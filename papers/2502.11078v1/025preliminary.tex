
Building on prior work\cite{yang2023palr,kang2023llms,zhou2024language}, we formalize the concept of persona quality and the objective of dynamic persona modeling as follows:

\noindent
\paragraph{Definition 1} (\textit{Persona Quality})
The extent to which a persona accurately represents a user’s preferences and behaviors, indicating its ability to predict future behaviors within a specific domain.

\noindent
\paragraph{Definition 2.} (\textit{Persona Optimization})
The updated persona better represents a user than the previous persona, with improved predictive capability within a specific domain.

\noindent
\paragraph{Objective:} (\textit{Continual Persona Optimization})
Iteratively enhance persona quality through multi-round updates, progressively enhancing its predictive capability within a specific domain.






\subsection{Task Formulation}
Consider a user $\mathcal{U}$ in domain $\mathcal{X}$. 
To capture temporal dynamics of user behaviors, we segment user’s online interactions into sequential, time-ordered windows $\mathbf{W}=\{\mathcal{W}_t\}_{t=0}^\mathcal{T}$. 
Each window $\mathcal{W}_t$ contains $N$ interactions, represented by an item list $\mathbf{I}_t = \{j_{t}^{j}\}_{j=1}^N$ and the corresponding user behaviors $\mathbf{O}_t = \{o_{t}^{j}\}_{j=1}^N$. 
As new data arrives at time $t$, the current window $\mathcal{W}_t$ captures interactions from the present period, while $\mathcal{W}_{t-1}$ reflects previous behaviors, and $\mathcal{W}_{t+1}$ outlines future interactions.

The LLM-based dynamic persona modeling pipeline consists of three stages:
\begin{itemize}[noitemsep,left=0pt]
    \item \textbf{Persona Initialization:} At time step $t=0$, the persona $\mathcal{S}_0$ is initialized based on the user behaviors in the initial window $\mathcal{W}_0$.
    \item \textbf{Behavior Observation and Prediction:} In each window $\mathcal{W}_t$, previous persona $\mathcal{S}_{t-1}$ is used to predict user behaviors $\hat{\mathbf{O}}_{t|\mathcal{S}_{t-1}} = \mathcal{P}(\mathcal{S}_{t-1})$, while actual behaviors $\mathbf{O}_t$ are observed.
    \item \textbf{Persona Update:} At the end of each window $\mathcal{W}_t$, the persona updates using new observations.
\end{itemize}

For the first two stages, we use frozen LLM to generate initial personas and predictions across all modeling paradigms. 
The Persona Update stage, however, varies by paradigm and is formulated as:
\begin{itemize}[noitemsep,left=0pt]
\item \textbf{Persona Regeneration:} Rebuild persona at the end of each window $\mathcal{W}_t$ using new behaviors $\mathbf{O}_t$:
\vspace{-2mm}
\[    
    \mathcal{S}_t = f_{\text{regen}}(\mathbf{O}_t). \tag{1} 
    \vspace{-2mm}
\]
\item \textbf{Persona Extension:} Extend the previous persona $\mathcal{S}_{t-1}$ with new behaviors $\mathbf{O}_t$:  
\vspace{-2mm}
\[
\mathcal{S}_t = f_{\text{exten}}(\mathcal{S}_{t-1}, \mathbf{O}_t). \tag{2} 
    \vspace{-2mm}
\]
\item \textbf{Persona Refinement (proposed):} Refine the previous persona $\mathcal{S}_{t-1}$ with new user behaviors $\mathbf{O}_t$, and predicted results 
$\hat{\mathbf{O}}_{t|\mathcal{S}_{t-1}}$:  
\vspace{-2mm}
\[
\mathcal{S}_t = f_{\text{refine}}(\mathcal{S}_{t-1}, \mathbf{O}_t, \hat{\mathbf{O}}_{t|\mathcal{S}_{t-1}}). \tag{3} 
\]
\end{itemize}
\subsection{Task Evaluation}

In this work, we assess persona quality indirectly through performance in a user- and domain-specific task: future behavior prediction. Prediction error, quantified by the Mean Absolute Error (MAE), serves as an indicator of \textit{Persona Quality}:

\vspace{-2mm}
\[
\varepsilon_{t+1|\mathcal{S}_t} = \frac{1}{n} \sum_{j=1}^N \big| \hat{o}_{t+1|\mathcal{S}_t}^{j} - o_{t+1}^{j} \big|. \tag{4}
\vspace{-2mm}
\]
$\mathbf{O}_{t+1} = \{o_{t+1}^j\}_{j=1}^N$ represents user actual behaviors in $\mathcal{W}_{t+1}$, while $\hat{\mathbf{O}}_{t+1|\mathcal{S}_t} = \{\hat{o}_{t+1|\mathcal{S}_t}^j\}_{j=1}^N$ denotes predictions with persona $\mathcal{S}_t$. 

Lower error indicates better alignment. \textit{Persona Optimization} is realized when an updated persona reduces the prediction error for future behaviors:
\vspace{-2mm}
\[
\varepsilon_{t+1|\mathcal{S}_t} < \varepsilon_{t|\mathcal{S}_{t-1}}. \tag{5}
\vspace{-2mm}
\]
Thus, the evaluation of a dynamic persona modeling method is determined by its ability to achieve the objective of \textit{Continual Persona Optimization}, with an effective update strategy evidenced by a progressive reduction in prediction error over time.