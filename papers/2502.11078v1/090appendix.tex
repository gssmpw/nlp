
\section{Dynamic Persona Modeling Details}
\subsection{Persona Initialization}
In this study, we employ the frozen LLM, GPT-4o-mini, to initialize user personas based on their first 10 ratings ($\mathcal{W}_0$) during the initial stage of dynamic persona modeling. The prompt used for persona initialization is presented in Table~\ref{persona_initialize}.

\begin{tcolorbox}
{\fontfamily{cmtt}\selectfont\small
TASK: Infer the user's persona based \\
on their ratings of {item\_type} items.\\
Instructions: \\
Below is a list of \\
\{item\_type\}s that the user has rated. \\
Each rating ranges from 1 to 5:\\
\{user\_ratings\}\\

Based on these, generate a user persona without mentioning item names or rating scores. 
\\
User Persona(at least  **200 words**):}
\end{tcolorbox}
\noindent\begin{minipage}{0.48\textwidth}
\captionof{table}{Persona Initialization prompt template.}\label{persona_initialize}
\end{minipage}

\subsection{Behavior Observation and Prediction}
For all user behavior prediction task, we use GPT-4o-mini to role-play the given input persona and predict user ratings on the given item list. Table~\ref{persona_prediction} shows the prompt template for the prediction task.

\begin{tcolorbox}
{\fontfamily{cmtt}\selectfont\small
TASK: Role-play the given persona and predict what score (out of 5) you would give to the following \{item\_type\} list.\\
Instructions: Based on the persona \{persona\}, predict ratings for each item in the list below.\\
\{items\}\\
\#\# Output format:\\
```json\\
\texttt{[}\\
    \{\{"item\_name":..., "predict\_rating":...\}\},\\
    \{\{"item\_name":..., "predict\_rating":...\}\},\\
    ...\\
\texttt{]}\\
```}
\end{tcolorbox}
\noindent\begin{minipage}{0.48\textwidth}
\captionof{table}{Behavior Prediction prompt template.}\label{persona_prediction}
\end{minipage}



\subsection{Persona Update}
In this work, the formulation of persona update stage varies by corresponding paradigms. For all baselines, we use GPT-4o-mini as backbone, while for \method, we use the fine-tune model via the iterative RL training framework based on Llama3.1-8b-Instruct. For each persona update method, we design corresponding update prompt template as follows.

\textbf{\method }
    The \method approach based on a refinement-based paradigm with predicted and actual user ratings. Table~\ref{persona_refinement_method_deeper} shows prompt template for persona update with \method.
    
    \begin{tcolorbox} 
        {\fontfamily{cmtt}\selectfont\small 
        TASK: \\
        Refine the old user persona based on differences 
        between predicted and actual ratings of \{item\_type\} 
        items.\ Instructions: \\
        Below is the existing persona 
        inferred from past behavior:\\
        \{old\_persona\} \\
        Below is the comparison of predicted ratings (based on the old persona) 
        versus actual ratings:\\
        \{predict\_and\_actual\_user\_ratings\}\\
        Reflect on these differences and generate a refined 
        user persona without mentioning item names or rating scores.
        Refined User Persona:

        }
        \end{tcolorbox}
        \noindent\begin{minipage}{0.48\textwidth}
        \captionof{table}{\method Persona Refinement prompt template.}\label{persona_refinement_method_deeper}
        \end{minipage}
        

\textbf{FullRegen}
In the FullRegen, we fully regenerate the user's persona whenever new ratings are provided. This method does not consider the prior persona and instead creates a fresh representation based all observed ratings. Table~\ref{persona_update_fullregen} shows the prompt template for persona update with FullRegen.

\begin{tcolorbox}
    {\fontfamily{cmtt}\selectfont\small
    TASK: Infer the user's persona based \\
    on their ratings of {item\_type} items.\\
    Instructions: \\
    Below is a list of \\
    \{item\_type\}s that the user has rated. \\
    Each rating ranges from 1 to 5:\\
    \{Full\_user\_ratings\}\\
    
    Based on these, generate a user persona without mentioning item names or rating scores. 
\\
    User Persona:
}
    \end{tcolorbox}
\noindent\begin{minipage}{0.48\textwidth}
\captionof{table}{FullRegen Persona Update prompt template.}
\label{persona_update_fullregen}
\end{minipage}




\textbf{SlideRegen} 
In the SlideRegen method, we regenerate personas based on their recent ratings of 
\{item\_type\} items(latest window). 
Table~\ref{persona_update_slideregen} shows the prompt template for persona update with SlideRegen.

\begin{tcolorbox}
    {\fontfamily{cmtt}\selectfont\small
    TASK: Infer the user's persona based \\
    on their ratings of {item\_type} items.\\
    Instructions: \\
    Below is a list of \\
    \{item\_type\}s that the user has rated. \\
    Each rating ranges from 1 to 5:\\
    \{Slide\_user\_ratings\}\\\\
Based on these, generate a user persona without mentioning item names or rating scores. 
\\
    User Persona:
   }
\end{tcolorbox}
\noindent\begin{minipage}{0.48\textwidth}
\captionof{table}{SlideRegen Persona Update prompt template.}\label{persona_update_slideregen}
\end{minipage}
    
    
\textbf{IncUpdate}
In the IncUpdate, the user's persona is dynamically updated by integrating new ratings with their existing persona. Table~\ref{persona_update_incupdate} shows prompt template for persona update with IncUpdate.

\begin{tcolorbox} {\fontfamily{cmtt}\selectfont\small 
    TASK: 
    Integrate the user's most recent ratings of \{item\_type\} \\
    items into their existing persona to generate an updated persona. \\
    Instructions: \\
    Below is the existing persona based on prior behaviors: \\
    \{old\_persona\} \\
    Below is a list of recent \{item\_type\}s that the user has rated.\\
    \ Each rating ranges from 1 to 5:\\
    \{user\_ratings\}\\
    \ Based on these, integrate 
    the new features from the recent ratings into the existing persona.\\
    \ Updated Persona:
   }
    \end{tcolorbox}
    \noindent\begin{minipage}{0.48\textwidth}
    \captionof{table}{IncUpdate Persona Update prompt template.}\label{persona_update_incupdate}
    \end{minipage}


\textbf{HierMerge}  
    The HierMerge method combines both long-term personas and short-term personas hierarchically. 
    Table~\ref{persona_update_hiermerge} shows prompt template for persona update with HierMerge.
    \begin{tcolorbox}
    {\fontfamily{cmtt}\selectfont\small
    \# Prompt 1:\\
    TASK: Infer the user's persona based on \\
    their ratings of \{item\_type\} items.\\
    Instructions: \\
    Below is a list of \\
    \{item\_type\}s that the user has rated.\\
    Each rating ranges from 1 to 5:\\
    \{user\_ratings\}\\
    Based on these, generate a user\\
     persona without mentioning item names or rating scores.\\
    User Persona:\\

    


    \# Prompt 2:
    TASK: 
    Update the long-term persona by merging 
    it with the newly generated short-term 
    persona.
    Instructions: \\
    Below is 
    the existing long-term persona based 
    on prior behaviors:\{long\_term\_persona\} \\
    Below is the newly generated short-term persona 
    based on recent behaviors:\{short\_term\_persona\} \\ 
    Merge the short-term persona into the long-term persona 
    to capture both historical stability and recent dynamics.\\ 
    The updated persona should reflect both long-term \\
    preferences and recent changes without losing consistency.\\ 
    Updated Long-Term Persona: \\
   
    }
    \end{tcolorbox}
    \noindent\begin{minipage}{0.48\textwidth}
    \captionof{table}{HierMerge Persona Update prompt template.}\label{persona_update_hiermerge}
    \end{minipage}
    




\begin{table*}[t]
    \footnotesize
    \begin{tabular}{cccccc}
    \toprule
    \midrule
    \textbf{Dataset} & \textbf{Abbreviation} & \textbf{Usage} & \multicolumn{1}{c}{\begin{tabular}[c]{@{}c@{}}\textbf{\# Users}\\ \textbf{in Train}\\ \end{tabular}} & \multicolumn{1}{c}{\begin{tabular}[c]{@{}c@{}}\textbf{\# Users}\\ \textbf{in Eval}\end{tabular}} & \multicolumn{1}{c}{\begin{tabular}[c]{@{}c@{}}\textbf{\# Train}\\ \textbf{Examples}\end{tabular}} \\ \midrule
    \begin{tabular}[c]{@{}c@{}}Food.com Recipes \\ - and Interactions\end{tabular} & Recipe & Train/Eval & 1000 & 356 & A \\  \midrule
    \begin{tabular}[c]{@{}c@{}}Amazon Review Data (2018) \\ - Books\end{tabular} & Book & Train/Eval & 3000 & 897 & B \\\midrule  
    \begin{tabular}[c]{@{}c@{}}Amazon Review Data (2018) \\ - Clothing Shoes and Jewelry\end{tabular} & Clothing Shoes and Jewelry & Train/Eval & 300 & 243 & C \\  \midrule
    \begin{tabular}[c]{@{}c@{}}Google Local Data (2021) \\ - New York\end{tabular} & Local Business & Train/Eval & 2500 & 826 & D \\ \midrule
    \begin{tabular}[c]{@{}c@{}}MovieLens \\ - 20M Dataset\end{tabular} & MovieLens & Train/Eval & 3000 & 1000 & E \\ \midrule 
    \begin{tabular}[c]{@{}c@{}}Amazon Review Data (2018) \\ - Art Crafts and Sewing\end{tabular} & Art Crafts and Sewing & Eval & - & 86 & F \\  \midrule
    \begin{tabular}[c]{@{}c@{}}Amazon Review Data (2018) \\ - Automative\end{tabular} & Automative & Eval & - & 143 & G \\  \midrule
    \begin{tabular}[c]{@{}c@{}}Amazon Review Data (2018) \\ - Sports and Outdoors\end{tabular} & Sports and Outdoors & Eval & - & 236 & H \\  \midrule
    \begin{tabular}[c]{@{}c@{}}Amazon Review Data (2018) \\ - Grocery and Gourmet Food\end{tabular} & Grocery and Gourmet Food & Eval & - & 185 & I \\ 
    \bottomrule
    \end{tabular}
    \caption{Details of Datasets Used in Experiments.}
    \label{tab:data1set}
    \vskip -0.1in
\end{table*}


\section{Dataset Details}


\subsection{User Details}

We utilize four publicly available and well-known datasets, selecting a total of 10 domains. From six domains, we randomly sampled a total of 14,959 users with at least 50 ratings. Among these, 10,800 users are used for constructing the training data, and 4,159 users are used for constructing the testing data. Additionally, to evaluate the generalization ability of the methods, we sampled 650 users with at least 50 ratings from four unseen domains to construct an additional test set. Each user's 50 rating behaviors are sorted by timestamp and divided into five sequences of length 10, simulating multi-round online user interactions. The detailed user sampling statistics are in Table ~\ref{tab:data1set}:





\subsection{Training Data Construction}
In \textbf{Iteration 1}, a total of 10,800 
context data points are constructed, 
each corresponding to the first persona refinement step for each user. 
For each context, 15 candidate personas are randomly sampled using the 
Llama3.1-8b-Instruct model, with inference parameters set as follows: 
\texttt{temperature=1} (to ensure diversity among the candidates), 
\texttt{top\_p=0.4} (to control the cumulative probability of tokens), 
and \texttt{repetition\_penalty=1.1} (to prevent repetition in the generated output). 
The boundaries for positive and negative reward sets are set to 0.5 and 0, 
with a margin of 0.5. In total, 34,782 DPO preference pairs are constructed, 
with 10\% randomly selected for the validation set. This data is used to train 
\textbf{Model 1}.

In \textbf{Iteration 2}, \textbf{Model 1} is first used to generate outputs for the 10,800 context data points from Iteration 1, completing the first persona update for each user. These results, in turn, are used to construct a second set of 10,800 context data points for the second persona refinement. These are then combined with the 10,800 context data points constructed in the first iteration, resulting in a total of 21,600 context data points for sampling in the second iteration. For each context, 15 candidate personas are again randomly sampled using \textbf{Model 1}, with the same inference parameters as in Iteration 1. The boundaries for positive and negative reward sets are set to 0.5 and 0, with a margin of 0.8. A total of 28,612 new DPO preference pairs are generated. Additionally, 5,000 preference pairs with a margin greater than 0.8 are randomly selected from Iteration 1 to be included in the training set, mitigating the issue of catastrophic forgetting. This results in a total of 33,612 DPO preference pairs, with 10\% randomly selected for the validation set, used to train \textbf{Model 2}.



\begin{table*}[ht]
   \footnotesize
    \centering
    \caption{Hyperparameter Details for Training}
    \label{tab:hyperparameters}
    \begin{tabular}{ccc}
        \toprule
        \midrule
    \textbf{Parameter}               & \textbf{Value}                                  & \textbf{Description}                                  \\
    \\\midrule
    Model Name or Path               & \texttt{Llama-3.1-8B-Instruct}                  & Path to the model                                     \\
    Finetuning Type                  & \texttt{lora}                                   & Type of finetuning                                   \\ 
    Training Stage                   & \texttt{dpo}                                    & Current training stage                               \\ 
    LoRA Target                      & \texttt{all}                                    & LoRA target layers                                  \\  
    LoRA Rank                        & 16                                              & LoRA rank                                           \\  
    LoRA Alpha                       & 32                                              & LoRA alpha                                          \\  
    LoRA Dropout                     & 0.2                                             & LoRA dropout rate                                   \\  
    Preference Beta                  & 0.2                                             & Preference loss beta                                \\  
    Preference Loss Type             & \texttt{sigmoid}                                & Type of preference loss                             \\  
    Preference Finetune Rate         & 0.1                                             & Preference finetuning rate                         \\ 
    Maximum Sequence Length          & 2048                                            & Maximum input sequence length                      \\  
    Training Batch Size              & 4                                               & Batch size per device during training             \\  
    Gradient Accumulation Steps      & 8                                               & Steps for gradient accumulation                   \\  
    Learning Rate                    & 5.0e-06                                         & Learning rate                                     \\  
    Number of Epochs                 & 4.0                                             & Total number of training epochs                   \\  
    Learning Rate Scheduler          & \texttt{cosine}                                 & Learning rate scheduling strategy                 \\  
    Warmup Steps                     & 250                                             & Warmup steps before full learning rate            \\  
    Maximum Gradient Norm            & 1.0                                             & Maximum norm for gradient clipping                \\  
    BF16 Precision                   & \texttt{true}                                   & Use BF16 precision                                 \\ 
    Optimizer                        & \texttt{adamw\_torch}                           & Type of optimizer                                 \\  
    Validation Size                  & 0.1                                             & Fraction of data used for validation              \\  
    Evaluation Batch Size            & 4                                               & Batch size per device during evaluation           \\  
    Evaluation Strategy              & \texttt{steps}                                  & Evaluation scheduling strategy                    \\  
    Evaluation Steps                 & 100                                             & Steps between evaluations                         \\  
    \midrule
    \bottomrule    
\end{tabular}
    \end{table*}

\newpage
\section{Training Details}
\subsection{Hyperparameter Details}

The hyperparameters used in the training process are summarized in Table~\ref{tab:hyperparameters}.

\subsection{Loss Function Details}
In this section, we provide the detailed formulations of the training loss functions combined with DPO loss and SFT loss.

\paragraph{DPO Loss}
The DPO loss optimizes the model by leveraging user preference signals to align persona refinements with higher rewards. The loss is defined as:

\begin{align}
  \small
  \mathcal{L}_{\text{DPO}}(\pi_\theta; \pi_{\text{ref}}) = 
  &-\mathbb{E}_{(x, y_w, y_l) \sim \mathcal{D}} \notag \\
  &\left[ 
  \log \sigma \left( 
  \beta \log \frac{\pi_\theta(y_w \mid x)}{\pi_{\text{ref}}(y_w \mid x)} 
  \right. \right. \notag \\
  &\left. \left. - 
  \beta \log \frac{\pi_\theta(y_l \mid x)}{\pi_{\text{ref}}(y_l \mid x)} 
  \right) 
  \right]. \tag{11}
  \end{align} 
  
  
The policy distribution of the model being trained, parameterized by \(\theta\). It represents the probability of generating specific outputs conditioned on the input \(x\).
The reference model's policy distribution, used as a baseline for comparison. It is typically a pretrained model or a checkpoint used to stabilize training.
A tuple sampled from the dataset \(\mathcal{D}\), where:
\begin{itemize}[noitemsep,left=0pt]
        \item \(x\): The input prompt or context.
        \item \(y_w\): better personas, corresponding to more optimal update directions.
        \item \(y_l\): poor personas, corresponding to less effective update directions.
\end{itemize}

    A scaling factor that controls the sensitivity of the loss function to the difference between the preferred and less preferred outputs. Larger values emphasize the contrast between the two.
    The conditional probabilities of the preferred (\(y_w\)) and less preferred (\(y_l\)) outcomes under the current model.
    The conditional probabilities of the preferred and less preferred outcomes under the reference model.
    The loss is computed as an average over the entire dataset \(\mathcal{D}\), which contains human-annotated preference pairs \((x, y_w, y_l)\).



\paragraph{SFT Loss}
The SFT loss is used to aline the model output with high-quality refined-persona candidates. The loss is computed as the negative log-likelihood of the reference outputs:
\[
\mathcal{L}_{\text{SFT}}(\pi_\theta) = - \mathbb{E}_{(x, y_w) \sim \mathcal{D}} \big[ \log \pi_\theta(y_w|x) \big]. \tag{12}
\]
where \(\mathcal{D}\) is the dataset of supervised examples, \(x\) represents the input context, and \(y\) is the corresponding ground truth persona refinement.


\paragraph{Combined Loss for Iterative Training}
To achieve robust refinement across iterations, we combine the SFT loss and DPO loss :
\[
\mathcal{L}(\pi_\theta; \pi_{\text{ref}}) = \mathcal{L}_{\text{DPO}}(\pi_\theta; \pi_{\text{ref}}) +  \mathcal{L}_{\text{SFT}}(\pi_\theta). \tag{13}
\]








\clearpage
\section{Dynamic Persona Modeling Task}


In the main experiment, we focused on the dynamic persona modeling task, where different methods are employed to perform four rounds of updates on the test set. These iterative updates provided specific values for predicting future user behavior, enabling us to assess the accuracy and effectiveness of each method in forecasting user actions. By evaluating the Mean Absolute Error (MAE) across various domains before and after refinement, we are able to determine the improvements achieved through each method. The results, detailed in Table \ref{tab:Deeper_results},Table \ref{tab:fullregen_results},Table \ref{tab:slideregen_results},Table \ref{tab:incupdate_results},Table \ref{tab:hiermerge_results}, highlight the performance gains and validate the superiority of the proposed approaches in enhancing prediction accuracy.



\begin{table}[h]
    \centering
    \scriptsize
    \def\arraystretch{.99}
    \setlength{\tabcolsep}{0.42em}
    \begin{tabular}{lccccc}
      \toprule
      \textbf{Domain} & $\varepsilon_{1|\mathcal{S}_0}$ & $\varepsilon_{2|\mathcal{S}_1}$ & $\varepsilon_{3|\mathcal{S}_2}$ & $\varepsilon_{4|\mathcal{S}_3}$ & $\varepsilon_{5|\mathcal{S}_4}$ \\
      \midrule
      Art Crafts and Sewing     & 0.76 & 0.43 & 0.44 & 0.41 & 0.40 \\
      Automative                & 0.84 & 0.61 & 0.60 & 0.59 & 0.57 \\
      Book                      & 1.00 & 0.79 & 0.70 & 0.68 & 0.67 \\
      Clothing Shoes and Jewelry& 1.00 & 0.88 & 0.84 & 0.75 & 0.74 \\
      Grocery and Gourmet Food  & 1.19 & 0.89 & 0.79 & 0.77 & 0.73 \\
      Local Business            & 1.04 & 0.80 & 0.70 & 0.70 & 0.69 \\
      Movie                     & 0.87 & 0.73 & 0.73 & 0.72 & 0.72 \\
      Movies and TV             & 1.12 & 0.98 & 0.83 & 0.79 & 0.77 \\
      Recipe                    & 0.91 & 0.72 & 0.65 & 0.59 & 0.58 \\
      Sports and Outdoors       & 0.91 & 0.80 & 0.68 & 0.66 & 0.66 \\
      \bottomrule
    \end{tabular}
    \caption{Deeper Results}
    \label{tab:Deeper_results}
    \vspace{-0.1cm}
  \end{table}
  




\begin{table}[h]
    \centering
    \scriptsize
    \def\arraystretch{.99}
    \setlength{\tabcolsep}{0.42em}
    \begin{tabular}{lccccc}
      \toprule
      \textbf{Domain} & $\varepsilon_{1|\mathcal{S}_0}$ & $\varepsilon_{2|\mathcal{S}_1}$ & $\varepsilon_{3|\mathcal{S}_2}$ & $\varepsilon_{4|\mathcal{S}_3}$ & $\varepsilon_{5|\mathcal{S}_4}$ \\
      \midrule
      Art Crafts and Sewing     & 0.76 & 0.77 & 0.74 & 0.69 & 0.75 \\
      Automative                & 0.84 & 0.92 & 0.92 & 0.92 & 0.93 \\
      Book                      & 1.00 & 1.03 & 1.00 & 1.00 & 1.00 \\
      Clothing Shoes and Jewelry& 1.00 & 1.03 & 1.03 & 1.03 & 1.03 \\
      Grocery and Gourmet Food  & 1.19 & 1.20 & 1.17 & 1.14 & 1.13 \\
      Local Business            & 1.04 & 1.04 & 1.02 & 1.03 & 1.02 \\
      Movie                     & 0.87 & 0.83 & 0.84 & 0.84 & 0.85 \\
      Movies and TV             & 1.12 & 1.12 & 1.13 & 1.13 & 1.11 \\
      Recipe                    & 0.91 & 0.92 & 0.83 & 0.84 & 0.85 \\
      Sports and Outdoors       & 0.91 & 0.93 & 0.85 & 0.88 & 0.88 \\
      \bottomrule
    \end{tabular}
    \caption{FullRegen (GPT-4o-mini) Results}
    \label{tab:fullregen_results}
    \vspace{-0.1cm}
  \end{table}
  


\begin{table}[h]
    \centering
    \scriptsize
    \def\arraystretch{.99}
    \setlength{\tabcolsep}{0.42em}
    \begin{tabular}{lccccc}
      \toprule
      \textbf{Domain} & $\varepsilon_{1|\mathcal{S}_0}$ & $\varepsilon_{2|\mathcal{S}_1}$ & $\varepsilon_{3|\mathcal{S}_2}$ & $\varepsilon_{4|\mathcal{S}_3}$ & $\varepsilon_{5|\mathcal{S}_4}$ \\
      \midrule
      Art Crafts and Sewing     & 0.76 & 0.81 & 0.72 & 0.66 & 0.74 \\
      Automative                & 0.84 & 0.96 & 0.91 & 0.91 & 0.90 \\
      Book                      & 1.00 & 1.06 & 1.02 & 1.03 & 1.02 \\
      Clothing Shoes and Jewelry& 1.00 & 1.09 & 1.08 & 1.02 & 1.07 \\
      Grocery and Gourmet Food  & 1.19 & 1.14 & 1.13 & 1.13 & 1.09 \\
      Local Business            & 1.04 & 1.06 & 1.05 & 1.03 & 1.03 \\
      Movie                     & 0.87 & 0.84 & 0.85 & 0.87 & 0.86 \\
      Movies and TV             & 1.12 & 1.14 & 1.16 & 1.17 & 1.14 \\
      Recipe                    & 0.91 & 0.92 & 0.89 & 0.87 & 0.87 \\
      Sports and Outdoors       & 0.91 & 0.94 & 0.87 & 0.92 & 0.93 \\
      \bottomrule
    \end{tabular}
    \caption{SlideRegen (GPT-4o-mini) Results}
    \label{tab:slideregen_results}
    \vspace{-0.1cm}
  \end{table}
  

\begin{table}[h]
    \centering
    \scriptsize
    \def\arraystretch{.99}
    \setlength{\tabcolsep}{0.42em}
    \begin{tabular}{lccccc}
      \toprule
      \textbf{Domain} & $\varepsilon_{1|\mathcal{S}_0}$ & $\varepsilon_{2|\mathcal{S}_1}$ & $\varepsilon_{3|\mathcal{S}_2}$ & $\varepsilon_{4|\mathcal{S}_3}$ & $\varepsilon_{5|\mathcal{S}_4}$ \\
      \midrule
      Art Crafts and Sewing     & 0.76 & 0.71 & 0.70 & 0.59 & 0.66 \\
      Automative                & 0.84 & 0.88 & 0.81 & 0.87 & 0.82 \\
      Book                      & 1.00 & 0.96 & 0.94 & 0.92 & 0.94 \\
      Clothing Shoes and Jewelry & 1.00 & 1.00 & 0.97 & 0.93 & 0.92 \\
      Grocery and Gourmet Food  & 1.19 & 1.10 & 1.05 & 1.05 & 1.04 \\
      Local Business            & 1.04 & 0.97 & 0.94 & 0.93 & 0.91 \\
      Movie                     & 0.87 & 0.76 & 0.76 & 0.76 & 0.75 \\
      Movies and TV             & 1.12 & 1.06 & 1.06 & 1.04 & 1.05 \\
      Recipe                    & 0.91 & 0.91 & 0.84 & 0.84 & 0.81 \\
      Sports and Outdoors       & 0.91 & 0.89 & 0.85 & 0.85 & 0.83 \\
      \bottomrule
    \end{tabular}
    \caption{IncUpdate (GPT-4o-mini) Results}
    \label{tab:incupdate_results}
   \end{table}
  
\newpage


\begin{table}[t]
    \centering
    \scriptsize
    \def\arraystretch{.99}
    \setlength{\tabcolsep}{0.42em}
    \begin{tabular}{lccccc}
      \toprule
      \textbf{Domain} & $\varepsilon_{1|\mathcal{S}_0}$ & $\varepsilon_{2|\mathcal{S}_1}$ & $\varepsilon_{3|\mathcal{S}_2}$ & $\varepsilon_{4|\mathcal{S}_3}$ & $\varepsilon_{5|\mathcal{S}_4}$ \\
      \midrule
      Art Crafts and Sewing     & 0.76 & 0.75 & 0.74 & 0.67 & 0.74 \\
      Automative                & 0.84 & 0.88 & 0.86 & 0.94 & 0.87 \\
      Book                      & 1.00 & 1.03 & 0.98 & 0.97 & 0.96 \\
      Clothing Shoes and Jewelry& 1.00 & 1.04 & 1.01 & 1.04 & 1.04 \\
      Grocery and Gourmet Food  & 1.19 & 1.19 & 1.17 & 1.18 & 1.16 \\
      Local Business            & 1.04 & 1.04 & 1.00 & 1.01 & 1.00 \\
      Movie                     & 0.87 & 0.82 & 0.83 & 0.83 & 0.82 \\
      Movies and TV             & 1.12 & 1.12 & 1.11 & 1.10 & 1.09 \\
      Recipe                    & 0.91 & 0.94 & 0.87 & 0.83 & 0.83 \\
      Sports and Outdoors       & 0.91 & 0.90 & 0.89 & 0.91 & 0.88 \\
      \bottomrule
    \end{tabular}
    \caption{HierMerge (GPT-4o-mini) Results}
    \label{tab:hiermerge_results}

  \end{table}
  



\clearpage
\section{What Enables \method's Effectiveness}
Below, we present an in-depth analysis of the mechanisms underlying \method’s effectiveness.

\subsection{Proving Effectiveness of Direction search}
Firstly, we prove the effectiveness of the direction search method by comparing its performance with a direct refinement using the frozen model(GPT-4o-mini and the base model, Llama3.1-8b-Instruct), through a single round of refinement. The details of the experimental results are as follows Label \ref{tab:direction_search_use}.

\begin{itemize}[noitemsep,left=0pt]
    \item \textbf{Baseline 1} Directly Refine personas with the base model (Llama3.1-8b-Instruct) 
    \item \textbf{Baseline 2} Directly Refine personas with the more powerful model (GPT-4o-mini) 
    \item \textbf{\method} Refine personas with auto-direction search mechanism
\end{itemize}



\begin{table}[h]
\centering
\scriptsize
\def\arraystretch{.99}
\setlength{\tabcolsep}{0.42em}
  \begin{tabular}{lcccc}
    \toprule
    & \multicolumn{1}{c}{\textbf{\begin{tabular}[c]{@{}c@{}}Before \\ Update\end{tabular}}} & \multicolumn{3}{c}{\textbf{\begin{tabular}[c]{@{}c@{}}After \\ Update\end{tabular}}} \\
    \midrule
    \textbf{Domain} & $\varepsilon_{1|\mathcal{S}_0}$ & \begin{tabular}[c]{@{}c@{}}$\varepsilon_{2|\mathcal{S}_1}$ \\ (\method)\end{tabular}& \begin{tabular}[c]{@{}c@{}}$\varepsilon_{2|\mathcal{S}_1}$ \\(GPT-4o-mini)\end{tabular} & \begin{tabular}[c]{@{}c@{}}$\varepsilon_{2|\mathcal{S}_1}$ \\ (Llama3.1-8b-Instruct)\end{tabular}\\
    \midrule
    A                    & 0.91 & 0.72 & 0.99 & 1.07 \\
    B                      & 1.01 & 0.79 & 1.20 & 1.21 \\
    C& 1.03 & 0.88 & 1.09 & 1.14 \\
    D            & 1.04 & 0.80 & 1.20 & 1.19 \\
    E             & 1.18 & 0.98 & 1.24 & 1.19 \\
    F                     & 0.85 & 0.73 & 0.84 & 0.87 \\
    G     & 0.74 & 0.43 & 0.95 & 0.89 \\
    H                & 0.85 & 0.61 & 1.02 & 1.08 \\
    I  & 1.26 & 0.89 & 1.26 & 1.19 \\
    J       & 0.96 & 0.80 & 1.04 & 1.02 \\
    \bottomrule
  \end{tabular}
  \caption{Future behaviour prediction errors before and after one-step refinement with \method and the frozen models.}
  \label{tab:direction_search_use}
  \vspace{-0.1cm}
\end{table}


\subsection{Proving the Effectiveness of Balanced Reward}

In this analysis, we aim to demonstrate the effectiveness of the balanced reward strategy by comparing it against two baseline reward settings. Specifically, we evaluate how different reward configurations influence the performance of the model during the refinement process.


\paragraph{Baseline Reward Settings}
We establish two baseline configurations to assess the impact of reward settings:

\begin{itemize}[noitemsep,left=0pt]
    \item \textbf{Baseline 1: Future Advancement Only} \\
    In this setting, the reward at each timestep $t$ is solely based on future advancement. Mathematically, this is defined as:
    \[
    r_t = r_{\text{fut}} = r_t^{\text{fut}}. \tag{14}
    \]
    
    \item \textbf{Baseline 2: Decayed Rewards} \\
    Here, we incorporate past, current, and future rewards with decay factors applied to past and current rewards. The reward at timestep $t$ is calculated as:
    \[
    r_t = r_{\text{decay}} = 0.25 \cdot r_t^{\text{prev}} + 0.5 \cdot r_t^{\text{curr}} + r_t^{\text{fut}}. \tag{15}
    \]
    where the decay factor $y = 0.5$ is applied to both past and current rewards.
\end{itemize}

\paragraph{Our Reward Setting: Balanced Rewards}
Our proposed reward setting balances the three components—past, current, and future—without applying decay factors. The reward at timestep $t$ is defined as:
\[
r_t = r_t^{\text{prev}} + r_t^{\text{curr}} + r_t^{\text{fut}}. \tag{16}
\]
This approach ensures that all three goals are equally considered during the refinement process.

\textbf{Experimental Results}
The experimental results comparing the baseline reward settings with our balanced reward strategy are presented in Table \ref{tab:balanced_reward_results_refined}, which showcase future prediction errors across various domains before and after one-step refinement under different reward configurations.

\begin{table}[h]
\centering
\scriptsize
\def\arraystretch{.99}
\setlength{\tabcolsep}{0.42em}
  \begin{tabular}{lcccc}
    \toprule
    & \multicolumn{1}{c}{\textbf{\begin{tabular}[c]{@{}c@{}}Before \\ Update\end{tabular}}} & \multicolumn{3}{c}{\textbf{\begin{tabular}[c]{@{}c@{}}After \\ Update\end{tabular}}} \\
    \midrule
    \textbf{Domain} & $\varepsilon_{1|\mathcal{S}_0}$ & \begin{tabular}[c]{@{}c@{}}$\varepsilon_{2|\mathcal{S}_1}$ \\ (\method)\end{tabular}& \begin{tabular}[c]{@{}c@{}}$\varepsilon_{2|\mathcal{S}_1}$ \\($r_{\text{fut}}$)\end{tabular} & \begin{tabular}[c]{@{}c@{}}$\varepsilon_{2|\mathcal{S}_1}$ \\ ($r_{\text{decay}}$)\end{tabular}\\
    \midrule
    A                    & 0.91 & 0.72 & 0.81 & 0.74 \\
    B                      & 1.01 & 0.79 & 0.86 & 0.84 \\
    C & 1.03 & 0.88 & 0.95 & 0.95 \\
    D            & 1.04 & 0.80 & 0.88 & 0.84 \\
    E             & 1.18 & 0.98 & 1.03 & 1.03 \\
    F                     & 0.85 & 0.73 & 0.81 & 0.77 \\
    G     & 0.74 & 0.43 & 0.59 & 0.51 \\
    H                & 0.85 & 0.61 & 0.83 & 0.68 \\
    I  & 1.26 & 0.89 & 0.94 & 0.92 \\
    J       & 0.96 & 0.80 & 0.85 & 0.83 \\
    \bottomrule
  \end{tabular}
  \caption{Balanced reward (\method) vs. Baseline reward settings results}
  \label{tab:balanced_reward_results_refined}
  \vspace{-0.1cm}
\end{table}




\subsection{Proving the Effectiveness of Iterative RL Training}

In this analysis, we aim to demonstrate the effectiveness of iterative RL training by comparing the performance of the model after one iteration of refinement versus two iterations. This comparison helps to understand whether additional refinement iterations contribute to improved model performance.

\textbf{Baseline} To evaluate the impact of iterative RL training, we establish two baseline configurations:
\begin{itemize}[noitemsep,left=0pt]
    \item \textbf{Baseline 1: Single Iteration} \\
    The model undergoes one iteration of training.
    
    \item \textbf{Baseline 2: Two Iterations} \\
   The model undergoes two consecutive iterations of training to assess whether additional refinement leads to further performance gains.
\end{itemize}

\textbf{Experimental Results} The experimental results comparing single and double iterations of RL-based refinement are presented in Table \ref{tab:iterative_rl_training_results_refined}.

    
\begin{table}[h]
\centering
\scriptsize
\def\arraystretch{.99}
\setlength{\tabcolsep}{0.42em}
  \begin{tabular}{lccc}
    \toprule
    & \multicolumn{1}{c}{\textbf{\begin{tabular}[c]{@{}c@{}}Before \\ Update\end{tabular}}} & \multicolumn{2}{c}{\textbf{\begin{tabular}[c]{@{}c@{}}After \\ Update\end{tabular}}} \\
    \midrule
    \textbf{Domain} & $\varepsilon_{1|\mathcal{S}_0}$ & \begin{tabular}[c]{@{}c@{}}$\varepsilon_{2|\mathcal{S}_1}$ \\ (\method(Iter1))\end{tabular}& \begin{tabular}[c]{@{}c@{}}$\varepsilon_{2|\mathcal{S}_1}$ \\(\method(Iter2))\end{tabular} \\
    \midrule
    A                    & 0.91 & 0.84 & 0.72 \\
    B                      & 1.01 & 0.93 & 0.79 \\
    C & 1.03 & 0.99 & 0.88 \\
    D            & 1.04 & 0.98 & 0.80 \\
    E             & 1.18 & 1.12 & 0.98 \\
    F                     & 0.85 & 0.78 & 0.73 \\
    G     & 0.74 & 0.65 & 0.43 \\
    H                & 0.85 & 0.87 & 0.61 \\
    I  & 1.26 & 1.03 & 0.89 \\
    J       & 0.96 & 0.91 & 0.80 \\
    \bottomrule
  \end{tabular}
  \caption{Iterative RL Training (\method) Results comparison: Single vs. Double Training Iterations}
  \label{tab:iterative_rl_training_results_refined}
  \vspace{-0.1cm}
\end{table}

\newpage
\subsection{Proving the Effectiveness of Introducing Prediction Results in Refinement Paradigm}

In this analysis, we aim to demonstrate the effectiveness of incorporating prediction results into the paradigm. Specifically, we leverage the iterative RL training framework of \method to enhance IncUpdate(Inc-FT), which is the best performing baseline and based on paradigm of Persona Extension. This enable auto-direction search in traditional dynamic persona paradigm which does not involve prediction results into observations. The comparison between \method and Inc-FT helps to understand whether integrating prediction results helps direction search.

\textbf{Experimental Results} The experimental results are presented in Table \ref{tab:prediction_result_effectiveness_results_refined}. 

\begin{table}[h]
\centering
\scriptsize
\def\arraystretch{.99}
\setlength{\tabcolsep}{0.42em}
  \begin{tabular}{lccc}
    \toprule
    & \multicolumn{1}{c}{\textbf{\begin{tabular}[c]{@{}c@{}}Before \\ Update\end{tabular}}} & \multicolumn{2}{c}{\textbf{\begin{tabular}[c]{@{}c@{}}After \\ Update\end{tabular}}} \\
    \midrule
    \textbf{Domain} & $\varepsilon_{1|\mathcal{S}_0}$ & \begin{tabular}[c]{@{}c@{}}$\varepsilon_{2|\mathcal{S}_1}$ \\ (\method)\end{tabular}& \begin{tabular}[c]{@{}c@{}}$\varepsilon_{2|\mathcal{S}_1}$ \\(Inc-FT))\end{tabular} \\
    \midrule
    Recipe                    & 0.91 & 0.72 & 0.77 \\
    Book                      & 1.01 & 0.79 & 0.85 \\
    Clothing Shoes and Jewelry& 1.03 & 0.88 & 0.95 \\
    Local Business            & 1.04 & 0.80 & 0.81 \\
    Movies and TV             & 1.18 & 0.98 & 1.02 \\
    Movie                     & 0.85 & 0.73 & 0.79 \\
    Art Crafts and Sewing     & 0.74 & 0.43 & 0.62 \\
    Automative                & 0.85 & 0.61 & 0.78 \\
    Grocery and Gourmet Food  & 1.26 & 0.89 & 0.97 \\
    Sports and Outdoors       & 0.96 & 0.91 & 0.81 \\
    \bottomrule
  \end{tabular}
  \caption{Effectiveness of Introducing Prediction Results: \method vs. IncUpdate (Inc-FT)}
  \label{tab:prediction_result_effectiveness_results_refined}
  \vspace{-0.1cm}
\end{table}



\begin{table*}[t]
      \small
      \centering
      \caption{Important Profiling Dimensions in the Book Domain}
      \begin{tabular}{lp{7.5cm}}  % Reduce width to fit within the page
      \toprule
      \textbf{Dimensions}            & \textbf{High-Frequency Terms and Frequency}                                                                                                      \\ \midrule
      \textbf{Story \& Plot}       & story (759), experience (596), reader (579), narrative (566), storytelling (445), development (440), plot (286), adventure (196), fantasy (187), suspense (156), mystery (155), action (150), passion (149), thriller (109), journey (92), arc (75), drama (66), protagonist (58), redemption (54)           \\ \midrule
      \textbf{Genre \& Theme}      & theme (655), genre (647), romance (388), aspect (406), level (379), content (329), complexity (325), depth (325), world (277), novel (212), topic (189), element (231), idea (189), nuance (148), literature (137), nature (118), issue (122), setting (88), balance (97), thought (96)      \\ \midrule
      \textbf{Author \& Character} & author (143), quality (155), character (600), characteristic (93), identity (70), protagonist (58) \\ \midrule
      \textbf{Emotion \& Experience}  & affinity (217), appreciation (700), experience (596), willingness (685), desire (563), love (410), enthusiasm (377), resonance (352), emotion (185), escapism (203), curiosity (182), expectation (167), favor (153), enjoyment (136), excitement (121), comfort (117) \\ \midrule
      \textbf{User Behavior Traits}  & range (568), star (518), growth (318), perspective (279), engagement (250), title (247), tendency (185), habit (155), exploration (140), investment (86), variety (67) \\ \midrule
      \textbf{User Personality \& Values} & willingness (685), preference (581), individual (388), value (221), self (183), discerning (183), personality (132), creativity (94), empathy (85), adaptability (90) \\ \midrule
      \textbf{Social \& Cultural Context} & life (198), community (164), time (181), boundary (99), need (112), culture (77), knowledge (88), learning (95), justice (61) \\ \midrule
      \textbf{Relationship \& Connection} & connection (474), relationship (411), choice (98), family (67), interaction (57) \\ \bottomrule
      \end{tabular}
      \label{tab:profiling_dimensions}
    \end{table*}
    
\newpage
\section{Persona Probing}

\subsection{Important Profiling Dimensions in Book Domain}
    Table ~\ref{tab:profiling_dimensions} summarizes the key profiling dimensions for users in the book domain, along with the high-frequency terms and their frequencies within each dimension. These dimensions include “Story \& Plot,” “Genre \& Theme,” “Author \& Character,” among others, which encapsulate critical aspects of user preferences and behaviors. The table highlights the most commonly used terms, such as “story,” “experience,” and “reader” under the “Story \& Plot” dimension, providing insights into what users value when engaging with book-related content.


\subsection{Insights into User Group Characteristics}
Table ~\ref{tab:group_user} illustrates the unique adjectives frequently associated with specific user groups, providing a detailed view of the preferences that distinguish these groups. For instance, Group 1 exhibits traits such as “romantic” and “dedicated,” while Group 4 emphasizes “practical” and “cultural” preferences. These findings underscore the variation in user characteristics, enabling targeted persona optimization based on group-specific attributes.

\begin{table}[h]
  \small
  \centering
  \caption{Group-level preference for users}
  \begin{tabular}{lp{5cm}} % 允许内容换行
  \toprule
  \textbf{User Groups}    & \textbf{Unique High-Frequency Adjectives}  \\
  \midrule
  Group 1    & romantic, paranormal, voracious, \\  % 加中线
             & dedicated, afraid                                    \\ \midrule
  Group 2    & notable, humorous, unconventional, \\  % 加中线
             & close, entertaining                                \\ \midrule
  Group 3    & dramatic, dedicated, \\   % 加中线
             & resonant                                                         \\ \midrule
  Group 4    & practical, spiritual, historical, cultural, \\ % 加中线
             & likely, playful, dynamic, inspirational, close \\ \midrule
  Group 5    & thoughtful, non, suspenseful, \\   % 加中线
             & fiction, dynamic, engaging, immersive                   \\ 
  \bottomrule
  \end{tabular}
  \label{tab:group_user}
\end{table}
      

\clearpage
\section{Case Study: A User in Book Domain}
To deeply evaluate the performance of different persona updates methods for dynamic persona modeling, we selected a single user from the book domain. This domain provides a complex and rich context, as users often demonstrate evolving preferences, diverse genre interests, and emotional connections with books over time. In case study, we focus on the improvements of future prediction task over four update rounds and the evolution of user's personas with \method as the update method.
\subsection{Dynamic Persona Modeling}
We first compares five persona update methods: \method, FullRegen, SlideRegen, IncUpdate, and HierMerge, focusing on the evolution of the user’s persona across 4 update steps and evaluate their effectiveness based on the future prediction error (MAE) at each step, as shown in Table \ref{tab:future_prediction_error}. 
 The results of this case demonstrates that \method consistently reduces prediction error across refinement steps, achieving continual persona optimization, while all baseline methods not only fail to improve but also degrade persona quality over time.


    \begin{table}[!h]
      \small
      \centering
      \setlength{\tabcolsep}{0.8em}
      \caption{Future prediction error across 4 persona updates.}
      \begin{tabular}{lccccc}
        \toprule
        \textbf{Domain} & $\varepsilon_{1|\mathcal{S}_0}$ & $\varepsilon_{2|\mathcal{S}_1}$ & $\varepsilon_{3|\mathcal{S}_2}$& $\varepsilon_{4|\mathcal{S}_3}$& $\varepsilon_{5|\mathcal{S}_4}$ \\
        \midrule
        \method    & 1.1 & 1.0 & 0.5 & 0.3 & 0.2 \\
        FullRegen & 1.1 & 1.6 & 1.5 & 1.5 & 1.7 \\
        SlideRegen & 1.1 & 1.4 & 1.8 & 1.9 & 1.5 \\
        IncUpdate & 1.1 & 1.3 & 1.6 & 1.7 & 1.2 \\
        HierMerge & 1.1 & 1.7 & 1.8 & 1.9 & 1.3 \\ 
        \bottomrule
      \end{tabular}
      \label{tab:future_prediction_error}
    \end{table}


\newpage
\subsection{Persona Evolution}
In this section, we display the evolution of the user’s persona and corresponding observations in each window over four persona update rounds with \method (Table ~\ref{tab:persona_evolve_1}, Table ~\ref{tab:persona_evolve_2}, Table ~\ref{tab:persona_evolve_3}, Table ~\ref{tab:persona_evolve_4}, Table ~\ref{tab:persona_evolve_5}).
\begin{table*}[h!]
  \centering
  \small
  \resizebox{\linewidth}{!}{
  \begin{tabular}{ll}
  \toprule
  \multicolumn{2}{c}{\textbf{Examples of Persona Evolution of \method(\textit{A User from Book Domain})}} \\ \midrule
  \multicolumn{1}{l}{$\mathcal{S}_0$ and observartions in  $\mathcal{W}_1$} &
  \parbox{0.75\textwidth}{"The user appears to be an individual with a strong appreciation for both creative expression and practical knowledge. Their high ratings for works that blend storytelling with deeper themes suggest a reflective and imaginative personality. They likely enjoy narratives that not only entertain but also provoke thought and inspire personal growth. The consistent high ratings for books related to finance and funding indicate a keen interest in practical skills and knowledge, suggesting that they may be entrepreneurial or involved in creative industries where funding and financial acumen are crucial. This duality in their reading preferences points to a well-rounded individual who values both the arts and the practicalities of life. The user’s enjoyment of stories that involve mystery and justice indicates a fascination with problem-solving and perhaps a desire for moral clarity in complex situations. Their varied interests suggest they are open-minded and curious, likely seeking to expand their horizons through diverse genres. Overall, this user embodies a blend of creativity and pragmatism, with a penchant for narratives that inspire, educate, and entertain, reflecting a holistic approach to personal and professional development."} \\ \cmidrule{2-2} 
  \multicolumn{1}{l}{} &
  \parbox{0.75\textwidth}{item\_list = ["Insights of an Ordinary Man","Aura Advantage: How the Colors in Your Aura Can Help You Attain What You Desire and Attract Success","Georgia Bound", "Fifth Life of the Cat Woman", "Lady Justice and the Assassin", "Lord James Harrington and the Winter Mystery (Volume 1)", "Elemental Magic", "Enchantments of the Heart","The Grimm Diaries Prequels 1-6", "The Quest for the Crystal Skulls"]\\\\
  actual\_ratings =   [5, 5, 5, 5, 5, 5, 4, 3, 5, 5]\\
  predict\_ratings = [4, 3, 3, 4, 5, 4, 3, 3, 3, 4]} 
  \\\bottomrule
    \end{tabular}
    }
    \caption{Examples of $\mathcal{S}_0$ and observartions in $\mathcal{W}_1$}
    \label{tab:persona_evolve_1}
    \end{table*}

\begin{table*}[h!]
  \centering
  \small
  \resizebox{\linewidth}{!}{
  \begin{tabular}{ll}
  \toprule
  \multicolumn{2}{c}{\textbf{Examples of Persona Evolution of \method(\textit{A User from Book Domain})}} \\ \midrule
  \multicolumn{1}{l}{$\mathcal{S}_1$ and observartions in  $\mathcal{W}_2$} &
  \parbox{0.75\textwidth}{"The user appears to be a creative and open-minded individual with a strong appreciation for diverse forms of expression. Their high ratings for a wide range of books, including those that blend fiction with spiritual or self-help themes, suggest a deep interest in personal growth and self-discovery. This inclination towards inspirational and motivational content may indicate that the user is seeking guidance or validation in their own life journey. Their consistent 5-star ratings across various genres, including mystery and fantasy, demonstrate a willingness to explore new ideas and perspectives. The user's appreciation for practical knowledge and skills, as evident in their interest in finance and funding, highlights their pragmatic side and potential entrepreneurial or creative pursuits. Their enjoyment of stories that involve justice and problem-solving suggests a strong sense of morality and a desire for fairness. Overall, this user embodies a unique blend of creativity, curiosity, and practicality, with a penchant for narratives that inspire, educate, and entertain. They seem to value diversity and are not afraid to explore unconventional ideas, making them a highly open-minded and adaptable individual."} \\ \cmidrule{2-2} 
  \multicolumn{1}{l}{} &
  \parbox{0.75\textwidth}{item\_list= [ "A Hidden Fire: Elemental Mysteries Book 1", "It's Just a Little Crush: A Lizzie Hart Mystery (The Lizzie Hart Mysteries) (Volume 1)","The Devil Drinks Coffee", "The Depot: When Life and Death Cross Tracks","Lady Justice and the Lottery (Volume 14)", "Wuthering Heights (Penguin Classics)","The Ambitious Card (An Eli Marks Mystery) (Volume 1)","Miracles \& Mischief: Meringue for your Brain", "The Color of Greed: Raja Williams Series (Raja Williams Mystery Thriller Series)", "Thursday Morning Breakfast (and Murder) Club"]\\\\
actual\_ratings= [5, 5, 5, 5, 5, 5, 5, 5, 5, 5]\\
predict\_ratings = [4, 4, 3, 4, 5, 5, 4, 3, 4, 4]} \\\bottomrule
  \end{tabular}
  }
  \caption{Examples of $\mathcal{S}_1$ and observartions in $\mathcal{W}_2$.}
  \label{tab:persona_evolve_2}
  \end{table*}
  



  \newpage

  \begin{table*}[h!]
    \centering
    \small
    \resizebox{\linewidth}{!}{
    \begin{tabular}{ll}
    \toprule
    \multicolumn{2}{c}{\textbf{Examples of Persona Evolution of \method(\textit{A User from Book Domain})}} \\ \midrule
   
    \multicolumn{1}{l}{$\mathcal{S}_2$ and observartions in  $\mathcal{W}_3$} &
    \parbox{0.75\textwidth}{ "The user appears to be an extremely enthusiastic and optimistic individual who thoroughly enjoys a wide range of books across various genres. Their high ratings for a vast array of titles, including those that blend fiction with spiritual or self-help themes, suggest a deep interest in personal growth and self-discovery. This inclination towards inspirational and motivational content may indicate that the user is seeking guidance or validation in their own life journey. Their consistent 5-star ratings across various genres, including mystery and fantasy, demonstrate a willingness to explore new ideas and perspectives. The user's appreciation for practical knowledge and skills, as evident in their interest in finance and funding, highlights their pragmatic side and potential entrepreneurial or creative pursuits. Their enjoyment of stories that involve justice and problem-solving suggests a strong sense of morality and a desire for fairness. However, their tendency to rate books at the maximum score, regardless of predicted ratings, suggests a more impulsive and emotional approach to evaluating content. This user seems to value diversity and is not afraid to explore unconventional ideas, making them a highly open-minded and adaptable individual. Their love for storytelling and enthusiasm for new experiences may indicate a creative or artistic personality, always seeking inspiration and joy in their reading habits. Overall, this user embodies a unique blend of creativity, curiosity, and practicality, with a penchant for narratives that inspire, educate, and entertain."} \\ \cmidrule{2-2}
    \multicolumn{1}{l}{} &
    \parbox{0.75\textwidth}{item\_list = ["Lust, Money \& Murder - Book 1: A Female Secret Service Agent Takes on an International Criminal - Kindle edition", "Lust, Money \& Murder - Books 1, 2 \& 3: A Female Secret Service Agent Takes on an International Criminal","The Hitman's Lover (Jack Scully Thrillers) (Volume 1)", "Initiation, Human and Solar","Consciousness of the Atom", "Contagious: Why Things Catch On","The Poetical Works of Elizabeth Barrett Browning, Vol. I eBook","The Original Folk and Fairy Tales of Grimm Brothers: The Complete First Edition", "My Short, Happy Life In 'Jeopardy!'", "22/11/63"]\\

    actual\_ratings= [5, 5, 5, 4, 5, 5, 5, 3, 5, 3]\\
    predict\_ratings = [5, 5, 5, 5, 5, 5, 5, 5, 5, 5]} \\ \bottomrule

    \end{tabular}
    }
    \caption{Examples of $\mathcal{S}_2$ and observartions in $\mathcal{W}_3$}
    \label{tab:persona_evolve_3}
    \end{table*}



    \begin{table*}[h!]
      \centering
      \small
      \resizebox{\linewidth}{!}{
      \begin{tabular}{ll}
      \toprule
      \multicolumn{2}{c}{\textbf{Examples of Persona Evolution of \method(\textit{A User from Book Domain})}} \\ \midrule
      \multicolumn{1}{l}{$\mathcal{S}_3$ and observartions in $\mathcal{W}_4$} &
      \parbox{0.75\textwidth}{"The user appears to be a highly enthusiastic and optimistic individual who enjoys a wide range of books across various genres. Their love for storytelling and enthusiasm for new experiences suggests a creative or artistic personality, always seeking inspiration and joy in their reading habits. However, their tendency to rate books at the maximum score, regardless of predicted ratings, suggests a more impulsive and emotional approach to evaluating content.Their consistent 5-star ratings for a variety of titles, including those that blend fiction with spiritual or self-help themes, suggest a deep interest in personal growth and self-discovery. This inclination towards inspirational and motivational content may indicate that the user is seeking guidance or validation in their own life journey. Their appreciation for practical knowledge and skills, as evident in their interest in finance and funding, highlights their pragmatic side and potential entrepreneurial or creative pursuits.However, their 3-star rating for"The Original Folk and Fairy Tales of Grimm Brothers" and 3-star rating for"22/11/63" suggests that they may not always appreciate complex or darker themes, and may prefer more lighthearted or uplifting content. This preference for happier endings and more optimistic themes may be a key aspect of their reading preferences.Their enjoyment of stories that involve justice and problem-solving suggests a strong sense of morality and a desire for fairness. However, their tendency to rate books at the maximum score, regardless of predicted ratings, suggests that they may be more focused on the emotional resonance of a story rather than its literary merit or technical quality.Overall, this user embodies a unique blend of creativity, curiosity, and practicality, with a penchant for narratives that inspire, educate, and entertain. They appear to be a highly open-minded and adaptable individual, always seeking new experiences and inspiration in their reading habits."} \\ \cmidrule{2-2} 
      \multicolumn{1}{l}{} &
      \parbox{0.75\textwidth}{item\_list= [ "Into the Light (Easyread Large Bold Edition): Real Life Stories About Angelic Visits, Visions of the Afterlife, and Other Pre-Death Experiences", "Catnapped: A Klepto Cat Mystery (Volume 1)", "Dancing In The Moonlight (The Cowboys of Cold Creek)", "11/22/63 (Thorndike Press Large Print Core)","The Medium: An Emily Chambers Spirit Medium Novel (Volume 1)","Passion, Power \& Sin - Book 1: The Victim of a Global Internet Scam Plots Her Revenge - Kindle edition", "Passion, Power \& Sin - Books 1-5 (Book 1 Free)", "Season of the Witch","Murder in the South of France: A Maggie Newberry Mystery, Vol. 1 (Maggie Newberry Mysteries)","World hunger: Twelve myths"]\\
  
      actual\_ratings= [5, 4, 5, 3, 5, 5, 5, 5, 4, 5]\\
      predict\_ratings=[5, 5, 5, 3, 5, 5, 5, 5, 5, 4]} \\ \bottomrule
  
      \end{tabular}
      }
      \caption{Examples of $\mathcal{S}_3$ and observartions in $\mathcal{W}_4$}
      \label{tab:persona_evolve_4}
      \end{table*}
  


    \newpage

    \begin{table*}[h!]
      \centering
      \small
      \resizebox{\linewidth}{!}{
      \begin{tabular}{ll}
      \toprule
      \multicolumn{2}{c}{\textbf{Examples of Persona Evolution of \method(\textit{A User from Book Domain})}} \\ \midrule
     
      \multicolumn{1}{l}{$\mathcal{S}_4$ and observartions in $\mathcal{W}_5$} &
      \parbox{0.75\textwidth}{"Based on the differences between predicted and actual ratings, the user reveals a more nuanced and complex individual. They appear to be a highly enthusiastic and optimistic person, always seeking inspiration and joy in their reading habits. Their love for storytelling and enthusiasm for new experiences suggest a creative or artistic personality, but with a notable emphasis on emotional resonance and personal connection.Their consistent 5-star ratings for a wide range of titles, including those with inspirational and motivational themes, suggest a deep interest in personal growth and self-discovery. However, their ratings also indicate a willingness to engage with more lighthearted and entertaining content, such as romance and mystery novels. This preference for happier endings and more optimistic themes may be a key aspect of their reading preferences.Their enjoyment of stories that involve justice and problem-solving suggests a strong sense of morality and a desire for fairness. However, their tendency to rate books at the maximum score, regardless of predicted ratings, suggests that they may be more focused on the emotional impact of a story rather than its literary merit or technical quality.Interestingly, their ratings also suggest a willingness to engage with complex and thought-provoking topics, such as world hunger and global issues. This inclination towards inspirational and motivational content, combined with a desire for practical knowledge and skills, highlights their pragmatic side and potential entrepreneurial or creative pursuits.They may not always appreciate complex or darker themes, and may prefer more uplifting content. However, their willingness to engage with more serious topics, such as world hunger, suggests a depth and nuance to their personality that is not immediately apparent.Overall, this user embodies a unique blend of creativity, curiosity, and practicality, with a penchant for narratives that inspire, educate, and entertain. They appear to be a highly open-minded and adaptable individual, always seeking new experiences and inspiration in their reading habits. Their refined persona reveals a more complex and multifaceted individual, with a deep appreciation for emotional resonance, personal growth, and practical knowledge."} \\ \cmidrule{2-2}
      \multicolumn{1}{l}{} &
      \parbox{0.75\textwidth}{item\_list= [ "The Quickening of America: Rebuilding Our Nation, Remaking Our Lives", "The Da Vinci Code (Robert Langdon)","The Accidental Cop (Ben Colder Mystery)", "Lingering Echoes", "Rumors (Lingering Echoes)","Murder in Paris (The Maggie Newberry Mystery Series)", "Stilettos \& Scoundrels", "Bitty And The Naked Ladies (The Sherri Travis Mystery Series) eBook", "Sati and the Rider: A Satyana Mystery (Volume 1)","Fleur deKey: a French Quarter Mystery (The Foundation Mystery Series) (Volume 1)"]\\\\
      actual\_ratings= [5, 4, 5, 5, 5, 5, 4, 5, 5, 5]\\
      predict\_ratings=[5, 5, 4, 5, 5, 5, 4, 5, 5, 5]
      } \\ \bottomrule
     
      \end{tabular}
      }
      \caption{Examples of $\mathcal{S}_4$ and observartions in $\mathcal{W}_5$}
      \label{tab:persona_evolve_5}
      \end{table*}
  