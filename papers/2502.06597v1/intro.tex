\section{Introduction}

Estimating the first and second moments of data is a fundamental step in many machine learning algorithms, ranging from foundational methods, such as linear regression, principal component analysis, or Gaussian model fitting, to state-of-the-art neural network components, such as BatchNorm~\citep{pmlr-v37-ioffe15}, and optimizers, such as Adam~\citep{kingma2014adam}. 
%
Often, these estimates must be computed and updated continuously, called the \emph{continual release} setting~\citep{dwork2010differential}. 
%
For example, this is the case when the data arrives sequentially and 
intermediate results are needed without delay, such as for sequential optimization algorithms, such as Adam, or for real-time systems in healthcare, finance, or online recommendation systems. In such scenarios, ensuring the privacy of sensitive data, such as user information or medical records, is essential.
%

\emph{Differential Privacy (DP)} is a widely established formal notion of privacy that ensures that the inclusion or exclusion of any single individualâ€™s data has a limited impact on the output of an algorithm. 
%
Technically, DP masks sensitive information by the addition of suitably scaled noise, thereby creating a trade-off between privacy (formalized as a \emph{privacy budget}) and utility (measured by the expected accuracy of the estimates).
%
This trade-off becomes particularly challenging when more than one quantity is meant to be estimated from the same private data, as is the case when estimating multiple data moments. 
%
Done naively, the privacy budget has to be split between the estimates, resulting in more noise and lower accuracy for both of them. 
In this work, we introduce a new method, \emph{\method\ (\acronym)}, that is able to privately estimate the first and second moments of vector-valued data without suffering from this shortcoming.
%
Algorithmically, \acronym relies on the recent \emph{matrix factorization (MF)} mechanism~\citep{li2015matrix} for continual release DP
to individually compute the first and the second moments of the data, thereby making it flexible to accommodate a variety of settings. 
%
For example, besides the standard uniform sum or weighted average across data items, exponentially weighted averages or sliding-window estimates are readily possible.
%
The key innovation of \acronym lies in our theoretical analysis of its properties. By jointly analyzing the \emph{sensitivity} of the otherwise independent estimation processes, in combination with considering a carefully calibrated trade-off between them, we show that one can privately estimate the second-moment matrix \emph{without having to increase the amount of noise required to keep the first moment private.}
%
In this sense, we obtain privacy of the second moment \emph{for free}. 
%
\acronym is practical and easily implemented using standard programming languages and toolboxes. 
We demonstrate this by showcasing two applications, one classical and one modern.
%
First, we use \acronym for continual density estimation using a multivariate Gaussian model, \eg we estimate the running mean and covariance matrix of a sequence of vector-valued observations. 
%
Our experiments confirm that \acronym achieves a lower Frobenius norm error for the covariance matrix in high-privacy regimes as well as a better fit to the true distribution as measured by the Kullback-Leibler divergence.
%
Second, we integrate \acronym into the \emph{Adam} optimizer, which is widely used in deep learning. 
% 
Here, as well, we observe that JME achieves better optimization accuracy than baseline methods in high-privacy and small-batch-size regimes.


