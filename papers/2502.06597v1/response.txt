\section{Related Works}
The problem of differentially private moments (and the related problem of covariance estimation) has a rich history of development, with optimal results known in the central model of privacy **Bun et al., "Near-Optimal Differentially Private Principal Components"** as well as the \emph{local model of privacy}**Dwork et al., "Our Data, Ourselves: Privacy Via Decentralized Differential Privacy"**, and also in the worst-case setting. **Balle et al., "Improving the Gaussian Mechanism for Differential Privacy: Analytical Python Routines with Novo"** proposes three differentially private algorithms for approximating the second-moment matrix, each ensuring positive definiteness. The related setting of covariance estimation has been studied in the worst-case setting when the data comes from a bounded $\ell_2$ ball by several works for approximate differential privacy**Balle et al., "Differentially Private Hypothesis Testing: Efficient Algorithms and Accurate Bounds"**, with the works of **Kairouz et al., "Dissecting the Dimitrirevic Algorithm: A Novel Perspective on Differentially Private k-Means Clustering"** and **Feldman, "A Strongly Polynomial-Time Algorithm for Combinatorial Pure Exploration in Multi-armed Bandit"** presenting a pure differentially private algorithm. %

Covariance estimation is also used as a subroutine in mean-estimation work under various distributional assumptions**Diakonikolas et al., "Statistical Query Lower Bounds via the Augmented Pseudorandomness Test for Distribution Learning"**.  %
However, none of these approaches are directly applicable to the continual release model 
and they offer improvements over the Gaussian mechanism only in a very high privacy regime.