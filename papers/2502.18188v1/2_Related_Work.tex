
\section{Related work}
\paragraph{Domain Generalization on Graph.}
Recently, the research of graph domain generalization (DG) to improve the generalization ability of Graph Neural Networks under distribution shifts has come into the spotlight.
Mostly, the domain generalization methods can be divided into three categories\cite{li2022out}:
model-level methods~\cite{li2021disentangled,li2022ood}, model-training-level methods~\cite{liu2022confidence,wu2022discovering} and data-level methods~\cite{rongdropedge,you2020graph}. Among them, the data-level methods are attractive  due to their simplicity and ease of deployment. The most important data-level method is data augmentation.
However, the existing data augmentations for DG are mainly specifically designed for inductive graph classification which is a graph-level task~\cite{kong2020flag}, or single graph node classification in which the distribution shift happens in node feature~\cite{park2021metropolis}, without considering the inductive cross graph node classification that the distribution shift occurs in graph structures. Therefore, it remains open to using data augmentation to improve the model generalization ability in cross-graph node classification.

\input{images/fig_node_space}
\paragraph{Structure Modification.}
Existing methods involving edge modification tend to tailor for i.i.d. data. Those methods aim at dropping out the potentially
task-irrelevant edges from input graphs. For example, \citet{luo2021learning} proposed a topology denoising algorithm for filtering out the task-irrelevant edges. \citet{zhao2021data} raised a 
 learnable augmenter to generate and remove the edges in the graph augmentation, where the augmenter is  optimized by the downstream task, capturing the information that is highly related to 
the environment. \citet{zheng2020robust} present a graph sparsification approach to remove potentially task-irrelevant edges via deep neural networks. Despite those methods being successful in the semi-supervised node classification tasks,
it is inappropriate to make the modified graph structure only concentrate on the domain-related task in the cross-graph domain generalization. 
These highly domain-related techniques  would focus so much on information about the current domain that they ignore domain-invariant information which is critical for domain generalization.



\paragraph{Cross Graph Node Classification.}
Cross-graph node classification is a common task in practice. For example, in protein-protein interaction networks, one can leverage the abundant functional information from a source network to help predict the functionalities of proteins in a newly formed target network.
Many methods~\cite{dai2022graph,shen2020adversarial,yang2022robust} propose to address the cross-graph node classification problem by integrating graph neural networks and adversarial domain adaptation, in which the graph neural network is used as a feature extractor to learn discriminative node representation while adversarial learning is utilized to capture domain invariant node representations. AdaGCN\cite{dai2022graph} employs GCN\cite{kipf2017semi} to preserve node attribute and topological structure and uses WDGRL~\cite{shen2018wasserstein} as the adversarial learning strategy. ACDNE\cite{shen2020adversarial} design a deep network embedding module with two feature extractors following the DANN~\cite{ganin2016domain} adversarial learning strategy. RGDAL\cite{yang2022robust} inherits the framework and further filter noisy information via constrained graph mutual information. Nevertheless, they have not considered the cross-graph node classification task under the domain generalization context, in which the target graphs cannot be accessed during training.


s


