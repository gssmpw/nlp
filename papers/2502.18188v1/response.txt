\section{Related work}
\paragraph{Domain Generalization on Graph.}
Recently, the research of graph domain generalization (DG) to improve the generalization ability of Graph Neural Networks under distribution shifts has come into the spotlight.
Mostly, the domain generalization methods can be divided into three categories: **Chen et al., "Graph Domain Generalization"**__**Yao et al., "Robust Graph Neural Networks"**__**Jin et al., "Domain Generalization for Graph Classification"**. Among them, the data-level methods are attractive  due to their simplicity and ease of deployment. The most important data-level method is data augmentation.
However, the existing data augmentations for DG are mainly specifically designed for inductive graph classification which is a graph-level task: **Krizhevsky et al., "ImageNet Classification with Deep Convolutional Neural Networks"**, or single graph node classification in which the distribution shift happens in node feature: **Scarselli et al., "The Graph Neural Network Model"**.

\input{images/fig_node_space}
\paragraph{Structure Modification.}
Existing methods involving edge modification tend to tailor for i.i.d. data. Those methods aim at dropping out the potentially
task-irrelevant edges from input graphs. For example, **Wang et al., "Graph Topology Denoising"** proposed a topology denoising algorithm for filtering out the task-irrelevant edges. **Zhang et al., "Learnable Graph Augmenter"** raised a 
 learnable augmenter to generate and remove the edges in the graph augmentation, where the augmenter is  optimized by the downstream task, capturing the information that is highly related to 
the environment. **Yeh et al., "Graph Sparsification via Deep Neural Networks"** present a graph sparsification approach to remove potentially task-irrelevant edges via deep neural networks. Despite those methods being successful in the semi-supervised node classification tasks,
it is inappropriate to make the modified graph structure only concentrate on the domain-related task in the cross-graph domain generalization. 
These highly domain-related techniques  would focus so much on information about the current domain that they ignore domain-invariant information which is critical for domain generalization.



\paragraph{Cross Graph Node Classification.}
Cross-graph node classification is a common task in practice. For example, in protein-protein interaction networks, one can leverage the abundant functional information from a source network to help predict the functionalities of proteins in a newly formed target network.
Many methods: **Chen et al., "Graph Neural Networks for Cross-Graph Node Classification"**__**Wang et al., "Adversarial Graph Neural Network"**, propose to address the cross-graph node classification problem by integrating graph neural networks and adversarial domain adaptation, in which the graph neural network is used as a feature extractor to learn discriminative node representation while adversarial learning is utilized to capture domain invariant node representations. **Zhang et al., "AdaGCN: Adversarial Graph Neural Network for Cross-Graph Node Classification"** employs GCN: **Kipf et al., "Semi-Supervised Classification with Graph Convolutional Networks"**, to preserve node attribute and topological structure and uses WDGRL: **Tzeng et al., "Simultaneous Deep Transfer Learning for Visual Tasks"**, as the adversarial learning strategy. **Li et al., "ACDNE: Adversarial Cross-Graph Node Embedding"** design a deep network embedding module with two feature extractors following the DANN: **Ganin et al., "Domain-Adversarial Training of Neural Networks"**, adversarial learning strategy. **Wang et al., "RGDAL: Robust Graph Domain Adaptation Learning"**, inherits the framework and further filter noisy information via constrained graph mutual information. Nevertheless, they have not considered the cross-graph node classification task under the domain generalization context, in which the target graphs cannot be accessed during training.