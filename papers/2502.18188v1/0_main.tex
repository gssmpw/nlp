\documentclass{ecai}
\usepackage{caption}
% \documentclass[doubleblind]{ecai}  % use option [doubleblind] for double blind submission and hiding the authors section
\usepackage{graphicx}
\usepackage{latexsym}

%%%%%%guanzi add%%%%%%%%%
% \usepackage[numbers]{natbib}
 \usepackage{amsmath}
 \usepackage{amsfonts}
 % \usepackage{unicode-math}
\usepackage{amsthm}
\usepackage{xcolor}

\usepackage{threeparttable}
\usepackage{multirow}
\usepackage{multicol}

\usepackage{makecell}
\usepackage{tabularborder}

\newtheorem*{remark}{Remark}

 %%%%%%guanzi add%%%%%%%%%
\usepackage[colorlinks=true, urlcolor=blue, linkcolor=red]{hyperref}
%%%%%%guanzi add%%%%%%%%%
\newcommand{\gz}[1]{\textcolor{red}{(guanzi: #1)}}
\newcommand{\jy}[1]{\textcolor{blue}{(JYadd:#1)}}
%magenta
\newcommand{\Eqref}[1]{Eq.~\eqref{#1}}
\newcommand{\todo}[1]{\textcolor{magenta}{(TODO:#1)}} %
 % \newcommand{\todo}[1]{} %magenta

\newcommand{\mbf}[1]{\mathbf{#1}}
\newcommand{\mbb}[1]{\mathbb{#1}}
\newcommand{\mcal}[1]{\mathcal{#1}}

\newcommand{\citet}[1]{\cite{#1}}
\newcommand{\citep}[1]{\cite{#1}}
% \newcommand{\ConfirmationBias}{confidence bias\xspace}
\def\Done{}%{$\checkmark$}

\def\W{\mathbf{W}}
\def\L{\mathbf{L}}
% \usepackage{amssymb} % mathbb 依赖包
\usepackage{amsthm}
\def\R{\mathbb{R}}
\def\I{\mathbf{I}}
\def\U{\mathbf{U}}
\def\u{\mathbf{u}}
\def\Q{\mathbf{Q}}
\def\w{\mathbf{w}}
\def\h{\mathbf{h}}
\def\x{\mathbf{x}}
\def\v{\mathbf{v}}
\def\e{\mathbf{e}}
\def\d{\mathbf{d}}
\def\X{\mathbf{X}}
\def\Z{\mathbf{Z}}
\def\z{\mathbf{z}}
\def\xx{\times}
\def\R{\mathbb{R}}
\def\V{\mathcal{V}}
\def\calE{\mathcal{E}}
\def\G{\mathcal{G}}
\def\Th{\mathbf{\Theta}}

\def\E{\mathbb{E}}

\def\H{\mbf{H}}
\def\D{\mbf{D}}
\def\W{\mbf{W}}
\def\T{\mbf{T}}
\def\P{\mbf{P}}
\def\L{\mbf{L}}
\def\K{\mbf{K}}
\def\F{\mathcal{F}}
\def\Y{\mathbf{Y}}


\def\A{\mbf{A}}
\def\B{\mbf{B}}
\def\S{\mbf{S}}
%%%%%%guanzi add%%%%%%%%%











%\ecaisubmission      % inserts page numbers. Use only for submission of paper.
                      % Do NOT use for camera-ready version of paper.

\paperid{426}        % paper id for double blind submission


\begin{document}

\begin{frontmatter}

% \title{Graph Augmentation for Domain Generalization with Out-of-Distribution Structure}
\title{Graph Augmentation for Cross Graph Domain Generalization}

\author[A]{\fnms{Guanzi}~\snm{Chen}$^\dagger$\thanks{\textit{Email:guanzichen99@gmail.com; yangli@sz.tsinghua.edu.cn} }}
\author[A]{\fnms{Jiying Zhang}$^\dagger$}
\author[A]{\fnms{Yang Li} }
% 
% {\fnms{First}~\snm{Author}\orcid{....-....-....-....}\thanks{Corresponding Author. Email: somename@university.edu.}}

% \author[B]{\fnms{Second}~\snm{Author}\orcid{....-....-....-....}}
% \author[B]{\fnms{Third}~\snm{Author}\orcid{....-....-....-....}} % use of \orcid{} is optional

\address[A]{Tsinghua University}
% \address[B]{Short Affiliation of Second Author and Third Author}

\begin{abstract}
Cross-graph node classification, utilizing the abundant labeled nodes from one graph to help classify unlabeled nodes in another graph, can be viewed as a domain generalization problem of graph neural networks (GNNs) due to the structure shift commonly appearing among various graphs.
Nevertheless, current endeavors for cross-graph node classification mainly focus on model training. Data augmentation approaches, a simple and easy-to-implement domain generalization technique,  remain under-explored.
In this paper, we develop a new graph structure augmentation for the cross-graph domain generalization problem.
Specifically, low-weight edge-dropping is applied to remove potential noise edges that may hinder the generalization ability of GNNs, stimulating the GNNs to capture the essential invariant information underlying different structures. Meanwhile, clustering-based edge-adding is proposed to generate invariant structures based on the node features from the same distribution. Consequently, with these augmentation techniques, the GNNs can maintain the domain invariant structure information that can improve the generalization ability. The experiments on out-of-distribution citation network datasets verify our method achieves state-of-the-art performance among conventional augmentations.
\end{abstract}

\end{frontmatter} 


\input{1_Introduction}


\input{2_Related_Work}

\section{Methodology}
\input{3_0_Preliminary}
\input{3_Method}


\input{4_Experiment}


\section{Conclusion and Future Work}
This paper introduces a simple and effective graph augmentation strategy for cross-graph node classification with OOD structure. 
There are still several directions that are worth exploring in the future: 1) the edge-dropping weight can be considered the more comprehensive method that can measure the significance of each edge. 2) The proposed augmentation can be extended to test time training.

% \newpage
\bibliography{0_main}
\input{5_Appendix}
\end{document}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
