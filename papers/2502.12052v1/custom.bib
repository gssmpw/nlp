% Use this file for citations not found in the ACL Anthology (contained in "anthology.bib").

@book{Aho:72,
    author  = {Alfred V. Aho and Jeffrey D. Ullman},
    title   = {The Theory of Parsing, Translation and Compiling},
    year    = "1972",
    volume  = "1",
    publisher = {Prentice-Hall},
    address = {Englewood Cliffs, NJ}
}

@book{APA:83,
    author  = {{American Psychological Association}},
    title   = {Publications Manual},
    year    = "1983",
    publisher = {American Psychological Association},
    address = {Washington, DC}
}

@article{Chandra:81,
	author = {Ashok K. Chandra and Dexter C. Kozen and Larry J. Stockmeyer},
	year = "1981",
	title = {Alternation},
	journal = {Journal of the Association for Computing Machinery},
	volume = "28",
	number = "1",
	pages = "114--133",
	doi = "10.1145/322234.322243",
}

@inproceedings{andrew2007scalable,
  title={Scalable training of {L1}-regularized log-linear models},
  author={Andrew, Galen and Gao, Jianfeng},
  booktitle={Proceedings of the 24th International Conference on Machine Learning},
  pages={33--40},
  year={2007},
}

@book{Gusfield:97,
    author  = {Dan Gusfield},
    title   = {Algorithms on Strings, Trees and Sequences},
    year    = "1997",
    publisher = {Cambridge University Press},
    address = {Cambridge, UK}
}

@article{rasooli-tetrault-2015,
    author    = {Mohammad Sadegh Rasooli and Joel R. Tetreault},
    title     = {Yara Parser: {A} Fast and Accurate Dependency Parser},
    journal   = {Computing Research Repository},
    volume    = {arXiv:1503.06733},
    year      = {2015},
    url       = {http://arxiv.org/abs/1503.06733},
    note    = {version 2}
}

@article{Ando2005,
	Acmid = {1194905},
	Author = {Ando, Rie Kubota and Zhang, Tong},
	Issn = {1532-4435},
	Issue_Date = {12/1/2005},
	Journal = {Journal of Machine Learning Research},
	Month = dec,
	Numpages = {37},
	Pages = {1817--1853},
	Publisher = {JMLR.org},
	Title = {A Framework for Learning Predictive Structures from Multiple Tasks and Unlabeled Data},
	Volume = {6},
	Year = {2005}
}


@inproceedings{papineni2002bleu,
  title={Bleu: a method for automatic evaluation of machine translation},
  author={Papineni, Kishore and Roukos, Salim and Ward, Todd and Zhu, Wei-Jing},
  booktitle={Proceedings of the 40th annual meeting of the Association for Computational Linguistics},
  pages={311--318},
  year={2002}
}

@inproceedings{zhangbertscore,
  title={BERTScore: Evaluating Text Generation with BERT},
  author={Zhang, Tianyi and Kishore, Varsha and Wu, Felix and Weinberger, Kilian Q and Artzi, Yoav},
  booktitle={International Conference on Learning Representations}
}

@article{gao2024analyzing,
  title={Analyzing and Evaluating Correlation Measures in NLG Meta-Evaluation},
  author={Gao, Mingqi and Hu, Xinyu and Lin, Li and Wan, Xiaojun},
  journal={arXiv preprint arXiv:2410.16834},
  year={2024}
}

@inproceedings{perrella2024guardians,
  title={Guardians of the Machine Translation Meta-Evaluation: Sentinel Metrics Fall In!},
  author={Perrella, Stefano and Proietti, Lorenzo and Scir{\`e}, Alessandro and Barba, Edoardo and Navigli, Roberto},
  booktitle={Proceedings of the 62nd Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers)},
  pages={16216--16244},
  year={2024}
}

@article{fabbri2021summeval,
  title={Summeval: Re-evaluating summarization evaluation},
  author={Fabbri, Alexander R and Kry{\'s}ci{\'n}ski, Wojciech and McCann, Bryan and Xiong, Caiming and Socher, Richard and Radev, Dragomir},
  journal={Transactions of the Association for Computational Linguistics},
  volume={9},
  pages={391--409},
  year={2021},
  publisher={MIT Press One Rogers Street, Cambridge, MA 02142-1209, USA journals-info~…}
}

@article{cohen1968weighted,
  title={Weighted kappa: Nominal scale agreement provision for scaled disagreement or partial credit.},
  author={Cohen, Jacob},
  journal={Psychological bulletin},
  volume={70},
  number={4},
  pages={213},
  year={1968},
  publisher={American Psychological Association}
}

@inproceedings{sakai2021evaluating,
  title={Evaluating evaluation measures for ordinal classification and ordinal quantification},
  author={Sakai, Tetsuya},
  booktitle={Proceedings of the 59th Annual Meeting of the Association for Computational Linguistics and the 11th International Joint Conference on Natural Language Processing (Volume 1: Long Papers)},
  pages={2759--2769},
  year={2021}
}


@article{wang2024dhp,
  title={DHP Benchmark: Are LLMs Good NLG Evaluators?},
  author={Wang, Yicheng and Yuan, Jiayi and Chuang, Yu-Neng and Wang, Zhuoer and Liu, Yingchi and Cusick, Mark and Kulkarni, Param and Ji, Zhengping and Ibrahim, Yasser and Hu, Xia},
  journal={arXiv preprint arXiv:2408.13704},
  year={2024}
}

@inproceedings{hu-etal-2024-llm,
    title = "Are {LLM}-based Evaluators Confusing {NLG} Quality Criteria?",
    author = "Hu, Xinyu  and
      Gao, Mingqi  and
      Hu, Sen  and
      Zhang, Yang  and
      Chen, Yicheng  and
      Xu, Teng  and
      Wan, Xiaojun",
    editor = "Ku, Lun-Wei  and
      Martins, Andre  and
      Srikumar, Vivek",
    booktitle = "Proceedings of the 62nd Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers)",
    month = aug,
    year = "2024",
    address = "Bangkok, Thailand",
    publisher = "Association for Computational Linguistics",
    url = "https://aclanthology.org/2024.acl-long.516/",
    doi = "10.18653/v1/2024.acl-long.516",
    pages = "9530--9570",
    abstract = "Some prior work has shown that LLMs perform well in NLG evaluation for different tasks. However, we discover that LLMs seem to confuse different evaluation criteria, which reduces their reliability. For further verification, we first consider avoiding issues of inconsistent conceptualization and vague expression in existing NLG quality criteria themselves. So we summarize a clear hierarchical classification system for 11 common aspects with corresponding different criteria from previous studies involved. Inspired by behavioral testing, we elaborately design 18 types of aspect-targeted perturbation attacks for fine-grained analysis of the evaluation behaviors of different LLMs. We also conduct human annotations beyond the guidance of the classification system to validate the impact of the perturbations. Our experimental results reveal confusion issues inherent in LLMs, as well as other noteworthy phenomena, and necessitate further research and improvements for LLM-based evaluation."
}

@inproceedings{li2025dna,
  title={DnA-Eval: Enhancing Large Language Model Evaluation through Decomposition and Aggregation},
  author={Li, Minzhi and Liu, Zhengyuan and Deng, Shumin and Joty, Shafiq and Chen, Nancy and Kan, Min-Yen},
  booktitle={Proceedings of the 31st International Conference on Computational Linguistics},
  pages={2277--2290},
  year={2025}
}

@article{liu2024hd,
  title={HD-Eval: Aligning Large Language Model Evaluators Through Hierarchical Criteria Decomposition},
  author={Liu, Yuxuan and Yang, Tianchi and Huang, Shaohan and Zhang, Zihan and Huang, Haizhen and Wei, Furu and Deng, Weiwei and Sun, Feng and Zhang, Qi},
  journal={arXiv preprint arXiv:2402.15754},
  year={2024}
}

@inproceedings{mehri2020usr,
  title={USR: An Unsupervised and Reference Free Evaluation Metric for Dialog Generation},
  author={Mehri, Shikib and Eskenazi, Maxine},
  booktitle={Proceedings of the 58th Annual Meeting of the Association for Computational Linguistics},
  pages={681--707},
  year={2020}
}

@article{achiam2023gpt,
  title={Gpt-4 technical report},
  author={Achiam, Josh and Adler, Steven and Agarwal, Sandhini and Ahmad, Lama and Akkaya, Ilge and Aleman, Florencia Leoni and Almeida, Diogo and Altenschmidt, Janko and Altman, Sam and Anadkat, Shyamal and others},
  journal={arXiv preprint arXiv:2303.08774},
  year={2023}
}

@article{dubey2024llama,
  title={The llama 3 herd of models},
  author={Dubey, Abhimanyu and Jauhri, Abhinav and Pandey, Abhinav and Kadian, Abhishek and Al-Dahle, Ahmad and Letman, Aiesha and Mathur, Akhil and Schelten, Alan and Yang, Amy and Fan, Angela and others},
  journal={arXiv preprint arXiv:2407.21783},
  year={2024}
}

@article{qwen2.5,
    title   = {Qwen2.5 Technical Report}, 
    author  = {An Yang and Baosong Yang and Beichen Zhang and Binyuan Hui and Bo Zheng and Bowen Yu and Chengyuan Li and Dayiheng Liu and Fei Huang and Haoran Wei and Huan Lin and Jian Yang and Jianhong Tu and Jianwei Zhang and Jianxin Yang and Jiaxi Yang and Jingren Zhou and Junyang Lin and Kai Dang and Keming Lu and Keqin Bao and Kexin Yang and Le Yu and Mei Li and Mingfeng Xue and Pei Zhang and Qin Zhu and Rui Men and Runji Lin and Tianhao Li and Tingyu Xia and Xingzhang Ren and Xuancheng Ren and Yang Fan and Yang Su and Yichang Zhang and Yu Wan and Yuqiong Liu and Zeyu Cui and Zhenru Zhang and Zihan Qiu},
    journal = {arXiv preprint arXiv:2412.15115},
    year    = {2024}
}


@article{team2024gemma,
  title={Gemma 2: Improving open language models at a practical size},
  author={Team, Gemma and Riviere, Morgane and Pathak, Shreya and Sessa, Pier Giuseppe and Hardin, Cassidy and Bhupatiraju, Surya and Hussenot, L{\'e}onard and Mesnard, Thomas and Shahriari, Bobak and Ram{\'e}, Alexandre and others},
  journal={arXiv preprint arXiv:2408.00118},
  year={2024}
}

@article{abdin2024phi,
  title={Phi-4 technical report},
  author={Abdin, Marah and Aneja, Jyoti and Behl, Harkirat and Bubeck, S{\'e}bastien and Eldan, Ronen and Gunasekar, Suriya and Harrison, Michael and Hewett, Russell J and Javaheripi, Mojan and Kauffmann, Piero and others},
  journal={arXiv preprint arXiv:2412.08905},
  year={2024}
}

@article{jiang2023tigerscore,
  title={Tigerscore: Towards building explainable metric for all text generation tasks},
  author={Jiang, Dongfu and Li, Yishan and Zhang, Ge and Huang, Wenhao and Lin, Bill Yuchen and Chen, Wenhu},
  journal={Transactions on Machine Learning Research}
}

@inproceedings{kim2023prometheus,
  title={Prometheus: Inducing fine-grained evaluation capability in language models},
  author={Kim, Seungone and Shin, Jamin and Cho, Yejin and Jang, Joel and Longpre, Shayne and Lee, Hwaran and Yun, Sangdoo and Shin, Seongjin and Kim, Sungdong and Thorne, James and others},
  booktitle={The Twelfth International Conference on Learning Representations},
  year={2023}
}
@article{kim2024prometheus,
  title={Prometheus 2: An open source language model specialized in evaluating other language models},
  author={Kim, Seungone and Suk, Juyoung and Longpre, Shayne and Lin, Bill Yuchen and Shin, Jamin and Welleck, Sean and Neubig, Graham and Lee, Moontae and Lee, Kyungjae and Seo, Minjoon},
  journal={arXiv preprint arXiv:2405.01535},
  year={2024}
}
@inproceedings{ligenerative,
  title={Generative Judge for Evaluating Alignment},
  author={Li, Junlong and Sun, Shichao and Yuan, Weizhe and Fan, Run-Ze and Liu, Pengfei and others},
  booktitle={The Twelfth International Conference on Learning Representations}
}
@inproceedings{ke2024critiquellm,
  title={Critiquellm: Towards an informative critique generation model for evaluation of large language model generation},
  author={Ke, Pei and Wen, Bosi and Feng, Andrew and Liu, Xiao and Lei, Xuanyu and Cheng, Jiale and Wang, Shengyuan and Zeng, Aohan and Dong, Yuxiao and Wang, Hongning and others},
  booktitle={Proceedings of the 62nd Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers)},
  pages={13034--13054},
  year={2024}
}
@article{cao2024compassjudger,
  title={CompassJudger-1: All-in-one Judge Model Helps Model Evaluation and Evolution},
  author={Cao, Maosong and Lam, Alexander and Duan, Haodong and Liu, Hongwei and Zhang, Songyang and Chen, Kai},
  journal={arXiv preprint arXiv:2410.16256},
  year={2024}
}
@inproceedings{hu2024themis,
  title={Themis: A Reference-free NLG Evaluation Language Model with Flexibility and Interpretability},
  author={Hu, Xinyu and Lin, Li and Gao, Mingqi and Yin, Xunjian and Wan, Xiaojun},
  booktitle={Proceedings of the 2024 Conference on Empirical Methods in Natural Language Processing},
  pages={15924--15951},
  year={2024}
}

@inproceedings{liu2023g,
  title={G-Eval: NLG Evaluation using Gpt-4 with Better Human Alignment},
  author={Liu, Yang and Iter, Dan and Xu, Yichong and Wang, Shuohang and Xu, Ruochen and Zhu, Chenguang},
  booktitle={Proceedings of the 2023 Conference on Empirical Methods in Natural Language Processing},
  pages={2511--2522},
  year={2023}
}

@inproceedings{chiang-lee-2023-closer,
    title = "A Closer Look into Using Large Language Models for Automatic Evaluation",
    author = "Chiang, Cheng-Han  and
      Lee, Hung-yi",
    editor = "Bouamor, Houda  and
      Pino, Juan  and
      Bali, Kalika",
    booktitle = "Findings of the Association for Computational Linguistics: EMNLP 2023",
    month = dec,
    year = "2023",
    address = "Singapore",
    publisher = "Association for Computational Linguistics",
    url = "https://aclanthology.org/2023.findings-emnlp.599/",
    doi = "10.18653/v1/2023.findings-emnlp.599",
    pages = "8928--8942",
    abstract = "Using large language models (LLMs) to evaluate text quality has recently gained popularity. Some existing prior works explore the idea of using LLMs for evaluation, while they differ in some details of the evaluation process. In this paper, we analyze *LLM evaluation* and *G-Eval*, and we discuss how those details in the evaluation process change how well the ratings given by LLMs correlate with human ratings. We find that the auto Chain-of-Thought (CoT) used in G-Eval does not always make G-Eval more aligned with human ratings. We also show that forcing the LLM to output only a numeric rating, as in G-Eval, is suboptimal. Last, we reveal that asking the LLM to explain its own ratings consistently improves the correlation between the ChatGPT and human ratings and pushes state-of-the-art (SoTA) correlations on two meta-evaluation datasets."
}


@misc{openai2024o1preview,
  author       = {OpenAI},
  title        = {Introducing OpenAI o1-preview},
  howpublished = {\url{https://openai.com/index/introducing-openai-o1-preview/}},
  year         = {2024},
}

@article{wei2022chain,
  title={Chain-of-thought prompting elicits reasoning in large language models},
  author={Wei, Jason and Wang, Xuezhi and Schuurmans, Dale and Bosma, Maarten and Xia, Fei and Chi, Ed and Le, Quoc V and Zhou, Denny and others},
  journal={Advances in neural information processing systems},
  volume={35},
  pages={24824--24837},
  year={2022}
}

@article{liu2024aligning,
  title={Aligning with human judgement: The role of pairwise preference in large language model evaluators},
  author={Liu, Yinhong and Zhou, Han and Guo, Zhijiang and Shareghi, Ehsan and Vuli{\'c}, Ivan and Korhonen, Anna and Collier, Nigel},
  journal={arXiv preprint arXiv:2403.16950},
  year={2024}
}


@inproceedings{lin2004rouge,
  title={Rouge: A package for automatic evaluation of summaries},
  author={Lin, Chin-Yew},
  booktitle={Text summarization branches out},
  pages={74--81},
  year={2004}
}

@article{yuan2021bartscore,
  title={Bartscore: Evaluating generated text as text generation},
  author={Yuan, Weizhe and Neubig, Graham and Liu, Pengfei},
  journal={Advances in Neural Information Processing Systems},
  volume={34},
  pages={27263--27277},
  year={2021}
}

@misc{chiang2024chatbot,
    title={Chatbot Arena: An Open Platform for Evaluating LLMs by Human Preference},
    author={Wei-Lin Chiang and Lianmin Zheng and Ying Sheng and Anastasios Nikolas Angelopoulos and Tianle Li and Dacheng Li and Hao Zhang and Banghua Zhu and Michael Jordan and Joseph E. Gonzalez and Ion Stoica},
    year={2024},
    eprint={2403.04132},
    archivePrefix={arXiv},
    primaryClass={cs.AI}
}

@inproceedings{kocmi2023large,
  title={Large Language Models Are State-of-the-Art Evaluators of Translation Quality},
  author={Kocmi, Tom and Federmann, Christian},
  booktitle={Proceedings of the 24th Annual Conference of the European Association for Machine Translation},
  pages={193--203},
  year={2023}
}

@inproceedings{chiang2023can,
  title={Can Large Language Models Be an Alternative to Human Evaluations?},
  author={Chiang, Cheng-Han and Lee, Hung-Yi},
  booktitle={Proceedings of the 61st Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers)},
  pages={15607--15631},
  year={2023}
}

@inproceedings{wang2023chatgpt,
  title={Is ChatGPT a Good NLG Evaluator? A Preliminary Study},
  author={Wang, Jiaan and Liang, Yunlong and Meng, Fandong and Sun, Zengkui and Shi, Haoxiang and Li, Zhixu and Xu, Jinan and Qu, Jianfeng and Zhou, Jie},
  booktitle={Proceedings of the 4th New Frontiers in Summarization Workshop},
  pages={1--11},
  year={2023}
}

@article{liu2024deepseek,
  title={Deepseek-v3 technical report},
  author={Liu, Aixin and Feng, Bei and Xue, Bing and Wang, Bingxuan and Wu, Bochao and Lu, Chengda and Zhao, Chenggang and Deng, Chengqi and Zhang, Chenyu and Ruan, Chong and others},
  journal={arXiv preprint arXiv:2412.19437},
  year={2024}
}

@misc{alpaca_eval,
  author = {Xuechen Li and Tianyi Zhang and Yann Dubois and Rohan Taori and Ishaan Gulrajani and Carlos Guestrin and Percy Liang and Tatsunori B. Hashimoto },
  title = {AlpacaEval: An Automatic Evaluator of Instruction-following Models},
  year = {2023},
  month = {5},
  publisher = {GitHub},
  journal = {GitHub repository},
  howpublished = {\url{https://github.com/tatsu-lab/alpaca_eval}}
}

@article{sullivan2013analyzing,
  title={Analyzing and interpreting data from Likert-type scales},
  author={Sullivan, Gail M and Artino Jr, Anthony R},
  journal={Journal of graduate medical education},
  volume={5},
  number={4},
  pages={541--542},
  year={2013},
  publisher={The Accreditation Council for Graduate Medical Education Suite 2000, 515~…}
}

@article{joshi2015likert,
  title={Likert scale: Explored and explained},
  author={Joshi, Ankur and Kale, Saket and Chandel, Satish and Pal, D Kumar},
  journal={British journal of applied science \& technology},
  volume={7},
  number={4},
  pages={396--403},
  year={2015}
}


@article{DBLP:journals/corr/abs-2406-18403,
  author       = {Anna Bavaresco and
                  Raffaella Bernardi and
                  Leonardo Bertolazzi and
                  Desmond Elliott and
                  Raquel Fern{\'{a}}ndez and
                  Albert Gatt and
                  Esam Ghaleb and
                  Mario Giulianelli and
                  Michael Hanna and
                  Alexander Koller and
                  Andr{\'{e}} F. T. Martins and
                  Philipp Mondorf and
                  Vera Neplenbroek and
                  Sandro Pezzelle and
                  Barbara Plank and
                  David Schlangen and
                  Alessandro Suglia and
                  Aditya K. Surikuchi and
                  Ece Takmaz and
                  Alberto Testoni},
  title        = {LLMs instead of Human Judges? {A} Large Scale Empirical Study across
                  20 {NLP} Evaluation Tasks},
  journal      = {CoRR},
  volume       = {abs/2406.18403},
  year         = {2024},
  url          = {https://doi.org/10.48550/arXiv.2406.18403},
  doi          = {10.48550/ARXIV.2406.18403},
  eprinttype    = {arXiv},
  eprint       = {2406.18403},
  timestamp    = {Mon, 22 Jul 2024 14:28:32 +0200},
  biburl       = {https://dblp.org/rec/journals/corr/abs-2406-18403.bib},
  bibsource    = {dblp computer science bibliography, https://dblp.org}
}




@article{DBLP:journals/corr/abs-2408-13704,
  author       = {Yicheng Wang and
                  Jiayi Yuan and
                  Yu{-}Neng Chuang and
                  Zhuoer Wang and
                  Yingchi Liu and
                  Mark Cusick and
                  Param Kulkarni and
                  Zhengping Ji and
                  Yasser Ibrahim and
                  Xia Hu},
  title        = {{DHP} Benchmark: Are LLMs Good {NLG} Evaluators?},
  journal      = {CoRR},
  volume       = {abs/2408.13704},
  year         = {2024},
  url          = {https://doi.org/10.48550/arXiv.2408.13704},
  doi          = {10.48550/ARXIV.2408.13704},
  eprinttype    = {arXiv},
  eprint       = {2408.13704},
  timestamp    = {Sat, 28 Sep 2024 18:01:46 +0200},
  biburl       = {https://dblp.org/rec/journals/corr/abs-2408-13704.bib},
  bibsource    = {dblp computer science bibliography, https://dblp.org}
}

@article{DBLP:journals/corr/abs-2406-12624,
  author       = {Aman Singh Thakur and
                  Kartik Choudhary and
                  Venkat Srinik Ramayapally and
                  Sankaran Vaidyanathan and
                  Dieuwke Hupkes},
  title        = {Judging the Judges: Evaluating Alignment and Vulnerabilities in LLMs-as-Judges},
  journal      = {CoRR},
  volume       = {abs/2406.12624},
  year         = {2024},
  url          = {https://doi.org/10.48550/arXiv.2406.12624},
  doi          = {10.48550/ARXIV.2406.12624},
  eprinttype    = {arXiv},
  eprint       = {2406.12624},
  timestamp    = {Sun, 06 Oct 2024 21:25:18 +0200},
  biburl       = {https://dblp.org/rec/journals/corr/abs-2406-12624.bib},
  bibsource    = {dblp computer science bibliography, https://dblp.org}
}

@article{DBLP:journals/corr/abs-2410-12784,
  author       = {Sijun Tan and
                  Siyuan Zhuang and
                  Kyle Montgomery and
                  William Y. Tang and
                  Alejandro Cuadron and
                  Chenguang Wang and
                  Raluca Ada Popa and
                  Ion Stoica},
  title        = {JudgeBench: {A} Benchmark for Evaluating LLM-based Judges},
  journal      = {CoRR},
  volume       = {abs/2410.12784},
  year         = {2024},
  url          = {https://doi.org/10.48550/arXiv.2410.12784},
  doi          = {10.48550/ARXIV.2410.12784},
  eprinttype    = {arXiv},
  eprint       = {2410.12784},
  timestamp    = {Tue, 26 Nov 2024 09:51:02 +0100},
  biburl       = {https://dblp.org/rec/journals/corr/abs-2410-12784.bib},
  bibsource    = {dblp computer science bibliography, https://dblp.org}
}

@article{DBLP:journals/corr/abs-2410-09893,
  author       = {Enyu Zhou and
                  Guodong Zheng and
                  Binghai Wang and
                  Zhiheng Xi and
                  Shihan Dou and
                  Rong Bao and
                  Wei Shen and
                  Limao Xiong and
                  Jessica Fan and
                  Yurong Mou and
                  Rui Zheng and
                  Tao Gui and
                  Qi Zhang and
                  Xuanjing Huang},
  title        = {{RMB:} Comprehensively Benchmarking Reward Models in {LLM} Alignment},
  journal      = {CoRR},
  volume       = {abs/2410.09893},
  year         = {2024},
  url          = {https://doi.org/10.48550/arXiv.2410.09893},
  doi          = {10.48550/ARXIV.2410.09893},
  eprinttype    = {arXiv},
  eprint       = {2410.09893},
  timestamp    = {Fri, 22 Nov 2024 21:38:27 +0100},
  biburl       = {https://dblp.org/rec/journals/corr/abs-2410-09893.bib},
  bibsource    = {dblp computer science bibliography, https://dblp.org}
}



@article{DBLP:journals/corr/abs-2403-13787,
  author       = {Nathan Lambert and
                  Valentina Pyatkin and
                  Jacob Morrison and
                  LJ Miranda and
                  Bill Yuchen Lin and
                  Khyathi Raghavi Chandu and
                  Nouha Dziri and
                  Sachin Kumar and
                  Tom Zick and
                  Yejin Choi and
                  Noah A. Smith and
                  Hannaneh Hajishirzi},
  title        = {RewardBench: Evaluating Reward Models for Language Modeling},
  journal      = {CoRR},
  volume       = {abs/2403.13787},
  year         = {2024},
  url          = {https://doi.org/10.48550/arXiv.2403.13787},
  doi          = {10.48550/ARXIV.2403.13787},
  eprinttype    = {arXiv},
  eprint       = {2403.13787},
  timestamp    = {Thu, 08 Aug 2024 15:05:27 +0200},
  biburl       = {https://dblp.org/rec/journals/corr/abs-2403-13787.bib},
  bibsource    = {dblp computer science bibliography, https://dblp.org}
}

@inproceedings{DBLP:conf/acl/WangLCCZLCKLLS24,
  author       = {Peiyi Wang and
                  Lei Li and
                  Liang Chen and
                  Zefan Cai and
                  Dawei Zhu and
                  Binghuai Lin and
                  Yunbo Cao and
                  Lingpeng Kong and
                  Qi Liu and
                  Tianyu Liu and
                  Zhifang Sui},
  editor       = {Lun{-}Wei Ku and
                  Andre Martins and
                  Vivek Srikumar},
  title        = {Large Language Models are not Fair Evaluators},
  booktitle    = {Proceedings of the 62nd Annual Meeting of the Association for Computational
                  Linguistics (Volume 1: Long Papers), {ACL} 2024, Bangkok, Thailand,
                  August 11-16, 2024},
  pages        = {9440--9450},
  publisher    = {Association for Computational Linguistics},
  year         = {2024},
  url          = {https://doi.org/10.18653/v1/2024.acl-long.511},
  doi          = {10.18653/V1/2024.ACL-LONG.511},
  timestamp    = {Sun, 19 Jan 2025 13:21:41 +0100},
  biburl       = {https://dblp.org/rec/conf/acl/WangLCCZLCKLLS24.bib},
  bibsource    = {dblp computer science bibliography, https://dblp.org}
}


@article{DBLP:journals/corr/abs-2410-02736,
  author       = {Jiayi Ye and
                  Yanbo Wang and
                  Yue Huang and
                  Dongping Chen and
                  Qihui Zhang and
                  Nuno Moniz and
                  Tian Gao and
                  Werner Geyer and
                  Chao Huang and
                  Pin{-}Yu Chen and
                  Nitesh V. Chawla and
                  Xiangliang Zhang},
  title        = {Justice or Prejudice? Quantifying Biases in LLM-as-a-Judge},
  journal      = {CoRR},
  volume       = {abs/2410.02736},
  year         = {2024},
  url          = {https://doi.org/10.48550/arXiv.2410.02736},
  doi          = {10.48550/ARXIV.2410.02736},
  eprinttype    = {arXiv},
  eprint       = {2410.02736},
  timestamp    = {Fri, 08 Nov 2024 08:36:35 +0100},
  biburl       = {https://dblp.org/rec/journals/corr/abs-2410-02736.bib},
  bibsource    = {dblp computer science bibliography, https://dblp.org}
}



@inproceedings{DBLP:conf/coling/LeeHT25,
  author       = {Noah Lee and
                  Jiwoo Hong and
                  James Thorne},
  editor       = {Owen Rambow and
                  Leo Wanner and
                  Marianna Apidianaki and
                  Hend Al{-}Khalifa and
                  Barbara Di Eugenio and
                  Steven Schockaert},
  title        = {Evaluating the Consistency of {LLM} Evaluators},
  booktitle    = {Proceedings of the 31st International Conference on Computational
                  Linguistics, {COLING} 2025, Abu Dhabi, UAE, January 19-24, 2025},
  pages        = {10650--10659},
  publisher    = {Association for Computational Linguistics},
  year         = {2025},
  url          = {https://aclanthology.org/2025.coling-main.710/},
  timestamp    = {Tue, 28 Jan 2025 16:22:22 +0100},
  biburl       = {https://dblp.org/rec/conf/coling/LeeHT25.bib},
  bibsource    = {dblp computer science bibliography, https://dblp.org}
}




@inproceedings{zhao-etal-2024-measuring,
    title = "Measuring the Inconsistency of Large Language Models in Preferential Ranking",
    author = "Zhao, Xiutian  and
      Wang, Ke  and
      Peng, Wei",
    editor = "Li, Sha  and
      Li, Manling  and
      Zhang, Michael JQ  and
      Choi, Eunsol  and
      Geva, Mor  and
      Hase, Peter  and
      Ji, Heng",
    booktitle = "Proceedings of the 1st Workshop on Towards Knowledgeable Language Models (KnowLLM 2024)",
    month = aug,
    year = "2024",
    address = "Bangkok, Thailand",
    publisher = "Association for Computational Linguistics",
    url = "https://aclanthology.org/2024.knowllm-1.14/",
    doi = "10.18653/v1/2024.knowllm-1.14",
    pages = "171--176",
    abstract = "Despite large language models' (LLMs') recent advancements, their bias and hallucination issues persist, and their ability to offer consistent and preferential rankings remains underexplored. This study investigates the capacity of LLMs to provide consistent ordinal preferences, a crucial aspect in scenarios lacking absolute answers. We introduce a formalization of consistency based on order theory, outlining criteria such as transitivity, asymmetry, reversibility, and independence from irrelevant alternatives. Our diagnostic experiments on selected state-of-the-art LLMs reveal their inability to meet these criteria, indicating a strong positional bias and poor transitivity, with preferences easily swayed by irrelevant alternatives. These findings highlight a significant inconsistency in LLM-generated preferential rankings, underscoring the need for further research to address these limitations."
}

@inproceedings{DBLP:conf/nips/ZhengC00WZL0LXZ23,
  author       = {Lianmin Zheng and
                  Wei{-}Lin Chiang and
                  Ying Sheng and
                  Siyuan Zhuang and
                  Zhanghao Wu and
                  Yonghao Zhuang and
                  Zi Lin and
                  Zhuohan Li and
                  Dacheng Li and
                  Eric P. Xing and
                  Hao Zhang and
                  Joseph E. Gonzalez and
                  Ion Stoica},
  editor       = {Alice Oh and
                  Tristan Naumann and
                  Amir Globerson and
                  Kate Saenko and
                  Moritz Hardt and
                  Sergey Levine},
  title        = {Judging LLM-as-a-Judge with MT-Bench and Chatbot Arena},
  booktitle    = {Advances in Neural Information Processing Systems 36: Annual Conference
                  on Neural Information Processing Systems 2023, NeurIPS 2023, New Orleans,
                  LA, USA, December 10 - 16, 2023},
  year         = {2023},
  url          = {http://papers.nips.cc/paper\_files/paper/2023/hash/91f18a1287b398d378ef22505bf41832-Abstract-Datasets\_and\_Benchmarks.html},
  timestamp    = {Tue, 11 Feb 2025 11:42:30 +0100},
  biburl       = {https://dblp.org/rec/conf/nips/ZhengC00WZL0LXZ23.bib},
  bibsource    = {dblp computer science bibliography, https://dblp.org}
}

@inproceedings{DBLP:conf/iclr/ZengYG0G024,
  author       = {Zhiyuan Zeng and
                  Jiatong Yu and
                  Tianyu Gao and
                  Yu Meng and
                  Tanya Goyal and
                  Danqi Chen},
  title        = {Evaluating Large Language Models at Evaluating Instruction Following},
  booktitle    = {The Twelfth International Conference on Learning Representations,
                  {ICLR} 2024, Vienna, Austria, May 7-11, 2024},
  publisher    = {OpenReview.net},
  year         = {2024},
  url          = {https://openreview.net/forum?id=tr0KidwPLc},
  timestamp    = {Thu, 17 Oct 2024 17:26:42 +0200},
  biburl       = {https://dblp.org/rec/conf/iclr/ZengYG0G024.bib},
  bibsource    = {dblp computer science bibliography, https://dblp.org}
}

@article{DBLP:journals/corr/abs-2308-01862,
  author       = {Xinghua Zhang and
                  Bowen Yu and
                  Haiyang Yu and
                  Yangyu Lv and
                  Tingwen Liu and
                  Fei Huang and
                  Hongbo Xu and
                  Yongbin Li},
  title        = {Wider and Deeper {LLM} Networks are Fairer {LLM} Evaluators},
  journal      = {CoRR},
  volume       = {abs/2308.01862},
  year         = {2023},
  url          = {https://doi.org/10.48550/arXiv.2308.01862},
  doi          = {10.48550/ARXIV.2308.01862},
  eprinttype    = {arXiv},
  eprint       = {2308.01862},
  timestamp    = {Sat, 26 Aug 2023 17:33:03 +0200},
  biburl       = {https://dblp.org/rec/journals/corr/abs-2308-01862.bib},
  bibsource    = {dblp computer science bibliography, https://dblp.org}
}

@inproceedings{DBLP:conf/iclr/YeKKHKJTKS24,
  author       = {Seonghyeon Ye and
                  Doyoung Kim and
                  Sungdong Kim and
                  Hyeonbin Hwang and
                  Seungone Kim and
                  Yongrae Jo and
                  James Thorne and
                  Juho Kim and
                  Minjoon Seo},
  title        = {{FLASK:} Fine-grained Language Model Evaluation based on Alignment
                  Skill Sets},
  booktitle    = {The Twelfth International Conference on Learning Representations,
                  {ICLR} 2024, Vienna, Austria, May 7-11, 2024},
  publisher    = {OpenReview.net},
  year         = {2024},
  url          = {https://openreview.net/forum?id=CYmF38ysDa},
  timestamp    = {Tue, 28 Jan 2025 14:37:23 +0100},
  biburl       = {https://dblp.org/rec/conf/iclr/YeKKHKJTKS24.bib},
  bibsource    = {dblp computer science bibliography, https://dblp.org}
}

@article{DBLP:journals/corr/abs-2406-05761,
  author       = {Seungone Kim and
                  Juyoung Suk and
                  Ji Yong Cho and
                  Shayne Longpre and
                  Chaeeun Kim and
                  Dongkeun Yoon and
                  Guijin Son and
                  Yejin Choi and
                  Sheikh Shafayat and
                  Jinheon Baek and
                  Sue Hyun Park and
                  Hyeonbin Hwang and
                  Jinkyung Jo and
                  Hyowon Cho and
                  Haebin Shin and
                  Seongyun Lee and
                  Hanseok Oh and
                  Noah Lee and
                  Namgyu Ho and
                  Se June Joo and
                  Miyoung Ko and
                  Yoonjoo Lee and
                  Hyungjoo Chae and
                  Jamin Shin and
                  Joel Jang and
                  Seonghyeon Ye and
                  Bill Yuchen Lin and
                  Sean Welleck and
                  Graham Neubig and
                  Moontae Lee and
                  Kyungjae Lee and
                  Minjoon Seo},
  title        = {The BiGGen Bench: {A} Principled Benchmark for Fine-grained Evaluation
                  of Language Models with Language Models},
  journal      = {CoRR},
  volume       = {abs/2406.05761},
  year         = {2024},
  url          = {https://doi.org/10.48550/arXiv.2406.05761},
  doi          = {10.48550/ARXIV.2406.05761},
  eprinttype    = {arXiv},
  eprint       = {2406.05761},
  timestamp    = {Sat, 27 Jul 2024 13:40:01 +0200},
  biburl       = {https://dblp.org/rec/journals/corr/abs-2406-05761.bib},
  bibsource    = {dblp computer science bibliography, https://dblp.org}
}



@inproceedings{DBLP:conf/emnlp/ZhangDTST023,
  author       = {Chen Zhang and
                  Luis F. D'Haro and
                  Chengguang Tang and
                  Ke Shi and
                  Guohua Tang and
                  Haizhou Li},
  editor       = {Houda Bouamor and
                  Juan Pino and
                  Kalika Bali},
  title        = {xDial-Eval: {A} Multilingual Open-Domain Dialogue Evaluation Benchmark},
  booktitle    = {Findings of the Association for Computational Linguistics: {EMNLP}
                  2023, Singapore, December 6-10, 2023},
  pages        = {5579--5601},
  publisher    = {Association for Computational Linguistics},
  year         = {2023},
  url          = {https://doi.org/10.18653/v1/2023.findings-emnlp.371},
  doi          = {10.18653/V1/2023.FINDINGS-EMNLP.371},
  timestamp    = {Wed, 02 Oct 2024 07:43:03 +0200},
  biburl       = {https://dblp.org/rec/conf/emnlp/ZhangDTST023.bib},
  bibsource    = {dblp computer science bibliography, https://dblp.org}
}

@inproceedings{DBLP:conf/emnlp/MendoncaTL24,
  author       = {John Mendon{\c{c}}a and
                  Isabel Trancoso and
                  Alon Lavie},
  editor       = {Yaser Al{-}Onaizan and
                  Mohit Bansal and
                  Yun{-}Nung Chen},
  title        = {Soda-Eval: Open-Domain Dialogue Evaluation in the age of LLMs},
  booktitle    = {Findings of the Association for Computational Linguistics: {EMNLP}
                  2024, Miami, Florida, USA, November 12-16, 2024},
  pages        = {11687--11708},
  publisher    = {Association for Computational Linguistics},
  year         = {2024},
  url          = {https://aclanthology.org/2024.findings-emnlp.684},
  timestamp    = {Mon, 18 Nov 2024 09:05:59 +0100},
  biburl       = {https://dblp.org/rec/conf/emnlp/MendoncaTL24.bib},
  bibsource    = {dblp computer science bibliography, https://dblp.org}
}

@inproceedings{DBLP:conf/naacl/LiuFCZHJLRWC24,
  author       = {Yixin Liu and
                  Alexander R. Fabbri and
                  Jiawen Chen and
                  Yilun Zhao and
                  Simeng Han and
                  Shafiq Joty and
                  Pengfei Liu and
                  Dragomir Radev and
                  Chien{-}Sheng Wu and
                  Arman Cohan},
  editor       = {Kevin Duh and
                  Helena G{\'{o}}mez{-}Adorno and
                  Steven Bethard},
  title        = {Benchmarking Generation and Evaluation Capabilities of Large Language
                  Models for Instruction Controllable Summarization},
  booktitle    = {Findings of the Association for Computational Linguistics: {NAACL}
                  2024, Mexico City, Mexico, June 16-21, 2024},
  pages        = {4481--4501},
  publisher    = {Association for Computational Linguistics},
  year         = {2024},
  url          = {https://doi.org/10.18653/v1/2024.findings-naacl.280},
  doi          = {10.18653/V1/2024.FINDINGS-NAACL.280},
  timestamp    = {Thu, 12 Sep 2024 13:29:32 +0200},
  biburl       = {https://dblp.org/rec/conf/naacl/LiuFCZHJLRWC24.bib},
  bibsource    = {dblp computer science bibliography, https://dblp.org}
}

@inproceedings{DBLP:conf/acl/SiledarNMRNBBPS24,
  author       = {Tejpalsingh Siledar and
                  Swaroop Nath and
                  Sankara Sri Raghava Ravindra Muddu and
                  Rupasai Rangaraju and
                  Swaprava Nath and
                  Pushpak Bhattacharyya and
                  Suman Banerjee and
                  Amey Patil and
                  Sudhanshu Singh and
                  Muthusamy Chelliah and
                  Nikesh Garera},
  editor       = {Lun{-}Wei Ku and
                  Andre Martins and
                  Vivek Srikumar},
  title        = {One Prompt To Rule Them All: LLMs for Opinion Summary Evaluation},
  booktitle    = {Proceedings of the 62nd Annual Meeting of the Association for Computational
                  Linguistics (Volume 1: Long Papers), {ACL} 2024, Bangkok, Thailand,
                  August 11-16, 2024},
  pages        = {12119--12134},
  publisher    = {Association for Computational Linguistics},
  year         = {2024},
  url          = {https://doi.org/10.18653/v1/2024.acl-long.655},
  doi          = {10.18653/V1/2024.ACL-LONG.655},
  timestamp    = {Tue, 24 Sep 2024 10:55:42 +0200},
  biburl       = {https://dblp.org/rec/conf/acl/SiledarNMRNBBPS24.bib},
  bibsource    = {dblp computer science bibliography, https://dblp.org}
}

@article{DBLP:journals/tacl/ChhunSC24,
  author       = {Cyril Chhun and
                  Fabian M. Suchanek and
                  Chlo{\'{e}} Clavel},
  title        = {Do Language Models Enjoy Their Own Stories? Prompting Large Language
                  Models for Automatic Story Evaluation},
  journal      = {Trans. Assoc. Comput. Linguistics},
  volume       = {12},
  pages        = {1122--1142},
  year         = {2024},
  url          = {https://doi.org/10.1162/tacl\_a\_00689},
  doi          = {10.1162/TACL\_A\_00689},
  timestamp    = {Thu, 24 Oct 2024 17:43:21 +0200},
  biburl       = {https://dblp.org/rec/journals/tacl/ChhunSC24.bib},
  bibsource    = {dblp computer science bibliography, https://dblp.org}
}

@inproceedings{DBLP:conf/wmt/FreitagMDLAR0BK24,
  author       = {Markus Freitag and
                  Nitika Mathur and
                  Daniel Deutsch and
                  Chi{-}kiu Lo and
                  Eleftherios Avramidis and
                  Ricardo Rei and
                  Brian Thompson and
                  Fr{\'{e}}d{\'{e}}ric Blain and
                  Tom Kocmi and
                  Jiayi Wang and
                  David Ifeoluwa Adelani and
                  Marianna Buchicchio and
                  Chrysoula Zerva and
                  Alon Lavie},
  editor       = {Barry Haddow and
                  Tom Kocmi and
                  Philipp Koehn and
                  Christof Monz},
  title        = {Are LLMs Breaking {MT} Metrics? Results of the {WMT24} Metrics Shared
                  Task},
  booktitle    = {Proceedings of the Ninth Conference on Machine Translation, {WMT}
                  2024, Miami, FL, USA, November 15-16, 2024},
  pages        = {47--81},
  publisher    = {Association for Computational Linguistics},
  year         = {2024},
  url          = {https://aclanthology.org/2024.wmt-1.2},
  timestamp    = {Thu, 21 Nov 2024 17:01:46 +0100},
  biburl       = {https://dblp.org/rec/conf/wmt/FreitagMDLAR0BK24.bib},
  bibsource    = {dblp computer science bibliography, https://dblp.org}
}


@inproceedings{chenmllm,
  title={MLLM-as-a-Judge: Assessing Multimodal LLM-as-a-Judge with Vision-Language Benchmark},
  author={Chen, Dongping and Chen, Ruoxi and Zhang, Shilin and Wang, Yaochen and Liu, Yinuo and Zhou, Huichi and Zhang, Qihui and Wan, Yao and Zhou, Pan and Sun, Lichao},
  booktitle={Forty-first International Conference on Machine Learning},
year={2024}
}


@inproceedings{liusie2024llm,
  title={LLM Comparative Assessment: Zero-shot NLG Evaluation through Pairwise Comparisons using Large Language Models},
  author={Liusie, Adian and Manakul, Potsawee and Gales, Mark},
  booktitle={Proceedings of the 18th Conference of the European Chapter of the Association for Computational Linguistics (Volume 1: Long Papers)},
  pages={139--151},
  year={2024}
}


@inproceedings{amigo2020effectiveness,
  title={An Effectiveness Metric for Ordinal Classification: Formal Properties and Experimental Results},
  author={Amig{\'o}, Enrique and Gonzalo, Julio and Mizzaro, Stefano and de Albornoz, Jorge Carrillo},
  booktitle={Proceedings of the 58th Annual Meeting of the Association for Computational Linguistics},
  pages={3938--3949},
  year={2020}
}