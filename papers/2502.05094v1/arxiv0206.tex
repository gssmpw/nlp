 
\documentclass[12pt]{article}
\usepackage{lmodern}

\usepackage[small]{titlesec}
\usepackage{natbib,amsmath,amssymb,amsthm,graphicx,setspace,paralist,booktabs,rotating,subcaption,float,color}
\usepackage{graphicx}
\usepackage{enumerate}
\usepackage{url} % not crucial - just used below for the URL 
\usepackage{amssymb, amsmath, amsthm}
\usepackage{breakcites}
\usepackage{adjustbox}
\usepackage{bigstrut} %needed to keep blockarrays from being crunched
\usepackage{blkarray}
\usepackage{booktabs}
\usepackage{enumitem} % detailed list control
\usepackage{float} % for 'H' forced placement of floats
\usepackage{graphicx}
\usepackage{subcaption}
%\usepackage{mwe}
\usepackage{comment}
\usepackage[colorlinks=true, allcolors=LinkBlue, backref=page]{hyperref}
\usepackage{lmodern}
\usepackage{mathrsfs} % for mathscr
\usepackage{multirow}
\usepackage{natbib} % for \citet and \citep
\usepackage{scalerel}
\usepackage{setspace}
\usepackage{soul} % for \st = strikethrough
\usepackage{subcaption}
\usepackage{titling}
\usepackage{verbatim}
\usepackage{xcolor}
\usepackage{xfrac}
\usepackage{algorithm}
\usepackage{algorithmic}
\usepackage{bbm}
\usepackage{setspace}
\usepackage{amsfonts}
\usepackage{outlines}
\usepackage{wrapfig}
\usepackage{authblk}
\usepackage{amsmath}
\usepackage{amssymb}
\usepackage{mathtools}
\usepackage{amsthm}
\usepackage{amsthm}
\newtheorem*{lemma*}{Lemma}
\AtBeginDocument{
	\abovedisplayskip=5pt plus 2pt minus 2pt
	\belowdisplayskip=\abovedisplayskip
	\abovedisplayshortskip=2pt plus 2pt minus 2pt
	\belowdisplayshortskip=\belowdisplayskip}

\titlespacing*{\section}{0pt}{*2}{*1}
\titlespacing*{\subsection}{0pt}{*2}{*1} 
\setlength\pltopsep\medskipamount
\bibpunct{(}{)}{;}{a}{}{,}
\setlength\bibsep{0pt}
\setlength\pltopsep\medskipamount 
\setlength\heavyrulewidth{.5pt}
\setlength\lightrulewidth{.4pt}
\setlength\cmidrulewidth{.4pt}

\setlist{noitemsep, topsep=0pt} % for enumitem
\definecolor{LinkBlue}{rgb}{.15, .25, .85} %for hyperref

\binoppenalty=\maxdimen % prevent linebreaks after binary operators, usually 700
\relpenalty=\maxdimen % prevent linebreaks after relations, usually 500

\setlength{\bigstrutjot}{1pt}

% Prevent natbib from breaking
\makeatletter
\renewcommand*{\NAT@spacechar}{~}
\makeatother


% Maybe unnecessary:
\parindent=0pt
\setlength{\parskip}{10pt plus 1pt minus 1pt}
\makeatletter


%\pdfminorversion=4
% NOTE: To produce blinded version, replace "0" with "1" below.
\newcommand{\blind}{1}

% DON'T change margins - should be 1 inch all around.
\addtolength{\oddsidemargin}{-.5in}%
\addtolength{\evensidemargin}{-1in}%
\addtolength{\textwidth}{1in}%
\addtolength{\textheight}{1.7in}%
\addtolength{\topmargin}{-1in}%

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% LyX specific LaTeX commands.
%% A simple dot to overcome graphicx limitations

%\floatstyle{ruled}
% Custom floats, theorems, etc.
\newfloat{algorithm}{tbp}{loa}
\providecommand{\algorithmname}{Algorithm}
\floatname{algorithm}{\protect\algorithmname}


\newtheorem{theorem}{Theorem}
\newtheorem{example}{Example}
\newtheorem{lemma}{Lemma}
\newtheorem{remark}{Remark}
\newtheorem{corollary}{Corollary}
\newtheorem{definition}{Definition}
\newtheorem{conjecture}{Conjecture}
\newtheorem{question}{Question}
\newtheorem{assumption}{Assumption}[section]
\newtheorem{prop}{Proposition}




\def \by {\bar{y}}
\def \bx {\bar{x}}
\def \bh {\bar{h}}
\def \bz {\bar{z}}
\def \cF {\mathcal{F}}
\def \bP {\mathbb{P}}
\def \bE {\mathbb{E}}
\def \bR {\mathbb{R}}
\def \bF {\mathbb{F}}
\def \cG {\mathcal{G}}
\def \cM {\mathcal{M}}
\def \cB {\mathcal{B}}
\def \cN {\mathcal{N}}
\def \var {\mathsf{Var}}
\def \cov {\mathsf{Cov}}

%\input defs.tex


\newcommand{\red}{\color{red}}
\newcommand{\blue}{\color{blue}}
\newcommand{\guanyang}[1]{\textcolor{red}{[GW: {#1}]}}

%%%%%%%%% bold face %%%%%%%%%%


\usepackage{xspace}

\newcommand{\Lip}{\mathrm{Lip}}
\newcommand{\stepa}[1]{\overset{\rm (a)}{#1}}
\newcommand{\stepb}[1]{\overset{\rm (b)}{#1}}
\newcommand{\stepc}[1]{\overset{\rm (c)}{#1}}
\newcommand{\stepd}[1]{\overset{\rm (d)}{#1}}
\newcommand{\stepe}[1]{\overset{\rm (e)}{#1}}


\newcommand{\floor}[1]{{\left\lfloor {#1} \right \rfloor}}
\newcommand{\ceil}[1]{{\left\lceil {#1} \right \rceil}}


\newcommand{\blambda}{\bar{\lambda}}
\newcommand{\reals}{\mathbb{R}}
\newcommand{\naturals}{\mathbb{N}}
\newcommand{\integers}{\mathbb{Z}}
\newcommand{\Expect}{\mathbb{E}}
\newcommand{\expect}[1]{\mathbb{E}\left[#1\right]}
\newcommand{\Prob}{\mathbb{P}}
\newcommand{\prob}[1]{\mathbb{P}\left[#1\right]}
\newcommand{\pprob}[1]{\mathbb{P}[#1]}
\newcommand{\intd}{{\rm d}}
\newcommand{\TV}{{\sf TV}}
\newcommand{\LC}{{\sf LC}}
\newcommand{\PW}{{\sf PW}}
\newcommand{\htheta}{\hat{\theta}}
\newcommand{\eexp}{{\rm e}}
\newcommand{\expects}[2]{\mathbb{E}_{#2}\left[ #1 \right]}
\newcommand{\diff}{\mathrm{d}}
\newcommand{\eg}{e.g.\xspace}
\newcommand{\ie}{i.e.\xspace}
\newcommand{\iid}{i.i.d.\xspace}
\newcommand{\fracp}[2]{\frac{\partial #1}{\partial #2}}
\newcommand{\fracpk}[3]{\frac{\partial^{#3} #1}{\partial #2^{#3}}}
\newcommand{\fracd}[2]{\frac{\diff #1}{\diff #2}}
\newcommand{\fracdk}[3]{\frac{\diff^{#3} #1}{\diff #2^{#3}}}
\newcommand{\renyi}{R\'enyi\xspace}
\newcommand{\lpnorm}[1]{\left\|{#1} \right\|_{p}}
\newcommand{\linf}[1]{\left\|{#1} \right\|_{\infty}}
\newcommand{\lnorm}[2]{\left\|{#1} \right\|_{{#2}}}
\newcommand{\Lploc}[1]{L^{#1}_{\rm loc}}
\newcommand{\hellinger}{d_{\rm H}}
\newcommand{\Fnorm}[1]{\lnorm{#1}{\rm F}}
%% parenthesis
\newcommand{\pth}[1]{\left( #1 \right)}
\newcommand{\qth}[1]{\left[ #1 \right]}
\newcommand{\sth}[1]{\left\{ #1 \right\}}
\newcommand{\bpth}[1]{\Bigg( #1 \Bigg)}
\newcommand{\bqth}[1]{\Bigg[ #1 \Bigg]}
\newcommand{\bsth}[1]{\Bigg\{ #1 \Bigg\}}
\newcommand{\xxx}{\textbf{xxx}\xspace}
\newcommand{\toprob}{{\xrightarrow{\Prob}}}
\newcommand{\tolp}[1]{{\xrightarrow{L^{#1}}}}
\newcommand{\toas}{{\xrightarrow{{\rm a.s.}}}}
\newcommand{\toae}{{\xrightarrow{{\rm a.e.}}}}
\newcommand{\todistr}{{\xrightarrow{{\rm D}}}}
\newcommand{\eqdistr}{{\stackrel{\rm D}{=}}}
\newcommand{\iiddistr}{{\stackrel{\text{\iid}}{\sim}}}
%\newcommand{\var}{\mathsf{var}}
\newcommand\indep{\protect\mathpalette{\protect\independenT}{\perp}}
\def\independenT#1#2{\mathrel{\rlap{$#1#2$}\mkern2mu{#1#2}}}
\newcommand{\Bern}{\text{Bern}}
\newcommand{\Poi}{\mathsf{Poi}}
\newcommand{\Geo}{{\mathsf{Geo}}}
\newcommand{\Binom}{{\mathsf{Binom}}}
\newcommand{\iprod}[2]{\left \langle #1, #2 \right\rangle}
\newcommand{\Iprod}[2]{\langle #1, #2 \rangle}
\newcommand{\indc}[1]{{\mathbf{1}_{\left\{{#1}\right\}}}}
\newcommand{\Indc}{\mathbf{1}}


\newcommand{\bfX}{{\mathbf{X}}}
\newcommand{\bfY}{{\mathbf{Y}}}


\newcommand{\tmu}{{\tilde{\mu}}}
\newcommand{\tf}{{\tilde{f}}}
\newcommand{\tp}{\tilde{p}}
\newcommand{\tilh}{{\tilde{h}}}
\newcommand{\tu}{{\tilde{u}}}
\newcommand{\tx}{{\tilde{x}}}
\newcommand{\ty}{{\tilde{y}}}
\newcommand{\tz}{{\tilde{z}}}
\newcommand{\tA}{{\tilde{A}}}
\newcommand{\tB}{{\tilde{B}}}
\newcommand{\tC}{{\tilde{C}}}
\newcommand{\tD}{{\tilde{D}}}
\newcommand{\tE}{{\tilde{E}}}
\newcommand{\tF}{{\tilde{F}}}
\newcommand{\tG}{{\tilde{G}}}
\newcommand{\tH}{{\tilde{H}}}
\newcommand{\tI}{{\tilde{I}}}
\newcommand{\tJ}{{\tilde{J}}}
\newcommand{\tK}{{\tilde{K}}}
\newcommand{\tL}{{\tilde{L}}}
\newcommand{\tM}{{\tilde{M}}}
\newcommand{\tN}{{\tilde{N}}}
\newcommand{\tO}{{\tilde{O}}}
\newcommand{\tP}{{\tilde{P}}}
\newcommand{\tQ}{{\tilde{Q}}}
\newcommand{\tR}{{\tilde{R}}}
\newcommand{\tS}{{\tilde{S}}}
\newcommand{\tT}{{\tilde{T}}}
\newcommand{\tU}{{\tilde{U}}}
\newcommand{\tV}{{\tilde{V}}}
\newcommand{\tW}{{\tilde{W}}}
\newcommand{\tX}{{\tilde{X}}}
\newcommand{\tY}{{\tilde{Y}}}
\newcommand{\tZ}{{\tilde{Z}}}

\newcommand{\sfa}{{\mathsf{a}}}
\newcommand{\sfb}{{\mathsf{b}}}
\newcommand{\sfc}{{\mathsf{c}}}
\newcommand{\sfd}{{\mathsf{d}}}
\newcommand{\sfe}{{\mathsf{e}}}
\newcommand{\sff}{{\mathsf{f}}}
\newcommand{\sfg}{{\mathsf{g}}}
\newcommand{\sfh}{{\mathsf{h}}}
\newcommand{\sfi}{{\mathsf{i}}}
\newcommand{\sfj}{{\mathsf{j}}}
\newcommand{\sfk}{{\mathsf{k}}}
\newcommand{\sfl}{{\mathsf{l}}}
\newcommand{\sfm}{{\mathsf{m}}}
\newcommand{\sfn}{{\mathsf{n}}}
\newcommand{\sfo}{{\mathsf{o}}}
\newcommand{\sfp}{{\mathsf{p}}}
\newcommand{\sfq}{{\mathsf{q}}}
\newcommand{\sfr}{{\mathsf{r}}}
\newcommand{\sfs}{{\mathsf{s}}}
\newcommand{\sft}{{\mathsf{t}}}
\newcommand{\sfu}{{\mathsf{u}}}
\newcommand{\sfv}{{\mathsf{v}}}
\newcommand{\sfw}{{\mathsf{w}}}
\newcommand{\sfx}{{\mathsf{x}}}
\newcommand{\sfy}{{\mathsf{y}}}
\newcommand{\sfz}{{\mathsf{z}}}
\newcommand{\sfA}{{\mathsf{A}}}
\newcommand{\sfB}{{\mathsf{B}}}
\newcommand{\sfC}{{\mathsf{C}}}
\newcommand{\sfD}{{\mathsf{D}}}
\newcommand{\sfE}{{\mathsf{E}}}
\newcommand{\sfF}{{\mathsf{F}}}
\newcommand{\sfG}{{\mathsf{G}}}
\newcommand{\sfH}{{\mathsf{H}}}
\newcommand{\sfI}{{\mathsf{I}}}
\newcommand{\sfJ}{{\mathsf{J}}}
\newcommand{\sfK}{{\mathsf{K}}}
\newcommand{\sfL}{{\mathsf{L}}}
\newcommand{\sfM}{{\mathsf{M}}}
\newcommand{\sfN}{{\mathsf{N}}}
\newcommand{\sfO}{{\mathsf{O}}}
\newcommand{\sfP}{{\mathsf{P}}}
\newcommand{\sfQ}{{\mathsf{Q}}}
\newcommand{\sfR}{{\mathsf{R}}}
\newcommand{\sfS}{{\mathsf{S}}}
\newcommand{\sfT}{{\mathsf{T}}}
\newcommand{\sfU}{{\mathsf{U}}}
\newcommand{\sfV}{{\mathsf{V}}}
\newcommand{\sfW}{{\mathsf{W}}}
\newcommand{\sfX}{{\mathsf{X}}}
\newcommand{\sfY}{{\mathsf{Y}}}
\newcommand{\sfZ}{{\mathsf{Z}}}


\newcommand{\calA}{{\mathcal{A}}}
\newcommand{\calB}{{\mathcal{B}}}
\newcommand{\calC}{{\mathcal{C}}}
\newcommand{\calD}{{\mathcal{D}}}
\newcommand{\calE}{{\mathcal{E}}}
\newcommand{\calF}{{\mathcal{F}}}
\newcommand{\calG}{{\mathcal{G}}}
\newcommand{\calH}{{\mathcal{H}}}
\newcommand{\calI}{{\mathcal{I}}}
\newcommand{\calJ}{{\mathcal{J}}}
\newcommand{\calK}{{\mathcal{K}}}
\newcommand{\calL}{{\mathcal{L}}}
\newcommand{\calM}{{\mathcal{M}}}
\newcommand{\calN}{{\mathcal{N}}}
\newcommand{\calO}{{\mathcal{O}}}
\newcommand{\calP}{{\mathcal{P}}}
\newcommand{\calQ}{{\mathcal{Q}}}
\newcommand{\calR}{{\mathcal{R}}}
\newcommand{\calS}{{\mathcal{S}}}
\newcommand{\calT}{{\mathcal{T}}}
\newcommand{\calU}{{\mathcal{U}}}
\newcommand{\calV}{{\mathcal{V}}}
\newcommand{\calW}{{\mathcal{W}}}
\newcommand{\calX}{{\mathcal{X}}}
\newcommand{\calY}{{\mathcal{Y}}}
\newcommand{\calZ}{{\mathcal{Z}}}

\newcommand{\bara}{{\bar{a}}}
\newcommand{\barb}{{\bar{b}}}
\newcommand{\barc}{{\bar{c}}}
\newcommand{\bard}{{\bar{d}}}
\newcommand{\bare}{{\bar{e}}}
\newcommand{\barf}{{\bar{f}}}
\newcommand{\barg}{{\bar{g}}}
\newcommand{\barh}{{\bar{h}}}
\newcommand{\bari}{{\bar{i}}}
\newcommand{\barj}{{\bar{j}}}
\newcommand{\bark}{{\bar{k}}}
\newcommand{\barl}{{\bar{l}}}
\newcommand{\barm}{{\bar{m}}}
\newcommand{\barn}{{\bar{n}}}
\newcommand{\baro}{{\bar{o}}}
\newcommand{\barp}{{\bar{p}}}
\newcommand{\barq}{{\bar{q}}}
\newcommand{\barr}{{\bar{r}}}
\newcommand{\bars}{{\bar{s}}}
\newcommand{\bart}{{\bar{t}}}
\newcommand{\baru}{{\bar{u}}}
\newcommand{\barv}{{\bar{v}}}
\newcommand{\barw}{{\bar{w}}}
\newcommand{\barx}{{\bar{x}}}
\newcommand{\bary}{{\bar{y}}}
\newcommand{\barz}{{\bar{z}}}
\newcommand{\barA}{{\bar{A}}}
\newcommand{\barB}{{\bar{B}}}
\newcommand{\barC}{{\bar{C}}}
\newcommand{\barD}{{\bar{D}}}
\newcommand{\barE}{{\bar{E}}}
\newcommand{\barF}{{\bar{F}}}
\newcommand{\barG}{{\bar{G}}}
\newcommand{\barH}{{\bar{H}}}
\newcommand{\barI}{{\bar{I}}}
\newcommand{\barJ}{{\bar{J}}}
\newcommand{\barK}{{\bar{K}}}
\newcommand{\barL}{{\bar{L}}}
\newcommand{\barM}{{\bar{M}}}
\newcommand{\barN}{{\bar{N}}}
\newcommand{\barO}{{\bar{O}}}
\newcommand{\barP}{{\bar{P}}}
\newcommand{\barQ}{{\bar{Q}}}
\newcommand{\barR}{{\bar{R}}}
\newcommand{\barS}{{\bar{S}}}
\newcommand{\barT}{{\bar{T}}}
\newcommand{\barU}{{\bar{U}}}
\newcommand{\barV}{{\bar{V}}}
\newcommand{\barW}{{\bar{W}}}
\newcommand{\barX}{{\bar{X}}}
\newcommand{\barY}{{\bar{Y}}}
\newcommand{\barZ}{{\bar{Z}}}

\newcommand{\hX}{\hat{X}}
\newcommand{\Ent}{\mathsf{Ent}}
\newcommand{\Avg}{\mathsf{Avg}}

\newcommand{\trans}{^{\rm T}}
\newcommand{\Th}{{^{\rm th}}}
\newcommand{\diverge}{\to \infty}

\newcommand{\V}{\mathsf{Var}}
\newcommand\blfootnote[1]{%
	\begingroup
	\renewcommand\thefootnote{}\footnote{#1}%
	\addtocounter{footnote}{-1}%
	\endgroup
}
\begin{document}
\title{Non-linear Quantum Monte Carlo}
\author[1]{Jose Blanchet}
\affil[1]{Stanford University\\
\texttt{jose.blanchet@stanford.edu}}
\author[2]{Yassine Hamoudi} 
\affil[2]{UniversitÃ© de Bordeaux, CNRS, LaBRI\\
\texttt{ys.hamoudi@gmail.com}}
\author[3]{Mario Szegedy} 
\affil[3]{Rutgers University\\ \texttt{szegedy@cs.rutgers.edu}}
\author[4]{Guanyang Wang} 
\affil[4]{Rutgers University\\ \texttt{guanyang.wang@rutgers.edu}}
\maketitle

 
\def\spacingset#1{\renewcommand{\baselinestretch}%
{#1}\small\normalsize} \spacingset{1}
\spacingset{1.5} 
\begin{abstract}
The mean of a random variable can be understood as a \textit{linear} functional on the space of probability distributions. Quantum computing is known to provide a quadratic speedup over classical Monte Carlo methods for mean estimation. In this paper, we investigate whether a similar quadratic speedup is achievable for estimating \textit{non-linear} functionals of probability distributions. We propose a quantum-inside-quantum Monte Carlo algorithm that achieves such a speedup for a broad class of non-linear estimation problems, including nested conditional expectations and stochastic optimization. Our algorithm improves upon the direct application of the quantum multilevel Monte Carlo algorithm introduced by \cite{an2021quantum}. The existing lower bound indicates that our algorithm is optimal up polylogarithmic factors. A key innovation of our approach is a new sequence of multilevel Monte Carlo approximations specifically designed for quantum computing, which is central to the algorithm's improved performance.
\end{abstract}
\section{Introduction}

From classic problems like Buffon's needle \citep{ramaley1969buffon} to modern Bayesian computations \citep{martin2023computing}, Monte Carlo methods have proven to be powerful tools for estimating the expected value of a given function. Specifically, the classical Monte Carlo method involves estimating 
$\mathbb{E}_{\mathbb{P}}[f(\mathbf{X})] = \int_{S} f(\mathbf{x}) \, \diff\mathbb{P}(\mathbf{x})$ by sampling, where the samples are drawn according to the probability distribution $\mathbb{P}$ in $S\subseteq \mathbb{R}^d$. We use the notation $\mathbb{E}_{\mathbb{P}}[\cdot]$ to highlight the dependence on $\mathbb{P}$ when needed.  Here, $\mathbb{E}_{\mathbb{P}}[f(\mathbf{X})]$ depends linearly on $\mathbb{P}$ in the sense that it is a linear operator mapping $\mathbb{P}$ to the expected value. We note that the random variable $\mathbf{X}$ is assumed to be multidimensional, meaning that $\mathbf{X} \in S\subseteq \mathbb{R}^d$. We assume that $f(\cdot)$ is a (measurable) function mapping $S$ to 
$\mathbb{R}^n$, and the expectation is computed component-wise, so it returns an $n$-dimensional vector.

 \iffalse
In statistics, unlike in probability theory, the term `random variable' commonly refers to a function that maps outcomes of a random process to numerical values, such as real or complex numbers or vectors. It is a black-box algorithm with a random input. Even if the randomness of the input changes, the symbol denoting the random variable remains the same. What remains invariant is the set $S$ of possible outcomes. The probability distribution, which assigns probabilities to these outcomes, is typically denoted as $\mathbb{P}$.

If this remark is intending to indicate that the we are omit the argument (typically denoted as $\omega$) in the random variable, which is a common practice statistics? 
\fi

Assuming $f$ has finite variance, the number of independent and identically distributed (i.i.d.) samples required to produce an estimate of $\bE_\bP[f(\bfX)]$ with an additive error of $\epsilon$ and a given degree (say 95\%) of confidence is $\calO(1/\epsilon^2)$ \footnote{Throughout this paper, we use big-O notation: \( f(n) = \mathcal{O}(g(n)) \) means \( f(n) \leq M g(n) \) for all \( n \) and some constant \( M \). We write \( f(n) = \tilde{\mathcal{O}}(g(n)) \) to ignore polylogarithmic factors, meaning \( f(n) = \mathcal{O}(g(n) \log^k g(n)) \) for some \( k \).} for the best classical algorithm. In the quantum setting, using a Grover-type algorithm \cite{grover1996fast}, it is known  \citep{kothari2023mean,montanaro2015quantum} that a quantum version of Monte Carlo achieves a quadratic speedup, resulting in a query complexity of 
\(\mathcal{O}(1/\epsilon)\) for the same task.

This paper focuses on settings involving a non-linear functional of $\bP$. In particular, we are interested in computing $\theta\left(  \bP\right)  $, where $\theta\left(  \cdot\right)$
is a nonlinear map from the space of probability measures supported on $S$, into $\mathbb{R}$. We assume that $\theta(v)$ is computable for any finitely supported distribution $v$, with a computation cost of $\calO(n)$ for support size $n$.

The classical Monte Carlo approach for estimating $\theta\left(  \bP\right)$ proceeds by sampling $n$ independent and identically distributed
i.i.d. random variables (r.v.) $X_{1},...,X_{n}$. The $X_{i}$'s may be multidimensional if $S$ is a subset of $\mathbb{R}^d$ for some $d>1$. The crude
Monte Carlo estimator is simply $\theta\left(
\bP_{n}\right)  $, where $\bP_{n}$ is the \textit{empirical distribution} induced by the sample, namely,
\[
\bP_{n}\left(  \cdot\right)  =\frac{1}{n}\sum_{i=1}^{n}\delta_{\{X_{i}%
\}}\left(  \cdot\right),
\]
where $\delta_{x}\left(  \cdot\right)  $ is the point-mass measure centered at $x$. Although this Monte Carlo estimator remains feasible to compute, the previous scaling \( n = \mathcal{O}(1/\epsilon^2) \) may no longer be adequate to obtain an \(\epsilon\)-accurate estimate when \(\theta\) is a nonlinear functional of \(\bP\).



\subsection{Examples of non-linear Monte Carlo}
Instances of non-linear Monte Carlo estimation problems include the following examples. 

%* Point out direct connections with applications --
%\bigskip
\begin{example}[Function of expectation]\label{eg:func of expectation}
    Suppose that $S=\mathbb{R}^{d}$ and that $\theta(\bP):= g(\bE[\bfX])$
for some (measurable) function $g:\mathbb{R}^{d}%
\rightarrow\mathbb{R}$. This setting involves a range of commonly encountered statistics. For example, the
\textit{standard deviation} of a random variable $W$ fits in this setting by defining $S= \mathbb{R}^2$, defining $\bfX=\left( X_{1},X_{2}\right)  :=\left(  W,W^{2}\right)$, and letting $g\left(x_1,x_2\right)
=\left(  x_{2}-x_{1}^2\right)  ^{1/2}$). Another popular statistic is the \textit{correlation coefficient}
between $Y$ and $W$. In this case, we can define
\[
\bfX=\left(  X_{1},...,X_{5}\right)=\left(  Y,W,Y^{2},W^{2},YW\right)
\]
and let
\[
g\left(  x\right)  =\frac{\left(  x_{5}-x_{1}x_{2}\right)  }{\left(
x_{3}-x_{1}^{2}\right)  ^{1/2}\left(  x_{4}-x_{2}^{2}\right)  ^{1/2}}.
\]
\end{example}


Moreover, Example \ref{eg:func of expectation} can be readily extended by allowing $g$ to be multidimensional. This generalized setting naturally includes the simultaneous estimation of standard deviations and correlations.

\begin{example}[Stochastic optimization]\label{eg:stochastic optimization}
    Consider the setting of \textit{stochastic
optimization}. In particular, given an objective function $F:\Theta \times \mathbb{R}%
^{k}\rightarrow\mathbb{R}$, consider the functional
\[
\theta\left(  \bP\right)  =\max_{\theta \in \Theta}%
\bE[F\left(  \theta,\bfY\right)].
\]

In this context, the crude Monte Carlo estimator arises in common machine learning tasks and takes the form
$$\theta(\bP_n)  = \max_{\theta\in \Theta} \frac{\sum_{i=1}^n F(\theta,\bfY_i)}{n},$$ commonly referred to as the sample-average approximation (SAA) or the empirical estimator for this type of optimization problem. This scenario can be included within the framework of Example \ref{eg:func of expectation} at least when $\Theta$ is finite. When $\Theta = (\theta_1, \theta_2, \ldots, \theta_m)$, we can define
\[
\bfX = (X_1, \ldots, X_m) := (F(\theta_1, \bfY), \ldots, F(\theta_m, \bfY))
\]
and let $g(z_1,...,z_m) = \max(z_1,...,z_m)$. 
\end{example} 

The next example is particularly interesting as it generalizes the previous examples we have discussed.
\bigskip

\begin{example}[Nested simulation]\label{eg:nested simulation}
    Given a probability distribution $\bP$ on the product space
$\calX\times \calY$, we can write it in the form
\[
\bP\left(  \diff x,\diff y\right)  =\eta\left(  \diff x\right)  \mu\left(
x,\diff y\right)  ,
\]
where $\eta$ is the marginal distribution on $\calX$ and $\mu\left(
x,\diff y\right)  $ is the conditional distribution on $\calY$ given a
realization $x$ from $\eta\left(  \cdot\right)  $. We can consider the
\textit{nested simulation }problem in which
\[
\theta\left(  \bP\right)  := \int g\left(  \int\phi(x,y) \mu\left(x,\diff y\right)  \right)  \eta(\diff x).
\]
Expressed in natural language, the quantity considered here is an ``expectation of a functional applied to the conditional distribution." When $g$ is a linear function, the problem simplifies to estimating the expectation of $\phi$ under the joint distribution $\bP$, which is a standard mean estimation problem. In other words, the nonlinearity of the map $\theta$ arises from the nonlinearity of $g$.
\end{example}


\subsection{Nested expectation}\label{subsec: nested expectation}

We now establish the notations that will be used throughout the rest of the paper. Let $\bP$ denote a probability distribution on $\calX \times \calY$. Since the explicit nonlinear dependence on the distribution $\bP$ has already been illustrated in previous examples, we will omit the subscript $\bP$ under $\mathbb{E}$ whenever it is clear from the context. Define a (vector-valued) function $\phi: \calX \times \calY \rightarrow \bR^m$ and another function $g: \calX \times \bR^m \rightarrow \bR$. Let $(X, Y)$ be a pair of random variables with the joint distribution $\bP$. Our paper addresses the estimation of the \textbf{nested expectation}, which takes the form:
\begin{align}\label{eqn:nested expectation}
    \mathbb{E}_X\left[g(X,\mathbb{E}_{Y \mid X}[\phi(X,Y)])\right].
\end{align}



If we set $\lambda(x) := g(x,\gamma(x))$ where $\gamma(x) = \bE_{Y \mid X=x}[\phi(x,Y)]$, the expression \eqref{eqn:nested expectation} can be written more simply as $\bE[\lambda(X)]$. However, it is more challenging than the standard Monte Carlo mean estimation problem as $\lambda(x)$ further depends on a conditional expectation  $\gamma(x)$ that needs to be estimated.

We will now describe the relationship between quantity \eqref{eqn:nested expectation} and the examples mentioned earlier. If $g$ depends solely on its second argument, meaning $g(x, \gamma(x)) = g(\gamma(x))$, then the target quantity in \eqref{eqn:nested expectation} reduces precisely to the one discussed in Example \ref{eg:nested simulation}, expressed here using more probabilistic notations. Furthermore, if the marginal distribution of $X$ is trivial (i.e. $X$ is deterministic), then the outer expectation in \eqref{eqn:nested expectation} will disappear, and \eqref{eqn:nested expectation} recovers Examples \ref{eg:func of expectation} and (the finite case of) Example \ref{eg:stochastic optimization} as special cases. 


The term ``nested expectation" was formally introduced and defined in \cite{rainforth2018nesting}. It also represents the simplest nontrivial case of ``repeated nested expectation" \citep{zhou2023unbiased, syed2023optimal,haji2023nested}. Some concrete applications are as follows: 
\begin{itemize}[leftmargin=*]
    \item In Bayesian experiment design \citep{lindley1956measure,hironaka2023efficient}, the expected information loss of the random variable $Y$ is defined as:
    \begin{align*}
          \bE_X\left[\log(\bE_{Y}[\bP(X\mid Y)])\right] - \bE_Y\left[\bE_{X \mid Y}[\log(\bP(X\mid Y)]\right].
    \end{align*}
Here a nested expectation appears in the first term. 

    \item Given $d$ functions $f_1, \ldots, f_d$ which can be understood as treatments, the expected value of partial perfect information (EVPPI) \citep{giles2019decision}, is defined as:
       \begin{align*}
       \bE_X\left[\max_k\bE_{Y\mid X}[f_k(X,Y)]\right] - \max_k \bE[f_k(X,Y)].
       \end{align*}
       EVPPI captures the expected benefit of knowing $X$. Here, a nested expectation appears also in the first term. 

    \item In financial engineering, financial derivatives are typically evaluated using
expectations and, therefore, Monte Carlo methods are often the method of choice
in practice. One of the most popular derivatives is the so-called call option, whose value (in simplified form) can be evaluated as
\[
  \mathbb{E}_{Y \mid X}\bigl[\max(Y - k, 0)\,\mid\,X\bigr].
\]
Here, \(k\) is the strike price, \(Y\) is the price of the underlying asset at a
future date, and \(X\) represents the available information on the underlying. For instance, the value of a Call on a Call (CoC) option (a call in which the underlying is also a call option with the same strike price) is
    \begin{align*}
        \bE_X\{\max(\bE_{Y|X}[\max(Y-k,0)|X]-k,0)\}.
    \end{align*}
\item The objective function in conditional stochastic optimization (CSO) \cite{hu2020biased, he2024debiasing} is formulated as a nested expectation, i.e., 
\[
\min_x F(x) := \min_x \bE_{\xi}[f(\bE_{\eta\mid\xi}[g_{\eta}(x,\xi)])].
\]
\end{itemize}

Numerous methods are available for estimating nested expectations. The most natural way is by nesting Monte Carlo estimators. This method works by first sampling $X_1, X_2, \ldots, X_m$ independent and identically distributed (i.i.d.). For each $X_i$, one further samples $Y_{i,1}, Y_{i,2},\ldots, Y_{i,n}$ i.i.d. from $\bP(Y \mid X_i)$. Then $\gamma(X_i)$ can be  estimated by $\hat\gamma(X_i) := \sum_{j=1}^n \phi(X_i, Y_{i,j})/n$, and the final estimator is of the form 
\begin{align}\label{eqn:nested-estimator}
    \frac{\sum_{i=1}^{m} g(X_i, \hat\gamma(X_i))}{m} =  \frac{\sum_{i=1}^{m} g(X_i, \sum_{j=1}^n \phi(X_i, Y_{i,j})/n)}{m}.
\end{align}

Under different smoothness assumptions on $g$, this nested estimator costs $\calO(1/\epsilon^3)$ to $\calO(1/\epsilon^4)$ samples to obtain an estimator with a mean square error (MSE) of up to $\epsilon^2$ \citep{hong2009estimating, rainforth2018nesting}. The Multilevel Monte Carlo (MLMC) technique further improves efficiency to $\calO(1/\epsilon^2)$ or $\calO((1/\epsilon^2)\log(1/\epsilon)^2)$, as outlined in Section 9.1 of \cite{giles2015multilevel} and \cite{blanchet2015unbiased}. 

If users have access to a quantum computer, \citet{an2021quantum} proposed a  QA-MLMC algorithm that improves upon the classical MLMC. The improvement ranges from quadratic to sub-quadratic, depending on the parameters of the MLMC framework detailed in Sections \ref{subsec: classical MLMC} and \ref{subsec: quantum MLMC}.

Under the standard Lipschitz assumptions, directly applying the QA-MLMC \cite{an2021quantum} to our non-linear nested expectation problem incurs a cost of $\tilde{\calO}(1/\epsilon^{1.5})$. This improves upon the classical cost $\tilde \calO(1/\epsilon^2)$ but falls short of the expected quadratic speed-up. Technical analysis explaining the loss of quadratic speed-up is given in Section \ref{subsec: motivation}.


\subsection{Our contribution}\label{subsec:contribution}
Our main algorithmic contribution of this paper is a \textit{quantum-inside-quantum MLMC algorithm} for estimating nested expectations. Under standard technical assumptions, the algorithm achieves a cost of $\tilde\calO(1/\epsilon)$ to produce an estimator with $\epsilon$-accuracy, which is proven to be optimal among all quantum algorithms up to logarithmic factors. As such, our algorithm provides a quadratic speedup compared to the classical MLMC algorithm, making it more efficient than the direct adaptation of the quantum algorithm proposed in \cite{an2021quantum}. The comparison between our algorithm and existing methods are summarized in Table \ref{tab: cost comparison}.
\begin{table}[htp]
\begin{center}
\begin{tabular}{|c|c|}
\hline
Method                       & Cost                          \\ \hline 
Nested estimator \eqref{eqn:nested-estimator}\cite{rainforth2018nesting} & $\calO(\epsilon^{-4})$         \\
Classical MLMC (Thm \ref{thm:MLMC})  \cite{giles2015multilevel}             & $\tilde\calO(\epsilon^{-2})$   \\
QA-MLMC (Thm \ref{thm:qa-MLMC})  \cite{an2021quantum}                   & $\tilde\calO(\epsilon^{-1.5})$ \\
{\textcolor{blue}{\textsc{Q-NestExpect} (Ours)}}             & \blue{$\tilde\calO(\epsilon^{-1})$}   \\ \hline
\end{tabular}
\end{center}
\caption{Computational cost of estimating the nested expectation with $\epsilon$-accuracy \eqref{eqn:nested expectation} using different methods. The first two rows are classical algorithms, while the last two are quantum algorithms.}
\label{tab: cost comparison}
\end{table}


We  provide a brief explanation of the basis of our improvement and the term ``quantum-inside-quantum", with more comprehensive explanations to follow in later sections. 
For a given target quantity  and an error budget $\epsilon$, every classical MLMC algorithm consists of two primary components: \textbf{(1)} decomposing the estimation problem into the task of separately estimating the expectations of different parts; and \textbf{(2)} distributing the total error budget $\epsilon$ among these parts to minimize the overall computational cost, followed by using (classical) Monte Carlo to estimate each expectation. The QA-MLMC algorithm \citep{an2021quantum} replaces step (2) with quantum Monte Carlo methods. We observed, however, that there are multiple ways to performing the decomposition in step (1). Notably, the most natural decomposition for classical MLMC is not optimal for quantum algorithms in our nested expectation problem. To address this, we developed a new decomposition strategy based on a different sequence of quantum Monte Carlo subroutines, ultimately achieving the desired quadratic speedup. Thus, the ``outside quantum" refers to the quantum Monte Carlo algorithm in Step (2) , while the ``inside quantum" denotes the sequence of quantum subroutines used in Step (1).
 
 
Besides addressing the nested expectation estimation problem itself, we show that quantum computing introduces new flexibility to MLMC. By redesigning the MLMC subroutines to leverage quantum algorithms, additional gains can be achieved. As MLMC is widely applied in computational finance, uncertainty quantification, and engineering simulations, we believe our strategy can also improve algorithmic efficiency across many of these applications.


\section{Multilevel Monte Carlo}
\subsection{Classical MLMC}\label{subsec: classical MLMC}
Multilevel Monte Carlo (MLMC) methods aim to estimate a specific statistic of a target distribution, such as the expectation of a function applied to the solution of a Stochastic Differential Equation (SDE) \citep{giles2008multilevel}, a function of an expectation \citep{blanchet2015unbiased}, solutions of stochastic optimization problems, quantiles, and steady-state expectations \cite{blanchet2019unbiased}. Typically, users have access to a sequence of approximations for the target distribution, where each successive approximation features reduced variance but increased computational cost. The following theorem offers theoretical guarantees for classical MLMC.


\begin{theorem}[Theorem 1 in \cite{giles2015multilevel}]\label{thm:MLMC}
Let $X$ denote a random variable whose expectation we want to estimate.
Suppose for each $l\geq 0$, we have an algorithm $\calA_l$ that outputs a random variable $\Delta_l$  with variance $V_l$ and computational cost $C_l$. Define $s_l := \sum_{k=0}^l \bE[\Delta_k]$  and assume the following holds for some $\alpha, \beta, \gamma$ such that $\alpha \geq \frac{1}{2}\max\{\gamma, \beta\}$ and:
\begin{itemize}
    \item $\lvert s_l - \bE[X]\rvert \leq \calO(2^{-\alpha l})$;
    \item $V_l \leq \calO(2^{-\beta l})$;
    \item $C_l \leq\calO(2^{\gamma l})$.
\end{itemize}
Then for any fixed $\epsilon < 1/e$, one can choose positive integers $L, N_1, \ldots, N_L$ depending on $\alpha,\beta, \gamma$, and construct an estimator 
$Y: = \sum_{l=1}^L \frac{1}{N_l} \sum_{i=1}^{N_l}\Delta_l^{(i)}$
satisfying $\bE[(Y- \bE[P])^2] < \epsilon^2$ with computational cost:

    $$
\begin{cases}
\calO(\epsilon^{-2}), ~~~\qquad\qquad \gamma < \beta\\
\calO(\epsilon^{-2}(\log\epsilon)^2), ~\qquad \gamma = \beta\\
\calO(\epsilon^{-2 - (\gamma - \beta)/\alpha}), \qquad \gamma > \beta,
\end{cases}
$$
here $\Delta_l^{(1)}, \Delta_l^{(2)}, \ldots$ are i.i.d. copies of $\Delta_l$ for each $l$.
\end{theorem}



The  MLMC estimator described in Theorem \ref{thm:MLMC} can be rewritten as $Y = \sum_{l=1}^L Y_l$, with each $Y_l :=\sum_{i=1}^{N_l}\Delta_l^{(i)}/N_l$ acting as a Monte Carlo estimator for $\bE[\Delta_l]$.



The design and analysis of the sequence \(\calA_l\) are central to  apply Theorem \ref{thm:MLMC} in every MLMC application. In the nested expectation problem, we follow Section 9.1 of \cite{giles2015multilevel} and provide the MLMC solution here. We define $\calA_0$ as: 1) simulate $X$; 2) simulate $Y$ given $X$; 3) output $g(X, \phi(X,Y))$. When $l \geq 1$, $\calA_l$ is defined in Algorithm \ref{alg:nested-classicalMLMC-Al}.

\begin{algorithm}[H]
\caption{Classical MLMC solution for nested expectation: $\mathcal \calA_l$ ($l\geq 1)$}
\label{alg:nested-classicalMLMC-Al}
\begin{algorithmic}[1]
    \STATE Generate $X$ 
    \STATE Generate $Y_1, \ldots, Y_{2^l}$ conditional on $X$
    \STATE Set $S_{\text{o}} = \sum_{i \text{~odd}} \phi(X, Y_i)$, $S_{\text{e}} = \sum_{i \text{~even}} \phi(X, Y_i)$, 
    \STATE \textbf{Output:} 
    
    $$g\left(X, \frac{1}{2^l}(S_\text{e} + S_{\text{o}})\right) - \frac{g\left(X, \frac{1}{2^{l-1}}S_{\text{e}}\right) + g\left(X, \frac{1}{2^{l-1}}S_{\text{o}}\right)}{2}$$. 
\end{algorithmic}
\end{algorithm}

Under assumptions 1-4 given in Section \ref{sec:main theorem}, one can check the sequence of algorithm $\calA_l$ satifies $\alpha = 0.5, \beta = \gamma = 1$ in Theorem \ref{thm:MLMC}, with a validity proof given in the Appendix \ref{sec: verify mlmc}. Therefore Theorem \ref{thm:MLMC} implies one can estimate the nested expectation with cost $\calO(\epsilon^{-2}(\log\epsilon)^2)$.


\subsection{Quantum-accelerated MLMC}\label{subsec: quantum MLMC}

In \citep{an2021quantum}, the authors propose a quantum-accelerated MLMC (QA-MLMC) algorithm which obtains speedup over the classical MLMC algorithm. The key insight is as follows: recall that $Y_l := \sum_{i=1}^{N_l}\Delta_l^{(i)}/N_l$ is a classical Monte Carlo estimator for $\bE[\Delta_l]$, meaning it estimates $\bE[\Delta_l]$ through i.i.d. sampling and then takes the average. This process can be accelerated by applying quantum Monte Carlo techniques, such as those discussed in \citep{montanaro2015quantum}. By replacing the classical Monte Carlo estimators $Y_l$ with their quantum counterparts, the following result is shown: 

\begin{theorem}[Theorem 2 in \cite{an2021quantum}]\label{thm:qa-MLMC}
With the same assumption as in Theorem \ref{thm:MLMC}, there is a quantum algorithm that estimates $\bE[X]$ up to additive error $\epsilon$ with probability at least $0.99$, and with cost
$$
\begin{cases}
\tilde\calO(\epsilon^{-1}), ~~~\qquad\qquad 2\gamma \leq \beta\\
\tilde\calO(\epsilon^{-1 - (\gamma-0.5\beta)/\alpha}), ~~~ 2\gamma > \beta,
\end{cases}
$$
where $\tilde\calO$ ignores factors that are polynomially logarithmic in $\epsilon^{-1}$. 
\end{theorem}
\begin{remark}
    Using the well-known ``median technique" (Lemma 1 in \citep{montanaro2015quantum}), one can improve the success rate to $1-\delta$ for any chosen $\delta$, by executing the algorithm $\calO(\log(\delta^{-1}))$ times and choosing the median outcome.
\end{remark}
When comparing the QA-MLMC (Theorem \ref{thm:qa-MLMC}) with the classical MLMC (Theorem \ref{thm:MLMC}), we find that QA-MLMC only offers a quadratic improvement (up to poly-logarithmic factors) within the specific parameter regime where $\beta \geq 2\gamma$. In a typical scenario where $\beta = \gamma = 1,\alpha\geq 0.5$, the computational cost for classical MLMC is  $\tilde{\mathcal{O}}(\epsilon^{-2})$, whereas for QA-MLMC, it is  $\tilde{\mathcal{O}}(\epsilon^{-1.5})$. In particular, QA-MLMC has cost 
$\tilde{\mathcal{O}}(\epsilon^{-1.5})$ for the nested expectation problem considered here. This finding is intriguing. Quantum Monte Carlo methods leverage Grover's algorithm to achieve a quadratic speedup over classical methods. This raises questions about why the proposed algorithm does not achieve a comparable speedup. It also prompts consideration of whether the algorithm can be improved.


\section{Main Algorithm}\label{sec:main theorem}
Consider a pair of random variables $(X, Y)\in \calX\times \calY$ with a joint distribution denoted as $\bP$. Users have access to two simulators, $\calS_1$ and $\calS_2$. The first simulator, $\calS_1$, does not take an input and outputs a sample based on the marginal distribution of $X$. The second simulator, $\calS_2$, accepts inputs $x$ and generates a sample $Y$ according to the conditional distribution $\bP(Y | X = x)$. Users may also call $\calS_2$ multiple times with the same input $x$ to generate i.i.d. realizations of $\bP(Y | X = x)$. Additionally, it is assumed that calling either simulator once results in a unit cost.



There are two functions $g: \calX \times \mathbb R^m \rightarrow \mathbb R$, and $\phi: \calX\times \calY\rightarrow \mathbb R^m$, accessible to users for queries, which also incur a cost per query. Recall that

\begin{definition}
A function \(g: \calX \times \mathbb R^m \rightarrow \mathbb{R}\) is 
uniformly \(K\)-Lipschitz in the second component
if there exists a positive real constant $K$ such that
for all \(x \in \calX\) and \(y_1, y_2 \in \mathbb{R}\),
\begin{equation}
|g(x,y_{1}) - g(x,y_{2})| \leq K \lVert y_{1} - y_{2}\rVert. \label{lip}
\end{equation}
\end{definition}

 The quantity of our interest is $\bE_X\left[g(X,\bE_{Y \mid X}[\phi(X,Y)])\right]$. We pose four assumptions:

\begin{enumerate}
    \item The function $g$ is uniformly $K$-Lipschitz in its second component.
    \item There is a constant $V$ known to the users satisfying $\bE_{Y\mid x}[\lvert\phi_i(x,Y)\rvert^2] \leq V$ for every component of $\phi$
    for every $x\in \calX$.
    \item There is a constant  $S \geq 1$   known to the users satisfying $\var_X\left[g(X,\bE_{Y \mid X}[\phi(X,Y)])\right]\leq S$.
    \item We have access to the code of the following two simulators (formal definition of `having the code' can be found in \cite{kothari2023mean}): 
\begin{enumerate}
    \item \(\mathcal{S}_1\) outputs samples from the marginal distribution of \(X\) without requiring any input.
    \item \(\mathcal{S}_2\) accepts an input \(x\) from \(\mathcal{X}\) and generates a sample of \(Y\) based on the conditional distribution \(\mathbb{P}(Y | X = x)\).
\end{enumerate}

\end{enumerate}

We briefly review the four assumptions. The first assumption is critical for achieving the $\tilde O(1/\epsilon)$ upper bound in Theorem \ref{thm:our}. This assumption holds in many practical problems of interest, particularly for functions like $g(x, y) := \max\{x, y\}$ or $x + y$.
 The second and third assumptions are technical conditions to ensure the variance and conditional second moment are well-behaved. For example, the second assumption is satisfied when $(X,Y)$ follows a regression model $Y = f(X) + \text{Noise}$ where noise has zero mean and variance no more than $V$, and $\phi(x,y)$ is taken as $y - f(x)$. The final assumption is common in the simulation literature.



We show:

\begin{theorem}\label{thm:our}
With assumptions $1-4$ stated above, let \((X, Y)\) be a pair of random variables from \(\mathcal{X} \times \mathcal{Y}\) with joint distribution \(\mathbb{P}\). 
We can design an algorithm \textsc{Q-NestExpect} (Algorithm \ref{alg:quantum_nested_expectation}) that estimates
\[
\mathbb{E}_X\left[g(X,\mathbb{E}_{Y \mid X}[\phi(X,Y)])\right]
\]
with an absolute error of no more than \(\epsilon\) and a success probability of 80\%. The  computational cost of this algorithm is \(\tilde\calO\left(\left(S + K V\right)/\epsilon\right)\). The $\tilde{O}$ notation hides a poly-logarithmic factor on $K, V$, and $\epsilon$. 
\end{theorem}
The next corollary is a direct application of the `median trick'.

\begin{corollary}\label{cor:(1-delta) probability}
    With all the notations as above, for any $\delta \in (0,0.2)$, we have a quantum algorithm that estimates
\[
\mathbb{E}_X\left[g(X,\mathbb{E}_{Y \mid X}[\phi(X,Y)])\right]
\]
with an absolute error of no more than \(\epsilon\) and a success probability of 80\%. The  computational cost of this algorithm is \(\tilde\calO\left(\log(1/\delta)\left(S + K V\right)/\epsilon\right)\). The $\tilde{O}$ notation hides a poly-logarithmic factor on $K, V$, and $\epsilon$. 
\end{corollary}


We highlight that the standard error metrics differ slightly between classical and quantum algorithms. Classical algorithms are usually evaluated based on their expected error or mean-squared error, whereas quantum algorithms typically ensure that the error is small with high probability. The former metric is slightly stronger than the latter; however, under mild additional conditions, the two error measures become equivalent. Appendix A of \cite{an2021quantum} has a detailed comparison between the two types of errors. Our error metric aligns with nearly all quantum algorithms, such as \cite{grover1996fast, brassard2002quantum, montanaro2015quantum, kothari2023mean, sidford2024quantum}.


\subsection{Roadmap}\label{subsec: motivation}


\textbf{Why the quadratic speedup is lost?}

A simple yet important observation is that quantum Monte Carlo methods offer a \textit{quadratic improvement in sample complexity} compared to classical Monte Carlo methods. However, this improvement does not automatically translate to a quadratic reduction in \textit{computational cost}. This distinction arises because the computational cost depends not only on the sample complexity but also on the cost of executing the underlying algorithm.

Suppose the goal is to estimate the expectation of a randomized algorithm $\mathcal{A}$, and the cost of a single execution of $\mathcal{A}$ is $C(\mathcal{A})$. The computational cost of classical Monte Carlo requires $\mathcal{O}(\sigma^2 / \epsilon^2)$ samples, where $\sigma^2$ represents the variance of $\mathcal{A}$, and $\epsilon$ denotes the desired error tolerance. Consequently, the total computational cost becomes $\mathcal{O}(C(\mathcal{A}) \sigma^2 / \epsilon^2)$. In contrast, the quantum Monte Carlo algorithm described in \cite{kothari2023mean} (Theorem \ref{thm:quantum-mean}) reduces the sample requirement to $\mathcal{O}(\sigma / \epsilon)$. This results in a computational cost of $\tilde{\mathcal{O}}(C(\mathcal{A}) \sigma / \epsilon)$.
This implies that quantum Monte Carlo achieves a nearly quadratic speedup in computational cost compared to classical Monte Carlo \textit{only if the cost of running the algorithm $\mathcal{A}$ is nearly constant}, i.e., $C(\mathcal{A}) = \tilde{\mathcal{O}}(1)$. 

Now, consider the MLMC framework. Instead of using a single randomized algorithm $\mathcal{A}$, it uses a sequence of algorithms $\mathcal{A}_l$ corresponding to levels $l = 0, 1, \dots, L$. The computational cost $C(\mathcal{A}_l)$ generally grows exponentially with increasing $l$. For example, $C(\calA_l) \sim 2^l$ in the MLMC solution for nested expectation problems (Algorithm \ref{alg:nested-classicalMLMC-Al}). The highest level $L$ is chosen as $\Theta(\log(1/\epsilon))$, therefore the cost at the highest level $C(\calA_L) = \mathcal{O}(\mathrm{poly}(1/\epsilon))$.


The main idea from the work of \cite{an2021quantum} is to replace each classical Monte Carlo estimator for $\mathbb{E}[\Delta_l]$ with its quantum counterpart. While this substitution works in principle, there is a critical issue as the level $l$ approaches the maximum level $L$: the computational cost $C_l$ can grow significantly, sometimes as high as $\mathcal{O}(\mathrm{poly}(1/\epsilon))$. This growth undermines the quadratic speedup achieved by QMC because the total cost is no longer dominated by $\tilde{\mathcal{O}}(1)$-cost subroutines. Instead, the increasing $C_l$ makes the computational cost scale poorly with the desired error tolerance $\epsilon$, leading to a loss of efficiency. Although the algorithm in \cite{an2021quantum} leverages quantum Monte Carlo to estimate $\mathbb{E}[\mathcal{A}_l]$, the achieved speedup is less than quadratic because $C(\mathcal{A}_l)$ scales as $\mathcal{O}(\text{poly}(1/\epsilon))$ instead of $\mathcal{O}(1)$ at the highest levels. This growth in cost undermines the expected quadratic speedup.

\textbf{How to recover the quadratic speedup?} 

We can break down Theorem \ref{thm:MLMC} to capture its core insights, then leverage them to refine our quantum algorithm. Theorem \ref{thm:MLMC} provides two main ideas: 
\begin{enumerate}
    \item The target quantity is written as a limit of quantities with vanishing bias, and then re-expressed as a telescoping sum, \(\text{Target} = \lim_{l\rightarrow \infty} s_l = \sum_{l=0}^\infty (s_{l+1} - s_l) + s_0\). The MLMC method estimates each level individually, optimizing resource allocation.
    \item Estimator Variance Control: At each level \( k \), an estimator \( \Delta_k \) is designed with bias and  variance diminishing with $k$, while cost increasing with $k$. 
\end{enumerate}

In the classical solution (Algorithm \ref{alg:nested-classicalMLMC-Al}), the sequence $s_l$ is 
\[
s_{l,\text{classical}} := \bE[g(X,2^{-l}\sum_{i=1}^{2^l}\phi(X,Y_i))].
\]
By the law of large numbers, it is clear that \( s_{l,\text{classical}} \) converges to the target. Algorithm \ref{alg:nested-classicalMLMC-Al} employs standard Monte Carlo to estimate \(s_{l,\text{classical}} - s_{l-1,\text{classical}}\).


A key observation is that we have designed a new sequence of quantum subroutines $\tilde{\mathcal{A}}_l$. They have similar statistical properties as the classical $\calA_l$ (in the sense of the $\alpha$ and $\beta$ parameters from Theorem \ref{thm:MLMC}), while achieving improved computational efficiency (improved $\gamma$ in Theorem \ref{thm:MLMC}). We define a new sequence  $s_{l,\text{quantum}}$ that also convergences to  the target value. This sequence uses quantum Monte Carlo to estimate the conditional expectation, with progressively higher precision as the sequence advances. Based on this new sequence, the new quantum subroutines $\tilde{\mathcal{A}}_l$ can be naturally defined to estimate $s_{l,\text{quantum}} - s_{l-1,\text{quantum}}$. Finally, we can use existing quantum Monte Carlo algorithms to estimate expectations of $\tilde{\mathcal{A}}_l$ at each level $l$. Together, these components achieve a quadratic speedup over classical MLMC, making this approach provably more efficient than a direct application of QA-MLMC.




Three additional points merit attention. First, it's important for readers to recognize that the original QA-MLMC algorithm applies to a wider range of scenarios than our current approach. Thus, our contribution should be seen as an improvement of QA-MLMC within a special yet critical set of problems. Second, while the study by \cite{an2021quantum} relies on the quantum algorithm from \cite{montanaro2015quantum} as its core quantum subroutine, our method leverages the more recent quantum Monte Carlo algorithm in \cite{kothari2023mean}. This newer algorithm not only eliminates the additional polylogarithmic factors in the error term found in \cite{montanaro2015quantum} but also requires less prerequisite knowledge from users. Finally, the computational model employed here (or `the code' in the language of \cite{kothari2023mean}), including the encoding and simulation of probabilities, is the same as the model in existing quantum Monte Carlo studies, such as \cite{kothari2023mean, montanaro2015quantum, hamoudi2021quantum}. Therefore we will not formally describe it in full details.



\subsection{Our algorithm}\label{subsec:q-nestexpect}
To introduce our algorithm, we first define a sequence of auxiliary algorithms $\calC_l$.  For any
$l\geq 0$, our auxiliary algorithm, $\calC_l$, works as follows:
\begin{algorithm}[htbp]
\caption{$\mathcal C_l$ ($l\geq 1)$}
\label{alg:Cl}
\begin{algorithmic}[1]
     \STATE \textbf{Input:} $x$ from $\calX$
    \STATE Apply quantum Monte Carlo \citep{kothari2023mean} to estimate 
    \[
    \bE_{Y\mid X=x}[\phi(X,Y)]
    \]
    with accuracy $2^{-(l+1)}/K$ and success probability at least $1-2^{-(2l+1)} (4K^2V)^{-1}$.
    \STATE Clip every component of the output into the region $\left[-\sqrt{V}, \sqrt{V}\right]$, denote the clipped output by $\hat{\phi_l}(x)$ 
    \STATE \textbf{Output:} $g(x, \hat{\phi_l}(x))$.  
\end{algorithmic}
\end{algorithm}

Algorithm $\calC_l$ with input $x$ estimates the quantity $g\left(x, \bE_{Y\mid X=x}[\phi(X,Y)]\right)$. Raising the value of $l$ will improve the accuracy but also elevate the computational cost. The typical way we obtain input \(x\) for Algorithm \(\calC_l\) is by generating it from \(\calS_1\). We refer to this combined process as \(\calC_l \circ \calS_1\).The sequence \(\{\calC_l \circ \calS_1\}_{l \geq 0}\) produces random variables whose expectations progressively approximate the target quantity \(\mathbb{E}_X\left[g(X,\mathbb{E}_{Y \mid X}[\phi(X,Y)])\right]\) as \(l\) increases. The properties of  $\calC_l$ and $\calC_l\circ \calS_1$ are studied in Lemma \ref{lemma:Cl properties}.

Now we define \(\calA_l\) based on \(\calC_l\). When \(l = 0\), \(\calA_0 := \calC_0\). When \(l \geq 1\), we define $\calA_l$ in Algorithm \ref{alg:Al}.

\medskip

\begin{algorithm}[H]
\caption{$\mathcal \calA_l$ ($l\geq 1)$}
\label{alg:Al}
\begin{algorithmic}[1]
    \STATE \textbf{Input:} $x$ from $\calX$.
    \STATE Apply $\calC_l$ with input $x$ to obtain  $g(x, \hat{\phi_l}(x))$. 
    \STATE Apply $\calC_{l-1}$ with the same $x$  to obtain  $g(x, \hat{\phi}_{l-1}(x))$.
    \STATE \textbf{Output:} $g(x, \hat{\phi_l}(x)) - g(x, \hat{\phi}_{l-1}(x))$. 
\end{algorithmic}
\end{algorithm}

Algorithm $\calA_l$ is a `coupled' difference of $\calC_l$ and $\calC_{l-1}$. It executes $\calC_l$ and $\calC_{l-1}$ using the same input $x$. Compared to independently executing $\calC_l$ and $\calC_{l-1}$ and then taking their difference, this coupled implementation maintains the same expectation but ensures that the variance of $\calA_l$ decreases to zero as $l$ increases, which is beneficial for our objective. Similarly, we define $\calA_l \circ \calS_1$ when the input $x$ for $\calA_l$ is  from $\calS_1$. In particular, we  denote the output of $\calA_l \circ \calS_1$ by $\tilde \calA_l$. The properties of $\calA_l$ and $\tilde \calA_l$ are studied in Lemma \ref{lemma:Al properties}.


Now we are ready to describe our main algorithm.

\begin{algorithm}[H]
\caption{\textsc{Q-NestExpect}}
\label{alg:quantum_nested_expectation}
\begin{algorithmic}[1]
    \STATE \textbf{Input:} Accuracy level $\epsilon$.
    \STATE Set $L = \ceil{\log_2(2/\epsilon)}$
    \FOR{$l=0$ to $L$}
    \STATE Apply quantum Monte Carlo \citep{kothari2023mean} to estimate $\bE[\tilde\calA_l]$ with accuracy $\epsilon/(2L)$ and success probability at least $1-0.1^l$ . Denote the output by $\hat\calA_l$.
    \ENDFOR
    \STATE \textbf{Output:} $\sum_{l=1}^L \hat\calA_l$. 
\end{algorithmic}
\end{algorithm}

\textsc{Q-NestExpect}  is a quantum-inside-quantum algorithm as it uses quantum Monte Carlo to estimate the expectation of another quantum Monte Carlo algorithm.
 In each iteration of the for loop in \textsc{Q-NestExpect}, we use a distinct quantum Monte Carlo algorithm to individually estimate $\bE[\tilde\calA_1], \bE[\tilde\calA_2], \ldots, \bE[\tilde\calA_L]$ and then sum the results. 

To demonstrate that Algorithm \ref{alg:quantum_nested_expectation} satisfies the guarantees stated in Theorem \ref{thm:our}, we first prove a few lemmas studying the properties of $\calC_l$ and $\calA_l$. The crucial property we will use from \cite{kothari2023mean} is as follows:

\begin{theorem}[Theorem 1.1 in \cite{kothari2023mean}]\label{thm:quantum-mean}
    Given the code for a random variable with mean $\mu$ and variance $\sigma$, there is a quantum algorithm that uses $\tilde\calO(\sigma/\epsilon)$ samples and outputs an estimate of $\mu$. The estimate is $\epsilon$-close to $\mu$ with probability at least $2/3$. Moreover, one can boost the probability from $2/3$ to $1 - \delta$ for any $\delta < 1/3$ by repeating the same algorithm for $ \calO(\log(1/\delta))$ times and then taking the median. 
\end{theorem}

In the theorem statement of Theorem \ref{thm:quantum-mean}, ``uses $k$ samples'' means  it uses the code for the corresponding random variable at most $k$ times. The formal definition of `the code' is given in \cite{kothari2023mean}. In the problems we considered, we always have the code as assumed in Assumption 4.



Now we study the computational and statistical properties of $\calC_l$. The formal statements of the next two lemmas can be found in Appendix \ref{sec:proof}.

\begin{lemma}[Informal]\label{lemma:Cl properties}
    For every $l\geq 0$, with $\calC_l$ defined in Algorithm \ref{alg:Cl}, it has the following properties:
    \begin{enumerate}
        \item \textbf{Cost:} Implementing both $\calC_l$ and $\calC_l\circ \calS_1$ with input $x$ have cost $\tilde\calO(l2^l K \sqrt{V})$. The $\tilde{\mathcal{O}}$ notation absorbs polylogarithmic factors in $K$ and $V$, but not in $l$.
        \item \textbf{Mean-squared error:}
         Executing $\calC_l$ with input $x$ results in a mean-squared error (MSE) of $2^{-2l}$ when estimating $g(x,\bE_{Y\mid X=x}[\phi(X,Y)])$.
        \item \textbf{Bias:} The bias of $\calC_l\circ\calS_1$ is no larger than $2^{-l}$ when estimating $\mathbb{E}_X\left[g(X,\mathbb{E}_{Y | X}[\phi(X,Y)])\right]$.
\item \textbf{Variance:} The variance of $\calC_l\circ\calS_1$ is no larger than $2S+2$ for every $l$.
    \end{enumerate}
               
\end{lemma}



Similarly, we study the properties of $\calA_l$.
\begin{lemma}[Informal]\label{lemma:Al properties}
    For any $l\geq 1$, given that $\calA_l$ is defined in Algorithm \ref{alg:Al}, the following properties hold:
    \begin{enumerate}
         \item \textbf{Cost:} Implementing both $\calA_l$ and $\calA_l\circ \calS_1$ have cost $\tilde\calO(l2^l K \sqrt{V})$. The $\tilde{\mathcal{O}}$ notation absorbs polylogarithmic factors in $K$ and $V$, but not in $l$.
        \item \textbf{Variance:}
         The random variable $\hat \calA_l$ (output of $\calA_l \circ \calS_1$) has variance at most $10 \times 2^{-2l}$.
        \item \textbf{Bias:} 
        The bias of $\sum_{i=1}^l \hat \calA_i$ is no larger than $2^{-l}$ when estimating $\mathbb{E}_X\left[g(X,\mathbb{E}_{Y | X}[\phi(X,Y)])\right]$.
    \end{enumerate}
\end{lemma}


By applying Lemma \ref{lemma:Al properties} and ignoring lower-order terms, our new sequence \(\{\tilde\calA_l\}\) corresponds to \(\alpha = 1, \beta = 2, \gamma = 1+o(1)\) in the MLMC framework, whereas the standard classical sequence (Algorithm \ref{alg:nested-classicalMLMC-Al}) has \(\alpha = 0.5, \beta = 1, \gamma = 1\). This improvement arises from our new quantum subroutine. It eventually enables us to prove our main Theorem \ref{thm:our}, showing a total cost of \(\tilde\calO(1/\epsilon)\) by applying quantum Monte Carlo to estimate each \(\bE[\tilde\calA_l]\). The full proof of Theorem \ref{thm:our} is provided in Appendix \ref{sec:proof}.


\textbf{Optimality of our algorithm:} Our algorithm achieves the optimal dependence on \(\epsilon\), up to polylogarithmic factors. In particular, when \( g(x, z) := z \) (which is 1-Lipschitz), the nested expectation in \eqref{eqn:nested expectation} simplifies to \( \bE[\phi] \). Thus our problem includes standard Monte Carlo as a special case. Moreover, from known lower bounds on the quantum complexity of mean approximation \cite{nayak1999quantum}, estimating a random variable with mean \(\mu\) and standard deviation \(\sigma\) requires at least \(\Omega(\sigma/\epsilon)\) cost. Our algorithm matches this dependence while extending to a broader class of problems. 


\section{Applications}
We now revisit the examples from Section \ref{subsec: nested expectation} and analyze the computational cost of applying our algorithm.

\textbf{Bayesian experiment design:} Recall our target is
\begin{align*}
          \bE_X\left[\log(\bE_{Y}[\bP(X\mid Y)])\right] - \bE_Y\left[\bE_{X \mid Y}[\log(\bP(X\mid Y)]\right].
\end{align*}

The first term corresponds to \eqref{eqn:nested expectation} with \(\phi(x,y) := \bP(X=x\mid Y = y)\) and \(g(x,z) := \log(z)\). If \(\bP(X\mid Y) \geq c\), which often holds when \(X\) is discrete or when \((X,Y)\) is supported on a compact set, then \(g(x,z)\) is \((1/c)\)-Lipschitz over its domain. Therefore \textsc{Q-NestExpect} can estimate the first term with cost $\tilde\calO(1/\epsilon)$. The second term is a standard expectation $\bE[\log(\bP(Y\mid X)]$. Assuming finite variance, we can apply \citet{kothari2023mean} to estimate it with cost \(\mathcal{O}(1/\epsilon)\). Combining this with \textsc{Q-NestExpect} allows us to compute the target with a total cost of \(\tilde{\mathcal{O}}(1/\epsilon)\).

\textbf{EVPPI:} In the EVPPI example, our target quantity is
\begin{align*}
       \bE_X\left[\max_{k\in \{1,\ldots,d\}}\bE_{Y\mid X}[f_k(X,Y)]\right] - \max_{k\in \{1,\ldots,d\}} \bE[f_k(X,Y)].
       \end{align*}
The first term corresponds to $g(x,y) = \max(y_1, \cdots, y_d)$, which is $1$-Lipschitz. Therefore \textsc{Q-NestExpect} can estimate the first term with cost $\tilde\calO(1/\epsilon)$. The second term can be estimated with cost $\calO(1/\epsilon)$ using \cite{kothari2023mean}. Similarly, we obtain a \(\tilde{\mathcal{O}}(1/\epsilon)\) algorithm for estimating EVPPI. However, we emphasize that our $\tilde\calO$ absorbs the parameter $d$ in this problem. A direct application of our algorithm along with \cite{kothari2023mean} leads to a linear dependence on \(d\). An interesting  question is whether an improved or optimal dependence on \(d\) can be achieved.

\textbf{CoC option pricing:} We have \( g(x,z) = g(z) \max\{z - k, 0\} \) with \( \phi = g \). Since $g$ is 1-Lipschitz, we can estimate the quantity with a cost of \(\tilde{\mathcal{O}}(1/\epsilon)\) using \textsc{Q-NestExpect}.
% In the unusual situation where you want a paper to appear in the
% references without citing it in the main text, use \nocite
\section{Future directions}
Quantum computing offers MLMC greater flexibility in designing new approximation sequences. In favorable scenarios, such as ours, a carefully crafted sequence can lead to a significantly improved (and potentially optimal) algorithm. This raises an intriguing question: which other MLMC applications could achieve a similar quantum quadratic speedup?

We expect that our technique can be extended to closely related problems. For instance, with additional assumptions, classical MLMC also has \(\tilde{\mathcal{O}}(1/\epsilon^2)\) cost when \( g(x,z) = g(z) = \mathbf{1}_{z\geq 0} \) is a Heaviside function \cite{giles2019multilevel,gordy2010nested}. This quantity plays a key role in computing Value-at-Risk (VaR) and Conditional Value-at-Risk (CVaR), which are widely used in finance.  Similarly, MLMC has been shown to be effective in  conditional stochastic optimization, bilevel optimization problems \cite{hu2020biased,hu2021bias, hu2024contextual}, which is an extension of our setting with additional optimization steps. We expect our approach can be adapted to address these problems.

Our primary focus is the dependence on \(\epsilon\), which is also central to both classical \cite{giles2015multilevel} and quantum MLMC \cite{an2021quantum} literature. However, our problem also involves other parameters, such as dimensionality, the Lipschitz constant, and variance. Quantum algorithms, in particular, show a more subtle dependence on  the underlying dimension \cite{cornelissen2022near}. An interesting open question is whether our current algorithm is optimal with respect to these parameters or if improvements are possible.
\section*{Acknowledgement} Jose Blanchet, Mario Szegedy, and Guanyang Wang  gratefully acknowledge support by the National Science Foundation through grant CCF-2403007.
\newpage

\bibliographystyle{chicago}
\setstretch{1.5}
\bibliography{ref}


%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% APPENDIX
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\newpage
\appendix
\onecolumn
\onehalfspacing
\section{Technical Proofs}\label{sec:proof}
\begin{lemma*}[Formal Statement of Lemma \ref{lemma:Cl properties}]
    With $\calC_l$ defined in Algorithm \ref{alg:Cl}, it has the following properties:
    \begin{enumerate}

    
            \item  Implementing $\calC_l$ with input $x$ has cost $\tilde\calO(l2^l K \sqrt{V})$. The $\tilde{O}$ notation hides a poly-logarithmic factor on $K, V$, but not on $l$.
            \item Implementing $\calC_l\circ \calS_1$ has cost $\tilde\calO(l2^l K \sqrt{V})$. The $\tilde{O}$ notation hides a poly-logarithmic factor on $K, V$, but not on $l$.
        \item  Executing $\calC_l$ with input $x$ results in a mean-squared error (MSE) of $2^{-2l}$ when estimating $g(x,\bE_{Y\mid X=x}[\phi(X,Y)])$, i.e.: 
           $$ \bE_{\calC_l(x)}\left[\left\lvert g(x,\hat{\phi_l}(x))  -  g(x,\bE_{Y\mid X=x}[\phi(X,Y)])\right\rvert^2\right] \leq  2^{-2l}.$$
        \item The bias of $\calC_l\circ\calS_1$ is no larger than $2^{-l}$ when estimating $\mathbb{E}_X\left[g(X,\mathbb{E}_{Y | X}[\phi(X,Y)])\right]$, i.e.:
        \begin{align*}
 \left\lvert \bE_{\calC_l\circ\calS_1}\left[g(x,\hat{\phi_l}(x))\right] - \mathbb{E}_X\left[g(X,\mathbb{E}_{Y | X}[\phi(X,Y)])\right] \right\rvert\leq 2^{-l}.
\end{align*}
\item The variance of $\calC_l\circ\calS_1$ is no larger than $2S+1$ for every $l$.
    \end{enumerate}
               
\end{lemma*}


\begin{proof}[Proof of Lemma \ref{lemma:Cl properties}] 
We prove the three properties separately. 


\noindent{\bf Cost of $\calC_l$.} Given input $x$, implementing Step 2-3 of $\calC_l$ incurs a computational cost of $\tilde\calO(l2^l K \sqrt{V})$. To see this,
note that  it would be sufficient to take $\calO(K\sqrt {V} 2^l)$ samples to have success probability $0.8$ using \citep{kothari2023mean}. When we increase the probability of success to
$1-2^{-(2l+1)} (4K^2V)^{-1}$, we need to multiply this with a factor of 
$\calO\left(\log \left(2^{2l+1}4K^2V\right)\right) = \calO(l) + \calO(\log K) + \calO(\log(V)$. Thus the total cost is $\tilde\calO(l2^l K \sqrt{V})$, where the constant in $\tilde\calO$ does not depend on $x$. Therefore, the cost of $\calC_l\circ \calS_1$ is also upper bounded by $\tilde\calO(l2^l K \sqrt{V})$.


\paragraph{MSE:} Let $\tilde \phi_l(x)$ be the output of Step 2 in $\calC_l$, i.e., output of quantum Monte Carlo algorithm in \cite{kothari2023mean} before clipping. We claim $$\lVert\tilde{\phi}_l(x) - \bE_{Y\mid X=x}[\phi(X,Y)]\rVert\geq \lVert\hat{\phi}_l(x) - \bE_{Y\mid X=x}[\phi(X,Y)]\rVert,$$ i.e., clipping will never increase the error. To see this, notice that $$\bE_{Y\mid X=x}[\phi_i(X,Y)]\leq \sqrt{V}$$ because $\bE[Z]^2 \leq \bE[Z^2]$ for any random variable $Z$. Therefore, we know as a-priori that every component of the target quantity of step 2 is between $-V$ and $V$. Suppose $\tilde \phi_{l,i}(x)$ is between $[-V, V]$, then $\tilde \phi_{l,i}(x) = \hat{\phi}_{l,i}(x) $, i.e. no clipping happens. Suppose $\tilde \phi_{l,i}(x) > V$, then 
\begin{align*}
    \lvert\tilde{\phi}_{l,i}(x) - \bE_{Y\mid X=x}[\phi_i(X,Y)]\rvert &= \tilde{\phi}_{l,i}(x) - \bE_{Y\mid X=x}[\phi_i(X,Y)] \geq \hat{\phi}_{l,i}(x) - \bE_{Y\mid X=x}[\phi_i(X,Y)]\\ 
    &= \lvert \hat{\phi}_l(x) - \bE_{Y\mid X=x}[\phi(X,Y)]  \rvert.
\end{align*}
Similar argument holds when $\tilde \phi_l(x) < -V$. Thus, the squared error of each component \(i\) either decreases or remains unchanged after clipping. Summing the squared errors over all components establishes the claim.


Since $\tilde \phi_l(x)$ has accuracy $2^{-(l+1)}/K$ with probability at least $1-2^{-(2l+1)} (4K^2V)^{-1}$, we know $\hat \phi_l(x)$ also has accuracy $2^{-(l+1)}/K$ with probability at least $1-2^{-(2l+1)} (4K^2V)^{-1}$. Moreover, the absolute error between $\hat \phi_l(x)$ and $\bE_{Y\mid X=x}[\phi(X,Y)]$ is at most $2\sqrt{V}$. Thus, the expected squared error between $\hat \phi_l(x)$ and $\bE_{Y\mid X=x}[\phi(X,Y)]$  can be upper bounded by 
\begin{align*}
  \bE_{\calC_l(x)}\left[\left\lVert \hat{\phi_l}(x)  -  \bE_{Y\mid X=x}[\phi(X,Y)]\right\rVert^2\right] &\leq  K^{-2} 2^{-2(l+1)} \times 1 + 4 V \times 2^{-(2l+1)}(4K^2V)^{-1} \\
  &\leq K^{-2} 2^{-2l}.
\end{align*}


For each fixed $x$, the  absolute error between $g(x, \hat{\phi_l}(x))$ and $g(x, \bE_{Y \mid x}[\phi(x,Y)])$ is not greater than
\[
 K\lVert \hat{\phi_l}(x)  -  \bE_{Y\mid X=x}[\phi(X,Y)]\rVert
\]
due to the Lipschitzness of $g$. Therefore, we have the following estimate on the mean-squared error of $\calC_l$ with input $x$:
\begin{align}\label{eqn:cond-mse}
  \bE_{\calC_l(x)}\left[\left\lvert g(x,\hat{\phi_l}(x))  -  g(x,\bE_{Y\mid X=x}[\phi(X,Y)])\right\rvert^2\right] \leq  2^{-2l}.
\end{align}

Moreover, if $x$ is sampled from $\calS_1$, the expected squared distance satisfy
\begin{align}\label{eqn:mse}
  \bE_{x\sim\calS_1,\calC(x)}\left[\left\lvert g(x,\hat{\phi_l}(x))  -  g(x,\bE_{Y\mid X=x}[\phi(X,Y)])\right\rvert^2\right] \leq  2^{-2l}.
\end{align}



\paragraph{Bias:}
We can also estimate the bias of $\calC_l\circ S_1$, which is:
\begin{align}\label{eqn:bias}
 \left\lvert \bE_{\calC_l\circ S_1}\left[g(x,\hat{\phi_l}(x))\right] - \mathbb{E}_X\left[g(X,\mathbb{E}_{Y | X}[\phi(X,Y)])\right] \right\rvert.
\end{align}

Again, conditioning on $\calS_1$ outputs $x$, we know the conditional bias 
\begin{align*}
& \left\lvert \bE_{\calC_l(x)}\left[g(x,\hat{\phi_l}(x))\right] - g(x,\mathbb{E}_{Y | X = x}[\phi(X,Y)]) \right\rvert \\
 &\leq \bE_{\calC_l(x)}\left[ \left\lvert g(x,\hat{\phi_l}(x)) - g(x,\mathbb{E}_{Y | X = x}[\phi(X,Y)])\right\rvert\right]\\
 &\leq \left(\bE_{\calC_l(x)}\left[\left\lvert g(x,\hat{\phi_l}(x))  -  g(x,\bE_{Y\mid X=x}[\phi(X,Y)])\right\rvert^2\right]\right)^{0.5}\\
 &\leq 2^{-l}.
\end{align*}
Here the first two inequalities follows from $\lvert\bE[X] - a \rvert \leq \bE[\lvert X - a \rvert]\leq \sqrt{\bE[\lvert X - a \rvert^2]}$, and the last inequality follows from \eqref{eqn:mse}. Now we can bound the bias of $\calC_l\circ\calS_1$ as:
\begin{align*}
 &\left\lvert \bE_{\calC_l\circ\calS_1}\left[g(x,\hat{\phi_l}(x))\right] - \mathbb{E}_X\left[g(X,\mathbb{E}_{Y | X}[\phi(X,Y)])\right] \right\rvert \\
 &= \left\lvert  
 \bE_{x\sim \calS_1}\left[\bE_{\calC_l(x)}\left[g(x,\hat{\phi_l}(x))\right]\right] - \bE_{x\sim \calS_1}[g(x,\mathbb{E}_{Y | X = x}[\phi(X,Y)])]
 \right\rvert \\
 &\leq \bE_{x\sim \calS_1}\left[\left\lvert 
 \bE_{\calC_l(x)}\left[g(x,\hat{\phi_l}(x))\right] - g(x,\mathbb{E}_{Y | X = x}[\phi(X,Y)]) 
 \right\rvert\right]\\
 &\leq 2^{-l}.
\end{align*}

\paragraph{Variance:} To simplify the notation, define \( G(x) \) as \( g(x, \mathbb{E}_{Y \mid X = x}[\phi(X,Y)]) \). Then Assumption $3$ reads $\var_X[G(X)] \leq S$. We bound the variance of $\calC_l \circ \calS_1$ as:
\begin{align*}
    \var_{\calC_l\circ\calS_1}\left[g(x,\hat{\phi_l}(x))\right] &\leq \bE_{\calC_l\circ\calS_1}\left[\left(g(x,\hat{\phi_l}(x)) - \bE_X[G(X)]\right)^2\right] \\
    &\leq 2\bE_{\calC_l\circ\calS_1}\left[\left(g(x,\hat{\phi_l}(x)) - G(x)\right)^2\right] + 2\bE_{x\sim\calS_1}[(G(x) - \bE_X[G(X)])^2] \\
    &\leq 2 \cdot 2^{-2l}  + 2S \leq 2S + 2,
\end{align*}
where the first inequality uses the fact $\var[X] = \min_a \bE[(X-a)^2]$, the third inequality uses \eqref{eqn:mse}.

\end{proof}


\begin{lemma*}[Formal statement of Lemma \ref{lemma:Al properties}]
    Given that $\calA_l$ is defined in Algorithm \ref{alg:Al}, the following properties hold:
    \begin{enumerate}
    
            \item  Implementing $\calA_l$ with input $x$ has cost $\tilde\calO(l2^l K \sqrt{V})$. The $\tilde{O}$ notation hides a poly-logarithmic factor on $K, V$, but not on $l$.
            \item The cost of implementing $\calA_l\circ \calS_1$ is no more than $\calO(l2^l K \sqrt{V})$.
        \item
         The random variable $\hat\calA_l$ (output of $\calA_l \circ \calS_1$) has variance at most $10 \times 2^{-2l}$.
        \item   
        
        The bias of $\sum_{i=1}^l \hat\calA_i$ is no larger than $2^{-l}$ when estimating $\mathbb{E}_X\left[g(X,\mathbb{E}_{Y | X}[\phi(X,Y)])\right]$, i.e.:
        \begin{align*}
 \left\lvert \sum_{i=1}^l \bE_{\calA_i\circ\calS_1}\left[\tilde \calA_i\right] - \mathbb{E}_X\left[g(X,\mathbb{E}_{Y | X}[\phi(X,Y)])\right] \right\rvert\leq 2^{-l}.
\end{align*}
\end{enumerate}
\end{lemma*}
\begin{proof}[Proof of Lemma \ref{lemma:Al properties}]
\noindent{\bf Cost of $\calA_l$.} Clearly implementing $\calA_l$ once costs around twice of the cost of $\calC_l$. 
Therefore the claims regarding the computational cost of $\calA_l$ and $\calA_l\circ\calS_1$ follows from Lemma \ref{lemma:Cl properties}.


\noindent{\bf Variance of $\hat\calA_l$.}   Moreover, we can bound the second moment of $\calA_l$ as follows:
\begin{align*}
    \bE[\tilde\calA_l^2] &= \bE_{x\sim\calS_1}\left[\bE_{\calA_l(x)}[\tilde\calA_l^2 | x]\right]\\
                   & = \bE_{x\sim\calS_1}\left[\bE_{\calA_l(x)}\left[\left(g(x, \hat{\phi_l}(x)) - g(x, \hat{\phi}_{l-1}(x))\right)^2|x\right]\right] \\
                   & \leq 2  \bE_{x\sim\calS_1}\left[\bE_{\calC_l(x)}\left[\left(g(x, \hat{\phi_l}(x)) - g(x, \bE_{Y \mid x}[\phi(x,Y)])\right)^2|x\right]\right]
                   \\
                   &~~+ 2\bE_{x\sim\calS_1}\left[\bE_{\calC_{l-1}(x)}\left[\left(g(x, \hat{\phi}_{l-1}(x)) -g(x, \bE_{Y \mid x}[\phi(x,Y)])\right)^2|x\right]\right]\\
                   & \leq 2 (2^{-2l} + 2^{-{2l-2}}) = 10 \times 2^{-2l}.
\end{align*}
Since the second moment is always no less than the variance. Our claim on $\var[\tilde\calA_l]$ is proven.


At the same time, we have 
\begin{align*}
    \left\lvert\sum_{l= 1}^L \bE[\calA_l] - \bE\left[g(X,\bE[\phi(X,Y)\mid X])\right]\right\rvert &= \left\lvert\sum_{l= 1}^L (\bE[\calC_l] - \bE[\calC_{l-1}]) - \bE\left[g(X,\bE[\phi(X,Y)\mid X])\right]\right\rvert \\
    & = \left\lvert \bE[\calC_L] - \bE\left[g(X,\bE[\phi(X,Y)\mid X])\right]\right\rvert \leq 2^{-L},
\end{align*}
for every $L$. 

\noindent{\bf Bias of $\sum_{i=1}^l\hat\calA_i$.} Since the expectation of $\calA_i$ is the difference in expectations between the outputs of $\calC_l \circ \calS_1$ and $\calC_{l-1} \circ \calS_1$ (by definition), we know the expectation of $\sum_{i=1}^l\tilde\calA_i$ equals the output of $\calC_l$'s expectation. Therefore our claim follows directly from Lemma \ref{lemma:Cl properties}.
\end{proof}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\begin{proof}[Proof of Theorem \ref{thm:our}]
We claim  \textsc{Q-NestExpect} (Algorithm \ref{alg:quantum_nested_expectation}) outputs an estimator that is $\epsilon$-close to $\bE\left[g(X,\bE[\phi(X,Y)\mid X])\right]$ with probability at least $0.8$. 

For each $l$, our failure probability is no larger than $0.1^l$. Therefore the probability of at least one failure in the for-loop of Algorithm \ref{alg:quantum_nested_expectation} is at most $0.1 + 0.1^2 + ... \leq 0.2$ by union bound. Thus there is a probability at least $1 - (0.1 + 0.1^2 + ... ) \geq 0.8$ such that $\hat\calA_l$ is $\epsilon/(2L)$-close to $\bE[\tilde\calA_l]$ for every $l$. Under this (good) event,
our final estimator has error
\begin{align*}
   \left\lvert \sum_{l=0}^L \hat\calA_l  - \sum_{l=0}^L\bE[\tilde\calA_l]\right\rvert \leq \sum_{l=0}^L  \left\lvert \hat\calA_l - \bE[\tilde\calA_l]\right \rvert \leq L\frac{\epsilon}{2L} = \frac{\epsilon}{2}.
\end{align*}
In other words, $\sum_{l=0}^L \hat\calA_l$ is $\epsilon/2$-close to $\sum_{l=0}^L\bE[\tilde\calA_l]$. At the same time, Lemma \ref{lemma:Al properties} shows $\sum_{l=1}^L\bE[\tilde\calA_l]$  is $2^{-L}$-close to $\bE\left[g(X,\bE[\phi(X,Y)\mid X])\right]$. Using $L = \ceil{\log_2(2/\epsilon)}$, we conclude our estimator has error
\begin{align*}
    &\left\lvert \sum_{l=0}^L \hat\calA_l  - \bE\left[g(X,\bE[\phi(X,Y)\mid X])\right]\right\rvert
    \leq \left\lvert \sum_{l=0}^L \hat\calA_l  - \sum_{l=0}^L\bE[\tilde\calA_l]\right\rvert \\
    &\qquad\qquad+ \left\lvert  \sum_{l=0}^L\bE[\tilde\calA_l] - \bE\left[g(X,\bE[\phi(X,Y)\mid X])\right]\right\rvert \leq \epsilon,
\end{align*}
with probability at least $0.8$.


The cost of our algorithm is the summation of $L$ different quantum Monte Carlo algorithms. 

For \( l = 0 \), since \( \calA_l = \calC_l \), it is known in Lemma \ref{lemma:Cl properties} that $\tilde\calA_0$ has variance at most $2S+1$, Theorem \ref{thm:quantum-mean} shows the cost of estimating \( \mathbb{E}[\tilde{A}_l] \) is \( \mathcal{O}(SL/\epsilon)\). Fix any $l\in \{1,\ldots, L\}$, the quantum Monte Carlo for estimating $\bE[\tilde\calA_l]$ has a cost of $ \calO(2L/\epsilon \times 2^{-l} \log(10^l))$ times the cost of implementing $\calA_l$, which is:
\begin{align*}
   \calO(2L/\epsilon \times 2^{-l} \log(10^l))&\times  \tilde\calO(l2^l K \sqrt{V}) \\
   &= \tilde\calO(2L/\epsilon \times l^2 K \sqrt{V})
\end{align*}

Summing up all the $L$ costs together yields a total cost of
\begin{align*}
    \tilde\calO(S/\epsilon + (2L^4/\epsilon) K \sqrt{V}) = \tilde\calO\left(\left(S + K \sqrt{V}\right)/\epsilon\right).
\end{align*}
\end{proof}
\section{Verifying the classical MLMC parameters}\label{sec: verify mlmc}
Under Assumptions 1-4 in Section \ref{sec:main theorem}, we verify the classical MLMC sequence Algorithm \ref{alg:nested-classicalMLMC-Al} corresponds to $\alpha = 0.5, \beta= \gamma = 1$.
Firstly, the computational cost of $\calA_l$ is clearly $\calO(2^l)$, thus $\gamma = 1$. To analyze the variance, it is useful to observe

\begin{align*}
   \left \lvert g\left(X, \frac{1}{2^l}(S_\text{e} + S_{\text{o}})\right) - \frac{g\left(X, \frac{1}{2^{l-1}}S_{\text{e}}\right) + g\left(X, \frac{1}{2^{l-1}}S_{\text{o}}\right)}{2}\right\rvert \leq \frac{K}{2^{l-1}} \lVert S_e - S_o\rVert 
\end{align*}
because the Lipschitz continuity. Let $Z_i = Y_{2i-1} - Y_{2i}$,  it is then clear that every $Z_i$ has zero mean and are conditionally independent given $X$. Further
\[
\var[Z_{i,j} \mid X] = \var[Y_{2i-1,j}\mid X] + \var[Y_{2i,j}\mid X] = 2 \var[Y_j\mid X]\leq 2V.
\]
Therefore
\begin{align*}
    \bE[\lVert S_e - S_o\rVert ^2] = \sum_{j=1}^m\var[S_{e,j} -S_{o,j}] = \sum_{j=1}^m\var[\sum_{i=1}^{2^{l-1}}Z_{i,j}] \leq 2^{l} mV.
\end{align*}

Thus
\begin{align*}
    \bE\left[\left \lvert g\left(X, \frac{1}{2^l}(S_\text{e} + S_{\text{o}})\right) - \frac{g\left(X, \frac{1}{2^{l-1}}S_{\text{e}}\right) + g\left(X, \frac{1}{2^{l-1}}S_{\text{o}}\right)}{2}\right\rvert^2\right]&\leq 
    \frac{K^2}{2^{2l-21}} \bE[\lVert S_e - S_o\rVert^2 ]\\
    &\leq \frac{K^2}{2^{2l-1}} 2^l mV  \\
    &= \frac{2K^2mV}{2^l}\\ 
    & = \calO(2^{-l}).
\end{align*}
Therefore $\beta = 1$, as claimed. 

Finally we study the bias, which is 
\begin{align*}
   \left\lvert \sum_{k=0}^l \bE[\Delta_k] - \mathbb{E}_X\left[g(X,\mathbb{E}_{Y \mid X}[\phi(X,Y)])\right]\right\rvert.
\end{align*}
It is clear from the algorithm design that 

$$\sum_{k=0}^l \bE[\Delta_k] = \bE_{X,Y}\left[g\left(X, \frac{1}{2^l}(S_\text{e} + S_{\text{o}})\right)\right].$$

Therefore 
\begin{align*}
   \left\lvert \sum_{k=0}^l \bE[\Delta_k] - \mathbb{E}_{X,Y}\left[g(X,\mathbb{E}_{Y \mid X}[\phi(X,Y)])\right]\right\rvert &\leq  \bE_{X,Y}\left[\left\lvert g\left(X, \frac{1}{2^l}(S_\text{e} + S_{\text{o}})\right) - g(X,\mathbb{E}_{Y \mid X}[\phi(X,Y)])\right\rvert\right]\\
   &\leq K\bE_X\left[ \bE_{Y\mid X}\left[\left\lVert \frac{1}{2^l}(S_\text{e} + S_{\text{o}})- \mathbb{E}_{Y \mid X}[\phi(X,Y)]\right\rVert\right]\right].
\end{align*}
We can bound the inside term by 
\begin{align*}
    \bE_{Y\mid X}\left[\left\lVert \frac{1}{2^l}(S_\text{e} + S_{\text{o}})- \mathbb{E}_{Y \mid X}[\phi(X,Y)]\right\rVert\right] &\leq \left(\var\left[\left\lVert \frac{1}{2^l}(S_\text{e} + S_{\text{o}})- \mathbb{E}_{Y \mid X}[\phi(X,Y)]\right\rVert\right]\right)^{0.5}\\
    &\leq \frac{V^{0.5}m^{0.5}}{2^{0.5l}}.
\end{align*}
Therefore, the bias is controlled by
\begin{align*}
    \left\lvert \sum_{k=0}^l \bE[\Delta_k] - \mathbb{E}_{X,Y}\left[g(X,\mathbb{E}_{Y \mid X}[\phi(X,Y)])\right]\right\rvert \leq \frac{KV^{0.5}m^{0.5}}{2^{0.5l}} = \calO(2^{-0.5l}).
\end{align*}
Thus we have $\alpha = 0.5$, as claimed.


\end{document}


