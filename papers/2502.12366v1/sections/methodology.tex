\section{Methodology}
In this section, we first describe the programmatic weak supervision (PWS) setup and then discuss approaches that we generate labeling functions by proposing different types of prompts to direct LLMs like Codex in ScriptoriumWS.

\subsection{Programmatic Weak Supervision Setup}
Let $\mathcal{X}, \mathcal{Y}$ be the instance and label spaces,  respectively. 
For each of the $n$ unlabeled examples, $x_i \in \mathcal{X}$,  we observe noisy labels $\lambda_{1,i}, \ldots, \lambda_{m,i}$. 
These are the outputs of $m$ \emph{labeling functions} (LFs) $s_a$, where $s_a : \mathcal{X} \rightarrow \mathcal{Y}$ and $\lambda_{a,i} = s_a(x_i)$. 
These LF outputs are fed to  a two-step process to construct pseudo labels. 
Firstly, we learn a \emph{noise model} (also called a label model) that determines how accurate the sources are. That is, we must learn $\mathbf{\theta}$ for $P_{\mathbf{\theta}}(\lambda_{1}, \lambda_{2}, \ldots, \lambda_m, y)$. 
Note that the model involves true labels $y$ that are not observed for any of the samples and this makes the estimation process challenging. 
Then, pseudo labels for each $x_i$ are inferred using the learned noise model. In other words, we compute $\tilde{y} = \argmax_{y\in\mathcal{Y}} P_{\hat{\mathbf{\theta}}}(\tilde{y}|\lambda_{1}, \lambda_{2}, \ldots, \lambda_m)$. 
% 
Finally, an end model can be trained using the generated training dataset: $D=\{(x_i, \tilde{y}_i)\}_{i=1}^n \subseteq \mathcal{X} \times \mathcal{Y}$. 

A variety of label models are used for the estimation and inference sets.
%
In this work, we focus on LF generation and use standard label models such as \cite{ratner2019training} and \cite{fu2020fast}. 


% \begin{equation}
% P_{\mathbf{\theta}}(\lambda_1, \ldots, \lambda_m|Y=y) = \frac{1}{Z} \exp\left(-\sum_{a=1}^m \theta_a d^2_\mathcal{Y}(\lambda_a,y) { - \sum_{(a,b) \in E} \theta_{a,b} d^2_{\mathcal{Y}}(\lambda_a, \lambda_b)}\right). 
% \label{eq:lbl-model-orig-a}
% \end{equation}

% Here $d_{\mathcal{Y}}$ is a distance function on the label space $\mathcal{Y}$, $Z$ is the normalizing partition function, $\mathbf{\theta} = [\theta_1, \ldots, \theta_m]^T > 0$ are the \emph{canonical} parameters, and $E$ is a set of correlations. Intuitively, if $\theta_a$ is large, the typical distance from $d_a$ to $y$ is small and the LF is reliable; if $\theta_a$ is small, the LF is unreliable. There are several reasons why this model is suitable. Firstly, it belongs to the exponential family and has desirable theoretical characteristics. Additionally, it encompasses well-known forms of noise, such as zero-mean multivariate Gaussian noise for regression and a similar version of the Ising model for binary label cases. 

%Several techniques have been proposed to estimate $\hat{\mathbf{\theta}}$ in order to construct pseudo labels. One way to get such pseudo labels is to compute
%$\tilde{y} = \argmin_{z \in \mathcal{Y}} 1/m \sum_{a=1}^m \hat{\theta}_a d^2_{\mathcal{Y}}(z, \lambda_{a})$. Note the estimated parameters $\hat{\theta}_a$ are used to weight the labeling functions appropriately to  ensure that more reliable LFs receive a larger weight. 

\subsection{ScriptoriumWS System}
ScriptoriumWS is built on top of the PWS framework. Instead of writing LFs $\lambda$ manually, we synthesize them using OpenAI Codex. Codex is a descendant of the GPT-3 model, fine-tuned for use in programming applications. It has shown remarkable performance \cite {xu2022systematic} on code generation tasks across various programming languages. We use the Codex API with natural language prompts to generate code. We vary the temperature parameter from 0 to 0.2 to increase the diversity of the outputs. We feed the synthesized LFs into the PWS pipeline.

\subsection{Types of Prompt}
\begin{figure}
    \centering
    \includegraphics[width=\linewidth]{figures/general_prompt.png}
    \caption{An example of synthesized LF using general prompt strategy for the YouTube spam classification task.}
    \label{fig:gq}
\end{figure}

We explored a variety of prompting strategies, based on the kinds of information typically available to weak supervision users. 
%
We describe these strategies as being one of five categories, generally going from the least to the most expensive information requirements.

\paragraph{General Prompts:}
%% programming language, task description, function signature, function instructions
%To make users easy to write prompt for diverse datasets, prompt should have specification and adaptability. In ScriptorimWS, we 
First, we propose a general prompt format that can be easily extended with additional information. A general prompt includes four components, which are the use of programming language, basic task description, function signature, and labeling instructions. We demonstrate an example for the YouTube spam classification task \cite{alberto2015tubespam} in Figure \ref{fig:gq}. 

A general prompt first provides the programming language to be used to synthesize code. 
%
%It helps to ensure the consistency of returned code. 
Next, the basic task description provides an overview of what the function is expected to do.
%
Afterward, the function signature outlines the name of the synthesized program and the input that the code generation model should use.
%
Finally, we place labeling instructions into the function signature to specify the format and structure of the returned output.

%% \begin{figure}
%%     \centering
%%     \includegraphics[width=\linewidth]{figures/mission_statement.png}
%%     \caption{An example of synthesized LF using mission statement strategy for the YouTube spam classification task}
%%     \label{fig:ms}
%% \end{figure}

\paragraph{Mission Statement:}
In addition to providing a basic task description, we also propose an extended type of prompt, which we call the \emph{Mission Statement}. Here we add information to the general prompt to give the code generation model a better understanding of the task in the context. This additional information includes the use of external knowledge bases, and it can include relevant background descriptions about the problem or high-level dataset information (i.e., feature or label classes).

\begin{figure}
    \centering
    \includegraphics[width=\linewidth]{figures/human_heuristic.png}
    \caption{An example of a synthesized LF by using human heuristic strategy for the YouTube spam classification task}
    \label{fig:hh}
\end{figure}

\paragraph{Human Heuristic:}
In practical applications, users generally have a wealth of prior knowledge and expertise that they can bring to the prompt, including heuristic rules and domain-specific knowledge. Incorporating this prior knowledge into the prompt can be helpful in guiding the code generation model to have a better understanding of the problem and potentially develop a more effective solution that leverages the user's expertise. For example, if a user knows that certain keywords are indicative of spam, they could include this information in the prompt. In ScriptoriumWS, we reference keywords from existing human-designed LFs and write them into heuristic rules then add these rules to the prompt. We demonstrate an example in the category of human heuristic in Figure \ref{fig:hh}.

\begin{figure}[t!]
    \centering
    \includegraphics[width=\linewidth]{figures/example.png}
    \caption{Two synthesized LF examples generated by adding label function examples (left) and data examples (right) for the YouTube spam classification task. We can see that code generation model takes the given label function example as reference and learn the relationship between data examples and their expected outputs to extend and synthesize it own program.}
    \label{fig:lfe}
\end{figure}

\paragraph{In-Context Labeling Function Exemplars:}
In-context few-shot learning is a popular approach to perform a new task by inputting a few examples without the need of fine-tuning. We consider a practical scenario where users have already written some LFs or are allowed to access a few existing LFs. Such LFs can be incorporated into the prompt. The code generation model can use them as function templates to synthesize its own LF, which can be more closely aligned with the user's prior knowledge and expertise, rather than relying solely on the model's own training data.

%% \begin{figure}
%%     \centering
%%     \includegraphics[width=\linewidth]{figures/data_example.png}
%%     \caption{A prompt example using type of data example for YouTube dataset.}
%%     \label{fig:de}
%% \end{figure}

\paragraph{In-Context Data Exemplars:}
Besides providing Codex with heuristic rules and in-context few-shot learning with human-designed LFs, we propose another approach by incorporating a few labeled data examples into the prompt to direct the model to understand the problem. Given data examples can serve as concrete illustrations of the problem and provide a clearer understanding of the task and the expected output. This can be especially easy and useful when the problem domain is too complex to design heuristic rules or labeling functions manually.
