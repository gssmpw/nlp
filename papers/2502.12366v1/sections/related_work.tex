\section{Related Work}

\paragraph{Programmatic Weak Supervision (PWS):} 
PWS refers to a broad set of techniques where the data is labeled using cheaply available but potentially noisy labeling information. This information could be from external knowledge bases, heuristics, web search results, and more. Programmatic weak supervision \cite{ratner2016data, ratner2017snorkel} abstracts out these sources as user-provided (written) labeling functions and gives principled ways to aggregate their outputs to produce accurate pseudolabels.
%
This framework is practically effective and widely used in industry \cite{ratner2017snorkel,bach2019snorkel} and also offers theoretical guarantees, including consistent estimation of accuracies of labeling functions \cite{ratner2016data, vishwakarma2022Lifting}.
%
Its main downside is that writing, iterating, and debugging programmatic labeling functions is slow and expensive. 

\paragraph{Automated Weak Supervision (AutoWS):} AutoWS is a class of  techniques that reduce the need for humans to design LFs. 
In many cases, designing LFs can be expensive or challenging, particularly when the feature space is too complex, nuanced, or high-dimensional to be reasoned-about by a human, such as in image and video domains. AutoWS techniques can be used in these situations to automate the LF design process by instead using small models as LFs \cite{varma2018snuba, das2020goggles, boecking2021interactive}, or by augmenting a few given human-designed LFs to explore more rules \cite{inproceedings}. Similarly, it is possible to directly query large pretrained models for noisy label estimates~\cite{smith2022language}. The downside of these approaches is that the resulting labeling functions are typically no longer programs that can be debugged, modified, and re-used. 
%These methods often rely on obtaining feature representations that are amenable to learning independent LFs, conditioned on the unobserved true label \cite{roberts2022autowsbench}. Additionally, these methods require a small initial set of labeled examples or initial label function examples, which might not be available in all instances. 

%% Though weak supervision alleviates the need to get costly human labels for data points and significantly reduces the time and cost of data labeling, it still needs users to write labeling functions(LFs). Auto-WS methods \cite{roberts2022autowsbench} are aimed at automating the LF writing process -- reducing(or even eliminating) human supervision even further. To reduce the effort required in crafting labeling functions, some researchers have developed methods for automatically generating LFs. Some trained weak learners as labeling sources with a small amount of labeled data to develop heuristic rules \cite{varma2018snuba, das2020goggles, boecking2021interactive}. Some generated LFs by augmenting initial given LFs to explore semantic relations between augmented rules \cite{inproceedings}. However, these approaches still require a level of supervision initially to learn and expand weak labels to unlabeled data.

%% prompting labels from foundation models is hard to scale up with millions of training data. Sending training data with OpenAI API induces privacy leakage
%% talk about prompting WS
%% is that possible to use LLM of code to generate label function and how to inject knowledge into prompt.
%% codexLF: automated generate label functions, reduce labeling cost, reusable, low-cost, is able to scale up with size of training data.
%% existing pre-trained model can be used as LFs to provide weak lables.

\paragraph{Large Pretrained Models and Prompt Engineering:} 
%\bh{Harit's Help}
%Large pretrained models are huge models with billions of parameters trained on enormous corpora. 
%
%Such large-scale training along with features of model architecture gives these models capabilities to answer complex questions, write code, etc. 
Prompting is a common way to tap into the knowledge and capabilities  of large pre-trained models \cite{liu2023PromptingSurvey}. Prompting refers to giving natural language instructions to the model in order to get the answer. These prompts can also contain examples of input-output pairs -- usually referred to as in-context learning \cite{brown2020language, ICL2023Survey}. Prompting has been successfully applied in various applications and understanding various aspects of prompting is a very active area of research. 
% discuss some prompting methods
There are various methods proposed for creating good prompts e.g. 
\cite{arora2023ask} give a general prompting method, chain of thought  prompting \cite{wei2022chain-of-thought} and methods to automate prompt generation \cite{zhou2022-auto-prompt}. For code generation, prompts with detailed instructions, problem statements, partial code, etc. have been used \cite{sami2022-prompting-code, paul2022prompting-code}. We are inspired by these strategies when designing our proposed system. 

%soft-prompting
%\cite{qin2021-soft-prompt},

%prompting debate \cite{mishra2022reframing,wu2022Prompt} 
%\cite{scao2021-prompt-worth}
%\cite{webson-pavlick-2022-prompt}

\textbf{Using Large Pretrained Models for Data Annotation:} Using large language models (LLMs) or other large pretrained models with appropriate prompts to annotate data is a promising direction that can reduce the cost and human effort in data labeling \cite{smith2022language, wang-etal-2021-want-reduce}. %Some of the recent works \cite{ smith2022language,wang-etal-2021-want-reduce} have used LLMs + prompting to annotate data. %According to \cite{smith2022language}, GPT-3 can be incorporated into PWS by modeling diverse prompts and taking returned answers as noisy weak labels. For instance, a data example from the spam dataset can be given to GPT-3 with a prompt like "Is the following comment spam? [Text]", then the prediction can be used as the weak label. While the use of natural language prompts makes PWS easier to take advantage of the knowledge learned by large-scale training in LLMs, this approach has 
The main limitation here is in terms of scalability and privacy. Inference via querying an API for every data example becomes cost-prohibitive when dealing with large-size training datasets, and sending training data through APIs to other organizations poses a risk of privacy leaks, especially for sensitive data.
 

% \cite{chen2022shoring} pre-trained models + no prompting. 

%% Another approach to generate weak labels is to leverage existing  large language models (LLMs) (i.e., BERT \cite{devlin2018bert}, GPT-3 \cite{brown2020language}, and T0++ \cite{sanh2022multitask}) as labeling sources \cite{chen2022shoring, smith2022language}. According to \cite{smith2022language}, GPT-3 can be incorporated into PWS by modeling diverse prompts and taking returned answers as noisy weak labels. For instance, a data example from the spam dataset can be given to GPT-3 with a prompt like "Is the following comment spam? [Text]", then the prediction can be used as the weak label. While the use of natural language prompts makes PWS easier to take advantage of the knowledge learned by large-scale training in LLMs, this approach has limitations in terms of scalability and privacy. Querying the API for every data example becomes cost-prohibitive when dealing with large-size training datasets, and sending training data through APIs to other organizations poses a risk of privacy leaks, especially for sensitive data.
%% soft-prompt
%% in-context learning

%Besides AutoWS, PromptWS is another approach that makes existing large language models (LLMs) (i.e. GPT-3 \cite{brown2020language} and T0++ \cite{sanh2022multitask}) as labeling sources and queries training data via multiple diverse prompts and model returned answers to generate labels \cite{smith2022language}. 
%
%\paragraph{Code Generation Models}
%% Program Synthesis
%% Codegen
%% Codex (plus competitors, Copilot, etc.) 
