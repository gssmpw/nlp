
In this paper, we introduced CAST, a novel single-image 3D scene reconstruction method that combines geometric fidelity, pixel-level alignment, and physically grounded constraints. By integrating scene decomposition, a perceptive 3D instance generation framework, and physical correction techniques, CAST addresses key challenges such as pose misalignment, object interdependencies, and partial occlusions. This structured pipeline results in 3D scenes that are both visually accurate and physically consistent, pushing beyond the limitations of traditional object-centric approaches. We validated CAST through extensive experiments and user studies, demonstrating significant performance improvements over state-of-the-art methods in terms of visual quality and physical plausibility. We anticipate that CAST will serve as a strong foundation for future developments in 3D generation, scene reconstruction, and immersive content creation.





\paragraph{Limitations and Future Work}

%当前的方法对于场景的恢复精度取决于物体生成的基础模型，目前生成的初始模型依旧缺乏足够的细节和准确性，还有很大的进步空间，导致后续优化时的稳定性受到影响。尽管我们已经添加了一些module来提升生成物体的鲁棒性和相似性，一个更好，更鲁棒的生成模型能显著提升整个场景的质量
The quality of scene generation in CAST is heavily dependent on the underlying object generation model. At present, the model still lacks sufficient detail and precision, this limitation leads to noticeable inconsistencies in the generated objects, affecting their alignment and spatial relationships in the scene. Although additional modules have been incorporated to enhance object robustness and similarity, the need for more advanced and robust generation models remains. A more detailed and accurate object generator could significantly improve the overall scene quality and enhance its real-world applicability.


%背景建模，环境光建模
A notable limitation of the current method is the absence of lighting estimation and background modeling. Without realistic lighting, the interactions between objects and their surroundings may lack natural shading and illumination effects, impacting the visual realism and immersion of the generated 3D environments. Future enhancements in CAST could benefit from integrating advanced techniques for lighting estimation and background modeling, which would significantly enrich the contextual depth and visual fidelity of the scenes.


%当前的场景生成模型在生成大规模、复杂场景时仍面临一定挑战。如果能够使用我们的方法生成open-vercabulary的各种类别的场景数据，未来可能可以训练出能够直接生成 3D 场景的大型生成模型，进一步提高模型的应用范围和生成质量。
In more complex scenes, the performance of the current method may experience slight degradation. Challenges such as intricate spatial layouts and dense object configurations could affect the accuracy of scene reconstruction to some extent. While CAST currently excels at reconstructing individual scenes, there is significant potential to utilize its outputs to build large-scale datasets, facilitating advanced research on fully learned scene or video generation pipelines. Expanding the variety and realism of generated scenes in this manner could further improve the robustness and applicability of 3D generative models in areas such as film production, simulation, and immersive media.
