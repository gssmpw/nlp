\subsection{RQ1: Comparison with SOTA Methods}

%-------------main results
% \begin{table}[t]
% \newcommand{\hlinebold}{\noalign{\hrule height 0.2mm}}
% \centering
% \caption{Performance for accuracy compared to existing OOC methods on the benchmark dataset NewsCLIPpings~\cite{luo2021newsclippings}. The best performances are indicated in \textbf{bold}.}
% \resizebox{\columnwidth}{!}{%
% \begin{tabular}{l|c|ccc}
% % \toprule
% Methods & Venue & \textbf{All} & \textbf{Falsified} & \textbf{Pristine}  \\
% \hlinebold
% SAFE~\cite{massarelli2019safe}  & PAKDD20 & 52.8 & 54.8 & 52.0  \\
% EANN~\cite{wang2018eann}  & SIGKDD18 & 58.1 & 61.8 & 56.2  \\
% \hline
% VisualBERT~\cite{li2019visualbert}  & arXiv19 & 58.6 & 38.9 & 78.4 \\
% CLIP~\cite{radford2021learning} & ICML21  & 66.0 & 64.3 & 67.7  \\
% Neu-Sym detector~\cite{zhang2023detecting} & arXiv23 & 68.2 & - & - \\
% DT-Transformer~\cite{papadopoulos2023synthetic} & MAD23 & 77.1 & 78.6 & 75.6  \\
% CCN~\cite{abdelnabi2022open} & CVPR22 & 84.7 & 84.8 & 84.5  \\
% SEN~\cite{yuan2023support} & EMNLP23 & 87.1 & 85.5 & 88.6  \\
% ECENet~\cite{zhang2023ecenet} & MM23 & 87.7 & - & - \\
% \hline
% SNIFFER~\cite{qi2024sniffer} & CVPR24 & 88.4 & 86.9 & \textbf{91.8}  \\
% \rowcolor{lightgreen} E2LVLM (\textit{Ours}) & & \textbf{89.9} & \textbf{90.3} & 89.4  \\
% % \hlinebold
% % \bottomrule
% \end{tabular}%
% }
% \label{tab:tab_1}
% \end{table}


% \begin{table}[t]
% \newcommand{\hlinebold}{\noalign{\hrule height 0.2mm}}
% \centering
% \small
% \caption{Performance for accuracy compared to existing OOC methods on the benchmark dataset NewsCLIPpings~\cite{luo2021newsclippings}. The best performances are indicated in \textbf{bold}.}
% \begin{adjustbox}{valign=c,max width=\columnwidth}
% \begin{tabular}{l|c|ccc}
% Methods & Venue & \textbf{All} & \textbf{Falsified} & \textbf{Pristine}  \\
% \hlinebold
% SAFE~\cite{massarelli2019safe}  & PAKDD20 & 52.8 & 54.8 & 52.0  \\
% EANN~\cite{wang2018eann}  & SIGKDD18 & 58.1 & 61.8 & 56.2  \\
% \hline
% VisualBERT~\cite{li2019visualbert}  & arXiv19 & 58.6 & 38.9 & 78.4 \\
% CLIP~\cite{radford2021learning} & ICML21  & 66.0 & 64.3 & 67.7  \\
% Neu-Sym detector~\cite{zhang2023detecting} & arXiv23 & 68.2 & - & - \\
% DT-Transformer~\cite{papadopoulos2023synthetic} & MAD23 & 77.1 & 78.6 & 75.6  \\
% CCN~\cite{abdelnabi2022open} & CVPR22 & 84.7 & 84.8 & 84.5  \\
% SEN~\cite{yuan2023support} & EMNLP23 & 87.1 & 85.5 & 88.6  \\
% ECENet~\cite{zhang2023ecenet} & MM23 & 87.7 & - & - \\
% \hline
% SNIFFER~\cite{qi2024sniffer} & CVPR24 & 88.4 & 86.9 & \textbf{91.8}  \\
% \rowcolor{lightgreen} E2LVLM (\textit{Ours}) & & \textbf{89.9} & \textbf{90.3} & 89.4  \\
% \end{tabular}%
% \end{adjustbox}
% \label{tab:tab_1}
% \end{table}

\Cref{tab:tab_1} presents the detailed comparison of E2LVLM with existing OOC methods on NewsCLIPpings. We use ``-'' for partial methods that do not release source codes or results. As shown in these results, we summarize the following findings: (1) As for the accuracy over ``All'', E2LVLM outperforms all methods by a large margin. Even for the state-of-the-art (SNIFFER), E2LVLM still outperforms it by around 1.5\% accuracy. (2) E2LVLM owns strong discriminatory powers, with an improvement of around 3.4\% over ``Falsified'', increasing the SOTA from 86.9\% to 90.3\%. (3) E2LVLM has a trade-off between ``Falsified'' and ``Pristine''. As reported by CCN~\cite{abdelnabi2022open}, a professional OOC misinformation detector should accurately identify both ``Falsified'' and ``Pristine'' samples. E2LVLM provides a closer distance between them, compared with the SOTA. This confirms that the improvement in the E2LVLM's performance on ``Falsified'' does not come at the cost of its performance on ``Pristine'', or vice versa. (4) With the increasing of architectural complexity, the performance of OOC misinformation detectors has been significantly enhanced, which is consistent with previous statements. In the context of LVLMs-based OOC methods, E2LVLM with Qwen2-VL-7B~\cite{wang2024qwen2} is superior to SNIFFER that depends on GPT-4~\cite{achiam2023gpt} and Vicuna-13B~\cite{vicuna2023}. These findings suggest the superiority of the proposed method E2LVLM on the OOC detection.


\begin{table}[t]
    \caption{Performance for accuracy compared to existing methods on NewsCLIPpings~\cite{luo2021newsclippings}. The best results are indicated in \textbf{bold}.}
      \centering
      \begin{adjustbox}{valign=c, max width=\columnwidth}
      \begin{tabular}{l|c|ccc}
        \toprule
        Methods & Venue & \textbf{All} & \textbf{Falsified} & \textbf{Pristine}  \\
        \hline
        SAFE~\cite{massarelli2019safe}  & PAKDD20 & 52.8 & 54.8 & 52.0  \\
        EANN~\cite{wang2018eann}  & SIGKDD18 & 58.1 & 61.8 & 56.2  \\
        \hline
        VisualBERT~\cite{li2019visualbert}  & arXiv19 & 58.6 & 38.9 & 78.4 \\
        CLIP~\cite{radford2021learning} & ICML21  & 66.0 & 64.3 & 67.7  \\
        Neu-Sym detector~\cite{zhang2023detecting} & arXiv23 & 68.2 & - & - \\
        DT-Transformer~\cite{papadopoulos2023synthetic} & MAD23 & 77.1 & 78.6 & 75.6  \\
        CCN~\cite{abdelnabi2022open} & CVPR22 & 84.7 & 84.8 & 84.5  \\
        SEN~\cite{yuan2023support} & EMNLP23 & 87.1 & 85.5 & 88.6  \\
        ECENet~\cite{zhang2023ecenet} & MM23 & 87.7 & - & - \\
        \hline
        SNIFFER~\cite{qi2024sniffer} & CVPR24 & 88.4 & 86.9 & \textbf{91.8}  \\
        \rowcolor{lightgreen} E2LVLM (\textit{Ours}) & & \textbf{89.9} & \textbf{90.3} & 89.4  \\
        \bottomrule
  \end{tabular}
  \end{adjustbox}
  \label{tab:tab_1}
\end{table}



% %------------------main results
% \begin{table}[t]
% \newcommand{\hlinebold}{\noalign{\hrule height 0.2mm}}
% \centering
% \small
% \caption{Performance for accuracy compared to existing OOC methods on the benchmark dataset NewsCLIPpings~\cite{luo2021newsclippings}. The best performances are indicated in \textbf{bold}.}
% \begin{adjustbox}{valign=c,max width=\columnwidth}
% \begin{tabular}{l|c|ccc}
% \toprule
% Methods & Venue & \textbf{All} & \textbf{Falsified} & \textbf{Pristine}  \\
% \hlinebold
% SAFE~\cite{massarelli2019safe}  & PAKDD20 & 52.8 & 54.8 & 52.0  \\
% EANN~\cite{wang2018eann}  & SIGKDD18 & 58.1 & 61.8 & 56.2  \\
% \hline
% VisualBERT~\cite{li2019visualbert}  & arXiv19 & 58.6 & 38.9 & 78.4 \\
% CLIP~\cite{radford2021learning} & ICML21  & 66.0 & 64.3 & 67.7  \\
% Neu-Sym detector~\cite{zhang2023detecting} & arXiv23 & 68.2 & - & - \\
% DT-Transformer~\cite{papadopoulos2023synthetic} & MAD23 & 77.1 & 78.6 & 75.6  \\
% CCN~\cite{abdelnabi2022open} & CVPR22 & 84.7 & 84.8 & 84.5  \\
% SEN~\cite{yuan2023support} & EMNLP23 & 87.1 & 85.5 & 88.6  \\
% ECENet~\cite{zhang2023ecenet} & MM23 & 87.7 & - & - \\
% \hline
% SNIFFER~\cite{qi2024sniffer} & CVPR24 & 88.4 & 86.9 & \textbf{91.8}  \\
% \rowcolor{lightgreen} E2LVLM (\textit{Ours}) & & \textbf{89.9} & \textbf{90.3} & 89.4  \\
% \end{tabular}%
% \end{adjustbox}
% \label{tab:tab_1}
% \end{table}