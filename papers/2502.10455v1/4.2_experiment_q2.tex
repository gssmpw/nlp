\subsection{RQ2: Ablation Study}

\begin{table}[t]
\caption{Ablation experiments for the E2LVLM. Evaluated on the NewsCLIPpings~\cite{luo2021newsclippings}. ``\#Evid.'' and ``\#Expla.'' represent the use of textual evidence and the supervised signal with explanations.}
\centering
\setlength{\tabcolsep}{1.5pt} % 调整列间距，减小为4pt
\renewcommand{\arraystretch}{1.2} % 调整行高（默认为1）
    \begin{adjustbox}{valign=c,max width=\columnwidth}
        \begin{tabular}{cccccc|ccc}
            \toprule
            Qwen2-VL & \#Evid. & Rerank & Rewrite& \#Expla. & Tuning & \textbf{All} & \textbf{Falsified} & \textbf{Pristine} \\
            \hline
            \cmark & \xmark & \xmark & \xmark & \xmark &\xmark & 69.1 & 54.4 & 83.9 \\
            \cmark & \cmark & \xmark & \xmark & \xmark &\xmark & 76.7 &	68.0 &	85.3 \\
            \hline
            \cmark & \xmark & \xmark & \xmark & \xmark &\cmark   & 78.9 & 73.8 & 84.2 \\
            \cmark & \cmark & \xmark & \xmark & \xmark &\cmark   & 83.0 & 77.1 & 88.9 \\
            \cmark & \cmark & \cmark & \xmark & \xmark &\cmark   & 87.7 & 86.5 & 88.7  \\
            \cmark & \cmark & \cmark & \cmark & \xmark &\cmark   & 88.5 & 87.7 & 89.1  \\
            \rowcolor{lightgreen} \cmark & \cmark & \cmark & \cmark &  \cmark &\cmark  & \textbf{89.9} & \textbf{90.3} & \textbf{89.4} \\
            \bottomrule
        \end{tabular}
    \end{adjustbox}
\label{tab:tab_2}
\end{table}









We conduct ablation experiments to analyze the effectiveness of primary procedures in E2LVLM. The results are shown in \Cref{tab:tab_2}, we can obtain the following findings:

\begin{itemize}
    \item We evaluate the impact of the use of textual evidence in zero-shot scenarios. As shown in the first two rows of \Cref{tab:tab_2}, the introduction of evidence achieves significant gains in performance, especially over ``Falsified''. Typically, the raw Qwen2-VL~\cite{wang2024qwen2} provides an accuracy of 69.1$\%$ over ``All'', which is higher than random guessing. It is attributed to the multimodal understanding capabilities of LVLMs. However, the base model struggles to discern falsified information, which necessitates robust methods to handle this challenge. Introducing textual evidence into the base model provides a performance improvement of 13.6$\%$ over the OOC. Besides, the accuracy on ``All'' reaches 76.7$\%$ (a 7.6$\%$ improvement in performance). This suggests the importance of the use of textual evidence in LVLMs for the OOC detection.
    \item In the second study, as shown in the remainder of \Cref{tab:tab_2}, each procedure contributes to the performance of E2LVLM. Typically, the task-specific fine-tuning technology extends LVLMs to the OOC, leading to promising results compared with zero-shot scenarios. Next, we conduct the textual evidence reranking strategy on E2LVLM, focusing on the salient item for debunking OOC misinformation. This results in an accuracy of 87.7$\%$ on ``All'', and shows a 9.4$\%$ improvement on ``Falsified'', while avoiding performance degradation on ``Pristine''. The reason is that such strategy appropriately eliminates the noise in the retrieved evidence. Further, we enforce the textual evidence rewriting strategy to generate coherent and contextually attuned content for better understanding, leading to an accuracy of 88.5$\%$ on ``All''. This suggests the importance of the reranking and rewriting of the retrieved textual evidence in E2LVLM for the OOC detection.
    \item Additionally, to understand the importance of the model’s explainability, we introduce the supervised signal with both judgment and explanation to the training phase, as shown in the last row of \Cref{tab:tab_2}. This results in an accuracy of 90.3$\%$ over ``Falsified'', higher than others. This is caused by the fact that such supervised signal enhances the model's discriminatory powers, thereby making the model provide accurate detections and attach them with compelling rationales for judgments. These results indicate that the supervised signal with both judgment and explanation contributes to the performance of E2LVLM.
\end{itemize}

% \newpage



