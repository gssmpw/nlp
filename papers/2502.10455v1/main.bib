@String(PAMI = {IEEE Trans. Pattern Anal. Mach. Intell.})
@String(IJCV = {Int. J. Comput. Vis.})
@String(CVPR= {IEEE Conf. Comput. Vis. Pattern Recog.})
@String(ICCV= {Int. Conf. Comput. Vis.})
@String(ECCV= {Eur. Conf. Comput. Vis.})
@String(NIPS= {Adv. Neural Inform. Process. Syst.})
@String(ICPR = {Int. Conf. Pattern Recog.})
@String(BMVC= {Brit. Mach. Vis. Conf.})
@String(TOG= {ACM Trans. Graph.})
@String(TIP  = {IEEE Trans. Image Process.})
@String(TVCG  = {IEEE Trans. Vis. Comput. Graph.})
@String(TMM  = {IEEE Trans. Multimedia})
@String(ACMMM= {ACM Int. Conf. Multimedia})
@String(ICME = {Int. Conf. Multimedia and Expo})
@String(ICASSP=	{ICASSP})
@String(ICIP = {IEEE Int. Conf. Image Process.})
@String(ACCV  = {ACCV})
@String(ICLR = {Int. Conf. Learn. Represent.})
@String(IJCAI = {IJCAI})
@String(PR   = {Pattern Recognition})
@String(AAAI = {AAAI})
@String(CVPRW= {IEEE Conf. Comput. Vis. Pattern Recog. Worksh.})
@String(CSVT = {IEEE Trans. Circuit Syst. Video Technol.})

@String(SPL	= {IEEE Sign. Process. Letters})
@String(VR   = {Vis. Res.})
@String(JOV	 = {J. Vis.})
@String(TVC  = {The Vis. Comput.})
@String(JCST  = {J. Comput. Sci. Tech.})
@String(CGF  = {Comput. Graph. Forum})
@String(CVM = {Computational Visual Media})


@String(PAMI  = {IEEE TPAMI})
@String(IJCV  = {IJCV})
@String(CVPR  = {CVPR})
@String(ICCV  = {ICCV})
@String(ECCV  = {ECCV})
@String(NIPS  = {NeurIPS})
@String(ICPR  = {ICPR})
@String(BMVC  =	{BMVC})
@String(TOG   = {ACM TOG})
@String(TIP   = {IEEE TIP})
@String(TVCG  = {IEEE TVCG})
@String(TCSVT = {IEEE TCSVT})
@String(TMM   =	{IEEE TMM})
@String(ACMMM = {ACM MM})
@String(ICME  =	{ICME})
@String(ICASSP=	{ICASSP})
@String(ICIP  = {ICIP})
@String(ACCV  = {ACCV})
@String(ICLR  = {ICLR})
@String(IJCAI = {IJCAI})
@String(PR = {PR})
@String(AAAI = {AAAI})
@String(CVPRW= {CVPRW})
@String(CSVT = {IEEE TCSVT})





@inproceedings{taigman2014deepface,
  title={Deepface: Closing the gap to human-level performance in face verification},
  author={Taigman, Yaniv and Yang, Ming and Ranzato, Marc'Aurelio and Wolf, Lior},
  booktitle={Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition},
  pages={1701--1708},
  year={2014}
}

@inproceedings{liu2024forgery,
  title={Forgery-aware adaptive transformer for generalizable synthetic image detection},
  author={Liu, Huan and Tan, Zichang and Tan, Chuangchuang and Wei, Yunchao and Wang, Jingdong and Zhao, Yao},
  booktitle={Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition},
  pages={10770--10780},
  year={2024}
}

@inproceedings{qi2024sniffer,
  title={SNIFFER: Multimodal Large Language Model for Explainable Out-of-Context Misinformation Detection},
  author={Qi, Peng and Yan, Zehong and Hsu, Wynne and Lee, Mong Li},
  booktitle={Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition},
  pages={13052--13062},
  year={2024}
}

@article{wang2024mmidr,
  title={MMIDR: Teaching Large Language Model to Interpret Multimodal Misinformation via Knowledge Distillation},
  author={Wang, Longzheng and Xu, Xiaohan and Zhang, Lei and Lu, Jiarui and Xu, Yongxiu and Xu, Hongbo and Zhang, Chuang},
  journal={arXiv preprint arXiv:2403.14171},
  year={2024}
}

@article{shao2024detecting,
  title={Detecting and grounding multi-modal media manipulation and beyond},
  author={Shao, Rui and Wu, Tianxing and Wu, Jianlong and Nie, Liqiang and Liu, Ziwei},
  journal={IEEE Transactions on Pattern Analysis and Machine Intelligence},
  year={2024}
}

@article{bohacek2024making,
  title={The making of an AI news anchorâ€”and its implications},
  author={Bohacek, Matyas and Farid, Hany},
  journal={Proceedings of the National Academy of Sciences of the United States of America},
  volume={121},
  number={1},
  pages={e2315678121},
  year={2024}
}


@article{lin2024detecting,
  title={Detecting multimedia generated by large ai models: A survey},
  author={Lin, Li and Gupta, Neeraj and Zhang, Yue and Ren, Hainan and Liu, Chun-Hao and Ding, Feng and Wang, Xin and Li, Xin and Verdoliva, Luisa and Hu, Shu},
  journal={arXiv preprint arXiv:2402.00045},
  year={2024}
}

@article{naeem2020covid,
  title={The COVID-19 `infodemic': A new front for information professionals},
  author={Naeem, Salman Bin and Bhatti, Rubina},
  journal={Health Information \& Libraries Journal},
  volume={37},
  number={3},
  pages={233--239},
  year={2020}
}

@inproceedings{abdelnabi2022open,
  title={Open-domain, content-based, multi-modal fact-checking of out-of-context images via online resources},
  author={Abdelnabi, Sahar and Hasan, Rakibul and Fritz, Mario},
  booktitle={Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition},
  pages={14940--14949},
  year={2022}
}

@inproceedings{yuan2023support,
  title={Support or Refute: Analyzing the Stance of Evidence to Detect Out-of-Context Mis-and Disinformation},
  author={Yuan, Xin and Guo, Jie and Qiu, Weidong and Huang, Zheng and Li, Shujun},
  booktitle={Proceedings of the 2023 Conference on Empirical Methods in Natural Language Processing (EMNLP 2023)},
  pages={4268--4280},
  year={2023}
}

@article{papadopoulos2023red,
  title={RED-DOT: Multimodal Fact-checking via Relevant Evidence Detection},
  author={Papadopoulos, Stefanos-Iordanis and Koutlis, Christos and Papadopoulos, Symeon and Petrantonakis, Panagiotis C},
  journal={arXiv preprint arXiv:2311.09939},
  year={2023}
}

@inproceedings{zhang2023ecenet,
  title={ECENet: Explainable and Context-Enhanced Network for Muti-modal Fact verification},
  author={Zhang, Fanrui and Liu, Jiawei and Zhang, Qiang and Sun, Esther and Xie, Jingyi and Zha, Zheng-Jun},
  booktitle={Proceedings of the 31st ACM International Conference on Multimedia},
  pages={1231--1240},
  year={2023}
}

@inproceedings{aneja2023cosmos,
  title={COSMOS: Catching out-of-context image misuse using self-supervised learning},
  author={Aneja, Shivangi and Bregler, Chris and Nie{\ss}ner, Matthias},
  booktitle={Proceedings of the AAAI Conference on Artificial Intelligence},
  volume={37},
  number={12},
  pages={14084--14092},
  year={2023}
}

@inproceedings{mu2023self,
  title={Self-supervised distilled learning for multi-modal misinformation identification},
  author={Mu, Michael and Das Bhattacharjee, Sreyasee and Yuan, Junsong},
  booktitle={Proceedings of the IEEE/CVF Winter Conference on Applications of Computer Vision},
  pages={2819--2828},
  year={2023}
}

@inproceedings{dang2024overview,
  title={Overview of the Grand Challenge on Detecting Cheapfakes at ACM ICMR 2024},
  author={Dang-Nguyen, Duc-Tien and Khan, Sohail Ahmed and Riegler, Michael and Halvorsen, P\r{a}l and Tran, Anh-Duy and Dao, Minh-Son and Tran, Minh-Triet},
  booktitle={International Conference on Multimedia Retrieval},
  pages={1275--1281},
  year={2024}
}

@inproceedings{luo2021newsclippings,
  title={NewsCLIPpings: Automatic Generation of Out-of-Context Multimodal Media},
  author={Luo, Grace and Darrell, Trevor and Rohrbach, Anna},
  booktitle={Proceedings of the 2021 Conference on Empirical Methods in Natural Language Processing (EMNLP 2021)},
  pages={6801--6817},
  year={2021}
}

@inproceedings{papadopoulos2023synthetic,
  title={Synthetic misinformers: Generating and combating multimodal misinformation},
  author={Papadopoulos, Stefanos-Iordanis and Koutlis, Christos and Papadopoulos, Symeon and Petrantonakis, Panagiotis},
  booktitle={Proceedings of the 2nd ACM International Workshop on Multimedia AI against Disinformation},
  pages={36--44},
  year={2023}
}

@article{gu2024learning,
  title={Learning Domain-Invariant Features for Out-of-Context News Detection},
  author={Gu, Yimeng and Zhang, Mengqi and Castro, Ignacio and Wu, Shu and Tyson, Gareth},
  journal={arXiv preprint arXiv:2406.07430},
  year={2024}
}

@inproceedings{tahmasebi2024multimodal,
  title={Multimodal Misinformation Detection using Large Vision-Language Models},
  author={Tahmasebi, Sahar and M{\"u}ller-Budack, Eric and Ewerth, Ralph},
  booktitle={Proceedings of the 33rd ACM International Conference on Information and Knowledge Management},
  pages={2189--2199},
  year={2024}
}

@inproceedings{wu2024cotkr,
  title={CoTKR: Chain-of-Thought Enhanced Knowledge Rewriting for Complex Knowledge Graph Question Answering},
  author={Wu, Yike and Huang, Yi and Hu, Nan and Hua, Yuncheng and Qi, Guilin and Chen, Jiaoyan and Pan, Jeff Z},
  booktitle={Proceedings of the 2024 Conference on Empirical Methods in Natural Language Processing (EMNLP 2024)},
  year={2024}
}

@article{achiam2023gpt,
  title={Gpt-4 technical report},
  author={Achiam, Josh and Adler, Steven and Agarwal, Sandhini and Ahmad, Lama and Akkaya, Ilge and Aleman, Florencia Leoni and Almeida, Diogo and Altenschmidt, Janko and Altman, Sam and Anadkat, Shyamal and others},
  journal={arXiv preprint arXiv:2303.08774},
  year={2023}
}

@article{wang2024qwen2,
  title={Qwen2-vl: Enhancing vision-language model's perception of the world at any resolution},
  author={Wang, Peng and Bai, Shuai and Tan, Sinan and Wang, Shijie and Fan, Zhihao and Bai, Jinze and Chen, Keqin and Liu, Xuejing and Wang, Jialin and Ge, Wenbin and others},
  journal={arXiv preprint arXiv:2409.12191},
  year={2024}
}

@article{yin2023survey,
  title={A survey on multimodal large language models},
  author={Yin, Shukang and Fu, Chaoyou and Zhao, Sirui and Li, Ke and Sun, Xing and Xu, Tong and Chen, Enhong},
  journal={arXiv preprint arXiv:2306.13549},
  year={2023}
}

@article{team2023gemini,
  title={Gemini: A family of highly capable multimodal models},
  author={Team, Gemini and Anil, Rohan and Borgeaud, Sebastian and Alayrac, Jean-Baptiste and Yu, Jiahui and Soricut, Radu and Schalkwyk, Johan and Dai, Andrew M and Hauth, Anja and Millican, Katie and others},
  journal={arXiv preprint arXiv:2312.11805},
  year={2023}
}

@misc{vicuna2023,
    title = {Vicuna: An Open-Source Chatbot Impressing GPT-4 with 90\%* ChatGPT Quality},
    author = {Chiang, Wei-Lin and Li, Zhuohan and Lin, Zi and Sheng, Ying and Wu, Zhanghao and Zhang, Hao and Zheng, Lianmin and Zhuang, Siyuan and Zhuang, Yonghao and Gonzalez, Joseph E. and Stoica, Ion and Xing, Eric P.},
    month = {March},
    year = {2023}
}

@inproceedings{kuckreja2024geochat,
  title={Geochat: Grounded large vision-language model for remote sensing},
  author={Kuckreja, Kartik and Danish, Muhammad Sohail and Naseer, Muzammal and Das, Abhijit and Khan, Salman and Khan, Fahad Shahbaz},
  booktitle={Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition},
  pages={27831--27840},
  year={2024}
}

@inproceedings{chen2024lion,
  title={Lion: Empowering multimodal large language model with dual-level visual knowledge},
  author={Chen, Gongwei and Shen, Leyang and Shao, Rui and Deng, Xiang and Nie, Liqiang},
  booktitle={Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition},
  pages={26540--26550},
  year={2024}
}

@inproceedings{zhang2023aligning,
  title={Aligning Instruction Tasks Unlocks Large Language Models as Zero-Shot Relation Extractors},
  author={Zhang, Kai and Gutierrez, Bernal Jimenez and Su, Yu},
  booktitle={Proceedings of the 61st Annual Meeting of the Association For Computational Linguistics},
  year={2023}
}

@inproceedings{jiao2023instruct,
  title={Instruct and Extract: Instruction Tuning for On-Demand Information Extraction},
  author={Jiao, Yizhu and Zhong, Ming and Li, Sha and Zhao, Ruining and Ouyang, Siru and Ji, Heng and Han, Jiawei},
  booktitle={Proceedings of the 2023 Conference on Empirical Methods in Natural Language Processing (EMNLP 2023)},
  pages={10030--10051},
  year={2023}
}

@inproceedings{jin2024llava,
  title={LLaVA-VSD: Large Language-and-Vision Assistant for Visual Spatial Description},
  author={Jin, Yizhang and Li, Jian and Zhang, Jiangning and Hu, Jianlong and Gan, Zhenye and Tan, Xin and Liu, Yong and Wang, Yabiao and Wang, Chengjie and Ma, Lizhuang},
  booktitle={Proceedings of the 32nd ACM International Conference on Multimedia},
  pages={11420--11425},
  year={2024}
}

@article{gou2021knowledge,
  title={Knowledge distillation: A survey},
  author={Gou, Jianping and Yu, Baosheng and Maybank, Stephen J and Tao, Dacheng},
  journal={International Journal of Computer Vision},
  volume={129},
  number={6},
  pages={1789--1819},
  year={2021},
}

@article{yang2024gpt4tools,
  title={Gpt4tools: Teaching large language model to use tools via self-instruction},
  author={Yang, Rui and Song, Lin and Li, Yanwei and Zhao, Sijie and Ge, Yixiao and Li, Xiu and Shan, Ying},
  journal={Advances in Neural Information Processing Systems},
  volume={36},
  year={2024}
}

@inproceedings{dai2023instructblip,
  title={InstructBLIP: Towards general-purpose vision-language models with instruction tuning},
  author={Dai, Wenliang and Li, Junnan and Li, Dongxu and Tiong, Anthony Meng Huat and Zhao, Junqi and Wang, Weisheng and Li, Boyang and Fung, Pascale and Hoi, Steven},
  booktitle={International Conference on Neural Information Processing Systems},
  pages={49250--49267},
  year={2023}
}

@article{ouyang2022training,
  title={Training language models to follow instructions with human feedback},
  author={Ouyang, Long and Wu, Jeffrey and Jiang, Xu and Almeida, Diogo and Wainwright, Carroll and Mishkin, Pamela and Zhang, Chong and Agarwal, Sandhini and Slama, Katarina and Ray, Alex and others},
  journal={Advances in Neural Information Processing Systems},
  volume={35},
  pages={27730--27744},
  year={2022}
}

@article{hurst2024gpt,
  title={GPT-4o System Card},
  author={Hurst, Aaron and Lerer, Adam and Goucher, Adam P and Perelman, Adam and Ramesh, Aditya and Clark, Aidan and Ostrow, AJ and Welihinda, Akila and Hayes, Alan and Radford, Alec and others},
  journal={arXiv preprint arXiv:2410.21276},
  year={2024}
}

@inproceedings{radford2021learning,
  title={Learning transferable visual models from natural language supervision},
  author={Radford, Alec and Kim, Jong Wook and Hallacy, Chris and Ramesh, Aditya and Goh, Gabriel and Agarwal, Sandhini and Sastry, Girish and Askell, Amanda and Mishkin, Pamela and Clark, Jack and others},
  booktitle={International Conference on Machine Learning},
  pages={8748--8763},
  year={2021}
}

@inproceedings{li2023blip,
  title={Blip-2: Bootstrapping language-image pre-training with frozen image encoders and large language models},
  author={Li, Junnan and Li, Dongxu and Savarese, Silvio and Hoi, Steven},
  booktitle={International Conference on Machine Learning},
  pages={19730--19742},
  year={2023}
}

@inproceedings{jiang2024hallucination,
  title={Hallucination augmented contrastive learning for multimodal large language model},
  author={Jiang, Chaoya and Xu, Haiyang and Dong, Mengfan and Chen, Jiaxing and Ye, Wei and Yan, Ming and Ye, Qinghao and Zhang, Ji and Huang, Fei and Zhang, Shikun},
  booktitle={Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition},
  pages={27036--27046},
  year={2024}
}

@inproceedings{shao2023prompting,
  title={Prompting large language models with answer heuristics for knowledge-based visual question answering},
  author={Shao, Zhenwei and Yu, Zhou and Wang, Meng and Yu, Jun},
  booktitle={Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition},
  pages={14974--14983},
  year={2023}
}

@inproceedings{liu2024fka,
  title={FKA-Owl: Advancing Multimodal Fake News Detection through Knowledge-Augmented LVLMs},
  author={Liu, Xuannan and Li, Peipei and Huang, Huaibo and Li, Zekun and Cui, Xing and Liang, Jiahao and Qin, Lixiong and Deng, Weihong and He, Zhaofeng},
  booktitle={Proceedings of the 32nd ACM International Conference on Multimedia},
  pages={10154--10163},
  year={2024}
}

@article{massarelli2019safe,
  title={SAFE: Self-Attentive Function Embeddings for Binary Similarity},
  author={Massarelli, Luca and Di Luna, Giuseppe Antonio and Petroni, Fabio and Baldoni, Roberto and Querzoni, Leonardo},
  journal={Detection of Intrusions and Malware, and Vulnerability Assessment},
  pages={309--329},
  year={2019}
}

@inproceedings{wang2018eann,
  title={Eann: Event adversarial neural networks for multi-modal fake news detection},
  author={Wang, Yaqing and Ma, Fenglong and Jin, Zhiwei and Yuan, Ye and Xun, Guangxu and Jha, Kishlay and Su, Lu and Gao, Jing},
  booktitle={Proceedings of the 24th ACM SIGKDD International Conference on Knowledge Discovery \& Data Mining},
  pages={849--857},
  year={2018}
}

@article{li2019visualbert,
  title={Visualbert: A simple and performant baseline for vision and language},
  author={Li, Liunian Harold and Yatskar, Mark and Yin, Da and Hsieh, Cho-Jui and Chang, Kai-Wei},
  journal={arXiv preprint arXiv:1908.03557},
  year={2019}
}

@article{zhang2023detecting,
  title={Detecting out-of-context multimodal misinformation with interpretable neural-symbolic model},
  author={Zhang, Yizhou and Trinh, Loc and Cao, Defu and Cui, Zijun and Liu, Yan},
  journal={arXiv preprint arXiv:2304.07633},
  year={2023}
}

@article{paszke2019pytorch,
  title={Pytorch: An imperative style, high-performance deep learning library},
  author={Paszke, Adam and Gross, Sam and Massa, Francisco and Lerer, Adam and Bradbury, James and Chanan, Gregory and Killeen, Trevor and Lin, Zeming and Gimelshein, Natalia and Antiga, Luca and other},
  journal={Advances in Neural Information Processing Systems},
  volume={32},
  year={2019}
}

@inproceedings{dao2024flashattention,
    title={FlashAttention-2: Faster Attention with Better Parallelism and Work Partitioning},
    author={Tri Dao},
    booktitle={International Conference on Learning Representations},
    year={2024},
}

@article{loshchilov2017decoupled,
  title={Decoupled weight decay regularization},
  author={Loshchilov, I},
  journal={arXiv preprint arXiv:1711.05101},
  year={2017}
}

@inproceedings{hu2022lora,
    title={LoRA: Low-Rank Adaptation of Large Language Models},
    author={Edward J Hu and Yelong Shen and Phillip Wallis and Zeyuan Allen-Zhu and Yuanzhi Li and Shean Wang and Lu Wang and other},
    booktitle={International Conference on Learning Representations},
    year={2022}
}

@article{papadopoulos2024verite,
  title={VERITE: A Robust benchmark for multimodal misinformation detection accounting for unimodal bias},
  author={Papadopoulos, Stefanos-Iordanis and Koutlis, Christos and Papadopoulos, Symeon and Petrantonakis, Panagiotis C},
  journal={International Journal of Multimedia Information Retrieval},
  volume={13},
  number={1},
  pages={4},
  year={2024},
}

@inproceedings{confabulation,
    title = "Confabulation: The Surprising Value of Large Language Model Hallucinations",
    author = "Sui, Peiqi  and
      Duede, Eamon  and
      Wu, Sophie  and
      So, Richard",
    editor = "Ku, Lun-Wei  and
      Martins, Andre  and
      Srikumar, Vivek",
  booktitle={ACL},
    year = "2024",
    pages = "14274--14284",
}


@inproceedings{abdelnabi2022open_v1,
  title={Open-domain, content-based, multi-modal fact-checking of out-of-context images via online resources},
  author={Abdelnabi, Sahar and Hasan, Rakibul and Fritz, Mario},
  booktitle={CVPR},
  pages={14940--14949},
  year={2022}
}