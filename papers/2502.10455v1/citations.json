[
  {
    "index": 0,
    "papers": [
      {
        "key": "abdelnabi2022open",
        "author": "Abdelnabi, Sahar and Hasan, Rakibul and Fritz, Mario",
        "title": "Open-domain, content-based, multi-modal fact-checking of out-of-context images via online resources"
      }
    ]
  },
  {
    "index": 1,
    "papers": [
      {
        "key": "luo2021newsclippings",
        "author": "Luo, Grace and Darrell, Trevor and Rohrbach, Anna",
        "title": "NewsCLIPpings: Automatic Generation of Out-of-Context Multimodal Media"
      },
      {
        "key": "papadopoulos2023synthetic",
        "author": "Papadopoulos, Stefanos-Iordanis and Koutlis, Christos and Papadopoulos, Symeon and Petrantonakis, Panagiotis",
        "title": "Synthetic misinformers: Generating and combating multimodal misinformation"
      },
      {
        "key": "gu2024learning",
        "author": "Gu, Yimeng and Zhang, Mengqi and Castro, Ignacio and Wu, Shu and Tyson, Gareth",
        "title": "Learning Domain-Invariant Features for Out-of-Context News Detection"
      }
    ]
  },
  {
    "index": 2,
    "papers": [
      {
        "key": "zhang2023ecenet",
        "author": "Zhang, Fanrui and Liu, Jiawei and Zhang, Qiang and Sun, Esther and Xie, Jingyi and Zha, Zheng-Jun",
        "title": "ECENet: Explainable and Context-Enhanced Network for Muti-modal Fact verification"
      },
      {
        "key": "wang2024mmidr",
        "author": "Wang, Longzheng and Xu, Xiaohan and Zhang, Lei and Lu, Jiarui and Xu, Yongxiu and Xu, Hongbo and Zhang, Chuang",
        "title": "MMIDR: Teaching Large Language Model to Interpret Multimodal Misinformation via Knowledge Distillation"
      },
      {
        "key": "liu2024forgery",
        "author": "Liu, Huan and Tan, Zichang and Tan, Chuangchuang and Wei, Yunchao and Wang, Jingdong and Zhao, Yao",
        "title": "Forgery-aware adaptive transformer for generalizable synthetic image detection"
      }
    ]
  },
  {
    "index": 3,
    "papers": [
      {
        "key": "abdelnabi2022open",
        "author": "Abdelnabi, Sahar and Hasan, Rakibul and Fritz, Mario",
        "title": "Open-domain, content-based, multi-modal fact-checking of out-of-context images via online resources"
      }
    ]
  },
  {
    "index": 4,
    "papers": [
      {
        "key": "yuan2023support",
        "author": "Yuan, Xin and Guo, Jie and Qiu, Weidong and Huang, Zheng and Li, Shujun",
        "title": "Support or Refute: Analyzing the Stance of Evidence to Detect Out-of-Context Mis-and Disinformation"
      }
    ]
  },
  {
    "index": 5,
    "papers": [
      {
        "key": "qi2024sniffer",
        "author": "Qi, Peng and Yan, Zehong and Hsu, Wynne and Lee, Mong Li",
        "title": "SNIFFER: Multimodal Large Language Model for Explainable Out-of-Context Misinformation Detection"
      }
    ]
  },
  {
    "index": 6,
    "papers": [
      {
        "key": "vicuna2023",
        "author": "Chiang, Wei-Lin and Li, Zhuohan and Lin, Zi and Sheng, Ying and Wu, Zhanghao and Zhang, Hao and Zheng, Lianmin and Zhuang, Siyuan and Zhuang, Yonghao and Gonzalez, Joseph E. and Stoica, Ion and Xing, Eric P.",
        "title": "Vicuna: An Open-Source Chatbot Impressing GPT-4 with 90\\%* ChatGPT Quality"
      }
    ]
  },
  {
    "index": 7,
    "papers": [
      {
        "key": "zhang2023aligning",
        "author": "Zhang, Kai and Gutierrez, Bernal Jimenez and Su, Yu",
        "title": "Aligning Instruction Tasks Unlocks Large Language Models as Zero-Shot Relation Extractors"
      },
      {
        "key": "chen2024lion",
        "author": "Chen, Gongwei and Shen, Leyang and Shao, Rui and Deng, Xiang and Nie, Liqiang",
        "title": "Lion: Empowering multimodal large language model with dual-level visual knowledge"
      },
      {
        "key": "jin2024llava",
        "author": "Jin, Yizhang and Li, Jian and Zhang, Jiangning and Hu, Jianlong and Gan, Zhenye and Tan, Xin and Liu, Yong and Wang, Yabiao and Wang, Chengjie and Ma, Lizhuang",
        "title": "LLaVA-VSD: Large Language-and-Vision Assistant for Visual Spatial Description"
      }
    ]
  },
  {
    "index": 8,
    "papers": [
      {
        "key": "yang2024gpt4tools",
        "author": "Yang, Rui and Song, Lin and Li, Yanwei and Zhao, Sijie and Ge, Yixiao and Li, Xiu and Shan, Ying",
        "title": "Gpt4tools: Teaching large language model to use tools via self-instruction"
      },
      {
        "key": "wang2024mmidr",
        "author": "Wang, Longzheng and Xu, Xiaohan and Zhang, Lei and Lu, Jiarui and Xu, Yongxiu and Xu, Hongbo and Zhang, Chuang",
        "title": "MMIDR: Teaching Large Language Model to Interpret Multimodal Misinformation via Knowledge Distillation"
      },
      {
        "key": "kuckreja2024geochat",
        "author": "Kuckreja, Kartik and Danish, Muhammad Sohail and Naseer, Muzammal and Das, Abhijit and Khan, Salman and Khan, Fahad Shahbaz",
        "title": "Geochat: Grounded large vision-language model for remote sensing"
      }
    ]
  },
  {
    "index": 9,
    "papers": [
      {
        "key": "dai2023instructblip",
        "author": "Dai, Wenliang and Li, Junnan and Li, Dongxu and Tiong, Anthony Meng Huat and Zhao, Junqi and Wang, Weisheng and Li, Boyang and Fung, Pascale and Hoi, Steven",
        "title": "InstructBLIP: Towards general-purpose vision-language models with instruction tuning"
      }
    ]
  },
  {
    "index": 10,
    "papers": [
      {
        "key": "ouyang2022training",
        "author": "Ouyang, Long and Wu, Jeffrey and Jiang, Xu and Almeida, Diogo and Wainwright, Carroll and Mishkin, Pamela and Zhang, Chong and Agarwal, Sandhini and Slama, Katarina and Ray, Alex and others",
        "title": "Training language models to follow instructions with human feedback"
      }
    ]
  },
  {
    "index": 11,
    "papers": [
      {
        "key": "qi2024sniffer",
        "author": "Qi, Peng and Yan, Zehong and Hsu, Wynne and Lee, Mong Li",
        "title": "SNIFFER: Multimodal Large Language Model for Explainable Out-of-Context Misinformation Detection"
      }
    ]
  },
  {
    "index": 12,
    "papers": [
      {
        "key": "achiam2023gpt",
        "author": "Achiam, Josh and Adler, Steven and Agarwal, Sandhini and Ahmad, Lama and Akkaya, Ilge and Aleman, Florencia Leoni and Almeida, Diogo and Altenschmidt, Janko and Altman, Sam and Anadkat, Shyamal and others",
        "title": "Gpt-4 technical report"
      }
    ]
  }
]