[
  {
    "index": 0,
    "papers": [
      {
        "key": "wei2024jailbroken",
        "author": "Wei, Alexander and Haghtalab, Nika and Steinhardt, Jacob",
        "title": "Jailbroken: How does llm safety training fail?"
      },
      {
        "key": "huang2023catastrophic",
        "author": "Huang, Yangsibo and Gupta, Samyak and Xia, Mengzhou and Li, Kai and Chen, Danqi",
        "title": "Catastrophic jailbreak of open-source llms via exploiting generation"
      }
    ]
  },
  {
    "index": 1,
    "papers": [
      {
        "key": "wei2024jailbroken",
        "author": "Wei, Alexander and Haghtalab, Nika and Steinhardt, Jacob",
        "title": "Jailbroken: How does llm safety training fail?"
      }
    ]
  },
  {
    "index": 2,
    "papers": [
      {
        "key": "zou2023universal",
        "author": "Zou, Andy and Wang, Zifan and Carlini, Nicholas and Nasr, Milad and Kolter, J Zico and Fredrikson, Matt",
        "title": "Universal and transferable adversarial attacks on aligned language models"
      }
    ]
  },
  {
    "index": 3,
    "papers": [
      {
        "key": "liuautodan",
        "author": "Liu, Xiaogeng and Xu, Nan and Chen, Muhao and Xiao, Chaowei",
        "title": "AutoDAN: Generating Stealthy Jailbreak Prompts on Aligned Large Language Models"
      }
    ]
  },
  {
    "index": 4,
    "papers": [
      {
        "key": "andriushchenko2024jailbreaking",
        "author": "Andriushchenko, Maksym and Croce, Francesco and Flammarion, Nicolas",
        "title": "Jailbreaking leading safety-aligned llms with simple adaptive attacks"
      }
    ]
  },
  {
    "index": 5,
    "papers": [
      {
        "key": "nasr2023scalable",
        "author": "Nasr, Milad and Carlini, Nicholas and Hayase, Jonathan and Jagielski, Matthew and Cooper, A Feder and Ippolito, Daphne and Choquette-Choo, Christopher A and Wallace, Eric and Tram{\\`e}r, Florian and Lee, Katherine",
        "title": "Scalable extraction of training data from (production) language models"
      }
    ]
  },
  {
    "index": 6,
    "papers": [
      {
        "key": "shen2024anything",
        "author": "Shen, Xinyue and Chen, Zeyuan and Backes, Michael and Shen, Yun and Zhang, Yang",
        "title": "`` do anything now\": Characterizing and evaluating in-the-wild jailbreak prompts on large language models"
      }
    ]
  },
  {
    "index": 7,
    "papers": [
      {
        "key": "zhang2024breaking",
        "author": "Zhang, Boyang and Tan, Yicong and Shen, Yun and Salem, Ahmed and Backes, Michael and Zannettou, Savvas and Zhang, Yang",
        "title": "Breaking agents: Compromising autonomous llm agents through malfunction amplification"
      },
      {
        "key": "yang2024watch",
        "author": "Yang, Wenkai and Bi, Xiaohan and Lin, Yankai and Chen, Sishuo and Zhou, Jie and Sun, Xu",
        "title": "Watch out for your agents! investigating backdoor threats to llm-based agents"
      },
      {
        "key": "chen2024agentpoisonredteamingllmagents",
        "author": "Zhaorun Chen and Zhen Xiang and Chaowei Xiao and Dawn Song and Bo Li",
        "title": "AgentPoison: Red-teaming LLM Agents via Poisoning Memory or Knowledge Bases"
      },
      {
        "key": "zou2024poisonedrag",
        "author": "Zou, Wei and Geng, Runpeng and Wang, Binghui and Jia, Jinyuan",
        "title": "Poisonedrag: Knowledge poisoning attacks to retrieval-augmented generation of large language models"
      }
    ]
  },
  {
    "index": 8,
    "papers": [
      {
        "key": "zeng2024good",
        "author": "Zeng, Shenglai and Zhang, Jiankun and He, Pengfei and Xing, Yue and Liu, Yiding and Xu, Han and Ren, Jie and Wang, Shuaiqiang and Yin, Dawei and Chang, Yi and others",
        "title": "The good and the bad: Exploring privacy issues in retrieval-augmented generation (rag)"
      }
    ]
  },
  {
    "index": 9,
    "papers": [
      {
        "key": "debenedetti2024agentdojodynamicenvironmentevaluate",
        "author": "Edoardo Debenedetti and Jie Zhang and Mislav Balunovi\u0107 and Luca Beurer-Kellner and Marc Fischer and Florian Tram\u00e8r",
        "title": "AgentDojo: A Dynamic Environment to Evaluate Attacks and Defenses for LLM Agents"
      },
      {
        "key": "andriushchenko2024agentharm",
        "author": "Andriushchenko, Maksym and Souly, Alexandra and Dziemian, Mateusz and Duenas, Derek and Lin, Maxwell and Wang, Justin and Hendrycks, Dan and Zou, Andy and Kolter, Zico and Fredrikson, Matt and others",
        "title": "Agentharm: A benchmark for measuring harmfulness of llm agents"
      }
    ]
  },
  {
    "index": 10,
    "papers": [
      {
        "key": "chowdhury2024breakingdefensescomparativesurvey",
        "author": "Arijit Ghosh Chowdhury and Md Mofijul Islam and Vaibhav Kumar and Faysal Hossain Shezan and Vaibhav Kumar and Vinija Jain and Aman Chadha",
        "title": "Breaking Down the Defenses: A Comparative Survey of Attacks on Large Language Models"
      },
      {
        "key": "das2024securityprivacychallengeslarge",
        "author": "Badhan Chandra Das and M. Hadi Amini and Yanzhao Wu",
        "title": "Security and Privacy Challenges of Large Language Models: A Survey"
      },
      {
        "key": "shayegani2023surveyvulnerabilitieslargelanguage",
        "author": "Erfan Shayegani and Md Abdullah Al Mamun and Yu Fu and Pedram Zaree and Yue Dong and Nael Abu-Ghazaleh",
        "title": "Survey of Vulnerabilities in Large Language Models Revealed by Adversarial Attacks"
      }
    ]
  },
  {
    "index": 11,
    "papers": [
      {
        "key": "cui2024risk",
        "author": "Cui, Tianyu and Wang, Yanling and Fu, Chuanpu and Xiao, Yong and Li, Sijia and Deng, Xinhao and Liu, Yunpeng and Zhang, Qinglin and Qiu, Ziyi and Li, Peiyang and others",
        "title": "Risk taxonomy, mitigation, and assessment benchmarks of large language model systems"
      },
      {
        "key": "he2024emerged",
        "author": "He, Feng and Zhu, Tianqing and Ye, Dayong and Liu, Bo and Zhou, Wanlei and Yu, Philip S",
        "title": "The emerged security and privacy of llm agent: A survey with case studies"
      }
    ]
  }
]