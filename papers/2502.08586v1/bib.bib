@misc{chowdhury2024breakingdefensescomparativesurvey,
      title={Breaking Down the Defenses: A Comparative Survey of Attacks on Large Language Models}, 
      author={Arijit Ghosh Chowdhury and Md Mofijul Islam and Vaibhav Kumar and Faysal Hossain Shezan and Vaibhav Kumar and Vinija Jain and Aman Chadha},
      year={2024},
      eprint={2403.04786},
      archivePrefix={arXiv},
      primaryClass={cs.CR},
      url={https://arxiv.org/abs/2403.04786}, 
}
@article{hurst2024gpt,
  title={Gpt-4o system card},
  author={Hurst, Aaron and Lerer, Adam and Goucher, Adam P and Perelman, Adam and Ramesh, Aditya and Clark, Aidan and Ostrow, AJ and Welihinda, Akila and Hayes, Alan and Radford, Alec and others},
  journal={arXiv preprint arXiv:2410.21276},
  year={2024}
}
@misc{llama3,
    title={Introducing Meta Llama 3: The most capable openly available LLM to date},
    author={{Meta AI}},
    year={2024},
    url={https://ai.meta.com/blog/meta-llama-3}
}
@misc{claude3,
    title={Introducing the next generation of Claude},
    author={Anthropic},
    year={2024},
    url={https://www.anthropic.com/news/claude-3-family}
}
@inproceedings{tolpegin2020data,
  title={Data poisoning attacks against federated learning systems},
  author={Tolpegin, Vale and Truex, Stacey and Gursoy, Mehmet Emre and Liu, Ling},
  booktitle={Computer security--ESORICs 2020: 25th European symposium on research in computer security, ESORICs 2020, guildford, UK, September 14--18, 2020, proceedings, part i 25},
  pages={480--501},
  year={2020},
  organization={Springer}
}
@article{chen2017targeted,
  title={Targeted backdoor attacks on deep learning systems using data poisoning},
  author={Chen, Xinyun and Liu, Chang and Li, Bo and Lu, Kimberly and Song, Dawn},
  journal={arXiv preprint arXiv:1712.05526},
  year={2017}
}
@article{wang2024badagent,
  title={BadAgent: Inserting and Activating Backdoor Attacks in LLM Agents},
  author={Wang, Yifei and Xue, Dizhan and Zhang, Shengjie and Qian, Shengsheng},
  journal={arXiv preprint arXiv:2406.03007},
  year={2024}
}
@article{chen2024agentpoison,
  title={Agentpoison: Red-teaming llm agents via poisoning memory or knowledge bases},
  author={Chen, Zhaorun and Xiang, Zhen and Xiao, Chaowei and Song, Dawn and Li, Bo},
  journal={arXiv preprint arXiv:2407.12784},
  year={2024}
}
@article{tian2023evil,
  title={Evil geniuses: Delving into the safety of llm-based agents},
  author={Tian, Yu and Yang, Xiao and Zhang, Jingyuan and Dong, Yinpeng and Su, Hang},
  journal={arXiv preprint arXiv:2311.11855},
  year={2023}
}
@inproceedings{ning2024cheatagent,
  title={Cheatagent: Attacking llm-empowered recommender systems via llm agent},
  author={Ning, Liang-bo and Wang, Shijie and Fan, Wenqi and Li, Qing and Xu, Xin and Chen, Hao and Huang, Feiran},
  booktitle={Proceedings of the 30th ACM SIGKDD Conference on Knowledge Discovery and Data Mining},
  pages={2284--2295},
  year={2024}
}
@article{shang2024can,
  title={Can LLMs deeply detect complex malicious queries? A framework for jailbreaking via obfuscating intent},
  author={Shang, Shang and Zhao, Xinqiang and Yao, Zhongjiang and Yao, Yepeng and Su, Liya and Fan, Zijing and Zhang, Xiaodan and Jiang, Zhengwei},
  journal={The Computer Journal},
  pages={bxae124},
  year={2024},
  publisher={Oxford University Press}
}
@inproceedings{zhao2024expel,
  title={Expel: Llm agents are experiential learners},
  author={Zhao, Andrew and Huang, Daniel and Xu, Quentin and Lin, Matthieu and Liu, Yong-Jin and Huang, Gao},
  booktitle={Proceedings of the AAAI Conference on Artificial Intelligence},
  volume={38},
  number={17},
  pages={19632--19642},
  year={2024}
}
@article{huang2023catastrophic,
  title={Catastrophic jailbreak of open-source llms via exploiting generation},
  author={Huang, Yangsibo and Gupta, Samyak and Xia, Mengzhou and Li, Kai and Chen, Danqi},
  journal={arXiv preprint arXiv:2310.06987},
  year={2023}
}

@inproceedings{schwarzschild2021just,
  title={Just how toxic is data poisoning? a unified benchmark for backdoor and data poisoning attacks},
  author={Schwarzschild, Avi and Goldblum, Micah and Gupta, Arjun and Dickerson, John P and Goldstein, Tom},
  booktitle={International Conference on Machine Learning},
  pages={9389--9398},
  year={2021},
  organization={PMLR}
}
@article{yang2024watch,
  title={Watch out for your agents! investigating backdoor threats to llm-based agents},
  author={Yang, Wenkai and Bi, Xiaohan and Lin, Yankai and Chen, Sishuo and Zhou, Jie and Sun, Xu},
  journal={arXiv preprint arXiv:2402.11208},
  year={2024}
}
@misc{command-r-plus,
    title={Introducing Command R+: A Scalable LLM Built for Business},
    author={{Cohere}},
    year={2024},
    url={https://cohere.com/blog/command-r-plus-microsoft-azure}
}
@article{goldblum2022dataset,
  title={Dataset security for machine learning: Data poisoning, backdoor attacks, and defenses},
  author={Goldblum, Micah and Tsipras, Dimitris and Xie, Chulin and Chen, Xinyun and Schwarzschild, Avi and Song, Dawn and Madry, Aleksander and Li, Bo and Goldstein, Tom},
  journal={IEEE Transactions on Pattern Analysis and Machine Intelligence},
  volume={45},
  number={2},
  pages={1563--1580},
  year={2022},
  publisher={IEEE}
}

@misc{UNH,
title = {Ransomware attack has cost UnitedHealth \$872 million; total expected to surpass \$1 billion} ,
author = {The Record},
year = {2024},
note = {\href{https://therecord.media/ransomware-unitedhealth-costs-billions-still-climbing}{link}},
}

@misc{XZ,
title = {Urgent security alert for Fedora Linux 40 and Fedora Rawhide users} ,
year = {2024},
author = {Red Hat},
note = {\href{https://www.redhat.com/en/blog/urgent-security-alert-fedora-40-and-rawhide-users}{link}},
}

@article{abdin2024phi3,
      title={Phi-3 Technical Report: A Highly Capable Language Model Locally on Your Phone}, 
      author={Marah Abdin and Sam Ade Jacobs and Ammar Ahmad Awan and Jyoti Aneja and Ahmed Awadallah and Hany Awadalla and Nguyen Bach and Amit Bahree and Arash Bakhtiari and Harkirat Behl and Alon Benhaim and Misha Bilenko and Johan Bjorck and Sébastien Bubeck and Martin Cai and Caio César Teodoro Mendes and Weizhu Chen and Vishrav Chaudhary and Parul Chopra and Allie Del Giorno and Gustavo de Rosa and Matthew Dixon and Ronen Eldan and Dan Iter and Amit Garg and Abhishek Goswami and Suriya Gunasekar and Emman Haider and Junheng Hao and Russell J. Hewett and Jamie Huynh and Mojan Javaheripi and Xin Jin and Piero Kauffmann and Nikos Karampatziakis and Dongwoo Kim and Mahoud Khademi and Lev Kurilenko and James R. Lee and Yin Tat Lee and Yuanzhi Li and Chen Liang and Weishung Liu and Eric Lin and Zeqi Lin and Piyush Madan and Arindam Mitra and Hardik Modi and Anh Nguyen and Brandon Norick and Barun Patra and Daniel Perez-Becker and Thomas Portet and Reid Pryzant and Heyang Qin and Marko Radmilac and Corby Rosset and Sambudha Roy and Olatunji Ruwase and Olli Saarikivi and Amin Saied and Adil Salim and Michael Santacroce and Shital Shah and Ning Shang and Hiteshi Sharma and Xia Song and Masahiro Tanaka and Xin Wang and Rachel Ward and Guanhua Wang and Philipp Witte and Michael Wyatt and Can Xu and Jiahang Xu and Sonali Yadav and Fan Yang and Ziyi Yang and Donghan Yu and Chengruidong Zhang and Cyril Zhang and Jianwen Zhang and Li Lyna Zhang and Yi Zhang and Yue Zhang and Yunan Zhang and Xiren Zhou},
      year={2024},
      journal={arXiv preprint arXiv:2404.14219},
}
@inproceedings{hua2024trustagent,
  title={Trustagent: Towards safe and trustworthy llm-based agents through agent constitution},
  author={Hua, Wenyue and Yang, Xianjun and Jin, Mingyu and Li, Zelong and Cheng, Wei and Tang, Ruixiang and Zhang, Yongfeng},
  booktitle={Trustworthy Multi-modal Foundation Models and AI Agents (TiFA)},
  year={2024}
}
@article{perez2022red,
  title={Red teaming language models with language models},
  author={Perez, Ethan and Huang, Saffron and Song, Francis and Cai, Trevor and Ring, Roman and Aslanides, John and Glaese, Amelia and McAleese, Nat and Irving, Geoffrey},
  journal={arXiv preprint arXiv:2202.03286},
  year={2022}
}
@article{deng2023attack,
  title={Attack prompt generation for red teaming and defending large language models},
  author={Deng, Boyi and Wang, Wenjie and Feng, Fuli and Deng, Yang and Wang, Qifan and He, Xiangnan},
  journal={arXiv preprint arXiv:2310.12505},
  year={2023}
}
@inproceedings{wang2024rlhfpoison,
  title={RLHFPoison: Reward poisoning attack for reinforcement learning with human feedback in large language models},
  author={Wang, Jiongxiao and Wu, Junlin and Chen, Muhao and Vorobeychik, Yevgeniy and Xiao, Chaowei},
  booktitle={Proceedings of the 62nd Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers)},
  pages={2551--2570},
  year={2024}
}
@article{li2024personal,
  title={Personal llm agents: Insights and survey about the capability, efficiency and security},
  author={Li, Yuanchun and Wen, Hao and Wang, Weijun and Li, Xiangyu and Yuan, Yizhen and Liu, Guohong and Liu, Jiacheng and Xu, Wenxing and Wang, Xiang and Sun, Yi and others},
  journal={arXiv preprint arXiv:2401.05459},
  year={2024}
}
@article{yao2024survey,
  title={A survey on large language model (llm) security and privacy: The good, the bad, and the ugly},
  author={Yao, Yifan and Duan, Jinhao and Xu, Kaidi and Cai, Yuanfang and Sun, Zhibo and Zhang, Yue},
  journal={High-Confidence Computing},
  pages={100211},
  year={2024},
  publisher={Elsevier}
}
@article{wang2024pandora,
  title={Pandora's White-Box: Increased Training Data Leakage in Open LLMs},
  author={Wang, Jeffrey G and Wang, Jason and Li, Marvin and Neel, Seth},
  journal={arXiv preprint arXiv:2402.17012},
  year={2024}
}
@inproceedings{wang2024white,
  title={White-box multimodal jailbreaks against large vision-language models},
  author={Wang, Ruofan and Ma, Xingjun and Zhou, Hanxu and Ji, Chuanjun and Ye, Guangnan and Jiang, Yu-Gang},
  booktitle={Proceedings of the 32nd ACM International Conference on Multimedia},
  pages={6920--6928},
  year={2024}
}
@article{xue2024trojllm,
  title={Trojllm: A black-box trojan prompt attack on large language models},
  author={Xue, Jiaqi and Zheng, Mengxin and Hua, Ting and Shen, Yilin and Liu, Yepeng and B{\"o}l{\"o}ni, Ladislau and Lou, Qian},
  journal={Advances in Neural Information Processing Systems},
  volume={36},
  year={2024}
}
@article{deng2022rlprompt,
  title={Rlprompt: Optimizing discrete text prompts with reinforcement learning},
  author={Deng, Mingkai and Wang, Jianyu and Hsieh, Cheng-Ping and Wang, Yihan and Guo, Han and Shu, Tianmin and Song, Meng and Xing, Eric P and Hu, Zhiting},
  journal={arXiv preprint arXiv:2205.12548},
  year={2022}
}

@inproceedings{chen2017zoo,
  title={Zoo: Zeroth order optimization based black-box attacks to deep neural networks without training substitute models},
  author={Chen, Pin-Yu and Zhang, Huan and Sharma, Yash and Yi, Jinfeng and Hsieh, Cho-Jui},
  booktitle={Proceedings of the 10th ACM workshop on artificial intelligence and security},
  pages={15--26},
  year={2017}
}
@inproceedings{radford2021learning,
  title={Learning transferable visual models from natural language supervision},
  author={Radford, Alec and Kim, Jong Wook and Hallacy, Chris and Ramesh, Aditya and Goh, Gabriel and Agarwal, Sandhini and Sastry, Girish and Askell, Amanda and Mishkin, Pamela and Clark, Jack and others},
  booktitle={International conference on machine learning},
  pages={8748--8763},
  year={2021},
  organization={PMLR}
}
@misc{verma2024operationalizingthreatmodelredteaming,
      title={Operationalizing a Threat Model for Red-Teaming Large Language Models (LLMs)}, 
      author={Apurv Verma and Satyapriya Krishna and Sebastian Gehrmann and Madhavan Seshadri and Anu Pradhan and Tom Ault and Leslie Barrett and David Rabinowitz and John Doucette and NhatHai Phan},
      year={2024},
      eprint={2407.14937},
      archivePrefix={arXiv},
      primaryClass={cs.CL},
      url={https://arxiv.org/abs/2407.14937}, 
}

@misc{shayegani2023surveyvulnerabilitieslargelanguage,
      title={Survey of Vulnerabilities in Large Language Models Revealed by Adversarial Attacks}, 
      author={Erfan Shayegani and Md Abdullah Al Mamun and Yu Fu and Pedram Zaree and Yue Dong and Nael Abu-Ghazaleh},
      year={2023},
      eprint={2310.10844},
      archivePrefix={arXiv},
      primaryClass={cs.CL},
      url={https://arxiv.org/abs/2310.10844}, 
}

@misc{das2024securityprivacychallengeslarge,
      title={Security and Privacy Challenges of Large Language Models: A Survey}, 
      author={Badhan Chandra Das and M. Hadi Amini and Yanzhao Wu},
      year={2024},
      eprint={2402.00888},
      archivePrefix={arXiv},
      primaryClass={cs.CL},
      url={https://arxiv.org/abs/2402.00888}, 
}

@misc{wei2023jailbrokendoesllmsafety,
      title={Jailbroken: How Does LLM Safety Training Fail?}, 
      author={Alexander Wei and Nika Haghtalab and Jacob Steinhardt},
      year={2023},
      eprint={2307.02483},
      archivePrefix={arXiv},
      primaryClass={cs.LG},
      url={https://arxiv.org/abs/2307.02483}, 
}

@misc{chen2024agentpoisonredteamingllmagents,
      title={AgentPoison: Red-teaming LLM Agents via Poisoning Memory or Knowledge Bases}, 
      author={Zhaorun Chen and Zhen Xiang and Chaowei Xiao and Dawn Song and Bo Li},
      year={2024},
      eprint={2407.12784},
      archivePrefix={arXiv},
      primaryClass={cs.LG},
      url={https://arxiv.org/abs/2407.12784}, 
}

@misc{debenedetti2024agentdojodynamicenvironmentevaluate,
      title={AgentDojo: A Dynamic Environment to Evaluate Attacks and Defenses for LLM Agents}, 
      author={Edoardo Debenedetti and Jie Zhang and Mislav Balunović and Luca Beurer-Kellner and Marc Fischer and Florian Tramèr},
      year={2024},
      eprint={2406.13352},
      archivePrefix={arXiv},
      primaryClass={cs.CR},
      url={https://arxiv.org/abs/2406.13352}, 
}

@misc{yang2024watchagentsinvestigatingbackdoor,
      title={Watch Out for Your Agents! Investigating Backdoor Threats to LLM-Based Agents}, 
      author={Wenkai Yang and Xiaohan Bi and Yankai Lin and Sishuo Chen and Jie Zhou and Xu Sun},
      year={2024},
      eprint={2402.11208},
      archivePrefix={arXiv},
      primaryClass={cs.CR},
      url={https://arxiv.org/abs/2402.11208}, 
}

@article{weng2023agent,
  title   = {LLM-powered Autonomous Agents},
  author  = {Lilian Weng},
  journal = {lilianweng.github.io},
  year    = {2023},
  month   = {Jun},
  url     = {https://lilianweng.github.io/posts/2023-06-23-agent/}
}

@article{andres2023chemcrow,
  title={ChemCrow: Augmenting large-language models with chemistry tools},
  author={Bran, Andres M. and Cox, Sam and Schilter, Oliver and White, Andrew D. and Schwaller, Philippe},
  journal={arXiv preprint arXiv:2304.05376},
  year={2023}
}

@article{skarlinski2024paperqa,
  title={Language agents achieve superhuman synthesis of scientific knowledge},
  author={Skarlinski, Michael D. and Cox, Sam and Laurent, Jon M. and Braza, James D. and Hinks, Michaela and Hammerling, Michael J. and Ponnapati, Manvitha and Rodriques, Samuel G. and White, Andrew D.},
  journal={arXiv preprint arXiv:2409.13740},
  year={2024}
}

@article{nasr2023scalable,
  title={Scalable extraction of training data from (production) language models},
  author={Nasr, Milad and Carlini, Nicholas and Hayase, Jonathan and Jagielski, Matthew and Cooper, A Feder and Ippolito, Daphne and Choquette-Choo, Christopher A and Wallace, Eric and Tram{\`e}r, Florian and Lee, Katherine},
  journal={arXiv preprint arXiv:2311.17035},
  year={2023}
}

@inproceedings{liuautodan,
  title={AutoDAN: Generating Stealthy Jailbreak Prompts on Aligned Large Language Models},
  author={Liu, Xiaogeng and Xu, Nan and Chen, Muhao and Xiao, Chaowei},
  booktitle={The Twelfth International Conference on Learning Representations},
  year={2024}
}

@article{zou2023universal,
  title={Universal and transferable adversarial attacks on aligned language models},
  author={Zou, Andy and Wang, Zifan and Carlini, Nicholas and Nasr, Milad and Kolter, J Zico and Fredrikson, Matt},
  journal={arXiv preprint arXiv:2307.15043},
  year={2023}
}

@article{andriushchenko2024jailbreaking,
  title={Jailbreaking leading safety-aligned llms with simple adaptive attacks},
  author={Andriushchenko, Maksym and Croce, Francesco and Flammarion, Nicolas},
  journal={arXiv preprint arXiv:2404.02151},
  year={2024}
}

@inproceedings{shen2024anything,
  title={`` do anything now": Characterizing and evaluating in-the-wild jailbreak prompts on large language models},
  author={Shen, Xinyue and Chen, Zeyuan and Backes, Michael and Shen, Yun and Zhang, Yang},
  booktitle={Proceedings of the 2024 on ACM SIGSAC Conference on Computer and Communications Security},
  pages={1671--1685},
  year={2024}
}

@article{zhang2024breaking,
  title={Breaking agents: Compromising autonomous llm agents through malfunction amplification},
  author={Zhang, Boyang and Tan, Yicong and Shen, Yun and Salem, Ahmed and Backes, Michael and Zannettou, Savvas and Zhang, Yang},
  journal={arXiv preprint arXiv:2407.20859},
  year={2024}
}

@article{zou2024poisonedrag,
  title={Poisonedrag: Knowledge poisoning attacks to retrieval-augmented generation of large language models},
  author={Zou, Wei and Geng, Runpeng and Wang, Binghui and Jia, Jinyuan},
  journal={arXiv preprint arXiv:2402.07867},
  year={2024}
}

@article{zeng2024good,
  title={The good and the bad: Exploring privacy issues in retrieval-augmented generation (rag)},
  author={Zeng, Shenglai and Zhang, Jiankun and He, Pengfei and Xing, Yue and Liu, Yiding and Xu, Han and Ren, Jie and Wang, Shuaiqiang and Yin, Dawei and Chang, Yi and others},
  journal={arXiv preprint arXiv:2402.16893},
  year={2024}
}

@article{andriushchenko2024agentharm,
  title={Agentharm: A benchmark for measuring harmfulness of llm agents},
  author={Andriushchenko, Maksym and Souly, Alexandra and Dziemian, Mateusz and Duenas, Derek and Lin, Maxwell and Wang, Justin and Hendrycks, Dan and Zou, Andy and Kolter, Zico and Fredrikson, Matt and others},
  journal={arXiv preprint arXiv:2410.09024},
  year={2024}
}

@article{inan2023llama,
  title={Llama guard: Llm-based input-output safeguard for human-ai conversations},
  author={Inan, Hakan and Upasani, Kartikeya and Chi, Jianfeng and Rungta, Rashi and Iyer, Krithika and Mao, Yuning and Tontchev, Michael and Hu, Qing and Fuller, Brian and Testuggine, Davide and others},
  journal={arXiv preprint arXiv:2312.06674},
  year={2023}
}

@article{wang2024defending,
  title={Defending llms against jailbreaking attacks via backtranslation},
  author={Wang, Yihan and Shi, Zhouxing and Bai, Andrew and Hsieh, Cho-Jui},
  journal={arXiv preprint arXiv:2402.16459},
  year={2024}
}

@article{liu2023jailbreaking,
  title={Jailbreaking chatgpt via prompt engineering: An empirical study},
  author={Liu, Yi and Deng, Gelei and Xu, Zhengzi and Li, Yuekang and Zheng, Yaowen and Zhang, Ying and Zhao, Lida and Zhang, Tianwei and Wang, Kailong and Liu, Yang},
  journal={arXiv preprint arXiv:2305.13860},
  year={2023}
}

@article{wei2024jailbroken,
  title={Jailbroken: How does llm safety training fail?},
  author={Wei, Alexander and Haghtalab, Nika and Steinhardt, Jacob},
  journal={Advances in Neural Information Processing Systems},
  volume={36},
  year={2024}
}

@article{cui2024risk,
  title={Risk taxonomy, mitigation, and assessment benchmarks of large language model systems},
  author={Cui, Tianyu and Wang, Yanling and Fu, Chuanpu and Xiao, Yong and Li, Sijia and Deng, Xinhao and Liu, Yunpeng and Zhang, Qinglin and Qiu, Ziyi and Li, Peiyang and others},
  journal={arXiv preprint arXiv:2401.05778},
  year={2024}
}

@article{he2024emerged,
  title={The emerged security and privacy of llm agent: A survey with case studies},
  author={He, Feng and Zhu, Tianqing and Ye, Dayong and Liu, Bo and Zhou, Wanlei and Yu, Philip S},
  journal={arXiv preprint arXiv:2407.19354},
  year={2024}
}

@article{gur2023real,
  title={A real-world webagent with planning, long context understanding, and program synthesis},
  author={Gur, Izzeddin and Furuta, Hiroki and Huang, Austin and Safdari, Mustafa and Matsuo, Yutaka and Eck, Douglas and Faust, Aleksandra},
  journal={arXiv preprint arXiv:2307.12856},
  year={2023}
}

@article{he2024webvoyager,
  title={WebVoyager: Building an End-to-End Web Agent with Large Multimodal Models},
  author={He, Hongliang and Yao, Wenlin and Ma, Kaixin and Yu, Wenhao and Dai, Yong and Zhang, Hongming and Lan, Zhenzhong and Yu, Dong},
  journal={arXiv preprint arXiv:2401.13919},
  year={2024}
}

@article{zhou2023webarena,
  title={Webarena: A realistic web environment for building autonomous agents},
  author={Zhou, Shuyan and Xu, Frank F and Zhu, Hao and Zhou, Xuhui and Lo, Robert and Sridhar, Abishek and Cheng, Xianyi and Ou, Tianyue and Bisk, Yonatan and Fried, Daniel and others},
  journal={arXiv preprint arXiv:2307.13854},
  year={2023}
}


@misc{openai2025operator,
  author       = {OpenAI},
  title        = {Introducing Operator},
  year         = {2025},
  month        = {January 23},
  howpublished = {\url{https://openai.com/index/introducing-operator/}},
  urldate      = {2025-02-07}
}

@misc{deepmind2025projectmariner,
  author       = {Google DeepMind},
  title        = {Project Mariner},
  howpublished = {\url{https://deepmind.google/technologies/project-mariner/}},
  year         = {2024},
  urldate      = {2025-02-07}
}

@misc{anthropic2024computeruse,
  author       = {Anthropic},
  title        = {Introducing computer use, a new Claude 3.5 Sonnet, and Claude 3.5 Haiku},
  year         = {2024},
  month        = {October 22},
  howpublished = {\url{https://www.anthropic.com/news/3-5-models-and-computer-use}},
  urldate      = {2025-02-07}
}

@misc{please2025,
  author       = {MultiOn},
  title        = {We are now Please: A new consumer AI company},
  howpublished = {\url{https://please.ai/}},
  note         = {Homepage of Please Platforms (formerly MultiOn). Retrieved February 07, 2025.},
  year         = {2024},
  urldate      = {2025-02-07}
}

@article{putta2024agent,
  title={Agent q: Advanced reasoning and learning for autonomous ai agents},
  author={Putta, Pranav and Mills, Edmund and Garg, Naman and Motwani, Sumeet and Finn, Chelsea and Garg, Divyansh and Rafailov, Rafael},
  journal={arXiv preprint arXiv:2408.07199},
  year={2024}
}