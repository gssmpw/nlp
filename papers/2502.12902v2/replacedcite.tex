\section{Related work}
In order to assess uncertainties in machine learning models, a variety of approaches are available; for a detailed overview compare ____. The most common way to perform uncertainty quantification is under the \textbf{Bayesian paradigm}. By utilizing Monte Carlo dropout during the inference phase of a neural network, ____ show that the corresponding predictive distribution is a Bayesian approximation of a deep Gaussian process. While the approach requires no additional training, the approximation does not hold for all architectures and no uncertainty information is used in the training process. Another method that has been popularized in deep learning recently is the Laplace approximation ____. It builds on the idea that, in a Bayesian setting, the posterior distribution over the network weights can be approximated by a Gaussian distribution, centered around a local maximum. The advantage is that this local maximum is available by regular training, while the covariance matrix of the Gaussian can be recovered by efficient approximations of the Hessian of the loss function ____. 

A different class of approaches to uncertainty quantification is given by \textbf{ensemble methods}, where the main idea is to obtain an ensemble of predictions that differ slightly from each other and act as an empirical predictive distribution. A common way to utilize this for neural networks is to use so-called deep ensembles ____, where the ensemble is created by training several networks separately, with each optimization leading to a different local minimum. Although this has shown to perform well in practice, it is hindered by the computational demands of training multiple neural networks. Another method to obtain ensembles is by perturbing the input data before the forward pass through the model, which leads to an ensemble-based distribution in the output. This approach is used mainly in dynamical systems and weather forecasting ____. However, this requires additional fine-tuning of the input perturbations and can lead to instabilities in the model predictions.

Finally, another way of uncertainty quantification is provided by \textbf{scoring rule}-based approaches. A scoring rule ____ assigns a numerical score to a distribution-observation pair and can be minimized as a loss function, in order to fit a predictive distribution. Scoring rule approaches have been combined with nonparametric distributional regression ____, or neural networks ____, including multivariate cases ____. However, to the best of our knowledge, scoring rule approaches have not yet been transferred to the infinite-dimensional setting.

Since neural operators map to function spaces, the previously mentioned approaches need to be adjusted for \textbf{uncertainty quantification in infinite-dimensional spaces}. ____ and ____ extend the Laplace approximation to Fourier neural operators, by performing the approximation in the last layers of the Fourier domain. While this approach is efficient to implement and requires no additional training, the assumption of a Gaussian can be restrictive, especially when it comes to calibration. Furthermore, the method is only applied post-hoc and no uncertainty information is used in the training process. ____ propose an uncertainty quantification method that utilizes an information bottleneck and a Gaussian distribution to recover mean and standard deviations in the output space. However, this approach only leads to an estimate of the mean and standard deviation and does not allow for other measures of uncertainty. ____ propose a quantile neural operator that is based on conformal prediction and provides a risk-controlling prediction set that includes the true solution with a user-specified probability. While this approach leads to a risk control for the error of the neural operator, it does not lead to a predictive distribution that can be used for assessing the full uncertainty in the prediction. In a different line of work, ____ utilize the deep ensemble and Monte Carlo dropout methods as baselines, as they can be extended to the infinite-dimensional setting in a straightforward manner, leading to a functional ensemble prediction. However, the usability of the deep ensemble approach is limited by the computational overhead of training multiple models independently, especially if a large number of ensembles are required.

To the best of our knowledge, there are no other methods than those mentioned above that are specifically designed to combine uncertainty quantification with neural operators. Our work overcomes the previously discussed limitations, as it provides a predictive distribution that is directly incorporated into the training process by combining neural operators with scoring rule training.