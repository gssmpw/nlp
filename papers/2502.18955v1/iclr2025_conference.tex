
\documentclass{article} % For LaTeX2e
\usepackage{iclr2025_conference,times}

% Optional math commands from https://github.com/goodfeli/dlbook_notation.
\input{math_commands.tex}

\usepackage{hyperref}
\usepackage{url}

\usepackage{amsmath}
\usepackage{amssymb}
\usepackage{mathtools}
\usepackage{amsthm}
\usepackage{xcolor}
\usepackage{microtype}
\usepackage{graphicx}
\usepackage{subfigure}
\usepackage{booktabs} % for professional tables


\usepackage{algorithm}
\usepackage{algorithmic}

\usepackage[utf8]{inputenc} % allow utf-8 input
\usepackage[T1]{fontenc}    % use 8-bit T1 fonts
\usepackage{hyperref}       % hyperlinks
\usepackage{url}            % simple URL typesetting
\usepackage{booktabs}       % professional-quality tables
\usepackage{amsfonts}       % blackboard math symbols
\usepackage{nicefrac}       % compact symbols for 1/2, etc.
\usepackage{microtype}      % microtypography
\usepackage{xcolor}         % colors

% \theoremstyle{plain}
\newtheorem{theorem}{Theorem}[section]
\newtheorem{proposition}[theorem]{Proposition}
\newtheorem{lemma}[theorem]{Lemma}
\newtheorem{corollary}[theorem]{Corollary}
\newtheorem{definition}[theorem]{Definition}
\newtheorem{assumption}[theorem]{Assumption}
\newtheorem{remark}[theorem]{Remark}

\usepackage[textsize=tiny]{todonotes}

\newcount\Comments  % 0 suppresses notes to selves in text
\Comments = 1
\newcommand{\kibitz}[2]{\ifnum\Comments=1{\color{#1}{#2}}\fi}
\newcommand{\tw}[1]{\kibitz{red}{#1}}

\usepackage{xcolor}
\newcommand\TODO[1]{\textcolor{red}{[TODO: #1]}}
\newcommand\CHANGE[1]{\textcolor{blue}{#1}}
\input{math_commands.tex}
\newcommand{\shortn}{\textup{\texttt{-}}}
\newcommand{\shorte}{\textup{\texttt{=}}}
\newcommand{\shortp}{\textup{\texttt{+}}}
\newcommand{\shortl}{\textup{\texttt{<}}}
\newcommand{\shortg}{\textup{\texttt{>}}}
\newcommand{\ie}{\textit{i}.\textit{e}.}
\newcommand{\eg}{\textit{e}.\textit{g}.}
\newcommand{\etal}{\textit{et al}.}
\newcommand{\etc}{\textit{etc}.}
\newcommand{\Tau}{\mathrm{T}}
\newcommand{\name}{\textsc{ReDOR}}
\newcommand{\rdcshort}{\mathtt{rdc}}
\newcommand{\namep}{$\mathtt{Prioritized}$}
\newcommand{\nameo}{$\mathtt{Complete\ Dataset}$}
\newcommand{\nameh}{$\mathtt{Top}\ x\%\ \mathtt{BC}$ }
\newcommand{\namer}{$\mathtt{Random}$}
\newcommand{\namec}{$\mathtt{No\ Cluster}$}
\newcommand{\namei}{$\mathtt{Single\ Round}$}
\newcommand{\nameq}{$\mathtt{Q\ Target}$}
\newcommand{\tact}{Transform2Act}

\newcommand{\originalant}{Handcrafted Robot}
\newcommand{\locomotionft}{Locomotion on Flat Terrain}
\newcommand{\locomotionvt}{Locomotion on Variable Terrain}
\newcommand{\escape}{Escape Bowl}
\newcommand{\pointnav}{Point Navigation}
\newcommand{\manipulationbox}{Manipulate Box}
\newcommand{\patrol}{Patrol}

\usepackage{thm-restate}

\title{Fewer May Be Better: Enhancing Offline Reinforcement Learning with Reduced Dataset}

% \title{ReDOR: Reduced Dataset for Offline Reinforcement Learning}

% Authors must not appear in the submitted version. They should be hidden
% as long as the \iclrfinalcopy macro remains commented out below.
% Non-anonymous submissions will be rejected without review.

\author{
	Yiqin Yang$^1$, Quanwei Wang$^2$, Chenghao Li$^2$, Hao Hu$^2$, Chengjie Wu$^2$, Yuhua Jiang$^2$, \\ 
	\textbf{Dianyu Zhong$^2$, Ziyou Zhang$^2$, Qianchuan Zhao$^2$, Chongjie Zhang$^3$, Bo Xu$^1$\footnotemark[2]} \\
    $^1$The Key Laboratory of Cognition and Decision Intelligence for Complex Systems, \\ 
    \ \ Institute of Automation, Chinese Academy of Sciences \\
    $^2$Tsinghua University \\ 
    $^3$Washington University in St. Louis \\
    \texttt{yiqin.yang@ia.ac.cn}
}

% The \author macro works with any number of authors. There are two commands
% used to separate the names and addresses of multiple authors: \And and \AND.
%
% Using \And between authors leaves it to \LaTeX{} to determine where to break
% the lines. Using \AND forces a linebreak at that point. So, if \LaTeX{}
% puts 3 of 4 authors names on the first line, and the last on the second
% line, try using \AND instead of \And before the third author name.

\newcommand{\fix}{\marginpar{FIX}}
\newcommand{\new}{\marginpar{NEW}}

\iclrfinalcopy % Uncomment for camera-ready version, but NOT for submission.
\begin{document}


\maketitle

\renewcommand{\thefootnote}{\fnsymbol{footnote}}
\footnotetext[2]{Corresponding Author}

\begin{abstract}
% Research in offline reinforcement learning (RL) marks a paradigm shift in RL.
% However, a critical yet under-investigated aspect of offline RL is determining the subset of the offline dataset, which is used to improve algorithm performance while accelerating algorithm training. Moreover, the size of reduced datasets can uncover the requisite offline data volume essential for addressing analogous challenges.
% Based on the above considerations, we propose identifying Reduced Datasets for Offline RL (\name) by formulating it as a gradient approximation optimization problem. 
% We prove that the common actor-critic framework in reinforcement learning can be transformed into a submodular objective.
% This insight enables us to construct a subset by adopting the orthogonal matching pursuit (OMP).
% Specifically, we have made several critical modifications to OMP to enable successful adaptation with Offline RL algorithms.
% The experimental results indicate that the data subsets constructed by the ReDOR can significantly improve algorithm performance with low computational complexity.
Offline reinforcement learning (RL) represents a significant shift in RL research, allowing agents to learn from pre-collected datasets without further interaction with the environment. A key, yet underexplored, challenge in offline RL is selecting an optimal subset of the offline dataset that enhances both algorithm performance and training efficiency. Reducing dataset size can also reveal the minimal data requirements necessary for solving similar problems.
In response to this challenge, we introduce ReDOR (Reduced Datasets for Offline RL), a method that frames dataset selection as a gradient approximation optimization problem. We demonstrate that the widely used actor-critic framework in RL can be reformulated as a submodular optimization objective, enabling efficient subset selection. To achieve this, we adapt orthogonal matching pursuit (OMP), incorporating several novel modifications tailored for offline RL.
Our experimental results show that the data subsets identified by ReDOR not only boost algorithm performance but also do so with significantly lower computational complexity.
\end{abstract}

\input{text/1-Introduction}
\input{text/2-Preliminary}
\input{text/3-Method.tex}
\input{text/3.1-Theorey}
\input{text/4-Experiments}
% \input{text/A-RelatedWork}
\input{text/5-Discussion}

\bibliography{iclr2025_conference}
\bibliographystyle{iclr2025_conference}

\newpage
\appendix
\onecolumn
% \input{text/A0-algorithm}
% \input{text/A-RelatedWork}
\input{text/B-Proofs}
\input{text/D-AddiExp}
\input{text/D1-Visual}
\input{text/C-ExpDetails}
% \input{text/E-checklist}

\end{document}
