\section{Related Work}
\paragraph{In-Context Learning.}
Initially popularized by GPT-3 ____, in-context learning has garnered extensive attention for its surprising ability to generalize with just a few example prompts. Many investigations center on how transformers might implicitly perform gradient descent or implement other adaptation mechanisms in their hidden activations ____ . See **Brown et al., "Language Models play Chess from My Fingers"**__**Henderson and Stancliffe, "In-Context Learning: A Brief Survey"** for surveys on the topic. However, these analyses often assume real-valued examples and very simple data distributions, leaving room to explore richer compositional structures that can align with natural language tasks.

\paragraph{Chain-of-Thought.}
CoT prompting **Wang et al., "Chain-of-Thought Prompting"** has emerged as an effective technique for eliciting more interpretable (and sometimes more accurate) intermediate reasoning from large language models. Despite empirical successes, debate persists as to whether models truly learn a generalized reasoning algorithm or simply latch onto superficial features ____ . While some efforts **Liu et al., "Chain-of-Thought Prompting: A Survey"** systematically study CoT's potential, they often rely on limited or handcrafted tasks that do not fully capture the complexity of multi-step compositional processes.

\paragraph{Synthetic Tasks for Controlled Model Analysis.}
Synthetic tasks provide controlled environments that enable precise interventions, ablation studies, and theoretical insights into the model behavior and training dynamics ____ . However, existing synthetic settings generally remain numeric and follow overly restrictive Markovian assumptions **Bengio et al., "Markov Chain Models of Text Generation"** (e.g., a single parent for each token). Our proposed \coticl~extends these efforts by decoupling the causal structure from token-processing functions. We leverage directed acyclic graphs (DAGs) to control the branching factor in the chain generation, and MLPs for varied levels of token transformations. This design grants extensive configurability, encompassing vocabulary size, multi-input example length, chain length, DAG sparsity, MLP depth, activations and more.

\paragraph{Chain-of-Thought \& Compositional Reasoning.}
Recent studies focus on dissecting CoT to assess how compositionality might emerge from ICL. For instance, **Chen et al., "Decomposing Chain-of-Thought Prompting"** examines how CoT might be effectively disentangled into filtering and learning components in the prompt. Furthermore, our work can be treated as a generalization of the \texttt{MechanisticProbe} approach by **Liu et al., "Measuring Emergent Reasoning"** where the filtering and reasoning tree construction process is not limited by the availability of natural language datasets.  While these and related efforts **Seymo et al., "Chain-of-Thought Prompting for Compositional Reasoning"** represent significant progress toward understanding emergent reasoning, their experimental setups typically do not offer the level of systematic and fine-grained complexity that \coticl~enables.

\bigskip


\vspace{-5mm}