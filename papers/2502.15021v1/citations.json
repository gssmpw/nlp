[
  {
    "index": 0,
    "papers": [
      {
        "key": "weinzaepfel2023croco",
        "author": "Weinzaepfel, Philippe and Lucas, Thomas and Leroy, Vincent and Cabon, Yohann and Arora, Vaibhav and Br{\\'e}gier, Romain and Csurka, Gabriela and Antsfeld, Leonid and Chidlovskii, Boris and Revaud, J{\\'e}r{\\^o}me",
        "title": "CroCo v2: Improved cross-view completion pre-training for stereo matching and optical flow"
      },
      {
        "key": "heo2025rotary",
        "author": "Heo, Byeongho and Park, Song and Han, Dongyoon and Yun, Sangdoo",
        "title": "Rotary position embedding for vision transformer"
      },
      {
        "key": "fuller2024lookhere",
        "author": "Anthony Fuller and Daniel Kyrollos and Yousef Yassin and James R Green",
        "title": "LookHere: Vision Transformers with Directed Attention Generalize and Extrapolate"
      }
    ]
  },
  {
    "index": 1,
    "papers": [
      {
        "key": "woo2023convnext",
        "author": "Woo, Sanghyun and Debnath, Shoubhik and Hu, Ronghang and Chen, Xinlei and Liu, Zhuang and Kweon, In So and Xie, Saining",
        "title": "Convnext v2: Co-designing and scaling convnets with masked autoencoders"
      }
    ]
  },
  {
    "index": 2,
    "papers": [
      {
        "key": "darcet2024vision",
        "author": "Timoth{\\'e}e Darcet and Maxime Oquab and Julien Mairal and Piotr Bojanowski",
        "title": "Vision Transformers Need Registers"
      }
    ]
  },
  {
    "index": 3,
    "papers": [
      {
        "key": "darcet2024vision",
        "author": "Timoth{\\'e}e Darcet and Maxime Oquab and Julien Mairal and Piotr Bojanowski",
        "title": "Vision Transformers Need Registers"
      }
    ]
  },
  {
    "index": 4,
    "papers": [
      {
        "key": "dong2024hymbahybridheadarchitecturesmall",
        "author": "Xin Dong and Yonggan Fu and Shizhe Diao and Wonmin Byeon and Zijia Chen and Ameya Sunil Mahabaleshwarkar and Shih-Yang Liu and Matthijs Van Keirsbilck and Min-Hung Chen and Yoshi Suhara and Yingyan Lin and Jan Kautz and Pavlo Molchanov",
        "title": "Hymba: A Hybrid-head Architecture for Small Language Models"
      },
      {
        "key": "vaquero2024lost",
        "author": "Vaquero, Lorenzo and Xu, Yihong and Alameda-Pineda, Xavier and Brea, V{\\'\\i}ctor M and Mucientes, Manuel",
        "title": "Lost and found: Overcoming detector failures in online multi-object tracking"
      },
      {
        "key": "leigh2024tokenization",
        "author": "Leigh, Matthew and Klein, Samuel and Charton, Fran{\\c{c}}ois and Golling, Tobias and Heinrich, Lukas and Kagan, Michael and Ochoa, In{\\^e}s and Osadchy, Margarita",
        "title": "Is Tokenization Needed for Masked Particle Modelling?"
      },
      {
        "key": "messaoud2025towards",
        "author": "Messaoud, Kaouther and Cord, Matthieu and Alahi, Alexandre",
        "title": "Towards Generalizable Trajectory Prediction Using Dual-Level Representation Learning And Adaptive Prompting"
      },
      {
        "key": "hu2024fm",
        "author": "Hu, Yang and Wang, Xiao and Wu, Lirong and Zhang, Huatian and Li, Stan Z and Wang, Sheng and Chen, Tianlong",
        "title": "FM-TS: Flow Matching for Time Series Generation"
      },
      {
        "key": "thimonier2024t",
        "author": "Thimonier, Hugo and Costa, Jos{\\'e} Lucas De Melo and Popineau, Fabrice and Rimmel, Arpad and Doan, Bich-Li{\\^e}n",
        "title": "T-JEPA: Augmentation-Free Self-Supervised Learning for Tabular Data"
      },
      {
        "key": "omranpour2024higher",
        "author": "Omranpour, Soroush and Rabusseau, Guillaume and Rabbany, Reihaneh",
        "title": "Higher Order Transformers: Enhancing Stock Movement Prediction On Multimodal Time-Series Data"
      }
    ]
  },
  {
    "index": 5,
    "papers": [
      {
        "key": "ryali2023hiera",
        "author": "Ryali, Chaitanya and Hu, Yuan-Ting and Bolya, Daniel and Wei, Chen and Fan, Haoqi and Huang, Po-Yao and Aggarwal, Vaibhav and Chowdhury, Arkabandhu and Poursaeed, Omid and Hoffman, Judy and others",
        "title": "Hiera: A hierarchical vision transformer without the bells-and-whistles"
      }
    ]
  },
  {
    "index": 6,
    "papers": [
      {
        "key": "liu2021swin",
        "author": "Liu, Ze and Lin, Yutong and Cao, Yue and Hu, Han and Wei, Yixuan and Zhang, Zheng and Lin, Stephen and Guo, Baining",
        "title": "Swin transformer: Hierarchical vision transformer using shifted windows"
      }
    ]
  },
  {
    "index": 7,
    "papers": [
      {
        "key": "fan2021multiscale",
        "author": "Fan, Haoqi and Xiong, Bo and Mangalam, Karttikeya and Li, Yanghao and Yan, Zhicheng and Malik, Jitendra and Feichtenhofer, Christoph",
        "title": "Multiscale vision transformers"
      }
    ]
  },
  {
    "index": 8,
    "papers": [
      {
        "key": "ryali2023hiera",
        "author": "Ryali, Chaitanya and Hu, Yuan-Ting and Bolya, Daniel and Wei, Chen and Fan, Haoqi and Huang, Po-Yao and Aggarwal, Vaibhav and Chowdhury, Arkabandhu and Poursaeed, Omid and Hoffman, Judy and others",
        "title": "Hiera: A hierarchical vision transformer without the bells-and-whistles"
      }
    ]
  },
  {
    "index": 9,
    "papers": [
      {
        "key": "he2022masked",
        "author": "He, Kaiming and Chen, Xinlei and Xie, Saining and Li, Yanghao and Doll{\\'a}r, Piotr and Girshick, Ross",
        "title": "Masked autoencoders are scalable vision learners"
      }
    ]
  },
  {
    "index": 10,
    "papers": [
      {
        "key": "cai2023efficientvit",
        "author": "Cai, Han and Li, Junyan and Hu, Muyan and Gan, Chuang and Han, Song",
        "title": "Efficientvit: Lightweight multi-scale attention for high-resolution dense prediction"
      }
    ]
  },
  {
    "index": 11,
    "papers": [
      {
        "key": "yun2024shvit",
        "author": "Yun, Seokju and Ro, Youngmin",
        "title": "SHViT: Single-Head Vision Transformer with Memory Efficient Macro Design"
      }
    ]
  },
  {
    "index": 12,
    "papers": [
      {
        "key": "qin2025mobilenetv4",
        "author": "Qin, Danfeng and Leichner, Chas and Delakis, Manolis and Fornoni, Marco and Luo, Shixin and Yang, Fan and Wang, Weijun and Banbury, Colby and Ye, Chengxi and Akin, Berkin and others",
        "title": "MobileNetV4: Universal Models for the Mobile Ecosystem"
      }
    ]
  },
  {
    "index": 13,
    "papers": [
      {
        "key": "howard2017mobilenets",
        "author": "Howard, Andrew G",
        "title": "Mobilenets: Efficient convolutional neural networks for mobile vision applications"
      },
      {
        "key": "sandler2018mobilenetv2",
        "author": "Sandler, Mark and Howard, Andrew and Zhu, Menglong and Zhmoginov, Andrey and Chen, Liang-Chieh",
        "title": "Mobilenetv2: Inverted residuals and linear bottlenecks"
      },
      {
        "key": "howard2019searching",
        "author": "Howard, Andrew and Sandler, Mark and Chu, Grace and Chen, Liang-Chieh and Chen, Bo and Tan, Mingxing and Wang, Weijun and Zhu, Yukun and Pang, Ruoming and Vasudevan, Vijay and others",
        "title": "Searching for mobilenetv3"
      },
      {
        "key": "han2020ghostnet",
        "author": "Han, Kai and Wang, Yunhe and Tian, Qi and Guo, Jianyuan and Xu, Chunjing and Xu, Chang",
        "title": "Ghostnet: More features from cheap operations"
      },
      {
        "key": "tan2019mnasnet",
        "author": "Tan, Mingxing and Chen, Bo and Pang, Ruoming and Vasudevan, Vijay and Sandler, Mark and Howard, Andrew and Le, Quoc V",
        "title": "Mnasnet: Platform-aware neural architecture search for mobile"
      },
      {
        "key": "vasu2023mobileone",
        "author": "Vasu, Pavan Kumar Anasosalu and Gabriel, James and Zhu, Jeff and Tuzel, Oncel and Ranjan, Anurag",
        "title": "Mobileone: An improved one millisecond mobile backbone"
      }
    ]
  },
  {
    "index": 14,
    "papers": [
      {
        "key": "qin2025mobilenetv4",
        "author": "Qin, Danfeng and Leichner, Chas and Delakis, Manolis and Fornoni, Marco and Luo, Shixin and Yang, Fan and Wang, Weijun and Banbury, Colby and Ye, Chengxi and Akin, Berkin and others",
        "title": "MobileNetV4: Universal Models for the Mobile Ecosystem"
      }
    ]
  },
  {
    "index": 15,
    "papers": [
      {
        "key": "dosovitskiy2021an",
        "author": "Alexey Dosovitskiy and Lucas Beyer and Alexander Kolesnikov and Dirk Weissenborn and Xiaohua Zhai and Thomas Unterthiner and Mostafa Dehghani and Matthias Minderer and Georg Heigold and Sylvain Gelly and Jakob Uszkoreit and Neil Houlsby",
        "title": "An Image is Worth 16x16 Words: Transformers for Image Recognition at Scale"
      }
    ]
  },
  {
    "index": 16,
    "papers": [
      {
        "key": "vasufastvit2023",
        "author": "Pavan Kumar Anasosalu Vasu and James Gabriel and Jeff Zhu and Oncel Tuzel and Anurag Ranjan",
        "title": "FastViT:  A Fast Hybrid Vision Transformer using Structural Reparameterization"
      },
      {
        "key": "mehta2021mobilevit",
        "author": "Mehta, Sachin and Rastegari, Mohammad",
        "title": "Mobilevit: light-weight, general-purpose, and mobile-friendly vision transformer"
      },
      {
        "key": "mehta2022separable",
        "author": "Mehta, Sachin and Rastegari, Mohammad",
        "title": "Separable self-attention for mobile vision transformers"
      },
      {
        "key": "li2023rethinking",
        "author": "Li, Yanyu and Hu, Ju and Wen, Yang and Evangelidis, Georgios and Salahi, Kamyar and Wang, Yanzhi and Tulyakov, Sergey and Ren, Jian",
        "title": "Rethinking vision transformers for mobilenet size and speed"
      },
      {
        "key": "pan2022edgevits",
        "author": "Pan, Junting and Bulat, Adrian and Tan, Fuwen and Zhu, Xiatian and Dudziak, Lukasz and Li, Hongsheng and Tzimiropoulos, Georgios and Martinez, Brais",
        "title": "Edgevits: Competing light-weight cnns on mobile devices with vision transformers"
      },
      {
        "key": "chen2022mobile",
        "author": "Chen, Yinpeng and Dai, Xiyang and Chen, Dongdong and Liu, Mengchen and Dong, Xiaoyi and Yuan, Lu and Liu, Zicheng",
        "title": "Mobile-former: Bridging mobilenet and transformer"
      },
      {
        "key": "li2022efficientformer",
        "author": "Li, Yanyu and Yuan, Geng and Wen, Yang and Hu, Ju and Evangelidis, Georgios and Tulyakov, Sergey and Wang, Yanzhi and Ren, Jian",
        "title": "Efficientformer: Vision transformers at mobilenet speed"
      }
    ]
  },
  {
    "index": 17,
    "papers": [
      {
        "key": "yun2024shvit",
        "author": "Yun, Seokju and Ro, Youngmin",
        "title": "SHViT: Single-Head Vision Transformer with Memory Efficient Macro Design"
      }
    ]
  }
]