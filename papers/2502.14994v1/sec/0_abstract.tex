\begin{abstract}
% The impressive achievements of generative models in creating high-quality videos have raised concerns about digital integrity and privacy vulnerabilities. Recent works to combat Deepfakes videos have developed detectors that are highly accurate at identifying GAN-generated samples. However, the robustness of these detectors on diffusion-generated videos generated from video creation tools (e.g., SORA by OpenAI, Runway Gen-2, and Pika, etc.) is still unexplored. 
% In this paper, we propose a novel framework for detecting videos synthesized from multiple state-of-the-art (SOTA) generative models, such as Stable Video Diffusion. 
% We find that the SOTA methods for detecting diffusion-generated images lack robustness in identifying diffusion-generated videos. 
% Our analysis reveals that the effectiveness of these detectors diminishes when applied to out-of-domain videos, primarily because they struggle to track the temporal features and dynamic variations between frames. 

% Yunyun's version
% The rise of multimodal content generation on social platforms has raised concerns about digital integrity and privacy vulnerabilities. Its hallucinations increase the difficulty in detection, requiring robust understanding across multiple types of explicit knowledge for accurate detection. Recent works of AI-generated content detection have been widely studied in the image field (e.g., deepfake), yet the video field has been unexplored.
% Large Vision Language Model (LVLM) has become an emerging tool for AI-generated content generation.
% % enabling us to utilize it for detection. 
% By leveraging its proficiency in processing video or text data, LVLM has strong reasoning capabilities and can serve as an agent for solving various tasks. Motivated by this, We propose \lavid, a novel LVLM-based agentic framework that leverages LVLM reasoning ability with structure prompt and explicit knowledge enhancement for fake video detection.
% Our insight is that (1.) Structuring the prompt can affect LVLM's reasoning ability to interpret information in video content. (2.) The selection of explicit knowledge information can affect the detection due to the reasoning discrepancy on different detectors. 
% Our proposed pipeline automatically selects a set of explicit knowledge tools for detection, then adaptively adjust the structure prompt by self-rewriting. Different from prior SOTA that trains additional detectors, our method is fully training-free and only requires inference the LVLM for detection. To facilitate our research, we also create a new benchmark \vidfor with hight-quality videos generated from multiple sources of video generation tools. Evaluation on several SOTA LVLM such as Gemini, GPT-4o, QWen demonstrate that our proposed framework improves the detection rate by xx points.



% \textbf{Qingyuan:} 
The impressive achievements of generative models in creating high-quality videos have raised concerns about digital integrity and privacy vulnerabilities. Recent works of AI-generated content detection have been widely studied in the image field (e.g., deepfake), yet the video field has been unexplored. Large Vision Language Model (LVLM) has become an emerging tool for AI-generated content detection for its strong reasoning and multimodal capabilities. It breaks the limitations of traditional deep learning based methods faced with like lack of transparency and inability to recognize new artifacts. Motivated by this, we propose \emph{\lavid}, a novel LVLMs-based ai-generated video detection with explicit knowledge enhancement. Our insight list as follows: (1) The leading LVLMs can call external tools to extract useful information to facilitate its own video detection task; (2) Structuring the prompt can affect LVLM's reasoning ability to interpret information in video content. Our proposed pipeline automatically selects a set of explicit knowledge tools for detection, and then adaptively adjusts the structure prompt by self-rewriting. Different from prior SOTA that trains additional detectors, our method is fully training-free and only requires inference of the LVLM for detection. To facilitate our research, we also create a new benchmark \vidfor with high-quality videos generated from multiple sources of video generation tools. Evaluation results show that \lavid improves F1 scores by 6.2 to 30.2\% over the top baselines on our datasets across four SOTA LVLMs.

% Recent works to combat Deepfakes videos have developed detectors that are highly accurate at identifying GAN-generated samples. 
% However, current deep learning based methods face limitations such as a lack of transparency (OR limited interpretability), risk for bias, and inability to recognize artifacts not written down(novel patterns not present in their training data). 
% Additionally, in real-world scenarios, the artifacts of the AI-generated video and the detection paradigm are not fixed due to the rapidly developed video generation model, preventing these methods from performing well in distinguishing uncommon artifacts in its training dataset.(?) 
% In this paper, we propose a novel framework to extract interpretable yet discriminative sets of artifacts for AI-generated video. The framework leverages Large Vision Language Models(LVLMs) as a commander, who can call external tools to assist the detection. 
% (We also discuss the efficiency of our method on traditional deepfake tasks) Our method produced state-of-the-art result on the comprehensive dataset.



% \yun{To address the above-mentioned challenge, we collect a new benchmark video dataset for diffusion-generated videos using SOTA video creation tools. We explore a wide range of feature landscapes as explicit knowledge to faciliate our detection, including spatial (motion), lightning (optical flow), depth estimation, three-dimensional reconstruction. We propose a comprehensive detection pipeline and investigate the capabilities of multimodal large language models (MLLMs) in video detection, such as GPT-4o, Gemini 1.5 pro, GPT-4V, LLaVA-NeXT-Video, ...etc. Our evaluation shows that...}.


\end{abstract}