\section{Related Work}
% \hangx{!! related work is to clarify the problem, key challenges, and the unsolved issues for the current methods}
% VRL 重要, gen重要, bisim, augmen, adapt
\subsection{Visual Generalization in RL}
% The ability to interpret visual input plays an essential role for reinforcement learning (RL) agents to solve a wide range of challenging tasks____. Recently, VRL has shown impressive achievements in clean environments but struggles to generalize to visually distracting environments____. The key to visual generalization is the ability to neglect visual distractions, i.e. acquire insensitive representations of distractions, and 

% which require extra model capacity for modeling useless distractions. 
% which no longer requires prior knowledge of visual distractors
%  without the connection between the adaptation objectives and intended downstream tasks

The ability to generalize across environments with unknown distractions is a long-stand challenge for the practical application of reinforcement learning (RL) agents____. Task-induced methods address the problem by learning structured representations that separate task-relevant features from confounding factors____. Augmentation-based methods regularize the representation between augmented images and clean equivalents____, but they require prior knowledge of the test-time variations to manually design augmentations. Adaptation-based methods____ do not assume the distractions and fine-tune the agent’s representation through self-supervised objectives. However, existing adaptation-based methods tend to lead to narrow empirical improvement____ or are limited to a specific type of visual distractions____. Several studies aim to tackle this issue with foundation models____, but they still struggle with computational budget and inference time.
% Therefore, the ability to efficiently generalize across visual distractions remains a critical challenge for the real-world deployment of VRL policies.

% \subsection{World Models}
% The concept of World Models was first introduced by____, describing a compressed spatial and temporal representation of the environment. In the subsequent works, the concept is soon amplified by constructing a Recurrent State Space Model (RSSM) to boost planning____ and policy learning____. In light of the 
% flourish in Transformers____, some recent works also integrate them into world models to improve long-term performance and learning efficiency____.

% Despite the proficiency in clean environments, it is non-trivial to directly learn a world model in distracting environments as the latent representation will be contaminated by the unpredictable visual distractions____. To tackle this issue, task-induced world models are proposed to separate task-relevant features from irrelevant ones by decomposing the learned latent state, but they have to spare extra model capacity and computational resources to model meaningless distractions____. Some other works aim to strengthen visual robustness by exploring reconstruction-free world models____. However, the performance gap between training in clean and distracting environments remains.

\subsection{Unsupervised Domain Transfer}
Unsupervised Domain Transfer aims to map data collected from the source domain to a related target domain without explicit supervision signals____. The topic has been explored in various research areas, such as style transfer____, pose transfer____, language translation____ and so on. However, one key difference between our setting and theirs is that we can interact with the environments to collect data rather than relying on pre-collected static datasets. Therefore, we can obtain a certain level of control over the distribution of collected data by selecting specific action sequences, which makes it possible for us to achieve the desired transfer from cluttered observations to clean ones with unsupervised distribution matching____.


\begin{figure}
    \centering
    \includegraphics[width=0.7\linewidth]{imgs/PGM.pdf}
    \caption{The graphical model of a NPOMDP, where $o_t$ and $o^n_t$ denote the clean and cluttered observation respectively.}
    \vspace{-1em}
    \label{fig_pgm}
\end{figure}

\begin{figure*}[tb]
\centering
% \centerline{\includegraphics[width=0.8\linewidth]{imgs/SCMA-algo-6.pdf}}
\centerline{\includegraphics[width=1.0\linewidth]{imgs/SCMA-algo-9.pdf}}
\caption{\textbf{An overview of Self-Consistent Model-based Adaption (SCMA)}. SCMA adapts the agent to distracting environments by transferring cluttered observations to clean ones with the denoising model $m_{\mathrm{de}}$. Leveraging a pre-trained world model, $m_{\mathrm{de}}$ can be efficiently optimized with self-consistent reconstruction, noisy reconstruction, and reward prediction loss.}
\label{fig_scma_algo}
\vspace{-1.2em}
\end{figure*}