@article{aljanaki2016studying,
  title={Studying emotion induced by music through a crowdsourcing game},
  author={Aljanaki, Anna and Wiering, Frans and Veltkamp, Remco C},
  journal={Information Processing \& Management},
  volume={52},
  number={1},
  pages={115--128},
  year={2016},
  publisher={Elsevier}
}

@article{aljanaki2017developing,
  title={Developing a benchmark for emotional analysis of music},
  author={Aljanaki, Anna and Yang, Yi-Hsuan and Soleymani, Mohammad},
  journal={PloS one},
  volume={12},
  number={3},
  pages={e0173392},
  year={2017},
  publisher={Public Library of Science San Francisco, CA USA}
}

@inproceedings{bogdanov2019mtg,
  title={The mtg-jamendo dataset for automatic music tagging},
  author={Bogdanov, Dmitry and Won, Minz and Tovstogan, Philip and Porter, Alastair and Serra, Xavier},
  year={2019},
  organization={ICML}
}

@inproceedings{bour2021frequency,
  title={Frequency Dependent Convolutions for Music Tagging.},
  author={Bour, Vincent},
  booktitle={MediaEval},
  year={2021}
}

@article{caruana1997multitask,
  title={Multitask learning},
  author={Caruana, Rich},
  journal={Machine learning},
  volume={28},
  pages={41--75},
  year={1997},
  publisher={Springer}
}

@inproceedings{ccano2017moodylyrics,
  title={Moodylyrics: A sentiment annotated lyrics dataset},
  author={{\c{C}}ano, Erion and Morisio, Maurizio},
  booktitle={Proceedings of the 2017 international conference on intelligent systems, metaheuristics \& swarm intelligence},
  pages={118--124},
  year={2017}
}

@inproceedings{chaki2020attentive,
  title={Attentive RNNs for Continuous-time Emotion Prediction in Music Clips.},
  author={Chaki, Sanga and Doshi, Pranjal and Patnaik, Priyadarshi and Bhattacharya, Sourangshu}

@inproceedings{cho2016music,
  title={Music emotion recognition using chord progressions},
  author={Cho, Yong-Hun and Lim, Hyunki and Kim, Dae-Won and Lee, In-Kwon},
  booktitle={2016 IEEE Int. Conf. on Systems, Man, and Cybernetics (SMC)},
  pages={002588--002593},
  year={2016},
  organization={IEEE}
}

@inproceedings{elizalde2023clap,
  title={Clap learning audio concepts from natural language supervision},
  author={Elizalde, Benjamin and Deshmukh, Soham and Al Ismail, Mahmoud and Wang, Huaming},
  booktitle={ICASSP 2023-2023 IEEE Int. Conf. on Acoustics, Speech and Signal Processing (ICASSP)},
  pages={1--5},
  year={2023},
  organization={IEEE}
}

@article{ferreira2021learning,
  title={Learning to generate music with sentiment},
  author={Ferreira, Lucas N and Whitehead, Jim},
  journal={arXiv:2103.06125},
  year={2021}
}

@article{greer2023creating,
  title={Creating musical features using multi-faceted, multi-task encoders based on transformers},
  author={Greer, Timothy and Shi, Xuan and Ma, Benjamin and Narayanan, Shrikanth},
  journal={Scientific Reports},
  volume={13},
  number={1},
  pages={10713},
  year={2023},
  publisher={Nature Publishing Group UK London}
}

@article{hasumi2025music,
  title={Music Tagging with Classifier Group Chains},
  author={Hasumi, Takuya and Komatsu, Tatsuya and Fujita, Yusuke},
  journal={arXiv:2501.05050},
  year={2025}
}

@inproceedings{hershey2017cnn,
  title={CNN architectures for large-scale audio classification},
  author={Hershey, Shawn and Chaudhuri, Sourish and Ellis, Daniel PW and Gemmeke, Jort F and Jansen, Aren and Moore, R Channing and Plakal, Manoj and Platt, Devin and Saurous, Rif A and Seybold, Bryan and others},
  booktitle={2017 ieee Int. conference on acoustics, speech and signal processing (icassp)},
  pages={131--135},
  year={2017},
  organization={IEEE}
}

@article{hinton2015distilling,
  title={Distilling the Knowledge in a Neural Network},
  author={Hinton, Geoffrey},
  journal={arXiv:1503.02531},
  year={2015}
}

@article{hizlisoy2021music,
  title={Music emotion recognition using convolutional long short term memory deep neural networks},
  author={Hizlisoy, Serhat and Yildirim, Serdar and Tufekci, Zekeriya},
  journal={Eng. Sci. Technol. Int J.},
  volume={24},
  number={3},
  pages={760--767},
  year={2021},
  publisher={Elsevier}
}

@article{huang2022adff,
  title={ADFF: Attention based deep feature fusion approach for music emotion recognition},
  author={Huang, Zi and Ji, Shulei and Hu, Zhilan and Cai, Chuangjian and Luo, Jing and Yang, Xinyu},
  journal={arXiv:2204.05649},
  year={2022}
}

@article{hung2021emopia,
  title={EMOPIA: A multi-modal pop piano dataset for emotion recognition and emotion-based music generation},
  author={Hung, Hsiao-Tzu and Ching, Joann and Doh, Seungheon and Kim, Nabin and Nam, Juhan and Yang, Yi-Hsuan},
  journal={arXiv:2108.01374},
  year={2021}
}

@article{jeong2022multitask,
  title={Multitask emotion recognition model with knowledge distillation and task discriminator},
  author={Jeong, Euiseok and Oh, Geesung and Lim, Sejoon},
  journal={arXiv:2203.13072},
  year={2022}
}

@article{jia2022music,
  title={A music emotion classification model based on the improved convolutional neural network},
  author={Jia, Xiaosong},
  journal={Computational Intelligence and Neuroscience},
  volume={2022},
  number={1},
  pages={6749622},
  year={2022},
  publisher={Wiley Online Library}
}

@article{kang2024we,
  title={Are we there yet? A brief survey of Music Emotion Prediction Datasets, Models and Outstanding Challenges},
  author={Kang, Jaeyong and Herremans, Dorien},
  journal={arXiv:2406.08809},
  year={2024}
}

@article{li2023mert,
  title={Mert: Acoustic music understanding model with large-scale self-supervised training},
  author={Li, Yizhi and Yuan, Ruibin and Zhang, Ge and Ma, Yinghao and Chen, Xingran and Yin, Hanzhi and Xiao, Chenghao and Lin, Chenghua and Ragni, Anton and Benetos, Emmanouil and others},
  journal={arXiv:2306.00107},
  year={2023}
}

@article{liu2017cnn,
  title={CNN based music emotion classification},
  author={Liu, Xin and Chen, Qingcai and Wu, Xiangping and Liu, Yan and Liu, Yang},
  journal={arXiv:1704.05665},
  year={2017}
}

@article{liu2024leveraging,
  title={Leveraging LLM Embeddings for Cross Dataset Label Alignment and Zero Shot Music Emotion Prediction},
  author={Liu, Renhang and Roy, Abhinaba and Herremans, Dorien},
  journal={arXiv:2410.11522},
  year={2024}
}

@inproceedings{malheiro2016bi,
  title={Bi-modal music emotion recognition: Novel lyrical features and dataset},
  author={Malheiro, Ricardo and Panda, Renato and Gomes, Paulo JS and Paiva, Rui Pedro},
  booktitle={9th Int. Workshop on Music and Machine Learning--MML},
  year={2016}
}

@inproceedings{mayerl2021recognizing,
  title={Recognizing Song Mood and Theme: Clustering-based Ensembles.},
  author={Mayerl, Maximilian and V{\"o}tter, Michael and Peintner, Andreas and Specht, G{\"u}nther and Zangerle, Eva},
  booktitle={MediaEval},
  year={2021}
}

@inproceedings{multi-source-mer2024,
  author    = {Giovanni Mazzetta and
               Antonio Greco and
               Marco Tagliasacchi and
               Antonio Pescap{\`{e}}},
  title     = {A Multi-Source Deep Learning Model for Music Emotion Recognition},
  booktitle = {Proc. of the AIxHMI Workshop at CEUR-WS},
  year      = {2024},
  volume    = {3903},
  pages     = {1--8},
  url       = {https://ceur-ws.org/Vol-3903/AIxHMI2024_paper4.pdf},
  publisher = {CEUR Workshop Proc.}
}

@inproceedings{panda2018musical,
  title={Musical texture and expressivity features for music emotion recognition},
  author={Panda, Renato and Malheiro, Ricardo and Paiva, Rui Pedro},
  booktitle={19th Int. Society for Music Information Retrieval Conf. (ISMIR 2018)},
  pages={383--391},
  year={2018}
}

@article{panda2018novel,
  title={Novel audio features for music emotion recognition},
  author={Panda, Renato and Malheiro, Ricardo and Paiva, Rui Pedro},
  journal={IEEE Transactions on Affective Computing},
  volume={11},
  number={4},
  pages={614--626},
  year={2018},
  publisher={IEEE}
}

@inproceedings{pham2021selab,
  title={SELAB-HCMUS at MediaEval 2021: Music Theme and Emotion Classification with Co-teaching Training Strategy.},
  author={Pham, Phu-Thinh and Huynh, Minh-Hieu and Nguyen, Hai-Dang and Tran, Minh-Triet},
  booktitle={MediaEval},
  year={2021}
}

@article{qiu2022novel,
  title={A novel multi-task learning method for symbolic music emotion recognition},
  author={Qiu, Jibao and Chen, CL and Zhang, Tong},
  journal={arXiv:2201.05782},
  year={2022}
}

@article{rajesh2020musical,
  title={Musical instrument emotion recognition using deep recurrent neural network},
  author={Rajesh, Sangeetha and Nalini, NJ},
  journal={Procedia Comput. Sci.},
  volume={167},
  pages={16--25},
  year={2020},
  publisher={Elsevier}
}

@inproceedings{shelke2024exploring,
  title={Exploring Machine Learning Techniques for Music Emotion Classification: A Comprehensive Review},
  author={Shelke, Sheetal and Patil, Mangal},
  booktitle={2024 11th Int. Conf. on Computing for Sustainable Global Development (INDIACom)},
  pages={1188--1195},
  year={2024},
  organization={IEEE}
}

@inproceedings{soleymani20131000,
  title={1000 songs for emotional analysis of music},
  author={Soleymani, Mohammad and Caro, Micheal N and Schmidt, Erik M and Sha, Cheng-Ya and Yang, Yi-Hsuan},
  booktitle={Proc. of the 2nd ACM Int. workshop on Crowdsourcing for multimedia},
  pages={1--6},
  year={2013}
}

@article{suresh2023transformer,
  title={Transformer-based automatic music mood classification using multi-modal framework},
  author={Suresh Kumar, Sujeesha Ajithakumari and Rajan, Rajeev},
  journal={Journal of Computer Science \& Technology},
  volume={23},
  year={2023}
}

@article{tan2021semi,
  title={Semi-supervised music emotion recognition using noisy student training and harmonic pitch class profiles},
  author={Tan, Hao Hao},
  journal={arXiv:2112.00702},
  year={2021}
}

@article{tong2022multimodal,
  title={Multimodal music emotion recognition method based on the combination of knowledge distillation and transfer learning},
  author={Tong, Guiying},
  journal={Scientific Programming},
  volume={2022},
  number={1},
  pages={2802573},
  year={2022},
  publisher={Wiley Online Library}
}

@inproceedings{turnbull2007towards,
  title={Towards musical query-by-semantic-description using the cal500 data set},
  author={Turnbull, Douglas and Barrington, Luke and Torres, David and Lanckriet, Gert},
  booktitle={Proc. of the 30th annual Int.  ACM SIGIR Conf. on Research and development in information retrieval},
  pages={439--446},
  year={2007}
}

@inproceedings{wang2014towards,
  title={Towards time-varying music auto-tagging based on cal500 expansion},
  author={Wang, Shuo-Yang and Wang, Ju-Chiang and Yang, Yi-Hsuan and Wang, Hsin-Min},
  booktitle={2014 IEEE Int.  Conf. on Multimedia and Expo (ICME)},
  pages={1--6},
  year={2014},
  organization={IEEE}
}

@inproceedings{yizhi2023mert,
  title={MERT: Acoustic music understanding model with large-scale self-supervised training},
  author={Yizhi, LI and Yuan, Ruibin and Zhang, Ge and Ma, Yinghao and Chen, Xingran and Yin, Hanzhi and Xiao, Chenghao and Lin, Chenghua and Ragni, Anton and Benetos, Emmanouil and others},
  booktitle={The Twelfth International Conference on Learning Representations},
  year={2023}
}

@inproceedings{zhang2018pmemo,
  title={The PMEmo dataset for music emotion recognition},
  author={Zhang, Kejun and Zhang, Hui and Li, Simeng and Yang, Changyuan and Sun, Lingyun},
  booktitle={Proc. of the 2018 acm on Int.  Conf. on multimedia retrieval},
  pages={135--142},
  year={2018}
}

