\section{Related Work}
Early spike sorting pipelines typically used thresholds to detect spike events, followed by dimensionality reduction (e.g., PCA or $t$-SNE) and clustering ____. Although this pipeline was straightforward, it often suffered from noise susceptibility, inaccurate detection of low SNR events, and reliance on manual parameter tuning.

Deep learning approaches have been adopted to replace or enhance certain steps in traditional pipelines, aiming to improve robustness, automation, and adaptability to diverse experimental conditions. Autoencoders have been explored as a method for dimensionality reduction ____. YASS ____ employed a convolutional neural network for spike detection and waveform cleaning, thereby mitigating clustering errors caused by distorted waveforms. CEED ____ applied a contrastive learning framework to enforce invariances to amplitude fluctuations, noise, and channel subset changes in the extracted embeddings. However, these methods were limited by their reliance on restricted training datasets, potentially reducing their generalization across diverse experimental conditions.

In particular, YASS depended on high-quality prior training data and assumed a consistent experimental setup with validated sorting results, limiting its utility in scenarios where training data were scarce or recording conditions varied significantly. 

Similarly, CEED had its limitations: (1) its invariance assumptions may not generalize to datasets with unaccounted variability; (2) it relied on KiloSort2.5-processed data, potentially inheriting inaccuracies from these analyses; (3) its training and testing datasets were narrowly scoped, originating from similar experimental conditions, which may constrain broader applicability; and (4) it did not optimize spike detection or provide a complete spike sorting pipeline.

Given these limitations, we propose a data-driven approach to develop a fully automated spike sorting pipeline that does not rely on manually defined parameters, demonstrating improved generalization across diverse datasets and recording conditions.