\vspace{-12pt}
\section{Introduction}
\begin{figure}[t]
  \centering
   \includegraphics[width=1\linewidth]{sec/figs/fig1.png}
   \caption{\captionMethodFigure}
   \label{fig:methodFigure}
\end{figure}
\begin{figure}[t]
  \centering
   \includegraphics[width=1\linewidth]{sec/figs/exampleFigure.png}
   \caption{\captionExampleFigure}
   \label{fig:exampleFigure}
   \vspace{-12pt}
\end{figure}
Vision-Language Models (VLMs), such as CLIP~\cite{CLIP}, have emerged as general-purpose systems for understanding visual data through language-based queries. These models enable a broad range of applications, from object detection to image captioning, by linking visual inputs to language prompts. In standard settings where images contain single, recognizable objects, VLMs perform remarkably well. However, for the more complex task of zero-shot multi-label recognition (MLR) (Fig. \ref{fig:methodFigure} (top)), where models must identify multiple objects within an image without prior training on specific data, VLMs face significant limitations. Zero-shot MLR is crucial for applications in fields like robotics and medical imaging, where objects rarely appear in configurations that align neatly with training distributions. In these scenarios, achieving robust multi-label recognition without fine-tuning is challenging, given the task’s reliance on mean Average Precision (mAP) scores, which depend on ranking images for object presence.

\noindent \textbf{VLM: Prompt Dependent AND/OR Noisy Channel.} Despite the promise of zero-shot capabilities, current VLM approaches often struggle with MLR due to inherent scoring behaviors and biases. The performance of these models is hampered by a mix of conjunction (AND) and disjunction (OR) behaviors in their scoring, leading to inflated scores in compound prompts that contain multiple objects. For example, a prompt like “cat and sofa” might yield a high score even if only one of these objects is present in the image. This tendency reflects biases learned during training, where common object pairs receive higher scores even when only one object is present, disrupting the accuracy of mAP-based evaluations. Furthermore, existing methods for adapting VLMs to zero-shot MLR frequently rely on prompt tuning or architectural adjustments—approaches that are often dependent on training data and computationally intensive fine-tuning, which limit their generalizability to novel tasks.

\noindent \textbf{Our Approach.} In contrast to these methods, we introduce SPARC (Score Prompting and Adaptive Fusion for Zero-Shot Multi-Label Recognition in VLMs), a novel approach to zero-shot MLR that bypasses the need for training data, prompt tuning, or model-specific modifications. Our method treats the VLM as a black box, relying solely on its output scores to infer object presence (see Fig. \ref{fig:methodFigure}). This black-box approach enables us to avoid assumptions about the model’s internal workings, allowing for a purely zero-shot framework that is both model-agnostic and dataset-independent. SPARC introduces two main innovations that address the unique challenges of zero-shot MLR.

\noindent \textbf{A. Compound Prompt Composition:} Recognizing that VLMs can provide richer information when prompted with combinations of objects, we develop a method for constructing compound prompts. These prompts reflect likely contextual associations between objects, such as “cat and sofa” or “car and bus.” By gathering scores from these compound prompts, we can capture a spectrum of potential object contexts within the image, enhancing detection without relying on training-based adaptations. This composition strategy allows us to agnostically extract information from the VLM, leveraging probable object relationships without depending on any specific dataset or VLM architecture.\\
\noindent \textbf{B. Score Debiasing and Adaptive Fusion.} A critical insight in our approach lies in the surprising observation that the \underline{maximum score among compound prompts} is often a poor proxy for true object presence. Although one might expect the highest score to serve as a reliable signal, we find that it frequently reflects compositional biases, as VLMs tend to respond to compound prompts with OR-like behavior, raising scores even when only one object in the prompt is present. Instead, we observe that the second-highest score consistently provides a more accurate indicator of object presence, minimizing the effects of false positives caused by compositional bias. Building on this insight, we develop a debiasing algorithm that normalizes scores across images to address image-specific noise and clarify genuine object presence signals. This debiased score set is then processed through a PCA-based fusion method that further refines object rankings by combining information from both compound and singleton prompts, ultimately optimizing mAP by enhancing score accuracy.\\
\textbf{Complementarity.} SPARC is complementary to other zero-shot and training-free MLR methods. When applied on top of these approaches, SPARC consistently enhances mAP scores by refining object ranking and reducing bias in VLM outputs. This capability makes SPARC an adaptable solution that can improve upon existing methods while maintaining a fully zero-shot, model-agnostic framework.

\noindent \textbf{Empirical Results.} SPARC achieves significant improvements in mAP, outperforming methods that incorporate architectural modifications. This outcome shows the potential of a fully zero-shot approach that relies only on systematic prompt design and score interpretation, rather than prompt-training or fine-tuning. By revealing that the second-highest score can be a superior proxy to the maximum, our findings provide new insights into VLM scoring behavior, suggesting that careful treatment of prompt compositions and score patterns can unlock robust MLR capabilities.

