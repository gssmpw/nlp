
%% bare_conf.tex
%% V1.3
%% 2007/01/11
%% by Michael Shell
%% See:
%% http://www.michaelshell.org/
%% for current contact information.
%%
%% This is a skeleton file demonstrating the use of IEEEtran.cls
%% (requires IEEEtran.cls version 1.7 or later) with an IEEE conference paper.
%%
%% Support sites:
%% http://www.michaelshell.org/tex/ieeetran/
%% http://www.ctan.org/tex-archive/macros/latex/contrib/IEEEtran/
%% and
%% http://www.ieee.org/

%%*************************************************************************
%% Legal Notice:
%% This code is offered as-is without any warranty either expressed or
%% implied; without even the implied warranty of MERCHANTABILITY or
%% FITNESS FOR A PARTICULAR PURPOSE! 
%% User assumes all risk.
%% In no event shall IEEE or any contributor to this code be liable for
%% any damages or losses, including, but not limited to, incidental,
%% consequential, or any other damages, resulting from the use or misuse
%% of any information contained here.
%%
%% All comments are the opinions of their respective authors and are not
%% necessarily endorsed by the IEEE.
%%
%% This work is distributed under the LaTeX Project Public License (LPPL)
%% ( http://www.latex-project.org/ ) version 1.3, and may be freely used,
%% distributed and modified. A copy of the LPPL, version 1.3, is included
%% in the base LaTeX documentation of all distributions of LaTeX released
%% 2003/12/01 or later.
%% Retain all contribution notices and credits.
%% ** Modified files should be clearly indicated as such, including  **
%% ** renaming them and changing author support contact information. **
%%
%% File list of work: IEEEtran.cls, IEEEtran_HOWTO.pdf, bare_adv.tex,
%%                    bare_conf.tex, bare_jrnl.tex, bare_jrnl_compsoc.tex
%%*************************************************************************

% *** Authors should verify (and, if needed, correct) their LaTeX system  ***
% *** with the testflow diagnostic prior to trusting their LaTeX platform ***
% *** with production work. IEEE's font choices can trigger bugs that do  ***
% *** not appear when using other class files.                            ***
% The testflow support page is at:
% http://www.michaelshell.org/tex/testflow/



% Note that the a4paper option is mainly intended so that authors in
% countries using A4 can easily print to A4 and see how their papers will
% look in print - the typesetting of the document will not typically be
% affected with changes in paper size (but the bottom and side margins will).
% Use the testflow package mentioned above to verify correct handling of
% both paper sizes by the user's LaTeX system.
%
% Also note that the "draftcls" or "draftclsnofoot", not "draft", option
% should be used if it is desired that the figures are to be displayed in
% draft mode.
%
%\documentclass[conference]{IEEEtran}
\documentclass[10pt, conference]{IEEEtran}


% \documentclass[conference]{IEEEtran}
% \IEEEoverridecommandlockouts
% Add the compsoc option for Computer Society conferences.
%
% If IEEEtran.cls has not been installed into the LaTeX system files,
% manually specify the path to it like:
% \documentclass[conference]{../sty/IEEEtran}





% Some very useful LaTeX packages include:
% (uncomment the ones you want to load)


% *** MISC UTILITY PACKAGES ***
%
%\usepackage{ifpdf}
% Heiko Oberdiek's ifpdf.sty is very useful if you need conditional
% compilation based on whether the output is pdf or dvi.
% usage:
% \ifpdf
%   % pdf code
% \else
%   % dvi code
% \fi
% The latest version of ifpdf.sty can be obtained from:
% http://www.ctan.org/tex-archive/macros/latex/contrib/oberdiek/
% Also, note that IEEEtran.cls V1.7 and later provides a builtin
% \ifCLASSINFOpdf conditional that works the same way.
% When switching from latex to pdflatex and vice-versa, the compiler may
% have to be run twice to clear warning/error messages.
\usepackage{caption}
\usepackage{cite}
% \usepackage{algorithm}
% \usepackage{algorithm2e}
% \usepackage{algpseudocode}
% \usepackage{mdwmath}
% \usepackage{mdwtab}
% \usepackage{eqparbox}
\usepackage{url}
\usepackage{amssymb}
\usepackage{blindtext}
\usepackage{comment}

\usepackage{subcaption}
\usepackage{xcolor,soul,framed}
\usepackage{amsmath}
\usepackage{graphicx}
\usepackage{multirow}
% *** CITATION PACKAGES ***
%
\IEEEoverridecommandlockouts
% The preceding line is only needed to identify funding in the first footnote. If that is unneeded, please comment it out.
% \usepackage{cite}
% \usepackage{amsmath,amssymb,amsfonts}
% \usepackage{algorithmic}
% \usepackage{graphicx}
% \usepackage{textcomp}
% \usepackage{xcolor}
\def\BibTeX{{\rm B\kern-.05em{\sc i\kern-.025em b}\kern-.08em
    T\kern-.1667em\lower.7ex\hbox{E}\kern-.125emX}}





%\usepackage{cite}
% cite.sty was written by Donald Arseneau
% V1.6 and later of IEEEtran pre-defines the format of the cite.sty package
% \cite{} output to follow that of IEEE. Loading the cite package will
% result in citation numbers being automatically sorted and properly
% "compressed/ranged". e.g., [1], [9], [2], [7], [5], [6] without using
% cite.sty will become [1], [2], [5]--[7], [9] using cite.sty. cite.sty's
% \cite will automatically add leading space, if needed. Use cite.sty's
% noadjust option (cite.sty V3.8 and later) if you want to turn this off.
% cite.sty is already installed on most LaTeX systems. Be sure and use
% version 4.0 (2003-05-27) and later if using hyperref.sty. cite.sty does
% not currently provide for hyperlinked citations.
% The latest version can be obtained at:
% http://www.ctan.org/tex-archive/macros/latex/contrib/cite/
% The documentation is contained in the cite.sty file itself.






% *** GRAPHICS RELATED PACKAGES ***
%
\ifCLASSINFOpdf
  % \usepackage[pdftex]{graphicx}
  % declare the path(s) where your graphic files are
  % \graphicspath{{../pdf/}{../jpeg/}}
  % and their extensions so you won't have to specify these with
  % every instance of \includegraphics
  % \DeclareGraphicsExtensions{.pdf,.jpeg,.png}
\else
  % or other class option (dvipsone, dvipdf, if not using dvips). graphicx
  % will default to the driver specified in the system graphics.cfg if no
  % driver is specified.
  % \usepackage[dvips]{graphicx}
  % declare the path(s) where your graphic files are
  % \graphicspath{{../eps/}}
  % and their extensions so you won't have to specify these with
  % every instance of \includegraphics
  % \DeclareGraphicsExtensions{.eps}
\fi
% graphicx was written by David Carlisle and Sebastian Rahtz. It is
% required if you want graphics, photos, etc. graphicx.sty is already
% installed on most LaTeX systems. The latest version and documentation can
% be obtained at: 
% http://www.ctan.org/tex-archive/macros/latex/required/graphics/
% Another good source of documentation is "Using Imported Graphics in
% LaTeX2e" by Keith Reckdahl which can be found as epslatex.ps or
% epslatex.pdf at: http://www.ctan.org/tex-archive/info/
%
% latex, and pdflatex in dvi mode, support graphics in encapsulated
% postscript (.eps) format. pdflatex in pdf mode supports graphics
% in .pdf, .jpeg, .png and .mps (metapost) formats. Users should ensure
% that all non-photo figures use a vector format (.eps, .pdf, .mps) and
% not a bitmapped formats (.jpeg, .png). IEEE frowns on bitmapped formats
% which can result in "jaggedy"/blurry rendering of lines and letters as
% well as large increases in file sizes.
%
% You can find documentation about the pdfTeX application at:
% http://www.tug.org/applications/pdftex





% *** MATH PACKAGES ***
%
%\usepackage[cmex10]{amsmath}
% A popular package from the American Mathematical Society that provides
% many useful and powerful commands for dealing with mathematics. If using
% it, be sure to load this package with the cmex10 option to ensure that
% only type 1 fonts will utilized at all point sizes. Without this option,
% it is possible that some math symbols, particularly those within
% footnotes, will be rendered in bitmap form which will result in a
% document that can not be IEEE Xplore compliant!
%
% Also, note that the amsmath package sets \interdisplaylinepenalty to 10000
% thus preventing page breaks from occurring within multiline equations. Use:
%\interdisplaylinepenalty=2500
% after loading amsmath to restore such page breaks as IEEEtran.cls normally
% does. amsmath.sty is already installed on most LaTeX systems. The latest
% version and documentation can be obtained at:
% http://www.ctan.org/tex-archive/macros/latex/required/amslatex/math/





% *** SPECIALIZED LIST PACKAGES ***
%
%\usepackage{algorithmic}
% algorithmic.sty was written by Peter Williams and Rogerio Brito.
% This package provides an algorithmic environment fo describing algorithms.
% You can use the algorithmic environment in-text or within a figure
% environment to provide for a floating algorithm. Do NOT use the algorithm
% floating environment provided by algorithm.sty (by the same authors) or
% algorithm2e.sty (by Christophe Fiorio) as IEEE does not use dedicated
% algorithm float types and packages that provide these will not provide
% correct IEEE style captions. The latest version and documentation of
% algorithmic.sty can be obtained at:
% http://www.ctan.org/tex-archive/macros/latex/contrib/algorithms/
% There is also a support site at:
% http://algorithms.berlios.de/index.html
% Also of interest may be the (relatively newer and more customizable)
% algorithmicx.sty package by Szasz Janos:
% http://www.ctan.org/tex-archive/macros/latex/contrib/algorithmicx/




% *** ALIGNMENT PACKAGES ***
%
%\usepackage{array}
% Frank Mittelbach's and David Carlisle's array.sty patches and improves
% the standard LaTeX2e array and tabular environments to provide better
% appearance and additional user controls. As the default LaTeX2e table
% generation code is lacking to the point of almost being broken with
% respect to the quality of the end results, all users are strongly
% advised to use an enhanced (at the very least that provided by array.sty)
% set of table tools. array.sty is already installed on most systems. The
% latest version and documentation can be obtained at:
% http://www.ctan.org/tex-archive/macros/latex/required/tools/


%\usepackage{mdwmath}
%\usepackage{mdwtab}
% Also highly recommended is Mark Wooding's extremely powerful MDW tools,
% especially mdwmath.sty and mdwtab.sty which are used to format equations
% and tables, respectively. The MDWtools set is already installed on most
% LaTeX systems. The lastest version and documentation is available at:
% http://www.ctan.org/tex-archive/macros/latex/contrib/mdwtools/


% IEEEtran contains the IEEEeqnarray family of commands that can be used to
% generate multiline equations as well as matrices, tables, etc., of high
% quality.


%\usepackage{eqparbox}
% Also of notable interest is Scott Pakin's eqparbox package for creating
% (automatically sized) equal width boxes - aka "natural width parboxes".
% Available at:
% http://www.ctan.org/tex-archive/macros/latex/contrib/eqparbox/





% *** SUBFIGURE PACKAGES ***
%\usepackage[tight,footnotesize]{subfigure}
% subfigure.sty was written by Steven Douglas Cochran. This package makes it
% easy to put subfigures in your figures. e.g., "Figure 1a and 1b". For IEEE
% work, it is a good idea to load it with the tight package option to reduce
% the amount of white space around the subfigures. subfigure.sty is already
% installed on most LaTeX systems. The latest version and documentation can
% be obtained at:
% http://www.ctan.org/tex-archive/obsolete/macros/latex/contrib/subfigure/
% subfigure.sty has been superceeded by subfig.sty.



%\usepackage[caption=false]{caption}
%\usepackage[font=footnotesize]{subfig}
% subfig.sty, also written by Steven Douglas Cochran, is the modern
% replacement for subfigure.sty. However, subfig.sty requires and
% automatically loads Axel Sommerfeldt's caption.sty which will override
% IEEEtran.cls handling of captions and this will result in nonIEEE style
% figure/table captions. To prevent this problem, be sure and preload
% caption.sty with its "caption=false" package option. This is will preserve
% IEEEtran.cls handing of captions. Version 1.3 (2005/06/28) and later 
% (recommended due to many improvements over 1.2) of subfig.sty supports
% the caption=false option directly:
%\usepackage[caption=false,font=footnotesize]{subfig}
%
% The latest version and documentation can be obtained at:
% http://www.ctan.org/tex-archive/macros/latex/contrib/subfig/
% The latest version and documentation of caption.sty can be obtained at:
% http://www.ctan.org/tex-archive/macros/latex/contrib/caption/




% *** FLOAT PACKAGES ***
%
%\usepackage{fixltx2e}
% fixltx2e, the successor to the earlier fix2col.sty, was written by
% Frank Mittelbach and David Carlisle. This package corrects a few problems
% in the LaTeX2e kernel, the most notable of which is that in current
% LaTeX2e releases, the ordering of single and double column floats is not
% guaranteed to be preserved. Thus, an unpatched LaTeX2e can allow a
% single column figure to be placed prior to an earlier double column
% figure. The latest version and documentation can be found at:
% http://www.ctan.org/tex-archive/macros/latex/base/



%\usepackage{stfloats}
% stfloats.sty was written by Sigitas Tolusis. This package gives LaTeX2e
% the ability to do double column floats at the bottom of the page as well
% as the top. (e.g., "\begin{figure*}[!b]" is not normally possible in
% LaTeX2e). It also provides a command:
%\fnbelowfloat
% to enable the placement of footnotes below bottom floats (the standard
% LaTeX2e kernel puts them above bottom floats). This is an invasive package
% which rewrites many portions of the LaTeX2e float routines. It may not work
% with other packages that modify the LaTeX2e float routines. The latest
% version and documentation can be obtained at:
% http://www.ctan.org/tex-archive/macros/latex/contrib/sttools/
% Documentation is contained in the stfloats.sty comments as well as in the
% presfull.pdf file. Do not use the stfloats baselinefloat ability as IEEE
% does not allow \baselineskip to stretch. Authors submitting work to the
% IEEE should note that IEEE rarely uses double column equations and
% that authors should try to avoid such use. Do not be tempted to use the
% cuted.sty or midfloat.sty packages (also by Sigitas Tolusis) as IEEE does
% not format its papers in such ways.





% *** PDF, URL AND HYPERLINK PACKAGES ***
%
%\usepackage{url}
% url.sty was written by Donald Arseneau. It provides better support for
% handling and breaking URLs. url.sty is already installed on most LaTeX
% systems. The latest version can be obtained at:
% http://www.ctan.org/tex-archive/macros/latex/contrib/misc/
% Read the url.sty source comments for usage information. Basically,
% \url{my_url_here}.





% *** Do not adjust lengths that control margins, column widths, etc. ***
% *** Do not use packages that alter fonts (such as pslatex).         ***
% There should be no need to do such things with IEEEtran.cls V1.6 and later.
% (Unless specifically asked to do so by the journal or conference you plan
% to submit to, of course. )


% correct bad hyphenation here
% \hyphenation{op-tical net-works semi-conduc-tor}


\begin{document}
%
% paper title
% can use linebreaks \\ within to get better formatting as desired
\title{RAILS: Risk-Aware Iterated Local Search for \\Joint SLA Decomposition and Service Provider Management in Multi-Domain Networks}


% author names and affiliations
% use a multiple column layout for up to three different
% affiliations
%University of Amsterdam, LAB42, Science Park 900, 1098 XH Amsterdam, The Netherlands
\author{\IEEEauthorblockN{Cyril Shih-Huan Hsu}
\IEEEauthorblockA{Informatics Institute\\
University of Amsterdam\\
Amsterdam, The Netherlands\\
s.h.hsu@uva.nl}
\and
\IEEEauthorblockN{Chrysa Papagianni}
\IEEEauthorblockA{Informatics Institute\\
University of Amsterdam\\
Amsterdam, The Netherlands\\
c.papagianni@uva.nl}
\and
\IEEEauthorblockN{Paola Grosso}
\IEEEauthorblockA{Informatics Institute\\
University of Amsterdam\\
Amsterdam, The Netherlands\\
p.grosso@uva.nl}
}

% conference papers do not typically use \thanks and this command
% is locked out in conference mode. If really needed, such as for
% the acknowledgment of grants, issue a \IEEEoverridecommandlockouts
% after \documentclass

% for over three affiliations, or if they all won't fit within the width
% of the page, use this alternative format:
% 
%\author{\IEEEauthorblockN{Michael Shell\IEEEauthorrefmark{1},
%Homer Simpson\IEEEauthorrefmark{2},
%James Kirk\IEEEauthorrefmark{3}, 
%Montgomery Scott\IEEEauthorrefmark{3} and
%Eldon Tyrell\IEEEauthorrefmark{4}}
%\IEEEauthorblockA{\IEEEauthorrefmark{1}School of Electrical and Computer Engineering\\
%Georgia Institute of Technology,
%Atlanta, Georgia 30332--0250\\ Email: see http://www.michaelshell.org/contact.html}
%\IEEEauthorblockA{\IEEEauthorrefmark{2}Twentieth Century Fox, Springfield, USA\\
%Email: homer@thesimpsons.com}
%\IEEEauthorblockA{\IEEEauthorrefmark{3}Starfleet Academy, San Francisco, California 96678-2391\\
%Telephone: (800) 555--1212, Fax: (888) 555--1212}
%\IEEEauthorblockA{\IEEEauthorrefmark{4}Tyrell Inc., 123 Replicant Street, Los Angeles, California 90210--4321}}




% use for special paper notices
%\IEEEspecialpapernotice{(Invited Paper)}




% make the title area
\maketitle


\begin{abstract}
The emergence of the fifth generation (5G) technology has transformed mobile networks into multi-service environments, necessitating efficient network slicing to meet diverse Service Level Agreements (SLAs). SLA decomposition across multiple network domains, each potentially managed by different service providers, poses a significant challenge due to limited visibility into real-time underlying domain conditions. This paper introduces Risk-Aware Iterated Local Search (RAILS), a novel risk model-driven meta-heuristic framework designed to jointly address SLA decomposition and service provider selection in multi-domain networks. By integrating online neural network (NN)-based risk modeling with iterated local search principles, RAILS effectively navigates the complex optimization landscape, utilizing historical feedback from domain controllers. We formulate the joint problem as a Mixed-Integer Nonlinear Programming (MINLP) problem and prove its NP-hardness. Extensive simulations demonstrate that RAILS achieves near-optimal performance, offering an efficient, real-time solution for adaptive SLA management in modern multi-domain networks.

% This paper introduces RAILS (Risk-Aware Iterated Local Search), a novel meta-heuristic framework designed to address the joint problem of Service Level Agreement (SLA) decomposition and service provider selection in multi-domain network environments. 
% The advent of 5G has enabled network slicing, which necessitates decomposing end-to-end (E2E) SLAs into domain-specific SLAs across multiple operators. However, traditional approaches often assume fixed service providers and lack real-time infrastructure visibility, limiting resource optimization. RAILS overcomes these limitations by integrating dynamic risk modeling with Iterated Local Search (ILS), capturing provider acceptance behavior based on historical feedback.

% We formulate the joint SLA decomposition and provider selection as a Mixed-Integer Nonlinear Programming (MINLP) problem and prove its NP-hardness. To tackle this complexity, RAILS employs a risk-aware meta-heuristic that iteratively refines provider selections and delay allocations, guided by up-to-date risk models. The framework leverages the principles of the Real-time Adaptive DEcomposition (RADE) system, enhancing adaptability through online learning and dynamic feedback integration.

% Empirical results from analytic model-based simulations demonstrate that RAILS achieves near-optimal performance in maximizing E2E acceptance probabilities, significantly outperforming baseline methods. This highlights RAILS' effectiveness in providing flexible, efficient resource utilization in dynamic, multi-domain network scenarios, making it a robust solution for modern network slicing management.
\end{abstract}
% IEEEtran.cls defaults to using nonbold math in the Abstract.
% This preserves the distinction between vectors and scalars. However,
% if the conference you are submitting to favors bold math in the abstract,
% then you can use LaTeX's standard command \boldmath at the very start
% of the abstract to achieve this. Many IEEE journals/conferences frown on
% math in the abstract anyway.

% no keywords
\begin{IEEEkeywords}
network slicing, service level agreement, risk model, quality of service, deep neural network, optimization
\end{IEEEkeywords}



% For peer review papers, you can put extra information on the cover
% page as needed:
% \ifCLASSOPTIONpeerreview
% \begin{center} \bfseries EDICS Category: 3-BBND \end{center}
% \fi
%
% For peerreview papers, this IEEEtran command inserts a page break and
% creates the second title. It will be ignored for other modes.
\IEEEpeerreviewmaketitle



\section{Introduction}
The advent of 5G has transformed mobile networks into multi-service environments tailored to diverse industry needs. A key enabler of this shift is network slicing, which creates multiple End-to-End (E2E) logical networks over shared infrastructure, each customized per Service Level Agreements (SLAs). SLAs define expected Quality of Service (QoS) through Service-Level Objectives (SLOs), covering metrics like throughput, latency, reliability, and security.
%Since a network slice often spans across multiple segments of the network, including (radio) access, transport, and core networks, involving multiple operators, meeting SLOs requires decomposing the E2E SLA into partial SLAs suited to each domain's capabilities.
A single network slice may span across multiple segments of the network, including (radio) access, transport, and core networks, and it may involve collaboration between different operators and infrastructure providers. To ensure that the service meets the agreed-upon SLOs across these domains, it is essential to adjust the service parameters accordingly. As a result, the E2E SLA associated with a network slice must be partitioned into specific SLOs for each domain.
This decomposition is crucial for effective resource allocation and remains a core challenge in network slicing.
Several studies have discussed this issue. \cite{ietf-teas-5g-network-slice-application-03} highlights the complexity of mapping E2E requirements to transport networks. \cite{hcltech2023networkslicing} focuses on lifecycle automation, orchestration, and real-time monitoring for SLA compliance. \cite{iovanna2022networkslicing} stresses the role of SLA parameters in E2E QoS and the need for appropriate transport resources. Additionally, \cite{su2019resource} underscores the importance of SLA decomposition for resource allocation, while \cite{10011552} explores AI-assisted SLA decomposition in automating 6G business processes.

In typical network slicing management architectures, a two-level hierarchy is employed~\cite{Vleeschauwer21_SLAdecomposition, SLADNN23, hsu2024online}. This includes an E2E service orchestrator, responsible for overseeing the lifecycle management of network services, and local domain controllers, which manage the instantiation of network slices within their specific domains. The orchestrator determines how the E2E SLA is partitioned into domain-specific SLOs. However, a common constraint is that the orchestrator usually lacks real-time visibility into the state of each domain's infrastructure at the moment of decomposition. Instead, it relies on historical data reflecting the outcomes of previous slice requests.
Several studies~\cite{8417711, 8931583, 10173672} have introduced prediction-based approaches for SLA management, though they do not explicitly tackle the E2E SLA decomposition problem. In~\cite{8417711}, the authors proposed a mapping layer that oversees the network within a service area, managing radio resource allocation to slices to ensure their target service requirements are met. The work in~\cite{8931583} presented an SLA-constrained optimization method leveraging Deep Learning (DL) to estimate resource requirements based on per-slice traffic. Similarly,~\cite{10173672} utilized a context-aware approach, employing graph representations to predict SLA violations in cloud computing environments.
Additionally, heuristic-based SLA decomposition methods have been explored in prior research~\cite{su2019resource}. In~\cite{9165317}, the authors introduced an E2E SLA decomposition system that applies supervised machine learning to partition E2E SLAs into access, transport, and core SLOs.

In our previous work~\cite{Vleeschauwer21_SLAdecomposition, SLADNN23}, we tackled the SLA decomposition problem using neural network (NN)-based risk models in a two-step approach that combined machine learning and optimization. Building on that,~\cite{hsu2024online} introduced an online learning–decomposition framework for dynamic, multi-domain SLA management. However, these studies assumed a preselected service provider per domain, focusing solely on optimizing E2E acceptance probabilities.
In real-world network environments, multiple service providers are often available within each domain, offering varying performance characteristics and capabilities.
For example, in a 5G network slice for autonomous vehicles, Ericsson provides high-capacity RAN for low-latency urban coverage, Nokia ensures reliable transport with energy-efficient networking, and AWS offers a scalable cloud-native core. This combination ensures stringent SLA requirements for real-time communication.
As a result, the optimization process should consider both the decomposition of SLAs and the selection of providers across domains to ensure more flexible and efficient resource utilization in multi-domain networks.
To address these limitations, this paper introduces Risk-Aware Iterated Local Search (RAILS), a novel risk model-driven meta-heuristic framework. RAILS extends the principles of Iterated Local Search (ILS) by integrating dynamic risk modeling and SLA decomposition techniques proposed in~\cite{hsu2024online}.
The main contributions of this paper are:
\begin{enumerate}
    \item [1.] We formulate the joint SLA decomposition and service provider selection tasks as a Mixed-Integer Nonlinear Programming (MINLP) problem and demonstrate its NP-hardness.
    \item [2.] We propose RAILS, a novel risk-aware meta-heuristic framework designed to jointly address the SLA decomposition and service provider selection problem.
    \item [3.] We empirically show that RAILS achieves near-optimal performance within an analytic model-based simulation environment with low computational overhead.
\end{enumerate}
The paper is organized as follows: Section II defines the system model and formulates the problem. Section III introduces the RAILS framework. Section IV details the simulation setup, while Section V presents and discusses the results. Section VI concludes the paper.
%These risk models, continuously updated through real-time feedback mechanisms, guide the local search process to explore provider selections and delay allocations that maximize the E2E acceptance probability. This joint optimization approach ensures that the SLA decomposition not only adheres to performance constraints but also dynamically adjusts to evolving network conditions.

% \section{Related Work}
% \textcolor{red}{\blindtext[1]}
% \textcolor{red}{\blindtext[1]}

\section{System Model}
% \section{Problem Formulation}

% In modern communication networks, the increasing demand for diverse and quality-assured services has motivated the development of network slicing. In a real-world network system, a network slice may span multiple technology domains (e.g., radio access, transport, and core networks), each managed by a set of local service providers. To guarantee the overall service quality, an end-to-end (E2E) Service Level Agreement (SLA) must be decomposed into partial SLAs that are enforced by each domain. This decomposition involves both the selection of an appropriate service provider within each domain and the allocation of a portion of the global delay budget to that domain.

% We consider a two-level network slice management architecture. At the top level, an E2E service orchestrator is responsible for ensuring that the overall SLA is met, whereas at the lower level, local domain controllers manage their respective domains. Due to practical constraints, the orchestrator has access only to historical feedback of admission control from the domain controllers; these data are used to construct risk models that capture each provider's acceptance probability as a function of the delay budget allocated. Given an E2E delay budget \( d_{\text{e2e}} \), the orchestrator must (i) select one service provider per domain and (ii) decompose the E2E delay budget into domain-specific delay SLO such that the E2E acceptance probability is maximized.

\subsection{Problem Formulation}
\label{sec:problem formulation}

Let \( N \) denote the number of domains that the service spans. For each domain \( i \) (with \( i=1,\dots,N \)), let \( \mathcal{J}_i \) denote the set of available service providers. We define the following decision variables:
\begin{itemize}
    \item \( x_{ij} \in \{0,1\} \): a binary variable that is $1$ if provider \( j \in \mathcal{J}_i \) is selected for domain \( i \), and $0$ otherwise.
    \item \( d_i \ge 0 \): the portion of the E2E delay budget allocated to domain \( i \).
\end{itemize}
The acceptance probability of domain \( i \) using provider \( j \) when allocated a delay of \( d_i \) is given by the function \( p_{ij}(d_i) \).
Assuming that the decisions made in the domains are statistically independent, the E2E acceptance probability \( p_{e2e} \) is modeled as the product of the acceptance probabilities of all domains:
\begin{equation}\label{eq:e2eprob}
p_{\text{e2e}} = \prod_{i=1}^{N} \left( \sum_{j \in \mathcal{J}_i} x_{ij}\, p_{ij}(d_i) \right).
\end{equation}
The goal is to \textbf{choose a provider in each domain} and \textbf{allocate the delay budgets} \( \{d_i\}_{i=1}^N \) such that the \textbf{E2E acceptance probability is maximized}, subject to the constraint that the domain-specific partial delays sum up to the E2E delay budget \( d_{\text{e2e}} \). Formally, the problem is formulated as follows:
\begin{equation}\label{eq:optimization_problem}
\begin{aligned}
\max_{\{x_{ij},\,d_i\}} \quad & \prod_{i=1}^{N} \left( \sum_{j \in \mathcal{J}_i} x_{ij}\, p_{ij}(d_i) \right) \\
\text{s.t.} \quad & \sum_{i=1}^{N} d_i = d_{\text{e2e}}, \\
& d_i \ge 0, \quad \forall\, i=1,\dots,N, \\
& \sum_{j \in \mathcal{J}_i} x_{ij} = 1, \quad \forall\, i=1,\dots,N, \\
& x_{ij} \in \{0,1\}, \quad \forall\, i=1,\dots,N,\; \forall\, j \in \mathcal{J}_i.
\end{aligned}
\end{equation}

The presence of both integer and continuous variables, coupled with the nonlinear characteristics of the objective function, designates the problem as a canonical MINLP problem. However, due to the lack of knowledge about \( p_{ij}(d_i) \), we leverage historical feedback data to construct a NN-based risk model for each domain~\cite{SLADNN23}. These risk models serve as surrogates for \( p_{ij}(d_i) \) in the optimization process, providing an estimated acceptance probability based on past observations.

\subsection{NP-Hardness Analysis}
We demonstrate that the joint optimization problem described in~(\ref{eq:optimization_problem}) is NP-hard by reducing from the well-known Multiple-Choice Subset Sum Problem (MCSSP). To this end, we consider a simplified version of the problem where only one provider is available per domain. In this case, the decision problem simplifies to the following objective:
\begin{equation}\label{eq:simple_problem}
\begin{aligned}
\max_{d_i} \quad & \prod_{i=1}^N p_i(d_i)\\
\text{s.t.} \quad & \sum_{i=1}^{N} d_i = d_{\text{e2e}}, \\
& d_i \ge 0, \quad \forall\, i=1,\dots,N.
\end{aligned}
\end{equation}
Now, we define an instance of MCSSP: Given $N$ disjoint sets $\{S_i\}_{i=1}^N$ of nonnegative integers and a target sum $K$, the goal is to determine whether it is possible to choose exactly one element from each set such that the sum of the selected elements equals $K$.
We then construct a corresponding instance of the simplified problem described in~(\ref{eq:simple_problem}) as follows:
\begin{itemize}
    \item The number of domains is set to $N$.
    \item The total E2E delay budget is $d_{\text{e2e}} = K$.
    \item For the provider in each domain $i$, we define the acceptance probability function $p_i(d_i)$ as:
    \begin{equation}
    p_i(d_i) =
    \begin{cases}
        1, & \text{if } d_i \in S_i, \\
        0, & \text{otherwise}.
    \end{cases}
    \end{equation}
    \item The decision version of the simplified problem asks \textit{whether there exists a feasible delay allocation $\{d_i\}_{i=1}^N$ such that $p_{\text{e2e}}=1$, subject to the constraints in}~(\ref{eq:simple_problem}).
\end{itemize}
This construction ensures that $p_i(d_i) = 1$ if and only if the allocated delay $d_i$ is equal to at least one element in $S_i$. As a result, $p_{\text{e2e}}$ is equal to 1 if and only if $d_i \in S_i$ for all $i$. Moreover, since $\{d_i\}_{i=1}^N$ sum up to $K$, any feasible solution that achieves $p_{\text{e2e}} = 1$ corresponds to a valid solution to the MCSSP instance.
%Conversely, if no such selection exists, then at least one domain will be assigned a value $d_i \notin S_i$, resulting in $p_i(d_i) = 0$ and hence $p_{\text{e2e}} = 0$.
Therefore, solving the decision version of the simplified problem is equivalent to solving MCSSP, which is known to be NP-complete~\cite{Kellerer2004}. Hence, the optimization version of simplified problem in~(\ref{eq:simple_problem}) is NP-hard. Since the original problem in~(\ref{eq:optimization_problem}) generalizes this setting by incorporating continuous, nonlinear acceptance probability functions and allowing multiple providers per domain, it is also NP-hard.


% We now demonstrate that the joint optimization problem in (\ref{eq:optimization_problem}) is NP-hard by reducing from the well-known Multiple-Choice Subset Sum Problem (MCSSP). To this end, consider a simplified version of our problem where the acceptance probability functions \( p_{ij}(d_i) \) are defined as threshold functions:
% \begin{equation}
% p_{ij}(d_i) =
% \begin{cases}
% 1, & \text{if } d_i \ge d_{ij}^{\min}, \\
% 0, & \text{otherwise},
% \end{cases}
% \end{equation}
% where \(d_{ij}^{\min}\) represents the minimum delay required by provider \( j \) in domain \( i \) to accept the SLA request. In this simplified version, the acceptance probability of domain \( i \) is $1$ if and only if the allocated delay \( d_i \) meets or exceeds the threshold \( d_{ij}^{\min} \) corresponding to the selected provider; otherwise, the acceptance probability is $0$.
% For the analysis, we assume that the thresholds \(d_{ij}^{\min}\) are known—a simplification not present in the original problem.
% Moreover, since the domain delay requests must sum to the E2E delay budget \( d_{\text{e2e}} \), the thresholds \( d_{ij}^{\min} \) effectively serve as the lower bounds for the feasible allocation \( d_i \).
% Consequently, a necessary condition for a feasible selection of providers is:
% \begin{equation}\label{eq:simplified}
% \sum_{i=1}^{N} d^{\min}_{i, j(i)} \leq d_{\text{e2e}},
% \end{equation}
% where $j(i) \in \mathcal{J}_i$ denotes the provider selected for domain $i$.
% This setup corresponds to a relaxed feasibility version of MCSSP, where the goal is to determine whether there exists a selection of exactly one item from each of several disjoint groups such that the sum of their weights is less than or equal to a given capacity. The mapping is as follows:
% \begin{itemize}
%     \item Each domain $i$ corresponds to a group in the MCSSP.
%     \item Each provider $j \in \mathcal{J}_i$ corresponds to an item in group $i$.
%     \item The weight of item $j$ in group $i$ is $d_{ij}^{\min}$.
%     \item The capacity is the E2E delay budget $d_{\text{e2e}}$.
%     %\item The objective is to select one item per group (i.e., one provider per domain) such that the total weight is less than or equal to $d_{\text{e2e}}$.
% \end{itemize}
% % The objective is to select one item per group (one provider per domain) such that the total weight ($d_{ij}^{\min}$) is less than or equal to the capacity ($d_{\text{e2e}}$), same as described in~(\ref{eq:simplified}).
% % Hence, satisfying (\ref{eq:simplified}) corresponds to finding a feasible solution to the MCSSP variant, which is known to be NP-complete~\cite{Kellerer2004}.
% Hence, finding a feasible solution to (\ref{eq:simplified}) corresponds to solving the MCSSP variant, which is known to be NP-complete~\cite{Kellerer2004}.
% Therefore, since solving even this simplified version of our problem is NP-hard, the original problem in~(\ref{eq:optimization_problem}), which generalizes it by incorporating nonlinear, data-driven acceptance functions and a maximization objective, is also NP-hard.
% This simplified formulation is equivalent to the MCKP. In the MCKP, we are given:
% \begin{itemize}
%     \item \( N \) disjoint groups, with each group \( i \) corresponding to domain \( i \).
%     \item For each group \( i \), a set of items (providers) \( j \in \mathcal{J}_i \), where each item is characterized by a weight \( d_{ij}^{\min} \) (minimum required delay) and an associated profit \( v_{ij} \) (which can be set to $1$ for all items, reflecting the SLA acceptance).
%     \item A knapsack with capacity \( d_{\text{e2e}} \) (the E2E delay budget).
% \end{itemize}
% The objective in the MCKP is to select exactly one item from each group such that the total weight does not exceed the knapsack capacity \( d_{\text{e2e}} \) while maximizing the total profit. In our case, achieving a total profit of \( N \) (i.e., a profit of $1$ from each domain) is equivalent to ensuring that the SLA is accepted across all domains.
% % Since the decision version of the MCKP is NP-hard, the simplified version of our problem inherits this computational complexity. As our original problem generalizes this case by incorporating more complex acceptance probability functions, it is also NP-hard.
% Since the decision version of the MCKP is NP-complete~\cite{Kellerer2004}, it follows that the simplified version of our problem is NP-hard. Given that our original problem in (\ref{eq:optimization_problem}) generalizes this setting by incorporating more complex acceptance probability functions \( p_{ij}(d_i) \), the overall problem is NP-hard as well.

% Due to the NP-hard nature of the problem, we resort to meta-heuristic approaches that leverage the risk models—constructed from historical data—to guide the search for near-optimal solutions in a computationally feasible manner.


Given the NP-hard nature of the problem, finding an exact solution is computationally intractable for large-scale systems. As a result, we resort to meta-heuristic approaches, leveraging the domain-specific risk models built from historical data to guide the search for near-optimal solutions.% In the subsequent section, we describe the proposed meta-heuristic approach.

% \subsection{NP-Hardness Analysis}

% We demonstrate that the joint optimization problem in (\ref{eq:optimization_problem}) is NP-hard by reducing from the well-known Multiple-Choice Knapsack Problem (MCKP). Consider a simplified version of our problem where the acceptance probability functions \( p_{ij}(d_i) \) are defined as threshold functions:
% \[
% p_{ij}(d_i) =
% \begin{cases}
% 1, & \text{if } d_i \ge T_{ij}, \\
% 0, & \text{otherwise},
% \end{cases}
% \]
% where \( T_{ij} \) represents the minimum delay required by provider \( j \) in domain \( i \) to accept the SLA request. Under this simplification, the acceptance probability for a domain \( i \) is 1 if and only if the allocated delay \( d_i \) meets or exceeds the threshold \( T_{ij} \) of the selected provider \( j \). Since each \( d_i \) not only must be at least \( T_{ij} \) for acceptance but also the allocations collectively must equal the available budget \( D \), the thresholds \( T_{ij} \) effectively serve as the feasible lower bounds for \( d_i \).
% As a result, a necessary condition for a feasible combination of providers is:
% \[
% \sum_{i=1}^{N} T_{ij} \le D.
% \]
 

% This formulation is equivalent to the MCKP. In the MCKP, we are given:
% \begin{itemize}
%     \item \( N \) disjoint groups (classes), where each group \( i \) corresponds to domain \( i \).
%     \item For each group \( i \), a set of items (providers) \( j \in \mathcal{J}_i \), where each item has a weight \( T_{ij} \) (interpreted as the required delay) and a profit \( v_{ij} \) (which we can set to 1 for all items, reflecting the binary success of the SLA acceptance).
%     \item A knapsack with capacity \( D \) (the overall delay budget).
% \end{itemize}
% The objective in the MCKP is to select exactly one item from each group such that the total weight does not exceed the capacity \( D \) and the total profit is maximized. In our case, achieving a total profit of \( N \) (i.e., a profit of 1 from each domain) is equivalent to ensuring that the SLA is accepted end-to-end. 

% Since the decision version of the MCKP is NP-complete, it follows that even this simplified instance of our problem is NP-hard. Given that our original problem (\ref{eq:optimization_problem}) generalizes this simplified case by incorporating more complex (and typically non-convex) acceptance probability functions \( p_{ij}(d_i) \), the overall problem is NP-hard as well.

% Due to the NP-hard nature of the problem, we resort to meta-heuristic approaches that leverage the risk models built from historical data to guide the search for near-optimal solutions in a computationally feasible manner.

% \subsection{NP-Hardness Analysis}

% The joint optimization problem in (\ref{eq:optimization_problem}) is a mixed-integer nonlinear programming (MINLP) problem, which is generally NP-hard. To illustrate this, we consider a simplified version of the problem. Assume that the acceptance probability \( p_{ij}(d_i) \) is a threshold function defined as follows:
% \[
% p_{ij}(d_i) =
% \begin{cases}
% 1, & \text{if } d_i \ge d_{ij}^{\min}, \\
% 0, & \text{otherwise},
% \end{cases}
% \]
% where \( d_{ij}^{\min} \) represents the minimum delay required for provider \( j \) in domain \( i \) to accept the SLO \( d_i \). Under this simplification, the E2E acceptance probability becomes 1 if and only if the delay allocated to each domain \( i \) is at least \( d_{ij}^{\min} \) for the chosen provider \( j \). Consequently, the problem reduces to:
% \begin{enumerate}
%     \item Selecting a provider \( j \) for each domain \( i \), and
%     \item Allocating delays \( d_i \ge d_{ij}^{\min} \) such that \( \sum d_i = d_{e2e} \).
% \end{enumerate}

% This simplified problem is similar to a variant of the knapsack problem, where one must choose items (providers) with associated minimum resource (delay) requirements \( d_{ij}^{\min} \) while ensuring that the total resource allocation does not exceed the available budget, i.e., \( \sum d_{ij}^{\min} \le d_{\text{e2e}} \). Since the knapsack problem is NP-hard, the simplified version of our problem inherits this computational complexity. As our original problem generalizes this case by incorporating more complex acceptance probability functions, it is also NP-hard.

% Due to the NP-hard nature of the problem, getting an exact solution is computationally intractable for large-scale systems. Hence, we resort to meta-heuristic approaches, leveraging the domain-specific risk models built from historical data to guide the search for near-optimal solutions. In the subsequent section, we describe the proposed meta-heuristic approach.



\section{Methodology}

\subsection{Background}
\noindent \textbf{ILS.} Iterated Local Search (ILS)~\cite{Lourenço2003} is a meta-heuristic approach that enhances local search algorithms by escaping local optima through iterative perturbations and refinements.
% It is especially useful for combinatorial optimization problems, where the search space is large and complex.
ILS operates by first generating an initial solution, either randomly or via a heuristic method, and then refining it through a local search procedure to find a local optimum. Once a local optimum is identified, the algorithm introduces controlled randomness to perturb the solution and push it away from the identified optimum.
% A predefined acceptance criterion is then applied to determine whether the perturbed solution should replace the current solution.
This cycle of local search and perturbation continues until a stopping condition, such as reaching a maximum number of iterations or meeting a convergence criterion, is satisfied.
% \noindent \textbf{ILS.} Iterated Local Search (ILS)~\cite{Lourenço2003} is a meta-heuristic approach that enhances local search algorithms by escaping local optima through iterative perturbations and refinements. ILS is particularly useful for combinatorial optimization problems, where the search space is large and complex. ILS operates by iteratively refining solutions through local search and perturbation steps. The key components of the algorithm are:
% \begin{itemize}
%     \item \textbf{Initial Solution.} A starting solution is generated, either randomly or through a heuristic approach.
%     \item \textbf{Local Search.} The solution is refined using a local search technique to find a local optimum.
%     \item \textbf{Perturbation.} The local optimum is modified by introducing controlled randomness, pushing the solution away from the local optima.
%     \item \textbf{Acceptance Criterion.} The perturbed solution is accepted based on predefined criteria, such as improvements or probabilistic acceptance.
%     \item \textbf{Iteration.} The process repeats until a stopping criterion, such as a maximum number of iterations or convergence is met.
% \end{itemize}
ILS is used in networked cloud resource mapping to address the challenge of optimally partitioning and embedding virtual resources across multiple cloud providers~\cite{6226390}. ILS-based request partitioning has been shown to effectively balance cost and performance, leading to improved virtual network embedding outcomes.

\noindent \textbf{RADE.} Real-time Adaptive DEcomposition (RADE)~\cite{hsu2024online} is an advanced SLA decomposition framework that dynamically adjusts decomposition strategies based on real-time feedback of network conditions. Unlike static decomposition approaches, RADE employs online learning to enhance adaptability and accuracy. It utilizes a two-step decomposition approach~\cite{Vleeschauwer21_SLAdecomposition, SLADNN23}. First, the orchestrator maintains domain-specific NN-based risk models trained on historical SLA acceptance and rejection feedback. Next, the E2E SLA is decomposed into domain-specific SLAs to maximize the overall acceptance probability, using a grid search followed by Sequential Least Squares Programming (SLSQP) algorithm. To adapt to evolving network conditions, these risk models are updated timely via Online Gradient Descent (OGD). A First In First Out (FIFO) memory buffer preserves recent observations, ensuring stable learning while mitigating overfitting caused by transient anomalies.
RADE addresses key limitations of static decomposition methods by incorporating real-time adaptation. It also offers resilience against data corruption through its FIFO memory buffer. Experimental results show that RADE consistently outperforms traditional methods in dynamic multi-domain environments, making it a promising solution for adaptive SLA management in modern network architectures.
% \noindent \textbf{RADE.}
% Real-time Adaptive DEcomposition (RADE)~\cite{hsu2024online} is an advanced SLA decomposition framework that dynamically adjusts decomposition strategies based on real-time feedback and network conditions. Unlike static decomposition approaches, RADE incorporates online learning to enhance adaptability and accuracy.
% RADE employs a two-step decomposition approach combined with neural network-based risk models:

% \begin{itemize}
%     \item \textbf{Risk Model Learning.} The orchestrator maintains domain-specific risk models trained on historical SLA acceptance and rejection feedback.
%     \item \textbf{Optimization-based Decomposition.} The E2E SLA is decomposed into domain-specific SLAs to maximize the E2E acceptance probability. A grid search followed by the SLSQP algorithm is employed.
%     \item \textbf{Online Update.} The risk models are updated in real-time using Online Gradient Descent (OGD) to adapt to evolving network conditions.
%     \item \textbf{FIFO Memory Buffer.} A memory buffer maintains recent observations, ensuring stable  learning while preventing overfitting from transient anomalies.
% \end{itemize}

% RADE addresses key limitations of static decomposition methods by incorporating real-time adaptation mechanisms.
% Furthermore, RADE offers resilience against data corruption with FIFO memory buffer.
% Experimental results demonstrate that RADE consistently outperforms traditional methods in dynamic multi-domain environments, making it a promising approach for adaptive SLA management in modern network architectures.





\subsection{Risk-Aware Iterated Local Search}
In this work, we propose RAILS, a risk model-driven meta-heuristic method to solve the joint provider selection and SLA decomposition problem.
The optimization problem involves two interconnected sets of decision variables (see Section~\ref{sec:problem formulation}). On one hand, we have discrete variables that determine which provider is selected in each domain. On the other hand, we have continuous variables that specify how the E2E delay budget is decomposed among the domains to maximize the E2E acceptance probability. These two aspects of the problem are inherently intertwined because the acceptance probability in each domain is computed using risk models that depend on both the selected provider and the assigned delay requests.
Specifically, once provider $j$ is chosen for domain $i$, the corresponding risk model serves as its surrogate, predicting \( p_{ij}(d_i) \) for a given delay budget \( d_i \).
%The risk models, which are constructed from historical data using NNs, capture the admission control behavior of each provider as a function of the delay allocation.
%When a provider is selected for a domain, the corresponding risk model serves as its surrogate, predicting performance for a given delay budget.
%This means that the evaluation of a potential solution—i.e., a combination of provider selections and delay assignments—cannot be decoupled into two independent problems.
%A provider might appear attractive under a particular delay allocation in one domain, but the overall E2E performance also depends on the delay allocations and provider choices in other domains.
%In other words, the discrete and continuous decisions interact nonlinearly through the acceptance probability functions.
In RAILS, the framework efficiently explores the complex search space by iteratively refining provider selections with risk models.
%Local search operators adjust selections, while up-to-date risk models compute maximum E2E acceptance probabilities, guiding the search.
%The RAILS approach leverages these refinements and risk assessments to navigate the non-separable optimization landscape.

% The ILS framework serves as a robust heuristic for tackling the complex search space generated by these interconnected decision variables. Within each iteration of ILS, local search operators explore the neighborhood of the current solution by adjusting the provider selections. The risk models play a critical role during the evaluation phase of ILS. For each candidate provider selections, the up-to-date risk models are used to compute the corresponding maximum E2E acceptance probabilities using RADE, which in turn guide the search toward more promising regions of the solution space. Thus, the proposed RAILS approach leverages the iterative refinement of candidate solutions, guided by risk model assessments, to navigate the challenging, non-separable optimization landscape.
\begin{figure}[ht]
     \centering
     \includegraphics[width=0.93\columnwidth]{figures/flow.png}
    \caption{A single-iteration workflow of RAILS.}
    \label{fig:flow}
\end{figure}
% The following outlines the main steps of RAILS:
% \begin{enumerate}
%     \item Receive a new SLA request along with the latest feedback data.
%     \item Update the risk models using the latest feedback data.
%     \item Randomly initialize a solution for the provider selections across all domains.
%     \item Apply perturbations to the current solution to explore different regions of the solution space.
%     \item Perform a local search, utilizing the up-to-date risk models to find the neighbor solution that yields the maximum E2E acceptance probability in~(\ref{eq:e2eprob}).
%     \item Repeat steps 4 and 5 until a stop criterion is met.
% \end{enumerate}

% Fig.~\ref{fig:flow} illustrates how RAILS progresses from receiving the new SLA request and the most recent feedback, through updating the risk models and the corresponding memory buffer, and then repeatedly refining a provider-selection solution. Specifically, after the models are updated, an initial solution is randomly generated, followed by iterative perturbation and local search that exploit the risk models to identify the neighbor candidate with the highest E2E acceptance probability. The process continues until a stopping condition is met, at which point the best solution found is returned. The proposed RAILS approach can be viewed as an ILS framework whose “engine” is RADE. In other words, RAILS repeatedly perturbs and refines a solution, while delegating the evaluation step to RADE’s dynamic risk modeling and online decomposition capabilities. This synergy enables effective handling of the coupled discrete–continuous nature of provider selection and SLA decomposition, offering a holistic solution for real-time, multi-domain systems.
Fig.~\ref{fig:flow} illustrates the workflow of the RAILS algorithm. The process begins with updating the risk models and memory buffer using the latest feedback data.
Next, an initial solution for provider selection is generated. The algorithm then enters an iterative refinement phase with perturbation and local search steps.
%These steps leverage the risk models to identify neighboring solutions with the highest E2E acceptance probability.
The perturbation step randomly alters the provider selection for each domain with a probability $p_{\mu}$ to possibly escape local optima, while the local search step refines the solution by randomly selecting a domain and exhaustively checking all provider options within the domain to identify the best one based on the risk models.
This iterative process continues within an inner and outer loop structure until a predefined stopping condition is met, at which point the best solution identified is returned. RAILS operates within an ILS framework, where the core evaluation mechanism is powered by RADE. Specifically, ILS performs the repeated perturbation and local search steps, while RADE handles dynamic risk modeling and real-time decomposition. This synergy enables effective handling of the coupled discrete–continuous nature of provider selection and SLA decomposition.

\section{Performance Evaluation}

\subsection{Simulation Environment}
In our simulation environment, we model the dynamic behavior of each provider's system load and the resulting performance characteristics that affect SLA acceptance. In particular, we capture the temporal variations in load and their impact on the minimum delay that a provider can support, which in turn governs the acceptance probability of an SLA request. Because this subsection focuses on a single-domain provider, we omit the $i$ and $j$ subscripts for clarity.

\noindent \textbf{System Load Modeling.} For each provider, the system load is assumed to evolve periodically over time. Let \( t \) denote the current time. The system load \( \ell(t) \) is modeled using a sinusoidal function~\cite{10.1145/2188286.2188301} as follows:
\begin{equation}\label{eq:system_load}
\ell(t) = \ell_{\text{base}} \cdot k + \ell_{\text{base}} \cdot (1 - k) \cdot \frac{1 + \sin\!\left(\frac{2\pi t}{T} + \phi\right)}{2},
\end{equation}
where \(\ell_{\text{base}}\) is a constant representing the baseline load of the provider, \( k \in [0,1] \) is a parameter that determines the fraction of the load that is static, \( T \) is the period of the sinusoidal fluctuation, and \(\phi\) is the phase shift.
% where:
% \begin{itemize}
%     \item \(\ell_{\text{base}}\) is a constant representing the baseline load of the provider.
%     \item \( k \in [0,1] \) is a parameter that determines the fraction of the load that is static.
%     \item \( T \) is the period of the sinusoidal fluctuation.
%     \item \(\phi\) is the phase shift.
% \end{itemize}
This formulation ensures that the system load varies between the minimum load \(\ell_{\text{base}} \cdot k\)  and the maximum load \(\ell_{\text{base}}\). The parameter $k$ allows for a mixture of a constant baseline load and a dynamic component.
%thereby enabling the simulation of various operational conditions in real-world network systems.

\noindent \textbf{Minimum Supportable Delay.}
Given the dynamic system load defined in~(\ref{eq:system_load}), the minimum delay that a provider can support for an incoming request is assumed to depend on both a fixed latency component and an exponential function of the system load. Specifically, the minimum supportable delay \( d^{\min}(t) \) is defined as:
\begin{equation}\label{eq:min_delay}
d^{\min}(t) = \alpha + \exp\!\left(\beta \cdot \ell(t)\right),
\end{equation}
where \( \alpha \) represents the inherent latency of the system when the load is minimal (i.e., the baseline latency), and \(\beta\) is a parameter that characterizes how sensitive the delay is to changes against system load.
% where:
% \begin{itemize}
%     \item \(\alpha\) represents the inherent latency of the system when the load is minimal (i.e., the baseline latency).
%     \item \(\beta\) is a parameter that characterizes how sensitive the delay is to changes against system load.
% \end{itemize}
This expression reflects that as the system load increases, the provider's capability to handle requests with low delay diminishes, leading to a higher minimum supportable delay. Fig.~\ref{fig:delay} demonstrates this effect for different parameter values.
\begin{figure}[ht]
     \centering
     \includegraphics[width=0.9\columnwidth]{figures/delay.png}
    \caption{Minimum supportable delay versus system load.}
    \label{fig:delay}
    \vspace{-0.5em}
\end{figure}
The exponential relationship captures the non-linear increase in minimum supportable delay as the load intensifies, while \(\alpha\) sets the lower bound of latency.

\noindent \textbf{Acceptance Probability.}
Based on the minimum supportable delay defined in~(\ref{eq:min_delay}), the acceptance probability of a service level request is defined as a function of the requested delay \( d \). Specifically, if the requested delay is less than the minimum supportable delay \( d^{\min}(t) \), the request is rejected. Otherwise, the acceptance probability follows an S-curve, increasing with the excess delay and saturating as the requested delay becomes much larger than \( d^{\min}(t) \)~\cite{Vleeschauwer21_SLAdecomposition}. Formally, the acceptance probability \( p(d; t) \) is defined as:
\begin{equation}\label{eq:acceptance_probability}
p(d; t) =
\begin{cases}
0, & \text{if } d < d^{\min}(t), \\[1mm]
1 - \exp\!\left(-\lambda \, (d - d^{\min}(t))\right), & \text{if } d \ge d^{\min}(t),
\end{cases}
\end{equation}
where \( \lambda > 0 \) is a parameter that controls the rate at which the acceptance probability increases as the delay requirement exceeds the minimum supportable delay. The response curves with different parameter settings are illustrated in Fig.~\ref{fig:prob}.
\begin{figure}[ht]
     \centering
     \includegraphics[width=0.9\columnwidth]{figures/acceptance.png}
    \caption{Piecewise acceptance response curves.}
    \label{fig:prob}
    \vspace{-0.5em}
\end{figure}

The piecewise function ensures that any request with a delay requirement less than the system's minimum supportable delay is rejected. For requests above this threshold, the probability of acceptance increases rapidly at first and gradually levels off, reflecting the typical behavior of admission control in real-world service provider systems.
%This simulation framework enables us to evaluate our SLA decomposition strategies under realistic and dynamically varying conditions, providing insights into the performance of our proposed method.

\subsection{Evaluation Scenarios}

To assess the long-term performance of the proposed RAILS framework, we conduct simulations over $100$ discrete time steps within the designed simulation environment. At each time step, a new service request arrives with an E2E delay budget of $100$\,ms. The RAILS is then applied to select a service provider for each domain and to determine the corresponding delay decomposition that maximizes the E2E acceptance probability according to the risk models built from historical data. Specifically, once the RAILS provides a provider selection and delay decomposition, this assignment is evaluated using the ground-truth acceptance probability models (described in~(\ref{eq:acceptance_probability})) to compute the actual E2E acceptance probability. This process is repeated at every time step, and the resulting E2E acceptance probabilities are collected to compute an overall average performance metric, namely:
\begin{equation}\label{eq:avge2e}
\overline{p}_{\text{e2e}} = \frac{1}{T} \sum_{t=1}^{T} p_{\text{e2e}}^{(t)} = \frac{1}{T} \sum_{t=1}^{T} \prod_{i=1}^{N} \left( \sum_{j \in \mathcal{J}_i} x_{ij}^{(t)} \, p_{ij}^{(t)}(d_i^{(t)}) \right),
\end{equation}
where \( T \) denote the total number of simulation time steps, and \( N \) represents the total number of involved domains.

% Let \( T \) denote the total number of simulation time steps (e.g., \(T=100\)). At each time step \( t \) (\( t = 1, 2, \ldots, T \)), suppose that an assignment is made by selecting one provider per domain and decomposing the E2E delay budget among the \( N \) domains. For domain \( i \) at time \( t \), let:
% \begin{itemize}
%     \item \( x_{ij}^{(t)} \in \{0,1\} \) be the binary variable that is 1 if provider \( j \) (from the set \( \mathcal{J}_i \)) is selected for domain \( i \) at time \( t \), and 0 otherwise,
%     \item \( d_{t,i} \ge 0 \) be the delay budget allocated to domain \( i \) at time \( t \),
%     \item \( p_{ij}(d_{t,i}) \) be the acceptance probability of domain \( i \) when using provider \( j \) given a delay \( d_{t,i} \).
% \end{itemize}

% Thus, the effective acceptance probability for domain \( i \) at time \( t \) is given by:
% \[
% P_{i}^{(t)} = \sum_{j \in \mathcal{J}_i} x_{ij}^{(t)} \, p_{ij}(d_{t,i}).
% \]

% Assuming that the acceptance events in the domains are independent, the overall E2E acceptance probability at time \( t \) is the product of the individual domain acceptance probabilities:
% \[
% P_{\text{E2E}}^{(t)} = \prod_{i=1}^{N} P_{i}^{(t)} = \prod_{i=1}^{N} \left( \sum_{j \in \mathcal{J}_i} x_{ij}^{(t)} \, p_{ij}(d_{t,i}) \right).
% \]

% Finally, the overall E2E average acceptance probability over the \( T \) time steps is defined as:
% \[
% \overline{P}_{\text{E2E}} = \frac{1}{T} \sum_{t=1}^{T} P_{\text{E2E}}^{(t)} = \frac{1}{T} \sum_{t=1}^{T} \prod_{i=1}^{N} \left( \sum_{j \in \mathcal{J}_i} x_{ij}^{(t)} \, p_{ij}(d_{t,i}) \right).
% \]

At each time step, we assume that a set of historical requests and their associated feedback are available from each provider. A historical sample is represented by a pair \((d^{(t)}, a^{(t)})\), where \(d^{(t)}\) is the delay request and \(a^{(t)} \in \{0,1\}\) is the binary decision outcome from the admission control. For generating the feedback data, we simulate requests by sampling delay requirements uniformly from the interval \([10\,\text{ms}, 100\,\text{ms}]\). Each request is then processed through the corresponding ground-truth acceptance probability model to obtain its actual acceptance probability, and a coin-flipping process is used to determine whether the request is accepted or not by the admission control.
For performance comparison, we consider two baselines:\\
% \begin{itemize}
%     \item \textbf{Non-Risk-Aware (NRA).} In this baseline, a provider is selected at random for each domain, and the E2E delay budget is evenly decomposed among the domains as a heuristic guess, without leveraging risk models.
%     \item \textbf{Optimal (OPT).} This benchmark is obtained via an exhaustive search with full access to ground-truth acceptance probability models, representing the theoretical upper bound on performance.
% \end{itemize}
\noindent \textbf{Non-Risk-Aware (NRA).} In this baseline, a provider is selected at random for each domain, and the E2E delay budget is evenly decomposed among the domains as a heuristic guess, without leveraging risk models.\\
\noindent \textbf{Optimal (OPT).} This benchmark uses an exhaustive search with full access to ground-truth acceptance probability models, representing the theoretical upper bound on performance.

%By comparing the RAILS approach with these baselines, we aim to demonstrate its effectiveness in  achieving higher E2E acceptance probabilities over time, while maintaining reasonable computational time.

\subsection{Experimental Setup}

In our experiments, we consider a network slicing scenario involving $3$ domains, each comprising 10 service providers. The ground-truth models for each provider are generated using a set of randomly selected parameters to emulate realistic and heterogeneous operational conditions. For each provider, the baseline latency \(\alpha\) is drawn uniformly from \([0, 2]\); The parameter $\lambda$ in~(\ref{eq:acceptance_probability}) is set to $0.2$, and $k$ is set to $0.5$ in~(\ref{eq:system_load}); A domain-wise additional latency, randomly chosen from the set \(\{0, 10, 20\}\), is added to the baseline latency \(\alpha\) to reflect inter-domain behavioral shifts; the load-sensitivity parameter \(\beta\) is sampled uniformly from \([0.04, 0.06]\); the baseline system load \(\ell_{\text{base}}\) is drawn uniformly from \([30, 50]\); the period of the sinusoidal load fluctuation is selected as an integer uniformly from the range \([30, 60]\); and the phase shift in the load function is chosen uniformly from the interval \([0, \pi]\).

At each time step, we assume that the number of recent feedback samples available from each provider is proportional to its current system load defined in~(\ref{eq:system_load}).  We use the integer part of the load as the number of samples. For the RAILS framework, the number of iterations is set empirically to the total number of providers across all domains (i.e., \(3 \times 10 = 30\)), and the perturbation probability $p_{\mu}$ is $0.8$. Results are averaged over $10$ independent runs to ensure statistical significance.
Each risk model is implemented as a $2$-layer monotonic Multi-Layer Perceptron (MLP) with a hidden dimension of $16$,
%Layer Normalization (LN), and ReLU activation function,
similar to that described in~\cite{hsu2024online}. AdamW optimizer is used with a learning rate of $0.01$. A memory buffer of size $300$ is maintained, and each risk model update involves $10$ iterations.



\section{Results and Discussion}
% Average E2E acceptance probability over time
Fig.~\ref{fig:e2eacc} presents the average E2E acceptance probability for the considered approaches. Each bar reflects the average performance metric defined in~(\ref{eq:avge2e}).
%, while Fig.~\ref{fig:runtime} reports the average run time per request. 
The NRA approach achieves an average acceptance probability of approximately $0.71$. The large error bars reveal significant performance fluctuations, suggesting that the absence of strategic decision-making leads to suboptimal performance. In contrast, the proposed RAILS method demonstrates a substantial improvement, achieving an average acceptance probability of around $0.89$. The error bars are smaller compared to the NRA approach, indicating more stable outcomes.
Moreover, we include results for a RAILS variant, denoted RAES, where the ILS search component is replaced with an exhaustive search. RAES's performance reflects RAILS running with an effectively infinite number of iterations. Both RAILS and RAES achieve comparable performance, while RAILS requires only $31.6\%$ of RAES's run time, demonstrating its computational efficiency, as shown in Fig.~\ref{fig:runtime}.
The OPT approach, which represents the theoretical performance upper bound, achieves an average acceptance probability of about $0.95$. While RAILS does not fully reach the OPT benchmark, it comes remarkably close, balancing computational efficiency with SLA acceptance rates.
% \begin{figure}[h]
%      \centering
%      \includegraphics[width=0.8\columnwidth]{figures/e2eacc.png}
%     \caption{Average E2E acceptance probabilities over time (colored bars, left axis) and run time (gray bars, right axis).}
%     \label{fig:e2eacc}
%     % \vspace{-0.5em}
% \end{figure}

\begin{figure}[h]
    \centering
    \begin{subfigure}{0.3\textwidth}
        \centering
        \includegraphics[width=\textwidth]{figures/e2eacc.png} % Replace with your first image file path
        % \caption{Run Time Comparison between RAILS and RAES}
        \caption{E2E Acceptance Probability}
        \label{fig:e2eacc}
    \end{subfigure}
    \begin{subfigure}{0.175\textwidth}
        \centering
        \includegraphics[width=\textwidth]{figures/runtime.png} % Replace with your second image file path
        % \caption{E2E Acceptance Probability for NRA, RAILS, RAES, and OPT}
        \caption{Run Time}
        \label{fig:runtime}
    \end{subfigure}
    \caption{Performance comparison: (a) E2E SLA acceptance probability over time; (b) computational run time.}
    \label{fig:combined}
\end{figure}

% \begin{table}
% \centering
% \caption{Partial trace of a simulation run.}\label{tab:log}
% \begin{tabular}{|c|c|c|c|c|}
% \hline
% Step & Method & $p_{\text{e2e}}$ & $d_1, d_2, d_3$ & Providers \\
% \hline
% \multirow{3}{*}{1} & NRA & 0.47 & 33.33, 33.33, 33.33 & 2, 4, 5 \\
%  & RAILS & 0.93 & 25.93, 35.02, 40.07 & 1, 0, 3 \\
%  & OPT & 0.94 & 24.59, 33.63, 42.78 & 9, 1, 3 \\
% \hline
% \multirow{3}{*}{5} & NRA & 0.71 & 33.33, 33.33, 33.33 & 3, 3, 6 \\
%  & RAILS & 0.93 & 23.89, 33.56, 43.55 & 7, 0, 8 \\
%  & OPT & 0.95 & 23.78, 33.55, 42.67 & 9, 6, 3 \\
% \hline
% \multirow{3}{*}{10} & NRA & 0.68 & 33.33, 33.33, 33.33 & 8, 8, 9 \\
%  & RAILS & 0.94 & 23.78, 32.20, 44.02 & 0, 0, 8 \\
%  & OPT & 0.95 & 23.55, 33.21, 43.24 & 9, 6, 3 \\
% \hline
% \multirow{3}{*}{15} & NRA & 0.84 & 33.33, 33.33, 33.33 & 2, 4, 8 \\
%  & RAILS & 0.93 & 22.91, 34.06, 43.03 & 0, 3, 8 \\
%  & OPT & 0.95 & 23.66, 33.22, 43.13 & 9, 3, 3 \\
% \hline
% \multirow{3}{*}{20} & NRA & 0.79 & 33.33, 33.33, 33.33 & 7, 5, 8 \\
%  & RAILS & 0.94 & 19.99, 36.75, 43.26 & 2, 7, 8 \\
%  & OPT & 0.95 & 23.82, 33.11, 43.08 & 9, 7, 1 \\
% \hline
% \end{tabular}
% \end{table}
% trace of selected providers
\begin{table}[ht]
\centering
\caption{Partial trace of a simulation run.}\label{tab:log}
\begin{tabular}{|c|c|c|c|c|}
\hline
Step & Method & $p_{\text{e2e}}$ & $d_1, d_2, d_3$ & Providers \\
\hline
\multirow{3}{*}{0} & NRA & 0.78 & 33.33, 33.33, 33.33 & 7, 9, 6 \\
& RAILS & 0.92 & 22.00, 33.00, 45.00 & 8, 6, 0 \\
& OPT & 0.94 & 24.23, 32.50, 43.27 & 3, 1, 0 \\
\hline
\multirow{3}{*}{5} & NRA & 0.81 & 33.33, 33.33, 33.33 & 3, 4, 9 \\
& RAILS & 0.88 & 22.63, 32.08, 45.30 & 4, 6, 1 \\
& OPT & 0.94 & 24.31, 32.49, 43.20 & 3, 1, 6 \\
\hline
\multirow{3}{*}{10} & NRA & 0.75 & 33.33, 33.33, 33.33 & 5, 4, 1 \\
& RAILS & 0.93 & 26.22, 30.30, 43.48 & 8, 6, 6 \\
& OPT & 0.94 & 24.17, 32.98, 42.85 & 5, 1, 3 \\
\hline
\multirow{3}{*}{15} & NRA & 0.73 & 33.33, 33.33, 33.33 & 7, 3, 9 \\
& RAILS & 0.90 & 20.00, 30.00, 50.00 & 1, 6, 7 \\
& OPT & 0.94 & 24.11, 33.00, 42.90 & 2, 4, 3 \\
\hline
\end{tabular}
\end{table}

Table~\ref{tab:log} provides a partial trace of a simulation run, showcasing the E2E acceptance probabilities, delay decompositions, and the indices of the selected providers across different time steps. The OPT method shows that the optimal provider selections and delay decompositions change frequently over time, reflecting dynamic network conditions. For instance, optimal providers shift from $(3, 1, 0)$ at step $0$ to $(2, 4, 3)$ at step $15$, highlighting the need for adaptive risk models to maintain high SLA acceptance rates.
Furthermore, RAILS achieves near-optimal performance across time steps, even without always selecting the optimal providers.
%Even without always selecting the optimal providers, RAILS achieves E2E acceptance probabilities close to the Optimal method across time steps.
\begin{figure}[ht]
     \centering
     \includegraphics[width=0.9\columnwidth]{figures/acc_overtime.png}
    \caption{E2E acceptance probability over time for a single run.}
    \label{fig:e2eacc_run}
    % \vspace{-0.5em}
\end{figure}

Fig.~\ref{fig:e2eacc_run} illustrates the temporal dynamics of E2E acceptance probabilities for a single representative run. The OPT method consistently achieves near-perfect acceptance.
RAILS closely tracks the optimal performance, with slight fluctuations, indicating its effectiveness in adapting to dynamic network conditions.
In contrast, the NRA method experiences significant variability and frequent drops in acceptance probability, revealing its limitations in predicting and responding to environmental changes.
% complexity analysis?


\section{Conclusion}
This paper introduced Risk-Aware Iterated Local Search (RAILS), a meta-heuristic framework driven by NN-based risk models, for SLA decomposition and service provider selection in multi-domain networks. We formulated the problem as a Mixed-Integer Nonlinear Programming (MINLP) problem and demonstrated its NP-hardness. RAILS integrates dynamic risk modeling with iterated local search, effectively handling the complex optimization landscape of interdependent decisions. Simulation results showed that RAILS achieves near-optimal performance against the theoretical optima while maintaining low computational overhead.
%This highlights RAILS' ability to adapt to dynamic network conditions with high SLA acceptance rates efficiently.
Overall, RAILS offers a robust and efficient solution for adaptive network slicing management in modern network systems. Future work will explore the long-term impact of each decision on subsequent ones by formulating the problem as a Markov Decision Process (MDP) and applying Deep Reinforcement Learning (DRL) techniques.
%Additionally, we aim to model the dependencies between domains in the environment, moving beyond the assumption of independence to better reflect realistic network dynamics.

% An example of a floating figure using the graphicx package.
% Note that \label must occur AFTER (or within) \caption.
% For figures, \caption should occur after the \includegraphics.
% Note that IEEEtran v1.7 and later has special internal code that
% is designed to preserve the operation of \label within \caption
% even when the captionsoff option is in effect. However, because
% of issues like this, it may be the safest practice to put all your
% \label just after \caption rather than within \caption{}.
%
% Reminder: the "draftcls" or "draftclsnofoot", not "draft", class
% option should be used if it is desired that the figures are to be
% displayed while in draft mode.
%
%\begin{figure}[!t]
%\centering
%\includegraphics[width=2.5in]{myfigure}
% where an .eps filename suffix will be assumed under latex, 
% and a .pdf suffix will be assumed for pdflatex; or what has been declared
% via \DeclareGraphicsExtensions.
%\caption{Simulation Results}
%\label{fig_sim}
%\end{figure}

% Note that IEEE typically puts floats only at the top, even when this
% results in a large percentage of a column being occupied by floats.


% An example of a double column floating figure using two subfigures.
% (The subfig.sty package must be loaded for this to work.)
% The subfigure \label commands are set within each subfloat command, the
% \label for the overall figure must come after \caption.
% \hfil must be used as a separator to get equal spacing.
% The subfigure.sty package works much the same way, except \subfigure is
% used instead of \subfloat.
%
%\begin{figure*}[!t]
%\centerline{\subfloat[Case I]\includegraphics[width=2.5in]{subfigcase1}%
%\label{fig_first_case}}
%\hfil
%\subfloat[Case II]{\includegraphics[width=2.5in]{subfigcase2}%
%\label{fig_second_case}}}
%\caption{Simulation results}
%\label{fig_sim}
%\end{figure*}
%
% Note that often IEEE papers with subfigures do not employ subfigure
% captions (using the optional argument to \subfloat), but instead will
% reference/describe all of them (a), (b), etc., within the main caption.


% An example of a floating table. Note that, for IEEE style tables, the 
% \caption command should come BEFORE the table. Table text will default to
% \footnotesize as IEEE normally uses this smaller font for tables.
% The \label must come after \caption as always.
%
%\begin{table}[!t]
%% increase table row spacing, adjust to taste
%\renewcommand{\arraystretch}{1.3}
% if using array.sty, it might be a good idea to tweak the value of
% \extrarowheight as needed to properly center the text within the cells
%\caption{An Example of a Table}
%\label{table_example}
%\centering
%% Some packages, such as MDW tools, offer better commands for making tables
%% than the plain LaTeX2e tabular which is used here.
%\begin{tabular}{|c||c|}
%\hline
%One & Two\\
%\hline
%Three & Four\\
%\hline
%\end{tabular}
%\end{table}


% Note that IEEE does not put floats in the very first column - or typically
% anywhere on the first page for that matter. Also, in-text middle ("here")
% positioning is not used. Most IEEE journals/conferences use top floats
% exclusively. Note that, LaTeX2e, unlike IEEE journals/conferences, places
% footnotes above bottom floats. This can be corrected via the \fnbelowfloat
% command of the stfloats package.








% conference papers do not normally have an appendix


% use section* for acknowledgement
\section*{Acknowledgment}
This research was partially funded by the HORIZON SNS JU DESIRE6G project (grant no. 101096466) and the Dutch 6G flagship project ``Future Network Services''.




% trigger a \newpage just before the given reference
% number - used to balance the columns on the last page
% adjust value as needed - may need to be readjusted if
% the document is modified later
%\IEEEtriggeratref{8}
% The "triggered" command can be changed if desired:
%\IEEEtriggercmd{\enlargethispage{-5in}}

% references section
\bibliographystyle{IEEEtran}
\bibliography{references.bib}

% can use a bibliography generated by BibTeX as a .bbl file
% BibTeX documentation can be easily obtained at:
% http://www.ctan.org/tex-archive/biblio/bibtex/contrib/doc/
% The IEEEtran BibTeX style support page is at:
% http://www.michaelshell.org/tex/ieeetran/bibtex/
%\bibliographystyle{IEEEtran}
% argument is your BibTeX string definitions and bibliography database(s)
%\bibliography{IEEEabrv,../bib/paper}
%
% <OR> manually copy in the resultant .bbl file
% set second argument of \begin to the number of references
% (used to reserve space for the reference number labels box)
% \begin{thebibliography}{1}

% \bibitem{IEEEhowto:kopka}
% H.~Kopka and P.~W. Daly, \emph{A Guide to \LaTeX}, 3rd~ed.\hskip 1em plus
%   0.5em minus 0.4em\relax Harlow, England: Addison-Wesley, 1999.

% \end{thebibliography}




% that's all folks
\end{document}


