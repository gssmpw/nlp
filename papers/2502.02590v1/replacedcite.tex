\section{Related Work}
\subsection{Articulated object modeling} 
One line of work focuses on the perception end, including reconstruction of articulated objects from observations, joint parameter estimation, etc. ____ and ____ train a network to reconstruct an articulated object from input multi-frame point clouds. Some other works ____ learn joint parameters from active interaction. ____, ____, ____ and ____ reconstruct the geometry and joint parameters of an articulated object from multiview images obtained at distinct states of the articulated object. ____ reconstructs articulated objects from a single real-world RGB image through a network trained on large-scale synthetic data. ____ estimates joint parameters and part segments given the poincloud or image of an articulated object. However, these approaches either demand extensive observation of the same object or rely on existing articulated object data to train neural networks, with limited ability to generalize across only a small range of categories.

Alongside perception works, generation works including  ____ and ____, represents articulated objects as graphs and employs a diffusion model to fit the distribution. The shape, position, and semantic information of the parts are encoded in the vertices, while joint parameters are stored in the edges.  Similar to perception methods, these generation methods also depend on existing articulated object datasets to train their diffusion models and are unable to generalize beyond the training data. 

Additionally, there is a recent survey on articulated object modeling ____.

Overall, none of the existing methods can automatically create articulated objects in an open-vocabulary manner. 

\subsection{Part aware 3D generation} Instead of generating an 3D object as a whole, part aware 3D generation methods generate objects with part-level information. ____ learns two separate VAEs to model global structural information and detailed part geometries. ____ encodes 3D objects into a representation that disentangles structure and geometry. ____ utilizes a graph VAE to encode shapes into hierarchical graph representations. ____ applies a Seq2Seq generative network for part assembly and generation. ____ independently models part geometry and global part transformation, and conditioned on both of them, a diffusion model synthesizes the final shape. ____, on the other hand, generates part geometry latents with one diffusion model and synthesizes the global geometry with another diffusion model conditioned on these latents. ____, a recent release, learns a Neus model from generated multi-view images and corresponding 2D segmentation maps provided by ____, and extracts 3D segmentation masks using a clustering algorithm.

While these methods can produce shapes with plausible structures and part geometries, they frequently depend on object datasets with part-level annotations and fail to generalize beyond the datasets used for training. Furthermore, they do not generate articulation parameters for individual parts, causing the generated parts to be individually non-manipulatable in simulation, which limits their applicability in downstream tasks for robot learning.