% Use this file for citations not found in the ACL Anthology (contained in "anthology.bib").

% Use this file for citations not found in the ACL Anthology (contained in "anthology.bib").
@string(NAACL2024 = "Proceedings of the 2024 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies")
@string(NAACL2022industry = "Proceedings of the 2022 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies: Industry Track")
@string(NAACL2021industry = "Proceedings of the 2021 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies: Industry Papers")
@string(NAACL2019 = "Proceedings of the 2019 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies")
@string(NAACL2016 = "Proceedings of the 2016 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies")
@string(NAACL2013demo = "Proceedings of the 2013 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies: Demonstration Session")
@string(EACL2021 = "Proceedings of the 16th Conference of the European Chapter of the Association for Computational Linguistics")
@string(ACL2022 = "Proceedings of the 60th Annual Meeting of the Association for Computational Linguistics")
@string(ACL2020 = "Proceedings of the 58th Annual Meeting of the Association for Computational Linguistics")
@string(ACL2017 = "Proceedings of the 55th Annual Meeting of the Association for Computational Linguistics")
@string(ACL2015 = "Proceedings of the 53rd Annual Meeting of the Association for Computational Linguistics and the 7th International Joint Conference on Natural Language Processing")
@string(ACL2002 = "Proceedings of the 40th Annual Meeting of the Association for Computational Linguistics")
@string(EMNLP2018 = "Proceedings of the 2018 Conference on Empirical Methods in Natural Language Processing")
@string(EMNLP2023 = "Proceedings of the 2023 Conference on Empirical Methods in Natural Language Processing")
@string(INLG2020 = "Proceedings of the 13th International Conference on Natural Language Generation")
@string(KDD2022 = "Proceedings of the 28th ACM SIGKDD International Conference on Knowledge Discovery and Data Mining")
@string(KDD2021 = "Proceedings of the 27th ACM SIGKDD International Conference on Knowledge Discovery and Data Mining")
@string(KDD2019 = "Proceedings of the 25th ACM SIGKDD International Conference on Knowledge Discovery and Data Mining")
@string(KDD2017 = "Proceedings of the 23rd ACM SIGKDD International Conference on Knowledge Discovery and Data Mining")
@string(KDD2013 = "Proceedings of the 19th ACM SIGKDD International Conference on Knowledge Discovery and Data Mining")
@string(CIKM2021 = "Proceedings of the 30th ACM International Conference on Information and Knowledge Management")
@string(CIKM2020 = "Proceedings of the 29th ACM International Conference on Information and Knowledge Management")
@string(CIKM2013 = "Proceedings of the 22nd ACM International Conference on Information and Knowledge Management")
@string(WSDM2015tutorial = "Proceedings of the 8th ACM International Conference on Web Search and Data Mining: Tutorial")
@string(SIGIR2018 = "Proceedings of the 41st International ACM SIGIR Conference on Research and Development in Information Retrieval")
@string(EC2008 = "Proceedings of the 9th ACM Conference on Electronic Commerce")
@string(ICML2019 = "Proceedings of the 36th International Conference on Machine Learning")
@string(NeurIPS2019 = "Advances in Neural Information Processing Systems 32")
@string(NIPS2022 = "Advances in Neural Information Processing Systems 35")
@string(NIPS2020 = "Advances in Neural Information Processing Systems 33")
@string(NIPS2017 = "Advances in Neural Information Processing Systems 30")
@string(NIPS2014 = "Advances in Neural Information Processing Systems 27")
@string(NIPS2007 = "Advances in Neural Information Processing Systems 20")
@string(WWW2021 = "Proceedings of The Web Conference 2021")
@string(WWW2020 = "Proceedings of The Web Conference 2020")
@string(WWW2019 = "Proceedings of The Web Conference 2019")
@string(CVPR2017 = "Proceedings of the 2017 IEEE Conference on Computer Vision and Pattern Recognition")
@string(CVPR2015 = "Proceedings of the 2015 IEEE Conference on Computer Vision and Pattern Recognition")
@string{ICASSP2019 = "Proceedings of the 2019 IEEE International Conference on Acoustics, Speech and Signal Processing"}
@string(ICEC2010 = "Proceedings of the 12th International Conference on Electronic Commerce")
@string(DEDM2013 = "Proceedings of the 1st International Conference on Digital Enterprise Design and Management")
@string(WACV2021 = "Proceedings of the 2021 IEEE Winter Conference on Applications of Computer Vision")
@string(NLP2022 = "NLP 2022")
@string(NLP2021 = "NLP 2021")
@string(NLP2019 = "NLP 2019")
@string(JSAI2021 = "JSAI 2021")
@string(JSAI2020 = "JSAI 2020")
@string(JSAI2019 = "JSAI 2019")
@string(LREC2008 = "Proceedings of the Sixth International Conference on Language Resources and Evaluation")
@string(LREC2010 = "Proceedings of the Seventh International Conference on Language Resources and Evaluation")
@string(LREC2018 = "Proceedings of the Eleventh International Conference on Language Resources and Evaluation")

@inproceedings{Fujita2010-xm,
title     = "Automatic generation of listing ads by reusing promotional texts",
booktitle = ICEC2010,
author    = "Fujita, Atsushi and Ikushima, Katsuhiro and Sato, Satoshi and
               Kamite, Ryo and Ishiyama, Ko and Tamachi, Osamu",
year      =  2010,
pages = {179--188},
url = {https://doi.org/10.1145/2389376.2389401},
doi = {10.1145/2389376.2389401},
}

@inproceedings{Bartz2008-ke,
title     = "Natural language generation for sponsored-search advertisements",
booktitle = EC2008,
author    = "Bartz, Kevin and Barr, Cory and Aijaz, Adil",
year      =  2008,
pages = {1--9},
url = {https://doi.org/10.1145/1386790.1386792},
doi = {10.1145/1386790.1386792},
}

@inproceedings{Hughes2019-sh,
author = {Hughes, J. Weston and Chang, Keng-hao and Zhang, Ruofei},
title = {Generating Better Search Engine Text Advertisements with Deep Reinforcement Learning},
year = {2019},
booktitle = KDD2019,
pages = {2269--2277},
url = {https://doi.org/10.1145/3292500.3330754},
doi = {10.1145/3292500.3330754},
}

@inproceedings{Wang2021-uq,
title      = "Reinforcing Pretrained Models for Generating Attractive Text Advertisements",
booktitle  = KDD2021,
author     = "Wang, Xiting and Gu, Xinwei and Cao, Jie and Zhao, Zihua and
                Yan, Yulan and Middha, Bhuvan and Xie, Xing",
year       =  2021,
pages = {3697--3707},
url = {https://doi.org/10.1145/3447548.3467105},
}

@INPROCEEDINGS{Kamigaito2021-iy,
title     = "An Empirical Study of Generating Texts for Search Engine Advertising",
booktitle = NAACL2021industry,
author    = "Kamigaito, Hidetaka and Zhang, Peinan and Takamura, Hiroya and
               Okumura, Manabu",
year      =  2021,
pages = "255--262",
url = {https://aclanthology.org/2021.naacl-industry.32/},
}

@inproceedings{duan2021query-variant,
author = {Duan, Siyu and Li, Wei and Cai, Jing and He, Yancheng and Wu, Yunfang},
title = {Query-Variant Advertisement Text Generation with Association Knowledge},
booktitle = CIKM2021,
year = {2021},
pages = {412--421},
url = {https://doi.org/10.1145/3459637.3482290},
}

@inproceedings{mishra2021tsi,
author = {Mishra, Shaunak and Hu, Changwei and Verma, Manisha and Yen, Kevin and Hu, Yifan and Sviridenko, Maxim},
title = {{TSI}: An Ad Text Strength Indicator Using Text-to-{CTR} and Semantic-Ad-Similarity},
year = {2021},
booktitle = CIKM2021,
pages = {4036--4045},
url = {https://doi.org/10.1145/3459637.3481957},
}

@inproceedings{mishra2020refinement,
author = {Mishra, Shaunak and Verma, Manisha and Zhou, Yichao and Thadani, Kapil and Wang, Wei},
title = {Learning to Create Better Ads: Generation and Ranking Approaches for Ad Creative Refinement},
year = {2020},
booktitle = CIKM2020,
pages = {2653--2660},
url = {https://doi.org/10.1145/3340531.3412720},
}

@inproceedings{youngmann2020,
author = {Youngmann, Brit and Yom-Tov, Elad and Gilad-Bachrach, Ran and Karmon, Danny},
title = {The Automated Copywriter: Algorithmic Rephrasing of Health-Related Advertisements to Improve Their Performance},
year = {2020},
booktitle = WWW2020,
pages = {1366--1377},
url = {https://doi.org/10.1145/3366423.3380211},
doi = {10.1145/3366423.3380211},
}

@inproceedings{thomaidou2013,
author = {Thomaidou, Stamatina and Lourentzou, Ismini and Katsivelis-Perakis, Panagiotis and Vazirgiannis, Michalis},
title = {Automated Snippet Generation for Online Advertising},
year = {2013},
booktitle = CIKM2013,
pages = {1841--1844},
url = {https://doi.org/10.1145/2505515.2507876},
doi = {10.1145/2505515.2507876},
}

@article{shuai2020prediction,
author = {Shuai, Jiamei and Charles, Denis and Zarar, Shuayb},
title = {Prediction and Exploration Models for Responsive Search Ads},
year = {2020},
journal = {Microsoft Journal of Applied Research},
volume = {13},
number = {1},
url = {https://www.microsoft.com/en-us/research/publication/prediction-and-exploration-models-for-responsive-search-ads/},
}

@inproceedings{thomaidou2013grammads,
author="Thomaidou, Stamatina
and Leymonis, Konstantinos
and Vazirgiannis, Michalis",
editor="Benghozi, Pierre-Jean
and Krob, Daniel
and Rowe, Frantz",
title="{GrammAds}: Keyword and Ad Creative Generator for Online Advertising Campaigns",
booktitle = DEDM2013,
year="2013",
pages="33--44",
url={https://doi.org/10.1007/978-3-642-37317-6_4},
doi={10.1007/978-3-642-37317-6_4},
}

@article{alnajjar_toivonen_2021, 
author={Alnajjar, Khalid and Toivonen, Hannu}, 
title={Computational generation of slogans}, 
year={2021}, 
journal={Natural Language Engineering}, 
volume={27}, 
number={5}, 
pages={575--607},
url = {https://doi.org/10.1017/S1351324920000236},
doi={10.1017/S1351324920000236},
}

@inproceedings{kanungo-etal-2021-ad,
title = "Ad Headline Generation using Self-Critical Masked Language Model",
author = "Kanungo, Yashal Shakti  and
      Negi, Sumit  and
      Rajan, Aruna",
booktitle = NAACL2021industry,
year = "2021",
pages = "263--271",
url = {https://aclanthology.org/2021.naacl-industry.33/},
}

@inproceedings{zhang2021chase,
author = {Zhang, Chao and Zhou, Jingbo and Zang, Xiaoling and Xu, Qing and Yin, Liang and He, Xiang and Liu, Lin and Xiong, Haoyi and Dou, Dejing},
title = {{CHASE}: Commonsense-Enriched Advertising on Search Engine with Explicit Knowledge},
year = {2021},
booktitle = CIKM2021,
pages = {4352--4361},
url = {https://doi.org/10.1145/3459637.3481902},
}

@online{dentsu2020survey,
  author = {{CARTA COMMUNICATIONS, Inc.} and {D2C Inc.} and {Dentsu Inc.} and {Dentsu Digital Inc.}},
  title = {2020年 日本の広告費 インターネット広告媒体費 詳細分析},
  year = {2021},
  howpublished = {\url{https://www.dentsu.co.jp/news/release/2021/0310-010348.html}},
}

@online{google-stats,
  author = {{Google, Inc.}},
  title = {Google Zeitgest 2012},
  year = {2012},
  howpublished = {\url{https://archive.google.com/zeitgeist/2012/#the-world}},
}

@inproceedings{sawai2020,
  title={自動生成された広告文の人手評価における評価指標と支援ツールの提案},
  author={澤井 悠 and 張 培楠 and 吉本 暁文},
  booktitle=JSAI2020,
  year={2020},
  doi={10.11517/pjsai.JSAI2020.0_3Rin480}
}

@article{raffel2020t5,
author  = {Colin Raffel and Noam Shazeer and Adam Roberts and Katherine Lee and Sharan Narang and Michael Matena and Yanqi Zhou and Wei Li and Peter J. Liu},
title   = {Exploring the Limits of Transfer Learning with a Unified Text-to-Text Transformer},
journal = {Journal of Machine Learning Research},
year    = {2020},
volume  = {21},
number  = {140},
pages   = {1--67},
url     = {http://jmlr.org/papers/v21/20-074.html}
}

@article{dong2019unilm,
author = {Dong, Li and Yang, Nan and Wang, Wenhui and Wei, Furu and Liu, Xiaodong and Wang, Yu and Gao, Jianfeng and Zhou, Ming and Hon, Hsiao-Wuen},
title = {Unified Language Model Pre-training for Natural Language Understanding and Generation},
year = {2019},
journal = NeurIPS2019,
url = {https://proceedings.neurips.cc/paper/2019/hash/c20bb2d9a50d5ac1f713f8b34d9aac5a-Abstract.html},
}

@article{sutskever2014seq2seq,
author = {Sutskever, Ilya and Vinyals, Oriol and Le, Quoc V},
title = {Sequence to Sequence Learning with Neural Networks},
year = {2014},
journal = NIPS2014,
url = {https://papers.nips.cc/paper/2014/hash/a14ac55a4f27472c5d894ec1c3c743d2-Abstract.html},
}

@inproceedings{see-etal-2017-get,
title = "Get To The Point: Summarization with Pointer-Generator Networks",
author = "See, Abigail  and
      Liu, Peter J.  and
      Manning, Christopher D.",
booktitle = ACL2017,
year = "2017",
pages = "1073--1083",
url = "https://aclanthology.org/P17-1099",
}

@misc{radford2019language,
title={Language Models are Unsupervised Multitask Learners},
author={Radford, Alec and Wu, Jeff and Child, Rewon and Luan, David and Amodei, Dario and Sutskever, Ilya},
year={2019},
howpublished={OpenAI Blog},
url={https://openai.com/blog/better-language-models/},
}

@article{vaswani2017attention,
author = {Vaswani, Ashish and Shazeer, Noam and Parmar, Niki and Uszkoreit, Jakob and Jones, Llion and Gomez, Aidan N and Kaiser, {\L}ukasz and Polosukhin, Illia},
title = {Attention is All you Need},
year = {2017},
journal = NIPS2017,
url = {https://papers.nips.cc/paper/2017/hash/3f5ee243547dee91fbd053c1c4a845aa-Abstract.html},
}

@article{likert1932,
title={A Technique for the Measurement of Attitudes},
author={Likert, Rensis},
journal={Archives of Psychology},
year={1932},
volume={22},
number={140},
pages={5--55},
url={https://psycnet.apa.org/record/1933-01885-001},
}

@inproceedings{rennie2017scst,
author={Rennie, Steven J. and Marcheret, Etienne and Mroueh, Youssef and Ross, Jerret and Goel, Vaibhava},
booktitle=CVPR2017,
title={Self-Critical Sequence Training for Image Captioning}, 
year={2017},
pages="7008--7024",
url={https://openaccess.thecvf.com/content_cvpr_2017/html/Rennie_Self-Critical_Sequence_Training_CVPR_2017_paper.html},
}

@inproceedings{li-etal-2016-diversity,
title = "A Diversity-Promoting Objective Function for Neural Conversation Models",
author = "Li, Jiwei  and
      Galley, Michel  and
      Brockett, Chris  and
      Gao, Jianfeng  and
      Dolan, Bill",
year = "2016",
booktitle = NAACL2016,
url = "https://aclanthology.org/N16-1014",
pages = "110--119",
}

@inproceedings{10.1145/3209978.3210080,
author = {Zhu, Yaoming and Lu, Sidi and Zheng, Lei and Guo, Jiaxian and Zhang, Weinan and Wang, Jun and Yu, Yong},
title = {Texygen: A Benchmarking Platform for Text Generation Models},
year = {2018},
booktitle = SIGIR2018,
pages = {1097--1100},
url = {https://doi.org/10.1145/3209978.3210080},
doi = {10.1145/3209978.3210080},
}

@inproceedings{pmlr-v97-shen19c,
title = {Mixture Models for Diverse Machine Translation: Tricks of the Trade},
author = {Shen, Tianxiao and Ott, Myle and Auli, Michael and Ranzato, Marc'Aurelio},
year = {2019},
booktitle = ICML2019,
pages = {5719--5728},
url = {https://proceedings.mlr.press/v97/shen19c.html},
}

@inproceedings{papineni-etal-2002-bleu,
title = "{BLEU}: A Method for Automatic Evaluation of Machine Translation",
author = "Papineni, Kishore  and
      Roukos, Salim  and
      Ward, Todd  and
      Zhu, Wei-Jing",
booktitle = ACL2002,
year = "2002",
pages = "311--318",
url = "https://aclanthology.org/P02-1040",
}

@inproceedings{lin-2004-rouge,
title = "{ROUGE}: A Package for Automatic Evaluation of Summaries",
author = "Lin, Chin-Yew",
booktitle = "Proceedings of the {ACL} Workshop: Text Summarization Branches Out",
year = "2004",
pages = "74--81",
url = "https://aclanthology.org/W04-1013",
}

@inproceedings{banerjee-lavie-2005-meteor,
title = "{METEOR}: An Automatic Metric for {MT} Evaluation with Improved Correlation with Human Judgments",
author = "Banerjee, Satanjeev  and
      Lavie, Alon",
booktitle = "Proceedings of the {ACL} Workshop on Intrinsic and Extrinsic Evaluation Measures for Machine Translation and/or Summarization",
year = "2005",
pages = "65--72",
url = "https://aclanthology.org/W05-0909",
}

@inproceedings{Vedantam_2015_CVPR,
author = {Vedantam, Ramakrishna and Lawrence Zitnick, C. and Parikh, Devi},
title = {{CIDEr}: Consensus-Based Image Description Evaluation},
booktitle = CVPR2015,
year = {2015},
pages = "4566--4575",
url = "https://openaccess.thecvf.com/content_cvpr_2015/html/Vedantam_CIDEr_Consensus-Based_Image_2015_CVPR_paper.html",
}

@inproceedings{devlin-etal-2019-bert,
title = "{BERT}: Pre-training of Deep Bidirectional Transformers for Language Understanding",
author = "Devlin, Jacob  and
      Chang, Ming-Wei  and
      Lee, Kenton  and
      Toutanova, Kristina",
booktitle = NAACL2019,
year = "2019",
pages = "4171--4186",
url = "https://aclanthology.org/N19-1423",
}

@inproceedings{howcroft-etal-2020-twenty,
title = "Twenty Years of Confusion in Human Evaluation: {NLG} Needs Evaluation Sheets and Standardised Definitions",
author = "Howcroft, David M.  and
      Belz, Anya  and
      Clinciu, Miruna-Adriana  and
      Gkatzia, Dimitra  and
      Hasan, Sadid A.  and
      Mahamood, Saad  and
      Mille, Simon  and
      van Miltenburg, Emiel  and
      Santhanam, Sashank  and
      Rieser, Verena",
booktitle = INLG2020,
year = "2020",
pages = "169--182",
url = "https://aclanthology.org/2020.inlg-1.23/",
}

@article{herbrich2007trueskill,
author = {Herbrich, Ralf and Minka, Tom and Graepel, Thore},
title = {TrueSkill\textsuperscript{\texttrademark}: A {Bayesian} Skill Rating System},
year = {2007},
journal = NIPS2007,
url = "https://papers.nips.cc/paper/2006/hash/f44ee263952e65b3610b8ba51229d1f9-Abstract.html",
}

@inproceedings{fukuda2019vae,
  title={キーワード条件つき変分Autoencoderによる広告文生成},
  author={福田 宏幸},
  booktitle=JSAI2019,
  year={2019},
  doi={10.11517/pjsai.JSAI2019.0_2L4J903}
}

@inproceedings{wakimoto2020,
  title={インターネット広告におけるキーワードに基づく広告文の自動生成},
  author={脇本 宏平 and 川本 峻頌 and 張 培楠},
  booktitle=JSAI2020,
  year={2020},
  doi={10.11517/pjsai.JSAI2020.0_4Rin170}
}

@inproceedings{kuroki2021bert2bert,
  title={キーワードを考慮したBERT2BERTによる広告文生成},
  author={黒木 開 and 川上 孝介 and 岩井 大志 and 石塚 湖太 and 中田 和秀},
  booktitle=JSAI2021,
  year={2021},
  doi={10.11517/pjsai.JSAI2021.0_2D3OS7a02}
}

@inproceedings{osone2021gpt2,
  title={GPT-2の転移学習によるキーワードを考慮した広告文生成},
  author={大曽根 宏幸 and 張 培楠},
  booktitle=JSAI2021,
  year={2021},
  doi={10.11517/pjsai.JSAI2021.0_2D4OS7b03}
}

@inproceedings{kawamoto2020posvae,
  title={スタイル制御を考慮した多様な広告文生成},
  author={川本 峻頌 and 張 培楠},
  booktitle=NLP2019,
  year={2019},
}

@inproceedings{ishizuka2021bert2bert,
  title={Generating Search Text Ads from Keywords and Landing Pages via BERT2BERT},
  author={Kota Ishizuka and Kai Kurogi and Kosuke Kawakami and Daishi Iwai and Kazuhide Nakata},
  booktitle=JSAI2021,
  year={2021},
  doi={10.11517/pjsai.JSAI2021.0_2N3IS2b05}
}

@inproceedings{song2019mass,
author = {Song, Kaitao and Tan, Xu and Qin, Tao and Lu, Jianfeng and Liu, Tie-Yan},
booktitle = ICML2019,
title = {{MASS}: Masked Sequence to Sequence Pre-training for Language Generation},
year = 2019,
pages = {5926--5936},
url = {https://proceedings.mlr.press/v97/song19d.html},
}

@article{rothe-etal-2020-leveraging,
title = "Leveraging Pre-trained Checkpoints for Sequence Generation Tasks",
author = "Rothe, Sascha  and
      Narayan, Shashi  and
      Severyn, Aliaksei",
year = "2020",
journal = "Transactions of the Association for Computational Linguistics",
volume = "8",
pages = "264--280",
url = "https://aclanthology.org/2020.tacl-1.18",
}

@inproceedings{murakami2022lp2text,
  title={LP-to-Text: マルチモーダル広告文生成},
  author={村上 聡一朗 and 星野 翔 and 張 培楠 and 上垣外 英剛 and 高村 大也 and 奥村学},
  booktitle=NLP2022,
  year={2022},
}

@article{gatt2018survey,
author = {Gatt, Albert and Krahmer, Emiel},
title = {Survey of the State of the Art in Natural Language Generation: Core Tasks, Applications and Evaluation},
year = {2018},
journal = {Journal of Artificial Intelligence Research},
volume = {61},
number = {1},
pages = {65--170},
url = {https://doi.org/10.1613/jair.5477},
}

@inproceedings{wang-etal-2020-towards,
title = "Towards Faithful Neural Table-to-Text Generation with Content-Matching Constraints",
author = "Wang, Zhenyi  and
      Wang, Xiaoyang  and
      An, Bang  and
      Yu, Dong  and
      Chen, Changyou",
booktitle = ACL2020,
year = "2020",
pages = "1072--1086",
url = "https://aclanthology.org/2020.acl-main.101",    
}

@inproceedings{nobori2021,
  title={企業情報を考慮したキャッチコピーの自動生成},
  author={昇 夏海 and 平岡 達也 and 丹羽 彩奈 and 西口 佳佑 and 岡崎 直観},
  booktitle=NLP2021,
  year={2021},
}

@article{jin2022slogan, 
author={Jin, Yiping and Bhatia, Akshay and Wanvarie, Dittaya and Le, Phu T. V.}, 
title={Towards improving coherence and diversity of slogan generation}, 
year={2022}, 
journal={Natural Language Engineering}, 
url={https://doi.org/10.1017/S1351324921000474},
doi={10.1017/S1351324921000474}, 
note = {Preprint},
}
%pages={1--33}

@inproceedings{wei2022creater,
author = {Wei, Penghui and Yang, Xuanhua and Liu, Shaoguo and Wang, Liang and Zheng, Bo},
title = {{CREATER}: {CTR}-driven Advertising Text Generation with Controlled Pre-Training and Contrastive Fine-Tuning},
booktitle = NAACL2022industry,
year = {2022},
pages = "9--17",
url = {https://aclanthology.org/2022.naacl-industry.2/},
}

@inproceedings{wang2019quality,
author = {Wang, Yongzhen and Huang, Heng and Yan, Yuliang and Liu, Xiaozhong},
title = {Quality-Sensitive Training! {S}ocial Advertisement Generation by Leveraging User Click Behavior},
year = {2019},
booktitle = WWW2019,
pages = {2045--2055},
url = {https://doi.org/10.1145/3308558.3313536},
doi = {10.1145/3308558.3313536},
}

@inproceedings{misawa2020distinctive,
title = "Distinctive Slogan Generation with Reconstruction",
author = "Misawa, Shotaro  and
      Miura, Yasuhide  and
      Taniguchi, Tomoki  and
      Ohkuma, Tomoko",
booktitle = "Proceedings of Workshop on Natural Language Processing in E-Commerce",
year = "2020",
pages = "87--97",
url = "https://aclanthology.org/2020.ecomnlp-1.9",
}

@inproceedings{luong-etal-2015-addressing,
title = "Addressing the Rare Word Problem in Neural Machine Translation",
author = "Luong, Thang  and
      Sutskever, Ilya  and
      Le, Quoc  and
      Vinyals, Oriol  and
      Zaremba, Wojciech",
booktitle = ACL2015,
year = "2015",
pages = "11--19",
url = "https://aclanthology.org/P15-1002",
doi = "10.3115/v1/P15-1002",
}

@misc{gehrmann-etal-2022-repairing,
author = {Gehrmann, Sebastian and Clark, Elizabeth and Sellam, Thibault},
title = {Repairing the Cracked Foundation: A Survey of Obstacles in Evaluation Practices for Generated Text},  
year = {2022},
doi = {10.48550/ARXIV.2202.06935},
url = {https://arxiv.org/abs/2202.06935},
howpublished = {Preprint, arXiv:2202.06935},
}

@inproceedings{wang2015tutorial,
author = {Wang, Jun and Yuan, Shuai},
title = {Real-Time Bidding: A New Frontier of Computational Advertising Research},
year = {2015},
booktitle = WSDM2015tutorial,
pages = {415--416},
url = {https://doi.org/10.1145/2684822.2697041},
doi = {10.1145/2684822.2697041},
}

@article{jelinek1977perplexity,
author = {Jelinek,F.  and Mercer,R. L.  and Bahl,L. R.  and Baker,J. K. },
title = {Perplexity--a measure of the difficulty of speech recognition tasks},
year = {1977},
journal = {Journal of the Acoustical Society of America},
volume = {62},
pages = {S63},
doi = {10.1121/1.2016299},
url = {https://doi.org/10.1121/1.2016299},
}

@article{brown-etal-1992-estimate,
title = "An Estimate of an Upper Bound for the Entropy of {E}nglish",
author = "Brown, Peter F.  and
      Della Pietra, Stephen A.  and
      Della Pietra, Vincent J.  and
      Lai, Jennifer C.  and
      Mercer, Robert L.",
year = "1992",
journal = "Computational Linguistics",
volume = "18",
number = "1",
pages = "31--40",
url = "https://aclanthology.org/J92-1002",
}

@inproceedings{cao-etal-2022-hallucinated,
title = "Hallucinated but Factual! Inspecting the Factuality of Hallucinations in Abstractive Summarization",
author = "Cao, Meng  and
      Dong, Yue  and
      Cheung, Jackie",
year = "2022",
booktitle = ACL2022,
pages = "3340--3354",
url = "https://aclanthology.org/2022.acl-long.236",
doi = "10.18653/v1/2022.acl-long.236",
}

@inproceedings{shao2021vae,
author = {Shao, Huajie and Wang, Jun and Lin, Haohong and Zhang, Xuezhou and Zhang, Aston and Ji, Heng and Abdelzaher, Tarek},
title = {Controllable and Diverse Text Generation in E-Commerce},
booktitle = WWW2021,
year = {2021},
pages = {2392--2401},
url = {https://doi.org/10.1145/3442381.3449838},
doi = {10.1145/3442381.3449838},
}

@inproceedings{zhang2019vae,  
author={Zhang, Yuchi and Wang, Yongliang and Zhang, Liping and Zhang, Zhiqiang and Gai, Kun},  
title={Improve Diverse Text Generation by Self Labeling Conditional Variational Auto Encoder},
booktitle=ICASSP2019,
year={2019},
pages={2767--2771},
url = {https://doi.org/10.1109/ICASSP.2019.8683090},
doi={10.1109/ICASSP.2019.8683090}
}

@inproceedings{lewis-etal-2020-bart,
author = "Lewis, Mike  and
      Liu, Yinhan  and
      Goyal, Naman  and
      Ghazvininejad, Marjan  and
      Mohamed, Abdelrahman  and
      Levy, Omer  and
      Stoyanov, Veselin  and
      Zettlemoyer, Luke",
title = "{BART}: Denoising Sequence-to-Sequence Pre-training for Natural Language Generation, Translation, and Comprehension",
booktitle = ACL2020,
year = "2020",
pages = "7871--7880",
url = "https://aclanthology.org/2020.acl-main.703",
doi = "10.18653/v1/2020.acl-main.703",
}

@misc{mary-internet-2018,
author={Meeker, Mary and Wu, Liang},
title={{Internet Trends Report} 2018},
howpublished={Kleiner Perkins},
year={2018},
url={https://www.kleinerperkins.com/perspectives/internet-trends-report-2018/},
}

@misc{statista2022,
title={Search Advertising - Worldwide},
author={Statista},
year={2022},
howpublished={Statista Market Forecast},
url={https://www.statista.com/outlook/dmo/digital-advertising/search-advertising/worldwide},
}

@article{card2000did,
author = {David Card and Alan B. Krueger},
title = {Minimum Wages and Employment: A Case Study of the Fast-Food Industry in New Jersey and Pennsylvania},
year = {1994},
journal = {The American Economic Review},
volume = {84},
number = {4},
pages = {772--793},
url = {http://www.jstor.org/stable/2118030},
}

@inproceedings{abrams2007fatigue,
author = "Abrams, Zo{\"e} and Vee, Erik",
title = "Personalized Ad Delivery When Ads Fatigue: An Approximation Algorithm",
year = "2007",
booktitle = "Proceedings of Workshop on Internet and Network Economics",
pages = "535--540",
url = {https://doi.org/10.1007/978-3-540-77105-0_57},
doi = {10.1007/978-3-540-77105-0_57},
}

@inproceedings{zhao-etal-2022-self,
author = "Zhao, Xue  and
      Liu, Dayiheng  and
      Ding, Junwei  and
      Yao, Liang  and
      Yan, Mahone  and
      Wang, Huibo  and
      Yao, Wenqing",
title = "Self-supervised Product Title Rewrite for Product Listing Ads",
year = "2022",
booktitle = NAACL2022industry,
pages = "79--85",
url = "https://aclanthology.org/2022.naacl-industry.10",
}

@inproceedings{li-etal-2022-culg,
author = "Li, Haonan  and
  Huang, Yameng  and
  Gong, Yeyun  and
  Jiao, Jian  and
  Zhang, Ruofei  and
  Baldwin, Timothy  and
  Duan, Nan",
title = "{CULG}: Commercial Universal Language Generation",
year = "2022",
booktitle = NAACL2022industry,
pages = "112--120",
url = "https://aclanthology.org/2022.naacl-industry.14",
}

@inproceedings{kanungo2022cobart,
author = {Kanungo, Yashal Shakti and Das, Gyanendra and A, Pooja and Negi, Sumit},
title = {{COBART}: Controlled, Optimized, Bidirectional and Auto-Regressive Transformer for Ad Headline Generation},
year = {2022},
url = {https://doi.org/10.1145/3534678.3539069},
doi = {10.1145/3534678.3539069},
booktitle = KDD2022,
pages = {3127–3136},
}

@misc{chai2022fast,
author = {Chai, Junyi and Pryzant, Reid and Dong, Victor Ye and Golobokov, Konstantin and Zhu, Chenguang and Liu, Yi},
title = {{FAST}: Improving Controllability for Text Generation with Feedback Aware Self-Training},
year = {2022},
doi = {10.48550/ARXIV.2210.03167},
url = {https://arxiv.org/abs/2210.03167},
howpublished = {Preprint, arXiv:2210.03167},
}

@article{philippe2022summac,
author = {Laban, Philippe and Schnabel, Tobias and Bennett, Paul N. and Hearst, Marti A.},
title = "{{SummaC}: Re-Visiting {NLI}-based Models for Inconsistency Detection in Summarization}",
year = {2022},
journal = {Transactions of the Association for Computational Linguistics},
volume = {10},
pages = {163--177},
doi = {10.1162/tacl_a_00453},
url = {https://aclanthology.org/2022.tacl-1.10/},
}

@inproceedings{tevet-berant-2021-evaluating,
title = "Evaluating the Evaluation of Diversity in Natural Language Generation",
author = "Tevet, Guy  and
  Berant, Jonathan",
year = "2021",
booktitle = EACL2021,
pages = "326--346",
url = "https://aclanthology.org/2021.eacl-main.25",
doi = "10.18653/v1/2021.eacl-main.25",
}

@inproceedings{murakami-etal-2022-aspect,
title = "Aspect-based Analysis of Advertising Appeals for Search Engine Advertising",
author = "Murakami, Soichiro  and
  Zhang, Peinan  and
  Hoshino, Sho  and
  Kamigaito, Hidetaka  and
  Takamura, Hiroya  and
  Okumura, Manabu",
year = "2022",
booktitle = NAACL2022industry,
pages = "69--78",
url = "https://aclanthology.org/2022.naacl-industry.9",
doi = "10.18653/v1/2022.naacl-industry.9",
}

@inproceedings{zhu-etal-2018-msmo,
title = "{MSMO}: Multimodal Summarization with Multimodal Output",
author = "Zhu, Junnan  and
  Li, Haoran  and
  Liu, Tianshang  and
  Zhou, Yu  and
  Zhang, Jiajun  and
  Zong, Chengqing",
year = "2018",
booktitle = EMNLP2018,
pages = "4154--4164",
url = "https://aclanthology.org/D18-1448",
doi = "10.18653/v1/D18-1448",
}

@inproceedings{Mathew_2021_WACV,
author = {Mathew, Minesh and Karatzas, Dimosthenis and Jawahar, C.V.},
title={{DocVQA}: A Dataset for {VQA} on Document Images}, 
year={2021},
booktitle=WACV2021, 
pages= "2199--2208",
url = {https://doi.org/10.1109/WACV48630.2021.00225},
doi={10.1109/WACV48630.2021.00225}
}

@inproceedings{wang2013psychological,
author = {Wang, Taifeng and Bian, Jiang and Liu, Shusen and Zhang, Yuyu and Liu, Tie-Yan},
title = {Psychological Advertising: Exploring User Psychology for Click Prediction in Sponsored Search},
year = {2013},
booktitle = KDD2013,
pages = "563--571",
url = {https://doi.org/10.1145/2487575.2487699},
doi = {10.1145/2487575.2487699},
}mar

@inproceedings{valizadeh-parde-2022-ai,
title = "The {AI} Doctor Is In: A Survey of Task-Oriented Dialogue Systems for Healthcare Applications",
author = "Valizadeh, Mina  and
  Parde, Natalie",
year = "2022",
booktitle = ACL2022,
pages = "6638--6660",
url = "https://aclanthology.org/2022.acl-long.458",
doi = "10.18653/v1/2022.acl-long.458",
}

@inproceedings{zhu2017cpc,
author = {Zhu, Han and Jin, Junqi and Tan, Chang and Pan, Fei and Zeng, Yifan and Li, Han and Gai, Kun},
title = {Optimized Cost per Click in {Taobao} Display Advertising},
year = {2017},
booktitle = KDD2017,
pages = {2191--2200},
numpages = {10},
url = {https://doi.org/10.1145/3097983.3098134},
doi = {10.1145/3097983.3098134},
}

@inproceedings{cao2022hallucinated,
title = "Hallucinated but Factual! {I}nspecting the Factuality of Hallucinations in Abstractive Summarization",
author = "Cao, Meng  and
  Dong, Yue  and
  Cheung, Jackie",
year = "2022",
booktitle = ACL2022,
pages = "3340--3354",
url = "https://aclanthology.org/2022.acl-long.236",
doi = "10.18653/v1/2022.acl-long.236",
}

@article{10.1145/3571730,
author = {Ji, Ziwei and Lee, Nayeon and Frieske, Rita and Yu, Tiezheng and Su, Dan and Xu, Yan and Ishii, Etsuko and Bang, Yejin and Madotto, Andrea and Fung, Pascale},
title = {Survey of Hallucination in Natural Language Generation},
year = {2022},
journal = {ACM Computing Surveys},
url = {https://doi.org/10.1145/3571730},
doi = {10.1145/3571730},
note = {Preprint},
}

% 以下、EMNLP予稿集公開に合わせて要更新

@misc{golobokov2022deepgen,
author = {Golobokov, Konstantin and Chai, Junyi and Dong, Victor Ye and Gu, Mandy and Chi, Bingyu and Cao, Jie and Yan, Yulan and Liu, Yi},
title = {{DeepGen}: Diverse Search Ad Generation and Real-Time Customization},
year = {2022},
url = {https://arxiv.org/abs/2208.03438},
doi = {10.48550/ARXIV.2208.03438},
howpublished = {Preprint, arXiv:2208.03438},
}

@misc{yi2022effective,
author = {Yi, Jingwei and Wu, Fangzhao and Wu, Chuhan and Huang, Xiaolong and Jiao, Binxing and Sun, Guangzhong and Xie, Xing},
title = {Effective and Efficient Query-aware Snippet Extraction for Web Search},
year = {2022},
url = {https://arxiv.org/abs/2210.08809},
doi = {10.48550/ARXIV.2210.08809},
howpublished = {Preprint, arXiv:2210.08809},
}

@article{fleiss1971mns,
  added-at = {2009-03-31T11:05:45.000+0200},
  author = {Fleiss, J.L. and others},
  biburl = {https://www.bibsonomy.org/bibtex/2506a1115df044659165a488a75f9e449/folke},
  interhash = {797f4464a67b244f18c30349379d4a7a},
  intrahash = {506a1115df044659165a488a75f9e449},
  journal = {Psychological Bulletin},
  keywords = {inter-rater measure reliability},
  number = 5,
  pages = {378--382},
  timestamp = {2009-03-31T11:05:45.000+0200},
  title = {{Measuring nominal scale agreement among many raters}},
  volume = 76,
  year = 1971
}

@InProceedings{takaoka2018sudachi,
  author = {Kazuma Takaoka and Sorami Hisamoto and Noriko Kawahara and Miho Sakamoto and Yoshitaka Uchida and Yuji Matsumoto},
  title = {Sudachi: a Japanese Tokenizer for Business},
  booktitle = LREC2018,
  year = {2018},
  month = {may},
  date = {7-12},
  editor = {Nicoletta Calzolari (Conference chair) and Khalid Choukri and Christopher Cieri and Thierry Declerck and Sara Goggi and Koiti Hasida and Hitoshi Isahara and Bente Maegaard and Joseph Mariani and Hélène Mazo and Asuncion Moreno and Jan Odijk and Stelios Piperidis and Takenobu Tokunaga},
  isbn = {979-10-95546-00-9},
  language = {english}
  }

@misc{murakami2023atgsurvey,
      title={Natural Language Generation for Advertising: A Survey}, 
      author={Soichiro Murakami and Sho Hoshino and Peinan Zhang},
      year={2023},
      eprint={2306.12719},
      archivePrefix={arXiv},
      primaryClass={cs.CL},
      url={https://arxiv.org/abs/2306.12719}, 
}

% ACL2024版に差し替える
@misc{mita2024camera,
      title={Striking Gold in Advertising: Standardization and Exploration of Ad Text Generation}, 
      author={Masato Mita and Soichiro Murakami and Akihiko Kato and Peinan Zhang},
      year={2024},
      eprint={2309.12030},
      archivePrefix={arXiv},
      primaryClass={cs.CL},
      url={https://arxiv.org/abs/2309.12030}, 
}

% arxiv版に差し替える
@misc{peinan2024adtec,
      title={{A}d{TEC}: A Unified Benchmark for Evaluating Text Quality in Search Engine Advertising}, 
      author={Peinan Zhang and Yusuke Sakai and Masato Mita and Hiroki Ouchi and Taro Watanabe},
      year={2024},
      eprint={2408.05906},
      archivePrefix={arXiv},
      primaryClass={cs.CL},
      url={https://arxiv.org/abs/2408.05906}, 
}


@inproceedings{lan-etal-2017-continuously,
    title = "A Continuously Growing Dataset of Sentential Paraphrases",
    author = "Lan, Wuwei  and
      Qiu, Siyu  and
      He, Hua  and
      Xu, Wei",
    editor = "Palmer, Martha  and
      Hwa, Rebecca  and
      Riedel, Sebastian",
    booktitle = "Proceedings of the 2017 Conference on Empirical Methods in Natural Language Processing",
    month = sep,
    year = "2017",
    address = "Copenhagen, Denmark",
    publisher = "Association for Computational Linguistics",
    url = "https://aclanthology.org/D17-1126",
    doi = "10.18653/v1/D17-1126",
    pages = "1224--1234",
    abstract = "A major challenge in paraphrase research is the lack of parallel corpora. In this paper, we present a new method to collect large-scale sentential paraphrases from Twitter by linking tweets through shared URLs. The main advantage of our method is its simplicity, as it gets rid of the classifier or human in the loop needed to select data before annotation and subsequent application of paraphrase identification algorithms in the previous work. We present the largest human-labeled paraphrase corpus to date of 51,524 sentence pairs and the first cross-domain benchmarking for automatic paraphrase identification. In addition, we show that more than 30,000 new sentential paraphrases can be easily and continuously captured every month at {\textasciitilde}70{\%} precision, and demonstrate their utility for downstream NLP tasks through phrasal paraphrase extraction. We make our code and data freely available.",
}

@inproceedings{dong-etal-2021-parasci,
    title = "{P}ara{SCI}: A Large Scientific Paraphrase Dataset for Longer Paraphrase Generation",
    author = "Dong, Qingxiu  and
      Wan, Xiaojun  and
      Cao, Yue",
    editor = "Merlo, Paola  and
      Tiedemann, Jorg  and
      Tsarfaty, Reut",
    booktitle = "Proceedings of the 16th Conference of the European Chapter of the Association for Computational Linguistics: Main Volume",
    month = apr,
    year = "2021",
    address = "Online",
    publisher = "Association for Computational Linguistics",
    url = "https://aclanthology.org/2021.eacl-main.33",
    doi = "10.18653/v1/2021.eacl-main.33",
    pages = "424--434",
    abstract = "We propose ParaSCI, the first large-scale paraphrase dataset in the scientific field, including 33,981 paraphrase pairs from ACL (ParaSCI-ACL) and 316,063 pairs from arXiv (ParaSCI-arXiv). Digging into characteristics and common patterns of scientific papers, we construct this dataset though intra-paper and inter-paper methods, such as collecting citations to the same paper or aggregating definitions by scientific terms. To take advantage of sentences paraphrased partially, we put up PDBERT as a general paraphrase discovering method. The major advantages of paraphrases in ParaSCI lie in the prominent length and textual diversity, which is complementary to existing paraphrase datasets. ParaSCI obtains satisfactory results on human evaluation and downstream tasks, especially long paraphrase generation.",
}

@misc{touvron2023llama2openfoundation,
      title={Llama 2: Open Foundation and Fine-Tuned Chat Models}, 
      author={Hugo Touvron and Louis Martin and Kevin Stone and Peter Albert and Amjad Almahairi and Yasmine Babaei and Nikolay Bashlykov and Soumya Batra and Prajjwal Bhargava and Shruti Bhosale and Dan Bikel and Lukas Blecher and Cristian Canton Ferrer and Moya Chen and Guillem Cucurull and David Esiobu and Jude Fernandes and Jeremy Fu and Wenyin Fu and Brian Fuller and Cynthia Gao and Vedanuj Goswami and Naman Goyal and Anthony Hartshorn and Saghar Hosseini and Rui Hou and Hakan Inan and Marcin Kardas and Viktor Kerkez and Madian Khabsa and Isabel Kloumann and Artem Korenev and Punit Singh Koura and Marie-Anne Lachaux and Thibaut Lavril and Jenya Lee and Diana Liskovich and Yinghai Lu and Yuning Mao and Xavier Martinet and Todor Mihaylov and Pushkar Mishra and Igor Molybog and Yixin Nie and Andrew Poulton and Jeremy Reizenstein and Rashi Rungta and Kalyan Saladi and Alan Schelten and Ruan Silva and Eric Michael Smith and Ranjan Subramanian and Xiaoqing Ellen Tan and Binh Tang and Ross Taylor and Adina Williams and Jian Xiang Kuan and Puxin Xu and Zheng Yan and Iliyan Zarov and Yuchen Zhang and Angela Fan and Melanie Kambadur and Sharan Narang and Aurelien Rodriguez and Robert Stojnic and Sergey Edunov and Thomas Scialom},
      year={2023},
      eprint={2307.09288},
      archivePrefix={arXiv},
      primaryClass={cs.CL},
      url={https://arxiv.org/abs/2307.09288}, 
}

@misc{openai2024gpt4technicalreport,
      title={{GPT-4} Technical Report}, 
      author={OpenAI},
      year={2024},
      eprint={2303.08774},
      archivePrefix={arXiv},
      primaryClass={cs.CL},
      url={https://arxiv.org/abs/2303.08774}, 
}

% and Josh Achiam and Steven Adler and Sandhini Agarwal and Lama Ahmad and Ilge Akkaya and Florencia Leoni Aleman and Diogo Almeida and Janko Altenschmidt and Sam Altman and Shyamal Anadkat and Red Avila and Igor Babuschkin and Suchir Balaji and Valerie Balcom and Paul Baltescu and Haiming Bao and Mohammad Bavarian and Jeff Belgum and Irwan Bello and Jake Berdine and Gabriel Bernadett-Shapiro and Christopher Berner and Lenny Bogdonoff and Oleg Boiko and Madelaine Boyd and Anna-Luisa Brakman and Greg Brockman and Tim Brooks and Miles Brundage and Kevin Button and Trevor Cai and Rosie Campbell and Andrew Cann and Brittany Carey and Chelsea Carlson and Rory Carmichael and Brooke Chan and Che Chang and Fotis Chantzis and Derek Chen and Sully Chen and Ruby Chen and Jason Chen and Mark Chen and Ben Chess and Chester Cho and Casey Chu and Hyung Won Chung and Dave Cummings and Jeremiah Currier and Yunxing Dai and Cory Decareaux and Thomas Degry and Noah Deutsch and Damien Deville and Arka Dhar and David Dohan and Steve Dowling and Sheila Dunning and Adrien Ecoffet and Atty Eleti and Tyna Eloundou and David Farhi and Liam Fedus and Niko Felix and Simón Posada Fishman and Juston Forte and Isabella Fulford and Leo Gao and Elie Georges and Christian Gibson and Vik Goel and Tarun Gogineni and Gabriel Goh and Rapha Gontijo-Lopes and Jonathan Gordon and Morgan Grafstein and Scott Gray and Ryan Greene and Joshua Gross and Shixiang Shane Gu and Yufei Guo and Chris Hallacy and Jesse Han and Jeff Harris and Yuchen He and Mike Heaton and Johannes Heidecke and Chris Hesse and Alan Hickey and Wade Hickey and Peter Hoeschele and Brandon Houghton and Kenny Hsu and Shengli Hu and Xin Hu and Joost Huizinga and Shantanu Jain and Shawn Jain and Joanne Jang and Angela Jiang and Roger Jiang and Haozhun Jin and Denny Jin and Shino Jomoto and Billie Jonn and Heewoo Jun and Tomer Kaftan and Łukasz Kaiser and Ali Kamali and Ingmar Kanitscheider and Nitish Shirish Keskar and Tabarak Khan and Logan Kilpatrick and Jong Wook Kim and Christina Kim and Yongjik Kim and Jan Hendrik Kirchner and Jamie Kiros and Matt Knight and Daniel Kokotajlo and Łukasz Kondraciuk and Andrew Kondrich and Aris Konstantinidis and Kyle Kosic and Gretchen Krueger and Vishal Kuo and Michael Lampe and Ikai Lan and Teddy Lee and Jan Leike and Jade Leung and Daniel Levy and Chak Ming Li and Rachel Lim and Molly Lin and Stephanie Lin and Mateusz Litwin and Theresa Lopez and Ryan Lowe and Patricia Lue and Anna Makanju and Kim Malfacini and Sam Manning and Todor Markov and Yaniv Markovski and Bianca Martin and Katie Mayer and Andrew Mayne and Bob McGrew and Scott Mayer McKinney and Christine McLeavey and Paul McMillan and Jake McNeil and David Medina and Aalok Mehta and Jacob Menick and Luke Metz and Andrey Mishchenko and Pamela Mishkin and Vinnie Monaco and Evan Morikawa and Daniel Mossing and Tong Mu and Mira Murati and Oleg Murk and David Mély and Ashvin Nair and Reiichiro Nakano and Rajeev Nayak and Arvind Neelakantan and Richard Ngo and Hyeonwoo Noh and Long Ouyang and Cullen O'Keefe and Jakub Pachocki and Alex Paino and Joe Palermo and Ashley Pantuliano and Giambattista Parascandolo and Joel Parish and Emy Parparita and Alex Passos and Mikhail Pavlov and Andrew Peng and Adam Perelman and Filipe de Avila Belbute Peres and Michael Petrov and Henrique Ponde de Oliveira Pinto and Michael and Pokorny and Michelle Pokrass and Vitchyr H. Pong and Tolly Powell and Alethea Power and Boris Power and Elizabeth Proehl and Raul Puri and Alec Radford and Jack Rae and Aditya Ramesh and Cameron Raymond and Francis Real and Kendra Rimbach and Carl Ross and Bob Rotsted and Henri Roussez and Nick Ryder and Mario Saltarelli and Ted Sanders and Shibani Santurkar and Girish Sastry and Heather Schmidt and David Schnurr and John Schulman and Daniel Selsam and Kyla Sheppard and Toki Sherbakov and Jessica Shieh and Sarah Shoker and Pranav Shyam and Szymon Sidor and Eric Sigler and Maddie Simens and Jordan Sitkin and Katarina Slama and Ian Sohl and Benjamin Sokolowsky and Yang Song and Natalie Staudacher and Felipe Petroski Such and Natalie Summers and Ilya Sutskever and Jie Tang and Nikolas Tezak and Madeleine B. Thompson and Phil Tillet and Amin Tootoonchian and Elizabeth Tseng and Preston Tuggle and Nick Turley and Jerry Tworek and Juan Felipe Cerón Uribe and Andrea Vallone and Arun Vijayvergiya and Chelsea Voss and Carroll Wainwright and Justin Jay Wang and Alvin Wang and Ben Wang and Jonathan Ward and Jason Wei and CJ Weinmann and Akila Welihinda and Peter Welinder and Jiayi Weng and Lilian Weng and Matt Wiethoff and Dave Willner and Clemens Winter and Samuel Wolrich and Hannah Wong and Lauren Workman and Sherwin Wu and Jeff Wu and Michael Wu and Kai Xiao and Tao Xu and Sarah Yoo and Kevin Yu and Qiming Yuan and Wojciech Zaremba and Rowan Zellers and Chong Zhang and Marvin Zhang and Shengjia Zhao and Tianhao Zheng and Juntang Zhuang and William Zhuk and Barret Zoph},

@inproceedings{pryzant-etal-2018-interpretable,
    title = "Interpretable Neural Architectures for Attributing an Ad{'}s Performance to its Writing Style",
    author = "Pryzant, Reid  and
      Basu, Sugato  and
      Sone, Kazoo",
    editor = "Linzen, Tal  and
      Chrupa{\l}a, Grzegorz  and
      Alishahi, Afra",
    booktitle = "Proceedings of the 2018 {EMNLP} Workshop {B}lackbox{NLP}: Analyzing and Interpreting Neural Networks for {NLP}",
    month = nov,
    year = "2018",
    url = "https://aclanthology.org/W18-5415",
    doi = "10.18653/v1/W18-5415",
    pages = "125--135",
    abstract = "How much does {``}free shipping!{''} help an advertisement{'}s ability to persuade? This paper presents two methods for \textit{performance attribution}: finding the degree to which an outcome can be attributed to parts of a text while controlling for potential confounders. Both algorithms are based on interpreting the behaviors and parameters of trained neural networks. One method uses a CNN to encode the text, an adversarial objective function to control for confounders, and projects its weights onto its activations to interpret the importance of each phrase towards each output class. The other method leverages residualization to control for confounds and performs interpretation by aggregating over learned word vectors. We demonstrate these algorithms{'} efficacy on 118,000 internet search advertisements and outcomes, finding language indicative of high and low click through rate (CTR) regardless of who the ad is by or what it is for. Our results suggest the proposed algorithms are high performance and data efficient, able to glean actionable insights from fewer than 10,000 data points. We find that quick, easy, and authoritative language is associated with success, while lackluster embellishment is related to failure. These findings agree with the advertising industry{'}s emperical wisdom, automatically revealing insights which previously required manual A/B testing to discover.",
}

@inproceedings{sato-etal-2008-automatic,
    title = "Automatic Assessment of {J}apanese Text Readability Based on a Textbook Corpus",
    author = "Sato, Satoshi  and
      Matsuyoshi, Suguru  and
      Kondoh, Yohsuke",
    editor = "Calzolari, Nicoletta  and
      Choukri, Khalid  and
      Maegaard, Bente  and
      Mariani, Joseph  and
      Odijk, Jan  and
      Piperidis, Stelios  and
      Tapias, Daniel",
    booktitle = LREC2008,
    month = may,
    year = "2008",
    url = "http://www.lrec-conf.org/proceedings/lrec2008/pdf/165_paper.pdf",
    abstract = "This paper describes a method of readability measurement of Japanese texts based on a newly compiled textbook corpus. The textbook corpus consists of 1,478 sample passages extracted from 127 textbooks of elementary school, junior high school, high school, and university; it is divided into thirteen grade levels and the total size is about a million characters. For a given text passage, the readability measurement method determines the grade level to which the passage is the most similar by using character-unigram models, which are constructed from the textbook corpus. Because this method does not require sentence-boundary analysis and word-boundary analysis, it is applicable to texts that include incomplete sentences and non-regular text fragments. The performance of this method, which is measured by the correlation coefficient, is considerably high (R {\textgreater} 0.9); in case that the length of a text passage is limited in 25 characters, the correlation coefficient is still high (R = 0.83).",
}

@article{patrick_human_feedback_survey_tacl,
    author = {Fernandes, Patrick and Madaan, Aman and Liu, Emmy and Farinhas, António and Martins, Pedro Henrique and Bertsch, Amanda and de Souza, José G. C. and Zhou, Shuyan and Wu, Tongshuang and Neubig, Graham and Martins, André F. T.},
    title = "{Bridging the Gap: A Survey on Integrating (Human) Feedback for Natural Language Generation}",
    journal = {Transactions of the Association for Computational Linguistics},
    volume = {11},
    pages = {1643-1668},
    year = {2023},
    month = {12},
    abstract = "{Natural language generation has witnessed significant advancements due to the training of large language models on vast internet-scale datasets. Despite these advancements, there exists a critical challenge: These models can inadvertently generate content that is toxic, inaccurate, and unhelpful, and existing automatic evaluation metrics often fall short of identifying these shortcomings. As models become more capable, human feedback is an invaluable signal for evaluating and improving models. This survey aims to provide an overview of recent research that has leveraged human feedback to improve natural language generation. First, we introduce a taxonomy distilled from existing research to categorize and organize the varied forms of feedback. Next, we discuss how feedback can be described by its format and objective, and cover the two approaches proposed to use feedback (either for training or decoding): directly using feedback or training feedback models. We also discuss existing datasets for human-feedback data collection, and concerns surrounding feedback collection. Finally, we provide an overview of the nascent field of AI feedback, which uses large language models to make judgments based on a set of principles and minimize the need for human intervention. We also release a website of this survey at feedback-gap-survey.info.}",
    issn = {2307-387X},
    doi = {10.1162/tacl_a_00626},
    url = {https://doi.org/10.1162/tacl\_a\_00626},
    eprint = {https://direct.mit.edu/tacl/article-pdf/doi/10.1162/tacl\_a\_00626/2199585/tacl\_a\_00626.pdf},
}


@inproceedings{kirk-etal-2023-past,
    title = "The Past, Present and Better Future of Feedback Learning in Large Language Models for Subjective Human Preferences and Values",
    author = "Kirk, Hannah  and
      Bean, Andrew  and
      Vidgen, Bertie  and
      Rottger, Paul  and
      Hale, Scott",
    editor = "Bouamor, Houda  and
      Pino, Juan  and
      Bali, Kalika",
    booktitle = EMNLP2023,
    month = dec,
    year = "2023",
    url = "https://aclanthology.org/2023.emnlp-main.148",
    doi = "10.18653/v1/2023.emnlp-main.148",
    pages = "2409--2430",
    abstract = "Human feedback is increasingly used to steer the behaviours of Large Language Models (LLMs). However, it is unclear how to collect and incorporate feedback in a way that is efficient, effective and unbiased, especially for highly subjective human preferences and values. In this paper, we survey existing approaches for learning from human feedback, drawing on 95 papers primarily from the ACL and arXiv repositories. First, we summarise the past, pre-LLM trends for integrating human feedback into language models. Second, we give an overview of present techniques and practices, as well as the motivations for using feedback; conceptual frameworks for defining values and preferences; and how feedback is collected and from whom. Finally, we encourage a better future of feedback learning in LLMs by raising five unresolved conceptual and practical challenges.",
}

@inproceedings{ouyang_instructGPT_2022,
 author = {Ouyang, Long and Wu, Jeffrey and Jiang, Xu and Almeida, Diogo and Wainwright, Carroll and Mishkin, Pamela and Zhang, Chong and Agarwal, Sandhini and Slama, Katarina and Ray, Alex and Schulman, John and Hilton, Jacob and Kelton, Fraser and Miller, Luke and Simens, Maddie and Askell, Amanda and Welinder, Peter and Christiano, Paul F and Leike, Jan and Lowe, Ryan},
 booktitle = NIPS2022,
 editor = {S. Koyejo and S. Mohamed and A. Agarwal and D. Belgrave and K. Cho and A. Oh},
 pages = {27730--27744},
 title = {Training language models to follow instructions with human feedback},
 url = {https://proceedings.neurips.cc/paper_files/paper/2022/file/b1efde53be364a73914f58805a001731-Paper-Conference.pdf},
 volume = {35},
 year = {2022}
}


@inproceedings{brown_gpt3_2020,
 author = {Brown, Tom and Mann, Benjamin and Ryder, Nick and Subbiah, Melanie and Kaplan, Jared D and Dhariwal, Prafulla and Neelakantan, Arvind and Shyam, Pranav and Sastry, Girish and Askell, Amanda and Agarwal, Sandhini and Herbert-Voss, Ariel and Krueger, Gretchen and Henighan, Tom and Child, Rewon and Ramesh, Aditya and Ziegler, Daniel and Wu, Jeffrey and Winter, Clemens and Hesse, Chris and Chen, Mark and Sigler, Eric and Litwin, Mateusz and Gray, Scott and Chess, Benjamin and Clark, Jack and Berner, Christopher and McCandlish, Sam and Radford, Alec and Sutskever, Ilya and Amodei, Dario},
 booktitle = NIPS2020,
 editor = {H. Larochelle and M. Ranzato and R. Hadsell and M.F. Balcan and H. Lin},
 pages = {1877--1901},
 publisher = {Curran Associates, Inc.},
 title = {Language Models are Few-Shot Learners},
 url = {https://proceedings.neurips.cc/paper_files/paper/2020/file/1457c0d6bfcb4967418bfb8ac142f64a-Paper.pdf},
 volume = {33},
 year = {2020}
}

@inproceedings{hu-etal-2023-decipherpref,
    title = "{D}ecipher{P}ref: Analyzing Influential Factors in Human Preference Judgments via {GPT}-4",
    author = "Hu, Yebowen  and
      Song, Kaiqiang  and
      Cho, Sangwoo  and
      Wang, Xiaoyang  and
      Foroosh, Hassan  and
      Liu, Fei",
    editor = "Bouamor, Houda  and
      Pino, Juan  and
      Bali, Kalika",
    booktitle = EMNLP2023,
    month = dec,
    year = "2023",
    url = "https://aclanthology.org/2023.emnlp-main.519",
    doi = "10.18653/v1/2023.emnlp-main.519",
    pages = "8344--8357",
    abstract = "Human preference judgments are pivotal in guiding large language models (LLMs) to produce outputs that align with human values. Human evaluations are also used in summarization tasks to compare outputs from various systems, complementing existing automatic metrics. Despite their significance, however, there has been limited research probing these pairwise or $k$-wise comparisons. The collective impact and relative importance of factors such as output length, informativeness, fluency, and factual consistency are still not well understood. It is also unclear if there are other hidden factors influencing human judgments. In this paper, we conduct an in-depth examination of a collection of pairwise human judgments released by OpenAI. Utilizing the Bradley-Terry-Luce (BTL) model, we reveal the inherent preferences embedded in these human judgments. We find that the most favored factors vary across tasks and genres, whereas the least favored factors tend to be consistent, e.g., outputs are too brief, contain excessive off-focus content or hallucinated facts. Our findings have implications on the construction of balanced datasets in human preference evaluations, which is a crucial step in shaping the behaviors of future LLMs.",
}

@inproceedings{cegin-etal-2023-chatgpt,
    title = "{C}hat{GPT} to Replace Crowdsourcing of Paraphrases for Intent Classification: Higher Diversity and Comparable Model Robustness",
    author = "Cegin, Jan  and
      Simko, Jakub  and
      Brusilovsky, Peter",
    editor = "Bouamor, Houda  and
      Pino, Juan  and
      Bali, Kalika",
    booktitle = EMNLP2023,
    month = dec,
    year = "2023",
    url = "https://aclanthology.org/2023.emnlp-main.117",
    doi = "10.18653/v1/2023.emnlp-main.117",
    pages = "1889--1905",
    abstract = "The emergence of generative large language models (LLMs) raises the question: what will be its impact on crowdsourcing? Traditionally, crowdsourcing has been used for acquiring solutions to a wide variety of human-intelligence tasks, including ones involving text generation, modification or evaluation. For some of these tasks, models like ChatGPT can potentially substitute human workers. In this study, we investigate whether this is the case for the task of paraphrase generation for intent classification. We apply data collection methodology of an existing crowdsourcing study (similar scale, prompts and seed data) using ChatGPT and Falcon-40B. We show that ChatGPT-created paraphrases are more diverse and lead to at least as robust models.",
}

@inproceedings{lin-ma-2024-generating,
    title = "Generating Attractive and Authentic Copywriting from Customer Reviews",
    author = "Lin, Yu-Xiang  and
      Ma, Wei-Yun",
    editor = "Duh, Kevin  and
      Gomez, Helena  and
      Bethard, Steven",
    booktitle = NAACL2024,
    month = jun,
    year = "2024",
    url = "https://aclanthology.org/2024.naacl-long.259",
    doi = "10.18653/v1/2024.naacl-long.259",
    pages = "4629--4642",
    abstract = "The goal of product copywriting is to capture the interest of potential buyers by emphasizing the features of products through text descriptions. As e-commerce platforms offer a wide range of services, it{'}s becoming essential to dynamically adjust the styles of these auto-generated descriptions. Typical approaches to copywriting generation often rely solely on specified product attributes, which may result in dull and repetitive content. To tackle this issue, we propose to generate copywriting based on customer reviews, as they provide firsthand practical experiences with products, offering a richer source of information than just product attributes. We have developed a sequence-to-sequence framework, enhanced with reinforcement learning, to produce copywriting that is attractive, authentic, and rich in information. Our framework outperforms all existing baseline and zero-shot large language models, including LLaMA-2-chat-7B and GPT-3.5, in terms of both attractiveness and faithfulness. Furthermore, this work features the use of LLMs for aspect-based summaries collection and argument allure assessment. Experiments demonstrate the effectiveness of using LLMs for marketing domain corpus construction. The code and the dataset is publicly available at: \url{https://github.com/YuXiangLin1234/Copywriting-Generation}.",
}

@ARTICLE{yuan2023persuadetoclick,
  author={Yuan, Yuan and Xu, Fengli and Cao, Hancheng and Zhang, Guozhen and Hui, Pan and Li, Yong and Jin, Depeng},
  journal={IEEE Transactions on Knowledge and Data Engineering}, 
  title={Persuade to Click: Context-Aware Persuasion Model for Online Textual Advertisement}, 
  year={2023},
  volume={35},
  number={2},
  pages={1938-1951},
  keywords={Context modeling;Analytical models;Computational modeling;Advertising;Predictive models;Skin;Pricing;Persuasive tactics;disentangled representation learning;context-aware;causal analysis},
  doi={10.1109/TKDE.2021.3110724}}

@article{hsuehcheng_wang__2012,
    author = {Wang, Hsueh-Cheng and Pomplun, Marc},
    title = "{The attraction of visual attention to texts in real-world scenes}",
    journal = {Journal of Vision},
    volume = {12},
    number = {6},
    pages = {26-26},
    year = {2012},
    month = {06},
    abstract = "{  When we look at real-world scenes, attention seems disproportionately attracted by texts that are embedded in these scenes, for instance, on signs or billboards. The present study was aimed at verifying the existence of this bias and investigating its underlying factors. For this purpose, data from a previous experiment were reanalyzed and four new experiments measuring eye movements during the viewing of real-world scenes were conducted. By pairing text objects with matching control objects and regions, the following main results were obtained: (a) Greater fixation probability and shorter minimum fixation distance of texts confirmed the higher attractiveness of texts; (b) the locations where texts are typically placed contribute partially to this effect; (c) specific visual features of texts, rather than typically salient features (e.g., color, orientation, and contrast), are the main attractors of attention; (d) the meaningfulness of texts does not add to their attentional capture; and (e) the attraction of attention depends to some extent on the observer's familiarity with the writing system and language of a given text. }",
    issn = {1534-7362},
    doi = {10.1167/12.6.26},
    url = {https://doi.org/10.1167/12.6.26},
    eprint = {https://arvojournals.org/arvo/content\_public/journal/jov/933494/i1534-7362-12-6-26.pdf},
}

@inproceedings{maekawa-etal-2010-design,
    title = "Design, Compilation, and Preliminary Analyses of {B}alanced {C}orpus of {C}ontemporary {W}ritten {J}apanese",
    author = "Maekawa, Kikuo  and
      Yamazaki, Makoto  and
      Maruyama, Takehiko  and
      Yamaguchi, Masaya  and
      Ogura, Hideki  and
      Kashino, Wakako  and
      Ogiso, Toshinobu  and
      Koiso, Hanae  and
      Den, Yasuharu",
    editor = "Calzolari, Nicoletta  and
      Choukri, Khalid  and
      Maegaard, Bente  and
      Mariani, Joseph  and
      Odijk, Jan  and
      Piperidis, Stelios  and
      Rosner, Mike  and
      Tapias, Daniel",
    booktitle = LREC2010,
    month = may,
    year = "2010",
    pages="1483--1486",
    url = "http://www.lrec-conf.org/proceedings/lrec2010/pdf/99_Paper.pdf",
    abstract = "Compilation of a 100 million words balanced corpus called the Balanced Corpus of Contemporary Written Japanese (or BCCWJ) is underway at the National Institute for Japanese Language and Linguistics. The corpus covers a wide range of text genres including books, magazines, newspapers, governmental white papers, textbooks, minutes of the National Diet, internet text (bulletin board and blogs) and so forth, and when possible, samples are drawn from the rigidly defined statistical populations by means of random sampling. All texts are dually POS-analyzed based upon two different, but mutually related, definitions of word. Currently, more than 90 million words have been sampled and XML annotated with respect to text-structure and lexical and character information. A preliminary linear discriminant analysis of text genres using the data of POS frequencies and sentence length revealed it was possible to classify the text genres with a correct identification rate of 88{\%} as far as the samples of books, newspapers, whitepapers, and internet bulletin boards are concerned. When the samples of blogs were included in this data set, however, the identification rate went down to 68{\%}, suggesting the considerable variance of the blog texts in terms of the textual register and style.",
}
    % publisher = "European Language Resources Association (ELRA)",

@article{richard1977iaa,
 ISSN = {0006341X, 15410420},
 URL = {http://www.jstor.org/stable/2529310},
 abstract = {This paper presents a general statistical methodology for the analysis of multivariate categorical data arising from observer reliability studies. The procedure essentially involves the construction of functions of the observed proportions which are directed at the extent to which the observers agree among themselves and the construction of test statistics for hypotheses involving these functions. Tests for interobserver bias are presented in terms of first-order marginal homogeneity and measures of interobserver agreement are developed as generalized kappa-type statistics. These procedures are illustrated with a clinical diagnosis example from the epidemiological literature.},
 author = {J. Richard Landis and Gary G. Koch},
 journal = {Biometrics},
 number = {1},
 pages = {159--174},
 publisher = {International Biometric Society},
 title = {The Measurement of Observer Agreement for Categorical Data},
 urldate = {2024-10-07},
 volume = {33},
 year = {1977}
}


@inproceedings{shen-etal-2022-evaluation,
    title = "On the Evaluation Metrics for Paraphrase Generation",
    author = "Shen, Lingfeng  and
      Liu, Lemao  and
      Jiang, Haiyun  and
      Shi, Shuming",
    editor = "Goldberg, Yoav  and
      Kozareva, Zornitsa  and
      Zhang, Yue",
    booktitle = "Proceedings of the 2022 Conference on Empirical Methods in Natural Language Processing",
    month = dec,
    year = "2022",
    url = "https://aclanthology.org/2022.emnlp-main.208",
    doi = "10.18653/v1/2022.emnlp-main.208",
    pages = "3178--3190",
    abstract = "In this paper we revisit automatic metrics for paraphrase evaluation and obtain two findings that disobey conventional wisdom: (1) Reference-free metrics achieve better performance than their reference-based counterparts. (2) Most commonly used metrics do not align well with human annotation.Underlying reasons behind the above findings are explored through additional experiments and in-depth analyses.Based on the experiments and analyses, we propose ParaScore, a new evaluation metric for paraphrase generation. It possesses the merits of reference-based and reference-free metrics and explicitly models lexical divergence. Based on our analysis and improvements, our proposed reference-based outperforms than reference-free metrics.Experimental results demonstrate that ParaScore significantly outperforms existing metrics.",
}
%    address = "Abu Dhabi, United Arab Emirates",
%   publisher = "Association for Computational Linguistics",


@inproceedings{kajiwara-etal-2021-wrime,
    title = "{WRIME}: A New Dataset for Emotional Intensity Estimation with Subjective and Objective Annotations",
    author = "Kajiwara, Tomoyuki  and
      Chu, Chenhui  and
      Takemura, Noriko  and
      Nakashima, Yuta  and
      Nagahara, Hajime",
    editor = "Toutanova, Kristina  and
      Rumshisky, Anna  and
      Zettlemoyer, Luke  and
      Hakkani-Tur, Dilek  and
      Beltagy, Iz  and
      Bethard, Steven  and
      Cotterell, Ryan  and
      Chakraborty, Tanmoy  and
      Zhou, Yichao",
    booktitle = "Proceedings of the 2021 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies",
    month = jun,
    year = "2021",
    url = "https://aclanthology.org/2021.naacl-main.169",
    doi = "10.18653/v1/2021.naacl-main.169",
    pages = "2095--2104",
    abstract = "We annotate 17,000 SNS posts with both the writer{'}s subjective emotional intensity and the reader{'}s objective one to construct a Japanese emotion analysis dataset. In this study, we explore the difference between the emotional intensity of the writer and that of the readers with this dataset. We found that the reader cannot fully detect the emotions of the writer, especially anger and trust. In addition, experimental results in estimating the emotional intensity show that it is more difficult to estimate the writer{'}s subjective labels than the readers{'}. The large gap between the subjective and objective emotions imply the complexity of the mapping from a post to the subjective emotion intensities, which also leads to a lower performance with machine learning models.",
}
%    address = "Online",
%    publisher = "Association for Computational Linguistics",


@inproceedings{yamada-etal-2020-luke,
    title = "{LUKE}: Deep Contextualized Entity Representations with Entity-aware Self-attention",
    author = "Yamada, Ikuya  and
      Asai, Akari  and
      Shindo, Hiroyuki  and
      Takeda, Hideaki  and
      Matsumoto, Yuji",
    editor = "Webber, Bonnie  and
      Cohn, Trevor  and
      He, Yulan  and
      Liu, Yang",
    booktitle = "Proceedings of the 2020 Conference on Empirical Methods in Natural Language Processing (EMNLP)",
    month = nov,
    year = "2020",
    url = "https://aclanthology.org/2020.emnlp-main.523",
    doi = "10.18653/v1/2020.emnlp-main.523",
    pages = "6442--6454",
    abstract = "Entity representations are useful in natural language tasks involving entities. In this paper, we propose new pretrained contextualized representations of words and entities based on the bidirectional transformer. The proposed model treats words and entities in a given text as independent tokens, and outputs contextualized representations of them. Our model is trained using a new pretraining task based on the masked language model of BERT. The task involves predicting randomly masked words and entities in a large entity-annotated corpus retrieved from Wikipedia. We also propose an entity-aware self-attention mechanism that is an extension of the self-attention mechanism of the transformer, and considers the types of tokens (words or entities) when computing attention scores. The proposed model achieves impressive empirical performance on a wide range of entity-related tasks. In particular, it obtains state-of-the-art results on five well-known datasets: Open Entity (entity typing), TACRED (relation classification), CoNLL-2003 (named entity recognition), ReCoRD (cloze-style question answering), and SQuAD 1.1 (extractive question answering). Our source code and pretrained representations are available at \url{https://github.com/studio-ousia/luke}.",
}
%    address = "Online",
%   publisher = "Association for Computational Linguistics",
