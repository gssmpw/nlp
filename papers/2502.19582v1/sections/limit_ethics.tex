\section{Limitations}\label{sec:limits}
We identify the following limitations for our work:
\begin{enumerate}
\item \textbf{Data and Data Availability Bias.} Our benchmark relies on publicly available datasets, which inherently reflect existing biases in language documentation and institutional support. Many Indigenous African languages remain severely underrepresented due to historical policies that prioritize dominant languages. As a result, our findings may not fully capture the linguistic diversity of the continent.

\item \textbf{Task Scope.} The evaluation primarily focuses on tasks where data is available, such as language identification and text classification. However, the scarcity of datasets for complex NLP tasks (e.g., machine translation, question answering) limits our ability to assess model performance in broader applications. Future efforts should address this gap by developing more comprehensive datasets across a wider range of tasks.

\item \textbf{Model Performance Constraints.} While we analyze the impact of data scarcity on model effectiveness, our study does not explore architectural modifications or fine-tuning strategies that could improve performance for low-resource languages. Further research is needed to examine whether adaptive techniques, such as multilingual pretraining with targeted data augmentation, could mitigate these challenges.

\item \textbf{Policy Implementation Challenges.} Our recommendations for policy reforms and inclusive data practices require significant institutional commitment and resources. While we outline actionable steps, their adoption depends on the willingness of governments, research institutions, and technology developers to prioritize African language inclusion in NLP.

\end{enumerate}

Despite these limitations, our work underscores the urgency of addressing data inequities and advocating for policies that foster greater linguistic diversity in AI development.










\section{Ethical Considerations}\label{sec:ethics}
We make the following ethics-related statements about our work:
\begin{enumerate}

\item Our research aims to investigate the progress of NLP for African languages, addressing historical language policies that have contributed to data inequities. By improving representation in NLP, we align with broader efforts to foster linguistic diversity in AI, ensuring that African languages are not sidelined in technological advancements.

\item  The datasets used in our benchmark are derived from publicly available sources, yet their existence is shaped by historical and contemporary policies that prioritize certain languages over others. We acknowledge that the digital presence of African languages is not merely a technical issue but a policy-driven reality that influences which languages receive institutional support and investment.

\item Although we do not develop models in this work, our findings highlight the impact of policy-induced data disparities on model performance. Addressing these challenges requires policy interventions that support multilingual data collection, equitable resource allocation, and ethical considerations in dataset creation.

\item Proper attribution to dataset authors is not just an academic necessity but a policy imperative for transparency and recognition. To mitigate concerns about data ownership and ethical usage, we provide a publicly accessible reference file citing all datasets included in our benchmark. We strongly encourage researchers and policymakers to acknowledge these sources, reinforcing the importance of ethical and inclusive data practices.

\end{enumerate}
