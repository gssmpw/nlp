Pokémon Red, a classic Game Boy JRPG, presents significant challenges as a testbed for agents, including multi-tasking, long horizons of tens of thousands of steps, hard exploration, and a vast array of potential policies.  
We introduce a simplistic environment and a Deep Reinforcement Learning (DRL) training methodology, demonstrating a baseline agent that completes an initial segment of the game up to completing Cerulean City.  
Our experiments include various ablations that reveal vulnerabilities in reward shaping, where agents exploit specific reward signals.  
We also discuss limitations and argue that games like Pokémon hold strong potential for future research on Large Language Model agents, hierarchical training algorithms, and advanced exploration methods.
Source Code: \url{https://github.com/MarcoMeter/neroRL/tree/poke_red}