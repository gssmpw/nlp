\section{Conclusion}

In this work we present a novel loss function called \loss for improving confidence calibration in a cascade between a small local and a larger remote model. Our loss is architecture and task agnostic, making it flexibly applicable across a wide range of applications. Our results demonstrate that our approach improves over standard confidence-based deferral rules and effectively leads the small model to unlearn how to handle complex queries in favor of easier ones. 

\textbf{Limitations} While our approach demonstrates promising results, there are a few notable constraints. First, we assume that only the smaller model can be tuned, while in some application the larger model might also adjustable for deferral. Second, our experiments primarily measure improvement over a single untuned baseline, potentially overlooking broader comparative insights. Third, we did not extensively evaluate across different model families in LLM and VLM settings (although we did so in classification experiments with ResNet vs.\ MobileNet). Finally, using a generative model (e.g., Gemini) to judge VLM captioning introduces the risk of erroneous assessments since LLMs are also imperfect oracles.
