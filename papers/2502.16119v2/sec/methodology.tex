\section{Methodology}
\label{sec:methodology}

\subsection{Problem Definition}
We consider a problem involving $M$ clients, which have heterogeneous models and private data. The local model of client $k$, $k\in\{1,\dots,M\}$, is split into two components: a feature extractor $f_k$ parameterized by $\phi_k$, and a classifier $h_k$ parameterized by $\theta_k$. Given a sample pair ($x, y$), the feature extractor $f_k$ transforms $x \in \mathbb{R}^{D}$ into a feature representation $r=f_k(x;\phi_k)$, $r \in \mathbb{R}^{K}$, where $D$ is the dimension of input and $K$ is the dimension of feature representation ($K \ll D$). The classifier $h_k$ maps the feature vector $r$ to logits $\in \mathbb{R}^{C}$, where $logits = h_k(r; \theta_k)$ and $C$ denotes the total number of classes. The client model's parameters are defined as $\omega_k = (\phi_k, \theta_k)$. The optimization objective of FedORGP is defined as:
\begin{equation}\min\sum_{k=1}^M\frac{|\mathcal{D}_k|}{|\mathcal{D}|}\mathcal{L}_k\left(\mathcal{D}_k,\omega_k,\mathcal{P}\right),
    \label{eq:overall objective}
\end{equation}
where $|\mathcal{D}|$ denotes the total size of datasets across all clients, $|\mathcal{D}_k|$ indicates the size of the dataset of client $k$, $\mathcal{P}$ represents the global prototype.

\subsection{Orthogonality Regularization on Prototypes}
Following FedProto \cite{tan2022fedproto}, the prototype of class $c$, $c \in \{1, \ldots, C\}$, for client $k$ is defined as follows:
\begin{equation}
    P_k^c=\mathbb{E}_{(x,c)\sim\mathcal{D}_{k,c}}f_k(x;\phi_k),
    \label{eq:client prototype definition}
\end{equation}
where $D_{k, c}$ is the subset of $D_k$ consisting of samples of class $c$. We initialize a random embedding $\tilde{P}^c$ for each class $c$. We define the trainable prototypes module $F$ which comprises two Fully-Connected layers with a ReLU activation function in between, parameterized by $\omega_s$ \cite{fedtgp}. We input the initial prototype vector $\tilde{P}^c\in\mathbb{R}^K$ into $F$, producing the final global prototype $\hat{P}^c=F(\tilde{P}^c;\omega_s)$. The transformation network parameters, along with the embeddings, are optimized jointly during training. This module is designed to generate adaptable prototype for each class.

To enhance the separation between global prototypes in the feature space, we adopt orthogonality regularization to train global prototypes. After client local training, the server will get the client prototypes $\mathcal{P}_k$, which consists of the prototypes of different classes of $k$-th client. Then, the dataset we use to train the global prototype can be expressed as $\mathcal{Q} = \bigcup_{k=1}^{M} \{ P^c_k \mid c \in \mathcal{C}_k \}$, where $\mathcal{C}_k \subseteq \{0, 1, ..., C - 1\}$ denotes the set of classes present on $k$-th client.

Our purpose is to cluster $\hat{P}^c$ and $P_k^c$, while discriminating between $\hat{P}^c$ and $P_k^{\Bar{c}}$, where $\bar{c} \ne c$. Formally, within a mini-batch $B_p \subseteq \mathcal{Q}$, we define $s$ as intra-prototype similarity and $d$ as inter-prototype similarity:
\begin{align}
    s &= \frac{1}{|B_p|}\sum_{P_k^c \in B_p}\langle P_k^c, \hat{P}^c\rangle, 
    \label{eq:similarity eqution}\\[1ex]
    d &= \frac{1}{|B_p|}\frac{1}{|C| - 1}\sum_{P_k^c \in B_p}\sum_{\substack{\bar{c} \in C \\ c\ne\bar{c}}}\left|\langle P_k^c, \hat{P}^{\bar{c}}\rangle\right|,
    \label{eq:dissimilarity eqution}
\end{align}
where $k \in \{1, \ldots, m\}$, $m$ is the number of clients participating in the training, $\left|\cdot\right|$ is the absolute value operator. Note that the cosine similarity operator $\langle\cdot,\cdot\rangle $ on two vectors involves normalization of features (projection to a unit hypersphere) and is calculated as $\langle v_i, v_j \rangle=\frac{v_i\cdot v_j}{\|v_i\|_2\cdot\|v_j\|_2}$, where $||\cdot||_2$ refers to the $l_2$ norm operator.

Then, we define a unified loss function $\mathcal{L}_{\mathrm{OR}}$ that simultaneously ensures intra-class clustering and inter-class orthogonality within a mini-batch as follows:
\begin{equation}
    \mathcal{L}_{\mathrm{OR}}=\lambda_s*(1-s)+\gamma*d,
    \label{eq:OC Loss eqution}
\end{equation}
where $\lambda_s$ and $\gamma$ are hyperparameters to balance the contributions of each term to the overall loss. Specifically, $\lambda_s$ is employed to regulate the influence of the intra-class loss, while $\gamma$ controls the weight of the inter-class loss. This configuration allows for a flexible adjustment of the intra-class compactness and inter-class separation.

\begin{figure}[t]
    \centering
    \includegraphics[width=\linewidth, height=3.3cm]{pictures/oc_hv.pdf}
    \caption{Orthogonality-constrained prototypes can expand inter-class margins while enhancing intra-class clustering.}
    \label{fig:orthogonal constraint picture}
\end{figure}

The training objective is to minimize the loss function $\mathcal{L}_{\mathrm{OR}}$ defined in Eq. \ref{eq:OC Loss eqution}. Notice that $(1 - s) > 0$ inherently holds (as $s \in (-1, 1)$, making $(1 - s) \in (0, 2)$), and $d$ is already an absolute value with $d \in (0, 1)$. Therefore, we should maximize $s$ toward 1 while minimizing $d$ toward 0. 
As depicted in Fig.\ref{fig:orthogonal constraint picture}, when minimizing this overall loss, the first term $\lambda_s * (1 - s)$ promotes clustering of prototypes within the same class, while the second term $\gamma * d$ enforces orthogonality among prototypes of different classes. The loss can be implemented efficiently in a vectorized manner on the mini-batch level, avoiding any loops.

To maintain directional independence, the prototypes of different classes are constrained to be orthogonal during the optimization process. This structure not only improve intra-class compactness but also explicitly enlarges inter-prototype separation, while preserving the semantic integrity of each class. 

\subsection{The Suitability of Orthogonality for CE Loss}
The multi-class Cross-Entropy loss function is a common loss function used in classification problems, for each sample $(x, y)$, the loss function can be defined as follows: 
\begin{align}
    \mathcal{L}_{CE}(\hat{y}, y) 
    &= -\sum_{c=1}^{C} \mathbb{I}(c = y) \log(p_c)
    % \left(\mathbb{I}(c = y) = \begin{cases}
    % 1, & c = y \\
    % 0, & c \neq y
    % \end{cases}\right)
    \nonumber\\
    &= - \log\left(\frac{\exp(z_{y})}{\sum_{c' = 1}^{C} \exp(z_{c'})} \right)\\
    &= - \log \left( \frac{\exp(r^y \cdot w^y)}{\sum_{c' = 1}^{C} \exp(r^y \cdot w^{c'})} \nonumber\right)
     \label{eq:cross_entropy}
\end{align}
where $\hat{y}$ is the predicted label and $y$ is the truth label. $\mathbb{I}\left(\cdot\right)$ is an indicator function. $p_{c}$ represents the predicted probability that the model predicts the sample to belong to class $c$. $z_y$ is the logits of the sample. 
We define the classifier $W = [w^1, ... , w^C]$, where $w^y \in \mathbb{R}^K$ is the learning projection vector of label $y$. The CE loss can then be defined in terms of discrepancy between the predicted $\hat{y}$ and ground-truth label $y$, by projecting the features $r^y$ onto the weight matrix $W$. When a client trains the model with the global prototypes, it ensures that $r^y$ remains aligned with the prototype $\hat{P}^y$. During updates with SGD, the CE loss further reinforces the alignment between weight vector $w^y$ and its corresponding feature representation $r^y$ through a dot product operation, given as: 
\begin{equation}
r^y \cdot w^y=\|r^y\|\cdot\|w^y\|\cdot\cos(\theta_{r^y,w^y}),
\label{eq:dot product}
\end{equation}
where $\theta_{r^y,w^y}$ represents the angle between $r^y$ and $w^y$. Thus, when the angle between the feature representation $r^y$ and the weight vector $w^y$ approaches zero, their inner product is maximized, indicating directional alignment. Meanwhile, since the feature representation $r^y$ is explicitly aligned with the global prototype $\hat{P}^y$ during training, the three components ($r^y$, $w^y$, and $\hat{P}^y$) continuously align with each other in the feature space. However, the Cross-Entropy (CE) loss inherently lacks an explicit mechanism to enforce angular separation between different classes, leading to potential overlap in feature representations and consequently suboptimal discriminative performance. To overcome this limitation, we propose orthogonality regularization (OR) to explicitly enlarge angular separation among global prototypes. By enforcing orthogonality among global prototypes, OR significantly reduces inter-class overlap, thereby ensuring robust directional consistency among $r^y$, $w^y$, and $\hat{P}^y$, and ultimately improving the discriminative capability of the classifier in heterogeneous federated environments.

\begin{figure}[t]
    \centering
    \includegraphics[width=\linewidth]{pictures/overview.pdf}
    \caption{This image illustrates the FedORGP framework involving two clients. From \ding{172} to \ding{175}: We input the samples, get the representations, then input them into the classifier for prediction, and finally calculate the CE loss. \ding{176}: The dissimilarity between the feature representation and its corresponding prototype is calculated as a regularization term. \ding{177}: After the local model is updated, we collect the client prototypes. \ding{178}: Orthogonality regularization are applied to the global prototypes on the server to enhance angular separation.}
    \label{fig:overview}
\end{figure}

% To address this, prior work has introduced angular margin modifications to the CE loss, such as additive angular margin $\cos(m+\theta_y)$, multiplicative angular margin $\cos(m\theta_y)$, and additive cosine margin $m+\cos(\theta_y)$, to ensure better separation between classes. These modifications, however, add computational complexity due to the gradient propagation challenges inherent in margin-based formulations. Instead of adding margins, our proposed loss function applies orthogonality regularization to enforce separation by encouraging class prototypes to be orthogonal, thereby simultaneously achieving class separation and intra-class clustering. This formulation facilitates efficient vectorized implementation, simplifying gradient computation and propagation.

\subsection{Local Model Update}
In FedORGP, the client updates its local model to generate embeddings that are consistent with the global prototypes shared across clients. To maintain directional alignment with the global prototype, a regularization term is added to the local loss function, which encourages feature representations from $k$-th client $r_k^c$ to align with their respective global prototypes $\hat{P}^c$ while minimizing classification error. Then, the client prototype $P_k^c$ has a more separate margin. Specifically, the loss function is formulated as follows:
\begin{equation}
\begin{split}
    \mathcal{L}_k:=
    &\mathbb{E}_{(x,y)\sim \mathcal{D}_k}\mathcal{L}_{CE}(h_k(f_k(x;\phi_k);\theta_k),y)+\\
    &\lambda_c \cdot \mathbb{E}_{(x,y)\sim \mathcal{D}_k}\mathcal{L}_R(f_k(x;\phi_k),\hat{P}^y),
\end{split}
\label{eq:client loss eqution}
\end{equation}
where $\lambda_c$ is a hyperparameter.
% and the regularization is defined as:
% \begin{equation}
% \mathbb{E}_{(x,y)\sim B}\mathcal{L}_R(r_k^y,\hat{P}^y)=1 - \frac{1}{|B|}\sum_{(x, y) \in B}\langle r^y,\hat{P}^y\rangle ,
% \label{client LR}
% \end{equation}
This regularization $\mathcal{L}_R$ facilitates the alignment between feature representations and global prototypes across clients, enhancing the global consistency and robustness of the federated model in heterogeneous environments.

\subsection{FedORGP Framework}

\begin{algorithm}[t]
\caption{The learning process of FedORGP}
\label{alg:workflow}
\begin{algorithmic}[1]
    \Require $M$ clients with heterogeneous models and data, trainable global prototypes $\hat{\mathcal{P}}$ on the server, local epochs $E$, and total communication rounds $T$
    \Ensure Well-trained client models.

    \State \textbf{Server:}
    \State \textbf{for} round $t = 1, \dots, T$ \textbf{do}
        \State \quad Randomly sample a client subset $\mathcal{I}^t$
        \State \quad Send $\hat{\mathcal{P}}$ to clients in $\mathcal{I}^t$
        \State \quad \textbf{for each} Client $k \in \mathcal{I}^t$ \textbf{in parallel do}
            \State \quad\quad Client $k$ performs local training
        \State \quad \textbf{end for}
        \State \quad Train the global prototype on the server by Eq. \ref{eq:OC Loss eqution}
    \State \textbf{end for}
    \State \Return Well-trained client models.

    \State \textbf{Client Local Training:}
    \State \quad \textbf{for} iteration $e$ = 1, \ldots, $E$ \textbf{do}
    \State \quad \quad Local training with the global prototype by Eq. \ref{eq:client loss eqution}
    \State \quad \textbf{end for}
    \State \quad Collect local prototypes $\{P^c_k | c \in \mathcal{C}_k\}$ by Eq. \ref{eq:client prototype definition}
    \State \quad Send local prototypes $\mathcal{P}_k$ to the server
\end{algorithmic}
\end{algorithm}


We present the complete workflow of FedORGP in Alg.\ref{alg:workflow} and give an illustration in Fig.\ref{fig:overview}. The well-trained, class-separable global prototypes are then distributed to clients in the subsequent round to guide client training for improving separability among feature representations.