\section{Related Work}
\label{sec:related work}

\subsection{Heterogenous Federated Learning}
% Federated Learning (FL) has gained significant attention as a privacy-preserving distributed machine learning approach, allowing collaborative model training without sharing private data \cite{fedavg}. The traditional FL methods, such as FedAvg \cite{fedavg}, focus on training a global model across multiple clients by aggregating gradients \cite{FLadvance}. However, these methods face major challenges in the presence of statistical and model heterogeneity, often resulting in suboptimal model performance due to non-IID data and diverse client hardware capabilities \cite{fl_challenges_methods_directions}. Although personalized FL methods \cite{t2020personalizedfl, li2021ditto, collins2021exploiting} are introduced to address the statistical heterogeneity in FL, they remain unsuitable for scenarios where clients deploy heterogeneous models tailored to their specific tasks. 

Heterogeneous Federated Learning (HtFL) has emerged as a solution that supports both model and statistical heterogeneity simultaneously, while ensuring user privacy.
% System heterogeneity, including differences in clients' computational power, network bandwidth, and storage capacity, is a major obstacle for scalable FL deployment \cite{data_and_model_heterogenous}. 
Early HtFL solutions \cite{diao2020heterofl, horvath2021fjord, wen2022federated} let clients sample different submodels from a shared global architecture, thereby reducing the computational burden on low-resource devices. However, these methods necessitate a common architecture to be shared across clients, raising privacy concerns regarding clientsâ€™ model architectures.

An alternative approach to system heterogeneity shares a common model of the same structure at the server side, e.g. a global header \cite{yi2023fedgh} or a global generator \cite{FedGen}, as a way to transfer global knowledge. LG-FedAvg \cite{lgfedavg} and FedGH \cite{yi2023fedgh} require clients to share the same top layer while allowing them to have different architectures in their lower layers. However, sharing and aggregation of top layers may result in suboptimal performance due to statistical heterogeneity \cite{nofearofclassifierbiases, nofearofheterogenity}. FedGen \cite{FedGen} is designed to mitigate model drift in heterogeneous FL environments by using a generative model to extract global knowledge from local models. While this method avoids reliance on proxy datasets, its performance highly relies on the quality of the generator \cite{fedtgp}. Despite allowing some level of flexibility, they still assume that clients share partially similar models. 

Alternatively, another HtFL approach aims to enable completely independent client model architectures by exchanging various forms of information, such as knowledge or prototypes. FedMD \cite{li2019fedmd} and FedDF \cite{FedDF} facilitate knowledge transfer between participants through distillation over public datasets. However, ideal public datasets are often difficult to access \cite{public_dataset_is_difficult_to_obtain}. FML \cite{fml} and FedKD \cite{fedkd} train and share a small auxiliary model using mutual distillation, circumventing the need for a global dataset \cite{fedtgp}. Nonetheless, the bi-directional distillation process relies on frequent communication between clients and the server, which can result in significant communication overhead.

Prototype-based HtFL methods \cite{tan2022fedproto,FedPCL,FedPAC} have shown promise in addressing both model and statistical heterogeneity. These approaches not only enhance model convergence in non-IID settings but also substantially reduce communication overhead by transmitting prototypes instead of full models \cite{FedPCL}. However, these methods rely on simple weighted averages of client prototypes, which increase the chance of overlap between global prototypes in the feature space. While FedTGP \cite{fedtgp} increases prototype separation by contrastive learning without using weighted averages, boosting the Euclidean distance between embeddings does not integrate well with CE loss \cite{opl, comprehensive-survey-of-distance}. In this work, we introduce orthogonal regularization to explicitly enhance the angular margin among global prototypes, thereby tackling data and model heterogeneity in HtFL.

\subsection{Prototype Learning}
Prototype refers to the average of features representations of the same class. FedNH \cite{FedNH} addresses data heterogeneity by leveraging uniformity and semantics of class prototypes. FPL \cite{FPL} and FedPLVM \cite{FedPLVM} mainly focus on solving the domain drift problem using prototype clustering. However, they all require model aggregation, which necessitates that client models share the same architecture, implying that they cannot work in scenarios with model heterogeneity. Our proposed FedORGP encourages prototype separation to establish distinct margins among prototypes, thereby guiding heterogeneous client models to assimilate global knowledge.

\subsection{Orthogonality}
Orthogonality typically describes the directional independence between two vectors. In high-dimensional space, two vectors are considered orthogonal if their dot product is zero \cite{opl}. FediOS \cite{Fedios} effectively separates generic and personalized features using orthogonal projections to address feature skew in personalized federated learning. However, it requires all client models to have identical architectures. C-FSCIL \cite{C-FSCIL}, OPL \cite{opl} and POP \cite{POP} enhance feature separation between classes via orthogonality regularization. However, they are only applicable to the optimisation of centralised training scenarios and are not applicable to the optimisation of federated scenarios. FOT \cite{FOT} and FedSOL \cite{FedSOL} are primarily concerned with the orthogonality of update directions to minimise interference across clients or tasks. However, neither of them can guarantee the orthogonality of the samples in the feature space.