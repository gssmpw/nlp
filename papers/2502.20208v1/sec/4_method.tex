\begin{figure*}[t]
    \centering
    \includegraphics[width=.9\linewidth]{images/pipeline.pdf}
    \caption{\textbf{Pipeline of 4Deform}: Given a temporal sequence of inputs, we initialize a latent vector to each point cloud. Then the network takes pairs of point clouds $\P_0$ and $\P_1$ (with sparse correspondences), together with the concatenated latent vector $\vt{z}_0$ and $\vt{z}_1$ as input. At training time, we jointly optimize two neural fields: a time-varying implicit representation (Implicit Net $\phi$) and a velocity field (Velocity Net $\mathcal{V}$) with proposed geometric and physical constraints losses. Conditioning on a time stamp $t$, we instantaneously obtain a continuous time-varying signed distance function (SDF), an offset of the input toward the target (velocity field).
    %, and an optimized latent space which gives more generalization applications.
    % and concatenate them to train in the implicit net and the Velocity Net. Both networks are jointly trained using proposed geometric and physical constraints. The implicit net recovers the SDF of inputs and intermediate shapes, the Velocity Net gives per-vertex movement at each time step. 
    % Our pipeline, 4Deform, starts from two point clouds ($\P_{0}$ and $\P_{1}$) from a collection of inputs, and a correspondence estimation obtained from a potentially imprecise module, even in terms of a spatial proxy (e.g., a registration not perfectly aligned with the input PC). At training time, we optimize two neural fields: an implicit representation (Implicit Net) and a velocity field (Velocity Net) with losses that let them help each other. Conditioning on a time stamp t, we instantaneously obtain an interpolated signed distance function (SDF) and offset of the input toward the target (velocity).
}\label{fig:pipeline}
\vspace*{-2mm}
\end{figure*}

\section{... to Neural Implicit Surface Deformation}
\label{sec:method}
% \paragraph{Motivation.} \RM{Here I would add a comment to repeat how we differentiate ourself from \cite{anonymous2024implicit}} \LS{Then it is the prefect change to introduce sequences input.}
% \inparagraph{Motivation.} Previous implicit or point cloud deformation methods either rely on ground truth correspondences, struggle with large deformations~\cite{anonymous2024implicit}, or are limited to shape pairs~\cite{liu2022learning, Novello2023neural, anonymous2024implicit}, restricting their applicability. To overcome these limitations, we propose a method that first incorporates a shape-matching block to address correspondence issues, then handles larger deformations by establishing stronger physical constraints, and extends functionality to collections of point clouds.
% \inparagraph{Overview.} 
Previous implicit or point cloud deformation methods either rely on ground truth correspondences, struggle with large deformations~\cite{anonymous2024implicit}, or are limited to shape pairs~\cite{liu2022learning, Novello2023neural, anonymous2024implicit}, restricting their applicability. To overcome these limitations, we propose a method that first incorporates a corresponding block to obtain sparse correspondences, then handles larger deformations by establishing stronger physical constraints, and extends functionality to \emph{temporal sequence} of point clouds via an AutoDecoder architecture~\cite{Goodfellow2016}. Given point clouds sequence $\{\P_{0}, \P_{1}, \dots, \P_{n},\dots \}$ with an initialized latent vector to each point cloud $\{\vt{z}_0, \vt{z}_1, \dots, \vt{z}_n, \dots\}$, where $\P_{k}=\{\vt{x}_i^k\}_i \subset \mathbb{R}^3$ and $\vt{z}_i \in \mathbb{R}^m$ is a trainable latent vector that is assigned to each input point cloud. We pair the inputs as a source point cloud and a target point cloud (for convenience we label them as $\P_0$ and $\P_1$). We aim to generate physically plausible intermediate stages of all training pairs accordingly. To this end, we propose to model the 4D movements using a time-varying implicit neural field of the form:
\eq{\label{eq:boundary}
% \surf{t} = \{ \vt{x} \in \dom | ~ f(\vt{x},t) = 0\}\;.
\surf{t} &= \{\vt{x} | \phi_{\vt{z}}(\vt{x}, t) =0\}, \text{for}~\vt{z} := \vt{z}_0~\oplus~\vt{z}_1 \;.
% \surf{1} &=\{\vt{x}| f(\vt{x}, 1, \vt{z}_1) =0\}\;.
}
Each shape $\surf{t}$ in time $t$ is encoded by the zero-crossing of the implicit function $\phi$. Particularly, $\surf{0}$ and $\surf{1}$ should coincide with $\P_0$ and $\P_1$. 
% Our method's pipeline is as shown in~\cref{fig:pipeline}. 
% For simplicity, we use $\vt{z}$ to refer to the concatenated latent vector in the following text.
\subsection{Correspondence Block}
Instead of relying on ground-truth correspondences, which are difficult to obtain in real-world settings, our method obtains the correspondences based on the state-of-the-art unsupervised non-rigid 3D shape matching method~\cite{cao2023unsup}. This method is based on the functional map framework~\cite{ovsjanikov2012functional} and follow-up learning-based approaches~\cite{roufosse2019unsupervised,donati2020deep}. The key ingredient of the functional map framework is that, instead of directly finding correspondences in the spatial domain, it encodes the correspondences in the compact spectral domain and thus is robust to large deformation~\cite{cao2023unsup}. More details about functional maps can be found in this lecture note~\cite{ovsjanikov2016computing}. It is worth noting that our method is agnostic to the choice of shape-matching methods. For instance, for specific types of input shapes (e.g. humans), specialized registration methods can also be utilized to obtain more accurate correspondences~\cite{marin2020farm,marin2023geometric,bhatnagar2020loopreg}.    

\subsection{Implicit and Velocity Fields}
To ensure the physically plausible intermediate stage, we model the deformation from the source point cloud to the target point cloud by tracking the point cloud path using the velocity field $\mathcal{V}_{\vt{z}}(\vt{x},t) \in \mathbb{R}^3$. We adopt the velocity field for two reasons, 
\begin{enumerate*}[label=(\roman*), itemjoin=~]
\item The velocity field allows us to control the generated deformation. It is easy to add physical-based constraints directly on velocity to force the intermediate movement to follow certain physical laws. 
\item There is a link from the velocity field to the implicit field as the implicit field can be seen as a macroscopic field. We can perform the material deviation to derive the natural relationship between velocity field $\mathcal{V}_{\vt{z}}(\vt{x},t)$ and implicit field $\phi_{\vt{z}}(\vt{x},t)$. For simplicity, we omit the latent vector $\vt{z}$ in the following equations.
\end{enumerate*}
We follow~\cite{anonymous2024implicit} to use the Modified Level Set equation to link the velocity field and implicit field via level-set loss
\eq{\label{eq:loss_i}
\mathcal{L}_i = \int_{\dom} \norm{\partial _t \phi + \mathcal{V} \cdot \nabla \phi +\lambda_l \phi \mathcal{R}(\vt{x}, t)}_{l^2} \dd \vt{x}\;.
}
Since the surface normal $\vt{n}$ coincides as implicit function gradient $\nabla \phi$, this loss offers \emph{geometry constraint} to Velocity Net, and as the point is moved by Velocity Net, Eq.~\eqref{eq:loss_i} also works as a \emph{physical constraint} from Velocity Net to Implicit Net, as shown in~\cref{fig:pipeline}.
We force the Velocity Net to move the point with known correspondences to the target input position by 
\eq{
% \L_m = \int_{\dom^*}\norm{\phi(\vt{x},1,\vt{z}) - \vt{x}^1}_{l^2} \dd \vt{x}\;,
\L_m = \int_{\dom^*}\norm{ \vt{x}^0+\int_0^1 \V{\vt{x},\tau}\dd \tau - \vt{x}^1}_{l^2} \dd \vt{x}\;,
}
where $\dom^*$ only contains points with known correspondences. 

\subsection{Physical Deformation Loss}
A key challenge in deforming implicit neural fields with external velocity fields is ensuring physically realistic movement, as commonly used constraints like as-rigid-as-possible (ARAP)~\cite{sorkine2007rigid} are difficult to enforce without a connectivity structure. To address this, we introduce new physical deformation losses on both the implicit and velocity fields to better control movement. These losses do not require connectivity information, thus it can be enforced on unordered input and allow arbitrary resolution of input.
% \eg, point cloud, and allow arbitrary resolution of the input.

\inparagraph{Distortion Loss.}
In the Eulerian perspective of continuum mechanics, the rate of deformation tensor provides a measure of how the fluid or solid material deforms over time from a fixed reference point in space, excluding rigid body rotations. It measures the rate of stretching, compression, and shear that a material element undergoes as it moves through the flow field~\cite{spencer2004continuum}. The rate of deformation tensor is defined by
\eq{\label{eq:deformation_tensor}
\vt{D} = \frac{1}{2}(\nabla \mathcal{V} + (\nabla \mathcal{V})^\top) \;.
}
The distortion of the particle moved under the velocity $\mathcal{V}$ can be described by the deviatoric form
\eq{\label{eq:distortion}
\mathcal{L}_{d} = \int_{\dom} \norm{\frac{1}{6}\tr(\vt{D})^2-\frac{1}{2} \tr(\vt{D} \cdot \vt{D})^2 }_{F}\dd \vt{x}\;.
}
Eq.~\eqref{eq:distortion} is the complement of the volumetric changes. This term removes the volumetric part, leaving behind the deviatoric (distortional) component. It offers \emph{physical constraint} to both networks during training.

\inparagraph{Stretching Loss.} %\LS{could shorten a bit...}
% Compared to mesh-based methods, where the connectivity of vertices is explicitly defined and stored in polygons. Thus, one can directly constrain the properties such as edge length or triangle areas to force a mesh to deform following physical law, e.g., stretching or bending movement of the mesh. However, in implicit representations with only point clouds as the underlying geometry property, it is hard to directly control the physical feature of the deformed surface. Luckily, with our setting, in which the movement of the point cloud is tracked by a velocity field, we can establish a constraint to directly control the stretching of the surface along the movements. 
By tracking point cloud movement with a velocity field in our approach, we can establish constraints to control surface stretching along the deformation.
We follow the idea of strain tensor from continuum mechanics~\cite{spencer2004continuum}. Consider deformation happens in infinitesimal time $\Delta t$, the displacement of point $\vt{x}$ is moved to $\vt{x}'$ such that
\eq{\label{eq:displacement}
\vt{x}' = \vt{x} + \V{\vt{x},t}\Delta t\;.
}
% $\phi(\vt{x}, t+\Delta t)$ and 
% \eq{\label{eq:displacement}
%  \vt{x}' = \phi(\vt{x}, t+\Delta t) = \vt{x} + \V{\vt{x}, t} \;.
% }
% The strain tensor describes the spatial change of distance after deformation. 
Consider a infinitesimal neigbourhood of $\vt{x}'$, denote as $\dd \vt{x}'$, the length of it is given by $ (\dd \vt{s}')^2 = \dd \vt{x}'^\top \dd \vt{x}'$. Similarly, the length of infinitesimal neighborhood of $\vt{x}$ is given by $(\dd\vt{s})^2=\dd\vt{x}^\top\dd\vt{x}$. Together with Eq.~\eqref{eq:displacement}, the stretched length after deformation is given by  
\eq{\label{eq:stretching}
(\dd \vt{s}')^2 - (\dd\vt{s})^2 = \dd\vt{x}^\top (\vt{F}^\top\vt{F}-\vt{I})\dd\vt{x}\;,
}
where $\vt{F} = \partial \vt{x}' / \partial \vt{x} = \vt{I} + \nabla \mathcal{V}$. However, instead of considering the stretch on the neighborhood patch of one surface point, preventing stretching on the tangent plane of a point is what makes a deformation physically realistic~\cite{yang2021geometry}. 
% For point $\vt{x}$ with normal $\vt{n}(\vt{x})$, to project any vector to the tangent space of $\vt{x}$ is given by $\vt{P}(\vt{x}) = \vt{I} - \vt{n}^\top\vt{n}$.
We project $\dd \vt{x}$ in  Eq.~\eqref{eq:stretching} to its tangent space using projection operator $\vt{P}(\vt{x}) = \vt{I} - \vt{n}(\vt{x})^\top\vt{n}(\vt{x})$ to compute the stretching on the tangent plane, where $\vt{n}(\vt{x})$ is the normal vector on point $\vt{x}$. Thus, the stretching on the tangent plane is
\eq{
 (\dd l)^2 = \dd \vt{x}^\top\vt{P}^\top(\vt{x})(\vt{F}^\top\vt{F}-\vt{I})\vt{P}(\vt{x}) \dd \vt{x} \;.
}
Finally, thanks to the nice properties of the implicit field, we have $\vt{n}(\vt{x}) = \frac{\nabla \phi(\vt{x},t)}{\norm{\nabla \phi(\vt{x},t)}}$. Therefore, for any $\dd \vt{x}$, we constraint the matrix Frobenius norm as 
\eq{\label{eq:stretching_loss}
\mathcal{L}_{st} = \int_{\dom} \norm{\vt{P}^\top(\nabla\mathcal{V}^\top\nabla\mathcal{V} + \nabla\mathcal{V} + \nabla\mathcal{V}^\top) \vt{P} }_{F} \dd \vt{x}
}
where $\vt{P} = \vt{I} - \nabla \phi\nabla \phi^\top$.
% and $\norm{\cdot}_{F}$ stand for Frobenius norm of matrix.

\subsection{Training and Inference}
\inparagraph{Training.} Given a temporal sequence of inputs $\{\P_k\}_k$, which may be point clouds or meshes, we start by using our correspondence blocks to obtain the correspondences of each training pair.
% Unlike most mesh-based methods, we do not need inputs to have the same properties such as point numbers or genus. 
Importantly, our method does not require full correspondence for every training point; it only requires a subsample of points. During training, we initialize a trainable latent vector for each shape. We concatenate the latent vectors of each training pair and optimize them using our Implicit Net $\phi$ and Velocity Net $\mathcal{V}$ jointly.  We sample $T+1$ discrete time steps uniformly for $t = \in \{0, 1/T,\dots, 1\}$ to compute the loss at each time step. 
The total loss is 
\eq{\label{eq:loss}
\mathcal{L} = \lambda_i \mathcal{L}_i + \lambda_s \mathcal{L}_s + \lambda_v \mathcal{L}_v + \lambda_{st} \mathcal{L}_{st} + \lambda_{m}\L_{m}\;,
}
where $\lambda_i$, $\lambda_s$, $\lambda_v$, $\lambda_{st}$ and $\lambda_{m}$ are  weights for each loss term. For further details about implementation and training, we refer to supplementary materials.

\inparagraph{Inference.} During inference, we give the optimized latent vector for each trained pair into the Implicit Net $\phi$ 
% \fb{f vs $\phi$; also, upper lower case of Implicit Net} 
to generate intermediate shapes at different discrete time steps $t$. Given an initial point cloud, we pass it with the optimized latent vector to the Velocity Net $\mathcal{V}$, producing a sequence of deformed points at each time step. 
% Our experiments demonstrate that we can also infer points that are not aligned with the training points and produce reasonable results, which broaden the application of our methods, as we show in our experiments sections.
% \fb{board? seems like the wrong term} 

% and by adjusting the latent vector, we can create new movement sequences.

