% \vspace*{-12pt}
\section{Introduction}
\label{sec:intro}
Inferring the dynamic 3D world from just a sparse set of discrete observations is among the fundamental goals of computer vision. These observations might come, for example, from video sequences~\cite{sun2021neucon}, Lidar scans~\cite{forlani2006c, tachella2019bayesian} or RGB-D cameras~\cite{Sommer2022, sang2023high}.
Even more challenging is the recovery of plausible motion in between such observations. Despite the relevance of this problem, just a few works addressed this, likely because the solution requires merging concepts of camera-based reconstruction with techniques of 3D shape analysis and interpolation.

% The complexity of this problem has encountered just a few attempts. Often, the Computer Graphics community proposed interpolation approaches for mesh representations \RM{cit.}. This setting lets the user define several intrinsic constraints to promote desirable properties, such as near-isometric deformations \RM{cit.} or relying on data-driven template \RM{cit.} or latent \RM{cit. LIMP} priors. However, they often assume a dense, exact point-to-point correspondence between the frames, which is usually unpractical and rare in Computer Vision. Also, such methods rely on a predefined topology and do not support changes (e.g., partiality, the interaction of multiple independent components).

In the computer graphics literature, researchers have developed interpolation approaches for mesh representations~\cite{sorkine2007rigid, eisenberger2021neuromorph,baek2015isometric}. 
These often require a dense, exact point-to-point correspondence between respective frames~\cite{cao2024motion2vecsets, cao2024spectral, eisenberger2021neuromorph}, which is usually unpractical and rare in real-world applications. Also, such methods rely on a predefined topology and do not support changes (\eg, partiality, the interaction of multiple independent components). Moreover, the recovered interpolation is defined only on the mesh surface, which limits the applicability to other data forms.

% The recent advent of neural implicit fields \RM{cit.} opened investigations toward more flexible solutions. These methods convert the start and final input meshes or point clouds into implicit representations and recover the intermediate frames by optimization, promoting physically motivated properties \RM{cit.}. The theoretical advantage comes from the topological flexibility of implicit representations \RM{cit.}. In practice, all these methods rely again on a quite strong assumption of a ground-truth dense point-to-point correspondence between the frames, which requires solving for the topological changes in advance. Also, the use of implicit representation makes it often difficult to rely on data priors \RM{and no previous methods incorporate this in their pipeline}.

The recent advent of neural implicit fields~\cite{gropp2020implicit, sang2023weight, sitzmann2019siren, haerenstam2024diffcd} opened the door to more flexible solutions. These methods convert the start and final meshes or point clouds into implicit representations and recover the intermediate frames by either latent space optimization~\cite{Novello2023neural, liu2022learning} or deformation modeling~\cite{anonymous2024implicit, yang2021geometry}. 
The theoretical advantage comes from the topological flexibility of implicit representations~\cite{sdf}. However, the latent space-based methods generally do not consider the physical properties of the recovered intermediate shapes and therefore fail to produce reasonable interpolations such as rigid movements~\cite{Novello2023neural, liu2022learning}. 
% However, these methods generally do not consider the physical properties of the recovered intermediate shapes, and therefore fail to produce reasonable interpolations such as movements or rigid deformations~\cite{Novello2023neural, liu2022learning} 
Some other methods propose physical constraints during optimization~\cite{anonymous2024implicit, yang2021geometry} but they either assume ground truth correspondences~\cite{anonymous2024implicit}
% \fb{if we discuss the method here, we need to provide an anonymous pdf in the supp mat}
or user-defined handle points~\cite{yang2021geometry}, which makes it fail on complicated deformation or non-isometric deformation.~\cref{tab:summary} summarizes the strengths and limitations of different methods. 
\input{tex_figure/table_summary}

% Similar to the recent \cite{anonymous2024implicit}, our method relies on training an implicit neural representation, together with a velocity field parametrized by time. But instead of posing this as an optimization that overfits two keyframes, we phrase it as training on a shape collection. This lets us learn a much richer latent representation that also enables interpolation and extrapolation of new, unseen dynamics. Also, we introduce two novel losses that minimize distortion and stretching of level set deformations. Combining these two elements lets us release the assumption of a dense ground-truth point-to-point correspondence. For the first time, we actually show results starting from correspondence obtained by unprecise shape matching and registation pipelines. We do not only show better results, surpassing the SoTA methods even when they are framed to overfit a specific pair of frames, but we also demonstrate the usefulness of our method with several real-world applications, such as Kinect point cloud interpolation from human-motion interaction sequences, real captures upsampling partial supervision, and sequence extrapolation.
In this work, we address the challenging task of recovering motion between sparse keyframe shapes, relying only on coarse and incomplete correspondences. Our method begins by establishing correspondences through a matching module, followed by representing the shapes with an implicit field and modeling deformation via a velocity field. We introduce two novel loss functions to minimize distortion and stretching, ensuring physically plausible deformations. Our approach encodes shapes in a latent space, enabling both sequence representation and extrapolation of new dynamics. 

For the first time, we present results that begin with imprecise correspondences obtained from standard shape matching and registration pipelines and even not always spatially aligned with the input points \eg, real-world data. Our method not only outperforms state-of-the-art approaches, even when they are designed to overfit specific frame pairs, but also demonstrates versatility in real-world applications, including Kinect point cloud interpolation for human-motion interaction sequences, upsampling of real captures with partial supervision, and sequence extrapolation, as shown in~\cref{fig:teaser}.
In summary, our contributions are:
\begin{itemize}
    \item A data-driven framework for 3D shape interpolation that merely requires an estimated (noisy and incomplete) correspondence, and for the first time demonstrates applicability to real data such as noisy and partial point clouds.
    \item The derivation of two losses to prevent distortion and stretching in implicit representation, promoting desirable physical properties on the interpolated sequence.
    \item Experimental results confirming state-of-the-art performance on shape interpolation and the applicability to challenging downstream tasks like temporal super-resolution and action extrapolation.
\end{itemize}
Our code will be released for future research.


% Goal: The world is dynamic. We want our algorithms to reason about it and infer its logic starting from just sparse, discrete set observations. 
% Problems: 
% \begin{itemize}

%    \item Dealing with sparse and noisy observations lies at the heart of Computer Vision. Often, such observations are just sparse points, which may change over time with chaotic patterns, like noise (e.g., Kinect). \RM{refer to works that address similar problems in different domains}
%    \item Even with the best manual intervention, obtaining accurate annotation is challenging, time-consuming, and an approximation
%    \item Mesh-based methods limitations: Use surface to regularize, but cannot handle the change of topologies, not suitable for real-world applications. \RM{add citations}
%    \item Implicit methods limitations: implicit-based approaches struggle to keep consistency. Difficult to define ...
%    \item Especially \cite{anonymous2024implicit}: formulate the interpolation between frames as an optimization, showing promising results. However, it has many shortcomings: it relies on GT correspondence, which is unrealistic for many real cases (often not available). It requires solving a costly optimization for every pair of frames, making it difficult to scale. It has many artifacts, cannot hold large pose changes, \dots
 
% \end{itemize}

% Solution:
% Our idea (contributions) are:
% \begin{itemize}
%     \item to train a single network on a dataset. 
%     \item to do not rely on any GT correspondence but use SoTA methods to estimate it
%     \item to add further regularizations
% \end{itemize}

% We show:
% \begin{itemize}
%     \item better performance \RM{Define comparisons}
%     \item Interesting applications: Real sequences upsampling, new sequences interpolation, \dots
% \end{itemize}
% \cite{anonymous2024implicit}

