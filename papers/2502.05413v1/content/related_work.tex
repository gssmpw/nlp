\section{Related Work}
\paragraph{Anomaly Diagnosis in Distributed Training. }

Anomaly diagnosis in large-scale distributed deep learning training tasks has consistently been a hot research focus\cite{jiangMegaScaleScaling, wuFALCONPinpointing, dongBoostingLargescale, peng2018optimus, haider2011fault, chen2020elastic}. Megascale~\cite{jiangMegaScaleScaling} only focuses on LLM training tasks based on Megatron-LM. It identifies network-related hardware and software issues in the training process by conducting intra-host network tests and NCCL tests. Falcon~\cite{wuFALCONPinpointing} detects prolonged iterations using the Bayesian Online Change-Point Detection algorithm.
% Then, it briefly pauses the training job to run benchmarking tests that validate link communication performance across training workers. 
C4D~\cite{dongBoostingLargescale} modifies the Collective Communication Library to collect message statistics, such as sizes and durations of transfers, to identify the performance bottlenecks. However, these approaches primarily address communication-related performance issues and fail to encompass the anomalies across the LLM training stack.
Additionally, they depend heavily on a single parallel backbone, Megatron, which limits their generality.
Meanwhile, many researches\cite{peng2018optimus, haider2011fault, chen2020elastic} focus on task recovery. These approaches are orthogonal to \sysname{}, which could seamlessly integrate with \sysname{}.

\paragraph{Anomaly Diagnosis in Large-scale Datacenter. }

Many research efforts\cite{bergerTriangulatingPython, wangDiagnosingApplicationnetwork,yangAAsclepiusMonitoring , han2021depth, wangZeroOverhead} focus on anomaly diagnosis at different levels of the datacenter, including runtime, network, and storage.
SCALENE\cite{bergerTriangulatingPython} introduces an algorithm to assist Python programmers in optimizing their code by distinguishing between inefficient Python execution and efficient native execution.
AND\cite{wangDiagnosingApplicationnetwork} is a unified application-network diagnosing system that leverages a single metric, TCP retransmissions (TCP retx), to identify network anomalies in cloud-native scenarios.
AAsclepius\cite{yangAAsclepiusMonitoring} proposes a PathDebugging technique to trace fault linkages between the middle network and autonomous systems.
Researchers~\cite{han2021depth} from Alibaba analyze four key factors that impact SSD failure correlations: drive models, lithography, age, and capacity.
As these works address anomaly problems in specific scenarios, they are unable to resolve the challenges targeted by \sysname{} in large-scale distributed LLM training.