\section{\sysname{} Design}
\begin{figure}
    \centering
    \includegraphics[width=0.83\linewidth]{figure/1-overview.pdf}
    \caption{Architecture overview of \sysname{}.}
    \label{fig:overview}
    \vspace{-4mm}
\end{figure}

% \sysname{} also could  the training infrastructure unifies all correlated teams

In this paper, we propose \sysname{}, a holistic and real-time diagnostic framework that identifies anomalies in large-scale training with low overhead and pinpoints their corresponding root causes.
\sysname{} is designed and implemented following three principles.
\begin{itemize}
[leftmargin=*,topsep=0.2em,itemsep=-0.2em]
    \item \sysname{} should be lightweight enough. In this case, it could run as a long-term diagnostic mechanism without compromising the training performance at any scale.   
    \item \sysname{} should cover enough runtime information. In this case, it could identify the attribution precisely with detailed analysis when encountering anomalies.
    \item \sysname{} should be backbone-agnostic. In this case, it is sufficiently extensible to function as a cluster-wide solution for anomaly diagnostics, regardless of the backbones employed.
\end{itemize}


\paragraph{Architecture overview.}

\autoref{fig:overview} illustrates the architecture of \sysname{}, which is deployed in Ant Group’s large-scale training cluster. \sysname{} is composed of two components: the tracing daemon and the diagnostic engine. 

By automatically attaching a tracing daemon to each training process in LLM training jobs, \sysname{} enables a framework-agnostic and lightweight tracing mechanism.
Specifically, the tracing daemon instruments only key code segments at the level of Python and C++ runtime, focusing on carefully selected Python APIs and GPU kernels.
During instrumentation, events are injected to measure the latencies of these code segments.
This approach draws on our experience hosting various large-scale LLM training jobs, targeting critical paths that commonly impact training efficiency.

Then, the timing data collected by the daemons is transmitted to the diagnostic engine for holistic anomaly diagnostics. The engine employs a fast hang-error diagnostic method and leverages novel aggregated metrics to effectively identify slowdowns.
The aggregated metrics encompass both macro-level metrics, such as training throughput, and micro-level metrics, including issue latency distribution of GPU kernels. 
Once the diagnostic engine identifies errors and slowdowns, the issues are routed to attribution teams, enabling swift resolution.

% \weihao{add a paragraph to emphasize \sysname{}'s necessity.}

% \autoref{fig:overview} illustrates the architecture of \sysname{}, as deployed in \groupname{}’s large-scale training clusters.
% \sysname{} employs a framework-agnostic and lightweight tracing mechanism, automatically attaching a tracing daemon to each training process in large-scale LLM training jobs.
% These daemons selectively inject events into key code segments, ensuring precise monitoring with minimal interference to the training process and low memory overhead for logging.
% The timing metrics collected by the daemons are transmitted to an diagnostic engine for real-time anomaly detection.
% The engine employs a fast hang-error diagnosis method and introduces novel aggregated metrics to effectively identify slowdowns. These diagnostics cover both macro metrics, such as training throughput, and micro-level information, including intra-kernel execution states.
% Detected errors and slowdowns are then routed to attribution teams, facilitating swift resolution and improving the overall training efficiency within \groupname{}.
