\section{Related Work}
\paragraph{Long Video Generation.} 
The training dynamics and the sampling methodology in this work are inspired by works like Diffusion Forcing ____, Rolling Diffusion Models ____ and AR-Diffusion ____. The main motivation behind these works is to unify the benefits of autoregression and full sequence diffusion by applying token-specific noise levels during training, which allows the model to generate future frames without fully denoising past frames in a sequence. ____ is a similar work that prescribes a progressive sampling schedule for increased smoothness of transitions between generation windows. FIFO-Diffusion is a training-free inference approach for infinite text-to-video generation that uses a similar progressive denoising schedule and latent partitioning to reduce the training-inference gap with pre-trained video diffusion models. Other methods like ____ and ____ use context frame conditioning similar to our method, but do not focus on long video generation. The closest to our work is ____, who also employ a masking-based design to generate arbitrary-length videos autoregressively. There are two key differences in our approach: We do not condition frame generation on any previous ground truth frames during training, but adopt a frame-level masking approach that is more flexible. We also employ confidence-based MGM-style sampling, which lets us sample entire training windows in very few sampling steps, whereas ____ employs MAR-style ____ sampling that requires a higher amount of sampling steps per individual frame and does not use vector quantization.
\vspace{-10pt}

\paragraph{Discrete Representations in Video Generation.}
There are several previous works that investigate the use of discrete representations for video diffusion. MaskGIT ____ is a generative transformer that uses a bidirectional transformer decoder to predict randomly masked tokens in an input sequence of image patches. This idea is extended to videos in MAGVIT ____, which tokenizes video pixel space inputs into spatial-temporal visual tokens and uses a masked auto-regressive approach to predict masked input tokens. Similar approaches like Muse ____ and MAGVIT-v2____ have shown promise in scaling up image and video generation tasks, but suffer from training instabilities. Latte ____ is a latent diffusion transformer model that uses a pre-trained VAE-based tokenizer to reduce the dimensions of frame sequences as well as a mixture of spatial and temporal attention blocks designed to decompose spatial and temporal dimensions of input sequences. We adapt this backbone to handle frame-level timestep conditioning to denoise frame sequences with independent masking levels. Unlike previous discrete methods____ that do not explicitly consider frame dependence in the noise schedule, we investigate how combining multiple sampling styles and leveraging guidance from previously generated frames can yield an efficient and flexible long-video generation paradigm.

\paragraph{Discrete Flow Matching.}
Flow matching ____ is an emerging generative modeling paradigm that generalizes common formulations of diffusion models and offers more freedom in the choice of the source distribution. Flow matching models have seen wide adoption in speech ____, image generation ____, super-resolution ____, depth estimation ____ and video generation ____, but their application in high-dimensional discrete domains is still limited. Discrete flow matching ____ addresses this limitation, introducing a novel discrete flow paradigm designed for discrete data generation. Building on this, ____ validates the efficacy of discrete flow matching in the image domain and bridges the connection between Discrete Diffusion and Masked Generative Models ____. %
In contrast, we explore vectorizing timesteps across frames for memory-efficient long-video generation with improved extrapolation to long sampling horizons while also analyzing the impact of sampling styles on video quality.