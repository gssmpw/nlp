\section{Related Work}
\subsection{Vertical Federated Learning}
Vertical Federated Learning (VFL) enables collaborative training across organizations with vertically partitioned features. Early VFL frameworks focused on simple client-side models such as logistic regression and linear models**Konecny et al., "Federated Optimization: Distributed Model Fusion via Local Solvers"**, where clients computed local gradients for global aggregation. These methods prioritized simplicity, but lacked expressiveness for complex tasks. To address this limitation, larger client-side models like deep neural networks (DNNs) were adopted**McMahan et al., "Communication-Efficient Learning of Deep Networks from Decentralized Data"**. Studies have demonstrated that these larger client‐side models can be more effective than classical methods**Konecny et al., "Federated Optimization: Distributed Model Fusion via Local Solvers"**. However, larger models requires higher computation capability and VRAM cost, which calls for computation and memory efficient methods.

In an effort to reduce communication cost, several communication-efficient VFL methods were proposed. One way of reducing communication overhead is by multiple local updates. **Konecny et al., "Federated Optimization: Distributed Model Fusion via Local Solvers"** introduced FedBCD, a federated stochastic block coordinate descent method, which allows clients to perform multiple updates before synchronization. Similarly, {\tt Flex-VFL}**Li et al., "Flexible Vertical Federated Learning for Heterogeneous Networks"**, a flexible strategy offering varying local update counts per party, constrained by a communication timeout. {\tt VIMADMM}**Konecny et al., "Federated Optimization: Distributed Model Fusion via Local Solvers"** adopted an ADMM-based approach to enable multiple local updates in VFL.
All these methods effectively reduce the number of round-trip communications in each iteration. On the other hand, Asynchronous VFL methods (e.g., {\tt FDML}**Li et al., "Federated Distributed Multi-Agent Learning for Resource Management"**, {\tt VAFL}**Mohri et al., "Data-Efficient Algorithms for Decentralized Federated Learning"**) decouple coordination, allowing clients to update models independently. While asynchronous methods risk staleness, they significantly improve scalability in cross-silo deployments. However, in first-order methods, the backward pass typically imposes communication overhead comparable to the forward pass. In contrast, our ZO-based approach significantly reduces the cost associated with backward propagation.
% \subsection{Privacy-Preserving VFL with Differential Privacy}  

Privacy guarantees are critical for VFL adoption. Some VFL architectures use crypto-based privacy-preserving techniques such as Homomorphic Encryption (HE)**Liu et al., "Secure Multi-Party Computation via Homomorphic Encryption"**, but lack formal assurances, while DP provides rigorous mathematical protection. Key DP-based methods include {\tt VAFL}**Mohri et al., "Data-Efficient Algorithms for Decentralized Federated Learning"**, which injects Gaussian noise into client embeddings during forward propagation to achieve Gaussian DP, and {\tt VIMADMM}**Konecny et al., "Federated Optimization: Distributed Model Fusion via Local Solvers"** which perturbs linear model parameters with bounded sensitivity, ensuring DP guarantees for convex settings.

\subsection{Zeroth-Order Optimization in VFL}  
Recent research has explored Zeroth‐Order(ZO) Optimization within VFL to accommodate clients whose models are non‐differentiable and to reduce gradient leakage. Early work like {\tt ZOO-VFL}**Mohri et al., "Data-Efficient Algorithms for Decentralized Federated Learning"** adopted a naive ZO approach throughout VFL training but provided no DP guarantees. {\tt VFL-CZOFO}**Konecny et al., "Federated Optimization: Distributed Model Fusion via Local Solvers"** introduced a cascaded hybrid optimization method, combining zeroth-order and first-order updates, which leveraged intrinsic noise from ZO for limited privacy. However, its DP level was not adjustable, often resulting in insufficient protection.

More recently, {\tt MeZO}**Ding et al., "Memory-Efficient Zero-Order Optimization for Decentralized Federated Learning"** proposed a memory-efficient ZO algorithm. Building upon these ideas, {\tt DPZero}**Wu et al., "Private Zeroth-Order Optimizations for Decentralized Machine Learning"**, and {\tt DPZO}**Xie et al., "Differentially Private Zeroth-Order Optimization for Federated Learning"** introduced private ZO variants offering baseline privacy features. In this work, we adopt the memory-efficient design of {\tt MeZO}. In addition to previous attempts to combine ZO Optimization with VFL, we integrate controllable DP into our ZO framework, which requires significantly less memory footprint. 

\begin{figure*}[t]
\centering
\includegraphics[width=0.98\linewidth]{images/DP_visuallize.pdf}
    \caption{
    An illustration of the training procedure of {\tt DPZV}. The communication between the server and clients follows an asymmetric process: at each global iteration $t$, feature embeddings are uploaded once, while the server performs model updates and broadcasts ZO information to the client with DP guarantees for total $K$ iterations. This asymmetric communication update is a key design that enables memory-efficient fast convergence for our method.
    }
    \label{fig:visualize}
\end{figure*}