%%%%%%%% ICML 2025 EXAMPLE LATEX SUBMISSION FILE %%%%%%%%%%%%%%%%%

\documentclass{article}

% Recommended, but optional, packages for figures and better typesetting:
\usepackage{microtype}
\usepackage{graphicx}
\usepackage{subfigure}
\usepackage{bm}
\usepackage{booktabs} % for professional tables
\usepackage{multirow}
% hyperref makes hyperlinks in the resulting PDF.
% If your build breaks (sometimes temporarily if a hyperlink spans a page)
% please comment out the following usepackage line and replace
% \usepackage{icml2025} with \usepackage[nohyperref]{icml2025} above.
\usepackage{hyperref}


% Attempt to make hyperref and algorithmic work together better:
\newcommand{\theHalgorithm}{\arabic{algorithm}}

% Use the following line for the initial blind version submitted for review:
% \usepackage{icml2025}

% If accepted, instead use the following line for the camera-ready submission:
\usepackage[accepted]{icml2025}

% For theorems and such
\usepackage{amsmath}
\usepackage{amssymb}
\usepackage{mathtools}
\usepackage{amsthm}
\usepackage{subcaption}
\usepackage{makecell}

% if you use cleveref..
\usepackage[capitalize,noabbrev]{cleveref}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% THEOREMS
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\theoremstyle{plain}
\newtheorem{theorem}{Theorem}[section]
\newtheorem{proposition}[theorem]{Proposition}
\newtheorem{lemma}[theorem]{Lemma}
\newtheorem{corollary}[theorem]{Corollary}
\theoremstyle{definition}
\newtheorem{definition}[theorem]{Definition}
\newtheorem{assumption}[theorem]{Assumption}
\theoremstyle{remark}
\newtheorem{remark}[theorem]{Remark}

% Todonotes is useful during development; simply uncomment the next line
%    and comment out the line below the next line to turn off comments
%\usepackage[disable,textsize=tiny]{todonotes}
\usepackage[textsize=tiny]{todonotes}

\newcommand{\red}[1]{\textcolor{red}{#1}}
\newcommand{\blue}[1]{\textcolor{blue}{#1}}
\newcommand{\orange}[1]{\textcolor{orange}{#1}}

\newcommand\zh[1]{\textcolor{orange}{[zengh: #1]}}

% The \icmltitle you define below is probably too long as a header.
% Therefore, a short form for the running title is supplied here:
\icmltitlerunning{Exploring Imbalanced Annotations for Effective In-Context Learning}
\newcommand\HW[1]{\textcolor{blue}{[Hongxin: #1]}}


\begin{document}

\twocolumn[
\icmltitle{Exploring Imbalanced Annotations for Effective In-Context Learning}

% It is OKAY to include author information, even for blind
% submissions: the style file will automatically remove it for you
% unless you've provided the [accepted] option to the icml2025
% package.

% List of affiliations: The first argument should be a (short)
% identifier you will use later to specify author affiliations
% Academic affiliations should list Department, University, City, Region, Country
% Industry affiliations should list Company, City, Region, Country

% You can specify symbols, otherwise they are numbered in order.
% Ideally, you should not use this facility. Affiliations will be numbered
% in order of appearance and this is the preferred way.
\icmlsetsymbol{equal}{*}
\icmlsetsymbol{icmlWorkDone}{†}

\begin{icmlauthorlist}
\icmlauthor{Hongfu Gao}{equal,school1,school2}
\icmlauthor{Feipeng Zhang}{school2}
\icmlauthor{Hao Zeng}{school1}
\icmlauthor{Deyu Meng}{school3}
\icmlauthor{Bingyi Jing}{school1}
\icmlauthor{Hongxin Wei}{school1}
\end{icmlauthorlist}

\icmlaffiliation{school1}{Department of Statistics and Data Science, Southern University of Science and Technology}
\icmlaffiliation{school2}{School of Economics and Finance, Xi’an Jiaotong University}
\icmlaffiliation{school3}{School of Mathematics and Statistics, Xi'an Jiaotong University}

\icmlcorrespondingauthor{Hongxin Wei}{weihx@sustech.edu.cn}
% \icmlcorrespondingauthor{Firstname2 Lastname2}{first2.last2@www.uk}

% You may provide any keywords that you
% find helpful for describing your paper; these are used to populate
% the "keywords" metadata in the PDF but will not be shown in the document
\icmlkeywords{Machine Learning, ICML}

\vskip 0.3in
]


% this must go after the closing bracket ] following \twocolumn[ ...

% This command actually creates the footnote in the first column
% listing the affiliations and the copyright notice.
% The command takes one argument, which is text to display at the start of the footnote.
% The \icmlEqualContribution command is standard text for equal contribution.
% Remove it (just {}) if you do not need this facility.

% \printAffiliationsAndNotice{}  % leave blank if no need to mention equal contribution
\printAffiliationsAndNotice{\icmlEqualContribution} % otherwise use the standard text.

\begin{abstract}
Large language models (LLMs) have shown impressive performance on downstream tasks through in-context learning (ICL), which heavily relies on the demonstrations selected from annotated datasets. 
Existing selection methods may hinge on the distribution of annotated datasets, which can often be long-tailed in real-world scenarios. 
In this work, we show that imbalanced class distributions in annotated datasets significantly degrade the performance of ICL across various tasks and selection methods.
Moreover, traditional rebalance methods fail to ameliorate the issue of class imbalance in ICL. 
Our method is motivated by decomposing the distributional differences between annotated and test datasets into two-component weights: class-wise weights and conditional bias.
The key idea behind our method is to estimate the conditional bias by minimizing the empirical error on a balanced validation dataset and to employ the two-component weights to modify the original scoring functions during selection.
Our approach can prevent selecting too many demonstrations from a single class while preserving the effectiveness of the original selection methods. 
Extensive experiments demonstrate the effectiveness of our method, improving the average accuracy by up to 5.46 on common benchmarks with imbalanced datasets.
\end{abstract}


\section{Introduction}
In-context learning (ICL) has been a remarkable capability of Large Language Models (LLMs), enabling them to perform downstream tasks by simply conditioning on a few task demonstrations. \citep{brown2020language}. 
ICL consistently outperforms zero-shot inference across various tasks without needing parameter updates, positioning it as a strong alternative to supervised fine-tuning (SFT) \citep{mosbach-etal-2023-shot,panwar2024incontext}. 
In particular, previous studies typically focus on designing methods for demonstration selection from high-quality annotated datasets \citep{liu-etal-2022-makes, baldassini2024makes, wang-etal-2024-bayesian}.
The effectiveness of these selection algorithms may hinge on the distribution of annotated datasets, which can often be long-tailed in real-world scenarios \citep{wei2022open, de2024survey} — certain classes are underrepresented (see Figure~\ref{figure:1}).
Thus, it is of great importance to investigate how such imbalances affect ICL's performance.
% numerous previous studies have introduced various approaches to improve ICL's performance by selecting demonstrations from an annotated dataset that has the same class prior distribution as the test dataset \HW{Do they have the hypothesis?}\citep{baldassini2024makes,liu-etal-2022-makes,su2023selective, wang-etal-2024-bayesian,Ye2023DPP}.
% However, real-world datasets often exhibit a long-tail distribution, where only a few classes (known as head classes) have an adequate number, whereas the rest of the classes (known as tail classes) are infrequent  \citep{de2024survey,shi2023re, wei2022open}. 
% It is still mysterious how demonstrations selected from imbalanced annotated dataset affect the ICL's performance. 


\begin{figure}[t]
\centering % 确保整个figure*环境中的内容居中  
{\includegraphics[width=0.49\textwidth]{Figure/Figure1.pdf}} % 
\caption{\textbf{An example of imbalanced dataset.} In Emotion \citep{saravia-etal-2018-carer},  a few sentiments make a large contribution and data tend to show a long-tailed distribution.  For example, ``joy`` and ``sadness`` are head classes, while most other classes, such as ``love`` and ``surprise``, are tail classes.}
\label{figure:1}
\end{figure}

In this work, we present the first study on the impact of long-tailed distribution in annotated datasets on in-context learning.
First, we theoretically show that the class prior distribution affects the prediction of ICL.
Empirically, we also find that imbalanced class distributions in annotated datasets significantly degrade the performance of ICL across various tasks and selection methods (refer to Figure~\ref{figure:2}).
Moreover, traditional rebalance methods not only fail to ameliorate but, in some cases, exacerbate the issue of class imbalance in ICL.
This motivates us to develop a universal method that consistently improves ICL's performance in the presence of imbalanced annotated datasets.

% We use Bayes’ theorem to derive that ICL becomes unreliable when there is a large
% discrepancy between the class priors of annotated and test distributions. 
% We empirical find that demonstrations selected from a long-tail annotated dataset significantly degrade ICL's performance on various tasks (see Figure \ref{figure:2}).  
% Moreover, some classical rebalance methods (i.e.,  over-sampling \citep{chawla2002smote}, under-sampling \citep{liu2008exploratory} and stratified sampling \citep{vilarino2005experiments}) cannot mitigate the negative effect of imbalanced annotated dataset for most downstream tasks. 
% This motivates our method, which can universally improve the robustness of existing selection methods for ICL in the presence of long-tail annotated dataset.


% One simple and intuitive approach to deal with the long-tailed problem is data-balancing (i.e.,  over-sampling \citep{chawla2002smote}, under-sampling \citep{liu2008exploratory}, stratified sampling \citep{vilarino2005experiments} and re-weighting \citep{cui2019class}), which simply provides a class-balancing weight for each candidates during selection. Unfortunately, we find that these traditional data-balancing methods have limited effectiveness for in-context learning (ICL) on most long-tail datasets (see Figure \ref{figure:3}).  To explain this phenomenon, we decompose  joint probability distributions between  annotated dataset and  test dataset into two components: class-wise weights, which inherits its effectiveness from the classic class-wise weightsing $P(Y)$ used in various applications, and conditional bias, which measures the difference in conditional probability $P(X|Y)$ between the annotated dataset and the test dataset. We empirically show that the assumption on which the above methods rely—that the annotated dataset and test datasets share the same class-conditioned distribution—is not valid.


In this paper,  we show that the issue of imbalanced annotated datasets can be mitigated by applying class weighting to the original scoring functions during selection.
Our method is motivated by accounting for the differences between annotated and test distributions using two-component weights: class-wise weights, which assesses the difference between class prior distributions, and conditional bias, which measures the bias of class-wise weights due to different conditional distributions.
Therefore, our key idea is to employ the two-component weights to rectify the original scoring functions during selection. Specifically, we employ effective number \citep{cui2019class} as class-wise weights and estimate conditional bias by minimizing the empirical error of a balanced validation set. 
We then employ the two-component weights to modify the original scoring functions during selection.  
In effect, our approach can prevent selecting too many demonstrations from a single class while preserving the effectiveness of the original selection methods. 



% In this paper, our key idea is to verify the existence of conditional bias and employ an adjusted class-wise weights to rectify the original scoring functions during selection, which universally enhances the performance of existing selection methods with imbalanced annotated datasets. 
% Specifically, we conduct a balanced validation dataset, estimate the conditional bias by minimizing the empirical error of the balanced validation dataset, and employ an adjusted class-wise weights to modify the original scoring functions during selection.  
% In effect, our approach can prevent selecting too many demonstrations from a single class while preserving the effectiveness of the original selection methods. 
% In this way, we ensure the diversity and relevancy of demonstrations, thereby improving the performance of in-context learning against imbalanced annotated datasets.



% The long-tail challenge is essentially a mismatch problem of distribution between the annotated dataset and the test dataset. Our method's key idea is to decompose the mismatch problem into class-wise differences and the conditional bias between annotated and test datasets. This can be achieved by constructing a balanced validation set from the annotated dataset and using it to guide the search for the conditional bias that leads to the best performance of ICL.

% In effect, our method can prevent too many selected demonstrations belonging to one class while preserving the effectiveness of the original selection methods.

To verify the effectiveness of our method, we conduct extensive evaluations on seven different downstream datasets, including Amazon \citep{marc_reviews}, AgNews, Yelp and Yahoo \citep{zhang2015character}, Emotion \citep{saravia-etal-2018-carer} NQ \citep{kwiatkowski-etal-2019-natural} and CodeSearchNet \citep{husain1909evaluating}. The results demonstrate that our method can largely improve the performance of ICL with the imbalanced annotated datasets. For example, on four classification tasks (Amazon \citep{marc_reviews}, AgNews, Yelp and Yahoo \citep{zhang2015character}) with 100 imbalance ratio, our method improves the test accuracy from 37.83$\%$ to 43.29$\%$,  – a significant direct improvement of \textbf{5.46}$\%$. Moreover, our approach can generalize to generation tasks to improve ICL's performance with imbalanced annotated datasets. The code and datasets are available in the supplementary material.

Our contributions are summarized as follows:

\begin{enumerate}
    \item We find that imbalanced class distributions in annotated datasets significantly degrade the ICL's performance. We also show that classical rebalance methods fail to ameliorate the imbalanced problems of ICL.
    \item We propose a simple and effective method to enhance ICL's performance with imbalanced annotated datasets. The key idea is to estimate the conditional bias and employ the two-component weights to modify the original scoring functions during selection.
    \item We empirically show that our method can improve the performance of existing selection methods across various imbalance ratios. Meanwhile, we also validate the effectiveness of our method on generation tasks.
\end{enumerate}


\section{Preliminary}
\subsection{In-context learning}
    In the context of large language models (LLMs), in-context learning (ICL) aims to generate text outputs $\mathrm{\mathbf{y}}=(y_1,...,y_{|\mathrm{\mathbf{y}}|})$ (i.e., token sequences) conditioned on input $\mathrm{\mathbf{x}}=(x_1,...,x_{|\mathrm{\mathbf{x}}|})$ and context $\mathrm{\mathbf{C}}_K$.
    % Given large language models (LLMs), in-context learning (ICL) generate text outputs $\mathrm{\mathbf{y}}=(y_1,...,y_{|\mathrm{\mathbf{y}}|})$ (i.e., token sequences) conditioned on input $\mathrm{\mathbf{x}}=(x_1,...,x_{|\mathrm{\mathbf{x}}|})$ and context $\mathrm{\mathbf{C}}_K$.
    %\{\mathrm{\mathbf{c}}_i\}^K_{i=1}
    In particular, the context $\mathrm{\mathbf{C}}_K=\{(\mathrm{\mathbf{x}}_i,\mathrm{\mathbf{y}}_i)\}^K_{i=1}$ comprises $K$ task demonstrations (e.g. input-output pairs) selected from a large annotated dataset with $N$ examples $\mathcal{D}_c = \{(\mathrm{\mathbf{x}}_i,\mathrm{\mathbf{y}}_i)\}^N_{i=1}$. 
    Let $f_\theta(\mathrm{\mathbf{C}}_K, \cdot)$ be the ICL model with demonstrations $\mathrm{\mathbf{C}}_K$, using the LLM $f$ parameterized by $\boldsymbol{\theta}$.
    Given a test input $\mathrm{\mathbf{x}}_t$, we generate the output $\mathrm{\mathbf{y}}_t$ via the ICL model as:
\begin{equation}
\label{formula:1}
    \mathrm{\mathbf{y}}_t = f_\theta(\mathrm{\mathbf{C}}_K, \mathrm{\mathbf{x}}_t) =  \mathop{\arg\max}\limits_{\mathrm{\mathbf{y}}} P_\theta  \left(\mathrm{\mathbf{y}}_t \vert \mathrm{\mathbf{C}}_K,\mathrm{\mathbf{x}}_t \right). 
\end{equation}
To improve the performance of ICL, previous studies \citep{liu-etal-2022-makes, peng-etal-2024-revisiting, rubin-etal-2022-learning, Ye2023DPP} designed various scoring functions $s(\cdot, \cdot)$ to select demonstrations $\mathrm{\mathbf{C}}_K$ from an annotated dataset $\mathcal{D}_c$ as:
\begin{align}
\label{formula:2}
\mathrm{\mathbf{C}}_K = \operatorname{Top}_K \left( \left\{ s(\mathrm{\mathbf{c}}_i,\mathrm{\mathbf{x}}_t) \right\}_{i=1}^N \right). 
\end{align}
where $\mathrm{\mathbf{c}}_i$ denotes the $i$-th demonstration in the annotated dataset $\mathcal{D}_c$ and $ \operatorname{Top}_K (\cdot)$ denotes the selection of the $K$ highest-ranked demonstrations from $\mathcal{D}_c$ based on the given scoring function \(s(\cdot, \cdot)\).
For example, Top$K$ \citep{liu-etal-2022-makes} utilizes the cosine similarity distance between $\mathrm{\mathbf{x}}_t$ and $\mathrm{\mathbf{c}}_i$ to select the closest demonstrations.

% proposes to select the closest examples to the test input in the embedding space based on cosine similarity score between $\mathrm{\mathbf{x}}_t$ and examples $\mathrm{\mathbf{c}}_i$ from the dataset $\mathcal{D}_c$. 

While current selection methods showcase promising performance on common-used benchmarks, their effectiveness may hinge on the distribution of annotation datasets $\mathcal{D}_c$. 
For example, ICL might struggle to make accurate predictions for underrepresented groups within these annotated datasets. Real-world datasets (see Figure~\ref{figure:1}), however, often exhibit an imbalanced distribution, with a few `head' classes containing many examples and numerous `tail' classes having significantly fewer examples. The concern may lead to challenges in effectively employing in-context learning in real-world applications. We proceed with a formulation of the imbalanced setting of ICL.

% For example, for the emotion classification task \citep{saravia-etal-2018-carer}, Joy, Sadness, Anger, Fear, Love, and Surprise account for 33$\%$, 29$\%$, 13$\%$, 12$\%$, 8$\%$, and 4$\%$, respectively. For the Code Summarization task \citep{husain1909evaluating}, the proportion of JavaScript, Java, Python, PHP, Go, Ruby are 29$\%$, 24$\%$, 18$\%$, 15$\%$, 11$\%$ and 3$\%$,  respectively.

% These existing selection methods mainly focus on how to select demonstrations from a high-quality annotated dataset but don't consider the distribution of the annotated dataset $\mathcal{D}_c$. 
% However, due to human preference and annotated cost, collecting a large-scale dataset with a well-balanced distribution is challenging and expensive.
% Real-world datasets (see Figure~\ref{figure:1}) often exhibit an imbalanced distribution, wherein a few ‘head’ classes contain a large number of examples, while numerous other classes, referred to as ‘tail’ classes, contain significantly fewer examples.
% This motivates us to analyze the issue of imbalanced dataset in ICL.

% % \zh{use citep style}

% \zh{Is \(C\) is a number? may use \(|\mathcal{D}|\) as the size of set.}
% \zh{Maybe better if use two inputs version of topK\( \operatorname{Top}_K(\mathcal{D}, \left\{ s(\mathrm{\mathbf{c}}_i,\mathrm{\mathbf{x}}_t) \right\}_{i=1}^|\mathcal{D})\)}
% where we use $ \operatorname{Top}_K$ to select the top $K$ examples ranked by given score \(s(\cdot, \cdot)\) from the annotated dataset $\mathcal{D}_c$. For example, \citet{liu-etal-2022-makes} propose to select the closest examples to the test input in the embedding space based on cosine similarity score between $\mathrm{\mathbf{x}}_t$ and examples $\mathrm{\mathbf{c}}_i$ from the annotated dataset. 
% \zh{use citep style}

% Notably, the existing demonstration selection approaches assume that the demonstration distribution  $P_c (X,Y)$ is equal to the test distribution $P_t (X,Y)$. 

% \HW{describe the selection methods. If this is the average performance, please write it as average accuracy across * selection methods.}

\subsection{Setting of imbalanced ICL}

In this work, we begin with the class-imbalance setting of in-context learning in classification tasks\footnote{In addition to labels, the imbalance can also occur among various groups, particularly in generation tasks. We extend the imbalanced setting to generation tasks in Section~\ref{sec:discussion}.
}, where the label space $\mathcal{Y} := \{1, \ldots, K\}$. Let $n_j$ denote the number of instances in class $j$, where $j \in \mathcal{Y}$. In the class-imbalanced setting, the annotated dataset $\mathcal{D}_c$ has an unequal distribution of instances across different classes in $\mathcal{Y}$. In particular, the class distribution is such that: $n_j \ll n_K$, for some $j,k \in \mathcal{Y}$, where $j \neq K$. We quantify the imbalance ratio as $\phi = \frac{\min_{j \in \mathcal{Y}} n_j}{\max_{j \in \mathcal{Y}} n_j}$, and a higher imbalance ratio indicates a more severe class imbalance in the dataset. 



% In this work, we consider a multi-class problem, where the label can be categorized into $k$ classes. 
% We assume that the class prior of the test distribution is balanced ($\max P_t(Y) = \min P_t(Y)$) but  annotated dataset $\mathcal{D}_c$ is imbalanced ($\max P_c(Y) > \min P_c(Y)$). 
% There is a large discrepancy of the class priors between annotated and test distributions. Conditioned on such demonstrations $\mathbf{C}_K$ selected from an imbalanced dataset $\mathcal{D}_c$, the output via ICL is generated as
% \begin{equation}
% \label{formula:3}
% \mathrm{\mathbf{\widetilde{y}}}_t = f_\theta(\mathrm{\mathbf{C}}_K, \mathrm{\mathbf{x}}_t) =\mathop{\arg\max}\limits_{\mathrm{\mathbf{y}}} P_\theta  \left(\mathrm{\mathbf{y}}_t \vert \mathrm{\mathbf{C}}_K,\mathrm{\mathbf{x}}_t \right). 
% \end{equation}
In the real world, class-imbalanced distributions are frequently observed in various datasets. 
For instance, in the Emotion dataset \citep{saravia-etal-2018-carer}, the `Joy' class constitutes 33\% of the data, whereas the `Surprise' class makes up only 4\%.
The CodeSearchNet dataset \citep{husain1909evaluating} includes 29\% JavaScript code while Ruby accounts for just 3\%, demonstrating the significant imbalance issue among programming languages.
Therefore, it is crucial to ensure the ICL performance across all classes under the class-imbalanced setting in $\mathcal{D}_c$.
In what follows, we analyze the effect of class imbalance on ICL from theoretical and empirical perspectives.
% Notably, the existing selection approaches as mentioned in Eq. (\ref{formula:2}) choose demonstrations based on an assumption that the distribution of annotated dataset $P_c (X,Y)$ is equal to the test distribution $P_t (X,Y)$.  It is still mysterious how an imbalanced annotated dataset affects the performance of ICL on a balanced test dataset.


% In real life, due to human preference or annotation costs, there exists a distribution of random variables that is more extensive than the balance distribution, i.e. the long-tailed distribution. It is mainly reflected in the fact that a small number of individuals usually make a large number of contributions, where a few classes occupy the majority of the dataset (i.e. head classes), while the majority of classes have very few data examples (i.e. tail classes). For example, for Emotion \citep{saravia-etal-2018-carer},  Joy, Sadness, Anger, Fear, Love, and Surprise account for 33.5$\%$, 29.2$\%$, 13.5$\%$, 12.1$\%$, 8.2$\%$, and 3.6$\%$, respectively.

% We assume that demonstrations are selected from an annotated dataset $\mathcal{D}_c$ with a long-tailed distribution, where the class prior distribution $P_c(Y)$ is highly skewed so that many underrepresented classes have a very low probability of occurrence. Specifically, we define the imbalance ratio as $\phi = \frac{\max_\mathrm{\mathbf{y}}(\mathrm{\mathbf{y}}_c)}{\min_\mathrm{\mathbf{y}}(\mathrm{\mathbf{y}}_c)}$ to indicate the skewness of data. Classes with high  $P_c(Y)$ are referred to as head classes, while others are referred to as tail classes. However, the distribution of the test dataset is usually balanced (i.e., a uniform distribution over labels). There is a large discrepancy of class priors between annotated dataset $P_c(Y)$ and test dataset $P_t(Y)$, i.e., $P_c(Y) \neq P_t(Y)$.


\section{Pilot study}
% In this section, we first provide both theoretical and empirical analysis to investigate the impact of imbalanced datasets on the performance of in-context learning. Moreover, we also investigate whether some classical rebalance methods can effectively improve the performance of ICL under the setting of long-tailed distribution.

\subsection{The effect of imbalanced dataset}
\subsubsection{Theoretical Analysis} 
We start by presenting Remark \ref{remark:1} \citep{xie2022an}, which demonstrates that ICL allows LLMs $f$ parameterized by $\theta$ to learn the context-generated distribution from demonstrations $\mathrm{\mathbf{C}}_K$, such that the model's prediction approximates the output $\mathrm{\mathbf{y}}$ generated by the data generated model $\theta^*$ given the test input $\mathrm{\mathbf{x}}$.

\begin{remark}
\label{remark:1} Assume both demonstrations $\mathrm{\mathbf{C}}_K$ and test sample $(\mathrm{\mathbf{x}}_t, \mathrm{\mathbf{y}}_t)$ are generated by data generated model $\theta^*$. Given such demonstrations $\mathrm{\mathbf{C}}_K$, in-context learning allows large language models to generate output $\mathrm{\mathbf{y}}$ as follows:
\begin{equation}
     f_\theta(\mathrm{\mathbf{C}}_K, \mathrm{\mathbf{x}}_t) \approx \mathop{\arg\max}\limits_{\mathrm{\mathbf{y}}}  P_{\theta^*} (\mathrm{\mathbf{y}}_t|\mathrm{\mathbf{x}}_t). \nonumber
\end{equation}
where large language models $\theta$ to generate correct output $\mathrm{\mathbf{y}}_t$ following context-generated distribution. 
\end{remark}



From a Bayesian perspective, the prediction of ICL is generally made as follows:
\begin{equation}
\label{formula:4}
    f_\theta(\mathrm{\mathbf{C}}_K, \mathrm{\mathbf{x}}_t) \approx   \mathop{\arg\max}\limits_{\mathrm{\mathbf{y}}}  P_{\theta^*} (\mathrm{\mathbf{x}}_t|\mathrm{\mathbf{y}}_t)  P_{\theta^*} (\mathrm{\mathbf{y}}_t). 
\end{equation}
where $P_{\theta^*} (\mathrm{\mathbf{x}}_c)$ and $P_{\theta^*} (\mathrm{\mathbf{y}}_t)$ represent $P_{\theta^*} (X=\mathrm{\mathbf{x}}_t)$ and $P_{\theta^*} (Y=\mathrm{\mathbf{y}}_t)$, respectively.


The Eq. \ref{formula:4} indicates that the class prior distribution $P(Y)$ affects the prediction of ICL.
in real-world tasks, the class prior of the test distribution is usually balanced  (i.e., a uniform distribution over labels), while the annotated dataset exhibits a long-tailed class distribution. Formally, we have $P_c(Y=j) \neq P_t(Y=j)$ for any class $j \in \mathcal{Y}$.
The predicted posterior probability in Eq. \ref{formula:4} becomes unreliable when there is a large discrepancy of class priors between annotated dataset $P_c(Y)$ and test dataset $P_t(Y)$. 



\subsubsection{Empirical Analysis} 
\begin{figure}[t]
\centering % 确保整个figure*环境中的内容居中  
\subfigure[]{\includegraphics[width=0.23\textwidth]{Figure/Figure2.pdf}} % 
\subfigure[]{\includegraphics[width=0.23\textwidth]{Figure/Figure29.pdf}} %  
\caption{
The effect of class imbalance on ICL across six existing selection methods ($K=8$) using OPT-6.7B \citep{zhang2022opt} with various imbalance ratios. (a) Average accuracy of four classification tasks. (b) Comparison of average accuracy for head and tail classes of AgNews.}
\label{figure:2}
\end{figure}
We also conduct experiments on various downstream tasks, including Amazon \citep{marc_reviews}, AgNews,   Yahoo and Yelp \citep{zhang2015character}, NQ \citep{kwiatkowski-etal-2019-natural} and CodeSearchNet \citep{husain1909evaluating}). 
To simulate the class-imbalanced setting, we generate imbalanced datasets with a pre-defined probability (e.g.,  $\phi$ = 0, 10, 50, 100).
We evaluate the performance of ICL on a balanced test dataset with three LLMs, including Llama3-8B \citep{llama3modelcard}, Mistral-7B \citep{jiang2023mistral} and OPT-6.7B \citep{zhang2022opt}.  
Furthermore, we also compare the performance of ICL with various set sizes and selection methods, including Random \citep{min-etal-2022-metaicl}, TopK \citep{liu-etal-2022-makes}, DPP \citep{Ye2023DPP}, VoteK \citep{su2023selective}, ConE \citep{peng-etal-2024-revisiting}, ByCS \citep{wang-etal-2024-bayesian}. 


\textbf{Imbalanced dataset significantly degrades ICL's performance.} Figure \ref{figure:2} (a) shows that selecting demonstrations from an imbalanced dataset significantly deteriorates ICL's performance across various imbalance ratios. 
Specifically, the average accuracy using OPT-6.7B \citep{zhang2022opt} drops approximately \textbf{20}$\%$ for four different classification tasks. 
Furthermore, we also investigate the effect of an imbalanced dataset on each class. For example, for AgNews, \textit{World} and \textit{Sport} are head classes and \textit{Business} and \textit{Sci/Tech} are tail classes. 
Figure \ref{figure:2} (b) shows that the decreasing trend in overall accuracy is mainly due to the reduction in accuracy of the tail classes. 
Additionally, the negative effect of an imbalanced dataset is also observed on different model architectures, including Llama3-8B \citep{llama3modelcard} and Mistral-7B \citep{jiang2023mistral} as shown in Appendix \ref{appendix_different_model}.  
Imbalanced datasets also hurt the ICL's performance on generation tasks as shown in Section \ref{section:generation}.

\textbf{The impact of demonstration number and demonstration selection.}  
Here, we also present the ICL's performance under various numbers of subsets (i.e., $K$) and the approach of selection, as shown in Table \ref{table:1}. 
We find that, under the imbalanced ICL settings, selecting a larger set of demonstrations does not completely mitigate the issue of imbalanced datasets. 
Additionally, the advantages of those powerful selection methods (i.e., TopK \citep{liu-etal-2022-makes} and DPP \citep{ye-etal-2023-complementary}) are neutralized in the presence of an imbalanced dataset. 
For example,  the ICL's performance using the TopK \citep{liu-etal-2022-makes} method decreases from 49.92 to 39.62, a reduction of approximately \textbf{25}$\%$. In conclusion, a larger set of demonstrations or the existing selection methods cannot mitigate the issue of imbalanced datasets.


Through the above analysis, we find that imbalanced datasets significantly hurt the ICL's performance.
Next, we will verify whether employing some classical rebalance methods can mitigate the issue of imbalanced datasets.

\subsection{The failure of classical rebalance methods}
Rebalance methods are widely used to deal with the issue of imbalanced annotated datasets.
One such approach is to address the bias towards the minor class by adjusting the annotated dataset. 
In this section, we use four different rebalance methods, including over-sampling \citep{chawla2002smote}, under-sampling \citep{liu2008exploratory}, stratified sampling \citep{vilarino2005experiments} and re-weighting \citep{cui2019class}. 
Specifically, given an annotated dataset with $N$ examples, we select demonstrations as follows:
\begin{align}
    \mathrm{\mathbf{C}}_K & =  \operatorname{Top}_K \left(\left\{ s(\mathrm{\mathbf{c}}^{'}_i,\mathrm{\mathbf{x}}_t) \right\}_{i=1}^{N^{'}}\right),\label{formula:5}\\
    \mathrm{\mathbf{C}}_K & = \cup_{i=1}^k\operatorname{top}_{\frac{K}{k}} \left(\left\{ s(\mathrm{\mathbf{c}}_j,\mathrm{\mathbf{x}}_t) \right\}_{j=1}^{n_i}\right),\label{formula:6}\\
    \mathrm{\mathbf{C}}_K & =  \operatorname{Top}_K \left(\left\{w_i\times s(\mathrm{\mathbf{c}}_i,\mathrm{\mathbf{x}}_t) \right\}_{i=1}^N\right).\label{formula:7}
\end{align}
For the over-sampling method in Eq. \ref{formula:5}, we select demonstrations $\mathbf{c}^{'}_i$ from an over-sampling dataset with $N^{'}$ examples where we repeat the examples of tail classes until their number matches that of head classes. 
The under-sampling method in Eq. \ref{formula:5} randomly trims examples belonging to head classes until the number of examples in head classes is equal to that of tail classes.
Suppose $n_j$ represents the size of the class to which $i$-th example belongs, stratified sampling in Eq. \ref{formula:6} selects $\frac{K}{k}$ demonstrations from each class with $n_j$ examples.
For the re-weighting method in Eq. \ref{formula:7}, according to the classical reweighing method for fine-tuning \citep{cui2019class}, we select the top $K$ examples based on the scoring functions $s(\mathrm{\mathbf{c}}_i,\mathrm{\mathbf{x}}_t)$ multiplied by the class-wise weights $w_j$ where $w_j = (1-\alpha)/(1-\alpha^{n_j})$ and $\alpha = (N-1)/N$.



We conduct experiments to verify the effectiveness of these rebalance strategies across various downstream tasks within the framework of ICL.  The results in Figure \ref{figure:3} show that employing over-sampling and under-sampling can improve  ICL's performance when annotated datasets exhibit long-tail distributions.  However, these rebalance strategies can only achieve limited effects for most downstream tasks, indicating poor generalization to ICL. Specifically, the limited effect of the oversampling method \citep{chawla2002smote} suggests that repeated examples do not provide additional information to LLMs to enhance the performance of ICL.  Under-sampling \citep{liu2008exploratory} may remove key information of head classes. Notably, the failure of the stratified sampling method in ICL is mainly due to the decreased performance of selection methods such as TopK \citep{liu-etal-2022-makes} and DPP \citep{Ye2023DPP}. The detailed results of generation tasks have been reported in Section \ref{section:generation}.

Our empirical analysis shows that existing rebalance methods cannot effectively address the issue of imbalanced datasets for ICL. This motivates us to design new rebalance methods for ICL that can universally enhance the performance of existing selection methods.
\begin{figure}[t]
\centering % 确保整个figure*环境中的内容居中  
{\includegraphics[width=0.495\textwidth]{Figure/Figure4.pdf}} % 
\caption{
 Comparison of performances on four classification tasks with different imbalance ratios using four different rebalance methods. We report the average accuracy (\%) of six existing selection methods ($K=8$) using OPT-6.7B \citep{zhang2022opt}.}
\label{figure:3}
\end{figure}


\section{Methodology}
In this section, we first decompose  the distributional differences between annotated and test datasets to explain why classical rebalance methods fail for ICL. In light of this, we propose a novel method to enhance the performance of ICL with imbalanced annotated datasets. 

\subsection{Decomposition of the distributional differences}
We aim to design a suitable demonstration selection method, which is used to select demonstrations for the given test input $\mathrm{\mathbf{x}}_t$, to minimize expected $\operatorname{Error}$ value across all classes:
\begin{small} 
\begin{align}
    \operatorname{Error} = \mathbb{E}_{P_t(\mathrm{\mathbf{x}},\mathrm{\mathbf{y}})}M\left[ f_\theta\left( \operatorname{Top}_K \left( \left\{ s(\mathrm{\mathbf{c}}_i,\mathrm{\mathbf{x}}_t) \right\}_{i=1}^N \right), \mathrm{\mathbf{x}}_t\right), \mathrm{\mathbf{y}}_t \right], \nonumber
\end{align}
\end{small} 
where $M[\cdot, \cdot]$ measures the mismatched degree between real output and the generated output conditioned on demonstrations $\mathrm{\mathbf{C}}_K$ and test input $\mathrm{\mathbf{x}}_t$. For example, for classification tasks, $M[\cdot, \cdot]$ denotes error rate. For question answering tasks, $M[\cdot, \cdot]$ represents the negative value of EM score.


We apply the importance sampling trick to connect the expected $\operatorname{Error}$ and decompose the distributional differences into two-component weights as follows:
\begin{small} 
% \begin{equation}
\begin{align}
    &\mathbb{E}_{P_t(\mathrm{\mathbf{x}},\mathrm{\mathbf{y}})}M\left[ f_\theta\left( \operatorname{Top}_K \left( \left\{ s(\mathrm{\mathbf{c}}_i,\mathrm{\mathbf{x}}_t) \right\}_{i=1}^N \right), \mathrm{\mathbf{x}}_t\right), \mathrm{\mathbf{y}}_t \right], \nonumber \\
    &=\mathbb{E}_{P_c(\mathrm{\mathbf{x}},\mathrm{\mathbf{y}})}M\left[ f_\theta\left( \operatorname{Top}_K \left( \left\{ s(\mathrm{\mathbf{c}}_i,\mathrm{\mathbf{x}}_t) \right\}_{i=1}^N \right), \mathrm{\mathbf{x}}_t\right), \mathrm{\mathbf{y}}_t \right] \frac{P_t(\mathrm{\mathbf{x}},\mathrm{\mathbf{y}})}{P_c(\mathrm{\mathbf{x}},\mathrm{\mathbf{y}})}, \nonumber \\
    &=\mathbb{E}_{P_c(\mathrm{\mathbf{x}},\mathrm{\mathbf{y}})}M\left[ f_\theta\left( \operatorname{Top}_K \left( \left\{ s(\mathrm{\mathbf{c}}_i,\mathrm{\mathbf{x}}_t) \right\}_{i=1}^N \right), \mathrm{\mathbf{x}}_t\right), \mathrm{\mathbf{y}}_t \right] (\bm{w}+\bm{\beta}). \nonumber 
    % \label{formula:8}
\end{align}
% \end{equation} 
\end{small}
where  $P_t(\mathrm{\mathbf{x}},\mathrm{\mathbf{y}})/ P_c(\mathrm{\mathbf{x}},\mathrm{\mathbf{y}})$ measures the distributional difference, $\bm{w} = P_t(Y)/P_c(Y)$ denotes class-wise weights and $\bm{\beta} = \frac{P_t(\mathrm{\mathbf{y}})}{P_c(\mathrm{\mathbf{y}})} \left( \frac{P_t(\mathrm{\mathbf{x}}|\mathrm{\mathbf{y}})}{P_c(\mathrm{\mathbf{x}}|\mathrm{\mathbf{y}})}-1 \right)$ is conditional bias.
% Next, we provide the detailed definition of conditional bias $\bm{\beta}$.
The detailed proof can be found in Appendix \ref{proof:2}. 


Notably, these existing rebalance methods (i.e. re-weighting \citep{cui2019class}) assume a shared conditional distribution between annotated and test datasets $P_c(X|Y) = P_t(X|Y)$  and only focus on how to use the class-wise weights $\bm{w}$ to process imbalanced datasets. However, in the real world, the conditional distribution $P(X|Y)$ is also prone to changes from the annotated dataset to the test dataset due to target shift and concept shift, especially in imbalanced datasets \citep{gopalan2013unsupervised, jamal2020rethinking, gu2022tackling}.

We also conduct experiments to verify whether there is a shared conditional distribution between annotated and test datasets $P_c(X|Y) = P_t(X|Y)$ in imbalanced datasets. Specifically, for each class, we firstly transform text input from each class into bag-of-words representation, employ the Latent Dirichlet Allocation (LDA) model to derive the document-topic distributions and then compute Kullback-Leibler (KL) divergence between annotated conditional distribution $P_c(X|Y)$ and test conditional distribution $P_t(X|Y)$.
For example,  as shown in Figure \ref{figure:4}, the KL divergence between annotated and test datasets is unequal to zero and the assumption that $\beta = 0$ is difficult to be satisfied.


In this paper, we relax the above assumption and allow a different conditional distribution of annotated and test datasets (e.g., $P_c(X|Y) \neq P_t(X|Y)$). However, directly computing the conditional bias $\bm{\beta}$ is non-trivial as real conditional distributions of annotated and test datasets are unknown. To circumvent the issue, we aim to design an effective method to estimate the conditional bias $\bm{\beta}$.
\subsection{Modeling the conditional bias $\bm{\beta}$}
Motivated by the previous analysis, we employ two-component weights, including class-wise weights $\bm{w}$ and conditional bias $\bm{\beta}$, to modify the original scoring functions during selection.
We let the class-wise weights resemble the empirically successful design in the literature. 
Our key idea is to estimate conditional bias $\bm{\beta}$ by achieving empirical $\operatorname{Error}$ minimization of a balanced validation set. 


% \subsection{The failure of classical rebalance methods}
\label{section:4.1}

\begin{figure}[t]
\centering % 确保整个figure*环境中的内容居中  
\subfigure[AgNews]{\includegraphics[width=0.23\textwidth]{Figure/Figure5.pdf}} % 
\subfigure[Amazon]{\includegraphics[width=0.23\textwidth]{Figure/Figure6.pdf}} %
\caption{The Kullback-Leibler (KL) divergence between $P_c(X|Y)$ and  $P_t(X|Y)$ for each class in the AgNews (a) and Amazon (b) datasets.}
\label{figure:4}
\end{figure}
\paragraph{Constructing balanced validation set}Given an imbalanced dataset $\mathcal{D}_c$ with $N$ examples,  the balanced validation set $\mathcal{D}_b$ is constructed by randomly selecting $n_b$ examples from $j$-class dataset $\mathcal{D}_{j}$ as follows:
\begin{align}
\label{formula:9}
    \mathcal{D}_b = \cup_{j=1}^k \left\{ \operatorname{RandomSample}(\mathcal{D}_{j}, n_b) \right\},
\end{align}
where $\operatorname{RandomSample}(\mathcal{D}_{j}, n_b)$ denotes randomly selecting $n_b$ examples from each class set $\mathcal{D}_{j}$. Notably, $n_b$ is constrained by the condition $n_b < \min(n_1,...,n_k)$. This process results in a validation set that is balanced across all classes, with each class contributing the same number of examples, similar to the composition of the test dataset. Meanwhile,  $\mathcal{D}_r$ denotes the imbalanced remaining dataset.

\begin{table*}[!t]
\caption{
Average test accuracy ($\%$) with standard deviation on four classification datasets with various imbalanced ratios (over 3 runs). The bold indicates the improved results by integrating our method.}
    \centering
    \resizebox{2\columnwidth}{!}{%
    \begin{tabular}{ccccccccc}
    \toprule
         $K$&  \multicolumn{4}{c}{8}&  \multicolumn{4}{c}{16}\\
\toprule
         \textbf{Imbalance Ratio}&  \textbf{0}&  \textbf{10}&  \textbf{50}&  \textbf{100} &  \textbf{0}&  \textbf{10}&  \textbf{50}& \textbf{100} \\
\midrule
Random&  32.63$\pm$0.73&  32.26$\pm$1.32&  30.91$\pm$1.20&  30.21$\pm$0.83
&  35.25$\pm$0.46&  36.17$\pm$0.91&  33.24$\pm$1.24& 
32.51$\pm$0.65
\\
 \textbf{+Ours}& 32.44$\pm$0.92& \textbf{36.66$\pm$1.05}& \textbf{36.45$\pm$1.26}& \textbf{37.63$\pm$1.79}
&34.68$\pm$0.53& 36.12$\pm$0.99& \textbf{38.74$\pm$1.36}&\textbf{40.32$\pm$1.79}
\\
 TopK& 49.90$\pm$0.05& 46.51$\pm$0.76& 41.51$\pm$1.11& 39.62$\pm$1.22
& 52.31$\pm$0.09& 48.18$\pm$0.98& 43.34$\pm$0.91&
40.95$\pm$0.61
\\
\textbf{+Ours}&49.75$\pm$0.41& \textbf{49.62$\pm$0.62}& \textbf{46.48$\pm$1.07}& \textbf{44.44$\pm$1.40}& 51.73$\pm$0.49& \textbf{51.19$\pm$1.08}& \textbf{48.21$\pm$1.01}&\textbf{45.52$\pm$1.40}\\
 DPP& 50.56$\pm$0.06& 46.59$\pm$0.79& 42.54$\pm$1.09& 40.26$\pm$1.22
& 53.66$\pm$0.15& 48.38$\pm$0.98& 43.53$\pm$0.91&
41.83$\pm$0.64
\\
\textbf{+Ours}& 50.36$\pm$0.31& \textbf{49.47$\pm$1.57}& \textbf{46.50$\pm$1.26}& \textbf{45.16$\pm$1.64}
& 52.84$\pm$0.27& \textbf{50.97$\pm$1.14}& \textbf{48.16$\pm$1.18}&\textbf{46.77$\pm$1.48}
\\
 VoteK& 48.69$\pm$0.14& 45.71$\pm$0.88& 41.51$\pm$1.13& 39.94$\pm$0.95
& 52.62$\pm$0.24& 48.02$\pm$0.71& 42.72$\pm$0.91&
40.57$\pm$0.60\\
  \textbf{+Ours}& 48.57$\pm$0.39&\textbf{ 48.21$\pm$0.97}& \textbf{46.39$\pm$1.23}& \textbf{44.77$\pm$1.27}
&52.62$\pm$0.44& \textbf{50.97$\pm$0.98}& \textbf{48.05$\pm$0.82}&\textbf{45.84$\pm$1.05}
\\
 ConE& 48.08$\pm$0.86& 44.55$\pm$1.51& 40.35$\pm$1.29& 38.03$\pm$1.31
& 51.18$\pm$0.58& 46.09$\pm$0.79& 41.30$\pm$0.63&38.92$\pm$0.72
\\
 \textbf{+Ours}& 48.51$\pm$0.70& \textbf{46.89$\pm$0.85}& \textbf{45.09$\pm$1.08}& \textbf{43.21$\pm$1.32}
& 50.95$\pm$0.46& \textbf{48.32$\pm$0.84}& \textbf{46.83$\pm$1.07}&\textbf{44.13$\pm$0.79}
\\
 ByDC& 50.07$\pm$0.45& 45.00$\pm$0.78& 41.10$\pm$1.23& 38.90$\pm$1.36& 53.15$\pm$0.44& 46.16$\pm$0.75& 41.90$\pm$0.76&38.92$\pm$0.62
\\
\textbf{+Ours}&  49.82$\pm$0.39&  \textbf{48.54$\pm$0.94}& \textbf{46.60$\pm$1.11}&  \textbf{44.52$\pm$1.05}
&  52.61$\pm$0.55&  \textbf{49.98$\pm$1.00}& \textbf{47.33$\pm$1.23}& \textbf{44.39$\pm$1.14}
\\\hline 
% \multirow{2}{*}{Average}&46.66$\pm$0.38&43.44$\pm$1.01&39.65$\pm$1.18&37.83$\pm$1.15
% &49.70$\pm$0.33&45.50$\pm$0.85&41.01$\pm$0.89& 38.95$\pm$0.64
% \\
% &46.58$\pm$0.52&\textbf{46.57$\pm$1.00}&\textbf{44.59$\pm$1.17}&\textbf{43.29$\pm$1.41}
% &49.24$\pm$0.46&\textbf{47.93$\pm$1.01}&\textbf{46.22$\pm$1.11}& \textbf{44.50$\pm$1.28}\\\hline
    \end{tabular}
    }
    \label{table:1}
\end{table*}

\paragraph{Bayesian optimizing conditional bias}
In practice, since the data distribution is unknown, we use empirical $\operatorname{Error}$ minimization of the balanced validation set $\mathcal{D}_b$ to achieve an empirical estimate of the underlying data distribution. 

Typically, we minimize the empirical $\operatorname{Error}$ as follows:
\begin{footnotesize}
\begin{align}
\label{formula:11}
\frac{1}{|\mathcal{D}_b|} \sum_{i=1}^{|\mathcal{D}_b|} M\left[ f_\theta\left( \operatorname{Top}_K \left( \{(w_i+\beta) \times s(\mathrm{\mathbf{c}}_i,\mathrm{\mathbf{x}}_b) \right\}_{i=1}^{|\mathcal{D}_r|}), \mathrm{\mathbf{x}}_b\right), \mathrm{\mathbf{y}}_b \right]. \nonumber
\end{align}
\end{footnotesize}
where we still use \textit{effective numbers} \citep{cui2019class} as class-wise weights where $w_i = (1-\alpha)/(1-\alpha^{n_j})$ and $\alpha = (N-1)/N$.
We estimate the conditional bias $\beta$ by employing a Bayesian optimizing framework, which is suitable for non-differentiable and black-box function optimization. 
In this way, the estimated conditional bias $\beta$ can be regarded as an approximation of the conditional bias between annotated and test datasets. 
We present our overall optimizing process in Appendix \ref{bayeopt}. 

\paragraph{Re-weighting with adjusted class-wise weights} We use existing selection methods to select a subset of candidates (e.g. $K^{'}$=100). We sort all candidates in increasing order by $(w_i+\beta) \times s(\mathrm{\mathbf{c}}_i,\mathrm{\mathbf{x}}_t)$ and obtain the indices for the sorted scores as $\mathcal{I}$. And we select these candidates with low-ranking examples in the sorted list $\mathcal{I}$: 
\begin{gather}
    g(\mathrm{\mathbf{c}}_i)  = \mathrm{1}\left( \operatorname{Loc}(\mathrm{\mathbf{c}}_i, \mathcal{I}) \leq K \right),\\ \mathcal{I} = \operatorname{argsort} \left\{  (w_i+\beta)s(\mathrm{\mathbf{c}}_i,\mathrm{\mathbf{x}}_t))\right\}_{i=1}^{K^{'}}.
\end{gather}
where $ \mathrm{1}$ is the indicator function and $\operatorname{Loc}(\mathrm{\mathbf{c}}_i, \mathcal{I})$ return the index of $\mathrm{\mathbf{c}}_i$ in the sorted list $\mathcal{I}$. After this, we establish the final demonstration set for in-context learning. Noticeably, our method offers several compelling advantages:
\begin{itemize}
    \item \textbf{Flexible}: Our method can be easily incorporated into existing selection methods under the class-imbalanced setting in $\mathcal{D}_c$.
    \item  \textbf{Easy to use}: Our method does not require heavy hyperparameter tuning, as it is insensitive to balance set $\mathcal{D}_b$ or class-wise weights $\bm{w}$ (see Figure \ref{figure:5} (a) and (b)). 
    \item  \textbf{Model-agnostic}: Our method requires access only to the model outputs and integrates effortlessly with any LLMs  (see Figure \ref{figure:5} (c) and (d)).
\end{itemize}




\vspace{-0.2cm}
\section{Experiments}
\subsection{Experimental Setup}
\textbf{Datasets and Evaluation} For our evaluations,  we verify the effectiveness of our method on four benchmark datasets, including Sentiment Classification (Amazon \citep{marc_reviews}, Yelp \citep{zhang2015character}) and  Topic Classification (AgNews, Yahoo \citep{zhang2015character}). Due to limited space, these tasks' input/output, statistics and split are reported in the Appendix \ref{appendix:experimental_setting}. To simulate the issue of imbalance data, we generate imbalanced datasetss with pre-defined imbalance ratios $\phi$ (e.g., 0, 10, 50, 100) and we evaluate the performance of ICL on another corresponding class-balanced test dataset. We report average accuracy (\%) with standard deviation (over 3 runs).



\textbf{Models and Baselines} We utilize various large language models, including  Llama3-8B \citep{llama3modelcard}, Mistral-7B \citep{jiang2023mistral} and OPT-6.7B \citep{zhang2022opt}. We use Bert-base-uncased sentence encoder \citep{Bert} as the similarity tokenizer. We also conduct experiments with existing selection methods as baselines, including \textbf{Random} \citep{min-etal-2022-metaicl}, \textbf{TopK} \citep{liu-etal-2022-makes}, \textbf{DPP} \citep{Ye2023DPP}, \textbf{VoteK} \citep{su2023selective}, \textbf{ConE} \citep{peng-etal-2024-revisiting}, \textbf{ByCS} \citep{wang-etal-2024-bayesian}.  For hyperparameters, we set the size of the balanced validation set as $|\mathcal{D}_b| =100$ by default. The details of our experiments are presented in Appendix \ref{appendix:experimental_setting}.

\begin{figure*}[t]
\centering % 确保整个figure*环境中的内容居中  
\subfigure[]{\includegraphics[width=0.24\textwidth]{Figure/Figure7.pdf}} % 
\subfigure[]{\includegraphics[width=0.24\textwidth]{Figure/Figure8.pdf}} %
\subfigure[]{\includegraphics[width=0.24\textwidth]{Figure/Figure9.pdf}} % 
\subfigure[]{\includegraphics[width=0.24\textwidth]{Figure/Figure10.pdf}} %
\caption{ Results for different ablation studies. (a)  Ablation on the different balanced validation set sizes. (b) Ablation on the different class-wise weights (c) Ablation on the different open-sourced LLMs, including Llama3-8B and Mistral-7B. (d) Ablation on Closed-sourced LLM (GPT-3.5-Turbo).}
\label{figure:5}
\end{figure*}

\vspace{-0.2cm}
\subsection{Main Results} 
\textbf{Can our method improve the performance of existing selection methods?} Table \ref{table:1} presents the average test accuracy of in-context learning with different selection methods on four benchmark datasets using OPT-6.7B, under various imbalance ratios.
A salient observation is that our method drastically improves the performance of ICL with imbalanced annotated datasets. 
For example, for the 100 imbalance ratio, our method improves the average accuracy of six existing selection methods from 37.93 to 43.29 – a \textbf{5.46} of direct improvement.  
More importantly, we show that our method can boost performance for a wide range of selection methods, such as TopK and DPP.  
For example, we observe that, for the 100 imbalance ratio, the test accuracy of the TopK is improved to \textbf{4.57} when integrating our methods. 
Table \ref{table:1} also presents the results for different demonstration numbers $K$, suggesting that our method can consistently improve the performance of ICL against imbalanced datasets with varying demonstration numbers $K$. 
The detailed results are reported in Appendix \ref{appendix_more_results}.


\textbf{How does the balanced validation set affect the robustness of our method?} 
In Figure \ref{figure:5} (a), we ablate how the size of balanced validation set $\mathcal{D}_b$ affects the effectiveness of our method (cf. Eq. \ref{formula:9}). 
The \textit{baselines} indicates all candidate demonstrations are selected without our method. 
It’s noteworthy that our method shows robustness to the choice of the size of the balanced validation set $|\mathcal{D}_b|$. 
Even when we set $|\mathcal{D}_b| = 50$, it still yields significant improvements in ICL performance on four classification tasks across six selection methods against imbalanced datasets.
Due to space constraints, we only report the average results of multiple baselines on various downstream tasks.

\textbf{Is our method effective with different class-wise weights $\bm{w}$?} 
In the paper, we employ \textit{effective numbers} as class-wise weights $\bm{w}$, which have been confirmed to empirically successfully deal with imbalance problems in previous studies \citep{cui2019class,jamal2020rethinking}. 
We also verify whether the type of class-wise weights affects the performance of our methods. 
Specifically, we employ class frequency $w_j=\frac{n_j}{N}$ \citep{Kang2020Decoupling,shi2023re}  as an alternative class-wise weights to verify the effectiveness of our method. 
Our results in Figure \ref{figure:5} (b) show that our method can improve the ICL's performance across various imbalanced ratios and achieve similar accuracy to the effective numbers.


\textbf{Is our method effective with different model architectures?} 
To demonstrate that our proposed method is model-agnostic, we conduct experiments on diverse open-sourced LLMs (Llama3-8B \citep{llama3modelcard} and Mistral-7B \citep{jiang2023mistral}) and present the average results of four common benchmarks using the two LLMs in Figure \ref{figure:5} (c). 
From the results, we observe that our method consistently improves test performance on various downstream tasks when using different model architectures.
For instance, using our method boosts the test accuracy from 47.10 to 54.31, a 7.21 of direct improvement with a 100 imbalance ratio.
Therefore, our method can improve the performance of ICL using various open-source LLMs against imbalanced annotated datasets.
More details are presented in Appendix \ref{appendix_different_model2}.


\textbf{Is our method effective with closed-sourced LLMs?}
While our method has demonstrated strong promise in open-source LLMs, we also verify its effectiveness using closed-source models. 
Specifically, we tested our method on ChatGPT-3.5-Turbo across four selection methods (Random, TopK, DPP and VoteK) with various imbalance ratios.
Figure \ref{figure:5} (d) reports the average results for ChatGPT-3.5-Turbo, showing that imbalanced annotated datasets significantly hurt the ICL performance of closed-source LLMs when employing these existing selection methods.
After integrating our method, Figure \ref{figure:5} (d) also shows significant improvements in average test accuracy across four downstream tasks, indicating the effectiveness of our method in addressing imbalances in closed-source LLMs.


\textbf{Can our method improve real-world imbalanced dataset}
We verify the effectiveness of our method on a real-world imbalanced dataset. 
The Emotion \citep{saravia-etal-2018-carer} dataset has a long-tailed distribution (refer to Figure \ref{figure:1}).  Figure \ref{figure:a5} shown that our method consistently improves existing selection methods and outperforms existing rebalance methods, including over-sampling \citep{chawla2002smote}, under-sampling \citep{liu2008exploratory}, stratified sampling \citep{vilarino2005experiments}, and re-weighting \citep{cui2019class}. 
For example, with OPT-6.7B \citep{zhang2022opt}, using our method boosts the average accuracy of six selection methods from 21.22 to 23.36, a relative improvement of 10.08\%. 
These results verify that our method is effective in improving ICL's performance in real-world imbalanced scenarios.


\section{Discussion}\label{sec:discussion}

\subsection{Data imbalance in text generation tasks}
\label{section:generation}
Text generation, which is a common task in in-context learning, may also follow a long-tailed distribution.
To address this, we verify the effect of imbalanced annotated datasets and the effectiveness of the proposed method in text generation tasks. 
Specifically, we consider two generation tasks: Open-Domain Question-Answering (NQ \citep{kwiatkowski-etal-2019-natural}) and Code Summarization (CodeSearchNet \citep{husain1909evaluating}).
The NQ \citep{kwiatkowski-etal-2019-natural} dataset can be divided into five categories, including person (10.41$\%$), time (20.32$\%$), geography (9.02$\%$), culture (45.18$\%$), and professional knowledge (15.06$\%$).
We report the average EM score of NQ using six existing selection methods across various imbalance ratios in Table \ref{table:3}.  



Table \ref{table:3} demonstrates that imbalanced annotated dataset significantly hurt ICL's performance on generation tasks. 
Additionally, Table \ref{table:3} also confirms the ineffectiveness of classical data balancing methods, including over-sampling \citep{chawla2002smote}, under-sampling \citep{liu2008exploratory}, stratified sampling \citep{vilarino2005experiments}, and re-weighting \citep{cui2019class}. 
After integrating our method, the existing selection methods show significant improvements in inference performance, indicating the generalization of our method to text generation. 
For example, our method improves the average exact match score from 21.20 to 22.93, a notable improvement of 0.73 over six existing demonstration methods. 
The detailed results of CodeSearchNet \citep{husain1909evaluating} task are presented in Table \ref{table:a6}.
\begin{table}
\caption{The average EM score of NQ dataset across six selection methods with various imbalance ratios. Bold numbers are the best results.}
    \centering
    \begin{tabular}{ccccc}
    \toprule
         \textbf{Imbalance Ratio}&  \textbf{0}&  \textbf{10}&  \textbf{50}& \textbf{100}\\
    \midrule
         Baselines&  23.67&  22.47&  21.33& 21.20\\
 +Over-Sampling& 23.60& 22.53& 22.53&22.33\\
 +Under-Sampling& 23.60& 19.87& 18.47&17.80\\
 +Stratified-Sampling& 22.15& 20.60& 18.82&18.47\\
 +Re-Weighting& 23.33& 22.60& 20.47&20.20\\
         \textbf{+Ours}&  \textbf{24.00}&  \textbf{23.87}&  \textbf{23.00}& \textbf{22.93}\\
    \hline
    \end{tabular}
    \label{table:3}
\end{table}


\subsection{Does a larger dataset address the imbalance issue?}
\begin{table}
\caption{Average classification accuracy (\%) of Baselines / \textbf{+Ours} methods on the Yahoo dataset with various imbalance ratios. Bold numbers are superior results.}
    \centering
    \resizebox{1\columnwidth}{!}{%
    \begin{tabular}{cccc}
    \toprule
         \textbf{Imbalance Ratio}&  \textbf{10}& \textbf{50} &\textbf{100}
\\
    \midrule
         \multicolumn{4}{c}{Baseline/\textbf{+Ours}}\\\hline
 Random& 37.87/\textbf{38.07}& 36.20/\textbf{39.87}&33.13/\textbf{37.73}
\\
 TopK& 47.33/\textbf{48.87}&45.00/\textbf{47.67}&43.07/\textbf{47.87}
\\
 DPP& 49.60/\textbf{50.27}&48.00/\textbf{49.33}&44.47/\textbf{47.80}\\
 VoteK& 47.13/\textbf{47.80}&43.87/\textbf{47.47}&44.67/\textbf{47.73}
\\
 ConE& 47.53/\textbf{49.13}&45.27/\textbf{46.80}&
41.47/\textbf{45.53}
\\
         ByDC&  48.40/\textbf{49.33}& 44.27/\textbf{47.47}&42.17/\textbf{46.50}\\
    \hline
    Average& 46.64/\textbf{47.25}& 43.77/\textbf{46.44}&41.50/\textbf{45.53}\\ \hline
    \end{tabular}}
    \label{table:2}
\end{table}
While our analysis has shown that imbalanced annotated datasets negatively impact in-context learning by reducing the number of examples in tail classes, one might wonder \textit{if this negative effect is due to the reduced size of the dataset rather than a shift in class prior distribution}. 
To address this, we verify the negative impact of imbalanced annotated datasets and the effectiveness of the proposed method on such datasets with an increasing number of examples.
Specifically, we consider creating an imbalanced annotated dataset by increasing the number of examples in head classes while keeping the number of examples in tail classes constant. 
For example, in the case of Yahoo \citep{zhang2015character}, when the imbalance ratio $\phi = 0$, the number of annotated examples for each class remains 50.
When the imbalance ratio $\phi = 100$, the number of examples in the head classes is 5,000, but the number in the tail classes remains 50.
We report the test accuracy of Yahoo using OPT-6.7B with six existing selection methods.

Table \ref{table:2} presents that imbalanced datasets significantly hurt ICL's performance when more examples are added to the head classes while keeping the number of examples in the tail classes constant.
This illustrates that the decreasing trend in ICL's performance mainly depends on the class prior distribution of the annotated dataset.
Additionally, Table \ref{table:2} reports the limited effect of more powerful selection methods (e.g. TopK and DPP) against imbalanced annotated datasets.
Notably, after integrating our method, ICL significantly improved the inference performance.
For instance, for 100 imbalance ratio, our method outperforms the baselines by a large margin of 4.03$\%$, indicating the effectiveness of our method against imbalanced annotated datasets.


\section{Conclusion}
In this paper, we study the effect of the imbalanced annotated dataset on the performance of in-context learning (ICL).
Both our theoretical analysis and empirical investigations reveal that imbalanced annotated datasets significantly hurt the performance of ICL.
Meanwhile classical rebalance methods cannot effectively mitigate the imbalanced datasets. To address the issue, we introduce our method, a general strategy that can universally enhance the performance of ICL across various imbalanced ratios. 
Our method is motivated by decomposing the distributional differences between annotated and test datasets into class-wise weights and conditional bias.
Extensive experiments demonstrate that our method can improve the performance of existing selection methods of ICL across various imbalance ratios. 
Our approach is practical to use, as it is insensitive to the hyperparameters and integrates effortlessly with any LLMs.

\textbf{Limitations.} Our methods need to split a balanced validation dataset from imbalanced annotated datasets, and these methods require that the size of examples in tail classes cannot be too small. 
Furthermore, it might be challenging to estimate multiple parameters for the class-conditional biases using balanced datasets with limited size. It might be an interesting direction to explore how to model the bias in a more data-efficient manner.
\clearpage
\section*{Impact Statements}
This paper presents work whose goal is to advance the field of Machine Learning. There are many potential societal consequences of our work, none of which we feel must be specifically highlighted here.



% M&=\mathbb{E}_{P_t(\mathrm{\mathbf{x}},\mathrm{\mathbf{y}})}M\left[ f( \operatorname{Top}_K \left(\operatorname{Score}(\mathrm{\mathbf{c}}_i,\mathrm{\mathbf{x}}_t) \right), \mathrm{\mathbf{x}}_t, \theta), \mathrm{\mathbf{y}}_t \right] \nonumber \\
%  & =
 
% \section{Electronic Submission}
% \label{submission}

% Submission to ICML 2025 will be entirely electronic, via a website
% (not email). Information about the submission process and \LaTeX\ templates
% are available on the conference website at:
% \begin{center}
% \textbf{\texttt{http://icml.cc/}}
% \end{center}

% The guidelines below will be enforced for initial submissions and
% camera-ready copies. Here is a brief summary:
% \begin{itemize}
% \item Submissions must be in PDF\@. 
% \item If your paper has appendices, submit the appendix together with the main body and the references \textbf{as a single file}. Reviewers will not look for appendices as a separate PDF file. So if you submit such an extra file, reviewers will very likely miss it.
% \item Page limit: The main body of the paper has to be fitted to 8 pages, excluding references and appendices; the space for the latter two is not limited in pages, but the total file size may not exceed 10MB. For the final version of the paper, authors can add one extra page to the main body.
% \item \textbf{Do not include author information or acknowledgements} in your
%     initial submission.
% \item Your paper should be in \textbf{10 point Times font}.
% \item Make sure your PDF file only uses Type-1 fonts.
% \item Place figure captions \emph{under} the figure (and omit titles from inside
%     the graphic file itself). Place table captions \emph{over} the table.
% \item References must include page numbers whenever possible and be as complete
%     as possible. Place multiple citations in chronological order.
% \item Do not alter the style template; in particular, do not compress the paper
%     format by reducing the vertical spaces.
% \item Keep your abstract brief and self-contained, one paragraph and roughly
%     4--6 sentences. Gross violations will require correction at the
%     camera-ready phase. The title should have content words capitalized.
% \end{itemize}

% \subsection{Submitting Papers}

% \textbf{Anonymous Submission:} ICML uses double-blind review: no identifying
% author information may appear on the title page or in the paper
% itself. \cref{author info} gives further details.

% \medskip

% Authors must provide their manuscripts in \textbf{PDF} format.
% Furthermore, please make sure that files contain only embedded Type-1 fonts
% (e.g.,~using the program \texttt{pdffonts} in linux or using
% File/DocumentProperties/Fonts in Acrobat). Other fonts (like Type-3)
% might come from graphics files imported into the document.

% Authors using \textbf{Word} must convert their document to PDF\@. Most
% of the latest versions of Word have the facility to do this
% automatically. Submissions will not be accepted in Word format or any
% format other than PDF\@. Really. We're not joking. Don't send Word.

% Those who use \textbf{\LaTeX} should avoid including Type-3 fonts.
% Those using \texttt{latex} and \texttt{dvips} may need the following
% two commands:

% {\footnotesize
% \begin{verbatim}
% dvips -Ppdf -tletter -G0 -o paper.ps paper.dvi
% ps2pdf paper.ps
% \end{verbatim}}
% It is a zero following the ``-G'', which tells dvips to use
% the config.pdf file. Newer \TeX\ distributions don't always need this
% option.

% Using \texttt{pdflatex} rather than \texttt{latex}, often gives better
% results. This program avoids the Type-3 font problem, and supports more
% advanced features in the \texttt{microtype} package.

% \textbf{Graphics files} should be a reasonable size, and included from
% an appropriate format. Use vector formats (.eps/.pdf) for plots,
% lossless bitmap formats (.png) for raster graphics with sharp lines, and
% jpeg for photo-like images.

% The style file uses the \texttt{hyperref} package to make clickable
% links in documents. If this causes problems for you, add
% \texttt{nohyperref} as one of the options to the \texttt{icml2025}
% usepackage statement.


% \subsection{Submitting Final Camera-Ready Copy}

% The final versions of papers accepted for publication should follow the
% same format and naming convention as initial submissions, except that
% author information (names and affiliations) should be given. See
% \cref{final author} for formatting instructions.

% The footnote, ``Preliminary work. Under review by the International
% Conference on Machine Learning (ICML). Do not distribute.'' must be
% modified to ``\textit{Proceedings of the
% $\mathit{42}^{nd}$ International Conference on Machine Learning},
% Vancouver, Canada, PMLR 267, 2025.
% Copyright 2025 by the author(s).''

% For those using the \textbf{\LaTeX} style file, this change (and others) is
% handled automatically by simply changing
% $\mathtt{\backslash usepackage\{icml2025\}}$ to
% $$\mathtt{\backslash usepackage[accepted]\{icml2025\}}$$
% Authors using \textbf{Word} must edit the
% footnote on the first page of the document themselves.

% Camera-ready copies should have the title of the paper as running head
% on each page except the first one. The running title consists of a
% single line centered above a horizontal rule which is $1$~point thick.
% The running head should be centered, bold and in $9$~point type. The
% rule should be $10$~points above the main text. For those using the
% \textbf{\LaTeX} style file, the original title is automatically set as running
% head using the \texttt{fancyhdr} package which is included in the ICML
% 2025 style file package. In case that the original title exceeds the
% size restrictions, a shorter form can be supplied by using

% \verb|\icmltitlerunning{...}|

% just before $\mathtt{\backslash begin\{document\}}$.
% Authors using \textbf{Word} must edit the header of the document themselves.

% \section{Format of the Paper}

% All submissions must follow the specified format.

% \subsection{Dimensions}




% The text of the paper should be formatted in two columns, with an
% overall width of 6.75~inches, height of 9.0~inches, and 0.25~inches
% between the columns. The left margin should be 0.75~inches and the top
% margin 1.0~inch (2.54~cm). The right and bottom margins will depend on
% whether you print on US letter or A4 paper, but all final versions
% must be produced for US letter size.
% Do not write anything on the margins.

% The paper body should be set in 10~point type with a vertical spacing
% of 11~points. Please use Times typeface throughout the text.

% \subsection{Title}

% The paper title should be set in 14~point bold type and centered
% between two horizontal rules that are 1~point thick, with 1.0~inch
% between the top rule and the top edge of the page. Capitalize the
% first letter of content words and put the rest of the title in lower
% case.

% \subsection{Author Information for Submission}
% \label{author info}

% ICML uses double-blind review, so author information must not appear. If
% you are using \LaTeX\/ and the \texttt{icml2025.sty} file, use
% \verb+\icmlauthor{...}+ to specify authors and \verb+\icmlaffiliation{...}+ to specify affiliations. (Read the TeX code used to produce this document for an example usage.) The author information
% will not be printed unless \texttt{accepted} is passed as an argument to the
% style file.
% Submissions that include the author information will not
% be reviewed.

% \subsubsection{Self-Citations}

% If you are citing published papers for which you are an author, refer
% to yourself in the third person. In particular, do not use phrases
% that reveal your identity (e.g., ``in previous work \cite{langley00}, we
% have shown \ldots'').

% Do not anonymize citations in the reference section. The only exception are manuscripts that are
% not yet published (e.g., under submission). If you choose to refer to
% such unpublished manuscripts \cite{anonymous}, anonymized copies have
% to be submitted
% as Supplementary Material via OpenReview\@. However, keep in mind that an ICML
% paper should be self contained and should contain sufficient detail
% for the reviewers to evaluate the work. In particular, reviewers are
% not required to look at the Supplementary Material when writing their
% review (they are not required to look at more than the first $8$ pages of the submitted document).

% \subsubsection{Camera-Ready Author Information}
% \label{final author}

% If a paper is accepted, a final camera-ready copy must be prepared.
% %
% For camera-ready papers, author information should start 0.3~inches below the
% bottom rule surrounding the title. The authors' names should appear in 10~point
% bold type, in a row, separated by white space, and centered. Author names should
% not be broken across lines. Unbolded superscripted numbers, starting 1, should
% be used to refer to affiliations.

% Affiliations should be numbered in the order of appearance. A single footnote
% block of text should be used to list all the affiliations. (Academic
% affiliations should list Department, University, City, State/Region, Country.
% Similarly for industrial affiliations.)

% Each distinct affiliations should be listed once. If an author has multiple
% affiliations, multiple superscripts should be placed after the name, separated
% by thin spaces. If the authors would like to highlight equal contribution by
% multiple first authors, those authors should have an asterisk placed after their
% name in superscript, and the term ``\textsuperscript{*}Equal contribution"
% should be placed in the footnote block ahead of the list of affiliations. A
% list of corresponding authors and their emails (in the format Full Name
% \textless{}email@domain.com\textgreater{}) can follow the list of affiliations.
% Ideally only one or two names should be listed.

% A sample file with author names is included in the ICML2025 style file
% package. Turn on the \texttt{[accepted]} option to the stylefile to
% see the names rendered. All of the guidelines above are implemented
% by the \LaTeX\ style file.

% \subsection{Abstract}

% The paper abstract should begin in the left column, 0.4~inches below the final
% address. The heading `Abstract' should be centered, bold, and in 11~point type.
% The abstract body should use 10~point type, with a vertical spacing of
% 11~points, and should be indented 0.25~inches more than normal on left-hand and
% right-hand margins. Insert 0.4~inches of blank space after the body. Keep your
% abstract brief and self-contained, limiting it to one paragraph and roughly 4--6
% sentences. Gross violations will require correction at the camera-ready phase.

% \subsection{Partitioning the Text}

% You should organize your paper into sections and paragraphs to help
% readers place a structure on the material and understand its
% contributions.

% \subsubsection{Sections and Subsections}

% Section headings should be numbered, flush left, and set in 11~pt bold
% type with the content words capitalized. Leave 0.25~inches of space
% before the heading and 0.15~inches after the heading.

% Similarly, subsection headings should be numbered, flush left, and set
% in 10~pt bold type with the content words capitalized. Leave
% 0.2~inches of space before the heading and 0.13~inches afterward.

% Finally, subsubsection headings should be numbered, flush left, and
% set in 10~pt small caps with the content words capitalized. Leave
% 0.18~inches of space before the heading and 0.1~inches after the
% heading.

% Please use no more than three levels of headings.

% \subsubsection{Paragraphs and Footnotes}

% Within each section or subsection, you should further partition the
% paper into paragraphs. Do not indent the first line of a given
% paragraph, but insert a blank line between succeeding ones.

% You can use footnotes\footnote{Footnotes
% should be complete sentences.} to provide readers with additional
% information about a topic without interrupting the flow of the paper.
% Indicate footnotes with a number in the text where the point is most
% relevant. Place the footnote in 9~point type at the bottom of the
% column in which it appears. Precede the first footnote in a column
% with a horizontal rule of 0.8~inches.\footnote{Multiple footnotes can
% appear in each column, in the same order as they appear in the text,
% but spread them across columns and pages if possible.}

% \begin{figure}[ht]
% \vskip 0.2in
% \begin{center}
% \centerline{\includegraphics[width=\columnwidth]{icml_numpapers}}
% \caption{Historical locations and number of accepted papers for International
% Machine Learning Conferences (ICML 1993 -- ICML 2008) and International
% Workshops on Machine Learning (ML 1988 -- ML 1992). At the time this figure was
% produced, the number of accepted papers for ICML 2008 was unknown and instead
% estimated.}
% \label{icml-historical}
% \end{center}
% \vskip -0.2in
% \end{figure}

% \subsection{Figures}

% You may want to include figures in the paper to illustrate
% your approach and results. Such artwork should be centered,
% legible, and separated from the text. Lines should be dark and at
% least 0.5~points thick for purposes of reproduction, and text should
% not appear on a gray background.

% Label all distinct components of each figure. If the figure takes the
% form of a graph, then give a name for each axis and include a legend
% that briefly describes each curve. Do not include a title inside the
% figure; instead, the caption should serve this function.

% Number figures sequentially, placing the figure number and caption
% \emph{after} the graphics, with at least 0.1~inches of space before
% the caption and 0.1~inches after it, as in
% \cref{icml-historical}. The figure caption should be set in
% 9~point type and centered unless it runs two or more lines, in which
% case it should be flush left. You may float figures to the top or
% bottom of a column, and you may set wide figures across both columns
% (use the environment \texttt{figure*} in \LaTeX). Always place
% two-column figures at the top or bottom of the page.

% \subsection{Algorithms}

% If you are using \LaTeX, please use the ``algorithm'' and ``algorithmic''
% environments to format pseudocode. These require
% the corresponding stylefiles, algorithm.sty and
% algorithmic.sty, which are supplied with this package.
% \cref{alg:example} shows an example.

% \begin{algorithm}[tb]
%    \caption{Bubble Sort}
%    \label{alg:example}
% \begin{algorithmic}
%    \STATE {\bfseries Input:} data $x_i$, size $m$
%    \REPEAT
%    \STATE Initialize $noChange = true$.
%    \FOR{$i=1$ {\bfseries to} $m-1$}
%    \IF{$x_i > x_{i+1}$}
%    \STATE Swap $x_i$ and $x_{i+1}$
%    \STATE $noChange = false$
%    \ENDIF
%    \ENDFOR
%    \UNTIL{$noChange$ is $true$}
% \end{algorithmic}
% \end{algorithm}

% \subsection{Tables}

% You may also want to include tables that summarize material. Like
% figures, these should be centered, legible, and numbered consecutively.
% However, place the title \emph{above} the table with at least
% 0.1~inches of space before the title and the same after it, as in
% \cref{sample-table}. The table title should be set in 9~point
% type and centered unless it runs two or more lines, in which case it
% should be flush left.

% % Note use of \abovespace and \belowspace to get reasonable spacing
% % above and below tabular lines.

% \begin{table}[t]
% \caption{Classification accuracies for Baselines Bayes and flexible
% Bayes on various data sets.}
% \label{sample-table}
% \vskip 0.15in
% \begin{center}
% \begin{small}
% \begin{sc}
% \begin{tabular}{lcccr}
% \toprule
% Data set & Baselines & Flexible & Better? \\
% \midrule
% Breast    & 95.9$\pm$ 0.2& 96.7$\pm$ 0.2& $\surd$ \\
% Cleveland & 83.3$\pm$ 0.6& 80.0$\pm$ 0.6& $\times$\\
% Glass2    & 61.9$\pm$ 1.4& 83.8$\pm$ 0.7& $\surd$ \\
% Credit    & 74.8$\pm$ 0.5& 78.3$\pm$ 0.6&         \\
% Horse     & 73.3$\pm$ 0.9& 69.7$\pm$ 1.0& $\times$\\
% Meta      & 67.1$\pm$ 0.6& 76.5$\pm$ 0.5& $\surd$ \\
% Pima      & 75.1$\pm$ 0.6& 73.9$\pm$ 0.5&         \\
% Vehicle   & 44.9$\pm$ 0.6& 61.5$\pm$ 0.4& $\surd$ \\
% \bottomrule
% \end{tabular}
% \end{sc}
% \end{small}
% \end{center}
% \vskip -0.1in
% \end{table}

% Tables contain textual material, whereas figures contain graphical material.
% Specify the contents of each row and column in the table's topmost
% row. Again, you may float tables to a column's top or bottom, and set
% wide tables across both columns. Place two-column tables at the
% top or bottom of the page.

% \subsection{Theorems and such}
% The preferred way is to number definitions, propositions, lemmas, etc. consecutively, within sections, as shown below.
% \begin{definition}
% \label{def:inj}
% A function $f:X \to Y$ is injective if for any $x,y\in X$ different, $f(x)\ne f(y)$.
% \end{definition}
% Using \cref{def:inj} we immediate get the following result:
% \begin{proposition}
% If $f$ is injective mapping a set $X$ to another set $Y$, 
% the cardinality of $Y$ is at least as large as that of $X$
% \end{proposition}
% \begin{proof} 
% Left as an exercise to the reader. 
% \end{proof}
% \cref{lem:usefullemma} stated next will prove to be useful.
% \begin{lemma}
% \label{lem:usefullemma}
% For any $f:X \to Y$ and $g:Y\to Z$ injective functions, $f \circ g$ is injective.
% \end{lemma}
% \begin{theorem}
% \label{thm:bigtheorem}
% If $f:X\to Y$ is bijective, the cardinality of $X$ and $Y$ are the same.
% \end{theorem}
% An easy corollary of \cref{thm:bigtheorem} is the following:
% \begin{corollary}
% If $f:X\to Y$ is bijective, 
% the cardinality of $X$ is at least as large as that of $Y$.
% \end{corollary}
% \begin{assumption}
% The set $X$ is finite.
% \label{ass:xfinite}
% \end{assumption}
% \begin{remark}
% According to some, it is only the finite case (cf. \cref{ass:xfinite}) that is interesting.
% \end{remark}
% %restatable

% \subsection{Citations and References}

% Please use APA reference format regardless of your formatter
% or word processor. If you rely on the \LaTeX\/ bibliographic
% facility, use \texttt{natbib.sty} and \texttt{icml2025.bst}
% included in the style-file package to obtain this format.

% Citations within the text should include the authors' last names and
% year. If the authors' names are included in the sentence, place only
% the year in parentheses, for example when referencing Arthur Samuel's
% pioneering work \yrcite{Samuel59}. Otherwise place the entire
% reference in parentheses with the authors and year separated by a
% comma \cite{Samuel59}. List multiple references separated by
% semicolons \cite{kearns89,Samuel59,mitchell80}. Use the `et~al.'
% construct only for citations with three or more authors or after
% listing all authors to a publication in an earlier reference \cite{MachineLearningI}.

% Authors should cite their own work in the third person
% in the initial version of their paper submitted for blind review.
% Please refer to \cref{author info} for detailed instructions on how to
% cite your own papers.

% Use an unnumbered first-level section heading for the references, and use a
% hanging indent style, with the first line of the reference flush against the
% left margin and subsequent lines indented by 10 points. The references at the
% end of this document give examples for journal articles \cite{Samuel59},
% conference publications \cite{langley00}, book chapters \cite{Newell81}, books
% \cite{DudaHart2nd}, edited volumes \cite{MachineLearningI}, technical reports
% \cite{mitchell80}, and dissertations \cite{kearns89}.

% Alphabetize references by the surnames of the first authors, with
% single author entries preceding multiple author entries. Order
% references for the same authors by year of publication, with the
% earliest first. Make sure that each reference includes all relevant
% information (e.g., page numbers).

% Please put some effort into making references complete, presentable, and
% consistent, e.g. use the actual current name of authors.
% If using bibtex, please protect capital letters of names and
% abbreviations in titles, for example, use \{B\}ayesian or \{L\}ipschitz
% in your .bib file.

% \section*{Accessibility}
% Authors are kindly asked to make their submissions as accessible as possible for everyone including people with disabilities and sensory or neurological differences.
% Tips of how to achieve this and what to pay attention to will be provided on the conference website \url{http://icml.cc/}.

% \section*{Software and Data}

% If a paper is accepted, we strongly encourage the publication of software and data with the
% camera-ready version of the paper whenever appropriate. This can be
% done by including a URL in the camera-ready copy. However, \textbf{do not}
% include URLs that reveal your institution or identity in your
% submission for review. Instead, provide an anonymous URL or upload
% the material as ``Supplementary Material'' into the OpenReview reviewing
% system. Note that reviewers are not required to look at this material
% when writing their review.

% % Acknowledgements should only appear in the accepted version.
% \section*{Acknowledgements}

% \textbf{Do not} include acknowledgements in the initial version of
% the paper submitted for blind review.

% If a paper is accepted, the final camera-ready version can (and
% usually should) include acknowledgements.  Such acknowledgements
% should be placed at the end of the section, in an unnumbered section
% that does not count towards the paper page limit. Typically, this will 
% include thanks to reviewers who gave useful comments, to colleagues 
% who contributed to the ideas, and to funding agencies and corporate 
% sponsors that provided financial support.

% \section*{Impact Statement}

% Authors are \textbf{required} to include a statement of the potential 
% broader impact of their work, including its ethical aspects and future 
% societal consequences. This statement should be in an unnumbered 
% section at the end of the paper (co-located with Acknowledgements -- 
% the two may appear in either order, but both must be before References), 
% and does not count toward the paper page limit. In many cases, where 
% the ethical impacts and expected societal implications are those that 
% are well established when advancing the field of Machine Learning, 
% substantial discussion is not required, and a simple statement such 
% as the following will suffice:

% ``This paper presents work whose goal is to advance the field of 
% Machine Learning. There are many potential societal consequences 
% of our work, none which we feel must be specifically highlighted here.''

% The above statement can be used verbatim in such cases, but we 
% encourage authors to think about whether there is content which does 
% warrant further discussion, as this statement will be apparent if the 
% paper is later flagged for ethics review.


% In the unusual situation where you want a paper to appear in the
% references without citing it in the main text, use \nocite
\nocite{langley00}

\bibliography{example_paper}
\bibliographystyle{icml2025}


%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% APPENDIX
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\newpage
\appendix
\onecolumn
\section{Appendix}


\subsection{Related Work}
\textbf{In-context learning} In-context learning (ICL) is a new paradigm for large language (LLMs), which allows LLMs to make predictions only based on a few demonstrations without explicitly updating parameters \citep{akyrek2023what,hendel2023context,agarwal2024many, dong2024survey,edwards-camacho-collados-2024-language,falck2024martingale}. Many studies show that ICL can achieve performance similar to fine-tuning but without the high computational cost \citep{gonen-etal-2023-demystifying, mosbach-etal-2023-shot,muller2024bayes,panwar2024incontext}. Despite achieving such outstanding performance, ICL has been criticized for being very sensitive to the quality of in-context examples \citep{fei-etal-2023-mitigating,gao2024noise}. Various approaches have been proposed to improve the robustness of ICL in recent years, including meta-tuning LLMs \citep{brunet2023icl}, calibration \citep{abbas2024enhancing},  demonstration selection \citep{zhang-etal-2022-active,nguyen2023context,qin2023context,ye-etal-2023-complementary,gao2024unifying,luo2024context,mo-etal-2024-c}, ordering \citep{lu-etal-2022-fantastically,liu2024let}, number \citep{zhang2025more} and formation \citep{voronov2024mind, yao-etal-2024-samples}.  

Notably, existing studies often assume that usually assume that annotated dataset and testing data are both i.i.d. (independent and identically distributed) sampled from the same data distribution \citep{luo2024context,van2024context}. However, this is not always true for real-world scenarios. Specifically, annotated dataset typically exhibit a long-tailed class distribution, where a small portion of classes have a massive number of sample points but the others are associated with only a few examples \citep{jamal2020rethinking,schultheis2024generalized}. It is still mysterious how demonstrations sampled from long-tailed distribution affect the performance of ICL on both text classification and generation tasks. In this paper, we show that annotation quality is crucial for ICL in both text classification and generation, where imbalanced datasetss significantly hurt the performance. Different from previous study \citep{hong2024mixtures},  we propose a simple and effective method to enhance the performance of ICL from the perspective of demonstration selection.


\textbf{Learning with imbalanced datasets} Imbalanced dataset is common in many real-world datasets \citep{cui2018large,cui2019class,jamal2020rethinking, schultheis2024generalized}. 
The existing approaches to learning with imbalanced datasets can be classified into two types: (1) training imbalance-robust models with imbalance training datasets: designing imbalance-robust loss function \citep{jamal2020rethinking,tan2020equalization,park2023robust,bhat2023robust,garcin2022stochastic} or designing imbalance-robust model architectures \citep{long2022retrieval,pan2024lt} to mitigate the issue of imbalanced datasets. However, this method is not suitable for ICL, which usually hypothesizes that users are unable to apply fine-tuning techniques. (2) handling imbalance examples: handling imbalanced datasets is crucial for ensuring balanced performance across all classes. One simple and intuitive approach to deal with the class-imbalanced problem is re-sampling. Under-sampling methods remove examples from the majority classes, which is infeasible under data imbalanced settings \citep{liu2008exploratory,wei2022open}. The over-sampling method adds repeated examples for the minority classes, usually causing over-fitting to the minority classes \citep{chawla2002smote,shi2023re}. It is noteworthy that these existing methods mainly focus on the fine-tuning setting, and the literature on how to mitigate the effects of imbalanced datasets in in-context learning is limited. This motivated us to design a method for addressing the issue of imbalanced datasets under the setting of ICL.


% \subsection{Proof of Proposition 2.2}
% \label{proof:1}
% \textit{From a Bayesian perspective, the prediction of in-context learning is generally made as follows:
% \begin{align}
%     f_\theta(\mathrm{\mathbf{C}}_K, \mathrm{\mathbf{x}}_t) \approx   \mathop{\arg\max}\limits_{\mathrm{\mathbf{y}}}  P_{\theta^*} (\mathrm{\mathbf{x}}_c|\mathrm{\mathbf{y}}_c)  P_{\theta^*} (\mathrm{\mathbf{y}}_c). \nonumber
% \end{align} 
% where $P_{\theta^*} (\mathrm{\mathbf{x}}_c)$ and $P_{\theta^*} (\mathrm{\mathbf{y}}_c)$ represent $P_{\theta^*} (X=\mathrm{\mathbf{x}}_c)$ and $P_{\theta^*} (Y=\mathrm{\mathbf{y}}_c)$, respectively.}

% \textbf{\textit{Proof.}} 
% Assume both demonstrations $\mathrm{\mathbf{C}}_K$ and test sample $(\mathrm{\mathbf{x}}_t, \mathrm{\mathbf{y}}_t)$ are generated by data generated model $\theta^*$. According to the \textit{Theorem 1} in \citet{xie2022an}, given such demonstrations $\mathrm{\mathbf{C}}_K$, in-context learning allows large language models $\theta$ to generate output $\mathrm{\mathbf{y}}$ as follows:
% \begin{align}
%      \mathop{\arg\max}\limits_{\mathrm{\mathbf{y}_t}} P_\theta  \left(\mathrm{\mathbf{y}}_t \vert \mathrm{\mathbf{C}}_K,\mathrm{\mathbf{x}}_t \right) \approx \mathop{\arg\max}\limits_{\mathrm{\mathbf{y}_c}}  P_{\theta^*} (\mathrm{\mathbf{y}}_t|\mathrm{\mathbf{x}}_t), \nonumber
% \end{align}
% where large language models $\theta$ to generate correct output $\mathrm{\mathbf{y}}_t$ just like data generated model $\theta^*$.

% The above equation can also be expressed as follows:
% \begin{align}
% \mathop{\arg\max}\limits_{\mathrm{\mathbf{y}_t}}  P_{\theta^*} (\mathrm{\mathbf{y}}_t|\mathrm{\mathbf{x}}_t) = \mathop{\arg\max}\limits_{\mathrm{\mathbf{y}_c}}  P_{\theta^*} (\mathrm{\mathbf{y}}_c|\mathrm{\mathbf{x}}_c)(1+\nu), \quad \nu = \frac{P_{\theta^*} (\mathrm{\mathbf{y}}_t|\mathrm{\mathbf{x}}_t)}{P_{\theta^*} (\mathrm{\mathbf{y}}_c|\mathrm{\mathbf{x}}_c) } - 1, \nonumber
% \end{align}
% where $\nu$ measure the difference of conditional distribution between the annotated dataset and test dataset. 

% According to \citet{xie2022an}, the test inputs $\mathrm{\mathbf{x}}_c$ are sampled similarly with demonstration inputs, leading to similar distributions of input features. 
% We have
% \begin{align}
%     P_c(\mathrm{\mathbf{x}}) \approx P_t(\mathrm{\mathbf{x}}).   \nonumber
% \end{align}
% \zh{number it num1}

% The output $\mathrm{\mathbf{y}}_t$ is generated as follows:
% \begin{align}
%      P_{\theta^*}(\mathrm{\mathbf{y}}_t|\mathrm{\mathbf{x}}_t)= \mathbb{E}_{{h_t^{start}} \sim P{\left( 
% h_t^{start} | \mathrm{\mathbf{x}}_t \right)}}\left[ P_{\theta^*}(\mathrm{\mathbf{y}}_t|\mathrm{\mathbf{x}}_t, h_t^{start}) \right], \nonumber
% \end{align}
% where the test output  $\mathrm{\mathbf{y}}_t$ for test input $\mathrm{\mathbf{x}}_t$ is generated  by using the start hidden state $h_t^{start}$ and data generated model $\theta^*$. 

% The input and output pair of demonstration are generated in a similar manner as follows:
% \begin{align}
%      P_{\theta^*}(\mathrm{\mathbf{y}}_c|\mathrm{\mathbf{x}}_c)=\mathbb{E}_{{h_c^{start}} = P{\left( 
% h_c^{start} | \mathrm{\mathbf{x}}_c \right)}}\left[ P_{\theta^*}(\mathrm{\mathbf{y}}_c|\mathrm{\mathbf{x}}_c, h_c^{start}) \right]. \nonumber
% \end{align}

% Due to the similarity in the generation method of demonstration input $\mathrm{\mathbf{x}}_c$ and test input $\mathrm{\mathbf{x}}_t$ and considering that $h^{start}$ denotes the hidden state corresponding to the first token of $\mathrm{\mathbf{x}}$, we can infer that 
% \begin{align}
% P_{\theta^*}(\mathrm{\mathbf{y}}_t|\mathrm{\mathbf{x}}_t) \approx P_{\theta^*}(\mathrm{\mathbf{y}}_c|\mathrm{\mathbf{x}}_c), \nonumber
% \end{align}
% then
% \begin{align}
% \nu = \frac{P_{\theta^*} (\mathrm{\mathbf{y}}_t|\mathrm{\mathbf{x}}_t)}{P_{\theta^*} (\mathrm{\mathbf{y}}_c|\mathrm{\mathbf{x}}_c) } - 1 \approx 0. \nonumber
% \end{align}
% \zh{number it num2}
% Thus 
% \begin{align}
%     f_\theta(\mathrm{\mathbf{C}}_K, \mathrm{\mathbf{x}}_t) & \approx   \mathop{\arg\max}\limits_{\mathrm{\mathbf{y}}}  P_{\theta^*} (\mathrm{\mathbf{y}}_c|\mathrm{\mathbf{x}}_c) \nonumber \\
%     &\approx   \mathop{\arg\max}\limits_{\mathrm{\mathbf{y}}}  P_{\theta^*} (\mathrm{\mathbf{x}}_c|\mathrm{\mathbf{y}}_c)  P_{\theta^*} (\mathrm{\mathbf{y}}_c). \nonumber
% \end{align} 
% \zh{where the first eq is caused by num2, and the second eq is caused by num1.}
% The in-context predictor can be expressed as follows:
% \begin{align}
% \mathop{\arg\max}\limits_{\mathrm{\mathbf{y}}}  P_{\theta^*} (\mathrm{\mathbf{y}}_t|\mathrm{\mathbf{x}}_t) = \mathop{\arg\max}\limits_{\mathrm{\mathbf{y}}}  P_{\theta^*} (\mathrm{\mathbf{y}}_c|\mathrm{\mathbf{x}}_c)(1+\nu), \nonumber \\
% \nu = \frac{P_{\theta^*} (\mathrm{\mathbf{y}}_t|\mathrm{\mathbf{x}}_t)}{P_{\theta^*} (\mathrm{\mathbf{y}}_c|\mathrm{\mathbf{x}}_c) } - 1 = \frac{P_{\theta^*} (\mathrm{\mathbf{x}}_t,\mathrm{\mathbf{y}}_t)}{P_{\theta^*} (\mathrm{\mathbf{x}}_c,\mathrm{\mathbf{y}}_c) } - 1. \nonumber
% \end{align}
% where $\nu$ measure the difference between the annotated dataset and test conditional distributions. 

% The demonstration inputs $\mathrm{\mathbf{x}}_c$ are sampled similarly. This implies that the process or criteria used to sample inputs for both annotated dataset and the test dataset are consistent, leading to similar distributions of input features, we have
% \begin{align}
%     D_{KL} \left(P(\mathrm{\mathbf{x}}_c)|P(\mathrm{\mathbf{x}}_t)\right) \approx 0  \nonumber
% \end{align}
% where $D_{KL}(\cdot,\cdot)$ denotes Kullback-Leibler Divergence. 

% The start hidden state $h^{start}$ start is determined based on the conditional probability $p_{\left(h^{start} | \mathrm{\mathbf{x}}\right)}$, we have
% \begin{align}
%     D_{KL} \left(P(h^{start}_c)|P(h^{start}_t)\right) \approx 0  \nonumber
% \end{align}
% This suggests that the hidden state is a function of the input features and the hidden state distributions should also be similar.

% Hence, 
% \begin{align}
%     P_{\theta^*} (\mathrm{\mathbf{y}}_t|\mathrm{\mathbf{x}}_t) \approx P_{\theta^*} (\mathrm{\mathbf{y}}_c|\mathrm{\mathbf{x}}_c), \quad \nu \approx 0 \nonumber
% \end{align}
% and 
% \begin{align}
%      f_\theta(\mathrm{\mathbf{C}}_K, \mathrm{\mathbf{x}}_t) &\approx  \mathop{\arg\max}\limits_{\mathrm{\mathbf{y}}}  P_{\theta^*} (\mathrm{\mathbf{y}}_c|\mathrm{\mathbf{x}}_c)(1+\nu), \nonumber \\ 
%     & = \mathop{\arg\max}\limits_{\mathrm{\mathbf{y}}}  P_{\theta^*} (\mathrm{\mathbf{x}}_c|\mathrm{\mathbf{y}}_c) P_{\theta^*} (\mathrm{\mathbf{y}}_c)(1+\nu). \nonumber
% \end{align}




% \begin{align}
% {P_{\theta^*} (\mathrm{\mathbf{x}}_c,\mathrm{\mathbf{y}}_c) } \approx {P_{\theta^*} (\mathrm{\mathbf{x}}_t,\mathrm{\mathbf{y}}_t) , \quad  \nu \approx 0 \nonumber\\
% \end{align}

% When the impact of the start hidden states $h^{start}$ is marginal, we have $P_{\theta^*} (\mathrm{\mathbf{y}}_c|\mathrm{\mathbf{x}}_c) = P_{\theta^*} (\mathrm{\mathbf{y}}_t|\mathrm{\mathbf{x}}_t)$ and $\nu = 0$. 


% The demonstration inputs $\mathrm{\mathbf{x}}_c$ are sampled similarly. This implies that the process or criteria used to sample inputs for both annotated dataset and the test dataset are consistent, leading to similar distributions of input features, we have
% \begin{align}
%     D_{KL} \left(P(\mathrm{\mathbf{x}}_c)|P(\mathrm{\mathbf{x}}_t)\right) \approx 0  \nonumber
% \end{align}
% where $D_{KL}(\cdot,\cdot)$ denotes Kullback-Leibler Divergence. 

% The start hidden state $h^{start}$ start is determined based on the conditional probability $p_{\left(h^{start} | \mathrm{\mathbf{x}}\right)}$. This suggests that the hidden state is a function of the input features and the hidden state distributions should also be similar, we have
% \begin{align}
%     D_{KL} \left(P(h^{start}_c)|P(h^{start}_t)\right) \approx 0  \nonumber
% \end{align}

% Hence, 
% \begin{align}
%     P_{\theta^*} (\mathrm{\mathbf{y}}_t|\mathrm{\mathbf{x}}_t) = P_{\theta^*} (\mathrm{\mathbf{y}}_c|\mathrm{\mathbf{x}}_c) (1+\nu)  \nonumber
% \end{align}
% where $\nu$ measure the difference between the annotated dataset and test conditional distributions. 


% \begin{align}
%     P_{\theta^*} (\mathrm{\mathbf{y}}_t|\mathrm{\mathbf{x}}_t) = P_{\theta^*} (\mathrm{\mathbf{y}}_c|\mathrm{\mathbf{x}}_c) (1+\nu)  \nonumber
% \end{align}



% The input-output pairs of demonstration are generated similarly by providing a demonstration input $\mathrm{\mathbf{x}}_c$ and start hidden state $h_c^{start}$. We have
% \begin{align}
%     P_{\theta^*} (\mathrm{\mathbf{y}}_t|\mathrm{\mathbf{x}}_t) = P_{\theta^*} (\mathrm{\mathbf{y}}_c|\mathrm{\mathbf{x}}_c) (1+\nu)  \nonumber
% \end{align}
% where $\nu$ measure the difference between the annotated dataset and test conditional distributions. According to the existing study \citep{xie2022an}, the demonstration inputs are sampled similarly and the start hidden state is determined based on $p_{\left( h^{start} | \mathrm{\mathbf{x}} \right)}$, we can obtained that the distribution of $h^{start}$ is same for annotated dataset and test dataset, so $P_{\theta^*} (\mathrm{\mathbf{x}}_t,\mathrm{\mathbf{y}}_t) \approx P_{\theta^*} (\mathrm{\mathbf{x}}_c,\mathrm{\mathbf{y}}_c)$.




% Therefore, we can regard that the demonstrations $\left\{\mathrm{(\mathbf{x}}_c, \mathrm{\mathbf{y}}_c) \right\}_{i=1}^N$ are generated in a manner similar to the input-output pairs of the test dataset $\left\{\mathrm{(\mathbf{x}}_t, \mathrm{\mathbf{y}}_t) \right\}_{t=1}^T$.


% $P_{\theta^*}(\mathrm{\mathbf{y}}_t|\mathrm{\mathbf{x}}_t)=\mathbb{E}_{{h_t^{start}} = p_{\left( 
% h_t^{start} | \mathrm{\mathbf{x}}_t \right)}}\left[ P_{\theta^*}(\mathrm{\mathbf{y}}_t|\mathrm{\mathbf{x}}_t, h_t^{start}) \right], \nonumber
% $

% When the impact of the start hidden states $h^{start}$ is marginal, we have $P_{\theta^*} (\mathrm{\mathbf{y}}_c|\mathrm{\mathbf{x}}_c) = P_{\theta^*} (\mathrm{\mathbf{y}}_t|\mathrm{\mathbf{x}}_t)$ and $\nu = 0$. 





\subsection{Proof}
\label{proof:2}
% \textit{Let's decouple the ratio of joint probability distributions between annotated dataset and the test dataset for in-context learning. We have
% \begin{align}
% f\left( \operatorname{Top}_K \left( \left\{ (w+\beta)s(\mathrm{\mathbf{c}}_i,\mathrm{\mathbf{x}}_t) \right\}_{i=1}^N \right), \mathrm{\mathbf{x}}_t, \theta\right). \nonumber
% \end{align}
% where $w$ denotes class-wise weights and conditional bias $\beta= w\left(\frac{P_t(\mathrm{\mathbf{x}}|\mathrm{\mathbf{y}})}{P_c(\mathrm{\mathbf{x}}|\mathrm{\mathbf{y}})}-1\right)$ measures the bias caused by difference of  conditional distribution between the annotated dataset and test conditional distributions.}


\textbf{\textit{Proof.}} We apply the importance sampling trick to connect the expected $\operatorname{Error}$ with the imbalanced annotated dataset:
\begin{align}
    \operatorname{Error}&=\mathbb{E}_{P_t(\mathrm{\mathbf{x}},\mathrm{\mathbf{y}})}M\left[ f_\theta\left( \operatorname{Top}_K \left( \left\{ s(\mathrm{\mathbf{c}}_i,\mathrm{\mathbf{x}}_t) \right\}_{i=1}^N \right), \mathrm{\mathbf{x}}_t\right), \mathrm{\mathbf{y}}_t \right], \nonumber \\
    &=\mathbb{E}_{P_c(\mathrm{\mathbf{x}},\mathrm{\mathbf{y}})}M\left[ f_\theta\left( \operatorname{Top}_K \left( \left\{ s(\mathrm{\mathbf{c}}_i,\mathrm{\mathbf{x}}_t) \right\}_{i=1}^N \right), \mathrm{\mathbf{x}}_t\right), \mathrm{\mathbf{y}}_t \right] \frac{P_t(\mathrm{\mathbf{x}},\mathrm{\mathbf{y}})}{P_c(\mathrm{\mathbf{x}},\mathrm{\mathbf{y}})}, \nonumber \\
    &=\mathbb{E}_{P_c(\mathrm{\mathbf{x}},\mathrm{\mathbf{y}})}M\left[ f_\theta\left( \operatorname{Top}_K \left( \left\{ s(\mathrm{\mathbf{c}}_i,\mathrm{\mathbf{x}}_t) \right\}_{i=1}^N \right), \mathrm{\mathbf{x}}_t\right), \mathrm{\mathbf{y}}_t \right] \frac{P_t(\mathrm{\mathbf{x}}|\mathrm{\mathbf{y}})P_t(\mathrm{\mathbf{y}})}{P_c(\mathrm{\mathbf{x}}|\mathrm{\mathbf{y}})P_c(\mathrm{\mathbf{y}})}, \nonumber 
    % &=\mathbb{E}_{P_c(\mathrm{\mathbf{x}},\mathrm{\mathbf{y}})}M\left[ f_\theta\left( \operatorname{Top}_K \left( \left\{ s(\mathrm{\mathbf{c}}_i,\mathrm{\mathbf{x}}_t) \right\}_{i=1}^N \right), \mathrm{\mathbf{x}}_t\right), \mathrm{\mathbf{y}}_t \right] \bm{w} (1+\bm{\widetilde{\beta}}). \nonumber 
    % &=\mathbb{E}_{P_c(\mathrm{\mathbf{x}},\mathrm{\mathbf{y}})}M\left[ f_\theta\left( \operatorname{Top}_K \left( \left\{ w (1+\widetilde{\beta})s(\mathrm{\mathbf{c}}_i,\mathrm{\mathbf{x}}_t) \right\}_{i=1}^N \right), \mathrm{\mathbf{x}}_t\right), \mathrm{\mathbf{y}}_t \right].
\end{align}
Here, we decompose the term \(\frac{P_t(\mathrm{\mathbf{x}}|\mathrm{\mathbf{y}})P_t(\mathrm{\mathbf{y}})}{P_c(\mathrm{\mathbf{x}}|\mathrm{\mathbf{y}})P_c(\mathrm{\mathbf{y}})}\) into two parts: 
the class-wise weights \(\bm{w} = \), and the conditional weight \(\bm{\widetilde{\beta}} = \). The class-wise weights measure the difference between class prior distributions $P(Y)$, and the conditional weight measures the difference between conditional distributions $P(X|Y)$. Then we have 
\begin{equation*}
    \operatorname{Error} =\mathbb{E}_{P_c(\mathrm{\mathbf{x}},\mathrm{\mathbf{y}})}M\left[ f_\theta\left( \operatorname{Top}_K \left( \left\{ s(\mathrm{\mathbf{c}}_i,\mathrm{\mathbf{x}}_t) \right\}_{i=1}^N \right), \mathrm{\mathbf{x}}_t\right), \mathrm{\mathbf{y}}_t \right] \bm{w} (1+\bm{\widetilde{\beta}})
\end{equation*}

where $\bm{w}$ denotes class-wise weights and conditional weight $\bm{\widetilde{\beta}}= \frac{P_t(\mathrm{\mathbf{x}}|\mathrm{\mathbf{y}})}{P_c(\mathrm{\mathbf{x}}|\mathrm{\mathbf{y}})}-1$ measures the difference of conditional distribution between the annotated and test datasets.

For simplicity, we introduce a conditional bias $\bm{\beta} = \bm{w} \times \bm{\widetilde{\beta}}$  and re-write the expected $\operatorname{Error}$ as:
\begin{align}
    \mathbb{E}_{P_c(\mathrm{\mathbf{x}},\mathrm{\mathbf{y}})}M\left[ f_\theta\left( \operatorname{Top}_K \left( \left\{ s(\mathrm{\mathbf{c}}_i,\mathrm{\mathbf{x}}_t) \right\}_{i=1}^N \right), \mathrm{\mathbf{x}}_t\right), \mathrm{\mathbf{y}}_t \right](\bm{w}+\bm{\beta}).
\end{align}
where conditional bias $\bm{\beta} = \bm{w} \times \bm{\widetilde{\beta}} = \frac{P_t(\mathrm{\mathbf{y}})}{P_c(\mathrm{\mathbf{y}})} \left( \frac{P_t(\mathrm{\mathbf{x}}|\mathrm{\mathbf{y}})}{P_c(\mathrm{\mathbf{x}}|\mathrm{\mathbf{y}})}-1 \right)$ denotes the deviation of class-wise weights caused by the presence of conditional weight $\bm{\widetilde{\beta}}$. 

\subsection{Bayesian Optimizing Conditional Bias}
\label{bayeopt}
In this section, we will introduce how to use Bayesian optimization \citep{gardner2014bayesian,bayesianopt} to find the optimal value of conditional bias $\beta$ by maximizing empirical $\operatorname{Error}$ as follows:
\begin{align}
\label{formula:10}
    \mathcal{F}_\theta\left(\beta|\mathcal{D}_r, \mathcal{D}_b, \bm{w}\right) = \frac{1}{|\mathcal{D}_b|} \sum_{i=1}^{|\mathcal{D}_b|} M\left[ f_\theta\left( \operatorname{Top}_K \left( \left\{ (w_i+\beta) 
\times s(\mathrm{\mathbf{c}}_i,\mathrm{\mathbf{x}}_b) \right\}_{i=1}^{|\mathcal{D}_r|} \right), \mathrm{\mathbf{x}}_b\right), \mathrm{\mathbf{y}}_b \right].
\end{align}
\textbf{Surrogate Model.} We use the Gaussian Process as a surrogate model to approximate the objective function \ref{formula:10}. Initially, a prior distribution is established in a general form for the estimated model parameters,
\begin{align}
    \mathcal{F}_\theta\left(\beta|\mathcal{D}_r, \mathcal{D}_b, \bm{w}\right) = \mathcal{N}\left( \mu(\beta), \sigma^2(\beta) \right), \nonumber
\end{align}
where $\mathcal{N}$ is the Gaussian distribution with a mean function $\mu(\beta)$ and a covariance function $\sigma^2(\beta)$. For a data point $\beta_j$ sampled from the Gaussian process $\mathcal{N}$, we compute its corresponding function values $\mathcal{F}_\theta\left(\beta_j|\mathcal{D}_r, \mathcal{D}_b, w\right)$.

% Using Bayes' theorem, we combine the prior distribution with the data points $\beta$ to compute the posterior probability distribution $h(\beta)$ as follows:
% \begin{align}
%     h(\beta) = \frac{P(\mathcal{F}|\beta)\times P(\beta)}{P(\mathcal{F})}, \nonumber
% \end{align}
\textbf{Acquisition Function.} We use the Expected Improvement (EI) criterion to select the point $\beta_{j+1}$ with the maximum expected improvement as the next query point:
\begin{align}
    \operatorname{EI}(\beta) & =\left\{\begin{array}{ll}
\left(\mu_{j}(\beta)-\mathcal{F}_\theta\left(\beta^{+}|\mathcal{D}_r, \mathcal{D}_b, w\right)-\epsilon\right) \Phi(Z)+\sigma_{j}(\beta) \phi(Z) & \text { if } \sigma_{j}(\beta)>0,  \nonumber \\
0 & \text { if } \sigma_{j}(\beta)=0.
\end{array}\right. \nonumber \\
Z & =\frac{\mu_{j}(\beta)-\mathcal{F}_\theta\left(\beta^{+}|\mathcal{D}_r, \mathcal{D}_b, w\right)-\epsilon}{\sigma_{j}(\beta)}. \nonumber
\end{align}
where $\mu_{j}(\beta)$ and $\sigma_{j}(\beta)$ represent the mean and standard deviation of the surrogate model at step $j$, $\beta^{+}$ denotes the current optimal observed point, $\epsilon$ is a tunable hyper-parameter. $\Phi(Z)$ and $\phi(Z)$ are the probability density function and cumulative density function of the Gaussian Process, respectively.

\textbf{Iterative Optimization Process.} We start with an initial set of observations $\beta_0,...,\beta_h$ by evaluating the objective function $\left\{\mathcal{F}\left(\beta_i|\mathcal{D}_r, \mathcal{D}_b, w, \theta\right)\right\}_{i=0}^h$ at a few selected points. Second, we use the observed data $\left(\beta_j, \mathcal{F}\left(\beta_j|\mathcal{D}_r, \mathcal{D}_b, w, \theta\right)\right)$ to update the Gaussian Process model, refining the estimates of $\mu_{j}(\beta)$ and  $\sigma_{j}(\beta)$. Third, we employ the \textit{Expected Improvement} criterion to determine the next point $\beta_{j+1}$ and obtain $\left\{\mathcal{F}\left(\beta_{j+1}|\mathcal{D}_r, \mathcal{D}_b, w, \theta\right)\right\}_{i=0}^h$. We continue the process of updating the model and selecting new points until a stopping criterion is met. Finally, we select the point $\beta^{+}$ with the best observed value of the objective function $\mathcal{F}_\theta\left(\beta^{+}|\mathcal{D}_r, \mathcal{D}_b, w\right)$ as the optimal solution.

\subsection{Experimental Setting}
\label{appendix:experimental_setting}
\textbf{Datasets} We conduct experiments on various classification and generation tasks and examples of each dataset are shown in Tables \ref{table:a1} and \ref{tabel:a2}. We collect all datasets from Huggingface. The train sets of these datasets are regarded as example datasets and the test datasets are used to evaluate the performance of ICL. We randomly subsample  examples from the test dataset to verify the performance of the imbalanced annotated dataset. We generate categories for Natural question \citep{kwiatkowski-etal-2019-natural} using ChatGPT-3.5-Turbo. The categories include people, time, geography, culture, and specialized knowledge.

\textbf{Baselines} To verify the effectiveness of our method, we compare our method with previous methods for demonstration retrieval by the downstream ICL's performance. We consider both learning-free and other learning-based retrievers as baselines, including
\begin{enumerate}
    \item \textbf{Random} selects demonstrations randomly from an example set without repetition \citep{min-etal-2022-metaicl}.
    \item \textbf{TopK} retrieves demonstrations that are semantically similar to a test query sample \citep{liu-etal-2022-makes}.
    \item \textbf{DPP} uses the original BERT embeddings as mentioned above without fine-tuning, and adopts MAP inference for subset retrieval \citep{Ye2023DPP}.
    \item \textbf{VoteK} proposes an unsupervised and graph-based selective annotation method to select diverse and representative demonstrations \citep{su2023selective}.
    \item  \textbf{ConE} searches for demonstrations by minimizing the difference in cross-entropy between the test input and the demonstrations \citep{peng-etal-2024-revisiting}.
    \item \textbf{ByCS} assumes that an accurate inverse likelihood probability will lead to an accurate posterior probability and selects demonstrations based on their inverse inference results \citep{wang-etal-2024-bayesian}.
\end{enumerate}

\textbf{Experiment details} We run our experiments on NVIDIA GeForce RTX 4090 and NVIDIA L40 GPU, and implement all methods by \textit{PyTorch} and \textit{transformers}.  Our code is inspired by OpenICL \cite{wu-etal-2023-openicl}. We thank the authors for releasing their code.


\subsection{Inference} 
\textbf{Perplexity} For classification tasks, we compute the sentence perplexity for each sequence formed by concatenating the input with each candidate answer \citep{brown2020language, wu-etal-2023-openicl}. Specifically, for each input instance $\mathrm{\mathbf{x}}$ is paired potential label set $\mathcal{Y}$, where $\mathcal{Y}$ represents the set of possible classes (e.g., Sports, Business, etc.). Then, for each possible label $\mathrm{\mathbf{y}}\in \mathcal{Y}$, we concatenate each tokenized input-output pair $(\mathrm{\mathbf{x}}, \mathrm{\mathbf{y}})$,  and obtain the corresponding tokenized sequence $\mathrm{\mathbf{c}}=(z_1,...,z_{|\mathrm{\mathbf{c}}|})=(x_1,...,x_{|\mathrm{\mathbf{x}}|},y_1,...,y_{|\mathrm{\mathbf{y}}|})$, where $|\mathrm{\mathbf{c}}|=|\mathrm{\mathbf{x}}|+|\mathrm{\mathbf{y}}|$. Now, the perplexity of $\mathrm{\mathbf{c}}$ is calculated as:
 \begin{equation}
\operatorname{Perplexity}(\mathrm{\mathbf{c}}) = \operatorname{exp}\{-\frac{1}{|\mathrm{\mathbf{c}}|}\sum^{|\mathrm{\mathbf{c}}|}_{i = 1} \log p_{\theta} (c_{i}|c_{< i})\}. \nonumber
\end{equation}
where $\log p_{\theta} (c_i|c_{< i})$ is the log-likelihood of the $i$-th token conditioned on the preceding tokens $c_{< i}$, from the given language model parameterized by $\theta$.  We select the label corresponding to the input-output pair $\mathrm{\mathbf{c}}$ with the lowest perplexity as the predicted label for the input $\mathrm{\mathbf{x}}$.

\textbf{Direct} For text generation tasks, we represent candidate answers using tokens from the vocabulary and select the final prediction based on the one with the highest probability \citep{brown2020language, wu-etal-2023-openicl}. To reduce computational cost, we set the maximum new tokens to 50 and limit unnecessary token generation.

\subsection{More empirical results}
\subsubsection{The effect of imbalanced dataset}
\label{appendix_different_model}
In this section, we show the effect of imbalanced datasets on the performance of in-context learning with different model architectures and various numbers of subsets.  Figures \ref{figure:a1} (b) and (c) report that imbalanced datasets significant degrade ICL’s performance of Llama3-8B \citep{llama3modelcard} and Mistral-7B \citep{jiang2023mistral}. This illustrates that the negative effect of imbalanced datasets can be commonly observed in various large language models. Additionally, Figure \ref{figure:a1} (a) also reports a larger set of demonstrations does not enhance the performance of ICL. Specifically, imbalanced datasets also negatively impact the performance of in-context learning.

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%


\subsubsection{The failure of classical rebalance methods}
\label{appendix_failure}
Figures \ref{figure:a3} (a) and (b) reports the Kullback-Leibler (KL) divergence between $P_c(X|Y)$ and  $P_t(X|Y)$ for each class in the Yelp and Yahoo datasets, respectively. Notably, the KL divergence between
$P_c(X|Y)$ and  $P_t(X|Y)$ for each class is unequal to zero and  the assumption that $\beta$ = 0 is difficult to be satisfied.

\subsubsection{Main results for each dataset}
\label{appendix_more_results}
Tables \ref{table:a3}, \ref{table:a4} \ref{table:a5} and \ref{table:a6} report average test accuracy ($\%$) with standard deviation on AgNews, Yahoo, Amazon and Yelp datasets with various imbalanced ratios (over 3 runs), respectively.

\subsubsection{Is our method effective with different model architectures?}
\label{appendix_different_model2}
In this section, we provide the detailed results of Llama3-8B \citep{llama3modelcard} and Mistral-7B \citep{jiang2023mistral}. Figures \ref{figure:a4} (a) and (b) report the average accuracy of four classification tasks across six selection methods. We can clearly observe that imbalanced annotated datasets significantly hurt the performance of in-context learning, which is consistent with our previous findings. Meanwhile, Figures \ref{figure:a4} (a) and (b) also demonstrate that integrating our method can improve the performance of ICL against imbalanced annotated datasets.



\subsubsection{Can our method improve real-world imbalanced dataset?}
\label{appendix_real_data}
We further verify the effectiveness of our method on a real-world class-imbalanced dataset (Emotion \citep{saravia-etal-2018-carer}). .We select demonstrations from the training set and construct a balanced test set from the original test set. Figure \ref{figure:a5} summarizes the test accuracy across six existing selection methods using baselines, classical rebalance methods, and our method on the Emotion dataset.  In particular, the proposed method is able to consistently improve the existing selection methods and outperforms existing rebalance methods in test accuracy.


\begin{figure*}[t]
\centering % 确保整个figure*环境中的内容居中  
\subfigure[OPT-6.7B]{\includegraphics[width=0.33\textwidth]{Figure/Figure13.pdf}} %
\subfigure[Llama3-8b]{\includegraphics[width=0.33\textwidth]{Figure/Figure11.pdf}} % 
\subfigure[Mistral-7B]{\includegraphics[width=0.33\textwidth]{Figure/Figure12.pdf}} %
\subfigure[AgNews]{\includegraphics[width=0.24\textwidth]{Figure/Figure3.pdf}} %
\subfigure[Amazon]{\includegraphics[width=0.24\textwidth]{Figure/Figure14.pdf}} %
\subfigure[Yelp]{\includegraphics[width=0.24\textwidth]{Figure/Figure15.pdf}} % 
\subfigure[Yahoo]{\includegraphics[width=0.24\textwidth]{Figure/Figure16.pdf}} %
\caption{
The effect of class imbalance on ICL across six existing selection methods ($K=16$) with various imbalance ratios. Figures \ref{figure:a1} (a), (b) and (c) report average accuracy ($\%$) of four classification tasks using four different models, including OPT-6.7B, Llama3-8B and Mistral-7B. Figures \ref{figure:a1} (d), (e), (f) and (g) report the comparison of average accuracy ($\%$) for each class of different three datasets.}
\label{figure:a1}
\end{figure*}

\clearpage

\begin{table*}[!t]
\caption{
Average test accuracy ($\%$) with standard deviation on AgNews dataset with various imbalanced ratios (over 3 runs). The bold indicates the improved results by integrating our method.}
    \centering
    \resizebox{1\columnwidth}{!}{%
    \begin{tabular}{ccccccccc}
    \toprule
         $K$&  \multicolumn{4}{c}{8}&  \multicolumn{4}{c}{16}\\
\toprule
         \textbf{Imbalance Ratio}&  \textbf{0}&  \textbf{10}&  \textbf{50}&  \textbf{100} &  \textbf{0}&  \textbf{10}&  \textbf{50}& \textbf{100} \\
\midrule
Random&  68.17$\pm$0.12&  58.58$\pm$1.25&  48.75$\pm$1.81&  46.25$\pm$0.35&  70.58$\pm$0.59&  61.33$\pm$0.82&  50.75$\pm$1.62& 48.25$\pm$1.24\\
 \textbf{+Ours}& 68.08$\pm$0.72& \textbf{67.75$\pm$1.43}& \textbf{69.75$\pm$0.82}& \textbf{69.92$\pm$1.78}&68.83$\pm$0.42& \textbf{69.83$\pm$0.31}& \textbf{70.01$\pm$2.36}&\textbf{73.42$\pm$4.19}
\\
 TopK& 86.67$\pm$0.12& 76.42$\pm$0.77& 70.25$\pm$1.27& 66.67$\pm$1.89& 88.75$\pm$0.00& 79.17$\pm$0.42& 71.50$\pm$1.08&68.00$\pm$0.35\\
\textbf{+Ours}&85.92$\pm$1.18& \textbf{86.17$\pm$0.62}& \textbf{81.83$\pm$1.53}& \textbf{76.50$\pm$1.24}& 88.33$\pm$0.24& \textbf{86.58$\pm$1.23}& \textbf{83.25$\pm$1.27}&\textbf{76.42$\pm$1.01}
\\
 DPP& 86.50$\pm$0.00& 76.42$\pm$1.83& 69.67$\pm$0.82& 66.25$\pm$1.34& 87.25$\pm$0.00& 78.42$\pm$1.36& 71.58$\pm$1.71&68.92$\pm$0.31
\\
\textbf{+Ours}& 86.42$\pm$0.12& \textbf{87.75$\pm$1.43}& \textbf{81.25$\pm$1.67}& \textbf{78.17$\pm$1.33}& 87.42$\pm$0.12& \textbf{87.42$\pm$1.84}& \textbf{82.83$\pm$1.53}&\textbf{77.50$\pm$2.30}\\
 VoteK& 85.17$\pm$0.12& 76.75$\pm$1.54& 69.58$\pm$0.82& 66.42$\pm$1.66& 86.42$\pm$0.12& 78.83$\pm$0.42& 72.17$\pm$0.92&68.67$\pm$1.23
\\
  \textbf{+Ours}& \textbf{85.50$\pm$0.20}& \textbf{85.92$\pm$0.24}& \textbf{82.17$\pm$1.71}& \textbf{77.42$\pm$1.50}&86.58$\pm$0.31& \textbf{86.25$\pm$1.41}& \textbf{82.50$\pm$0.00}&\textbf{76.75$\pm$1.41}
\\
 ConE& 85.58$\pm$1.12& 76.00$\pm$2.16& 69.00$\pm$1.97& 65.50$\pm$1.27& 85.75$\pm$1.14& 77.33$\pm$1.25& 71.08$\pm$0.82&66.5$\pm$0.54
\\
 \textbf{+Ours}& \textbf{85.83$\pm$0.94}& \textbf{82.83$\pm$1.31}& \textbf{79.50$\pm$0.54}& \textbf{74.85$\pm$2.46}& 86.08$\pm$0.72& \textbf{83.75$\pm$1.08}& \textbf{81.58$\pm$0.62}&\textbf{74.83$\pm$1.36}
\\
 ByDC& 85.40$\pm$0.43& 74.00$\pm$1.08& 67.58$\pm$1.16& 63.58$\pm$1.36& 87.92$\pm$0.47& 76.08$\pm$0.59& 69.58$\pm$1.12&63.75$\pm$0.54
\\
\textbf{+Ours}&  84.73$\pm$0.38&  \textbf{82.75$\pm$1.24}& \textbf{80.92$\pm$1.36}&  \textbf{77.17$\pm$1.85}&  \textbf{88.33$\pm$0.12}&  \textbf{86.25$\pm$1.41}& \textbf{81.50$\pm$1.41}& \textbf{72.75$\pm$1.41}
\\\hline Baselines&82.92$\pm$0.32&73.03$\pm$1.44&65.81$\pm$1.31&62.45$\pm$1.31&84.45$\pm$0.39&75.19$\pm$0.81&67.78$\pm$1.21& 64.02$\pm$0.70\\
\textbf{+Ours}&82.75$\pm$0.59&\textbf{82.20$\pm$1.05}&\textbf{79.24$\pm$1.27}&\textbf{75.67$\pm$1.69}&84.26$\pm$0.32&\textbf{83.35$\pm$1.21}&\textbf{80.28$\pm$1.20}& \textbf{75.28$\pm$1.95}\\\hline
    \end{tabular}
    }
    \label{table:a3}
\end{table*}


\begin{table*}[!t]
\caption{
Average test accuracy ($\%$) with standard deviation on Yahoo dataset with various imbalanced ratios (over 3 runs). The bold indicates the improved results by integrating our method.}
    \centering
    \resizebox{1\columnwidth}{!}{%
    \begin{tabular}{ccccccccc}
    \toprule
         $K$&  \multicolumn{4}{c}{8}&  \multicolumn{4}{c}{16}\\
\toprule
         \textbf{Imbalance Ratio}&  \textbf{0}&  \textbf{10}&  \textbf{50}&  \textbf{100} &  \textbf{0}&  \textbf{10}&  \textbf{50}& \textbf{100} \\
\midrule
Random&  
37.93$\pm$1.91&  39.53$\pm$2.22&  36.07$\pm$0.41&  33.13$\pm$1.47&  44.20$\pm$0.59&  44.47$\pm$0.81&  39.27$\pm$1.18& 37.60$\pm$0.59\\
 \textbf{+Ours}& 37.87$\pm$1.84& 38.87$\pm$0.81& 36.00$\pm$0.71& \textbf{37.73$\pm$1.64}&43.20$\pm$1.18& 42.93$\pm$0.25& \textbf{44.33$\pm$0.74}&\textbf{44.00$\pm$1.93}\\
 TopK& 52.80$\pm$0.00& 51.47$\pm$0.34& 45.53$\pm$0.68& 43.07$\pm$1.46& 53.67$\pm$0.19& 52.93$\pm$1.27& 50.27$\pm$0.90&47.27$\pm$1.32
\\
\textbf{+Ours}&\textbf{53.47$\pm$0.47}& \textbf{53.00$\pm$0.33}& \textbf{48.33$\pm$1.54}& \textbf{47.87$\pm$2.62}& \textbf{54.40$\pm$0.85}& \textbf{56.00$\pm$1.50}& \textbf{50.53$\pm$1.33}&\textbf{50.20$\pm$2.70}\\
 DPP& 
54.00$\pm$0.00& 52.80$\pm$0.16& 47.53$\pm$1.24& 44.47$\pm$2.00& 56.57$\pm$0.26& 54.03$\pm$0.97& 50.47$\pm$0.57&48.87$\pm$1.25
\\
\textbf{+Ours}& 53.80$\pm$0.28& 51.04$\pm$1.49& 48.13$\pm$0.74& \textbf{47.80$\pm$2.27}& 56.07$\pm$0.19& \textbf{54.87$\pm$0.68}& \textbf{51.07$\pm$1.46}&\textbf{51.60$\pm$1.82}\\
 VoteK& 52.13$\pm$0.19& 50.80$\pm$0.59& 46.67$\pm$1.09& 44.67$\pm$1.31& 56.37$\pm$0.45& 53.10$\pm$0.54& 48.70$\pm$1.08&46.20$\pm$0.82\\
  
\textbf{+Ours}& 51.73$\pm$0.52& 50.24$\pm$0.45& \textbf{48.53$\pm$1.84}& \textbf{47.73$\pm$1.59}&56.03$\pm$0.26& \textbf{55.10$\pm$1.10}& \textbf{52.03$\pm$1.31}&\textbf{51.07$\pm$0.94}
\\
 ConE& 
51.53$\pm$0.52& 49.20$\pm$0.86& 44.60$\pm$1.30& 41.47$\pm$1.89& 51.90$\pm$0.80& 49.37$\pm$0.90& 45.33$\pm$0.68&42.77$\pm$1.47
\\
 \textbf{+Ours}& 51.67$\pm$0.66& \textbf{50.07$\pm$0.41}& \textbf{46.93$\pm$0.75}& \textbf{45.53$\pm$1.16}& \textbf{52.90$\pm$0.67}& \textbf{49.37$\pm$0.90}& \textbf{49.00$\pm$1.50}&\textbf{47.43$\pm$0.83}
\\
 ByDC& 
53.67$\pm$0.74& 49.60$\pm$0.85& 44.80$\pm$1.70& 42.17$\pm$1.68& 55.03$\pm$0.58& 49.77$\pm$1.11& 47.40$\pm$0.86&44.87$\pm$1.25
\\
\textbf{+Ours}&  53.40$\pm$0.43&  \textbf{52.33$\pm$0.90}& \textbf{48.47$\pm$1.65}&  \textbf{46.50$\pm$0.57}&  \textbf{55.37$\pm$0.68}&  \textbf{52.07$\pm$0.94}& \textbf{50.40$\pm$0.86}& \textbf{48.87$\pm$0.94}
\\\hline Baselines&
50.34$\pm$0.56&48.90$\pm$0.84&44.20$\pm$1.07&41.50$\pm$1.64&52.96$\pm$0.48&50.61$\pm$0.93&46.91$\pm$0.88& 44.60$\pm$1.12\\
\textbf{+Ours}&50.32$\pm$0.70&\textbf{49.26$\pm$0.73}&\textbf{45.96$\pm$1.36}&\textbf{45.53$\pm$1.64}&53.00$\pm$0.64&\textbf{51.72$\pm$0.90}&\textbf{49.56$\pm$1.20}& \textbf{48.86$\pm$1.53}\\\hline    \end{tabular}
    }
    \label{table:a4}
\end{table*}



\begin{table*}[!t]
\caption{
Average test accuracy ($\%$) with standard deviation on Amazon dataset with various imbalanced ratios (over 3 runs). The bold indicates the improved results by integrating our method.}
    \centering
    \resizebox{1\columnwidth}{!}{%
    \begin{tabular}{ccccccccc}
    \toprule
         $K$&  \multicolumn{4}{c}{8}&  \multicolumn{4}{c}{16}\\
\toprule
         \textbf{Imbalance Ratio}&  \textbf{0}&  \textbf{10}&  \textbf{50}&  \textbf{100} &  \textbf{0}&  \textbf{10}&  \textbf{50}& \textbf{100} \\
\midrule
Random&  
12.33$\pm$0.62& 15.2$\pm$1.45& 18.53$\pm$1.32&  20.13$\pm$0.98
& 13.33$\pm$0.19&  18.53$\pm$1.05&  20.07$\pm$0.09&  20.33$\pm$0.34
\\
 \textbf{+Ours}& 12.53$\pm$0.47& \textbf{19.87$\pm$0.96}& \textbf{20.93$\pm$2.38}& \textbf{20.47$\pm$1.33}
&13.47$\pm$0.25& 16.13$\pm$2.54& 20.20$\pm$1.18& \textbf{21.07$\pm$0.62}
\\
 TopK& 28.73$\pm$0.09& 28.47$\pm$0.74& 24.40$\pm$1.80& 23.40$\pm$0.86&30.60$\pm$0.00& 28.13$\pm$1.15& 24.20$\pm$0.65&23.07$\pm$0.66
\\
\textbf{+Ours}&28.80$\pm$0.00& \textbf{29.47$\pm$0.50}& \textbf{27.87$\pm$0.96}& \textbf{27.20$\pm$0.49}& 30.40$\pm$0.00& \textbf{31.00$\pm$1.30}& \textbf{29.13$\pm$0.93}& \textbf{28.33$\pm$0.90}       \\
 DPP& 29.80$\pm$0.16& 27.13$\pm$0.68& 25.47$\pm$1.27& 24.13$\pm$0.5&32.47$\pm$0.09& 28.13$\pm$0.47& 24.00$\pm$0.43&23.00$\pm$0.75\\
\textbf{+Ours}& 29.60$\pm$0.00& \textbf{28.67$\pm$1.79}& \textbf{28.67$\pm$0.81}& \textbf{27.60$\pm$0.86}
& 31.87$\pm$0.75& \textbf{30.87$\pm$1.39}& \textbf{28.93$\pm$1.00}&\textbf{27.93$\pm$1.06}
\\
 VoteK& 28.67$\pm$0.09& 25.67$\pm$0.81& 22.73$\pm$1.23& 22.93$\pm$0.41 & 31.57$\pm$0.29& 27.67$\pm$0.82& 22.60$\pm$0.65& 21.93$\pm$0.25
\\
  \textbf{+Ours}& 28.13$\pm$0.09& \textbf{27.53$\pm$1.72}& \textbf{27.00$\pm$0.75}& \textbf{27.47$\pm$1.32} &\textbf{31.80$\pm$0.85}& \textbf{30.07$\pm$0.34}& \textbf{28.40$\pm$1.40}&\textbf{27.20$\pm$1.02}
\\
 ConE& 26.73$\pm$0.47& 25.40$\pm$1.34& 22.87$\pm$0.82& 21.27$\pm$1.16& 30.20$\pm$0.00& 27.73$\pm$0.47& 22.87$\pm$0.94&22.27$\pm$0.38
\\
 \textbf{+Ours}& 
\textbf{27.40$\pm$0.82}& \textbf{26.73$\pm$1.27}& \textbf{27.60$\pm$1.30}& \textbf{27.27$\pm$1.16}
& 30.27$\pm$0.34& \textbf{29.07$\pm$1.20}& \textbf{29.13$\pm$0.93}& \textbf{26.80$\pm$0.49}
\\
 ByDC& 
29.47$\pm$0.52& 27.13$\pm$0.34& 25.20$\pm$1.02& 23.53$\pm$1.57& 32.13$\pm$0.38& 27.93$\pm$0.66& 24.13$\pm$0.50&22.27$\pm$0.25
\\
\textbf{+Ours}&  29.67$\pm$0.50&  \textbf{28.80$\pm$1.42}& \textbf{29.20$\pm$0.71}&  \textbf{27.13$\pm$1.05}&  \textbf{31.53$\pm$1.23}&  \textbf{30.07$\pm$1.31}& \textbf{28.60$\pm$1.14}& \textbf{27.8$\pm$0.75} \\\hline 
Baselines&25.96$\pm$0.33&24.83$\pm$0.89&23.20$\pm$1.24&22.57$\pm$0.91&28.38$\pm$0.16&26.35$\pm$0.77&22.98$\pm$0.54& 22.15$\pm$0.44\\
\textbf{+Ours}&26.02$\pm$0.31&\textbf{26.85$\pm$1.28}&\textbf{26.88$\pm$1.15}&\textbf{26.19$\pm$1.04}&28.26$\pm$0.57&\textbf{27.87$\pm$1.35}&\textbf{27.40$\pm$1.10}& \textbf{26.52$\pm$0.81}\\\hline
    \end{tabular}
    }
    \label{table:a5}
\end{table*}







\begin{table*}[!t]
\caption{
Average test accuracy ($\%$) with standard deviation on Yelp dataset with various imbalanced ratios (over 3 runs). The bold indicates the improved results by integrating our method.}
    \centering
    \resizebox{1\columnwidth}{!}{%
    \begin{tabular}{ccccccccc}
    \toprule
         $K$&  \multicolumn{4}{c}{8}&  \multicolumn{4}{c}{16}\\
\toprule
         \textbf{Imbalance Ratio}&  \textbf{0}&  \textbf{10}&  \textbf{50}&  \textbf{100} &  \textbf{0}&  \textbf{10}&  \textbf{50}& \textbf{100} \\
\midrule
Random&  
12.07$\pm$0.25&  15.73$\pm$0.34& 20.27$\pm$1.25&  21.33$\pm$0.52&  12.87$\pm$0.47&  20.33$\pm$0.96&  22.87$\pm$2.07& 23.87$\pm$0.41
\\
 \textbf{+Ours}& 
11.27$\pm$0.66& \textbf{20.13$\pm$0.98}& \textbf{19.13$\pm$1.11}& \textbf{22.40$\pm$2.41}&\textbf{13.20$\pm$0.28}& \textbf{15.60$\pm$0.86}& 20.40$\pm$1.14& \textbf{22.80$\pm$0.43}\\
 TopK& 
31.40$\pm$0.00& 29.67$\pm$1.20& 25.87$\pm$0.68& 25.33$\pm$0.66& 36.20$\pm$0.16& 32.47$\pm$1.06& 27.40$\pm$0.99&25.47$\pm$0.09
\\
\textbf{+Ours}&30.80$\pm$0.00& \textbf{29.83$\pm$1.01}& \textbf{27.87$\pm$1.05}& \textbf{26.20$\pm$1.23}& 33.60$\pm$0.85& 31.17$\pm$0.29& \textbf{29.93$\pm$0.52}&\textbf{27.13$\pm$0.98}
\\
 DPP& 
31.93$\pm$0.09& 30.00$\pm$0.49& 27.47$\pm$1.04& 26.20$\pm$1.02& 38.33$\pm$0.25& 32.93$\pm$1.11& 28.07$\pm$0.93&26.53$\pm$0.25
\\
\textbf{+Ours}& 31.60$\pm$0.85& \textbf{30.40$\pm$1.57}& \textbf{27.93$\pm$0.93}& \textbf{27.07$\pm$2.10}& 36.00$\pm$0.00& 30.73$\pm$0.66& \textbf{29.80$\pm$0.71}&\textbf{30.03$\pm$0.73}
\\
 VoteK& 28.80$\pm$0.16& 29.60$\pm$0.59& 27.07$\pm$1.39& 25.73$\pm$0.41& 36.13$\pm$0.09& 32.47$\pm$1.06& 27.40$\pm$0.99&25.47$\pm$0.09
\\
  \textbf{+Ours}& 28.93$\pm$0.74& 29.13$\pm$1.48& \textbf{27.87$\pm$0.62}& \textbf{26.47$\pm$0.66}&36.07$\pm$0.34& 32.47$\pm$1.06& \textbf{29.27$\pm$0.57}&\textbf{28.33$\pm$0.82}
\\
 ConE& 
28.47$\pm$1.32& 27.60$\pm$1.66& 24.93$\pm$1.05& 23.87$\pm$0.93& 36.87$\pm$0.38& 29.93$\pm$0.52& 25.93$\pm$0.09&24.13$\pm$0.47
\\
 \textbf{+Ours}& 
\textbf{29.13$\pm$0.38}& \textbf{27.93$\pm$0.41}& \textbf{26.33$\pm$1.72}& \textbf{25.20$\pm$0.49}& 34.53$\pm$0.09& \textbf{31.07$\pm$0.19}&\textbf{ 27.60$\pm$1.23}&\textbf{27.47$\pm$0.47}
\\
 ByDC& 31.73$\pm$0.09& 29.27$\pm$0.84& 26.80$\pm$1.02& 26.33$\pm$0.84& 37.53$\pm$0.34& 30.87$\pm$0.62& 26.47$\pm$0.57&24.80$\pm$0.43
\\
\textbf{+Ours}&  
31.47$\pm$0.25&  \textbf{30.27$\pm$0.19}& 27.80$\pm$0.72&  \textbf{27.27$\pm$0.74}&  35.20$\pm$0.16&  \textbf{31.53$\pm$0.34}& \textbf{28.80$\pm$1.50}& \textbf{28.13$\pm$1.46}
\\\hline Baselines&
27.40$\pm$0.32&26.98$\pm$0.85&25.40$\pm$1.07&24.80$\pm$0.73&32.99$\pm$0.28&29.83$\pm$0.89&26.36$\pm$0.94& 25.05$\pm$0.29
\\
\textbf{+Ours}&27.20$\pm$0.48&\textbf{27.95$\pm$0.94}&\textbf{26.16$\pm$1.02}&\textbf{25.77$\pm$1.27}
&31.43$\pm$0.29&28.76$\pm$0.57&\textbf{27.63$\pm$0.95}& \textbf{27.32$\pm$0.82}
\\\hline
    \end{tabular}
    }
    \label{table:a6}
\end{table*}
\begin{table}
\caption{The average Rouge score of CodeSearchNet dataset across six selection methods with various imbalance ratios. Bold numbers are the best results.}
    \centering
    \begin{tabular}{ccccc}
    \toprule
         \textbf{Imbalance Ratio}&  \textbf{0}&  \textbf{10}&  \textbf{50}& \textbf{100}\\
    \midrule
         Baselines&  15.99 &  13.26 &  11.41 & 9.84 
\\
 +Over-Sampling& 16.12 & 13.82 & 10.07 &8.56\\
 +Under-Sampling& 16.08 & 10.17 & 10.06 &9.20\\
 +Stratified-Sampling& 10.59 & 9.95 & 9.54 &9.24 
\\
 +Re-Weighting& 15.86 & 13.33 & 8.59&7.96\\
         \textbf{+Ours}&  15.71&  \textbf{13.64} &  \textbf{11.86} & \textbf{10.90} 
\\
    \hline
    \end{tabular}
    \label{table:a7}
\end{table}
\clearpage



\begin{figure}[t]
\centering % 确保整个figure*环境中的内容居中  
\subfigure[Yelp]{\includegraphics[width=0.33\textwidth]{Figure/Figure17.pdf}} % 
\subfigure[Yahoo]{\includegraphics[width=0.5\textwidth]{Figure/Figure18.pdf}}
\caption{The Kullback-Leibler (KL) divergence between $P_c(X|Y)$ and  $P_t(X|Y)$ for each class in the Yelp (a) and Yahoo (b) datasets.}
\label{figure:a3}
\end{figure}


\begin{figure}[t]
\centering % 确保整个figure*环境中的内容居中  
\subfigure[Llama3-8B]{\includegraphics[width=0.33\textwidth]{Figure/Figure19.pdf}} %
\subfigure[Mistral-7B]{\includegraphics[width=0.33\textwidth]{Figure/Figure20.pdf}} % 
\caption{Average accuracy of four classification tasks across six selection methods  ($K=16$)  for different large language models, including Llama3-8B \citep{llama3modelcard} and Mistral-7B \citep{jiang2023mistral}.}
\label{figure:a4}
\end{figure}


\begin{figure}[t]
\centering % 确保整个figure*环境中的内容居中  
{\includegraphics[width=0.5\textwidth]{Figure/Figure21.pdf}} %
\caption{Average accuracy of Emotion tasks across six existing selection methods using OPT-6.7B \citep{zhang2022opt}.}
\label{figure:a5}
\end{figure}

\begin{table}[t]
\caption{The statistics, split and evaluation metrics of each dataset.}
    \centering
    \begin{tabular}{ccclc}
    \toprule
         Data&  Train Set&  test dataset&  Classes&Evaluation\\
    \midrule
         Amazon &  25000&  1000&  5&Accuracy\\
 AgNews & 20000&  1000& 4&Accuracy\\
         Yelp&  25000&  1000&  5&Accuracy\\
 Yahoo& 50000& 500& 10&Accuracy\\
 Emotion& 20000& 300& 6&Accuracy\\
 Natural Question& 25000& 500& 5&Exact Match\\
 CodeSearchNet& 18000& 500& 6&Rouge\\
 \hline
    \end{tabular}
    \label{table:a1}
\end{table}


\begin{table}[t]
\caption{The instructions, inference templates and example cases of tasks.}
    \centering
    \resizebox{1\columnwidth}{!}{%
    \begin{tabular}{ccc}
    \toprule
         Dataset&  Prompt&  Example\\
    \midrule
         Amazon&  \makecell[l]{Task Instruction: Sentiment of the sentence\\ Inference Verbalizer: Great, Good, Okay, Bad, Terrible?\\ Input: \textit{Question} \\Output: \textit{Answer}} &  \makecell[l]{Task Instruction: Sentiment of the sentence\\ Inference Verbalizer: Great, Good, Okay, Bad, Terrible? \\Input: why give me a date for a month then when its suppose to ship, \\its running late \\Output: Terrible}\\ \hline
 AgNews& \makecell[l]{Task Instruction: Text Classification Task\\ Inference Verbalizer: World, Sports, Business or Science New Topic?\\ Input: \textit{Question} \\Output: \textit{Answer}}&\makecell[l]{Task Instruction: Text Classification Task \\Inference Verbalizer: World, Sports, Business or Science New Topic?\\ Input: EBay Buys 25 Percent Stake in Craigslist Network By MAY WONG  \\  SAN JOSE, Calif. (AP) -- Online auctioneer eBay Inc... \\Output: Science}\\
         \hline
         Yelp& \makecell[l]{Task Instruction: Sentiment of the sentence\\ Inference Verbalizer: Great, Good, Okay, Bad, Terrible?\\ Input: \textit{Question} \\Output: \textit{Answer}} &  \makecell[l]{Task Instruction: Sentiment of the sentence\\ Inference Verbalizer: Great, Good, Okay, Bad, Terrible? \\Input: Awesome place!!! You must go and try all the services!!!! \\Output: Good}\\
         \hline
         Yahoo & \makecell[l]{Topic of the text:\\ Society $\&$ Culture, Science $\&$ Mathematics, \\Health, Education $\&$ Reference, Computers $\&$ Internet,\\ Sports, Business $\&$ Finance, Entertainment $\&$ Music, \\Family $\&$ Relationships, Politics $\&$ Government?\\ Input: \textit{Question} \\Output: \textit{Answer}} &  \makecell[l]{Topic of the text: Society $\&$ Culture, Science $\&$ Mathematics, \\Health, Education $\&$ Reference, Computers $\&$ Internet,\\ Sports, Business $\&$ Finance, Entertainment $\&$ Music, \\Family $\&$ Relationships, Politics $\&$ Government?\\ Input: what is god's kingdom that we are told to pray for? \\Output: Computers $\&$ Internet} \\
    \hline
 Emotion& \makecell[l]{Task Instruction: Sentiment of the sentence \\Inference Verbalizer: Sadness, Joy, Love, Anger, Fear, Surprise? \\Input: \textit{Question} Output: \textit{Answer}}&\makecell[l]{Task Instruction: Sentiment of the sentence Inference \\Verbalizer: Sadness, Joy, Love, Anger, Fear, Surprise?\\ Input: \textit{im feeling generous this week}\\ Output: \textit{Joy}}\\ \hline
 NQ &\makecell[l]{Question: \textit{Question} \\Answer: \textit{Answer}}&\makecell[l]{Question: \textit{who is the CEO of what's up} \\Answer: \textit{Jan Koum}}\\ \hline
 CodeSearchNet& \makecell[l]{Summarize the code.\\ Input: \textit{Input}\\ Output: \textit{Output}}&\makecell[l]{Summarize the code.\\ Input: "func NewMessage() Message $\{$\\
	return Message$\{$\\
		Context: context.Background(),\\
		Headers: map[string]string$\{$$\}$,\\
		Data:    render.Data$\{$$\}$,\\
		moot:    $\&$sync.RWMutex{},$\}$$\}$"  \\Output: \textit{NewMessage builds a new message.}}\\ \hline
    \end{tabular}}
    
    \label{tabel:a2}
\end{table}




\end{document}


% This document was modified from the file originally made available by
% Pat Langley and Andrea Danyluk for ICML-2K. This version was created
% by Iain Murray in 2018, and modified by Alexandre Bouchard in
% 2019 and 2021 and by Csaba Szepesvari, Gang Niu and Sivan Sabato in 2022.
% Modified again in 2023 and 2024 by Sivan Sabato and Jonathan Scarlett.
% Previous contributors include Dan Roy, Lise Getoor and Tobias
% Scheffer, which was slightly modified from the 2010 version by
% Thorsten Joachims & Johannes Fuernkranz, slightly modified from the
% 2009 version by Kiri Wagstaff and Sam Roweis's 2008 version, which is
% slightly modified from Prasad Tadepalli's 2007 version which is a
% lightly changed version of the previous year's version by Andrew
% Moore, which was in turn edited from those of Kristian Kersting and
% Codrina Lauth. Alex Smola contributed to the algorithmic style files.
