\section{Discussion}
Our study highlights the critical intersection of privacy, trust, and relationship-building in teen social media use. By framing privacy as a shared, dynamic process rather than an individual burden, we propose design strategies that empower teens to regulate boundaries while fostering meaningful social connections. Specifically, our findings contribute (1) empirical insights into how teens navigate boundary regulation in social media environments based on trust levels, (2) identification of key design shortcomings that undermine trust-building, and (3) concrete design interventions that could better align with teens' developmental and social needs. 

Importantly, some of the design ideas and prototypes we discuss are inspired by existing features or implementations. However, our work extends their relevance by demonstrating how they contribute to \textit{\textbf{trust-enabled privacy}}. Rather than viewing these features in isolation, we show how they function to foster relationship-building, reduce social risk, and support dynamic boundary regulation. By centering \textbf{\textit{trust}} as the mechanism that integrates boundary regulation and relationship-building, our work offers a framework for designing social media platforms that are developmentally and socially attuned.


\subsection{Developmentally Sensitive Privacy Design: Relationship Building and Empowerment}
Prior work has emphasized that teens' privacy concerns are deeply relational~\cite{zhao2022understanding} and that boundary regulation is a co-managed, ongoing process in networked environments~\cite{marwick2014networked}. The ability to control what they share with specific audiences---ensuring that disclosures reach trusted friends while remaining shielded from unintended viewers such as teachers or potential employers---is essential~\cite{Sleeper-2013-PostWasntFacebook-m, Stutzman-2012-BoundaryRegulationMedia-n}. However, privacy is not merely about separating trusted and untrusted audiences; it is a fluid, iterative process shaped by ongoing interactions, trust-building, and trust erosion over time. Framing privacy solely as information restriction---an approach often reinforced by prevention-focused online safety strategies~\cite{Wisniewski-2018-PrivacyParadox-l}---can push teens toward withdrawal and disengagement~\cite{kim2025privacysocialnormsystematically}, ultimately denying them opportunities to develop and negotiate social relationships online. Given the developmental significance of relationship-building during adolescence~\cite{Davis2012-bq}, privacy protections should not come at the cost of self-disclosure, as sharing is a fundamental mechanism for forming and strengthening social connections. Worse, rigid privacy models that force teens into a false trade-off between privacy and connection may leave them prioritizing connection at the expense of privacy rather than enabling them to manage boundaries in a way that adapts to shifting relationships and evolving trust.

Teens, highly attuned to peer norms and the nuances of social dynamics~\cite{Somerville2013-zf, Steinberg2005-qy}, often perceive online self-disclosure as high-stakes~\cite{Yau2019-ab}. While increased sharing might seem risky, self-disclosure and privacy are not inherently at odds. Rather, privacy functions as a foundation that enables confident sharing, shaping the conditions under which disclosure feels safe or precarious. In environments of distrust, teens share less yet feel more vulnerable when privacy violations occur~\cite{Petronio2002-ce, Williams2023-jm}. Conversely, when privacy norms are well-supported and trust is reinforced, teens not only feel more comfortable disclosing but are also more likely to respect others' privacy and assert their own boundaries~\cite{kim2025privacysocialnormsystematically, Waldman2018-dc, GhaiumyAnaraky-2021-DiscloseNotAdults-l}. By fostering an environment where privacy is actively negotiated rather than rigidly enforced, platforms can encourage a culture of mutual respect---helping teens navigate boundary regulation with greater agency and confidence.



\subsection{Designed for Distrust: How Social Media Undermines Boundary Regulation}
% \input{inserts/audiences}
Our study reveals that social media platforms frequently undermine trust rather than fostering it. Many of the design elements that structure online sharing implicitly assume---or actively cultures---a low-trust environment where privacy must be actively defended rather than mutually respected. 

One way platforms introduce distrust is by failing to provide adequate mechanisms for audience calibration. Teens often experience what we term \textit{communication fog}---uncertainty about how their disclosures will be received, who their audience truly is, and whether their content will be judged negatively. Unlike offline interactions, where trust is built through incremental, reciprocated disclosures, social media often forces teens to share with an ambiguous or overly broad audience. Our findings show that this ambiguity discourages engagement, as teens either self-censor to avoid risk or withdraw from participation altogether.

Additionally, platform norms contribute to a \textit{low-grace culture}, in which teens feel they have little room for casual, low-stakes sharing. The expectation of curated, polished self-presentation heightens the stakes of posting, making boundary negotiation more precarious. Given that privacy and trust are co-regulated rather than individually determined, this cultural expectation exacerbates feelings of vulnerability and discourages trust development. For example, the non-consensual nature of content distribution---where posts automatically appear in others' feeds without explicit consent~\cite{Im2021-ri}---creates turbulence in boundary regulation. 



\subsection{Design Guidelines for Teen User Social Media Privacy}
Our study shows the need for design interventions that recognize privacy as a relational process rather than individual responsibility. We propose four key design guidelines to support teens in managing privacy through trust-based interactions:

\parHeading{Contextualized and Bilateral Agreement in Sharing} Platforms should enable more intentional and segmented sharing spaces by allowing viewers to opt into specific types of content rather than receiving posts passively. This approach---resembling those on Discord---allows both sharers and audiences to establish more explicit and mutual expectations around visibility and engagement, reducing the ambiguity and pressure surrounding audience expectations. Further, supporting self-curated, interest-based spaces can empower teens to share more thoughtfully within relevant social circles. Platforms can better align privacy practices with evolving relationships by giving viewers a role in boundary regulation.

\parHeading{Options for Thoughtful, Low-Stakes Sharing} When contextualized sharing is difficult---such as in cases of large and ambiguous followings---platforms should provide lightweight, low-stakes ways to engage in self-disclosure with minimal social risk. Features like ephemeral posts, subtle status updates (e.g., updating music on a profile), and fostering norms of casual/frequent sharing can help users engage in disclosure without feeling exposed. Additionally, mechanisms should be in place to prevent unnecessary friction that erodes trust, such as ensuring that posts do not automatically take up space in others' feeds or allowing users to preemptively clarify context before sharing.    

\parHeading{Better Social Signals for Trust-Building and Boundary Regulation} Trust grows through repeated interactions, yet existing social media designs often lack meaningful signals for trust reinforcement. Platforms should introduce more deliberate and contextual social signals that help users gauge engagement, interest, and boundary norms. Platforms should introduce more meaningful social signals beyond ``Likes,'' including reactions tailored to content, quiet acknowledgments, or lightweight affirmations that reassure sharers. Clearer cues about audience composition and engagement (e.g., viewer interests, soft indicators of reciprocation) can also help users make more informed (and confident) privacy decisions.

\parHeading{Towards Collective Norms for Trust-Building} Privacy is fundamentally norm-based. Rather than placing the full burden of privacy management on individual users, platforms should establish shared norms that define and reinforce responsible boundary regulation. By making privacy a collective responsibility---through platform-wide expectations, accountability mechanisms, and proactive enforcement---social media can foster an environment where users feel supported in their privacy choices rather than left to navigate complex social dynamics alone.



\subsection{Limitations and Future Work}
Our participants were recruited through Instagram advertisements, meaning all participants were Instagram users. While our study did not focus on any specific social media platform, many participants shared their experiences primarily related to Instagram. This could indicate that teens perceive Instagram as the most representative of ``social media.'' However, the recruitment method may have influenced this outcome, as frequent Instagram users were more likely to engage with our study. Additionally, all participants were based in the U.S., potentially limiting the broader application of our findings since platform preferences and cultural norms around interpersonal interactions differ across countries and cultures. Furthermore, the sample was skewed, with girls and older adolescents overrepresented.

Our research centered on facilitating meaningful self-disclosure among teens, particularly with peers they do not yet fully trust. However, it is important to note that social desirability bias~\cite{fisher1993social} may have affected participants' responses. The issue of ``oversharing'' to the point of compromising privacy without receiving social validation remains prevalent. We did not explore privacy concerns like screenshots, privacy breaches, or the broader risks of content being shared out of context---issues that remain critical in the research community. While our focus was on strength-based and resilience-forward approaches to meaningful self-disclosure that foster relationship-building, we acknowledge the risks of self-disclosure without adequate safeguards.

Lastly, our design prototypes were hypothetical. Future studies should aim to iterate on and develop concrete prototypes to validate these design concepts.
