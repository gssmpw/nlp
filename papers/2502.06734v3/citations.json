[
  {
    "index": 0,
    "papers": [
      {
        "key": "other_ddim_huberman2024edit",
        "author": "Huberman-Spiegelglas, Inbar and Kulikov, Vladimir and Michaeli, Tomer",
        "title": "An edit friendly ddpm noise space: Inversion and manipulations"
      },
      {
        "key": "other_ddim_lu2022dpm",
        "author": "Lu, Cheng and Zhou, Yuhao and Bao, Fan and Chen, Jianfei and Li, Chongxuan and Zhu, Jun",
        "title": "Dpm-solver++: Fast solver for guided sampling of diffusion probabilistic models"
      },
      {
        "key": "other_ddim_wallace2023edict",
        "author": "Wallace, Bram and Gokul, Akash and Naik, Nikhil",
        "title": "Edict: Exact diffusion inversion via coupled transformations"
      }
    ]
  },
  {
    "index": 1,
    "papers": [
      {
        "key": "sdedit_meng2021sdedit",
        "author": "Meng, Chenlin and He, Yutong and Song, Yang and Song, Jiaming and Wu, Jiajun and Zhu, Jun-Yan and Ermon, Stefano",
        "title": "Sdedit: Guided image synthesis and editing with stochastic differential equations"
      }
    ]
  },
  {
    "index": 2,
    "papers": [
      {
        "key": "prompt_to_prompt_hertz2022prompt",
        "author": "Hertz, Amir and Mokady, Ron and Tenenbaum, Jay and Aberman, Kfir and Pritch, Yael and Cohen-Or, Daniel",
        "title": "Prompt-to-prompt image editing with cross attention control"
      }
    ]
  },
  {
    "index": 3,
    "papers": [
      {
        "key": "null_text_inversion_mokady2023null",
        "author": "Mokady, Ron and Hertz, Amir and Aberman, Kfir and Pritch, Yael and Cohen-Or, Daniel",
        "title": "Null-text inversion for editing real images using guided diffusion models"
      }
    ]
  },
  {
    "index": 4,
    "papers": [
      {
        "key": "instructpix2pix_brooks2023instructpix2pix",
        "author": "Brooks, Tim and Holynski, Aleksander and Efros, Alexei A",
        "title": "Instructpix2pix: Learning to follow image editing instructions"
      }
    ]
  },
  {
    "index": 5,
    "papers": [
      {
        "key": "hive_zhang2024hive",
        "author": "Zhang, Shu and Yang, Xinyi and Feng, Yihao and Qin, Can and Chen, Chia-Chih and Yu, Ning and Chen, Zeyuan and Wang, Huan and Savarese, Silvio and Ermon, Stefano and others",
        "title": "Hive: Harnessing human feedback for instructional visual editing"
      }
    ]
  },
  {
    "index": 6,
    "papers": [
      {
        "key": "magic_brush_zhang2024magicbrush",
        "author": "Zhang, Kai and Mo, Lingbo and Chen, Wenhu and Sun, Huan and Su, Yu",
        "title": "Magicbrush: A manually annotated dataset for instruction-guided image editing"
      }
    ]
  },
  {
    "index": 7,
    "papers": [
      {
        "key": "fatezero_qi2023fatezero",
        "author": "Qi, Chenyang and Cun, Xiaodong and Zhang, Yong and Lei, Chenyang and Wang, Xintao and Shan, Ying and Chen, Qifeng",
        "title": "Fatezero: Fusing attentions for zero-shot text-based video editing"
      },
      {
        "key": "stablev2v_liu2024stablev2v",
        "author": "Liu, Chang and Li, Rui and Zhang, Kaidong and Lan, Yunwei and Liu, Dong",
        "title": "StableV2V: Stablizing Shape Consistency in Video-to-Video Editing"
      }
    ]
  },
  {
    "index": 8,
    "papers": [
      {
        "key": "tuneavideo_wu2023tune",
        "author": "Wu, Jay Zhangjie and Ge, Yixiao and Wang, Xintao and Lei, Stan Weixian and Gu, Yuchao and Shi, Yufei and Hsu, Wynne and Shan, Ying and Qie, Xiaohu and Shou, Mike Zheng",
        "title": "Tune-a-video: One-shot tuning of image diffusion models for text-to-video generation"
      }
    ]
  },
  {
    "index": 9,
    "papers": [
      {
        "key": "pix2video_ceylan2023pix2video",
        "author": "Ceylan, Duygu and Huang, Chun-Hao P and Mitra, Niloy J",
        "title": "Pix2video: Video editing using image diffusion"
      }
    ]
  },
  {
    "index": 10,
    "papers": [
      {
        "key": "tokenflow_geyer2023tokenflow",
        "author": "Geyer, Michal and Bar-Tal, Omer and Bagon, Shai and Dekel, Tali",
        "title": "Tokenflow: Consistent diffusion features for consistent video editing"
      }
    ]
  },
  {
    "index": 11,
    "papers": [
      {
        "key": "ku2024anyv2v",
        "author": "Ku, Max and Wei, Cong and Ren, Weiming and Yang, Huan and Chen, Wenhu",
        "title": "Anyv2v: A plug-and-play framework for any video-to-video editing tasks"
      }
    ]
  },
  {
    "index": 12,
    "papers": [
      {
        "key": "gen3",
        "author": "{Gen-3}",
        "title": "Introducing Gen-3 Alpha: A New Frontier for Video Generation"
      }
    ]
  },
  {
    "index": 13,
    "papers": [
      {
        "key": "sora",
        "author": "OpenAI",
        "title": "Sora: Creating video from text"
      }
    ]
  },
  {
    "index": 14,
    "papers": [
      {
        "key": "insv2v_cheng2024consistent",
        "author": "Jiaxin Cheng and Tianjun Xiao and Tong He",
        "title": "Consistent Video-to-Video Transfer Using Synthetic Dataset"
      }
    ]
  },
  {
    "index": 15,
    "papers": [
      {
        "key": "eve_singer2025video",
        "author": "Singer, Uriel and Zohar, Amit and Kirstain, Yuval and Sheynin, Shelly and Polyak, Adam and Parikh, Devi and Taigman, Yaniv",
        "title": "Video editing via factorized diffusion distillation"
      }
    ]
  },
  {
    "index": 16,
    "papers": [
      {
        "key": "dreamfusion_poole2022dreamfusion",
        "author": "Poole, Ben and Jain, Ajay and Barron, Jonathan T and Mildenhall, Ben",
        "title": "Dreamfusion: Text-to-3d using 2d diffusion"
      }
    ]
  },
  {
    "index": 17,
    "papers": [
      {
        "key": "raccon_yoon2024raccoonremoveaddchange",
        "author": "Jaehong Yoon and Shoubin Yu and Mohit Bansal",
        "title": "RACCooN: Remove, Add, and Change Video Content with Auto-Generated Narratives"
      }
    ]
  },
  {
    "index": 18,
    "papers": [
      {
        "key": "vivid_10m_hu2024vivid",
        "author": "Hu, Jiahao and Zhong, Tianxiong and Wang, Xuebo and Jiang, Boyuan and Tian, Xingye and Yang, Fei and Wan, Pengfei and Zhang, Di",
        "title": "VIVID-10M: A Dataset and Baseline for Versatile and Interactive Video Local Editing"
      }
    ]
  },
  {
    "index": 19,
    "papers": [
      {
        "key": "propgen_liu2024generative",
        "author": "Liu, Shaoteng and Wang, Tianyu and Wang, Jui-Hsien and Liu, Qing and Zhang, Zhifei and Lee, Joon-Young and Li, Yijun and Yu, Bei and Lin, Zhe and Kim, Soo Ye and others",
        "title": "Generative Video Propagation"
      }
    ]
  },
  {
    "index": 20,
    "papers": [
      {
        "key": "instructpix2pix_brooks2023instructpix2pix",
        "author": "Brooks, Tim and Holynski, Aleksander and Efros, Alexei A",
        "title": "Instructpix2pix: Learning to follow image editing instructions"
      }
    ]
  },
  {
    "index": 21,
    "papers": [
      {
        "key": "magic_brush_zhang2024magicbrush",
        "author": "Zhang, Kai and Mo, Lingbo and Chen, Wenhu and Sun, Huan and Su, Yu",
        "title": "Magicbrush: A manually annotated dataset for instruction-guided image editing"
      }
    ]
  },
  {
    "index": 22,
    "papers": [
      {
        "key": "dalle2_ramesh2022hierarchical",
        "author": "Ramesh, Aditya and Dhariwal, Prafulla and Nichol, Alex and Chu, Casey and Chen, Mark",
        "title": "Hierarchical text-conditional image generation with clip latents"
      }
    ]
  },
  {
    "index": 23,
    "papers": [
      {
        "key": "hq_edit_hui2024hq",
        "author": "Hui, Mude and Yang, Siwei and Zhao, Bingchen and Shi, Yichun and Wang, Heng and Wang, Peng and Zhou, Yuyin and Xie, Cihang",
        "title": "Hq-edit: A high-quality dataset for instruction-based image editing"
      }
    ]
  },
  {
    "index": 24,
    "papers": [
      {
        "key": "dalle3_betker2023improving",
        "author": "Betker, James and Goh, Gabriel and Jing, Li and Brooks, Tim and Wang, Jianfeng and Li, Linjie and Ouyang, Long and Zhuang, Juntang and Lee, Joyce and Guo, Yufei and others",
        "title": "Improving image generation with better captions"
      }
    ]
  },
  {
    "index": 25,
    "papers": [
      {
        "key": "emu_edit_sheynin2024emu",
        "author": "Sheynin, Shelly and Polyak, Adam and Singer, Uriel and Kirstain, Yuval and Zohar, Amit and Ashual, Oron and Parikh, Devi and Taigman, Yaniv",
        "title": "Emu edit: Precise image editing via recognition and generation tasks"
      }
    ]
  },
  {
    "index": 26,
    "papers": [
      {
        "key": "ultraedit_zhao2024ultraedit",
        "author": "Zhao, Haozhe and Ma, Xiaojian and Chen, Liang and Si, Shuzheng and Wu, Rujie and An, Kaikai and Yu, Peiyu and Zhang, Minjia and Li, Qing and Chang, Baobao",
        "title": "UltraEdit: Instruction-based Fine-Grained Image Editing at Scale"
      }
    ]
  },
  {
    "index": 27,
    "papers": [
      {
        "key": "omniedit_wei2024omniedit",
        "author": "Wei, Cong and Xiong, Zheyang and Ren, Weiming and Du, Xinrun and Zhang, Ge and Chen, Wenhu",
        "title": "OmniEdit: Building Image Editing Generalist Models Through Specialist Supervision"
      }
    ]
  },
  {
    "index": 28,
    "papers": [
      {
        "key": "raccon_yoon2024raccoonremoveaddchange",
        "author": "Jaehong Yoon and Shoubin Yu and Mohit Bansal",
        "title": "RACCooN: Remove, Add, and Change Video Content with Auto-Generated Narratives"
      }
    ]
  },
  {
    "index": 29,
    "papers": [
      {
        "key": "insv2v_cheng2024consistent",
        "author": "Jiaxin Cheng and Tianjun Xiao and Tong He",
        "title": "Consistent Video-to-Video Transfer Using Synthetic Dataset"
      }
    ]
  }
]