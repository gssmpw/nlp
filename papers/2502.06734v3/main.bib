% Long form of conference & journal abbreviations -- especially for camera ready
@String(PAMI  = {IEEE Trans. Pattern Anal. Mach. Intell.})
@String(IJCV  = {Int. J. Comput. Vis.})
@String(CVPR  = {IEEE Conf. Comput. Vis. Pattern Recog.})
@String(ICCV  = {Int. Conf. Comput. Vis.})
@String(ECCV  = {Eur. Conf. Comput. Vis.})
@String(NeurIPS = {Adv. Neural Inform. Process. Syst.})
@String(ICML  = {Int. Conf. Mach. Learn.})
@String(ICLR  = {Int. Conf. Learn. Represent.})
@String(ACCV  = {Asian Conf. Comput. Vis.})
@String(BMVC  = {Brit. Mach. Vis. Conf.})
@String(CVPRW = {IEEE Conf. Comput. Vis. Pattern Recog. Worksh.})
@String(AAAI  = {AAAI})
@String(IJCAI = {IJCAI})
@String(ICIP  = {IEEE Int. Conf. Image Process.})
@String(ICPR  = {Int. Conf. Pattern Recog.})
@String(ICASSP=	{ICASSP})
@String(ICME  = {Int. Conf. Multimedia and Expo})
@String(JMLR  = {J. Mach. Learn. Res.})
@String(TMLR  = {Trans. Mach. Learn Res.})
@String(TOG   = {ACM Trans. Graph.})
@String(TIP   = {IEEE Trans. Image Process.})
@String(TVCG  = {IEEE Trans. Vis. Comput. Graph.})
@String(TCSVT = {IEEE Trans. Circuit Syst. Video Technol.})
@String(TMM   = {IEEE Trans. Multimedia})
@String(ACMMM = {ACM Int. Conf. Multimedia})
@String(PR    = {Pattern Recognition})

@String(MNI	  = {Nature Mach. Intell.})
@String(SPL	  = {IEEE Sign. Process. Letters})
@String(VR    = {Vis. Res.})
@String(JOV	  = {J. Vis.})
@String(TVC   = {The Vis. Comput.})
@String(JCST  = {J. Comput. Sci. Tech.})
@String(CGF   = {Comput. Graph. Forum})
@String(CVM   = {Computational Visual Media})


% Short form of conference & journal abbreviations -- especially for submission version
% if desired, remove these macros in favor of the above ones
@String(PAMI  = {IEEE TPAMI})
@String(IJCV  = {IJCV})
@String(CVPR  = {CVPR})
@String(ICCV  = {ICCV})
@String(ECCV  = {ECCV})
@String(NeurIPS = {NeurIPS})
@String(ICML  = {ICML})
@String(ICLR  = {ICLR})
@String(ACCV  = {ACCV})
@String(BMVC  =	{BMVC})
@String(CVPRW = {CVPRW})
@String(AAAI  = {AAAI})
@String(IJCAI = {IJCAI})
@String(ICIP  = {ICIP})
@String(ICPR  = {ICPR})
@String(ICASSP=	{ICASSP})
@String(ICME  =	{ICME})
@String(JMLR  = {JMLR})
@String(TMLR  = {TMLR})
@String(TOG   = {ACM TOG})
@String(TIP   = {IEEE TIP})
@String(TVCG  = {IEEE TVCG})
@String(TCSVT = {IEEE TCSVT})
@String(TMM   =	{IEEE TMM})
@String(ACMMM = {ACM MM})
@String(PR    = {PR})



@String(PAMI = {IEEE Trans. Pattern Anal. Mach. Intell.})
@String(IJCV = {Int. J. Comput. Vis.})
@String(CVPR= {IEEE Conf. Comput. Vis. Pattern Recog.})
@String(ICCV= {Int. Conf. Comput. Vis.})
@String(ECCV= {Eur. Conf. Comput. Vis.})
@String(NIPS= {Adv. Neural Inform. Process. Syst.})
@String(ICPR = {Int. Conf. Pattern Recog.})
@String(BMVC= {Brit. Mach. Vis. Conf.})
@String(TOG= {ACM Trans. Graph.})
@String(TIP  = {IEEE Trans. Image Process.})
@String(TVCG  = {IEEE Trans. Vis. Comput. Graph.})
@String(TMM  = {IEEE Trans. Multimedia})
@String(ACMMM= {ACM Int. Conf. Multimedia})
@String(ICME = {Int. Conf. Multimedia and Expo})
@String(ICASSP=	{ICASSP})
@String(ICIP = {IEEE Int. Conf. Image Process.})
@String(ACCV  = {ACCV})
@String(ICLR = {Int. Conf. Learn. Represent.})
@String(IJCAI = {IJCAI})
@String(PR   = {Pattern Recognition})
@String(AAAI = {AAAI})
@String(CVPRW= {IEEE Conf. Comput. Vis. Pattern Recog. Worksh.})
@String(CSVT = {IEEE Trans. Circuit Syst. Video Technol.})

@String(SPL	= {IEEE Sign. Process. Letters})
@String(VR   = {Vis. Res.})
@String(JOV	 = {J. Vis.})
@String(TVC  = {The Vis. Comput.})
@String(JCST  = {J. Comput. Sci. Tech.})
@String(CGF  = {Comput. Graph. Forum})
@String(CVM = {Computational Visual Media})


@article{adamw_loshchilov2017decoupled,
  title={Decoupled weight decay regularization},
  author={Loshchilov, Ilya and Hutter, Frank},
  journal={arXiv preprint arXiv:1711.05101},
  year={2017}
}

@article{t5_raffel2020exploring,
  title={Exploring the limits of transfer learning with a unified text-to-text transformer},
  author={Raffel, Colin and Shazeer, Noam and Roberts, Adam and Lee, Katherine and Narang, Sharan and Matena, Michael and Zhou, Yanqi and Li, Wei and Liu, Peter J},
  journal={The Journal of Machine Learning Research},
  volume={21},
  number={1},
  pages={5485--5551},
  year={2020},
  publisher={JMLRORG}
}

@article{beit3_wang2022image,
  title={Image as a foreign language: Beit pretraining for all vision and vision-language tasks},
  author={Wang, Wenhui and Bao, Hangbo and Dong, Li and Bjorck, Johan and Peng, Zhiliang and Liu, Qiang and Aggarwal, Kriti and Mohammed, Owais Khan and Singhal, Saksham and Som, Subhojit and others},
  journal={arXiv preprint arXiv:2208.10442},
  year={2022}
}

@misc{modelscope_wang2023modelscope,
      title={ModelScope Text-to-Video Technical Report}, 
      author={Jiuniu Wang and Hangjie Yuan and Dayou Chen and Yingya Zhang and Xiang Wang and Shiwei Zhang},
      year={2023},
      eprint={2308.06571},
      archivePrefix={arXiv},
      primaryClass={cs.CV}
}

@inproceedings{gen1_esser2023structure,
  title={Structure and content-guided video synthesis with diffusion models},
  author={Esser, Patrick and Chiu, Johnathan and Atighehchian, Parmida and Granskog, Jonathan and Germanidis, Anastasis},
  booktitle={Proceedings of the IEEE/CVF International Conference on Computer Vision},
  pages={7346--7356},
  year={2023}
}


@article{sora_videoworldsimulators2024,
  title={Video generation models as world simulators},
  author={Tim Brooks and Bill Peebles and Connor Holmes and Will DePue and Yufei Guo and Li Jing and David Schnurr and Joe Taylor and Troy Luhman and Eric Luhman and Clarence Ng and Ricky Wang and Aditya Ramesh},
  year={2024},
  url={https://openai.com/research/video-generation-models-as-world-simulators},
}
@inproceedings{zheng2022image,
  title={Image inpainting with cascaded modulation gan and object-aware training},
  author={Zheng, Haitian and Lin, Zhe and Lu, Jingwan and Cohen, Scott and Shechtman, Eli and Barnes, Connelly and Zhang, Jianming and Xu, Ning and Amirghodsi, Sohrab and Luo, Jiebo},
  booktitle={ECCV},
  year={2022}
}

@article{Dynamicrafter_xing2023dynamicrafter,
  title={Dynamicrafter: Animating open-domain images with video diffusion priors},
  author={Xing, Jinbo and Xia, Menghan and Zhang, Yong and Chen, Haoxin and Wang, Xintao and Wong, Tien-Tsin and Shan, Ying},
  journal={arXiv preprint arXiv:2310.12190},
  year={2023}
}


@article{stablevideodiffusion_blattmann2023stable,
  title={Stable video diffusion: Scaling latent video diffusion models to large datasets},
  author={Blattmann, Andreas and Dockhorn, Tim and Kulal, Sumith and Mendelevitch, Daniel and Kilian, Maciej and Lorenz, Dominik and Levi, Yam and English, Zion and Voleti, Vikram and Letts, Adam and others},
  journal={arXiv preprint arXiv:2311.15127},
  year={2023}
}

@inproceedings{controlnet_zhang2023adding,
  title={Adding conditional control to text-to-image diffusion models},
  author={Zhang, Lvmin and Rao, Anyi and Agrawala, Maneesh},
  booktitle={Proceedings of the IEEE/CVF International Conference on Computer Vision},
  pages={3836--3847},
  year={2023}
}

@article{lora_hu2021lora,
  title={Lora: Low-rank adaptation of large language models},
  author={Hu, Edward J and Shen, Yelong and Wallis, Phillip and Allen-Zhu, Zeyuan and Li, Yuanzhi and Wang, Shean and Wang, Lu and Chen, Weizhu},
  journal={arXiv preprint arXiv:2106.09685},
  year={2021}
}



@article{Diffedit_couairon2022diffedit,
  title={Diffedit: Diffusion-based semantic image editing with mask guidance},
  author={Couairon, Guillaume and Verbeek, Jakob and Schwenk, Holger and Cord, Matthieu},
  journal={arXiv preprint arXiv:2210.11427},
  year={2022}
}



@article{cogview2_ding2022cogview2,
  title={Cogview2: Faster and better text-to-image generation via hierarchical transformers},
  author={Ding, Ming and Zheng, Wendi and Hong, Wenyi and Tang, Jie},
  journal={Advances in Neural Information Processing Systems},
  volume={35},
  pages={16890--16902},
  year={2022}
}



@article{groundingdino_liu2023grounding,
  title={Grounding dino: Marrying dino with grounded pre-training for open-set object detection},
  author={Liu, Shilong and Zeng, Zhaoyang and Ren, Tianhe and Li, Feng and Zhang, Hao and Yang, Jie and Li, Chunyuan and Yang, Jianwei and Su, Hang and Zhu, Jun and others},
  journal={arXiv preprint arXiv:2303.05499},
  year={2023}
}


@article{dalle3_betker2023improving,
  title={Improving image generation with better captions},
  author={Betker, James and Goh, Gabriel and Jing, Li and Brooks, Tim and Wang, Jianfeng and Li, Linjie and Ouyang, Long and Zhuang, Juntang and Lee, Joyce and Guo, Yufei and others},
  journal={Computer Science. https://cdn.openai.com/papers/dall-e-3. pdf},
  volume={2},
  number={3},
  pages={8},
  year={2023}
}

@article{videocrafter2_chen2024videocrafter2,
  title={Videocrafter2: Overcoming data limitations for high-quality video diffusion models},
  author={Chen, Haoxin and Zhang, Yong and Cun, Xiaodong and Xia, Menghan and Wang, Xintao and Weng, Chao and Shan, Ying},
  journal={arXiv preprint arXiv:2401.09047},
  year={2024}
}

@inproceedings{dalle1_ramesh2021zero,
  title={Zero-shot text-to-image generation},
  author={Ramesh, Aditya and Pavlov, Mikhail and Goh, Gabriel and Gray, Scott and Voss, Chelsea and Radford, Alec and Chen, Mark and Sutskever, Ilya},
  booktitle={International Conference on Machine Learning},
  pages={8821--8831},
  year={2021},
  organization={PMLR}
}



@article{animatediff_guo2023animatediff,
  title={AnimateDiff: Animate Your Personalized Text-to-Image Diffusion Models without Specific Tuning},
  author={Guo, Yuwei and Yang, Ceyuan and Rao, Anyi and Wang, Yaohui and Qiao, Yu and Lin, Dahua and Dai, Bo},
  journal={arXiv preprint arXiv:2307.04725},
  year={2023}
}
@article{liew2023magicedit,
  title={MagicEdit: High-Fidelity and Temporally Coherent Video Editing},
  author={Liew, Jun Hao and Yan, Hanshu and Zhang, Jianfeng and Xu, Zhongcong and Feng, Jiashi},
  journal={arXiv preprint arXiv:2308.14749},
  year={2023}
}
@article{wang2023videocomposer,
  title={VideoComposer: Compositional Video Synthesis with Motion Controllability},
  author={Wang, Xiang and Yuan, Hangjie and Zhang, Shiwei and Chen, Dayou and Wang, Jiuniu and Zhang, Yingya and Shen, Yujun and Zhao, Deli and Zhou, Jingren},
  journal={arXiv preprint arXiv:2306.02018},
  year={2023}
}
@article{zhao2023make,
  title={Make-A-Protagonist: Generic Video Editing with An Ensemble of Experts},
  author={Zhao, Yuyang and Xie, Enze and Hong, Lanqing and Li, Zhenguo and Lee, Gim Hee},
  journal={arXiv preprint arXiv:2305.08850},
  year={2023}
}
@inproceedings{zhang2023adding,
  title={Adding conditional control to text-to-image diffusion models},
  author={Zhang, Lvmin and Rao, Anyi and Agrawala, Maneesh},
  booktitle={Proceedings of the IEEE/CVF International Conference on Computer Vision},
  pages={3836--3847},
  year={2023}
}

@inproceedings{rombach2022high,
  title={High-resolution image synthesis with latent diffusion models},
  author={Rombach, Robin and Blattmann, Andreas and Lorenz, Dominik and Esser, Patrick and Ommer, Bj{\"o}rn},
  booktitle={Proceedings of the IEEE/CVF conference on computer vision and pattern recognition},
  pages={10684--10695},
  year={2022}
}

@article{wang2023zero,
  title={Zero-shot video editing using off-the-shelf image diffusion models},
  author={Wang, Wen and Xie, Kangyang and Liu, Zide and Chen, Hao and Cao, Yue and Wang, Xinlong and Shen, Chunhua},
  journal={arXiv preprint arXiv:2303.17599},
  year={2023}
}
@article{khachatryan2023text2video,
  title={Text2video-zero: Text-to-image diffusion models are zero-shot video generators},
  author={Khachatryan, Levon and Movsisyan, Andranik and Tadevosyan, Vahram and Henschel, Roberto and Wang, Zhangyang and Navasardyan, Shant and Shi, Humphrey},
  journal={arXiv preprint arXiv:2303.13439},
  year={2023}
}
@article{an2023latent,
  title={Latent-shift: Latent diffusion with temporal shift for efficient text-to-video generation},
  author={An, Jie and Zhang, Songyang and Yang, Harry and Gupta, Sonal and Huang, Jia-Bin and Luo, Jiebo and Yin, Xi},
  journal={arXiv preprint arXiv:2304.08477},
  year={2023}
}
@article{schuhmann2021laion,
  title={Laion-400m: Open dataset of clip-filtered 400 million image-text pairs},
  author={Schuhmann, Christoph and Vencu, Richard and Beaumont, Romain and Kaczmarczyk, Robert and Mullis, Clayton and Katta, Aarush and Coombes, Theo and Jitsev, Jenia and Komatsuzaki, Aran},
  journal={arXiv preprint arXiv:2111.02114},
  year={2021}
}

@article{liu2023grounding,
  title={Grounding dino: Marrying dino with grounded pre-training for open-set object detection},
  author={Liu, Shilong and Zeng, Zhaoyang and Ren, Tianhe and Li, Feng and Zhang, Hao and Yang, Jie and Li, Chunyuan and Yang, Jianwei and Su, Hang and Zhu, Jun and others},
  journal={arXiv preprint arXiv:2303.05499},
  year={2023}
}

@article{kirillov2023segment,
  title={Segment anything},
  author={Kirillov, Alexander and Mintun, Eric and Ravi, Nikhila and Mao, Hanzi and Rolland, Chloe and Gustafson, Laura and Xiao, Tete and Whitehead, Spencer and Berg, Alexander C and Lo, Wan-Yen and others},
  journal={arXiv preprint arXiv:2304.02643},
  year={2023}
}
@inproceedings{xmem_cheng2022xmem,
  title={{XMem}: Long-Term Video Object Segmentation with an Atkinson-Shiffrin Memory Model},
  author={Cheng, Ho Kei and Alexander G. Schwing},
  booktitle={ECCV},
  year={2022}
}
@misc{openai2023gpt4,
      title={GPT-4 Technical Report}, 
      author={OpenAI},
      year={2023},
      eprint={2303.08774},
      archivePrefix={arXiv},
      primaryClass={cs.CL}
}
@article{ho2020denoising,
  title={Denoising diffusion probabilistic models},
  author={Ho, Jonathan and Jain, Ajay and Abbeel, Pieter},
  journal={Advances in neural information processing systems},
  volume={33},
  pages={6840--6851},
  year={2020}
}
@inproceedings{bain2021frozen,
  title={Frozen in time: A joint video and image encoder for end-to-end retrieval},
  author={Bain, Max and Nagrani, Arsha and Varol, G{\"u}l and Zisserman, Andrew},
  booktitle={Proceedings of the IEEE/CVF International Conference on Computer Vision},
  pages={1728--1738},
  year={2021}
}
@article{vaswani2017attention,
  title={Attention is all you need},
  author={Vaswani, Ashish and Shazeer, Noam and Parmar, Niki and Uszkoreit, Jakob and Jones, Llion and Gomez, Aidan N and Kaiser, {\L}ukasz and Polosukhin, Illia},
  journal={Advances in neural information processing systems},
  volume={30},
  year={2017}
}
@inproceedings{bar2023multidiffusion,
  author       = {Omer Bar{-}Tal and
                  Lior Yariv and
                  Yaron Lipman and
                  Tali Dekel},
  editor       = {Andreas Krause and
                  Emma Brunskill and
                  Kyunghyun Cho and
                  Barbara Engelhardt and
                  Sivan Sabato and
                  Jonathan Scarlett},
  title        = {MultiDiffusion: Fusing Diffusion Paths for Controlled Image Generation},
  booktitle    = {International Conference on Machine Learning, {ICML} 2023, 23-29 July
                  2023, Honolulu, Hawaii, {USA}},
  series       = {Proceedings of Machine Learning Research},
  volume       = {202},
  pages        = {1737--1752},
  publisher    = {{PMLR}},
  year         = {2023},
  url          = {https://proceedings.mlr.press/v202/bar-tal23a.html},
  timestamp    = {Mon, 28 Aug 2023 17:23:08 +0200},
  biburl       = {https://dblp.org/rec/conf/icml/Bar-TalYLD23.bib},
  bibsource    = {dblp computer science bibliography, https://dblp.org}
}

@inproceedings{glide_nichol2021glide,
  author       = {Alexander Quinn Nichol and
                  Prafulla Dhariwal and
                  Aditya Ramesh and
                  Pranav Shyam and
                  Pamela Mishkin and
                  Bob McGrew and
                  Ilya Sutskever and
                  Mark Chen},
  editor       = {Kamalika Chaudhuri and
                  Stefanie Jegelka and
                  Le Song and
                  Csaba Szepesv{\'{a}}ri and
                  Gang Niu and
                  Sivan Sabato},
  title        = {{GLIDE:} Towards Photorealistic Image Generation and Editing with
                  Text-Guided Diffusion Models},
  booktitle    = {International Conference on Machine Learning, {ICML} 2022, 17-23 July
                  2022, Baltimore, Maryland, {USA}},
  series       = {Proceedings of Machine Learning Research},
  volume       = {162},
  pages        = {16784--16804},
  publisher    = {{PMLR}},
  year         = {2022},
  url          = {https://proceedings.mlr.press/v162/nichol22a.html},
  timestamp    = {Thu, 25 May 2023 10:38:31 +0200},
  biburl       = {https://dblp.org/rec/conf/icml/NicholDRSMMSC22.bib},
  bibsource    = {dblp computer science bibliography, https://dblp.org}
}

@article{paintbyword_andonian2021paint,
  title={Paint by word},
  author={Andonian, Alex and Osmany, Sabrina and Cui, Audrey and Park, YeonHwan and Jahanian, Ali and Torralba, Antonio and Bau, David},
  journal={arXiv preprint arXiv:2103.10951},
  year={2021}
}


@article{taskvector_ilharco2022editing,
  title={Editing models with task arithmetic},
  author={Ilharco, Gabriel and Ribeiro, Marco Tulio and Wortsman, Mitchell and Gururangan, Suchin and Schmidt, Ludwig and Hajishirzi, Hannaneh and Farhadi, Ali},
  journal={arXiv preprint arXiv:2212.04089},
  year={2022}
}

@article{gpt1_radford2018improving,
  title={Improving language understanding by generative pre-training},
  author={Radford, Alec and Narasimhan, Karthik and Salimans, Tim and Sutskever, Ilya and others},
  year={2018},
  publisher={OpenAI}
}

@article{vqvae_van2017neural,
  title={Neural discrete representation learning},
  author={Van Den Oord, Aaron and Vinyals, Oriol and others},
  journal={Advances in neural information processing systems},
  volume={30},
  year={2017}
}

@article{sam_kirillov2023segment,
  title={Segment anything},
  author={Kirillov, Alexander and Mintun, Eric and Ravi, Nikhila and Mao, Hanzi and Rolland, Chloe and Gustafson, Laura and Xiao, Tete and Whitehead, Spencer and Berg, Alexander C and Lo, Wan-Yen and others},
  journal={arXiv preprint arXiv:2304.02643},
  year={2023}
}

@article{cotracker_cotracker2karaev2023cotracker,
      title={CoTracker: It is Better to Track Together}, 
      author={Nikita Karaev and Ignacio Rocco and Benjamin Graham and Natalia Neverova and Andrea Vedaldi and Christian Rupprecht},
      year={2023},
      journal={arXiv preprint arXiv:2307.07635}
}


@article{sdxl_podell2023sdxl,
  title={SDXL: improving latent diffusion models for high-resolution image synthesis},
  author={Podell, Dustin and English, Zion and Lacey, Kyle and Blattmann, Andreas and Dockhorn, Tim and M{\"u}ller, Jonas and Penna, Joe and Rombach, Robin},
  journal={arXiv preprint arXiv:2307.01952},
  year={2023}
}


@misc{lavie_wang2023lavie,
      title={LAVIE: High-Quality Video Generation with Cascaded Latent Diffusion Models}, 
      author={Yaohui Wang and Xinyuan Chen and Xin Ma and Shangchen Zhou and Ziqi Huang and Yi Wang and Ceyuan Yang and Yinan He and Jiashuo Yu and Peiqing Yang and Yuwei Guo and Tianxing Wu and Chenyang Si and Yuming Jiang and Cunjian Chen and Chen Change Loy and Bo Dai and Dahua Lin and Yu Qiao and Ziwei Liu},
      year={2023},
      eprint={2309.15103},
      archivePrefix={arXiv},
      primaryClass={cs.CV}
}

@misc{civitai,
  author = {{Civitai}},
  title = {Civitai},
  howpublished = {\url{https://civitai.com/}},
  year = {2022}
}

@misc{huggingface,
  author = {{Hugging Face}},
  title = {Huggingface},
  howpublished = {\url{https://huggingface.co/}},
  year = {2022}
}

@misc{gen2,
  author = {{Gen-2}},
  title = {Gen-2: The Next Step  Forward for Generative AI},
  howpublished = {\url{https://research.runwayml.com/gen2/}},
  year = {2023}
}

@misc{gen3,
  author = {{Gen-3}},
  title = {Introducing Gen-3 Alpha: A New Frontier for Video Generation},
  howpublished = {\url{https://runwayml.com/research/introducing-gen-3-alpha/}},
  year = {2024}
}


@misc{luma,
  author = {{Luma}},
  title = {The Ultimate AI Video Generator},
  howpublished = {\url{https://lumaai.video}},
  year = {2024}
}



@misc{keling,
  author = {{Keling}},
  title = {KLING VIDEO MODEL},
  howpublished = {\url{https://kling.kuaishou.com/en}},
  year = {2024}
}



@article{cogvideox_yang2024cogvideox,
      title={CogVideoX: Text-to-Video Diffusion Models with An Expert Transformer},
      author={Zhuoyi Yang and Jiayan Teng and Wendi Zheng and Ming Ding and Shiyu Huang and JiaZheng Xu and Yuanming Yang and Xiaohan Zhang and Xiaotao Gu and Guanyu Feng and Da Yin and Wenyi Hong and Weihan Wang and Yean Cheng and Yuxuan Zhang and Ting Liu and Bin Xu and Yuxiao Dong and Jie Tang},
      year={2024},
}

@misc{vdm_ho2022videodiffusionmodels,
      title={Video Diffusion Models}, 
      author={Jonathan Ho and Tim Salimans and Alexey Gritsenko and William Chan and Mohammad Norouzi and David J. Fleet},
      year={2022},
      eprint={2204.03458},
      archivePrefix={arXiv},
      primaryClass={cs.CV},
      url={https://arxiv.org/abs/2204.03458}, 
}

@misc{brushnet_ju2024brushnetplugandplayimageinpainting,
      title={BrushNet: A Plug-and-Play Image Inpainting Model with Decomposed Dual-Branch Diffusion}, 
      author={Xuan Ju and Xian Liu and Xintao Wang and Yuxuan Bian and Ying Shan and Qiang Xu},
      year={2024},
      eprint={2403.06976},
      archivePrefix={arXiv},
      primaryClass={cs.CV},
      url={https://arxiv.org/abs/2403.06976}, 
}

@article{opensora,
  author = {Zangwei Zheng and Xiangyu Peng and Tianji Yang and Chenhui Shen and Shenggui Li and Hongxin Liu and Yukun Zhou and Tianyi Li and Yang You},
  title = {Open-Sora: Democratizing Efficient Video Production for All},
  month = {March},
  year = {2024},
  url = {https://github.com/hpcaitech/Open-Sora}
}

@misc{vidu_bao2024viduhighlyconsistentdynamic,
      title={Vidu: a Highly Consistent, Dynamic and Skilled Text-to-Video Generator with Diffusion Models}, 
      author={Fan Bao and Chendong Xiang and Gang Yue and Guande He and Hongzhou Zhu and Kaiwen Zheng and Min Zhao and Shilong Liu and Yaole Wang and Jun Zhu},
      year={2024},
      eprint={2405.04233},
      archivePrefix={arXiv},
      primaryClass={cs.CV},
      url={https://arxiv.org/abs/2405.04233}, 
}

@misc{raccon_yoon2024raccoonremoveaddchange,
      title={RACCooN: Remove, Add, and Change Video Content with Auto-Generated Narratives}, 
      author={Jaehong Yoon and Shoubin Yu and Mohit Bansal},
      year={2024},
      eprint={2405.18406},
      archivePrefix={arXiv},
      primaryClass={cs.CV},
      url={https://arxiv.org/abs/2405.18406}, 
}

@inproceedings{he2015delving,
  title={Delving deep into rectifiers: Surpassing human-level performance on imagenet classification},
  author={He, Kaiming and Zhang, Xiangyu and Ren, Shaoqing and Sun, Jian},
  booktitle={Proceedings of the IEEE international conference on computer vision},
  year={2015}
}

@article{sam2_ravi2024sam2,
  title={SAM 2: Segment Anything in Images and Videos},
  author={Ravi, Nikhila and Gabeur, Valentin and Hu, Yuan-Ting and Hu, Ronghang and Ryali, Chaitanya and Ma, Tengyu and Khedr, Haitham and R{\"a}dle, Roman and Rolland, Chloe and Gustafson, Laura and Mintun, Eric and Pan, Junting and Alwala, Kalyan Vasudev and Carion, Nicolas and Wu, Chao-Yuan and Girshick, Ross and Doll{\'a}r, Piotr and Feichtenhofer, Christoph},
  journal={arXiv preprint arXiv:2408.00714},
  url={https://arxiv.org/abs/2408.00714},
  year={2024}
}

@inproceedings{video_inpainting_zhou2023propainter,
  title={Propainter: Improving propagation and transformer for video inpainting},
  author={Zhou, Shangchen and Li, Chongyi and Chan, Kelvin CK and Loy, Chen Change},
  booktitle={ICCV},
  year={2023}
}

@inproceedings{video_inpainting_kim2019deep,
  title={Deep video inpainting},
  author={Kim, Dahun and Woo, Sanghyun and Lee, Joon-Young and Kweon, In So},
  booktitle={CVPR},
  year={2019}
}

@inproceedings{video_inpainting_lee2019copy,
  title={Copy-and-paste networks for deep video inpainting},
  author={Lee, Sungho and Oh, Seoung Wug and Won, DaeYeun and Kim, Seon Joo},
  booktitle={ICCV},
  year={2019}
}

@inproceedings{video_inpainting_li2022towards,
  title={Towards an end-to-end framework for flow-guided video inpainting},
  author={Li, Zhen and Lu, Cheng-Ze and Qin, Jianhua and Guo, Chun-Le and Cheng, Ming-Ming},
  booktitle={CVPR},
  year={2022}
}

@inproceedings{video_inpainting_liu2021fuseformer,
  title={Fuseformer: Fusing fine-grained information in transformers for video inpainting},
  author={Liu, Rui and Deng, Hanming and Huang, Yangyi and Shi, Xiaoyu and Lu, Lewei and Sun, Wenxiu and Wang, Xiaogang and Dai, Jifeng and Li, Hongsheng},
  booktitle={ICCV},
  year={2021}
}

@inproceedings{video_inpainting_ouyang2021internal,
  title={Internal video inpainting by implicit long-range propagation},
  author={Ouyang, Hao and Wang, Tengfei and Chen, Qifeng},
  booktitle={Proceedings of the IEEE/CVF international conference on computer vision},
  pages={14579--14588},
  year={2021}
}

@inproceedings{video_inpainting_xu2019deep,
  title={Deep flow-guided video inpainting},
  author={Xu, Rui and Li, Xiaoxiao and Zhou, Bolei and Loy, Chen Change},
  booktitle={Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition},
  pages={3723--3732},
  year={2019}
}

@inproceedings{video_inpainting_zeng2020learning,
  title={Learning joint spatial-temporal transformations for video inpainting},
  author={Zeng, Yanhong and Fu, Jianlong and Chao, Hongyang},
  booktitle={Computer Vision--ECCV 2020: 16th European Conference, Glasgow, UK, August 23--28, 2020, Proceedings, Part XVI 16},
  year={2020},
}

@misc{hotshotxl,
  author = {{HotshotXL}},
  title = {Hotshot-XL},
  howpublished = {\url{https://huggingface.co/hotshotco/Hotshot-XL}},
  year = {2023}
}


@misc{pikalab,
  author = {{Pika Labs}},
  title = {Pika Labs},
  howpublished = {\url{https://www.pika.art/}},
  year = {2023}
}


@misc{pexels,
  author="Pexels",
  title="https://www.pexels.com/",
  url = "https://www.pexels.com/",
  year = "2024"
}

@article{dit_peebles2022scalable,
  title={Scalable Diffusion Models with Transformers},
  author={Peebles, William and Xie, Saining},
  journal={arXiv preprint arXiv:2212.09748},
  year={2022}
}




@misc{mochi_1,
  author = {{Mochi-1}},
  title = {Mochi-1},
  howpublished = {\url{https://www.genmo.ai/blog}},
  year = {2024}
}


@inproceedings{dreambooth_ruiz2023dreambooth,
  title={Dreambooth: Fine tuning text-to-image diffusion models for subject-driven generation},
  author={Ruiz, Nataniel and Li, Yuanzhen and Jampani, Varun and Pritch, Yael and Rubinstein, Michael and Aberman, Kfir},
  booktitle={Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition},
  pages={22500--22510},
  year={2023}
}


@article{videopoet_kondratyuk2023videopoet,
  title={Videopoet: A large language model for zero-shot video generation},
  author={Kondratyuk, Dan and Yu, Lijun and Gu, Xiuye and Lezama, Jos{\'e} and Huang, Jonathan and Hornung, Rachel and Adam, Hartwig and Akbari, Hassan and Alon, Yair and Birodkar, Vighnesh and others},
  journal={arXiv preprint arXiv:2312.14125},
  year={2023}
}

@article{ddpm_ho2020denoising,
  title={Denoising diffusion probabilistic models},
  author={Ho, Jonathan and Jain, Ajay and Abbeel, Pieter},
  journal={Advances in neural information processing systems},
  volume={33},
  pages={6840--6851},
  year={2020}
}

@inproceedings{webvid_bain2021frozen,
  title={Frozen in time: A joint video and image encoder for end-to-end retrieval},
  author={Bain, Max and Nagrani, Arsha and Varol, G{\"u}l and Zisserman, Andrew},
  booktitle={Proceedings of the IEEE/CVF International Conference on Computer Vision},
  pages={1728--1738},
  year={2021}
}



@article{transformer_vaswani2017attention,
  title={Attention is all you need},
  author={Vaswani, Ashish and Shazeer, Noam and Parmar, Niki and Uszkoreit, Jakob and Jones, Llion and Gomez, Aidan N and Kaiser, {\L}ukasz and Polosukhin, Illia},
  journal={Advances in neural information processing systems},
  volume={30},
  year={2017}
}


@inproceedings{unet_ronneberger2015u,
  title={U-net: Convolutional networks for biomedical image segmentation},
  author={Ronneberger, Olaf and Fischer, Philipp and Brox, Thomas},
  booktitle={Medical Image Computing and Computer-Assisted Intervention--MICCAI 2015: 18th International Conference, Munich, Germany, October 5-9, 2015, Proceedings, Part III 18},
  pages={234--241},
  year={2015},
  organization={Springer}
}


@article{vae_kingma2013auto,
  title={Auto-encoding variational bayes},
  author={Kingma, Diederik P and Welling, Max},
  journal={arXiv preprint arXiv:1312.6114},
  year={2013}
}


@article{avid_zhang2023avid,
  title={AVID: Any-Length Video Inpainting with Diffusion Model},
  author={Zhang, Zhixing and Wu, Bichen and Wang, Xiaoyan and Luo, Yaqiao and Zhang, Luxin and Zhao, Yinan and Vajda, Peter and Metaxas, Dimitris and Yu, Licheng},
  journal={arXiv preprint arXiv:2312.03816},
  year={2023}
}


@article{dalle2_ramesh2022hierarchical,
  title={Hierarchical text-conditional image generation with clip latents},
  author={Ramesh, Aditya and Dhariwal, Prafulla and Nichol, Alex and Chu, Casey and Chen, Mark},
  journal={arXiv preprint arXiv:2204.06125},
  volume={1},
  number={2},
  pages={3},
  year={2022}
}
@article{imagen_saharia2022photorealistic,
  title={Photorealistic text-to-image diffusion models with deep language understanding},
  author={Saharia, Chitwan and Chan, William and Saxena, Saurabh and Li, Lala and Whang, Jay and Denton, Emily L and Ghasemipour, Kamyar and Gontijo Lopes, Raphael and Karagol Ayan, Burcu and Salimans, Tim and others},
  journal={Advances in Neural Information Processing Systems},
  volume={35},
  pages={36479--36494},
  year={2022}
}
@article{yu2022scaling,
  title={Scaling autoregressive models for content-rich text-to-image generation},
  author={Yu, Jiahui and Xu, Yuanzhong and Koh, Jing Yu and Luong, Thang and Baid, Gunjan and Wang, Zirui and Vasudevan, Vijay and Ku, Alexander and Yang, Yinfei and Ayan, Burcu Karagol and others},
  journal={arXiv preprint arXiv:2206.10789},
  volume={2},
  number={3},
  pages={5},
  year={2022},
  publisher={Jun}
}


@misc{xie2023dreaminpainter,
      title={DreamInpainter: Text-Guided Subject-Driven Image Inpainting with Diffusion Models}, 
      author={Shaoan Xie and Yang Zhao and Zhisheng Xiao and Kelvin C. K. Chan and Yandong Li and Yanwu Xu and Kun Zhang and Tingbo Hou},
      year={2023},
      eprint={2312.03771},
      archivePrefix={arXiv},
      primaryClass={cs.CV}
}
@misc{ma2024magicme,
      title={Magic-Me: Identity-Specific Video Customized Diffusion}, 
      author={Ze Ma and Daquan Zhou and Chun-Hsiao Yeh and Xue-She Wang and Xiuyu Li and Huanrui Yang and Zhen Dong and Kurt Keutzer and Jiashi Feng},
      year={2024},
      eprint={2402.09368},
      archivePrefix={arXiv},
      primaryClass={cs.CV}
}
@article{jiang2023videobooth,
  title={VideoBooth: Diffusion-based Video Generation with Image Prompts},
  author={Jiang, Yuming and Wu, Tianxing and Yang, Shuai and Si, Chenyang and Lin, Dahua and Qiao, Yu and Loy, Chen Change and Liu, Ziwei},
  journal={arXiv preprint arXiv:2312.00777},
  year={2023}
}
@misc{guo2023sparsectrl,
      title={SparseCtrl: Adding Sparse Controls to Text-to-Video Diffusion Models}, 
      author={Yuwei Guo and Ceyuan Yang and Anyi Rao and Maneesh Agrawala and Dahua Lin and Bo Dai},
      year={2023},
      eprint={2311.16933},
      archivePrefix={arXiv},
      primaryClass={cs.CV}
}

@misc{zeng2023tvtsv2,
      title={TVTSv2: Learning Out-of-the-box Spatiotemporal Visual Representations at Scale}, 
      author={Ziyun Zeng and Yixiao Ge and Zhan Tong and Xihui Liu and Shu-Tao Xia and Ying Shan},
      year={2023},
      eprint={2305.14173},
      archivePrefix={arXiv},
      primaryClass={cs.CV}
}

@misc{zhang2023show1,
      title={Show-1: Marrying Pixel and Latent Diffusion Models for Text-to-Video Generation}, 
      author={David Junhao Zhang and Jay Zhangjie Wu and Jia-Wei Liu and Rui Zhao and Lingmin Ran and Yuchao Gu and Difei Gao and Mike Zheng Shou},
      year={2023},
      eprint={2309.15818},
      archivePrefix={arXiv},
      primaryClass={cs.CV}
}
@inproceedings{fan2023hierarchical,
  title={Hierarchical masked 3d diffusion model for video outpainting},
  author={Fan, Fanda and Guo, Chaoxu and Gong, Litong and Wang, Biao and Ge, Tiezheng and Jiang, Yuning and Luo, Chunjie and Zhan, Jianfeng},
  booktitle={Proceedings of the 31st ACM International Conference on Multimedia},
  pages={7890--7900},
  year={2023}
}
@misc{yin2023dragnuwa,
      title={DragNUWA: Fine-grained Control in Video Generation by Integrating Text, Image, and Trajectory}, 
      author={Shengming Yin and Chenfei Wu and Jian Liang and Jie Shi and Houqiang Li and Gong Ming and Nan Duan},
      year={2023},
      eprint={2308.08089},
      archivePrefix={arXiv},
      primaryClass={cs.CV}
}
@misc{chen2023controlavideo,
      title={Control-A-Video: Controllable Text-to-Video Generation with Diffusion Models}, 
      author={Weifeng Chen and Yatai Ji and Jie Wu and Hefeng Wu and Pan Xie and Jiashi Li and Xin Xia and Xuefeng Xiao and Liang Lin},
      year={2023},
      eprint={2305.13840},
      archivePrefix={arXiv},
      primaryClass={cs.CV}
}


@article{renderavideo_yang2023rerender,
  title={Rerender A Video: Zero-Shot Text-Guided Video-to-Video Translation},
  author={Yang, Shuai and Zhou, Yifan and Liu, Ziwei and Loy, Chen Change},
  journal={arXiv preprint arXiv:2306.07954},
  year={2023}
}
@article{videop2p_liu2023video,
  title={Video-p2p: Video editing with cross-attention control},
  author={Liu, Shaoteng and Zhang, Yuechen and Li, Wenbo and Lin, Zhe and Jia, Jiaya},
  journal={arXiv preprint arXiv:2303.04761},
  year={2023}
}
@article{editavideo_shin2023edit,
  title={Edit-A-Video: Single Video Editing with Object-Aware Consistency},
  author={Shin, Chaehun and Kim, Heeseung and Lee, Che Hyun and Lee, Sang-gil and Yoon, Sungroh},
  journal={arXiv preprint arXiv:2303.07945},
  year={2023}
}
@inproceedings{tuneavideo_wu2023tune,
  title={Tune-a-video: One-shot tuning of image diffusion models for text-to-video generation},
  author={Wu, Jay Zhangjie and Ge, Yixiao and Wang, Xintao and Lei, Stan Weixian and Gu, Yuchao and Shi, Yufei and Hsu, Wynne and Shan, Ying and Qie, Xiaohu and Shou, Mike Zheng},
  booktitle={Proceedings of the IEEE/CVF International Conference on Computer Vision},
  pages={7623--7633},
  year={2023}
}
@article{qin2023instructvid2vid,
  title={InstructVid2Vid: Controllable Video Editing with Natural Language Instructions},
  author={Qin, Bosheng and Li, Juncheng and Tang, Siliang and Chua, Tat-Seng and Zhuang, Yueting},
  journal={arXiv preprint arXiv:2305.12328},
  year={2023}
}
@article{magicprop_yan2023magicprop,
  title={MagicProp: Diffusion-based Video Editing via Motion-aware Appearance Propagation},
  author={Yan, Hanshu and Liew, Jun Hao and Mai, Long and Lin, Shanchuan and Feng, Jiashi},
  journal={arXiv preprint arXiv:2309.00908},
  year={2023}
}
@article{ma2023follow,
  title={Follow Your Pose: Pose-Guided Text-to-Video Generation using Pose-Free Videos},
  author={Ma, Yue and He, Yingqing and Cun, Xiaodong and Wang, Xintao and Shan, Ying and Li, Xiu and Chen, Qifeng},
  journal={arXiv preprint arXiv:2304.01186},
  year={2023}
}

@inproceedings{pix2video_ceylan2023pix2video,
  title={Pix2video: Video editing using image diffusion},
  author={Ceylan, Duygu and Huang, Chun-Hao P and Mitra, Niloy J},
  booktitle={Proceedings of the IEEE/CVF International Conference on Computer Vision},
  pages={23206--23217},
  year={2023}
}
@article{makeavideo_singer2022make,
  title={Make-a-video: Text-to-video generation without text-video data},
  author={Singer, Uriel and Polyak, Adam and Hayes, Thomas and Yin, Xi and An, Jie and Zhang, Songyang and Hu, Qiyuan and Yang, Harry and Ashual, Oron and Gafni, Oran and others},
  journal={arXiv preprint arXiv:2209.14792},
  year={2022}
}
@inproceedings{stablediffusion_blattmann2023align,
  title={Align your latents: High-resolution video synthesis with latent diffusion models},
  author={Blattmann, Andreas and Rombach, Robin and Ling, Huan and Dockhorn, Tim and Kim, Seung Wook and Fidler, Sanja and Kreis, Karsten},
  booktitle={Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition},
  pages={22563--22575},
  year={2023}
}
@article{imagenvideo_ho2022imagen,
  title={Imagen video: High definition video generation with diffusion models},
  author={Ho, Jonathan and Chan, William and Saharia, Chitwan and Whang, Jay and Gao, Ruiqi and Gritsenko, Alexey and Kingma, Diederik P and Poole, Ben and Norouzi, Mohammad and Fleet, David J and others},
  journal={arXiv preprint arXiv:2210.02303},
  year={2022}
}
@article{fatezero_qi2023fatezero,
  title={Fatezero: Fusing attentions for zero-shot text-based video editing},
  author={Qi, Chenyang and Cun, Xiaodong and Zhang, Yong and Lei, Chenyang and Wang, Xintao and Shan, Ying and Chen, Qifeng},
  journal={arXiv preprint arXiv:2303.09535},
  year={2023}
}
@inproceedings{smartbrush_xie2023smartbrush,
  title={Smartbrush: Text and shape guided object inpainting with diffusion model},
  author={Xie, Shaoan and Zhang, Zhifei and Lin, Zhe and Hinz, Tobias and Zhang, Kun},
  booktitle={Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition},
  pages={22428--22437},
  year={2023}
}
@misc{Shutterstock, 
  title={Stock Images, Photos, Vectors, Video, and Music | Shutterstock (https://www.shutterstock.com/) },
  author={Shutterstock},
  url={https://www.shutterstock.com/},
  journal={Shutterstock}
} 
@inproceedings{ddim_song2020denoising,
  author       = {Jiaming Song and
                  Chenlin Meng and
                  Stefano Ermon},
  title        = {Denoising Diffusion Implicit Models},
  booktitle    = {9th International Conference on Learning Representations, {ICLR} 2021,
                  Virtual Event, Austria, May 3-7, 2021},
  publisher    = {OpenReview.net},
  year         = {2021},
  url          = {https://openreview.net/forum?id=St1giarCHLP},
  timestamp    = {Wed, 23 Jun 2021 17:36:39 +0200},
  biburl       = {https://dblp.org/rec/conf/iclr/SongME21.bib},
  bibsource    = {dblp computer science bibliography, https://dblp.org}
}
@article{improvedscorematching_song2020improved,
  title={Improved techniques for training score-based generative models},
  author={Song, Yang and Ermon, Stefano},
  journal={Advances in neural information processing systems},
  volume={33},
  pages={12438--12448},
  year={2020}
}
@article{sdeforgm_song2020score,
  title={Score-based generative modeling through stochastic differential equations},
  author={Song, Yang and Sohl-Dickstein, Jascha and Kingma, Diederik P and Kumar, Abhishek and Ermon, Stefano and Poole, Ben},
  journal={arXiv preprint arXiv:2011.13456},
  year={2020}
}
@inproceedings{clip_ramesh2021zero,
  title={Zero-shot text-to-image generation},
  author={Ramesh, Aditya and Pavlov, Mikhail and Goh, Gabriel and Gray, Scott and Voss, Chelsea and Radford, Alec and Chen, Mark and Sutskever, Ilya},
  booktitle={International Conference on Machine Learning},
  pages={8821--8831},
  year={2021},
  organization={PMLR}
}
@article{song2022diffusion,
  title={Diffusion Guided Domain Adaptation of Image Generators},
  author={Song, Kunpeng and Han, Ligong and Liu, Bingchen and Metaxas, Dimitris and Elgammal, Ahmed},
  journal={arXiv preprint arXiv:2212.04473},
  year={2022}
}
@inproceedings{DiffusionCLIP_kim2022diffusionclip,
  title={DiffusionCLIP: Text-Guided Diffusion Models for Robust Image Manipulation},
  author={Kim, Gwanghyun and Kwon, Taesung and Ye, Jong Chul},
  booktitle={CVPR},
  pages={2426--2435},
  year={2022}
}

@article{liu2022name,
  title={Name Your Style: An Arbitrary Artist-aware Image Style Transfer},
  author={Liu, Zhi-Song and Wang, Li-Wen and Siu, Wan-Chi and Kalogeiton, Vicky},
  journal={arXiv preprint arXiv:2202.13562},
  year={2022}
}
@article{kwon2022diffusion,
  title={Diffusion Models already have a Semantic Latent Space},
  author={Kwon, Mingi and Jeong, Jaeseok and Uh, Youngjung},
  journal={arXiv preprint arXiv:2210.10960},
  year={2022}
}
@article{avrahami2022blendedldm,
  title={Blended latent diffusion},
  author={Avrahami, Omri and Fried, Ohad and Lischinski, Dani},
  journal={arXiv preprint arXiv:2206.02779},
  year={2022}
}
@article{hertz2022prompt,
  title={Prompt-to-prompt image editing with cross attention control},
  author={Hertz, Amir and Mokady, Ron and Tenenbaum, Jay and Aberman, Kfir and Pritch, Yael and Cohen-Or, Daniel},
  journal={arXiv preprint arXiv:2208.01626},
  year={2022}
}
@inproceedings{
gal2022image,
title={An Image is Worth One Word: Personalizing Text-to-Image Generation using Textual Inversion},
author={Rinon Gal and Yuval Alaluf and Yuval Atzmon and Or Patashnik and Amit Haim Bermano and Gal Chechik and Daniel Cohen-or},
booktitle={The Eleventh International Conference on Learning Representations },
year={2023},
url={https://openreview.net/forum?id=NAQvF08TcyG}
}
@article{dreambooth_ruiz2022dreambooth,
  title={Dreambooth: Fine tuning text-to-image diffusion models for subject-driven generation},
  author={Ruiz, Nataniel and Li, Yuanzhen and Jampani, Varun and Pritch, Yael and Rubinstein, Michael and Aberman, Kfir},
  journal={arXiv preprint arXiv:2208.12242},
  year={2022}
}
@article{imagic_kawar2022imagic,
  title={Imagic: Text-Based Real Image Editing with Diffusion Models},
  author={Kawar, Bahjat and Zada, Shiran and Lang, Oran and Tov, Omer and Chang, Huiwen and Dekel, Tali and Mosseri, Inbar and Irani, Michal},
  journal={arXiv preprint arXiv:2210.09276},
  year={2022}
}
@article{liu2021more,
  title={More control for free! image synthesis with semantic diffusion guidance},
  author={Liu, Xihui and Park, Dong Huk and Azadi, Samaneh and Zhang, Gong and Chopikyan, Arman and Hu, Yuxiao and Shi, Humphrey and Rohrbach, Anna and Darrell, Trevor},
  journal={arXiv preprint arXiv:2112.05744},
  year={2021}
}
@article{miyake2023negative,
  title={Negative-prompt Inversion: Fast Image Inversion for Editing with Text-guided Diffusion Models},
  author={Miyake, Daiki and Iohara, Akihiro and Saito, Yu and Tanaka, Toshiyuki},
  journal={arXiv preprint arXiv:2305.16807},
  year={2023}
}
@article{han2023improving,
  title={Improving Negative-Prompt Inversion via Proximal Guidance},
  author={Han, Ligong and Wen, Song and Chen, Qi and Zhang, Zhixing and Song, Kunpeng and Ren, Mengwei and Gao, Ruijiang and Chen, Yuxiao and Liu, Di and Zhangli, Qilong and others},
  journal={arXiv preprint arXiv:2306.05414},
  year={2023}
}
@article{han2023svdiff,
  title={Svdiff: Compact parameter space for diffusion fine-tuning},
  author={Han, Ligong and Li, Yinxiao and Zhang, Han and Milanfar, Peyman and Metaxas, Dimitris and Yang, Feng},
  journal={arXiv preprint arXiv:2303.11305},
  year={2023}
}
@inproceedings{han2020robust,
  title={Robust conditional GAN from uncertainty-aware pairwise comparisons},
  author={Han, Ligong and Gao, Ruijiang and Kim, Mun and Tao, Xin and Liu, Bo and Metaxas, Dimitris},
  booktitle={Proceedings of the AAAI Conference on Artificial Intelligence},
  volume={34},
  pages={10909--10916},
  year={2020}
}
@article{t2iadapter_mou2023t2i,
  title={T2i-adapter: Learning adapters to dig out more controllable ability for text-to-image diffusion models},
  author={Mou, Chong and Wang, Xintao and Xie, Liangbin and Zhang, Jian and Qi, Zhongang and Shan, Ying and Qie, Xiaohu},
  journal={arXiv preprint arXiv:2302.08453},
  year={2023}
}
@article{zhao2023uni,
  title={Uni-ControlNet: All-in-One Control to Text-to-Image Diffusion Models},
  author={Zhao, Shihao and Chen, Dongdong and Chen, Yen-Chun and Bao, Jianmin and Hao, Shaozhe and Yuan, Lu and Wong, Kwan-Yee K},
  journal={arXiv preprint arXiv:2305.16322},
  year={2023}
}
@inproceedings{couairon2023zero,
  title={Zero-shot spatial layout conditioning for text-to-image diffusion models},
  author={Couairon, Guillaume and Careil, Marl{\`e}ne and Cord, Matthieu and Lathuili{\`e}re, St{\'e}phane and Verbeek, Jakob},
  booktitle={Proceedings of the IEEE/CVF International Conference on Computer Vision},
  pages={2174--2183},
  year={2023}
}
@article{cogvideo_hong2022cogvideo,
  title={Cogvideo: Large-scale pretraining for text-to-video generation via transformers},
  author={Hong, Wenyi and Ding, Ming and Zheng, Wendi and Liu, Xinghan and Tang, Jie},
  journal={arXiv preprint arXiv:2205.15868},
  year={2022}
}
@article{phenaki_villegas2022phenaki,
  title={Phenaki: Variable length video generation from open domain textual description},
  author={Villegas, Ruben and Babaeizadeh, Mohammad and Kindermans, Pieter-Jan and Moraldo, Hernan and Zhang, Han and Saffar, Mohammad Taghi and Castro, Santiago and Kunze, Julius and Erhan, Dumitru},
  journal={arXiv preprint arXiv:2210.02399},
  year={2022}
}
@article{Godiva_wu2021godiva,
  title={Godiva: Generating open-domain videos from natural descriptions},
  author={Wu, Chenfei and Huang, Lun and Zhang, Qianxi and Li, Binyang and Ji, Lei and Yang, Fan and Sapiro, Guillermo and Duan, Nan},
  journal={arXiv preprint arXiv:2104.14806},
  year={2021}
}
@inproceedings{nuwa_wu2022nuwa,
  title={N{\"u}wa: Visual synthesis pre-training for neural visual world creation},
  author={Wu, Chenfei and Liang, Jian and Ji, Lei and Yang, Fan and Fang, Yuejian and Jiang, Daxin and Duan, Nan},
  booktitle={European conference on computer vision},
  pages={720--736},
  year={2022},
  organization={Springer}
}
@article{laion5b_schuhmann2022laion,
  title={Laion-5b: An open large-scale dataset for training next generation image-text models},
  author={Schuhmann, Christoph and Beaumont, Romain and Vencu, Richard and Gordon, Cade and Wightman, Ross and Cherti, Mehdi and Coombes, Theo and Katta, Aarush and Mullis, Clayton and Wortsman, Mitchell and others},
  journal={Advances in Neural Information Processing Systems},
  volume={35},
  pages={25278--25294},
  year={2022}
}
@inproceedings{esser2023structure,
  title={Structure and content-guided video synthesis with diffusion models},
  author={Esser, Patrick and Chiu, Johnathan and Atighehchian, Parmida and Granskog, Jonathan and Germanidis, Anastasis},
  booktitle={Proceedings of the IEEE/CVF International Conference on Computer Vision},
  pages={7346--7356},
  year={2023}
}
@article{videodiffusionmodel_ho2022video,
title={Video diffusion models},
author={Ho, Jonathan and Salimans, Tim and Gritsenko, Alexey and Chan, William and Norouzi, Mohammad and Fleet, David J},
journal={arXiv:2204.03458},
year={2022}}
}
@article{clipscore_hessel2021clipscore,
  title={Clipscore: A reference-free evaluation metric for image captioning},
  author={Hessel, Jack and Holtzman, Ari and Forbes, Maxwell and Bras, Ronan Le and Choi, Yejin},
  journal={arXiv preprint arXiv:2104.08718},
  year={2021}
}
@article{dreamix_molad2023dreamix,
  title={Dreamix: Video diffusion models are general video editors},
  author={Molad, Eyal and Horwitz, Eliahu and Valevski, Dani and Acha, Alex Rav and Matias, Yossi and Pritch, Yael and Leviathan, Yaniv and Hoshen, Yedid},
  journal={arXiv preprint arXiv:2302.01329},
  year={2023}
}
@inproceedings{repaint_lugmayr2022repaint,
  title={Repaint: Inpainting using denoising diffusion probabilistic models},
  author={Lugmayr, Andreas and Danelljan, Martin and Romero, Andres and Yu, Fisher and Timofte, Radu and Van Gool, Luc},
  booktitle={Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition},
  pages={11461--11471},
  year={2022}
}
@inproceedings{inout_cheng2022inout,
  title={Inout: Diverse image outpainting via gan inversion},
  author={Cheng, Yen-Chi and Lin, Chieh Hubert and Lee, Hsin-Ying and Ren, Jian and Tulyakov, Sergey and Yang, Ming-Hsuan},
  booktitle={Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition},
  pages={11431--11440},
  year={2022}
}
@article{tokenflow_geyer2023tokenflow,
  title={Tokenflow: Consistent diffusion features for consistent video editing},
  author={Geyer, Michal and Bar-Tal, Omer and Bagon, Shai and Dekel, Tali},
  journal={arXiv preprint arXiv:2307.10373},
  year={2023}
}
@inproceedings{mokady2023null,
  title={Null-text inversion for editing real images using guided diffusion models},
  author={Mokady, Ron and Hertz, Amir and Aberman, Kfir and Pritch, Yael and Cohen-Or, Daniel},
  booktitle={Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition},
  pages={6038--6047},
  year={2023}
}

@misc{VideoCrafter1_chen2023videocrafter1,
      title={VideoCrafter1: Open Diffusion Models for High-Quality Video Generation}, 
      author={Haoxin Chen and Menghan Xia and Yingqing He and Yong Zhang and Xiaodong Cun and Shaoshu Yang and Jinbo Xing and Yaofang Liu and Qifeng Chen and Xintao Wang and Chao Weng and Ying Shan},
      year={2023},
      eprint={2310.19512},
      archivePrefix={arXiv},
      primaryClass={cs.CV}
}
@article{liu2022pseudo,
  title={Pseudo numerical methods for diffusion models on manifolds},
  author={Liu, Luping and Ren, Yi and Lin, Zhijie and Zhao, Zhou},
  journal={arXiv preprint arXiv:2202.09778},
  year={2022}
}
@article{classifierfree_ho2022classifier,
  title={Classifier-free diffusion guidance},
  author={Ho, Jonathan and Salimans, Tim},
  journal={arXiv preprint arXiv:2207.12598},
  year={2022}
}
@article{llama2_touvron2023llama,
  title={Llama 2: Open foundation and fine-tuned chat models},
  author={Touvron, Hugo and Martin, Louis and Stone, Kevin and Albert, Peter and Almahairi, Amjad and Babaei, Yasmine and Bashlykov, Nikolay and Batra, Soumya and Bhargava, Prajjwal and Bhosale, Shruti and others},
  journal={arXiv preprint arXiv:2307.09288},
  year={2023}
}
@inproceedings{xie2015holistically,
  title={Holistically-nested edge detection},
  author={Xie, Saining and Tu, Zhuowen},
  booktitle={Proceedings of the IEEE international conference on computer vision},
  pages={1395--1403},
  year={2015}
}
@inproceedings{brooks2023instructpix2pix,
  title={Instructpix2pix: Learning to follow image editing instructions},
  author={Brooks, Tim and Holynski, Aleksander and Efros, Alexei A},
  booktitle={Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition},
  pages={18392--18402},
  year={2023}
}
@inproceedings{kumari2023multi,
  title={Multi-concept customization of text-to-image diffusion},
  author={Kumari, Nupur and Zhang, Bingliang and Zhang, Richard and Shechtman, Eli and Zhu, Jun-Yan},
  booktitle={Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition},
  pages={1931--1941},
  year={2023}
}
@inproceedings{yu2018generative,
  title={Generative image inpainting with contextual attention},
  author={Yu, Jiahui and Lin, Zhe and Yang, Jimei and Shen, Xiaohui and Lu, Xin and Huang, Thomas S},
  booktitle={Proceedings of the IEEE conference on computer vision and pattern recognition},
  pages={5505--5514},
  year={2018}
}
@inproceedings{saharia2022palette,
  title={Palette: Image-to-image diffusion models},
  author={Saharia, Chitwan and Chan, William and Chang, Huiwen and Lee, Chris and Ho, Jonathan and Salimans, Tim and Fleet, David and Norouzi, Mohammad},
  booktitle={ACM SIGGRAPH 2022 Conference Proceedings},
  pages={1--10},
  year={2022}
}
@inproceedings{Renderdiffusion_anciukevivcius2023renderdiffusion,
  title={Renderdiffusion: Image diffusion for 3d reconstruction, inpainting and generation},
  author={Anciukevi{\v{c}}ius, Titas and Xu, Zexiang and Fisher, Matthew and Henderson, Paul and Bilen, Hakan and Mitra, Niloy J and Guerrero, Paul},
  booktitle={Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition},
  pages={12608--12618},
  year={2023}
}
@inproceedings{sine_zhang2023sine,
  title={Sine: Single image editing with text-to-image diffusion models},
  author={Zhang, Zhixing and Han, Ligong and Ghosh, Arnab and Metaxas, Dimitris N and Ren, Jian},
  booktitle={Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition},
  pages={6027--6037},
  year={2023}
}
@inproceedings{yang2023paint,
  title={Paint by example: Exemplar-based image editing with diffusion models},
  author={Yang, Binxin and Gu, Shuyang and Zhang, Bo and Zhang, Ting and Chen, Xuejin and Sun, Xiaoyan and Chen, Dong and Wen, Fang},
  booktitle={Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition},
  pages={18381--18391},
  year={2023}
}
@article{avrahami2023blended,
  title={Blended latent diffusion},
  author={Avrahami, Omri and Fried, Ohad and Lischinski, Dani},
  journal={ACM Transactions on Graphics (TOG)},
  volume={42},
  number={4},
  pages={1--11},
  year={2023},
  publisher={ACM New York, NY, USA}
}
@inproceedings{clip_radford2021learning,
  title={Learning transferable visual models from natural language supervision},
  author={Radford, Alec and Kim, Jong Wook and Hallacy, Chris and Ramesh, Aditya and Goh, Gabriel and Agarwal, Sandhini and Sastry, Girish and Askell, Amanda and Mishkin, Pamela and Clark, Jack and others},
  booktitle={International conference on machine learning},
  pages={8748--8763},
  year={2021},
  organization={PMLR}
}
@inproceedings{yang2023uni,
  title={Uni-paint: A Unified Framework for Multimodal Image Inpainting with Pretrained Diffusion Model},
  author={Yang, Shiyuan and Chen, Xiaodong and Liao, Jing},
  booktitle={Proceedings of the 31st ACM International Conference on Multimedia},
  pages={3190--3199},
  year={2023}
}
@inproceedings{han2022show,
  title={Show me what and tell me how: Video synthesis via multimodal conditioning},
  author={Han, Ligong and Ren, Jian and Lee, Hsin-Ying and Barbieri, Francesco and Olszewski, Kyle and Minaee, Shervin and Metaxas, Dimitris and Tulyakov, Sergey},
  booktitle={Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition},
  pages={3615--3625},
  year={2022}
}

@inproceedings{han2021dual,
  title={Dual projection generative adversarial networks for conditional image generation},
  author={Han, Ligong and Min, Martin Renqiang and Stathopoulos, Anastasis and Tian, Yu and Gao, Ruijiang and Kadav, Asim and Metaxas, Dimitris N},
  booktitle={Proceedings of the IEEE/CVF International Conference on Computer Vision},
  pages={14438--14447},
  year={2021}
}
@inproceedings{avrahami2022blended,
  title={Blended diffusion for text-driven editing of natural images},
  author={Avrahami, Omri and Lischinski, Dani and Fried, Ohad},
  booktitle={Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition},
  pages={18208--18218},
  year={2022}
}
@inproceedings{imageneditor_wang2023imagen,
  title={Imagen editor and editbench: Advancing and evaluating text-guided image inpainting},
  author={Wang, Su and Saharia, Chitwan and Montgomery, Ceslee and Pont-Tuset, Jordi and Noy, Shai and Pellegrini, Stefano and Onoe, Yasumasa and Laszlo, Sarah and Fleet, David J and Soricut, Radu and others},
  booktitle={Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition},
  pages={18359--18369},
  year={2023}
}
@misc{Vats_2023, title={Exploring video-inpainting: A comparative analysis of videocomposer}, url={https://medium.com/@john.vats/exploring-video-inpainting-a-comparative-analysis-of-videocomposer-e1e6ebb0d057}, journal={Medium}, publisher={Medium}, author={Vats, John}, year={2023}, month={Nov}} 

@inproceedings{yu2019free,
  title={Free-form image inpainting with gated convolution},
  author={Yu, Jiahui and Lin, Zhe and Yang, Jimei and Shen, Xiaohui and Lu, Xin and Huang, Thomas S},
  booktitle={Proceedings of the IEEE/CVF international conference on computer vision},
  pages={4471--4480},
  year={2019}
}

@inproceedings{peebles2023scalable,
  title={Scalable diffusion models with transformers},
  author={Peebles, William and Xie, Saining},
  booktitle={Proceedings of the IEEE/CVF International Conference on Computer Vision},
  pages={4195--4205},
  year={2023}
}

@inproceedings{ruiz2023dreambooth,
  title={Dreambooth: Fine tuning text-to-image diffusion models for subject-driven generation},
  author={Ruiz, Nataniel and Li, Yuanzhen and Jampani, Varun and Pritch, Yael and Rubinstein, Michael and Aberman, Kfir},
  booktitle={Proceedings of the IEEE/CVF conference on computer vision and pattern recognition},
  pages={22500--22510},
  year={2023}
}
@article{telea2004image,
  title={An image inpainting technique based on the fast marching method},
  author={Telea, Alexandru},
  journal={Journal of graphics tools},
  volume={9},
  number={1},
  pages={23--34},
  year={2004},
}


@article{cheng2023consistent,
  title={Consistent video-to-video transfer using synthetic dataset},
  author={Cheng, Jiaxin and Xiao, Tianjun and He, Tong},
  journal={arXiv preprint arXiv:2311.00213},
  year={2023}
}

@article{ku2024anyv2v,
  title={Anyv2v: A plug-and-play framework for any video-to-video editing tasks},
  author={Ku, Max and Wei, Cong and Ren, Weiming and Yang, Huan and Chen, Wenhu},
  journal={arXiv preprint arXiv:2403.14468},
  year={2024}
}

@article{mou2024revideo,
  title={Re{V}ideo: Remake a {V}ideo with {M}otion and {C}ontent {C}ontrol},
  author={Mou, Chong and Cao, Mingdeng and Wang, Xintao and Zhang, Zhaoyang and Shan, Ying and Zhang, Jian},
  journal={arXiv preprint arXiv:2405.13865},
  year={2024}
}

@inproceedings{ouyang2024codef,
  title={Codef: Content deformation fields for temporally consistent video processing},
  author={Ouyang, Hao and Wang, Qiuyu and Xiao, Yuxi and Bai, Qingyan and Zhang, Juntao and Zheng, Kecheng and Zhou, Xiaowei and Chen, Qifeng and Shen, Yujun},
  booktitle={Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition},
  year={2024}
}

@inproceedings{liu2024video,
  title={Video-p2p: Video editing with cross-attention control},
  author={Liu, Shaoteng and Zhang, Yuechen and Li, Wenbo and Lin, Zhe and Jia, Jiaya},
  booktitle={Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition},
  year={2024}
}

@inproceedings{wu2023tune,
  title={Tune-a-video: One-shot tuning of image diffusion models for text-to-video generation},
  author={Wu, Jay Zhangjie and Ge, Yixiao and Wang, Xintao and Lei, Stan Weixian and Gu, Yuchao and Shi, Yufei and Hsu, Wynne and Shan, Ying and Qie, Xiaohu and Shou, Mike Zheng},
  booktitle={Proceedings of the IEEE/CVF International Conference on Computer Vision},
  year={2023}
}

@inproceedings{qi2023fatezero,
  title={Fatezero: Fusing attentions for zero-shot text-based video editing},
  author={Qi, Chenyang and Cun, Xiaodong and Zhang, Yong and Lei, Chenyang and Wang, Xintao and Shan, Ying and Chen, Qifeng},
  booktitle={Proceedings of the IEEE/CVF International Conference on Computer Vision},
  year={2023}
}

@article{blattmann2023stable,
  title={Stable video diffusion: Scaling latent video diffusion models to large datasets},
  author={Blattmann, Andreas and Dockhorn, Tim and Kulal, Sumith and Mendelevitch, Daniel and Kilian, Maciej and Lorenz, Dominik and Levi, Yam and English, Zion and Voleti, Vikram and Letts, Adam and others},
  journal={arXiv preprint arXiv:2311.15127},
  year={2023}
}

@article{zhang2023i2vgen,
  title={I2vgen-xl: High-quality image-to-video synthesis via cascaded diffusion models},
  author={Zhang, Shiwei and Wang, Jiayu and Zhang, Yingya and Zhao, Kang and Yuan, Hangjie and Qin, Zhiwu and Wang, Xiang and Zhao, Deli and Zhou, Jingren},
  journal={arXiv preprint arXiv:2311.04145},
  year={2023}
}

@inproceedings{guo2025sparsectrl,
  title={Sparsectrl: Adding sparse controls to text-to-video diffusion models},
  author={Guo, Yuwei and Yang, Ceyuan and Rao, Anyi and Agrawala, Maneesh and Lin, Dahua and Dai, Bo},
  booktitle={European Conference on Computer Vision},
  year={2025},
}

@article{hu2021lora,
  title={Lora: Low-rank adaptation of large language models},
  author={Hu, Edward J and Shen, Yelong and Wallis, Phillip and Allen-Zhu, Zeyuan and Li, Yuanzhi and Wang, Shean and Wang, Lu and Chen, Weizhu},
  journal={arXiv preprint arXiv:2106.09685},
  year={2021}
}

@article{ouyang2024i2vedit,
  title={{I2VE}dit: {F}irst-{F}rame-{G}uided {V}ideo {E}diting via {I}mage-to-{V}ideo {D}iffusion {M}odels},
  author={Ouyang, Wenqi and Dong, Yi and Yang, Lei and Si, Jianlou and Pan, Xingang},
  journal={arXiv preprint arXiv:2405.16537},
  year={2024}
}

@inproceedings{gu2024videoswap,
  title={Videoswap: Customized video subject swapping with interactive semantic point correspondence},
  author={Gu, Yuchao and Zhou, Yipin and Wu, Bichen and Yu, Licheng and Liu, Jia-Wei and Zhao, Rui and Wu, Jay Zhangjie and Zhang, David Junhao and Shou, Mike Zheng and Tang, Kevin},
  booktitle={Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition},
  year={2024}
}

@article{yan2023magicprop,
  title={Magicprop: Diffusion-based video editing via motion-aware appearance propagation},
  author={Yan, Hanshu and Liew, Jun Hao and Mai, Long and Lin, Shanchuan and Feng, Jiashi},
  journal={arXiv preprint arXiv:2309.00908},
  year={2023}
}

@inproceedings{shi2024motion,
  title={Motion-i2v: Consistent and controllable image-to-video generation with explicit motion modeling},
  author={Shi, Xiaoyu and Huang, Zhaoyang and Wang, Fu-Yun and Bian, Weikang and Li, Dasong and Zhang, Yi and Zhang, Manyuan and Cheung, Ka Chun and See, Simon and Qin, Hongwei and others},
  booktitle={ACM SIGGRAPH 2024 Conference Papers},
  year={2024}
}

@article{yan2023motion,
  title={Motion-conditioned image animation for video editing},
  author={Yan, Wilson and Brown, Andrew and Abbeel, Pieter and Girdhar, Rohit and Azadi, Samaneh},
  journal={arXiv preprint arXiv:2311.18827},
  year={2023}
}

@inproceedings{jampani2017video,
  title={Video propagation networks},
  author={Jampani, Varun and Gadde, Raghudeep and Gehler, Peter V},
  booktitle={Proceedings of the IEEE conference on computer vision and pattern recognition},
  year={2017}
}

@misc{sora,
  author = {OpenAI},
  title = {Sora: Creating video from text},
  howpublished = {\url{https://openai.com/index/sora/}},
  year = {2024}
}

@article{moviegen,
  title={Movie gen: A cast of media foundation models},
  author={Polyak, Adam and Zohar, Amit and Brown, Andrew and Tjandra, Andros and Sinha, Animesh and Lee, Ann and Vyas, Apoorv and Shi, Bowen and Ma, Chih-Yao and Chuang, Ching-Yao and others},
  journal={arXiv:2410.13720},
  year={2024}
}

@inproceedings{xing2025dynamicrafter,
  title={Dynamicrafter: Animating open-domain images with video diffusion priors},
  author={Xing, Jinbo and Xia, Menghan and Zhang, Yong and Chen, Haoxin and Yu, Wangbo and Liu, Hanyuan and Liu, Gongye and Wang, Xintao and Shan, Ying and Wong, Tien-Tsin},
  booktitle={European Conference on Computer Vision},
  year={2025},
}

@article{hong2022cogvideo,
  title={Cogvideo: Large-scale pretraining for text-to-video generation via transformers},
  author={Hong, Wenyi and Ding, Ming and Zheng, Wendi and Liu, Xinghan and Tang, Jie},
  journal={arXiv preprint arXiv:2205.15868},
  year={2022}
}

@inproceedings{chen2024videocrafter2,
  title={Videocrafter2: Overcoming data limitations for high-quality video diffusion models},
  author={Chen, Haoxin and Zhang, Yong and Cun, Xiaodong and Xia, Menghan and Wang, Xintao and Weng, Chao and Shan, Ying},
  booktitle={Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition},
  year={2024}
}

@article{singer2022make,
  title={Make-a-video: Text-to-video generation without text-video data},
  author={Singer, Uriel and Polyak, Adam and Hayes, Thomas and Yin, Xi and An, Jie and Zhang, Songyang and Hu, Qiyuan and Yang, Harry and Ashual, Oron and Gafni, Oran and others},
  journal={arXiv preprint arXiv:2209.14792},
  year={2022}
}

@inproceedings{villegas2022phenaki,
  title={Phenaki: Variable length video generation from open domain textual descriptions},
  author={Villegas, Ruben and Babaeizadeh, Mohammad and Kindermans, Pieter-Jan and Moraldo, Hernan and Zhang, Han and Saffar, Mohammad Taghi and Castro, Santiago and Kunze, Julius and Erhan, Dumitru},
  booktitle={International Conference on Learning Representations},
  year={2022}
}

@article{ho2022imagen,
  title={Imagen video: High definition video generation with diffusion models},
  author={Ho, Jonathan and Chan, William and Saharia, Chitwan and Whang, Jay and Gao, Ruiqi and Gritsenko, Alexey and Kingma, Diederik P and Poole, Ben and Norouzi, Mohammad and Fleet, David J and others},
  journal={arXiv preprint arXiv:2210.02303},
  year={2022}
}

@article{zi2024cococo,
  title={{C}o{C}o{C}o: Improving {T}ext-{G}uided {V}ideo {I}npainting for {B}etter {C}onsistency, {C}ontrollability and {C}ompatibility},
  author={Zi, Bojia and Zhao, Shihao and Qi, Xianbiao and Wang, Jianan and Shi, Yukai and Chen, Qianyu and Liang, Bin and Wong, Kam-Fai and Zhang, Lei},
  journal={arXiv preprint arXiv:2403.12035},
  year={2024}
}

@inproceedings{singer2025video,
  title={Video editing via factorized diffusion distillation},
  author={Singer, Uriel and Zohar, Amit and Kirstain, Yuval and Sheynin, Shelly and Polyak, Adam and Parikh, Devi and Taigman, Yaniv},
  booktitle={European Conference on Computer Vision},
  year={2025},
}

@inproceedings{teed2020raft,
  title={Raft: Recurrent all-pairs field transforms for optical flow},
  author={Teed, Zachary and Deng, Jia},
  booktitle={Computer Vision--ECCV 2020: 16th European Conference, Glasgow, UK, August 23--28, 2020, Proceedings, Part II 16},
  year={2020},
}

@article{kasten2021layered,
  title={Layered neural atlases for consistent video editing},
  author={Kasten, Yoni and Ofri, Dolev and Wang, Oliver and Dekel, Tali},
  journal={ACM Transactions on Graphics (TOG)},
  year={2021},
}

@article{cong2023flatten,
  title={Flatten: optical flow-guided attention for consistent text-to-video editing},
  author={Cong, Yuren and Xu, Mengmeng and Simon, Christian and Chen, Shoufa and Ren, Jiawei and Xie, Yanping and Perez-Rua, Juan-Manuel and Rosenhahn, Bodo and Xiang, Tao and He, Sen},
  journal={arXiv preprint arXiv:2310.05922},
  year={2023}
}

@inproceedings{ceylan2023pix2video,
  title={Pix2video: Video editing using image diffusion},
  author={Ceylan, Duygu and Huang, Chun-Hao P and Mitra, Niloy J},
  booktitle={Proceedings of the IEEE/CVF International Conference on Computer Vision},
  year={2023}
}

@article{xu2018youtube,
  title={Youtube-vos: A large-scale video object segmentation benchmark},
  author={Xu, Ning and Yang, Linjie and Fan, Yuchen and Yue, Dingcheng and Liang, Yuchen and Yang, Jianchao and Huang, Thomas},
  journal={arXiv preprint arXiv:1809.03327},
  year={2018}
}

@article{ravi2024sam2,
  title={{SAM} 2: {S}egment {A}nything in {I}mages and {V}ideos},
  author={Ravi, Nikhila and Gabeur, Valentin and Hu, Yuan-Ting and Hu, Ronghang and Ryali, Chaitanya and Ma, Tengyu and Khedr, Haitham and R{\"a}dle, Roman and Rolland, Chloe and Gustafson, Laura and Mintun, Eric and Pan, Junting and Alwala, Kalyan Vasudev and Carion, Nicolas and Wu, Chao-Yuan and Girshick, Ross and Doll{\'a}r, Piotr and Feichtenhofer, Christoph},
  journal={arXiv preprint arXiv:2408.00714},
  year={2024}
}

@article{geyer2023tokenflow,
  title={Tokenflow: Consistent diffusion features for consistent video editing},
  author={Geyer, Michal and Bar-Tal, Omer and Bagon, Shai and Dekel, Tali},
  journal={arXiv preprint arXiv:2307.10373},
  year={2023}
}

@inproceedings{kara2024rave,
  title={Rave: Randomized noise shuffling for fast and consistent video editing with diffusion models},
  author={Kara, Ozgur and Kurtkaya, Bariscan and Yesiltepe, Hidir and Rehg, James M and Yanardag, Pinar},
  booktitle={Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition},
  year={2024}
}

@article{wang2023zero,
  title={Zero-shot video editing using off-the-shelf image diffusion models},
  author={Wang, Wen and Jiang, Yan and Xie, Kangyang and Liu, Zide and Chen, Hao and Cao, Yue and Wang, Xinlong and Shen, Chunhua},
  journal={arXiv preprint arXiv:2303.17599},
  year={2023}
}

@inproceedings{bar2022text2live,
  title={Text2live: Text-driven layered image and video editing},
  author={Bar-Tal, Omer and Ofri-Amar, Dolev and Fridman, Rafail and Kasten, Yoni and Dekel, Tali},
  booktitle={European conference on computer vision},
  year={2022},
}

@inproceedings{wu2024fairy,
  title={Fairy: Fast parallelized instruction-guided video-to-video synthesis},
  author={Wu, Bichen and Chuang, Ching-Yao and Wang, Xiaoyan and Jia, Yichen and Krishnakumar, Kapil and Xiao, Tong and Liang, Feng and Yu, Licheng and Vajda, Peter},
  booktitle={Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition},
  year={2024}
}

@article{zhao2023controlvideo,
  title={Controlvideo: Adding conditional control for one shot text-to-video editing},
  author={Zhao, Min and Wang, Rongzhen and Bao, Fan and Li, Chongxuan and Zhu, Jun},
  journal={arXiv preprint arXiv:2305.17098},
  year={2023}
}

@inproceedings{zhao2025motiondirector,
  title={Motiondirector: Motion customization of text-to-video diffusion models},
  author={Zhao, Rui and Gu, Yuchao and Wu, Jay Zhangjie and Zhang, David Junhao and Liu, Jia-Wei and Wu, Weijia and Keppo, Jussi and Shou, Mike Zheng},
  booktitle={European Conference on Computer Vision},
  year={2025},
}

@inproceedings{yatim2024space,
  title={Space-time diffusion features for zero-shot text-driven motion transfer},
  author={Yatim, Danah and Fridman, Rafail and Bar-Tal, Omer and Kasten, Yoni and Dekel, Tali},
  booktitle={Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition},
  year={2024}
}

@inproceedings{jeong2024vmc,
  title={Vmc: Video motion customization using temporal attention adaption for text-to-video diffusion models},
  author={Jeong, Hyeonho and Park, Geon Yeong and Ye, Jong Chul},
  booktitle={Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition},
  year={2024}
}

@inproceedings{esser2023structure,
  title={Structure and content-guided video synthesis with diffusion models},
  author={Esser, Patrick and Chiu, Johnathan and Atighehchian, Parmida and Granskog, Jonathan and Germanidis, Anastasis},
  booktitle={Proceedings of the IEEE/CVF International Conference on Computer Vision},
  year={2023}
}

@inproceedings{liang2024flowvid,
  title={Flowvid: Taming imperfect optical flows for consistent video-to-video synthesis},
  author={Liang, Feng and Wu, Bichen and Wang, Jialiang and Yu, Licheng and Li, Kunpeng and Zhao, Yinan and Misra, Ishan and Huang, Jia-Bin and Zhang, Peizhao and Vajda, Peter and others},
  booktitle={Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition},
  year={2024}
}

@article{xing2024make,
  title={Make-your-video: Customized video generation using textual and structural guidance},
  author={Xing, Jinbo and Xia, Menghan and Liu, Yuxin and Zhang, Yuechen and Zhang, Yong and He, Yingqing and Liu, Hanyuan and Chen, Haoxin and Cun, Xiaodong and Wang, Xintao and others},
  journal={IEEE Transactions on Visualization and Computer Graphics},
  year={2024},
}

@article{wang2024videocomposer,
  title={Videocomposer: Compositional video synthesis with motion controllability},
  author={Wang, Xiang and Yuan, Hangjie and Zhang, Shiwei and Chen, Dayou and Wang, Jiuniu and Zhang, Yingya and Shen, Yujun and Zhao, Deli and Zhou, Jingren},
  journal={Advances in Neural Information Processing Systems},
  year={2024}
}

@inproceedings{kim2019deep,
  title={Deep video inpainting},
  author={Kim, Dahun and Woo, Sanghyun and Lee, Joon-Young and Kweon, In So},
  booktitle={Proceedings of the IEEE/CVF conference on computer vision and pattern recognition},
  year={2019}
}

@inproceedings{ke2021occlusion,
  title={Occlusion-aware video object inpainting},
  author={Ke, Lei and Tai, Yu-Wing and Tang, Chi-Keung},
  booktitle={Proceedings of the IEEE/CVF International Conference on Computer Vision},
  year={2021}
}

@misc{wu2023cvpr,
  title={{CVPR} 2023 {T}ext {G}uided {V}ideo {E}diting {C}ompetition}, 
  author={Jay Zhangjie Wu and Xiuyu Li and Difei Gao and Zhen Dong and Jinbin Bai and Aishani Singh and Xiaoyu Xiang and Youzeng Li and Zuwei Huang and Yuanxi Sun and Rui He and Feng Hu and Junhua Hu and Hai Huang and Hanyu Zhu and Xu Cheng and Jie Tang and Mike Zheng Shou and Kurt Keutzer and Forrest Iandola},
  year={2023},
  eprint={2310.16003},
  archivePrefix={arXiv},
  primaryClass={cs.CV}
}

@article{turk2012amazon,
  title={Amazon mechanical turk},
  author={Turk, Amazon Mechanical},
  journal={Retrieved August},
  year={2012}
}

@article{error2010mean,
  title={Mean squared error},
  author={Error, Mean Squared},
  journal={MA: Springer US},
  year={2010}
}

@article{yang2024cogvideox,
  title={Cog{V}ideo{X}: Text-to-Video Diffusion Models with An Expert Transformer},
  author={Yang, Zhuoyi and Teng, Jiayan and Zheng, Wendi and Ding, Ming and Huang, Shiyu and Xu, Jiazheng and Yang, Yuanming and Hong, Wenyi and Zhang, Xiaohan and Feng, Guanyu and others},
  journal={arXiv preprint arXiv:2408.06072},
  year={2024}
}

@inproceedings{radford2021learning,
  title={Learning transferable visual models from natural language supervision},
  author={Radford, Alec and Kim, Jong Wook and Hallacy, Chris and Ramesh, Aditya and Goh, Gabriel and Agarwal, Sandhini and Sastry, Girish and Askell, Amanda and Mishkin, Pamela and Clark, Jack and others},
  booktitle={International conference on machine learning},
  year={2021},
}

@inproceedings{zhou2023propainter,
  title={Propainter: {I}mproving propagation and transformer for video inpainting},
  author={Zhou, Shangchen and Li, Chongyi and Chan, Kelvin CK and Loy, Chen Change},
  booktitle={Proceedings of the IEEE/CVF International Conference on Computer Vision},
  year={2023}
}

@article{huang2023inve,
  title={Inve: {I}nteractive neural video editing},
  author={Huang, Jiahui and Sigal, Leonid and Yi, Kwang Moo and Wang, Oliver and Lee, Joon-Young},
  journal={arXiv preprint arXiv:2307.07663},
  year={2023}
}

@article{davis2017pont,
  title={The 2017 Davis Challenge on Video Object Segmentation},
  author={Pont-Tuset, Jordi and Perazzi, Federico and Caelles, Sergi and Arbel{\'a}ez, Pablo and Sorkine-Hornung, Alex and Van Gool, Luc},
  journal={arXiv preprint arXiv:1704.00675},
  year={2017}
}

@misc{zhang2023adding,
  title={Adding Conditional Control to Text-to-Image Diffusion Models}, 
  author={Lvmin Zhang and Anyi Rao and Maneesh Agrawala},
  booktitle={IEEE International Conference on Computer Vision (ICCV)},
  year={2023},
}

@inproceedings{shin2024edit,
  title={Edit-a-video: Single video editing with object-aware consistency},
  author={Shin, Chaehun and Kim, Heeseung and Lee, Che Hyun and Lee, Sang-gil and Yoon, Sungroh},
  booktitle={Asian Conference on Machine Learning},
  year={2024},
}

@inproceedings{feng2024ccedit,
  title={Ccedit: Creative and controllable video editing via diffusion models},
  author={Feng, Ruoyu and Weng, Wenming and Wang, Yanhui and Yuan, Yuhui and Bao, Jianmin and Luo, Chong and Chen, Zhibo and Guo, Baining},
  booktitle={Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition},
  year={2024}
}

@inproceedings{li2024vidtome,
  title={Vidtome: Video token merging for zero-shot video editing},
  author={Li, Xirui and Ma, Chao and Yang, Xiaokang and Yang, Ming-Hsuan},
  booktitle={Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition},
  year={2024}
}

@article{zhang2024towards,
  title={Towards consistent video editing with text-to-image diffusion models},
  author={Zhang, Zicheng and Li, Bonan and Nie, Xuecheng and Han, Congying and Guo, Tiande and Liu, Luoqi},
  journal={Advances in Neural Information Processing Systems},
  year={2024}
}

@inproceedings{tu2024motioneditor,
  title={Motioneditor: Editing video motion via content-aware diffusion},
  author={Tu, Shuyuan and Dai, Qi and Cheng, Zhi-Qi and Hu, Han and Han, Xintong and Wu, Zuxuan and Jiang, Yu-Gang},
  booktitle={Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition},
  year={2024}
}
@misc{hunyuanvideosystematicframeworklargekong2025,
      title={HunyuanVideo: A Systematic Framework For Large Video Generative Models}, 
      author={Weijie Kong and Qi Tian and Zijian Zhang and Rox Min and Zuozhuo Dai and Jin Zhou and Jiangfeng Xiong and Xin Li and Bo Wu and Jianwei Zhang and Kathrina Wu and Qin Lin and Junkun Yuan and Yanxin Long and Aladdin Wang and Andong Wang and Changlin Li and Duojun Huang and Fang Yang and Hao Tan and Hongmei Wang and Jacob Song and Jiawang Bai and Jianbing Wu and Jinbao Xue and Joey Wang and Kai Wang and Mengyang Liu and Pengyu Li and Shuai Li and Weiyan Wang and Wenqing Yu and Xinchi Deng and Yang Li and Yi Chen and Yutao Cui and Yuanbo Peng and Zhentao Yu and Zhiyu He and Zhiyong Xu and Zixiang Zhou and Zunnan Xu and Yangyu Tao and Qinglin Lu and Songtao Liu and Daquan Zhou and Hongfa Wang and Yong Yang and Di Wang and Yuhong Liu and Jie Jiang and Caesar Zhong},
      year={2025},
      eprint={2412.03603},
      archivePrefix={arXiv},
      primaryClass={cs.CV},
      url={https://arxiv.org/abs/2412.03603}, 
}

@article{kolors,
  title={Kolors: Effective Training of Diffusion Model for Photorealistic Text-to-Image Synthesis},
  author={Kolors Team},
  journal={arXiv preprint},
  year={2024}
}

@article{pixart_chen2023,
  title={Pixart-alpha: Fast training of diffusion transformer for photorealistic text-to-image synthesis},
  author={Chen, Junsong and Yu, Jincheng and Ge, Chongjian and Yao, Lewei and Xie, Enze and Wu, Yue and Wang, Zhongdao and Kwok, James and Luo, Ping and Lu, Huchuan and others},
  journal={arXiv preprint arXiv:2310.00426},
  year={2023}
}

@misc{flux,
  author = {{Black Forest Labs}},
  title = {Black Forest Labs},
  howpublished = {\url{https://github.com/black-forest-labs/flux/}},
  year = {2024}
}

@inproceedings{dit_peebles2023scalable,
  title={Scalable diffusion models with transformers},
  author={Peebles, William and Xie, Saining},
  booktitle={Proceedings of the IEEE/CVF International Conference on Computer Vision},
  pages={4195--4205},
  year={2023}
}


@inproceedings{ddim_based_parmar2023zero,
  title={Zero-shot image-to-image translation},
  author={Parmar, Gaurav and Kumar Singh, Krishna and Zhang, Richard and Li, Yijun and Lu, Jingwan and Zhu, Jun-Yan},
  booktitle={ACM SIGGRAPH 2023 Conference Proceedings},
  pages={1--11},
  year={2023}
}

@inproceedings{ddim_based_kawar2023imagic,
  title={Imagic: Text-based real image editing with diffusion models},
  author={Kawar, Bahjat and Zada, Shiran and Lang, Oran and Tov, Omer and Chang, Huiwen and Dekel, Tali and Mosseri, Inbar and Irani, Michal},
  booktitle={Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition},
  pages={6007--6017},
  year={2023}
}

@article{ddim_based_gal2022image,
  title={An image is worth one word: Personalizing text-to-image generation using textual inversion},
  author={Gal, Rinon and Alaluf, Yuval and Atzmon, Yuval and Patashnik, Or and Bermano, Amit H and Chechik, Gal and Cohen-Or, Daniel},
  journal={arXiv preprint arXiv:2208.01618},
  year={2022}
}


@inproceedings{ddim_based_tumanyan2023plug,
  title={Plug-and-play diffusion features for text-driven image-to-image translation},
  author={Tumanyan, Narek and Geyer, Michal and Bagon, Shai and Dekel, Tali},
  booktitle={Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition},
  pages={1921--1930},
  year={2023}
}

@inproceedings{omni_citation_geng2024instructdiffusion,
  title={Instructdiffusion: A generalist modeling interface for vision tasks},
  author={Geng, Zigang and Yang, Binxin and Hang, Tiankai and Li, Chen and Gu, Shuyang and Zhang, Ting and Bao, Jianmin and Zhang, Zheng and Li, Houqiang and Hu, Han and others},
  booktitle={Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition},
  pages={12709--12720},
  year={2024}
}

@inproceedings{instructpix2pix_brooks2023instructpix2pix,
  title={Instructpix2pix: Learning to follow image editing instructions},
  author={Brooks, Tim and Holynski, Aleksander and Efros, Alexei A},
  booktitle={Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition},
  pages={18392--18402},
  year={2023}
}

@article{magic_brush_zhang2024magicbrush,
  title={Magicbrush: A manually annotated dataset for instruction-guided image editing},
  author={Zhang, Kai and Mo, Lingbo and Chen, Wenhu and Sun, Huan and Su, Yu},
  journal={Advances in Neural Information Processing Systems},
  volume={36},
  year={2024}
}

@inproceedings{emu_edit_sheynin2024emu,
  title={Emu edit: Precise image editing via recognition and generation tasks},
  author={Sheynin, Shelly and Polyak, Adam and Singer, Uriel and Kirstain, Yuval and Zohar, Amit and Ashual, Oron and Parikh, Devi and Taigman, Yaniv},
  booktitle={Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition},
  pages={8871--8879},
  year={2024}
}

@article{ultraedit_zhao2024ultraedit,
  title={UltraEdit: Instruction-based Fine-Grained Image Editing at Scale},
  author={Zhao, Haozhe and Ma, Xiaojian and Chen, Liang and Si, Shuzheng and Wu, Rujie and An, Kaikai and Yu, Peiyu and Zhang, Minjia and Li, Qing and Chang, Baobao},
  journal={arXiv preprint arXiv:2407.05282},
  year={2024}
}


@article{glide_fu2023guiding,
  title={Guiding instruction-based image editing via multimodal large language models},
  author={Fu, Tsu-Jui and Hu, Wenze and Du, Xianzhi and Wang, William Yang and Yang, Yinfei and Gan, Zhe},
  journal={arXiv preprint arXiv:2309.17102},
  year={2023}
}


@article{pyramidalflow_jin2024pyramidal,
  title={Pyramidal flow matching for efficient video generative modeling},
  author={Jin, Yang and Sun, Zhicheng and Li, Ningyuan and Xu, Kun and Jiang, Hao and Zhuang, Nan and Huang, Quzhe and Song, Yang and Mu, Yadong and Lin, Zhouchen},
  journal={arXiv preprint arXiv:2410.05954},
  year={2024}
}

@article{propgen_liu2024generative,
  title={Generative Video Propagation},
  author={Liu, Shaoteng and Wang, Tianyu and Wang, Jui-Hsien and Liu, Qing and Zhang, Zhifei and Lee, Joon-Young and Li, Yijun and Yu, Bei and Lin, Zhe and Kim, Soo Ye and others},
  journal={arXiv preprint arXiv:2412.19761},
  year={2024}
}

@inproceedings{video_p2p_liu2024video,
  title={Video-p2p: Video editing with cross-attention control},
  author={Liu, Shaoteng and Zhang, Yuechen and Li, Wenbo and Lin, Zhe and Jia, Jiaya},
  booktitle={Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition},
  pages={8599--8608},
  year={2024}
}

@inproceedings{
insv2v_cheng2024consistent,
title={Consistent Video-to-Video Transfer Using Synthetic Dataset},
author={Jiaxin Cheng and Tianjun Xiao and Tong He},
booktitle={The Twelfth International Conference on Learning Representations},
year={2024},
url={https://openreview.net/forum?id=IoKRezZMxF}
}


@article{omniedit_wei2024omniedit,
  title={OmniEdit: Building Image Editing Generalist Models Through Specialist Supervision},
  author={Wei, Cong and Xiong, Zheyang and Ren, Weiming and Du, Xinrun and Zhang, Ge and Chen, Wenhu},
  journal={arXiv preprint arXiv:2411.07199},
  year={2024}
}


@article{hq_edit_hui2024hq,
  title={Hq-edit: A high-quality dataset for instruction-based image editing},
  author={Hui, Mude and Yang, Siwei and Zhao, Bingchen and Shi, Yichun and Wang, Heng and Wang, Peng and Zhou, Yuyin and Xie, Cihang},
  journal={arXiv preprint arXiv:2404.09990},
  year={2024}
}


@article{cococo_zi2024cococo,
  title={CoCoCo: Improving Text-Guided Video Inpainting for Better Consistency, Controllability and Compatibility},
  author={Zi, Bojia and Zhao, Shihao and Qi, Xianbiao and Wang, Jianan and Shi, Yukai and Chen, Qianyu and Liang, Bin and Wong, Kam-Fai and Zhang, Lei},
  journal={arXiv preprint arXiv:2403.12035},
  year={2024}
}


@article{revideo_mou2024revideo,
  title={ReVideo: Remake a Video with Motion and Content Control},
  author={Mou, Chong and Cao, Mingdeng and Wang, Xintao and Zhang, Zhaoyang and Shan, Ying and Zhang, Jian},
  journal={arXiv preprint arXiv:2405.13865},
  year={2024}
}


@article{vivid_10m_hu2024vivid,
  title={VIVID-10M: A Dataset and Baseline for Versatile and Interactive Video Local Editing},
  author={Hu, Jiahao and Zhong, Tianxiong and Wang, Xuebo and Jiang, Boyuan and Tian, Xingye and Yang, Fei and Wan, Pengfei and Zhang, Di},
  journal={arXiv preprint arXiv:2411.15260},
  year={2024}
}

@inproceedings{raccoon_yoon2024raccoon,
  title={Raccoon: Remove, add, and change video content with auto-generated narratives},
  author={Yoon, Jaehong and Yu, Shoubin and Bansal, Mohit},
  booktitle={Workshop on Video-Language Models@ NeurIPS 2024},
  year={2024}
}

@inproceedings{panda_70m_chen2024panda,
  title={Panda-70m: Captioning 70m videos with multiple cross-modality teachers},
  author={Chen, Tsai-Shien and Siarohin, Aliaksandr and Menapace, Willi and Deyneka, Ekaterina and Chao, Hsiang-wei and Jeon, Byung Eun and Fang, Yuwei and Lee, Hsin-Ying and Ren, Jian and Yang, Ming-Hsuan and others},
  booktitle={Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition},
  pages={13320--13331},
  year={2024}
}

@inproceedings{DB1_majumdar2020improving,
  title={Improving vision-and-language navigation with image-text pairs from the web},
  author={Majumdar, Arjun and Shrivastava, Ayush and Lee, Stefan and Anderson, Peter and Parikh, Devi and Batra, Dhruv},
  booktitle={Computer Vision--ECCV 2020: 16th European Conference, Glasgow, UK, August 23--28, 2020, Proceedings, Part VI 16},
  pages={259--274},
  year={2020},
  organization={Springer}
}


@inproceedings{DB2_gavrilyuk2018actor,
  title={Actor and action video segmentation from a sentence},
  author={Gavrilyuk, Kirill and Ghodrati, Amir and Li, Zhenyang and Snoek, Cees GM},
  booktitle={Proceedings of the IEEE conference on computer vision and pattern recognition},
  pages={5958--5966},
  year={2018}
}

@inproceedings{mllm_inpainting_wu2024towards,
  title={Towards language-driven video inpainting via multimodal large language models},
  author={Wu, Jianzong and Li, Xiangtai and Si, Chenyang and Zhou, Shangchen and Yang, Jingkang and Zhang, Jiangning and Li, Yining and Chen, Kai and Tong, Yunhai and Liu, Ziwei and others},
  booktitle={Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition},
  pages={12501--12511},
  year={2024}
}

@inproceedings{null_text_inversion_mokady2023null,
  title={Null-text inversion for editing real images using guided diffusion models},
  author={Mokady, Ron and Hertz, Amir and Aberman, Kfir and Pritch, Yael and Cohen-Or, Daniel},
  booktitle={Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition},
  pages={6038--6047},
  year={2023}
}

@article{sdedit_meng2021sdedit,
  title={Sdedit: Guided image synthesis and editing with stochastic differential equations},
  author={Meng, Chenlin and He, Yutong and Song, Yang and Song, Jiaming and Wu, Jiajun and Zhu, Jun-Yan and Ermon, Stefano},
  journal={arXiv preprint arXiv:2108.01073},
  year={2021}
}


@inproceedings{hive_zhang2024hive,
  title={Hive: Harnessing human feedback for instructional visual editing},
  author={Zhang, Shu and Yang, Xinyi and Feng, Yihao and Qin, Can and Chen, Chia-Chih and Yu, Ning and Chen, Zeyuan and Wang, Huan and Savarese, Silvio and Ermon, Stefano and others},
  booktitle={Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition},
  pages={9026--9036},
  year={2024}
}

@article{ddim_inversion_dhariwal2021diffusion,
  title={Diffusion models beat gans on image synthesis},
  author={Dhariwal, Prafulla and Nichol, Alexander},
  journal={Advances in neural information processing systems},
  volume={34},
  pages={8780--8794},
  year={2021}
}


@article{ddim_inversion_song2020denoising,
  title={Denoising diffusion implicit models},
  author={Song, Jiaming and Meng, Chenlin and Ermon, Stefano},
  journal={arXiv preprint arXiv:2010.02502},
  year={2020}
}


@article{ddim_inversion_song2020score,
  title={Score-based generative modeling through stochastic differential equations},
  author={Song, Yang and Sohl-Dickstein, Jascha and Kingma, Diederik P and Kumar, Abhishek and Ermon, Stefano and Poole, Ben},
  journal={arXiv preprint arXiv:2011.13456},
  year={2020}
}

@inproceedings{other_ddim_huberman2024edit,
  title={An edit friendly ddpm noise space: Inversion and manipulations},
  author={Huberman-Spiegelglas, Inbar and Kulikov, Vladimir and Michaeli, Tomer},
  booktitle={Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition},
  pages={12469--12478},
  year={2024}
}


@article{other_ddim_lu2022dpm,
  title={Dpm-solver++: Fast solver for guided sampling of diffusion probabilistic models},
  author={Lu, Cheng and Zhou, Yuhao and Bao, Fan and Chen, Jianfei and Li, Chongxuan and Zhu, Jun},
  journal={arXiv preprint arXiv:2211.01095},
  year={2022}
}


@inproceedings{other_ddim_wallace2023edict,
  title={Edict: Exact diffusion inversion via coupled transformations},
  author={Wallace, Bram and Gokul, Akash and Naik, Nikhil},
  booktitle={Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition},
  pages={22532--22541},
  year={2023}
}

@article{unicontrolnet_zhao2024uni,
  title={Uni-controlnet: All-in-one control to text-to-image diffusion models},
  author={Zhao, Shihao and Chen, Dongdong and Chen, Yen-Chun and Bao, Jianmin and Hao, Shaozhe and Yuan, Lu and Wong, Kwan-Yee K},
  journal={Advances in Neural Information Processing Systems},
  volume={36},
  year={2024}
}

@inproceedings{eve_singer2025video,
  title={Video editing via factorized diffusion distillation},
  author={Singer, Uriel and Zohar, Amit and Kirstain, Yuval and Sheynin, Shelly and Polyak, Adam and Parikh, Devi and Taigman, Yaniv},
  booktitle={European Conference on Computer Vision},
  pages={450--466},
  year={2025},
  organization={Springer}
}


@article{dreamfusion_poole2022dreamfusion,
  title={Dreamfusion: Text-to-3d using 2d diffusion},
  author={Poole, Ben and Jain, Ajay and Barron, Jonathan T and Mildenhall, Ben},
  journal={arXiv preprint arXiv:2209.14988},
  year={2022}
}


@article{Cogvlm2_hong2024cogvlm2,
  title={Cogvlm2: Visual language models for image and video understanding},
  author={Hong, Wenyi and Wang, Weihan and Ding, Ming and Yu, Wenmeng and Lv, Qingsong and Wang, Yan and Cheng, Yean and Huang, Shiyu and Ji, Junhui and Xue, Zhao and others},
  journal={arXiv preprint arXiv:2408.16500},
  year={2024}
}


@article{prompt_to_prompt_hertz2022prompt,
  title={Prompt-to-prompt image editing with cross attention control},
  author={Hertz, Amir and Mokady, Ron and Tenenbaum, Jay and Aberman, Kfir and Pritch, Yael and Cohen-Or, Daniel},
  journal={arXiv preprint arXiv:2208.01626},
  year={2022}
}


@inproceedings{blip2_li2023blip,
  title={Blip-2: Bootstrapping language-image pre-training with frozen image encoders and large language models},
  author={Li, Junnan and Li, Dongxu and Savarese, Silvio and Hoi, Steven},
  booktitle={International conference on machine learning},
  pages={19730--19742},
  year={2023},
  organization={PMLR}
}


@article{llama3_dubey2024llama,
  title={The llama 3 herd of models},
  author={Dubey, Abhimanyu and Jauhri, Abhinav and Pandey, Abhinav and Kadian, Abhishek and Al-Dahle, Ahmad and Letman, Aiesha and Mathur, Akhil and Schelten, Alan and Yang, Amy and Fan, Angela and others},
  journal={arXiv preprint arXiv:2407.21783},
  year={2024}
}


@misc{midjourney,
  author = {{Midjourney}},
  title = {Midjourney},
  howpublished = {\url{https://www.midjourney.com/}},
  year = {2024}
}

@misc{recraft_v3,
  author = {{Recraft}},
  title = {Recraft},
  howpublished = {\url{https://www.recraft.ai/}},
  year = {2024}
}

@article{stablev2v_liu2024stablev2v,
  title={StableV2V: Stablizing Shape Consistency in Video-to-Video Editing},
  author={Liu, Chang and Li, Rui and Zhang, Kaidong and Lan, Yunwei and Liu, Dong},
  journal={arXiv preprint arXiv:2411.11045},
  year={2024}
}

@article{lee2024generative,
  title={Generative Omnimatte: Learning to Decompose Video into Layers},
  author={Lee, Yao-Chih and Lu, Erika and Rumbley, Sarah and Geyer, Michal and Huang, Jia-Bin and Dekel, Tali and Cole, Forrester},
  journal={arXiv preprint arXiv:2411.16683},
  year={2024}
}

@article{video_diffusion_inpainter_lee2024video,
  title={Video diffusion models are strong video inpainter},
  author={Lee, Minhyeok and Cho, Suhwan and Shin, Chajin and Lee, Jungho and Yang, Sunghun and Lee, Sangyoun},
  journal={arXiv preprint arXiv:2408.11402},
  year={2024}
}