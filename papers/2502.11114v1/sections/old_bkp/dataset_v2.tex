\section{The \App{} Dataset}
\label{section:dataset}
In this section, we provide a detailed description of \App{}, including its structure (§\ref{section:background:struct}), annotation process (§\ref{section:background:annot-process}), dataset statistics and quality, and a comparison with previously released datasets for this task (§\ref{section:dataset:statistics}).

\subsection{Structure and Task}
\label{section:background:struct}
% \App{} is designed to assist models in training and testing for the temporal relation extraction (TRE) task (§\ref{section:background:datasets}). 
\App{} is built following the MATRES \cite{ning-etal-2018-multi} approach; however, instead of annotating events only in consecutive sentences, the annotation is \textit{exhaustive}, covering all event pairs across the entire document.
\App{} consists of a set of documents, each containing a set of event mentions, with every pair assigned one of the following relations: \textit{before}, \textit{after}, \textit{equal}, or \textit{vague}.
% Notably, the temporal relation graph derived from each document is \textit{complete}.

% \App{} consists of a set of documents, where each document contains a set of event mentions, with every pair assigned one of the relations: \textit{before}, \textit{after}, \textit{equal}, or \textit{vague} denoting a relation that cannot be resolved from the provided text. Notably, the temporal graph derived from each document is \textit{complete}.

% \cite{do-etal-2012-joint, chambers-etal-2014-dense, ning-etal-2018-multi}. TRE is formulated as follows: given a document with a set of event mentions highlighted within it, the task is to determine the temporal relations between these events. 


\subsection{Annotation Process}
\label{section:background:annot-process}
% Our goal in creating \App{}, in conjunction with previous datasets, is to provide a complete annotation that covers all possible temporal relations between any pair of event mentions in the text. However, such annotation is considered impractical for human annotators due to the quadratic complexity of annotating all pairs and the linguistic challenges involved in annotating temporal relations \cite{naik-etal-2019-tddiscourse, rogers-etal-2024-narrativetime}. To address this, we utilized the recently published EventFull annotation tool \cite{eirew2024eventfullcompleteconsistentevent}, which provides several automated functionalities that significantly reduce both the manual and cognitive workload required for annotating all relations. At the same time, it ensures that all event pairs are covered and that the temporal annotations remain consistent and free of contradictions.

% For the annotation protocol, we follow the MATRES methodology \cite{ning-etal-2018-multi}. In this method, events are distinguished by their temporal characteristics—events that are actual or ``anchorable in time'' (e.g., they \textit{\underline{won}} the game) are included, while intentional, negated, recurring, conditional, or wishful events (e.g., I \textit{wish} they \textit{\underline{win}} the game) are excluded. Furthermore, this method requires considering only the starting time of events when establishing temporal relations. Finally, we adopt the same set of relations as MATRES, covering \textit{before}, \textit{after}, \textit{equal}, and \textit{vague}, where \textit{vague} indicates that the relation cannot be determined from the provided context.


% For the annotation process, we hired three non-expert annotators, all native English speakers and either first-degree students or graduates. Using the tool, annotators first underwent 2-3 training iterations on 2-3 test documents to ensure a thorough understanding of the tasks. The actual annotation was conducted on 30 news documents (\alone{should we say these are from Multi-News?}), each approximately 500 words. To extract the initial set of event mentions, we employed the event detection method proposed by \citet{cattan-etal-2021-cross-document}, which extracted an average of 60 event mentions per document. 


We built \App{} to ensure temporal relations are annotated exhaustively between all event pairs in a document. However, the complexity of this task, especially for non-expert annotators (see §\ref{section:background:datasets}), makes full annotation hard to achieve.
% Our motivation in developing \App{} is to create a resource where temporal relations are annotated exhaustively between all event pairs within a document. However, the complexity of exhaustively labeling such a resource (as discussed in §\ref{section:background:datasets}), particularly for non-expert annotators, makes this task nearly infeasible.

%every event pair and the linguistic challenges involved in annotating temporal relations \cite{naik-etal-2019-tddiscourse, rogers-etal-2024-narrativetime} make it nearly impossible for human annotators to keep up.  

Luckily, EventFull \cite{eirew2024eventfullcompleteconsistentevent}, a recently published annotation tool, automates aspects of temporal relation annotation. This significantly reduces complexity, making the process more manageable for annotators while ensuring full event pair coverage, consistency, and preventing contradictions.\footnote{EventFull is designed to support multiple event-event relations, including temporal, causal, and coreference; we customized it to focus exclusively on temporal relation annotation.}

For event selection, we follow the MATRES annotation guidelines, considering only events that are ``actual'' (e.g., \textit{they \underline{won} the game}). Events that are ``non-actual'', such as intentional, negated, recurring, conditional, or wishful (e.g., \textit{I wish they \underline{win} the game}) are excluded from the annotation process.
Additionally, during annotation, only the starting time of events is considered when establishing temporal relations. 
%rather than their ending times. Finally, we adopted the same set of temporal relations as MATRES: \textit{before}, \textit{after}, \textit{equal}, and \textit{vague}.

We hired three annotators to perform the annotation process,\footnote{The time and cost of the annotation is further detailed in Appendix~\ref{appx:annot-costs}} all non-expert native English speakers and either undergraduate or graduate students.\footnote{Annotation time and cost are provided in Appendix~\ref{appx:annot-costs}.} For onboarding, each annotator participated in 2–3 training sessions using 2–3 test documents to ensure a thorough understanding of the annotation guidelines.
The actual annotation was done on 30 news documents, each containing approximately 500 words. The annotators used the EventFull annotation tool, with all events in each document already highlighted. These events were extracted using the event detection method proposed by \citet{cattan-etal-2021-cross-document}, which identifies all types of events (actual and non-actual) and extracts an average of 60 event mentions per document, forming the initial set of events.

We follow the same annotation protocol as proposed in EventFull. First, the annotation process begins with the selection of 15 to 18 of the most salient ``actual'' events from each story.\footnote{\citet{eirew2024eventfullcompleteconsistentevent} found that beyond 18 events, annotation becomes challenging for non-expert annotators. This event reduction aligns with previous efforts to decrease annotation workload by limiting the number of events considered \cite{chambers-etal-2014-dense, ning-etal-2018-multi, tan-etal-2024-set}.} After selecting these events, each document was annotated for temporal relations by all three annotators using the EventFull tool. Finally, majority voting was used to determine the final relation, and in cases of disagreement, the relation was labeled as \textit{vague}.


% \input{tables/agreement}


\subsection{Dataset Statistics and Comparison}
\label{section:dataset:statistics}

Table~\ref{tab:stats} summarizes the \App{} dataset's statistics. Overall, the final annotated version of \App{} consists of 30 documents, corresponding to 470 event mentions and 3,483 relations.

% Notably, both MATRES \cite{ning-etal-2018-multi} and \App{} define temporal relations based on event start times without considering duration, using four relation types (\textit{before}, \textit{after}, \textit{equal}, and \textit{vague}). In contrast, TimeBank-Dense \cite{chambers-etal-2014-dense} and NarrativeTime \cite{rogers-etal-2024-narrativetime} annotate six and seven relation types, respectively, incorporating \textit{includes} and \textit{is-included} and considering both start and end times as well as event duration. These distinctions create different challenges for models, with TimeBank-Dense and NarrativeTime presenting a more complex task. This difference is also reflected in the distinct relation distributions between the two groups, as shown in Table~\ref{tab:stats}.


\App{} provides complete annotations within each document, similar to NarrativeTime, which also follows an exhaustive annotation approach. In contrast, as discussed in §\ref{section:background}, the creators of all other relevant datasets (listed in Appendix~\ref{append:additional-figures}, Table~\ref{tab:stats_all}) did not focus on complete annotation, resulting in a lower density of annotated relations per document.
%MATRES, TimeBank-Dense, and TCR annotate only relations between events in consecutive sentences, leading to lower annotation density per document.  
In datasets with incomplete annotation, unlabeled event pairs can sometimes be inferred through transitivity rules. However, the extent to which this automatic inference scales remains unclear. To investigate this, we use the NarrativeTime dataset, which provides exhaustive annotations, allowing us to test whether transitivity can recover relations between events separated by more than two sentences and to assess their correctness against gold-standard labels. Our analysis shows that while some long-distance relations are recovered, most inferred relations remain within close proximity and occur infrequently. This highlights the importance of exhaustive annotation for constructing more complete and accurate story timelines. The full analysis is provided in Appendix~\ref{appx:trans-rels}.

% To assess this, we considered only event pairs labeled in consecutive sentences in NarrativeTime\footnote{We conducted this assessment on NarrativeTime instead of \App{}, as events in \App{} are more spread out across documents, resulting in fewer event pairs in consecutive sentences.} and applied the transitive closure algorithm \cite{warsheall-1962} to construct additional relations. While this process introduced some longer-distance relations, they remained mostly within close proximity and occurred infrequently.  

% Detailed results, including the distribution of relations by sentence distance, are provided in Appendix~\ref{append:additional-figures}. This experiment highlights the importance of exhaustive annotation for constructing more complete and accurate story timelines.


% While \App{} is of a smaller scale, its annotations are complete within each document, similar to NarrativeTime, which also emphasizes exhaustive annotations. In contrast, MATRES, TimeBank-Dense, and TCR annotate only relations between events in consecutive sentences, resulting in lower annotation density per document. We evaluate whether applying a temporal relation transitive closure algorithm \cite{warsheall-1962} can mitigate this limitation. To do so, we extracted only relations between events in consecutive sentences from the NarrativeTime\footnote{We conducted this experiment on NarrativeTime rather than \App{}, as events in \App{} are distributed throughout the documents, resulting in fewer event pairs occurring in consecutive sentences.} corpus and applied transitive closure to infer additional relations. Appendix~\ref{append:additional-figures} Figure~\ref{fig:nt_sentdiff} presents the distribution of relations by sentence distance. While this process introduces some longer-distance relations, they extend only slightly beyond consecutive sentences and occur infrequently. This underscores the importance of dense annotations for constructing a more complete and accurate story timeline.


% However, applying a temporal relation transitive closure algorithm \cite{ALLEN1984123} can help infer relations beyond consecutive sentences. 


Finally, the agreement among our annotators averaged 0.72 kappa \cite{kappa-1973}, which corresponds to substantial agreement and is comparable to that of TimeBank-Dense (0.56$\kappa$–0.64$\kappa$), NarrativeTime (0.68$\kappa$), TDD-Manual (0.69$\kappa$), and MATRES (0.84$\kappa$). Additionally, to verify annotation accuracy, one of the authors re-annotated 50 randomly selected pairs, with 46 matching the majority vote of the annotators, further confirming the high quality of the annotations.


% Finally, the agreement among our annotators averaged at 0.72 kappa \cite{kappa-1973}, which is above TimeBank-Dense (0.56-0.64), NarrativeTime (0.68), TDD-Manual (0.69$\kappa$) and slightly below MATRES (0.84). Additionally, to verify annotation accuracy, one of the authors re-annotated 50 randomly selected pairs, with 46 matching the majority vote of the annotators, further confirming the high quality of the annotations.
