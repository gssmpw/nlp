\section{Complete Zero-Shot Graph Generation}
\label{section:model}
The landscape of modeling approaches for temporal relation extraction has been dominated by the pairwise approach. In this approach the model received a single pair at a time and expect to extract the temporal relation for this pair and only after, continue to manage the next pair. Applying the pairwise approaches using LLMs has presented significant lower performances the task specific trained models and has been widely considered as ineffective for solving this task \alone{cite works}. This is specifically notable in the zero-shot setting, where only one work has been published investigate LLM capabilities on this task.

However, given the vast knowledge that contemporary LLM holds in their parameters, their multi-task performance, common-sense reasoning, and ability to compute vast texts and instruction, motivated us to revisit the zero-shot settings in a new global approach. In this section we describe the three methods we investigated.


\subsection{Pairwise Model}
Most contemporary models for creating temporal relation graphs are pairwise models. These models take a pair of events within their context, one pair at a time, and are tasked with generating the temporal relation between the events. However, because these models do not consider global temporal cues, they often produce inconsistent temporal graphs \cite{ning-etal-2018-joint, wang-etal-2020-joint, alsayyahi-batista-navarro-2023-timeline}. One of the goals of this work is to advance temporal relation extraction in two key aspects: 1) generating complete and consistent temporal graphs, and 2) moving beyond the pairwise approach to a more global approach. 

To achieve this, we adopted as our baseline models the two models from Bayesian-Trans \cite{tan-etal-2023-event}. this model is the current publicly available state-of-the-art model for both TB-Dense and MATRES datasets and prove to be a strong pairwise model. The Bayesian model follow on previous works \cite{wang-etal-2020-joint, niu-etal-2024-contempo} taking advantage of common-sense knowledge (proved to be very affective in reasoning about temporal relations between events). The model take advantage of an external knowledge source ATOMIC and COMET common sense model \cite{Hwang2020COMETATOMIC2O} to draw the relation distribution (Give more details). Indeed this model also presented strong results on our \App{} dataset \alone{ref to table}.


\input{tables/matres}

\input{tables/transfere}

\input{tables/costs}

However, our goal is to produce temporal graphs that are consistent, while a pairwise model cannot take into consideration the temporal graph properties of transitive relation, when required to produce a \textit{complete} temporal graph, the model predict many inconsistencies. Additionally, in line with prior work, we found the model also to be inconsistent in producing symmetric relations, this indicates that the model will produce unstable performance on the given dataset, depending on the set of relations and relation direction given to the model. 

To produce a temporal graph that is consistent, we apply at inference the constraints method from \citep{ning-etal-2018-joint}, this method, using the model predictions on the entire graph (n\^2 including all symmetric and transitive relations), apply symmetric and transitive constraints at inference to create the optimized consistent graph (that adhere to the transitive constraints). We fixed one of the constraints in \citep{ning-etal-2018-joint}, the vague/vague relation, in \citep{ning-etal-2018-joint}, the transitive constraints of such path is set to be vague, however, in such a case, any relation is possible (i.e., before, after, equal and vauge).

This method created a consistent graph as well as slightly improving performance. However, we observed, that the model predicts many symmetric relations that are contradicting, while under estimating the vague relations, this steams from the model tendency to predict a relation rather then the vague relation and can be sensitive to the order of features in the feature vector. To adress this, we incorporate a logic to consider such ambiguities by slightly increasing the weight of the vague relation \alone{need to better explain this with the formula}. This further increase the model performance.

\input{tables/mat_omni}

\input{tables/tb_nt}


\subsection{LLM's Model}
\begin{itemize}
    \item Our goal is to create more efficient methods of modeling the temporal extraction method that is beyond the pairwise approach (which is time and cost inefficient). To that end we created a novel approach to generate the entire graph using ZSL GPT \alone{(We also experimented with Gemeni 1.5 pro and Lamma-3 (70B) however we found GPT-4o to perform best on this task)}. 
    \item We also see that taking the 5 best scoring docs obtained from the k-fold experiment on the training set creates a much better performance then only considering the best document, however beyond this results start to deteriorate. 
    \item The model performance exceed  we achieved are rather in line with previous work, however this is more effective as we query GPT-4o once, however, these performances are much less accurate then what can be achieved using small dedicated models.
    \alone{TRY MAJORITY VOTING, take the 5 different results (I got using different examples). fill the results into a 4 hot vector and normalize to create a distribution, use this distribution with Ning.)}
\end{itemize}

\subsection{Hybrid Model}
\begin{itemize}
    \item 
\end{itemize}

\subsection{Evaluation}

\subsection{Experiments Details}
