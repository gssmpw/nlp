\section{Zero-Shot Temporal Graph Generation}
\label{section:model}
% In this section, we outline our approach to zero-shot global temporal graph generation. 
%We begin with a vanilla global approach (ZSL-Global), refine it using a chain-of-thought planning approach (ZSL-Timeline), and then describe two methods for enforcing consistency — ZSL-SelfConsistency and ZSL-GraphConsistency — on the generated temporal graphs.

\textbf{ZSL-Global}. Our approach begins with a simple yet ambitious idea: prompting an LLM\footnote{In this work we experiment with GPT-4o \url{https://platform.openai.com}.} to generate the full temporal graph of a document in a single call. This initial method, which we call ZSL-Global (prompt is provided in Appendix~\ref{append:additional-figures}), follows a straightforward zero-shot approach where the model is explicitly instructed to produce relations for all event pairs at once.

To implement this, we structure the prompt, following \citet{yuan-etal-2023-zero}. It begins with a general instruction about the task, explaining that the model needs to extract temporal relations between events. The entire document is then provided, with the relevant event mentions highlighted using angle brackets assigned unique identifiers (e.g., `<attack(7)>’). Finally, to create a realistic scenario where relations between all event pairs are desired, we include all possible pairs instead of only the gold-labeled ones. When the number of event pairs exceeds 100–200, depending on the number of events in the document, we divide them into groups of up to 200, to fit the output length constraints of the LLM. Each group is processed in a separate call to the LLM, with the full document provided alongside the subset of event pairs. Further details on how event pairs are segmented are provided in Appendix~\ref{appx:experiment:details}.
For the output, we instruct the model to represent relations as a graph, where events serve as nodes and relations as links, and format it in the DOT language \cite{Gansner2006DrawingGW} to facilitate parsing.


\textbf{ZSL-Timeline}. While the previous method provides a strong baseline, the model sometimes produces incorrect relations even when clear temporal cues exist in the text.
To improve accuracy, rather than directly generating a structured graph, we first ask the model to construct a free-form timeline—an unstructured summary describing the sequence of only the marked events in natural language (illustrated in Figure~\ref{fig:figure1}). This approach is inspired by reasoning-based prompting techniques \cite{wang-etal-2023-plan, sun-etal-2024-pearl}. By generating the timeline first, the model gains a broader understanding of the temporal flow before making explicit classification decisions. Once the timeline is generated, the model then starts generating the temporal relations for all event pairs in the DOT format, as before. This process encourages the model to ``think'' before assigning relations. We call this method ZSL-Timeline (an example of the generated timeline is presented in Appendix~\ref{append:additional-figures}, Figure~\ref{fig:timeline-output}).


\textbf{ZSL-SelfConsistency}. LLMs are inherently stochastic and may generate different labels for the same input when run multiple times. This variability can lead to unstable outputs, particularly for event pairs that are naturally difficult to classify. To address this, we incorporate self-consistency prompting \cite{wang2023selfconsistency}, where we run the model five\footnote{We generate five outputs based on experimental results showing that performance saturates beyond this point.} times on each input and aggregate the results using majority voting to determine the most frequently classified relation for each event pair. This method, which we call ZSL-SelfConsistency, improves robustness by reducing randomness.

\textbf{ZSL-GlobalConsistency}. While self-consistency helps stabilize the model’s predictions, it does so by focusing only on individual label distributions. Although the LLM considers global context when predicting all relations at once, majority voting treats each relation independently, disregarding dependencies between temporal relations.
To address this, we replace majority voting with transitive constraints using an Integer Linear Programming optimization algorithm \cite{ning-etal-2018-joint}, which enforces global consistency by resolving conflicts (For example, if event \textit{A} precedes event \textit{B} and \textit{B} precedes event \textit{C}, then \textit{A} must also precede \textit{C}), while optimizing overall likelihood over the predicted classifications. By applying these rules, the algorithm ensures that the final temporal graph satisfies transitivity and maintains logical consistency across all event pairs. A formal description of this process is provided in Appendix~\ref{appx:formal-zsl-global}.
%To address this, we replace majority voting with the transitive constraints optimization algorithm \cite{ning-etal-2018-joint}, which enforces global consistency by formulating temporal constraints as an optimization problem, ultimately constructing the final temporal graph.

Through this evolution—from a basic zero-shot approach to a structured, globally consistent method—we develop an increasingly effective strategy for leveraging LLMs in generating global temporal relation graphs. In §\ref{section:results}, we evaluate each method individually for both accuracy and consistency.  
