\section{Conclusion}

In this work, we introduced a novel zero-shot LLM approach for temporal relation extraction that generates the entire temporal graph at once. 
Our method moves beyond traditional pairwise approaches, which suffer from computational inefficiency and lack a global perspective. To ensure temporal consistency in predictions, we incorporated self-consistency prompting and transitive constraints optimization, significantly improving both accuracy and efficiency while generating relations completely free of inconsistencies. Our results show that zero-shot LLMs, when prompted to generate the timeline of events in free-form language before assigning labels to event pairs and extended with a global constraints algorithm, can serve as a viable alternative to supervised models, particularly in domains without annotated data. Additionally, we introduced \textit{\App{}}, a new dataset with complete annotations for all event pairs, following the refined annotation guidelines of MATRES. By providing gold labels for every event pair in a document, this dataset enables a fair evaluation of zero-shot approaches.

