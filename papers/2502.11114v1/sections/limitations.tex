\section*{Limitations}

While our proposed zero-shot temporal graph generation approach demonstrates significant advantages over pairwise methods, several limitations remain that warrant further investigation.

First, closed LLMs such as GPT-4o do not disclose their training data. Therefore, results on the three datasets we investigate may be affected by potential data contamination if their test sets were included in GPT's training phase. However, \App{} is a completely new resource that is not yet publicly available, ensuring uncontaminated results.

Second, although self-consistency prompting mitigates stochasticity to some extent, the modelâ€™s responses can still be inconsistent, especially when handling long-distance temporal dependencies or ambiguous event relations.

Third, the computational cost of using LLMs for large-scale inference remains a challenge. While our approach significantly reduces costs compared to pairwise methods, generating a full temporal graph for documents with many events can still be time-intensive and expensive, particularly when applying self-consistency with multiple generations.

Fourth, in this research, we present our results on GPT-4o; however, we expect similar conclusions with other equivalent LLMs.

Finally, our dataset, \textbf{OmniTemp}, provides exhaustive event-event relation annotations following the MATRES-style four-relation schema (\textit{before, after, equal, vague}), considering only the start time of events. As a result, it may not represent all TRE tasks, such as those requiring the \textit{includes} relation or those that also consider event end times and durations.

Despite these limitations, our study highlights promising directions for leveraging LLMs in structured event reasoning and lays the groundwork for future improvements in temporal relation extraction.
