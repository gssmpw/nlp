\section{Conclusions}
\label{sec:conclusion}

In this paper, we study the underlying mechanism that transformer-based LLMs use to solve in-context two-hop reasoning tasks, especially in the presence of distracting information. By carefully analyzing the training dynamics and fully reverse-engineering a three-layer transformer, we identified an interim uniform guessing mechanism during the early training stages and a sequential query mechanism after a sharp phase transition. Then, we analyzed a three-parameter dynamical system to provide further evidence and a more in-depth understanding of the phase transition in the form of the sequential query mechanism. Finally, our extensive experimental results on Llama2-7B-Base provide strong evidence that the original pre-trained model performs the uniform guessing mechanism on the two-hop reasoning task, and very few steps of fine-tuning suffice to teach the model to learn a correct mechanism.

