\section{Restricted Attention Models}
\label{sec:restricted_attention}


% The input of each layer $\ell$ is a sequence of embedding vectors $\mH^{(\ell-1)} = [\vh^{(\ell-1)}_1, \vh^{(\ell-1)}_2, \ldots, \vh^{(\ell-1)}_T ] \in \real^{d\times T}$, and the output is also a sequence of embeddings $\mH^{(\ell)} = [\vh^{(\ell)}_1, \vh^{(\ell)}_2, \ldots, \vh^{(\ell)}_T ] \in \real^{d\times T}$. The final output is $\softmax(\Wreadout\vh_T^{(L)}) \in \Delta(\vocab)$ where $\Wreadout \in \real^{V \times d}$ is the readout matrix.

% For each layer $\ell$, we have
% \begin{align*}
% \vh_i^{(\ell)} &= \sum_{j \leq i} q_{ij}^{(\ell)} \mV^{(\ell)} \vh_j^{(\ell-1)}, \\
% \text{ where } q_{ij}^{(\ell)} &= \frac{\exp(S_{ij}^{(\ell)})}{\sum_{k\leq i} \exp(S_{ik}^{(\ell)}) + \xi^{(\ell)}}. 
% \end{align*}

% Note that $\xi^{(\ell)} > 0$ is the attention logit for attention sink in layer $\ell$, where a query token can dump attention logits when there are no key tokens requiring attention~\citep{guo2024active}.

% $S_{ij}^{(\ell)}$ denotes the attention logit from token $i$ to token $j$ in layer $\ell$. Note that since we use causal attention,  $S_{ij}^{(\ell)}$ is non-zero only if $i \geq j$. Below, we provide the value of all non-zero terms among $\{S^{(\ell)}_{ij}\}$.

% \begin{align*}
% S_{ij}^{(1)} = \alpha, \quad i = \idx(\child), \, j = i-1
% \end{align*}

% \begin{align*}
% S_{ij}^{(2)} &=
% \begin{cases}
%     \beta_1 \langle \vh_i^{(1)}, \vh_j^{(1)} \rangle & i = \idx(\query),  j = \idx(\target  \brg) \\
%     \beta_2 \langle \vh_i^{(1)}, \vh_j^{(1)} \rangle & i \in \idx(\target \ed),  j = \idx(\brg \, \of \, i) \\
%     \lambda & i \in \idx(\ed),  j \in \idx(\parent)
% \end{cases}
% \end{align*}

% \begin{align*}
% S_{ij}^{(3)} &=
% \begin{cases}
%     \gamma \langle \vh_i^{(2)}, \vh_j^{(2)} \rangle + \eta & i = \idx(\query), \, j = \idx(\target \, \ed) \\
%     \eta & i = \idx(\query), \, j \in \idx(\child)
% \end{cases}
% \end{align*}


\subsection{Details of the mechanism of in-context two-hop reasoning}
\label{sec:illustration_mechanism}

% \Cref{fig:mechanism_illustration} shows the internal mechanism of a three-layer transformer to perform in-context two-hop reasoning.

In this section, we discuss the internal mechanism of a three-layer transformer to perform in-context two-hop reasoning in detail. For better visualization, we use illustrative attention maps and relegate the real attention map to Appendix~\ref{app:sec_DI_mechanism}.

\begin{figure}[h]
    \centering
    \includegraphics[width=0.7\linewidth]{figs/mlp_zero_out.pdf}
    \caption{Accuracies of the full model and the ablated models with skipped MLPs in different training stages.}
    \label{fig:mlp_zero_out}
\end{figure}

\paragraph{Attention-only model suffices to solve our in-context two-hop reasoning tasks.} We conducted ablation studies on the effect of MLP layers. \Cref{fig:mlp_zero_out} shows that even if we skip all MLP layers during inference, the model's performance on the validation set during different training stages remains nearly the same. Note that we kept all the MLP layers during the training, which provides strong evidence that MLP layers play nearly no role in the in-context two-hop reasoning tasks. Therefore, we mainly focus on attention-only transformers in this section. 

\begin{figure}[h]
    \centering
    \includegraphics[width=0.7\linewidth]{figs/acc_dynamics.pdf}
    \caption{Training Dynamics of the three-layer transformer.}
    \label{fig:acc_dynamics}
\end{figure}

\paragraph{Phase transition during training.} According to \Cref{fig:acc_dynamics}, the model mainly experienced two different phases during training. In the early stage (e.g., around training step 400), the model learned to predict an end token randomly (in \Cref{fig:acc_dynamics}, our data contains one target reasoning chain and one distracting reasoning chain, so the curve in \Cref{fig:acc_dynamics} shows that in the early stage, the model will predict the target end or non-target end with roughly equal probability). After a sharp phase transition after more than 800 training steps, the model learns to predict the correct answer perfectly. We call the interim mechanism that the model learned during the early stage \emph{uniform guessing mechanism}, and observed that the final mechanism the model learned to make the perfect prediction is a \emph{sequential query mechanism}. Besides, previous literature~\citep{sanford2024transformers} posited that the transformer performs in-context two-hop reasoning by a mechanism they theoretically constructed, which we called \emph{double induction head mechanism}. Below, we explain the uniform guessing mechanism and the sequential query mechanism layer by layer in detail. The details of the double induction head mechanism are deferred to \Cref{app:sec_DI_mechanism}.

\paragraph{The first layer.} For all the above three mechanisms, in the first layer, each child token pays all attention to its parent token by positional encoding and then copies its parent token to its buffer space to be used in subsequent layers. This is pictorially illustrated in \Cref{fig:mech:L1_copy}.

\begin{figure}[h]
    \centering
    \includegraphics[width=0.8\linewidth]{figs/mechanism/L1_copy.pdf}
    \caption{An illustration of the mechanism of the first layer. Each child token pays attention to its parent token and copies it to its buffer space.}
    \label{fig:mech:L1_copy}
\end{figure}

\begin{table}[h]
    \centering
    \renewcommand{\arraystretch}{1} % Adjust row height for better spacing
    \begin{tabular}{lccc}
        \toprule
        \textbf{Step} & \textit{Pre}-$\Brg$ & \textit{Self}-$\Ed$ & \textit{Post}-$\Brg$ \\
        \midrule
        $\mathbf{0}$ & 0.00 & 0.01 & 0.02 \\
        $\mathbf{400}$ & -1.55 & 7.14 & -0.02 \\
        $\mathbf{2000}$ & -4.80 & 11.50 & -0.05 \\
        \bottomrule
    \end{tabular}
    \caption{\textbf{The logit lens shows effect of \Ed~tokens' value states in layer 3 on the final output.} Through the logit lens, the value states become a logit score for the next token prediction. We track three groups of logits in the logit lens: The ``\textit{Pre}-\brg'' denotes the logits correspond to \brg~tokens precede the \Ed~token. The increasing logit score indicates the increasing suppression effect of the value states for \Ed~tokens to the prediction of \brg~tokens; The``\textit{Self}-\Ed'' denotes the logit corresponds to the \Ed~token itself, The increasing score indicates that \Ed's value states have increasing propensity to predict itself; The ``\textit{Post}-\brg'' denotes the \brg~tokens succeed the \Ed~token. The zero scores indicate that the suppression effect is formed in-context, not from memorization.}
    \label{tab:logit_lens_value}
\end{table}


\paragraph{The interim mechanism in early stage: uniform guessing.} During the early stage (e.g., around 400 steps), the model learns to randomly pick an end token by distinguishing between the end and bridge tokens among all child tokens. The underlying mechanism we observed is as follows. In the second layer, as shown in \Cref{fig:mech:L2_guess}, each child token will attend equally to all previous parent tokens and copy (the superposition of) them to its buffer.  The buffer space will later be used in the last layer, where the query entity (i.e., the last token in the input sequence) will attend equally to all child tokens as shown in \Cref{fig:mech:L3_guess}.  Thanks to the information on the buffer space collected in the second layer, the value state of each copied child token through the logit lens contains not only itself but also all parent tokens before that child token with a negative sign in the corresponding coordinate (\Cref{fig:mech:logit_lens_guess}). By aggregating the value states of all child tokens in the last layer, the query entity can distinguish the end token from the bridge token since the positive value of the bridge token due to $\brga$, a child token, is canceled out by the negative value caused by $\brgb$, a parent token, in the same corresponding coordinate. As a result, this interim mechanism learned in the early stage can uniformly guess an end entity as its prediction.

\begin{figure}[h]
    \centering
    \includegraphics[width=0.7\linewidth]{figs/mechanism/L2_guess.pdf}
    \caption{The uniform guessing mechanism in the second layer. Each child token pays attention to all the previous parent tokens.}
    \label{fig:mech:L2_guess}
\end{figure}

\begin{figure}[h]
    \centering
    \includegraphics[width=0.8\linewidth]{figs/mechanism/L3_guess.pdf}
    \caption{The uniform guessing mechanism in the third layer. The query entity pays attention to all the child tokens.}
    \label{fig:mech:L3_guess}
\end{figure}

\begin{figure}[h]
    \centering
    \includegraphics[width=\linewidth]{figs/mechanism/logit_lens_guess.pdf}
    \caption{Value states of the last layer through logit lens for the uniform guessing mechanism. The value of the coordinate of bridge tokens will cancel out after aggregating, which enables the query token to distinguish between the bridge entity and the end entity.}
    \label{fig:mech:logit_lens_guess}
\end{figure}

\paragraph{The (observed) sequential query mechanism after phase transition.} After the phase transition during training, the model achieves nearly perfect accuracy, and we observed a sequential query mechanism during that stage. After copying parent entities in the first layer (\Cref{fig:mech:L1_copy}), in the second layer, the query entity will pay attention to the bridge entity whose corresponding source entity in the buffer space matches the query entity. Then, it copies this bridge entity to the query entity's buffer space (\Cref{fig:mech:L2_sequential}). In the last layer, the query entity uses the collected bridge entity from the last layer to do the query again and obtains the corresponding end entity, which is exactly the expected answer (\Cref{fig:mech:L3_sequential}). Note that in a $k$-hop reasoning setting, the above sequential query mechanism performs one hop per layer and thus requires $(k+1)$ layers.

\begin{figure}[h]
    \centering
    \includegraphics[width=0.5\linewidth]{figs/mechanism/L2_sequential.pdf}
    \caption{Sequential query mechanism in the second layer. The query entity pays attention to the target \brga  entity.}
    \label{fig:mech:L2_sequential}
\end{figure}

\begin{figure}[h]
    \centering
    \includegraphics[width=0.5\linewidth]{figs/mechanism/L3_sequential.pdf}
    \caption{Sequential query mechanism in the third layer.}
    \label{fig:mech:L3_sequential}
\end{figure}

\paragraph{The model is prone to learn the sequential query mechanism.} Although the double induction head mechanism is theoretically optimal in terms of the number of layers required to perform multi-hop reasoning tasks (see \Cref{app:sec_DI_mechanism} for details), even for the simplest two-hop reasoning, the model tends to learn the sequential query mechanism according to our observations. To further understand why the model prefers the seemingly less efficient sequential query mechanism, as well as why the model abruptly learned how to solve the task during the rapid phase transition, we study a three-parameter model that fully captures the training dynamics of the three-layer transformers on our two-hop reasoning settings in \Cref{sec:three_param_model}.

\subsection{Training dynamics of the three-parameter model}
\label{sec:three_param_model}
Although the dynamics of the 3-layer transformer can be fully interpreted through uniform guessing and sequential querying, our claims are primarily based on empirical observations. To provide further evidence and gain a deeper understanding of the phase transition in the form of sequential querying, we propose studying a \textit{three-parameter dynamical system}.

Following the approach of \citet{reddy2023mechanistic}, we use the three-parameter model to simulate the dynamics of two potential mechanisms: the sequential query mechanism and the double induction head mechanism. If the dynamics of the three-parameter model match with 3-layer transformers, we gain strong evidence that the dynamics of the 3-layer transformer are truly driven by the proposed mechanism. For convenience, we define the approximate softmax operator as:
\[
\pseudosoftmax(u, M) = \frac{\exp(u)}{\exp(u)+M}.
\]
Intuitively, the approximate softmax gives the probability of an item with logit $u$ where the remaining $M$ logits are all zero. It is useful especially when we consider the ``average attention weights'' from all child to parent tokens. 

Given a residual state $u$, we use $\content(u)$, $\buffer_1(u)$, $\buffer_2(u)$ to denote the original content (i.e., the token embedding and the positional embedding) of token $u$, the buffer space of $u$ in the first layer, and the buffer space of $u$ in the second layer, respectively.

We first consider the next-token prediction \logit~on the query token. In the logit lens, as illustrated in \Cref{tab:logit_lens_value}, the value states of \Ed~tokens have large logits on itself. Therefore, we assume that $\Val(\target-\Ed) = \xi \cdot \bm{e}_{\Ed} \in \R^V$, with $\xi>0$ and $\bm{e}_{\Ed}$ being a one-hot vector in $\R^V$ that is non-zero on the index of $\Ed$. In our simulation, we fix $\xi=30$. Additionally, the attention from the query token increasingly concentrates on the target-\Ed~token along the training dynamics.  We approximate the attention weight from the query to the \target-\Ed~with $\pseudosoftmax(\attlogit(\query\to\target-\Ed), 2N)$.
Ignoring other irrelevant terms, the loss can therefore be approximated through
\begin{equation}\small
\text{Loss} = -\log(\pseudosoftmax(\attlogit(\query\to\target-\Ed)) \xi). \label{eqn:loss}
\end{equation}

To model the \attlogit, recall that the attention logit between tokens $h$ and $u$ is given by $h^\top K^{(\ell)}Q^{(\ell)} u$, with $K^{(\ell)}$, $Q^{(\ell)}$ being the weights of the key, query matrices in layer $\ell$. We rescale the $K^{(\ell)}Q^{(\ell)}$ matrices so that 
$$\alpha=\|K^{(1)}Q^{(1)}\|_2, \beta=\|K^{(2)}Q^{(2)}\|_2, \gamma=\|K^{(3)}Q^{(3)}\|_2.$$ 
We only set $\alpha$, $\beta$, and $\gamma$ as the three trainable models, which reflects the evolution of the weights in transformers.
Following the mechanism illustrated in \Cref{fig:mech:L3_sequential}, $\attlogit(\query\to\target-\Ed)$ is given by the inner product between $\buffer_2(\query)$ and $\buffer_1(\target-\Ed)$, scaled by $\gamma$. We therefore set that
\begin{align}
~& \attlogit(\query\to\target-\Ed) \nonumber \nonumber \\
= ~& \gamma \cdot \langle \buffer_2(\query), \buffer_1(\target-\Ed)\rangle.\label{eqn:gamma}
\end{align}
Similarly, as illustrated in \Cref{fig:mech:L2_sequential}, the $\buffer_2(\query)$ is proportional to the attention from query token to $\brga$ in the second layer. The query token uses its $\content(\query)$ to fit the $\buffer_1(\brga)$, copying $\content(\brg)$ to the residual stream. Therefore, we set $\buffer_2(\query)=\pseudosoftmax(\attlogit(\query\to\brga), 2N)\cdot \content(\brg)$, with 
\begin{align} 
 ~& \attlogit(\query\to\brga) \nonumber \\
= ~& \beta \langle \buffer_1(\brga), \content(\brg) \rangle. \label{eqn:beta}
\end{align}
The $\buffer_1(\cdot)$ is merely given by the copying head in the first layer, which purely relies on the positional information. We assume that the \attlogit~is only affected by the scale of the $Q^{(1)}K^{(1)}$. Therefore, for any $\child$ and $\parent$, we assume
\begin{equation}\label{eqn:alpha}
\attlogit(\child\to\parent)=\alpha. 
\end{equation}
Since the child tokens uniformly have $1$ to $2N-1$ tokens ($N$ being the number of premises) in front of them, but each of them has the same attention logit $\alpha$ with their parent, we can use $\pseudosoftmax(\alpha, N)$ to approximate the average attention weights for copying. We therefore set $\buffer_1(\brga)=\pseudosoftmax(\alpha, N)\content(\Src)$ and $\buffer_1(\Ed)=\pseudosoftmax(\alpha, N)\content(\brg)$. At last, since the task is entirely in-context, there is no fixed relationship between any tokens. We assume that $\langle\content(a),\content(b)\rangle = \bm{1}(a=b)$, which means that $\{\content(\cdot)\}$ is an orthonormal basis. By combining Equations~\eqref{eqn:gamma}, \eqref{eqn:beta}, and \eqref{eqn:alpha}, and \eqref{eqn:loss}, we get a model with three parameters $\alpha$, $\beta$, and $\gamma$ that simulates the sequential query mechanism. We optimize the loss function in Eq.~\eqref{eqn:loss} by updating $\alpha$, $\beta$, and $\gamma$ through gradient descent. 

\begin{figure}
    \centering
    \begin{subfigure}[t]{0.23\textwidth}
        \centering 
        \caption{\small Loss}
\includegraphics[width=\textwidth]{figs/loss_3.png}
    \end{subfigure}
    \begin{subfigure}[t]{0.23\textwidth}
    \centering
        \subcaption{Parameters}
\includegraphics[width=\textwidth]{figs/param_3.png}
    \end{subfigure}
    \caption{\textbf{The simulations results of the 3-parameter model} \textit{Left (a)}:  The loss function remains unchanged until a sudden phase transition occurs, after which it stabilizes at zero. \textit{Right (b)}: The parameters also went through a sudden phase transition around the step 1000.}
    \label{fig:3_param_dnamics}
\end{figure}

\Cref{fig:3_param_dnamics} presents the simulation results of the 3-parameter model. Since the model does not incorporate the random guessing mechanism, the loss remains unchanged during the first 1000 steps. This supports the hypothesis that random guessing contributes to the slow learning phase observed in the dynamics of the three-layer transformer.
Both the parameters and the loss function go through a sudden phase transition around step 1000, suggesting that the emergence of the sequential query mechanism is the driving force behind the abrupt drop in loss.

% \subsection{Experimental results}

% \hanlin{The following part might be deleted, and we will simply use the above formula.}

% The input of each layer $l$ is a sequence of embedding vectors $\mH^{(l-1)} = [\vh^{(l-1)}_1, \vh^{(l-1)}_2, \ldots, \vh^{(l-1)}_T ] \in \real^{d\times T}$, and the output is also a sequence of embeddings $\mH^{(l)} = [\vh^{(l)}_1, \vh^{(l)}_2, \ldots, \vh^{(l)}_T ] \in \real^{d\times T}$. The final output is $\softmax(\Wreadout\vh_T^{(L)}) \in \Delta(\vocab)$ where $\Wreadout \in \real^{V \times d}$ is the readout matrix. \todo{might want to use a restricted readout function to reduce the number of parameters}

% \paragraph{The first layer.} In the first layer, each child node pays attention to its parent node and copies its value state. As a result, we assume that
% \begin{equation}
% \label{eq:restricted_attn_layer_1}
% \begin{aligned}
%     \vh^{(1)}_i = \vh^{(0)}_i + \indicator\{ i > 1, i \text{ is odd} \} \cdot \Val^{(1)}(\vh^{(0)}_{i-1}). 
% \end{aligned}
% \end{equation}

% \paragraph{The second layer.} The second layer is the most interesting part and is the focus of our analysis. There is an interim mechanism appeared in the early training stage ($\beta_0$), and two candidate mechanisms after phase transition: one is the sequential query mechanism observed in our experiments ($\beta_1$), and the other was posited by previous literature ($\beta_2$). Mathematically, we have
% \begin{equation}
% \label{eq:restricted_attn_layer_2}
% \begin{aligned}
% &\Key^{(2)}(\vh^{(1)}_i) \cdot \Qry^{(2)}(\vh^{(1)}_j)  \\ 
%      = & \beta_0 \cdot \indicator\{i \text{ is even, } j \text{ is odd, } i < j \} \\
%     & + \beta_1 \cdot \indicator\{s_{i-1}=s_j, i+1 <j=T \text{ and } i \text{ is odd } \}
%     \\  & + \beta_2 \cdot \indicator\{s_{i-1}=s_j, i<j \text{ and } i, j \text{ are odd }\}
% \end{aligned}
% \end{equation}

% \paragraph{The last layer.} In the last layer, we only need to keep track of $\vh^{(3)}_T$. In either the sequential query mechanism or binary lifting mechanism, 
% \begin{equation}
% \label{eq:restricted_attn_layer_3}
% \begin{aligned}
% &\Key^{(3)}(\Val^{(2)}(\Val^{(1)}(\vh^{(0)}_i)) \cdot \Qry^{(3)}(\vh^{(0)}_T)   =  \indicator\{s_i = s_T\} \\ 
%      & \beta_0 \cdot \indicator\{i \text{ is even, } j \text{ is odd, } i < j \} \\
%     & + \beta_1 \cdot \indicator\{s_{i-1}=s_j, i+1 <j=T \text{ and } i \text{ is odd } \}
%     \\  & + \beta_2 \cdot \indicator\{s_{i-1}=s_j, i<j \text{ and } i, j \text{ are odd }\}
% \end{aligned}
% \end{equation}