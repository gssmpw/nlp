In this work, we propose an interpretable method for clinical DR grading in OCTA images. We establish a specialized heterogeneous graph representation that models the particularities of the retinal vasculature. Building on this novel data representation, we develop an efficient GNN model that solves DR staging as a graph classification task, surpassing image-based methods in performance. Finally, we introduce an interpretability tool providing fine-grained explanations for our predictions using spatial explanations that highlight critical structures and attribute their importance to specific characteristics. 


Our classification approach provides a notable step towards interpretable disease classification of OCTA images, which is crucial for adapting discriminative models in clinical practice. 
While our method improves existing explainability frameworks, we have not created a perfectly interpretable classification pipeline. Our improvements concern perspective and mathematical interpretability. Perspective interpretability is improved by the fine-grained spatial explanations that allow us to precisely visualize important vessels and intercapillary areas, which has been impossible for CNNs and vision transformers. Moreover, our attributions consist of human-interpretable concepts that are commonly associated with disease progression. By introducing a data representation based on the retinal vasculature, we restrict our model to these anatomical constraints in decision-making. We improve mathematical interpretability by limiting learnable parameters and network layers \cite{barcelo2020model}. Nevertheless, our model consists of multiple layers with activations and numerous features, which allows for non-trivial feature interaction. Therefore, the study of feature interaction, which has been previously done for MLPs \cite{tsang2017detecting}, is a necessary future work. 



%\subsection{Segmentation Dependence}
Although our approach avoids using the largely uninterpretable CNN and transformer models for the classification stage, it still relies on these architectures to generate high-quality segmentations. Utilizing this class of networks in the data representation stage provides some advantages compared to the usage at the later stage. The first advantage is the enhanced interpretability of the algorithmic outcomes using the abstracted representation. The second advantage is that the vision models can be trained on existing large-scale synthetic datasets \cite{kreitner2023detailed} compared to the disease classification task, where high-quality data is still limited. A limitation persists in the susceptibility of the graph representation to segmentation errors. However, we argue that single-stage CNN or vision transformer models would implicitly create internal representations similar to a segmentation and, therefore, may be similarly affected. Moreover, segmentation errors are easier to detect than reasoning about erroneous internal representations in CNNs and vision transformers. 
Beyond image classification, we believe that our representation is a foundation for future applications, such as link prediction for correcting erroneous segmentation and anomaly detection of intercapillary areas or vessel segments, considering their properties and neighborhoods. Finally, disease prediction through graph classification, as shown in this work, can be extended to a diverse set of clinically relevant diseases. 
