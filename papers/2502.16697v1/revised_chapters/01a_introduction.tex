Diabetic Retinopathy (DR), a complication of diabetes that affects the retinal vasculature, is one of the leading causes of blindness in adulthood \cite{teo2021global}. It is associated with pathological changes to the retinal microvasculature, resulting in a widening of the intercapillary areas, and enlargement of the foveal avascular zone (FAZ). Currently, clinicians study biomarkers that capture these changes, such as blood vessel density (BVD), Fractal Dimension (FD), and FAZ area. 
These biomarkers can be extracted from retinal images, e.g., via optical coherence tomography angiography (OCTA), a non-invasive and high-resolution retinal imaging technique \cite{sun2019oct,le2021machine}. OCTA enables the detailed examination of the retinal vasculature \cite{fayed2024retinal} down to the capillary level by resolving the superficial (SVC) and deep vascular complex (DVC), which enables early-stage DR detection \cite{moore1999three}. 

\begin{figure}[t]
    \centering
    \includegraphics[trim={0cm 0cm 1cm 0cm},clip,width = \linewidth]{figures/figure1_data_representation.drawio.pdf}
    \caption{Schematic illustration of our heterogeneous graph representing the retinal vasculature. We elevate the image to a higher abstraction level, where nodes represent understandable biological concepts, such as vessels, intercapillary areas, and the FAZ. Because of each node's biological meaning, known tabular biomarkers are naturally encoded in our heterogeneous graph. Consequently, classifiers trained on our representation combine the favorable interpretability of tabular biomarkers with image-level localization and performance.}
    \vspace{-0.5cm}
    \label{fig:abstraction}
\end{figure}

Current Machine Learning (ML)-based approaches trained on OCTA images and OCTA-extracted biomarkers have shown excellent performance for diagnosing DR \cite{le2021machine, alam2019supervised, sandhu2020automated, alam2020quantitative, heisler2020ensemble, ryu2021deep, zang2022diabetic}. However, these deep learning (DL) approaches are not used for clinical decision-making, partially because their outcomes are not interpretable, making it difficult for clinicians to verify or falsify model predictions. Although DL models may implicitly leverage high-level concepts (e.g., BVD or FAZ area), existing explainability methods fail to attribute the model's decision to these. For convolutional neural networks (CNNs), CAM \cite{zhou2016learning} and grad-CAM \cite{selvaraju2017grad} are common methods that focus on localizing critical image regions. Previous studies \cite{heisler2020ensemble, ryu2021deep, zang2022diabetic} employed these explainability methods for DR classification with mixed results. While the approach allowed a rough identification of critical image regions, the emphasized areas remain broad and unspecific. Moreover, the most critical shortcoming of these methods is the semantic gap between the highlighted image regions and human-interpretable concepts. Unlike DL approaches, inherently interpretable models, such as decision trees based on human-understandable biomarkers, do not achieve state-of-the-art prediction accuracy.

To address the challenge of interpretable OCTA image analysis with DL, we introduce a novel graph representation for OCTA images, combined with a methodological framework, for accurate and interpretable DR staging.\footnote{Code available at https://github.com/luxtu/OCTA-graph.} Specifically, our contributions are as follows:

\begin{enumerate}
    \item We introduce a heterogeneous graph representation that expresses the biological structures in OCTA images. It preserves spatial and semantic information content while abstracting from the raw image representation to make it interpretable by clinicians. Furthermore, this heterogeneous graph representation preserves neighborhood information by incorporating both homogeneous and heterogeneous edges. Figure \ref{fig:abstraction} illustrates how our approach combines the raw image's precise spatial information with the interpretative power of high-level biomarkers. The proposed representation is a foundation for diverse classification or correlation tasks, utilizing convolutional architectures such as graph neural networks (GNNs).

    \item We employ a graph learning architecture to our new representation for DR staging and exceed current state-of-the-art deep learning approaches and conventional biomarker-based solutions in prediction performance. With this application, we highlight the potential of our graph-based representation for downstream tasks.

    \item Leveraging our heterogeneous graph representation, we introduce an explainability framework for DR staging that enables the precise identification of important structures in OCTA images and couples it with interpretable features at those specific locations.
    
\end{enumerate}

By providing an interpretable data representation combined with an explainable and high-performing prediction algorithm, we aim to advance support tools for clinical decision-making.