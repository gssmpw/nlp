@incollection{Bengio+chapter2007,
author = {Bengio, Yoshua and LeCun, Yann},
booktitle = {Large Scale Kernel Machines},
publisher = {MIT Press},
title = {Scaling Learning Algorithms Towards {AI}},
year = {2007}
}

@article{Hinton06,
author = {Hinton, Geoffrey E. and Osindero, Simon and Teh, Yee Whye},
journal = {Neural Computation},
pages = {1527--1554},
title = {A Fast Learning Algorithm for Deep Belief Nets},
volume = {18},
year = {2006}
}

@book{goodfellow2016deep,
title={Deep learning},
author={Goodfellow, Ian and Bengio, Yoshua and Courville, Aaron and Bengio, Yoshua},
volume={1},
year={2016},
publisher={MIT Press}
}

@article{laskin2022context,
  title={In-context reinforcement learning with algorithm distillation},
  author={Laskin, Michael and Wang, Luyu and Oh, Junhyuk and Parisotto, Emilio and Spencer, Stephen and Steigerwald, Richie and Strouse, DJ and Hansen, Steven and Filos, Angelos and Brooks, Ethan and others},
  journal={arXiv preprint arXiv:2210.14215},
  year={2022}
}

@article{mnih2013playing,
  title={Playing atari with deep reinforcement learning},
  author={Mnih, Volodymyr},
  journal={arXiv preprint arXiv:1312.5602},
  year={2013}
}

@article{kumar2020conservative,
  title={Conservative q-learning for offline reinforcement learning},
  author={Kumar, Aviral and Zhou, Aurick and Tucker, George and Levine, Sergey},
  journal={Advances in Neural Information Processing Systems},
  volume={33},
  pages={1179--1191},
  year={2020}
}

@article{kostrikov2021offline,
  title={Offline reinforcement learning with implicit q-learning},
  author={Kostrikov, Ilya and Nair, Ashvin and Levine, Sergey},
  journal={arXiv preprint arXiv:2110.06169},
  year={2021}
}

@article{vaswani2017attention,
  title={Attention is all you need},
  author={Vaswani, A},
  journal={Advances in Neural Information Processing Systems},
  year={2017}
}

@article{brown2020language,
  title={Language models are few-shot learners},
  author={Brown, Tom and Mann, Benjamin and Ryder, Nick and Subbiah, Melanie and Kaplan, Jared D and Dhariwal, Prafulla and Neelakantan, Arvind and Shyam, Pranav and Sastry, Girish and Askell, Amanda and others},
  journal={Advances in neural information processing systems},
  volume={33},
  pages={1877--1901},
  year={2020}
}

@article{lee2024supervised,
  title={Supervised pretraining can learn in-context reinforcement learning},
  author={Lee, Jonathan and Xie, Annie and Pacchiano, Aldo and Chandak, Yash and Finn, Chelsea and Nachum, Ofir and Brunskill, Emma},
  journal={Advances in Neural Information Processing Systems},
  volume={36},
  year={2024}
}

@article{zisman2024n,
  title={N-Gram Induction Heads for In-Context RL: Improving Stability and Reducing Data Needs},
  author={Zisman, Ilya and Nikulin, Alexander and Sinii, Viacheslav and Tarasov, Denis and Lyubaykin, Nikita and Polubarov, Andrei and Kiselev, Igor and Kurenkov, Vladislav},
  journal={arXiv preprint arXiv:2411.01958},
  year={2024}
}

@article{sinii2023context,
  title={In-context reinforcement learning for variable action spaces},
  author={Sinii, Viacheslav and Nikulin, Alexander and Kurenkov, Vladislav and Zisman, Ilya and Kolesnikov, Sergey},
  journal={arXiv preprint arXiv:2312.13327},
  year={2023}
}

@article{schmied2024retrieval,
  title={Retrieval-augmented decision transformer: External memory for in-context rl},
  author={Schmied, Thomas and Paischer, Fabian and Patil, Vihang and Hofmarcher, Markus and Pascanu, Razvan and Hochreiter, Sepp},
  journal={arXiv preprint arXiv:2410.07071},
  year={2024}
}

@article{dai2024context,
  title={In-context Exploration-Exploitation for Reinforcement Learning},
  author={Dai, Zhenwen and Tomasi, Federico and Ghiassian, Sina},
  journal={arXiv preprint arXiv:2403.06826},
  year={2024}
}

@article{sondistilling,
  title={DISTILLING REINFORCEMENT LEARNING ALGO-RITHMS FOR IN-CONTEXT MODEL-BASED PLANNING},
  author={Son, Jaehyeon and Lee, Soochan and Kim, Gunhee},
  year={2024}
}

@article{grigsby2023amago,
  title={Amago: Scalable in-context reinforcement learning for adaptive agents},
  author={Grigsby, Jake and Fan, Linxi and Zhu, Yuke},
  journal={arXiv preprint arXiv:2310.09971},
  year={2023}
}

@article{elawady2024relic,
  title={ReLIC: A Recipe for 64k Steps of In-Context Reinforcement Learning for Embodied AI},
  author={Elawady, Ahmad and Chhablani, Gunjan and Ramrakhya, Ram and Yadav, Karmesh and Batra, Dhruv and Kira, Zsolt and Szot, Andrew},
  journal={arXiv preprint arXiv:2410.02751},
  year={2024}
}

@article{levine2020offline,
  title={Offline reinforcement learning: Tutorial, review, and perspectives on open problems},
  author={Levine, Sergey and Kumar, Aviral and Tucker, George and Fu, Justin},
  journal={arXiv preprint arXiv:2005.01643},
  year={2020}
}

@inproceedings{yamagata2023q,
  title={Q-learning decision transformer: Leveraging dynamic programming for conditional sequence modelling in offline rl},
  author={Yamagata, Taku and Khalil, Ahmed and Santos-Rodriguez, Raul},
  booktitle={International Conference on Machine Learning},
  pages={38989--39007},
  year={2023},
  organization={PMLR}
}

@article{hu2024q,
  title={Q-value regularized transformer for offline reinforcement learning},
  author={Hu, Shengchao and Fan, Ziqing and Huang, Chaoqin and Shen, Li and Zhang, Ya and Wang, Yanfeng and Tao, Dacheng},
  journal={arXiv preprint arXiv:2405.17098},
  year={2024}
}

@article{zhuang2024reinformer,
  title={Reinformer: Max-return sequence modeling for offline rl},
  author={Zhuang, Zifeng and Peng, Dengyun and Liu, Jinxin and Zhang, Ziqi and Wang, Donglin},
  journal={arXiv preprint arXiv:2405.08740},
  year={2024}
}

@article{huang2024context,
  title={In-Context Decision Transformer: Reinforcement Learning via Hierarchical Chain-of-Thought},
  author={Huang, Sili and Hu, Jifeng and Chen, Hechang and Sun, Lichao and Yang, Bo},
  journal={arXiv preprint arXiv:2405.20692},
  year={2024}
}

@article{beck2023survey,
  title={A survey of meta-reinforcement learning},
  author={Beck, Jacob and Vuorio, Risto and Liu, Evan Zheran and Xiong, Zheng and Zintgraf, Luisa and Finn, Chelsea and Whiteson, Shimon},
  journal={arXiv preprint arXiv:2301.08028},
  year={2023}
}

@inproceedings{fujimoto2019off,
  title={Off-policy deep reinforcement learning without exploration},
  author={Fujimoto, Scott and Meger, David and Precup, Doina},
  booktitle={International conference on machine learning},
  pages={2052--2062},
  year={2019},
  organization={PMLR}
}

@article{fujimoto2021minimalist,
  title={A minimalist approach to offline reinforcement learning},
  author={Fujimoto, Scott and Gu, Shixiang Shane},
  journal={Advances in neural information processing systems},
  volume={34},
  pages={20132--20145},
  year={2021}
}

@article{an2021uncertainty,
  title={Uncertainty-based offline reinforcement learning with diversified q-ensemble},
  author={An, Gaon and Moon, Seungyong and Kim, Jang-Hyun and Song, Hyun Oh},
  journal={Advances in neural information processing systems},
  volume={34},
  pages={7436--7447},
  year={2021}
}

@article{chen2021decision,
  title={Decision transformer: Reinforcement learning via sequence modeling},
  author={Chen, Lili and Lu, Kevin and Rajeswaran, Aravind and Lee, Kimin and Grover, Aditya and Laskin, Misha and Abbeel, Pieter and Srinivas, Aravind and Mordatch, Igor},
  journal={Advances in neural information processing systems},
  volume={34},
  pages={15084--15097},
  year={2021}
}

@article{tarasov2024revisiting,
  title={Revisiting the minimalist approach to offline reinforcement learning},
  author={Tarasov, Denis and Kurenkov, Vladislav and Nikulin, Alexander and Kolesnikov, Sergey},
  journal={Advances in Neural Information Processing Systems},
  volume={36},
  year={2024}
}

@article{agarwal2021deep,
  title={Deep Reinforcement Learning at the Edge of the Statistical Precipice},
  author={Agarwal, Rishabh and Schwarzer, Max and Castro, Pablo Samuel
          and Courville, Aaron and Bellemare, Marc G},
  journal={Advances in Neural Information Processing Systems},
  year={2021}
}

@article{snell2022offline,
  title={Offline rl for natural language generation with implicit language q learning},
  author={Snell, Charlie and Kostrikov, Ilya and Su, Yi and Yang, Mengjiao and Levine, Sergey},
  journal={arXiv preprint arXiv:2206.11871},
  year={2022}
}

@article{schweighofer2021dataset,
  title={A Dataset Perspective on Offline Reinforcement Learning},
  author={Schweighofer, Kajetan and Radler, Andreas and Dinu, Marius-Constantin and Hofmarcher, Markus and Patil, Vihang and Bitto-Nemling, Angela and Eghbal-zadeh, Hamid and Hochreiter, Sepp},
  journal={arXiv preprint arXiv:2111.04714},
  year={2021}
}

@article{tarasov2024corl,
  title={CORL: Research-oriented deep offline reinforcement learning library},
  author={Tarasov, Denis and Nikulin, Alexander and Akimov, Dmitry and Kurenkov, Vladislav and Kolesnikov, Sergey},
  journal={Advances in Neural Information Processing Systems},
  volume={36},
  year={2024}
}

@article{watkins1992q,
  title={Q-learning},
  author={Watkins, Christopher JCH and Dayan, Peter},
  journal={Machine learning},
  volume={8},
  pages={279--292},
  year={1992},
  publisher={Springer}
}

@article{kingma2014adam,
  title={Adam: A method for stochastic optimization},
  author={Kingma, Diederik P},
  journal={arXiv preprint arXiv:1412.6980},
  year={2014}
}

@article{kurenkov2024katakomba,
  title={Katakomba: tools and benchmarks for data-driven NetHack},
  author={Kurenkov, Vladislav and Nikulin, Alexander and Tarasov, Denis and Kolesnikov, Sergey},
  journal={Advances in Neural Information Processing Systems},
  volume={36},
  year={2024}
}

@article{kuttler2020nethack,
  title={The nethack learning environment},
  author={K{\"u}ttler, Heinrich and Nardelli, Nantas and Miller, Alexander and Raileanu, Roberta and Selvatici, Marco and Grefenstette, Edward and Rockt{\"a}schel, Tim},
  journal={Advances in Neural Information Processing Systems},
  volume={33},
  pages={7671--7684},
  year={2020}
}

@article{nikulin2023xland,
  title={XLand-minigrid: Scalable meta-reinforcement learning environments in JAX},
  author={Nikulin, Alexander and Kurenkov, Vladislav and Zisman, Ilya and Agarkov, Artem and Sinii, Viacheslav and Kolesnikov, Sergey},
  journal={arXiv preprint arXiv:2312.12044},
  year={2023}
}

@article{nikulin2024xland,
  title={XLand-100B: A Large-Scale Multi-Task Dataset for In-Context Reinforcement Learning},
  author={Nikulin, Alexander and Zisman, Ilya and Zemtsov, Alexey and Sinii, Viacheslav and Kurenkov, Vladislav and Kolesnikov, Sergey},
  journal={arXiv preprint arXiv:2406.08973},
  year={2024}
}

@inproceedings{yu2020meta,
  title={Meta-world: A benchmark and evaluation for multi-task and meta reinforcement learning},
  author={Yu, Tianhe and Quillen, Deirdre and He, Zhanpeng and Julian, Ryan and Hausman, Karol and Finn, Chelsea and Levine, Sergey},
  booktitle={Conference on robot learning},
  pages={1094--1100},
  year={2020},
  organization={PMLR}
}

@article{raparthy2023generalization,
  title={Generalization to new sequential decision making tasks with in-context learning},
  author={Raparthy, Sharath Chandra and Hambro, Eric and Kirk, Robert and Henaff, Mikael and Raileanu, Roberta},
  journal={arXiv preprint arXiv:2312.03801},
  year={2023}
}

@misc{polubarov2025vintixactionmodelincontext,
      title={Vintix: Action Model via In-Context Reinforcement Learning}, 
      author={Andrey Polubarov and Nikita Lyubaykin and Alexander Derevyagin and Ilya Zisman and Denis Tarasov and Alexander Nikulin and Vladislav Kurenkov},
      year={2025},
      eprint={2501.19400},
      archivePrefix={arXiv},
      primaryClass={cs.LG},
      url={https://arxiv.org/abs/2501.19400}, 
}

@article{zisman2023emergence,
  title={Emergence of In-Context Reinforcement Learning from Noise Distillation},
  author={Zisman, Ilya and Kurenkov, Vladislav and Nikulin, Alexander and Sinii, Viacheslav and Kolesnikov, Sergey},
  journal={arXiv preprint arXiv:2312.12275},
  year={2023}
}

@inproceedings{lee2022offline,
  title={Offline-to-online reinforcement learning via balanced replay and pessimistic q-ensemble},
  author={Lee, Seunghyun and Seo, Younggyo and Lee, Kimin and Abbeel, Pieter and Shin, Jinwoo},
  booktitle={Conference on Robot Learning},
  pages={1702--1712},
  year={2022},
  organization={PMLR}
}

@article{nair2020awac,
  title={Awac: Accelerating online reinforcement learning with offline datasets},
  author={Nair, Ashvin and Gupta, Abhishek and Dalal, Murtaza and Levine, Sergey},
  journal={arXiv preprint arXiv:2006.09359},
  year={2020}
}

@article{kumar2022should,
  title={When should we prefer offline reinforcement learning over behavioral cloning?},
  author={Kumar, Aviral and Hong, Joey and Singh, Anikait and Levine, Sergey},
  journal={arXiv preprint arXiv:2204.05618},
  year={2022}
}

@article{moeini2025survey,
  title={A Survey of In-Context Reinforcement Learning},
  author={Moeini, Amir and Wang, Jiuqi and Beck, Jacob and Blaser, Ethan and Whiteson, Shimon and Chandra, Rohan and Zhang, Shangtong},
  journal={arXiv preprint arXiv:2502.07978},
  year={2025}
}

@inproceedings{todorov2012mujoco,
  title={Mujoco: A physics engine for model-based control},
  author={Todorov, Emanuel and Erez, Tom and Tassa, Yuval},
  booktitle={2012 IEEE/RSJ international conference on intelligent robots and systems},
  pages={5026--5033},
  year={2012},
  organization={IEEE}
}


@inproceedings{fujimoto2018addressing,
  title={Addressing function approximation error in actor-critic methods},
  author={Fujimoto, Scott and Hoof, Herke and Meger, David},
  booktitle={International conference on machine learning},
  pages={1587--1596},
  year={2018},
  organization={PMLR}
}

@inproceedings{rakelly2019efficient,
  title={Efficient off-policy meta-reinforcement learning via probabilistic context variables},
  author={Rakelly, Kate and Zhou, Aurick and Finn, Chelsea and Levine, Sergey and Quillen, Deirdre},
  booktitle={International conference on machine learning},
  pages={5331--5340},
  year={2019},
  organization={PMLR}
}

@inproceedings{haarnoja2018soft,
  title={Soft actor-critic: Off-policy maximum entropy deep reinforcement learning with a stochastic actor},
  author={Haarnoja, Tuomas and Zhou, Aurick and Abbeel, Pieter and Levine, Sergey},
  booktitle={International conference on machine learning},
  pages={1861--1870},
  year={2018},
  organization={PMLR}
}

@article{huang2022cleanrl,
  author  = {Shengyi Huang and Rousslan Fernand Julien Dossa and Chang Ye and Jeff Braga and Dipam Chakraborty and Kinal Mehta and João G.M. Araújo},
  title   = {CleanRL: High-quality Single-file Implementations of Deep Reinforcement Learning Algorithms},
  journal = {Journal of Machine Learning Research},
  year    = {2022},
  volume  = {23},
  number  = {274},
  pages   = {1--18},
  url     = {http://jmlr.org/papers/v23/21-1342.html}
}

@article{ba2016layer,
  title={Layer normalization},
  author={Ba, Jimmy Lei and Kiros, Jamie Ryan and Hinton, Geoffrey E},
  journal={arXiv preprint arXiv:1607.06450},
  year={2016}
}

@article{akyurek2024context,
  title={In-context language learning: Architectures and algorithms},
  author={Aky{\"u}rek, Ekin and Wang, Bailin and Kim, Yoon and Andreas, Jacob},
  journal={arXiv preprint arXiv:2401.12973},
  year={2024}
}

@article{obando2024mixtures,
  title={Mixtures of experts unlock parameter scaling for deep rl},
  author={Obando-Ceron, Johan and Sokar, Ghada and Willi, Timon and Lyle, Clare and Farebrother, Jesse and Foerster, Jakob and Dziugaite, Gintare Karolina and Precup, Doina and Castro, Pablo Samuel},
  journal={arXiv preprint arXiv:2402.08609},
  year={2024}
}

@article{shazeer2017outrageously,
  title={Outrageously large neural networks: The sparsely-gated mixture-of-experts layer},
  author={Shazeer, Noam and Mirhoseini, Azalia and Maziarz, Krzysztof and Davis, Andy and Le, Quoc and Hinton, Geoffrey and Dean, Jeff},
  journal={arXiv preprint arXiv:1701.06538},
  year={2017}
}

@article{farebrother2024stop,
  title={Stop regressing: Training value functions via classification for scalable deep rl},
  author={Farebrother, Jesse and Orbay, Jordi and Vuong, Quan and Ta{\"\i}ga, Adrien Ali and Chebotar, Yevgen and Xiao, Ted and Irpan, Alex and Levine, Sergey and Castro, Pablo Samuel and Faust, Aleksandra and others},
  journal={arXiv preprint arXiv:2403.03950},
  year={2024}
}

@article{tarasov2024value,
  title={Is Value Functions Estimation with Classification Plug-and-play for Offline Reinforcement Learning?},
  author={Tarasov, Denis and Brilliantov, Kirill and Kharlapenko, Dmitrii},
  journal={arXiv preprint arXiv:2406.06309},
  year={2024}
}