[
  {
    "index": 0,
    "papers": [
      {
        "key": "levine2020offline",
        "author": "Levine, Sergey and Kumar, Aviral and Tucker, George and Fu, Justin",
        "title": "Offline reinforcement learning: Tutorial, review, and perspectives on open problems"
      }
    ]
  },
  {
    "index": 1,
    "papers": [
      {
        "key": "kumar2020conservative",
        "author": "Kumar, Aviral and Zhou, Aurick and Tucker, George and Levine, Sergey",
        "title": "Conservative q-learning for offline reinforcement learning"
      },
      {
        "key": "an2021uncertainty",
        "author": "An, Gaon and Moon, Seungyong and Kim, Jang-Hyun and Song, Hyun Oh",
        "title": "Uncertainty-based offline reinforcement learning with diversified q-ensemble"
      },
      {
        "key": "kostrikov2021offline",
        "author": "Kostrikov, Ilya and Nair, Ashvin and Levine, Sergey",
        "title": "Offline reinforcement learning with implicit q-learning"
      },
      {
        "key": "fujimoto2021minimalist",
        "author": "Fujimoto, Scott and Gu, Shixiang Shane",
        "title": "A minimalist approach to offline reinforcement learning"
      }
    ]
  },
  {
    "index": 2,
    "papers": [
      {
        "key": "kumar2020conservative",
        "author": "Kumar, Aviral and Zhou, Aurick and Tucker, George and Levine, Sergey",
        "title": "Conservative q-learning for offline reinforcement learning"
      }
    ]
  },
  {
    "index": 3,
    "papers": [
      {
        "key": "kostrikov2021offline",
        "author": "Kostrikov, Ilya and Nair, Ashvin and Levine, Sergey",
        "title": "Offline reinforcement learning with implicit q-learning"
      }
    ]
  },
  {
    "index": 4,
    "papers": [
      {
        "key": "tarasov2024corl",
        "author": "Tarasov, Denis and Nikulin, Alexander and Akimov, Dmitry and Kurenkov, Vladislav and Kolesnikov, Sergey",
        "title": "CORL: Research-oriented deep offline reinforcement learning library"
      }
    ]
  },
  {
    "index": 5,
    "papers": [
      {
        "key": "tarasov2024revisiting",
        "author": "Tarasov, Denis and Kurenkov, Vladislav and Nikulin, Alexander and Kolesnikov, Sergey",
        "title": "Revisiting the minimalist approach to offline reinforcement learning"
      }
    ]
  },
  {
    "index": 6,
    "papers": [
      {
        "key": "fujimoto2021minimalist",
        "author": "Fujimoto, Scott and Gu, Shixiang Shane",
        "title": "A minimalist approach to offline reinforcement learning"
      }
    ]
  },
  {
    "index": 7,
    "papers": [
      {
        "key": "chen2021decision",
        "author": "Chen, Lili and Lu, Kevin and Rajeswaran, Aravind and Lee, Kimin and Grover, Aditya and Laskin, Misha and Abbeel, Pieter and Srinivas, Aravind and Mordatch, Igor",
        "title": "Decision transformer: Reinforcement learning via sequence modeling"
      }
    ]
  },
  {
    "index": 8,
    "papers": [
      {
        "key": "yamagata2023q",
        "author": "Yamagata, Taku and Khalil, Ahmed and Santos-Rodriguez, Raul",
        "title": "Q-learning decision transformer: Leveraging dynamic programming for conditional sequence modelling in offline rl"
      },
      {
        "key": "hu2024q",
        "author": "Hu, Shengchao and Fan, Ziqing and Huang, Chaoqin and Shen, Li and Zhang, Ya and Wang, Yanfeng and Tao, Dacheng",
        "title": "Q-value regularized transformer for offline reinforcement learning"
      },
      {
        "key": "zhuang2024reinformer",
        "author": "Zhuang, Zifeng and Peng, Dengyun and Liu, Jinxin and Zhang, Ziqi and Wang, Donglin",
        "title": "Reinformer: Max-return sequence modeling for offline rl"
      }
    ]
  },
  {
    "index": 9,
    "papers": [
      {
        "key": "laskin2022context",
        "author": "Laskin, Michael and Wang, Luyu and Oh, Junhyuk and Parisotto, Emilio and Spencer, Stephen and Steigerwald, Richie and Strouse, DJ and Hansen, Steven and Filos, Angelos and Brooks, Ethan and others",
        "title": "In-context reinforcement learning with algorithm distillation"
      }
    ]
  },
  {
    "index": 10,
    "papers": [
      {
        "key": "lee2024supervised",
        "author": "Lee, Jonathan and Xie, Annie and Pacchiano, Aldo and Chandak, Yash and Finn, Chelsea and Nachum, Ofir and Brunskill, Emma",
        "title": "Supervised pretraining can learn in-context reinforcement learning"
      }
    ]
  },
  {
    "index": 11,
    "papers": [
      {
        "key": "sinii2023context",
        "author": "Sinii, Viacheslav and Nikulin, Alexander and Kurenkov, Vladislav and Zisman, Ilya and Kolesnikov, Sergey",
        "title": "In-context reinforcement learning for variable action spaces"
      },
      {
        "key": "schmied2024retrieval",
        "author": "Schmied, Thomas and Paischer, Fabian and Patil, Vihang and Hofmarcher, Markus and Pascanu, Razvan and Hochreiter, Sepp",
        "title": "Retrieval-augmented decision transformer: External memory for in-context rl"
      },
      {
        "key": "dai2024context",
        "author": "Dai, Zhenwen and Tomasi, Federico and Ghiassian, Sina",
        "title": "In-context Exploration-Exploitation for Reinforcement Learning"
      },
      {
        "key": "huang2024context",
        "author": "Huang, Sili and Hu, Jifeng and Chen, Hechang and Sun, Lichao and Yang, Bo",
        "title": "In-Context Decision Transformer: Reinforcement Learning via Hierarchical Chain-of-Thought"
      },
      {
        "key": "sondistilling",
        "author": "Son, Jaehyeon and Lee, Soochan and Kim, Gunhee",
        "title": "DISTILLING REINFORCEMENT LEARNING ALGO-RITHMS FOR IN-CONTEXT MODEL-BASED PLANNING"
      },
      {
        "key": "zisman2024n",
        "author": "Zisman, Ilya and Nikulin, Alexander and Sinii, Viacheslav and Tarasov, Denis and Lyubaykin, Nikita and Polubarov, Andrei and Kiselev, Igor and Kurenkov, Vladislav",
        "title": "N-Gram Induction Heads for In-Context RL: Improving Stability and Reducing Data Needs"
      }
    ]
  },
  {
    "index": 12,
    "papers": [
      {
        "key": "grigsby2023amago",
        "author": "Grigsby, Jake and Fan, Linxi and Zhu, Yuke",
        "title": "Amago: Scalable in-context reinforcement learning for adaptive agents"
      }
    ]
  },
  {
    "index": 13,
    "papers": [
      {
        "key": "elawady2024relic",
        "author": "Elawady, Ahmad and Chhablani, Gunjan and Ramrakhya, Ram and Yadav, Karmesh and Batra, Dhruv and Kira, Zsolt and Szot, Andrew",
        "title": "ReLIC: A Recipe for 64k Steps of In-Context Reinforcement Learning for Embodied AI"
      }
    ]
  },
  {
    "index": 14,
    "papers": [
      {
        "key": "fujimoto2019off",
        "author": "Fujimoto, Scott and Meger, David and Precup, Doina",
        "title": "Off-policy deep reinforcement learning without exploration"
      },
      {
        "key": "levine2020offline",
        "author": "Levine, Sergey and Kumar, Aviral and Tucker, George and Fu, Justin",
        "title": "Offline reinforcement learning: Tutorial, review, and perspectives on open problems"
      }
    ]
  }
]