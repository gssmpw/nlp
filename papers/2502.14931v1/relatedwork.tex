\section{Related Work}
% 1) visual SLAM with and without semantic
\subsection{Visual SLAM system}

    Visual Simultaneous Localization and Mapping (SLAM) using visual sensors is a long-standing and active research topic that focuses on the simultaneous estimation of ego-motion and the reconstruction of a global 3D map. 
    Traditional SLAM methods \cite{mur2015orb, mur2017orb, campos2021orb, engel2017direct}, developed over many years, have demonstrated both high accuracy and robustness, even in challenging environments. This makes them an indispensable frontend foundation for various real-world applications, such as autonomous driving and drones.
    In recent years, several new 3D representations have emerged in the 3D computer vision fields. With the advent of neural implicit representations, numerous works \cite{sucar2021imap, zhu2022nice, zhu2024nicer, johari2023eslam} have demonstrated the effectiveness of NeRF-based SLAM approaches. These new representations introduce novel capabilities to the SLAM community, including enhanced rendering capability. %, novel view synthesis, and the ability to fully leverage neural networks.
    3D Gaussian Splatting is the latest advancement in the 3D vision field, offering significantly faster rendering speed and strong performance compared with neural implicit representations. Recent works \cite{keetha2023splatam, matsuki2024gaussian, yugay2023gaussian, huang2024photo} have demonstrated new SLAM capabilities by integrating 3D Gaussian Splatting techniques, further pushing the boundaries of real-time scene understanding and reconstruction.

% 2) Neural Implicit semantic SLAM with and without semantic
\subsection{Neural implicit visual SLAM}

    Neural Radiance Fields (NeRF) \cite{mildenhall2021nerf} is a neural rendering technique that represents 3D scenes using a fully connected neural network.
    iMap \cite{sucar2021imap} proposes a real-time keyframe-based RGB-D SLAM method that uses a multilayer perceptron (MLP) as the sole scene representation.
    Nice-SLAM \cite{zhu2022nice} introduces a dense SLAM system that incorporates multi-level local information by employing a hierarchical scene representation.
    Nicer-SLAM \cite{zhu2024nicer} extends this approach by proposing a monocular SLAM system with a hierarchical neural implicit map representation, eliminating the dependency on depth information.
    Integrating SLAM with semantic understanding, many works \cite{li2023dns, zhu2023sni, haghighi2023neural} have explored neural implicit representations for semantic mapping and localization tasks. 
    DNS-SLAM \cite{li2023dns} incorporates 2D semantic priors with a coarse-to-fine geometry representation to embed semantic information into the map.
    SNI-SLAM \cite{zhu2023sni} integrates geometry, appearance, and semantic features into a shared feature space to enhance the robustness of the SLAM method.
    However, these approaches are constrained by the slow convergence of neural implicit map representations, which often leads to performance degradation when coupled with semantic objectives \cite{Hu2022CVPR, Liu2023ICCV}. 
    In contrast, Gaussian Splatting provides significant advantages, including fast rendering performance and high-density reconstruction quality, making it a promising alternative for map representation.

    % Semantic SLAM has been a long-standing research focus in computer vision and robotics \cite{chang2021kimera, li2023textslam, rosinol2020kimera, li2020textslam, sualeh2019simultaneous}. 
    

    % NeRF (Neural Radiance Fields) is a neural rendering technique that represents 3D scenes using a fully connected neural network. It learns to encode the volumetric appearance and geometry of a scene from a set of 2D images with known camera poses and can synthesize novel views by querying the learned model. NeRF models a scene as a continuous function that maps a 3D point and a viewing direction to color (RGB) and density (opacity). It is trained using a differentiable rendering process, optimizing the network by minimizing the difference between rendered and observed images.

% 1) 3D Gaussian Splatting SLAM with and without semantic
\subsection{3D Gaussian Splatting SLAM}
    % 3d gs slam without semantics
    3D Gaussian Splatting has recently gained attention as a promising 3D representation due to its fast rendering performance and high-density reconstruction quality. 
    Leveraging this 3D representation, SplaTAM \cite{keetha2023splatam} uses silhouette guidance for pose estimation and map reconstruction in RGB-D SLAM systems, while MonoGS \cite{matsuki2024gaussian} supports both monocular and RGB-D SLAM. 
    Photo-SLAM \cite{huang2024photo} utilizes 3D points generated by ORB-SLAM as position parameters for Gaussian Splatting primitives within the SLAM system.
    % GS-SLAM \cite{yan2024gs} employs a coarse-to-fine camera tracking method with sparse Gaussian selection, and Photo-SLAM \cite{huang2024photo} combines ORB-SLAM3 for pose estimation with 3D Gaussian Splatting to create global maps. 
    % Gaussian-SLAM \cite{yugay2023gaussian} further enhances the framework by utilizing pose results from DROID-SLAM \cite{teed2021droid} to manage active and inactive 3D Gaussian submaps.
    These studies highlight the strong potential of 3D Gaussian Splatting in SLAM tasks across various scenarios \cite{keetha2023splatam, matsuki2024gaussian, yan2024gs, huang2024photo, yugay2023gaussian}. 
    However, integrating semantic understanding into SLAM presents a significant challenge, as it requires jointly solving three high-dimensional optimization problems with varying value ranges and convergence behaviors, while also significantly increasing storage requirements. 
    %% our work
    % In this paper, we address this challenge by employing hierarchical coding for semantic information and developing an effective optimization strategy to ensure robust performance.
    % Gaussian Splatting Semantic SLAM
    % With the recent rise of 3D Gaussian Splatting, there have been attempts to integrate semantic information into the 3D Gaussian Splatting SLAM system.
    Focus on the integration of semantic information into the Gaussian Splatting SLAM, SGS-SLAM \cite{li2024sgs} added RGB 3-channels to create a semantic visualization map to avoid true semantic labels learning.
    SemGauss-SLAM \cite{zhu2024semgauss} uses a flat semantic representation supervised by a large pre-trained foundation model. However, these methods overlook the natural hierarchical structure of the real world. Additionally, relying on large foundation models increases the complexity of the neural network and its computational demands, with performance largely dependent on the embeddings from these pre-trained models.
    Eliminating the dependency on foundation models, this work proposes a simple yet effective hierarchical representation for semantic understanding in the SLAM system which largely reduces the training storage and time. 


% \subsection{Feed-forward Methods?} % review