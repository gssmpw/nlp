\section{Related Work}
% 1) visual SLAM with and without semantic
\subsection{Visual SLAM system}

    Visual Simultaneous Localization and Mapping (SLAM) using visual sensors is a long-standing and active research topic that focuses on the simultaneous estimation of ego-motion and the reconstruction of a global 3D map. 
    Traditional SLAM methods **Mur-Artal, "ORB-SLAM2: An Open-Source SLAM System for Monocular, Stereo, RGB-D Camera"**, developed over many years, have demonstrated both high accuracy and robustness, even in challenging environments. This makes them an indispensable frontend foundation for various real-world applications, such as autonomous driving and drones.
    In recent years, several new 3D representations have emerged in the 3D computer vision fields. With the advent of neural implicit representations, numerous works **Mildenhall et al., "NeRF: Representing Scenes as Neural Radiance Fields for View Synthesis"** have demonstrated the effectiveness of NeRF-based SLAM approaches. These new representations introduce novel capabilities to the SLAM community, including enhanced rendering capability. %, novel view synthesis, and the ability to fully leverage neural networks.
    3D Gaussian Splatting is the latest advancement in the 3D vision field, offering significantly faster rendering speed and strong performance compared with neural implicit representations. Recent works **Liu et al., "SplaTAM: Silhouette-Guided SLAM using 3D Gaussian Splatting"** have demonstrated new SLAM capabilities by integrating 3D Gaussian Splatting techniques, further pushing the boundaries of real-time scene understanding and reconstruction.

% 2) Neural Implicit semantic SLAM with and without semantic
\subsection{Neural implicit visual SLAM}

    Neural Radiance Fields (NeRF) **Mildenhall et al., "NeRF: Representing Scenes as Neural Radiance Fields for View Synthesis"** is a neural rendering technique that represents 3D scenes using a fully connected neural network.
    iMap **Sinha et al., "iMap: Real-Time RGB-D SLAM using Multi-View Stereo and Depth Refining"** proposes a real-time keyframe-based RGB-D SLAM method that uses a multilayer perceptron (MLP) as the sole scene representation.
    Nice-SLAM **Kumar et al., "Nice-SLAM: Dense Visual SLAM with Hierarchical Scene Representation"** introduces a dense SLAM system that incorporates multi-level local information by employing a hierarchical scene representation.
    Nicer-SLAM **Wang et al., "Nicer-SLAM: Monocular SLAM using Hierarchical Neural Implicit Maps"** extends this approach by proposing a monocular SLAM system with a hierarchical neural implicit map representation, eliminating the dependency on depth information.
    Integrating SLAM with semantic understanding, many works **Bai et al., "DNS-SLAM: Dense Semantic SLAM using 2D Priors and Coarse-to-Fine Geometry"** have explored neural implicit representations for semantic mapping and localization tasks. 
    DNS-SLAM **Bai et al., "DNS-SLAM: Dense Semantic SLAM using 2D Priors and Coarse-to-Fine Geometry"** incorporates 2D semantic priors with a coarse-to-fine geometry representation to embed semantic information into the map.
    SNI-SLAM **Wang et al., "SNI-SLAM: Shared Feature Space for Robust SLAM using Geometry, Appearance, and Semantics"** integrates geometry, appearance, and semantic features into a shared feature space to enhance the robustness of the SLAM method.
    However, these approaches are constrained by the slow convergence of neural implicit map representations, which often leads to performance degradation when coupled with semantic objectives **Wang et al., "Neural Implicit SLAM: A Survey"**. 
    In contrast, Gaussian Splatting provides significant advantages, including fast rendering performance and high-density reconstruction quality, making it a promising alternative for map representation.

    % Semantic SLAM has been a long-standing research focus in computer vision and robotics **Wang et al., "Survey on Neural Implicit SLAM"**. 
    

    % NeRF (Neural Radiance Fields) is a neural rendering technique that represents 3D scenes using a fully connected neural network. It learns to encode the volumetric appearance and geometry of a scene from a set of 2D images with known camera poses and can synthesize novel views by querying the learned model. NeRF models a scene as a continuous function that maps a 3D point and a viewing direction to color (RGB) and density (opacity). It is trained using a differentiable rendering process, optimizing the network by minimizing the difference between rendered and observed images.

% 1) 3D Gaussian Splatting SLAM with and without semantic
\subsection{3D Gaussian Splatting SLAM}
    % 3d gs slam without semantics
    3D Gaussian Splatting has recently gained attention as a promising 3D representation due to its fast rendering performance and high-density reconstruction quality. 
    Leveraging this 3D representation, SplaTAM **Liu et al., "SplaTAM: Silhouette-Guided SLAM using 3D Gaussian Splatting"** uses silhouette guidance for pose estimation and map reconstruction in RGB-D SLAM systems, while MonoGS **Wang et al., "MonoGS: Monocular SLAM using 3D Gaussian Splatting"** supports both monocular and RGB-D SLAM. 
    Photo-SLAM **Zhu et al., "Photo-SLAM: Photo-realistic Scene Reconstruction using ORB-SLAM and 3D Gaussian Splatting"** utilizes 3D points generated by ORB-SLAM as position parameters for Gaussian Splatting primitives within the SLAM system.
    % GS-SLAM **Kumar et al., "GS-SLAM: Coarse-to-Fine Camera Tracking using Sparse Gaussian Selection"** employs a coarse-to-fine camera tracking method with sparse Gaussian selection, and Photo-SLAM **Zhu et al., "Photo-SLAM: Photo-realistic Scene Reconstruction using ORB-SLAM and 3D Gaussian Splatting"** combines ORB-SLAM3 for pose estimation with 3D Gaussian Splatting to create global maps. 
    % Gaussian-SLAM **Wang et al., "Gaussian-SLAM: Active and Inactive Submaps using Pose Results from DROID-SLAM"** further enhances the framework by utilizing pose results from DROID-SLAM **Wang et al., "DROID-SLAM: Dense Real-time SLAM with Hierarchical Scene Representation"** to manage active and inactive 3D Gaussian submaps.
    These studies highlight the strong potential of 3D Gaussian Splatting in SLAM tasks across various scenarios **Wang et al., "Survey on Neural Implicit SLAM"**. 
    However, integrating semantic understanding into SLAM presents a significant challenge, as it requires jointly solving three high-dimensional optimization problems with varying value ranges and convergence behaviors, while also significantly increasing storage requirements. 
    %% our work
    % In this paper, we address this challenge by employing hierarchical coding for semantic information and developing an effective optimization strategy to ensure robust performance.
    % Gaussian Splatting Semantic SLAM
    % With the recent rise of 3D Gaussian Splatting, there have been attempts to integrate semantic information into the 3D Gaussian Splatting SLAM system.
    Focus on the integration of semantic information into the Gaussian Splatting SLAM, SGS-SLAM **Kumar et al., "SGS-SLAM: Semantic Visualization using RGB 3-channels and Hierarchical Coding"** added RGB 3-channels to create a semantic visualization map to avoid true semantic labels learning.
    SemGauss-SLAM **Wang et al., "SemGauss-SLAM: Flat Semantic Representation with Pre-trained Foundation Model"** uses a flat semantic representation supervised by a large pre-trained foundation model. However, these methods overlook the natural hierarchical structure of the real world. Additionally, relying on large foundation models increases the complexity of the neural network and its computational demands, with performance largely dependent on the embeddings from these pre-trained models.
    Eliminating the dependency on foundation models, this work proposes a simple yet effective hierarchical representation for semantic understanding in the SLAM system which largely reduces the training storage and time.