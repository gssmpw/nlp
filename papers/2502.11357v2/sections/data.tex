



We design an automatic web trajectory synthesis pipeline that explores websites to generate diverse web trajectories.
It utilizes Playwright\footnote{https://playwright.dev/} to execute actions and collect metadata from real-world websites, starting from an initial URL.\footnote{For a 4K subset of trajectories, we instruct GPT-4o to navigate to the target website by formulating a Google search query based on the task description.}
The metadata includes screenshots, HTML,  A11y tree, and actions in grounded and natural language forms.
The action space is given in Table~\ref{tab:action}.

\subsection{Website Selection}
We use a combination of URL sources to generate the synthetic web trajectories.
We obtain the top 100 URLs from \url{similarweb.com} corresponding to the high-traffic portion of the web with transactional tasks like booking flights, restaurant reservations, government services, sports, entertainment, etc.
The Tranco \cite{DBLP:conf/ndss/PochatGTKJ19} URLs include 49K URLs representing the head portion of the web, which is less trafficked but popular nonetheless.
We filter out harmful websites containing violent or explicit content to ensure safety compliance.
Overall, we generate 94K trajectories across both sources.
The complete data generation takes 50 hours, utilizing 60 parallel processes.
The viewport resolution is up to $1980\times1080$.





\input{tables/action_space}

\input{tables/traj_source_stats}

\input{figures/hist_num_toks}

\input{tables/cost_analysis}

\input{figures/data_composition}

\subsection{Data Generation Pipeline}


We aim to develop a generalized pipeline for web exploration to collect diverse web trajectory data.
To enhance diversity, we adopt a bottom-up approach, starting with low-level actions and progressively shaping them into high-level task descriptions while maintaining a coherent task intent.
In the first step, the proposer agent generates an abstract task, which is refined to a more specific task through a refinement process.
For instance, starting from the Amazon homepage, the initial task proposal might be ``Find today’s deals on Amazon'', which is progressively refined into ``Proceed to checkout for the Amazon eero Pro 6E mesh Wi-Fi router with 36\% off'' (Figure~\ref{fig:data_pipeline}).
Since the agents execute actions alongside the refinement process, the generated tasks respect real-world constraints, such as product availability, available color options, and other specifications, ensuring practical applicability.
Our pipeline consists of the following LLM-powered agents\footnote{We use GPT-4o as the agent backbone throughout the data generation process.}:

\paragraph{Task Proposer.}
Given a website homepage, including its screenshot and accessibility tree, the task proposer agent generates diverse initial tasks that could be performed on that website.
The task descriptions at this stage are instructed to be high-level and abstract versions of the real-world tasks, which will be refined into more specific tasks in later stages.
Along with generating the task proposal, the agent proposes and executes the first action toward completing that task.
Furthermore, the agent is instructed to halt upon encountering robot detection mechanisms, CAPTCHA verification, login prompts, or payment requests.



\paragraph{Task Refiner.}
The task refiner agent receives the initial task proposal or the refined task description from the previous step, along with the corresponding action history as inputs.
It then predicts the next action consistent with the input task description and the updated refined task description 
while incorporating the complete action history.
By iteratively refining the task description after each action, the agent ensures that the updated task remains aligned with the action history.

\paragraph{Task Summarizer.}
This module processes the entire action and screenshot history to predict an overall task description that aligns with the trajectory.
The task summary is expected to be high level, \textit{i.e.}, it should describe what the task entails while omitting how it is accomplished.

\paragraph{Task Verifier.}\label{sec:verifier}
Inspired by \citet{DBLP:journals/corr/abs-2404-06474}, the task verifier agent receives the task description and action history, serving as a critic to evaluate whether the trajectory successfully completes the specified task.
In addition to the screenshots of the trajectory, it also receives a markdown representation of the last page.
This ensures the verifier has the full context of the website's final state, even when the viewport cannot capture all the content.
Such automatic evaluation of web trajectories has been widely adopted in prior work \cite{xu2024agenttrek, DBLP:conf/acl/HeYM0D0L024, koh2024tree}. 
Figure~\ref{fig:data_pipeline} illustrates the above pipeline.
The prompts for the above agents are given in Appendix~\ref{sec:prompt_details}. 






\subsection{Dataset Analysis}


\model comprises web trajectories spanning diverse domains, including services, entertainment, shopping, travel, and information, ensuring broad task diversity.
Figure~\ref{fig:data_composition} visualizes the domain and subdomain distribution, highlighting the dataset's rich diversity.
Sample tasks from \model are presented in Table~\ref{tab:traj_ex}.
To the best of our knowledge, \model with 94K trajectories is the largest web trajectory dataset of this scale.
Table~\ref{tab:data_comp} shows a comparison with existing web agent datasets from the literature.
The detailed statistics are given in Table~\ref{tab:data_stat}. 
Figure~\ref{fig:hist_num_tok} shows the histogram of token distribution across the dataset.

Beyond diversity, \model is also highly scalable and cost-efficient.
Our approach achieves a cost of \$0.28 per successful trajectory, making it approx.\ $2\times$ more cost-effective than AgentTrek \cite{xu2024agenttrek} (which incurs \$0.55 per trajectory) and significantly cheaper than human annotation (Table~\ref{tab:cost}).
Unlike human annotation, which requires training crowd workers and continuous quality monitoring, Explorer’s automated generation pipeline eliminates these bottlenecks, ensuring scalability with minimal overhead.
By integrating diversity, scalability, and cost efficiency, \model sets a new benchmark for generating large-scale web trajectory datasets, making it a valuable resource for training generalist web agents.



