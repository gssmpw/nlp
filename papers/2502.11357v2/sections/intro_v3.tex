Graphical User Interfaces (GUIs) serve as the primary medium for user interaction across digital environments.
Within the GUI environment, LLM-based agents \cite{language-agent-tutorial} have shown great potential in automating complex workflows for human users.
These agents are designed to operate across diverse interfaces, including the web \cite{mind2web, DBLP:conf/iclr/ZhouX0ZLSCOBF0N24, zheng2024gpt}, desktop \cite{xie2024osworld, wu2024oscopilot, bonatti2024windows}, and mobile platforms \cite{rawles2023androidinthewild, yan2023gpt}.
Navigating modern GUI interfaces, which integrate textual, graphical, and interactive components, typically requires agents to possess visual grounding, long-term planning, and memory management capabilities.

% 2. Training GUI agents needs data. There is a lot of synthetic GUI grounding data. However, trajectory data is still human annotated.

Recent work \cite{seeclick, gou2024uground} has demonstrated the effectiveness of synthetic data for enhancing visual grounding \cite{gou2024uground, chen2024guicourse, DBLP:conf/eccv/KapoorBRKKAS24, chen2024edge} and planning \cite{xu2024aguvis, zhang-etal-2024-android}.
Developing end-to-end GUI agents with long-term planning and grounding capabilities requires training on multi-step trajectory data \cite{xu2024agenttrek, xu2024aguvis, qin2025ui}.
However, existing trajectory datasets are primarily human-annotated \cite{mind2web, li2024on, DBLP:conf/icml/LuKR24} or leverage synthetic data just for task proposal curation \cite{DBLP:conf/kdd/LaiLIYCSYZZD024, chen2024guicourse}.
And human annotation is expensive to scale for collecting large and diverse training datasets.
Therefore, synthetic data has emerged as a promising alternative to human-annotated data~\cite{hartvigsen2022toxigen, sahu2022data, ye2022zerogen, tang2023does, mukherjee2023orca, mitra2024agentinstruct}.
% , leveraging the ability of LLMs to generate fluent, human-like text.
Collecting trajectory-level datasets presents unique challenges:
1) curating a diverse set of task intents at scale,
2) deploying an agent capable of interacting with a real-world environment to complete these tasks through a series of actions, and
3) verifying whether the task is accomplished by the executed action sequence.

\input{figures/data_pipeline}

% 3.	The diversity of data plays a key role in learning a variety of skills for generalist web agents. Diversity is important for better cross-domain generalization. Web tutorials (AgentTrek, Synatra) have limited diversity. Human annotation cannot achieve diversity in a scalable manner (AutoWebGLM, GUICourse)

Data diversity is essential for equipping generalist web agents with a broad range of skills.
Existing work on synthetic web trajectory generation employs self-instruct for task proposal generation \cite{he2024openwebvoyager}.
% ; however, its disjoint approach to proposal and execution limits diversity.
% Existing work has attempted to address this by introducing diversity in task proposal curation \cite{he2024openwebvoyager}.
% However, its disjoint approach to task proposal and execution results in limited diversity.
It formulates task proposals from homepages or parametric LLM knowledge, overlooking the richer content available in deeper web pages, which is essential for achieving broader task diversity.
Another line of work leverages web tutorials as a form of supervision for generating web trajectories \cite{Ou2024SynatraTI, xu2024agenttrek}.
While web tutorials effectively cover common daily user tasks, the resulting trajectory data exhibits limited domain diversity in terms of website and domain coverage (Table~\ref{tab:data_comp}).
Additionally, information-seeking tasks remain underrepresented.
Due to these limitations, web agents trained on existing synthetic trajectory datasets have not seen much success in more realistic online evaluation settings.
% Due to these limitations, web agents trained on existing trajectory datasets have been evaluated primarily on offline benchmarks, \textit{limiting their generalization to real-world online environments}.
To enhance web agents' performance in real-world settings, it is essential to incorporate greater diversity in their training trajectories.

\input{tables/dataset_comparison}

% 4.	RQ: How can we automatically synthesize diverse data? We suggest creating task descriptions using exploration. Exploration is key to diversity and thereby cross-domain generalization. Briefly describe approach as in para 4.

In this work, we develop a \textit{scalable} and \textit{diverse} web trajectory data synthesis recipe for training GUI agent models.
% Humans typically navigate both the breadth and depth of a websiteâ€™s features to understand its functionality. 
Inspired by how humans learn to use the internet, \textit{we leverage exploration as a key mechanism for achieving diversity in task intents}.
We introduce \textbf{\model} (\underline{EXPL}oration-driven web traject\underline{OR}y g\underline{E}nerato\underline{R}), a framework for systematic web exploration to generate diverse, high-quality trajectory datasets.
Unlike prior work that relies on static task proposals, \model dynamically explores web environments to curate diverse, real-world tasks.
This exploration-based approach ensures broader task coverage and better generalization to real-world scenarios.
% We instantiate this pipeline using popular URLs for several sources as seeds - Tranco \cite{DBLP:conf/ndss/PochatGTKJ19}, Clueweb \cite{DBLP:conf/sigir/OverwijkXC22}, and \url{similarweb.com}.
We instantiate this framework using popular URLs from several sources, such as Tranco \cite{DBLP:conf/ndss/PochatGTKJ19} and \url{similarweb.com} as seeds.
% The resulting dataset contains approximately 94K diverse web trajectories across unique 49K URLs.
Our dataset comprises 94K diverse web trajectories spanning 49K unique URLs, making it the largest web trajectory dataset to date.
Each trajectory is richly annotated with artifacts such as screenshots, raw and set-of-mark \cite{yang2023set} annotated versions, HTML, and the accessibility tree, enabling comprehensive web agent training.
To construct this dataset, we develop a multi-agent pipeline that starts with an abstract task proposal and iteratively refines it into a more specific task through web exploration (Figure~\ref{fig:data_pipeline}).
Unlike previous approaches, our pipeline generates tasks better grounded in real-world websites, improving task relevance and diversity.
To demonstrate the effectiveness of our dataset, we train small language models using just the synthetic data and outperform existing web agent baselines by a significant margin.
% In summary, our contributions are as follows:
The main contributions of this work are as follows:
\begin{itemize}

    \item We develop a scalable and easily customizable multi-agent pipeline for web agent trajectory synthesis. This pipeline leverages exploration as a core mechanism to generate diverse trajectory data, ensuring broad domain coverage and skill diversity in the resulting dataset.
    
    \item We leverage this pipeline to generate a diverse and high-quality GUI trajectory dataset consisting of \textbf{94K trajectories}, spanning \textbf{49K unique URLs} with 720K screenshots and 33M web elements, making it the largest web trajectory dataset of this scale.
    
   \item We demonstrate the effectiveness of our dataset by training small language models, which achieve strong performance on both online and offline benchmarks, significantly surpassing existing web agent baselines, including those with larger parameter counts.
\end{itemize}