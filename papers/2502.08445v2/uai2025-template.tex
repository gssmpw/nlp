%\documentclass{uai2025} % for initial submission
\documentclass[accepted]{uai2025} % after acceptance, for a revised version; 
%\documentclass[twocolumn]{article}
% also before submission to see how the non-anonymous paper would look like 
                        
%% There is a class option to choose the math font
% \documentclass[mathfont=ptmx]{uai2025} % ptmx math instead of Computer
                                         % Modern (has noticeable issues)
%\documentclass[mathfont=newtx]{uai2025} % newtx fonts (improves upon
%                                          %ptmx; less tested, no support)
% NOTE: Only keep *one* line above as appropriate, as it will be replaced
%       automatically for papers to be published. Do not make any other
%       change above this note for an accepted version.

%% Choose your variant of English; be consistent
%\usepackage[american]{babel}
% \usepackage[british]{babel}

%% Some suggested packages, as needed:
\usepackage{natbib} % has a nice set of citation styles and commands
    \bibliographystyle{plainnat}
    \renewcommand{\bibsection}{\subsubsection*{References}}
\usepackage{mathtools} % amsmath with fixes and additions
% \usepackage{siunitx} % for proper typesetting of numbers and units
\usepackage{booktabs} % commands to create good-looking tables


% SELF
% For theorems and such
%\usepackage{times}

% Use fancyhdr package
%\usepackage{fancyhdr}

    
% Attempt to make hyperref and algorithmic work together better:


%\usepackage{eso-pic} % used by \AddToShipoutPicture
\usepackage{forloop}
\usepackage{url}

\usepackage{amsmath}
\usepackage{amssymb}
\usepackage{mathtools}
\usepackage{amsthm}
\usepackage{authblk}
\usepackage{bbding}
\usepackage{multirow}
\usepackage{comment}
% if you use cleveref..
\usepackage[table,dvipsnames]{xcolor}
\usepackage{hyperref}
\hypersetup{
    colorlinks=true,
    linkcolor=red,
    filecolor=magenta,      
    urlcolor=cyan,
    citecolor=Blue,
    pdftitle={Overleaf Example},
    pdfpagemode=FullScreen,
    }
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% THEOREMS
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\theoremstyle{plain}
\newtheorem{theorem}{Theorem}[section]
\newtheorem{proposition}[theorem]{Proposition}
\newtheorem{lemma}[theorem]{Lemma}
\newtheorem{corollary}[theorem]{Corollary}
\theoremstyle{definition}
\newtheorem{definition}[theorem]{Definition}
\newtheorem{assumption}[theorem]{Assumption}
\theoremstyle{remark}
\newtheorem{remark}[theorem]{Remark}

% Todonotes is useful during development; simply uncomment the next line
%    and comment out the line below the next line to turn off comments
% \usepackage[disable,textsize=tiny]{todonotes}
% \usepackage[textsize=tiny]{todonotes}
\newcommand*\dif{\mathop{}\!\mathrm{d}}



%% Provided macros
% \smaller: Because the class footnote size is essentially LaTeX's \small,
%           redefining \footnotesize, we provide the original \footnotesize
%           using this macro.
%           (Use only sparingly, e.g., in drawings, as it is quite small.)

%% Self-defined macros
%\newcommand{\swap}[3][-]{#3#1#2} % just an example

\title{\texttt{LucidAtlas}: Learning Uncertainty-Aware, Covariate-Disentangled, Individualized Atlas Representations}

% The standard author block has changed for UAI 2025 to provide
% more space for long author lists and allow for complex affiliations
%
% All author information is authomatically removed by the class for the
% anonymous submission version of your paper, so you can already add your
% information below.
%
%Add authors
\author[1]{Yining Jiao}
\author[1]{Sreekalyani Bhamidi}
\author[1]{Huaizhi Qu}
\author[1]{Carlton Zdanski}
\author[1]{Julia Kimbell}
\author[1]{Andrew Prince}
\author[1]{Cameron Worden}
\author[1]{Samuel Kirse}
\author[1]{Christopher Rutter}
\author[1]{Benjamin Shields}
\author[1]{Jisan Mahmud}
\author[1]{Tianlong Chen}
\author[2]{Marc Niethammer}
% Add affiliations after the authors
\affil[1]{UNC-Chapel Hill} \affil[2]{UCSD}

\begin{document}
\maketitle

\begin{abstract}
 The goal of this work is to develop principled techniques to extract information from high dimensional data sets with complex dependencies in areas such as medicine that can provide insight into individual as well as population level variation. We develop \texttt{LucidAtlas}, an approach that can represent spatially varying information, and can capture the influence of covariates as well as population uncertainty. As a versatile atlas representation, \texttt{LucidAtlas} offers robust capabilities for covariate interpretation, individualized prediction, population trend analysis, and uncertainty estimation, with the flexibility to incorporate prior knowledge. Additionally, we discuss the trustworthiness and potential risks of neural additive models for analyzing dependent covariates and then introduce a marginalization approach to explain the dependence of an individual predictor on the models' response (the atlas). To validate our method, we demonstrate its generalizability on two medical datasets. Our findings underscore the critical role of by-construction interpretable models in advancing scientific discovery. Our code will be publicly available upon acceptance. 
\end{abstract}


\section{Introduction}
\label{sec.intro}

% what is atlas,
%In medical or scientific discovery, we frequently need to quantify and disentangle those effects from different covariates to the outcome. To do this, one would first need to construct an atlas with collected data, which consists of a collection of subjects with covariates $\mathcal{X}$ and outcome $\mathcal{Y}$, which we are mostly concerned about. For example, for Alzheimer's disease analysis, $\mathcal{X}$ can be demographic information and $\mathcal{Y}$ can be the hippocampus volume; for pediatric airway analysis, $\mathcal{X}$ can be demographic information and $\mathcal{Y}$ can be the airway shape. 

% Define the problem
In the context of medical image analysis and computational anatomy, an \emph{atlas} is a standardized representation of biological structures that serves as a reference model~\citep{joshi2004unbiased, thompson2002framework}. An atlas is often created by aggregating data from multiple patients to represent "typical" or "average" anatomy. Atlases are crucial in medical research, diagnosis, and treatment planning, providing a baseline for comparison with individual patient data~\citep{atlashong2013pediatric,commowick2005incorporating}. Although often representing average structures, some atlases also incorporate information on anatomical variability within a population~\citep{jin2019howmany,kovavcevic2005three}.

The goal of this work is to enhance atlas representations by incorporating covariates and uncertainties, providing clinicians with a more comprehensive tool for disease analysis. Our approach goes beyond traditional models, offering covariate disentanglement and uncertainty estimation for improved population understanding. Specifically, accounting for covariates and capturing subject- and population-level aspects about the data is important to address the following questions relevant for clinicians and technical users who might want to build upon our model: 

%Table~\ref{tab.lit} shows three important aspects for the atlas construction problems we are addressing.

%%real-world scientific or medical discovery problems with an atlas, which we define as \emph{atlas discovery} problems. Atlas discovery in the wild is challenging because people expect to solve multiple tasks with an evolving-collected dataset. 

\paragraph{Covariate-Level} 
    % \textcircled{1} \emph{Interpretation for Human}. Humans usually understand a covariate's importance by analyzing its relationship with the observation, i.e.,  assuming only one covariate is known, how does the population trend evolve under its control?  %$p(y|c_i)$
    % \textcircled{2}  \emph{Interpretation from Models.} Understanding the underlying mechanisms of model predictions is crucial for assessing their trustworthiness. Inherently interpretable models are desirable in our atlas construction problem because their decision-making processes are transparent~\citep{rudin2019stop}.
    \textcircled{1}  \emph{Covariate Disentanglement.}  Understanding the effects of covariates is frequently a goal of medical studies. Therefore, it is critical to disentangle covariate effects on the population to interpret an atlas representation and to ensure that these effects align with human knowledge. Inherently interpretable models are desirable for atlas building because such atlas representations are then transparent by construction~\citep{rudin2019stop}.
    \textcircled{2} \emph{Covariate Marginalization}. Clinicians usually understand the importance of a covariate by analyzing its relationship with the response, e.g.,  how a population trend evolves under the control of a specic covariate regardless of the existence of other covariates. For example, how does a brain change for normal people versus Alzheimer patients, regardless of age?%$p(y|c_i)$
    \textcircled{3}  \emph{Prior Knowledge.} Suppose we have  prior knowledge about some or all covariates, e.g., monotonicity\footnote{For example, a pediatric airway should typically expand with age, as a child grows.} how can such prior knowledge assist in better atlas construction? Do our modeling assumptions  align with our prior knowledge and are they reasonable for human data?
\paragraph{Subject-Level}
    \textcircled{1}  \emph{Predictions based on the Population Trend.} Is the constructed atlas a good predictor for individual anatomies given their covariates?  \textcircled{2} \emph{Individualized Temporal Analysis.} Can the model provide individualized predictions at time $B$ based on observations based on a prior time $A$? This is a challenging task, as the collected data often consists of numerous one-time observations rather than longitudinal data.
\paragraph{Population-Level} 
    \textcircled{1} \emph{Individual Variability.}  Variation across the population may surpass the variation explained by covariates. How can we quantify population variation not captured by the covariates? \textcircled{2} \emph{Heteroscedasticity.}  Variability may be heteroskedastic across covariates and anatomical geometry. For example, population variance may differ change with age and airway location when constructing a pediatric airway atlas. 
\paragraph{Spatial-Level} 
    \textcircled{1} \emph{Spatial Dependence.} Capturing spatial dependence is essential for atlas construction. For instance, different anatomical locations may exhibit distinct population trends and variations influenced by covariates, highlighting the need to model spatial dependence effectively.
    
%\textcircled{2} \emph{Small Dataset with Missingness.} Data collection is often a gradual process rather than a one-time effort. Researchers may update protocols over time, incorporating new facilities, modalities, or demographic variables, which can result in missing covariates and small datasets, particularly in preliminary studies.



% what to do
To address covariate-, subject-, population-, and spatial-questions simultaneously, we propose the versatile \texttt{LucidAtlas} model. This uncertainty-aware, covariate-disentangled individualized atlas representation extends the Neural Additive Model (NAM)~\citep{agarwal2020neural} to enhance atlas construction by integrating uncertainty quantification and incorporating prior knowledge. We introduce a marginalization approach that incorporates covariate dependencies to provide a more comprehensive covariate interpretation; while NAM's interpretations only focus on individual covariate effects in isolation. %We introduce a marginalization approach that aligns the disentangled covariate effects from NAMs with the overall population distribution to better account for dependent covariate effects. 
%An additional advantage of \texttt{LucidAtlas} is its ability to handle missing covariates, further increasing our model's robustness and applicability in cases of missing data.

The main contributions of \texttt{LucidAtlas} are as follows:
\begin{itemize}
    \item[1)] \texttt{LucidAtlas} is a versatile atlas representation capable of enhancing traditional atlas representations by incorporating covariates, uncertainties, and prior knowledge, providing clinicians with a more comprehensive tool for disease analysis.
    \item[2)] We show potential risks when using NAMs for covariate interpretation in the context of dependent features. We further propose a marginalization approach to address these shortcomings. 
    \item[3)] We validate our approach on two medical datasets%\footnote{Medical datasets are challenging for validation because heteroscedasticity often exists spatially or with covariates for scientific discovery in such contexts.}
    : 1) the OASIS Brain Volume dataset~\citep{jack2008alzheimer}, and 2) a Pediatric Airway Shape dataset. Our experiments quantitatively demonstrate the superior performance of \texttt{LucidAtlas} compared to baseline methods.
\end{itemize}


%We introduce a marginalization approach to eliminate potentially confusing interpretations caused by covariate correlation and to improve the model's trustworthiness.

\begin{table}[t]
\centering
\resizebox{0.49\textwidth}{!}{%
\begin{tabular}{l|cc|c|c|c}
\hline
 &
  \multicolumn{2}{c|}{\cellcolor[HTML]{F8E5E4}Covariate-} &
  \cellcolor[HTML]{E2E3F8}Subject- &
  \cellcolor[HTML]{FFFFC7}Population- &
  \cellcolor[HTML]{E9FEE9}Spatial- \\ \cline{2-6} 
\multirow{-2}{*}{Method} &
  \multicolumn{1}{c|}{Cov. Marg.} &
  Prior. &
  Ind. Pred. &
  Hetero.+Aleatoric &
  Spa. Dep. \\ \hline
NAM~\citep{agarwal2020neural}      & \multicolumn{1}{c|}{\XSolidBrush} & \XSolidBrush & \XSolidBrush & \XSolidBrush & \XSolidBrush \\ \hline
OAK~\citep{lu2022oak}              & \multicolumn{1}{c|}{\Checkmark}   & \XSolidBrush & \XSolidBrush & \XSolidBrush & \XSolidBrush \\ \hline
LA-NAM~\citep{bouchiat2023lanam}   & \multicolumn{1}{c|}{\XSolidBrush} & \XSolidBrush & \Checkmark   & \XSolidBrush & \XSolidBrush \\ \hline
NAMLSS~\citep{thielmann2024namlss} & \multicolumn{1}{c|}{\XSolidBrush} & \XSolidBrush & \Checkmark   & \Checkmark   & \XSolidBrush \\ \hline
NAISR~\citep{jiao2023naisr}        & \multicolumn{1}{c|}{\XSolidBrush} & \XSolidBrush & \Checkmark   & \XSolidBrush & \Checkmark   \\ \hline
\texttt{LucidAtlas}(Ours)          & \multicolumn{1}{c|}{\Checkmark}   & \Checkmark   & \Checkmark   & \Checkmark   & \Checkmark   \\ \hline
\end{tabular}
}
\caption{\small Comparison of interpretable representations based on the desirable properties discussed in Sec.\ref{sec.intro}. \textbf{Cov.Marg.} denotes covariate marginalization. \textbf{Prior.} indicates prior knowledge. \textbf{Ind. Pred.} indicates individualized prediction, i.e., whether the model can predict a response for time $B$ given an earlier observation at time $A$. \textbf{Hetero.+Aleatoric} indicates whether the model considers heteroscedasticity when modeling aleatoric uncertainty. \textbf{Spa. Dep.} indicates spatial dependence. A \Checkmark indicates that a model has a property; a \XSolidBrush indicates that it does not. Only \texttt{LucidAtlas} has all the desired properties. }
\label{tab.lit}
\end{table}



\section{Related Work}
We first introduce the three most related research directions. 

\paragraph{Additive Models}
Model-agnostic methods, such as Partial Dependence~\citep{friedman2001greedy}, SHAP~\citep{lundberg2017unified}, and LIME~\citep{ribeiro2016should}, offer a standardized approach to explaining machine learning predictions. However, when applied to deep neural networks (DNNs), these methods may fail to provide faithful representations of their full complexity~\citep{rudin2019stop}. A more transparent alternative involves leveraging Generalized Additive Models (GAMs)~\citep{hastie2017generalized}, where the response variable \( y \) is modeled using an additive structure:  
\begin{small}
\begin{equation}
E[y | c_1, . . . , c_N] = h(\beta_0 + f_1(c_1) + \dots + f_N(c_N))
\label{eq.nam}
\end{equation}
\end{small}
where \( h(\cdot) \) is the inverse of the link function (a form of activation function) ; $\beta_0$ denotes the intercept and $f_{i}(\cdot)$ represent independent functions for the $i^{th}$ covariate. Neural Additive Models (NAMs)~\citep{agarwal2020neural, jiao2023naisr} build upon this framework, offering enhanced interpretability while maintaining the flexibility of neural networks. Specifically, for NAMs the functions $f_i(\cdot)$ are deep neural networks. NAISR~\citep{jiao2023naisr} pioneers the use of NAMs to capture spatial deformations with respect to an estimated atlas shape that is modulated by covariates. \emph{\texttt{LucidAtlas} extends this concept by integrating NAMs to construct an atlas that captures population trends and uncertainties with spatial dependencies}.

\paragraph{Epistemic Uncertainty versus Aleatoric Uncertainty}
%Epistemic and aleatoric uncertainties are two different kinds of uncertainties. Epistemic uncertainty relates to model parameters and stems from limited model knowledge, which is reducible with more data or better modeling. Aleatoric uncertainty arises from inherent data randomness and is irreducible. 

Estimating uncertainty is important to understand the quality of a model fit and to capture variations across the data population. Two different types of uncertainties need to be distinguished: epistemic uncertainty captures model uncertainty whereas aleatoric uncertainty captures uncertainty in the data~\citep{hullermeier2021survey}. 

More attention is generally paid to epistemic uncertainties in the context of interpretable models~\citep{wang2025uncertaintysurvey}. NAMs used ensembling to estimate model uncertainties~\citep{agarwal2020neural}. LA-NAM used a Laplace approximation for uncertainty estimation~\citep{bouchiat2023lanam} with NAMs. In atlas construction, aleatoric uncertainty is especially important when individual differences in a dataset are large. Capturing aleatoric uncertainty is crucial in medicine to understand population variations. NAMLSS~\citep{thielmann2024namlss} can model aleatoric uncertainty by using NAMs to approximate the parameters $\{\theta^{(n)}\}$ of a chosen data distribution~\citep{thielmann2024namlss}, as
\begin{small}
\begin{equation}
\theta^{(n)}=h^{(n)}\left(\beta^{(n)}+\sum_{i=1}^{N} f_{i}^{(n)}\left(c_{i}\right)\right) 
\label{eq.namlss}
\end{equation}
\end{small}
where $\theta^{(n)}$ can for example be the mean and variance of Gaussian distributions; $\beta^{(n)}$ denotes the parameter-specific intercept and $f_{i}^{(n)}$ represents the feature network for the $n$-th parameter for the $i$-th feature. \emph{\texttt{LucidAtlas} extends NAMLSS to a more versatile representation, enabling individualized prediction, incorporating prior knowledge, and capturing spatial dependencies.}
%~\citep{monteiro2020stochasticsegmentationnetworksmodelling,valiuddin2021improvingaleatoricuncertaintyquantification,Wang_2019,kawashima2020aleatoricuncertaintyestimationusing,Martin_2022,nevin2024deepuqassessingaleatoricuncertainties}

\paragraph{Heteroscedasticity versus Homoscedasticity}
Distinguishing between homoscedasticity and heteroscedasticity is crucial in statistical analysis, especially for regression models. Homoscedasticity indicates constant variance of random variables , whereas heteroscedasticity indicates that the variance of random variables may differ~\citep{wooldridge2016homohetr}. For example, when modeling airway cross-sectional area the population variance may change (increase) with age. \texttt{LucidAtlas} assumes and supports estimating heteroscedasticity with respect to different locations in an anatomical region and with respect to covariates across a patient population. Many interpretable approaches assume homoscedasticity, e.g., OAK-GP~\citep{lu2022oak} and LA-NAM~\citep{bouchiat2023lanam} assume homoscedasticity in their additive networks. To our knowledge, only NAMLSS considers heteroscedasticity in its additive network design~\citep{thielmann2024namlss}. However, NAMLSS interprets individual covariate effects and uncertainties in isolation resulting, as we will see, in difficulties for data interpretation. \emph{\texttt{LucidAtlas} advances beyond NAMLSS by capturing spatial heteroscedasticity and incorporating covariate dependencies via a marginalized covariate interpretation approach.}%\emph{\texttt{LucidAtlas} can capture spatial heteroscedasticity and utilize heteroscedasticity for marginalized covariate interpretation, which takes a further step to NAMLSS.} 

Table~\ref{tab.lit} compares \texttt{LucidAtlas} to related interpretable models with respect to the discussed properties above. A more comprehensive discussion of
related work is available in Sec.~\ref{supp.sec.supp_related_work} of the Supplementary Material.


\section{Method}
\label{sec.method_model_arch}
%Sec.~\ref{sec.prob_des} introduces the problem description of atlas construction. Sec.~\ref{sec.workflow_lucidatlas} describes the workflow of \texttt{LucidAtlas}, which by construction ensures the \emph{interpretations from transparent models}. In Sec.~\ref{subsec.why_mrg}, we discuss trustworthiness and the potential risks of the neural additive models and then introduce our marginalization approach in Sec.~\ref{subsubsec.how_marg} to \emph{align model interpretations with human understanding} and verify their trustworthiness.

Sec.~\ref{sec.prob_des} introduces our general atlas construction formulation. Sec.~\ref{sec.workflow_lucidatlas} describes \texttt{LucidAtlas}, which by construction ensures \emph{covariate disentanglement based on an additive model formulation}. Sec.~\ref{subsec.why_mrg} discusses the potential concerns for neural additive models when dealing with dependent covariates. To address these concerns  Sec.~\ref{subsubsec.how_marg} introduces our covariate marginalization approach. Table~\ref{supp.tab.exp_notations} lists the mathematical notations used in this paper. % to \emph{align disentangled covariate effects to the population trend} and verify their trustworthiness.


\subsection{General Atlas Formulation}
\label{sec.prob_des}
Consider a set of anatomies $\{\mathcal{Y}^k\}$, where each anatomy $\mathcal{Y}^k$ is associated with a vector of covariates $\boldsymbol{c}^k = [c^k_1, \dots, c^k_i, \dots, c^k_N]$. A point within an anatomy is denoted as $x$, with an observed value $y \in \mathbb{R}$, which is the primary focus of our study.

Our goal is to construct an atlas representation that addresses the questions outlined in Section~\ref{sec.intro} by learning the mapping from covariates $\boldsymbol{c}$ and spatial location $x$ to observations $y$, while simultaneously accounting for heteroscedastic uncertainties within the population, represented as $p(y \mid \boldsymbol{c}, x) = \mathcal{N}(f^m(\boldsymbol{c}, x), f^v(\boldsymbol{c}, x))$.


\subsection{\texttt{LucidAtlas} Formulation}
\label{sec.workflow_lucidatlas}
\subsubsection{Introducing Spatial Dependency}
\label{sec.spatial_dep}
\begin{figure*}
    \centering
    \includegraphics[width=0.85\linewidth]{figures/LucidAtlas_pipeline.pdf}
    \caption{\small \texttt{LucidAtlas}: Learning an Uncertainty-Aware, Covariate-Disentangled, Individualized Atlas Representation. \textcircled{1} As an example use case, we depict an airway with its anatomical landmarks at different depths (i.e., anatomical location) along its centerline~\citep{atlashong2013pediatric}. \textcircled{2} During training, each subnetwork $f_i(c_i, x)$ receives the location $x$ and covariate $c_i$ as input to predict the covariate-specific distributional parameters $f^m_i$ and $f^v_i$, which are added to obtain the overall distributional parameters to capture the population trend and variation as $f^m=\sum_i f^m_i$ and $f^v=\sum_i f^v_i$ respectively. \textcircled{3} The goal of marginalization is to discover $p(y|c_i, x)$, by integrating out the potentially dependent covariates $\{c_k\}_{k \neq i}$. Each subnetwork $g_i(c_i)$ receives covariate $c_i$ to parameterize a multivariate Gaussian distribution $p(\boldsymbol{c}|c_i)$ for all $N$ covariates, from which we obtain $p(c_k|c_i)$ and $p(c_{K_1}, c_{K_2}|c_i)$. The marginalization requires that the outputs of $\{f_i\}$ and $\{g_i\}$ are as described in Sec.~\ref{subsubsec.how_marg}. \textcircled{4} \texttt{LucidAtlas} can obtain different interpretations, i.e., 1) a covariate disentanglement corresponding to  each covariate's additive effect from $\{f_i\}$; 2) dependence between covariates modeled by $\{g_i\}$ as $p(c_k|c_i)$ and 3) a marginalization illustrating the overall impact from each covariate on the predicted response (here the cross-sectional area $y$ at a specific location $x$) via marginalization. \textcircled{5} Monotonic neural networks by construction are  used if the influence of a covariate on the response is assumed to be monotonic based on prior knowledge/domain knowledge; otherwise, a multi-layer perceptron (MLP) is used to parameterize the subnetworks.}
    \label{fig.method}
\end{figure*}

%Inspired by neural additive~\citep{agarwal2020neural} and generalized additive~\citep{hastie2017generalized} models, we assume that the expectation of the overall observation $f^m(\boldsymbol{c})$ is the sum of the contributions from the individual covariates: $f^m(\boldsymbol{c})=\sum_{i=1}^{N} f^m_i(c_i)$. Inspired by NAMLSS~\citep{thielmann2024namlss}, we assume that the variance of the overall observation $f^v(\boldsymbol{c})$ is the sum of the variances contributed by the individual covariates: $f^v(\boldsymbol{c})=\sum_{i=1}^{N} f^v_i(c_i)$. 
We develop \texttt{LucidAtlas} based on NAMLSS~\citep{thielmann2024namlss}, first extending it by incorporating spatial dependency, which is not explicitly modeled in NAMLSS. To achieve this, we introduce neural subnetworks \(\{f_i(c_i, x)\}\) that predict the distributional parameters of \(p(y|\boldsymbol{c}, x)\). Each network \(f_i(c_i, x)\) has two outputs: \(f^m_i(c_i, x)\) and \(f^v_i(c_i, x)\), which capture the contribution from $c_i$ at location $x$ to the mean and variance of $p(y|\boldsymbol{c},x)$ respectively. The overall population mean and variance are then obtained by summing these individual contributions:
\begin{small}
\begin{equation}
f^m(\boldsymbol{c},x) = \sum_{i=1}^{N} f^m_i(c_i,x) \\,
f^v(\boldsymbol{c},x) = \sum_{i=1}^{N} f^v_i(c_i,x)\,.
\label{eq.follow_namlss}
\end{equation}
\end{small}By explicitly modeling spatial dependencies, \texttt{LucidAtlas} extends NAMLSS to spatial atlas construction.
\paragraph{Loss Function.}
We optimize the subnetworks $\{f_i\}$ by minimizing the negative log-likelihood resulting in the loss function%$\mathcal{L}(\{f_i\}, \boldsymbol{c}, x)$ as 
\begin{small}
\begin{equation}
\mathcal{L}(\{f_i\}, \boldsymbol{c}, x) =  \frac{1}{2}\log(2\pi \cdot f^v(\boldsymbol{c},x)) + \frac{(y - f^m(\boldsymbol{c},x))^2}{2 \cdot f^v(\boldsymbol{c},x)}\,,% \\,
\label{eq.nll_loss}
\end{equation}
\end{small} where $y$ is the observation at location $x$ given the  covariates $\boldsymbol{c}$.


\begin{comment}

As shown in Fig.~\ref{fig.method}, each additive subnetwork $f_i$ receives $c_i$ and predicts $f^m_i$ and $f^v_i$ to parameterize the covariates' contribution as $\mathcal{N}(f^m_i(c_i), f^v_i(c_i))$. We follow NAMLSS~\citep{thielmann2024namlss} to train \texttt{LucidAtlas} by minimizing the negative log-likelihood as the loss function, $-\log (\mathcal{L}(\theta \mid y))$ as 
\begin{small}
\begin{equation}
\mathcal{L}(f^m(\boldsymbol{c}^k), \sigma(\boldsymbol{c}^k)) = -\sum_{k=1}^{K} \left[ -\frac{1}{2}\log(2\pi \cdot f^v(\boldsymbol{c}^k)) - \frac{(y^k - f^m(\boldsymbol{c}^k))^2}{2f^v(\boldsymbol{c}^k)} \right] \\,
\label{eq.nll_loss}
\end{equation}
\end{small} $y^k$ is the $k^{th}$ observation whose covariates are $\boldsymbol{c}^k$.

The additive design of the expectation \( f^m(\boldsymbol{c}) \) and variance \( f^v(\boldsymbol{c}) \) provides clear \emph{interpretations from the model}, offering insights into how the neural additive model makes predictions. 

\end{comment}


%The population trend $f^m(\boldsymbol{c})$ and heteroscadastistic variances $f^v$ are obtained by adding up as the contribution of the covariates in terms of the distribution parameters as $ f^m(\boldsymbol{c})= \sum_{i=1}^{N} f^m_{i}(c_{i})$ and $f^v(\boldsymbol{c})= \sum_{i=1}^{N} f^v_{i}(c_{i})$. 


% \begin{small}
% \begin{equation}
% \mathcal{L}(f^m(\boldsymbol{c}), f^v(\boldsymbol{c})) = -\sum_{i=1}^{N} \left[ -\frac{1}{2}\log(2\pif^v(\boldsymbol{c})) - \frac{(y_i - f^m(\boldsymbol{c}))^2}{2f^v(\boldsymbol{c})} \right]
% \label{eq.nll_loss}
% \end{equation}
% \end{small}

% \subsubsection{Interpretation from NAMs}
% \label{sec.inter_from_nam}
% Interpretation from NAMs~\citep{thielmann2024namlss} for covariate $c_j$ can be formulated as 
% \begin{small}
% \begin{equation}
% \hat{f^m}_j(c_j) = f^m_j(c_j) + \sum_{i\neq j}^N f^m_i(\bar{c_i}) \\,
% \hat{\sigma}_j^2(c_j) = f^v_j(c_j) + \sum_{i\neq j}^N f^v_i(\bar{c_i})
% \label{eq.intp_from_model}
% \end{equation}
% \end{small}$\bar{c_i}$ is the mean value of $c_i$, which is 0 if normalized. Therefore, $\hat{f^m}_j(c_j)$ and $\hat{\sigma}_j^2(c_j)$ equal the output of the subnetwork $f_i(\cdot)$ plus a constant.


\subsubsection{Disentangled Covariate Effects}
\label{sec.dist_cov_effects}
We choose NAMs~\citep{agarwal2020neural,thielmann2024namlss} for atlas representation due to their inherent ability to disentangle covariate effects, enabled by their additive subnetwork design. The disentangled effect of covariate \(c_i\) on the population trend is represented by \(f^m_i(c_i, x)\), while its contribution to the population variation is captured by \(f^v_i(c_i, x)\).




\subsubsection{Prior Knowledge}
\label{sec.prior_knolwedge}
To take a further step, we improve the uncertainty-aware neural additive model~\citep{thielmann2024namlss} by incorporating \emph{prior knowledge} of monotonicity~\citep{kitouni2023mono} for the covariates. Specifically, assuming that the distribution of the response $y$ has a stochastically increasing relationship with respect to a particular covariate $c_j$ (while keeping all other covariates fixed), can be incorporated via the modeling ansatz 
\begin{small}
\begin{equation}
    \frac{\partial {f^m(\boldsymbol{c},x)}}{\partial c_j} = \sum_{i=1}^N \frac{\partial f^m_i(c_i,x)}{\partial c_j}=\frac{\partial f^m_j(c_j,x)}{\partial c_j} \geq 0\,.
\label{eq.prior_know}
\end{equation}
\end{small}
As illustrated in Fig.~\ref{fig.method}, $f_j(c_j)$ can be parameterized using a monotonic Lipschiz neural network by design~\citep{kitouni2023mono} when such prior monotonicity information is available. This design guarantees the monotonicity of \(f_j(c_j)\) by construction and ensures that the interpretations derived from the NAMs align with human prior knowledge. 

\subsection{Rethinking the Neural Additive Model}
\label{subsec.why_mrg}
The underlying assumption behind NAMs is that each covariate contributes independently to the outcome. Even if the covariates are dependent, the NAMs will spread out the contribution from each covariate to its subnetworks as additive functions~\citep{agarwal2020neural}. In most real-world applications, such as our airway atlas construction problem in Sec.~\ref{sec.prob_des}, the independence between covariates cannot be guaranteed. \emph{A natural question is whether accepting the independence assumption unquestioningly and directly using NAMs is appropriate.} In this section, we discuss trustworthiness and the potential risks of neural additive models. 

We can investigate this problem with a toy example, where $y=sin(c_1)+c_2 +\epsilon$ where $\epsilon$ is a noise term and $c_1$,  $c_2$ are covariates that influence the observed outcome $y$. Assuming there is a NAM that already fits this function well, the subnetworks capture $f_1(c_1) = \sin(c_1)$ and $f_2(c_2) = c_2$ and thus approximate $y$ with $f(c_1, c_2) = f_1(c_1) + f_2(c_2)$.

If we want to interpret the population trend of $y$ only with respect to $c_1$, we need to marginalize $c_2$ out as,
\begin{small}
\begin{equation}
\begin{split}
&F_1(c_1)=\int_{-\infty}^{\infty} [f_1(c_1) + f_2(c_2)]p(c_2|c_1) \dif c_2 \\
&=\underbrace{f_1(c_1)}_{\text{Interpretation from NAMs}}+\underbrace{\int_{-\infty}^{\infty} f_2(c_2)p(c_2|c_1) \dif c_2}_{\text{Interpretation from Dependence: } :=h_1(c_1)} 
\end{split}
\label{eq.source_of_intr}
\end{equation}
\end{small}

where $h_1(c_1)$ measures how the dependence between $c_1$ and $c_2$ influences the marginalization $F_1(c_1)$. We can see from Eq.~\eqref{eq.source_of_intr} that $F_1(c_1)$ is composed of the interpretation from the NAM's subnetwork plus the interpretation from the dependence between $c_1$ and $c_2$ as $h_1(c_1)$.

\textbf{If $c_1$ and $c_2$ are \textit{independent}}, $h_1(c_1)=\int_{-\infty}^{\infty} f_2(c_2)p(c_2|c_1) \dif c_2=\int_{-\infty}^{\infty} f_2(c_2)p(c_2) \dif c_2=constant$, which means the marginalization is the actual covariate disentanglement in Eq.~\eqref{eq.follow_namlss} plus a constant. \textbf{If $c_1$ and $c_2$ are \textit{dependent}}, $h_1(c_1)$ is a function of $c_1$ which no longer needs to be a constant and could be a non-trivial function of $c_1$ arising from the inherent stochastic dependence between $c_1$ and $c_2$. Therefore, considering the relationship between $c_1$ and $c_2$ is crucial when using either covariate by itself to interpret the population trend.

In summary, disentangled covariate effects of NAMs, combined with those effects contributed by covariate dependence, shape human-understandable explanations aligned with population trends. \emph{While ignoring potential dependencies in NAMs may not impact prediction performance, it can result in ambiguous or misleading interpretations when analyzing population trends.} More analysis is available in Sec.~\ref{supp.subsec.toy_dataset} in the Supplementary Material.


\subsection{Covariate Marginalization}
\label{subsubsec.how_marg}
\emph{\textcolor{blue}{Due to space constraints, the full derivation is provided in Sec.~\ref{supp.subsubsec.how_marg} of the Supplementary Material.}} This section introduces our proposed marginalization approach to improve the trustworthiness of NAMs when trying to understand the dependency of a covariate on the response.  The dependency of covariates can be modeled with a multivariate Gaussian distribution as $p(\boldsymbol{c}|c_i)=\mathcal{N}(\hat{\boldsymbol{\mu}}(c_i), \hat{\boldsymbol{\Sigma}}(c_i))$ where $\hat{\boldsymbol{\mu}}(c_i)$ represents the mean vector and  $\hat{\boldsymbol{\Sigma}}(c_i)$ the covariance matrix conditioned on $c_i$. From $p(\boldsymbol{c}|c_i)$, one can extract the distribution of an individual covariate $c_k$ conditioned on $c_i$, as $p(c_k|c_i)=\mathcal{N}(\hat{\mu}_k(c_i), \hat{\Sigma}_{k,k}(c_i))$, e.g., how age $c_i$ determines weight $c_k$. One can also extract the joint distribution of $c_{K_1}$ and $c_{K_2}$ conditioned on $c_i$ as $p(c_{K_1}, c_{K_2}|c_i)$ from $p(\boldsymbol{c}|c_i)$, i.e.,
\begin{small}
\begin{equation}
\begin{split}
p(c_{K_1}, c_{K_2}|c_i) =
\mathcal{N}
\left(
\begin{bmatrix}
\hat{\mu}_{K_1}(c_i) \\
\hat{\mu}_{K_2}(c_i) 
\end{bmatrix},
\begin{bmatrix}
\hat{\Sigma}_{K_1, K_1}(c_i) & \hat{\Sigma}_{K_1, K_2}(c_i)  \\
\hat{\Sigma}_{K_2, K_1}(c_i) & \hat{\Sigma}_{K_2, K_2}(c_i)
\end{bmatrix}
\right),
\end{split}
\label{eq.mgd}
\end{equation}
\end{small}
where $\hat{\Sigma}_{K_1, K_2}(c_i)$ is the covariance between $c_{K_1}$ and $c_{K_2}$.

We employ subnetworks $\{g_i(c_i)\}$, each controlled by an individual covariate $c_i$, to model the corresponding conditional distributions $\{p(\boldsymbol{c}|c_i)\}$. Specifically, each subnetwork $g_i(c_i)$ captures a multivariate Gaussian distribution, expressed as: $p(\boldsymbol{c}|c_i) = \mathcal{N}(g^m_i(c_i), g^v_i(c_i))$, where the mean vector $g^m_i(c_i)$ and the covariance matrix $g^v_i(c_i)$ are predicted by \(g_i(c_i)\), as illustrated in Fig.~\ref{fig.method}. %\textcolor{red}{While the above might seem vaguely similar to modeling the dependence between the co-variates as an $N$-dimensional jointly multivariate  normal distribution, since most of the ensuing downstream tasks considered in this paper only require understanding specific functionals of pairwise dependence, we use the above approach to learn the relevant sub-networks needed for the response. }

Next, from Eq.~\eqref{eq.follow_namlss}, the observation $y$ can be formulated as 
\begin{small}
\begin{equation}
y=f^m(\boldsymbol{c},x) + f^v(\boldsymbol{c},x)\cdot \epsilon \\, ~\epsilon \sim \mathcal{N}(0,1) \\.%\sum_{i=1}^Nf^m_i(c_i,x)
\end{equation}
\end{small}
With trained $\{f_i\}$ and $\{g_i\}$, we now investigate how $c_i$ influences the distribution of the observation $y$ as $p(y|c_i,x)= \mathcal{N}(\Tilde{\mu}(c_i, x), \Tilde{\sigma}^2(c_i, x))$, where $\Tilde{\mu}(c_i, x)$ is the expectation of $y$ when fixing $c_i$ and $x$, i.e. $\mathrm{E}[y|c_i,x]$; and $\Tilde{\sigma}^2(c_i, x)$ is the variance of $y$ when fixing $c_i$ and $x$, i.e. $\mathrm{Var}(y|c_i,x)$. 

\paragraph{Mean of $p(y|c_i,x)$.}
We expand the two variable case in Sec.~\ref{subsec.why_mrg} to multi-covariates, with the \emph{law of total expectation}~(1)
\begin{small}
\begin{equation}
\begin{split}
&\Tilde{\mu}(c_i, x) = f^m_i(c_i,x) + \int_{-\infty}^{\infty} (\sum_{k \neq i} f^m_{k}(c_{k},x)) p(\boldsymbol{c}_{k \neq i}|c_i) \dif \boldsymbol{c}_{k \neq i} \\
&= f^m_i(c_i,x) + \sum_{k \neq i} \int_{-\infty}^{\infty} f^m_{k}(c_{k},x) p(c_k|c_i) \dif c_k\,, 
\end{split}
\label{eq.E_y_given_ci}
\end{equation}
\end{small} where $f^m_k(c_k)$ represents the interpretation from the additive subnetwork $f_k$ of \texttt{LucidAtlas} and $\boldsymbol{c}_{k \neq i}=[c_1, ..., c_{i-1}, c_{i+1}, ..., c_N]$.

Eq.~\eqref{eq.E_y_given_ci} indicates that even when multiple covariates are involved, only conditional dependencies with respect to individual covariates ($p(c_k|c_i)$) are required to compute $\Tilde{\mu}(c_i, x)$ as a consequence of the additive model for a NAM, which simplifies computations.

\paragraph{Variance of $p(y|c_i,x)$.}
The \emph{law of total variance} is $\mathrm{Var}(Y) =\mathrm{E}[\mathrm{Var}(Y|X)] + \mathrm{Var}(\mathrm{E}[Y|X])$ which states that the total variance of a random variable $Y$ can be broken into two parts: \textcircled{1} the \textbf{expected variance of $Y$ given $X$}, which represents how much $Y$ fluctuates around its mean for each specific value of $X$; and \textcircled{2} The variance of the \textbf{expected value of $Y$ given $X$}, which measures how much the mean of $Y$ changes as $X$ varies.
With the \emph{law of total variance}, 
\begin{small}
\begin{equation}
\mathrm{Var}(y|c_i,x)= \underbrace{\mathrm{E}[\mathrm{Var}(y|\boldsymbol{c}_{k \neq i}, c_i,x)]}_{ \text{\textcircled{1}} :=\Tilde{\sigma}^2_E(c_i, x)} + \underbrace{\mathrm{Var}(\mathrm{E}[y|\boldsymbol{c}_{k \neq i}, c_i,x])}_{\text{\textcircled{2}}:=\Tilde{\sigma}^2_V(c_i, x)}
\label{eq.Var_dist}
\end{equation}
\end{small}
The expected variance of $f^v(\boldsymbol{c}, x)$ given $c_i$ and $x$ is
\begin{small}
\begin{equation}
\begin{split}
&\Tilde{\sigma}^2_E(c_i, x) = f^v_i(c_i,x) + \sum_{k \neq i} \int_{-\infty}^{\infty} f^v_{k}(c_{k},x) p(c_k|c_i) \dif c_k\,.
\end{split}
\label{eq.E_of_V}
\end{equation}
\end{small}
And the variance of the expected value of $f^m(\boldsymbol{c},x)$ given $c_i$ and $x$ can be computed as
\begin{tiny}
\begin{equation}
\begin{split}
&\Tilde{\sigma}^2_V(c_i, x) =\mathrm{Var}(\mathrm{E}[y|\boldsymbol{c}_{k \neq i}, c_i,x])=\mathrm{Var}(\sum_{k \neq i}f^m_k(c_k, x)|c_i, x) \\ &= \sum_{k \neq i} \underbrace{\mathrm{Var}(f^m_k(c_k,x)|c_i, x)}_{\text{\textcircled{3}}} + \mathop{\sum\sum}_{K_1\neq K_2 \neq i} \underbrace{\mathrm{Cov}(f^m_{K_1}(c_{K_1}, x), f^m_{K_2}(c_{K_2}, x) | c_i, x)}_{\text{\textcircled{4}}}
\end{split}
\label{eq.V_of_E}
\end{equation}
\end{tiny}
where
\begin{small}
\begin{equation}
\begin{split}
&\text{\textcircled{3}} = \int_{-\infty}^{\infty} (f^m_k(c_k, x) - \Tilde{\mu}_k(c_i, x))^2p(c_k| c_i) \dif c_k ,\\
& \Tilde{\mu}_k(c_i, x) = \int_{-\infty}^{\infty} f^m_k(c_k, x)p(c_k|c_i)dc_k
\end{split}
\label{eq.V_of_E_part1}
\end{equation}
\end{small}
\begin{tiny}
\begin{equation}
\begin{split}
\text{\textcircled{4}} = \int_{-\infty}^{\infty}\int_{-\infty}^{\infty} f^m_{K_1}(c_{K_1}, x)f^m_{K_2}(c_{K_2}, x)p(c_{K_1}, c_{K_2}|c_i)\dif c_{K_1} \dif c_{K_2} \\
 - \Tilde{\mu}_{K_1}(c_i, x) \Tilde{\mu}_{K_2}(c_i, x) 
\end{split}
\label{eq.V_of_E_part2}
\end{equation}
\end{tiny}

%&= \int_{-\infty}^{\infty} (f^m(c_i, \boldsymbol{c}_{k \neq i},x) - \Tilde{\mu})^2 p(\boldsymbol{c}_{k \neq i}|c_i) d\boldsymbol{c}_{k \neq i} 

Eqs.~\eqref{eq.E_of_V}-\eqref{eq.V_of_E_part2} imply that instead of sampling the entire covariate space, one only needs to sample from the joint Gaussian distribution between the two covariates, conditioned on the individual covariates, to obtain the marginalized distribution $p(y|c_i,x)$.



\paragraph{Approximation.} 
The integrals in $\Tilde{\mu}(c_i, x)$ (in Eq.~\eqref{eq.E_y_given_ci}), $\Tilde{\sigma}^2_E(c_i, x)$ (in Eq.~\eqref{eq.E_of_V}) and $\Tilde{\sigma}^2_V(c_i, x)$ (in Eqs.~\eqref{eq.E_of_V}-\eqref{eq.V_of_E_part2}) can be approximated using Monte Carlo sampling from $p(c_k|c_i)$ and $p(c_{K_1}, c_{K_2}|c_i)$..


\paragraph{Computational Complexity.}
Suppose there are $N$ covariates and $L$ samples. The computational complexity of marginalizing the NAM for a covariate is \(\mathcal{O}(LN)\), making it feasible in practice. In contrast, for a black-box model, which does not assume our additive structure, the complexity is exponentially higher at \(\mathcal{O}(L^N)\), making direct computation infeasible for large \(N\).

As a result, we obtain $\Tilde{\mu}(c_i, x)$ and $\Tilde{\sigma}^2(c_i, x)=\Tilde{\sigma}^2_E(c_i, x)+\Tilde{\sigma}^2_V(c_i, x)$ to parameterize $p(y|c_i) = \mathcal{N}(\Tilde{\mu}(c_i, x), \Tilde{\sigma}^2(c_i, x))$, capturing the influence of a single covariate $c_i$ on the observation $y$. Our approach aligns with NAM interpretations and can be applied post-hoc.


\subsubsection{Imputation}
\label{sec.imputation}
Our approach naturally facilitates the imputation of missing covariates, as it inherently predicts the conditional distributions \(\{p(c_k \mid c_i)\}\), enabling a principled way to estimate missing values.
 Specifically, if $c_i$ is missing, one can choose the $g_s$ whose uncertainty is the smallest as the predictor for $c_i$ as $s \gets \arg\min_{k,k \neq i} \{{g^v_{k,i}(c_k)}\}$. 


\subsubsection{Individualized Prediction}
\label{sec.ind_pred}
One challenge in the context of atlas discovery is to make individualized predictions when observations are predominantly limited to a single time point, i.e., when the atlas is built from cross sectional data. \texttt{LucidAtlas} provides an approach for individualized prediction based on previous observations. Note that this approach is not based on true longitudinal data  (as such data is frequently not available) but instead aims to predict individual future responses based on the cross-sectional population trend.

We define our problem as follows. Given an observation $y^t$ at $x$ with its corresponding covariates $\boldsymbol{c}^t$  at time $t$, how will a subject's response change when $\boldsymbol{c}^t$ changes to $\boldsymbol{c}^{t+1}$ at time $t+1$?
First, we can obtain the probability distribution with  \texttt{LucidAtlas}, as $p(y^t|\boldsymbol{c}^t,x)=\frac{1}{\sqrt{2\pi f^v(\boldsymbol{c}^t,x)}}\exp(-\frac{(y^t-f^m(\boldsymbol{c}^t,x))^2}{2 \cdot f^v(\boldsymbol{c}^t,x)})$.

\begin{assumption}
We assume that the percentile of a subject remains stationary between observations at two nearby time points, i.e., the cumulative distribution, $\mathrm{F}$, should be stationary: $\mathrm{F}(y^t) = \mathrm{F}(y^{t+1})$.
\label{assump1}
\end{assumption}
An intuitive example for Assumption~\ref{assump1} is that if a child has the largest airway among all 2-year-olds, it is likely that this child's airway will remain the largest over a short period of time. Therefore, an approximate individualized prediction can be obtained as $y^{t+1} \approx f^m(\boldsymbol{c}^{t+1},x) + {\sqrt{\frac{f^v(\boldsymbol{c}^{t+1},x)}{f^v(\boldsymbol{c}^{t},x)}}(y^t-f^m(\boldsymbol{c}^t,x))}$\,.





\section{Experiments}
We aim to answer the following questions with our experiments: \textcircled{1} \emph{How well can \texttt{LucidAtlas} estimate population trends?} \textcircled{2} \emph{Can \texttt{LucidAtlas} capture heteroscadastistic variances across a population?} \textcircled{3} \emph{Do explanations from \texttt{LucidAtlas} align with our prior knowledge?} \textcircled{4} \emph{Isaccepting the independence assumption unquestioningly and directly using NAMs  appropriate in scientific discovery?}  \textcircled{5} \emph{How well can \texttt{LucidAtlas} predict responses at  time B given observations at an earlier time A?}


\subsection{Datasets \& Experimental Protocols}

Learning a pediatric airway atlas is the primary motivating problem of our work~\citep{atlashong2013pediatric}. We also use the OASIS brain dataset~\cite{marcus2007oasis} to validate our approach. The Supplementary Material provides more details about these two datasets and our experimental settings in Sec.~\ref{supp.sec.dataset}.

\textbf{Pediatric Airway Geometry.} 
The dataset includes 358 upper airway shapes obtained from computed tomography (CT) images of children with radiographically normal airways. These 358 airway shapes correspond to 264 patients, with 34 having longitudinal observations and 230 who are observed only once. We consider three covariates in this study: age, weight, and height. The majority of the missing data occur in height and the field of view of the airway. Each complete airway has 11 anatomical landmarks, of which 6 are used in our experiments (Fig.~\ref{fig.method}); 263 scans have complete covariate data (age, weight, height).  

We aim to construct an airway atlas which captures airway cross sectional area (CSA) as well as CSA population distributions, incorporating the prior knowledge that CSA shoul monotonically increase with age, weight, and height.  

We convert the $k^{th}$ airway shape into a CSA function mapping normalized depth $x \in [0,1]$ to CSA values as $CSA = C_k(x)$. Based on our discretization complete airways have 500 depth-CSA pairs uniformly distributed on the airway centerline, while incomplete ones have \( \leq 500 \).  

The dataset is split into 80\%/20\% training / test sets respectively by patient, with all longitudinal data in the test set. This ensures that the model learns population trends from individual observations while retaining longitudinal data for individual evaluations.  

%More details are available in the Supplementary Material at Sec.~\ref{supp.subsec.airway_dataset}.

%Errors in the shapes $\{\mathcal{S}^k\}$ may arise from image segmentation error, differences in head positioning, missing parts of the airway shapes due to incomplete image coverage, and dynamic airway deformations due to breathing. 


\paragraph{OASIS Brain Volumes.} 
Brain segmentations were obtained from the OASIS dataset~\citep{marcus2007oasis}, which includes two subsets:  
\textcircled{1} A cross-sectional set with 416 subjects aged 18–96, primarily single-time observations, plus a reliability subset of 20 non-demented subjects rescanned within 90 days.  
\textcircled{2} A longitudinal set of 150 older adults (60–96 years), totaling 373 imaging sessions.  

Our experiments include four covariates: age, socioeconomic status (SES), mini-mental state examination (MMSE), and clinical dementia rating (CDR). The response variable is the normalized whole brain volume (nWBV).  

\emph{We aim to investigate the relationships between these covariates and brain volume.} Based on prior knowledge, brain volume should not increase with age or CDR, nor decrease when mental state improves~\citep{fotenos2008brain}.  




%72 of the subjects were characterized as nondemented throughout the study. 64 of the included subjects were characterized as demented at the time of their initial visits and remained so for subsequent scans, including 51 individuals with mild to moderate Alzheimer’s disease. Another 14 subjects were characterized as nondemented at the time of their initial visit and were subsequently characterized as demented at a later visit.


\paragraph{Comparison Methods.}
We choose the current state-of-the-art explainable regression methods, i.e., LightGBM~\citep{ke2017lightgbm} and Explainable Boosting Machines (EBM)~\citep{lou2013EBM} to provide high-quality regression performance. We also compare \texttt{LucidAtlas} with NAM with Exu activations and ensembling strategies~\citep{agarwal2020neural}. We found that NAMLSS performs best for learning population trends, justifying our choice of an additive structure. Besides NAMLSS for uncertainty estimation, we also directly use a multi-layer perceptron (MLP) for mean-variance parameterization of the negative log-likelihood loss as a baseline, termed MLP+NLL. I.e., this MLP+NLL model does not assume an additive structure.



%Our principle of selecting comparison methods is that 1) explainable approaches which attain excellent  performance on a certain task (in our case regression population trends) or 2) it has similarities in principle with our approach, i.e., the approaches based on additive models

\paragraph{Evaluation Metrics.}
 The Mean Absolute Relative Percent Difference (MARPD) evaluates regression accuracy in capturing population trends, while the Negative Log-Likelihood (NLL) assesses how closely the modeled distribution aligns with the true data distribution. %We visualize the learned covariate interpretation from different approaches to check their validity. The quality of individualized predictions is evaluated with MARPD. 

\begin{table*}[t]
\centering
\resizebox{0.9\textwidth}{!}{
\begin{tabular}{c|ccc|c|ccccccc}
\hline
 &
   &
   &
   &
  \cellcolor[HTML]{E9FEE9} &
  \multicolumn{7}{c}{\cellcolor[HTML]{E2E3F8}\textbf{Pediatric Airway}} \\ \cline{6-12} 
\multirow{-2}{*}{Methods} &
  \multirow{-2}{*}{Spa.} &
  \multirow{-2}{*}{Add.} &
  \multirow{-2}{*}{Mono.} &
  \multirow{-2}{*}{\cellcolor[HTML]{E9FEE9}\textbf{OASIS Brain}} &
  \multicolumn{1}{c|}{\textbf{Overall}} &
  nasal spine &
  choana &
  epiglottic tip &
  \cellcolor[HTML]{F8E5E4}TVC &
  \cellcolor[HTML]{F8E5E4}subglottis &
  \cellcolor[HTML]{F8E5E4}carina \\ \hline
EBM &
  \XSolidBrush &
  \XSolidBrush &
  \Checkmark &
  3.1920$\pm$2.4985 &
  \multicolumn{1}{c|}{38.8774$\pm$38.9116} &
  44.0259$\pm$40.0036 &
  41.9254$\pm$48.9492 &
  17.7694$\pm$22.4692 &
  20.8076$\pm$26.3942 &
  22.3948$\pm$28.1368 &
  25.4489$\pm$31.4176 \\
LightGBM &
  \XSolidBrush &
  \XSolidBrush &
  \XSolidBrush &
  3.0289$\pm$2.4324 &
  \multicolumn{1}{l|}{36.7755$\pm$35.8704} &
  46.1999$\pm$39.9386 &
  {\color[HTML]{9A0000} \textbf{28.4655$\pm$29.9739}} &
  {\color[HTML]{9A0000} \textbf{14.1479$\pm$12.1693}} &
  19.3283$\pm$16.9426 &
  20.6356$\pm$19.1491 &
  19.9048$\pm$23.6890 \\
NAM &
  \XSolidBrush &
  \Checkmark &
  \XSolidBrush &
  \multicolumn{1}{l|}{3.3882$\pm$2.4748} &
  \multicolumn{1}{l|}{37.1746$\pm$35.1216} &
  \multicolumn{1}{l}{43.8124$\pm$40.1094} &
  \multicolumn{1}{l}{\textbf{37.2806$\pm$33.4382}} &
  \multicolumn{1}{l}{17.4907$\pm$13.0446} &
  \multicolumn{1}{l}{21.0430$\pm$18.8356} &
  \multicolumn{1}{l}{22.5744$\pm$21.0187} &
  \multicolumn{1}{l}{21.8049$\pm$24.0872} \\ \hline
MLP+NLL &
  \XSolidBrush &
  \XSolidBrush &
  \XSolidBrush &
  3.1036$\pm$2.6835 &
  \multicolumn{1}{l|}{38.3364$\pm$36.8091} &
  33.9609$\pm$26.9933 &
  45.0381$\pm$34.6801 &
  18.5780$\pm$17.1130 &
  20.5003$\pm$23.1434 &
  19.9590$\pm$23.7551 &
  21.0536$\pm$13.8406 \\
NAMLSS &
  \XSolidBrush &
  \Checkmark &
  \XSolidBrush &
  {\color[HTML]{000000} \textbf{3.0244$\pm$2.3980}} &
  \multicolumn{1}{l|}{37.3115$\pm$34.7218} &
  {\color[HTML]{9A0000} \textbf{30.7901$\pm$25.6496}} &
  41.1237$\pm$33.3017 &
  {\color[HTML]{000000} 21.5784$\pm$17.1608} &
  {\color[HTML]{000000} 25.3131$\pm$24.5728} &
  {\color[HTML]{000000} 24.2743$\pm$24.6332} &
  {\color[HTML]{000000} 21.1646$\pm$16.1043} \\ \hline
\rowcolor[HTML]{EFEFEF} 
Ours  np &
  \Checkmark &
  \Checkmark &
  \XSolidBrush &
  {\color[HTML]{000000} \textbf{3.0244$\pm$2.3980}} &
  \multicolumn{1}{c|}{\cellcolor[HTML]{EFEFEF}{\color[HTML]{000000} \textbf{36.4472$\pm$35.5650}}} &
  \textbf{32.9029$\pm$25.5350} &
  40.4435$\pm$33.1123 &
  16.1585$\pm$15.4162 &
  {\color[HTML]{9A0000} \textbf{19.2762$\pm$23.1651}} &
  {\color[HTML]{9A0000} \textbf{17.8992$\pm$23.5066}} &
  {\color[HTML]{000000} \textbf{17.4608$\pm$12.2250}} \\
\rowcolor[HTML]{EFEFEF} 
Our part &
  \Checkmark &
  \Checkmark &
  \Checkmark &
  {\color[HTML]{9A0000} \textbf{3.0045$\pm$2.2426}} &
  \multicolumn{1}{c|}{\cellcolor[HTML]{EFEFEF}37.1696$\pm$35.6229} &
  37.4176$\pm$27.0885 &
  42.1177$\pm$33.8561 &
  16.3098$\pm$15.7531 &
  19.7589$\pm$23.1405 &
  19.1237$\pm$23.3031 &
  17.9994$\pm$12.3826 \\
\rowcolor[HTML]{EFEFEF} 
Ours imp &
  \Checkmark &
  \Checkmark &
  \Checkmark &
  3.0936$\pm$2.2473 &
  \multicolumn{1}{c|}{\cellcolor[HTML]{EFEFEF}{\color[HTML]{9A0000} \textbf{36.2685$\pm$35.6709}}} &
  34.1421$\pm$26.2881 &
  42.3398$\pm$33.8903 &
  \textbf{15.2841$\pm$14.7377} &
  \textbf{19.2930$\pm$22.9405} &
  \textbf{18.6742$\pm$23.1107} &
  {\color[HTML]{9A0000} \textbf{17.3280$\pm$12.0628}} \\ \hline
\end{tabular}}
\caption{\small Quantitative Evaluation of Normalized Brain Volume Regression (OASIS Brain Dataset) and Cross-Sectional Area Regression (Pediatric Airway Dataset) with respect to Mean Absolute Relative Percent Difference (MARPD, \%). We also evaluate with respect to  different landmarks. The \{TVC, subglottic and carina\} landmarks are significant landmarks for airway obstruction analysis~\citep{atlashong2013pediatric}. \textbf{\textcolor{purple}{Bold red values}} indicate the best scores across all methods. \textbf{Bold black values} indicate the 2nd best scores of all methods. \textbf{Spa.} indicates whether spatial dependency is considered. \textbf{Add.} indicates whether a model has an additive design. \textbf{Mono.} indicates whether prior knowledge about monotonicity is used. \textit{Ours np} refers to \texttt{LucidAtlas} without incorporating prior knowledge. \textit{Ours part} denotes our model trained only on complete data, while \textit{Ours imp} represents using the full dataset for training, including missing values. \texttt{LucidAtlas} performs best overall.}
\label{exp.single_quant_marpd}
\end{table*}






\begin{table}[t]
\centering
\resizebox{0.5\textwidth}{!}{
\begin{tabular}{c|ccc|c|ccccccc}
\hline
\multicolumn{1}{l|}{} &
   &
   &
   &
  \cellcolor[HTML]{E9FEE9} &
  \multicolumn{7}{c}{\cellcolor[HTML]{E2E3F8}\textbf{Pediatric Airway}} \\ \cline{6-12} 
\multicolumn{1}{l|}{\multirow{-2}{*}{}} &
  \multirow{-2}{*}{Spa.} &
  \multirow{-2}{*}{Add.} &
  \multirow{-2}{*}{Mono.} &
  \multirow{-2}{*}{\cellcolor[HTML]{E9FEE9}\textbf{OASIS Brain}} &
  \multicolumn{1}{c|}{\textbf{Overall}} &
  nasal spine &
  choana &
  epiglottic tip &
  \cellcolor[HTML]{F8E5E4}TVC &
  \cellcolor[HTML]{F8E5E4}subglottis &
  \cellcolor[HTML]{F8E5E4}carina \\ \hline
MLP+NLL &
  \XSolidBrush &
  \XSolidBrush &
  \XSolidBrush &
  {\color[HTML]{000000} 2.5573} &
  \multicolumn{1}{c|}{{\color[HTML]{000000} 1.0273}} &
  {\color[HTML]{9A0000} \textbf{1.7403}} &
  {\color[HTML]{000000} 1.7702} &
  {\color[HTML]{000000} -0.1508} &
  {\color[HTML]{000000} -0.0302} &
  {\color[HTML]{000000} 0.0778} &
  {\color[HTML]{000000} 0.2415} \\
NAMLSS &
  \XSolidBrush &
  \Checkmark &
  \XSolidBrush &
  {\color[HTML]{000000} 0.6714} &
  \multicolumn{1}{c|}{{\color[HTML]{000000} 1.0020}} &
  {\color[HTML]{000000} \textbf{1.7591}} &
  {\color[HTML]{9A0000} \textbf{1.4011}} &
  {\color[HTML]{000000} -0.0561} &
  {\color[HTML]{000000} 0.4015} &
  {\color[HTML]{000000} 0.3951} &
  {\color[HTML]{000000} 0.917} \\ \hline
\rowcolor[HTML]{EFEFEF} 
Ours  np &
  \Checkmark &
  \Checkmark &
  \XSolidBrush &
  {\color[HTML]{000000} 0.6714} &
  \multicolumn{1}{c|}{\cellcolor[HTML]{EFEFEF}{\color[HTML]{000000} 0.9365}} &
  {\color[HTML]{000000} 1.7796} &
  {\color[HTML]{000000} \textbf{1.4115}} &
  {\color[HTML]{000000} \textbf{-0.3948}} &
  {\color[HTML]{000000} \textbf{-0.1274}} &
  {\color[HTML]{9A0000} \textbf{-0.1633}} &
  {\color[HTML]{9A0000} \textbf{0.0331}} \\
\rowcolor[HTML]{EFEFEF} 
Our part &
  \Checkmark &
  \Checkmark &
  \Checkmark &
  {\color[HTML]{9A0000} \textbf{0.6457}} &
  \multicolumn{1}{c|}{\cellcolor[HTML]{EFEFEF}{\color[HTML]{9A0000} \textbf{0.8467}}} &
  1.9669 &
  1.4561 &
  -0.3043 &
  {\color[HTML]{9A0000} \textbf{-0.1293}} &
  \textbf{-0.1185} &
  \textbf{0.0726} \\
\rowcolor[HTML]{EFEFEF} 
Ours imp &
  \Checkmark &
  \Checkmark &
  \Checkmark &
  \textbf{0.6514} &
  \multicolumn{1}{c|}{\cellcolor[HTML]{EFEFEF}\textbf{0.8901}} &
  1.8087 &
  1.4542 &
  {\color[HTML]{9A0000} \textbf{-0.4341}} &
  -0.0065 &
  0.0146 &
  0.0966 \\ \hline
\end{tabular}
}
\caption{\small Quantitative Evaluation of Population Distribution Estimation based on Negative Log-Likelihood (NLL). Our approach achieves the best performance overall.  }
\label{exp.single_quant_nll}
\end{table}


\begin{table}[t]
\centering
\resizebox{0.5\textwidth}{!}{
\begin{tabular}{ccccccccc}
\hline
\rowcolor[HTML]{E2E3F8} 
\multicolumn{9}{c}{\cellcolor[HTML]{E2E3F8}\textbf{Pediatric Airway}} \\ \hline
\multicolumn{1}{c|}{Covariate} &
  \multicolumn{1}{c|}{Corr.} &
  \multicolumn{1}{c|}{Overall} &
  nasal spine &
  choana &
  epiglottic tip &
  \cellcolor[HTML]{F8E5E4}TVC &
  \cellcolor[HTML]{F8E5E4}subglottis &
  \cellcolor[HTML]{F8E5E4}carina \\ \hline
\multicolumn{1}{c|}{Age} &
  \multicolumn{1}{c|}{\XSolidBrush} &
  \multicolumn{1}{c|}{0.9907} &
  {\color[HTML]{9A0000} \textbf{1.9341}} &
  1.4836 &
  0.4278 &
  {\color[HTML]{000000} 0.1805} &
  0.1673 &
  0.5516 \\
\rowcolor[HTML]{EFEFEF} 
\multicolumn{1}{c|}{\cellcolor[HTML]{EFEFEF}Age} &
  \multicolumn{1}{c|}{\cellcolor[HTML]{EFEFEF}\Checkmark} &
  \multicolumn{1}{c|}{\cellcolor[HTML]{EFEFEF}{\color[HTML]{9A0000} \textbf{0.8565}}} &
  {\color[HTML]{000000} 2.0124} &
  {\color[HTML]{9A0000} \textbf{1.4789}} &
  {\color[HTML]{9A0000} \textbf{-0.183}} &
  {\color[HTML]{9A0000} \textbf{-0.1709}} &
  {\color[HTML]{9A0000} \textbf{-0.1777}} &
  {\color[HTML]{9A0000} \textbf{0.1485}} \\ \hline
\multicolumn{1}{c|}{Height} &
  \multicolumn{1}{c|}{\XSolidBrush} &
  \multicolumn{1}{c|}{0.9830} &
  2.1449 &
  1.4496 &
  0.4049 &
  0.2185 &
  0.2179 &
  0.4715 \\
\rowcolor[HTML]{EFEFEF} 
\multicolumn{1}{c|}{\cellcolor[HTML]{EFEFEF}Height} &
  \multicolumn{1}{c|}{\cellcolor[HTML]{EFEFEF}\Checkmark} &
  \multicolumn{1}{c|}{\cellcolor[HTML]{EFEFEF}{\color[HTML]{9A0000} \textbf{0.8330}}} &
  {\color[HTML]{9A0000} \textbf{1.9187}} &
  {\color[HTML]{9A0000} \textbf{1.3968}} &
  {\color[HTML]{9A0000} \textbf{-0.2574}} &
  {\color[HTML]{9A0000} \textbf{-0.1002}} &
  {\color[HTML]{9A0000} \textbf{-0.0819}} &
  {\color[HTML]{9A0000} \textbf{0.0968}} \\ \hline
\multicolumn{1}{c|}{Weight} &
  \multicolumn{1}{c|}{\XSolidBrush} &
  \multicolumn{1}{c|}{1.0804} &
  2.1305 &
  {\color[HTML]{9A0000} \textbf{1.3957}} &
  0.6239 &
  0.4729 &
  0.4701 &
  0.7822 \\
\rowcolor[HTML]{EFEFEF} 
\multicolumn{1}{c|}{\cellcolor[HTML]{EFEFEF}Weight} &
  \multicolumn{1}{c|}{\cellcolor[HTML]{EFEFEF}\Checkmark} &
  \multicolumn{1}{c|}{\cellcolor[HTML]{EFEFEF}{\color[HTML]{9A0000} \textbf{0.8813}}} &
  {\color[HTML]{9A0000} \textbf{1.9122}} &
  1.431 &
  {\color[HTML]{9A0000} \textbf{-0.1077}} &
  {\color[HTML]{9A0000} \textbf{0.0004}} &
  {\color[HTML]{9A0000} \textbf{0.0237}} &
  {\color[HTML]{9A0000} \textbf{0.1829}} \\ \hline
\end{tabular}
}
\caption{\small Quantitative Comparison of Different Ways of Marginalization. NLL is computed between the marginalized covariate interpretation and the data distribution. A \Checkmark in the \textbf{Corr.} column indicates that covariate dependence is considered, while \XSolidBrush signifies that it is ignored. Accounting for covariate dependence improves alignment between covariate interpretation and the data distribution.
}
\label{exp.airway_cov_corr}
\end{table}







% \begin{table}[]
% \resizebox{0.45\textwidth}{!}{
% \begin{tabular}{ccllllll}
% \hline
% \multicolumn{8}{c}{\cellcolor[HTML]{E2E3F8}\textbf{Pediatric Airway}} \\ \hline
% \multicolumn{1}{c|}{Covariate} &
%   \multicolumn{1}{c|}{Corr.} &
%   \multicolumn{1}{c}{nasal spine} &
%   \multicolumn{1}{c}{choana} &
%   \multicolumn{1}{c}{epiglottic tip} &
%   \multicolumn{1}{c}{\cellcolor[HTML]{F8E5E4}TVC} &
%   \multicolumn{1}{c}{\cellcolor[HTML]{F8E5E4}subglottis} &
%   \multicolumn{1}{c}{\cellcolor[HTML]{F8E5E4}carina} \\ \hline
% \multicolumn{1}{c|}{Age} &
%   \multicolumn{1}{c|}{\XSolidBrush} &
%   {\color[HTML]{9A0000} \textbf{1.9341$\pm$2.2978}} &
%   1.4836$\pm$1.5584 &
%   0.4278$\pm$0.5069 &
%   {\color[HTML]{000000} 0.1805$\pm$0.4773} &
%   0.1673$\pm$0.4717 &
%   0.5516$\pm$0.6499 \\
% \multicolumn{1}{c|}{\cellcolor[HTML]{EFEFEF}Age} &
%   \multicolumn{1}{c|}{\cellcolor[HTML]{EFEFEF}\Checkmark} &
%   {\color[HTML]{000000} 2.0124$\pm$2.7535} &
%   {\color[HTML]{9A0000} \textbf{1.4789$\pm$1.6962}} &
%   {\color[HTML]{9A0000} \textbf{-0.1830$\pm$0.7643}} &
%   {\color[HTML]{9A0000} \textbf{-0.1709$\pm$1.4722}} &
%   {\color[HTML]{9A0000} \textbf{-0.1777$\pm$1.5094}} &
%   {\color[HTML]{9A0000} \textbf{0.1485$\pm$0.6957}} \\ \hline
% \multicolumn{1}{c|}{Height} &
%   \multicolumn{1}{c|}{\XSolidBrush} &
%   2.1449$\pm$3.0665 &
%   1.4496$\pm$1.3368 &
%   0.4049$\pm$0.5811 &
%   0.2185$\pm$0.5248 &
%   0.2179$\pm$0.5406 &
%   0.4715$\pm$0.6026 \\
% \multicolumn{1}{c|}{\cellcolor[HTML]{EFEFEF}Height} &
%   \multicolumn{1}{c|}{\cellcolor[HTML]{EFEFEF}\Checkmark} &
%   {\color[HTML]{9A0000} \textbf{1.9187$\pm$2.4983}} &
%   {\color[HTML]{9A0000} \textbf{1.3968$\pm$1.4765}} &
%   {\color[HTML]{9A0000} \textbf{-0.2574$\pm$0.7023}} &
%   {\color[HTML]{9A0000} \textbf{-0.1002$\pm$1.7037}} &
%   {\color[HTML]{9A0000} \textbf{-0.0819$\pm$1.7978}} &
%   {\color[HTML]{9A0000} \textbf{0.0968$\pm$0.6210}} \\ \hline
% \multicolumn{1}{c|}{Weight} &
%   \multicolumn{1}{c|}{\XSolidBrush} &
%   2.1305$\pm$3.2151 &
%   {\color[HTML]{9A0000} \textbf{1.3957$\pm$1.1857}} &
%   0.6239$\pm$0.5923 &
%   0.4729$\pm$0.6277 &
%   0.4701$\pm$0.6406 &
%   0.7822$\pm$0.7949 \\
% \multicolumn{1}{c|}{\cellcolor[HTML]{EFEFEF}Weight} &
%   \multicolumn{1}{c|}{\cellcolor[HTML]{EFEFEF}\Checkmark} &
%   {\color[HTML]{9A0000} \textbf{1.9122$\pm$2.5534}} &
%   1.4310$\pm$1.5167 &
%   {\color[HTML]{9A0000} \textbf{-0.1077$\pm$0.7675}} &
%   {\color[HTML]{9A0000} \textbf{0.0004$\pm$1.3256}} &
%   {\color[HTML]{9A0000} \textbf{0.0237$\pm$1.3644}} &
%   {\color[HTML]{9A0000} \textbf{0.1829$\pm$0.6037}} \\ \hline
% \end{tabular}}
% \caption{\small Quantitative Evaluation of Different Interpretation Types on OASIS Brain Dataset. Marginalization calibrates feature interpretation to population distribution. Marginalization will not increase CORR for independent covariates. }
% \label{exp.brain_global_vs_local_corr}
% \end{table}









\begin{table}[t]
\centering
\resizebox{0.5\textwidth}{!}{
\begin{tabular}{l|l|llllllllllllll}
\hline
\multicolumn{1}{c|}{} &
  \multicolumn{1}{c|}{\cellcolor[HTML]{E9FEE9}} &
  \multicolumn{14}{c}{\cellcolor[HTML]{E2E3F8}\textbf{Pediatric Airway}} \\ \cline{3-16} 
\multicolumn{1}{c|}{\multirow{-2}{*}{Time}} &
  \multicolumn{1}{c|}{\multirow{-2}{*}{\cellcolor[HTML]{E9FEE9}\textbf{OASIS Brain}}} &
  \multicolumn{1}{c|}{\textbf{Overall}} &
  \multicolumn{2}{c}{nasal spine} &
  \multicolumn{2}{c}{choana} &
  \multicolumn{2}{c}{epiglottic tip} &
  \multicolumn{3}{c}{\cellcolor[HTML]{F8E5E4}TVC} &
  \multicolumn{2}{c}{\cellcolor[HTML]{F8E5E4}subglottis} &
  \multicolumn{2}{c}{\cellcolor[HTML]{F8E5E4}carina} \\ \hline
T0 &
  1.6042 &
  \multicolumn{1}{l|}{37.2944} &
  \multicolumn{2}{l}{31.2867} &
  \multicolumn{2}{l}{50.55989} &
  \multicolumn{2}{l}{11.9559} &
  \multicolumn{3}{l}{13.2770} &
  \multicolumn{2}{l}{14.2701} &
  \multicolumn{2}{l}{19.1819} \\
Pop. &
  3.1563 &
  \multicolumn{1}{l|}{37.8092} &
  \multicolumn{2}{l}{39.1704} &
  \multicolumn{2}{l}{{\color[HTML]{9A0000} \textbf{45.2991}}} &
  \multicolumn{2}{l}{14.7017} &
  \multicolumn{3}{l}{15.2413} &
  \multicolumn{2}{l}{15.2040} &
  \multicolumn{2}{l}{{\color[HTML]{9A0000} \textbf{17.1568}}} \\ \hline
\rowcolor[HTML]{EFEFEF} 
Ind. &
  {\color[HTML]{9A0000} \textbf{1.4687}} &
  \multicolumn{1}{l|}{\cellcolor[HTML]{EFEFEF}{\color[HTML]{9A0000} \textbf{35.7221}}} &
  \multicolumn{2}{l}{\cellcolor[HTML]{EFEFEF}{\color[HTML]{9A0000} \textbf{31.1910}}} &
  \multicolumn{2}{l}{\cellcolor[HTML]{EFEFEF}50.1397} &
  \multicolumn{2}{l}{\cellcolor[HTML]{EFEFEF}{\color[HTML]{9A0000} \textbf{9.2835}}} &
  \multicolumn{3}{l}{\cellcolor[HTML]{EFEFEF}{\color[HTML]{9A0000} \textbf{10.2199}}} &
  \multicolumn{2}{l}{\cellcolor[HTML]{EFEFEF}{\color[HTML]{9A0000} \textbf{11.2128}}} &
  \multicolumn{2}{l}{\cellcolor[HTML]{EFEFEF}17.2563} \\ \hline
\end{tabular}
}
\caption{\small Mean Absolute Relative Percent Difference (in \%) for Individualized Prediction. \textbf{T0} in the \textbf{Time} column indicates directly using the observation from the initial time point $T0$ to predict at time $T1$. \textbf{Pop.} indicates ignoring the observation at $T0$ and directly using the mean population value $f^m(\boldsymbol{c},x)$ for individualized prediction for $T1$. \textbf{Ind.} indicates our approach illustrated in Sec.~\ref{sec.ind_pred}. Individualized prediction provides the best performance for both datasets and for most landmarks. 
 }
\label{exp.quant_long_marpd}
\end{table}


\begin{figure}[t]
    \centering
    \includegraphics[width=0.95\linewidth]{figures/sgs_com_vis_small.pdf}
    \caption{\small Visualizations of Covariate Interpretations from \texttt{LucidAtlas} for CSA Distribution at the Subglottis Landmark (Pediatric Airway Dataset). (1) $f_i(c_i)$ represents the disentangled covariate effect directly from a NAM as illustrated in Sec.~\ref{sec.dist_cov_effects}; (2) Marginalized covariate interpretation without accounting for covariate dependence; (3) Marginalized covariate interpretation incorporating covariate dependence. \textcolor{SeaGreen}{Green} and \textcolor{Orchid}{purple} dots indicate training and testing samples respectively. The \textcolor{BrickRed}{red} lines represent the learned population trend, and the \textcolor{Gray}{gray} shading spans \(\pm 2 \times\) standard deviations. Considering covariate dependence is essential for accurately capturing how each covariate influences the population trend and associated uncertainties.} 
    \label{fig.vis_whether_do_correlation}
\end{figure}



\begin{figure}[t]
    \centering
    \includegraphics[width=0.97\linewidth]{figures/compare_prior_vis_small.pdf}
    \caption{\small Visualizations of the Effect of Prior Knowledge in \texttt{LucidAtlas} at the Subglottis Landmark (Pediatric Airway Dataset). The \textcolor{red}{$\times$} symbol indicates the covariate interpretation contradicts prior knowledge, such as the NAM incorrectly interpreting airway CSA as decreasing with a child's weight. Without incorporating prior knowledge, the model may deviate form our prior assumptions. Without marginalization, to account for covariate dependencies, the data may not be fit well.}
    \label{fig.whether_use_prior}
\end{figure}







% \begin{figure}
%     \centering
%     \includegraphics[width=0.99\linewidth]{figures/vis_brain_atlas.pdf}
%     \caption{\small{Visualizations of the Learned Interpretable Brain Atlas with Uncertainties. See illustrations of the figure setting at Fig.~\ref{fig.vis_airway_atlas}. Our local covariate interpretations match the prior knowledge about monotonicity. Our global covariate interpretations closely follow the population distribution. (Best viewed zoomed.) }}
%     \label{fig.vis_brain_atlas}
% \end{figure}



\subsection{Discussions}
\textbf{Population Trend Regression.} Table~\ref{exp.single_quant_marpd} presents the quantitative evaluation of population trend regression. Notably, in the absence of a spatial variable $x$, such as in the OASIS Brain dataset, \texttt{LucidAtlas} is equivalent to NAMLSS when no prior knowledge is incorporated. NAMLSS outperforms \textit{MLP+NLL}, highlighting the advantage of an additive network structure with uncertainty estimation in capturing population trends. Among all methods, \texttt{LucidAtlas} achieves the best performance. For the pediatric airway dataset, training with data that include missing values, as described in Sec.~\ref{sec.imputation}, further enhances regression accuracy. 
We observe that the standard deviations of the MARPD metrics in Table~\ref{exp.single_quant_marpd} are large, largely due to data uncertainties. Beyond regression performance, our primary concern is how well the distribution captured by \texttt{LucidAtlas} aligns with the true population distribution, as this accounts for data uncertainties.
\textbf{Population Distribution.} Table~\ref{exp.single_quant_nll} quantifies the performance of different approaches in estimating population distributions. Our approach outperforms all baselines, demonstrating that incorporating prior knowledge of monotonicity, as implemented in \texttt{LucidAtlas}, enhances NAMs' capability in modeling population distributions.
\textbf{Benefit of Prior Knowledge.} Fig.~\ref{fig.whether_use_prior} compares covariate interpretations with and without prior knowledge in \texttt{LucidAtlas} at the subglottis landmark. While the marginalized covariate interpretations in Fig.~\ref{fig.whether_use_prior}(2, 4) may appear similar, disregarding prior knowledge leads to unreasonable covariate interpretations. For instance, the model erroneously interprets airway CSA as decreasing with respect to a child’s weight at the subglottis landmark. Additional visualizations are provided in the Supplementary Material.
\textbf{Role of Covariate Dependence.}
Table~\ref{exp.airway_cov_corr} and Fig.~\ref{fig.vis_whether_do_correlation} examine the significance of covariate dependence in single-feature interpretation. Fig.~\ref{fig.vis_whether_do_correlation} illustrates that ignoring covariate dependence results in underconfident uncertainty estimation and suboptimal population trend prediction, highlighting the necessity of incorporating covariate dependence for reliable interpretation. The quantitative results in Table~\ref{exp.airway_cov_corr} further confirm that, marginalized covariate interpretation with dependence better aligns with the data distribution.
\textbf{Individualized Prediction.} We quantify the performance of individualized predictions (to predict for $T1$ given the observation at $T0$). As described in Sec.~\ref{sec.ind_pred}, our approach, which intergrates the observations at $T0$ with population trends, yields the best predictive performance. More experiment results and visualizations are available at Sec.~\ref{supp.more_vis_exp}.

\section{Limitations and Future Work}
\label{sec.limit}
%This work focuses on modeling aleatoric uncertainty to capture population variance. Moving forward, we aim to incorporate epistemic uncertainty, for example, using a Laplace Approximation~\citep{daxberger2021laplace}.
\texttt{LucidAtlas} models population variance with a Gaussian distribution. Expanding beyond Gaussian assumptions, more flexible probabilistic frameworks—such as non-parametric approaches or mixture models—could improve expressiveness and model fits.
Identifiability issues arise when covariates are dependent or the latent space is redundant, potentially affecting interpretability~\citep{zhou2020identifiability, siems2023curve}. Addressing these concerns is crucial for ensuring well-posed solutions.
Another key extension is incorporating categorical variables into uncertainty quantification, as such variables often exist for real-world datasets. 
Currently, we describe the airway using cross-sectional area. In future work, we plan to develop a probabilistic representation for 3D shape modeling with uncertainties by extending NAISR~\citep{jiao2023naisr}.


\section{Conclusions}
We introduced \texttt{LucidAtlas}, an approach for learning an uncertainty-aware, covariate-disentangled, and individualized atlas representation. Additionally, we highlighted potential risks in using NAMs for covariate interpretation in the presence of covariate dependence and proposed a computationally efficient marginalization approach to mitigate these limitations. Furthermore, we found that incorporating prior knowledge helps eliminate misleading interpretations. We evaluated our method using two distinct datasets, validating its trustworthiness and effectiveness. \texttt{LucidAtlas} stands out as the only atlas representation capable of addressing covariate-, subject-, population-, and spatial-level questions in an interpretable and reliable manner. %Our work demonstrates the crucial role of interpretable models in scientific discovery, enhancing interpretability and trustworthiness while maintaining high performance.






\section{Acknowledgement}
The research reported in this publication was supported by NIH grant 1R01HL154429 and 1R21HL172230-01A1. The content is solely the responsibility of the authors and does not necessarily represent the official views of the NIH. 

\newpage
\clearpage

\bibliography{uai2025-template}
%\bibliographystyle{icml2025}


%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% APPENDIX
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\clearpage
\newpage
\appendix
\input{supplementary}
\onecolumn
\end{document}
