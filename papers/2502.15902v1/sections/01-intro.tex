Large Language Models (LLMs), characterized by their massive scale and extensive training data ~\cite{r1}, have achieved significant advances in natural language processing (NLP) ~\cite{r10,r11,r12}. However, with the advanced capabilities of LLMs, they are subject to frequent misused in various domains, including academic fraud, the creation of deceptive material, and the generation of fabricated information~\cite{r13,r14,r15}, which underscores the critical need to distinguish between human-written text (HWT) and LLM-generated text (LGT)~\cite{r14,r18,r19}.

However, due to their sophisticated functionality, LLMs pose significant challenges in the robustness of current AI detection systems~\cite{r12}. The existing detection systems, including commercial ones, frequently misclassify texts as HWT~\cite{r20,r21} and generate inconsistent results when analyzing the same text using different detectors~\cite{r22,r23}. Studies show false positive rates reaching up to 50\% and false negative rates as high as 100\% in different tools~\cite{r23} when dealing with out-of-distribution (OOD) datasets.

Another critical issue with the existing AI detection systems is their lack of verifiable evidence~\cite{r24}, as these tools typically provide only simple outputs like \textit{"likely written by AI"} or percentage-based predictions~\cite{r23}. The lack of evidence prevents users from defending themselves against false accusations~\cite{r22} and hinders organizations from making judgments based solely on the detection results without convincing evidences~\cite{r23}. This problem is particularly troublesome not only because the low accuracy of such systems as mentioned before, but also due to the consequent inadequate response to LLM misuse, which can lead to significant societal harm~\cite{r25,r26,r27,r12}. These limitations highlight the pressing need for more reliable, explainable and robust detectors.
%in light of the low accuracy in such systems as mentioned above, which highlights the pressing need for more reliable and explainable detectors to prevent the misuse of LLMs~\cite{r25,r26,r27,r12}.

\begin{figure*}[t]
  \centering
  \includegraphics[width=0.7\textwidth]{workflow.png}
  \caption{The overall workflow of our proposed IPAD framework}
  \label{fig:workflow}
\end{figure*}

In this paper, we propose IPAD (Inverse Prompt for AI Detection), a novel framework comprising two key components as shown in Figure~\ref{fig:workflow}: a ~\textbf{Prompt Inverter} that reconstructs prompts from input text, and a ~\textbf{Distinguisher} that classifies text as HWT or LGT. We consider and examine two distinct approaches for the Distinguisher: the ~\textit{Prompt-Text Consistency Verifier} evaluates direct alignment between predicted prompts and input text, while the ~\textit{Regeneration Comparator} examines contents similarity by comparing input texts with the corresponding regenerated texts. Our framework introduces a paradigm shift in AI text detection by establishing an interpretable pipeline that reveals the underlying step-by-step reasoning process, therefore it enhances both detection robustness and explainability. Through comprehensive experiments comparing these two ~\textbf{Distinguishers}, we demonstrate their respective strengths and limitations, providing new insights into how different text characteristics affect detection performance.



Empirical evaluations demonstrate that both ~\textbf{Distinguishers} significantly surpass baseline methods, with the ~\textit{Regeneration Comparator} outperforming baselines by 9.73\% (F1-score) on in-distribution data and 12.65\% (AUROC) on out-of-distribution (OOD) data. Additionally, the ~\textit{Regeneration Comparator} exhibits better performance than the ~\textit{Prompt-Text Consistency Verifier} on attacked data with 3.78\% (F1-score), and slightly better on OOD data with 0.13\% (F1-score). Furthermore, a user study indicates that IPAD enhances the AI detection experience and trustworthiness by allowing users to directly examine its decision-making evidence, which includes the predicted prompts and regenerated texts, and hence provide transparent and interpretable support for its state-of-the-art detection results. 
%
The code will be available at \url{https://github.com/Bellafc/IPAD-Inver-Prompt-for-AI-Detection-}.
%
% Code is anonymously available \footnote{https://anonymous.4open.science/r/IPAD-Inver-Prompt-for-AI-Detection--65B6/}.