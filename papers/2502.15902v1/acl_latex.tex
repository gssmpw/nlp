% This must be in the first 5 lines to tell arXiv to use pdfLaTeX, which is strongly recommended.
\pdfoutput=1
% In particular, the hyperref package requires pdfLaTeX in order to break URLs across lines.

\documentclass[11pt]{article}

% Change "review" to "final" to generate the final (sometimes called camera-ready) version.
% Change to "preprint" to generate a non-anonymous version with page numbers.
\usepackage[preprint]{acl}

% Standard package includes
\usepackage{times}
\usepackage{latexsym}

% For proper rendering and hyphenation of words containing Latin characters (including in bib files)
\usepackage[T1]{fontenc}
% For Vietnamese characters
% \usepackage[T5]{fontenc}
% See https://www.latex-project.org/help/documentation/encguide.pdf for other character sets

% This assumes your files are encoded as UTF8
\usepackage[utf8]{inputenc}

% This is not strictly necessary, and may be commented out,
% but it will improve the layout of the manuscript,
% and will typically save some space.
\usepackage{microtype}

% This is also not strictly necessary, and may be commented out.
% However, it will improve the aesthetics of text in
% the typewriter font.
\usepackage{inconsolata}

%Including images in your LaTeX document requires adding
%additional package(s)
\usepackage{graphicx}
\usepackage{amsmath}
\usepackage{enumitem}
\usepackage{xcolor}
\usepackage{todonotes}

\usepackage{multirow} 
\usepackage{hyperref}
\usepackage{graphicx}
\usepackage{array}
\usepackage{booktabs}

% If the title and author information does not fit in the area allocated, uncomment the following
%
%\setlength\titlebox{<dim>}
%
% and set <dim> to something 5cm or larger.

\newcommand{\fys}[1]{{\color{orange}{[fys: #1]}}}

\title{IPAD: Inverse Prompt for AI Detection - A Robust and Explainable LLM-Generated Text Detector}

% Author information can be set in various styles:
% For several authors from the same institution:
% \author{Author 1 \and ... \and Author n \\
%         Address line \\ ... \\ Address line}
% if the names do not fit well on one line use
%         Author 1 \\ {\bf Author 2} \\ ... \\ {\bf Author n} \\
% For authors from different institutions:
% \author{Author 1 \\ Address line \\  ... \\ Address line
%         \And  ... \And
%         Author n \\ Address line \\ ... \\ Address line}
% To start a separate ``row'' of authors use \AND, as in
% \author{Author 1 \\ Address line \\  ... \\ Address line
%         \AND
%         Author 2 \\ Address line \\ ... \\ Address line \And
%         Author 3 \\ Address line \\ ... \\ Address line}


\author{%
  \textbf{Zheng Chen\textsuperscript{1}\thanks{Authors contributed equally to this work.}},%
  \textbf{Yushi Feng\textsuperscript{2}\footnotemark[1]},%
  \textbf{Changyang He\textsuperscript{3}},%
  \textbf{Yue Deng\textsuperscript{1}},%
  \textbf{Hongxi Pu\textsuperscript{4}},%
  \textbf{Bo Li\textsuperscript{1}}\\[1ex]
  \textsuperscript{1}Hong Kong University of Science and Technology, Hong Kong\\
  \textsuperscript{2}The University of Hong Kong, Hong Kong\\
  \textsuperscript{3}Max Planck Institute, Germany\\
  \textsuperscript{4}University of Michigan, United States\\[1ex]
  \small{\textbf{Correspondence:} \href{mailto:zchenin@connect.ust.hk}{zchenin@connect.ust.hk}}
}


%\author{
%  \textbf{First Author\textsuperscript{1}},
%  \textbf{Second Author\textsuperscript{1,2}},
%  \textbf{Third T. Author\textsuperscript{1}},
%  \textbf{Fourth Author\textsuperscript{1}},
%\\
%  \textbf{Fifth Author\textsuperscript{1,2}},
%  \textbf{Sixth Author\textsuperscript{1}},
%  \textbf{Seventh Author\textsuperscript{1}},
%  \textbf{Eighth Author \textsuperscript{1,2,3,4}},
%\\
%  \textbf{Ninth Author\textsuperscript{1}},
%  \textbf{Tenth Author\textsuperscript{1}},
%  \textbf{Eleventh E. Author\textsuperscript{1,2,3,4,5}},
%  \textbf{Twelfth Author\textsuperscript{1}},
%\\
%  \textbf{Thirteenth Author\textsuperscript{3}},
%  \textbf{Fourteenth F. Author\textsuperscript{2,4}},
%  \textbf{Fifteenth Author\textsuperscript{1}},
%  \textbf{Sixteenth Author\textsuperscript{1}},
%\\
%  \textbf{Seventeenth S. Author\textsuperscript{4,5}},
%  \textbf{Eighteenth Author\textsuperscript{3,4}},
%  \textbf{Nineteenth N. Author\textsuperscript{2,5}},
%  \textbf{Twentieth Author\textsuperscript{1}}
%\\
%\\
%  \textsuperscript{1}Affiliation 1,
%  \textsuperscript{2}Affiliation 2,
%  \textsuperscript{3}Affiliation 3,
%  \textsuperscript{4}Affiliation 4,
%  \textsuperscript{5}Affiliation 5
%\\
%  \small{
%    \textbf{Correspondence:} \href{mailto:email@domain}{email@domain}
%  }
%}

\begin{document}
\maketitle
\begin{abstract}
Large Language Models (LLMs) have attained human-level fluency in text generation, which complicates the distinguishing between human-written and LLM-generated texts. This increases the risk of misuse and highlights the need for reliable detectors. Yet, existing detectors exhibit poor robustness on out-of-distribution (OOD) data and attacked data, which is critical for real-world scenarios. Also, they struggle to provide explainable evidence to support their decisions, thus undermining the reliability. In light of these challenges, we propose ~\textbf{IPAD (Inverse Prompt for AI Detection)}, a novel framework consisting of a ~\textbf{Prompt Inverter} that identifies predicted prompts that could have generated the input text, and a ~\textbf{Distinguisher} that examines how well the input texts align with the predicted prompts. We develop and examine two versions of ~\textbf{Distinguishers}. Empirical evaluations demonstrate that both ~\textbf{Distinguishers} perform significantly better than the baseline methods, with version2 outperforming baselines by 9.73\% on in-distribution data (F1-score) and 12.65\% on OOD data (AUROC). Furthermore, a user study is conducted to illustrate that IPAD enhances the AI detection trustworthiness by allowing users to directly examine the decision-making evidence, which provides interpretable support for its state-of-the-art detection results.


%: the ~\textit{Prompt-Text Consistency Verifier} that verifies whether the predicted prompt could plausibly generate the input text, and the ~\textit{Regeneration Comparator} that evaluates the similarity between the regenerated texts and the input texts. 

% a novel framework for detecting AI-generated text by identifying the most likely prompts that could have produced it. IPAD experiments in two settings: \textbf{Setting1} verifies whether the predicted prompt could plausibly generate the input text, and \textbf{Setting2} further assesses the similarity between the re-generated texts and the input texts. Empirical evaluations demonstrate that both settings significantly surpass baseline detectors, with Setting2 outperforming baselines by 11.3\% on in-distribution data and 12.65\% on out-of-distribution (ood) data. Additionally, Setting2 exhibits superior robustness on ood data and attacked data. These results highlight the enhanced reliability, robustness, and explainability of IPAD. Furthermore, a user study indicates that IPAD enhances the AI detection experience by providing more explainable and reliable results.
%也许太长不放在abstract里. If the result is affirmative, it suggests that the possible prompt is likely to have generated the user input, implying that the content is probably AI-generated. Conversely, if the result is negative, it indicates that even the most probable prompt cannot generate the user input, suggesting that it is most likely human-written.
%说AI DETECTOR还是LLM DETECTOR也许还要斟酌一下。

\end{abstract}

\section{Introduction}\label{sec:Introduction}
\input{sections/01-intro.tex}
\section{Methodology}\label{sec:Method}
\input{sections/03-Method.tex}
\section{Experiments}\label{sec:Evaluation}
\input{sections/04-Evaluation.tex}
\section{Related Work}\label{sec:Related Work}
\input{sections/02-related_work.tex}
\section{Conclusion}\label{sec:Conclusion}
\input{sections/05-Conclusion.tex}
\section{Limitations}\label{sec:Limitation}
\input{sections/06-Limitation}



\section*{Acknowledgments}

% Bibliography entries for the entire Anthology, followed by custom entries
%\bibliography{anthology,custom}
% Custom bibliography entries only
\bibliography{custom}

\appendix
\section{AUROC formula}
\label{sec:AUROC formula}
Since our model predicts binary labels, we follow the ~\textit{Wilcoxon-Mann-Whitney} statistic~\cite{r56} to calculate the Area Under Receiver Operating Characteristtic curve (AUROC):

\[
\text{AUC}(f) = \frac{\sum_{t_0 \in \mathcal{D}^0} \sum_{t_1 \in \mathcal{D}^1} \mathbf{1}[f(t_0) < f(t_1)]}{|\mathcal{D}^0| \cdot |\mathcal{D}^1|}
\]

where \( \mathbf{1}[f(t_0) < f(t_1)] \) denotes an indicator function which returns 1 if \( f(t_0) < f(t_1) \) and 0 otherwise. \( \mathcal{D}^0 \) is the set of negative examples, and \( \mathcal{D}^1 \) is the set of positive examples.

\section{Calculation of Summary Statistics}
\label{Calculation}
\begin{itemize}

\item[$\bullet$] IPAD with ~\textit{Regeneration Comparator} outperforms the baselines by 9.73\% on in-distribution data. As shown in Table~\ref{tab:performance_metrics_detection}, RoBERTa-base has the best average F1 score of (92.9\% + 92.8\% + 91.3\% + 78.9\%) / 4. In comparison, the average F1 score for IPAD version 2 is (99.85\% + 98.5\% + 97.6\% + 98.86\%) / 4, showing an improvement of 9.73\%.

\item[$\bullet$] IPAD with ~\textit{Regeneration Comparator} outperforms the baselines by 12.65\% on in-distribution data. As shown in Table~\ref{tab:OOD_performance}, RoBERTa-base achieves the highest average AUROC score, but since the F1-score is not available for the baseline, we use the AUROC difference to calculate the improvement, which is (95.65\% - 83\%) = 12.65\%.

\item[$\bullet$] IPAD with ~\textit{Regeneration Comparator} outperforms IPAD with ~\textit{Prompt-Text Consistency Verifier} by 0.13\% on out-of-distribution (OOD) data. As shown in Table~\ref{tab:OOD_performance}, IPAD version 2 has the highest AUROC of 95.65\%, while IPAD version 1 has an AUROC of 95.52\%, resulting in a 0.13\% difference.

\item[$\bullet$] IPAD with ~\textit{Regeneration Comparator} outperforms IPAD with ~\textit{Prompt-Text Consistency Verifier} by 3.78\% on attacked data. As shown in Table~\ref{tab:performance_metrics_detection} (rows 3-4) and Table~\ref{tab:OOD_performance} (rows 6-8), IPAD version 2 achieves the best F1 score and AUROC scores. To calculate the overall attacked dataset score, we calculate the F1 scores for Table~\ref{tab:OOD_performance}: 94.82\%, 95.35\%, 95.31\% for IPAD version 2, and 83.58\%, 88.34\%, and 94.70\% for IPAD version 1. The average F1 score difference is thus (94.82\% + 95.35\% + 95.31\% - 83.58\% - 88.34\% - 94.70\% + 97.60\% + 98.86\% - 97.55\% - 98.85\%) / 5 = 3.78\%.

\end{itemize}


\section{DPIC (decouple prompt and intrinsic characteristics) Prompt Extraction Zero-shot Prompts}
\label{sec:DPIC prompt}
~\textit{"I want you to play the role of the questioner. I will type an answer in English, and you will ask me a question based on the answer in the same language. Don’t write any explanations or other text, just give me the question. <TEXT>."}. 


\section{Linguistic Difference Examples}
\label{sec:Linguistic Difference Examples}
Figure ~\ref{fig:sentence complexity} shows examples where HWT and LGT prompts with different sentence complexity. Figure ~\ref{fig:comparison} shows the results of analytical thinking level statistics. Figure ~\ref{fig:person} shows examples of using different personas and different analytical thinking levels.

% \begin{figure}[t]
%   \centering
%   \includegraphics[width=0.5\textwidth]{concept scope.png}
%   \caption{Concept Scope Examples}
%   \label{fig:concept scope}
% \end{figure}


\begin{figure}[t]
  \centering
  \includegraphics[width=0.5\textwidth]{sentence_complexity.png}
  \caption{Sentence Complexity Examples, where ~\textbf{HWT Prompt} stands for prompt generated by the Prompt Inverter from HWT, and ~\textbf{LGT Prompt} stands for prompt generated by the Prompt Inverter from LGT. The HWT Prompts have longer sentence lengths, more words with more than three syllabus (as shown in bold), and more stop-words (as shown with underline).}
  \label{fig:sentence complexity}
\end{figure}


\begin{figure}[t]
  \centering
  \includegraphics[width=0.5\textwidth]{comparison.png}
  \caption{Comparison of different analytical thinking levels, with LGT has higher percentage of level 4 and level 5.}
  \label{fig:comparison}
\end{figure}

\begin{figure}[t]
  \centering
  \includegraphics[width=0.5\textwidth]{person.png}
  \caption{Examples that use different persona usage (above), and different analytical thinking levels (below left has level 2, and below right has level 5, they are prompts generated by the same problem statements).}
  \label{fig:person}
\end{figure}

\section{User Study}
Figure ~\ref{fig:gptzero}~\ref{fig:quillbot} and ~\ref{fig:scribbr} shows the screenshots of online AI detectors. Figure ~\ref{fig:questionnaire} shows the questionnaire questions. Figure ~\ref{fig:guide} shows the user guide.
\label{User study}
\subsection{Online AI Detectors Screenshots}


\begin{figure}[t]
  \centering
  \includegraphics[width=0.5\textwidth]{gptzero.png}
  \caption{GPTZero Online Detector Screenshot}
  \label{fig:gptzero}
\end{figure}

\begin{figure}[t]
  \centering
  \includegraphics[width=0.5\textwidth]{quillbot.png}
  \caption{Quillbot Online Detector Screenshot}
  \label{fig:quillbot}
\end{figure}

\begin{figure}[t]
  \centering
  \includegraphics[width=0.5\textwidth]{scribbr.png}
  \caption{Scribbr Online Detector Screenshot}
  \label{fig:scribbr}
\end{figure}

\subsection{Questionnaire questions}
\begin{figure}[t]
  \centering
  \includegraphics[width=0.5\textwidth]{questionnaire.png}
  \caption{Questionnaire questions}
  \label{fig:questionnaire}
\end{figure}


\begin{figure}[t]
  \centering
  \includegraphics[width=0.5\textwidth]{IRB.png}
  \caption{User Study User guide}
  \label{fig:guide}
\end{figure}
\end{document}
