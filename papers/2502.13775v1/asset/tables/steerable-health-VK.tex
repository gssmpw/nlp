\begin{table*}[!htp]\centering
\scriptsize
\resizebox{.95\linewidth}{!}{
\begin{tabular}{
l@{\hspace{5pt}}c@{\hspace{5pt}}c@{\hspace{5pt}}c@{\hspace{5pt}}c@{\hspace{5pt}}c@{\hspace{5pt}}c@{\hspace{5pt}}c@{\hspace{5pt}}c@{}}\toprule[1.5pt]
& \textbf{\texttt{LLaMA2}} & \textbf{\texttt{Gemma}} & \textbf{\texttt{Qwen2.5}} & \textbf{\texttt{LLaMA3}} & \textbf{\texttt{LLaMA2}} & \textbf{\texttt{Qwen2.5}} & \textbf{\texttt{LLaMA2}} & \multirow{2}{*}{\textbf{\texttt{ChatGPT}}} \\
& \textbf{\texttt{7B}} & \textbf{\texttt{7B}} & \textbf{\texttt{7B}} & \textbf{\texttt{8B}} & \textbf{\texttt{13B}} & \textbf{\texttt{14B}} & \textbf{\texttt{70B}} & {} \\
\midrule

Unaligned LLM & \textbf{47.32} & \textbf{57.12} & \textbf{69.10} & 43.56 & 18.92 & \textbf{73.47} & \textbf{42.56} & 46.47 \\
\ \ w/ Prompting & 19.64 & \underline{56.27} & \underline{67.57} & 47.06 & 1.82 & 70.64 & \underline{37.88} & 44.24 \\
\ \ w/ \moe & 41.07 & 41.75 & 49.00 & 40.65 & \underline{37.74} & 53.97 & 35.86 & 40.34 \\
\ \ w/ \modplural & \underline{43.22} & 39.72 & 45.26 & 38.64 & \textbf{39.18} & 48.23 & 35.59 & 39.42 \\
\midrule
Aligned LLM & 34.33 & 48.54 & 66.68 & \underline{67.71} & 19.80 & \underline{72.11} & 30.46 & \underline{65.60} \\
\ \ w/ Prompting & 34.24 & 37.59 & 63.58 & \textbf{68.18} & 27.56 & 71.96 & 29.48 & \textbf{69.79} \\
\ \ w/ \moe & 35.48 & 41.74 & 50.64 & 45.53 & 35.23 & 49.99 & 34.37 & 44.90 \\
\ \ w/ \modplural & 34.92 & 42.03 & 49.87 & 41.78 & 35.07 & 58.22 & 34.10 & 47.00 \\
\bottomrule[1.5pt]
\end{tabular}
}
\caption{Results of LLMs for \steerable mode in \ourdataset specifically for value situations, in accuracy ($\uparrow$ better). Refer \reffig{fig:steerable-main} for overall \steerable results. The best and second-best performers are represented in \textbf{bold} and \underline{underline}, respectively.}
\label{table:steerable-vk}
\end{table*}
