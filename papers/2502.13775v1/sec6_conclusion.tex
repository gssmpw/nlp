\section{Conclusion}



In this work, we investigate the LLM's potential to reflect diverse values and opinions (\aka pluralistic alignment), specifically within the health domain. The first step in improving the health AI systems is to evaluate how current solutions can model pluralistic views. We introduce a dedicated benchmark dataset, \ourdataset, focusing on health, derived carefully from a mix of value-laden and multiple-choice question corpora. Now, such a benchmark will help before deploying in the health and evaluating if it is safe. With this benchmark, we argue and provide empirical evidence that current alignment techniques may be limited (not \textit{representative}) for pluralistic AI in the health domain, motivating the need for health-specific alignment techniques.


\section*{Limitations}
It is important to note that \modplural represents a general solution and does not specifically include health-related aspects—a focus that future studies should consider based on our findings.
Regarding the comprehensiveness of \ourdataset, while we strive to include as many perspectives and values as possible in our benchmark, it is infeasible to encompass all principles and values. In the future, we will incorporate a broader range of perspectives to make the framework more holistic. For now, we release this smaller benchmark for the community to evaluate the alignment of the LLMs being deployed actively in the health domain. We plan to augment and expand this benchmark with more samples and other modalities, making it more comprehensive. Furthermore, we only benchmarked for the English datasets; in the future, we plan to expand this benchmark with multi-linguality.


\section*{Ethics Statement}
To construct the \ourdataset dataset, we have leveraged a diverse range of existing datasets, which are central to our analysis of pluralistic alignment in health. Our use of these datasets adheres to accepted ethical standards and serves its intended purpose. Additionally, we acknowledge the potential risk of perpetuating stereotypes despite our efforts to enhance health alignment and reduce biases in LLMs. We will make \ourdataset openly available to further research in pluralistic alignment for health, NLP, and AI. \ourdataset is intended solely for research purposes and does not reflect the views of the authors. Through this benchmark dataset, we hope to promote a pluralistic, inclusive, and equitable representation of health viewpoints while consistently addressing biases to improve fairness.

\section*{Acknowledgements}
This research was supported by the Macquarie University Research Acceleration Scheme (MQRAS) and Data Horizon funding.
This research was supported by The University of Melbourne’s Research Computing Services and the Petascale Campus Initiative.
We also thank Mohammad Arham and Mahdi Khoursha for their support in data annotation and analysis.
