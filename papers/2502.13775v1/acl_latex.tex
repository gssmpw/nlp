\pdfoutput=1

\documentclass[11pt]{article}

\usepackage[preprint]{acl}

\input{math_commands}

\input{def}

\usepackage{times}
\usepackage{latexsym}
\usepackage{enumitem}
\usepackage[T1]{fontenc}

\usepackage[utf8]{inputenc}

\usepackage{microtype}

\usepackage{inconsolata}

\usepackage{graphicx}


\title{\ourdataset: A New Dataset for Benchmarking Pluralistic~Alignment~in~Healthcare}


\author{
  Anudeex Shetty$^{\diamondsuit,\clubsuit}$, Amin Beheshti$^{\clubsuit}$, Mark Dras$^{\clubsuit}$, Usman Naseem$^{\clubsuit}$ \\
  $^\diamondsuit${School of Computing and Information System, the University of Melbourne, Australia} \\
  $^\clubsuit${School of Computing, FSE, Macquarie University, Australia} \\
  {\tt\{anudeex.shetty,amin.beheshti,mark.dras,usman.naseem\}@mq.edu.au}
}


\begin{document}
\maketitle
\begin{abstract}



Alignment techniques have become central to ensuring that Large Language Models (LLMs) generate outputs consistent with human values. However, existing alignment paradigms often model an averaged or monolithic preference, failing to account for the diversity of perspectives across cultures, demographics, and communities. This limitation is particularly critical in health-related scenarios, where plurality is essential due to the influence of culture, religion, personal values, and conflicting opinions. Despite progress in pluralistic alignment, no prior work has focused on health, likely due to the unavailability of publicly available datasets. To address this gap, we introduce \ourdataset, a new benchmark dataset comprising 13.1K value-laden situations and 5.4K multiple-choice questions focused on health, designed to assess and benchmark pluralistic alignment methodologies. Through extensive evaluation of eight LLMs of varying sizes, we demonstrate that existing pluralistic alignment techniques fall short in effectively accommodating diverse healthcare beliefs, underscoring the need for tailored AI alignment in specific domains. This work highlights the limitations of current approaches and lays the groundwork for developing health-specific alignment solutions.\footnote{We will release our data and code post-acceptance.}

\end{abstract}















































\input{sec1_intro}
\input{sec2_related_work}
\input{sec3_method}
\input{sec4_experiment}
\input{sec6_conclusion}

\bibliography{custom}

\clearpage
\appendix
\input{sec7_supp}

\end{document}
