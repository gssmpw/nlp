
\section{Background and Related Work}
\paragraph{LLM Alignment.} Alignment techniques have been fundamental to the success of LLMs \citep{wang2023aligning}. Initial alignment methods involved reward models informed by human preferences and feedback \citep{schulman2017proximal,christiano2017deep,stiennon2020learning}. Subsequent research has introduced several enhancements to these methods \citep{ouyang2022training,rafailov2024direct,xia-etal-2024-aligning}. However, such techniques are prone to aligning with average human preferences. 

\paragraph{Pluralistic Alignment.} Recognising the diversity of human values and preferences, \citet{positionpluralistic} proposed a framework for pluralistic alignment to address these limitations. They defined three modes of pluralism in AI systems. \reffig{fig:vital-alignment-overview} illustrates these modes: \overton should encompass all diverse values and perspectives; \steerable should represent a specific value or attribute as defined in a user query; \distributional focused on matching underlying real-world population distributions (see \refapp{app:plural-alignment-modes} for more details). Later work by \citet{feng2024modular} introduced, \modplural, a multi-LLM collaboration technique between \textit{main} and \textit{community} LLMs. While this demonstrated overall improvements, its performance in the health domain remains unexamined. Although some studies evaluate pluralistic alignment in various contexts \citep{liu-etal-2024-evaluating-moral,benkler2023assessing,huang2024flames} or within specific alignment modes \citep{lake2024from,meister2024benchmarking}, none holistically assess all three pluralistic modes for healthcare. Prior research suggests that LLMs require domain-specific solutions \citep{zhao2023survey}. With the growing use of LLMs in healthcare \citep{yang_large_nodate,thirunavukarasu2023large}, it is critical to benchmark and evaluate LLMs for pluralistic alignment in this domain.

\input{asset/tables/datasets-lit-review}

\paragraph{Existing Datasets.} For such evaluations, a suitable dataset is necessary for benchmarking. \reftab{table:dataset-lit-review}, provides a non-exhaustive overview of existing alignment datasets, revealing a scarcity of pluralistic datasets with none focused solely on health. To address this gap, we introduce \ourdataset, a health-focused pluralistic alignment  dataset.

