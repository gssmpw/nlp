\section{Atlas Framework}\label{sec:framework}

\atlas introduces two core components to the ML lifecycle:
\begin{enumerate*}[label=\arabic*)]
    \item the transparency service interacting with MLaaS providers;
    \item the verification service that model users and verifiers use to verify integrity and provenance.
\end{enumerate*}
Fig.~\ref{fig:atlas-arch} depicts an example ML model lifecycle with \atlas.

\begin{figure}[t]
    \centering
    \includegraphics[width=\columnwidth]{./img/atlas-arch.pdf}
    \caption{
	        Example ML lifecycle with \atlas.
	        Striped boxes and bolded arrows represent \atlas components and data flows.
	        MLaaS providers obtain model artifacts (datasets or models) and perform transformations on them.
	        \atlas attestation clients generate and submit digitally signed artifact and transformation metadata to a transparency log.
	        Model users commonly delegate model provenance checking to an \atlas verifier.
	    }
    \label{fig:atlas-arch}
\end{figure}

\subsection{Transparency Service}\label{sec:framework:transparency}

To provide transparency across stages of the ML lifecycle, MLaaS providers
integrate an \atlas attestation client in their system.
The transparency log makes all attestation clients' collected metadata available
to verifiers.
The four core techniques underlying the \atlas transparency service are designed
to be general, allowing them to remain agnostic to the particular ML lifecycle
stage or pipeline they are applied to (\textbf{R6}).

\subsubsection{Artifact Measurements}\label{sec:framework:transparency:artifact}

The \atlas attestation client within an MLaaS provider cryptographically
measures every artifact ingested into and output by an ML pipeline.
That is, we use a collision resistant cryptographic hash function to compute
unique, immutable measurement values for every artifact.
Because any changes to a given artifact result in a different hash value, \atlas
verifiers wishing to check whether a given model artifact matches their
expectation are able to detect tampering between stages of the lifecyle (\textbf{R1}).

\subsubsection{Model Transformation Integrity}\label{sec:framework:transparency:transformation}

In addition to capturing measurements about all inputs and outputs of an ML
pipeline, the \atlas attestation client continuously verifies new inputs and
monitors an ML system's execution to collect detailed information about pipeline
state and operations that transform the input artifacts.
That is, during data processing, the client tracks dataset modifications and
preprocessing operations; during model training, \atlas captures state changes
in model weights, hyperparameters, and configurations.

To enhance the integrity of the ML artifacts and system at runtime,
\atlas runs ML pipeline code within trusted execution environments (TEEs) (e.g.,
Intel TDX~\cite{tdx} or AMD SEV-SNP~\cite{amd-sev}), which serve as a hardware-based
root of trust for ML system component measurements extending from its hardware
to the firmware and software.

These measures allow the \atlas attestation client to verify the integrity
and authenticity of the compute environment before beginning the execution of
the pipeline.
Throughout execution, the TEE maintains isolated memory regions, reducing the
risk of interference with the pipeline, as well as unauthorized disclosure
of artifacts and pipeline code, by a compromised MLaaS provider
(\textbf{R4} \& \textbf{R5}).

At the conclusion of an operation in a given pipeline, the client generates a
record with all collected ML system information, and digitally signs it with a
TEE-generated key along with all artifact measurements, providing a model
\emph{transformation attestation} (\textbf{R2}).
If required by the artifact producer, \atlas may encrypt the produced model
artifacts prior to digitally signing and uploading them to a given hub to
further enhance artifact authenticity and confidentiality while in transit and
at rest (\textbf{R1} \& \textbf{R5}).

%\subsubsection{Security Components}
%Our security architecture implements custom operators for metadata generation and verification,
%coupled with integrity verification controllers that continuously monitor pipeline execution.
%The system employs transparent logging middleware to track all operations, while hardware-backed
%attestation services integrate directly with the pipeline stages. These components work together to enable
%security-enhanced workflow execution where each stage's artifacts are automatically signed and verified.

\subsubsection{Provenance Chains}\label{sec:framework:transparency:provenance}

To allow verifiers to trace an ML model throughout all of its lifecycle stages
from data preparation to deployment, \atlas embeds the cryptographic hash of the
transformation attestation for every pipeline input that passed verification
into the output attestation.
These hash values are digitally signed as part of the transformation
attestation.
Thus, \atlas attestation clients establish an authenticated, cryptographically
verifiable \emph{provenance chain} representing a model's lineage relationships
throughout its lifecycle (\textbf{R3}).

%Each ML artifact -- whether model weights, training data, or configuration -- receives a C2PA manifest
%containing cryptographic measurements, hardware-backed TDX attestation hashes, digital signatures,
%and temporal information about its creation and modifications.
%The system establishes clear ingredient relationships between artifacts, where training data becomes an
%ingredient of model checkpoints, checkpoints link to the final model, and configuration files maintain connections
%to their respective training runs.
%\begin{figure}[h]
%	\centering
%	\includegraphics[width=0.5\textwidth]{img/hf-sidecar.drawio}
%	\caption{Metadata Management System Architecture showing how ML pipeline integrity is maintained: A sidecar container runs alongside the main workload container to measure and verify artifacts (model weights, training data, configurations).
%		The sidecar generates cryptographic measurements and attestation data for each artifact, which are verified by a metadata verifier before being stored in both a transparency log and artifact repository.
%		This ensures continuous validation of ML pipeline components while maintaining a verifiable audit trail.}
%	\label{fig:metadata-sidecar}
%\end{figure}

\subsubsection{Transparency Log}\label{sec:framework:transparency:log}

% The text below attempts to actually define the properties
% we want from the log from a design standpoint (not implementation). What is the
% internal structure of the Merkle tree (BST vs append-only)? How do trees map to
% different pipelines (1:1, n:1)? How do we manage multiple cycles of a lifecycle?
% if it's way off, let's discuss!

On the server side, a \emph{transparency log} contains the golden values (i.e.,
known good values) of a producer's model artifacts, an MLaaS provider's system
components, and the transformation attestations collected by the clients
throughout the ML lifecycle.
To enable efficient insertion and provenance verification while
accommodating the cyclical nature of the ML lifecycle, \atlas relies on two
data structures.

First, to provide cryptographic tamper-evidence for the stored values, the
transparency log is constructed using an \emph{append-only} Merkle tree~\cite{merkle-tree1987},
meaning that pipeline metadata can be efficiently inserted in the right-most
empty leaf node of the tree (e.g., as in~\cite{sigstore2025}).
Second, to enable more efficient verification of provenance \emph{across}
pipelines (or even cycles of the ML lifecycle), \atlas can represent each discreet
pipeline/cycle using a different Merkle tree and \emph{chain} the trees by
embedding the Merkle root hash of the upstream pipeline or previous cycle into
the ``current'' Merkle tree's root (e.g., as in~\cite{coniks2015}), limiting tree
traversal operations when verifying a lifecycle over time (\textbf{R7}).

We note that the choice of whether and how to partition the transparency log's
Merkle trees will result in different security and performance tradeoffs;
depending on the party that operates the transparency service in
practice, they may favor maintaining a smaller or larger number of trees
according to their specific metadata access control and resource requirements.
%providing cryptographic proof of the complete model lineage at any point in time.
%This relationship structure creates a verifiable lineage chain where each
%Ingredients maintain secure links to their source manifests, enabling validation of the complete
%artifact chain from any point to verify authenticity.
%The sidecar container implementing this tracking
%system continuously monitors the ML pipeline for new or modified artifacts, generating manifests and updating relationship maps as transformations occur.
%
%Our extension implements comprehensive validation layers handling manifest verification,
%attestation validation, and integrity checks. The immutable storage layer preserves both ML pipeline artifacts
%and detailed pipeline history, including transformation records, version control, and attestation chains.

\subsection{Verification System}\label{sec:framework:verification}

The \atlas verification system performs staged verification.
When a pipeline ingests an input artifact, the attestation client requests
the artifact's verification at the verification service, interacting
with the transparency log to obtain the golden values and provenance
information.

First, the verification service validates that the received metadata was
produced by the expected parties via their digital signatures, and checks
whether the artifact matches the expected golden value measurements.
If the first verification stage passes, \atlas inspects the received
transformation metadata to confirm the recorded ML system and
pipeline operations ran as expected based on their TEE-backed attestations.
Third, the artifact's lineage is validated by tracing its provenance chain
to check its transformations as far back as specified in the verifier's policy.

To enable efficient batch verification of input artifacts, \atlas
groups related artifacts including training datasets,
model weights, algorithm implementations, and evaluation results.
By maintaining a cache of verified states and an incremental verification flow,
the system avoids re-computing cryptographic operations for unchanged artifacts
(\textbf{R7}).
This particularly benefits ML pipelines where only small portions of the
workflow change between iterations.

%Third, the Metadata \& Artifact Integrity layer validates relationships between pipeline components.
%The validated data is then stored in two parallel tracks: (1) ML Pipeline Artifacts storing training data, model checkpoints, and validation results, and (2) Pipeline History maintaining transformation records and dependency tracking. This approach ensures comprehensive verification of both the ML artifacts and their complete lineage.

%First, the certificate chain of the signing keys for each transformation attestation
%is verified to establish trust in the signing authorities.
%
%Next, hash verification aims to detect modifications to model artifacts via their measurements.
%Third, the transformation attestation is validated against the verifier's expectations about a given pipeline's operation.
%Finally, relationship validation checks for inconsistencies across component dependencies and versions.

%\begin{figure}[h]
%	\centering
%	\includegraphics[width=0.5\textwidth]{img/hf-validation-layer.drawio}
%	\caption{Multi-layered validation architecture for ML pipeline integrity: The system implements three validation stages before storing ML artifacts.}
%	\label{fig:rekor-extension}
%\end{figure}

%The framework maintains verification state to track validated components and their relationships.
%When verification failures occur, the system defines policies for invalidating affected components while
%preserving verified states.
%Error handling includes mechanisms for detailed forensic logging.
