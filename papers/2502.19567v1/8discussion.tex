\section{Discussion and Conclusion}\label{sec:discussion}
%Detailed adoption considerations and future directions are discussed in App.~\ref{sec:appendix:discussion} and App.~\ref{sec:appendix:future}, respectively.

% condensed / maybe not too much
Our implementation and evaluation reveal several key considerations for practical deployment ML pipeline security.
Organizations must balance security requirements with operational efficiency, considering factors like verification
frequency, attestation depth, and computational overhead.
\atlas' modular design enables customization of these tradeoffs while maintaining core security guarantees.

%\subsection{Implementation Considerations}\label{sec:discussion:impl}
Current hardware security architectures present integration challenges, particularly around GPU and accelerator attestation support.
While \atlas provides secure boundaries for CPU-GPU data transfers,
emerging technologies like confidential GPU computing will enable more comprehensive coverage.
Integration with legacy HPC systems also requires careful consideration, as traditional
job schedulers often lack modern observability capabilities needed for fine-grained monitoring and attestation.

\section{Adoption Considerations}\label{sec:discussion:adoption} 
\subsection{Storage Optimizations}\label{sec:discussion:adoption:storage}
% mvd frm sec 8 - Storage Considerations
\subsubsection{Storage and Scalability}\label{sec:discussion:adoption:storage:scalability}
Our analysis suggests opportunities for optimizing manifest storage through decomposed and hybrid architectures. Rather than 
storing complete manifests as single documents, separating components like assertions, signatures, and metadata could improve 
efficiency while maintaining security guarantees. Organizations should consider distributed storage strategies that balance 
immutability requirements with query performance needs.

\subsubsection{Decomposed Storage Model}\label{sec:discussion:adoption:storage:decomposed}
Instead of storing complete manifests as single documents, the system could decompose manifests into their constituent components.
The assertion store, claim signatures, and metadata could be stored separately, with relationships maintained through a reference system.
This approach would enable more efficient updates and queries of specific manifest components.

The decomposed model could leverage distributed ledger technology (DLT)~\cite{geeksforgeeks2023dlt} for critical manifest components
while maintaining bulk data in optimized storage systems.
This hybrid approach would:
\begin{itemize}
\item Store cryptographic proofs and signatures on the distributed ledger for immutability
\item Maintain manifest metadata and relationships in graph databases for efficient querying
\item Use object storage for large artifacts like model weights and datasets
\item Link components through cryptographic references preserved in the ledger
\end{itemize}

\subsubsection{Hybrid Storage Architecture}\label{sec:discussion:adoption:storage:hybrid}
A hybrid approach could maintain critical verification data in Rekor for its transparency guarantees
while storing detailed manifest data in optimized storage systems.
This would balance the need for immutable proof of existence with efficient data access and management.

These storage optimizations could significantly reduce operational overhead while maintaining the security guarantees of our framework.
Performance testing indicates potential reduction in storage requirements and query latency through these alternative approaches.

\subsection{Deployment Guidelines}\label{sec:discussion:adoption:deployment}
% mvd frm sec 8 - Organization-specific Adaptations and Deployment Considerations
\subsubsection{Organizational Adaptations}\label{sec:discussion:adoption:deployment:org}
Organization-specific adaptations are necessary to align with existing infrastructure and security policies.
Key considerations include:
\begin{itemize}
   \item Integration with current MLOps platforms
   \item Alignment with existing security monitoring systems
   \item Customization of verification policies
   \item Adaptation to specific hardware security capabilities
   \item Compliance with organizational security standards
\end{itemize}

\subsubsection{Security Requirement Balance}\label{sec:discussion:adoption:deployment:security}
Security requirement balance directly impacts operational efficiency.
Organizations must determine appropriate verification frequencies and depth based on their risk profile and performance requirements.
For instance, continuous hardware attestation of all pipeline components provides maximum security but introduces significant overhead.
A more balanced approach might implement full verification at critical pipeline stages while using lightweight checks during intermediate steps.

\subsubsection{Computational Overhead Management}\label{sec:discussion:adoption:deployment:overhead}
Computational overhead management becomes crucial when scaling the framework across large ML operations.
Our implementation shows that intelligent caching of verification results and batch processing of integrity checks can significantly reduce overhead.
Organizations should consider:
\begin{itemize}
    \item Strategic placement of verification checkpoints - Organizations can tailor verification intensity based on their specific security needs and operational context. While financial or healthcare institutions might require comprehensive verification throughout their ML pipeline, research or development environments might focus verification efforts primarily on model publication or deployment stages. This flexible approach enables efficient resource utilization while maintaining appropriate security levels for each use case.
    \item Optimization of hardware attestation frequency - By analyzing pipeline characteristics and risk patterns, attestation frequency can be tuned to concentrate on high-risk operations while reducing overhead during stable processing phases.
    \item Efficient manifest storage and retrieval mechanisms - The system maintains an indexed store of manifests with hierarchical organization, enabling quick validation of model lineage while managing storage overhead for long-term provenance tracking. 
    \item Parallel verification processing where possible - This approach utilizes available computational resources effectively by running verification operations concurrently when component dependencies allow.
\end{itemize}

\section{Future Work}\label{sec:discussion:future}
% mvd frm sec 8.B - Future Improvements
%\subsection{Framework Extensions}\label{sec:appendix:future:extensions}
Several potential enhancements could extend our framework's capabilities and applicability:

\Paragraph{Distributed Training Support.}\label{sec:discussion:future:distributed}
The current framework could be enhanced to handle multiple TEEs coordinating across training nodes, with cross-node attestation
and verification protocols. This would require developing protocols for maintaining integrity across distributed components
while managing the additional complexity of verifying inter-node communications and state synchronization~\cite{menetrey2022attestation}.

\Paragraph{Federated Learning Compatibility.}\label{sec:discussion:future:federated}
Our current framework could be extended to support federated learning environments,
particularly through integration with Intel's OpenFL (Open Federated Learning)~\cite{wei2020federated} framework.
OpenFL's architecture, which separates aggregator and participant nodes while maintaining model security,
presents unique opportunities and challenges for provenance tracking. The framework would need to extend its attestation and
verification protocols to handle distributed model updates while preserving the privacy guarantees inherent in federated learning.

Key considerations include tracking model aggregation operations, verifying participant contributions,
and maintaining cryptographic proofs across federation rounds. OpenFL's existing security features, including
its support for secure aggregation and TEE integration, provide natural integration points for our provenance framework.
The challenge lies in extending our verification protocols to handle the partial model updates and differential privacy
mechanisms~\cite{foley2022openfl} common in federated learning scenarios.

\Paragraph{Enhanced Scalability Features.}\label{sec:discussion:future:scalability}
Support for more complex ML architectures, particularly for multi-model systems and ensemble methods,
would expand the framework's utility. This would require developing verification protocols for model composition and
interaction, tracking dependencies between component models, and maintaining provenance across model combinations\cite{zheng2020decent}.

The framework could also be extended to support dynamic trust models, allowing for flexible trust relationships between
different components and participants in the ML pipeline.

\Paragraph{Algorithmic Security Enhancements.}\label{sec:discussion:future:algorithmic}
Our framework's modular design allows for integration of additional algorithmic security methods to enhance pipeline protection.
Model watermarking techniques~\cite{regazzoni2021survey, boenisch2021watermarking} could be incorporated to embed verifiable ownership proofs directly into model weights,
providing an additional layer of provenance verification.
These watermarks would be included in the manifest chain, creating cryptographically verifiable links between model
versions and their origins.

\Paragraph{Verification Protocol Extensions.}\label{sec:discussion:future:verification}
Our staged verification system could be extended to support dynamic trust models.
This would allow more flexible verification policies based on component criticality and risk levels, while maintaining our core
security guarantees. The current implementation's classification system provides a foundation for such policy-based verification.

Neural fingerprinting~\cite{cao2023fingerprinting, regazzoni2021survey} methods could extend our verification capabilities by enabling detection of unauthorized model modifications or derivatives.
By maintaining fingerprint signatures in our provenance records, the framework could track model lineage even when traditional hash-based verification is insufficient.
This is particularly valuable for scenarios involving fine-tuning or transfer learning.

Property attestation mechanisms could verify specific algorithmic characteristics of models throughout the pipeline. For example,
robustness guarantees~\cite{benbraiek2024robustness}, fairness metrics~\cite{liang2023fairness}, or backdoor resistance~\cite{bagdasaryan2023mithridates} could be measured and included in the manifest chain.
These properties would enhance the framework's ability to detect subtle manipulations that might not affect model
hashes but could impact model behavior.
% mvd to EVALUATION SECTION
%\subsection{Framework Limitations}\label{sec:discussion:framework_limitation}
%Current limitations include:
%\begin{itemize}
%    \item \textbf{Hardware security feature dependencies} While GPUs are essential for efficient ML training and inference,
%    current hardware security architectures do not provide native attestation support for GPU computations~\cite{intel2024tdx}.
%    Similar limitations exist for TPUs and other specialized ML accelerators.
%    This requires additional security boundaries when data moves between the CPU's
%    trusted execution environment and these accelerator components. Several technologies could address these
%    limitations in future iterations. Bounce buffers provide one potential solution for securing data transfers
%    between trusted and untrusted components. This approach would enable secure data movement between the TEE and accelerators,
%    though with some performance overhead. Other emerging technologies, such as confidential GPU computing and secure I/O paths,
%    are being developed by hardware vendors (e.g, Intel, NVIDIA)~\cite{intel2024tdx}. As these technologies mature and hardware attestation capabilities
%    expand to cover accelerators, our framework could be extended to provide comprehensive security coverage across all compute resources.
%
%    \item \textbf{Integration complexity with legacy systems} Integration complexity with legacy systems presents significant challenges,
%    particularly in HPC environments where traditional job schedulers~\cite{nag2020hpc} and resource managers~\cite{hyperqueue2021} lack modern observability capabilities.
%    APC orchestrators like SLURM or PBS, commonly used in scientific computing environments,
%    don't provide native support for the fine grained monitoring and attestation mechanisms our framework requires.
%    These systems often operate with limited visibility into workload internals and lack standardized interfaces for security
%    instrumentation.
%    Integration with such environments would require developing custom monitoring solutions and potentially modifying
%    job submission and execution workflows. While possible, this adds significant complexity and might impact system
%    performance and usability. Furthermore, many HPC environments maintain strict security policies that limit the deployment
%    of additional monitoring components or modifications to the runtime environment.
%\end{itemize}

% mvd to apdx
%\subsection{Future Improvements}\label{sec:discussion:future_improvements}
%Several potential enhancements could extend our framework's capabilities and applicability:
%\begin{itemize}
%    \item \textbf{Distributed training environment support}
%    represents a significant expansion opportunity.
%    The current framework could be enhanced to handle multiple TEEs coordinating across training nodes, with cross-node attestation
%    and verification protocols. This would require developing protocols for maintaining integrity across distributed components
%    while managing the additional complexity of verifying inter-node communications and state synchronization~\cite{menetrey2022attestation}.
%
%    \item \textbf{Federated Learning Compatibility}
%    Our current framework could be extended to support federated learning environments,
%    particularly through integration with Intel's OpenFL (Open Federated Learning)~\cite{wei2020federated} framework.
%    OpenFL's architecture, which separates aggregator and participant nodes while maintaining model security,
%    presents unique opportunities and challenges for provenance tracking. The framework would need to extend its attestation and
%    verification protocols to handle distributed model updates while preserving the privacy guarantees inherent in federated learning.
%    Key considerations include tracking model aggregation operations, verifying participant contributions,
%    and maintaining cryptographic proofs across federation rounds. OpenFL's existing security features, including
%    its support for secure aggregation and TEE integration, provide natural integration points for our provenance framework.
%    The challenge lies in extending our verification protocols to handle the partial model updates and differential privacy
%    mechanisms~\cite{foley2022openfl} common in federated learning scenarios.
%
%    \item \textbf{Enhanced scalability features}
%    Support for more complex ML architectures, particularly for multi-model systems and ensemble methods,
%    would expand the framework's utility. This would require developing verification protocols for model composition and
%    interaction, tracking dependencies between component models, and maintaining provenance across model combinations\cite{zheng2020decent}.
%
%    The framework could also be extended to support dynamic trust models, allowing for flexible trust relationships between
%    different components and participants in the ML pipeline.
%    \item \textbf{Algorithmic Security Enhancements}
%    Our framework's modular design allows for integration of additional algorithmic security methods to enhance pipeline protection.
%    Model watermarking techniques~\cite{regazzoni2021survey, boenisch2021watermarking}  could be incorporated to embed verifiable ownership proofs directly into model weights,
%    providing an additional layer of provenance verification.
%    These watermarks would be included in the manifest chain, creating cryptographically verifiable links between model
%    versions and their origins.
%    \item \textbf{Verification Protocol Extensions} Our staged verification system could be extended to support dynamic trust models.
%    This would allow more flexible verification policies based on component criticality and risk levels, while maintaining our core
%    security guarantees. The current implementation's classification system provides a foundation for such policy-based verification.
%
%    Neural fingerprinting~\cite{cao2023fingerprinting, regazzoni2021survey} methods could extend our verification capabilities by enabling detection of unauthorized model modifications or derivatives.
%    By maintaining fingerprint signatures in our provenance records, the framework could track model lineage even when traditional hash-based verification is insufficient.
%    This is particularly valuable for scenarios involving fine-tuning or transfer learning.
%
%    Property attestation mechanisms could verify specific algorithmic characteristics of models throughout the pipeline. For example,
%    robustness guarantees~\cite{benbraiek2024robustness}, fairness metrics~\cite{liang2023fairness}, or backdoor resistance~\cite{bagdasaryan2023mithridates} could be measured and included in the manifest chain.
%    These properties would enhance the framework's ability to detect subtle manipulations that might not affect model
%    hashes but could impact model behavior.
%
%    These algorithmic security methods would enhance our existing integrity checks by providing independent verification channels,
%    enabling detection of sophisticated modifications, supporting fine-grained model comparison,
%    and strengthening ownership and origin validation while maintaining the framework's core security guarantees.
%\end{itemize}

% mvd to apdx
%\subsection{Storage Considerations}\label{sec:discussion:storage_considerations}
%
%While our current implementation uses Rekor as a transparency log, our analysis reveals several limitations with this approach.
%Storing C2PA~\cite{c2pa2023} manifests as single documents in Rekor introduces significant overhead, particularly when dealing with large-scale ML operations.
%The manifest structure, contains complex relationships and nested data that could be more efficiently managed through alternative storage strategies.
%
%\subsubsection{Decomposed Storage Model}\label{sec:discussion:storage_considerations:decomposition}
%Instead of storing complete manifests as single documents, the system could decompose manifests into their constituent components.
%The assertion store, claim signatures, and metadata could be stored separately, with relationships maintained through a reference system.
%This approach would enable more efficient updates and queries of specific manifest components.
%
%The decomposed model could leverage distributed ledger technology (DLT)~\cite{geeksforgeeks2023dlt}for critical manifest components
%while maintaining bulk data in optimized storage systems.
%This hybrid approach would:
%\begin{itemize}
%\item Store cryptographic proofs and signatures on the distributed ledger for immutability
%\item Maintain manifest metadata and relationships in graph databases for efficient querying
%\item Use object storage for large artifacts like model weights and datasets
%\item Link components through cryptographic references preserved in the ledger
%\end{itemize}
%
%\subsubsection{Hybrid Storage Architecture}\label{sec:discussion:storage_considerations:hybrid}
%A hybrid approach could maintain critical verification data in Rekor for its transparency guarantees
%while storing detailed manifest data in optimized storage systems.
%This would balance the need for immutable proof of existence with efficient data access and management.
%
%These storage optimizations could significantly reduce operational overhead while maintaining the security guarantees of our framework.
%Performance testing indicates potential reduction in storage requirements and query latency through these alternative approaches.

% mvd to apdx OR CASE STUDY DISCUSSION
%\subsection{Organization-specific Adaptations}\label{sec:discussion:organization_adaptations}
%Organization-specific adaptations are necessary to align with existing infrastructure and security policies.
%This includes:
%\begin{itemize}
%   \item Integration with current MLOps platforms
%   \item Alignment with existing security monitoring systems
%   \item Customization of verification policies
%   \item Adaptation to specific hardware security capabilities
%   \item Compliance with organizational security standards
%\end{itemize}
%
%The framework's modular design enables these adaptations while maintaining core security guarantees.
%Organizations can adjust the balance between security coverage and operational efficiency based
%on their specific requirements and constraints.

% mvd to CASE STUDIES
%\subsection{Deployment Considerations}\label{sec:discussion:deployment_consideration}
%\todo{This needs to be mvd to case studies}
%The implementation of our framework requires careful consideration of several practical aspects to ensure successful deployment in production environments. Here's a detailed analysis of key deployment factors:
%
%\subsubsection{Security Requirement Balance}\label{sec:discussion:deployment_consideration:sec_balance}
%Security requirement balance directly impacts operational efficiency.
%Organizations must determine appropriate verification frequencies and depth based on their risk profile and performance requirements.
%For instance, continuous hardware attestation of all pipeline components provides maximum security but introduces significant overhead.
%A more balanced approach might implement full verification at critical pipeline stages while using lightweight checks during intermediate steps.
%
%\subsubsection{Computational Overhead Management}\label{sec:discussion:deployment_consideration:comp_overhead_mgmt}
%Computational overhead management becomes crucial when scaling the framework across large ML operations.
%Our implementation shows that intelligent caching of verification results and batch processing of integrity checks can significantly reduce overhead.
%Organizations should consider:
%\begin{itemize}
%   \item Strategic placement of verification checkpoints - Organizations can tailor verification intensity based on their specific security needs and operational context. While financial or healthcare institutions might require comprehensive verification throughout their ML pipeline, research or development environments might focus verification efforts primarily on model publication or deployment stages. This flexible approach enables efficient resource utilization while maintaining appropriate security levels for each use case.
%   \item Optimization of hardware attestation frequency - By analyzing pipeline characteristics and risk patterns, attestation frequency can be tuned to concentrate on high-risk operations while reducing overhead during stable processing phases.
%   \item Efficient manifest storage and retrieval mechanisms - The system maintains an indexed store of manifests with hierarchical organization, enabling quick validation of model lineage while managing storage overhead for long-term provenance tracking.
%   \item Parallel verification processing where possible - This approach utilizes available computational resources effectively by running verification operations concurrently when component dependencies allow.
%\end{itemize}
