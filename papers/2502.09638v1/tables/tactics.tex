\begin{table}[t]
\centering
\small
\begin{tabular}{l p{11.5cm}}
% \toprule
% \toprule
\textbf{Tactic} & \textbf{Explanation} \\
\midrule
Direct Request & Directly asking the LLM a harmful request. \\
\hline
Echoing & Asking the model to replicate, confirm, or expand upon a harmful statement in the prompt. \\
\hline
Hidden Intention Streamline & A series of turns that seem harmless in isolation, but eventually amount to a harmful request; most similar to \citet{russinovich2024great,gibbs2024multiturn}. \\
\hline
Injection & Providing a specific input in the prompt to obtain a particular outcome in the response. \\
\hline
Obfuscation & Burying harmful content within harmless symbols, questions, synonyms, or data in the prompt. \\
\hline
Output Format & Requesting an output to adhere to a specific style or format. \\
\hline
Request Framing & Contextualizing a prompt to increase the likelihood of compliance -- for example, by framing as a fictional, urgent, or emotionally charged scenario. \\
\hline
\end{tabular}
\caption{Summary description of tactics in our MHJ taxonomy. Detailed breakdowns and examples for each tactic can be found in \Cref{app:tactics-breakdown,app:tactics-examples}.}
\label{tab:tactics}
\vspace{-15pt}
\end{table}
