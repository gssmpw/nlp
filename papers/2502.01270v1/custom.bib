% Use this file for citations not found in the ACL Anthology (contained in "anthology.bib").
@article{DBLP:journals/corr/RibeiroSG16,
  author    = {Marco T{\'{u}}lio Ribeiro and
               Sameer Singh and
               Carlos Guestrin},
  title     = {"Why Should {I} Trust You?": Explaining the Predictions of Any Classifier},
  journal   = {CoRR},
  volume    = {abs/1602.04938},
  year      = {2016},
  url       = {http://arxiv.org/abs/1602.04938},
  eprinttype = {arXiv},
  eprint    = {1602.04938},
  timestamp = {Mon, 13 Aug 2018 16:49:09 +0200},
  biburl    = {https://dblp.org/rec/journals/corr/RibeiroSG16.bib},
  bibsource = {dblp computer science bibliography, https://dblp.org}
}

@inproceedings{ribeiro2016should,
  title={" Why should i trust you?" Explaining the predictions of any classifier},
  author={Ribeiro, Marco Tulio and Singh, Sameer and Guestrin, Carlos},
  booktitle={Proceedings of the 22nd ACM SIGKDD international conference on knowledge discovery and data mining},
  pages={1135--1144},
  year={2016}
}

@article{ye2022unreliability,
  title={The unreliability of explanations in few-shot prompting for textual reasoning},
  author={Ye, Xi and Durrett, Greg},
  journal={Advances in neural information processing systems},
  volume={35},
  pages={30378--30392},
  year={2022}
}

@article{radford2019language,
  title={Language models are unsupervised multitask learners},
  author={Radford, Alec and Wu, Jeffrey and Child, Rewon and Luan, David and Amodei, Dario and Sutskever, Ilya and others},
  journal={OpenAI blog},
  volume={1},
  number={8},
  pages={9},
  year={2019}
}

@article{li2022explanations,
  title={Explanations from large language models make small reasoners better},
  author={Li, Shiyang and Chen, Jianshu and Shen, Yelong and Chen, Zhiyu and Zhang, Xinlu and Li, Zekun and Wang, Hong and Qian, Jing and Peng, Baolin and Mao, Yi and others},
  journal={arXiv preprint arXiv:2210.06726},
  year={2022}
}

@inproceedings{zhang-etal-2022-fine,
    title = "Fine-tuning Pre-trained Language Models for Few-shot Intent Detection: Supervised Pre-training and Isotropization",
    author = "Zhang, Haode  and
      Liang, Haowen  and
      Zhang, Yuwei  and
      Zhan, Li-Ming  and
      Wu, Xiao-Ming  and
      Lu, Xiaolei  and
      Lam, Albert",
    editor = "Carpuat, Marine  and
      de Marneffe, Marie-Catherine  and
      Meza Ruiz, Ivan Vladimir",
    booktitle = "Proceedings of the 2022 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies",
    month = jul,
    year = "2022",
    address = "Seattle, United States",
    publisher = "Association for Computational Linguistics",
    url = "https://aclanthology.org/2022.naacl-main.39",
    doi = "10.18653/v1/2022.naacl-main.39",
    pages = "532--542",
    abstract = "It is challenging to train a good intent classifier for a task-oriented dialogue system with only a few annotations. Recent studies have shown that fine-tuning pre-trained language models with a small set of labeled utterances from public benchmarks in a supervised manner is extremely helpful. However, we find that supervised pre-training yields an anisotropic feature space, which may suppress the expressive power of the semantic representations. Inspired by recent research in isotropization, we propose to improve supervised pre-training by regularizing the feature space towards isotropy. We propose two regularizers based on contrastive learning and correlation matrix respectively, and demonstrate their effectiveness through extensive experiments. Our main finding is that it is promising to regularize supervised pre-training with isotropization to further improve the performance of few-shot intent detection. The source code can be found at \url{https://github.com/fanolabs/isoIntentBert-main}.",
}

@inproceedings{casanueva-etal-2020-efficient,
    title = "Efficient Intent Detection with Dual Sentence Encoders",
    author = "Casanueva, I{\~n}igo  and
      Tem{\v{c}}inas, Tadas  and
      Gerz, Daniela  and
      Henderson, Matthew  and
      Vuli{\'c}, Ivan",
    editor = "Wen, Tsung-Hsien  and
      Celikyilmaz, Asli  and
      Yu, Zhou  and
      Papangelis, Alexandros  and
      Eric, Mihail  and
      Kumar, Anuj  and
      Casanueva, I{\~n}igo  and
      Shah, Rushin",
    booktitle = "Proceedings of the 2nd Workshop on Natural Language Processing for Conversational AI",
    month = jul,
    year = "2020",
    address = "Online",
    publisher = "Association for Computational Linguistics",
    url = "https://aclanthology.org/2020.nlp4convai-1.5",
    doi = "10.18653/v1/2020.nlp4convai-1.5",
    pages = "38--45",
    abstract = "Building conversational systems in new domains and with added functionality requires resource-efficient models that work under low-data regimes (i.e., in few-shot setups). Motivated by these requirements, we introduce intent detection methods backed by pretrained dual sentence encoders such as USE and ConveRT. We demonstrate the usefulness and wide applicability of the proposed intent detectors, showing that: 1) they outperform intent detectors based on fine-tuning the full BERT-Large model or using BERT as a fixed black-box encoder on three diverse intent detection data sets; 2) the gains are especially pronounced in few-shot setups (i.e., with only 10 or 30 annotated examples per intent); 3) our intent detectors can be trained in a matter of minutes on a single CPU; and 4) they are stable across different hyperparameter settings. In hope of facilitating and democratizing research focused on intention detection, we release our code, as well as a new challenging single-domain intent detection dataset comprising 13,083 annotated examples over 77 intents.",
}

@inproceedings{hayati-etal-2021-bert,
    title = "Does {BERT} Learn as Humans Perceive? Understanding Linguistic Styles through Lexica",
    author = "Hayati, Shirley Anugrah  and
      Kang, Dongyeop  and
      Ungar, Lyle",
    editor = "Moens, Marie-Francine  and
      Huang, Xuanjing  and
      Specia, Lucia  and
      Yih, Scott Wen-tau",
    booktitle = "Proceedings of the 2021 Conference on Empirical Methods in Natural Language Processing",
    month = nov,
    year = "2021",
    address = "Online and Punta Cana, Dominican Republic",
    publisher = "Association for Computational Linguistics",
    url = "https://aclanthology.org/2021.emnlp-main.510",
    doi = "10.18653/v1/2021.emnlp-main.510",
    pages = "6323--6331",
    abstract = "People convey their intention and attitude through linguistic styles of the text that they write. In this study, we investigate lexicon usages across styles throughout two lenses: human perception and machine word importance, since words differ in the strength of the stylistic cues that they provide. To collect labels of human perception, we curate a new dataset, Hummingbird, on top of benchmarking style datasets. We have crowd workers highlight the representative words in the text that makes them think the text has the following styles: politeness, sentiment, offensiveness, and five emotion types. We then compare these human word labels with word importance derived from a popular fine-tuned style classifier like BERT. Our results show that the BERT often finds content words not relevant to the target style as important words used in style prediction, but humans do not perceive the same way even though for some styles (e.g., positive sentiment and joy) human- and machine-identified words share significant overlap for some styles.",
}

@inproceedings{wang-etal-2016-attention,
    title = "Attention-based {LSTM} for Aspect-level Sentiment Classification",
    author = "Wang, Yequan  and
      Huang, Minlie  and
      Zhu, Xiaoyan  and
      Zhao, Li",
    editor = "Su, Jian  and
      Duh, Kevin  and
      Carreras, Xavier",
    booktitle = "Proceedings of the 2016 Conference on Empirical Methods in Natural Language Processing",
    month = nov,
    year = "2016",
    address = "Austin, Texas",
    publisher = "Association for Computational Linguistics",
    url = "https://aclanthology.org/D16-1058",
    doi = "10.18653/v1/D16-1058",
    pages = "606--615",
}


@InProceedings{pmlr-v37-xuc15,
  title = 	 {Show, Attend and Tell: Neural Image Caption Generation with Visual Attention},
  author = 	 {Xu, Kelvin and Ba, Jimmy and Kiros, Ryan and Cho, Kyunghyun and Courville, Aaron and Salakhudinov, Ruslan and Zemel, Rich and Bengio, Yoshua},
  booktitle = 	 {Proceedings of the 32nd International Conference on Machine Learning},
  pages = 	 {2048--2057},
  year = 	 {2015},
  editor = 	 {Bach, Francis and Blei, David},
  volume = 	 {37},
  series = 	 {Proceedings of Machine Learning Research},
  address = 	 {Lille, France},
  month = 	 {07--09 Jul},
  publisher =    {PMLR},
  pdf = 	 {http://proceedings.mlr.press/v37/xuc15.pdf},
  url = 	 {https://proceedings.mlr.press/v37/xuc15.html},
  abstract = 	 {Inspired by recent work in machine translation and object detection, we introduce an attention based model that automatically learns to describe the content of images. We describe how we can train this model in a deterministic manner using standard backpropagation techniques and stochastically by maximizing a variational lower bound. We also show through visualization how the model is able to automatically learn to fix its gaze on salient objects while generating the corresponding words in the output sequence. We validate the use of attention with state-of-the-art performance on three benchmark datasets: Flickr8k, Flickr30k and MS COCO.}
}

@inproceedings{joshi2021towards,
  title={Towards explainable dialogue system: Explaining intent classification using saliency techniques},
  author={Joshi, Ratnesh and Chatterjee, Arindam and Ekbal, Asif},
  booktitle={Proceedings of the 18th International Conference on Natural Language Processing (ICON)},
  pages={120--127},
  year={2021}
}
@inproceedings{binder2016layer,
  title={Layer-wise relevance propagation for neural networks with local renormalization layers},
  author={Binder, Alexander and Montavon, Gr{\'e}goire and Lapuschkin, Sebastian and M{\"u}ller, Klaus-Robert and Samek, Wojciech},
  booktitle={International Conference on Artificial Neural Networks},
  pages={63--71},
  year={2016},
  organization={Springer}
}

@inproceedings{ribeiro2018anchors,
  title={Anchors: High-precision model-agnostic explanations},
  author={Ribeiro, Marco Tulio and Singh, Sameer and Guestrin, Carlos},
  booktitle={Proceedings of the AAAI conference on artificial intelligence},
  volume={32},
  number={1},
  year={2018}
}

@inproceedings{sundararajan2017axiomatic,
  title={Axiomatic attribution for deep networks},
  author={Sundararajan, Mukund and Taly, Ankur and Yan, Qiqi},
  booktitle={International conference on machine learning},
  pages={3319--3328},
  year={2017},
  organization={PMLR}
}

@article{lundberg2017unified,
  title={A unified approach to interpreting model predictions},
  author={Lundberg, Scott M and Lee, Su-In},
  journal={Advances in neural information processing systems},
  volume={30},
  year={2017}
}

@article{guidotti2018survey,
  title={A survey of methods for explaining black box models},
  author={Guidotti, Riccardo and Monreale, Anna and Ruggieri, Salvatore and Turini, Franco and Giannotti, Fosca and Pedreschi, Dino},
  journal={ACM computing surveys (CSUR)},
  volume={51},
  number={5},
  pages={1--42},
  year={2018},
  publisher={ACM New York, NY, USA}
}

@article{mehrabi2021survey,
  title={A survey on bias and fairness in machine learning},
  author={Mehrabi, Ninareh and Morstatter, Fred and Saxena, Nripsuta and Lerman, Kristina and Galstyan, Aram},
  journal={ACM Computing Surveys (CSUR)},
  volume={54},
  number={6},
  pages={1--35},
  year={2021},
  publisher={ACM New York, NY, USA}
}

@article{samanta2017towards,
  title={Towards crafting text adversarial samples},
  author={Samanta, Suranjana and Mehta, Sameep},
  journal={arXiv preprint arXiv:1707.02812},
  year={2017}
}

@article{elsayed2018adversarial,
  title={Adversarial examples that fool both computer vision and time-limited humans},
  author={Elsayed, Gamaleldin and Shankar, Shreya and Cheung, Brian and Papernot, Nicolas and Kurakin, Alexey and Goodfellow, Ian and Sohl-Dickstein, Jascha},
  journal={Advances in neural information processing systems},
  volume={31},
  year={2018}
}

@article{jia2017adversarial,
  title={Adversarial examples for evaluating reading comprehension systems},
  author={Jia, Robin and Liang, Percy},
  journal={arXiv preprint arXiv:1707.07328},
  year={2017}
}


@article{coucke2018snips,
  title={Snips voice platform: an embedded spoken language understanding system for private-by-design voice interfaces},
  author={Coucke, Alice and Saade, Alaa and Ball, Adrien and Bluche, Th{\'e}odore and Caulier, Alexandre and Leroy, David and Doumouro, Cl{\'e}ment and Gisselbrecht, Thibault and Caltagirone, Francesco and Lavril, Thibaut and others},
  journal={arXiv preprint arXiv:1805.10190},
  year={2018}
}

@article{gunaratna2022explainable,
  title={Explainable slot type attentions to improve joint intent detection and slot filling},
  author={Gunaratna, Kalpa and Srinivasan, Vijay and Yerukola, Akhila and Jin, Hongxia},
  journal={arXiv preprint arXiv:2210.10227},
  year={2022}
}

@article{kim2014convolutional,
  title={Convolutional neural networks for sentence classification},
  author={Kim, Yoon},
  journal={arXiv preprint arXiv:1408.5882},
  year={2014}
}

@article{doshi2017towards,
  title={Towards a rigorous science of interpretable machine learning},
  author={Doshi-Velez, Finale and Kim, Been},
  journal={arXiv preprint arXiv:1702.08608},
  year={2017}
}

@article{hochreiter1997long,
  title={Long short-term memory},
  author={Hochreiter, Sepp and Schmidhuber, J{\"u}rgen},
  journal={Neural computation},
  volume={9},
  number={8},
  pages={1735--1780},
  year={1997},
  publisher={MIT press}
}

@inproceedings{mathew2021hatexplain,
  title={Hatexplain: A benchmark dataset for explainable hate speech detection},
  author={Mathew, Binny and Saha, Punyajoy and Yimam, Seid Muhie and Biemann, Chris and Goyal, Pawan and Mukherjee, Animesh},
  booktitle={Proceedings of the AAAI conference on artificial intelligence},
  volume={35},
  number={17},
  pages={14867--14875},
  year={2021}
}

@article{wu2021explaining,
  title={On explaining your explanations of bert: An empirical study with sequence classification},
  author={Wu, Zhengxuan and Ong, Desmond C},
  journal={arXiv preprint arXiv:2101.00196},
  year={2021}
}

@article{liu2019roberta,
  title={Roberta: A robustly optimized bert pretraining approach},
  author={Liu, Yinhan and Ott, Myle and Goyal, Naman and Du, Jingfei and Joshi, Mandar and Chen, Danqi and Levy, Omer and Lewis, Mike and Zettlemoyer, Luke and Stoyanov, Veselin},
  journal={arXiv preprint arXiv:1907.11692},
  year={2019}
}

@article{landis1977measurement,
  title={The measurement of observer agreement for categorical data},
  author={Landis, J Richard and Koch, Gary G},
  journal={biometrics},
  pages={159--174},
  year={1977},
  publisher={JSTOR}
}

@article{heaton2018ian,
  title={Ian Goodfellow, Yoshua Bengio, and Aaron Courville: Deep learning: The MIT Press, 2016, 800 pp, ISBN: 0262035618},
  author={Heaton, Jeff},
  journal={Genetic programming and evolvable machines},
  volume={19},
  number={1-2},
  pages={305--307},
  year={2018},
  publisher={Springer}
}

@article{liu2016attention,
  title={Attention-based recurrent neural network models for joint intent detection and slot filling},
  author={Liu, Bing and Lane, Ian},
  journal={arXiv preprint arXiv:1609.01454},
  year={2016}
}

@inproceedings{atanasova-etal-2020-diagnostic,
    title = "A Diagnostic Study of Explainability Techniques for Text Classification",
    author = "Atanasova, Pepa  and
      Simonsen, Jakob Grue  and
      Lioma, Christina  and
      Augenstein, Isabelle",
    booktitle = "Proceedings of the 2020 Conference on Empirical Methods in Natural Language Processing (EMNLP)",
    month = nov,
    year = "2020",
    address = "Online",
    publisher = "Association for Computational Linguistics",
    url = "https://aclanthology.org/2020.emnlp-main.263",
    doi = "10.18653/v1/2020.emnlp-main.263",
    pages = "3256--3274",
    abstract = "Recent developments in machine learning have introduced models that approach human performance at the cost of increased architectural complexity. Efforts to make the rationales behind the models{'} predictions transparent have inspired an abundance of new explainability techniques. Provided with an already trained model, they compute saliency scores for the words of an input instance. However, there exists no definitive guide on (i) how to choose such a technique given a particular application task and model architecture, and (ii) the benefits and drawbacks of using each such technique. In this paper, we develop a comprehensive list of diagnostic properties for evaluating existing explainability techniques. We then employ the proposed list to compare a set of diverse explainability techniques on downstream text classification tasks and neural network architectures. We also compare the saliency scores assigned by the explainability techniques with human annotations of salient input regions to find relations between a model{'}s performance and the agreement of its rationales with human ones. Overall, we find that the gradient-based explanations perform best across tasks and model architectures, and we present further insights into the properties of the reviewed explainability techniques.",
}

@article{deyoung2019eraser,
  title={ERASER: A benchmark to evaluate rationalized NLP models},
  author={DeYoung, Jay and Jain, Sarthak and Rajani, Nazneen Fatema and Lehman, Eric and Xiong, Caiming and Socher, Richard and Wallace, Byron C},
  journal={arXiv preprint arXiv:1911.03429},
  year={2019}
}

@inproceedings{qin2021co,
  title={A co-interactive transformer for joint slot filling and intent detection},
  author={Qin, Libo and Liu, Tailu and Che, Wanxiang and Kang, Bingbing and Zhao, Sendong and Liu, Ting},
  booktitle={ICASSP 2021-2021 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP)},
  pages={8193--8197},
  year={2021},
  organization={IEEE}
}

@article{devlin2018bert,
  title={Bert: Pre-training of deep bidirectional transformers for language understanding},
  author={Devlin, Jacob and Chang, Ming-Wei and Lee, Kenton and Toutanova, Kristina},
  journal={arXiv preprint arXiv:1810.04805},
  year={2018}
}

@article{liu2019incorporating,
  title={Incorporating priors with feature attribution on text classification},
  author={Liu, Frederick and Avci, Besim},
  journal={arXiv preprint arXiv:1906.08286},
  year={2019}
}

@incollection{scholkopf2022causality,
  title={Causality for machine learning},
  author={Sch{\"o}lkopf, Bernhard},
  booktitle={Probabilistic and Causal Inference: The Works of Judea Pearl},
  pages={765--804},
  year={2022}
}

@article{montavon2019layer,
  title={Layer-wise relevance propagation: an overview},
  author={Montavon, Gr{\'e}goire and Binder, Alexander and Lapuschkin, Sebastian and Samek, Wojciech and M{\"u}ller, Klaus-Robert},
  journal={Explainable AI: interpreting, explaining and visualizing deep learning},
  pages={193--209},
  year={2019},
  publisher={Springer}
}

@inproceedings{raymond2007generative,
  title={Generative and discriminative algorithms for spoken language understanding},
  author={Raymond, Christian and Riccardi, Giuseppe},
  booktitle={Interspeech 2007-8th Annual Conference of the International Speech Communication Association},
  year={2007}
}

@article{zhong2019fine,
  title={Fine-grained sentiment analysis with faithful attention},
  author={Zhong, Ruiqi and Shao, Steven and McKeown, Kathleen},
  journal={arXiv preprint arXiv:1908.06870},
  year={2019}
}

@inproceedings{jayaram-allaway-2021-human,
    title = "Human Rationales as Attribution Priors for Explainable Stance Detection",
    author = "Jayaram, Sahil  and
      Allaway, Emily",
    booktitle = "Proceedings of the 2021 Conference on Empirical Methods in Natural Language Processing",
    month = nov,
    year = "2021",
    address = "Online and Punta Cana, Dominican Republic",
    publisher = "Association for Computational Linguistics",
    url = "https://aclanthology.org/2021.emnlp-main.450",
    doi = "10.18653/v1/2021.emnlp-main.450",
    pages = "5540--5554",
    abstract = "As NLP systems become better at detecting opinions and beliefs from text, it is important to ensure not only that models are accurate but also that they arrive at their predictions in ways that align with human reasoning. In this work, we present a method for imparting human-like rationalization to a stance detection model using crowdsourced annotations on a small fraction of the training data. We show that in a data-scarce setting, our approach can improve the reasoning of a state-of-the-art classifier{---}particularly for inputs containing challenging phenomena such as sarcasm{---}at no cost in predictive performance. Furthermore, we demonstrate that attention weights surpass a leading attribution method in providing faithful explanations of our model{'}s predictions, thus serving as a computationally cheap and reliable source of attributions for our model.",
}
@article{chen2019bert,
  title={Bert for joint intent classification and slot filling},
  author={Chen, Qian and Zhuo, Zhu and Wang, Wen},
  journal={arXiv preprint arXiv:1902.10909},
  year={2019}
}

@inproceedings{hemphill-etal-1990-atis,
    title = "The {ATIS} Spoken Language Systems Pilot Corpus",
    author = "Hemphill, Charles T.  and
      Godfrey, John J.  and
      Doddington, George R.",
    booktitle = "Speech and Natural Language: Proceedings of a Workshop Held at Hidden Valley, {P}ennsylvania, June 24-27,1990",
    year = "1990",
    url = "https://aclanthology.org/H90-1021",
}

@inproceedings{pratapa2018language,
  title={Language modeling for code-mixing: The role of linguistic theory based synthetic data},
  author={Pratapa, Adithya and Bhat, Gayatri and Choudhury, Monojit and Sitaram, Sunayana and Dandapat, Sandipan and Bali, Kalika},
  booktitle={Proceedings of the 56th Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers)},
  pages={1543--1553},
  year={2018}
}

@inproceedings{gupta-etal-2020-semi,
    title = "A Semi-supervised Approach to Generate the Code-Mixed Text using Pre-trained Encoder and Transfer Learning",
    author = "Gupta, Deepak  and
      Ekbal, Asif  and
      Bhattacharyya, Pushpak",
    booktitle = "Findings of the Association for Computational Linguistics: EMNLP 2020",
    month = nov,
    year = "2020",
    address = "Online",
    publisher = "Association for Computational Linguistics",
    url = "https://aclanthology.org/2020.findings-emnlp.206",
    doi = "10.18653/v1/2020.findings-emnlp.206",
    pages = "2267--2280",
    abstract = "Code-mixing, the interleaving of two or more languages within a sentence or discourse is ubiquitous in multilingual societies. The lack of code-mixed training data is one of the major concerns for the development of end-to-end neural network-based models to be deployed for a variety of natural language processing (NLP) applications. A potential solution is to either manually create or crowd-source the code-mixed labelled data for the task at hand, but that requires much human efforts and often not feasible because of the language specific diversity in the code-mixed text. To circumvent the data scarcity issue, we propose an effective deep learning approach for automatically generating the code-mixed text from English to multiple languages without any parallel data. In order to train the neural network, we create synthetic code-mixed texts from the available parallel corpus by modelling various linguistic properties of code-mixing. Our codemixed text generator is built upon the encoder-decoder framework, where the encoder is augmented with the linguistic and task-agnostic features obtained from the transformer based language model. We also transfer the knowledge from a neural machine translation (NMT) to warm-start the training of code-mixed generator. Experimental results and in-depth analysis show the effectiveness of our proposed code-mixed text generation on eight diverse language pairs.",
}

@inproceedings{cetinoglu-etal-2016-challenges,
    title = "Challenges of Computational Processing of Code-Switching",
    author = {{\c{C}}etino{\u{g}}lu, {\"O}zlem  and
      Schulz, Sarah  and
      Vu, Ngoc Thang},
    booktitle = "Proceedings of the Second Workshop on Computational Approaches to Code Switching",
    month = nov,
    year = "2016",
    address = "Austin, Texas",
    publisher = "Association for Computational Linguistics",
    url = "https://aclanthology.org/W16-5801",
    doi = "10.18653/v1/W16-5801",
    pages = "1--11",
}

@article{hu2020xtreme,
      author    = {Junjie Hu and Sebastian Ruder and Aditya Siddhant and Graham Neubig and Orhan Firat and Melvin Johnson},
      title     = {XTREME: A Massively Multilingual Multi-task Benchmark for Evaluating Cross-lingual Generalization},
      journal   = {CoRR},
      volume    = {abs/2003.11080},
      year      = {2020},
      archivePrefix = {arXiv},
      eprint    = {2003.11080}
}

@inproceedings{devlin-etal-2019-bert,
    title = "{BERT}: Pre-training of Deep Bidirectional Transformers for Language Understanding",
    author = "Devlin, Jacob  and
      Chang, Ming-Wei  and
      Lee, Kenton  and
      Toutanova, Kristina",
    booktitle = "Proceedings of the 2019 Conference of the North {A}merican Chapter of the Association for Computational Linguistics: Human Language Technologies, Volume 1 (Long and Short Papers)",
    month = jun,
    year = "2019",
    address = "Minneapolis, Minnesota",
    publisher = "Association for Computational Linguistics",
    url = "https://aclanthology.org/N19-1423",
    doi = "10.18653/v1/N19-1423",
    pages = "4171--4186",
    abstract = "We introduce a new language representation model called BERT, which stands for Bidirectional Encoder Representations from Transformers. Unlike recent language representation models (Peters et al., 2018a; Radford et al., 2018), BERT is designed to pre-train deep bidirectional representations from unlabeled text by jointly conditioning on both left and right context in all layers. As a result, the pre-trained BERT model can be fine-tuned with just one additional output layer to create state-of-the-art models for a wide range of tasks, such as question answering and language inference, without substantial task-specific architecture modifications. BERT is conceptually simple and empirically powerful. It obtains new state-of-the-art results on eleven natural language processing tasks, including pushing the GLUE score to 80.5 (7.7 point absolute improvement), MultiNLI accuracy to 86.7{\%} (4.6{\%} absolute improvement), SQuAD v1.1 question answering Test F1 to 93.2 (1.5 point absolute improvement) and SQuAD v2.0 Test F1 to 83.1 (5.1 point absolute improvement).",
}

@inproceedings{conneau-etal-2020-unsupervised,
    title = "Unsupervised Cross-lingual Representation Learning at Scale",
    author = "Conneau, Alexis  and
      Khandelwal, Kartikay  and
      Goyal, Naman  and
      Chaudhary, Vishrav  and
      Wenzek, Guillaume  and
      Guzm{\'a}n, Francisco  and
      Grave, Edouard  and
      Ott, Myle  and
      Zettlemoyer, Luke  and
      Stoyanov, Veselin",
    booktitle = "Proceedings of the 58th Annual Meeting of the Association for Computational Linguistics",
    month = jul,
    year = "2020",
    address = "Online",
    publisher = "Association for Computational Linguistics",
    url = "https://aclanthology.org/2020.acl-main.747",
    doi = "10.18653/v1/2020.acl-main.747",
    pages = "8440--8451",
    abstract = "This paper shows that pretraining multilingual language models at scale leads to significant performance gains for a wide range of cross-lingual transfer tasks. We train a Transformer-based masked language model on one hundred languages, using more than two terabytes of filtered CommonCrawl data. Our model, dubbed XLM-R, significantly outperforms multilingual BERT (mBERT) on a variety of cross-lingual benchmarks, including +14.6{\%} average accuracy on XNLI, +13{\%} average F1 score on MLQA, and +2.4{\%} F1 score on NER. XLM-R performs particularly well on low-resource languages, improving 15.7{\%} in XNLI accuracy for Swahili and 11.4{\%} for Urdu over previous XLM models. We also present a detailed empirical analysis of the key factors that are required to achieve these gains, including the trade-offs between (1) positive transfer and capacity dilution and (2) the performance of high and low resource languages at scale. Finally, we show, for the first time, the possibility of multilingual modeling without sacrificing per-language performance; XLM-R is very competitive with strong monolingual models on the GLUE and XNLI benchmarks. We will make our code and models publicly available.",
}

@inproceedings{conneau-etal-2018-xnli,
    title = "{XNLI}: Evaluating Cross-lingual Sentence Representations",
    author = "Conneau, Alexis  and
      Rinott, Ruty  and
      Lample, Guillaume  and
      Williams, Adina  and
      Bowman, Samuel  and
      Schwenk, Holger  and
      Stoyanov, Veselin",
    booktitle = "Proceedings of the 2018 Conference on Empirical Methods in Natural Language Processing",
    month = oct # "-" # nov,
    year = "2018",
    address = "Brussels, Belgium",
    publisher = "Association for Computational Linguistics",
    url = "https://aclanthology.org/D18-1269",
    doi = "10.18653/v1/D18-1269",
    pages = "2475--2485",
    abstract = "State-of-the-art natural language processing systems rely on supervision in the form of annotated data to learn competent models. These models are generally trained on data in a single language (usually English), and cannot be directly used beyond that language. Since collecting data in every language is not realistic, there has been a growing interest in cross-lingual language understanding (XLU) and low-resource cross-language transfer. In this work, we construct an evaluation set for XLU by extending the development and test sets of the Multi-Genre Natural Language Inference Corpus (MultiNLI) to 14 languages, including low-resource languages such as Swahili and Urdu. We hope that our dataset, dubbed XNLI, will catalyze research in cross-lingual sentence understanding by providing an informative standard evaluation task. In addition, we provide several baselines for multilingual sentence understanding, including two based on machine translation systems, and two that use parallel data to train aligned multilingual bag-of-words and LSTM encoders. We find that XNLI represents a practical and challenging evaluation suite, and that directly translating the test data yields the best performance among available baselines.",
}

@inproceedings{williams-etal-2018-broad,
    title = "A Broad-Coverage Challenge Corpus for Sentence Understanding through Inference",
    author = "Williams, Adina  and
      Nangia, Nikita  and
      Bowman, Samuel",
    booktitle = "Proceedings of the 2018 Conference of the North {A}merican Chapter of the Association for Computational Linguistics: Human Language Technologies, Volume 1 (Long Papers)",
    month = jun,
    year = "2018",
    address = "New Orleans, Louisiana",
    publisher = "Association for Computational Linguistics",
    url = "https://aclanthology.org/N18-1101",
    doi = "10.18653/v1/N18-1101",
    pages = "1112--1122",
    abstract = "This paper introduces the Multi-Genre Natural Language Inference (MultiNLI) corpus, a dataset designed for use in the development and evaluation of machine learning models for sentence understanding. At 433k examples, this resource is one of the largest corpora available for natural language inference (a.k.a. recognizing textual entailment), improving upon available resources in both its coverage and difficulty. MultiNLI accomplishes this by offering data from ten distinct genres of written and spoken English, making it possible to evaluate systems on nearly the full complexity of the language, while supplying an explicit setting for evaluating cross-genre domain adaptation. In addition, an evaluation using existing machine learning models designed for the Stanford NLI corpus shows that it represents a substantially more difficult task than does that corpus, despite the two showing similar levels of inter-annotator agreement.",
}

@article{artetxe2019massively,
  title={Massively multilingual sentence embeddings for zero-shot cross-lingual transfer and beyond},
  author={Artetxe, Mikel and Schwenk, Holger},
  journal={Transactions of the Association for Computational Linguistics},
  volume={7},
  pages={597--610},
  year={2019},
  publisher={MIT Press}
}

@inproceedings{dou2021word,
  title={Word Alignment by Fine-tuning Embeddings on Parallel Corpora},
  author={Dou, Zi-Yi and Neubig, Graham},
  booktitle={Conference of the European Chapter of the Association for Computational Linguistics (EACL)},
  year={2021}
}

@inproceedings{qi2020stanza,
 author = {Qi, Peng and Zhang, Yuhao and Zhang, Yuhui and Bolton, Jason and Manning, Christopher D.},
 booktitle = {Proceedings of the 58th Annual Meeting of the Association for Computational Linguistics: System Demonstrations},
 title = {Stanza: A {Python} Natural Language Processing Toolkit for Many Human Languages},
 url = {https://nlp.stanford.edu/pubs/qi2020stanza.pdf},
 year = {2020}
}

@inproceedings{peters-etal-2018-deep,
    title = "Deep Contextualized Word Representations",
    author = "Peters, Matthew E.  and
      Neumann, Mark  and
      Iyyer, Mohit  and
      Gardner, Matt  and
      Clark, Christopher  and
      Lee, Kenton  and
      Zettlemoyer, Luke",
    booktitle = "Proceedings of the 2018 Conference of the North {A}merican Chapter of the Association for Computational Linguistics: Human Language Technologies, Volume 1 (Long Papers)",
    month = jun,
    year = "2018",
    address = "New Orleans, Louisiana",
    publisher = "Association for Computational Linguistics",
    url = "https://aclanthology.org/N18-1202",
    doi = "10.18653/v1/N18-1202",
    pages = "2227--2237",
    abstract = "We introduce a new type of deep contextualized word representation that models both (1) complex characteristics of word use (e.g., syntax and semantics), and (2) how these uses vary across linguistic contexts (i.e., to model polysemy). Our word vectors are learned functions of the internal states of a deep bidirectional language model (biLM), which is pre-trained on a large text corpus. We show that these representations can be easily added to existing models and significantly improve the state of the art across six challenging NLP problems, including question answering, textual entailment and sentiment analysis. We also present an analysis showing that exposing the deep internals of the pre-trained network is crucial, allowing downstream models to mix different types of semi-supervision signals.",
}

@InProceedings{hewitt2019designing,
    author =      "Hewitt, John and Liang, Percy",
    title =       "Designing and Interpreting Probes with Control Tasks",
    booktitle =   "Conference on Empirical Methods in Natural Language Processing",
    year =        "2019",
    publisher =   "Association for Computational Linguistics",
    location =    "Hong Kong",
}

@article{elazar-etal-2021-amnesic,
    title = "Amnesic Probing: Behavioral Explanation with Amnesic Counterfactuals",
    author = "Elazar, Yanai  and
      Ravfogel, Shauli  and
      Jacovi, Alon  and
      Goldberg, Yoav",
    journal = "Transactions of the Association for Computational Linguistics",
    volume = "9",
    year = "2021",
    address = "Cambridge, MA",
    publisher = "MIT Press",
    url = "https://aclanthology.org/2021.tacl-1.10",
    doi = "10.1162/tacl_a_00359",
    pages = "160--175",
    abstract = "Abstract A growing body of work makes use of probing in order to investigate the working of neural models, often considered black boxes. Recently, an ongoing debate emerged surrounding the limitations of the probing paradigm. In this work, we point out the inability to infer behavioral conclusions from probing results, and offer an alternative method that focuses on how the information is being used, rather than on what information is encoded. Our method, Amnesic Probing, follows the intuition that the utility of a property for a given task can be assessed by measuring the influence of a causal intervention that removes it from the representation. Equipped with this new analysis tool, we can ask questions that were not possible before, for example, is part-of-speech information important for word prediction? We perform a series of analyses on BERT to answer these types of questions. Our findings demonstrate that conventional probing performance is not correlated to task importance, and we call for increased scrutiny of claims that draw behavioral or causal conclusions from probing results.1",
}

@article{wu2020perturbed,
  title={Perturbed masking: Parameter-free probing for analyzing and interpreting BERT},
  author={Wu, Zhiyong and Chen, Yun and Kao, Ben and Liu, Qun},
  journal={arXiv preprint arXiv:2004.14786},
  year={2020}
}

@article{wang2019cross,
  title={Cross-lingual ability of multilingual bert: An empirical study},
  author={Wang, Zihan and Mayhew, Stephen and Roth, Dan and others},
  journal={arXiv preprint arXiv:1912.07840},
  year={2019}
}

@misc{tenney2020language,
    title={The Language Interpretability Tool: Extensible, Interactive Visualizations and Analysis for {NLP} Models},
    author={Ian Tenney and James Wexler and Jasmijn Bastings and Tolga Bolukbasi and Andy Coenen and Sebastian Gehrmann and Ellen Jiang and Mahima Pushkarna and Carey Radebaugh and Emily Reif and Ann Yuan},
    booktitle = "Proceedings of the 2020 Conference on Empirical Methods in Natural Language Processing: System Demonstrations",
    year = "2020",
    publisher = "Association for Computational Linguistics",
    pages = "107--118",
    url = "https://www.aclweb.org/anthology/2020.emnlp-demos.15",
}

@article{DBLP:journals/corr/SundararajanTY17,
  author    = {Mukund Sundararajan and
               Ankur Taly and
               Qiqi Yan},
  title     = {Axiomatic Attribution for Deep Networks},
  journal   = {CoRR},
  volume    = {abs/1703.01365},
  year      = {2017},
  url       = {http://arxiv.org/abs/1703.01365},
  eprinttype = {arXiv},
  eprint    = {1703.01365},
  timestamp = {Mon, 13 Aug 2018 16:48:32 +0200},
  biburl    = {https://dblp.org/rec/journals/corr/SundararajanTY17.bib},
  bibsource = {dblp computer science bibliography, https://dblp.org}
}

@article{DBLP:journals/corr/BinderMBMS16,
  author    = {Alexander Binder and
               Gr{\'{e}}goire Montavon and
               Sebastian Bach and
               Klaus{-}Robert M{\"{u}}ller and
               Wojciech Samek},
  title     = {Layer-wise Relevance Propagation for Neural Networks with Local Renormalization
               Layers},
  journal   = {CoRR},
  volume    = {abs/1604.00825},
  year      = {2016},
  url       = {http://arxiv.org/abs/1604.00825},
  eprinttype = {arXiv},
  eprint    = {1604.00825},
  timestamp = {Mon, 13 Aug 2018 16:47:10 +0200},
  biburl    = {https://dblp.org/rec/journals/corr/BinderMBMS16.bib},
  bibsource = {dblp computer science bibliography, https://dblp.org}
}

@article{DBLP:journals/corr/abs-2009-07896,
  author    = {Narine Kokhlikyan and
               Vivek Miglani and
               Miguel Martin and
               Edward Wang and
               Bilal Alsallakh and
               Jonathan Reynolds and
               Alexander Melnikov and
               Natalia Kliushkina and
               Carlos Araya and
               Siqi Yan and
               Orion Reblitz{-}Richardson},
  title     = {Captum: {A} unified and generic model interpretability library for
               PyTorch},
  journal   = {CoRR},
  volume    = {abs/2009.07896},
  year      = {2020},
  url       = {https://arxiv.org/abs/2009.07896},
  eprinttype = {arXiv},
  eprint    = {2009.07896},
  timestamp = {Tue, 03 Aug 2021 17:00:18 +0200},
  biburl    = {https://dblp.org/rec/journals/corr/abs-2009-07896.bib},
  bibsource = {dblp computer science bibliography, https://dblp.org}
}

@misc{https://doi.org/10.48550/arxiv.2210.05096,
  doi = {10.48550/ARXIV.2210.05096},
  
  url = {https://arxiv.org/abs/2210.05096},
  
  author = {Gowda, Thamme and Gheini, Mozhdeh and May, Jonathan},
  
  keywords = {Computation and Language (cs.CL), Artificial Intelligence (cs.AI), Computers and Society (cs.CY), FOS: Computer and information sciences, FOS: Computer and information sciences},
  
  title = {Checks and Strategies for Enabling Code-Switched Machine Translation},
  
  publisher = {arXiv},
  
  year = {2022},
  
  copyright = {Creative Commons Attribution Share Alike 4.0 International}
}

@article{DBLP:journals/corr/abs-2010-05607,
  author    = {Jasmijn Bastings and
               Katja Filippova},
  title     = {The elephant in the interpretability room: Why use attention as explanation
               when we have saliency methods?},
  journal   = {CoRR},
  volume    = {abs/2010.05607},
  year      = {2020},
  url       = {https://arxiv.org/abs/2010.05607},
  eprinttype = {arXiv},
  eprint    = {2010.05607},
  timestamp = {Tue, 20 Oct 2020 15:08:10 +0200},
  biburl    = {https://dblp.org/rec/journals/corr/abs-2010-05607.bib},
  bibsource = {dblp computer science bibliography, https://dblp.org}
}

@article{DBLP:journals/corr/abs-2105-08855,
  author    = {Kaiser Sun and
               Ana Marasovic},
  title     = {Effective Attention Sheds Light On Interpretability},
  journal   = {CoRR},
  volume    = {abs/2105.08855},
  year      = {2021},
  url       = {https://arxiv.org/abs/2105.08855},
  eprinttype = {arXiv},
  eprint    = {2105.08855},
  timestamp = {Mon, 31 May 2021 16:16:57 +0200},
  biburl    = {https://dblp.org/rec/journals/corr/abs-2105-08855.bib},
  bibsource = {dblp computer science bibliography, https://dblp.org}
}

@article{DBLP:journals/corr/abs-2004-12376,
  author    = {Simran Khanuja and
               Sandipan Dandapat and
               Anirudh Srinivasan and
               Sunayana Sitaram and
               Monojit Choudhury},
  title     = {GLUECoS : An Evaluation Benchmark for Code-Switched {NLP}},
  journal   = {CoRR},
  volume    = {abs/2004.12376},
  year      = {2020},
  url       = {https://arxiv.org/abs/2004.12376},
  eprinttype = {arXiv},
  eprint    = {2004.12376},
  timestamp = {Tue, 28 Apr 2020 16:10:02 +0200},
  biburl    = {https://dblp.org/rec/journals/corr/abs-2004-12376.bib},
  bibsource = {dblp computer science bibliography, https://dblp.org}
}

@article{DBLP:journals/corr/abs-2105-08807,
  author    = {Ganesh Jawahar and
               El Moatez Billah Nagoudi and
               Muhammad Abdul{-}Mageed and
               Laks V. S. Lakshmanan},
  title     = {Exploring Text-to-Text Transformers for English to Hinglish Machine
               Translation with Synthetic Code-Mixing},
  journal   = {CoRR},
  volume    = {abs/2105.08807},
  year      = {2021},
  url       = {https://arxiv.org/abs/2105.08807},
  eprinttype = {arXiv},
  eprint    = {2105.08807},
  timestamp = {Mon, 31 May 2021 16:16:57 +0200},
  biburl    = {https://dblp.org/rec/journals/corr/abs-2105-08807.bib},
  bibsource = {dblp computer science bibliography, https://dblp.org}
}

@article{DBLP:journals/corr/abs-2107-06483,
  author    = {Ishan Tarunesh and
               Syamantak Kumar and
               Preethi Jyothi},
  title     = {From Machine Translation to Code-Switching: Generating High-Quality
               Code-Switched Text},
  journal   = {CoRR},
  volume    = {abs/2107.06483},
  year      = {2021},
  url       = {https://arxiv.org/abs/2107.06483},
  eprinttype = {arXiv},
  eprint    = {2107.06483},
  timestamp = {Wed, 21 Jul 2021 15:55:35 +0200},
  biburl    = {https://dblp.org/rec/journals/corr/abs-2107-06483.bib},
  bibsource = {dblp computer science bibliography, https://dblp.org}
}

@article{lei2016rationalizing,
  title={Rationalizing neural predictions},
  author={Lei, Tao and Barzilay, Regina and Jaakkola, Tommi},
  journal={arXiv preprint arXiv:1606.04155},
  year={2016}
}

@inproceedings{jain-etal-2020-learning,
    title = "{L}earning to Faithfully Rationalize by Construction",
    author = "Jain, Sarthak  and
      Wiegreffe, Sarah  and
      Pinter, Yuval  and
      Wallace, Byron C.",
    booktitle = "Proceedings of the 58th Annual Meeting of the Association for Computational Linguistics",
    month = jul,
    year = "2020",
    address = "Online",
    publisher = "Association for Computational Linguistics",
    url = "https://aclanthology.org/2020.acl-main.409",
    doi = "10.18653/v1/2020.acl-main.409",
    pages = "4459--4473",
    abstract = "In many settings it is important for one to be able to understand why a model made a particular prediction. In NLP this often entails extracting snippets of an input text {`}responsible for{'} corresponding model output; when such a snippet comprises tokens that indeed informed the model{'}s prediction, it is a faithful explanation. In some settings, faithfulness may be critical to ensure transparency. Lei et al. (2016) proposed a model to produce faithful rationales for neural text classification by defining independent snippet extraction and prediction modules. However, the discrete selection over input tokens performed by this method complicates training, leading to high variance and requiring careful hyperparameter tuning. We propose a simpler variant of this approach that provides faithful explanations by construction. In our scheme, named FRESH, arbitrary feature importance scores (e.g., gradients from a trained model) are used to induce binary labels over token inputs, which an extractor can be trained to predict. An independent classifier module is then trained exclusively on snippets provided by the extractor; these snippets thus constitute faithful explanations, even if the classifier is arbitrarily complex. In both automatic and manual evaluations we find that variants of this simple framework yield predictive performance superior to {`}end-to-end{'} approaches, while being more general and easier to train. Code is available at https://github.com/successar/FRESH.",
}