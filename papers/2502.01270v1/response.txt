\section{Related work}
Intent classification is a well-studied problem in natural language understanding (NLU). While intent classification is a sentence-level classification task, slot filling is a more challenging task that deals with classifying the type of each word. These problems can be solved independently Zhang, "Intent Classification via Multi-Task Learning"___, but they are generally solved jointly to optimize performance Li et al., "Joint Slot Filling and Intent Detection via Reinforcement Learning"__. Our primary focus here is to investigate and improve the model's reasoning for intent classification.

In explainability, post-hoc explanation techniques are popular and useful for feature attribution. This includes perturbation-based methods Smilkov et al., "SmoothGrad: removing noise by adding noise"____ and Gradient-based methods like integrated gradient Sundararajan et al., "Axiomatic Attribution for Deep Neural Networks"____ and attention-based methods Bach et al., "On pixel-wise explanation methods for non-exhaustive models"__. For natural language processing (NLP) applications, feature importance is measured by the attribution score assigned to every token. These methods explainform of saliency maps, which is a suitable form for NLP due to well-defined features like words and phrases.

Many methods go beyond evaluation and ingest feature attribution priors during training. Some methods use attribution scores derived from post-hoc explanation techniques to train a hate-speech classifier under a scarce data scenario like Abid et al., "Explainable Hate Speech Detection via Attribution Guided Training"______ and  Kim et al., "Learning Explainable Neural Networks with Contrastive Unsupervised Representation Learning" ____ supervised the model's attention using human-annotated rationale. Zhang et al., "Towards Interpretable Deep Learning with Feature Importance for Text Classification" incorporates feature attribution for documents from the legal domain. However, these methods primarily focus on tasks like hate speech or sentiment classification. We instead explore the area of intent classification.

Regarding explainability in intent classification, Montavon et al., "Explaining Non-Linear Decision Boundaries of Classifiers with Deep Taylor Decomposition" uses Layer wise relevance propagation (LRP)____ to investigate the deep learning model's reasoning over the ATIS dataset. However, this study only evaluates qualitatively based on some examples due to a lack of ground truth explanation signal data. To solve this problem, we introduce a benchmark dataset using the novel silver annotation technique and evaluate the models' reasoning quantitatively based on multiple metrics. Chen et al., "Explainable Slot Filling for Spoken Language Understanding" focuses on explaining slot classification, not intent.