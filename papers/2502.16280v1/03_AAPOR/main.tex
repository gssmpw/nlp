\documentclass{article}


\usepackage{PRIMEarxiv}

\usepackage[utf8]{inputenc} % allow utf-8 input
\usepackage[T1]{fontenc}    % use 8-bit T1 fonts
\usepackage{hyperref}       % hyperlinks
\usepackage{url}            % simple URL typesetting
\usepackage{natbib}
\usepackage{booktabs}       % professional-quality tables
\usepackage{amsfonts}       % blackboard math symbols
\usepackage{nicefrac}       % compact symbols for 1/2, etc.
\usepackage{microtype}      % microtypography
\usepackage{lipsum}
\usepackage{fancyhdr}       % header
\usepackage{graphicx}       % graphics
\graphicspath{{media/}}     % organize your images and other figures under media/ folder

%Header
\pagestyle{fancy}
\thispagestyle{empty}
\rhead{ \textit{ }} 

% Update your Headers here
\fancyhead[LO]{Running Title for Header}
% \fancyhead[RE]{Firstauthor and Secondauthor} % Firstauthor et al. if more than 2 - must use \documentclass[twoside]{article}



  
%% Title
\title{Can language models replace human surveys? A technical analysis 
%%%% Cite as
%%%% Update your official citation here when published 
\thanks{\textit{\underline{Citation}}: 
\textbf{Authors. Title. Pages.... DOI:000000/11111.}} 
}
%LLMs can complement surveys if you know how

\author{
  Author1, Author2 \\
  Affiliation \\
  Univ \\
  City\\
  \texttt{\{Author1, Author2\}email@email} \\
  %% examples of more authors
   \And
  Author3 \\
  Affiliation \\
  Univ \\
  City\\
  \texttt{email@email} \\
  %% \AND
  %% Coauthor \\
  %% Affiliation \\
  %% Address \\
  %% \texttt{email} \\
  %% \And
  %% Coauthor \\
  %% Affiliation \\
  %% Address \\
  %% \texttt{email} \\
  %% \And
  %% Coauthor \\
  %% Affiliation \\
  %% Address \\
  %% \texttt{email} \\
}


\begin{document}
\maketitle


\begin{abstract}
With the release of ChatGPT in November 2022, the world has seen a spike in interest in large language models (LLMs). Many academic disciplines, as well as the business world, wonder if and how they can integrate LLMs into their endeavors. One emerging---and highly debated---topic is the usage of LLMs for (public) opinion research. The idea is that one can leverage LLMs to substitute for surveying humans. Yet, the question remains as to how valid and reliable it is to substitute humans with LLMs. Previous research mainly focuses on comparing LLM predictions based on personas to a gold standard survey prediction for these personas. The results of such analyses are mixed \citep{argyle2023out, %durmus2023towards, 
kim2023ai}, revealing problems like, e.g., prediction instability that occurs with slight formulation changes in the prompt \cite{bisbee2023synthetic} and performance differences between countries \cite{von2024united}. While such approaches might give first insights into how well LLMs can predict general past questions of interest, we lack a deeper understanding of how ``opinion formation" works on a \textit{technical} level in LLMs. 
%However, an analysis of how feasible such an approach on the \textit{technical} level is remains missing. 

In this paper, we look inside the latent space of LLMs to uncover how reliable personas are mapped to parties in the German multi-party context. With this, we aim to find out which attributes of personas lead to differences in LLM party associations. Our analyses allow us to predict how stable persona mappings are inside an LLM for different demographic groups, thereby providing technically-backed insights to practitioners. 

Our methodology is based on trained probes (Multi-Layer-Perceptron), which classify whether an LLM embedding represents a specific German party. With the help of these probes, we identify so-called ``value vectors" inside the LLM, which, when triggered, increase the probability of outputting word fragments (tokens) that are related to this specific party. Next, we analyze how changes in the persona attributes relate to activating these party value vectors. Finally, we explore how instabilities in the persona-party-mapping can explain prediction instabilities that occur with slight wording changes of the prompt. 

Our preliminary findings indicate that i) our probes can identify party value vectors of the LLM with high certainty, ii) persona attributes, such as gender or age, correlate differently with political subscriptions embedded in the value vectors, and iii) varying textual phrases describing persona attributes heavily impact the results. 

\end{abstract}


%Bibliography
\bibliographystyle{unsrt}  
\bibliography{99_References/references.bib}  


\end{document}
