\section{Related Work and Motivation}
Over the past two decades, MOEAs have been developed and applied to multi-objective optimisation problems. 
These MOEAs can be categorised into three classes____: Pareto-based____, indicator-based____, and decomposition-based MOEAs____. Among the three classes, decomposition-based MOEAs have become increasingly popular for solving MOPs due to their clear strengths. These strengths include providing high selection pressure____, having evenly distributed solutions on certain problems____, and being capable of handling many-objective optimisation problems____. 
%\miqing{people may say indicator-based MOEAs also have such strengths?}
\begin{figure*}[tbp]
	\begin{center}
        \begin{tabular}{@{}c@{}c@{}c@{}c@{}}			
			\includegraphics[scale=0.35]{Figures/sec2_a_.pdf}&
			\includegraphics[scale=0.35]{Figures/sec2_c_.pdf}&
			\includegraphics[scale=0.35]{Figures/sec2_d_.pdf}&
			\includegraphics[scale=0.35]{Figures/sec2_b_.pdf}\\
			(a) RVEA on DTLZ1 & (b) RVEA on IDTLZ1 & (c) RVEAi-GNG on IDTLZ1 & (d) RVEAi-GNG on DTLZ1 \\
		\end{tabular}
	\end{center}
	\caption{Comparison of the performance of a weight-fixing algorithm, RVEA____, and a weight-adaptive algorithm, RVEAi-GNG____, on two tri-objective optimisation problems: DTLZ1____ with a regular Pareto front and IDTLZ1____ with an irregular Pareto front.}
	\label{fig:sec2}
\end{figure*}

%\textcolor{blue}{MOEA/D is a typical algorithm in decomposition-based MOEAs.} 
%\miqing{why the last says MOEAs based on decomposition, here we say MOEA/D?} 
%\miqing{I think one way to address this is to say MOEA/D here is a general term, representing all decomposition-based MOEAs.}
Decomposition-based MOEAs solve an MOP by decomposing them into sub-problems using predefined weights and solving them collaboratively. The diversity of the solutions obtained is controlled by the weights, which can be initialised using different methods. They include simplex-lattice design____, multi-layer simplex-lattice design____, and uniform random sampling design____. These methods can generate a set of uniformly distributed weights.

%simplex-lattice design, which generates evenly distributed weights by dividing the space into a lattice of regular simplex shapes____; multi-layer simplex lattice design and uniform design, which can enhance the uniformity of the weights in high-dimensional space____; uniform random sampling design, which can generate an arbitrary number of uniform weights for any dimension____. 

%By initialising weights uniformly, MOEA/D can provide diversified solutions for specific MOPs. \sout{which is a desirable characteristic for real-world problems____ }. \miqing{do the cited papers support this? why mention real-world problems?}


However, uniformly distributed weights work well only for MOPs with regular Pareto fronts, where uniformly distributed solutions can be obtained. For MOPs with irregular Pareto fronts, the solutions obtained are likely to be distributed poorly____. In such a case, several weights may correspond to one solution, wasting computational resources and more importantly, reducing the options (i.e., candidate solutions) for the decision maker in the decision-making process. 
Table~\ref{tab:Sec2} (upper part) lists several decomposition-based MOEAs with uniformly distributed
%表中是fixed
weights such as MOEA/D____, MOEA/D-DE____, NSGA-III____, MOEA/D-M2M____ and RVEA____. These algorithms are effective when the problem's Pareto front is regular, but are ineffective when the problem's Pareto front is irregular____.
%\miqing{can we give some references to support the statement?}

\begin{comment}
% tab:Sec2
\begin{table}[tbp]
	\centering
	\caption{\sout{Performance of representative MOEA/D algorithms for regular and irregular Pareto fronts.}}
	\begin{tabular}{p{3cm}<{\centering}m{1cm}<{\centering}m{1.6cm}<{\centering}m{1.7cm}<{\centering}}
		\hline
		\specialrule{0em}{1pt}{1pt}
		\multirow{2}[0]{*}{Algorithm} & \multirow{2}[0]{*}{Type} & \multicolumn{2}{c}{Pareto fronts} \\
		\specialrule{0em}{1pt}{1pt}
		&       & Regular & Irregular \\
        \specialrule{0em}{1pt}{1pt}
		\hline
		\specialrule{0em}{1pt}{1pt}
		 \multicolumn{1}{m{3cm}}{MOEA/D____, MOEA/D-DE____, NSGA-III____, MOEA/D-M2M____, RVEA____} & fixed weights & excellent & poor\\
		\hline
		\specialrule{0em}{1pt}{1pt}
		 \multicolumn{1}{m{3cm}}{MOEA/D-AWA____, iRVEA____, MOEA/D-LTD____, DEA-GNG____, RVEA-iGNG____, MOEA/D-LTD____, AdaW____, MOEA/D-AM2M____, A-NSGA-III____,  RVEA*____, g-DBEA____} & adaptive weights & worse than weight-fixing algorithms & better than weight-fixing algorithms\\
        \specialrule{0em}{1pt}{1pt}
		\hline
	\end{tabular}
	\label{tab:addlabel}
 \miqing{the alignment does not look good...}
\end{table}
\end{comment}

\begin{table}[htbp]
  \centering
  \caption{Performance of representative decomposition-based MOEAs for regular and irregular Pareto fronts.}
    \begin{tabular}{p{2.6cm}m{1cm}<{\centering}m{1.6cm}<{\centering}m{1.7cm}<{\centering}}
    \hline
    \specialrule{0em}{1pt}{1pt}
    \multirow{2}{2.6cm}{Algorithm} & \multirow{2}{1cm}{\centering Type} & \multicolumn{2}{c}{Pareto fronts} \\
          &       & Regular & Irregular \\
    \specialrule{0em}{1pt}{1pt}
    \hline
    \specialrule{0em}{1pt}{1pt}
    MOEA/D____ & \multirow{5}{1cm}{\centering Fixed weights} & \multirow{5}{1.6cm}{\centering Excellent} & \multirow{5}{1.7cm}{\centering Poor} \\
    MOEA/D-DE____ &       &       &  \\
    NSGA-III____ &       &       &  \\
    MOEA/D-M2M____ &       &       &  \\
    RVEA____  &       &       &  \\
    \specialrule{0em}{1pt}{1pt}
    \hline
    \specialrule{0em}{1pt}{1pt}
    MOEA/D-AWA____ & \multirow{10}{1cm}{\centering Adaptive weights} & \multirow{10}{1.6cm}{\centering Worse than weight-fixing algorithms} & \multirow{10}{1.7cm}{\centering Better than weight-fixing algorithms} \\
    iRVEA____ &       &       &  \\
    MOEA/D-LTD____ &       &       &  \\
    DEA-GNG____ &       &       &  \\
    RVEA-iGNG____ &       &       &  \\
    AdaW____  &       &       &  \\
    MOEA/D-AM2M____ &       &       &  \\
    A-NSGA-III____ &       &       &  \\
    RVEA*____ &       &       &  \\
    g-DBEA____ &       &       &  \\
    \specialrule{0em}{1pt}{1pt}
    \hline
    \end{tabular}%
  \label{tab:Sec2}%
\end{table}%


For example, 
Figure~\ref{fig:sec2}(a) and (b) give the solutions obtained by the algorithm RVEA____ on a problem with a regular Pareto front (DTLZ1____ having a triangle Pareto front), and another problem with an irregular Pareto front (IDTLZ1____ having an inverted triangle Pareto front), respectively. 
%\miqing{need to add references when saying something first time.} 
As can be seen from the figure, RVEA performs very well on the DTLZ1 (Figure~\ref{fig:sec2}(a)) but performs poorly on IDTLZ1 (Figure~\ref{fig:sec2}(b)). 


In order to tackle this issue, researchers have proposed weight adaptation methods that adjust the weights to approximate the shape of the Pareto front during the evolutionary process. Table~\ref{tab:Sec2} (lower part) lists several representative weight adaptation algorithms, including MOEA/D-AM2M____, RVEA*____, iRVEA____, MOEA/D-LTD____, DEA-GNG____, RVEA-iGNG____, AdaW____, MOEA/D-AM2M____, A-NSGA-III____, and g-DBEA____. 
With adaptation of its weights, decomposition-based MOEAs can work much better on problems with irregular Pareto fronts.
For example, 
as shown in Figure~\ref{fig:sec2}(c), 
the algorithm RVEA-iGNG____ can obtain a set of well-diversified solutions on IDTLZ1,
compared to the solution set obtained by RVEA in Figure~\ref{fig:sec2}(b).




However, adapting weights during the search process can lead to degradation in performance on problems with regular Pareto fronts. 
Adapting the weights means changing search directions, 
and it affects not only the convergence of the population but also the diversity since the adaptation is conducted based on the current population which may not be able to reflect the problem's true Pareto front.  
Figure~\ref{fig:sec2}(d) gives the results of the weight adaptation algorithm RVEA-iGNG on the regular problem DTLZ1. 
As shown, the obtained solution set performs worse than that obtained by RVEA (Figure~\ref{fig:sec2}(a)). \footnote{It is worth mentioning that, apart from these weight adaptation methods, there are other methods being explored to address MOPs with irregular Pareto fronts. For instance, the utilisation of multiple sets of weights____ and the application of adaptive scalarising functions____ have also demonstrated robust performance in dealing with MOPs with irregular Pareto fronts. However, these methods also show somewhat weaker performance on MOPs with regular Pareto fronts.}

%This is because weight adaptation methods can disturb the uniform distribution of the initial weights, making them less effective compared to the original fixed-weight MOEA/D. Table~\ref{tab:Sec2} shows these weight adaptation algorithms may be less effective on problems with regular Pareto fronts compared to the original fixed-weight MOEA/D. 
%\miqing{could we give a concrete example empirically here so people know what ``effective'' and ``less effective'' mean?}

%\textcolor{blue}{To further investigate this issue, we conducted experiments on both the fixed-weight algorithm RVEA and its adaptive-weight version RVEAi-GNG, using two problems: 3-objective DTLZ1 with a regular Pareto front and 3-objective DTLZ7 with an irregular Pareto front. The experimental results, depicted in Figure 1, showed that the RVEA performed well on the DTLZ1 by generating a uniformly distributed set of solutions, but was ineffective on DTLZ7. On the other hand, RVEAi-GNG, was more effective on the irregular problem DTLZ7, but less effective on the regular problem DTLZ1, compared to the fixed-weight RVEA.}



%\begin{figure}
%\centering
%\begin{subfigure}{0.21\textwidth}
%  \centering
%  \includegraphics[width=\linewidth]{Figures/sec2_a_.pdf}
%  \caption{RVEA}
%  \label{fig:sub1}
%\end{subfigure}%
%\begin{subfigure}{0.22\textwidth}
%  \centering
%  \includegraphics[width=\linewidth]{Figures/sec2_b_.pdf}
%  \caption{RVEA-iGNG}
%  \label{fig:sub2}
%\end{subfigure}
%\caption{Comparison of the performance of a fixed-weight algorithm RVEA and an adaptive-weight algorithm RVEAi-GNG on the 3-objective DTLZ1}
%\label{fig:DTLZ1}
%\end{figure}


% tab: Sec2
\begin{comment} 
\begin{table*}[htbp]
	\centering
	\caption{\sout{Performance of Typical Decomposition-based Multi-Objective Evolutionary Algorithms on Regular and Irregular Pareto Fronts}}
	\begin{tabular}{cccc}
		\hline
		\specialrule{0em}{1pt}{1pt}
		\multirow{2}[0]{*}{Type} & \multirow{2}[0]{*}{Algorithm} & \multicolumn{2}{c}{Applicable Pareto fronts} \\
		\specialrule{0em}{1pt}{1pt}
		&       & Regular Pareto fronts & Irregular Pareto fronts\\
		\hline
		\specialrule{0em}{1pt}{1pt}
		\multirow{4}[0]{*}{Fixed weights} 
        & MOEA/D & Effective & Not Effective (than fixed-weight)\\
        & MOEA/D-DE  & Effective & Not Effective (than fixed-weight)\\
		& NSGA-III & Effective & Not Effective (than fixed-weight)\\
		& MOEA/D-M2M & Effective & Not Effective (than fixed-weight)\\
		& RVEA  & Effective & Not Effective (than fixed-weight)\\
		\hline
		\specialrule{0em}{1pt}{1pt}
		\multirow{10}[0]{*}{Adaptive Weights} & MOEA/D-AWA & Less Effective (than fixed-weight) & More Effective (than fixed-weight)\\
		& iRVEA & Less Effective (than fixed-weight) & More Effective (than fixed-weight)\\
		& RVEA-iGNG & Less Effective (than fixed-weight) & More Effective (than fixed-weight)\\
		& MOEA/D-LTD & Less Effective (than fixed-weight) & More Effective (than fixed-weight)\\
		& AdaW  & Less Effective (than fixed-weight) & More Effective (than fixed-weight)\\
		& MOEA/D-AM2M & Less Effective (than fixed-weight) & More Effective (than fixed-weight)\\
		& A-NSGA-III & Less Effective (than fixed-weight) & More Effective (than fixed-weight)\\
		& A2-NSGA-III & Less Effective (than fixed-weight) & More Effective (than fixed-weight)\\
		& RVEA* & Less Effective (than fixed-weight) & More Effective (than fixed-weight)\\
		& g-DBEA & Less Effective (than fixed-weight) & More Effective (than fixed-weight)\\
		\hline
	\end{tabular}
	\label{tab:Sec2}
\end{table*}
\end{comment}




%It should be noted that in addition to using decomposition-based algorithms, some researchers have incorporated weight adaptation techniques into non-decomposition-based EMO algorithms. For example introduced weight adaptation for Pareto-based search, while AR-MOEA____ applied weight adaptation to indicator-based search. Other researchers have explored adaptive weights of search directions based on the distribution of the evolutionary population, which can be viewed as a form of weight adaptation (VaEA____,).

%\sout{It is worth noting that some researchers have proposed meaningful MOEAs to address this issue, such as g-DBEA and AR-MOEA.
%g-DBEA begins by initialising a set of uniformly distributed weights and then collects information on the feasibility and non-dominated solutions associated with these weights over a specified learning period. During the evolutionary process, new weights can be added to a set of active weights, while the weights that should have been deleted are stored in a set of inactive weights. They have a chance to return to the set of active weights and replace the newly added weights. This allows for the handling of multi-objective optimisation problems with rules.
%AR-MOEA is an indicator-based EMO, but it introduces weights and is therefore also considered a weight adjustment method. AR-MOEA not only utilises weights uniformly sampled from a unit hyperplane but also adaptively adjusts the distribution of reference points based on the contribution of candidate solutions in an external archive in terms of IGD-NS. Compared to existing reference point adaptation methods, AR-MOEA has better versatility in capturing different type of Pareto fronts. These weight adjustment algorithms are effective for regular problems, but as pointed out in the literature [], the diversity of the solution set needs to be improved for irregular problems. Moreover, frequent weight adjustments in irregular problems lead to poor convergence of the solution [].} \miqing{why do we need to pick up AR-MOEA in detail?}


In this paper, we make an attempt to address the above issues, with the aim of making decomposition-based MOEAs perform very well on irregular problems without compromising their good performance on regular ones. We do so by proposing a weight adaptation trigger mechanism, which will be detailed in the next section. 

%\sout{In addition, it is also worth mentioning that there are a couple of studies that attempted to balance the performance on regular and irregular Pareto fronts, though not being decomposition-based MOEAs, such as g-DBEA}____ \miqing{why g-DBEA cannot be categorised into the above weight adaptation methods?} and AR-MOEA____. 
%\miqing{can we use one sentence to briefly summarise their idea?}.
%\sout{Some of them, such as AR-MOEA performs very well on both regular and irregular Pareto fronts. For comprehensive evaluation of the proposed algorithm, we have included them in our comparative experiments.}

In addition, 
it is worth mentioning that there are a couple of studies that attempted to balance the performance on regular and irregular Pareto fronts, though not being decomposition-based MOEAs, such as AR-MOEA____, VaEA____, BCE-IBEA____. 
They perform very well on both regular and irregular Pareto fronts. 
For comprehensive evaluation of the proposed algorithm, we will include them in our comparative experiments. The results are presented in the supplementary material. 
%\miqing{I suggest we could include AR-MOEA and BCE or some other algorithms into the Appendix; but hold on... where is the Appendix?}

%Some researchers have proposed meaningful MOEAs to address this issue, such as g-DBEA____ and AR-MOEA____.
%In g-DBEA, weights can be dynamically added to an active set while old weights are stored in an inactive set. This mechanism allows for old weights to potentially return to the active set and replace newly added weights when dealing with the regular Pareto front.
%AR-MOEA, on the other hand, introduces reference points (weights) and adaptively adjusts the reference points based on the contribution of candidate solutions in an external archive. When dealing with the regular Pareto front, its reference points can be uniformly distributed. AR-MOEA is effective for regular problems, but when compared with other weight adaptation algorithms, the diversity of the solutions has room to be improved for problems with an irregular Pareto front____. Additionally, In these weight adaptation algorithms, frequent weight adaptation can lead to poor convergence of the solutions____.


%\sout{Our work is motivated by the weaknesses of existing weight adaptation methods. We aim to utilise the population and maintain a well-constructed archive during the evolutionary process to determine the type of the Pareto front for the problem. Based on the analysis, we will decide whether weight adjustment is necessary. Throughout this process, we consider various issues such as maintaining the archive, reducing the frequency of weight adjustment, and ensuring population uniformity when dealing with irregular Pareto fronts. Our paper strives to address these challenges.} \miqing{I guess it would be better to say it in a more general sense.}
  

%\textcolor{blue}{MODIFIED VERSION: Our work is motivated by the limitations of existing weight adaptation methods. We propose an algorithm that can determine the type of the Pareto front by using an archive and population. Besides that, we also consider important factors such as maintaining a well-distributed archive, reducing the frequency of weight adjustment, and ensuring population uniformity. Our goal is to address these challenges and provide a new perspective on weight adaptation in multi-objective optimisation problems.}