% This is samplepaper.tex, a sample chapter demonstrating the
% LLNCS macro package for Springer Computer Science proceedings;
% Version 2.20 of 2017/10/04
%

\documentclass[final]{llncs}
% \usepackage[review]{lrec-coling2024} % this is the new style
% \usepackage[final]{lrec-coling2024}
% our package

% \makeatletter
% \def\input@path{{tex-gyre/}}
% \makeatother


% \usepackage{tgbonum}
% \usepackage{tgheros}
% \usepackage{tgcursor}


% \makeatletter
% \def\@mb@citenamelist{cite,citep,citet,citealp,citealt,citepalias,citetalias}
% \makeatother
% \newcites{languageresource}{~}
% \renewcommand{\refname}{{}}
\usepackage{graphicx}
\usepackage{tabularx}
\usepackage{soul}
\usepackage{amsmath}
\usepackage{amssymb}
\usepackage{pifont}
% \usepackage{graphicx}
% \usepackage{caption}
\usepackage{float} 
\usepackage{subfigure}
\usepackage{color}
\usepackage{amsfonts}
% \usepackage {amsthm}
\usepackage{makecell}
\usepackage[most]{tcolorbox} % 引入tcolorbox宏包
% \usepackage{xcolor}%
\usepackage{arydshln} % for dashed lines in tables
% \newtheorem {definition} {Definition}
% \usepackage[table]{xcolor}

\usepackage[misc]{ifsym}
\usepackage[ruled,vlined]{algorithm2e}

\usepackage{hyperref}
% \newtheorem {definition} {Definition}
\usepackage{array, multirow, boldline}

\newcommand{\down}[1]{\ensuremath{#1\downarrow}}

\newcommand{\up}[1]{\ensuremath{#1\uparrow}}


\usepackage{graphicx}
% Used for displaying a sample figure. If possible, figure files should
% be included in EPS format.
%
% If you use the hyperref package, please uncomment the following line
% to display URLs in blue roman font according to Springer's eBook style:
% \renewcommand\UrlFont{\color{blue}\rmfamily}

\begin{document}
%
\title{Collaborative Stance Detection via Small-Large Language Model Consistency Verification}
% \title{S\textsuperscript{2}-HTC: Hierarchical Text Classification via Structural and Semantic Modeling}
%
\titlerunning{CoVer}
% If the paper title is too long for the running head, you can set
% an abbreviated paper title here SLLM



\author{Yu Yan\inst{1,3} \and
Sheng Sun\inst{1} \and 
Zixiang Tang\inst{2} \and 
Teli Liu\inst{2} \and 
Min Liu\inst{1,3,4}\thanks{Min Liu is the corresponding author. This research was supported by the National Key Research and Development Program of China (Grant No. 2021YFB2900102), Natural Science Foundation Program (Grant No. 62472410 and 62202449).}
}
% \thanks{Min Liu (liumin@ict.ac.cn) is the corresponding author. This research was supported by the Natural Science Foundation Program (Grant No. 62472410).}
\authorrunning{Y. Yan et al.}
% First names are abbreviated in the running head.
% If there are more than two authors, 'et al.' is used.

% \institute{Key Laboratory of AI Safety, Institute of Computing Technology, Chinese Academy of Sciences\\ \email{\{shenyinghan,shenhuawei\}@ict.ac.cn} \and
% School of Information and Cyber Security, People's Public Security University of China\\ \email{\{202021430009.stu,yindechun\}@ppsuc.edu.cn} \and
% Institute of Computing Technology, Chinese Academy of Sciences
% }
\institute{Institute of Computing Technology, Chinese Academy of Sciences, Beijing, China\\ \email{\{yanyu24z,sunsheng,liumin\}@ict.ac.cn} \and
People Public Security University of China, Beijing, China\\ 
\email{\{202220250034,202221610039\}@stu.ppsuc.edu.cn} 
% \email{sherryjohnson0511@163.com, 202221610039@stu.ppsuc.edu.cn}
\and
University of Chinese Academy of Sciences, Beijing, China \and
Zhongguancun Laboratory, Beijing, China
}



\maketitle              % typeset the header of the contribution
% SLM for verifying consistency in the LLM’s reasoning and classification for stance detection 
% collaboratively introducing LLM only for reasoning and using SLM to verify the reasoning correctness for stance detection.
% which balances the model performance and computational consumption
% Specifically, LLM jointly outputs texts' stance predictions and corresponding reasons. To ensure the correctness, we introduce the consistency verification mechanism, where SLM is used for verifying LLM's reasoning.
% Specifically, instead of  processing each text individually, CoVer first obtains a batch of texts' stance predictions and corresponding explanations via LLM's batch reasoning under a shared context.

\begin{abstract}
Stance detection on social media aims to identify attitudes expressed in tweets towards specific targets. Current studies prioritize Large Language Models (LLMs) over Small Language Models (SLMs) due to the overwhelming performance improving provided by LLMs. However, heavily relying on LLMs for stance detection, regardless of the cost, is impractical for real-world social media monitoring systems that require vast data analysis.
To this end, we propose \textbf{\underline{Co}}llaborative Stance Detection via Small-Large Language Model Consistency \textbf{\underline{Ver}}ification (\textbf{CoVer}) framework, which enhances LLM utilization via context-shared batch reasoning and logical verification between LLM and SLM.
Specifically, instead of processing each text individually, CoVer processes texts batch-by-batch, obtaining stance predictions and corresponding explanations via LLM reasoning in a shared context.
Then, to exclude the bias caused by context noises, CoVer introduces the SLM for logical consistency verification.
Finally, texts that repeatedly exhibit low logical consistency are classified using consistency-weighted aggregation of prior LLM stance predictions.
Our experiments show that CoVer outperforms state-of-the-art methods across multiple benchmarks in the zero-shot setting, achieving 0.54 LLM queries per tweet while significantly enhancing performance.
Our CoVer offers a more practical solution for LLM deploying for social media stance detection.

% For knowledge augmentation, CoVer employs entity linking to enrich the input data with external knowledge.

% % first employs entity linking for knowledge augmentation. Then, through consistency verification and confidence-weighted aggregation, CoVer ensures the classification accuracy of difficult samples.
% %  and then conduct the 
% % module to expand input text information, enhancing the model's understanding of target content. It then uses a batch detection mechanism where the LLM generates preliminary classification results and their rationale, optimizing resource use. 
% A consistency verification module is then applied to perform confidence analysis and adjust these results, ensuring accuracy and consistency. Samples failing verification are reprocessed in subsequent batches to further improve performance. 

% 立场检测旨在对文本中针对特定目标的态度进行分类（支持、反对、中立）。近年来，研究主要集中于利用大型语言模型（LLM）进行预测，但频繁调用大型模型以处理简单问题，导致计算资源的浪费并降低了整体效率。为此，本文提出了一种名为CoVer的模型，通过大小模型的协同工作，实现了计算效率与预测性能的平衡。CoVer首先通过知识增强模块对输入文本进行信息扩展，以提升模型对目标内容的理解。随后，采用批量检测机制，由大型语言模型生成初步分类结果及其分类依据，从而优化了计算资源的使用。对于这些初步结果及其依据，模型通过一致性检验模块进行置信度分析与校正，以确保分类结果的准确性和一致性。对于未通过一致性检验的样本，将其纳入下一批次进行重新处理，进一步提高整体性能。实验结果表明，CoVer在多个立场检测数据集上表现优于传统方法，显著降低了计算资源消耗，并提升了分类准确性，为立场检测提供了一种高效且实用的解决方案。
\keywords{Small and Large Language Model \and Collaborative Interference \and Stance Detection}
\end{abstract}
% Natural Language Processing \and

\setlength{\intextsep}{6pt plus 2pt minus 1pt}
\setlength{\textfloatsep}{6pt plus 2pt minus 1pt}

\pagenumbering{gobble}

%  and expression styles
\vspace{-5pt}
\section{Introduction} \vspace{-5pt}
Stance Detection (SD) is a powerful tool to reveal public viewpoints  across a variety of social events. It has many important applications in social research \cite{allaway2020zero,li2021p,liu2021enhancing,mohammad2016semeval} including sentiment analysis, social media monitoring and rumor detection. 
In stance detection, each text is annotated with a stance label (Favor, Against, or None) toward a specific target. Due to the informal and ambiguous nature of expressions with heterogeneous user knowledge in those vast social media tweets, it poses challenges to efficient large-scale stance detection.


According to the computational scale of backbone model, stance detection methods can be categorized as Small Language Model Based (SLM-based) and Large Language Model Based (LLM-based) methods \cite{cruickshank2023use}. 
SLM-based methods \cite{allaway2021adversarial,liang2022zero,liu2021enhancing,liu2019roberta} utilize the classifier to extract patterns from texts for stance detection. After task-specific training, SLM-based methods perform well on specific domain data, making them suitable for efficient processing \cite{zhang2022would}.
However, their reliance on predefined patterns and specific keywords \cite{liang2022jointcl,liu2021enhancing} limits their capability to generalize, dealing with implicit or subtle stances, as shown in Fig.\ref{Fig.EXA}(a).
In contrast, LLM-based methods\cite{lan2024stance,li2024mitigating,li2023stance,zhang2022would} utilize general Large Language Models (LLMs) for stance detection, leveraging their reasoning and contextual understanding capabilities to comprehend diverse expression styles and knowledge in social media tweets.
Despite the powerful strengths of LLMs, their stance detection performance still requires logical consistency verification to address issues such as hallucinations and outdated information, which can lead to inconsistencies between the LLM's reasoning and stance likelihood estimation, as shown in Fig.\ref{Fig.EXA}(b).


\begin{figure}[t]
% \label{Fig.EXA}
\footnotesize
\centering
\centering
\includegraphics[width=1.\linewidth]{pic/exa3.pdf}
\vspace{-8pt} 
\caption{Illustration of different stance detection methods for the target (\textit{iPhone 16}) via Small Language Model (SLM), Large Language Model (LLM), and Small-Large Language Model (SLLM) Collaboration. (a) SLM-based method relies on pattern extraction, achieving low computational consumption but often struggling with background knowledge understanding. (b) LLM-based method leverages LLMs' reasoning capabilities for reliable stance detection but at a high computational cost. (c) Small-Large Language Model (SLLM) Collaboration method combines the strengths of both SLM and LLM to balance computational consumption and model performance, where LLM provides advanced reasoning, and SLM performs verification.}
\label{Fig.EXA}
\end{figure}


% Some recent studies have recognized the importance of ensuring logical consistency between the LLM's stance reasoning and estimation for effective stance detection, employing techniques such as multi-agent systems \cite{lan2024stance} and chain-of-thought \cite{zhang2023investigating,zhang2023logically} to correct these inconsistencies through iterative use of the LLM.
Some recent studies have highlighted the importance of ensuring logical consistency between the LLM's stance reasoning and estimation for effective stance detection. These studies employ techniques such as multi-agent systems \cite{lan2024stance} and chain-of-thought \cite{zhang2023logically,zhang2023investigating} to address inconsistencies through iterative use of the LLM.
However, these methods overlook that stance detection is a time-sensitive task for large-scale data analysis, requiring both efficiency and accuracy. Repeatedly invoking LLM for a single short tweet is clearly cost-prohibitive.

To reduce redundant LLM utilization spent on calibrating logical inconsistencies, we innovatively put forward the insight of Small-Large Language Model (SLLM) Collaboration method, where the SLM collaborates with the LLM to ensure logical consistency in reasoning and stance likelihood estimation.
As shown in Fig.\ref{Fig.EXA}(c), consider the tweet ``\textit{The battery capacity is 3,561 mAh. I’m stunned!}", regarding the target ``\textit{iPhone 16}". The LLM recognizes that``\textit{stunned}" conveys surprise but interprets it critically to low battery capacity, thus assigning an ``\textit{Against}" stance. 
For the LLM, its strength lies in its advanced reasoning and contextual understanding, which allows the LLM to explain background cues, making nuanced stance predictions even when sentiments are implicitly expressed.
Then, the SLM is used to check that LLM's interpretation aligns with explicit indicators in the tweet, ensuring consistency between the reasoning and stance likelihood estimation.
For the SLM, its strength lies in its ability to quickly recognize explicit patterns, which enables SLM to verify the consistency of LLM’s predictions by checking for alignment with straightforward cues.

% The Small-Large Language Model Collaboration method provides a more balanced framework for computational consumption and model performance in stance detection.






Building on these insights, we propose the \textit{\textbf{\underline{Co}}llaborative Stance Detection via Small-Large Language Model Consistency \textbf{\underline{Ver}}ification} (\textbf{CoVer}) framework, which combines the LLM's reasoning capabilities with the SLM's verification efficiency.
CoVer first reconstructs the context of tweets through knowledge augmentation and irrelevant context filtering, ensuring clear and unbiased stance reasoning. It then processes texts batch-by-batch, feeding each batch into the LLM for simultaneous reasoning, allowing for efficient context reuse.
Finally, CoVer employs the SLM to verify the logical consistency of the LLM’s reasoning for stance classification. For texts exhibiting repeated low consistency, CoVer performs consistency-weighted aggregation of likelihood scores for final classification.
We perform extensive Zero-Shot Stance Detection (ZSSD) experiments on classic benchmarks, including SemEval-2016, VAST, and P-Stance. Experimental results show that CoVer outperforms state-of-the-art methods with only 0.54 LLM queries per text using GPT-4o-mini, highlighting its performance and resource efficiency.

The major contributions of our study are as follows:

% To reduce redundant LLM utilization spent on calibrating logical inconsistencies, 


\begin{itemize}
% \vspace{-5pt}semantic
    % \item To balance the effectiveness and efficiency of stance detection,
    \item We introduce CoVer, a Small-Large Language Model collaboration framework that utilizes the strengths of the LLM for reasoning and minimizes unnecessary re-queries of the LLM using the SLM, achieving the balancing of computational consumption and model performance.
    % CoVer utilizes the strengths of both the LLM and SLM to improve stance detection efficiency and reliability.
    % In CoVer, the LLM performs stance reasoning on batch inputs, while the SLM verifies the reasoning-prediction consistency.
    % \vspace{-5pt}
    \item To further improve LLM utilization, we employ a batch-by-batch LLM reasoning approach in CoVer, which uses the LLM to process multiple texts with a single LLM query. Experiments indicate that CoVer not only reduces query overhead but also enhances performance through efficient context reuse by leveraging shared contextual cues across these texts.
    \item Our CoVer demonstrates significant performance improvements over several state-of-the-art methods across three classic benchmarks with only 0.54 LLM queries per tweet on zero-shot stance detection.
    % highlighting its effectiveness and efficiency in stance detection on social media.
\end{itemize}

    % \item To further improve LLM utilization, we employ a batch-by-batch processing approach in CoVer, enabling the LLM to leverage shared contextual cues across multiple texts. This approach allows us to detect multiple texts with a single query, significantly enhancing efficiency.
    % \item To further improve LLM utilization, we employ LLM to batch-by-batch processing the texts in CoVer, allowing the LLM to leverage shared contextual cues across multiple texts.
    % which also ensure the robustness of LLM's internal classification criteria.
    % \item To further improve LLM utilization, we employ a batch-by-batch processing approach in CoVer, which also ensure the robustness of LLM's internal classification criteria due to such shared contextual cues across multiple texts. 
    % leverage shared contextual cues across multiple texts, which enhances the context utilization and robustness of LLM's internal classification criteria. 
% By optimizing the loss computation mechanism, S\textsuperscript{2}-HTC ensures effective learning of lower-level label features.
    % \vspace{-5pt}

% To this end 
% which balances the effectiveness and efficiency through collaborative work between LLM and SLM. 
% Then, to fully reuse the context, CoVer groups a batch of tweets as input to LLM for reasoning simultaneously. 

% To reduce redundant LLM utilization spent on calibrating logical inconsistencies, we propose \textit{\textbf{\underline{Co}}llaborative Stance Detection via Small-Large Language Model Consistency \textbf{\underline{Ver}}ification} (\textbf{CoVer}) framework, which combines LLM’s reasoning capabilities with SLM’s verification efficiency.
% Specifically, to obtain a clear context for unbiased stance reasoning, CoVer first reconstructing the context of tweets via knowledge augmentation and irrelevant context filtering. 
% Then, to fully reuse the context, CoVer processes texts batch-by-batch, feeding each batch into the LLM for simultaneous reasoning.
% Finally, CoVer leverages an SLM to verify the logical consistency of the LLM's reasoning for stance classification. For texts that repeatedly exhibit low consistency, CoVer classifies them by performing a consistency-weighted aggregation of the likelihood scores.
% We conduct extensive Zero-Shot Stance Detection (ZSSD) experiments on the classic benchmarks, SemEval-2016, VAST, and P-Stance. Experimental results have shown that our CoVer outperforms existing state-of-the-art methods on effectiveness with only 0.54 LLM queries per text using GPT-4o-mini.

\vspace{-10pt}
\section{Problem Statement}
Zero-Shot Stance Detection (ZSSD) \cite{allaway2020zero,li2021p,liu2021enhancing,mohammad2016semeval} is defined as the task of classifying the stance (\textit{Favor}, \textit{Against}, \textit{None}) expressed in a given tweet towards a specific target without providing any specific training data or reference samples about the target. 
In our study, for a given raw tweet \( x_{\text{raw}} \) toward target $t$, we pre-process it as the augmented tweet \( x \), and develop a Large Language Model (LLM) and Small Language Model (SLM) collaboration framework to classifying the stance label $y$ for $x$ in zero-shot setting.
% using the training data about the target $t$.


\vspace{-10pt}
\section{Methodology}
\vspace{-6pt}
In this section, we introduce our \textit{\textbf{\underline{Co}}llaborative Stance Detection via Small-Large Language Model Consistency \textbf{\underline{Ver}}ification} (\textbf{CoVer}) framework, which combines the strengths of LLM and SLM to achieve balanced computational consumption and model performance in stance detection tasks. The overall structure of CoVer is shown in Fig.\ref{Fig.overlook} and the workflow of our CoVer is shown in Algorithm \ref{workflow}.

\begin{figure*}[h]
	\centering
		\includegraphics[width=1.\linewidth]{pic/SDSLM1.pdf}
        \vspace{-12pt}
	\caption{The overall structure of our CoVer. Specifically, in Context Reconstruction (\S\ref{4.1}), CoVer first uses SLM to preprocess the input tweets by filtering out irrelevant contextual information and incorporating relevant knowledge to obtain the context-augmented tweets. Then, in batch reasoning (\S\ref{4.2}), CoVer uses LLM to perform stance reasoning and estimate the corresponding stance likelihood on a batch of tweets. Finally, in consistency verification (\S\ref{4.3}), CoVer uses SLM to verify the alignment between the LLM's reasoning and stance predictions. Those tweets with repeatedly low consistency will be classified through the consistency-weighted aggregation of LLMs' prior predictions. The SLM classifier is trained (\S\ref{4.4}) on LLM batch reasoning data.}
    % \vspace{-18pt}
	\label{Fig.overlook}
\end{figure*}


\vspace{-10pt}
\subsection{Context Reconstruction}\label{4.1}
% \vspace{-6pt}
To ensure effective reasoning, it’s crucial to optimize the input context for the LLM, especially when processing multiple tweets within a limited context window. 
Therefore, we employ Context Reconstruction to attach external knowledge and then filter out non-relevant content to ensure LLMs' unbiased reasoning.

\vspace{-6pt}
\subsubsection{Knowledge Augmentation}
To identify the stance of those tweets with implicit expressing, we introduce external knowledge to enrich the context.

Given the external knowledge base \( \mathcal{K} = \{ (k_0, d_0), (k_1, d_1)...\}\), where \( k_i \) is the knowledge entity, and \( d_i \) refers to the description associated with knowledge \( k_i \), we employ entity linking match the knowledge.
For those matched knowledge entries and corresponding descriptions, we concatenate them with the raw tweet \( x_{\text{raw}} \) to create an knowledge augmented tweet \( x_{\text{k}} \):

\begin{equation}
\small
    x_{\text{k}} = x_{\text{raw}} \oplus \mathcal{D}, \mathcal{D} = \{ k_i\oplus d_i \mid (k_i, d_i) \in \mathcal{K} \text{ and } k_i \in x_{\text{raw}} \},
\end{equation}
where  \( \oplus \) denotes the string concatenation, $\mathcal{E}$ is the set of matched knowledge via entity linking.


% defined as:
%In social media, most of lengthy tweets \cite{allaway2020zero} where only a few key sentences convey the stance, the sentence filtering module aims to removing redundant information in tweets to enhance the LLM’s reasoning efficiency. 

% However, An essential step for stance variance computing is to estimate the stance $P(y|t)$ in text pre-processing stage,
% To further refine $\text{SD}_{x_{\text{k}}}$ in the pre-processing stage, 

\vspace{-6pt}
\subsubsection{Sentence Filtering}
To determine a sentence or the knowledge weather contributes to externalizing the stance expression of the tweet, we measure its impact through \textbf{Stance Entropy (SE)}. A lower entropy for tweet \( x \) indicates more discriminative stance labels, suggesting the processed text effectively externalizes the stance. Entropy for tweet \( x \) is calculated as:

\vspace{-3pt}
\begin{equation}
\label{SE}
\small
    \text{SE}_x = -\sum_{y \in \mathcal{Y}} \hat{P}(y|x,t) \log \hat{P}(y|x,t),
\end{equation}
\vspace{-3pt}
where \( \mathcal{Y} \) is the stance label set \{Favor, Against, None\}. A lower SE implies the tweet better externalizes its stance expression, as the stance likelihood is more concentrated on a specific stance.

% we measure its impact through \textbf{stance variance} (SD). A higher variance of tweet $x$ indicates more discriminative stance labels, suggesting the processed text effectively externalizes the stance.
% SD for tweet $x$ is calculated as:
% \begin{equation}
% \label{SD}
%     \text{SD}_x=\sigma^2=\frac{1}{|\mathcal{Y}|} \sum_{y \in \mathcal{Y}} (\hat{P}(y|t,x) - \mu)^2, \mu = \sum_{y \in \mathcal{Y}} \hat{P}(y|t,x)/|\mathcal{Y}|,
% \end{equation}
% where $\mathcal{Y}$ is the stance label set \{Favor, Against, None\}. A larger variance implies the tweet better externalizes its stance expression.

To refine $x_{\text{k}}$, we split the knowledge augmented tweet $x_{\text{k}}$ into the sentence set $X_{\text{k}}=\{ s_1, s_2, \dots \}$ based on stance entropy. 
Our goal of sentence filtering is defined as:

\vspace{-3pt}
\begin{equation}
\small
X = \arg\max_{X \subseteq X_{\text{k}}} \text{SE}_{x}, \quad x=\bigoplus_{s_i \in X} s_i,
\end{equation}
where \( x \) is the refined tweet concatenated from the optimal subset of sentences \( X \)  that maximizes \( \text{SE}_{x} \).
We filter the irrelevant sentences according to the change in stance variance after the removal of each sentence.
Specifically:

\begin{itemize}
    \item \textbf{Redundant Sentence}: If removing a sentence \( s_i \) results in an obvious decrease in stance entropy \( \text{SE}_{x \setminus s_i} \), i.e., \textbf{\( \text{SE}_{x} \geq \text{SE}_{x \setminus s_i} \)}, this suggests that \( s_i \) is redundant or has minimal impact on clarifying the stance. Thus, \( s_i \) is excluded from the tweet.
    \item \textbf{Relevant Sentence}: If removing a sentence \( s_i \) leads to a significant increase in stance entropy \( \text{SE}_{x \setminus s_i} \), i.e., \textbf{\( \text{SE}_{x} < \text{SE}_{x \setminus s_i} \)}, this indicates that \( s_i \) contributes meaningfully to the stance expression, and it is retained.
\end{itemize}

To calculate the $\text{SE}_{x}$ for tweet $x$, we estimate stance likelihood \( \hat{P}(y|x,t) \). Specifically, we construct the stance phrase \( s_y(t) \) that clearly expresses stance toward the target $t$, e.g., ``My stance toward \{target\} is ``\{stance\}". Then, we use the semantics similarity between tweets \( x \) and the stance phrases to estimate the $\hat{P}(y|x,t)$ as:
\vspace{-3pt}
% \begin{equation}
%     \hat{P}(y|x,t) = \text{sim}(\text{embedder}(x), \text{embedder}(s_y(t))),
% \end{equation}
\begin{equation}
\small
    \hat{P}(y|x, t) = \frac{\exp(\text{sim}(h_{x}, h_{s_y}))}{\sum_{y' \in \mathcal{Y}} \exp(\text{sim}(h_{x}, h_{s_{y'}}))},
\end{equation}
where we use the embedder (SLM, e.g., BGE-M3 \cite{bge-m3}) for text semantic representation, \( h_x \) is the embedding of the tweet \( x \), \( h_{s_y} \) is the embedding of the stance phrase \( s_y(t) \), and \( \text{sim}(\cdot, \cdot) \) is the cosine similarity between two embeddings.


% To calculate the $\text{SE}_{x_{\text{k}}}$ for the knowledge augmented tweet $x_{\text{k}}$, we estimate stance likelihood \( \hat{P}(y|x_{\text{k}},t) \). Specifically, we construct the stance phrase \( s_y(t) \) that clearly expresses stance toward the target $t$, e.g., ``My stance toward \{target\} is ``\{stance\}". Then, we use the semantics similarity between tweets \( x_{\text{k}} \) and the stance phrases to estimate the $\hat{P}(y|x_{\text{k}},t)$ as:

% % \begin{equation}
% %     \hat{P}(y|x,t) = \text{sim}(\text{embedder}(x), \text{embedder}(s_y(t))),
% % \end{equation}
% \begin{equation}
%     \hat{P}(y|x_{\text{k}}, t) = \frac{\exp(\text{sim}(h_{x_{\text{k}}}, h_{s_y}))}{\sum_{y' \in \mathcal{Y}} \exp(\text{sim}(h_{x_{\text{k}}}, h_{s_{y'}}))},
% \end{equation}
% where we use the embedder (SLM, e.g., BGE-M3 \cite{bge-m3}) for text semantic representation, \( h_x \) is the embedding of the tweet \( x \), \( h_{s_y} \) is the embedding of the stance phrase \( s_y(t) \), and \( \text{sim}(\cdot, \cdot) \) is the cosine similarity between two embeddings.

\vspace{-6pt}
\subsection{Batch Reasoning}\label{4.2}
\vspace{-3pt}
% 为了提高大模型在立场检测中的上下文利用率，我们会将一批的tweet组建为LLM input。
To enhance the LLM's utilization of context in stance detection, we group a batch of tweets as LLM input and classify the stance by reasoning.
By processing a batch of tweets together, LLM gains access to a broader context that helps it understand relations between tweets, especially when tweets share a common theme or topic. Furthermore, the shared context also enhances the robustness and consistency of LLM’s predictions across similar stance expressions.

To conduct the batch reasoning, we guide LLM to predict the stance likelihood $P_{\text{LLM},i}$ and output corresponding explanation \( e_i\) for each tweet $x_i$ in the text batch $\mathcal{B}=\{(x_0,t_0),(x_1,t_1),...(x_B,t_B)\}$: 
% by the following query $Q_R$:

\begin{equation}
\label{peoutput}
\small
    \{(P_{\text{LLM},i}, e_i)\}_{i=1}^B = {\text{LLM}}(\text{prompt} \oplus \mathcal{B}),
\end{equation}
\begin{equation}
\small
    P_{\text{LLM},i}=P(y | x_i, t_i, \mathcal{B}),
\end{equation}
where \( P(y | x_i, t_i, \mathcal{B}) \) is the conditional probability of stance output by LLM for tweet \( x_i \) with respect to target \( t_i \) and the context of text batch \( \mathcal{B} \), the prompt is the task instruction for stance detection. 
Shared context improves the model’s ability to maintain consistency across similar stance expressions.




% \begin{center}
\begin{figure}[t]
\centering
% \small

% \resizebox{0.8\textwidth}{!}{
\begin{tcolorbox}[width=.9\columnwidth, % Set the width to 90% of a column width
                  colback=gray!0, % Background color gray with 10% opacity
                  colframe=black, % Border color black
                  left=1mm, % Left margin inside the box
                  right=1mm, % Right margin inside the box
                  top=1mm, % Top margin inside the box
                  bottom=1mm, % Bottom margin inside the box
                  boxsep=1mm, % Space between text and box boundary
                  arc=0mm, % Size of the rounded corners
                  boxrule=1pt, % Thickness of the border
                  coltitle=black,
                  colbacktitle=gray!10,
                  title=Batch Reasoning Prompt] 

{You are a stance detection assistant...}

\textbf{Texts and Targets:}
\begin{verbatim}
{text_target_pairs}
\end{verbatim}
% {Please evaluate whether each text holds a favor, against, or (neutral/no stance expressed) stance toward its corresponding target.}
{... Please respond in the following JSON format:}
\begin{verbatim}
{
    "results": [
        {
            "text_id": Text ID,
            "explanation": "A brief explanation",
            "favor_probability": probability (0 to 1),
            "neutral_probability": probability (0 to 1),
            "against_probability": probability (0 to 1)
        },
        ...
    ]
}
\end{verbatim}

\end{tcolorbox}
% }
% \end{center}
\end{figure}

\vspace{-5pt}
\subsection{Consistency Verification}\label{4.3}
\vspace{-5pt}
However, due to the fact that cross-influence of contextual information can potentially lead LLM to mistakenly apply the context of one tweet to another, it is important to exclude such negative influence caused by the shared context.

% can independently and faithfully reflect its predictions
To verify LLM's predictions, we use the SLM as a third-party model to observe only the explanation for stance classification and compare the stance entropy of the prediction distribution before and after LLM reasoning.
Specifically, for the corresponding explanation \( e_i \) generated by LLM for the tweet $x_i$ from formula (\ref{peoutput}), it serves as the input to SLM:

\begin{equation}
\small
    P_{\text{SLM},i}=P(y | e_i, t_i)=\text{SLM}([CLS]e_i[SEP]t_i[SEP]),
% t_i[SEP]
\end{equation}
where \( P_{\text{SLM},i} = P(y | e_i, t_i) \) is the stance likelihood produced by the SLM based solely on the explanation \( e_i \) for tweet \( x_i \) toward target $t_i$.

Then, we calculate the stance entropy of explanation $e_i$ and tweet $x_i$, denoted as $SE_{e_i}$ and $SE_{x_i}$, and stance likelihood similarity between SLM and LLM using the cosine similarity, denoted as $\text{sim}(P_{\text{LLM},i}, P_{\text{SLM},i})$. 
Based on the above variables, our consistency verification mechanism is as follows:

% \begin{equation}
%     \text{sim}(P_{\text{LLM},i}, P_{\text{SLM},i}) = \frac{P_{\text{LLM},i} \cdot P_{\text{SLM},i}}{\|P_{\text{LLM},i}\| \|P_{\text{SLM},i}\|},
% \end{equation}

% Then, we Our consistency verification mechanism is as follows:

\begin{itemize}
    \item \textbf{Invalid Prediction: }If LLM reasoning can not expose the stance, i.e., \textbf{$SE_{e_i} > SE_{x_i}$},the prediction and corresponding explanation generated by LLM for $x_i$ is invalid. $x_i$ will be re-classified.
    \item \textbf{Valid Prediction: }If LLM reasoning exposes the stance and the prediction distribution from SLM and LLM is consistent, i.e., \textbf{$SE_{e_i} \leq SE_{x_i}$ and $\text{sim}(P_{\text{LLM},i}, P_{\text{SLM},i}) \geq  \delta$}, the prediction and corresponding explanation generated by LLM for $x_i$ is valid. $P_{\text{LLM},i}$ will be used as the predicted result for tweet $x_i$.
    \item \textbf{Referable Prediction: }If LLM reasoning exposes the stance but the prediction distribution from SLM and LLM is inconsistent, i.e., \textbf{$SE_{e_i} > SE_{x_i}$ but $\text{sim}(P_{\text{LLM},i}, P_{\text{SLM},i}) <  \delta$}, the prediction and corresponding explanation generated by LLM for $x_i$ is referable. 
    $x_i$ will be re-classified and $P_{\text{LLM},i}$ will be used for weighted-aggregation as the final prediction if the stance of $x_i$ still can not be correctly predicted after $M$ round classifying.
\end{itemize}

After \( M \) rounds of re-classification, for those tweets only with invalid predictions, a stronger LLM will be used for classifying. Those tweets only with referable predictions will be predicted by consistency-weighted aggregation as:

\begin{equation}
\small
P_{\text{Agg}}(y | x_i, t_i) = \sum_{j=1}^{M'} w_j \cdot P_{\text{LLM},i}^{(j)},    
\end{equation}
where \( w_j = \text{sim}(P_{\text{LLM},i}^{(j)}, P_{\text{SLM},i}^{(j)})\) is the weight assigned to the \( j \)-th round prediction. This weighted aggregation ensures a robust decision for those difficult classifying tweets. $M'$ is the number of referable predictions for tweet $x_i$.

% 为了取得一个针对LLM的推理进行验证的模型，我们基于预训练的BERT模型进行微调取得。为了确保模型能学习到正确的推理模式，我们收集了LLM的正确推理数据进行训练。我们的训练损失如下：
\subsection{Reasoning-Augmented Training}
\label{4.4}
\vspace{-4pt}
To ensure the SLM classifier in consistency verification (\S \ref{4.3}) is capable of verifying the correctness of LLM reasoning, we fine-tune a BERT model \cite{liu2019roberta} as the classifier. To ensure that the classifier learns the correct reasoning patterns, we trained it on data collected from LLMs' correct reasoning explanations. We introduce the multi-task learning framework combining the cross-entropy and the contrastive loss \cite{liang2022jointcl} as:
\vspace{-4pt}
\begin{equation}
\small
\mathcal{L} = \mathcal{L}_{CE} + \lambda \cdot \mathcal{L}_{C}\label{eq:final},
\end{equation}

% |\mathcal{Y}|
\begin{equation}
\small
\mathcal{L}_{CE} = -\frac{1}{|{\mathcal{B}}|}\sum_{i=1}^{|{\mathcal{B}}|}\sum_{j=1}^{|\mathcal{Y}|}y_{i,j}\log(P_{i,j}),
\end{equation}

\begin{equation}
\small
\mathcal{L}_{C} = -\frac{1}{|{\mathcal{B}}|} \sum_{x_i \in \mathcal{B}} \ell_{c}(\textbf{h}_{x_i}),
\end{equation}

\begin{equation}
\small
\ell_{c}(\textbf{h}_{x_i}) = \log \frac{\sum_{(x_i, x_j^+)\in \mathcal{P}_i}\exp(\text{sim}({\textbf{h}_{x_i}}, {\textbf{h}_{x_j}^+}) / \tau_s)}{\sum_{x_j \in \mathcal{B}\backslash {x_i}} \exp(\text{sim}({\textbf{h}_{x_i}}, {\textbf{h}_{x_j}}) / \tau_s)},
\end{equation}
where $\lambda$ is weight hyperparameter, \( \tau_s \) is temperature hyperparameter, $\textbf{h}_{(\cdot)}$ is the embedding of tweet output by SLM. 
\(\mathcal{B} =\{x_0, x_1,...\}\) is mini-batch training data, and \(\mathcal{B}\backslash {x_i}\) is \(\mathcal{B}\) excluding sample \(x_i\).
\(\mathcal{P}_i = \{({{x_i}}, {{x_0}^+}),({{x_i}}, {{x_1}^+}),...\}\) is the set of positive pairs for $x_i$, which consists of samples with the same label in mini-batch.

\vspace{-5pt}
\subsection{\textbf{Workflow of CoVer}}
\vspace{-2pt}
To provide a clear understanding of the workflow of CoVer, we present a detailed pseudocode in Algorithm~\ref{workflow}, which focuses on the stages of reasoning and stance classification of CoVer.

\begin{algorithm}[t]
\label{workflow}
\SetAlgoLined
\KwIn{Text Dataset $\mathcal{X} = \{ (x_i, t_i) \}_{i=1}^N$}
\KwOut{Stance labels $\mathcal{L} = \{ l_i \}_{i=1}^N$}


\While{$\text{round} < M$}{
Divide $\mathcal{X}$ into batches $\{\mathcal{B}_1, \mathcal{B}_2, \dots \}$\;
\textbf{Context Reconstruction}(\S\ref{4.1})  Refine each tweet within text batch \( \mathcal{B} \);


\textbf{Batch Reasoning}(\S\ref{4.2}) $\{(p_{\text{LLM},j}, \text{reason}_j)\}_{j=1}^B \leftarrow \text{LLM}(\text{prompt}\oplus\mathcal{B})$\;

\textbf{Consistency Verification}(\S\ref{4.3}) \\
\ForEach{$(p_{\text{LLM},j}, \text{reason}_j)$}{
    $ s_j  \leftarrow \text{sim}( p_{\text{SLM}} , p_{\text{LLM}} )$, where $p_{\text{SLM},j} \leftarrow \text{SLM}(\text{reasons}_j)$\;
    
    \If{$s_j$ exceeds threshold}{
        Add $l_j = \arg\max(p_{\text{LLM},j})$ to $\mathcal{L}$\;
    }\Else{
        Retain for re-detect\;
}
}
Update $\mathcal{X}$ by removing classified instances, $round+=1$\;
}

Apply weighted aggregation on retained instances to finalize $\mathcal{L}$\;

\Return{$\mathcal{L}$}
\caption{The workflow of CoVer}
\end{algorithm}
% $(x_j,t_j,p_{\text{LLM},j},s_j)$




\section{Experiments}

% \vspace{-5pt}
\subsection{Experiment Settings}
\label{ES}
% \vspace{-5pt}
\subsubsection{Datasets}

% 为了展现CoVer方法面对不同话题的通用性，我们在三个数据集上进行实验。 https://anonymous.4open.science/r/CoVer-EC42
To demonstrate the effectiveness of CoVer, we perform experiments of zero-shot stance detection on three benchmarks: \textbf{Sem16 (SemEval-2016)} \cite{mohammad2016semeval}, \textbf{P-stance} \cite{li2021p}, and \textbf{VAST} \cite{allaway2020zero}. For Sem16 and P-stance, we use the leave-one-target-out evaluation setup. For the VAST dataset, we use their original zero-shot dataset settings. We adhere to standard train, validation, and test splits in alignment with previous studies \cite{lan2024stance,li2023stance,li2024mitigating}.




\vspace{-10pt}
\subsubsection{Evaluation Metrics}
% \vspace{-5pt}
We adopt the typical metric employed in stance detection \cite{mohammad2016semeval,sobhani2017dataset,xu2016overview} to evaluate the effectiveness of different methods, denoted as $F_{\text{AVG}}$. 
For sem16 and P-stance, $F_{\text{AVG}}$ is computed by averaging the F1-scores of the ``Favor" and ``Against" categories.
For VAST, $F_{\text{AVG}}$ is computed by averaging the F1-scores of ``Pro", ``Con" and ``Neutral" categories. 
To evaluate different methods' utilization efficiency of LLMs, we use \( Q_{\text{AVG}} \) to measure the average query count required for one sample stance detection.




\vspace{-10pt}
\subsubsection{Experimental Setups}

% CoVer中的Embedder SLM使用BAAI/bge-m3通用嵌入模型。知识来自于使用GPT-4o对训练数据集中出现的concepts进行解释而得到。
% CoVer一共使用LLM进行3轮的迭代的批量检测，每轮迭代的批大小分别为8，4，1，使用的模型分别是Qwen2.5-7B，Qwen2.5-32B，Qwen2.5-72B，模型温度均设置为0。
% 数据批是从测试数据集中随机打乱后组成的。
% CoVer中的classifier SLM使用Roberta模型，训练数据来自于LLM在Sem16、P-stance、VAST训练集上预测正常的样本组成。对比损失权重为0.1.
% LLM和SLM的一致性阈值为0.6

In CoVer\footnote{Our code is available at \url{https://github.com/qzqdz/CoVer}.}, the SLM embedder employs the general-purpose embedding model BGE-M3 \cite{bge-m3}. Knowledge is derived from the description of concepts in the training data, generated using GPT-4o. 
CoVer performs batch reasoning iteratively with LLMs across three rounds. The batch sizes for each round are 8, 4, and 1, utilizing gpt-4o-mini-2024-07-18 as LLM with a model temperature set to 0.1 for all iterations, GPT-4o is used for the final invalid prediction. Test data batches are randomly shuffled.
The classifier SLM in CoVer uses a Roberta \cite{liu2019roberta}, trained on samples predicted correctly by the LLM from the Sem16, P-Stance, and VAST training sets. The contrastive loss weight is set to 0.1. 
The consistency threshold between the LLM reasoner and SLM classifier is set to 0.9.
For SLM training, $\lambda$ is 0.1, $\tau_s$ is 0.05, batch size is 32.

% For the English dataset, our base model is RoBERTa-tweet model \cite{dimosthenis-etal-2022-twitter}. For the Chinese dataset, our base model is RoBERTa \cite{chinese-bert-wwm}. The learning rate is set at 2e-5 with a warmup proportion of 0.1. 
% The training process incorporates an early stopping mechanism to prevent overfitting, with the model's performance being evaluated every 100 steps. The total number of epochs for training is 15. A multi-head attention mechanism with 2 attention heads is employed within the layer-text context. The batch size for training is set to 32, and sequences are truncated or padded to a fixed length of 88 tokens.
% Each Aspect-Augmented Tweet vector undergoes a dropout layer with a dropout rate of 0.3 before any further processing. For each target, the model dynamically selects the aspects for augmentation ranging from 3 to 5 based on performance measures during validation.
% We use the GPT-4 \cite{achiam2023gpt} for aspect extraction. 
% % Fifty samples with the same stance label, i.e., Favor or Against, are input each time for aspect extraction. 
% For OAE, $o$ is 1, $m$ is 50, $r$ is 5, $k$ is 20, $n''$ is 20 for Sem16 and NLPCC-2016, 30 for P-stance,
% The aspects obtained by LLM under each target are between 15-30 items. 
% For loss calculation, $\lambda_1$ is 1, $\lambda_2$ is 0.1, $\gamma$ is 0.1.






% RoBERTa
% BERT
% PET-BERT
% PET-GPT2
\vspace{-12pt}
\subsubsection{Baseline Methods}
\label{BM}
% \vspace{-5pt}
We provide an overview of the baseline methods for comparison in our experiments, including {Small Language Model Based Methods}: 
1)\textbf{ BERT-GCN} \cite{liu2021enhancing} leverages commonsense knowledge from ConceptNet to improve the model’s generalization.
2)\textbf{ TOAD} \cite{allaway2021adversarial} uses adversarial learning to improve zero-shot stance detection, enabling effective stance classification on unseen targets.
3)\textbf{ JointCL} \cite{liang2022jointcl} uses joint contrastive learning framework.
4)\textbf{ PT-HCL} \cite{liang2022zero} leverages hierarchical contrastive learning to distinguish between target-invariant and target-specific stance features.
5)\textbf{ TGA-Net} \cite{liang2022zero} applies topic-grouped attention to capture relationships between targets.
6) \textbf{TarBK-BERT} \cite{zhu2022enhancing} leverages targeted background knowledge from Wikipedia to improve performance.
{Large Language Model Based Methods}:
7) \textbf{KASD} \cite{li2023stance} leverages episodic knowledge from Wikipedia and discourse knowledge for knowledge augmentation.
8) \textbf{COLA} \cite{lan2024stance} uses a multi-agent framework to debate the stance of tweets.
9) \textbf{LC-CoT} \cite{zhang2023logically} employs the structured chain-of-thought approach for stance detection.
10) \textbf{Task-Des} \cite{li2024mitigating} uses task-related descriptions for stance detection.
11) \textbf{Task-CoT-Demo} \cite{li2024mitigating} uses the task description with 4-shot chain-of-thought demonstration.



\vspace{-8pt}
\subsection{Experimental Results}
\label{MR}
We aim to answer the following research questions (RQs) by conducting a series of experiments:
\begin{itemize}
    \item \noindent \textbf{RQ1:} Does CoVer demonstrate superior effectiveness and adaptability compared to existing state-of-the-art stance detection methods?
    \item \noindent \textbf{RQ2:} If CoVer outperforms existing methods, what mechanisms contribute to its success?
    \item \noindent \textbf{RQ3:} Given that CoVer employs multiple re-generations strategy for those samples with low consistency, does this imply lower efficiency compared to other LLM-based methods?
\end{itemize}
% \noindent \textbf{RQ1:} Does CoVer demonstrate superior effectiveness and adaptability compared to existing state-of-the-art stance detection methods?

% \noindent \textbf{RQ2:} If CoVer outperforms existing methods, what mechanisms contribute to its success?

% \noindent \textbf{RQ3:} Given that CoVer employs multiple re-generations strategy for those samples with low consistency, does this imply lower efficiency compared to other LLM-based methods?


% Is every component in CoVer contributory to performance enhancement?


\subsubsection{Baseline Comparison (RQ1)} To answer RQ1, the baseline comparison experiment is conducted. As evidenced in Table \ref{tab.RES} and Table \ref{tab.RES1}, CoVer attains a comparable performance to the baselines on cross-target datasets. Specifically, CoVer achieves the best performance on sem16 and P-stance by outperforming the top existing methods with 1.98\% and 2.44\% on average, and outperforming all large language model based methods on VAST, showcasing robust effectiveness and adaptability across datasets. 

% of different methods
\begin{table}[t]
\caption{Zero-Shot Stance Detection Experiments on Sem16 and VAST datasets. The best results are in \textbf{bold} and the second-best results are in \underline{underline}. Results with * denote that CoVer significantly outperforms baselines with the p-value $<$ 0.05.}
\vspace{-8pt}
\label{tab.RES}
\centering
\begin{tabular}
% @{\hspace{0.8em}}
{lc@{\hspace{0.6em}}c@{\hspace{0.6em}}c@{\hspace{0.6em}}c@{\hspace{0.6em}}c@{\hspace{0.4em}}cc}
\Xhline{1pt}
\multirow{2}{*}{Model} & \multicolumn{6}{c}{Sem16 (\%)} & \multicolumn{1}{c}{VAST (\%)} \\ \cline{2-8} 
                       & HC    & FM    & LA    & A     & CC    & Avg   & All       \\ \hline
\multicolumn{8}{l}{\textbf{Small Language Model Based Methods}}                   \\
BERT-GCN              & 50.00 & 44.30 & 44.20 & 53.60 & 35.50 & 48.03 & 68.60      \\
TOAD                  & 51.20 & 54.10 & 46.20 & 46.10 & 30.90 & 49.40 & 41.00      \\
JointCL               & 54.80 & 53.80 & 49.50 & 54.50 & 39.70 & 53.15 & 72.30      \\
PT-HCL                & 54.50 & 54.60 & 50.90 & 56.50 & 38.90 & 54.13 & 71.60      \\
TGA-Net               & 49.30 & 46.60 & 45.20 & 52.70 & 36.60 & 48.45 & 66.60      \\
TarBK-BERT            & 55.10 & 53.80 & 48.70 & 56.20 & 39.50 & 53.45 & 73.60      \\
KASD-BERT             & 64.78 & 57.13 & 51.63 & 55.97 & 40.11 & 57.38 & \textbf{76.82}      \\ \hdashline
\multicolumn{8}{l}{\textbf{Large Language Model Based Methods}}                   \\
KASD-LLaMA-2          & 77.70 & 65.57 & 57.07 & 39.55 & 39.55 & 55.89 & 43.42      \\
LLaMA-2-Task-Des      & 73.79 & 71.03 & 66.00 & 60.44 & 61.91 & 66.63 & 68.54      \\
LLaMA-2-CoT-Demo      & 72.09 & \textbf{73.83} & 66.50 & 57.58 & 65.11 & 67.02 & 67.28      \\
GPT-3.5-Turbo-Task-Des & 72.70 & 71.71 & 67.89 & 28.87 & 59.36 & 60.11 & 50.21      \\
GPT-3.5-Turbo-CoT-Demo & 78.69 & 73.22 & \textbf{72.24} & \underline{65.15} & \underline{71.54} & \underline{72.17} & 70.14      \\
KASD-ChatGPT          & 80.32 & 70.41 & 62.71 & 63.95 & 55.83 & 66.64 & 67.03      \\
COLA                  & 75.90 & 69.10 & 71.00 & 62.30 & 64.00 & 68.46 & 73.40      \\
LC-CoT                & \textbf{82.90} & 70.40 & 63.20 & -     & -     & -     & 72.50      \\ \hdashline
\multicolumn{8}{l}{\textbf{Small-Large Language Model Based Method}}             \\
CoVer (ours)          & \underline{81.17}* & \underline{73.35} & \underline{72.01}* & \textbf{70.40}* & \textbf{73.81} & \textbf{74.15}* & \underline{74.79}      \\ \Xhline{1pt}
\end{tabular}
\end{table}


% of different methods
\begin{table}[t]
\caption{Zero-Shot Stance Detection Experiments on the P-stance dataset. The best results are in \textbf{bold} and the second-best results are in \underline{underline}. Results with * denote that CoVer significantly outperforms baselines with the p-value $<$ 0.05.}
\label{tab.RES1}
\centering
\begin{tabular}{l@{\hspace{0.8em}}c@{\hspace{2em}}c@{\hspace{2em}}c@{\hspace{2em}}c}
\Xhline{1pt}
\multirow{2}{*}{Method} & \multicolumn{4}{c}{P-stance (\%)} \\ \cline{2-5} 
                        & Biden & Sanders & Trump & Avg      \\ \hline
TarBK-BERT              & 75.49 & 70.45   & 65.80 & 70.58    \\
KASD-BERT               & 79.04 & 75.09   & 70.90 & 74.09    \\
KASD-LLaMA-2            & 75.28 & 74.09   & 69.29 & 72.87    \\
KASD-ChatGPT            & 83.12 & \underline{82.14}   & {82.04} & 82.28    \\
COLA                    & \underline{83.60} & {79.66}   & \underline{84.31} & \underline{82.52}    \\
CoVer (ours)            & \textbf{85.86}* & \textbf{82.63}   & \textbf{86.40}* & \textbf{84.96}*    \\ 
\Xhline{1pt}
\end{tabular}
\end{table}

We observe a clear performance gap between small and large language model based methods. 
LLMs utilize their internal commonsense and background knowledge for effective stance inference. In contrast, SLMs depend on heuristic training and explicit background knowledge modeling, limiting their generalization in scenarios with imbalanced targets, such as CC, where no SLM-based method exceeds 41\%, and in low-resource settings, such as Sem16, where only KASD-BERT’s average performance surpasses that of the weakest LLM-based method, KASD-LLaMA-2. Furthermore, we also observe that LLMs cannot fully utilize their capabilities without consistency verification, such as GPT-3.5-Turbo-CoT-Demo outperforms GPT-3.5-Turbo-Task-Des 12.06\% on Sem16 and 19.93\% on VAST. Therefore, CoVer enhances consistency verification utilizing SLM, which is more efficient and effective than relying solely on LLMs for verification.


\subsubsection{Ablation Study (RQ2)} \label{exp.abs}
To answer RQ2, the contributory of every component in CoVer is investigated by ablation study as shown in Table \ref{tab.ABS}. The ablation settings and analysis are as follows:

\textbf{Effectiveness of Consistency Verification (Ver.)}\quad Ver. plays a crucial role in enhancing CoVer's overall performance by ensuring reasoning consistency. To evaluate it, we remove Ver. from CoVer for testing, (denoted as {w/o Ver.}). Experimental results indicate that without Ver., CoVer’s \( F_{\text{AVG}} \) significantly decreases by 5.00\% on Sem16, 6.90\% on VAST and 4.85\% on P-stance, requiring less LLM queries \( Q_{\text{AVG}} \). 
Without Ver., the LLM performs reasoning without verification, potentially leading to more biased outputs and negatively impacting overall performance. This phenomenon further highlights the importance of ensuring the consistency of reasoning. Different from existing LLM self-verification approaches, Ver. ensure the LLM's reasoning consistency via SLM with fewer (0.54 on average) LLM queries per tweet.
% while demands less queies. 
% However, such direct output approach worsens LLM's performance on complex samples,


% is designed to capture the contextual relationships between sentences, which aids the LLM in more accurately inferring the stance of the text. resulting in a higher $Q_{\text{AVG}}$.
\textbf{Effectiveness of Contextual Reconstruction (Ctx.)}\quad Ctx. Largely ensures CoVer's performance. To evaluate it, we remove the Ctx. from CoVer for testing (denoted as {w/o Ctx.}). Experimental results show that without Ctx., the CoVer's $F_{\text{AVG}}$ decreases by 3.62\% on Sem16, 4.35\% on VAST, and 1.43\% on P-stance. Additionally, the higher $Q_{\text{AVG}}$ indicates that the lack of context augmentation also causes the inefficiency of the overall methods. 
This phenomenon suggests that the clearer context allows CoVer to capture implicit reasons and key information in tweets, thereby ensuring LLM to generate the consistent reasoning. 
By reconstructing context, CoVer can more effectively and efficiently reason the stance for those ambiguous tweets and lengthy tweets. 



% \textbf{Effectiveness of Batch Reasoning (Bat.):}  
% To evaluate the effectiveness of batch reasoning in the CoVer framework, we conducted an experiment by removing the batch reasoning component (w/o Bat.). The core function of batch reasoning is to improve the reasoning efficiency and consistency of the LLM by processing multiple text segments simultaneously. Experimental results show that removing the batch reasoning component leads to a decrease in the model’s \( F_{\text{AVG}} \) score across all datasets, particularly dropping to 70.47\% on the Sem16 dataset. Meanwhile, the \( Q_{\text{AVG}} \) value significantly increases. This change indicates that the absence of batch reasoning causes the model to process each text segment individually, lacking the support of global context, which decreases the reliability and stability of classification results, thereby affecting the overall classification accuracy.

\textbf{Effectiveness of Batch Reasoning (Bat.)}\quad
Batch reasoning (Bat.) plays a crucial role in improving the LLM utilization of CoVer. To evaluate it, we remove the batch reasoning for testing (denoted as w/o Bat.). Experimental results show that without Bat., the CoVer's $F_{\text{AVG}}$ lightly decreases by 3.68\% on Sem16, while $Q_{\text{AVG}}$ increases significantly by 1.96 on Sem16, 1.29 on VAST and 1.34 on P-stance.
% , indicating the efficiency obtained from batch reasoning. 
The dramatic increase in $Q_{\text{AVG}}$ with bat. further highlights its importance in reducing redundant LLM utilization.
Furthermore, instead of introducing stance biases or misclassifications, such shared context in batch processing also could enhance the robustness of LLM's internal stance comprehension criteria under some conditions. As evidenced by CoVer's improved \( F_{\text{AVG}} \) on Sem16, the performance enhancing by batch reasoning indicates that its potential effectiveness for minimizing LLM's reasoning biases.
% leverage shared contextual cues across multiple texts, which enhances the context utilization and robustness of LLM's internal classification criteria. 
% Furthermore, CoVer process each text segment individually, lacking the support of global context. As a result, the robustness of the classification results are reduced, negatively impacting the overall performance. 

\begin{table}[t]
\caption{ Experimental results of Ablation Study on Sem16, P-stance and VAST. The best result is highlighted in \textbf{bold}. The second best result is highlighted in \underline{underline}.}
\label{tab.ABS}
\centering
\begin{tabular}{lcc@{\hspace{1em}}cc@{\hspace{1em}}cc}
\Xhline{1pt}
\multirow{2}{*}{Variants} & \multicolumn{2}{c}{Sem16}          & \multicolumn{2}{c}{VAST}          & \multicolumn{2}{c}{P-stance}          \\ \cline{2-7}
                          & $F_{\text{AVG}}(\uparrow, \%)$   & $Q_{\text{AVG}}(\downarrow)$  & $F_{\text{AVG}}(\uparrow, \%)$ & $Q_{\text{AVG}}(\downarrow)$ & $F_{\text{AVG}}(\uparrow, \%)$ & $Q_{\text{AVG}}(\downarrow)$ \\ \hline
CoVer                     & \textbf{74.15} & \underline{0.53} & \underline{74.79} & \underline{0.54} & \underline{84.96} & \underline{0.54} \\
\quad w/o Ver.                  & 69.15$_{\downarrow 5.00}$ & \textbf{0.35} & 67.89$_{\downarrow 6.90}$ & \textbf{0.26} & 80.11$_{\downarrow 4.85}$ & \textbf{0.21} \\ 
\quad w/o Ctx.                  & \underline{70.53}$_{\downarrow 3.62}$ & 0.99$_{ 0.46 \uparrow}$ & 70.44$_{\downarrow 4.35}$ & 0.67$_{ 0.13 \uparrow}$ & 83.53$_{\downarrow 1.43}$ & 0.98$_{ 0.44 \uparrow}$ \\
\quad w/o Bat.                  & {70.47}$_{\downarrow 3.68}$ & 2.49$_{ 1.96 \uparrow}$ & \textbf{75.18} & 1.83$_{ 1.29 \uparrow}$ & \textbf{85.20} & 1.88$_{ 1.34 \uparrow}$ \\ \Xhline{1pt}
\end{tabular}
\end{table}



\begin{table}[t]
\caption{Prompt efficiency comparison across different LLM-based methods including DQA (Direct Question-Answering \cite{zhang2023investigating}), StSQA (Step-by-Step Question-Answering \cite{zhang2023investigating}), KASD-ChatGPT and COLA. The more ``\checkmark" a method has, the less efficient its LLM utilization is.  Single-C: Single text Classification. T-Demo: Task Demonstration. K-Aug: Knowledge Augmentation. M-Round: Multiple Round.}
% The best results are in \textbf{bold} and the second-best results are in \underline{underline}.
\label{tab:sem16_config_efficiency}
\centering
\begin{tabular}{lccc@{\hspace{1em}}cccc}
\Xhline{1pt}
\multirow{2}{*}{Method} & \multicolumn{5}{c}{Prompt Tactics} & \multicolumn{2}{c}{Sem16} \\ \cline{2-6} \cline{7-8}
                        & Single-C & T-Demo & K-Aug & CoT & M-Round & $F_{\text{AVG}} (\uparrow, \%)$ & $Q_{\text{AVG}} (\downarrow)$ \\ \hline
CoVer (ours)            & \ding{55}  & \checkmark & \checkmark & \ding{55} & \checkmark & \textbf{74.15} & \textbf{0.53}$\pm$0.29 \\ 
DQA                     & \checkmark & \ding{55}  & \ding{55}  & \ding{55} & \ding{55} & 48.22$_{\downarrow 25.93}$ & \underline{1.00} $_{\up{0.47}}$ \\
StSQA                   & \checkmark & \checkmark & \ding{55}  & \checkmark & \checkmark & 49.35$_{\downarrow 24.80}$ & 3.00 $_{\up{2.47}}$ \\
KASD-ChatGPT            & \checkmark & \checkmark & \checkmark & \checkmark & \checkmark & \underline{68.46}$_{\downarrow 5.69}$ & 3.00 $_{\up{2.47}}$ \\
COLA                    & \checkmark & \checkmark & \checkmark & \checkmark & \checkmark & 66.64$_{\downarrow 7.51}$ & 6.00 $_{\up{5.47}}$ \\
\Xhline{1pt}
\end{tabular}
\end{table}


\subsubsection{Efficiency Comparison (RQ3)} 
To answer RQ3, we selected several LLM-based methods for a comparison of model performance and LLM utilization on Sem16, as shown in Table \ref{tab:sem16_config_efficiency}. 
We can observe that CoVer achieves the highest $F_{\text{AVG}}$ 74.15\% with the lowest average query count ($Q_{\text{AVG}}$) 0.53 with less complicated prompt tactics.
The comparison results demonstrate that CoVer achieves high performance with less LLM utilization by combining LLM batch reasoning with SLM consistency verification.
This efficiency is attributed to CoVer's SLM and LLM collaboration mechanism, which leverages the strengths of the LLM for reasoning and uses SLM to reduce redundant queries to the LLM.




\subsubsection{Case Study}
To illustrate CoVer's consistency verification of LLM reasoning to ensure correct predictions, we conduct the case study shown in Figure \ref{fig.case}. In this case, the tweet implies a critique of alimony but does not explicitly connect this critique to the ``\textit{Feminist Movement}'', making the stance challenging to classify with certainty.
Both reasoner 1 and reasoner 3 predict a ``Neutral" stance, with moderate consistency scores (0.8341 and 0.8119, respectively), interpreting the text as lacking an explicit critical stance towards ``\textit{Feminist Movement}''. Their explanations highlight that, while the text discusses alimony reform, it does not directly oppose ``\textit{Feminist Movement}''. In contrast, reasoner 2 predicts an ``Against" stance with a higher consistency score (0.8972), suggesting it interprets the text as implicitly critical of alimony, aligning with an opposition stance towards the ``\textit{Feminist Movement}''.


\begin{figure}[t]
    \centering
    \includegraphics[width=0.9\linewidth]{pic/case3.pdf}\vspace{-4pt}
    \caption{Case study of CoVer, where the tweet only mentions ``\textit{CalAlimony}" in support of ending alimony, which seems neutral but implies a critique relevant to ``\textit{Feminist Movement}" indirectly. CoVer uses weighted aggregation to verify consistency across different LLM outputs, leveraging the SLM to ensuring the correct stance prediction.}
    \label{fig.case}
\end{figure}



Through weighted aggregation, CoVer assigns higher weight to reasoner 2 due to its higher consistency score, resulting in an``Against" stance as the final prediction. This case demonstrates CoVer’s ability to reconcile differing model outputs through weighted aggregation, achieving accurate stance classification even when model interpretations vary.

% CoVer进行这么加权的理念为，

% 解释这个case的正确分析思路。
% Qwen2.5-72B输出的解释和小模型分布相似度差异过大，表明模型的推理和分类出现了严重的不一致，Qwen2.5-7B和32B输出的解释和立场分类一致性较大，接近1。
% 在三者结果的加权聚合下，模型最终也能成功将结果预测为反对。



\subsection{Discussion of CoVer}
A fundamental component of CoVer is using batch reasoning to improve model efficiency. Intuitively, such shared context could introduce negative cross-influence between tweets, potentially causing bias in stance predictions. 
However, our ablation study in \S \ref{exp.abs} has shown that increasing batch size does not necessarily degrade model performance. This phenomenon warrants further investigation into the correlation between batch size scaling and LLM performance.


\begin{figure}[t]
    \centering
    \includegraphics[width=0.9\linewidth]{pic/Discussion_1.jpg}
    \vspace{-12pt}
    \caption{Comparative analysis of $F_{\text{AVG}}$ acorss different LLMs and batch settings on Sem16, demonstrating the scalability of CoVer's batch reasoning. Results demonstrate that increasing batch sizes (1 $\rightarrow$ 32) does not necessarily degrade model performance. CoVer effectively leverages batch reasoning to ensure the robustness of stance detection across different LLMs.
    }
    \label{fig.ab_res}
\end{figure}



We conduct experiments across different LLMs with varying batch sizes on the Sem16 dataset. We compare the Cover with the Task-Demo baseline, whose task instruction consistent with CoVer, across batch sizes (1, 8, 16, 32) on four advanced LLMs (LLAMA-3.1-8B\footnote{https://huggingface.co/meta-llama/Llama-3.1-8B-Instruct}, Qwen2.5-7B\footnote{https://huggingface.co/Qwen/Qwen2.5-7B-Instruct}, GLM4-9B\footnote{https://huggingface.co/THUDM/glm-4-9b-chat}, GPT-4o-mini\footnote{https://platform.openai.com/docs/models/gpt-4o-mini}). As shown in Fig.\ref{fig.ab_res}, experimental results indicate that: 1) Single-sample processing does not achieve the best performance across different LLMs. Compared to single-sample processing, batch processing allows LLMs to simultaneously process multiple samples, which ensures the establishment of more robust pattern recognition and decision criteria. 2) Different LLMs demonstrate model-specific optimal batch sizes, e.g., LlaMa3.1-8B is 8, while Qwen2.5-7B and GPT-4o-mini is 16, GLM4-9B is 32. This can be attributed to their capability for long-sequence processing. 3) CoVer consistently improves LLM performance across batch sizes, e.g., CoVer achieves an improvement of over 5\% on GPT-4o-mini. This suggests that the consistency verification and context reconstruction of CoVer can effectively remove the biases in LLM batch reasoning.

Our CoVer validates the feasibility of batch reasoning. Furthermore, through the collaboration between SLM and LLM, CoVer achieves a balanced trade-off between model effectiveness and computational efficiency, making it a practical solution for real-world applications.
% our CoVer validates that batch reasoning can enhance both effectiveness and efficiency in stance detection tasks. 


% \vspace{-10pt}
\section{Related work}
% \vspace{-6pt}
% Our CoVer uses the collaboration of SLM and LLM to handle two key challenges on stance detection: information insufficiency and unclear classification criteria.

\subsubsection{Stance Detection via Knowledge-Augmentation}
To enhance the understanding and classification of a stance in a given text \cite{li2023stance,liu2021enhancing}, many studies leverage external knowledge sources, such as knowledge graphs \cite{liu2021enhancing}, structured databases \cite{auer2007dbpedia}, and external textual information \cite{zhu2022enhancing} for knowledge augmentation. By incorporating external knowledge such as DBpedia \cite{auer2007dbpedia} or ConceptNet \cite{speer2017conceptnet}, models can gain a deeper contextual understanding, particularly useful for identifying implicit stances or understanding domain-specific terminology.
Additionally, recent studies \cite{wang2023boosting} indicate that integrating factual and contextual knowledge can significantly enhance the model’s ability to detect subtle or implicit stances, especially in scenarios with limited or biased training data.

In summary, knowledge augmentation has been proven by existing studies to be an effective strategy for enhancing stance classification. It addresses information insufficiency by providing context, resolving ambiguities, and identifying subtle relationships between the text and the target, which is especially effective in complex scenarios where direct textual information is limited.

\vspace{-5pt}
\subsubsection{Stance Detection via Reasoning}
Many studies \cite{liang2022zero,liu2021enhancing,zhang2023investigating} emphasize identifying stances in text through logical reasoning. 
These methods focus on analyzing arguments, causal relations, and implicit cues within the text to determine the stance, making them particularly effective in few-shot and zero-shot scenarios with complex arguments.
Recently, some studies have combined LLMs with such strategies to generate reasoning chains for stance detection. Specifically, the Logically Consistent Chain-of-Thought (LC-CoT) \cite{zhang2023investigating} enhances zero-shot stance detection by evaluating external knowledge requirements, invoking APIs to retrieve background knowledge, and employing if-then logic templates to generate reasoning chains. The Collaborative Role-Infused LLM-based Agents (COLA) \cite{lan2024stance} sets up multi-role LLM agents (e.g., linguistic experts, domain specialists, social media experts) for multi-view analysis.

In summary, stance detection via reasoning effectively handles implicit meanings and multi-step reasoning contexts by logical reasoning, demonstrating significant advantages in few-shot and zero-shot scenarios.




% In this work, we propose the method named Hierarchical Text Classification via Fusing the Structural and Semantic  (S\textsuperscript{2}-HTC), which ensures consistent hierarchical classification by integrating explicit structural relation information and implicit label semantic information. 
% Firstly, we use the Label Semantic-Aware Hierarchical Adjacency Matrix (LSA-HAM) to record both structural and semantic relations among labels. By applying the LSA-HAM, we execute a hierarchical consistency alignment process to incorporate hierarchical information features into our model.
% To more effectively capture the features of minor classes, we introduce the Class Balanced Negative Tolerance Regulation (CB-NTR) loss function.
% Moreover, we explore the effectiveness of Simple Contrastive Learning of Sentence Embeddings (SimCSE) and pre-trained methods, which contribute to the enhancement of our model. 
% Our experiments on the WOS, BGC, and NST5 datasets illustrate the state-of-the-art performance of S\textsuperscript{2}-HTC.

% combines the strengths of LLM and SLM to achieve balanced computational consumption and model performance
\section{Conclusion}\label{sec13}
% \vspace{-5pt}
In this study, we propose \textit{\textbf{\underline{Co}}llaborative Stance Detection via Small-Large Language Model Consistency \textbf{\underline{Ver}}ification} (\textbf{CoVer}), which combines the strengths of LLM and SLM to balance the computational consumption and model performance.
Specifically, to ensure unbiased stance reasoning, CoVer uses the context reconstruction module for knowledge augmentation and irrelevant context filtering. Then, to improve the utilization of LLM, CoVer introduces the batch reasoning module, allowing the LLM to process multiple tweets simultaneously. Finally, to ensure the correctness of stance classification, CoVer employs a consistency verification module with an SLM to align reasoning and stance predictions.
% ensure reasoning-prediction alignment. 
For tweets that repeatedly show low consistency, CoVer classifies them using a consistency-weighted aggregation of the likelihood scores.
Experimental results have indicated that CoVer demonstrates state-of-the-art performance across various benchmarks and reduces LLM queries to 0.54 per tweet, which offers a more practical solution for stance detection on social media.
% In future work, we aim to explore the feasibility of applying CoVer to multimodal scenarios and larger reasoning input sizes, and investigate additional factors that positively influence stance classification in batch reasoning.

% , and showing higher generalization capability in resource-constrained scenarios.

% This paper presents a collaborative stance detection framework, CoVer, which leverages the synergy of Small Language Models (SLMs) and Large Language Models (LLMs) to significantly enhance both efficiency and accuracy in stance detection tasks. 



\bibliographystyle{splncs04}
% \vspace{-10pt}
\bibliography{bib_copy}



\end{document}





% \bibitem{ref_lncs1}
% Author, F., Author, S.: Title of a proceedings paper. In: Editor,
% F., Editor, S. (eds.) CONFERENCE 2016, LNCS, vol. 9999, pp. 1--13.
% Springer, Heidelberg (2016). \doi{10.10007/1234567890}

% \bibitem{ref_book1}
% Author, F., Author, S., Author, T.: Book title. 2nd edn. Publisher,
% Location (1999)

% \bibitem{ref_proc1}
% Author, A.-B.: Contribution title. In: 9th International Proceedings
% on Proceedings, pp. 1--2. Publisher, Location (2010)

% \bibitem{ref_url1}
% LNCS Homepage, \url{http://www.springer.com/lncs}. Last accessed 4
% Oct 2017
% \end{thebibliography}



---------------------


% 

% \begin{itemize}
%  \item \textbf{Sem16} \cite{mohammad2016semeval} dataset is produced by an international evaluation activity for natural language processing and text analysis. It's the first released English stance detection dataset collected from Twitter. Each tweet in the Sem16 dataset features a target and a manually annotated stance label that can be categorized as Favor, Against, or None (3-class). 
%  we conduct our experiment on the three targets: \textit{Hillary Clinton} (HC), \textit{Feminist Movement} (FM), \textit{Legalization of Abortion} (LA), as these targets have a larger number of samples.
%  \item \textbf{NLPCC-2016} \cite{xu2016overview} dataset is a Chinese stance detection dataset crawled from Sina Weibo. It consists of 4,000 Chinese tweets annotated with favor, against, or none (3-class). We conduct our experiment on the four representative targets:  \textit{iphone 15} (IS), \textit{Set off firecrackers} in the Spring Festival (SF),  \textit{Two child} policy (TP), and the \textit{Prohibition of motorcycles} and restrictions on electric vehicles in Shenzhen (PM).
 
%  \item \textbf{P-stance} \cite{li2021p} dataset is a large annotated dataset consisting of 21,574 English tweets from the political field, each corresponding to one of the three politicians: \textit{Donald Trump} (Trump), \textit{Joe Biden} (Biden) and \textit{Bernie Sanders} (Bernie). Similar to prior studies \cite{li2021p}, we treat P-stance as a 2-class classification task. 
% \end{itemize}

% %To demonstrate the performance of our model, we use the Chinese microblogs dataset from NLPCC-2016 shared task 4 \cite{xu2016overview} and the English microblogs dataset from Semeval 2016 \cite{pontiki2016semeval} in our experiments. The typical topics we have chosen include 'iphone 15', 'Ban of Fireworks', 'Two-child Policy', 'Ban of Tricycles', 'Feminist Movement', 'Hillary Clinton', and 'Legalization of Abortion'. The statistics of these two datasets are shown in Table \ref{Tab.data}.


% % The distribution of instances in the P-stance dataset, on which the stance detection task can be seen as a binary classification task.

% \vspace{-10pt}
% \begin{table}[h]
% \caption{The statistics for the Sem16 and NLPCC-2016 Dataset, on which the stance detection can be seen as a 3-class classification task.}
% \label{Tab.data1}
% \centering
% \small
% \begin{tabular}{c|cccc|cccc}
% \Xhline{1pt}
% Target & Train & \%Favor & \%Against & \%None & Test & \%Favor & \%Against & \%None \\ \hline
% IS     & 600   & 40.8    & 34.8      & 24.3   & 200  & 37.5    & 52.0      & 10.5   \\
% SF     & 600   & 41.7    & 41.7      & 16.7   & 200  & 47.0    & 44.0      & 9.0    \\
% TP     & 600   & 43.3    & 33.3      & 23.3   & 200  & 49.5    & 47.5      & 3.0    \\
% PM     & 600   & 26.7    & 50.0      & 23.3   & 200  & 31.5    & 55.0      & 13.5   \\
% FM     & 664   & 31.6    & 49.4      & 19.0   & 285  & 20.4    & 64.2      & 15.4   \\
% HC     & 689   & 17.1    & 57.0      & 25.8   & 295  & 15.3    & 58.3      & 26.4   \\
% LA     & 653   & 18.5    & 54.4      & 27.1   & 280  & 16.4    & 67.5      & 16.1   \\ \Xhline{1pt}
% \end{tabular}
% \end{table}

% % 
% \begin{table}[h]
% \caption{The statistics for the P-stance dataset, on which the stance detection can be seen as a 2-class classification task.}
% \label{Tab.data2}
% \centering
% \begin{tabular}{c|ccc|ccc}
% \Xhline{1pt}
% Target  & Train & \%Favor & \%Against & Test & \%Favor & \%Against \\ \hline
% Trump   & 6362  & 46.2    & 53.8      & 796  & 45.4    & 54.6      \\
% Biden   & 5806  & 44.0    & 56.0      & 745  & 45.2    & 54.8      \\
% Bernie & 5056  & 56.5    & 43.5      & 635  & 54.0    & 46.0      \\ \Xhline{1pt}
% \end{tabular}
% \end{table}


% \vspace{-5pt}
 % In this section, we run experiments on two stance detection datasets to demonstrate that the effectiveness of the method we propose. Specifically, in Section \ref{ES}, we describe the datasets and the details of our training setting. In Section \ref{BM}, we introduce the baseline methods. In Section \ref{MR}, we present our main experiment results. In Section \ref{A}, we provide a detail analysis of our proposed model.

aaaf实验-----------------

%在中英文数据集上，IPAN 以及基线模型的表现见表 2，其中，表现最好的模型使用粗
%体标出，次优的模型使用下划线标出。
% The performance of AAAF and the baseline models on the datasets are shown in Table 3, where the best-performing model is highlighted in bold, and the second best model is underlined.


% In the triple classification datasets, according to the results in Table 3, AAAF can achieve significant improvements compared to the performance of most models on most topic datasets. Specifically, AAAF exceeds 7 out of 10 models in FM, 9 out of 10 in HC, 7 out of 10 in LA, 8 out of 9 in IS, 7 out of 9 in SF, 6 out of 9 in TP,  7 out of 9 in PM. In P-stance datasets, AAAF can achieve significant improvements compared to the performance of all baselines on all the three datasets. AAAF improved by 1.55\% in Bernie compared to the best baseline model BERT, in Biden improved by 1.66\% compared to the best baseline model PET, and in Trump improved by 0.86\% compared to the best baseline model BERT. 

% % Performance evaluation of various models on English dataset.
% \begin{table}[h]
% \captionsetup{width=1\textwidth}
% \caption{Experimental results of various models on Sem16 and NLPCC-2016 datasets (triple classification). The best result is highlighted in \textbf{bold}. The second best result is highlighted in \underline{underline}.}
% \label{fig.RES}
% \centering
% \begin{tabular}{l|ccc|cccc|cc}
% \Xhline{1pt}
% Model    & FM    & HC    & LA    & IS    & SF    & TP    & PM    & Mac\_avg    & Mic\_avg   \\ \hline
% NBOW     & 50.21 & 55.98 & 55.07 & 55.07 & 55.12 & 50.21 & 55.98 & 53.95 & 53.84 \\
% LSTM     & 49.06 & 61.84 & 51.03 & 51.03 & 58.18 & 80.36 & 61.84 & 59.05 & 58.58 \\
% % LSTME    & 52.04 & 56.89 & 60.34 & 73.78 & 55.23 & 63.59 & 71.23 & 61.87 & 61.21 \\
% TAN      & 55.77 & 65.38 & 63.72 & 59.33 & 77.50  & 65.00    & 72.38 & 65.58 & 65.07 \\
% T-PAN    & 58.45 & 57.48 & 60.21 & 62.39 & 76.23 & 68.37 & 70.46 & 64.80 & 64.18 \\
% T-DAN    & 64.12 & 63.53 & 66.74 & 66.42 & 73.15 & 69.27 & 76.09 & 68.47 & 68.07 \\
% BERT     & 58.9  & 66.96 & 55.14 & 58.62 & 79.2  & 82.5  & 79.52 & 68.69 & 67.81 \\
% PET      & 56.9  & 40.77 & 42.36 & 60.69 & 72.44 & 67.71 & 61.15 & 57.43 & 56.49 \\
% % TAPD     & 63.93 & 70.01 & 67.23 & -     & -     & -     & -     & -     & -     \\
% KNN-TACL & 65.40  & 71.02 & 67.41 & 63.45 & 82.16 & 85.67 & 83.02 & 74.02 & 73.40 \\
% AAAF     & 65.16 & 71.95 & 67.80  & 64.26 & 81.59 & 83.62 & 82.21 & 73.80 & 73.22 \\
% \Xhline{1pt}
% \end{tabular}
% \end{table}

% The main experimental results for the AAAF, as shown in Table \ref{tab.RES}, demonstrate its exceptional performance across different datasets. 

% CL integrates contrastive learning to strengthen the model's discriminative capability on text representation. It helps refine the learned representations to better distinguish between different stances.
% To evaluate the influence of data imbalance on performance, we remove the R-FL function for verification, denoted as "r.m. R-FL". The experiment reveals a 1.58\% drop in results, which means that addressing data imbalance is useful for stance detection.

% LLM-AE (Large Language Model Aspect Extraction): The removal of LLM-AE leads to the most significant performance drop, as indicated by the lowered bars across both datasets. This underscores the critical role of aspect extraction by the LLM in enriching the semantic understanding of the model, directly influencing the macro-average scores.

% ND (Neutrality Detection): The second set of bars, representing the removal of the ND module, shows a marked decline, especially in the HC category of the Sem16 dataset and the IS category of the NLPCC-2016 dataset. This demonstrates the importance of the ND module in discerning neutral from non-neutral tweets, affecting the model's precision in stance classification.

% NNR (Nearest Neighbor Retrieval): The impact of excluding the NNR mechanism is evident from the further reduced heights of the bars. This component's absence diminishes the model's capacity to utilize contextually relevant aspects for enhancing the semantic representation of tweets.

% AAA (Aspect-Augmented Attention): Without the AAA module, there is a noticeable decline in the model's focus on salient aspects, which is essential for accurate stance detection. The reduction in macro-average scores suggests that the model becomes less adept at highlighting key aspects without this module.

% R-FL (Rebalanced Focal Loss): Finally, the absence of R-FL, particularly affects the performance in the NLPCC-2016 dataset, revealing its role in managing the challenges posed by class imbalance within the data.

% These findings from the bar chart not only validate the interdependent efficacy of each module within the AAAF but also showcase the comprehensive strength of the model when all components work in unison. The visualization affirms that each module is not just an additive part but a crucial element that synergistically contributes to the robustness of the stance detection framework.

% % 目的：探究知识总结的有效性。 实验设置，使用用于被总结的样本作为tweet匹配检索的代替。
% Removing LLM-AE (Exp 2) results in a significant drop in performance, particularly in the Macro average score across both datasets. This highlights the importance of aspect extraction in providing context and enriching the semantic representation of tweets.


% % 目的：探究排除中立言论进行方面匹配的必要性 配置：在匹配aspect的时候，不对中立样本的检测
% The absence of ND (Exp 3) also causes a notable decrease in performance, particularly in the HC category of Sem16 and the IS category of NLPCC-2016. This suggests that accurately detecting and handling neutral tweets is crucial for effective stance detection.

% % 目的：探究aspect信息增强的有效性 配置：不进行 aspect相关的增强
% Excluding NNR (Exp 4) leads to lower scores, demonstrating the importance of accurately matching tweets with relevant aspects for context augmentation.

% % 目的：特征融合方式的有效性 设置：只将匹配的第一个aspect和句子做拼接
% Without the AAA module (Exp 5), the model experiences a decline in its ability to concentrate on the most critical aspects, as reflected in the reduced Macro average scores.

% % 目的：探究数据不平衡的影响。 配置：移除平衡损失函数
% Removing R-FL (Exp 6), which is designed to handle class imbalances, results in a decrease in performance, especially in the NLPCC-2016 dataset. This indicates the module's effectiveness in improving model performance in imbalanced data scenarios.


% In conducting the ablation studies for the Aspect-Augmented Attention Framework (AAAF), we aim to isolate and evaluate the contribution of each individual module within the framework to the overall performance. The results are presented in Table \ref{tab:ab_res}, and our analysis reveals the following insights:

% When we remove the Large Language Model Aspect Extraction (LLM-AE) component, there is a notable decline in performance across both the Sem16 and NLPCC-2016 datasets. This suggests that the aspect extraction driven by the large language model is vital for capturing the nuanced features required for accurate stance detection.

% The removal of the Neutrality Detection (ND) module results in the second-best performance for the Feminist Movement (FM) and Law (LA) categories in the Sem16 dataset, indicating the importance of identifying neutral stances which are not explicitly in favor or against a topic.

% Excluding the Nearest Neighbor Retrieval (NNR) mechanism leads to a moderate reduction in performance, underscoring its role in aligning the most relevant aspects with their corresponding tweets to enrich the semantic context.

% Omitting the Aspect-Augmented Attention (AAA) module results in a slight drop in the model's effectiveness, highlighting the AAA's role in focusing the model's attention on the most significant aspects for each tweet.

% Lastly, when the Rebalanced Focal Loss (R-FL) is removed, we observe the most substantial performance decline in the Information Security (IS) category of the NLPCC-2016 dataset, stressing the importance of R-FL in optimizing the stance detection, especially in balancing the class distribution.

% Overall, the ablation studies underscore the interdependence of AAAF components and their collective contribution to the framework's state-of-the-art performance in stance detection tasks.


% The results are shown as Table 5 and Table 6. There are four parts which are placed by design to enhance the ability of our model: ND, NNR, AAA, DB. Among them, NNR is an essential part for the model can't accomplish stance detection tasks without it. Therefore, we design three experiments. Each of them has one of ND, AAA, R-FL removed on the basis of AAAF. And the three experiments are denoted as "experiment 2", "experiment 3", "experiment 4" in turn. According to the results, all of ND, AAA and R-FL can bring a significant effect on the accuracy of stance detection on most datasets.  



%在大多数数据集中，BERTweet比BERT的准确率高，证明针对？的文本编码器有助于提升模型性能。对ND/AAA/DB分别进行的消融实验结果都表明，预先将中立立场和有态度的立场区分开、最近邻检索机制、方面增强注意力模块、Distribution Balanced Loss有助于提升模型的准确率。
%

% \begin{table}[h]
% \begin{tabular}{cccccccc}
% \hline
% Exp & Description                        & KNN         & MA          & SAA         & AAA         & Dropout     & DBLoss      \\ \hline
% 1   & AAAF                               & \checkmark  & \checkmark  & -           & \checkmark  & \checkmark  & \checkmark  \\
% 2   & AAAF-CE                            & \checkmark  & \checkmark  & -           & \checkmark  & \checkmark  & -           \\
% 3   & AAAF-NA-CE                         & \checkmark  & -           & -           & -           & \checkmark  & -           \\
% 4   & AAAF-NA                            & \checkmark  & -           & -           & -           & \checkmark  & \checkmark  \\
% 5   & AAAF-BA-CE                         & \checkmark  & -           & -           & \checkmark  & \checkmark  & \checkmark  \\
% 6   & Naive Classification Method        & -           & -           & -           & -           & \checkmark  & -           \\
% 7   & Naive Classification Method-Dbloss & -           & -           & -           & -           & \checkmark  & \checkmark  \\ \hline
% \end{tabular}
% \end{table}

% \begin{table}[h]
% \begin{tabular}{cccc}
% \hline
% Method                             & Bernie         & Biden          & Trump          \\ \hline
% \textbf{AAAF}                      & \textbf{75.14} & \textbf{80.08} & \textbf{80.05} \\ \hline
% AAAF-CE                            & 75.14          & 79.17          & 74.39          \\
% AAAF-NA-CE                         & 35.07          & 81.91          & 77.88          \\
% AAAF-NA                            & 35.07          & 81.15          & 77.88          \\
% AAAF-BA-CE                         & 74.49          & 35.39          & 78.82          \\ \hline
% Naive Classification Method        & 35.07          & 35.39          & 73.26          \\
% Naive Classification Method-Dbloss & 35.39          & 35.39          & 79.66          \\ \hline
% \end{tabular}
% \end{table}


% \begin{table}[h]
% \centering
% \captionsetup{width=0.8\textwidth}
% \caption{The setup of the ablation study for AAAF. In the table, BERT and BERTweet are the text encoders. ND is the Neutrality Detection module. NNR is the Nearest Neighbor Retrieval mechanism. AAA is the Aspect-Augmented Attention module. DB is the $\mathcal{L}_{DB}$.}
% \label{tab:ab_set}
% \begin{tabular}{c|cccccc}
% \hline
% Exp & BERT & BERTweet & ND & NNR & AAA & DB \\ \hline
% 1   &   -   & \checkmark & \checkmark & \checkmark & \checkmark & \checkmark \\
% 2   & \checkmark &   -   & \checkmark & \checkmark & \checkmark & \checkmark \\
% 3   & -      & \checkmark &     -     & \checkmark & \checkmark & \checkmark \\
% 4   &   -   & \checkmark & \checkmark & \checkmark &       -     & \checkmark \\
% 5   &   -   & \checkmark & \checkmark & \checkmark &  \checkmark   & - \\
% 6   &   -   & \checkmark & - &     -      &      -      & \checkmark \\ 
% \hline
% \end{tabular}
% \end{table}

% \begin{table}[h]
% \centering
% \captionsetup{width=1\textwidth}
% \caption{The setup of the ablation study for AAAF. In the table, ND is the Neutrality Detection module. NNR is the Nearest Neighbor Retrieval mechanism. AAA is the Aspect-Augmented Attention module. R-FL is the rebalanced loss.}
% \label{tab:ab_set}
% \begin{tabular}{c|l|cccc}
% \Xhline{1pt}
% Exp & Description                               & ND & NNR & AAA & R-FL \\ \hline
% 1   & AAAF                                      & \checkmark & \checkmark & \checkmark & \checkmark \\
% 2   & r.m. Neutrality Detection module          &     -     & \checkmark & \checkmark & \checkmark \\
% 3   & r.m. Nearest Neighbor Retrieval mechanism & \checkmark &     -      &      -      & \checkmark \\
% 4   & r.m. Aspect-Augmented Attention module    &  \checkmark & \checkmark &       -     & \checkmark \\
% 5   & r.m. Rebalanced Focal Loss mechanism &  \checkmark & \checkmark &  \checkmark   & - \\
 
% \Xhline{1pt}
% \end{tabular}
% \end{table}


% \begin{table}[h]
% \centering
% \captionsetup{width=0.8\textwidth}
% \caption{The results of the ablation study for AAAF. }
% \label{tab:ab_res}
% \begin{tabular}{ccccccccccc}
% \hline
% \multirow{2}{*}{Exp} & \multicolumn{3}{c}{Sem16} & \multicolumn{4}{c}{NLPCC-2016} & \multicolumn{3}{c}{P-stance} \\ \cline{2-11}
% \multicolumn{1}{c}{}                     & FM        & HC        & LA       & IS     & SF    & TP    & PM    & Bernie   & Biden   & Trump   \\ \hline
% 1                                        & 78.59     & 77.62     & 79.21    & 62.16  & 70.95 & 65.80 & 73.26 & 75.14    & 80.08   & 80.05   \\
% 2                                        & 84.15     & 77.40     & 79.25    & 54.14  & 67.29 & 65.1  & 71.62 & 35.39    & 35.39   & 79.66   \\
% 3                                        & 79.98     & 75.06     & 79.57    & 56.17  & 65.63 & 66.46 & 71.85 & 35.07    & 81.15   & 77.88   \\
% 4                                        & 78.41     & 74.98     & 82.92    & 56.74  & 69.41 & 57.96 & 74.73 & 75.14    & 79.17   & 74.39   \\ \hline
% \end{tabular}
% \end{table}



% \begin{table}[h]
% \centering
% % \captionsetup{width=0.8\textwidth}
% \caption{The results of the ablation studies for AAAF. In the table, LLM-AE is the aspect extraction using large language model. ND is the Neutrality Detection module. NNR is the Nearest Neighbor Retrieval mechanism. AAA is the Aspect-Augmented Attention module. R-FL is the rebalanced focal loss. The best result is highlighted in \textbf{bold}. The second best result is highlighted in \underline{underline}.}
% \label{tab:ab_res}
% \begin{tabular}{l|cccc|ccccc}
% \Xhline{1pt}
% \multirow{2}{*}{Exp} & \multicolumn{4}{c}{Sem16 (\%)} & \multicolumn{5}{c}{NLPCC-2016 (\%)}           \\ \cline{2-5}\cline{6-10} 
%                      & FM    & HC    & LA    & Mac\_avg & IS    & SF    & TP    & PM    & Mac\_avg \\ \hline 
% AAAF                                & \textbf{65.16} & \textbf{71.95} & \textbf{67.80} & \textbf{68.30}    & \underline{64.26} & \textbf{81.59} & \textbf{83.62} & \textbf{82.21} & \textbf{77.92}    \\
% \textit{r.m.} LLM-AE                & 56.43 & \underline{69.43} & 57.96 & 61.27    & 59.43 & 78.63 & \underline{80.45} & 78.71 & 74.31 \\
% \textit{r.m.} ND                    & \underline{62.42} & 65.24 & \underline{66.85} & \underline{64.84}    & 56.08 & 77.44 & 76.46 & 80.08 & 72.52    \\
% \textit{r.m.} NNR                   & 59.17 & 66.63 & 63.46 & 63.09    & 62.85 & 79.98 & 75.06 & 79.57 & 74.37    \\
% \textit{r.m.} AAA                   & 59.34 & 69.55 & 64.97 & 64.62    & 62.62 & \underline{80.89} & 74.98 & 76.32 & 73.70    \\
% \textit{r.m.} R-FL                  & 59.52 & 67.28 & 65.44 & 64.08    & \textbf{66.60} & 79.65 & 78.24 & \underline{81.42} & \underline{76.48}    \\
% \Xhline{1pt}
% \end{tabular}
% \end{table}


---------------主实验



% \begin{table}[h]
% \captionsetup{width=1\textwidth}
% \caption{Experimental results of various models on Sem16 and NLPCC-2016 datasets (triple classification). The best result is highlighted in \textbf{bold}. The second best result is highlighted in \underline{underline}.}
% \label{tab.RES}
% \centering
% \begin{tabular}{lcccc|ccccc}
% \Xhline{1pt}
% \multicolumn{1}{c}{\multirow{2}{*}{Model}} & \multicolumn{4}{c}{Sem16 (\%)} & \multicolumn{5}{c}{NLPCC-2016 (\%)} \\ \cline{2-10} 
% \multicolumn{1}{c}{} & FM    & HC    & LA    & Mac\_avg & IS    & SF    & TP    & PM    & Mac\_avg \\
% \hline
% NBOW \cite{wallach2006topic}                & 50.21 & 55.98 & 55.07 & 53.75    & 55.07 & 55.12 & 50.21 & 55.98 & 54.10    \\
% BiLSTM \cite{hochreiter1997long}            & 49.06 & 61.84 & 51.03 & 53.98    & 51.03 & 58.18 & 80.36 & 61.84 & 62.85    \\
% TAN \cite{du2017stance}                     & 55.77 & 65.38 & 63.72 & 61.62    & 59.33 & 77.50 & 65.00 & 72.38 & 68.55    \\
% T-PAN \cite{dey2018topical}                 & 58.45 & 57.48 & 60.21 & 58.71    & 62.39 & 76.23 & 68.37 & 70.46 & 69.36    \\
% T-DAN \cite{yang2020tweet}                  & 64.12 & 63.53 & 66.74 & 64.80    & \textbf{66.42} & 73.15 & 69.27 & 76.09 & 71.23    \\
% BERT \cite{devlin2018bert}                  & 58.90 & 66.96 & 55.14 & 60.33    & 60.43 & 71.57 & 69.40 & 66.90 & 67.08     \\
% % BERT \cite{devlin2018bert}                & 58.90 & 66.96 & 55.14 & 60.33    & 58.62 & 79.20 & 82.50 & 79.52 & 74.96    \\
% BERTweet \cite{nguyen2020bertweet}          & 62.31 & 62.31 & 64.14 & 62.92    & -     & -     & -     & -     & -        \\
% PET-BERT \cite{schick2020exploiting}          & 56.90 & 60.77 & 52.36 & 56.68 & 60.69 & 72.44 & 67.71 & 61.15 & 65.50       \\
% KNN-TACL \cite{sun2023topic}                & \textbf{65.40} & \underline{71.02} & \underline{67.41} & \underline{67.94}    & 63.45 & \textbf{82.16} & \textbf{85.67} & \textbf{83.02} & \textbf{78.58}    \\
% % AAAF (Ours)                                       & \underline{65.16} & \textbf{71.95} & \textbf{67.80} & \textbf{68.30}    & \underline{64.26} & \underline{81.59} & \underline{83.62} & \underline{82.21} & \underline{77.92}   \\
% AAAF (Ours) & \underline{64.83} & \textbf{72.13} & \textbf{70.46} & \textbf{69.14} & \underline{64.26} & \underline{81.59} & \underline{83.62} & \underline{82.21} & \underline{77.92}    \\
% \Xhline{1pt}
% \end{tabular}
% \end{table}


% When examining models that also focus on topic modeling, such as KNN-TACL, TAN, T-PAN, and T-DAN, AAAF emerges as a comprehensive leader, indicating its effectiveness in capturing and enhancing semantic representations of stances in a topic-centric manner.

% AAAF具有跨语言通用性（cross-linguistic adaptability），我们的方法在NLPCC-2016数据集上的实验同样取得了出色的效果。
% AAAF的主题下的潜在层面进行信息增强具有有效性。在针对主题进行建模的方法中，KNN-TACL、TAN、T-PAN、T-DAN等方法，AAAF取得了综合最优的表现
% AAAF对于2-class和3-class分类都能比较好的适应。our Sem16、NLPCC-2016是3分类数据集，p-stacen是二分类

% In the Sem16 dataset, AAAF demonstrates its robustness in the nuanced task of stance detection with the highest Macro average scores, particularly excelling in the 'Hillary Clinton' (HC) category. This success underscores the framework's ability to augment tweet context with relevant aspects, providing a more comprehensive understanding of the stance conveyed.

% For the NLPCC-2016 dataset, AAAF continues to show strong performance, especially in the 'Information Security' (IS) category. Although it doesn't always secure the top position, its results are consistently high, indicating its effectiveness in the Chinese language context and affirming its cross-linguistic capabilities.

% In the P-stance datasets, AAAF outshines the baselines in binary classification tasks, particularly when assessing stances towards political figures such as Biden and Trump. This highlights AAAF's precision in capturing the subtleties of stance expression, further emphasizing the model's capacity for context extraction and aspect-tweet matching.

% In the Sem16 and NLPCC-2016 datasets, AAAF attains the comparable performance to the state-of-the-art models, which indicates AAAF's robustness in handling complex stance detection challenges across diverse topics both in English and Chinese data.
% Notably, AAAF outperforms in scenarios with a mix of explicit and implicit stances, thanks to its ability to augment tweet context through aspect-augmentation. 
% Its performance is particularly noteworthy in the 'Hillary Clinton' (HC) category of Sem16 and 'Information Security' (IS) category of NLPCC-2016.

% In the P-stance datasets, AAAF also outperforms the baselines, particularly in the stances classification towards politicians Biden and Trump. This reinforces the framework's effectiveness in nuanced stance detection, where understanding the underlying context and aspects is critical. The success of AAAF in these datasets can be attributed to its innovative use of LLMs for context extraction and aspect-tweet matching, which enhances the model's ability to discern nuanced stances in UGC.






% \begin{itemize}
% \item In cases where the inconsistency between training and testing dataset distributions is small, the balancing function still has a strong boosting effect. Since the Chinese dataset has been re-partitioned, the labels for the training and testing datasets are not entirely consistent. However, a comparison of the performance of variant IPAN-CE and IPAN on the Chinese dataset reveals that this slight distribution inconsistency does not affect the function of the loss balancing.
% \item Topic information embedding has significant effectiveness. The experimental results show that models incorporating topic information (such as TAN and IPAN) outperform models without topic information on most topics. This indicates that embedding topic information is effective for stance detection tasks; it can help models more accurately capture the semantic links between the text being detected and the target topic.
% \item Interest points, as explicit information communication channels, strengthen the association between text and stance attitudes. The significant improvements achieved by IPAN and its variant models on various topics demonstrate that interest points, as explicit information communication channels in this study, enhance the connection between the text and stance.
% \item Semantic representation is an important consideration for accurate sample classification. PET also performs very well in the experiments. As a method that uses language patterns for training classification models, it enhances the model's text understanding abilities by taking full advantage of knowledge from the pre-training stage.
% \item In Chinese datasets, a simple attention mechanism has more advantages. IPAN-BA performs better than IPAN in Chinese datasets. Due to the differences in expression between Chinese and English, and the concentration of key information, the interest point attention network model based on a single-head attention mechanism outperforms the multi-head attention mechanism.

% \end{itemize}
% Open Aspect Extraction (OAE): The OAE module iteratively extracts and refines target aspects from unlabeled data by guiding large language models (LLMs). Removing OAE leads to a 3.45% drop in performance, indicating its essential role in enhancing the semantic representation of tweets. OAE addresses the challenge of dynamic knowledge changes in stance detection by capturing the diverse and evolving aspects associated with different targets through open-domain concept extraction.



----
% Most existing solutions mainly utilize the structure of labels for hierarchy modeling but lack consideration of the semantic relations between labels. 
% Realizing the natural challenge of long-tailed label distributions in HTC, S\textsuperscript{2}-HTC adopts the balanced loss computation to efficiently represent low-level label features.
% Realizing the long-tailed label distribution in HTC, S\textsuperscript{2}-HTC adopts the balanced loss computation to efficiently represent low-level label features.

% Stance detection aims to classify the attitudes expressed in text towards specific targets (support, against, neutral). In recent years, research has primarily focused on utilizing large language models (LLMs) for prediction. However, the frequent use of LLMs to handle simple tasks results in inefficient use of computational resources and reduces overall efficiency. To address this issue, this paper proposes a model named CoVer, which achieves a balance between computational efficiency and prediction performance through the collaboration of large and small models. CoVer initially utilizes a knowledge enhancement module to expand the information in the input text, thereby improving the model's understanding of target content. Subsequently, it employs a batch detection mechanism, where the LLM generates preliminary classification results and their corresponding rationale, optimizing the usage of computational resources. The model then applies a consistency verification module to perform confidence analysis and adjustment on these preliminary results and rationales, ensuring the accuracy and consistency of the classification outcomes. Samples that do not pass the consistency verification are reprocessed in subsequent batches, further enhancing overall performance.Experimental results demonstrate that CoVer outperforms traditional methods across multiple stance detection datasets, significantly reducing computational resource consumption while improving classification accuracy. This provides an efficient and practical solution for stance detection tasks.

% However, relying heavily on LLMs for this task is resource-intensive, leading dynamic monitoring of vast social media streams.  However, relying heavily on LLMs for this task is resource-intensive, thus leading to the impracticality of vast social media stream monitoring.



------------intro rw


% 立场检测（Stance Detection）旨在识别文本中针对特定目标所表达的态度（如支持、反对、中立），特别在大规模社交媒体平台的文本分析中具有重要应用价值。通过对这些平台上的海量内容进行立场检测，可以更深入地了解公众观点的分布和变化趋势，并有助于分析新闻报道的立场倾向和舆情走向。


% aims to identify attitudes (Favor, Against, or None) expressed in text towards a specific target, which holds significant value in analyzing content on social media platforms. By deploying stance detection applications on these platforms, enabling the deeper insights into public opinion trends and biases toward different social events. 

% , holding significant value in analyzing content on large-scale social media platforms. 

% 对于社交媒体平台的tweet立场检测，它不仅需要从非正式和缺乏具体上文的短文本中识别文本中的情感，还需要通过利害关系的推理，得出的文本对特定目标的态度。早期的研究主要依赖于手动特征工程来提取语言特征 \cite{somasundaran2010recognizing} 或结构特征 \cite{sridhar2015joint}，但这些方法在处理大规模数据时往往泛化性差且建模成本高。而后，基于预训练机制和知识推理机制被引入到立场检测中来解决短文本信息不足的问题。Liang等人（2022）提出了一种名为JointCL的联合对比学习框架，用于增强零样本立场检测的泛化能力 (Liang et al., 2022)。同年，Zhu等人（2022）提出了一种通过融入背景知识来增强零样本立场检测的方法，该方法利用外部知识来建立已知和未知目标之间的联系，从而提高模型的推理能力 (Zhu et al., 2022)。此阶段方法的特点是需要根据不同的话题重新训练模型来确保检测效果，但知识驱动推理的思想极大启发了后续的研究。随着大语言模型（LLM）的兴起，立场检测研究逐渐将其与LLM相结合，使得立场检测检测模型性能取得极大提升。Lan等人（2023）提出了一种基于协作角色的大语言模型代理系统（COLA），通过多角色协作的方式来应对立场检测的挑战。COLA利用不同角色（如语言学专家、领域专家和社交媒体老手）对文本进行多维分析，并通过推理增强的辩论和总结阶段提升对复杂任务的准确性 (Lan et al., 2023)。然而，这些方法主要依赖于大型语言模型甚至多智能体协同进行一个短文本的逐句分析，尽管这样的做法的性能表现出色，但是算法的开销极大。

% Stance detection on social media platforms such as Twitter, not only requires identifying the sentiment within informal and context-limited short texts but also involves inferring the relationships and implications to determine the stance towards a specific target. 

% Early studies mainly conducted feature engineering to extract linguistic \cite{somasundaran2010recognizing} or structural \cite{sridhar2015joint} features manually for stance detection, which had limited generalization capability and high resource consumption. Subsequently, pre-training mechanisms and knowledge reasoning approaches were introduced into stance detection to address the issue of insufficient information in short texts. 
% Liang et al.\cite{liang2022jointcl} proposed a joint contrastive learning framework named JointCL, which aimed to enhance the generalization capability of zero-shot stance detection. 
% Zhu et al. \cite{zhu2022enhancing} introduced a method to improve zero-shot stance detection by incorporating background knowledge, and leveraging external knowledge to establish connections between known and unknown targets, thereby enhancing the model's reasoning abilities. 
% A key feature of these approaches is the need to retrain the model based on different topics to ensure detection accuracy. Yet, the concept of knowledge-driven reasoning greatly inspired subsequent research.

% With the emergence of Large Language Models (LLMs), stance detection studies increasingly combined them with LLMs, significantly improving model performance. Lan et al.\cite{lan2024stance}proposed a collaborative role-based large language model agent system (COLA) to tackle the challenges of stance detection. COLA employed multiple roles (such as linguistic experts, domain experts, and social media veterans) to conduct multi-dimensional analysis of texts and enhance the accuracy of complex tasks through debate and summarization phases, which were aimed at reinforcing reasoning. However, these approaches heavily rely on large language models or even multi-agent collaboration to perform sentence-by-sentence analysis of short texts. Although such methods demonstrate outstanding performance, the computational cost of these algorithms is substantial.
%目前，立场检测主要依赖于大型语言模型（LLM），通过对大量语料进行预训练，具备强大的语义理解和预测能力，并在立场检测任务中取得了显著效果。



% $LLM-based 方法为了确保识别文本中对于特定目标的立场，会通过设置

% 我们基于conceptnet计算各个标签之间的语义相似度。
% The semantic similarity scores between labels are calculated using ConceptNet and presented in Fig.\ref{Fig.EXA}(b).
% It is worth noting that the label pairs such as \textit{Literature} and \textit{Fiction} share a significant semantic relation since fiction belongs to the literature genre. Moreover, it should be noted that labels that are not structurally related within the hierarchy may also exhibit semantic relationships. For instance, the label \textit{Adventure} and \textit{Romance} can be considered semantically related, given that numerous adventure fictions integrate themes of romance (e.g., where the hero rescues the princess and then they fall in love).

% Understanding these semantic relations between labels, both at the same level and across different levels of the hierarchy is crucial for label-label relation patterns learning, especially beneficial for enhancing the classification performance of long-tail distribution data. Some recent studies have started to recognize the importance of these non-structural relations between labels. For example, PeerHTC \cite{song2023peer} models relations between same-level labels, but it doesn’t fully address cross-level relations.
% Modeling the semantic relations of labels can provide the model with a richer background knowledge of labels, especially long-tail labels, enhancing the model's generalization capability. 
%如图所示，现有的立场检测方法可以被分为两种，如图一（a）和图一（b）所示。一种方法仅使用小型语言模型（SLM），这种策略适用于处理简单明确的文本任务，计算开销小，且能实现批量检测，但面对复杂表述时容易出现误判。例如，在图（a）中，SLM未能准确判断``Spirit Island"的完整描述或电池问题的细节。第二种方法是基于大型语言模型（LLM）的逐句分析，尽管能够精确处理复杂表达，但无法实现批处理，开销极大。如图（b）中的``It's a pretty pink color"，此句话表意明确，包含褒义词``pretty"，其实无需进一步引用知识和推理分析。为克服现有这两种方法的局限性，如图一（c）所示，基于大小模型协同的立场检测方法能通过让大小模型合理分工，实现准确性和低开销的兼顾。在该方法中，LLM进行批量的原始文本处理，形成直白和带有显著特征的文本，而后只需利用SLM对其进行校验，这能有效减少不必要的推理计算，提高整体检测效率，同时保持对复杂语境的准确理解。例如，SLM能够高效处理``It's a pretty pink color"这样简单的文本，而LLM则能精确分析更复杂的``Just don't want to increase the 3500 battery"句子，从而识别反对立场。这样，大小模型协同策略通过多层次的理解模式，不仅确保了复杂文本的精确处理，还优化了计算资源的使用，大幅提高了整体效率。这种大小模型协同的合作框架在大规模社交媒体平台的立场检测任务能展现出显著优势。

% Existing studies often alleviate this problem by performing iterative self-verification.

% inconsistencies in their reasoning and stance prediction
% the implicit contexts. prevent issues such as hallucinations, which can lead to inconsistencies in their reasoning and stance prediction, potentially resulting in the unstable performance.
%  and outdated information

%然而,这些方法忽略了立场检测是一个需要对大量文本分析（数据密集型？我说的对吗）的任务，需要兼顾效率和性能，针对一个推文（20字不到），调用多次LLM的反复推理是显然很贵的.


% For the SLM, the strength lies in its ability to quickly recognize explicit patterns, which enables the SLM to verify the consistency of the LLM’s predictions by checking for alignment with straightforward cues. For instance, for the tweet ``\textit{The battery capacity ...}" toward the target ``\textit{iPhone 16}", the LLM can recognize that the phrase ``stunne" expresses surprise, but in a critical sense, due to the relatively low battery capacity (3,561mAh), thus classifying the tweet in an ``against" stance. 


% For the LLM, its strength is, 
% By converting implicit cues from the original tweets into prediction probabilities and clear explanations using the LLM, the SLM can verify LLM's predictions without requiring deep reasoning. 
% 对于大模型，其优势是xx，小模型的优势是xxx

% To verify the consistency of LLM’s prediction and reasoning, the SLM can be introduced, .  
% The LLM comprehends diverse user expression styles and heterogeneous knowledge in short tweets, enabling it to generate reasoning-based analyses that transform implicit information into a more explicit form. For instance, for the tweet ``\textit{The battery capacity ...}" toward the target ``\textit{iPhone 16}", the LLM can recognize that the phrase ``stunne" expresses surprise, but in a critical sense, due to the relatively low battery capacity (3,561mAh), thus classifying the tweet in an ``against" stance. 




% To verify the LLM's consistency, the SLM can be introduced
% , allowing for efficient validation of the LLM's outputs

% 我们使用SLM的方法来大模型的输出内容的检验，如Fig.\ref{Fig.EXA}(c)所示。LLM能将一段充满复杂表达方法和异构知识的短文本进行立场的推理并给出基于理由的立场标签的概率，这段包含立场推理推理的文本通常




% As illustrated in Figure 1, existing stance detection methods can be categorized into two types, as shown in Figures 1(a) and 1(b). The first approach relies solely on Small Language Models (SLMs), which are suitable for handling simple and straightforward text tasks. This strategy has low computational overhead and supports batch processing, but it is prone to misjudgments when faced with complex expressions. For instance, in Figure 1(a), the SLM fails to accurately interpret the detailed description of "Spirit Island" or the nuances of the battery issue. The second approach involves sentence-by-sentence analysis using Large Language Models (LLMs). While this method can handle complex expressions with precision, it does not support batch processing and incurs significant computational costs. For example, the phrase "It's a pretty pink color" in Figure 1(b) is straightforward and contains the positive word "pretty," which does not require further reference to external knowledge or reasoning.

% To overcome the limitations of these two approaches, a stance detection method based on collaborative small-large model coordination, as shown in Figure 1(c), has been proposed. This method aims to achieve a balance between accuracy and low computational costs by leveraging the complementary strengths of SLMs and LLMs. In this framework, LLMs perform the initial batch processing of raw texts, identifying straightforward texts and those with significant features. Subsequently, SLMs are used for validation, which effectively reduces unnecessary reasoning computations, enhances overall detection efficiency, and maintains an accurate understanding of complex contexts. For example, SLMs can efficiently handle simple phrases like "It's a pretty pink color." while LLMs can accurately analyze more complex sentences such as "Just don't want to increase the 3500 battery" to identify a stance of opposition. 
% % This multi-level understanding approach ensures precise handling of complex texts and optimizes resource utilization, significantly improving overall efficiency. This collaborative small-large model framework demonstrates significant advantages in stance detection tasks on large-scale social media platforms.

% This multi-level understanding approach not only enables precise handling of complex texts but also optimizes resource utilization, leading to a substantial improvement in overall efficiency. As a result, the collaborative framework of small and large models offers notable advantages in stance detection tasks on large-scale social media platforms.
% 因此，本文提出了 CoVer 模型，通过大小模型的协同工作，进一步优化了立场检测任务的计算资源使用。CoVer 通过引入知识增强模块，提升了模型对目标内容的理解能力，从而有效应对复杂的语境信息。相比于传统的单一大型模型方法，CoVer 通过批量检测机制，将大型语言模型的强大语义建模能力与小型模型的高效任务处理能力相结合，使得整个系统在处理不同复杂度的文本时更加灵活。具体来说，大型语言模型在初步阶段生成分类结果和分类依据，通过一致性检验模块进行进一步的置信度分析与结果校正。这样的设计确保了分类的准确性，同时避免了不必要的计算资源消耗。对于未通过一致性检验的样本，CoVer 模型会将其纳入下一批次进行重新处理，逐步提高分类精度。



% To this end, we propose the method named Hierarchical Text Classification via Fusing the Structural and Semantic  (S\textsuperscript{2}-HTC), which achieves hierarchy classification by leveraging a method incorporating label semantics and structural relations with the balancing loss calculation.
% Specifically, for hierarchy modeling, we introduce the Label Semantic-Aware Hierarchical Adjacency Matrix (LSA-HAM) to jointly capture the structural and semantic relations of labels in the taxonomy hierarchy, and propose a hierarchical consistency alignment method for hierarchical and textual information fusion.
% Compared to the structure encoder, our method reduces the potential noise from heterogeneous fusion and random initialization \cite{zhou2020hierarchy}.
% % Furthermore, we adopt a hierarchical consistency alignment processing method for labeled relational information fusion. 
% Hierarchical text classification inherently exhibits the long-tail distribution of data. We incorporate the balancing loss calculation \cite{huang2021balancing} to effectively learn the features of long-tail labels.


% that combines the strong semantic modeling capabilities of large language models with the efficient task processing capabilities of small models, making the entire system more flexible in handling texts of varying complexity. 
% Specifically, the large language model generates initial classification results and supporting rationales, which are then subjected to further confidence analysis and correction through a consistency-check module. 
% This design ensures classification accuracy while avoiding unnecessary computational overhead. For samples that fail the consistency check, the CoVer model reprocesses them in subsequent batches, progressively improving classification precision.



% The major contributions of our study are as follows:
% \begin{itemize}
%     \item We propose the Aspect-Aware Attention Framework (AAAF) that leverages open-domain concept extraction and expansion to address the challenge of dynamic knowledge changes in stance detection tasks. In AAAF, Open Aspect Extraction (OAE) iteratively extracts and refines target aspects by guiding Large Language Models (LLMs) reasoning, which effectively enhances the short text representation.

%     \item We design an aspect-aware attention mechanism based on semantic retrieval to integrate the relevant aspects into the text representation, in order to capture the diverse and dynamic stance knowledge. Additionally, AAAF integrates contrastive learning to further strengthen the model's discriminative capability on the text representation.
    
%     \item We conduct extensive experiments on three cross-domain benchmarks including SemEval-2016, NLPCC-2016 and P-Stance. The results demonstrate that our proposed AAAF significantly outperforms existing baseline methods, exhibiting excellent performance and technical advantages in short text stance detection tasks.
% \end{itemize}

% \subsection{Stance detection}

% The hierarchical text classification (HTC) task is a challenging sub-task of multi-label text classification \cite{zangari2023hierarchical}. The hierarchical label dependencies of HTC can often be represented by a tree or a directed acyclic graph (DAG). Training methods of HTC models can be classified as local approaches and global approaches \cite{deng2021htcinfomax}. 
% Local approaches \cite{kowsari2017hdltex} decompose the taxonomic hierarchy and construct multiple local classifiers to classify subsets of labels.
% Compared with local approaches, global approaches have two key characteristics in common \cite{zangari2023hierarchical}. 
% They take the entire taxonomic hierarchy into account simultaneously and do not adopt modular approaches for local training of classifiers. 
% Besides the smaller model size, the main advantage of the global approaches is that misclassifications at the given level would not propagate to the next level of hierarchy.

% Current studies are mainly focused on global approaches such as graph encoders \cite{zhou2020hierarchy,deng2021htcinfomax}, semantic space mapping and matching \cite{chen2021hierarchy}, prompt methods \cite{wang2022hpt}, sequence-to-tree generation \cite{yu2022constrained,xiao2021expert}.
% Moreover, many studies \cite{lu2022multi} have simultaneously considered the combination of the global approach and local approach, which also achieved good experimental results.


% 此外，不少研究同时考虑将global approach and local approach相结合，这样的方法同样取得了较好的实验效果。
% 多标签分类
% 局部方法
% 现有方法主要是全局方法为主 such as 图编码器、语义空间映射与匹配、prompt方法、sequence-to-tree generation。


% Specifically, 对于hierarchy representation,我们通过标签体系和文本编码器，得到关系邻接矩阵和语义相似度矩阵，进而得到Label Semantic-Aware Hierarchical Adjacency Matrix （LSA-HAM）.对于文本信息，我们通过执行一个带有dropout layer的flat classifier得到初步分类结果。随后，通过Hierarchical Consistency Alignment方法生成层次特征向量，最后通过MLP层实现特征融合，输出最终分类结果以及通过balancing loss calculation进行模型训练。

% 基于知识的立场检测方法利用外部知识来源，如知识图谱、结构化数据库以及外部文本信息，来增强对给定文本立场的理解和分类。通过引入外部知识，模型能够获得更深的上下文理解，这对于识别隐含立场或理解领域特定术语尤其有用。

% 许多研究探讨了将知识图谱整合到立场检测任务中的方法。利用来自DBpedia或ConceptNet等知识图谱的嵌入表示来丰富目标和文本的表示。这些方法旨在通过建立文本中实体与知识库中的实体之间的语义连接来提高立场分类的准确性。此外，最近的研究表明，整合事实和上下文知识可以显著提升模型检测细微或隐含立场的能力，尤其是在训练数据稀少或存在偏差的情况下。

% 总而言之，基于知识的立场检测方法通过利用外部知识提供上下文、解决歧义以及识别文本与目标之间的细微关系来增强立场分类，在直接文本信息不足的复杂场景中显示出了良好的效果。


% Specifically, studies have explored the integration of knowledge graphs into stance detection tasks. The Embeddings derived from knowledge graphs such as DBpedia \cite{auer2007dbpedia} or ConceptNet \cite{speer2017conceptnet} are used to enrich the representation of both targets and text. 
% These methods aim to improve stance classification accuracy by establishing semantic connections between entities in the text and those in the knowledge base \cite{paulheim2017knowledge}. 


% 基于推理的立场检测方法强调通过逻辑推理和信息推断来识别文本中的立场。这类方法通过分析文本的论点、因果关系及隐含信息来判断其立场，对处理复杂论据的文本尤为有效。

% 近年来，自然语言推理（Natural Language Inference, NLI）模型被用于评估文本与目标陈述之间的逻辑一致性，以此推断立场标签。最近发展的一些模型采用预训练语言模型生成推理链来辅助立场检测的策略。例如，Logically Consistent Chain-of-Thought (LC-CoT) 模型通过评估外部知识需求、调用API获取背景知识、并利用if-then逻辑模板生成推理链，从而提升零样本立场检测性能。此外，Collaborative Role-Infused LLM-based Agents (COLA) 模型通过设置多角色LLM代理（如语言专家、领域专家、社交媒体专家）进行多维分析，并在推理增强的辩论阶段中由代理辩论各自立场，最后由综合代理进行立场判断，从而提升复杂场景下的立场检测准确性。

% 总的来说，基于推理的立场检测通过模拟人类的逻辑推理过程，有效处理隐含含义及多步推理情境，在复杂文本的立场检测中展现了显著优势。


% Reasoning-based stance detection methods
% These methods analyze arguments, causal relations, and implicit information in the text to determine the stance, making them particularly effective for handling texts with complex arguments in few-shot and zero-shot conditions.
% In recent years, Natural Language Inference (NLI) models\cite{conforti2020will} have been used to assess the logical consistency between the text and the target statement, thereby inferring stance labels. 


---------------
code
% This framework significantly improves contextual relevance, consistency validation, and classification accuracy by leveraging the strengths of both SLM and LLM.
 % CoVe的整体框架如下：首先，利用嵌入模型（SLM）对输入文本进行预处理，通过过滤掉无关的上下文信息，并引入相关知识，生成知识增强的文本表示。在文本分类阶段，利用大型语言模型（LLM）作为推理引擎，进行多次迭代推理，以验证分类结果的一致性。如果在迭代过程中发现结果不一致，系统将启动重新分类，确保分类的稳定性。最后，通过加权聚合的方式，将文本特征与推理结果进行融合，实现最终的立场分类。该框架通过结合SLM和LLM的优势，显著提高了上下文相关性、一致性验证及分类结果的准确性。
% \begin{algorithm}[h]
% \SetAlgoLined
% \KwIn{
%     $\mathcal{T} = \{ t_1, t_2, \dots, t_N \}$: Set of texts \\
%     $\mathcal{S} = \{ s_1, s_2, \dots, s_N \}$: Corresponding targets \\
%     $\mathcal{K}$: Knowledge base (JSON file) \\
%     $\mathcal{M}$: Set of language models \\
%     $\text{BatchSize}$: Size of each batch \\
%     $\text{Language}$: Language of texts (e.g., 'en' or 'zh')
% }
% \KwOut{
%     $\mathcal{P} = \{ (t_i, l_i, r_i) \}_{i=1}^N$: Predicted stances with explanations
% }

% Initialize empty list $\mathcal{P}$\;
% Initialize $\text{Unclassified} \leftarrow \mathcal{T}$\;
% Initialize $\text{RetryCount} \leftarrow 0$\;
% Initialize $\text{LowConfidenceSamples} \leftarrow \{\}$\;

% \While{$\text{Unclassified} \neq \emptyset$ \textbf{and} $\text{RetryCount} < \text{MaxRetries}$}{
%     Select model $M$ from $\mathcal{M}$ based on $\text{RetryCount}$\;
%     Set $\text{CurrentBatchSize} \leftarrow \text{BatchSize} / (2^{\text{RetryCount}})$\;
%     Divide $\text{Unclassified}$ into batches $\{\mathcal{B}_1, \mathcal{B}_2, \dots\}$ of size $\text{CurrentBatchSize}$\;
    
%     \ForEach{batch $\mathcal{B}$ in $\{\mathcal{B}_1, \mathcal{B}_2, \dots\}$}{
%         \ForEach{$t_i \in \mathcal{B}$}{
%             Enhance $t_i$ using knowledge base $\mathcal{K}$ to get $t'_i$\;
%             Calculate stance std difference $\sigma_{\text{diff}}(t_i, t'_i)$ as external similarity $s_{\text{exter}}$\;
%             Construct prompt $p_i$ for $t'_i$ and target $s_i$\;
%         }
%         Use model $M$ to generate responses $\{ r_i \}$ for prompts $\{ p_i \}$\;
        
%         \ForEach{response $r_i$}{
%             Extract probabilities $(p_{\text{favor}}, p_{\text{neutral}}, p_{\text{against}})$\;
%             Compute internal similarity $s_{\text{inter}}$ based on model outputs\;
            
%             \eIf{$s_{\text{inter}} \geq \text{Threshold}$ \textbf{and} $s_{\text{exter}} \geq 0$}{
%                 Determine predicted label $l_i$ using $\arg\max$ of $(p_{\text{favor}}, p_{\text{neutral}}, p_{\text{against}})$\;
%                 Append $(t_i, l_i, r_i)$ to $\mathcal{P}$\;
%             }{
%                 Add $t_i$ to $\text{LowConfidenceSamples}$\;
%             }
%         }
%     }
%     Remove classified texts from $\text{Unclassified}$\;
%     Increment $\text{RetryCount}$\;
% }

% \ForEach{sample $t_i$ in $\text{LowConfidenceSamples}$}{
%     Aggregate responses from multiple models for $t_i$, using similarity weights\;
%     Compute weighted probabilities $(p_{\text{favor}}, p_{\text{neutral}}, p_{\text{against}})$\;
%     Determine final predicted label $l_i$ with $\arg\max$\;
%     Append $(t_i, l_i)$ to $\mathcal{P}$\;
% }

% \Return{$\mathcal{P}$}
% \caption{Stance Detection Framework}
% \label{alg:stance_detection}
% \end{algorithm}


------------------


% % \subsection{Problem Definition}
% Formally, we define the hierarchical text classification (HTC) task as follows: 
% Given the set containing $n$ texts $S = \{({X_1},{Y_1}),({X_2},{Y_2}),...,({X_n},{Y_n})\}$, where $X_{i}$ is the feature vector of text instance, ${Y_i} \in {\{ 0,1\} ^{N \times 1}}$ is the vector of supervised label of the text. 

% The goal of HTC is to establish a mapping function $F$, i.e. $F(\mathbb{X}, G) \to \mathbb{Y}$. $\mathbb{X}$ is the feature space which consists of all feature vectors of text instances. $\mathbb{Y}$ is the label space which consists of all supervised label vectors. $G = \{V,E\}$ is the taxonomic hierarchy of text labels, where $V = \{ {v_i}\left| {0 \le i < N} \right.\}$ refers to a set of label nodes, $E = \{ ({v_i},{v_j})|{v_i} \in V,{v_j} \in child({v_i})\}$ is a set of edges, and $child(v_i)$ denotes the descendant label set of $v_i$ in the taxonomic hierarchy.
% $N$ is the total number of labels. 
% The label set $V$ is distributed in the hierarchical level $L = ({L^1},{L^2},...,{L^m})$, where $m$ is the total number of levels, ${L^i} = \{ {v_0},{v_1},...\}  \in {\{ 0,1\} ^{|{L^i}|}}$ is possible hierarchical level $i$.
% % $G$ is the relation information of the taxonomic hierarchy.
% % Within this broad framework, Hierarchical Multi-Label Text Classification (HMTC) specifically refers to those HTC tasks that have multiple labels at the same hierarchical level.

% Within this context, a "family" within $G$ is defined as a subset of labels $V_f \subseteq V$ that share a common ancestor label in the hierarchy.





% Then, in Batch Reasoning (\S\ref{4.2}), CoVer employs the LLM as the inference engine, performing stance prediction across multiple texts simultaneously to leverage shared contextual cues. In Consistency Verification (\S\ref{4.3}), the SLM verifies the alignment between the LLM's reasoning and predicted stance by comparing outputs, ensuring consistency.


% 本章介绍了CoVer框架的主要流程：4.1节描述了上下文重构过程，通过筛选与目标相关的句子并引入外部知识来增强文本表示，从而为立场分类提供更精准的语义支持。4.2节详细介绍了批量推理过程，通过构建提示引导大型语言模型生成文本的立场分布及解释信息，以提升立场分类的准确性。4.3节介绍了一致性检验步骤，通过小模型对解释文本进行立场分类，并与大模型的预测结果进行对比，确保分类结果的稳定性和可靠性。
% \S\ref{4.1} describes the context reconstruction process, where target-relevant sentences are selected and external knowledge is incorporated to enhance text representation, providing more precise semantic support for stance classification. \S\ref{4.2} details the batch reasoning process, where prompts are constructed to guide the large language model in generating stance distributions and explanation information, improving the accuracy of stance classification. \S\ref{4.3} presents the consistency verification step, in which a small model classifies the stance of the explanation text and compares it with the predictions of the large model, ensuring the stability and reliability of the classification results.

% In the hierarchical text classification task, child labels are subordinate to their parent labels. 
% Building upon the structural and semantic information of the hierarchy, we propose the Label Semantic-Aware Hierarchical Adjacency Matrix (LSA-HAM), which not only delineates the explicit hierarchical structure but also captures the implicit semantic similarities and differences between labels. This section sequentially introduces the computation methods for LSA-HAM.
% 语义上下文重构（SCR）筛选与目标相关的句子，并对文本进行重构，从而提升输入文本的表示效果，本节将依次介绍SCR的重构方法。

-----------------
方法4.1重构：

% The Hierarchical Adjacency Matrix (HAM, $M^{(*)}$)  is designed for recording the structural relation between labels. HAM consists of two matrices, i.e. the Descendant Adjacency Matrix (DAM, $M^D$) and the Ancestor Adjacency Matrix (AAM, $M^A$), which represent the up-down and down-up relationships of labels in the hierarchy, respectively.
% For each $i, j \in \{0, 1, \dots, N-1\}$, we define the HAMs as follows:
% \vspace{-5pt}
% \begin{equation}
% \small
% M^D_{i,j} = \left\{ 
% \begin{array}{ll}
% 1 & \text{if } (v_i, v_j) \in E \\
% 0 & \text{otherwise},
% \end{array} 
% \right.    
% \end{equation}
% \vspace{-5pt}
% \begin{equation}
% \small
% M^A_{i,j} = \left\{ 
% \begin{array}{ll}
% 1 & \text{if } (v_j, v_i) \in E \\
% 0 & \text{otherwise.}
% \end{array} 
% \right.
% \end{equation}
% \vspace{-5pt}
% where $M^D$ denotes the DAM and $M^A$ represents the AAM.
% \vspace{-10pt}
% \subsubsection{Label Semantic Similarity Matrix:}
% The Label Semantic Similarity Matrix (LSSM) can be employed to record the similarities between labels.
% We define the Label Semantic Similarity Matrix ($S$) through cosine similarity computations of label embeddings.
% Given a label $v$, its label embedding  $\text{Enc}(v)$ is provided by a specific output from the text encoder.
% For the label pair $v_i$  and $v_j$, their semantic similarity  $\text{Sim}(v_i, v_j)$ is computed using cosine similarity:
% \vspace{-4pt}
% \begin{equation}
% \text{Sim}(v_i, v_j) = \frac{\text{Enc}(v_i) \cdot \text{Enc}(v_j)}{||\text{Enc}(v_i)||_2 \times ||\text{Enc}(v_j)||_2},   
% \end{equation}

% where $\cdot$ denotes the dot product between two embeddings, and $||\cdot||_2$ is the L2 norm. 
% For all the set of labels  $V = \{ v_1, v_2, ..., v_N \}$, the Label Semantic Similarity Matrix $S$ is calculated as:
% \vspace{-4pt}
% \begin{equation}
%  S_{i,j} = \text{Sim}(v_i, v_j).
% \end{equation}

% \vspace{-6pt}
% \subsubsection{Label Semantic-Aware Hierarchical Adjacency Matrix:}
% % $\theta$ is the scale factor to expand the  
% We integrate the Label Semantic Similarity Matrix with the Hierarchical Adjacency Matrix to obtain the Label Semantic-Aware Hierarchical Adjacency Matrix (LSA-HAM), which is calculated as follows:

% \begin{equation}
% \small
% H_{i,j}^{D} = 
% \begin{cases} 
% \alpha \times S_{i,j} & \text{if } M_{i,j}^{D} = 0 \\
% min(\theta + S_{i,j},1) & \text{otherwise},
% \end{cases}
% \end{equation}
% % \vspace{-5pt}
% \begin{equation}
% \small
% H_{i,j}^{A} = 
% \begin{cases} 
% \alpha \times S_{i,j} & \text{if } M_{i,j}^{A} = 0 \\
% min(\theta + S_{i,j},1) & \text{otherwise},
% \end{cases}
% \end{equation}

% where $H=[H^D, H^A]$ is the LSA-HAM, with $H^D$ and $H^A$ representing the components of LSA-DAM and LSA-AAM respectively. To avoid excessive interference of semantics between relational labels of non-identical families on the hierarchy, we set a scale factor $\alpha$ to constrain the maximum value of semantic similarity between labels of non-identical families. Additionally, $\theta$ is the bias value of the other labels, ensuring the clear representation of structural relations.

% Compared to HAM, LSA-HAM not only considers the inherent label hierarchical structure, but also introduces the label semantic similarity, which means that the model can have richer background knowledge about the labels, and improves the generalization for correctly classifying different label combinations.


% 通过以下计算方式，我们将标签关系和意义相似度进行聚合，得到语义增强的标签关系矩阵（LSA-HAM）:
% 为避免非同上下位关系标签间的语义对层级关系造成过分的干扰，我们设置了一个比例引子$\alpha$来约束非同类标签间语义关系的最大值。
% LSA-HAM的计算方法如下：

% 相比于仅通过关系矩阵，SRM不仅考虑了标签间的固有层级结构，还引入了标签之间的语义相似性。
% 这意味着在后续的标签依赖关系特征抽取中，模型能有更丰富的背景知识，提高模型对不同标签组合进行正确分类的泛化性。


% 以往的工作中，
% \cite{giunchiglia2020coherent}
% 直接对标签依赖关系进行硬编码并以此作为约束条件来增强标签分类的一致性。

% \cite{zhou2020hierarchy}
% 有引入标签在training corpus中的共现概率作为反映标签依赖关系的特征

% 基于标签关系矩阵，可以实现对标签间上下位关系的记录。
% 为兼顾标签的上下位关系和语义关联，我们将标签语义相似度矩阵与标签关系矩阵进行融合。
% Specifically, 

% 对于层级标签的关系来说，

---------------

% However, directly classifying the stance at this stage may not capture subtle contextual nuances, especially for complex or ambiguous expressions. Instead, we compute an average similarity score between the given tweet and each stance category (Favor, Against, None) based on embeddings. This similarity-based approach provides a probabilistic stance estimation, which serves as a foundation for assessing the relevance of each sentence.

% To model target relevance, CoVer employs the SLM as an embedder to compute the relevance of a given tweet with respect to stance categories as 

% For the annotated single-label dataset $\mathcal{D}_k = \{(x_k, t_k, y_k)\}_{i=1}^{n_k}, k \in \{\text{Favor},\text{Against},\text{None}\}$, we analysis the 
% For a tweet $t_i$ with sentence set $\mathcal{S}_{t_i}=\{s_{t_i,j}\}_{j=1}^{S_{t_i}}$, we compute its stance similarities across three categories using the embedder:
% \begin{equation}
%     \text{sim}_k(t_i) = \frac{1}{|\mathcal{D}_k|} \sum_{d \in \mathcal{D}_k} \text{cosine}(h_t, h_d), \quad k \in \{\text{Favor},\text{Against},\text{None}\},
% \end{equation}
% where $\mathcal{D}_k$ represents the sample tweet set of stance category $k$, and $h_T,h_d$ denote the SLM-generated embeddings.

% The stance variance $\sigma^2$ measuring similarity dispersion is computed as:
% \begin{equation}
%     \sigma^2 = \frac{1}{3} \sum_{k \in \{f,a,n\}} (\text{sim}_k(T) - \mu)^2
% \end{equation}
% where $\mu = \frac{1}{3}\sum_{k \in \{f,a,n\}} \text{sim}_k(T)$ is the mean similarity.

% The core sentence identification process involves:
% \begin{enumerate}
%     \item Sentence-level relevance scoring: For each sentence $a_i$, compute its relevance to target $t$ via:
%     \begin{equation}
%         r_i = \text{cosine}(h_{a_i}, h_t)
%     \end{equation}
    
%     \item Relevance filtering: Retain sentences with relevance scores above threshold $\delta$:
%     \begin{equation}
%         X = \{a_i | r_i \geq \delta\}
%     \end{equation}
    
%     \item Iterative pruning: Remove sentences from $X$ sequentially. A sentence is pruned if its removal increases $\sigma^2$, indicating it dilutes stance signals.
% \end{enumerate}

% This filtering process effectively removes stance-irrelevant content while preserving core sentences that contribute to stance expression, thereby improving the efficiency of subsequent LLM-based reasoning.




% sentence Filtering divides the input text into multiple sentences, forming a sentence set \( A = \{ a_i \}_{i=1}^M \), where \( M \) denotes the total number of sentences in the text.



% % single-label dataset $\mathcal{D}_k = \{(x_k, t_k, y_k)\}_{i=1}^{n_k}, k \in \{\text{Favor},\text{Against},\text{None}\}$ for each stance \( y \):
% % By obtaining $\hat{P}(y|t)$, we computing the SD via formula \ref{SD}.

% % where \({sim}(h_i, h_t) = \frac{h_i \cdot h_t}{\|h_i\| \|h_t\|}\) is the cosine similarity of the embedding between the text embedding \( h_i \) and the stance template \( h_{s_y} \).

% % \vspace{-6pt}


% % Context Reconstruction selects target-relevant sentences and attach external knowledge to restructure the context of texts to context augmentation. 
% % This section details the reconstruction methods of CR.
% % Relevance-based Sentence Filtering (RSF)首先将输入文本划分为多个句子，构建句子集合 \( X = \{ x_i \}_{i=1}^M \)，其中 \( M \) 表示文本中句子的总数。



% % 为了评估每个句子 \( x_i \) 与目标 \( T \) 的相关性，我们计算句子嵌入 \( h_i \) 和目标嵌入 \( h_T \) 之间的余弦相似度 \( \text{sim}(h_i, h_T) \)，\[ \text{sim}(h_i, h_T) = \frac{h_i \cdot h_T}{\|h_i\| \|h_T\|}\] 基于相似度得分，设定一个相关性阈值 \( \delta \)，仅保留与目标相关性大于 \( \delta \) 的句子，得到相关句子集合 \( \hat{X} \)，\[\hat{X} = \{ x_i \mid \text{sim}(h_i, h_T) \geq \delta \}\]
% To evaluate the relevance of each sentence \( a_i \) with respect to the target \( T \), we compute the cosine similarity between the sentence embedding \( h_i \) and the target embedding \( h_T \), \({sim}(h_i, h_T) = \frac{h_i \cdot h_T}{\|h_i\| \|h_T\|}\)

% Based on the similarity score \( {sim}(h_i, h_T) \), we set a relevance threshold \( \delta \), retaining only sentences with a relevance score greater than \( \delta \). The resulting set of relevant sentences \(X = \{ x_i \mid \text{sim}(h_i, h_T) \geq \delta \}\)
% %接下来，对保留的句子进行排序，并通过迭代的方式，从 \( \hat{X} \) 中逐步选取前 \( k \) 个句子，构建句子子集 \( X_i \)。计算该子集的立场标准差（Stance Standard Deviation,  std\( \text{S}(X_i) \)。具体公式如下：
% The retained sentences are sorted, and an iterative process is used to gradually select the top \( k \) sentences from \( \hat{X} \), forming a sentence subset \( X_i \). The stance standard deviation (Stance Standard Deviation, denoted as \( \text{S}(X_i) \)) of this subset is calculated. The specific formula is as follows:
% \begin{equation}
%     \text{S}(X_i) = \sqrt{\frac{1}{k} \sum_{i=1}^k \left( \text{sim}(X_i, T) - \bar{L} \right)^2}
% \end{equation}



% % 其中，\( k \) 表示子集中句子的数量，\( \text{Sim}(s_i, t) \) 代表句子 \( s_i \) 与目标 \( t \) 之间的相似度，\( \bar{L} \) 则表示子集内所有句子与目标相似度的平均值。
% Where, \( k \) represents the number of sentences in the subset, \( \text{Sim}(X_i, T) \) denotes the similarity between the sentence \( s_i \) and the target \( t \), and \( \bar{L} \) indicates the average similarity of all sentences in the subset with the target.
----------------
3。1


% \vspace{-8pt}
% \vspace{-8pt}
% 零样本立场检测被定义为在没有为特定目标 $t$ 提供任何特定训练样本的情况下，自动分类给定推文 $x$ 对特定目标 $t$ 所表达的立场。推文 $x$ 由一系列单词 $\{w^x_0, w^x_1, \ldots\}$ 组成，而目标 $t$ 由一系列单词 $\{w^t_0, w^t_1, \ldots\}$ 组成。零样本立场检测的目标是从预定义的立场标签集合 $y = \{\text{支持}, \text{中立}, \text{无}\}$（中确定立场标签 $y$，其中 $y$ 表示 $x$ 对 $t$ 的立场，而模型在训练阶段并没有直接接触与目标 $t$ 相关的标签或实例。
% \section{Definition}
% \section{Problem Statement}
% % \begin{definition}[{Zero-Shot Stance Detection}] 
% Zero-Shot Stance Detection (ZSSD) \cite{kuccuk2020stance,li2021p,allaway2020zero,mohammad2016semeval} is defined as the task that classifying the stance ({Favor}, {Against}, {None}) expressed in a given tweet $x$ towards a specific target $t$ without providing any specific training data or reference sample about the target $t$. 
% \end{definition}

% $\mathcal{Y} = \{\text{Favor}, \text{Against}, \text{None}\}$ be the stance label set

% \begin{definition}[Stance Variance] 
% Stance Variance (SD) is the variance of stance label distribution of a tweet $x$, indicating how discriminative the tweet expresses its stance.
% It is calculated as:
% \begin{equation}
% \label{SD}
%     \text{SD}_x=\sigma^2=\frac{1}{|\mathcal{Y}|} \sum_{y \in \mathcal{Y}} (P(y|t,x) - \mu)^2, \mu = \sum_{y \in \mathcal{Y}} P(y|t,x)/|\mathcal{Y}|,
% \end{equation}
% where $\mathcal{Y}$ is the stance label set \{Favor, Against, None\}. A larger variance implies the tweet better externalizes its stance expression.

% \end{definition}



% where embedder is the SLM used for text representation. $\text{sim}(\cdot, \cdot)$ is the cosine similarity.
% Based on $\hat{P}(y|t)$, we obtain the $\text{SD}_x$ via formula \ref{SD}.





% \begin{equation}
%     \hat{P}(y|x,t) = \frac{\exp(\text{sim}(\text{embedder}(x), \text{embedder}(s_y(t))))}{\sum_{y' \in \mathcal{Y}} \exp(\text{sim}(\text{embedder}(x), \text{embedder}(s_{y'}(t))))},
% \end{equation}

% where \( \text{embedder} \) is the SLM used for text representation, \( \mathcal{Y} \) is the set of stance labels \(\{\text{Favor}, \text{Against}, \text{None}\}\), and \( s_y(t) \) is the stance phrase associated with stance \( y \) and target \( t \). Using these normalized likelihoods \( \hat{P}(y|t) \), we then compute the stance variance \( \text{SD}_x \) as described in Equation \ref{SD}.


% \begin{equation} 
% \mathcal{X}^* = \arg\max_{\text{Sentence set}} \text{SD}_x \end{equation}


% The stance standard deviation of the augmented sentence set \( X_i^{\text{aug}} \) is denoted as \( \text{S}(X_i^{\text{aug}}) \). We select the external knowledge \( (t_i, e_i) \) that maximizes the stance standard deviation \( \text{S}(X_i^{\text{aug}}) \), thereby constructing the optimal sentence set \( X^* \).

% \begin{equation}
%     X^* = \underset{i \in \{1, 2, \ldots, K\}\ }{\text{argmax}} \ \text{S}(X_i^{\text{aug}})
% \end{equation}

% \begin{equation}
%     x^* = \underset{x' \subset x}{\text{argmax}} \ \text{SD}(x'),
% \end{equation}

%Compared to the lengthy tweets, short tweets are more common in most cases.
% Knowledge-Based Context Enhancement进一步引入与目标 \( T \) 相关的外部知识 \( \mathcal{K} \)，构建最佳句子集合 \( X^* \)。
%construct the optimal sentence set \( X^* \).
% 外部知识 \( \mathcal{K} \) 可以表示为 \(\{ (t_i, e_i) \mid i \in \{1, 2, \ldots, K\} \}\)，其中 \( t_i \) 为知识术语，\( e_i \) 为与术语 \( t_i \) 相关的解释。通过引入额外的上下文信息，可以提升句子集合的语义表达能力，使其更好地匹配目标的立场和内容，从而有效提高分类模型的准确性和稳定性。
%Knowledge-Based Context Enhancement further introduces external knowledge \( \mathcal{K} \) relevant to the target \( T \) to 

%By introducing additional contextual information, the semantic representation capability of the sentence set can be enhanced, allowing it to better align with the target's stance and content, thereby effectively improving the accuracy and stability of the classification model.

%增强后的句子集合 \( X_i^{\text{aug}} \) 的立场标准差表示为 \( \text{S}(X_i^{\text{aug}}) \)。我们选择能够最大化立场标准差 \( \text{S}(X_i^{\text{aug}}) \) 的外部知识 \( (t_i, e_i) \)，从而构建最佳句子集合 \( X^* \)。






%该方法通过选择能最大化立场标准差的外部知识，优化了句子集合\( X_i \) 的语义表达能力。

% This method optimizes the semantic representation of the sentence set \( X_i \) by selecting external knowledge that maximizes the stance standard deviation.
---------------
3.2


% $\mathbf{x_D}$ is the output of $\mathbf{x}$ aligned consistently by DAM, $\mathbf{x_A}$ is the output of $\mathbf{x}$ aligned consistently by AAM.

% Among them, 


% To ensure the hierarchical consistency of the output, the core idea of HCA is to map the high probability of an individual label to its entire family. 
% However, after the hierarchical consistency alignment of labels, it is hard to distinguish those labels within the same family.
% % In the section \ref{IF}, we introduce an information fusion mechanism to integrate the information from $\mathbf{x}$, $\mathbf{x_A}$ and $\mathbf{x_D}$.
% Considering this, we integrate $\mathbf{x}$, $\mathbf{x_A}$ and $\mathbf{x_D}$ to calculate the label prediction:
% \begin{equation}
% \label{xc}
%     \mathbf{p}=\sigma({\bf{W}} \cdot \mathbf{x_{C}}+{\bf{b}}),
% \end{equation}

% where $ \mathbf{p}\in \mathbb{R}^{N\times 1} $ is the final prediction result of the sample, and $ \mathbf{x_C}\in \mathbb{R}^{3N\times1} $ is the concatenation of $\mathbf{x}$, $ \mathbf{x_A} $, and $ \mathbf{x_D} $. $\sigma$ is the sigmoid function.
% Z ????? z_i

% Due to the challenge of distinguishing individual labels within a family , it is imperative in subsequent procedures to introduce an information fusion mechanism to integrate the information from \(x\), \(x_A\), and \(x_D\).
% 由于通过家族映射后的标签概率分布难以具体区分家族内的标签。因此，在后续过程中，我们需要引入一个信息融合机制，将$x$、$x_A$、$x_D$三者的信息进行集成。


% The core idea is to ensure that the classification output aligns with the taxonomic hierarchy.
% By mapping the high probability of individual label to its whole family, we can ensure the consistency in hierarchical classification.
% The core idea is to utilize the Hadamard product operation between the matrix $C$, where each row is a replica of the flat classification output $x$, and the hierarchical adjacency matrix \( H \). The resultant matrix $W$ undergoes a series of operations to produce the desired consistency-constrained output $z$.
% 假设$X in \mathbb{R}^{1 \times N}$ 为flat classification的输出。
% 通过将单个数据点的高概率映射至整个家族，进而保证层级分类的一致性





% 平衡损失函数


----------------

% 当余弦相似度 \text{sim}\left(\mathbf{P}_{\text{big}}(x_i), \mathbf{P}_{\text{exp}}(x_i)\right) 小于阈值 \( \delta \) 时，大模型的预测结果和小模型的预测结果存在较大差异，需要进行重新分类。此时，将进行多轮推理，并将每一轮的推理结果 \( R^{(1)}, R^{(2)}, \ldots, R^{(m)} \) 分别计算 favor、neutral 和 against 三个立场标签的概率分布 \( P^{(j)}_{\text{favor}}(x_i), P^{(j)}_{\text{neutral}}(x_i), P^{(j)}_{\text{against}}(x_i) \)。
% When the consistency function  \( f\left(\mathbf{P}_{\text{LLM}}, \mathbf{P}_{\text{SLM}}\right) \) is lower than the threshold \( \delta \), there is a significant difference between the prediction results of the large model and the small model, indicating the need for reclassification. In this case, multiple rounds of inference are performed, and the probability distributions of the three stance labels, favor, neutral, and against, are calculated for each inference round \( R^{(1)}, R^{(2)}, \ldots, R^{(m)} \) as \( P^{(j)}_{\text{favor}}(x_i), P^{(j)}_{\text{neutral}}(x_i), P^{(j)}_{\text{against}}(x_i) \).



% 当一致性函数 \( f\left(\mathbf{P}_{\text{LLM}}, \mathbf{P}_{\text{SLM}}\right) \) 低于阈值 \( \delta \) 时，表明大模型（LLM）和小模型（SLM）的预测结果存在显著差异，需要进行重新分类。在这种情况下，进行多轮推理。在每一轮推理 \( R^{(1)}, R^{(2)}, \ldots, R^{(m)} \) 中，计算三个立场标签 favor、neutral 和 against 的概率分布向量 \( \mathbf{P}^{(j)}_(SLM), \mathbf{P}^{(j)}_(LLM)\)，用于表示每一轮推理中的立场概率分布。


% 在多轮推理后，通过将每轮推理的余弦相似度\text{sim}\left(\mathbf{P}_{\text{big}}(x_i), \mathbf{P}_{\text{exp}}(x_i)\right)作为权重值加权融合综合每一轮的推理结果。从而得到三个立场标签的最终概率。



After multiple rounds of inference, the consistency function \( f\left(\mathbf{P}_{\text{LLM}}, \mathbf{P}_{\text{SLM}}\right) \) is used as a weight to aggregate and integrate the inference results from each round. Thus, the final probability vector for the three stance labels is obtained as:
\begin{equation}
    l(x_i) = \arg \max \left(\frac{\sum_{j=1}^m w_j \cdot P^{(j)}_{\text{LLM}}}{\sum_{j=1}^m w_j}\right)
\end{equation}
Finally, the label with the maximum probability is selected as the final stance label. Through the above steps, the predictions of the large model and the small model can be effectively combined, thereby enhancing the stability and accuracy of the stance detection task.








% \begin{equation}
%     Q_R =  P_{R} \oplus \mathcal{B}
% \end{equation}
% \begin{equation}
%     \{(P_{\text{LLM},i}, e_i)\}_{i=1}^B = \arg\max_{y} \prod_{i=1}^B P(y | x_i, t_i, \text{LLM}, \mathcal{B})
% \end{equation}


% In the batch inference stage of the CoVer framework, prompts are directly constructed to guide LLM in generating the stance distribution and explanations for each text. 
% For each context-reconstructed text, we construct prompts in the following format:

% \begin{equation}
%     p =  X^* \oplus T_p \oplus l_p
% \end{equation}



% % 将当前推理的目标信息 \( t_p \) 和实例标签信息 \( l_p \) 作为输入，构建一个完整的 Prompt。然后将该 Prompt 输入到大语言模型 \( \mathcal{M} \) 中，以生成其他文本的专家信息和预测标签。
% The target information \( T_p \) and the instance label information \( l_p \) of the current inference are taken as input to construct a complete Prompt. Then, the constructed Prompt is fed into the large language model \( \mathcal{M} \) to generate expert information and predicted labels for other texts.

% \begin{equation}
%     \hat{l}_j, E_j = {\text{LLM}}(p\oplus l_j)
% \end{equation}



% % 其中，\( \hat{l}_j \) 表示大语言模型（LLM）预测的文本 \( X^* \) 相对于目标 \( t_j \) 的立场标签（如支持、反对或中立）的概率分布，\( E_j \) 则表示与该预测结果 \( \hat{l}_j \) 相关的解释信息。
% Where, \( \hat{l}_j \) represents the stance label probability distribution of the text \( X^* \) predicted by the large language model (LLM) with respect to the target \( t_j \) (such as support, oppose, or neutral), and \(E_j \) denotes the explanation information related to the predicted result \( \hat{l}_j \).


% 一致性检验部分首先使用预训练的 BERT 模型来对解释文本进行立场分类。将解释文本 \(E_j \) 编码为向量表示，然后通过 BERT 模型获取该文本的隐向量 \( \mathbf{H}_i \)，并提取分类标记 [CLS] 的表示 \( \mathbf{h}_i^{\text{[CLS]}} \)。接着，\( \mathbf{h}_i^{\text{[CLS]}} \) 被输入到一个全连接的分类层中，生成 favor、neutral 和 against 三个标签的 logits 分数 \( \mathbf{z}_i \)。通过 softmax 函数将这些 logits 转化为立场概率向量\( P\)，从而得出解释文本在三种立场下的概率分布。
% In the consistency verification stage, a pre-trained BERT model is first used to classify the stance of the explanation text. The explanation text \( E_j \) is encoded into a vector representation, and then the hidden vector of the text \( \mathbf{H}_i \) is obtained through the BERT model, extracting the [CLS] token representation \( \mathbf{h}_i^{\text{[CLS]}} \). Next, \( \mathbf{h}_i^{\text{[CLS]}} \) is fed into a fully connected classification layer, generating the logits scores \( \mathbf{z}_i \) for the three labels: favor, neutral, and against. The softmax function is then used to convert these logits into stance probabilities \( P_{\text{favor}}^{E_j}(T_i) \), \( P_{\text{neutral}}^{E_j}(T_i) \), and \( P_{\text{against}}^{E_j}(T_i) \), thereby obtaining the probability distribution of the explanation text across the three stance labels.


% 一致性检验部分使用预训练的BERT模型对解释文本进行立场分类。具体而言，首先将解释文本编码为向量表示，经过双隐层处理后生成隐层表示 \( h \)。该表示再通过一个全连接层，其中 \( W \) 和 \( b \) 分别为全连接层的权重和偏置项，并使用softmax作为激活函数，将logits向量转换为立场概率向量 \( P_i \)：

% 其中，\( P \) 是预测的立场概率分布向量，表示文本在 favor、neutral 和 against 三个标签上的概率分布。


% 对于每个样本 \( x_i \)，大模型预测的 favor、neutral 和 against 三个标签的概率分别记为 \\mathbf{P}_{\text{big}}(x_i) = \left[ P_{\text{favor}}^{\text{big}}(x_i), P_{\text{neutral}}^{\text{big}}(x_i), P_{\text{against}}^{\text{big}}(x_i) \right]。同样，小模型根据解释文本的预测结果表示为 \mathbf{P}_{\text{exp}}(x_i) = \left[ P_{\text{favor}}^{\text{exp}}(x_i), P_{\text{neutral}}^{\text{exp}}(x_i), P_{\text{against}}^{\text{exp}}(x_i) \right]。通过计算两者之间的余弦相似度 \( \text{sim}(\mathbf{P}_{\text{big}}(x_i), \mathbf{P}_{\text{exp}}(x_i)) \) 来量化模型结果相似度。


% For each sample \( x_i \), the probabilities predicted by the large model for the three labels—favor, neutral, and against—are denoted as \( \mathbf{P}_{\text{LLM}}(x_i) = \left[ P_{\text{favor}}^{\text{LLM}}(x_i), P_{\text{neutral}}^{\text{LLM}}(x_i), P_{\text{against}}^{\text{LLM}}(x_i) \right] \). Similarly, the predictions of the small model based on the explanation text are represented as \( \mathbf{P}_{\text{SLM}}(x_i) = \left[ P_{\text{favor}}^{\text{SLM}}(x_i), P_{\text{neutral}}^{\text{SLM}}(x_i), P_{\text{against}}^{\text{SLM}}(x_i) \right] \). The similarity between the results of the two models is quantified by calculating the cosine similarity \( \text{C}(\mathbf{P}_{\text{LLM}}(x_i), \mathbf{P}_{\text{SLM}}(x_i)) \).

% \[
% \text{C}\left(\mathbf{P}_{\text{LLM}}(x_i), \mathbf{P}_{\text{SLM}}(x_i)\right) = \frac{\mathbf{P}_{\text{LLM}}(x_i) \cdot \mathbf{P}_{\text{SLM}}(x_i)}{\left\|\mathbf{P}_{\text{LLM}}(x_i)\right\| \left\|\mathbf{P}_{\text{SLM}}(x_i)\right\|}
%  \]

% % 当余弦相似度\text{sim}\left(\mathbf{P}_{\text{big}}(x_i), \mathbf{P}_{\text{exp}}(x_i)\right) 大于等于设定阈值 \( \delta \) 时，大模型的预测结果和小模型的预测结果是一致的。此时，直接采纳大模型的预测结果 \mathbf{P}_{\text{big}}(x_i)作为最终的预测结果。
% When the cosine similarity \( \text{sim}\left(\mathbf{P}_{\text{LLM}}(x_i), \mathbf{P}_{\text{SLM}}(x_i)\right) \) is greater than or equal to the set threshold \( \delta \), the prediction results of the large model and the small model are considered consistent. In this case, the prediction result of the large model \( \mathbf{P}_{\text{LLM}}(x_i) \) is directly adopted as the final prediction result.
% For each sample \( x_i \), the probabilities predicted by the large model for the three labels—favor, neutral, and against—are denoted as \( \mathbf{P}_{\text{LLM}}(x_i) = \left[ P_{\text{favor}}^{\text{LLM}}(x_i), P_{\text{neutral}}^{\text{LLM}}(x_i), P_{\text{against}}^{\text{LLM}}(x_i) \right] \). Similarly, the predictions of the small model based on the explanation text are represented as \( \mathbf{P}_{\text{SLM}}(x_i) = \left[ P_{\text{favor}}^{\text{SLM}}(x_i), P_{\text{neutral}}^{\text{SLM}}(x_i), P_{\text{against}}^{\text{SLM}}(x_i) \right] \). The consistency between the results of the two models is quantified by calculating the consistency function \( \text{C}(\mathbf{P}_{\text{LLM}}(x_i), \mathbf{P}_{\text{SLM}}(x_i)) \).




% 对于每个样本 \( x_i \)，大模型预测的 favor、neutral 和 against 三个标签的概率分布表示为向量 \( \mathbf{P}_{\text{LLM}} \)。同样，小模型基于解释文本的预测结果表示为向量 \( \mathbf{P}_{\text{SLM}}\)。通过计算一致性函数 \( \text{C}(\mathbf{P}_{\text{LLM}}, \mathbf{P}_{\text{SLM}}) \) 来量化两个模型结果的一致性。


% \begin{equation}
%     \text{F_c}\left(\mathbf{P}_{\text{LLM}}(x_i), \mathbf{P}_{\text{SLM}}(x_i)\right) = \frac{\mathbf{P}_{\text{LLM}}(x_i) \cdot \mathbf{P}_{\text{SLM}}(x_i)}{\left\|\mathbf{P}_{\text{LLM}}(x_i)\right\| \left\|\mathbf{P}_{\text{SLM}}(x_i)\right\|}
% \end{equation}



% % 最后，选择具有最大概率的标签作为最终的立场标签：
% Finally, the label with the maximum probability is selected as the final stance label:
%    \[
%    l(x_i) = \arg \max \left(\hat{P}_{\text{favor}}(x_i), \hat{P}_{\text{neutral}}(x_i), \hat{P}_{\text{against}}(x_i)\right)
%    \]

% % 通过上述步骤，可以有效地结合大模型和小模型的预测结果，从而增强立场检测任务的稳定性和准确性。
% Through the above steps, the predictions of the large model and the small model can be effectively combined, thereby enhancing the stability and accuracy of the stance detection task.




















% 其中，分子表示两个向量的点积，分母表示两个向量的范数乘积。
% class--label
% 层级文本分类任务中，上级标签天然地多于下级标签的数量。
% 因此，基于全局方法处理HTC任务就需要克服标签长尾分布。
% 在计算分类损失的时候，结合每类标签的样本数量分布情况，加权计算损失将是一个可行的方法。
% We introduce Class Balanced (CB) Focal Loss \cite{cui2019class} 以及该loss方法的 negative-tolerant regularization版本\cite{huang2021balancing} 来优化损失计算。
% 对于数据集$({x^1},{y^1}),...,({x^N},{y^N})$，${y^k} = [y_1^k,...,y_c^k] \in {\{ 0,1\} ^c}$为样本$k$对应的真实标签，${z^k} = [z_1^k,...,z_c^k] \in R$是分类器的输出。
% 使用sigmoid function计算$p_k^i$，$p_k^i = \sigma (z_k^i)$
% 对于每类的平衡权重，计算方法如下：

% In hierarchical text classification tasks, the higher-level labels are usually more numerous than the lower-level labels. This presents a challenge due to the long-tail distribution of data, necessitating global approaches to tackle the issue. One such approach involves weighting the classification loss using the distribution of samples for each label. To optimize the loss calculation, we utilize the Class Balanced (CB) Focal Loss \cite{cui2019class} along with its variant that incorporates negative-tolerant regularization \cite{huang2021balancing}. 
% In hierarchical text classification, the prevalence of higher-level labels often surpasses that of lower-level ones, resulting in the long-tail distributing phenomenon. To address this issue, we utilize the Class Balanced (CB) Focal Loss \cite{cui2019class} and its variant incorporating negative-tolerant regularization (CB-NTR) \cite{huang2021balancing}. These methods are employed to compute the classification loss based on the sample distribution.

% % considering
% Consider the text-label pair $({X_k},{Y_k})$, where \({Y_k} = [y_k^1,...,y_k^N] \in {\{ 0,1\} ^N}\) denotes the true labels for sample \(k\), and \({z_k} = [z_k^1,...,z_k^N] \in \mathbb{R}^N\) represents the outputs of S\textsuperscript{2}-HTC. The weight for each class is determined by:

% % Consider the text-label pair $({X_k},{Y_k})$, where \({Y_k} = [y_k^1,...,y_k^N] \in {\{ 0,1\} ^N}\) denotes the true labels for sample \(k\), and \({z_k} = [z_k^1,...,z_k^N] \in \mathbb{R}^N\) represents the outputs of S\textsuperscript{2}-HTC. The weight for each class is determined by:

% \begin{equation}
% \small
%     {r_{CB}} = \frac{{1 - \beta }}{{1 - {\beta ^{{n_i}}}}},
% \end{equation}

% where ${n_i}$ is the number of samples in the label $v_i$, $\beta  \in [0,1)$ is used to adjust the influence of weight.
% The BCE Loss Function based on the Class-Balanced approach is as follows:
% \begin{equation}
% \small
% \mathcal{L}_{CB} = \left\{ \begin{array}{l}
%  - {r_{CB}}{(1 - p_k^i)^\gamma }\log (p_k^i)\quad{\rm if}\ y_k^i{\rm{ = 1 }}\\
%  - {r_{CB}}(p_k^i)\log (1 - p_k^i) \quad {\rm{otherwise}},
% \end{array} \right.
% \end{equation}

% where $\mathcal{L}_{CB}$ is the CB Focal loss, $\gamma \in \mathbb{R}$ is the adjustment parameter, and the probability \(p_k^i\) is calculated as \(p_k^i = \sigma (z_k^i)\).

% % Using \(L_{CB}\), \(L_{CB-NTR}\) \cite{huang2021balancing} assigned lower weights to easily classified negative samples by integrating negative tolerance regulation (NTR) into the loss function, resulting in:
% % Based on the $L_{CB}$, $L_{CB-NTR}$ \cite{huang2021balancing} proposed assigning reduced weights to easily classified negative samples. They incorporated the concept of negative tolerance regulation (NTR) into the loss computation, leading to the subsequent formulation of the loss function:
% % They incorporated the concept of negative tolerance regulation (NTR) into the loss computation, leading to the subsequent formulation of the loss function:
% The CB-NTR Focal Loss \cite{huang2021balancing} aims to integrate negative tolerance regulation (NTR) into the loss function, which assigns lower weights to those easily classified negative samples: 

% \begin{equation}
% \small
%     q_k^i = \left\{ \begin{array}{l}
%  \sigma (z_k^i)\quad {\rm if}\  y_k^i=1\\
%  \sigma (\lambda z_k^i)\quad {\rm{otherwise}},
% \end{array} \right.
% \end{equation}

% \begin{equation}
% \small
%     \mathcal{L}_{CB - NTR} = \left\{ \begin{array}{l}
%  - {r_{CB}}{(1 - q_k^i)^\gamma }\log (q_k^i)\quad {\rm if}\ y_k^i=1\\
%  - {r_{CB}}\frac{1}{\lambda }(q_k^i)\log (1 - q_k^i)\quad{\rm{otherwise}},
% \end{array} \right.
% \end{equation}

% where $\mathcal{L}_{CB - NTR}$ is the CB-NTR Focal Loss, and $\lambda \in \mathbb{R}$ is the NTR factor to control weights of negative samples.

% % gamma=2
% % lambda=2
% % 



% \vspace{-6pt}
% \subsection{Contrastive Learning for Text Embedding Optimization}
% \vspace{-6pt}
% Contrastive Learning (CL) enhances sample representation by narrowing intra-class distances and widening inter-class distances. We adopt CL technique in the HTC task to examine its effect on multi-label tasks. 

% Notably, Simple Contrastive Learning of Sentence Embeddings (SimCSE, \cite{gao2021simcse}) creates superior sentence embeddings using contrastive learning with in-batch negatives. Given a dataset $D = \{ ({x_i},x_i^ + )\} _{i = 1}^N$, where the text pair ${x_i}$ and $x_i^ + $ are semantically related, $N$ is the total number of sample pairs. In the batch with $n$ pairs, the SimCSE optimization objective is:
% \vspace{-5pt}
% \begin{equation}
% \small
% \mathcal{L}_i =  - \log \frac{{{e^{\text{Sim}({x_i},x_i^ + )/\tau }}}}{{\sum\nolimits_{j = 1}^n {{e^{\text{Sim}({x_i},x_j^ + )/\tau }}} }},
% \end{equation}

% where $\tau $ is the temperature hyperparameter. 
% % where $sim({h_1},{h_2})$ is the cosine similarity, and $\tau$ is a temperature parameter.

% For unsupervised CL, sample pairs arise from slight text encoder variations, while supervised CL pairs samples based on label consistency. To counter sample sparsity, we group samples under common parent labels. After optimizing the pre-trained model's sample representation via CL, it's further refined for specific downstream tasks.



---------------------

% , and that each tweet’s stance is faithfully represented despite potential contextual interference.

% tweets also could be negatively impacted by the shared context in batch reasoning, leading to inconsistencies between the LLM's stance predictions and its explanations. Specifically, if the LLM’s generated explanation truly reflects its stance prediction distribution, then a third-party model (SLM) observing only the explanation should yield a stance probability distribution consistent with the LLM’s prediction. 

% 在batch reasoning中，单个tweet可能在预测过程中受到共享上下文的负面影响，这表现在模型对样本的预测分数和解释的不一致性上。
% 如果LLM生成的理由能忠实地反映大模型的预测分布，则第三者（SLM）仅根据理由而观测到的立场概率分布应该和大模型的预测一致。

% 在批处理推理（batch reasoning）过程中，单个推文可能会因共享上下文的负面影响而受到干扰，导致LLM生成的解释无法忠实地反映大模型的实际预测结果，意味着模型的推理结果存疑。

% 据此，我们利用小模型对大模型提供的预测和对应解释进行后验证。分类器（SLM）和推理者（LLM）在不同视角下得出的预测是一致的，我们认为这个结果是更为可信的。这意味着解释模型能够忠实地反映大模型的预测，从而提高了解释的可信度和透明度

% 如果大型语言模型（LLM）生成的解释无法忠实地反映大模型的实际预测结果，则可以认为大型语言模型（LLM）生成的解释存在一致性问题。

%当解释和原始输入上下文都能得到相似的输出结果时，就说明解释不仅反映了原始输入，还不依赖于其他不必要的干扰条件，从而保证了解释的独立性和稳定性。


% LLM在批量预测的情况下，会潜在地受到其他样本


-------------------


% \begin{equation}
% P(y | e_i) = \left( \frac{P(e_i | \mathcal{B}, x_i, t_i, y)}{\sum_{y' \in \mathcal{Y}} P(e_i | \mathcal{B}, x_i, t_i, y')} \right) \cdot P(y | \mathcal{B}, x_i, t_i),
% \end{equation}



 



% % \begin{equation}
% %     \text{sim}(P_{\text{LLM},i}, P_{\text{SLM},i}) \rightarrow  1
% % \end{equation}

% If the similarity score \( \text{sim}(P_{\text{LLM},i}, P_{\text{SLM},i}) \) exceeds a predefined threshold \( \delta \), we consider the explanation \( e_i \) to be consistent with the LLM's stance prediction \( P_{\text{LLM},i} \). This high similarity indicates that the explanation faithfully represents the LLM's stance prediction without significant distortion from the shared context in the batch, affirming that \( e_i \) can be reliably used to interpret the LLM's prediction for tweet \( x_i \).



% % By calculating a similarity metric, such as cosine similarity or KL divergence, between \( P_{\text{LLM},i} \) and \( P_{\text{SLM},i} \), we assess whether the explanation \( e_i \) faithfully represents the stance prediction from the LLM. 

% % If the similarity score between \( P_{\text{LLM},i} \) and \( P_{\text{SLM},i} \) exceeds a predefined threshold \( \delta \), this indicates that the explanation \( e_i \) is consistent with the LLM’s stance prediction and is not adversely influenced by the shared context. In cases where the similarity score is below \( \delta \), it suggests potential inconsistency due to contextual cross-influence, and further adjustments or recalibrations may be necessary to ensure accurate stance representation.




% % The consistency verification process then involves comparing \( P_{\text{SLM},i} \) with the original stance prediction distribution \( P_{\text{LLM},i} = P(y | x_i, t_i, \mathcal{B}) \) generated by the LLM for tweet \( x_i \) within the batch context \( \mathcal{B} \). We calculate a similarity score between these two distributions using a metric such as cosine similarity or KL divergence:

% % \begin{equation}
% %     \text{sim}(P_{\text{LLM},i}, P_{\text{SLM},i}) = \frac{P_{\text{LLM},i} \cdot P_{\text{SLM},i}}{\|P_{\text{LLM},i}\| \|P_{\text{SLM},i}\|}
% % \end{equation}

% % If the similarity score exceeds a predefined threshold \( \delta \), it indicates that the explanation \( e_i \) accurately reflects the LLM's stance prediction \( P_{\text{LLM},i} \), suggesting that the shared context has not adversely influenced the explanation. Thus, the consistency between \( P_{\text{LLM},i} \) and \( P_{\text{SLM},i} \) validates that the explanation is an unbiased representation of the model’s stance.


% % for stance likelihood distribution prediction \( P_{\text{SLM}}(y | e_i) \) based solely on the explanation.

% % The consistency between the LLM's and SLM's distributions is quantified by a similarity function \( \text{sim}(P_{\text{LLM}}, P_{\text{SLM}}) \), such as cosine similarity or KL divergence, to measure the alignment between \( P_{\text{LLM}}(y | x_i, t_i, \mathcal{B}) \) and \( P_{\text{SLM}}(y | e_i) \). This similarity score allows us to evaluate whether the LLM’s explanation accurately conveys the stance as predicted by the model, independent of the shared context.

% % \begin{equation}
% %     \text{sim}(P_{\text{LLM}}, P_{\text{SLM}}) = \frac{P_{\text{LLM}} \cdot P_{\text{SLM}}}{\|P_{\text{LLM}}\| \|P_{\text{SLM}}\|}
% % \end{equation}

% % If the similarity score exceeds a set threshold \( \delta \), we consider the LLM’s prediction and explanation for tweet \( x_i \) to be consistent.


% In the consistency verification stage, a pre-trained BERT model is used to classify the stance of the explanation text. Specifically, the explanation text is first encoded as a vector representation, and after processing through two hidden layers, a hidden representation \( h_i \) is generated. This representation is then passed through a fully connected layer, where \( W \) and \( b \) are the weights and biases of the fully connected layer, respectively. The softmax function is applied as the activation function to convert the logits vector into the stance probability vector \({P_i} \):

% \begin{equation}
%     {P_i} = \text{softmax}(W \cdot h_i + b)
% \end{equation}

% where \( {P_i} \) is the predicted stance probability distribution, representing the probabilities of the text across the favor, neutral, and against labels.


% For each sample \( x_i \), the probability distribution predicted by the large model for the favor, neutral, and against labels is represented as the vector \( {P}_{\text{LLM}} \). Similarly, the prediction results of the small model based on the explanation text are represented as the vector \( {P}_{\text{SLM}} \). The consistency between the results of the two models is quantified by calculating the consistency function \( f({P}_{\text{LLM}}, {P}_{\text{SLM}}) \).



% \begin{equation}
%     f\left({P}_{\text{LLM}}, {P}_{\text{SLM}}\right) = \frac{{P}_{\text{LLM}} \cdot {P}_{\text{SLM}}}{\|{P}_{\text{LLM}}\| \|{P}_{\text{SLM}}\|}
% \end{equation}


 

% When the consistency function \( f\left({P}_{\text{LLM}}, {P}_{\text{SLM}}\right) \) is greater than or equal to the set threshold \( \delta \), the prediction results of the large model and the small model are considered consistent. In this case, the prediction result of the large model \( \mathbf{P}_{\text{LLM}}\) is directly adopted as the final prediction result.



% When the consistency function \( f\left({P}_{\text{LLM}}, {P}_{\text{SLM}}\right) \) is lower than the threshold \( \delta \), it indicates a significant difference between the prediction results of the large model (LLM) and the small model (SLM), necessitating reclassification. In this case, multiple rounds of inference are performed. For each inference round \( R^{(1)}, R^{(2)}, \ldots, R^{(m)} \), the probability distribution vectors \( {P}^{(j)}_{\text{SLM}}, {P}^{(j)}_{\text{LLM}} \) for the three stance labels favor, neutral, and against are calculated to represent the stance probability distribution in each inference round.
-----------------

exp


% \begin{tabular}{lcc@{\hspace{1em}}cc@{\hspace{1em}}cc}
% \Xhline{1pt}
% \multirow{2}{*}{Variants} & \multicolumn{2}{c}{Sem16}          & \multicolumn{2}{c}{VAST}          & \multicolumn{2}{c}{P-stance}          \\ \cline{2-7}
%                           & $F_{\text{AVG}}(\uparrow, \%)$   & $Q_{\text{AVG}}(\downarrow)$  & $F_{\text{AVG}}(\uparrow, \%)$ & $Q_{\text{AVG}}(\downarrow)$ & $F_{\text{AVG}}(\uparrow, \%)$ & $Q_{\text{AVG}}(\downarrow)$ \\ \hline
% CoVer                     & 74.15 & 0.53 & 74.79 & 0.54 & 84.96 & 0.54 \\
% w/o Ver.                  & 62.15$_{\downarrow 12.00}$ & 0.35$_{\downarrow 0.18}$ & 60.89$_{\downarrow 13.90}$ & 0.26$_{\uparrow 0.01}$ & 74.11$_{\downarrow 10.85}$ & 0.21$_{\downarrow 0.33}$ \\ 
% w/o Ctx.                  & 62.53$_{\downarrow 11.62}$ & 0.99$_{\uparrow 0.46}$ & 68.44$_{\downarrow 6.35}$ & 0.47$_{\uparrow 0.22}$ & 83.53$_{\downarrow 1.43}$ & 0.98$_{\uparrow 0.44}$ \\
% w/o Bat.                  & 70.47$_{\downarrow 3.68}$ & 2.49$_{\uparrow 1.96}$ & 75.18$_{\uparrow 0.39}$ & 1.83$_{\uparrow 1.58}$ & 85.20$_{\uparrow 0.24}$ & 1.88$_{\uparrow 1.34}$ \\ \Xhline{1pt}
% \end{tabular}


% \begin{figure}[h]
% \label{Fig.EXA}
% \footnotesize
% \centering
% \subfigure[Taxonomic hierarchy]{
% 	\label{Fig.TH}
% 	\includegraphics[width=0.3\linewidth]{pic/exa5c.pdf}}
% % \hspace{0.1cm}
%  % \qquad
% \subfigure[Label similarity matrix]{
% 	\label{Fig.HAM}
% 	\includegraphics[width=0.3\linewidth]{pic/combine_mat_red.png}}
% % \vspace{-8pt} 
% \caption{An illustration of the book taxonomic hierarchy labels is provided in Fig.\ref{Fig.TH}. As depicted in Fig.\ref{Fig.HAM}, these relations extend beyond mere structural relationships to encompass semantic ones as well. In the label similarity matrix in Fig.\ref{Fig.HAM}, the shaded sections in a row signify the descendant labels of the respective row number label. The red value represents a prominent semantic relation with its non-descendant labels.}
% \label{Fig.EXA}
% \end{figure}


% % 单样本分类
% % 背景知识 
% % 样例展示/ 多智能体交互/ CoT/ Foundation Model
% % 任务指令
% % 
% We also investigate the performance of the LLM approach for stance detection:
% 1) \textbf{DQA} \cite{lan2024stance} is the method that direct query LLM for stance detection, which is implemented in strict accordance with \cite{zhang2022would} for target-specific zero-shot learning based on GPT-3.5.
% 2) \textbf{StSQA} \cite{zhang2023investigating} is a step-by-step question-answering method, which uses GPT-3.5 as the backbone.



% \begin{table}[h]
% \caption{Effectiveness and efficiency comparison across different LLM-based methods on Sem16 dataset. The best results are in \textbf{bold} and the second-best results are in \underline{underline}.}
% \label{tab:sem16_quality_scores}
% \centering
% \begin{tabular}{l@{\hspace{0.8em}}c@{\hspace{0.8em}}c@{\hspace{0.8em}}c@{\hspace{0.8em}}c@{\hspace{0.8em}}c@{\hspace{0.8em}}c@{\hspace{1em}}c}
% \Xhline{1pt}
% \multirow{2}{*}{Model} & \multicolumn{6}{c}{Sem16 $F_{\text{AVG}} (\uparrow, \%)$} & \multirow{2}{*}{$Q_{\text{AVG}} (\downarrow)$} \\ \cline{2-7}
%                        & HC   & FM    & LA    & A     & CC    & Avg     &       \\ \hline
% CoVer (ours)                  & \textbf{81.17} & \textbf{73.35} & \textbf{72.01} & \textbf{70.40} & \textbf{73.81} & \textbf{74.15}   & 0.53$\pm$0.29     \\ 
% DQA                    & 74.00   & 59.10  & 52.00  & 10.00  & 24.70  & 48.22$_{\downarrow 25.93}$   & 1.00 $_{\up{0.47}}$     \\
% StSQA                  & 75.50 & 60.80  & 55.30  & 10.30  & 25.20  & 49.35$_{\downarrow 24.80}$   & 3.00 $_{\up{2.47}}$     \\
% KASD-ChatGPT           & \underline{80.32} & \underline{70.41} & 62.71 & \underline{63.95} & 55.83 & \underline{68.46}$_{\downarrow 5.69}$   & 3.00 $_{\up{2.47}}$    \\
% COLA                   & 75.90 & 69.10 & \underline{71.00} & 62.30 & \underline{64.00} & 66.64$_{\downarrow 7.51}$   & 6.00 $_{\up{5.47}}$     \\
% \Xhline{1pt}
% \end{tabular}
% \end{table}


---------------------------


% \noindent \textbf{The Effectiveness of Label Semantic and Structural Information Fusing (Q2):} 
% For LSA-HAM, we remove HAM in Exp 5 and LSSM in Exp 6, respectively.
% In the taxonomic hierarchy, some labels are semantically related but not hierarchically adjacent as shown in Fig.\ref{Fig.EXA}. 
% Compared to HAM, LSA-HAM can explicitly capture the relations of these labels.
% The substitution of LSA-HAM with HAM (Exp 6) leads to a notable decline in model performance across the three datasets. This phenomenon further indicates that semantics modeling significantly contributes to performance enhancement. 
% However, the model performance drops in Exp 5 indicates that only using the semantic similarity information could result in failing to maintain the hierarchy consistency of the classification output.
% \noindent \textbf{上下文重构的有效性（Ctx）：}  
% 为评估上下文重构（Ctx）模块在 CoVer 框架中的作用，我们设计了去除 Ctx 组件的实验（w/o Ctx）。Ctx 模块的主要功能在于通过捕捉句子间的语境关系，帮助 LLM 更准确地推理文本的立场。实验结果显示，去除 Ctx 组件后，模型的 \( F_{\text{AVG}} \) 分数在所有数据集上均显著下降，例如在 Sem16 数据集上降至 62.53%，而 \( Q_{\text{AVG}} \) 值则有所上升。这种变化表明，缺少 Ctx 组件会导致模型在处理复杂句子和语义相似的文本时难以捕捉准确的语境信息，从而降低了模型的整体分类准确性。尤其是在存在多重含义和复杂语境的样本中，缺少 Ctx 会导致模型对立场判断出现偏差，导致 \( Q_{\text{AVG}} \) 增加，反映出分类的一致性和精确性不足。
% \noindent \textbf{Comparison of Structural and Semantic Information (Q2):} 
% In the taxonomic hierarchy, some labels are semantically related but not hierarchically adjacent as shown in Figure \ref{Fig.EXA}. 

% \noindent \textbf{Bidirectional Label Relation Modeling (Q3):} According to the formula \ref{xc}, we remove $\mathbf{x_D}$ in Exp 3 and $\mathbf{x_A}$ in Exp 4, respectively. By comparing the results of Exp 1, 3, and 4 across three datasets, We observe that the Micro-F1 in Exp 4 has dropped more significantly than in Exp 3. This indicates that the down-up label relation information modeled by LSA-AAM plays a more important role in S\textsuperscript{2}-HTC than the up-down information provided by LSA-DAM. It indicates that the classification boundary of the low-level class is clearer than that of the high-level class.

% \noindent \textbf{批量推理（Batch Reasoning）的有效性：}  
% 为评估批量推理（Batch Reasoning）在 CoVer 框架中的效果，我们设计了去除批量推理组件的实验（w/o Bat）。批量推理的核心作用在于通过同时处理多个文本片段，提升 LLM 的推理效率和一致性。实验结果显示，去除批量推理组件后，模型的 \( F_{\text{AVG}} \) 分数在所有数据集上均有所下降，尤其在 Sem16 数据集上降至 70.47%。同时，\( Q_{\text{AVG}} \) 值显著上升。这种变化表明，批量推理的缺失会导致模型在各个文本片段上逐一处理，缺乏全局上下文的支持，使得分类结果的可靠性和稳定性有所下降，从而影响整体的分类准确性。


--------------------

% Ctx. enhances CoVer's robustness in dealing with varied linguistic structures and mitigates the noise in the input text. 

% accuracy and consistency of stance classification, especially in cases where sentence meaning is complex or context-dependent.
% The lack of background information makes the model need to repeat more rounds to output consistent answers
% hinders the CoVer to output the consistent predictions and explanations. 
% The lack of background information makes the model need to repeat more rounds to output consistent answers
% handle complex texts. Particularly in samples with multiple meanings and intricate contexts, the absence of Ctx. leads to stance misjudgments, resulting in a higher $Q_{\text{AVG}}$. This demonstrates the importance of the contextual reconstruction module in improving the model's classification accuracy and consistency.
% To evaluate the role of the contextual reconstruction module in the CoVer framework, we conducted an experiment by removing the contextual reconstruction component. The primary function of the  module is to capture contextual relationships between sentences, aiding the LLM in more accurately inferring the stance of the text. Experimental results show that removing the component leads to a significant decrease in the model’s \( F_{\text{AVG}} \) score across all datasets, dropping to 62.53\% on the Sem16 dataset, while the \( Q_{\text{AVG}} \) value increases. This change indicates that the absence of the component hinders the model’s ability to capture accurate contextual information when dealing with complex sentences and semantically similar texts, thereby reducing overall classification accuracy. Particularly in samples with multiple meanings and complex contexts, the lack of contextual reconstruction leads to stance misjudgments, resulting in increased \( Q_{\text{AVG}} \), which reflects deficiencies in classification consistency and precision.
----------------discussion
% CoVer通过大小模型的协同来尽可能提高LLM的利用效率，然而不同的大小模型组合对模型的分类性能也有一定的影响。本文进一步讨论模型组合对于CoVer性能的影响。
% We further explores the impact of different model combination on the performance of CoVer.
% CoVer improves the efficiency of LLM utilization by collaborating on SLM and LLM. 


% The experimental results indicate that, compared to traditional LLM methods, CoVer achieves a better balance between efficiency and performance. Specifically, Fig\ref{fig.case} illustrates the performance of CoVer and four baseline large language models under different batch settings. Regardless of batch size (ranging from batch 1 to batch 32), the CoVer framework demonstrates a significantly higher average F1 score (F1 AVG) on the Sem16 dataset compared to the standard approach. Notably, at larger batch sizes (e.g., batch 16 and batch 32), CoVer’s performance improvement becomes more pronounced, indicating that CoVer efficiently leverages the computational advantages of batch reasoning while maintaining high consistency and accuracy.

% % CoVer 通过小模型（SLM）和大模型（LLM）的协同工作来提高 LLM 的利用效率，充分利用二者异构知识的互补性。通过对一致性较低的样本进行再生成检测，而非频繁调用 LLM，CoVer 有效降低了计算成本。这一方法确保了仅在必要时重新生成，从而优化了计算资源的使用。因此，CoVer 框架在提升性能的同时没有显著增加计算成本，甚至在较大批量下进一步提高了推理效率。
% CoVer improves the utilization efficiency of LLMs by leveraging the collaborative work of small models (SLMs) and large models (LLMs), fully utilizing the complementary nature of their heterogeneous knowledge. By re-generating predictions only for samples with low consistency rather than frequently invoking the LLM, CoVer effectively reduces computational costs. This approach ensures re-generation only when necessary, thereby optimizing the use of computational resources. Consequently, the CoVer framework enhances performance without significantly increasing computational costs and even improves inference efficiency at larger batch sizes.


% The results of the ablation study for AAAF on the Sem16 dataset. In the figure, OEA is the Open Aspect Extraction. AAM is the Aspect Attention Module. CL is the Contrastive Learning approach.

-----------------------


% In this study, we proposed Collaborative Stance Detection via Small-Large Language Model Consistency Verification, an approach for stance detection on short texts from social media, which ensures consistent hierarchical classification by integrating explicit structural relation information and implicit label semantic information. 
% Firstly, we use the Label Semantic-Aware Hierarchical Adjacency Matrix (LSA-HAM) to record both structural and semantic relations among labels. By applying the LSA-HAM, we execute a hierarchical consistency alignment process to incorporate hierarchical information features into our model.
% To more effectively capture the features of minor classes, we introduce the Class Balanced Negative Tolerance Regulation (CB-NTR) loss function.
% Moreover, we explore the effectiveness of Simple Contrastive Learning of Sentence Embeddings (SimCSE) and pre-trained methods, which contribute to the enhancement of our model. 
% Our experiments on the WOS, BGC, and NST5 datasets illustrate the state-of-the-art performance of S\textsuperscript{2}-HTC.

% 本文提出了一个名为 CoVer 的协同立场检测框架，通过小语言模型（SLM）和大语言模型（LLM）的协同工作，显著提升了立场检测任务的效率和准确性。CoVer 框架利用 LLM 对大批量推文进行初步的立场预测和推理，随后通过 SLM 验证推理结果的准确性，以确保模型判断的稳健性。对于一致性较低的样本，采用重新检测的方法，进一步提高了检测结果的可靠性。实验结果表明，CoVer 在多种基准测试中表现优异，尤其在零样本环境下显现出明显优势。有效地平衡了检测效果和效率，使查询次数降低至每条推文 0.54 次。特别是在资源受限的场景中，显示出更高的泛化能力。
% In this study, we propose the Aspect-Augmented Attention Framework (AAAF) for stance detection, which extracts the implicit topic aspects from text samples by Large Language Model (LLM) and achieves context information augmentation via an attention mechanism for stance detection.
% To enrich the context information of the text, we introduce the LLM for Aspect Extraction (LLM-AE) by conducting the text summarization task on the training data. These extracted topic aspects could be used for information augmentation. 
% To ensure the information is correctly introduced, we incorporate a Nearest Neighbor Retrieval (NNR) to match tweets with the most relevant aspects and utilize Neutrality Filtering (NF) to avoid aspect matching for neutral tweets.
% To fuse the augmented information, we utilize the Aspect Attention Module (AAM), which further adjusts the text representation.
% Our experimental findings on the typical datasets demonstrate that AAAF excellent outperforms existing models.


----------------------
%  which is training on correct inference patterns
% 大模型能结合自身带有的常识和对target的背景信息进行立场的推理，进而得出立场分类。相比而言，小模型通过启发式的训练和背景信息引入才能较好地完成立场检测。这使得小模型在面对数据不平衡（target CC）或者数据匮乏的场景时泛化性不足（Sem16 dataset）。CoVer通过利用大模型将要检测的文本映射到相对固定的文本中，能充分地发挥小模型的能力。
% 此外，我们同样可以观察到，缺乏一致性验证的情况，大模型的能力仍然无法充分发挥（CoT-Demo，LC-CoT和Task-Des相比较），然而，使用模型进行自我纠正是低效的，CoVer通过收集正确的推理模式数据训练小模型，能更高效和有效的进行一致性验证。
% CoVer's use of large models to map short texts that are obscure and lacking in context to texts with relatively fixed patterns and sufficient information can fully utilize the capabilities of small models.



% 知识的引入保证了大模型的无偏分析。

% 单批次的表现对模型性能的提升有限。

% 一致性验证保证了批量检测的准确性。



% \noindent \textbf{Main part of the S\textsuperscript{2}-HTC (Q1):} We replace BERT with SciBERT in Exp 2 and remove balancing loss in Exp 8, LSA-HAM in Exp 9, respectively.
% For S\textsuperscript{2}-HTC, the impact of each component varies depending on the complexity of the dataset hierarchy.
% The balancing loss function is important in simpler hierarchies like WOS (12.86\% drop in Micro-F1 on WOS, Exp 8), while label relation modeling is crucial in more complex structures like BGC and NST5. Across three datasets, label modeling is essential,   since its removal leads to a substantial performance drop (28.50\% in Micro-R and 22.71\% in Micro-F1 in NST5, Exp 9). 
% Although the text encoder also contributes to our model, its impact is relatively inferior to the balancing loss function and label relation modeling.
% A more obvious comparison can be seen in Fig.\ref{Fig.ABS_mif1}.
% Therefore, we can conclude that both the balancing loss function and hierarchical label relation modeling are integral to the effectiveness of the S\textsuperscript{2}-HTC model, where each plays an important role in different hierarchical contexts.
% \noindent \textbf{一致性验证的有效性：} 在 CoVer 框架中去除一致性验证，以评估其对立场检测性能的影响。Ver 组件在确保 LLM 和 SLM 预测的一致性方面起到了关键作用实验结果显示，去除 Ver 组件后，模型的 \( F_{\text{AVG}} \) 分数显著下降，而 \( Q_{\text{AVG}} \) 值在所有数据集上均有所降低。这种 \( Q_{\text{AVG}} \) 的变化表明，缺少一致性验证使得模型更倾向于直接输出偏向性较强的结果，从而使得部分简单分类的样本 \( Q \) 值下降。然而，这种直接输出的方式会导致模型在复杂样本上的表现变差，进而影响整体的 \( F_{\text{AVG}} \) 分数。这一现象进一步说明，Ver 组件不仅提升了模型的分类稳定性，同时在处理多样化的输入时，也确保了分类结果的层级一致性和合理性。 

-------------------

% Results across diverse LLM architectures reveal that CoVer maintains robust performance with increasing batch sizes (1→32), suggesting its potential for efficient large-scale stance classification. 
% Comparison of Sem16 \( F_{\text{AVG}} \) across different LLMs and batch sizes, using Normal and CoVer settings. Results indicate that CoVer enhances the effectiveness of batch processing across various batch sizes and models, achieving higher performance with larger batches.

% 一个关键的方法是CoVer使用了批量推理的方法来提高模型的利用率，然而，直觉地认为，由于共享上下文会导致推文的内容之间会相互干扰，并导致模型在预测立场时出现偏差，然而，我们在消融实验的分析表明，多批次的分类不一定会造成模型分类的失败，反而会有助于模型的立场分类。那么，上下文批次的增加，模型总体发呢类效果是不是一定会下降？

%为此本文进一步讨论不同LLM下不同批次的分类效果。我们在sem16上设置了两组对比实验，一个是直接用LLM进行批量分类，一个是使用CoVer方法，分别在1，8，16，32批次上进行实验。
% 实验结果表明，1）单批次情况下，总体性能下降严重。2）每个模型都有自己适合的最佳批次，这个可能和LLM的长文本处理能力有关。3）CoVer对LLM分类性能的提升依赖于模型本身的能力，

% % 实验结果显示，与传统 LLM 方法相比，CoVer 在效率和性能之间实现了更优的平衡。具体而言，图表展示了 CoVer 和四种基础大语言模型在不同批量设置下的表现。无论批量大小如何（从 batch 1 到 batch 32），CoVer 框架在 Sem16 F1 平均分数（F1 AVG）方面都明显优于普通方法。特别是在较大批量（如 batch 16 和 batch 32）时，CoVer 框架的性能提升更为显著，这表明 CoVer 能够高效地利用批量推理带来的计算优势，同时保持较高的一致性和准确性。
--------------

% remove the sentences by
% To  on $x_{\text{k}}$, 


% \begin{itemize}
%     \item \textbf{Redundant Sentence}: If removing a sentence \( s_i \) results in an obvious increase in stance variance \( \text{SD}_{x \setminus s_i} \), this suggests that \( s_i \) is redundant or has minimal impact on clarifying the stance. Thus, \( s_i \) is excluded from the tweet.
%     \item \textbf{Relevant Sentence}: If removing a sentence \( s_i \) leads to a significant decrease in stance variance \( \text{SD}_{x \setminus s_i} \), this indicates that \( s_i \) contributes meaningfully to the stance expression, and it is retained.
% \end{itemize}

% if removing a sentence leads to an increase in stance variance of the refined tweet, this suggests that the sentence was redundant or had little impact on clarifying the stance. Conversely, if the stance variance decreases largely without the sentence, this indicates that the sentence contributes meaningfully to the stance expression, and it will be retained.


% 在CoVer框架的批量推理阶段，通过直接构建提示（Prompt）来引导大语言模型（LLM）生成每个文本的立场分布及解释。对于每个经过上下文重构的文本，我们构建如下形式的提示：

% To enhance the LLM’s use of context across multiple texts, we process a batch of tweets as a single input query.
% For each refined tweet \( x \) obtained from the context reconstruction phase, we construct the query \( Q \) as follows:


---------------


% identify users' actual stance.
% balance the effectiveness and efficiency for stance detection.


% Ensuring LLM's logical consistency between reasoning and classification of stance is an effective assurance for enhancing stance detection performance without task-specific training. 
% Some recent studies have recognized the importance of logical consistency and employed techniques such as multi-agent systems \cite{lan2024stance} and chain-of-thought \cite{zhang2023investigating,zhang2023logically} to correct these inconsistencies via using LLM iteratively.
% However, these methods overlook that stance detection is a large-scale data analysis task, demanding both efficiency and effectiveness. Repeatedly invoking LLM for a single short tweet is clearly cost-prohibitive.

% To balance the efficiency and effectiveness, we introduce the Small-Large Language Model Collaboration method for stance detection as shown in Fig.\ref{Fig.EXA}(c).

% Despite the powerful strengths of LLMs, as shown in Fig.\ref{Fig.EXA}(b), their stance detection performance still requires logical verification feedback to prevent the issues such as hallucinations and the misleading of outdated information, which potentially cause LLM's inconsistencies between reasoning and likelihood estimating of stance.
% Some recent studies have recognized the importance of ensuring the logical consistency between LLM's stance reasoning and estimating, employed techniques such as multi-agent systems \cite{lan2024stance} and chain-of-thought \cite{zhang2023investigating,zhang2023logically} to correct these inconsistencies via using LLM iteratively.
