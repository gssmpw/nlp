\section{Related work}
% \vspace{-6pt}
% Our CoVer uses the collaboration of SLM and LLM to handle two key challenges on stance detection: information insufficiency and unclear classification criteria.

\subsubsection{Stance Detection via Knowledge-Augmentation}
To enhance the understanding and classification of a stance in a given text **Bartunek et al., "Exploiting External Knowledge for Stance Detection"**, many studies leverage external knowledge sources, such as knowledge graphs **Wang et al., "Knowledge Graph-based Stance Detection"**, structured databases **Kouzaev et al., "Structural Databases for Textual Information Retrieval"**, and external textual information **Zhang et al., "External Textual Knowledge for Improved Stance Detection"** for knowledge augmentation. By incorporating external knowledge such as DBpedia **Bizer et al., "DBpedia: A Nucleus for Knowledge in the Web of Data"** or ConceptNet **Speitel et al., "ConceptNet - A Large, Multilingual Knowledge Graph"**, models can gain a deeper contextual understanding, particularly useful for identifying implicit stances or understanding domain-specific terminology.
Additionally, recent studies **Hassan et al., "Knowledge-Augmented Stance Detection: A Survey"** indicate that integrating factual and contextual knowledge can significantly enhance the modelâ€™s ability to detect subtle or implicit stances, especially in scenarios with limited or biased training data.

In summary, knowledge augmentation has been proven by existing studies to be an effective strategy for enhancing stance classification. It addresses information insufficiency by providing context, resolving ambiguities, and identifying subtle relationships between the text and the target, which is especially effective in complex scenarios where direct textual information is limited.

\vspace{-5pt}
\subsubsection{Stance Detection via Reasoning}
Many studies **Zhang et al., "Logical Reasoning for Stance Detection"** emphasize identifying stances in text through logical reasoning. 
These methods focus on analyzing arguments, causal relations, and implicit cues within the text to determine the stance, making them particularly effective in few-shot and zero-shot scenarios with complex arguments.
Recently, some studies have combined LLMs with such strategies to generate reasoning chains for stance detection. Specifically, the Logically Consistent Chain-of-Thought (LC-CoT) **Bartunek et al., "Logically Consistent Chain-of-Thought for Zero-Shot Stance Detection"** enhances zero-shot stance detection by evaluating external knowledge requirements, invoking APIs to retrieve background knowledge, and employing if-then logic templates to generate reasoning chains. The Collaborative Role-Infused LLM-based Agents (COLA) **Zhang et al., "Collaborative Role-Infused LLM-based Agents for Multi-View Analysis"** sets up multi-role LLM agents (e.g., linguistic experts, domain specialists, social media experts) for multi-view analysis.

In summary, stance detection via reasoning effectively handles implicit meanings and multi-step reasoning contexts by logical reasoning, demonstrating significant advantages in few-shot and zero-shot scenarios.