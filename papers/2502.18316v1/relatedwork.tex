\section{Related Work}
\subsection{Challenges in LLMs MCQ Benchmarks }

Several works raised concerns about the effectiveness of MCQ benchmarks in LLM
assessment. For example, \citet{balepur2024artifactsabductionllmsanswer} showed
that some LLMs can answer MCQs using only the answer choices, without seeing
the questions, and perform well-above baselines. Furthermore, more works
suggested that LLMs are biased towards certain answer keys (A/B/C/D) due to
unbalanced prior probabilities rather than actual knowledge
\citep{myrzakhan2024openllmleaderboardmultichoiceopenstylequestions,clark2018thinksolvedquestionanswering}.
Another line of research attributes LLMs hallucinations to being unable to
identify when they lack sufficient knowledge about the subject matter
\citep{li2024thinktwicetrustingselfdetection, ji-etal-2022-answer}.
Nonetheless, current evaluation benchmarks do not assess this capability
effectively. We view our work as an addition towards efficient evaluation of
LLMs to avoid spurious correlations and account for knowledge and reasoning
gaps.

\subsection{None of the Above in Educational Tests}

Multiple-choice questions (MCQs) are effective assessments when they include
plausible distractors, as they encourage deeper processing to think not only
about why a given choice is correct, but also why other choices are wrong and
improve knowledge recall \cite{little2019role, little2015optimizing}. The use
of \nota~ as a distractor in MCQs is an area of research and debate. It can
provide unique insight into the understanding of the examinees and potentially
differentiate their abilities \cite{DiBattista03042014, dochy2001assessment}.
However, \nota~ can affect the confidence of the examinee, leading them to
avoid selecting \nota~ as the correct answer, even when it is true
\cite{little2023does, odegard2007none}. Nevertheless, incorporating \nota~ into
practice tests can enhance the learning process by encouraging deeper
engagement with the material \cite{DiBattista03042014,
    pezeshkpour-hruschka-2024-large, zheng2024largelanguagemodelsrobust}.