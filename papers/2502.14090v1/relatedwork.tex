\section{Related Work}
Image super-resolution has been a major task in computer vision, with early approaches relying on interpolation techniques such as bicubic scaling~\cite{jahnavi2024study, navarrete2022edge, chen2015train}. While these methods are computationally efficient, they lack adaptability to image features and often produce artifacts like blurriness and jagged edges in images. Advances like SRCNN~\cite{srcnn} and FSRCNN~\cite{fsrcnn} introduced learnable features through CNNs, significantly improving SR performance. However, these models are computationally intensive and might be challenging for real-time deployment on resource-constrained devices.

To address efficiency concerns, lightweight SR models such as ESPCN~\cite{shi2016real}, DVMSR~\cite{lei2024dvmsr}, and SRMamba-T~\cite{srmamba} have been proposed. ESPCN utilizes sub-pixel convolution layers to reduce computational overhead, but it struggles to maintain high reconstruction quality at larger scales. DVMSR, which outperformed RLFN~\cite{rlfn}, the winner of the NTIRE 2023 Efficient Super-Resolution Challenge~\cite{ntire}, utilizes Vision Mamba~\cite{zhu2024visionmamba} modules and state space blocks to balance efficiency and accuracy. SRMamba-T combines Mamba and Transformer architectures to balance computational efficiency with high performance.

Frameworks like ESHP~\cite{wang2024eshp} extend these advancements by leveraging heterogeneous hardware to optimize SR tasks. ESHP dynamically allocates CPU, GPU, and NPU resources using deep reinforcement learning. However, its dependence on specialized hardware ecosystems introduces complexity and limits deployment flexibility. Edge-SR~\cite{navarrete2022edge} proposes lightweight one-layer architectures for real-time applications. Although practical for constrained devices, its performance is often inferior to more advanced multi-layer networks. Similarly, thermal imaging SR pipelines~\cite{mathur2021real} and facial verification systems~\cite{perez2023efficient} focus on specific use cases but are not flexible enough for wider SR applications.

The proposed MambaLiteSR further advances these foundations by integrating low-rank Mamba architecture and a knowledge distillation framework, offering a unified solution to the limitations of prior methods. Unlike simpler interpolation‐based techniques, MambaLiteSR dynamically adapts to complex image features for improved SR quality. Meanwhile, its design addresses the memory and computational constraints typically faced by CNN‐based or transformer‐heavy approaches, reducing reliance on specialized hardware. By managing parameter usage and supporting real‐time deployment, MambaLiteSR provides an effective, flexible solution for lightweight SR on edge devices.

\begin{figure}[t]
	\centering
	\includegraphics[width=.45\textwidth]
         {Images/model.png}
	\caption{Architecture of DVMSR \cite{lei2024dvmsr} and Vision Mamba \cite{visionmamba}: Input image is preprocessed and fed into the DVMSR model, which consists of Vision Mamba modules, convolution layers, and a decoder.}
	\label{model}
\end{figure}