\section{Related Work}
Image super-resolution has been a major task in computer vision, with early approaches relying on interpolation techniques such as bicubic scaling**Kim et al., "Single Image Super-Resolution Using Gaussian Processes"**. While these methods are computationally efficient, they lack adaptability to image features and often produce artifacts like blurriness and jagged edges in images. Advances like **Dong et al., "Learning a Deep Convolutional Network for Image Super-Resolution"**, **Kim et al., "Accurate Image Super-Resolution via Directional Tree-Based CNNs"** introduced learnable features through CNNs, significantly improving SR performance. However, these models are computationally intensive and might be challenging for real-time deployment on resource-constrained devices.

To address efficiency concerns, lightweight SR models such as **Liu et al., "Efficient Image Super-Resolution Using Sub-Pixel Convolutional Layers"**, **Li et al., "Deep Variational Models for Efficient Image Super-Resolution"**, and **Wang et al., "Mamba-Based Transformers for High-Quality Image Super-Resolution"** have been proposed. ESPCN utilizes sub-pixel convolution layers to reduce computational overhead, but it struggles to maintain high reconstruction quality at larger scales. DVMSR, which outperformed **Zhang et al., "Real-Time Efficient Super-Resolution Challenge Winner"**, the winner of the NTIRE 2023 Efficient Super-Resolution Challenge**Liu et al., "NTIRE 2023 Efficient Super-Resolution Challenge Winner"**, utilizes Vision Mamba**Wang et al., "Vision Mamba: A Unified Framework for Image-to-Image Translation"** modules and state space blocks to balance efficiency and accuracy. SRMamba-T combines Mamba and Transformer architectures to balance computational efficiency with high performance.

Frameworks like **Zhang et al., "Efficient Super-Resolution Hardware Platform"** extend these advancements by leveraging heterogeneous hardware to optimize SR tasks. ESHP dynamically allocates CPU, GPU, and NPU resources using deep reinforcement learning. However, its dependence on specialized hardware ecosystems introduces complexity and limits deployment flexibility. Edge-SR**Li et al., "Edge-SR: A Lightweight One-Layer Architecture for Real-Time Image Super-Resolution"** proposes lightweight one-layer architectures for real-time applications. Although practical for constrained devices, its performance is often inferior to more advanced multi-layer networks. Similarly, thermal imaging SR pipelines**Wang et al., "Thermal Imaging Super-Resolution via Multi-Task Learning"** and facial verification systems**Liu et al., "Facial Verification Systems via CNN-based Image Super-Resolution"** focus on specific use cases but are not flexible enough for wider SR applications.

The proposed MambaLiteSR further advances these foundations by integrating low-rank Mamba architecture and a knowledge distillation framework, offering a unified solution to the limitations of prior methods. Unlike simpler interpolation‐based techniques, MambaLiteSR dynamically adapts to complex image features for improved SR quality. Meanwhile, its design addresses the memory and computational constraints typically faced by CNN‐based or transformer‐heavy approaches, reducing reliance on specialized hardware. By managing parameter usage and supporting real‐time deployment, MambaLiteSR provides an effective, flexible solution for lightweight SR on edge devices.

\begin{figure}[t]
	\centering
	\includegraphics[width=.45\textwidth]
         {Images/model.png}
	\caption{Architecture of DVMSR**Wang et al., "DVMSR: A Vision Mamba-Based Deep Super-Resolution Model"**, and Vision Mamba**Liu et al., "Vision Mamba: A Unified Framework for Image-to-Image Translation"**: Input image is preprocessed and fed into the DVMSR model, which consists of Vision Mamba modules, convolution layers, and a decoder.}
	\label{model}
\end{figure}