\section{Literature Review}
\subsubsection{Optimization based Charging Navigation Algorithm}

Optimization based navigation algorithms utilize optimization techniques to determine cost-minimum routes ____. A hierarchical game approach ____ is proposed for EV path planning. At the upper level, a non-cooperative game is proposed to model the competition between EVCSs, while multiple evolutionary games are formulated at the lower level for EVs to choose a suitable EVCS as the destination. In ____, a simplified charge-control (SCC) based programming algorithm is presented for navigation which can simplify the charging control decisions within an SCC set. ____ proposes an evolutionary game model for navigation in a complex network which considers the social relationships and mutual learning among users. In ____, a mixed-integer linear programming model is developed to tackle the traveling salesman problem that takes into account the impact of time-of-use electricity pricing, predefining distribution routes and specifying charging points along the route for electric logistics vehicles.  ____ develops a bi-layer navigation model which coordinates both the transportation network and distribution network. The model minimizes the total navigation cost through the upper level and reduces energy exchange among EVCSs and power grid upon the lower level.

\subsubsection{Heuristic Charging Navigation Algorithm}
Heuristic charging navigation algorithms utilize the heuristic rules or strategies ____ to guide the decision-making process, such as prioritizing charging at EVCSs, minimizing detours for charging, or considering traffic conditions ____. In ____, a driving strategy based on the distributed ant system algorithm was designed for EV charging navigation. ____ presents a comprehensive framework that considers different problem variants, speedup techniques, and develops three solution algorithms: an exact labeling algorithm, a heuristic labeling algorithm, and a roll-out algorithm. In ____, a cooperative-A* algorithm was proposed to solve the cooperative real-time EV planning problem.

\subsubsection{DRL based Charging Navigation Algorithm}
 DRL acquires decision-making strategies through interacting with environment ____. The most common-used DRL framework for EV charging navigation is Deep-Q-Network (DQN) ____. In ____, the EV charging navigation problem is firstly framed as a Markov Decision Process (MDP), and DQN is developed aiming at capturing the unique state of the unknown environment, ultimately providing the optimal travel route and EVCS selection policy for the EV drivers. In another study ____, a Constrained MDP was formulated to design a constrained charging/discharging scheduling strategy to minimize charging costs while ensuring that EVs achieve a full charge. 
 
 For GNN-based DRL algorithms, ____ uses a graph convolutional network to extract the environment information from the coupled power-traffic system of the urban area. In ____, a bi-level graph based DRL method is proposed, where the upper level focuses on selecting the optimal EVCS, while the lower level is dedicated to routing EVs efficiently. In ____, a bi-timescale GNN based DRL algorithm was introduced, of which at the slow timescale the algorithm focuses on resolving the distribution locational marginal pricing of the node and employs multi-agent DRL to address real-time EV requests on the fast timescale. In ____, three supplementary models concerning the traffic network, charging station, and EV driver are incorporated into the GNN-based DRL framework to enhance the overall performance of the algorithm.