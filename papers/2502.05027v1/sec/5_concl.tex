\section{Conclusion}

In this work, we propose a Trust-Aware Diversion (TAD) dataset distillation method to tackle the realistic yet challenging task of Dataset Distillation with Noisy Labels (DDNL). 
TAD introduces an iterative dual-loop (\ie, outer loop and inner loop) optimization framework to effectively mitigate the negative impact of mislabeled samples.
The outer loop partitions data into trusted and untrusted spaces, ensuring that distillation is guided by reliable samples, while the inner loop recalibrates untrusted samples, transforming them into valuable ones.
Through this iterative refinement, TAD expands the trusted space while shrinking the untrusted space, leading to more robust and reliable dataset distillation.
Extensive experiments on three benchmark datasets (CIFAR-10, CIFAR-100, and Tiny ImageNet) demonstrate that TAD achieves significant improvements under three noisy labeling settings: symmetric, asymmetric, and real-world noise. 
These results highlight the importance of handling noisy samples within dataset distillation. 
We believe this work will open up new avenues for practical and robust dataset distillation with noisy labels, making distilled datasets more applicable to a wide range of real-world applications.





