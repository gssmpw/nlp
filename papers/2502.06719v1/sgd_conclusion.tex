In our paper, we performed the fully non-asymptotic analysis of the multiplier bootstrap procedure for SGD applied to strongly convex minimization problems. We showed that the algorithm can achieve approximation rates in convex distances of order up to $1/\sqrt{n}$. We highlight the fact that the validity of the multiplier bootstrap procedure does not require one to consider Berry-Esseen bounds with the asymptotic covariance matrix $\Sigma_{\infty}$, which is in sharp contrast to the methods that require direct estimation of $\Sigma_{\infty}$.