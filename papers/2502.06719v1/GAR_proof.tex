We first provide details of the expansion \eqref{eq:linear and nonlinear terms}. Recall that the error of SGD approximation may be rewritten as follows
\begin{equation}
    \label{eq: sgd_reccurence_with_remainder}
    \theta_k-\thetas = (\Id - \alpha_k G) (\theta_{k-1}-\thetas) - \alpha_k ( H(\theta_{k-1}) + \eta(\xi_k) + g(\theta_{k-1}, \xi_k))\eqsp.
\end{equation}
Iteratively spinning this expression out we get
\begin{equation}
    \label{eq: sgd_reccurence_with_remainder_2}
    \theta_k-\thetas = \prod_{j=1}^k(\Id - \alpha_j G) (\theta_{0}-\thetas) - \sum_{j=1}^k \alpha_j \prod_{i = j+1}^k (\Id - \alpha_i G) ( H(\theta_{j-1}) + \eta(\xi_j) + g(\theta_{j-1}, \xi_j))\eqsp.
\end{equation}
Taking average of \eqref{eq: sgd_reccurence_with_remainder} and changing the order of summation, we obtain 
\begin{equation}
    \sqrt{n}(\bar\theta_n -\thetas) = \frac{1}{\sqrt{n}\alpha_0}Q_0(\theta_0-\thetas) -\frac{1}{\sqrt{n}}\sum_{i=1}^{n-1}Q_i(H(\theta_{i-1}) + \eta(\xi_i) + g(\theta_{i-1}, \xi_i)),
\end{equation}
where $Q_i$ is defined in \eqref{eq:Q_i_def}. Finally, we obtain \eqref{eq:linear and nonlinear terms}. 

\begin{proof}[Proof of Theorem \ref{th:bound_kolmogorov_dist_pr_sigma_n}]
We normalize the both parts of  \eqref{eq:linear and nonlinear terms} by $\Sigma_n^{1/2}$ and obtain
\begin{equation}
    \label{eq: norm_PR_decomposition}
    \sqrt{n}\Sigma_n^{-\frac{1}{2}}(\bar\theta_n -\thetas) = \sum_{i=1}^{n-1}\underbrace{\frac{\Sigma_n^{-\frac{1}{2}}}{\sqrt{n}}Q_i\eta(\xi_i)}_{w_i} + D_{n,1} + D_{n,2} + D_{n,3}\eqsp,
\end{equation}
where we have set 
\begin{equation}
\label{eq:D_n_1_3_def}
\begin{split}
D_{n,1} &= \frac{\Sigma_n^{-\frac{1}{2}}}{\sqrt{n}\alpha_0}Q_0(\theta_0-\thetas)\eqsp, \\
D_{n,2} &= -\frac{\Sigma_n^{-\frac{1}{2}}}{\sqrt{n}}\sum_{i=1}^{n-1}Q_i H(\theta_{i-1})\eqsp, \\
D_{n,3} &= -\frac{\Sigma_n^{-\frac{1}{2}}}{\sqrt{n}}\sum_{i=1}^{n-1}Q_i g(\theta_{i-1}, \xi_i)) \eqsp.
\end{split}
\end{equation}
Also, for any $1 \leq i \leq n-1$ we construct
\begin{align}
    &D_{n,1}^{(i)} = \frac{\Sigma_n^{-1/2}}{\sqrt{n}\alpha_0}Q_0(\theta_0^{(i)}-\thetas) \eqsp,\\& 
    D_{n,2}^{(i)} = -\frac{\Sigma_n^{-1/2}}{\sqrt{n}}\sum_{j=1}^{n-1}Q_jH(\theta_{j-1}^{(i)})\eqsp,\\&
    D_{n,3}^{(i)} = -\frac{\Sigma_n^{-1/2}}{\sqrt{n}}\sum_{j=1}^{n-1}Q_jg(\theta_{j-1}^{(i)}, \widetilde{\xi_j}^{(i)})),
\end{align}
where we set
\begin{equation}
    \widetilde{\xi_j}^{(i)} =
    \begin{cases}
        \xi_j \eqsp, &\text{if } j \neq i\\
        \xi_j' \eqsp, &\text{if } j = i \eqsp. 
    \end{cases}
\end{equation}
Define $D_n = D_{n,1} +  D_{n,2} +  D_{n,3}$, $D_n^{(i)}= D_{n,1}^{(i)} +  D_{n,2}^{(i)} +  D_{n,3}^{(i)}$, $W_n=\sum_{i=1}^{n-1}w_i$ and  $\Upsilon_{n} = \sum_{i=1}^n\PE[\norm{\omega_i}^3]$(we keep the same notations as in the unnormalized setting for simplicity). 
Let $Y \sim \mathcal{N}(0, I_d)$. Then, using \cite[Theorem 2.1]{shao2022berry}, we have
\begin{equation}
    \kolmogorov (\sqrt{n}\Sigma_n^{-1/2}(\bar\theta_n-\thetas), Y) \leq 259d^{1/2}\Upsilon_n + 2\PE\{\norm{W_n}\norm{D_n}\} + 2\sum_{i=1}^{n-1}\PE[\norm{\omega_i}\norm{D_n-D_n^{(i)}}]\eqsp.
\end{equation}
Note that $\PE^{1/2}[\norm{W_n}^2]=\sqrt{d}$. Applying \Cref{lem:bound_Q_i_and_Sigma_n},  we get $\PE^{1/2}\norm{w_i}^2\leq \frac{1}{\sqrt{n}}C_{\Sigma}C_Q\sigma_2$  and 
$$
\Upsilon_n \leq \frac{1}{\sqrt{n}}(C_{\Sigma}C_Q\sigma_4)^3 \eqsp.
$$
Applying H\"{o}lder's inequality together with \Cref{lem:bound_Dn} and \Cref{lem:bound_sum_Dn-Dni}, we obtain
\begin{equation}
\kolmogorov(\sqrt{n} \Sigma_{n}^{-1/2}(\bar\theta_n -\thetas), Y) \leq \frac{\sqrt{d}M_{3,1}}{\sqrt{n}} + \frac{M_{3,2}}{\sqrt{n}}(\norm{\theta_0-\thetas}+\norm{\theta_0-\thetas}^2+\sigma_2+ \sigma_4^2) + M_{3,3}n^{1/2-\gamma}+M_{3,4}n^{-\gamma/2}\eqsp,
\end{equation}
     where 
    \begin{equation}
    \begin{split}
        &M_{3,1} =259(C_{\Sigma}C_Q\sigma_4)^3\eqsp,\\
        &M_{3,2} = 2\sqrt{d}M_{1,1}  + C_{\Sigma}C_Q\sigma_2M_{2,1}\eqsp,\\
        &M_{3,3} = 2\sqrt{d}M_{1,2}\sigma_4^2\eqsp,\\
        &M_{3, 4} = (2\sqrt{d}M_{1,3}+M_{2,3}C_{\Sigma}C_Q\sigma_2)\sigma_2 + C_{\Sigma}C_QM_{2,2}\sigma_4^2\sigma_2\eqsp.
    \end{split}
    \end{equation}
    Constants $M_{1,1}, M_{1,2}, M_{1,3}$ are defined in \eqref{eq:def_const_M_1} and $M_{2,1}, M_{2,2}, M_{3,3}$ are defined in \eqref{eq:def_const_M_2}.
    We simplify the last inequality and get the statement of the theorem with
\begin{equation}
\label{eq:def_Const_M_3_i}
    \begin{split}
        &\ConstC_{1} = \sqrt{d} M_{3,1} + M_{3,2} \norm{\theta_0-\thetas}+\norm{\theta_0-\thetas}^2+\sigma_2+ \sigma_4^2 \eqsp,\\
        &\ConstC_{2} = M_{3,3}\eqsp,\\
        &\ConstC_{3} = M_{3,4}\eqsp.
    \end{split}
    \end{equation}   
\end{proof}


Define 
\begin{equation}
\label{def:const_T_1_T_2}
\begin{split}
     &T_1(A) = 1 + \frac{1}{A^{1/(1-\gamma)}(1-\gamma)}\Gamma(\frac{1}{1-\gamma})\eqsp,\\
      &T_2(A) = 1 + \max\biggl(\exp\biggl\{\frac{1}{1-\gamma}\biggr\}\frac{1}{A^{1/(1-\gamma)}(1-\gamma)}\Gamma(\frac{1}{1-\gamma}), \frac{1}{A(1-\gamma)^2}\biggr)\eqsp.
\end{split}
\end{equation}

\begin{lemma}
\label{lem:bound_Dn}
    Assume \Cref{ass:L-smooth},\Cref{ass:noise_decomposition}($4$), \Cref{ass:hessian_Lipschitz_ball} and \Cref{ass:step_size}. Then it holds that 
    \begin{equation}
        \PE^{1/2}[\norm{D_n}^2]\leq \frac{M_{1,1}}{\sqrt{n}}(\norm{\theta_0-\thetas}+\norm{\theta_0-\thetas}^2+\sigma_2+ \sigma_4^2)+M_{1,2}\sigma_4^2n^{1/2-\gamma}+M_{1,3}\sigma_2n^{-\gamma/2},
    \end{equation}
    where 
    \begin{equation}
    \label{eq:def_const_M_1}
        \begin{split}         &M_{1,1}=C_{\Sigma}C_Q\biggl(T_1(\frac{\mu c_0}{4})(L_2+L_H)\max(\sqrt{C_{4,1}},\sqrt{C_1}) + k_0^\gamma/c_0\biggr)\\&M_{1,2}=C_{\Sigma}C_QL_H\sqrt{C_{4,2}}c_0\frac{k_0^{1-\gamma}}{1-\gamma}\\&M_{1,3}=C_{\Sigma}C_QL_2\sqrt{C_{2}}\sqrt{c_0}\sqrt{\frac{k_0^{1-\gamma}}{1-\gamma}}\eqsp,
        \end{split}
    \end{equation}
where $C_{4,1}$ and $C_{4,2}$ are defined in \Cref{cor:fourth_moment_bound_last_iterate}, $C_1$ and $C_2$ are defined in \Cref{lem:bound_last_iter_second_moment} and $T_1(\cdot)$ is defined in \cref{def:const_T_1_T_2}.
\end{lemma}
\begin{proof}
Using Minkowski's inequality and the definition of $D_n$, we obtain 
\begin{equation}
    \PE^{1/2}[\norm{D_n}^2] \leq 
    \PE^{1/2}[\norm{D_{n,1}}^2] +\PE^{1/2}[\norm{D_{n,2}}^2] + \PE^{1/2}[\norm{D_{n,3}}^2]\eqsp,
\end{equation}
and consider each of the terms $D_{n,1}, D_{n,2}, D_{n,3}$ separately. Applying \Cref{lem:bound_Q_i_and_Sigma_n}, we get
\begin{equation}
     \PE^{1/2}[\norm{D_{n,1}}^2] \leq \frac{C_{\Sigma}C_{Q}k_0^\gamma}{\sqrt{n}c_0}\norm{\theta_0-\thetas}\eqsp.
\end{equation}
Now we consider the term $D_{n,2}$. Applying Minkowski's inequality, \Cref{lem:bound_Q_i_and_Sigma_n} and \Cref{lem:H_theta_bound}, we have
\begin{equation}
    \PE^{1/2}[\norm{D_{n,2}}^2] \leq \frac{C_{\Sigma}C_{Q}}{\sqrt{n}}\sum_{i=1}^{n-1}\PE^{1/2}[\norm{H(\theta_{i-1})}^2]\leq \frac{C_{\Sigma}C_{Q}L_H}{\sqrt{n}}\sum_{i=1}^{n-1}\PE^{1/2}[\norm{\theta_{i-1}-\thetas}^4]\eqsp.
\end{equation}
For $D_{n,3}$ we note that $\{g(\theta_{i-1},\xi_i)\}_{i=1}^{n-1}$ is a  martingale difference with respect to $\F_i$. Hence, using  \Cref{lem:bound_Q_i_and_Sigma_n} and \Cref{ass:noise_decomposition}, we get 
\begin{equation}
\PE^{1/2}[\norm{D_{n,3}}^2] \leq \frac{C_{\Sigma}C_{Q}}{\sqrt{n}}\left(\sum_{i=1}^{n-1}\PE[\norm{g(\theta_{i-1},\xi_i)}^2]\right)^{1/2}
\leq \frac{C_{\Sigma}C_{Q}L_2}{\sqrt{n}}\left(\PE[\sum_{i=1}^{n-1}\norm{\theta_{i-1}-\thetas}^2]\right)^{1/2}\eqsp.
\end{equation}
Hence, it is enough to upper bound $\PE[\norm{\theta_{i}-\thetas}^{2p}]$ for $p = 1$ and $p = 2$ and $i \in \{0,\ldots,n-2\}$. Using \Cref{lem:bound_last_iter_second_moment} and \Cref{lem:bound_sum_exponent}, we obtain 
\begin{align}
&\left(\sum_{i=0}^{n-2}\PE[\norm{\theta_{i}-\thetas}^2]\right)^{1/2} \leq \left(\sum_{i=0}^{n-2} C_1\exp\biggl\{ -\frac{\mu c_0}{4}(i+k_0)^{1-\gamma}\biggr\}[\norm{\theta_0-\thetas}^2 + \sigma_2^2] + C_2\sigma_2^2\alpha_i\right)^{1/2}\\
&\qquad  \leq \sqrt{C_1}\sqrt{T_1\biggl(\frac{\mu c_0}{4}\biggr)}[\norm{\theta_0-\thetas} + \sigma_2] + \sqrt{C_2}\sigma_2\sqrt{c_0}\left(\frac{(n-2+k_0)^{1-\gamma} -(k_0-1)^{1-\gamma}}{1-\gamma}\right)^{1/2}, 
\end{align}
where $T_1(\cdot)$ is defined in \eqref{def:const_T_1_T_2}. Using \Cref{cor:fourth_moment_bound_last_iterate} and \Cref{lem:bound_sum_exponent}, we get 
\begin{align}
    &\sum_{i=0}^{n-2}\PE^{1/2}[\norm{\theta_{i}-\thetas}^4] \leq \sum_{i=0}^{n-2} \sqrt{C_{4,1}}\exp\biggl\{ -\frac{\mu c_0}{4}i^{1-\gamma}\biggr\}[\norm{\theta_0-\thetas}^2 + \sigma_4^2] + \sqrt{C_{4,2}}\sigma_4^2\alpha_i\\& \leq \sqrt{C_{4,1}}T_1\biggl(\frac{\mu c_0}{4}\biggr)[\norm{\theta_0-\thetas}^2 + \sigma_4^2] + \sqrt{C_{4,2}}\sigma_4^2 c_0\left(\frac{(n-2+k_0)^{1-\gamma}- (k_0-1)^{1-\gamma}}{1-\gamma}\right)\eqsp.
\end{align}
We finish the proof, using simple inequality $(n-2+k_0)^{1-\gamma}- (k_0-1)^{1-\gamma} \leq (k_0n)^{1-\gamma}$
\end{proof}


Let $(\xi_1',\ldots, \xi_{n-1}')$ be an independent copy of $(\xi_1,\ldots, \xi_{n-1})$. For each $1 \leq i \leq n-1$, we construct the sequence $\theta_k^{(i)}$, $1 \leq k \leq n-1$, as follows:
\begin{equation}
\label{eq:independent_replace_construct}
\theta_k^{(i)} = 
    \begin{cases}
     \theta_k\eqsp, \qquad &\text{if }k<i\\
     \theta_{k-1}^{(i)} - \alpha_k(\nabla f(\theta_{k-1}^{(i)}) + g(\theta_{k-1}^{(i)}, \xi_k')+ \eta(\xi_k')) \eqsp,\qquad&\text{if }k=i\\
     \theta_{k-1}^{(i)} - \alpha_k(\nabla f(\theta_{k-1}^{(i)}) + g(\theta_{k-1}^{(i)}, \xi_k)+\eta(\xi_k))\eqsp,\qquad&\text{if }k>i \eqsp.
    \end{cases}
\end{equation}

\begin{lemma}
\label{lem:bound_second_moment_difference}
   Assume \Cref{ass:L-smooth},\Cref{ass:noise_decomposition}($2$), \Cref{ass:hessian_Lipschitz_ball} and \Cref{ass:step_size}. Then for any $k \in \nset$ and $1 \leq i \leq n-1$ it holds  
    \begin{equation}
        \PE[\norm{\theta_k^{(i)}-\theta_k}^2] \leq  \alpha_i^2R_1\exp\biggl\{-2\mu\sum_{j=i+1}^{k}\alpha_j\biggr\}\biggl(R_2\exp\biggl\{-\frac{\mu c_0}{4}(i+k_0-1)^{1-\gamma}\biggr\}(\norm{\theta_{0}-\thetas}^2 + \sigma_2^2) + R_3\sigma_2^2
    \biggr),
    \end{equation}
    where we have set
    \begin{equation}
    \label{eq:def_R_1_R_2_R_3}
        R_1 = 4 \exp\biggl\{\frac{2 c_0^2(L_1+L_2)^2}{2\gamma-1}\biggr\}\eqsp, \qquad R_2 = L_2^2C_1, \qquad  R_3 =(1+C_2L_2) \eqsp.
    \end{equation}
    And constant $C_1$ and $C_2$ are defined in \Cref{lem:bound_last_iter_second_moment}.
    \end{lemma}
\begin{proof}
    By construction \eqref{eq:independent_replace_construct}, we have 
    \begin{equation}
    \theta_k^{(i)}-\theta_k = 
    \begin{cases}
     0\eqsp, \quad &\text{if }k<i\\
      - \alpha_k\bigl(g(\theta_{k-1}, \xi_k')+\eta(\xi_k')-g(\theta_{k-1}, \xi_k)-\eta(\xi_k)\bigr)\eqsp,\quad&\text{if }k=i\\
     \theta_{k-1}^{(i)}-\theta_{k-1}-\alpha_k\bigl(\nabla f(\theta_{k-1}^{(i)}) - \nabla f (\theta_{k-1}) +g(\theta_{k-1}^{(i)}, \xi_k)-g(\theta_{k-1}, \xi_k)\bigr) \eqsp,\quad&\text{if }k>i\\
    \end{cases}
    \end{equation}
    Since $\xi_i'$ is independent copy of $\xi_i$, we obtain 
    \begin{align}
        \PE[\norm{\theta_i^{(i)}-\theta_i}^2] &\overset{(a)}{\leq} 4\alpha_i^2(L_2^2\PE[\norm{\theta_{i-1}-\thetas}^2] + \sigma_2^2) \\&\overset{(b)}{\leq} 4\alpha_i^2\biggl(L_2^2C_1\exp\biggl\{-\frac{\mu c_0}{4}(i+k_0-1)^{1-\gamma}\biggr\}(\norm{\theta_{0}-\thetas}^2 + \sigma_2^2) + (1+C_2L_2)\sigma_2^2
    \biggr),
    \end{align}
    where in (a) we used \Cref{ass:noise_decomposition}, and in (b) we used \Cref{lem:bound_last_iter_second_moment} and $\alpha_{k-1}L_2 \leq 1$.
    For $k>i$, applying \cref{ass:noise_decomposition} and \cref{ass:L-smooth}, we have 
    \begin{align}
         \PE [\norm{\theta_k^{(i)}-\theta_k}^2|\F_{k-1}] &\leq \norm{\theta_{k-1}^{(i)}-\theta_{k-1}}^2 -2\alpha_k\langle\theta_{k-1}^{(i)}-\theta_{k-1}, \nabla f(\theta_{k-1}^{(i)}) - \nabla f (\theta_{k-1}) \rangle \\&\qquad + 2\alpha_k^2(L_1+L_2)^2\norm{\theta_{k-1}^{(i)}-\theta_{k-1}}^2\eqsp.
    \end{align}
    Taking expectation from both sides and applying \Cref{ass:L-smooth} with \Cref{lem:bounds_on_sum_step_sizes}\ref{eq:sum_alpha_k_p}, we obtain  
    \begin{align}
        \PE [\norm{\theta_k^{(i)}-\theta_k}^2] &\leq (1-2\alpha_k\mu + 2\alpha_k^2(L_1+L_2)^2)\PE[\norm{\theta_{k-1}^{(i)}-\theta_{k-1}}]^2 \\&\leq \exp\biggl\{\frac{2c_0^2(L_1+L_2)^2}{2\gamma-1}\biggr\}\exp\biggl\{-2\mu\sum_{j=i+1}^{k}\alpha_j\biggr\}\PE[ \norm{\theta_i^{(i)}-\theta_i}^2]\eqsp.
    \end{align}
    Combining the above inequalities completes the proof.
\end{proof}

\begin{lemma}
\label{lem:bound_fourth_moment_difference}
   Assume \Cref{ass:L-smooth},\Cref{ass:noise_decomposition}($4$), \Cref{ass:hessian_Lipschitz_ball} and \Cref{ass:step_size}. Then for any $k \in \nset$ and $1 \leq i \leq n-1$ it holds  
    \begin{equation}
        \PE[\norm{\theta_k^{(i)}-\theta_k}^4] \leq\alpha_i^4R_{4,1}\exp\biggl\{ -4\mu\sum_{j=i+1}^k\alpha_j\biggr\}\biggl(R_{4,2}\exp\{-\frac{2\mu c_0}{4}(i+k_0-1)^{1-\gamma}\}(\norm{\theta_{0}-\thetas}^4 + \sigma_4^4) + R_{4,3}\sigma_4^4\biggr)
    \end{equation}
    where we have set
    \begin{equation}
    \label{eq:def_R_41_R_42_R_43}
    R_{4,1} = 64\exp\biggl\{ \frac{4(L_1+L_2)^2(1+3c_0(L_1+L_2))^2)}{2\gamma-1}\biggr\}\eqsp, \quad R_{4,2} = L_2^4C_{4,1}\eqsp, \quad R_{4,3} =1+ L_2^2C_{4,2}\eqsp.
    \end{equation}
    And constant $C_{4,1}$, $C_{4,2}$ are defined in \Cref{cor:fourth_moment_bound_last_iterate}.
    \end{lemma}
\begin{proof}
Repeating the proof of the \Cref{lem:bound_second_moment_difference} for $k = i$, we get
\begin{align}
        \PE[\norm{\theta_i^{(i)}-\theta_i}^4] &\leq64\alpha_i^4(L_2^4\PE[\norm{\theta_{i-1}-\thetas}^4] + \sigma_4^4) \\& \leq 64\alpha_i^4\biggl(L_2^4C_{4,1}\exp\biggl\{-\frac{2\mu c_0}{4}(i+k_0-1)^{1-\gamma}\biggr\}(\norm{\theta_{0}-\thetas}^4 + \sigma_4^4) + (1+L_2^2C_{4,2})\sigma_4^4\biggr)\eqsp.
\end{align}
For $k>i$ we denote $\delta_k^{(i)} = \norm{\theta_k^{(i)}-\theta_k}$, similar to \eqref{eq:coupling_recurence}, we obtain 
\begin{align}
E[\{\delta_k^{(i)}\}^4|\F_{k-1}] \leq (1 -4\mu\alpha_k + 4\alpha_k^2(L_1+L_2)^2(1+3c_0(L_1+L_2))^2)\{\delta_{k-1}^{(i)}\}^4\eqsp.
\end{align}
Using 
\Cref{lem:bounds_on_sum_step_sizes}\ref{eq:sum_alpha_k_p}, we obtain
\begin{equation}
    E[\{\delta_k^{(i)}\}^4]\leq \exp\biggl\{ \frac{4(L_1+L_2)^2(1+3c_0(L_1+L_2))^2)}{2\gamma-1}\biggr\}\exp\biggl\{ -4\mu\sum_{j=i+1}^k\alpha_j\biggr\} \PE[\norm{\theta_i^{(i)}-\theta_i}^4]\eqsp.
\end{equation}
Combining the above inequalities completes the proof.
\end{proof}


\begin{lemma}
\label{lem:bound_sum_Dn-Dni}
        Assume \Cref{ass:L-smooth},\Cref{ass:noise_decomposition}($4$), \Cref{ass:hessian_Lipschitz_ball} and \Cref{ass:step_size}. Then it holds that 
        \begin{equation}
            \sum_{i=1}^{n-1}\PE^{1/2}[\norm{D_n-D_n^{(i)}}^2] \leq \frac{M_{2,1}}{\sqrt{n}}(\norm{\theta_0-\thetas}+\norm{\theta_0-\thetas}^2+\sigma_2+ \sigma_4^2) + M_{2,2}\sigma_4^2n^{1/2-\gamma}+  M_{2,3}\sigma_2n^{1/2-\gamma/2},
        \end{equation}
            where 
    \begin{equation}
    \label{eq:def_const_M_2}
        \begin{split}         &M_{2,1}=C_{\Sigma}C_QT_1(\frac{\mu c_0}{8})T_2(\frac{\mu c_0}{1-\gamma})(L_2+L_H)\max(\sqrt{2(C_1+c_0^2k_0^{-\gamma}R_1R_2)},c^2k_0^{-\gamma}\sqrt{R_{4,1}R_{4,2}})\\&M_{2,2}=C_{\Sigma}C_QL_Hc_0\sqrt{R_{4,1}R_{4,3}}T_2(\frac{\mu c_0}{1-\gamma})\frac{k_0^{1-\gamma}}{1-\gamma}\\&M_{2,3}=\sqrt{2}C_{\Sigma}C_QL_2\sqrt{C_{2}+R_1R_3c_0T_2(\frac{\mu c_0}{1-\gamma})}\frac{k_0^{1-\gamma/2}}{1-\gamma/2} \eqsp.
        \end{split}
    \end{equation}
    Constants $R_1, R_2, R_3$ are defined in \eqref{eq:def_R_1_R_2_R_3} and constants $R_{4,1}, R_{4,2}, R_{4,3}$ are defined \eqref{eq:def_R_41_R_42_R_43}.
\end{lemma}
\begin{proof}
Using Minkowski's inequality and the definition of $D_n$ and $D_n^{(i)}$, we obtain 
\begin{equation}
    \sum_{i=1}^{n-1}\PE^{1/2}[\norm{D_n-D_n^{(i)}}^2] \leq \sum_{i=1}^{n-1}\PE^{1/2}[\norm{D_{n,2}-D_{n,2}^{(i)}}^2] +\sum_{i=1}^{n-1}\PE^{1/2}[\norm{D_{n,3}-D_{n,3}^{(i)}}^2] 
\end{equation}
 Define $\F_j^{(i)} = \F_j$ if $j\leq i$ and $\F_j^{(i)} = \sigma(\F_j \vee \sigma(\xi_i'))$ otherwise. Then $\{g(\theta_{j-1},\xi_j)-g(\theta_{j-1}^{(i)},\widetilde{\xi}_j)\}_{j=1}^{n-1}$ is a martingale difference with respect to $\F_j^{(i)}$. Hence, we have, using \Cref{lem:bound_Q_i_and_Sigma_n} and the fact that $\theta_{j-1} = \theta_{j-1}^{(i)}$ for $j \leq i$, we obtain that 
 \begin{align}
&\PE[\norm{D_{n,3}-D_{n,3}^{(i)}}^2] = \PE\norm{\frac{\Sigma_n^{-1/2}}{\sqrt{n}}\sum_{j=1}^{n-1}Q_j(g(\theta_{j-1},\xi_j)-g(\theta_{j-1}^{(i)},\widetilde{\xi}_j))}^2 \\
&\qquad \leq \frac{C_{\Sigma}^2C_Q^2}{n}\PE[\norm{g(\theta_{i-1},\xi_i)-g(\theta_{i-1},\xi_i')}^2] +\frac{C_{\Sigma}^2C_Q^2}{n}\sum_{j=i+1}^{n-1}\PE[\norm{g(\theta_{j-1},\xi_j)-g(\theta_{j-1}^{(i)},\xi_j)}^2]\eqsp.
\end{align}
   Using \Cref{ass:noise_decomposition} and \Cref{lem:bound_Q_i_and_Sigma_n}, we get 
   \begin{equation}
       \PE[\norm{D_{n,3}-D_{n,3}^{(i)}}^2] \leq \frac{2C_{\Sigma}^2C_Q^2L_2^2}{n}\PE[\norm{\theta_{i-1}-\thetas}^2] +\frac{C_{\Sigma}^2C_Q^2L_2^2}{n}\sum_{j=i+1}^{n-1}\PE[\norm{\theta_{j-1}-\theta_{j-1}^{(i)}}^2]\eqsp.
   \end{equation}
   Using \Cref{lem:bound_second_moment_difference} and \Cref{lem:bound_sum_exponent}, we obtain 
   \begin{align}
       &\sum_{j=i+1}^{n-1}\PE[\norm{\theta_{j-1}-\theta_{j-1}^{(i)}}^2] \leq R_1R_2\exp\biggl\{-\frac{\mu c_0}{4}(i+k_0-1)^{1-\gamma}\biggr\}\alpha_i^2(\norm{\theta_{0}-\thetas}^2 + \sigma_2^2)T_2\biggl(\frac{\mu c_0}{1-\gamma}\biggr)(i+k_0)^{\gamma} \\ 
      & \qquad \qquad \qquad \qquad \qquad \qquad \qquad \qquad \qquad \qquad \qquad  + R_1R_3\sigma_2^2\alpha_i^2T_2\biggl(\frac{\mu c_0}{1-\gamma}\biggr)(i+k_0)^{\gamma} \\
      & \qquad \leq R_1R_3\sigma_2^2c_0T_2\biggl(\frac{\mu c_0}{1-\gamma}\biggr)\alpha_i + R_1R_2c_0^2k_0^{-\gamma}T_2\biggl(\frac{\mu c_0}{1-\gamma}\biggr)\exp\biggl\{-\frac{\mu c_0}{4}(i+k_0-1)^{1-\gamma}\biggr\}(\norm{\theta_{0}-\thetas}^2+\sigma_2^2)\eqsp.
   \end{align}
   Combining inequalities above, we get 
   \begin{align}
       \sum_{i=1}^{n-1}\PE^{1/2}[\norm{D_{n,3}-D_{n,3}^{(i)}}^2] &\leq \frac{\sqrt{2}C_{\Sigma}C_QL_2}{\sqrt{n}}\sqrt{C_1+ c_0^2k_0^{-\gamma}R_1R_2T_2\biggl(\frac{\mu c_0}{1-\gamma}\biggr)}T_1\biggl(\frac{\mu c_0}{8}\biggr)(\norm{\theta_0-\thetas}+\sigma_2)\\ &+\frac{\sqrt{2}C_{\Sigma}C_QL_2}{\sqrt{n}}\sqrt{C_2+ R_1R_3c_0T_2\biggl(\frac{\mu c_0}{1-\gamma}\biggr)}\sigma_2\left(\frac{(n+k_0-2)^{1-\gamma/2}-(k_0-1)^{1-\gamma/2}}{1-\gamma/2}\right)\eqsp.
   \end{align}
   We now proceed with $\sum_{i=1}^{n-1}\PE^{1/2}[\norm{D_{n,2}-D_{n,2}^{(i)}}^2]$.
   Using Minkowski's inequality together with  \Cref{lem:bound_Q_i_and_Sigma_n} and  \Cref{lem:H_theta_bound}, we get 
   \begin{equation}
       \PE^{1/2}[\norm{D_{n,2}-D_{n,2}^{(i)}}^2] \leq \frac{C_{\Sigma} C_Q L_H}{\sqrt{n}}\sum_{j=i+1}^{n-1}\PE^{1/2}[\norm{\theta_{j-1}-\theta_{j-1}^{(i)}}^4]\eqsp.
   \end{equation}
    Applying \Cref{lem:bound_fourth_moment_difference} and \Cref{lem:bound_sum_exponent}, we get using that $\alpha_i^2 (i+k_0)^{\gamma} \leq \alpha_0^2k_0^{-\gamma}$ that 
   \begin{align}
    \sum_{j=i+1}^{n-1}\PE^{1/2}[\norm{\theta_{j-1}-\theta_{j-1}^{(i)}}^4] &\leq c_0^2k_0^{-\gamma}\sqrt{R_{4,1}R_{4,2}}T_2(\frac{\mu c_0}{1-\gamma})\exp\{-\frac{\mu c_0}{4}(i+k_0-1)^{1-\gamma}\}(\norm{\theta_{0}-\thetas}^2 + \sigma_4^2) \\
       & \qquad \qquad \qquad \qquad + \alpha_ic_0\sqrt{R_{4,1}R_{4,3}}T_2(\frac{\mu c_0}{1-\gamma})\sigma_4^2\eqsp. 
   \end{align}
   Finally, applying \Cref{lem:bound_sum_exponent}, we get 
   \begin{align}
       \sum_{i=1}^{n-1}\PE^{1/2}[\norm{D_{n,2}-D_{n,2}^{(i)}}^2] &\leq \frac{C_{\Sigma} C_Q L_H}{\sqrt{n}}c_0^2k_0^{-\gamma}\sqrt{R_{4,1}R_{4,2}}T_2(\frac{\mu c_0}{1-\gamma})T_1(\frac{\mu c_0}{4})(\norm{\theta_{0}-\thetas}^2 + \sigma_4^2) \\&+ \frac{C_{\Sigma} C_Q L_H}{\sqrt{n}}c_0\sqrt{R_{4,1}R_{4,3}}T_2(\frac{\mu c_0}{1-\gamma})\sigma_4^2(\frac{(n+k_0-2)^{1-\gamma}-(k_0-1)^{1-\gamma}}{1-\gamma})\eqsp.
   \end{align}
   We finish the proof, using that $(n-2+k_0)^{\beta}- (k_0-1)^{\beta} \leq (k_0n)^{\beta}$ for $\beta \in (0,1)$
\end{proof}