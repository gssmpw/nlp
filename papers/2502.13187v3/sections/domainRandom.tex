\subsection{Domain Randomization}




\subsubsection{State Representation}
Representation grounding (RG) is a technique focusing on the State element of the Markov Decision Process in which the agent’s observations are mapped to key characteristics of the environment to facilitate the learning process [?]. The primary objective of RG is to align the agent's observations with real-world phenomena, thereby addressing the Sim-to-Real gap. Notably, recent works focusing explicitly on bridging this gap through RG—such as [S2R VLN, Reduce S2R, Human Ambiguity, R2S2R, Manipulate Object Collections]—are comparatively fewer than those employing Domain Randomization.
\\

One noteworthy approach within RG is Visual-Representation Grounding (VRG) [Human Ambiguity, TransVG], wherein an agent seeks to segment locations described by natural language. The work presented in [Human Ambiguity] tackles the challenges associated with visual grounding by introducing a fully decoupled modular framework. This framework segments objects in crowded scenes based on natural language descriptions, effectively addressing the limitations of traditional methods. By utilizing scene graph annotations and training each module independently in simulation, it enables robust and interpretable visual grounding for service robots interacting with non-expert users. This modular approach not only enhances performance across diverse scenarios but also provides a clear pathway for bridging the Sim-to-Real gap in robotic applications. Conversely, [TransVG] proposes a transformer-based framework for VRG that efficiently associates language queries with relevant image regions. By reformulating visual grounding as a direct coordinates regression problem and leveraging a simple stack of transformer layers, it circumvents the complexities tied to traditional methods. Although [TransVG] does not explicitly address Sim-to-Real applications, it offers an alternative technique for visual grounding that complements the insights provided by [Human Ambiguity]. Additionally, [Reduce S2R] aims to minimize the Sim-to-Real gap by incorporating depth images into the agent's observations, grounding these observations in reality.
\\

RG is particularly prominent in a widely studied problem formulation known as Vision-Language Navigation (VLN), where an agent learns to ground language instructions to both visual observations and actions [S2R VLN]. Various methodologies for addressing representation grounding are employed within works that utilize the VLN problem formulation [S2R VLN, Scene Intuitive, Are You Looking?, S2S]. These diverse RG techniques in VLN may serve as inspiration for future research endeavors aimed at bridging the Sim-to-Real gap. For instance, [Scene Intuitive] exemplifies the integration of both VLN and VRG by enabling agents to localize target objects based on high-level natural language instructions. This work implements a two-stage training process that enhances cross-modal understanding and effectively links language with visual environments. In a similar vein, [S2R VLN] explores the challenge of transferring a VLN agent trained in simulation to a physical robot operating in an unseen environment. By employing a subgoal model, this study effectively bridges the gap between high-level discrete navigation commands and the robot's low-level continuous actions. It uniquely utilizes representation grounding by developing an occupancy map and navigation graph that align high-level language instructions with real-world navigation points, thereby facilitating the effective grounding of the robot's actions within its physical surroundings. Furthermore, [Are You Looking?] investigates how grounding language instructions—such as "turn right" and "stop at the door"—can be achieved through multiple modalities. This research reveals that models relying solely on geometric route structures can outperform those dependent on visual features in unseen environments, presenting a contrasting perspective to other works that underscore the significance of visual input for effective representation grounding. This highlights a potential avenue for future research in optimizing the balance between visual and structural modalities in VLN tasks. Lastly, recent research [S2S] comparing two VLN environmental paradigms, including the continuous VLN-CE setting, uncovers a significant performance gap, with agents struggling to transfer effectively from topological to continuous environments. This study emphasizes the necessity of refining transfer techniques to sustain performance across varying levels of realism, distinguishing itself from [Scene Intuitive] by focusing more on the challenges of sim-to-sim transfer rather than the direct grounding of language instructions.
\\

The remaining works discussed in this section each present distinct methodologies for addressing representation grounding, showcasing a diverse array of approaches that enrich the broader understanding of RG. While some of these studies may not directly target Sim-to-Real transfer, they provide valuable insights and techniques that could inspire future research in this domain. For instance, [Read watch move] introduces a reinforcement learning-based framework for video grounding, formulating the task as a sequential decision-making process that allows an agent to progressively regulate temporal grounding boundaries. Similarly, [TSP] focuses on temporally grounding language in untrimmed videos through a framework that mimics human decision-making, enabling iterative refinement of temporal boundaries while clearly representing semantic concepts as branches in the policy. More closely aligned with Sim-to-Real transfer, [R2S2R] grounds the environment by adopting a Real-to-Sim approach, which generates "digital twin" simulations from minimal real-world data. This methodology aids in grounding the representations in the simulation to the actual real-world environment and enhances policy robustness without extensive human oversight. Additionally, [Weakly-Supervised Phrase Grounding] expands on the concept of representation grounding by presenting a dual reinforcement learning framework that directly optimizes the phrase grounding model, effectively linking textual phrases to their corresponding image regions in a weakly-supervised context. This approach underscores the importance of establishing robust connections between language and visual representations—a central theme across the discussed works—highlighting the potential for integrated strategies that leverage both language and visual cues to enhance grounding performance. Finally, [Manipulate Object Collections] is directly related to Sim-to-Real transfer, proposing a method for sim-to-real robot learning that exploits simulator state information, allowing for scalability across numerous objects. This study trains two encoders on raw object pose targets to learn representations that accurately ground the state information of a multi-object environment. Their evaluations demonstrate that employing grounded state representations to train a reinforcement learning policy improves performance and contributes to bridging the Sim-to-Real gap.
