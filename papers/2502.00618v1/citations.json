[
  {
    "index": 0,
    "papers": [
      {
        "key": "li2017learning",
        "author": "Li, Zhizhong and Hoiem, Derek",
        "title": "Learning without forgetting"
      },
      {
        "key": "kirkpatrick2017overcoming",
        "author": "Kirkpatrick, James and Pascanu, Razvan and Rabinowitz, Neil and Veness, Joel and Desjardins, Guillaume and Rusu, Andrei A and Milan, Kieran and Quan, John and Ramalho, Tiago and Grabska-Barwinska, Agnieszka and others",
        "title": "Overcoming catastrophic forgetting in neural networks"
      },
      {
        "key": "douillard2020podnet",
        "author": "Douillard, Arthur and Cord, Matthieu and Ollion, Charles and Robert, Thomas and Valle, Eduardo",
        "title": "Podnet: Pooled outputs distillation for small-tasks incremental learning"
      }
    ]
  },
  {
    "index": 1,
    "papers": [
      {
        "key": "kirkpatrick2017overcoming",
        "author": "Kirkpatrick, James and Pascanu, Razvan and Rabinowitz, Neil and Veness, Joel and Desjardins, Guillaume and Rusu, Andrei A and Milan, Kieran and Quan, John and Ramalho, Tiago and Grabska-Barwinska, Agnieszka and others",
        "title": "Overcoming catastrophic forgetting in neural networks"
      }
    ]
  },
  {
    "index": 2,
    "papers": [
      {
        "key": "li2017learning",
        "author": "Li, Zhizhong and Hoiem, Derek",
        "title": "Learning without forgetting"
      },
      {
        "key": "rebuffi2017icarl",
        "author": "Rebuffi, Sylvestre-Alvise and Kolesnikov, Alexander and Sperl, Georg and Lampert, Christoph H",
        "title": "icarl: Incremental classifier and representation learning"
      }
    ]
  },
  {
    "index": 3,
    "papers": [
      {
        "key": "yan2021dynamically",
        "author": "Yan, Shipeng and Xie, Jiangwei and He, Xuming",
        "title": "Der: Dynamically expandable representation for class incremental learning"
      },
      {
        "key": "boschini2022class",
        "author": "Boschini, Matteo and Bonicelli, Lorenzo and Buzzega, Pietro and Porrello, Angelo and Calderara, Simone",
        "title": "Class-incremental continual learning into the extended der-verse"
      },
      {
        "key": "wang2022foster",
        "author": "Wang, Fu-Yun and Zhou, Da-Wei and Ye, Han-Jia and Zhan, De-Chuan",
        "title": "Foster: Feature boosting and compression for class-incremental learning"
      },
      {
        "key": "zhou2022model",
        "author": "Zhou, Da-Wei and Wang, Qi-Wei and Ye, Han-Jia and Zhan, De-Chuan",
        "title": "A model or 603 exemplars: Towards memory-efficient class-incremental learning"
      }
    ]
  },
  {
    "index": 4,
    "papers": [
      {
        "key": "wang2022anti",
        "author": "Wang, Runqi and Bao, Yuxiang and Zhang, Baochang and Liu, Jianzhuang and Zhu, Wentao and Guo, Guodong",
        "title": "Anti-retroactive interference for lifelong learning"
      },
      {
        "key": "zhou2022model",
        "author": "Zhou, Da-Wei and Wang, Qi-Wei and Ye, Han-Jia and Zhan, De-Chuan",
        "title": "A model or 603 exemplars: Towards memory-efficient class-incremental learning"
      }
    ]
  },
  {
    "index": 5,
    "papers": [
      {
        "key": "zhu2021class",
        "author": "Zhu, Fei and Cheng, Zhen and Zhang, Xu-Yao and Liu, Cheng-lin",
        "title": "Class-incremental learning via dual augmentation"
      },
      {
        "key": "zhu2021prototype",
        "author": "Zhu, Fei and Zhang, Xu-Yao and Wang, Chuang and Yin, Fei and Liu, Cheng-Lin",
        "title": "Prototype augmentation and self-supervision for incremental learning"
      },
      {
        "key": "petit2023fetril",
        "author": "Petit, Gr{\\'e}goire and Popescu, Adrian and Schindler, Hugo and Picard, David and Delezoide, Bertrand",
        "title": "Fetril: Feature translation for exemplar-free class-incremental learning"
      }
    ]
  },
  {
    "index": 6,
    "papers": [
      {
        "key": "zhou2024expandable",
        "author": "Zhou, Da-Wei and Sun, Hai-Long and Ye, Han-Jia and Zhan, De-Chuan",
        "title": "Expandable subspace ensemble for pre-trained model-based class-incremental learning"
      },
      {
        "key": "zhou2023revisiting",
        "author": "Zhou, Da-Wei and Cai, Zi-Wen and Ye, Han-Jia and Zhan, De-Chuan and Liu, Ziwei",
        "title": "Revisiting class-incremental learning with pre-trained models: Generalizability and adaptivity are all you need"
      },
      {
        "key": "wang2022learning",
        "author": "Wang, Zifeng and Zhang, Zizhao and Lee, Chen-Yu and Zhang, Han and Sun, Ruoxi and Ren, Xiaoqi and Su, Guolong and Perot, Vincent and Dy, Jennifer and Pfister, Tomas",
        "title": "Learning to prompt for continual learning"
      },
      {
        "key": "wang2022dualprompt",
        "author": "Wang, Zifeng and Zhang, Zizhao and Ebrahimi, Sayna and Sun, Ruoxi and Zhang, Han and Lee, Chen-Yu and Ren, Xiaoqi and Su, Guolong and Perot, Vincent and Dy, Jennifer and others",
        "title": "Dualprompt: Complementary prompting for rehearsal-free continual learning"
      }
    ]
  },
  {
    "index": 7,
    "papers": [
      {
        "key": "wang2022learning",
        "author": "Wang, Zifeng and Zhang, Zizhao and Lee, Chen-Yu and Zhang, Han and Sun, Ruoxi and Ren, Xiaoqi and Su, Guolong and Perot, Vincent and Dy, Jennifer and Pfister, Tomas",
        "title": "Learning to prompt for continual learning"
      },
      {
        "key": "wang2022dualprompt",
        "author": "Wang, Zifeng and Zhang, Zizhao and Ebrahimi, Sayna and Sun, Ruoxi and Zhang, Han and Lee, Chen-Yu and Ren, Xiaoqi and Su, Guolong and Perot, Vincent and Dy, Jennifer and others",
        "title": "Dualprompt: Complementary prompting for rehearsal-free continual learning"
      },
      {
        "key": "smith2023coda",
        "author": "Smith, James Seale and Karlinsky, Leonid and Gutta, Vyshnavi and Cascante-Bonilla, Paola and Kim, Donghyun and Arbelle, Assaf and Panda, Rameswar and Feris, Rogerio and Kira, Zsolt",
        "title": "Coda-prompt: Continual decomposed attention-based prompting for rehearsal-free continual learning"
      },
      {
        "key": "gao2024consistent",
        "author": "Gao, Zhanxin and Cen, Jun and Chang, Xiaobin",
        "title": "Consistent Prompting for Rehearsal-Free Continual Learning"
      }
    ]
  },
  {
    "index": 8,
    "papers": [
      {
        "key": "zhou2024expandable",
        "author": "Zhou, Da-Wei and Sun, Hai-Long and Ye, Han-Jia and Zhan, De-Chuan",
        "title": "Expandable subspace ensemble for pre-trained model-based class-incremental learning"
      },
      {
        "key": "zhou2023revisiting",
        "author": "Zhou, Da-Wei and Cai, Zi-Wen and Ye, Han-Jia and Zhan, De-Chuan and Liu, Ziwei",
        "title": "Revisiting class-incremental learning with pre-trained models: Generalizability and adaptivity are all you need"
      }
    ]
  },
  {
    "index": 9,
    "papers": [
      {
        "key": "radford2021learning",
        "author": "Radford, Alec and Kim, Jong Wook and Hallacy, Chris and Ramesh, Aditya and Goh, Gabriel and Agarwal, Sandhini and Sastry, Girish and Askell, Amanda and Mishkin, Pamela and Clark, Jack and others",
        "title": "Learning transferable visual models from natural language supervision"
      },
      {
        "key": "li2022blip",
        "author": "Li, Junnan and Li, Dongxu and Xiong, Caiming and Hoi, Steven",
        "title": "Blip: Bootstrapping language-image pre-training for unified vision-language understanding and generation"
      },
      {
        "key": "kirillov2023segment",
        "author": "Kirillov, Alexander and Mintun, Eric and Ravi, Nikhila and Mao, Hanzi and Rolland, Chloe and Gustafson, Laura and Xiao, Tete and Whitehead, Spencer and Berg, Alexander C and Lo, Wan-Yen and others",
        "title": "Segment anything"
      },
      {
        "key": "openai2023gpt4",
        "author": "OpenAI",
        "title": "GPT-4 Technical Report"
      },
      {
        "key": "alayrac2022flamingo",
        "author": "Alayrac, Jean-Baptiste and Donahue, Jeff and Luc, Pauline and Miech, Antoine and Barr, Iain and Hasson, Yana and Lenc, Karel and Mensch, Arthur and Millican, Katherine and Reynolds, Malcolm and others",
        "title": "Flamingo: a visual language model for few-shot learning"
      }
    ]
  },
  {
    "index": 10,
    "papers": [
      {
        "key": "radford2021learning",
        "author": "Radford, Alec and Kim, Jong Wook and Hallacy, Chris and Ramesh, Aditya and Goh, Gabriel and Agarwal, Sandhini and Sastry, Girish and Askell, Amanda and Mishkin, Pamela and Clark, Jack and others",
        "title": "Learning transferable visual models from natural language supervision"
      }
    ]
  },
  {
    "index": 11,
    "papers": [
      {
        "key": "jia2021scaling",
        "author": "Jia, Chao and Yang, Yinfei and Xia, Ye and Chen, Yi-Ting and Parekh, Zarana and Pham, Hieu and Le, Quoc and Sung, Yun-Hsuan and Li, Zhen and Duerig, Tom",
        "title": "Scaling up visual and vision-language representation learning with noisy text supervision"
      }
    ]
  },
  {
    "index": 12,
    "papers": [
      {
        "key": "zhou2022learning",
        "author": "Zhou, Kaiyang and Yang, Jingkang and Loy, Chen Change and Liu, Ziwei",
        "title": "Learning to prompt for vision-language models"
      },
      {
        "key": "zhou2022conditional",
        "author": "Zhou, Kaiyang and Yang, Jingkang and Loy, Chen Change and Liu, Ziwei",
        "title": "Conditional prompt learning for vision-language models"
      },
      {
        "key": "10171397",
        "author": "Xing, Yinghui and Wu, Qirui and Cheng, De and Zhang, Shizhou and Liang, Guoqiang and Wang, Peng and Zhang, Yanning",
        "title": "Dual Modality Prompt Tuning for Vision-Language Pre-Trained Model"
      },
      {
        "key": "yao2023visual",
        "author": "Yao, Hantao and Zhang, Rui and Xu, Changsheng",
        "title": "Visual-language prompt tuning with knowledge-guided context optimization"
      },
      {
        "key": "10814093",
        "author": "Zhang, Wenyao and Wu, Letian and Zhang, Zequn and Yu, Tao and Ma, Chao and Jin, Xin and Yang, Xiaokang and Zeng, Wenjun",
        "title": "Unleash the Power of Vision-Language Models by Visual Attention Prompt and Multi-modal Interaction"
      }
    ]
  },
  {
    "index": 13,
    "papers": [
      {
        "key": "yao2024tcp",
        "author": "Yao, Hantao and Zhang, Rui and Xu, Changsheng",
        "title": "TCP: Textual-based Class-aware Prompt tuning for Visual-Language Model"
      }
    ]
  },
  {
    "index": 14,
    "papers": [
      {
        "key": "li2024graphadapter",
        "author": "Li, Xin and Lian, Dongze and Lu, Zhihe and Bai, Jiawang and Chen, Zhibo and Wang, Xinchao",
        "title": "Graphadapter: Tuning vision-language models with dual knowledge graph"
      },
      {
        "key": "pantazis2022svl",
        "author": "Pantazis, Omiros and Brostow, Gabriel and Jones, Kate and Mac Aodha, Oisin",
        "title": "Svl-adapter: Self-supervised adapter for vision-language pretrained models"
      },
      {
        "key": "xin2024vmt",
        "author": "Xin, Yi and Du, Junlong and Wang, Qiang and Lin, Zhiwen and Yan, Ke",
        "title": "Vmt-adapter: Parameter-efficient transfer learning for multi-task dense scene understanding"
      }
    ]
  },
  {
    "index": 15,
    "papers": [
      {
        "key": "zhang2024concept",
        "author": "Zhang, Yi and Zhang, Ce and Yu, Ke and Tang, Yushun and He, Zhihai",
        "title": "Concept-Guided Prompt Learning for Generalization in Vision-Language Models"
      },
      {
        "key": "wu2024transferring",
        "author": "Wu, Wenhao and Sun, Zhun and Song, Yuxin and Wang, Jingdong and Ouyang, Wanli",
        "title": "Transferring vision-language models for visual recognition: A classifier perspective"
      },
      {
        "key": "luo2024cheap",
        "author": "Luo, Gen and Zhou, Yiyi and Ren, Tianhe and Chen, Shengxin and Sun, Xiaoshuai and Ji, Rongrong",
        "title": "Cheap and quick: Efficient vision-language instruction tuning for large language models"
      },
      {
        "key": "gao2022pyramidclip",
        "author": "Gao, Yuting and Liu, Jinfeng and Xu, Zihan and Zhang, Jun and Li, Ke and Ji, Rongrong and Shen, Chunhua",
        "title": "Pyramidclip: Hierarchical feature alignment for vision-language model pretraining"
      }
    ]
  },
  {
    "index": 16,
    "papers": [
      {
        "key": "zhou2022learning",
        "author": "Zhou, Kaiyang and Yang, Jingkang and Loy, Chen Change and Liu, Ziwei",
        "title": "Learning to prompt for vision-language models"
      }
    ]
  },
  {
    "index": 17,
    "papers": [
      {
        "key": "zhou2022conditional",
        "author": "Zhou, Kaiyang and Yang, Jingkang and Loy, Chen Change and Liu, Ziwei",
        "title": "Conditional prompt learning for vision-language models"
      }
    ]
  },
  {
    "index": 18,
    "papers": [
      {
        "key": "wang2023attriclip",
        "author": "Wang, Runqi and Duan, Xiaoyue and Kang, Guoliang and Liu, Jianzhuang and Lin, Shaohui and Xu, Songcen and L{\\\"u}, Jinhu and Zhang, Baochang",
        "title": "Attriclip: A non-incremental learner for incremental knowledge learning"
      }
    ]
  },
  {
    "index": 19,
    "papers": [
      {
        "key": "yu2024boosting",
        "author": "Yu, Jiazuo and Zhuge, Yunzhi and Zhang, Lu and Hu, Ping and Wang, Dong and Lu, Huchuan and He, You",
        "title": "Boosting continual learning of vision-language models via mixture-of-experts adapters"
      }
    ]
  },
  {
    "index": 20,
    "papers": [
      {
        "key": "konishi2023parameter",
        "author": "Konishi, Tatsuya and Kurokawa, Mori and Ono, Chihiro and Ke, Zixuan and Kim, Gyuhak and Liu, Bing",
        "title": "Parameter-level soft-masking for continual learning"
      }
    ]
  },
  {
    "index": 21,
    "papers": [
      {
        "key": "wang2022sparcl",
        "author": "Wang, Zifeng and Zhan, Zheng and Gong, Yifan and Yuan, Geng and Niu, Wei and Jian, Tong and Ren, Bin and Ioannidis, Stratis and Wang, Yanzhi and Dy, Jennifer",
        "title": "Sparcl: Sparse continual learning on the edge"
      }
    ]
  },
  {
    "index": 22,
    "papers": [
      {
        "key": "zhang2024overcoming",
        "author": "Zhang, Wenxuan and Janson, Paul and Aljundi, Rahaf and Elhoseiny, Mohamed",
        "title": "Overcoming Generic Knowledge Loss with Selective Parameter Update"
      }
    ]
  },
  {
    "index": 23,
    "papers": [
      {
        "key": "zheng2023preventing",
        "author": "Zheng, Zangwei and Ma, Mingyuan and Wang, Kai and Qin, Ziheng and Yue, Xiangyu and You, Yang",
        "title": "Preventing zero-shot transfer degradation in continual learning of vision-language models"
      }
    ]
  },
  {
    "index": 24,
    "papers": [
      {
        "key": "yu2025select",
        "author": "Yu, Yu-Chu and Huang, Chi-Pin and Chen, Jr-Jen and Chang, Kai-Po and Lai, Yung-Hsuan and Yang, Fu-En and Wang, Yu-Chiang Frank",
        "title": "Select and distill: Selective dual-teacher knowledge transfer for continual learning on vision-language models"
      }
    ]
  }
]