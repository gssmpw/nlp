\section{Related Works}
\label{sec_related_works}
Several works have investigated the training dynamics of neural networks in the small initialization regime. One of the earliest works examined diagonal linear networks, showing that small initialization leads gradient flow to converge towards minimum $\ell_1$-norm solutions \citep{srebro_ib, dln_sparse}. For linear neural networks, it has been observed that gradient descent with small initialization tends to converge toward low-rank solutions \citep{guna_mtx_fct, cohen_mtx_fct}, although rigorous results are primarily limited to shallow linear networks \citep{mahdi_ib, lee_saddle}. A similar sparsity-inducing effect of small initialization has been observed for non-linear neural networks as well \citep{chizat_lazy}, but theoretical results have mostly been established for two-layer neural networks trained on simple data sets \citep{lyu_simp,gf_orth,wang_saddle}. Recent works on two-layer networks have explored more challenging scenarios \citep{damian_reps, abbe_msp, mousavi_sgd}, but they often make other assumptions about the training algorithm, such as layer-wise training, the use of explicit regularization like weight decay, etc., whereas we study the dynamics of gradient flow with respect to all the weights and do not add any explicit regularization in the training loss. It is also worth noting that most of the aforementioned works examine the \emph{entire} training process; in contrast, our work describes a segment of the gradient flow dynamics beyond the origin, however, our results hold for a wider class of neural networks. 

Another line of work has identified the so-called saddle-to-saddle dynamics in the trajectory of gradient descent when the initialization is small \citep{jacot_sd, lyu_resolving}.  These works have observed that during training, the trajectory of gradient descent passes through a sequence of saddle points. Moreover, the loss curve almost appears like a piece-wise constant function, alternating between being stagnant and decreasing sharply; see \Cref{fig:loss_evol_2l} for an example. Some other works also refer to this phenomenon as \emph{incremental learning} \citep{gidel_incr, gissin_incr}, noting that the function learned by the neural network gradually increases in complexity as it moves from one saddle to another. So far, this kind of saddle-to-saddle dynamics has been rigorously established for diagonal linear neural networks \citep{pesme_sd, abbe_inc} and two-layer linear and non-linear neural networks trained with various gradient-based methods under data-related assumptions \citep{lee_saddle, gf_orth, wang_saddle, montanari_saddle,abbe_sgd}, and is conjectured to be true for a wider class of neural networks. Our work, which describes the first saddle point encountered by gradient flow after escaping the origin, can be seen as a step towards establishing it.

Lastly, we highlight the work by \cite{lyu_resolving}, which studies the gradient flow dynamics of linear neural networks under small initialization after escaping the origin. While our paper studies a broader class of neural networks, their proof technique has inspired our approach.