\documentclass[11pt, sigconf]{acmart}


\AtBeginDocument{%
  \providecommand\BibTeX{{%
    \normalfont B\kern-0.5em{\scshape i\kern-0.25em b}\kern-0.8em\TeX}}}




\usepackage[ruled,vlined]{algorithm2e}
\usepackage[noend]{algpseudocode}

\input{macros}



    

\newcommand{\sysname}{F\emph{in}P}

\setcopyright{acmlicensed}
\copyrightyear{2025}
\acmYear{2025}
\acmDOI{XXXXXXX.XXXXXXX}
%% These commands are for a PROCEEDINGS abstract or paper.
\acmConference[ACM'25]{ACM Conference}{2025}{ }

\makeatletter
\renewcommand\@formatdoi[1]{\ignorespaces}
\makeatother


\settopmatter{printfolios=true}


\begin{document}


\title{\sysname: Fairness-in-Privacy in Federated Learning by Addressing Disparities in Privacy Risk}




\author{Tianyu Zhao}
\email{tzhao15@uci.edu}
\affiliation{%
  \institution{University of California, Irvine}
  \city{}
  \state{}
  \country{}
}
\author{Mahmoud Srewa}
\email{msrewa@uci.edu}
\affiliation{%
  \institution{University of California, Irvine}
  \city{}
  \state{}
  \country{}
}

\author{Salma Elmalaki}
\email{salma.elmalaki@uci.edu}
\affiliation{%
  \institution{University of California, Irvine}
  \city{}
  \state{}
  \country{}
}

\renewcommand{\shortauthors}{Zhao et al.}








\begin{acronym}
    \acro{har}[HAR]{Human Activity Recognition}
    \acro{tcn}[TCN]{Temporal Convolutional Network }
    \acro{fl}[FL]{Federated Learning}
    \acro{aasd}[AASD]{Average Absolute SIA Difference From Mean}
    \acro{sia}[SIA]{Source Inference Attack}
    \acro{mia}[MIA]{Membership Inference Attack }
    \acro{mad}[MAD]{Mean Average Deviation}
    \acro{acc}[ACC]{Accuracy}
    \acro{rl}[RL]{Reinforcement learning}
    \acro{fedavg}[FedAvg]{Federated Averaging Algorithm}
    \acro{noniid}[non-IID]{Non-Independent and Identically Distributed}
    \acro{dp}[DF]{Differential Privacy}
    \acro{he}[HE]{Homomorphic Encryption}
    \acro{smpc}[SMPC]{Secure Multi-Party Computation}
    \acro{fe}[FE]{Functional Encryption}
\end{acronym}


\begin{abstract}
Ensuring fairness in machine learning, particularly in human-centric applications, extends beyond algorithmic bias to encompass fairness in privacy, specifically the equitable distribution of privacy risk. This is critical in federated learning (FL), where decentralized data necessitates balanced privacy preservation across clients. We introduce \sysname, a framework designed to achieve fairness in privacy by mitigating disproportionate exposure to source inference attacks (SIA). \sysname employs a dual approach: (1) server-side adaptive aggregation to address unfairness in client contributions in global model, and (2) client-side regularization to reduce client vulnerability. This comprehensive strategy targets both the symptoms and root causes of privacy unfairness. Evaluated on the Human Activity Recognition (HAR) and CIFAR-10 datasets, \sysname\ demonstrates a $\approx 20\%$ improvement in fairness in privacy on HAR with minimal impact on model utility, and effectively mitigates SIA risks on CIFAR-10, showcasing its ability to provide fairness in privacy in FL systems without compromising performance.



\end{abstract}

%%
%% The code below is generated by the tool at http://dl.acm.org/ccs.cfm.
%% Please copy and paste the code instead of the example below.
%%
% \begin{CCSXML}
% <ccs2012>
%    <concept>
%        <concept_id>10002978</concept_id>
%        <concept_desc>Security and privacy</concept_desc>
%        <concept_significance>500</concept_significance>
%        </concept>
%    <concept>
%        <concept_id>10010147.10010257.10010258.10010261</concept_id>
%        <concept_desc>Computing methodologies~Reinforcement learning</concept_desc>
%        <concept_significance>500</concept_significance>
%        </concept>
%    <concept>
%        <concept_id>10003120</concept_id>
%        <concept_desc>Human-centered computing</concept_desc>
%        <concept_significance>300</concept_significance>
%        </concept>
%  </ccs2012>
% \end{CCSXML}

% \ccsdesc[500]{Security and privacy}
% \ccsdesc[500]{Computing methodologies~Reinforcement learning}
% \ccsdesc[300]{Human-centered computing}

%%
%% Keywords. The author(s) should pick words that accurately describe
%% the work being presented. Separate the keywords with commas.
\keywords{fairness in privacy, federated learning, human-centered design}

\maketitle

\input{01_introduction}
\input{02_relatedwork}
\input{03_threatmodel}
\input{04_fairnessmetric}
\input{06_evaluations}
\input{07_discussion}
\input{08_conclusion}


%%
%% The acknowledgments section is defined using the "acks" environment
%% (and NOT an unnumbered section). This ensures the proper
%% identification of the section in the article metadata, and the
%% consistent spelling of the heading.
\begin{acks}
This work is supported by the U.S. National Science Foundation (NSF) under grant number 2339266.
\end{acks}


%%
%% The next two lines define the bibliography style to be used, and
%% the bibliography file.
\balance
\bibliographystyle{ACM-Reference-Format}
\bibliography{facctref}


%%
%% If your work has an appendix, this is the place to put it.
\appendix
\input{09_appendix}



\end{document}
\endinput

