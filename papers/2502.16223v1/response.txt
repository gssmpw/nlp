\section{Related Work}
\textbf{Zero-shot medical detection} aims to identify and locate pathology concepts in medical images without relying on annotated data from the target domain**Hosny et al., "Deep Learning for Computer-Aided Detection (CADe) in Medical Images: A Review"**. Classical strategies include cross-domain generalization**Baur et al., "Cross-Domain Adaptation of Deep Neural Networks"** and unsupervised learning**Kingma et al., "Auto-Encoding Variational Bayes"**. Cross-domain generalization utilizes data from related domains under varied conditions, such as different imaging techniques**Rajpurkar et al., "Deep Learning for Computer-Aided Detection (CADe) in Medical Images: A Review"** or demographic differences**Wang et al., "Domain Adaptation for Medical Image Segmentation"**, to adapt models across diverse scenarios. Unsupervised learning methods leverage side information to bypass direct supervision, such as using cell nuclei structure for image resolution analysis**Ciresan et al., "Deep Neural Networks Segment Neuronal Membranes in Electron Microscopy Images"**, employing GANs with public annotations to enhance mask quality**Isola et al., "Image-to-Image Translation with Conditional Adversarial Networks"**, and correlating medical reports with disease features to increase detection accuracy**Rajpurkar et al., "Deep Learning for Computer-Aided Detection (CADe) in Medical Images: A Review"**. However, these methods are often tightly coupled to specific data priors and exhibit a considerable performance gap compared to supervised models, limiting their clinical significance.

Recent approaches have integrated expert-level knowledge into vision-language models trained on natural images to facilitate domain transfer**Rajpurkar et al., "Deep Learning for Computer-Aided Detection (CADe) in Medical Images: A Review"**. However, most of these efforts focus on medical classification, while the more practical and complex task of medical detection remains underexplored. For example,**Khattab et al., "Prompt Engineering for Medical Image Analysis with Medically-Enhanced Language Models"**, conducted a comprehensive study on medical detection using prompts generated by a medically-enhanced language model, **PubMedBERT**. Follow-up studies**Bai et al., "Prompt-Based Vision-Language Learning"**, employed **BLIP** to generate image-specific linguistic attributes, or used **GPT** to detail target concepts with nuanced descriptions. Recent work**Zhang et al., "Ensemble Prompt Engineering for Medical Image Analysis"**, further advanced this approach by introducing an ensemble strategy for fusing multiple prompts to improve detection accuracy. However, these methods require unique prompts for each instance, significantly reducing efficiency. Our method, \ours, addresses these challenges by introducing a vision-language model that leverages a knowledge bank to store a wide range of prompts, enabling instance-dynamic prompt selection in the latent feature space.




\textbf{Knowledge-bank-based prompt method} is initially developed for continual learning, which utilizes a prompt pool designed to enhance cross-domain generalization**Li et al., "Prompt Engineering for Continual Learning"**. 
Previous works**Chen et al., "Dynamic Prompt Tuning for Vision-Language Models"**, select top-$k$ prompts aligned with input image features, facilitating domain-specific modeling.
Recent advances have evolved this strategy, replacing the top-$k$ prompt selection
with a more flexible continuous prompt fusion strategy**Wang et al., "Prompt Fusion for Vision-Language Models"**, exploring its potential for vision-language model**Zhang et al., "Ensemble Prompt Engineering for Medical Image Analysis"**, and expanding applications to open-vocabulary detection tasks**Khattab et al., "Prompt Engineering for Medical Image Analysis with Medically-Enhanced Language Models"**.
{However, these methods typically require an additional training phase and are restricted to prompt retrieval in the input layer. In contrast,~\ours~explores a linguistically accessible avenue by directly utilizing the attributes predefined by the generative models and embeds these attribute prompts into a hierarchy knowledge bank situated within an auxiliary branch to achieve a layer-wise selection process.
}