\section{Related Work}
\textbf{Zero-shot medical detection} aims to identify and locate pathology concepts in medical images without relying on annotated data from the target domain____. Classical strategies include cross-domain generalization____ and unsupervised learning____. Cross-domain generalization utilizes data from related domains under varied conditions, such as different imaging techniques____ or demographic differences____, to adapt models across diverse scenarios. Unsupervised learning methods leverage side information to bypass direct supervision, such as using cell nuclei structure for image resolution analysis____, employing GANs with public annotations to enhance mask quality____, and correlating medical reports with disease features to increase detection accuracy____. However, these methods are often tightly coupled to specific data priors and exhibit a considerable performance gap compared to supervised models, limiting their clinical significance.

Recent approaches have integrated expert-level knowledge into vision-language models trained on natural images to facilitate domain transfer____. However, most of these efforts focus on medical classification, while the more practical and complex task of medical detection remains underexplored. For example,____ conducted a comprehensive study on medical detection using prompts generated by a medically-enhanced language model, PubMedBERT____. Follow-up studies____ employed BLIP____ to generate image-specific linguistic attributes, or used GPT____ to detail target concepts with nuanced descriptions. Recent work____ further advanced this approach by introducing an ensemble strategy for fusing multiple prompts to improve detection accuracy. However, these methods require unique prompts for each instance, significantly reducing efficiency. Our method, \ours, addresses these challenges by introducing a vision-language model that leverages a knowledge bank to store a wide range of prompts, enabling instance-dynamic prompt selection in the latent feature space.




\textbf{Knowledge-bank-based prompt method} is initially developed for continual learning, which utilizes a prompt pool designed to enhance cross-domain generalization____. 
Previous works____ select top-$k$ prompts aligned with input image features, facilitating domain-specific modeling.
Recent advances have evolved this strategy, replacing the top-$k$ prompt selection
with a more flexible continuous prompt fusion strategy____, exploring its potential for vision-language model____, and expanding applications to open-vocabulary detection tasks____.
{However, these methods typically require an additional training phase and are restricted to prompt retrieval in the input layer. In contrast,~\ours~explores a linguistically accessible avenue by directly utilizing the attributes predefined by the generative models and embeds these attribute prompts into a hierarchy knowledge bank situated within an auxiliary branch to achieve a layer-wise selection process.
}