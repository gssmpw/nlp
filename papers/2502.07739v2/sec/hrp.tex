\section{Method: High-Rank Preheating}
In this section, we introduce High-Rank Preheating (HRP, Algorithm \ref{hrp-alg}), our proposed LoRA initialization algorithm for addressing the weaknesses identified in Section \ref{sec:theory}. 

The target of HRP is approaching the wise initialization suggested in Section \ref{theory-observation}, which makes both Asymmetric LoRA and classic LoRA theoretically guaranteed to converge better in matrix sensing. This initialization is not directly available because $W^{\operatorname{pre}}$ is unknown. However, through HRP, it can be approximated by using a few steps of high-rank LoRA. Specifically, HRP can be decomposed into two stages: the preheating stage and the initializing stage. 

In the preheating stage, HRP uses high-rank LoRA to approximate the main singular vectors of $W^{\operatorname{target}}-W^{\operatorname{pre}}$ as preheating. 
Using high-rank LoRA is inspired by Theorem \ref{ms-loss}, which tells that LoRA with higher rank has better-converged results in expectation. What we want from high-rank LoRA is an approximation of the main singular vectors of $W^{\operatorname{target}}-W^{\operatorname{pre}}$, which is achieved by main singular values of $\hat{B}\hat{A}^\top$. However, these singular values emerge at the beginning stage of high-rank LoRA optimization, which means a few steps of optimization of high-rank LoRA are enough for preheating. 

In the initializing stage, HRP calculates the SVD decomposition of $\hat{B}\hat{A}^\top=U\Sigma V^\top$ and treats $U[:,:r], V[:,:r]$ as an approximation of left and right main singular vectors of $W_i^{\operatorname{target}}-W_i^{\operatorname{pre}}$. 
Then, HRP injects LoRA into target modules with initialization
\begin{align*}
    \operatorname{LSI}: A_0=O_{a\times r},~~~~B_0=U[:,:r],\\
    \operatorname{RSI}: A_0=V[:,:r],~~~~B_0=O_{b\times r}.
\end{align*}
If HRP approximates the main singular vectors of $W^{\operatorname{target}}-W^{\operatorname{pre}}$ well, HRP is expected to achieve better results in practice. However, it is also constrained by the limitation of high-rank LoRA. To address this problem, we re-analyze the matrix sensing problem and find that at least, HRP makes low-rank LoRA have comparable convergence properties with high-rank LoRA. Specifically, we have the following theorem. 

\begin{algorithm}
\label{hrp-alg}
\caption{HRP: High-Rank Preheating}
\begin{algorithmic}[1]
\INPUT Rank $R$ and $\#$steps $S$ for preheating, rank $r$ and $\#$steps $s$ for fine-tuning, pre-trained model $W$
\STATE High-rank preheating $$\hat{A}, \hat{B}\leftarrow AsymLoRA(\hat{A_0}, \hat{B_0}, S)$$
\STATE Calculate SVD decomposition $U\Sigma V^\top=\hat{B}\hat{A}^\top$
\STATE Re-initialize $$\operatorname{RSI:}~~~A_0=V_{:,:r}, B_0=O_{b\times r}$$ or $$\operatorname{LSI:}~~~A_0=O_{a\times r}, B_0=U_{:,:r}$$
\STATE Fine-tuning $A, B\leftarrow LoRA(A_0,B_0,S)$
\OUTPUT fine-tuned model $W+BA^\top$
\end{algorithmic}
\end{algorithm}

\begin{theorem}
    \label{hrp-theory}
    For HRP initialized Asymmetric LoRA with one pre-heating step and the same updating rules (LSI preheating with LSI fine-tuning or RSI preheating with RSI fine-tuning) under problem \ref{matrix-sensing}, if $\operatorname{rank}(M)\leq r$ we have
    \begin{align*}
        &\mathbb{E}_{LSI}\left[\mathcal{L}(\lim_{t\to\infty}X_t)\right]=\frac{b-R}{2b}\sum_{i=1}^r\sigma_i(M)^2,\\
        &\mathbb{E}_{RSI}\left[\mathcal{L}(\lim_{t\to\infty}X_t)\right]=\frac{a-R}{2a}\sum_{i=1}^r\sigma_i(M)^2,
    \end{align*}
    where $R$ is the rank at the preheating stage while $r$ is the rank at the real optimizing stage. 
\end{theorem}
Proof is included in Appendix \ref{hrp-theory-proof}. 
Theorem \ref{hrp-theory} tells that when target $M$ is also of low rank, HRP makes the expected loss of converged result decrease to the same as Asymmetric LoRA with rank $R$, which could improve a lot from zero+random initialization when high rank $R$ is well-settled. Specifically, when preheating LoRA is a full-rank adapter, HRP achieves the wise initialization suggested in Theorem \ref{asym-wise}. We also note that assuming $W^{\operatorname{target}}-W^{\operatorname{pre}}$ to have a low rank is reasonable in practice. \citet{wang2021pufferfish,wang2023cuttlefish} observe a stabilizing effect in the stable ranks of neural network layers during training, indicating both $W^{\operatorname{pre}}$ and $W^{\operatorname{target}}$ having small stable rank. 


Beyond its convergence advantages, HRP maintains the same number of trainable parameters as low-rank LoRA, thereby preserving the strong generalization properties that mitigate the risk of overfitting. Furthermore, no more trainable parameters also ensure that after a few steps of preheating, HRP requires no additional memory during optimization, retaining the computational benefits that make low-rank LoRA particularly attractive for fine-tuning tasks.









