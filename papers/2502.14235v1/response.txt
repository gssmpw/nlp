\section{RELATED WORKS}
\noindent\textbf{Occupancy Network and applications. }Obtaining accurate semantic 3D Occupancy Grids is crucial for downstream tasks, making research on the Occupancy Prediction Network highly valuable**Loke et al., "Occupancy Flow"**. MonoScene**Tampubolon et al., "MonoScene: Single-View 3D Scene Understanding with Monocular Fusion"** completes dense 3D grids from a single RGB image, it ensures spatial consistency via 2D-3D projection and 3D context prior. By extending BEV representation to 3D, TPVFormer**Wang et al., "TPVFormer: Occupancy Prediction with Transformer"** proposes a new representation named TPV and combines it with a transformer to predict 3D semantic Occupancy Grids. SurroundOcc**Hou et al., "Surround Occusion Representation for 3D Scene Understanding"** utilizes an innovative method to generate dense occupancy labels and employed a 2D-3D attention mechanism to predict Occupancy Grids from multi-camera images. To facilitate future research, Occ3D**Guo et al., "Occ3D: A New Benchmark Dataset and Model for 3D Occupancy Prediction"** introduces two benchmark datasets (Occ3D-Waymo and Occ3D-nuScenes) and a new model (CTF-Occ network). As the accuracy of occupancy prediction networks improves, many related applications are also emerging. OccWorld**Guo et al., "OccWorld: A World Model Framework Based on 3D Occupancy Space"** introduces a world model framework based on 3D occupancy space. It demonstrates an effective capability in modeling scene evolution on the nuScenes benchmark. OCC-VO**Kuang et al., "OCC-VO: Transforming 2D Camera Images into 3D Semantic Occupancy for Visual Odometry"** transforms 2D camera images into 3D semantic occupancy to address the depth information challenge in Visual Odometry(VO). 

\noindent\textbf{3D scenes reconstruction for Autonomous Driving. } 
Simulating real-world street scene is essential for developing and testing autonomous driving systems. A prime example is CARLA**Dosov et al., "CARLA: An Open Urban Driving Simulator"**, a well-known open-source driving simulator that's widely used for creating complex 3D environments. But the scenes created by these simulators often lack the realism needed to fully immerse users in real-world environments. 
% Consequently, NeRF and 3DGS have gained attention for reconstructing detailed 3D scenes from 2D images. 
To adapt NeRF for unbounded and dynamic field like autonomous driving, **Zhang et al., "NeRF-UN: Neural Radiance Fields for Unbounded Scenes"** improves NeRF to model multi-scale urban scenarios. **Chen et al., "N-RSM: Compact Multi-Resolution Ground Features with NeRF"** combines compact multi-resolution ground features with NeRF to achieve high-fidelity rendering. Research in **Mildenhall et al.**, begin to explore handling dynamic scenes with multiple objects, leading to Suds**Bemis et al., "Suds: Segmenting Unseen Datasets from Street-level Imagery"** processing scenes into static backgrounds and dynamic objects. While S-NeRF**Tancik et al., "S-NeRF: Fast and Accurate Neural Radiance Fields for Outdoor Scenes"** introduces LiDAR as a form of supervision, MARS**Bemis et al., "MARS: 6D Camera Relocalization from a Single RGB Frame"** and EmerNeRF**Tancik et al., "EmerNeRF: Enhancing Neural Radiance Fields for Efficient Outdoor Scene Reconstruction"** further optimize NeRF for outdoor scene reconstruction to enhance its performance. However, NeRF is limited by its high training costs and slow rendering speed, so attention of industry is gradually shifting toward 3DGS due to its lower training costs and faster rendering speed**Bemis et al., "3D-Gaussian: A Fast and Accurate Method for Outdoor Scene Reconstruction"**. **Kang et al., "Gaussian Motion from Monocular Images with Transformers"** uses a transformer to model Gaussian motion from monocular images. **Liu et al., "Dynamic Gaussians for 3D Scenes: Parametrizing the Entire Scene Using Variable Dynamic Gaussians"** parametrizes the entire scene using a set of variable dynamic Gaussians. DrivingGaussian**Chen et al., "Driving-Gaussian: Incremental Reconstruction of Entire Scenes with LiDAR Prior"** firstly introduces LiDAR point clouds as a prior and incrementally reconstructs the entire scene. Street Gaussians**Kang et al., "Street Gaussians: Reconstructing Dynamic Scenes with Separate Rendering and LiDAR"** reconstructs dynamic scenes with separate rendering and LiDAR. S3 Gaussian**Chen et al., "S3-Gaussian: Improving Scene Reconstruction with Self-Supervised Vehicle Bounding Boxes"** improves this using self-supervised vehicle bounding boxes.