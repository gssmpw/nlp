\section{Evaluation Framework}
The evaluation framework for LLM-based role-playing agents primarily consists of the following components: the LLM itself (\(\mathcal{M}\)), character profile (\(\mathcal{P}\)), evaluation task (\(\mathcal{T}\)), evaluation metric (\(\mathcal{E}\)), and, when applicable, a reference standard answer (\(\mathcal{A}\)).
In this study, we focus on whether reasoning techniques (\(\mathcal{R}\)) can enhance the role-playing capabilities of LLMs. 
Therefore, the overall evaluation process can be formalized as follows:

Given an LLM \(\mathcal{M}\), a predefined character profile \(\mathcal{P}\), an evaluation task \(\mathcal{T}\), and an evaluation metric \(\mathcal{E}\), the role-playing performance of \(\mathcal{M}\) is assessed by generating responses conditioned on \(\mathcal{P}\) and \(\mathcal{T}\). The generated outputs are then evaluated using \(\mathcal{E}\), which quantifies alignment with the intended role. 
Additionally, reasoning techniques \(\mathcal{R}\) are incorporated into \(\mathcal{M}\) to examine their impact on enhancing role-playing abilities.
Formally, the evaluation process can be expressed as:
$S = \mathcal{E}(\mathcal{M}(\mathcal{P}, \mathcal{T}, \mathcal{R}), \mathcal{A})$
where \( S \) represents the final performance score, capturing the effectiveness of \(\mathcal{M}\) in role-playing under the given conditions. 
A higher \( S \) indicates stronger role-playing capabilities.
If \(\mathcal{A}\) is unavailable or unnecessary, the evaluation metric \(\mathcal{E}\) can be adapted to rely on alternative assessment criteria, such as LLM-as-a-Judge.
