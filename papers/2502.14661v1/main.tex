 % RECOMMENDED %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
 \documentclass[graybox]{svmult}
 \usepackage{type1cm}      
                           
 \usepackage{makeidx}      
 \usepackage{graphicx}     
                           
 \usepackage{multicol}     
 \usepackage[bottom]{footmisc}

\usepackage{comment}
 \usepackage{newtxtext}      
 \usepackage[varvw]{newtxmath}      
 \input{common-macros}


\usepackage{scrextend}



\begin{document}

\title*{Quasi-Monte Carlo for Bayesian Shape Inversion Governed by the Poisson Problem Subject to Gevrey Regular Domain Deformations}
\titlerunning{Quasi-Monte Carlo for Bayesian Shape Inversion}
\author{Ana Djurdjevac, Vesa Kaarnioja, Max Orteu, and Claudia Schillings}
\institute{A.~Djurdjevac $\cdot$ V.~Kaarnioja $\cdot$ M.~Orteu $\cdot$ C.~Schillings\at Department of Mathematics and Computer Science, Free University of Berlin, Arnimallee 6, 14195 Berlin, Germany, {\tt adjurdjevac@zedat.fu-berlin.de, vesa.kaarnioja@fu-berlin.de, m.orteu.capdevila@fu-berlin.de, c.schillings@fu-berlin.de}}


\maketitle



\abstract{We consider the application of a quasi-Monte Carlo cubature rule to Bayesian shape inversion subject to the Poisson equation under Gevrey regular parameterizations of domain uncertainty. We analyze the parametric regularity of the associated posterior distribution and design randomly shifted rank-1 lattice rules which can be shown to achieve dimension-independent, faster-than-Monte Carlo cubature convergence rates for high-dimensional integrals over the posterior distribution. In addition, we consider the effect of dimension truncation and finite element discretization errors for this model. Finally, a series of numerical experiments are presented to validate the theoretical results.}

\keywords{Bayesian inversion, measurement model, random domain, uncertainty quantification, Gevrey regularity, quasi-Monte Carlo method}

\section{Introduction}

Shape recovery problems involve reconstructing the geometry or boundary of an object from indirect or incomplete measurements and they are a significant subset of inverse problems. For instance, in inverse problems governed by  partial differential equations (PDEs), such as those arising in groundwater flow~\cite{darcy} or electrical impedance tomography~\cite{somersalo}, the geometry required for computational inversion is often not perfectly known. In the Bayesian statistical inversion paradigm~\cite{kaipiosomersalo,stuart}, it is possible to model the uncertain geometry as a random field in addition to other unknown model parameters of interest. Based on partial, indirect, and possibly noisy measurements of the state of a PDE system, 
the Bayesian approach enables making inferences about the uncertain geometry.

We shall investigate a setting where the measurement model can be described by the solution $u(\cdot,\omega)\!:D(\omega)\to \mathbb R$ to the Poisson problem
\begin{align}\label{eq:poissonprob}
\begin{cases}
-\Delta u(\bsx,\omega)=f(\bsx)&\text{for}~\bsx\in D(\omega),\\
u(\bsx,\omega)=0&\text{for}~\bsx\in\partial D(\omega)
\end{cases}\quad\text{for $\mathbb P$-a.e.}~\omega\in \Omega,
\end{align}
where $(\Omega,\mathcal A,\mathbb P)$ is a probability space, $f$ is a fixed source term, and the {\textit{domain $D(\omega)\subset\mathbb R^d$, $d\in\{1,2,3\}$, is assumed to be uncertain}}. Analyses on effective approximation of the response statistics of this model problem have been carried out previously in~\cite{canote16,ChDjEl20,djurdjevac24,harbrecht16,xiu06}. 

In this paper, we shall focus on the Bayesian inverse problem of inferring the domain shape based on measurements of certain observable quantities of interest (QoIs) of the Poisson problem~\eqref{eq:poissonprob}. The uncertain domains $D(\omega)$ are modeled as images of a fixed reference domain $D_{\rm ref}\subset\mathbb R^d$ under a mapping $\boldsymbol V(\cdot,\bsy(\omega))\!:\mathbb R^d\to \mathbb R^d$, parameterized by a countable sequence of i.i.d.~random variables $\bsy=\bsy(\omega)$. It is standard practice to treat the random variables $\bsy$ as parameters supported over a sequence space $\varnothing\neq U\subset\mathbb R^{\mathbb N}$ equipped with an appropriate probability measure, a framework that we will also adopt.

The domain mapping $\boldsymbol V$ can be regarded in the Bayesian framework as a pushforward probability measure for the uncertain domain, and in this work, we shall develop a quasi-Monte Carlo (QMC) convergence analysis for a general class of Gevrey regular parameterizations for the domain mapping $\boldsymbol V$ in the inverse setting. The Gevrey class contains smooth, but not necessarily holomorphic, functions with a growth condition on the higher-order partial derivatives, and recently there has been a surge of interest in forward uncertainty quantification for PDEs with parametric inputs belonging to this class~\cite{chernov1,chernov2,gk24gevrey,harbrecht24}. Meanwhile, QMC analysis for Bayesian inference of a Gevrey regular parameterization of an unknown conductivity field has been considered by~\cite{BaKaLa24} within the context of electrical impedance tomography.

A number of shape recovery problems subject to PDEs have been considered in the literature: inverse random acoustic scattering has been studied within the context of multilevel Halton and sparse grid cubatures~\cite{dolz}, the well-posedness of Bayesian shape inversion for time-harmonic Helmholtz transmission and exterior Dirichlet problems has been studied by~\cite{scarabosio24}, and the parametric regularity of the Bayesian posterior for PDEs subject to holomorphic random perturbation fields has been studied by~\cite{gantnerpeters18} within the context of higher-order QMC. Hyv\"onen et al.~\cite{hyvonen17} studied shape recovery for electrical impedance tomography numerically using sparse grids. 

The aim of the present work lies in developing cubature rules with fast rates of convergence for the computation of the posterior mean for Bayesian shape recovery problems in the setting described above. Our main contributions are the following: 
\begin{itemize} 
    \item We consider Bayesian shape inversion subject to Gevrey regular parameterizations of the input random field. Gevrey regular random fields cover a wider range of potential parameterizations for uncertain domains than those previously covered by  holomorphic models of domain uncertainty.
    \item We design dimension-independent randomly shifted rank-1 lattice QMC rules for this model and prove that they exhibit essentially linear cubature convergence rates with respect to the number of cubature points. 
    \item We present a series of high-dimensional numerical experiments which showcase our theoretical convergence results and the quality of the reconstructed features. In particular, we look at the convergence of the root mean square (rms) error and the reconstruction of the expected domain. 
\end{itemize}

This paper is organized as follows. The  notation and function spaces used throughout this work are introduced in Section~\ref{sec:notations}. In Section~\ref{sec: QMC for Bayesian inversion} we present the model problem and associated modeling assumptions, as well as the Bayesian approach to inverse problems and the basic properties of randomly shifted rank-1 lattice rules. Section~\ref{sec:parametricanalysis} contains the main parametric regularity analysis developed for the Bayesian shape inversion problem, followed by our main convergence results. Numerical experiments are presented in Section~\ref{sec:numex} to assess the sharpness of our theoretical results. The paper concludes with a summary of our findings in Section~\ref{sec:conclusions}.

\subsection{Notation}\label{sec:notations}

We will use boldfaced symbols to denote vectors and multi-indices while the subscript notation $\nu_j$ is used to refer to the $j^{\rm th}$ component of $\boldsymbol \nu$. The set of finitely supported multi-indices is denoted by
$\mathscr F:=\{\boldsymbol\nu\in\mathbb N_0^{\mathbb N}:|\bsnu|<\infty\}$, where the {\em modulus} is defined by $|\bsnu|:=\sum_{j\geq 1}\nu_j$.

Let $\bsnu,\boldsymbol m\in\mathscr F$ and let $\bsx:=(x_j)_{j\geq 1}$ be a sequence of real numbers. We define the shorthand notations (with the convention $0^0:=1$):
\begin{align*}
\partial^{\bsnu}:=\partial_{\bsy}^{\bsnu}:=\prod_{j\geq 1}\frac{\partial^{\nu_j}}{\partial y_j^{\nu_j}},\quad \binom{\bsnu}{\boldsymbol m}:=\prod_{j\geq 1}\binom{\nu_j}{m_j},\quad \text{and}\quad \bsx^{\boldsymbol \nu}:=\prod_{j\geq 1}x_j^{\nu_j}.
\end{align*}

For   a nonempty Lipschitz domain $D\subset\mathbb R^d$, $d\in\{1,2,3\}$, we denote by $H_0^1(D)$ the subspace of $H^1(D)$ with zero trace on $\partial D$, equipped with the norm $\|v\|_{H_0^1(D)}:=\|\nabla v\|_{L^2(D)}$. Moreover, we define 
$$
\|v\|_{L^\infty(D)}:={\rm ess\,sup}_{\bsx\in D}\|v(\bsx)\|,
$$
where $\|v\|$ is the absolute value if $v: D \to \mathbb{R}$, the Euclidean norm for vectors if $v: D \to \mathbb{R}^d$, and the spectral norm for matrices if $v: D \to \mathbb{R}^{d\times d}$ and
$$
\|v\|_{W^{1,\infty}(D)}:= \max\big\{{\rm ess\,sup}_{\bsx\in D}\|v(\bsx)\|,{\rm ess\,sup}_{\bsx\in D}\|\nabla v(\bsx)\|\big\},
$$
where $\nabla v$ is the gradient if $v$ is scalar-valued and the Jacobian matrix if $v$ is vector-valued. Finally, we also define the norm
$$
\|v\|_{\mathcal C^k(\overline{D})}:=\max_{|\bsnu|\leq k}\sup_{\bsx\in \overline{D}}|\partial_{\bsx}^{\bsnu}v(\bsx)|\quad\text{for}~v\in \mathcal C^k(\overline{D}).
$$

When working with spaces of parameters and their truncated counterparts, we in general write, e.g., $\bsy \in [-1/2, 1/2]^{\mathbb{N}}$ or $\bsy \in [-1/2, 1/2]^{s}$, for some $s \in \mathbb{N}$. Wherever this might lead to confusion, we use the subindex $\bsy_s$ for the truncated case. 

\section{Quasi-Monte Carlo Methods for Bayesian Shape Inversion Problems}
\label{sec: QMC for Bayesian inversion}

In this section, we present the model problem and its variational formulation, and introduce the associated Bayesian inverse problem. Finally, we outline rank-1 QMC methods for the problem.

\subsection{Model Problem}\label{subsec:model} 


Let $D_{\rm ref}\subset\mathbb R^d$, $d\in\{1,2,3\}$, denote a fixed, nonempty, and bounded Lipschitz domain and let $U:=[-1/2,1/2]^{\mathbb N}$ be a set of parameters, which will later be truncated to some stochastic dimension $s$. We denote by $\boldsymbol V(\cdot,\bsy)\!:\overline{D_{\rm ref}}\to\mathbb R^d$ a domain mapping for $\bsy\in U$. Furthermore, we denote the Jacobian matrix of $\boldsymbol V(\bsx,\bsy)$ with respect to $\bsx\in D_{\rm ref}$ by $J(\cdot,\bsy)\!:D_{\rm ref}\to\mathbb R^{d\times d}$ for $\bsy\in U$. The family of {\em admissible domains} $\{D(\bsy)\}_{\bsy\in U}$ is defined by setting
$$
D(\bsy):=\boldsymbol V(D_{\rm ref},\bsy),\quad \bsy\in U,
$$
and the {\em hold-all domain} $\mathscr D$ is defined as
$$
\mathscr D:=\bigcup_{\bsy\in U}D(\bsy).
$$

\smallskip

\noindent \textbf{Assumptions on transformation $\bsV$ and source term $f$}
\begin{addmargin}[1.3em]{0em}
\begin{enumerate}
\item[(A1)] For each $\bsy\in U$, $\boldsymbol V(\cdot,\bsy)\!:\overline{D_{\rm ref}}\to\mathbb R^d$ is an invertible and continuously differentiable vector field.\label{a1}
\item[(A2)] Let $C_0>0$ be such that\label{a2}
$$
\|\boldsymbol V(\cdot,\bsy)\|_{\mathcal C^1(\overline{D_{\rm ref}})}\leq C_0\quad \text{and}\quad \|\boldsymbol V^{-1}(\cdot,\bsy)\|_{\mathcal C^1(\overline{D(\bsy)})}\leq C_0\quad\text{for all}~\bsy\in U.
$$
\item[(A3)] There exist constants $0<\sigma_{\min}\leq 1\leq \sigma_{\max}<\infty$ such that\label{a3}
$$
\sigma_{\min}\leq \min\sigma(J(\bsx,\bsy))\leq \max \sigma(J(\bsx,\bsy))\leq \sigma_{\max}
~\text{ for all}~\bsx\in D_{\rm ref}~\text{and}~\bsy\in U,$$
where $\sigma(J(\bsx,\bsy))$ denotes the set of all singular values of matrix $J(\bsx,\bsy)$.
\item[(A4)] Gevrey regularity: there exist constants $C,\beta\geq 1$ and a sequence of nonnegative numbers $\boldsymbol b=(b_j)_{j\geq 1}$ such that\label{a4}
$$
\|\partial_\bsy^{\bsnu}\boldsymbol V(\cdot,\bsy)\|_{W^{1,\infty}(D_{\rm ref})}\leq C(|\bsnu|!)^{\beta}\boldsymbol b^{\bsnu}\quad\text{for all}~\bsnu\in\mathscr F~\text{and}~\bsy\in U.
$$
\item[(A5)] There exist constants $C,\beta\geq 1$ and a sequence of nonnegative numbers $\boldsymbol \rho=(\rho_j)_{j=1}^d \in \mathbb{R}_{\geq 0}^d$ such that\label{a5}
$$
\|\partial_{\bsx}^{\bsnu} f\|_{L^\infty(\mathscr D)}\leq C(|\bsnu|!)^{\beta}\boldsymbol \rho^{\bsnu}\quad\text{for all}~\bsnu\in\mathscr F.
$$
\end{enumerate}
\end{addmargin}

{\em Remark.} Without loss of generality, we may assume that the constants $C$ and $\beta$ in Assumptions (A4) and (A5) coincide.

The parametric weak formulation of~\eqref{eq:poissonprob} can be stated as: for each $\bsy\in U$, find $u(\cdot,\bsy)\in H_0^1(D(\bsy))$ such that
\begin{align}
\int_{D(\bsy)}\nabla u(\bsx,\bsy)\cdot \nabla v(\bsx)\,{\rm d}\bsy=\int_{D(\bsy)}f(\bsx)v(\bsx)\,{\rm d}\bsx\quad\text{for all}~v\in H_0^1(D(\bsy)).\label{eq:nonpullback}
\end{align}
However, for the purposes of analysis, it is convenient to consider the pullback of the solution to~\eqref{eq:nonpullback} on the reference domain $D_{\rm ref}$ (cf. \cite{harbrecht16}). We note that the pullback solution $\widehat u(\cdot,\bsy)\in H_0^1(D_{\rm ref})$ is related to $u(\cdot,\bsy)$ via
$$
\widehat u(\cdot,\bsy)=u(\boldsymbol V(\cdot,\bsy),\bsy)\quad\text{for all}~\bsy\in U,
$$
and in fact, the pullback solution can be identified as the solution to the following parametric weak formulation: for each $\bsy\in U$, find $\widehat u(\cdot,\bsy)\in H_0^1(D_{\rm ref})$ such that
$$
\int_{D_{\rm ref}}(A(\bsx,\bsy)\nabla \widehat u(\bsx,\bsy))\cdot \nabla \widehat v(\bsx)\,{\rm d}\bsx=\int_{D_{\rm ref}}f_{\rm ref}(\bsx,\bsy)\widehat v(\bsx)\,{\rm d}\bsx\quad\text{for all}~\widehat v\in H_0^1(D_{\rm ref}),
$$
where we define
$$
A(\bsx,\bsy):=(J(\bsx,\bsy)^{\rm T}J(\bsx,\bsy))^{-1}\det J(\bsx,\bsy)\quad\text{for all}~\bsx\in D_{\rm ref}~\text{and}~\bsy\in U
$$
and
$$
f_{\rm ref}(\bsx,\bsy):=f(\boldsymbol V(\bsx,\bsy))\det J(\bsx,\bsy)\quad\text{for all}~\bsx\in D_{\rm ref}~\text{and}~\bsy\in U.
$$

We shall also be interested in the dimensionally-truncated PDE solution $\widehat u_s(\cdot,\bsy)$ for $\bsy\in [-1/2,1/2]^s=:U_s$ corresponding to a finite-dimensional perturbation field $\boldsymbol V_s\!:U_s\times \overline{D_{\rm ref}}\to \mathbb R^d$, which we define as
$$
\boldsymbol V_s(\cdot,\bsy)=\boldsymbol V(\cdot,(y_1,\ldots,y_s,0,0,\ldots)).
$$

\subsection{Bayesian Inverse Problem}
\label{subsec: Bayes}
We use the Bayesian statistical inversion paradigm to infer the realization of the uncertain domain based on measurements of the PDE forward model. Specifically, we assume that the unknown parameter $\bsy\in U_s$ has a uniform prior distribution $\mathcal U([-1/2,1/2]^s)$. We denote by $u_s$ the solution to the $s$-dimensional truncated problem  and in the following assume that $\cup_{\bsy \in U_s} D(\bsy) \subset \mathscr D$ also for all $s \in \mathbb{N}$. We note that this is not a restriction since alternatively one can define $\mathscr D^+ := \mathscr D \cup (\cup_{s \in \mathbb{N}} \cup_{\bsy \in U_s} D(\bsy)) $ and argue in $\mathscr D^+$. 

We consider the mathematical measurement model
\begin{equation}\label{delta}
    \boldsymbol\delta=\mathcal G(\bsy)+\boldsymbol\eta,
\end{equation}
where $\boldsymbol\delta\in\mathbb R^k$ are the measurements, $\boldsymbol\eta\sim\mathcal N(0,\Gamma)$ is $k$-dimensional additive Gaussian noise with symmetric and positive definite covariance matrix $\Gamma\in\mathbb R^{k\times k}$, $\boldsymbol\eta$ is assumed to be independent of the process generating the observations, and $\mathcal G\!:U_s\to\mathbb R^k$ is the \emph{parameter-to-observation map}. We will consider the following particular form of observations that depends on fixed reference points and is given by
\begin{equation}\label{observationOperator}
    \mathcal G(\bsy):={\mathcal{O}}(u_s(\cdot,\bsy), \bsy),\quad \bsy\in U_s,
\end{equation}
where
$\mathcal O\!:H_0^1(\mathscr D)\times U_s\to\mathbb R^k$ is the observation operator applied to the solution $u_s$ evaluated at $\boldsymbol V_s(\bsx_0, \bsy), \dots, \boldsymbol V_s(\bsx_{k-1}, \bsy)$, where the $\bsx_i \in D_{\rm ref}$, $i = 0, \dots, k-1$, are given fixed points. 

Bayes' formula can be used to express the posterior probability density function of the unknown parameter $\bsy$ conditioned on the measurements $\boldsymbol\delta$ as
$$
\pi(\bsy|\boldsymbol\delta)=\frac{\pi(\boldsymbol\delta|\bsy)\pi(\bsy)}{Z(\boldsymbol\delta)},\quad\bsy\in U_s,
$$
where $\pi(\bsy):=\mathbf 1_{U_s}(\bsy)$ for $\bsy\in U_s$ is the prior density, 
$$
\pi(\boldsymbol\delta|\bsy):=\exp\bigg(-\frac12 \|\boldsymbol\delta-\mathcal G(\bsy)\|_{\Gamma^{-1}}^2\bigg)
$$
is the likelihood, and
$$
Z_s(\boldsymbol\delta):=\int_{U_s}\pi(\boldsymbol\delta|\bsy)\,{\rm d}\bsy
$$
is the normalizing constant. For the reconstruction of the unknown domain, we consider the Bayesian estimator of the expected value of the posterior distribution of $\bsV_s$ given data $\bsdelta$, which we denote by $\mathbb{E}_s^{\bsdelta}[\bsV_s](\bsx)$. It can be expressed as
$$
\mathbb{E}_s^{\bsdelta}[\bsV_s](\bsx):=\mathbb E_s[\boldsymbol V_s(\bsx,\cdot)|\boldsymbol\delta]=\frac{Z_s'(\boldsymbol\delta)}{Z_s(\boldsymbol\delta)},
$$
where $\bsx \in D_{\rm ref}$ and
$$
Z_s'(\boldsymbol\delta):=\int_{U_s} \boldsymbol V_s(\bsx,\bsy)\pi(\boldsymbol\delta|\bsy)\,{\rm d}\bsy.
$$

We also identify $$\mathbb E^{\boldsymbol\delta}[\boldsymbol V](\bsx):=\frac{Z'(\boldsymbol\delta)}{Z(\boldsymbol \delta)},$$ where
$$
Z(\boldsymbol\delta):=\int_U \exp\bigg(-\frac12 \|\boldsymbol\delta-\mathcal G(\bsy)\|_{\Gamma^{-1}}^2\bigg)\,{\rm d}\bsy
$$
and
$$
Z'(\boldsymbol\delta):=\int_U \boldsymbol V(\bsx,\bsy)\exp\bigg(-\frac12 \|\boldsymbol\delta-\mathcal G(\bsy)\|_{\Gamma^{-1}}^2\bigg)\,{\rm d}\bsy.
$$

Both $Z_s'$ and $Z_s$ are high-dimensional integrals, which we want to approximate using a rank-1 QMC cubature rule. In order to find the appropriate weights that guarantee a dimension-independent error in this case, we will need to study the regularity of our QoI, i.e., the expected domain $\mathbb{E}^{\bsdelta}[\bsV_s](D_{\rm ref})$, with respect to the stochastic parameters. This is addressed later in Section \ref{subsec:QMC error}.


\subsection{Quasi-Monte Carlo Methods}\label{subsec:qmc}
Let $F\!:U_s\to\mathbb R$ be a continuous function. In what follows, we will consider numerical approximations of $s$-dimensional integrals
$$
I(F):=\int_{U_s}F(\bsy)\,{\rm d}\bsy.
$$

The randomly shifted rank-1 QMC estimator of $I(F)$ is defined by (cf. \cite{actanumer})
$$
Q_{n, s}(F):=\frac{1}{nR}\sum_{r=1}^R \sum_{\ell=1}^n F(\{\bst_\ell+\boldsymbol\Delta^{(r)}\}-\tfrac{\mathbf 1}{\mathbf 2}),
$$
where $\boldsymbol\Delta^{(1)},\ldots,\boldsymbol\Delta^{(R)}$ are i.i.d.~random shifts drawn from $\mathcal U([0,1]^s)$ and the cubature nodes are defined by
$$
\bst_\ell:=\bigg\{\frac{\ell\boldsymbol z}{n}\bigg\},\quad \ell\in\{1,\ldots,n\},
$$
where $\{\cdot\}$ denotes the component-wise fractional part and $\boldsymbol z\in\{1,\ldots,n-1\}^s$ is the {\em generating vector}.


In order to obtain the quadrature error, we will assume that 
the integrand $F$ belongs to a weighted Sobolev space of dominating first order mixed smoothness $\mathcal W_{s,\boldsymbol\gamma}$ (cf. \cite{kuonuyenssurvey}) endowed with the norm
$$
\|F\|_{s,\bsgamma}:=\bigg(\sum_{\setu\subseteq\{1,\ldots,s\}}\frac{1}{\gamma_{\setu}}\int_{U_{|\setu|}}\bigg(\int_{U_{s-|\setu|}}\frac{\partial^{|\setu|}}{\partial\bsy_{\setu}}F(\bsy)\,{\rm d}\bsy_{-\setu}\bigg)^2\,{\rm d}\bsy_{\setu}\bigg)^{1/2},
$$
where $\boldsymbol\gamma=(\gamma_{\setu})_{\setu\subseteq\{1,\ldots,s\}}$ is a sequence of positive weights, ${\rm d}\bsy_{\setu}:=\prod_{j\in\setu}{\rm d}y_j$ and ${\rm d}\bsy_{-\setu}:=\prod_{j\in\{1,\ldots,s\}\setminus\setu}{\rm d}y_j$.


The following result states that it is possible to construct generating vectors using a \emph{component-by-component (CBC)} algorithm~\cite{cbc1,actanumer,cbc2} satisfying rigorous error bounds.
\begin{theorem}[{cf.~\cite[Theorem~5.1]{kuonuyenssurvey}}]
Let $F \in \mathcal W_{s,\bsgamma}$ with weights $\bsgamma=(\gamma_{\setu})_{\setu\subseteq\{1,\ldots,s\}}$. For a prime number $n$, a randomly shifted lattice rule with $n$ points in $s$ dimensions can be constructed by a CBC algorithm such that for $R$ independent random shifts and for all $\lambda\in(1/2,1]$, there holds
$$
\sqrt{\mathbb E_{\boldsymbol\Delta}|I(F)-Q_{n, s}(F)|^2}\leq \frac{1}{\sqrt R}\bigg(\frac{1}{n-1}\sum_{\varnothing\neq\setu\subseteq\{1,\ldots,s\}}\gamma_{\setu}^{\lambda}\bigg(\frac{2\zeta(2\lambda)}{(2\pi^2)^\lambda}\bigg)^{|\setu|}\bigg)^{1/(2\lambda)}\|F\|_{s,\bsgamma},
$$
where the left-hand side is the rms error, $\mathbb E_{\boldsymbol\Delta}$ denotes the expected value with respect to the uniformly distributed random shifts over $[0,1]^s$ and $\zeta(x):=\sum_{k=1}^\infty k^{-x}$ is the Riemann zeta function for $x>1$.
\end{theorem}

\section{Regularity and Error Analysis}\label{sec:parametricanalysis}

In this section we  analyze the total  error incurred in the numerical approximation of the 
expected domain given as the inverse problem through the Poisson equation. For the spatial discretization we will use finite element method (FEM) and denote by $u_{s,h}$ the corresponding spatial approximation of the $s$-dimensional truncated problem. Given data $\bsdelta$, we write $\mathbb{E}_{s}^{\bsdelta}[\bsV_s](\bsx)$ for the posterior expectation of our QoI in the dimensionally-truncated problem, $\mathbb{E}_{s,h}^{\bsdelta}[\bsV_s](\bsx)$ for the posterior expectation of the dimensionally-truncated and discretized problem, and $\mathbb{E}_{s,h,n}^{\bsdelta}[\bsV_s](\bsx)$ 
for the QMC approximation of our QoI for the dimensionally-truncated and discretized problem. Similarly, we write $Z_s'(\bsdelta)$, $Z_{s,h}'(\bsdelta)$, and $Z_{s,h,n}'(\bsdelta)$. The total error $ \| \mathbb{E}^{\bsdelta}[\bsV](\bsx) - \mathbb{E}_{s,h,n}^{\bsdelta}[\bsV_s](\bsx) \|_{L^2(D_{\rm ref})}$ can then be decomposed into first terms  
\begin{align*}
\| \mathbb{E}^{\bsdelta}[\bsV](\bsx) - \mathbb{E}_{s,h,n}^{\bsdelta}[\bsV_s](\bsx) \|_{L^2(D_{\rm ref})} &\leq
{\| \mathbb{E}^{\bsdelta}[\bsV](\bsx) - \mathbb{E}_{s}^{\bsdelta}[\bsV_s](\bsx)\|_{L^2(D_{\rm ref})}}
\\
&\quad +{\| \mathbb{E}_{s}^{\bsdelta}[\bsV_s](\bsx) -\mathbb{E}_{s,h}^{\bsdelta}[\bsV_s](\bsx)\|_{L^2(D_{\rm ref})}}
\\
&\quad +{\| \mathbb{E}_{s,h}^{\bsdelta}[\bsV_s](\bsx) -\mathbb{E}_{s,h,n}^{\bsdelta}[\bsV_s](\bsx) \|_{L^2(D_{\rm ref})}},
\end{align*}
where the first term is the dimension truncation error, the second one is the FEM error, and the last one is the QMC cubature error. We will bound each of these terms separately. 


\subsection{Regularity of the Forward Problem}

Our starting point is the following result from \cite{djurdjevac24}, which guarantees the Gevrey regularity with respect to the parameter $\bsy$ of the pullback solution in the reference domain and that we will later need for the truncation and QMC  error analysis.

\begin{theorem}[cf.~{\cite{djurdjevac24}}]  Let assumptions {\rm (A1)--(A5)} hold. Then, for all $\bsnu\in\mathscr F$ and $\bsy\in U$, there holds\label{thm: forward regularity}
$$
\| \partial_{\boldsymbol{y}}^{\boldsymbol{\nu}} \widehat{u}(\cdot,\boldsymbol{y}) \|_{H_0^1(D_{\rm{ref}})} \leq c_1 \mathop{c_2^{|\boldsymbol{\nu}|}}(\mathop{|\boldsymbol{\nu}|!})^\beta\boldsymbol{b}^{\boldsymbol{\nu}}
$$
with
\begin{equation*}
    c_1 = 1 + \left(\frac{\sigma_{\max}}{\sigma_{\min}}\right)^d \frac{\sigma_{\max}^2 C_{D_{\rm ref}}|D_{\rm ref}|^{1/2}C}{2^\beta},
\end{equation*}
\begin{equation*}
    c_2 = \max \{\tilde{c}_1, \tilde{c}_2, \tilde{c}_3, \tilde{c}_4 \}^2 ((d^2)!)^\beta 2^{\beta(d^2+1)+1},
\end{equation*}
where 
$$
\tilde{c}_1 = \left(\frac{\sigma_{\max}}{\sigma_{\min}}\right)^d \frac{1}{\sigma_{\min}^2 ((d^2)!)^\beta}, \quad \tilde{c}_2 = 2\left(\frac{2^{\beta}C}{\sigma_{\min}}\right)^3,
$$
$$
\tilde{c}_3 = \frac{c_1 - 1}{\sigma_{\max}^{2} ((d^2)!)^\beta}, \quad \tilde{c}_4 =  \frac{(2^{\beta}C)^2}{\sigma_{\min}}\max\{1, \| \bsrho \|_{\ell^{1/\beta}}\},
$$
and $C_{D_{\rm{ref}}}$ is the Poincar\'e constant of $D_{\rm{ref}}$ while $|D_{\rm ref}|=\int_{D_{\rm ref}}{\rm d}\bsx$.
\end{theorem}

In applications, one does not typically observe the solution in the reference domain, but rather in a realization $D(\bsy)$. This motivates the study of observation operators considered in the sampled domain or depending on the solution $u$ in $D(\bsy)$. However, 
the pushforward solution $u$ does not directly inherit the regularity with respect to $\bsy$ from the pull-backed solution $\widehat{u}$, due to the spatial derivative of $\widehat{u}$ that appears from the chain rule.

For this reason, we use the specific form \eqref{observationOperator} of the observation operator.

\subsection{Truncation and Finite Element Error}

As already mentioned,  it is often necessary to truncate the perturbation field $\bsV$ to some stochastic dimension $s$. Hence, instead of the solution $u$ we consider the solution $u_s$ to the dimensionally-truncated problem. Further, in general the solution to the dimensionally-truncated problem cannot be calculated analytically and it is instead necessary to approximate it with a discretized solution. In this section, we study the error induced by the dimension truncation and discretization errors for an arbitrary QoI.

We now consider the space of domains in $\mathscr D$ with the Hausdorff distance $d_H$, which makes $(\mathscr D, d_H)$ a metric space. We then define the map $S: \mathscr D \to H_0^1(\mathscr D)$ that maps a domain $D(\bsy)$ from $\mathscr D$  to the solution $u$ of the variational Poisson problem \eqref{eq:nonpullback} in $D(\bsy)$. In what follows, we identify the solutions $u_s \in H_0^1(D(\bsy))$ with their zero extension in $H_0^1(\mathscr D)$.

\begin{lemma}
    \label{lemma: continuity forward operator}
    Let $f \in L^2(\mathscr D)$ and $D_{\rm{ref}} \subset \mathbb{R}^d$ be a bounded reference domain. Then, the map $S: \mathscr D \to H_0^1(\mathscr D)$ is continuous.
\end{lemma}

\begin{proof}
    Since the result depends only on the distance of the domains and not on the perturbation field generating them, we do not specify whether $\bsy \in U$ or $\bsy \in U_s$ for some $s \in \mathbb{N}$. For the same reason, we also do not specify whether a solution $u$ solves \eqref{eq:nonpullback} or its truncated version.
    
    Given a domain realization $\bsV(D_{\rm{ref}}, \bsy) = D(\bsy)$, we want to prove that for any sequence $(D_n(\bsy))_n \to D(\bsy)$, $(D_n(\bsy))_n \subset \mathscr D$ $\forall n \in \mathbb{N}$, we have $u_{n} \to u$ in $H_0^1(\mathscr D)$, where $u_{n}$ is the solution of the Poisson problem in $D_n(\bsy)$. 

    Without loss of generality, we consider a sequence $D_n(\bsy) \nearrow D(\bsy)$, with $d_{H}(D_n(\bsy), D(\bsy)) < 1/n$, and define $z_n = u - u_{n} \in H_0^1(\mathscr D)$ and $\tilde{f} = f\cdot\mathbf{1}|_{D(\bsy)\backslash D_n(\bsy)}$. Our goal is then to prove $z_n \to 0$. By definition, $z_n$ satisfies
    \begin{align}   
        \begin{split}
        \label{eq:solution-difference}
        - \Delta z_n = \tilde{f}, \hspace{1.5em} &\text{in } D(\bsy), \\
        z_n = 0, \hspace{1.5em} &\text{on } \partial D(\bsy),
        \end{split}
    \end{align}
    and in particular, there holds $\Delta z_n = 0$ in $D_n(\bsy)$.

    Consider now $\mu_\epsilon * z_n =: z_{n}^\epsilon \in C^\infty(\mathscr D)$. By the continuity of $z_{n}^\epsilon$ and the homogeneous boundary condition, we have that $z_{n}^\epsilon|_{\partial D_n(\bsy)} \xrightarrow[]{n \to \infty} 0$. Further, since $z_{n}^\epsilon$ is harmonic in $D_n(\bsy)$, it satisfies the maximum principle, so
    $$
        z_{n}^\epsilon|_{D(\bsy)} \xrightarrow[]{n \to \infty} 0,
    $$
    and by the convergence properties of mollifiers (cf. \cite{GiTr2001}), we have
    $$
        z_{n}^\epsilon \xrightarrow[]{\epsilon \to \infty} z_{n} \xrightarrow[]{n \to \infty} 0 \text{ in } L^2(\mathscr D).
    $$

    On the other hand, $z_n$ is a weak solution of \eqref{eq:solution-difference} if and only if
    $$
        \int_{D(\bsy)} \nabla z_n\cdot \nabla v \,{\rm d}\bsx= \int_{D(\bsy)} \tilde{f} v\,{\rm d}\bsx
    $$
    for all $v \in H_0^1(\mathscr D)$. In particular, choose $v = z_n$, and then there holds
    $$
        \int_{D(\bsy)} |\nabla z_n|^2 {\rm d}\bsx = \left| \int_{D(\bsy)} \tilde{f} z_n {\rm d}\bsx \right|  \leq || \tilde{f} ||_{L^2(D(\bsy))} || z_n ||_{L^2(D(\bsy))} \to 0,
    $$
    since both $\tilde{f}, z_n \to 0$ in $L^2(D(\bsy))$. Hence, we conclude that $||z_n||_{H_0^1(\mathscr D)} \xrightarrow[]{n \to \infty} 0$.
\end{proof}

In order to obtain convergence rates for the dimension truncation error, we will need additional natural assumptions on the truncated perturbation field. 

\bigskip

\noindent\begin{minipage}{\textwidth} \textbf{Further assumptions on the perturbation field $\bsV$}

\begin{addmargin}[1.3em]{0em}
\begin{enumerate}
    \item[(A6)] \label{a6} For all $\bsy \in U$, $\bsy_s \in U_s$, such that $\bsy|_{U_s} = \bsy_s$ there holds that
    \begin{equation*}
        \lim_{s \to \infty}\| \bsV_s(\bsx, \bsy_s) - \bsV(\bsx, \bsy) \|_{C^1(\overline{D(\bsy)})} \to 0.
    \end{equation*}
    \item[(A7)] There exists $p\in(0,1)$, such that  $\bsb$ in (A4) satisfies $\boldsymbol b\in\ell^p(\mathbb N)$ and $b_1\geq b_2\geq \dots \geq 0$.\label{a7}
\end{enumerate}
\end{addmargin}\end{minipage}

\begin{theorem}
    \label{thm: dimension-truncation}
    Suppose that assumptions {\rm (A1)--(A7)} hold. 
    Then
    $$
        \Bigg\| \int_{U} \widehat u(\cdot, \boldsymbol{y})\,{\rm d}\boldsymbol{y} - \int_{U_s} \widehat u_s(\cdot, \bsy)\,{\rm d}\bsy \Bigg\|_{H_0^1(D_{\rm ref})} \leq C s^{-2/p+1},
    $$
    where the constant $C > 0$ is independent of the dimension $s$. Further, let $\widehat{\mathcal{O}}: H_0^1(D_{\rm ref}) \to \mathbb{R}$ be an arbitrary linear and bounded functional. Then 
    $$
        \Bigg| \int_{U} \widehat{\mathcal{O}}(\widehat u(\boldsymbol{y}))\,{\rm d}\boldsymbol{y} - \int_{U_s} \widehat{\mathcal{O}}(\widehat u_s(\boldsymbol{y}))\,{\rm d}\boldsymbol{y} \Bigg| \leq C \|\widehat{\mathcal{O}}\| s^{-2/p+1},
    $$
    where $\| \widehat{\mathcal{O}} \|$ is the operator norm of $\widehat{\mathcal{O}}$ and the constant $C > 0$ is as above.
\end{theorem}

\begin{proof}
    The proof (see {\cite[Theorem 4.3]{gk22}}) relies on the following condition: for a.e. $\bsy \in U$, $\bsy_s \in U_s$ such that $\bsy|_{U_s} = \bsy_s$ there holds
        \begin{equation}
            \| \widehat u(\cdot, \boldsymbol{y}) - \widehat u_s(\cdot, \bsy_s) \|_{H_0^1(D_{\rm ref})} \to 0 \text{ as } s \to \infty.
            \label{eq:condition-truncation}
        \end{equation}
     
     By (A6), for $s \to \infty$ we have $\bsV_s(D_{\rm ref}, \bsy_s) \to \bsV(D_{\rm ref}, \bsy)$, and by Lemma \ref{lemma: continuity forward operator} and the continuity of $\bsV$, this means that the corresponding solutions $u_s$, $u$ to \eqref{eq:nonpullback} satisfy $\| u(\cdot, \bsy) - u_s(\cdot, \bsy_s) \|_{H_0^1(\mathscr D)} \to 0$. By the identity $\widehat u(\bsx, \bsy) = u(\bsV(\bsx, \bsy), \bsy)$ and assumption (A6), the convergence \eqref{eq:condition-truncation} is satisfied.
\end{proof}

Theorem \ref{thm: dimension-truncation} together with our choice of observation operator yields an error estimate for the term ${\| \mathbb{E}^{\bsdelta}[\bsV](\bsx) - \mathbb{E}_{s}^{\bsdelta}[\bsV_s](\bsx)\|_{L^2(D_{\rm ref})}}$.
 
The following result controls the error when approximating $u_s$ by $u_{s,h}$, where $h$ is the mesh size, using a first-order FEM solver. In order to avoid the reference domain approximation error and to obtain higher regularity of the solution, we assume the additional regularity.

\bigskip

\begin{samepage}\noindent \textbf{Further assumptions on the reference domain $D_{\rm ref}$}
\begin{addmargin}[1.3em]{0em}
\begin{enumerate}
    \item [(A8)] The reference domain $D_{\rm ref}\subset\mathbb R^d$ is a convex and bounded polyhedron. \label{a8}
\end{enumerate}
\end{addmargin}\end{samepage}
\bigskip

With this assumption, by \cite[Theorem 3.2.1.2]{Grisvard} we then have that for all $\bsy \in U_s$ $\widehat u_s(\cdot, \boldsymbol{y}) \in H^2(D_{\rm{ref}}) \cap H_0^1(D_{\rm{ref}})$, and thus $u_s(\cdot, \boldsymbol{y}) \in H^2(D(\bsy)) \cap H_0^1(D(\bsy))$. Hence, we can use the following result from \cite{Qu2014}.

\begin{theorem}
    \label{thm: FEM-L2}
    Let assumptions {\rm (A1)--(A5)} and {\rm (A8)} hold. Further, let $u_s(\cdot, \bsy) \in H_0^1(D(\boldsymbol{y}))$, $\bsy \in U_s$, be the exact solution of the variational problem \eqref{eq:nonpullback} and $u_{s, h}$ its approximate solution obtained with a first-order FEM approximation with mesh size $h$. Moreover, let $u_s(\cdot, \bsy) \in C^0(\overline{D(\boldsymbol{y})}) \cap H^{2}(D(\boldsymbol{y}))$. Then, the following \textit{a priori} error estimate in the norm of $L^2(D(\boldsymbol{y}))$ holds:
    $$
       \| u_s(\cdot, \bsy) - u_{s, h}(\cdot, \bsy) \|_{L^2(D(\boldsymbol{y}))} \leq C h^{2} \| u_s(\cdot, \bsy) \|_{H^{2}(D(\boldsymbol{y}))},
    $$
    with $C = C({\rm diam}(D(\boldsymbol{y})), \hat{K})$ being a constant independent of $h$ and $u$, where $\hat{K}$ is the reference element.
\end{theorem}

\begin{proof}
     See \cite[Theorem 4.7]{Qu2014}, noting that $u_s(\cdot, \bsy) \in C^0(\overline{D(\boldsymbol{y})}) \cap H^{2}(D(\boldsymbol{y}))$, for all $\bsy \in U_s$, since by the Kondrachov theorems one has the compact injection $H^{2}(D(\boldsymbol{y})) \hookrightarrow C^0(\overline{D(\boldsymbol{y})})$ for $d < 4$.
\end{proof}

\subsection{Quasi-Monte Carlo and Total Error}
\label{subsec:QMC error}

The following result states a suitable choice of {\em product and order dependent} (POD) weights ensuring dimension-independent QMC convergence for the approximation of the posterior mean.

\bigskip

\noindent \textbf{Further assumption on the covariance matrix $\Gamma$}

\begin{addmargin}[1.3em]{0em}
\begin{enumerate}
    \item[(A9)] There exists a lower bound $0 < \tau_{\min} \leq 1$ on the smallest eigenvalue of $\Gamma$. \label{a9}
\end{enumerate}
\end{addmargin}

\begin{theorem} \label{thm: inverse exponential}
Let $\bsy \in U$. Under assumptions {\rm (A1)--(A5)}, and {\rm (A9)}
there holds
$$
\big|\partial_{\bsy}^{\bsnu}{\rm e}^{-\frac12 \|\boldsymbol\delta-\mathcal G(\bsy)\|_{\Gamma^{-1}}^2}\big|\leq c_3 c_4^{|\boldsymbol{\nu}|}  \mathop{(|\boldsymbol{\nu}|! )^\beta}\boldsymbol{b}^{\boldsymbol{\nu}},
$$
where
$$
c_3=\frac{1}{2^{\beta}}\cdot 3.47^k,\quad c_4=2^{\beta} c_1 c_2 \tau_{\min}^{-1/2}.
$$
\end{theorem}
\begin{proof} See \cite[Lemma 5.3]{ks24}. \end{proof} 

\begin{theorem}
Let $\bsy \in U$. Under assumptions {\rm (A1)--(A5)} and {\rm (A9)}, we have
$$
\big|\partial_{\bsy}^{\bsnu}\big(\boldsymbol V(\bsx,\bsy){\rm e}^{-\frac12 \|\boldsymbol\delta-\mathcal G(\bsy)\|_{\Gamma^{-1}}^2}\big)\big|\leq c_5c_{6}^{|\bsnu|} (\mathop{\left( |\boldsymbol{\nu}| + 1 \right)!})^\beta \boldsymbol{b}^{\boldsymbol{\nu}},
$$
where $c_5=Cc_3$ and $c_{6}=\max\{1,c_4\}$.
\end{theorem}
\begin{proof} 
Using Theorem \ref{thm: inverse exponential} and the Leibniz product rule there holds
    \begin{align*}
         \Big| \partial_{\bsy}^{\boldsymbol{\nu}} \left(\bsV(\boldsymbol{x},\boldsymbol{y}) e^{-\frac{1}{2}\| \boldsymbol{\delta} - \mathcal{G}(\boldsymbol{y}) \|_{\Gamma^{-1}}^2} \right) \Big|  
        & =  \Big| \sum_{ \boldsymbol{m} \leq \boldsymbol{\nu}} \binom{\boldsymbol{\nu}}{\boldsymbol{m}} \partial^{\boldsymbol{m}} V(\boldsymbol{x},\boldsymbol{y}) \partial^{\boldsymbol{\nu}-\boldsymbol{m}} e^{-\frac{1}{2}\| \boldsymbol{\delta} - \mathcal{G}(\boldsymbol{y}) \|_{\Gamma^{-1}}^2} \Big|
        \\
        & = \sum_{ \boldsymbol{m} \leq \boldsymbol{\nu}} \binom{\boldsymbol{\nu}}{\boldsymbol{m}} C (\mathop{|\boldsymbol{m}|!})^\beta\boldsymbol b^{\boldsymbol m} c_7c_8^{|\bsnu-\boldsymbol m|}((|\bsnu-\boldsymbol m|)!)^\beta \boldsymbol b^{\bsnu-\boldsymbol m}
        \\
        & \leq C c_3 \max\{1,c_4\}^{|\bsnu|}\boldsymbol b^{\bsnu}\sum_{ \boldsymbol{m} \leq \boldsymbol{\nu}} \binom{\boldsymbol{\nu}}{\boldsymbol{m}} (\mathop{|\boldsymbol{m}|!} \mathop{|\boldsymbol{\nu} - \boldsymbol{m}|!})^\beta\\
                & \leq Cc_3 \max\{1,c_4\}^{|\bsnu|}\boldsymbol b^{\bsnu}|\bsnu|!\sum_{\ell=0}^{|\bsnu|} (\mathop{\ell!} (\mathop{|\boldsymbol{\nu}| - \ell)!})^{\beta-1}
        \\
        & \leq Cc_3 \max\{1,c_4\}^{|\bsnu|}\boldsymbol b^{\bsnu}|\bsnu|!(|\bsnu|!)^{\beta-1}\sum_{\ell=0}^{|\bsnu|} 1\\
        & \leq Cc_3\max\{1,c_4\}^{|\bsnu|}\boldsymbol b^{\bsnu} (\mathop{ (|\boldsymbol{\nu}| + 1)!})^\beta,
    \end{align*}
which proves the assertion.
\end{proof}

\begin{theorem} \label{thm: weights}
For $s \in \mathbb{N}$, $n$ a prime number, and weights $\boldsymbol{\gamma} = (\gamma_{\mathfrak{u}})$, a randomly shifted lattice rule with $n$ points in $s$ dimensions can be constructed by a CBC algorithm such that the rms error for approximating the finite dimensional integral $Z_{s,h}'(\bsdelta)$ satisfies, for all $\lambda \in (1/2, 1],$
    \begin{equation*}
        \sqrt{\mathbb{E}_{\boldsymbol{\Delta}}[|Z_{s,h}'(\bsdelta) - Z_{s,h,n}'(\bsdelta)|^2]} \leq \frac{c_5 C_{\boldsymbol{\gamma}}(\lambda)}{(n-1)^{1/(2\lambda)}},
    \end{equation*}
    where $\mathbb{E}_{\boldsymbol{\Delta}}[\cdot]$ denotes the expectation with respect to the random shift which is uniformly distributed over $[0,1]^s$, and
    \begin{equation*}
        C_{\boldsymbol{\gamma}}(\lambda) := \left( \sum_{|{\mathfrak{u}}| < \infty} \gamma_{{\mathfrak{u}}}^\lambda \bigg[\frac{2\zeta(2\lambda)}{(2\pi^2)^\lambda}\bigg]^{|{\mathfrak{u}}|} \right)^{1/(2\lambda)}\left( \sum_{|{\mathfrak{u}}| < \infty} \frac{((|{\mathfrak{u}}|+1)!)^{2\beta} \prod_{j \in {\mathfrak{u}}} b_j^2}{\gamma_{{\mathfrak{u}}}} \right)^{1/2},
    \end{equation*}
    but $C_{\boldsymbol{\gamma}}(\lambda)$ is possibly infinite. Then the choice of weights
\begin{align*}
&\gamma_{\setu}=\bigg(((|\setu|+1)!)^\beta \prod_{j\in\setu}\frac{c_{6}b_j}{\sqrt{2\zeta(2\lambda)/(2\pi^2)^\lambda}}\bigg)^{2/(1+\lambda)},\quad\setu\subseteq\mathbb N,\\
&\lambda=\begin{cases}
\frac{p}{2-p}&\text{if}~p\in(\tfrac23,\tfrac{1}{\beta}),\\
\frac{1}{2-2\alpha}&\text{if}~p\in(0,\min\{\tfrac23,\tfrac{1}{\beta}\}],~p\neq \tfrac{1}{\beta}
\end{cases}
\end{align*}
for arbitrary $\alpha\in (0,1/2)$, minimizes $C_{\boldsymbol{\gamma}}(\lambda)$ and leads to
    $$
        C_{\boldsymbol{\gamma}}(\lambda) < \infty \hspace{1em} \text{ and } \hspace{1em} \sup_{s \geq 1}|| Z_{s,h}'(\bsdelta) ||_{\mathcal{W}_{s,\boldsymbol{\gamma}}} < \infty.
    $$
    However, $C_{\boldsymbol{\gamma}}(\frac{1}{2-2\delta}) \to \infty$ as $\alpha \to 0$, and $C_{\boldsymbol{\gamma}}(\frac{p}{2-p}) \to \infty$ as $p \to (2/3)^+$. In consequence, the error is of order
    $$
        \begin{cases}
            n^{-(1-\alpha)} &\text{ when } p \in (0, 2/3], \\
            n^{-(1/p-1/2)} &\text{ when } p \in (2/3, 1).
        \end{cases}
    $$
\end{theorem}

\begin{proof}
    The proof is carried out in a similar way to \cite[Theorem 6.4]{kss12}.
\end{proof}

Since the bounds on the mixed derivatives of $Z_{s,h}'(\bsdelta$), i.e. the numerator of $\mathbb{E}_{s,h}^{\bsdelta}[\bsV_s](\bsx)$, dominate those of the denominator $Z_{s,h}(\bsdelta)$, this choice of weights guarantees the dimension-independent error bound in both cases. By usual arguments (see for example \cite{BaKaLa24}), this in turn means that the estimation of the ratio satisfies the bound
$$
\big\| \mathbb{E}_{s,h}^{\boldsymbol{\delta}}[\boldsymbol{V}_s] -\mathbb{E}_{s,h,n}^{\boldsymbol{\delta}}[\boldsymbol{V}_s] \big\|_{L^2(D_{\rm ref})} \lesssim n^{\max\{ -1/p + 1/2, -1+\alpha\}}.
$$

\begin{theorem}
    Let assumptions {\rm (A1)--(A9)} hold. With the choice of weights in Theorem \ref{thm: weights}, the total error satisfies the following bound:
    $$
    \big\| \mathbb{E}^{\boldsymbol{\delta}}[\boldsymbol{V}] -\mathbb{E}_{s,h,n}^{\boldsymbol{\delta}}[\boldsymbol{V}_s]\big\|_{L^2(D_{\rm ref})} \lesssim s^{-2/p+1} + h^2 + n^{\max\{ -1/p + 1/2, -1+\alpha\}}.
    $$
\end{theorem}

\begin{proof}
    The assertion follows from Theorems 3, 4, 6, and 7.
\end{proof}

\section{Numerical Experiments}\label{sec:numex}

In this section we present numerical experiments to verify the theoretical convergence rates in the setting presented above. We consider three methods: Monte Carlo (MC), QMC based on a generating vector $\bsz$ constructed with the weights derived in Theorem \ref{thm: weights}, leaving out the constant $c_6$ for numerical stability, and QMC with an off-the-shelf generating vector \cite[\texttt{lattice-32001-1024-1048576.3600}]{Kuo24}. 

We consider examples where $D_{\rm ref} := \{ (x_1,x_2) \in \mathbb{R}^2 : x_1^2 + x_2^2 \leq 1 \}$ is the unit disk, and solve the variational problem \eqref{eq:nonpullback} for $f(x_1, x_2) = 10\sin(x_1 x_2) - 5\cos(x_1+x_2)^2$ and a Gevrey regular (with Gevrey parameter $\beta = 2$) perturbation field $\bsV$ of the form $\boldsymbol{V}(\boldsymbol{x}, \boldsymbol{y}) = a(\boldsymbol{x}, \boldsymbol{y}) \boldsymbol{x}$, where
\begin{equation*}
a((x_1,x_2);\boldsymbol{y}) = 1 + \frac{6}{5} \sum_{j\geq 1} \frac{\cos\left(3 j \arctan2(x_1,x_2) - \pi/2 \right)}{j^{2.1}} \exp\left(-\frac{1}{\frac12 + y_j}\right).
\end{equation*}

As mentioned above, we set for our observation operator, 
$$
\mathcal{O}: H_0^1(\mathscr D) \times U_s \to \mathbb{R}^k, \quad (u,\bsy) \mapsto (u(\bsx_0, \bsy), \dots, u(\bsx_{k-1}, \bsy)),
$$
where we assume that $k$ fixed points are given in $D_{\rm ref}$ (see Figure \ref{fig:point-evaluations} for $k = 5$).

\begin{figure}[!t]
    \centering
    \includegraphics[width=\textwidth]{Images/Points_evaluations.eps}
    \caption{Fixed and transported evaluation points for three realizations, $k=5$.}
    \label{fig:point-evaluations}
        \centering
    \includegraphics[height=0.455\textwidth]{Images/Disk_gamma10_5p_oneline.eps}\includegraphics[height=0.46\textwidth]{Images/Reconstruction_QMC_n128021.eps}
    \caption{Results corresponding to the Bayesian inverse problem ($\eta = 10\% \| \bsdelta \|_{\infty}$, $k=5$). Left: Computed rms errors for the ratio estimator with increasing $n$ for the three methods. Right: The reconstructed domains for MC and QMC with $n=128021$ vis-\`a-vis the ground truth.}
    \label{fig:rms convergence}
\end{figure}

The data $\bsdelta$ given by \eqref{delta} is generated after sampling from a truncated $\bsV$ with a stochastic dimension $s_* = 200$ and discretizing the problem with a mesh size $h_* = 2^{-6}$. We then obtain $(\delta_0, \dots, \delta_{k-1}) = (u_{s_*,h_*}(\bsV_{s_*}(\bsx_0, \bsy)), \dots, u_{s_*,h_*}(\bsV_{s_*}(\bsx_{k-1}, \bsy)))$. Finally, we set the noise level $\eta$ to $10\%$ of the maximum absolute value in $\bsdelta$.

To reconstruct the uncertain domain, we set a stochastic dimension $s = 100$ and discretize the PDE solution with a mesh size $h = 2^{-5}$. To test the convergence of the rms error as predicted in Theorem \ref{thm: weights}, we estimate the rms error using $R=8$ random shifts for prime values of $n$ ranging from $67$ to $128021$. 


The results on the left-hand side of Figure \ref{fig:rms convergence} show the rms error for the approximation $\mathbb{E}_{s,h,n}[\bsV_s]$ with $k = 5$ observation points. We observe a roughly linear convergence rate for the QMC approximation with the weights derived in Theorem \ref{thm: weights}, and hence an almost doubled rate with respect to the MC approach. The QMC approximation with an off-the-shelf generating vector $\bsz$ also performs consistently better than MC, but it exhibits a higher variance.

On the right-hand side of Figure~\ref{fig:rms convergence}, we present reconstructions for the weight-tailored QMC and the MC approximations. Due to the scaling of the parameters, both methods converge to the shown reconstructions already for small values of $n$. Nevertheless, the results indicate the consistency of the QMC approximation.

\section{Conclusions}\label{sec:conclusions}

In this work, we have studied the application of randomly shifted rank-1 lattice rules to Bayesian shape inversion subject to Gevrey regular deformations of a reference domain with the Poisson equation as the forward model. Modeling the uncertain geometry using Gevrey regular perturbation fields covers a wider range of potential parameterizations than those covered by the affine or holomorphic frameworks, while also retaining a nearly optimal QMC convergence rate in the inverse setting as showcased by Theorem \ref{thm: weights} and our numerical experiments. In addition, we showed that this setting leads to the optimal dimension truncation error rate as well as the standard FEM error rate.

The regularity analysis in this paper was presented for the pullback PDE solution. However, in many practical applications, it would be more natural to consider the pushforward PDE solution on the actual realization of the random or uncertain geometry instead. Our choice of the observation operator allows us to perform the experiments on the deformed domains while retaining the parametric regularity of the pullback PDE solution. Extending the regularity analysis for more general observation operators as well as more involved forward models is left for future work.

\section*{Acknowledgements}
Ana Djurdjevac, Max Orteu, and Claudia Schillings acknowledge support from DFG CRC/TRR 388 ``Rough
Analysis, Stochastic Dynamics and Related Fields'', Project B06. The authors would also like to thank the HPC Service of FUB-IT, Freie Universit\"at Berlin, for computing time.

\begin{thebibliography}{99}
\bibitem{BaKaLa24} Bazahica, L., Kaarnioja, V., Roininen, L.: Uncertainty quantification for electrical impedance tomography using quasi-Monte Carlo methods. Preprint, arXiv:2411.11538 [math.NA] (2024)
\bibitem{canote16} Castrill\'on-Cand\'as, J.~E., Nobile, F., Tempone, R.~F.: Analytic regularity and collocation approximation for elliptic PDEs with random domain deformations. \emph{Comput. Math. Appl.} \textbf{71}(6), 1173--1197 (2016)
\bibitem{chernov1} Chernov, A., L{\^{e}}, T.: Analytic and Gevrey class regularity for parametric elliptic eigenvalue problems and applications. {\em SIAM J. Numer. Anal.} \textbf{4}(62), 1874--1900 (2024)
\bibitem{chernov2} Chernov, A., L{\^{e}}, T.: Analytic and Gevrey class regularity for parametric semilinear reaction-diffusion problems and applications in uncertainty quantification. {\em Comput. Math. Appl.} \textbf{164}, 116--130 (2024)
\bibitem{ChDjEl20} Church, L., Djurdjevac, A., Elliott, C.~M.: A domain mapping approach for elliptic equations posed on random bulk and surface domains. \emph{Numer. Math.} \textbf{146}, 1--49 (2020)
\bibitem{cbc1} Cools, R., Kuo, F.~Y., Nuyens, D.: Constructing embedded lattice rules for multivariate integration. {\em SIAM J. Sci. Comput.}~\textbf{28}, 2162--2188 (2006)
\bibitem{actanumer} Dick, J., Kuo, F.~Y., Sloan, I.~H.: High-dimensional integration: the quasi-Monte Carlo way. {\em Acta Numer.}~\textbf{22}, 133--288 (2013)
\bibitem{djurdjevac24} Djurdjevac, A., Kaarnioja, V., Schillings, C., Zepernick, A.: Uncertainty quantification for stationary and time-dependent PDEs subject to Gevrey regular random domain deformations. Preprint, arXiv:2502.12345 [math.NA] (2025)
\bibitem{dolz} D\"olz, J., Harbrecht, H., Jerez-Hanckes, C., Multerer, M.: Isogeometric multilevel quadrature for forward and inverse acoustic scattering. \emph{Comput. Methods Appl. Mech. Eng.} \textbf{388}, 114242 (2022) 
\bibitem{gantnerpeters18} Gantner, R.~N., Peters, M.~D.: Higher-order quasi-Monte Carlo for Bayesian shape inversion. {\em SIAM/ASA J. Uncertain. Quantif.} \textbf{6}(2), 707--736 (2018)
\bibitem{GiTr2001} Gilbarg, D., Trudinger, N.~S.: {\em Elliptic Partial Differential Equations of Second Order}. Springer Berlin, Heidelberg (2001)
\bibitem{Grisvard} Grisvard, P.: {\em Elliptic Problems in Nonsmooth Domains}. Society for Industrial and Applied Mathematics (2011)
\bibitem{gk22} Guth, P.~A., Kaarnioja, V.: Generalized dimension truncation error analysis for high-dimensional numerical integration: lognormal setting and beyond. \emph{SIAM J. Numer. Anal.} \textbf{62}(2), 872--892 (2024)
\bibitem{gk24gevrey} Guth, P.~A., Kaarnioja, V.: Quasi-Monte Carlo for partial differential equations with generalized Gaussian input uncertainty. Preprint, arXiv:2411.03793 [math.NA] (2024)
\bibitem{harbrecht16} Harbrecht, H., Peters, M., Siebenmorgen, M.: Analysis of the domain mapping method for elliptic diffusion problems on random domains. {\em Numer. Math.} \textbf{134}, 823--856 (2016)
\bibitem{harbrecht24} Harbrecht, H., Schmidlin, M., Schwab, Ch.: The Gevrey class implicit mapping theorem with application to UQ of semilinear elliptic PDEs. {\em Math. Models Methods Appl. Sci.} \textbf{34}(5), 881--917 (2024)
\bibitem{hyvonen17} Hyv\"onen, N., Kaarnioja, V., Mustonen, L., Staboulis, S.: Polynomial collocation for handling an inaccurately known measurement configuration in electrical impedance tomography. \emph{SIAM J. Appl. Math.} \textbf{77}, 202--223 (2017)
\bibitem{ks24} Kaarnioja, V., Schillings, C.: Quasi-Monte Carlo for Bayesian design of experiment problems governed by parametric PDEs. Preprint, arXiv:2405.03529 [math.NA] (2024)
\bibitem{kaipiosomersalo} Kaipio, J., Somersalo, E.: {\em Statistical and Computational Inverse Problems}. Springer, New York (2004)
\bibitem{scarabosio24} Kuijpers, S., Scarabosio, L.: Wavenumber-explicit well-posedness of Bayesian shape inversion in acoustic scattering. Preprint, arXiv:2410.23100 [math.AP] (2024)
\bibitem{Kuo24} Kuo. F. Y.: Lattice rule generating vectors.\\
\url{https://web.maths.unsw.edu.au/\textasciitilde fkuo/lattice/}
\bibitem{kuonuyenssurvey} Kuo, F.~Y., Nuyens, D.: Application of quasi-Monte Carlo methods to elliptic PDEs with random diffusion coefficients: a survey of analysis and implementation. \emph{Found. Comput. Math.} \textbf{16}(6), 1631--1696 (2016)
\bibitem{kss12} Kuo, F.~Y., Schwab, Ch., Sloan, I.~H.: Quasi-Monte Carlo finite element methods for a class of elliptic partial differential equations with random coefficients. {\em SIAM J. Numer. Anal.} {\bf 50}(6), 3351--3374 (2012)
\bibitem{cbc2} Nuyens, D., Cools, R.: Fast algorithms for component-by-component construction of rank-1 lattice rules in shift-invariant reproducing kernel Hilbert spaces. {\em Math. Comp.} \textbf{75}, 903--920 (2006)
\bibitem{Qu2014} Quarteroni, A.: {\em Numerical Models for Differential Problems}. Springer Milano (2014)
\bibitem{darcy}Scheichl, R., Stuart, A.~M., Teckentrup, A.~L.: Quasi-Monte Carlo and multilevel Monte Carlo methods for computing posterior expectations in elliptic inverse problems. {\em SIAM/ASA J. Uncertain. Quantif.} \textbf{5}(1), 493--518 (2017)
\bibitem{somersalo} Somersalo, E., Cheney, M., Isaacson, D.: Existence and uniqueness for electrode models for electric current computed tomography. \emph{SIAM J. Appl. Math.} \textbf{52}(4), 1023--1040 (1992)
\bibitem{stuart} Stuart, A.~M.: Inverse problems: a Bayesian perspective. {\em Acta Numer.} \textbf{19}, 451--559 (2010)
\bibitem{xiu06} Xiu, D., Tartakovsky, D.~M.: Numerical methods for differential equations in random domains. \emph{SIAM J. Sci. Comput.} \textbf{28}(3), 1167--1185 (2006)
\end{thebibliography}

\end{document}
