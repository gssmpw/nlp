\section{Related Work}
Misclassification risk and uncertainty quantification for various types of classifiers have been very well studied in the literature **Kumar, "Risk and Uncertainty Quantification"**. In **Liu et al., "Risk-Calibrated Classifiers"**, the authors propose a risk-calibrated classifier to reduce the costs associated with misclassification errors, and empirically show the effectiveness of their algorithm in a deep learning framework. In **Zhang et al., "Cost-Sensitive Learning"**, the authors study cost-sensitive learning for class balancing in order to improve the quality of predictions in decision tree learning methods. In our work, we consider a hypothesis testing (or classification) task in a Bayesian learning framework.

A subset of the literature has addressed the problem of sequential information gathering within a limited budget **Ghasemi et al., "Data Source Selection"**. The authors of  **Liu et al., "Sequential Information Gathering"** study data source selection for a monitoring application, where the sources are selected sequentially in order to estimate certain parameters of an environment. In **Kumar et al., "Sequential Information Gathering"**, the authors study sequential information gathering under a limited budget for a robotic navigation task. In **Zhang et al., "Sequential Sensor Scheduling"**, the authors study sequential sensor scheduling to jointly estimate a process and present a stochastic selection algorithm which is computationally tractable.  In contrast, we consider the scenario where the information set is selected \textit{a priori}, i.e., at \textit{design-time}, and propose an efficient algorithm with guarantees.

A substantial body of work focuses on the study of submodularity (and/or weak submodularity) properties for efficient greedy techniques with provable guarantees for feature selection in sparse learning **Xu et al., "Submodular Optimization"**, sensor selection for estimation  **Zhang et al., "Sensor Selection"** & Kalman filtering **Liu et al., "Kalman Filtering"**, and observation selection for mixed-observable Markov decision processes **Kumar et al., "Observation Selection"**.  Along the lines of these works, we leverage the weak submodularity property of the performance metric and present greedy algorithms with performance guarantees.

Robust sensor selection has been extensively studied in the context of resource-constrained environments where sensors may fail, be removed, or experience adversarial attacks **Kumar et al., "Robust Sensor Selection"**. Early works, such as those by **Liu et al., "Near-Optimal Sensor Placement"**, focused on optimizing submodular objectives to achieve near-optimal sensor placement under budget constraints, ensuring reliable performance despite uncertainty. In the robust setting, adversarial or stochastic failures were explored by **Zhang et al., "Robust Weak-Submodular Optimization"**, where greedy algorithms were developed to guarantee near-optimal performance. The authors of **Xu et al., "Robust Submodular Optimization"** study robust weak-submodular optimization of a set of weak-submodular functions, where the goal is to maximize the utility of the worst-case objective. Along similar lines as these works, we study the robust information selection problem where the objective is not submodular, and present greedy algorithms with near-optimality guarantees. Furthermore, we present a submodular surrogate metric which enjoys improved performance guarantees for greedy approximation.