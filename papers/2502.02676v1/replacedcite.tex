\section{Related Works}
\label{sec:related_works}
In this section, we present research related to inpainting and deep learning-based visible watermark removal (VWR). We also provide key observations from deep learning based VWR.

\textbf{Inpainting.} Inpainting aims to restore missing or corrupted regions in an image. Traditional methods often rely on partial differential equations (PDEs)____ or patch synthesis____ while deep learning approaches____ leverage large datasets to learn complex features, often employing generative adversarial networks (GANs). Recent advancements harness denoising diffusion probabilistic models (DDPMs)____ for inpainting by iteratively refining noisy versions of an image. Methods like Stable Diffusion____ and LaMa____ achieve high-quality results.

\textbf{Deep Learning Watermark Removal Methods.} Recent advancements in VWR have been driven by deep learning-based approaches. In____, the authors introduce a seminal image-to-image translation approach driven by the object detection of watermarks which are then refined using a convolution neural network (CNN). To bypass the reliance on detection-based components, ____ and ____ proposed generative adversarial network (GAN) techniques. In____, the authors introduce a multi-task learning framework utilizing a single encoder with multi-decoder architecture to reconstruct the background, motif (watermark) mask, and motif (watermark) image. ____ introduce a two-stage network for multi-task decoding and then refinement called \textit{SplitNet}. ____ refine mask predictions even further using a coarse-to-fine strategy known as \textit{SLBR}. Instead of estimating only the mask of the watermark, \textit{WDNet}____ attempts to predict the mask, opacity and color of the watermark. \textit{DENet} attempts to disentangle watermark and image embeddings in the feature space, employing contrastive learning to ensure task-specific representation for watermark removal and background reconstruction____. In ____, the authors also implement a two-stage approach consisting of watermark localization and background content restoration, known as \textit{RIRCI}.

\textbf{Key Observations.} \textbf{[1-2]} Most deep learning methods for watermark removal use a mask prediction component to guide background restoration as shown in \figref{fig:restore_ex}. This procedure boosts image quality metrics by enabling a focus on reconstructing or refining the watermarked area. However, the accuracy of the predicted mask is crucial, as it directly impacts the final image composition. Many prior methods focus on improving the reconstructed image while neglecting mask refinement. \figref{fig:mask_ex} illustrates example predicted masks for SLBR, where under-prediction often leaves watermark residuals in the sanitized image. \textbf{[3]} Another key limitation is the reliance on access to watermark-free images during training. Training datasets typically include \textit{watermarked images}, \textit{watermark masks}, and \textit{watermark-free images}____. In real-world scenarios, matching the distribution of watermarked and watermark-free images is highly unlikely. For instance, when watermarked images are scraped from platforms like Shutterstock.com, the true background behind the watermark is unknown. This raises a critical challenge: how can these methods be effectively evaluated when ground truth watermark-free images are unavailable in practice?




% In the majority of the deep learning approaches, there is a mask prediction component which is then used to direct background content restoration. While not explicitly stated in these papers, SplitNet, SLBR, WDNet, and DENet all then use these masks to combine with the original image, as shown in \figref{fig:restore_ex}, where the original image $\inputim$ is combined with the inverse of the provided mask $\inversemask$ for the background and the processed output $\xhat$ is combined with the provided mask $\dilateout$ to retrieve the cleaned watermarked region. The background is then combined with the watermark region to produce the restored image. This procedure helps to boost image quality metrics and allows each respective method to focus on the reconstruction or refinement of the watermarked region. The accuracy of the predicted mask becomes crucial, as it directly influences the refinement of the watermarked area and the final image composition. Interestingly, most prior methods emphasize improving the reconstructed image while underestimating the importance of refining the mask itself. \figref{fig:mask_ex} shows example predicted masks for SLBR. The masks rarely, if ever, over-predict the mask. This means that watermark residuals are often left behind in the sanitized image, as the predicted masks fail to fully encompass the watermark regions. 

% An equally significant observation is that all these methods rely on access to watermark-free images during training. The training datasets typically consist of (1) \textit{watermarked images}, (2) \textit{watermark masks}, and (3) \textit{watermark-free images}____. However, in real-world scenarios, it is highly unlikely to have watermark-free images that match the distribution of watermarked images. For instance, if bad actors scrape watermarked images from platforms like Shutterstock.com, the true background behind the watermark remains unknown. This raises a critical question: how can we effectively evaluate these methods against the watermark-free version when such ground truth is unavailable in practical applications? 

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%    Introduction
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%