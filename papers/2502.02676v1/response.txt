\section{Related Works}
\label{sec:related_works}
In this section, we present research related to inpainting and deep learning-based visible watermark removal (VWR). We also provide key observations from deep learning based VWR.

\textbf{Inpainting.} Inpainting aims to restore missing or corrupted regions in an image. Traditional methods often rely on partial differential equations (PDEs) **Li, "Image Inpainting Using PDE-Based Methods"** or patch synthesis **Bertalm√≠o et al., "Navier-Stokes Fluid Image Filtering"** while deep learning approaches **Yeh et al., "Deep Image Reconstruction from Multiple Frames"** leverage large datasets to learn complex features, often employing generative adversarial networks (GANs). Recent advancements harness denoising diffusion probabilistic models (DDPMs) **Ho et al., "Denoising Diffusion Probabilistic Models"** for inpainting by iteratively refining noisy versions of an image. Methods like Stable Diffusion **Rombach et al., "DALL-E 2: Transforming Data with AI"** and LaMa **Yu et al., "LaMa: A Large Mask Inpainting Model"** achieve high-quality results.

\textbf{Deep Learning Watermark Removal Methods.} Recent advancements in VWR have been driven by deep learning-based approaches. In **Kim et al., "Watermark Removal Using Image-to-Image Translation"**, the authors introduce a seminal image-to-image translation approach driven by the object detection of watermarks which are then refined using a convolution neural network (CNN). To bypass the reliance on detection-based components, **Zhou et al., "Generative Adversarial Networks for Watermark Removal"** and **Wang et al., "Deep Learning Based Visible Watermark Removal"** proposed generative adversarial network (GAN) techniques. In **Li et al., "Multi-Task Learning Framework for Visible Watermark Removal"**, the authors introduce a multi-task learning framework utilizing a single encoder with multi-decoder architecture to reconstruct the background, motif (watermark) mask, and motif (watermark) image. **Zhang et al., "SplitNet: A Two-Stage Network for Multi-Task Decoding and Refinement"** refine mask predictions even further using a coarse-to-fine strategy known as \textit{SLBR}. Instead of estimating only the mask of the watermark, \textit{WDNet} **Wang et al., "Watermark Detection and Removal Using Deep Learning"** attempts to predict the mask, opacity and color of the watermark. \textit{DENet} **Zhou et al., "Disentangling Watermark and Image Embeddings for Visible Watermark Removal"** attempts to disentangle watermark and image embeddings in the feature space, employing contrastive learning to ensure task-specific representation for watermark removal and background reconstruction**Kim et al., "Contrastive Learning for Visible Watermark Removal"**. In **Li et al., "A Two-Stage Approach for Visible Watermark Localization and Background Content Restoration"**, the authors also implement a two-stage approach consisting of watermark localization and background content restoration, known as \textit{RIRCI}.

\textbf{Key Observations.} \textbf{[1-2]} Most deep learning methods for watermark removal use a mask prediction component to guide background restoration as shown in \figref{fig:restore_ex}. This procedure boosts image quality metrics by enabling a focus on reconstructing or refining the watermarked area. However, the accuracy of the predicted mask is crucial, as it directly impacts the final image composition. Many prior methods focus on improving the reconstructed image while neglecting mask refinement. \figref{fig:mask_ex} illustrates example predicted masks for SLBR, where under-prediction often leaves watermark residuals in the sanitized image. \textbf{[3]} Another key limitation is the reliance on access to watermark-free images during training. Training datasets typically include \textit{watermarked images}, \textit{watermark masks}, and \textit{watermark-free images} **Kim et al., "Watermark Removal Datasets: A Review"**. In real-world scenarios, matching the distribution of watermarked and watermark-free images is highly unlikely. For instance, when watermarked images are scraped from platforms like Shutterstock.com, the true background behind the watermark is unknown. This raises a critical challenge: how can these methods be effectively evaluated when ground truth watermark-free images are unavailable in practice?

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%    Introduction
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%