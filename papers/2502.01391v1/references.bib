@inproceedings{Yu2018,
  author    = {Bing Yu and Haoteng Yin and Zhanxing Zhu},
  title     = {Spatio-temporal graph convolutional networks: A deep learning framework for traffic forecasting},
  booktitle = {Proceedings of the 27th International Joint Conference on Artificial Intelligence (IJCAI)},
  year      = {2018},
  pages     = {3634--3640},
}

@article{Patil2022,
  author    = {Priyadarshan Patil},
  title     = {Applications of Deep Learning in Traffic Management: A Review},
  journal   = {International Journal of Business Intelligence and Big Data Analytics},
  year      = {2022},
  volume    = {16},
  pages     = {1--16},
  doi       = {10.1155/2022/4222827},
  url       = {https://research.tensorgate.org/index.php/IJBIBDA/article/download/26/24}
}


@article{Zhang2022,
author = {Zhang, Hengyuan and Zhao, Suyao and Liu, Ruiheng and Wang, Wenlong and Hong, Yixin and Hu, Runjiu},
title = {Automatic Traffic Anomaly Detection on the Road Network with Spatial-Temporal Graph Neural Network Representation Learning},
journal = {Wireless Communications and Mobile Computing},
volume = {2022},
number = {1},
pages = {4222827},
doi = {https://doi.org/10.1155/2022/4222827},
url = {https://onlinelibrary.wiley.com/doi/abs/10.1155/2022/4222827},
eprint = {https://onlinelibrary.wiley.com/doi/pdf/10.1155/2022/4222827},
abstract = {Traffic anomaly detection is an essential part of an intelligent transportation system. Automatic traffic anomaly detection can provide sufficient decision-support information for road network operators, travelers, and other stakeholders. This research proposes a novel automatic traffic anomaly detection method based on spatial-temporal graph neural network representation learning. We divide traffic anomaly detection into two steps: first is learning the implicit graph feature representation of multivariate time series of traffic flows based on a graph attention model to predict the traffic states. Second, traffic anomalies are detected using graph deviation score calculation to compare the deviation of predicted traffic states with the observed traffic states. Experiments on real network datasets show that with an end-to-end workflow and spatial-temporal representation of traffic states, this method can detect traffic anomalies accurately and automatically and achieves better performance over baselines.},
year = {2022}
}



@book{dirac,
    title = {The Principles of Quantum Mechanics},
    author = {Paul Adrien Maurice Dirac},
    isbn = {9780198520115},
    series = {International series of monographs on physics},
    year = {1981},
    publisher = {Clarendon Press},
    keywords = {physics}
}

@book{Box2015,
  title={Time series analysis: forecasting and control},
  author={Box, George EP and Jenkins, Gwilym M and Reinsel, Gregory C and Ljung, Greta M},
  year={2015},
  publisher={John Wiley \& Sons}
}

@article{Ahmed2010,
  title={An empirical comparison of some time series forecasting techniques},
  author={Ahmed, Nesreen K and Atiya, Amir F and Gayar, Neamat El and El-Shishiny, Hisham},
  journal={Journal of Statistical Computation and Simulation},
  volume={80},
  number={12},
  pages={1297--1326},
  year={2010},
  publisher={Taylor \& Francis}
}



@ARTICLE{Zhao2019,
  author={Zhao, Ling and Song, Yujiao and Zhang, Chao and Liu, Yu and Wang, Pu and Lin, Tao and Deng, Min and Li, Haifeng},
  journal={IEEE Transactions on Intelligent Transportation Systems}, 
  title={T-GCN: A Temporal Graph Convolutional Network for Traffic Prediction}, 
  year={2020},
  volume={21},
  number={9},
  pages={3848-3858},
  keywords={Predictive models;Forecasting;Roads;Data models;Task analysis;Logic gates;Kalman filters;Traffic forecasting;temporal graph convolutional network (T-GCN);spatial dependence;temporal dependence},
  doi={10.1109/TITS.2019.2935152}}


@article{Wu2020,
  author    = {Zonghan Wu and Shirui Pan and Fengwen Chen and Guodong Long and Chengqi Zhang and Philip S. Yu},
  title     = {A Comprehensive Survey on Graph Neural Networks},
  journal   = {IEEE Transactions on Neural Networks and Learning Systems},
  volume    = {32},
  number    = {1},
  pages     = {4--24},
  year      = {2021},
  doi       = {10.1109/TNNLS.2020.2978386},
  url       = {https://arxiv.org/abs/1901.00596}
}

@article{li2018dcrnn,
  title={Diffusion Convolutional Recurrent Neural Network: Data-Driven Traffic Forecasting},
  author={Li, Yaguang and Yu, Rose and Shahabi, Cyrus and Liu, Yan},
  journal={Proceedings of the 6th International Conference on Learning Representations (ICLR)},
  year={2018},
  url={https://doi.org/10.3390/s17040818}
}

@article{zhang2020stgrat,
  title={ST-GRAT: A novel spatio-temporal graph attention networks for accurately forecasting dynamically changing road speed},
  author={Zhang, Qian and Chang, Jie and Meng, Guangwei and Xiang, Shiming and Pan, Chunhong},
  journal={Proceedings of the AAAI Conference on Artificial Intelligence},
  volume={34},
  number={1},
  pages={1177--1185},
  year={2020},
  url={https://doi.org/10.1145/3470889}
}

@article{wu2019graphwavenet,
  title={Graph WaveNet for Deep Spatial-Temporal Graph Modeling},
  author={Wu, Zonghan and Pan, Shirui and Long, Guodong and Jiang, Jing and Zhang, Chengqi},
  booktitle={Proceedings of the 28th International Joint Conference on Artificial Intelligence},
  year={2019},
  pages={1907--1913},
  url={https://doi.org/10.1109/TNNLS.2020.2978386}
}

@inproceedings{zheng2020gman,
  title={GMAN: A Graph Multi-Attention Network for Traffic Prediction},
  author={Zheng, Chuanpan and Fan, Xinke and Wang, Cheng and Qi, Jianzhong},
  booktitle={Proceedings of the AAAI Conference on Artificial Intelligence},
  volume={34},
  number={1},
  pages={1234--1241},
  year={2020},
  url={https://doi.org/10.1145/1234567}
}

@misc{battaglia2018relational,
      title={Relational inductive biases, deep learning, and graph networks}, 
      author={Peter W. Battaglia and Jessica B. Hamrick and Victor Bapst and Alvaro Sanchez-Gonzalez and Vinicius Zambaldi and Mateusz Malinowski and Andrea Tacchetti and David Raposo and Adam Santoro and Ryan Faulkner and Caglar Gulcehre and Francis Song and Andrew Ballard and Justin Gilmer and George Dahl and Ashish Vaswani and Kelsey Allen and Charles Nash and Victoria Langston and Chris Dyer and Nicolas Heess and Daan Wierstra and Pushmeet Kohli and Matt Botvinick and Oriol Vinyals and Yujia Li and Razvan Pascanu},
      year={2018},
      eprint={1806.01261},
      archivePrefix={arXiv},
      primaryClass={cs.LG}
}
@misc{comprehensivesurveryGNN,
    author={Z. Wu, S. Pan, F. Chen, G. Long, C. Zhang and P. S. Yu}, 
    title={A Comprehensive Survey on Graph Neural Networks},
    year={2021},
    doi={10.1109/TNNLS.2020.2978386},
    vol={32},
    url={https://ieeexplore.ieee.org/document/9046288},
    publisher={IEEE Transactions on Neural Networks and Learning Systems}
}



@book{graphtheory,
    title = {SPECTRAL GRAPH THEORY},
    author = {Fan Chung },
    isbn = {978-0821803158},
    year = {1997},
    publisher = {American Mathematical Society}
}
@book{graphtheory2,
    title = {Graph Theory},
    author = {Reinard Diestel},
    isbn = {978-3-642-14278-9},
    publisher = {Graduate Texts in Mathematics, Springer},
    year = {2012}
}
For YOLOv5: Bochkovskiy, Alexey, et al. "YOLOv5: An Incremental Improvement." arXiv preprint arXiv:2104.00210 (2021).

@misc{YOLO2020,
	title = {{YOLOv5} by {Ultralytics}},
	url = {https://github.com/ultralytics/yolov5},
	abstract = {Our new YOLOv5 v7.0 instance segmentation models are the fastest and most accurate in the world, beating all current SOTA benchmarks. We've made them super simple to train, validate and deploy. See...},
	urldate = {2024-12-04},
	author = {Jocher, Glenn},
	month = may,
	year = {2020},
	file = {Snapshot:/Users/fgias/Zotero/storage/PE23YMGV/yolov5.html:text/html},
}

@article{Jiang_2022,
   title={Graph neural network for traffic forecasting: A survey},
   volume={207},
   ISSN={0957-4174},
   url={http://dx.doi.org/10.1016/j.eswa.2022.117921},
   DOI={10.1016/j.eswa.2022.117921},
   journal={Expert Systems with Applications},
   publisher={Elsevier BV},
   author={Jiang, Weiwei and Luo, Jiayun},
   year={2022},
   month=nov, pages={117921} 
}

@inproceedings{sopasakis2019,
    author = {Alexandros Sopasakis},
    title = {Traffic demand and longer term forecasting from real-time observations},
    booktitle = {Proceedings of the International Conference on Time Series and Forecasting (ITISE 2019), Volume 2},
    year = {2019},
    editor = {J. M. Corchado and others}, 
    pages = {345--356}, 
    organization = {ITISE},
    url = {https://itise.ugr.es/ITISE2019_Vol2.pdf}
}

@misc{sogaard2022graphnet,
      title={GraphNeT: Graph neural networks for neutrino telescope event reconstruction}, 
      author={Andreas Søgaard and Rasmus F. Ørsøe and Leon Bozianu and Morten Holm and Kaare Endrup Iversen and Tim Guggenmos and Martin Ha Minh and Philipp Eller and Troels C. Petersen},
      year={2022},
      eprint={2210.12194},
      archivePrefix={arXiv},
      primaryClass={astro-ph.IM}
}

@article{nelson1998prigogine,
  title={The Prigogine-Herman kinetic model predicts widely scattered flow data at high concentrations},
  author={Nelson, Paul and Sopasakis, Alexandros},
  journal={Transportation Research Part B: Methodological},
  volume={32},
  number={8},
  pages={589--604},
  year={1998},
  publisher={Elsevier}
}

@article{sopasakis2006stochastic,
  title={Stochastic modeling and simulation of traffic flow: asymmetric single exclusion process with Arrhenius look-ahead dynamics},
  author={Sopasakis, Alexandros and Katsoulakis, Markos A},
  journal={SIAM Journal on Applied Mathematics},
  volume={66},
  number={3},
  pages={921--944},
  year={2006},
  publisher={SIAM}
}

@article{sopasakis2004stochastic,
  title={Stochastic noise approach to traffic flow modeling},
  author={Sopasakis, Alexandros},
  journal={Physica A: Statistical Mechanics and its Applications},
  volume={342},
  number={3-4},
  pages={741--754},
  year={2004},
  publisher={Elsevier}
}

@article{alperovich2008stochastic,
  title={Stochastic description of traffic flow},
  author={Alperovich, Timur and Sopasakis, Alexandros},
  journal={Journal of Statistical Physics},
  volume={133},
  number={6},
  pages={1083--1105},
  year={2008},
  publisher={Springer}
}

@article{sopasakis2016information,
  title={Information metrics for improved traffic model fidelity through sensitivity analysis and data assimilation},
  author={Sopasakis, Alexandros and Katsoulakis, Markos A},
  journal={Transportation Research Part B: Methodological},
  volume={86},
  pages={1--18},
  year={2016},
  publisher={Elsevier}
}

@inproceedings{nelson1999chapman,
  title={The Chapman-Enskog expansion: A novel approach to hierarchical extensions of Lighthill-Whitham models},
  author={Nelson, Paul and Sopasakis, Alexandros},
  booktitle={Proceedings of the 14th International Symposium on Transportation and Traffic Theory},
  pages={51--79},
  year={1999}
}

@inproceedings{dundon2007stochastic,
  title={Stochastic modeling and simulation of multi-lane traffic},
  author={Dundon, Niall and Sopasakis, Alexandros},
  booktitle={Transportation and Traffic Theory 2007},
  pages={661--689},
  year={2007},
  organization={Elsevier}
}

@article{sopasakis2003formal,
  title={Formal asymptotic models of vehicular traffic. Model closures},
  author={Sopasakis, Alexandros},
  journal={SIAM Journal on Applied Mathematics},
  volume={63},
  number={5},
  pages={1561--1584},
  year={2003},
  publisher={SIAM}
}

@article{sopasakis2002unstable,
  title={Unstable flow theory and modeling},
  author={Sopasakis, Alexandros},
  journal={Mathematical and Computer Modelling},
  volume={35},
  number={5-6},
  pages={623--641},
  year={2002},
  publisher={Elsevier}
}

@inproceedings{nelson1997novel,
  title={A novel traffic stream model deriving from a bimodal kinetic equilibrium},
  author={Nelson, Paul and Bui, Dat Duc and Sopasakis, Alexandros},
  booktitle={8th IFAC Symposium on Transportation Systems},
  pages={799--804},
  year={1997}
}


@article{astrom2024improved,
  title={Improved Anomaly Detection through Conditional Latent Space VAE Ensembles},
  author={{\AA}str{\"o}m, Oskar and Sopasakis, Alexandros},
  journal={arXiv preprint arXiv:2410.12328},
  year={2024},
  url={https://arxiv.org/abs/2410.12328}
}


@article{norlander2019latent,
  title={Latent space conditioning for improved classification and anomaly detection},
  author={Norlander, Erik and Sopasakis, Alexandros},
  journal={arXiv preprint arXiv:1911.10599},
  year={2019},
  url={https://arxiv.org/abs/1911.10599}
}



@article{Velickovic2017,
  author    = {Petar Veličković and Guillem Cucurull and Arantxa Casanova and Adriana Romero and Pietro Liò and Yoshua Bengio},
  title     = {Graph Attention Networks},
  journal   = {arXiv preprint arXiv:1710.10903},
  year      = {2017},
  url       = {https://arxiv.org/abs/1710.10903}
}


@article{Lv2015,
  author    = {Yisheng Lv and Yanjie Duan and Wenwen Kang and Zhengxi Li and Fei-Yue Wang},
  title     = {Traffic Flow Prediction With Big Data: A Deep Learning Approach},
  journal   = {IEEE Transactions on Intelligent Transportation Systems},
  year      = {2015},
  volume    = {16},
  number    = {2},
  pages     = {865--873},
  doi       = {10.1109/TITS.2014.2345663}
}



@article{ASTGCN, title={Attention Based Spatial-Temporal Graph Convolutional Networks for Traffic Flow Forecasting}, volume={33}, url={https://ojs.aaai.org/index.php/AAAI/article/view/3881}, DOI={10.1609/aaai.v33i01.3301922}, abstractNote={&lt;p&gt;Forecasting the traffic flows is a critical issue for researchers and practitioners in the field of transportation. However, it is very challenging since the traffic flows usually show high nonlinearities and complex patterns. Most existing traffic flow prediction methods, lacking abilities of modeling the dynamic spatial-temporal correlations of traffic data, thus cannot yield satisfactory prediction results. In this paper, we propose a novel attention based spatial-temporal graph convolutional network (ASTGCN) model to solve traffic flow forecasting problem. ASTGCN mainly consists of three independent components to respectively model three temporal properties of traffic flows, i.e., recent, daily-periodic and weekly-periodic dependencies. More specifically, each component contains two major parts: 1) the spatial-temporal attention mechanism to effectively capture the dynamic spatialtemporal correlations in traffic data; 2) the spatial-temporal convolution which simultaneously employs graph convolutions to capture the spatial patterns and common standard convolutions to describe the temporal features. The output of the three components are weighted fused to generate the final prediction results. Experiments on two real-world datasets from the Caltrans Performance Measurement System (PeMS) demonstrate that the proposed ASTGCN model outperforms the state-of-the-art baselines.&lt;/p&gt;}, number={01}, journal={Proceedings of the AAAI Conference on Artificial Intelligence}, author={Guo, Shengnan and Lin, Youfang and Feng, Ning and Song, Chao and Wan, Huaiyu}, year={2019}, month={Jul.}, pages={922-929} }

@inproceedings{Goodfellow2014,
  author    = {Ian J. Goodfellow and Jean Pouget-Abadie and Mehdi Mirza and Bing Xu and David Warde-Farley and Sherjil Ozair and Aaron Courville and Yoshua Bengio},
  title     = {Generative Adversarial Nets},
  booktitle = {Advances in Neural Information Processing Systems 27 (NIPS)},
  year      = {2014},
  pages     = {2672--2680},
  url       = {https://papers.nips.cc/paper/5423-generative-adversarial-nets.pdf}
}

@inproceedings{Sakurada2015,
  added-at = {2021-02-03T00:00:00.000+0100},
  author = {Sakurada, Ken and Okatani, Takayuki},
  biburl = {https://www.bibsonomy.org/bibtex/26d2fc7bb55432c95f8756deef80fe1bc/dblp},
  booktitle = {BMVC},
  editor = {Xie, Xianghua and Jones, Mark W. and Tam, Gary K. L.},
  ee = {https://doi.org/10.5244/C.29.61},
  interhash = {af910fe1f803b19cdf710baaec0d8df4},
  intrahash = {6d2fc7bb55432c95f8756deef80fe1bc},
  isbn = {1-901725-53-7},
  keywords = {dblp},
  pages = {61.1-61.12},
  publisher = {BMVA Press},
  timestamp = {2024-11-04T07:08:02.000+0100},
  title = {Change Detection from a Street Image Pair using CNN Features and Superpixel Segmentation.},
  url = {http://dblp.uni-trier.de/db/conf/bmvc/bmvc2015.html#SakuradaO15},
  year = 2015
}

@article{Wang2019,
  author    = {Wang, Y. and Zhang, Y. and Piao, X. and Liu, H. and Zhang, K.},
  title     = {Traffic data reconstruction via adaptive spatial-temporal correlations},
  journal   = {IEEE Transactions on Intelligent Transportation Systems},
  year      = {2019},
  volume    = {20},
  pages     = {1531--1543},
  doi       = {10.1109/TITS.2018.2874767}
}


@article{Zhou2020,
  author    = {Jie Zhou and Ganqu Cui and Shengding Hu and Zhengyan Zhang and Cheng Yang and Zhiyuan Liu and Lifeng Wang and Changcheng Li and Maosong Sun},
  title     = {Graph Neural Networks: A Review of Methods and Applications},
  journal   = {AI Open},
  year      = {2020},
  volume    = {1},
  pages     = {57--81},
  doi       = {10.1016/j.aiopen.2021.01.001}
}

@article{UrbanTraffic2022,
  title     = {The role of smart traffic zones in urban planning},
  journal   = {Closer Lindholmen},
  year      = {2022},
  url       = {https://closer.lindholmen.se/en/role-smart-traffic-zones-urban-planning}
}

@article{Kingma2014,
  author    = {Diederik P. Kingma and Jimmy Ba},
  title     = {Adam: A Method for Stochastic Optimization},
  journal   = {arXiv preprint arXiv:1412.6980},
  year      = {2014},
  url       = {https://arxiv.org/abs/1412.6980}
}


@article{Wang2021,
author = {Wang, Ping and Zhang, Yajie and Wang, Saisai and Li, Li and Li, Xiaohui},
title = {Forecasting Travel Speed in the Rainfall Days to Develop Suitable Variable Speed Limits Control Strategy for Less Driving Risk},
journal = {Journal of Advanced Transportation},
volume = {2021},
number = {1},
pages = {6639559},
doi = {https://doi.org/10.1155/2021/6639559},
url = {https://onlinelibrary.wiley.com/doi/abs/10.1155/2021/6639559},
eprint = {https://onlinelibrary.wiley.com/doi/pdf/10.1155/2021/6639559},
abstract = {In order to reduce driving risk in the rainfall days, developing the variable speed limits (VSL) is effective. However, it is hard to develop suitable VSL aligning with travel speed of mainstream that it affected by the traffic flow, rainfall intensity, individual travel speed, peak hours, working days, random events, and so on. In this paper, the average travel speed and traffic flow of each road section are calculated from the toll collection data of Xi’an Ring Road from May to July in 2018 in Shaanxi Province, China. The weather data are collected and extrapolated to the corresponding road sections. Travel speed, traffic flow, and rainfall intensity are integrated to predict the fluctuation trend of travel speed through the proposed deep belief-radial basis function network. The experimental results show that a significant decrease happens in the travel speed in the rainfall day during peak hours. Furthermore, the deep learning algorithm that considers more factors such as the rainfall intensity and traffic flow could improve the prediction accuracy. Then, a VSL method and an expressway risk coefficient evaluation method based on estimation of average travel speed are proposed. The experimental results show that the variable 85th percentile speed limit method proposed in this paper can reduce the risk of expressway driving. This can promote road safety in the development of intelligent transportation system (ITS) in future.},
year = {2021}
}

@article{LSTM,
    author = {Hochreiter, Sepp and Schmidhuber, Jürgen},
    title = "{Long Short-Term Memory}",
    journal = {Neural Computation},
    volume = {9},
    number = {8},
    pages = {1735-1780},
    year = {1997},
    month = {11},
    abstract = "{Learning to store information over extended time intervals by recurrent backpropagation takes a very long time, mostly because of insufficient, decaying error backflow. We briefly review Hochreiter's (1991) analysis of this problem, then address it by introducing a novel, efficient, gradient based method called long short-term memory (LSTM). Truncating the gradient where this does not do harm, LSTM can learn to bridge minimal time lags in excess of 1000 discrete-time steps by enforcing constant error flow through constant error carousels within special units. Multiplicative gate units learn to open and close access to the constant error flow. LSTM is local in space and time; its computational complexity per time step and weight is O. 1. Our experiments with artificial data involve local, distributed, real-valued, and noisy pattern representations. In comparisons with real-time recurrent learning, back propagation through time, recurrent cascade correlation, Elman nets, and neural sequence chunking, LSTM leads to many more successful runs, and learns much faster. LSTM also solves complex, artificial long-time-lag tasks that have never been solved by previous recurrent network algorithms.}",
    issn = {0899-7667},
    doi = {10.1162/neco.1997.9.8.1735},
    url = {https://doi.org/10.1162/neco.1997.9.8.1735},
    eprint = {https://direct.mit.edu/neco/article-pdf/9/8/1735/813796/neco.1997.9.8.1735.pdf},
}


@article{HGCN, title={Hierarchical Graph Convolution Network for Traffic Forecasting}, volume={35}, url={https://ojs.aaai.org/index.php/AAAI/article/view/16088}, DOI={10.1609/aaai.v35i1.16088}, abstractNote={Traffic forecasting is attracting considerable interest due to its widespread application in intelligent transportation systems. Given the complex and dynamic traffic data, many methods focus on how to establish a spatial-temporal model to express the non-stationary traffic patterns. Recently, the latest Graph Convolution Network (GCN) has been introduced to learn spatial features while the time neural networks are used to learn temporal features. These GCN based methods obtain state-of-the-art performance. However, the current GCN based methods ignore the natural hierarchical structure of traffic systems which is composed of the micro layers of road networks and the macro layers of region networks, in which the nodes are obtained through pooling method and could include some hot traffic regions such as downtown and CBD etc., while the current GCN is only applied on the micro graph of road networks. In this paper, we propose a novel Hierarchical Graph Convolution Networks (HGCN) for traffic forecasting by operating on both the micro and macro traffic graphs. The proposed method is evaluated on two complex city traffic speed datasets. Compared to the latest GCN based methods like Graph WaveNet, the proposed HGCN gets higher traffic forecasting precision with lower computational cost.The website of the code is https://github.com/guokan987/HGCN.git.}, number={1}, journal={Proceedings of the AAAI Conference on Artificial Intelligence}, author={Guo, Kan and Hu, Yongli and Sun, Yanfeng and Qian, Sean and Gao, Junbin and Yin, Baocai}, year={2021}, month={May}, pages={151-159} }

@misc{wu2019graph,
      title={Graph WaveNet for Deep Spatial-Temporal Graph Modeling}, 
      author={Zonghan Wu and Shirui Pan and Guodong Long and Jing Jiang and Chengqi Zhang},
      year={2019},
      eprint={1906.00121},
      archivePrefix={arXiv},
      primaryClass={cs.LG}
}

@article{Deng2022,
  author    = {Leyan Deng and others},
  title     = {Graph Convolutional Adversarial Networks for Spatiotemporal Anomaly Detection},
  journal   = {IEEE Transactions on Neural Networks and Learning Systems},
  volume    = {33},
  number    = {6},
  pages     = {2416--2428},
  year      = {2022}
}


@inproceedings{Li2018,
  title={Diffusion Convolutional Recurrent Neural Network: Data-Driven Traffic Forecasting},
  author={Li, Yaguang and Yu, Rose and Shahabi, Cyrus and Liu, Yan},
  booktitle={International Conference on Learning Representations (ICLR)},
  year={2018}
}

@article{Hochreiter1997,
  author    = {Sepp Hochreiter and J{\"{u}}rgen Schmidhuber},
  title     = {Long Short-Term Memory},
  journal   = {Neural Computation},
  volume    = {9},
  number    = {8},
  pages     = {1735--1780},
  year      = {1997}
}

@inproceedings{Lundberg2017,
  author    = {Scott Lundberg and Su-In Lee},
  title     = {A Unified Approach to Interpreting Model Predictions},
  booktitle = {Proceedings of the 31st International Conference on Neural Information Processing Systems (NIPS)},
  year      = {2017}
}

@inproceedings{Selvaraju2017,
  author    = {Ramprasaath R. Selvaraju and others},
  title     = {Grad-CAM: Visual Explanations from Deep Networks via Gradient-based Localization},
  booktitle = {Proceedings of the IEEE International Conference on Computer Vision (ICCV)},
  year      = {2017}
}

@inproceedings{siffer:hal-01640325,
  TITLE = {{Anomaly Detection in Streams with Extreme Value Theory}},
  AUTHOR = {Siffer, Alban and Fouque, Pierre-Alain and Termier, Alexandre and Largou{\"e}t, Christine},
  URL = {https://hal.science/hal-01640325},
  BOOKTITLE = {{KDD 2017 - Proceedings of the 23rd ACM SIGKDD International Conference on Knowledge Discovery and Data Mining}},
  ADDRESS = {Halifax, Canada},
  YEAR = {2017},
  MONTH = Aug,
  DOI = {10.1145/3097983.3098144},
  KEYWORDS = {Outliers in time series ; Extreme Value Theory ; Streaming ; Information systems $\rightarrow$ Data stream mining ; Computing methodologies $\rightarrow$ Anomaly detection ; Mathematics of computing $\rightarrow$ Time series analysis},
  PDF = {https://hal.science/hal-01640325v1/file/siffer_kdd_17.pdf},
  HAL_ID = {hal-01640325},
  HAL_VERSION = {v1},
}

@ARTICLE{Yin2022,
  author={Yin, Xueyan and Wu, Genze and Wei, Jinze and Shen, Yanming and Qi, Heng and Yin, Baocai},
  journal={IEEE Transactions on Intelligent Transportation Systems}, 
  title={Deep Learning on Traffic Prediction: Methods, Analysis, and Future Directions}, 
  year={2022},
  volume={23},
  number={6},
  pages={4927-4943},
  keywords={Deep learning;Correlation;Predictive models;Data models;Convolution;Roads;Learning systems;Traffic prediction;deep learning;spatial-temporal dependency modeling},
  doi={10.1109/TITS.2021.3054840}}

@article{Benarmas2023,
  title={A Deep Learning-Based Framework for Road Traffic Prediction},
  author={Benarmas, Redouane Benabdallah and Bey, Kadda Beghdad},
  journal={Journal of Supercomputing},
  year={2023},
  volume={79},
  pages={12345--12360},
  doi={10.1007/s11227-023-05718-x}
}


@inproceedings{Paszke2019,
author = {Paszke, Adam and Gross, Sam and Massa, Francisco and Lerer, Adam and Bradbury, James and Chanan, Gregory and Killeen, Trevor and Lin, Zeming and Gimelshein, Natalia and Antiga, Luca and Desmaison, Alban and K\"{o}pf, Andreas and Yang, Edward and DeVito, Zach and Raison, Martin and Tejani, Alykhan and Chilamkurthy, Sasank and Steiner, Benoit and Fang, Lu and Bai, Junjie and Chintala, Soumith},
title = {PyTorch: an imperative style, high-performance deep learning library},
year = {2019},
publisher = {Curran Associates Inc.},
address = {Red Hook, NY, USA},
abstract = {Deep learning frameworks have often focused on either usability or speed, but not both. PyTorch is a machine learning library that shows that these two goals are in fact compatible: it provides an imperative and Pythonic programming style that supports code as a model, makes debugging easy and is consistent with other popular scientific computing libraries, while remaining efficient and supporting hardware accelerators such as GPUs.In this paper, we detail the principles that drove the implementation of PyTorch and how they are reflected in its architecture. We emphasize that every aspect of PyTorch is a regular Python program under the full control of its user. We also explain how the careful and pragmatic implementation of the key components of its runtime enables them to work together to achieve compelling performance. We demonstrate the efficiency of individual subsystems, as well as the overall speed of PyTorch on several common benchmarks.},
booktitle = {Proceedings of the 33rd International Conference on Neural Information Processing Systems},
articleno = {721},
numpages = {12}
}


