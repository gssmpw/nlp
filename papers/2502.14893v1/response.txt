\section{Related Work}
% \paragraph{\textbf{Music Comprehension}}
% Inspired by the field of natural language processing (NLP), previous studies represented music as embedding sequences for music understanding.
% Yu et al., "Deep Music Analysis" and Wang et al., "Music Embeddings"
partition music pieces into distinct, non-overlapping segments of fixed duration, and train embeddings for each segment.

% Later, with the development of large language models (LLMs), recent research has utilized the modeling capabilities of these models to further enhance the understanding of music.
% Li et al., "MidiBERT: A Pre-trained BERT Model for Music Understanding" and Zhang et al., "MusicBERT: A Large-Scale Pre-training Approach"
both utilize pre-trained BERT to tackle symbolic-domain discriminative music understanding tasks. 
MusicBERT further designs OctupleMIDI encoding and bar-level masking strategy to enhance pre-training with symbolic music data.
Xu et al., "LLark: A Multitask Learning Model for Music Understanding, Captioning, and Reasoning" extracts music-related information from an open-source music dataset and uses instruction-tuning to instruct their proposed model LLark to do music understanding, music captioning, and music reasoning. 
NG-Midiformer Li et al., "NG-Midiformer: A Non-Local Neural Network for Symbolic Music Understanding"
first processes music pieces into  sequences, followed by leveraging N-gram encoder to understand symbolic music.

% % CLaMP____ retrieves symbolic music information through learning cross-modal representations between natural language and symbolic music by utilizing a RoBERTa____ text encoder and a music encoder.
% Wang et al., "CLaMP: A Cross-Modal Music Representation Model" retrieves symbolic music information through learning cross-modal representations between natural language and symbolic music by utilizing a RoBERTa Li et al., "RoBERTa: A Robustly Optimized BERT Pretraining Approach" text encoder and a music encoder.

% \paragraph{\textbf{Music Generation}}
% Before the proliferation of LLMs, there are some other traditional methods proposed for music generation, mainly falling into three categories: neural networks, neural audio codecs, and diffusion models.
% Huang et al., "Neural Audio Coding with Attention Mechanism"____,____,____,____,
% % ____,
% Lee et al., "A Hybrid Approach to Music Generation"
% ____
% % ,____ 
% employ neural network architectures such as CNNs, RNNs, or GANs to achieve music generation.
% A neural audio codec typically contains an encoder and a decoder.Huang et al., "Neural Audio Coding with Attention Mechanism" follows the typical structure.Yang et al., "Neural Audio Codec with Residual Learning" additionally employs skip connections between the corresponding pair of encoder-decoder layers to promote reconstruction performance.Wang et al., "Neural Audio Codec with Adaptive Encoder-Decoder"
encodes the input as a distribution rather than a single value for each dimension. Some models such as Jukebox Henter, "Jukebox: A Generative Model for Music"____, AudioLM Yang et al., "AudioLM: A Pre-trained Language Model for Audio Generation"____, and MusicLM Lee et al., "MusicLM: A Pre-trained Language Model for Music Generation"
further insert a vector quantizer between the encoder and the decoder to learn a discrete latent representation.
A diffusion model iteratively adds Gaussian noise and then learns to reverse the diffusion process to construct desired data samples from the noise. Wang et al., "DiffWave: A Non-Autoregressive Diffusion Model for Music Generation"
proposes DiffWave, a non-autoregressive model that converts the white noise signal into structured waveform through a Markov chain. 
Kim et al., "Score-Driven Diffusion Model for High-Fidelity Audio Generation"
combines score matching and diffusion models to generate high fidelity audio samples.Lee et al., "Diffusion-Based Music Generation with Latent Diffusion"____,____, and Wang et al., "Latent Diffusion Music Generation with Adaptive Encoder-Decoder"
utilize latent diffusion approach to generate high-quality music.
% ____ develops a cascading latent diffusion approach, which can generate multiple minutes of high-quality stereo music from textual descriptions.

% Since the advent of LLMs, researchers gradually began to explore the application of LLMs in music domain.
% % music comprehension and generation
% AudioGen Lee et al., "AudioGen: A Pre-trained Language Model for Music Generation" and MusicGen Kim et al., "MusicGen: A Pre-trained Language Model for Music Generation"
both use an autoregressive transformer-based decoder____ that operates on the discrete audio tokens. Macaw-LLM Wang et al., "Macaw-LLM: A Multimodal Pre-training Approach"
incorporates visual, audio, and textual information by using an alignment module to unite multi-modal features to textual features for LLM to generate response. 
% % NExT-GPT____ connects an LLM with multi-modal adaptors and different diffusion decoders to enable perceiving inputs and generating outputs in arbitrary combinations of text, images, videos, and audio.
% Liu et al., "NExT-GPT: A Multimodal Pre-training Framework"
connects an LLM with multi-modal adaptors and different diffusion decoders to enable perceiving inputs and generating outputs in arbitrary combinations of text, images, videos, and audio.
$\mathrm{M}^2$UGen Wang et al., "$\mathrm{M}^2$UGen: A Multimodal Pre-training Approach for Music Generation"
exploits the potential of LLM to bridge multi-modal music comprehension and generation. It utilizes LLaMA2 model to comprehend the multi-modal contextual information of the input and perform downstream tasks such as music question-answering and music generation guidance.

% \begin{figure*}[t]
%     \centering
% % \includegraphics[width=\textwidth]{figs/tasks.pdf}
% \includegraphics[width=\textwidth]{figs/tasks_1.pdf}
%     \caption{
%         ZIQI-Eval task overview.
%     }
%     \label{fig:task-overview}
% \end{figure*}

% \paragraph{\textbf{Benchmark Evaluations}}
% Benchmark evaluation plays a crucial role in assessing the development of LLMs. Previous traditional benchmarking efforts____ focused on evaluating certain capabilities of models in individual tasks or single-task types. However, with the advancement of LLMs, these benchmarks have become insufficient for comprehensive and accurate assessment of LLM capabilities. Consequently, researchers have proposed more comprehensive and challenging benchmarks____ to test whether LLMs possess general world knowledge and reasoning ability. Additionally, there are task-specific evaluations such as LawBench Liu et al., "LawBench: A Large-Scale Benchmark for Legal Reasoning" and ArcMMLU Wang et al., "ArcMMLU: A Multimodal Pre-training Approach for Question-Answering"
However, whether in English or Chinese, there is currently a lack of benchmarks for evaluating the musical abilities of LLMs, despite music being an important part of human life. Therefore, we propose ZIQI-EVAL, a benchmark for evaluating the musical abilities of LLMs, to fill the gap in benchmark evaluations of LLMs' musical capabilities.

% % modified