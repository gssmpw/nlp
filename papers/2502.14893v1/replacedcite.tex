\section{Related Work}
% \paragraph{\textbf{Music Comprehension}}
% Inspired by the field of natural language processing (NLP), previous studies represented music as embedding sequences for music understanding.
% ____ and ____ partition music pieces into distinct, non-overlapping segments of fixed duration, and train embeddings for each segment.

% Later, with the development of large language models (LLMs), recent research has utilized the modeling capabilities of these models to further enhance the understanding of music.
% MidiBERT____ and MusicBERT____ both utilize pre-trained BERT to tackle symbolic-domain discriminative music understanding tasks. 
% MusicBERT further designs OctupleMIDI encoding and bar-level masking strategy to enhance pre-training with symbolic music data.
% ____ extracts music-related information from an open-source music dataset and uses instruction-tuning to instruct their proposed model LLark to do music understanding, music captioning, and music reasoning. 
% NG-Midiformer____ first processes music pieces into  sequences, followed by leveraging N-gram encoder to understand symbolic music.

% % CLaMP____ retrieves symbolic music information through learning cross-modal representations between natural language and symbolic music by utilizing a RoBERTa____ text encoder and a music encoder.

% \paragraph{\textbf{Music Generation}}
% Before the proliferation of LLMs, there are some other traditional methods proposed for music generation, mainly falling into three categories: neural networks, neural audio codecs, and diffusion models.

% ____,____,____,____,
% % ____,
% ____
% % ,____ 
% employ neural network architectures such as CNNs, RNNs, or GANs to achieve music generation.
% A neural audio codec typically contains an encoder and a decoder.____ follows the typical structure.____ additionally employs skip connections between the corresponding pair of encoder-decoder layers to promote reconstruction performance.____ encodes the input as a distribution rather than a single value for each dimension. Some models such as Jukebox____, AudioLM____, and MusicLM____ further insert a vector quantizer between the encoder and the decoder to learn a discrete latent representation.
% A diffusion model iteratively adds Gaussian noise and then learns to reverse the diffusion process to construct desired data samples from the noise. ____ proposes DiffWave, a non-autoregressive model that converts the white noise signal into structured waveform through a Markov chain. 
% ____ combines score matching and diffusion models to generate high fidelity audio samples.____,____, and____ utilize latent diffusion approach to generate high-quality music.
% % ____ develops a cascading latent diffusion approach, which can generate multiple minutes of high-quality stereo music from textual descriptions.

% Since the advent of LLMs, researchers gradually began to explore the application of LLMs in music domain.
% % music comprehension and generation
% AudioGen____ and MusicGen____ both use an autoregressive transformer-based decoder____ that operates on the discrete audio tokens. Macaw-LLM____ incorporates visual, audio, and textual information by using an alignment module to unite multi-modal features to textual features for LLM to generate response. 
% % NExT-GPT____ connects an LLM with multi-modal adaptors and different diffusion decoders to enable perceiving inputs and generating outputs in arbitrary combinations of text, images, videos, and audio.
% $\mathrm{M}^2$UGen____ exploits the potential of LLM to bridge multi-modal music comprehension and generation. It utilizes LLaMA2 model to comprehend the multi-modal contextual information of the input and perform downstream tasks such as music question-answering and music generation guidance.

% \begin{figure*}[t]
%     \centering
% % \includegraphics[width=\textwidth]{figs/tasks.pdf}
% \includegraphics[width=\textwidth]{figs/tasks_1.pdf}
%     \caption{
%         ZIQI-Eval task overview.
%     }
%     \label{fig:task-overview}
% \end{figure*}

% \paragraph{\textbf{Benchmark Evaluations}}
% Benchmark evaluation plays a crucial role in assessing the development of LLMs. Previous traditional benchmarking efforts____ focused on evaluating certain capabilities of models in individual tasks or single-task types. However, with the advancement of LLMs, these benchmarks have become insufficient for comprehensive and accurate assessment of LLM capabilities. Consequently, researchers have proposed more comprehensive and challenging benchmarks____ to test whether LLMs possess general world knowledge and reasoning ability. Additionally, there are task-specific evaluations such as LawBench____ and ArcMMLU____. However, whether in English or Chinese, there is currently a lack of benchmarks for evaluating the musical abilities of LLMs, despite music being an important part of human life. Therefore, we propose ZIQI-EVAL, a benchmark for evaluating the musical abilities of LLMs, to fill the gap in benchmark evaluations of LLMs' musical capabilities.

% % modified
%