\section{Dataset and metrics}

\subsection{Data collection and annotation}
\label{sec:data}

We generate echograms for the Caltech Fish Counting dataset (CFC) from \cite{kay2022caltechfishcountingdataset}. We use the default training and validation sets, ``KL-train'' and ``KL-val'' from the \textbf{l}eft bank of the \textbf{K}enai River in Alaska, and we also test on one out-of-distribution test set, ``KR'' from the Kenai \textbf{r}ight bank. %The resulting echograms range from 96px to 576px wide and 618px to 1948px tall, spanning an aspect ratio range of 0.05 to 1.
In total, this gives us 481 KL-train images, 66 KL-val images, and 406 KR test images. We refer to the ground truth count labels for CFC as \textbf{strong labels} in our experiments.

We also generate additional \textbf{weak labels} on a set of previously-unlabeled ARIS files collected from the same camera locations as the KL-train and KL-val sets. These weak labels are generated by the public detector and tracker pipeline released with CFC~\cite{kay2022caltechfishcountingdataset}. We label counts in the same way as \cite{kay2022caltechfishcountingdataset}: a fish whose trajectory start and end are on opposite sides of a vertical line drawn through the center of the frame is counted as either an\textit{left} or \textit{right} traveling fish, based on the relative start and end points of the trajectory. We ensure there is no overlap between the KL validation set and the detector-tracker annotated training or validation set.
%, but there may be overlap between the KL training set and the detector-tracker annotated training and validation sets.
In total, we generated weak labels using this pipeline for 33,437 images from the KL location.

There is a large imbalance between leftward and rightward moving fish, since the data is collected to monitor salmon migrating upstream. We orient all clips such that right-moving fish travel upstream and left-moving fish travel downstream, to make the model invariant to the physical upstream direction.

\subsection{Metrics}

To evaluate model performance we use the normalized Mean Absolute Error (nMAE) as in prior work~\cite{kay2022caltechfishcountingdataset}:

\vspace{-5pt}
\begin{equation}
    \text{nMAE}=\frac{\sum_{i=0}^{N} E_i}{\sum_{i=0}^{N}\hat{z}_i}
\end{equation}

\noindent
where $N$ is the number of clips, $\hat{z}_i$ is the target number of counts on the $i$th clip, and the error $E_i$ is the sum of absolute errors on left and right counts on the $i$th clip.
% \begin{equation}
%     E_i = |z_{left,i} - \hat{z}_{left,i}| + |z_{right,i} - \hat{z}_{right,i}|
% \end{equation}
We also report nMAE for left and right counts separately. 
%For reference, an overall count error below about 10\%  would bring our model on par with the performance of field technicians~\cite{kay2022caltechfishcountingdataset}.



