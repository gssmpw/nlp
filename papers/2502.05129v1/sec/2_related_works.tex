
\section{Related work}
\label{sec:related}

\input{fig/echogram}

% \subsection{Salmonid escapement monitoring}

% Salmon population monitoring allows fisheries and state departments to make data-driven fishery management decisions and evaluate the efficacy of various conservation programs. In particular, fishery managers and conservationists are interested in salmonid \textit{escapement}: the abundance of returning salmon from the sea which successfully spawn. 
\noindent
\textbf{Salmon escapement monitoring.} Several methods exist for monitoring salmon escapement, including weirs, counting towers, and various sonar hardware. We include a broader overview of these methodologies in the supplemental material.
In this paper we focus on a relatively new generation of sonar hardware known as \textit{imaging sonar} that produce high-resolution videos using multi-beam acoustic hardware. Imaging sonar can be accurately analyzed to count and measure salmon by both human technicians~\cite{AlaskaSonar} as well as computer vision systems~\cite{kay2022caltechfishcountingdataset}.



\noindent
\textbf{Computer vision for salmon monitoring.}
% Analysis with computer vision has the potential to more efficiently and accurately automate the analysis of sonar video for escapement monitoring. 
Existing computer vision approaches to salmon counting utilize tracking-by-detection to first perform object detection on individual frames and then link together predicted bounding boxes into trajectories~\cite{kay2022caltechfishcountingdataset,ouis2023yolo}.
% \jk{Re-word this so it's not the same as intro} Prior work has introduced approaches based on object detection and multi-object tracking~\cite{kay2022caltechfishcountingdataset}. In these approaches, an object detection model is run on individual frames from a given clip and then a multi-object tracker is used to link together predicted bounding boxes into tracks. 
Once these tracks are determined, different heuristics may be used to determine fish counts. While such approaches produce accurate counts when the training river and testing river are the same, they struggle on out-of-distribution test data sourced from \eg different rivers or different environmental conditions than the training data~\cite{kay2022caltechfishcountingdataset,kay2024align,kay2023unsupervised}. Another key challenge for real-world deployment of these models is their compute requirements, as fish counting technicians are often stationed in remote locations with only consumer laptops; on such hardware, even efficient object detection and tracking techniques like YOLO~\cite{redmon2016you} and SORT~\cite{bewley2016simple} are a severe processing bottleneck. Our method aims to enable more efficient inference by bypassing frame-by-frame video analysis through compressed temporal representations called echograms.

% The type of object detector and tracker chosen may be heavily influenced by the project's need for efficiency and low-power inference. The portion of the above computer vision pipeline that this work focuses on is the object detection step. As the most time- and compute-intensive step, an efficiency improvement here would benefit the entire pipeline. YOLO is currently the dominant efficient object detection library in use; rather than running regression successively on bounding boxes as in a R-CNN, YOLO applies regression only once to an image to find the most likely bounding boxes, increasing efficiency and incorporating global information, with a tradeoff of less precisely localizing small objects. \cite{redmon2016lookonceunifiedrealtime} Other real-time object detection libraries include SSD \cite{Liu_2016}, which also detects objects in a single pass through the network; and Faster R-CNN \cite{ren2016fasterrcnnrealtimeobject}, which combines region proposals with convolutional neural networks. \jk{The choice of object tracker is also influenced by efficiency concerns.} For instance, Kay et al.~\cite{kay2022caltechfishcountingdataset} used the SORT tracker for real-time tracking due to its speed. \jk{Our method also enables low power inference by ...}

% \subsection{Model cascades}

% Our work bears similarity to \textit{model cascades}, which utilize sequentially larger models in serial to improve efficiency. To achieve additional increases in efficiency in the object detection step, the data can be fed through multiple models. A model ensemble applies different models to the same input data (e.g. each individual image in the video stream) and selects the result through some process such as averaging the prediction from each model; Wang et al.~\cite{wang2022wisdomcommitteesoverlookedapproach} show that this approach of combining existing, simpler models is often more efficient and accurate than developing a new, more complex architecture, and using a \textit{cascade} of models applied sequentially on insufficiently confident predictions is more efficient than an ensemble of the same models. 

% More advanced model cascades which implement multi-scale detection architectures or early exit from training for easy examples also show improvements, but Wang et al show that even a basic cascade of pretrained models will outperform a single large model in all computational regimes: Wang's cascade matches EfficientNet-B7 accuracy while using 5.4x fewer FLOPs. 

% These techniques have also been applied to efficient video analytics, \eg NoScope uses model ensembles to ...Alternatively, a model cascade can be used over a whole video, applying models sequentially from weakest and most efficient to strongest and most expensive: only those regions of video in which initial detections are not confident enough are passed to a more powerful model. \cite{kang2017noscopeoptimizingneuralnetwork} Our work also \jk{mention similarities}, however we \jk{mention differences}.

% similar to noscope: apply "reference model" to the whole video, this serves as the "ground truth" for our model, which aims to perform the same classification at lower computational cost; differences: actually we want *better* performance than the detection model since we are also incorporating the tracking model in labeling the echogram! detection model on its own is too noisy------------------------------------------------------