\clearpage
\section*{\hspace{-0.5em}Appendix}
\captionsetup[figure]{labelformat=default, labelsep=colon, name=Appendix Figure}
\captionsetup[table]{labelformat=default, labelsep=colon, name=Appendix Table}
\renewcommand{\thefigure}{\arabic{figure}}
\setcounter{figure}{0}
\setcounter{table}{0}

\begin{figure*}[ht]
  \includegraphics[width=\columnwidth]{figures/readerstudyvis.pdf}
  \caption{\textbf{Reader study user interface}. Expert readers score each reconstructed chest x-ray with respect to image fidelity, preservation of clinically-relevant features, and the presence of artifacts. Each expert reader is presented with a pair of chest X-rays, consisting of an original high-resolution image $x$ on the left and a reconstructed image $\hat{x}$ on the right. Readers are blinded to both the method and the downsizing factor used to generate the reconstructed image. }
  \label{fig:readerstudyui}
\end{figure*}



\begin{table*}[t]
% \scriptsize
\begin{center}
{\renewcommand{\arraystretch}{1.2}%
{
\resizebox{\linewidth}{!}{
\begin{tabular}{lccccccc}
\toprule
\textbf{Classification Task}
& \textbf{Image Dimensionality}
& \textbf{Num. Classes}
& \textbf{Dataset}
& \textbf{Modality}
& \textbf{Anatomy}
& \textbf{Num. Images}
\\ 
\midrule
Malignancy Detection & 2D & 2 & CMMD~\cite{cai2023online} & FFDM & Breast & 3744\\
Calcification Detection & 2D & 2 & CMMD~\cite{cai2023online} & FFDM & Breast & 5202\\
BI-RADS Classification & 2D & 5 & VinDR-Mammo~\cite{nguyen2022vindrmammo} & FFDM & Breast & 20,000 \\
Bone Age Prediction & 2D & 20 & RSNA Bone Age~\cite{rsnaboneage} & X-Ray & Hand & 14,036 \\
Wrist Fracture Detection & 2D & 2 &  GRAZPEDWRI-DX~\cite{Nagy2022wristfrac} & X-Ray & Wrist & 14,113 \\
Spine Fracture Detection & 3D & 2 &  VerSe~\cite{loffler2020vertebral} & CT & Spine & 160 \\
Head Fracture Detection & 3D & 2 &  CQ500~\cite{chilamkurthy2018development} & CT & Head & 378 \\
ACL \& Meniscal Tear Detection & 3D & 2 &  MRNet~\cite{bien2018deep} & MRI & Knee & 1250  \\
\bottomrule
\end{tabular}
}
}
}
\end{center}
\caption{\textbf{Summary of CAD tasks used for evaluating latent representation quality}. We report the task name, number of classes associated with the task, the dataset name, imaging modality, anatomical features, and the number of images after preprocessing.}
\label{table:clssummary}
\end{table*}


\begin{table*}[t]
%\scriptsize
\centering
\resizebox{\linewidth}{!}
{%\renewcommand{\arraystretch}{1.2}%
\begin{tabular}{ lcccccccc }
\toprule
\textbf{}
& \multicolumn{2}{c}{\textbf{}}
& \multicolumn{5}{c}{\textbf{AUROC} $\uparrow$}
& \textbf{}
\\
\cmidrule(l{3pt}r{0pt}){4-8}
\cmidrule(l{3pt}r{0pt}){9-9}
\textbf{Method}
& \textbf{$f$}
& \textbf{$C$}
& \small Malignancy
& \small Calcification
& \small BI-RADS
& \small Bone Age
& \small Wrist Fracture
& Avg.
\\ 
\midrule
\small High-Resolution & 1 & 1 & \textbf{66.1} & \textbf{62.4} & \textbf{63.4} & \textbf{80.2}  & \textbf{73.7} & \textbf{69.2}\\

\midrule
\small 2D Base Autoencoder (Stage 1) \hspace{0.5mm} & 16 & 3 &  58.7 & 60.5 & 58.0 & 72.0 & 64.3 & 62.7 \\
\small 2D MedVAE (Stage 2) \hspace{0.5mm} & 16 & 3 &   \textbf{66.1} &   \textbf{61.7} & \textbf{62.3} & \textbf{82.1}  &   \textbf{70.6} & \textbf{68.6}\\
\midrule

\small 2D Base Autoencoder (Stage 1) \hspace{0.5mm} & 64 & 4 &   63.4 &  54.4 & 58.6 & 65.7 & 61.9 & 60.8 \\
\small 2D MedVAE (Stage 2) \hspace{0.5mm} & 64 & 4  &  \textbf{64.9} &  \textbf{58.5} & \textbf{60.6} &\textbf{ 73.0} & \textbf{66.7} & \textbf{64.7}\\
\bottomrule
\end{tabular}
}
\caption{\textbf{Effect of each autoencoder training stage on 2D MedVAE latent representation quality.} We evaluate the effects of each stage of 2D MedVAE training on latent representation quality using five 2D CAD tasks.}
\label{table:ablations2d}
\vspace{-1mm}
\end{table*}


\begin{table*}[t]
%\scriptsize
\centering
\resizebox{0.8\linewidth}{!}
{%\renewcommand{\arraystretch}{1.2}%
\begin{tabular}{ lcccccc }
\toprule
\textbf{}
& \multicolumn{2}{c}{\textbf{}}
& \multicolumn{3}{c}{\textbf{AUROC} $\uparrow$}
& \textbf{}
\\
\cmidrule(l{3pt}r{0pt}){4-6}
\cmidrule(l{3pt}r{0pt}){7-7}
\textbf{Method}
& \textbf{$f$}
& \textbf{$C$}
& \small Spine Fractures
& \small Skull Fractures
& \small Knee Injury
& Avg.
\\ 
\midrule
\small High-Resolution & 1 & 1 & \textbf{82.9} & \textbf{63.9} & \textbf{69.9} & \textbf{72.2}\\

\midrule
\small 2D Base Autoencoder (Stage 1) \hspace{0.5mm} & 64 & 1 & 76.1 & 36.6 & 65.0 & 59.2 \\
\small 3D MedVAE (Stage 2) \hspace{0.5mm} & 64 & 1 & \textbf{83.7} & \textbf{87.0} & \textbf{68.4} & {\textbf{79.7}} \\
\midrule

\small 2D Base Autoencoder (Stage 1) \hspace{0.5mm} & 512 & 1 & \textbf{72.5 } & 45.4 & \textbf{68.8} & 62.2 \\
\small 3D MedVAE (Stage 2) \hspace{0.5mm} & 512 & 1  & 72.0 & \textbf{49.1} & 58.2 & 59.8\\
\bottomrule
\end{tabular}
}
\caption{\textbf{Effect of each autoencoder training stage on 3D MedVAE latent representation quality.} We evaluate the effects of each stage of 3D MedVAE training on latent representation quality using three 3D CAD tasks. Since Stage 1 training exclusively involves 2D images, we evaluate this model on 3D tasks by stitching 2D latent representations together across slices such that the size of the 2D latent representation matches those generated by 3D models.}
\vspace{-1mm}
\label{table:ablations3d}
\end{table*}





\begin{table*}[ht]
% \scriptsize
\centering
{%
\begin{tabular}{ lcccccc }
\toprule
\textbf{}
& \multicolumn{2}{c}{\textbf{}}
& \multicolumn{3}{c}{\textbf{AUROC} $\uparrow$}
& \textbf{}
\\
\cmidrule(l{3pt}r{0pt}){4-6}
\cmidrule(l{3pt}r{0pt}){7-7}
\textbf{Method}
& \textbf{$f$}
& \textbf{$C$}
& \small Spine Fractures
& \small Skull Fractures
& \small Knee Injury
& Average
\\ 
\midrule
\small High-Resolution & 1 & 1  & \textbf{82.9$_{\pm2.2}$} & \textbf{63.9$_{\pm6.3}$} & \textbf{69.9$_{\pm0.6}$} & \textbf{72.2}\\

\midrule
\small 2D MedVAE  & 64 & 1  & 80.5$_{\pm4.9}$ & 57.4$_{\pm4.0}$ & 67.3$_{\pm3.6}$ &  68.4\\
\small 2D MedVAE & 64 & 3  & 78.6$_{\pm0.8}$ & 50.9$_{\pm19.5}$ & 60.9$_{\pm4.2}$ &  63.5\\
\small 3D MedVAE & 64 & 1  & \textcolor{blue}{\textbf{83.7$_{\pm2.8}$}} & \textcolor{blue}{\textbf{87.0$_{\pm7.3}$}} & \textbf{68.4$_{\pm2.4}$} & \textbf{79.7}\\
\midrule
\small 2D MedVAE & 512 & 1  & 65.9$_{\pm8.7}$ & \textbf{63.0$_{\pm1.1}$} & 55.9$_{\pm8.3}$ & \textbf{61.6} \\
\small 2D MedVAE  & 512 & 4  & \textbf{81.9$_{\pm1.2}$} & 17.1$_{\pm8.6}$ & 52.6$_{\pm1.9}$ & 50.5 \\
\small 3D MedVAE & 512 & 1  & 72.0$_{\pm3.8}$ & 49.1$_{\pm19.8}$ & \textbf{58.2$_{\pm1.7}$} & 59.8 \\
\bottomrule
\end{tabular}
}
\caption{\textbf{Comparing 2D MedVAE and 3D MedVAE on 3D CAD tasks.} We compare 3D MedVAE with 2D MedVAE models. For 2D MedVAE, we stitch 2D latent representations together across slices such that the size of the 2D latent representation matches those generated by the 3D model. Here, $f$ represents the downsizing factor applied to the 3D volume of the input image and $C$ represents the number of latent channels. The best performing models on each task are bolded. We highlight methods that perfectly preserve clinically-relevant features in \textcolor{blue}{blue}.}
\label{table:2d3dcad}
\vspace{-1mm}
\end{table*}




\begin{table*}[t]
% \scriptsize
\centering
\resizebox{\linewidth}{!}{
\begin{tabular}{lcccccccccccccc}
\toprule
\textbf{Method}
& \textbf{$f$}
& \textbf{$C$}
& \multicolumn{2}{c}{\textbf{Brain MRIs}}
& \multicolumn{2}{c}{\textbf{Head CTs}}
& \multicolumn{2}{c}{\textbf{Abdomen CTs}}
& \multicolumn{2}{c}{\textbf{TS CTs}}
& \multicolumn{2}{c}{\textbf{Lung CTs}}
& \multicolumn{2}{c}{\textbf{Knee MRIs}}
\\
\cmidrule(l{3pt}r{0pt}){4-5}
\cmidrule(l{3pt}r{0pt}){6-7}
\cmidrule(l{3pt}r{0pt}){8-9}
\cmidrule(l{3pt}r{0pt}){10-11}
\cmidrule(l{3pt}r{0pt}){12-13}
\cmidrule(l{3pt}r{0pt}){14-15}
% "
& 
&
& \small PSNR $\uparrow$
& \small MS-SSIM $\uparrow$
& \small PSNR $\uparrow$
& \small MS-SSIM $\uparrow$
& \small PSNR $\uparrow$
& \small MS-SSIM $\uparrow$
& \small PSNR $\uparrow$
& \small MS-SSIM $\uparrow$
& \small PSNR $\uparrow$
& \small MS-SSIM $\uparrow$
& \small PSNR $\uparrow$
& \small MS-SSIM $\uparrow$
\\ 
\midrule
\small 2D MedVAE-Decoder & 64 & 1  & 28.88 & 0.978 & 35.01 & 0.997 & 31.47 & 0.983 & 29.96 & 0.981 & 27.54 & 0.965 & 27.04 & 0.992 \\
\small 3D MedVAE  & 64 & 1 & \textbf{29.52} &\textbf{ 0.983} & \textbf{39.03} & \textbf{0.999} & \textbf{36.61} & \textbf{0.993} & \textbf{31.35} & \textbf{0.987} & \textbf{28.79} & \textbf{0.975} & \textbf{28.25} &\textbf{ 0.994} \\
\midrule
\small 2D MedVAE-Decoder & 512 & 1 & 25.85 & 0.927 & 18.65 & 0.824 & 20.47 & 0.699 & 25.26 & 0.929 & 23.33 & 0.909 & 23.92 & 0.969 \\
\small 3D MedVAE  & 512 & 1 & \textbf{26.23} &\textbf{ 0.937} & \textbf{30.85} & \textbf{0.991} &\textbf{ 29.47} &\textbf{ 0.960} & \textbf{26.34} & \textbf{0.949} & \textbf{24.76} & \textbf{0.934} & \textbf{24.36} & \textbf{0.977} \\

\bottomrule
\end{tabular}
}
\caption{\textbf{Comparisons of 3D MedVAE and 2D MedVAE Decoder.} The 2D MedVAE-Decoder model performs downsizing on individual 2D slices, which are then stitched and interpolated together to form a latent representation of equivalent size to the 3D MedVAE model; we then perform fine-tuning of the decoder using our curated dataset of 3D volumes. We compare perceptual quality of reconstructed volumes across six 3D image types. Here, $f$ represents the downsizing factor applied to the 3D volume of the input image and $C$ represents the number of latent channels. The best performing models on each task are bolded.}
\label{table:decoder}
\end{table*}