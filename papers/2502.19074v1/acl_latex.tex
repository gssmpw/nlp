% This must be in the first 5 lines to tell arXiv to use pdfLaTeX, which is strongly recommended.
\pdfoutput=1
% In particular, the hyperref package requires pdfLaTeX in order to break URLs across lines.

\documentclass[11pt]{article}

% Change "review" to "final" to generate the final (sometimes called camera-ready) version.
% Change to "preprint" to generate a non-anonymous version with page numbers.
\usepackage[preprint]{acl}

% Standard package includes
\usepackage{times}
\usepackage{latexsym}
\usepackage{booktabs}
\usepackage{graphicx}
\usepackage{makecell}
\usepackage{multirow}
\usepackage{caption}
\setlength{\abovecaptionskip}{0pt} % Space above the caption
\setlength{\belowcaptionskip}{0pt} % Space below the caption
% For proper rendering and hyphenation of words containing Latin characters (including in bib files)
\usepackage[T1]{fontenc}
% For including images
\usepackage{caption}  
% For customizing captions
\usepackage{subcaption} % For subfigures Required for inserting images
% For Vietnamese characters
% \usepackage[T5]{fontenc}
% See https://www.latex-project.org/help/documentation/encguide.pdf for other character sets

% This assumes your files are encoded as UTF8
\usepackage[utf8]{inputenc}

% This is not strictly necessary, and may be commented out,
% but it will improve the layout of the manuscript,
% and will typically save some space.
\usepackage{microtype}

% This is also not strictly necessary, and may be commented out.
% However, it will improve the aesthetics of text in
% the typewriter font.
\usepackage{inconsolata}

%Including images in your LaTeX document requires adding
%additional package(s)
\usepackage{graphicx}
\newcommand\sr[1]{\textbf{\textcolor{purple}{SR: #1}}}

%highlighting
\usepackage{xcolor}
%\usepackage[dvipsnames]{xcolor}
\newcommand{\cYellow}{yellow}
\definecolor{darkblue}{rgb}{0.0, 0.05, 0.7} 


\hypersetup{
colorlinks   = true,
linkcolor    = darkblue,
citecolor    = darkblue,
urlcolor    =  darkblue
}
% If the title and author information does not fit in the area allocated, uncomment the following
%
%\setlength\titlebox{<dim>}
%
% and set <dim> to something 5cm or larger.

\title{Improving the quality of Web-mined Parallel Corpora of Low-Resource Languages using Debiasing Heuristics}

% Author information can be set in various styles:
% For several authors from the same institution:
% \author{Author 1 \and ... \and Author n \\
%         Address line \\ ... \\ Address line}
% if the names do not fit well on one line use
%         Author 1 \\ {\bf Author 2} \\ ... \\ {\bf Author n} \\
% For authors from different institutions:
% \author{Author 1 \\ Address line \\  ... \\ Address line
%         \And  ... \And
%         Author n \\ Address line \\ ... \\ Address line}
% To start a separate ``row'' of authors use \AND, as in
% \author{Author 1 \\ Address line \\  ... \\ Address line
%         \AND
%         Author 2 \\ Address line \\ ... \\ Address line \And
%         Author 3 \\ Address line \\ ... \\ Address line}

% \author{Aloka Fernando \\
% Dept. of Computer Science and Engineering, University of Moratuwa,10400, Sri Lanka \\
% Affiliation / Address line 2 \\
% Affiliation / Address line 3 \\
% \texttt{email@domain} \\\And
% Surangika Ranathunga \\
% Affiliation / Address line 1 \\
% Affiliation / Address line 2 \\
% Affiliation / Address line 3 \\
% \texttt{email@domain} \\
% Nisansa de Silva \\
% Dept. of Computer Science and Engineering, /University of Moratuwa,/10400, Sri Lanka \\
% Affiliation / Address line 2 \\
% Affiliation / Address line 3 \\
% \texttt{email@domain} \\}

\author{
 \textbf{Aloka Fernando\textsuperscript{1}},
 \textbf{Surangika Ranathunga \textsuperscript{2}},
 \textbf{Nisansa de Silva\textsuperscript{1}}
\\
\texttt{\{alokaf,NisansaDdS\}@cse.mrt.ac.lk}
\\
\texttt{s.ranathunga@massey.ac.nz}
\\
\textsuperscript{1}Dept. of Computer Science and Engineering, University of Moratuwa,10400, Sri Lanka\\
 \textsuperscript{2}Massey University, Palmerston North, New Zealand, 4443
\\
 \small{
   \textbf{Correspondence:} \href{mailto:alokaf@cse.mrt.ac.lk}{alokaf@cse.mrt.ac.lk}
 }
}

\begin{document}
\maketitle
\begin{abstract}
Parallel Data Curation (PDC) techniques aim to filter out noisy parallel sentences from the web-mined corpora. Prior research has demonstrated that ranking sentence pairs using similarity scores on sentence embeddings derived from Pre-trained Multilingual Language Models (multiPLMs) and training the NMT systems with the top-ranked samples, produces superior NMT performance than when trained using the full dataset. However, previous research has shown that the choice of multiPLM significantly impacts the ranking quality. This paper investigates the reasons behind this disparity across multiPLMs. Using the web-mined corpora CCMatrix and CCAligned for En$\rightarrow$Si, En$\rightarrow$Ta and  Si$\rightarrow$Ta, we show that different multiPLMs (LASER3, XLM-R, and LaBSE) are biased towards certain types of sentences, which allows noisy sentences to creep into the top-ranked samples. We show that by employing a series of heuristics, this noise can be removed to a certain extent. This results in improving the results of NMT systems trained with web-mined corpora and reduces the disparity across multiPLMs. 
\end{abstract}

\section{Introduction}\label{sec:introduction}
Parallel data mined from the web at scale is often considered an alternative to human-created data, in training Neural Machine Translation (NMT) models~\cite{costa2022nllb,banon2020paracrawl}. CCAligned~\cite{el2020ccaligned}, CCMatrix~\cite{schwenk2021ccmatrix} and ParaCrawl~\cite{banon2020paracrawl} are examples of such web-mined corpora, which cover Low-Resource Languages (LRLs) as well. However, web-mined parallel data is noisy~\cite{koehn2020findings}, which adversely affects the NMT performance ~\cite{khayrallah2018impact}.

Parallel Data Curation (PDC) aims to filter noisy parallel sentences from such web-mined parallel corpora. Initiated by the work of ~\citet{chaudhary2019low}, it was proven that obtaining embeddings from a Pre-trained Multilingual Language Model (multiPLM) to calculate the similarity score, and training the NMT system with the top-ranked sentence pairs leads to improved results, compared to training the NMT system with the full corpus. However,~\citet{ranathunga2024quality,moon2023doubts}  showed that the NMT performance depends on the multiPLM used to rank the parallel sentences.

In order to further investigate how the selection of multiPLM affects the NMT performance, we ranked CCMatrix~\cite{schwenk2021ccmatrix} and CCAligned~\cite{el2020ccaligned} corpora for the LRL pairs En$\rightarrow$Si, En$\rightarrow$Ta, and Si$\rightarrow$Ta language pairs, using three multiPLMs: LASER3~\cite{heffernan2022bitext}, XLM-R~\cite{conneau2020xlmr} and LaBSE~\cite{feng2022language}. Then we trained NMT systems using the top 100k sentences of each of these ranked corpora. As shown in Figure~\ref{fig:disparity}, we observed that there is a significant disparity among the NMT results, which were trained with the ranked corpora using different multiPLMs, specifically for En$\rightarrow$Si and En$\rightarrow$Ta.

\begingroup
\setlength{\abovecaptionskip}{0pt}
\setlength{\belowcaptionskip}{0pt}
\begin{figure}[h]%
\centering
\includegraphics[trim={0cm 0cm 0cm 0cm}, clip, width=0.45\textwidth]{images/Fig1_baseline_disparity.png}
\vspace{1mm}
\caption{Baseline NMT scores by utilizing LASER3, XLM-R and LaBSE multiPLMs for ranking CCMatrix and CCAligned web mined corpora.}\label{fig:disparity}
\end{figure}
\endgroup

In order to investigate the cause for this disparity, we randomly selected 100 sentence pairs from the top 100k sentences obtained to train the aforementioned NMT system and carried out a human evaluation. We employed the error taxonomy established by \citet{ranathunga2024quality} and found that different multiPLMs tend to prioritize on certain inherent characteristics when ranking parallel sentences. As shown in Table~\ref{tab:examples_noisy_parallel_sentences} certain types of such sentences are considered as noise for the NMT systems, by the existing work. 

%noise types
\begin{table*}[ht]
\centering
\begin{tabular}{c}
\includegraphics[width=0.9\linewidth]{images/HE_noise_examples.pdf}\\
\end{tabular}
\caption{Example parallel sentences from the En-Si and En-Ta language pairs belong to noise classes~\cite{ranathunga2024quality}, identified during human evaluation.}
\label{tab:examples_noisy_parallel_sentences}
\end{table*}

We can hypothesize that if such noisy sentences are removed from the web-mined parallel corpora, the quality of the corpus would improve, which would, in turn, improve the NMT output. Applying heuristics has been a common solution to improve the quality of parallel corpora~\cite{sloto2023findings,steingrimsson2023filtering}. In this research, we incorporate heuristics proposed in previous studies, along with several of our own, to investigate whether a more refined selection of top-ranked parallel sentences can be obtained. We find that a combination of a subset of these heuristics provides the best NMT result across the web-mined corpora for the language pairs we selected. Further, we observe that the disparity caused by these multiPLMs is significantly reduced, making the NMT results comparable. The subsequent human evaluation on the heuristic based filtered corpus, further confirms that the percentage of the quality parallel sentences has increased by a substantial margin.

Our key contributions are as follows:

\begin{itemize}
    \item We are the first to carry out a comparative Human evaluation, to analyse the noise distribution in the top-ranked samples obtained using different, multiPLMs namely, LASER3, XLM-R and LaBSE. We suggest that the retained noise reflects the bias inherent in the multiPLMs.     
    \item We introduce new heuristics to augment the existing heuristics and show that these heuristics contribute to improving the downstream NMT performance significantly.
    \item We identify the optimal combination of heuristics for PDC via a series of ablation studies. Additionally, we observe that the optimal heuristic combination reduces the disparity among NMT systems, brought in by the utilized multiPLM.
\end{itemize}

\section{Related Work}\label{sec:related_work}

%Parallel data mining from web is aimed at alleviating the data scarcity problem for LRLs. However, the quality audits~\cite{ranathunga2024quality,bane2022comparison} conducted on such data revealed that the parallel data is noisy.~\citet{khayrallah2018impact} showed that NMT systems are sensitive to noise and hence a line of research evolved to filter out noise from such parallel data~\cite{sloto2023findings,bucc-2024-building}. 
%~\cite{costa2022nllb,banon2020paracrawl,schwenk2021ccmatrix}
%A summary of the noise categories they have considered in their work is shown in Table~\ref{tab:noise_categories}.

%Early works of PDC techniques focused on using language-agnostic shallow heuristics for filtration~\cite{koehn2005europarl}. Alternatively, more recent PDC techniques have been deep learning-based. Among them, NMT-based scoring~\cite{junczys2018dual} and multiPLM-based scoring~\cite{chaudhary2019low} mechanisms were prominent. It could be observed that the latter was more reliable for LRLs, while the former was most suitable for high-resource language pairs. Other existing work trained a classifier~\cite{accarcciccek2020filtering}, used translation phrase-tables~\cite{minh2023fast} and combinations of the above techniques~\cite{steingrimsson2023filtering,lu2020alibaba} in the PDC task.

%\subsection{multiPLM-based Parallel Data Curation}

In multiPLM-based PDC~\cite{sloto2023findings,haddad2023proceedings,koehn2020findings}, first, the parallel sentences are ranked in descending order using a similarity score calculated between the source and target sentence embeddings obtained from the multiPLM. Then the top-ranked parallel sentence pairs are used to train the NMT system, yielding superior results compared to training with the full corpus. %However, the selection of multiPLMs in related PDC studies remains a subject of debate. \\ 

%In the WMT2023 shared task, LASER2~\cite{artetxe2019massively} was utilized by the task organizers to set the baseline NMT scores, whereas~\citet{steingrimsson2023sentence} implemented a filtration pipeline using LaBSE~\cite{feng2022language}. Additionally,~\citet{gala2023indictrans2} employed LaBSE instead of LASER3 for their filtration task, when both multiPLMs supported the language pairs under consideration. However, the rationale for the choice of multiPLM in the PDC, and its impact on the NMT performance had not been studied in-depth.

While the common practice is to simply use of one those multiPLMs to derive sentence representations~\citet{steingrimsson2023sentence,gala2023indictrans2},\citet{ranathunga2024quality} showed that NMT results vary when they are trained using the samples (top, bottom and random) obtained from a ranked parallel corpora with LASER3, XLMR, and LaBSE. Overall, the top sample produced superior NMT results when trained with the LASER3 ranked corpus. On the other hand, \citet{moon2023doubts} used LASER3 and LaBSE, for scoring and observed that the topmost sample was biased towards certain characteristics of the dataset, such as short sentences, high overlapping of untranslated text~\cite{herold2022detecting} etc. From the NMT perspective, such sentences are considered as noise and they adversely affect the NMT performance.

\subsection{Noise in the web-mined Parallel Data}
Human quality audits conducted by ~\citet{khayrallah2018impact,kreutzer2022quality} have provided insights into the types of noise present in web-mined corpora. Alternatively,~\citet{ranathunga2024quality,bane2022comparison} have conducted human audits to quantify the noise that was present in the ranked corpora using multiPLMs. All such noise classes identified during these works are summarized in Table~\ref{tab:flt_heuristics}.\\

%Identified noise classes
\begin{table}[h]\centering
\scriptsize
\renewcommand{\arraystretch}{1.3}
\resizebox{0.45\textwidth}{!}{%
\begin{tabular}{lrrrrr}
\toprule
Noise Type &\rotatebox{90}{\citet{khayrallah2018impact}} &\rotatebox{90}{\citet{bane2022comparison}} &\rotatebox{90}{\citet{herold2022detecting}} &\rotatebox{90}{\citet{kreutzer2022quality}} &\rotatebox{90}{\citet{ranathunga2024quality}} \\
\midrule
Deduplication - Identical & -& -& -&Y &Y\\
Misaligned sentences &Y &Y &Y &Y &Y\\
Misordered words &Y &Y &Y &Y &Y\\
Spelling permutations & -&Y & -&Y &Y\\
Wrong Language &Y &Y &Y &Y &Y\\
Untranslated Sentences &Y &Y &Y & -&Y\\
Short Sentences &Y & -&Y & -&-\\
Over/Under translation & -&Y &Y &Y&-\\
Mismatch numbers & &Y & -& -&-\\
Machine Translated Sentences & -& -&Y &Y &-\\
Not a language* & -& -& -&Y &Y\\
Correct translation - Short & -& -& -&Y &Y\\
Correct translation - Low quality & -&Y & -&Y &Y\\
Perfect translations & -& -& -&Y &Y\\
Near perfect translation & -& -& -& -&Y\\
\hline
\end{tabular}}
\vspace{1mm}
\caption{Summarized noise classes in existing work.}\label{tab:flt_heuristics}
\end{table}

\section{Heuristic-based PDC}\label{sec:heuristic_based_pdc}
Heuristics were employed in the PDC to eliminate noise in the web-mined corpora based on rules~\cite{costa2022nllb,gala2023indictrans2} or using statistical models ~\cite{gale1994program,zhang2020parallel,steingrimsson2023filtering}. Despite the widespread use of heuristics in the PDC tasks, their impact on downstream NMT tasks remains understudied and unquantified. To our knowledge, no prior work has systematically assessed their impact. This research addresses this critical gap through a comprehensive empirical study.

Table~\ref{tab:flt_heuristics} lists the commonly used heuristics. These can be broadly categorized into four distinct \textbf{heuristic classes}.\\

\noindent\textbf{De-duplication: }It is a common practice to remove identical duplicates in the monolingual sides before filtration~\cite{costa2022nllb}. On the parallel sentences, identical sentence de-duplication~\cite{costa2022nllb}, de-duplicating after removing non-alpha characters and punctuations~\cite{bala2023improving} had been considered in the existing work. On top of these deduplication techniques (i.e.~identical sentence de-duplication (\textit{dedup}), de-duplicate by removing numbers only (\textit{nums}) and removing both numbers and punctuations (\textit{punctsNums})) have been considered by~\citet{gala2023indictrans2}, we introduce de-duplication based on consecutive word n-grams. \\

\noindent\textbf{Length-based : }~\citet{gala2023indictrans2,aulamo2023unsupervised} have employed removal of short sentences \textit{(sLen)}. In our work, we also select these heuristics and analyse the impact of filtering short sentences.

\noindent\textbf{LID-based : } Language (\textbf{L}) Identification (\textbf{ID}) heuristics have been employed to eliminate untranslated text and content in the wrong language, either fully or partially~\cite{steingrimsson2023filtering,gala2023indictrans2,zhang2020parallel}. \\


\noindent\textbf{Ratio-based :} Since the early work of~\cite {gale1993program}, ratio-based heuristics~\cite{minh2023fast,aulamo2023unsupervised} have been commonly employed in the PDC pipeline. We considered (1) source-to-target sentence length ratio \textit{(STRatio)} (2) alpha only words to sentence words ratio \textit{(sentWRatio)} and (3) alpha-only character ratio \textit{(sentCRatio)} with respective to the sentence characters as heuristics under this class. 

Finally we use combination of the heuristics to find the optimal gain.

\section{Experiments}\label{sec:experiments}
\textbf{Data} We use the language pairs, En$\rightarrow$Si, En$\rightarrow$Ta, and Si$\rightarrow$Ta. Sinhala and Tamil are morphologically rich low-resource and mid-resourced languages~\cite{joshi2020state, ranathunga2022some} respectively. Further, Sinhala, Tamil and English belong to three distinct language families Indo-Aryan, Dravarian and Indo-European. 

We use CCMatrix~\cite{schwenk2021ccmatrix} and CCAligned~\cite{el2020ccaligned} as the web-mined corpora. These web-mined corpora are reported to be noisy~\cite{van2025quality}, especially for LRLs. Additionally, we selected CCMatrix and CCAligned, since they have parallel data for the considered language pairs.  Appendix~\ref{sec:appendixLangsDatasets} contains details on the chosen languages and the corpora in this study.

We apply the heuristics and sample the top 100k parallel sentences to train the NMT systems. As the validation and evaluation sets, we use the dev and devtest subsets from  FLORES+\footnote{https://github.com/openlanguagedata/flores}. The dataset statistics are in Table~\ref{tab:dataset_stats}.

%corpus statistics
\begin{table}[!htp]\centering
\scriptsize
\renewcommand{\arraystretch}{1.35}
\resizebox{0.45\textwidth}{!}{%
\begin{tabular}{lrrrrr}
\hline
\textbf{Language-pair} &\textbf{CCMatrix} &\textbf{CCAligned} &\textbf{dev} &\textbf{devtest} \\\midrule
En-Si &6270801 &619711 &997 &1012 \\
En-Ta &7291119 &880547 &997 &1012 \\
Si-Ta &215966 &260118 &997 &1012 \\
\bottomrule
\end{tabular}}
\caption{Corpus statistics of CCMatrix and CCAligned full datasets. The counts are the total number of sentences per language pair in each of the splits.}\label{tab:dataset_stats}
\end{table}

\subsection{Selection of muliPLMs}
We selected LASER3~\cite{heffernan2022bitext}, XLM-R~\cite{conneau2020xlmr} and LaBSE~\cite{feng2022language} multiPLMs for deriving embeddings to calculate the cosine similarity to obtain the semantic similarity between parallel sentences. The rationale for selecting these multiPLMs along with details has been included in Appendix~\ref{sec:AppendixCMultiPLMs}.


\subsection{Baselines}
The baseline scores were obtained by training NMT systems using the top-ranked 100,000 sentence pairs considering the embeddings obtained from LASER3, XLM-R and LaBSE multiPLMs. 

\subsection{Heuristic-based PDC Experiments}
In our initial ablation study, first, we apply each heuristic in isolation, to filter the parallel corpora. \\

\noindent\textbf{Deduplication}: We consider different granularities of de-duplication. ie. Identical de-duplication \textit{(dedup)}, de-duplicate by removing numbers only (\textit{nums}) and removing both numbers and punctuations (\textit{punctsNums})). Subsequently, we de-duplicate considering different n-gram spans ie. 4-grams, 5-grams, 6-grams and 7-grams. \\

\noindent\textbf{Length-based:} We filter sentences less than 5 words. We have selected this threshold, based on existing work. \\

\noindent\textbf{LID-based:}
 We used the LID model\footnote{https://github.com/facebookresearch/fairseq/tree/nllb} with a threshold of 0.7 \textit{(LIDThresh)}\footnote{Thresholds less than 0.7 returned degraded NMT results.} to identify quality sentences in the respective language and to filter those out if found otherwise.\\

\noindent\textbf{Ratio-based:} For each ratio-based heuristic, \textit{(STRatio)}, \textit{(sentWRatio)} and \textit{(sentCRatio)}, the filtration threshold was considered as 0.6\footnote{The threshold less than 0.5 returned degraded NMT performance.}.


Each heuristic is initially applied to the source side (S), target side (T) and both sides (ST) and we evaluate the impact on the NMT system.(Section~\ref{sec:heuristic_based_pdc}). Then from the filtered corpora, we select the top 100,000 sentences, which were ranked using the multiPLMs and trained the NMT systems. Secondly, we combine these heuristics and run ablation experiments to finalise the optimal combination of heuristics returning the best NMT scores.  


\subsection{NMT Experiments}
First a Sentencepiece\footnote{https://github.com/google/sentencepiece} tokenizer with a vocabulary size of 25000 is trained. Then we use the fairseq toolkit ~\citep{ott2019fairseq} to model and train the transformer-based Sequence-to-Sequence NMT model until convergence. The hyper-parameters used in these NMT experiments are shown in Table~\ref{tab:nmt_hyperparameters} in Appendix~\ref{sec:AppendixNMTExperiments}. We use ChrF++~\cite{popovic2017chrfpp} metric to report NMT results. 


\section{Human Evaluation}

We carry out a human evaluation in two stages: before and after applying heuristics.\\ % Our human evaluation has two main objectives. The first objective is to quantify the noise in the parallel corpora, which were ranked using the embeddings obtained by the multiPLMs. Secondly, we quantify the qualitative improvement in the top-ranked sample, after employing the heuristic-based PDC on the same corpora. \\

\noindent \textbf{Process : }We selected a total of nine professional translators, ensuring three translators per language pair for the evaluation. %In addition to their professional translation experience, they had prior experience working on various parallel corpora tasks related to machine translation projects. Therefore, their expertise and experience contribute to a high-quality and reliable evaluation process.

From the top 100k samples in each of the ranked corpus using LASER3, XLM-R and LaBSE, we randomly selected 100 parallel sentences for each language pair. Using the error taxonomy by~\citet{ranathunga2024quality} (Appendix~\ref{sec:AppendixHumanEvaluation} Table~\ref{tab:HE_error_taxonomy}) we asked each translator to select an annotation category for each sentence pair. Each sentence pair was annotated by three translators to reduce human error and mitigate any potential bias caused by the individual translators.

\section{Results and Analysis}\label{sec:results}
%In this section, we report the results obtained for the NMT experiments for the three language pairs En$\rightarrow$Si, En$\rightarrow$Ta and Si$\rightarrow$Ta and discuss the impact of the heuristic-based PDC on the final NMT performance. The results of the ablation experiments can be found in Table~\ref{tab:results_full_table} in Appendix~\ref{sec:AppendixNMTExperiments} for the three language pairs.


\subsection{Disparity in NMT Results}

As evident from Figure~\ref{fig:disparity} and Table~\ref{tab:results_full_table} in Appendix~\ref{sec:AppendixNMTExperiments}, the results across different multiPLMs show a great disparity in the baseline NMT scores. For En$\rightarrow$Si and En$\rightarrow$Ta language pairs, this is significant. However, between Si$\rightarrow$Ta languages, the disparity is minimal. \\ 
The following observations were made when analysing the top-ranked sentences: Parallel sentence pairs ranked top by XLM-R are mostly short and contain overlapping text - mainly numbers, acronyms, URLs etc. In contrast, LaBSE favors sentences with numbers and date overlaps, while LASER3 selects sentences that are mainly textual. The impact of the nature of the top-ranked sentences is evident in Figure~\ref{fig:disparity}, where results related to LASER3 outperform its two counterparts by a significant margin, in most of the experiments. 


%As observe that the top-ranked sentence pairs obtained using XLM-R and LaBSE tend to contain less textual content, which contributes to degraded NMT performance. In contrast, LASER3 yields superior results, as its top-ranked sentence pairs contain more textual content, which better supports the NMT system in learning the sequence-to-sequence mappings.

\subsection{Impact of the Heuristic Classes on the NMT Performance}

In this section, we take each heuristic class and discuss its impact on the PDC task. The full results table is shown in Table~\ref{tab:results_full_table} in Appendix~\ref{sec:AppendixNMTExperiments}.\\

\subsubsection{Impact of De-duplication based PDC}

With de-duplication-based PDC, we obtain the best gains for XLM-R, LaBSE and LASER3 as +18.57, +11.82 and +2.91 ChrF++ points for CCAligned En$\rightarrow$Ta, CCMatrix En$\rightarrow$Si and CCAligned En$\rightarrow$Si respectively.     

Secondly, the NMT results show that de-duplication on the target side improves the NMT performance, than on the source side. However, de-duplicating both the source and target sides improves the results further. 

In line with the existing work, while identical de-duplication leads to improved NMT results, de-duplication with numbers and punctuations improves these gains further for the majority of the cases. Our proposed de-duplication based on n-grams (ie. \textit{dedup+punctNums+ngrams}), shows ChrF++ gains ranges between, (+0.9 - +1.27), (+0.18 - +2.53) and (+0.10 - +5.28) for Si$\rightarrow$Ta, En$\rightarrow$Si and En$\rightarrow$Ta  language pairs respectively, over \textit{dedup+punctNums}. However, the exact n-gram sequence that resulted in the best gains was dependent on the corpus characteristics. The NMT scores for each corpus and each language pair are shown in Figure~\ref{fig:scores_dd} while the absolute values are available in Table~\ref{tab:results_full_table} in Appendix~\ref{sec:AppendixNMTExperiments}.

%Applying the proposed granularity in this work, which is n-gram based de-duplication, on top of \textit{dedup-punctNums}, we observed that \textit{dedup+punctNums+ngram} produced the highest gains except CCMatrix En$\rightarrow$Ta direction and CCAligned Si$\rightarrow$Ta directions. Further, the best ChrF++ gains vary from (+1.77 to +18.57), (+2.91 to +10.94) and (+1.77 to +18.57) for En$\rightarrow$Ta, En$\rightarrow$Si and Si$\rightarrow$Ta language pairs. Compared to other heuristic classes, PDC using de-duplication is more impactful to improve the final NMT performance.


\begin{figure}[h]
    \centering
    % First row of images
    \begin{subfigure}{0.225\textwidth}        \includegraphics[width=\linewidth]{images/sita_ccmatrix.pdf}
        \caption{SiTa - CCMatrix}
        \label{fig:image1}
    \end{subfigure}
    \hfill
    \begin{subfigure}{0.225\textwidth}        \includegraphics[width=\linewidth]{images/sita_ccaligned.pdf}
        \caption{SiTa - CCAligned}
        \label{fig:image2}
    \end{subfigure}
    \hfill
    \begin{subfigure}{0.225\textwidth}        \includegraphics[width=\linewidth]{images/ensi_ccmatrix.pdf}
        \caption{EnSi - CCMatrix}
        \label{fig:image3}
    \end{subfigure}    
    %\vspace{0.5cm} 
    % Space between rows
    % Second row of images
    \begin{subfigure}{0.225\textwidth}        \includegraphics[width=\linewidth]{images/ensi_ccaligned.pdf}
        \caption{EnSi - CCAligned}
        \label{fig:image4}
    \end{subfigure}
    \hfill
    \begin{subfigure}{0.225\textwidth}       \includegraphics[width=\linewidth]{images/enta_ccmatrix.pdf}
        \caption{EnTa - CCMatrix}
        \label{fig:image5}
    \end{subfigure}
    \hfill
    \begin{subfigure}{0.225\textwidth}     \includegraphics[width=\linewidth]{images/enta_ccaligned.pdf}
        \caption{EnTa - CCAligned}
        \label{fig:image6}
    \end{subfigure}
    \vspace{1mm}
    \caption{The ChrF++ scores for NMT systems based on different granularities of de-duplication. BL - Baseline, DD- Identical De-duplication, ngram - n-gram based de-duplication, N - de-duplication after removing numbers, PN - de-duplication after removing numbers and punctuations.}\label{fig:scores_dd}
\end{figure}

\subsubsection{Impact of Length-Based 
 PDC}
%As shown in Figure~\ref{fig:gains_slength}, we analyse the ChrF++ gains produced between the baseline NMT system and the highest NMT score produced utilizing the LASER3, XLM-R and LaBSE ranked corpus when applying \textit{slength} heuristic. 
We show gains obtained with length-based PDC in Figure~\ref{fig:gains_slength}. Here also, we could observe significant gains for XLM-R and LaBSE ranked corpora for En$\rightarrow$Si and En$\rightarrow$Ta language pairs. The best gains are +15.27 and +12.08 ChrF++ points for XLM-R and LaBSE-ranked corpora. However, for the Si$\rightarrow$Ta language pair, the ChrF++ gains are marginal and are in the ranges of (+0.33 to +1.11) ChrF++ points. Here too we can observe that removing short sentences has benefited to improve NMT performance and to reduce the disparity among the multiPLM ranked corpora.  

\begin{figure}[h]%
\centering
\includegraphics[width=0.45\textwidth]{images/Fig_sLength.pdf}
\vspace{1mm}
\caption{ChrF++ gains of NMT systems for CCMatrix and CCAligned web mined corpora.}\label{fig:gains_slength}
\end{figure}

\subsubsection{Impact of LID-Based 
 PDC} With LID-based PDC, the best gains for NMT experiments were +10.57, +13.58 and +11.40 with LASER3, XLM-R and LaBSE multiPLMs for CCMatrix-EnTa, CCAligned-EnTa and CCAligned-EnTa corpora respectively. We observed that LID with threshold returned superior results compared to LID-only PDC across all other corpora and language pairs, except for CCMatrix Si$\rightarrow$Ta with LaBSE ranked corpus. Further, we observe that with CCAligned corpus across all three language pairs, the multiPLM ranked corpora produce comparable results. However with CCMatrix, XLM-R and LaBSE scores were still lagging for En$\rightarrow$Si and En$\rightarrow$Ta directions. The results can be visualized in Figure~\ref{fig:LID_results}, while the absolute results are available in Table~\ref{tab:results_full_table} in Appendix~\ref{sec:AppendixNMTExperiments}. 
 
\begin{figure}[h]
    \centering
    % First row of images
    \begin{subfigure}{0.45\textwidth}        \includegraphics[width=\linewidth]{images/Fig_sita_LID.pdf}
        \caption{SiTa}
        \label{fig:image1}
    \end{subfigure}
    \hfill
    \begin{subfigure}{0.45\textwidth}   \includegraphics[width=\linewidth]{images/Fig_ensi_LID.pdf}
        \caption{EnSi}
        \label{fig:image2}
    \end{subfigure}
    \hfill
    \begin{subfigure}{0.45\textwidth}  \includegraphics[width=\linewidth]{images/Fig_enta_LID.pdf}
        \caption{EnTa}
        \label{fig:image3}
    \end{subfigure}  
    \caption{ChrF++ gains of NMT systems trained with the top 100,000 sentences with LASER3, XLM-R and LaBSE ranked CCMatrix and CCAligned web mined corpora. Here the PDC was using LID and LID with a threshold of 0.7.}\label{fig:LID_results}
\end{figure}

\subsubsection{Impact of Ratio-based PDC}
As described in Section~\ref{sec:heuristic_based_pdc}, out of the ratio-based PDC, \textit{sentWRatio} consistently reported the best NMT results for CCAligned corpus with LASER, XLM-R and LaBSE ranking. But with CCMatrix, as shown in Table~\ref{tab:results_ratios}, although there was no clear winner, the \textit{sentWRatio} results were comparable with the best score under this category in most of the cases. We suspect that the other noise types in the corpus may be prominent for the XLM-R and LaBSE to under-perform in case of En$\rightarrow$Si and En$\rightarrow$Ta language pairs.  

\begin{table}[!htp]\centering
\renewcommand{\arraystretch}{1.35}
\resizebox{0.45\textwidth}{!}{%
\scriptsize
\begin{tabular}{lrrrrrrr}\toprule
\multirow{2}{*}{} &\multicolumn{3}{c}{\textbf{CCMatrix}} &\multicolumn{3}{c}{\textbf{CCAligned}} \\\cmidrule{2-7}
&\textbf{LASER3} &\textbf{XLM-R} &\textbf{LaBSE} &\textbf{LASER3} &\textbf{XLM-R} &\textbf{LaBSE} \\\midrule
\multicolumn{7}{c}{\textbf{Sinhala-Tamil}} \\
\hline
Baseline &31.08 &30.99 &31.63 &35.36 &35.97 &35.79 \\
STRatio &31.74 &22.80 &31.34 &36.39 &35.74 &35.30 \\
sentWRatio &31.93 &31.59 &32.03 &\textbf{36.44} &\textbf{36.72} &\textbf{36.46} \\
sentCRatio &\textbf{32.28} &\textbf{31.90} &\textbf{32.04} &36.36 &36.18 &36.11 \\
\hline
\multicolumn{7}{c}{\textbf{English-Sinhala}} \\
\hline
Baseline &30.76 &5.55 &14.49 &32.33 &19.39 &27.57 \\
STRatio &31.09 &5.20 &15.40 &33.47 &24.05 &30.21 \\
sentWRatio &\textbf{31.50} &\textbf{7.40} &\textbf{15.50} &\textbf{34.15} &\textbf{28.73} &\textbf{31.35} \\
sentCRatio &30.85 &7.05 &15.28 &34.06 &23.84 &30.10 \\
\hline
\multicolumn{7}{c}{\textbf{English-Tamil}} \\
\hline
Baseline &19.02 &5.86 &14.20 &40.13 &17.40 &26.00 \\
STRatio &\textbf{20.52} &5.40 &\textbf{18.29} &40.91 &22.71 &28.61 \\
sentWRatio &19.42 &5.79 &14.08 &\textbf{42.05} &\textbf{30.88} &\textbf{35.77} \\
sentCRatio &19.90 &\textbf{6.78} &13.83 &41.76 &22.48 &30.82 \\
\bottomrule
\end{tabular}}
\vspace{2mm}
\caption{ChrF++ gains of NMT systems trained with the top 100,000 sentences from the filtered corpora. The ratio-based PDC has been applied to the LASER3, XLM-R and LaBSE-ranked CCMatrix and CCAligned web-mined corpora.}\label{tab:results_ratios}
\end{table}

\subsection{Summary of Heuristic-based PDC}

\textit{1. Impact of the Individual Heuristics on the NMT Experiments}\\
In summary, n-gram based de-duplication on top of de-duplicated sentence-pairs after removing punctuations and numbers \textit{(dedup+puntsNum+ngrams)}, short sentences~\textit{(sLength)}, LID with threshold~\textit{(LIDThresh)} and PDC with word-to-sentence ratio~\textit{(sentWRatio)} are effective on its own to reduce the disparity among the NMT systems trained using the ranked corpora with the three multiPLMs. Although there are exceptional cases, those are mainly due to the inherent characteristics of the dataset.
As an individual heuristic, we observe from CCAligned corpus that \textit{LIDThresh} is more impactful and the sentence length~\textit{(sLength)} based PDC. However, for CCMatrix it was mainly the \textit{dedup+punctNums+ngram}. Therefore, we consider this to be the third most prominent heuristic when sentences in the corpus are in the wrong language, and short sentences have a lesser impact.\\
 
\noindent\textit{2. Impact of Combined Heuristics on the NMT Performance}\\
For En$\rightarrow$Si language pair the heuristic combination with \textit{dedup+punctsNum+5gram+sLength+\\
LIDThresh+sentWRatio} performs best. Further, we can observe that the overall highest gains of +18.63, +19.45 and +5.34 were returned for NMT systems trained with XLM-R, LaBSE and LASER3 multiPLMs. 

For En$\rightarrow$Ta and Si$\rightarrow$Ta language pairs, the best results were given when \textit{sentWRatio}, \textit{STRatio} or \textit{sentCRatio} was combined with \textit{dedup+punctsNum+5gram+sLength+LIDThresh}. As shown in Table~\ref{tab:results_summary}, for En$\rightarrow$Ta language pair, the combined heuristics produce a gain of +24.34, +16.02 and +3.34 with XLM-R, LaBSE and LASER3 multiPLM ranked corpora. In conclusion, we observe that the disparity is minimized significantly with the final scores. The results suggest that a combination of deduplication, language identification thresholding, sentence length filtering, and ratio-based filtering is highly effective apply during the PDC irrespective of the multiPLM being selected.

%Summarized results
\begin{table*}[!htb]\centering
\scriptsize
\renewcommand{\arraystretch}{1.35}
\resizebox{1.0\textwidth}{!}{%
\begin{tabular}{lrrrlrrr}
\toprule
\multirow{2}{*}{\textbf{Heustics}} &\multicolumn{3}{c}{\textbf{CCMatrix}} &\multirow{2}{*}{\textbf{Heustics}} &\multicolumn{3}{c}{\textbf{CCAligned}} \\\cmidrule{2-4}\cmidrule{6-8}
&\textbf{LASER3} &\textbf{XLM-R} &\textbf{LaBSE} & &\textbf{LASER3} &\textbf{XLM-R} &\textbf{LaBSE} \\
\hline
\multicolumn{8}{l}{\textbf{Sinhala$\rightarrow$Tamil}} \\
\hline
Baseline &31.08 &30.99 &31.63 &Baseline &35.36 &35.97 &35.79 \\
dedup+puntsNums+5gram &\textbf{32.98} &\textbf{32.73} &\textbf{32.60} &LIDThresh &\textcolor{gray}{36.73} &\textcolor{gray}{36.73} &\textcolor{gray}{36.80} \\
dedup+punctsNum+5gram+sLength+sentCharRatio &31.45 &\textbf{\textcolor{gray}{32.65}} &31.17 &dedup+punctsNum+7gram+sLength+sentWRatio &36.60 &\textbf{36.85} &36.32 \\
dedup+punctsNum+5gram+sLength+LIDThresh+sentCharRatio &\textbf{\textcolor{gray}{32.64}} &31.30 &\textbf{\textcolor{gray}{32.28}} &dedup+punctsNum+7gram+sLength+LIDThresh+sentWRatio0.8 &\textbf{36.83} &36.66 &\textbf{37.54} \\
\textbf{\textcolor{teal}{Gains}} &\textbf{\textcolor{teal}{+1.56}} &\textbf{\textcolor{teal}{+1.66}} &\textbf{\textcolor{teal}{+0.65}} &\textbf{\textcolor{teal}{Gains}} &\textbf{\textcolor{teal}{+1.47}} &\textbf{\textcolor{teal}{+0.88}} &\textbf{\textcolor{teal}{+1.75}} \\
\hline
\multicolumn{8}{l}{\textbf{English$\rightarrow$Sinhala}} \\
\hline
Baseline &30.76 &5.55 &14.49 &Baseline &32.33 &19.39 &27.57 \\
dedup+puntsNums+5gram &\textbf{\textcolor{gray}{34.50}} &\textbf{\textcolor{gray}{16.09}} &25.78 &LIDThresh (S) &\textbf{\textcolor{gray}{35.73}} &30.86 &32.69 \\
sLength &32.82 &8.24 &\textbf{\textcolor{gray}{29.96}} &LIDThresh (ST) &35.11 &\textbf{\textcolor{gray}{32.97}} &32.88 \\
\multicolumn{4}{c}{} &sLength &34.83 &29.55 &\textbf{\textcolor{gray}{33.50}} \\
dedup+punctsNum+5gram+sLength+LIDThresh +sentWRatio &\textbf{36.10} &23.84 &\textbf{33.94} &dedup+punctsNum+5gram+sLength+LIDThresh+sentWRatio &36.15 &34.50 &\textbf{35.67} \\
dedup+punctsNum+5gram+sLength+LIDThresh+sentWRatio>0.8 &35.66 &\textbf{24.18} &33.19 &dedup+punctsNum+5gram+sLength+LIDThresh+sentWRatio>0.8 &\textbf{36.26} &\textbf{35.66} &35.42 \\
\textbf{\textcolor{teal}{Gains}} &\textbf{\textcolor{teal}{+5.34}} &\textbf{\textcolor{teal}{+18.63}} &\textbf{\textcolor{teal}{+19.45}} &\textbf{\textcolor{teal}{+Gains}} &\textbf{\textcolor{teal}{+3.93}} &\textbf{\textcolor{teal}{+16.27}} &\textbf{\textcolor{teal}{+8.10}} \\
\hline
\multicolumn{8}{l}{\textbf{English$\rightarrow$Tamil}} \\
\hline
Baseline &19.02 &5.86 &14.20 &Baseline &40.13 &17.40 &26.00 \\
LIDThresh &\textbf{\textcolor{gray}{29.59}} &\textbf{\textcolor{gray}{15.24}} &24.51 &LIDThresh &\textbf{\textcolor{gray}{42.63}} &\textbf{\textcolor{gray}{38.01}} &37.40 \\
&28.93 &15.16 &\textbf{\textcolor{gray}{25.33}} &sLength &41.14 &32.67 &\textbf{\textcolor{gray}{38.08}} \\
dedup+punctsNum+5gram+sLength+LIDThresh+STRatio &\textbf{30.67} &\textbf{23.36} &\textbf{31.80} &dedup+punctsNum+6gram+sLength+LIDThresh+sentWRatio &\textbf{43.47} &\textbf{41.74} &41.06 \\
\multicolumn{4}{c}{} &dedup+punctsNum+6gram+sLength+LIDThresh+sentWRatio>0.8 &42.08 &40.56 &\textbf{42.02} \\
\textbf{\textcolor{teal}{Gains}} &\textbf{\textcolor{teal}{+11.65}} &\textbf{\textcolor{teal}{+17.50}} &\textbf{\textcolor{teal}{+17.60}} &\textbf{\textcolor{teal}{Gains}} &\textbf{\textcolor{teal}{+3.34}} &\textbf{\textcolor{teal}{+24.34}} &\textbf{\textcolor{teal}{+16.02}} \\
\bottomrule
\end{tabular}}
\vspace{1mm}
\caption{Summary of the ablation experiments. For each language pair, and each multiPLM scorer, we have included the best NMT score considering an individual heuristic as well as the combination of heuristics. The \textit{Gains} row contains the highest ChrF++ gain observed using the heuristics, respective to the baseline in terms of ChrF++ points for each multiPLM per language pair.}\label{tab:results_summary}
\end{table*}

\subsection{Human Evaluation Results}
Human evaluation results are shown in Table~\ref{tab:HE_results}. The results show that heuristic-based PDC had reduced the noise in the multiPLM top-ranked sample consistently for the three language pairs across both CCMatrix and CCAligned corpora. 

%Human Evaluation Table
\begin{table*}[!htp]\centering
\scriptsize
\renewcommand{\arraystretch}{1.35}
\resizebox{\linewidth}{!}{
\begin{tabular}{l|rrrrrrrrrr|rrrrrrrrrr|rrrrrrrrrrr}
\toprule
\multirow{2}{*}{\textbf{}} &\textbf{CC} &\textbf{CN} &\textbf{CB} &\textbf{C} &\textbf{CS} &\textbf{UN} &\textbf{X} &\textbf{WL} &\textbf{NL} &\textbf{E} &\textbf{CC} &\textbf{CN} &\textbf{CB} &\textbf{C} &\textbf{CS} &\textbf{UN} &\textbf{X} &\textbf{WL} &\textbf{NL} &\textbf{E} &\textbf{CC} &\textbf{CN} &\textbf{CB} &\textbf{C} &\textbf{CS} &\textbf{UN} &\textbf{X} &\textbf{WL} &\textbf{NL} &\textbf{E} \\
\midrule
&\multicolumn{10}{c}{\textbf{English - Sinhala}} &\multicolumn{10}{c}{\textbf{English - Tamil}} &\multicolumn{10}{c}{\textbf{Sinhala - Tamil}} \\
\hline
\textbf{CCMatrix} &\textbf{} &\textbf{} &\textbf{} &\textbf{} &\textbf{} &\textbf{} &\textbf{} &\textbf{} &\textbf{} &\textbf{} &\textbf{} &\textbf{} &\textbf{} &\textbf{} &\textbf{} &\textbf{} &\textbf{} &\textbf{} &\textbf{} &\textbf{} &\textbf{} &\textbf{} &\textbf{} &\textbf{} &\textbf{} &\textbf{} &\textbf{} &\textbf{} &\textbf{} &\textbf{} \\
LASER3 - Before &24.33\% &25.33\% &16.00\% &\textbf{65.66\%} &11.33\% &13.67\% &9.00\% &0.33\% &0.00\% &\textbf{34.33\%} &8.33\% &13.33\% &21.33\% &\textbf{42.99\%} &1.00\% &50.67\% &4.33\% &0.00\% &1.00\% &\textbf{57.00\%} &20.00\% &12.67\% &27.33\% &\textbf{60.00\%} &17.67\% &8.00\% &6.67\% &2.33\% &5.33\% &\textbf{40.00\%} \\
LASER3 - After &24.67\% &35.00\% &23.67\% &\textbf{83.34\%} &1.00\% &2.67\% &13.00\% &0.00\% &0.00\% &\textbf{16.67\%} &21.67\% &19.00\% &36.67\% &\textbf{77.34\%} &0.00\% &10.33\% &12.33\% &0.00\% &0.00\% &\textbf{22.66\%} &12.67\% &18.67\% &36.67\% &\textbf{68.01\%} &1.00\% &1.00\% &29.67\% &0.00\% &0.33\% &\textbf{32.00\%} \\
XLMR - Before &3.33\% &6.67\% &14.33\% &\textbf{24.33\%} &2.33\% &34.67\% &37.00\% &1.33\% &0.33\% &\textbf{75.66\%} &0.33\% &2.00\% &6.33\% &\textbf{8.66\%} &0.67\% &84.00\% &5.67\% &0.33\% &0.67\% &\textbf{91.34\%} &12.67\% &16.67\% &30.33\% &\textbf{59.67\%} &18.00\% &7.67\% &11.67\% &1.00\% &2.00\% &\textbf{40.34\%} \\
XLMR - After &4.33\% &15.67\% &28.00\% &\textbf{48.00\%} &0.67\% &2.00\% &49.33\% &0.00\% &0.00\% &\textbf{52.00\%} &3.33\% &8.33\% &23.00\% &\textbf{34.66\%} &0.00\% &7.67\% &56.00\% &0.33\% &1.33\% &\textbf{65.33\%} &14.00\% &11.00\% &38.00\% &\textbf{63.00\%} &5.67\% &7.00\% &23.00\% &0.33\% &1.00\% &\textbf{37.00\%} \\
LaBSE - Before &49.67\% &20.33\% &7.00\% &\textbf{77.00\%} &13.00\% &4.33\% &5.33\% &0.33\% &0.00\% &\textbf{22.99\%} &44.00\% &24.00\% &14.00\% &\textbf{82.00\%} &2.33\% &11.33\% &4.00\% &0.00\% &0.33\% &\textbf{17.99\%} &19.00\% &12.67\% &26.00\% &\textbf{57.67\%} &1.00\% &0.00\% &41.33\% &0.00\% &0.00\% &\textbf{42.33\%} \\
LaBSE - After &37.33\% &32.33\% &18.33\% &\textbf{87.99\%} &2.33\% &1.00\% &8.67\% &0.00\% &0.00\% &\textbf{12.00\%} &35.67\% &25.00\% &29.00\% &\textbf{89.67\%} &0.67\% &1.00\% &8.00\% &0.00\% &0.67\% &\textbf{10.34\%} &33.00\% &12.33\% &28.00\% &\textbf{73.33\%} &20.00\% &2.33\% &2.00\% &2.00\% &0.33\% &\textbf{26.66\%} \\
\textbf{CCAligned} &\textbf{} &\textbf{} &\textbf{} &\textbf{} &\textbf{} &\textbf{} &\textbf{} &\textbf{} &\textbf{} &\textbf{} &\textbf{} &\textbf{} &\textbf{} &\textbf{} &\textbf{} &\textbf{} &\textbf{} &\textbf{} &\textbf{} &\textbf{} &\textbf{} &\textbf{} &\textbf{} &\textbf{} &\textbf{} &\textbf{} &\textbf{} &\textbf{} &\textbf{} &\textbf{} \\
LASER3 - Before &7.00\% &11.33\% &36.67\% &\textbf{55.00\%} &19.33\% &9.67\% &15.33\% &0.00\% &0.67\% &\textbf{45.00\%} &12.33\% &15.67\% &51.33\% &\textbf{79.33\%} &10.00\% &6.33\% &0.67\% &0.00\% &3.67\% &\textbf{20.67\%} &24.00\% &13.33\% &37.00\% &\textbf{74.33\%} &15.67\% &3.00\% &5.67\% &0.33\% &1.00\% &\textbf{25.67\%} \\
LASER3 - After &12.00\% &11.33\% &47.67\% &\textbf{71.00\%} &5.00\% &1.67\% &22.33\% &0.00\% &0.00\% &\textbf{29.00\%} &14.67\% &26.00\% &53.67\% &\textbf{94.34\%} &1.33\% &0.33\% &2.33\% &0.00\% &1.67\% &\textbf{5.66\%} &16.00\% &23.67\% &53.67\% &\textbf{93.34\%} &2.67\% &0.67\% &2.67\% &0.67\% &0.00\% &\textbf{6.68\%} \\
XLMR - Before &12.67\% &13.00\% &38.33\% &\textbf{64.00\%} &4.33\% &4.67\% &26.67\% &0.00\% &0.33\% &\textbf{36.00\%} &5.33\% &17.67\% &16.00\% &\textbf{39.00\%} &20.67\% &17.33\% &9.67\% &0.33\% &13.00\% &\textbf{61.00\%} &17.33\% &21.33\% &35.33\% &\textbf{73.99\%} &14.00\% &0.33\% &7.00\% &1.00\% &3.67\% &\textbf{26.00\%} \\
XLMR - After &13.00\% &15.00\% &41.67\% &\textbf{69.67\%} &3.33\% &3.67\% &23.33\% &0.00\% &0.00\% &\textbf{30.33\%} &12.00\% &25.33\% &56.00\% &\textbf{93.33\%} &1.67\% &0.67\% &3.00\% &0.00\% &1.33\% &\textbf{6.67\%} &13.00\% &19.67\% &56.67\% &\textbf{89.34\%} &5.00\% &0.00\% &5.67\% &0.00\% &0.00\% &\textbf{10.67\%} \\
LaBSE - Before &13.00\% &25.33\% &14.67\% &\textbf{53.00\%} &32.67\% &5.33\% &6.67\% &0.00\% &2.33\% &\textbf{47.00\%} &22.67\% &26.67\% &24.00\% &\textbf{73.34\%} &20.00\% &2.00\% &0.67\% &1.00\% &3.00\% &\textbf{26.67\%} &25.67\% &22.67\% &29.00\% &\textbf{77.34\%} &17.33\% &1.67\% &3.33\% &0.00\% &0.33\% &\textbf{22.66\%} \\
LaBSE - After &19.67\% &17.00\% &37.00\% &\textbf{73.67\%} &7.67\% &1.67\% &16.67\% &0.00\% &0.33\% &\textbf{26.34\%} &19.67\% &20.67\% &57.33\% &\textbf{97.67\%} &0.00\% &0.00\% &0.33\% &0.33\% &1.67\% &\textbf{2.33\%} &17.00\% &23.67\% &40.67\% &\textbf{81.34\%} &13.67\% &0.67\% &1.00\% &0.67\% &2.67\% &\textbf{18.68\%} \\
\bottomrule
\end{tabular}}
\vspace{1mm}
\caption{Human evaluation results annotating parallel sentences from CCMatrix and CCAligned datasets for the three language pairs. The error taxonomy is used as outlined in Table~\ref{tab:HE_error_taxonomy}. Columns C and E represent the averaged percentage annotations made for the parallel sentences sample. Results are reported for LASER3, XLM-R, and LaBSE before and after heuristic-based filtering.}\label{tab:HE_results}
\end{table*}


The best quality category (C) improvements were reported with CCAligned En$\rightarrow$Ta, CCMatrix En$\rightarrow$Ta as 54.33\% and 34.35\% with CCAligned and CCMatrix ranked corpora. Similarly in the En$\rightarrow$Si direction, for CCMatrix and CCAligned, the overall quality category (C) improvement of 23.67\% and 20.67\% could be observed. These are promising observations for the PDC task, particularly when multiPLMs are used to rank a low-resource language pair this confirms the need to apply heuristics. 

Further, the human evaluation results become comparable for the LASER3, XLM-R and LaBSE ranked corpus after heuristic-based PDC for majority of the cases. We observe the same pattern in NMT results as well. Therefore it is evident that the improvement in the NMT results is strongly correlated to the qualitative improvement in the ranked corpora. %With En$\rightarrow$Si and En$\rightarrow$Ta CCMatrix XLM-R ranked corpora, the category C percentage was lagging compared to LASER3 and LaBSE ranked corpora. This was the only     

When observing the overall noise percentages (E), it was noted that consistently the noise percentage has reduced after the heuristic-based PDC step. However from the individual noise categories it was observed that still there were parallel-sentences in the untranslated (X) noise category in the filtered top-ranked corpora. Since there was no heuristic to filter out the untranslated sentences, this category of noise would need to be eliminated by means of an alignment model similar to~\citet{steingrimsson2023filtering,minh2023fast}.

In conclusion, the human evaluation results indicate that the heuristic-based PDC approach is beneficial for multiPLM ranking in two key ways.
First, it produces the top-ranked sentence pairs from multiPLM to be qualitatively comparable. Secondly, it removes the noisy parallel sentences which cause the disparity among the NMT systems trained using ranked corpora from the multiPLMs.

% \subsection{NMT Performance based on Training Data Size}
% We further investigate the effect of the training dataset size on the final NMT performance. We sample 50k, 100k, 150k and 200k from the ranked corpus, for each language pair,  and train the NMT systems. The results are shown in Figure~\ref{}\sr{fill}, and the ChrF++ full results are available in Table~\ref{} in Appendix~\ref{sec:AppendixC}.

\section{Conclusion}\label{sec:conclusion}

In this research we empirically analyse the disparity between the NMT systems trained with the ranked web-mined corpora using different multiPLMs - LASER3, XLM-R and LaBSE.  With a human evaluation, we show that the disparity is caused due to different multiPLMs ranking parallel sentences with certain characteristics as high, but are treated as noise for NMT systems. Then we empirically show that heuristic-based PDC can be used to eliminate these noisy parallel sentences and then conduct an ablation study to quantify the impact on the final NMT performance. We then conduct ablation experiments to find the optimal heuristic combination and show that the results improve further. Additionally, our comparative human evaluation show that the proportion of parallel-sentences in the noisy categories are greatly reduced in the ranked samples after the heuristic-based PDC and proportionately the quality categories are improved further. 

As future work we will extend this study to employ alignment-based models, classification-based models and other LLM-based models to analyse their effectiveness on the PDC task to remove the parallel sentences prevailing as noise classes after the heuristic-based PDC. We will conduct this study specifically for diverse low-resourced language-pairs.   

\section{Limitations and Ethical Concerns}\label{sec:limitations}
\subsection{Limitations}
Our evaluation involves only three languages. This
was inevitable because these are the only languages
we had provisions to find human translators to carry
out a meaningful evaluation.


\subsection{Ethical Concerns}
We used publicly available parallel corpora that are free to use. We paid all the translators according to the government's stipulated rates. We only collected personal information that is needed for us to determine their suitability for the task and to arrange their payment. None of these personal details has been publicly released.\\

\section*{Acknowledgments}
We would like to thank the National Languages Processing (NLP) Center, at the University of Moratuwa for providing the GPUs to execute the experiments related to the research. This work was funded by the Google Award for Inclusion Research (AIR) 2022 received by Surangika Ranathunga and Nisansa de Silva.

\bibliography{references}

\appendix

\section{Selection of Languages and Datasets}\label{sec:appendixLangsDatasets}
This section contains details on the selected languages and the web-mined corpora considered under the study.

\noindent\textbf{Sinhala} is an Indo-Aryan language spoken primarily in Sri Lanka by the Sinhalese majority. It exhibits complex morphological structures, including rich inflectional and derivational processes but is classified as a low-resource language due to the scarcity of linguistic resources and tools.\\

\noindent\textbf{Tamil}, a Dravidian language with a rich literary history, is spoken by Tamil communities in Sri Lanka, India, and the global diaspora. Unlike Sinhala, Tamil benefits from a relatively larger digital presence, but it still faces challenges in NLP applications due to morphological complexity, agglutinative grammar, and resource limitations in certain domains.\\

\noindent \textbf{CCMatrix}~\cite{schwenk2021ccmatrix} is a web-mined parallel corpus extracted using LASER2-based sentence embeddings to align bitext. While it provides large-scale data, it is highly noisy due to the \textit{global mining} approach to determine alignments, resulting in misaligned or low-quality translations.\\

\noindent \textbf{CCAligned}~\cite{el2020ccaligned}
extracts bitext from Common Crawl~\footnote{https://commoncrawl.org/} using document-level and sentence-level alignment based on multilingual embeddings. Though it improves alignment quality over global bitext-mined corpora, it still contains significant noise, requiring careful filtering for reliable use.\\


\section{Selection of multiPLMs}\label{sec:AppendixCMultiPLMs}
We include the details on the three multiPLMs considered in this study.\\

\noindent\textbf{LASER3}~\cite{heffernan2022bitext} (L=12, H=1024, A=4, 250M)\footnote{No of Layers, Hidden Layer Dimensions and No of Attention Heads are defined by L, H and A respectively.} is a multiPLM favourable for bitext mining and cross-lingual tasks. It improves over previous LASER2 versions by supporting more languages and enhancing alignment quality but still faces challenges in low-resource settings.\\

\noindent\textbf{XLM-R}~\cite{conneau2020xlmr}(L=12, H=768, A=6, 278M parameters) is a transformer-based multiPLM trained on massive amounts of text using masked language modelling. It achieves strong cross-lingual performance but struggles with low-resource languages due to limited training data.\\

\noindent\textbf{LaBSE}~\cite{feng2022language}(L=12, H=768, A=12, 471M)  is a BERT-based model optimized for multilingual sentence embeddings and bitext retrieval. It provides high-quality cross-lingual representations and is favourable for cross-lingual tasks.\\

\section{NMT Experiments}\label{sec:AppendixNMTExperiments}
The experiments were conducted on a NVIDIA Quadro RTX6000 GPU with 24GB VRAM. The hyper-parameters used during training along with the training parameters are shown in Table~\ref{tab:nmt_hyperparameters}. We conduct training on the NMT systems for 100 epochs with early stopping criteria and report the results using ChrF++. ChrF++ was chosen over the conventional multi-BLEU~\cite{papineni2002bleu} and sacreBLEU~\citep{post2018sacrebleu} because character-level evaluation is more suitable for the considered Sinhala and Tamil languages which are morphologically rich in nature.

%NMT model parameters
\begin{table}[!htp]\centering
\scriptsize
\begin{tabular*}{0.45\textwidth}{@{\extracolsep\fill}lr}
\toprule
\textbf{Hyperparameter} &\textbf{Argument value} \\
\midrule
encoder/decoder Layers &6 \\
encoder/decoder attention heads &4\\
encoder-embed-dim &512\\
decoder-embed-dim &512\\
encoder-ffn-embed-dim &2048 \\
decoder-ffn-embed-dim &2048 \\
dropout &0.4\\
attention-dropout &0.2\\
optimizer &adam\\
Adam $\beta_1$, Adam $\beta_2$ &0.9, 0.99 \\
warmup-updates &4000\\
warmup-init-lr &1e-7\\
learning rate &1e-3\\
batch-size &32\\
patience &6\\
fp16 &True\\
\midrule
\end{tabular*}
\caption{Training parameters for NMT experiments.}\label{tab:nmt_hyperparameters}
\end{table}

%Full results table
\begin{table*}[!htp]\centering
\scriptsize
\renewcommand{\arraystretch}{1.35}
\resizebox{\linewidth}{!}{
\begin{tabular}{ll|rrrrrr|rrrrrr|rrrrrrr}\toprule
\multirow{3}{*}{\textbf{Heuristic}} &\multirow{3}{*}{\textbf{Applicable Side}} &\multicolumn{6}{c}{\textbf{Sinhala-Tamil}} &\multicolumn{6}{c}{\textbf{English-Sinhala}} &\multicolumn{6}{c}{\textbf{English-Tamil}} \\
\cmidrule{3-20}
& &\multicolumn{3}{c}{\textbf{CCMatrix}} &\multicolumn{3}{c}{\textbf{CCAligned}} &\multicolumn{3}{c}{\textbf{CCMatrix}} &\multicolumn{3}{c}{\textbf{CCAligned}} &\multicolumn{3}{c}{\textbf{CCMatrix}} &\multicolumn{3}{c}{\textbf{CCAligned}} \\
\cmidrule{3-20}
& &\textbf{LASER3} &\textbf{XLM-R} &\textbf{LaBSE} &\textbf{LASER3} &\textbf{XLM-R} &\textbf{LaBSE} &\textbf{LASER3} &\textbf{XLM-R} &\textbf{LaBSE} &\textbf{LASER3} &\textbf{XLM-R} &\textbf{LaBSE} &\textbf{LASER3} &\textbf{XLM-R} &\textbf{LaBSE} &\textbf{LASER3} &\textbf{XLM-R} &\textbf{LaBSE} \\
\midrule
Baseline & &31.08 &30.99 &31.63 &35.36 &35.97 &35.79 &30.76 &5.55 &14.49 &32.33 &19.39 &27.57 &19.02 &5.86 &14.20 &40.13 &17.40 &26.00 \\
\hline
dedup &\textbf{S} &32.05 &\textbf{31.50} &32.07 &36.40 &\textbf{36.01} &34.98 &29.72 &6.35 &14.69 &33.26 &21.04 &28.22 &19.67 &4.93 &14.96 &\textbf{40.87} &19.47 &26.26 \\
&T &31.39 &31.44 &31.73 &36.26 &35.86 &\textbf{35.96} &33.81 &12.59 &25.97 &\textbf{33.66} &21.41 &28.32 &19.48 &\textbf{6.87} &\textbf{17.96} &40.13 &17.90 &27.79 \\
&\textbf{ST} &\textbf{32.26} &31.10 &\textbf{32.25} &\textbf{36.41} &36.08 &35.32 &\textbf{34.01} &\textbf{13.80} &\textbf{26.18} &33.47 &\textbf{22.22} &\textbf{29.49} &\textbf{20.32} &6.45 &17.53 &40.56 &\textbf{19.83} &\textbf{30.01} \\
dedup-4gram &S &30.37 &30.65 &30.53 &35.74 &35.24 &34.55 &28.69 &8.56 &13.05 &31.56 &23.53 &28.25 &19.72 &7.06 &19.56 &35.54 &25.64 &26.49 \\
&T &31.00 &29.90 &29.39 &36.05 &35.98 &35.44 &31.79 &13.60 &23.66 &32.86 &\textbf{24.95} &29.05 &19.82 &7.08 &20.23 &39.83 &\textbf{27.44} &\textbf{31.18} \\
&ST &30.86 &31.13 &30.80 &35.28 &35.36 &34.64 &28.72 &\textbf{15.17} &20.45 &28.15 &15.45 &21.37 &\textbf{18.15} &7.00 &21.37 &35.02 &25.70 &27.41 \\
dedup-5gram &S &30.89 &30.90 &31.25 &35.64 &35.81 &35.87 &28.73 &7.14 &13.51 &33.44 &23.98 &28.79 &18.06 &4.70 &17.16 &40.39 &24.07 &29.07 \\
&\textbf{T} &31.24 &\textbf{31.55} &32.10 &36.26 &35.87 &35.23 &33.98 &14.01 &\textbf{26.23} &34.10 &22.27 &\textbf{31.10} &20.15 &6.75 &18.78 &41.12 &24.05 &30.26 \\
&\textbf{ST} &30.78 &31.53 &31.35 &35.64 &35.94 &35.44 &31.95 &13.87 &23.07 &31.60 &17.10 &23.52 &19.61 &6.25 &20.12 &21.77 &25.22 &29.36 \\
dedup-6gram &S &31.89 &30.82 &31.76 &36.31 &\textbf{36.11} &35.88 &31.10 &7.62 &13.41 &33.53 &21.47 &28.51 &20.32 &5.47 &15.59 &40.48 &21.75 &27.64 \\
&\textbf{T} &\textbf{32.51} &30.41 &\textbf{32.29} &36.35 &36.23 &\textbf{36.01} &34.21 &13.98 &24.91 &\textbf{34.24} &23.63 &30.23 &21.75 &6.69 &20.32 &40.44 &20.31 &30.48 \\
&ST &31.89 &30.82 &31.76 &35.84 &35.95 &35.54 &33.63 &14.96 &24.72 &33.29 &15.54 &25.55 &20.38 &7.18 &20.19 &\textbf{41.73} &24.89 &31.06 \\
dedup-7gram &S &31.48 &31.27 &32.03 &36.26 &35.67 &35.50 &30.93 &5.91 &15.94 &33.27 &19.90 &29.58 &21.54 &5.71 &16.49 &40.63 &20.01 &28.91 \\
&T &31.56 &31.06 &30.85 &\textbf{36.44} &36.10 &35.16 &\textbf{34.27} &13.72 &25.58 &32.97 &22.14 &28.22 &20.91 &\textbf{7.37} &\textbf{21.96} &40.49 &19.18 &28.69 \\
&ST &31.48 &31.27 &32.03 &35.74 &35.90 &34.82 &33.93 &14.95 &24.95 &33.63 &14.58 &24.96 &17.56 &5.98 &20.71 &40.94 &22.16 &29.40 \\
dedup\_nums &S &31.51 &31.37 &31.99 &36.61 &36.66 &35.99 &30.54 &5.92 &15.12 &34.77 &28.07 &31.81 &17.00 &5.60 &13.41 &41.40 &28.65 &35.22 \\
&T &31.17 &30.51 &32.09 &36.30 &36.45 &36.32 &33.83 &14.44 &25.86 &34.47 &27.27 &31.90 &17.54 &6.09 &19.01 &41.36 &28.40 &35.12 \\
&ST &31.71 &31.22 &31.66 &36.49 &36.37 &36.10 &33.83 &14.15 &26.12 &34.24 &\textbf{28.45} &31.64 &19.19 &5.15 &18.92 &41.46 &30.49 &35.42 \\
dedup+puntNums &S &31.90 &31.47 &31.02 &36.50 &36.00 &36.12 &30.55 &6.28 &16.67 &34.72 &27.25 &31.89 &18.15 &5.79 &15.66 &41.78 &30.55 &35.78 \\
&T &31.90 &32.05 &30.89 &36.63 &36.47 &36.86 &\textbf{33.89} &\textbf{14.81} &26.31 &\textbf{35.06} &27.69 &\textbf{32.01} &\textbf{21.57} &\textbf{8.24} &\textbf{20.41} &41.64 &29.35 &35.32 \\
&ST &32.05 &31.31 &32.53 &35.96 &\textbf{36.71} &36.23 &33.37 &14.15 &26.08 &34.08 &27.80 &32.59 &20.99 &5.82 &18.83 &41.80 &30.69 &35.91 \\
dedup+puntsNums+5gram &ST+T &\textbf{{32.98}} &\textbf{32.73} &\textbf{32.60} &36.24 &36.21 &36.35 &\multicolumn{3}{c}{NA} &30.64 &29.48 &30.19 &19.49 &6.67 &20.6 &41.82 &\textbf{35.97} &\textbf{37.08} \\
dedup+puntsNums+6gram &ST+T &30.41 &31.38 &31.42 &\textbf{36.73} &36.62 &\textbf{36.37} &\textbf{34.50} &\textbf{16.09} &26.78 &33.81 &\textbf{30.33} &\textbf{32.74} &\multicolumn{3}{c}{NA} &\textbf{41.90} &35.90 &35.94 \\
dedup+puntsNums+7gram &&\multicolumn{6}{c}{NA} &\multicolumn{6}{c}{NA} &\textbf{35.24} &28.21 &31.26 &\multicolumn{3}{c}{NA} \\
\hline
sLength &\textbf{S} &\textbf{31.41} &\textbf{31.52} &\textbf{32.30} &36.42 &36.37 &36.52 &32.49 &6.58 &20.70 &\textbf{33.86} &26.53 &32.97 &17.50 &5.11 &18.74 &41.40 &27.60 &36.77 \\
&T &31.38 &30.56 &31.97 &36.30 &\textbf{36.71} &36.58 &31.88 &7.83 &28.51 &\textbf{34.88} &29.42 &33.14 &18.52 &\textbf{6.33} &\textbf{21.73} &\textbf{41.54} &30.16 &37.61 \\
&ST &31.21 &31.32 &31.37 &\textbf{36.47} &35.99 &\textbf{36.60} &\textbf{32.82} &\textbf{8.24} &\textbf{29.96} &34.83 &\textbf{29.55} &\textbf{33.50} &\textbf{19.45} &5.33 &20.79 &41.14 &\textbf{32.67} &\textbf{38.08} \\
\hline
LID &\textbf{S} &\textbf{31.48} &\textbf{31.36} &\textbf{31.78} &36.05 &36.03 &35.64 &31.00 &6.23 &14.69 &34.39 &27.33 &31.73 &18.44 &6.93 &13.43 &41.80 &31.41 &33.95 \\
&T &30.78 &31.14 &31.53 &35.68 &36.07 &35.85 &32.48 &12.22 &16.04 &33.70 &24.38 &30.48 &\textbf{29.59} &14.70 &24.24 &41.51 &24.24 &30.69 \\
&ST &31.43 &30.66 &31.40 &36.17 &36.12 &35.18 &31.99 &13.32 &\textbf{16.20} &34.11 &28.87 &32.26 &\textbf{29.59} &13.54 &23.45 &41.42 &32.33 &36.13 \\
LIDThresh &S &30.05 &31.25 &31.06 &35.60 &35.25 &34.29 &30.32 &7.12 &15.26 &\textbf{35.73} &30.86 &32.69 &18.98 &6.02 &13.06 &41.60 &35.25 &36.29 \\
&T &31.28 &30.40 &30.68 &35.03 &30.01 &32.01 &32.82 &12.94 &15.81 &35.22 &27.46 &30.40 &\textbf{29.59} &\textbf{15.24} &24.51 &41.03 &30.01 &34.01 \\
\hline
&ST &30.33 &30.46 &30.71 &\textbf{36.73} &\textbf{36.73} &\textbf{36.80} &\textbf{32.84} &\textbf{14.08} &13.71 &35.11 &\textbf{32.97} &\textbf{32.88} &28.93 &15.16 &\textbf{25.33} &\textbf{42.63} &\textbf{38.01} &\textbf{37.40} \\
STRatio (0.85-1.57) & &31.74 &22.80 &31.34 &36.39 &35.74 &35.30 &31.09 &\textbf{5.20} &15.40 &33.47 &24.05 &30.21 &\textbf{20.52} &5.40 &\textbf{18.29} &40.91 &22.71 &28.61 \\
sentWRatio &S &30.65 &30.62 &32.03 &36.17 &35.77 &35.54 &\textbf{31.50} &7.40 &10.86 &\textbf{34.15} &25.97 &\textbf{31.35} &19.42 &5.79 &13.93 &42.05 &29.70 &35.53 \\
&T &30.71 &31.59 &31.34 &36.24 &36.17 &36.46 &30.99 &6.39 &15.13 &33.51 &26.93 &30.47 &18.61 &5.65 &11.08 &41.87 &30.06 &35.54 \\
&ST &31.93 &31.56 &30.98 &36.44 &36.72 &36.01 &30.64 &7.00 &\textbf{15.50} &33.85 &\textbf{28.73} &31.17 &18.99 &4.82 &14.08 &\textbf{41.05} &\textbf{30.88} &\textbf{35.77} \\
sentCRatio &S &31.67 &31.24 &31.14 &35.94 &36.18 &35.86 &30.15 &7.05 &14.46 &34.06 &21.52 &30.10 &17.47 &6.22 &13.83 &40.68 &22.48 &29.37 \\
&T &30.98 &31.21 &31.93 &36.36 &35.43 &35.85 &30.65 &5.83 &15.28 &33.64 &23.14 &29.05 &19.90 &\textbf{6.78} &12.51 &40.78 &19.63 &29.42 \\
&\textbf{ST} &\textbf{32.28} &\textbf{31.90} &\textbf{32.04} &36.33 &35.60 &36.11 &30.85 &6.45 &14.64 &33.60 &23.84 &29.70 &19.54 &6.45 &10.79 &41.76 &21.82 &30.82 \\
\hline
\multicolumn{20}{l}{\textbf{Combined Heuristics}} \\
\hline
\multicolumn{20}{l}{dedup+punctsNum+ngram (SiTa n=5, EnSi n=5, EnTa n=7)} \\
+sLength &T+ST &30.17 &29.02 &29.99 &36.32 &36.81 &36.61 &35.03 &21.70 &26.32 &35.68 &33.49 &34.43 &30.29 &19.44 &29.85 &42.84 &39.36 &40.16 \\
+LIDThresh &T+ST &31.49 &30.13 &30.68 &36.58 &36.37 &37.02 &35.42 &19.58 &32.43 &34.77 &32.58 &34.72 &20.53 &7.52 &23.35 &42.68 &38.45 &39.60 \\
+sentWRatio &T+S &31.37 &30.55 &30.92 &36.83 &36.75 &36.30 &33.99 &15.76 &24.92 &33.97 &31.40 &32.72 &21.67 &8.23 &24.58 &42.11 &37.47 &38.07 \\
+slength+LIDThresh &T+ST &29.28 &30.85 &29.96 &36.47 &36.81 &36.88 &35.70 &23.92 &32.77 &34.97 &34.92 &35.60 &30.65 &20.86 &31.49 &42.85 &41.17 &41.31 \\
+slength+sentCRatio &T+ST+ST &31.45 &32.65 &31.17 &\textbf{36.60} &\textbf{36.85} &36.32 &35.71 &18.93 &32.53 &35.45 &33.42 &33.82 &22.46 &9.11 &23.82 &41.97 &40.07 &40.06 \\
+slength+LIDThresh+sentWRatio &T+ST+ST+S &29.81 &29.53 &29.73 &36.83 &36.66 &\textbf{37.03} &\textbf{36.10} &23.84 &\textbf{33.94} &36.15 &34.50 &\textbf{35.67} &\multicolumn{6}{c}{NA} \\
+slength+LIDThresh+sentWRatio>0.8 &T+ST+ST+ST &28.70 &28.39 &28.34 &36.20 &36.60 &35.89 &35.66 &\textbf{24.18} &33.19 &\textbf{36.26} &\textbf{35.66} &35.42 &\multicolumn{6}{c}{NA} \\
+slength+LIDThresh+STRatio &T+ST+ST+STR &\multicolumn{6}{c}{NA} &\multicolumn{6}{c}{NA} &\textbf{30.67} &\textbf{23.36} &\textbf{31.80} &\textbf{43.47} &\textbf{41.74} &41.06 \\
\bottomrule
\end{tabular}}
\vspace{1mm}
\caption{Ablation experiments and ChrF++ scores obtained when applying the heuristics on the CCMatrix and CCAligned corpora for the three language pairs.}\label{tab:results_full_table}
\end{table*}

\section{Human Evaluation}\label{sec:AppendixHumanEvaluation}
We go by the error taxonomy defined by~\cite{ranathunga2024quality} to annotate the parallel sentences, as described in Table~\ref{tab:HE_error_taxonomy}.

%Error Taxonomy
\begin{table*}[!htp]
\centering
\scriptsize
\renewcommand{\arraystretch}{1.1}
\resizebox{\linewidth}{!}{%
\begin{tabular}{lp{5cm}p{8cm}} \toprule
Noise Category & Noise Category Description & Explanation \\ \midrule
CC  & Perfect Translation Pair   & Contains no spelling or grammar mistakes in the individual sentences. \\
CN  & Near Perfect Translation Pair   & Just a few spelling, grammar, punctuation, or unnecessary characters have to be handled. \\
CB  & Low-Quality Translation Pair  & Individual sentence can be a full sentence or a full phrase, but it is a low-quality (boilerplate) translation. \\
CS  & Short Phrase-Pair/Few Words  & Translation-wise correct, but it is a short phrase or just a few words. \\
X   & Wrong Translation  & Translation has the correct source and target languages, but the translation is completely incorrect. \\
UN  & Untranslated Text  & Either the source or target side is just copied from the translation counterpart, either partially or in full. \\
NL  & Not a Language  & At least one of the sources and targets is not linguistic content. \\
WL  & Wrong Language  & The source and target are linguistic content, but either the source, target, or both are not in the expected language. \\ 
\bottomrule
\end{tabular}}
\vspace{1mm}
\caption{Error taxonomy used for annotating parallel sentences during human evaluation.}
\label{tab:HE_error_taxonomy}
\end{table*}





\end{document}
