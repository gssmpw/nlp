\section{Scheduling in \sys}
\label{sec:scheduling}
This section \xzyao{introduces} our scheduling algorithm, which aims to optimize the overall \jyhh{SLO attainment} of the serving. 

\begin{figure}[!t] 
  \centering
  \includegraphics[width=\linewidth]{img/algorithm_flow.pdf} % Adjust the width as needed
  \vspace{-1em}
  \caption{\jyh{\small{Workflow of our scheduling algorithm.}}}
  \vspace{-1em}
  \label{fig:scheduling_routine}
\end{figure}

\subsection{Overview and Problem Formulation}

To describe the model deployment over the available resources of heterogeneous capabilities, the scheduling algorithm should produce four essential components: \mytextcircled{1} The \ul{\textit{group construction}}, i.e., how to partition the GPUs into multiple model serving groups, where each group is responsible for one model replica. 
\mytextcircled{2} The \ul{\textit{phase designation}} that indicates whether each group should serve as the prefill or decode phase. 
\mytextcircled{3} The \ul{\textit{parallel configuration}} for each model replica.
\mytextcircled{4} The \ul{\textit{orchestration of prefill and decode replicas}} to guide how the requests should be routed. We term a solution to these four components as a \textbf{\ul{\textit{deployment plan}}}.

% In fact, our scheduling algorithm aims to solve a two-level hierarchical optimization problem as follows.
As each deployment plan consists of four components, there is an extremely huge solution space. To ease the scheduling, we decouple the huge solution space into the Cartesian product of two sub spaces, by turning the derivation of deployment plan into a two-level hierarchical optimization problem as follows. 
\begin{itemize}[topsep=5pt, leftmargin=*]
 
\item \textbf{Upper-level:} 
Suppose there are $G$ GPUs of $T$ types in total, and $G_{t}$ denotes the number of GPUs of type $t$. The objective of the upper-level problem is to find out the best combination of group construction and phase designation that maximizes the end-to-end \jyhh{SLO attainment.}

 
\item \textbf{Lower-level.} 
% Given the constructed model serving groups and their designated phases, 
Given the group construction and phase designation, 
the objective of the lower-level problem is to determine the best parallel configuration for each group and how the prefill and decode replicas should be orchestrated to maximize the end-to-end \jyhh{SLO attainment}.
 
\end{itemize} 
Obviously, the Cartesian product of the solution spaces of the two problems completely covers all possible deployment plans, so finding the optimal deployment plan is equivalent to solving the hierarchical optimization problem by nature. 
% 
Figure \ref{fig:scheduling_routine} shows the workflow of our scheduling algorithm. 
Given the target model and the available resources, we initiate the GPU construction and phase designation process, which involves a tabu search process that iteratively proposes solutions to the upper-level problem (\S\ref{sec:schedule_upper_level}). 
Then, for any possible solution to the upper-level problem, we solve the lower-level problem to obtain its performance, which involves the the parallel configuration deduction and phase orchestration process (\S\ref{sec:schedule_lower_level}).


\subsection{Solving the Upper-level Problem}
\label{sec:schedule_upper_level}
In cloud environments, there are various types of GPUs with heterogeneous capabilities, making the group construction a non-trivial problem. In addition, the phase-splitting design requires meticulous phase designation to the model serving groups for better performance, making the upper-level problem even more complex. 
Formally, in \autoref{appendix:a}, we show that the upper-level problem is essentially a job shop scheduling problem (JSSP), which is a notoriously difficult NP-hard problem in combinatorial optimization \cite{sotskov1995np,omar2006job}. 

% A well-known heuristic yet effective approach to solve JSSP is tabu search \cite{glover1990tabu,glover1998tabu,gendreau2005tabu} and there have been many research works applying tabu search to solve JSSP under various situations \cite{hurink1994tabu,tabu_jssp_1997,zhang2007tabu}. Motivated by this, we introduce a heuristic algorithm based on tabu search for the upper-level problem.

% \begin{algorithm}[tb]
% \caption{Routine of solving the upper-level problem based on tabu search, where $N_{\text{step}}$ denotes the number of search steps, $N_{\text{nghb}}$ denotes the number of neighbors to navigation in each step, $N_{\text{mem}}$ denotes the maximum number of memorized solutions, and $f(\cdot)$ denotes the performance of a solution evaluated by solving the lower-level problem.
% }
% \label{alg:tabu}
% \begin{algorithmic}

% \STATE \textbf{function} \textsc{TabuSearch}($N_{\text{step}}$=100, $N_{\text{nghb}}$=10, $N_{\text{mem}}$=5)
% \STATE Initialize the current solution $x$
% \STATE Initialize tabu list $T \gets []$, best solution $x_{best} \gets x$
% \STATE {\color{gray}{/* Iterative Neighborhood Search */}}
% % \While{termination conditions not met}
% \FOR{$N_{\text{step}}$ search steps}
%     \STATE Construct $N_{\text{nghb}}$ neighbors of $x$ and exclude those in $T$ to form the neighborhood set $\mathcal{N}$ for navigation
%     % \State{\textcolor{gray}{/* Neighborhood Evaluation */}}
%     \STATE $x' \gets \argmax_{x'' \in \mathcal{N}} f(x'')$
%     % \State{\textcolor{gray}{/* Update Best Solution */}}
%     \STATE \textbf{if} $f(x') > f(x_{best})$ \textbf{then} $x_{best} \gets x'$
%     % \State{\textcolor{gray}{/* Manage Tabu List */}}
%     \STATE $T.\operatorname{append}(x')$
%     %\textbf{if} $x' \not\in T$ \textbf{then} $T.\operatorname{append}(x')$
%     \STATE \textbf{if} $\operatorname{len}(T) > N_{\text{mem}}$ \textbf{then} $T \gets T[-N_{\text{mem}}:\;]$
%     \STATE $x \gets x'$
% \ENDFOR
% % \EndWhile
% \STATE \textbf{return} $x_{best}$
% \STATE \textbf{endfunction}
% % \EndFunction
% \end{algorithmic}
% \end{algorithm}

% 
% \noindent \textbf{Tabu search.} 
% Tabu search is a metaheuristic search method, which ranks among the most effective techniques for solving complex optimization problems \cite{glover1990tabu,glover1998tabu,gendreau2005tabu}.
% Its versatility has been demonstrated through its successful application across diverse industries, including manufacturing for optimizing production schedules, transportation for efficient vehicle routing, telecommunications for network design, finance for portfolio optimization, and healthcare for nurse scheduling \cite{glover2007principles,cordeau2005new,burke2004state}. 
% The core idea behind tabu search is to start from an initial solution, and then iteratively navigate a set of neighboring solutions of the current solution and transit to an improved one. 
% % navigate the solution space of the target problem, by iteratively transitioning from the current solution to an improved one in the neighborhood space. 
% During navigation, it also considers the strategic acceptance of inferior solutions to circumvent local optima, guided by a tabu list that works as a short-term memory for visited solutions. 
% We refer interested readers to related literature for further details about tabu search.


\input{tabu_search_algorithm}

% The upper-level problem is essentially a job shop scheduling problem (JSSP) (detailed in \autoref{appendix:a}), which is a notoriously difficult NP-hard problem in combinatorial optimization \cite{sotskov1995np,omar2006job}. 
A well-known approach to solve JSSP is tabu search \cite{glover1990tabu,glover1998tabu,gendreau2005tabu} and there have been many efforts applying tabu search to solve JSSP under various situations \cite{hurink1994tabu,tabu_jssp_1997,zhang2007tabu}. Motivated by this, we adapt tabu search to the upper-level problem and design a brand new algorithm to identify the optimal deployment plan, which is demonstrated in Algorithm \ref{alg:tabu}. 
% The complete workflow of our algorithm based on tabu search is demonstrated in Algorithm \ref{alg:tabu}.
In essence, it starts from an initial solution, and leverages an iterative neighborhood search process to improve the solution. 
Below we focus on how to determine the initial solution and how to construct neighbors given the current solution in our scenario.
% Due to the space constraint, below we focus on how to determine the initial solution and how to construct neighbors given the current solution in our scenario, while leaving the detailed workflow in Algorithm \ref{alg:tabu}.
% Below, we introduce how the initial solution is determined, and how to construct neighbors given the current solution. 
% iteratively navigates the neighborhood space of the current solution, 


\noindent \textbf{Initialization.} It is essential to have a good initial solution in tabu search in order to speedup the search process and escape from local optima. 
% Thus, we initialize the model serving group through Hierarchical Clustering method \cite{shetty2021hierarchical} guided by the provided communication matrix. 
Thus, we utilize the Hierarchical Clustering method \cite{shetty2021hierarchical} to cluster the GPUs according to their inter-connection bandwidth matrix, and subsequently treat each generated cluster as one model serving group at initialization.
Intuitively, this makes the initial assignment of model serving groups strategically avoid connections with ultra-low communication bandwidth in the cloud environment. In addition, the phase designation of each group is randomly initialized.


\noindent \textbf{Neighbor construction.} 
In the iterative search process, tabu search evaluates a set of neighboring solutions given the current solution. Denote $g_{i,t}$ as the number of GPUs of type $t$ in group $i$. We provide four approaches of to construct the neighboring solutions, as exemplified in \autoref{fig:tabusearch graph} and detailed below.
% 
\begin{itemize}[leftmargin=*,topsep=5pt]
 % 
\item \textit{Flipping phase designation.} This approach randomly selects a group and flips its phase. In other word, if the group is originally designated to serve as a prefill replica, then it will be changed to a decode replica, and vice versa. 
% 
\item \textit{Splitting a group into two.} This approach randomly selects and splits a group {\semismall \( g_{s,t} \)} into two based on a random ratio {\semismall \( r \)}, assigning {\semismall \( \lfloor g_{s,t} \times r \rfloor \)} GPUs to the first new group {\semismall \( g_{s_1,t}' \)} and the remainder to the second group {\semismall \( g_{s_2,t}' \)}, which is effective for exploring how dividing resources impacts performance, particularly when a group might be overly large or tasked beyond its efficient operating capacity, i.e.,
% {\semismall
% \[
% g_{s_1,t}' \leftarrow \lfloor g_{s,t} \times r \rfloor, \quad g_{s_2,t}' \leftarrow g_{s,t} - g_{s_1,t}', \quad \forall t \in \{1, \ldots, T\}.
% \]
% }
\begin{equation*}
g_{s_1,t}' \leftarrow \left\lfloor g_{s,t} \times r \right\rfloor, 
g_{s_2,t}' \leftarrow g_{s,t} - g_{s_1,t}', \forall t \in \{1, \ldots, T\}.
\end{equation*}
% 
The phase of the new groups will be randomly designated.
% 
\item \textit{Merging two groups into one.} This approach randomly selects and merges two groups {\semismall \( g_{i,t}, g_{j,t} \)} into one, which explores the potential benefits or drawbacks of resource centralization for individual model serving, i.e.,
% {\semismall
% \[
% g_{\text{merged},t}' \leftarrow g_{i,t} + g_{j,t}, \quad \forall t \in \{1, \ldots, T\}.
% \]
% }
\begin{equation*}
g_{\text{merged},t}' \leftarrow g_{i,t} + g_{j,t}, \quad \forall t \in \{1, \ldots, T\}.
\end{equation*}
% 
The phase of the new group will be randomly designated.
% 
\item \textit{Moving GPUs between groups.} This approach involves moving a certain number of (denoted as {\semismall \( m_t \)}) GPUs of type {\semismall \( t \)} from group {\semismall \( i \)} to group {\semismall \( j \)}. 
It is useful for exploring the effects of resource reallocation in scenarios where different groups may benefit from different GPU capabilities.
% {\semismall
% \[
% \quad g_{i,t}' \leftarrow g_{i,t} - m_t, \quad g_{j,t}' \leftarrow g_{j,t} + m_t
% \]
% }
\begin{equation*}
g_{i,t}' \leftarrow g_{i,t} - m_t, \quad g_{j,t}' \leftarrow g_{j,t} + m_t.
\end{equation*}
% 
\end{itemize}
% 
The adjustment in group construction and phase designation iteratively navigate the neighborhood space of the current solution, enabling tabu search to explore potential performance enhancements.
Additionally, to expedite the search process, early checks are performed for each generated neighborhood. For instance, if the total GPU memory of any serving group after the moving or splitting operations is insufficient to hold even a single copy of the model parameters, then the constructed neighbor is eliminated from further evaluation.


\begin{figure}[!t]
  \centering
  \includegraphics[width=\linewidth]{img/movesplitmerge_.pdf} % Adjust the width as needed
  \vspace{-1em}
  \caption{\jyh{\small{Examples of neighbor construction in tabu search (changes in phase designation are omitted for simplicity).}}}
  \label{fig:tabusearch graph}
  \vspace{-1em}
  % \vspace{-1em}
\end{figure}


\subsection{Solving the Lower-level Problem}
\label{sec:schedule_lower_level}
The goal of the lower-level problem is two-fold, i.e., finding the optimal parallel configuration for each model serving group and how to orchestrate all groups together. Fortunately, since the available resources and the designated phase of each group are given, we find that the deduction of optimal parallel configuration is independent to the orchestration. To be specific, suppose $C'$ is a parallel configuration for an arbitrary group, and $C''$ is another configuration with higher performance, then it is obvious that we can always find out an orchestration with $C''$ that is at least as good as that with $C'$. As a result, we first deduce the optimal parallel configuration for each group individually, and then determine the orchestration, as introduced below. 


\noindent \textbf{Deduction of parallel configuration.} Given the available resources and the designated phase of each group, we wish to deduce the optimal parallel configuration. 
As discussed in \S\ref{sec:batching}, the two phases differ in workload characteristics, so their desirable parallel configurations also vary. 
For groups that serve as prefill replicas, we aim to deduce the latency-optimal parallel configurations, since the prefill phase is computation-intensive and batching does not help to enhance efficiency.
In contrast, for groups that serve as decode replicas, we aim to deduce the throughput-optimal parallel configurations, since this memory bandwidth bounded phase benefits from batching. 

Numerous studies \cite{jiang2024hexgen,zheng2022alpa,li2023alpaserve,Miao_2022,miao2023spotserve,wang2024improving} have investigated how to deduce the optimal parallel configuration by meticulously enumerating a vast number of possible configurations. In this work, we further take the key characteristics of cloud environments into account and design heuristics to accelerate the enumeration process. We introduce the heuristics below and leave the details of the deduction routine in \autoref{appendix:b}. 

\begin{itemize}[topsep=5pt, leftmargin=*]
     
    \item Typically, cloud services generally do not provide rapid links among nodes. Thus, we disallow tensor model parallelism to be deployed over GPUs across different nodes due to its demand of higher network bandwidth. 

    \item Since different types of GPUs may differ in the memory capacity and computing ability, we support non-uniform pipeline layer partitioning for pipeline model parallelism. 

    \item In response to the heterogeneity in inter-node communication, we employ a dynamic programming algorithm that aims to identify the path minimizing the cross-stage communication cost in pipeline model parallelism.

\end{itemize}

\begin{figure}[!t] 
  \centering
  \includegraphics[width=0.8\linewidth]{img/orchestration.pdf} % Adjust the width as needed
  \caption{\small{An example orchestration of prefill and decode replicas.}}
  \label{fig:orches}
  \vspace{-1em}
\end{figure}



\noindent \textbf{Orchestration of prefill and decode replicas.}
Due to the network heterogeneity in cloud environments, it is essential to identify the optimal orchestration of prefill and decode replicas within the cluster to minimize KV cache communication cost and optimize overall \jyhh{SLO attainment}.

% We develop an inference task simulator to evaluate the end-to-end \jyhh{SLO attainment}. 
\jyhh{We adopt the inference task simulator from DistServe \cite{zhong2024distserve}}, which estimates the \jyhh{SLO attainment} according to workload information (e.g., input length, output length, etc.) and single request processing time. It is noteworthy \jyhh{that we integrate the KV cache communication cost into the simulator,} since it is non-negligible in cloud environments. To be specific, suppose there are $m$ prefill replicas and $n$ decode replicas, our simulator enumerates every pair of them and estimates the \jyhh{SLO attainment} by integrating the KV cache communication cost, which is analyzed via the alpha-beta model \cite{hockney1994communication}:
\begin{equation}
\semismall
\label{eq:kv_comm_cost}
  {T}^{(kv\_comm)}_{ij} = {\alpha_{ij}} + {2bsh\text{N}_{\text{bytes}}}/{\beta_{ij}},
\end{equation}
where \( b, s \) represent the batch size and sequence length for inference, \( h \) represents the hidden size of a Transformer block, \(\text{N}_{\text{bytes}} \) represents the byte size for KV cache communication, and \( \alpha_{ij}, \beta_{ij} \) represent the network latency and bandwidth between the $i$-th prefill replica and the $j$-th decode replica. \jyhh{We evaluate the simulator and alpha-beta model accuracy in \autoref{appendix:simu}.}

Based on this, we estimate the \jyhh{SLO attainment} of every pair of prefill and decode replicas. Formally, denote $D \in \mathbb{R}^{m \times n}$ as the \jyhh{SLO attainment} matrix, where $D_{ij}$ represents the estimated \jyhh{SLO attainment} when requests are processed by the $i$-th prefill replica and the $j$-th decode replica. Then, we turn the optimization problem of overall system \jyhh{SLO attainment} into a simple two-stage transportation problem (TSTP)~\cite{santoso2022development}
as follows:
\begin{equation*}
\semismall
\begin{aligned}
& \argmax_{X \in \mathbb{R}^{m}, Y \in \mathbb{R}^{m \times n}} 
\sum_{i=1}^{m} \sum_{j=1}^{n} X_i Y_{ij} D_{ij} \\
& \text{s.t. } 
\sum_{i=1}^{m} X_i = 1, \;
\sum_{j=1}^{n} Y_{ij} \text{ for }\forall i, \;
X_i \geq 0 \text{ for }\forall i, \;
Y_{ij} \geq 0 \text{ for }\forall i, j,
\end{aligned}
\end{equation*}
where $X_i$ denotes the portion of incoming requests that are assigned to the $i$-th prefill replica, and $Y_{ij}$ denotes the portion of requests processed by the $i$-th prefill replica that are dispatched to the $j$-th decode replica. The TSTP can be solved by linear programming, and the optimal $X^*, Y^*$ describe how requests are routed among the model serving groups, which also represent the orchestration of different replicas to maximize the overall system \jyhh{SLO attainment}.

By combining the deduction of optimal parallel configuration and the orchestration of different replicas, we accomplish the solution to the lower-level problem, and the resulting system \jyhh{SLO attainment} is returned to the tabu search process (i.e., $f(\cdot)$ in Algorithm \ref{alg:tabu}).


% \begin{table*}
% \centering
% \jyh{
% \tiny
% \caption{\jyh{Throughput (tokens/s) by prefill-to-decode ratio. Impact of phase designation and orchestration on overall system throughput. We experiment with LLaMA-13B on both coding and conversation workloads across clusters with 8, 12, and 16 A5000 GPUs, respectively, with two GPUs serving one replica. The ratio represents the prefill-to-decode ratio (i.e., the ratio of \# prefill replicas to \# decode replicas).}}
% \begin{tabular}{c|ccc|ccccc|ccccccc}
% \hline
% & \multicolumn{3}{c|}{4 replicas} & \multicolumn{5}{c|}{6 replicas} & \multicolumn{7}{c}{8 replicas} \\
% \hline
%  prefill/decode & 1/3 & 1/1 & 3/1 & 1/5 & 1/2 & 1/1 & 2/1 & 5/1 & 1/7 & 1/3 & 3/5 & 1/1 & 5/3 & 3/1 & 7/1 \\
% \hline
% coding & 8394 & \textbf{12974} & 9709 & 8346 & 16740 & 25143 & \textbf{30350} & 14892 & 8395 & 16790 & 25081 & 33205 & \textbf{41591} & 29977 & 15153 \\
% \hline
% conversation & \textbf{6041} & 3129 & 1148 & \textbf{9120} & 6295 & 3694 & 3252 & 2018 & 9115 & \textbf{11007} & 9710 & 7959 & 6059 & 3783 & 1765 \\
% \hline
% \end{tabular}
% \label{tab:throughputvsratio}
% }
% \end{table*}


\begin{figure}
    \centering
    \includegraphics[width=\linewidth]{img/ratiovsthroughput.pdf}
    \vspace{-2em}
    \caption{\small{Throughput (token/s) by prefill-to-decode ratio. Impact of phase designation and orchestration on overall system throughput. We experiment with LLaMA-13B on both coding and conversation workloads across clusters with 8, 12, and 16 A5000 GPUs, respectively, with two GPUs serving one replica. The ratio represents the prefill-to-decode ratio (i.e., the ratio of \# prefill replicas to \# decode replicas). We have also provided SLO Attainment results in \autoref{fig:ratio_goodput} of \autoref{appendix:ratio}.}}
    \label{tab:throughputvsratio}
    \vspace{-1em}
\end{figure}

\subsection{Lightweight Rescheduling in Real Time}
\label{sec:method_light_reschedule}
Numerous factors in cloud services affect the optimal deployment plan, with two primary factors being LLM inference workloads and GPU availability. On the one hand, LLM services usually exhibit significant variation in workload characteristics across different downstream tasks. For instance, coding workloads typically generate shorter responses than conversational workloads but usually have longer prompts \cite{patel2023splitwise}. 
On the other hand, compared to in-house clusters, cloud resources are inherently more dynamic and unstable, necessitating a good support for cluster size adjustments in real-time. 
Consequently, rescheduling is essential for \sys to adapt the deployment plan to varying online workloads and cluster size changes on cloud.
However, altering the deployment plan is far from trivial in cloud environments. If we re-run the scheduling algorithm from scratch and reload the model parameters according to the updated deployment plan (take minutes to complete), it would lead to severe interruption to the online services. 
% To be specific, the parameter reloading process is particularly prolonged by the constraints of budget-friendly cloud GPU instances, which often lack direct access to NVMe SSDs or shared I/O resources with other tenants. During the substantially long loading time (up to dozens of minutes in our experience), the online services must be paused, significantly impairing the stability and performance of our system.
Therefore, 
% rather than re-running the scheduling algorithm from scratch and reloading model parameters, 
we propose a \textit{lightweight rescheduling} process that only adjusts the phase designation and orchestration in the deployment plan to accommodate varying workloads and cluster sizes.

The rationality behind our lightweight rescheduling is that the changes in workload generally influence the demands on the prefill and decode phases. To elaborate, we conduct comprehensive experiments to demonstrate the impact of phase designation and orchestration over diverse workloads and cluster sizes (with fixed group construction and parallel configuration). 
% Comprehensive experiments were conducted to demonstrate the impact of the \jyh{orchestration of prefill and decode replicas} on diverse workloads and cluster sizes. We deployed LLaMA-13B models across clusters with 8, 12, and 16 A5000 GPUs, with two GPUs serving one \jyh{model pipeline}, and handle both coding and conversation workloads. 
As shown in \autoref{tab:throughputvsratio}, the coding workload, characterized by relatively longer input length and shorter output length, exhibits enhanced performance with more prefill replicas and fewer decode replicas. Conversely, the conversation workload, typified by relatively shorter prompts and longer responses, necessitates more decode replicas and fewer prefill replicas to prioritize resources to the long-running decoding, with the ideal prefill-to-decode ratio fluctuating as the cluster size varies. 
These findings underscore the critical importance of precise adjustments in the phase designation and orchestration to achieve optimal system performance and realize the ability to adapt to various workloads and cluster sizes.

The lightweight rescheduling is done by simplifying the routines introduced in \S\ref{sec:schedule_upper_level} and \S\ref{sec:schedule_lower_level}: 
% 
\begin{itemize}[topsep=0pt, leftmargin=*]
\item For the tabu search process, only the flipping phase designation approach is used to construct neighboring solutions, while the other approaches are not involved in the lightweight rescheduling.
 % 
\item The deduction of parallel configuration is skipped and the orchestration problem will be solved using the unaltered parallel configurations and the newly designated phases.
\end{itemize}
% 
Although our lightweight rescheduling leads to sub-optimality, our experiments in \S\ref{sec:effectiveness_and_ablation} show that it achieves comparable performance against rescheduling from scratch in various scenarios. More importantly, by merely adjusting the phase designation and orchestration, there is no need to reload the parameters, and thus introduces almost zero overhead to the online services. Consequently, our lightweight rescheduling improves the flexibility and robustness of \sys to a great extent.