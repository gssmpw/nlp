@misc{jiang2024hexgen,
      title={HexGen: Generative Inference of Large-Scale Foundation Model over Heterogeneous Decentralized Environment}, 
      author={Youhe Jiang and Ran Yan and Xiaozhe Yao and Yang Zhou and Beidi Chen and Binhang Yuan},
      year={2024},
      eprint={2311.11514},
      archivePrefix={arXiv},
      primaryClass={cs.DC}
}

@misc{zhao2024llmpq,
      title={LLM-PQ: Serving LLM on Heterogeneous Clusters with Phase-Aware Partition and Adaptive Quantization}, 
      author={Juntao Zhao and Borui Wan and Yanghua Peng and Haibin Lin and Chuan Wu},
      year={2024},
      eprint={2403.01136},
      archivePrefix={arXiv},
      primaryClass={cs.LG}
}

@misc{griggs2024melange,
      title={M\'elange: Cost Efficient Large Language Model Serving by Exploiting GPU Heterogeneity}, 
      author={Tyler Griggs and Xiaoxuan Liu and Jiaxiang Yu and Doyoung Kim and Wei-Lin Chiang and Alvin Cheung and Ion Stoica},
      year={2024},
      eprint={2404.14527},
      archivePrefix={arXiv},
      primaryClass={cs.DC}
}

@misc{patel2023splitwise,
      title={Splitwise: Efficient generative LLM inference using phase splitting}, 
      author={Pratyush Patel and Esha Choukse and Chaojie Zhang and Íñigo Goiri and Aashaka Shah and Saeed Maleki and Ricardo Bianchini},
      year={2023},
      eprint={2311.18677},
      archivePrefix={arXiv},
      primaryClass={cs.AR}
}

@misc{zhong2024distserve,
      title={DistServe: Disaggregating Prefill and Decoding for Goodput-optimized Large Language Model Serving}, 
      author={Yinmin Zhong and Shengyu Liu and Junda Chen and Jianbo Hu and Yibo Zhu and Xuanzhe Liu and Xin Jin and Hao Zhang},
      year={2024},
      eprint={2401.09670},
      archivePrefix={arXiv},
      primaryClass={cs.DC}
}

@misc{hu2024inference,
      title={Inference without Interference: Disaggregate LLM Inference for Mixed Downstream Workloads}, 
      author={Cunchen Hu and Heyang Huang and Liangliang Xu and Xusheng Chen and Jiang Xu and Shuang Chen and Hao Feng and Chenxi Wang and Sa Wang and Yungang Bao and Ninghui Sun and Yizhou Shan},
      year={2024},
      eprint={2401.11181},
      archivePrefix={arXiv},
      primaryClass={cs.DC}
}

@article{achiam2023gpt,
  title={Gpt-4 technical report},
  author={Achiam, Josh and Adler, Steven and Agarwal, Sandhini and Ahmad, Lama and Akkaya, Ilge and Aleman, Florencia Leoni and Almeida, Diogo and Altenschmidt, Janko and Altman, Sam and Anadkat, Shyamal and others},
  journal={arXiv preprint arXiv:2303.08774},
  year={2023}
}

@article{touvron2023llama,
  title={Llama 2: Open foundation and fine-tuned chat models},
  author={Touvron, Hugo and Martin, Louis and Stone, Kevin and Albert, Peter and Almahairi, Amjad and Babaei, Yasmine and Bashlykov, Nikolay and Batra, Soumya and Bhargava, Prajjwal and Bhosale, Shruti and others},
  journal={arXiv preprint arXiv:2307.09288},
  year={2023}
}

@misc{falcon180b,
     title={Falcon 180B},
    author={Technology Innovation Institute},
    url={https://falconllm.tii.ae/falcon-180b.html},
    year={2023}
}

@misc{zhang2022opt,
      title={OPT: Open Pre-trained Transformer Language Models}, 
      author={Susan Zhang and Stephen Roller and Naman Goyal and Mikel Artetxe and Moya Chen and Shuohui Chen and Christopher Dewan and Mona Diab and Xian Li and Xi Victoria Lin and Todor Mihaylov and Myle Ott and Sam Shleifer and Kurt Shuster and Daniel Simig and Punit Singh Koura and Anjali Sridhar and Tianlu Wang and Luke Zettlemoyer},
      year={2022},
      eprint={2205.01068},
      archivePrefix={arXiv},
      primaryClass={cs.CL}
}

@inproceedings{kwon2023efficient,
  title={Efficient memory management for large language model serving with pagedattention},
  author={Kwon, Woosuk and Li, Zhuohan and Zhuang, Siyuan and Sheng, Ying and Zheng, Lianmin and Yu, Cody Hao and Gonzalez, Joseph and Zhang, Hao and Stoica, Ion},
  booktitle={Proceedings of the 29th Symposium on Operating Systems Principles},
  pages={611--626},
  year={2023}
}

@article{zheng2023efficiently,
  title={Efficiently programming large language models using sglang},
  author={Zheng, Lianmin and Yin, Liangsheng and Xie, Zhiqiang and Huang, Jeff and Sun, Chuyue and Yu, Cody Hao and Cao, Shiyi and Kozyrakis, Christos and Stoica, Ion and Gonzalez, Joseph E and others},
  journal={arXiv preprint arXiv:2312.07104},
  year={2023}
}

@inproceedings{yu2022orca,
  title={Orca: A distributed serving system for $\{$Transformer-Based$\}$ generative models},
  author={Yu, Gyeong-In and Jeong, Joo Seong and Kim, Geon-Woo and Kim, Soojeong and Chun, Byung-Gon},
  booktitle={16th USENIX Symposium on Operating Systems Design and Implementation (OSDI 22)},
  pages={521--538},
  year={2022}
}

@article{shoeybi2019megatron,
  title={Megatron-lm: Training multi-billion parameter language models using model parallelism},
  author={Shoeybi, Mohammad and Patwary, Mostofa and Puri, Raul and LeGresley, Patrick and Casper, Jared and Catanzaro, Bryan},
  journal={arXiv preprint arXiv:1909.08053},
  year={2019}
}

@article{huang2019gpipe,
  title={Gpipe: Efficient training of giant neural networks using pipeline parallelism},
  author={Huang, Yanping and Cheng, Youlong and Bapna, Ankur and Firat, Orhan and Chen, Dehao and Chen, Mia and Lee, HyoukJoong and Ngiam, Jiquan and Le, Quoc V and Wu, Yonghui and others},
  journal={Advances in neural information processing systems},
  volume={32},
  year={2019}
}

@inproceedings{narayanan2019pipedream,
  title={PipeDream: generalized pipeline parallelism for DNN training},
  author={Narayanan, Deepak and Harlap, Aaron and Phanishayee, Amar and Seshadri, Vivek and Devanur, Nikhil R and Ganger, Gregory R and Gibbons, Phillip B and Zaharia, Matei},
  booktitle={Proceedings of the 27th ACM symposium on operating systems principles},
  pages={1--15},
  year={2019}
}

@article{kivi2024,
  title={Kivi: A tuning-free asymmetric 2bit quantization for kv cache},
  author={Liu, Zirui and Yuan, Jiayi and Jin, Hongye and Zhong, Shaochen and Xu, Zhaozhuo and Braverman, Vladimir and Chen, Beidi and Hu, Xia},
  journal={arXiv preprint arXiv:2402.02750},
  year={2024}
}

@misc{kang2024gear,
      title={GEAR: An Efficient KV Cache Compression Recipe for Near-Lossless Generative Inference of LLM}, 
      author={Hao Kang and Qingru Zhang and Souvik Kundu and Geonhwa Jeong and Zaoxing Liu and Tushar Krishna and Tuo Zhao},
      year={2024},
      eprint={2403.05527},
      archivePrefix={arXiv},
      primaryClass={cs.LG}
}

@misc{xiao2024smoothquant,
      title={SmoothQuant: Accurate and Efficient Post-Training Quantization for Large Language Models}, 
      author={Guangxuan Xiao and Ji Lin and Mickael Seznec and Hao Wu and Julien Demouth and Song Han},
      year={2024},
      eprint={2211.10438},
      archivePrefix={arXiv},
      primaryClass={cs.CL}
}

@misc{sheng2023flexgen,
      title={FlexGen: High-Throughput Generative Inference of Large Language Models with a Single GPU}, 
      author={Ying Sheng and Lianmin Zheng and Binhang Yuan and Zhuohan Li and Max Ryabinin and Daniel Y. Fu and Zhiqiang Xie and Beidi Chen and Clark Barrett and Joseph E. Gonzalez and Percy Liang and Christopher Ré and Ion Stoica and Ce Zhang},
      year={2023},
      eprint={2303.06865},
      archivePrefix={arXiv},
      primaryClass={cs.LG}
}

@misc{ainslie2023gqa,
      title={GQA: Training Generalized Multi-Query Transformer Models from Multi-Head Checkpoints}, 
      author={Joshua Ainslie and James Lee-Thorp and Michiel de Jong and Yury Zemlyanskiy and Federico Lebrón and Sumit Sanghai},
      year={2023},
      eprint={2305.13245},
      archivePrefix={arXiv},
      primaryClass={cs.CL}
}

@software{yao2023open,
author = {Yao, Xiaozhe},
month = sep,
title = {{Open Compute Framework: Peer-to-Peer Task Queue for Foundation Model Inference Serving}},
url = {https://github.com/autoai-org/OpenComputeFramework},
version = {0.0.1},
year = {2023}
}

@misc{libp2p,
    title={A modular network stack},
    author={LibP2P},
    url={https://libp2p.io/},
    year={2023}
}

@article{sotskov1995np,
  title={NP-hardness of shop-scheduling problems with three jobs},
  author={Sotskov, Yu N and Shakhlevich, Natalia V},
  journal={Discrete Applied Mathematics},
  volume={59},
  number={3},
  pages={237--266},
  year={1995},
  publisher={Elsevier}
}

@inproceedings{omar2006job,
  title={A job-shop scheduling problem (JSSP) using genetic algorithm (GA)},
  author={Omar, Mahanim and Baharum, Adam and Hasan, Yahya Abu},
  booktitle={Proceedings of the 2nd im TG T Regional Conference on Mathematics, Statistics and Applications Universiti Sains Malaysia},
  year={2006}
}

@article{glover1990tabu,
  title={Tabu search: A tutorial},
  author={Glover, Fred},
  journal={Interfaces},
  volume={20},
  number={4},
  pages={74--94},
  year={1990},
  publisher={INFORMS}
}

@book{glover1998tabu,
  title={Tabu search},
  author={Glover, Fred and Laguna, Manuel},
  year={1998},
  publisher={Springer}
}

@article{gendreau2005tabu,
  title={Tabu search},
  author={Gendreau, Michel and Potvin, Jean-Yves},
  journal={Search methodologies: introductory tutorials in optimization and decision support techniques},
  pages={165--186},
  year={2005},
  publisher={Springer}
}

@article{glover2007principles,
  title={Principles of tabu search},
  author={Glover, Fred and Laguna, Manuel and Marti, Rafael},
  journal={Approximation algorithms and metaheuristics},
  volume={23},
  pages={1--12},
  year={2007},
  publisher={Chapman \& Hall/CRC}
}

@article{hurink1994tabu,
  title={Tabu search for the job-shop scheduling problem with multi-purpose machines},
  author={Hurink, Johann and Jurisch, Bernd and Thole, Monika},
  journal={Operations-Research-Spektrum},
  volume={15},
  pages={205--215},
  year={1994},
  publisher={Springer}
}

@article{tabu_jssp_1997,
  title={An integrated approach for modeling and solving the general multiprocessor job-shop scheduling problem using tabu search},
  author={Dauz{\`e}re-P{\'e}r{\`e}s, St{\'e}phane and Paulli, Jan},
  journal={Annals of Operations Research},
  volume={70},
  number={0},
  pages={281--306},
  year={1997},
  publisher={Springer}
}

@article{zhang2007tabu,
  title={A tabu search algorithm with a new neighborhood structure for the job shop scheduling problem},
  author={Zhang, ChaoYong and Li, PeiGen and Guan, ZaiLin and Rao, YunQing},
  journal={Computers \& Operations Research},
  volume={34},
  number={11},
  pages={3229--3242},
  year={2007},
  publisher={Elsevier}
}

@article{cordeau2005new,
  title={New heuristics for the vehicle routing problem},
  author={Cordeau, Jean-Fran{\c{c}}ois and Gendreau, Michel and Hertz, Alain and Laporte, Gilbert and Sormany, Jean-Sylvain},
  journal={Logistics systems: design and optimization},
  pages={279--297},
  year={2005},
  publisher={Springer}
}

@article{burke2004state,
  title={The state of the art of nurse rostering},
  author={Burke, Edmund K and De Causmaecker, Patrick and Berghe, Greet Vanden and Van Landeghem, Hendrik},
  journal={Journal of scheduling},
  volume={7},
  pages={441--499},
  year={2004},
  publisher={Springer}
}

@article{shetty2021hierarchical,
  title={Hierarchical clustering: a survey},
  author={Shetty, Pranav and Singh, Suraj},
  journal={International Journal of Applied Research},
  volume={7},
  number={4},
  pages={178--181},
  year={2021}
}

@misc{li2023alpaserve,
      title={AlpaServe: Statistical Multiplexing with Model Parallelism for Deep Learning Serving}, 
      author={Zhuohan Li and Lianmin Zheng and Yinmin Zhong and Vincent Liu and Ying Sheng and Xin Jin and Yanping Huang and Zhifeng Chen and Hao Zhang and Joseph E. Gonzalez and Ion Stoica},
      year={2023},
      eprint={2302.11665},
      archivePrefix={arXiv},
      primaryClass={cs.LG}
}

@article{floridi2020gpt,
  title={GPT-3: Its nature, scope, limits, and consequences},
  author={Floridi, Luciano and Chiriatti, Massimo},
  journal={Minds and Machines},
  volume={30},
  pages={681--694},
  year={2020},
  publisher={Springer}
}

@article{bai2023longbench,
  title={Longbench: A bilingual, multitask benchmark for long context understanding},
  author={Bai, Yushi and Lv, Xin and Zhang, Jiajie and Lyu, Hongchang and Tang, Jiankai and Huang, Zhidian and Du, Zhengxiao and Liu, Xiao and Zeng, Aohan and Hou, Lei and others},
  journal={arXiv preprint arXiv:2308.14508},
  year={2023}
}

@misc{sharegpt,
    author={Sharegpt teams},
    url={https://sharegpt.com/},
    year={2023}
}

@article{mirjalili2019genetic,
  title={Genetic algorithm},
  author={Mirjalili, Seyedali and Mirjalili, Seyedali},
  journal={Evolutionary algorithms and neural networks: Theory and applications},
  pages={43--55},
  year={2019},
  publisher={Springer}
}

@misc{dao2022flashattention,
      title={FlashAttention: Fast and Memory-Efficient Exact Attention with IO-Awareness}, 
      author={Tri Dao and Daniel Y. Fu and Stefano Ermon and Atri Rudra and Christopher Ré},
      year={2022},
      eprint={2205.14135},
      archivePrefix={arXiv},
      primaryClass={cs.LG}
}

@misc{triton,
    title={Triton inference server: An optimized cloud and edge inferencing solution},
    author={NVIDIA Corporation},
    year={2019}
}

@misc{agrawal2023sarathi,
      title={SARATHI: Efficient LLM Inference by Piggybacking Decodes with Chunked Prefills}, 
      author={Amey Agrawal and Ashish Panwar and Jayashree Mohan and Nipun Kwatra and Bhargav S. Gulavani and Ramachandran Ramjee},
      year={2023},
      eprint={2308.16369},
      archivePrefix={arXiv},
      primaryClass={cs.LG}
}

@misc{wu2023fast,
      title={Fast Distributed Inference Serving for Large Language Models}, 
      author={Bingyang Wu and Yinmin Zhong and Zili Zhang and Gang Huang and Xuanzhe Liu and Xin Jin},
      year={2023},
      eprint={2305.05920},
      archivePrefix={arXiv},
      primaryClass={cs.LG}
}

@misc{leviathan2023fast,
      title={Fast Inference from Transformers via Speculative Decoding}, 
      author={Yaniv Leviathan and Matan Kalman and Yossi Matias},
      year={2023},
      eprint={2211.17192},
      archivePrefix={arXiv},
      primaryClass={cs.LG}
}

@misc{liu2023deja,
      title={Deja Vu: Contextual Sparsity for Efficient LLMs at Inference Time}, 
      author={Zichang Liu and Jue Wang and Tri Dao and Tianyi Zhou and Binhang Yuan and Zhao Song and Anshumali Shrivastava and Ce Zhang and Yuandong Tian and Christopher Re and Beidi Chen},
      year={2023},
      eprint={2310.17157},
      archivePrefix={arXiv},
      primaryClass={cs.LG}
}

@misc{oh2024exegpt,
      title={ExeGPT: Constraint-Aware Resource Scheduling for LLM Inference}, 
      author={Hyungjun Oh and Kihong Kim and Jaemin Kim and Sungkyun Kim and Junyeol Lee and Du-seong Chang and Jiwon Seo},
      year={2024},
      eprint={2404.07947},
      archivePrefix={arXiv},
      primaryClass={cs.DC}
}

@misc{miao2023spotserve,
      title={SpotServe: Serving Generative Large Language Models on Preemptible Instances}, 
      author={Xupeng Miao and Chunan Shi and Jiangfei Duan and Xiaoli Xi and Dahua Lin and Bin Cui and Zhihao Jia},
      year={2023},
      eprint={2311.15566},
      archivePrefix={arXiv},
      primaryClass={cs.DC}
}

@article{Miao_2022,
  title={Galvatron: Efficient Transformer Training over Multiple GPUs Using Automatic Parallelism},
  author={Miao, Xupeng and Wang, Yujie and Jiang, Youhe and Shi, Chunan and Nie, Xiaonan and Zhang, Hailin and Cui, Bin},
  journal={Proceedings of the VLDB Endowment},
  volume={16},
  number={3},
  pages={470--479},
  year={2022},
  publisher={VLDB Endowment}
}

@misc{zheng2022alpa,
      title={Alpa: Automating Inter- and Intra-Operator Parallelism for Distributed Deep Learning}, 
      author={Lianmin Zheng and Zhuohan Li and Hao Zhang and Yonghao Zhuang and Zhifeng Chen and Yanping Huang and Yida Wang and Yuanzhong Xu and Danyang Zhuo and Eric P. Xing and Joseph E. Gonzalez and Ion Stoica},
      year={2022},
      eprint={2201.12023},
      archivePrefix={arXiv},
      primaryClass={cs.LG}
}

@article{hockney1994communication,
  title={The communication challenge for MPP: Intel Paragon and Meiko CS-2},
  author={Hockney, Roger W},
  journal={Parallel computing},
  volume={20},
  number={3},
  pages={389--398},
  year={1994},
  publisher={Elsevier}
}

@article{santoso2022development,
  title={Development of Two-Stage Transportation Problem Model with Fixed Cost for Opening the Distribution Centers},
  author={Santoso, S and Heryanto, Rainisa Maini},
  journal={Jurnal Ilmiah Teknik Industri},
  volume={21},
  number={1},
  pages={63--71},
  year={2022}
}


@inproceedings{euromlsysworkshop,
  title={ML Training with Cloud GPU Shortages: Is Cross-Region the Answer?},
  author={Strati, Foteini and Elvinger, Paul and Kerimoglu, Tolga and Klimovic, Ana},
  booktitle={Proceedings of the 4th Workshop on Machine Learning and Systems},
  pages={107--116},
  year={2024}
}

@inproceedings{skypilot,
  title={$\{$SkyPilot$\}$: An intercloud broker for sky computing},
  author={Yang, Zongheng and Wu, Zhanghao and Luo, Michael and Chiang, Wei-Lin and Bhardwaj, Romil and Kwon, Woosuk and Zhuang, Siyuan and Luan, Frank Sifei and Mittal, Gautam and Shenker, Scott and others},
  booktitle={20th USENIX Symposium on Networked Systems Design and Implementation (NSDI 23)},
  pages={437--455},
  year={2023}
}

@misc{tensorrt_llm,
   title = {TensorRT-LLM},
   author = {Nvidia},
   howpublished = {\url{https://github.com/NVIDIA/TensorRT-LLM}},
   year = {2023}
}


@article{mei2024helix,
  title={Helix: Distributed Serving of Large Language Models via Max-Flow on Heterogeneous GPUs},
  author={Mei, Yixuan and Zhuang, Yonghao and Miao, Xupeng and Yang, Juncheng and Jia, Zhihao and Vinayak, Rashmi},
  journal={arXiv preprint arXiv:2406.01566},
  year={2024}
}



% ====== database reference ======

@article{zhang2022mics,
  title={MiCS: near-linear scaling for training gigantic model on public cloud},
  author={Zhang, Zhen and Zheng, Shuai and Wang, Yida and Chiu, Justin and Karypis, George and Chilimbi, Trishul and Li, Mu and Jin, Xin},
  journal={Proceedings of the VLDB Endowment},
  volume={16},
  number={1},
  pages={37--50},
  year={2022},
  publisher={VLDB Endowment}
}

@inproceedings{nagrecha2021model,
  title={Model-parallel model selection for deep learning systems},
  author={Nagrecha, Kabir},
  booktitle={Proceedings of the 2021 international conference on management of data},
  pages={2929--2931},
  year={2021}
}

@inproceedings{miao2021heterogeneity,
  title={Heterogeneity-aware distributed machine learning training via partial reduce},
  author={Miao, Xupeng and Nie, Xiaonan and Shao, Yingxia and Yang, Zhi and Jiang, Jiawei and Ma, Lingxiao and Cui, Bin},
  booktitle={Proceedings of the 2021 International Conference on Management of Data},
  pages={2262--2270},
  year={2021}
}

@article{miao2023sdpipe,
  title={Sdpipe: A semi-decentralized framework for heterogeneity-aware pipeline-parallel training},
  author={Miao, Xupeng and Shi, Yining and Yang, Zhi and Cui, Bin and Jia, Zhihao},
  journal={Proceedings of the VLDB Endowment},
  volume={16},
  number={9},
  pages={2354--2363},
  year={2023},
  publisher={VLDB Endowment}
}

@article{nie2023flexmoe,
  title={Flexmoe: Scaling large-scale sparse pre-trained model training via dynamic device placement},
  author={Nie, Xiaonan and Miao, Xupeng and Wang, Zilong and Yang, Zichao and Xue, Jilong and Ma, Lingxiao and Cao, Gang and Cui, Bin},
  journal={Proceedings of the ACM on Management of Data},
  volume={1},
  number={1},
  pages={1--19},
  year={2023},
  publisher={ACM New York, NY, USA}
}

@article{nie2023angel,
  title={Angel-PTM: A Scalable and Economical Large-Scale Pre-Training System in Tencent},
  author={Nie, Xiaonan and Liu, Yi and Fu, Fangcheng and Xue, Jinbao and Jiao, Dian and Miao, Xupeng and Tao, Yangyu and Cui, Bin},
  journal={Proceedings of the VLDB Endowment},
  volume={16},
  number={12},
  pages={3781--3794},
  year={2023},
  publisher={VLDB Endowment}
}

@article{wang2024improving,
  title={Improving Automatic Parallel Training via Balanced Memory Workload Optimization},
  author={Wang, Yujie and Jiang, Youhe and Miao, Xupeng and Fu, Fangcheng and Zhu, Shenhan and Nie, Xiaonan and Tu, Yaofeng and Cui, Bin},
  journal={IEEE Transactions on Knowledge and Data Engineering},
  year={2024},
  publisher={IEEE}
}

% ====== new work reference ======

@article{qin2024mooncake,
  title={Mooncake: Kimi's KVCache-centric Architecture for LLM Serving},
  author={Qin, Ruoyu and Li, Zheming and He, Weiran and Zhang, Mingxing and Wu, Yongwei and Zheng, Weimin and Xu, Xinran},
  journal={arXiv preprint arXiv:2407.00079},
  year={2024}
}

@article{jin2024p,
  title={P/D-Serve: Serving Disaggregated Large Language Model at Scale},
  author={Jin, Yibo and Wang, Tao and Lin, Huimin and Song, Mingyang and Li, Peiyang and Ma, Yipeng and Shan, Yicheng and Yuan, Zhengfan and Li, Cailong and Sun, Yajing and others},
  journal={arXiv preprint arXiv:2408.08147},
  year={2024}
}

@inproceedings{um2024metis,
  title={Metis: Fast Automatic Distributed Training on Heterogeneous $\{$GPUs$\}$},
  author={Um, Taegeon and Oh, Byungsoo and Kang, Minyoung and Lee, Woo-Yeon and Kim, Goeun and Kim, Dongseob and Kim, Youngtaek and Muzzammil, Mohd and Jeon, Myeongjae},
  booktitle={2024 USENIX Annual Technical Conference (USENIX ATC 24)},
  pages={563--578},
  year={2024}
}

@article{hethub,
  author       = {Si Xu and
                  Zixiao Huang and
                  Yan Zeng and
                  Shengen Yan and
                  Xuefei Ning and
                  Haolin Ye and
                  Sipei Gu and
                  Chunsheng Shui and
                  Zhezheng Lin and
                  Hao Zhang and
                  Sheng Wang and
                  Guohao Dai and
                  Yu Wang},
  title        = {HetHub: {A} Heterogeneous distributed hybrid training system for large-scale
                  models},
  journal      = {CoRR},
  volume       = {abs/2405.16256},
  year         = {2024},
}

@inproceedings{acc_par,
  author       = {Linghao Song and
                  Fan Chen and
                  Youwei Zhuo and
                  Xuehai Qian and
                  Hai Li and
                  Yiran Chen},
  title        = {AccPar: Tensor Partitioning for Heterogeneous Deep Learning Accelerators},
  booktitle    = {{IEEE} International Symposium on High Performance Computer Architecture, 2020 (HPCA 2020)},
  pages        = {342--355},
  year         = {2020},
}

@inproceedings{amp_hetero_model_parallel,
  author       = {Dacheng Li and
                  Hongyi Wang and
                  Eric P. Xing and
                  Hao Zhang},
  title        = {{AMP:} Automatically Finding Model Parallel Strategies with Heterogeneity
                  Awareness},
  booktitle    = {Annual Conference on Neural Information Processing Systems 2022 (NeurIPS 2022)},
  year         = {2022},
}

@inproceedings{whale,
  author       = {Xianyan Jia and
                  Le Jiang and
                  Ang Wang and
                  Wencong Xiao and
                  Ziji Shi and
                  Jie Zhang and
                  Xinyuan Li and
                  Langshi Chen and
                  Yong Li and
                  Zhen Zheng and
                  Xiaoyong Liu and
                  Wei Lin},
  title        = {Whale: Efficient Giant Model Training over Heterogeneous GPUs},
  booktitle    = {2022 {USENIX} Annual Technical Conference ({ATC} 2022)},
  pages        = {673--688},
  year         = {2022},
}

@inproceedings{hap,
  author       = {Shiwei Zhang and
                  Lansong Diao and
                  Chuan Wu and
                  Zongyan Cao and
                  Siyu Wang and
                  Wei Lin},
  title        = {{HAP:} {SPMD} {DNN} Training on Heterogeneous {GPU} Clusters with
                  Automated Program Synthesis},
  booktitle    = {Proceedings of the Nineteenth European Conference on Computer Systems (EuroSys 2024)},
  pages        = {524--541},
  year         = {2024},
}

@inproceedings{duan2024parcae,
  title={Parcae: Proactive,$\{$Liveput-Optimized$\}$$\{$DNN$\}$ Training on Preemptible Instances},
  author={Duan, Jiangfei and Song, Ziang and Miao, Xupeng and Xi, Xiaoli and Lin, Dahua and Xu, Harry and Zhang, Minjia and Jia, Zhihao},
  booktitle={21st USENIX Symposium on Networked Systems Design and Implementation (NSDI 24)},
  pages={1121--1139},
  year={2024}
}

@article{yousif2018cloud,
  title={Cloud computing reliability—failure is an option},
  author={Yousif, Mazin},
  journal={IEEE Cloud Computing},
  volume={5},
  number={3},
  pages={4--5},
  year={2018},
  publisher={IEEE}
}

@article{erben2024can,
  title={How Can We Train Deep Learning Models Across Clouds and Continents? An Experimental Study},
  author={Erben, Alexander and Mayer, Ruben and Jacobsen, Hans-Arno},
  journal={Proceedings of the VLDB Endowment},
  volume={17},
  number={6},
  pages={1214--1226},
  year={2024},
  publisher={VLDB Endowment}
}

@article{wang2024burstgpt,
  title={BurstGPT: A Real-world Workload Dataset to Optimize LLM Serving Systems},
  author={Wang, Yuxin and Chen, Yuhan and Li, Zeyu and Kang, Xueze and Tang, Zhenheng and He, Xin and Guo, Rui and Wang, Xin and Wang, Qiang and Zhou, Amelie Chi and others},
  year={2024}
}

% ==== no cite ====

@article{murray2021tf,
  title={tf. data: A Machine Learning Data Processing Framework},
  author={Murray, Derek G and {\v{S}}im{\v{s}}a, Ji{\v{r}}{\'\i} and Klimovic, Ana and Indyk, Ihor},
  journal={Proceedings of the VLDB Endowment},
  volume={14},
  number={12},
  pages={2945--2958},
  year={2021},
  publisher={Association for Computing Machinery}
}

@inproceedings{miao2024demystifying,
  title={Demystifying Data Management for Large Language Models},
  author={Miao, Xupeng and Jia, Zhihao and Cui, Bin},
  booktitle={Companion of the 2024 International Conference on Management of Data},
  pages={547--555},
  year={2024}
}

@article{xia2023flash,
  title={Flash-LLM: Enabling Cost-Effective and Highly-Efficient Large Generative Model Inference with Unstructured Sparsity},
  author={Xia, Haojun and Zheng, Zhen and Li, Yuchao and Zhuang, Donglin and Zhou, Zhongzhu and Qiu, Xiafei and Li, Yong and Lin, Wei and Song, Shuaiwen Leon},
  journal={Proceedings of the VLDB Endowment},
  volume={17},
  number={2},
  pages={211--224},
  year={2023},
  publisher={VLDB Endowment}
}


@Misc{Nvida_blackwell,
title = {NVIDIA Blackwell Platform Arrives to Power a New Era of Computing},
author={Nvidia},
url={https://nvidianews.nvidia.com/news/nvidia-blackwell-platform-arrives-to-power-a-new-era-of-computing},
year = {2024},
}

@Misc{Nvida_hopper,
title = {NVIDIA Announces Hopper Architecture, the Next Generation of Accelerated Computing},
author={Nvidia},
url={https://nvidianews.nvidia.com/news/nvidia-announces-hopper-architecture-the-next-generation-of-accelerated-computing},
year = {2022},
}

@Misc{Nvida_turing,
title = {NVIDIA Reinvents Computer Graphics with Turing Architecture},
author={Nvidia},
url={https://nvidianews.nvidia.com/news/nvidia-reinvents-computer-graphics-with-turing-architecture},
year = {2018},
}

@Misc{Nvida_ampere,
title = {NVIDIA’s New Ampere Data Center GPU in Full Production},
author={Nvidia},
url={https://nvidianews.nvidia.com/news/nvidias-new-ampere-data-center-gpu-in-full-production},
year = {2020},
}

@Misc{Nvidia_tesla,
title = { GPU Computing Solutions for HPC},
author={Nvidia},
url={https://www.nvidia.com/docs/IO/43395/tesla_product_overview_dec.pdf},
year = {2006},
}

@Misc{Amazon,
title = {Amazon EC2 Instance types},
author={Amazon},
url={https://aws.amazon.com/ec2/instance-types/},
year = {2024},
}


@inproceedings{zhang2025sageattention,
      title={SageAttention: Accurate 8-Bit Attention for Plug-and-play Inference Acceleration}, 
      author={Zhang, Jintao and Wei, Jia and Zhang, Pengle and Zhu, Jun and Chen, Jianfei},
      booktitle={International Conference on Learning Representations (ICLR)},
      year={2025}
}

@misc{zhang2024sageattention2,
      title={SageAttention2: Efficient Attention with Thorough Outlier Smoothing and Per-thread INT4 Quantization}, 
      author={Jintao Zhang and Haofeng Huang and Pengle Zhang and Jia Wei and Jun Zhu and Jianfei Chen},
      year={2024},
      eprint={2411.10958},
      archivePrefix={arXiv},
      primaryClass={cs.LG},
      url={https://arxiv.org/abs/2411.10958}, 
}

@misc{zhang2025spargeattn,
      title={SpargeAttn: Accurate Sparse Attention Accelerating Any Model Inference}, 
      author={Jintao Zhang and Chendong Xiang and Haofeng Huang and Haocheng Xi and Jia Wei and Jun Zhu and Jianfei Chen},
      year={2025}
}

@article{jiang2025demystifying,
  title={Demystifying Cost-Efficiency in LLM Serving over Heterogeneous GPUs},
  author={Jiang, Youhe and Fu, Fangcheng and Yao, Xiaozhe and He, Guoliang and Miao, Xupeng and Klimovic, Ana and Cui, Bin and Yuan, Binhang and Yoneki, Eiko},
  journal={arXiv preprint arXiv:2502.00722},
  year={2025}
}