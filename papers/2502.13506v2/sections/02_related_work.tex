
\section{Related Work}

\header{Negation in NLP.}
Negation is a complex semantic phenomenon in natural language that affects the performance of various Natural Language Processing (NLP) applications \cite{sineva2021negation,morante2021recent}. It "transforms an expression into another expression whose meaning is in some way opposed to the original" as mentioned by \citet{morante2021recent}. It occurs frequently, with the proportion of sentences with negation in English corpora ranging between 9\% and 32\% \cite{sineva2021negation}. Negation is a challenging problem in machine translation, natural language inference, and sentiment analysis \cite{garcia2023not, sineva2021negation}.

To highlight this problem, \citet{garcia2023not} have created a dataset to assess LLMs handling of negation in NLP. They find that LLMs struggle with negative sentences and lack a deep understanding in negation. The importance of negation in NLP tasks is also highlighted by \citet{hossain2022analysis}, which explores the role of negation in eight corpora for six popular natural language understanding tasks. The study finds that negation is virtually ignored by these corpora and that state-of-the-art transformers trained with these corpora face challenges in understanding negation.

\header{Negation in Information Retrieval.}
At the time of the NevIR paper's publication, little to no prior research had explored negation in neural IR models. More recently, \citet{zhang2024excluir} introduced ExcluIR, which includes an evaluation benchmark and a training set designed to improve retrieval modelsâ€™ ability to handle exclusionary queries. While both NevIR and ExcluIR examine how IR models handle negation, they address different aspects of it: NevIR focuses on negation within documents, whereas ExcluIR emphasizes the exclusionary nature of queries. Nonetheless, it can be considered a branch of negation, rather than a completely separate class.

Additionally, \citet{malaviya2023quest} developed QUEST, a dataset of natural language queries with implicit set operations, which map to a set of entities corresponding to Wikipedia documents, including negation. They analyzed several modern retrieval systems and, in alignment with the findings from NevIR, observed that IR models often struggle with queries involving negation

\header{LLMs for Information Retrieval.}
As LLMs have demonstrated strong representational capabilities, they are increasingly used as backbones in information retrieval (IR) architectures \cite{zhularge}. These backbones are integrated into both bi-encoder and cross-encoder models, enhancing query-document representations for retrieval and reranking tasks \cite{zhularge}. Around the introduction of NevIR \cite{weller2024nevirnegationneuralinformation}, most LLM-based IR models primarily relied on what are now considered relatively smaller-scale models, such as BERT \cite{BERT} and T5 \cite{T5}. With the emergence of larger and more accessible open-source LLMs, including those from LLaMA-3 \cite{llama3}, Mistral \cite{mistral7b}, and Qwen-2 \cite{yang2024qwen2technicalreport}, recent developments have integrated these models into IR systems, achieving state-of-the-art performance ~\cite{promptriever, repllama_rankllama, qwen_gte, gritlm}.

With these improvements in LLM performance, researchers have also begun using LLMs directly as rerankers, prompting them to reorder a list of retrieved documents given a query \cite{rankGPT, rankLLM}. RankGPT \cite{rankGPT} has demonstrated that generative LLMs, when prompted effectively, can outperform traditional rerankers by leveraging their strong contextual understanding. Similarly, RankLLM \cite{rankLLM} fine-tunes open-source LLMs for listwise document ranking, showing competitive performance with minimal additional training. To address the efficiency limitations of these models, ~\citet{FIRST}  introduce an approach that leverages the output logits of the first generated identifier to directly derive a ranked ordering of the candidates.
