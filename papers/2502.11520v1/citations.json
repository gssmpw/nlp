[
  {
    "index": 0,
    "papers": [
      {
        "key": "wei2022cot",
        "author": "Wei, Jason and Wang, Xuezhi and Schuurmans, Dale and Bosma, Maarten and Xia, Fei and Chi, Ed and Le, Quoc V and Zhou, Denny and others",
        "title": "Chain-of-thought prompting elicits reasoning in large language models"
      }
    ]
  },
  {
    "index": 1,
    "papers": [
      {
        "key": "yao2024tree",
        "author": "Yao, Shunyu and Yu, Dian and Zhao, Jeffrey and Shafran, Izhak and Griffiths, Tom and Cao, Yuan and Narasimhan, Karthik",
        "title": "Tree of thoughts: Deliberate problem solving with large language models"
      }
    ]
  },
  {
    "index": 2,
    "papers": [
      {
        "key": "yu2023metamath",
        "author": "Yu, Longhui and Jiang, Weisen and Shi, Han and Yu, Jincheng and Liu, Zhengying and Zhang, Yu and Kwok, James T and Li, Zhenguo and Weller, Adrian and Liu, Weiyang",
        "title": "Metamath: Bootstrap your own mathematical questions for large language models"
      },
      {
        "key": "luo2023wizardmath",
        "author": "Luo, Haipeng and Sun, Qingfeng and Xu, Can and Zhao, Pu and Lou, Jianguang and Tao, Chongyang and Geng, Xiubo and Lin, Qingwei and Chen, Shifeng and Zhang, Dongmei",
        "title": "Wizardmath: Empowering mathematical reasoning for large language models via reinforced evol-instruct"
      },
      {
        "key": "yue2023mammoth",
        "author": "Yue, Xiang and Qu, Xingwei and Zhang, Ge and Fu, Yao and Huang, Wenhao and Sun, Huan and Su, Yu and Chen, Wenhu",
        "title": "Mammoth: Building math generalist models through hybrid instruction tuning"
      },
      {
        "key": "gou2023tora",
        "author": "Gou, Zhibin and Shao, Zhihong and Gong, Yeyun and Shen, Yelong and Yang, Yujiu and Huang, Minlie and Duan, Nan and Chen, Weizhu",
        "title": "Tora: A tool-integrated reasoning agent for mathematical problem solving"
      }
    ]
  },
  {
    "index": 3,
    "papers": [
      {
        "key": "openai2024o1",
        "author": "OpenAI",
        "title": "Learning to reason with LLMs"
      },
      {
        "key": "openai2024o1_mini",
        "author": "OpenAI",
        "title": "Openai-o1-mini: Advancing cost efficient reasoning"
      }
    ]
  },
  {
    "index": 4,
    "papers": [
      {
        "key": "snell2024scaling",
        "author": "Snell, Charlie and Lee, Jaehoon and Xu, Kelvin and Kumar, Aviral",
        "title": "Scaling llm test-time compute optimally can be more effective than scaling model parameters"
      }
    ]
  },
  {
    "index": 5,
    "papers": [
      {
        "key": "zheng2024processbench",
        "author": "Zheng, Chujie and Zhang, Zhenru and Zhang, Beichen and Lin, Runji and Lu, Keming and Yu, Bowen and Liu, Dayiheng and Zhou, Jingren and Lin, Junyang",
        "title": "Processbench: Identifying process errors in mathematical reasoning"
      },
      {
        "key": "zhang2025lessons",
        "author": "Zhang, Zhenru and Zheng, Chujie and Wu, Yangzhen and Zhang, Beichen and Lin, Runji and Yu, Bowen and Liu, Dayiheng and Zhou, Jingren and Lin, Junyang",
        "title": "The Lessons of Developing Process Reward Models in Mathematical Reasoning"
      },
      {
        "key": "mcaleese2024llm",
        "author": "McAleese, Nat and Pokorny, Rai Michael and Uribe, Juan Felipe Ceron and Nitishinskaya, Evgenia and Trebacz, Maja and Leike, Jan",
        "title": "Llm critics help catch llm bugs"
      }
    ]
  },
  {
    "index": 6,
    "papers": [
      {
        "key": "wang2024math",
        "author": "Wang, Peiyi and Li, Lei and Shao, Zhihong and Xu, Runxin and Dai, Damai and Li, Yifei and Chen, Deli and Wu, Yu and Sui, Zhifang",
        "title": "Math-shepherd: Verify and reinforce llms step-by-step without human annotations"
      }
    ]
  },
  {
    "index": 7,
    "papers": [
      {
        "key": "lightman2023let",
        "author": "Lightman, Hunter and Kosaraju, Vineet and Burda, Yura and Edwards, Harri and Baker, Bowen and Lee, Teddy and Leike, Jan and Schulman, John and Sutskever, Ilya and Cobbe, Karl",
        "title": "Let's verify step by step"
      }
    ]
  },
  {
    "index": 8,
    "papers": [
      {
        "key": "wu2023fine",
        "author": "Wu, Zeqiu and Hu, Yushi and Shi, Weijia and Dziri, Nouha and Suhr, Alane and Ammanabrolu, Prithviraj and Smith, Noah A and Ostendorf, Mari and Hajishirzi, Hannaneh",
        "title": "Fine-grained human feedback gives better rewards for language model training"
      }
    ]
  },
  {
    "index": 9,
    "papers": [
      {
        "key": "uesato2022solving",
        "author": "Uesato, Jonathan and Kushman, Nate and Kumar, Ramana and Song, Francis and Siegel, Noah and Wang, Lisa and Creswell, Antonia and Irving, Geoffrey and Higgins, Irina",
        "title": "Solving math word problems with process-and outcome-based feedback"
      },
      {
        "key": "pan2023let",
        "author": "Pan, Sarah and Lialin, Vladislav and Muckatira, Sherin and Rumshisky, Anna",
        "title": "Let's Reinforce Step by Step"
      }
    ]
  },
  {
    "index": 10,
    "papers": [
      {
        "key": "luo2024improve",
        "author": "Luo, Liangchen and Liu, Yinxiao and Liu, Rosanne and Phatale, Samrat and Lara, Harsh and Li, Yunxuan and Shu, Lei and Zhu, Yun and Meng, Lei and Sun, Jiao and others",
        "title": "Improve Mathematical Reasoning in Language Models by Automated Process Supervision"
      }
    ]
  },
  {
    "index": 11,
    "papers": [
      {
        "key": "zheng2023judging",
        "author": "Zheng, Lianmin and Chiang, Wei-Lin and Sheng, Ying and Zhuang, Siyuan and Wu, Zhanghao and Zhuang, Yonghao and Lin, Zi and Li, Zhuohan and Li, Dacheng and Xing, Eric and others",
        "title": "Judging llm-as-a-judge with mt-bench and chatbot arena"
      }
    ]
  },
  {
    "index": 12,
    "papers": [
      {
        "key": "zhang2025lessons",
        "author": "Zhang, Zhenru and Zheng, Chujie and Wu, Yangzhen and Zhang, Beichen and Lin, Runji and Yu, Bowen and Liu, Dayiheng and Zhou, Jingren and Lin, Junyang",
        "title": "The Lessons of Developing Process Reward Models in Mathematical Reasoning"
      }
    ]
  }
]