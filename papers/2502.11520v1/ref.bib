@inproceedings{park2023generative,
  title={Generative agents: Interactive simulacra of human behavior},
  author={Park, Joon Sung and O'Brien, Joseph and Cai, Carrie Jun and Morris, Meredith Ringel and Liang, Percy and Bernstein, Michael S},
  booktitle={Proceedings of the 36th annual acm symposium on user interface software and technology},
  pages={1--22},
  year={2023}
}

@article{kaddour2023challenges,
  title={Challenges and applications of large language models},
  author={Kaddour, Jean and Harris, Joshua and Mozes, Maximilian and Bradley, Herbie and Raileanu, Roberta and McHardy, Robert},
  journal={arXiv preprint arXiv:2307.10169},
  year={2023}
}

@article{openai2023gpt,
  title={Gpt-4 technical report},
  author={OpenAI},
  journal={arXiv preprint arXiv:2303.08774},
  year={2023}
}

@article{zhu2024deepseek,
  title={DeepSeek-Coder-V2: Breaking the Barrier of Closed-Source Models in Code Intelligence},
  author={Zhu, Qihao and Guo, Daya and Shao, Zhihong and Yang, Dejian and Wang, Peiyi and Xu, Runxin and Wu, Y and Li, Yukun and Gao, Huazuo and Ma, Shirong and others},
  journal={arXiv preprint arXiv:2406.11931},
  year={2024}
}

@article{muennighoff2023scaling,
  title={Scaling data-constrained language models},
  author={Muennighoff, Niklas and Rush, Alexander and Barak, Boaz and Le Scao, Teven and Tazi, Nouamane and Piktus, Aleksandra and Pyysalo, Sampo and Wolf, Thomas and Raffel, Colin A},
  journal={Advances in Neural Information Processing Systems},
  volume={36},
  pages={50358--50376},
  year={2023}
}

@article{wei2022emergent,
  title={Emergent abilities of large language models},
  author={Wei, Jason and Tay, Yi and Bommasani, Rishi and Raffel, Colin and Zoph, Barret and Borgeaud, Sebastian and Yogatama, Dani and Bosma, Maarten and Zhou, Denny and Metzler, Donald and others},
  journal={arXiv preprint arXiv:2206.07682},
  year={2022}
}

@article{zheng2023judging,
  title={Judging llm-as-a-judge with mt-bench and chatbot arena},
  author={Zheng, Lianmin and Chiang, Wei-Lin and Sheng, Ying and Zhuang, Siyuan and Wu, Zhanghao and Zhuang, Yonghao and Lin, Zi and Li, Zhuohan and Li, Dacheng and Xing, Eric and others},
  journal={Advances in Neural Information Processing Systems},
  volume={36},
  pages={46595--46623},
  year={2023}
}

@article{wei2022cot,
  title={Chain-of-thought prompting elicits reasoning in large language models},
  author={Wei, Jason and Wang, Xuezhi and Schuurmans, Dale and Bosma, Maarten and Xia, Fei and Chi, Ed and Le, Quoc V and Zhou, Denny and others},
  journal={Advances in neural information processing systems},
  volume={35},
  pages={24824--24837},
  year={2022}
}

@inproceedings{ji2023towards,
  title={Towards mitigating LLM hallucination via self reflection},
  author={Ji, Ziwei and Yu, Tiezheng and Xu, Yan and Lee, Nayeon and Ishii, Etsuko and Fung, Pascale},
  booktitle={Findings of the Association for Computational Linguistics: EMNLP 2023},
  pages={1827--1843},
  year={2023}
}

@article{swiechowski2023monte,
  title={Monte Carlo tree search: A review of recent modifications and applications},
  author={{\'S}wiechowski, Maciej and Godlewski, Konrad and Sawicki, Bartosz and Ma{\'n}dziuk, Jacek},
  journal={Artificial Intelligence Review},
  volume={56},
  number={3},
  pages={2497--2562},
  year={2023},
  publisher={Springer}
}

@inproceedings{besta2024graph,
  title={Graph of thoughts: Solving elaborate problems with large language models},
  author={Besta, Maciej and Blach, Nils and Kubicek, Ales and Gerstenberger, Robert and Podstawski, Michal and Gianinazzi, Lukas and Gajda, Joanna and Lehmann, Tomasz and Niewiadomski, Hubert and Nyczyk, Piotr and others},
  booktitle={Proceedings of the AAAI Conference on Artificial Intelligence},
  volume={38},
  number={16},
  pages={17682--17690},
  year={2024}
}

@article{yao2024tree,
  title={Tree of thoughts: Deliberate problem solving with large language models},
  author={Yao, Shunyu and Yu, Dian and Zhao, Jeffrey and Shafran, Izhak and Griffiths, Tom and Cao, Yuan and Narasimhan, Karthik},
  journal={Advances in Neural Information Processing Systems},
  volume={36},
  year={2024}
}

@article{zhao2024large,
  title={Large language models as commonsense knowledge for large-scale task planning},
  author={Zhao, Zirui and Lee, Wee Sun and Hsu, David},
  journal={Advances in Neural Information Processing Systems},
  volume={36},
  year={2024}
}

@article{shinn2024reflexion,
  title={Reflexion: Language agents with verbal reinforcement learning},
  author={Shinn, Noah and Cassano, Federico and Gopinath, Ashwin and Narasimhan, Karthik and Yao, Shunyu},
  journal={Advances in Neural Information Processing Systems},
  volume={36},
  year={2024}
}

@inproceedings{koa2024learning,
  title={Learning to generate explainable stock predictions using self-reflective large language models},
  author={Koa, Kelvin JL and Ma, Yunshan and Ng, Ritchie and Chua, Tat-Seng},
  booktitle={Proceedings of the ACM on Web Conference 2024},
  pages={4304--4315},
  year={2024}
}

@inproceedings{wang2024math,
  title={Math-shepherd: Verify and reinforce llms step-by-step without human annotations},
  author={Wang, Peiyi and Li, Lei and Shao, Zhihong and Xu, Runxin and Dai, Damai and Li, Yifei and Chen, Deli and Wu, Yu and Sui, Zhifang},
  booktitle={Proceedings of the 62nd Annual Meeting of the Association for Computational Linguistics},
  pages={9426--9439},
  year={2024}
}

@inproceedings{kocsis2006bandit,
  title={Bandit based monte-carlo planning},
  author={Kocsis, Levente and Szepesv{\'a}ri, Csaba},
  booktitle={European conference on machine learning},
  pages={282--293},
  year={2006},
  organization={Springer}
}

@inproceedings{coulom2006efficient,
  title={Efficient selectivity and backup operators in Monte-Carlo tree search},
  author={Coulom, R{\'e}mi},
  booktitle={International conference on computers and games},
  pages={72--83},
  year={2006},
  organization={Springer}
}

@misc{teamqwen2024qwq,
  author       = {Team Qwen},
  title        = {Qwq: Reflect deeply on the boundaries of the unknown},
  year         = {2024},
  month        = {November},
  url          = {https://qwenlm.github.io/blog/qwq-32b-preview/},
}

@misc{openai2024o1,
  author       = {OpenAI},
  title        = {Learning to reason with LLMs},
  year         = {2024},
  url          = {https://openai.com/index/learning-to-reason-with-llms/},
}

@misc{openai2024o1_mini,
  author       = {OpenAI},
  title        = {Openai-o1-mini: Advancing cost efficient reasoning},
  year         = {2024},
  url          = {https://openai.com/index/openai-o1-mini-advancing-cost-efficient-reasoning/},
}

@article{lightman2023let,
  title={Let's verify step by step},
  author={Lightman, Hunter and Kosaraju, Vineet and Burda, Yura and Edwards, Harri and Baker, Bowen and Lee, Teddy and Leike, Jan and Schulman, John and Sutskever, Ilya and Cobbe, Karl},
  journal={arXiv preprint arXiv:2305.20050},
  year={2023}
}

@article{luo2024improve,
  title={Improve Mathematical Reasoning in Language Models by Automated Process Supervision},
  author={Luo, Liangchen and Liu, Yinxiao and Liu, Rosanne and Phatale, Samrat and Lara, Harsh and Li, Yunxuan and Shu, Lei and Zhu, Yun and Meng, Lei and Sun, Jiao and others},
  journal={arXiv preprint arXiv:2406.06592},
  year={2024}
}


@article{cobbe2021orm1,
  title={Training verifiers to solve math word problems},
  author={Cobbe, Karl and Kosaraju, Vineet and Bavarian, Mohammad and Chen, Mark and Jun, Heewoo and Kaiser, Lukasz and Plappert, Matthias and Tworek, Jerry and Hilton, Jacob and Nakano, Reiichiro and others},
  journal={arXiv preprint arXiv:2110.14168},
  year={2021}
}

@article{yu2023orm2,
  title={Outcome-supervised verifiers for planning in mathematical reasoning},
  author={Yu, Fei and Gao, Anningzhe and Wang, Benyou},
  journal={arXiv preprint arXiv:2311.09724},
  year={2023}
}

@article{zhang2025lessons,
  title={The Lessons of Developing Process Reward Models in Mathematical Reasoning},
  author={Zhang, Zhenru and Zheng, Chujie and Wu, Yangzhen and Zhang, Beichen and Lin, Runji and Yu, Bowen and Liu, Dayiheng and Zhou, Jingren and Lin, Junyang},
  journal={arXiv preprint arXiv:2501.07301},
  year={2025}
}

@article{uesato2022solving,
  title={Solving math word problems with process-and outcome-based feedback},
  author={Uesato, Jonathan and Kushman, Nate and Kumar, Ramana and Song, Francis and Siegel, Noah and Wang, Lisa and Creswell, Antonia and Irving, Geoffrey and Higgins, Irina},
  journal={arXiv preprint arXiv:2211.14275},
  year={2022}
}


@article{zheng2024processbench,
  title={Processbench: Identifying process errors in mathematical reasoning},
  author={Zheng, Chujie and Zhang, Zhenru and Zhang, Beichen and Lin, Runji and Lu, Keming and Yu, Bowen and Liu, Dayiheng and Zhou, Jingren and Lin, Junyang},
  journal={arXiv preprint arXiv:2412.06559},
  year={2024}
}

@article{cao2024towards,
  title={Towards Scalable Automated Alignment of LLMs: A Survey},
  author={Cao, Boxi and Lu, Keming and Lu, Xinyu and Chen, Jiawei and Ren, Mengjie and Xiang, Hao and Liu, Peilin and Lu, Yaojie and He, Ben and Han, Xianpei and others},
  journal={arXiv preprint arXiv:2406.01252},
  year={2024}
}

@article{zhou2024your,
  title={Is your model really a good math reasoner? evaluating mathematical reasoning with checklist},
  author={Zhou, Zihao and Liu, Shudong and Ning, Maizhen and Liu, Wei and Wang, Jindong and Wong, Derek F and Huang, Xiaowei and Wang, Qiufeng and Huang, Kaizhu},
  journal={arXiv preprint arXiv:2407.08733},
  year={2024}
}

@article{wang2022self,
  title={Self-consistency improves chain of thought reasoning in language models},
  author={Wang, Xuezhi and Wei, Jason and Schuurmans, Dale and Le, Quoc and Chi, Ed and Narang, Sharan and Chowdhery, Aakanksha and Zhou, Denny},
  journal={arXiv preprint arXiv:2203.11171},
  year={2022}
}

@inproceedings{fu2022complexity,
  title={Complexity-based prompting for multi-step reasoning},
  author={Fu, Yao and Peng, Hao and Sabharwal, Ashish and Clark, Peter and Khot, Tushar},
  booktitle={The Eleventh International Conference on Learning Representations},
  year={2022}
}

@article{jin2024impact,
  title={The impact of reasoning step length on large language models},
  author={Jin, Mingyu and Yu, Qinkai and Shu, Dong and Zhao, Haiyan and Hua, Wenyue and Meng, Yanda and Zhang, Yongfeng and Du, Mengnan},
  journal={arXiv preprint arXiv:2401.04925},
  year={2024}
}

@inproceedings{dong2024survey,
  title={A survey on in-context learning},
  author={Dong, Qingxiu and Li, Lei and Dai, Damai and Zheng, Ce and Ma, Jingyuan and Li, Rui and Xia, Heming and Xu, Jingjing and Wu, Zhiyong and Chang, Baobao and others},
  booktitle={Proceedings of the 2024 Conference on Empirical Methods in Natural Language Processing},
  pages={1107--1128},
  year={2024}
}

@article{xiong2024building,
  title={Building math agents with multi-turn iterative preference learning},
  author={Xiong, Wei and Shi, Chengshuai and Shen, Jiaming and Rosenberg, Aviv and Qin, Zhen and Calandriello, Daniele and Khalman, Misha and Joshi, Rishabh and Piot, Bilal and Saleh, Mohammad and others},
  journal={arXiv preprint arXiv:2409.02392},
  year={2024}
}

@article{yang2024qwen25math,
  title={Qwen2.5-Math Technical Report: Toward Mathematical Expert Model via Self-Improvement}, 
  author={An Yang and Beichen Zhang and Binyuan Hui and Bofei Gao and Bowen Yu and Chengpeng Li and Dayiheng Liu and Jianhong Tu and Jingren Zhou and Junyang Lin and Keming Lu and Mingfeng Xue and Runji Lin and Tianyu Liu and Xingzhang Ren and Zhenru Zhang},
  journal={arXiv preprint arXiv:2409.12122},
  year={2024}
}

@article{wei2023skywork,
  title={Skywork: A more open bilingual foundation model},
  author={Wei, Tianwen and Zhao, Liang and Zhang, Lichang and Zhu, Bo and Wang, Lijie and Yang, Haihua and Li, Biye and Cheng, Cheng and L{\"u}, Weiwei and Hu, Rui and others},
  journal={arXiv preprint arXiv:2310.19341},
  year={2023}
}

@misc{skyworkopeno12024,
  title={Skywork-o1 Open Series},
  author={Skywork},
  year={2024},
  month={November},
  howpublished={\url{https://huggingface.co/Skywork}},
  url={https://huggingface.co/Skywork},
}

@article{li2024numinamath,
  title={Numinamath: The largest public dataset in ai4maths with 860k pairs of competition math problems and solutions},
  author={Li, Jia and Beeching, Edward and Tunstall, Lewis and Lipkin, Ben and Soletskyi, Roman and Huang, Shengyi and Rasul, Kashif and Yu, Longhui and Jiang, Albert Q and Shen, Ziju and others},
  journal={Hugging Face repository},
  volume={13},
  year={2024}
}

@misc{RLHFlow,
      author={Wei Xiong and Hanning Zhang and Nan Jiang and Tong Zhang},
  title = {An Implementation of Generative PRM},
  year = {2024},
  publisher = {GitHub},
  journal = {GitHub repository},
  howpublished = {\url{https://github.com/RLHFlow/RLHF-Reward-Modeling}}
}


@misc{RLHFmodel,
      author={Wei Xiong and Hanning Zhang and Nan Jiang and Tong Zhang},
  title = {RLHFlow/Llama3.1-8B-PRM-Mistral-Data},
  year = {2024},
  publisher = {Hugging Face},
  journal={Hugging Face repository},
  howpublished = {\url{https://huggingface.co/RLHFlow/Llama3.1-8B-PRM-Mistral-Data}}
}


@article{yu2023metamath,
  title={Metamath: Bootstrap your own mathematical questions for large language models},
  author={Yu, Longhui and Jiang, Weisen and Shi, Han and Yu, Jincheng and Liu, Zhengying and Zhang, Yu and Kwok, James T and Li, Zhenguo and Weller, Adrian and Liu, Weiyang},
  journal={arXiv preprint arXiv:2309.12284},
  year={2023}
}

@article{luo2023wizardmath,
  title={Wizardmath: Empowering mathematical reasoning for large language models via reinforced evol-instruct},
  author={Luo, Haipeng and Sun, Qingfeng and Xu, Can and Zhao, Pu and Lou, Jianguang and Tao, Chongyang and Geng, Xiubo and Lin, Qingwei and Chen, Shifeng and Zhang, Dongmei},
  journal={arXiv preprint arXiv:2308.09583},
  year={2023}
}

@article{yue2023mammoth,
  title={Mammoth: Building math generalist models through hybrid instruction tuning},
  author={Yue, Xiang and Qu, Xingwei and Zhang, Ge and Fu, Yao and Huang, Wenhao and Sun, Huan and Su, Yu and Chen, Wenhu},
  journal={arXiv preprint arXiv:2309.05653},
  year={2023}
}

@article{gou2023tora,
  title={Tora: A tool-integrated reasoning agent for mathematical problem solving},
  author={Gou, Zhibin and Shao, Zhihong and Gong, Yeyun and Shen, Yelong and Yang, Yujiu and Huang, Minlie and Duan, Nan and Chen, Weizhu},
  journal={arXiv preprint arXiv:2309.17452},
  year={2023}
}

@article{snell2024scaling,
  title={Scaling llm test-time compute optimally can be more effective than scaling model parameters},
  author={Snell, Charlie and Lee, Jaehoon and Xu, Kelvin and Kumar, Aviral},
  journal={arXiv preprint arXiv:2408.03314},
  year={2024}
}

@article{mcaleese2024llm,
  title={Llm critics help catch llm bugs},
  author={McAleese, Nat and Pokorny, Rai Michael and Uribe, Juan Felipe Ceron and Nitishinskaya, Evgenia and Trebacz, Maja and Leike, Jan},
  journal={arXiv preprint arXiv:2407.00215},
  year={2024}
}

@article{pan2023let,
  title={Let's Reinforce Step by Step},
  author={Pan, Sarah and Lialin, Vladislav and Muckatira, Sherin and Rumshisky, Anna},
  journal={arXiv preprint arXiv:2311.05821},
  year={2023}
}

@article{wu2023fine,
  title={Fine-grained human feedback gives better rewards for language model training},
  author={Wu, Zeqiu and Hu, Yushi and Shi, Weijia and Dziri, Nouha and Suhr, Alane and Ammanabrolu, Prithviraj and Smith, Noah A and Ostendorf, Mari and Hajishirzi, Hannaneh},
  journal={Advances in Neural Information Processing Systems},
  volume={36},
  pages={59008--59033},
  year={2023}
}

@inproceedings{xu2024re,
  title={Re-reading improves reasoning in large language models},
  author={Xu, Xiaohan and Tao, Chongyang and Shen, Tao and Xu, Can and Xu, Hongbo and Long, Guodong and Lou, Jian-Guang and Ma, Shuai},
  booktitle={Proceedings of the 2024 Conference on Empirical Methods in Natural Language Processing},
  pages={15549--15575},
  year={2024}
}

@article{zhang2023and,
  title={What and how does in-context learning learn? bayesian model averaging, parameterization, and generalization},
  author={Zhang, Yufeng and Zhang, Fengzhuo and Yang, Zhuoran and Wang, Zhaoran},
  journal={arXiv preprint arXiv:2305.19420},
  year={2023}
}

@article{grondman2012survey,
  title={A survey of actor-critic reinforcement learning: Standard and natural policy gradients},
  author={Grondman, Ivo and Busoniu, Lucian and Lopes, Gabriel AD and Babuska, Robert},
  journal={IEEE Transactions on Systems, Man, and Cybernetics, part C (applications and reviews)},
  volume={42},
  number={6},
  pages={1291--1307},
  year={2012},
  publisher={IEEE}
}

@misc{inftech_pi_zero2024,
  author       = {INF-o1 Team},
  title        = {INF-o1 (\(\pi_0\)): Initiating the Journey to the Infinity of LLM Reasoning},
  year         = {2024},
  url          = {https://inftech-pi-zero.github.io/},
  note         = {Accessed: 2024-12-31}
}

@misc{qwen2.5,
    title = {Qwen2.5: A Party of Foundation Models},
    url = {https://qwenlm.github.io/blog/qwen2.5/},
    author = {Qwen Team},
    month = {September},
    year = {2024}
}

@article{qwen2,
  title={Qwen2 technical report},
  author={Yang, An and Yang, Baosong and Hui, Binyuan and Zheng, Bo and Yu, Bowen and Zhou, Chang and Li, Chengpeng and Li, Chengyuan and Liu, Dayiheng and Huang, Fei and others},
  journal={arXiv preprint arXiv:2407.10671},
  year={2024}
}

@article{inf-llm,
  author = {INF-Team},
  title = {INF’s Open-Source Large Language Models},
  year = {2024},
  url = {https://github.com/infly-ai/INF-LLM}
}

@misc{ai2024yi,
    title={Yi: Open Foundation Models by 01.AI},
    author={01. AI and : and Alex Young and Bei Chen and Chao Li and Chengen Huang and Ge Zhang and Guanwei Zhang and Heng Li and Jiangcheng Zhu and Jianqun Chen and Jing Chang and Kaidong Yu and Peng Liu and Qiang Liu and Shawn Yue and Senbin Yang and Shiming Yang and Tao Yu and Wen Xie and Wenhao Huang and Xiaohui Hu and Xiaoyi Ren and Xinyao Niu and Pengcheng Nie and Yuchi Xu and Yudong Liu and Yue Wang and Yuxuan Cai and Zhenyu Gu and Zhiyuan Liu and Zonghong Dai},
    year={2024},
    eprint={2403.04652},
    archivePrefix={arXiv},
    primaryClass={cs.CL}
}

@article{dubey2024llama,
  title={The llama 3 herd of models},
  author={Dubey, Abhimanyu and Jauhri, Abhinav and Pandey, Abhinav and Kadian, Abhishek and Al-Dahle, Ahmad and Letman, Aiesha and Mathur, Akhil and Schelten, Alan and Yang, Amy and Fan, Angela and others},
  journal={arXiv preprint arXiv:2407.21783},
  year={2024}
}

@article{cobbe2021gsm8k,
  title={Training Verifiers to Solve Math Word Problems},
  author={Cobbe, Karl and Kosaraju, Vineet and Bavarian, Mohammad and Chen, Mark and Jun, Heewoo and Kaiser, Lukasz and Plappert, Matthias and Tworek, Jerry and Hilton, Jacob and Nakano, Reiichiro and Hesse, Christopher and Schulman, John},
  journal={arXiv preprint arXiv:2110.14168},
  year={2021}
}

@article{hendrycksmath2021,
  title={Measuring Mathematical Problem Solving With the MATH Dataset},
  author={Dan Hendrycks and Collin Burns and Saurav Kadavath and Akul Arora and Steven Basart and Eric Tang and Dawn Song and Jacob Steinhardt},
  journal={NeurIPS},
  year={2021}
}

@misc{he2024olympiadbenchchallengingbenchmarkpromoting,
      title={OlympiadBench: A Challenging Benchmark for Promoting AGI with Olympiad-Level Bilingual Multimodal Scientific Problems}, 
      author={Chaoqun He and Renjie Luo and Yuzhuo Bai and Shengding Hu and Zhen Leng Thai and Junhao Shen and Jinyi Hu and Xu Han and Yujie Huang and Yuxiang Zhang and Jie Liu and Lei Qi and Zhiyuan Liu and Maosong Sun},
      year={2024},
      eprint={2402.14008},
      archivePrefix={arXiv},
      primaryClass={cs.CL},
      url={https://arxiv.org/abs/2402.14008}, 
}
