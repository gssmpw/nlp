\section{Proposed Architecture}
\label{sec:methodology}

The proposed National Clinical Data Warehouse (NCDW) architecture, shown in Fig.~\ref{fig:ncdw_architecture}, can be divided into five stages: (1) Data Integration, (2) Data Standardization, (3) Analytical Infrastructure, (4) Centralized Data Management, and (5) Analytical Dashboard. 
% Each stage ensures efficiency, scalability, privacy, and supports analytics and outbreak prediction.


\begin{figure*}[ht]
    % \vspace{-2mm}
    \centering
    \includegraphics[width=0.85\linewidth,trim={2 3 5 5},clip]{figures/architecture.jpg}
    \caption{Wrapper-based Architecture of NCDW Supporting Dengue Data Mart}
    \label{fig:ncdw_architecture}
    \vspace{-3mm}
\end{figure*}

\subsection{Data Integration}
\label{subsec:data_integration}

The data integration process employs a \textbf{wrapper-based framework} to collect data from healthcare providers, environmental agencies, and population statistics. The data is anonymized using the Key-Based Secured Record Linkage (KSRL) algorithm~\cite{ksrl}, which replaces patient identifiers with pseudonymous keys, and then cleaned to resolve errors and reduce noise. Finally, the processed data is loaded into the CDW's temporal storage using an \textbf{API-based plugin} for standardization and transformation.




\subsection{Data Standardization}
\label{subsec:data_standardization}

%To ensure accuracy, consistency, and interoperability across healthcare records, globally recognized data standards are followed in the NCDW. HL7 EHR CRFP is used to structure healthcare data exchange, while SNOMED CT and LOINC establish a common language for clinical terms and laboratory tests. ICD-11 is utilized for disease classification, UCUM maintains uniform measurement units, and NHS Pathology is referenced for laboratory test categorization and reporting \cite{mia2022privacy}.
%Transformation rules further standardize timestamps and environmental attributes (e.g., temperature, humidity, rainfall, air pollutants)~\cite{batini2009methodologies}, with the Intelligence Data Interfacing Model (IDIM) preparing the data for warehouse loading. Through batch processing, the transformed, standardized, and consistent data from the staging area is merged and loaded into the multidimensional data models of the central data warehouse in NCDW, enabling parallel data processing.

The NCDW follows global data standards for accuracy, consistency  and  interoperability in healthcare records. The HL7 Clinical Research Functional Profile (CRFP) for EHR facilitates structured data exchange, while SNOMED CT and LOINC define a common language for clinical terms and laboratory tests. ICD-11 classifies diseases, UCUM standardizes units, and NHS Pathology categorizes lab tests~\cite{NCVHS2018,ICD-11}. Transformation rules standardize timestamps and environmental data (e.g., temperature, humidity, rainfall)~\cite{batini2009methodologies}, and the Intelligence Data Interfacing Model (IDIM) prepares data for warehouse loading. Batch processing merges and loads the data into the multidimensional models of the central warehouse for parallel processing.






\subsection{Centralized Data Warehousing and Management}
\vspace{-1.5mm}
The NCDW employs a star schema architecture, as shown in Fig.~\ref{fig:star_schema}, a widely used analytical data modeling approach for its computational efficiency~\cite{Nugawela, Insights_clinical, 4743972}. The schema includes two fact tables: TESTRESULT and AMBIENT, along with eight dimension tables. The newly added dimension, GEOGRAPHY, enhances dengue outbreak detection by incorporating the attributes CITY, UPAZILA, DISTRICT, and DIVISION linked by a unique GEOKEY generated during transformation. The AMBIENT fact table connects to the TIME and GEOGRAPHY dimensions, recording five key measures: density, average rainfall, humidity, air pollutants, and percentage of positive dengue patients. The dynamic schema leaves scope for future extensions, such as adding genomic or molecular data.

Dimension identifiers, like healthcare key, lab key, and attribute key, are generated as five-digit IDs to minimize fact table size and computational complexity. The TIME key is represented as UNIX format (e.g., 847493700 for 8th Nov 1996, 3:55 PM), while the Patient Identifier Key (PIK) is anonymized for privacy. Table~\ref{tab:new_tables} summarizes the newly added tables.

\begin{table}[ht]
    \centering
    \caption{Details of newly added fact and dimension tables}
    \label{tab:new_tables}
    \resizebox{\linewidth}{!}{%
    \begin{tabular}{ccp{3cm}}
        \toprule
        \textbf{Type} & \textbf{Table Name} & \textbf{Description} \\ 
        \midrule
        Fact          & AMBIENT             & Detection and prediction of dengue outbreak \\ 
        % \hline
        Dimension     & GEOGRAPHY           & Logs ambient data and geographical attributes \\ \bottomrule
    \end{tabular}%
    }
\end{table}

\vspace{-2mm}
% \paragraph{Cube Hierarchy and Aggregation}
\textit{Cube Hierarchy and Aggregation:} As illustrated in Fig.~\ref{fig:cube}, aggregated data from the schema enables the creation of multi-dimensional cubes for diagnosis and disease analysis. The 5D Clinical Test Data Cube, depicted in Fig.~\ref{fig:testdatacube}, supports national CDW development, with a cube hierarchy ranging from the 0-D apex cube, summarizing national health statistics, to the 4-D base cube for granular data. The system precomputes common analytics, such as patient counts by diagnosis, procedure tracking, and retesting statistics, ensuring fast and efficient query responses. These preaggregated datasets enhance knowledge discovery, prediction, and dataset generation, aligning with the warehouse's goal of enabling real-time insights.

\begin{figure}[!ht]
    \centering
    \includegraphics[width=0.75\linewidth]{figures/cube.jpg}
    \caption{CUBE Hierarchy In Disease Analysis}
    \label{fig:cube}
\end{figure}


\begin{figure}[!ht]
    \centering
    \includegraphics[width=1.0\linewidth]{figures/test-DataCube.png}
    \caption{Clinical Test Data Cube}
    \label{fig:testdatacube}
    \vspace{-6.5mm}
\end{figure}

\begin{figure}[!ht]
    \centering
    \includegraphics[width=1.0\linewidth,trim={15 15 15 15},clip]{figures/schema.png}
    \caption{Star Schema of NCDW Supporting Dengue Data Mart}
    \label{fig:star_schema}
    \vspace{-5mm}
\end{figure}
% \vspace{-2mm}

%To identify the best storage solution for NCDW, PostgreSQL and HBase have been compared based on execution time and storage efficiency using data cube operations on datasets ranging from 100,000 to 1,000,000 records. The tests, conducted with 3D and 4D cubes, simulate real-world analytics. PostgreSQL is recommended for structured clinical data because it needs ACID compliance, while HBase is better for large-scale environmental and genomic data due to its scalability and high-speed write capabilities.


To identify the best storage solution for NCDW, PostgreSQL and HBase were compared using 3D and 4D data cubes (100K–1M records) based on execution time and efficiency.PostgreSQL suits structured clinical data needing ACID compliance, while HBase offers scalability and fast writes for environmental and genomic data.


\subsection{Analytical Infrastructure and Dashboard}
\label{subsec:analytical_infrastructure}
The analytical infrastructure integrates Online Analytical Processing (OLAP) and data mining to detect, predict, and analyze disease outbreaks. Using dengue as a proof-of-concept, the system demonstrates its ability to analyze climate-disease correlations and forecast outbreaks. Data is processed and standardized using the Intelligence Data Interfacing Model (IDIM) and batch-loaded into the NCDW, enabling parallel processing and automated generation of disease-specific data marts for infectious diseases such as COVID-19, Malaria, Dengue, and other infectious and parasitic diseases.

The dashboard provides a read-only interface with interactive visualizations, real-time reports, and predictive analytics. It forecasts disease spread and severity, examines seasonal and geographical climate-disease relationships, and evaluates medical capacity and intervention readiness. These results support evidence-based planning and public health interventions, with the system designed for scalability across other diseases. 

% \subsection{Experimental Setup}
% \label{subsec:experimental_setup}

% To validate the proposed architecture, a prototype was deployed on a server at IICT, BUET, with a 2×4-core CPU, 150 GB HDD, and 32 GB RAM. The web-based interface enabled interactive analysis via maps and charts, while PostgreSQL managed the backend. A subject-oriented data mart, \emph{DENGUE}, was derived for specialized dengue analysis.

\vspace{-5mm}
\subsection{Dataset and Experimental Setup}
\label{subsec:dataset_description}

The NCDW integrates four datasets: \textbf{Clinical}, \textbf{Dengue}, \textbf{Environmental}, and \textbf{UrbanStats}. Clinical dataset consists of anonymized health records of 9443 patients, while the Dengue dataset includes 70,049 test records and 101,658 records for 69633 anonymous patients, covering all districts. Environmental and demographic data from Bangladesh Meteorological Department (BMD),
% ~\cite{bmd},
Department of Environment (DOE),
% ~\cite{doe},
and Bangladesh Bureau of Statistics (BBS)
% ~\cite{bbs}
provide weather parameters and population density for disease analysis. Table~\ref{tab:datasets_summary} provides a summary of these datasets.
% \begin{table}
%     \centering
%     \caption{Summary of Datasets Used in NCDW}
%     \label{tab:datasets_summary}
%     \resizebox{\linewidth}{!}{%
%     \begin{tabular}{|p{2cm}|p{2 
%     cm}|p{3cm}|}
%         \hline
%         \textbf{Dataset}         & \textbf{Sources}              & \textbf{Key Attributes} \\ \hline
%         Clinical Dataset              (1,161,654 records)       & 3 Private Hospitals           & Anonymized patient records, test results, age, gender \\ \hline
%         Dengue Dataset                (70,049 records)          & 6 Hospitals (2016–2022)       & Test outcomes, positive cases, gender, geographical coverage across all districts \\ \hline
%         Environmental \& Demographic Dataset        &  BMD, DOE, BBS & Weather Ambient (rainfall, humidity, air quality, temperature) and Demographic (population density ) \\ \hline
%     \end{tabular}%
%     }
% \end{table}

\begin{table}[]
    \centering
    \caption{Summary of datasets used in NCDW.}
    \label{tab:datasets_summary}
    \begin{tabular}{p{1.5cm}p{1.5cm}p{4cm}}
        \toprule
         \textbf{Dataset (\#records)}         & \textbf{Sources}              & \textbf{Key Attributes}  \\
         \hline
         % Clinical (1,161,654)       & 3 Hospitals           & Anonymized patient records, test results, age, gender \\
         Clinical (1161654)       & 13 Hospitals           & Anonymized patient records, test results, age, gender \\
         \hline
         Dengue\hspace{0.5cm}  (70049)          & 6 Hospitals (2016–2022)       & Test outcomes, gender(39801 male, 30246 female, 2 other),+Ve cases(16510), geographical coverage across all districts \\ 
         \hline
         Environmental &  BMD, DOE & rainfall, humidity, air quality, temperature\\ 
         \hline
         UrbanStats        & BBS &Population/Building Density \\
         \bottomrule
    \end{tabular}
\end{table}

To validate the proposed architecture, a prototype was deployed on a server at IICT, BUET, with a 2×4-core CPU, 150 GB HDD, and 32 GB RAM. The web-based interface enabled interactive analysis via maps and charts, while PostgreSQL managed the backend. A subject-oriented data mart, \emph{DENGUE}, was derived for specialized dengue analysis.

%\vspace{-0.5cm} 


% \subsection{Load and Size Estimation of NCDW}
% \label{subsec:load_estimation}

% Estimating the daily data load and total storage requirements of the NCDW is crucial for efficient management. The daily load is calculated by aggregating record entries from various healthcare facilities, using the formula:
% \begin{equation}
%      R =\bar{r}\times  \left \{ \sum_{j=1}^{n} \left ( \frac{s_j*hospital\,count}{\sum_{}^{total\,bed}s} \right ) \right \}\times d(days)
% \end{equation}

% where $R$ represents daily record entries, $\bar{r}$ is the average records per hospital, $s_j$ denotes hospital weight based on bed count, $n$ is the total hospitals, and $d$ is the number of days.

% The total NCDW size is estimated as:

% \begin{equation} 
% \label{eqn2}
% \text{Size} = R \times d \times S_r 
% \end{equation}

% where $S_r$ is the average record size in kilobytes. These calculations help in planning storage needs for different periods (e.g., one to five years), ensuring scalability through cloud-based solutions.

% By applying these formulas, future data growth can be anticipated, enabling proactive infrastructure planning.







\subsection{Name Matching for Data Consistency}

In developing countries like Bangladesh, patient identification is challenging due to inconsistent healthcare data, low literacy rates, and the absence of standardized identity documents. Variations in name spellings, repeated ages due to missing birth records, and high patient volumes further contribute to data inconsistencies. Limited staff expertise and rushed data entry introduce errors, making traditional record linkage methods ineffective in such environments.


\begin{algorithm}
\caption{Soundex Name Matching Algorithm. $\alpha$ is a function to retain the first character. $f$ is the mapping fuction}
\textbf{Input:} A string $S=\{S_1S_2...S_n\}$ representing a name.\\
\textbf{Output:} A four-character soundex code $C$ for $S$.

\begin{algorithmic}[1]
\label{alg:soundex}
\STATE {\bfseries Begin}
\STATE Initialize $C \gets \text{empty string}$.
\STATE Retain the first letter of $S$: $C_1 \gets \alpha(S_1)$.
\STATE Initialize $P \gets \text{MappingFunction} f(C_1)$.

\FOR{$i=2$ to $n$ in $S$}
    \IF{$f(S_i) = \emptyset$}
    \STATE \textbf{continue}
  \ELSIF{$f(S_i) \neq P$}
    \STATE Append $f(S_i)$ to $C$
    \STATE Update $P \gets f(S_i)$
  % \ELSIF{some even more bizarre condition is met}
  %   \STATE do something else
  % \ELSE
  %   \STATE do the default actions
  \ENDIF
\ENDFOR

\IF{$|C| < 4$}
    \STATE Append "0" to $C$ until $|C| = 4$.
\ELSIF{$|C| < 4$}
    \STATE Truncate $C$ to the first four characters.
\ENDIF

\STATE {\bfseries return} $C$
\STATE {\bfseries End}
\end{algorithmic}
\end{algorithm}
\vspace{-3mm}

% \[
% \text{MappingFunction }f(x) = 
% \begin{cases}
% 1 & \text{if } x \in \{B, F, P, V\} \\
% 2 & \text{if } x \in \{C, G, J, K, Q, S, X, Z\} \\
% 3 & \text{if } x \in \{D, T\} \\
% 4 & \text{if } x = L \\
% 5 & \text{if } x \in \{M, N\} \\
% 6 & \text{if } x = R \\
% \emptyset & \text{if } x \in \{A, E, I, O, U, H, W, Y\}
% \end{cases}
% \]

\begin{table}[!h]
    \centering
    \caption{Mapping Function}
    \label{tab:map_func}
    \begin{tabular}{c|c}
    \toprule
         Value of $x$&  $\text{MappingFunction }f(x)$\\
         \midrule
         $x \in \{B, F, P, V\}$ & 1\\
         $x \in \{C, G, J, K, Q, S, X, Z\}$ &2\\
         $x \in \{D, T\}$ &3\\
         $x=L$ &4\\
         $x \in \{M, N\}$ &5\\
         $x \in \{M, N\}x = R$ &6\\
         $x \in \{A, E, I, O, U, H, W, Y\}$ &$\emptyset$ \\ 
         \bottomrule
    \end{tabular}
\end{table}
% \vspace{-30mm}
To address patient identification challenges, we proposed a name-matching algorithm [\ref{alg:soundex}] that generates phonetic identifiers to handle spelling variations and pronunciation differences. It converts names into a fixed-length four-character code, reducing ambiguity and ensuring standardized comparison. For instance, “Sobuj Chowdhury” and “Sabuj Chaudhury” produce identical Soundex codes, enabling accurate record linkage. This approach minimizes data inconsistencies and improves patient record management in resource-constrained healthcare systems, as shown in Table~\ref{tab:soundex}.
\begin{table}[!h]
    \centering
    \caption{Usage of soundex encoding process for name Standardization. \textbf{*} before adjustment.}
    \label{tab:soundex}
    \setlength{\tabcolsep}{2pt}
    \begin{tabular}{c|cccc}
    \toprule
         \textbf{Inputted Name }&\textbf{1st Lette}r &\textbf{Mapped Values} & \textbf{Code*}  &\textbf{Final Code}  \\
         \midrule
         Sabuj/Sobuj/Sabuz &S &1,3,2 &S132 &S132\\
         % Sobuj &S &1,3,2 &S132 &S132\\
         % Sabuz &S &1,3,2 &S132 &S132\\
         % \hline
         Chowdhury/Choudhury & C &3,6 &C36 &C360\\
         % Choudhury & C &3,6 &C36 &C360\\
         % \hline
         % Smyth &S &5,3 &S53 &S530\\
         Smyth/Smith/Smeth &S &5,3 &S53 &S530\\
         \bottomrule
    \end{tabular}
% \vspace{-5mm}
\end{table}
% \vspace{-5mm}


