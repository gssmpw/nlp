\begin{table*}[h]
\caption{Experimental Results for RQ4.}
\label{tab:rq4}
\centering
\begin{threeparttable}
\small
%\fontsize{5.5}{6}\selectfont 
%\begin{tabular}{|>{\columncolor{gray!30}\bfseries}c|l|c|c|c|c|>%{\columncolor{gray!30}\bfseries}c|l|c|c|c|c|c|c|c|}
%\hline
\begin{tabular}{|>{\columncolor{gray!30}\bfseries}c|l|c|c|c|c|>{\columncolor{gray!30}\bfseries}c|l|c|c|c|c|}
\hline
\rowcolor{gray!30} ID & Bug Report  & RD &  RB & AG   & BL  & ID & Bug Report  & RD &  RB & AG  & BL  \\ 
\hline
1 & AFM-1657 & $\times$  & $\times$ & $\times$ & $\times$ & 22 & AFM-1794  & $\checkmark$ & $\checkmark$ &$\checkmark$  & $\checkmark$ \\ 
2 & AFM-1795  & $\checkmark$  & $\checkmark$ & $\checkmark$ & $\checkmark$ & 23 & AndOTP-827  &  $\times$ &  $\times$ &  $\times$  & $\times$ \\ 
3 & AFM-1796  & $\times$  & $\times$ & $\checkmark$ & $\checkmark$ & 24 & AndrOBD-243  & $\checkmark$ & $\checkmark$ &$\checkmark$  & $\checkmark$ \\ 
4 & AFM-2477  & $\times$  & $\times$ & $\times$ & $\times$ & 25 & Android-1248 &  $\times$ &  $\times$ &  $\times$  & $\times$ \\ 
5 & andOTP-551  & $\times$  & $\times$ & $\times$ & $\times$ & 26 & AnyMemo-500 &  $\times$ &  $\times$ &  $\times$  & $\times$ \\ 
6 & andOTP-827  & $\times$  & $\times$ & $\times$ & $\times$ & 27 & Fenix-27725  &  $\times$ &  $\times$ &  $\times$  & $\times$ \\ 
7 & Anki-13919  & $\times$  & $\times$ & $\times$ & $\times$ & 28 & Fenix-27987 &  $\times$ &  $\times$ &  $\times$  & $\times$ \\ 
8 & Anki-14609  & $\times$  & $\times$ & $\times$ & $\times$ & 29 & Fenix-28086  &  $\times$ &  $\times$ &  $\times$  & $\times$ \\ 
9 & Anki-16325  & $\times$ & $\checkmark$ & $\times$ & $\times$ & 30 & k9-4804  &  $\times$ &  $\times$ &  $\times$  & $\times$ \\ 
10 & AnkiDroid-6228   & $\times$ & $\times$ & $\times$ & $\times$ & 31 & Markor-1815 &  $\times$ &  $\times$ &  $\checkmark$  & $\checkmark$ \\ 
11 & AnkiDroid-7286   & $\times$ & $\times$ & $\times$ & $\times$ & 32 & Markor-1961  &  $\times$ &  $\times$ &  $\times$  & $\times$ \\ 
12 & AnkiDroid-9005   & $\checkmark$ & $\checkmark$ & $\checkmark$ & $\checkmark$ & 33 & NewPipe-10090  &  $\times$ &  $\times$ &  $\times$  & $\times$ \\ 
13 & AnyMemo-502  &  $\times$ & \textcolor{red}{$\circ$} & \textcolor{red}{$\circ$} & \textcolor{red}{$\circ$}  & 34 & NewPipe-10380 &  $\times$ &  $\times$ &  $\times$ & $\times$ \\ 
14 & Kiwix-1868 & $\times$  & $\times$ & $\times$ & $\times$ & 35 & NewPipe-10646  &  $\times$ &  $\times$ &  $\times$  & $\times$ \\ 
15 & Markor-1020   & $\times$  & $\times$ & $\times$ & $\checkmark$ & 36 & NewPipe-41  &  $\times$ &  $\times$ &  $\times$  & $\times$ \\ 
16 & Markor-1565   & $\times$  & $\times$ & $\times$ & $\times$ & 37 & NewPipe-56  &  $\times$ &  $\times$ &  $\times$  & $\times$ \\ 
17 & Markor-1729   & $\times$  & $\times$ & $\times$ & $\times$ & 38 & News-156  &  $\checkmark$&  $\checkmark$ &  $\checkmark$  & $\checkmark$ \\ 
18 & Markor-550   & $\times$ & $\times$ & $\times$ & $\times$ & 39 & OpenNoteScanner-166  &  $\times$ &  $\times$ &  $\times$  & $\times$ \\ 
19 & Markor-567   & $\times$ & $\times$ & $\times$ & $\times$ & 40 & OpenNoteScanner-39  &  $\times$ &  $\times$ &  $\times$  & $\times$ \\ 
20 & OmniNotes-634   & $\times$ & $\times$ & \textcolor{red}{$\circ$} & \textcolor{red}{$\circ$} & 41 & Aopentasks-898  &  $\checkmark$&  $\checkmark$ &  $\checkmark$  & $\checkmark$ \\ 
21 & Trickytripper-49  & $\times$ & $\checkmark$ & $\checkmark$ & $\checkmark$& 42 & PdfViewer-55  &  $\times$ &  $\times$ &  $\times$  & $\times$ \\ 
\hline
\end{tabular}

\begin{tablenotes}
\item[1] $\checkmark$ Reproduction succeeds without considering the image.
\item[2] $\circ$ Reproduction succeeds only after manually providing the information of the image.
\item[3] $\times$ Reproduction failed in both cases.
\end{tablenotes}

\vspace{-10pt}

\end{threeparttable}
%\caption{\textbf{Experimental Results for RQ2. The abbreviations RD, RB, AG, RM, and RL in the table header stand for ReCDroid, ReproBot, AdbGPT, Roam, and ReBL, respectively. For each approach, the reproduction time (in seconds) is recorded if the bug report is successfully reproduced. If the reproduction fails, it is indicated with a ×.}}
\end{table*}



\subsection{Existing Tools (RQ4)}

In this section, we assess how images in bug reports influence the effectiveness of automated bug reproduction through two experiments. First, we examine whether existing tools, which currently lack the capability to process images as input, can successfully reproduce bugs when images are omitted from the reports. 
Second, we explore whether the functional content of images, if ideally translated into descriptive text, can enhance the accuracy and effectiveness of bug reproduction with existing tools.




%
\subsubsection{Experiment Design and Setup}
The first experiment uses textual information from bug reports as input to determine whether existing tools could automatically reproduce bug reports.  If the tools successfully reproduced the bugs within a reasonable timeframe without utilizing the images from the bug reports, it would suggest that the images may not be critical, as the textual hints provided are sufficient to guide the existing tools. The second experiment focused on the cases where the first experiment failed. In these cases, we manually turned the information from the images into text descriptions. We divided the images into two groups: S2R and non-S2R. S2R Images provide clues about specific actions, targets, or elements involved in the reproduction steps. We translated these images into precise action-target tuples that existing tools can interpret.  In contrast, non-S2R images, which lack specific actions and targets and cannot be directly converted into action-target tuples, were handled by listing the names of the UI elements on the images. This included details such as the page title (if any) and the various UI elements present in the image. If supplementing the translated information leads to successfully reproducing previously failed cases, it suggests that precisely capturing the image’s intent and extracting key information can effectively leverage images to enhance bug reproduction.
%\commentty{In some cases, images cannot be straightforwardly converted into text. And the way how images are converted can also affect the results. Need more details. }

We conducted our experiment on a physical x86 machine running Ubuntu 16.04, equipped with an i7-4790 CPU @ 3.60GHz and 32 GB of memory. We followed the same evaluation settings as in ReCDroid~\cite{zhao2019recdroid}, 
ReproBot~\cite{zhang2023automatically}
AdbGPT~\cite{feng2024prompting}, and ReBL~\cite{wang2024feedback} limiting each experiment to a maximum runtime of one hour. If an experiment exceeds this time limit, it is terminated and marked as a failure. For ReBL~\cite{wang2024feedback}, which includes a summarization mechanism, we maintained the same experimental settings, setting the summarization threshold to three iterations.


\subsubsection{Results} 
Table~\ref{tab:rq4} shows detailed results of the bug reproduction for each bug report by the state-of-the-art tools. 23.8\% of bug reports were successfully reproduced by at least one tool, while 76.2\% were not reproduced by any existing tools. We further analyze the failed cases and summarize the following key observations.

%We conducted a qualitative analysis based on each bug report and the associated images, combining experimental results with the capabilities of the tools. This analysis primarily focused on two questions: (1) Why does ignoring images still lead to successful reproduction? (2) In cases where all existing tools failed, is it due to the impact of missing images or the inherent limitations of the tools? Below are the results:



\begin{itemize}[leftmargin=0.3cm]

\item  
\textbf{\emph{ \textit{S2R$_{context}$ image} and \textit{S2R$_{standalone}$ image} play a critical role in filling in missing steps during the bug reproduction process.} (Example: AnyMemo\#502).} As introduced in RQ2 of our empirical study (Section~\ref{fig:roles}) S2R${standalone}$ represents a complete Step-to-Reproduce (S2R) image that visually illustrates specific actions, while an S2R${context}$ image complements the textual S2R by providing additional context. 
%
Our experimental results validate these findings, showing that omitting these images often leads to incomplete information or overlooked steps, resulting in failed reproduction attempts. 
%
Additionally, in a second experiment, we attempted to convert the visual information from images into action-target components to enhance the textual reports. This approach led to successful reproduction in two previously failed cases, demonstrating the potential of leveraging S2R images to complete the S2Rs. This proof-of-concept suggests that developing methods to translate S2R images into actionable text could help address these challenges and harness the benefits of S2R images in future automated bug reproduction.

%
\item 
\textbf{\emph{Images in bug reports are less critical if the textual S2Rs are sufficient.} (Example: Trickytripper\#49).} 
Sufficient information refers to Steps to Reproduce (S2Rs) that are comprehensive and detailed, providing all the necessary target-action information required for accurately reproducing the bug.
In these cases, images become less critical in automated bug reproduction, as existing tools have made significant progress using S2Rs alone, applying various techniques (e.g., reinforcement learning, and prompt engineering) and achieving promising results. This raises an interesting question: can we assess if textual information is sufficient for bug reproduction before running the tool? If so, we could selectively use text-only tools or incorporate images as needed. Beyond this, the classifier could help determine whether to leverage LLM-based~\cite{wang2024feedback, feng2024prompting} or NLP-based~\cite{zhao2019recdroid} tools, depending on whether the textual information is structured and the action-target details are clearly documented, opt for tool using crash log as input if a crash log is available~\cite{huang2024crashtranslator}, or apply video-based reproduction tools~\cite{feng2022gifdroid} when videos are provided.
%
Therefore, it might be beneficial to build a classifier to assess information sufficiency, enabling more efficient tool selection and improved performance.


%\commentty{what does this finding imply? Can we select tools based on how sufficient the information is? Maybe designing a classifier to determine when to use text-only tools? But what would be the benefit of this classifier?}


\item 
\textbf{\emph{The role of non-S2R images needs to be further determined.}} 
%
S2R images can be accurately translated manually into a textual format, such as action-target pairs, which existing tools can readily use. This structured format is effective because it aligns well with the current capabilities of automated tools. However, when images convey information beyond simple action-target pairs—such as OB (Observed Behavior) images that illustrate the varying symptoms or EB (Expected Behavior) images that depict the desired outcome—it becomes challenging to convert them accurately into text, and text alone cannot intuitively capture these nuances. A significant challenge in existing works is the bug oracle, which requires a comprehensive understanding of OB information. Therefore, exploring OB and EB images might be a breakthrough in addressing this challenge, as incorporating images can supplement and enrich the textual OB and EB information.


\end{itemize}

\begin{tcolorbox}[colback=blue!5, colframe=black, boxrule=0.5pt]

\textbf{Finding 6:} 
First, S2R${context}$ and S2R${standalone}$ images are essential for automated bug reproduction and can be effectively translated into textual tuples, aligning well with the current capabilities of automated tools.
%
Second, non-S2R images are more complex because they lack the clear action-target patterns found in S2R images, making them harder to interpret. These images often convey nuanced information, such as observed or expected behaviors, which require further investigation to effectively integrate into automated bug reproduction.
\end{tcolorbox}