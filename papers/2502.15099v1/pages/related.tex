\section{Threats to Validity}
Our study may suffer from some threats to validity. 
First, although we used a 95\% confidence level, some unique or less common characteristics of bug reports may still be underrepresented, potentially impacting our findings. 
%
Second, the relatively small number of bug reports in RQ4 may limit the generalizability of our conclusions. This limitation is further reflected in the size of the S2R dataset, which, while imbalanced, mirrors real-world scenarios. The limited number of bug reports containing S2R may impact the generalization of our findings, similar to other empirical studies. However, as this is the first dataset of image-based bug reports, we plan to expand its size as part of our future work.
%
Third, the manual classification of image roles introduces potential for human error, even with cross-validation, which may impact labeling consistency. To enhance generalizability, we analyzed two third-party datasets, AndroR2 and RegDroid, to classify the functional roles of images within these datasets. The results from both datasets are consistent with our findings.
%
Fourth, we evaluated two recent tools, AdbGPT and ReBL, in RQ4. Both tools use GPT~\cite{chatgpt} models, which are continually updated, meaning that the results may not remain consistent over time. Additionally, our findings highlight a critical limitation of current tools: they are primarily designed to process textual S2R information, making them less effective at leveraging the rich information within non-S2R images to improve bug reproduction.



%The primary external validity concern in this study revolves around the representativeness of the apps, bug reports, and tools utilized. 
%
%In our evaluation, we aimed to create realistic settings using real bug reports and Android apps. The emulator and execution engine (UI Automator) are widely adopted in both industry and academia, 
%consistent with other Android testing works~\cite{ zhao2022recdroid+, zhang2023automatically,feng2024prompting}.
%Furthermore, existing approaches (e.g., ReCDroid~\cite{zhao2019recdroid}, AdbGPT~\cite{feng2024prompting}]) have demonstrated the effectiveness of such automated reproduction tools over manual reproduction by real-world developers. 
%
%However, we acknowledge that our results may not be fully generalizable to all bug reports in different domains. We did our best to provide a general study to validate the representativeness of our findings.  Additionally, the relatively small number of bug reports presents in RQ4 , potentially impacting the breadth of our conclusions. 

%Since this study relies on manual analysis and classification of images, there is a potential for human error, such as misclassification or subjective bias. This could impact the consistency and accuracy of the findings, particularly if criteria for categorizing images roles. We employed cross-validation, allowing multiple reviewers to validate each classification and improve reliability.


\section{Related Work}

\noindent\textbf{Automated Bug Report Reproduction.}
There are existing approaches that specifically target automatically reproducing Android bug reports as listed in Table~\ref{table:toolsummary} in Section~\ref{sec:intro},
including Yakusu~\cite{fazzini2018automatically},  ReCDroid~\cite{zhao2019recdroid},  GIFdroid~\cite{feng2022gifdroid}, DroidScope~\cite{huang2023context},  ReproBot~\cite{zhang2023automatically}, AdbGPT~\cite{feng2024prompting}, CrashTranslator~\cite{huang2024crashtranslator}, Roam~\cite{zhang2024mobile} and ReBL~\cite{wang2024feedback}.  Section~\ref{tools} provides introductions to each of these approach.
These tools aim to use various types of information in bug reports—such as crash logs, full textual reports, and videos—to automate the bug reproduction process. 

However, none have considered the role of images, though GIFdroid automates bug replay from GIFs and videos in bug reports. While it involves processing GIFs and videos using image techniques, its goal is fundamentally different from our study. GIFdroid focuses on replaying sequential interactions from video-based bug reports, leveraging the temporal continuity of frames. In contrast, our work investigates how standalone images—without sequential context—can be utilized for automated bug reproduction. This distinction highlights the unique challenges and opportunities in leveraging images independently, motivating the need for our empirical study.


%MACA~\cite{liuAutomatedClassificationActions2020},
%The most recent work,  AdbGPT~\cite{feng2024prompting}, uses LLMs to extract S2R entities for guiding bug report reproduction. However, similar to other existing techniques, AdbGPT's employment of the traditional two-phase structure—consisting of the S2R Entity Extraction phase and the Entity Matching phase—suffers. 
%There are other works that approach bug reproduction from different aspects, such as recording and replaying bugs ~\cite{gomez2013reran, feng2022gifdroid, nurmuradov2017caret, bell2013chronicler, bernal2020translating},  analyzing stack traces~\cite{huang2024crashtranslator}, and leveraging the call stack~\cite{white2015generating}.  ReBL~\cite{wang2024feedback} uses the whole textual bug report and by pass the use of entity. However, ReBL lacks of the consideration of using image in bug reports which is sutying by this paper.
%
%Among these, GIFdroid~\cite{feng2022gifdroid} utilizes screen recordings to automate bug reproduction by adopting image processing techniques. CrashTranslator~\cite{huang2024crashtranslator}  reproduces crash reports directly from stack traces by leveraging a pre-trained LLM to predict the steps necessary for reproduction.

\noindent\textbf{Bug Report Study and Analysis.}
There have been several research efforts dedicated to studying and analyzing Android bug reports.
For instance, Wendland et al~\cite{wendland2021andror2} studied 90 manually reproduced bug reports to support automated research in bug analysis and reproduction. Building on this basis, Johnson et al~\cite{johnson2022empirical} extended the dataset and conducted an empirical study on 180 Android bug reports to examine reproduction challenges and the quality of reported details.
%
Chaparro et al.\cite{chaparroDetectingMissingInformation2017} conducted a study on user-reported behaviors, reproduction steps, and expected outcomes, identifying typical discourse patterns. They later developed Euler\cite{chaparroAssessingQualitySteps2019}, an automated method to evaluate the quality of S2R in Android bug reports based on simple grammar patterns. Liu et al.~\cite{liuAutomatedClassificationActions2020} introduced Maca, a machine-learning classifier that organizes S2R action words into standard categories.

Several studies have explored using LLMs to analyze and interpret bug reports. Lee et al.\cite{lee2022light} applied LLMs for bug triage, while Messaoud et al.\cite{messaoud2022duplicate} used a BERT model to detect duplicate reports. Kang et al.~\cite{kang2023large} proposed generating JUnit test methods for Java programs from bug reports


Some research focuses on improving the bug reporting process. Moran et al.\cite{moran2015auto} developed Fusion, which uses dynamic analysis to capture app UI events for more informative reports. Fazzini et al.\cite{fazzini2022enhancing} support reporters in writing precise reproduction steps by leveraging static and dynamic analysis to predict next actions. Yang et al.~\cite{song2022toward} offer a guided system with instant feedback and graphical hints to enhance report quality. %While not directly aimed at reproduction, these methods could help LLMs better understand bug reproduction through improved report clarity.

However, these studies focus solely on improving the accuracy of identifying textual S2Rs, with no consideration given to images. Our study examines not only the functional role of images in automated bug report reproduction but also their characteristics within bug reports, offering insights into  potential opportunities to leverage them in automated bug reproduction.