@inproceedings{achiam2017constrained,
  title={Constrained policy optimization},
  author={Achiam, Joshua and Held, David and Tamar, Aviv and Abbeel, Pieter},
  booktitle={International conference on machine learning},
  pages={22--31},
  year={2017},
  organization={PMLR}
}

@article{anderson2020neurosymbolic,
  title={Neurosymbolic reinforcement learning with formally verified exploration},
  author={Anderson, Greg and Verma, Abhinav and Dillig, Isil and Chaudhuri, Swarat},
  journal={Advances in neural information processing systems},
  volume={33},
  pages={6172--6183},
  year={2020}
}

@article{bozkus2024multi,
  title={Multi-timescale ensemble Q-learning for Markov decision process policy optimization},
  author={Bozkus, Talha and Mitra, Urbashi},
  journal={IEEE Transactions on Signal Processing},
  year={2024},
  publisher={IEEE}
}

@article{chapman2021risk,
  title={Risk-sensitive safety analysis using conditional value-at-risk},
  author={Chapman, Margaret P and Bonalli, Riccardo and Smith, Kevin M and Yang, Insoon and Pavone, Marco and Tomlin, Claire J},
  journal={IEEE Transactions on Automatic Control},
  volume={67},
  number={12},
  pages={6521--6536},
  year={2021},
  publisher={IEEE}
}

@article{chow2018lyapunov,
  title={A lyapunov-based approach to safe reinforcement learning},
  author={Chow, Yinlam and Nachum, Ofir and Duenez-Guzman, Edgar and Ghavamzadeh, Mohammad},
  journal={Advances in neural information processing systems},
  volume={31},
  year={2018}
}

@article{chow2018risk,
  title={Risk-constrained reinforcement learning with percentile risk criteria},
  author={Chow, Yinlam and Ghavamzadeh, Mohammad and Janson, Lucas and Pavone, Marco},
  journal={Journal of Machine Learning Research},
  volume={18},
  number={167},
  pages={1--51},
  year={2018}
}

@article{ghasemipour2022so,
  title={Why so pessimistic? estimating uncertainties for offline rl through ensembles, and why their independence matters},
  author={Ghasemipour, Kamyar and Gu, Shixiang Shane and Nachum, Ofir},
  journal={Advances in Neural Information Processing Systems},
  volume={35},
  pages={18267--18281},
  year={2022}
}

@article{jiang2024importance,
  title={On the importance of exploration for generalization in reinforcement learning},
  author={Jiang, Yiding and Kolter, J Zico and Raileanu, Roberta},
  journal={Advances in Neural Information Processing Systems},
  volume={36},
  year={2024}
}

@article{liu2021learning,
  title={Learning policies with zero or bounded constraint violation for constrained mdps},
  author={Liu, Tao and Zhou, Ruida and Kalathil, Dileep and Kumar, Panganamala and Tian, Chao},
  journal={Advances in Neural Information Processing Systems},
  volume={34},
  pages={17183--17193},
  year={2021}
}

@inproceedings{ma2021model,
  title={Model-based constrained reinforcement learning using generalized control barrier function},
  author={Ma, Haitong and Chen, Jianyu and Eben, Shengbo and Lin, Ziyu and Guan, Yang and Ren, Yangang and Zheng, Sifa},
  booktitle={2021 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)},
  pages={4552--4559},
  year={2021},
  organization={IEEE}
}

@article{moldovan2012risk,
  title={Risk aversion in Markov decision processes via near optimal Chernoff bounds},
  author={Moldovan, Teodor and Abbeel, Pieter},
  journal={Advances in neural information processing systems},
  volume={25},
  year={2012}
}

@article{perkins2002lyapunov,
  title={Lyapunov design for safe reinforcement learning},
  author={Perkins, Theodore J and Barto, Andrew G},
  journal={Journal of Machine Learning Research},
  volume={3},
  number={Dec},
  pages={803--832},
  year={2002}
}

@inproceedings{qin2021density,
  title={Density constrained reinforcement learning},
  author={Qin, Zengyi and Chen, Yuxiao and Fan, Chuchu},
  booktitle={International conference on machine learning},
  pages={8682--8692},
  year={2021},
  organization={PMLR}
}

@article{rigter2024one,
  title={One risk to rule them all: A risk-sensitive perspective on model-based offline reinforcement learning},
  author={Rigter, Marc and Lacerda, Bruno and Hawes, Nick},
  journal={Advances in Neural Information Processing Systems},
  volume={36},
  year={2024}
}

@inproceedings{sui2015safe,
  title={Safe exploration for optimization with Gaussian processes},
  author={Sui, Yanan and Gotovos, Alkis and Burdick, Joel and Krause, Andreas},
  booktitle={International conference on machine learning},
  pages={997--1005},
  year={2015},
  organization={PMLR}
}

@article{tang2019worst,
  title={Worst cases policy gradients},
  author={Tang, Yichuan Charlie and Zhang, Jian and Salakhutdinov, Ruslan},
  journal={arXiv preprint arXiv:1911.03618},
  year={2019}
}

@inproceedings{wu2024ocean,
  title={OCEAN-MBRL: Offline Conservative Exploration for Model-Based Offline Reinforcement Learning},
  author={Wu, Fan and Zhang, Rui and Yi, Qi and Gao, Yunkai and Guo, Jiaming and Peng, Shaohui and Lan, Siming and Han, Husheng and Pan, Yansong and Yuan, Kaizhao and others},
  booktitle={Proceedings of the AAAI Conference on Artificial Intelligence},
  volume={38},
  number={14},
  pages={15897--15905},
  year={2024}
}

@article{zanon2020safe,
  title={Safe reinforcement learning using robust MPC},
  author={Zanon, Mario and Gros, S{\'e}bastien},
  journal={IEEE Transactions on Automatic Control},
  volume={66},
  number={8},
  pages={3638--3652},
  year={2020},
  publisher={IEEE}
}

@article{zhang2024entropy,
  title={Entropy-regularized diffusion policy with q-ensembles for offline reinforcement learning},
  author={Zhang, Ruoqi and Luo, Ziwei and Sj{\"o}lund, Jens and Sch{\"o}n, Thomas B and Mattsson, Per},
  journal={arXiv preprint arXiv:2402.04080},
  year={2024}
}

