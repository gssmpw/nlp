\begin{table}[t]
\centering
\small
% \vspace{-0.05in}
\vspace{-0.1in}
\centering\small
% >{\columncolor{mycolor}
\newcolumntype{a}{>{\columncolor{mygreen! 10}}c}
% \newcommand{\gap}[1]{{\scriptsize(#1)}}
% \resizebox{\linewidth}{!}{% 

% \setlength\tabcolsep{1.7pt} 
\begin{tabular}{l  ccccc}
\toprule
 & Pickscore & MPS & VQA & VILA\\
\midrule
Diffusion-DPO~\citep{wallace2023diffusion} & 22.71 & 11.59 & 0.834 & 6.049 \\
DPO-Syn  & 22.74 & 11.59 & 0.825 & 6.074 \\
CaPO  & {\bf 22.83} & {\bf 11.71} & {\bf 0.838} & {\bf 6.141}\\
\bottomrule
% \subcaption{a}
\end{tabular}
\vspace{-2mm}
\caption{
\textbf{Comparison with Diffusion-DPO~\citep{wallace2023diffusion}.} 
We compare CaPO with Diffusion-DPO, which is trained on human annotated preference dataset Pick-a-pic~\citep{kirstain2023pick}. 
For fair comparison, we train CaPO with same prompts from Pick-a-pic, but trained with generated images from SDXL. Also, we use Pickscore~\citep{kirstain2023pick}, which is trained on Pick-a-pic dataset. We also train DPO for our synthetic dataset, denoted as DPO-Syn.
We report Pickscore, MPS, VQAscore, and VILA score by generating images from Parti prompts. 
}\label{tab:dpo_comp}
\vspace{-0.05in}
\end{table}

