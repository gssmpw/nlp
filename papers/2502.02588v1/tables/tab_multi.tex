\begin{table*}[t]
\centering
\small
\centering\small
\newcolumntype{a}{>{\columncolor{mygreen! 10}}c}
\setlength\tabcolsep{1.5pt} 
\begin{minipage}{0.49\textwidth}
\centering\small
\begin{tabular}{ll  cc cc cc  }
\toprule
% &\multicolumn{3}{c}{Sum of rewards} & \multicolumn{3}{c}{Model merging} & \multicolumn{3}{c}{Joint (Ours)}\\
% \cmidrule(lr){2-4}\cmidrule(lr){5-7}\cmidrule(lr){8-10}
&& \multicolumn{2}{c}{MPS}  & \multicolumn{2}{c}{VQAscore}  & \multicolumn{2}{c}{VILA} \\
\cmidrule(lr){3-4}\cmidrule(lr){5-6} \cmidrule(lr){7-8}
Objective & Method  & Win (\%) & Score & Win (\%) & Score & Win (\%) & Score\\
%  & MPS & VQA & VILA  & VQA & MPS & VILA & VILA & MPS & VQA  \\
\midrule
SDXL & \multicolumn{1}{c}{-} & - & 11.30 & - & 0.826 & - &5.953 \\
\midrule
\multirow{3}{*}{DPO} 
& {\tt{SUM}}  & 57.2 & 11.48 & 52.1 & 0.829 & 71.9 & 6.193  \\
& {\tt{SOUP}} & 56.5 & 11.46 & 52.2 & 0.830 & 74.3 & 6.227 \\
& {\tt{FRS}}  & 58.1 & 11.54 & 52.9 & 0.834 & 78.6 & 6.294 \\
\midrule
\multirow{3}{*}{IPO} 
& {\tt{SUM}}  & 57.4 & 11.49 & 51.1 & 0.828 & 66.8 & 6.111  \\
& {\tt{SOUP}} & 55.4 & 11.44 & 52.0 & 0.830 & 70.3 & 6.154  \\
& {\tt{FRS}}  & 57.8 & 11.52 & 52.0 & 0.830 & 74.4 & 6.238  \\
\midrule
\multirow{3}{*}{CaPO} 
& {\tt{SUM}}  & {\bf 61.2} & 11.62 & 52.5 & 0.834 & 75.0 & 6.258 \\
& {\tt{SOUP}} & 59.4 & 11.44 & 52.8 & 0.835 & 77.6 & 6.259 \\
& {\tt{FRS}}  & {\bf 61.2} & {\bf 11.66} & {\bf 54.6} & {\bf 0.839} & {\bf 79.2} & {\bf 6.340} \\
\bottomrule
% \subcaption{a}
\end{tabular}
\caption*{(a) Base model SDXL}
\end{minipage}
\begin{minipage}{0.49\textwidth}
\centering\small
\hfill
\begin{tabular}{ll  cc cc cc  }
\toprule
&& \multicolumn{2}{c}{MPS}  & \multicolumn{2}{c}{VQAscore}  & \multicolumn{2}{c}{VILA} \\
\cmidrule(lr){3-4}\cmidrule(lr){5-6} \cmidrule(lr){7-8}
Objective & Method  & Win (\%) & Score & Win (\%) & Score & Win (\%) & Score\\
\midrule
SD3-M & \multicolumn{1}{c}{-} & - & 13.39 & - & 0.908 & - & 5.793\\
\midrule
\multirow{3}{*}{DPO} 
& {\tt{SUM}} & 55.3 & 13.50 & 52.8 & 0.910 & 55.0 & 5.832 \\
& {\tt{SOUP}} & 56.1 & 13.39 & 54.7 & 0.908 & 63.4 & 5.875 \\
& {\tt{FRS}} & 56.7 & 13.55 & 53.2 & 0.909 & 68.7 & 5.922 \\
\midrule
\multirow{3}{*}{IPO} 
& {\tt{SUM}}  & 54.1 & 13.47 & 53.9 & 0.912 & 58.9 & 5.847 \\
& {\tt{SOUP}} & 55.6 & 13.39 & 53.5 & 0.910 & 60.4 & 5.848 \\
& {\tt{FRS}}  & 55.5 & 13.55 & 54.6 & 0.913 & 64.7 & 5.913 \\
\midrule
\multirow{3}{*}{CaPO} 
& {\tt{SUM}}  & 57.8 & 13.56 & 54.3 & 0.912 & 57.0 & 5.833 \\
& {\tt{SOUP}} & {\bf 59.4} & {\bf 13.60} & 54.9 & 0.911 & 67.6 & 5.896 \\
& {\tt{FRS}}  & 59.0 & 13.58 & {\bf 55.7} & {\bf 0.914} & {\bf 69.3} & {\bf 5.943} \\
\bottomrule
\end{tabular}
\caption*{(b) Base model SD3-M}
\end{minipage}
\vspace{-2mm}
\caption{
\textbf{Multi-reward results.} We report the average reward scores (Score) and win-rate (\%) over base model by using automatic evaluation with each reward model (Win).
We compare preference objectives DPO~\cite{wallace2023diffusion}, IPO~\cite{azar2024general}, and CaPO and combination with different pair selection methods, \emph{e.g.}, using sum of rewards to conduct top-1 and worst-1 sampling ({\tt{SUM}}), and using frontier-based rejection sampling ({\tt{FRS}}).
Furthermore, we compare our method with rewarded soup~\citep{rame2024rewarded}, by merging single reward optimized models ({\tt{SOUP}}). 
% We use Parti prompts~\citep{yu2022scaling} to generate 4 images per prompt for base model and models fine-tuned with each reward signal and method. \yl{Spell out FRS in caption?}
% We highlight the \textcolor{mygreen}{row} to indicate the usage of rewards used for fine-tuning.
}\label{tab:multi}
\end{table*}

