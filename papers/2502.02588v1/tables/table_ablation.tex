\begin{table}[t]
\centering
\small
\vspace{-0.1in}
\centering\small
% \setlength\tabcolsep{1.7pt} 
\begin{tabular}{l  ccc}
\toprule
 & MPS & VQA & VILA \\
\midrule
Constant weighting  & 56.5  & 51.8 & 70.8  \\
\midrule
Sigmoid weighting ($b=1.0$)  & 59.1 &	54.5 &73.3 \\
Sigmoid weighting ($b=1.5$)  & 61.2 & 54.6 & 79.2   \\
Sigmoid weighting ($b=2.0$)  & 58.6 & 52.6 & 75.2   \\
\bottomrule
% \subcaption{a}
\end{tabular}
\vspace{-2mm}
\caption{
\textbf{Ablation on loss weighting.} We show the results of CaPO multi-reward fine-tuning SDXL with constant weighting (\emph{i.e.}, $-w_t\lambda_t'=1$), and sigmoid weighting by varying bias $b=1.0, 1.5, 2.0$. Using sigmoid weighting shows better results than constant weighting, and $b=1.5$ performs the best.
}\label{tab:abl}
\end{table}