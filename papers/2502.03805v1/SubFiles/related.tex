\section{Related Works}

\textbf{Perturbation-based analysis} has achieved remarkable success in neural network interpretability and pruning. For example, Catformer~\cite{pmlr-v139-davis21a} and Admin~\cite{liu-etal-2020-understanding} utilize output perturbation analysis to create more stable network architectures and enhance training methods. Similarly, pruning techniques~\cite{learning, sparsegpt}, with Wanda~\cite{wanda} as a representative, aim to identify neurons whose removal minimally impacts output, thereby reducing network parameters.
In this paper, we present the first analysis of output perturbations aimed at developing more effective selection metrics for cache eviction in efficient LLM inference.

\textbf{KV cache eviction} aims to retain only critical KV cache entries while evicting non-essential ones to reduce cache size, facilitating efficient long-sequence inference in LLMs. Early methods \citep{streamingllm}, which preserved recent entries in a sliding window, risked losing important information in long sequences. Techniques like H2O \citep{h2o} and Scissorhands \citep{liu2024scissorhands} used accumulated attention scores to identify key entries, aiming to retain crucial context. Subsequent works refined these methods \citep{ ge2024modeltellsdiscardadaptive,adnan2024keyformer,ge2024model,SnapKV}, with SnapKV \citep{SnapKV} achieving the SOTA performance through introducing observation window-based attention weight accumulation and pooling operations. Recent budget allocation optimization methods \citep{yang2024pyramidinfer,pyramidkv}, exemplified by AdaKV \citep{ada}, enhance post-eviction generation by allocating budgets based on attention head characteristics. However, these methods are largely empirical, relying solely on attention weights to identify critical entries. Our paper introduces a novel perturbation-constrained selection algorithm based on in-depth analysis from an output perturbation perspective. This algorithm seamlessly integrates into existing cache eviction methods without altering underlying accumulation processes. In our work, we demonstrate its effectiveness by applying it to SnapKV and AdaKV, all showing consistent improvements in post-eviction generation quality under varying budgets.
