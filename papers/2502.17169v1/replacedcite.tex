\section{Related work}
Our work stands at the intersection of two lines of research: logical reasoning with synthetic simplified English data, and context length evaluation. ____ and ____ explored the intersection of the two, but they imported the padding technique from previous work on LLM stress-texting, while we scale the dataset's original generation process instead of padding it with other text.
Human annotated long context benchmarks are very valuable but hard to annotate ____, which causes current language models to saturate them.

\paragraph{Synthetic datasets for reasoning}

%\paragraph{Neuro-symbolic methods and externalization} Our work ____

Numerous works investigate the logical capabilities of NLP models using textual datasets and symbolic reasoning ____. We focus on the grammar-derived synthetic datasets. RuleTaker ____ LogicNLI ____, FLD ____ and FOL-NLI ____ address different subsets of first-order logic with English translations. Other works also explore non-standard logic with synthetic datasets, notably probabilistic ____, paraconsistent ____, epistemic ____ logics.

These approaches focus on input sizes typically suitable to a standard BERT ____ encoder (<512 tokens). Here, we push the number of expressions in the input while avoiding paradoxes. This is related to the satisfiability problem which was explored by ____ who use a solver to study the satisfiability in natural language using the Z3 solver and dedicated generation logic on constrained problems.  However, they also focus on relatively moderate text size while we use satisfiability checking as a stepping stone to generate large text and not only as a task in itself.

\paragraph{LLM context length stress tests}  Our work is also related to context window stress testing. The Long-Range Arena ____ provides the first systematic analysis of the long-range processing capabilities of text encoders, focusing mainly on algorithmic reasoning and retrieval tasks. Needle in Haystack benchmarks ____ test longer window sizes with simple retrieval tasks and use Paul Graham essays as padding. BABILong   ____ uses bAbi ____ reasoning tasks and interleaves relevant text with irrelevant input from BookCorpus ____. FlenQA ____ applies a similar process to the RuleTaker ____ deductive logical reasoning task and uses Paul Graham essays as padding. Ruler uses simple algorithmic tasks like variable tracking and word counting. They also use Paul Graham essays as noise, or repetitions of sentences such as \textit{The sky is blue}, following ____. %____ evaluates missing item prediction. % and also shows that the context window is shortened when the input is homogeneous, but they use a simplistic missing item prediction task.
The MuSR dataset uses GPT-4 generated ____ problems, which makes it hard to verify the problems' integrity at scale.