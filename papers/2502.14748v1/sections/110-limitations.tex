Data exploration is a complex task that relies heavily on human reasoning and analysis to produce meaningful insights. 
%
While manually sorting data is cumbersome and inefficient, tools like topic models can significantly make the process more efficient and effective for social scientists.
%
With the growing usage of \mm{}s in social science tasks, variations of topic modeling methods are shifting to \mm{}-based~\cite{pham2024topicgpt, lam2024concept}, which also raises important questions and challenges about their effectiveness, accuracy, and interpretability~\cite{li-etal-2024-pedants, li2025benchmarkevaluationsapplicationschallenges, hoyle2021automated,doogan-buntine-2021-topic, mondal2024scidoc2diagrammermafgenerationscientificdiagrams}.
%
To address these concerns, we evaluate and compare traditional topic models with \mm{}-based approaches using a combination of metrics: clustering evaluation, automatic metrics for pretest and post tests. 
%
Additionally, we use human pairwise answer preference, analyzed through the Bradley-Terry model~\cite{Bradley1952RankAO}, to incorporate a social science-inspired application perspective rather than relying solely on automated evaluations. 
%
Although this evaluation method provides valuable insights into the capabilities of \mm{}-based tools for data exploration applications, it is challenging to scale~\cite{zhou2024multi}.
%
In addition, despite these advances of \mm{}s for data exploration, no current approach can fully balance topic interpretability, user-friendliness, hallucination, and minimal user input. 
%
While \bass{} appears to help users generate effective responses and topics the most, it requires significant human supervision, particularly on simple datasets that can be fully automated.
%
Future work could focus on developing more user-friendly methods to reduce the need for extensive human supervision in topic generation. 
%
A promising direction is a hybrid approach: leveraging traditional clustering techniques to generate initial clusters, using \mm{}s to produce topics, and using a confidence detector to identify problematic topics for user correction. 
%
This approach can minimize user effort by eliminating the need to start topic generation from scratch while also reducing the cost of excessive \mm{} prompting.
