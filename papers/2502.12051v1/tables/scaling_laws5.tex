\begin{table*}[!htb]
    \centering
    \begin{tabular}{p{3.5cm} p{5.2cm} p{5.2cm}}
        \cline{1-3}
        \textbf{Paper} & \textbf{Key insights} & \textbf{Applicability} \\
        \cline{1-3}
        \citet{clark_unified_2022} & Routing-based models show diminishing returns at larger scales, requiring optimal routing strategies for efficiency. & Routing-based models, MoEs, transformer scaling. \\
        \cline{1-3}
        \citet{krajewski_scaling_2024} & Fine-grained MoEs achieve up to 40$\times$ compute efficiency gains when expert granularity is optimized. & Mixture of Experts models, large-scale compute efficiency. \\
        \cline{1-3}
        \citet{frantar_scaling_2023} & Sparse model scaling enables predicting optimal sparsity levels for given compute budgets. & Sparse models, structured sparsity optimization, parameter reduction. \\
        \cline{1-3}
    \end{tabular}
    \caption{Scaling laws for routing, sparsity, pruning, and quantization.}
    \label{tab:scaling_laws5}
\end{table*}
