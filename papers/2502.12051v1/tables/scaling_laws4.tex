\begin{table*}[!htb]
    \centering
    \scalebox{0.9}{
    \begin{tabular}{p{3.5cm} p{6.3cm} p{5.9cm}}
        \cline{1-3}
        \textbf{Paper} & \textbf{Key insights} & \textbf{Applicability} \\
        \cline{1-3}
        \multirow{5}{*}{\citet{ brown_large_2024}} & Adaptive test-time compute strategies reduce computational costs by 4$\times$ while maintaining performance, enabling smaller models to compete with much larger ones. & Test-time compute efficiency, inference cost reduction, compute-limited environments. \\
        \cdashline{1-3}
        \multirow{4}{*}{\citet{wu_inference_2024}} & Advanced inference methods like REBASE tree search allow smaller models to match the performance of significantly larger ones. & High-efficiency inference, performance optimization for small models. \\
        %\cline{1-3}
        %\citet{sardana_beyond_2024} & Contrary to Chinchilla scaling laws, extreme tokens-per-parameter ratios (up to 10,000) improve model quality and efficiency. & Long-duration training, optimizing token efficiency, data efficiency improvements. \\
        \cdashline{1-3}
        \multirow{4}{*}{\citet{shao_scaling_2024}} & Increasing datastore size in retrieval-augmented models consistently improves performance under the same compute budget, without evident saturation. & Retrieval-augmented language models, knowledge-intensive tasks, compute-efficient architectures. \\
        \cdashline{1-3}
        \multirow{3}{*}{\citet{clark_unified_2022}} & Routing-based models show diminishing returns at larger scales, requiring optimal routing strategies for efficiency. & Routing-based models, MoEs, transformer scaling. \\
        \cdashline{1-3}
        \multirow{3}{*}{\citet{krajewski_scaling_2024}} & Fine-grained MoEs achieve up to 40$\times$ compute efficiency gains when expert granularity is optimized. & Mixture of Experts models, large-scale compute efficiency. \\
        \cdashline{1-3}
        \multirow{3}{*}{\citet{frantar_scaling_2023}} & Sparse model scaling enables predicting optimal sparsity levels for given compute budgets. & Sparse models, structured sparsity optimization, parameter reduction. \\
        \cline{1-3}
    \end{tabular}
    }
    \caption{Scaling laws of efficient models.}
    \label{tab:scaling_laws4}
\end{table*}
