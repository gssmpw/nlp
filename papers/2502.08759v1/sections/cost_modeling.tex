
\section{Detailed Analysis of Feedback Solicitation Costs and Their Impact on Cumulative Rewards}

In systems that integrate human feedback, the cost of feedback solicitation plays a crucial role in determining the efficiency and practicality of the algorithm. Below, we provide a structured analysis of these costs and their effects.

\subsection{Cost Components in Feedback Solicitation}

Feedback solicitation costs can be broken into three primary components:
\begin{itemize}
    \item \textbf{Human Effort Cost (\(C_h\))}: Time, cognitive load, or financial compensation required for a human expert to provide feedback.
    \item \textbf{System Overhead (\(C_s\))}: Computational and communication overhead associated with querying, collecting, and processing feedback.
    \item \textbf{Opportunity Cost (\(C_o\))}: Delay or missed opportunities to explore other actions during feedback solicitation.
\end{itemize}

The total cost per solicitation can be expressed as:
\[
C_{\text{total}} = C_h + C_s + C_o.
\]

\subsection{Trade-off Between Feedback and Performance}

Feedback improves learning by reducing uncertainty in decision-making but comes at a cost. The trade-off is evident in two opposing factors:
\begin{itemize}
    \item \textbf{Benefits}: Incorporating feedback accelerates convergence, reduces regret, and improves cumulative rewards.
    \item \textbf{Costs}: Frequent feedback queries increase the total cost, potentially diminishing the system’s overall utility.
\end{itemize}

The cumulative rewards \(R_T\) after \(T\) rounds with feedback solicitation frequency \(p\) can be modeled as:
\[
R_T = \sum_{t=1}^T r_t - p \cdot C_{\text{total}},
\]
where \(r_t\) represents the reward at time step \(t\), and \(p\) is the fraction of rounds in which feedback is solicited.

\subsection{Effect of Feedback Quality and Frequency}

\subsubsection{High-Quality Feedback (\(q_t \to 1\))}

\begin{itemize}
    \item \textbf{Impact}: High-quality feedback significantly reduces regret, as the system quickly learns optimal actions.
    \item \textbf{Cost Justification}: Even with higher solicitation costs, the performance gains justify frequent feedback, especially in complex environments.
\end{itemize}

\subsubsection{Low-Quality Feedback (\(q_t \to 0\))}

\begin{itemize}
    \item \textbf{Impact}: Low-quality feedback adds noise to the learning process, diminishing performance gains.
    \item \textbf{Cost Justification}: Frequent solicitation becomes inefficient, and selective feedback solicitation based on entropy thresholds (\(\lambda\)) is preferred.
\end{itemize}

\subsubsection{Frequency of Feedback (\(p\))}

\begin{itemize}
    \item High \(p\) improves learning but incurs higher total costs, leading to diminishing returns as cumulative rewards plateau.
    \item Low \(p\) reduces costs but risks slower convergence and higher regret.
\end{itemize}

\subsection{Entropy-Based Feedback Solicitation}

An entropy-based mechanism optimizes feedback solicitation by querying only when the model’s uncertainty surpasses a predefined threshold (\(\lambda\)):
\begin{itemize}
    \item \textbf{High Entropy (\(H(\pi) > \lambda\))}: Feedback is requested to resolve uncertainty, ensuring maximum utility from the cost incurred.
    \item \textbf{Low Entropy (\(H(\pi) \leq \lambda\))}: Feedback is avoided as the model is confident in its decision.
\end{itemize}

This selective querying strategy reduces the total feedback cost while maintaining performance by focusing resources where they have the highest impact.

\subsection{Experimental Analysis}

Using simulated environments:
\begin{itemize}
    \item \textbf{Performance vs. Cost}: Reducing feedback frequency (\(p\)) by increasing \(\lambda\) leads to a marginal decrease in performance while significantly reducing costs. For instance, at \(p = 0.3\), performance dropped by only 5\% compared to \(p = 1.0\), but the cost was reduced by 70\%.
    \item \textbf{Dataset Dependency}: Feedback efficiency varies across datasets. Datasets with large action spaces benefit more from frequent feedback (e.g., Delicious dataset), while datasets with fewer actions (e.g., Bibtex dataset) require less frequent feedback due to faster convergence.
\end{itemize}

\subsection{Insights and Practical Implications}

\begin{itemize}
    \item \textbf{Optimal Feedback Strategy}: Use selective feedback based on model uncertainty and adjust \(\lambda\) to balance feedback costs with performance gains depending on the application.
    \item \textbf{Recommendations for Practitioners}: In high-cost settings, prioritize low feedback frequency (\(p \to 0.2-0.4\)) with robust entropy thresholds. For critical applications, higher feedback costs can be justified for improved cumulative rewards.
    \item \textbf{Scalability}: Entropy-based solicitation is particularly effective for large-scale systems where querying all rounds is impractical.
\end{itemize}

\subsection{Conclusion}

Balancing feedback solicitation costs and cumulative rewards requires careful tuning of feedback frequency and quality thresholds. An entropy-based approach effectively minimizes costs while maintaining performance, making it a practical solution for real-world applications. Future work could explore dynamic threshold adaptation to further optimize this trade-off.

