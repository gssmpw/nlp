% \section{TODO List for the paper}
% \begin{itemize}[label=$\square$]
%     % \item[$\checkmark$] Implement neural bandit strategies 
%     % \item[$\checkmark$]  How the work articulates with current RLHF literature and whether RLHF algorithms with discount factor $0$ are applicable?
%     % \item[$\checkmark$]   Decide whether to keep linear UCB as a comparison algorithm since, we need to compare it with other algorithms with linearzied strategies. (not important since we are using non-linear version of other algorithms, so better to remove it)
%     % \item[$\checkmark$] Rewrite the methodology section with more detail and scientific notations. 
%     % \item[$\checkmark$]  Implement TAMER framework, which will act as a baseline for CBHF by setting the discount factor to $0$
%     \item use references to ground the proposed variation and highlight the novelty of the approach 
%     \item lack of relevancy of RL with bandit approach (may be focus only on the bandit approach without explicitly referencing rlhf framework)
%     % \item[$\checkmark$] The difference between implicit feedback and preference based feedback is not presented.
%     \item Justification of obtaining feedback every 200 and 600 epochs, and a pseudo code of the algorithm to justify where to incorporate the entropy based setup. \textbf{a small experimens on 200, 300, and etc. (In the main paper, one line. Add experiments to appendix)}
%     \item \textbf{IMPORTANT} Why does the community need specific literature on bandits with human feedback, what’s the added value compared to RLHF strategies, and why isn’t it enough to set the discount factor of RLHF to 0? \textbf{We can set the discount factor RLHF to 0.} Has the idea of using entropy been explored in RLHF, and bandits with HF? \textbf{Idea of using entropy is new. Reviewers' main concern: why do we care about entropy based method?}
%     \item The quality of human feedback is not correlated with the learner’s final performance provide more intuition on why this is observed empirically
%     \item elaborate on why entropy based methods achieve good empirical performance. 
%     % \item[$\checkmark$] Why do you use a random forest classifier to generate different levels of expert quality? Can you not simply generate synthetic experiments where the level of quality is chosen uniformly at random?
%     \item \textcolor{red}{Make the method Incorporating human Feedback part more scientific, More elaborations on entropy based action restriction}
%     \item Fix the tables and figures, missing references.
%     % \item[$\checkmark$] Third item (checked)
% \end{itemize}
