\subsection{Imitation learning}
The goal of imitation learning is to learn a behavior policy $\pi^b$ given access to either the expert policy $\pi^e$ or trajectories derived from the expert policy $\tau^e$. This work operates in the setting where the agent only has access to observation-based trajectories, i.e. $\tau^e \equiv \{(o_t, a_t)_{t=0}^{T}\}_{n=0}^N$. Here $N$ and $T$ denote the number of demonstrations and episode timesteps respectively. We choose this specific setting since obtaining observations and actions from expert or near-expert demonstrators is feasible in real-world settings~\cite{aloha,openteach} and falls in line with recent work in this area~\cite{baku,vqbet,aloha,diffusionpolicy}.


\subsection{Behavior Cloning}
Behavior Cloning (BC)~\cite{pomerleau1998autonomous,shafiullah2024supervised} corresponds to solving the maximum likelihood problem shown in Eq.~\ref{eq:bc}. Here $\mathcal{T}^{e}$ refers to expert demonstrations. When parameterized by a normal distribution with fixed variance, the objective can be framed as a regression problem where, given observations $o^e$, $\pi^{BC}$ needs to output $a^e$.
\begin{equation}
    \mathcal{L}^{BC} = \mathbb{E}_{(o^{e},a^{e})\sim \mathcal{T}^{e}} \|a^{e} - \pi^{BC}(o^{e})\|^{2}
    \label{eq:bc}
\end{equation}

 After training, it enables $\pi^{BC}$ to mimic the actions corresponding to the observations seen in the demonstrations.

\subsection{Semantic Correspondence and Point Tracking}
Semantic correspondence and point tracking are fundamental problems in computer vision. Semantic correspondence matches semantically equivalent points between images of different scenes, while point tracking follows reference points across video frames. We leverage these ideas using two state-of-the-art models: DIFT~\cite{dift} and Co-Tracker~\cite{cotracker}. DIFT establishes correspondences between reference and observed images, as illustrated in Figure~\ref{fig:correspondence}, while Co-Tracker tracks initialized key points throughout the video trajectory (Figure~\ref{fig:method}). This integration enables robust identification and tracking of semantically meaningful points across diverse visual scenarios, forming a key component \method{}. We have included a more detailed explanation in Appendix~\ref{appendix:background}.
