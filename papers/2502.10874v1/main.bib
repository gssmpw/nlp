@article{Graefe11a,
  author  = {Goetz Graefe},
  title   = {Modern B-Tree Techniques},
  journal = {Found. Trends Databases},
  volume  = {3},
  number  = {4},
  pages   = {203--402},
  year    = {2011}
}

@article{Graefe24,
  author  = {Goetz Graefe},
  title   = {More Modern B-Tree Techniques},
  journal = {Found. Trends Databases},
  volume  = {13},
  number  = {3},
  pages   = {169--249},
  year    = {2024}
}

@inproceedings{leanstore18,
  author    = {Leis, Viktor and Haubenschild, Michael and Kemper, Alfons and Neumann, Thomas},
  booktitle = {2018 IEEE 34th International Conference on Data Engineering (ICDE)},
  title     = {LeanStore: In-Memory Data Management beyond Main Memory},
  year      = {2018},
  volume    = {},
  number    = {},
  pages     = {185-196},
  keywords  = {Random access memory;Indexes;Memory management;Hardware;Data structures;storage engine;in memory;SSD},
  doi       = {10.1109/ICDE.2018.00026}
}

@article{rocksdb21,
  author     = {Dong, Siying and Kryczka, Andrew and Jin, Yanqin and Stumm, Michael},
  title      = {RocksDB: Evolution of Development Priorities in a Key-value Store Serving Large-scale Applications},
  year       = {2021},
  issue_date = {2021-10},
  publisher  = {Association for Computing Machinery},
  address    = {New York, NY, USA},
  volume     = {17},
  number     = {4},
  issn       = {1553-3077},
  url        = {https://doi.org/10.1145/3483840},
  doi        = {10.1145/3483840},
  abstract   = {This article is an eight-year retrospective on development priorities for RocksDB, a key-value store developed at Facebook that targets large-scale distributed systems and that is optimized for Solid State Drives (SSDs). We describe how the priorities evolved over time as a result of hardware trends and extensive experiences running RocksDB at scale in production at a number of organizations: from optimizing write amplification, to space amplification, to CPU utilization. We describe lessons from running large-scale applications, including that resource allocation needs to be managed across different RocksDB instances, that data formats need to remain backward- and forward-compatible to allow incremental software rollouts, and that appropriate support for database replication and backups are needed. Lessons from failure handling taught us that data corruption errors needed to be detected earlier and that data integrity protection mechanisms are needed at every layer of the system. We describe improvements to the key-value interface. We describe a number of efforts that in retrospect proved to be misguided. Finally, we describe a number of open problems that could benefit from future research.},
  journal    = {ACM Trans. Storage},
  month      = {10},
  articleno  = {26},
  numpages   = {32},
  keywords   = {Key-value stores, large-scale applications, RocksDB, SSD, compaction, databases}
}

@misc{databricks2018stream,
  author = {{Databricks}},
  title  = {Introducing Stream-Stream Joins in {Apache Spark} 2.3},
  year   = {2018},
  url    = {https://www.databricks.com/blog/2018/03/13/introducing-stream-stream-joins-in-apache-spark-2-3.html}
}

@misc{postgresql2024incremental,
  author = {{PostgreSQL}},
  title  = {Incremental View Maintenance},
  year   = {2023},
  url    = {https://wiki.postgresql.org/wiki/Incremental_View_Maintenance#Outer_Join_Support},
  note   = {Section: Outer Join Support, Accessed: 2024-05-17}
}

@article{Budiu2023DBSP,
  author  = {Mihai Budiu and Tej Chajed and Frank McSherry and Leonid Ryzhyk and Val Tannen},
  title   = {{DBSP}: Automatic Incremental View Maintenance for Rich Query Languages},
  journal = {Proc. VLDB Endow.},
  volume  = {16},
  number  = {7},
  pages   = {1601--1614},
  year    = {2023}
}

@article{Blakeley1989UpdatingDerivedRelations,
  author  = {Jos{\'e} A. Blakeley and Neil Coburn and Per-{\AA}ke Larson},
  title   = {Updating Derived Relations: Detecting Irrelevant and Autonomously Computable Updates},
  journal = {ACM Trans. Database Syst.},
  volume  = {14},
  number  = {3},
  pages   = {369--400},
  year    = {1989}
}

@article{Blakeley1986EfficientlyUpdatingMaterializedViews,
  author    = {José A. Blakeley and Per-Åke Larson and Frank Wm Tompa},
  title     = {Efficiently Updating Materialized Views},
  journal   = {Proceedings of the ACM SIGMOD International Conference on Management of Data},
  year      = {1986},
  pages     = {61-71},
  publisher = {ACM},
  address   = {Waterloo, Ontario, Canada},
  doi       = {10.1145/500.50075}
}

@misc{microsoft2024indexedviews,
  author = {{Microsoft SQL Server}},
  title  = {Create Indexed Views: Additional requirements},
  year   = {2024},
  url    = {https://learn.microsoft.com/en-us/sql/relational-databases/views/create-indexed-views?view=sql-server-ver16#additional-requirements},
  note   = {Accessed: 2024-09-01}
}

@misc{mysql2024viewupdatability,
  author = {{MySQL}},
  title  = {Updatable and Insertable Views},
  year   = {2024},
  url    = {https://dev.mysql.com/doc/refman/8.4/en/view-updatability.html},
  note   = {Accessed: 2024-09-01}
}

@misc{ibm2024mqts,
  author = {{IBM Db2}},
  title  = {Refreshing system-maintained materialized query tables},
  year   = {2024},
  url    = {https://www.ibm.com/docs/en/db2-for-zos/13?topic=tables-refreshing-system-maintained-materialized-query-table},
  note   = {Accessed: 2024-09-01}
}

@inproceedings{larson2007outerjoin,
  author    = {Larson, Per-{\AA}ke and Zhou, Jingren},
  booktitle = {2007 IEEE 23rd International Conference on Data Engineering},
  title     = {Efficient Maintenance of Materialized Outer-Join Views},
  year      = {2007},
  volume    = {},
  number    = {},
  pages     = {56-65},
  keywords  = {Warehousing;Databases;XML;Query processing},
  doi       = {10.1109/ICDE.2007.367851}
}

@book{carpenter2022cassandra,
  title     = {CASSANDRA: The Definitive Guide, (revised) Third Edition},
  author    = {Carpenter, J. and Hewitt, E.},
  isbn      = {9781492097112},
  url       = {https://books.google.com/books?id=MKVaEAAAQBAJ},
  year      = {2022},
  publisher = {O'Reilly Media, Incorporated}
}

@misc{oracle2024mvrefresh,
  author = {{Oracle}},
  title  = {Refreshing Materialized Views},
  year   = {2024},
  url    = {https://docs.oracle.com/en/database/oracle/oracle-database/23/dwhsg/refreshing-materialized-views.html},
  note   = {Accessed: 2024-09-01}
}

@misc{oracle2024mvrewrite,
  author = {{Oracle}},
  title  = {Basic Query Rewrite with Materialized Views},
  year   = {2024},
  url    = {https://docs.oracle.com/en/database/oracle/oracle-database/23/dwhsg/basic-query-rewrite-materialized-views.html},
  note   = {Accessed: 2024-09-01}
}

@inproceedings{graefe2007merged,
  title     = {Algorithms for merged indexes},
  author    = {Goetz Graefe},
  booktitle = {Datenbanksysteme in Business, Technologie und Web (BTW 2007), 12. Fachtagung des GI-Fachbereichs Datenbanken und Informationssysteme (DBIS)},
  editor    = {Alfons Kemper and Harald Schöning and Thomas Rose and Matthias Jarke and Thomas Seidl and Christoph Quix and Christoph Brochhaus},
  year      = {2007},
  pages     = {112-127},
  publisher = {Gesellschaft für Informatik, Bonn}
}

@inproceedings{graefe2007locking,
  title     = {Hierarchical Locking in B-tree Indexes},
  author    = {Goetz Graefe},
  booktitle = {Datenbanksysteme in Business, Technologie und Web (BTW 2007), 12. Fachtagung des GI-Fachbereichs Datenbanken und Informationssysteme (DBIS)},
  editor    = {Alfons Kemper and Harald Schöning and Thomas Rose and Matthias Jarke and Thomas Seidl and Christoph Quix and Christoph Brochhaus},
  year      = {2007},
  pages     = {112-127},
  publisher = {Gesellschaft für Informatik, Bonn}
}

@article{gupta1995maintenance,
  title   = {Maintenance of materialized views: Problems, techniques, and applications},
  author  = {Gupta, Ashish and Mumick, Inderpal Singh and others},
  journal = {IEEE Data Engineering Bulletin},
  volume  = {18},
  number  = {2},
  pages   = {3--18},
  year    = {1995}
}

@article{Zhuge1995ViewMaintenance,
author = {Zhuge, Yue and Garc\'{\i}a-Molina, H\'{e}ctor and Hammer, Joachim and Widom, Jennifer},
title = {View maintenance in a warehousing environment},
year = {1995},
issue_date = {1995-05},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {24},
number = {2},
issn = {0163-5808},
url = {https://doi.org/10.1145/568271.223848},
doi = {10.1145/568271.223848},
abstract = {A warehouse is a repository of integrated information drawn from remote data sources. Since a warehouse effectively implements materialized views, we must maintain the views as the data sources are updated. This view maintenance problem differs from the traditional one in that the view definition and the base data are now decoupled. We show that this decoupling can result in anomalies if traditional algorithms are applied. We introduce a new algorithm, ECA (for "Eager Compensating Algorithm"), that eliminates the anomalies. ECA is based on previous incremental view maintenance algorithms, but extra "compensating" queries are used to eliminate anomalies. We also introduce two streamlined versions of ECA for special cases of views and updates, and we present an initial performance study that compares ECA to a view recomputation algorithm in terms of messages transmitted, data transferred, and I/O costs.},
journal = {SIGMOD Rec.},
month = {5},
pages = {316–327},
numpages = {12}
}

@article{DARMONT199655,
  title    = {A comparison study of object-oriented database clustering techniques},
  journal  = {Information Sciences},
  volume   = {94},
  number   = {1},
  pages    = {55-86},
  year     = {1996},
  issn     = {0020-0255},
  doi      = {https://doi.org/10.1016/0020-0255(96)00119-3},
  url      = {https://www.sciencedirect.com/science/article/pii/0020025596001193},
  author   = {Jérôme Darmont and Le Gruenwald},
  abstract = {It is widely acknowledged that a good object clustering is critical to the performance of OODBs. Clustering means storing related objects close together on secondary storage so that when one object is accessed from disk, all its related objects are also brought into memory. Then access to these related objects is a main memory access that is much faster than a disk access. The aim of this paper is to compare the performance of three clustering algorithms: Cactis, CK, and ORION. Simulation experiments we performed showed that the Cactis algorithm is better than the ORION algorithm and that the CK algorithm totally outperforms both other algorithms in terms of response time and clustering overhead.}
}

@techreport{tpc2010benchmark,
  title       = {{TPC Benchmark C Standard Specification}},
  author      = {{Transaction Processing Performance Council (TPC)}},
  year        = {2010},
  version     = {Revision 5.11},
  institution = {{Transaction Processing Performance Council}},
  url         = {http://www.tpc.org},
  note        = {{\copyright} 2010 Transaction Processing Performance Council}
}

@article{bayer1972organization,
  title     = {Organization and maintenance of large ordered indexes},
  author    = {Rudolf Bayer and Edward McCreight},
  journal   = {Acta Informatica},
  volume    = {1},
  number    = {3},
  pages     = {173--189},
  year      = {1972},
  publisher = {Springer},
  doi       = {10.1007/BF00289509}
}

@article{comer1979ubiquitous,
  title     = {The ubiquitous {B}-tree},
  author    = {Douglas Comer},
  journal   = {ACM Computing Surveys},
  volume    = {11},
  number    = {2},
  pages     = {121--137},
  year      = {1979},
  doi       = {10.1145/356770.356776},
  publisher = {ACM}
}

@article{ONeil1996LSMTree,
  author  = {Patrick E. O'Neil and Edward Cheng and Dieter Gawlick and Elizabeth J. O'Neil},
  title   = {The Log-Structured Merge-tree ({LSM}-Tree)},
  journal = {Acta Inf.},
  volume  = {33},
  number  = {4},
  pages   = {351--385},
  year    = {1996}
}

@inproceedings{Jagadish1997LSM,
  author    = {Jagadish, H. V. and Narayan, P. P. S. and Seshadri, S. and Sudarshan, S. and Kanneganti, Rama},
  title     = {Incremental Organization for Data Recording and Warehousing},
  year      = {1997},
  isbn      = {1558604707},
  publisher = {Morgan Kaufmann Publishers Inc.},
  address   = {San Francisco, CA, USA},
  booktitle = {Proceedings of the 23rd International Conference on Very Large Data Bases},
  pages     = {16–25},
  numpages  = {10},
  series    = {VLDB '97}
}

@article{tozun2024reminiscences,
  author       = {Pınar Tözün and Matthias Boehm and Stratos Idreos and Martin L. Kersten and Stefan Manegold},
  title        = {Reminiscences on Influential Papers},
  journal      = {SIGMOD Record},
  volume       = {53},
  number       = {2},
  year         = {2024},
  pages        = {68--78},
  editor       = {Pınar Tözün},
  note         = {{Database Cracking. In Proceedings of the Conference on Innovative Data Systems Research (CIDR), 2007}},
  publisher    = {ACM},
  address      = {New York, NY, USA}
}

@inproceedings{flume,
title	= {FlumeJava: Easy, Efficient Data-Parallel Pipelines},
author	= {Craig Chambers and Ashish Raniwala and Frances Perry and Stephen Adams and Robert Henry and Robert Bradshaw and Nathan},
year	= {2010},
URL	= {http://dl.acm.org/citation.cfm?id=1806638},
booktitle	= {ACM SIGPLAN Conference on Programming Language Design and Implementation (PLDI)},
pages	= {363-375},
address	= {2 Penn Plaza, Suite 701 New York, NY 10121-0701}
}

@book{gupta1999selfm,
    author = {Gupta, Ashish and Mumick, Inderpal Singh},
    title = "{Materialized Views: Techniques, Implementations, and Applications}",
    publisher = {The MIT Press},
    year = {1999},
    month = {05},
    abstract = "{When an application is built, an underlying data model is chosen to make that application effective. Frequently, other applications need the same data, only modeled differently. The naïve solution of copying the underlying data and modeling is costly in terms of storage and makes data maintenance and evolution impossible. View mechanisms are a technique to model data differently for various applications without affecting the underlying format and structure of the data. The technique enables applications to customize shared data objects without affecting other applications that use the same objects. The growing data-manipulation needs of companies cannot be met by existing legacy systems that contain valuable data. Thus view mechanisms are becoming increasingly important as a way to model and use legacy data in new applications.Materialized views are views that have been computed and stored in databases. Because they reduce the need to recompute the view and/or data being queried, they speed up the querying of large amounts of data. Further, because they provide a systematic way to describe how to recompute the data, maintenance and evolution can be automated. Materialized views are especially useful in data warehousing, query optimization, integrity constraint maintenance, online analytical processing, and applications such as billing, banking, and retailing. This comprehensive volume, with a foreword by Jeff Ullman of Stanford University, will serve as a reference for students and commercial users, and encourage further use and development of materialized views.}",
    isbn = {9780262287500},
    doi = {10.7551/mitpress/4472.001.0001},
    url = {https://doi.org/10.7551/mitpress/4472.001.0001},
    chapter = {5 Data Integration Using Self-Maintainable Views},
}

@inproceedings{Blakeley1990PerformanceAnalysis,
  author    = {Jos{\'e} A. Blakeley and Nancy L. Martin},
  title     = {Join Index, Materialized View, and Hybrid-Hash Join: A Performance Analysis},
  booktitle = {ICDE},
  pages     = {256--263},
  year      = {1990}
}

@article{GUPTAchangetable,
title = {Incremental maintenance of aggregate and outerjoin expressions},
journal = {Information Systems},
volume = {31},
number = {6},
pages = {435-464},
year = {2006},
issn = {0306-4379},
doi = {https://doi.org/10.1016/j.is.2004.11.011},
url = {https://www.sciencedirect.com/science/article/pii/S030643790400119X},
author = {Himanshu Gupta and Inderpal Singh Mumick},
keywords = {View maintenance, Aggregate views, Outerjoin views, Incremental maintenance},
abstract = {Views stored in a data warehouse need to be kept current. As recomputing the views is very expensive, incremental maintenance algorithms are required. Over recent years, several incremental maintenance algorithms have been proposed. None of the proposed algorithms handle the general case of relational expressions involving aggregate and outerjoin operators efficiently. In this article, we develop the change-table technique for incrementally maintaining general view expressions involving relational and aggregate operators. We show that the change-table technique outperforms the previously proposed techniques by orders of magnitude. The developed framework easily extends to efficiently maintaining view expressions containing outerjoin operators. We prove that the developed change-table technique is an optimal incremental maintenance scheme for a given view expression tree under some reasonable assumptions.}
}

@inproceedings{selinger1979access,
  author       = {Patricia G. Selinger and Morton M. Astrahan and Donald D. Chamberlin and Raymond A. Lorie and Thomas G. Price},
  title        = {Access path selection in a relational database management system},
  booktitle    = {Proceedings of the ACM SIGMOD Conference},
  year         = {1979},
  pages        = {23--34},
  publisher    = {ACM}
}

@article{mumick1997maintenance,
author = {Mumick, Inderpal Singh and Quass, Dallan and Mumick, Barinderpal Singh},
title = {Maintenance of data cubes and summary tables in a warehouse},
year = {1997},
issue_date = {1997-06},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {26},
number = {2},
issn = {0163-5808},
url = {https://doi.org/10.1145/253262.253277},
doi = {10.1145/253262.253277},
abstract = {Data warehouses contain large amounts of information, often collected from a variety of independent sources. Decision-support functions in a warehouse, such as on-line analytical processing (OLAP), involve hundreds of complex aggregate queries over large volumes of data. It is not feasible to compute these queries by scanning the data sets each time. Warehouse applications therefore build a large number of summary tables, or materialized aggregate views, to help them increase the system performance.As changes, most notably new transactional data, are collected at the data sources, all summary tables at the warehouse that depend upon this data need to be updated. Usually, source changes are loaded into the warehouse at regular intervals, usually once a day, in a batch window, and the warehouse is made unavailable for querying while it is updated. Since the number of summary tables that need to be maintained is often large, a critical issue for data warehousing is how to maintain the summary tables efficiently.In this paper we propose a method of maintaining aggregate views (the summary-delta table method), and use it to solve two problems in maintaining summary tables in a warehouse: (1) how to efficiently maintain a summary table while minimizing the batch window needed for maintenance, and (2) how to maintain a large set of summary tables defined over the same base tables.While several papers have addressed the issues relating to choosing and materializing a set of summary tables, this is the first paper to address maintaining summary tables efficiently.},
journal = {SIGMOD Rec.},
month = {6},
pages = {100–111},
numpages = {12}
}

@inproceedings{gray1996data,
  author       = {J. Gray and A. Bosworth and A. Layman and H. Pirahesh},
  title        = {Data cube: A relational aggregation operator generalizing group-by, cross-tab, and sub-total},
  booktitle    = {Proceedings of the Twelfth IEEE International Conference on Data Engineering},
  year         = {1996},
  pages        = {152--159},
  address      = {New Orleans, LA},
  month        = {2},
  publisher    = {IEEE}
}

@article{griffin1998algebraic,
author = {Griffin, Timothy and Kumar, Bharat},
title = {Algebraic change propagation for semijoin and outerjoin queries},
year = {1998},
issue_date = {Sept. 1, 1998},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {27},
number = {3},
issn = {0163-5808},
url = {https://doi.org/10.1145/290593.290597},
doi = {10.1145/290593.290597},
abstract = {Many interesting examples in view maintenance involve semijoin and outerjoin queries. In this paper we develop algebraic change propagation algorithms for the following operators: semijoin, anti-semijoin, left outerjoin, right outerjoin, and full outerjoin.},
journal = {SIGMOD Rec.},
month = {sep},
pages = {22–27},
numpages = {6}
}

@article{mv12,
url = {http://dx.doi.org/10.1561/1900000020},
year = {2012},
volume = {4},
journal = {Foundations and Trends® in Databases},
title = {Materialized Views},
doi = {10.1561/1900000020},
issn = {1931-7883},
number = {4},
pages = {295-405},
author = {Rada Chirkova and Jun Yang}
}

@misc{ibm2024indexsync,
  author = {{IBM}},
  title  = {Index synchronization concepts},
  year   = {2024},
  url    = {https://www.ibm.com/docs/en/configurepricequote/10.0?topic=considerations-index-synchronization-concepts},
  note   = {Accessed: 2024-09-11}
}

@misc{microsoft2024rebuildindex,
  author = {{Microsoft SQL Server}},
  title  = {Reorganize and rebuild indexes},
  year   = {2024},
  url    = {https://learn.microsoft.com/en-us/sql/relational-databases/indexes/reorganize-and-rebuild-indexes?view=sql-server-ver16},
  note   = {Accessed: 2024-09-11}
}

@article{qiao2022b,
  title={Revisiting B+-tree vs. LSM-tree: The Arrival of Modern Storage Hardware with Built-in Transparent Compression},
  author={Yifan Qiao and Xubin Chen and Ning Zheng and Jiangpeng Li and Yang Liu and Tong Zhang},
  journal={USENIX ;login: Online},
  year={2022},
  month={3},
  url={https://www.usenix.org/publications/loginonline/revisit-b-tree-vs-lsm-tree-upon-arrival-modern-storage-hardware-built},
}

@misc{oracle2024mvbasic,
  author = {{Oracle}},
  title  = {Basic Materialized Views},
  year   = {2024},
  url    = {https://docs.oracle.com/en/database/oracle/oracle-database/23/dwhsg/basic-materialized-views.html},
  note   = {Accessed: 2024-09-11}
}

@article{haerder1978access,
author = {Haerder, Theo},
title = {Implementing a generalized access path structure for a relational database system},
year = {1978},
issue_date = {Sept. 1978},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {3},
number = {3},
issn = {0362-5915},
url = {https://doi.org/10.1145/320263.320284},
doi = {10.1145/320263.320284},
abstract = {A new kind of implementation technique for access paths connecting sets of tuples qualified by attribute values is described. It combines the advantages of pointer chain and multilevel index implementation techniques. Compared to these structures the generalized access path structure is at least competitive in performing retrieval and update operations, while a considerable storage space saving is gained. Some additional features of this structure support m-way joins and the evaluation of multirelation queries, and allow efficient checks of integrity assertions and simple reorganization schemes.},
journal = {ACM Trans. Database Syst.},
month = sep,
pages = {285–298},
numpages = {14},
keywords = {B-trees, access path structures, database, index structures, relational model}
}

@Inbook{Domdouzis2021,
author="Domdouzis, Konstantinos
and Lake, Peter
and Crowther, Paul",
title="Hierarchical Databases",
bookTitle="Concise Guide to Databases: A Practical Introduction",
year="2021",
publisher="Springer International Publishing",
address="Cham",
pages="205--212",
abstract="What the reader will learn:",
isbn="978-3-030-42224-0",
doi="10.1007/978-3-030-42224-0_9",
url="https://doi.org/10.1007/978-3-030-42224-0_9"
}

@Inbook{Lake2013,
author="Lake, Peter
and Crowther, Paul",
title="A History of Databases",
bookTitle="Concise Guide to Databases: A Practical Introduction",
year="2013",
publisher="Springer London",
address="London",
pages="21--40",
abstract="In Chap. 1we discussed data as an organisational asset. We saw data, usually in the form of records has been with us since at least ancient Egyptian times. We also so that the big drivers of the need to keep detailed records were trade and taxation. Electronic computers provided an accurate and fast way of recording and calculating data. The first commercial computers appeared in the early 1950's and with these Data could now be processed much faster and with fewer errors compared with manual systems and a greater range of reports which were more up to date could be produced. Initially the processing required whole files to be processed---sequential processing but with advancing hardware technologies and falling prices direct access to data meant it was possible to update individual records without having to process an entire file. It also meant data needed to be structured to avoid duplication and make efficient use of electronic storage. Initially this was in the form of hierarchical and network structures. In 1970 Edgar Codd provided the theoretical framework which was developed into relational data structures. This became the basis of many of the systems which are in use today. Relational databases were designed to optimise disk usage and performance, but the very nature of a hard disk meant there were speed limitations. Now memory based systems which require different structuring to data are appearing. The evolution of database is continuing.",
isbn="978-1-4471-5601-7",
doi="10.1007/978-1-4471-5601-7_2",
url="https://doi.org/10.1007/978-1-4471-5601-7_2"
}

@misc{beam2024cogroupbykey,
  author = {{Apache Beam}},
  title  = {CoGroupByKey},
  year   = {2024},
  url    = {https://beam.apache.org/documentation/transforms/python/aggregation/cogroupbykey/},
  note   = {Accessed: 2024-09-30}
}

@article{LEE2010928,
title = {An efficient method for maintaining data cubes incrementally},
journal = {Information Sciences},
volume = {180},
number = {6},
pages = {928-948},
year = {2010},
note = {Special Issue on Modelling Uncertainty},
issn = {0020-0255},
doi = {https://doi.org/10.1016/j.ins.2009.11.037},
url = {https://www.sciencedirect.com/science/article/pii/S0020025509005076},
author = {Ki Yong Lee and Yon Dohn Chung and Myoung Ho Kim},
keywords = {Data cube, Materialized view, OLAP, Data warehouse},
abstract = {The data cube operator computes group-bys for all possible combinations of a set of dimension attributes. Since computing a data cube typically incurs a considerable cost, the data cube is often precomputed and stored as materialized views in data warehouses. A materialized data cube needs to be updated when the source relations are changed. The incremental maintenance of a data cube is to compute and propagate only its changes, rather than recompute the entire data cube from scratch. For n dimension attributes, the data cube consists of 2n group-bys, each of which is called a cuboid. To incrementally maintain a data cube with 2n cuboids, the conventional methods compute 2n delta cuboids, each of which represents the change of a cuboid. In this paper, we propose an efficient incremental maintenance method that can maintain a data cube using only a subset of 2n delta cuboids. We formulate an optimization problem to find the optimal subset of 2n delta cuboids that minimizes the total maintenance cost, and propose a heuristic solution that allows us to maintain a data cube using only n⌈n/2⌉ delta cuboids. As a result, the cost of maintaining a data cube is substantially reduced. Through various experiments, we show the performance advantages of the proposed method over the conventional methods. We also extend the proposed method to handle partially materialized cubes and dimension hierarchies.}
}

@inproceedings{Li2004median,
author = {Li, Cuiping and Cong, Gao and Tung, Anthony K. H. and Wang, Shan},
title = {Incremental maintenance of quotient cube for median},
year = {2004},
isbn = {1581138881},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1014052.1014079},
doi = {10.1145/1014052.1014079},
abstract = {Data cube pre-computation is an important concept for supporting OLAP(Online Analytical Processing) and has been studied extensively. It is often not feasible to compute a complete data cube due to the huge storage requirement. Recently proposed quotient cube addressed this issue through a partitioning method that groups cube cells into equivalence partitions. Such an approach is not only useful for distributive aggregate functions such as SUM but can also be applied to the holistic aggregate functions like MEDIAN.Maintaining a data cube for holistic aggregation is a hard problem since its difficulty lies in the fact that history tuple values must be kept in order to compute the new aggregate when tuples are inserted or deleted. The quotient cube makes the problem harder since we also need to maintain the equivalence classes. In this paper, we introduce two techniques called addset data structure and sliding window to deal with this problem. We develop efficient algorithms for maintaining a quotient cube with holistic aggregation functions that takes up reasonably small storage space. Performance study shows that our algorithms are effective, efficient and scalable over large databases.},
booktitle = {Proceedings of the Tenth ACM SIGKDD International Conference on Knowledge Discovery and Data Mining},
pages = {226–235},
numpages = {10},
keywords = {holistic aggregation, data cube},
location = {Seattle, WA, USA},
series = {KDD '04}
}

@INPROCEEDINGS{bei2019vertica,
  author={Bei, Yuanzhe and Pham, Thao and Aggarwal, Akshay and Tran, Nga and Dave, Jaimin and Bear, Chuck and Leuchtenburg, Michael},
  booktitle={2019 IEEE International Conference on Big Data (Big Data)}, 
  title={Vertica Flattened Tables and Live Aggregate Projections: A Column-based Alternative to Materialized Views for Analytics}, 
  year={2019},
  volume={},
  number={},
  pages={1749-1758},
  keywords={Computer architecture;Aggregates;Databases;Maintenance engineering;Data models;Standards;Big Data},
  doi={10.1109/BigData47090.2019.9006271}}


@article{oneil1995joinindex,
author = {O'Neil, Patrick and Graefe, Goetz},
title = {Multi-table joins through bitmapped join indices},
year = {1995},
issue_date = {Sept. 1995},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {24},
number = {3},
issn = {0163-5808},
url = {https://doi.org/10.1145/211990.212001},
doi = {10.1145/211990.212001},
abstract = {This technical note shows how to combine some well-known techniques to create a method that will efficiently execute common multi-table joins. We concentrate on a commonly occurring type of join known as a star-join, although the method presented will generalize to any type of multi-table join. A star-join consists of a central detail table with large cardinality, such as an orders table (where an order row contains a single purchase) with foreign keys that join to descriptive tables, such as customers, products, and (sales) agents. The method presented in this note uses join indices with compressed bitmap representations, which allow predicates restricting columns of descriptive tables to determine an answer set (or foundset) in the central detail table; the method uses different predicates on different descriptive tables in combination to restrict the detail table through compressed bitmap representations of join indices, and easily completes the join of the fully restricted detail table rows back to the descriptive tables. We outline realistic examples where the combination of these techniques yields substantial performance improvements over alternative, more traditional query evaluation plans.},
journal = {SIGMOD Rec.},
month = sep,
pages = {8–11},
numpages = {4}
}

@inproceedings{Idris2017DyanmicYanakakis,
author = {Idris, Muhammad and Ugarte, Martin and Vansummeren, Stijn},
title = {The Dynamic Yannakakis Algorithm: Compact and Efficient Query Processing Under Updates},
year = {2017},
isbn = {9781450341974},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3035918.3064027},
doi = {10.1145/3035918.3064027},
abstract = {Modern computing tasks such as real-time analytics require refresh of query results under high update rates. Incremental View Maintenance (IVM) approaches this problem by materializing results in order to avoid recomputation. IVM naturally induces a trade-off between the space needed to maintain the materialized results and the time used to process updates. In this paper, we show that the full materialization of results is a barrier for more general optimization strategies. In particular, we present a new approach for evaluating queries under updates. Instead of the materialization of results, we require a data structure that allows: (1) linear time maintenance under updates, (2) constant-delay enumeration of the output, (3) constant-time lookups in the output, while (4) using only linear space in the size of the database. We call such a structure a Dynamic Constant-delay Linear Representation (DCLR) for the query. We show that DYN, a dynamic version of the Yannakakis algorithm, yields DCLRs for the class of free-connex acyclic CQs. We show that this is optimal in the sense that no DCLR can exist for CQs that are not free-connex acyclic. Moreover, we identify a sub-class of queries for which DYN features constant-time update per tuple and show that this class is maximal. Finally, using the TPC-H and TPC-DS benchmarks, we experimentally compare DYN and a higher-order IVM (HIVM) engine. Our approach is not only more efficient in terms of memory consumption (as expected), but is also consistently faster in processing updates.},
booktitle = {Proceedings of the 2017 ACM International Conference on Management of Data},
pages = {1259–1274},
numpages = {16},
keywords = {acyclic joins, dynamic query processing, incremental view maintenance},
location = {Chicago, Illinois, USA},
series = {SIGMOD '17}
}

@inproceedings{dbtoaster,
  author    = {Yanif Ahmad and Oliver Kennedy and Christoph Koch and Milos Nikolic},
  title     = {DBToaster: Higher-order Delta Processing for Dynamic, Frequently Fresh Views},
  booktitle = {Proceedings of the VLDB Endowment},
  volume    = {5},
  number    = {10},
  year      = {2012},
  pages     = {968--979},
  publisher = {VLDB Endowment},
  address   = {Istanbul, Turkey},
  month     = {8},
  abstract  = {Applications ranging from algorithmic trading to scientific data analysis require realtime analytics based on views over databases that change at very high rates. Such views have to be kept fresh at low maintenance cost and latencies. At the same time, these views have to support classical SQL, rather than window semantics, to enable applications that combine current with aged or historical data. In this paper, we present viewlet transforms, a recursive finite differencing technique applied to queries. The viewlet transform materializes a query and a set of its higher-order deltas as views. These views support each other’s incremental maintenance, leading to a reduced overall view maintenance cost.},
  note      = {This work was supported by ERC Grant 279804. Articles from this volume were invited to present their results at The 38th International Conference on Very Large Data Bases, August 27th--31st 2012, Istanbul, Turkey.},
  doi       = {10.14778/2336664.2336670},
  url       = {https://doi.org/10.14778/2336664.2336670}
}

@article{IQP,
author = {Tang, Dixin and Shang, Zechao and Elmore, Aaron J. and Krishnan, Sanjay and Franklin, Michael J.},
title = {Intermittent query processing},
year = {2019},
issue_date = {July 2019},
publisher = {VLDB Endowment},
volume = {12},
number = {11},
issn = {2150-8097},
url = {https://doi.org/10.14778/3342263.3342278},
doi = {10.14778/3342263.3342278},
abstract = {Many applications ingest data in an intermittent, yet largely predictable, pattern. Existing systems tend to ignore how data arrives when making decisions about how to update (or refresh) an ongoing query. To address this shortcoming we propose a new query processing paradigm, Intermittent Query Processing (IQP), that bridges query execution and policies, to determine when to update results and how much resources to allocate for ensuring fast query updates. Here, for a query the system provides an initial result that is to be refreshed when policy dictates, such as after a defined number of new records arrive or a time interval elapses. In between intermittent data arrivals, IQP inactivates query execution by selectively releasing some resources occupied in normal execution that will be least helpful (for future refreshes) according to the arrival patterns for new records. We present an IQP prototype based on PostgreSQL that selectively persists the state associated with query operators to allow for fast query updates while constraining resource consumption. Our experiments show that for several application scenarios IQP greatly lowers query processing latency compared to batch systems, and largely reduces memory consumption with comparable latency compared to a state-of-the-art incremental view maintenance technique.},
journal = {Proc. VLDB Endow.},
month = jul,
pages = {1427–1441},
numpages = {15}
}

@inproceedings{Urhan2000XJoinAR,
  title={XJoin: A Reactively-Scheduled Pipelined Join Operator},
  author={Tolga Urhan and Michael J. Franklin},
  year={2000},
  url={https://api.semanticscholar.org/CorpusID:260705811}
}

@inproceedings{wilschut1991shj,
  author    = {A. N. Wilschut and P. M. G. Apers},
  title     = {Dataflow Query Execution in a Parallel Main-Memory Environment},
  booktitle = {Proceedings of the 1st International Conference on Parallel and Distributed Information Systems},
  address   = {Miami Beach, FL},
  year      = {1991}
}

@article{hong1993shj,
  author    = {W. Hong and M. Stonebraker},
  title     = {Optimization of Parallel Query Execution Plans in XPRS},
  journal   = {Distributed and Parallel Databases},
  volume    = {1},
  number    = {1},
  pages     = {9--32},
  year      = {1993}
}

@article{dbtoasterFK,
author = {Svingos, Christoforos and Hernich, Andre and Gildhoff, Hinnerk and Papakonstantinou, Yannis and Ioannidis, Yannis},
title = {Foreign Keys Open the Door for Faster Incremental View Maintenance},
year = {2023},
issue_date = {May 2023},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {1},
number = {1},
url = {https://doi.org/10.1145/3588720},
doi = {10.1145/3588720},
abstract = {Serverless cloud-based warehousing systems enable users to create materialized views in order to speed up predictable and repeated query workloads. Incremental view maintenance (IVM) minimizes the time needed to bring a materialized view up-to-date. It allows the refresh of a materialized view solely based on the base table changes since the last refresh. In serverless cloud-based warehouses, IVM uses computations defined as SQL scripts that update the materialized view based on updates to its base tables. However, the scripts set up for materialized views with inner joins are not optimal in the presence of foreign key constraints. For instance, for a join of two tables, the state of the art IVM computations use a UNION ALL operator of two joins - one computing the contributions to the join from updates to the first table and the other one computing the remaining contributions from the second table. Knowing that one of the join keys is a foreign-key would allow us to prune all but one of the UNION ALL branches and obtain a more efficient IVM script. In this work, we explore ways of incorporating knowledge about foreign key into IVM in order to speed up its performance. Experiments in Redshift showed that the proposed technique improved the execution times of the whole refresh process up to 2 times, and up to 2.7 times the process of calculating the necessary changes that will be applied into the materialized view.},
journal = {Proc. ACM Manag. Data},
month = may,
articleno = {40},
numpages = {25},
keywords = {foreign key constraints, incrementally updated materialized views, relational databases}
}

@article{wisckey,
author = {Lu, Lanyue and Pillai, Thanumalayan Sankaranarayana and Gopalakrishnan, Hariharan and Arpaci-Dusseau, Andrea C. and Arpaci-Dusseau, Remzi H.},
title = {WiscKey: Separating Keys from Values in SSD-Conscious Storage},
year = {2017},
issue_date = {February 2017},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {13},
number = {1},
issn = {1553-3077},
url = {https://doi.org/10.1145/3033273},
doi = {10.1145/3033273},
abstract = {We present WiscKey, a persistent LSM-tree-based key-value store with a performance-oriented data layout that separates keys from values to minimize I/O amplification. The design of WiscKey is highly SSD optimized, leveraging both the sequential and random performance characteristics of the device. We demonstrate the advantages of WiscKey with both microbenchmarks and YCSB workloads. Microbenchmark results show that WiscKey is 2.5 \texttimes{} to 111 \texttimes{} faster than LevelDB for loading a database (with significantly better tail latencies) and 1.6 \texttimes{} to 14 \texttimes{} faster for random lookups. WiscKey is faster than both LevelDB and RocksDB in all six YCSB workloads.},
journal = {ACM Trans. Storage},
month = mar,
articleno = {5},
numpages = {28},
keywords = {LevelDB, WiscKey, flash-based SSDs}
}

@inproceedings{lepers2019kvell,
  title={Kvell: the design and implementation of a fast persistent key-value store},
  author={Lepers, Baptiste and Balmau, Oana and Gupta, Karan and Zwaenepoel, Willy},
  booktitle={Proceedings of the 27th ACM Symposium on Operating Systems Principles},
  pages={447--461},
  year={2019}
}

@inproceedings{dayan2017monkey,
  title={Monkey: Optimal navigable key-value store},
  author={Dayan, Niv and Athanassoulis, Manos and Idreos, Stratos},
  booktitle={Proceedings of the 2017 ACM International Conference on Management of Data},
  pages={79--94},
  year={2017}
}

@INPROCEEDINGS{nljsurvey,
  author={Yamada, Hiroyuki and Goda, Kazuo and Kitsuregawa, Masaru},
  booktitle={2023 IEEE 39th International Conference on Data Engineering (ICDE)}, 
  title={Nested Loops Revisited Again}, 
  year={2023},
  volume={},
  number={},
  pages={3708-3717},
  keywords={Clustering algorithms;Parallel processing;Data engineering;Hardware;Robustness;Database systems;parallel query processing;join algorithms;parallel databases},
  doi={10.1109/ICDE55515.2023.00299}}

@INPROCEEDINGS{nljgpu,
  author={Nguyen, Anh and Edahiro, Masato and Kato, Shinpei},
  booktitle={2018 International Conference on High Performance Computing and Simulation (HPCS)}, 
  title={GPU-Accelerated VoltDB: A Case for Indexed Nested Loop Join}, 
  year={2018},
  volume={},
  number={},
  pages={204-212},
  keywords={Graphics processing units;Instruction sets;Vegetation;Indexes;Computer architecture;Acceleration},
  doi={10.1109/HPCS.2018.00046}}

@INPROCEEDINGS{DINER,
  author={Bornea, Mihaela A. and Vassalos, Vasilis and Kotidis, Yannis and Deligiannakis, Antonios},
  booktitle={2009 IEEE 25th International Conference on Data Engineering}, 
  title={Double Index NEsted-Loop Reactive Join for Result Rate Optimization}, 
  year={2009},
  volume={},
  number={},
  pages={481-492},
  keywords={Delay;Query processing;Data engineering;Pipeline processing;Smoothing methods;Switches;Computer science;Computer networks;Application software;Production},
  doi={10.1109/ICDE.2009.101}}

@article{smjparallel,
author = {Albutiu, Martina-Cezara and Kemper, Alfons and Neumann, Thomas},
title = {Massively parallel sort-merge joins in main memory multi-core database systems},
year = {2012},
issue_date = {June 2012},
publisher = {VLDB Endowment},
volume = {5},
number = {10},
issn = {2150-8097},
url = {https://doi.org/10.14778/2336664.2336678},
doi = {10.14778/2336664.2336678},
abstract = {Two emerging hardware trends will dominate the database system technology in the near future: increasing main memory capacities of several TB per server and massively parallel multi-core processing. Many algorithmic and control techniques in current database technology were devised for disk-based systems where I/O dominated the performance. In this work we take a new look at the well-known sort-merge join which, so far, has not been in the focus of research in scalable massively parallel multi-core data processing as it was deemed inferior to hash joins. We devise a suite of new massively parallel sort-merge (MPSM) join algorithms that are based on partial partition-based sorting. Contrary to classical sort-merge joins, our MPSM algorithms do not rely on a hard to parallelize final merge step to create one complete sort order. Rather they work on the independently created runs in parallel. This way our MPSM algorithms are NUMA-affine as all the sorting is carried out on local memory partitions. An extensive experimental evaluation on a modern 32-core machine with one TB of main memory proves the competitive performance of MPSM on large main memory databases with billions of objects. It scales (almost) linearly in the number of employed cores and clearly outperforms competing hash join proposals -- in particular it outperforms the "cutting-edge" Vectorwise parallel query engine by a factor of four.},
journal = {Proc. VLDB Endow.},
month = jun,
pages = {1064–1075},
numpages = {12}
}

@article{blasgen1977storage,
  author  = {M. W. Blasgen and K. P. Eswaran},
  title   = {Storage and access in relational databases},
  journal = {IBM Systems Journal},
  volume  = {16},
  number  = {4},
  pages   = {363--377},
  year    = {1977}
}

@inproceedings{dewitt1985multiprocessor,
  author    = {D. J. DeWitt and R. H. Gerber},
  title     = {Multiprocessor Hash-Based Join Algorithms},
  booktitle = {VLDB},
  pages     = {151--164},
  year      = {1985}
}

@inproceedings{dewitt1984main,
  author    = {David J. DeWitt and Randy H. Katz and Frank Olken and Leonard D. Shapiro and Michael R. Stonebraker and David A. Wood},
  title     = {Implementation Techniques for Main Memory Database Systems},
  booktitle = {SIGMOD},
  pages     = {1--8},
  year      = {1984}
}

@inproceedings{kim1980product,
  author    = {W. Kim},
  title     = {A New Way to Compute the Product and Join of Relations},
  booktitle = {SIGMOD},
  pages     = {179--187},
  year      = {1980}
}

@misc{microsoft2024modifyindex,
  author = {{Microsoft SQL Server}},
  title  = {Modify an index},
  year   = {2024},
  url    = {https://learn.microsoft.com/en-us/sql/relational-databases/indexes/modify-an-index?view=sql-server-ver16},
  note   = {Accessed: 2025-01-02}
}

@misc{oracle2024index,
  author = {{Oracle}},
  title  = {Managing Indexes},
  year   = 2024,
  url    = {https://docs.oracle.com/cd/E11882_01/server.112/e25494/indexes.htm#ADMIN016},
  note   = {Accessed: 2025-01-02}
}

@article{Google-Spanner,
  author       = {James C. Corbett and
                  Jeffrey Dean and
                  Michael Epstein and
                  Andrew Fikes and
                  Christopher Frost and
                  J. J. Furman and
                  Sanjay Ghemawat and
                  Andrey Gubarev and
                  Christopher Heiser and
                  Peter Hochschild and
                  Wilson C. Hsieh and
                  Sebastian Kanthak and
                  Eugene Kogan and
                  Hongyi Li and
                  Alexander Lloyd and
                  Sergey Melnik and
                  David Mwaura and
                  David Nagle and
                  Sean Quinlan and
                  Rajesh Rao and
                  Lindsay Rolig and
                  Yasushi Saito and
                  Michal Szymaniak and
                  Christopher Taylor and
                  Ruth Wang and
                  Dale Woodford},
  title        = {Spanner: Google's Globally Distributed Database},
  journal      = {{ACM} Trans. Comput. Syst.},
  volume       = {31},
  number       = {3},
  pages        = {8},
  year         = {2013}
}

@misc{oracle-table-cluster,
  author = {{Oracle}},
  title  = {Table Clusters},
  year   = {2024},
  url    = {https://docs.oracle.com/database/121/CNCPT/tablecls.htm#CNCPT010},
  note   = {Accessed: 2025-01-02}
}

@INPROCEEDINGS {Dossinger2021streamjoin,
author = { Dossinger, Manuel and Michel, Sebastian },
booktitle = { 2021 IEEE 37th International Conference on Data Engineering (ICDE) },
title = {{ Optimizing Multiple Multi-Way Stream Joins }},
year = {2021},
volume = {},
ISSN = {},
pages = {1985-1990},
abstract = { We address the joint optimization of multiple stream joins in a scale-out architecture by tailoring prior work on multi-way stream joins to predicate-driven data partitioning schemes. We present an integer linear programming (ILP) formulation for selecting the partitioning and tuple routing with minimal probe load. The presented algorithms and optimization schemes are implemented in CLASH, a data stream processor developed in our group that translates queries to deployable Apache Storm topologies after optimization. The experiments conducted on TPC-H data exhibit the potential of multi-query optimization of multi-way stream joins and the effectiveness and feasibility of the ILP optimization problem. },
keywords = {Storms;Conferences;Integer linear programming;Routing;Data engineering;Topology;Partitioning algorithms},
doi = {10.1109/ICDE51399.2021.00188},
url = {https://doi.ieeecomputersociety.org/10.1109/ICDE51399.2021.00188},
publisher = {IEEE Computer Society},
address = {Los Alamitos, CA, USA},
month =apr}

@inproceedings{Dittrich2002PMJ,
author = {Dittrich, Jens-Peter and Seeger, Bernhard and Taylor, David Scot and Widmayer, Peter},
title = {Progressive merge join: a generic and non-blocking sort-based join algorithm},
year = {2002},
publisher = {VLDB Endowment},
abstract = {Many state-of-the-art join-techniques require the input relations to be almost fully sorted before the actual join processing starts. Thus, these techniques start producing first results only after a considerable time period has passed. This blocking behaviour is a serious problem when consequent operators have to stop processing, in order to wait for first results of the join. Furthermore, this behaviour is not acceptable if the result of the join is visualized or/ and requires user interaction. These are typical scenarios for data mining applications. The, off-time' of existing techniques even increases with growing problem sizes.In this paper, we propose a generic technique called Progressive Merge Join (PMJ) that eliminates the blocking behaviour of sort-based join algorithms. The basic idea behind PMJ is to have the join produce results, as early as the external mergesort generates initial runs. Hence, it is possible for PMJ to return first results very early. This paper provides the basic algorithms and the generic framework of PMJ, as well as use-cases for different types of joins. Moreover, we provide a generic online selectivity estimator with probabilistic quality guarantees. For similarity joins in particular, first non-blocking join algorithms are derived from applying PMJ to the state-of-the-art techniques.We have implemented PMJ as part of an object-relational cursor algebra. A set of experiments shows that a substantial amount of results are produced, even before the input relationas would have been sorted. We observed only a moderate increase in the total runtime compared to the blocking counterparts.},
booktitle = {Proceedings of the 28th International Conference on Very Large Data Bases},
pages = {299–310},
numpages = {12},
location = {Hong Kong, China},
series = {VLDB '02}
}

@INPROCEEDINGS{Cuzzocrea2022streamjoinsurvey,
  author={Cuzzocrea, Alfredo},
  booktitle={2022 IEEE International Conference on Data Mining Workshops (ICDMW)}, 
  title={Scalable Joins over Big Data Streams: Actual and Future Research Trends}, 
  year={2022},
  volume={},
  number={},
  pages={1016-1019},
  keywords={Smart cities;Databases;Medical services;Big Data;Market research;Distance measurement;Data mining},
  doi={10.1109/ICDMW58026.2022.00132}}


@inproceedings{Chen2010prjoin,
author = {Chen, Shimin and Gibbons, Phillip B. and Nath, Suman},
title = {PR-join: a non-blocking join achieving higher early result rate with statistical guarantees},
year = {2010},
isbn = {9781450300322},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1807167.1807186},
doi = {10.1145/1807167.1807186},
abstract = {Online aggregation is a promising solution to achieving fast early responses for interactive ad-hoc queries that compute aggregates on a large amount of data. Essential to the success of online aggregation is a good non-blocking join algorithm that enables both (i) high early result rates with statistical guarantees and (ii) fast end-to-end query times. We analyze existing non-blocking join algorithms and find that they all provide sub-optimal early result rates, and those with fast end-to-end times achieve them only by further sacrificing their early result rates.We propose a new non-blocking join algorithm, Partitioned expanding Ripple Join (PR-Join), which achieves considerably higher early result rates than previous non-blocking joins, while also delivering fast end-to-end query times. PR-Join performs separate, ripple-like join operations on individual hash partitions, where the width of a ripple expands multiplicatively over time. This contrasts with the non-partitioned, fixed-width ripples of Block Ripple Join. Assuming, as in previous non-blocking join studies, that the input relations are in random order, PR-Join ensures representative early results that are amenable to statistical guarantees. We show both analytically and with real-machine experiments that PR-Join achieves over an order of magnitude higher early result rates than previous non-blocking joins. We also discuss the benefits of using a flash-based SSD for temporary storage, showing that PR-Join can then achieve close to optimal end-to-end performance. Finally, we consider the joining of finite data streams that arrive over time, and find that PR-Join achieves similar or higher result rates than RPJ, the state-of-the-art algorithm specialized for that domain.},
booktitle = {Proceedings of the 2010 ACM SIGMOD International Conference on Management of Data},
pages = {147–158},
numpages = {12},
keywords = {statistical guarantee, pr-join, online aggregation, non-blocking join, finite data stream, fast early result, data warehouse},
location = {Indianapolis, Indiana, USA},
series = {SIGMOD '10}
}

@inproceedings{mokbel2004hash,
  title={Hash-merge join: A non-blocking join algorithm for producing fast and early join results},
  author={Mokbel, Mohamed F and Lu, Ming and Aref, Walid G},
  booktitle={Proceedings. 20th International Conference on Data Engineering},
  pages={251--262},
  year={2004},
  organization={IEEE}
}

@article{10.1145/304181.304208,
author = {Haas, Peter J. and Hellerstein, Joseph M.},
title = {Ripple joins for online aggregation},
year = {1999},
issue_date = {June 1999},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {28},
number = {2},
issn = {0163-5808},
url = {https://doi.org/10.1145/304181.304208},
doi = {10.1145/304181.304208},
abstract = {We present a new family of join algorithms, called ripple joins, for online processing of multi-table aggregation queries in a relational database management system (DBMS). Such queries arise naturally in interactive exploratory decision-support applications.Traditional offline join algorithms are designed to minimize the time to completion of the query. In contrast, ripple joins are designed to minimize the time until an acceptably precise estimate of the query result is available, as measured by the length of a confidence interval. Ripple joins are adaptive, adjusting their behavior during processing in accordance with the statistical properties of the data. Ripple joins also permit the user to dynamically trade off the two key performance factors of on-line aggregation: the time between successive updates of the running aggregate, and the amount by which the confidence-interval length decreases at each update. We show how ripple joins can be implemented in an existing DBMS using iterators, and we give an overview of the methods used to compute confidence intervals and to adaptively optimize the ripple join “aspect-ratio” parameters. In experiments with an initial implementation of our algorithms in the POSTGRES DBMS, the time required to produce reasonably precise online estimates was up to two orders of magnitude smaller than the time required for the best offline join algorithms to produce exact answers.},
journal = {SIGMOD Rec.},
month = jun,
pages = {287–298},
numpages = {12}
}

@inproceedings{Haas1999RippleJoins,
author = {Haas, Peter J. and Hellerstein, Joseph M.},
title = {Ripple joins for online aggregation},
year = {1999},
isbn = {1581130848},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/304182.304208},
doi = {10.1145/304182.304208},
abstract = {We present a new family of join algorithms, called ripple joins, for online processing of multi-table aggregation queries in a relational database management system (DBMS). Such queries arise naturally in interactive exploratory decision-support applications.Traditional offline join algorithms are designed to minimize the time to completion of the query. In contrast, ripple joins are designed to minimize the time until an acceptably precise estimate of the query result is available, as measured by the length of a confidence interval. Ripple joins are adaptive, adjusting their behavior during processing in accordance with the statistical properties of the data. Ripple joins also permit the user to dynamically trade off the two key performance factors of on-line aggregation: the time between successive updates of the running aggregate, and the amount by which the confidence-interval length decreases at each update. We show how ripple joins can be implemented in an existing DBMS using iterators, and we give an overview of the methods used to compute confidence intervals and to adaptively optimize the ripple join “aspect-ratio” parameters. In experiments with an initial implementation of our algorithms in the POSTGRES DBMS, the time required to produce reasonably precise online estimates was up to two orders of magnitude smaller than the time required for the best offline join algorithms to produce exact answers.},
booktitle = {Proceedings of the 1999 ACM SIGMOD International Conference on Management of Data},
pages = {287–298},
numpages = {12},
location = {Philadelphia, Pennsylvania, USA},
series = {SIGMOD '99}
}

@inproceedings{Luo2002hashripple,
author = {Luo, Gang and Ellmann, Curt J. and Haas, Peter J. and Naughton, Jeffrey F.},
title = {A scalable hash ripple join algorithm},
year = {2002},
isbn = {1581134975},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/564691.564721},
doi = {10.1145/564691.564721},
abstract = {Recently, Haas and Hellerstein proposed the hash ripple join algorithm in the context of online aggregation. Although the algorithm rapidly gives a good estimate for many join-aggregate problem instances, the convergence can be slow if the number of tuples that satisfy the join predicate is small or if there are many groups in the output. Furthermore, if memory overflows (for example, because the user allows the algorithm to run to completion for an exact answer), the algorithm degenerates to block ripple join and performance suffers. In this paper, we build on the work of Haas and Hellerstein and propose a new algorithm that (a) combines parallelism with sampling to speed convergence, and (b) maintains good performance in the presence of memory overflow. Results from a prototype implementation in a parallel DBMS show that its rate of convergence scales with the number of processors, and that when allowed to run to completion, even in the presence of memory overflow, it is competitive with the traditional parallel hybrid hash join algorithm.},
booktitle = {Proceedings of the 2002 ACM SIGMOD International Conference on Management of Data},
pages = {252–262},
numpages = {11},
location = {Madison, Wisconsin},
series = {SIGMOD '02}
}

@article{factorizedDB,
author = {Olteanu, Dan and Schleich, Maximilian},
title = {Factorized Databases},
year = {2016},
issue_date = {June 2016},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {45},
number = {2},
issn = {0163-5808},
url = {https://doi.org/10.1145/3003665.3003667},
doi = {10.1145/3003665.3003667},
abstract = {This paper overviews factorized databases and their application to machine learning. The key observation underlying this work is that state-of-the-art relational query processing entails a high degree of redundancy in the computation and representation of query results. This redundancy can be avoided and is not necessary for subsequent analytics such as learning regression models.},
journal = {SIGMOD Rec.},
month = sep,
pages = {5–16},
numpages = {12}
}

@inproceedings{f-ivm,
author = {Nikolic, Milos and Olteanu, Dan},
title = {Incremental View Maintenance with Triple Lock Factorization Benefits},
year = {2018},
isbn = {9781450347037},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3183713.3183758},
doi = {10.1145/3183713.3183758},
abstract = {We introduce F-IVM, a unified incremental view maintenance (IVM) approach for a variety of tasks, including gradient computation for learning linear regression models over joins, matrix chain multiplication, and factorized evaluation of conjunctive queries.F-IVM is a higher-order IVM algorithm that reduces the maintenance of the given task to the maintenance of a hierarchy of increasingly simpler views. The views are functions mapping keys, which are tuples of input data values, to payloads, which are elements from a task-specific ring. Whereas the computation over the keys is the same for all tasks, the computation over the payloads depends on the task. F-IVM achieves efficiency by factorizing the computation of the keys, payloads, and updates. We implemented F-IVM as an extension of DBToaster. We show in a range of scenarios that it can outperform classical first-order IVM, DBToaster's fully recursive higher-order IVM, and plain recomputation by orders of magnitude while using less memory.},
booktitle = {Proceedings of the 2018 International Conference on Management of Data},
pages = {365–380},
numpages = {16},
keywords = {stream processing, rings, query optimization, materialized views, incremental view maintenance, factorized representation},
location = {Houston, TX, USA},
series = {SIGMOD '18}
}

@inproceedings{Berkholz2017conjunctive,
author = {Berkholz, Christoph and Keppeler, Jens and Schweikardt, Nicole},
title = {Answering Conjunctive Queries under Updates},
year = {2017},
isbn = {9781450341981},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3034786.3034789},
doi = {10.1145/3034786.3034789},
abstract = {We consider the task of enumerating and counting answers to k-ary conjunctive queries against relational databases that may be updated by inserting or deleting tuples. We exhibit a new notion of q-hierarchical conjunctive queries and show that these can be maintained efficiently in the following sense. During a linear time pre-processing phase, we can build a data structure that enables constant delay enumeration of the query results; and when the database is updated, we can update the data structure and restart the enumeration phase within constant time. For the special case of self-join free conjunctive queries we obtain a dichotomy: if a query is not q-hierarchical, then query enumeration with sublinear *) delay and sublinear update time (and arbitrary preprocessing time) is impossible.For answering Boolean conjunctive queries and for the more general problem of counting the number of solutions of k-ary queries we obtain complete dichotomies: if the query's homomorphic core is q-hierarchical, then size of the the query result can be computed in linear time and maintained with constant update time. Otherwise, the size of the query result cannot be maintained with sublinear update time.All our lower bounds rely on the OMv-conjecture, a conjecture on the hardness of online matrix-vector multiplication that has recently emerged in the field of fine-grained complexity to characterise the hardness of dynamic problems. The lower bound for the counting problem additionally relies on the orthogonal vectors conjecture, which in turn is implied by the strong exponential time hypothesis.*) By sublinear we mean O(n(1-ε) for some ε > 0, where n is the size of the active domain of the current database.},
booktitle = {Proceedings of the 36th ACM SIGMOD-SIGACT-SIGAI Symposium on Principles of Database Systems},
pages = {303–318},
numpages = {16},
keywords = {constant delay enumeration, counting complexity, dichotomy, dynamic algorithms, online matrix-vector multiplication, query evaluation},
location = {Chicago, Illinois, USA},
series = {PODS '17}
}

@inproceedings{mcsherry2013differentialdataflow,
  title={Differential dataflow},
  author={McSherry, Frank and Isard, Michael and Murray, Derek G},
  booktitle={Proceedings of the 6th Biennial Conference on Innovative Data Systems Research (CIDR)},
  year={2013},
  pages={1--11},
  publisher={CIDR}
}

% https://www.postgresql.org/docs/current/indexes-intro.html
@misc{postgres2024index,
  author = {{PostgreSQL}},
  title  = {Indexes},
  year   = 2024,
  url    = {https://www.postgresql.org/docs/current/indexes-intro.html},
  note   = {Accessed: 2025-01-02}
}

@inproceedings{DatabaseCracking,
  author       = {Stratos Idreos and
                  Martin L. Kersten and
                  Stefan Manegold},
  title        = {Database Cracking},
  booktitle    = {Third Biennial Conference on Innovative Data Systems Research, {CIDR}
                  2007, Asilomar, CA, USA, January 7-10, 2007, Online Proceedings},
  pages        = {68--78},
  publisher    = {www.cidrdb.org},
  year         = {2007},
  url          = {http://cidrdb.org/cidr2007/papers/cidr07p07.pdf},
  timestamp    = {Mon, 18 Jul 2022 17:13:00 +0200},
  biburl       = {https://dblp.org/rec/conf/cidr/IdreosKM07.bib},
  bibsource    = {dblp computer science bibliography, https://dblp.org}
}

@article{valduriez87joinindex,
author = {Valduriez, Patrick},
title = {Join indices},
year = {1987},
issue_date = {June 1987},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {12},
number = {2},
issn = {0362-5915},
url = {https://doi.org/10.1145/22952.22955},
doi = {10.1145/22952.22955},
abstract = {In new application areas of relational database systems, such as artificial intelligence, the join operator is used more extensively than in conventional applications. In this paper, we propose a simple data structure, called a join index, for improving the performance of joins in the context of complex queries. For most of the joins, updates to join indices incur very little overhead. Some properties of a join index are (i) its efficient use of memory and adaptiveness to parallel execution, (ii) its compatibility with other operations (including select and union), (iii) its support for abstract data type join predicates, (iv) its support for multirelation clustering, and (v) its use in representing directed graphs and in evaluating recursive queries. Finally, the analysis of the join algorithm using join indices shows its excellent performance.},
journal = {ACM Trans. Database Syst.},
month = jun,
pages = {218–246},
numpages = {29}
}

@inproceedings{lawrence2005early,
  title={Early hash join: A configurable algorithm for the efficient and early production of join results},
  author={Lawrence, Ramon},
  booktitle={Proceedings of the 31st international conference on Very large data bases},
  pages={841--852},
  year={2005}
}

%https://cloud.google.com/compute/docs/disks

@inproceedings{gclouddisk,
  author = {Google Cloud},
  title = {Disks},
  year = {2024},
  url = {https://cloud.google.com/compute/docs/disks},
  note = {Accessed: 2025-01-02}
}