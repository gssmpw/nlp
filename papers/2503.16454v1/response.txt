\section{Related Work}
\subsection{Brain emotional learning}
	The emotional circuits in the brain have long been a central focus of neurophysiological research, as understanding the mechanisms behind emotions is crucial for motivations related to human-machine interaction and artificial intelligence in the context of hybrid intelligence**Morén et al., "A Brain Emotional Learning Model"**. Similarly, simulating the functions of emotional pathways in the human brain is a prominent area of study in the fields of artificial intelligence (AI) and affective computing, where researchers aim to replicate or model the emotional responses and behaviors of the brain. 
	
	In this context, Morén et al. proposed a BEL model, which was inspired by the organizational structure of the limbic system in the mammalian brain. The BEL model emphasizes the interaction between key brain regions involved in emotional processing, such as the amygdala and the orbitofrontal cortex. It simulates the transmission and processing of emotional stimuli through the reflex pathways of the brain, offering insights into how emotional information is processed and reacted to by the neural circuits of the brain**Lotfi et al., "Supervised Brain Emotion Learning"**. Building upon this foundational work, Lotfi et al. further developed a supervised version of the Brain Emotion Learning model. This enhanced model is capable of learning from target pattern examples, and has been experimentally compared with several alternative approaches, including Multi-Layer Perceptron (MLP) and Adaptive Neuro-Fuzzy Inference Systems (ANFIS). The distinctive feature of the supervised BEL model lies in its ability to achieve rapid training for predictive problems, making it highly effective for real-time applications in emotional learning and decision-making**Wang et al., "Biomimetic Memory Circuit"**. In a further extension of the BEL framework, Wang et al. proposed a biomimetic memory circuit with both emotion learning and generation capabilities. This circuit is designed to conduct neuromorphic emotion learning and generation, enabling the processing of various input types to simulate emotional responses. Their model advances the state of emotional circuit simulation by incorporating memory elements, which are essential for emulating the ability of the brain to recall and modify emotional states based on past experiences**Wang et al., "Biomimetic Memory Circuit"**. Sun et al.                                                                                                                                                                                                                                                                                                                      introduced a biomimetic circuit that simulates a three-dimensional emotional space model. This circuit generates brain-like emotional responses based on multimodal input, including visual, speech, and text information. This model represents a significant step forward in the development of emotion-sensing and emotion-generating systems for bionic robots, providing a potential framework for achieving emotional companionship between humans and machines**Sun et al., "3D Emotional Space Model"**. 
	
	While the BEL model has made notable progress in the domains of intelligent control, classification prediction, and the development of emotional circuits, the simulation and utilization of the emotional circuitry of the brain have encountered certain bottlenecks in recent years. With ongoing advancements in neuroscience and neuroengineering, it has become increasingly important to refine and enhance the biomimetic simulation of emotional circuits to improve their functionality, accuracy, and adaptability. The proposed AVF-BEL model represents an advancement over the original BEL framework, not only improving the biomimetic capabilities of emotional circuitry but also offering significant benefits in terms of design efficiency, lightweight operation, and interpretability. This development paves the way for more complex models capable of processing complex emotional stimuli in a manner more akin to the brain, potentially addressing some of the current limitations. It is hoped that, in the future, more effective emotion simulations can be realized in artificial intelligence systems and robotic applications.
	
	\subsection{Emotion generation technology}
    Emotion generation techniques utilize multimodal data, such as images, text, and music, to enable computers to simulate or generate emotional responses. This multidisciplinary approach leverages diverse sources of input to capture the complexity of emotional states and enhance the emotional intelligence of computational systems. 
    
    Zhou et al. introduced an innovative model called the Emotional Chat Machine (ECM), which not only responds appropriately in terms of content relevance and grammatical structure but also effectively manages the emotional aspects of dialogue, ensuring emotional consistency throughout interactions**Zhou et al., "Emotional Chat Machine"**. Building on this work, Wang et al. proposed a novel deep generative model designed to synthesize facial videos based on neutral facial images and specific facial expression labels, such as spontaneous smiles. The model is composed of two main components: an image generator and a frame sequence generator. The image generator is realized through a deep neural network that combines Generative Adversarial Networks (GANs) with Variational Autoencoders (VAEs), while the sequence generator is a label-conditioned recursive neural network. This approach allows for the generation of dynamic facial expressions that are temporally consistent**Wang et al., "Facial Video Synthesis"**. In another advancement, Chen et al. proposed a memory-based emotion generation circuit, which is capable of storing emotional memories, retrieving them as needed, and deploying them to generate consistent personality traits. This circuit is designed to address the challenges of low power consumption, area efficiency, and memory processing, making it suitable for integration into resource-constrained systems, such as mobile robots or embedded devices**Chen et al., "Memory-Based Emotion Generation"**. Further contributing to the field, Zhang et al. introduced a brain-inspired emotion generation system based on the Pleasure-Arousal-Dominance (PAD) model, a three-dimensional emotional space that simulates the neural circuits involved in emotion generation within the limbic system**Zhang et al., "Pleasure-Arousal-Dominance Model"**. 
    
    Advancements in emotion generation technologies have made significant progress in areas such as text-based dialogue systems, emotion generation circuits, and facial expression synthesis. These breakthroughs rely heavily on sophisticated deep learning techniques, extensive emotional datasets, and optimized hardware components. However, despite these advancements, widespread deployment and application of emotion generation technologies remain challenging due to the substantial investments required in both software and hardware infrastructure. As such, there are significant barriers to achieving scalable and cost-effective solutions. In contrast to many of these resource-intensive approaches, our AVF-BEL model emphasizes a lightweight design and high interpretability, while also achieving excellent performance in neuroanatomical alignment and result similarity. These features are particularly valuable for large-scale applications in areas such as robot emotion generation and artificial intelligence emotion synthesis. By optimizing for efficiency and ease of interpretation, the AVF-BEL model offers a promising avenue for overcoming the challenges associated with resource-intensive emotion generation systems, potentially enabling more widespread adoption and practical implementation in real-world applications.