\section{Conclusion}
To address the challenge of fine-grained and efficient retrieval in STEM teaching scenarios, we proposed a multi-style and multi-modal STEM education retrieval task and curated a multi-style dataset of over 24,000 samples for model fine-tuning.
To balance training efficiency and retrieval performance, we developed a lightweight and plug-and-play feature expression module, Prompt Bank, and built a database-driven accurate retrieval model, Uni-Retrieval, based on Prompt Bank.
Compared to current state-of-the-art retrieval models, Uni-Retrieval significantly improves retrieval performance with only a 26M (less than 5\%) increase in parameter size and less than 10ms additional retrieval time. Furthermore, the training and deployment costs of Uni-Retrieval are substantially lower than those of existing large retrieval models, making it a more economical and practical solution for educational scenarios.
We hope Uni-Retrieval can inspire new possibilities for the community, offering an effective and accessible approach to retrieval in STEM education and beyond.

\section*{Limitation}
However, our work still has some limitations that require further research. Firstly, STEM education differs significantly from higher education, K-12 education, humanities education, and other scenarios in terms of data and usage requirements. A key challenge for future research is how to maintain efficient retrieval performance while adapting to a wider range of educational scenarios.
Additionally, we plan to exploring how to efficiently acquire various professional educational knowledge based on VLMs. These improvements aim to make Uni-Retrieval more versatile and impactful across diverse educational domains.
