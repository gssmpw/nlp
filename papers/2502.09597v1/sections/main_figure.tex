\begin{figure}[t]
    \centering
    \includegraphics[width=0.99\linewidth]{figs/prefbench.pdf}
\caption{\ours{} setup overview. Key components from left to right: 1) \textbf{Multi-Session Conversation Setup}: \ours{} evaluates LLMs' ability to follow user preferences in multi-session conversation, challenging LLMs to handle preference inference, long-range retrieval, and context-aware preference following simultaneously. 2) \textbf{Preferences and Queries}: User preferences can be expressed through both explicit and implicit forms. Queries are designed such that a non-personalized answer would inadvertently conflict with user preferences, testing the LLM's adherence. 3) \textbf{Tasks and Evaluations}: \ours{} includes generation and classification tasks. Generation tasks are evaluated using an LLM-based evaluator to measure preference following accuracy and analyze error types. Classification tasks enable quicker evaluation through multiple-choice questions (MCQ). The two tasks' performances are highly correlated as shown in Fig~\ref{fig:mcq_correlation}.}
    \label{fig:main_fig}
\end{figure}