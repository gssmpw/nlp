@book{james2013introduction,
  title={An introduction to statistical learning},
  author={James, Gareth and Witten, Daniela and Hastie, Trevor and Tibshirani, Robert and others},
  volume={112},
  year={2013},
  publisher={Springer}
}


@article{song2023ensemble,
  title={Ensemble reinforcement learning: A survey},
  author={Song, Yanjie and Suganthan, Ponnuthurai Nagaratnam and Pedrycz, Witold and Ou, Junwei and He, Yongming and Chen, Yingwu and Wu, Yutong},
  journal={Applied Soft Computing},
  pages={110975},
  year={2023},
  publisher={Elsevier}
}

@article{krogh1994neural,
  title={Neural network ensembles, cross validation, and active learning},
  author={Krogh, Anders and Vedelsby, Jesper},
  journal={Advances in neural information processing systems},
  volume={7},
  year={1994}
}

@inproceedings{dietterich2000ensemble,
  title={Ensemble methods in machine learning},
  author={Dietterich, Thomas G},
  booktitle={International workshop on multiple classifier systems},
  pages={1--15},
  year={2000},
  organization={Springer}
}

@article{brown2005diversity,
  title={Diversity creation methods: a survey and categorisation},
  author={Brown, Gavin and Wyatt, Jeremy and Harris, Rachel and Yao, Xin},
  journal={Information fusion},
  volume={6},
  number={1},
  pages={5--20},
  year={2005},
  publisher={Elsevier}
}


@article{jiang2023llm,
  title={Llm-blender: Ensembling large language models with pairwise ranking and generative fusion},
  author={Jiang, Dongfu and Ren, Xiang and Lin, Bill Yuchen},
  journal={arXiv preprint arXiv:2306.02561},
  year={2023}
}

@inproceedings{tekin-etal-2024-llm,
    title = "{LLM}-{TOPLA}: Efficient {LLM} Ensemble by Maximising Diversity",
    author = "Tekin, Selim Furkan  and
      Ilhan, Fatih  and
      Huang, Tiansheng  and
      Hu, Sihao  and
      Liu, Ling",
    editor = "Al-Onaizan, Yaser  and
      Bansal, Mohit  and
      Chen, Yun-Nung",
    booktitle = "Findings of the Association for Computational Linguistics: EMNLP 2024",
    month = nov,
    year = "2024",
    address = "Miami, Florida, USA",
    publisher = "Association for Computational Linguistics",
    url = "https://aclanthology.org/2024.findings-emnlp.698/",
    doi = "10.18653/v1/2024.findings-emnlp.698",
    pages = "11951--11966"
}

@article{chen2023frugalgpt,
  title={Frugalgpt: How to use large language models while reducing cost and improving performance},
  author={Chen, Lingjiao and Zaharia, Matei and Zou, James},
  journal={arXiv preprint arXiv:2305.05176},
  year={2023}
}


@article{wan2024knowledge,
  title={Knowledge fusion of large language models},
  author={Wan, Fanqi and Huang, Xinting and Cai, Deng and Quan, Xiaojun and Bi, Wei and Shi, Shuming},
  journal={arXiv preprint arXiv:2401.10491},
  year={2024}
}

@article{ong2024routellm,
  title={Routellm: Learning to route llms with preference data},
  author={Ong, Isaac and Almahairi, Amjad and Wu, Vincent and Chiang, Wei-Lin and Wu, Tianhao and Gonzalez, Joseph E and Kadous, M Waleed and Stoica, Ion},
  journal={arXiv preprint arXiv:2406.18665},
  year={2024}
}

@article{zhao2024eagle,
  title={Eagle: Efficient training-free router for multi-llm inference},
  author={Zhao, Zesen and Jin, Shuowei and Mao, Z Morley},
  journal={arXiv preprint arXiv:2409.15518},
  year={2024}
}


@article{schulman2017proximal,
  title={Proximal policy optimization algorithms},
  author={Schulman, John and Wolski, Filip and Dhariwal, Prafulla and Radford, Alec and Klimov, Oleg},
  journal={arXiv preprint arXiv:1707.06347},
  year={2017}
}


@article{sutton1999policy,
  title={Policy gradient methods for reinforcement learning with function approximation},
  author={Sutton, Richard S and McAllester, David and Singh, Satinder and Mansour, Yishay},
  journal={Advances in neural information processing systems},
  volume={12},
  year={1999}
}


@inproceedings{tavakoli2018action,
  title={Action branching architectures for deep reinforcement learning},
  author={Tavakoli, Arash and Pardo, Fabio and Kormushev, Petar},
  booktitle={Proceedings of the aaai conference on artificial intelligence},
  volume={32},
  number={1},
  year={2018}
}



@article{tekin2024h,
  title={$ H3$ Fusion: Helpful, Harmless, Honest Fusion of Aligned LLMs},
  author={Tekin, Selim Furkan and Ilhan, Fatih and Huang, Tiansheng and Hu, Sihao and Yahn, Zachary and Liu, Ling},
  journal={arXiv preprint arXiv:2411.17792},
  year={2024}
}

@inproceedings{wu2021boosting,
  title={Boosting ensemble accuracy by revisiting ensemble diversity metrics},
  author={Wu, Yanzhao and Liu, Ling and Xie, Zhongwei and Chow, Ka-Ho and Wei, Wenqi},
  booktitle={Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition},
  pages={16469--16477},
  year={2021}
}



@article{fleiss,
author = {Joseph L. Fleiss and Jacob Cohen},
title ={The Equivalence of Weighted Kappa and the Intraclass Correlation Coefficient as Measures of Reliability},
journal = {Educational and Psychological Measurement},
volume = {33},
number = {3},
pages = {613-619},
year = {1973},
doi = {10.1177/001316447303300309},
URL = {    
        https://doi.org/10.1177/001316447303300309

},
eprint = { 
        https://doi.org/10.1177/001316447303300309

}
}


@inproceedings{liu2024dynamic,
  title={A dynamic LLM-powered agent network for task-oriented agent collaboration},
  author={Liu, Zijun and Zhang, Yanzhe and Li, Peng and Liu, Yang and Yang, Diyi},
  booktitle={First Conference on Language Modeling},
  year={2024}
}

@article{li2024more,
  title={More agents is all you need},
  author={Li, Junyou and Zhang, Qin and Yu, Yangbin and Fu, Qiang and Ye, Deheng},
  journal={arXiv preprint arXiv:2402.05120},
  year={2024}
}

@misc{open-llm-leaderboard,
  author = {Edward Beeching and Cl√©mentine Fourrier and Nathan Habib and Sheon Han and Nathan Lambert and Nazneen Rajani and Omar Sanseviero and Lewis Tunstall and Thomas Wolf},
  title = {Open LLM Leaderboard},
  year = {2023},
  publisher = {Hugging Face},
  howpublished = "\url{https://huggingface.co/spaces/HuggingFaceH4/open_llm_leaderboard}"
}

@article{suzgun2022challenging,
  title={Challenging BIG-Bench Tasks and Whether Chain-of-Thought Can Solve Them},
  author={Suzgun, Mirac and Scales, Nathan and Sch{\"a}rli, Nathanael and Gehrmann, Sebastian and Tay, Yi and Chung, Hyung Won and Chowdhery, Aakanksha and Le, Quoc V and Chi, Ed H and Zhou, Denny and and Wei, Jason},
  journal={arXiv preprint arXiv:2210.09261},
  year={2022}
}

@article{cobbe2021training,
  title={Training verifiers to solve math word problems},
  author={Cobbe, Karl and Kosaraju, Vineet and Bavarian, Mohammad and Chen, Mark and Jun, Heewoo and Kaiser, Lukasz and Plappert, Matthias and Tworek, Jerry and Hilton, Jacob and Nakano, Reiichiro and others},
  journal={arXiv preprint arXiv:2110.14168},
  year={2021}
}

@article{rein2023gpqa,
  title={Gpqa: A graduate-level google-proof q\&a benchmark},
  author={Rein, David and Hou, Betty Li and Stickland, Asa Cooper and Petty, Jackson and Pang, Richard Yuanzhe and Dirani, Julien and Michael, Julian and Bowman, Samuel R},
  journal={arXiv preprint arXiv:2311.12022},
  year={2023}
}

@article{sprague2023musr,
  title={Musr: Testing the limits of chain-of-thought with multistep soft reasoning},
  author={Sprague, Zayne and Ye, Xi and Bostrom, Kaj and Chaudhuri, Swarat and Durrett, Greg},
  journal={arXiv preprint arXiv:2310.16049},
  year={2023}
}

@article{hendrycks2020measuring,
  title={Measuring massive multitask language understanding},
  author={Hendrycks, Dan and Burns, Collin and Basart, Steven and Zou, Andy and Mazeika, Mantas and Song, Dawn and Steinhardt, Jacob},
  journal={arXiv preprint arXiv:2009.03300},
  year={2020}
}




@article{ji2024beavertails,
  title={Beavertails: Towards improved safety alignment of llm via a human-preference dataset},
  author={Ji, Jiaming and Liu, Mickel and Dai, Josef and Pan, Xuehai and Zhang, Chi and Bian, Ce and Chen, Boyuan and Sun, Ruiyang and Wang, Yizhou and Yang, Yaodong},
  journal={Advances in Neural Information Processing Systems},
  volume={36},
  year={2024}
}

@misc{alpaca_clean,
  author = {Rohan Taori and Ishaan Gulrajani and Tianyi Zhang and Yann Dubois and Xuechen Li and Carlos Guestrin and Percy Liang and Tatsunori B. Hashimoto },
  title = {Stanford Alpaca: An Instruction-following LLaMA model},
  year = {2023},
  publisher = {GitHub},
  journal = {GitHub repository},
  howpublished = {\url{https://github.com/tatsu-lab/stanford_alpaca}},
}

@article{lin2021truthfulqa,
  title={Truthfulqa: Measuring how models mimic human falsehoods},
  author={Lin, Stephanie and Hilton, Jacob and Evans, Owain},
  journal={arXiv preprint arXiv:2109.07958},
  year={2021}
}


@article{achiam2023gpt,
  title={Gpt-4 technical report},
  author={Achiam, Josh and Adler, Steven and Agarwal, Sandhini and Ahmad, Lama and Akkaya, Ilge and Aleman, Florencia Leoni and Almeida, Diogo and Altenschmidt, Janko and Altman, Sam and Anadkat, Shyamal and others},
  journal={arXiv preprint arXiv:2303.08774},
  year={2023}
}

@article{brown2020language,
  title={Language models are few-shot learners},
  author={Brown, Tom B},
  journal={arXiv preprint arXiv:2005.14165},
  year={2020}
}

@article{jiang2024mixtral,
  title={Mixtral of experts},
  author={Jiang, Albert Q and Sablayrolles, Alexandre and Roux, Antoine and Mensch, Arthur and Savary, Blanche and Bamford, Chris and Chaplot, Devendra Singh and Casas, Diego de las and Hanna, Emma Bou and Bressand, Florian and others},
  journal={arXiv preprint arXiv:2401.04088},
  year={2024}
}

@article{touvron2023llama,
  title={Llama 2: Open foundation and fine-tuned chat models},
  author={Touvron, Hugo and Martin, Louis and Stone, Kevin and Albert, Peter and Almahairi, Amjad and Babaei, Yasmine and Bashlykov, Nikolay and Batra, Soumya and Bhargava, Prajjwal and Bhosale, Shruti and others},
  journal={arXiv preprint arXiv:2307.09288},
  year={2023}
}

@article{team2024gemma,
  title={Gemma: Open models based on gemini research and technology},
  author={Team, Gemma and Mesnard, Thomas and Hardin, Cassidy and Dadashi, Robert and Bhupatiraju, Surya and Pathak, Shreya and Sifre, Laurent and Rivi{\`e}re, Morgane and Kale, Mihir Sanjay and Love, Juliette and others},
  journal={arXiv preprint arXiv:2403.08295},
  year={2024}
}

@article{kaplan2020scaling,
  title={Scaling laws for neural language models},
  author={Kaplan, Jared and McCandlish, Sam and Henighan, Tom and Brown, Tom B and Chess, Benjamin and Child, Rewon and Gray, Scott and Radford, Alec and Wu, Jeffrey and Amodei, Dario},
  journal={arXiv preprint arXiv:2001.08361},
  year={2020}
}

@article{wang2022self,
  title={Self-instruct: Aligning language models with self-generated instructions},
  author={Wang, Yizhong and Kordi, Yeganeh and Mishra, Swaroop and Liu, Alisa and Smith, Noah A and Khashabi, Daniel and Hajishirzi, Hannaneh},
  journal={arXiv preprint arXiv:2212.10560},
  year={2022}
}



@inproceedings{fu2022complexity,
  title={Complexity-based prompting for multi-step reasoning},
  author={Fu, Yao and Peng, Hao and Sabharwal, Ashish and Clark, Peter and Khot, Tushar},
  booktitle={The Eleventh International Conference on Learning Representations},
  year={2022}
}

@article{li2022advance,
  title={On the advance of making language models better reasoners},
  author={Li, Yifei and Lin, Zeqi and Zhang, Shizhuo and Fu, Qiang and Chen, Bei and Lou, Jian-Guang and Chen, Weizhu},
  journal={arXiv preprint arXiv:2206.02336},
  year={2022}
}


@article{wang2022rationale,
  title={Rationale-augmented ensembles in language models},
  author={Wang, Xuezhi and Wei, Jason and Schuurmans, Dale and Le, Quoc and Chi, Ed and Zhou, Denny},
  journal={arXiv preprint arXiv:2207.00747},
  year={2022}
}


@article{liang2023encouraging,
  title={Encouraging divergent thinking in large language models through multi-agent debate},
  author={Liang, Tian and He, Zhiwei and Jiao, Wenxiang and Wang, Xing and Wang, Yan and Wang, Rui and Yang, Yujiu and Shi, Shuming and Tu, Zhaopeng},
  journal={arXiv preprint arXiv:2305.19118},
  year={2023}
}

@article{du2023improving,
  title={Improving factuality and reasoning in language models through multiagent debate},
  author={Du, Yilun and Li, Shuang and Torralba, Antonio and Tenenbaum, Joshua B and Mordatch, Igor},
  journal={arXiv preprint arXiv:2305.14325},
  year={2023}
}


@article{chan2023chateval,
  title={Chateval: Towards better llm-based evaluators through multi-agent debate},
  author={Chan, Chi-Min and Chen, Weize and Su, Yusheng and Yu, Jianxuan and Xue, Wei and Zhang, Shanghang and Fu, Jie and Liu, Zhiyuan},
  journal={arXiv preprint arXiv:2308.07201},
  year={2023}
}

@article{wang2023fusing,
  title={Fusing models with complementary expertise},
  author={Wang, Hongyi and Polo, Felipe Maia and Sun, Yuekai and Kundu, Souvik and Xing, Eric and Yurochkin, Mikhail},
  journal={arXiv preprint arXiv:2310.01542},
  year={2023}
}

@article{yao2024tree,
  title={Tree of thoughts: Deliberate problem solving with large language models},
  author={Yao, Shunyu and Yu, Dian and Zhao, Jeffrey and Shafran, Izhak and Griffiths, Tom and Cao, Yuan and Narasimhan, Karthik},
  journal={Advances in Neural Information Processing Systems},
  volume={36},
  year={2024}
}


@inproceedings{nemeth2022split,
  title={Split feature space ensemble method using deep reinforcement learning for algorithmic trading},
  author={N{\'e}meth, Marcell and Sz{\H{u}}cs, G{\'a}bor},
  booktitle={Proceedings of the 2022 8th International Conference on Computer Technology Applications},
  pages={188--194},
  year={2022}
}


@article{liu2020new,
  title={A new hybrid ensemble deep reinforcement learning model for wind speed short term forecasting},
  author={Liu, Hui and Yu, Chengqing and Wu, Haiping and Duan, Zhu and Yan, Guangxi},
  journal={Energy},
  volume={202},
  pages={117794},
  year={2020},
  publisher={Elsevier}
}

@article{perepu2020reinforcement,
  title={Reinforcement learning based dynamic weighing of ensemble models for time series forecasting},
  author={Perepu, Satheesh K and Balaji, Bala Shyamala and Tanneru, Hemanth Kumar and Kathari, Sudhakar and Pinnamaraju, Vivek Shankar},
  journal={arXiv preprint arXiv:2008.08878},
  year={2020}
}

@article{chua2018deep,
  title={Deep reinforcement learning in a handful of trials using probabilistic dynamics models},
  author={Chua, Kurtland and Calandra, Roberto and McAllister, Rowan and Levine, Sergey},
  journal={Advances in neural information processing systems},
  volume={31},
  year={2018}
}

@article{partalas2009pruning,
  title={Pruning an ensemble of classifiers via reinforcement learning},
  author={Partalas, Ioannis and Tsoumakas, Grigorios and Vlahavas, Ioannis},
  journal={Neurocomputing},
  volume={72},
  number={7-9},
  pages={1900--1909},
  year={2009},
  publisher={Elsevier}
}


@inproceedings{liu2020instance,
  title={Instance-based ensemble selection using deep reinforcement learning},
  author={Liu, Zhengshang and Ramamohanarao, Kotagiri},
  booktitle={2020 International Joint Conference on Neural Networks (IJCNN)},
  pages={1--7},
  year={2020},
  organization={IEEE}
}

@article{ouyang2022training,
  title={Training language models to follow instructions with human feedback},
  author={Ouyang, Long and Wu, Jeffrey and Jiang, Xu and Almeida, Diogo and Wainwright, Carroll and Mishkin, Pamela and Zhang, Chong and Agarwal, Sandhini and Slama, Katarina and Ray, Alex and others},
  journal={Advances in neural information processing systems},
  volume={35},
  pages={27730--27744},
  year={2022}
}

@article{liu2024rl,
  title={RL-GPT: Integrating Reinforcement Learning and Code-as-policy},
  author={Liu, Shaoteng and Yuan, Haoqi and Hu, Minda and Li, Yanwei and Chen, Yukang and Liu, Shu and Lu, Zongqing and Jia, Jiaya},
  journal={arXiv preprint arXiv:2402.19299},
  year={2024}
}


@article{monea2024llms,
  title={Llms are in-context reinforcement learners},
  author={Monea, Giovanni and Bosselut, Antoine and Brantley, Kiant{\'e} and Artzi, Yoav},
  year={2024}
}

@article{zhang2021multi,
  title={Multi-agent reinforcement learning: A selective overview of theories and algorithms},
  author={Zhang, Kaiqing and Yang, Zhuoran and Ba{\c{s}}ar, Tamer},
  journal={Handbook of reinforcement learning and control},
  pages={321--384},
  year={2021},
  publisher={Springer}
}

@article{sun2024llm,
  title={LLM-based Multi-Agent Reinforcement Learning: Current and Future Directions},
  author={Sun, Chuanneng and Huang, Songjun and Pompili, Dario},
  journal={arXiv preprint arXiv:2405.11106},
  year={2024}
}
