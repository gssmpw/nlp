 %%%%%%%% ICML 2025 EXAMPLE LATEX SUBMISSION FILE %%%%%%%%%%%%%%%%%

\documentclass{article}

% Recommended, but optional, packages for figures and better typesetting:
\usepackage{microtype}
\usepackage{graphicx}
\usepackage{subfigure}
\usepackage{booktabs} % for professional tables
\usepackage{enumitem}
\usepackage{multirow}
% hyperref makes hyperlinks in the resulting PDF.
% If your build breaks (sometimes temporarily if a hyperlink spans a page)
% please comment out the following usepackage line and replace
% \usepackage{icml2025} with \usepackage[nohyperref]{icml2025} above.
\usepackage{hyperref}


% Attempt to make hyperref and algorithmic work together better:
\newcommand{\theHalgorithm}{\arabic{algorithm}}

% Use the following line for the initial blind version submitted for review:
%\usepackage{icml2025}

% If accepted, instead use the following line for the camera-ready submission:
\usepackage[accepted]{icml2025}

% For theorems and such
\usepackage{amsmath}
\DeclareMathOperator*{\argmin}{arg\,min}
\usepackage{amssymb}
\usepackage{mathtools}
\usepackage{amsthm}
\usepackage{mathrsfs}
\usepackage{bm}

% if you use cleveref..
\usepackage[capitalize,noabbrev]{cleveref}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% THEOREMS
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\theoremstyle{plain}
\newtheorem{theorem}{Theorem}[section]
\newtheorem{proposition}[theorem]{Proposition}
\newtheorem{lemma}[theorem]{Lemma}
\newtheorem{corollary}[theorem]{Corollary}
\theoremstyle{definition}
\newtheorem{definition}[theorem]{Definition}
\newtheorem{assumption}[theorem]{Assumption}
\theoremstyle{remark}
\newtheorem{remark}[theorem]{Remark}

% Todonotes is useful during development; simply uncomment the next line
%    and comment out the line below the next line to turn off comments
%\usepackage[disable,textsize=tiny]{todonotes}
\usepackage[textsize=tiny]{todonotes}


% The \icmltitle you define below is probably too long as a header.
% Therefore, a short form for the running title is supplied here:
\icmltitlerunning{Under Review}

\begin{document}

\twocolumn[
\icmltitle{End-to-End Learning Framework for Solving \\ Non-Markovian Optimal Control}

% It is OKAY to include author information, even for blind
% submissions: the style file will automatically remove it for you
% unless you've provided the [accepted] option to the icml2025
% package.

% List of affiliations: The first argument should be a (short)
% identifier you will use later to specify author affiliations
% Academic affiliations should list Department, University, City, Region, Country
% Industry affiliations should list Company, City, Region, Country

% You can specify symbols, otherwise they are numbered in order.
% Ideally, you should not use this facility. Affiliations will be numbered
% in order of appearance and this is the preferred way.
\icmlsetsymbol{equal}{*}

\begin{icmlauthorlist}
\icmlauthor{Xiaole Zhang}{usc}
\icmlauthor{Peiyu Zhang}{usc}
\icmlauthor{Xiongye Xiao}{usc}
\icmlauthor{Shixuan Li}{usc}
\\ \icmlauthor{Vasileios Tzoumas}{umich}
\icmlauthor{Vijay Gupta}{purdue}
\icmlauthor{Paul Bogdan}{usc}
%\icmlauthor{}{sch}
%\icmlauthor{Firstname8 Lastname8}{sch}
%\icmlauthor{Firstname8 Lastname8}{yyy,comp}
%\icmlauthor{}{sch}
%\icmlauthor{}{sch}
\end{icmlauthorlist}

\icmlaffiliation{usc}{Ming Hsieh Department of Electrical and Computer Engineering, University of Southern California,  Los Angeles, CA 90089, USA}
\icmlaffiliation{umich}{Department of Aerospace Engineering, University of Michigan, Ann Arbor, MI 48109, USA}
\icmlaffiliation{purdue}{Elmore Family School of Electrical and Computer Engineering, Purdue University, West Lafayette, IN 47907, USA}

\icmlcorrespondingauthor{Xiaole Zhang}{xiaolezh@usc.edu}
\icmlcorrespondingauthor{Paul Bogdan}{pbogdan@usc.edu}

% You may provide any keywords that you
% find helpful for describing your paper; these are used to populate
% the "keywords" metadata in the PDF but will not be shown in the document
\icmlkeywords{Machine Learning, ICML}
\vskip 0.3in
]

% this must go after the closing bracket ] following \twocolumn[ ...

% This command actually creates the footnote in the first column
% listing the affiliations and the copyright notice.
% The command takes one argument, which is text to display at the start of the footnote.
% The \icmlEqualContribution command is standard text for equal contribution.
% Remove it (just {}) if you do not need this facility.

\printAffiliationsAndNotice{}  % leave blank if no need to mention equal contribution
%\printAffiliationsAndNotice{\icmlEqualContribution} % otherwise use the standard text.

\begin{abstract}
Integer-order calculus often falls short in capturing the long-range dependencies and memory effects found in many real-world processes. Fractional calculus addresses these gaps via fractional-order integrals and derivatives, but fractional-order dynamical systems pose substantial challenges in system identification and optimal control due to the lack of standard control methodologies. In this paper, we theoretically derive the optimal control via \textit{linear quadratic regulator} (LQR) for \textit{fractional-order linear time-invariant }(FOLTI) systems and develop an end-to-end deep learning framework based on this theoretical foundation. Our approach establishes a rigorous mathematical model, derives analytical solutions, and incorporates deep learning to achieve data-driven optimal control of FOLTI systems. Our key contributions include: (i) proposing an innovative system identification method control strategy for FOLTI systems, (ii) developing the first end-to-end data-driven learning framework, \textbf{F}ractional-\textbf{O}rder \textbf{L}earning for \textbf{O}ptimal \textbf{C}ontrol (FOLOC), that learns control policies from observed trajectories, and (iii) deriving a theoretical analysis of sample complexity to quantify the number of samples required for accurate optimal control in complex real-world problems. Experimental results indicate that our method accurately approximates fractional-order system behaviors without relying on Gaussian noise assumptions, pointing to promising avenues for advanced optimal control. 

%The source code is available at https://anonymous.4open.science/r/Fractional-Order-Learning-for-Control-Framework-69A0.

%Integer-order calculus often falls short in capturing the long-range dependencies and memory effects found in many real-world processes. Fractional calculus addresses these gaps via fractional-order integrals and derivatives, but fractional-order dynamical systems (FoDS) pose substantial challenges in identification and control. This paper introduces a novel approach for fractional-order linear time-invariant (LTI) systems. We propose a system identification method using multiple trajectories, and derive two optimal control solutions based on the linear quadratic regulator (LQR). We derive the sample complexity of the end to end learning process, with the theoretical bound \(\mathcal{O}(\frac{1}{\sqrt{N}})\) validated through experiments. We propose the first end to end machine learning framework for functioning approximately optimal control sequences for unknown fractional-order linear time-invariant systems using a single trajectory. This approach is able to handle scenarios with unknown or non-Gaussian noise distributions without requiring Gaussian noise assumptions. Experimental results further demonstrate that fractional-order linear time-invariant systems can accurately approximate nonlinear Markovian systems using real-world data. These contributions highlight the effectiveness of the end to end FoDS based machine learning framework in addressing complex system identification and control problems.

\end{abstract}

\section{Introduction}
\label{submission}
Many real-world systems, including biological networks, financial markets, and control systems, exhibit long-range dependencies and memory effects that traditional integer-order models struggle to capture \cite{lundstrom2008fractional, ivanov1999multifractality, ghorbani2018gene}. Fractional-order linear time-invariant (FOLTI) systems extend classical integer-order models through fractional calculus, providing a more flexible framework for modeling such complex behaviors. Due to their ability to represent non-local dependencies and history-dependent dynamics, FOLTI systems have found broad applications in control systems, bioengineering, neuroscience, physical, and financial modeling. However, the practical deployment of FOLTI systems faces significant challenges in system identification and optimal control. Unlike Markovian systems, where the current state depends solely on the immediate past state, FOLTI systems exhibit non-Markovian properties, meaning their evolution is influenced by a broad range of past states. This memory effect introduces additional complexities, making it difficult for traditional methods to generalize effectively to FOLTI systems.

Despite their advantages, FOLTI systems present significant challenges in both modeling and control. Identifying system parameters for fractional-order dynamical systems remains an open research problem. One major difficulty in system identification arises from the non-Markovian nature of fractional-order systems, where the state evolution is not solely determined by recent states but depends on an entire history of past observations. Additionally, the fractional derivative operators, such as the Grünwald–Letnikov fractional derivative \cite{hilfer2000applications, monje2010fractional, oldham1974fractional}, introduce combinatorial complexity and nonlinearities, making standard parameter estimation techniques ineffective. Existing methods often rely on strong assumptions, such as noiseless data or constrained data generation processes, limiting their applicability in practical scenarios. 

Beyond system identification, optimal control of FOLTI systems remains a major challenge. Unlike integer-order systems, where well-established control frameworks exist, fractional-order systems exhibit long-range dependencies and memory effects, making classical control strategies difficult to apply directly. In particular, the lack of analytical solutions for optimal control in FOLTI systems necessitates new approaches that account for their unique dynamics. Addressing these challenges is crucial for enabling real-world applications of FOLTI systems in control systems. 

A well-established framework for optimal control in integer-order systems is the Linear Quadratic Regulator (LQR), introduced by Rudolf Kalman in 1960 \cite{kalman1960contributions}. LQR aims to determine an optimal control policy that minimizes a quadratic cost function defined over the system state and control input, subject to weighing matrices, for systems governed by linear dynamics. The traditional integer-order LQR problem has been extensively studied over the decades \cite{dean2018regretboundsrobustadaptive, dean2020sample, pmlr-v99-tu19a}. For linear time-invariant (LTI) systems with known parameters, the LQR problem has a closed-form solution on the infinite time horizon and can be solved efficiently using dynamic programming on finite horizons \cite{anderson2007optimal}. Furthermore, numerous researchers have developed end-to-end guarantees for LQR in the context of LTI systems. These guarantees often involve a two-step process: (I) estimating the unknown system parameters, and (ii) designing robust controllers to account for model uncertainties. 




While the LQR problem for integer-order LTI systems is well understood (see related work in Appendix \ref{relatedwork}), far less attention has been devoted to the case of fractional-order dynamical systems \cite{monje2010fractional}. These systems, which originate from fractional calculus \cite{hilfer2000applications, ionescu2017role}, differ significantly from their integer-order counterparts. Unlike Markovian systems, where the current state depends solely on the immediate past state, fractional-order systems exhibit a non-Markovian behavior, with the current state influenced by a memory effect spanning a broad range of past states. This memory effect makes the analysis and control of fractional-order dynamical systems particularly challenging. Estimation of unknown parameters in fractional-order dynamical systems remains an open problem \cite{yaghooti2023inferring, chatterjee2022learning, zhang2025samplingcomplexityawareframeworkdiscretetime}, even under the assumption of linear fractional operators. For finite horizons, optimal control problems have been addressed under specific assumptions \cite{li2008fractional}, but no comprehensive results exist for infinite horizons. Moreover, achieving end-to-end guarantees for fractional-order systems is particularly challenging, as both system identification \cite{yaghooti2023inferring, zhang2025samplingcomplexityawareframeworkdiscretetime} and robust control present significant technical difficulties.



To address these challenges, this work establishes a theoretical framework for fractional-order LQR, deriving a principled end-to-end learning approach for FOLTI optimal control. Specifically, we formulate the mathematical structure of FOLTI systems, enabling a rigorous extension of LQR to the fractional-order setting. Given the diagonal elements of the system matrix, we propose a method to estimate the unknown system parameters from multiple observed trajectories. Using this estimated model, we derive the optimal control policy using LQR, leveraging least squares optimization and Lagrange multipliers to obtain analytically tractable solutions despite the inherent complexities introduced by fractional-order dynamics.

Beyond theoretical derivations, we develop an end-to-end data-driven learning framework, fractional-order learning for optimal control (FOLOC), that jointly performs system identification and optimal control. Unlike classical control methods that require pre-specified system dynamics, our approach learns both the system parameters and control policies directly from observed trajectories. We further analyze the sample complexity of this learning process, quantifying the number of samples required for the estimated LQR loss to converge to the true LQR loss under unknown input conditions. Unlike classical approaches that assume structured noise distributions, our framework is designed to operate in realistic, noisy environments. Specifically, we incorporate deep learning-based modeling techniques to ensure that the control policy remains robust under non-Gaussian noise, distributional shifts, and real-world uncertainties.

In summary, this work makes the following key contributions: (i) We provide theoretical foundations for optimal control of fractional-order linear time-invariant (FOLTI) systems. (ii) We develop a principled end-to-end data-driven learning framework, FOLOC, that jointly optimizes system identification loss and control policies, ensuring robustness to non-Gaussian noise and real-world uncertainties.  (iii) We analyze the theoretical sample complexity, providing convergence guarantees for learned control policies under unknown system dynamics. (iv) We conduct extensive experiments, demonstrating the FOLOC’s robustness across noise distributions, scalability to different system complexities, and computational efficiency in real-time control tasks.

\section{Preliminaries and Problem Formulation}
In this section, we introduce key theoretical foundations from fractional calculus, focusing on the Grünwald–Letnikov fractional-order derivative and its role in modeling FOLTI systems. By extending LQR to FOLTI systems, we then formulate the end-to-end learning problem, where the objective is to identify system parameters and optimize control policies directly from data. This formulation integrates system identification and control optimization, addressing challenges arising from memory effects and non-Markovian dynamics in FOLTI systems.

%In this section, we first introduce key theoretical foundations from fractional calculus and then formulate the end-to-end learning problem for FOLTI systems.

\subsection{Fractional-Order Derivative}

\begin{definition}[Grünwald–Letnikov fractional-order derivative]
\label{def:gl_derivative}
The left-side and right-side Grünwald–Letnikov fractional-order derivatives of order \( \alpha \) on the finite interval \( I = [a, b] \) are defined as follows:
\begin{equation}
    \left( ^{GL}D_{a+}^\alpha f \right)(x) 
    = \lim_{h \to 0^+} \frac{1}{h^\alpha} \sum_{k=0}^{\left\lfloor \frac{x-a}{h} \right\rfloor} (-1)^k \binom{\alpha}{k} f(x-kh), \\
\end{equation}
\begin{equation}
    \left( ^{GL}D_{b-}^\alpha f \right)(x) 
    = \lim_{h \to 0^-} \frac{1}{h^\alpha} \sum_{k=0}^{\left\lfloor \frac{b-x}{h} \right\rfloor} (-1)^k \binom{\alpha}{k} f(x+kh),
\end{equation}
where \( x \in \mathbb{R} \), \( 0 < h < b -a\), and \( \alpha > 0 \). Here, \( \binom{\alpha}{k} \) denotes the generalized binomial coefficient, defined as
\(
\binom{\alpha}{k} = \frac{\Gamma(\alpha+1)}{\Gamma(k+1) \Gamma(\alpha-k+1)},
\) where \( \Gamma(\cdot) \) denotes the gamma function, which is defined as \( \Gamma(z) = \int_0^\infty t^{z-1} e^{-t} \, dt \) for \( z > 0 \).
\end{definition}

\subsection{Grünwald–Letnikov Difference Operator}
The fractional-order Grünwald–Letnikov difference operator allows to discretize the fractional-order derivative and represent it as a finite difference as follows:
\begin{equation}
\Delta^\alpha x_k := \sum_{j=0}^{k} D(\alpha, j) x_{k-j}, \label{3}
\end{equation}
where \( x_k \in \mathbb{R}^n \), \( \alpha = [\alpha_1, \alpha_2, \ldots, \alpha_n]^\top \in \mathbb{R}^n \) represents the order of the difference operator, and \( D(\alpha, j) \in \mathbb{R}^{n \times n} \) is an \( n \times n \) diagonal matrix defined as
\begin{equation}
D(\alpha, j) \coloneqq \operatorname{diag} \big( \psi(\alpha_1, j), \psi(\alpha_2, j), \dots, \psi(\alpha_n, j) \big),
\end{equation}
with
\begin{equation}
\psi(\alpha_i, j) := \frac{\Gamma(j - \alpha_i)}{\Gamma(-\alpha_i) \Gamma(j + 1)}, \quad i = 1, 2, \ldots, n.
\end{equation}

\subsection{Fractional-Order Linear Time Invariant System}
The state-space representation of the discrete-time fractional-order linear time invariant system reads:
\begin{equation}
\Delta^\alpha x_{k+1} = A x_k + B u_k, \label{con:A^B param}
\end{equation}
where \(x_k \in \mathbb{R}^n \) is the state vector, \( u_k \in \mathbb{R}^m \) is the system input, matrices \(A\) and \(B\) are constant matrices with size \(n \times n\) and \(n \times m\), respectively.

Using the Grünwald–Letnikov difference operator, we can write the system as follows:
\begin{equation}
x_{k+1} = A x_k + B u_k - \sum_{j=1}^{k+1} D(\alpha, j) x_{k+1-j}.
\label{eq7}
\end{equation}
The last term in Eq.~\ref{eq7} represents the memory-dependent nature of fractional-order dynamical systems, making them suitable for modeling non-Markovian and long-range dependent processes.

\subsection{Linear Quadratic Regulator for FOLTI systems}
The linear quadratic regulator (LQR) problem is that of optimal control of a dynamical system given known and fixed quadratic costs. Formally, the goal of LQR is to find the optimal control \(u_t\) that minimizes the quadratic loss fitting in the FOLTI systems, which in turn solves the following optimization problem. 
\begin{definition}[LQR for FOLTI systems]
\label{def:LQR}
The LQR problem for FOLTI systems is defined as follows:
\begin{align}
    \min_{\{u_i\}_{i=0}^{T-1}} \; &J_T(u):= \sum_{k=0}^{T-1} \left( x_k^\top Q x_k + u_k^\top R u_k \right) + x_T^\top Q_f x_T \\
    \text{s. t.} \;  &\Delta^\alpha x_{k+1} = A x_k + B u_k,
\end{align}
\noindent where \( Q \in \mathbb{R}^{n \times n} \) and \( Q_f \in \mathbb{R}^{n \times n} \) are positive semi-definite matrices representing the state cost and terminal state cost, respectively, where \( n \) is the dimension of the state vector \( x_k \). Similarly, \( R \in \mathbb{R}^{m \times m} \) is a positive semi-definite matrix representing the control cost, where \( m \) is the dimension of the control input vector \( u_k \).
\end{definition}


\subsection{Problem Formulation}
Consider a fractional-order linear time-invariant system defined using the Grünwald–Letnikov difference operator. The goal is to find an optimal control sequence via solving LQR problem based on system identification from observed data. 

Specifically, we are given \(N\) trajectories, each trajectory consisting of \(T\) time steps, sampled from a joint distribution \(\Pi\) over initial states, process noise, system parameters and cost matrices, i.e., 
\(
\{x_0, \{w_k\}_{k = 0}^{T-1}, \{u_k\}_{k = 0}^{T-1}, \{A,B,\alpha\}, \{Q, R\}  \} \sim \Pi.
\) 
Thus, we can represent the  dataset as
\(
\mathcal{D} = \{\{x_k^i\}_{k=0}^{T}, \{u_k^i\}_{k = 0}^{T-1}, Q^i, R^i, \{{u_k^i}^o(x_0^i, A, B, \alpha)\}_{k=0}^{T-1}\}_{i=1}^N\), where \({u_k^i}^o\) denotes the optimal control input. 
We aim to solve the following two-step problem:

\textbf{(i) System Identification.}
The fractional-order system dynamics are parameterized by \(\Theta := \{A, B, \alpha\}\), where \(A \in \mathbb{R}^{n \times n}\) and \(B \in \mathbb{R}^{n \times m}\) are system matrices, and \(\alpha \in (0, 1)^n\) is the fractional order. The system identification problem is posed as:
\begin{equation}
\hat{\Theta} = \argmin_{\Theta} \sum_{i=1}^N \sum_{k=1}^T \left\| \hat{x}_k^i(\Theta) - x_k^i \right\|_2^2,
\end{equation}
where \(\hat{x}_k^i(\Theta)\) represents the predicted state at time \(k\) for the \(i\)-th trajectory, obtained using the identified parameters \(\Theta\).

\textbf{(ii) Optimal Control.}
Once \(\hat{\Theta} = \{\hat{A}, \hat{B}, \hat{\alpha}\}\) is estimated, the optimal control problem is formulated as:
\begin{equation}
\min_{\{u_k\}_{k=0}^{T-1}} \; \hat{J}_T(u) := \sum_{k=0}^{T-1} \left( x_k^\top Q x_k + u_k^\top R u_k \right) + x_T^\top Q_f x_T,
\end{equation}
subject to the identified system dynamics:
\begin{equation}
\Delta^{\hat{\alpha}} x_{k+1} = \hat{A} x_k + \hat{B} u_k.
\end{equation}


\textbf{Deep Learning-Based Reformulation.}
The optimal control problem can be framed in a deep learning context as learning an operator \(\mathcal{L} : \mathcal{D} \to \mathcal{U}\), where \(\mathcal{U}\) represents the set of optimal control inputs. Formally, the operator \(\mathcal{L} : \mathcal{D} \to \mathcal{U}\) computes the optimal control policy \(\{u_t^o\}_{t=0}^{T-1}\) directly from the observed trajectory, while simultaneously uncovering the system parameters \(\Theta = \{A, B, \alpha\}\) that encapsulate the dynamics of the fractional-order system.   

\section{Methodology}
\subsection{Mathematical Foundations for Fractional-Order Learning and Control}  \label{subsec:math_foundations}


\begin{lemma}[Discrete-time FOLTI system solution]
\label{lem:FOLTIsolution}
The solution to the discrete-time FOLTI system is given by \cite{guermah2012discrete}:
\begin{align}
    x_k &= G_k x_0 + \sum_{j=0}^{k-1} G_{k-1-j} B u_j,
\end{align}
where the matrices \( G_k \) are defined recursively as:
\begin{align}
    G_k &=
    \begin{cases} 
        I & \text{for } k = 0, \\
        \sum_{j=0}^{k-1} A_j G_{k-1-j} & \text{for } k \geq 1,
    \end{cases} \label{con:G_param}
\end{align}
and the matrices \( A_j \) are given by:
\begin{align}
    A_j &=
    \begin{cases} 
        A - \text{diag}(\alpha_1, \dots, \alpha_n) & \text{if } j = 0, \\
        -D(\alpha, j+1) & \text{if } j \geq 1. \label{con:Aj_eq}
    \end{cases}
\end{align}
\end{lemma}
The proof is provided in Appendix \ref{sec:proof_l1}. The first component of the FOLTI system solution represents the unforced response of the system. The term \(G_k\) exhibts the particularity of being time-varying, attributed to the fractional-order \(\alpha\) which inherently accounts for all the past states. The second component takes the role of the convolution sum corresponding to the forced response. 

\begin{theorem}[LQR solution for FOLTI systems]
\label{thm:LQRsolution}
The least-squares optimal control solution for the LQR problem of a FOLTI system is given by:
\begin{align}
    U &= -\left( G^\top \bar{Q} G + \bar{R} \right)^{-1} G^\top \bar{Q}^\top H x_0,
\end{align}
whereas the Lagrange multiplier optimal control solution is:
\begin{align}
    U = -R^{-1}B^\top \otimes (I - G_\lambda)^{-1}H_\lambda x_0.
\end{align}
Here, \( U \), \( G \), \( G_\lambda \), \( H \), \( H_\lambda \), \( \bar{R} \), and \( \bar{Q} \) are defined in Appendix \ref{sec:proof_t2}, and \(\otimes\) denotes the Kronecker product. Notably, \(U =\begin{bmatrix}
        u_0^\top & u_1^\top &\cdots &u_{T-1}^\top 
    \end{bmatrix}^\top \).
\end{theorem}

Using the optimal control solution via LQR, a natural question arises: given a system identification algorithm and a threshold error \(\epsilon\), how many samples are required for the system identification process to ensure that the error between the estimated LQR loss \(\hat{J}\) and the true LQR loss \(J\) (computed with the true system parameters) remains within the threshold \( d(\hat{J} - J) \leq \epsilon\), where \( d(\cdot)\) denotes the metric. We derive the following sample complexity results.

\begin{theorem}[Sample Complexity for FOLTI systems]
\label{thm:sample_complexity_1}
Consider a FOLTI system with a known matrix \( A \), fractional order \( \alpha \), and an unknown matrix \( B \). The following sample complexity bounds hold using the system identification in Appendix \ref{sec:system_identification}:
Let
    \[
    K_B = \frac{1}{N} (\phi^\top \phi)^{-1} \phi^\top K_w \phi (\phi^\top \phi)^{-1},
    \]
\begin{enumerate}[label=(\alph*)]
    \item Least-squares solution. 
    \begin{align}
    \mathbb{E} \left[ \left| \hat{J} - J \right| \right]  
    &\leq \|z\|_2^2 \| R^{-1}\|_2 \big(1 + \|B\|_2^2 \|R^{-1}\|_2 \|S\|_2 \big) \notag\\
    &\cdot\big(\operatorname{Tr}(K_B) + 2 \|B\|_2 \sqrt{\operatorname{Tr}(K_B)} \big),
    \end{align}

    \item Lagrange multiplier solution. Assume \( L_{QG}^{-1}(I - L_u) \succeq 0, \)
    \begin{align}
    \mathbb{E} \left[ \left| \hat{J} - J \right| \right] 
    &\leq  \|z\|_2 \|H_\lambda x_0 \|_2 \| R^{-1}\|_2 \|\mathbb{L}\|_2 
    \big(1 + \|B\|_2^2 \notag\\
    &\quad \cdot \|R^{-1}\|_2 \|\mathbb{L}\|_2 \|L_{QG}\|_2 \big)
    \big(\operatorname{Tr}(K_B) + \notag\\ 
    &\quad 2 \|B\|_2 \sqrt{\operatorname{Tr}(K_B)} \big),
    \end{align}
\end{enumerate}
where \( z = G_d^\top \bar{Q}^\top H x_0, \; S = G_d^\top \bar{Q} G_d, \; \|\mathbb{L}\|_2 = \|(L_{QG})^{-1}\|_2 \|L_{QG}\|_2 ,\) and \( G_d \), \( \bar{Q} \), and \( H \) are system matrices as defined in Appendix \ref{sec:proof_t3}.
\end{theorem}

\begin{corollary}[Simplified Sample Complexity for FOLTI systems]
\label{cor:simplified_sample_complexity}
Let \( K_w = \sigma_w^2 I \) and \( u_0^i \sim \mathcal{N}(0, I) \). For \( p > m + 1 \), then:
\begin{equation}
    \operatorname{Tr}(K_B) = \frac{nm \sigma_w^2}{N\left(p - m - 1\right)}
\end{equation}

where \(p\) and \(N\) denote the number of samples, and \(m\) is the dimension of control inputs (see Appendix \ref{sec:proof_c4}).
\end{corollary}

The sample complexity results demonstrate that the overall convergence rates of the least-squares solution and the Lagrange multiplier solution are both \(\mathcal{O}(\frac{1}{\sqrt{N}})\), differing only in their constant factors.

\subsection{Theoretical Approach for Fractional-Order System Identification and Optimal Control}
Our end-to-end theoretical learning method follows a similar strategy to those used in Markovian processes, specifically for LTI systems. The learning procedure can be summarized in two main steps. Given \(N\) noisy trajectories, each of \(T\) time steps, and assuming the diagonal elements of the system matrix \(A\) are known, we first formulate a least-squares problem to identify the system parameters by using the linearity of the Grünwald–Letnikov difference operator. The state evolution with noise can be represented as
\begin{equation}
\Delta^\alpha x_{k+1} = A x_k + B u_k + w_k,
\end{equation}
where \(\{w_k\}_{k=0}^{T-1}\) is an independent and identically distributed (i.i.d) Gaussian noise process. Using the linearity of the fractional difference operator, the state evolution for each trajectory can be expressed as:
\begin{align}
x_1 &= Ax_0 + B u_0 + C_\alpha x_0 + w_0 
\end{align}
Using this formulation, we define the following optimization problem across \(N\) trajectories
\begin{equation}
\hat{\theta} = \arg\min_{\theta} \|X - \xi \theta\|_2^2,
\end{equation}
with the closed-form solution
\begin{equation}
\hat{\theta} = \left(\xi^\top \xi\right)^{-1} \xi^\top X,
\end{equation}
where system parameters \(C_{\alpha}, \theta\) and feature matrices \(X, \xi\) are detailed in Appendix \ref{sec:system_identification}.

In the second step, the derived system parameters are used to compute the optimal control solution as described in Theorem \ref{thm:LQRsolution}. For a given identified FOLTI system and a time horizon \(T\), the optimal control sequence can be derived for any cost matrices \(Q\) and \(R\), along with the initial condition \(x_0\).

\begin{figure*}[htbp]
    \centering
    \includegraphics[width=\textwidth]{plot/Model_Architecture_4.pdf}

    \vspace{-2.25em}
    \caption{Overview of the proposed model architecture. The pipeline first infers fractional-order system parameters $(A, \alpha, B)$ from input $\mathcal{X}$ using an RNN+MLP based system identification module, These parameters are then encoded as embeddings of sequential tokens $A_i$ for time-dependent modeling. An attention-based Sequence Encoder processes these embeddings to obtain latent representations, which along with cost matrices $Q$, $R$, estimated system matrix $B$ are fed to the Stack MLPs with residual connection input $\mathcal{X}$ for Fourier Neural Operator to predict optimal control signals. Finally, a Composite Loss function unifies system identification and control prediction, enabling end-to-end training of both system parameter estimation and control law synthesis.}
    \vspace{-1em}
    \label{fig:model architecture}
\end{figure*}

\subsection{Fractional-Order Learning for Optimal Control Framework} \label{sec:Deep Learning Framework}

Our end-to-end deep learning framework FOLOC is guided by the mathematical derivation of the optimal control policy for FOLTI systems (see Methodology~\ref{subsec:math_foundations}). Generally, FOLOC framework can be structured into two main components.

\textbf{System Identification Module:} Inspired by traditional LTI and our proposed FOLTI system identification, we use deep learning based time-series models to estimate system parameters and approximate intermediate variables. The objective is to learn the underlying function that maps trajectories to the variables required for solving the LQR problem.

Theoretical system identification for both LTI and FOLTI systems predominantly relies on least-squares methods, which can be viewed as operators learning a function that maps from the trajectory and control input space $\mathcal{X}$ to the system parameter space $\mathcal{S}$. Consider the temporal nature of the trajectory, we choose a recurrent neural network to estimate the system parameters. The mapping is defined as \(\mathcal{R}_\theta: {\mathcal{X}} \in \mathbb{R}^{T \times (n + m)}\to \mathcal{S} \in \mathbb{R}^{n^2 + nm +n}\) such that \(vectorize (\hat{A}_\theta, \hat{B}_\theta, \hat{\alpha}_\theta) = \mathcal{R}_\theta(\{{x_i, u_i}\}_{i=0}^{T-1})\). From Lemma \ref{lem:FOLTIsolution}, the function mapping between the system parameters to the time-varying matrices \(A_k\) and then to the matrices \(G_k\) can be represented as follows respectively 
\begin{align}
    A_k &= g_k(A, \alpha; \Gamma), \notag \\
    G_k &= f_k(A_0, \cdots, A_{k-1}),
\end{align}
where $g_k(\cdot; \Gamma)$ is obtained as a function of the Gamma function, which governs the fractional-order dynamics. To model the first mapping, we use MLPs with injecting time embeddings to approximate the function \(\mathcal{R}_g: \mathcal{S} \to \mathcal{H} \in \mathbb{R}^{T \times h}\) such that \(\{\hat{A}_{i_g}\}_{i=0}^{T-1} = \mathcal{R}_g(\hat{A}_\theta, \hat{\alpha}_\theta, \{e_i\}_{i=0}^{T-1})\), where \(h\) can be chosen based on the dynamics complexity and \(\{ e_{i} \} _{i=0}^{T-1}\)  represents an embedding of a specific timestamp $i$. The second mapping is approximated by an Encoder-only Transformer \(\mathcal{R}_f:\mathcal{H} \to \mathcal{G} \in \mathbb{R}^{T \times n}\) such that \(\{\hat{G}_{i_f}\}_{i=0}^{T-1} = \mathcal{R}_f(\{\hat{A}_{i_g}\}_{i=0}^{T-1})\), where $\hat{G}_{i_f}$ represents the learned approximation of the intermediate parameters $G_k$.

% where $g_\Gamma$ derived from the Gamma function, which governs the fractional-order dynamics. To model this mapping, we use another time-series deep learning model to approximate the function \(\mathcal{R}_\zeta: \mathcal{S} \cup \mathcal{X} \to \mathcal{G} \in \mathbb{R}^{T \times n}\) such that \(\{\hat{G}_{i_\zeta}\}_{i=0}^{T-1} = \mathcal{R}_\zeta(\hat{A}_\theta, \hat{\alpha}_\theta, \{{\color{blue}e_i}\}_{i=0}^{T-1})\), where $\hat{G}_{i_\zeta}$ represents the learned approximation of the intermediate parameters $G_k$.

\textbf{Optimal Control Module:} Building upon the mathematical derivation of the LQR problem using Lagrange multipliers, we use a neural operator to learn the mapping between the input space (variable required for solving the LQR problem) and the output space \(\{u_i^o\}_{i=0}^{T-1}\)(optimal control sequence).

%{\color{red}We first define the Block Toeplitz matrix that generalizes Toeplitz matrix as follows.}
The core of optimal control module mirrors the process of solving the linear system derived from the LQR problem through Lagrange multipliers. The mathematical formulation of the linear system is expressed as:
\begin{equation}
(I - G_\lambda)\lambda = 2H_\lambda x_0,
\end{equation}
where \(\lambda\) is defined in Appendix \ref{sec:proof_t2} and \(I - G_\lambda \in \mathbb{R}^{Tn \times Tn}\) is a block Toeplitz matrix (see Definition \ref{def:Toeplitz}). Using the solution of the Lagrange multipliers, the optimal control sequence \(\{u_i^o\}_{i=0}^{T-1}\) can be given by:
\begin{align}
    U = -R^{-1}B^\top \otimes (I - G_\lambda)^{-1}H_\lambda x_0.
\end{align}

\citet{luo2024neural} has demonstrated that solving linear systems via Krylov iterations can be significantly accelerated by using the Fourier Neural Operator (FNO). Specifically, FNO learns the mapping from the linear system to its corresponding invariant subspace, using the predicted subspace to guide iterative solvers. Inspired by this approach, we use a neural operator to directly learn the mapping between two Hilbert spaces, denoted as \(\mathcal{T}: \mathcal{A} \to \mathcal{U} \in \mathbb{R}^{T \times n}\). Due to the block Toeplitz structure of the linear system, the input to FNO is the reduced relevant function variables \(a \in \mathbb{R}^{T\times d_a}\). The transformation operator \(\mathcal{L}\) first lifts the input \(a\) to a higher dimensional channel space \(v_0 \in \mathbb{R}^{d_v \times c}\), where \(c \) is the number of channels. Then iteratively applying several Fourier layer to update the representation \(v_i \to v_{i+1}\),  we have the final \(v_T \in \mathbb{R}^{d_v \times c}\), which has the same dimensionality as \(v_0\). The FNO outputs optimal control sequence \(U = \mathcal{Q}(v_T)\) through the projection of \(v_T\) by the transformation operator \(\mathcal{Q}: \mathbb{R}^{d_v \times c} \to \mathbb{R}^{T \times n}\). This design enables efficient computation of the optimal control sequence by leveraging the special properties of the block Toeplitz linear system and the expressive capabilities of the FNO.

The loss function used in the training process is defined as follows:
\begin{align}
\label{loss_fuc}
l(\theta) &=  \lambda_w l_{s}(\theta) + \left(1-\lambda_w\right)l_{o}(\theta),    
\end{align}
where \(l_s\) quantifies the loss due to system identification errors, and \(l_{o}\) quantifies the loss due to optimal control errors. Specifically,
% \begin{align}
% l_s(i;\theta) &= \|A_i - \hat{A}_{i_\theta}\|_2^2 + \|B_i - \hat{B}_{i_\theta}\|_2^2 + \| \alpha_i - \hat{\alpha}_{i_\theta}\|_2^2, \notag \\
% l_{o}(i; \theta) &= \|U_i - \hat{U}_{i_\theta} \|_2^2.
% \end{align}

\begin{align}
l_s(\theta) &= \|A - \hat{A}_{\theta}\|_2^2 + \|B - \hat{B}_{\theta}\|_2^2 + \| \alpha - \hat{\alpha}_{\theta}\|_2^2, \notag \\
l_{o}(\theta) &= \|U - \hat{U}_{\theta} \|_2^2.
\end{align}
Here, \(\lambda\) is a user-defined weighting parameter that determines the balance between system identification and optimal control errors during the learning process.

\textbf{Remark.} The fractional-order dynamical system parameters \(A, B\) and \(\alpha\) can be extracted from an intermediate layer in the network because of the underlying loss function. Though our end-to-end deep learning framework is guided by the theoretical optimal control solution derived by using Lagrange multipliers, certain learned parameters do not directly correspond one-to-one with their theoretical counterparts (see Appendix \ref{sec:modeldetail} for details). 



% \begin{table*}[ht]
% 	\small
% 	%	\vspace{-0.25cm}
% 				\renewcommand\arraystretch{1.2}
% 	\begin{center}
% 		\setlength{\tabcolsep}{4.4mm}{
% 			\resizebox{\linewidth}{!}{\begin{tabular}{ccccccc}
% 				\toprule
% 				\multirow{2}*{Methods}&\multicolumn{4}{c}{FID$\downarrow$}&\multirow{2}*{Parameters$\downarrow$}&\multirow{2}*{Sampling Time(s)$\downarrow$}\\
%             \cline{2-5}
%                 ~&CelebA-HQ (5K)&CelebA-HQ (30K)&AFHQ-Cat (5K)&Colon&~&\\
% 				\midrule
%                 SGM&90.83&78.50 &80.93& 109.23& 160M&15.093\\ 
% 				WSGM&49.97&26.74 &17.12& 54.35& 351M&11.097\\ 	
% 				\textbf{WMGM(Ours)}&\textbf{30.58}&\textbf{25.38}&\textbf{16.29}&\textbf{45.76}&\textbf{89M}&\textbf{2.31}\\ 
% 				\bottomrule 
% 		\end{tabular}}}
%   \caption{Comparison of SGM, WSGM and our method on CelebA-HQ (5K) and Celeba-HQ (30K). 16 discretization steps per scale was utilized for WSGM, our model and SGM keep the same total sampling steps and same sampling batch size (100 pictures per batch). Sampling time is the time to generate each 100 images under the same GPU resource consumption. \textbf{Bold} data represents the optimal results overall.}%Underlined values indicate the best results for each column, while }
% 		\label{table1}
% 		\vspace{-0.5cm}
% 	\end{center}
	
% \end{table*}

%% Insert the first plot
% \begin{figure}[htbp]
%     \centering
%     \includegraphics[width=0.48\textwidth]{plot/SC.pdf}
%     \vspace{-2em}
%     \caption{Sample complexity bound simulation.}
%     \vspace{-1em}
%     \label{fig:SC_result}
% \end{figure}

%  \begin{figure}[htbp]
%     \centering
%     \includegraphics[width=0.48\textwidth]{plot/Comparison.pdf}
%     \vspace{-2em}
%     \caption{Numerical simulation.}
 %    \vspace{-1em}
%     \label{fig:NM_result}
% \end{figure}

\newcommand{\perf}[2]{#1/#2}
\newcommand{\bperf}[2]{\textbf{#1}/{#2}}
\newcommand{\uperf}[2]{\underline{#1}/{#2}}

\begin{table*}[!t]
\small  % 字体大小
\renewcommand{\arraystretch}{0.7}  %行距
\caption{Experimental results on synthetic FOLTI system under varying input conditions. All reported values are in units of \(10^{-3}\). \textbf{Bolded} values represent the minimum in each row.}
\label{comparison_table}
\setlength{\tabcolsep}{4pt}  % 列间距
\begin{tabular*}{\textwidth}{@{\extracolsep{\fill}}c|ccccc@{}}
\toprule
Metrics& \textbf{MSE/MAE} & \textbf{MSE/MAE} & \textbf{MSE/MAE} & \textbf{MSE/MAE} & \textbf{MSE/MAE} \\
\cline{1-6}\rule{0pt}{2.5ex}
Fractional& alpha = 0.1 & alpha = 0.3 & alpha = 0.5 & alpha = 0.7 & alpha = 0.9 \\[2pt]
\cline{2-6}\rule{0pt}{2.5ex}
Order & \textbf{\perf{3.39$\pm$0.52}{8.04$\pm$0.42}} & \perf{5.04$\pm$1.82}{12.5$\pm$1.11} & \perf{5.61$\pm$0.84}{16.5$\pm$0.61} & \perf{5.18$\pm$0.06}{9.22$\pm$0.08} & \perf{4.94$\pm$0.09}{10.5$\pm$0.09}  \\

\midrule
State &$n = 1$ & $n = 2$ & $n = 4$ & $n = 6$ & $n = 8$ \\[2pt]
\cline{2-6}\rule{0pt}{2.5ex}
 Dimension& \textbf{\perf{1.98$\pm$0.08}{6.60$\pm$0.13}} & \perf{5.61$\pm$0.84}{16.5$\pm$0.61} & \perf{5.84$\pm$0.71}{13.4$\pm$0.55} & \perf{4.88$\pm$0.34}{13.4$\pm$0.26} & \perf{4.26$\pm$0.22}{12.3$\pm$0.14}  \\

\midrule
Time &T = 8 & T = 16 & T = 32 & T = 64 & T = 128 \\[2pt]
\cline{2-6}\rule{0pt}{2.5ex}
 Horizon& \perf{101$\pm$18.4}{111$\pm$4.40} & \perf{43.2$\pm$8.20}{59.1$\pm$1.12} & \perf{14.2$\pm$2.96}{31.5$\pm$1.70} & \perf{5.61$\pm$0.84}{16.5$\pm$0.61} & \textbf{\perf{2.66$\pm$0.64}{8.62$\pm$0.70}}  \\

 \midrule
\multirow{2}{*}{Noise Type} & Cauchy & Gamma & Sinc-squared & Uniform & Poisson  \\[2pt]
\cline{2-6}\rule{0pt}{2.5ex}
 & \perf{6.98$\pm$1.89}{17.0$\pm$0.71} & \perf{\textbf{5.84$\pm$1.15}}{16.7$\pm$1.16} & \perf{6.87$\pm$1.46}{17.6$\pm$0.75} & \perf{6.46$\pm$1.29}{17.0$\pm$1.30} & \perf{6.59$\pm$1.59}\textbf{{16.5$\pm$0.90}}  \\
 
 \midrule
Noise Scale  & $\sigma = 0.0001$ & $\sigma = 0.001$ & $\sigma = 0.01$ & $\sigma = 0.1$ & $\sigma = 1$ \\[2pt]
\cline{2-6}\rule{0pt}{2.5ex}
 (Gaussian)& \perf{5.85$\pm$0.65}{16.9$\pm$0.65} & \perf{6.09$\pm$0.74}{17.4$\pm$0.87} & \perf{5.74$\pm$0.83}{16.7$\pm$0.86} & \textbf{\perf{5.65$\pm$0.70}{16.0$\pm$0.39}} & \perf{10.2$\pm$8.11}{20.5$\pm$7.37} \\


\midrule
\multirow{2}{*}{Training Size}  & $N_T = 1000$ & $N_T = 2000$ & $N_T = 4000$ & $N_T = 6000$& $N_T = 8000$ \\[2pt]
\cline{2-6}\rule{0pt}{2.5ex}
  & \perf{5.18$\pm$1.13}{12.9$\pm$0.80} & \perf{4.44$\pm$1.30}{11.4$\pm$0.38} & \perf{\textbf{3.98$\pm$0.89}}{10.9$\pm$1.01} & \perf{4.79$\pm$2.11}{10.4$\pm$0.58}& \perf{5.22$\pm$2.31}\textbf{{10.1$\pm$0.78}} \\

\bottomrule
\end{tabular*}
\end{table*}

% \clearpage
\section{Experiments}
% \textcolor{red}{A brief description of the experiment and the results}
In this section, we empirically evaluate the proposed system identification algorithm and FOLOC framework using both synthetic and real-world system dynamics. The synthetic data is categorized into two primary types: (i) data generated from a single FOLTI system with fixed system parameters \(A, B\), and \(\alpha\); and (ii) data generated from multiple FOLTI systems, where \(A, B\) are fixed, and \(\alpha\) vary across systems. The real-world data is simulated from a cart pole and a quadrotor dynamical systems. 

%We compare our approach to existing system identification strategies and optimal control solvers based on LQR in Markovian processes (See the Appendix \ref{baselti}). We test FOLOC's performance varying different conditions.


%The experiments show that our FOLOC framework not only achieves low MSE and mean absolute error (MAE) but also exhibits short inference time. We also demonstrate that the end-to-end deep learning framework is robust to various noise types and noise scales. It can predict approximately accurate optimal control sequences even under non-Gaussian noise, which poses a significant challenge for traditional system identification algorithms relying on Gaussian noise assumptions. {\color{red} We also do ablation study in the Appendix \ref{Abla}. }

\subsection{Performance Evaluation on Synthetic Data}

We evaluate our theoretical end-to-end learning approach and FOLOC framework using synthetic data. Due to the strict assumptions required for the theoretical learning process, we test it using synthetic data generated from a single underlying FOLTI system, with data corrupted by Gaussian noise. Our empirical analysis examines the performance of FOLOC framework from different perspectives.

The underlying fractional-order dynamics used to generate the data for our model are defined as follows:  
\begin{equation}
x_{k+1} = A x_k + B u_k - \sum_{j=1}^{k+1} D(\alpha, j) x_{k+1-j} + w_k,
\end{equation}  
where \(w_k\) represents the process noise.  

\textbf{\textit{Theoretical approach validation.}} By varying the number of trajectories used in the system identification process, we empirically validate the sample complexity results presented in Theorem \ref{thm:sample_complexity_1} as shown in Fig. \ref{fig:SC_result}. We also compare our method with the traditional end-to-end learning framework for LTI systems (see Appendix \ref{baselti}). The mean MSE of FOLTI system learning framwork decreases by 81.36\% compared with LTI system learning framework. 

%% Insert the first plot
 \begin{figure}[htbp]
     \centering
     \includegraphics[width=0.48\textwidth]{plot/SC.pdf}
     \vspace{-2em}
     \caption{Sample complexity bound simulation.}
     \vspace{-1em}
     \label{fig:SC_result}
 \end{figure}

  \begin{figure}[htbp]
     \centering
     \includegraphics[width=0.48\textwidth]{plot/Comparison.pdf}
     \vspace{-2em}
     \caption{Numerical simulation.}
     \vspace{-1em}
     \label{fig:NM_result}
 \end{figure}

%The numerical simulations in Figure \ref{fig:NM_result} demonstrate that our method more accurately approximates the underlying fractional-order dynamics, both in simulating the optimal control sequence and the system trajectories.

\textbf{\textit{FOLOC framework evaluation}}. We evaluate our proposed data-driven approach by varying different variables. Our main findings are as follows: (i) FOLOC framework effectively captures the underlying system dynamics with high accuracy and remains robust to variations in fractional orders, system dimensions, noise types, noise scales, and training samples. (ii) The model’s ability to learn the system dynamics improves as the time horizon increases. (iii) FOLOC framework can be trained using a small number of samples.  

\textbf{Varying fractional orders.} By varying the fractional order \(\alpha\), we observe that FOLOC framework effectively captures long-term dependencies. The results of our experiments on commensurate FOLTI systems (see Appendix \ref{Why_FO}) with different fractional orders \(\alpha = 0.1, \;0.3, \;0.5, \;0.7, \;0.9 \) are shown in Table \ref{comparison_table}. As the fractional order \(\alpha\) increases, we observe that the MSE and MAE remain approximately the same, with an overall mean MSE of 0.40\% (standard deviation: 0.21\%) and an overall mean MAE of 0.95\% (standard deviation: 0.55\%). 

%This contrasting trend can be attributed to the substantial increase in the trajectory scale with higher fractional orders, reflecting the influence of the long-term memory effect inherent to fractional-order dynamics.

\iffalse
\begin{table}[h]
\centering
\setlength{\tabcolsep}{4pt} 
{\begin{tabular}{lccccc}
    \toprule
    Metrics & $\alpha=0.1$ & $\alpha=0.3$ & $\alpha=0.5$ & $\alpha=0.7$ & $\alpha=0.9$ \\
    \midrule
    MAE & 0.0081 & 0.0126 & 0.0175 & 0.0402 & 0.0165 \\
    MSE & 0.0029 & 0.0040 & 0.0055 & 0.0202 & 0.0097 \\
    L2loss & 0.6126 & 0.6685 & 0.6033 & 0.3725 & 0.3601 \\
    \bottomrule
\end{tabular}}
\label{tab:metrics}
\caption{Performance metrics for different $\alpha$ values ($d=2$, $t=64$)}
\end{table}
\fi

\textbf{Varying time horizons.} We show the results of learning fractional-order dynamics with different time horizons \(T = 8, \;16, \; 32, \; 64, \; 128\) in Table \ref{comparison_table}. As the time horizon increases, FOLOC framework demonstrates improved ability to capture the fractional-order dynamics. Compared with at \(T = 8\), the MSE and MAE at \(T = 128\) of FOLOC framework decrease by 97.37\% and 92.23\% respectively.



\iffalse 
\begin{table}[h]
\centering
{\begin{tabular}{lccccc}
    \toprule
    Metrics & t=8 & t=16 & t=32 & t=64 & t=128 \\
    \midrule
    MAE & 0.1114 & 0.0628 & 0.0297 & 0.0175 & 0.0097 \\
    MSE & 0.1212 & 0.0358 & 0.0075 & 0.0055 & 0.0039 \\
    L2loss & 0.6412 & 0.5176 & 0.7395 & 0.6032 & 0.5809 \\
    \bottomrule
\end{tabular}}
\label{tab:timestep_metrics}
\caption{Performance metrics for different timesteps ($d=2$, $\alpha=0.5$)}
\end{table}
\fi

\textbf{Varying state dimensions.} We vary the system state dimension \(n = 1, \; 2, \; 4, \; 6, \; 8\) to evaluate its impact on the learning process (assume \(n = m\)). Increasing the state dimension significantly raises the learning complexity due to the larger number of variables and the interactions or couplings between the states. Despite this, FOLOC framework demonstrates consistent performance, with an overall mean MSE of 0.45\% (standard deviation: 0.15\%) and an overall mean MAE of 1.24\% (standard deviation: 0.36\%). Compared with at \(n = 2\), the MSE (MAE) of FOLOC framework decreases by 13.01\% (18.79\%) at \(n = 6\) and 24.06\% (25.45\%) at \(n=8\). This experiment demonstrates the scalability of our model, and verifies its ability to capture the interactions within the fractional dynamics of the state.

\iffalse 
\begin{table}[h]
\centering
{\begin{tabular}{lcccc}
    \toprule
    Metrics & d=1 & d=2 & d=4 & d=8 \\
    \midrule
    MAE & 0.0069 & 0.0129 & 0.0141 & 0.0218 \\
    MSE & 0.0021 & 0.0097 & 0.0072 & 0.0110 \\
    L2loss & 1.4218 & 0.3634 & 0.7381 & 0.6755 \\
    \bottomrule
\end{tabular}}
\label{tab:dimension_metrics}
\caption{Performance metrics for different dimensions ($\alpha=0.5$, $t=64$)}
\end{table}
\fi
\vspace{-1em}
\begin{figure}[htbp]
     \centering
     \includegraphics[width=0.48\textwidth]{plot/timestep_mse_mae.pdf}
     \vspace{-2em}
     \caption{Vary time horizons.}
     
     \label{fig:vary_time_horizon}
    \vspace{-2em}
\end{figure}

\textbf{Varying training samples.} We show the model performance with different number of training samples \(N = 1000, \; 2000, \; 4000, \; 6000, \; 8000\). Compared with at \(N = 8000\), the MSE only decreases by 1.65\% at \(N = 1000\). This demonstrates that FOLOC framework is sample-efficient and capable of learning the underlying fractional-order dynamics with a limited number of samples.
%14.87\%, 23.72\% and 8.11\% while the MAE increases by 18.97\%, 8.04\%, 3.95\% and -0.93\% as \(N\) increases. This demonstrates that FOLOC framework can learn the underlying fractional-order dynamics using a small number of training samples.

\textbf{Varying noise distributions.} By varying the distribution of process noise, we demonstrate the robustness and effectiveness of FOLOC framework. We evaluate the model’s performance by simulating the noise from the following probability distribution functions: Gaussian, Poisson, Uniform, Gamma, Sinc-squared \cite{adigun2023hidden, 10651174}, and Cauchy. Compared with using Gaussian noise, the maximal increases of MSE/MAE by 24.42\%/6.67\% (Cauchy/Sinc-squared). The empirical results (Table \ref{comparison_table}) show that FOLOC framework can not only predict an approximately accurate optimal control sequence but also effectively estimate the system parameters.

\textbf{Varying noise scales.} FOLOC framework shows the ability to learning the fractional-order dynamics with data corrupted by different Gaussian noise scales. As data is corrupted by different scales of Gaussian noise, FOLOC framework demonstrates consistent performance, with an overall mean MSE of 0.67\% (standard deviation: 0.19\%) and an overall mean MAE of 1.75\% (standard deviation: 0.18\%).

The additional results also demonstrate that the FOLOC framework is computationally efficient (see Appendix \ref{compa_inf}) and capable of learning from multiple FOLTI systems (see Apendix \ref{dif_folti}). We also evaluate the performance by varying the weight parameter \(\lambda_w\) in the loss function (\ref{loss_fuc}) (see Appendix \ref{Ident_weight}).

\subsection{Performance Evaluation on Real-World Systems}
To demonstrate that our deep learning model can effectively capture complex system dynamics, we evaluate it on two practical scenarios: cart-pole dynamics and quadrotor dynamics \cite{zhou2024simultaneousidentificationmodelpredictive}. The detail of system dynamics is given in Appendix \ref{sysdyn}.

\textbf{Cart Pole.} The empirical experiments show that FOLOC framework can correctly capture the underlying system dynamics even when we add some large-scale Gaussian noise. The overall mean MSE is less than \(3.99 \times 10^{-5}\) and the overal mean MAE is less than \(3.39 \times 10^{-3}\).  


\vspace{-10pt}
\begin{table}[h]
\centering
\small
\caption{Model performance in the cart pole experiment.}
\setlength{\tabcolsep}{8pt}
{\begin{tabular}{@{}lccccc@{}}
    \toprule
    \multirow{2}{*}{Metrics} & \multicolumn{4}{c}{Noise Scale ($\sigma$)} & \multirow{2}{*}{\begin{tabular}[c]{@{}c@{}}No\\noise\end{tabular}} \\
    \cmidrule(lr){2-5}
    & 1 & $10^{-1}$ & $10^{-2}$ & $10^{-3}$ & \\
    \midrule
   
    MSE $(10^{-5})$ & 4.0 & 3.9 & 4.1 & 3.9 & 3.9 \\
     MAE $(10^{-3})$ & 3.4 & 3.4 & 3.4 & 3.3 & 3.3 \\
    \bottomrule
\end{tabular}}
\label{tab:metrics}
\end{table}
\vspace{-10pt}


\textbf{Quadrotor.} The empirical experiments show that FOLOC framework is robust to different Gaussian noise scales when learning the Quadrotor dynamics. The overall mean MSE is 0.13 (standard deviation: 0.052), and the overall mean MAE is 0.21 (standard deviation: 0.086).

\vspace{-10pt}
\begin{table}[h]
\centering
\small
\caption{Model performance in the quadrotor experiment.}
\setlength{\tabcolsep}{8pt}
{\begin{tabular}{@{}lccccc@{}}
    \toprule
    \multirow{2}{*}{Metrics} & \multicolumn{4}{c}{Noise Scale ($\sigma$)} & \multirow{2}{*}{\begin{tabular}[c]{@{}c@{}}No\\noise\end{tabular}} \\
    \cmidrule(lr){2-5}
    & 1 & $10^{-1}$ & $10^{-2}$ & $10^{-3}$ & \\
    \midrule
    
    MSE $(10^{-1})$ & 1.27 & 1.27 & 1.25 & 1.32 & 1.23 \\
    MAE $(10^{-1})$ & 2.10 & 2.14 & 2.08 & 2.13 & 2.06 \\
    \bottomrule
\end{tabular}}
\label{tab:metrics_quadrotor}
\end{table}
\vspace{-10pt}


% \newcommand{\perf}[2]{#1/#2}
% \newcommand{\bperf}[2]{\textbf{#1}/{#2}}
% \newcommand{\uperf}[2]{\underline{#1}/{#2}}



\section{Conclusion}
This paper introduces a theoretical learning framework for optimal control of FOLTI systems, addressing key challenges in system identification, control design, and sample complexity analysis. By extending LQR to the fractional-order setting, we derive analytical solutions and provide sample complexity guarantees. Based on this theoretical foundation, we propose FOLOC, an end-to-end framework that jointly estimates system parameters and learns optimal control policies from noisy trajectories. Unlike classical methods, FOLOC framework is designed to operate effectively in real-world, noisy environments, ensuring robustness against non-Gaussian noise and limited training samples. Extensive simulations and real-world applications demonstrate the scalability, robustness, and computational efficiency of our approach. 

\textbf{Limitation}: While our framework is effective for FOLTI systems, its LTI-based design requires further validation in non-LTI settings. Future work will extend the framework to non-LTI dynamics, enhancing its applicability to more complex systems.

%\textbf{Limitation}: While our framework is effective for FOLTI systems, its current focus on LTI settings limits its applicability to broader settings. Future work will extend the framework to handle non-LTI dynamics, making it applicable to a broader range of complex systems.

%Future research directions include extending the theoretical learning framework for FOLTI systems to more general setting, investigating adaptive learning techniques for real-time control, and exploring alternative optimal control formulations beyond LQR. Additionally, bridging the gap between theoretical guarantees and hardware implementation remains an important step for deploying fractional-order controllers in practical applications.

%We propose FOLOC framework, an end-to-end deep learning framework, that jointly estimates system parameters and learns optimal control policies directly from observed noisy trajectories. Unlike classical methods that assume structured noise, FOLOC framework is designed to operate effectively in real-world, noisy environments, ensuring robustness against non-Gaussian noise and a small number of training samples. We demonstrate the scalability, robustness, and computational efficiency of our approach though extensive simulations, highlighting its potential for real-world applications such as control systems, bioengineering, and financial modeling.

%Future research directions include extending the theoretical learning framework for FOLTI systems to more general setting, investigating adaptive learning techniques for real-time control, and exploring alternative optimal control formulations beyond LQR. Additionally, bridging the gap between theoretical guarantees and hardware implementation remains an important step for deploying fractional-order controllers in practical applications.







% Note use of \abovespace and \belowspace to get reasonable spacing
% above and below tabular lines.



% \section*{Accessibility}


% \section*{Software and Data}

% Acknowledgements should only appear in the accepted version.
% \section*{Acknowledgements}
\clearpage
\section*{Impact Statement}
Fractional-order dynamical systems can model complex dynamical behaviors characterized by long-range dependencies and memory effects, yet their practical implementation remains challenging due to the lack of system identification and control strategies. This work advances the field by formulating both theoretical and deep learning frameworks for solving fractional-order optimal control via the LQR. For theoretical learning, we provide a new fractional-order system identification and a new sample complexity analysis that gives guarantees on the number of samples required for achieving reliable control performance. Beyond theoretical contributions, we develop a novel end-to-end data-driven learning framework that jointly estimates system parameters and optimizes control policies directly from observed trajectories. Unlike traditional methods that rely on strong assumptions (e.g., noiseless data or structured disturbances), our approach remains robust under realistic, noisy environments with non-Gaussian uncertainties. 

By bridging theoretical foundations with deep learning techniques, our work enables scalable and efficient optimal control for fractional-order dynamical systems in domains such as biomedical engineering, neuroscience, and financial modeling. Experimental results validate the effectiveness of our approach, demonstrating accurate system identification and control policy learning across various noise distributions and system complexities.

This research lays the groundwork for future advancements in learning-based control of fractional-order dynamical systems, paving the way for real-world deployment of fractional-order optimal controllers in autonomous systems, robotics, and large-scale networks.

% In the unusual situation where you want a paper to appear in the
% references without citing it in the main text, use \nocite
\nocite{langley00}

\bibliography{example_paper}
\bibliographystyle{icml2025}


%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% APPENDIX
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\newpage
\appendix
\onecolumn
\section{Code Availability}
\label{code}
The source code is available at \href{https://anonymous.4open.science/r/Fractional-Order-Learning-for-Control-Framework-69A0}{https://anonymous.4open.science/r/Fractional-Order-Learning-for-Control-Framework-69A0}.

\section{Related Work}
\label{relatedwork}

While research on system identification and optimal control for FOLTI systems remains limited, significant progress has been made in LTI systems. Estimating unknown parameters of linear dynamical systems is a well-established subfield of system identification in control theory \cite{JMLR:v22:19-725, faradonbeh2018finitetimeidentificationunstable, simchowitz2018learningmixingsharpanalysis}, where the task is to estimate parameters from input-output time series generated by the underlying system. With the increasing interest in machine learning and deep learning, many researchers use different deep learning based modeling techniques to solve general nonlinear system identification. \citet{chen1990non} shows a single hidden layer neural network can identify discrete time nonlinear systems and derives new parameter estimation algorithms based on a prediction error formulation. \citet{80202} demonstrates that neural networks can be used effectively for both identification and control of nonlinear dynamical systems. The hierarchical structures of multilayer feedforward neural networks can include dynamic systems features \cite{zancato2021noveldeepneuralnetwork} and bring extra flexibility for probablistic approaches \cite{hendriks2020deepenergybasednarxmodels}. Kernel-based methods also have been studied in system identification. Linear system identification can be seen as an application of learning the impulse response function, which can be approximated by kernels \cite{aronszajn1950theory,dinuzzo2012representer, cho2009kernel}. Deep state-space models \cite{gedon2021deep} like recurrent neural networks \cite{hochreiter1997long, cho2014learningphraserepresentationsusing} and autoencoders \cite{masti2021learning, lusch2018deep} are also gaining in popularity for system identification. For Another critical aspect of optimal control via LQR is the design of control inputs, which are typically formulated as linear combinations of disturbance processes \cite{dean2020sample}.
    
Solving the optimal control problem via LQR involves addressing a potentially large linear system with a block Toeplitz matrix of size $\mathbb{R}^{Tn \times Tn}$. While solutions for Toeplitz and block Toeplitz systems have been extensively studied \cite{trench1986solution, kalouptsidis1984fast, chandrasekaran1998fast}, they still present significant computational challenges. Direct solution methods for Toeplitz systems typically exhibit a computational complexity of $\mathcal{O}(N^2)$, where $N$ represents the degrees of freedom. However, the high memory requirements of these methods often limit their applicability to large-scale problems. Iterative solvers \cite{chan2007introduction, strang1986proposal} are more memory-efficient and can achieve a complexity of $\mathcal{O}(N \log^2(N))$ for a single linear block Toeplitz system. Advanced approaches, such as global and block variants of the generalized minimal residual (GMRES) method \cite{saad1986gmres}, can efficiently address sequences of block Toeplitz systems with multiple right-hand sides \cite{jelich2021efficient}. Machine learning-based methods, such as neural operators \cite{li2021fourierneuraloperatorparametric, gupta2021multiwavelet, gupta2022non, xiao2022coupled}, offer a promising alternative for accelerating the solution of linear systems. Neural operator-assisted Krylov iterations \cite{luo2024neural}, for example, have demonstrated significant computational advantages, achieving up to a $5.5\times$ speedup in computation time and a $16.1\times$ reduction in the number of iterations. These advancements underscore the potential of machine learning techniques to address computational bottlenecks in optimal control for FOLTI systems.

\section{Why Fractional Order?}
\label{Why_FO}
According to the well-known definition, the first-order derivative of the function \( f(t) \), denoted by \( \mathcal{D}^1 f(t) \), is defined by
\begin{equation}
\mathcal{D}^1 f(t) = \frac{df(t)}{dt} = \lim_{h \to 0} \frac{f(t) - f(t - h)}{h},
\end{equation}
that is, as the limit of a backward difference. Similarly,
\begin{equation}
\mathcal{D}^2 f(t) = \frac{d^2 f(t)}{dt^2} = \lim_{h \to 0} \frac{1}{h^2} \big[f(t) - 2f(t - h) + f(t - 2h)\big]
\end{equation}
and
\begin{equation}
\mathcal{D}^3 f(t) = \frac{d^3 f(t)}{dt^3} = \lim_{h \to 0} \frac{1}{h^3} \big[f(t) - 3f(t - h) + 3f(t - 2h) - f(t - 3h)\big].
\end{equation}

Iterating \( n \)-times, we can obtain
\begin{equation}
\mathcal{D}^n f(t) = \frac{d^n f(t)}{dt^n} = \lim_{h \to 0} \frac{1}{h^n} \sum_{k=0}^n (-1)^n \binom{n}{k} f(t - kh),
\end{equation}
where
\begin{equation}
\binom{n}{k} = \frac{n(n - 1)(n - 2) \cdots (n - k + 1)}{k!}.
\end{equation}
Naturally we can extend the common binomial coefficients for any \(n \in \mathbb{R}^+\) by letting \((n-1)! = \Gamma(n)\). So the Riemann-Liouville fractional-order integral can be defined as a consequence of Cauchy's formula for repeated integrals.

\begin{definition}[Riemann-Liouville fractional-order integral]
\label{def:rl_integral}
Given a positive real number \(\alpha\), the Riemann-Liouville fractional-order integral is defined as
\begin{equation}
\mathcal{I}_c^\alpha f(t) \coloneqq \frac{1}{\Gamma(\alpha)} \int_c^t (t-\tau)^{\alpha-1} f(\tau) \, \mathrm{d}\tau, \quad t > c, \, \alpha \in \mathbb{R}^+.
\end{equation}
\end{definition}

Consider an integer-order derivative operator \(\mathcal{D}^n\) \((n \in \mathbb{N})\). The derivative operator \(\mathcal{D}^n\) is only a left-inverse of the integral operator \(\mathcal{I}^n\) such that \(\mathcal{D}^n \mathcal{I}^n = \mathbb{I}\) and \(\mathcal{I}^n \mathcal{D}^n \neq \mathbb{I}\). In order to generalize integer-order derivatives, the fractional-order derivative operator \(\mathcal{D}^\alpha \) should follow the same left-inverse rule. We show the definition of the Riemann-Liouville fractional-order derivative as follows.
\begin{definition}[Riemann–Liouville fractional-order derivative]
\label{def:rl_derivative}
Let \( f : \mathbb{R} \to \mathbb{R} \) be a function and let $I = [a, b]$ be a finite interval on the real axis $\mathbb{R}$. The left-side and right-side fractional-order derivatives $^{RL}D_{a+}^\alpha f$ and $^{RL}D_{b-}^\alpha f$ of order $\alpha \in \mathbb{R}$ are defined by
\begin{align}
    \left( ^{RL}{\mathcal{D}}_{a+}^\alpha f \right)(x) 
    &= \frac{1}{\Gamma(n-\alpha)} \left( \frac{d}{dx} \right)^n \int_a^x \frac{f(t)\, dt}{(x-t)^{\alpha-n+1}}, 
    \label{leftRL}\\
    \left( ^{RL}\mathcal{D}_{b-}^\alpha f \right)(x) 
    &= \frac{1}{\Gamma(n-\alpha)} \left( -\frac{d}{dx} \right)^n \int_x^b \frac{f(t)\, dt}{(t-x)^{\alpha-n+1}}, \label{rightRL}
\end{align}
where \( n-1 \leq \alpha \leq n \), \( x > a \) in (\ref{leftRL}), and \( x < b \) in (\ref{rightRL}).
\end{definition}

The Grünwald–Letnikov fractional-order derivative is defined as the limit of finite differences and is mathematically equivalent to the Riemann–Liouville fractional-order derivative. The Grünwald–Letnikov fractional-order derivative plays an important role establishing fractional-order dynamical systems. The equations for a continuous-time fractional-order dynamical system can be written as follows:
\begin{equation}
H\left(\mathcal{D}^{\alpha_0\alpha_1\alpha_2\cdots\alpha_n}\right)(y_1, y_2, \cdots, y_l) = G\left(\mathcal{D}^{\beta_0\beta_1\beta_2\cdots\beta_m}\right)(u_1, u_2, \cdots, u_k), 
\end{equation}
where $y_i, u_i$ are functions of time and $H(\cdot), G(\cdot)$ are the combination laws of the fractional-order derivative operator.

A single-input single-output LTI fractional-order system can be described by a fractional differential equation of the form
\begin{equation}
    \sum_{k=0}^n a_k \mathcal{D}^{\alpha_k} y(t) = \sum_{k=0}^m b_k\mathcal{D}^{\beta_k} u(t),
\end{equation}
with a corresponding transfer function of the form:
\begin{equation}
G(s) = \frac{Y(s)}{U(s)} = \frac{\sum_{k=0}^{m} b_k s^{\beta_k}}{\sum_{k=0}^na_k s^{\alpha_k}},
\end{equation}
where \(a_k\), \(b_k \in \mathbb{R}\). The system is said to be commensurate if \(\alpha_k = \beta_k = k\alpha\), where \(\alpha \in \mathbb{R}^+\), otherwise the system is non-commensurate. 

We can use the Grünwald–Letnikov fractional-order derivative to rewrite the fractional-order differential equation as follows in the discrete-time case: 
\begin{equation}
\sum_{k=0}^n a_k \Delta_h^{\alpha_k} y(t) 
=  \sum_{k=0}^m b_k \Delta_h^{\beta_k} u(t), 
\end{equation}
with a corresponding transfer function of the following form:
\begin{equation}
G(z) = \frac{\sum_{k=0}^m b_k \left( \omega(z^{-1}) \right)^{\beta_k}}
{\sum_{k=0}^n a_k \left( \omega(z^{-1}) \right)^{\alpha_k}}, 
\end{equation}
where $\omega(z^{-1})$ is the $Z$ transform of the operator $\Delta_h^1$.

\section{Theorems and Proofs}

\subsection{System Identification}
\label{sec:system_identification}
We aim to estimate the parameters \(\Theta = \{A, B, \alpha\}\) of the following FOLTI system:
\begin{equation}
x_{k+1} = Ax_k + B u_k - \sum_{j=1}^{k+1} \psi(\alpha, j) x_{k+1-j}.
\end{equation}
To note, we can not identify \(\Theta\) jointly so we make some assumptions during the system identification.

\subsubsection{Data Generation}
In this step, we generate data following the procedure outlined below:
\begin{align}
x_1^1 &= Ax_0^1 + B u_0^1 - \psi(\alpha,1) x_0^1 + w_0^1 \notag\\
&= Ax_0^1 + B u_0^1 + C_\alpha x_0^1 + w_0^1 \\
x_1^2 &= Ax_0^2 + B u_0^2 - \psi(\alpha,1) x_0^2 + w_0^2 \notag\\
&= Ax_0^2 + B u_0^2 + C_\alpha x_0^2 + w_0^2 \\
&\notag\text{...} \\
x_1^p &= Ax_0^p + B u_0^p - \psi(\alpha,1) x_0^p + w_0^p \notag \\
&= Ax_0^p + B u_0^p + C_\alpha x_0^p + w_0^p
\end{align}
where \( x_0^i \) are the \( i \)-th initial conditions, \( x_1^i \) represents the corresponding state at the second time step generated from the initial condition, and \( w_0^i \) are independent and identically distributed (i.i.d.) white Gaussian noise for \( i = 1, \ldots, p \), and \( C_\alpha = \operatorname{diag}(\alpha_1, \alpha_2, \ldots, \alpha_n) \).

\subsubsection{Estimation}

We can write (86) as follows
\begin{align}
x_1^i &= Ax_0^i + B u_0^i + C_\alpha x_0^i + w_0^i \notag\\
&=
\underbrace{\begin{bmatrix}
\gamma_1^1 + \alpha_1 & \gamma_2^1 & \cdots & \gamma_n^1 \\
\gamma_1^2 & \gamma_2^2 + \alpha_2 & \cdots & \gamma_n^2 \\
\vdots & \vdots & \cdots & \vdots \\
\gamma_1^n & \gamma_2^n & \cdots & \gamma_n^n + \alpha_n \\
\end{bmatrix}}_{A_{\alpha}}x_0^i + 
\underbrace{\begin{bmatrix}
\beta_1^1 & \beta_2^1 & \cdots & \beta_m^1 \\
\beta_1^2 & \beta_2^2 & \cdots & \beta_m^2 \\
\vdots & \vdots & \cdots & \vdots \\
\beta_1^n & \beta_2^n & \cdots & \beta_m^n \\
\end{bmatrix}}_{B}u_0^i + w_0^i \notag\\
&=
\underbrace{\begin{bmatrix}
{x_0^i}^{\top} & 0 & \cdots & \cdots \\
0 & {x_0^i}^{\top} & 0 & \cdots \\
\vdots & \vdots & \ddots & \vdots\\
0 & \cdots & \cdots & {x_0^i}^{\top}
\end{bmatrix}}_{\pi_i}
\begin{bmatrix}
\gamma_1 \\
\vdots \\
\gamma_n
\end{bmatrix} + 
\underbrace{\begin{bmatrix}
{u_0^i}^{\top} & 0 & \cdots & \cdots \\
0 & {u_0^i}^{\top} & 0 & \cdots \\
\vdots & \vdots & \ddots & \vdots\\
0 & \cdots & \cdots & {u_0^i}^{\top} 
\end{bmatrix}}_{\phi_i}
\begin{bmatrix}
\beta_1 \\
\vdots \\
\beta_n
\end{bmatrix} + w_0^i
\end{align}
Thus, given the generated data, we solve the following least squares problem:
\begin{equation}
\underbrace{\begin{bmatrix}
x_1^1 \\
\vdots \\
x_1^p
\end{bmatrix}}_X
=
\underbrace{\begin{bmatrix}
\pi_1 \\
\vdots \\
\pi_p
\end{bmatrix}}_\pi
\underbrace{\begin{bmatrix}
\gamma_1 \\
\vdots \\
\gamma_n
\end{bmatrix}}_\gamma
+
\underbrace{\begin{bmatrix}
\phi_1 \\
\vdots \\
\phi_p
\end{bmatrix}}_\phi
\underbrace{\begin{bmatrix}
\beta_1 \\
\vdots \\
\beta_n
\end{bmatrix}}_\beta
+
\underbrace{\begin{bmatrix} 
w_0^1 \\ 
\vdots \\ 
w_0^p 
\end{bmatrix}}_\omega,
\end{equation}
\begin{equation}
X = \pi\gamma + \phi\beta + w = \begin{bmatrix} \pi & \phi \end{bmatrix}\begin{bmatrix} \gamma \\ \beta \\ \end{bmatrix} + w.
\end{equation}
Then we have the following optimization problem
\begin{equation}
\hat{\theta} = \arg\min_{\theta} \|X - \xi \theta\|_2^2,
\end{equation}
with the solution
\begin{equation}
\hat{\theta} = \left(\xi^\top \xi\right)^{-1} \xi^\top X,
\end{equation}
where \( \theta = [\gamma^\top, \beta^\top]^\top\), and \( \xi = [\pi, \phi]\).

Follow \cite{zhang2025samplingcomplexityawareframeworkdiscretetime}, we can revise the above strategy and formulate the sample complexity problem as follows:
\begin{align}
    \theta_{t+1} &= \theta_t, \notag\\
    X_t & = \xi \theta_t + w_t, 
\end{align}
where the state vector \( \theta_t = [\gamma^\top, \beta^\top]^\top \), and \( w_k \) is a white Gaussian noise vector \( w_t \sim \mathcal{N}(0, K_w) \), where \( K_w \) is a diagonal covariance matrix, and \(t = 1, 2, \dots, N\). Thus, the solution \(\hat{\theta}\) has the following Gaussian distribution:
\begin{equation}
\hat{\theta} \sim N\left(\theta, \frac{1}{N} (\xi\top \xi)^{-1} \xi\top K_w \xi (\xi\top \xi)^{-1}\right).
\end{equation}
Notice that the matrix \( A \) and the fractional order \( \alpha \) are coupled. Therefore, if the diagonal elements of \( A \) are known, the fractional order \( \alpha \) can be identified by subtracting these constant values from the corresponding positions in the estimated parameter vector \( \hat{\theta} \).

\subsection{Proof of Lemma \ref{lem:FOLTIsolution}}
\label{sec:proof_l1}
\textit{Proof.} By mathematical induction as follows:

(1) When \(t = 0, x[0] = G_0x[0] = x[0]\). When \(t = 1, x[1] = G_1x[0] + Bu[0]\)

(2) Assume we have \(x[k] = G_k x[0] + \sum_{j=0}^{k-1} G_{k-1-j} B u[j],\) when \(t = k.\)

When \(t = k+1\), 
\begin{align}
x[k+1] &= \sum_{j=0}^{k}A_jx[k-j] + Bu[k] \notag\\
       &= \sum_{j=0}^{k}(A_j(G_{k-j}x[0] + \sum_{i=0}^{k-j-1}G_{k-1-i-j}Bu[i])) + Bu[k] \notag\\
       &= \sum_{j=0}^{k}A_jG_{k-j}x[0] + \sum_{j=0}^{k}A_j(\sum_{i=0}^{k-j-1}G_{k-1-i-j}Bu[i]) + Bu[k] \notag\\
       &= G_{k+1}x[0] + \sum_{j=0}^{k}\sum_{i=0}^{k-j-1}A_j(G_{k-1-i-j}Bu[i]) + Bu[k]
\end{align}
By expanding the second term, thus
\begin{equation}
x[k+1] = G_{k+1} x[0] + \sum_{j=0}^{k} G_{k-j} B u[j]. \label{56}
\end{equation} \hfill $\square$

\subsection{Proof of Theorem \ref{thm:LQRsolution}}
\label{sec:proof_t2}
\textit{Proof of least-squares solution.} 
Rewrite as follows:

\begin{equation}
\begin{bmatrix}
x_0 \\ x_1 \\ x_2 \\ x_3 \\ \vdots \\ x_T
\end{bmatrix}
=
\underbrace{
\begin{bmatrix}
0 & 0 & 0 & 0 & \cdots & 0 \\
G_0B & 0 & 0 & 0 & \cdots & 0 \\
G_1B & G_0B & 0 & 0 & \cdots & 0 \\
G_2B & G_1B & G_0B & 0 & \cdots & 0 \\
\vdots & \vdots & \vdots & \vdots & \ddots & \vdots \\
G_{T-1}B & G_{T-2}B & G_{T-3}B & G_{T-4}B & \cdots & G_0B
\end{bmatrix}
}_{G}
\begin{bmatrix}
u_0 \\ u_1 \\ u_2 \\ u_3 \\ \vdots \\ u_{T-1}
\end{bmatrix}
+
\underbrace{
\begin{bmatrix}
I \\ G_1 \\ G_2 \\ G_3 \\ \vdots \\ G_T
\end{bmatrix}
}_{H} x_0.
\end{equation}

\begin{equation}
\label{58}
X = GU + Hx_0
\end{equation}

Rewrite as follows:
\begin{equation}
J_T(U) = \min_{U}\left\{X^\top\bar{Q}X + U^\top\bar{R}U\right\} \label{59}
\end{equation}
where 
\begin{equation}
\bar{Q} = \begin{bmatrix}
Q & 0 & 0 & 0 & \cdots & 0 \\
0 & Q & 0 & 0 & \cdots & 0 \\
0 & 0 & Q & 0 & \cdots & 0 \\
0 & 0 & 0 & Q & \cdots & 0 \\
\vdots & \vdots & \vdots & \vdots & \ddots & \vdots \\
0 & 0 & 0 & 0 & \cdots & Q_f
\end{bmatrix}
\notag\end{equation}
\begin{equation}
\bar{R} = \begin{bmatrix}
R & 0 & 0 & 0 & \cdots & 0 \\
0 & R & 0 & 0 & \cdots & 0 \\
0 & 0 & R & 0 & \cdots & 0 \\
0 & 0 & 0 & R & \cdots & 0 \\
\vdots & \vdots & \vdots & \vdots & \ddots & \vdots \\
0 & 0 & 0 & 0 & \cdots & R
\end{bmatrix}
\end{equation}

Substitute (\ref{59}) using (\ref{58}):
\begin{equation}
\min_{U}J_T(U) = \min_{U}\left\{(GU + Hx_0)^\top\bar{Q}(GU + Hx_0) + U^\top\bar{R}U\right\}
\end{equation}

The solution for the least squares problem is
\begin{align}
(G^\top\bar{Q}G + \bar{R})U &= -G^\top\bar{Q}^\top Hx_0  \notag\\
U &= -(G^\top \bar{Q}G + \bar{R})^{-1}G^\top \bar{Q}^\top Hx_0
\end{align}  \hfill $\square$

\textit{Proof of Lagrange multiplier solution.}
\label{Lagmul}
\begin{lemma}[Lagrange multiplier condition]
\label{lem:LMsolution}
The Lagrangian function \(\mathcal{L}\) is given by:

\begin{equation}
\mathcal{L}(x, u, \lambda) = \sum_{k=0}^{T-1} \left( x_k^\top Q x_k + u_k^\top R u_k + \lambda_{k+1}^\top ( A x_k + B u_k - \Delta^\alpha x_{k+1}) \right) + x_T^\top Q_f x_T.
\end{equation}
and the solution is given by:
\begin{align}
u_k &= -\frac{1}{2} R^{-1} B^\top \lambda_{k+1},\notag \\
\lambda_{k} &= 2 Q x_k + A^\top \lambda_{k+1} - \sum_{i=k+1}^{T}D(\alpha, i-k)\lambda_{i} 
\end{align}
with \(x_0 = x_0\) and \(\lambda_{T} = 2Q_fx_T\).
\end{lemma}

\textit{Proof of Lemma 1.} Taking the partial derivative with respect to \(u_k, x_k, \lambda_k\), we have

\begin{equation}
\frac{\partial \mathcal{L}}{\partial u_k} = 2 R u_k + B^\top \lambda_{k+1} = 0 \implies u_k = -\frac{1}{2} R^{-1} B^\top \lambda_{k+1},  \label{65}
\end{equation}

\begin{equation}
\frac{\partial \mathcal{L}}{\partial x_k} = 2 Q x_k + A^\top \lambda_{k+1} -\sum_{i=k}^{T}D(\alpha, i-k)\lambda_{i} = 0, \label{66}
\end{equation}

\begin{equation}
\implies \lambda_{k} = 2 Q x_k + A^\top \lambda_{k+1} - \sum_{i=k+1}^{T}D(\alpha, i-k)\lambda_{i} \label{67}
\end{equation}

\begin{equation}
\frac{\partial \mathcal{L}}{\partial \lambda_k} = A x_k + B u_k - \Delta^\alpha x_{k+1} = 0. 
\end{equation}
Explanation for Eq. (\ref{66}):
From Eq. (\ref{3}), we have
\begin{equation}
\Delta^\alpha x_{k} = \sum_{j=0}^k D(\alpha, j) x[k - j]
\end{equation}
Then, we have
\begin{align}
\frac{\partial}{\partial x_k} \left( \lambda_{k}^\top \Delta^\alpha x_{k} \right) &= D(\alpha, 0)\lambda_{k} \notag\\
\frac{\partial}{\partial x_k} \left( \lambda_{k+1}^\top \Delta^\alpha x_{k+1} \right) &= D(\alpha, 1)\lambda_{k+1} \notag\\
\vdots \notag\\
\frac{\partial}{\partial x_k} \left( \lambda_{T}^\top \Delta^\alpha x_{T} \right) &= D(\alpha, T-k)\lambda_{T} 
\end{align} \hfill $\square$ 

Solve the \(\lambda\) jointly and then substitute in (\ref{65}) to get \(u_k\).

Note we have the following equations by (\ref{56}), (\ref{65}) and (\ref{66}):
\begin{align}
u_k &= -\frac{1}{2} R^{-1} B^\top \lambda_{k+1}, \notag\\
\lambda_{k} &= 2 Q x_k + A^\top \lambda_{k+1} - \sum_{i=k+1}^{T}D(\alpha, i-k)\lambda_{i} \notag\\
x[k] &= G_k x[0] + \sum_{j=0}^{k-1} G_{k-1-j} B u[j]
\end{align}
Obeserve that
\begin{equation}
\lambda_k = \begin{bmatrix}
2QG_{k} & -QG_{k-1}BR^{-1}B^\top & \cdots & -QG_{0}BR^{-1}B^\top & A^\top-D(\alpha,1) & \cdots &-D(\alpha, T-k) 
\end{bmatrix}
\begin{bmatrix}
x_0 \\ \lambda_1 \\ \vdots \\ \lambda_{k} \\ \lambda_{k+1} \\ \vdots \\ \lambda_{T}    
\end{bmatrix}
\end{equation}
We have the following matrix form, where \(G_\lambda\) and \(I - G_\lambda\) are block Toeplitz matrices (see Definition \ref{def:Toeplitz}).
\begin{align}
\begin{bmatrix}
\lambda_1 \\ \lambda_2 \\ \lambda_3 \\ \vdots \\ \lambda_T
\end{bmatrix}
&=
\underbrace{
\begin{bmatrix}
-QG_{0}BR^{-1}B^\top & A^\top - D(\alpha,1) & -D(\alpha,2)  & \cdots & -D(\alpha,T-1) \\
-QG_{1}BR^{-1}B^\top & -QG_{0}BR^{-1}B^\top & A^\top-D(\alpha, 1) & \cdots & -D(\alpha,T-2) \\
-QG_{2}BR^{-1}B^\top & -QG_{1}BR^{-1}B^\top & -QG_{0}BR^{-1}B^\top & \cdots & -D(\alpha, T-3) \\
\vdots & \vdots & \vdots & \vdots & \ddots \\
-QG_{T-1}BR^{-1}B^\top & -QG_{T-2}BR^{-1}B^\top & \cdots & \cdots & -QG_{0}BR^{-1}B^\top
\end{bmatrix}
}_{G_\lambda}
\begin{bmatrix}
\lambda_1 \\ \lambda_2 \\ \lambda_3 \\ \vdots \\ \lambda_T
\end{bmatrix} \notag\\
&+ 2
\underbrace{
\begin{bmatrix}
 QG_1 \\ QG_2 \\ QG_3 \\ \vdots \\ QG_T
\end{bmatrix}
}_{H_\lambda} x_0.
\end{align}
\begin{align}
\lambda &= G_\lambda\lambda + 2H_\lambda x_0 \notag \\
(I &- G_\lambda)\lambda = 2H_\lambda x_0 \notag\\
\lambda &= 2(I - G_\lambda)^{-1}H_\lambda x_0
\end{align}

\begin{definition}[Block Toeplitz matrix]
\label{def:Toeplitz}
A \textit{block Toeplitz matrix} is a block matrix where the block structure follows a Toeplitz pattern. Specifically, let \( \mathscr{T} \in \mathbb{R}^{mn \times mn} \) be partitioned into \( m \times m \) blocks, each of size \( n \times n \). The matrix \( \mathscr{T} \) is defined as:
\[
\mathscr{T} = 
\begin{bmatrix}
\mathscr{A}_0 & \mathscr{A}_{-1} & \cdots & \mathscr{A}_{-(m-1)} \\
\mathscr{A}_1 & \mathscr{A}_0 & \cdots & \mathscr{A}_{-(m-2)} \\
\vdots & \vdots & \ddots & \vdots \\
\mathscr{A}_{m-1} & \mathscr{A}_{m-2} & \cdots & \mathscr{A}_0
\end{bmatrix},
\]
where each \( \mathscr{A}_k \in \mathbb{R}^{n \times n} \) represents a block matrix.
\end{definition}

Using (\ref{65}), we have 
\begin{equation}
U = -R^{-1}B^\top \otimes (I - G_\lambda)^{-1}H_\lambda x_0
\end{equation} \hfill $\square$ 

\subsection{Proof of Theorem \ref{thm:sample_complexity_1}}
\label{sec:proof_t3}
\textit{Proof of least-squares sample complexity result.} 
If we know \(A\) and \(\alpha\), then \(\theta\) will reduce to \(vectorize(B)\) and the distribution reduces to the following:
\begin{equation}
\hat{\theta} = vectorize(\hat{B}) \sim  N\left(vectorize(B), \frac{1}{N} (\phi\top \phi)^{-1} \phi\top K_w \phi (\phi\top \phi)^{-1}\right).
\end{equation}
Then
\begin{align}
\mathbb{E} \left[| \hat{J} - J |\right]  &= \mathbb{E} \left[\| \hat{J} - J \|_2 \right]
= \mathbb{E} \left[ \|\hat{a} - a\|_2 \right] \notag\\
&= \mathbb{E} \left[ \| z^\top \left( \underbrace{\hat{P} \left( \hat{P}^\top S \hat{P} + \bar{R} \right)^{-1} \hat{P}^\top}_{F(\hat{P})} 
- \underbrace{P \left( P^\top S P + \bar{R} \right)^{-1} P^\top}_{F(P)} \right) z \|_2 \right] \notag \\
& \leq \mathbb{E}\left[\|F(\hat{P}) - F(P)\|_2 \right] \|z\|_2^2
\end{align}
We rewrite \(F(\hat{P}) - F(P)\) as follows:
\begin{align}
F(\hat{P}) - F(P) &= \hat{P} (\hat{P}^\top S \hat{P} + \bar{R})^{-1} (\hat{P}^\top - P^\top) \notag\\
&\quad + \left( \hat{P} (\hat{P}^\top S \hat{P} + \bar{R})^{-1} - P (P^\top S P + \bar{R})^{-1} \right) P^\top \notag\\
&= \hat{P} \left( \hat{P}^\top S \hat{P} + \bar{R} \right)^{-1} \left( \hat{P}^\top - P^\top\right) \notag \\
&\quad + \left( (\hat{P} - P) (\hat{P}^\top S \hat{P} + \bar{R})^{-1} + P \left( \left( \hat{P}^\top S \hat{P} + \bar{R} \right)^{-1} - \left( P^\top S P + \bar{R} \right)^{-1} \right) \right) P^\top \notag\\
&= \hat{P} \left( \hat{P}^\top S \hat{P} + \bar{R} \right)^{-1} \left( \hat{P}^\top - P^\top\right) \notag \\
&\quad + (\hat{P} - P) (\hat{P}^\top S \hat{P} + \bar{R})^{-1} P^\top + P \left( \left( \hat{P}^\top S \hat{P} + \bar{R} \right)^{-1} - \left( P^\top S P + \bar{R} \right)^{-1} \right) P^\top
\end{align}
Then we have 
\begin{align}
\mathbb{E} \left[| \hat{J} - J |\right] & \leq \mathbb{E}\left[\|F(\hat{P}) - F(P)\|_2 \right] \|z\|_2^2 \notag \\
& \leq \underbrace{\mathbb{E}\left[ \left\|\hat{P} \left( \hat{P}^\top S \hat{P} + \bar{R} \right)^{-1} \left( \hat{P}^\top - P^\top\right) \right\|_2\right]}_{(i)} \left\| z \right\|_2^2\notag \\
&\quad + \underbrace{\mathbb{E} \left[ \left\|(\hat{P} - P) (\hat{P}^\top S \hat{P} + \bar{R})^{-1} P^\top \right\|_2 \right]}_{(ii)} \left\| z \right\|_2^2\notag \\
&\quad+ \underbrace{\mathbb{E} \left[ \left\| P \left( \left( \hat{P}^\top S \hat{P} + \bar{R} \right)^{-1} - \left( P^\top S P + \bar{R} \right)^{-1} \right) P^\top \right\|_2 \right]}_{(iii)}  \left\| z \right\|_2^2 
\end{align}
We bound term (i) as follows:

\begin{align}
(i) \quad &\mathbb{E} \left[ \left\| \hat{P} \left( \hat{P}^\top S \hat{P} + \bar{R} \right)^{-1} \left( \hat{P}^\top - P^\top \right) \right\|_2 \right] \notag\\
&\leq \mathbb{E} \left[ \left\| \hat{P} \right\|_2 \left\| \left( \hat{P}^\top S \hat{P} + \bar{R} \right)^{-1} \right\|_2 \left\| \hat{P} - P \right\|_2 \right] \notag\\
&\leq \left\| \bar{R}^{-1} \right\|_2 \mathbb{E} \left[ \left\| \hat{P} \right\|_2 \left\| \hat{P} - P \right\|_2 \right].
\end{align}

\noindent
We now use the following:
\[
\begin{cases}
\left\| \hat{P} \right\|_2 = \left\| \hat{P} - P + P \right\|_2 \leq \left\| \hat{P} - P \right\|_2 + \left\| P \right\|_2, \\
\left\| \hat{P} \right\|_2 \left\| \hat{P} - P \right\|_2 \leq ( \left\| \hat{P} - P \right\|_2 + \left\| P \right\|_2 ) \left\| \hat{P} - P \right\|_2 = \left\| \hat{P} - P \right\|_2^2 + \left\| P \right\|_2 \left\| \hat{P} - P \right\|_2.
\end{cases}
\]

\begin{align}
\quad &\leq \left\| \bar{R}^{-1} \right\|_2 \mathbb{E} \left[ \left\| \hat{P} - P \right\|_2^2 + \left\| P \right\|_2 \left\| \hat{P} - P \right\|_2 \right] \notag\\
&= \left\| \bar{R}^{-1} \right\|_2 \mathbb{E} \left[ \left\| \hat{B} - B \right\|_2^2 + \left\| P \right\|_2 \left\| \hat{B} - B \right\|_2 \right] \notag\\
&\leq \left\| \bar{R}^{-1} \right\|_2 \mathbb{E} \left[ \left\| \hat{B} - B \right\|_F^2 + \left\| P \right\|_2 \left\| \hat{B} - B \right\|_F \right] \notag\\
&\leq \left\| \bar{R}^{-1} \right\|_2 \left( \text{Tr}(K_{B}) + \left\| P \right\|_2 \sqrt{\text{Tr}(K_{B})} \right) \notag\\
&= \left\| \bar{R}^{-1} \right\|_2 \ \left( \text{Tr}(K_{B}) + \left\| B \right\|_2 \sqrt{\text{Tr}(K_{B})}\right).
\end{align}

We bound (ii) as follows:
\begin{align}
(ii) \quad & \mathbb{E} \left[ \left\|(\hat{P} - P) (\hat{P}^\top S \hat{P} + \bar{R})^{-1} P^\top \right\|_2 \right] \notag\\
&\leq \left\| \bar{R}^{-1} \right\|_2 \mathbb{E} \left[ \left\| \hat{P} - P \right\|_2 \right] \left\| B \right\|_2 \notag\\
&= \left\| \bar{R}^{-1} \right\|_2 \mathbb{E} \left[ \left\| \hat{B} - B \right\|_2 \right] \left\| B \right\|_2 \notag \\
&\leq \left\| \bar{R}^{-1} \right\|_2 \mathbb{E} \left[ \left\| \hat{B} - B \right\|_F \right] \left\| B \right\|_2 \notag \\
&\leq \left\| \bar{R}^{-1} \right\|_2 \sqrt{\text{Tr}(K_B)} \left\| B \right\|_2.
\end{align}

We bound (iii) as follows:
\begin{align}
(3) \quad &\mathbb{E} \left[ \left\| P \left(\left(  \hat{P}^\top S \hat{P} + \bar{R} \right)^{-1} - \left( P^\top S P + \bar{R} \right)^{-1} \right) P^\top \right\|_2 \right] \notag\\
&\leq \left\| P \right\|_2^2 \mathbb{E} \left[ \left\| \left( \hat{P}^\top S \hat{P} + \bar{R} \right)^{-1} - \left( P^\top S P + \bar{R} \right)^{-1} \right\|_2 \right] \notag\\
&\leq \left\| P \right\|_2^2 \mathbb{E} \left[ \left\| -\left( P^\top S P + \bar{R} \right)^{-1} \left( \hat{P}^\top S \hat{P} - P^\top S P \right) \left( \hat{P}^\top S \hat{P} + \bar{R} \right)^{-1} \right\|_2 \right] \notag\\
&\leq \left\| P \right\|_2^2 \left\| \bar{R}^{-1} \right\|_2^2 \mathbb{E} \left[ \left\| \hat{P}^\top S \hat{P} - P^\top S P \right\|_2 \right] \notag\\
&= \left\| P \right\|_2^2 \left\| \bar{R}^{-1} \right\|_2^2 \mathbb{E} \left[ \left\| \hat{P}^\top S (\hat{P} - P) + \left(\hat{P}^\top - P^\top\right) S P) \right\|_2 \right] \notag\\
&= \left\| P \right\|_2^2 \left\| \bar{R}^{-1} \right\|_2^2 \mathbb{E} \left[ \left\|  \left( \hat{P}^\top - P^\top \right) S  (\hat{P} - P) + P^\top S (\hat{P} - P) + \left( \hat{P}^\top - P^\top \right) SP \right\|_2 \right] \notag\\
&\leq \left\| P \right\|_2^2 \left\| \bar{R}^{-1} \right\|_2^2 \mathbb{E} \left[ \left\| \left( \hat{P}^\top - P^\top \right) S (\hat{P} - P) \right\|_2 + \left\| P^\top S (\hat{P} - P) \right\|_2 + \left\| \left( \hat{P}^\top - P^\top \right) S P \right\|_2 \right] \notag\\
&\leq \left\| P \right\|_2^2 \left\| \bar{R}^{-1} \right\|_2^2 \left( \left\| S \right\|_2 \text{Tr}(K_B) + \left\| B \right\|_2 \left\| S \right\|_2 \sqrt{\text{Tr}(K_B)} + \left\| S \right\|_2 \left\| B \right\|_2 \sqrt{\text{Tr}(K_B)} \right) \notag\\
&= \left\| B \right\|_2^2 \left\| \bar{R}^{-1} \right\|_2^2 \left( \left\| S \right\|_2 \text{Tr}(K_B) + 2 \left\| B \right\|_2 \left\| S \right\|_2 \sqrt{\text{Tr}(K_B)} \right).
\end{align}

Put everything together, we have the following bound:
\begin{align}
\mathbb{E} \left[ \left| \hat{J} - J \right| \right] 
&\leq \left\| z \right\|_2^2 \Bigg[ \left\| \bar{R}^{-1} \right\|_2 \left( \text{Tr}(K_{B}) + \left\| B \right\|_2 \sqrt{\text{Tr}(K_{B})} \right) \notag \\
&\quad + \left\| \bar{R}^{-1} \right\|_2 \sqrt{\text{Tr}(K_B)} \left\| B \right\|_2 \notag \\
&\quad + \left\| B \right\|_2^2 \left\| \bar{R}^{-1} \right\|_2^2 \left( \left\| S \right\|_2 \text{Tr}(K_B) + 2 \left\| B \right\|_2 \left\| S \right\|_2 \sqrt{\text{Tr}(K_B)} \right) \Bigg] \notag \\
& =\left\| z \right\|_2^2 \Bigg[\left( \left\| \bar{R}^{-1} \right\|_2 + \left\| B \right\|_2^2 \left\| \bar{R}^{-1} \right\|_2^2 \left\| S \right\|_2 \right) \text{Tr}(K_B) \notag\\
&\quad + \left( 2 \left\| \bar{R}^{-1} \right\|_2 \left\| B \right\|_2 + 2 \left\| B \right\|_2^3 \left\| \bar{R}^{-1} \right\|_2^2 \left\| S \right\|_2 \right) \sqrt{\text{Tr}(K_B)} \Bigg] \notag \\
&= \|z\|_2^2 \| R^{-1}\|_2 \left(1 + \|B\|_2^2 \|R^{-1}\|_2 \|S\|_2 \right) \left(\text{Tr}(K_B) + 2 \|B \|_2 \sqrt{\text{Tr}(K_B)} \right). 
\end{align}  \hfill $\square$ 

\textit{Proof of Lagrange multiplier sample complexity result.} 
\begin{align}
U &= -R^{-1} B^\top \otimes (I - G_\lambda)^{-1} H_\lambda x_0 \notag\\
  &= - 
\underbrace{\begin{bmatrix}
R^{-1}B^\top & & & \\
& \ddots & & \\
& & \ddots & \\
& & & R^{-1}B^\top
\end{bmatrix}}_{D_{RB}}
(I - G_\lambda)^{-1} H_\lambda x_0 \notag\\
  &= - D_{RB} (I - G_\lambda)^{-1} H_\lambda x_0 \notag\\
  &= - 
\underbrace{\begin{bmatrix}
R^{-1} & & & \\
& \ddots & & \\
& & \ddots & \\
& & & R^{-1}
\end{bmatrix}}_{\bar{R}^{-1}}
\underbrace{\begin{bmatrix}
B^\top & & & \\
& \ddots & & \\
& & \ddots & \\
& & & B^\top
\end{bmatrix}}_{P^\top}
(I - G_\lambda)^{-1} H_\lambda x_0 \notag\\
  &= - \bar{R}^{-1} P^\top (I - G_\lambda)^{-1} H_\lambda x_0
\end{align}

\begin{align}
J  &= x_0^\top H^\top \bar{Q} G U + x_0^\top H^\top \bar{Q} H x_0 \notag \\
  &= -x_0^\top H^\top \bar{Q} G D_{RB}\left( I - G_{\lambda} \right)^{-1} H_{\lambda} x_0 + x_0^\top H^\top \bar{Q} H x_0 \notag \\
  &= -\underbrace{x_0^\top H^\top \bar{Q} G_d P \bar{R}^{-1} P^\top \left( I - G_{\lambda} \right)^{-1} H_{\lambda} x_0}_a + \underbrace{x_0^\top H^\top \bar{Q} H x_0}_b 
\end{align}
\begin{align}
\mathbb{E} \left[| \hat{J} - J |\right]  &= \mathbb{E} \left[\| \hat{J} - J \|_2 \right]
= \mathbb{E} \left[ \|\hat{a} - a\|_2 \right] 
\end{align}
Then
\begin{align}
\mathbb{E}\left[\| \hat{a} - a \|_2 \right] 
&= \mathbb{E}\left[\|x_0^\top H^\top \bar{Q} G_d \hat{P} \bar{R}^{-1} \hat{P}^\top (I - \hat{G}_\lambda)^{-1} H_\lambda x_0 
- x_0^\top H^\top \bar{Q} G_d P \bar{R}^{-1} P^\top (I - G_\lambda)^{-1} H_\lambda x_0 \|_2 \right] \notag\\
&= \mathbb{E}\left[\|x_0^\top H^\top \bar{Q} G_d \left( \hat{P} \bar{R}^{-1} \hat{P}^\top (I - \hat{G}_\lambda)^{-1} 
- P \bar{R}^{-1} P^\top (I - G_\lambda)^{-1} \right) H_\lambda x_0 \|_2 \right] \notag\\
&\leq \|x_0^\top H^\top \bar{Q} G_d \|_2 \|H_\lambda x_0\|_2 \, \mathbb{E}\left[\| \hat{P} \bar{R}^{-1} \hat{P}^\top (I - \hat{G}_\lambda)^{-1} 
- P \bar{R}^{-1} P^\top (I - G_\lambda)^{-1} \|_2 \right].
\end{align}
Then 
\begin{align}
&\mathbb{E}\left[\| \hat{P} \bar{R}^{-1} \hat{P}^\top (I - \hat{G}_\lambda)^{-1} - P \bar{R}^{-1} P^\top (I - G_\lambda)^{-1} \|_2\right] \notag\\
&= \mathbb{E}\left[\| (\hat{P} - P) \bar{R}^{-1} \hat{P}^\top (I - \hat{G}_\lambda)^{-1} + P \bar{R}^{-1} \left(\hat{P}^\top (I - \hat{G}_\lambda)^{-1} - P^\top (I - G_{\lambda})^{-1} \right) \|_2\right] \notag\\
&= \mathbb{E}\left[\| (\hat{P} - P) \bar{R}^{-1} \hat{P}^\top (I - \hat{G}_\lambda)^{-1} 
+ P \bar{R}^{-1} \left((\hat{P}^\top - P^\top) (I - \hat{G}_\lambda)^{-1} + P^\top (I - \hat{G}_{\lambda})^{-1} - P^\top (I - G_{\lambda})^{-1} \right) \|_2\right] \notag\\
&= \mathbb{E}\left[\| (\hat{P} - P) \bar{R}^{-1} \hat{P}^\top (I - \hat{G}_\lambda)^{-1} 
+ P \bar{R}^{-1} (\hat{P}^\top - P^\top) (I - \hat{G}_\lambda)^{-1} + P \bar{R}^{-1}P^\top \left((I - \hat{G}_{\lambda})^{-1} - (I - G_{\lambda})^{-1} \right) \|_2\right] \notag \\
&\leq \underbrace{\mathbb{E} \left[ \| (\hat{P} - P) \bar{R}^{-1} \hat{P}^\top (I - \hat{G}_\lambda)^{-1} \|_2 \right]}_{(i)} + \underbrace{\mathbb{E} \left[ \| P \bar{R}^{-1} (\hat{P}^\top - P^\top) (I - \hat{G}_\lambda)^{-1}\|_2 \right]}_{(ii)} \notag \\
&\quad + \underbrace{\mathbb{E} \left[ \|  P \bar{R}^{-1}P^\top \left((I - \hat{G}_{\lambda})^{-1} - (I - G_{\lambda})^{-1} \right)\|_2 \right]}_{(iii)} 
\end{align}
Let us rewrite \(G_\lambda\) as follows:
\begin{align}
G_\lambda &= L_d + L_u \notag \\
&= -
\underbrace{\begin{bmatrix}
Q G_0 & 0 & \dots & 0 \\
Q G_1 & Q G_0 & \dots & 0 \\
\vdots & \vdots & \ddots & \vdots \\
Q G_{T-1} & Q G_{T-2} & \dots & Q G_0
\end{bmatrix}}_{L_{QG}}
\underbrace{\begin{bmatrix}
BR^{-1}B^\top & & & \\
& \ddots & & \\
& & \ddots & \\
& & & BR^{-1}B^\top
\end{bmatrix}}_{D_{BRB}} + L_u \notag\\
&= - 
\underbrace{\begin{bmatrix}
Q& & & \\
& \ddots & & \\
& & \ddots & \\
& & & Q
\end{bmatrix}}_{D_Q}
\underbrace{\begin{bmatrix}
G_0 & 0 & \dots & 0 \\
G_1 & G_0 & \dots & 0 \\
\vdots & \vdots & \ddots & \vdots \\
G_{T-1} & G_{T-2} & \dots & G_0
\end{bmatrix}}_{L_G} D_{BRB} + L_u \notag \\
&= - D_Q L_G D_{BRB} + L_u,
\end{align}
where 
\begin{align}
L_u = 
\begin{bmatrix}
0 & A^\top - D(\alpha,1) & -D(\alpha,2)  & \cdots & -D(\alpha,T-1) \\
0 & 0 & A^\top-D(\alpha, 1) & \cdots & -D(\alpha,T-2) \\
0 & 0 & 0 & \cdots & -D(\alpha, T-3) \\
\vdots & \vdots & \vdots & \vdots & \ddots \\
0 & 0 & \cdots & \cdots & 0
\end{bmatrix}
\end{align}
Then using the psd assumption \(L_{QG}^{-1}(I - L_u) \succeq 0\), 
\begin{align}
\| (I - G_\lambda)^{-1} \|_2 
&= \| (I - L_u + D_Q L_G D_{BRB})^{-1} \|_2 \notag \\
&= \| \left[D_Q L_G\left((D_Q L_G)^{-1}(I - L_u) + D_{BRB}\right)\right]^{-1} \|_2 \notag \\
&\leq \|(D_Q L_G)^{-1} \|_2 \| \left((D_Q L_G)^{-1}(I - L_u) + D_{BRB}\right)^{-1} \|_2 \notag \\
&\leq \|(D_Q L_G)^{-1} \|_2 \| \left((D_Q L_G)^{-1}(I - L_u)\right)^{-1} \|_2 \notag \\
&\leq \|(L_{QG})^{-1}\|_2 \|L_{QG}\|_2 \| (I - L_u)^{-1} \|_2.
\end{align}
We bound \((i)\) as follows:
\begin{align}
&\mathbb{E}\left[\| (\hat{P} - P) \bar{R}^{-1} \hat{P}^\top (I - \hat{G}_\lambda)^{-1} \|_2\right] \notag \\
&\leq \mathbb{E}\left[\| \hat{P} - P \|_2 \|\bar{R}^{-1}\|_2 \|\hat{P}^\top\|_2 \|(I - \hat{G}_\lambda)^{-1}\|_2\right] \notag \\
&\leq \|\bar{R}^{-1}\|_2 \mathbb{E}\left[\| \hat{P} - P \|_2 \left(\|\hat{P} - P\|_2 + \|P\|_2\right) \|(I - \hat{G}_\lambda)^{-1}\|_2\right] \notag \\
&\leq \|\bar{R}^{-1}\|_2 \mathbb{E}\left[\| \hat{P} - P \|_2 \left(\|\hat{P} - P\|_2 + \|P\|_2\right)\right] \|(L_{QG})^{-1}\|_2 \|L_{QG}\|_2 \| (I - L_u)^{-1} \|_2 \notag \\
&\leq \|\bar{R}^{-1}\|_2 \|(L_{QG})^{-1}\|_2 \|L_{QG}\|_2 \| (I - L_u)^{-1} \|_2 \left(\mathbb{E}\left[\| \hat{B} - B \|_2^2\right] + \mathbb{E}\left[\| \hat{B} - B \|_2\right] \|B\|_2\right) \notag \\
&\leq \|\bar{R}^{-1}\|_2 \|(L_{QG})^{-1}\|_2 \|L_{QG}\|_2 \| (I - L_u)^{-1} \|_2\left(\text{Tr}(K_B) + \sqrt{\text{Tr}(K_B)} \|B\|_2\right). 
\end{align}
We bound \((ii)\) as follows:
\begin{align}
&\mathbb{E}\left[\| P \bar{R}^{-1} (\hat{P}^\top - P^\top) (I - \hat{G}_\lambda)^{-1} \|_2\right] \notag \\
&\leq \|B\|_2 \|\bar{R}^{-1}\|_2 \|(L_{QG})^{-1}\|_2 \|L_{QG}\|_2 \| (I - L_u)^{-1} \|_2 \sqrt{\text{Tr}(K_B)}. 
\end{align}
We Bound \((iii)\) as follows:
\begin{align}
\text{(iii)} \quad &\mathbb{E}\left[\| P \bar{R}^{-1} P^\top \left((I - \hat{G}_\lambda)^{-1} - (I - G_\lambda)^{-1}\right) \|_2 \right] \notag \\
&\leq \|P\|_2^2 \|\bar{R}^{-1}\|_2 \mathbb{E}\left[\| (I - \hat{G}_\lambda)^{-1} - (I - G_\lambda)^{-1} \|_2\right] \notag \\
&= \|P\|_2^2 \|\bar{R}^{-1}\|_2 \mathbb{E}\left[\| (I - \hat{G}_\lambda)^{-1} \left(\hat{G}_\lambda - G_\lambda\right) (I - G_\lambda)^{-1} \|_2\right] \notag \\
&\leq \|P\|_2^2 \|\bar{R}^{-1}\|_2 \|(L_{QG})^{-1}\|_2^2 \|L_{QG}\|_2^2 \| (I - L_u)^{-1} \|_2^2 \mathbb{E}\left[\|\hat{G}_\lambda - G_\lambda\|_2\right] \notag \\
&= \|P\|_2^2 \|\bar{R}^{-1}\|_2 \|(L_{QG})^{-1}\|_2^2 \|L_{QG}\|_2^2 \| (I - L_u)^{-1} \|_2^2 \mathbb{E}\left[\|L_{QG} (\hat{D}_{BRB} - D_{BRB})\|_2\right] \notag \\
&\leq \|P\|_2^2 \|\bar{R}^{-1}\|_2 \|(L_{QG})^{-1}\|_2^2 \|L_{QG}\|_2^3 \| (I - L_u)^{-1} \|_2^2 \mathbb{E}\left[\| \hat{B} R^{-1} \hat{B}^\top - B R^{-1} B^\top \|_2\right] \notag \\
&= \|P\|_2^2 \|\bar{R}^{-1}\|_2 \|(L_{QG})^{-1}\|_2^2 \|L_{QG}\|_2^3 \| (I - L_u)^{-1} \|_2^2 \mathbb{E}\Bigg[\| (\hat{B} - B) R^{-1} (\hat{B} - B)^\top \notag \\
&\quad + (\hat{B} - B) R^{-1} B^\top + B R^{-1} (\hat{B} - B)^\top \|_2\Bigg] \notag \\
&\leq \|B\|_2^2 \|\bar{R}^{-1}\|_2^2 \|(L_{QG})^{-1}\|_2^2 \|L_{QG}\|_2^3 \| (I - L_u)^{-1} \|_2^2 \left( \text{Tr}(K_B) + 2 \|B\|_2 \sqrt{\text{Tr}(K_B)}\right). 
\end{align}
Using \(\| (I - L_u)^{-1} \|_2 = 1\) and putting everything together we have
\begin{align}
&\mathbb{E} \left[| \hat{J} - J |\right] \notag \\
\quad &\leq  \|z\|_2 \|H_{\lambda}x_0 \|_2 \| R^{-1}\|_2 \|\mathbb{L}\|_2 \left(1 + \| B\|_2^2 \| R^{-1}\|_2 \|\mathbb{L}\|_2 \|L_{QG}\|_2\right)\Bigg[ \text{Tr}(K_B) + 2\|B \|_2 \sqrt{\text{Tr}(K_B)} \Bigg], \notag \\
&\textit{where} \; \|\mathbb{L}\|_2 = \|(L_{QG})^{-1}\|_2 \|L_{QG}\|_2.
\end{align} \hfill $\square$ 

\subsection{Proof of Corollary \ref{cor:simplified_sample_complexity}}
\label{sec:proof_c4}
\textit{Proof.} We first expand \(K_B\) as follows
\begin{align}
K_B &= \frac{1}{N} \left( \phi^\top \phi \right)^{-1} \phi^\top \sigma_w^2 I \phi \left( \phi^\top \phi \right)^{-1} \notag\\
    &= \frac{\sigma_w^2}{N} \left( \phi^\top \phi \right)^{-1} \notag\\
    &= \frac{\sigma_w^2}{N} \left[ \sum_{i=1}^p \phi_i^\top \phi_i \right]^{-1},
\end{align}
where
\begin{align}
\sum_{i=1}^p \phi_i^\top \phi_i &= 
\begin{bmatrix}
\sum_{i=1}^p u_0^{i} {u_0^{i}}^\top & \cdots & 0 \\
\vdots & \ddots & \vdots \\
0 & \cdots & \sum_{i=1}^p u_0^{i} {u_0^{i}}^\top
\end{bmatrix}.
\end{align}
Then we have

\begin{align}
    \text{Trace}(K_B) &= \frac{\sigma_w^2}{N} \, \mathbb{E}\left[\text{Trace}\left(\left[\sum_{i=1}^p \phi_i^\top \phi_i \right]^{-1}\right)\right] \notag\\
    &= \frac{n \sigma_w^2}{N} \mathbb{E}\left[ \text{Trace} \left( \left( \sum_{i=1}^p u_0^i {u_0^i}^\top \right)^{-1} \right) \right] \notag \\
    &= \frac{n \sigma_w^2}{N} \, \text{Trace} \left( \mathbb{E} \left[ \left( \sum_{i=1}^p u_0^i {u_0^i}^\top \right)^{-1} \right] \right).
\end{align}

\[
\text{(1)} \quad \left\{
\begin{aligned}
    & u_0^i \sim \mathcal{N}(0, I) \implies \sum_{i=1}^p u_0^i {u_0^i}^\top \sim \mathcal{W}(I, p), \quad \text{Wishart Distribution \cite{wishart1928generalised}}, \\
    & \implies \left( \sum_{i=1}^p u_0^i {u_0^i}^\top \right)^{-1} \sim \mathcal{W}^{-1}(I, p), \quad \text{Inverse Wishart Distribution},\\
    & \implies \mathbb{E} \left[ \left( \sum_{i=1}^p u_0^i {u_0^i}^\top \right)^{-1} \right] = \frac{I}{p - m - 1}, \quad \text{for } p > m + 1.
\end{aligned}
\right.
\]

\begin{align}
    \text{Trace}(K_B) &\overset{(1)}{=} \frac{n \sigma_w^2}{N} \, \text{Trace} \left( \frac{I}{p - m - 1} \right) \notag \\
    &= \frac{n m\sigma_w^2}{N(p - m - 1)}, \quad \text{for } p > m + 1.
\end{align} \hfill $\square$ 

\section{Experiment Details}
\label{supsec:exp}

\subsection{Model Architecture}
\label{sec:modeldetail}

Our proposed Fractional-Order Learning for Optimal Control Framework (FOLOC) is a deep learning framework designed for fractional-order optimal control tasks, combining the strengths of nerual operater, sequential modeling, and parameter regression. The architecture is structured into four key components, enabling end-to-end learning of complex control dynamics from system states and parameters. Fig. \ref{fig:model architecture} illustrates the overall pipeline.

\subsubsection{System Identification}
The system identification module is designed to infer fractional-order time-invariant system parameters, including the fractional-order \(\alpha\) of size $n$ and the constant matrices $A$ and $B$ of sizes $n \times n$ and $n \times m$ respectively, as introduced in Eq. \ref{con:A^B param}. These parameters are directly inferred from the observed control input space $\mathcal{X}$, which is formed by concatenating $x_k$ and $u_k$, where $x_k \in \mathbb{R}^{n}$ is the state vector and $u_k \in \mathbb{R}^{m}$ is the system input. This component leverages a hybrid architecture to accommodate both static and temporally correlated systems. Specifically, we use an MLP with residual skip connections and a Sequence Model (e.g., Recurrent Neural Networks, Gated Recurrent Unit Networks, or Long Short-Term Memory Networks) as the backbone of system identification module.

For non-Markovian systems with long-range temporal temporal dependencies, sequential encoders—such as bidirectional LSTMs, GRUs, or RNNs—are adopted. These models process the input sequence autoregressively, capturing latent temporal patterns through hidden state evolution. Bidirectional processing further enables context aggregation from both past and future observations within the horizon T. The regressor outputs a flattened tensor, which is decomposed into $A$, $B$ and $\alpha$ via learned linear projections, ensuring dimensional consistency with the underlying physical system. We formalize this module as follows.

For non-Markovian systems, bidirectional LSTMs model temporal dependencies:
\begin{align}
h_t, c_t &= \mathrm{LSTM}\bigl([x_t;\,u_t], (h_{t-1},\,c_{t-1})\bigr),
\end{align}
where $h_t \in \mathbb{R}^{2d}$ (bidirectional hidden states). The final state $h_T$ aggregates sequence information.

Then we apply a stack of residual MLP blocks processes final state $h_T$: 
\begin{align}
\mathrm{h}^{(0)} = h_T,
\mathrm{h}^{(l)} = \mathrm{BatchNorm}\!\Bigl(
  \sigma\bigl(W^{(l)} \, \mathrm{h}^{(l-1)} + b^{(l)}\bigr)
  \;+\; \mathrm{h}^{(l-1)}
\Bigr),
\end{align}
where $\sigma$ is an activation function (e.g., ReLU) and 
$1,...,L$ indexes the residual blocks.

The regressor outputs a flattened tensor $\theta \in \mathbb{R}^{n^{2}+nm+n}$, which can be decomposed into $A$, $B$ and $\alpha$
\begin{align}
\theta &= W_{out}\mathrm{h^{(L)}}, \\
A = Reshape(\theta_{1:n^{2}}), B&=Reshape(\theta_{n^{2}+1:n^{2}+nm}),\alpha=\theta_{n^{2}+nm+1:n^{2}+nm+n}
\end{align}
The module minimizes a multi-task regression loss:
\begin{align}
\mathcal{L}_{\mathrm{s}} 
  &= \|A - A^*\|_2^2 
   + \|B - B^*\|_2^2 
   + \|\alpha - \alpha^*\|_2^2.
\end{align}




This module is trained under a multi-task objective, jointly optimizing the reconstruction of system parameters while preserving their interpretable structure (e.g., enforcing A as a state transition matrix). By unifying static and sequential modeling paradigms, the regressor adapts to diverse dynamical regimes, laying a foundation for downstream control synthesis.


\subsubsection{Temporal Embedding for $A$ Matrix Evolution}

In order to obtain the temporal embedding of matrix $A$, we propose an embedding estimation module that transforms the estimated fractional-order system parameters into time-aware representations. These representations capture both the spectral properties of the dynamics and their temporal evolution. By addressing the challenge of modeling parameter drift in partially observed systems, this approach maintains physical consistency throughout.

Our architecture implements a novel parameterization of the system matrix $A$, explicitly encoding hierarchical damping effects. This allows for both stability guarantees and adaptive temporal evolution. Building on Eq. \ref{con:Aj_eq}, the module constructs time-dependent embeddings $A_t^{emb} \in \mathbb{R}^{d}$ through a dual-branch architecture.

Let $A \in \mathbb{R}^{n \times n}$ and $\alpha \in \mathbb{R}^{n}$ denote the estimated constant matrix and fractional-order from the system identification module. To compute the embedding of the first token $A_0$, we decompose the system matrix $A_{\alpha} = A - \mathrm{diag}(a)$ through spectral analysis: 
\begin{align} 
A_{\alpha} =& V \Lambda V^{-1}, \quad \Lambda = \mathrm{diag}(\lambda_1, \ldots, \lambda_n), \\ 
h_{spec} &= \sigma\bigl(W_{\gamma} \bigl[\mathrm{Re}(\Lambda), \mathrm{Im}(\Lambda)\bigr]\bigr), 
\end{align} 
where $\lambda_i \in \mathbb{C}$ are eigenvalues encoding system stability. A residual MLP processes the concatenated real/imaginary components $[\mathrm{Re}(\Lambda), \mathrm{Im}(\Lambda)]$ to produce base embeddings $A_0$.

In parallel, time embeddings $e_t$ are generated via an embedding layer that encodes sequential time indices. These are concatenated with embeddings derived from $\alpha$, enabling the model to capture both temporal and parametric variations: 
\begin{align}
h_{\text{state}} &= \phi_x(e_t) \oplus \phi_\alpha(\alpha), \quad \phi_x, \phi_\alpha : \text{Linear Projections}. \end{align}

Next, the adaptive fused embeddings pass through a series of stacked residual multi-layer perceptron (MLP) blocks with normalization and an activation function (e.g., ReLU or GELU). This produces the final embeddings that serve as inputs to the temporal processor. This residual architecture enhances the model’s capacity to learn complex representations while preserving information from earlier layers:

\begin{align}
A^{emb} &= \mathrm{ResMLP}\bigl([h_{spec} \oplus h_{\text{state}}]; {W_l,b_l}_{l=1}^L\bigr), A^{emb} \in \mathbb{R}^{T \times hidden\_size}
\end{align}

This embedding mechanism enables the model to generate time-dependent parameter representations without directly relying on the input state vector $x$. By encoding dynamic properties through eigenvalues and temporal embeddings, the model effectively captures system behavior over time, making it suitable for tasks such as time-series forecasting and control parameter prediction.


\subsubsection{Sequence Encoder Processor}
The Sequence Processor translates spectral-temporal embeddings $A_t^{emb}$ into latent states $G_t^{enc}$ that encode the system’s temporal evolution, enabling adaptive control under time-varying dynamics. The sequence processor computes latent states $G_t^{enc}$ through a recursive hierarchical structure, enabling efficient modeling of temporal dependencies while preserving stability, rooted in the governing Eq. \ref{con:G_param}.

we implements this recurrence through a deep encoder architecture, which projects the raw recursive computation into a latent space. For systems requiring global temporal context, we use Transformer as backbone:
\begin{align}
    G_k^{enc} = TransformerEncoder(A_k^{emb} + Pk),
\end{align}
where $P_k$ is a positional encoding encoding the step $k$. Multi-head self-attention layers implicitly approximate the summation in Eq. \ref{con:G_param} by learning attention weights that mirror the  hierarchy $A_j$.

\subsubsection{Stack MLPs for Fourier Neural Operator}
The final stage of our architecture synthesizes hierarchical system representations into spatiotemporal control signals through a two-step process: feature unification via the Stack MLPs and spectral control synthesis via the Fourier Neural Operator (FNO). This combination enables efficient learning of distributed control laws while preserving physical consistency.
Given temporal states $G_k^{enc}$, system parameters $B$, LQR cost matrices $Q$,$R$, and residual skip connection input $[x;u]$, the transformation constructs an enriched input tensor $\mathcal{X} \in \mathbb{R}^{T \times d}$ for the FNO:
\begin{align}
\chi_t &= \phi_G(G_t) 
         \oplus \phi_B(B)
         \oplus \phi_Q(Q)
         \oplus \phi_R(R)
         \oplus x_t 
         \oplus u_t 
\end{align}

where $\phi$ are a series of stacked residual multi-layer perceptron (MLP) blocks and $\oplus$ denotes channel-wise concatenation.
Next, The FNO processes $\mathcal{X}$ through spectral convolutions and residual connections as we introduced in Section \ref{sec:Deep Learning Framework}:
\begin{align}
\mathcal{F}(\chi)(k) &= \mathbf{W}(k) \cdot \chi(k) + \mathbf{b}(k),
\quad k \in \mathbb{Z}^d
\end{align}
where $\chi(k) = \mathcal{F}(\chi)$ is the Fourier transform of the input, 
and $\mathbf{W}, \mathbf{b}$ are learnable parameters in frequency space. 
Only low-frequency modes $\|\mathbf{k}\| \leq k_{\max}$ are retained, 
enforcing spectral sparsity.

Then, we apply the inverse transformation to predict the optimal control $U$:
\begin{align}
U &= \mathcal{F}^{-1}\Biggl(
    \prod_{l=1}^L \Bigl( (W_l \,\mathcal{F} + K_l)\,\mathcal{F}(\chi) \Bigr)
\Biggr)
+ \mathrm{MLP}(\chi),
\end{align}
where $K_l$ are local kernel integrations in physical space.

The module minimizes the deviations between predicted $U_t$ and optimal control trajectories $U _t^*$:

\begin{align}
\mathcal{L}_u &= \frac{1}{T m} 
\sum_{t=1}^T \bigl\| U_t - U_t^{*} \bigr\|_{2}^2.
\end{align}

\subsubsection{Composite Loss Formulation}
The training objective combines fractional-order system parameter regression and control prediction errors through a multi-task loss function, enabling joint optimization of system identification and control synthesis:
\begin{align}
\mathcal{L}_{\text{total}}
&= \underbrace{\mathcal{L}_{\text{s}}}_{\text{System ID}}
 + \underbrace{\mathcal{L}_{u}}_{\text{Control Prediction}}.
\end{align}
This unified framework successfully marries physics-guided feature engineering with data-driven spectral learning, enabling real-time optimal control in high-dimensional dynamical systems and the unified loss formulation enables end-to-end learning of control policies while maintaining physically consistent parameter estimates—a critical requirement for deployment in safety-critical dynamical systems.

remark:
Specifically, the system parameters \(A, B\) and \(\alpha\) can be extracted from an intermediate layer in the network because of the underlying loss function. The intermediate variable \(A_k\) is approximated using a shallow neural network \(\mathcal{P}\) such that \(A_k = \mathcal{P}(A, \alpha,t)\) and the variable \(G_k\) is reduced to \(\mathbb{R}^n\) instead of \(\mathbb{R}^{n \times n}\). Similarly, the cost matrices \(Q\) and \(R\) are transformed into reduced representations via local transformation operators \(\mathcal{N}_Q: \mathbb{R}^{n\times n} \to \mathbb{R}^{d_Q}\) and \(\mathcal{N}_R: \mathbb{R}^{n \times m} \to \mathbb{R}^{d_R}\). The block Toeplitz structure of \(G_\lambda \) indicates that it can be fully represented using the parameters \(Q, R, A, B, \alpha, x_0\) and \(\{G_k\}_{k=0}^{T}\). Using this property, the input dimension of the FNO is determined as \(d_a = T\times(2n + m + d_Q + d_R + d_B )\), where the extra terms \(n\) and \(m\) correspond to the trajectory and control input dimensions, respectively. These additional features empirically enhance the performance of the FNO by providing more comprehensive representations of the underlying dynamics.

\subsection{Synthetic Data}
The synthetic data is generated as follows: \\
State Transition Matrix ($A$): Rondomly sampled from a uniform distribution and normalized to ensure stability by scaling with its spectral radius. \\
Control Input Matrix ($B$): Randomly sampled from a uniform distribution. \\
Initial State ($x_0$): Randomly sampled from a standard normal distribution. \\
Control Inputs ($u$): Sequence of uniformly random inputs. \\
Cost Matrices ($Q, R$): Symmetric positive semi-definite matrices constructed via \(M^\top M\) for some uniformly random $M$.

\subsection{Real-World System Dynamics}
\label{sysdyn}
In our experiments, we simulate the system dynamics to generate trajectories and optimal control sequences by randomly choosing an initial state and control inputs and then using model predictive control (MPC) to find the optimal control sequence given the quadratic cost matrices \(Q\) and \(R\).
\subsubsection{Cart Pole System Dynamics}
\label{cart_pole}
The dynamics of the cart pole is as follows:
\begin{align}
\ddot{x} &= \frac{m_p l \left( \dot{\theta}^2 \sin \theta - \ddot{\theta} \cos \theta \right) + F}{m_c + m_p}, \notag \\
\ddot{\theta} &= \frac{g \sin \theta + \cos \theta \left( \frac{-m_p l \dot{\theta}^2 \sin \theta - F}{m_c + m_p} \right)}{l \left( \frac{4}{3} - \frac{m_p \cos^2 \theta}{m_c + m_p} \right)},
\end{align}
where \(\ddot{x}\) is the horizontal acceleration of the cart, \(\ddot{\theta}\) is the acceleration of the pole, \(m_c\) is the mass of the cart, \(m_p\) is the mass of the pole, and \(g\) is the acceleration due to gravity. The control input is the external force \(F\) applied to the center of mass of the cart.

\subsubsection{Quadrotor System Dynamics}
\label{Quadrotor}
The quadrotor dynamics is as follows:
\begin{align}
\dot{p} &= v, \notag \\
\dot{q} &= \frac{1}{2} q \otimes \begin{bmatrix} 0 \\ \omega\end{bmatrix}, \notag \\
m\dot{v} &= mg + f + f_a, \notag \\
\mathcal{J} \dot{\omega} &= -\omega \times \mathcal{J} \omega + \tau.
\end{align}
Here, $p \in \mathbb{R}^{3}$ and $v \in \mathbb{R}^{3}$ represent the position and velocity in the inertial frame, \(\omega \in \mathbb{R}^3 \) is the angular velocity, and the quaternion $q$ describes the orientation with $\otimes$ denoting quaternion multiplication. The mass of the quadrotor is given by $m$, and $\mathcal{J}$ denotes the inertia matrix. Gravity is denoted by $g$, the aerodynamic force is denoted by $f_a \in \mathbb{R}^{3}$, the total thrust and body torques are denoted by \(f \in \mathbb{R}^3\) and \(\tau \in \mathbb{R}^3\).



\section{Training Parameters}
The experiments utilizing GPU acceleration on an NVIDIA A100 80GB PCIe GPU. The experiments are conducted on a machine running Ubuntu 22.04.5 LTS with an Intel(R) Xeon(R) Platinum 8358 CPU (2.60 GHz), featuring 128 cores and support for 256 concurrent threads. 

The training process is configured to optimize model performance using the Adam optimizer with a learning rate of $ 10^{-3}$. The model is trained for 300 epochs with a batch size of 128, Learning rate scheduling is managed by a \texttt{ReduceLROnPlateau} scheduler, which monitors validation loss and reduces the learning rate by a factor of 0.1 after 5 epochs without improvement. The scheduler uses a relative threshold of 0.0001 to detect improvement. The minimum learning rate is set to zero, and early learning stabilization is facilitated by an epsilon value of $1 \times 10^{-8}$. The loss function  based on the $L_p$-norm.

To ensure robust training, data normalization is applied, with both the input data and control signals ($U$) included in the modeling process. The architecture supports both encoder-only and sequence-to-sequence configurations; however, in this setup, the sequence-to-sequence mode is disabled.


\section{Metrics}

\textbf{Mean Squared Error (MSE).} The Mean Squared Error is given by

\begin{equation}
    \mathcal{L}_{\text{MSE}}(\hat{y}, y) = \frac{1}{n} \sum_{i=1}^{n} (y_i - \hat{y}_i)^2,
\end{equation}

where \( n \) denotes the number of samples, \( y_i \in \mathbb{R} \) is the ground truth value, and \( \hat{y}_i \in \mathbb{R} \) is the predicted value for the \( i \)-th sample.

\textbf{Mean Absolute Error (MAE).} The Mean Absolute Error is given by

\begin{equation}
    \mathcal{L}_{\text{MAE}}(\hat{y}, y) = \frac{1}{n} \sum_{i=1}^{n} \left| y_i - \hat{y}_i \right|,
\end{equation}

where \( n \), \( y_i \), and \( \hat{y}_i \) are defined as in the MSE formulation.

\section{Ablation Study}
\label{Abla}
In this section, we provide further analyses to uncover how the choice of encoder models and weight of identification loss affect the performance of the FOLOC framework.

\subsection{Varying Sequence Encoder Module}
To investigate the performance of different encoder layers on fractional-order system, we choose four sequence encoder variants—Transformer, RNN, LSTM, and GRU. Our analysis of sequence encoder architectures reveals statistically significant differences in performance and stability across models. The results are given in Table \ref{tab:seq_encoder_ablation}. The Transformer encoder demonstrates superior performance, achieving the lowest mean squared error (MSE = 0.0049 ± 0.00009) with minimal variance, underscoring its robustness to initialization. These results highlight the ability of our model's self-attention mechanisms to handle tasks involving global temporal dependencies. Based on our experiments, the Transformer architecture mitigates the risk of gradient vanishing or explosion by distributing information through attention, effectively stabilizing the optimization process and demonstrating strong suitability for safety-critical control tasks.

% \begin{table}[ht]
% \small  % 字体大小
% \renewcommand{\arraystretch}{1}
% \centering
% \caption{Comparison of different sequence encoders.}\label{tab:seq_encoder_ablation}
% \setlength{\tabcolsep}{8pt}
% \begin{tabular}{lccc}
% \toprule
% \textbf{Encoder-Model} & 
% \textbf{MSE} & 
% \textbf{MAE} & 
% \textbf{L2Loss} \\
% \midrule
% Transformer & 
% \textbf{0.0049 $\pm$ 0.0001} & 
% \textbf{0.0105 $\pm$ 0.00009} & 
% \textbf{0.2205 $\pm$ 0.0025 } \\
% RNN & 
% 0.0060 $\pm$ 0.0015 & 
% 0.0115 $\pm$ 0.0017 & 
% 0.2501 $\pm$ 0.0485 \\
% LSTM & 
% 0.0055 $\pm$ 0.0015 & 
% 0.0112 $\pm$ 0.0018 & 
% 0.2421 $\pm$ 0.0492 \\
% GRU & 
% 0.0068 $\pm$ 0.0024 & 
% 0.0129 $\pm$ 0.0034 & 
% 0.2838 $\pm$ 0.0878 \\
% \bottomrule
% \end{tabular}
% \end{table}

\begin{table}[ht]
\small  % 字体大小
\renewcommand{\arraystretch}{1}
\centering
\caption{Ablation study of different sequence encoders.}
\label{tab:seq_encoder_ablation}
\setlength{\tabcolsep}{15pt}
\begin{tabular}{lccc}
\toprule
\textbf{Model} 
& \textbf{MSE} \,(10\textsuperscript{-3}) 
& \textbf{MAE} \,(10\textsuperscript{-2}) 
& \textbf{LpLoss} \,(10\textsuperscript{-1}) \\
\midrule
\textbf{Transformer} 
& 4.95 $\pm$ 0.10
& 1.05 $\pm$ 0.10
& 2.21 $\pm$ 0.02 \\
RNN 
& 6.00 $\pm$ 1.46
& 1.15 $\pm$ 0.17
& 2.50 $\pm$ 0.48 \\
LSTM 
& 5.54 $\pm$ 1.49
& 1.12 $\pm$ 0.18
& 2.42 $\pm$ 0.49 \\
GRU 
& 6.78 $\pm$ 2.36
& 1.29 $\pm$ 0.34
& 2.84 $\pm$ 0.88 \\
\bottomrule
\end{tabular}
\end{table}


\subsection{Varying Identification Weight}
\label{Ident_weight}
We evaluate the performance of the FOLOC framework by varying the system identification weight $\lambda_w$ over the values $\{0.1, 0.2, 0.3, 0.4, 0.5\}$. Experimental results show that FOLOC's performance remains approximately the same, with a mean MSE of 0.52\% (standard deviation: 0.04\%) and a mean MAE of 1.09\% (standard deviation: 1.11\%). The results are given in Table \ref{id_table}.


\begin{table*}[!t]
\small  % 字体大小
\renewcommand{\arraystretch}{0.7}  %行距
\caption{Varying identification weight. All reported values are in units of \(10^{-3}\).}
\label{id_table}
\setlength{\tabcolsep}{4pt}  % 列间距
\begin{tabular*}{\textwidth}{@{\extracolsep{\fill}}c|ccccc@{}}
\toprule
Metrics& \textbf{MSE/MAE} & \textbf{MSE/MAE} & \textbf{MSE/MAE} & \textbf{MSE/MAE} & \textbf{MSE/MAE} \\
\cline{1-6}\rule{0pt}{2.5ex}
Identification  & $\lambda_w = 0.1$ & $\lambda_w = 0.2$ & $\lambda_w = 0.3$ & $\lambda_w = 0.4$ & $\lambda_w = 0.5$ \\[2pt]
\cline{2-6}\rule{0pt}{2.5ex}
 Weight& \perf{4.95$\pm$0.10}{10.5$\pm$0.10} & \textbf{\perf{4.89$\pm$0.14}{10.3$\pm$0.07}} & \perf{5.19$\pm$0.65}{11.0$\pm$0.83} & \perf{5.84$\pm$1.36}{11.4$\pm$1.69} & \perf{5.08$\pm$0.29}{11.1$\pm$0.54} \\


\bottomrule
\end{tabular*}
\end{table*}


\section{Baseline}
\label{baselti}

To the best of our knowledge, no existing end-to-end deep learning framework addresses the optimal control problem under fractional-order dynamical systems, nor is there a theoretical framework that integrates end-to-end learning with FOLTI system identification and optimal control laws. Due to the principle that fractional-order calculus generalizes integer-order calculus, we did some experiments to compare our proposed methods with the traditional theoretical end-to-end approach for optimal control in LTI systems. The end-to-end learning framework for LTI systems involves system identification using ordinary least squares, followed by solving the optimal control problem through dynamic programming \cite{anderson2007optimal}. 





\section{Additional Results}

\subsection{Test Loss of Different Time Horizons}
We present the MSE test loss across different time horizons as shown in Fig. \ref{fig:loss}, reveals critical insights into its temporal generalization capabilities. With performance steadily improving as the horizon extends, it reflects the FOLOC framework capacity to suppress high-frequency errors through spectral filtering while gradually resolving low-frequency dynamics. $T=128$ not only shows a smooth reduction in MSE but also achieves the lowest MSE loss among all tested horizons, indicating that the model better captures long-range temporal dependencies when provided with more context. The finding that extending the prediction window enhances both model robustness and accuracy confirms that, when given sufficient historical information, our approach is better equipped to handle complex dynamics of fractional-order systems.

\begin{figure}[htbp]
     \centering
     \includegraphics[width=0.48\textwidth]{plot/loss_curves.pdf}
     \vspace{0em}
     \caption{Test MSE loss under each epochs.}
     \vspace{0em}
     \label{fig:loss}
 \end{figure}


\subsection{Results of Different Fractional-Order Systems}
\label{dif_folti}
To evaluate the model’s robustness across diverse fractional-order systems, we tested FOLOC framework on a dataset constructed from 10,000 unique systems with varying parameters. Our approach demonstrates consistent performance on this heterogeneous evaluation set, achieving a mean squared error (MSE) of $(8.0025\pm1.1420) \times 10^{-3}$ and mean absolute error (MAE) of $(9.4546 \pm 0.7698) \times 10^{-3}$,  indicating stable generalization despite substantial system diversity. These results reflect the architecture’s capacity to adapt to different fractional-order systems without task-specific fine-tuning. Such findings align with theoretical expectations, as the spectral-temporal embeddings and the FOLOC framework inherently decouple system-specific features from control synthesis, enabling robust out-of-distribution operation.


\subsection{Comparison of Inference Time}
\label{compa_inf}
The experimental results demonstrate that FOLOC framework achieves superior computational efficiency compares to LTI model. Specifically, FOLOC framework requires only 1.215 ms per sample for inference, which represents a significant $44.6\%$ reduction in processing time compared to LTI model's 2.1935 ms per sample. 
\begin{table}[htbp]
\centering
\caption{Model inference time comparison.}
\begin{tabular}{lc}
\toprule
Model & Inference time (ms/sample) \\
\midrule
LTI Model & 2.1935 \\
FOLOC & 1.215 \\
\bottomrule
\end{tabular}
%\caption{Model Inference Time Comparison}
\label{tab:inference_time}
\end{table}
 

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\end{document}


% This document was modified from the file originally made available by
% Pat Langley and Andrea Danyluk for ICML-2K. This version was created
% by Iain Murray in 2018, and modified by Alexandre Bouchard in
% 2019 and 2021 and by Csaba Szepesvari, Gang Niu and Sivan Sabato in 2022.
% Modified again in 2023 and 2024 by Sivan Sabato and Jonathan Scarlett.
% Previous contributors include Dan Roy, Lise Getoor and Tobias
% Scheffer, which was slightly modified from the 2010 version by
% Thorsten Joachims & Johannes Fuernkranz, slightly modified from the
% 2009 version by Kiri Wagstaff and Sam Roweis's 2008 version, which is
% slightly modified from Prasad Tadepalli's 2007 version which is a
% lightly changed version of the previous year's version by Andrew
% Moore, which was in turn edited from those of Kristian Kersting and
% Codrina Lauth. Alex Smola contributed to the algorithmic style files.

Reference:
Contributions to the theory of optimal control
