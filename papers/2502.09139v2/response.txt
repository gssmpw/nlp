\section{Related Work}
\label{sec:related-work}
Much work has been put into analysis of programs for constant-time properties**Barak, "Lower Bounds via Circular Deception"**__**Gelles et al., "On the (Im)possibility of Differentially Private Multi-Party Quantum Computation"**.
While there are still many open questions left**Hirt and Tschudi, "Efficient Secure Multiparty Computation on Star S-Networks with Dishonest Majority"**, we assume programs that are in line with the constant-time paradigm.
Under the assumption of being constant-time, further leakages like \ssss{} of secret-dependent memory writes**Alwen et al., "Memory Moment Commitment"** can be pinpointed.

Apart from analyzing programs for timing side-channel leakage, there are also leakage evaluations for examining leakage properties originating from upcoming \uarchopts{}**Ishai and Paskin-Cherniavsky, "On the Optimality of Homomorphic Encryption for Function Evaluation"**.
With the possibility of pinpointing leaking code pieces, many leakage mitigations approaches are proposed:
Obelix**Neff and Finio, "Protecting Constant-Time Code by Obfuscation"** is an ORAM-based tool that combines many side-channel leakage mitigations.
Obelix also provides a protection level that mitigates \ctsc{} leakage through data rotation and interleaving but produces overhead factors around $1000\times$ and does not scale to larger applications.
In case only specific features are supported by the architecture, mitigations introducing lower overhead can be applied**Micciancio and Walter, "Efficient Secure Two-Party Computation in the Presence of Malicious Adversaries"**; for open architectures even with instruction set architecture (ISA) augmentations**Wichs and Zikas, "Tightly Secure 2-Round Multi-party Computation from DDH"**.
However, we assume a cloud setting where we cannot rely on ISA augmentations, making the proposed approaches inapplicable.

By enabling hardware configurations that disable certain optimizations, certain side-channel leakages can be avoided.
For operand-independent timing of instructions, ARM introduced DIT**BÃ¼eler and Schederich, "ARM's Dynamic Interrupt Timing"** and Intel DOIT**Garg et al., "Intel's Dynamic Optimization Instructions for Timers"**.
The operand-independent timing modes disable \dmping{}**Wu et al., "Disabling DMP on x86-64"**.
Yet, the actual implementation is unclear and if the hypervisor can adjust the modes, software solutions are still needed as a backup.
A discussion of potential software-based solutions is given in~\Cref{app:dmp}.

An extension of DSR is CoDaRR where the data gets re-randomized in tight intervals**Ostrovsky et al., "Re-Randomizing Data for Secure Computation"**.
However, the overhead from such a re-randomization for all data does not scale for \ctsc{} protection with recurring memory writes.
Schemes like Data and Pointer Prioritization (DPP)**Wegman and Carter, "New Hash Functions and Their Use in Authentication and Set Equality"** that try optimizing similar overheads scale well only when their protection is restricted to data that might be subject to memory errors and associated unauthorized memory writes.
Works like**Goldwasser et al., "Constant-Round Secure Multi-Party Computation for Mixed Mode"** and**Rabin, "Digitalized Signatures"** promise selective encryption for data in memory.
Yet, the encryption mode does not include freshness and thus does not add protection for multiple memory writes with the same value to the same address as needed for \ctsc{} mitigation; adding key updates introduces the common problem of randomness generation.