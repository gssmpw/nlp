@inproceedings{bohi2024large,
  title={Large Language Models for Wearable Data Analysis and Interpretation},
  author={B{\"o}hi, Simon and Gashi, Shkurta},
  booktitle={Tiny Paper ICLR 2024},
  year={2024}
}

@article{chan2024medtsllm,
  title={Medtsllm: Leveraging llms for multimodal medical time series analysis},
  author={Chan, Nimeesha and Parker, Felix and Bennett, William and Wu, Tianyi and Jia, Mung Yao and Fackler, James and Ghobadi, Kimia},
  journal={arXiv preprint arXiv:2408.07773},
  year={2024}
}

@article{cosentino2024towards,
  title={Towards a Personal Health Large Language Model},
  author={Cosentino, Justin and Belyaeva, Anastasiya and Liu, Xin and Furlotte, Nicholas A and Yang, Zhun and Lee, Chace and Schenck, Erik and Patel, Yojan and Cui, Jian and Schneider, Logan Douglas and others},
  journal={arXiv preprint arXiv:2406.06474},
  year={2024}
}

@article{fang2024physiollm,
  title={Physiollm: Supporting personalized health insights with wearables and large language models},
  author={Fang, Cathy Mengying and Danry, Valdemar and Whitmore, Nathan and Bao, Andria and Hutchison, Andrew and Pierce, Cayden and Maes, Pattie},
  journal={arXiv preprint arXiv:2406.19283},
  year={2024}
}

@article{imran2024llasa,
  title={LLaSA: Large Multimodal Agent for Human Activity Analysis Through Wearable Sensors},
  author={Imran, Sheikh Asif and Khan, Mohammad Nur Hossain and Biswas, Subrata and Islam, Bashima},
  journal={arXiv preprint arXiv:2406.14498},
  year={2024}
}

@article{kim2024health,
  title={Health-llm: Large language models for health prediction via wearable sensor data},
  author={Kim, Yubin and Xu, Xuhai and McDuff, Daniel and Breazeal, Cynthia and Park, Hae Won},
  journal={arXiv preprint arXiv:2401.06866},
  year={2024}
}

@article{liu2023large,
  title={Large language models are few-shot health learners},
  author={Liu, X. and McDuff, D. and Kovacs, G. and Galatzer-Levy, I. and Sunshine, J. and Zhan, J. and Poh, M. and Liao, S. and Di Achille, P. and Patel, S.},
  journal={arXiv preprint arXiv:2305.15525},
  year={2023}
}

@inproceedings{liu2024large,
  title={Large language models for cuffless blood pressure measurement from wearable biosignals},
  author={Liu, Zengding and Chen, Chen and Cao, Jiannong and Pan, Minglei and Liu, Jikui and Li, Nan and Miao, Fen and Li, Ye},
  booktitle={Proceedings of the 15th ACM International Conference on Bioinformatics, Computational Biology and Health Informatics},
  pages={1--11},
  year={2024}
}

@article{merrill2024transforming,
  title={Transforming wearable data into health insights using large language model agents},
  author={Merrill, Mike A and Paruchuri, Akshay and Rezaei, Naghmeh and Kovacs, Geza and Perez, Javier and Liu, Yun and Schenck, Erik and Hammerquist, Nova and Sunshine, Jake and Tailor, Shyam and others},
  journal={arXiv preprint arXiv:2406.06464},
  year={2024}
}

@article{tang2023alpha,
  title={ALPHA: AnomaLous Physiological Health Assessment Using Large Language Models},
  author={Tang, Jiankai and Wang, Kegang and Hu, Hongming and Zhang, Xiyuxing and Wang, Peiyu and Liu, Xin and Wang, Yuntao},
  journal={arXiv preprint arXiv:2311.12524},
  year={2023}
}

@article{team2023gemini,
  title={Gemini: a family of highly capable multimodal models},
  author={Team, Gemini and Anil, Rohan and Borgeaud, Sebastian and Alayrac, Jean-Baptiste and Yu, Jiahui and Soricut, Radu and Schalkwyk, Johan and Dai, Andrew M and Hauth, Anja and Millican, Katie and others},
  journal={arXiv preprint arXiv:2312.11805},
  year={2023}
}

@article{yoon2024my,
  title={By My Eyes: Grounding Multimodal Large Language Models with Sensor Data via Visual Prompting},
  author={Yoon, Hyungjun and Tolera, Biniyam Aschalew and Gong, Taesik and Lee, Kimin and Lee, Sung-Ju},
  journal={arXiv preprint arXiv:2407.10385},
  year={2024}
}

@inproceedings{yu2023zero,
  title={Zero-shot ECG diagnosis with large language models and retrieval-augmented generation},
  author={Yu, Han and Guo, Peikun and Sano, Akane},
  booktitle={Machine Learning for Health (ML4H)},
  pages={650--663},
  year={2023},
  organization={PMLR}
}

