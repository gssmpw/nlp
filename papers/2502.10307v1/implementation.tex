\subsection{Nowcasting}

In our approach, we utilize the pre-trained Google Vision Transformer (ViT) \cite{google_vit}, a model with 632 million parameters, to generate embeddings for sky camera images. To reduce sensor dependence and focus on image features, we exclude meteorological sensor data, incorporating only auxiliary variables such as zenith and azimuth angles, clear sky irradiance, panel tilt, and orientation. These image embeddings are subsequently concatenated with the auxiliary vector to form the final feature representation. The combined feature vectors, paired with their corresponding ground truth GHI values, are then used to train an XGBoost regressor within a supervised learning framework. The model is optimized by minimizing the Mean Squared Error (MSE) loss function, which measures the difference between the predicted and actual GHI values.

\subsection{Forecasting}

For forecasting, we employ the Google Vision Transformer (ViT) \cite{google_vit} to generate image embeddings, which are subsequently concatenated with the auxiliary variables to form a comprehensive feature representation. To account for temporal dependencies, we input a sequence of six images, representing a 1-hour context window, into a transformer-based time-series encoder \cite{vaswani2017attention}. This encoder processes the temporal sequence and learns a latent representation of the past context, which is then fused with a future covariate vector that includes azimuth and zenith angles, as well as clear sky GHI. The resulting representation is passed through a multi-layer perceptron (MLP) to predict the solar irradiance for the 1-hour, 2-hour, 3-hour, and 4-hour forecast intervals. This implementation exemplifies one approach in our framework, with additional variations incorporating different vision encoders of varied sizes in the ablation studies detailed in Section~\ref{sec:ablation_studies}.

