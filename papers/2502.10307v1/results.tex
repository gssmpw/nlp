\subsection{Zero-shot Transfer Learning}

Tables~\ref{tab:zeroshot_nowcast} and~\ref{tab:zeroshot_forecast} present the results for zero-shot transfer learning, demonstrating that our model consistently outperforms the state-of-the-art baseline across both cross-location and cross-setup scenarios in both nowcasting and forecasting tasks. When transitioning between camera setups within the same location, our model consistently shows better performance relative to the baseline. However, more notably, when moving across different locations, our model achieves up to 45\% improvement. In this more complex cross-location setting, our model significantly outperforms the baseline, highlighting its superior generalizability and robustness. Furthermore, even in the traditional setup where models are trained and tested on the same location, our approach demonstrates enhanced forecasting performance, further emphasizing its effectiveness across diverse deployment conditions.

\subsection{Fine-tuning with Limited Data}

For the analysis of fine-tuning results, we merge cross-setup and cross-location scenarios to ensure a sufficient number of data points for robust confidence interval plots, as depicted in both the nowcasting (Figure~\ref{fig:finetune_nowcast}) and forecasting (Figure~\ref{fig:finetune_forecast}) tasks. Since nowcasting is a relatively simpler task, both models exhibit rapid improvement within the first week. However, the baseline model reaches performance saturation early, at approximately 45\%, while our model continues to reduce its error, achieving a significant improvement, dropping below 20\% within four weeks. 

In forecasting, SPIRIT consistently outperforms the baseline, demonstrating notably lower variance, particularly in data-limited settings (0-2 weeks of data). This underscores SPIRIT's superior stability and reliability, with its nMAP error remaining consistently below that of the baseline. In contrast, the baseline model exhibits higher variance, indicating greater inconsistency and confusion in its performance when limited data is available. Both models experience a typical performance decline as the forecasting horizon extends from 1-hour to 4-hour forecasts, driven by the increased uncertainty over longer time horizons. Nonetheless, SPIRITâ€™s consistently lower variance and sustained performance highlight its robustness and its ability to adapt more effectively to challenging conditions. The transition from a zero-shot configuration to fine-tuning results in noticeable performance improvements; however, the gains diminish after approximately eight weeks of fine-tuning, suggesting that extended fine-tuning beyond this period yields only marginal additional benefits. All the results are in Appendix~\ref{sec:appendix_fine-tuning_detailed_results}.