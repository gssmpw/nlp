% fill this part up
% 0. talk about importance of solar forecasting and various applications.
% 1. talk about the use of DL in this task since 2019 Talha and Shiv's paper
% 2. talk about the 2022 wacv paper training a ground up transformer
% 3. say that the 2022 paper is sota in nowcasting, however, gets similar results to the 2019 paper in forecasting.
% 4. then cite some other paper saying that even they try doing irradiance forecast etc, but none of them use pretrained foundation models

% can we also subtly talk about how most of these other models are trained on a lot of data?

% we may need to mention that there has been some direct work in transfer learning - [yuhao nie's paper on transfer learning 2022]

% mention that many models are either cnn+lstm / conv+lstm architectures... or they are transformer-based architectures - both with ground up training.

% version


Traditional methods for solar forecasting have relied heavily on Numerical Weather Prediction (NWP) models and satellite imagery~\cite{markovics2022comparison}. While these methods provide valuable insights, they often lack the spatial and temporal resolution required for accurate short-term forecasts. For instance, NWP models typically operate on a grid scale of several kilometers and update every few hours which may not capture rapid changes in cloud cover that affect solar irradiance~\cite{kostylev2011solar}. Over the past few years, several time series forecasting approaches have been used for solar forecasting. However, they typically operate on a time frame of multiple hours to day-ahead and are not suitable for capturing short-term variations in solar generation due to transient factors such as cloud cover~\cite{iyengar2014solarcast,falope2024three}.  

Use of sky camera imagers for short-term solar forecasting has garnered significant attention in recent years due to their potential to enhance the accuracy of solar power predictions~\cite{hammond2024,wacv2022,yuhao_transfer_learning}. Sky cameras, equipped with fish-eye lenses, capture wide-angle images of the sky, providing valuable data on cloud cover and movement, which are critical factors in solar irradiance forecasting~\cite{dev2019estimating}. Recent advancements have focused on leveraging sky cameras to address the limitations of traditional approaches. Hammond et al.~\cite{hammond2024} and Gao et al.~\cite{wacv2022} demonstrated the potential of sky cameras in developing high-accuracy models for short-term solar forecasting. These studies utilized extensive site-specific data collected over multiple years to train their models, achieving significant improvements in forecast accuracy compared to traditional methods.


Siddiqui et al.\cite{talha2019} proposed a deep learning framework using sky-camera images and auxiliary meteorological data to predict solar irradiance. Their approach employs a convolutional neural network (CNN) with dilated convolutions, followed by an LSTM for temporal forecasting up to four hours ahead. By training on 10 years of data, they demonstrated that incorporating auxiliary data such as temperature, wind speed, and relative humidity enhances generalization and stability in predictions. Similarly, Gao et al.~\cite{wacv2022} introduced a transformer-based architecture that integrates a clear sky model to estimate the residual irradiance beyond clear-sky assumptions. Trained on 10 years of data, their model achieves improved forecasting accuracy compared to earlier CNN-LSTM-based methods. Both works underscore the importance of leveraging sky images and auxiliary data for precise solar nowcasting and forecasting. Despite their promise, sky camera-based approaches face challenges related to data availability. With the global solar PV fleet expected to increase from 1 TW in 2022 to 10 TW by 2030, a large majority of the solar farms worldwide will have negligible historical data to train custom models from scratch. 

Building upon these challenges, it becomes evident that addressing the limited availability of site-specific data is critical for advancing solar forecasting. Although the use of sky cameras and auxiliary data has substantially improved short-term predictions, the scalability of these methods remains constrained by the dearth of historical data at many solar installations. In this context, transfer learning emerges as a promising solution, as it enables the leveraging of knowledge from pre-trained models and the adaptation of learned representations across different datasets and locations. Notably, previous work such as Nie \emph{et al}.~\cite{yuhao_transfer_learning} has demonstrated that training on a fusion of multiple datasets yields models that perform better on each individual dataset, thereby highlighting the potential benefits of cross-dataset knowledge transfer.

% The use of sky camera imagers for short-term solar forecasting has garnered significant attention in recent years due to their potential to enhance the accuracy of solar power predictions~\cite{hammond2024,wacv2022,yuhao_transfer_learning}. Sky cameras, equipped with fish-eye lenses, capture wide-angle images of the sky, providing valuable data on cloud cover and movement, which are critical factors in solar irradiance forecasting~\cite{dev2019estimating}. Recent advancements have focused on leveraging sky cameras to address the limitations of traditional approaches. Hammond et al.~\cite{hammond2024} and Gao et al.~\cite{wacv2022} demonstrated the potential of sky cameras in developing high-accuracy models for short-term solar forecasting. These studies utilized extensive site-specific data collected over multiple years to train their models, achieving significant improvements in forecast accuracy compared to traditional methods.



% First about doing this task at a particular site only
% The application of dl to this problem showed improvements \cite{talha2019}. 
% other than ml, statistical methods like ARIMA are also used.

% Many models used to use a cnn with an ann, or a cnn with an lstm.
% since vits came into the picture, the use of vision transformers improved the results with \cite{wacv2022}

% some papers try doing extensive feature engineering
% transfer learning is relatively unexplored (\cite{yuhao_transfer_learning}).
% those who do, they use homogenous transfer learning, where the prediction values stay the same.
% very few papers consider heterogenous scenarios, where a model trained on irradiance may need to predict pv output. 
% No one has tried using pre-trained models or models trained on relatively general datasets for this specialized task.

% % Solar irradiance forecasting has seen significant progress with the application of deep learning methods since Talha. \emph{et al}~\cite{talha2019}. Their approach used a ConvLSTM architecture.
% % A transformer-based architecture was trained by Gao. \emph{et al}~\cite{wacv2022} from scratch for solar forecasting which significantly boosted the results.

% % Other studies have also explored irradiance forecasting using various deep learning architectures, typically having the following as the backbone of their architectures: hybrid CNN and LSTM models that combine spatial and temporal processing, or a transformer-based architecture. While these approaches have shown promise, most rely on extensive datasets collected over long periods, making them resource-intensive and slow to adapt to new locations. Furthermore, none of these models have explored the use of pre-trained foundation models, which hold the potential to generalize across locations with minimal fine-tuning.

% Efforts in transfer learning have been made(\cite{yuhao_transfer_learning}) which demonstrated the viability of transferring models pre-trained on similar tasks to new datasets. However, these approaches remain focused on specific architectures rather than leveraging the flexibility and scalability of foundation models. Additionally, the reliance on extensive training data for most existing models remains a bottleneck for rapid deployment in new locations.

% % In summary, while advancements in DL architectures for solar irradiance forecasting have introduced effective solutions, they often require substantial data and rely on ground-up training processes, limiting their adaptability. Our work addresses these gaps by leveraging pre-trained foundation models to enable robust performance in zero-shot transfer learning scenarios and achieve high accuracy with minimal local data, paving the way for scalable and accessible forecasting solutions.



