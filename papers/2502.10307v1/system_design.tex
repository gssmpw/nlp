\subsection{Key Concepts and Problem Setup}

Nowcasting refers to the prediction of solar power generation over very short time horizons, typically ranging from a few minutes to a few hours \cite{nowcasting_defn}. In contrast, short-term forecasting extends the prediction horizon to cover periods from one hour to 24 hours \cite{forecasting_defn}. Methods developed to provide forecasts utilize various data sources, such as satellite data \cite{nowcasting_satellite, nowcasting_defn}, weather station observations \cite{nowcasting_defn}, and sky camera images \cite{wacv2022, nwp_and_tsi, talha2019}. Nowcasting and short-term forecasting are indispensable for managing the intermittency of solar power, allowing grid operators to perform better scheduling, dispatching, and balancing of energy resources \cite{dairi2020short, aouidad2024machine}.

\textbf{Sky Camera:} 
Sky cameras enhance nowcasting and short-term forecasting by capturing sky images with fish-eye lenses, providing detailed cloud movement, and sun position data. These images enable algorithms to track cloud dynamics and predict their trajectories, essential for estimating solar irradiance~\cite{saraswat2023sky, dev2019estimating}. Offering a low-latency alternative to weather satellites, sky cameras facilitate real-time monitoring. However, variations in camera setup and quality affect image appearance, as shown in Figure~\ref{fig:dataset_grid} in Appendix~\ref{subsec:appendix_overview_of_datasets}. As a key tool in solar forecasting, sky cameras contribute to more reliable energy predictions~\cite{rajagukguk2021deep}. Further details are provided in Appendix~\ref{sec:appendix_clear_sky_global_horizontal_irradiance}.


\textbf{Irradiance measurements:} Understanding solar irradiance requires distinguishing between three key measurements:

(1) \textbf{Direct Normal Irradiance (DNI):} The amount of solar radiation received per unit area on a  surface perpendicular to the sunâ€™s rays without being scattered or diffused by the atmosphere.

(2) \textbf{Diffuse Horizontal Irradiance (DHI):} The portion of solar radiation that reaches a horizontal surface after being scattered by molecules, aerosols, and clouds in the atmosphere. Unlike DNI, DHI comes from all directions in the sky and plays a crucial role during overcast conditions when direct sunlight is obstructed.

(3) \textbf{Global Horizontal Irradiance (GHI):} The total solar radiation received on a horizontal surface, combining both direct and diffuse components. GHI is the sum of DNI, projected onto a horizontal plane, and DHI:  
\begin{equation}
    GHI = DNI \times \cos(\theta) + DHI
\end{equation}  
where \( \theta \) is the angle between the direction of incoming solar radiation and the vertical, called the zenith angle.

GHI is the most commonly used irradiance measure in solar energy applications, as it directly influences photovoltaic (PV) panel performance and solar power generation, making it the primary focus of research in irradiance forecasting. Henceforth, unless explicitly stated otherwise, any mention of irradiance or solar irradiance
refers specifically to Global Horizontal Irradiance.

% Several third-party service providers have API access to get $DNI$, $DHI$, and $GHI$ for any location on earth for a given time~\cite{wagner2023importance,solcast,openweather}. 

\textbf{Photovoltaic Power Output:}
PV power output refers to the electricity generated by solar panels from incoming solar radiation. While it is primarily driven by GHI \cite{ghi_pv_linear}, factors like temperature, and system losses also play a role. Under stable conditions, the relationship between GHI and PV output is roughly linear \cite{pv_output, pv_output2}. Since PV output is a more actionable metric for grid management and energy planning, predicting it directly is often more desirable.


\subsection{Nowcasting Architecture}
\label{subsec:nowcasting_architecture}
We propose an architecture that encodes sky images into vector representations, which are augmented with auxiliary data and physics-based features. This representation captures information about the GHI, which is then effectively extracted by a regression model.
% We introduce an architecture that first encodes sky images into vector representations. These vectors are augmented with auxiliary data relevant to the image, along with physics-inspired features, which are mathematically derived from the auxillary data, creating a comprehensive feature representation. We reason that the information regarding the global horizontal irradiance of an image is captured within its concatenated feature representation and can be effectively extracted using a regression model.


Let \( \mathcal{X} \) be the set of sky camera images, and \( \mathcal{D} \) be the dataset, defined as \( \mathcal{D} = \{(X_i, \mathbf{A}_i, y_i)\}_{i=1}^N \), where \( X_i \in \mathcal{X} \) represents the \(i\)-th sky image, \( \mathbf{A}_i \in \mathbb{R}^k \) corresponds to the auxiliary features such as azimuth and zenith angles of the Sun, and \( y_i \in \mathbb{R}^+ \) are the corresponding solar irradiance measurements.

An encoder function \( E: \mathcal{X} \rightarrow \mathbb{R}^d \) is defined that assigns a \( d \)-dimensional embedding vector to each image \( X \in \mathcal{X} \):

\[
\mathbf{Z} = E(X), \quad \mathbf{Z} \in \mathbb{R}^d
\]


To leverage domain knowledge in solar power prediction, we introduce a set of additional features, \( \mathbf{P} \), derived from the auxiliary measurements \( \mathbf{A} \). These features incorporate established solar engineering principles, such as clear sky irradiance, and panel tilt and orientation, as defined in Subsection \ref{subsec:physics_inspired}. The feature vector \( \mathbf{P} \) is given by:
\[
\mathbf{P} \in \mathbb{R}^p
\]
where \( p \) represents the number of physics-based features extracted from the auxiliary data.

The final feature representation \( \mathbf{f} \in \mathbb{R}^{d+k+p} \) is constructed by concatenating the image embedding \( \mathbf{Z} \), raw auxiliary measurements \( \mathbf{A} \), and the physics-based features \( \mathbf{P} \):
\[
\mathbf{f} = \mathbf{Z} \oplus \mathbf{A} \oplus \mathbf{P}
\]
where \( \oplus \) denotes the concatenation operation. This combined representation leverages data-driven features, visual features, and domain-specific engineering knowledge, providing a comprehensive characterization of each sample \( (X_i, \mathbf{A}_i, y_i) \in \mathcal{D} \).

A regression function \( R_\omega: \mathbb{R}^{d+k+p} \rightarrow \mathbb{R}^+ \), parameterized by weights \( \omega \), is defined such that:

\[
\hat{y} = R_\omega(\mathbf{f}) = R_\omega(E(X) \oplus \mathbf{A} \oplus \mathbf{P})
\]


Nowcasting loss function \( \mathcal{L}_{nowcast}(\omega) \) is defined as the average of the individual regression losses for each sample, where each individual loss measures the discrepancy between the predicted \( \hat{y}_i = R_\omega(\mathbf{f}_i) \) and the true value \( y_i \):

\[
\mathcal{L}_{nowcast}(\omega) = \frac{1}{N} \sum_{i=1}^N \mathcal{L}(R_\omega(\mathbf{f}_i), y_i)
\]

where \( \mathcal{L}(R_\omega(\mathbf{f}_i), y_i) \) is the regression loss for the \(i\)-th sample. To learn the optimal parameters \( \omega^* \), we minimize \( \mathcal{L}_{nowcast}(\omega) \) using gradient-based methods.

\subsection{Forecasting Architecture}
Our forecasting architecture processes sequences of sky images to predict GHI across multiple future intervals. Each image is encoded using the embedding and augmentation approach from Section~\ref{subsec:nowcasting_architecture}. A time-series model captures a latent representation of past features, while predictable future covariates, such as the zenith angle, are precomputed and integrated as a vector. The combined past and future representations are then input into a regressor to generate GHI predictions.


% Our forecasting architecture processes a sequence of sky images to predict future GHI values for multiple future intervals. For each image in the sequence, we generate a feature representation using the same embedding and augmentation approach described in \ref{subsec:nowcasting_architecture}. A time-series model is used to predict a latent representation of the past feature vectors. Certain future values, such as the zenith angle, can be calculated in advance, owing to their predictable nature based on the time and location of the observation.. These known future covariates are incorporated into the model in the form of a vector. Together with the past covariates, this combined representation is then used to predict the future GHI values through a regressor.


A sequence of \( T \) images \( X_{1:T} = \{ X_1, X_2, \dots, X_T \} \) along with their corresponding auxiliary features \( \mathbf{A}_{1:T} = \{ \mathbf{A}_1, \mathbf{A}_2, \dots, \mathbf{A}_T \} \), where each \( \mathbf{A}_t \in \mathbb{R}^k \) represents the auxiliary feature vector at time \( t \), is given.

An encoder function \( E \) generates the vector representation \( \mathbf{Z}_t = E(X_t) \in \mathbb{R}^d \) for each image at time step \( t = 1, 2, \dots, T \). The physics-based features \( \mathbf{P}_t \) are derived from auxiliary measurements \( \mathbf{A}_t \). The final feature vectors \( \mathbf{f}_t \in \mathbb{R}^{d+k+p} \) are obtained by concatenating the image embedding, auxiliary data, and physics-based features:
\[
\mathbf{f}_t = \mathbf{Z}_t \oplus \mathbf{A}_t \oplus \mathbf{P}_t
\]

where \( \oplus \) denotes concatenation, providing a comprehensive characterization of each sample \( (X_t, \mathbf{A}_t, y_t) \in \mathcal{D} \).

Thus, the collection of feature vectors over the sequence of \( T \) time steps is given by:

\[
\mathbf{F_{1:T}} = \{ \mathbf{f}_1, \mathbf{f}_2, \dots, \mathbf{f}_T \}
\]

where \( \mathbf{F_{1:T}} \) represents the set of concatenated feature representations created for each timestamp in the sequence.

Given the collection of feature vectors \( \mathbf{F_{1:T}} = \{ \mathbf{f}_1, \mathbf{f}_2, \dots, \mathbf{f}_T \} \), a time-series model \( \mathcal{M} \) is used to encode the observed sequence into a latent vector \( \mathbf{L} \in \mathbb{R}^m \), which captures the full context of the input data series while retaining its temporal patterns and dependencies:

\[
\mathbf{L} = \mathcal{M}(\mathbf{F_{1:T}}) \in \mathbb{R}^m
\]

where \( \mathcal{M} \) represents the time-series model that transforms the observed sequence of feature vectors \( \mathbf{F_{1:T}} \) into a compact representation in the latent space \(\mathbb{R}^m \).


To integrate known future information, derived from the spatiotemporal context of time and location, future covariate vectors \( \mathbf{C}_{T+\tau_i} \in \mathbb{R}^{q} \) are constructed for each forecast time \( T + \tau_i \), . The full covariate vector \( \mathbf{C} \in \mathbb{R}^{q \cdot H} \) is then formed by concatenating these individual representations across all forecast horizons:

\[
\mathbf{C} = \bigoplus_{i=1}^{H} \mathbf{C}_{T+\tau_i}, \quad \mathbf{C}_{T+\tau_i} \in \mathbb{R}^{q}
\]

We concatenate the future covariate vector \( \mathbf{C} \) with the latent representation of the past time steps \( \mathbf{L} \), forming the final vector that encompasses all relevant information:

\[
\mathbf{h} = \mathbf{L} \oplus \mathbf{C}
\]

This ensures that both past contextual information as well as known future data contribute to the forecasting process.

Next, a regression function \( R_\omega: \mathbb{R}^{m+q \cdot H} \to \mathbb{R}^H \), parameterized by \( \omega \), is applied to the vector \( \mathbf{h} \in \mathbb{R}^{m+q \cdot H}\) to generate the corresponding predicted GHI values. The regressor outputs a vector \( \hat{\mathbf{y}} \in \mathbb{R}^H \) of predicted GHI values for the forecast time intervals \( T + \tau_1, T + \tau_2, \dots, T + \tau_H \):

\[
\hat{\mathbf{y}} = R_\omega(\mathbf{h}) = \left[ \hat{y}_{T+\tau_1}, \hat{y}_{T+\tau_2}, \dots, \hat{y}_{T+\tau_H} \right] \in \mathbb{R}^H
\]

where each \( \hat{y}_{i} \) corresponds to the irradiance forecast for the time interval \( T + \tau_i \), and the vector \( \hat{\mathbf{y}} \) represents the full set of predicted irradiance values across all forecast intervals \( T + \tau_1, T + \tau_2, \dots, T + \tau_H \).



Forecasting loss function \( \mathcal{L}_{forecast}(\omega) \) is defined as the mean of the individual regression losses computed over all forecast intervals \( T + \tau_j \) for each sample \( i \) . Specifically, the total loss is given by:

\[
\mathcal{L}_{forecast}(\omega) = \frac{1}{N \cdot H} \sum_{i=1}^N \sum_{j=1}^H \mathcal{L}(\hat{y}^{(i)}_{T+\tau_j}, y^{(i)}_{T+\tau_j})
\]


where \( \mathcal{L}(\hat{y}^{(i)}_{T+\tau_j}, y^{(i)}_{T+\tau_j}) \)  is the individual regression loss for the forecast interval \( T + \tau_j \) for sample \( i \) . To learn the optimal parameters \( \omega^* \), we minimize \( \mathcal{L}_{forecast}(\omega) \) using gradient-based optimization methods. The complete architecture is illustrated in Figure \ref{fig:crown_jewel}.



\textbf{The Significance of Generalized Encoders:}
A key distinction of our approach is that in prior work \cite{wacv2022, prior_methods_site_specific, talha2019}, the encoder \( E \) is a vision model typically trained on data from a specific location and camera setup. Furthermore, studies aiming for generalizability typically rely on training models using a fusion of solar datasets from multiple locations \cite{yuhao_transfer_learning, site_specific_trained_transfer_learning}. In contrast, we argue, and later demonstrate, that leveraging a foundation model, a highly generalizable feature extractor, provides a more robust \( E \) function. A foundation model not only matches the performance of site-specific encoders at a given location with a particular setup but also demonstrates an unparalleled advantage in generalizing across diverse locations and camera setups.

\subsection{Physics-inspired Feature Engineering}
\label{subsec:physics_inspired}

\textbf{Clear sky models} \cite{ineichen1, clearsky1, perez1, clearsky_solis} are mathematical models that estimate the theoretical solar irradiance at a given location under cloud-free conditions, serving as a representation of the maximum possible radiation reaching the Earth's surface. These models leverage fundamental atmospheric physics and employ mathematical formulations based on solar geometry \cite{clearsky1}, atmospheric transmittance \cite{clearsky1}, and radiative transfer \cite{clearsky1} to derive estimations of GHI, DNI and DHI under clear sky conditions. The Ineichen clear sky model \cite{ineichen1} requires inputs such as latitude, longitude, time, and date, which are readily available. This allows clear sky irradiance values to be readily computed and incorporated into our model as features, providing a reference for expected irradiance levels in the absence of cloud interference.

\textbf{Physics behind solar irradiance:}
Solar irradiance, the power per unit area received from the Sun in the form of electromagnetic radiation, is measured in watts per square meter $(W/m^2)$. The amount of solar irradiance received by a solar panel depends on additional site-specific factors, including the panel's tilt and orientation angle, the Sun's altitude and azimuth, and the geographic location's latitude and longitude. We first look at the angle of incidence ($\theta$)~\cite{sandia}, i.e. the angle between the incoming solar rays and the normal to the surface of the solar panel. It can be calculated using the following formula:

\begin{equation}
cos(\theta)=cos(\theta_{z}) \cdot cos(\beta) + sin(\theta_{z}) \cdot sin(\beta) \cdot cos(\gamma - \alpha)
\end{equation}
where $\theta_{z}$ and $\gamma$ are the solar zenith and azimuth angles respectively. While $\beta$ and $\alpha$ are the tilt and azimuth angles of the panel.

We calculate the effective irradiance by adding the three main components: direct, diffuse, and reflected irradiance (see below):  

\begin{equation}
   I_{panel} = DNI \cdot cos(\theta) + DHI \cdot \frac{1 + cos(\beta)}{2} + GHI \cdot \rho \cdot \frac{1 - cos(\beta)}{2} 
\end{equation}

where $I_{panel}$ is the effective irradiance and $\rho$ is the ground reflectance.

