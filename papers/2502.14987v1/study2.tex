\section{Energy Study}
\label{sec:study}
We designed this study to validate our conjectures that externally manipulating queuing and CPU frequency can yield a diverse space for exploring energy-efficient "sweet spots". To our knowledge, this study is the first to conduct a study of interrupt coalescing, CPU frequency combinations across two distinct OSes running baremetal, and with a variety of network applications shown in~\cref{table:wrkcfgs}.

\renewcommand{\tabcolsep}{2pt}
\begin{table}[t]
\small
\begin{tabular}{|c|c|c|c|c|}
    \hline
  OS & App & Network Loads & Loop & Type\\
  \hline
     & NetPIPE & 64B, 8KB, 64KB, 512KB & Closed & OS\\ \cline{2-5}
     Linux, & NodeJS & N/A & Closed & App \\ \cline{2-5}
   EbbRT & Memcached & 200K, 400K, 600K QPS & Open & OS\\ \cline{2-5}
   & Silo & 50K, 100K, 200K QPS & Open & App\\ \hline
\end{tabular}
\vspace{-10pt}
\caption{
Operating system (OS), application, and network configurations.
\textbf{Network Loads} reflect mean values: requests-per-second \textit{(QPS)} or message sizes \textit{(KB)}. \textbf{Type} indicates whether an application is more reliant on application processing or OS processing.}
\label{table:wrkcfgs}
\end{table}
% CPU/App and CPU/OS 

\subsection{Study Setup}
Our infrastructure consists of seven nodes, featuring a mix of 16-core Intel(R) Xeon(R) CPU E5-2690 @ 2.90GHz with 126 GB RAM and 12-core Intel(R) Xeon(R) CPU E5-2630L v2 @ 2.40GHz processors with 256 GB RAM, all equipped with Intel 82599ES 10-Gigabit SFI/SFP+ NICs. The single node used for booting into both baremetal EbbRT and Linux includes a 16-core Intel(R) Xeon(R) CPU E5-2690 @ 2.90GHz, 126 GB RAM, and an Intel 82599ES 10-Gigabit SFI/SFP+ NIC. Ensuring hardware parity between Linux and EbbRT, we carefully configured IA-32 Architectural MSRs, processor-specific MSRs (refer to Tables 35-2 and 35-18 in~\cite{intel_msr}), and NIC features, including disabled direct-cache injection (DCA), enabled receive-side scaling (RSS) for multi-core packet processing distribution, and enabled hardware checksum offloading. We matched NIC transmit and receive descriptors and write-back thresholds for packet transmissions. Additionally, to minimize system noise, hyperthreads and TurboBoost are disabled on all processors. We excluded TurboBoost due to reported energy anomalies when used with different sleep states~\cite{slowdownorsleep}. 
\begin{figure*}[hbt!]
\centering
\includegraphics[width=1.0\textwidth]{closed_loop_overview.png}
\caption[]{\small NetPIPE and NodJS Webserver performance and energy results for different message sizes. Every datapoint is the result of a single experimental run with a unique ITR, DVFS combination while \textit{Linux-default} has dynamic ITR-delay, DVFS algorithms enabled instead. LibOS refers to EbbRT. The X-axis is a measure of performance (lower is better) and Y-axis shows the total energy consumed. For \textit{Linux-tuned} (or Linux-static) and \textit{LibOS-tuned} (or EbbRT-static), the labeled (ITR-delay, DVFS) pair are experimental values that resulted in the lowest energy use. \textit{LibOS-poll} shows EbbRT with a run-to-completion polling loop at different processor frequencies (shown as change in gradient colors). \textit{Note: The X and Y scales are different to show the structure of collected data.}}
\label{fig:closed_overview}
\vspace{-0.1in}
\end{figure*}

\subsection{Hardware Mechanisms}
\label{sec:hwmech}
We summarize the software and hardware techniques we use to conduct sweeps of static ITR-delay, and DVFS combinations.

\subsubsection{Interrupt Coalescing (ITR-delay)}
Most modern NICs have a hardware feature to control per-interrupt rates~\cite{intelitr, mellanoxsinterrupt} that induce interrupt coalescing. Typically in Linux, these rates are set dynamically by pre-built dynamic policies within their respective device drivers. However, it is possible to set them statically and we use \textit{ethtool}~\cite{intelethtool} in the Linux study\footnote{\textit{ethtool} is a user tool that maps interrupt coalescing values to appropriate NIC settings}. For EbbRT, we program the NIC directly via its Intel device driver. ITR-delay on Intel NIC's can be programmed in 2 $\mu$s increments.

\subsubsection{CPU Frequency (DVFS)}
DVFS power states (p-states) are features on modern processors that trade-off instruction execution speed for a reduction in energy use~\cite{armdvfs, amdpstate, intel_manual}. Normally, p-states are set dynamically by a policy governor in Linux~\cite{cpufreq_governor}. In this study, we disable dynamic DVFS through Linux's \texttt{userspace} governor and write directly to the IA32\_PERF\_CTL MSR register~\cite{intel_msr} instead. We replicate this in EbbRT by writing to the same register.

\subsection{OS Softwares}
\label{sec:OS}
We explored two OSes with fundamentally different system designs. This gave us the ability to deepen our understanding of how ITR-delay and DVFS mechanisms impact performance and energy consumption under different system implementations.

\subsubsection{Linux}
We build a set of application-specific Linux appliances~\cite{271072, hanappliance} for each of the applications shown in~\cref{table:wrkcfgs}. These appliances are specially constructed to run a RAM-based filesystem and contain only a small set of system libraries and kernel modules required to run their constituent applications. We construct these appliances from a custom 5.5.17 kernel which we built using a modified configuration file for high performance, following suggestions from previous work that studied Linux core operation costs~\cite{linux-core-ops}. To reduce scheduling overheads and noise, we pin all applications to physical cores, disable Linux ~\textit{irqbalance}, and affinitize packet receive interrupts to their respective cores.

\subsubsection{EbbRT}
Specialized systems aimed at accelerating network applications have seen significant research~\cite{ix, arrakis, zygos, shenango, rumpkernel, aliraza, unikernels, scalingmcdfacebook, arachne, mtcp, sandstorm, affinityaccept, flexnic, mica, seda, ebbrt}. However, these systems often overlook importance of their energy efficiency~\cite{SmoothOperator, Dynamo, nature1}. To explore the performance and energy implications of such a specialized system, we chose EbbRT~\cite{ebbrt}, an open-source platform for building per-application library OSes (around 20K LOC). EbbRT shares properties with these prior systems and employs a run-to-completion, event-driven model in a single execution domain. We developed a network device driver for EbbRT for the network applications to run baremetal on servers with Intel 82599 10 GbE NICs~\cite{82599} (around 3K LOC).

\subsection{Per-Interrupt Log Collection}
For the study, we built a per-interrupt logging framework, \texttt{intlog} (Acesss to our data and logging scripts can be found at https://anonymous.4open.science/r/intlog-9925), in Linux and EbbRT's network device driver. We collect the following data in the NIC's interrupt handler code: received and transmitted bytes, descriptors, sleep state statistics, and current timestamp via \texttt{rdtsc} instruction. Additionally, per-core Intel performance monitoring counters (PMCs) capture hardware statistics every millisecond, including instructions, cycles, and last-level cache misses. We use standard Running Average Power Limit (RAPL) hardware registers to read per-package energy values~\cite{intel_rapl}~\footnote{The 1 ms rate is due to sampling granularity of RAPL}. Using rack-level energy measurement mechanisms, we have validated that the changes in energy consumption we observe using RAPL are accurate and impactful\footnote{While we have validated that ITR-delay and DVFS also impact rack-level energy savings, we use RAPL instead because the granularity of the rack-level measurements (on the order of seconds) made it difficult to attribute detailed energy use to specific system events.}.

\subsection{Study Results}
\label{sec:exp}
In our results, we compare and contrast the performance and energy consumption achieved by three OS configurations: 
 \begin{enumerate}
     \item \textbf{Linux}, which has both its dynamic ITR-delay and DVFS algorithms enabled - DVFS is set by Linux \texttt{ondemand} governor~\cite{cpufreq_governor}, while ITR-delay is set by Intel's dynamic policy~\cite{intelitr})
     \item \textbf{Linux-static} and \textbf{EbbRT-static} where ITR-delay and DVFS are set to specific fixed values.
 \end{enumerate}
For both \textbf{*-static} OSes, we conducted a study sweeping to 340 \footnote{This is due to the experimental scope and also to cover a broad range of possible pairs out of 2 million.} static ITR-delay, DVFS pairs, and repeated up to 10 times for stability; our gathered statistics show a standard deviation error of less than 0.01\%. In each experiment, we measure a software stack's performance (elapsed time for closed-loop and 99\% tail latency for open-loop applications) and overall energy usage. While our study generated over 5 TB of data across multiple runs, we will concentrate on presenting three representative findings based on the results of NetPIPE~\cite{snell1996netpipe} and memcached~\cite{memcached} experiments in the following sections.

\paragraph*{Closed Loop} 
NetPIPE is a simple network ping-pong application of fixed-size messages over a single TCP connection and is an example of a closed loop application~\cite{Barroso:2009:DCI:1643608, oldi-study, oldi-pegasus, warehouse-power, energyproportion, WebSearch}. For closed-loop applications, the work to be done is a sequence of requests that have an inter-dependency on each other. Linux runs NetPIPE-3.7.1 while EbbRT uses a custom version ported to its interfaces. 

\paragraph*{Open Loop}
Memcached is an example of an open-loop application, characterized by an external request rate considered largely independent of the time required for request servicing. In our setup, an unloaded client, running mutilate~\cite{mutilate}\footnote{Mutilate is configured to pipeline up to four connections to enhance its request rate.}, interfaces with five agent nodes generating requests to the memcached server. Each agent node operates on a 16-core machine, with each core establishing 16 connections, resulting in a total of 1280 connections. Linux executes memcached-1.6.6, while EbbRT utilizes a re-implemented version tailored to its native interfaces, supporting the standard memcached binary protocol. We run the representative ETC workload from Facebook~\cite{workloadanalysisfacebook}. It uses 20 to 70-byte keys and 1-byte to 1-KB values and contains 75\% GET requests. We use a stringent SLA objective where the 99\% tail latency < 500 $\mu$s.\\


\begin{figure}[h!]
\centering
\includegraphics[width=0.45\textwidth]{netpipe_65536_itr_vals.png}
\caption[]{\small ITR-delay values set by Linux's dynamic ITR-delay algorithm. This is captured during a live run of NetPIPE at 64 KB message size.}
\label{fig:netpipe_65536_itr_vals}
\end{figure}

% Finding: ITR-delay Exposes Energy Efficient Batching of Packet Processing
\subsubsection{ITR-delay and DVFS impact on batched packet processing}
\label{sec:closed_energy}
While the focus of our work is on open-loop style SLA-driven applications, we begin our study with a NetPIPE server. NetPIPE's closed-loop style and simple application protocol allow us to explore how different message sizes, ITR-delay and DVFS affect the overall performance and energy of different OSes. Fig.~\ref{fig:closed_overview} shows that at 64 KB message size, the static ITR-delay in Linux demonstrates a performance improvement of over 60\%, and a 50\% reduction in energy consumption compared to dynamic policies in Linux. To understand why this is dramatic, consider the dynamic ITR-delay policy, visualized in fig.~\ref{fig:netpipe_65536_itr_vals}, which reveals extreme variability at a per-interrupt granularity\footnote{We instrumented a simple log in Linux's network device driver to save every updated ITR-delay value during a single run of NetPIPE for a 64 KB message.}. This indicates that the current policy, designed for general use cases, operates at an inappropriate timescale for NetPIPE and that significant advantages can be gained through specialization. Moreover, fig.\ref{fig:closed_overview} illustrates the Pareto-optimal performance-energy curve for various message sizes in both Linux and EbbRT. As the NetPIPE message size increases from 8KB to 64KB and 512KB, the fixed ITR-delay values yielding optimal energy efficiency also increase toward 26$\mu$s and 28$\mu$s at 512KB for EbbRT and Linux, respectively (labeled in red and green boxes). Intuitively, this result indicates that ITR-delay effectively batches processing by controlling the amount of payload transmitted from the NIC to the OS within a time window. Optimal ITR-delay settings suggest a "sweet spot" where the OS paces packet processing, saving energy through a combination of idling and CPU frequency control.

Lastly, though (ITR-delay, DVFS) pairs in fig.~\ref{fig:closed_overview} have different values for the different OSes explored, the performance-energy curves for the OSes follow a common 'V' shape. The lowest point in this 'V' shape represents a setting that consumed the least energy while being competitive in performance while the left points represent settings that sacrificed energy for better performance. This 'V' shape also illustrates that it is essential to be strategic in tuning, as while some static settings can outperform dynamic control, there can also be sub-optimal static settings, as shown by points to the right of Linux in Fig.~\ref{fig:closed_overview}. 

\begin{figure*}[!htb]
\centering
\includegraphics[width=0.99\textwidth]{mcd_overview.png}
\caption[]
{\small Memcached: Each point represents a single experimental run. The \textit{*-static} data points use a unique (ITR-delay, DVFS) pair. We only illustrate data that lie on the Pareto-optimal curve. The X-axis shows performance measurement (lower is better) and the Y-axis shows total energy consumed.
\textit{Linux results for 1000K and 1500K QPS loads are not shown as Linux could not support them without violating SLA.}
}
\label{fig:mcd_overview}
\end{figure*}

\begin{figure}[!htb]
\includegraphics[width=1\columnwidth]{sig_mcd_ins_itr.png}
\caption[]{\small Memcached: ITR-delay impact on instruction count ($1e11$). 
\textit{Not drawn to scale to show structure in data.}
}
\label{fig:sig_mcd_ins_itr}
\end{figure}

%Finding: OS Specialization Magnifies Energy and Performance Wins
\subsubsection{OS Specialization on Energy and Performance}
\label{sec:open1}
Next, we consider experiments that explore the performance and energy trade-offs of memcached with varying requests-per-second (QPS) loads under the same SLA objective. Our key findings are that 1) different OS designs can impose different trade-offs between performance and energy, and 2) specialized systems can achieve dramatic efficiency in both. This can be seen in fig.~\ref{fig:mcd_overview} which illustrates the Pareto-optimal curves \footnote{We filter out (ITR-delay, DVFS) pairs that resulted in SLA violations.} of EbbRT and Linux. Fig.~\ref{fig:mcd_overview} shows that as QPS increases, EbbRT exhibits a consistent vertical structure, suggesting effective energy savings without impacting latency. Conversely, Linux's curves become more horizontal, indicating performance degradation as QPS rises due to increased trade-offs between performance and energy. Notably, EbbRT's optimized stack allows it to handle higher peak QPS (2000K) compared to Linux (800K). In particular, fig.~\ref{fig:sig_mcd_ins_itr} shows the impact of ITR-delay on the total amount of instructions needed to run a single memcached server in both Ebbrt and Linux. This figure shows how a large ITR-delay (e.g. 400 $\mu$s) can reduce overall instruction count by up to 30\% in Linux. It also shows the drastic differences in instruction count between the two OSes, as EbbRT uses up to 2.5X fewer instructions to support the same load as Linux does. This implies that a greater fraction of EbbRT's instructions were spent getting actual work done rather than traversing the network stack, which suggests that combining ITR-delay and DVFS control with EbbRT's optimized network paths presents substantial opportunities for maximizing \textit{race-to-idle} energy benefits~\cite{dreamweaver, dynsleep}.

\begin{figure}[!htb]
\begin{subfigure}{\textwidth}
  \includegraphics[width=0.5\linewidth]{mcdgradient400K.pdf}
\end{subfigure}
\caption{\small Illustrates the change in energy and 99\% latency as different ITR-delay, DVFS pairs are explored for Linux memcached.}
\label{fig:gradients}
\end{figure}

\subsubsection{Polling can be energy efficient}
As indicated earlier, the use of a single fast ITR value resulted in both best performance and subsequent combining with DVFS also resulted in lowest energy use as well. This prompted us to explore the effects of eliminating interrupts altogether and use a dedicated poll loop. In \cref{fig:closed_overview}, we illustrate that LibOS-poll (or EbbRT-poll) was able to achieve both best case latency and competitive lowest energy. We found that by modulating DVFS, EbbRT-poll can be made energy efficient for small payloads under its specialized OS paths - this is in contrast to the normative assumptions of OS poll where it often trades performance for higher energy use. For example, EbbRT was able to improve tail latency by 27\% while using 35\% less energy in Memcached. In NetPIPE~\cite{snell1996netpipe}, polling can achieve up to 3X better performance while using 4X lower energy as compared to baseline Linux. However, polling with DVFS must be used judiciously as in other application-centric workloads such as Memcached-silo often results in both worst performance and energy use as compared to their interrupt-driven counterparts.

This finding suggests the importance for energy aware OS-level optimizations that can switch between poll and interrupt-driven IO in response to changes in demand. Therefore, OS path specialization techniques can explore the use of polling to achieve both low-latency and energy efficiency with careful use of DVFS in new hybrid policies.

\subsubsection{Revealing ITR-delay and DVFS Performance-Energy Trade-offs}
\label{sec:open2}
To help build intuition of the impact of specific ITR-delay and DVFS settings on the performance and energy of open-loop style applications, we present an example in \cref{fig:gradients} featuring a Linux memcached server with a load of 400K QPS. Using colored gradients, the figure visually represents the effects of each ITR-delay, and DVFS pair; each data point is divided in half, providing insights into their respective impacts on 99\% latency and energy.

In \cref{fig:gradients}, one can see the trend that as DVFS decreases from 2.9 GHz: the energy gradient becomes lighter, indicating a more pronounced impact on reducing energy use. Simultaneously, increasing ITR horizontally has an immediate effect on increasing measured 99\% latency, evident in the darkening of colored gradients. Further, we observe two notable behaviors at a DVFS frequency of 1.3 Ghz: 1) a fast ITR-delay (0 $\mu$s) triggers a spike in tail latency, violating the 500 $\mu$s SLA objective due to the slow CPU frequency's insufficient processing of incoming requests, and 2) as ITR-delay increases, this induces additional queuing which enables efficient request batching, thereby facilitating additional energy savings. 

These observations indicate that the combination of ITR-delay and DVFS enables one to select different operating points that can move within this space. This is evident in the common "L" shapes seen in \cref{fig:mcd_overview}; which while they differ in absolute performance and energy, illustrates how ITR-delay and DVFS can be combined to reduce energy while still meeting SLA objectives in both OSes.