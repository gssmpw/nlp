\section{Introduction}
Today latency-sensitive cloud applications\footnote{Examples of latency-sensitive cloud applications include kev-value stores, search, and image and speech recognition.  The execution of such applications must often meet a specific performance target expressed as a Service Level Agreement (SLA). A common SLA is a 99\% tail latency requirement -- Eg. 99\% of all requests must be completed within some time limit.} 
play a critical role; in many cases, fleets of servers are dedicated to running a single instance of these applications~\cite{ixcp, heracles, PerAppPower, twine, twittermcd}. 
Researchers have shown that it is worth exploiting techniques to bypass the kernel and design highly specialized software stacks that combine a purpose-built library OS with these applications to improve their performance~\cite{ix, arrakis, zygos, shenango, rumpkernel, aliraza, unikernels, scalingmcdfacebook, arachne, mtcp, sandstorm, affinityaccept, flexnic, mica, seda}. 
As global data center energy use continues to rise~\cite{gupta2020chasing, NLP-energy,warehouse-power,nature1}, it is critical to find ways to meet the challenging requirements of these applications while reducing their energy use. 

Studies of latency-sensitive applications have shown that they experience stable mean demand curves.  
These curves show gradual changes in offered loads over extended periods, ranging from multiple hours to days. Such stability arises from recurring diurnal patterns and use of load balancers~\cite{scalingmcdfacebook, twittermcd, netflixmcd, redditmcd}.
Generally, these studies suggest that for a particular service there exists a stable mean arrival rate and composition of requests over some time scale.

This load stability (i.e. request rates and composition of requests) offers opportunities to meet SLA objectives while reducing energy use. Specifically, queuing theory suggests that the slack between request arrival, service time, and the SLA can be leveraged to improve energy efficiency. For example, induced queuing can amortize per-packet overhead to improve coalescing and processing efficiency~\cite{mootaz}, and even introduce idle periods in which the system can enter low-energy sleep states~\cite{slowdownorsleep}.

However, for a specific offered load, application, operating system (OS), and hardware, the most energy-efficient way to meet the SLA objective is specific to how the exact combination of software and hardware interacts.  
For example, queuing and processing rate settings that mimic a ``race-to-idle'' policy, executing as fast as possible to create the greatest amount of idle time to spend in a deep sleep state (that may flush CPU caches), maybe the right choice. 
It is, however, also possible that for the combination of hardware and software being used, it is better to choose a setting that mimics a "pace-to-idle" policy, executing more slowly and either entering a light sleep state or not entering a sleep state altogether~\cite{pacingtoidle}.  

Our research adds to the body of work on energy management\cite{slowdownorsleep,dreamweaver,dynsleep,pacingtoidle} by demonstrating that one can exploit stability in system behavior to efficiently find queuing and CPU processing rate settings to meet a tail latency target while reducing energy consumption.
We explore three basic conjectures:
\begin{enumerate}

\item There is a combination of queuing and CPU frequencies for a
  particular offered load and system (application, OS, hardware) that yields ``sweet spots'' where one can
  achieve an acceptable latency distribution while significantly reducing energy
  consumption.

\item Despite complex interactions between software and hardware, the ``sweet spot'' setting for
  a system and load are stable and, once found, will continue to yield good behavior \textit{if} queuing and CPU frequencies are fixed (i.e., not dynamically changed by the OS).

\item A system's response to changes in the queuing and CPU frequencies, at a fixed mean offered load, is well-behaved such that
  it is possible to use a generic black-box search strategy to quickly find a ``sweet spot'' setting on a running system.\footnote{Such an approach has the potential to be
  universal as it operates at runtime on the entire system and does not depend on tables of parameters, prior training, or profiling.}

\end{enumerate}


We explore the first two conjectures in an experimental study (\cref{sec:study}) on two applications across two distinct OSes: Linux and an OS specialized for latency-sensitive applications (EbbRT~\cite{ebbrt}). Similar to Co-PI~\cite{9248059}, we use existing hardware mechanisms: network interrupt coalescing (ITR-delay~\cite{intelinterruptmoderation}) and dynamic voltage frequency scaling~\cite{cpufreq_governor} (DVFS) to externally sweep queuing and CPU frequency on the server for a fixed set of offered load. Our study explored up to 340 combinations of ITR-delay, and DVFS and found "sweet spots" that both improved performance by 60\% while also lowering energy use by 50\% (\cref{sec:closed_energy}) in closed-loop applications. For open-loop applications (\cref{sec:open1}, \cref{sec:open2}), these mechanisms can lower energy use by 76\% in Linux (in contrast to its \textit{ondemand} DVFS policy)\footnote{We've studied the available Linux governors and found \textit{ondemand} to the most appropriate for these workloads.}  while meeting SLA objectives. 
We find that the specialized system has not only much better performance but also achieves a \textbf{further} 43\% reduction in energy. 
Most importantly, we found that, while the settings differ, the general purpose and specialized system have similar responses to changes, suggesting one could formally capture this common structure.

This common structure led us to the third conjecture -- it is plausible to use a generic search strategy to dynamically find energy-efficient ITR-delay, and DVFS settings for a given offered load. 
We successfully model (\cref{sec:model}) our experimental data to capture latency and energy profiles across both OSes. 
The accuracy of our model fit suggests that  a generic black-box-based controller can be used.
We then  built a prototype controller (\cref{sec:cachetrace}) using 
an established machine learning technique, Bayesian optimization~\cite{garnett_bayesoptbook_2022}, and we illustrate its use in exploiting the stable mean demand curve of a publicly available key-value trace~\cite{cacheWorkload-OSDI20} to save up to 60\% in server energy. 
Note that the goal of the prototype is to validate that a black box approach is possible; issues like how and when to trigger search are not studied. 
Finally (\cref{sec:tailbench}) we demonstrate the generality of our approach,  finding savings up to 36\% on applications different from our study (Tailbench~\cite{tailbench}) and on radically different hardware platforms released almost a decade apart 
(i.e. Intel E5-2640-released Q1'12 and Ampere ARMv8 released Q4'21) with different interrupt coalescing mechanisms. 

This work shows that in environments where: 1) dedicated servers are used for critical cloud applications and, 2) there is significant stability (on the order of minutes) in offered load: 
\begin{enumerate}
   \item  There are dramatic energy savings possible if one controls queuing and CPU frequency outside the OS for an offered demand; controls that can be applied to a general purpose OS like Linux with no changes.
   
   \item  Today's specialized research systems that have been developed for performance achieve dramatically better energy use than general purpose system when run baremetal. 
   
    \item A black-box-based controller can be built to exploit the stable demand curves of latency-sensitive applications to find energy-efficient "sweet spots" that are apply across a range of applications, operating systems and hardware. 
\end{enumerate}
The rest of our paper is structured as follows: \cref{sec:study} details our study and some key experimental findings, \cref{sec:model} presents a subset of our modeling results as motivation towards the design and evaluation of our controller in \cref{sec:cachetrace}. We then present related works in \cref{sec:related} and conclude in \cref{sec:conc}.