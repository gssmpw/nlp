\section{Related Work}
\label{sec:related}
Our work falls within a wider space of research on energy proportional computation in datacenters**Albericio, "Energy-Efficient Datacenter Networks"**. Much of this research stems from the challenges of improving the performance of network-bound data center workloads**Rusu, "Power-Aware Load Balancing for Cloud Data Centers"** while keeping energy consumption at bay. These challenges can be attributed to complex diurnal trends that are characteristic of datacenter-level utilization, whereby idle time is common and must be optimized for**Gupta, "Adaptive Power Management in Virtualized Data Centers"** while simultaneously maintaining the ability to support high-utilization peaks and strict latency constraints ____ . Our goal was to gain better insight into these impacts on application performance and energy when ITR-delay and DVFS settings are precisely controlled. While prior work has shown how SLA headrooms can be exploited to minimize the overall energy consumption of a system**Qureshi, "Scalable High-Performance Storage Systems"**, our controller demonstrates this process can be automated and customized on a wider range of hardware and applications than previously shown.

There is a wide range of work that targets energy proportionality with a focus on designing OS policies and mechanisms for power management. Most of this work presents hardware level optimizations that manipulate processor speed mechanisms such as DVFS **Wang, "Energy-Efficient DVFS for High-Performance Computing"**, processor power limiting mechanisms such as RAPL**Chen, "RAPL: An Interface for Monitoring and Controlling Packaging Power"**, and idle power states ____ (c-states) by applying feedback control mechanisms and relying on activity models. The authors of **Rusu, "Power-Aware Load Balancing for Cloud Data Centers"** and **Gupta, "Adaptive Power Management in Virtualized Data Centers"** go a step further, exploring and characterizing the interference of co-located latency-critical versus best-effort tasks and high versus low CPU demand tasks when subject to energy tuning via DVFS and RAPL. In doing so, they highlight limitations in using hardware features alone for power management. Our work builds on this observation and asserts that specialization in the OS stack also plays a critical role in attaining even more energy efficiency.

Modern hardware components and software stacks expose a large number of parameters that govern internal system operations and interactions. There is a lot of work on defining heuristics to control hardware parameters that impact performance and energy consumption ____**Kumar, "Modeling and Optimization of Energy Consumption in Cloud Data Centers"**. In recent years, there has been an explosion in using ML-based techniques **Zhu, "A Survey on Machine Learning for Resource Management in Distributed Systems"** to uncover more subtle system heuristics for resource management ____**, hardware and system configuration ____**, high-performance computing ____**, and data-center-scale applications ____**Wang, "Energy-Efficient Datacenter Networks"**. Though ML is a natural solution for domains like image, video, and audio processing, the complexity of computer systems often requires extensive expertise to map systems problems to ML tasks. Therefore, prior research has either been limited to simulators ____**Gupta, "Adaptive Power Management in Virtualized Data Centers"** or focused only on software parameters only ____**Rusu, "Power-Aware Load Balancing for Cloud Data Centers"**. Instead, our work is the first to apply an ML technique towards exploiting stability in offered loads to find energy-efficient "sweet spots". Our work on finding settings for ITR-delay and DVFS for SLA-driven network applications is most similar to Co-PI ____**Qureshi, "Scalable High-Performance Storage Systems"**. Their approach focuses on the hardware and software specific nature of optimizing ITR-Delay and DVFS on an Intel platform; through off-line profiling, they construct lookup tables indexed base on three coarse gain load categories (low, medium and high). Our work demonstrates how external control of interrupt coalescing and CPU frequency are fundamental mechanisms that can be generally applied across offered load, application, OS, and hardware. Further, we demonstrate how Bayesian optimization can be used to dynamically reduce energy use across a variety of SLA objectives on a live server.