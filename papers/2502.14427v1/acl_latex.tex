\pdfoutput=1
\documentclass[11pt]{article}

\usepackage[final]{acl}
\usepackage{times}
\usepackage{latexsym}
\usepackage{xcolor}
\usepackage{todonotes}

\usepackage[T1]{fontenc}
\usepackage[utf8]{inputenc}

\usepackage{microtype}

\usepackage{inconsolata}

\usepackage{graphicx}
\usepackage{amsmath}
\usepackage{amssymb}
\usepackage{amsfonts}
\usepackage{booktabs}
\usepackage{lipsum}
\usepackage{multicol}
\usepackage{multirow}
\usepackage{bm}
\usepackage{cleveref}
\usepackage{easyeqn}
\usepackage{listings}
\usepackage{placeins}
\usepackage{color,xcolor,colortbl}
\usepackage[multiple]{footmisc}
\usepackage{paralist}
\usepackage{subcaption}
\usepackage{enumitem}

\usepackage{graphicx}

\newcommand{\xv}{\mathbf{x}}
\newcommand{\qv}{\mathbf{q}}
\newcommand{\tv}{\mathbf{t}}
\newcommand{\yv}{\mathbf{y}}
\newcommand{\thetav}{\bm{\theta}}
\newcommand{\BC}{\mathcal{B}}
\newcommand{\TC}{\mathcal{T}}
\newcommand{\EC}{\mathcal{E}}
\newcommand{\QC}{\mathcal{Q}}
\newcommand{\DC}{\mathcal{D}}
\newcommand{\CC}{\mathcal{C}}
\newcommand{\HC}{\mathcal{H}}
\newcommand{\IC}{\mathcal{I}}
\newcommand{\KC}{\mathcal{K}}
\newcommand{\MC}{\mathcal{M}}
\newcommand{\YC}{\mathcal{Y}}
\newcommand{\XSet}{\mathcal{X}}
\newcommand{\uv}{\mathbf{u}}
\newcommand{\multirowcell}[1]{\begin{tabular}[c]{@{}c@{}}#1\end{tabular}}

\title{Token-Level Density-Based Uncertainty Quantification Methods for Eliciting Truthfulness of Large Language Models}

\author{
Artem Vazhentsev\textsuperscript{2,3} \quad
Lyudmila Rvanova\textsuperscript{3,5} \quad
Ivan Lazichny\textsuperscript{3} \enspace
\\
\bf Alexander Panchenko\textsuperscript{2,3}\quad
Maxim Panov\textsuperscript{1}\quad
Timothy Baldwin\textsuperscript{1,4}\quad
Artem Shelmanov\textsuperscript{1}\\
\textsuperscript{1}MBZUAI \;
\textsuperscript{2}Skoltech \; 
\textsuperscript{3}AIRI \;
\textsuperscript{4}The University of Melbourne \; \\
\textsuperscript{5}Laboratory for Analysis and Controllable Text Generation Technologies RAS \; 
\\
\href{mailto:vazhentsev@airi.net}{vazhentsev@airi.net} ~~ 
\href{mailto:artem.shelmanov@mbzuai.ac.ae}{artem.shelmanov@mbzuai.ac.ae}
}


\begin{document}
\maketitle
\begin{abstract}
  Uncertainty quantification (UQ) is a prominent approach for eliciting truthful answers from large language models (LLMs). To date, information-based and consistency-based UQ have been the dominant UQ methods for text generation via LLMs. Density-based methods, despite being very effective for UQ in text classification with encoder-based models, have not been very successful with generative LLMs. In this work, we adapt Mahalanobis Distance (MD) -- a well-established UQ technique in classification tasks -- for text generation and introduce a new supervised UQ method. Our method extracts token embeddings from multiple layers of LLMs, computes MD scores for each token, and uses linear regression trained on these features to provide robust uncertainty scores. Through extensive experiments on eleven datasets, we demonstrate that our approach substantially improves over existing UQ methods, providing accurate and computationally efficient uncertainty scores for both sequence-level selective generation and claim-level fact-checking tasks. Our method also exhibits strong generalization to out-of-domain data, making it suitable for a wide range of LLM-based applications.\footnote{The code is available online at \url{https://github.com/ArtemVazh/token_mahalanobis_distance}}
\end{abstract}


\section{Introduction}

  \begin{figure*}[t!]
    \centering
    \includegraphics[trim={0.cm 0.cm 0.cm 0.cm},clip,width=1.\linewidth]{./token_md.pdf}
    \caption{
    An illustration of the proposed method. After each decoder layer, the embeddings of each generated token are extracted. Subsequently, we compute the Mahalanobis distance for each token and layer and then average over all tokens in the generated sequence. Finally, we train a linear regression on the PCA decomposition of the calculated features with the addition of sequence probability to predict the uncertainty of the generation.}
    \label{fig:tmd_scheme}
  \end{figure*}

  Large language models (LLMs) have achieved impressive results over various tasks and applications~\cite{openai2024gpt4technicalreport,llama3,gemma2}. Nevertheless, even the most advanced LLMs are inevitably prone to making mistakes during text generation. Their responses often contain hallucinations or non-factual claims~\cite{xiao-wang-2021-hallucination,dziri-etal-2022-origin}, posing significant challenges for LLM deployment in safety-critical domains. 

  Many studies have investigated methods for assessing the truthfulness of LLM responses~\cite{manakul2023selfcheckgpt,min2023factscore,chen2023hallucination,feng-etal-2024-dont}. However, many of the proposed techniques have limited practical applicability, as they often rely on external knowledge sources or require ensembling multiple large LLMs, leading to high computational costs that make them economically unfeasible for many use cases.

  One of the most promising approaches to addressing this challenge is uncertainty quantification (UQ)~\cite{gal2016dropout,shelmanov-etal-2021-certain,baan2023uncertainty,geng2023survey,fadeeva2023lm}. This research direction recognizes that we will never have complete information about model predictions due to the limited amount of training data and ambiguity of the tasks, and suggests general ways to estimate the reliability of predictions under different conditions.
  Recently, a suite of UQ methods specifically designed for text generation with LLMs has been developed~\cite{fomicheva-etal-2020-unsupervised,lin2023generating,kuhn2023semantic,farquhar2024detecting,duan-etal-2024-shifting}. However, many of these methods are either ineffective or come with a substantial computational overhead, limiting their practicality for large-scale or real-time applications.

  For text classification and regression tasks, researchers have identified several groups of techniques that maintain a balance between effectiveness and computational efficiency~\cite{zhang-etal-2019-mitigating,he2020towards,xin-etal-2021-art,wang-etal-2022-uncertainty,vazhentsev-etal-2023-hybrid,he-etal-2024-uncertainty}. One such class of approach is so-called \textit{density-based uncertainty scores}~\cite{lee2018simple,ddu_amersfoort,nuq_kotelevskii,yoo-etal-2022-detection}. These methods use embeddings of instances obtained from the top layers of a classification model to fit the density of the training distribution in the latent space. The likelihood of the input data under this estimated distribution is then used for confidence estimation.
  This has been demonstrated to achieve excellent results in out-of-distribution detection tasks~\cite{podolskiy2021revisiting}, and proven to be useful for selective text classification~\cite{vazhentsev-etal-2022-uncertainty,vazhentsev-etal-2023-hybrid}. 
  Despite being computationally lightweight, these techniques often outperform more resource-intensive methods, such as deep ensembles~\cite{NIPS2017_9ef2ed4b} and Monte Carlo dropout~\cite{gal2016dropout,tsymbalov2018dropout}. Unfortunately, the reported performance of density-based scores for text generation so far has been notably low~\cite{vashurin2024benchmakring}. 

  Recent work has demonstrated that the internal states of LLMs carry a lot of information about their uncertainty~\cite{azaria-mitchell-2023-internal,chen2024eigenscore,he-etal-2024-llm,ch-wang-etal-2024-androids,vazhentsev2024unconditional}. These techniques train a supplementary model on top of the activations of LLM internal layers. However, they often rely on simplistic features and fail to incorporate more advanced, well-established density-based UQ methods, limiting their ability to capture uncertainty.

  In this work, we address this gap by adapting density-based techniques for the UQ of LLMs and
  propose a new supervised method based on density-based features. Specifically, we adapt one of the most robust methods for UQ in the classification tasks, namely Mahalanobis Distance (MD;~\citet{lee2018simple}), and train a linear regression on top of the MD scores from various layers of the LLM. These features are supplemented with a probability of the generated sequence. 
  \Cref{fig:tmd_scheme} illustrates the scheme of the proposed supervised UQ method. Our extensive experimental evaluation demonstrates that the proposed method provides substantial improvement over the state of the art.

  Our key \textbf{contributions} are as follows.
  \begin{compactitem}
    \item We conduct a comprehensive investigation of density-based UQ methods for LLMs. While previous research ~\cite{vashurin2024benchmakring} has indicated that sequence-level density-based methods are ineffective, we propose a token-level adaptation of MD that is on par with or better than state-of-the-art UQ techniques.

    \item We propose a new computationally efficient supervised method for UQ in LLMs using layer-wise density-based scores as features to improve uncertainty estimation without sacrificing the performance.

    \item We conduct a vast empirical investigation that demonstrates the effectiveness of the proposed methods for sequence-level selective classification across eleven datasets and claim-level fact-checking.
  \end{compactitem}
    

\section{Related Work}
  Many effective UQ methods, such as deep ensembles~\citep{NIPS2017_9ef2ed4b} and Monte Carlo (MC) dropout~\citep{gal2016dropout}, require sampling multiple predictions from a model, which leads to substantial computational and memory overheads. A key challenge in UQ is developing techniques that balance effectiveness with computational efficiency. Among the most promising approaches in this regard are density-based methods~\cite{lee2018simple,NEURIPS2020_543e8374,ddu_amersfoort,nuq_kotelevskii,yoo-etal-2022-detection}. These methods leverage latent representations of instances to model the training data distribution, then estimate how likely a new instance belongs to that distribution.~\citet{lee2018simple} propose to use Mahalanobis Distance (MD) as a measure of uncertainty for out-of-distribution detection in computer vision tasks. \citet{podolskiy2021revisiting} adapt  MD  to out-of-distribution in text classification tasks. \citet{vazhentsev-etal-2022-uncertainty,vazhentsev-etal-2023-efficient} show that it also provides high performance in selective text classification.  

  For LLMs, \citet{fomicheva-etal-2020-unsupervised} and~\citet{kuhn2023semantic} proposed UQ methods that sample multiple predictions and leverage their diversity. In the context of black-box LLMs, where we have no access to the logits or embeddings of a model, \citet{fomicheva-etal-2020-unsupervised} propose the use of lexical dissimilarity of sampled texts as a measure of uncertainty. \citet{lin2023generating} leverage a similarity matrix between responses for deeper analysis of the diversity of the sampled generations. Some methods also combine sampling diversity measures with the probability of each generation~\cite{kuhn2023semantic,duan-etal-2024-shifting,nikitin2024kernel,cheng-vlachos-2024-measuring,chen2024eigenscore,vashurin2025cocoageneralizedapproachuncertainty}.

  Recently, it was demonstrated that MD is an efficient approach for out-of-distribution detection in sequence-to-sequence models~\cite{vazhentsev-etal-2023-efficient,ren2023outofdistribution,darrin-etal-2023-rainproof}. However, for selective generation tasks, density-based methods so far have substantially underperformed compared to trivial baselines~\citep{vashurin2024benchmakring}.

  Supervised methods are another research direction for UQ of LLMs. \citet{azaria-mitchell-2023-internal} demonstrate that the internal states of the model contain information about uncertainty, and propose to train a multi-layer perceptron over the hidden LLM representation to predict the truthfulness of the model responses. \citet{he-etal-2024-llm} enhance this idea by training a deep neural network with recurrent and convolutional layers. Furthermore, this method uses embeddings from all layers and incorporates features based on the probability and the dynamics of the generated tokens through layers. In contrast to these methods, we employ a simple linear model, but focus on more accurate feature extraction from internal layers, using well-established density-based UQ methods.

\section{Background on Density-Based Methods}
  Recently, Mahalanobis distance (MD) and Robust Density Estimation (RDE) were adapted~\cite{vazhentsev-etal-2023-efficient,ren2023outofdistribution} to the text generation task by considering the marginal distribution of the training dataset. 

  Following the assumption of a Gaussian distribution of training instance representations, the MD method~\cite{lee2018simple} calculates a centroid of the training data $\mu$ and the empirical covariance matrix $\Sigma$. For a given instance $\xv$, the uncertainty score is defined as the Mahalanobis distance:
  \begin{equation*}
    U^{\text{MD}}(\xv, l) = (h_l(\xv) - \mu)^{T} \Sigma^{-1} (h_l(\xv) - \mu),
  \end{equation*}
  where $h_l(\xv)$ is a hidden representation extracted from the layer $l$.

  RDE~\cite{yoo-etal-2022-detection} operates within the reduced dimensionality of $h_l(\xv)$ via the kernel PCA decomposition. To ensure the robustness of the covariance matrix, it uses the Minimum Covariance Determinant estimate~\cite{Rousseeuw84leastmedian}. Finally, the uncertainty score is computed as the Mahalanobis distance in the reduced dimensionality.

  \citet{ren2023outofdistribution} proposed a modification of MD -- Relative Mahalanobis Distance (RMD). It takes into account a background contrastive MD score. The score aims to assess how close the test instance is to the in-domain training data compared to the background data. The uncertainty score based on RMD is given by the following equation:
  \begin{equation*}
    U^{\text{RMD}}(\xv, l) = U^{\text{MD}}(\xv, l) - U^{\text{MD}}_0(\xv, l),
  \end{equation*}
  where $U^{\text{MD}}_0(\xv, l)$ is a Mahalanobis distance computed with the centroid $\mu^0$ and the empirical covariance matrix $\Sigma^0$ calculated using the background dataset, such as C4~\cite{c4dataset}.

  For the sequence-to-sequence tasks, it was proposed to use the last encoder and decoder layer for extracting hidden representation of the model~\cite{vazhentsev-etal-2023-efficient,ren2023outofdistribution}. In contrast, recent research~\cite{azaria-mitchell-2023-internal,chen2024eigenscore} indicates that the middle layers of the model may be more suitable for decoder-only models. 

\section{Proposed Method: Token-Level Mahalanobis Distance}

  To define the method, we assume access to training data consisting of a set of prompts paired with LLM responses, each accompanied by an assessment of its correctness. The assessment can be based on ground truth answers (as in tasks like question-answering, machine translation, or summarization) or through alternative means, such as human annotation or another big LLM.

\subsection{Layer-Wise Uncertainty Score}

\paragraph{Embedding extraction.}
  First of all, we need to extract embeddings of instances in the training dataset. We note that previous works use sequence-level embeddings, which are essentially an average of token-level embeddings. Recent studies~\cite{azaria-mitchell-2023-internal,chen2024eigenscore} note that sequence embeddings might be useless for UQ with LLMs and propose to use embeddings of the last or the first generated token, as they encode useful information for estimating the truthfulness of the entire generation. We acknowledge that this property may not always hold, as the informative tokens are likely to vary depending on the specific task. In our method, we first compute individual token-level uncertainty scores and then aggregate them into a sequence-level score. 

\paragraph{Embedding selection.}
  To construct a covariance matrix and centroid for MD, a model training set is required. 
  However, unlike standard text classification tasks, where training sets are typically limited and accessible during the development of an ML-based application, the pre-training data for general-purpose LLMs is extremely large and usually not publicly available. Moreover, even if this data were available, LLM performance on it would likely be not homogeneous and could be low for certain tasks. Therefore, to construct the parameters for MD, we propose selecting a subset of token embeddings from high-quality LLM responses. 

  From the responses generated in the training set, we select a subset of token embeddings that correspond to responses that meet a defined correctness criterion. Let $\TC$ be a training set of input prompts and $|\TC| = N_{|\TC|}$. For each prompt $\xv^j \in \TC$, the model generates a response as a sequence $\tilde{\yv}^j = \tv^j_1, \dots, \tv^j_{N_j}$, where $N_j$ is a length of the $j$-th generation and $\tv^j_i, i\in[1, \dots, N_j]$ is an $i$-th token in the response. We define a set of selected tokens as $\DC = \{\tv^j_i\colon\QC(\tilde{\yv}^j) > \tau, i\in[1, \dots, N_j], j\in[1, \dots, N_{|\TC|}] \}$, where $\QC(\cdot)$ is a quality metric and $\tau$ is a given threshold. Then $\EC_l = \{h_l(\tv)\colon\tv\in\DC\}$ is the set of selected token embeddings. The correctness criterion helps filter out low-quality responses. Depending on the dataset in the experiment, exact match and AlignScore are employed as quality metrics. The correctness criterion used for token selection is described in \Cref{sec:setup}. 

\paragraph{Layer-wise scores.}
  For each layer $l=1, \dots, L$ of the model, we compute the covariance matrix $\Sigma_{\EC_l}$ and the centroid $\mu_{\EC_l}$ using the set of selected token embeddings $\EC_l$. For each token from the generated sequence $\tilde{\yv}^k = \tv^k_1, \dots, \tv^k_{N_k}$, we compute the layer-wise MD as follows:
  \begin{equation*}
    U^{\text{MD}}(\tv^k_i, l) \!=\! \bigl(h_l(\tv^k_i) - \mu_{\EC_l}\bigr)^{T} \Sigma_{\EC_l}^{-1} \bigl(h_l(\tv^k_i) - \mu_{\EC_l}\bigr).
  \end{equation*}
  %
  For the token-level RMD, we additionally compute the background covariance matrix $\Sigma^0_l$ and the background centroid $\mu^0_l$ using the embeddings of all generated tokens for the input prompts from some background dataset. 

  Finally, the uncertainty score of the entire generated sequence $\tilde{\yv}^k$ is the \textit{Average Token-level Mahalanobis Distances (ATMD)} over $\tv^k_i, i=1, \dots, N_k$ (for RMD, we designate it as ATRMD).

\subsection{Linear Regression on Layer-Wise Scores}
\label{sec:supervised}
  The ATMD and ATRMD scores can be computed on various layers. \citet{azaria-mitchell-2023-internal} indicate that the best-performing layer may vary depending on the generation task. To effectively integrate information from multiple layers, we propose training a regression model on top of the layer-wise scores.

  For a generation $\tilde{\yv}^k$, we construct a vector of features based on $\text{ATMD}$ or $\text{ATRMD}$: $f^{*}(\tilde{\yv}^k)=[U^{*}(\tilde{\yv}^k, 1), \dots, U^{*}(\tilde{\yv}^k, L)]$ (we use $*$ instead of $\text{ATMD}$ or $\text{ATRMD}$). To learn the uncertainty of the generation, we define target variables as negative values of a quality metric for generations $\tilde{\yv}^k$: $\qv^k= - \QC(\tilde{\yv}^k)$. We note that the features $f^{*}(\tilde{\yv}^k)$ might be highly correlated with each other (a multicollinearity problem;~\citet{multicollinearity}), which makes linear models to overfit~\cite{mitigating_multicollinearity}. To make our features more robust, we use top $N=10$ components from the PCA decomposition of feature vectors: $\tilde{f^{*}}(\tilde{\yv}^k) = \text{PCA}_N \bigl(f^{*}(\tilde{\yv}^k)\bigr)$.

  We train the machine learning model $G(\cdot)$ to predict an uncertainty score as follows:
  \begin{enumerate}[topsep=0pt,itemsep=-1ex,partopsep=1ex,parsep=1ex]
    \item Split the entire training dataset $\TC$ into two parts $\TC_1$ and $\TC_2$.
    \item Using $\TC_1$, construct $\EC_l, l \in [1, \dots, L]$ and fit layer-wise covariance matrices and centroids. ATRMD also fits layer-wise background covariance matrices and background centroids.
    \item For each generation $\tilde{\yv}^k, k = 1, \dots, |\TC_2|$ for the prompts from $\TC_2$, compute features $\tilde{f^{*}}(\tilde{\yv}^k)$ and targets $\qv^k$.
    \item Train the machine learning model $G^{*}(\cdot)$ to predict the targets $\qv^k$ using the features $\tilde{f^{*}}(\tilde{\yv}^k)$, $k = 1, \dots, |\TC_2|$. In our work, we use linear regression models as $G^{*}(\cdot)$.
    \item Re-estimate layer-wise parameters of the distribution using the entire training dataset $\TC$.
  \end{enumerate}

  Finally, the supervised uncertainty score for a test generation $\tilde{\yv}^k$ based on token-level MD or RMD, namely SATMD or SATRMD is:
  \begin{equation*}
    U^{\text{S*}}(\tilde{\yv}^k) = G^{*}\bigl(\tilde{f^{*}}(\tilde{\yv}^k)\bigr).
  \end{equation*}

  Following~\citet{he-etal-2024-llm}, we also experiment with adding the sequence probability $P(\tilde{\yv}^k \mid \xv^k)$ as an additional feature to the features vector: $\tilde{f^{*}}_{prob}(\tilde{\yv}^k) = [\tilde{f^{*}}(\tilde{\yv}^k); P(\tilde{\yv}^k \mid \xv^k)]$, and get
  \begin{equation*}
    U^{\text{S*+MSP}}(\tilde{\yv}^k) = G^{*}\bigl(\tilde{f^{*}}_{prob}(\tilde{\yv}^k)\bigr).
  \end{equation*}


\subsection{Hybrid Score}
  In addition, we explore Hybrid Uncertainty Quantification (HUQ;~\citet{vazhentsev-etal-2023-hybrid}), which empirically combines multiple uncertainty scores. Using HUQ, we combine sequence probability $U_{\text{1}}(\tilde{\yv}^k) = 1 - P(\tilde{\yv}^k \mid \xv^k)$ and the proposed SATMD or SATRMD scores: $U_{\text{2}}(\tilde{\yv}^k) = U^{\text{S*}}(\tilde{\yv}^k)$. The hyperparameters of HUQ are tuned on the $\TC_2$ dataset. A detailed description of the HUQ method is given in~\Cref{sec:huq}.
  

\section{Experiments}

  \begin{figure*}[t!]
    \centering
    \includegraphics[trim={0.cm 0.cm 0.cm 0.cm},clip,width=1.\linewidth]
    {./layer_wise_methods_6cols.pdf}
    \caption{
    Performance of embeddings from various layers in density-based scores. PRR$\uparrow$ for density-based methods computed using embeddings from various layers of Llama 8b v3.1 (upper row) and Gemma 9b v2 (lower row) models. Raw ATMD/ATRMD denotes a corresponding method without selecting embeddings using the correctness criterion. Higher values indicate better results.
    }
    \label{fig:tmd_layerwise}
  \end{figure*}

\subsection{Experimental Setup}
\label{sec:setup}
  For the experimental evaluation, we employ the LM-Polygraph framework~\cite{fadeeva2023lm,vashurin2024benchmakring}. We consider two tasks: (1) sequence-level selective generation~\cite{ren2023outofdistribution}, in which we can ``reject'' untruthful generations based on provided uncertainty; (2) claim-level fact-checking~\cite{fadeeva2024factchecking}, where we aim to identify nonfactual claims in long generations, consisting of several claims. 

\paragraph{Metrics.}
  To evaluate the quality of UQ methods on the selective generation task, we use the standard Prediction Rejection Ratio (PPR) metric~\cite{malinin21uncertainty,vashurin2024benchmakring}. This metric measures the correctness of the ranking of generations based on uncertainty relative to a specified quality metric. PRR computes the area under the Prediction Rejection (PR) curve, which is constructed by sequentially rejecting the most uncertain generation and calculating the average quality for all stored generations at each possible threshold. Subsequently, this area is normalized by scaling between the PR curve for the random selection and oracle selection. A higher value of the PRR corresponds to a better quality of selective generation. Following previous work~\cite{vashurin2024benchmakring}, we use ROUGE-L, Accuracy, and AlignScore~\cite{zha-etal-2023-alignscore} as text generation quality metrics.

  For claim-level fact-checking, we follow previous work~\cite{fadeeva2024factchecking} and consider this task as a binary classification problem. We utilize the ROC-AUC and PR-AUC metrics, where nonfactual claims represent a positive class.

\paragraph{Models.}
  For selective generation, we experiment with two state-of-the-art LLMs in their size: Llama@8b~v3.1~\cite{llama3} and Gemma~9b~v2~\cite{gemma2}. For fact-checking, we utilize Mistral 7b v0.1 Instruct~\cite{mistral}. The inference hyperparameters are presented in \Cref{tab:llm_hyperparameters} in \Cref{sec:hyperparameters}.

\paragraph{Datasets.}

  \input{./llama_aggregations}

  We consider several text generation tasks, including text summarization (TS), question-answering (QA) with long free-form answers, QA based on reading comprehension, QA with short free-form answers, and multiple-choice QA. Dataset statistics are presented in~\Cref{tab:dataset_stat} in~\Cref{sec:datasets}. For TS, we utilize XSum~\cite{xsum}, SamSum~\cite{gliwa-etal-2019-samsum}, and the CNN/DailyMail~\cite{see-etal-2017-get} dataset. For QA with long free-form answers, we use PubMedQA~\cite{jin-etal-2019-pubmedqa}, MedQUAD~\cite{medquad}, TruthfulQA~\cite{lin-etal-2022-truthfulqa}, and GSM8k~\cite{gsm8k}. For reading comprehension, we use CoQA~\cite{coqa} and SciQ~\cite{welbl-etal-2017-crowdsourcing}. For QA with short free-form answers, we use TriviaQA~\cite{joshi-etal-2017-triviaqa}. The last three datasets represent the common benchmarks for evaluating UQ methods in previous work~\cite{kuhn2023semantic,duan-etal-2024-shifting,lin2023generating}. For multiple-choice QA, we utilize MMLU~\cite{mmlu}, which is a common dataset for evaluating LLMs.

\paragraph{UQ baselines.}
  In an experimental evaluation, we compare the proposed methods against several UQ baselines, including trivial yet robust information-based methods such as Maximum Sequence Probability (MSP) and Perplexity~\cite{fomicheva-etal-2020-unsupervised}, and consistency-based methods considered state-of-the-art for LLMs~\cite{vashurin2024benchmakring}: Lexical Similarity based on ROUGE-L~\cite{fomicheva-etal-2020-unsupervised}, black-box methods (DegMat, Eccentricity, EigValLaplacian; \citet{lin2023generating}), Semantic Entropy~\cite{kuhn2023semantic}, and Shifting Attention to Relevance (SAR; \citet{duan-etal-2024-shifting}). Furthermore, to ensure the robustness of the proposed methods, the suite of baselines in our experiments also includes methods that utilize model internal states: Factoscope~\cite{he-etal-2024-llm}, SAPLMA~\cite{azaria-mitchell-2023-internal}, and EigenScore~\cite{chen2024eigenscore}. The first two are supervised methods, while EigenScore is unsupervised. Following the previous works~\cite{azaria-mitchell-2023-internal,chen2024eigenscore}, we use embeddings from the middle layer of the model for the latter two methods. For the methods that require sampling, we sample five generations for each input text.

\paragraph{Configuration of ATMD/ATRMD.}
  In in-domain experimental evaluation on the SciQ, CoQA, TriviaQA, MMLU, and GSM8k datasets, we select token embeddings used to construct the covariance matrix and centroids for ATMD and ATRMD from generations that are fully accurate according to the exact match criterion. On other datasets, we utilize generations with AlignScore greater than 0.3. Raw ATMD/ATRMD denotes a corresponding method without selecting embeddings using the correctness criterion.

\subsection{Results}
\paragraph{Layer-wise comparison of density-based methods.}
\label{sec:layer_wise_results}
  \Cref{fig:tmd_layerwise} presents the layer-wise comparison of various sequence-level density-based approaches for selective generation for the Llama 8b v3.1 and Gemma 9b v2 models. These results demonstrate the presence of robust patterns across the majority of datasets and models. 
  
  Consistent with the findings of~\citet{vashurin2024benchmakring}, we observe that in most cases, density-based methods that use sequence-level embeddings (MD, RMD, and RDE) yield PRR scores that are close to or below zero, indicating performance comparable to random selection. Only for GSM8k, these methods provide meaningful uncertainty scores, but they still do not outperform the basic MSP baseline. Furthermore, we see that using sequence-level embeddings derived from internal layers does not improve the performance of density-based methods; they usually perform better when using embeddings from the last layer. 
  \input{./llama}
  
  MD that uses token-level embeddings performs consistently better than the MD based on sequence-level embeddings for all datasets except SamSum, where all methods perform similarly to each other.
  Moreover, density-based methods that compute MD using token-level embeddings from internal layers outperform those that rely on embeddings from the top layers. While for SamSum and MMLU with the Gemma 9b v2 model, ATMD achieves the best performance using the last layer embeddings, for all other cases the best performance is achieved by using embeddings from the middle layers. This finding is consistent with previous research~\cite{azaria-mitchell-2023-internal,chen2024eigenscore}. 
  
  Using the selection of correct generations from the training dataset for fitting the covariance matrix and centroid is key to achieving good performance of the methods based on token-level MDs. ATMD/ATRMD consistently outperform raw ATMD/ATRMD. The highest difference was observed on the MedQUAD and TruthfulQA datasets, where using selection improved PRR by 0.2-0.3. 
  
\paragraph{Comparison of sequence-level aggregations.}
  \Cref{tab:llama_agg_results,tab:gemma_agg_results} in \Cref{sec:aggregation} present the comparison of various sequence-level supervised approaches for selective generation for the Llama 8b v3.1 and Gemma 9b v2 models. The results demonstrate that SATMD and SATRMD provide stable and robust performance, which is often superior or equal to the performance of the MD/RMD using the embeddings from the best layer. As anticipated, the incorporation of MSP as an additional feature or combining it using HUQ significantly improved the performance of SATMD/SATRMD. While on average by mean rank, the best performance across various datasets was achieved by SATMD+MSP, for XSum and SciQ, HUQ-SATRMD exhibited a slight improvement. It is also noteworthy that using RMD led to a consistent improvement in performance compared to the original MD for all variants of the supervised method. 

\paragraph{Main results on the selective generation tasks.}
  The main results on the selective generation tasks for the Llama 8b v3.1 and Gemma 9b v2 models are presented in \Cref{tab:llama_results,tab:gemma_results} in \Cref{sec:overall_results}. In the summarization task, our supervised methods outperform all the baselines on XSum and SamSum.
  HUQ-SATRMD achieves the best performance on the XSum and SamSum datasets in terms of PRR-ROUGE-L. For SamSum, the SATRMD+MSP method significantly outperforms other methods in terms of PRR-AlignScore. For the CNN dataset, the proposed methods demonstrate the second-best results in terms of PRR-ROUGE-L, but they substantially fall behind unsupervised UQ techniques in terms of PRR-AlignScore.

  In the QA tasks with long answers (PubMedQA, MedQUAD, TruthfulQA, and GSM8k), SATRMD+MSP consistently demonstrates the best performance, with a notable margin over best supervised and unsupervised techniques, while HUQ-SATRMD ranks second. In the reading comprehension task, HUQ-SATRMD is the best-performing method. Meanwhile, on the MMLU dataset, SATRMD+MSP is the most effective method, significantly outperforming HUQ-SATRMD and other state-of-the-art baselines.

  Considering QA with short answers on CoQA, we observe that HUQ-SATRMD performs on par with the MSP baseline, while on the SciQ dataset performs the best with a large margin. On TriviaQA, SATRMD+MSP outperforms the MSP baseline, underperforming only sampling-based methods that require much more computation time. 

  Overall, we can conclude that HUQ-SATRMD is the most effective method for summarization and reading comprehension tasks, where it significantly outperforms state-of-the-art unsupervised UQ methods. For all other QA datasets, including those with long answers and tasks requiring internal knowledge, the best performance is demonstrated by SATRMD+MSP.

\paragraph{Out-of-domain generalization.}
  \input{./generalization_llama_v2}

    \begin{figure*}[t!]
    \centering
    \includegraphics[trim={0.cm 0.cm 0.cm 0.cm},clip,width=1.\linewidth]{./impact_threshold.pdf}
    \caption{
    Dependency of PRR$\uparrow$ of the SATRMD+MSP and HUQ-SATRMD methods on the correctness threshold for the embedding selection for the centroid and covariance matrix for MD for the Llama 8b v3.1 model. Higher values indicate better results.
    }
    \label{fig:tmd_threshold}
  \end{figure*}

  \Cref{tab:llama_gen_results} presents a comparison of various sequence-level methods for the selective generation task for the Llama 8b v3.1 model in the out-of-domain settings. We train and evaluate supervised methods using a leave-one-out approach: train on all datasets except one, which is left for testing.
  For each evaluation dataset, the training set is composed of 400 instances sampled from each of the remaining datasets. We use the negative AlignScore generation quality metric as a target for all considered datasets in this setting. 

  The performance of supervised methods in the out-of-domain setting shows a significant decline compared to the in-domain setting. Despite this, HUQ-SATRMD achieves the best results according to the mean rank, outperforming unsupervised state-of-the-art methods across the majority of datasets and metrics, except MSP on SamSum and MedQUAD in terms of PRR-ROUGE-L. Notably, when testing on the MMLU dataset, the training data consists of texts from summarization tasks and free-form QA, which differ significantly from the multiple-choice QA format used in MMLU. Nevertheless, the strong performance on MMLU demonstrates the potential of our supervised method HUQ-SATRMD for broad generalization.
  
  Other supervised methods, including SATRMD+MSP and the baselines, show significantly poorer results in the out-of-domain setting. SATRMD+MSP underperforms MSP on several datasets, including SamSum, MedQUAD, and TruthfulQA. SAPLMA and Factoscope are not able to provide meaningful uncertainty scores, lagging significantly behind unsupervised UQ methods.

\paragraph{Fact-checking results.}

\input{./factchecking}

  \Cref{tab:factcheking_results} presents a comparison of various claim-level methods for the fact-checking task using the Mistral 7b v0.1 Instruct model. The baseline supervised method SAPLMA performs similarly to a random choice. Our method SATRMD provides meaningful uncertainty scores slightly outperforming Maximum Claim Probability (MCP). We note that CCP, like MCP, is also based on the probabilities derived from the model output but demonstrates better performance than MCP. Consequently, we combine CCP with SATRMD to provide more effective claim-level fact-checking. The results demonstrate that HUQ-SATRMD achieves the best results in terms of ROC-AUC, outperforming CCP by 3.4\%, while in terms of PR-AUC, SATRMD+CPP is the best, outperforming CCP by 2.6\%. These results demonstrate that the proposed SATRMD methods are effective not only for sequence-level uncertainty quantification but also for estimating uncertainty on the claim level.

  \begin{figure*}[t!]
    \centering
    \includegraphics[trim={0.cm 0.cm 0.cm 0.cm},clip,width=1.\linewidth]%{./pca_impact.pdf}
    {./pca_impact_6cols.pdf}
    \caption{
    Dependency of PRR$\uparrow$ of the SATRMD+MSP and HUQ-SATRMD methods on the number of the PCA components for the features of linear regression for the Llama 8b v3.1 model. Higher values indicate better results.
    }
    \label{fig:tmd_pca}
  \end{figure*}

\paragraph{Impact of training data size.}
  \Cref{fig:tmd_trainsize} in \Cref{sec:trainsize_results} illustrates the dependency of the performance of supervised UQ methods on the size of the training data. As expected, the optimal results on all datasets are achieved when the maximum number of training instances is used. 
  Nevertheless, for all datasets, except SamSum and MedQUAD, the results obtained with 200-500 training instances are only slightly lower than with 2,000-5,000 instances. Furthermore, even with fewer than 200 training instances for MedQUAD, GSM8k, and MMLU, HUQ and SATRMD+MSP are able to substantially outperform the MSP method. These results demonstrate the robustness of the proposed methods with respect to the size of the training dataset.

\paragraph{Impact of the correctness threshold.}
  \Cref{fig:tmd_threshold} presents the dependence of the performance of the SATRMD+MSP and HUQ-SATRMD methods on the correctness threshold used for the embedding selection for computing the centroid and covariance matrix for MD. %We demonstrate the datasets, for which we use AlignScore as a correctness metric. 

  The results demonstrate that the proposed methods are generally not sensitive to the correctness threshold and consistently show high performance. However, for the MedQUAD dataset, we can see the results with a threshold of 0.3 are significantly better than those with other thresholds. Specifically, lower thresholds (e.g., 0.1) result in selecting the embeddings corresponding to incorrect instances, while higher thresholds (e.g., 0.8) exclude some embeddings associated with correct instances. Both scenarios result in suboptimal estimation of the centroid and covariance matrix, leading to a slight degradation in overall performance.

\paragraph{Impact of the number of PCA components.}
  \Cref{fig:tmd_pca} illustrates the impact of the number of PCA components used for the features of linear regression on the performance of SATRMD+MSP and HUQ-SATRMD methods. The best performance is achieved with 10 or 20 components for most datasets. Only for CNN and TruthfulQA, using just 2 components yields slightly better results than using more. Overall, these results indicate that our choice of 10 components is well-balanced on average across multiple datasets. We also observe that results with more than five PCA components remain stable across all datasets, showing minimal variation. Therefore, methods based on RMD are not sensitive to the precise choice of the number of PCA components.

\paragraph{Computational efficiency.}
  \Cref{tab:comp_efficiency} in~\Cref{sec:comp_eff} summarizes the average runtime per instance for each UQ method, along with the percentage overhead compared to standard LLM inference. State-of-the-art UQ methods that require sampling from the LLM multiple times (Semantic Entropy, SAR, Lexical Similarity) introduce a huge computational overhead (315-700\%). In contrast, the proposed methods HUQ-SATRMD and SATRMD+MSP introduce minimal overhead (5.3-7.6\%), which makes them much more practical.

 
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\section{Conclusion}
  We have introduced a series of new supervised UQ methods based on layer-wise features derived from the Mahalanobis distance. We show that calculating MD over token-level embeddings yields much better results than previous attempts that leverage sequence-level embeddings. Training a linear regression on top of the layer-wise scores allows us to produce even better uncertainty scores and outperform the state-of-the-art supervised and unsupervised UQ methods in selective classification across eleven datasets and in claim-level fact-checking.
  We also show that the proposed methods are computationally efficient and have the potential for generalization, which makes them useful in real-world LLM-based applications.

  In future work, we aim to improve the generalization capabilities of the supervised UQ methods on out-of-domain data by investigating new features and a more robust training pipeline.

\section*{Limitations}
  Our approach is supervised, which means that its performance depends on the quality and size of the data available for supervision. We evaluated the robustness of the approach to dataset variation, which demonstrates that the method does not significantly degrade its quality compared to the target dataset. Nevertheless, we observe certain performance drops; thus, the resulting UQ method should be used with care beyond the supervision domain.

  We did not test our method on very large LLMs, such as LLaMA 3 70b, as we were limited to using 7-9b models due to constraints in our computational resources.

\section*{Ethical Considerations}
  In our study, we focused on open-source LLMs and datasets that are not designed to produce harmful content. However, LLMs can still generate potentially harmful texts that may impact various groups. Uncertainty quantification techniques offer a way to enhance the reliability of neural networks and can even be used to detect harmful outputs, though this is not our focus.

  Although our proposed method shows substantial performance improvements, it may sometimes incorrectly flag safe and accurate generated text as having high uncertainty. While we explicitly benchmarked the method on robustness to the task change, its applicability across various tasks remains limited.

\section*{Acknowledgments}
We thank the anonymous reviewers for their valuable suggestions, which significantly contributed to improving this paper.

\bibliography{custom}

\appendix
\onecolumn

\section{Additional Experimental Results}
\label{sec:experiments}

\subsection{Comparison of Sequence-Level Aggregations}
\label{sec:aggregation}
  \input{./gemma_aggregations}

\subsection{Selective Generation Results}
\label{sec:overall_results}
  \input{./gemma}

\subsection{Dependency on the Size of the Training Dataset}
\label{sec:trainsize_results}
  \Cref{fig:tmd_trainsize} presents the results when varying the size of the training dataset for the supervised methods. We train the linear regression model on the training datasets of size: 100, 200, 500, 1000, 2000, and additionally on a training dataset of 5000 instances for SciQ and MMLU. Since the TruthfulQA dataset consists of only 817 instances, of which we use 409 instances as the test subset, we train linear regression on the training datasets of sizes: 100, 200, and 408. 

  \begin{figure*}[ht!]
    \centering
    \includegraphics[trim={0.cm 0.cm 0.cm 0.cm},clip,width=1.\linewidth]{./train_size.pdf}
    \caption{
    Dependency of PRR$\uparrow$ of the supervised methods on the size of the training dataset for the Llama 8b v3.1 model. Higher values indicate better results.
    }
    \label{fig:tmd_trainsize}
  \end{figure*}

\section{Hybrid Uncertainty Quantification}
\label{sec:huq}
  We combine the sequence probability $U_{\text{1}}(\tilde{\yv}^k) = 1 - P(\tilde{\yv}^k \mid \xv^k)$ with the SATMD and SATRMD methods $U_{\text{2}}(\tilde{\yv}^k) = U^{\text{S*}}(\tilde{\yv}^k)$. For a given $\TC_1$ and $\TC_2$ from~\Cref{sec:supervised}, and trained SATRMD method, we fit HUQ hyperparameters on the $\TC_2$ set.

  Following~\citet{vazhentsev-etal-2023-hybrid}, we define the set of in-distribution instances from $\TC_2$ as follows: $\TC_{\text{ID}} = \{\xv \in \TC_2\colon U_{\text{2}}(\xv) \leq \delta_{\min}\}$. We define the set of arbitrary in-distribution instances $\XSet_{\text{ID}} = \{\xv\colon U_{\text{2}}(\xv) \leq \delta_{\min}\}$ and ambiguous in-distribution instances $\XSet_{\text{IDA}} = \{\xv {\in \XSet_{\text{ID}}}\colon U_{\text{1}}(\xv) > \delta_{\max}\}$ using $\delta_{\min}$, $\delta_{\max}$ are thresholds selected on the $\TC_2$ dataset. 

  To make different uncertainty scores comparable, we define a ranking function $R(\uv, \mathfrak{D})$ as a rank of $\uv$ over a sorted dataset $\mathfrak{D}$, where $\uv_1 > \uv_2$ implies $R(\uv_1, \mathfrak{D}) > R(\uv_2, \mathfrak{D})$. We compute the total uncertainty $U_{\text{T}}(\xv)$ as a linear combination $U_{\text{T}}(\xv) = \!\!(1 - \alpha) R(U_{\text{2}}(\xv), \TC_2) + \alpha R(U_{\text{1}}(\xv), \TC_2)$, where $\alpha$ is a hyperparameter selected on the $\TC_2$ dataset. As a result, we define HUQ as follows:
  \begin{equation*}
    U_{\text{HUQ}}(\xv)
    = 
    \begin{cases}
      R(U_{\text{1}}(\xv), \TC_{\text{ID}}), \forall \xv \in \XSet_{\text{ID}} \setminus \XSet_{\text{AID}}, \\
      R(U_{\text{1}}(\xv), \TC_2),  \forall \xv \in \XSet_{\text{AID}}, \\
      U_{\text{T}}(\xv), \forall \xv \notin \XSet_{\text{ID}}.
    \end{cases}
  \end{equation*}

\section{Computational Efficiency}
\label{sec:comp_eff}
  \input{./comp_time}

\section{Computational Resources}
  All experiments were conducted on a cluster with 6 NVIDIA H100 GPUs. The total time for all conducted experiments for all models across all datasets is approximately 400 GPU hours.

\section{Dataset Statistics}
\label{sec:datasets}
  \input{./datasets}

\clearpage
\section{Inference Hyperparameters}
\label{sec:hyperparameters}
  \input{./llms_hp}

\end{document}
\typeout{get arXiv to do 4 passes: Label(s) may have changed. Rerun}