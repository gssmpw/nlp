\section{Related Work}
Many effective UQ methods, such as deep ensembles____ and Monte Carlo (MC) dropout____, require sampling multiple predictions from a model, which leads to substantial computational and memory overheads. A key challenge in UQ is developing techniques that balance effectiveness with computational efficiency. Among the most promising approaches in this regard are density-based methods____. These methods leverage latent representations of instances to model the training data distribution, then estimate how likely a new instance belongs to that distribution.____ propose to use Mahalanobis Distance (MD) as a measure of uncertainty for out-of-distribution detection in computer vision tasks. ____ adapt  MD  to out-of-distribution in text classification tasks. ____ show that it also provides high performance in selective text classification.  

  For LLMs, ____ and____ proposed UQ methods that sample multiple predictions and leverage their diversity. In the context of black-box LLMs, where we have no access to the logits or embeddings of a model, ____ propose the use of lexical dissimilarity of sampled texts as a measure of uncertainty. ____ leverage a similarity matrix between responses for deeper analysis of the diversity of the sampled generations. Some methods also combine sampling diversity measures with the probability of each generation____.

  Recently, it was demonstrated that MD is an efficient approach for out-of-distribution detection in sequence-to-sequence models____. However, for selective generation tasks, density-based methods so far have substantially underperformed compared to trivial baselines____.

  Supervised methods are another research direction for UQ of LLMs. ____ demonstrate that the internal states of the model contain information about uncertainty, and propose to train a multi-layer perceptron over the hidden LLM representation to predict the truthfulness of the model responses. ____ enhance this idea by training a deep neural network with recurrent and convolutional layers. Furthermore, this method uses embeddings from all layers and incorporates features based on the probability and the dynamics of the generated tokens through layers. In contrast to these methods, we employ a simple linear model, but focus on more accurate feature extraction from internal layers, using well-established density-based UQ methods.