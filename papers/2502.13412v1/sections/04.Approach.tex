\section{APPROACH}

\begin{figure*}[t]
    \centering
    \includegraphics[width=1.0\linewidth]{materials/figs/methodology/approach.pdf}
    \caption{Overall Framework of Our Method.}
    \label{fig: approach}
\end{figure*}

In this paper, we propose an LLM-based automated method for API KG construction.
The overall framework of our method is shown in Fig.~\ref{fig: approach}, which consists of three modules: KG exploration, KG construction, and KG filtering.
The KG exploration module thoroughly analyzes entity types and relation types from seed texts.
It then combines entity types and relation types comprehensively using a fully connected strategy to form a KG schema containing all potential type triples.
The KG construction module extracts instance triples based on this schema to construct a rich but unreliable KG, which may contain some suspicious instance triples.
The KG filtering module then removes these suspicious instances using frequency-based statistics, constructing a rich and reliable KG.
Next, we will introduce each module in detail.

% In this paper, we propose an automated schema-based method for API KG construction, as shown in Fig.~\ref{fig: approach}, which consists of three modules: KG exploration, KG construction, and KG filtering.
% The KG Exploration module deeply analyzes entity types and relation types from seed texts, and comprehensively combines them using a fully connected strategy to form a KG schema containing all potential type triples, thereby enhancing the utility of the KG.
% The KG Construction module extracts instances based on this schema to build a preliminary KG, which may include some suspicious instance triples.
% The KG Filtering module removes suspicious instances using frequency statistics, improving the reliability of the KG.
% Our method enhances the efficiency of KG construction while ensuring its utility and reliability.

\subsection{KG Exploration}
To construct a richness API KG, the primary task is to design a KG schema that contains diverse entity types and relation types.
To achieve this, we design the KG exploration module, which follows the principle of ``abstracting high-dimensional types from low-dimensional facts'' to automatically design the KG schema in a bottom-up manner.
As shown in Fig.~\ref{fig: module1}, the KG Exploration module consists of seven functional units: entity extraction, relation extraction, entity type labeling, relation type labeling, entity type fusion, relation type fusion, and fully connected KG schema generation.
Among them, except for the relation type labeling and the fully connected KG schema generation unit, the other units are all AI units, which implement specific functions by calling LLMs.  
The input of the KG exploration module is a set of seed texts, and the output is a potential KG schema.
Next, we will provide a detailed description of the functional units of this module to help understand its workflow.


\begin{figure}[t]
    \centering
    \includegraphics[width=1.0\linewidth]{materials/figs/methodology/module1.pdf}
    \caption{Workflow of KG Exploration Module.}
    \label{fig: module1}
\end{figure}

\subsubsection{Entity Extraction}
This unit is used to extract API entity instances of any type from the given text.
As shown in Fig.~\ref{fig: module1}, the input of this unit is natural language text, and the output is the API entities contained in the text.
To improve the performance of LLMs, based on the extensive prompting pattern proposed by Xing et al.~\cite{xing2025when}, we format the natural language prompt into a controllable structured prompt. 
For each AI unit of our framework, we provide a detailed description of its prompt design, including role descriptions, task commands, and considerations, as well as four illustrative examples.
For more details, please refer to the Appendix~\ref{sec: appendix}.
The structured prompt design for this unit is shown in Fig.~\ref{fig: ee}.

\subsubsection{Relation Extraction}\label{sec: relation extraction}
To extract the relations between API entities more accurately, similar to previous works~\cite{yanbang2}, we combine the extracted entities into API pairs. 
For example, \textit{$e_{1}$}, \textit{$e_{2}$}, and \textit{$e_{3}$} can be combined into (\textit{$e_{1}$}, \textit{$e_{2}$}), (\textit{$e_{2}$}, \textit{$e_{3}$}), and (\textit{$e_{1}$}, \textit{$e_{3}$}).
As shown in Fig.~\ref{fig: module1}, we input the text and API entity pairs into the relation extraction unit at the same time, it outputs the instance triples in the form of (\textit{$e_{head}$}, \textit{r}, \textit{$e_{tail}$}).
The structured prompt design for this unit is shown in Fig.~\ref{fig: re}.

\subsubsection{Entity Type Labeling}
This unit is used to label the entity types of API entities. 
As shown in Fig.~\ref{fig: module1}, its input is the text and the extracted API entities, and its output is the entity type to which each entity belongs.
In order to achieve the goal of abstracting high-dimensional types from low-dimensional facts, this unit should output specific and low-dimensional entity types, such as concrete class, utility class, etc.
Please refer to Fig.~\ref{fig: etl} for more detailed information.

\subsubsection{Relation Type Labeling}\label{sec: Relation Type Labeling}
The relation type labeling unit is used to label the relation types of the relation. 
Since the relation instances in the instance triples are concise enough, they can be regarded as low-dimensional relation types.
In short, the relation types here are exactly the relation instances in the instance triples, so this unit is a non-AI unit and does not require the participation of the LLM.

\subsubsection{Entity Type Fusion}
As shown in Fig.~\ref{fig: module1}, this unit can only start after the entity types in all the seed texts have been labeled.
It takes all low-dimensional entity types as input and outputs new high-dimensional entity types.
For example, concrete class and utility class are fused into the class category.
To improve the accuracy of subsequent schema-guided entity extraction, this unit also generates definitions for each fused entity type.
Moreover, it outputs the mapping between the new entity types and the original types, such as ``class: [concrete class, utility class]'', for performance evaluation.
The prompt design for this unit can be seen in Fig.~\ref{fig: etf}.

\subsubsection{Relation Type Fusion}
The relation type fusion unit abstracts low-dimensional relation types into high-dimensional ones. 
It takes all low-dimensional relation types as input and outputs new high-dimensional relation types.
For example, ``relies on'' and ``depends on'' can be fused into new relation type ``dependency''
This unit can only start after all relation types have been extracted from the seed texts.
It also outputs the definition of the new relation type and the mapping between the new relation type and the low-dimensional relation types.
More details of this unit can be found in Fig.~\ref{fig: rtf}.

\subsubsection{Fully Connected KG Schema Generation}
This unit is used to construct the KG schema, which guides the subsequent schema-based entity extraction and relation extraction units.
Its input consists of the fused entity types and relation types, and its output is a KG schema containing type triples.
In order to construct an API KG with rich API knowledge, we would like to mine as many type triples as possible.
Therefore, this unit adopts a full combination strategy, combining all entity types and relation types to generate all potential type triples.
For example, given two fused entity types \textit{$ET_1$} and \textit{$ET_2$}, and two fused relation types \textit{$RT_1$} and \textit{$RT_2$}, they can be combined into four potential type triples, such as (\textit{$ET_1$}, \textit{$RT_1$}, \textit{$ET_2$}).

\vspace{-2mm}
\subsection{KG Construction}
To construct API KG based on KG schema, we design the KG construction module.
As shown in Fig.~\ref{fig: module2}, this module consists of three functional units: schema-guided entity extraction, schema-guided relation extraction, and entity-relation collection. 
The first two are AI units while entity-relation collection is a non-AI unit.
Next, we will describe these units.

\subsubsection{Schema-guided Entity Extraction}
This unit is used to extract API entities of a given type from the text. 
Its input is the text, entity types and their definitions, and its output is API entity instances and the entity types to which they belong.
The prompt design of this unit can be seen in Fig.~\ref{fig: see}.

\subsubsection{Schema-guided Relation Extraction}
To improve the accuracy of relation extraction, we combine the extracted API entities into API pairs.
Then, we input the text, API entity pairs, and the relation types into this unit, which output are the extracted API relations and the relation types to which they belong.
Please refer to Fig.~\ref{fig: sre} for more details.


\subsubsection{Entity-Relation Collection}
After extracting entities and relations from all the texts, this unit will collect all the instance triples and their type information to construct the API KG.

\begin{figure}[t]
    \centering
\includegraphics[width=1.0\linewidth]{materials/figs/methodology/module2.pdf}
    \caption{Workflow of KG Construction Module.}
    \label{fig: module2}
\end{figure}

\vspace{-2mm}
\subsection{KG Filtering}
Since the KG exploration module is fully automated and lacks manual verification of the KG schema, there may be many invalid type triples.
As a result, the KG constructed based on this schema may contain suspicious instance triples.
To remove these suspicious instance triples, we design a KG filtering module.
As shown in Fig.~\ref{fig: module3}, this module consists of two non-AI units: KG schema update and KG update.

\subsubsection{KG Schema Update}
This unit is used to remove invalid type triples in the KG schema.
Its inputs are the unreliable KG and the potential KG schema, and its output is the validated KG schema.
In this module, we adopt a frequency-based method to access the validity of type triples.

In the field of data mining, the association rule is often used to measure the association strength between different items~\cite{asso1, asso2, asso3}.
Inspired by this, we apply the association rule to evaluate the association strength between entity types and relation types in type triples, that is, the validity of type triples.
However, there are various ways to construct association rules. 
For example, the relation type can be inferred from the entity type pair, that is, ($ET_{1}$, $ET_{2}$) $\rightarrow$ $RT_{1}$;
another entity type can also be inferred from a certain entity type and the relation type, that is, ($ET_{1}$, $RT_{1}$) $\rightarrow$ $ET_{2}$.
Since this paper mainly focuses on the potential relation types between entity types, the \textit{Pattern} ($ET_{1}$, $ET_{2}$) $\rightarrow$ $RT_{1}$ is adopted.
For this \textit{Pattern}, the method includes three metrics:

\begin{itemize}[leftmargin=*]
    \item \textit{Support}: It refers to the proportion of the number of type triples 
    $\mathit{(ET_{1}, RT_{1}, ET_{2})}$ in the KG, which can be used to measure the universality of the type triple.
    Its calculation formula is as follows, where \textit{all} refers to the total number of type triples.
    \[
    \small \textit{Support}\left( \textit{Pattern} \right) = \frac{\textit{num}\left( \mathit{ET_1, RT_1, ET_2} \right)}{\textit{all}}
    \]
    \item \textit{Confidence}: It refers to the conditional probability of the appearance of the relation type $RT_{1}$ under the condition that the entity types $ET_{1}$ and $ET_{2}$ already exist, which can be used to measure the reliability of the type triple. 
    Its calculation formula is as follows:
    \[
    \small \textit{Confidence}\left( \textit{Pattern} \right) = \frac{\textit{Support}\left( \textit{Pattern} \right)}{\textit{Support}\left( ET_1, ET_2 \right)}
    \]
    \item \textit{Lift}: It is the ratio of the confidence of the \textit{Pattern} ($ET_{1}$, $ET_{2}$) $\rightarrow$ $RT_{1}$ to the probability of the relation type $RT_{1}$ appearing independently in the KG, which is used to measure whether there is dependence between ($ET_{1}$, $ET_{2}$) and $RT_{1}$. 
    Its calculation formula is as follows:
    \[
    \small \textit{Lift}\left( \textit{Pattern} \right) = \frac{\textit{Confidence}\left( \textit{Pattern} \right)}{\textit{Support}\left( RT_1 \right)}
    \]
\end{itemize}

\begin{figure}[t]
    \centering
\includegraphics[width=1.0\linewidth]{materials/figs/methodology/module3.pdf}
    \caption{Workflow of KG Filtering Module.}
    \label{fig: module3}
    \vspace{-4mm}
\end{figure}


In summary, these three metrics evaluate the validity of type triples from different perspectives.
The support reflects the universality, the confidence reflects the reliability of the association, and the lift reflects the interdependence.
However, when the thresholds are set too high, some valid type triples will be missed;
conversely, when the thresholds are set too low, some invalid triples will be retained.
To address this, we design an experiment to explore the optimal choice of thresholds (see Section~\ref{sec: RQ1} for details).
Finally, \textit{Support}, \textit{Confidence}, and \textit{Lift} are set to 0.005, 0.02, and 1.0, respectively.
In this unit, a type triple can be considered valid only when the values of these three metrics of the type triple are all higher than their respective thresholds.
Based on this, we remove the invalid type triples and obtain a validated KG schema.

\subsubsection{KG Update}
With the validated KG schema, we can compare the type information in the KG with the type triples, and then remove the suspicious instance triples in the KG.
Therefore, the inputs to this unit are the validated KG schema and the unreliable KG, and the output is the reliable KG.

\begin{figure*}[t]
    \centering
    \includegraphics[width=1.0\linewidth]{materials/figs/methodology/running_example.pdf}
    \caption{Running Example of Our Framework.}
    \label{fig: running example}
\end{figure*}

\subsection{Running Example}
In this section, we will use an example to explain the execution process of our framework in detail.
As shown in Fig.~\ref{fig: running example}, we select a small portion of text from Stack Overflow posts as the seed text, and another portion as the text to be extracted.
In the KG exploration module, the Seed Texts are first input into the entity extraction unit, which outputs API entities like \textit{Collections} and \textit{Arrays}.
These entities are then combined into API pairs, such as (\textit{Collections}, \textit{Arrays}).
The entity pairs, along with the text, are then input into the relation extraction unit, resulting in instance triples like (\textit{Arrays}, \textit{outperforms}, \textit{Collections}).
Simultaneously, the API entities are sent to the entity type labeling unit to generate the specific entity type for each entity (e.g., utility class), and the instance triples are processed by the relation type labeling unit to obtain the relation type (e.g., outperforms).
The entity type fusion unit then merges all specific entity types into abstract types (e.g., class), while the relation type fusion unit combines all relation types into abstract relation types (e.g., preference). Finally, these entity and relation types are combined to form a comprehensive KG schema, consisting of 12 type triples, e.g., (\textit{class}, \textit{preference}, \textit{class}).
In this schema, as shown in Fig.\ref{fig: running example}, blue and green nodes represent method and class entity types, while red, yellow, and pink edges represent dependency, preference, and equivalence relation types, respectively.

In the KG construction module, all texts and the KG schema containing all potential type triples are input into the schema-guided entity extraction unit, which identifies API entities based on specific entity types (e.g., \textit{Collections.sort}: \textit{static method}).
These entities are then paired to form API pairs.
Next, the API pairs, along with the text and schema, are input into the schema-guided relation extraction unit, which generates instance triples that match specific relation types, e.g., (\textit{method}, \textit{dependency}, \textit{method}): (\textit{Collections.sort}, \textit{relies on}, \textit{ArrayList.asList}).
After all the entities and relations have been extracted from the text, the entity-relation collection unit gathers these instance triples and their type information to construct the API KG, which includes 6 entities and 4 instance triples.
However, because the schema contains invalid type triples (e.g., (\textit{class}, \textit{equivalence}, \textit{method})), some instance triples in the KG are suspicious (e.g., (\textit{ArrayList}, \textit{similar to}, \textit{Collections.reverse})).
To ensure the KG's reliability, these suspicious instance triples must be removed.

As shown in Fig.~\ref{fig: running example}, the KG schema with all potential type triples and the unreliable KG are input into the KG filtering module. 
This module calculates the support, confidence, and lift for each type triple, removing those that do not meet the threshold, along with their corresponding instance triples from the API KG.
For example, the type triple (\textit{class}, \textit{equivalence}, \textit{method}) falls below the threshold, so it is removed from the KG schema, along with the instance triple (\textit{ArrayList}, \textit{similar to}, \textit{Collections.reverse}) from the KG. 
Finally, the KG filtering module outputs a validated KG schema with 6 type triples and a reliable KG containing 6 entities and 3 instance triples.

