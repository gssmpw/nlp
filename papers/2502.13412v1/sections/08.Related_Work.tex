\section{RELATED WORK}
An API KG is a complex network that represents API entities and their relations using a graph structure.
In an API KG, nodes typically represent API entities (e.g., classes, methods, etc.), while edges represent relations between entities (e.g., invocation, constraint, etc.).
The construction of an API KG aims to extract structured knowledge from API documentation, codebases, and other resources, helping developers better understand and utilize APIs.
For example, an API KG can recommend suitable APIs for specific tasks to developers~\cite{huang2023answering}.
Additionally, API KGs can support tasks such as code generation~\cite{liao20243, liu2023codegen4libs} and misuse detection~\cite{ren2023misuse, Ren2020APIMisuseDD}.



Early API KG construction methods~\cite{Ren2021KGAMDAA, Liu2020GeneratingCB, Li2018ImprovingAC} rely on manually designed KG schemas.
These methods typically follow a ``pipeline'' approach, including sub-tasks such as entity identification, entity classification, and relation classification.
For instance, entity identification may use regular expressions~\cite{bacchelli2010linking}, island parsing~\cite{Treude2016AugmentingAD}, or heuristic rules~\cite{Huang2018APIMR}, while relation classification relies on syntactic analysis and annotation techniques~\cite{Liu2020GeneratingCB, li2018improving}.
Additionally, some studies attempt to use machine learning methods to automate the extraction of entities and relations.
For example, Ye et al.~\cite{crf1} propose APIReal, which uses CRF to identify API entities.
Huo et al.~\cite{lstmcrf} design ARCLIN, which uses BI-LSTM as encoder and CRF as decoder to identify API entities, rather than just CRF.
To further improve the accuracy of knowledge extraction, Huang et al. propose AERJE~\cite{yanbang1}, which achieves joint extraction of API entities and relations by fine-tuning a T5 model.
Although these methods perform well in specific scenarios, they also have significant limitations.
% First, manually designed patterns and rules require extensive domain knowledge and time investment.
On one hand, rule-based methods have limited generalization ability and struggle to adapt to the diversity of different API documents.
On the other hand, machine learning methods typically require large amounts of labeled data, which is particularly challenging in low-resource environments.


With the advancement of LLM technologies, LLM-based KG construction methods have gradually become mainstream.
These methods can be categorized into schema-based and schema-free approaches, depending on whether they rely on predefined KG schemas. Schema-based methods depend on predefined schemas to guide the extraction of entities and relations.
By adding entity and relation types into prompts, they guide the LLM to generate triples that conform to the schema.
For example, Huang et al.~\cite{yanbang2} use GPT-4 to infer API instance triples that align with predefined relation types.
However, schema-based methods also face several challenges: first, schema design requires extensive domain knowledge and manual intervention, which limits automation;
second, manually designed KG schemas may fail to cover all potential relation types, leading to insufficient KG coverage.
For example, Huang et al.~\cite{Manual} only summarize 9 types of semantic relation types, while we discover 13 types.


To reduce manual effort, researchers attempt to build KGs using schema-free methods.
These methods do not rely on predefined schemas and directly extract relation triples from text, making them widely applicable in the field of natural language processing.
For example, Han et al.~\cite{han2023pive} propose the PIVE, which iteratively supplements additional triples by prompting LLMs. Zhang et al.~\cite{EDC} introduce the EDC, which constructs KGs from domain information through steps such as extraction, definition, and normalization.
In our field, researchers focus more on using LLMs to extract API entities rather than relation triples.
For instance, Huang et al. propose PCR~\cite{PCR}, which utilizes Copilot to extract simple names of APIs.
However, schema-free methods also face several challenges.
First, the constructed KGs lack type information, which limits their effectiveness in retrieving specific information.
Second, the relation triples output by LLMs may contain noise.
On the contrary, we propose an automated schema-based API KG construction method.
This method not only alleviates the manual overhead in schema design but also reduces noise through schema-guided API entity-relation extraction.
The KG constructed by this method contains rich type information, significantly enhancing its practicality.




% These methods leverage pre-trained models like T5~\cite{raffel2020exploring} and GPT-3~\cite{Brown2020LanguageMA} to extract entities and relations. 
% For example, AERJE~\cite{AERJE} uses T5 to extract both entities and relations, 
% APIRI relies on GPT-3.5~\cite{GPT3-5} for relation extraction, 
% and PCR~\cite{PCR} utilizes Copilot~\cite{copilot} to extract API simple names and FQNs. 
% However, these methods still require manual KG schema design, limiting full automation.


% Recently, some methods have been able to automatically generate API KG schemas and construct API KGs based on them. 
% For example, the semi-automated method GraphRAG~\cite{GraphRAG} analyzes data from the perspective of API entity types, generating a schema with only entity types, and extracts entity and relation instances (without relation types) to build the KG. 
% Similarly, the automated method EDC~\cite{EDC} focuses on relation types, generating a schema with only relation types, and extracts instances without entity types. 
% However, these methods still face issues like missing types, missing instances, and containing suspicious instances during KG construction. 
% To address these challenges, we propose an LLM-based intelligent method that simulates human processes of exploration, construction, and filtering to efficiently build a reliable KG.


% Current methods often rely on natural language prompts, leading to low instance extraction accuracy and difficulty in controlling LLM output. 
% To address this, some studies propose structured prompts. 
% For example, Zhong et al.\cite{Zhong2022ProQASP} applied them to question-answering, and Li et al.\cite{li2023structured, Li2024AceCoderAE} used them for code generation. 
% However, these approaches are task-specific. 
% Inspired by prompt guidelines~\cite{Promptmanship, unstructedprompt}, we designed modular prompts, such as ``@Persona'' to specify task information.
% These modules are flexible, task-agnostic, and generalizable. 
% Structured prompts help LLMs generate accurate, format-compliant responses, improving instance extraction.