In this section, we present \methodname, a fully quantized training method for on-device LLM fine-tuning. We begin by reviewing the fundamentals of LLM PEFT, highlighting the bottlenecks of implementing existing PEFT methods on device, and then review relevant neural network quantization literature (Sec.\ref{sec: background}). Building on these insights, we propose a new LLM fine-tuning framework—\emph{Group-Shared Exponents Integer in Fully Quantized Training}—for on-device scenarios. To enable this framework, we design two key components: (1) A \emph{Group-Shared Exponents Integer data format} to replace floating-point representations (Sec.\ref{sec: gse}). 
(2) A \emph{Fully Quantized Fine-tuning Framework} that leverages our new data format (Sec.\ref{sec: FQFT}). 
Finally, we explore the performance–efficiency trade-off in \methodname~via Pareto frontier analysis (Sec.\ref{sec:Pareto}) , providing practical guidance for its use.