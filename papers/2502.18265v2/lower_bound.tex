\section{Detailed Proof of Theorem~\ref{thm:non-adaptive-lower-bound}}
\label{sec:app:lower_bound}

%\begin{theorem}\label{thm:non-adaptive-lower-bound} Every randomized non-adaptive threshold-based posted-price mechanism has competitive ratio larger than $\frac{\log n}{2}$.
%\end{theorem}

%\begin{proof} 
We consider a family of instances $\mathcal{I} = \{ I_0, I_1, ..., I_{\log n} \}$. Every instance consists of $n$ value-private cost pairs $(v,c)$, where for instance $I_i$, $v = 1$ and $c = B/2^i$, for every $i \in \{0,1,...,\log n\}$ (i.e., $I_i$ consists of $n$ value-cost pairs $(1, B/2^i)$).

We construct a probability distribution $\mathcal{D}_{\mathcal{I}}$ over the family $\mathcal{I}$ of instances such that the expected value of any deterministic non-adaptive linear-price mechanism on $\mathcal{D}_{\mathcal{I}}$ is at most $1$, while the expected value of the optimal solution on $\mathcal{D}_{\mathcal{I}}$ is $\frac{\log n}{2}+1$. Then, we apply Yao's principle, which extends the lower bound to any randomized mechanism (\cite[Chapter~8.4]{BoroYan1998} and \cite{Yao1977}). 

Specifically, for every $i = 0, 1, 2, \ldots \log(n)-1$, we let $I_{i}$ appear with probability $p_{i} = 1/2^{i+1}$ in $\mathcal{D}_{\mathcal{I}}$. We let $I_{\log n}$ appear with probability $p_{\log n} = 1/n$ in $\mathcal{D}_{\mathcal{I}}$, so that the sum of $p_i$'s is equal to $1$. The optimal solution in each $I_{i}$ is $2^i$. Therefore, the expected value of the optimal solution is 
%
\[ \Exp[\opt] = \frac{n}{n} + \sum_{i=0}^{\log(n)-1} \frac{2^i}{2^{i+1}}
=\frac{\log n}{2}+1\,.
\]

We let now fix any deterministic non-adaptive linear-price mechanism $\alg$. For simplicity and without loss of generality, we assume that $\alg$ is aware of $v$ in advance (clearly, this can only work in $\alg$'s favor). 
%
Since $\alg$ knows $v$ and does not get any information about the agents' private costs before it makes its first offer, $\alg$ can be regarded as selecting an arbitrary fixed index $i \in \{ 0, 1, \ldots, \log n\}$ and an arbitrary fixed threshold $\hat{t} \in [2^i, 2^{i+1})$. Then, $\alg$ determines its linear-price, which is the same for every agent. 

For simplicity, we let $\alg$'s fixed price be $B/2^i$, for some fixed $i \in \{ 0, 1, \ldots, \log n\}$. Then, $\alg$'s value for instance $I_j$ is $0$, if $j < i$, and $2^i$ for all $j = i, \ldots, \log n$. Therefore, the expected value of $\alg$'s solution is 
%
\[ \Exp[\alg] = \frac{2^i}{n} + 2^i \sum_{j=i}^{\log(n)-1} \frac{1}{2^{j+1}}
= \frac{2^i}{n} + 2^i \left(\frac{1}{2^i} - \frac{1}{n}\right) = 1\,.
\]
%
Then, the theorem follows from Yao's principle. \qed
%\end{proof}

%\begin{definition}[Non-Adaptive Linear-Price Mechanisms]\label{dfn:non-adaptive} A posted-price mechanism is \emph{non-adaptive threshold-based} if it decides on a fixed estimate $\hat{t}$ before its first offer to an agent and uses $\hat{t}$ in order to determine the linear price $p(f_S(i)) = 2 f_s(i) B / \hat{t}$ offered to every remaining agent $i$.
%\end{definition}

%The key idea behind the following lower bound is that a non-adaptive threshold-based posted-price mechanism has to decide on a fixed threshold $\hat{t}$ before getting any information about the agents' private costs (which for posted-price mechanisms is obtained only by interacting with the agents through their accept / reject responses to the mechanism's offers). Hence, essentially the best approach of non-adaptive threshold-based posted-price mechanisms is to learn $v_{\max}$ and then select their threshold $\hat{t}$ from $\{ 1, 2, 4, \ldots, 2^{\log n}\}$ uniformly at random (which is what the posted-price mechanism of \cite[Section~4]{Bada2012} actually does). 



%A probabilistic non-adaptive threshold based algorithm decides on a distribution over the possible thresholds before it makes its first offer to an agent. Since $ALG$ knows $v$ and does not get any information about agents' private costs 

%We let $\{1, 2,..., n\}$ as the support of the distribution since suggesting any other offer would not be meaningful. The algorithm must fix a probability distribution $p = (p_0, p_1,..., p_{\log(n)})$ where $p_i$ represents the probability of offering $2^i$ before observing any private cost $c$ and therefore without being able to gather any information about the instance it is in.\\

%\textbf{Property A.} For an algorithm to be $\frac{\log(n)}{2}$ competitive it must gather at least $\frac{2 OPT}{\log(n)}$ value in each instance in $\mathcal{I}$. It is $OPT(I_j) = 2^j$.\\

%The expected value gathered by the algorithm in an instance $I_j$ is 
%\[\mathbb{E}[ALG(p,I_j)] = \sum\limits_{k=0}^j p_k \cdot ALG(p_k, I_j) = \sum\limits_{k=0}^j 2^k p_k \]

%Demanding Property A to hold produces a linear system of equations described as $p_0 \geq 2/ \log(n)$ and $p_i \geq 2/ \log(n) - \sum_{k=0}^{i-1} p_k \frac{2}{2^k \log(n)}$ and remembering that $p$ is probability distribution it is $\sum_{k=0}^{\log(n)} p_k = 1$. This system has no valid solution and therefore there is no probability distribution such that it is $\frac{\log(n)}{2}$ competitive in this family of instances.
%\end{proof}
