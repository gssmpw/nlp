    \section{Mechanism with Predictions}
In the following we will suppose that apart from our input $(\mathcal{N},B)$ we are also given a prediction $\hat{t}$, a recommended value for the threshold parameter. We will present how to achieve a smooth transition between the $O(1)$ consistency and $O(\log\log n \log \log\log n)$ robustness, depending on the error of the given prediction. 

We will call this mechanism $ProcurementPrediction$. The main idea behind it is to split the mechanism at two phases. Each phase will consist of $\ell$ rounds constructed exactly as in the \ref{alg:Init}.
\subsection{Phase A}
During phase A we will begin by applying threshold $\hat{t}$ at the first round. If the round is successful, we will double the threshold, else we halve it. We can view this procedure as a random walk where the state space is a discretized array of threshold values. This random walk is heavily drifted towards thresholds greater than $\frac{f(OPT)}{7}$. Phase B will be exactly the same as \ref{alg:FINAL}.

We present the complete $ProcurementPrediction$ mechanism, formally written in pseudocode:

\begin{algorithm}[H]
\caption{PREDICTION-MECHANISM}\label{alg:PRED}
\begin{algorithmic}[1]
\STATE \textbf{Input}: Set of agents $\mathcal{N}$, budget $B$, at each timestep $i \in [n]$ an agent $b(i)$ in random order.
\STATE \textbf{Initialize:} Timestep $i=0$, solution $S =\emptyset$
\STATE
    \STATE $i=0$
    \FOR{$j \in [2\ell]$}
    \STATE Draw $n_j$ from $Bi(n-i,a)$.
    \STATE $i \gets i+ n_j$.
    \ENDFOR
\STATE
    \FOR{$j\in [\ell]$}
    \IF{$TestThreshold([b(i),\dots, b(i+n_j-1)],\hat{t}) > 0$ }{
        \STATE$\hat{t} \gets 2\cdot \hat{t}$
    }
    \ELSE{
        \STATE $\hat{t} \gets \hat{t} / 2$
    }
    \ENDIF
    \ENDFOR
    \STATE Construct $d$ using the agent with the highest utility observed till now, then conduct binary search like before.
\end{algorithmic}
\end{algorithm}

 To understand why our mechanism works we will investigate the overall value achieved from the following random walk:
 \begin{definition}
     $\mathcal{M}_1$ is a Markov Chain with states $\{\dots,-1,0,1,\dots\}$, where being in state $i$ means that we use threshold $2^{-i}\cdot \hat{t}$, and 
 the transition probabilities at a round $j$ are the following:
 \begin{equation}
 \begin{split}
          \Prob{S_{j+1} = i-1| S_{j} = i} &= \Prob{\text{round } j \text{ succeeds while using threshold } 2^{-i}\cdot \hat{t}}\\
     \Prob{S_{j+1} = i+1| S_{j} = i}& = \Prob{\text{round } j \text{ fails while using threshold } 2^{-i}\cdot \hat{t}}
 \end{split}
 \end{equation}
 \end{definition}
This random walk models the exact behaviour of our mechanism. To simplify the analysis of the random walk we investigate the competitive ratio of our mechanism under the following assumption:
\begin{assumption}\label{ass1}
All thresholds greater than $\frac{f(OPT)}{7}$ fail in all rounds.    
\end{assumption}
 It is evident that this way we underestimate the actual competitive ratio of our mechanism. Another problem are the time-varying and unknown transition probabilities that make a complete analysis hard. To tackle this, we study Markov Chains with "worse", but constant, success probabilities than $\mathcal{M}_1$. Proving the desired results in these simplified Markov Chains we manage to transfer them to $\mathcal{M}_1$ by properly coupling them. A complete analysis is available at the appendix.

Let $i^{*}$ be the smallest integer such that $2^{-i^{*}}\cdot \hat{t} \le \frac{f(OPT)}{7}$. To simplify even further our analysis, we take into account the utility achieved only from state $i^{*}$. 

 Our main lemmas are the following:
\begin{lemma}\label{lemSteps}
    With probability at least $0.5$ Random walk $\mathcal{M}_1$ reaches state $i^{*}$ after $\frac{|i^{*}|}{0.8}$ rounds.
\end{lemma}

The lemma above signifies the drift towards $\frac{f(OPT)}{7}$. The following lemma suggests that once our mechanism has reached $i^{*}$ it will make many visits to it again. 

\begin{lemma}\label{lemReturn}
    If random walk $\mathcal{M}_1$ is in state $i^{*}$ and there are $r$ rounds left, then with probability at least $0.5$ it will return at least $\left\lfloor r\cdot 0.49\right\rfloor$ times to it again.
\end{lemma}
We are now ready to prove our main theorem of mechanism \ref{alg:PRED}.

\begin{theorem}
    Mechanism \ref{alg:PRED} is $O(1)$ consistent and $O(\log\log n\log\log\log n)$ robust.
\end{theorem}
\begin{proof}
    We begin by considering the following cases:
    \begin{enumerate}
        \item Prediction is inaccurate, namely $\max\left\{ \log \left(\frac{\hat{t}}{f(OPT)}\right),\log\left (\frac{f(OPT)}{\hat{t}}\right)\right\} > \log\log n \cdot \log\log\log n $. In this case, we ignore phase A, and we have guaranteed $O(\log\log n \log\log\log n)$  competitive ratio by the second phase where we conduct binary search.
        \item Prediction is accurate, namely $\max\left\{ \log \left(\frac{\hat{t}}{f(OPT)}\right),\log\left (\frac{f(OPT)}{\hat{t}}\right)\right\} > \log\log n \cdot \log\log\log n $. We will showcase how the competitive ratio is improved in this case. Firstly, we should note that in this case the following holds $|i^{*}|<3\log\log n \log\log\log n$. We consider two cases again:
        \begin{enumerate}
            \item $i^* > 0$:
             In this case, the worst scenario is for all rounds in  states  less than $i^*$ to fail, as in any other case we will have accumulated greater utility. Thus, we can suppose that after exactly $i^*$ rounds we have reached  state $i^*$., and according to lemma \ref{lemReturn} it will return another $\left\lfloor (\ell - i^*)\cdot 0.49\right\rfloor$ times. Combining this with lemma \ref{lemmaJustify} we get the following bound for the utility of our mechanism:
            \begin{equation}
                \begin{split}
                    \E{}{Pred(\mathcal{N},\hat{t},B)} \ge \underbrace{0.5 \cdot (1+\left\lfloor (\ell - i^*)\cdot 0.49\right\rfloor )}_{\text{expected number of visits to } i^*}\cdot \underbrace{0.9 \cdot C_2 \cdot a \cdot \frac{f(OPT)}{14}}_{\text{expected utility from a visit to }i^*}
                \end{split}
            \end{equation}
            \item $i^* \le 0$:
            In this case we use lemma \ref{lemSteps} to argue that with probability at least $0.5$ our mechanism will reach state $i^*$ after at most $\frac{|i^{*}|}{0.8}$ rounds. Now applying lemma \ref{lemReturn}, we get that with probability at least $0.5$ it will return to $i^*$ at least $\left\lfloor (\ell - \frac{|i^{*}|}{0.8})\cdot 0.49\right\rfloor$ times. Finally, applying lemma \ref{lemmaJustify} we get the following bound:
            \begin{equation}
                \begin{split}
                    \E{}{Pred(\mathcal{N},\hat{t},B)} \ge \underbrace{0.5\cdot 0.5 \cdot \left[1+\left\lfloor \left(\ell - \frac{|i^{*}|}{0.8}\right)\cdot 0.49\right\rfloor \right]}_{\text{expected number of visits to } i^*}\cdot \underbrace{0.9 \cdot C_2 \cdot a \cdot \frac{f(OPT)}{14}}_{\text{expected utility from a visit to }i^*}
                \end{split}
            \end{equation}
        \end{enumerate}
    \end{enumerate}
\end{proof}