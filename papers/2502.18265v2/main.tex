%\documentclass{article}
\documentclass[11pt]{llncs}
\usepackage{graphicx,graphics,hyperref,color}
\usepackage{alphabeta}
\usepackage{float}
%\usepackage{bbold}
\setlength{\parindent}{0pt}
\usepackage{amsmath}
\usepackage[ruled,vlined,linesnumbered,longend]{algorithm2e}
\usepackage{algorithmic}
%\usepackage{cleveref}

\newlength\myindent
\setlength\myindent{2em}
\newcommand\bindent{%
    \begingroup
    \setlength{\itemindent}{\myindent}
    \addtolength{\algorithmicindent}{\myindent}
}
\newcommand\eindent{\endgroup}
\usepackage{eqparbox}
\renewcommand{\algorithmiccomment}[1]{\hfill\eqparbox{COMMENT}{\# #1}}



\newtheorem{notation}{Notation}
\newtheorem{assumption}{Assumption}
\newtheorem{law}{Law}
\newcommand{\set}[1]{\{#1\}}
\newcommand{\To}{\Longrightarrow}
\newcommand{\xml}{\en{XML}}

%\documentclass[10pt, runningheads,a4paper]{llncs}

\usepackage[margin=1in]{geometry}
\usepackage{thmtools}
\usepackage{preamble}
\usepackage{maths}

\newcommand{\vmax}{v_{\text{max}}}
\def\Ball{\mathrm{Ball}}
\def\ALG{\mathrm{ALG}}
\def\alg{\mathrm{ALG}}
\def\OPT{\mathrm{OPT}}
\def\opt{\mathrm{OPT}}
\def\Exp{\mathbb{E}}

\allowdisplaybreaks %to allow page break in equations


\title{A Competitive Posted-Price Mechanism for Online Budget-Feasible Auctions}
%andcharalamp@gmail.com
%fotakis@cs.ntua.gr
%patsilinak@mail.ntua.gr
%
\institute{School of ECE, National Technical University of Athens, Greece \and Université Paris-Dauphine, Université PSL, CNRS \and
 Archimedes, Athena Research Center, Greece\\\email{andcharalamp@gmail.com, fotakis@cs.ntua.gr, thanostolias@mail.ntua.gr, panagiotis.patsilinakos@dauphine.psl.eu}}
\author{Andreas Charalampopoulos\inst{1,3} \and Dimitris Fotakis\inst{1,3} \and Panagiotis Patsilinakos\inst{2} \and Thanos Tolias\inst{1,3} } 

\date{19/12/2024}

\begin{document}

\maketitle

\begin{abstract}
We consider online procurement auctions, where the agents arrive sequentially, in random order, and have private costs for their services. The buyer aims to maximize a monotone submodular value function for the subset of agents whose services are procured, subject to a budget constraint on their payments. We consider a posted-price setting where upon each agent's arrival, the buyer decides on a payment offered to them. The agent accepts or rejects the offer, depending on whether the payment exceeds their cost, without revealing any other information about their private costs whatsoever. We present a randomized online posted-price mechanism with constant competitive ratio, thus resolving the main open question of (Badanidiyuru, Kleinberg and Singer, EC 2012). Posted-price mechanisms for online procurement typically operate by learning an estimation of the optimal value, denoted as $\opt$, and using it to determine the payments offered to the agents. The main challenge is to learn $\opt$ within a constant factor from the agents' accept / reject responses to the payments offered. Our approach is based on an online test of whether our estimation is too low compared against $\opt$ and a carefully designed adaptive search that gradually refines our estimation. 
\end{abstract}

\input{intro}
\input{prelim}
\input{mechanism}
 
\section{First Period -- Learning the Maximum Value}
\label{sec:FirstPeriod}

To learn $\vmax$, we sample the first $\tau$ agents, where $\tau \sim \Bin(n,1/3)$. Conditional on event $\Event$, the agent with the maximum value $\vmax$ is among the first $\tau$ agents. In this case, we can use the highest observed value to construct the interval $[\vmax, n \cdot \vmax]$, which is guaranteed to contain $\opt$, due to the submodularity of $f$. The pseudocode for the first period is given in Mechanism~\ref{alg:Vmax}.

\begin{algorithm}[t]
  \caption{LearningMaxValue}\label{alg:Vmax}
 \begin{algorithmic}[1]
     \STATE \textbf{Input:} Current set $\Nrem$ of agents available 
     \STATE Sample $\tau \sim \Bin(|\Nrem|, 1/3)$, 
     $\mathcal{N}_{\text{period}} \leftarrow \Nrem[1 : \tau]$
    \STATE Offer price $p=0$ to the agents in $\mathcal{N}_{\text{period}}$
    \STATE Let $\vmax \leftarrow \max_{b \in \mathcal{N}_{\text{period}}}f(b)$ and $\Nrem \leftarrow \Nrem \setminus \mathcal{N}_{\text{period}}$
    \STATE \textbf{return} $\vmax, \Nrem$
 \end{algorithmic}
\end{algorithm}


\section{Second Period -- Power Tower Search}
\label{sec:SecondPeriod}

Next, we further refine our estimation of $\opt$, narrowing it down to two intervals of power tower length. To this end, we partition the interval $[\vmax,n\cdot \vmax]$ into an interval sequence  $\mathcal{T}$ as follows:
%
\begin{equation}
    \mathcal{T} = \left\{[t_1,t_2],(t_2,t_3],\dots,(t_T,t_{T+1}]\right\},
\end{equation} 
%
where $t_1 = \vmax, t_2 = 10^7\,\vmax$, $t_i = 2^{\frac{t_{i-1}}{\vmax}}\cdot t_{i-1}$ for $2<i<T+1$, and $t_{T+1}=n\cdot \vmax$, with $T=|\mathcal{T}|$. 
%
Using \hyperref[alg:TestTHRESHOLD]{TestThreshold}, we test all intervals $(t_i, t_{i+1}]$, for $i = 2, \ldots, T-1$, so that we find the correct interval to pick. We exclude $[t_1, t_2]$ and $(t_T, t_{T+1}]$, because the correct interval can be inferred without directly testing these values. To test each interval $(t_i, t_{i+1}]$, we apply \hyperref[alg:TestTHRESHOLD]{TestThreshold} with threshold $\hat{t} = t_i$ to a $(\gamma_i, a_i,t_i)$-phase, where the length parameter is $a_i = \frac{81\cdot e\cdot \vmax}{t_i}$ and the number of rounds is $\gamma_i =\frac{3}{2}\cdot\log\left(\frac{t_i}{\vmax}\right)$. The pseudocode of \hyperref[alg:PowerTower]{PowerTowerSearch} is given in Mechanism~\ref{alg:PowerTower}.

\begin{algorithm}[t]
  \caption{PowerTowerSearch}\label{alg:PowerTower}
 \begin{algorithmic}[1]
     \STATE \textbf{Input:} Current state $(S, \val, \Nrem, \Brem)$, budget $B$, interval $[\vmax, n \cdot \vmax]$.
    \STATE \textbf{Construct:} sequence $\mathcal{T}$ of interval s.t. $t_1 \gets \vmax, t_2 \gets 10^7\cdot \vmax$, $t_i \gets 2^{\frac{t_{i-1}}{\vmax}}\cdot t_{i-1}$ and $t_{T+1} \gets n\cdot \vmax$.
    \STATE \textbf{Initialization:} Length parameters $a_i = \frac{81\cdot e\cdot \vmax}{t_i}$ and phase sizes $\gamma_i =\frac{3}{2}\cdot\log\left(\frac{t_i}{\vmax}\right) $, $\text{index} \gets 1$.
    %\STATE
    \FOR{$i=2$ to $|\mathcal{T}|$}
    \STATE $(\text{hit}, S, \val, \Nrem, \Brem) \leftarrow \text{TestThreshold}((S, \val, \Nrem, \Brem), B,\gamma_i, a_i, t_i )$
    \STATE \textbf{if} {$\text{hit} = 1$} \textbf{then} $\text{index} \gets i$ \textbf{end if}
    \ENDFOR
    \STATE With probability $1/2$: $t_{\min} \gets \mathcal{T}[\text{index}-1]$ and $t_{\max} \gets \mathcal{T}[\text{index}]$.
    \STATE Otherwise $t_{\min} \gets \mathcal{T}[\text{index}]$ and $t_{\max} \gets \mathcal{T}[\text{index}+1]$.
    \STATE \textbf{return} $t_{\min}, t_{\max}, (S, \val, \Nrem, \Brem)$.
 \end{algorithmic}
\end{algorithm}

A $(a_i, \gamma_i,t_i)$-phase is considered \emph{successful}, if \hyperref[alg:TestTHRESHOLD]{TestThreshold} applied with threshold $\hat{t} = t_i$ returns success in at least $\gamma_i/2$ rounds. Each length parameter $a_i$ is chosen such that every $(a_i,t_i)$-round is `good'.
 
\begin{proposition}\label{prop:good1}
    During PowerTowerSearch, all phases consist of `good' $(a_i,t_i)$-rounds.
\end{proposition}

The phase lengths $\gamma_i$ are carefully chosen so that (i) the total number of agents examined during this period is at most a constant fraction of $n$; and (ii) we ensure that a phase with threshold much larger than $\opt$ cannot be successful. Formally:

%Part of the rationale for testing each estimate in a Phase instead of just a round is to prevent extreme overestimations of \( OPT \) from succeeding. More formally:
\begin{lemma}\label{lemma:PERIOD1}
    Let $\frac{\opt}{8}\in (t_{i-1}, t_{i}]$. Then,   for every $j \geq i+1$, the $(\gamma_j, a_j,t_j)$-phase tested with threshold $\hat{t} = t_j$ is not successful. 
\end{lemma}

\begin{proof}
    Without loss of generality, let $t_{i} = \frac{\opt}{8}$. We prove that the $(\gamma_{i+1}, a_{i+1},t_{i+1})$-phase tested with threshold $\hat{t} = t_{i+1}$ cannot be successful (if proven for $j=i+1$, this must also apply to every $j > i+1$). 
    
    If the $(\gamma_{i+1}, a_{i+1},t_{i+1})$-phase tested with threshold $\hat{t} = t_{i+1}$ was successful, the total value that we would have collected during that phase would be:
\[
            \text{Value} \ge \frac{\gamma_{i+1}}{2} \cdot C \cdot a_{i+1} \cdot t_{i+1}  
\]
    Using the definitions of $a_i$ and $\gamma_i$, we get that:
\[
         \text{Value}\ge \frac{\frac{3}{2}\cdot \log\left(\frac{t_{i+1}}{\vmax}\right)}{2} \cdot C \cdot \frac{81\cdot e \cdot \vmax}{t_{i+1}} \cdot t_{i+1} 
\]
%
    Since $t_{i+1} = 2^{t_{i}/\vmax}\cdot t_i$ and using that $C = 1/(7e)$, we obtain that:
    \begin{equation}
         \text{Value}> 8\cdot\log\left(2^{\frac{t_i}{\vmax}}\cdot \frac{t_{i}}{\vmax}\right)\cdot \vmax
    \end{equation}
    Since $2^{\frac{t_i}{\vmax}}\cdot \frac{t_{i}}{\vmax} \ge 2^{\frac{t_i}{\vmax}}$, we get 
    %
    $\text{Value} > 8 \cdot t_i =\opt$, a contradiction to the definition of $\opt$.
\end{proof}

After testing all $(\gamma_i, a_i,t_{i})$-phases corresponding to intervals $(t_i, t_{i+1}]$, each with threshold $t_i$, we select the interval corresponding to the last successful phase and the interval preceding it. I.e., if $(t_i, t_{i+1}]$ corresponds to the last successful phase, we select the intervals $(t_{i-1}, t_i]$ and $(t_i, t_{i+1}]$. In the definition of event $\Event_2$, we require that either $\frac{\opt}{8} \in (t_{i-1}, t_{i}]$ or $\frac{\opt}{8} \in (t_{i}, t_{i+1}]$, where $(t_{i-1}, t_i]$ and $(t_i, t_{i+1}]$ are the intervals selected by PowerTowerSearch. Let $i^\ast$ be such that $\frac{\opt}{8} \in (t_{i^{*}}, t_{i^{*}+1}]$. Then, for the event $\Event_2$ to occur, we require that either the $(\gamma_{i^\ast}, a_{i^\ast}, t_{i^\ast})$-phase or the $(\gamma_{i^\ast+1}, a_{i^\ast+1}, t_{i^\ast+1})$-phase is the last successful phase. 

We next show that the event $\Event_2$ is implied by the event that the $(\gamma_{i^\ast}, a_{i^\ast}, t_{i^\ast})$-phase is dense. So, let us assume that the $(\gamma_{i^\ast}, a_{i^\ast}, t_{i^\ast})$-phase is dense, which occurs with probability at least $0.9$, by Lemma~\ref{lemma:E2} (which, in turn, follows from Lemma~\ref{lemma:PhaseProbability}). Hence, with probability at least $0.9$, the $(\gamma_{i^\ast}, a_{i^\ast}, t_{i^\ast})$-phase is successful. If the $(\gamma_{i^\ast}, a_{i^\ast}, t_{i^\ast})$-phase is the last successful phase, then we select the intervals $(t_{i^\ast-1}, t_{i^\ast}]$ and $(t_{i^\ast}, t_{i\ast+1}]$ and the event $\Event_2$ occurs. Otherwise, Lemma \ref{lemma:PERIOD1} implies that the $(\gamma_{i^\ast+1}, a_{i^\ast+1}, t_{i^\ast+1})$-phase must be the last successful phase. Then, we select the intervals $(t_{i^\ast}, t_{i^\ast+1}]$ and $(t_{i^\ast+1}, t_{i\ast+2}]$ and the event $\Event_2$ occurs again. 



\section{Third Period -- Binary Search}
\label{sec:ThirdPeriod}
   % If the optimal value lies in the interval $[t_1, t_2]$, then the algorithm fails to gather sufficient value. However, due to its combination with Dynkin's algorithm, we obtain an $O(1)$ approximation ratio. In the following, we assume that the second period returned a different interval.
  
  We next show how to apply \emph{binary search} to the interval returned by Period $2$. To apply binary search to the given interval $(t_{\min},t_{\max}]$, it is essential that the feedback on each estimation is correct with high probability. To achieve this, we test each estimation $\hat{t}$ of the optimum on $(m,a,\hat{t})$-phases, where $m=\left\lceil 8\cdot \log\log\left(\frac{t_{\max}}{t_{\min}}\right)\right\rceil $ rounds and $a=\frac{1}{6\,\left\lceil\log \log\left(\frac{t_{\max}}{t_{\min}}\right)\right\rceil \cdot m}$. The value of $m$ is set so that we can lower bound the probability of the event $\Event_3$ by union bound on the number of different phases. The length parameter $a$ is set so that the total number of phases used in Period $3$ times the number $m$ of rounds in each phase times $a$ is at most $1/3$ (which implies that Period $3$ ``consumes'' about $1/3$ of the agent sequence). We next show that this choice of $a$ makes our rounds good:
  \begin{proposition}\label{prop:good2}
    $(a,t_{\min})$-rounds (and thus all rounds) during BinarySearch are good.
  \end{proposition}
  
  \begin{proof}
  We need to verify that $\frac{t_{\min}}{\vmax} \ge \frac{81\,e}{a}$. Using our choice of $a$, we obtain that: 
      \begin{equation}
          \begin{split}
      \frac{t_{\min}}{\vmax} \ge 486\cdot e \cdot \left\lceil\log\log\left(\frac{t_{\max}}{t_{\min}}\right)\right\rceil\cdot \left\lceil 8\cdot  \log\log\left(\frac{t_{\max}}{t_{\min}}\right)\right\rceil 
          \end{split}
      \end{equation}
      Using the fact that $t_{\max} = 2^{\frac{t_{\min}}{\vmax}}\cdot t_{\min}$, we get:
      \begin{equation}
          \frac{t_{\min}}{\vmax}\ge 486\cdot e\cdot \left\lceil\log\left(\frac{t_{\min}}{\vmax}\right)\right\rceil\cdot \left\lceil 8\cdot  \log\left(\frac{t_{\min}}{\vmax}\right)\right\rceil\,, 
      \end{equation}
      which is true for $\frac{t_{\min}}{\vmax}\ge  10^7$.
  \end{proof}
The number of rounds needed to conduct BinarySearch is $\ell = \frac{1}{6\cdot a}$. The pseudocode for BinarySearch is presented in Mechanism~\ref{alg:binarysearch}.

\begin{algorithm}[t]
\caption{BinarySearch}\label{alg:binarysearch}
\begin{algorithmic}[1]
\STATE \textbf{Input}: Current state $(S, \val, \Nrem, \Brem)$, budget $B$, search interval $[t_{\min},t_{\max}]$
\STATE \textbf{Initialization:} Phase size $m \gets \left \lceil 8\cdot\log\log\left(\frac{t_{\max}}{t_{\min}}\right)\right\rceil$\,, length parameter $a \gets \frac{1}{6\,\left\lceil\log\log\left(\frac{t_{\max}}{t_{\min}}\right)\right\rceil\cdot m}$, \\
%
\hspace*{2.1cm}$\text{low} \gets 0$, 
$\text{high} \gets \left\lceil \log\left(\frac{t_{\max}}{t_{\min}}\right) \right\rceil$, $\text{mid} \gets \left\lceil (\text{high} + \text{low})/2 \right\rceil$
%\STATE
    \WHILE{$\text{low} \leq \text{high}$}
    \STATE $\text{hit} \gets 0$
    \STATE $(\text{hit}, S, \val, \Nrem, \Brem) \leftarrow \text{TestThreshold}((S, \val, \Nrem, \Brem), B,m, a, 2^{\text{mid}}\cdot t_{\min})$
    \STATE \textbf{if} $\text{hit} = 1$ \textbf{then} $\text{low} \gets \text{mid}$, $\text{mid} \gets \lceil (\text{high} + \text{low})/2 \rceil$.
    \STATE \textbf{else} $\text{high} \gets \text{mid}$, $\text{mid} \gets \lfloor \text{high} + \text{low})/2 \rfloor$ \textbf{end if}
    \ENDWHILE
    \STATE \textbf{return} $(2^{\text{mid}}\cdot t_{\min}, (S, \val, \Nrem, \Brem))$.
\end{algorithmic}
\end{algorithm}
 

By Lemma~\ref{lemma:phasesucc}, if all thresholds not greater than $\frac{\opt}{4}$ are tested on dense phases, we cannot end up with a substantial underestimation of $\opt$ after conducting BinarySearch. Below we prove an even sharper bound on the possible estimates that BinarySearch may return.
\begin{lemma}\label{lemma:dist}
    Let $\hat{t}$ be the estimate \hyperref[alg:binarysearch]{BinarySearch} returns, under event $\mathcal{E}$. Then:
    \begin{equation}
        \frac{\opt}{8} \le \hat{t} \le 84\cdot e\cdot \left\lceil\log\log\left(\frac{t_{\max}}{t_{\min}}\right)\right\rceil\cdot \opt
    \end{equation}
\end{lemma}
\begin{proof}
    Suppose $\hat{t}<\frac{\opt}{8}$. This would imply that an intermediate estimate $\hat{t}' \in \left[\frac{\opt}{8},\frac{\opt}{4}\right]$ failed in a dense phase. However, this cannot happen under event $\mathcal{E}$, due to Lemma  \ref{lemma:phasesucc}.
    Now consider the case where $\hat{t}> 84 \, e\, \left\lceil\log\log\left(\frac{t_{\max}}{t_{\min}}\right)\right\rceil\cdot \opt$. This would mean that a dense phase succeeded using an overestimated value  $\hat{t}' >84\, e\, \left\lceil\log\log\left(\frac{t_{\max}}{t_{\min}}\right)\right\rceil\cdot \opt$. Specifically, in that phase, the accumulated value would be:
    \begin{equation}
        \begin{split}
            \text{Value}\ge \frac{m}{2}\cdot C \cdot a \cdot \hat{t}' 
        \end{split}
    \end{equation}
    By using the assumption of the overestimation $\hat{t}'$, along with the definitions of $C$ and $a$ we get:
    \begin{equation}
        \begin{split}
            \text{Value}> \frac{m}{2}\cdot \frac{1}{7e} \cdot \frac{1}{6\left\lceil\log \log\left(\frac{t_{\max}}{t_{\min}}\right)\right\rceil \cdot m} \cdot 84\, e\, \left\lceil\log\log\left(\frac{t_{\max}}{t_{\min}}\right)\right\rceil\cdot \opt=\opt
        \end{split}
    \end{equation}    
    which clearly contradicts the definition of $\opt$.

   Thus, we conclude that $\hat{t} \in \left[\frac{\opt}{8},\ \ 84 \, e\,\log\log\left(\frac{t_{\max}}{t_{\min}}\right)\cdot \opt\right]$
\end{proof}

\section{Fourth Period -- Exploitation}\label{sec:FourthPeriod}


Lemma \ref{lemma:dist} indicates that, after running BinarySearch, our estimation is at most $84\cdot e \cdot \left\lceil\log\log\left(\frac{t_{\max}}{t_{\min}}\right)\right\rceil$ times $\opt$. In the final stage of our mechanism, we aim to converge to a threshold $\hat{t}$ close to $\opt$ and apply $\hat{t}$ to a constant fraction of agents, thereby collecting a total value of $\Omega(\opt)$. 

\begin{algorithm}[t]
\caption{Exploitation}\label{alg:exploitation}
\begin{algorithmic}[1]
\STATE \textbf{Input}: Current state $(S, \val, \Nrem, \Brem)$, budget $B$, initial threshold $\tinit$, search interval $[t_{\min}, t_{\max}]$
%
\STATE \textbf{Initialization:} $\hat{t} \gets \tinit$, Phase size $m \gets \left \lceil 8\cdot\log\log\left(\frac{t_{\max}}{t_{\min}}\right)\right\rceil$\,, length parameter $a \gets \frac{1}{6\,\left\lceil\log\log\left(\frac{t_{\max}}{t_{\min}}\right)\right\rceil\cdot m}$
%\STATE
    \FOR{$i = 1$ to $\frac{1}{6 \cdot m \cdot a} = \left\lceil\log\log\left(\frac{t_{\max}}{t_{\min}}\right)\right\rceil$}
    \STATE $(\text{hit}, S, \val, \Nrem, \Brem) \leftarrow \text{TestThreshold}((S, \val, \Nrem, \Brem), B, a, \hat{t})$
    \STATE \textbf{if} $\text{hit} =1$ \textbf{then} $\hat{t} \gets 2 \cdot \hat{t}$ \textbf{else} $\hat{t} \gets \hat{t}/2$ \textbf{end if}
    \ENDFOR
    \STATE \textbf{return} $(S, \val)$.
\end{algorithmic}
\end{algorithm}

\hyperref[alg:exploitation]{Exploitation}, whose pseudocode is presented in Mechanism~\ref{alg:exploitation}, is applied across  a total number of $\ell/m$ $(m,a,\hat{t})$-phases, thus using $\ell = 1/(6a)$ rounds in total. Under the event $\Event$, it holds that $\tmin \le \frac{\opt}{8}$. Thus, we can leverage Proposition~\ref{prop:good2} to claim the following:
\begin{proposition}\label{prop:good3}
    Conditioning on the event $\Event$, all rounds during Exploitation are good. 
\end{proposition}
The mechanism operates by doubling the estimation after every successful phase and halving it after every failed phase. Under the event $\Event$, the threshold $\hat{t}$ never falls below $\opt / 8$, by Lemma \ref{lemma:phasesucc}. Combining this with Lemma~\ref{lemma:dist}, we conclude that we can have no more than \[ \frac{\frac{\ell}{m} + \log\log\log\left(\frac{t_{\max}}{t_{\min}} \right)+ \log(84e)+2}{2} \] failed phases; exceeding this would cause our estimation to drop below \( \frac{\opt}{8} \). Consequently, we are guaranteed at least \( \frac{\frac{\ell}{m} -\log\log\log\left(\frac{t_{\max}}{t_{\min}} \right)- \log(84e)-2}{2}\) successful phases, which ensures a constant competitive ratio. Formally,

\begin{lemma} \label{lemma:compratio}
    Conditional on the event $\Event$, Exploitation collects a total value of at least $\frac{\opt}{4032e}$.
\end{lemma}
\begin{proof}
    As we have argued already, we are guaranteed to have at least $\frac{\frac{\ell}{m} -\log\log\log\left(\frac{t_{\max}}{t_{\min}} \right)- \log(84e)-2}{2}$ successful Phases, which in turn means that the value gathered is greater than:
\[
        \text{Value}\ge \underbrace{\frac{\frac{\ell}{m} -\log\log\log\left(\frac{t_{\max}}{t_{\min}} \right)- \log(84e)-2}{2}}_{\text{successful Phases}} \cdot \underbrace{\frac{m}{2} \cdot C \cdot a\cdot \frac{\opt}{8}}_{\text{Value of each Phase}} 
\]
    Now using the definitions of $a$, $\ell$, $C$, and $t_{\max}$, we get that
\[
        \text{Value} \ge\left(\frac{1}{6} - \frac{\log\log\log\left(2^{\frac{t_{\min}}{\vmax}}\right) + \log(84e)+2}{6\cdot\log\log\left(2^{\frac{t_{\min}}{\vmax}}\right)}\right)\cdot \frac{\opt}{224e}
\]
    Finally, by the monotonocity of $g(x) = \frac{-\log\log\log(x) - \log(84e)-2}{6\cdot\log\log(x)}$, along with the fact that $\frac{t_{\min}}{\vmax} \ge  10^7,$ we conclude that $\text{Value}  \ge \frac{1}{4032e}\cdot \opt$.
\end{proof}


\section{Putting Everything Together and Removing the Large Market Assumption}\label{sec:MainTheorem}

%To extend our result for dense phases, we must account for the dependencies between the outcomes of rounds. Conditional on a previous round having failed, subsequent rounds are more likely to succeed. This dependency arises from the constraint that the utility of all rounds must sum to the total utility of all agents. 
%We present our \hyperref[alg:LMMECH]{LM-Mechanism} written in Pseudocode:

%\begin{algorithm}[H]
%\caption{LM-Mechanism}\label{alg:LMMECH}
%\begin{algorithmic}[1]
%\STATE \textbf{Input}: Set of agents $\mathcal{N}$, budget $B$%, at each timestep $i \in [n]$ an agent $b(i)$ in secretary order.
%\STATE \textbf{Parameters}: $m,a,OPT_{min},OPT_{max},$ rounds $\{n_j\}$
%\STATE \textbf{Initialize:} Timestep $i=0$, solution $S =\emptyset$
%\STATE $\vmax, i \gets \text{Period 1}(\mathcal{N}).$
%\STATE $t_{min},t_{max} , i \gets \text{TestIntervals}(\mathcal{N}[i:n],B,[\vmax,n\cdot\vmax])$.
%\STATE Set $a,m$ to the proper values.
%\STATE $t, i \gets \text{BinarySearch}(\mathcal{N}[i:n],B, [t_{min},t_{max}],a,m)$.
%\STATE Exploitation$(\mathcal{N}[i:n],B,t,a,m)$.
%\end{algorithmic}
%\end{algorithm}

%We are now ready to 

Below we present the proof of the competitiveness of \hyperref[alg:LMMECH]{LM-Mechanism}.

\begin{theorem}\label{theorem:lm}
    Assuming that $\opt > 10^{7}\cdot \vmax$, \hyperref[alg:LMMECH]{LM-Mechanism} is $O(1)$-competitive.
\end{theorem}

\begin{proof}
In the four periods of \hyperref[alg:LMMECH]{LM-Mechanism}, we assume that the event $\Event$ occurs. Lemma~\ref{lemma:GoodEvent} proves that $\Event$ happens with probability at least $1/20$. Conditional on the event $\Event$, the \hyperref[alg:LMMECH]{LM-Mechanism} achieves a competitive ratio of $4032e$ due to Lemma~\ref{lemma:compratio}. Overall, the expected total value of \hyperref[alg:LMMECH]{LM-Mechanism} is  at least $\frac{1}{20} \cdot \frac{1}{4032e}\cdot \opt$.
\end{proof}

Finally, we need to remove the Large Market Assumption that $\opt > 10^{7}\cdot \vmax$. To this end, we present the mechanism PostedPrices, whose pseudocode can be found in Mechanism~\ref{alg:PPMECH}.
\hyperref[alg:PPMECH]{PostedPrices} invokes three different mechanisms, with a constant probability each, which deal with instances of different market size (i.e., magnitude of $\frac{\opt}{\vmax}$). We are now ready to prove our main result:


\begin{algorithm}[t]
\caption{PostedPrices}\label{alg:PPMECH}
\begin{algorithmic}[1]
\STATE \textbf{Input}: Set of agents $\mathcal{N}$, budget $B$%, at each timestep $i \in [n]$ an agent $b(i)$ in secretary order.
%\STATE \textbf{Parameters}: $m,a,OPT_{min},OPT_{max},$ rounds $\{n_j\}$
\STATE With probability $0.1$, execute Dynkin's algorithm on $\N$.
\STATE With probability $0.1$, execute \hyperref[alg:MMMECH]{MediumMarket} on the set of agents $\N$ with budget $B$.
\STATE With probability $0.8$, execute \hyperref[alg:LMMECH]{LM-Mechanism} on the set of agents $\N$ with budget $B$.
\end{algorithmic}
\end{algorithm} 

\begin{algorithm}[t]
\caption{MediumMarket}\label{alg:MMMECH}
\begin{algorithmic}[1]
\STATE \textbf{Input}: Set of agents $\mathcal{N}$, budget $B$%, at each timestep $i \in [n]$ an agent $b(i)$ in secretary order.
%\STATE \textbf{Parameters}: $m,a,OPT_{min},OPT_{max},$ rounds $\{n_j\}$
\STATE Learn $\vmax$ using \hyperref[alg:Vmax]{LearningMaxValue}

\STATE Pick uniformly at random a threshold $t \in \left\{2^6 \cdot \vmax,2^8 \cdot \vmax,\dots,2^{23} \cdot \vmax\right\}$

\STATE Apply linear pricing with threshold $t$ and budget $B$ to the rest of the agent sequence.


\end{algorithmic}
\end{algorithm} 



\begin{theorem}
    \hyperref[alg:PPMECH]{PostedPrices} is a universally truthful $O(1)$-competitive posted-price mechanism for online budget-feasible procurement auctions with secretary agent arrivals and  monotone submodular buyer's valuations.
\end{theorem}
\begin{proof}
    Universal truthfulness follows from the fact that 
    \hyperref[alg:PPMECH]{PostedPrices} is a probability distribution over three universally truthful (and posted-price) mechanisms. 
    
    Regarding the competitive ratio of \hyperref[alg:PPMECH]{PostedPrices}, we consider the following cases:
    \begin{enumerate}
        \item $\opt<1024\cdot \vmax$: Then Dynkin's algorithm is executed with probability $0.1$ and collects an expected value of at least $\frac{1}{10}\cdot\frac{\opt}{1024 \cdot e}$\,.
        \item $1024\cdot\vmax \le\opt<10^7\cdot \vmax$: Then \hyperref[alg:LMMECH]{MedianMarket} is executed with probability $0.1$. With probability at least $0.9$, the optimal value for the set of agents not used for the calculation of $\vmax$ by \hyperref[alg:Vmax]{LearningMaxValue}, in step~2, is at least $\opt / 4$. With probability at least $1/18$, the threshold $t$ selected is such that $\frac{\opt}{16}\le t \le \frac{\opt}{8}$\,. Thus, by Lemma~\ref{lem:threshold}, the chosen threshold $t$ results in at least $(\frac{1}{4}-\frac{\vmax}{\opt})\cdot \frac{\opt}{4}>\frac{\opt}{18}$ value. Overall the expected total value is at least:
        \begin{equation}
            \frac{1}{10}\cdot \frac{9}{10}\cdot \frac{1}{18} \cdot\frac{\opt}{18} = \frac{\opt}{3600}
        \end{equation}
        \item $10^7\cdot \vmax\le\opt$: Then, \hyperref[alg:LMMECH]{LM-Mechanism} is executed with probability $0.8$, which by Theorem \ref{theorem:lm} results in an expected total value of at least
        a $0.8\cdot\frac{1}{20}\cdot \frac{\opt}{4032e}$\,.
    \end{enumerate}
%
 Putting the three cases together, we conclude that the competitive ratio of \hyperref[alg:PPMECH]{PostedPrices} is $O(1)$. We note that at many places, we prioritized simplicity over trying to optimize the resulting constant.
\end{proof}


\section{Conclusions}

In this work, we have introduced a randomized, constant-competitive posted-price mechanism for online procurement auctions, thus resolving the main open question of Badanidiyuru, Kleinberg and Singer \cite{Bada2012}. Our findings demonstrate that in online procurement auctions, sequential posted-price mechanisms can be as powerful, in terms of the asymptotics of their competitive ratio, as seal-bid mechanisms, whose performance has been extensively studied. We note that despite our mechanism is elaborate to design and analyze, its interface with the agents is simple and transparent. 

In addition to improving the constants in our analysis, an interesting direction for further research is whether our refined adaptive search can be generalized and applied to other posted-price mechanisms, such as combinatorial auctions with submodular bidders \cite{Assadi019,AssadiS20,DuttingKL24}, towards  improved competitive ratios. 

\section{Acknowledgement}
This work has been partially supported by project MIS 5154714 of the National Recovery and Resilience Plan Greece 2.0 funded by the European Union under the NextGenerationEU Program.

\bibliographystyle{IEEEtran} % We choose the "plain" reference style
\bibliography{references} % Entries are in the refs.bib file

\appendix

% Appendix
\clearpage\appendix
\section*{\Large Appendix}

\input{lower_bound}

\section{Proofs Missing from Section~\ref{sec:rounds}} %Rounds and Phases}
\subsection{Partitioning into Rounds}\label{A1}
Suppose we wish to construct $\kappa$ rounds with length parameters $\{a_1,a_2,\dots,a_{\kappa}\}$. We will analytically compute the participation probability of the $\kappa$-th round.

\begin{proof}[Proof of Lemma \ref{lemma:RoundPro}:]
    Consider an agent $b$ and let $R_\kappa$ denote the set of agents in the $\kappa$-th round, then:
    \begin{equation}
        \Prob{b \in R_\kappa} = \sum_{x_{1} = 0}^{n_1}\Prob{x_{1}}\sum_{x_{2} = 0}^{n_{2}}\dots\sum_{x_{\kappa-1} = 0}^{n_{\kappa-1}}\Prob{x_{\kappa-1}}\sum_{x_{\kappa} = 1}^{n_{\kappa}}\Prob{x_{\kappa}}\cdot \Prob{b\in R_\kappa| x_1,\dots x_{\kappa}}.
    \end{equation}
    Where $n_1=n$ and $n_i = n-\sum_{j=1}^{i-1}x_i$. By using the fact that the order of the agents follows a uniform distribution  we get that:
    \begin{equation}
        \Prob{b\in R_\kappa} =\sum_{x_{1} = 0}^{n_1}\Prob{x_{1}}\sum_{x_{2} = 0}^{n_{2}}\dots\sum_{x_{\kappa-1} = 0}^{n_{\kappa-1}}\Prob{x_{\kappa-1}}\sum_{x_{\kappa} = 1}^{n_{\kappa}}\Prob{x_{\kappa}}\cdot \frac{x_{\kappa}}{n}.
    \end{equation}
     By definition, $\sum_{x_{\kappa} = 1}^{n_{\kappa}}\Prob{x_{\kappa}}\cdot x_{\kappa} = \E{}{\kappa\text{-th round length}} = a_{\kappa}\cdot n_{\kappa}$, thus:
    \begin{equation}
        \Prob{b\in R_\kappa} =\sum_{x_{1} = 0}^{n_1}\Prob{x_{1}}\sum_{x_{2} = 0}^{n_{2}}\dots\sum_{x_{\kappa-1} = 0}^{n_{\kappa-1}}\Prob{x_{\kappa-1}}\frac{n_{\kappa}}{n}\cdot a_{\kappa}.
    \end{equation}
     Observing that $n_{\kappa} = n_{\kappa-1} - x_{\kappa-1}$ and applying the same argument as before repeatedly, we finally get:
        \begin{equation}
        \Prob{b\in R_\kappa} =(1-a_1)\cdot(1-a_2)\cdots (1-a_{\kappa-1})\cdot a_{\kappa}.
    \end{equation}

    Now it remains to prove the independency among agents.

    Suppose 2 agents $b_1,b_2$, then:
    \begin{equation}
        \Prob{\{b_1,b_2\}\in R_\kappa} =\sum_{x_{1} = 0}^{n_1-2}\Prob{x_{1}}\sum_{x_{2} = 0}^{n_{2}-2}\dots\sum_{x_{\kappa-1} = 0}^{n_{\kappa-1}-2}\Prob{x_{\kappa-1}}\sum_{x_{\kappa} = 2}^{n_{\kappa}}\Prob{x_{\kappa}}\cdot \Prob{\{b_1,b_2\}\in R_\kappa|x_1,\dots,x_{\kappa}}.
    \end{equation}
    Since agent order follows a uniform distribution and the round lengths are drawn from a binomial distribution, we get:
    \begin{equation}
        \Prob{\{b_1,b_2\}\in R_\kappa} =\sum_{x_{1} = 0}^{n_1-2}\Prob{x_{1}}\sum_{x_{2} = 0}^{n_{2}-2}\dots\sum_{x_{\kappa-1} = 0}^{n_{\kappa-1}-2}\Prob{x_{\kappa-1}}\sum_{x_{\kappa} = 2}^{n_{\kappa}}\begin{pmatrix}
            n_\kappa\\
            x_\kappa
        \end{pmatrix}\cdot a_\kappa ^{x_\kappa}\cdot (1-a_\kappa)^{n_\kappa - x_\kappa}\cdot  \frac{\begin{pmatrix}
            x_\kappa\\
            2
        \end{pmatrix}}{\begin{pmatrix}
            n\\
            2
        \end{pmatrix}}.
    \end{equation}
    Using the identity: 
    \begin{equation}
        \begin{pmatrix}
            n_\kappa\\
            x_\kappa
        \end{pmatrix} \cdot \begin{pmatrix}
            x_\kappa\\
            2
        \end{pmatrix} = \begin{pmatrix}
            n_\kappa\\
            2
        \end{pmatrix}\cdot \begin{pmatrix}
            n_\kappa-2\\
            x_\kappa-2
        \end{pmatrix},
    \end{equation} we obtain:
    \begin{equation}
        \Prob{\{b_1,b_2\}\in R_\kappa} =\sum_{x_{1} = 0}^{n_1-2}\Prob{x_{1}}\sum_{x_{2} = 0}^{n_{2}-2}\dots\sum_{x_{1} = 0}^{n_{\kappa-1}-2}\Prob{x_{\kappa-1}}\cdot \frac{\begin{pmatrix}
            n_\kappa\\
            2
        \end{pmatrix}}{\begin{pmatrix}
            n\\
            2
        \end{pmatrix}}\sum_{x_{\kappa} = 2}^{n_{\kappa}}\begin{pmatrix}
            n_\kappa-2\\
            x_\kappa-2
        \end{pmatrix}\cdot a_\kappa ^{x_\kappa}\cdot (1-a_\kappa)^{n_\kappa - x_\kappa}.
    \end{equation}
    Noting that:
    \begin{equation}
        \sum_{x_{\kappa} = 2}^{n_{\kappa}}\begin{pmatrix}
            n_\kappa-2\\
            x_\kappa-2
        \end{pmatrix}\cdot a_\kappa ^{x_\kappa}\cdot (1-a_\kappa)^{n_\kappa - x_\kappa} = a_\kappa ^2 \cdot \sum_{x_{\kappa} = 0}^{n_{\kappa}-2}\begin{pmatrix}
            n_\kappa-2\\
            x_\kappa
        \end{pmatrix}\cdot a_\kappa ^{x_\kappa}\cdot (1-a_\kappa)^{n_\kappa-2 - x_\kappa} =a_\kappa ^2.
    \end{equation}
    and thus:
    \begin{equation}
        \Prob{\{b_1,b_2\}\in R_\kappa} =\sum_{x_{1} = 0}^{n_1-2}\Prob{x_{1}}\sum_{x_{2} = 0}^{n_{2}-2}\dots\sum_{x_{\kappa-1} = 0}^{n_{\kappa-1}-2}\Prob{x_{\kappa-1}}\cdot \frac{\begin{pmatrix}
            n_\kappa\\
            2
        \end{pmatrix}}{\begin{pmatrix}
            n\\
            2
        \end{pmatrix}}\cdot a_{\kappa}^2.
    \end{equation}
    Now we focus on the last sum,
    \begin{equation}\label{eq:2}
        \sum_{x_{\kappa-1} = 0}^{n_{\kappa-1}-2}\Prob{x_{\kappa-1}}\cdot \frac{\begin{pmatrix}
            n_{\kappa}\\
            2
        \end{pmatrix}}{\begin{pmatrix}
            n\\
            2
        \end{pmatrix}}\cdot a_{\kappa}^2 =a_{\kappa}^2\sum_{x_{\kappa-1} = 0}^{n_{\kappa-1}-2} \begin{pmatrix}
            n_{\kappa-1}\\
            x_\kappa
        \end{pmatrix}\cdot a_{\kappa-1} ^{x_{\kappa-1}}\cdot (1-a_{\kappa-1})^{n_{\kappa-1} - x_{\kappa-1}}\cdot \frac{\begin{pmatrix}
            n_\kappa\\
            2
        \end{pmatrix}}{\begin{pmatrix}
            n\\
            2
        \end{pmatrix}}.
    \end{equation}
    We notice that:
    \begin{equation}\label{eq:1}
        \begin{pmatrix}
            n_{\kappa-1}\\
            x_\kappa
        \end{pmatrix}\cdot \frac{\begin{pmatrix}
            n_\kappa\\
            2
        \end{pmatrix}}{\begin{pmatrix}
            n\\
            2
        \end{pmatrix}} = \begin{pmatrix}
            n_{\kappa-1}-2\\
            x_{\kappa-1}
        \end{pmatrix}\cdot \frac{\begin{pmatrix}
            n_{\kappa-1}\\
            2
        \end{pmatrix}}{\begin{pmatrix}
            n\\
            2
        \end{pmatrix}}, 
    \end{equation}
    and by applying  (\ref{eq:1}) to  (\ref{eq:2}) we get:
    \begin{equation}\label{eq:4}
        \sum_{x_{\kappa-1} = 0}^{n_{\kappa-1}-2}\Prob{x_{\kappa-1}}\cdot \frac{\begin{pmatrix}
            n_\kappa\\
            2
        \end{pmatrix}}{\begin{pmatrix}
            n\\
            2
        \end{pmatrix}}\cdot a_{\kappa}^2 =a_{\kappa}^2\frac{\begin{pmatrix}
            n_{\kappa-1}\\
            2
        \end{pmatrix}}{\begin{pmatrix}
            n\\
            2
        \end{pmatrix}}\cdot \sum_{x_{\kappa-1} = 0}^{n_{\kappa-1}-2}\begin{pmatrix}
            n_{\kappa-1}-2\\
            x_{\kappa-1}
        \end{pmatrix}\cdot a_{\kappa-1} ^{x_{\kappa-1}}\cdot (1-a_{\kappa-1})^{n_{\kappa-1} - x_\kappa}.
    \end{equation}
    Next we notice that:
    \begin{equation}\label{eq:3}
        \sum_{x_{\kappa-1} = 0}^{n_{\kappa-1}-2}\begin{pmatrix}
            n_{\kappa-1}-2\\
            x_{\kappa-1}
        \end{pmatrix}\cdot a_{\kappa-1} ^{x_{\kappa-1}}\cdot (1-a_{\kappa-1})^{n_{\kappa-1} - x_\kappa} = (1-a_{\kappa -1})^{2},
    \end{equation} and combining (\ref{eq:4}), (\ref{eq:3}) we get that:
    \begin{equation}
        \sum_{x_{\kappa-1} = 0}^{n_{\kappa-1}-2}\Prob{x_{\kappa-1}}\cdot \frac{\begin{pmatrix}
            n_\kappa\\
            2
        \end{pmatrix}}{\begin{pmatrix}
            n\\
            2
        \end{pmatrix}}\cdot a_{\kappa}^2 =\frac{\begin{pmatrix}
            n_{\kappa-1}\\
            2
        \end{pmatrix}}{\begin{pmatrix}
            n\\
            2
        \end{pmatrix}}\cdot (1-a_{\kappa-1})^2\cdot a_{\kappa}^2
    \end{equation}
    It is now evident that by following the same procedure for the rest of the sums we get that:
    \begin{equation}
        \Prob{\{b_1,b_2\}\in R_\kappa} = a_{\kappa}^2\cdot\prod_{i=1}^{\kappa-1}(1-a_i)^2 = \Prob{b_1\in R_\kappa}\cdot\Prob{b_2\in R_\kappa} 
    \end{equation}
    This confirms that agent selections are independent.
\end{proof}

Lemma \ref{lemma:RoundPro} also proves that rounds are indeed equivalent with a random set of the whole input where each agent is included with the same probability.\\

An important property of the lengths drawn in Period 2 that will turn our very useful in the rest of our analysis is the following:
\begin{lemma}\label{lemma:SeqBound}
    For every $i\in \{2,\dots, T\}$ (where $T$ is the number of intervals in the partitioning of $[\vmax, n\cdot\vmax]$ used in Section~\ref{sec:SecondPeriod}), it holds that:
    \[a_i\cdot \gamma_i \le \frac{1}{i^{10}}\]
\end{lemma}
\begin{proof}
    We first notice the following:
    \begin{equation}
        \begin{split}
            a_i \cdot \gamma_i = 81e\cdot \frac{\vmax}{t_i}\cdot \frac{3}{2}\cdot\log\left(\frac{t_i}{\vmax}\right)
        \end{split}
    \end{equation}
    Applying the fact that $\log\left(\frac{t_i}{\vmax}\right) < \frac{t_{i-1}}{\vmax}$, we get:
    \begin{equation}
         a_i \cdot \gamma_i < 122e\cdot \frac{t_{i-1}}{t_i}
    \end{equation}
    Now consider the following sequences of real numbers:
    \begin{equation}
        \begin{split}
        h_{1,i} &= 122e\cdot \frac{t_{i-1}}{t_i}\\
        h_{2,i} &= \frac{1}{i^{10}}
        \end{split}
    \end{equation}
    we have that:
    \begin{equation}
      h_{1,2} = \frac{122e}{10^7} < \frac{1}{1024} = h_{2,2}  
    \end{equation}
    Taking into account that $h_{1,i} = 122e\cdot \frac{t_{i-1}}{t_i} = 122e\cdot 2^{-\frac{t_{i-1}}{\vmax}}$ it becomes evident that $h_1$ drops to $0$ faster than $h_2$ and thus the desired inequality is proved.
\end{proof}

\subsection{The Proof of Lemma~\ref{lemma:PART}}
\label{sec:PART}

We are now ready to prove Lemma~\ref{lemma:PART}
\begin{proof}[Proof of Lemma \ref{lemma:PART}:]\label{proof:PART}
    First let $R$ be the set of all the rounds that \hyperref[alg:LMMECH]{LM-Mechanism} uses.
    Using lemma \ref{lemma:RoundPro} we get the following trivial bound for the participation probability $q_j$ of the $j-$th round:
    \begin{equation}
        q_j \ge a_j\cdot \prod_{i\in R}(1-a_i) 
    \end{equation}
    All that remains is to bound $\prod_{i\in R}(1-a_i)$.
    We break this product into 3 parts:
    \begin{enumerate}
        \item The first term of the product is $\frac{2}{3}$ and it corresponds to $\tau$.
        \item Next comes the following product of terms from the tests of the second period:
        \begin{equation}
        \begin{split}
        \prod_{i=2}^{T}(1-a_i)^{\gamma_i} \ge \prod_{i=2}^{T} (1-a_i\cdot \gamma_i), 
        \end{split}
        \end{equation}
        where the last inequality comes from taking the first order Taylor approximation of the convex function $g(x) = (1-x)^{\log(\frac{c}{x})}$.
        Using Lemma \ref{lemma:SeqBound}, we get:
        \begin{equation}
           \prod_{i=2}^{T}(1-a_i)^{\gamma_i} \ge \prod_{i=2}^{T} \left(1-\frac{1}{i^{10}}\right) \ge \frac{9}{10}.
        \end{equation} 
        \item Lastly, we have the terms from the BinarySearch and Exploitation:
        \begin{equation}
            \prod_{i=1}^{2\cdot\ell} (1-a) = (1-a)^{2\cdot\ell}\ge \frac{1}{e}.
        \end{equation}
    \end{enumerate}
    Combining all of the above together:
    \begin{equation}
        q_j \ge a_j\cdot \prod_{i\in R}(1-a_i) \ge \frac{6}{10e}\cdot a_j
    \end{equation}
\end{proof}
Before we delve deeper into the properties of our rounds we first need to establish a basic property of Threshold-Based mechanisms.

\subsection{The Proof of Lemma \ref{lemma:roundProb}}\label{proof4.5}

\begin{lemma}[\cite{Bada2012}]\label{lem:threshold}
Let $k = \frac{\opt}{v_{\max}}$. For any $ \hat{t} = h \cdot \opt$, such that $h\in (0,1)$, the following holds:
    \begin{equation}
            \text{PostedPrices}(\hat{t},\mathcal{N},B) \ge \min\left\{(1-h)\cdot \opt,\ \  \left(h-\frac{1}{k}\right)\cdot \opt\right\}\,,
        \end{equation} where $\text{PostedPrices}(\hat{t},\mathcal{N},B)$ denotes the expected value gathered by applying linear pricing with threshold $\hat{t}$ to the set $\N$ of agents with budget $B$.
\end{lemma}
\begin{proof}
    Suppose that we use \(\hat{t}=h \cdot \opt\) for the entire input. Let \( S \) be the allocation obtained using \(\hat{t}\).
    We consider the following cases:
    \begin{enumerate}
        \item There is an agent $b$ such that $b \in S^{*}\setminus S$ cause of insufficient Budget. In this case:
        \begin{equation}
            \begin{split}
                &\sum_{b_{j}\in S}p_{j} = \sum_{b_{j}\in S} \frac{B}{\hat{t}}(f_{S_{j}}(b_{j})) = \frac{B\cdot f(S)}{\hat{t}} = B\cdot \frac{f(S)}{\opt \cdot h} \text{ and } \\
            &c(b) \le \frac{B}{\hat{t}} \cdot f(b) \le B\cdot \frac{1}{\opt\cdot h} \cdot \frac{\opt}{k} = B\cdot \frac{1}{h\cdot k}
            \end{split}
        \end{equation}
        and thus
        \begin{equation}\begin{split}
            &B < c(b) + \sum_{b_{j}\in S}p_{j} \le B\cdot \frac{f(S)}{\opt \cdot h} + B\cdot \frac{1}{h\cdot k} \Longrightarrow \\
            &\opt\cdot \left(h-\frac{1}{k}\right) < f(S)
        \end{split}
        \end{equation}
        \item Otherwise: $c(b)> \frac{B}{\hat{t}}\cdot f_{S}(b)$ for every $b\in S^{*}\setminus S$ and thus
        \begin{equation}
            \sum_{b\in S^{*}\setminus S} f_S(b) = \sum_{b\in S^{*}\setminus S} \frac{f_{S}(b)}{c(b)} \cdot c(b) \le \sum_{b\in S^{*}\setminus S}\frac{\hat{t}}{B}\cdot c(b)\le \hat{t}  
        \end{equation}
        and it follows that \begin{equation}
        \begin{split}
                        &\opt-f(S) \le f(S^{*}\cup S) -f(S) \le \sum_{b\in S^{*}\setminus S} f_S(b)\le \hat{t} \Longrightarrow \\
            &f(S) \ge (1-h)\cdot \opt
        \end{split}
        \end{equation}
    \end{enumerate}
    
    Finally, we conclude that $f(S)\ge \min\{(1-h),(h-\frac{1}{k})\}\cdot \opt$. 
\end{proof}

We notice that the last bound is maximized for $\hat{h} = \frac{k+1}{2k}$ and thus we consider it to be exactly that for the rest of our analysis.

Let $\hat{t}=\hat{h}\cdot \opt = \frac{k+1}{2k}\cdot \opt$ and $S$ be the allocation we get by applying the threshold $\hat{t}$ to the whole input, for some permutation of the agents. Denote $\{s_i\}_{i=1}^{|S|}$ the elements of $S$ in order of appearance and let $S_i = \bigcup_{j=1}^{i}\{s_j\}$. Now, letting $w_i = f_{S_{i-1}}(s_i)$, we can bound the cost of all subsets $X\subseteq S$ the following way:
 
\begin{lemma}\label{lem4.6}
     For every subset $X\subseteq S$ it is true that:
   \begin{equation}
       \begin{split}
           c(X)\le \frac{\sum_{i: s_i \in X}w_i}{\hat{h}\cdot \opt}\cdot B
       \end{split}
   \end{equation}
\end{lemma}
\begin{proof}
    The cost of each agent in $S$ is at most $\frac{f_{S_i}(s_i)}{\hat{t}}\cdot B = \frac{w_i}{\hat{t}}\cdot B.$ Consequently, for each subset $X$ of $S$ we get: \begin{equation}
        \begin{split}
            c(X) = \sum_{j:b_j \in X}c(b_j) 
            \le \sum_{i:s_i \in X}\frac{w_i}{\hat{t}}\cdot B . 
        \end{split}
    \end{equation}
\end{proof}
The following lemma showcases a way to lower bound the value of subsets $X \subseteq S$.
\begin{lemma}\label{lem4.7}
    Let $I$ be the set of indices of elements $s_i\in S$ sampled in a round. Then, the following holds:
    \begin{equation}
        \begin{split}
            f\lp(\bigcup_{j\in I}\{s_j\}\rp) \ge \sum_{j\in I} w_j
        \end{split}
    \end{equation}
\end{lemma}
\begin{proof}
   Let $J = \bigcup_{j\in I}\{s_j\}$. The value of the set $J$ is the same regardless of the order of appearance of elements $s_j$. Thus we can suppose that they appear in the same order as in $S$ and thus:
   \begin{equation}
       \begin{split}
           f(J) = \sum_{j\in I} f_{S_{j-1}\cap J}(s_j) \ge \sum_{j\in I} f_{S_{j-1}}(s_j) = \sum_{j\in I} w_j  
       \end{split}
   \end{equation}
\end{proof}

Combining the lemmas \ref{lem4.6} and \ref{lem4.7} we get the following bound for the cost of all subsets $X\subseteq S$.

\begin{corollary}\label{cor4.2}
    For every $X\subseteq S$ it holds that:
    \begin{equation}
        \begin{split}
            c(X) \le \frac{2k}{k+1}\cdot \frac{f(X)}{OPT}\cdot B
        \end{split}
    \end{equation}
\end{corollary}
Let, once again, $R$ be the set of rounds. Suppose that $X$ is the subset of agents of $S$ that is included in a round $j$ with length parameter $a_j$, such that $a_j \cdot \frac{\opt}{\vmax}\ge81\, e$. Now
consider the following random variables for $j\in R, i \in [|S|]$:
\begin{equation}
    \begin{split}
            X_i^{j} &= \begin{cases} 
      w_i & \text{ w.p.  } \frac{6}{10e}\cdot a_j\\
      0 & \text{ otherwise  } 
   \end{cases}\\
   X^{j}&= \sum_{i=1}^{|S|}X_{i}^{j}
    \end{split}
\end{equation}

 By lemmas ~\ref{lemma:RoundPro},~\ref{lem4.7} it is evident that $X^{j}$ is a lower bound of the value $f(X)$ contained in round $j$. Furthermore, we can prove the following:

\begin{lemma}\label{lemmaTool}
    Let $\opt_j$ be the value of an optimal solution for an $a_j$-round $j$, when restricted to budget $B_j = 3\cdot C\cdot a_j\cdot B$ budget, where $a_j$ is good with respect to $\opt$. If $C\cdot a_j\cdot \opt\le X^j$ then 
    \begin{equation}
        \begin{split}
            \opt_j \ge C\cdot a_j\cdot \opt
        \end{split}
    \end{equation}
\end{lemma}
\begin{proof}
Let $X$ be the set of agents included in round $j$. Define $S_{j} = X\cap S$ and denote by $s_{j,i}$ the $i-$th element of $S_j$ in the order of appearance within the round. We can select the first $\mu$ agents $ \{s_{j,i}\}_{i=1}^{\mu}$ (for some $\mu \in \mathbb{N}$) such that their total value $f( \{s_{j,i}\}_{i=1}^{\mu})$ does not exceed $C\cdot a_j\cdot \opt$ by more than $\vmax.$ More specifically, there exists $\mu \in \mathbb{N}$ such that:
\begin{equation}
    \begin{split}
        C\cdot a_j\cdot \opt &\le f\left(\bigcup_{i=1}^{\mu}\{s_{j,i}\}\right ) \\
        &\le C\cdot a_j\cdot \opt+ \vmax\ \\
        &= \left(C\cdot a_j+ \frac{\vmax}{\opt}\right)\cdot \opt 
    \end{split}
\end{equation}
Which, by Corollary \ref{cor4.2}, implies:
\begin{equation}
            c\lp(\bigcup_{i=1}^{\mu}\{s_{j,i}\}\rp) \le 2\cdot\left (C\cdot a_j \cdot + \frac{\vmax}{\opt}\right)\cdot B\le 3\cdot C\cdot a_j\cdot B,
\end{equation}
where the last inequality is due to $a_j$ being good with respect to $\opt$, i.e., $a_j \geq 81\,e\,\vmax\,/\,\opt$.
\end{proof}

Lemma~\ref{lemmaTool} enables us to analyze the value of $X^j$ to determine whether a round is dense, rather than relying on $\opt_j$. Now we can use concentration bounds on the random variable $X_{j}$ to bound the probability that the $j$-th round is dense.

We now ready to conclude this section with presenting the proof of Lemma~\ref{lemma:roundProb}.

\begin{proof}[Proof of lemma \ref{lemma:roundProb}:]

     By Lemma \ref{lemmaTool}:
    \begin{equation}
        \begin{split}
            \Prob{\text{round $j$ is not dense}} \le \Prob{X^{j}<C\cdot a_j \cdot \opt}
        \end{split}
    \end{equation}
    We notice that $\frac{1}{2}\cdot \frac{6}{10e} \cdot \frac{k-1}{2k} \ge C$ (for $k\ge 10^7$) and thus:
    \begin{equation}
        \Prob{\text{round $j$ is not dense}} \le \Prob{X^{j}<\frac{1}{2}\cdot \frac{6}{10e}\cdot a_j \cdot \frac{k-1}{2k}\cdot \opt}
    \end{equation}
    Now using the fact that $\E{}{X^j} = q_j\cdot f(S)$, along with Lemma \ref{lemma:RoundPro}:
        \begin{equation}
        \Prob{\text{round $j$ is not dense}} \le\Prob{X^{j}\le \frac{1}{2}\cdot \E{}{X^{j}}} 
    \end{equation}
    We can now apply Chernoff bound (setting $\delta = \frac{1}{2}$) on random variable $X^{j}$ to get:
    \begin{equation}
        \begin{split}
           \Prob{\text{round $j$ is not dense}} &\le \Prob{X^{j}\le (1-\delta)\E{}{X^{j}}}\\
            &\le \exp\lp\{\frac{-\delta^2 \E{}{X^{j}}}{2\cdot \max{X_{i}^{j}}}\rp\}
        \end{split}
    \end{equation}
    Using the fact that $\E{}{X^{j}} =  \frac{6}{10e}\cdot a_j\cdot f(S) \ge \frac{6}{10e}\cdot a_j\cdot \frac{k-1}{2k}\cdot \opt$:
    \begin{equation}
        \Prob{\text{round $j$ is not dense}} \le \exp\lp\{\frac{-\delta^2 \cdot \frac{6}{10e}\cdot a_j\cdot\frac{k-1}{2k}\cdot \opt}{2\vmax}\rp\} 
    \end{equation}
    After calculations we reach the following:
    \begin{equation}
        \Prob{\text{round $j$ is not dense}} \le\exp\lp\{\frac{- a_j \cdot  (k-1)}{27e}\rp\} \le 0.1
    \end{equation}
    The last inequality follows from the fact that $a_j$ is good with respect to $\opt$, i.e., $a_j \geq 81\,e\,\vmax\,/\,\opt$, and from the hypothesis that $k\ge 10^7$.
\end{proof}

\subsection{The Proof of Lemma~\ref{lemma:PhaseProbability}}\label{negdep}

To extend our analysis to dense phases we should first pay attention to the dependency between the probability of success of consecutive rounds. Indeed, we should notice that conditional to the previous round having failed the next round is more likely to succeed. Such a dependency bares a significant resemblance to the Balls and Bins problem \cite{johnson1977urn}. Below we present how to utilize results from \cite{negativedepend} to prove that concentration of mass arguments still hold in this setting.

In the following we will present a complete proof of the validity of Chernoff bound on the following random variables:

\begin{equation}
    \begin{split}
    Q_i &= \begin{cases} 
      1 ,& \text{ if round } $i$ \text{ is dense}\\
      0, & \text{ otherwise  } 
   \end{cases}\\
    \end{split}
\end{equation}

Firstly, we need to present some important notions from \cite{negativedepend}.

\begin{definition}[Negative Association]
   Let $\mathbf{X} := (X_1, \dots, X_n)$ be a vector of random variables.

\begin{enumerate}
    \item [$(-A)$] The random variables, $\mathbf{X}$ are \emph{negatively associated} if for any two disjoint index sets, $I, J \subseteq [n]$,
\[
\mathbb{E}[f(X_i, i \in I)g(X_j, j \in J)] \leq \mathbb{E}[f(X_i, i \in I)]\mathbb{E}[g(X_j, j \in J)]
\]
for all functions $f : \mathbb{R}^{|I|} \to \mathbb{R}$ and $g : \mathbb{R}^{|J|} \to \mathbb{R}$ that are both non-decreasing or both non-increasing.
\end{enumerate}
\end{definition}

\begin{lemma}[Zero-One Lemma for ($-A$)] \label{ZeroOne}
    If $X_1, \dots, X_n$ are zero-one random variables such that $\sum_i X_i = 1$, then $X_1, \dots, X_n$ satisfy ($-A$).
\end{lemma}

\begin{proposition}\label{proptrans}
    \begin{enumerate}
    \item If $\mathbf{X}$ and $\mathbf{Y}$ satisfy ($-A$) and are mutually independent, then the augmented vector $(\mathbf{X}, \mathbf{Y}) = (X_1, \dots, X_n, Y_1, \dots, Y_m)$ satisfies ($-A$).
    
    \item Let $\mathbf{X} := (X_1, \dots, X_n)$ satisfy ($-A$). Let $I_1, \dots, I_k \subseteq [n]$ be disjoint index sets, for some positive integer $k$. For $j \in [k]$, let $h_j : \mathbb{R}^{|I_j|} \to \mathbb{R}$ be functions that are all non-decreasing or all non-increasing, and define $Y_j := h_j(X_i, i \in I_j)$. Then the vector $\mathbf{Y} := (Y_1, \dots, Y_k)$ also satisfies ($-A$). That is, non-decreasing (or non-increasing) functions of disjoint subsets of negatively associated variables are also negatively associated.
\end{enumerate}
\end{proposition}

\begin{proposition}\label{lemChern}
    The Chernoff--Hoeffding bounds are applicable to sums of variables that satisfy the negative association condition ($-A$).
\end{proposition}

 We are now ready to complete our proof:
 \begin{lemma}
     We can apply Chernoff bound on $\{Q_i\}_{i\in[\ell]}$
 \end{lemma}
 \begin{proof}
     Consider the following random variables:
     \begin{equation}
         \begin{split}
              Y_i^{j} &= \begin{cases} 
      1 & \text{ if agent $b_i$ is in round $j$}\\
      0 & \text{ otherwise  } 
   \end{cases}\\
    Q_j &= \begin{cases} 
      1 & \text{ if  } \sum_{i=1}^{n}w_i \cdot Y_{i}^{j} \ge  C\cdot a_j \cdot  OPT\\
      0 & \text{ otherwise  } 
   \end{cases}
         \end{split}
     \end{equation}

     By lemma \ref{ZeroOne} it is immediate that $(Y_i^{1},Y_{i}^2,\dots,Y_{i}^{\ell})$ are negatively associated. By Proposition \ref{proptrans}.1, along with the independency among agents, we can conclude that the whole set $(Y_{i}^{j})_{i\in [n],j\in[\ell]}$ is negatively associated. Finally, we use proposition \ref{proptrans}.2, setting 
     \begin{equation}
         \begin{split}
             h_j = \begin{cases} 
      1 & \text{ if  } \sum_{i=1}^{n}w_i\cdot Y_{i}^{j} \ge C\cdot a\cdot OPT\\
      0 & \text{ otherwise  } 
   \end{cases}
         \end{split}
     \end{equation} which is an increasing function of $Y_i^{j}$, to get that
     $(Q_1,Q_2,\dots,Q_\ell)$ are negatively associated. We now get the desired result directly from Proposition \ref{lemChern}
 \end{proof}

The following lemma effectively leverages this dependency to demonstrate that all phases, whose rounds are good with respect to their thresholds, are dense with significant probability.

\begin{proof}[Proof of Lemma \ref{lemma:PhaseProbability}]
Proposition \ref{lemma:roundProb} suggests that every round succeeds with probability at least $0.9$. Now let $\{Q_i\}_{i=1}^{\delta}$ be random variables under the following distribution:
\begin{equation}
    \begin{split}
    Q_i &= \begin{cases} 
      1 ,& \text{ if round } $i$ \text{ is dense}\\
      0, & \text{ otherwise  } 
   \end{cases}\\
    \end{split}
\end{equation}
 By leveraging the previous results, we can argue that the variables $ Q_i $ exhibit negative dependence, which permits the use of concentration inequalities.

Let $Q = \sum_{i=1}^m  Q_i$. The probability a Phase is not dense is, by applying Chernoff bound on $Q$, at most:
\begin{equation}
    \begin{split}
       \Prob{ Q < \frac{\delta}{2} } &\le \Prob{ Q < \frac{1}{1.8} \cdot \E{}{Q} } \\
       &\le \exp\lp\{ - \frac{(\frac{0.8}{1.8})^2\cdot 0.9 \cdot \delta}{2} \rp\} \\
       & = \exp\lp\{ - \frac{4 \cdot \delta}{45} \rp\}
    \end{split}
\end{equation}
\end{proof}


 \subsection{Lemmas Used in Estimating the Correctness Probability in Section~\ref{sec:estimate}}
 \label{A3}

\begin{lemma}\label{lemma:E2}
    The event $\mathcal{E}_2$ happens with probability at least $0.9$.
\end{lemma}
\begin{proof}
    To successfully identify the correct intervals, we need the last, or the second to last, successful Phase to include $\frac{\opt}{8}$. Let us denote by $P_i$ the Phase that tests threshold $t_i$. Let $\frac{\opt}{8}\in (t_j,t_{j+1}]$, then, if $P_j$ is dense, $P_j$ will be successful and all $P_i$, with $i>j+1$ will fail, by Lemma \ref{lemma:PERIOD1}. Thus, the set of intervals we end up with will include $(t_j,t_{j+1}].$ Thus, we need to investigate the probability that Phase $P_j$ is dense. By Lemma \ref{lemma:PhaseProbability} we have that:
\begin{equation}
    \begin{split}
            \Prob{P_j \text{ is dense}} &\ge 1-\exp\left\{-\frac{4\cdot \gamma_{j}}{45}\right\}\\
        &\ge 1-\exp\left\{-\frac{4\cdot \gamma_{2}}{45}\right\}  =1-\exp\left\{-3\right\}\ge 0.9 
    \end{split}
\end{equation}
\end{proof}

 \begin{lemma}\label{lemma:BinaryProb}
    All phases tested with a threshold $t\le\frac{\opt}{8}$, during BinarySearch and Exploitation, are dense with probability at least $0.9$ (i.e., the event $\Event_3$ occurs with probability at least $0.9$). 
\end{lemma}

\begin{proof}
In the worst case we might need all of the $\frac{2\ell}{m}$ Phases to be dense.
Lemma \ref{lemma:roundProb} suggests that every round succeeds with probability at least $0.9$. Now let $\{Q_i\}_{i=1}^{m}$ be random variables under the following distribution:
\begin{equation}
    \begin{split}
    Q_i &= \begin{cases} 
      1 ,& \text{ if round } $i$ \text{ is dense}\\
      0, & \text{ otherwise  } 
   \end{cases}\\
    \end{split}
\end{equation}

Let $Q = \sum_{i=1}^m  Q_i$.
As argued before (\ref{negdep}), we can apply concentration of mass arguments to $Q$. The probability a Phase is not dense is, by applying Chernoff bound on $Q$, at most:
\begin{equation}
           \Prob{ Q < \frac{m}{2} } \le \Prob{ Q < \frac{1}{1.8} \cdot \E{}{Q} } 
       \le \exp\lp\{ - \frac{(\frac{0.8}{1.8})^2\cdot 0.9 \cdot m}{2} \rp\}
\end{equation}
Using the definitions of $m$ and $t_{\max}$, we get:
\begin{equation}
    \Prob{ Q < \frac{m}{2} } \le\frac{1}{\log\left(\frac{t_{\max}}{t_{\min}}\right)}= \frac{1}{t_{\min}}
\end{equation}
Leveraging our hypothesis that $t_{\min}\ge 10^7$:
\begin{equation}\label{eq:77}
    \Prob{ Q < \frac{m}{2} } \le \frac{1}{20\left\lceil\log\left(t_{\min}\right)\right\rceil}
\end{equation}
To get the desired probability bound, we will now use Union Bound on the event where the first $\frac{2\cdot\ell}{m}$ Phases are dense. Namely:
\begin{equation}
    \begin{split}
         \Prob{\text{First }\frac{2\cdot\ell}{m} \text{ Phases are dense} } &\ge 1 - 2\cdot \left\lceil\log\log\left(\frac{t_{\max}}{t_{\min}}\right)\right\rceil \cdot \Prob{\text{A Phase is not dense}} 
    \end{split}
\end{equation}
Now using the definition of $t_{\max} = 2^{\frac{t_{\min}}{\vmax}}\cdot t_{\min}$, along with inequality~\ref{eq:77}:
\begin{equation}
    \Prob{\text{First }\frac{2\cdot\ell}{m} \text{ Phases are dense} } \ge 1 - \frac{\left\lceil\log\left(t_{\min}\right)\right\rceil}{10\cdot \left\lceil\log\left(t_{\min}\right)\right\rceil} = 0.9
\end{equation}
\end{proof}

Sampling round lengths from a distribution introduces the risk that we run out of agents during the execution of our mechanism. Consequently, our analysis relies on the assumption that the total round lengths remain within the input size. Fortunately, the following lemma guarantees that this condition holds with constant probability:  

\begin{lemma}\label{lemma:Fit}
    We will not run out of agents during the execution of \hyperref[alg:LMMECH]{LM-Mechanism} with probability at least $0.97$ (i.e., the event $\Event_4$ occurs with probability at least $0.97$).
\end{lemma}
\begin{proof}
    We will investigate the round lengths drawn as follows:
\begin{enumerate}
    \item Applying Chernoff bound onto the random length $\tau$ drawn for the estimation of $\vmax$ we get that:
    \begin{equation}
        \begin{split}
            \Prob{\tau \ge \frac{2}{5}\cdot n} \le \exp\left\{-\frac{n}{225}\right\}\le 0.01,
        \end{split}
    \end{equation}
    where the last inequality holds for $n\ge10^7$, which must be true for our assumption $\opt\ge10^7\vmax$ to hold.
    %We will denote the event where $\tau \ge \frac{2}{5}n$ as $E_\tau$
    Thus:
    \begin{equation}
        \Prob{\tau < \frac{2}{5}\cdot n}\ge 0.99
    \end{equation}
    \item We now consider the random lengths $n_{i,j}$ drawn during Period 2. Consider $m_{i,j}\sim B(n,a_{i})$. If we were to use $m_i$ as our round lengths then our risk of running out of agents would be greater than with $n_i$. We observe that: 
    \begin{equation}
        \E{}{\sum_{i=2}^{T}\sum_{j=1}^{\gamma_i} n_{i,j}}\le\E{}{\sum_{i=2}^{T}\sum_{j=1}^{\gamma_i} m_{i,j}} = n\cdot \sum_{i=2}^{T}\gamma_i \cdot a_i
    \end{equation}
    By applying Markov's inequality on the sum of these random variables, and noticing that  $\E{}{m_{i,j}} = n\cdot a_{i}$, we get:
    \begin{equation}
        \Prob{\sum_{i=2}^{T}\sum_{j=1}^{\gamma_i} n_{i,j} \ge 100\cdot n \cdot\sum_{i=2}^{T} a_{i} \cdot \gamma_i}\le\Prob{\sum_{i=2}^{T}\sum_{j=1}^{\gamma_i} m_{i,j} \ge 100\cdot n \cdot\sum_{i=2}^{T} a_{i} \cdot \gamma_i}\le 0.01
    \end{equation}
    Thus:
    \begin{equation}
        \begin{split}
            \Prob{\sum_{i=2}^{T}\sum_{j=1}^{\gamma_i} n_{i,j} \ge 100\cdot n \cdot\sum_{i=2}^{T} a_{i} \cdot\gamma_i}\le 0.01 
        \end{split}
    \end{equation}
    By lemma \ref{lemma:SeqBound} we get  $\sum_{i=2}^{T}a_i \cdot \gamma_i < \frac{1}{500}$, and thus:
    \begin{equation}
        \begin{split}
            100\cdot n \cdot\sum_{i=2}^{T} a_{i} \cdot \gamma_i < \frac{n}{5}
        \end{split}
    \end{equation}
    Overall:
    \begin{equation}
        \Prob{\sum_{i=2}^{T}\sum_{j=1}^{\gamma_i} n_{i,j} < \frac{n}{5}}\ge 0.99 
    \end{equation}
    \item Finally, we draw $2\cdot\ell$ lengths $n_i\sim B(N_i,a)$ for the rounds of BinarySearch and Exploitation with the same length parameter $a$. Suppose, similarly with before, the random variables $m_i \sim B(n,a)$ for $i\in[2\,\ell]$. It is evident that 
    \begin{equation}
        \E{}{\sum_{i=1}^{2\,\ell}n_i}\le\E{}{\sum_{i=1}^{2\,\ell}m_i} =  n\cdot 2\,\ell \cdot a = \frac{n}{3}.
    \end{equation} 
    By applying now Chernoff bound on $m_i$ we get that:
        \begin{equation}
        \begin{split}
                        \Prob{\sum_{i=1}^{2\,\ell} n_{i} \ge \frac{2}{5}\cdot n}\le\Prob{\sum_{i=1}^{2\,\ell} m_{i} \ge \frac{2}{5}\cdot n}\le 0.01. 
        \end{split}
    \end{equation}
    Overall we get:
            \begin{equation}
        \begin{split}
\Prob{\sum_{i=1}^{2\,\ell} n_{i} < \frac{2}{5}\cdot n}\ge 0.99
        \end{split}
    \end{equation}
\end{enumerate}
All in all, by Union Bound on the events described before, we get that we will not run out of agents during our Mechanism with probability at least $1 - 0.01-0.01-0.01 = 0.97$ 
\end{proof}

%We are now ready to present a complete proof for lemma \ref{lemma:GoodEvent}
%\begin{proof}[Proof of lemma \ref{lemma:GoodEvent}]
%    The bound on event $\mathcal{E}_2$ and $\mathcal{E}_3$ are an immidiate consequence of lemmas \ref{lemma:E2} and \ref{lemma:BinaryProb}. The bound on the event $\mathcal{E}_4$ is obtained from lemma \ref{lemma:Fit}. We then conclude the proof as presented in the main text.
%\end{proof}



\section{The Proof of Lemma~\ref{BUDGET}}\label{budgetproofs}

Below we prove that all needed rounds can be conducted without fear of running out of budget.
\begin{proof}[Proof of Lemma \ref{BUDGET}:]
According to Property \ref{property:a} during Period 2 in worst case the overall budget expended is the following:
\begin{equation}
    \begin{split}
        \sum_{i=2}^{T}  \gamma_i\cdot3\cdot C\cdot a_i\cdot B &\le\sum_{i=2}^{T}\frac{3\cdot C}{i^{10}}\cdot B < 0.04\cdot B ,
    \end{split}
\end{equation}
where the second to last inequality follows from Lemma~\ref{lemma:SeqBound}.

According to Property \ref{property:a}, during Period 3 and 4, in worst case the overall budget expended is the following:
\begin{equation}
    \begin{split}
        \sum_{i=1}^{2\cdot\ell} 3\cdot C\cdot a\cdot B         &\le 6\cdot C\cdot \ell \cdot a\cdot B \\
        &= C\cdot B\\
        &\le 0.06\cdot B
    \end{split}
\end{equation}    
Overall we have expended a budget of at most $B/10$.
\end{proof}

\end{document}
