\section{Related Work}
\label{sec:relate}
%In this section, we provide a comprehensive review of related works, including model-based traditional methods and data-driven deep networks.
%The fairly representative methods were based on the Retinex____ decomposition way like KinD____, UTVNet____ and URetinex____. They deepened the network layers to acquire the features of different levels for decomposition or established unique blocks for more comprehensive image information. There existed other effective but complicated as the above methods like FIDE____ and RCTNet____. They adopted deep-level frameworks like U-Net to train the enhancer and they commonly stacked more network layers to characterize textures/details.
%
%Recently, as the demand for real-time performance in practical applications has become increasingly urgent, researchers are no longer satisfied with merely improving visual quality and are gradually shifting their focus towards optimizing computational efficiency. Along with the development of deep enhancers, researchers put their focus on computational efficiency. DCE____ proposed an efficient unsupervised image enhancement method by transforming light enhancement into a task of image-specific curve estimation. RUAS____ employed unrolling optimization in the NAS process to construct a high-efficiency model. SCI____ proposed a  self-calibrated cascaded illumination learning process with the setting of weight sharing, which was more flexible and faster than the presented works before. It is noticeable that these lightweight methods were mostly designed around illumination.

\subsection{Model-based Traditional Methods}
In the era of model-based traditional methods, prevailing approaches endeavored to guide the design of image enhancement through the incorporation of physical imaging models, with Retinex theory-based schemes standing out as the most emblematic and widely employed. The Retinex theory____ posits that low-light images can be decomposed into illumination and reflectance components, with the former closely tied to scene factors and the latter representing a well-exposed clear image. This theory plays a pivotal role in the field, spurring traditional methods to develop efficient statistical priors centered around Retinex theory.

A direct approach for Retinex theory-based traditional methods is to design regularization priors separately for the illumination and reflectance components. The work in____ innovatively introduced the Total Variation (TV) regularization and applied it to the optimization of both illumination and reflectance. Gu~\emph{et al.}____ further refined integer-order TV regularization by employing fractional calculus to enhance the effectiveness of illumination decomposition. Conversely, the work in____ designed a structure and texture-aware Retinex model, using an exponential local derivative to devise an exponential filter for regularizing the illumination and reflectance variables obtained from Retinex decomposition. Cai~\emph{et al.}____ enhanced the illumination constraints by incorporating piece-wise shape prior and bright channel prior, establishing a unified intrinsic-extrinsic model.
Subsequently, to counteract the detrimental influence of potential noise, researchers turned their attention to formulating noise-suppressed reflectance priors. Fu~\emph{et al.}____ introduced weighted sparsity regularization to enforce piece-wise smoothing of the estimated reflectance. And the work in____ proposed a robust Retinex model incorporating a noise map to achieve structure-revealed reflectance under a gradient-based fidelity term.

% In____, low-rank prior regularization was employed to generate noise-free reflectance from a new perspective.

%In____, the first attempt was made by applying Total Variation (TV) regularization____ to both illumination and reflectance. Cai~\emph{et al.}____ further strengthened the illumination constraint by introducing piece-wise shape prior and bright channel prior, to building a joint intrinsic-extrinsic model. Gu~\emph{et al.}____ exploited fractional-order gradient to enhance the integer-order TV regularization terms for generating better illumination. In contrast, Xu~\emph{et al.}____ developed a structure and texture-aware Retinex model by using exponentiated local derivatives to distinguish structure and texture, which were employed for regularizing illumination and reflectance, respectively.
%Recognizing the detrimental impact of potential noise on image quality, researchers shifted their focus to defining noise-suppressed reflectance priors to mitigate the adverse effects of noise. Fu~\emph{et al.}____ introduced a weighted sparsity  regularization to enforce piece-wise smoothing of the estimated reflectance. A robust Retinex model was proposed in____, where a noise map was incorporated to obtain the structure-revealed reflectance under a gradient-based fidelity term. The work in____ introduced low-rank prior regularization, taking a different approach to facilitate the generation of noise-free reflectance. 

Despite the progress made by the aforementioned approaches that estimate and optimize dual variables using a single model, a notable drawback of these methods is their low computational efficiency, as the multi-variable setting significantly increases the inference burden. To address this issue, a series of methods focused on optimizing the core component (illumination) emerged and have become the mainstream in traditional approaches. LIME____ represents a seminal approach in this class of methods, employing Relative Total Variation (RTV) for direct illumination estimation, which initially devised for image smoothing____. This method is notable for its simple single-variable optimization process, enabling it to achieve rapid inference while preserving impressive visual quality. Building on the success of single-variable optimization, subsequent works____ sought to address the over-exposure issues inherent in LIME. 
Zhang~\emph{et al.}____ introduced a perceptual bidirectional similarity criterion and combined it with Retinex theory to frame the exposure correction problem as an illumination optimization task, resulting in enhanced images with more uniform exposure. The work in____ identified the over-exposure problem stemming from the use of image smoothing models for illumination estimation and proposed a novel fidelity measure to resolve it.

%Inspired by the success of single-variable optimization, a series of subsequent works____ endeavored to tackle the over-exposure challenge that emerged in LIME. Zhang~\emph{et al.}____ employed perceptually bidirectional similarity to constrain the illumination, but this led to an inevitable slowdown in computational speed. Ma~\emph{et al.}____ offered an explanation for the over-exposure issue arising from the use of an image smoothing model for illumination estimation and then developed a new fidelity to settle it. 

\subsection{Data-driven Deep Networks}
In recent years, spurred by the rapid advancements in deep learning and the exponential growth of low-light datasets, the research focus in low-light image enhancement has shifted from designing statistical priors to learning deep models from extensive datasets____. Data-driven deep network approaches now hold the central position in contemporary low-light image enhancement technology.

%In recent years, the field of exposure correction has witnessed a significant shift away from relying on defining statistical priors for task modeling. Instead, the focus has increasingly shifted towards learning deep models from massive data. Data-driven deep networks____ have become central to the development of exposure correction techniques.

% 自数据驱动深度网络被开发至今，设计网络架构一直是最基础的方案且广受关注。研究人员一直在努力尝试设计搭建各种网络结构，以有效提升低光图像增强的性能。RetinexNet是该领域内的里程碑式工作，它受Retinex理论启发设计了一种分解网络以同时估计光照和反射率。该经典分解式框架也启发了更多研究人员探索更有效的建模机制。KinD在其基础上进行了进一步调整，针对光照和反射进一步设计调整模块以强化不同组件之间的联系。其拓展版本对网络结构进行了进一步优化以加速训练进程。Yang等人设计了一种稀疏梯度最小化网络以更好地保留边缘信息，并进一步设计子网络解决分解分量中存在的对比度偏移和密集噪声问题。Zhao等人将基于Retinex的分解过程视作一个生成问题，并基于该视角提出了一种统一的深度低光图像增强框架。A中的工作则通过引入用于提取语义信息的分割网络，将Retinex分解与语义信息感知相结合得到语义引导的反射。
%The work in____ integrated Retinex decomposition with semantic information perception by introducing a segmentation network for extracting semantic information. In addition, the combination of optimization-inspired unrolling flow and deep networks has also been widely investigated____ to generate decomposition-type networks with interpretability.
{Since the development of data-driven deep networks, designing network architectures____ has been a foundational and highly focused endeavor. Researchers have continuously experimented with various network structures to enhance the performance of low-light image enhancement effectively. RetinexNet____, a milestone in this field, is inspired by Retinex theory and designs a decomposition network to simultaneously estimate illumination and reflectance. This classical decomposition framework has also inspired further exploration into more efficient modeling mechanisms. Building on this, KinD____ introduced additional modules to refine illumination and reflectance, strengthening the connections between different components. Kandula~\textit{et al.}____ proposed a method that primarily focuses on utilizing contextual information to guide and optimize illumination for unsupervised image enhancement. The work in____ compared to the previous work, further integrated computational efficiency into the task objectives by constructing an efficient neural network without the need for additional decomposition networks or regularization functions. Moreover, with the recent surge in popularity of Transformers and diffusion models, a series of related novel approaches have emerged. LLFormer____ introduces a Transformer-based low-light image enhancement algorithm designed for ultra-high-definition images, utilizing an axial multi-head self-attention mechanism and cross-layer attention fusion blocks to achieve low linear complexity. The work in ____ proposes a degradation-aware learning scheme using diffusion models, which considers latent degradation representations to guide the diffusion process, enabling effective brightness enhancement for low-light images. Recently, Hou~\emph{et al.}____ introduced a global structure-aware regularization method, which helps preserve intricate details and enhance contrast during the diffusion process, mitigating noise generation.}

%Apart from the decomposition-type modeling paradigm, a series of techniques have made efforts in heuristically designing architectures____. 

%Designing network architectures____ serves as the foundational element for data-driven deep networks and has garnered widespread attention. Researchers have been actively exploring and optimizing different network structures to effectively handle exposure correction. RetinexNet____ emerged as a representative and foundational work for designing Retinex-inspired deep decompositon networks capable of simultaneously estimating illumination and reflectance. Around this decomposition framework, researchers began to explore more effective modeling mechanisms. KinD____ strengthened the connection between different components, and its extended version KinD++____ further optimized the network architecture to accelerate training. The approach in____ developed a sparse gradient minimization subnetwork for preserving crucial structural information in the decomposition process. Fan~\emph{et al.}____ introduced segmentation network for extracting semantic information to acquire semantic-aware reflectance. 

{Compared to methods centered on network architecture design, recent advancements in low-light image enhancement have increasingly focused on leveraging carefully designed learning strategies to improve computational efficiency, leading to the proposal of a series of efficiency-oriented approaches____. Guo~\emph{et al.}____ introduced a lightweight unsupervised approach, meticulously tailoring a series of loss functions to capture pixel-level high-order curves. Ma~\emph{et al.}____ crafted a weight-sharing cascaded process for illumination estimation, accelerating the algorithm through self-calibration learning strategies that constrain each stage. The work in____ designed a cooperative learning framework, exploring the intrinsic connections between various visual tasks and features in low-light scenes. Fu~\emph{et al.}____ proposed establishing connections between images with identical content within the reflectance domain, employing a self-supervised mechanism to further eliminate the interference of redundant features in RAW images. ZeroIG____ developed a zero-shot image enhancement method, introducing denoising-related constraints in the illumination-guided enhancement process to better handle noise interference. SCLM____ aims to simplify the network architecture to achieve lightweight image enhancement. They first build a single convolutional layer model for coarse enhancement
using re-parameterization, and then introduce a curve adjustment-based local adaptive module to optimize the enhancement results. However, due to the difficulty in ensuring the correlation between the predefined re-parameterization structure and task requirements, SCLM experiences certain limitations in performance enhancement.}

%Different from the above methods that focused on architecture design, recent research had moved towards designing learning strategies, following the emergence of various learning methods in other fields____. Guo~\emph{et al.,}____ proposed a lightweight unsupervised method by carefully customizing a series of loss functions to learn pixel-level high-order curve. Ma~\emph{et al.,}____ designed a weight-sharing cascaded process for illumination estimation, achieving algorithm acceleration by introducing self-calibration learning strategies to constrain each stage. Liu~\emph{et al.,}____ devised a cooperative learning framework by delving into the intrinsic connections between various visual tasks and low-light scene features. 

%