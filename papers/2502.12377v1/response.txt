\section{Related Work}
\label{sec:related}
There has been substantial progress on bridging the representational differences between humans and machine learning models over the last few years. **Kamnitsas, "DeepMedic: Automatic Brain Tumor Segmentation Using Cascaded Residual Connection-Based Dilated Convolutional**__**Nair, Vosoughi, & Khashabi, "Debiasing Transfer Learning in Natural Language Processing"**
 designs a new block for CNNs called the VOne block, which simulates V1 area processing. This work found that incorporating the VOne block into ResNet models increased robustness to both white box adversarial examples and common corruptions without sacrificing clean performance on ImageNet. **Geirhos et al., "Imagenet-trained CNNs are biased towards texture; increasing shape bias improves accuracy"**
 introduced a technique for regularizing machine learning models based on human neural readings and found that the resultant regularized models were more robust and human-aligned.


**Geirhos et al., "ImageNet-trained CNNs are biased towards texture; increasing shape bias improves accuracy"** shows that the property difference of the spatial frequency channel between humans and neural networks explains both shape bias and adversarial robustness of networks. 
Models with higher levels of human alignment have also been shown to be more robust to distribution shifts and ImageNet-A data**Geirhos et al., "Imagenet-trained CNNs are biased towards texture; increasing shape bias improves accuracy"**.
Additionally, it has been shown that models tend to prioritize texture information over shape information**Geirhos et al., "ImageNet-trained CNNs are biased towards texture; increasing shape bias improves accuracy"** and that this bias extends to real-data decisions and is one of the major causes for vulnerability to natural adversarial samples**Goodfellow, Shlens, & Szegedy, "Explaining and Harnessing Adversarial Examples"**.