
\documentclass{article} % For LaTeX2e
\usepackage{iclr2025_re-align_workshop,times}

% Optional math commands from https://github.com/goodfeli/dlbook_notation.
\input{math_commands.tex}

\usepackage{hyperref}
\usepackage{url}
\usepackage{xcolor}
\usepackage{graphicx}
\usepackage{subfig}
\usepackage{booktabs}
\newcommand\todo[1]{\textcolor{red}{#1}}
\newcommand{\nummodels}{118}
\renewcommand{\sectionautorefname}{Section}
\renewcommand{\subsectionautorefname}{Section}
\renewcommand{\subsubsectionautorefname}{Section}
\renewcommand{\appendixautorefname}{Appendix}
% \usepackage[subtle]{savetrees}


\title{Alignment and Adversarial Robustness: Are More Human-Like Models More Secure?}

% Authors must not appear in the submitted version. They should be hidden
% as long as the \iclrfinalcopy macro remains commented out below.
% Non-anonymous submissions will be rejected without review.

\author{Blaine Hoak\thanks{Equal contribution.}, ~ Kunyang Li\footnotemark[1] ~ \& Patrick McDaniel \\
Department of Computer Science\\
University of Wisconsin-Madison\\
\texttt{\{bhoak, kli253, mcdaniel\}@cs.wisc.edu}
}

% \author{Blaine Hoak\thanks{Equal contribution.}\\ 
% Department of Computer Science\\
% University of Wisconsin-Madison\\
% \texttt{bhoak@cs.wisc.edu} \\
% \And
% Kunyang Li\footnotemark[1] \\
% Department of Computer Science\\
% University of Wisconsin-Madison\\
% \texttt{kli253@cs.wisc.edu} \\
% \And
% Patrick McDaniel \\
% Department of Computer Science\\
% University of Wisconsin-Madison\\
% \texttt{mcdaniel@cs.wisc.edu}
% }

% The \author macro works with any number of authors. There are two commands
% used to separate the names and addresses of multiple authors: \And and \AND.
%
% Using \And between authors leaves it to \LaTeX{} to determine where to break
% the lines. Using \AND forces a linebreak at that point. So, if \LaTeX{}
% puts 3 of 4 authors names on the first line, and the last on the second
% line, try using \AND instead of \And before the third author name.

\newcommand{\fix}{\marginpar{FIX}}
\newcommand{\new}{\marginpar{NEW}}
\newcommand{\shortsection}{\noindent\textbf}

\iclrfinalcopy % Uncomment for camera-ready version, but NOT for submission.
\begin{document}


\maketitle

\begin{abstract}
Representational alignment refers to the extent to which a modelâ€™s internal representations mirror biological vision, offering insights into both neural similarity and functional correspondence. Recently, some more aligned models have demonstrated higher resiliency to adversarial examples, raising the question of whether more human-aligned models are inherently more secure. 
In this work, we conduct a large-scale empirical analysis to systematically investigate the relationship between representational alignment and adversarial robustness. We evaluate \nummodels{} models spanning diverse architectures and training paradigms, measuring their neural and behavioral alignment and engineering task performance across 106 benchmarks as well as their adversarial robustness via AutoAttack. Our findings reveal that while average alignment and robustness exhibit a weak overall correlation, \textit{specific} alignment benchmarks serve as strong predictors of adversarial robustness, particularly those that measure selectivity towards texture or shape. These results suggest that different forms of alignment play distinct roles in model robustness, motivating further investigation into how alignment-driven approaches can be leveraged to build more secure and perceptually-grounded vision models.


\end{abstract}

\input{0_intro}
\input{1_background}
\input{2_methods}
\input{3_results}
\input{4_related}

\section{Conclusions}
In this work, we find that, perhaps surprisingly, representational alignment and adversarial robustness in vision systems are not always correlated. However, we do observe that certain individual benchmarks serve as strong indicators of robust accuracy, particularly those that assess a model's preference for texture information over shape. From this, we hope to encourage future work to leverage insights found in both areas to build more secure and aligned vision systems.


\subsubsection*{Acknowledgments}
% Use unnumbered third level headings for the acknowledgments. All
% acknowledgments, including those to funding agencies, go at the end of the paper.
This material is based upon work supported by, or in part by, the National Science Foundation under Grant No. CNS 2343611, and by the Combat Capabilities Development Command Army Research Office under Grant No. W911NF-21-1-0317 (ARO MURI). Any opinions, findings, and conclusions or recommendations expressed in this publication are those of the author(s) and do not necessarily reflect the views of the National Science Foundation, the U.S. Government, or the Department of Defense. The U.S. Government is authorized to reproduce and distribute reprints for government purposes notwithstanding any copyright notation hereon.


\bibliography{references.bib}
\bibliographystyle{iclr2025_conference}

\appendix
\input{appendix}


\end{document}
