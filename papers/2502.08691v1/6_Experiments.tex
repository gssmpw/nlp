\section{Performance Evaluation}\label{sec:performances}

% Expected Conclusion: if you have enough LLM throughout, you can run as many agents as possible.

% Follow: \url{https://tsinghuafiblab.yuque.com/hhbywg/wg833b/qgmb4g194q7m2yrn} !!!

In this section, we will analyze the performance of our proposed large-scale social simulator through a series of comprehensive experiments in order to reveal its strengths and limitations from different aspects.
The experiments focus on the following key research questions:
\begin{itemize}
    \item RQ1: What is the performance of the implementation of the societal environment?
    \item RQ2: What is the performance of the MQTT-powered agent messaging system compared to alternative communication approaches?
    \item RQ3: What is the performance of the large-scale social simulator built from the above components with LLM-driven agents?
\end{itemize}
All experiments were conducted on Huawei Cloud c7.16xlarge.4 cloud servers to ensure comparability of results.
To mitigate potential interference from rate-limiting effects inherent in LLM API calls during large-scale social simulator execution, we chosen the DeepSeek API platform\footnote{\url{https://platform.deepseek.com/}} that officially claims no request limit\footnote{\url{https://api-docs.deepseek.com/quick_start/rate_limit}}.
Related experiments were specifically scheduled during DeepSeek's off-peak hours (05:00-07:00 local time) to maximize the LLM API throughput.
According to a DeepSeek website statement, the model used during the experiments was DeepSeek-V3~\cite{liu2024deepseek}.

In the following content, we will present the experimental settings, results, and further discussion to address RQ1 in Section~\ref{sec:perf:env}.
Those about RQ2 will be discussed in Section~\ref{sec:perf:mess}.
Finally, in Section~\ref{sec:perf:sim}, we will conduct detailed experiments to answer RQ3.

\subsection{Societal Environment Performance}\label{sec:perf:env}

% One Sentence to start
To evaluate the interaction performance with our simulation environment, we conducted a series of experiments to show our environment is able to handle high concurrency tasks from massive agents.

\textbf{Experimental Settings.}
% Talk about the experimental settings.
We utilized the Social Environment Simulator tool-chain to generate varying numbers of individuals: 1,000, 10,000, 100,000, and 1,000,000, as the specific load for the simulator itself. The departure times of these individuals were distributed according to a typical weekday pattern, and all simulations were set starting from the morning peak hour of 8:30.

The test queries were divided into setting queries and fetching data queries at a ratio of 1:999, meaning one setting query after 999 steps of fetching query for each agent. This ratio was chosen because it is close to the actual request distribution in real agent simulations with our framework.
We limited the maximum number of Social Environment Simulator processes from 2, 4, 8, 16, to 32.
Each experimental setup was repeated five times, lasting for 10 seconds, with queries per second ranging from \(10^2\) to \(10^5\).

\textbf{Performance Metrics.} 
% Talk about the metrics used to evaluate performance IF NEEDED.
We conducted two experiments to evaluate our environment simulation performance. 
First, we measured the simulation speed with the metric of calculating the time consumption per simulation step, with the simulation time set to 24 hours.
Second, we assessed concurrency performance by measuring the increase in queries per second (qps) along with the change in time consumption per simulation step.

\textbf{Evaluation Results.} 
% Show figures and give some discussion.
The result of simulation speed is shown in Table \ref{tab:mean_sd_perf}.
The results indicate that even as the number of individuals and query rates increased significantly, performance degradation was minimal, suggesting that our platform can effectively and timely handle massive interactions between agents and the simulation platform.

\begin{table}[ht]
\caption{Mean time per step with different numbers of agents.}
\hspace*{-1cm}
\centering
\begin{tabular}{ccc}
\toprule
\textbf{\# of Agents} & \textbf{Mean Time per Step (s)} $\pm$ \textbf{SD} \\
\midrule
$10^3$ & 8.578$\times 10^{-3} \pm 3.0\times 10^{-5}$ \\
$10^4$ & 9.129$\times 10^{-3} \pm 1.5\times 10^{-5}$ \\
$10^5$ & 1.800$\times 10^{-2} \pm 5.66\times 10^{-4}$ \\
$10^6$ & 0.1680 $\pm$ 5.34$\times 10^{-4}$ \\
\bottomrule
\end{tabular}
\label{tab:mean_sd_perf}
\end{table}

% One sentence to conclude
In conclusion, the simulation environment is capable of supporting extensive interactions without significant degradation, making it solid for large-scale social simulations.

\subsection{Agent Messaging System Performance}\label{sec:perf:mess}

To validate the comparative advantages of MQTT over other messaging systems, we evaluated various commonly used publish/subscribe systems or message queue systems, including Redis, RabbitMQ, and Kafka.

\textbf{Experimental Settings.} To simulate real-world usage as closely as possible and comprehensively evaluate the systems' capabilities in terms of supported agent count and message throughput, we designed the following experimental procedure.
We assumed a total of 100,000 agents, with each message containing 100 bytes of data.
Each agent sends messages to 10 randomly selected agents.
Given the maximum available CPU cores are limited to 32, we selected parallel process counts from \{2, 4, 8, 16, 32\} and reported the configuration achieving peak throughput.
As simulator startup time constitutes a small proportion of total simulation duration, initialization overhead was excluded from measurements.
We specifically recorded the time interval between message transmission initiation and complete reception to calculate message throughput across different systems.

\textbf{Compared Approaches.} We briefly introduce the comparative methods as follows:
\begin{itemize}
    \item \textbf{Redis Pub/Sub\footnote{\url{https://redis.io/}}:} A lightweight in-memory publish/subscribe subsystem in Redis optimized for real-time messaging with minimal latency.
    It uses a broadcast model where messages are transient and not persisted, making it suitable for ephemeral data or scenarios requiring high-speed communication.
    However, its lack of message durability and limited scalability in high-volume environments may constrain its use in mission-critical applications.
    \item \textbf{RabbitMQ\footnote{\url{https://www.rabbitmq.com/}}:} A robust message broker implementing the AMQP (Advanced Message Queuing Protocol) standard.
    It supports complex routing logic, message persistence, and acknowledgment mechanisms, ensuring reliable delivery.
    Its flexible exchange types (e.g., direct, topic, fanout) and queue management make it ideal for enterprise workflows, though its overhead increases with transactional guarantees.
    \item \textbf{Kafka\footnote{\url{https://kafka.apache.org/}}:} A distributed streaming platform designed for high-throughput, fault-tolerant, and persistent log-based messaging.
    Kafka organizes data into partitioned topics, enabling horizontal scalability and parallel processing.
    Its append-only log structure and consumer offset tracking make it well-suited for large-scale event streaming, real-time analytics, and data pipelines, though it introduces complexity for lightweight use cases.
\end{itemize}
It is worth noting that all services are running on the experimental machine, and the distributed version is not utilized.

\textbf{Evaluation Methods and Metrics.}
In the evaluation of a messaging system, the most critical metric is throughput, which refers to the number of messages that can be transmitted per second.
Once the throughput meets the requirements, we will further consider whether the software system provides user-friendly auxiliary tools to help monitor the service’s operational status or facilitate testing and configuration, such as dashboards.
For throughput requirements, assuming all agents are always attempting to communicate with other agents and the LLM generates a message every 5 seconds, the minimum throughput the system needs to support would be 20,000 msg/s.

\textbf{Evaluation Results.} We conducted five tests on various messaging systems and calculated the mean and standard deviation of throughput, as presented in Table~\ref{tab:mes}.
From the results, we observe that MQTT, Redis Pub/Sub, and RabbitMQ meet the throughput requirements under the aforementioned extreme conditions.
Among them, RabbitMQ's performance was only slightly above the throughput requirement, thus it was the first to be excluded.
The results for Kafka were not reported because it could not even complete the initialization of 100,000 agents within 5 minutes; hence, no specific test results were available.
Although MQTT's throughput is approximately half that of Redis Pub/Sub, its built-in GUI tools can effectively assist users in simple service monitoring, debugging, and testing, which constitutes the primary reason for our ultimate selection of MQTT as the default implementation for the agent messaging system.
Regarding Redis Pub/Sub's high-performance characteristics, we propose that the simulation engine should support flexible user specification of backend implementations for agent messaging systems in the future, thereby accommodating application scenarios with stringent requirements for inter-agent communication.

\begin{table}[htbp]
\small
\centering
\caption{Comparison of different messaging systems.}
\label{tab:mes}
\begin{tabular}{lccc}
\toprule
\textbf{System} & \textbf{Best Parallel Process Number} & \textbf{Throughput (msg/s)} & \textbf{Auxiliary Tools} \\
\midrule
MQTT (emqx v5.8.1) & 32     & $44,702.1 \pm 111.3$          & \textbf{Built-in GUI}                    \\
Redis Pub/Sub (v6.2) & 16   & $ 81,216.2 \pm 333.6 $             & -               \\
RabbitMQ (v4.0.5)   &  16  & $23,667.3 \pm 1,777.7$             & \textbf{Built-in GUI}     \\
% Kafka (v3.9.0)     &   -  & $\times$          & - \\
\bottomrule
\end{tabular}
\end{table}

\subsection{Social Simulator Performance}\label{sec:perf:sim}

% 想一想，要不要分成两个subsection

% One Sentence to start
% \textbf{Experimental Settings.} Talk about the experimental settings.
% \textbf{Performance Metrics.} Talk about the metrics used to evaluate performance IF NEEDED.
% \textbf{Evaluation Results.} Show figures and give some discussion.
% One sentence to conclude

To evaluate the scalability and efficiency of the proposed social simulation framework, we conducted a series of experiments designed to replicate the execution of large-scale intelligent agents under realistic conditions.

\textbf{Experimental Settings.}  
The experiments were conducted on a 64-core machine, with 32 cores allocated to running the environment and the remaining 32 cores dedicated to executing the simulation engine.Testing was performed during the system's low utilization period, while targeting simulation time intervals where agent activities were relatively high to ensure representative measurements.  

We evaluated the system throughput by simulating \{10\textsuperscript{3}, 10\textsuperscript{4}\} agents, The number of processes was varied as \{8, 16, 32\}.
% excluding non-agent entities such as firms and governments from the agent count. 
% and for each configuration, 
% the total time taken to complete five interaction rounds, total token usage (distinguishing input and output tokens), and the number of LLM API calls. Additionally, we measured the LLM API time cost distribution and the Environment API time cost distribution.

\textbf{Performance Metrics.}  
To evaluate the system’s performance, the following metrics were collected:
\begin{itemize}
    \item \textbf{Total execution time:} The total time required for all agents to complete five interaction rounds.  
    \item \textbf{Token usage statistics:} The total number of input and output tokens utilized during the simulation.  
    \item \textbf{LLM time cost distribution:} The distribution of response times for calls to the LLM API, providing insights into latency variability.  
    \item \textbf{Environment time cost distribution:} The distribution of response times for calls to the environment API, measured to evaluate internal system performance.  
\end{itemize}

\textbf{Evaluation Results.}  
The evaluation results are summarized in Table~\ref{tab:performance}, which demonstrates the system’s scalability as the number of agents increases and highlights the performance impact of distributed computing. Specifically, the table shows how performance metrics such as LLM call time and environment response time vary with different group configurations (8, 16, and 32).

Figure~\ref{fig:distribution_analysis} presents four distribution plots that illustrate key metrics in large-scale LLM interactions with 10k agents under varying group configurations. The first two plots, Figure~\ref{fig:input_tokens} and Figure~\ref{fig:output_tokens}, show the distributions of input and output tokens, respectively. These plots reveal that token usage patterns remain remarkably stable across different configurations, indicating that parallelization does not significantly alter the overall amount of data being processed. In contrast, Figure~\ref{fig:llm_api_response} shows the distribution of LLM API call times, revealing that the time required for API calls is more sensitive to the level of parallelization. Finally, Figure~\ref{fig:env_response} presents the environment time cost distribution, which illustrates how the environment’s responsiveness fluctuates with the number of groups.

\begin{table}[htbp]
    \centering
    \small
    \caption{Performance metrics for different configurations.}
    \label{tab:performance}
    \resizebox{\textwidth}{!}{
    \begin{tabular}{cccccccc}
        \toprule
        \multicolumn{5}{c}{\textbf{Parameters}} & \multicolumn{3}{c}{\textbf{Average Time Cost}} \\
        \midrule
        \textbf{\#Agents} & \textbf{\#Groups} & \textbf{LLM Calls} & \textbf{ITs (/call)} & \textbf{OTs (/call)} &  \textbf{All (s/round)} & \textbf{LLM (s/call)} & \textbf{Env (ms/call)}\\
        \midrule
        $10^3$ & 8  & 4803.0 & 430.04 & 79.17 & 82.45 & 4.51 & 12.26 \\
        $10^3$ & 16 & 3120.8 & 398.78 & 77.18 & 41.17 & 2.92 & 14.31 \\
        $10^3$ & 32 & 4790.4 & 412.82 & 75.56 & 43.30 & 2.94 & 9.55 \\
        \midrule
        $10^4$ & 8  & 54135.4 & 430.35 & 75.84 & 5681.18 & 52.54 & 33.55  \\
        $10^4$ & 16 & 54002.2 & 430.24 & 75.80 & 1422.48 & 3.53 & 33.55 \\
        $10^4$ & 32 & 54075.0 & 430.47 & 76.14 & 458.82 & 8.05  & 30.53 \\
        \bottomrule
    \end{tabular}
    }
\end{table}


\begin{figure}[ht]
    \centering
    \begin{subfigure}[t]{0.45\textwidth}
        \centering
        \includegraphics[width=\linewidth]{Figure/input_tokens_dist.png}
        \caption{Input Token Distribution}
        \label{fig:input_tokens}
    \end{subfigure}
    % \hfill
    \begin{subfigure}[t]{0.45\textwidth}
        \centering
        \includegraphics[width=\linewidth]{Figure/output_tokens_dist.png}
        \caption{Output Token Distribution}
        \label{fig:output_tokens}
    \end{subfigure}
    \begin{subfigure}[t]{0.45\textwidth}
        \centering
        \includegraphics[width=\linewidth]{Figure/api_time_dist.png}
        \caption{LLM Time Cost Distribution}
        \label{fig:llm_api_response}
    \end{subfigure}
    \begin{subfigure}[t]{0.45\textwidth}
        \centering
        \includegraphics[width=\linewidth]{Figure/system_time_dist.png}
        \caption{Environment Time Cost Distribution}
        \label{fig:env_response}
    \end{subfigure}
    \caption{Distribution analysis for 10k agents.}
    \label{fig:distribution_analysis}
\end{figure}


The Average Time Cost analysis provides deeper insights into the system’s performance, as summarized in Table~\ref{tab:performance}. The total time per round (All) decreases as the number of groups increases, demonstrating the positive impact of parallelization on processing efficiency. This trend reflects the effectiveness of the distributed parallel framework, which optimally utilizes multi-core computational power, minimizing the CPU bottleneck and enabling the system to handle larger agent scales efficiently. However, the LLM time remains the primary bottleneck in the system, even under fully parallel conditions. Despite the reduction in execution time with more groups, LLM API calls still represent a significant portion of the total execution time. This is due to the nature of the external API calls, where server-side load introduces variability and causes unpredictable performance fluctuations. As shown in the evaluation results, the environment time (Env) remains minimal, in the millisecond range, which indicates that the system is capable of supporting large-scale simulations with minimal impact from the environment processing.

The experimental findings also highlight that the execution efficiency of large-scale agents is primarily constrained by the LLM API calls. Under fully parallel conditions, this constraint becomes more pronounced, making LLM performance a critical factor in scaling agent-based simulations. To achieve more stable operation for larger-scale simulations (e.g., >10\textsuperscript{4} agents), researchers may consider deploying a private LLM inference service. While this approach could offer more reliable performance, it comes with substantial initial costs, including GPU deployment and model configuration selection. The token distribution data in this study could serve as a reference for estimating GPU resources and model configurations required for such a deployment.

In conclusion, the experiments demonstrate the simulation engine’s ability to efficiently handle large-scale agent execution. However, the findings also emphasize the need for careful consideration of LLM API performance and the trade-offs involved in private deployment options. To improve stability and scalability, further research should focus on optimizing the LLM infrastructure or exploring alternative solutions for large-scale intelligent agent simulations.


\section{Exemplary Social Experiments}\label{sec:social_experiment}

\subsection{One Day Life}\label{sec:one_day_life}

% 使用一个人一个典型日的例子，分别用不同的颜色分别展示心理（情绪、认知、需求），社交、移动、经济行为（Yuwei）
\definecolor{needColor}{RGB}{255,0,0}        % 红色，代表需求
\definecolor{cogColor}{RGB}{128,0,128}     % Purple for cognition
\definecolor{mobilityColor}{RGB}{255,165,0}  % Orange for action
\definecolor{socialColor}{RGB}{204,0,102}    % 紫红色，代表社交
\definecolor{economyColor}{RGB}{0,153,0}     % 绿色，代表经济
\definecolor{otherColor}{RGB}{128,128,128}  % 灰色，代表其他行为

This section presents a self-directed day in the life of a socially intelligent agent, illustrating how it navigates daily tasks while balancing internal needs, emotional states, and cognitive processes. Through a simulated 24-hour scenario, we examine how the agent's dynamic priorities influence its decisions across three domains: mobility (e.g., route planning with energy constraints), social interaction (e.g., adapting communication style to context), and economic behavior (e.g., resource allocation under uncertainty). This micro-level analysis serves to validate the coherence of its behavioral patterns and their alignment with human-like temporal rhythms. The one day life journey for a specific person is shown as Tab.\ref{tab:onedaylife}.

By examining this one-day life scenario, we can see how the agent’s \textcolor{needColor}{needs} drive the formation of a plan and lead to specific actions (\textcolor{mobilityColor}{mobility}, \textcolor{socialColor}{social}, \textcolor{economyColor}{economy}, \textcolor{otherColor}{other}), all of which are continuously shaped by the agent’s \textcolor{cogColor}{cognition}. Through this table, the agent demonstrates behaviors that reflect realistic decision-making processes across various domains—managing its hunger, social connections, work responsibilities, and leisure. Such a framework helps researchers evaluate the consistency and depth of the agent’s behavior, providing a solid basis for exploring more complex social interactions and collective dynamics in virtual environments. Besides, Tab~\ref{tab:daily_interaction} summarizes the number of interactions between the social agent and various environmental spaces during a typical day.

\begin{table}[htbp]
    \centering
    \caption{Daily environment interactions per agent.}
    \begin{tabular}{l l l}
        \toprule
        \textbf{Space} & \textbf{Interaction Type}     & \textbf{Counts} \\
        \midrule
        \multirow{2}{*}{Urban Space}  & Get         & 465.67 \\
                                      & Set         & 4.27   \\\hline
        \multirow{2}{*}{Economy Space}& Get         & 9.26   \\
                                      & Set         & 3.30    \\\hline
        Social Space                & SendMessage & 9.08   \\\hline
        \textbf{Sum} & \textbf{ALL} & \textbf{491.68} \\
        \bottomrule
    \end{tabular}
    \label{tab:daily_interaction}
\end{table}

Based on the Social Agent's capability to simulate a one-day life, we further conducted simulation experiments in the domains of cognition, social interaction, economics, and mobility. These experiments were designed to validate the Social Agent's proficiency in capturing behaviors across various domains, as illustrated in Fig.\ref{fig:experiment_overview}.

\begin{figure}[ht]
    \centering
    \includegraphics[width=1\linewidth]{Figure/experiment.pdf}
    \caption{Experiment configuration overview.}
    \label{fig:experiment_overview}
\end{figure}

\begin{table}[htbp]
\caption{One Day Life}
\label{tab:onedaylife}
\centering
\begin{tabular}{|p{7cm}|p{6cm}|}
\hline
\textbf{Actions} & \textbf{Mind} \\
\hline

(08:00–12:30)
\begin{itemize}
\item \textcolor{mobilityColor}{Commute to office (Mobility)}
\item \textcolor{economyColor}{Respond to priority emails (Economy)}
\item \textcolor{economyColor}{Attend project planning meeting (Economy)}
\item \textcolor{economyColor}{Coordinate cross-department tasks (Economy)}
\end{itemize}
&
\begin{itemize}
\item \textcolor{needColor}{Need: Safe}
\item \textcolor{cogColor}{Emotion: Resentment}
\item \textcolor{cogColor}{Cognition: "Sequential task execution ensures workflow integrity"}
\end{itemize}
\\
\hline

(12:30–13:30)
\begin{itemize}
\item \textcolor{mobilityColor}{Commute via grocery store (Mobility)}
\item \textcolor{economyColor}{Compare product prices (Economy)}
\item \textcolor{otherColor}{Prepare lunch (Other)}
\item \textcolor{otherColor}{Eat (Other)}
\end{itemize}
&
\begin{itemize}
\item \textcolor{needColor}{Need: Hungry}
\item \textcolor{cogColor}{Emotion: Disappointment}
\item \textcolor{cogColor}{Cognition: "Economic constraints necessitate adaptive consumption patterns"}
\end{itemize}
\\
\hline

(13:30-14:00)
\begin{itemize}
\item \textcolor{mobilityColor}{Browse social networking sites (Social)}
\item \textcolor{socialColor}{Find friend to contact with (Social)}
\item \textcolor{socialColor}{Send message to friend (Social)}
\end{itemize}
&
\begin{itemize}
\item \textcolor{needColor}{Need: Social}
\item \textcolor{cogColor}{Emotion: Gratification}
\item \textcolor{cogColor}{Cognition: "Social capital accumulation facilitates opportunity discovery"}
\end{itemize}
\\
\hline

(14:00-18:00)
\begin{itemize}
\item \textcolor{economyColor}{Develop quarterly budget (Economy)}
\item \textcolor{otherColor}{Mentor junior staff (Other)}
\item \textcolor{mobilityColor}{Inspect branch office locations (Mobility)}
\item \textcolor{economyColor}{Submit audit report (Economy)}
\end{itemize}
&
\begin{itemize}
\item \textcolor{needColor}{Need: Safe}
\item \textcolor{cogColor}{Emotion: Relief}
\item \textcolor{cogColor}{Cognition: "Multi-layered verification prevents operational risks"}
\end{itemize}
\\
\hline

(18:00–20:00)
\begin{itemize}
\item \textcolor{mobilityColor}{Go back home (Mobility)}
\item \textcolor{otherColor}{Check refrigerator (Other)}
\item \textcolor{otherColor}{Prepare dinner (Other)}
\item \textcolor{otherColor}{Eat dinner (Other)}
\end{itemize}
&
\begin{itemize}
\item \textcolor{needColor}{Need: Hungry}
\item \textcolor{cogColor}{Emotion: Gratification}
\item \textcolor{cogColor}{Cognition: "Having finished the day's work, I was pleased with myself"}
\end{itemize}
\\
\hline

(20:00–22:00)
\begin{itemize}
\item \textcolor{otherColor}{Browse webpages(Other)}
\item \textcolor{otherColor}{Play video games(Other)}
\end{itemize}
&
\begin{itemize}
\item \textcolor{needColor}{Need: Whatever}
\item \textcolor{cogColor}{Emotion: Relief}
\item \textcolor{cogColor}{Cognition: "Entertainment makes me feel relaxed"}
\end{itemize}
\\
\hline

(22:00–24:00)
\begin{itemize}
\item \textcolor{otherColor}{Complete bedtime routine (Other)}
\item \textcolor{otherColor}{Go to sleep (Other)}
\end{itemize}
&
\begin{itemize}
\item \textcolor{needColor}{Need: Tired}
\item \textcolor{cogColor}{Emotion: Satisfaction}
\item \textcolor{cogColor}{Cognition: "Resource allocation efficiency impacts systemic stability"}
\end{itemize}
\\
\hline
\end{tabular}
\end{table}

\begin{figure}[htbp]
  \centering
  \newlength{\subimgsize}
  \setlength{\subimgsize}{0.45\linewidth}

  \begin{subfigure}[b]{\subimgsize}
    \includegraphics[width=\subimgsize, height=\subimgsize]{Figure/front1.jpg}
    \caption{Large-scale Simulation}
    \label{fig:suba}
  \end{subfigure}
  \hfill
  \begin{subfigure}[b]{\subimgsize}
    \includegraphics[width=\subimgsize, height=\subimgsize]{Figure/front2.jpg}
    \caption{Self-driven Daily Life}
    \label{fig:subb}
  \end{subfigure}
  
  \caption{Large-scale social simulation.}
  \label{fig:frontend}
\end{figure}


\subsection{Polarization}\label{sec:polarization}

% 极化的实验结果




% 第一段，实验背景，为什么研究极化很重要
Polarization is a phenomenon where opinions within a population become increasingly divided, often forming distinct clusters that are difficult to reconcile. Understanding polarization is critical because it influences how societies debate, make decisions, and implement solutions to pressing challenges. By studying the factors that drive polarization, researchers can uncover why divisions deepen over time and how they can be addressed. This research provides valuable insights into fostering more cohesive societies, promoting constructive dialogue, and navigating complex issues in a way that incorporates diverse perspectives.


% 中间，实验设计，画一张图说明实验的步骤
To investigate the dynamics of polarization, an experimental setting is designed to simulate discussions among agents focused on a specific policy issue: gun control. In the control group, agents engage in discussions about the gun control issue, with opinions naturally divided between support and opposition. No external interventions are introduced in this setting, allowing opinions to evolve organically through agents' autonomous social interactions. Two treatment groups are introduced to study the effects of persuasive messages on opinion dynamics. In one treatment group, agents are only exposed to persuasive messages that align with their existing opinions, which we refer to as the homophilic interaction group. In the other treatment group, agents only receive persuasive messages with opposing opinions, which is the heterogeneous interaction group. This experimental setup provides a ground to analyze how different opinions contribute to the formation of polarization.

% 最后一段，实验结果，每个结果一个图

\begin{figure}
    \centering
    \includegraphics[width=1\linewidth]{Figure/polarization.pdf}
    \caption{Opinion changes on the political issue of Gun Control across three experimental setups.}
    \label{fig:polarization}
\end{figure}

Figure~\ref{fig:polarization} presents the opinion changes on the political issue of Gun Control across three experimental setups: (a) the control group, (b) the homophilic interaction group, and (c) the heterogeneous interaction group. In the control group, where agents engage in discussions without external interventions, 39\% of agents adopt more polarized opinions, while 33\% become more moderate after interactions. By contrast, in the homophilic interaction group, a clear polarization pattern emerges, with 52\% of agents becoming more polarized. This result suggests the effect of echo chambers, where excessive interactions with like-minded peers can potentially intensify opinion polarization. In the heterogeneous interaction group, 89\% of agents adopt more moderate opinions, and 11\% are persuaded to adopt opposing viewpoints. This indicates that exposure to opposing content and opinions could be an effective mitigation strategy for curbing polarization.


\subsection{Spread of Inflammatory Messages}\label{sec:infl_message}
Information propagation in social networks is a fundamental research problem in social computing. Social networks enable users to share various types of content such as news, personal status updates and public discussions. Among these information flows, inflammatory messages containing extreme opinions and inaccurate claims present significant challenges. These messages can quickly spread across social networks and increase conflicts in online discussions. Standard information diffusion models cannot fully explain how inflammatory messages propagate~\cite{romero2011differences,brady2017emotion}, because user sharing behaviors often deviate from typical patterns when encountering such content. Additionally, current content moderation systems on social platforms face difficulties in balancing effective content filtering with maintaining regular user communications. Simulation experiments offer a practical approach to analyze these propagation dynamics and test different intervention methods, providing insights that complement real-world social network studies.

To investigate the spread of inflammatory messages, we design experiments based on a real-world event, the case of the chained woman in Xuzhou~\cite{gao2023s}. Using a population of hundreds of agents, our experiments consist of four parts. In the control group, we place non-inflammatory seed messages at selected nodes and observed the natural progression of information spread and emotional evolution within the group. For the experimental group, we introduce emotionally charged, selectively expressed inflammatory messages at certain nodes to examine whether these would alter the trajectory of information spread and emotional dynamics. To simulate the suppression of inflammatory messages, we implemented two intervention strategies: node intervention and edge intervention. In both approaches, the social platform monitors messages sent by agents, using large language models to determine if content is inflammatory. Under node intervention, accounts that repeatedly share harmful inflammatory content above a certain threshold are suspended. With edge intervention, when inflammatory content is detected traveling between two nodes, the social connection between them is permanently removed. We track how these interventions affect both information propagation patterns and the evolution of group emotions. Finally, we conduct interviews with agents to understand their motivations for sharing messages, helping us uncover the underlying psychological and social factors that drive information-sharing behavior when encountering inflammatory content.
\begin{figure}[ht]
    \centering
    \begin{subfigure}[t]{0.48\textwidth}
        \centering
        \includegraphics[width=\linewidth]{Figure/information_spread.pdf}
        \caption{Information Spread over Time}
        \label{fig:information_spread}
    \end{subfigure}
    \hfill % 添加一些水平间距
    \begin{subfigure}[t]{0.48\textwidth}
        \centering
        \includegraphics[width=\linewidth]{Figure/emotional_intensity.pdf}
        \caption{Emotional Intensity over Time}
        \label{fig:emotional_intensity}
    \end{subfigure}
    \caption{Simulation results of the spread of inflammatory messages.}
    \label{fig:social_curve}
\end{figure}

Our experimental results are shown in Figure~\ref{fig:social_curve}. The experimental results demonstrate distinct patterns in information propagation dynamics and emotional responses across different intervention strategies. Our findings validate that inflammatory messages exhibit unique diffusion characteristics compared to regular content in social networks. The experimental group, where inflammatory messages are introduced, shows substantially higher information reach than the control group with non-inflammatory content, confirming that inflammatory messages possess stronger viral potential in social networks. This observation aligns with previous findings about the deviation of inflammatory content from standard diffusion patterns~\cite{romero2011differences,brady2017emotion}.

The intervention strategies demonstrate varying degrees of effectiveness in managing inflammatory content spread. Node-level intervention, which suspends accounts that frequently share inflammatory content, proves to be the more effective approach in containing information propagation. Edge-level intervention, while showing moderate containment effects, is less efficient than node-based approaches. This difference suggests that targeting individual spreading behaviors might be more effective than modifying network structure for content moderation.

The emotional intensity measurements provide additional insights into the intervention dynamics. The experimental group exhibits markedly elevated emotional responses compared to the control group, indicating that inflammatory messages significantly amplify emotional engagement within the network. Node intervention demonstrates superior effectiveness in moderating these emotional responses, achieving substantial reduction in overall emotional intensity. Edge intervention, though less effective than node-based approaches, still shows notable moderation effects on emotional dynamics. 
\begin{figure}[ht]
    \centering
    \includegraphics[width=0.7\linewidth]{Figure/wordcloud_social.pdf}
    \caption{Agent opinions on the chained woman incident.}
    \label{fig:social_opinion}
\end{figure}

Interview analysis reveals key factors that drive inflammatory message sharing behavior, as shown in the word cloud in Figure~\ref{fig:social_opinion}. The responses mainly focus on emotional reactions and social responsibility. Analysis shows that strong emotions, especially sympathy and worry, often trigger sharing behaviors. Many agents share information because they feel they have a duty to let others know about important social issues. The interviews show that agents think about the broader social impact when sharing information, seeing it as a way to join public discussions. Agents also show clear goals in their sharing behavior, mainly wanting to increase public attention and get responses from institutions. These findings suggest that inflammatory message spread is driven by both emotional factors and social awareness. Understanding why agents share such messages helps us develop better content moderation strategies in social networks.

These experimental results demonstrate three key findings in inflammatory content management. First, inflammatory messages show stronger viral potential and trigger higher emotional responses compared to regular content. Second, node-level intervention is more effective than edge-level intervention in both containing information spread and moderating emotional intensity. Third, through agent interviews, we find that emotional factors and social responsibility drive sharing behaviors. These findings provide empirical evidence for designing content moderation systems, suggesting that user-level interventions combined with consideration of emotional and social factors may lead to more effective control of inflammatory content in social networks.
% 煽动性信息的实验结果

% 第一段，实验背景，为什么信息传播很重要
% 中间，实验设计，说明实验的步骤
% 最后一段，实验结果，每个结果一个图

\subsection{Universal Basic Income}\label{sec:ubi}

% UBI实验结果

% 第一段，实验背景，为什么ubi很重要
% 中间，实验设计，画一张图说明实验的步骤
% 最后一段，实验结果，每个结果一个图

Universal Basic Income (UBI) has always been a highly controversial macroeconomic policy. The implementation cost of UBI is enormous, and the outcomes of UBI policies around the world have shown inconsistent effects on both the participants and economic development. Therefore, accurately understanding the impact of UBI on the socio-economic environment and its underlying reasons is crucial in determining whether UBI policies should be implemented in the real world to alleviate poverty. Based on our simulation platform, we conduct intervention experiments on UBI and explore its effects on both agents and the macroeconomics.

We conduct two macroeconomic simulations based on the demographic distribution of residents in cities that have implemented UBI policies (Texas, USA). One simulation is without the UBI policy, while the other incorporates UBI intervention, where each agent is given a monthly unconditional payment of \$1,000. By comparing the economic and social metrics generated from both simulations, we explore the impact of the UBI policy and assess whether these influence align with the outcomes observed in Texas' UBI social experiment.

The basic simulation results are shown in the Figure \ref{fig:econ_curve}, including the simulated curves of real GDP and agent consumption levels. As can be seen, as the simulation progresses, the fluctuations in the curves become smaller, indicating that the economic system is stabilizing.

\begin{figure}[ht]
    \centering
    \begin{subfigure}[t]{0.47\textwidth}
        \centering
        \includegraphics[width=\linewidth]{Figure/real_gdp_curve.pdf}
        \caption{Real GDP}
        \label{fig:gdp}
    \end{subfigure}
    \hfill % 添加一些水平间距
    \begin{subfigure}[t]{0.50\textwidth}
        \centering
        \includegraphics[width=\linewidth]{Figure/consumption_curve.pdf}
        \caption{Consumption Level}
        \label{fig:consumption}
    \end{subfigure}
    \caption{Simulation results of the economic system.}
    \label{fig:econ_curve}
\end{figure}

We introduce the UBI policy at step 96 of the simulation and compare the economic and social metrics of the two simulation results over the next 24 steps in Figure \ref{fig:econ_bar}, namely agent consumption levels and depression levels, with depression levels assessed through surveys using the widely recognized Center for Epidemiologic Studies Depression Scale (CES-D)~\cite{radloff1991use}. The comparison shows that the UBI policy increases consumption levels and reduces depression levels, which is similar to the impact observed in Texas' UBI policy~\cite{bartik2024impact}, thus validating the realism of the simulation.

\begin{figure}[ht]
    \centering
    \begin{subfigure}[t]{0.48\textwidth}
        \centering
        \includegraphics[width=\linewidth]{Figure/consumption.pdf}
        \caption{Consumption Level}
        \label{fig:gdp}
    \end{subfigure}
    \hfill % 添加一些水平间距
    \begin{subfigure}[t]{0.48\textwidth}
        \centering
        \includegraphics[width=\linewidth]{Figure/depression.pdf}
        \caption{Depression Level}
        \label{fig:depression}
    \end{subfigure}
    \caption{The comparison of economic and social metrics.}
    \label{fig:econ_bar}
\end{figure}

We also interview agents about their views on the UBI policy, which are summarized in the word cloud in Figure \ref{fig:ubi_opinion}. The results show that the impact of the UBI policy is mainly related to key terms such as interest rates, long-term benefits, savings, and necessities of life, reflecting the common perceptions of UBI policy in the real world.

\begin{figure}[ht]
    \centering
    \includegraphics[width=0.7\linewidth]{Figure/opinions.pdf}
    \caption{Agent opinions on UBI policy.}
    \label{fig:ubi_opinion}
\end{figure}

\subsection{External Shocks of Hurricane}\label{sec:hurricane}

% 外部灾害的实验结果
% 第一段，实验背景，为什么外部灾害很重要
% 中间，实验设计，画一张图说明实验的步骤
% 最后一段，实验结果，每个结果一个图

The impact of external disasters on human mobility is a critical area of study due to their profound effects on societal structures and individual behaviors. Understanding how such events influence human movement patterns is essential for enhancing emergency response strategies and mitigating potential risks.
Hurricanes, as severe natural disasters, pose significant threats to human life and property. The destruction of infrastructure, displacement of populations, and disruption of daily activities necessitate a comprehensive understanding of human mobility during such events. 

The experiment focuses on Hurricane Dorian, which impacted the southeastern United States in 2019. The city of Columbia, South Carolina, serves as the primary case study due to its significant population density and the availability of detailed mobility data.
The analysis utilizes two primary data sources:

\begin{itemize}
    \item \textbf{SafeGraph Data\footnote{\url{https://www.safegraph.com/}}:} Provides comprehensive information on points of interest (POIs) and human mobility patterns (from 2019.8.28 - 2019.9.5).
    \item \textbf{Census Block Group (CBG) Data\footnote{\url{https://docs.safegraph.com/docs/open-census-data}}:} Offers demographic profiles of residents, facilitating the sampling of city residents' profiles (including gender, age, race, income, home cbg, etc.).
\end{itemize}

These datasets are integrated to model and analyze the movement behaviors of social agents during the hurricane event.

Specifically, the experiment involves 1,000 social agents, and incorporates real-time weather updates to influence agent behaviors, thereby reflecting the dynamic nature of human responses to the hurricane. We evaluate mobility patterns through two metrics:  
1) \textbf{Activity Level} ($\frac{\text{Traveling Individuals}}{\text{Area Population}}$), visualized through three phase-specific maps. The results are shown as Fig.\ref{fig:activity_phases}.
2) \textbf{Total Daily Trips} (9-day normalized time-series). The result is shown as Fig.\ref{fig:trip_ts}.

According to Fig. \ref{fig:activity_phases}, the hurricane significantly impacts the mobility behavior of the social agent. Before the hurricane, the average activity level (defined as the ratio of travelers to the total population) across the CBGs remained between 70\% and 90\%. However, when the hurricane arrived, the activity level sharply decreased to approximately 30\%, indicating a significant reduction in mobility behavior. After the hurricane passed, the activity level gradually returned to normal levels. This analysis suggests that the social agent could adapt its mobility demand effectively based on environmental information, mimicking human behavior in response to extreme weather events.

% Activity Level Subplots
\begin{figure}[htbp]
    \centering
    \newlength{\activitysize}
      \setlength{\activitysize}{0.3\linewidth}
    
      \begin{subfigure}[b]{\activitysize}
        \includegraphics[width=\activitysize]{Figure/activity_stage_1.png}
        \caption{Before landfall (8.28-8.30)}
        \label{fig:suba}
      \end{subfigure}
      \hfill
      \begin{subfigure}[b]{\activitysize}
        \includegraphics[width=\activitysize]{Figure/activity_stage_2.png}
        \caption{Landfall (8.31-9.2)}
        \label{fig:subb}
      \end{subfigure}
      \hfill
      \begin{subfigure}[b]{\activitysize}
        \includegraphics[width=\activitysize]{Figure/activity_stage_3.png}
        \caption{After landfall (9.3-9.5)}
        \label{fig:subb}
      \end{subfigure}
    \caption{Activity level spatial distributions.}
    \label{fig:activity_phases}
\end{figure}

The line graph presented above (Fig. \ref{fig:trip_ts}) compares the daily outflow patterns of the real data with the simulated visits over the course of the experiment. Both the real and simulated data exhibit similar trends, with a noticeable decline in visit activity around August 30th, corresponding to the onset of the hurricane impact, followed by a significant recovery in early September. Notably, while the simulated visits closely follow the general trend of the real data, slight deviations are observed, particularly during the hurricane's peak. This suggests that the social agent's behavior, while generally aligned with actual human patterns, may exhibit some discrepancies in terms of the magnitude and speed of response. However, the overall similarity in the temporal progression of visits indicates that the simulation captures key aspects of human mobility under the influence of extreme weather events, validating the social agent's effectiveness in approximating real-world behavior.

% Trip Volume Time-Series
\begin{figure}[htbp]
    \centering
    \includegraphics[width=0.8\textwidth]{Figure/date_out.png}
    \caption{Normalized daily trips.}
    \label{fig:trip_ts}
\end{figure}

The results effectively demonstrate that the constructed social agents, within the framework of the social simulator, can accurately replicate human mobility behaviors and group characteristics during a hurricane event. This validation underscores the simulator's potential as a tool for analyzing and understanding human responses to external shocks, thereby contributing to improved disaster preparedness and response strategies.
