\section{Literature Review}
\label{sec:Literature_Review}

    We will now set out to answer the following research question. 
    
    \begin{enumerate}[label=\textbf{RQ\arabic*}:, left=2em]
        \item \textit{What problems have researchers applied Machine Unlearning to?}
    \end{enumerate}
    
    Likewise, we will provide an unfettered description of both the problem formulation and corresponding Machine Unlearning solutions for various works. If a selected paper doesn't lend itself to being summarized in the previously delineated way, then we will provide a commentary on how its content benefits the study. In performing this step, we hope to situate our study within the current body of relevant literature. To this end, we will query the corpora--\textit{IEEE Xplore}, \textit{ACM Digital Library}, and \textit{Google Scholar}--with the string \texttt{\say{Machine Unlearning} AND \say{Application}}.
    
    \subsection{Cao2015}
    \label{subsec:Cao2015}
    
        The researchers chose four real-world, Machine Learning systems--\textit{LensKit} (a media recommendation system), \textit{Zozzle} (a malware detector), \textit{OSNF} (a spam filter), and \textit{PJScan} (a PDF malware detector)--and revised them to incorporate unlearning. They analytically evaluated their algorithmic revision by quantifying the completeness of unlearning and the timeliness of the process. The crux of the study is determining the ease of adapting existing Machine Learning systems to support unlearning. It demonstrates that not every Machine Learning algorithm can be converted to realize unlearning. This is unfortunate as unlearning, or forgetting systems in general, aim to restore privacy, security, and usability ____.
    
    \subsection{WangkunXu2024}
    \label{subsec:WangkunXu2024}
    
        This paper introduces a Machine Unlearning algorithm for a load forecasting model to eliminate the influence of data that is adversarial or contains sensitive information of individuals. 
        
        To balance between unlearning completeness and model performance, \textit{PAMU}, a performance-aware Machine Unlearning algorithm, is proposed by evaluating the sensitivity of local model parameter change using influence function and sample re-weighting. To handle the divergence between statistical and task-aware criteria, the authors propose \textit{TAMU}, task-aware Machine Unlearning ____.
        
        The key takeaway from this work is the idea of Adversarial Machine Learning, or data poisoning, being a strong motivating factor for Machine Unlearning outside of the obvious compulsion of seeking heightened privacy.
    
    \subsection{Hu2024}
    \label{subsec:Hu2024}
    
        The authors perform an investigation to study to what extent Machine Unlearning methods can partially or fully leak the data of unlearned information. The researchers propose unlearning attacks that, when given access to the original and unlearned models, can reveal the feature and label information of the unlearned data. Their attack extends to both approximate and exact unlearning methods, which directly relates to our intended study. The paper provides sufficient evidence that while Machine Unlearning is invaluable to preserving privacy, it too can be leveraged to thwart privacy. This is especially relevant if uncovered features, as unearthed in the attack demonstrated in the paper, contain personally identifiable information ____.
    
    \subsection{Zhang2024}
    \label{subsec:Zhang2024}
    
        The researchers propose a framework for protecting the deletion rights of dataset owners in Machine Unlearning scenarios. \textit{DuplexGuard} makes use of duplex watermarks, or a set of two watermarks, that allow the framework to signify potential dataset usage statuses. Watermarking, or backdoor watermarking, is commonly used for dataset inference to prove its legitimate ownership by means of making the model memorize specific information other than that from the normal samples, and then use this knowledge for verification afterward ____.
        
        The most compelling contribution of this work is \textit{DuplexGuard}'s ability to verify the unlearning effect of the target model after a data deletion request is issued. It is one thing to claim that a Machine Unlearning implementation deletes elements as requested, but it is far more important to ensure the effect of the removal cascades throughout the affected model. It could be argued that the verification aspect of Machine Learning is inseparable from the approach, for what use does a deletion request serve if it does not achieve some modicum of privacy?
    
    \subsection{Lin2023}
    \label{subsec:Lin2023}
    
        The researchers construct an experiment that makes use of \textit{DaRE}, which we have indicated as a suitable Machine Unlearning implementation for our own study. The authors provide insights into its capabilities, which, again, proves beneficial for our current endeavors. The paper describes \textit{DaRE} like so. \textit{DaRE} only supports binary classification tasks and uses a simple model that considers all trees independently.
        
        The authors juxtapose \textit{DaRE}'s failings with their improved Machine Unlearning implementation: Gradient-Boosting Decision Trees (\textit{GBDT}) with Machine Unlearning functionality. Their \textit{GBDT} model interweaves dependencies within the trees, which, from their results, can lead to superior unlearning performance ____.
    
    \subsection{Tarun2023}
    \label{subsec:Tarun2023}
    
        The text delves into the \textit{UNSIR} method, or unlearning by selective impair and repair, that thrives in a zero-glance privacy setting. A zero glance setting is one where data samples of the requested unlearning class is either not available or can not be used, which the authors posit has practical real-world applications. The problem that they address is the use-case of unlearning as it pertains to facial recognition. The results seem to support that the \textit{UNSIR} method can make a trained model efficiently forget a single face or multiple faces without glancing at the samples of the unlearning faces ____.
        
        This strict, self-imposed problem formulation confers greater privacy guarantees, as it assumes that the model owner no longer has access to the material requested for removal. The study not only operates under the assumption of absolute inaccessibility but also ensures that their implementation executes as if it is an iron-clad fact. This is especially desirable given the potential fallout of highly sensitive information.
    
    \subsection{Schelter2021}
    \label{subsec:Schelter2021}
    
        The study examines the problem of low-latency Machine Unlearning, which is concerned with maintaining a deployed ML model in place under the removal of a small fraction of training samples without retraining. The researchers proposed a classification model called \textit{HedgeCut} for this setting, which is based on an ensemble of randomized decision trees ____.
        
        \textit{HedgeCut}, much like \textit{DaRE}, was one of the few Machine Unlearning implementations with open-source code that we found during our scouring of literature. Given how both deal with ensemble methods, with the former working with Extremely Randomised Trees (\textit{ERTs}) and the latter with standard trees. Our decision to prioritize the use of \textit{DaRE} over \textit{HedgeCut} came down to a simple cost-benefit analysis. The learning curve of picking up \textit{DaRE} over \textit{HedgeCut} was smaller, ergo we went with \textit{DaRE}. Despite our determination, we would be remiss not to mention other Machine Unlearning alternatives.
    
    \subsection{Juliussen2023}
    \label{subsec:Juliussen2023}
    
        To visually represent our study's usage of Naive Retraining and Exact Unlearning via Sharding, Isolation, Slicing, and Aggregation (SISA), we provide suitable figures that encapsulate each process. Note that the author's usage of \say{Exact Unlearning} corresponds to our definition of \say{Naive Retraining}, whereas \say{Sharded, Isolated, Sliced, and Aggregated Training} align with our characterization of \say{Exact Unlearning via Sharding, Isolation, Slicing, and Aggregation (SISA)}. In any case, we attribute our usage of the two figures to their rightful owners; they elegantly capture our topic of discussion in easily interpretable diagrams.
        
        \begin{figure}[H]
            \centering
            \includegraphics[width=1\linewidth]{Juliussen2023_Figure_01.png}
            \caption{____'s Depiction of Naive Retraining}
        \end{figure}
        
        \begin{figure}[H]
            \centering
            \includegraphics[width=1\linewidth]{Juliussen2023_Figure_02.png}
            \caption{____'s Depiction of Exact Unlearning via SISA}
        \end{figure}

    \subsection{Chen2025}
    \label{subsec:Chen2025}

        While Machine Unlearning holds promise as a technique to enhance privacy and data control, the authors identify several potential avenues for misuse by malicious actors ____. These include:
        
        \begin{enumerate}[label=(Atk. \arabic*):, left=2em]
            \item \textbf{Misclassification Attacks}: Adversaries manipulate unlearning to cause misclassifications of target samples.
            \item \textbf{Adversarial Robustness Attacks}: Adversaries exploit unlearning to weaken model robustness against adversarial examples.
            \item \textbf{Backdoor Injection Attacks}: Adversaries inject \textit{backdoors} (a poisoned, adversarially crafted data point that alters a model's predictions when a specific trigger is present in its input data) in unlearned models by submitting malicious unlearning requests.
            \item \textbf{Fairness Attacks}: Adversaries craft unlearning sets to introduce bias and discrimination in unlearned models.
            \item \textbf{Explanation Attacks}: Adversaries exploit unlearning to invalidate previously generated model explanations.
            \item \textbf{Running Time Attacks}: Adversaries attack unlearning algorithms to increase the cost of erasing certain requests.
        \end{enumerate}
        
        While the promise of Machine Unlearning is alluring, it would be irresponsible to present an overly \say{rosy} depiction without acknowledging its potential pitfalls. Like any emerging technology, Machine Unlearning carries both merits and demerits that must be carefully weighed.