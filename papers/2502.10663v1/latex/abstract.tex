\begin{abstract}
    Recent advancements in text-to-image (T2I) generation models have transformed the field. However, challenges remain in generating images that reflect demanding textual descriptions, especially for fine-grained details and unusual relationships. Existing evaluation metrics focus on text-image alignment but overlook the realism of the generated image, which can be crucial for downstream applications like data augmentation in machine learning. To address this gap, we propose \name, an automatic evaluation framework that assesses realism of T2I outputs along three dimensions: fine-grained visual attributes, unusual visual relationships, and visual styles. \name achieves a Spearmanâ€™s $\rho$ score of up to 0.62 in alignment with human judgment and demonstrates utility in ranking and filtering augmented data for tasks like image captioning, classification, and visual relationship detection. Empirical results show that high-scoring images evaluated by our metrics improve F1 scores of image classification by up to 11.3\%, while low-scoring ones degrade that by up to 4.95\%. We benchmark four major T2I models across the realism dimensions, providing insights for future improvements in T2I output realism.
\end{abstract}