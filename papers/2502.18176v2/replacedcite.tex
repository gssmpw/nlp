\section{Related Work}
\textbf{Zero-Shot Image Classification.}
Unlike traditional models that are limited to predefined categories, vision-language models (VLMs) are trained on open-vocabulary data and align the embeddings of images and their captions into a common semantic space. This enables them to perform as zero-shot classifiers by matching the semantics of images to textual categories, offering superior generality and flexibility. CLIP ____, trained on extensive internet image-text pairs, achieves advanced results in zero-shot classification tasks. Additionally, other VLMs including Stable Diffusion ____, Imagen ____, and DaLLE-2 ____ also possess zero-shot classification capabilities ____.

\textbf{Adversarial Purification in Pixel Space.}
A prevalent paradigm of adversarial purification aims to maximize the log-likelihood of samples to remove perturbations in pixel space. Since purification has no assumption of the attack type, enabling it to defend against unseen attacks using pre-trained generative models such as PixelCNN ____, GANs ____, VAEs ____, Energy-based models ____, and Diffusion Models ____. Owing to the capability of diffusion models, diffusion-based adversarial purification achieves state-of-the-art robustness among these techniques.



\textbf{CLIP-based Defense.}
While CLIP achieves impressive accuracy in zero-shot classification, it remains vulnerable to imperceptible perturbations ____. Adversarially training the CLIP model on ImageNet / Tiny-ImageNet ____ enhances its robustness but undermines its zero-shot capabilities and struggles against unseen attacks. ____ suggests smoothing techniques for certification. ____ advocates using robust prompts for image classification, but the defensive effectiveness is limited. Additionally, other research focuses on the out-of-distribution (OOD) robustness of the CLIP model ____, which is orthogonal to our adversarial defense objectives.

%