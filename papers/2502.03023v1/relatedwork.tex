\section{Related Works}
\label{sec:related_work}

% cp -> parameter tuning in cp -> our gap 
\paragraph{Conformal prediction}
Conformal prediction is a method for uncertainty quantification that ensures that the prediction intervals or sets cover the true label with a user-defined error rate~\citep{papadopoulos2008inductive, vovk2005algorithmic, vovk2012conditional}. 
% It could be used for regression~\citep{lei2018distributionfree} and classification~\citep{sadinle2019least}. 
On the one hand, conditional coverage validity is a key property of conformal prediction, ensuring the algorithm fairness~\citep{angelopoulos2021uncertainty, gibbs2024conformal, romano2020classification,huang2024conformal}.
On the other hand, to enhance the efficiency of conformal prediction, recent studies~\citep{liu2025cadapter, stutz2022learning, kiyani2024length, kiyani2024conformal} have proposed training-based methods, which could be regarded as adapters, performing tuning prior to conformal prediction.
Beyond these, with many non-conformity scores proposed, the score selection or aggregation is another challenge in conformal prediction~\citep{yang2024selection, luo2024weighted, fan2024utopia, gasparin2024conformal, ge2024optimal, qin2024sat}.
These recent paradigms of conformal prediction typically require tuning some parameters on a hold-out dataset, and our work provides the first study to quantify the negative effect induced by using the same dataset for tuning and calibration.
% Though a great deal of work has been researched for efficiency or (conditional) coverage validity, the tuning bias of parameter tuning in conformal prediction is still an open problem. 


% PAC and learnability of cp 1) PAC 2) 引出 CP 使用 3） our work uses PAC 
\paragraph{Learnability}
As classical learnability theory, a learnable model could be regarded as a risk minimization model with a specific hypothesis class~\citep{vapnik1971uniform,vapnik1991principles,vandervaart1996weak, vapnik1999overview, vershynin2018highdimensional}.
And further, the constrained risk minimization model is developed as a special case of learnability theory, where the hypothesis class is the set with a specific constraint or structure, such as structural risk minimization of character recognition~\citep{guyon1991structural}, of data-dependent hypothesis class~\citep{shawe-taylor1998structural}, of Rademacher penalty method~\citep{koltchinskii2001rademacher} and rough set-based classifier~\citep{liu2020structural}.
As for conformal prediction, several works study learn the conformal prediction directly by designing a specific objective function~\citep{stutz2022learning, noorani2024conformal}. 
Further, the conformal prediction is a special case of risk minimization problem with the constraint of coverage guarantee, and the generalization loss for the size of prediction set could be quantified~\citep{gupta2022nested, yang2024selection}, including classification~\citep{bai2022efficient} and regression~\citep{gupta2022nested, fan2024utopia}.
As we proposed in~\cref{sec:theoretical_results}, we interpret the tuning bias as a further constrained risk minimization problem of conformal prediction and provide the first theoretical analysis of the tuning bias.
% In this work, we interpret the tuning bias as a further constrained ERM problem of conformal prediction. 
% In this work, we are the first to interpret the tuning bias as a further constrained ERM problem of conformal prediction.

% The issue of tuning bias could also be interpreted as a special case of learnability, where the hypothesis class is the set of all possible indicator functions that score below the thresholds with transformation parameters.
% Though a great deal of work has been done on learnability in conformal prediction, the research on learnability in tuning bias remains blank.