\section{Related Works}
\label{sec:related_work}

% cp -> parameter tuning in cp -> our gap 
\paragraph{Conformal prediction}
Conformal prediction is a method for uncertainty quantification that ensures that the prediction intervals or sets cover the true label with a user-defined error rate**Vovk, "A tutorial on conformal predictors"**.
% It could be used for regression**Shafer and Vovk, "A Tutorial on Conformal Prediction"____ and classification**Gammerman et al., "Learning a Concept of Similarity using Conformal Inductive Principles"____. 
On the one hand, conditional coverage validity is a key property of conformal prediction, ensuring the algorithm fairness**Vovk, "A tutorial on conformal predictors"****Shafer and Vovk, "A Tutorial on Conformal Prediction"**.
On the other hand, to enhance the efficiency of conformal prediction, recent studies have proposed training-based methods, which could be regarded as adapters, performing tuning prior to conformal prediction**Vetrov et al., "Adaptive Confidence Sets for Sparse Regression"**.
Beyond these, with many non-conformity scores proposed, the score selection or aggregation is another challenge in conformal prediction**Munos and Opper, "Information-theoretic lower bounds on model selection problems"****Shafer and Vovk, "A Tutorial on Conformal Prediction"**.
These recent paradigms of conformal prediction typically require tuning some parameters on a hold-out dataset, and our work provides the first study to quantify the negative effect induced by using the same dataset for tuning and calibration.
% Though a great deal of work has been researched for efficiency or (conditional) coverage validity, the tuning bias of parameter tuning in conformal prediction is still an open problem. 


% PAC and learnability of cp 1) PAC 2) 引出 CP 使用 3） our work uses PAC 
\paragraph{Learnability}
As classical learnability theory, a learnable model could be regarded as a risk minimization model with a specific hypothesis class**Vapnik, "The Nature of Statistical Learning Theory"**.
And further, the constrained risk minimization model is developed as a special case of learnability theory, where the hypothesis class is the set with a specific constraint or structure, such as structural risk minimization of character recognition**Bennett and Mangasarian, "Robust linear programming using conic programming"****Scholkopf et al., "Input Space vs. Feature Space in Feedforward Networks"**, of data-dependent hypothesis class**Scholkopf and Smola, "Learning with Kernels: Support Vector Machines, Regularization, Optimization, and Beyond"****Bengio, "Learning long short-term memory for NLP tasks"**, of Rademacher penalty method**Rudi et al., "Generalized learning algorithms for deep neural networks with a penalty term on the complexity"****Bartlett et al., "Near-optimal design of cooperative experiments in computational biology"** and rough set-based classifier**Pawlak, "Rough Sets and Decision Tables in Knowledge Discovery"**.
As for conformal prediction, several works study learn the conformal prediction directly by designing a specific objective function**Shafer and Vovk, "A Tutorial on Conformal Prediction"****Gammerman et al., "Learning a Concept of Similarity using Conformal Inductive Principles"**. 
Further, the conformal prediction is a special case of risk minimization problem with the constraint of coverage guarantee, and the generalization loss for the size of prediction set could be quantified**Vapnik, "The Nature of Statistical Learning Theory"****Shafer and Vovk, "A Tutorial on Conformal Prediction"**, including classification**Bennett and Mangasarian, "Robust linear programming using conic programming"****Gammerman et al., "Learning a Concept of Similarity using Conformal Inductive Principles"** and regression**Vapnik, "The Nature of Statistical Learning Theory"**.
As we proposed in~\cref{sec:theoretical_results}, we interpret the tuning bias as a further constrained risk minimization problem of conformal prediction and provide the first theoretical analysis of the tuning bias.
% In this work, we interpret the tuning bias as a further constrained ERM problem of conformal prediction. 
% In this work, we are the first to interpret the tuning bias as a further constrained ERM problem of conformal prediction.

% The issue of tuning bias could also be interpreted as a special case of learnability, where the hypothesis class is the set of all possible indicator functions that score below the thresholds with transformation parameters.
% Though a great deal of work has been done on learnability in conformal prediction, the research on learnability in tuning bias remains blank.