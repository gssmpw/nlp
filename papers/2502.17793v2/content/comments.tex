% abstract

The recent surge of AI for design has led to the active use of text-to-image (T2I) models in creative processes, enabling rapid concept design and synthesis. 
\kw{I would simplify this sentence and just say "Text-to-Image (T2I) models enable rapid concept design and synthesis and have been widely used in AI for design"}
While existing T2I models pursue either semantic or stylistic variations of the generated concepts, our work tackles an essential yet overlooked aspect of generating novel concepts: \textit{functional coherence}. 
\kw{Do you mean something like: "Recent studies primarily focus on generating semantic and stylistic variations of given design concepts. In this paper, we shift the focus to generating novel concepts, with an emphasis on ensuring functional coherenceâ€”an essential yet often overlooked aspect."}
Functional coherence is ensuring that a model-generated concept coherently preserves the affordances of its source components. \heng{not sure what 'source components' means. make it consistent between component and part} In this paper, we propose \textsc{Synthia}, a framework for novel concept design that ensures both visual novelty and functional coherence. We introduce a hierarchical concept ontology and an effective affordance sampling-based curriculum learning method \heng{"affordance sampling-based curriculum learning method" is too vague. make it clear how you pick positive and negative samples based on affordance distance, and what affordance distance means} that empowers pre-trained T2I models to generate new concepts that cohesively integrate the original affordances of concept materials \heng{not sure what you mean by concept materials} given as inputs to the model. Both our automatic and human evaluations demonstrate the consistency and affordance-preserving characteristics of our proposed framework compared to current state-of-the-art T2I models, \kw{This might be picky, but it's weird to say compare a "framework" with "models". I would probably say "Synthia  Automatic and human evaluations show that Synthia outperforms state-of-the-art frameworks like ConceptLab and Kandinsky3 in maintaining consistency and preserving affordance." (I will remove "offering a ..." as it's redundant.)}
offering a new pathway for advancing AI-driven creative design in synthesizing functionally coherent and visually novel concepts. \heng{add a note to promise data and code will be made public. mention resource as additional contribution, briefly mention some stats \#concepts, parts, instances with part and affordance annotation} \heng{replace the final sentence with a concrete sentence summarizing detailed results}



% intro
Imagine a coffee machine with wheels that brews a perfect morning coffee and delivers it to your bed every morning. 
\kw{Need transition between these two sentences. Something like "This example illustrates how novel concept ..."}
Novel concept synthesis requires an effective fusion of disparate concepts (e.g., \texttt{coffee machine}, \texttt{trolley}), much akin to how humans blend ideas from different cognitive domains to generate novel ideas~\cite{fauconnier2002wwt, Han2018THECD}. 
\kw{I would move the following sentences "T2I models ... visualized concepts." to related work. It's not relevant to the discussion of "novel concept" here.}
Text-to-Image (T2I) models such as DALL-E~\citep{dalle} and Stable Diffusion~\citep{stabled} have ignited a new era of creative possibilities, transforming how artists and designers project their ideas into tangible, visualized concepts \citep{wang2024diffusion, boutin2023diffusion, vinker2023concept, richardson2024conceptlab, rahman2024visual, kwon2024concept, wang2024divide}. 

Existing studies on conceptual design using T2I models have enabled the rapid exploration \heng{unclear what you mean by rapid exploration} of novel visual concepts \citep{wang2024inspired, cai2023designaid, ma2023conceptual} by addressing user challenges during the creative process \citep{wang2024inspired}, or using large language models (LLMs) to bootstrap initial ideation candidates in textual format \citep{cai2023designaid, zhu2023generative}. These methods, however, often rely on naively feeding LLM-generated textual inputs to the T2I models, which consists of simple key phrases or semantic variations of visual concept description \citep{cai2023designaid, wang2024inspired}. One central limitation of existing approaches in novel concept synthesis is the lack of preservation of concept functions. For example, when combining two disparate concepts, e.g., a \texttt{coffee machine} and a \texttt{trolley}~\cite{liew2022magicmix}, the resulting concept should not only exhibit novelty in terms of appearance, but also maintain the essential functions of the two original concepts, ensuring their \textit{functional coherence.}

\heng{another important angle is missing in motivation - it's more about visual-text alignment. existing work takes control on pixel level. but you noticed that many concepts are decomposable into parts and some of these parts indicate affordance. We can call these parts with affordance as building blocks/functional modules. So we can send instructions based on functional modules as control to generate new concepts. We train the model so it implicitly learn 'decompose and reassemble' by associating affordance to parts. It will be good to visualize attention etc. to confirm the method does learn functional module level association. So the results can be more explanable.}
\kw{Agree. We need to make the logic flow and motivation clear in the 2nd paragraph. I would suggest following the example and discussion in the first paragraph, you can first define functional coherence and argue why it is important. Then like Heng said --argue existing work focusing on pixel-level control miss this important aspect. I would move all other irrelevant discussion like T2I are popular, and what other related works address to the related work section.  }

\input{figure/figure1_all}
In this work, we propose \textsc{Synthia}, a novel framework for Concept \textbf{Synth}es\textbf{i}s with \textbf{A}ffordance sampling that achieves both functional coherence and visual novelty using T2I models. Our work first proposes a hierarchical concept ontology, which structures visual concepts (e.g., \texttt{Furniture}-\texttt{Sofa}) based on their constituent parts (e.g., \texttt{leg}, \texttt{cushion}) and their corresponding affordances (e.g., \texttt{support, rest}).
Unlike prior works that focus on stylistic variations or aesthetic features~\cite{richardson2024conceptlab, vinker2023concept}, we leverage \textit{affordances} -- defined as ``the functionality offered by an object or its parts'' -- to guide novel concept synthesis. We construct the hierarchical concept ontology to enable a structured understanding of concepts based on their affordances, 
\kw{I feel the first part of this sentence repeats line 134, I would see how to merge these sentences to make this paragraph more concise.}
enabling the synthesis of functionally coherent, practical, and visually novel objects; for instance, a smart kitchen tool that can cut, weigh, and store ingredients while preserving each component's intended affordance (e.g., blades for cutting, compartments for storage).
\input{figure/concept_fig}
% \zhenhailong{this part is more like a novel task setting instead of a key part for our method/framework?} \jeongh{The affordance sampling strategy is a key part of our proposed method upon which we build our curriculum learning.}

\kw{I would probably start this paragraph by motivating the challenge of affordance sampling. Why we need affordance sampling, why it is important in novel concept design.It's not clear to me what is the subjects the sampling technique applies to like you're sampling from wha}
The key to our framework is the affordance sampling strategy, inspired by the theory of combinational creativity among humans~\cite{Han2018THECD}. Our affordance sampling strategically selects disparate concepts based on the affordance-based similarity metric (\S\ref{sec:data_gen}), which determines how far apart two concepts are based on their affordance overlap. Our sampling strategy based on the hierarchical ontology ensures that the sampled concepts possess sufficiently different affordances and avoid redundant functionalities, preventing trivial combinations (e.g., combining a cooker and a stove (Fig.~\ref{fig:close}) while encouraging novel designs (e.g., merging a car with a vacuum cleaner (Fig. ~\ref{fig:distant})). 

Furthermore, existing T2I models struggle to generate coherent multi-functional concepts (Fig.~\ref{fig:distant}) upon being provided a set of affordance pairs; for instance, the Stable Diffusion model simply generates a car for the \texttt{Drive} and \texttt{Vacuum} affordances, producing disjoint concepts with missing or separately depicted concepts rather than seamlessly integrated designs. To this end, \textsc{Synthia} proposes a framework to effectively fine-tune T2I models to jointly encode multiple affordances into a single functional concept. Our constraint-based optimization method (\S \ref{sec:ft}) incorporates positive and negative constraints derived from our proposed affordance sampling framework, where positive constraints ensure that generated concepts align with the intended affordances while negative constraints encourage novelty by differentiating outputs from existing concepts. \heng{this method seems to require these existing concepts are representative. How do we make sure they are representative?} To effectively and contrastively fine-tune T2I models with limited data, we employ curriculum learning, which gradually increases synthesis complexity by varying affordance distances as shown in Fig. \ref{fig:main_figure}.
