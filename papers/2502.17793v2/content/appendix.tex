\appendix
\onecolumn

\begin{center}{\bf {\LARGE Supplementary Materials}}\end{center}


\section{Hierarchical Concept Ontology Structure}
\begin{figure}[ht]
    \centering
    \includegraphics[width=0.8\linewidth]{figure/images/ontology.pdf}
    \caption{\textbf{Hierarchical Concept Ontology.}}
    \label{fig:ontology}
\end{figure}


\section{Prompts}
\subsection{Data Generation}
\begin{tcolorbox}[colback=gray!10, colframe=black, title=Prompt for Image Caption Generation]

You are a creative assistant who designs diverse novel concepts satisfying given conditions and generates a description of the concept. 
You should design three different novel concepts where each has all functions in the given positive constraints while the concept is different from the given negative constraints. 

Generate three different descriptions of three novel concepts that contain visible unique characteristics to use generated descriptions as image captions to generate images. Each description should consist of at most three sentences and contain given positive constraints but should not contain non-visible characteristics such as sound, smell, and taste. You must not simply combine multiple existing concepts that have each function but creatively design a single concept that has multiple functions at once. Generate three descriptions of three novel concepts that are not similar to each other but distinct, and each description should be clear without unnecessary explanations for generating images. Please separate each description with \textbackslash n\textbackslash n. Simply follow the format given in the example below.
\begin{verbatim}
{
    Positive Constraints: [sit, store]
    Negative Constraints: [chair, car, sofa, bench, shelve, drawer]
    Image Captions: [“...”]
}
\end{verbatim}
\label{app:gpt-prompt}
\end{tcolorbox}


\subsection{Automatic Evaluation}
\label{appendix:eval_prompt}
\begin{tcolorbox}[colback=gray!10, colframe=black, title=Prompt for Absolute Automatic Evaluation]

Please act as an impartial evaluator to assess the quality of a single concept image generated by an AI, based on the user’s requirements. Your evaluation should use the following three criteria, each scored on a scale of 1 to 5:\\

Faithfulness: Evaluate how well the object aligns with the provided instructions, including its intended affordances and functionalities. Does the text and image together indicate that the object serves the purpose for which it was designed?\\
Scoring:\\
5: Flawlessly combines all specified functionalities as per the instructions. Text and image work in harmony to demonstrate a well-designed and fully functional object.\\
4: Fulfills most instructions and intended functionalities, with only minor inconsistencies or missing details. The text and image are mostly aligned.\\
3: Partially fulfills the instructions. Some functionalities are present but not well-integrated or consistent. There may be a minor mismatch between text and image.\\
2: Struggles to meet the provided instructions, missing key functionalities or combining them poorly. Text and image may conflict.\\
1: Does not follow the instructions at all. Functionalities are completely missing, irrelevant, or nonsensical.\\

Novelty: Assess the originality and innovation of the design. Does the object show an exciting, novel design that would surprise or intrigue users?\\
Scoring:\\
5: Highly innovative, unique, and impressive. Inspires curiosity or excitement, making it highly desirable to explore.\\
4: Contains interesting and novel elements, showing clear creative thought and appeal.\\
3: Displays moderate novelty, with some unique features but remaining relatively conventional or uninspiring.\\
2: Shows limited novelty, with minimal creativity and overly simplistic or derivative design.\\
1: Entirely unoriginal and mundane, lacking any creativity and appearing common or uninspiring.\\

Practicality: Evaluate the real-world applicability of the object. Does the design make sense for human use? Would it align with human preferences and be feasible for production?\\
Scoring:\\
5: Extremely practical and human-centric. Highly functional, aligns perfectly with human preferences, and seamlessly fits into real-world scenarios.\\
4: Mostly practical and applicable, with minor limitations that could be addressed to improve usability.\\
3: Somewhat practical but with notable flaws or unrealistic elements that may limit usability in real-world scenarios.\\
2: Largely impractical, with significant flaws or inconsistencies that make it unlikely to be useful.\\
1: Entirely impractical and unusable, failing to align with human preferences or real-world feasibility.\\
\end{tcolorbox}

\begin{tcolorbox}[colback=gray!10, colframe=black, title=Prompt for Absolute Automatic Evaluation (continued)]
Coherence: This metric evaluates whether the image generated by the AI model contains only one primary object as instructed, focusing on the object's clarity and functionality without the presence of additional, unintended objects.\\
Scoring:\\
5: The image perfectly showcases one distinct object that aligns with the described attributes. There are no extraneous objects or elements that distract from the main object.\\
4: The primary object is clear and mostly isolated, but there may be minor elements in the background or periphery that do not significantly detract from the main object.\\
3: The main object is present and identifiable, but there are other elements in the image that somewhat distract from its clarity and functionality.\\
2: The image contains multiple objects where the main object is not clearly dominant or distinguishable from other unnecessary elements.\\
1: The image primarily features multiple objects, making it difficult to identify the intended single object; the composition is cluttered or entirely irrelevant to the instruction.

Provide a score for each criterion, followed by a concise explanation justifying your ratings. Your final response should strictly follow this format: 
\begin{verbatim}
{
    "Faithfulness": [Your Faithfulness Score],
    "Novelty": [Your Novelty Score],
    "Practicality": [Your Practicality Score],
    "Coherence": [Your Coherence Score]
}

\end{verbatim}
\label{app:absolute-prompt}
\end{tcolorbox}

\begin{tcolorbox}[colback=gray!10, colframe=black, title=Prompt for Relative Automatic Evaluation]

Please act as an impartial evaluator to assess the quality of concept images generated by two AI concept generators based on the user’s requirements. The evaluation criteria are as follows:
Faithfulness: Evaluate how well the object aligns with the provided instructions, including its intended affordances and functionalities. Does the text and image together indicate that the object serves the purpose for which it was designed? 
Novelty: Assess the originality and innovation of the design. Does the concept demonstrate a surprising or intriguing approach that stands out as fresh and exciting?
Practicality: Evaluate the real-world applicability of the concept. Does the design make sense for human use, align with user preferences, and appear feasible for production?
Coherence: This metric evaluates whether the image generated by the AI model contains only one primary object as instructed, focusing on the object's clarity and functionality without the presence of additional, unintended objects.
Provide your answer based on the following available choices:
"A" if the first image is better,
"B" if the second image is better,
"C" if both are equally strong.
Your final response should strictly follow this format: 
\begin{verbatim}
{
    "Faithfulness": [Your Faithfulness Choice],
    "Novelty": [Your Novelty Choice],
    "Practicality": [Your Practicality Choice],
    "Coherence": [Your Coherence Choice]
}

\end{verbatim}
\label{app:relative-prompt}
\end{tcolorbox}


% \input{figure/app_affordance_dist}


\section{Human Evaluation Details}
\label{app:humanevaluation}
\begin{tcolorbox}[colback=gray!10, colframe=black, title=Human Evaluation Instruction]
\textbf{Objective}

The goal of this evaluation is to assess the quality of novel concepts that integrate multiple affordances into a single, coherent design. Affordance refers to the functional properties of an object or its components. For example, a sofa affords the function of sitting, while its legs provide the function of support.


As an annotator, you will evaluate the given concepts based on four key metrics: \textbf{faithfulness}, \textbf{novelty}, \textbf{practicality}, and \textbf{coherence}. Each metric is defined below, along with its respective scoring criteria. \\



\textbf{Evaluation Criteria}

Faithfulness (Does the concept effectively integrate the specified affordances?)\\
This metric assesses whether the generated concept successfully incorporates all provided affordances in a meaningful and functional manner. \\


Scoring Scale:



5 – Fully integrates all specified affordances, demonstrating a well-designed and fully functional object.

4 – Incorporates all affordances with minor inconsistencies or slight missing details.

3 – Partially fulfills the affordances; some functionalities are present but not well-integrated or consistent.

2 – Struggles to meet the provided affordances; key functionalities are missing or poorly combined.

1 – Does not incorporate the specified affordances; functionalities are entirely missing, irrelevant, or nonsensical. \\



Novelty (To what extent does the concept demonstrate originality and innovation?) \\
This metric evaluates the uniqueness and creative appeal of the design, considering whether it introduces novel elements that would intrigue or surprise users.


Scoring Scale:



5 – Highly innovative and unique; presents a strikingly original concept that is engaging and thought-provoking.

4 – Contains clear novel elements, demonstrating creative thought and originality.

3 – Moderately novel; some unique aspects are present, but the overall concept remains relatively conventional.

2 – Limited novelty; the design appears simplistic, derivative, or lacking in creativity.

1 – Entirely unoriginal and uninspiring, closely resembling existing designs with no innovative aspects. \\



Practicality (Is the design feasible and suitable for real-world use?) \\
This metric assesses whether the concept is functionally viable and aligned with human preferences and usability considerations.


Scoring Scale:



5 – Highly practical and user-centered; seamlessly functional and feasible for real-world applications.

4 – Mostly practical; minor limitations exist but do not significantly hinder usability.

3 – Somewhat practical; contains notable flaws or unrealistic elements that may limit real-world applicability.

2 – Largely impractical; significant design flaws make real-world usability unlikely.

1 – Entirely impractical and non-functional; does not align with human preferences or feasibility constraints.

\end{tcolorbox}

\begin{tcolorbox}[colback=gray!10, colframe=black, title=Human Evaluation Instruction (continued)]
Coherence (Does the image clearly depict a single, distinct object?) \\
This metric evaluates whether the design presents a singular, well-defined object, free from extraneous elements that may obscure its intended functionality.


Scoring Scale:



5 – The image clearly and exclusively depicts a single object that integrates all specified affordances without any distractions.

4 – The primary object is distinct and well-defined, though minor background elements may be present without significantly detracting from clarity.

3 – The main object is identifiable, but additional elements in the image introduce some visual or conceptual distractions.

2 – The image contains multiple objects, making it difficult to distinguish the intended primary object or missing at least one affordance.

1 – The image primarily features multiple objects, with affordances spread across different elements rather than a unified concept, making it unclear what the primary object is. \\



\textbf{Final Instructions}

Please evaluate each concept independently based on the above criteria.

Assign a score for each metric according to the provided descriptions.

If a concept does not fit neatly into the scoring categories, use your best judgment to determine the most appropriate score.


Your evaluations will contribute to assessing the effectiveness of novel concept generation and help improve future designs. Thank you for your participation.


\end{tcolorbox}

\section{Experiments}
\subsection{Dataset}
\label{app:dataset}
To evaluate the performance of our proposed method, we conduct our experiments by constructing a dataset from two types of resources:
\begin{itemize}
    \item \textbf{Existing Concept Images}: For each existing concept in our ontology, we collect a dataset of 60 images from external platforms including Google Images and iStock. To ensure that the dataset is object-centric and minimizes noise, we filter out low-quality images using CLIP model~\citep{radford2021learningtransferablevisualmodels}. Specifically, we compute the similarity between the image embeddings and the text embeddings of the "\texttt{a photo of \{concept name\}}", selecting top-5 images with the highest similarity scores for each concept used as negative constraints. %\kw{I'm not sure I get this -- if this is novel concept, then you may not be able to find existing images?}
    \item \textbf{Generated Novel Concept Images}: With our affordance sampling, we uniformly sample 600 affordance pairs among 82K possible pairs for fine-tuning. For the test dataset, we select 500 affordance pairs among the ones not used for fine-tuning. We use the generated images from the sampled affordances for fine-tuning and evaluation.
    %\heng{the previous sentence is not parsable. not sure what you mean. rewrite it}
    The overall statistics can be found in Table ~\ref{app:dataset_stats}.
\end{itemize}
\begin{table}[ht]
    \centering
    % \resizebox{0.8\linewidth}{!}{%
    \begin{tabular}{cccc}
    \midrule
    \multirow{2}{*}{\textbf{Dataset}} & \multicolumn{2}{c}{Fine-tuning} & Inference \\
    \cmidrule{2-3}
    & Existing & Generated & Generated \\
    \midrule
    \textbf{\# Concepts} & 772 & 600 & 500 \\
    % \midrule
    \textbf{\# Images} & 3860 & 1800 & 500 \\
    \bottomrule
    \end{tabular}%
    % }
    \caption{Statistics of the datasets.
    }
    \label{app:dataset_stats}
\end{table}


\subsection{Baseline Methods}
\label{app:baseline}
\begin{itemize}
    \item \textbf{Stable Diffusion} \citep{esser2024scalingrectifiedflowtransformers} is a strong baseline model for high-fidelity image synthesis, which is built on a diffusion-based framework. In this work, we leverage the pre-trained \textit{stable-diffusion-3.5-large} model as the foundation model for the text-to-image task to generate a novel concept. Due to the limited context window length, we input only the positive constraints that contain the desired affordances, omitting the negative constraints associated with existing concepts.
    \item \textbf{Kandinsky} \citep{arkhipkin2023kandinsky, vladimir-etal-2024-kandinsky} model serves as another strong baseline model for comparison. We utilize the pre-trained \textit{Kandinsky 3.0} model without any finetuning as the baseline, aligning it with the foundation model used in our proposed framework. This approach ensures a consistent starting point for evaluation and a fair comparison. This baseline allows us to effectively demonstrate the impact of our proposed training framework by comparing performance before and after the fine-tuning process.
    \item \textbf{ConceptLab} \citep{richardson2024conceptlab} is a state-of-the-art framework designed for creative concept generation, which leverages an innovative approach that formulates the generation problem as an optimization process over the output space of the diffusion prior. It adopts a similar input format to the one used in our setting. We follow the finetuning process in the original framework, applying our training data to generate novel concepts. We then compare the generation quality during the inference time.
\end{itemize}

\input{figure/num_of_data}

\begin{figure*}
    \centering
    \includegraphics[width=\textwidth]{figure/images/our_rel_final.pdf}
    \vspace{-0.2in}
    \caption{Results of the relative automatic evaluation. We compare the quality of concepts generated from our models with ones from existing T2I models. Numbers indicate the percentage (\%) of baseline model wins, ties, and DALLE model wins.}
    \label{fig:rel_eval_ours}
\end{figure*}



\subsection{Hyper-parameter Settings}
\label{app:hyperparam}
To fine-tune the diffusion model with the constructed dataset from DALL-E,
%\heng{do you mean constructed dataset? how did you construct ground truth? if it's just from another model, then just call it as another system. it's weird to use automatically generated data as ground truth}
we use the optimizer AdamW \citep{loshchilov2019decoupledweightdecayregularization} with a learning rate of $\eta = \{5 * 10^{-6}, 10^{-6}, 5 * 10^{-7}\}$ to avoid the catastrophic forgetting problem. During the curriculum learning, we split the dataset into three groups based on their difficulty and trained 20 epochs for each group. For the weight factor in the triplet loss, we set $\gamma = \{0, 0.2, 0.5, 0.8, 1\}$. We finetune the UNet part in the pre-trained model and freeze the weights of other components in the diffusion model.

\section{Additional Experimental Results}
\subsection{Effectiveness of affordance-based textual prompt}
During the inference for novel concept generation, we align textual prompts with affordances as we described in Sec~\ref{sec:inference}. To further demonstrate the effectiveness of incorporating affordance to guide the novel concept synthesis, we additionally conduct experiments with textual input based on concept-level prompts without adding additional signals of affordances. We especially use prompts of ``\textit{a new design that includes functions from \{concepts that possess desired affordances -- e.g., sofa, chair\}.}''. For a fair comparison, we use the same fine-tuned models and baseline models but only utilize different prompts (concept-level prompt vs. affordance-level prompt) to evaluate the quality of the generated concepts. As shown in Table~\ref{results_automatic_triple}, affordance-level prompts facilitate a better design across different models, achieving an improvement in faithfulness and coherence. This demonstrates that aligning textual prompts with affordances can benefit even off-the-shelf T2I models to achieve better functionally coherent concepts. However, they are still far behind our models, showing the fundamental challenges in affordance-aware novel concept synthesis. 

\begin{table*}[t]
    \centering
    \small
    \resizebox{0.8\linewidth}{!}{%
    \begin{tabular}{cccccc}
    \midrule
    \textbf{Model} & \textbf{Type} & \textbf{Faithfulness}  & \textbf{Novelty} & \textbf{Practicality} & \textbf{Coherence} \\
    \midrule
    \multirow{2}{*}{Stable Diffusion} & Concept & $2.99$ &  $3.83$ &  $2.87$ & $2.65$ \\
    & Affordance & $3.73$ & $3.80$ & $3.33$ & $3.97$ \\
    \hdashline
    \multirow{2}{*}{Kandinsky3} & Concept & $3.10$ & $3.92$ & $2.79$ & $3.24$ \\
    & Affordance & $3.52$ & $3.91$ & $3.11$ & $4.20$ \\
    \hdashline
    \multirow{2}{*}{ConceptLab} & Concept & $3.61$ & $4.13$ & $3.14$ & $4.31$ \\
    & Affordance & $3.78$ & $4.03$ & $3.08$ & $4.27$ \\
    \midrule
    \multirow{2}{*}{\textsc{Synthia}} & Concept & $3.90$ & $4.34$ & $3.28$ & $4.60$ \\
    & Affordance & $3.99$ & $4.45$ & $3.36$ & $4.76$ \\
    \bottomrule
    \end{tabular}%
    }
    \caption{Results of the automatic evaluation with three positive affordances. We compare our method with baseline models. For each metric, a higher number indicates a better performance, where the absolute score ranges between 0 and 5.
    }
    \label{results_automatic_triple}
\end{table*}


\begin{table*}[t]
    \centering
    \small
    \resizebox{0.8\linewidth}{!}{%
    \begin{tabular}{cccccc}
    \midrule
    \textbf{Model} & \textbf{Type} & \textbf{Faithfulness}  & \textbf{Novelty} & \textbf{Practicality} & \textbf{Coherence} \\
    \midrule
    \multirow{2}{*}{Stable Diffusion} & Concept & $2.74$ &  $3.73$ &  $2.73$ & $2.38$ \\
    & Affordance & $3.41$ & $3.82$ & $3.08$ & $3.71$ \\
    \hdashline
    \multirow{2}{*}{Kandinsky3} & Concept & $2.92$ & $3.88$ & $2.62$ & $2.82$ \\
    & Affordance & $3.33$ & $3.87$ & $3.13$ & $4.07$ \\
    \hdashline
    \multirow{2}{*}{ConceptLab} & Concept & $3.67$ & $4.03$ & $3.03$ & $4.42$ \\
    & Affordance & $3.61$ & $3.98$ & $2.98$ & $4.17$ \\
    \midrule
    \multirow{2}{*}{\textsc{Synthia}} & Concept & $3.85$ & $4.36$ & $3.14$ & $4.59$ \\
    & Affordance & $3.86$ & $4.52$ & $3.25$ & $4.80$ \\
    \bottomrule
    \end{tabular}%
    }
    \caption{Results of the automatic evaluation with four positive affordances. We compare our method with baseline models. For each metric, a higher number indicates a better performance, where the absolute score ranges between 0 and 5.
    }
    \label{results_automatic_four}
\end{table*}


\begin{table*}[ht]
    \centering
    \small{%
    \begin{tabular}{cccc}
    \midrule
    \textbf{Model} & \textbf{Type} & \textbf{Close}  & \textbf{Distant} \\
    \midrule
    \multirow{2}{*}{Stable Diffusion} & Concept & $3.92$ &  $4.13$ \\
    & Affordance & $3.71$ & $3.88$ \\
    \hdashline
    \multirow{2}{*}{Kandinsky3} & Concept & $4.04$ & $4.13$ \\
    & Affordance & $4.18$ & $4.14$ \\
    \hdashline
    \multirow{2}{*}{ConceptLab} & Concept & $4.18$ & $4.17$ \\
    & Affordance & $3.96$ & $4.20$ \\
    \midrule
    \multirow{2}{*}{\textsc{Synthia}} & Concept & $4.26$ & $4.33$ \\
    & Affordance & $4.46$ & $4.59$ \\
    \bottomrule
    \end{tabular}%
    }
    \caption{Results of the automatic novelty evaluation with different distances. We compare our method with baseline models. For each metric, a higher number indicates a better performance, where the absolute score ranges between 0 and 5.
    }
    \label{results_automatic_novelty_sampling}
\end{table*}


\begin{table*}[t]
    \centering
    \small
    \resizebox{0.8\linewidth}{!}{%
    \begin{tabular}{cccccc}
    \midrule
    \textbf{Model} & \textbf{Type} & \textbf{Faithfulness}  & \textbf{Novelty} & \textbf{Practicality} & \textbf{Coherence} \\
    \midrule
    \multirow{2}{*}{\textsc{Synthia} without CL} & Concept & $3.61$ & $4.03$ & $3.07$ & $4.30$ \\
    & Affordance & $3.56$ & $4.13$ & $2.95$ & $4.59$ \\
    \midrule
    \multirow{2}{*}{\textsc{Synthia}} & Concept & $3.97$ & $4.33$ & $3.30$ & $4.51$ \\
    & Affordance & $3.99$ & $4.55$ & $3.35$ & $4.81$ \\
    \bottomrule
    \end{tabular}%
    }
    \caption{Results of the automatic evaluation with and without curriculum learning. For each metric, a higher number indicates a better performance, where the absolute score ranges between 0 and 5.
    }
    \label{results_automatic_no_curriculum}
\end{table*}



\begin{figure*}
    \centering
    \includegraphics[width=\textwidth]{figure/images/human_eval_result.pdf}
    \vspace{-0.2in}
    \caption{Results of the human evaluation.}
    \label{fig:human_eval_results}
\end{figure*}


