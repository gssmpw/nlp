
\section{Additional Numerical Experiments} \label{sec:numerical}

\subsection{Construction of Nested Systems}\label{sec:con-nest}

Recall the construction of the nested system described in Section \ref{sec:con-nest-m}.
It immediately follows Proposition \ref{thm:DP} that the construction satisfies Assumption \ref{as:ne-un} in the unsupervised setting.

% In the supervised setting, the above strategy can be repeated $n+1$ times to construct $\{S_j(X_i)\}_{j\in[m]}$ for $i=n+1,\cdots,2n+1$. As outlined in Section \ref{sec:DCP-DP}, for each $i=n+1,\cdots,2n+1$, we first generate independent samples $Y_1(X_i),\cdots,Y_L(X_i)$ from $\widehat{F}(\cdot\mid X_i)$ for some sufficiently large integer $L$. Then, applying the three steps listed above to $Y_1(X_i),\cdots,Y_L(X_i)$, we obtain the nested system $\{S_j(X_i)\}_{j\in[m]}$. 
% \vnote{Changing this since this is not exactly how this is implemented for the supervised setting.}

In the supervised setting, the construction of the nested system is based on $\widehat{F}(y\mid x)$. For each $x\in\{X_{n+1},\cdots,X_{2n+1}\}$, we generate $Y_1(x),\cdots,Y_L(x)$ according to the quantile level
$$Y_l(x)=\argmax\{y:\widehat{F}(y\mid x)\leq l/L\}.$$
Then, the greedy expansion and contraction procedure described in Section \ref{sec:con-nest-m} is applied on $Y_1(x),\cdots,Y_L(x)$. Effectively, this is equivalent to using $\widetilde{F}(y\mid x)=\frac{1}{L}\sum_{l=1}^L\mathbb{I}\{Y_l(x)\leq y\}$ as input. By its definition, $\widetilde{F}(y\mid x)$ is a uniform approximation to $\widehat{F}(y\mid x)$ with error $1/L$. Thus, Assumption \ref{as:ne-su} is still satisfied for $\widetilde{F}(y\mid x)$. In all of our experiment, we set $L=m$.

\iffalse
In the supervised setting, for each test example \(X_{\mathrm{test}}\) we do not have access to samples of \(Y | X = X_{\mathrm{test}}\).  Instead, we have estimated quantiles of the distirbution of \(Y | X = X_{\mathrm{test}}\), for quantiles in some grid of \(m + 1\) levels evenly distributed in \([0, 1]\).  We modify our dynamic programming procedure to operate on these quantiles instead of sampled data points.  At a high level, the gap between each of the quantiles in the grid corresponds to an interval that captures a \(\frac{1}{m}\) probability, and the \(y\) values of each quantile give the volume of the interval.  Thus the problem becomes morally equivalent to having \(m\) ``sample" points placed between each pair of estimated quantiles.  The greedy expansion and greedy contraction mechanisms can also be translated to this setting in a similar way. 
Similar to the argument in the unsupervised setting, the nested systems in the supervised setting satisfy Assumption \ref{as:ne-su}.
\fi

\begin{remark}
It is clear that the details of the greedy expansion step and the greedy contraction step do not matter much for Assumption \ref{as:ne-un} or \ref{as:ne-su} to be satisfied. However, different choices will indeed affect practical performance, especially in the supervised setting when $\widehat{F}(y\mid x)$ is not close to $F(y\mid x)$. To be more specific, sensible choices of expansion and contraction sets from the $S_{j^*}$ generated by DP will serve as a safety net against model misspecification.  We discuss this in more detail in Section \ref{sec:app-labeled-data}, see e.g. Figure \ref{fig:volume-aware-example}.
\end{remark}


\subsection{Unsupervised Setting}

Given i.i.d. observations $Y_1, Y_2, \dots, Y_{2n} \in \R$ drawn from some distribution $P$, the goal is to find a prediction set $\widehat{C}=\widehat{C}(Y_1, \dots, Y_{2n})$ such that $\Pr(Y_{2n+1} \in \widehat{C}) \geq 1-\alpha$ for an independent future observation $Y_{2n+1}$ drawn from the same $P$. 
We implement the proposed conformalized dynamic programming (DP) method $\widehat{C}_{\rm CP-DP}$, and compare it with the conformalized kernel density estimation (KDE) proposed by~\cite{Lei2013DistributionFreePS} on the following synthetic datasets: (1) Gaussian; (2) Censored Gaussian; (3) Mixture of Gaussians; (4) ReLU-Transformed Gaussian.

Though the original conformalized KDE was proposed in the full conformal framework, we will consider its split conformal version for a direct comparison. We believe the comparison between the full conformal versions of the two methods will lead to the same conclusion.
For the conformalized DP method, the conformity score is constructed based on the nested system described in Section \ref{sec:con-nest} with $m=50$ and $\delta = \sqrt{(k + \log n)/n}$. 
The conformalized KDE is also in the form of (\ref{eq:pred-set-un}), with the conformity score given by
$$q_{\rm KDE}(x)=\frac{1}{n\rho}\sum_{i=1}^nK\left(\frac{y-Y_i}{\rho}\right),$$
where $K(\cdot)$ is the standard Gaussian kernel and $\rho$ is the bandwidth parameter.
Both methods involve a single tuning parameter, $k$ for conformalized DP and $\rho$ for conformalized KDE.

\paragraph{Gaussian:} Our first distribution is $P=N(0,1)$, which is a benign example for sanity check. We consider sample size being $100$, and set the coverage probability $1-\alpha=30\%$ for a more transparent comparison between the two methods. The conformalized DP is computed with number of intervals $k$ ranging from $1$ to $10$. It turns out that the output of the prediction set is quite stable when $k$ varies (Figure~\ref{fig:gaussian_length}). Even for $k=10$, our method still produces a single interval in this unimodal distribution.



The conformalized KDE is implemented with bandwidth $\rho$ ranging from $0.001$ to $0.005$. We observe that the quality of the prediction set is quite sensitive to the choice of the bandwidth. As is shown by Figure~\ref{fig:gaussian_interval}, if the bandwidth of KDE is too small, the conformal prediction will output almost the entire support of the data set. This is because if the KDE overfits the training samples, the level set of the KDE will likely not cover the future observation. Therefore, a conformal procedure, which guarantees finite sample coverage, has to be conservative by outputting the entire support. Figure~\ref{fig:gaussian_length} shows that this issue will be alleviated as the bandwidth gets larger.

\begin{figure}[H]
    \centering
        \includegraphics[width=0.45\textwidth]{figures/Gaussian_DP_1.png}
    \hfill
        \includegraphics[width=0.45\textwidth]{figures/Gaussian_KDE_001.eps}
    \caption{Conformal prediction sets on the Gaussian dataset. The left plot shows the histogram of the dataset and the prediction set produced by conformalized DP with $k=1$; the right plot shows the kernel density estimation with bandwidth $\rho=0.001$ and the prediction set given by the conformalized KDE. }
    \label{fig:gaussian_interval}
\end{figure}

\begin{figure}[H]
    \centering
        \includegraphics[width=0.45\textwidth]{figures/Gaussian_DP.eps}
    \hfill
        \includegraphics[width=0.45\textwidth]{figures/Gaussian_KDE.eps}
    \caption{Volumes of prediction sets of the two methods on the Gaussian dataset (blue) and the benchmark $\opt_1(N(0,1),0.3)=0.7706$ (red). The blue curves are computed by averaging $100$ independent experiments. }
    \label{fig:gaussian_length}
\end{figure}

\paragraph{Censored Gaussian:} We next consider $P$ being a censored Gaussian distribution. We take the sample size to be $100$, and each sample can be generated according to $Y_i = \sigma(Z_i+1) - \sigma(Z_i-1)$ with $Z_i\sim N(0,1)$ and $\sigma(t)=\max(t,1)$ being the ReLU transform. This is equivalently a truncated Gaussian distribution, which has a standard Gaussian density on $(0,2)$ and a point mass at $0$ with probability $\Pr(Z_i \leq -1)$ and another point mass at $2$ with probability $\Pr(Z_i \geq 1)$. Again, for the sake of comparison, we set the coverage probability to be $1-\alpha=30\%$.

Since $\Pr(|Z_i| \leq -1) \geq 1-\alpha$, the population optimal volume is $\opt(P,0.3)=\opt_2(P,0.3)=0$ due to the point masses at $\{0,2\}$. By setting $k=2$ for the conformalized DP procedure, the prediction set concentrates on the two point masses (Figure~\ref{fig:trunc_gaussian_interval}). Moreover, it produces very similar results as we increase $k$ up to $10$. Figure~\ref{fig:trunc_gaussian_length} shows that the only exception is $k=1$, since one short interval obviosly cannot cover two points that are far away from each other.

We also run conformalized KDE with bandwidth $\rho$ ranging from $0.001$ to $1$. Since the distribution does not even have a density function on the entire support, KDE is not really suitable for this setting. Not surprisingly, for a typical choice of bandwidth that is not too small, the conformalized KDE will not identify the two point masses due to smoothing (Figure~\ref{fig:trunc_gaussian_interval}). Figure~\ref{fig:trunc_gaussian_length} reports the volume of the prediction set as we vary bandwidth, and the volume of the prediction set is close to optimal only when the bandwidth is extremely close to $0$.

\begin{figure}[H]
    \centering
        \includegraphics[width=0.45\textwidth]{figures/Trunc_Gaussian_DP_2.png}
    \hfill
        \includegraphics[width=0.45\textwidth]{figures/Trunc_Gaussian_KDE_bandwidth0.2.eps}
    \caption{Conformal prediction sets on the censored Gaussian dataset. The left plot shows the histogram of the dataset and the prediction set given by conformalized DP with $k=2$ intervals (The prediction set is two zero-length intervals at $0.0$ and $2.0$). The right plot shows the kernel density estimation with bandwidth $\rho=0.2$ and the prediction set by conformalized KDE.}
    \label{fig:trunc_gaussian_interval}
\end{figure}

\begin{figure}[H]
    \centering
        \includegraphics[width=0.45\textwidth]{figures/Trunc_Gaussian_DP.eps}
    \hfill
        \includegraphics[width=0.45\textwidth]{figures/Trunc_Gaussian_KDE.eps}
    \caption{Volumes of prediction sets of the two methods on the censored Gaussian dataset (blue) and the optimal volume (red). The blue curves are computed by averaging $100$ independent experiments.}
    \label{fig:trunc_gaussian_length}
\end{figure}


\paragraph{Mixture of Gaussians:}
In this experiment, we consider $P=\frac{1}{3}N(-6,0.0001)+\frac{1}{3}N(0,1)+\frac{1}{3}N(8,0.25)$. The sample size and coverage probability are set as $600$ and $1-\alpha=80\%$, respectively. The two methods are compared with $k$ ranging from $1$ to $10$ in conformalized DP and bandwidth $\rho$ ranging from $0.001$ to $5$ in conformalized KDE.

\begin{figure}[H]
    \centering
    \begin{subfigure}{0.32\textwidth}
        \includegraphics[width=\textwidth]{figures/mix_gaussian3_DP_k2.png}
        \caption{$k=2$}
    \end{subfigure}
    \hfill
    \begin{subfigure}{0.32\textwidth}
        \includegraphics[width=\textwidth]{figures/mix_gaussian3_DP_k3.png}
        \caption{$k=3$}
    \end{subfigure}
    \hfill
    \begin{subfigure}{0.32\textwidth}
        \includegraphics[width=\textwidth]{figures/mix_gaussian3_DP_k6.png}
        \caption{$k=6$}
    \end{subfigure}
    \caption{Prediction sets provided by the conformalized DP method with the number of intervals $k=2,3,6$ on the mixture of Gaussians dataset.}
    \label{fig:mix_gaussian_intervals_DP}
\end{figure}

\begin{figure}[H]
    \centering
    \begin{subfigure}{0.32\textwidth}
        \includegraphics[width=\textwidth]{figures/mix_gaussian3_KDE_bandwidth0.01.eps}
        \caption{$\rho=0.01$}
    \end{subfigure}
    \hfill
    \begin{subfigure}{0.32\textwidth}
        \includegraphics[width=\textwidth]{figures/mix_gaussian3_KDE_bandwidth0.5.eps}
        \caption{$\rho=0.5$}
    \end{subfigure}
    \hfill
    \begin{subfigure}{0.32\textwidth}
        \includegraphics[width=\textwidth]{figures/mix_gaussian3_KDE_bandwidth5.eps}
        \caption{$\rho=5.0$}
    \end{subfigure}
    \caption{Prediction sets provided by the conformalized KDE using bandwidth $\rho=0.01,0.5,5.0$ on the mixture of Gaussians dataset.}
    \label{fig:mix_gaussian_intervals_KDE}
\end{figure}

We report typical results of conformalized DP with $k\in\{2,3,6\}$ in Figure~\ref{fig:mix_gaussian_intervals_DP} and report those of conformalized KDE with $\rho\in\{0.01,0.5,5.0\}$ in Figure~\ref{fig:mix_gaussian_intervals_KDE}. The proposed method based on DP produces similar prediction sets close to optimal as long as $k\geq 3$ (Figure~\ref{fig:mix_gaussian_length}). This is because $\opt(P,0.8)=\opt_3(P,0.8)$ with $P$ being a Gaussian mixture of three components. In comparison, the results based on KDE are quite sensitive to the bandwidth choice, since different bandwidths lead to kernel density estimators with completely different numbers of modes. Figure~\ref{fig:mix_gaussian_length} shows that for the optimal choice of bandwidth around $0.5$, the KDE successfully identifies the three modes of the Gaussian mixture. However, even with the optimal bandwidth, the volume of the prediction set is in general still greater than that of the conformalized DP. This is partly because the three components of the Gaussian mixture do not have the same variance parameters, and thus cannot be optimally estimated by KDE with a single bandwidth.







\begin{figure}[H]
    \centering
        \includegraphics[width=0.45\textwidth]{figures/mix_gaussian3_DP.eps}
    \hfill
        \includegraphics[width=0.45\textwidth]{figures/mix_gaussian3_KDE.eps}
    \caption{Volumes of prediction sets of the two methods on the mixture of Gaussians dataset (blue) and the optimal volume $\opt(P,0.8)=3.0178$ (red). The blue curves are computed by averaging $100$ independent experiments.}
    \label{fig:mix_gaussian_length}
\end{figure}


\paragraph{ReLU-Transformed Gaussian:} The ReLU-Transformed Gaussian is generated according to $X_i = \sum_{j=1}^t a_j * \sigma(w_j*Z_i + b_j)$ with $Z_i\sim N(0,1)$. It includes the censored Gaussian as a special case. Here, we take $t=7$ and take a randomly generated set of coefficients. The resulting density function is plot in Figure~\ref{fig:ReLU_example} (a). The sample size and coverage probability are taken as $600$ and $1-\alpha=80\%$, respectively.

Figure~\ref{fig:ReLU_example} also shows a typical prediction set produced by conformalized DP with $k=4$ and one produced by conformalized KDE with bandwidth $\rho=0.02$. Figure~\ref{fig:ReLU_length} gives a more thorough comparison. The proposed conformalized DP achieves near optimality when $k\geq 4$, since the distribution has $4$ modes. The KDE solutions are sensitive to the choice of bandwidth for this complicated distribution. 

\begin{figure}[H]
    \centering
    \begin{subfigure}{0.32\textwidth}
        \includegraphics[width=\textwidth]{figures/ReLU_OPT.eps}
        \caption{Optimal Coverage Set}
    \end{subfigure}
    \hfill
    \begin{subfigure}{0.32\textwidth}
        \includegraphics[width=\textwidth]{figures/ReLU_DP_k4.png}
        \caption{Conformalized DP with $k=4$}
    \end{subfigure}
    \hfill
    \begin{subfigure}{0.32\textwidth}
        \includegraphics[width=\textwidth]{figures/ReLU_KDE_bandwidth0.02.eps}
        \caption{Conformalized KDE with $\rho=0.02$}
    \end{subfigure}
    \caption{(a) Density of The ReLU-Transformed Gaussian and prediction set with optimal volume; (b) Conformalized DP with $k=4$; (c) Conformalized KDE with $\rho=0.02$.}
    \label{fig:ReLU_example}
\end{figure}

\begin{figure}[ht]
    \centering
        \includegraphics[width=0.49\columnwidth]{figures/ReLU_DP.eps}
    \hfill
        \includegraphics[width=0.49\columnwidth]{figures/ReLU_KDE.eps}
    \caption{Volumes of prediction sets of the two methods on the ReLU-transformed Gaussian dataset (blue) and the optimal volume $\opt(P,0.8)=5.1361$ (red). The blue curves are computed by averaging $100$ independent experiments.}
    \label{fig:ReLU_length}
\end{figure}

\paragraph{Effects of Sample Sizes and Coverage Probabilites:}
Finally, we study the effects of sample sizes and coverage probabilities for the two methods. Specifically, we examine how the volume of the prediction set decays as the sample size increases and how it varies with different coverage probabilities. The experiments will be conducted with data generated from the following two distributions:
\begin{enumerate}
\item $\frac{1}{3}N(-6,0.0001)+\frac{1}{3}N(0,1)+\frac{1}{3}N(8,0.25)$.
\item The ReLU-Transformed Gaussian $Y_i = \sum_{j=1}^t a_j * \sigma(w_j*Z_i + b_j)$ with $Z_i\sim N(0,1)$, $t=7$ and coefficients are the same as in the previous experiment.
\end{enumerate}
For conformalized DP, we will set $k=3$ for the first distribution and $k=4$ for the second one to match the number of modes in the two cases. For conformalized KDE, since the method is sensitive to the choice of bandwidth, we will scan the bandwidth $\rho$ from $0.001$ to $0.2$, and only report the one with the smallest volume. We also benchmark the performances of the two methods by the optimal volume and a standard split conformal procedure with conformity score $q_{\rm standard}(y)=-\left|y-\frac{1}{n}\sum_{i=1}^nY_i\right|$.

\begin{figure}[htbp]
    \centering
        \includegraphics[width=0.45\textwidth]{figures/Sample_Size_Mixgaussian2.eps}
    \hfill
        \includegraphics[width=0.45\textwidth]{figures/Sample_Size_ReLU.eps}
    \caption{Volume of prediction set against sample size. Left: $\frac{1}{3}N(-6,0.0001)+\frac{1}{3}N(0,1)+\frac{1}{3}N(8,0.25)$. Right: ReLU-Transformed Gaussian. All curves are plotted by averaging results from $100$ independent experiments.}
    \label{fig:sample_size}
\end{figure}

\begin{figure}[H]
    \centering
        \includegraphics[width=0.45\textwidth]{figures/Coverage_mixgaussian2.png}
    \hfill
        \includegraphics[width=0.45\textwidth]{figures/Coverage_ReLU.eps}
    \caption{Volume of prediction set against coverage probability. Left: $\frac{1}{3}N(-6,0.0001)+\frac{1}{3}N(0,1)+\frac{1}{3}N(8,0.25)$. Right: ReLU-Transformed Gaussian. All curves are plotted by averaging results from $100$ independent experiments.}
    \label{fig:coverage}
\end{figure}

Figure \ref{fig:sample_size} shows the results with sample size ranging from $200$ to $1000$ with the coverage probability fixed by $1-\alpha=80\%$. Both conformalized DP and conformalized KDE produce smaller prediction sets as sample size increase. Even with the bandwidth optimally tuned for conformalized KDE, which is not feasible in practice, the proposed conformalized DP tends to achieve smaller volumes in most cases. In setting of the ReLU-Transformed Gaussian, we observe that the volume of conformalized KDE prediction set barely decreases after sample size $600$, since in this case density estimation is very hard for KDE.

Figure~\ref{fig:coverage} considers coverage probability ranging from $0.1$ to $0.9$, with sample size fixed at $600$. The conformalized DP constantly achieves smaller volume than the conformalized KDE even though the later is computed with optimally tuned bandwidth. This demonstrates the robustness of the conformalized DP in handling varying coverage requirements while maintaining efficiency in volume.



\subsection{Supervised Setting}
\label{sec:app-labeled-data}

In the supervised setting, we validate our results on the simulated datasets in \citet{romano2019conformalized} and \citet{izbicki2020flexible}.  We compare against the methods of Conformalized Quantile Regression (CQR) of \citet{romano2019conformalized} and Distributional Conformal Prediction (DCP) of \citet{chernozhukov2021distributional} and CD-split and HPD-split of \citet{izbicki2022cd}.

\paragraph{Simulated Dataset \citep{romano2019conformalized}.} We first describe the simulated dataset in \citet{romano2019conformalized}. In this data, each one-dimensional predictor variable \(X_i\) is sampled uniformly from the range \([0, 5]\).  The response variable is then sampled according to 
\[Y_i \sim \mathrm{Pois}(\sin^2(X_i) + 0.1) + 0.03 ~X_i ~\varepsilon_{1, i} + 25 ~\mathbf{1}\{U_i < 0.01\} ~\varepsilon_{2, i},\]
where \(\mathrm{Pois}(\lambda)\) is the Poisson distribution with mean \(\lambda\), \(\epsilon_{1, i}\) and \(\epsilon_{2, i}\) are independent standard Gaussian noise, and \(U_i\) is drawn uniformly on the interval \([0, 1]\).  The first component of the distribution, \(\mathrm{Pois}(\sin^2(X_i) + 0.1)\), generates a distribution that is clustered around positive integer values of \(Y\), with variance that changes periodically in \(X\).  The second component of the distribution, \(0.03 ~X_i ~\varepsilon_{1, i}\), adds some additional variance to each of the integer centered clusters, where the magnitude of the variance increases with \(X\).  The final component, \(25 ~\mathbf{1}\{U_i < 0.01\} ~\varepsilon_{2, i}\), adds a small fraction of outliers to the distribution.   
We generate 2000 training examples, and 5000 test examples, as in the work of \cite{romano2019conformalized}.  The same subset of training and test examples are used in the illustration of each of these methods.  The set of test examples is visualized in Figure \ref{fig:synthetic-zoom-out}, with the full range of \(Y\) values including the outliers.  In the plots associated with our conformal output, we zoom in on the \(Y\) axis for readability, leaving the outliers off the chart.   

\begin{figure}
    \centering
    \includegraphics[width=0.49\linewidth]{figures/synthetic-zoom-out.png}
    \caption{Simulated data of \citet{romano2019conformalized}, including outliers.}
    \label{fig:synthetic-zoom-out}
\end{figure}

\paragraph{Simulated Dataset \citep{izbicki2020flexible}.}
We now describe the simulated dataset in \citet{izbicki2020flexible}. In this data, the predictor variables \( X = (X_1, \dots, X_d) \) with $d = 20$ dimensions are independently and uniformly sampled from the range \([-1.5, 1.5]\). The response variable \( Y \) is then generated according to the following bimodal conditional distribution:

$$
Y \mid X \sim 0.5 \mathcal{N}( f (X) - g (X), \sigma^2(X) ) + 0.5 \mathcal{N}( f (X) + g (X), \sigma^2(X) ).
$$

where the functions \( f(X) \), \( g(X) \), and \( \sigma^2(X) \) are defined as:
$$
f(X) = (X_1 - 1)^2 (X_1 + 1), \quad g(X) = 2 \mathbb{I}(X_1 \geq -0.5) \sqrt{X_1 + 0.5}, \quad \sigma^2(X) = \frac{1}{4} + |X_1|.
$$

Here, \( \mathcal{N}(\mu, \sigma^2) \) denotes a normal distribution with mean \( \mu \) and variance \( \sigma^2 \), and the indicator function \( \mathbb{I}(X_1 \geq -0.5) \) accounts for the bimodal nature of the data, introducing a piecewise behavior in the response variable. The first term \( f(X) \) captures a polynomial relationship with \( X_1 \), while the second term \( g(X) \) introduces an asymmetric bimodal effect depending on the value of \( X_1 \). The variance \( \sigma^2(X) \) increases linearly with \( |X_1| \), adding heteroscedasticity to the distribution.

We generate $2000$ training examples and $5000$ test examples. The same training and test sets are used consistently across all experiments to ensure reproducibility. The test set is visualized in Figure~\ref{fig:bimodal-synthetic}, showcasing the full range of \( Y \) values, including the effects of bimodality and variance heterogeneity.

\begin{figure}
    \centering
    \includegraphics[width=0.49\linewidth]{figures/bimodal_dataset.png}
    \caption{Simulated data from \citet{izbicki2020flexible}, illustrating the bimodal distribution of the response variable.}
    \label{fig:bimodal-synthetic}
\end{figure}

\paragraph{Methods.}  We compare our conformalized DP with the following methods: Conformalized Quantile Regression (CQR) of \citet{romano2019conformalized} and Distributional Conformal Prediction via Quantile Regression (DCP-QR) and Optimal Distributional Conformal Prediction via Quantile Regression (DCP-QR*) of \citet{chernozhukov2021distributional} and CD-split and HPD-split of \citet{izbicki2022cd}.  

We now describe the implementation of these methods. The compared methods, CQR, DCP-QR, DCP-QR*, and our conformalized DP rely on quantile regression. 
For simulated dataset~\citep{romano2019conformalized} with single dimensional predictor variable, we use the package \texttt{sklearn-quantile} \citep{sklearn-quantile} to implement the quantile regression, which implements the method of Quantile Regression Forests, due to \citet{Meinshausen06Quantile}.  
The CD-Split and HPD-Split methods require the conditional density estimation, which is achieved by the R package \texttt{FlexCoDE} \citep{izbicki2017converting}.
For simulated dataset \citep{izbicki2020flexible} with high dimensional predictor variables, the quantile regression by \texttt{sklearn-quantile} is not informative.
For CQR, DCP-QR, DCP-QR*, and our conformalized DP, we first use the R package \texttt{FlexCoDE} to generate the conditional density estimation and then integrate the conditional density estimation to get quantile regression and conditional CDF. 
The CD-Split and HPD-Split methods again use the conditional density estimation provided by \texttt{FlexCoDE}.
All methods are implemented within the split conformal framework, where the training data is randomly divided into two equal parts. Specifically, half of the data is allocated for model training, while the remaining half is used as the calibration set to ensure valid coverage guarantees.

For convenience, we will refer to the \(q\)th estimated quantile of \(Y\) given \(X = x\) as \(\widehat{Q}(q, x)\).  Some of the following methods use quantile regression to estimate the whole conditional c.d.f.\ of \(Y\) given \(X\), by estimating a set of quantiles from a fine grid.  This gives us an estimate of the conditional c.d.f., which gives us access to \(\widehat{F}(y\mid x)\), the inverse of \(\widehat{Q}\).  (That is, \(\widehat{F}(y\mid x) = q\), such that \(y = \widehat{Q}(q, x)\).  Since we only have \(\widehat{Q}\) for values of \(q\) in the grid, we set \(\widehat{F}(y\mid x)\) to be the smallest \(q\) in the grid such that \(y \le \widehat{Q}(q, x)\).)

\begin{itemize}
    \item Conformalized Quantile Regression (CQR), \cite{romano2019conformalized}:  This method fits a model to two quantiles of the data, \(q_{\mathrm{low}} = \frac{\alpha}{2}\) and \(q_{\mathrm{high}} = 1 - \frac{\alpha}{2}\).   On a new test example \(X_\mathrm{test}\), CQR uses the model to estimate the low and high quantile, and  the conformal procedure will output the interval 
    \[\left[\widehat{Q}(q_{\mathrm{low}}, X_\mathrm{test}) - b, ~\widehat{Q}(q_{\mathrm{high}}, X_\mathrm{test}) + b \right],\] 
    where \(b\) is a buffer value chosen in the calibration step of the conformal procedure to guarantee coverage.  

    \item Distributional Conformal Prediction via Quantile Regression (DCP-QR), \cite{chernozhukov2021distributional}:  In this framework, we assume access to a model \(\widehat{F}\) that can estimate the conditional c.d.f. of the distribution of \(Y\) given \(X\), which we estimate via quantile regression. Similar to CQR, we start with \(q_{\mathrm{low}} = \frac{\alpha}{2}\) and \(q_{\mathrm{high}} = 1 - \frac{\alpha}{2}\).  In DCP, instead of adding the buffer in the \(Y\) space, the buffer is added in the quantile space.  That is, on a new test example \(X_\mathrm{test}\), DCP will output the interval 
    \[\left[\widehat{Q}(q_{\mathrm{low}} - b, X_\mathrm{test}),  ~\widehat{Q}(q_{\mathrm{high}} + b, X_\mathrm{test})\right],\]
    where \(b\) is a buffer value chosen in the calibration step of the conformal procedure to guarantee coverage.  

    \item Optimal Distributional Conformal Prediction via Quantile Regression (DCP-QR*), \cite{chernozhukov2021distributional}:  The optimal DCP is very similar to DCP, except that \(q_{\mathrm{low}}\) and \(q_{\mathrm{high}}\) need not be symmetric around the median (\(q = \frac{1}{2}\)).  Instead, they are chosen to provide the minimum volume interval that achieves the desired coverage.  We note that the buffer is still applied symmetrically in the quantile space. That is, the lower quantile is lowered by some value \(b\), and the upper quantile is raised by the same value \(b\).

    \item CD-Split \citep{izbicki2020flexible, izbicki2022cd}: 
    This method provides prediction sets based on the conditional density estimation and a partitioning of the feature space. 
    The conformity score in CD-split is based on a conditional density estimator, which allows the method to approximate the highest predictive density (HPD) set. The feature space is partitioned based on the profile of the conditional density estimator, and the cut-off values are computed locally within each partition. This approach enables CD-split to achieve local and asymptotic conditional validity while providing more informative prediction sets, especially for multimodal distributions.

    \item HPD-Split \cite{izbicki2022cd}:
    The HPD-split method outputs prediction sets based on the highest predictive density (HPD) sets of the conditional density estimation. Unlike CD-split, which partitions the feature space, HPD-Split uses the conformity score based on the conditional CDF of the condition density estimator. Since this conditional CDF is independent of the feature variable, HPD-Split does not require the partition of the feature space and tuning parameters for that as in CD-Split. When the conditional density estimation is accurate, HPD-Split converges to the highest predictive density (HPD) sets.
    

    \item Conformalized Dynamic Programming, \(k = 1\) and \(k = 5\):  We implement a modification of the procedure described in this work.  In the unsupervised setting, we described the dynamic programming procedure that outputs the minimum volume set of \(k\) intervals that contain a desired fraction of samples.  In this setting, given a new test example \(X\), we do not have access to samples.  Instead, we have access to a grid of estimated quantiles of \(Y\) given \(X\).  We implement a version of the dynamic programming procedure that operates on this quantile grid instead of a set of points, to output the minimum volume set of \(k\) intervals that cover at least the desired probability mass.  We can also modify our greedy contraction and expansion procedures to provide a nested system of sets for different coverage levels.  
\end{itemize}


\paragraph{Discussion.}  The results of our experiments are illustrated in Figure \ref{fig:supervised_experiments}.  Our experiments show that Conformalized Quantile Regression (CQR) and Distributional Conformal Prediction via Quantile Regression (DCP-QR) perform approximately as well as each other on this dataset, achieving average volume 1.42 and 1.48 respectively (see Figures \ref{subfig:cqr}, \ref{subfig:dcp-qr}).  

Optimal Distributional Conformal Prediction via Quantile Regression (DCP-QR*) achieves a significant improvement over DCP-QR on this data, achieving average volume 1.29 (see Figure \ref{subfig:dcp-qrstar}).  This is due to the fact that the distribution of \(Y\) values is not symmetric around, or peaked at the median \(Y\) value.  Thus, DCP-QR suffers a disadvantage, because it outputs intervals that are centered around the median in quantile space, and does not take into account the relative volumes of the quantiles in \(Y\) space.  DCP-QR* on the other hand, is able to take advantage of the fact that, for this data, quantiles close to 0 have very low volume, and output intervals that use these quantiles.   

While DCP-QR* uses information about the relative volume of the quantiles to choose \(q_{\mathrm{low}}\) and \(q_{\mathrm{high}}\), which define the output intervals before conformalization, it does not take the volume into account during the conformalization step.  Expanding the interval by a buffer value \(b\) that is small in quantile space, can lead to a large difference in \(Y\) space, increasing the volume of the output interval significantly.  For example in Figure \ref{subfig:dcp-qrstar}, the intervals for \(X\) just larger than 4 stretch very far into the negative \(Y\) region, as a small adjustment in quantile space is a large adjustment in \(Y\) space.  

This issue is avoided by our Conformalized Dynamic Programming (Conformalized DP) method with greedy expansion and contraction for \(k = 1\) interval.  Before conformalization, the interval output by Conformalized DP and DCP-QR* is the same: it is the volume optimal interval that achieves a given coverage according to the estimated c.d.f..  However, our method takes the relative volume of different quantiles into account in the conformalization step, and avoids the issue of expanding the interval in quantile space in directions that add too much volume in \(Y\) space.  This allows the method to achieve an improved average volume of 1.14 (see Figure \ref{subfig:conformalizeddpk-1}).  

An illustration of this issue is given in Figure \ref{fig:volume-aware-example}.  Suppose that for a new test example \(X\), the estimated conditional distribution of \(Y\) is skewed.  (In this illustration it is \(\chi^2(5)\).)  Suppose that our target coverage was 0.5, and in the calibration phase we are required to expand coverage to 0.7.  Both ConformalizedDP and DCP-QR* will start by calculating the minimum volume interval that captures 0.5 of the probability mass.  In this case it is the red region from \(x = 1.58\) to \(x = 5.14\) (i.e., the set of \(x\) such that \(f(x) > 0.12\), where \(f(x)\) is the p.d.f. of the distribution).  Then, each method must expand this interval to capture 0.7 of the probability mass.  DCP-QR* does this by adding two blue regions, each of which capture an additional 0.1 probability mass.  This results in expanding the interval significantly to the right, even though the density is low.  ConformalizedDP takes the volume (i.e., density) into account when expanding the interval, and produces the minimum volume interval that captures 0.7 of the distribution (i.e., the set of \(x\) such that \(f(x) > 0.085\)), in this example.  (We note that the expansion and contraction procedure of ConformalizedDP does not always result in the volume optimal prediction set for the adjusted coverage, only the original target coverage.  However, in this case, since the distribution is unimodal and \(k = 1\), we do indeed recover the volume optimal set even for the adjusted coverage.)  

Finally, we also implement Conformalized DP with \(k = 5\) intervals.  This allows us to fit to the multimodal shape of the \(Y\) data, and achieve a much lower average volume of 0.45 (see Figure \ref{subfig:conformalizeddpk-5}). 

\begin{figure}[H]
    \centering
    \begin{subfigure}{0.49\textwidth}
        \includegraphics[width=\textwidth]{figures/chi2-dcpqrstar.png}
        \caption{When expanding from the red region, coverage 0.5, to a region of coverage 0.7, DCP-QR* chooses the blue region with additional volume 2.56.}
    \end{subfigure}
    \hfill
    \begin{subfigure}{0.49\textwidth}
        \includegraphics[width=\textwidth]{figures/chi2-conformalizedDP.png}
        \caption{When expanding from the red region, coverage 0.5, to a region of coverage 0.7, Conformalized DP chooses the blue region with additional volume 1.96.}
    \end{subfigure}
    \caption{We illustrate the difference between DCP-QR* and Conformalized DP for \(k = 1\), on the example where the estimated conditional distribution of \(Y\) for a new \(X_\mathrm{test}\) is \(\chi^2(5)\).  We plot the intervals that are chosen by the methods against the p.d.f. of the estimated distribution.}
    \label{fig:volume-aware-example}
\end{figure}

\begin{figure}[H]
    \centering
    \begin{subfigure}{0.49\textwidth}
        \includegraphics[width=\textwidth]{figures/cqr-synthetic.png}
        \caption{Conformalized Quantile Regression (CQR), \cite{romano2019conformalized}, achieves average volume 1.42 and empirical coverage 70.62\%.}
        \label{subfig:cqr}
    \end{subfigure}
\end{figure}

\begin{figure}[H]\ContinuedFloat
    \begin{subfigure}{0.49\textwidth}
        \includegraphics[width=\textwidth]{figures/dcp-qr-synthetic.png}
        \caption{Distributional Conformal Prediction (DCP), \cite{chernozhukov2021distributional}, achieves average volume 1.48 and empirical coverage 71.6\%.}
        \label{subfig:dcp-qr}
    \end{subfigure}
    \hfill
    \begin{subfigure}{0.49\textwidth}
        \includegraphics[width=\textwidth]{figures/dcp-qrstar-synthetic.png}
        \caption{Optimal Distributional Conformal Prediction (DCP-QR*), \cite{chernozhukov2021distributional}, achieves average volume 1.29 and empirical coverage 71.06\%.}
        \label{subfig:dcp-qrstar}
    \end{subfigure}
    \hfill
    \begin{subfigure}{0.49\textwidth}
    \includegraphics[width=\textwidth]{figures/CD-split.png}
        \caption{CD-split Conformal Prediction, \cite{izbicki2022cd}, achieves average volume 1.83 and empirical coverage 69.94\%.}
        \label{subfig:CD-split}
    \end{subfigure}
    \hfill
    \begin{subfigure}{0.49\textwidth}
    \includegraphics[width=\textwidth]{figures/HPD-split.png}
        \caption{HPD-split Conformal Prediction, \cite{izbicki2022cd}, achieves average volume 1.75 and empirical coverage 69.44\%.}
        \label{subfig:HPD-split}
    \end{subfigure}
    \hfill
    \begin{subfigure}{0.49\textwidth}
    \includegraphics[width=\textwidth]{figures/conformalizedDP-k1-synthetic.png}
        \caption{Conformalized Dynamic Programming ($k = 1$), achieves average volume 1.14 and empirical coverage 74.04\%.}
        \label{subfig:conformalizeddpk-1}
    \end{subfigure}
    \hfill
    \begin{subfigure}{0.49\textwidth}
        \includegraphics[width=\textwidth]{figures/conformalizedDP-k5-synthetic.png}
        \caption{Conformalized Dynamic Programming ($k = 5$), achieves average volume 0.45 and empirical coverage 72.36\%.} 
        \label{subfig:conformalizeddpk-5}
    \end{subfigure}
    \caption{Comparison of supervised conformal prediction methods on simulated data from \cite{romano2019conformalized}.  All results are for a target coverage of 0.70.}
    \label{fig:supervised_experiments}
\end{figure}


\begin{figure}[H] 
    \centering
    \begin{subfigure}{0.49\textwidth}
    \includegraphics[width=\textwidth]{figures/bimodal_cqr.png}
        \caption{CQR, achieves average volume 4.10 and empirical coverage 71.54\%.}
        \label{subfig:bimodal_cqr}
    \end{subfigure}\\
    \hfill
    \begin{subfigure}{0.49\textwidth}
    \includegraphics[width=\textwidth]{figures/bimodal_dcp_qr.png}
        \caption{DCP-QR, achieves average volume 4.04 and empirical coverage 70.85\%.}
        \label{subfig:bimodal_dcp_qr}
    \end{subfigure}
    \hfill
    \begin{subfigure}{0.49\textwidth}
        \includegraphics[width=\textwidth]{figures/bimodal_dcp_qrstar.png}
        \caption{DCP-QR*, achieves average volume 4.05 and empirical coverage 69.66\%.} 
        \label{subfig:bimodal_dcp_qrstar}
    \end{subfigure}
    \hfill
    \begin{subfigure}{0.49\textwidth}
    \includegraphics[width=\textwidth]{figures/bimodal_cd_split.png}
        \caption{CD-Split, achieves average volume 3.69 and empirical coverage 69.86\%.}
        \label{subfig:bimodal_cd_split}
    \end{subfigure}
    \hfill
    \begin{subfigure}{0.49\textwidth}
        \includegraphics[width=\textwidth]{figures/bimodal_hpd_split.png}
        \caption{HPD-Split, achieves average volume 3.60 and empirical coverage 69.64\%.} 
        \label{subfig:bimodal_hpd_split}
    \end{subfigure}
\end{figure}

\begin{figure}[H]\ContinuedFloat
    \begin{subfigure}{0.49\textwidth}
    \includegraphics[width=\textwidth]{figures/bimodal_dp_k1_c70.png}
        \caption{Conformalized Dynamic Programming ($k = 1$), achieves average volume 4.00 and empirical coverage 68.98\%.}
        \label{subfig:bimodal_dp_k1}
    \end{subfigure}
    \hfill
    \begin{subfigure}{0.49\textwidth}
        \includegraphics[width=\textwidth]{figures/bimodal_dp_k2_c70.png}
        \caption{Conformalized Dynamic Programming ($k = 2$), achieves average volume 3.55 and empirical coverage 69.42\%.} 
        \label{subfig:bimodal_dp_k2}
    \end{subfigure}
    \caption{Comparison of supervised conformal prediction methods on simulated data from \cite{izbicki2020flexible}.  All results are for a target coverage of 0.70.}
    \label{fig:supervised_experiments_bimodal}
\end{figure}