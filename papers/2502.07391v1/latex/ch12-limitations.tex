\section{Limitations} \label{sec:limitations}
Despite beating all existing cutting-edge methods for generating sarcasm explanations for sarcastic multimodal social media posts, certain limitations still exist in \model\ which we address in this section. 

First, we extract external knowledge concepts in a deterministic way, that is, for a given token, it will always be linked to the same external knowledge concept regardless of the context surrounding the token. As shown in Appendix \ref{sec:appendix-error-analysis}, this can lead to the extraction of knowledge concepts that, despite being semantically related to the feature tokens, are not relevant in the given context. We believe that a method devised to dynamically extract relevant knowledge concepts based on the context surrounding a sample can help resolve this and can lead to better sarcasm reasoning. 

Second, we incorporate the target of sarcasm in our model by simply concatenating it with the textual tokens (\S \ref{sec:incorporation-of-target}). While the experimental results prove that incorporating the target of sarcasm in this manner leads to better explanation generations when compared to variants that do not do so, we hypothesize that incorporating this annotation in a more specialized manner can help the model learn more relevant semantic insights. For instance, perhaps fusing it with unimodal or multimodal feature representations in a manner that amplifies the more salient features with respect to the target of sarcasm can lead to a more explicit revelation of the underlying semantic incongruity.

Lastly, we recognize that using an annotated target of sarcasm leads to an additional manually provided input. This constrains the dataset since extending the dataset would now require extra manual annotations for the target of sarcasm as well. However, we suggest that this can be tackled by training another model to learn to generate the target of sarcasm given a multimodal social media post using the current dataset. We can use the output of this model as the input target of sarcasm in \model. This allows for the creation of a generative pipeline that does not require the target of sarcasm to be furnished manually as an input and reduces the potential manual work to be done in case of any extensions to the existing dataset since annotators will not be bound to annotate the target of sarcasm for the newly added samples. While such a pipeline would be useful, it would introduce a new challenge - ensuring that the generated target of sarcasm is up to par since in case it is not, it could end up pointing the explanation generation model in the wrong direction, leading to poor performance.