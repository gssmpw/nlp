\section{Related Work}
The field of automated text summarization, particularly in the context of supply chain risk analysis, has evolved significantly with the advent of LLMs. This section provides an overview of prior research, highlighting key advancements, methodologies, and persisting challenges.

\subsection{Advancements in Automated News Summarization}

Liu and Lapata (2019) demonstrated that pretrained transformer models offer substantial improvements in news summarization. By integrating extractive and abstractive techniques, they improved summary coherence and informativeness, particularly when fine-tuned for domain-specific applications \cite{Liu2019}.

Stiennon et al. (2020) explored human feedback-driven training for summarization. They developed a reward model based on human preference alignment, which significantly improved model performance compared to traditional supervised learning techniques \cite{Stiennon2020}.

Goyal et al. (2022) assessed GPT-3's capabilities in news summarization. They found that GPT-3 could generate high-quality summaries without explicit fine-tuning, often outperforming human-generated summaries in coherence and fluency \cite{Goyal2022}.

Wei et al. (2022) introduced chain-of-thought prompting, demonstrating how structured reasoning prompts enable LLMs to perform complex summarization tasks with greater contextual awareness \cite{wei2022chain}.

Liu et al. (2023) proposed using LLM-generated summaries as reference training data for smaller models. Their approach enhanced the efficiency of smaller-scale summarization models, presenting a cost-effective alternative to fine-tuning large models \cite{liu2023learning}.

Zhang et al. (2024) studied the impact of instruction tuning on zero-shot summarization. They found that aligning models with high-quality reference summaries significantly improved performance, often rivaling human-written summaries \cite{zhang2024benchmarking}.

Further, Zhang et al. (2024) provided a systematic review of text summarization. They examined the transition from extractive to abstractive techniques and highlighted key challenges, such as factual accuracy, handling long documents, and mitigating biases in generated content \cite{zhang2024systematic}.

An underexplored aspect of summarization is identifying related news articlesâ€”also known as news story chains. Gedikli et al. (2021) addressed this challenge in \cite{Gedikli2021} by leveraging clustering and Named Entity Recognition (NER) to create datasets for automated story chain detection, significantly reducing manual labeling efforts while maintaining high-quality outputs. Similarly, Stockem Novo and Gedikli (2023) \cite{StockemNovo2023} investigate BERT-based methods for near-duplicate news article detection, highlighting the importance of NER in identifying duplicate content. Accurate duplicate detection is essential for risk news summarization, as redundant information can distort risk assessments and lead to inefficiencies in decision-making.

\subsection{Research Gaps and Contributions of This Work}

Despite significant progress, several challenges remain unaddressed in the field of automated news summarization, particularly in the context of supply chain risk analysis. This study aims to bridge the following gaps:

\begin{itemize}
  \item \textbf{Domain-Specific Adaptation:} Most existing LLMs are not optimized for supply chain risk analysis. This study explores methods to tailor LLMs for industry-specific summarization.
  \item \textbf{Factual Accuracy and Bias Mitigation:} Ensuring the reliability of generated summaries remains a critical issue. We investigate strategies to enhance factual accuracy and mitigate biases \cite{zhang2024benchmarking}.
  \item \textbf{Real-Time Integration:} The deployment of LLMs for real-time news analysis and early risk detection has been insufficiently explored. This work examines the feasibility of integrating LLMs into dynamic monitoring systems.
  \item \textbf{Evaluation of Readability and Duplicate Detection:} While some models produce coherent summaries, their effectiveness in detecting duplicate information and maintaining readability in large-scale analysis remains unclear.
  \item \textbf{Fine-Tuning for Risk Identification:} There is a lack of research on optimizing LLMs specifically for identifying and categorizing risk-related information in news articles relevant to supply chain disruptions.
\end{itemize}

By addressing these gaps, our work contributes to the ongoing development of AI-driven risk analysis solutions, demonstrating how LLMs can be effectively leveraged to enhance supply chain monitoring and resilience.