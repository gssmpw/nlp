\section{Introduction}
\label{sec:intro}




Modular \gls{E2E} \gls{AD} is gaining attention for combining the strengths of traditional pipeline methods with strict \gls{E2E} approaches. 
In this framework, perception, prediction, and planning form the core set of tasks, which ideally complement one another to enhance overall system performance.
However, the modular \gls{E2E} framework also presents a multi-task learning challenge.
A poorly designed multi-task learning structure could not only fail to facilitate mutual learning but also adversely affect individual tasks, a phenomenon known as negative transfer~\cite{crawshaw2020multi}.
The prevalent modular \gls{E2E} approaches~\cite{hu2023planning, jiang2023vad, zheng2025genad, sun2024sparsedrive} typically employ a sequential structure (\cref{fig:intro_compare}a).
This structure aligns with how humans perform driving tasks and has demonstrated promising planning performance. However, these approaches exhibit negative transfer in object detection and tracking. In other words, the perception performance of jointly trained \gls{E2E} models is typically inferior to those trained without the motion prediction and planning tasks. 

\begin{figure}[t]
    \centering
    \includegraphics[width=1.0\linewidth]{figures/intro_comparison.pdf}
    \caption{\textbf{Comparison of \gls{E2E} structures.} In (a), semantic and motion learning occur sequentially. In (b), the multi-head structure parallelizes tasks with different heads; however, motion and semantic learning remain sequential in detection, tracking, and prediction. In (c), semantic and motion learning are performed in parallel without latent feature sharing or gradient propagation. In contrast, the exchange of information between the object and map perception modules is enhanced.}
    \label{fig:intro_compare}
\end{figure}

We analyze the underlying causes of negative transfer by inspecting the types of learned heterogeneous information: semantic and motion. Semantic information encompasses the categories of surrounding objects, lanes, crossings, \etc, while motion information describes the temporal changes occurring within the environment. Sequential methods~\cite{hu2023planning, jiang2023vad, zheng2025genad, doll2024dualad} execute these two processes in succession.
They first conduct detection and tracking and then use the extracted object features for trajectory prediction. This sequential design forces the features to contain motion information, compromising the initially learned semantic and leading to negative transfer in perception. The SHAP values analysis~\cite{NIPS2017_7062} provides supporting evidence for our argument.
Another \gls{E2E} structure is depicted in \cref{fig:intro_compare}b. It executes most tasks with different heads in parallel, as PARA-Drive~\cite{weng2024drive} and NMP~\cite{zeng2019end}. However, since detection and prediction remain sequential, the issue of negative transfer persists.


In this work, we propose \textbf{DMAD structure} (\cref{fig:intro_compare}c), \textbf{D}ividing and \textbf{M}erging motion and semantic learning for \gls{E2E} \textbf{A}utonomous \textbf{D}riving. DMAD addresses the issue of negative transfer by separating semantic and motion learning. Furthermore, it leverages correlations among semantic tasks by merging them.

For dividing, we propose \textbf{Neural-Bayes motion decoder}. We maintain a set of motion queries that attend to the sensor embeddings parallel to the object (detection and tracking) queries. The key difference between motion and object queries is that they are decoded into past and future trajectories rather than bounding boxes with classes. Motion and object queries share a single set of reference points, updated recursively by detection and prediction. It allows only limited information exchange between both types of queries, mediated through the reference points without gradient flow. Moreover, we calculate the object's velocity using the predicted trajectory with finite differences, thereby removing the requirement for object queries to learn the velocity directly. In this manner, the object query focuses on learning semantic and appearance features, while the motion query is dedicated to capturing motion features. The two types of heterogeneous information are learned separately along distinct paths, effectively preventing negative transfer. Notably, the DMAD structure promotes motion learning to the same level of semantic learning, treating detection, tracking, and prediction as concurrent tasks for the first time, to the best of our knowledge.

For merging, we propose \textbf{interactive semantic decoder} to enhance the exchange of semantic insights in detection and map segmentation. Object perception and map perception are inherently related tasks. Previous methods often overlook this connection, typically executing the two along parallel paths~\cite{hu2023planning, jiang2023vad, zheng2025genad}. DualAD~\cite{doll2024dualad} leverages this correlation but allows only object perception to learn from the map. Our method uses layer-wise iterative self-attention~\cite{vaswani2017attention} to enable mutual learning between object and map tasks, fostering positive transfer.

Experiments on the nuScenes~\cite{caesar2020nuscenes} dataset showcase the effectiveness of DMAD structure in mitigating negative transfer. Our approach achieves significant performance gains in perception and prediction, which benefits the planning module and outperforms state-of-the-art (SOTA) \gls{E2E} \gls{AD} models.

Our key contributions are summarized as follows:
\begin{itemize}
    \item We examine the similarity and heterogeneity among tasks in modular \gls{E2E} \gls{AD} and argue that the prevailing design—learning information for conflicting tasks within a single feature—is the cause of negative transfer in perception. We analyze SHAP values to validate this hypothesis. Conversely, we propose that information exchange between similar tasks can facilitate positive transfer.
    \item We propose DMAD, a modular \gls{E2E} \gls{AD} paradigm that divides and merges tasks according to the information they are supposed to learn. This design eliminates negative transfer between different types of tasks while reinforcing positive transfer among similar tasks.
    \item We introduce two decoders: the Neural-Bayes motion decoder for concurrent trajectory prediction with object detection and tracking; the interactive semantic decoder to enhance information sharing between object and map perception. The proposed decoders improve existing SOTA methods, leading to better performance across all tasks.
\end{itemize}










