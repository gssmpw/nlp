\section{Related work}
\mvspace{-2mm}
\paragraph{Human-AI complementarity.}

Many empirical studies of human-AI collaboration focus on AI-assisted human decision-making for legal, ethical, or safety reasons____.
However, a recent meta-analysis by ____ finds that, on average, human–AI teams perform worse than the better of the two agents alone. 
In response, a growing body of work seeks to evaluate and enhance complementarity in human–AI systems ____.
The present work differs from much of this prior work by approaching human-AI complementarity from the perspective of information value and use, including asking whether the human and AI decisions provide additional information that is not used by the other.
\mvspace{-2mm}
\paragraph{Evaluation of human decision-making with machine learning.}
Our work contributes methods for evaluating the decisions of human-AI teams____.
____ proposed that evaluations of human-AI collaboration should be based on the information that is available at the time of decisions.
% \jessica{can omit:} A significant portion of this literature addresses \textit{performative prediction}____, where predictions or decisions affect future outcomes. 
% Because counterfactual decisions’ outcomes remain unobserved, researchers typically rely on worst-case analyses to bound the potential performance ____. 
% Though these issues arise in many canonical human-AI collaboration tasks, we focus on standard ``prediction policy problems'' where the payoff can be translated into policy gains____.
According to this view, our work defines Bayesian best-attainable-performance benchmarks similar to several prior works____. 
Closest to our work, ____ model the expected performance of a rational Bayesian agent faced with deciding between the human and AI recommendations as the theoretical upper bound on the expected performance of any human-AI team.
This benchmark provides a basis for identifying exploitable information within a decision problem.

\mvspace{-3mm}
\paragraph{Human information in machine learning.}

Some approaches focus on automating the decision pipeline by explicitly incorporating human expertise in developing machine learning models, such as by learning to defer____.
____ propose multicalibration over human and AI model confidence information to guarantee the existence of an optimal monotonic decision rule.
____ propose a hypothesis testing framework to evaluate the added value of human expertise over AI forecasts.
Our work shares the motivation of incorporating human expertise, but targets a slightly broader scope by quantifying the information value for all available signals and agent decisions in a human–AI decision pipeline.