\documentclass[preprint,12pt]{elsarticle}
\usepackage{amssymb}
\usepackage{xurl}
\usepackage{comment}
\usepackage{multirow}
\usepackage{tabularx}
\usepackage{amsmath}
\usepackage{enumitem}
\usepackage{hyperref}
\usepackage{bookmark}
\usepackage{xcolor}
\usepackage{wasysym}
\usepackage{graphicx}
\usepackage{subfig}


%% The amsthm package provides extended theorem environments
%% \usepackage{amsthm}

\journal{To be determined}

\begin{document}

\begin{frontmatter}

\title{Factors influencing the perceived usability of mobile applications}
%\begin{comment}
\author[inst1]{Paweł Weichbroth*}
\affiliation[inst1]{organization={Gdansk University of Technology, Faculty of Electronics, Telecommunications and Informatics, Department of Software Engineering},
            city={Gdansk},
            country={Poland}, \newline *Corresponding Author: pawel.weichbroth@pg.edu.pl}
%\ead[inst1]{pawel.weichbroth@pg.edu.pl}
%\end{comment}

\begin{abstract}
The advent of mobile applications has brought new frontiers to usability studies. So far, the ongoing research has undertaken considerable efforts to model usability in such new challenging context. One of these endeavors is the PACMAD+3 model, which consists of a total of ten unique factors. However, to the best of our knowledge, little or no effort has been made to empirically evaluate these factors against perceived influence. With this in mind, the objective of this study is to explore this issue by evaluating the selected factors. To achieve this goal in a reliable and reproducible manner, we took advantage of previous attempts to conceptualize the mobile usability factors, but we contribute by operationalizing these theoretical constructs into observable and measurable phenomena. In this sense, the survey was designed and carried out on the sample of 838 users in order to evaluate the significance of the PACMAD+3 factors on the perceived usability of mobile applications. Our findings show that, on average, users rated efficiency as highly important, while the remaining seven, namely: cognitive load, errors, learnability, operability, effectiveness, memorability, and understandability, were rated as moderately important. The discussed results provide insight into the importance of usability attributes and quality criteria from both perspectives, ultimately facilitating and securing the design and development of mobile applications. Therefore, our research contributes to the field of human-computer interaction, with both theoretical and practical implications for mobile usability researchers, UX designers, and quality assurance engineers.
\end{abstract}

\begin{keyword}
usability \sep mobile application \sep factor \sep importance \sep significance
\end{keyword}

\end{frontmatter}

\section{Introduction}
\label{sec:introduction}
The introduction of the first smartphone in 2007 marked has changed the world computed and communicated \cite{ens2012guidelines}. It is well known that the "reinvention of the phone" has led to a combination of hardware and software features that have taken the quality of use to new heights \cite{moumane2016usability}. The benefits of smartphones include instant communication, digital consumption of social media, gaming and entertainment, just to name a few.

From the perspective of software vendors, the mobility paradigm introduces a different environment for applications, requiring significant changes in their design and development \cite{lee2004mobile, wasserman2010software}. Thus, usability has been revisited in the light of limited resources on the one hand and different user requirements on the other. However, little is known about the factors that influence the perceived usability of mobile applications.

While for user experience practitioners the term "usability" as a goal is equivalent to quality of use, which means that the product is used by real and satisfied users \cite{nascimento2016userbility, jeddi2020usability}. 
In this way of thinking, usability has two equivalent roles in design: as an attribute that must be designed into a product, and as the highest quality goal that ultimately aims at user satisfaction. For users of mobile applications, usability goes beyond mere functionality and includes factors related to a seamless and enjoyable interaction with the application \cite{adu2020development, manzano2023usability, shinozaki2024usability}. 

There have been a number of intensive research efforts to understand the nature and phenomena of mobile usability \cite{aryana2013mobile, da2019set, kivijarvi2023instrumental}, with a particular focus on identifying contributing factors \cite{ham2006conceptual, baharuddin2013usability, ghazizadeh2017quantitative}. 
However, despite nearly two dozen years of studies, the ongoing discussion has not yielded conclusive results due to the lack of uniformity in modeling mobile usability. One of the first attempts to find a unified model was made in 2013 by Harrison et al. \cite{harrison2013usability} and was recently updated in 2024 by Weichbroth \cite{weichbroth2024usability}. While the former consists of seven factors, the latter added three more. However, to the best of our knowledge, there is no study that evaluates the impact of all these factors on the perceived usability of mobile applications.

In order to fill this gap, as well as to provide a deeper understanding in this area, our study is guided by the above question and attempts to answer it through a literature review and survey. In short, while the review aims to conceptualize and operationalize both usability and interface design factors, the questionnaire aims to evaluate them by users of mobile applications. 

\section{Background and Motivation}
\label{Background}
In light of the results reported by \cite{weichbroth2020usability}, the most commonly adopted usability definition for mobile applications is ISO 9241-11, which is also considered valid in the current study.
Hence, usability is understood as the "extent to which a system, product or service can be used by specified users to achieve specified goals with effectiveness, efficiency and satisfaction in a specified context of use" \cite{ISO9242-11}.

For the sake of clarity, while the majority of studies refer to usability attributes as the notion of certain qualities of mobile applications, we will refer to usability factors in this paper due to the exclusive focus on user perceptions. Each factor is then manifested by a set of mobile application features or properties. 

According to ISO 9241-11 \cite{ISO9242-11}, the concept of usability can be broken down into three factors, namely:
\begin{itemize}
    \item effectiveness: “the accuracy and completeness with which users achieve specified goals”;
    \item efficiency: “the resources expended in relation to the accuracy and completeness with which users achieve goals”;
    \item satisfaction: “the comfort and acceptability of the work system to its users and other people affected by its use”.
\end{itemize}

Considering the above definitions from the user's perspective, only effectiveness and efficiency are subject to evaluation due to their nature. In other words, satisfaction is excluded from our study as it is a result of the physical interaction between a user and a mobile application.

It should be noted that the "context of use" is defined as the "characteristics of users, tasks, and organizational and physical environments" \cite{ISO9242-11}. It is a critical concept in human-centered design and mobile usability studies. It refers to the specific environment, conditions, and characteristics in which a product, system, or interface is used. Understanding the context of use is essential for usability design and evaluation to be relevant and actionable.

The literature review shows the lack of consensus regarding the usability attributes of mobile applications. It should be noted that a lot of research has been carried out in this area. Researchers have defined usability itself in different ways and specified different attributes. However, the recent study conducted by Weichbroth \cite{weichbroth2024usability} has informed our research as this paper attempts to find a consensus by synthesizing the state of the art literature in the field of mobile usability. 
In particular, the paper introduces a consolidated universal usability model for mobile applications, termed PACMAD+3. Through the lens of existing human-computer interaction theory, and by employing a mix of qualitative and quantitative methods, this model appears to synthesize the current body of knowledge in a comprehensive and reliable manner. 

The PACMAD+3 model consists of ten attributes divided into three groups:
\begin{itemize}
    \item ISO 9241-11: effectiveness, efficiency, satisfaction.
    \item PACMAD: learnability, memorability, errors, cognitive load.
    \item Others: understandability, ease of use, operability.
\end{itemize}

Given the context of the current research, we also exclude ease of use for similar reasons in the case of satisfaction. Therefore, a total of eight attributes (factors) are further conceptualized and operationalized. 

\section{Factors Conceptualization and Operationalization}
This section is divided into subsections that reflect unique usability attributes. First, an attribute definition is provided along with commonly used measurement metrics. Second, each factor is then operationalized by a set of manifest variables that correspond to a particular mobile application feature or the result of an interaction between a user and a mobile application. Each particular variable is assigned a unique five-character code, where the first four characters are the short name of the attribute (fixed part) and the last character is the number (dynamic part). To present this information in a readable way, we used a tabular format. It's also easy to interpret and takes less time.

\subsection{Effectiveness}
Effectiveness is the ability of a user to complete a task in a specified context \cite{harrison2013usability, parsazadeh2018framework}, and is measured by assessing whether or not participants can complete a set of specified tasks to estimate the task completion rate \cite{miguel2017voice}. 

From the user perspective, the ability to perform a given task is supported by four application properties, given in Table \ref{tab:oper-effectiveness}.

\begin{table}[h]
\caption{Mobile Effectiveness Operationalization.}
\label{tab:oper-effectiveness}
\footnotesize
\begin{tabular}{|l|p{9cm}|p{2.5cm}|}
\hline
\textbf{Code}  & \textbf{Feature}     & \textbf{Source} \\ \hline
ES1 &  total number of steps required to complete the task & \cite{restuputri2022role}, \cite{weichbroth2020usability} \cite{weichbroth2022empirical}        \\ \hline
ES2 &  autofill form feature      &  \cite{rukzio2008automatic}, \cite{oesch2021emperor}, \cite{simmons2021systematization}      \\ \hline
ES3 &  automatic login   &   \cite{zhu2019riskcog}, \cite{shin2023heuristic}      \\ \hline
ES4 &  access to frequently used functions & \cite{mahamad2007user}, \cite{kern2009design}, \cite{yang2022influence} \\ \hline
\end{tabular}
\end{table}

In mobile devices, a task is considered to be efficiently designed if a number of required actions is as low as possible for a user to perform. Having said that the following three mobile application features facilitate task performance.  
First, the autofill feature of the mobile application has been introduced to save time and maximise convenience, during the task performance by the user. Second, with auto-login enabled, an application will pop-up the user's credentials whenever the user visits a login page, saving time and effort by eliminating the need to enter a username and password. 
Third, the three-bar ("hamburger") menu navigation, which facilitates access to frequently used functions, has become widespread due to the physical limitations of small smartphone screens.

\subsection{Efficiency}
Efficiency is the ability of the user to complete their task with speed and accuracy \cite{nosseir2012mobile, hutahaean2020identifying}. This attribute reflects the productivity of a user while using the application \cite{bevan2008classifying}. Efficiency can be measured in a number of ways, such as the time to complete a given task, or the number of keystrokes required to complete a given task. These requirements are supported by four application properties, given in Table \ref{tab:oper-efficiency}.

\begin{table}[h]
\caption{Mobile Efficiency Operationalization.}
\label{tab:oper-efficiency}
\footnotesize
\begin{tabular}{|l|p{9cm}|p{2.5cm}|}
\hline
\textbf{Code}  & \textbf{Feature}     & \textbf{Related Work} \\ \hline
EY1 & duration of the application starting and closing & \cite{dixon2016usability}, \cite{nam2016user}, \cite{weichbroth2024usabilitya}        \\ \hline
EY2 & duration of content loading   & \cite{barakovic2015multidimensional},   \cite{wang2021effect}, \cite{wang2023waiting}  \\ \hline
EY3 & application performance continuity (no deadlocks) &  \cite{gao2014mobile}, \cite{majrashi2018task}      \\ \hline
EY4 & duration of the application response to the performed action & \cite{von2016usability}, \cite{saleh2017evaluating}, \cite{yu2020unravelling}  \\ \hline
\end{tabular}
\end{table}

Duration is the primary metric for evaluating the performance of a mobile application. In this context, the measurement refers to both the launch and shutdown time of the mobile application. Besides, depending on the its nature, other areas may also be monitored and acted upon to optimize performance by mitigating resource consumption. 
A deadlock in the mobile computing environment refers to the state where two or more threads are incapable of proceeding because each is waiting for the other to release an occupied resources, preventing any progress \cite{Hussain2024}. One of the most common effects of deadlocks is application performance degradation, manifested by significant response delays that can affect other running applications. Other more severe effects include application crashes, hangs, unresponsiveness or, in the worst case, fatal errors. 

\subsection{Learnability}
Learnability is the ease with which a user can gain proficiency with an application \cite{az2019evaluating}. 
It typically reflects how long it takes a person to be able to use the application effectively \cite{irwansyah2018radio}. In order to measure learnability, a user’s performance during a series of tasks is observed to measure how long it takes these participants to reach a pre-specified level of proficiency. 

Table \ref{tab:oper-learnability} presents app features support learning user's capabilities.
\begin{table}[h]
\caption{Mobile Learnability Operationalization}
\label{tab:oper-learnability}
\footnotesize
\begin{tabular}{|l|p{9cm}|p{2.5cm}|}
\hline
\textbf{Code} & \textbf{Feature}    & \textbf{Related Work} \\ \hline
LY1 & intuitive use  &  \cite{marsh2008design}, \cite{britton2013intuitive}, \cite{naumann2010benchmarks}      \\ \hline
LY2 & learning duration of how to use the application functions & \cite{liu2021case},  \cite{ramdowar2023comprehensive}, \cite{xiao2024design} \\ \hline
LY3 & changes resulting from the application update &  \cite{mathur2017impact}, \cite{huang2022updating}      \\ \hline
\end{tabular}
\end{table}

Under the umbrella of mobile usability, the key principle revolves around learnability, emphasizing the ease with which visitors can accomplish tasks during their first interaction. Essentially, the mobile application should be effortless to understand and navigate, achieved through intuitive design, instinctive navigation, and informative prompts to help users navigate the interface. 
It is well known that reducing learning time increases perceived usability by raising task completion effectiveness and ultimately user satisfaction.

\subsection{Memorability}
Memorability is the degree to which a user can remember how to use an application in an effective way \cite{weichbroth2020usability} which is the result of the ability to recognize its functions and menus \cite{nurdina2021usability}.
Generally, some applications are used sporadically while some are used on a regular basis. However, both are expected to be used without the need to learn and remember how to use them. Human perception is developed by a combination of attention, eye movements and memory \cite{lahrache2018visualizations}. Thus, memorability can be measured by asking users to perform a series of tasks after having become proficient with the use of the application, and afterwards asking them to perform similar tasks after a period time of inactivity. To determine how memorable the application was a comparison can be made between the two sets of results \cite{harrison2013usability}. 

Table \ref{tab:oper-memo} shows an app properties which supports user's ability to memorize its effective usage.

\begin{table}[h]
\caption{Operationalization of the attribute Memorability for mobile applications}
\label{tab:oper-memo}
\footnotesize
\begin{tabular}{|l|p{9cm}|p{2.5cm}|}
\hline
\textbf{Code}  & \textbf{Feature}   & \textbf{Related Work} \\ \hline
MY1 & using the application does not require memorizing its specific options, messages and symbols & \cite{coursaris2011meta}, \cite{afif2021evaluating}, \cite{nizamani2021novel}      
\\ \hline
MY2 & using the application does not require memorizing previously input data &  \cite{abd2019evaluation}, \cite{hsu2014usability}      
\\ \hline
MY3 & displaying task hints &   \cite{hung2012enhancing}, \cite{bodrunova2018impact}     \\ \hline
MY4 & description (metadata) of locally stored data & \cite{nickerson2015managing}, \cite{nickerson2016selecting}, \cite{azadi2020mobile}  \\ \hline
\end{tabular}
\end{table}

By setting a common language and providing standard reference points, design patterns minimize 
misunderstandings to a minimum and establish consistency. Specifically, the use of known messages, signs, and symbols in a familiar structure enhances the user experience by promoting familiarity and intuitiveness as users encounter consistent interactions across applications and solutions. This not only reduces the learning curve for users, but also contributes to overall usability.
User input on a relatively small touch screen is a time-consuming task. As a result, the user's ability to remember the data entered decreases over time. The application should inform the user, if needed, about the saved information.

A mobile application can preset task hints for the necessary checkpoints. In fact, displaying task hints can provide guidance to users, especially new or inexperienced ones, by offering step-by-step instructions on how to perform certain actions or tasks within the app. On the other hand, task hints can highlight features or functionalities that users might not be aware of, thus improving the discoverability of those features.

Last but not least, while metadata aims to categorize and label data, it provides the essential semantics of the locally collected data by extending the limited description. In other words, the better the user understands the data, the greater the perceived usefulness in a given application.

\subsection{Errors}
A usability attribute termed as Errors reflects how well the user can perform the desired tasks without making errors, while the estimated user rate can be used to infer the simplicity of a system \cite{harrison2013usability}. Such information allows one to identify areas that are problematic for users and ultimately improve those areas in subsequent development iterations of the mobile application. 

On the other hand, users should make few errors while using an application, and if they do make errors, they should be able to easily recover from them \cite{ali2022mobile} by being provided with context-sensitive help and meaningful feedback when errors occur \cite{seffah2006usability}. By understanding the nature of these errors, it becomes possible to prevent them from occurring in next versions of the application \cite{parsazadeh2018framework}. 

That being said, Errors, as the mobile usability attribute, is manifested by the four application features, listed in Table \ref{tab:oper-errors}. 

\begin{table}[h]
\caption{Operationalization of the attribute Errors for mobile applications}
\label{tab:oper-errors}
\footnotesize
\begin{tabular}{|l|p{9cm}|p{2.5cm}|}
\hline
\textbf{Code}  & \textbf{Feature}   & \textbf{Related Work} \\ \hline
ER1 & ability to withdraw  the last performed action without losing the already input data &
\cite{franke2012mobile}, \cite{alvarado2018layered}, \cite{nunez2020model}       \\ \hline
ER2 & messages to prevent possible errors  &  \cite{inostroza2012usability}, \cite{kuparinen2013introducing} \\ \hline
ER3 & performing a wrong gesture does not result in application errors  & \cite{heuwing2015usability}, \cite{pushp2018privacyshield}, \cite{wu2020user}       \\ \hline
ER4 & verification of the correctness of the input data & \cite{schneider2008investigation}, \cite{qin2011usability}, \cite{george2018usability}  \\ \hline
\end{tabular}
\end{table}

Bearing in mind the different circumstances and associated limitations that a user may face, a mobile application should have the ability to skip an operation while preserving the user's input, such as form data or written notes. More generally, it refers to data persistence, which is the ability of an application to store and retrieve data after it is closed or the device is restarted. 

A message is a basic means of communication between an application and a user. A message can also assist a user by providing additional explanations or a possible solution. Considering current UX practices, error messages are implemented in a reactive manner, meaning that an application reacts to a specific situation (e.g. bad user password). In this sense, both error-preventive design and implemented data quality controls aim at reducing or even eliminating error-prone user behavior.

%Note that all four of these properties can be verified during application testing. The underlying goal, then, is to make the application more tolerant of user actions and to facilitate communication between applications.

\subsection{Cognitive Load}  %jest w ankiecie
Cognitive load refers to the amount of cognitive processing required by the user to use the application \cite{harrison2013usability}. 
In traditional usability studies a common assumption is that the user is performing only a single task and can therefore concentrate completely on that task. However, in a mobile context users will often be performing a second action in addition to using the mobile application \cite{deegan2015complex}. Thus, in this context, cognitive load includes mental load and mental effort, reflecting users intrinsic load which is a combination of extraneous load, and germane load \cite{sweller1998cognitive}. While the former refers to those mental resources which does not aid using mobile application, then the latter refers to the effort needed to use memory and intelligence to process information into schema.

Table \ref{tab:oper-cognitive-load} presents the manifesting variables that are used to operationalize the attribute of cognitive load. 

\begin{table}[h]
\caption{Mobile Cognitive Load Operationalization}
\label{tab:oper-cognitive-load}
\footnotesize
\begin{tabular}{|l|p{9cm}|p{2.5cm}|}
\hline
\textbf{Code}  & \textbf{Feature}  & \textbf{Related Work} \\ \hline
CL1 & application allows other activities to be performed at the same time & \cite{deegan2015complex}, \cite{weichbroth2020usability}, \cite{karczewska2021usability}   \\ \hline
CL2 & no user interaction required while the app is running in the background   & \cite{smith2017adaptive}, \cite{deegan2011usability}      \\ \hline
CL3 & ability to use other applications or device functions while the app is running in the background &   
\cite{harrison2013usability}, \cite{daud2023design}, \cite{deegan2014mobile}     \\ \hline
CL4 & ability to perform another activity without having to stop one already started  & \cite{harrison2013usability}, \cite{alasmari2020effect}, \cite{weichbroth2024usability}  \\ \hline
\end{tabular}
\end{table}

%CL4 & duration of mental effort during interaction with the application &  \cite{ibili2019assessing}, \cite{ilany2019mobile}, \cite{schobel2020measuring}    \\ \hline

As can be seen, cognitive load is operationalized by four indicators related to the level of user involvement required to perform tasks.
Here, intrinsic cognitive load is determined by the intrinsic nature of the information to be read and understood, more specifically, by the number of interacting information components that the performing task comprises. Note that, novice app users, with little or none any prior knowledge of the task, have to engage more mental effort, however, over time, as learning progresses, information components become incorporated (or chunked) into cognitive schemata. Therefore, the intrinsic cognitive load that is imposed by a task is much higher for novices than for more advanced app users. 

Note that extraneous cognitive load arises from the performance of tasks that require the user to engage in cognitive processes that do not directly contribute to the task by forcing the user to mentally integrate temporally or spatially separate but interrelated. For instance, a user may simultaneously check the physical route with the directions provided by a mobile navigation map due to current traffic jams or suddenly occurring adverse events. Therefore, extraneous cognitive is the result of confounding variables whose presence affects the perceived usability. 

In one perspective, researchers argue that germane load is synonymous with intrinsic load, since without intrinsic load there would be no germane load to facilitate the construction of new knowledge \cite{greenberg2023revisiting}, while in a more robust view, germane load is dependent on intrinsic load, it cannot become an autonomous source of cognitive load \cite{leppink2015evolution}. On the other hand, one can question the application capability to prioritize germane load, which in this case refers to the essential information that users need to acquire new knowledge effectively, unless such purpose is intentionally implemented and facilitated by specific app features. In this vein, for instance, one could point to the military services who typically take a great responsibility of the undertaken actions based on the information delivered by the mobile solutions. 

To summarize, considering the above arguments on the one hand, and since our goal is to operationalize the cognitive goal in a generic way and thus applicable to the broad types of mobile applications, the assigned manifest variables exclusively represent the intrinsic load. However, for contextual studies that aim to evaluate user behavior or perceptions under the intervention of the specific stimulus, other variables should be formulated and investigated.

\subsection{Understandability} %feedback and guidance 10 
Understandability refers to the capability of the mobile application to allow users to understand its application and to easily performs tasks \cite{ammar2019usability}. From the perspective of the interaction, understandability can be considered as the degree to which the application's messages are understood by the user. Typically, an individual message is the app reaction to user's performed action. In other words, such feedback can bring the form of graphics, text or a combination of both, and haptics, sounds and spoken messages as well. One can distinguish  three types of messages: input requests, status notifications, and error messages \cite{pfister2011affective}. 
Under specific circumstances, an app can guide a user by ad hoc delivering a brief documentation, context-aware help or a form-based wizards. 

Having said that, Table \ref{tab:oper-understand} presents the features that manifest mobile application understandability.

\begin{table}[h]
\caption{Operationalization of the attribute Understandability for mobile applications}
\label{tab:oper-understand}
\footnotesize
\begin{tabular}{|l|p{9cm}|p{2.5cm}|}
\hline
\textbf{Code}  & \textbf{Feature}  & \textbf{Related Work} \\ \hline
UY1 & availability of help or a user manual    & \cite{ahmad2021spiritual}, \cite{afrin2022usability}, \cite{castilla2023digital}  \\ \hline
UY2 & autocomplete feature with default values  &  \cite{chang2013improving}, \cite{piplani2018ict}, \cite{holstrom2020effects}      \\ \hline
UY3 & visual confirmation of the performed action  &  \cite{goumopoulos2017development}, \cite{perez2020evaluation}, \cite{tovide2022signsupport}     \\ \hline
UY4 & word completion feature  & \cite{agosti2003managing}, \cite{chittaro2007mobile}, \cite{bilal2018analyzing}   \\ \hline
UY5 & input data description  &  \cite{liang2017mobile}, \cite{ali2022mobile}    \\ \hline
\end{tabular}
\end{table}

Detailed help or tutorials allow users to solve common problems on their own, lowering the learning curve by making the application more accessible, especially for new users. Autocomplete speeds up data entry by predicting what the user is likely to type next, reducing the number of keystrokes required and making interaction more efficient, while default values provide quick options, minimizing user effort and making the application more user-friendly and helpful. In addition, new users may find it easier to learn and use the it when they see suggestions and default values, which can reduce the initial learning curve.

Visual confirmation provides immediate feedback, letting users know that their actions have been recognized and processed. This is essential for maintaining user confidence and ensuring they feel in control of the application, as well as guiding users through their interactions with the application and helping them understand what is happening at each step.

By design, word completion feature offers convenience and consistency. The former allows users to quickly select suggested words from a list, which is especially beneficial on mobile devices with smaller keyboards and screen sizes, while the latter ensures that commonly used words and phrases are entered consistently, which is important for maintaining data quality and governance.

Providing input data descriptions help users understand what information is required, in particular on the format, units, and type of data expected, which can be particularly helpful for complex or unfamiliar inputs. Note that in some cases, providing data descriptions is necessary to comply with regulatory standards and to ensure that all required information is collected accurately and completely. In general, descriptions help communicate the purpose and meaning of each data field, reducing ambiguity and improving overall communication between the application and the user.

Above properties being an application outputs, passively and actively support user confidence during tasks’ performance. The actions undertaken should neither distract the user nor obscure the current display. Providing appropriate feedback and guidance leads to a better understanding of the application's functionality.

\subsection{Operability} %W ankiecie jest visibility
Operability is the ability of the mobile application to allow the user to operate and control it in different contexts of use \cite{weichbroth2024usability}. 

More specifically, when visual on-screen objects are clearly visible and easily accessible within the interface, users can more effectively navigate the application and perform tasks. In this line of thinking, visibility seems to be a closely related concept understood in terms of perceived affordances or signifiers \cite{norman2010gestural}. An affordance is the design aspect of an object that suggests how the object should be used \cite{mcgrenere2000affordances}, while signifiers are visual cues that indicate the affordances of an application.

Due to the physical limitations of mobile devices, the complexity of graphics and icons has been reduced to a minimum, while the elements of the user interface have to be of a size that allows a user to easily manipulate them by performing certain touch gestures, on the one hand, and still have to be understood by preserving the true meaning. 

Table \ref{tab:oper-operability} shows the variables used to operationalize the operability of the mobile application.

\begin{table}[h]
\caption{Operationalization of the attribute Operability for mobile applications}
\label{tab:oper-operability}
\footnotesize
\begin{tabular}{|l|p{9cm}|p{2.7cm}|}
\hline
\textbf{Code}  & \textbf{Feature}  & \textbf{Related Work} \\ \hline
OP1 & location of text boxes and buttons & \cite{kangas2005applying}, \cite{nguyen2015reverse}, \cite{natarajan2018p2a} \\ \hline
OP2 & size of text boxes and buttons  & \cite{kangas2005applying}, \cite{deniz2019comparison}       \\ \hline
OP3 & language used to describe text boxes  &  \cite{kangas2005applying}, \cite{kim2022speak}, \cite{wen2023droidbot}   \\ \hline
OP4 & current progress of the task being performed by the application  & \cite{mansar2012usability},  \cite{moroyoqui2022smartasko}, \cite{nakagawa2022implementation}  \\ \hline
\end{tabular}
\end{table}

The location of text boxes and buttons in mobile applications aims to establish a clear visual hierarchy, maintain contextual relevance, and guide user focus. Appropriate size allows to organize input fields and buttons in an accessible and intuitive sequence, matching the user's natural flow of interaction. 
Using language relevant to the specific context of each text box provides a better understanding of the purpose of each input field by explaining the context necessary for accurate data entry. 
In the case of complex task performance, displaying the current progress of tasks informs the user that the application is working on their request and gives them a sense of the remaining work needed to complete the task. On the other hand, a real-time update progress message assures the user that their input has been acknowledged and is being processed by the application.

In practice, the elements on the screen must be adequately aligned and contrasted \cite{cunha2013heuristic}. Taking into account physical limitations of the mobile devices applying these properties leads to an increase in the effectiveness of the user in completing the task.

\section{Methodology}
\label{sec:methodology}
After establishing the theoretical foundation through the conceptualization and operationalization of mobile usability factors, the following research question is posed: What factors, and to what extent, directly influence the perceived usability of mobile applications?
In order to answer it, we used survey as a research method \cite{fowler2013survey}, following and adapting the guidelines developed by Bennett et al. \cite{bennett2011reporting} and Passmore et al. \cite{passmore2002guidelines}. To collect the necessary data, we designed a questionnaire with scalable responses that allow us to elicit unambiguous responses that can be further quantified and compared across a sample of respondents.

\subsection{Survey design}
The survey was divided into three parts. 
The first part began with an introductory statement and a set of standard demographic questions to identify respondents age, gender, education and professional experience in number of years. 
In second part, respondents were asked to select the types of mobile devices (tablet, e-book reader, and smartphone) and their respective operating systems (Android OS, Apple iOS, Windows OS, BlackBerry OSx, and other) and the corresponding built-in operating system, utilizing for at least 3 months.
The third part of the survey contained a list of 46 items to rate, based on the respondent's experience, the extent to which the following factors affect the perceived usability of the mobile applications you use. In this regard, we use the measurement scale which was divided into five categories: (1) very weak, (2) weak, (3) moderate, (4) strong and (5) very strong.

\subsection{Data gathering and pre-processing}
Data gathering was carried out both on the paper and electrically.
In the case of the former type was submitted in case of the lack of the desktop computers since the questionnaire web page was not optimized for mobile devices, while in case of the latte type, a link was sent by the email to the people who agreed to participate in the study. We used a well-known and free of charge survey administration software tool to collect data.

The study period was 6 months, i.e. March-August 2018, using convenience sampling method \cite{emerson2015convenience}. 
It means that data was collected from the population members who were conveniently available to participate in the study. This method involves getting respondents wherever the circumstances and willingness to participate occurred. Therefore, no inclusion (exclusion) criteria were identified and applied prior to the selection process. It is worth noting that respondents did not receive any form of reward for completing the survey.

All paper-based responds were manually input into the database. The gathered data was exported in the plain text format, and processed in the spreadsheet desktop application.
Next the merged dataset was analyzed to exclude unreliable respondents who have selected: (a) all possible answers in the the second section, OR in the third section, OR (b) the same answer in the sixth section. In total, six respondents were excluded, since they met at least one of the three above conditions. The Table \ref{tab:survey-summary} provides a summary of the survey in this scope.

\begin{table}[h]
\centering
\small
\begin{tabular}{|l|l|l|}
\hline
\textbf{Observations} & \textbf{Volume}   & \textbf{Share}     \\ \hline
Valid        & 838 & 99.30\% \\ \hline
Excluded     & 6   & 0.71\%  \\ \hline
All          & 844 & 100\% \\ \hline
\end{tabular}
\caption{\label{tab:survey-summary}The summary of collected data, after initial pruning.}
\end{table}

As one can observe, the valid number of respondents was 838, therefore the exclusion rate was about 0.71\%, which can be considered very low.

\subsection{Sample Characteristics}
The mean age of 838 participants who gave their age was 25.5 years (SD 8.00). The youngest respondent was 16 while the oldest was 65. The sample was divided into six age groups, depicted by Table \ref{tab:sample-age}.

\begin{table}[h]
\centering
\small
\begin{tabular}{|l|l|l|}
\hline
\textbf{Age group} & \textbf{Volume}  & \textbf{Share}     \\ \hline
19 or less      & 106   & 12,65\% \\ \hline
20--24          & 425   & 50,72\% \\ \hline
25--29          & 111   & 13,25\% \\ \hline
30--34          & 91    & 10,86\% \\ \hline
35--39          & 44    & 5,25\% \\ \hline
40 or more      & 61    & 7,28\%  \\ \hline
\textbf{All}    & \textbf{838}   & \textbf{100\%} \\ \hline
\end{tabular}
\caption{\label{tab:sample-age}The age distribution of the respondents.}
\end{table}

As once can notice, over half of the study participants (50.72\%) ranged from 20 to 24 years old. Not surprisingly, the larger part of the remaining (25.9\%) concerns the older (13.25\%) and the younger group (12.65\%). The rest (23.38\%) includes the groups of subject at the age of 30 and greater.

%gender
The sample consists of 354 (42.2\%) women (\female)  and 484 (57.8\%) men (\male).
%education level
The basic education was declared by 68 (8.1\%) respondents (28 women and 40 men), secondary by 483 (57.6\%, 189 women and 294 men), while higher education by 287 (34.2\%, 137 women and 150 men). 
%proffesional experience 

No work experience was reported by 335 respondents (40\%, 134 \female, and 201 \male), 
one year by 75 (8.9\%, 28 \female, and 49 \male), two years by 91 (10.9\%, 35 \female, and 56 \male), and three years or more by 337 (40.2\%, 157 \female, and 180 \male). 

For another question related to the mobile devices and embedded operating systems used, we divided the survey sample into two mutually exclusive subsets based on the gender of the respondents. In this regard, the details in case of women and men are provided by Table \ref{tab:device-OS-w} and Table \ref{tab:device-OS-m}, respectively.

\begin{table}[h]
\centering
\small
\begin{tabular}{|l|l|l|l|l|l|}
\hline
\textbf{Device} \textbackslash \textbf{OS} & \textbf{Android} & \textbf{iOS} & \textbf{Windows} & \textbf{BlackBerry} & \textbf{Other} \\ \hline
Tablet        & 98 (27.68\%)   & 26 (7.34\%)   & 25 (7.06\%) & 0 (0\%) & 3 (0.85\%)     \\ \hline
Ebook Reader  & 24  (6.78\%)   & 9   (2.54\%)   & 3 (0.85\%)  & 1 (0.28\%)  & 24 (6.78\%)    \\ \hline
Smartphone    & 249  (70.34\%)  & 90  (25.42\%) & 18 (5.08\%) & 0  (0\%)    & 0  (0\%)   \\ \hline
\end{tabular}
\caption{\label{tab:device-OS-w}The device and built-in operating system used by women.}
\end{table}

Among women (Table \ref{tab:device-OS-w}), the most popular mobile device was a smartphone, with Android (70.34\%), iOS (25.42\%) and Windows (5.08\%) on board. The second place took Tablet, with Android (27.68\%), iOS, (7.34\%) and Windows (7.06\%), as the host operating systems. The ebook reader proved to be the least popular, where only Android share was significant (6.78\%), as the share of the two remaining OS did not exceed five percent, except those with no specified operating system (6.78\%).

\begin{table}[h]
\centering
\small
\begin{tabular}{|l|l|l|l|l|l|}
\hline
\textbf{Device} \textbackslash  \textbf{OS} & \textbf{Android} & \textbf{iOS} & \textbf{Windows} & \textbf{BlackBerry} & \textbf{Other} \\ \hline
Tablet        & 152 (31.40\%)  & 47 (9.71\%) & 27 (5.58\%) & 0 (0\%) & 9 (1.86\%)     \\ \hline
Ebook Reader  & 25  (5.17\%) & 6  (1.24\%) & 7 (1.45\%) & 0 (0\%) & 48 (9.92\%)   \\ \hline
Smartphone    & 375 (77.48\%) & 106 (21.9\%) & 20 (4.13\%) & 0 (0\%) & 0 (0\%) \\ \hline
\end{tabular}
\caption{\label{tab:device-OS-m}The device and built-in operating system used by men}
\end{table}
When considering men (Table \ref{tab:device-OS-m}), and comparing with women, the results are similar. Again, the most popular mobile device was smartphone, running under Android (77.48\%), iOS (31.04\%) and Windows (5.17\%), followed by tablet with Android (31.40\%), iOS (9.71\%), and Windows (5.58\%), along with ebook reader on the non-specified OS (9.92\%) and Android (5.17\%). 

Interestingly, 20 respondents (7 \female, and 13 \male) declared not using smartphones at all, whereas 34 (7 \female, and 27 \male) reported using two smartphones, and 4 (2 \female, and 2 \male) even three smartphones at the same time.

\section{Results}
%factors evaluation results
Quantitative data from the questionnaire were analyzed using a well-known commercial spreadsheet software package, along with jamovi, a free and open source software for data analysis and statistical tests. Analyses were carried out using descriptive statistics such as: absolute and relative frequencies, mean (\textit{M}), standard deviation (\textit{SD}), coefficient of variation (\textit{CV}), skewness coefficient (\textit{Sk}), and coefficient of kurtosis ($\kappa$). We used Cronbach's $\alpha$ and McDonald's $\omega$ in terms of measuring and evaluating the internal consistency. We have presented the results of all calculations in tabular form for the sake of clarity and ease of understanding.

\begin{table}[]
\footnotesize
\begin{tabular}{|l|l|l|l|l|l|}
\hline
\textbf{ID} / \textbf{Score} & \textbf{very weak (1)} & \textbf{weak (2)} & \textbf{moderate (3)}  & \textbf{high (4)} & \textbf{very high (5)} \\ \hline
ES1               & 33 (3.93\%)   & 90 (10.73\%)  & 280 (33.41\%) & 278 (33.17\%) & 157 (18.73\%) \\ \hline
ES2               & 39 (4.65\%)   & 94 (11.21\%)  & 305 (36.39\%) & 271 (32.33\%) & 129 (15.39\%) \\ \hline
ES3               & 37 (4.41\%)   & 62 (7.39\%)   & 251 (29.95\%) & 274 (32.69\%) & 214 (25.53\%) \\ \hline
ES4               & 32 (3.81\%)   & 54 (6.44\%)   & 247 (29.47\%) & 309 (36.87\%) & 196 (23.38\%) \\ \hline
EY1               & 26 (3.1\%)    & 65 (7.75\%)   & 160 (19.09\%) & 235 (28.04\%) & 352 (42\%)    \\ \hline
EY2               & 22 (2.62\%)   & 54 (6.44\%)   & 157 (18.73\%) & 237 (28.28\%) & 368 (43.91\%) \\ \hline
EY3               & 22 (2.62\%)   & 45 (5.36\%)   & 146 (17.42\%) & 176 (21\%)    & 449 (53.57\%) \\ \hline
EY4               & 20 (2.38\%)   & 51 (6.08\%)   & 146 (17.42\%) & 251 (29.95\%) & 370 (44.15\%) \\ \hline
LY1               & 18 (2.14\%)   & 34 (4.05\%)   & 225 (26.84\%) & 283 (33.77\%) & 278 (33.17\%) \\ \hline
LY2               & 39 (4.65\%)   & 83 (9.9\%)    & 248 (29.59\%) & 256 (30.54\%) & 212 (25.29\%) \\ \hline
LY3               & 57 (6.8\%)    & 127 (15.15\%) & 277 (33.05\%) & 246 (29.35\%) & 131 (15.63\%) \\ \hline
MY1               & 38 (4.53\%)   & 62 (7.39\%)   & 275 (32.81\%) & 300 (35.79\%) & 163 (19.45\%) \\ \hline
MY2               & 35 (4.17\%)   & 74 (8.83\%)   & 271 (32.33\%) & 284 (33.89\%) & 174 (20.76\%) \\ \hline
MY3               & 37 (4.41\%)   & 89 (10.62\%)  & 340 (40.57\%) & 266 (31.74\%) & 106 (12.64\%) \\ \hline
MY4               & 46 (5.48\%)   & 97 (11.57\%)  & 351 (41.88\%) & 244 (29.11\%) & 100 (11.93\%) \\ \hline
ER1               & 28 (3.34\%)   & 59 (7.04\%)   & 214 (25.53\%) & 236 (28.16\%) & 301 (35.91\%) \\ \hline
ER2               & 32 (3.81\%)   & 79 (9.42\%)   & 251 (29.95\%) & 304 (36.27\%) & 172 (20.52\%) \\ \hline
ER3               & 24 (2.86\%)   & 68 (8.11\%)   & 245 (29.23\%) & 283 (33.77\%) & 218 (26.01\%) \\ \hline
ER4               & 33 (3.93\%)   & 65 (7.75\%)   & 238 (28.4\%)  & 307 (36.63\%) & 195 (23.26\%) \\ \hline
CL1               & 36 (4.29\%)   & 60 (7.15\%)   & 228 (27.2\%)  & 248 (29.59\%) & 266 (31.74\%) \\ \hline
CL2               & 34 (4.05\%)   & 85 (10.14\%)  & 293 (34.96\%) & 266 (31.74\%) & 160 (19.09\%) \\ \hline
CL3               & 35 (4.17\%)   & 51 (6.08\%)   & 241 (28.75\%) & 258 (30.78\%) & 253 (30.19\%) \\ \hline
CL4               & 35 (4.17\%)   & 61 (7.27\%)   & 189 (22.55\%) & 255 (30.42\%) & 298 (35.56\%) \\ \hline
UY1               & 63 (7.51\%)   & 131 (15.63\%) & 293 (34.96\%) & 235 (28.04\%) & 116 (13.84\%) \\ \hline
UY2               & 43 (5.13\%)   & 112 (13.36\%) & 321 (38.3\%)  & 254 (30.31\%) & 108 (12.88\%) \\ \hline
UY3               & 36 (4.29\%)   & 87 (10.38\%)  & 292 (34.84\%) & 297 (35.44\%) & 126 (15.03\%) \\ \hline
UY4               & 59 (7.04\%)   & 116 (13.84\%) & 320 (38.18\%) & 252 (30.07\%) & 91 (10.85\%)  \\ \hline
UY5               & 59 (7.04\%)   & 114 (13.6\%)  & 343 (40.93\%) & 222 (26.49\%) & 100 (11.93\%) \\ \hline
OP1               & 19 (2.26\%)   & 47 (5.6\%)    & 224 (26.73\%) & 334 (39.85\%) & 214 (25.53\%) \\ \hline
OP2               & 15 (1.78\%)   & 65 (7.75\%)   & 307 (36.63\%) & 298 (35.56\%) & 153 (18.25\%) \\ \hline
OP3               & 28 (3.34\%)   & 88 (10.5\%)   & 300 (35.79\%) & 276 (32.93\%) & 146 (17.42\%) \\ \hline
OP4               & 23 (2.74\%)   & 93 (11.09\%)  & 288 (34.36\%) & 313 (37.35\%) & 121 (14.43\%) \\ \hline
\end{tabular}
\caption{\label{tab:all-features-shares}Calculated absolute and relative frequency of scores reflecting the level of impact on perceived usability given to the features by the study respondents.}
\end{table}

Table \ref{tab:all-features-shares} provides the results of calculated absolute and relative frequency of scores, showing the level of the features impact on perceived usability, given by the study respondents. 
As one can notice, out of the 32 features evaluated individually and while considering the highest calculated relative share, thirteen received a high score (4), twelve a moderate score (3), and seven a very high score (5). In addition, further analysis of the distribution of score values allows us to conclude that in case of all features the relative share of very low scores (1) was the lowest, followed by the low scores (2).  

\begin{table}[]
\begin{tabular}{|l|l|l|l|l|l|}
\hline
\textbf{ID} / \textbf{Statistics}  & \textbf{M} & \textbf{SD}  & \textbf{CV} & \textbf{Sk} & \textbf{$\kappa$}     \\ \hline
ES1 & 3.5203  & 1.0376 & 0.2948 & -0.3694 & -0.3116  \\ \hline
ES2 & 3.4260  & 1.0282 & 0.3001 & -0.3291 & -0.2431  \\ \hline
ES3 & 3.6754  & 1.0697 & 0.2910 & -0.5585 & -0.1631  \\ \hline
ES4 & 3.6957  & 1.0192 & 0.2758 & -0.5993 & 0.0720   \\ \hline
EY1 & 3.9809  & 1.0962 & 0.2754 & -0.8842 & -0.0256  \\ \hline
EY2 & 4.0442  & 1.0583 & 0.2617 & -0.9491 & 0.1802   \\ \hline
EY3 & 4.1754  & 1.0638 & 0.2548 & -1.1480 & 0.4949   \\ \hline
EY4 & 4.0740  & 1.0343 & 0.2539 & -0.9991 & 0.3494   \\ \hline
LY1 & 3.9177  & 0.9748 & 0.2488 & -0.6569 & 0.0616   \\ \hline
LY2 & 3.6193  & 1.1048 & 0.3052 & -0.4797 & -0.4107  \\ \hline
LY3 & 3.3186  & 1.1147 & 0.3359 & -0.2682 & -0.5676  \\ \hline
ES4 & 3.6957  & 1.0192 & 0.2758 & -0.5993 & 0.0720   \\ \hline
MY1 & 3.5823  & 1.0264 & 0.2865 & -0.5183 & 0.0005   \\ \hline
MY2 & 3.5823  & 1.0426 & 0.2910 & -0.4575 & -0.1970  \\ \hline
MY3 & 3.3759  & 0.9829 & 0.2911 & -0.2867 & -0.0677  \\ \hline
MY4 & 3.3043  & 1.0062 & 0.3045 & -0.2565 & -0.1174  \\ \hline
ER1 & 3.8628  & 1.0860 & 0.2812 & -0.6847 & -0.2315  \\ \hline
ER2 & 3.6026  & 1.0339 & 0.2870 & -0.4940 & -0.1820  \\ \hline
ER3 & 3.7196  & 1.0283 & 0.2765 & -0.5021 & -0.2551  \\ \hline
ER4 & 3.6754  & 1.0379 & 0.2824 & -0.5862 & -0.0495  \\ \hline
CL1 & 3.7733  & 1.1012 & 0.2918 & -0.6403 & -0.2222  \\ \hline
CL2 & 3.5167  & 1.0388 & 0.2954 & -0.3491 & -0.2998  \\ \hline
CL3 & 3.7673  & 1.0752 & 0.2854 & -0.6310 & -0.1129  \\ \hline
CL4 & 3.8592  & 1.1090 & 0.2874 & -0.7787 & -0.0865  \\ \hline
UY1 & 3.2506  & 1.1090 & 0.3412 & -0.2275 & -0.5456  \\ \hline
UY2 & 3.3246  & 1.0264 & 0.3087 & -0.2495 & -0.2914  \\ \hline
UY3 & 3.4654  & 1.0080 & 0.2909 & -0.3998 & -0.1345  \\ \hline
UY4 & 3.2387  & 1.0486 & 0.3238 & -0.2891 & -0.3068  \\ \hline
UY5 & 3.2267  & 1.0535 & 0.3265 & -0.2106 & -0.2970  \\ \hline
OP1 & 3.8079  & 0.9567 & 0.2512 & -0.6176 & 0.1656   \\ \hline
OP2 & 3.6074  & 0.9312 & 0.2581 & -0.2572 & -0.2081  \\ \hline
OP3 & 3.5060  & 1.0050 & 0.2867 & -0.3066 & -0.2742  \\ \hline
OP4 & 3.4964  & 0.9626 & 0.2753 & -0.3403 & -0.1852  \\ \hline
\end{tabular}
\caption{\label{tab:ds-all-features}Summary of descriptive statistics calculated for mobile usability features.}
\end{table}

In this line of thinking, the importance of the usability attributes is also evident from the results of the descriptive statistics calculated. Reading Table \ref{tab:ds-all-features} across the rows, and taking into account the 5-point scale used, it seems clear that on average three features were considered highly important and the rest moderately important. A standard deviation, a measure of how dispersed the data is in relation to the mean, is in the range between 0,9312 and 1,1147. In addition, its relative size compared to the mean is in the range of 24.88\% and 34.12\%. While a rule of thumb says that a coefficient of variation (\textit{CV}) of 30\% or less is a desirable level, slightly higher \textit{CV}s are acceptable in survey research due to the natural, inherent variability in human perception. 

We used Cronbach's alpha ($\alpha$) and McDonald's omega ($\omega$) to measure the internal consistency of each usability factor, along with a set of features assembled. In this regard, Table \ref{tab:reliability-all-items} presents the values of both calculated measures, along with item-rest correlation, used to evaluate the association of the feature with the total score on the other features. 
The general rule is that $\alpha$ or $\omega$ values between 0.6 and 0.90 indicate acceptable internal consistency in exploratory research. Coefficient values below 0.5 are usually unacceptable, while those between 0.5 and 0.6 can still be considered sufficient. In our study, although only one indicator (LY2) is 0.509, while the others range from 0.605 to 0.897, and all item-rest correlations are greater than 0.3, internal consistency seems to be achieved. 

\begin{table}[]
\begin{tabular}{|l|l|l|l|}
\hline
\textbf{ID} / \textbf{Statistics}  & \textbf{Item-rest correlation} & \textbf{Cronbach's $\alpha$} & \textbf{McDonald's $\omega$} \\ \hline
ES1 & 0.470                 & 0.804        & 0.808        \\ \hline
ES2 & 0.634                 & 0.725        & 0.745        \\ \hline
ES3 & 0.662                 & 0.709        & 0.712        \\ \hline
ES4 & 0.650                 & 0.717        & 0.734        \\ \hline
EY1 & 0.793                 & 0.897        & 0.898        \\ \hline
EY2 & 0.840                 & 0.881        & 0.883        \\ \hline
EY3 & 0.810                 & 0.891        & 0.893        \\ \hline
EY4 & 0.792                 & 0.897        & 0.899        \\ \hline
LY1 & 0.479                 & 0.605        & 0.605        \\ \hline
LY2 & 0.548                 & 0.509        & 0.512        \\ \hline
LY3 & 0.457                 & 0.634        & 0.637        \\ \hline
MY1 & 0.710                 & 0.786        & 0.788        \\ \hline
MY2 & 0.722                 & 0.780        & 0.784        \\ \hline
MY3 & 0.667                 & 0.805        & 0.816        \\ \hline
MY4 & 0.611                 & 0.828        & 0.834        \\ \hline
ER1 & 0.684                 & 0.811        & 0.812        \\ \hline
ER2 & 0.710                 & 0.800        & 0.804        \\ \hline
ER3 & 0.710                 & 0.800        & 0.803        \\ \hline
ER4 & 0.652                 & 0.825        & 0.825        \\ \hline
CL1 & 0.766                 & 0.812        & 0.815        \\ \hline
CL2 & 0.650                 & 0.858        & 0.858        \\ \hline
CL3 & 0.735                 & 0.825        & 0.828        \\ \hline
CL4 & 0.727                 & 0.828        & 0.831        \\ \hline
UY1 & 0.585                 & 0.841        & 0.842        \\ \hline
UY2 & 0.713                 & 0.806        & 0.810        \\ \hline
UY3 & 0.697                 & 0.811        & 0.814        \\ \hline
UY4 & 0.671                 & 0.817        & 0.820        \\ \hline
UY5 & 0.646                 & 0.824        & 0.828        \\ \hline
OP1 & 0.638                 & 0.767        & 0.771        \\ \hline
OP2 & 0.696                 & 0.741        & 0.742        \\ \hline
OP3 & 0.641                 & 0.767        & 0.777        \\ \hline
OP4 & 0.573                 & 0.797        & 0.806        \\ \hline
\end{tabular}
\caption{\label{tab:reliability-all-items}Summary of features Reliability statistics.}
\end{table}

\begin{figure}[htbp]
    \centering
    \small
    \subfloat[Effectiveness]{{\includegraphics[width=0.45\textwidth, height=4.8cm]{effectiveness.png}}}
    \subfloat[Efficiency]{{\includegraphics[width=0.45\textwidth, height=4.6cm]{efficiency.png}}}
    \hfill
    \subfloat[Learnability]{{\includegraphics[width=0.45\textwidth, height=4.6cm]{learnability.png}}}
    \subfloat[Memorability]{{\includegraphics[width=0.45\textwidth, height=4.6cm]{memorability.png}}}
    \hfill
    \subfloat[Errors]{{\includegraphics[width=0.45\textwidth, height=4.6cm]{errors.png}}}
    \subfloat[Cognitive Load]{{\includegraphics[width=0.45\textwidth, height=4.6cm]{cognitive-load.png}}}
    \hfill
    \subfloat[Understandability]{{\includegraphics[width=0.45\textwidth, height=4.6cm]{understandability.png}}}
    \subfloat[Operability]{{\includegraphics[width=0.45\textwidth, height=4.6cm]{operability.png}}} 
    \caption{Correlation heatmaps of mobile usability features.}
    \label{fig:heatmaps}
\end{figure}

Figure \ref{fig:heatmaps} shows the correlation between features for each individual attribute, depicted in the form of a heat map. By analyzing the values, one can conclude that the strength of the correlations varies greatly between the attributes, ranging from weak (less than 0.4) to very strong (0.8 or more). On the other hand, the lack of opposite, negative correlations suggests that there are no opposing effects of individual features on the perceived usability of mobile applications. Since all features exhibit a positive correlation, it can be argued that the test results indicate reliability. In addition, Table \ref{tab:attributes-importance} shows reliability statistics ($\alpha$ and $\omega$) for all eight mobile usability attributes. For each attribute, we obtained values that met the minimum threshold of 0.6, implying acceptable reliability in the case of learnability, while good or excellent for the others. 

In summary, we find these results satisfactory and therefore proceed with further analysis to answer the stated research question: \textbf{What factors, and to what extent, directly influence the perceived usability of mobile applications?}
Based on the data collected from the sample in the size of 838 respondents, we found out that efficiency as the only one showed the high influence on the perceived usability of mobile applications. The rest of the attributes had a moderate level of importance, in descending order considering the mean values, starting with Cognitive Load, Errors, Learnability, Operability, Effectiveness, Memorability, and Understandability. In this regard, Table \ref{tab:attributes-importance} presents the detailed results, including the calculated mean, standard deviation and coefficient of variation.

\begin{table}[]
\begin{tabular}{|l|l|l|l|l|l|}
\hline
\textbf{Factor} & \textbf{M}  & \textbf{SD} & \textbf{CV}  & \textbf{Cronbach's $\alpha$} & \textbf{McDonald's $\omega$} \\ \hline
Efficiency        & 4.07 & 0.951 & 0.234 & 0.916        & 0.917        \\ \hline
Cognitive Load    & 3.73 & 0.915 & 0.245 & 0.868        & 0.869        \\ \hline
Errors            & 3.72 & 0.869 & 0.234 & 0.850        & 0.851        \\ \hline
Learnability      & 3.62 & 0.832 & 0.230 & 0.679        & 0.687        \\ \hline
Operability       & 3.60  & 0.774 & 0.215 & 0.816        & 0.819        \\ \hline
Effectiveness     & 3.58 & 0.815 & 0.228 & 0.792        & 0.798        \\ \hline
Memorability      & 3.46 & 0.836 & 0.242 & 0.842        & 0.844        \\ \hline
Understandability & 3.30 & 0.830  & 0.252 & 0.851        & 0.853        \\ \hline
\end{tabular}
\caption{\label{tab:attributes-importance}Summary of mobile usability factor importance and reliability statistics.}
\end{table}

\section{Discussion}
\subsection{Implications for theory}
Our results have confirmed the importance of the eight attributes on the perceived usability of mobile applications derived from the PACMAD+3. Our results have confirmed the importance of the eight attributes for the perceived usability of mobile applications derived from PACMAD+3. However, their importance to our respondents differs from the general opinion where effectiveness, efficiency, and satisfaction are highlighted as the three most important factors \cite{johnson2020usability}. Obviously, this does not mean that existing mobile usability theory needs to be revisited. On the contrary, the importance of individual utility attributes may depend on many different determinants. During the data collection, the author personally collected many valuable verbal comments from the respondents. For example, for mobile gamers, the duration of launching an application is not that important, since by design a game launched on a mobile device takes relatively more time compared to an everyday mobile application such as an email client or a photo gallery. Thus, the generalizability of the results should be considered as the first limitation of our study. 

On the other hand, throughout our discussion we have both explicitly and implicitly emphasized the need to specify usability in a context of use. In addition, considering the limited functionality of mobile applications compared to their desktop equivalents, the variety of usability issues has unexpectedly magnified \cite{vasa2012preliminary, genc2017systematic, alqahtani2020insights} over time. For this reason, the ongoing discussion about mobile usability modeling is not a closed issue.  Indeed, considerable efforts have been made to address various usability issues \cite{heo2009framework, hensher2021scoping, schlichtig2024building}. Nevertheless, our study is based on a specific, newly introduced model, namely PACMAD+3.  While its generic nature makes it applicable in a wide scope, the contextless nature of the investigated attributes can be seen as a second limitation of our study. 

Evidently, more research is needed to fill these gaps. While other data samples may yield more evidence-based findings, the contextual settings may reveal hidden facets of the qualities that users expect from specific mobile solutions. It should be noted that the PACMAD+3 model does not impose any restrictions on research. On the contrary, it is an open reference model, without fixed relationships between attributes, nor limited by a fixed feature design. Thus, further research can cover the entire set of attributes or just a subset. In this line of thinking, a similar approach can be applied to feature selection.

\subsection{Implications for practice}
Our findings show that respondents praised all efficiency features the most. Actually, users expect fast performance, which means an efficient app responds quickly to input. On the other hand, an efficient app provides a seamless experience that keeps users active and engaged. Undeniably, applications that are fast and easy to use encourage frequent interaction, which can lead to higher user retention rates \cite{zuniga2019tortoise}. By focusing on efficiency, software vendors can develop mobile applications that are not only comfortable to use, but also reliable enough to reach a wider audience. But as many lessons learned show \cite{leitner2007usability, redlarski2016hard, inupakutika2022performance}, efficiency is not a one-time goal. On the contrary, it is an ongoing process in app development. Therefore, one should consider implementing continuous testing and optimization practices throughout the lifecycle.

On top of that, every task must be executable, regardless of the user's knowledge and skill level. Desirably, a task should require as few steps as possible to achieve the desired result. Therefore, the ultimate goal should be zero steps, which means eliminating or reducing user's workload by combining two or more tasks into one. That being said, effectiveness is measured by the percentage of tasks completed \cite{ferreira2022impact}, and more specifically by the number of steps required \cite{weichbroth2020usability}. In practice, effective user interface design follows three principles: utility, consistency, and accessibility \cite{UX-principles2023}. While in the first place usually workshops are organized with the participation of the actual users to get and better understand their needs and requirements \cite{canbazoglu2016developing}, then cognitive walkthroughs are used to identify usability issues from the perspective of user actions while using a mobile application \cite{jadhav2013usability}.

In this line of thinking, however in a broader view, the goal of the usability evaluation is to determine whether the user is likely to succeed at each step of the tasks performed, particularly with the goal of identifying and documenting any errors that occur. On the other hand, a cognitive walkthrough is a technique used to evaluate the learnability \cite{Salazar2022}. Since quality of use over time involves comparing the usability of a mobile application for experienced and novice users \cite{marrella2018measuring}, targeted testing is required when redesigning the user interface, or implementing additional features. For many software practitioners, the first imperative is simplified navigation, meaning easy and intuitive navigation, as a key driver for engaging and retaining users \cite{Shweta2024}.

While operability, memorability, and understandability are interrelated notions, mutually reinforcing to overall usability, interaction design appears to play a major role in the user's perception of its underlying logic and meaning. Pointing out the need for user testing for mobile applications is certainly not new.  However, interaction with mobile applications presents several challenges. 
First, while interaction with desktop computers relies on a mouse and keyboard, which provide more precise control but less direct engagement with screen objects, mobile users interact with touch gestures such as tapping, pinching, and swiping, which provide a more direct and tactile experience. 
Second, mobile (smaller) screens require more concise content and adaptive layouts that support both portrait and landscape orientation. 
Third, mobile applications rely on virtual keyboards and voice input, which can be less efficient for text-heavy tasks but more convenient for short inputs.

To summarize. Any application that fails to satisfy users is considered a failure. Therefore, the development process should be approached with one goal in mind: maximum application usability and user satisfaction. The easiest way to establish a long-term strategy is to perform usability testing with clearly defined usability metrics. It seems that not only observable properties play an important role for the user, but also latent variables that are not always easy or unambiguous to measure. Therefore, in practice, the presented operationalization of the PACMAD+3 model should be adapted, taking into account the actual application features, as well as the current needs of the user. 

\subsection{Study Contributions}
Our contributions to the field of mobile human-computer interaction can be summarized in two distinct but mutually complementary parts. The first is the operationalization of the factors that constitute the PACMAD+3 mobile usability model. To the best of our knowledge, this is the first attempt to date that has ever been made. In addition, while typically latent variables are operationalized by meaningful statements, yet either intangible and untied to a specific application property or feature, our study stays in opposite to such approach, whenever the nature of a particular factor pretends its operationalization through the observable and tangible qualities or objects. The second contribution is an evaluation of mobile usability factors and corresponding features based on survey data collected from 838 respondents. Specifically, we provide evidence-based results showing their level of influence on the perceived usability of mobile applications. Such knowledge is valuable for at least two reasons. From a theoretical perspective, the strength and direction of the effects of individual features have been empirically demonstrated, while from a practical view, designers and developers can adopt and adapt specific features to enable users to perform tasks more efficiently.

\subsection{Threats to validity}
Since we used convenience sampling, not all members of the population have an equal opportunity to participate in the study. However, to mitigate this threat, we collected data through multiple channels, including telephone contacts and peers on social media networks. In this way, our respondents represented different professional groups, occupied different roles, and varied in gender, age, and education level. 
On the other hand, respondents reported using a variety of mobile applications in both their personal and professional spheres. 

The threat of invalid responses was mitigated by making the survey voluntary, with no incentives promised at the beginning of the survey. The majority of the questionnaires were submitted in paper form in the physical presence of the author. A preliminary screening was carried out under favorable conditions. In this way, a few cases were excluded from the sample for at least one of the following reasons: skipping one or more questions, selecting all available answers, or giving false answers, regarding age, work experience, or indicating the use of non-existent mobile applications. Furthermore, while it was technically possible to complete the survey more than once, we found no evidence of this in the data. Again, due to the effort required to complete the survey, we consider multiple entries from the same respondent to be highly unlikely.

The threat of bias in item wording was mitigated during the design process. The survey included 32 features expressed in natural language. Their names were taken from the relevant literature, including research and review papers, books, and gray literature such as reports, working papers, and websites. Finally, the coded themes were validated by referencing related studies that also used the same terms in a similar context. In addition, we also randomly asked respondents, immediately after returning the completed questionnaire, if any items were misunderstood.

The threat associated with the 5-point Likert scale used involves fewer response choices, resulting in a narrower range of opinions collected. However, the 5-point scale is said to be easy for people to understand and use \cite{arkorful2022voter} and is considered as one of the most widely used \cite{ginters2023pragmatic}.
In particular, a neutral response seems to be more tangible, ensuring that respondents don't lose interest. The Likert scale was also provided with a corresponding numerical descriptors. In addition, in order to reduce extreme response bias, neither positive nor negative emotional traits were contained in the survey items.

\section{Conclusions}
Undeniably, usability in general stands for user acceptance of mobile applications \cite{alqahtani2015investigation, hajesmaeel2022most, camilleri2023functionality}. However, if one asks about the importance of certain factors that contribute to mobile usability, there are many voices around us that convincingly tell us which ones are relevant. 
Our study brings a better understanding of usability for mobile applications by evaluating the influence of eight factors borrowed from the PACMAD+3 model. In our opinion, the reported findings are useful for both researchers and practitioners, contributing to theory and practice by confirming the validity and importance of the model. It should be noted that our results also raise the possibility of using evaluated features in quality assurance strategy, at the top of the mobile software development process. Nevertheless, our paper does not pretend to be the last word on the subject, but further studies are needed to extend the frontiers of knowledge in this area. 

In the area of mobile application usability, future research on the problem of maintaining application quality in use could be expanded to include other factors related to context awareness, security, and responsiveness. In addition, one may also address issues arising from integration with other systems, including autonomous cars, hardware devices, desktop computers, home automation devices, portable and wearable computer device, just to name a few.  
Undoubtedly, the next milestone in mobile human-computer interaction will be the use of machine learning techniques for real-time user interface personalization based on explicit and implicit features. It seems that the emerging revolution may revalue and reformulate the principles and patterns of mobile user interface design and development, ultimately and irrevocably changing the way we understand usability.

\begin{thebibliography}{99}
\bibitem{ens2012guidelines}Ens, B., Eskicioglu, R. \& Irani, P. Guidelines for designing awareness-augmented mobile DUIs. {\em International Journal Of Human-Computer Interaction}. \textbf{28}, 730-736 (2012)

\bibitem{moumane2016usability}Moumane, K., Idri, A. \& Abran, A. Usability evaluation of mobile applications using ISO 9241 and ISO 25062 standards. {\em SpringerPlus}. \textbf{5} pp. 1-15 (2016)

\bibitem{lee2004mobile}Lee, V., Schneider, H. \& Schell, R. Mobile applications: architecture, design, and development. (Prentice Hall PTR,2004)

\bibitem{wasserman2010software}Wasserman, A. Software engineering issues for mobile application development. {\em Proceedings Of The FSE/SDP Workshop On Future Of Software Engineering Research}. pp. 397-400 (2010)

\bibitem{nascimento2016userbility}Nascimento, I., Silva, W., Gadelha, B. \& Conte, T. Userbility: a technique for the evaluation of user experience and usability on mobile applications. {\em Human-Computer Interaction. Theory, Design, Development And Practice: 18th International Conference, HCI International 2016, Toronto, ON, Canada, July 17-22, 2016. Proceedings, Part I 18}. pp. 372-383 (2016)

\bibitem{jeddi2020usability}Jeddi, F., Nabovati, E., Bigham, R. \& Khajouei, R. Usability evaluation of a comprehensive national health information system: relationship of quality components to users’ characteristics. {\em International Journal Of Medical Informatics}. \textbf{133} pp. 104026 (2020)

\bibitem{adu2020development}Adu, M., Malabu, U., Malau-Aduli, A. \& Malau-Aduli, B. The development of My Care Hub mobile-phone app to support self-management in Australians with type 1 or type 2 diabetes. {\em Scientific Reports}. \textbf{10}, 7 (2020)

\bibitem{manzano2023usability}Manzano-Monfort, G., Paluzie, G., D\'{\i}az-Gegúndez, M. \& Chabrera, C. Usability of a mobile application for health professionals in home care services: A user-centered approach. {\em Scientific Reports}. \textbf{13}, 2607 (2023)

\bibitem{shinozaki2024usability}Shinozaki, M., Saito, D., Tomita, K., Nakada, T., Nomura, Y. \& Nakaguchi, T. Usability evaluation of a glove-type wearable device for efficient biometric collection during triage. {\em Scientific Reports}. \textbf{14}, 9874 (2024)

\bibitem{aryana2013mobile}Aryana, B. \& Clemmensen, T. Mobile usability: experiences from Iran and Turkey. {\em International Journal Of Human-Computer Interaction}. \textbf{29}, 220-242 (2013)

\bibitem{da2019set}Da Costa, R., Canedo, E., De Sousa, R., Albuquerque, R. \& Villalba, L. Set of usability heuristics for quality assessment of mobile applications on smartphones. {\em IEEE Access}. \textbf{7} pp. 116145-116161 (2019)

\bibitem{kivijarvi2023instrumental}Kivijärvi, H. \& Pärnänen, K. Instrumental usability and effective user experience: Interwoven drivers and outcomes of Human-Computer interaction. {\em International Journal Of Human–Computer Interaction}. \textbf{39}, 34-51 (2023)

\bibitem{ham2006conceptual}Ham, D., Heo, J., Fossick, P., Wong, W., Park, S., Song, C. \& Bradley, M. Conceptual framework and models for identifying and organizing usability impact factors of mobile phones. {\em Proceedings Of The 18th Australia Conference On Computer-Human Interaction: Design: Activities, Artefacts And Environments}. pp. 261-268 (2006)

\bibitem{baharuddin2013usability}Baharuddin, R., Singh, D. \& Razali, R. Usability dimensions for mobile applications-a review. {\em Res. J. Appl. Sci. Eng. Technol}. \textbf{5}, 2225-2231 (2013)

\bibitem{ghazizadeh2017quantitative}Ghazizadeh, F. \& Vafadar, S. A quantitative evaluation of usability in mobile applications: An empirical study. {\em 2017 International Symposium On Computer Science And Software Engineering Conference (CSSE)}. pp. 1-6 (2017)

\bibitem{harrison2013usability}Harrison, R., Flood, D. \& Duce, D. Usability of mobile applications: literature review and rationale for a new usability model. {\em Journal Of Interaction Science}. \textbf{1} pp. 1-16 (2013)

\bibitem{weichbroth2024usability}Weichbroth, P. Usability of mobile applications: A consolidated model. {\em IEEE Access}. (2024)

\bibitem{weichbroth2020usability}Weichbroth, P. Usability of mobile applications: a systematic literature study. {\em Ieee Access}. \textbf{8} pp. 55563-55577 (2020)

\bibitem{ISO9242-11}ISO ISO 9241-11:2018(en) Ergonomics of human-system interaction — Part 11: Usability: Definitions and concepts. (2018), https://www.iso.org/obp/ui/\#iso:std:iso:9241:-11:ed-2:v1:en [Accessed on: 02.11.2023]

\bibitem{parsazadeh2018framework}Parsazadeh, N., Ali, R. \& Rezaei, M. A framework for cooperative and interactive mobile learning to improve online information evaluation skills. {\em Computers \& Education}. \textbf{120} pp. 75-89 (2018)

\bibitem{miguel2017voice}Miguel-Hurtado, O., Guest, R. \& Lunerti, C. Voice and face interaction evaluation of a mobile authentication platform. {\em 2017 International Carnahan Conference On Security Technology (ICCST)}. pp. 1-6 (2017)

\bibitem{restuputri2022role}Restuputri, D., Masudin, I. \& Damayanti, A. The role of usability in business-to-customer digital transactions on multiservice platforms of Indonesian e-money providers. {\em Digital Transformation Management}. pp. 226-246 (2022)

\bibitem{weichbroth2022empirical}Weichbroth, P. An empirical study on the impact of gender on mobile applications usability. {\em IEEE Access}. \textbf{10} pp. 119419-119436 (2022)

\bibitem{rukzio2008automatic}Rukzio, E., Noda, C., De Luca, A., Hamard, J. \& Coskun, F. Automatic form filling on mobile devices. {\em Pervasive And Mobile Computing}. \textbf{4}, 161-181 (2008)

\bibitem{oesch2021emperor}Oesch, S., Gautam, A. \& Ruoti, S. The emperor’s new autofill framework: a security analysis of autofill on iOS and Android. {\em Proceedings Of The 37th Annual Computer Security Applications Conference}. pp. 996-1010 (2021)

\bibitem{simmons2021systematization}Simmons, J., Diallo, O., Oesch, S. \& Ruoti, S. Systematization of password manageruse cases and design paradigms. {\em Proceedings Of The 37th Annual Computer Security Applications Conference}. pp. 528-540 (2021)

\bibitem{zhu2019riskcog}Zhu, T., Qu, Z., Xu, H., Zhang, J., Shao, Z., Chen, Y., Prabhakar, S. \& Yang, J. RiskCog: Unobtrusive real-time user authentication on mobile devices in the wild. {\em IEEE Transactions On Mobile Computing}. \textbf{19}, 466-483 (2019)

\bibitem{shin2023heuristic}Shin, J. \& Jung, S. Heuristic smartphone usability evaluations of the mobile application NANDA, nursing interventions classification, and nursing outcomes classification customized for nursing home registered nurses. {\em International Journal Of Nursing Knowledge}. \textbf{34}, 307-315 (2023)

\bibitem{mahamad2007user}Mahamad, S., Syed Mansoor, S. \& Annamalai, R. User Perception on Intelligent Split Menu for Web Browser Data Entry. {\em Innovations And Advanced Techniques In Computer And Information Sciences And Engineering}. pp. 439-442 (2007)

\bibitem{kern2009design}Kern, D. \& Schmidt, A. Design space for driver-based automotive user interfaces. {\em Proceedings Of The 1st International Conference On Automotive User Interfaces And Interactive Vehicular Applications}. pp. 3-10 (2009)

\bibitem{yang2022influence}Yang, W. Influence of Mental Model of GUI on Usability. {\em 9th International Conference On Kansei Engineering And Emotion Research. KEER2022. Proceedings}. pp. 377-386 (2022)

\bibitem{nosseir2012mobile}Nosseir, A., Flood, D., Harrison, R. \& Ibrahim, O. Mobile development process spiral. {\em 2012 Seventh International Conference On Computer Engineering \& Systems (ICCES)}. pp. 281-286 (2012)

\bibitem{hutahaean2020identifying}Hutahaean, H., Govindaraju, R. \& Sudirman, I. Identifying usability risks for mobile application. {\em Proceedings Of The 2020 International Conference On Engineering And Information Technology For Sustainable Industry}. pp. 1-6 (2020)

\bibitem{bevan2008classifying}Bevan, N. Classifying and selecting UX and usability measures. {\em International Workshop On Meaningful Measures: Valid Useful User Experience Measurement}. \textbf{11} pp. 13-18 (2008)

\bibitem{dixon2016usability}Dixon, J., Dehlinger, J., Dixon, S. \& Chakraborty, J. Usability Testing Results for a Mobile Medical Transition Application. {\em Design, User Experience, And Usability: Novel User Experiences: 5th International Conference, DUXU 2016, Held As Part Of HCI International 2016, Toronto, Canada, July 17–22, 2016, Proceedings, Part II 5}. pp. 569-577 (2016)

\bibitem{nam2016user}Nam-gu, I. The User Experience of Smart-Phone Information Hierarchy and Screen Transition Patterns. {\em International Journal Of Multimedia And Ubiquitous Engineering}. \textbf{11}, 293-302 (2016)

\bibitem{weichbroth2024usabilitya}Weichbroth, P. Usability Testing of Mobile Applications: A Methodological Framework. {\em Applied Sciences}. \textbf{14}, 1792 (2024)

\bibitem{barakovic2015multidimensional}Baraković, S. \& Skorin-Kapov, L. Multidimensional modelling of quality of experience for mobile web browsing. {\em Computers In Human Behavior}. \textbf{50} pp. 314-332 (2015)

\bibitem{wang2021effect}Wang, Y., Huang, Y., Li, J. \& Zhang, J. The effect of mobile applications’ initial loading pages on users’ mental state and behavior. {\em Displays}. \textbf{68} pp. 102007 (2021)

\bibitem{wang2023waiting}Wang, J., Li, Y., Yang, S., Dong, S. \& Li, J. Waiting experience: Optimization of feedback mechanism of voice user interfaces based on time perception. {\em IEEE Access}. \textbf{11} pp. 21241-21251 (2023)

\bibitem{gao2014mobile}Gao, J., Tsai, W., Paul, R., Bai, X. \& Uehara, T. Mobile Testing-as-a-Service (MTaaS)–Infrastructures, Issues, Solutions and Needs. {\em 2014 IEEE 15th International Symposium On High-Assurance Systems Engineering}. pp. 158-167 (2014)

\bibitem{majrashi2018task}Majrashi, K., Hamilton, M. \& Uitdenbogerd, A. Task continuity and mobile user interfaces. {\em Proceedings Of The 17th International Conference On Mobile And Ubiquitous Multimedia}. pp. 475-481 (2018)

\bibitem{von2016usability}Wangenheim, C., Witt, T., Borgatto, A., Nunes, J., Lacerda, T., Krone, C. \& Oliveira Souza, L. A usability score for mobile phone applications based on heuristics. {\em International Journal Of Mobile Human Computer Interaction (IJMHCI)}. \textbf{8}, 23-58 (2016)

\bibitem{saleh2017evaluating}Saleh, A., Ismail, R. \& Fabil, N. Evaluating usability for mobile application: A MAUEM approach. {\em Proceedings Of The 2017 International Conference On Software And E-Business}. pp. 71-77 (2017)

\bibitem{yu2020unravelling}Yu, M., Zhou, R., Cai, Z., Tan, C. \& Wang, H. Unravelling the relationship between response time and user experience in mobile applications. {\em Internet Research}. \textbf{30}, 1353-1382 (2020)

\bibitem{Hussain2024}Hussain, A. Dead Lock - iOS App Development.  (2024), https://www.linkedin.com/pulse/dead-lock-ios-app-development-ios-mobile-app-developer–ua1nf/ [Accessed on: 09.05.2024]

\bibitem{az2019evaluating}Az-zahra, H., Fauzi, N. \& Kharisma, A. Evaluating E-marketplace mobile application based on people at the center of mobile application development (PACMAD) usability model. {\em 2019 International Conference On Sustainable Information Engineering And Technology (SIET)}. pp. 72-77 (2019)

\bibitem{irwansyah2018radio}Irwansyah, I. Radio Mobile Apps Review: User Measurement and Appreciation. {\em Advanced Science Letters}. \textbf{24}, 7137-7140 (2018)

\bibitem{marsh2008design}Marsh, A. \& Setchi, R. Design for intuitive use: a study of mobile phones. {\em 4th I* PROMS Virtual International Conference}. (2008)

\bibitem{britton2013intuitive}Britton, A., Setchi, R. \& Marsh, A. Intuitive interaction with multifunctional mobile interfaces. {\em Journal Of King Saud University-Computer And Information Sciences}. \textbf{25}, 187-196 (2013)

\bibitem{naumann2010benchmarks}Naumann, A. \& Hurtienne, J. Benchmarks for intuitive interaction with mobile devices. {\em Proceedings Of The 12th International Conference On Human Computer Interaction With Mobile Devices And Services}. pp. 401-402 (2010)

\bibitem{liu2021case}Liu, C. \& Correia, A. A Case Study of Learners' Engagement in Mobile Learning Applications.. {\em Online Learning}. \textbf{25}, 25-48 (2021)

\bibitem{ramdowar2023comprehensive}Ramdowar, H., Khedo, K. \& Chooramun, N. A comprehensive review of mobile user interfaces in mHealth applications for elderly and the related ageing barriers. {\em Universal Access In The Information Society}. pp. 1-17 (2023)

\bibitem{xiao2024design}Xiao, T., Wang, J., Zheng, H. \& Yao, J. Design and optimization of mobile learning applications based on Hierarchical Bayes conjoint models of user preferences. {\em Multimedia Tools And Applications}. \textbf{83}, 17001-17024 (2024)

\bibitem{mathur2017impact}Mathur, A. \& Chetty, M. Impact of user characteristics on attitudes towards automatic mobile application updates. {\em Thirteenth Symposium On Usable Privacy And Security (SOUPS 2017)}. pp. 175-193 (2017)

\bibitem{huang2022updating}Huang, R., Miao, H. \& Wang, N. Updating APP to Improve Users’ Satisfaction: Insights from users’ Review.  (2022)

\bibitem{nurdina2021usability}Nurdina, G., Putri, T. \& Hayati, S. Usability Telecontextual Study for Nursing Students: Unfolding Case Study. {\em KnE Life Sciences}. pp. 697-704 (2021)

\bibitem{lahrache2018visualizations}Lahrache, S., El Ouazzani, R. \& El Qadi, A. Visualizations memorability through visual attention and image features. {\em Procedia Computer Science}. \textbf{127} pp. 328-335 (2018)

\bibitem{coursaris2011meta}Coursaris, C. \& Kim, D. A meta-analytical review of empirical mobile usability studies. {\em Journal Of Usability Studies}. \textbf{6}, 117-171 (2011)

\bibitem{afif2021evaluating}Afif, M. Evaluating PSAU mobile application based on people at the center of mobile application development (PACMAD) usability model: empirical investigation. {\em Journal Of Computer Science}. \textbf{17}, 275-283 (2021)

\bibitem{nizamani2021novel}Nizamani, S., Hassan, S., Shaikh, R., Abozinadah, E. \& Mehmood, R. A novel hybrid textual-graphical authentication scheme with better security, memorability, and usability. {\em IEEE Access}. \textbf{9} pp. 51294-51312 (2021)

\bibitem{abd2019evaluation}Abd Raof, S., Hashim, N. \& Zainuddin, N. An Evaluation of Quran Memorization Mobile App among Middle-Aged Adults and Early Elderly. {\em Journal Of Computing Research And Innovation}. \textbf{4}, 1-7 (2019)

\bibitem{hsu2014usability}Hsu, S., Perng, C., Chiou, W. \& Ou, T. Usability Evaluation of Mobile Commerce Website on Internet–An empirical study.  (2014)

\bibitem{hung2012enhancing}Hung, C., Chou, J. \& Ding, C. Enhancing mobile satisfaction through integration of usability and flow. {\em Engineering Management Research}. \textbf{1}, 44 (2012)

\bibitem{bodrunova2018impact}Bodrunova, S. \& Yakunin, A. Impact of menu complexity upon user behavior and satisfaction in information search. {\em Human Interface And The Management Of Information. Information In Applications And Services: 20th International Conference, HIMI 2018, Held As Part Of HCI International 2018, Las Vegas, NV, USA, July 15-20, 2018, Proceedings, Part II 20}. pp. 55-66 (2018)

\bibitem{nickerson2015managing}Nickerson, R. \& Mourato-Dussault, F. Managing stored data for mobile apps: survey of apps and case study.  (2015)

\bibitem{nickerson2016selecting}Nickerson, R. \& Mourato-Dussault, F. Selecting a stored data approach for mobile apps. {\em Journal Of Theoretical And Applied Electronic Commerce Research}. \textbf{11}, 35-49 (2016)

\bibitem{azadi2020mobile}Azadi, F., Adu-Gyamfi, Y., Sun, C. \& Edara, P. Mobile application development and testing for work zone activity real-time data collection. {\em Transportation Research Record}. \textbf{2674}, 351-362 (2020)

\bibitem{ali2022mobile}Ali, W., Riaz, O., Mumtaz, S., Khan, A., Saba, T. \& Bahaj, S. Mobile Application Usability Evaluation: A Study Based on Demography. {\em IEEE Access}. \textbf{10} pp. 41512-41524 (2022)

\bibitem{seffah2006usability}Seffah, A., Donyaee, M., Kline, R. \& Padda, H. Usability measurement and metrics: A consolidated model. {\em Software Quality Journal}. \textbf{14} pp. 159-178 (2006)

\bibitem{franke2012mobile}Franke, D., Kowalewski, S. \& Weise, C. A mobile software quality model. {\em 2012 12th International Conference On Quality Software}. pp. 154-157 (2012)

\bibitem{alvarado2018layered}Alvarado, L., Dom\'{\i}nguez, E., Velázquez, Y., Isidro, S. \& Toledo, C. Layered software architecture for the development of mobile learning objects with augmented reality. {\em IEEE Access}. \textbf{6} pp. 57897-57909 (2018)

\bibitem{nunez2020model}Núñez, M., Bonhaure, D., González, M. \& Cernuzzi, L. A model-driven approach for the development of native mobile applications focusing on the data layer. {\em Journal Of Systems And Software}. \textbf{161} pp. 110489 (2020)

\bibitem{inostroza2012usability}Inostroza, R., Rusu, C., Roncagliolo, S., Jimenez, C. \& Rusu, V. Usability heuristics for touchscreen-based mobile devices. {\em 2012 Ninth International Conference On Information Technology-new Generations}. pp. 662-667 (2012)

\bibitem{kuparinen2013introducing}Kuparinen, L., Silvennoinen, J. \& Isomäki, H. Introducing usability heuristics for mobile map applications. {\em International Cartographic Conference}. (2013)

\bibitem{heuwing2015usability}Heuwing, B., Köller, I., Schanz, V. \& Mandl, T. Usability of Gesture-based Mobile Applications for First-time Use.. {\em MuC}. pp. 233-242 (2015)

\bibitem{pushp2018privacyshield}Pushp, S., Liu, Y., Xu, M., Koh, C. \& Song, J. PrivacyShield: A mobile system for supporting subtle just-in-time privacy provisioning through off-screen-based touch gestures. {\em Proceedings Of The ACM On Interactive, Mobile, Wearable And Ubiquitous Technologies}. \textbf{2}, 1-38 (2018)

\bibitem{wu2020user}Wu, H. \& Yang, L. User-defined gestures for dual-screen mobile interaction. {\em International Journal Of Human–Computer Interaction}. \textbf{36}, 978-992 (2020)

\bibitem{schneider2008investigation}Schneider, N., Wilkes, J., Grandt, M. \& Schlick, C. Investigation of input devices for the age-differentiated design of human-computer interaction. {\em Proceedings Of The Human Factors And Ergonomics Society Annual Meeting}. \textbf{52}, 144-148 (2008)

\bibitem{qin2011usability}Qin, J., Liu, X. \& Zhang, Y. Usability Testing for Mobile Input Method Interaction Design. {\em Applied Mechanics And Materials}. \textbf{63} pp. 952-955 (2011)

\bibitem{george2018usability}George, D., Hassali, M., Amar-Singh, H. \& Others Usability testing of a mobile app to report medication errors anonymously: mixed-methods approach. {\em JMIR Human Factors}. \textbf{5}, e12232 (2018)

\bibitem{deegan2015complex}Deegan, R. Complex mobile learning that adapts to learners' cognitive load. {\em International Journal Of Mobile And Blended Learning (IJMBL)}. \textbf{7}, 13-24 (2015)

\bibitem{sweller1998cognitive}Sweller, J., Van Merrienboer, J. \& Paas, F. Cognitive architecture and instructional design. {\em Educational Psychology Review}. \textbf{10} pp. 251-296 (1998)

\bibitem{karczewska2021usability}Karczewska, B., Kukla, E., Muke, P., Telec, Z. \& Trawiński, B. Usability study of mobile applications with cognitive load resulting from environmental factors. {\em Intelligent Information And Database Systems: 13th Asian Conference, ACIIDS 2021, Phuket, Thailand, April 7–10, 2021, Proceedings 13}. pp. 851-864 (2021)

\bibitem{smith2017adaptive}Smith-Creasey, M. \& Rajarajan, M. Adaptive threshold scheme for touchscreen gesture continuous authentication using sensor trust. {\em 2017 IEEE Trustcom/BigDataSE/ICESS}. pp. 554-561 (2017)

\bibitem{deegan2011usability}Deegan, R. \& Rothwell, P. Usability in Mobile Learning: Results from a study of learning under varying levels of extraneous cognitive load. {\em Proc IHCI}. (2011)

\bibitem{daud2023design}Daud, M., Yusoff, F., Abdul-Razak, S., Baharudin, N., Mohamed-Yassin, M., Badlishah-Sham, S., Nikmat, A., Isa, M., Jamil, N., Nawawi, H. \& Others Design, development, utility and usability testing of the EMPOWER-SUSTAIN Self-Management Mobile App© among primary care physicians and patients with metabolic syndrome. {\em Digital Health}. \textbf{9} pp. 20552076231176645 (2023)

\bibitem{deegan2014mobile}Deegan, R. Mobile HCI: Issues Surrounding Cognition, Distraction, Usability and Performance. {\em International Journal Of Mobile Human Computer Interaction (IJMHCI)}. \textbf{6}, 1-14 (2014)

\bibitem{alasmari2020effect}Alasmari, T. The effect of screen size on students’ cognitive load in mobile learning. {\em Journal Of Education, Teaching And Learning}. \textbf{5}, 280-295 (2020)

\bibitem{ibili2019assessing}Ibili, E. \& Billinghurst, M. Assessing the relationship between cognitive load and the usability of a mobile augmented reality tutorial system: A study of gender effects. {\em International Journal Of Assessment Tools In Education}. \textbf{6}, 378-395 (2019)

\bibitem{ilany2019mobile}Ilany-Tzur, N. \& Fink, L. Mobile State of Mind: The Effect of Cognitive Load on Mobile Users' Cognitive Performance.. {\em ICIS}. (2019)

\bibitem{schobel2020measuring}Schobel, J., Probst, T., Reichert, M., Schlee, W., Schickler, M., Kestler, H. \& Pryss, R. Measuring mental effort for creating mobile data collection applications. {\em International Journal Of Environmental Research And Public Health}. \textbf{17}, 1649 (2020)

\bibitem{greenberg2023revisiting}Greenberg, K. \& Zheng, R. Revisiting the debate on germane cognitive load versus germane resources. {\em Journal Of Cognitive Psychology}. \textbf{35}, 295-314 (2023)

\bibitem{leppink2015evolution}Leppink, J. \& Heuvel, A. The evolution of cognitive load theory and its application to medical education. {\em Perspectives On Medical Education}. \textbf{4} pp. 119-127 (2015)

\bibitem{ammar2019usability}Ammar, L. A usability model for mobile applications generated with a model-driven approach. {\em International Journal Of Advanced Computer Science And Applications}. \textbf{10} (2019)

\bibitem{pfister2011affective}Pfister, H., Wollstädter, S. \& Peter, C. Affective responses to system messages in human–computer-interaction: Effects of modality and message type. {\em Interacting With Computers}. \textbf{23}, 372-383 (2011)

\bibitem{ahmad2021spiritual}Ahmad, N., Baharum, Z., Zainal, A., Razak, F. \& Adnan, W. Spiritual User Experience (iSUX) for Older Adult Users using Mobile Application. {\em International Journal Of Advanced Computer Science And Applications}. \textbf{12} (2021)

\bibitem{afrin2022usability}Afrin, S., Zaman, S., Sadekeen, D., Islam, Z., Tabassum, N. \& Islam, M. How usability and user experience vary among the basic m-commerce, AR and VR based user interfaces of mobile application for online shopping. {\em Advances In Design And Digital Communication II: Proceedings Of The 5th International Conference On Design And Digital Communication, Digicom 2021, November 4–6, 2021, Barcelos, Portugal}. pp. 44-53 (2022)

\bibitem{castilla2023digital}Castilla, R., Pacheco, A. \& Franco, J. Digital government: Mobile applications and their impact on access to public information. {\em SoftwareX}. \textbf{22} pp. 101382 (2023)

\bibitem{chang2013improving}Chang, K., Myers, B., Cahill, G., Simanta, S., Morris, E. \& Lewis, G. Improving structured data entry on mobile devices. {\em Proceedings Of The 26th Annual ACM Symposium On User Interface Software And Technology}. pp. 75-84 (2013)

\bibitem{piplani2018ict}Piplani, D., Singh, D., Srinivasan, K., Lonkar, V. \& Shinde, S. ICT in Social Development—Context-Sensitive Design Strategies to Develop Mobile Applications for Barefoot Animal Breeders. {\em Advanced Computational And Communication Paradigms: Proceedings Of International Conference On ICACCP 2017, Volume 2}. pp. 415-423 (2018)

\bibitem{holstrom2020effects}Holstrom, C. The effects of suggested tags and autocomplete features on social tagging behaviors. {\em Proceedings Of The Association For Information Science And Technology}. \textbf{57}, e263 (2020)

\bibitem{goumopoulos2017development}Goumopoulos, C., Papa, I. \& Stavrianos, A. Development and evaluation of a mobile application suite for enhancing the social inclusion and well-being of seniors. {\em Informatics}. \textbf{4}, 15 (2017)

\bibitem{perez2020evaluation}Pérez-Medina, J., Zalakeviciute, R., Rybarczyk, Y. \& González, M. Evaluation of the usability of a mobile application for public air quality information. {\em Advances In Human Factors And Systems Interaction: Proceedings Of The AHFE 2019 International Conference On Human Factors And Systems Interaction, July 24-28, 2019, Washington DC, USA 10}. pp. 451-462 (2020)

\bibitem{tovide2022signsupport}Tovide, A., Tucker, W. \& Ajayi, O. Signsupport: an emergency mobile application for the Deaf. {\em 2022 IST-Africa Conference (IST-Africa)}. pp. 1-13 (2022)

\bibitem{agosti2003managing}Agosti, M. \& Ferro, N. Managing the interactions between handheld devices, mobile applications, and users. {\em Advances In Mobile Commerce Technologies}. pp. 205-234 (2003)

\bibitem{chittaro2007mobile}Chittaro, L., Zuliani, F. \& Carchietti, E. Mobile devices in emergency medical services: user evaluation of a PDA-based interface for ambulance run reporting. {\em International Workshop On Mobile Information Technology For Emergency Response}. pp. 19-28 (2007)

\bibitem{bilal2018analyzing}Bilal, A., Rextin, A., Kakakhel, A. \& Nasim, M. Analyzing emergent users’ text messages data and exploring its benefits. {\em IEEE Access}. \textbf{7} pp. 2870-2879 (2018)

\bibitem{liang2017mobile}Liang, T., Chen, L., Ying, X., Philip, S., Wu, J. \& Zheng, Z. Mobile application rating prediction via feature-oriented matrix factorization. {\em 2017 IEEE International Conference On Web Services (ICWS)}. pp. 261-268 (2017)

\bibitem{norman2010gestural}Norman, D. \& Nielsen, J. Gestural interfaces: a step backward in usability. {\em Interactions}. \textbf{17}, 46-49 (2010)

\bibitem{mcgrenere2000affordances}McGrenere, J. \& Ho, W. Affordances: Clarifying and evolving a concept. {\em Graphics Interface}. \textbf{2000} pp. 179-186 (2000)

\bibitem{kangas2005applying}Kangas, E. \& Kinnunen, T. Applying user-centered design to mobile application development. {\em Communications Of The ACM}. \textbf{48}, 55-59 (2005)

\bibitem{nguyen2015reverse}Nguyen, T. \& Csallner, C. Reverse engineering mobile application user interfaces with remaui (t). {\em 2015 30th IEEE/ACM International Conference On Automated Software Engineering (ASE)}. pp. 248-259 (2015)

\bibitem{natarajan2018p2a}Natarajan, S. \& Csallner, C. P2A: A tool for converting pixels to animated mobile application user interfaces. {\em Proceedings Of The 5th International Conference On Mobile Software Engineering And Systems}. pp. 224-235 (2018)

\bibitem{deniz2019comparison}Deniz, G. \& Durdu, P. A comparison of mobile form controls for different tasks. {\em Computer Standards \& Interfaces}. \textbf{61} pp. 97-106 (2019)

\bibitem{kim2022speak}Kim, D., Granquist, A., Patton, E., Friedman, M. \& Abelson, H. Speak your mind: Introducing aptly, the software platform that turns ideas into working apps. {\em ICERI2022 Proceedings}. pp. 1653-1660 (2022)

\bibitem{wen2023droidbot}Wen, H., Wang, H., Liu, J. \& Li, Y. Droidbot-gpt: Gpt-powered ui automation for android. {\em ArXiv Preprint ArXiv:2304.07061}. (2023)

\bibitem{mansar2012usability}Mansar, S., Jariwala, S., Shahzad, M., Anggraini, A., Behih, N. \& AlZeyara, A. A usability testing experiment for a localized weight loss mobile application. {\em Procedia Technology}. \textbf{5} pp. 839-848 (2012)

\bibitem{moroyoqui2022smartasko}Moroyoqui, M., Espina, D., Osuna, H. \& Escobedo, L. SmarTasko: Supporting short and spontaneous activities of daily living of ADHD individuals. {\em Proceedings Of The 9th Mexican International Conference On Human-Computer Interaction}. pp. 1-6 (2022)

\bibitem{nakagawa2022implementation}Nakagawa, R., Ohkawa, Y., Zhao, X., Takahashi, A., Ohyama, T., Mitsuishi, T. \& Hayakawa, Y. Implementation of UX Design to Enhance Spontaneous and Continuous Study of a Mobile Application for Foreign Language Learning. {\em EdMedia+ Innovate Learning}. pp. 1119-1123 (2022)

\bibitem{cunha2013heuristic}Cunha, B., Machado Neto, O. \& Pimentel, M. A heuristic evaluation of a mobile annotation tool. {\em Proceedings Of The 19th Brazilian Symposium On Multimedia And The Web}. pp. 89-92 (2013)

\bibitem{fowler2013survey}Fowler Jr, F. Survey research methods. (Sage publications,2013)

\bibitem{bennett2011reporting}Bennett, C., Khangura, S., Brehaut, J., Graham, I., Moher, D., Potter, B. \& M. Grimshaw, J. Reporting guidelines for survey research: an analysis of published guidance and reporting practices. {\em PLoS Medicine}. \textbf{8}, e1001069 (2011)

\bibitem{passmore2002guidelines}Passmore, C., Dobbie, A., Parchman, M. \& Tysinger, J. Guidelines for constructing a survey. {\em Family Medicine-Kansas City}. \textbf{34}, 281-286 (2002)

\bibitem{emerson2015convenience}Emerson, R. Convenience sampling, random sampling, and snowball sampling: How does sampling affect the validity of research?. {\em Journal Of Visual Impairment \& Blindness}. \textbf{109}, 164-168 (2015)

\bibitem{johnson2020usability}Johnson, S., Potrebny, T., Larun, L., Ciliska, D. \& Olsen, N. Usability methods and attributes reported in usability studies of mobile apps for health care education: protocol for a scoping review. {\em JMIR Research Protocols}. \textbf{9}, e19072 (2020)

\bibitem{vasa2012preliminary}Vasa, R., Hoon, L., Mouzakis, K. \& Noguchi, A. A preliminary analysis of mobile app user reviews. {\em Proceedings Of The 24th Australian Computer-human Interaction Conference}. pp. 241-244 (2012)

\bibitem{genc2017systematic}Genc-Nayebi, N. \& Abran, A. A systematic literature review: Opinion mining studies from mobile app store user reviews. {\em Journal Of Systems And Software}. \textbf{125} pp. 207-219 (2017)

\bibitem{alqahtani2020insights}Alqahtani, F. \& Orji, R. Insights from user reviews to improve mental health apps. {\em Health Informatics Journal}. \textbf{26}, 2042-2066 (2020)

\bibitem{heo2009framework}Heo, J., Ham, D., Park, S., Song, C. \& Yoon, W. A framework for evaluating the usability of mobile phones based on multi-level, hierarchical model of usability factors. {\em Interacting With Computers}. \textbf{21}, 263-275 (2009)

\bibitem{hensher2021scoping}Hensher, M., Cooper, P., Dona, S., Angeles, M., Nguyen, D., Heynsbergh, N., Chatterton, M. \& Peeters, A. Scoping review: development and assessment of evaluation frameworks of mobile health apps for recommendations to consumers. {\em Journal Of The American Medical Informatics Association}. \textbf{28}, 1318-1329 (2021)

\bibitem{schlichtig2024building}Schlichtig, M. Building a Framework to Improve the User Experience of Static Analysis Tools. {\em Proceedings Of The 2024 IEEE/ACM 46th International Conference On Software Engineering: Companion Proceedings}. pp. 165-169 (2024)

\bibitem{zuniga2019tortoise}Zuniga, A., Flores, H., Lagerspetz, E., Nurmi, P., Tarkoma, S., Hui, P. \& Manner, J. Tortoise or hare? Quantifying the effects of performance on mobile app retention. {\em The World Wide Web Conference}. pp. 2517-2528 (2019)

\bibitem{leitner2007usability}Leitner, G., Ahlström, D. \& Hitz, M. Usability of mobile computing in emergency response systems–Lessons learned and future directions. {\em HCI And Usability For Medicine And Health Care: Third Symposium Of The Workgroup Human-Computer Interaction And Usability Engineering Of The Austrian Computer Society, USAB 2007 Graz, Austria, November, 22, 2007. Proceedings 3}. pp. 241-254 (2007)

\bibitem{redlarski2016hard}Redlarski, K. \& Weichbroth, P. Hard lessons learned: delivering usability in IT projects. {\em 2016 Federated Conference On Computer Science And Information Systems (FedCSIS)}. pp. 1379-1382 (2016)

\bibitem{inupakutika2022performance}Inupakutika, D., Rodriguez, G., Akopian, D., Lama, P., Chalela, P. \& Ramirez, A. On the Performance of Cloud-Based mHealth Applications: A Methodology on Measuring Service Response Time and a Case Study. {\em IEEE Access}. \textbf{10} pp. 53208-53224 (2022)

\bibitem{ferreira2022impact}Ferreira, J., Rodr\'{\i}guez, F., Santos, A., Dieste, O., Acuña, S. \& Juristo, N. Impact of usability mechanisms: A family of experiments on efficiency, effectiveness and user satisfaction. {\em IEEE Transactions On Software Engineering}. \textbf{49}, 251-267 (2022)

\bibitem{UX-principles2023}CodeAgency UX/UI Design: How to create an intuitive and usable interface?.  (2023), https://codeagency.pl/en/ux-ui-design-how-to-create-an-intuitive-and-usable-interface/ [Accessed on: 08.06.2024]

\bibitem{canbazoglu2016developing}Canbazoglu, E., Salman, Y., Yildirim, M., Merdenyan, B. \& Ince, I. Developing a mobile application to better inform patients and enable effective consultation in implant dentistry. {\em Computational And Structural Biotechnology Journal}. \textbf{14} pp. 252-261 (2016)

\bibitem{jadhav2013usability}Jadhav, D., Bhutkar, G. \& Mehta, V. Usability evaluation of messenger applications for Android phones using cognitive walkthrough. {\em Proceedings Of The 11th Asia Pacific Conference On Computer Human Interaction}. pp. 9-18 (2013)

\bibitem{Salazar2022}Salazar, K. Evaluate Interface Learnability with Cognitive Walkthroughs.  (2022), https://www.nngroup.com/articles/cognitive-walkthroughs/ [Accessed on: 09.06.2024]

\bibitem{marrella2018measuring}Marrella, A. \& Catarci, T. Measuring the learnability of interactive systems using a Petri Net based approach. {\em Proceedings Of The 2018 Designing Interactive Systems Conference}. pp. 1309-1319 (2018)

\bibitem{Shweta2024}Joshi, S. Top 20 must-know mobile app UX best practices.  (2024), https://sendbird.com/blog/mobile-app-ux-best-practices [Accessed on: 09.06.2024]

\bibitem{arkorful2022voter}Arkorful, V., Lugu, B., Basiru, I., Hammond, A., Arkorful, V. \& Budu, G. Voter's choice of a presidential candidate: An empirical study. {\em Journal Of Public Affairs}. \textbf{22}, e2576 (2022)

\bibitem{ginters2023pragmatic}Ginters, E. Pragmatic statistics: Likert-type questionnaires processing. {\em World Conference On Information Systems And Technologies}. pp. 23-51 (2023)

\bibitem{alqahtani2015investigation}Alqahtani, M., Alhadreti, O., Alrobaea, R. \& Mayhew, P. Investigation into the impact of the usability factor on the acceptance of mobile transactions: Empirical study in Saudi Arabia. {\em International Journal Of Human Computer Interaction}. \textbf{6}, 1-35 (2015)

\bibitem{hajesmaeel2022most}Hajesmaeel-Gohari, S., Khordastan, F., Fatehi, F., Samzadeh, H. \& Bahaadinbeigy, K. The most used questionnaires for evaluating satisfaction, usability, acceptance, and quality outcomes of mobile health. {\em BMC Medical Informatics And Decision Making}. \textbf{22}, 22 (2022)

\bibitem{camilleri2023functionality}Camilleri, M., Troise, C. \& Kozak, M. Functionality and usability features of ubiquitous mobile technologies: the acceptance of interactive travel apps. {\em Journal Of Hospitality And Tourism Technology}. \textbf{14}, 188-207 (2023)


\end{thebibliography}

\clearpage
\section*{Declarations}
\subsection*{Ethical Approval} 
No experiments were performed. Therefore, ethics committee approval was not required. Informed consent was obtained from all individual participants in the study.

\subsection*{Funding}
No funding has been received.

\subsection*{Availability of data and materials }
Data available on reasonable request. Please contact correspondence author for access to dataset.

\end{document}