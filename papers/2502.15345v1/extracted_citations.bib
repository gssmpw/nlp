@inproceedings{agarwal2020model,
  title={Model-based reinforcement learning with a generative model is minimax optimal},
  author={Agarwal, Alekh and Kakade, Sham and Yang, Lin F},
  booktitle={Conference on Learning Theory},
  pages={67--83},
  year={2020},
  organization={PMLR}
}

@inproceedings{agarwal2020optimistic,
  title={An optimistic perspective on offline reinforcement learning},
  author={Agarwal, Rishabh and Schuurmans, Dale and Norouzi, Mohammad},
  booktitle={International conference on machine learning},
  pages={104--114},
  year={2020},
  organization={PMLR}
}

@article{antoniadis2020secretary,
  title={Secretary and online matching problems with machine learned advice},
  author={Antoniadis, Antonios and Gouleakis, Themis and Kleer, Pieter and Kolev, Pavel},
  journal={Advances in Neural Information Processing Systems},
  volume={33},
  pages={7933--7944},
  year={2020}
}

@article{arulkumaran2017deep,
  title={Deep reinforcement learning: A brief survey},
  author={Arulkumaran, Kai and Deisenroth, Marc Peter and Brundage, Miles and Bharath, Anil Anthony},
  journal={IEEE Signal Processing Magazine},
  volume={34},
  number={6},
  pages={26--38},
  year={2017},
  publisher={IEEE}
}

@article{auer2002adaptive,
  title={Adaptive and self-confident on-line learning algorithms},
  author={Auer, Peter and Cesa-Bianchi, Nicolo and Gentile, Claudio},
  journal={Journal of Computer and System Sciences},
  volume={64},
  number={1},
  pages={48--75},
  year={2002},
  publisher={Elsevier}
}

@article{balseiro2022single,
  title={Single-leg revenue management with advice},
  author={Balseiro, Santiago and Kroer, Christian and Kumar, Rachitesh},
  journal={arXiv preprint arXiv:2202.10939},
  year={2022}
}

@article{bellman1966dynamic,
  title={Dynamic programming},
  author={Bellman, Richard},
  journal={science},
  volume={153},
  number={3731},
  pages={34--37},
  year={1966},
  publisher={American Association for the Advancement of Science}
}

@article{bertsekas1996neuro,
  title={Neuro-dynamic programming},
  author={Bertsekas, DP},
  journal={Athena Scientific},
  year={1996}
}

@book{bertsekas2012dynamic,
  title={Dynamic programming and optimal control: Volume I},
  author={Bertsekas, Dimitri},
  volume={4},
  year={2012},
  publisher={Athena scientific}
}

@book{bertsekas2022abstract,
  title={Abstract dynamic programming},
  author={Bertsekas, Dimitri},
  year={2022},
  publisher={Athena Scientific}
}

@inproceedings{carmon2022making,
  title={Making sgd parameter-free},
  author={Carmon, Yair and Hinder, Oliver},
  booktitle={Conference on Learning Theory},
  pages={2360--2389},
  year={2022},
  organization={PMLR}
}

@inproceedings{cheng2020reduction,
  title={A reduction from reinforcement learning to no-regret online learning},
  author={Cheng, Ching-An and Combes, Remi Tachet and Boots, Byron and Gordon, Geoff},
  booktitle={International Conference on Artificial Intelligence and Statistics},
  pages={3514--3524},
  year={2020},
  organization={PMLR}
}

@inproceedings{christianson2022chasing,
  title={Chasing convex bodies and functions with black-box advice},
  author={Christianson, Nicolas and Handina, Tinashe and Wierman, Adam},
  booktitle={Conference on Learning Theory},
  pages={867--908},
  year={2022},
  organization={PMLR}
}

@inproceedings{cutkosky2018black,
  title={Black-box reductions for parameter-free online learning in banach spaces},
  author={Cutkosky, Ashok and Orabona, Francesco},
  booktitle={Conference On Learning Theory},
  pages={1493--1529},
  year={2018},
  organization={PMLR}
}

@inproceedings{cutkosky2022leveraging,
  title={Leveraging initial hints for free in stochastic linear bandits},
  author={Cutkosky, Ashok and Dann, Chris and Das, Abhimanyu and Zhang, Qiuyi},
  booktitle={International Conference on Algorithmic Learning Theory},
  pages={282--318},
  year={2022},
  organization={PMLR}
}

@inproceedings{dutting2021secretaries,
  title={Secretaries with advice},
  author={D{\"u}tting, Paul and Lattanzi, Silvio and Paes Leme, Renato and Vassilvitskii, Sergei},
  booktitle={Proceedings of the 22nd ACM Conference on Economics and Computation},
  pages={409--429},
  year={2021}
}

@inproceedings{fujimoto2019off,
  title={Off-policy deep reinforcement learning without exploration},
  author={Fujimoto, Scott and Meger, David and Precup, Doina},
  booktitle={International conference on machine learning},
  pages={2052--2062},
  year={2019},
  organization={PMLR}
}

@article{gheshlaghi2013minimax,
  title={Minimax PAC bounds on the sample complexity of reinforcement learning with a generative model},
  author={Gheshlaghi Azar, Mohammad and Munos, R{\'e}mi and Kappen, Hilbert J},
  journal={Machine learning},
  volume={91},
  pages={325--349},
  year={2013},
  publisher={Springer}
}

@inproceedings{golowich2022can,
  title={Can Q-learning be improved with advice?},
  author={Golowich, Noah and Moitra, Ankur},
  booktitle={Conference on Learning Theory},
  pages={4548--4619},
  year={2022},
  organization={PMLR}
}

@article{golrezaei2023online,
  title={Online resource allocation with convex-set machine-learned advice},
  author={Golrezaei, Negin and Jaillet, Patrick and Zhou, Zijie},
  journal={arXiv preprint arXiv:2306.12282},
  year={2023}
}

@inproceedings{jadbabaie2015online,
  title={Online optimization: Competing with dynamic comparators},
  author={Jadbabaie, Ali and Rakhlin, Alexander and Shahrampour, Shahin and Sridharan, Karthik},
  booktitle={Artificial Intelligence and Statistics},
  pages={398--406},
  year={2015},
  organization={PMLR}
}

@inproceedings{jin2020efficiently,
  title={Efficiently solving MDPs with stochastic mirror descent},
  author={Jin, Yujia and Sidford, Aaron},
  booktitle={International Conference on Machine Learning},
  pages={4890--4900},
  year={2020},
  organization={PMLR}
}

@article{jin2022online,
  title={Online bipartite matching with advice: Tight robustness-consistency tradeoffs for the two-stage model},
  author={Jin, Billy and Ma, Will},
  journal={Advances in Neural Information Processing Systems},
  volume={35},
  pages={14555--14567},
  year={2022}
}

@article{kaelbling1996reinforcement,
  title={Reinforcement learning: A survey},
  author={Kaelbling, Leslie Pack and Littman, Michael L and Moore, Andrew W},
  journal={Journal of artificial intelligence research},
  volume={4},
  pages={237--285},
  year={1996}
}

@article{kumar2019stabilizing,
  title={Stabilizing off-policy q-learning via bootstrapping error reduction},
  author={Kumar, Aviral and Fu, Justin and Soh, Matthew and Tucker, George and Levine, Sergey},
  journal={Advances in neural information processing systems},
  volume={32},
  year={2019}
}

@article{kumar2020conservative,
  title={Conservative q-learning for offline reinforcement learning},
  author={Kumar, Aviral and Zhou, Aurick and Tucker, George and Levine, Sergey},
  journal={Advances in Neural Information Processing Systems},
  volume={33},
  pages={1179--1191},
  year={2020}
}

@article{levine2020offline,
  title={Offline reinforcement learning: Tutorial, review, and perspectives on open problems},
  author={Levine, Sergey and Kumar, Aviral and Tucker, George and Fu, Justin},
  journal={arXiv preprint arXiv:2005.01643},
  year={2020}
}

@article{li2024beyond,
  title={Beyond black-box advice: learning-augmented algorithms for MDPs with Q-value predictions},
  author={Li, Tongxin and Lin, Yiheng and Ren, Shaolei and Wierman, Adam},
  journal={Advances in Neural Information Processing Systems},
  volume={36},
  year={2024}
}

@article{lykouris2021competitive,
  title={Competitive caching with machine learned advice},
  author={Lykouris, Thodoris and Vassilvitskii, Sergei},
  journal={Journal of the ACM (JACM)},
  volume={68},
  number={4},
  pages={1--25},
  year={2021},
  publisher={ACM New York, NY}
}

@inproceedings{lyu2023bandits,
  title={Bandits with knapsacks: advice on time-varying demands},
  author={Lyu, Lixing and Cheung, Wang Chi},
  booktitle={International Conference on Machine Learning},
  pages={23212--23238},
  year={2023},
  organization={PMLR}
}

@article{mitzenmacher2022algorithms,
  title={Algorithms with predictions},
  author={Mitzenmacher, Michael and Vassilvitskii, Sergei},
  journal={Communications of the ACM},
  volume={65},
  number={7},
  pages={33--35},
  year={2022},
  publisher={ACM New York, NY, USA}
}

@article{orabona2014simultaneous,
  title={Simultaneous model selection and optimization through parameter-free stochastic learning},
  author={Orabona, Francesco},
  journal={Advances in Neural Information Processing Systems},
  volume={27},
  year={2014}
}

@article{orabona2019modern,
  title={A modern introduction to online learning},
  author={Orabona, Francesco},
  journal={arXiv preprint arXiv:1912.13213},
  year={2019}
}

@article{purohit2018improving,
  title={Improving online algorithms via ML predictions},
  author={Purohit, Manish and Svitkina, Zoya and Kumar, Ravi},
  journal={Advances in Neural Information Processing Systems},
  volume={31},
  year={2018}
}

@book{puterman2014markov,
  title={Markov decision processes: discrete stochastic dynamic programming},
  author={Puterman, Martin L},
  year={2014},
  publisher={John Wiley \& Sons}
}

@inproceedings{rakhlin2013online,
  title={Online learning with predictable sequences},
  author={Rakhlin, Alexander and Sridharan, Karthik},
  booktitle={Conference on Learning Theory},
  pages={993--1019},
  year={2013},
  organization={PMLR}
}

@article{rakhlin2013optimization,
  title={Optimization, learning, and games with predictable sequences},
  author={Rakhlin, Sasha and Sridharan, Karthik},
  journal={Advances in Neural Information Processing Systems},
  volume={26},
  year={2013}
}

@inproceedings{rohatgi2020near,
  title={Near-optimal bounds for online caching with machine learned advice},
  author={Rohatgi, Dhruv},
  booktitle={Proceedings of the Fourteenth Annual ACM-SIAM Symposium on Discrete Algorithms},
  pages={1834--1845},
  year={2020},
  organization={SIAM}
}

@article{sidford2018near,
  title={Near-optimal time and sample complexities for solving Markov decision processes with a generative model},
  author={Sidford, Aaron and Wang, Mengdi and Wu, Xian and Yang, Lin and Ye, Yinyu},
  journal={Advances in Neural Information Processing Systems},
  volume={31},
  year={2018}
}

@article{streeter2010less,
  title={Less regret via online conditioning},
  author={Streeter, Matthew and McMahan, H Brendan},
  journal={arXiv preprint arXiv:1002.4862},
  year={2010}
}

@book{sutton2018reinforcement,
  title={Reinforcement learning: An introduction},
  author={Sutton, Richard S and Barto, Andrew G},
  year={2018},
  publisher={MIT press}
}

@book{szepesvari2022algorithms,
  title={Algorithms for reinforcement learning},
  author={Szepesv{\'a}ri, Csaba},
  year={2022},
  publisher={Springer nature}
}

@article{wainwright2019variance,
  title={Variance-reduced $ Q $-learning is minimax optimal},
  author={Wainwright, Martin J},
  journal={arXiv preprint arXiv:1906.04697},
  year={2019}
}

@article{wang2020randomized,
  title={Randomized linear programming solves the markov decision problem in nearly linear (sometimes sublinear) time},
  author={Wang, Mengdi},
  journal={Mathematics of Operations Research},
  volume={45},
  number={2},
  pages={517--546},
  year={2020},
  publisher={INFORMS}
}

@inproceedings{wei2020taking,
  title={Taking a hint: How to leverage loss predictors in contextual bandits?},
  author={Wei, Chen-Yu and Luo, Haipeng and Agarwal, Alekh},
  booktitle={Conference on Learning Theory},
  pages={3583--3634},
  year={2020},
  organization={PMLR}
}

@article{wu2019behavior,
  title={Behavior regularized offline reinforcement learning},
  author={Wu, Yifan and Tucker, George and Nachum, Ofir},
  journal={arXiv preprint arXiv:1911.11361},
  year={2019}
}

