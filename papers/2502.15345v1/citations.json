[
  {
    "index": 0,
    "papers": [
      {
        "key": "bellman1966dynamic",
        "author": "Bellman, Richard",
        "title": "Dynamic programming"
      },
      {
        "key": "bertsekas1996neuro",
        "author": "Bertsekas, DP",
        "title": "Neuro-dynamic programming"
      },
      {
        "key": "bertsekas2012dynamic",
        "author": "Bertsekas, Dimitri",
        "title": "Dynamic programming and optimal control: Volume I"
      },
      {
        "key": "bertsekas2022abstract",
        "author": "Bertsekas, Dimitri",
        "title": "Abstract dynamic programming"
      },
      {
        "key": "sutton2018reinforcement",
        "author": "Sutton, Richard S and Barto, Andrew G",
        "title": "Reinforcement learning: An introduction"
      },
      {
        "key": "szepesvari2022algorithms",
        "author": "Szepesv{\\'a}ri, Csaba",
        "title": "Algorithms for reinforcement learning"
      }
    ]
  },
  {
    "index": 1,
    "papers": [
      {
        "key": "kaelbling1996reinforcement",
        "author": "Kaelbling, Leslie Pack and Littman, Michael L and Moore, Andrew W",
        "title": "Reinforcement learning: A survey"
      },
      {
        "key": "arulkumaran2017deep",
        "author": "Arulkumaran, Kai and Deisenroth, Marc Peter and Brundage, Miles and Bharath, Anil Anthony",
        "title": "Deep reinforcement learning: A brief survey"
      }
    ]
  },
  {
    "index": 2,
    "papers": [
      {
        "key": "puterman2014markov",
        "author": "Puterman, Martin L",
        "title": "Markov decision processes: discrete stochastic dynamic programming"
      },
      {
        "key": "bertsekas2012dynamic",
        "author": "Bertsekas, Dimitri",
        "title": "Dynamic programming and optimal control: Volume I"
      }
    ]
  },
  {
    "index": 3,
    "papers": [
      {
        "key": "gheshlaghi2013minimax",
        "author": "Gheshlaghi Azar, Mohammad and Munos, R{\\'e}mi and Kappen, Hilbert J",
        "title": "Minimax PAC bounds on the sample complexity of reinforcement learning with a generative model"
      }
    ]
  },
  {
    "index": 4,
    "papers": [
      {
        "key": "sidford2018near",
        "author": "Sidford, Aaron and Wang, Mengdi and Wu, Xian and Yang, Lin and Ye, Yinyu",
        "title": "Near-optimal time and sample complexities for solving Markov decision processes with a generative model"
      }
    ]
  },
  {
    "index": 5,
    "papers": [
      {
        "key": "wainwright2019variance",
        "author": "Wainwright, Martin J",
        "title": "Variance-reduced $ Q $-learning is minimax optimal"
      }
    ]
  },
  {
    "index": 6,
    "papers": [
      {
        "key": "agarwal2020model",
        "author": "Agarwal, Alekh and Kakade, Sham and Yang, Lin F",
        "title": "Model-based reinforcement learning with a generative model is minimax optimal"
      }
    ]
  },
  {
    "index": 7,
    "papers": [
      {
        "key": "wang2020randomized",
        "author": "Wang, Mengdi",
        "title": "Randomized linear programming solves the markov decision problem in nearly linear (sometimes sublinear) time"
      }
    ]
  },
  {
    "index": 8,
    "papers": [
      {
        "key": "jin2020efficiently",
        "author": "Jin, Yujia and Sidford, Aaron",
        "title": "Efficiently solving MDPs with stochastic mirror descent"
      },
      {
        "key": "cheng2020reduction",
        "author": "Cheng, Ching-An and Combes, Remi Tachet and Boots, Byron and Gordon, Geoff",
        "title": "A reduction from reinforcement learning to no-regret online learning"
      }
    ]
  },
  {
    "index": 9,
    "papers": [
      {
        "key": "jin2020efficiently",
        "author": "Jin, Yujia and Sidford, Aaron",
        "title": "Efficiently solving MDPs with stochastic mirror descent"
      }
    ]
  },
  {
    "index": 10,
    "papers": [
      {
        "key": "jin2020efficiently",
        "author": "Jin, Yujia and Sidford, Aaron",
        "title": "Efficiently solving MDPs with stochastic mirror descent"
      }
    ]
  },
  {
    "index": 11,
    "papers": [
      {
        "key": "cheng2020reduction",
        "author": "Cheng, Ching-An and Combes, Remi Tachet and Boots, Byron and Gordon, Geoff",
        "title": "A reduction from reinforcement learning to no-regret online learning"
      }
    ]
  },
  {
    "index": 12,
    "papers": [
      {
        "key": "sidford2018near",
        "author": "Sidford, Aaron and Wang, Mengdi and Wu, Xian and Yang, Lin and Ye, Yinyu",
        "title": "Near-optimal time and sample complexities for solving Markov decision processes with a generative model"
      }
    ]
  },
  {
    "index": 13,
    "papers": [
      {
        "key": "wainwright2019variance",
        "author": "Wainwright, Martin J",
        "title": "Variance-reduced $ Q $-learning is minimax optimal"
      }
    ]
  },
  {
    "index": 14,
    "papers": [
      {
        "key": "agarwal2020model",
        "author": "Agarwal, Alekh and Kakade, Sham and Yang, Lin F",
        "title": "Model-based reinforcement learning with a generative model is minimax optimal"
      }
    ]
  },
  {
    "index": 15,
    "papers": [
      {
        "key": "golowich2022can",
        "author": "Golowich, Noah and Moitra, Ankur",
        "title": "Can Q-learning be improved with advice?"
      }
    ]
  },
  {
    "index": 16,
    "papers": [
      {
        "key": "li2024beyond",
        "author": "Li, Tongxin and Lin, Yiheng and Ren, Shaolei and Wierman, Adam",
        "title": "Beyond black-box advice: learning-augmented algorithms for MDPs with Q-value predictions"
      }
    ]
  },
  {
    "index": 17,
    "papers": [
      {
        "key": "cutkosky2022leveraging",
        "author": "Cutkosky, Ashok and Dann, Chris and Das, Abhimanyu and Zhang, Qiuyi",
        "title": "Leveraging initial hints for free in stochastic linear bandits"
      }
    ]
  },
  {
    "index": 18,
    "papers": [
      {
        "key": "lyu2023bandits",
        "author": "Lyu, Lixing and Cheung, Wang Chi",
        "title": "Bandits with knapsacks: advice on time-varying demands"
      }
    ]
  },
  {
    "index": 19,
    "papers": [
      {
        "key": "mitzenmacher2022algorithms",
        "author": "Mitzenmacher, Michael and Vassilvitskii, Sergei",
        "title": "Algorithms with predictions"
      }
    ]
  },
  {
    "index": 20,
    "papers": [
      {
        "key": "christianson2022chasing",
        "author": "Christianson, Nicolas and Handina, Tinashe and Wierman, Adam",
        "title": "Chasing convex bodies and functions with black-box advice"
      }
    ]
  },
  {
    "index": 21,
    "papers": [
      {
        "key": "mitzenmacher2022algorithms",
        "author": "Mitzenmacher, Michael and Vassilvitskii, Sergei",
        "title": "Algorithms with predictions"
      },
      {
        "key": "purohit2018improving",
        "author": "Purohit, Manish and Svitkina, Zoya and Kumar, Ravi",
        "title": "Improving online algorithms via ML predictions"
      }
    ]
  },
  {
    "index": 22,
    "papers": [
      {
        "key": "lykouris2021competitive",
        "author": "Lykouris, Thodoris and Vassilvitskii, Sergei",
        "title": "Competitive caching with machine learned advice"
      },
      {
        "key": "rohatgi2020near",
        "author": "Rohatgi, Dhruv",
        "title": "Near-optimal bounds for online caching with machine learned advice"
      }
    ]
  },
  {
    "index": 23,
    "papers": [
      {
        "key": "balseiro2022single",
        "author": "Balseiro, Santiago and Kroer, Christian and Kumar, Rachitesh",
        "title": "Single-leg revenue management with advice"
      },
      {
        "key": "golrezaei2023online",
        "author": "Golrezaei, Negin and Jaillet, Patrick and Zhou, Zijie",
        "title": "Online resource allocation with convex-set machine-learned advice"
      }
    ]
  },
  {
    "index": 24,
    "papers": [
      {
        "key": "jin2022online",
        "author": "Jin, Billy and Ma, Will",
        "title": "Online bipartite matching with advice: Tight robustness-consistency tradeoffs for the two-stage model"
      }
    ]
  },
  {
    "index": 25,
    "papers": [
      {
        "key": "antoniadis2020secretary",
        "author": "Antoniadis, Antonios and Gouleakis, Themis and Kleer, Pieter and Kolev, Pavel",
        "title": "Secretary and online matching problems with machine learned advice"
      },
      {
        "key": "dutting2021secretaries",
        "author": "D{\\\"u}tting, Paul and Lattanzi, Silvio and Paes Leme, Renato and Vassilvitskii, Sergei",
        "title": "Secretaries with advice"
      }
    ]
  },
  {
    "index": 26,
    "papers": [
      {
        "key": "christianson2022chasing",
        "author": "Christianson, Nicolas and Handina, Tinashe and Wierman, Adam",
        "title": "Chasing convex bodies and functions with black-box advice"
      }
    ]
  },
  {
    "index": 27,
    "papers": [
      {
        "key": "rakhlin2013online",
        "author": "Rakhlin, Alexander and Sridharan, Karthik",
        "title": "Online learning with predictable sequences"
      },
      {
        "key": "rakhlin2013optimization",
        "author": "Rakhlin, Sasha and Sridharan, Karthik",
        "title": "Optimization, learning, and games with predictable sequences"
      },
      {
        "key": "jadbabaie2015online",
        "author": "Jadbabaie, Ali and Rakhlin, Alexander and Shahrampour, Shahin and Sridharan, Karthik",
        "title": "Online optimization: Competing with dynamic comparators"
      }
    ]
  },
  {
    "index": 28,
    "papers": [
      {
        "key": "wei2020taking",
        "author": "Wei, Chen-Yu and Luo, Haipeng and Agarwal, Alekh",
        "title": "Taking a hint: How to leverage loss predictors in contextual bandits?"
      }
    ]
  },
  {
    "index": 29,
    "papers": [
      {
        "key": "carmon2022making",
        "author": "Carmon, Yair and Hinder, Oliver",
        "title": "Making sgd parameter-free"
      }
    ]
  },
  {
    "index": 30,
    "papers": [
      {
        "key": "streeter2010less",
        "author": "Streeter, Matthew and McMahan, H Brendan",
        "title": "Less regret via online conditioning"
      }
    ]
  },
  {
    "index": 31,
    "papers": [
      {
        "key": "auer2002adaptive",
        "author": "Auer, Peter and Cesa-Bianchi, Nicolo and Gentile, Claudio",
        "title": "Adaptive and self-confident on-line learning algorithms"
      },
      {
        "key": "orabona2014simultaneous",
        "author": "Orabona, Francesco",
        "title": "Simultaneous model selection and optimization through parameter-free stochastic learning"
      },
      {
        "key": "cutkosky2018black",
        "author": "Cutkosky, Ashok and Orabona, Francesco",
        "title": "Black-box reductions for parameter-free online learning in banach spaces"
      },
      {
        "key": "orabona2019modern",
        "author": "Orabona, Francesco",
        "title": "A modern introduction to online learning"
      }
    ]
  },
  {
    "index": 32,
    "papers": [
      {
        "key": "levine2020offline",
        "author": "Levine, Sergey and Kumar, Aviral and Tucker, George and Fu, Justin",
        "title": "Offline reinforcement learning: Tutorial, review, and perspectives on open problems"
      }
    ]
  },
  {
    "index": 33,
    "papers": [
      {
        "key": "fujimoto2019off",
        "author": "Fujimoto, Scott and Meger, David and Precup, Doina",
        "title": "Off-policy deep reinforcement learning without exploration"
      },
      {
        "key": "kumar2019stabilizing",
        "author": "Kumar, Aviral and Fu, Justin and Soh, Matthew and Tucker, George and Levine, Sergey",
        "title": "Stabilizing off-policy q-learning via bootstrapping error reduction"
      },
      {
        "key": "kumar2020conservative",
        "author": "Kumar, Aviral and Zhou, Aurick and Tucker, George and Levine, Sergey",
        "title": "Conservative q-learning for offline reinforcement learning"
      },
      {
        "key": "agarwal2020optimistic",
        "author": "Agarwal, Rishabh and Schuurmans, Dale and Norouzi, Mohammad",
        "title": "An optimistic perspective on offline reinforcement learning"
      },
      {
        "key": "wu2019behavior",
        "author": "Wu, Yifan and Tucker, George and Nachum, Ofir",
        "title": "Behavior regularized offline reinforcement learning"
      }
    ]
  }
]