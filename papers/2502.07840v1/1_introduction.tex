\section{Introduction}
\label{sec:intro}

% maybe a statement that says depth information is important for robot manipulation, but due to this failing for transparent objects, it makes manipulating of transparent objects difficult. 
% Manipulation of transparent objects is a critical challenge in robotics where standard depth sensors or depth completion methods often fail. This leads to incomplete depth reconstruction, noise, and artifacts. Several solutions have been proposed to address such limitations by incorporating additional sensors such as thermal infrared\cite{huo-2023-tip} or polarized cameras \cite{mei-2022-cvpr, kalra-2020-cvpr}, however, these solutions complicate hardware setup and require extensive senor calibration. 

% Manipulating transparent objects is a significant challenge in robotics, as standard depth sensors and depth completion methods often fail to provide accurate reconstructions, resulting in incomplete depth maps, noise, and artifacts. Such inaccuracies lead to incorrect 3D perception and errors in estimating grasping points for transparent objects.

Manipulating transparent objects is a significant challenge in robotics, as standard depth sensors and depth completion methods often fail to provide accurate reconstructions due to the reflections and refractions inherent in transparent materials. These optical phenomena result in incomplete depth maps, noise, and artifacts, leading to incorrect 3D perception and errors in estimating grasping points.

To address these challenges, previous solutions have focused on hardware or learning-based approaches. Hardware-based methods use additional sensors, such as thermal infrared cameras \cite{huo-2023-tip} or polarized cameras \cite{mei-2022-cvpr, kalra-2020-cvpr}, to provide auxiliary depth information. However, thermal cameras are costly to operate, and polarized cameras require specific polarized cues, complicating hardware setups.

More recent solutions emphasize learning-based methods for depth completion using single-view \cite{zhu-2021-cvpr, fang-2022-ral} and multi-view RGB images \cite{kerr-2022-corl, ichnowski-2022-corl, duisterhof2024residualnerf}, facilitated by datasets specifically targeting transparent objects \cite{wang-2022-cvpr, bashkirova-2022-cvpr, chen-2022-eccv}. Multi-view RGB methods, particularly those leveraging \ac{NeRF}, offer more robust depth completion by improving occlusion handling and scale consistency. However, existing methods face three key limitations. First, transparent objects, as non-Lambertian surfaces \cite{sajjan2020clear}, are highly sensitive to changes in illumination and viewpoint, causing photometric inconsistencies. When using NeRF or \ac{3D-GS} for depth rendering, these inconsistencies introduce noise and artifacts in the depth maps. Second, directly rendering transparent surfaces based solely on RGB images often causes opacity values to collapse to zero \cite{lee2023nfl}, resulting in holes in the reconstructed depth. Third, NeRF-based techniques for novel view synthesis of transparent objects, despite recent advancements \cite{ichnowski-2022-corl,duisterhof2024residualnerf}, still suffer from slow inference times.
% More recently, several datasets on transparent objects have been proposed \cite{wang-2022-cvpr, bashkirova-2022-cvpr, chen-2022-eccv} with a growing interest in transparent object manipulation. Subsequent works thus proposed various learning-based solutions for depth completion of transparent objects from single RGB images \cite{zhu-2021-cvpr, fang-2022-ral} and multi-view RGB images \cite{kerr-2022-corl, ichnowski-2022-corl, duisterhof2024residualnerf}. In particular, multi-view RGB based methods utilized \ac{NeRF} for depth completion of transparent objects, offering more robustness to occlusion and scale consistency. 



%To address these limitations, researchers have explored several approaches, including the use of specialized hardware like thermal \cite{huo-2023-tip} or polarized cameras \cite{mei-2022-cvpr, kalra-2020-cvpr}. While effective, these solutions require additional equipment beyond standard RGB cameras, limiting their practical application. Consequently, there has been growing interest in reconstructing depth using only RGB images, especially as transparent object datasets \cite{wang-2022-cvpr, bashkirova-2022-cvpr, chen-2022-eccv} become more readily available. This has led to the development of advanced techniques, such as single-view depth completion \cite{zhu-2021-cvpr, fang-2022-ral}.


\begin{figure}[!t]
    \centering
    \includegraphics[width=1\linewidth]{figure/figure1_ver3.pdf}
    \caption{TranSplat optimizes 3D Gaussian splatting by jointly training with RGB and surface embeddings as inputs. This approach prevents the opacity of transparent objects from collapsing to zero and ensures smooth rendering, leading to accurate depth completion and reliable grasping points.}
    \label{fig:figure1}
    \vspace{-7mm}
\end{figure}

% \begin{figure}[t]
%   \centering
%   % \hfill
%   \begin{subfigure}{\columnwidth}
%     \centering
%     \includegraphics[width=0.8\columnwidth]{figure/fig1a_jyk.png}
%     \caption{Conventional depth completion method for transparent objects}
%     \label{fig:conventional}
%   \end{subfigure}
%   \begin{subfigure}{\columnwidth}
%     \centering
%     \includegraphics[width=\columnwidth]{figure/fig1b_jyk.png}
%     \caption{Depth rendering of transparent objects based on TranSplat}
%     \label{fig:transplat_overview}
%   \end{subfigure}
%   \caption{TranSplat renders 3D Gaussian splatting by joint optimization of guassian kernels from both RGB and surface embedding inputs. The use of both inputs prevent opacity of transparent from collapsing down to zero while maintaining smooth rendering of transparent object surfaces, resulting in accurate depth completion and robot grasping points. }
%   \label{fig:overview1}
% \end{figure}


\begin{figure*}[t]
    \centering
    \includegraphics[width=\linewidth]{figure/figure2.pdf}
    \caption{Overview of the TranSplat method for manipulating transparent objects. First, data is collected using a robot manipulator. Next, a latent diffusion model is employed to learn surface embeddings. Then, both surface embeddings and RGB images are used for joint Gaussian optimization. Finally, depth is rendered to enable accurate robotic grasping.}
    \label{fig:method-overview}
    \vspace{-6mm}
\end{figure*}

%caption: (a)에서 RGB to surfemb using latent diffusion model로 preprocessing (b)에서는 3d-GS에서는 depth rendering결과가 별로여서 grasp fail, TranSplat은 surfemb을 함께 넣어줘 depth가 잘나와서 success

In our work, we propose TranSplat (\figref{fig:figure1}), a novel method combining the strengths of \ac{3D-GS} \cite{kerbl20233d} and latent diffusion models to improve the reconstruction of transparent objects. TranSplat uses latent diffusion models to extract surface embeddings—continuous surface representations \cite{lee2023nfl, haugaard2022surfemb}—from transparent object features, ensuring consistent representations that are robust to changes in illumination and viewpoint. This reduces noise and artifacts in depth maps. Additionally, TranSplat introduces a jointly-optimized \ac{3D-GS} approach that synthesizes novel views of transparent objects by using both surface embeddings and RGB images. The surface embeddings, acting as surrogate features for non-Lambertian surfaces, prevent the collapse of opacity values and yield accurate depth representation of transparent surfaces. Moreover, employing \ac{3D-GS} instead of NeRF not only speeds up rendering but also enhances depth completion accuracy for transparent objects.

% TranSplat demonstrates significant improvement in depth completion accuracy when extensively evaluated on both synthetic dataset and real world transparent object benchmark, TRansPose \cite{kim2024transpose}. We further show its robustness and feasibility for manipulation through robot grasping of transparent objects. The key contributions of our work include the following:
TranSplat demonstrates significant improvements in depth completion accuracy on both synthetic datasets and the real-world TRansPose dataset \cite{kim2024transpose}. We further evaluate its effectiveness in depth estimation by applying it to transparent object manipulation, achieving accurate detection of grasping points. The key contributions of our work include:

\begin{itemize}
    \item \textbf{Diffusion-based Surface Embeddings}: We introduce a novel latent diffusion model specifically designed for transparent objects. This model generates background-agnostic surface embeddings that provide consistent representations of transparent surfaces, regardless of viewpoint and illumination changes. By leveraging surface embeddings, our approach achieves enhanced interframe consistency across consecutive RGB images, improving the overall quality of depth completion.
    % \item \textbf{Gaussian Splatting for transparent object}: We propose an improved alpha blending method for transparent objects. Our alpha blending incorporates both surface embeddings and RGB images to acquire accurate depth reconstruction from various transparent objects. We further demonstrate the efficacy of our method through real world grasping of transparent objects.   
    \item \textbf{Gaussian Splatting for Transparent object}: We propose an enhanced \ac{3D-GS} method through joint optimization of Gaussian kernels using both RGB images and surface embeddings. This approach effectively captures the surface characteristics of transparent objects, achieving accurate depth reconstruction. We further demonstrate the efficacy of our method through real world grasping of transparent objects.     
    \item \textbf{Open-sourcing Synthetic Dataset}: Our model and the synthetic datasets used for this work will be open-sourced for future development to this field. 
    
\end{itemize}


%the introduction of diffusion-based surface feature generation to address the unique challenges posed by transparent objects, the enhancement of Gaussian Splatting for improved depth perception, and the provision of synthetic data to facilitate further research in this area.
 

%We tackle the speed limitations of \ac{NeRF}-based methods by leveraging Gaussian Splatting, which offers a more efficient rendering process.  While our method draws conceptual inspiration from , 


%the application of diffusion models for surface feature generation is an innovation unique to this paper. These surface features are seamlessly integrated into the Gaussian Splatting framework, which not only improves consistency across views but also effectively addresses the issue of alpha blending—a challenge that can otherwise lead to the exclusion of transparent objects from the final depth reconstruction.


















% These approaches requires specific
% proprioceptive
% do not provide direct measurements of the system’s pose (rotation and position) in space, given initial pose and velocity conditions, one can integrate these data following the classical mechanics’ equations to obtain information about the system’s trajectory through time.
% It is common to compute a discrete numerical integration assuming piecewise constant angular velocities, which can be inaccurate.


