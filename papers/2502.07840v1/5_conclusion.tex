\section{Conclusion}
\label{sec:conclusion}
\begin{figure}[!t]
    \centering
    \includegraphics[width=1\linewidth]{figure/grasp_result.pdf}
    \caption{The first column is RGB images. The second column shows the grasp planning locations from Graspnet. }
    \label{fig:grasp_result}
    \vspace{-5mm}
\end{figure}

Accurately capturing the depth of transparent objects remains a significant challenge for conventional depth sensors, which often struggle with transparency. Existing methods using radiance field-based techniques attempt to address this by rendering depth from novel views, but they often fail to handle transparent surfaces adequately, leading to incomplete depth renderings. In this work, we introduced TranSplat, which overcomes this limitation by incorporating surface embeddings generated through latent diffusion models. TranSplat consistently outperforms existing methods in accurately capturing the depth of transparent objects in both synthetic and real-world datasets, including practical applications in robot grasping tasks. For future work, we plan to enhance TranSplat by estimating uncertainties in the input RGB images used for conditioning, further improving its robustness and applicability.



% This improvement would enable TranSplat to dynamically decide whether to use RGB conditioning based on the presence of image degradation, thereby further optimizing its performance in varying real-world conditions.


\newpage