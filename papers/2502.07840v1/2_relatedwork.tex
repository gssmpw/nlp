

\section{related work}
\label{sec:relatedwork}

\subsection{Explicit Representation for Robot Manipulation}
% In robot manipulation, various explicit representations have been used to model objects in discrete spaces, such as keypoints \cite{mjeon-2022-ral} or object poses. Recent studies have shown that continuous surface representations provide better modeling capabilities, particularly for handling objects with symmetric axes \cite{haugaard2023multi}. One such approach is SurfEmb \cite{haugaard2022surfemb}, which generates dense features based on 3D CAD models to facilitate 2D-3D matching. However, SurfEmb's dependence on 3D CAD models for each object and the need for separate networks for different objects limit its scalability.

% To overcome these limitations, NeuSurfEmb \cite{milano2024neusurfemb} uses \ac{NeRF} to generate large-scale synthetic datasets for training, enabling dense correspondence matching across a variety of objects without requiring CAD models. In our work, we adopt SurfEmb to represent transparent objects due to its scene-agnostic characteristics. This property ensures local consistency in the representation of transparent objects between consecutive image frames, making it particularly suitable for applications involving dynamic environments.
% In our work, we use SurfEmb to represent from transparent objects, which has scene-agnostic characteristic. Such characteristic enables local consistency in transparent object representation between consecutive image frames.

In robot manipulation, explicit object representations such as keypoints \cite{mjeon-2022-ral} and object poses have been commonly used, but recent studies suggest that continuous surface representations, like SurfEmb \cite{haugaard2022surfemb}, offer better modeling capabilities, especially for symmetric objects \cite{haugaard2023multi}. SurfEmb facilitates 2D-3D matching by generating dense features from 3D CAD models; however, its reliance on CAD models and the need for separate networks for each object limit its scalability. To address these issues, NeuSurfEmb \cite{milano2024neusurfemb} employs \ac{NeRF} to create large-scale synthetic datasets, enabling dense correspondence matching without CAD models. In our work, we leverage SurfEmb for transparent objects due to its scene-agnostic nature, which ensures consistent representation across consecutive frames, making it effective for dynamic environments.

\subsection{Latent Diffusion for Representation Generation}

With the growing popularity of latent diffusion models for image generation, these models have also demonstrated versatility in various vision tasks, such as depth estimation \cite{Ke2024marigold}, object detection \cite{chen2023diffusiondet}, optical flow \cite{saxena2024surprising}, and visual navigation \cite{sridhar2024nomad}. In robotic manipulation, diffusion models have been utilized to formulate representations for pose estimation. A notable example is 6D-Diff \cite{xu20246ddiff}, which leverages diffusion models to generate keypoint representations, resulting in improved pose estimation accuracy. To the best of our knowledge, our work is the first to employ latent diffusion models to generate explicit representations of transparent objects in the form of SurfEmb.

\subsection{Depth Completion for Grasping Transparent Objects}

% Depth completion for transparent objects presents unique challenges that are still being addressed by the research community. Supervised methods, relies on securing paired image-depth paired data from datasets like Dex-NeRF \cite{ichnowski-2022-corl}, ClearPose \cite{chen-2022-eccv}, and TRansPose \cite{kim2024transpose}, however, for novel objects, it faces significant challenges in obtaining accurate 3D CAD models. In particular, for synthetic data, achieving visual fidelity for closing the sim-to-real gap is difficult; similarly, for real for data, acquiring accurate ground truth for real-world data is challenging, leading to reduced performance when these models are applied to out-of-domain scenarios. This limits their effectiveness in practical applications such as robotic grasping.

Depth completion for transparent objects presents unique challenges that are still being addressed by the research community. Supervised methods rely on paired image-depth data from existing datasets \cite{ichnowski-2022-corl, chen-2022-eccv, kim2024transpose}, but obtaining accurate 3D CAD models for novel objects is difficult. Moreover, achieving visual fidelity in synthetic data and obtaining precise ground truth in real data remain challenging, leading to reduced performance in out-of-domain scenarios and limiting effectiveness in practical applications like robotic grasping.

Recent approaches have used radiance field-based methods \cite{ichnowski-2022-corl, kerr-2022-corl, duisterhof2024residualnerf} for depth completion through 3D scene reconstruction. Although \ac{NeRF}-based methods, including those using \ac{SH} coefficients, have shown promise in handling non-Lambertian surfaces, they struggle with transparent objects due to inconsistencies caused by reflection and refraction. Concurrent methods have tried to mitigate inter-frame inconsistencies by extracting geometry using object masks \cite{chen2023nerrf, ummadisingu2024said}. While these techniques achieve higher surface density through MLP outputs, they often face challenges in maintaining consistency and rely heavily on mask priors, which complicates handling the complexities of transparent objects.