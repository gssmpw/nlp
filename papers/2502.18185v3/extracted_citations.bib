@inproceedings{Lam2021,
  title={Paying attention to varying receptive fields: object detection with Atrous filters and vision transformers},
  author={Lam, A. and Lim, J. Y. and Sutopo, R. and Baskaran, V. M.},
  booktitle={British Machine Vision Conference 2021},
  year={2021},
  journal={British Machine Vision Association}
}

@inproceedings{Liu2022,
  title={Skin lesion segmentation via intensive atrous spatial transformer},
  author={Liu, X. and Fan, W. and Zhou, D.},
  booktitle={International Conference on Wireless Algorithms, Systems, and Applications},
  pages={15--26},
  year={2022},
  publisher={Springer Nature Switzerland},
}

@ARTICLE{TONG2024213,
  author  = {Tong, L. and Li, T. and Zhang, Q. and Zhang, Q. and Zhu, R. and Du, W. and Hu, P.},
  title   = {LiViT-Net: A U-Net-like, lightweight Transformer network for retinal vessel segmentation},
  journal = {Computational and Structural Biotechnology},
  pages   = {213--224},
  year    = {2024}
}

@ARTICLE{Yu2015,
  author  = {Yu, F. and Koltun, V.},
  title   = {Multi-Scale Context Aggregation by Dilated Convolutions},
  journal = {arXiv preprint arXiv:1511.07122},
  year    = {2015}
}

@ARTICLE{r10,
  author  = {Ma, J. and He, Y. and Li, F. and Han, L. and You, C. and Wang, B.},
  title   = {Segment anything in medical images},
  journal = {Nature Communications},
  volume  = {15},
  number  = {1},
  pages   = {654},
  year    = {2024}
}

@ARTICLE{r11,
  author  = {Zhang, K. and Liu, D.},
  title   = {Customized segment anything model for medical image segmentation},
  journal = {arXiv preprint arXiv:2304.13785},
  year    = {2023}
}

@inproceedings{r19,
  title={Sam-adapter: Adapting segment anything in underperformed scenes},
  author={Chen, Tianrun and Zhu, Lanyun and Deng, Chaotao and Cao, Runlong and Wang, Yan and Zhang, Shangzhan and Li, Zejian and Sun, Lingyun and Zang, Ying and Mao, Papa},
  booktitle={Proceedings of the IEEE/CVF International Conference on Computer Vision},
  pages={3367--3375},
  year={2023}
}

@ARTICLE{r20,
  author  = {Chen, Z. and Duan, Y. and Wang, W. and He, J. and Lu, T. and Dai, J. and Qiao, Y.},
  title   = {Vision Transformer Adapter for Dense Predictions},
  journal = {The Eleventh International Conference on Learning Representations.},
  year    = {2022}
}

@inproceedings{r8,
  title={Unetr: Transformers for 3d medical image segmentation},
  author={Hatamizadeh, Ali and Tang, Yucheng and Nath, Vishwesh and Yang, Dong and Myronenko, Andriy and Landman, Bennett and Roth, Holger R and Xu, Daguang},
  booktitle={Proceedings of the IEEE/CVF winter conference on applications of computer vision},
  pages={574--584},
  year={2022}
}

@ARTICLE{r9,
  author  = {Huang, Y. and Yang, X. and Liu, L. and Zhou, H. and Chang, A. and Zhou, X. and Chen, R. and Yu, J. and Chen, J. and Chen, C. and others},
  title   = {Segment anything model for medical images?},
  journal = {Medical Image Analysis},
  volume  = {92},
  pages   = {103061},
  year    = {2024}
}

