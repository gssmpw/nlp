\section{Discussion}
\paragraph{Compositional generalization}
Our results indicate that CLIP has a (weak) ability for compositional generalization, which is influenced by the composition of its training data. Specifically, CLIP's compositional generalization performance worsens when a subset of classes of the test domain, that is queried during evaluation, is seen during training (\cref{tab:cg-overfitting}).
However, by including only classes that do not overlap with the queried classes in the training data, CLIP's compositional generalization significantly narrows the gap to the maximally achievable performance.
In particular, performance on unseen sketch classes significantly improved from 19.5\% (Natural-only) to 36.9\% (CG high-diversity w/ non-queried classes only, \cref{tab:cg-overfitting}), approaching the maximally achievable performance of 44.3\% (\cref{tab:generalization-gap}). This result supports the hypothesis that compositional generalization could be indeed a driver behind CLIP's generalization.

Our results also allow us to reinterpret the main experiment from \citet[Table 1]{mayilvahanan2024does}. In their experiment, the maximally achievable performance corresponds to the unaltered LAION-200M dataset, while the pruned versions of LAION-200M--where, \eg, (near) duplicates of all ImageNet-Sketch classes were removed--can be interpreted analogous to the curated compositional generalization setting with high diversity from above. They observed only a slight deterioration in performance despite these exclusions. Our result suggests that compositional generalization could be the key contributor of the sustained performance observed here, though further analysis is required to exclude other (unknown) factors.

\paragraph{Rethinking CLIP's \acrshort{ood} generalization}
Recent works have concluded that CLIP's \acrshort{ood} generalization is largely driven by its vast and diverse training distribution \citep{fang2022data,mayilvahanan2024search}. Our experiments reaffirm that while CLIP can \emph{weakly} generalize (\cref{fig:effective-robustness}), a gap persists when compared to a model that has been exposed to class-specific samples of the test domain(s) (\cref{tab:generalization-gap}). We believe it is worth studying how narrow this gap can become and if this gap can ever be closed without access to (near) duplicate samples during training.

\paragraph{Mechanistic similarity analysis}
Mechanistic similarity analysis (\cref{sec:quickdraw}) is a general framework that first discovers circuits and then measures their similarity. In future work, we plan to apply this framework to other problems, \eg, to investigate whether multi-lingual LLMs process different languages in similar or very different ways.

\paragraph{Larger dataset sizes}
At the time of writing, to the best of our knowledge, no large-scale domain datasets comparable to DomainNet currently exists. To address this, future work could filter a diverse dataset, such as LAION \citep{schuhmann2021laion}, by domains. For example, the data filtering approach of \citet{mayilvahanan2024search}, which filters images into natural and non-natural, could be extended to various visual domains. The existing filtered natural-only subset of LAION-200M from \citeauthor{mayilvahanan2024search} could be directly adopted as our base dataset $D_0$.

Although, this would help overcome the scarcity of domain-specific data, we lack the computational resources to conduct such large-scale experiments. However, we are confident that our findings remain robust across dataset sizes, as demonstrated by consistent results in all three base datasets, with sizes ranging from approximately 0.5~M to 10~M samples, in \cref{app:other_choices}.

\paragraph{Carbon emission estimate}
We conducted our experiments mainly on NVIDIA RTX 2080 GPUs and estimated the total GPU hours to be approximately $25\,000$. With a carbon efficiency of 0.482~kgCO$_2$eq/kWh\footnote{Estimated carbon efficiency of the global power grid in 2023. Numbers for 2024 were not released at time of writing.}, total emissions are estimated to be about $2\,600$~kgCO$_2$eq, using the \href{https://mlco2.github.io/impact#compute}{Machine Learning Impact calculator} \citep{lacoste2019quantifying}.

\section{Conclusion}
In this work, we analyzed when CLIP generalizes to unseen domains and domain-class pairs using systematically created training data setups (see \cref{fig:dataset-setup}), identifying domain diversity as a prerequisite for both domain and compositional generalization. We showed that compositional generalization can fail in certain scenarios, \ie, even perform worse than domain generalization. We supported these findings with in-depth experiments and mechanistic analyses, offering insights into the internal workings that make generalization succeed or fail.