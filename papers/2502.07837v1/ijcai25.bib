@article{A1,
  title={Masked visual pre-training for motor control},
  author={Xiao, Tete and Radosavovic, Ilija and Darrell, Trevor and Malik, Jitendra},
  journal={arXiv preprint arXiv:2203.06173},
  year={2022}
}

@inproceedings{A2,
  title={Masked autoencoders are scalable vision learners},
  author={He, Kaiming and Chen, Xinlei and Xie, Saining and Li, Yanghao and Doll{\'a}r, Piotr and Girshick, Ross},
  booktitle={Proceedings of the IEEE/CVF conference on computer vision and pattern recognition},
  pages={16000--16009},
  year={2022}
}

@inproceedings{A3,
  title={Real-world robot learning with masked visual pre-training},
  author={Radosavovic, Ilija and Xiao, Tete and James, Stephen and Abbeel, Pieter and Malik, Jitendra and Darrell, Trevor},
  booktitle={Conference on Robot Learning},
  pages={416--426},
  year={2023},
  organization={PMLR}
}

@article{A4,
  title={See, hear, and feel: Smart sensory fusion for robotic manipulation},
  author={Li, Hao and Zhang, Yizhi and Zhu, Junzhe and Wang, Shaoxiong and Lee, Michelle A and Xu, Huazhe and Adelson, Edward and Fei-Fei, Li and Gao, Ruohan and Wu, Jiajun},
  journal={arXiv preprint arXiv:2212.03858},
  year={2022}
}

@article{A5,
  title={Vision-language foundation models as effective robot imitators},
  author={Li, Xinghang and Liu, Minghuan and Zhang, Hanbo and Yu, Cunjun and Xu, Jie and Wu, Hongtao and Cheang, Chilam and Jing, Ya and Zhang, Weinan and Liu, Huaping and others},
  journal={arXiv preprint arXiv:2311.01378},
  year={2023}
}

@inproceedings{A6,
  title={Cliport: What and where pathways for robotic manipulation},
  author={Shridhar, Mohit and Manuelli, Lucas and Fox, Dieter},
  booktitle={Conference on robot learning},
  pages={894--906},
  year={2022},
  organization={PMLR}
}

@article{A7,
  title={Rt-2: Vision-language-action models transfer web knowledge to robotic control},
  author={Brohan, Anthony and Brown, Noah and Carbajal, Justice and Chebotar, Yevgen and Chen, Xi and Choromanski, Krzysztof and Ding, Tianli and Driess, Danny and Dubey, Avinava and Finn, Chelsea and others},
  journal={arXiv preprint arXiv:2307.15818},
  year={2023}
}

@article{A8,
  title={Attention is all you need},
  author={Vaswani, Ashish},
  journal={arXiv preprint arXiv:1706.03762},
  year={2017}
}

@article{A9,
  title={Bert: Pre-training of deep bidirectional transformers for language understanding},
  author={Devlin, Jacob},
  journal={arXiv preprint arXiv:1810.04805},
  year={2018}
}

@inproceedings{A10,
  title={Learning transferable visual models from natural language supervision},
  author={Radford, Alec and Kim, Jong Wook and Hallacy, Chris and Ramesh, Aditya and Goh, Gabriel and Agarwal, Sandhini and Sastry, Girish and Askell, Amanda and Mishkin, Pamela and Clark, Jack and others},
  booktitle={International conference on machine learning},
  pages={8748--8763},
  year={2021},
  organization={PMLR}
}

@article{A11,
  title={Improving language understanding by generative pre-training},
  author={Radford, Alec and Narasimhan, Karthik and Salimans, Tim and Sutskever, Ilya and others},
  year={2018},
  publisher={San Francisco, CA, USA}
}

@article{A12,
  title={Language models are unsupervised multitask learners},
  author={Radford, Alec and Wu, Jeffrey and Child, Rewon and Luan, David and Amodei, Dario and Sutskever, Ilya and others},
  journal={OpenAI blog},
  volume={1},
  number={8},
  pages={9},
  year={2019}
}

@article{A13,
  title={Language models are few-shot learners},
  author={Brown, Tom and Mann, Benjamin and Ryder, Nick and Subbiah, Melanie and Kaplan, Jared D and Dhariwal, Prafulla and Neelakantan, Arvind and Shyam, Pranav and Sastry, Girish and Askell, Amanda and others},
  journal={Advances in neural information processing systems},
  volume={33},
  pages={1877--1901},
  year={2020}
}

@article{A14,
  title={A survey on multimodal large language models},
  author={Yin, Shukang and Fu, Chaoyou and Zhao, Sirui and Li, Ke and Sun, Xing and Xu, Tong and Chen, Enhong},
  journal={arXiv preprint arXiv:2306.13549},
  year={2023}
}

@article{A14-2,
  title={Foundation models in robotics: Applications, challenges, and the future},
  author={Firoozi, Roya and Tucker, Johnathan and Tian, Stephen and Majumdar, Anirudha and Sun, Jiankai and Liu, Weiyu and Zhu, Yuke and Song, Shuran and Kapoor, Ashish and Hausman, Karol and others},
  journal={arXiv preprint arXiv:2312.07843},
  year={2023}
}

@article{A15,
  title={Visual instruction tuning},
  author={Liu, Haotian and Li, Chunyuan and Wu, Qingyang and Lee, Yong Jae},
  journal={Advances in neural information processing systems},
  volume={36},
  year={2024}
}

@inproceedings{A16,
  title={Blip-2: Bootstrapping language-image pre-training with frozen image encoders and large language models},
  author={Li, Junnan and Li, Dongxu and Savarese, Silvio and Hoi, Steven},
  booktitle={International conference on machine learning},
  pages={19730--19742},
  year={2023},
  organization={PMLR}
}

@article{A17,
  title={Flamingo: a visual language model for few-shot learning},
  author={Alayrac, Jean-Baptiste and Donahue, Jeff and Luc, Pauline and Miech, Antoine and Barr, Iain and Hasson, Yana and Lenc, Karel and Mensch, Arthur and Millican, Katherine and Reynolds, Malcolm and others},
  journal={Advances in neural information processing systems},
  volume={35},
  pages={23716--23736},
  year={2022}
}

@inproceedings{A18,
  title={Deep residual learning for image recognition},
  author={He, Kaiming and Zhang, Xiangyu and Ren, Shaoqing and Sun, Jian},
  booktitle={Proceedings of the IEEE conference on computer vision and pattern recognition},
  pages={770--778},
  year={2016}
}

@article{A19,
  title={An intriguing failing of convolutional neural networks and the coordconv solution},
  author={Liu, Rosanne and Lehman, Joel and Molino, Piero and Petroski Such, Felipe and Frank, Eric and Sergeev, Alex and Yosinski, Jason},
  journal={Advances in neural information processing systems},
  volume={31},
  year={2018}
}

@article{A20,
  title={Calvin: A benchmark for language-conditioned policy learning for long-horizon robot manipulation tasks},
  author={Mees, Oier and Hermann, Lukas and Rosete-Beas, Erick and Burgard, Wolfram},
  journal={IEEE Robotics and Automation Letters},
  volume={7},
  number={3},
  pages={7327--7334},
  year={2022},
  publisher={IEEE}
}

@article{A21,
  title={Llama: Open and efficient foundation language models},
  author={Touvron, Hugo and Lavril, Thibaut and Izacard, Gautier and Martinet, Xavier and Lachaux, Marie-Anne and Lacroix, Timoth{\'e}e and Rozi{\`e}re, Baptiste and Goyal, Naman and Hambro, Eric and Azhar, Faisal and others},
  journal={arXiv preprint arXiv:2302.13971},
  year={2023}
}

@article{A22,
  title={Llama-adapter: Efficient fine-tuning of language models with zero-init attention},
  author={Zhang, Renrui and Han, Jiaming and Liu, Chris and Gao, Peng and Zhou, Aojun and Hu, Xiangfei and Yan, Shilin and Lu, Pan and Li, Hongsheng and Qiao, Yu},
  journal={arXiv preprint arXiv:2303.16199},
  year={2023}
}

@article{A24,
  title={A generalist agent},
  author={Reed, Scott and Zolna, Konrad and Parisotto, Emilio and Colmenarejo, Sergio Gomez and Novikov, Alexander and Barth-Maron, Gabriel and Gimenez, Mai and Sulsky, Yury and Kay, Jackie and Springenberg, Jost Tobias and others},
  journal={arXiv preprint arXiv:2205.06175},
  year={2022}
}

@inproceedings{A25,
  title={Perceiver-actor: A multi-task transformer for robotic manipulation},
  author={Shridhar, Mohit and Manuelli, Lucas and Fox, Dieter},
  booktitle={Conference on Robot Learning},
  pages={785--799},
  year={2023},
  organization={PMLR}
}

@inproceedings{A26,
  title={Blip: Bootstrapping language-image pre-training for unified vision-language understanding and generation},
  author={Li, Junnan and Li, Dongxu and Xiong, Caiming and Hoi, Steven},
  booktitle={International conference on machine learning},
  pages={12888--12900},
  year={2022},
  organization={PMLR}
}

@article{A27,
  title={Interactive language: Talking to robots in real time},
  author={Lynch, Corey and Wahid, Ayzaan and Tompson, Jonathan and Ding, Tianli and Betker, James and Baruch, Robert and Armstrong, Travis and Florence, Pete},
  journal={IEEE Robotics and Automation Letters},
  year={2023},
  publisher={IEEE}
}

@article{A28,
  title={Energy-based imitation learning},
  author={Liu, Minghuan and He, Tairan and Xu, Minkai and Zhang, Weinan},
  journal={arXiv preprint arXiv:2004.09395},
  year={2020}
}

@article{A29,
  title={Diffusion policy: Visuomotor policy learning via action diffusion},
  author={Chi, Cheng and Feng, Siyuan and Du, Yilun and Xu, Zhenjia and Cousineau, Eric and Burchfiel, Benjamin and Song, Shuran},
  journal={arXiv preprint arXiv:2303.04137},
  year={2023}
}

@article{A30,
  title={Steps toward artificial intelligence},
  author={Minsky, Marvin},
  journal={Proceedings of the IRE},
  volume={49},
  number={1},
  pages={8--30},
  year={1961},
  publisher={IEEE}
}

@article{A31,
  title={Alvinn: An autonomous land vehicle in a neural network},
  author={Pomerleau, Dean A},
  journal={Advances in neural information processing systems},
  volume={1},
  year={1988}
}

@article{A32,
  title={What matters in language conditioned robotic imitation learning over unstructured data},
  author={Mees, Oier and Hermann, Lukas and Burgard, Wolfram},
  journal={IEEE Robotics and Automation Letters},
  volume={7},
  number={4},
  pages={11205--11212},
  year={2022},
  publisher={IEEE}
}

@article{A33,
  title={Learning fine-grained bimanual manipulation with low-cost hardware},
  author={Zhao, Tony Z and Kumar, Vikash and Levine, Sergey and Finn, Chelsea},
  journal={arXiv preprint arXiv:2304.13705},
  year={2023}
}

@article{A34,
  title={Unleashing large-scale video generative pre-training for visual robot manipulation},
  author={Wu, Hongtao and Jing, Ya and Cheang, Chilam and Chen, Guangzeng and Xu, Jiafeng and Li, Xinghang and Liu, Minghuan and Li, Hang and Kong, Tao},
  journal={arXiv preprint arXiv:2312.13139},
  year={2023}
}

@inproceedings{A35,
  title={You only look once: Unified, real-time object detection},
  author={Redmon, Joseph and Divvala, Santosh and Girshick, Ross and Farhadi, Ali},
  booktitle={Proceedings of the IEEE conference on computer vision and pattern recognition},
  pages={779--788},
  year={2016}
}

@inproceedings{A36,
  title={Multimodal Diffusion Transformer: Learning Versatile Behavior from Multimodal Goals},
  author={Reuss, Moritz and Ya{\u{g}}murlu, {\"O}mer Erdin{\c{c}} and Wenzel, Fabian and Lioutikov, Rudolf},
  booktitle={First Workshop on Vision-Language Models for Navigation and Manipulation at ICRA 2024},
  year={2024}
}

@article{A37,
  title={An image is worth 16x16 words: Transformers for image recognition at scale},
  author={Dosovitskiy, Alexey and Beyer, Lucas and Kolesnikov, Alexander and Weissenborn, Dirk and Zhai, Xiaohua and Unterthiner, Thomas and Dehghani, Mostafa and Minderer, Matthias and Heigold, Georg and Gelly, Sylvain and others},
  journal={arXiv preprint arXiv:2010.11929},
  year={2020}
}

@article{A38,
  title={Language conditioned imitation learning over unstructured data},
  author={Lynch, Corey and Sermanet, Pierre},
  journal={arXiv preprint arXiv:2005.07648},
  year={2020}
}

@inproceedings{A39,
  title={Unified-io: A unified model for vision, language, and multi-modal tasks},
  author={Lu, Jiasen and Clark, Christopher and Zellers, Rowan and Mottaghi, Roozbeh and Kembhavi, Aniruddha},
  booktitle={The Eleventh International Conference on Learning Representations},
  year={2022}
}

@article{A40,
      title={DeeR-VLA: Dynamic Inference of Multimodal Large Language Models for Efficient Robot Execution}, 
      author={Yang Yue and Yulin Wang and Bingyi Kang and Yizeng Han and Shenzhi Wang and Shiji Song and Jiashi Feng and Gao Huang},
      year={2024},
      eprint={2411.02359},
      archivePrefix={arXiv},
      primaryClass={cs.RO},
      url={https://arxiv.org/abs/2411.02359}, 
}

@article{A41,
      title={Efficient Diffusion Transformer Policies with Mixture of Expert Denoisers for Multitask Learning}, 
      author={Moritz Reuss and Jyothish Pari and Pulkit Agrawal and Rudolf Lioutikov},
      year={2024},
      eprint={2412.12953},
      archivePrefix={arXiv},
      primaryClass={cs.LG},
      url={https://arxiv.org/abs/2412.12953}, 
}

@article{A42,
      title={3D Diffuser Actor: Policy Diffusion with 3D Scene Representations}, 
      author={Tsung-Wei Ke and Nikolaos Gkanatsios and Katerina Fragkiadaki},
      year={2024},
      eprint={2402.10885},
      archivePrefix={arXiv},
      primaryClass={cs.RO},
      url={https://arxiv.org/abs/2402.10885}, 
}

@article{A43,
      title={mixup: Beyond Empirical Risk Minimization}, 
      author={Hongyi Zhang and Moustapha Cisse and Yann N. Dauphin and David Lopez-Paz},
      year={2018},
      eprint={1710.09412},
      archivePrefix={arXiv},
      primaryClass={cs.LG},
      url={https://arxiv.org/abs/1710.09412}, 
}

@article{A44,
      title={RoboAgent: Generalization and Efficiency in Robot Manipulation via Semantic Augmentations and Action Chunking}, 
      author={Homanga Bharadhwaj and Jay Vakil and Mohit Sharma and Abhinav Gupta and Shubham Tulsiani and Vikash Kumar},
      year={2023},
      eprint={2309.01918},
      archivePrefix={arXiv},
      primaryClass={cs.RO},
      url={https://arxiv.org/abs/2309.01918}, 
}

@article{A45,
      title={RT-1: Robotics Transformer for Real-World Control at Scale}, 
      author={Anthony Brohan and Noah Brown and Justice Carbajal and Yevgen Chebotar and Joseph Dabis and Chelsea Finn and Keerthana Gopalakrishnan and Karol Hausman and Alex Herzog and Jasmine Hsu and Julian Ibarz and Brian Ichter and Alex Irpan and Tomas Jackson and Sally Jesmonth and Nikhil J Joshi and Ryan Julian and Dmitry Kalashnikov and Yuheng Kuang and Isabel Leal and Kuang-Huei Lee and Sergey Levine and Yao Lu and Utsav Malla and Deeksha Manjunath and Igor Mordatch and Ofir Nachum and Carolina Parada and Jodilyn Peralta and Emily Perez and Karl Pertsch and Jornell Quiambao and Kanishka Rao and Michael Ryoo and Grecia Salazar and Pannag Sanketi and Kevin Sayed and Jaspiar Singh and Sumedh Sontakke and Austin Stone and Clayton Tan and Huong Tran and Vincent Vanhoucke and Steve Vega and Quan Vuong and Fei Xia and Ted Xiao and Peng Xu and Sichun Xu and Tianhe Yu and Brianna Zitkovich},
      year={2023},
      eprint={2212.06817},
      archivePrefix={arXiv},
      primaryClass={cs.RO},
      url={https://arxiv.org/abs/2212.06817}, 
}