\section{Related Work}
\label{sec:relatedwork}

\begin{comment}

\cite{wang2021neurips}
\cite{mei2024energy}
\cite{wang2022ivc}
\cite{hendrycks2022icml}
\cite{zhao2023open}
\cite{zhao2023towards}
\end{comment}

We briefly introduce uncertainty estimation methods and review the most relevant work in OOD detection for single- and multi-label object recognition.

\subsubsection{Uncertainty Estimation.}
Uncertainty is primarily categorized into two types: epistemic uncertainty, which arises from insufficient training data, and aleatoric uncertainty, which is associated with random noise during sample collection \cite{kendall2017uncertainties}.
To estimate uncertainty, several deep neural methods have been developed, mainly for classification and regression problems \cite{gawlikowski2021survey}. These include Bayesian methods, which learn a distribution over the weights \cite{blundell2015weight};  ensemble methods, which are based on interpreting Bayesian methods as an ensemble of thin networks with shared weights \cite{lakshminarayanan2017simple}; test-time augmentation methods, which perform multiple forwards passes by randomly altering the input data to perform the prediction and the quantification of the uncertainty \cite{wang2019aleatoric}; and single deterministic methods, such as those based on evidence theory \cite{sensoy2018evidential}. In our work, we have been inspired by the latter due to the good results shown in OOD detection for single-label recognition \cite{sensoy2018evidential} and extend its approach to multi-label settings. 

\subsubsection{Single-Label OOD.}
In recent years, several OOD detection approaches have been proposed \cite{yang2024surveyOOD}, which can be divided into four categories: classification-based, density-based, distance-based and reconstruction-based methods. Some classification-based methods rely directly on the confidence of the classifier, i.e. samples with low likelihoods are considered OOD \cite{devries2018OOD, wang2021iccv}. Some other techniques focus on training strategies, such as logit normalization \cite{wei2022icml} or outlier synthesis \cite{du2022iclr,du2023neurips}. Density-based methods estimate the probability density of the training data and identify OOD samples as the ones that deviate from this distribution \cite{abati2019cvpr,xiao2020neurips,wang2022cvpr}. Compared to classification-based method, density-based methods are more difficult to use since they rely on generative models whose training and optimization are still challenging problems. Distance-based methods leverage the idea that OOD samples tend to lie farther from the in-distribution data in some feature space. These methods measure distances between test samples and in-distribution data points or centroids to determine if a sample is OOD. The existing approaches could be either parametric (based on Mahalanobis distance) \cite{lee2018neurips,ren2021arxiv} or non-parametric (based on nearest-neighbor distance) \cite{lee2018neurips,ren2021arxiv}. Finally, reconstruction-based methods rely on the premise that models trained on in-distribution data will reconstruct in-distribution samples accurately, but fail to do so for OOD samples. Existing approaches apply a reconstruction model to the whole image \cite{denouden2018arxiv}, masking a random part of it \cite{yang2022eccv,li2023cvpr} or to the hidden features \cite{zhoucvpr2022}.

\subsubsection{Multi-Label OOD.}
While OOD detection of single-label data clearly dominates the literature, recently there has been an increasing interest to extend the OOD detection to multi-label data. An energy-based approach has been proposed in \cite{wang2021neurips} which estimates the OOD data by aggregating label-wise energy scores
from multiple labels. The approach is based on an energy model that assigns a scalar ({\it energy score}) to an input sample: data belonging to the training set tend to have lower energy, while OOD data have higher energy. It was demonstrated theoretically and empirically that the energy score is superior to both softmax-based score and
generative-based methods for OOD detection. 
Another approach has been proposed in \cite{wang2022ivc} which exploits the co-occurrence and sparsity properties of labels for distinguishing the OOD data from in-distribution data. Their approach consists of three steps: (i) filtering out low-confidence predictions to simulate label sparsity; (ii) counting label co-occurrences from high-confidence predictions and the label co-occurrence matrix; and (iii) using these counts as weights to calculate the final OOD detection score.

Regarding practical, real-world applications, multi-label OOD data detection has been applied to image classification \cite{hendrycks2022icml}, action recognition \cite{zhao2023open}, and sewer defect classification \cite{zhao2023towards}.