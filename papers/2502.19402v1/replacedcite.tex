\section{Related Works}
\textbf{Evaluating Reasoning in Large Language Models.}
LLMs like GPT-4 ____, Llama 3 ____, and Qwen ____ have demonstrated impressive reasoning capabilities. However, as demonstrated with our esoteric programming language experiment, their reasoning remains fragile, often overfitting to training data patterns. These results are coherent with the findings of ____, which evaluate LLMs' reasoning under counterfactual tasks and modified math problems.  
____ explored the interplay between memorization and reasoning, revealing that fine-tuning enhances both memorization and reasoning generalization .

\textbf{Inference-time Scaling for Reasoning.} 
Recent research on inference-time scaling methods falls into two broad categories. The first category encompasses search-based approaches that do not require additional training. Methods, such as Chain-of-Thought ____, Tree-of-Thought ____, Self-Consistency ____, break down reasoning into sub-problems or explore multiple reasoning paths during inference and select the optimal solution based on the consistency criteria. The second category comprises of RL-based methods, which integrate search with learning mechanisms guided by reward models. Techniques like Reinforcement Learning with Human Feedback ____, ReST ____, and STaR ____ use search to generate diverse outputs with intermediate reasoning steps and provide feedback or reward signals ____ to improve the model’s reasoning policies. These methods adaptively refine reasoning by iteratively training the model on successful outcomes.

% \textbf{Disentangling Knowledge and Reasoning}
% Research by ____ suggests that reasoning capabilities emerge from data structural properties rather than specific language tokens. Pretraining's reliance on next-token prediction encourages memorization over generalization. RL techniques, inspired by AlphaGo ____ and AlphaZero ____, offer a promising alternative.
% \par
\textbf{Memory Architectures.}
Current memory approaches like Retrieval-Augmented Generation (RAG) ____ provide static memory augmentation but lack dynamism.  Neural Turing Machines (NTMs) ____ explored differentiable memory architectures but face optimization challenges due to the backpropagation through time. Recent innovations ____ embed memory as a persistent KV-cache into the model's weights, but because the memory is intricately tied to the models' representations, it becomes difficult to add new knowledge without retraining. ____ proposed a novel framework using trainable ⟨memory⟩ and ⟨reason⟩ tokens to separate knowledge retrieval from reasoning, addressing key challenges in LLMs such as hallucinations and logical inconsistencies. However, this method still ties knowledge with reasoning in a single model.


\textbf{Synthetic Data.}
Most current efforts ____ focus on generating synthetic data directly in natural language using pretrained models. In contrast, there is a less explored avenue that involves using simple, symbolic synthetic datasets for pretraining ____. These approaches typically depend on manually crafted rules (e.g., Set, Identity) to generate data. On top of this lack of scalability, they often lack the complexity required for emergent behavior, limiting their ability to support more complex structures or patterns. The simplicity of these rules can restrict the diversity and depth of the learned priors.

% In other domains, synthetic data derived from Markov chains and noise-based images have consistently outperformed or matched the effectiveness of language-based pretraining ____. These methods serve as priors that narrow down the search space, enabling more efficient exploration .

In other various domains, synthetic data has also shown promise. Studies in vision tasks ____ and RL ____ demonstrate the effectiveness of synthetic data derived from random Markov chains and noise-based images.