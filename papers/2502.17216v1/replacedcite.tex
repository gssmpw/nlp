\section{Related Work}
\label{sec:related-work}

The seminal \textit{Attention is All You Need}____ paper laid the foundations
for LLMs such as GPT-4____, Gemini____,
or Llama____.
%
Surprisingly, LLMs perform decent on reasoning tasks,
especially if prompted via a Chain-of-Thought (CoT) approach____.
This behavior is part of an emergent property of LLMs named \textit{in-context-learning}
or \textit{few-shot-learning}____.
Although CoT achieves astonishing results on reasoning benchmarks,
it is not faithful\footnote{
\textit{Faithful} means that the reasoning chain corresponds to how the model arrives at the answer____.}
____.
Further, it is argued that not only is the reasoning not faithful
but also, that LLMs ``remain limited in their capabilities to performing probabilistic retrieval'' 
and, therefore, that ``pure statistical learning can \textit{not} cope with the combinatorial explosion inherent in many common-sense reasoning tasks''____.
Related results show that LLMs do not
acquire systematic problem solving skills____.
%
%Earlier language-models were constructed by recurrent neural networks____.
%Later work already used the attention mechanisms____,
%however the seminal \textit{Attention Is All You Need}____ paper
%laid the foundations for the Large Language Models (LLMs) as we know of today.
%An overview is given in____,
%
%On a societal side, the public release of GPT-3____ demonstrated LLMs capability to an audience outside of the AI community.
%GPT-4____ improved upon GPT-3 on several metrics, but also has a significant larger size.
%Other popular LLMs include
%Llama____,
%Gemini____, or
%Mistral____.
%
%Truly surprising for LLMs is that they perform decent in reasoning tasks,
%especially if prompted via a Chain-of-Thought (CoT) approach____.
%CoT is an example of an emergent property of LLMs, 
%which is commonly referred to as \textit{in-context-learning}, 
%or \textit{few-shot-learning}____.
%Although CoT achieves astonishing results on reasoning benchmarks,
%it is not faithful
%\footnote{\textit{Faithful} means that the reasoning chain corresponds to how the model arrives at the answer____.}
%____.
%Further it is argued that not only is the reasoning not faithful,
%but further, that LLMs ``remain limited in their capabilities to performing probabilistic retrieval'' 
%and therefore, that ``pure statistical learning can \textit{not} cope with the combinatorial explosion inherent in many common-sense reasoning tasks.''____.
%

The logical reasoning capability of LLMs is measured with datasets such as
the ProntoQA____,  
the ProofWriter____, or
the \textit{FOLIO}____ dataset.
%
%For measuring the logical reasoning capabilities of LLMs multiple datasets have been proposed.
%The \textit{ProntoQA}
%\footnote{Proof and Ontology-Generated Question-Answering}
%is a recent synthetically generated dataset____.
%Alternative datasets include the \textit{ProofWriter}____,
%\textit{AR-LSAT}____,
%and the \textit{LogicalDeduction}____
%dataset.
%____ introduced Syllogism, Wason, and NLI datasets for LLMs.
%
Improving LLM's reasoning capability was approached by different angles.
____ try to improve numerical capabilities
by injecting additional numerical data in the pre-training phase
and further fine-tune the model.
Other approaches focus on fine-tuning____.
However, it was argued that these approaches fail to address the inherent inability of LLMs to reason 
mathematically____.

Neurosymbolic AI____ approaches offer an alternative to the pure sub-symbolic approaches.
Examples include differentiable logic____,
designing neural networks that act as Turing machines____,
or visual question answering with logic-programming and
deep learning____.
%or combining learning with logic-programming____.
For LLM logical reasoning tasks, 
\textit{Logic-LM}____ is a neurosymbolic method that
combines LLMs with symbolic solvers.
%by combining LLMs with symbolic solvers.
The studied solvers include a Prolog____, First-Order-Logic (FOL)____, Constraint-Satisfaction-Problems____, and a Satisfiability-Problem____ solver.
Implementation-wise, Logic-LM uses Python libraries for these solvers.
For Prolog they use \textit{Pyke}____,
for SMT solving (SAT) they use \textit{Z3}____,
for FOL they use \textit{Prover9}____,
and for constraint solving they use the \textit{Python-constraint}____ library.
Logic-LM++____ claims to improve on Logic-LM
by adding an improved self-refinement module that
takes more solver information into account.
____ acknowledge performance differences between solvers
but fail to identify that these stem from the chosen intermediate language.
For knowledge based systems previous research shows that different query languages have an
impact on LLM understanding____.

Differing from these approaches,
we study the impact of the used syntax inherent to the intermediate language of 
neurosymbolic logical reasoners.
%symbolic formalisms for logical reasoning tasks.
%This paper discusses the effect of the used syntax inherent in different symbolic formalisms.
In particular, this paper contrasts the syntax used by Logic-LM, to Pyke's
and Answer Set Programming's (ASP) syntax.
Answer Set Programming (ASP)____ is a declarative problem-solving paradigm.
As our ASP solver we use Clingo____ due to its
readily available Python support.
%