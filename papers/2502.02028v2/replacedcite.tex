\section{Related Work}
\subsection{Language Models in Recipe Generation}
Previous works have explored various language model architectures for recipe generation. ____ explored the performance of BART-based ____ and BRIO-based ____ across different recipe datasets, mostly in English and Vietnamese, which were then evaluated using ROUGE scores. Our work extends these previous ones by systematically comparing models across different sizes and architectures, from smaller models like SmolLM-135M to larger ones like Phi-2. This paper provides a detailed analysis on how model size impacts different aspects of recipe quality. 

\subsection{Recipe Generation Models}
This paper builds on several recent advances in recipe generation and personalization. ____ proposed a personalized recipe generation model using attention mechanisms to focus on recipes previously consumed by the user. Their approach showed promising results in generating recipes that aligned with user preferences. The dataset from this paper has been used in this research with their encoder-decoder model being used as a baseline.

____ implemented a framework using constrained question answering over a large-scale knowledge graph to recommend food recipes considering users' explicit requirements and health factors. This helped recommend healthy alternatives to users, which aligned with the study's goal of providing allergen-free options and gave us the inspiration for a RAG-based system for allergen substitution. 

\subsection{Multi-modal Approaches}
The FIRE system, by ____ and Nutrify AI by ____ both use a multi-modal approach, generating recipes from food images and ingredients. While it differs from this work due to us not using images, these studies also incorporate different types of input in the process of recipe generation.

LLava-Chef, by ____ and  is another multi-modal approach to recipe generation, which was fine-tuned on both the cross-entropy loss and a novel loss function computed using BLEU and ROUGE scores to ensure that the model generated recipes that were closer to the ground truth. This paper adopted these evaluation metrics and the idea of creating custom ones from this paper, as well as what inputs to include for recipe generation. However, this work doesn't use the novel loss function to fine-tune the language models, since penalizing generations for not being closer to the ground truth might hinder the personalization of the generated recipes, which is an important part of allergen substitution.

Other multi-modal recipe generation approaches include ChefFusion by ____ and Inverse Cooking by ____. ChefFusion provides complete multimodality by developing a framework for both recipe generation using images and image generation using recipes. This paper, along with LLava-Chef, uses metrics like SacreBLEU____ and ROUGE, which wasn't preferred due to the limitations of these metrics for creative generation. Inverse Cooking ,  which uses encoder-decoder transformer ____ blocks to generate recipes from images, provided the inspiration to use Ingredient Coverage as an evaluation metric, which is similar to how the paper evaluates the ingredients extracted from the image and the ground truth.
\vspace{-5pt}
\subsection{Evaluation}
Many of these studies, such as LLava-Chef or Retrieval Augmented Recipe Generation by ____, use conventional metrics such as BLEU, ROUGE, and F1-score for ingredient matching to assess recipe quality. This paper distinguishes itself by employing both general and domain-specific metrics such as ingredient coverage, which was used by both ____ and ____ to attain a more profound understanding of the quality implications across many aspects of the generated recipe since traditional metrics focus more on overlap and thus hinder creativity in generation.