\section{Related Works and Background}
\label{sec:related_work}
This section briefly reviews relevant contributions related to PnT and object-throwing, we divide works into two classes: (i) analytical solutions and (ii) learning-based solutions. Moreover, we report background notions on GPR.

\subsection{Analytical solutions}
In ____, the authors present an innovative industrial-grade waste sorting system composed of a robot performing a PnT task. The paper focuses on demonstrating the overall advantages of PnT over PnP. The PnT strategy is completely engineered, and targets are in fixed positions just outside the robot workspace. The system is composed of a Delta Robot, equipped with a Deep Learning powered vision system, and a conveyor belt where waste material is fed to the robot. The Manipulator has to pick each thrash object from the conveyor, recognize the class of the material, and throw the picked object in the bin assigned to the material. The PnT procedure proves to be faster than a classical PnP, allowing the system to process significantly more waste in the same amount of time.
%Other examples of analyitical solutions to object-throwing are ____.
____ introduces a framework for optimizing both the shape and motion of a planar rigid end-effector to meet a specified manipulation task. The framework addresses the optimization and real-world implementation of the shape and motion of a dynamic throwing arm. The task is defined by a set of constraints and a fitness cost, ensuring that the solution aligns with the dynamics of frictional hard contact while fulfilling the task requirements.
In ____ the authors present an offline motion planning for a robotic arm to execute a throwing task, aiming to deliver an object to a specified target. The planning algorithm seeks a feasible throwing trajectory that adheres to kinodynamic constraints.
____ is a ball-thrower robotic system, a visual system estimates the target's position, while offline motion planning implements the throwing motion.

\subsection{Learning-based solutions}
Among learning-based solutions, we can make a further distinction based on how objects are released from the manipulator in mid-motion.
Handling the release of objects during arm motion is a complex task for a robotic system since it requires precise synchronization between the arm and the gripper. In several real-life scenarios, the arm and the gripper are not synchronized in real-time, thus making the object tossing particularly challenging. Even small errors can substantially change the final outcome if the arm velocity is high, such as the one required to throw objects. 
For this reason, previous works on robotic skill learning tackle the problem of object-throwing employing specialized cup-like end effectors or placing the objects over the end-effector unconstrained. In this way, the release is obtained by a deceleration of the arm, that effectively detaches the object from the end-effector. This approach simplifies the engineering behind a real-world setup and allows one to focus on the skill-learning or motion-planning task. We first discuss works that rely on cup-like end-effectors, and finally, we present the solutions using a gripper.

\subsubsection{Object-throwing with cup-like end-effector}

In ____, the authors use MFRL to train a tossing policy to map raw visual observations to a sequence of velocity commands. The agent receives a reward when the bullet hits or lands close to a target object.
In ____ the authors train a simulated 3 Degrees of Freedom (DoF) robot how to throw a ball to a goal position on a hilly landscape, the agent learns a hierarchical policy that decides where the robot is placed in the space between two possibilities, on top of the joint velocity.
In ____, ball throwing is a benchmark for a skill learning framework, which uses human demonstration to build basic actions and MFRL to refine skill learning.
In ____ MFRL is used to tune motor primitives for a robotic arm that is used to throw a ball at a fixed target.
To the best of our knowledge, ____ is the most complete work of this category. The object-throwing task is learned in a latent space of the selected skill representation, allowing generalization to arbitrary target positions. Although results are noteworthy, the real-world experiments only show results for 2 target positions.

Despite these remarkable results, using a cup instead of a gripper poses considerable limitations to the application of PnT in an actual industrial environment, since we can not rely on standard strategies for grasping, which should instead be addressed through ad-hoc hardware or software solutions.


\subsubsection{Object-throwing with gripper grasping}
The task of tossing objects with a robotic manipulator, using a prehensile tool, like a gripper or a suction cup, is a sub-task of PnT. 
Tossingbot ____ is a MFRL algorithm that exploits an end-to-end self-supervised Deep learning architecture to learn the whole PnT task by trial and error. 
This algorithm uses two dynamics movement primitives 
____ to parameterize the grasping and throwing skills. 
Two neural networks are trained on experience, to decide grasping and throwing parameters, namely the orientation of the end-effector in the grasping operation, and the release velocity of the throwing primitive. In this way, the release direction is fixed, and the learning-based procedure optimizes only the release velocity. The training is done by maximizing the pick-and-throw success rate based on outcomes collected on the real system, without relying on a model of the system dynamics. 
On one hand, this choice simplifies the algorithm setup, on the other hand, it could limit data efficiency. This means that the algorithm might require a considerable number of trials to effectively learn the task. For instance, empirical results in ____ demonstrate that even for the task of picking up and throwing a ball, Tossingbot necessitates hundreds or even thousands of trials to reach convergence. Experiments carried out considered a relatively small target variability, namely, targets are a grid positioned in front of the robot. 
In ____, the authors introduce a PnT implementation, based on MFRL. A Deep Q-Network (DQN) ____ approach is used to evaluate objects' picking feasibility from visual data. The  MFRL algorithm Deep Deterministic Policy Gradient (DDPG) ____ is used to derive a throwing policy. Also in this work, the release direction is fixed, and the throwing policy determines only the release velocity. The method is applied both in simulation and on an actual setup. As in ____, results show potential improvements as concerns time-efficiency, while the operational workspace is marginally enlarged, namely, targets are just outside the robot workspace. As in ____, the multiple target areas are a fixed grid.
In ____, the authors present an object-throwing system implemented with a soft robot ____. A MFRL approach based on Proximal Policy Optimization (PPO) ____ learns the actuation pattern of the arm, for the tossing task. Also in this work targets are multiple but in fixed locations. ____ implements an object-throwing system using an industrial manipulator, a MFRL approach based on Decision Transformers (DT) ____ is used to learn joint trajectories as well as gripper opening time, for the task of throwing a ball toward a single fixed target.


\subsection{Background: Gaussian Process Regression}
\label{sec:gp}

% In this section, we briefly review background notions on Gaussian Process Regression (GPR) and the MBRL algorithm MC-PILCO, which are fundamental in this work. GPR is used to derive a data-driven model of object dynamics, while MC-PILCO is the basis of the MBRL strategy we propose. 

% \subsection{Gaussian Processes}
GPR is a machine learning tool used for regression problems, in this work GPR is used to derive a data-driven model of object dynamics.
Let $\D = \{\X, \y\}$ be an input-output dataset, where 
$\X = [{\x}_1^T, \dots, {\x}_n^T]^T$, and $\y=[y_1, \dots y_n]^T$ are, respectively, measurements of the inputs and relative outputs of a system at steps $t = 1 \dots n$.
GPR assumes the following probabilistic model,
\begin{equation}
    \y = f({\X}) + \e = \begin{bmatrix}
        f({\x}_1) \\ \vdots \\ f({\x}_n)
    \end{bmatrix} + \begin{bmatrix}
        {e}_1 \\ \vdots \\ {e}_n
    \end{bmatrix},
\end{equation}
where vector $\e$ accounts for noise, defined a priori as zero mean independent Gaussian noise with variance $\sigma^2$. $f$ is modeled a prior as a zero mean Gaussian Process (GP), with covariance defined by a kernel function $\kappa({\x}_{i},{\x}_{j})$. Namely,  $f({\X}) \sim N(0, K_{{\X} {\X}})$, where the element of $K_{{\X} {\X}}$ at row $i$ and column $j$ is $E[y_{i}, y_{j}] = \kappa({\x}_{i},{\x}_{j})$. 
One typical choice of kernel function is the squared-exponential kernel: 
\begin{equation}\label{eq:se-kernel}
    \kappa({\x}_{i}, {\x}_{j}):= \lambda^2 \e^{-\norm{{\x}_{i}- {\x}_{j}}^2_{\Lambda^{-1}}}
\end{equation}
where $\lambda$ and $\Lambda$ are hyperparameters that can be trained by maximizing the marginal likelihood (ML) of the training samples ____.
$\lambda$ is a scaling factor that determines the a priori standard deviation of the target function from its mean. Instead, $\Lambda$ is a matrix that defines the metric used to compute the weighted distance between samples. In this work, we assume $\Lambda$  is a diagonal matrix, with the diagonal elements named lengthscales.%, i.e. how the distance between points should be weighted for each dimension of the input vector.

As explained in ____, the posterior distribution of $f(x_t)$ given $\mathcal{D}$ is Gaussian distributed, with mean $\E[\hat{f}(x_t)]$ and variance $var[\hat{f}(x_t)]$ expressed by the following closed-form expressions:
\begin{subequations}
    \begin{align}
        &\E[\hat{f}(x_t)] = K_{{\x}_t {\X}} \Gamma_i^{-1} \y    \label{eq:gp_regression_formulas-mean}\\
        &var[\hat{f}(x_t)] = \kappa ({\x}_t, {\x}_t) - K_{{\x}_t {\X}} \Gamma^{-1} K_{{\X} {\x}_t}\label{eq:gp_regression_formulas-var} \\
        &\Gamma = K_{{\X} {\X}} + \sigma^2 I \nonumber
    \end{align}
    \label{eq:gp_regression_formulas}
\end{subequations}
with $ K_{{\x}_t {\X}} = [\kappa(\x_t, \x_1), \dots, \kappa(\x_t, \x_n)]$, and $ K_{{\X} {\x}_t} = K_{{\x}_t {\X}}^T$.
Given the Gaussian distribution, $\E[\hat{f}(x_t)]$ is also the maximum a posteriori estimate of $f(x_t)$. Instead, $var[\hat{f}(x_t)]$ provides a measure of the uncertainty, due to the limited availability of training data or intrinsic stochasticity of the system. 
For the use of GPs in system identification and control we refer the interested reader to
____.