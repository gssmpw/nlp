\section{Introduction}


\begin{figure}[t]
  \centering
  \includegraphics[width=7cm]{head_figure.pdf}
  \vspace{-1em}
  \caption{A conceptual comparison between our proposed ChorusCVR and existing CVR models on the perspective of the discrimination spaces of soft labels.}
  \label{intro}
  \vspace{-2em}
\end{figure}
Recommender systems are crafted to provide users with personalized content (videos, products and ads, \emph{etc.,}) that match their preferences \cite{youtubenet,sim,mmoe,din}. Generally, industrial RecSys typically divided into two major stages. 1) Retrieval stage, which aims to search thousands of related candidates from massive item pool. 2) Ranking stage, which aims to estimate interaction probability, \emph{e.g.,} click-through rate (CTR) and post-click conversion rate (CVR), for each user-item pair for retrieved candidates, and select a set of best items for users. In this paper, we focus on the post-click conversion rate (CVR) estimation task during ranking stage.

\textit{Problem statement.} Typically, a positive CVR sample follows the following data funnel: 
%
\textit{exposure} $\mathcal{D}$$\to$\textit{click} $\mathcal{O}$$\to$\textit{conversion} $\mathcal{R}$, where the \textit{click} space $\mathcal{O}$ is around about $4\sim6\%$ of \textit{exposure} space $\mathcal{D}$ and the \textit{conversion} space $\mathcal{R}$ takes up $2\sim4\%$ of \textit{click} space $\mathcal{O}$.
%
Different with CTR which is learned using exposure space samples, CVR is typically learned using only click space samples because we are unaware the un-clicked samples would be converted or not. 
% 
%
However, during online inference, the CTR and CVR scores are utilized in the same assumed exposure space, which leads to a well-known mismatch sample selected bias (SSB) issue \cite{ssb1,ssb2,ssb3,dcmt}, that CVR learning module is trained in \textit{click} space $\mathcal{O}$ but is used for inference at  \textit{exposure} space $\mathcal{D}$.
%









\textit{Motivation.} To alleviate the SSB problem, previous wisdom introduce several techniques to extend CVR task to \textit{exposure} space.
%
Specifically, ESMM \cite{essm} propose a click-through \& conversion rate (CTCVR) task to merge two CVR and CTR scores as one score to supervised it in \textit{exposure} space, which successfully extend the CVR to entire space to solve space inconsistency between training and inference.
%
Unfortunately, the CTCVR loss made a strong assumption that \textbf{\textbf{un-clicked} training samples are hard negative samples in CTCVR training}. This assumption overlooks some ambiguous negative samples which may be easy for users to buy after he/she clicked, but without chance to be clicked yet \cite{multiipw,dcmt}.
%
To alleviate this false negative sample issue, the recent works are dedicated to find reasonable pseudo soft labels to for \textbf{un-clicked} sample learning.
%
Specifically, the DCMT \cite{dcmt} propose to regularize the CVR objectives by a complementary constraint with a novel counterfactual CVR objective. 
%
For counterfactual CVR learning, DCMT first assumes all un-clicked items as positive samples while all converted items are negative samples, and then apply a $CVR = 1 - counterfactualCVR$ constraints for CVR learning module, as shown in Figure~\ref{intro}(b). 
%
Besides, the NISE \cite{nise} and DDPO \cite{ddpo} first utilize the outputs of an additional CVR tower learned in click space to act as pseudo soft label, and then employ a cross-entropy constraints $CVR\thickapprox extraCVR$ in un-click space, as shown in Figure~\ref{intro}(c).
% 

It has come to our attention that the quality of soft CVR labels is the key to mitigating SSB issues.  So we ask, \textit{what requirements should an ideal soft CVR label satisfies}? Our key insight is, an ideal soft label should at least satisfy two requirements: \textbf{R1. Discriminability}: for a clicked sample, the label can discriminate it would be converted or not; \textbf{R2. Robustness}: for un-converted sample, the label can separate the factually un-converted sample in click space from those ambiguous un-converted sample in un-click space. With this in mind, we  present the discrimination surface of soft labels in existing methods (DCMT, NISE and DDPO) in Figure~\ref{intro}. We find their discrimination surface are fully overlapped with certain part of the surfaces of  ESMM (CTCVR task w/o soft labels), which miss either \textbf{R1} or \textbf{R2}. Thus, few of existing methods can meet all these requirements.

To fill this gap, we present a novel entire-space dual multi-task learning model, namly \textbf{ChorusCVR}, to realize effective CVR learning in un-click space that  fulfills both \textbf{R1} and \textbf{R2} (see Figure~\ref{intro}(d)).  The ChorusCVR consists of two modules, \emph{i.e.,} \textbf{N}egative sample \textbf{D}iscrimination \textbf{M}odule (NDM) and \textbf{S}oft \textbf{A}lignment \textbf{M}odule (SAM). In NDM, we introduce a novel CTunCVR auxiliary task, to provide robust soft CVR labels with the ability to discriminate factual CVR negative samples (clicked but un-converted) and ambiguous CVR negative samples (un-clicked).  In SAM, we utilize generated CTunCVR soft outputs to supervise  CVR learning with several alignment objectives, to realize debiased CVR learning in entire-space. Our contributions can be summarized as follows:
\begin{itemize}[leftmargin=*,align=left]
    \item We introduce a novel CTunCVR auxiliary task to provide soft CVR labels with both discriminability and robustness in entire space.
    \item We propose a novel ChorusCVR model with effective alignment objectives for debiased CVR modelling in entire space.
    \item We conduct extensive experiments on both public and production environment datasets and online A/B testing to verify the efficacy of our method, which show that our ChorusCVR achieves superior performance over all existing state-of-the-art methods.  
\end{itemize}