\section{Methodology}


\begin{figure*}[t]
  \centering
\includegraphics[width=0.70\textwidth]{main_figure_v2.png}
  \vspace{-1em}
  \caption{Systematic overview of our Chorus CVR model.}
  \label{choruscvr}
  \vspace{-1em}
\end{figure*}


\subsection{Preliminary}
In the ranking stage of industrial recommendation system, all \textit{exposure} user-item pairs will be collected and formed as a data-streaming for model training, i.e., $\mathcal{D}$.
Specifically, each user-item sample in $\mathcal{D}$ could represent as $(u, i, \{\mathbf{x}_u, \mathbf{x}_i,$ $\mathbf{x}_{ui}\}, o_{ui}, r_{ui}) \in \mathcal{D}$, where $u$/$i$ denotes the user-item pair, $\mathbf{x}_u\in\mathbb{R}^{d_u}, \mathbf{x}_i\in\mathbb{R}^{d_i}, \mathbf{x}_{ui}\in\mathbb{R}^{d_{ui}}$ are the user-side features (e.g., user ID), item-side features (e.g., item ID), and item-aware cross features (e.g., SIM \cite{sim}).
%
The $o_{ui}\in\{0,1\}$ and $r_{ui}\in\{0,1\}$ are user-item ground-truth interacted labels, where $o_{ui}$ denotes whether user $u$ clicked item $i$ and $r_{ui}$ denotes whether user $u$ converted item $i$. 
%
According to the entire \textbf{\textit{exposure} space} $\mathcal{D}$, we could further obtain several subset spaces:
%
\begin{itemize}[leftmargin=*,align=left]
\item \textbf{\textit{Click} space} $\mathcal{O}\in\mathcal{D}$, if click label $o_{ui} = 1$.
\item \textbf{\textit{un-Click} space} $\mathcal{N}=\mathcal{D} - \mathcal{O}$, if click label $o_{ui} = 0$.
\item \textbf{\textit{Conversion} space} $\mathcal{R}\in\mathcal{O}$: if label $o_{ui}=1$ and $r_{ui}=1$.
\item \textbf{\textit{un-Conversion} space} $\mathcal{M}=\mathcal{O}-\mathcal{R}$: if label $o_{ui}=1$ and $r_{ui}=0$.
\end{itemize}
%
Based on them, a simple ranking model can be formed as:
\begin{equation}
% \small
\begin{split}
&\hat{y}^{ctr}_{ui} = \texttt{MLP}^{ctr}(\mathbf{x}_{ui}),\quad \hat{y}^{cvr}_{ui} = \texttt{MLP}^{cvr}(\mathbf{x}_{ui}),\\
&\mathbf{x}_{ui} = \texttt{Multi-Task-Encoder}(\mathbf{x}_u\oplus \mathbf{x}_i\oplus \mathbf{x}_{ui}),\\
\end{split}
\label{base}
\end{equation}
where the $\oplus$ denotes the concatenate operator, $\mathbf{x}\in\mathbb{R}^d$ is the encoded hidden states, and $\texttt{MLP}(\cdot)$ denotes a stacked neural-network. We use a share-bottom based multi-task paradigm to predict CTR and CVR scores, $\hat{y}^{ctr},\hat{y}^{cvr}$.
%
Next, we directly minimize the cross-entropy binary classification loss to train CTR tower and CVR towers with corresponding space samples:
%
%
%
\begin{equation}
% \small
% \footnotesize
\begin{split}
&\mathcal{L}^{ctr} = - \frac{1}{|\mathcal{D}|}\big(\sum_{(u,i)\in\mathcal{D}}\delta(\hat{y}^{ctr}_{ui}, o_{ui})\big),\\
&\mathcal{L}^{cvr} = - \frac{1}{|\mathcal{O}|}\big(\sum_{(u,i)\in\mathcal{O}}\delta(\hat{y}^{cvr}_{ui}, r_{ui})\big).
\end{split}
\label{crossentropy}
\end{equation}
%
% 
%
In inference, given the hundreds item candidates in a certain user request, we could obtain predicted CTCVR by  $\hat{y}^{ctcvr}_{ui} =\hat{y}^{ctr}_{ui} \cdot \hat{y}^{cvr}_{ui}$ for each item, which is used for final ranking. Then top K highest items will be returned and shown to user. The CVR are learned in click space during training but be predicted in an assumed explore space during inference, which brings up the question of sample selection bias problem.
% 





To alleviate sample selection bias,  ESMM \cite{essm} expand the click-space CVR learning task to exposure-space CTCVR learning task, to directly solve the inconsistency between training and inference:
\begin{equation}
% \small
\begin{split}
\mathcal{L}^{ctcvr} = &- \frac{1}{|\mathcal{D}|}\Big(\sum_{(u,i)\in\mathcal{D}}\delta(\hat{y}^{ctr}_{ui}\cdot\hat{y}^{cvr}_{ui}, o_{ui}\cdot r_{ui})\Big)
\end{split}
\label{ctxcvr}
\end{equation}
which treats all un-clicked samples as negative samples of CTCVR task. However those un-clicked samples that would be converted if clicked, which are falsely negative samples,  still leads to missing not at random (MNAR) problem  \cite{multiipw}. To mitigate this problem, inverse propensity weighting (IPW) \cite{multiipw,escm2} based method inversely weight the CVR loss in click space by propensity score of observing  $(u,i)$ in click space $\mathcal{O}$, to eliminate the influence of click event to CVR estimation in entire space $D$
\begin{equation}
\small
\begin{split}
\mathcal{L}^{cvr}_{IPW} =& - \frac{1}{|\mathcal{O}|}\Big(\sum_{(u,i)\in\mathcal{O}}\frac{\delta(\hat{y}^{cvr}_{ui}, r_{ui})}{\hat{y}^{ctr}_{ui}}\Big),
\end{split}
\label{cvripw}
\end{equation}
% 
%
Our method is based on above ESMM with IPW  framework. Although alleviating SSB and MNAR problem, IPW-based methods still lack reasonable labels for \textit{un-clicked} samples, which we solve by generating discriminative and robust soft labels.






\subsection{ChorusCVR}
In this section, we dive into ChorusCVR and explain how we realize entire-space debiased CVR learning by generating discriminative and robust soft CVR labels (as shown in Figure~\ref{choruscvr}).

\subsubsection{Negative sample Discrimination Module (NDM)}

As mentioned before, the soft labels introduced by previous works are suboptimal for lack either discriminability or robustness. As shown in Figure~\ref{intro} (d), an ideal discrimination surface should separate the factual negative samples (clicked but un-converted) from positive samples (clicked \& converted), and factual negative samples from ambiguous negative samples (un-clicked). With this in mind, we find the ideal discrimination surface implies a new task, CTunCVR prediction. We formulate CTunCVR labels as:
\begin{equation}
y^{ctuncvr} = o_{ui} * (1-r_{ui}) = 
\begin{cases} 
1 & o_{ui}=1~\&~r_{ui} = 0, \\
0 &  o_{ui}=0, \\
0 & o_{ui}=1~\&~r_{ui} = 1,
\end{cases}
\end{equation}
where only \textit{clicked but un-converted} samples are positive samples, both \textit{clicked \& converted} and \textit{un-clicked} samples are negative samples. Instead of directly predicting CTunCVR score in exposure space, we follow a typical two-stage prediction paradigm to obtain CTunCVR to 
reduce cumulative error. We firstly introduce an additional unCVR tower to predict unCVR score $\hat{y}^{uncvr}$, then combine it with $\hat{y}^{ctr}$ to form CTunCVR score:
% 
\begin{equation}
% \small
\begin{split}
\hat{y}^{uncvr}_{ui} = \hat{y}^{ctr}_{ui}\cdot\hat{y}^{cvr}_{ui}\quad \quad
\hat{y}^{ctuncvr}_{ui} =\hat{y}^{ctr}_{ui}\cdot\hat{y}^{uncvr}_{ui}
\end{split}
\label{uncvr}
\end{equation}
Then we can naturally optimize CTunCVR objective in exposure space by cross entropy loss: 
\begin{equation}
% \small
\begin{split}
\mathcal{L}^{ctuncvr} = - \frac{1}{|\mathcal{D}|}\Big(\sum_{(u,i)\in\mathcal{D}}\delta(\hat{y}^{ctuncvr}_{ui}, o_{ui} * (1-r_{ui})\Big).
\end{split}
\label{uncvr}
\end{equation}
% With the help of this formulation, we can narrow down the problem to the accurate estimation of unCVR. 
With the help of $\mathcal{L}^{ctuncvr}$ and an extra \textbf{unCVR prediction result} $\hat{y}^{uncvr}_{ui}$, we can narrow down the aforementioned problem to consider \textbf{R1. Discriminability} and \textbf{R2. Robustness} problem at same time.
%
For the $\hat{y}^{uncvr}_{ui}$ generation, we add an mirror unCVR tower which similar with the Eq.(\ref{base}) and (\ref{crossentropy}):
%
%
%
% 
%
%
% $
% 
\begin{equation}
% \smalluncvr
\begin{split}
\hat{y}^{uncvr}_{ui} &= \texttt{MLP}^{uncvr}(\mathbf{x}_{ui}), \\
\mathcal{L}^{uncvr} = - \frac{1}{|\mathcal{O}|}\Big(&\sum_{(u,i)\in\mathcal{O}}\delta\big(\hat{y}^{uncvr}_{ui}, 1-r_{ui})\big)\Big)
\end{split}
\label{uncvr}
\end{equation}
% 
Next, analogously with the Eq.(\ref{cvripw}), we then adopt the predicted click $\hat{y}^{ctr}_{ui}$ to inversely weight the unCVR error, to $\mathcal{L}^{uncvr}$ as:
% 
\begin{equation}
% \small
\begin{split}
\mathcal{L}^{uncvr}_{IPW} = - \frac{1}
{|\mathcal{O}|}\Big(\sum_{(u,i)\in\mathcal{O}}\frac{\delta(\hat{y}^{uncvr}_{ui}, 1-r_{ui})}{\hat{y}^{ctr}_{ui}}\Big)
\end{split}
\label{uncvr}
\end{equation}
In this way, the \textit{click} space tendency can be alleviated that higher/lower $pCTR$ sample will declined/enhanced for a fair training. So far we obtain debiased unCVR soft labels, which we will utilize to help the CTunCVR training and CVR component supervision.



\subsubsection{Soft Alignment Module (SAM)}
Up to now, we fulfill the initial goal of obtain high-quality soft labels in un-clicked space. In this section we present the solution to utilize the unCVR score as soft labels to supervise CVR learning, which we call \emph{soft alignment mechanism}. We first use $1-unCVR$ manner as soft labels for entropy-based CVR learning. In the same time, we also use $1-CVR$ manner to generate soft labels for unCVR learning, in a mutual supervision fashion to align unCVR predictions to CVR. All these objectives are inversely weighted by predicted CTR in a IPW paradigm (see $\mathcal{L}^{align1}_{IPW}$ and $\mathcal{L}^{align2}_{IPW}$ in Figure.~\ref{choruscvr}). To further alleviate SSB for un-click space, we also propose a \textit{un-click space IPW} approach, to inversely weight the un-click samples with $1-pCTR$ for CTR and unCVR alignment objectives (see $\mathcal{L}^{align3}_{IPW}$ and $\mathcal{L}^{align4}_{IPW}$ in Figure.~\ref{choruscvr}). Overall, all alignment objectives are as follows:
\begin{equation}
% \small
\begin{split}
\mathcal{L}^{align}_{IPW} = &- \frac{1}{|\mathcal{O}|}\big(\frac{\delta(\hat{y}^{cvr}_{ui}, 1-\texttt{sg}(\hat{y}^{uncvr}_{ui}))}{\hat{y}^{ctr}_{ui}}\big)
- \frac{1}{|\mathcal{N}|}\big(\frac{\delta(\hat{y}^{cvr}_{ui}, 1-\texttt{sg}(\hat{y}^{uncvr}_{ui}))}{1-\hat{y}^{ctr}_{ui}}\big)\\
&- \frac{1}{|\mathcal{O}|}\big(\frac{\delta(\hat{y}^{uncvr}_{ui}, 1-\texttt{sg}(\hat{y}^{cvr}_{ui}))}{\hat{y}^{ctr}_{ui}}\big)
- \frac{1}{|\mathcal{N}|}\big(\frac{\delta(\hat{y}^{uncvr}_{ui}, 1-\texttt{sg}(\hat{y}^{cvr}_{ui}))}{1-\hat{y}^{ctr}_{ui}}\big)
\end{split}
\label{soft}
\end{equation}

where the $\texttt{sg}(\cdot)$ means the stop gradient function, the $\hat{y}^{ctr}_{ui}, (1 - \hat{y}^{ctr}_{ui})$ denote the click propensity in the \textit{click} and \textit{un-click} space, respectively.
% 
%
All losses of our ChorusCVR are as follows:
\begin{equation}
% \small
\begin{split}
\mathcal{L} = \mathcal{L}^{ctcvr} + \mathcal{L}^{cvr}_{IPW} + \mathcal{L}^{ctuncvr} + \mathcal{L}^{uncvr}_{IPW} + \mathcal{L}^{align}_{IPW}
\end{split}
\label{soft}
\end{equation}
In this way, our ChorusCVR  make CVR and unCVR supervise each other during training, which results in an equilibrium. 