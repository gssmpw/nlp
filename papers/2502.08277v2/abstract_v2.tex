Post-click conversion rate (CVR) estimation is a vital task in many recommender systems of revenue businesses, \emph{e.g.,} e-commerce and advertising. In a perspective of sample, a typical CVR positive sample usually goes through a funnel of \textit{exposure}$\to$\textit{click}$\to$\textit{conversion}. For lack of post-event labels for un-clicked samples, CVR learning task commonly only utilizes clicked samples, rather than all exposed samples as for click-through rate (CTR) learning task. However, during online inference, CVR and CTR are estimated on the same assumed exposure space, which leads to a inconsistency of sample space between training and inference, \emph{i.e.,} sample selection bias (SSB). To alleviate SSB, previous wisdom proposes to design novel auxiliary tasks to enable the CVR learning on un-click training samples, such as CTCVR and counterfactual CVR, \emph{etc}. Although alleviating SSB to some extent, none of them pay attention to the discrimination between ambiguous negative samples (un-clicked) and factual negative samples (clicked but un-converted) during modelling, which makes CVR model lacks robustness. To full this gap, we propose a novel \textbf{ChorusCVR} model to realize debiased CVR learning in entire-space. We propose a Negative sample Discrimination Module (NDM), which aims to provide robust soft labels with the ability to discriminate factual negative samples (clicked but un-converted) from ambiguous negative samples (un-clicked). Moreover, we propose a  Soft Alignment Module (SAM) to supervise CVR learning with several alignment objectives using generated soft labels. 
Extensive offline experiments and online A/B testing at Kuaishouâ€™s e-commerce live service validates the efficacy of our ChorusCVR. 