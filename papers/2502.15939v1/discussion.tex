\section{DISCUSSION}
The results of our study underscore the importance of cultural sensitivity when designing LLM interventions, particularly for healthcare and stigmatized topics. While LLMs offer promising opportunities to improve access to health information, especially in resource-constrained settings, their effectiveness depends on their ability to respond to complex cultural contexts. In this section, we first consider what constitutes culture in the LLM context, \RD{and how our understanding relates to approaches in prior work.} We then present a framework for the design of culturally sensitive LLM-based chatbots, \RD{also taking inspiration from related chatbot research}, and reflect on the challenges and complexities inherent in this process. 
Through this discussion, we aim to shed light on key considerations for designing AI systems that respect cultural norms while delivering medically accurate and actionable health information. 

%\RD{While existing chatbot applications have focused on integrating certain cultural beliefs within the community, they often remain limited in their ability to adapt to user-specific beliefs and evolving conversational contexts. Our approach refines prior work by leveraging a trained LLM and unpredictable real-world conversations ensuring that interactions remain contextually relevant. Departing from the previous approaches \cite{yadav_feedpal_2019, wang2022artificial}, our framework is designed to be adaptive,  modifying its responses in real time based on user input and cultural nuances, making it a more practical solution for diverse healthcare interactions. }


\subsection{What Constitutes ``Culture'' in LLM Development?}
Our focus on culture was driven by the motivation to address sensitive health topics in a manner that respects the norms of the community. 
While medical accuracy was considered by the Myna team to be the most critical criteria, cultural relevance was seen as being equally important to ensure that the information provided was relevant to the needs of community members and accepted by them despite the taboo nature of the topic.
% When we initially, engaged in. 
However, integrating cultural relevance was a non-trivial task. Our findings illustrate how culture is deeply intertwined with other context dimensions, such as social norms, accessibility, and legal considerations.
Though we presented our findings in neat categories, many of the user queries touched on multiple of these elements.
For example, cultural beliefs regarding the appropriate age for family planning (Table \ref{tab:mar}) can be closely linked to regional laws governing the minimum age for consent and marriage, and societal expectations around gender roles. In such cases, it becomes difficult to isolate multiple elements, as they mutually shape individuals' perceptions and decisions. 

Setting aside these complexities for a moment, let us revisit the definition of culture that we started with. We initially relied on the definition of culture from health communication literature as \textit{``shared values, norms, codes, roles, and assumptions that shape a group's beliefs, attitudes, and behavior through their interactions in and with their environments''} ~\cite{griffith2024cultural}. 
In a recent review of literature on LLMs by, Adilazuarda et al. present a ``taxonomy of culture'' based on proxies that they identified in LLM literature  \cite{adilazuarda2024measuringmodelingculturellms}. In contrast, we take a bottom-up approach to categorizing the role of culture in LLMs, by studying how users asked questions in a specific context.
We offer a definition of a \textit{culturally sensitive} LLM as---\textit{an LLM (or LLM-based service) that provides verified \chiadd{and verifiable} information while considering the user's beliefs, attitudes, and behavior, shaped by \chirm{their cultural backgrounds} \chiadd{the shared values, norms, codes, roles, and assumptions prevalent in their community.}}
% The challenge with integrating culture into LLM-based chatbots, even more so than in the case of other digital technologies, is that they attempt to reach a wide audience but have to respond to the particularities of individual users.
We deliberately consider the impact on the individual user \chiadd {(rather than group messaging which is common in health communications),} because many LLM-based applications support highly personalized one-to-one conversations.

%\RD{Previous work primarily focused on regional and community-level elements, Our framework extends beyond these limitations in a significant way by incorporating societal and individual considerations.}

This leads us to propose a multi-dimensional approach to understanding the role of culture in the design of LLM-based interventions. We categorize context as four layers, each enveloping the other--- societal, regional, community, and individual. 
% Each of these dimensions entails multiple elements of context that operate at that level. 
Culture is most strongly linked to the three high-level layers (society, region, and community), which shape individual beliefs, attitudes, and behaviors (see Figure \ref{fig:contextlayers}).
Each of these layers is further broken down into multiple dimensions; most though not all of them are tied to culture. These dimensions emerged from our inductive coding process.
 % are shapedinfluence what happens at the individual level
We present the detailed framework next.

\begin{figure}[h]
  \centering
\includegraphics[width=0.5\textwidth]{context_layers.png} 
  \caption{\textbf{The four context layers that shape cultural relevance of LLM-generated text}.}
  \label{fig:contextlayers}
  \Description{Figure that shows four context layers that shape the cultural relevance of LLM-generated text starting with the Individual layer from the bottom followed by Community, Regional, and Societal layers.}
\end{figure}

%Structured knowledge bases in chatbots can improve this by providing more relevant and context-aware responses, enabling users to navigate information more effectively. Enhanced interaction capabilities through knowledge organization can also empower users to engage more meaningfully with chatbots.

% This balancing act underscores the complexity of addressing healthcare in diverse cultural environments, where societal, regional, and individual factors are interdependent.


% Medical accuracy, for instance, must be communicated in a way that aligns with cultural beliefs without compromising factual integrity. 
% Medical accuracy.

\begin{table*}[h]
% \fontsize{6}{5}\selectfont
% \footnote
\centering
\small
  \begin{tabular}{>{\raggedright\arraybackslash}p{1.2cm} p{2.6cm} p{4.3cm} p{6cm}}
% \begin{tabular}{l l l l}
\toprule
\textbf{Context Layers} &\textbf{Dimension} & \textbf{Example of Relevance to SRH or LLM Choices} & \textbf{Implications for Design} \\
\toprule
Societal  & Medical Consensus & Medication approved for use by regulatory bodies; consensus on how to prevent spread of HIV & Include in Knowledge Base (KB)\\
& Laws and Regulations & Legal age of consent for sex & Include in KB \\
 %  & &   & \\ 
 \hline

Regional & Spoken Language & Use of Hindi, Marathi, and Urdu widely in Mumbai & Pick LLM model or translation service to support that language \\
  % & & &  \\ 
 & Written Script & Use of transliterated Hindi widely in WhatsApp communications & Gather and study examples of everyday chat communications; consider fine-tuning with this data if translation does not work well or existing LLMs for that language perform poorly\\
% & &  &   \\
% & & &   \\
% & & &  \\
 & Healthcare Access & Lack of affordable clinics in the area & Suggesting accessible actions such as offering teleconsulation or referring to free or local services \\
% & & &  \\
% & & &  \\
  \hline
  
Community & Community Dynamics & Taking a neighbor's health advice on how to reduce pain during periods & Update KB to recognize importance of community,  and encourage consulting a community leader for advice, while prioritizing verified medical information \\
   & Community Beliefs & Lack of belief in vaccinations & Counter misconceptions, counter harmful practices, maintain a neutral tone if it is a benign practice  \\  
  %  % & & & any harmful practices, \\
  % & & &  \\
 & Religion & Belief that sterilization is not allowed in their religion & Update KB to recognize religious and communal beliefs, encourage talking to a religious/community \\
 & Caste \& Tribe & Belief that a woman is impure while menstruating &  leader, and offer alternatives if a recommendation goes against their beliefs \\
     % &  &  &  if they believe that a certain recommendation 
  % &  & eligibility for government schemes & \\  
 & Dialect & Specific manner of speaking or writing & Dictionary to swap out with words used locally \\
& Gender Roles & Limited mobility of women shaping healthcare access & Prompt asks LLM to acknowledge dominant gender roles, but also that they can change. Center  women's agency and offer strategies to negotiate power over one's health and in their relationships\\
 & Diet & Dietary preferences & Update KB with recommendations based on local dietary practices \\
   \hline
   
Individual & Household Dynamics & Discomfort talking about sex with partner & Include suggestions for navigating family dynamics in KB \\
 & Privacy Practices & Woman shares device with her son & Design the LLM prompt to generate text with a tone that is respectful and formal, similar to a medical professional\\
 & Age & Experiencing menopausal symptoms & Ask follow-up questions on age when relevant to a health symptom, and factor age in prompt when brought up by user \\
 & Income \& Occupation & Stigma around accessing free government services & Consider when suggesting actions to take such as offering teleconsulation or referrals \\
 & Marital Status & Taboo on using contraceptives (having sex) before marriage & Update KB to provide information while acknowledging taboos \\
 % &  &   &\\ 
%  & Occupation & Works in a labor-intensive job and cannot rest & \\
% & &   during pregnancy  & \\
 % & Education & Learned reproductive health in 10th grade &\\
 & Digital Literacy & Discomfort with typing resulting in grammatical errors & Do grammar correction, offer voice capabilities \\
 & Health Literacy & Unfamiliar with a medical term & Continually update dictionary and KB with simple language\\
 & Medical History & Having a prior miscarriage; or experiences with heavy and painful periods & Ask follow-up questions on medical history relevant to a health symptom, and include medical history in the prompt when brought up by the user \\
 & (Dis)Abilities & Mobility impacting healthcare access & Offer accessible services like teleconsultation \\ 
\bottomrule
  \end{tabular}
    \vspace{-5pt}
 \caption{\textbf{Framework for Culturally Sensitive Design of LLMs in Healthcare.} The acronym KB refers to the Knowledge Base.}
  \label{tab:framework}
  \Description{Framework designed for culturally Sensitive Design of LLMs in Healthcare is presented with context layers, dimensions for each layer, examples of relevance to SRH, and implications of design. The acronym KB used in the framework refers to the Knowledge Base. }
  \end{table*}


\subsection{Framework for the Design of ``Culturally Sensitive'' LLM Interventions}
% \RD{Yadav et al. and Wang et al.'s work align with Resnicow et al.'s primary dimensions of cultural sensitivity \cite{resnicow1999cultural}. At the surface structure \cite{resnicow1999cultural}, they supported code-mixing and voice input, enhancing accessibility for users. More significantly, their approach considered elements of deep structure \cite{resnicow1999cultural} such as social influences, particularly the role of mothers-in-law in shaping maternal health decisions \cite{yadav_feedpal_2019}, and addressed social stigma surrounding SRH discussions among youth \cite{wang2022artificial}. 
% In comparison to SnehAI and FeedPal, which are not LLM-based, our approach refines their work by leveraging a trained LLM and unpredictable real-world conversations. While we take inspiration from their work, our findings prompted us to emphasize cultural beliefs more explicitly, recognizing the need for a more comprehensive framework that also accounts to user-specific beliefs and evolving conversational contexts.
% }

The use of LLMs for healthcare applications calls for a structured approach to ensure that culture is considered in design.
Based on our analysis, we developed a framework (Table \ref{tab:framework}), which summarizes the key layers influencing interactions in healthcare contexts. This framework identifies societal, regional, community, and individual layers that we propose be considered when designing culturally sensitive LLM interventions. Each of these has further been broken down into dimensions associated with them, such as laws and regulations, dialects, community beliefs, medical histories, and more.
We envision this framework as a starting point to help shape both the design and evaluation of LLM-based healthcare applications.

The framework aims to support the design of applications that are flexible enough to accommodate cultural dimensions across these various layers.
% , ensuring that users receive health advice that is not only medically sound but also culturally appropriate.
For instance, considering the \textit{societal} level, the system should always provide medical information that adheres to local laws (such as the age of consent) and current medical consensus. At the \textit{regional} level, it should adapt to spoken languages and dialects, and written script. \RD{Prior studies in other domains have also emphasized the significance of regional languages and local dialects as cultural indicators \cite{li2024should}. Within healthcare (though not using LLMs), Wang et al. and Yadav et al. have studied code-mixing and the importance of language adaptation in chatbot design \cite{wang2022artificial,yadav_feedpal_2019}.}
Additionally, our framework considers \textit{community} dimensions, such as the influence of religious beliefs or community dynamics on health behaviors. \RD{In one study, Rahman et al. also considered the role of religious beliefs in an adolescent sexual health education chatbot \cite{rahman_adolescentbot_2021}.} \chiadd{Myna's own chatbot design encourages users to consult community leaders or healthcare providers, thus taking into account how users’ social networks influence chatbot interactions and how they verify and act on information presented by a chatbot.} 
At the \textit{individual} level, understanding factors such as household dynamics, literacy, and medical history is crucial for personalized and effective health advice. \RD{Other studies have considered this aspect, such as the role of mothers-in-law in shaping health decisions in the context of a breastfeeding education chatbot \cite{yadav_feedpal_2019}}.
\RD{A study by Jo et al. on a voice-based LLM agent to address social isolation among older adults also illustrated the role of age, social networks, and digital literacies \cite{jo2023understanding}. 
% While not explicitly noted as a cultural element, their findings highlight how older users valued LLM-driven chatbots for emotional support \cite{jo2023understanding}. 
Their findings highlighted how users valued emotional support, but were also disappointed with the lack of individual personalization \cite{jo2023understanding}.} %particularly the chatbot's inability to remember their medical history.}

\chiadd{Our framework highlights that integrating cultural sensitivity may entail one or more of the following: the choice of the LLM or translation service in the first place, the choice between using pre-trained or fine-tuned models, integration of RAG to ensure accuracy in preserving cultural context while reducing hallucinations, updating the knowledge base with locally generated content and in response to new usage data, prompt tuning and including conversational history where relevant (with the prompt explicitly stating the specific voice or tone the LLM response will take, the cultural context to integrate, integration of community support, legal aspects, and more), and including a dictionary which can swap our text with locally-relevant terms. 
In addressing cultural sensitivity, it is also crucial to differentiate between aspects that can be integrated during the development process (including updating the knowledge base) and adopting a comprehensive, process-driven approach overall. While updating the knowledge base is an important step, it represents only one part of a broader, methodology required to achieve cultural sensitivity effectively. Enhancing the knowledge base with new information is insufficient because cultural contexts are deeply rooted in dynamic and subjective elements such as shared values, norms, codes, roles, assumptions, beliefs, attitudes, and behaviors.}

\chiadd{To navigate these complexities, we propose a scalable and generalizable \textit{methodology and development process} that prioritizes adaptability and community engagement (see Figure \ref{fig:methods} in the Methods section). 
We emphasize that cultural sensitivity is a \textit{spectrum}. We can never claim that we have achieved cultural sensitivity, especially given that culture itself can be dynamic, particularly in urban and increasingly online environments. We can only target doing better.
Our approach hence allows for iteratively integrating cultural elements into the development process, ensuring they are not static but evolve as the communities they serve evolve.
% By focusing on scalable processes rather than fixed outcomes, this methodology supports the integration of cultural sensitivity that can be applied across diverse populations.
Our outlined methodology for developing culturally sensitive chatbots consists of the following steps (Figure \ref{fig:methods}): (1) collaborate with community members and/or a local community organization to initially gather insights into their health concerns and identify key values and cultural elements, (2) work alongside the community and local healthcare professionals to co-develop a database of question-answer pairs to use for testing performance of pretrained LLM models and/or fine-tuning (and offer training when appropriate to enable this), (3) conduct iterative testing with local healthcare professionals and community members, and (4) monitor usage and incorporating user feedback into iterative improvements.
This approach underscores that cultural sensitivity is not a one-and-done goal but a continuous effort that evolves with a community's needs. By focusing on the ``how'' rather than just the ``what,'' this methodology hopes to integrate cultural sensitivity in a way that is both flexible and sustainable.}
% The chatbot use of formal language needs careful consideration to ensure appropriateness across different cultural contexts.
% The chatbot generally avoids making assumptions about gender but sometimes gives overly generic responses, especially concerning gender roles. For instance, it responds to questions about family planning without addressing societal gender expectations, which might be seen as a lack of sensitivity to specific cultural contexts.

% The chatbot should account for regional dietary preferences and economic considerations. It provides general dietary advice without considering dietary restrictions or financial constraints, which may not be relevant to all users.
% Responses on legal and medical topics can be inconsistent. The bot sometimes provides specific legal ages but lacks clarity in other instances. Ensuring that legal and medical information is accurate and contextually relevant is also important.
% It is essential for the chatbot to clarify misconceptions respectfully while acknowledging cultural beliefs. Responses should be evidence-based to correct harmful misconceptions without offending users' cultural values.

% We are not doing fine-tuning in this project, there's no question bank that's been provided to the chatbot, the only thing that's been provided is a dictionary, and then the RAG part, making sure that the knowledge base is up to the mark. And then the the prompt has been crafted very carefully and iterated on. And this could be something that comes later where, you know, we could have just fed all of this to like, a fine tuned model, but we tried that, and it didn't work as well. What actually worked better was this dictionary approach, which is constantly being updated, as in when like, more emerging behaviors appear so and we can talk about the implication of that in the discussion.


\subsection{Complexities in Designing for Cultural Sensitivity}
Designing a chatbot to navigate cultural sensitivity presents significant challenges, particularly when even humans struggle to interpret and address sensitive cultural issues. The framework above aims to surface and present mechanisms to address these challenges. 
For example, terms like ``abortion'' versus ``miscarriage'' or ``family planning'' may have different connotations in the local context, leading to confusion or misunderstandings. The term ``abortion'' was used to refer to both miscarriages and abortions in our study context. On one hand, this has reduced the stigma around choosing to have an abortion. 
On the other hand, it has made it difficult to understand user context and provide appropriate advice based on whether someone has had an abortion or a miscarriage. 
Another major challenge lies in the language used by users, who may struggle to articulate their health concerns in a way the chatbot can understand. We noted how terms like ``cyst'' or ``Copper-T'' may be miscommunicated or misunderstood (e.g. leading them to be typed as ``cest,'' or ``cooperate T'' or ``copper tee'' respectively) due to limited familiarity with English and literacy levels. This linguistic complexity highlights the need for continuous updates to the chatbot's dictionary and prompt crafting, allowing it to better interpret emerging language patterns and provide more accurate responses.

Focusing on medical accuracy and cultural relevance at the same time can also lead to conflicts with dominant cultural, religious, or community health practices. We envision such situations being resolved as follows. If the health practice is benign and there is no documented evidence that it is not harmful, then the chatbot does not question the practice. If the practice is harmful, then medically accurate information is presented, without denigrating the practice but presenting evidence. If the health practice does not conflict with medical consensus, then the link to the community practices only helps to reinforce uptake. In all cases, we acknowledge the user's concern and encourage them to talk to their community leader and a doctor who can help them resolve the conflict better.

The notion of medical consensus in itself can be complicated in some contexts. Within India, not only are there competing community knowledges but also multiple complementary and alternative medicine systems. These are supported by the Indian government under the Ministry of AYUSH---Ayurveda, Yoga and Naturopathy, Unani, Siddha, Sowa Rigpa, and Homeopathy---and have their own boards and consensus. Though AYUSH is followed by a large population of Indians, there is limited scientific evidence underpinning these practices, and they can come into conflict with evidence-based medicine. In this paper, by medical consensus, we refer to evidence-based medicine and do not consider AYUSH.
% \chiadd{Chatbots would have a varied, distinct set of users, and the ability of the users to control their interactions and evaluate the beliefs with the bot would not be very consistent. Hence, it is important for the chatbot to consider the possible cultural nuances without depending on the user agency. However, if the bot is targeted and the users are known beforehand, their context and level of comprehension can be fed as input to the bot.}

Given the various complexities, Myna’s decision to rely on a dictionary-based approach and retrieval-augmented generation (RAG) rather than fine-tuning an LLM proved to be more effective in addressing the nuances of cultural sensitivity. Fine-tuning a model can limit its adaptability, as it may not keep pace with the evolving language and behaviors within communities. In contrast, the dictionary was constantly updated with new terms, idioms, and cultural practices as they emerge, ensuring that the chatbot remains relevant and responsive to users' changing needs.
This approach also allows for more control over the chatbot’s responses, ensuring that they align with the cultural and contextual information provided by the knowledge base. Fine-tuning a model could potentially lead to overfitting on outdated or overly rigid cultural norms, while a dictionary-based approach offers greater flexibility and responsiveness. This adaptability is critical for addressing the complexity of healthcare in diverse and dynamic cultural environments.

% s discussed in the methods section, 
\chiadd{Thus far, we have discussed how the chatbot design aims to meet the user's cultural context. However, there is a significant role that user agency plays in shaping how women interpret and make sense of information presented by the chatbot, and act on the information. To integrate their perspectives, Myna prioritized a community-centric methodological approach by ensuring that women from the community played a key role throughout the process, from the pre-development phase to iterative testing and development to evaluation (see Figure \ref{fig:methods}). %Understanding user profiles and contexts can lead to more adaptive AI-driven systems, further promoting user agency \cite{}.
In the evaluation phase, initially, women even had the option to provide open-ended user feedback, and also quantitatively rate the chatbot responses on metrics such as---overall rating, satisfied by answer,  helpful answer, language simplicity, response time, friendliness, and helpfulness. 
% While most metrics were rated on a scale of 1 to 5, satisfied by answer and helpful answer were binary (Yes/No), and user feedback was open-ended.
They consistently rated responses highly, making it challenging to draw meaningful insights. Additionally, some women abstained from rating altogether, and the open-ended feedback option was never utilized. By instead involving the women in focus groups and actively engaging them in generating questions, their agency became increasingly evident. In particular, we noticed a learning effect, where the more time women spent asking questions about SRH, the more complex their queries became over time and their ability to understand medical terms increased.
Though this highlights how individual differences may shape interpretation which can pose a challenge for developers, it also speaks to the women's agency in actively shaping chatbot interactions, during development as well as deployment.}
% This approach highlighted the nature of user agency component, while it can introduce bias through individual perspectives, it empowered the community especially women as active participants in shaping the chatbot’s direction. 

% Ensuring that the chatbot prioritizes user safety while being respectful of cultural sensitivities requires a clear hierarchy of responses that balance medical accuracy with cultural nuance.



% Expecting chatbot to do what humans struggle with in this context. 

% Challenges even in making sense of language used within the community
% E.g. how is abortion vs miscarriage and family planning interpreted in local context? 
% prioritize safety while still being culturally sensitive - establish clear hierarchy

% Users struggle to get the words right to ask the bot and bot sometimes does not understand what user is trying to say. (cyst, copper -t)


% The chatbot provides responses to user queries, which is useful for users seeking health information. However, it sometimes falls short in delivering comprehensive answers, leading to user frustration.
% Users may get frustrated if the bot primarily directs them to consult a doctor without providing additional information. Balancing the recommendation to see a doctor with actionable information is crucial to maintaining user engagement and satisfaction.