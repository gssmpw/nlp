% This must be in the first 5 lines to tell arXiv to use pdfLaTeX, which is strongly recommended.
\pdfoutput=1
% In particular, the hyperref package requires pdfLaTeX in order to break URLs across lines.

\documentclass[11pt]{article}

% Remove the "review" option to generate the final version.
\usepackage{acl}
% \usepackage{acl}

% Standard package includes
\usepackage{times}
\usepackage{latexsym}

% For proper rendering and hyphenation of words containing Latin characters (including in bib files)
\usepackage[T1]{fontenc}
% For Vietnamese characters
% \usepackage[T5]{fontenc}
% See https://www.latex-project.org/help/documentation/encguide.pdf for other character sets

% This assumes your files are encoded as UTF8
\usepackage[utf8]{inputenc}

% This is not strictly necessary, and may be commented out,
% but it will improve the layout of the manuscript,
% and will typically save some space.
\usepackage{microtype}

\usepackage{makecell}
\usepackage{times}
\usepackage{latexsym}
\usepackage{tabularx}
\usepackage{array}
\usepackage{multirow}
\usepackage{siunitx}
\sisetup{round-mode = figures, round-precision = 4}
\usepackage{booktabs}
\usepackage[pdftex]{graphicx}
\usepackage{enumitem}
\usepackage{xspace}
\usepackage{caption}

% more packages
\usepackage{url}            % simple URL typesetting
\usepackage{amsmath,amsthm,amsfonts,amssymb,bm,stmaryrd}       % blackboard math symbols
\usepackage{nicefrac}       % compact symbols for 1/2, etc.
\usepackage{enumitem}
\usepackage[noend]{algpseudocode}
\usepackage{algorithm}
\usepackage{mathtools}
\usepackage{nccmath}
\usepackage{multirow}
\usepackage{bigdelim}
\usepackage{color, colortbl}
%\usepackage{scalerel}
\usepackage{xcolor}		% make links dark blue
\definecolor{darkblue}{rgb}{0, 0, 0.5}
\hypersetup{colorlinks=true, citecolor=darkblue, linkcolor=darkblue, urlcolor=darkblue}
\usepackage{booktabs}
\usepackage{dcolumn}
\newcolumntype{d}{D{.}{.}{-1}}
\newcolumntype{z}{D{(}{\ (}{1.1}}
\usepackage{graphicx}
\usepackage{titlesec}
\usepackage{hyperref}
\usepackage{url}
\usepackage{framed}
\usepackage{tcolorbox}
% \usepackage{subfigure}
\usepackage{subcaption}
\usepackage{graphicx}
\usepackage[normalem]{ulem}
\useunder{\uline}{\ul}{}
\usepackage{fontawesome5}
\usepackage{calc}

\usepackage{cleveref}

\crefformat{section}{\textcolor{blue}{\S#2#1#3}} % see manual of cleveref, section 8.2.1
\crefformat{subsection}{\textcolor{blue}{\S#2#1#3}}
\crefformat{subsubsection}{\textcolor{blue}{\S#2#1#3}}
\crefformat{equation}{\textcolor{orange}{Eq.~(#1)}}

% \usepackage[notes=true, done=false, later=false, ]{dtrt} % for in-line comments. Remove before submission.

% \pagenumbering{gobble}
\input{macros}

% If the title and author information does not fit in the area allocated, uncomment the following
%
%\setlength\titlebox{<dim>}
%
% and set <dim> to something 5cm or larger.

% \title{Rethinking Reference Determinacy in Natural Language Inference}
\title{On Reference \textit{(In-)}Determinacy in Natural Language Inference}


\author{Sihao Chen\textsuperscript{\msftlogo}\thanks{\,~Work done during Sihao's and Chaitanya's internship at Google. Sihao was a Ph.D. student at the University of Pennsylvania at the time.  } \, \textbf{Chaitanya Malaviya}\textsuperscript{\pennlogo} \, \textbf{Alex Fabrikant}\textsuperscript{\gdmlogo} \\ \textbf{Hagai Taitelbaum}\textsuperscript{\googlogo} \, \textbf{Tal Schuster}\textsuperscript{\gdmlogo} \, \textbf{Senaka Buthpitiya}\textsuperscript{\gdmlogo} \, \textbf{Dan Roth}\textsuperscript{\pennlogo} \vspace{0.1in}
\\
\textsuperscript{\pennlogo} University of Pennsylvania \,
\textsuperscript{\gdmlogo} Google DeepMind \\
\textsuperscript{\googlogo} Google Research \, \textsuperscript{\msftlogo} Microsoft \\
}

% \author{
% \textbf{Tong Chen}\textsuperscript{$\clubsuit$}\thanks{$\ \ $Work was done during internship at Tencent AI Lab, Bellevue.} \,
% \textbf{Hongwei Wang}\textsuperscript{$\diamondsuit$} \,
% \textbf{Sihao Chen}\textsuperscript{$\heartsuit$} \,
% \textbf{Wenhao Yu\textsuperscript{$\diamondsuit$}} \\
% \textbf{Kaixin Ma}\textsuperscript{$\diamondsuit$} \,
% \textbf{Xinran Zhao}\textsuperscript{$\spadesuit$} \,
% \textbf{Hongming Zhang}\textsuperscript{$\diamondsuit$} \,
% \textbf{Dong Yu}\textsuperscript{$\diamondsuit$}
% \vspace{5pt} \\ 
% \textsuperscript{$\clubsuit$}University of Washington \,
% \textsuperscript{$\diamondsuit$}Tencent AI Lab \\
% \textsuperscript{$\heartsuit$}University of Pennsylvania \,
% \textsuperscript{$\spadesuit$}Carnegie Mellon University \,
% }


\begin{document}
\maketitle


\begin{abstract}
% Natural Language Inference (NLI) provides a general task format for evaluating the semantic relations between two pieces of text. 
% As NLI tasks, datasets and models are now used extensively in a wide variety of applications, it is important to understand how the definition of NLI could limit or influence its downstream usage.
% Natural Language Inference (NLI) provides a general task format for evaluating the semantic relations between two pieces of text, which can be useful for various applications such as fact verification and text attribution.
% As \textit{natural language inference} (NLI)
% However, existing datasets for NLI and models trained on these datasets make assumptions about the context from which the premise and hypothesis are sampled.
We revisit the \textit{reference determinacy} (RD) assumption in the task of natural language inference (NLI), i.e., the premise and hypothesis are assumed to refer to the same context when human raters annotate a label. 
While RD is a practical assumption for constructing a new NLI dataset, we observe that current NLI models---which are typically trained solely on hypothesis-premise pairs created with the RD assumption---fail in downstream applications such as fact verification, where the input premise and hypothesis may refer to different contexts. To highlight the impact of this phenomenon in real-world use cases, we introduce \datasetname, a diagnostic benchmark for identifying reference ambiguity in NLI examples.  
% . \datasetname emulates the fact verification setting, 
In \datasetname, the premise is retrieved from a knowledge source (i.e. Wikipedia) and does not necessarily refer to the same context as the hypothesis. With \datasetname, we demonstrate that finetuned NLI models and few-shot prompted LLMs both fail to recognize context mismatch, leading to $>80\%$ false contradiction and $>50\%$ entailment predictions. We discover that the existence of reference ambiguity in NLI examples can in part explain the inherent human disagreements in NLI, and provide insight into how the RD assumption impacts NLI dataset creation process.
\\\\
\faGithub \,\,\url{https://github.com/refnli-authors/refnli}
% We discuss the implications of such,   
% can We discuss the connection of this finding to human disagreement on NLI labels. We then compare and discuss a few strategies for NLI model training and LLM inference to enhance their ability to recognize reference determinacy.


% Natural Language Infernece (NLI), or recognizing textual entailment (RTE) 
% This paper discusses the effect of reference determinacy assumption empirical point of view 
% argue that the current way  NLI datasets 

% In existing general-purpose NLI datasets such as SNLI and MNLI, We observe that humans inherently disagree more on 
\end{abstract}


\input{sections/intro}
\input{sections/motivation}
\input{sections/benchmark}
\input{sections/experiments}
\input{sections/discussion}
\input{sections/related}
\input{sections/conclusion}
% \input{sections/limitations}
% \input{sections/acknowledgements}

% Entries for the entire Anthology, followed by custom entries
\bibliography{anthology,custom}

\newpage
\appendix


\input{appendix/rater_guidelines}
\input{appendix/human_disagreements}


\end{document}
