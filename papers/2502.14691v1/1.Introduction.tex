\section{Introduction}

\par
Computer architects use simulators to design new microarchitectures, conduct research, and propose new designs or optimizations to existing ones. In GPGPUs, one of the most popular simulators is Accel-sim \cite{accelsim}, based on GPGPUSim \cite{gpgpusimOriginal}. The Accel-sim framework can simulate modern NVIDIA GPU architectures such as Volta \cite{voltaPaper}, Turing \cite{turingPaper}, Ampere \cite{amperePaper}, Ada \cite{adaPaper}, or Hopper\cite{hopperPaper}.

\par
Previous works have reported that simulating GPU systems can be 44,000x slower in Multi2Sim \cite{multi2sim} and 480,000x slower in GPGPU-Sim \cite{gputejas}. The Accel-sim framework is single-threaded, and simulating some workloads requires an immense amount of time to complete. \autoref{fig:motivation_sim_time} shows the time different applications take to be simulated in Accel-sim when executed in nodes with the specifications of Table 2. We can observe that many benchmarks require several hours to be simulated but some other applications such asxtit{mst}, \textit{sssp}, and \textit{lavaMD} need much more time, close to three days ($>259200s$) for \textit{mst} and \textit{sssp} and more than five days ($>432000s$) for \textit{lavaMD}. This long simulation runs compromise the amount of iterations in the typical research loop (propose a new feature, evaluate it) that can be performed and therefore, it limits the productivity of researchers.

\begin{figure}[ht]
  \centering
  \includegraphics[trim={1.3cm 1.3cm 1.4cm 0.3cm},clip,width=8cm]{charts/time_sim_1Thread.pdf}
  \caption{Time in seconds required to execute each workload with a single thread.}
  \label{fig:motivation_sim_time}
\end{figure}

\par
In this paper, we propose to parallelize the Accel-sim simulator with a simple approach using OpenMP \cite{openmp}. This achieves very important reductions in simulation time. For instance, using \summaryNumCores{} threads, we achieve an \summaryAvgSpeedup{} average speed-up and up to \summaryMaxSpeedup{} in some workloads. Besides, the user can easily configure how many threads each simulated workload will use, which provides several benefits. The main one is improving the efficiency of the hardware platform where simulations run by reducing the time unused cores are allocated by cluster schedulers such as SLURM \cite{slurm}, which assigns cores to jobs when they demand a certain amount of RAM even if they do not perform any computation. Moreover, our proposal does not affect simulation accuracy, a very critical aspect, unlike previous works that parallelize GPGPU-Sim \cite{parallelGPUSim1} \cite{parallelGPUSim2}. As the modifications to execute the simulator in parallel are minimal and can be easily configured to be disabled and executed sequentially, debug tasks are as easy as in the vanilla simulator. In addition, our approach is compatible with other techniques that speed up simulation by using sampling \cite{pcaKernelGpuSampling}, and others that reduce the detail of some components, such as NVAS \cite{nvas}.

\par
By speeding up simulators, researchers can model GPU architectures in more detail, simulate larger workloads and simulate bigger GPUs/multi-GPUs.

\par
The rest of this paper is organized as follows. In \autoref{sec:relatedwork}, we discuss previous works in the area. \hyperref[sec:work]{Section~\ref*{sec:work}} analyses the code of Accel-sim and explains how its parallelization has been implemented. Then, we evaluate the benefits of parallelizing the simulator in \autoref{sec:evaluation}. Finally, we summarize the main conclusions in \autoref{sec:conclusions}.