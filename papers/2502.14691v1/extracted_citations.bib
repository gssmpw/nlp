@INPROCEEDINGS{accelsim,
  author={Khairy, Mahmoud and Shen, Zhesheng and Aamodt, Tor M. and Rogers, Timothy G.},
  booktitle={2020 ACM/IEEE 47th Annual International Symposium on Computer Architecture (ISCA)}, 
  title={{Accel-Sim: An Extensible Simulation Framework for Validated GPU Modeling}}, 
  month = {May},
  year={2020},
  volume={},
  number={},
  pages={473-486},
  doi={10.1109/ISCA45697.2020.00047}}

@misc{amdevergreen,
   author = {AMD},
   title = {AMD Evergreen Family Instruction Set Arch},
   url = {www.amd.com},
   year = {2011},
}

@misc{amdgcn3,
   author = {AMD},
   title = {Graphics Core Next Architecture, Generation 3, Reference Guide},
   url = {www.amd.com},
   year = {2016},
}

@INPROCEEDINGS{barra,
  author={Collange, Caroline and Daumas, Marc and Defour, David and Parello, David},
  booktitle={2010 IEEE International Symposium on Modeling, Analysis and Simulation of Computer and Telecommunication Systems}, 
  title={Barra: A Parallel Functional Simulator for GPGPU}, 
  year={2010},
  volume={},
  number={},
  pages={351-360},
  keywords={Graphics processing unit;Registers;Computational modeling;Computer architecture;Instruction sets;Hardware;Load modeling;GPU;GPGPU;UNISIM;CUDA},
  doi={10.1109/MASCOTS.2010.43}}

@INPROCEEDINGS{gpgpusimOriginal,
  author={Bakhoda, Ali and Yuan, George L. and Fung, Wilson W. L. and Wong, Henry and Aamodt, Tor M.},
  booktitle={2009 IEEE International Symposium on Performance Analysis of Systems and Software}, 
  title={Analyzing CUDA workloads using a detailed GPU simulator}, 
  year={2009},
  volume={},
  number={},
  pages={163-174},
  keywords={Analytical models;Yarn;Graphics;Parallel processing;Microarchitecture;Hardware;Process design;Concurrent computing;Parallel programming;Computational modeling},
  doi={10.1109/ISPASS.2009.4919648}}

@INPROCEEDINGS{gputejas,
  author={Malhotra, Geetika and Goel, Seep and Sarangi, Smruti R.},
  booktitle={2014 21st International Conference on High Performance Computing (HiPC)}, 
  title={GpuTejas: A parallel simulator for GPU architectures}, 
  year={2014},
  volume={},
  number={},
  pages={1-10},
  keywords={Graphics processing units;Instruction sets;Java;Kernel;Timing;Computational modeling;Computer architecture;GPU;Simulator;Timing model;Cycle-level;Parallel Architectural Simulation;Nvidia;Tesla},
  doi={10.1109/HiPC.2014.7116897}}

@INPROCEEDINGS{mgpusim,
  author={Sun, Yifan and Baruah, Trinayan and Mojumder, Saiful A. and Dong, Shi and Gong, Xiang and Treadway, Shane and Bao, Yuhui and Hance, Spencer and McCardwell, Carter and Zhao, Vincent and Barclay, Harrison and Ziabari, Amir Kavyan and Chen, Zhongliang and Ubal, Rafael and Abellán, José L. and Kim, John and Joshi, Ajay and Kaeli, David},
  booktitle={2019 ACM/IEEE 46th Annual International Symposium on Computer Architecture (ISCA)}, 
  title={MGPUSim: Enabling Multi-GPU Performance Modeling and Optimization}, 
  year={2019},
  volume={},
  number={},
  pages={197-209},
  keywords={multi-GPU systems;simulation;memory management},
  doi={}}

@INPROCEEDINGS{multi2sim,
  author={Ubal, Rafael and Jang, Byunghyun and Mistry, Perhaad and Schaa, Dana and Kaeli, David},
  booktitle={2012 21st International Conference on Parallel Architectures and Compilation Techniques (PACT)}, 
  title={Multi2Sim: A simulation framework for CPU-GPU computing}, 
  year={2012},
  volume={},
  number={},
  pages={335-344},
  keywords={Computational modeling;Graphics processing units;Kernel;Computer architecture;VLIW;Benchmark testing;Hardware;GPU;AMD;Evergreen ISA;Multi2Sim},
  doi={}}

@INPROCEEDINGS{nvas,
  author={Villa, Oreste and Lustig, Daniel and Yan, Zi and Bolotin, Evgeny and Fu, Yaosheng and Chatterjee, Niladrish and Jiang, Nan and Nellans, David},
  booktitle={2021 IEEE International Symposium on High-Performance Computer Architecture (HPCA)}, 
  title={Need for Speed: Experiences Building a Trustworthy System-Level GPU Simulator}, 
  year={2021},
  volume={},
  number={},
  pages={868-880},
  keywords={Productivity;Computational modeling;Buildings;Memory management;Graphics processing units;Machine learning;Tools;GPU;Simulation;Performance Modeling;System Simulation},
  doi={10.1109/HPCA51647.2021.00077}}

@ARTICLE{openmp,
  author={Dagum, L. and Menon, R.},
  journal={IEEE Computational Science and Engineering}, 
  title={OpenMP: an industry standard API for shared-memory programming}, 
  year={1998},
  volume={5},
  number={1},
  pages={46-55},
  keywords={Message passing;Scalability;Hardware;Computer architecture;Power system modeling;ANSI standards;Parallel processing;Coherence;Software systems;Parallel programming},
  doi={10.1109/99.660313}}

@INPROCEEDINGS{parallelGPUSim1,
  author={Lee, Sangpil and Ro, Won Woo},
  booktitle={2013 IEEE International Symposium on Performance Analysis of Systems and Software (ISPASS)}, 
  title={Parallel GPU architecture simulation framework exploiting work allocation unit parallelism}, 
  year={2013},
  volume={},
  number={},
  pages={107-117},
  keywords={Graphics processing units;Computational modeling;Instruction sets;Process control;Load modeling;Multiprocessor interconnection},
  doi={10.1109/ISPASS.2013.6557151}}

@ARTICLE{parallelGPUSim2,
  author={Lee, Sangpil and Ro, Won Woo},
  journal={IEEE Transactions on Computers}, 
  title={Parallel GPU Architecture Simulation Framework Exploiting Architectural-Level Parallelism with Timing Error Prediction}, 
  year={2016},
  volume={65},
  number={4},
  pages={1253-1265},
  keywords={Graphics processing units;Computational modeling;Instruction sets;Computer architecture;Load modeling;Predictive models;Synchronization;Parallel, Simulation;GPU architecture;Error prediction;Relaxed synchronization;Parallel;simulation;GPU architecture;error prediction;relaxed synchronization},
  doi={10.1109/TC.2015.2444848}}

@inproceedings{pcaKernelGpuSampling,
author = {Avalos Baddouh, Cesar and Khairy, Mahmoud and Green, Roland N. and Payer, Mathias and Rogers, Timothy G.},
title = {Principal Kernel Analysis: A Tractable Methodology to Simulate Scaled GPU Workloads},
year = {2021},
isbn = {9781450385572},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3466752.3480100},
doi = {10.1145/3466752.3480100},
abstract = {Simulating all threads in a scaled GPU workload results in prohibitive simulation cost. Cycle-level simulation is orders of magnitude slower than native silicon, the only solution is to reduce the amount of work simulated while accurately representing the program. Existing solutions to simulate GPU programs either scale the input size, simulate the first several billion instructions, or simulate a portion of both the GPU and the workload. These solutions lack validation against scaled systems, produce unrealistic contention conditions and frequently miss critical code sections. Existing CPU sampling mechanisms, like SimPoint, reduce per-thread workload, and are ill-suited to GPU programs where reducing the number of threads is critical. Sampling solutions on GPUs space lack silicon validation, require per-workload parameter tuning, and do not scale. A tractable solution, validated on contemporary scaled workloads, is needed to provide credible simulation results. By studying scaled workloads with centuries-long simulation times, we uncover practical and algorithmic limitations of existing solutions and propose Principal Kernel Analysis: a hierarchical program sampling methodology that concisely represents GPU programs by selecting representative kernel portions using a scalable profiling methodology, tractable clustering algorithm and detection of intra-kernel IPC stability. We validate Principal Kernel Analysis across 147 workloads and three GPU generations using the Accel-Sim simulator, demonstrating a better performance/error tradeoff than prior work and that century-long MLPerf simulations are reduced to hours with an average cycle error of 27\% versus silicon.},
booktitle = {MICRO-54: 54th Annual IEEE/ACM International Symposium on Microarchitecture},
pages = {724–737},
numpages = {14},
keywords = {Workload sampling, Simulation methodology, GPU},
location = {Virtual Event, Greece},
series = {MICRO '21}
}

@ARTICLE{teslaHotchips,
  author={Lindholm, Erik and Nickolls, John and Oberman, Stuart and Montrym, John},
  journal={IEEE Micro}, 
  title={{NVIDIA Tesla: A Unified Graphics and Computing Architecture}}, 
  year={2008},
  volume={28},
  number={2},
  pages={39-55},
  keywords={Graphics;Computer architecture;Parallel processing;Pipelines;Concurrent computing;Load management;Multicore processing;Parallel programming;Portable computers;Workstations;Hot Chips 19;GPU;parallel processor;SIMT;SIMD;unified graphics and parallel computing architecture;graphics processing unit;cooperative thread array;Tesla},
  doi={10.1109/MM.2008.31}
}

@techreport{voltaPaper,
author = {NVIDIA},
file = {:home/rodhuega/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Unknown - 2017 - NVIDIA TESLA V100 GPU ARCHITECTURE THE WORLD'S MOST ADVANCED DATA CENTER GPU.pdf:pdf},
institution = {NVIDIA},
title = {{NVIDIA Tesla V100 GPU architecture the world's most advanced data center GPU}},
year = {2017}
}

