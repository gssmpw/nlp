\section{Measuring Concept Understanding via Summative Assessment}
\label{sec:towards}







It is intrinsically challenging to measure the extent to which LLMs {understand} a sentence or concept. Indeed, ~\citet{bender2020climbing} provide a definition of "understanding" from a linguistic perspective, but this definition depends on another abstract and unmeasurable term, ``\emph{meaning}''. 
Therefore, even with this definition, accurately measuring "understanding" remains elusive.

We approach the measurement of whether LLMs understand a concept from an educational and cognitive perspective, using \textbf{summative assessment}~\cite{black1998assessment,black1998inside,harlen1997assessment}.
Summative assessment is widely used by educators as an appealing strategy to evaluate students' understanding and knowledge acquisition in educational and cognitive psychology.
For example, when middle school physics teachers want to know whether a student truly understands the concept ``\emph{Gravity}'', they would design a series of questions specifically related to the concept of gravity to assess comprehension, \emph{e.g.}, the properties like inverse square law and examples like orbital motions. If a student struggles to answer many of these questions, the teacher may conclude that the student does not understand the concept well or has a poor grasp of it.

We extend the idea of summative assessment to evaluating the concept understanding of machines. Formally, assume $\mathcal{S}$ denotes an intelligent system and $\mathcal{C}$ is a specific concept.
To evaluate the extent how $\mathcal{S}$ understands the concept $\mathcal{C}$, our summative assessment includes the following two steps:
\begin{itemize}[noitemsep,nolistsep,leftmargin=*]
    \item \emph{Task design towards $\mathcal{C}$}: design several concept understanding tasks, each of which consists of several questions manually created towards understanding the concept $\mathcal{C}$.
    \item \emph{Evaluating $\mathcal{S}$}: 
    ask $\mathcal{S}$ to answer the questions from the tasks and calculate its accuracy. 
\end{itemize}







\paragraph{Requirements for Validity}
The success (validity) of the proposed evaluation approach highly depends on the task design~\cite{black1998assessment,black1998inside}. For example, if the questions are too easy, even a weak system could answer them correctly. This leads to an overestimation of the system's understanding capabilities, making the assessment ineffective. 
To ensure good validity, we adhere to the principles outlined in summative assessment~\cite{black1998assessment,black1998inside} for task design:
\begin{itemize}[noitemsep,nolistsep,leftmargin=*]
    \item \emph{Alignment with evaluating objectives}: the questions should be related to the targeted concept, and should measure the specific knowledge about the targeted concept. 
    \item \emph{Different difficulty levels}: the questions should be with different difficulty levels from easy to difficult level,  to ensure that the evaluation results have distinctiveness for different systems.
    \item \emph{Variety}: the questions should reflect various understanding aspects of the targeted concept; addressing both its denotation and connotation.
    \item \emph{Simplicity}: while not mandatory, a simpler benchmark for humans can more effectively highlight the issue faced by current models, i.e., the stochastic parrot effect in LLMs.
\end{itemize}



