\section{Related Work}
\paragraph{Stochastic Parrots on LLMs}
The pioneer study by \cite{bender2020climbing} questioned the understanding ability of large models; and \citet{bender2021dangers} first introduced the terminology of stochastic parrot.
The concept of stochastic parrot has received great attention, leading to a surge of studies on this topic. 
According to Google Scholar, the term ``stochastic parrot'' appears in the titles of dozens of papers from diverse research fields~\cite{borji2023stochastic,li2023dark,duan2024flocks,henrique2023stochastic}. 
However, although the concept of stochastic parrots in LLMs is widely accepted and recognized, to the best of our knowledge, there is a lack of quantitative experiments to precisely verify this viewpoint. This gap directly motivates our work.




\paragraph{Abstract Reasoning Challenge}

Abstract reasoning challenge (ARC) aims to examine the inductive reasoning ability in a few-shot scenario~\cite{chollet2019measure} and it has been used as a remarkable testbed to measure the intelligence of LLMs.
Recently, many research efforts have been made on improving the performance of LLMs on ARC benchmark~\cite{tan2023large,wang2023hypothesis,xu2023llms,mirchandani2023large,wang2024speak,huang2024anpl}. 
We draw inspiration from ARC by utilizing input-output grids as abstract representations in our task design. However, our task is significantly different from the ARC-style work --- our high-level understanding task focuses on comprehending the transformation rules from inputs to outputs and relating them to physical concepts, and is designed to assess the stochastic parrot phenomenon.


\paragraph{Challenging Tasks towards LLMs' Understanding}
Extensive recent efforts have been made on designing tasks that challenge the understanding abilities of LLMs~\cite{chakrabarty-etal-2022-flute,tong2024metaphor,shapira-etal-2023-well,hessel-etal-2023-androids,donadel2024can,li2024previously}. 
For example, %
~\citet{hessel-etal-2023-androids} proposed a humor understanding task, revealing a large performance gap between LLMs and humans.
As a by-product, our \datasetname challenges the understanding capabilities of LLMs, relating it to the above studies. 
However, we make primary contribution to provide an quantitative experiment to verify stochastic parrots in LLMs via controllably paired low-level and high-level tasks.