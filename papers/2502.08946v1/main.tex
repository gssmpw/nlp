\pdfoutput=1

\documentclass[11pt]{article}

\usepackage[preprint]{acl}

\usepackage{times}
\usepackage{latexsym}

\usepackage[T1]{fontenc}

\usepackage[utf8]{inputenc}

\usepackage{microtype}

\usepackage{inconsolata}

\usepackage{graphicx}

\usepackage[T1]{fontenc}
\usepackage{times}
\usepackage{latexsym}
\usepackage{hyperref}
\usepackage{inconsolata}
\usepackage{url}
\usepackage{amsmath}
\usepackage{amsthm}
\usepackage{amsfonts}
\theoremstyle{definition}
\newtheorem{definition}{Definition}[section]
\usepackage{graphicx}
\usepackage{subcaption}
\usepackage{booktabs}
\usepackage{multirow}
\usepackage{makecell}
\usepackage{wrapfig}
\usepackage{enumitem}
\usepackage{comment}
\usepackage{blindtext}
\usepackage{xcolor}
\usepackage{svg}
\usepackage{xspace}
\usepackage{adjustbox}

\newcommand{\tulu}{\textsc{T\"ulu}\xspace}

\renewcommand{\cite}{\citep}

\input{codestyle}


\newcommand\modelname{{\usefont{T1}{Discognate}{m}{n}{DTM}}\xspace}


\usepackage[T1]{fontenc}


\usepackage[utf8]{inputenc}

\usepackage{microtype}

\usepackage{inconsolata}

\usepackage[]{todonotes}
\newcommand{\fixme}[2][]{{\todo[color=yellow,size=\scriptsize,fancyline,caption={},#1]{#2}}}
\newcommand{\note}[4][]{{\todo[author=#2,color=#3,size=\scriptsize,fancyline,caption={},#1]{#4}}}
\newcommand{\mo}[2][]{{\note[#1]{MO}{blue!20}{#2}}}
\newcommand{\Mo}[2][]{\mo[inline,#1]{#2}\noindent}
\newcommand{\lemao}[1]{\textcolor{red}{\textbf{#1 --Lemao}}}
\newcommand{\shunchi}[1]{\textcolor{orange}{\textbf{#1 --Shunchi}}}
\newcommand{\rebuttal}[1]{\textcolor{red}{#1}}

\usepackage{amsthm}
\newtheorem{question}{Research Question}
\newcounter{research}

\newcounter{rqsection}

\renewcommand{\therqsection}{RQ \arabic{rqsection}}

\newcommand{\rqsection}[1]{
  \refstepcounter{rqsection} %
  \medskip
  \noindent\textbf{\therqsection: \emph{#1}} %
}


\newcommand{\datasetname}{\textsc{PhysiCo }}
\newcommand{\datasetnamens}{\textsc{PhysiCo}}

\newcommand{\coredataset}{\datasetnamens-\textsc{Core }}
\newcommand{\harddataset}{\datasetnamens-\textsc{Associative }}
\newcommand{\coredatasetns}{\datasetnamens-\textsc{Core}}
\newcommand{\harddatasetns}{\datasetnamens-\textsc{Associative}}


\title{\emph{The Stochastic Parrot on LLM's Shoulder:}\\ A Summative Assessment of Physical Concept Understanding}



\newcommand{\authorsep}{\quad}
\newcommand{\footnotemarksep}{\enspace}

\author{%
Mo Yu$^1$\thanks{Equal contribution.}\authorsep
Lemao Liu$^1$\footnotemark[1]\authorsep
Junjie Wu$^2$\footnotemark[1]\authorsep
Tsz Ting Chung$^2$\footnotemark[1]\authorsep
Shunchi Zhang$^3$\footnotemark[1]\authorsep
\\
\bfseries
Jiangnan Li$^1$\authorsep
Dit-Yan Yeung$^2$\authorsep
Jie Zhou$^1$\authorsep
\\
\textsuperscript{1}WeChat AI, Tencent\authorsep
\textsuperscript{2}HKUST\authorsep
\textsuperscript{3}JHU\\
\texttt{moyumyu@global.tencent.com}\authorsep
\texttt{redmondliu@tencent.com}\\
\texttt{\{junjie.wu,ttchungac\}@connect.ust.hk}\authorsep
\texttt{szhan256@cs.jhu.edu}\\
{\hypersetup{urlcolor=magenta} \url{https://physico-benchmark.github.io}}
}


\newcommand{\fix}{\marginpar{FIX}}
\newcommand{\new}{\marginpar{NEW}}

\begin{document}


\maketitle

\begin{abstract}
In a systematic way, we investigate a widely asked question: \emph{Do LLMs really understand what they say?}, which relates to the more familiar term \emph{Stochastic Parrot}.
To this end, we propose a summative assessment over a carefully designed physical concept understanding task, \datasetnamens.
Our task alleviates the memorization issue via the usage of grid-format inputs that abstractly describe physical phenomena.
The grids represents varying levels of understanding, from the core phenomenon, application examples to analogies to other abstract patterns in the grid world.
A comprehensive study on our task demonstrates: (1) state-of-the-art LLMs, including GPT-4o, o1 and Gemini 2.0 flash thinking, lag behind humans by $\sim$40\%; (2) the stochastic parrot phenomenon is present in LLMs, as they fail on our grid task but can describe and recognize the same concepts well in natural language;
(3) our task challenges the LLMs due to intrinsic difficulties rather than the unfamiliar grid format, as in-context learning and fine-tuning on same formatted data added little to their performance.
\end{abstract}

\input{1-introduction}
\input{2-framework}
\input{3-dataset}
\input{4-validation}
\input{5-experiment}
\input{6-related}
\input{7-conclusion}

\section*{Acknowledgment}
We thank the anonymous reviewers for their constructive feedback.
We also express our gratitude to Mr. Fran√ßois Chollet for developing the ARC benchmark and the annotation tool for abstract grid tasks\footnote{\url{https://arc-editor.lab42.global/?next=\%2Feditor}}. His introduction of this tool to us was particularly instrumental in the creation of \datasetnamens. This work has also been made possible by a Research Impact Fund project (RIF R6003-21) and a General Research Fund project (GRF 16203224) funded by the Research Grants Council (RGC) of the Hong Kong Government.




\bibliography{custom}


\appendix
\clearpage

\section{Details of the Included Concepts in our \datasetnamens}
\label{app:dataset_details}

\paragraph{Concepts in \coredatasetns}
The concepts in \coredatasetns\ are basic physical concepts that we manually design problems for. The development set covers 27 concepts and the test set covers 25 concepts as follows:

\begin{table}[h!]
    \small
    \centering
    \begin{adjustbox}{width=\linewidth}
    \begin{tabular}{l c||lc}
    \toprule
    reference frame&12&gravity&10\\
    reflection&10&refraction&10\\
    light imaging&10&communicating vessels&10\\
    cut&10&laser&10\\
    surface tension&10&move&10\\
    \midrule
    buoyancy&10&acceleration&10\\
    inertia&10&electricity&10\\
    repulsive force&8&wave&8\\
    lever&6&optical filters&6\\
    compression&4&diffuse reflection of light&4\\
    \midrule
    wave interference&4&diffusion&4\\
    vortex&4&expansion&4\\
    nuclear fission&2&nuclear fusion&2\\
    diffraction of waves&2\\
    \bottomrule
    \end{tabular}
    \end{adjustbox}
    \caption{Concepts and their corresponding number of instances in \coredatasetns-Dev.}
    \label{tab:concept_stats_core}
\end{table}

\begin{table}[h!]
    \small
    \centering
    \begin{adjustbox}{width=\linewidth}
    \begin{tabular}{l c||lc}
    \toprule
    atmospheric pressure & 12 & energe conservation & 10 \\
    elastic force & 10 & friction & 9 \\
    photoelectric effect & 8 & heat conduction & 8 \\
    doppler effect & 8 & electromagnetic wave & 8 \\
    melting & 8 & vaporization & 8 \\
    \midrule
    fluid pressure & 8 & thermal expansion and contraction & 8 \\
    Brownian motion & 8 & splashing & 8 \\
    oscillation & 8 & relativity & 8 \\
    lighting & 8 & lifting & 8 \\
    force composition & 8 & pulley & 8 \\
    \midrule
    inclined plane & 8 & Bernoulli effect & 7 \\
    fictitious force & 6 & siphon & 6 \\
    resonance & 4 & ~ & ~ \\
    \bottomrule
    \end{tabular}
    \end{adjustbox}
    \caption{Concepts and their corresponding number of instances in \coredatasetns-Test.}
    \label{tab:concept_stats_core_test}
\end{table}

\paragraph{Concepts in \harddatasetns}
The following table summarized all the concepts from \harddatasetns:

\begin{table}[h!]
    \small
    \centering
    \begin{adjustbox}{width=\linewidth}
    \begin{tabular}{l c||lc}
    \toprule
    mirror                    & 30 & laser                     & 20 \\
    zoom in                   & 15 & magnet                    & 14 \\
    wave                      & 13 & explosion                 & 11 \\
    compression               & 10 & rotation                  & 10 \\
    gravity                   &  9 & expansion                 &  9 \\
    \midrule
    move                      &  8 & change of reference frame &  8 \\
    water ripples             &  7 & long exposure             &  7 \\
    reflection                &  5 & wetting                   &  5 \\
    diffusion                 &  4 & zoom out                  &  3 \\
    projection                &  2 & polarization of light     &  1 \\
    \midrule
    vortex                    &  1 & chemical bond             &  1 \\
    nuclear fission           &  1 & squeeze                   &  1 \\
    nuclear fusion            &  1 & lumination                &  1 \\
    wave interference         &  1 & optical filter            &  1 \\
    vacuum                    &  1 &  \\
    \bottomrule
    \end{tabular}
    \end{adjustbox}
    \caption{Concepts and their corresponding number of instances in \harddatasetns.}
    \label{tab:concept_stats_all}
\end{table}


\section{Details of Analysis Methods in \ref{rq:textual_input}}
\label{app:rq1_details}
\subsection{Masking of Textual Descriptions}
This experiment follows the setting in the ``Physical Concept Selection Subtask'' in section \ref{sec: low-level}. The definitions of the corresponding phenomena were extracted from Wikipedia as well as generated by GPT-3.5 and GPT-4. To maintain consistency, the terms representing concepts were masked as {\small \texttt{[PHENOMENON]}} while relevant terms are masked as {\small \texttt{[MASK]}}. For instance, ``interference'' which corresponds to the phenomenon ``wave interference'' was masked as {\small \texttt{[PHENOMENON]}}. In contrast, ``Newton's first law of motion'' which corresponds to the phenomenon ``inertia'' was masked as {\small \texttt{[MASK]}}.

An example of the masked description can be found in Figure~\ref{fig:masked_description_example}.

\subsection{Prompts Used for Description Generation and Classification}
Figure~\ref{fig:nl_gen_prompt_template} and \ref{fig:nl_guess_prompt_template} include the prompts used for generation and classification respectively.


\begin{figure}[h]
    \centering
    \lstinputlisting[language=prompt]{prompt/textual_generation.txt}
    \caption{The prompt template used for generating descriptions of physical concepts (denoted as the variable \textcolor{magenta}{\small \textbf{\texttt{CONCEPT}}}) in \ref{rq:textual_input}.}
    \label{fig:nl_gen_prompt_template}
\end{figure}

\begin{figure}[h]
    \centering
    \lstinputlisting[language=prompt]{prompt/textual_guessing.txt}
    \caption{The prompt template used for guessing the referred physical concept from four candidates (denoted as the variable \textcolor{magenta}{\small \textbf{\texttt{CANDIDATE ANSWERS}}}) from the natural language descriptions (denoted as the variable \textcolor{magenta}{\small \textbf{\texttt{MASKED DESCRIPTION}}}) in \ref{rq:textual_input}.}
    \label{fig:nl_guess_prompt_template}
\end{figure}

\begin{figure*}[h]
    \centering
    \lstinputlisting[language=prompt]{prompt/masked_description_example.txt}
    \caption{An example of our masked description for the concept \texttt{inertia}.}
    \label{fig:masked_description_example}
\end{figure*}

\subsection{Additional Results on the Self-Play Game}
\label{app:self_play}
Automatic evaluation of a text generation task is in general difficult.
Especially, in our scenario each concept have many different ground-truth examples in its description, thus existing automatic metrics such as BLEU~\cite{papineni2002bleu} and METEOR~\cite{banerjee2005meteor} are not capable of accurately measuring the quality. 
Therefore, we propose an alternative automatic metric via a self-play game for this subtask: 

For each generated description of a concept, we mask the synonyms of the concept in it as in the previous selection subtask, and ask the same LLM to identify the concept being described from four options. 
This metric evaluates the quality of LLMs' generated concept descriptions in an objective manner. 

\begin{table}[t!]
    \small
    \centering
    \vspace{-0.1in}
    \begin{tabular}{ccccc}
    \toprule
      & \bf Mistral & \bf Llama-3 & \bf GPT-3.5 & \bf GPT-4 \\
     \midrule
    Human &92.6& 100 &100 & 100\\
    \midrule
    SP & 89.2$_{\pm\text{1.6}}$ & 91.9$_{\pm\text{0.6}}$ &96.0$_{\pm\text{0.4}}$ & 99.8$_{\pm\text{0.2}}$\\    
    \bottomrule
    \end{tabular}
    \vspace{-0.1in}
    \caption{Evaluations on the concept generation subtask, with metrics of Self-Play success and Human evaluation.}
    \vspace{-0.1in}
    \label{tab:generation_extended}
\end{table}

\paragraph{Results}
The results of automatic evaluation via self-play are shown in Table~\ref{tab:generation_extended} together with the human evaluation results. 
In the self-play test, all LLMs can accurately recognize the physical concepts from the descriptions they wrote by themselves.
Combined with the conclusion from human evaluation, 
it shows the LLMs can generate correct and sufficient information.


\section{Details of the Methods Used in \ref{rq:matrix_input} and \ref{rq:visual_input}}

We use the prompt template in Figure~\ref{fig:matrix_prompt_template} for experiments on text-only LLMs (\ref{rq:matrix_input}); and the template in Figure~\ref{fig:visual_prompt_template} for multi-modal LLMs (\ref{rq:visual_input}).

\begin{figure*}[t]
    \centering
    \lstinputlisting[language=prompt]{prompt/matrix_template.txt}
    \caption{The prompt template used in \ref{rq:matrix_input}. The pair of an \textcolor{magenta}{\small \textbf{\texttt{INPUT GRID}}} and an \textcolor{magenta}{\small \textbf{\texttt{OUTPUT GRID}}} consists of one example of a physical phenomenon in matrix format.}
    \label{fig:matrix_prompt_template}
\end{figure*}

\begin{figure*}[t]
    \centering
    \lstinputlisting[language=prompt]{prompt/visual_template.txt}
    \caption{The prompt template used in \ref{rq:visual_input}. \textcolor{magenta}{\small \textbf{\texttt{UPLOADED IMAGE}}} is an image consists of three or more examples like in Figure~\ref{fig:level_examples}.}
    \label{fig:visual_prompt_template}
\end{figure*}


\section{Performance Decomposition in \ref{rq:matrix_input} and \ref{rq:visual_input}}
\label{app:perf_decomp}
Table~\ref{tab:perf_decomp_to_concept} provides a performance decomposition of text-based GPT-4, text-based o1-preview and multi-modal GPT-4o on our \coredatasetns-Test set. Because the rate limit of o1-preview, we conduct experiment on a subset of 50 instances. The result shows that o1-preview does not show superior results compared to the other two LLMs.

\begin{table*}[h!]
    \small
    \centering
    \begin{adjustbox}{width=\linewidth}
    \begin{tabular}{l ccccccccccc}
    \toprule
    \bf Concept       & GPT-4 (t)               & GPT-4o (v)              & o1 (t)& o1 (v)& Gemini2 FTE (v)        & DeepSeek R1 (t) & o3 (t)                   \\
    \midrule
gravity               & 60.0$_{\pm\text{8.2}}$  & 33.3$_{\pm\text{4.7}}$  & 50.0  &  80.0 & 63.3$_{\pm\text{0.3}}$  &  60.0          &  55.0$_{\pm\text{5.0}}$ \\
compression           & 50.0$_{\pm\text{20.4}}$ & 50.0$_{\pm\text{0.0}}$  & 0.0   &  50.0 & 50.0$_{\pm\text{0.0}}$  &   0.0          &   0.0$_{\pm\text{0.0}}$ \\
diffuse reflection of light
                      & 50.0$_{\pm\text{0.0}}$  & 33.3$_{\pm\text{11.8}}$ & 25.0  &  25.0 & 25.0$_{\pm\text{0.0}}$  &  25.0          &  25.0$_{\pm\text{0.0}}$ \\
lever                 & 0.0$_{\pm\text{0.0}}$   & 50.0$_{\pm\text{0.0}}$  & 16.7  &  66.7 & 77.8$_{\pm\text{0.9}}$  &  16.7          &   8.3$_{\pm\text{8.3}}$ \\
wave interference     & 83.3$_{\pm\text{11.8}}$ & 100.0$_{\pm\text{0.0}}$ & 100.0 & 100.0 & 91.7$_{\pm\text{2.1}}$  &  75.0          &  75.0$_{\pm\text{0.0}}$ \\
spectrum of light and optical filters
                      & 66.7$_{\pm\text{0.0}}$  & 88.9$_{\pm\text{15.7}}$ & 66.7  & 100.0 & 94.4$_{\pm\text{0.9}}$  & 100.0          & 100.0$_{\pm\text{0.0}}$ \\
surface tension       & 43.3$_{\pm\text{17.0}}$ & 50.0$_{\pm\text{8.2}}$  & 30.0  &  90.0 & 40.0$_{\pm\text{1.0}}$  &  40.0          &  40.0$_{\pm\text{0.0}}$ \\
nuclear fission       & 16.7$_{\pm\text{23.6}}$ & 100.0$_{\pm\text{0.0}}$ & 100.0 &  50.0 & 0.0$_{\pm\text{0.0}}$   &  50.0          &  50.0$_{\pm\text{0.0}}$ \\
nuclear fusion        & 0.0$_{\pm\text{0.0}}$   & 100.0$_{\pm\text{0.0}}$ & 50.0  &  50.0 & 33.3$_{\pm\text{33.3}}$ &  50.0          &  25.0$_{\pm\text{25.0}}$ \\
communicating vessels & 3.3$_{\pm\text{4.7}}$   & 3.3$_{\pm\text{4.7}}$   & 10.0  &  10.0 & 0.0$_{\pm\text{0.0}}$   &  50.0          &  45.0$_{\pm\text{5.0}}$ \\
diffraction of waves  & 83.3$_{\pm\text{23.6}}$ & 100.0$_{\pm\text{0.0}}$ & --    & 100.0 & 100.0$_{\pm\text{0.0}}$ & 100.0          & 100.0$_{\pm\text{0.0}}$ \\
reflection            & 86.7$_{\pm\text{4.7}}$  & 43.3$_{\pm\text{4.7}}$  & --    &  10.0 & 66.7$_{\pm\text{1.3}}$  &  70.0          &  70.0$_{\pm\text{0.0}}$ \\
refraction            & 20.0$_{\pm\text{8.2}}$  & 83.3$_{\pm\text{4.7}}$  & --    & 100.0 & 50.0$_{\pm\text{4.0}}$  &  40.0          &  50.0$_{\pm\text{10.0}}$ \\
light imaging         & 10.0$_{\pm\text{0.0}}$  & 0.0$_{\pm\text{0.0}}$   & --    &   0.0 & 16.7$_{\pm\text{0.3}}$  &   0.0          &   0.0$_{\pm\text{0.0}}$ \\
cut                   & 90.0$_{\pm\text{0.0}}$  & 73.3$_{\pm\text{4.7}}$  & --    &  60.0 & 93.3$_{\pm\text{0.3}}$  & 100.0          & 100.0$_{\pm\text{0.0}}$ \\
laser                 & 46.7$_{\pm\text{12.5}}$ & 53.3$_{\pm\text{4.7}}$  & --    &  50.0 & 26.7$_{\pm\text{2.3}}$  &  10.0          &  15.0$_{\pm\text{5.0}}$ \\
move                  & 96.7$_{\pm\text{4.7}}$  & 86.7$_{\pm\text{4.7}}$  & --    &  30.0 & 83.3$_{\pm\text{4.3}}$  &  60.0          &  70.0$_{\pm\text{10.0}}$ \\
buoyancy              & 43.3$_{\pm\text{12.5}}$ & 100.0$_{\pm\text{0.0}}$ & --    & 100.0 & 46.7$_{\pm\text{2.3}}$  &  40.0          &  40.0$_{\pm\text{0.0}}$ \\
acceleration          & 10.0$_{\pm\text{8.2}}$  & 73.3$_{\pm\text{12.5}}$ & --    &  20.0 & 46.7$_{\pm\text{0.3}}$  &  40.0          &  30.0$_{\pm\text{10.0}}$ \\
inertia               & 80.0$_{\pm\text{8.2}}$  & 6.7$_{\pm\text{4.7}}$   & --    &  10.0 & 36.7$_{\pm\text{2.3}}$  &  30.0          &  45.0$_{\pm\text{15.0}}$ \\
electricity           & 16.7$_{\pm\text{4.7}}$  & 53.3$_{\pm\text{9.4}}$  & --    &  60.0 & 30.0$_{\pm\text{0.0}}$  &  60.0          &  60.0$_{\pm\text{0.0}}$ \\
reference frame       & 27.8$_{\pm\text{3.9}}$  & 13.9$_{\pm\text{3.9}}$  & --    &  66.7 & 47.2$_{\pm\text{1.6}}$  &  25.0          &  29.1$_{\pm\text{4.1}}$ \\
repulsive force       & 20.8$_{\pm\text{5.9}}$  & 20.8$_{\pm\text{11.8}}$ & --    &  50.0 & 20.8$_{\pm\text{0.5}}$  & 100.0          &  87.5$_{\pm\text{12.5}}$ \\
diffusion             & 8.3$_{\pm\text{11.8}}$  & 100.0$_{\pm\text{0.0}}$ & --    &   0.0 & 83.3$_{\pm\text{2.1}}$  &   0.0          &   0.0$_{\pm\text{0.0}}$ \\
vortex                & 0.0$_{\pm\text{0.0}}$   & 100.0$_{\pm\text{0.0}}$ & --    &  75.0 & 91.7$_{\pm\text{2.1}}$  &   0.0          &  12.5$_{\pm\text{12.5}}$ \\
expansion             & 50.0$_{\pm\text{0.0}}$  & 75.0$_{\pm\text{0.0}}$  & --    &  75.0 & 91.7$_{\pm\text{2.1}}$  &  75.0          &  87.5$_{\pm\text{12.5}}$ \\
wave                  & 16.7$_{\pm\text{15.6}}$ & 33.3$_{\pm\text{5.9}}$  & --    &  62.5 & 25.0$_{\pm\text{0.0}}$  &  25.0          &  18.8$_{\pm\text{6.2}}$ \\
    \bottomrule
    \end{tabular}
    \end{adjustbox}
    \caption{Performance decomposition to concepts on \coredatasetns-Dev. \emph{t} and \emph{v} refer to LLMs with textual or visual inputs.}
    \label{tab:perf_decomp_to_concept}
\end{table*}

\section{Construction of Synthetic Training Data Used in \ref{rq:format_analysis}}
\label{app:synthetic_data}
We investigate whether fine-tuning LLMs on matrix property-related questions could improve their performances on our tasks. Specifically, we generate 3000 extra input-output grid pairs calculate the size, transpose, and locations of the subgrid's corner elements for these matrices as ground truths. Furthermore, since correctly recognizing the location of the subgrid may contribute more to finish the Move and Copy tasks compared to other properties, we create additional ground truths only with the gold locations of the subgrid's corner elements. 



\section{Hyperparameters of Supervised Fine-Tuning in \ref{rq:format_analysis} and \ref{rq:sup_training}}
\label{app:sft_details}

For all the fine-tuning experiments, we use LoRA~\cite{hu2021lora}. We fine-tune each model for 3 epochs with a batch size of 4 on a single machine with 8 A100 GPUs. The dimension of LoRA's attention layer is set to 64, and the $\alpha$ and dropout rates are set to 16 and 0.1, respectively. The learning rate and weight decay are set to 2e-4 and 0.001, respectively.
The hyperparameters are selected according to the development performance on the synthetic matrix data in 
Appendix \ref{app:synthetic_data}.


\end{document}
