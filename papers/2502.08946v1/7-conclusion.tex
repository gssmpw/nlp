\section{Conclusion}
We introduce \datasetnamens, a novel task to assess
machines' understanding of physical concepts at different levels.
Our experiments reveal that:
1) LLMs lag significantly behind humans on \datasetnamens, indicating a lack of deep understanding of the covered concepts;
2) LLMs exhibit the stochastic parrot phenomenon, as they excel at low-level remembering tasks but struggle with high-level understanding tasks;
3) LLMs' poor performance stems from its intrinsic deficiencies, as neither in-context learning nor fine-tuning improves their results.





