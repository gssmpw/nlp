\section{Introduction}
\label{sec:intro}
\label{sec:formatting}


Diffusion-based generative models have emerged as a breakthrough AI technology, achieving state-of-the-art performance in scenarios like audio, image, and video generation~\cite{generative_survey}. Recent advancements in diffusion models for high-dimensional data generation have introduced a novel application domain: the generation of neural network weights. This technology avoids the overhead associated with gradient-based training or fine-tuning, offering promising solutions for few-shot, multi-task, and multi-domain problems that require frequent weight updates.

\begin{figure}[t]
    \centering
    \includegraphics[width=0.95\linewidth]{landscape.pdf}
    \caption{Inference chain of models trained with and without trajectory weights. In the 2D PAC reduced weight landscape, darker areas indicate lower downstream task loss. With the same initial points, trajectory weights help constrain the inference chain, whereas the diffusion chain of vanilla diffusion without trajectory weights tends to deviate from the optimal weights.}
    \label{fig:landscape_2d}
\end{figure}

Previous researchers leverage models such as Variational Autoencoder (VAE)~\cite{VAE} and Hypernetwork~\cite{hypernetworks} to learn the latent distribution of optimal weights for target tasks. OCD~\cite{OCD} and Meta-Diff~\cite{MetaDiff} attempt to use the diffusion model to simulate the weight optimization process. However, these approaches are constrained by single-level optimization frameworks and demonstrate limited capability for knowledge transfer between tasks, which subsequently impacts their generalization capacity for new tasks. 

More importantly, current weight generation methods only utilize the optimal weights as training samples, overlooking the value of other weights along the optimization trajectory\footnote{We will denote such weight as trajectory weight in the following section for brevity.}. This limited utilization of available training resources results in suboptimal performance in terms of both accuracy and efficiency.

\begin{figure*}[t]
    \centering
    \includegraphics[width=0.8\linewidth]{overview.pdf}
    \caption{Workflow of Lt-Di. In the weights preparation stage, it updates $\theta^h$ and constructs the optimization trajectory $Tra_i=\{\theta^h_m, ... ,\theta^h_0\}$ for each task $T_i$. In the meta-training stage, it uses $r(\cdot)$ to map optimization trajectory to the inference chain $C_{infer}=\{x_T,...,x_0\}$ for diffusion learning. In the inner-loop of meta-learning, it performs trajectory diffusion and decouples functional components into the weight preparation stage for efficiency. In the evaluation stage, it uses the well-trained denoise $\phi^*$ to generate optimal weights $\theta^{h^*}$ for unseen task $T_{n+1}$ without gradient computation. The red rectangle shows that trajectory diffusion is an extended version of vanilla diffusion with more observed data and loss functions.}
    \label{fig:overview}
\end{figure*} 

In this paper, (1) we propose to \textbf{L}earn to Learn Weight Generation via \textbf{T}rajectory \textbf{Di}ffusion, \ie, Lt-Di. This method utilizes diffusion models within the framework of bi-level optimization. Benefiting from the generalization capability offered by bi-level optimization (\ie, learn to learn), Lt-Di enables fast weight generation across multiple tasks or domains. Figure~\ref{fig:overview} shows Lt-Di's workflow, which consists of weight preparation, meta-training, and evaluation stages. (2) We extend the vanilla diffusion algorithm to trajectory diffusion, which leverages the weights along the optimization trajectory for training. As shown in Figure~\ref{fig:landscape_2d}, when trained with trajectory weights, Lt-Di's inference chain converges midway, making the final generated weights closer to the optimal weights. The above characteristics enable Lt-Di to achieve higher generation accuracy while tolerating fewer diffusion steps. (3) We analyze the convergence properties of the weight generation paradigm and introduce improvements. We decouple functional components, \ie, data augmentation~\cite{survey_neural} for robustness and sharpness-aware minimization~\cite{SAM} for convergence efficiency from the meta-training stage to the weight preparation stage, improving performance without additional time overhead. 
% \vspace{1em}

Our contributions can be summarized as follows:
% \vspace{-2em}
\begin{itemize}
    % \setlength{\itemsep}{5pt} 
    % \setlength{\parskip}{5pt}
    \item We propose Trajectory Diffusion, which leverages a whole trajectory to guide the diffusion model's inference chain.
    \item We propose Lt-Di, which combines meta-learning and trajectory diffusion to efficiently generate weights for unseen tasks.
    \item We analyze the convergency property of the weight generation paradigm and improve convergence efficiency without additional time overhead.
\end{itemize}




% Meta-learning algorithms with bi-level optimization paradigm are widely utilized to improve generalization ability in few-shot learning and reinforcement learning tasks~\cite{survey_neural,survey,a_closer_again,generalization_PAC_1,generalization_information_2}. However, such an approach typically faces two major challenges. The first is trade-off between meta-overfitting~\cite{meta_without_memory, survey_neural, Deconfounding, noise_data} against training overhead, and the second is evaluation latency~\cite{liu2022fewshot, ANIL, meta_bootstrap}.

% First, during training, meta-learning algorithms require explicit definition of inner-loop objective, such as image classification, to align with downstream targets. This can lead to meta-overfitting, where models fit superficial task patterns rather than deep shared representations, limiting adaptability to scenarios like multi-domain and multi-task learning. Introducing trainable parameters, noise adversarialing mechanism, or additional regularization function~\cite{Deconfounding,meta_without_memory,noise_data} can address this issue but incur significant overhead. This is because meta-learning's bi-level optimization and second-order derivation are highly sensitive to additional burdens in the inner-loop. Second, during evaluation, the gradient-based finetuning introduces considerable latency. This process cannot be handled in parallel, which impacts practical usage. Nowadays, generative algorithm have been applied to the learning of network weights. Researchers~\cite{VAE_weights, hypernetworks, GHN3} leverage models such as Variational Autoencoder (VAE)~\cite{VAE} and Hypernetwork~\cite{hypernetworks} to learn the latent distribution of optimal weights for target task. The advantage of this approach is that it enables finetuning using only forward propagation. However, these methods adopt a single-level learning approach, failing not only to address the issue of meta-overfitting but also losing the advantages of bi-level optimization in few-shot task.
% \begin{figure*}[t]
%     \centering
%     \includegraphics[width=0.8\linewidth]{overview.pdf}
%     \caption{Workflow of Lt-Di. In weights preparation stage, it updates $\theta^h$ and record the optimization trajectory $Tra_i=\{\theta^h_m, ... ,\theta^h_0\}$ for each task $T_i$. In meta training stage, it use $r(\cdot)$ mapping optimization trajectory to inference chain $\{x_T,...,x_0\}$ for subsequent diffusion learning. In the inner-loop of meta-learning, it performs trajectory diffusion in and decouple functional components to weight preparation stage. In evaluation stage, it uses the well trained denoise $\phi^*$ to generate optimal weights $\theta^{h^*}$ for unseen task $T_{n+1}$ without gradient computation. The red rectangle shows that trajectory diffusion is an extension version of vanilla diffusion with more observed data and loss functions.}
%     \label{fig:overview}
% \end{figure*}

% In this paper, we propose Lt-Di, \ie, Learn to Learn Weight Generation with Trajectory Diffusion. This method introduces diffusion algorithm~\cite{DDPM} to meta-learning by defining the meta-objective~\cite{survey_neural} as "learn to generate network weights". Figure~\ref{fig:landscape_2d} shows the workflow, it consist of weight preparation, meta-learning, and evaluation stages. This indirect approach makes the learning of inner-loop accomplished in an implicit way, reducing multi-domain and even multi-task learning to the problem of fitting optimal weights, thus avoiding meta-overfitting. Furthermore, based on theoretical derivation, we extend vanilla diffusion algorithm to trajectory diffusion, which leverages the whole optimization trajectory collect from weight preparation stage to guide diffusion model's inference chain. This algorithm reduces the steps needed by forward and reverse processes of diffusion model, enhancing generation quality while reducing overhead. As shown in Figure~\ref{fig:landscape_2d}, Lt-Di is constrained by optimization trajectory while Melv-Diff is the non-trajectory version. The diffusion chain of Lt-Di converges midway, making the generated weights being closer to the optimal weights. In addition, we analyzed the convergence property of Lt-Di and introduced improvement. We decouple functional components (\eg, noise adversarialing for meta-overfitting and sharpness aware minimization~\cite{SAM} for convergence) from inner-loop to weight preparation stage, improving performance in a "computation-free" manner. Our contributions can be summarize as follows:
  
% \begin{itemize}
%     \item We propose Trajectory Diffusion, which leverages the a trajectory to guide the learning of diffusion model.
%     \item We propose Lt-Di, which introduces diffusion algorithm to meta-learning. This method mitigates the overhead caused by meta-overfitting and gradient-based finetuning.
%     \item We analyze Lt-Diâ€™s convergence properties and introduce improvements in a computation-free manner.
%     \item We demonstrate Lt-Di's effectiveness on zero-shot, few-shot, multi-domain generalization, and LLM finetuning tasks.
% \end{itemize}







