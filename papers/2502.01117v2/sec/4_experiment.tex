\section{Experiment}\label{sec:experiment}
Our experimental platform includes two A100 GPUs, one Intel Xeon Gold 6348 processor, and 512 TB of DDR4 memory. For all experiment results, we report the mean and standard deviation over 5 independent repeated experiments. In the following section, we present the basic experimental results and setups, with more details provided in~\ref{sec:appendix_4}.

\subsection{Ablation Study}\label{sec:ablation}
\subsubsection{Main Components}
The advantages of Lt-Di stem from three main components: 
% \vspace{-1em}
\begin{itemize}[align=left]
    \item C1: Learning to generate optimal weights indirectly.
    \item C2: Using diffusion models to generate high-quality weights.
    \item C3: Using trajectory diffusion to guide the diffusion model.
\end{itemize}

As shown in Table~\ref{tab:ablation_main}, we validate the effectiveness of Lt-Di by ablating these components. When none of the components are used, Lt-Di degrades to the original REPTILE. When only C1 is used, we employ the vanilla VAE~\cite{VAE} to generate weights, while we refer to this method as LLO-VAE. When using C1 and C2, Lt-Di degrades to Lv-Di. Results in Table~\ref{tab:ablation_main} indicate that LLO-VAE demonstrates lower performance compared to REPTILE on the Omniglot dataset, suggesting the necessity for an enhanced generative algorithm. The comparison between REPTILE and Lv-Di shows that such an issue can be mitigated by using the diffusion model, which we attribute to its multi-step generation process that effectively captures the latent distribution of model weights. After adding the optimization trajectory, Lt-Di achieved the highest accuracy by modeling the entire optimization trajectory rather than just one optimal weight.

\begin{table}[t]
\centering
\resizebox{\linewidth}{!}{
\begin{tabular}{lcccccc}
    \toprule
    & \textbf{C1} & \textbf{C2} & \textbf{C3} & \textbf{Omniglot} & \textbf{Mini-Imagenet} \\
    \midrule
    REPTILE    &             &             &             & 95.39 ± 0.35 & 47.07 ± 0.26 \\
    LLO-VAE    & \cmark      &             &             & 94.92 ± 0.42 & 58.12 ± 0.28 \\
    Lv-Di       & \cmark      & \cmark      &             & 96.35 ± 0.21 & 66.90 ± 0.32 \\
    Lt-Di      & \cmark      & \cmark      & \cmark      & 97.12 ± 0.23 & 68.10 ± 0.24 \\
    \bottomrule
\end{tabular}}
\caption{Ablation main components on Omniglot and Mini-Imagenet datasets. Evaluate the accuracy of each variant on 5-way 1-shot tasks.}
\label{tab:ablation_main}
\end{table}

\subsubsection{Functional components}\label{sec:ablation_functional}
Following the setup given by~\citet{MAML}, we conducted a case study to evaluate the accuracy improvement and overhead burden brought by each functional component. We incrementally added SAM and data augmentation components to Lt-Di's data preparation stage. In Omniglot and Mini-Imagenet datasets, we construct 5-way 1-shot tasks and record the model's accuracy on the meta-test set at each period of training. Figure~\ref{fig:components_ablation} shows the GPU Hours vs. Accuracy trade-off curve in the meta-training stage. The results demonstrate that adding functional components can improve the model's performance without additional time overhead at \textit{any stage of training}. As mentioned in~\ref{sec:weight preparation}, during meta-learning, the functional information is already included in the trajectory weights, allowing the meta-learning algorithm to focus solely on learning these weights. Therefore, the three models in the figure exhibit identical convergence rates and progressively increasing accuracy.

\begin{figure}
    \centering
    \includegraphics[width=\linewidth]{ablation.pdf}
    \caption{Ablation functional components on Omniglot and Mini-ImageNet datasets. Comparing Accuracy vs GPU Hours trade-off curve of each variant on 5-way 1-shot tasks.}
    \label{fig:components_ablation}
\end{figure}

\subsection{Comparison Experiments}\label{sec:main_experiments}

\begin{table*}[t]
\centering
\resizebox{0.75\linewidth}{!}{
\begin{tabular}{llcccccc}
\hline
\textbf{Learning Type} & \textbf{Method} & \textbf{CIFAR-10} & \textbf{CIFAR-100} & \textbf{STL-10} & \textbf{Aircraft} & \textbf{Pets} & \textbf{Latency (ms)} \\ \hline
Directly Learning & REPTILE~\cite{REPTILE} & 48.31 \(\pm\) 0.96 & 32.92 \(\pm\) 0.61 & 45.25 \(\pm\) 0.86 & 11.82 \(\pm\) 2.84 & 17.25 \(\pm\) 2.01 & \textbf{1.3} \\
Directly Learning & Meta-Baseline~\cite{meta_baseline} & 55.48 \(\pm\) 0.64 & 40.52 \(\pm\) 0.37 & 75.06 \(\pm\) 0.17 & 19.17 \(\pm\) 2.70 & 22.84 \(\pm\) 1.25 & 1.4 \\
Weights Generation & ICIS~\cite{ICIS} & 61.75 \(\pm\) 0.31 & 47.66 \(\pm\) 0.24 & 80.59 \(\pm\) 0.12 & 26.42 \(\pm\) 1.56 & 28.71 \(\pm\) 1.60 & 9.2 \\
Weights Generation & GHN3~\cite{GHN3} & 61.18 \(\pm\) 0.28 & 49.94 \(\pm\) 0.26 & 80.54 \(\pm\) 0.14 & 26.46 \(\pm\) 1.22 & 29.95 \(\pm\) 1.75 & 14.5 \\
\rowcolor{gray!20} Weights Generation & Lv-Di(ours) & 61.74 \(\pm\) 0.39 & 48.42 \(\pm\) 0.26 & 78.89 \(\pm\) 0.15 & 27.87 \(\pm\) 1.67 & 29.53 \(\pm\) 1.08 & 3.8 \\
\rowcolor{gray!20} Weights Generation & Lt-Di(ours) & \textbf{62.07 \(\pm\) 0.33} & \textbf{51.73 \(\pm\) 0.25} & \textbf{81.64 \(\pm\) 0.12} & \textbf{28.69 \(\pm\) 1.14} & \textbf{31.88 \(\pm\) 1.53} & 2.6 \\
\hline
\end{tabular}}
\caption{Zero-shot transfer learning accuracy comparison on various datasets with average per-sample evaluation latency.}
\label{tab:zero_shot_performance}
\end{table*}




\begin{table*}[t]
\centering
\resizebox{\linewidth}{!}{
\begin{tabular}{llccccccccc}
    \hline
     & & \multicolumn{4}{c}{\textbf{Omniglot}} & \multicolumn{4}{c}{\textbf{Mini-Imagenet}} &  \\
    \cmidrule(lr){3-6}  % 左右间距会自动加入
    \cmidrule(lr){7-10}
    \textbf{Learning Type}& \textbf{Method} & \textbf{(5, 1)} & \textbf{(5, 5)} & \textbf{(20, 1)} & \textbf{(20, 5)} & \textbf{(5, 1)} & \textbf{(5, 5)} & \textbf{(20, 1)} & \textbf{(20, 5)} & \textbf{Latency (ms)} \\
    \hline
    Direct Learning &REPTILE~\cite{REPTILE}          & 95.39 ± 0.18 & 98.90 ± 0.14 & 88.14 ± 0.15 & 96.65 ± 0.33 & 47.07 ± 0.26 & 62.74 ± 0.37 & 38.24 ± 0.39 & 50.16 ± 0.46 & 20.7 \\
    Direct Learning &Meta-baseline~\cite{meta_baseline}    & \textbf{97.75 ± 0.25} & \textbf{99.68 ± 0.18} & 90.35 ± 0.20 & 96.92 ± 0.28 & 58.10 ± 0.31 & 74.50 ± 0.29 & 39.08 ± 0.40 & 52.14 ± 0.45 & 20.5 \\
    Weights Generation &Meta-Hypernetwork~\cite{Meta-Hypernetwork}& 96.57 ± 0.22 & 98.83 ± 0.16 & 89.90 ± 0.17 & 96.80 ± 0.30 & 60.51 ± 0.28 & 76.08 ± 0.34 & 40.07 ± 0.42 & 52.75 ± 0.48 & 13.1 \\
    Weights Generation &OCD~\cite{OCD}         & 95.04 ± 0.18 & 98.74 ± 0.14 & 89.25 ± 0.19 & 96.55 ± 0.25 & 62.76 ± 0.27 & 75.16 ± 0.35 & 41.53 ± 0.37 & 53.92 ± 0.46 & 8.4 \\
    Weights Generation &GHN3~\cite{GHN3}       & 95.23 ± 0.23 & 98.65 ± 0.19 & 89.07 ± 0.22 & 96.40 ± 0.31 & 66.22 ± 0.29 & 79.79 ± 0.33 & 44.10 ± 0.45 & 54.50 ± 0.50 & 22.5 \\
    Weights Generation &Meta-Diff~\cite{MetaDiff}    & 96.65 ± 0.20 & 98.91 ± 0.12 & 90.50 ± 0.16 & 97.11 ± 0.32 & 67.23 ± 0.33 & 80.81 ± 0.31 & 48.29 ± 0.39 & 59.25 ± 0.44 & 8.9 \\
    \rowcolor{gray!20}Weights Generation &Lv-Di(ours)             & 96.35 ± 0.21 & 98.83 ± 0.15 & 89.19 ± 0.18 & 96.70 ± 0.27 & 66.90 ± 0.32 & 80.25 ± 0.28 & 48.75 ± 0.38 & 59.95 ± 0.47 & 6.2 \\
    \rowcolor{gray!20}Weights Generation &Lt-Di(ours)           & 97.12 ± 0.23 & 99.42 ± 0.08 & \textbf{90.83 ± 0.16} & \textbf{97.18 ± 0.25} & \textbf{68.10 ± 0.24} & \textbf{81.42 ± 0.30} & \textbf{51.29 ± 0.32} & \textbf{62.18 ± 0.45} & \textbf{4.3} \\
    \hline
\end{tabular}}
\caption{Few-shot task accuracy comparison on Omniglot and Mini-Imagenet datasets with average per-sample evaluation latency.}
\label{tab:few_shot_performance_latency}
\end{table*}


\subsubsection{Zero-Shot Transfer Learning}
\noindent\textbf{Task.} In this task, we train and evaluate models on disjoint pre-training and evaluation datasets. During evaluation, we do not use any labeled data to adjust the models. We evaluated the zero-shot transfer learning capability of the models using both accuracy and average per-sample evaluation latency.
\par
\noindent\textbf{Dataset.} We partitioned ImageNet-1k~\cite{imagenet} into 20k subsets of 50 classes each with 50 images per class per task for pre-training. The evaluation datasets are CIFAR-10, CIFAR-100~\cite{CIFAR1O_100}, STL-10~\cite{STL10}, Aircraft~\cite{aifcraft}, and Pets~\cite{pets}.
\par
\noindent\textbf{Baselines.}
We benchmark against REPTILE~\cite{REPTILE}, Meta-Baseline~\cite{meta_baseline}, ICIS~\cite{ICIS}, and GHN3~\cite{GHN3}. The first two directly learn from downstream task samples, while the others learn to generate weight. For all the aforementioned models, the downstream network uses ResNet12~\cite{resnet} as body $\theta^b$, and a two-layer linear probe as head $\theta^h$. For denoiser $\phi$, we employ the same U-Net architecture given by~\cite{DDPM} and maintain this setup across all experiments in this paper.
\par
\noindent\textbf{Results.}
Table~\ref{tab:zero_shot_performance} shows that Lt-Di consistently improves performance on all tasks while utilizing the same network architecture as other methods. Compared to the state-of-the-art method, Lt-Di improved accuracy by an average of 1.58\% across five evaluation datasets. This result demonstrates the generalizability of Lt-Di, which can be well applied to zero-shot transfer learning scenarios. As mentioned in Section~\ref{sec:ablation_functional}, Lt-Di also outperforms its simplified variants, \ie, REPTILE and Lv-Di, demonstrating that indirectly learning optimization trajectory improves the model’s generalization ability. In terms of overhead, except for directly learning algorithms, \ie, REPTILE and Meta-Baseline, which do not generate weights, Lt-Di exhibits the lowest evaluation latency among other methods, confirming its efficiency.

\subsubsection{Few-Shot Learning}\label{sec:few_shot_learning} 
\noindent\textbf{Task.} Following the setup provided by~\citet{MAML}, we train and evaluate models on disjoint meta-training and meta-testing tasks. During the evaluation stage, we use the support set in meta-test tasks to fine-tune the models, and then compare the accuracy and average per-sample evaluation latency on the query set.
\par
\noindent\textbf{Dataset.} We use Omniglot~\cite{omniglot} and Mini-Imagenet~\cite{miniImagenet} datasets for the construction of 5-way 1-shot, 5-way 5-shot, 20-way 1-shot, and 20-way 5-shot tasks. The classes of the meta-training and the meta-testing tasks are disjoint from each other.
\par
\noindent\textbf{Baselines.}\label{sec:zero-shot}
We benchmark against REPTILE~\cite{REPTILE}, Meta-baseline~\cite{meta_baseline}, Meta-Hypernetwork~\cite{Meta-Hypernetwork}, OCD~\cite{OCD}, GHN3~\cite{GHN3}, and Meta-Diff~\cite{MetaDiff}. Following the setting given by~\citet{MAML}, the downstream network uses four convolution blocks as body $\theta^b$, and a two-layer linear probe as head $\theta^h$. 
\par
\noindent\textbf{Results.}
Table~\ref{tab:zero_shot_performance} shows that Lt-Di can improve performance on almost all tasks. Since the 5-way task of Omniglot is relatively easy to learn, the Meta-Baseline algorithm can achieve slightly higher accuracy in a direct learning manner. Compared to the latest methods, Lt-Di achieves an average accuracy increase of 1.10\%. Compared to the current fastest weight generation algorithm, \ie, OCD, Lt-Di reduces evaluation latency by 48.81\%. Note that the direct learning algorithms REPTILE and Meta-Baseline have the highest latency here, as they require gradient computation to complete fine-tuning.

\subsubsection{Multi-Domain Generalization}\label{sec:multi-domain}
\noindent\textbf{Task.} In this task, we explore the multi-domain generalizability of Lt-Di. We follow the few-shot task given by~\citet{hierar_meta} to evaluate the model's performance.
\par
\noindent\textbf{Dataset.} We use DomainNet~\cite{DomainNet} for the construction of 5-way 1-shot and 20-way 5-shot tasks. Specifically, we use Clipart, Infograph, Painting, Quickdraw, and Real domains for meta-training, while Sketch domains for meta-testing. Under this setting, the tasks in the meta-training set may come from different domains, and the tasks in the meta-testing set may come from another unseen domain.
\par
\noindent\textbf{Baselines.}
We benchmark against REPTILE, Meta-baseline, Meta-Hypernetwork, GHN3, OCD, and Meta-Diff. The downstream network uses ResNet12 as body $\theta^b$, and a two-layer linear probe as head $\theta^h$.
\par
\noindent\textbf{Results.}
Table~\ref{tab:multi_domain_performance} shows that Lt-Di significantly outperforms current methods on few-shot multi-domain generalization tasks. Compared to the best-performing baseline Meta-Diff, Lt-Di achieved an average improvement of 4.35\% in accuracy. It can be observed that, compared to direct learning methods REPTILE and Meta-Baseline, methods that indirectly learn the optimal weight exhibit a significant advantage gap. Building on these approaches, Lt-Di further learns the optimization trajectory, which enhances the model's performance even more. In terms of overhead, Lt-Di reduces evaluation latency by 46.39\% compared to OCD, showing the same advantage as in zero-shot and few-shot tasks.
\begin{table}[t]
\centering
\resizebox{\linewidth}{!}{
\begin{tabular}{llccc}
    \toprule
          && \multicolumn{2}{c}{\textbf{DomainNet}} \\
    \cmidrule(lr){3-4}
    \textbf{Learning Type}&\textbf{Method} & \textbf{(5, 1)} & \textbf{(20, 5)}& \textbf{Latency(ms)} \\
    \midrule
    Direct Learning&REPTILE~\cite{REPTILE}          & 48.13 ± 0.50 & 52.32 ± 0.42 & 26.8 \\
    Direct Learning&Meta-Baseline~\cite{meta_baseline}         & 50.54 ± 0.47 & 54.45 ± 0.40 &26.2\\
    Weights Generation&Meta-Hypernetwork~\cite{Meta-Hypernetwork}    & 59.00 ± 0.39 & 63.32 ± 0.35 &10.3 \\
    Weights Generation&OCD~\cite{OCD} & 64.58 ± 0.42 & 67.10 ± 0.38 &9.7  \\
    Weights Generation&GHN3~\cite{GHN3}             & 63.11 ± 0.36 & 66.42 ± 0.33 &30.1 \\
    Weights Generation&Meta-Diff~\cite{MetaDiff}              & 64.24 ± 0.41 & 67.58 ± 0.39 &10.9 \\
    \rowcolor{gray!20}Weights Generation&Lv-Di(ours)        & 66.75 ± 0.35 & 69.98 ± 0.32 &7.0\\
    \rowcolor{gray!20}Weights Generation&Lt-Di(ours)    & \textbf{68.10 ± 0.33} & \textbf{72.42 ± 0.36} &\textbf{5.2} \\
    \bottomrule
\end{tabular}}
\caption{Multi-domain generalization accuracy comparison on DomainNet with 5-way 1-shot and 20-way 5-shot tasks.}
\label{tab:multi_domain_performance}
\end{table}

\subsubsection{Large Language Model fine-tuning}
\noindent\textbf{Task.}
In this section, we demonstrate that Lt-Di can be applied to the fine-tuning of LLM by learning to generate LoRA~\cite{LoRa} matrices for new tasks with low latency. We compared the algorithms in terms of their fine-tuning accuracy upon convergence and the latency required to achieve it.
\par
\noindent\textbf{Datasets.}
We conduct a case study to demonstrate the generalizability and efficiency of Lt-Di. We use five binary classification tasks, \ie, SST-2, QQP, RTE, WNIL, and CoLA from the GLUE~\cite{GLUE} benchmark for pre-training. Then we use the other two tasks, \ie, MRPC and QNIL, to evaluate the performance of the methods.
\par
\noindent\textbf{Baselines.}
We benchmark against Full-fine-tuning baseline, LoRA~\cite{LoRa}, AdaLoRA~\cite{AdaLoRA}, DyLoRA~\cite{DyLoRA}, and FourierFT~\cite{FourierFT}, which are all gradient-based fine-tuning algorithms. The large language model we fine-tuned is RoBERTa-base~\cite{FourierFT} and the LoRA matrices are generated following the fine-tuning process given by~\citet{FourierFT}. Note that Lt-Di is a meta-learning-based method that can learn on all training tasks, while other baselines are single-task fine-tuning methods that only work on one task. \textit{Smart readers} may notice that Lt-Di requires extra time for meta-learning, but this approach is a one-time effort and shows better potential in multi-task fine-tuning scenarios.
\par
\noindent\textbf{Results.}
Table~\ref{tab:performance_fine-tune_time_comparison} shows that Lt-Di achieves comparable binary classification accuracy on two evaluation tasks compared to other gradient-based fine-tuning algorithms while significantly accelerating the fine-tuning speed by 300\% to 400\%. Through its implementation of meta-learning, Lt-Di demonstrates remarkable efficiency in capturing shared representations from pre-training tasks, enabling direct generation of task-specific LoRA matrices without the need for gradient computation.

\begin{table}[t]
\centering
\resizebox{\linewidth}{!}{
\begin{tabular}{llcccc}
    \toprule
     && \multicolumn{2}{c}{\textbf{MRPC}} & \multicolumn{2}{c}{\textbf{QNLI}} \\
     \cmidrule(lr){3-4}  % 左右间距会自动加入
    \cmidrule(lr){5-6}
    \textbf{fine-tuning Type}&\textbf{Method} & \textbf{Acc} & \textbf{Latency (h)} & \textbf{Acc} & \textbf{Latency (h)} \\
    \midrule
    Gradient-Based&Full-fine-tune   & \textbf{90.24 ± 0.57} & 1.47 & 92.84 ± 0.26 & 3.15 \\
    Gradient-Based&LoRA~\cite{LoRa}            & 89.76 ± 0.69 & 0.81 & \textbf{93.32 ± 0.20} & 1.76 \\
    Gradient-Based&AdaLoRA~\cite{AdaLoRA}         & 88.71 ± 0.73 & 0.74 & 93.17 ± 0.25 & 1.68 \\
    Gradient-Based&DyLoRA~\cite{DyLoRA}          & 89.59 ± 0.81 & 0.76 & 92.21 ± 0.32 & 1.63 \\
    Gradient-Based&FourierFT~\cite{FourierFT}       & 90.03 ± 0.54 & 0.68 & 92.25 ± 0.15 & 1.55 \\
    \rowcolor{gray!20}Weights Generation&Lv-Di(ours)        & 88.15 ± 0.62 & 0.22 & 90.96 ± 0.18 & 0.48 \\
    \rowcolor{gray!20}Weights Generation&Lt-Di(ours)       & 89.03 ± 0.56 & \textbf{0.19} & 91.52 ± 0.22 & \textbf{0.41} \\
    \bottomrule
\end{tabular}}
\caption{Accuracy and fine-tuning latency comparison on GLUE-MRPC and GLUE-QNLI tasks for different fine-tuning algorithms.}
\label{tab:performance_fine-tune_time_comparison}
\end{table}




