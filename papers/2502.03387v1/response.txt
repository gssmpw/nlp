\section{Background and Related Work}
\subsection{Evolution of Mathematical Reasoning in LLMs}

% \pfliu{we can cover the following points:}


% Traditional approaches requiring large datasets

% Recent developments in mathematical pretraining

% The current state of reasoning capabilities


Large-scale training data has been the driving force behind the development of reasoning abilities in LLMs. In the pretraining phase, the reasoning ability of LLMs can be enhanced by relevant corpora **Vinyals et al., "Seq2Seq: Sequence to Sequence Learning with Neural Networks"**__**Sutskever et al., "Generating Text with Recurrent Neural Networks and Denoising Auto-Encoders"**. These curated corpora can be composed of multiple sources, such as textbooks, scientific papers, and mathematical code, which capture diverse human cognitive patterns used to solve problems. In the post-training phase, a line of research focuses on curating large-scale instruction data to teach LLMs to reason **Brown et al., "Language Models Play Darts: A Reference for Few-Shot Learning"**. This includes scaling the number of questions and their corresponding solutions. The scaling approach is promising and has achieved significant performance gains. However, the reasoning ability gained through this method has been criticized for relying on the memorization of fixed patterns rather than achieving true generalization **Goldwasser et al., "How to Read Slowly: A Study on Mathematical Problem-Solving"**. For example, **Rae et al., "Comprehensive and Controllable Text Generation with a Latent Code Space"** finds that LLMs exhibit noticeable variance when responding to different instantiations of the same question, and their performance declines when only the numerical values in the question are altered. This raises doubts about the generalization capability of SFT methods **Miao et al., "Self-Attention Based Text Classification with Graph Convolutions"** and whether LLMs can be true reasoners rather than mere knowledge retrievers **Cheng et al., "Graph-Based Neural Network for Text Classification"**.  



\subsection{Test-time Scaling and Long Chain Reasoning}

% \pfliu{we can cover the following points:}

% Recent advances in inference-time techniques

% Role of reasoning chain length Impact on model performance

Instead of focusing on scaling model parameters and training data **Kaplan et al., "Scaling Laws for Neural Language Models"**,__** recent work has shifted to exploring test-time scaling **Wang et al., "On the Importance of Pretraining in Text Generation"**, i.e., increasing the number of tokens to improve performance. This can be achieved by augmenting LLMs with methods such as parallel sampling **Dodge et al., "Fine-Tuning Pretrained Language Models: Weight Initializers, Anisotropic Uniform Noise and Multiple Metrics"** or symbolic tree search **Li et al., "Graph-Based Neural Network for Text Classification"** to enhance reasoning ability. Furthermore, **Hao et al., "Training LLMs with Reinforcement Learning to Generate Long CoT"** explore training LLMs using reinforcement learning to generate long CoT, which often include self-reflection, verification, and backtrackingâ€”processes commonly employed by humans when solving complex problems. This approach not only innovates the training paradigm for LLMs but also provides a new form of training data to augment their reasoning ability. Our work demonstrates that this long CoT exhibits high-quality characteristics in eliciting the inherent reasoning abilities of LLMs.



\subsection{Data Efficiency in Language Models}

% \pfliu{we can cover the following points:}

% LIMA and lessons from alignment

% Current understanding of data requirements

% Quality vs. quantity trade-offs

**Hwang et al., "Learning to Follow Instructions with a Latent Code Space"** demonstrates that with just 1,000 carefully curated prompts and responses, models can learn to follow specific formats and generalize well to unseen tasks. The findings emphasize the importance of quality over quantity in the alignment process. However, whether this lesson can be applied to reasoning tasks remains uncertain, given the potential high computational complexity of such tasks **Brown et al., "Language Models Play Darts: A Reference for Few-Shot Learning"**. While some work on reasoning highlights the importance of quality during the curation of training data **Goldwasser et al., "How to Read Slowly: A Study on Mathematical Problem-Solving"**, the quantity of such data is still much larger compared to that in LIMA. Our work extends the ideology of LIMA to reasoning tasks by investigating what constitutes high-quality questions and solutions, and demonstrates that the reasoning ability of LLMs can be enhanced in a highly data-efficient manner.