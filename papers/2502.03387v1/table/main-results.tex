\begin{table*}[ht]
    \centering
    \caption{
    \textbf{Comparison of model performance (pass@1) across various mathematical reasoning benchmarks} Models include state-of-the-art LLMs (OpenAI-o1-preview, QwQ-32B-Preview), our base model (Qwen2.5-32B-Instruct), and models fine-tuned on different datasets. Training data sizes are shown in parentheses. 
    %The evaluation is conducted on both in-domain tasks (AIME24, MATH500, AMC23) and out-of-domain tasks (e.g., OlympiadBench, MinervaMath). 
    Best results for each benchmark are shown in bold. Our proposed LIMO model (highlighted in blue) achieves superior performance despite using significantly fewer training examples (817) compared to other fine-tuned models (more than 100k).
    }
    \renewcommand{\arraystretch}{1.2}
    \setlength{\tabcolsep}{5pt}
    \begin{tabularx}{\textwidth}{l c c c c c c}
        \toprule
        \textbf{Datasets} & \textbf{\makecell{OpenAI-o1\\-preview}} & \textbf{\makecell{Qwen2.5-32B\\-Instruct}} & \textbf{\makecell{QwQ-32B-\\preview}}  & 
        \textbf{\makecell{OpenThoughts\\(114k)}} & \textbf{\makecell{NuminaMath\\(100k)}} & \cellcolor[HTML]{dceffe}
        \textbf{\makecell{LIMO\\ours(817)}} \\
        \midrule
        \multicolumn{7}{c}{In Domain} \\
        \midrule
        AIME24 & 44.6 & 16.5&50.0   &50.2 & 6.5 &\cellcolor[HTML]{dceffe} \textbf{57.1}\\
        MATH500 &85.5 & 79.4 & 89.8 &  80.6 & 59.2 & \cellcolor[HTML]{dceffe} \textbf{94.8}\\
        AMC23& 81.8  & 64.0 & 83.6  & 80.5 & 40.6 & \cellcolor[HTML]{dceffe} \textbf{92.0}\\
        
        \midrule
        \multicolumn{7}{c}{Out of Domain} \\
        \midrule
        OlympiadBench & 52.1 & 45.3& 58.5  & 56.3 & 36.7 & \cellcolor[HTML]{dceffe} \textbf{66.8}\\
        CHMath & 50.0 & 27.3& 68.5  & 74.1 & 11.2 & \cellcolor[HTML]{dceffe} \textbf{75.4}\\
        Gaokao &62.1 & 72.1& 80.1  & 63.2 & 49.4 & \cellcolor[HTML]{dceffe} \textbf{81.0} \\
        Kaoyan & 51.5 & 48.2 & 70.3&54.7&32.7&\cellcolor[HTML]{dceffe} \textbf{73.4}\\
        GradeSchool & 62.8&56.7 & 63.8 & 39.0 & 36.2 & \cellcolor[HTML]{dceffe} \textbf{76.2} \\
        Minerva & \textbf{47.1} & 41.2& 39.0  & 41.1 & 24.6 & \cellcolor[HTML]{dceffe} 44.9\\
        GPQA &  \textbf{73.3} & 48.0& 65.1  & 42.9 & 25.8 & \cellcolor[HTML]{dceffe} 66.7\\
        \midrule
        AVG. & 61.1 & 49.9 & 66.9 & 58.3& 32.3 & \cellcolor[HTML]{dceffe} \textbf{72.8}\\
        \bottomrule
    \end{tabularx}
    \label{tab:main_results}
\end{table*}

    % \yxye{Why qwen2.5-32B-instruct? Why AIME? Why these 500 question?}
    % \yxye{Do we need a list of datasets defining their formal names? And length of each dataset?}
    % \yxye{Graphs may be better for exhibition
    % \yxye{Do we need a list of datasets defining their formal names? And length of each dataset?}}
    % \yxye{\#TODO: Greedy pass@1 test for AIME24}