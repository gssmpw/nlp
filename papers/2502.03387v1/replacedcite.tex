\section{Background and Related Work}
\subsection{Evolution of Mathematical Reasoning in LLMs}

% \pfliu{we can cover the following points:}


% Traditional approaches requiring large datasets

% Recent developments in mathematical pretraining

% The current state of reasoning capabilities


Large-scale training data has been the driving force behind the development of reasoning abilities in LLMs. In the pretraining phase, the reasoning ability of LLMs can be enhanced by relevant corpora____. These curated corpora can be composed of multiple sources, such as textbooks, scientific papers, and mathematical code, which capture diverse human cognitive patterns used to solve problems. In the post-training phase, a line of research focuses on curating large-scale instruction data to teach LLMs to reason____. This includes scaling the number of questions and their corresponding solutions. The scaling approach is promising and has achieved significant performance gains. However, the reasoning ability gained through this method has been criticized for relying on the memorization of fixed patterns rather than achieving true generalization____. For example,____ finds that LLMs exhibit noticeable variance when responding to different instantiations of the same question, and their performance declines when only the numerical values in the question are altered. This raises doubts about the generalization capability of SFT methods____ and whether LLMs can be true reasoners rather than mere knowledge retrievers____.  



\subsection{Test-time Scaling and Long Chain Reasoning}

% \pfliu{we can cover the following points:}

% Recent advances in inference-time techniques

% Role of reasoning chain length Impact on model performance

Instead of focusing on scaling model parameters and training data____, recent work has shifted to exploring test-time scaling____, i.e., increasing the number of tokens to improve performance. This can be achieved by augmenting LLMs with methods such as parallel sampling____ or symbolic tree search____ to enhance reasoning ability. Furthermore,____ explore training LLMs using reinforcement learning to generate long CoT, which often include self-reflection, verification, and backtrackingâ€”processes commonly employed by humans when solving complex problems. This approach not only innovates the training paradigm for LLMs but also provides a new form of training data to augment their reasoning ability. Our work demonstrates that this long CoT exhibits high-quality characteristics in eliciting the inherent reasoning abilities of LLMs.



\subsection{Data Efficiency in Language Models}

% \pfliu{we can cover the following points:}

% LIMA and lessons from alignment

% Current understanding of data requirements

% Quality vs. quantity trade-offs

____ demonstrates that with just 1,000 carefully curated prompts and responses, models can learn to follow specific formats and generalize well to unseen tasks. The findings emphasize the importance of quality over quantity in the alignment process. However, whether this lesson can be applied to reasoning tasks remains uncertain, given the potential high computational complexity of such tasks____. While some work on reasoning highlights the importance of quality during the curation of training data____, the quantity of such data is still much larger compared to that in LIMA. Our work extends the ideology of LIMA to reasoning tasks by investigating what constitutes high-quality questions and solutions, and demonstrates that the reasoning ability of LLMs can be enhanced in a highly data-efficient manner.