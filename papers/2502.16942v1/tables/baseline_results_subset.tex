\begin{table*}[!ht]
    \centering
    \resizebox{\linewidth}{!}{%
    \begin{tabular}{lccccccccc}
    \toprule
       Model & \multicolumn{1}{c}{RougeL} & \multicolumn{1}{c}{BERTScore} & \multicolumn{3}{c}{Llama3.1-7B-Instruct}   \\

      &   F1 $\uparrow$ &   F1 $\uparrow$ & Score with Expl. $\uparrow$ & Plain Score $\uparrow$ & Avg. Rank $\downarrow$ \\
    \midrule
       Whisper + LLama31-Instruct  &   23.26 &    86.81 &   \textbf{77.75} &  \textbf{84.30} & \textbf{1.23}  \\
       Qwen2-Audio &  16.26 &   84.94 & 48.42 &  39.50 & 3.47 \\
       End2End Finetuned &   \textbf{24.47} &  \textbf{86.71 }&   70.67 &   75.73 & 1.83\\

    \bottomrule
    \end{tabular}%
    }
    \caption{Baseline Results, the finetuned model is a HuBERT + Qformer + LLama31Instruct model on the subset used for human annotation (30 examples).}
    \label{tab:baselines_subset}
\end{table*}
