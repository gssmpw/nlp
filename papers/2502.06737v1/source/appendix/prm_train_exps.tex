\subsection{Evaluation Results for Math PRMs and~\ourprm~Across all Categories}
\label{sec:mathprm-fullevals}





\begin{table*}[ht]
\caption{Comparison among various math PRMs and~\ourprm~on different domains in~\ourdataeval~when using WMV with min-aggregation on $N=16$ CoTs generated per question using Llama3.1-8B-Instruct. In parenthesis we report the relative difference between WMV and the MV baseline (WMV$-$MV). While WMV using math PRMs exhibit greater improvement in math and math-adjacent domains, there is no significant improvement on MV in other domains.}
\small
\centering
\setlength{\tabcolsep}{4pt}
\resizebox{\textwidth}{!}{
\begin{tabular}{l|c|cccccc}
\toprule
\textbf{Category} & \textbf{MV (Baseline)} & \textbf{Math-PSA} & \textbf{Math-Shepherd} & \textbf{Qwen-2.5-Math-PRM} & \textbf{RLHFLow-Deepseek} & \textbf{LlamaPRM800K} & \textbf{\ourprm} \\
\midrule
All & 57.15 & 57.87(+0.72) & 57.66(+0.51) & 58.17(+1.02) & 57.59(+0.44) & 58.16(+1.01) & \textbf{61.22(+4.07)} \\
All except math & 56.61 & 56.82(+0.21) & 57.01(+0.40) & 57.32(+0.71) & 56.96(+0.35) & 57.71(+1.10) & \textbf{60.29(+3.68)} \\
Math & 62.40 & 64.20(+1.80) & 64.13(+1.73) & 67.20(+4.80) & 64.07(+1.67) & 65.40(+3.00) & \textbf{68.87(+6.47)} \\
Math-Adjacent & 56.75 & 57.98(+1.23) & 57.48(+0.73) & 58.30(+1.55) & 57.33(+0.58) & 58.27(+1.52) & \textbf{61.22(+4.47)} \\
Non-Math-Adjacent & 56.69 & 56.79(+0.10) & 57.14(+0.45) & 57.09(+0.40) & 57.02(+0.33) & 57.55(+0.86) & \textbf{60.00(+3.31)} \\
\midrule
Chemistry & 58.67 & 60.47(+1.80) & 60.13(+1.46) & 60.67(+2.00) & 59.13(+0.46) & 60.47(+1.80) & \textbf{66.13(+7.46)} \\
Computer Science & 55.80 & 56.93(+1.13) & 56.07(+0.27) & 56.13(+0.33) & 56.07(+0.27) & 56.40(+0.60) & \textbf{58.60(+2.80)} \\
Engineering & 51.67 & 50.67(-1.00) & 51.07(-0.60) & 53.13(+1.46) & 51.87(+0.20) & 52.27(+0.60) & \textbf{55.27(+3.60)} \\
Physics & 58.53 & 61.87(+3.34) & 61.87(+3.34) & 61.47(+2.94) & 60.80(+2.27) & 61.47(+2.94) & \textbf{64.87(+6.34)} \\
\midrule
Biology & 75.38 & 75.23(-0.15) & 75.38(+0.00) & 75.69(+0.31) & 75.77(+0.39) & 76.38(+1.00) & \textbf{80.00(+4.62)} \\
Health & 63.36 & 63.00(-0.36) & 63.93(+0.57) & 63.50(+0.14) & 63.57(+0.21) & 64.50(+1.14) & \textbf{65.50(+2.14)} \\
Psychology & 61.60 & 61.47(-0.13) & 61.47(-0.13) & 62.27(+0.67) & 61.47(-0.13) & 61.87(+0.27) & \textbf{64.53(+2.93)} \\
Business & 61.34 & 61.95(+0.61) & 62.21(+0.87) & 63.02(+1.68) & 62.21(+0.87) & 62.62(+1.28) & \textbf{64.50(+3.16)} \\
Economics & 62.00 & 62.67(+0.67) & 62.33(+0.33) & 62.53(+0.53) & 62.67(+0.67) & 62.40(+0.40) & \textbf{64.27(+2.27)} \\
Law & 35.93 & 35.72(-0.21) & 37.24(+1.31) & 36.28(+0.35) & 36.07(+0.14) & 36.90(+0.97) & \textbf{43.86(+7.93)} \\
History & 49.20 & 49.00(-0.20) & 49.87(+0.67) & 49.40(+0.20) & 49.40(+0.20) & 49.87(+0.67) & \textbf{50.67(+1.47)} \\
Philosophy & 44.83 & 44.90(+0.07) & 44.70(-0.13) & 45.17(+0.34) & 44.56(-0.27) & 45.30(+0.47) & \textbf{49.13(+4.30)} \\
Other & 55.53 & 55.80(+0.27) & 55.47(-0.06) & 56.07(+0.54) & 55.87(+0.34) & 57.07(+1.54) & \textbf{59.00(+3.47)} \\
\bottomrule
\end{tabular}
}
\vskip -0.1in
\label{tab:math_prm_on_multi_domain}
\end{table*}


\subsection{PRM Training with Counterfactual Augmented Data}

\begin{figure*}[ht]
    \begin{center}
        \includegraphics[width=\linewidth]{figures/new_figures/prm_noaugs_vs_augs_min_agg.pdf}        
        \caption{Comparison of WMV (top) and BoN (bottom) using our two multi-domain PRMs (w/ and w/o counterfactually augmented training data) on the categories of~\ourdataeval. We use min-aggregation and the CoTs are generated using Llama-3.1-8B-Instruct. When using WMV, counterfactual augmented data can further improve the performance of PRM on non-math-adjacent domains.}
        \label{fig:counteraug}
    \end{center}
\end{figure*}


\clearpage


\subsection{WMV and BoN using different aggregation methods}
\label{sec:agg-comp3}


\begin{figure*}[ht]
    \begin{center}
        \includegraphics[width=\linewidth]{figures/new_figures/prm_diff_agg.pdf}        
        \caption{Comparison of WMV (left) and BoN (right) using \ourprm~with different reward aggregations on~\ourdataeval. The CoTs are generated using Llama 3.1 8B Instruct. Overall, min-aggregation brings the largest inference performance boost.}
        \label{fig:prm-diff-agg2}
    \end{center}
\end{figure*}


\clearpage


\subsection{Larger Generator Inference with PRM Rewarding}
\label{sec:agg-comp}


\begin{figure*}[ht]
    \begin{center}
        \includegraphics[width=\linewidth]{figures/new_figures/prm_on_70b_cot.pdf}        
        \caption{Comparison of WMV (left) and BoN (right) using \ourprm~against math PRMs on~\ourdataeval. We use min-aggregation and the CoTs are generated using Llama-3.1-70B-Instruct. Similar trends to using 8B model as the generator are observed, indicating that our Multi-Domain PRM can generalize across generators with different capacities.}
        \label{fig:prm-diff-agg}
    \end{center}
\end{figure*}


\clearpage


\subsection{Inference with Compact PRM}
\label{sec:agg-comp2}


\begin{figure*}[ht]
    \begin{center}
        \includegraphics[width=\linewidth]{figures/new_figures/prm_with_3b_min_agg.pdf}        
        \caption{Comparison of WMV (top) and BoN (bottom) using \ourprm~(Llama3B Base), a compact PRM based on Llama-3.2-3B-Instruct and trained on our multi-domain dataset. We use min-aggregation and the CoTs are generated using Llama-3.1-8B-Instruct. Compared with using \ourprm~(Llama Base), which applies the same training data and configurations but is based on Llama-3.1-8B-Instruct, \ourprm~(Llama3B Base) brings a less significant performance boost. However, the overall trends are similar, indicating the efficacy of the inference pipeline using PRM.}
        \label{fig:prm-diff-agg1}
    \end{center}
\end{figure*}

\clearpage


\subsection{Comparison of~\ourprm~against Other Open-Source Math PRMs on WMV and BoN by Category}
\label{sec:bon-mv-bycat}


\begin{figure*}[ht]
    \begin{center}
        \includegraphics[width=\linewidth]{figures/new_figures/prm_all_domains_wmv_min_agg.pdf}        
        \caption{Comparison of WMV using \ourprm~against open-source PRMs on more other categories of~\ourdataeval. We use min-aggregation and the CoTs are generated using Llama-3.1-8B-Instruct.}
        \label{fig:prm-wmv-more-domains}
    \end{center}
\end{figure*}


\begin{figure*}[ht]
    \begin{center}
        \includegraphics[width=\linewidth]{figures/new_figures/prm_all_domains_bon_min_agg.pdf}        
        \caption{Comparison of BoN using \ourprm~against open-source PRMs on more other categories of~\ourdataeval. 
        We use min-aggregation and the CoTs are generated using Llama-3.1-8B-Instruct.}
        \label{fig:prm-bon-more-domains1}
    \end{center}
\end{figure*}


\clearpage

\subsection{Comparison of~\ourprm~against Other Open-Source Math PRMs on MCTS and Beam Search by Category}
\label{sec:mcts-detailed}


\begin{figure*}[ht]
    \begin{center}
        \includegraphics[width=\linewidth]{figures/new_figures/all_domains_mcts_vs_beam.pdf}        
        \caption{Comparison of \ourprm~and LlamaPRM800K
        with beam search and MCTS. In more other categories from~\ourdataeval, \ourprm~achieves better performance.}
        \label{fig:prm-wmv-more-domains2}
    \end{center}
\end{figure*}