
\begin{algorithm}[ht]
\caption{Beam Search with Process Reward Model}
\label{alg:beam}
\begin{algorithmic}[1]
\REQUIRE Large Language Model $\text{LLM}(\cdot)$, Process Reward Model $\text{PRM}(\cdot)$, Prompt $s_0$, Number of Beams $N$, Beam width $M$, Maximum step length $L$
\STATE $\mathcal{B} \gets [s_0]$
\STATE $\mathcal{Q} \gets [0]$
\FOR{$i = 1$ to $L$}
    \STATE $\mathcal{B} \gets \text{Expand}(\mathcal{B}, \frac{N}{\operatorname{len}(\mathcal{B})})$

    \STATE $\mathcal{B} \gets \text{LLM.step}(\mathcal{B})$


    \STATE $\mathcal{Q} \gets \text{Aggr}(\mathcal{B})$

    \STATE $\texttt{best\_idxs} \gets$ Indexes of the highest $\frac{N}{M}$ scores in $\mathcal{Q}$

    \STATE $\mathcal{B} \gets \mathcal{B}[\texttt{best\_idxs}]$
    \STATE $\mathcal{Q} \gets \mathcal{Q}[\texttt{best\_idxs}]$
    
    \IF{All sequences in $\mathcal{B}$ contain a terminal leaf node}
        \STATE \textbf{break}
    \ENDIF
\ENDFOR
\STATE Return the sequence with the highest score from $\mathcal{B}$

\end{algorithmic}
\end{algorithm}



\Cref{alg:beam} is a greedy search algorithm that uses a PRM select the best CoT during search. More details are given in \Cref{sec:inference-time-methods}.


\clearpage


\begin{algorithm}[ht]
\caption{Monte Carlo Tree Search with Process Reward Model}
\label{alg:mcts}
\begin{algorithmic}[1]
    \REQUIRE Large Language Model $\text{LLM}(\cdot)$, Process Reward Model $\text{PRM}(\cdot)$, Prompt $s_0$, Maximum step length $L$, Number of roll-outs $K$, Number of generated child nodes $d$, Exploration weight $w$
    \STATE Initialize the value function $Q : \mathcal S \mapsto \mathbb R$ and
    visit counter $N : \mathcal S \mapsto \mathbb N$ 
    \FOR {$n \gets 0, \dots, K - 1$}
        \STATE // \textit{Selection}
        \STATE $t \gets 0$
        \WHILE {$s_t$ is not a leaf node}
            \STATE $N(s_t) \gets N(s_t) + 1$ 
            \STATE $s_{t+1} \gets \arg\max_{\text{children}(s_t)} \left[ Q(\text{child}(s_t)) + w \sqrt{\frac{\ln N(s_t)}{N(\text{child}(s_t))}} \right]$
            \STATE $t \gets t + 1$
        \ENDWHILE
        \STATE // \textit{Expansion \& Simulation} (equivalent to the beam search with $N=M=d$)
        \STATE $\mathcal{B} \gets [s_t]$
        \WHILE {$s_t$ is not a terminal leaf node $\wedge$ $t \leq L$}
            \STATE $N(s_t) \gets N(s_t) + 1$
            \STATE $\mathcal{B} \gets \text{Expand}(\mathcal{B}, d)$
            \STATE $\mathcal{B} \gets \text{LLM.step}(\mathcal{B})$
    
        \FOR {$s \in \mathcal{B}$} 
            \STATE $Q(s) \gets \text{Aggr}(s)$
            %\STATE $N(s) \gets N(s) + 1$
            %\STATE $Q(s) \gets \text{PRM}(s)$ // or $\text{Aggr}(s)$
        \ENDFOR
        
            %\STATE $\texttt{best\_idx} \gets$ Index of the highest score in $\mathcal{S}$
            \STATE $s_{t+1} \gets \arg\max_{s \in \mathcal{B}} Q(s)$ 
            \STATE $t \gets t + 1$ 
            \STATE $\mathcal{B} \gets [s_t]$
        \ENDWHILE
        \STATE // \textit{Back Propagation}
        \FOR {$t' \gets t, \dots, 0$}
            \STATE $Q(s_{t'}) \gets \max (Q(s_{t'}), Q(s_{t}))$
        \ENDFOR
    \ENDFOR
    \STATE Return the sequence with the highest score among the terminal nodes
\end{algorithmic}
\end{algorithm}



\Cref{alg:mcts} is a tree-based search algorithm that iteratively expands a search tree to find the CoT with the highest PRM score. MCTS iteratively builds a search tree through the following steps:
\begin{enumerate}
    \item \textbf{Selection}: Starting from the root node, the algorithm traverses the tree by selecting child nodes according to a selection policy.
    \item \textbf{Expansion and Simulation}: Upon reaching a non-terminal leaf node, the tree is expanded iteratively by generating a fixed number of child nodes and then greedily selecting the child node with the highest value (which for us is determined by the PRM). This process continues until a terminal node is reached.
    \item \textbf{Backpropagation}: The results from the simulation are propagated back through the tree, updating value estimates and visit counts for each node along the path.
\end{enumerate}
These steps are repeated for a fixed number of iterations or until a computational or time limit is reached. To determine the final prediction, we choose the terminal node with the highest value.


\clearpage