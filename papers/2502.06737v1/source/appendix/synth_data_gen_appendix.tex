\subsection{Dataset Composition}
The total composition of \ourdatatrain~is as follows.

\begin{table}[ht]
    \centering
    \caption{Composition of \textit{\ourdatatrain}}
    \small
    \begin{tabular}{cccc} \toprule
          & \textbf{Total} & \textbf{Fully Correct} & \textbf{Incorrect}   \\ \midrule
         Number of CoTs & 84098 & 36935 & 47163 \\
         Number of Steps & 487380 & 440217 & 47163\\
         \bottomrule
    \end{tabular} 
    \label{tab:dataset_composition}
\end{table}


\subsection{Data Generation Pipeline Prompts}
\label{sec:synth-gen-prompts}


To generate chain-of-thought (CoT) reasoning for MMLU-Pro questions, we utilize the prompt shown in~\Cref{fig:cot-gen-prompt-mmlu}.
To ensure the generated CoT adhere to the proper format---where steps are separated by two newline characters and the final step follows the structure ``the answer is (X)''---we include five few-shot examples. These examples are derived from the CoTs provided in the validation split of MMLU-Pro, with additional processing to ensure each step is delimited. The code for generating the complete prompt will be open-sourced alongside the rest of our code and data.


During generation, we use a temperature of $0.8$ and set the maximum generation length to 2,048 tokens. During auto-labeling, we use a temperature of 0, and the maximum generation length remains at 2,048 tokens.

\begin{figure}[ht]
    \centering
    \begin{minipage}{6in}
    \begin{tcolorbox}[width=6in, sharp corners=all, colback=white!95!black]
The following is a multiple choice question and its ground truth answer. You are also given a students solution (split into step, enclosed with tags and indexed from 0):

\-

[Multiple Choice Question]

\{question\}

\-

[Ground Truth Answer]

\{answer\}

\-

[Student Solution]

\{$<$step\_0$>$\\
Student solution step 0\\
$<$/step\_0$>$

\-\\
$<$step\_1$>$\\
Student solution step 0\\
$<$/step\_1$>$

\-\\...\}

\end{tcolorbox}
    \end{minipage}
    \caption{User prompt template for auto-labeling.}
    \label{fig:v6-auto-label-prompt}
\end{figure}

\begin{figure}[ht]
    \centering
    \begin{minipage}{6in}
    \begin{tcolorbox}[width=6in, sharp corners=all, colback=white!95!black]

You are an experienced evaluator specializing in assessing the quality of reasoning steps in problem-solving. Your task is to find the first BAD step in a student's solution to a multiple choice question.

\-\\
You will judge steps as GOOD, OK or BAD based on the following criteria:\\
1. GOOD Step\\
A step is classified as GOOD if it meets all of these criteria:\\
- Correct: Everything stated is accurate and aligns with known principles or the given problem.\\
- Verifiable: The step can be verified using common knowledge, simple calculations, or a quick reference (e.g., recalling a basic theorem). If verifying requires extensive effort (e.g., detailed calculations or obscure references), mark it BAD instead.\\
- Appropriate: The step fits logically within the context of the preceding steps. If a prior mistake exists, a GOOD step can correct it.\\
- Insightful: The step demonstrates reasonable problem-solving direction. Even if ultimately progress in the wrong direction, it is acceptable as long as it represents a logical approach.

\-\\
2. OK Step\\
A step is classified as OK if it is:\\
- Correct and Verifiable: Contains no errors and can be verified.\\
- Unnecessary or Redundant: Adds little value, such as restating prior information or providing basic encouragement (e.g., “Good job!”).\\
- Partially Progressing: Makes some progress toward the solution but lacks decisive or significant advancement.

\-\\
3. BAD Step\\
A step is classified as BAD if it:\\
- Is Incorrect: Contains factual errors, misapplies concepts, derives an incorrect result, or contradicts the ground truth answer.\\
- Is Hard to Verify: Requires significant effort to confirm due to poor explanation.\\
- Is Off-Topic: Includes irrelevant or nonsensical information.\\
- Derails: Leads to dead ends, circular reasoning, or unreasonable approaches.

\-\\
\#\#\#\# Task Description\\
You will be provided with:\\
1. A Question\\
2. A Ground Truth Answer\\
3. A Reference explanation of the answer\\
4. A Student's Step-by-Step Solution, where each step is enclosed with tags and indexed from 0

\-\\
You may use the ground truth answer and reference explanation in classifying the type of each step.\\
A student's final answer is considered correct if it matches the ground truth answer or only differs due to differences in how the answer is rounded.
Once you identify a BAD step, return the index of the earliest BAD step. Otherwise,
return the index of -1 (which denotes all steps are GOOD or OK).
Please put your final answer (i.e., the index) in $\backslash\backslash$boxed{}.
\end{tcolorbox}
    \end{minipage}
    \caption{System prompt for auto-labeling.}
    \label{fig:v5-auto-label-prompt}
\end{figure}

% 

\clearpage

\subsection{Counterfactual Augmentation}
\label{sec:counter-aug}


\begin{figure*}[ht]
    \begin{center}
        \includegraphics[width=0.9\textwidth]{figures/Counterfactual_Augmentation_Pipeline.pdf}
         \caption{Diagram of the counterfactual augmentation pipeline}
        \label{fig:neg-aug-pipeline}
    \end{center}
\end{figure*}


After generating and labeling our synthetic reasoning CoTs (as described in~\Cref{sec:synth-data-gen}), we attempted to create additional incorrect steps by augmenting the correct reasoning steps. Our pipeline is depicted in~\Cref{fig:neg-aug-pipeline}.
We provide the full CoT to Llama-3.1-70B-Instruct, instructing it to select and rewrite a step where it would be appropriate to introduce an error.
Additionally, we define a list of possible fine-grained error types. To encourage the generation of a variety of different error types, we only include a random selection of two of these error types in each system prompt, forcing the LLM to choose one. The error types are:
\begin{itemize}
    \item Conflicting Steps: The reasoning step includes statements that contradict previous steps.
    \item Non-sequitur: The reasoning step introduces information that is irrelevant to the question.
    \item Factual: The reasoning step contains incorrect statements of factual information.
    \item False Assumption: The reasoning step makes an incorrect assumption about the question.
    \item Contextual: The reasoning step misinterprets information given within the question/context.
\end{itemize}



For the prompt format used in counterfactual augmentation,
see~\Cref{fig:neg-augmentation-system-prompt}.
In total, we generated 73,829 augmented incorrect steps.


\begin{figure}[ht]
    \centering
    \begin{minipage}{6in}
    \begin{tcolorbox}[width=6in, sharp corners=all, colback=white!95!black]
    The following are multiple choice questions (with answers). Think step by step and then finish your answer with "the answer is (X)" where X is the correct letter choice.
    \end{tcolorbox}
    \end{minipage}
    \caption{Prompt to generate CoTs for MMLU Pro.}
    \label{fig:cot-gen-prompt-mmlu}
\end{figure}


\begin{figure}[ht]
    \centering
    \begin{minipage}{6in}
    \begin{tcolorbox}[width=6in, sharp corners=all, colback=white!95!black]
\small You are a highly knowledgeable philosopher with expertise across many domains, tasked with analyzing reasoning processes. 
Your goal is to identify how a reasoning process could naturally deviate toward an incorrect conclusion through the introduction of subtle errors.

\-\\
Here are a list of potential error types, all of which are equally valid:\\
\textrm{[ERROR TYPE 1]: [ERROR TYPE 1 DEFINITION]}\\
\textrm{[ERROR TYPE 2]: [ERROR TYPE 2 DEFINITION]}

\-\\
Instructions:\\
You will be provided with:\\
1. A question.\\
2. A complete chain of reasoning steps, where each step is numbered (e.g., Step X).

\-\\
Your task is to:
1. Identify the major factual information, reasoning, and conclusions within the reasoning steps.\\
3. Explain how to generate an incorrect step to replace one of the existing steps. This should include:\\
   - Identifying a step where the reasoning could naturally deviate.\\
   - Speculating what type of error would be most appropriate to introduce at the chosen step.\\
4. Introduce an incorrect next step that aligns stylistically with the previous steps. This incorrect step should:\\
   - Reflect a deviation in reasoning that significantly harms the correctness.\\
   - Appear natural and believable in the context of the reasoning process.\\
5. Clearly explain how the incorrect step is an error, highlighting the specific logical or conceptual flaw.

\-\\
Output Format:

\-\\
STEP\_SUMMARY:\\
\textrm{[Summarize the reasoning within the steps in 1-2 sentences, identifying major information, logical steps, and conclusions.]}

\-\\
INCORRECT\_STEP\_GEN:\\
\textrm{[Explain how the reasoning at a specific step could deviate naturally into being incorrect. Clearly describe the type of error that could be introduced at this step.]}

\-\\
ERROR\_TYPE:\\
\textrm{[The name of the type of error chosen to be introduced.]}

\-\\
STEP\_NUM:\\
\textrm{[The number of the step that was identified as a place where the reasoning could naturally deviate. Only include the number here.]}

\-\\
INCORRECT\_STEP:\\
\textrm{[Write the incorrect step in the same tone and style as the other steps. Wrap the incorrect step inside curly braces (e.g. \{incorrect step\}).]}

\-\\
ERROR\_EXPLANATION:\\
\textrm{[}Explain how the incorrect step fits the definition of the selected error type, identifying the specific flaw.\textrm{]}
\end{tcolorbox}
    \end{minipage}
    \caption{System prompt for counterfactual augmentation.}
    \label{fig:neg-augmentation-system-prompt}
\end{figure}




\clearpage