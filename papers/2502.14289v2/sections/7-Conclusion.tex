\section{Conclusion}

We introduce \textbf{Drift}, a training-free framework for personalizing LLMs via decoding-time alignment with implicit user preferences. By decomposing implicit personal preferences into a weighted combination of interpretable attributes, Drift enables few-shot personalization that is both computationally efficient and interpretable. 
In the personalized AI domain—where obtaining sufficient annotations is challenging and training individual, user-specific LLMs is impractical—Drift represents a significant advance. Ultimately, Drift holds promise for democratizing personalized AI services and fostering human-aligned AI systems that are adaptable to individual needs.

% Extensive experiments on synthetic and real-world datasets demonstrate that Drift achieves robust performance with as few as 50–100 examples, outperforming traditional reward models trained on substantially more data.
% Ultimately, Drift holds promise for democratizing personalized AI services and fostering human-aligned AI systems.

