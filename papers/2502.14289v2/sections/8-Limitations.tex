
\section*{Limitations}

While Drift contributes promising advances in implicit personal preferences, several limitations remain that should be addressed in future research.

\paragraph{Needs of Online Human Evaluation Benchmarks.}  
A major challenge in personal preference research is the absence of reproducible human evaluations. Even if future benchmarks collect more user-specific annotations beyond PRISM, evaluating personalized generation outputs requires \textit{re-engaging with the same users for feedback}. Although we designed the Perspective dataset to align the label construction and test set evaluation pipelines, it still relies on virtual personas. Therefore, to advance this field, there is a need for online evaluation benchmarks that can reproducibly assess personalized generation using real user feedback.

\paragraph{Limited Analysis Between Drift Attributes and Actual Users.}  
Due to practical and ethical issues, we do not have full access to the backgrounds of actual users. While the PRISM dataset provides basic information (e.g., the intended use of LLMs and brief self-introductions), our analysis (as seen in Figure~\ref{fig:activated-attributes-prism}) is limited in explaining why certain attributes are activated and how these relate to user characteristics. A more in-depth investigation into the correlation between Drift attributes and real user profiles should be studied with future benchmarks.

\paragraph{Biases in Differential Prompting.}  
Our study does not thoroughly analyze the limitations of the zero-shot rewarding mechanism used for each attribute. It is possible that differential prompting may fail to capture certain attributes accurately, and methods like those employed in Helpsteer2—where data is explicitly constructed—could offer more precise evaluations. Nevertheless, given the vast diversity of personal preferences, a zero-shot approach remains essential. As shown in Figure~\ref{fig:rm-results}, this approach yields significantly higher performance, and Figure~\ref{fig:attributes_num} demonstrates that even when the number of attributes is reduced to levels comparable to those used in Helpsteer2, performance remains robust. In essence, unreliable attributes are unlikely to be used during decoding, which mitigates this limitation. Moreover, as future research develops to enable LLM to follow system prompts more precisely, these advances will directly enhance Drift.

\paragraph{Tokenizer Dependency.}  
Drift Decoding adjusts the next-token distribution at each step, which requires that the LLM and the sLM share the same support—that is, they must use the same tokenizer. 

\paragraph{Limited Baselines.}  
Due to the scarcity of datasets for implicit personal preferences, this domain is far less mature compared to explicit preferences. As highlighted in Table~\ref{tab:method_comparison}, the limited availability of extensive baselines forced us to concentrate primarily on analyzing the unique characteristics of Drift.

\section*{Ethical Statement}

While Drift effectively integrates users’ implicit preferences into generated outputs, it also introduces several ethical risks that must be carefully managed. Notably, the Drift Approximation stage allows us to directly assess the activation levels of each attribute, which provides an opportunity to identify and preemptively block system prompts that could lead to harmful or undesirable content before they are incorporated into the decoding process. This capability underscores the importance of further research into combining Drift with diverse system prompts, ensuring that the generation of undesirable content is minimized while still delivering personalized services.

Additionally, considering that existing research~\citep{kim2024guaranteed} indicates it is impossible to obtain filtered autoregressive distributions under certain conditions, it is necessary to combine rejection sampling on final outputs using safeguards~\citep{lifetox} such as LlamaGuard~\citep{llamaguard} and ShieldGemma~\citep{shieldgemma}. This approach can further enhance the safety of the final generated content.
