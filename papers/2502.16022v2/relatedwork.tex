\section{Related Work}
Identifying jargon terms important to patients is part of the biomedical Named Entity Recognition (BioNER) task, which involves identifying predefined entities in a text and labeling each token with the corresponding entity.
Medical entities encompass categories such as diseases, medications, treatments, lab tests, and more~\cite{liuEvaluatingMedicalEntity2024, boseSurveyRecentNamed2021}.
Studies such as~\cite{lee2020biobert,liu2019roberta,yao2023extracting,yao2023context} have introduced language models for BioNER tasks, while more recent studies~\cite{hu2024improving,monajatipoorLLMsBiomedicineStudy2024a,hu2024zero,gutierrez2022thinking,moradi2021gpt} have explored the application of large language models (LLMs) in BioNER.
However, BioNER tasks primarily focus on extracting entities without considering their importance and relevance to the personal needs of patients, which distinguishes them from our objective.

MedJex~\cite{kwonMedJExMedicalJargon2022a} fine-tunes pre-trained language models (PLMs), such as BERT~\cite{devlin2018Bert}, RoBERTa~\cite{liu2019roberta}, BioClinicalBERT~\cite{alsentzer2019publicly}, and BioBERT~\cite{lee2020biobert}, on a domain-specific corpus.
It leverages Wikipedia hyperlink spans during pretraining and transfers the learned weights to a target model fine-tuned on MedJ, an expert-annotated medical dataset.
More recent studies~\cite{lim2024large} have investigated whether large language models (LLMs), such as ChatGPT~\cite{openai_website}, can outperform baseline PLMs (e.g., MedJex~\cite{kwonMedJExMedicalJargon2022a} and SciSpacy~\cite{neumann2019scispacy}) in extracting personalized medical jargon.
Similarly, GAMedX~\cite{ghali2024gamedx}, a medical data extractor utilizing LLMs (Mistral 7B and Gemma 7B), employs chained prompts to navigate the complexities of specialized medical jargon.
Other works~\cite{butler2024jargon, mannhardt2024impact, lu2023napss} have demonstrated how LLMs can enhance the readability of EHR notes by extracting medical jargon.


This work also shares similarities with topic modeling, a task that extracts topics from input text.
Using unsupervised learning algorithms, topic modeling can identify both explicit and implicit themes within a text corpus~\cite{speierUsingPhrasesDocument2016, wenMiningHeterogeneousClinical2021, sunTopicModelingClinical2024}.
Through topic modeling, a text can be represented by multiple keywords or topics, which can then be incorporated into supervised models.
However, topic modeling heavily relies on term frequencies and may easily overlook important terms that are clinically relevant to individual patients.

Among the most relevant works, such as FOCUS~\cite{chenFindingImportantTerms2016a}, ADS~\cite{chenRankingMedicalTerms2017}, and FIT~\cite{chenUnsupervisedEnsembleRanking2017},
FOCUS~\cite{chenFindingImportantTerms2016a} employs MetaMap~\cite{aronson2010overview} to extract medical jargon from EHR notes and utilizes feature-rich learning-to-rank techniques to determine whether the terms are important.
%Leveraging feature engineering, both ADS~\cite{chenRankingMedicalTerms2017} and FIT~\cite{chenUnsupervisedEnsembleRanking2017} rank medical jargon terms based on their importance to patients using supervised and unsupervised approaches.
However, none of the previous works have identified and ranked medical jargon terms in a note-specific manner.
This is an important task, as ranking terms based on their relevance to a specific note may help the patient comprehend the note by linking important jargon terms to their lay definitions~\cite{yao2023readme}, or help 
%conducting patient post-discharge comprehension assessments~\cite{cai2023paniniqa}, or 
generate patient-friendly after-visit summaries~\cite{cai2022generation}.