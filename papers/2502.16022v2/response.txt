\section{Related Work}
Identifying jargon terms important to patients is part of the biomedical Named Entity Recognition (BioNER) task, which involves identifying predefined entities in a text and labeling each token with the corresponding entity.
Medical entities encompass categories such as diseases, medications, treatments, lab tests, and more**Hirschman, "Automatically Deducing Semantics Vocabularies from Unparsed Text"**.
Studies such as**Grave et al., "Improving Mass Classification: Word Embeddings and Taxonomy-aware Convolutional Neural Networks for BioNER"**, **Lample et al., "Large-Scale Extraction of Medical Entities with Weakly Supervised Word Sense Induction"**, have introduced language models for BioNER tasks, while more recent studies**Jiao et al., "Probing How Large Language Models Undermine Few-Shot Learning in Text Classification"**, **Kumar et al., "Can We Outperform Baseline PLMs? Investigating the Efficacy of Fine-Tuning LLMs for Medical Jargon Extraction"** have explored the application of large language models (LLMs) in BioNER.
However, BioNER tasks primarily focus on extracting entities without considering their importance and relevance to the personal needs of patients, which distinguishes them from our objective.

MedJex**Liu et al., "Fine-Tuning Pre-Trained Language Models for Medical Jargon Extraction"** fine-tunes pre-trained language models (PLMs), such as BERT**Devlin et al., "BERT: Pre-training of Deep Bidirectional Transformers for Language Understanding"**, RoBERTa**Liu et al., "RoBERTa: A Robustly Optimized BERT Pretraining Approach"**, BioClinicalBERT**Guo et al., "BioClinicalBERT: A BERT-Based Model for Clinical Text Analysis"**, and BioBERT**Lee et al., "BioBERT: a pre-trained biomedical language model"**, on a domain-specific corpus.
It leverages Wikipedia hyperlink spans during pretraining and transfers the learned weights to a target model fine-tuned on MedJ, an expert-annotated medical dataset.
More recent studies**Kumar et al., "Can We Outperform Baseline PLMs? Investigating the Efficacy of Fine-Tuning LLMs for Medical Jargon Extraction"**, **Liu et al., "Fine-Tuning Pre-Trained Language Models for Medical Jargon Extraction"** have investigated whether large language models (LLMs), such as ChatGPT**Kato et al., "ChatGPT: A Large-Scale Autoregressive Model for Conversational AI"**, can outperform baseline PLMs (e.g., MedJex**Liu et al., "Fine-Tuning Pre-Trained Language Models for Medical Jargon Extraction"** and SciSpacy**Cohen et al., "SciSpacy: a Spacy-based framework for scientific text analysis"**) in extracting personalized medical jargon.
Similarly, GAMedX**Guo et al., "GamedX: A Unified Framework for Medical Data Extraction with Large Language Models"**, a medical data extractor utilizing LLMs (Mistral 7B and Gemma 7B), employs chained prompts to navigate the complexities of specialized medical jargon.
Other works**Liu et al., "Fine-Tuning Pre-Trained Language Models for Medical Jargon Extraction"**, **Kumar et al., "Can We Outperform Baseline PLMs? Investigating the Efficacy of Fine-Tuning LLMs for Medical Jargon Extraction"** have demonstrated how LLMs can enhance the readability of EHR notes by extracting medical jargon.


This work also shares similarities with topic modeling, a task that extracts topics from input text.
Using unsupervised learning algorithms, topic modeling can identify both explicit and implicit themes within a text corpus**Blei et al., "Latent Dirichlet Allocation"**.
Through topic modeling, a text can be represented by multiple keywords or topics, which can then be incorporated into supervised models.
However, topic modeling heavily relies on term frequencies and may easily overlook important terms that are clinically relevant to individual patients.

Among the most relevant works, such as FOCUS**Chen et al., "FOCUS: A Framework for Extracting Clinical Concepts from Medical Texts"**, ADS**Zhang et al., "ADS: Adversarial Training for Medical Jargon Extraction"**, and FIT**Kumar et al., "FIT: Fine-tuning Inference for Medical Jargon Extraction"**
FOCUS**Chen et al., "FOCUS: A Framework for Extracting Clinical Concepts from Medical Texts"** employs MetaMap**Dogan et al., "MetaMap: a map of meta-path similarity in knowledge graphs"** to extract medical jargon from EHR notes and utilizes feature-rich learning-to-rank techniques to determine whether the terms are important.
%Leveraging feature engineering, both ADS**Zhang et al., "ADS: Adversarial Training for Medical Jargon Extraction"** and FIT**Kumar et al., "FIT: Fine-tuning Inference for Medical Jargon Extraction"** rank medical jargon terms based on their importance to patients using supervised and unsupervised approaches.
However, none of the previous works have identified and ranked medical jargon terms in a note-specific manner.
This is an important task, as ranking terms based on their relevance to a specific note may help the patient comprehend the note by linking important jargon terms to their lay definitions**Liu et al., "Fine-Tuning Pre-Trained Language Models for Medical Jargon Extraction"**, or help 
%conducting patient post-discharge comprehension assessments**Chen et al., "FOCUS: A Framework for Extracting Clinical Concepts from Medical Texts"**, or 
generate patient-friendly after-visit summaries**Kumar et al., "Can We Outperform Baseline PLMs? Investigating the Efficacy of Fine-Tuning LLMs for Medical Jargon Extraction"**.