\documentclass[conference]{IEEEtran}
\IEEEoverridecommandlockouts
% The preceding line is only needed to identify funding in the first footnote. If that is unneeded, please comment it out.
%Template version as of 6/27/2024

\usepackage{cite}
\usepackage{amsmath,amssymb,amsfonts}
\usepackage{algorithmic}
\usepackage{graphicx}
\usepackage{textcomp}
\usepackage{xcolor}
%\documentclass{article}
%\usepackage{spconf,amsmath,graphicx}
\usepackage{booktabs}
\usepackage{array}
\usepackage{float}
\usepackage[export]{adjustbox}
% Example definitions.
% --------------------
\def\x{{\mathbf x}}
\def\L{{\cal L}}

\def\BibTeX{{\rm B\kern-.05em{\sc i\kern-.025em b}\kern-.08em
    T\kern-.1667em\lower.7ex\hbox{E}\kern-.125emX}}
    
\begin{document}

\title{Enhancing Standard and Dialectal Frisian ASR: Multilingual Fine-tuning and Language Identification for Improved Low-resource Performance\\
%{\footnotesize \textsuperscript{*}Note: Sub-titles are not captured for https://ieeexplore.ieee.org  and
%should not be used}
%\thanks{Identify applicable funding agency here. If none, delete this.}
}

%\author{
%\IEEEauthorblockN{Reihaneh Amooie}
%\IEEEauthorblockA{\textit{Center for Language and Cognition} \\
%\textit{University of Groningen}\\
%Groningen, The Netherlands \\
%r.amooie@rug.nl}
%\and
%\IEEEauthorblockN{Wietse de Vries}
%\IEEEauthorblockA{\textit{Center for Language and %Cognition} \\
%\textit{University of Groningen}\\
%Groningen, The Netherlands\\
%wietse.de.vries@rug.nl}
%\and
%\IEEEauthorblockN{Yun Hao}
%\IEEEauthorblockA{\textit{Center for Language and Cognition} \\
%\textit{University of Groningen}\\
%Groningen, The Netherlands \\
%yun.hao@rug.nl}
%\and
%\IEEEauthorblockN{Jelske Dijkstra}
%\IEEEauthorblockA{\textit{Fryske Akademy} \\
%Friesland, The Netherlands \\
%jdijkstra@fryske-akademy.nl}
%\and
%\IEEEauthorblockN{Matt Coler}
%\IEEEauthorblockA{\textit{Campus Fryslan} \\
%\textit{University of Groningen}\\
%Friesland, The Netherlands \\
%m.coler@rug.nl}
%\and
%\IEEEauthorblockN{Martijn Wieling}
%\IEEEauthorblockA{\textit{Center for Language and Cognition} \\
%\textit{University of Groningen}\\
%Groningen, The Netherlands \\
%m.b.wieling@rug.nl}
%}



\author{
\IEEEauthorblockN{Reihaneh Amooie}
\IEEEauthorblockA{\textit{Center for Language and Cognition} \\
\textit{University of Groningen}\\
Groningen, The Netherlands \\
r.amooie@rug.nl}
\and
\IEEEauthorblockN{Wietse de Vries}
\IEEEauthorblockA{\textit{Center for Language and Cognition} \\
\textit{University of Groningen}\\
Groningen, The Netherlands\\
wietse.de.vries@rug.nl}
\and
\IEEEauthorblockN{Yun Hao}
\IEEEauthorblockA{\textit{Center for Language and Cognition} \\
\textit{University of Groningen}\\
Groningen, The Netherlands \\
yun.hao@rug.nl} 
\and 
\IEEEauthorblockN{Jelske Dijkstra}
\IEEEauthorblockA{\textit{Mercator European Research Centre} \\
\textit{Fryske Akademy}\\
Friesland, The Netherlands \\
jdijkstra@fryske-akademy.nl\\
}  % Added phantom line to balance height
\and
\IEEEauthorblockN{Matt Coler}
\IEEEauthorblockA{\textit{Speech Technology Lab} \\
\textit{University of Groningen}\\
Friesland, The Netherlands \\
m.coler@rug.nl}
\and
\IEEEauthorblockN{Martijn Wieling}
\IEEEauthorblockA{\textit{Center for Language and Cognition} \\
\textit{University of Groningen}\\
Groningen, The Netherlands \\
m.b.wieling@rug.nl}
}



\maketitle
\begin{abstract}
Automatic Speech Recognition (ASR) performance for low-resource languages is still far behind that of higher-resource languages such as English, due to a lack of sufficient labeled data.  State-of-the-art methods deploy self-supervised transfer learning where a model pre-trained on large amounts of data is fine-tuned using little labeled data in a target low-resource language. In this paper, we present and examine a method for fine-tuning an SSL-based model in order to improve the performance for Frisian and its regional dialects (Clay Frisian, Wood Frisian, and South Frisian). We show that Frisian ASR performance can be improved by using multilingual (Frisian, Dutch, English and German) fine-tuning data and an auxiliary language identification task. In addition, our findings show that performance on dialectal speech suffers substantially, and, importantly, that this effect is moderated by the elicitation approach used to collect the dialectal data. Our findings also particularly suggest that relying solely on standard language data for ASR evaluation may underestimate real-world performance, particularly in languages with substantial dialectal variation.
\end{abstract}

\begin{IEEEkeywords}
automatic speech recognition, low-resource languages, self-supervised learning, XLS-R, dialectal speech recognition.
\end{IEEEkeywords}

\section{Introduction}
Automatic Speech Recognition (ASR) systems are an integral component in human-machine interaction systems. %such as digital assistants and social robots.
Despite  advancements driven by the availability of extensive data and computational resources, achieving near human-like performance remains confined mainly to high-resource languages and standard dialects, leaving minority languages underrepresented. %such as English, 
%and predominantly for standard, non-dialectal speech. 
%This disparity leaves minority languages %and their dialects
%underrepresented. %underscoring a  need for  research to bridge this performance gap.
Our study  approaches this challenge within the context of Frisian, a minority language from the province of Friesland, The Netherlands, and its regional dialects: Klaaifrysk (Clay Frisian), Wâldfrysk (Wood Frisian), and Súdwesthoeksk (South West Frisian, hereafter referred to as South Frisian). %These varieties present unique phonetic and syntactic features which are less well represented in conventional ASR systems, posing a challenge and an opportunity for multilingual ASR research.
%For instance, the distinct phonological characteristics of Súdwesthoeksk and Wâldfrysk, compared to Standard Frisian (which is similar to Klaaifrysk), could affect the acoustic modeling in ASR systems, leading to higher error rates and less effective communication technologies for these speakers.
% Matt comments:
Frisian and its varieties present a unique and compelling case study for low-resource ASR research due to several factors. As a minority language closely related to Dutch and German, Frisian exists in a complex multilingual environment where code-switching and interference from dominant languages are common. Moreover, as mentioned, Frisian encompasses several distinct dialects, each with its own phonological and lexical variations. This dialectal diversity within a single low-resource language creates additional challenges for ASR. By addressing these challenges, our work has broader implications for other low-resource languages with similar challenges. %, particularly those in multilingual regions or with significant dialectal variation. 
%Success in developing robust ASR for Frisian could provide valuable insights and methodologies applicable to languages facing similar challenges. 
Furthermore, this research contributes to the preservation and technological support of minority languages, an important consideration in the field of speech technology.

In light of the potential for multilingual training to enhance ASR performance across diverse linguistic landscapes~\cite{chen2023improving}, our research, which is inspired by the works of Chen and colleagues  \cite{chen2023improving}, and Liu and colleagues \cite{liu2023hierarchical}, explores the application of multilingual self-supervised models. In that context, our study aims to determine the effectiveness of leveraging multilingual fine-tuning data alongside a targeted strategy (language identification) during fine-tuning, to adapt the advanced SSL models to the specific needs of Frisian and its dialects. %Through this approach, %which is inspired by the works of Chen and colleagues  \cite{chen2023improving}, and Liu and colleagues \cite{liu2023hierarchical}, 
%we seek not only to improve ASR performance for under-resourced language varieties, but also to deepen our understanding of cross-lingual transfer in machine learning. 

%This document is a model and instructions for \LaTeX.
%Please observe the conference page limits. For more information about how to become an IEEE Conference author or how to write your paper, please visit   IEEE Conference Author Center website: https://conferences.ieeeauthorcenter.ieee.org/.

%\subsection{Maintaining the Integrity of the Specifications}

%The IEEEtran class file is used to format your paper and style the text. All margins, 
%column widths, line spaces, and text fonts are prescribed; please do not 
%alter them. You may note peculiarities. For example, the head margin
%measures proportionately more than is customary. This measurement 
%and others are deliberate, using specifications that anticipate your paper 
%as one part of the entire proceedings, and not as an independent document. 
%Please do not revise any of the current designations.

\section{Related Work}
\label{sec:format}

Various approaches have been proposed to improve the performance of low-resource ASR systems. %in the absence of a large amount of labeled data. %One simple, yet effective technique is data augmentation,  which improves the performance by generating new, varied samples from the existing data. Examples of the proposed data augmentation methods for ASR are SpecAugment~\cite{park2019specaugment}, MixSpeech~\cite{meng2021mixspeech} and TTS-based augmentation techniques~\cite{bartelds2023making}. These techniques mainly involve warping or combining features of the input speech as well as using text-to-speech to generate new data samples.
One important line of research focuses on the potential of transferring cross-lingual knowledge from high-resource to low-resource languages~\cite{yadav2022survey}. Recent work has found that multilingual models can be beneficial in improving ASR performance for low-resource languages, as they can learn universal features that are transferable across  languages. Specifically, Liu and colleagues~\cite{liu2023hierarchical} proposed a method for explicit transfer of cross-lingual knowledge at the decoding stage. Their proposed model (which performs multilingual hierarchical Softmax decoding using a Huffman tree) can capture cross-linguistic similarity among units such as characters and phones. %Their method yielded up to 2.7\% character error rate (CER) improvement for Romance, Slavic and Turkic languages. As another example, Yang and colleagues in~\cite{yang2023learning} proposed ASR pathways, a sparse multilingual ASR model that activates language-specific sub-networks, such that the parameters for each language are learned explicitly. Consequently, the overlapping sub-networks enable knowledge transfer to low-resource languages. %They applied their method to English, French, Italian and Dutch and reported an average word error rate (WER) improvement of up to 4.5\% as compared to a dense (non-pruned) baseline.   
However, despite being relatively  effective, these types of cross-lingual transfer approaches introduce further challenges as a result of variability in phonology, grammar, and orthography across different languages~\cite{chen2023improving}.
A promising avenue for improving and optimizing multilingual end-to-end ASR systems is making the models aware of the identity of the languages and dialects that they should be transcribing~\cite{kashiwagi2024rapid}. The most basic method for this is implementing a language identification (LID) module as a pre-processing step before ASR processing~\cite{kwon2023mole}. This, however, results in higher latency~\cite{waters2019leveraging}.  
A possible technique to address this latency issue is jointly performing the two tasks of language identification and speech recognition via multi-task learning \cite{zhang2022streaming}. %The method proposed by Zhang and colleagues \cite{zhang2022streaming} provides an example of this. In their approach, language identification and speech recognition are performed via multi-task learning (jointly modeling LID and ASR).  %They showed that with a 96\% LID accuracy, the WER for seven languages (English, Spanish, Italian, German, Spanish, Chinese and Japanese) remained the same (7.8\%) as in the case where LIDs were provided at the pre-processing step. 
In a related approach, Kwon and Chung \cite{kwon2023mole} implemented a system containing multiple language experts (MoLEs; adapted from Mixture-of-Experts  \cite{you2022speechmoe2} together with a Switch Transformer \cite{fedus2022switch}). This system is then deployed to assign the input sequence (a sentence) to a certain language-specific expert according to the language type, and the language-agnostic experts process it regardless of language. %They applied this method to both higher-resource languages (English, Spanish, and French) and lower-resource languages (Japanese and Chinese). %Their MoLE-based model showed an overall CER improvement of 0.2 to 1.3\% as compared to the vanilla transformer-based architecture.
An alternative strategy involves the technique proposed by Chen and colleagues  \cite{chen2023improving}, where an auxiliary CTC~\cite{graves2012connectionist} objective enables the early encoder layers to focus on language identification, so that, %in a hierarchical manner, 
the later layers can be conditioned on the predicted language. %The method is applied to the FLEURS~\cite{conneau2023fleurs} 102-language ASR dataset and demonstrated up to 1.3\% improvement in WER as compared to their baselines (w2v-bert-51~\cite{chung2021w2v} and mSLAM~\cite{bapna2022mslam} without language identification). 
Inspired by the above-mentioned approaches, in this work, we propose combining multilingual fine-tuning data and language identification for improving ASR for Frisian and its regional varieties.



%Before you begin to format your paper, first write and save the content as a 
%separate text file. Complete all content and organizational editing before 
%formatting. Please note sections \ref{AA} to \ref{FAT} below for more information on 
%proofreading, spelling and grammar.

%Keep your text and graphic files separate until after the text has been 
%formatted and styled. Do not number text heads---{\LaTeX} will do that 
%for you.

%\subsection{Abbreviations and Acronyms}\label{AA}
%Define abbreviations and acronyms the first time they are used in the text, 
%even after they have been defined in the abstract. Abbreviations such as 
%IEEE, SI, MKS, CGS, ac, dc, and rms do not have to be defined. Do not use 
%abbreviations in the title or heads unless they are unavoidable.

%\subsection{Units}
%\begin{itemize}
%\item Use either SI (MKS) or CGS as primary units. (SI units are encouraged.) English units may be used as secondary units (in parentheses). An exception would be the use of English units as identifiers in trade, such as ``3.5-inch disk drive''.
%\item Avoid combining SI and CGS units, such as current in amperes and magnetic field in oersteds. This often leads to confusion because equations do not balance dimensionally. If you must use mixed units, clearly state the units for each quantity that you use in an equation.
%\item Do not mix complete spellings and abbreviations of units: ``Wb/m\textsuperscript{2}'' or ``webers per square meter'', not ``webers/m\textsuperscript{2}''. Spell out units when they appear in text: ``. . . a few henries'', not ``. . . a few H''.
%\item Use a zero before decimal points: ``0.25'', not ``.25''. Use ``cm\textsuperscript{3}'', not ``cc''.)
%\end{itemize}

%\subsection{Equations}
%Number equations consecutively. To make your 
%equations more compact, you may use the solidus (~/~), the exp function, or 
%appropriate exponents. Italicize Roman symbols for quantities and variables, 
%but not Greek symbols. Use a long dash rather than a hyphen for a minus 
%sign. Punctuate equations with commas or periods when they are part of a 
%sentence, as in:
%\begin{equation}
%a+b=\gamma\label{eq}
%\end{equation}

%Be sure that the 
%symbols in your equation have been defined before or immediately following 
%the equation. Use ``\eqref{eq}'', not ``Eq.~\eqref{eq}'' or ``equation \eqref{eq}'', except at 
%the beginning of a sentence: ``Equation \eqref{eq} is . . .''

%\subsection{\LaTeX-Specific Advice}

%Please use ``soft'' (e.g., \verb|\eqref{Eq}|) cross references instead
%of ``hard'' references (e.g., \verb|(1)|). That will make it possible
%to combine sections, add equations, or change the order of figures or
%citations without having to go through the file line by line.

%Please don't use the \verb|{eqnarray}| equation environment. Use
%\verb|{align}| or \verb|{IEEEeqnarray}| instead. The \verb|{eqnarray}|
%environment leaves unsightly spaces around relation symbols.

%Please note that the \verb|{subequations}| environment in {\LaTeX}
%will increment the main equation counter even when there are no
%equation numbers displayed. If you forget that, you might write an
%article in which the equation numbers skip from (17) to (20), causing
%the copy editors to wonder if you've discovered a new method of
%counting.

%{\BibTeX} does not work by magic. It doesn't get the bibliographic
%data from thin air but from .bib files. If you use {\BibTeX} to produce a
%bibliography you must send the .bib files. 

%{\LaTeX} can't read your mind. If you assign the same label to a
%subsubsection and a table, you might find that %Table I has been cross
%referenced as Table IV-B3. 

%{\LaTeX} does not have precognitive abilities. If you put a
%\verb|\label| command before the command that updates the counter it's
%supposed to be using, the label will pick up the last counter to be
%cross referenced instead. In particular, a %\verb|\label| command
%should not go before the caption of a figure or a table.

%Do not use \verb|\nonumber| inside the \verb|{array}| environment. It
%will not stop equation numbers inside \verb|{array}| (there won't be
%any anyway) and it might stop a wanted equation number in the
%surrounding equation.

%\subsection{Some Common Mistakes}\label{SCM}
%\begin{itemize}
%\item The word ``data'' is plural, not singular.
%\item The subscript for the permeability of vacuum $\mu_{0}$, and other common scientific constants, is zero with subscript formatting, not a lowercase letter ``o''.
%\item In American English, commas, semicolons, periods, question and exclamation marks are located within quotation marks only when a complete thought or name is cited, such as a title or full quotation. When quotation marks are used, instead of a bold or italic typeface, to highlight a word or phrase, punctuation should appear outside of the quotation marks. A parenthetical phrase or statement at the end of a sentence is punctuated outside of the closing parenthesis (like this). (A parenthetical sentence is punctuated within the parentheses.)
%\item A graph within a graph is an ``inset'', not an ``insert''. The word alternatively is preferred to the word ``alternately'' (unless you really mean something that alternates).
%\item Do not use the word ``essentially'' to mean ``approximately'' or ``effectively''.
%\item In your paper title, if the words ``that uses'' can accurately replace the word ``using'', capitalize the ``u''; if not, keep using lower-cased.
%\item Be aware of the different meanings of the homophones ``affect'' and ``effect'', ``complement'' and ``compliment'', ``discreet'' and ``discrete'', ``principal'' and ``principle''.
%\item Do not confuse ``imply'' and ``infer''.
%\item The prefix ``non'' is not a word; it should be joined to the word it modifies, usually without a hyphen.
%\item There is no period after the ``et'' in the Latin abbreviation ``et al.''.
%\item The abbreviation ``i.e.'' means ``that %is'', and the abbreviation ``e.g.'' means ``for example''.
%\end{itemize}
%An excellent style manual for science writers is \cite{b7}.

%\subsection{Authors and Affiliations}\label{AAA}
%\textbf{The class file is designed for, but not limited to, six authors.} A 
%minimum of one author is required for all conference articles. Author names 
%should be listed starting from left to right and then moving down to the 
%next line. This is the author sequence that will be used in future citations 
%and by indexing services. Names should not be listed in columns nor group by 
%affiliation. Please keep your affiliations as succinct as possible (for 
%example, do not differentiate among departments of the same organization).

%\subsection{Identify the Headings}\label{ITH}
%Headings, or heads, are organizational devices that guide the reader through 
%your paper. There are two types: component heads and text heads.

%Component heads identify the different components of your paper and are not 
%topically subordinate to each other. Examples include Acknowledgments and 
%References and, for these, the correct style to use is ``Heading 5''. Use 
%``figure caption'' for your Figure captions, and ``table head'' for your 
%table title. Run-in heads, such as ``Abstract'', will require you to apply a 
%style (in this case, italic) in addition to the style provided by the drop 
%down menu to differentiate the head from the text.

%Text heads organize the topics on a relational, hierarchical basis. For 
%example, the paper title is the primary text head because all subsequent 
%material relates and elaborates on this one topic. If there are two or more 
%sub-topics, the next level head (uppercase Roman numerals) should be used 
%and, conversely, if there are not at least two sub-topics, then no subheads 
%should be introduced.

%\subsection{Figures and Tables}\label{FAT}
%\paragraph{Positioning Figures and Tables} Place figures and tables at the top and 
%bottom of columns. Avoid placing them in the middle of columns. Large 
%figures and tables may span across both columns. Figure captions should be 
%below the figures; table heads should appear above the tables. Insert 
%figures and tables after they are cited in the text. Use the abbreviation 
%``Fig.~\ref{fig}'', even at the beginning of a sentence.

%\begin{table}[htbp]
%\caption{Table Type Styles}
%\begin{center}
%\begin{tabular}{|c|c|c|c|}
%\hline
%\textbf{Table}&\multicolumn{3}{|c|}{\textbf{Table Column Head}} \\
%\cline{2-4} 
%\textbf{Head} & \textbf{\textit{Table column subhead}}& \textbf{\textit{Subhead}}& \textbf{\textit{Subhead}} \\
%\hline
%copy& More table copy$^{\mathrm{a}}$& &  \\
%\hline
%\multicolumn{4}{l}{$^{\mathrm{a}}$Sample of a Table footnote.}
%\end{tabular}
%\label{tab1}
%\end{center}
%\end{table}

%\begin{figure}[htbp]
%\centerline{\includegraphics{fig1.png}}
%\caption{Example of a figure caption.}
%\label{fig}
%\end{figure}

%Figure Labels: Use 8 point Times New Roman for Figure labels. Use words 
%rather than symbols or abbreviations when writing Figure axis labels to 
%avoid confusing the reader. As an example, write the quantity 
%``Magnetization'', or ``Magnetization, M'', not just ``M''. If including 
%units in the label, present them within parentheses. Do not label axes only 
%with units. In the example, write ``Magnetization (A/m)'' or ``Magnetization 
%\{A[m(1)]\}'', not just ``A/m''. Do not label axes with a ratio of 
%quantities and units. For example, write ``Temperature (K)'', not 
%``Temperature/K''.


\section{Method}
\label{sec:pagestyle}
%In this section, we first introduce our  fine-tuning and evaluation datasets. Thereafter, we provide details on the the experimental setup and the architecture used for our proposed method. 

\subsection{Data}
\subsubsection{Fine-tuning data}
\label{sssec:subsubhead}
As a first step in our approach, we fine-tune our pre-trained base model with monolingual Common Voice (CV) 17.0 \cite{commonvoice:2020} Frisian data. Specifically, we use the official training split data for this purpose, which consists of about 5.5 hours of validated read speech from 195 different speakers. The source material was presented in Standard Frisian. This model serves as our baseline.  

In a second step, we create multilingual fine-tuning data by adding Common Voice 17.0 data from three other  West Germanic languages, namely Dutch, German and English. We create separate fine-tuning datasets by incrementally adding more languages to the monolingual Frisian dataset. The order in which the languages were added to the fine-tuning data was based on their similarity to Frisian. The similarity was calculated based on %Figure~\ref{fig:similarity}. This figure visualizes
lexical-phonetic distances of Frisian, Dutch, German and English on the basis of the Automated Similarity Judgement Program (ASJP) data \cite{wichmann2010evaluating}, and was adapted from \cite{de2021adapting}. Based on this similarity measure, we first added Dutch (being the most similar to Frisian), then German, and finally English.\footnote{In line with historical developments of Frisian, we also experimented with adding English before German, but this resulted in lower performance compared to only including Frisian and Dutch data.} The audio data for all languages was sampled at 16 kHz. In order to make the multilingual fine-tuning datasets more balanced and prevent bias, the size of the original datasets for Dutch, German and English were each reduced by random sampling to that of the  Frisian dataset (3,921 sentences). Table~\ref{tab:finetuning_data_info} provides an overview of the resulting fine-tuning datasets.


%\begin{figure}[h!]
   %\centering
   %\includegrap%hics[width=0.5\textwidth]%{SLT_2024_Package/bar %chart.pdf}
   %\caption{Composition of %the multilingual fine-%tuning dataset, showing %the proportion of data %from each language %(Frisian, Dutch, English, %and German).}
%   \label{fig:pie}
%\end{figure}


%\begin{figure}[h!]
%   \centering
%   \includegraphics[width=0.5\textwidth]{png2pdf-2.pdf}
%   \caption{Multidimensional scaling visualization of the linguistic distances between Frisian, Dutch, German and English based on the LDND measure from the ASJP database \cite{wichmann2010evaluating}. Figure adapted from \cite{de2021adapting}.}
%   \label{fig:similarity}
%\end{figure}


\begin{table*}[t]
\caption{Datasets used for fine-tuning (subsets from CV 17.0~\cite{commonvoice:2020}).}
\begin{center}
\begin{tabular}{|l|l|c|c|}
\hline
\textbf{Languages} & \textbf{ISO Codes} & \textbf{Duration} & \textbf{Sentences} \\
\hline
Frisian & fy & 5.5h & 3,921 \\
\hline
Frisian, Dutch & fy-nl & 11.0h & 7,842 \\
\hline
Frisian, Dutch, German & fy-nl-de & 16.0h & 11,763 \\
\hline
Frisian, Dutch, German, English & fy-nl-de-en & 22.0h & 15,684 \\
\hline
\multicolumn{4}{l}{}
\end{tabular}
\label{tab:finetuning_data_info}
\end{center}
\end{table*}

%There is no information available about how dialectal the dataset is. However, since the text from which the utterances have been produced seems to be standard, we assume that the data is close to standard Frisian speech.



%\begin{table*}[h]
%    \centering
%    \caption{Training datasets used for fine-tuning (subsets from CV 17.0 ~\cite{commonvoice:2020}).}
%    \begin{tabular}{>{\bfseries} l l r r}
%        \toprule
%        \textbf{Languages} & \textbf{ISO codes} & \textbf{Duration} & \textbf{Number of sentences}  \\
%        \midrule
%         Frisian & fy & 5.5h & 3,921 \\
%         Frisian, Dutch  & fy-nl & 11.0h & 7,842\\
%        Frisian, Dutch, German & fy-nl-de & 16.0h & 11,763 \\
%         Frisian, Dutch, German, English & fy-nl-de-en & 22.0h & 15,684\\
%        \bottomrule
%    \end{tabular}    \label{tab:finetuning_data_info}
%\end{table*}



%\begin{table}[h]
%\centering
%\caption{Table Type Styles}
%\begin{center}
%\begin{tabular}{|c|c|c|c|}
%\hline
%\textbf{Table}&\multicolumn{3}{|c|}{\textbf{Table Column Head}} \\
%\textbf{Table} &\multicolumn{3}{|c|c|c|}{\textbf{Table}} \\
%\cline{1-4} 
%\textbf{Head} & \textbf{\textit{Table column subhead}}& \textbf{\textit{Subhead}}& \textbf{\textit{Subhead}} \\
%\hline
%copy & More & nn & nnn \\
%\hline
%copy & More & nn & nnn \\
%\hline

%\multicolumn{4}{l}{$^{\mathrm{a}}$Sample of a Table footnote.}
%\multicolumn{4}{l}{}
%\end{tabular}
%\label{tab1}
%\end{center}
%\end{table}





%\begin{figure}[H!]
%    \centering
%   \includegraphics[width=\textwidth{Distance.pdf}
%    \caption{Your caption here}
%    \label{fig:wide-figure}
%\end{figure}



%\begin{table}[h]
%    \caption{Multilingual fine-tuning data}
%    \label{tab:ssls}  

%\begin{tabular}{cccc}
%\toprule

%\textbf{Dataset}    & \textbf{Language} & %\textbf{Duration}                                  %                              \\ \midrule

%CV17.0       & Frisian          & 12               %          \\ %\cline{1-3} \cline{5-5} 
%CV17.0   & Dutch          & 12                                                                                                       \\ %\cline{1-3} \cline{5-5} 
%CV17.0      & English         & 24                                                                    %                                              \\ %\cline{1-3} \cline{5-5} 
%CV17.0  & German         & 24                                                                                                                            %                                                \\ %\bottomrule
%\end{tabular}
%\end{table}





%\begin{table*}[h]
    %\centering
    %\caption{SPRAAKLAB~\cite{wieling2023spraaklab} dataset details, consisting of dialectal Frisian speech collected from different regions of %Friesland, with utterances based on both Dutch %and Standard Frisian source texts.}
    %\begin{tabular}{>{\bfseries}l c c c c }
        %\toprule
        %\textbf{Variety} & \textbf{Number of %sentences} &  \textbf{Number of speakers} & %\textbf{Source text language} \\
        %\midrule
        %South Frisian& 103 & 3 & Dutch   \\
        %Clay Frisian & 103 & 2 & Dutch    \\
        %Wood Frisian & 103 & 3 & Dutch   \\
        %\midrule
        %South Frisian  & 103 & 3 & Standard Frisian \\
        %Clay Frisian  &   103 & 2 & Standard Frisian  %  \\
        %Wood Frisian  & 103 & 3 & Standard Frisian   %\\
        
%        \bottomrule
%    \end{tabular}    
%    \label{tab:spraaklab_data_info}
%\end{table*}

%\begin{table*}[t]  % Use table* to span both columns and [t] for top placement
%\caption{SPRAAKLAB~\cite{wieling2023spraaklab} dataset details, consisting of dialectal Frisian speech collected from different regions of Friesland, with utterances based on both Dutch and Standard Frisian source texts.}
%\begin{center}
%\begin{tabular}{|l|c|c|c|}
%\hline
%\textbf{Variety} & \textbf{Number of Sentences} & \textbf{Number of Speakers} & \textbf{Source Text Language} \\
%\hline
%South Frisian & 103 & 3 & Dutch \\
%\hline
%Clay Frisian & 103 & 2 & Dutch \\
%\hline
%Wood Frisian & 103 & 3 & Dutch \\
%\hline
%South Frisian & 103 & 3 & Standard Frisian \\
%\hline
%Clay Frisian & 103 & 2 & Standard Frisian \\
%\hline
%Wood Frisian & 103 & 3 & Standard Frisian \\
%\hline
%\end{tabular}

%\label{tab:spraaklab_data_info}
%\end{center}
%\end{table*}



\subsubsection{Development data}
We used the development split from Common Voice 17.0 as our development dataset. This dataset  contains 3,170 sentences uttered by 237 speakers based on Standard Frisian text. The audio data was sampled at 16 KHz.  
\subsubsection{Evaluation data}
\label{sssec:subsubhead}
In order to evaluate the resulting fine-tuned models, we use two different datasets. First, we use the official Common Voice 17.0 Frisian test split which includes 3,171 sentences of read speech based on Standard Frisian.  This enables us to examine the performance of the models on Standard Frisian speech. Next, we investigate the performance on dialectal speech. In order to collect dialectal Frisian speech, we used the SPRAAKLAB \cite{wieling2023spraaklab} mobile laboratory to collect dialectal speech data from three regions in the province of Friesland, where different dialects are spoken (see Figure~\ref{fig:dialects}). The collected SPRAAKLAB data can be divided into two subsets. %(see Table~\ref{tab:spraaklab_data_info}). 
For the first subset, the speakers were shown a group of sentences in Dutch (the national language of the Netherlands which is taught in schools). This text was translated from an original Frisian story book.\footnote{https://websjop.afuk.frl/frl/winkel/nee-heb-je-ja-kunje-krijgen-het-verhaal-van-de-lytse-yerke/} The speakers were asked to translate each sentence in their head, after which they uttered the sentence in their own regional variety (Clay, Wood, or South Frisian). The utterances were then manually transcribed and used as labels in our evaluation dataset. In the second subset, the participants were shown the original Standard Frisian sentences from the same story book and they uttered them in their own regional variety. The reason for this division is that translating from Dutch text to spoken dialectal Frisian allows the speech to be potentially less constrained by Standard Frisian norms, which may result in more natural dialectal variation. The group of participants comprised of sixteen men, all above the age of 60. We balanced the groups, such that both modalities had an equal number of speakers per region. Consequently, in both groups there were three Wood Frisian speakers, two Clay Frisian speakers and three South Frisian speakers. Both the subset collected based on Dutch text and the subset collected based on Standard Frisian text contains 824 sentences (103 sentences per speaker). All audio recordings were sampled at 16KHz. %, recorded from three Wood Frisian speakers, two Clay Frisian speakers and three South Frisian speakers. 

\begin{figure}[h]
   \centering
   \includegraphics[width=0.5\textwidth]{frisia_final.pdf}
   \caption{Distribution of Frisian dialects spoken in the province of Friesland, the Netherlands. Figure adapted from~\cite{heeringa2005dialect}.} 
   \label{fig:dialects}
\end{figure}

 

%\begin{figure*}[h]
%    \centering
%    \includegraphics[width=\textwidth]{xls-r.pdf}
%    \caption{Architecture of the XLS-R model used as the pre-trained base model in this study. Figure adapted from \cite{conneau2020unsupervised}.}
%    \label{fig:wide-figure}
%\end{figure*}

\subsection{Experimental Setup}
%Our experimental framework utilizes a pre-trained SSL-based model (XLS-R), which has been initially trained on thousands of hours of multilingual speech data. To adapt this model to our  task of recognizing Frisian and its dialects, we make  modifications during the conventional fine-tuning phase.


\subsubsection{Model Architecture}

As our pre-trained base model, we used the XLS-R 1B architecture \cite{babu2021xls}, which contains 1 billion parameters and was trained on 436,000 hours of speech data from 128 languages. This model utilizes a Transformer \cite{vaswani2017attention} architecture with 48 encoder layers, each containing 1,024 hidden units and 16 attention heads. 
%The model employs the Wav2Vec 2.0~\cite{baevski2020wav2vec} objective for self-supervised learning, which optimizes feature extraction by masking spans of the input audio and predicting the latent representations of the masked regions. XLS-R stands out for its robust cross-lingual capability, as its extensive training data ensures strong performance across a wide variety of languages and dialects, including low-resource ones. 
%Table~\ref{tab:data-info} summarizes the information about the hyperparameters used.
%Comment by MATT: 
%As our pre-trained base model, we used the XLS-R 1B architecture [16], which contains 1 billion parameters and was trained on 436,000 hours of speech data from 128 languages. This model utilizes a Transformer architecture with 24 encoder layers, each containing 1,024 hidden units and 16 attention heads. The model employs the Wav2Vec 2.0 [17] objective for self-supervised learning.


\subsubsection{Fine-Tuning Process}
 %we first fine-tuned this model on monolingual Frisian Common Voice 17.0 to obtain the baseline performance.
 For fine-tuning, we froze the feature extractor and only updated the encoder layers. We used the following hyperparameters:
{\begin{itemize}
    \item Learning rate: 0.00008
    \item Batch size: 8 with 16 gradient accumulation steps
    \item Maximum number of training epochs: 50
    \item Loss function: CTC loss
    \item Vocabulary size: 87
    
\end{itemize}}
All experiments were conducted using 16-bit floating point precision on a single NVIDIA A100 GPU. We used a staged approach for fine-tuning:
\begin{itemize}
    \item \textbf{Monolingual baseline:} We initially fine-tuned the model using only the Common Voice 17.0 Frisian dataset to establish the baseline performance.
    \item \textbf{Incremental multilingual integration:} We progressively introduced additional languages (Dutch, German, and English) to the fine-tuning data. The order of language addition was based on their linguistic proximity to Frisian, determined by the LDND distances. 
    In other words, after starting with the model based only on Frisian fine-tuning data, a second model was fitted with Frisian and Dutch fine-tuning data. The third model was fitted with Frisian, Dutch and German fine-tuning data, and the final model was fitted using  fine-tuning data from all four languages. To prevent bias towards higher-resource languages, we down-sampled the data from Dutch, German, and English to match the number of sentences available in the Frisian data.
    
    %MATT comemnts: 
%We progressively introduced additional languages (Dutch, German, and English) to the fine-tuning data. The order of language addition was based on their linguistic proximity to Frisian, determined by the LDND distances. This analysis revealed that Dutch was closest to Frisian, followed by German, and then English. To prevent bias towards higher-resource languages, we down-sampled the data from Dutch, German, and English to match the number of sentences available in the Frisian data
    \item \textbf{LID token integration:} To make the model aware of the language it should transcribe, we included language identification in the multilingual models. %We examine the effect of leveraging auxiliary language identification (LID) on ASR performance in the three models where multilingual fine-tuning data (Frisian-Dutch, Frisian-Dutch-German, Frisian-Dutch-German-English) was used. 
    We implemented this %in a data preparation step 
    by adding an LID token at the beginning of each target transcription. This approach allows the model to learn to recognize the language and adjust its processing based on the language context~\cite{waters2019leveraging}.   
%MATT comments:
%language identification information in the multilingual models (Frisian-Dutch, Frisian-Dutch-German, Frisian-Dutch-German-English). We implemented this by adding an LID token at the beginning of each target transcription during data preparation. This approach allows the model to learn to recognize the language and adjust its processing based on the language context [6].
\end{itemize}
% uncomment this block if there is enough space at the end:
%These modifications were intended to equip the model with the necessary capabilities to effectively handle a multilingual environment, thereby potentially improving its accuracy and reliability in applications involving Frisian and its dialects.

%\begin{table}[h]
%    \centering
%    \caption{Experimental setup and hyperparameters.}
%    \begin{tabular}{>{\bfseries}l c c c}
%        \toprule
%        \textbf{Parameter} & \textbf{Value}  \\
%        \midrule
%        Per device training batch size & 8   \\
%        Learning rate & 0.00008 \\
%        Warm-up ratio & 0.1   \\
%        Warm-up steps & 1000   \\
%        Gradient accumulation steps & 16   \\
%        FP16 & True   \\
%        Adam beta2 & 0.98   \\
%        Maximum number of training epochs & 50   \\
%        Weight decay &  0.005  \\
        
%        \bottomrule
%    \end{tabular}    
%    \label{tab:data-info}
%\end{table}

%\begin{table}[h]  % Use [h] to specify placement
%\caption{Experimental setup and hyperparameters.}
%\begin{center}  % Center the table
%\begin{tabular}{|l|c|}
%\hline
%\textbf{Parameter} & \textbf{Value} \\
%\hline
%Per device training batch size & 8 \\
%\hline
%Learning rate & 0.00008 \\
%\hline
%Warm-up ratio & 0.1 \\
%\hline
%Warm-up steps & 1000 \\
%\hline
%Gradient accumulation steps & 16 \\
%\hline
%FP16 & True \\
%\hline
%Adam beta2 & 0.98 \\
%\hline
%Maximum number of training epochs & 50 \\
%\hline
%Weight decay & 0.005 \\
%\hline
%\end{tabular}
%\label{tab:data-info}
%\end{center}  % End center environment
%\end{table}

%\begin{table*}[h]
    %\centering
    %\caption{The impact of using multilingual %fine-tuning data on standard test data . %WER scores are only based on Frisian (CV %17.0) test data.}
    %\begin{tabular}{>{\bfseries}  c  l c   c}
        %\toprule
        
        %\textbf{SSL features} & \textbf{Fine-%tuning language(s)} &
        %\textbf{Dev WER} & \textbf{Test WER }  %\\
        %\midrule
        %xls-r-1b  & fy        & 13.4   & 14.2  %\\
        %xls-r-1b  & fy-nl        & 13.2   & %13.6  \\
        %xls-r-1b & fy-nl-de &  \textbf{12.6} & %\textbf{13.1}\\
        %xls-r-1b  & fy-nl-en     & 14.0   &  14.2   \\
        %xls-r-1b  & fy-nl-de-en  & 12.9  & %13.4   \\
        
%        \bottomrule
%    \end{tabular}    
%    \label{tab:data-info-1}
%\end{table*}


\begin{table*}[htbp]  % Use [htbp] for better placement options
\caption{The impact of using multilingual fine-tuning data on standard test data. WER scores are only based on Frisian (CV 17.0) test data.}
\begin{center}  % Center the table content
\begin{tabular}{|l|c|c|}
\hline
 \textbf{Fine-tuning language(s)} & \textbf{Dev WER} & \textbf{Test WER} \\
\hline
 fy        & 13.4   & 14.2  \\
\hline
 fy-nl     & 13.2   & 13.6  \\
\hline
 fy-nl-de  &  \textbf{12.6} & \textbf{13.1} \\
\hline
fy-nl-de-en & 12.9  & 13.4   \\
\hline
\end{tabular}
\label{tab:data-info-1}
\end{center}  % End of center environment
\end{table*}


\begin{table*}[htbp]  % Use [htbp] for better placement options
\caption{The impact of including language identification tokens during fine-tuning on the WER of models fine-tuned on multilingual data. WER scores are only based on CV 17.0 Frisian test data. Similarly, we only report LID recall for Frisian since we only test on Frisian.}
\begin{center}  % Center the table content
\begin{tabular}{|l|c|c|c|}
\hline
\textbf{Fine-tuning languages} & \textbf{LID recall} & \textbf{Dev WER} & \textbf{Test WER} \\
\hline
fy-nl   & - & 13.2 & 13.6 \\       
\hline
 fy-nl + LID & 99.7 & 12.8 & 13.1 \\
\hline
 fy-nl-de & - & 12.6 & 13.1 \\
\hline
 fy-nl-de + LID & 99.3 & \textbf{12.6} & \textbf{13.1} \\
\hline
fy-nl-de-en & - & 12.9 & 13.4 \\
\hline
fy-nl-de-en + LID & 99.4 & 13.0 & 13.2 \\
\hline
\end{tabular}
\label{tab:lid_impact}
\end{center}  % End of center environment
\end{table*}





%\begin{table*}[h!]
%    \centering
%    \caption{The impact of using multilingual fine-tuning data and language identification on  dialectal Frisian test data. Two WERs are shown, the subscripts denote the language in which the original sentences were presented (SF: Standard Frisian; D: Dutch). }
    %\begin{tabular}{>{\bfseries}  c l c c c c }
    %    \toprule
        
    %    \textbf{SSL features} & \textbf{Fine-tuning  language(s)} & \ \textbf{LID$_\textrm{SF}$ recall} & \textbf{LID$_\textrm{D}$ recall} & \textbf{WER$_\textrm{SF}$} & \textbf{WER$_\textrm{D}$} \\
    %    \midrule
    %     xls-r-1b  & fy   &  - & -  &  25.1 & 26.0 \\
    %     \midrule
    %     xls-r-1b  & fy-nl & - & - & 27.0 & 26.2 \\
    %    xls-r-1b  & fy-nl + LID &97.5 & 99.3&  25.1 & 25.2 \\
    %    \midrule
    %    xls-r-1b  & fy-nl-de   & - & - & 25.6 & 26.3 \\
    %    xls-r-1b  & fy-nl-de + LID &95.5 & 98.5  & \textbf{24.1} & 25.4\\
    %    \midrule
    %   xls-r-1b  & fy-nl-de-en  & -  & - & 26.2 & 25.9 \\
    %    xls-r-1b  & fy-nl-de-en + LID & 87.3& 91.6& 24.9 & \textbf{25.1}\\

        
        


        
    %    \bottomrule
    %\end{tabular}    
    %\label{tab:data-info-2}
%\end{table*}



%\begin{table*}[h!]
    %\centering
    %\caption{The impact of including language %identification tokens during fine-tuning %on the WER of models fine-tuned on %multilingual data. WER scores are only %based on CV 17.0 Frisian test data. %Similarly, we only report LID recall for %Frisian since we only test on Frisian.}
    %\begin{tabular}{>{\bfseries} c   l c c c   %c}
        %\toprule
        
        %\textbf{SSL features} & \textbf{Fine-%tuning  languages}   & \textbf{LID %recall} & \textbf{Dev WER} & %\textbf{Test WER}  \\
        %\midrule
         %xls-r-1b  & fy-nl   & - & 13.2 & 13.6  %\\       
        %xls-r-1b  & fy-nl + LID &  99.7  & %12.8 & 13.1\\

        
        %\midrule
         %xls-r-1b  & fy-nl-de     & -  & 12.6 %& 13.1 \\
         %xls-r-1b  & fy-nl-de + LID    & 99.3 %& \textbf{12.6}  & \textbf{13.1}\\

         %\midrule
         %xls-r-1b  & fy-nl-en    & -  & 12.6 & 13.1 \\
         %xls-r-1b  & fy-nl-en + LID    & ? &  & ?\\

        %\midrule
        %xls-r-1b  & fy-nl-de-en     &  
 %- &12.9 & 13.4\\
         %xls-r-1b  & fy-nl-de-en + LID & 99.4   %& 13.0 & 13.2\\

%        \bottomrule
        
%    \end{tabular}    
%    \label{tab:lid_impact}
%\end{table*}


%\begin{table*}[htbp]  % Use [htbp] for better placement options
%\caption{The impact of including language identification tokens during fine-tuning on the WER of models fine-tuned on multilingual data. WER scores are only based on CV 17.0 Frisian test data. Similarly, we only report LID recall for Frisian since we only test on Frisian.}
%\begin{center}  % Center the table content
%\begin{tabular}{|c|l|c|c|c|}
%\hline
%\textbf{SSL features} & \textbf{Fine-tuning languages} & \textbf{LID recall} & \textbf{Dev WER} & \textbf{Test WER} \\
%\hline
%xls-r-1b  & fy-nl   & - & 13.2 & 13.6 \\       


%\hline
%xls-r-1b  & fy-nl + LID & 99.7 & 12.8 & 13.1 \\
%\hline
%xls-r-1b  & fy-nl-de & - & 12.6 & 13.1 \\
%\hline
%xls-r-1b  & fy-nl-de + LID & 99.3 & \textbf{12.6} & \textbf{13.1} \\
%\hline
%xls-r-1b  & fy-nl-de-en & - & 12.9 & 13.4 \\
%\hline
%xls-r-1b  & fy-nl-de-en + LID & 99.4 & 13.0 & 13.2 \\
%\hline
%\end{tabular}
%\label{tab:lid_impact}
%\end{center}  % End of center environment
%\end{table*}


\begin{table*}[htbp]  % Use [htbp] for better placement options
\caption{The impact of using multilingual fine-tuning data and language identification on dialectal Frisian test data. Two WERs are shown, the subscripts denote the language in which the original sentences were presented (SF: Standard Frisian; D: Dutch).}
\begin{center}  % Center the table content
\begin{tabular}{|l|c|c|c|c|}
\hline
\textbf{Fine-tuning languages} & \textbf{LID$_\textrm{SF}$ recall} & \textbf{LID$_\textrm{D}$ recall} & \textbf{WER$_\textrm{SF}$} & \textbf{WER$_\textrm{D}$} \\
\hline
 fy & - & - & 25.1 & 26.0 \\
\hline
 fy-nl & - & - & 27.0 & 26.2 \\
\hline
 fy-nl + LID & 97.5 & 99.3 & 25.1 & 25.2 \\
\hline
 fy-nl-de & - & - & 25.6 & 26.3 \\
\hline
 fy-nl-de + LID & 95.5 & 98.5 & \textbf{24.1} & 25.4 \\
\hline
fy-nl-de-en & - & - & 26.2 & 25.9 \\
\hline
 fy-nl-de-en + LID & 87.3 & 91.6 & 24.9 & \textbf{25.1} \\
\hline
\end{tabular}
\label{tab:data-info-2}
\end{center}  % End of center environment
\end{table*}


%In this section, we report and discuss the results of our experiments.

%\textbf{Monolingual vs.~ multilingual fine-tuning data:}
%We report word error rate (WER (\%)) for three different models and compare their performance with our baseline. In Table~\ref{tab:data-info-1}, the WER is reported for Common Voice 17.0 development and test sets. Compared with the model fine-tuned on monolingual Frisian data, adding both Dutch and German languages to the fine-tuning data appears to improve the performance by  1.1\%. However, adding English data appears to be detrimental, as it instead results in diminished performance (13.4\%). This may be due to the larger distance between English and Frisian compared to the other two languages. %This can also be attributed to the imbalance in the composition of the fine-tuning data in this step, since Frisian accounts for one third of the whole data. 

%\textbf{Language identification:}
%Regarding the impact of explicitly incorporating a LID token in the input utterances, we observe only minor improvements in WER in the CV 17.0 experiments with one, two and three additional languages (Frisian-Dutch,  Frisian-Dutch-German, and Frisian-Dutch-German-English), as detailed in Table~\ref{tab:lid_impact}). The best performance on Frisian was achieved with the multilingual model including Frisian, Dutch and German data, regardless of the use of LID tokens. 

%However, a more pronounced effect of LID tokens was observed when evaluating on the dialectal SPRAAKLAB data. Here, the inclusion of LID tokens led to a reduction in WER of approximately 1\% (see Table~\ref{tab:data-info-2}). The greater absolute benefit of LID in this case may be due to the relatively higher WER for this dataset. 
%Language identification accuracy was high (x \% for Frisian-Dutch model and x\% for Frisian-Dutch-English model), . and the model fine-tuned on Frisian and Dutch with language ID proved to be the second best model, achieving a 14.6\% WER on the CV17.0 evaluation dataset. This is contrary to our assumption provoked by similar works such as~\cite{chen2023improving}, where providing language identity information has helped improve ASR performance. This can be explained by considering that in similar work, predictions of the latter encoder are conditioned on the LID, while in our models, LID tokens are predicted by the models.

%\textbf{Standard vs.~dialectal speech:}
%The final part of our study evaluates the models on dialectal speech using the SPRAAKLAB data to compare their performance on standard versus dialectal speech (see Table~\ref{tab:data-info-2}). All models were tested on datasets with Frisian and Dutch stimuli and compared against a baseline. As expected, the models performed worse on dialectal data, indicating that Common Voice data is closer to Standard Frisian. The higher performance on the Common Voice test set could also be due to its similarity to its training subset, unlike the more varied SPRAAKLAB data. Furthermore, the positive effect of adding Dutch and German to the fine-tuning data was consistent with previous results on standard speech, but only when language identification (LID) tokens were included. Lastly, models performed slightly better on data with Standard Frisian stimuli compared to Dutch stimuli, suggesting that Dutch texts may introduce more regional variability in Frisian than Standard Frisian texts.
%The final part of our study involves evaluating the models on dialectal speech. In order to compare the performance of our models on standard and dialectal speech, we evaluate the models using the SPRAAKLAB  data (see Table~\ref{tab:data-info-2}). We evaluate all models on the datasets with Frisian and Dutch stimuli and compare their performance with our baseline. As expected, all of the models showed poorer performance on dialectal data, which suggests that the Common Voice data is relatively close to Standard Frisian. The higher performance on the Common Voice test set may also be attributed to the fact that CV test dataset is more similar to its training subset than the SPRAAKLAB data, regardless of the dialect of its speakers. Moreover, we observed that the beneficial effect of adding Dutch and German to the fine-tuning data is mostly consistent with the previous experiments on standard speech, but only in combination with LID and not without. Additionally, the models perform slightly better on the data with Standard Frisian stimuli than on the data with Dutch stimuli. This suggests that using Dutch texts likely allows for more regional variability in Frisian than using standard Frisian texts.


\section{Results and Discussion}
\label{sec:typestyle}
In this section, we report and discuss the results of our experiments.

\textbf{Monolingual vs.~ multilingual fine-tuning data:}
We report word error rate (WER (\%)) for three different models and compare their performance with our baseline. In Table~\ref{tab:data-info-1}, the WER is reported for Common Voice 17.0 development and test sets. Compared with the model fine-tuned on monolingual Frisian data, adding both Dutch and German languages to the fine-tuning data appears to improve the performance by  1.1\% (a relative reduction in error of about 7.5\%). However, adding English data appears to be detrimental, as it instead results in diminished performance (13.4\%). This may be due to the larger distance between English and Frisian. %This can also be attributed to the imbalance in the composition of the fine-tuning data in this step, since Frisian accounts for one third of the whole data. 

\textbf{Language identification:}
We observe only minor improvements in WER of the LID addition in the CV 17.0 experiments with one, two, and three additional languages (Frisian-Dutch,  Frisian-Dutch-German, and Frisian-Dutch-German-English), as detailed in Table~\ref{tab:lid_impact}. The best performance for Frisian was achieved with the multilingual model including Frisian, Dutch and German data, regardless of the use of LID tokens. However, a more pronounced beneficial effect of LID tokens was observed when evaluating using the dialectal SPRAAKLAB data. Here, the inclusion of LID tokens led to a reduction in WER of approximately 1\% (see Table~\ref{tab:data-info-2}). The greater benefit of LID in this case may be due to the relatively higher WER for this dataset. %Language identification accuracy was high (x \% for Frisian-Dutch model and x\% for Frisian-Dutch-English model), . and the model fine-tuned on Frisian and Dutch with language ID proved to be the second best model, achieving a 14.6\% WER on the CV17.0 evaluation dataset. This is contrary to our assumption provoked by similar works such as~\cite{chen2023improving}, where providing language identity information has helped improve ASR performance. This can be explained by considering that in similar work, predictions of the latter encoder are conditioned on the LID, while in our models, LID tokens are predicted by the models.
\newline
\textbf{Standard vs. dialectal speech:}
%The final part of our study involves evaluating the models on dialectal speech. 
To compare the performance of our models on standard and dialectal speech, we evaluate the models using the SPRAAKLAB  data (see Table~\ref{tab:data-info-2}). We evaluate all models on the datasets with Frisian and Dutch stimuli and compare their performance with our baseline. As expected, all of the models showed poorer performance on dialectal data, which suggests that the Common Voice data is relatively close to Standard Frisian. The higher performance on the Common Voice test set may also be attributed to the fact that CV test dataset is more similar to its training subset than the SPRAAKLAB data, regardless of the dialect of its speakers. Moreover, we observed that the beneficial effect of adding Dutch and German to the fine-tuning data is mostly consistent with the previous experiments on standard speech, but only in combination with LID and not without. Additionally, the models perform slightly better on the data with Standard Frisian stimuli than on the data with Dutch stimuli. This suggests that using Dutch texts (which need to be translated) likely allows for more regional variability in Frisian than using standard Frisian texts.

%Matt's comments: 
%if space permits in IV we can include a more detailed error analysis in which we detail types of errors the model makes on dialectal speech versus standard Frisian w examples of common mistranscriptions and discuss potential reasons for these errors (e.g., phonetic similarities, influence of Dutch).

%Also: add a couple sentences discussing the broader implications for ASR in multilingual environments with closely related languages. -- Or maybe that goes int the con?

\section{Conclusion}
\label{sec:print} 
In this paper, we studied the impact of using multilingual fine-tuning data and language identification  %for implementing 
in an ASR model for Frisian. %for the task of automatic speech recognition for Frisian. 
We implemented %\footnote{https://github.com/Riha1992/Frisian-ASR} 
the models by incrementally adding more languages from three West Germanic languages %(Dutch, German, and English)
and incorporating LID tokens at the input. %within the input utterances for language identification. 
We observed that adding Dutch and German helps Frisian ASR performance. Similarly, including language identification information appears to have an additional marginal positive effect. % on ASR performance.
We also %evaluated our models on standard and dialectal speech, showing 
showed that the models performed better on standard speech than dialectal speech. Moreover, %the models performed slightly better on speech read from Standard Frisian texts than speech that had to be translated from Dutch texts, 
the experiments indicated that speech is more ``dialectal'' when %dialectal speech is more likely to be 
elicited by \textit{not} presenting texts in the standard language. This may have implications for developing ASR systems for minority languages, as performance estimations on the basis of test sets which use stimuli presented in the standard language may underestimate the real-life performance when there is much dialect variation. From a broader perspective, our findings highlight the importance of incorporating shared features among languages in multilingual environments and the potential of context-aware modeling for improving generalization and robustness in ASR systems.
%In the future we will further investigate the effect of language-relatedness in choosing multilingual fine-tuning data. Furthermore, we intend to collect more dialectal data  to assess the impact of adding this data to the fine-tuning stage of the model.

















%\begin{figure}[t]
%  \centering
%  \includegraphics[scale=3, width=1\linewidth]{xls-r.pdf}
%  \caption{Wav2Vec2-XLSR. The figure from \cite{baevski2020wav2vec}.}
%  \label{fig:xlsr}
%\end{figure}




%The paper title (on the first page) should begin 1.38 inches (35 mm) from the
%top edge of the page, centered, completely capitalized, and in Times 14-point,
%boldface type.  
%\textbf{The authors' name(s) and affiliation(s) must not be included in the initial version of the paper submitted for blind review.
%}If a paper is accepted, in the final camera ready-version, the authors' name(s) and affiliation(s) appear below the title in capital and lower case letters. 
%Papers with multiple authors and affiliations may %require two or more lines for this information. 
% % \label{sec:results}
% This section presents the evaluation of our models across various configurations, highlighting the impacts of multilingual fine-tuning and language identification tokens on ASR performance.

% \subsection{Performance Metrics}
% \label{sec:performance_metrics}
% We report the WER for each model configuration. Table~\ref{tab:data-info-1} provides an  overview of these metrics.



% %\subsection{Statistical significance}
% %To validate the statistical significance of the observed differences in performance metrics, we conducted one-way ANOVA tests. The analysis revealed that the improvements in WER when adding Dutch and German to the training data are statistically significant (p $<$ 0.05). Conversely, the addition of English did not produce a statistically significant change (p $>$ 0.05), suggesting that its linguistic distance may not contribute positively to the model's learning process.


% \subsection{Performance Analysis}
% \label{sec:performance_analysis}

% \textbf{Monolingual vs.~Multilingual Fine-Tuning Data:}
% We observed distinct performance trends when comparing the ASR models trained on monolingual data against those trained on multilingual data. Table~\ref{tab:data-info-1} presents the Word Error Rate (WER) for models under different training configurations.

% Figure~\ref{fig:performance_comparison} illustrates the WER for different configurations. We found that adding Dutch and German significantly improved the ASR performance on Frisian (p < 0.05), as confirmed by one-way ANOVA tests. These languages, being linguistically closer to Frisian, likely provided more relevant phonetic and linguistic diversity, enhancing the model's robustness.

% In contrast, adding English data did not yield a statistically significant improvement (p > 0.05). This might be attributed to the larger phonetic and linguistic distance from Frisian, which could introduce noise rather than beneficial variance.

% \subsection{Error Analysis}
% \label{sec:error_analysis}
% An error analysis reveals the types of errors most affected by the inclusion of LID tokens and additional languages. Common errors include misrecognition of specific phonemes that are distinctive in Dutch and German but not in Frisian.

% \subsection{Discussion}
% \label{sec:discussion}
% The findings  show that multilingual fine-tuning with linguistically similar languages like Dutch and German, improves ASR accuracy for the low-resource Frisian language. This suggests that phonetic and linguistic commonalities between closely related languages can be leveraged to enhance model training, a strategy that may be applicable to other minority languages as well.

% Conversely, the inclusion of English did not yield a significant improvement in performance. This outcome highlights the potential challenges of integrating linguistically diverse data, which may introduce non-beneficial variability into the training process. 

% Future work will focus on expanding the range of languages considered, exploring the effects of different language families, and refining the use of language identification tokens to optimize training processes. Additionally, investigating the model's ability to handle dialectal variations within the same language group could provide further insights into building robust multilingual ASR systems.









%The preferred spelling of the word ``acknowledgment'' in America is without 
%an ``e'' after the ``g''. Avoid the stilted expression ``one of us (R. B. 
%G.) thanks $\ldots$''. Instead, try ``R. B. G. thanks$\ldots$''. Put sponsor 
%acknowledgments in the unnumbered footnote on %the first page.

%\section*{References}

%Please number citations consecutively within brackets \cite{b1}. The 
%sentence punctuation follows the bracket \cite{b2}. Refer simply to the reference 
%number, as in \cite{b3}---do not use ``Ref. \cite{b3}'' or ``reference \cite{b3}'' except at 
%the beginning of a sentence: ``Reference \cite{b3} was the first $\ldots$''

%Number footnotes separately in superscripts. Place the actual footnote at 
%the bottom of the column in which it was cited. Do not put footnotes in the 
%abstract or reference list. Use letters for table footnotes.

%Unless there are six authors or more give all authors' names; do not use 
%``et al.''. Papers that have not been published, even if they have been 
%submitted for publication, should be cited as ``unpublished'' \cite{b4}. Papers 
%that have been accepted for publication should be cited as ``in press'' \cite{b5}. 
%Capitalize only the first word in a paper title, except for proper nouns and 
%element symbols.

%For papers published in translation journals, please give the English 
%citation first, followed by the original foreign-language citation \cite{b6}.

%\begin{thebibliography}{00}
%\bibitem{b1} G. Eason, B. Noble, and I. N. Sneddon, ``On certain integrals of Lipschitz-Hankel type involving products of Bessel functions,'' Phil. Trans. Roy. Soc. London, vol. A247, pp. 529--551, April 1955.
%\bibitem{b2} J. Clerk Maxwell, A Treatise on Electricity and Magnetism, 3rd ed., vol. 2. Oxford: Clarendon, 1892, pp.68--73.
%\bibitem{b3} I. S. Jacobs and C. P. Bean, ``Fine particles, thin films and exchange anisotropy,'' in Magnetism, vol. III, G. T. Rado and H. Suhl, Eds. New York: Academic, 1963, pp. 271--350.
%\bibitem{b4} K. Elissa, ``Title of paper if known,'' unpublished.
%\bibitem{b5} R. Nicole, ``Title of paper with only first word capitalized,'' J. Name Stand. Abbrev., in press.
%\bibitem{b6} Y. Yorozu, M. Hirano, K. Oka, and Y. Tagawa, ``Electron spectroscopy studies on magneto-optical media and plastic substrate interface,'' IEEE Transl. J. Magn. Japan, vol. 2, pp. 740--741, August 1987 [Digests 9th Annual Conf. Magnetics Japan, p. 301, 1982].
%\bibitem{b7} M. Young, The Technical Writer's Handbook. Mill Valley, CA: University Science, 1989.
%\bibitem{b8} D. P. Kingma and M. Welling, ``Auto-encoding variational Bayes,'' 2013, arXiv:1312.6114. [Online]. Available: https://arxiv.org/abs/1312.6114
%\bibitem{b9} S. Liu, ``Wi-Fi Energy Detection Testbed (12MTC),'' 2023, gitHub repository. [Online]. Available: https://github.com/liustone99/Wi-Fi-Energy-Detection-Testbed-12MTC
%\bibitem{b10} ``Treatment episode data set: discharges (TEDS-D): concatenated, 2006 to 2009.'' U.S. Department of Health and Human Services, Substance Abuse and Mental Health Services Administration, Office of Applied Studies, August, 2013, DOI:10.3886/ICPSR30122.v2
%\bibitem{b11} K. Eves and J. Valasek, ``Adaptive control for singularly perturbed systems examples,'' Code Ocean, Aug. 2023. [Online]. Available: https://codeocean.com/capsule/4989235/tree
%\end{thebibliography}

%\vspace{12pt}
%\color{red}
%IEEE conference templates contain guidance text for composing and formatting conference papers. Please ensure that all template text is removed from your conference paper prior to submission to the conference. Failure to remove the template text from your paper may result in your paper not being published.

\section*{Acknowledgment}
This work was supported by the Provinsje Frysl\^an. We are also grateful to the ILSE project of the Center for Information Technology, University of Groningen, for
providing access to the computing resources utilized in this research.

\newpage
\bibliographystyle{IEEEbib}
\bibliography{strings,refs}

\end{document}
