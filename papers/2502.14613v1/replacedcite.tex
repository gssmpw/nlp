\section{Related Work}
\textbf{Evaluating and Interpreting Summarization.}
Recent work suggests that LLMs match or surpass human performance in news summarization____.
However, traditional evaluation protocols remain unreliable especially for LLM-generated summaries____.
This spurred interest in analyzing summarization model behavior.
Studies found biases towards content near the beginning/end of documents____.
Others analyze training dynamics of summarization models to identify when skills like content selection are learned____.
Extract-then-abstract pipelines____ aim for interpretable text summarization but this interpretability is limited to the document-level____.
Our research complements prior work by providing a \emph{global interpretation} of what topics LLMs consider important through the lens of text summarization.

\textbf{Explainable Topic Modeling.}
Our analysis method draws inspiration from the interpretable topic modeling literature.
While classical topic models such as LDA____ have long been used to explain latent themes in text corpora, they are often difficult to interpret____.
Recent work showed that LLMs can effectively be used to generate natural language descriptions of latent themes in text mining, clustering and concept induction workflows____.
Our framework uses LLMs to describe salient summary content in form of information-seeking QUDs.
The use of QUDs as a representation of information units was shown successful in a wide range of tasks____.