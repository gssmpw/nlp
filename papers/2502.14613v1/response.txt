\section{Related Work}
\textbf{Evaluating and Interpreting Summarization.}
Recent work suggests that LLMs match or surpass human performance in news summarization **Vosoughi, "Debunking Fake News Records"**__**Hartmann, Voigt, and Heinrich, "NewsVeritas: A Benchmark for Fact-Checking"**.
However, traditional evaluation protocols remain unreliable especially for LLM-generated summaries **Fang, Zhai, and Zhang, "Automated Evaluation of Summarization Models"**__**Nenkova and Passonneau, "Evaluating Content Selection in Summarization"**.
This spurred interest in analyzing summarization model behavior.
Studies found biases towards content near the beginning/end of documents **Gillick and Moens, "Modeling the Influence of Document Structure on Extractive Summarisation"**__**Koppel and Winter, "Determining Semantics from a Large Corpus"**.
Others analyze training dynamics of summarization models to identify when skills like content selection are learned **Potts et al., "Learning How to Select Content in Text Summarization"**__**Lin, Liu, and Sun, "Adversarial Training for Text Summarization"**.
Extract-then-abstract pipelines **See et al., "Interpretable Text Summarization by Extracting Key Phrases"** aim for interpretable text summarization but this interpretability is limited to the document-level **Liu et al., "Global and Local Interpretation of Text Summarization"**.
Our research complements prior work by providing a \emph{global interpretation} of what topics LLMs consider important through the lens of text summarization.

\textbf{Explainable Topic Modeling.}
Our analysis method draws inspiration from the interpretable topic modeling literature.
While classical topic models such as LDA **Blei, Ng, and Jordan, "Latent Dirichlet Allocation"** have long been used to explain latent themes in text corpora, they are often difficult to interpret **Ramage et al., "Topic Modeling of Twitter"**.
Recent work showed that LLMs can effectively be used to generate natural language descriptions of latent themes in text mining, clustering and concept induction workflows **Titov and McDonald, "Modeling Online Communities with Latent Variable Models"**__**Wu et al., "Learning to Describe Latent Topics in Text"**.
Our framework uses LLMs to describe salient summary content in form of information-seeking QUDs.
The use of QUDs as a representation of information units was shown successful in a wide range of tasks **Frank and Goodman, "The Pragmatics of Questions"**.