\section{Experiments}

To assess the performance of our system, in context of a \ac{DMS} as previously described, we conducted a series of experiments. First, we aim to quantify the accuracy of the decentralized estimation of the global property: the geometric center. Additionally, we investigate the system's robustness, which we categorize into two distinct aspects: fault tolerance and noise tolerance. Fault tolerance pertains to the system's ability to maintain functionality when individual components fail or are removed, while noise tolerance evaluates its resilience to variations or noise in sensor signals. Lastly, we explored the scalability capabilities of the model by testing its performance across sensor arrays of varying sizes. %

\subsection{Performance Evaluation}
\label{ss:perfeval}

In this experiment, we compared the performance of two models, trained using calibrated and uncalibrated data, respectively, as detailed in \cref{sectionNNmodel}. Both models were tested on their respective datasets, and the average estimation provided of individual agents was computed with the ground truth. \Cref{fig:comparison} shows that both models exhibit an average distance error of $7.19$ mm and $6.79$ mm respectively.

This result highlights that the system can effectively estimate the \ac{GC} with a high degree of accuracy. Given the coil width of 30~mm and a center-to-center coil spacing of 37.5~mm, achieving a positional error of below 7.2 mm ($\approx$ 0.24 times the width of a coil) showcases the systemâ€™s ability to accurately determine the \ac{GC} at much smaller distances than coil spacing of without relying on it being positioned directly above a single coil. 

The use of uncalibrated data appeared to slightly reduce estimation errors compared to the use of calibrated data. However, after performing statistical testing, the distributions were found not to be statistically significant, with $P= 0.304$.

\begin{figure}[t]
\centerline{\includegraphics[width=0.85\columnwidth]{Figures/Comparison.png}}
\caption{Error distribution of models trained and evaluated with calibrated and uncalibrated data from respective test sets.}
\label{fig:comparison}
\end{figure}

\subsection{Comparison with Centralized Approaches}



To evaluate the performance of the proposed \ac{NCA}-based system, we compare it against a centralized \ac{CNN} architecture. The centralized \ac{NN} processes all sensor readings simultaneously using two consecutive convolutional layers to extract global spatial features, followed by 3 fully connected layers to estimate the object's position. The resulting comparison is shown in \cref{fig:center}, where it can be observed that both the centralized and decentralized approaches perform comparably on calibrated data. Notably, the uncalibrated centralized model exhibits slightly worse performance, potentially due to domain shifts that the architecture cannot accommodate without calibration.

\begin{figure}[t]
\centerline{\includegraphics[width=0.85\columnwidth]{Figures/Comparison_Centralized.png}}
\caption{Box plots of estimation error for Centralized and NCA approaches, showing median (line), inter-quartile range (box), and range (whiskers)}
\label{fig:center}
\end{figure}


\subsection{Fault Tolerance}

Fault tolerance was evaluated by systematically introducing sensor failures and measuring the system's performance.  Faulty sensors were simulated by replacing their readings with zero, effectively removing their influence on the system's computations. We masked a fault on between $0\%$ to $90\%$ of sensors (rounded down) in increments of $10\%$. 
    The model was then evaluated across $100$ different object locations, each time with a new random selection of faulty sensors to ensure statistical robustness. We measured the distance error between the estimated \ac{GC} and the ground truth, recording both the mean and standard deviation of these errors, the results are shown in \cref{fig:faulty}.

\begin{figure}[t]
\centerline{\includegraphics[width=0.85\columnwidth]{Figures/Fault_Tolerance.png}}
\caption{Mean and standard deviation of estimation error for different percentages of faulty agents.}
\label{fig:faulty}
\end{figure}



\subsection{Noise Tolerance}

The system's noise tolerance was evaluated by introducing Gaussian noise to sensor data at varying levels, ranging from $0\%$ to $100\%$ in increments of $10\%$. The noise magnitude was scaled relative to the sensor's signal strength, simulating real-world conditions such as electronic interference, signal attenuation, or sensor drift. 



For each noise level, 100 trials were conducted, and the mean and standard deviation of the distance error were recorded. As shown in \cref{fig:noise}, the system demonstrates resilience to increasing noise levels, maintaining consistent accuracy at moderate noise intensities and gracefully degrading as noise becomes severe. 

\begin{figure}[t]
\centerline{\includegraphics[width=0.85\columnwidth]{Figures/NoiseTolerance_.png}}
\caption{Mean and standard deviation of estimation error for different noise levels.}
\label{fig:noise}
\end{figure}



\subsection{Scalability}

One of the key advantages of \acp{NCA} is their inherent locality, allowing the same trained model to be applied to networks of varying sizes without retraining. 

To evaluate this property, a model trained on a grid of $8\times8$ sensors was tested on grids ranging from $4 \times 4$ to $100 \times 100$, representing up to 10000 agents. 
Due to hardware limitations, binary synthetic data was used for both training and evaluation. 
Performance was measured in terms of distance errors expressed in tile sizes (the distance between adjacent sensors). \Cref{fig:scale} shows the results of the experiment.

\begin{figure}[t]
\centerline{\includegraphics[width=0.85\columnwidth]{Figures/Scalability_results.png}}
\caption{Mean and standard deviation of estimation error for different sizes of agents network.}
\label{fig:scale}
\end{figure}

The mean distance errors remained consistent across all network sizes. Error metrics did not increase with the addition of more agents, indicating that the model successfully scaled without any degradation in performance. This consistency highlights the effectiveness of \acp{NCA} in maintaining robustness and accuracy, regardless of the network's size.





