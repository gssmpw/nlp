% This must be in the first 5 lines to tell arXiv to use pdfLaTeX, which is strongly recommended.
\pdfoutput=1
% In particular, the hyperref package requires pdfLaTeX in order to break URLs across lines.

\documentclass[11pt]{article}

% Remove the "review" option to generate the final version.
\usepackage[review]{ACL2023}

% Standard package includes
\usepackage{times}
\usepackage{latexsym}
\usepackage{tikz}
\usepackage{hyperref}
\usepackage[edges]{forest}
\usepackage{graphicx}
\usepackage{algorithm}
\usepackage[noend]{algpseudocode}
\algnewcommand{\LeftComment}[1]{\Statex \(\triangleright\) #1}
\usepackage{multicol}
\usepackage{rotating}
\usepackage{tikz}
\usetikzlibrary{trees,shapes,calc}
\usepackage{makecell}
\let\OldMakecell\makecell
\renewcommand{\makecell}[1]{%
    \OldMakecell{\color{.}{#1}} % Use current color context
}
% \setlength{\extrarowheight}{0pt}
% \setlength{\arrayrulewidth}{0.5pt}
% For proper rendering and hyphenation of words containing Latin characters (including in bib files)
\usepackage[T1]{fontenc}
% For Vietnamese characters
% \usepackage[T5]{fontenc}
% See https://www.latex-project.org/help/documentation/encguide.pdf for other character sets

% This assumes your files are encoded as UTF8
\usepackage[utf8]{inputenc}

% This is not strictly necessary, and may be commented out.
% However, it will improve the layout of the manuscript,
% and will typically save some space.
\usepackage{microtype}
\usepackage{amsmath}
% This is also not strictly necessary, and may be commented out.
% However, it will improve the aesthetics of text in
% the typewriter font.
\usepackage{inconsolata}
%\usepackage[margin=0.2in, top=0.2in]{geometry}

\usepackage{titlesec}
\titlespacing{\section}{0pt}{-1pt}{-1pt} %{12pt plus 4pt minus 2pt}{6pt plus 2pt minus 1pt}
\titlespacing{\subsection}{0pt}{-1pt}{-1pt} %{10pt plus 3pt minus 2pt}{5pt plus 2pt minus 1pt}
\titlespacing\subsubsection{0pt}{0pt}{0pt}
% Remove paragraph indentation and set space between paragraphs
\setlength{\parindent}{0pt} % No paragraph indentation
\setlength{\parskip}{6pt}   % Space between paragraphs

% \titlespacing\section{0pt}{0pt}{0pt}
% \titlespacing\subsection{0pt}{0pt}{0pt}
% \titlespacing\subsubsection{0pt}{0pt}{0pt}
% \titlespacing\section{0pt}{5pt}{5pt}
% \titlespacing\subsection{0pt}{5pt}{5pt}
% \titlespacing\subsubsection{0pt}{5pt}{5pt}


% \usepackage[top=1cm, bottom=1cm]{geometry}
\setlength{\abovedisplayskip}{0pt} % Space above equation
\setlength{\belowdisplayskip}{0pt} % Space below equation
\setlength{\abovedisplayshortskip}{0pt} % Space above equations in short paragraphs
\setlength{\belowdisplayshortskip}{0pt} % Space below equations in short paragraphs

\usepackage{mdframed}
\usepackage[textsize=small]{todonotes}

\usepackage{booktabs}
\usepackage{rotating}


\usepackage{tcolorbox}
\usepackage{colortbl}
\usepackage{adjustbox}
\colorlet{lightgray}{White!70!lightgray}
\colorlet{lightblue}{White!10!MidnightBlue}
\newcommand{\cmark}{\ding{51}}
\newcommand{\xmark}{\ding{55}}

\newcommand{\interalia}{\emph{inter alia}}
\newcommand{\zx}[1]{\textcolor{RoyalBlue}{[ZX: #1]}}

%% for making comment
\newcommand{\ignore}[1]{}
\newcommand{\shuai}[1]{\textcolor{blue}{\textbf{[#1 --\textsc{Shuai}]}}}
\newcommand{\kiran}[1]{\textcolor{orange}{\textbf{[#1 --\textsc{Kiran}]}}}

\setlength{\textfloatsep}{5pt} % Space between floats and text
\setlength{\floatsep}{5pt}      % Space between two floats
\setlength{\intextsep}{5pt}     % Space between floats and text when inside text
\makeatletter
\setlength{\@fptop}{0pt} % Set to 0pt to eliminate space
\makeatother
% If the title and author information does not fit in the area allocated, uncomment the following
%
%\setlength\titlebox{<dim>}
%
% and set <dim> to something 5cm or larger.

\title{A Systematic Survey of Automatic Prompt Optimization Techniques}

% Author information can be set in various styles:
% For several authors from the same institution:
% \author{Author 1 \and ... \and Author n \\
%         Address line \\ ... \\ Address line}
% if the names do not fit well on one line use
%         Author 1 \\ {\bf Author 2} \\ ... \\ {\bf Author n} \\
% For authors from different institutions:
% \author{Author 1 \\ Address line \\  ... \\ Address line
%         \And  ... \And
%         Author n \\ Address line \\ ... \\ Address line}
% To start a seperate ``row'' of authors use \AND, as in
% \author{Author 1 \\ Address line \\  ... \\ Address line
%         \AND
%         Author 2 \\ Address line \\ ... \\ Address line \And
%         Author 3 \\ Address line \\ ... \\ Address line}

\author{Kiran Ramnath, Kang Zhou, {\bf Sheng Guan}, {\bf Soumya Smruti Mishra}, {\bf Xuan Qi}, {\bf Zhengyuan Shen}, 
\\ {\bf Shuai Wang}, {\bf Sangmin Woo}, {\bf Sullam Jeoung}, {\bf Yawei Wang}, {\bf Haozhu Wang}, {\bf Han Ding},   
\\ {\bf Yuzhe Lu}, {\bf Zhichao Xu}, {\bf Yun Zhou}, {\bf Balasubramaniam Srinivasan}, {\bf Qiaojing Yan}, {\bf Yueyan Chen}, 
\\ {\bf Haibo Ding}, {\bf Panpan Xu}, \and {\bf Lin Lee Cheong}\\
  Amazon Web Services \\
  % Affiliation / Address line 2 \\
  % Affiliation / Address line 3 \\  
  \parbox[c]{\textwidth}{\texttt{\{raxkiran,zhoukang,shguan,soumish,xuaqi,donshen, wshui,sangminw,sullamij, \\
  yawenwan, haozhuw, handing, yuzhelu, xzhichao, yunzzhou, srbalasu, qiaojiny, yyanc, hbding, xupanpan, lcheong\}@amazon.com}}}
\begin{document}
\maketitle
\begin{abstract}
Since the advent of large language models (LLMs), prompt engineering has been a crucial step for eliciting desired responses for various Natural Language Processing (NLP) tasks. However, prompt engineering remains an impediment for end users due to rapid advances in models, tasks, and associated best practices. To mitigate this, Automatic Prompt Optimization (APO) techniques have recently emerged that use various automated techniques to help improve the performance of LLMs on various tasks. In this paper, we present a comprehensive survey summarizing the current progress and remaining challenges in this field. We provide a formal definition of APO, a 5-part unifying framework, and then proceed to rigorously categorize all relevant works based on their salient features therein. We hope to spur further research guided by our framework. 
\end{abstract}
\section{Introduction}
\label{sec:introduction}
Since \citet{decanlp} cast multi-task NLP as Question Answering, using prompts as inputs has become the standard way to elicit desired responses from Large Language Models (LLMs). Furthermore, LLMs' few-shot learning \cite{fewshot}, instruction-following \cite{instruction-alignment}, and zero-shot reasoning capabilities \cite{zeroshot} have led to a widespread proliferation of prompting tricks for various tasks and model variants. However, LLMs still exhibit unpredictable sensitivity to various factors (explanation of the task \cite{li2023large},ordering \cite{liu2024lost}, stylistic formatting \cite{sclarquantifying}, etc.) causing a performance gap between two prompts that are semantically similar, thereby adding impediments for adoption by end users. Against this backdrop, Black-Box Automatic Prompt Optimization (APO) techniques have emerged that improve task performance via automated prompt improvements. The possess various attractive features - (1) they do not require parameter access on LLMs performing the task, (2) they systematically search through the prompt solution space, and (3) they retain human interpretability of prompt improvements. \ignore{\citet{smart} categorizes two broad directions in APO - Exemplar Optimization (EO, also called In-context learning) and Instruction Optimization (IO).\ignore{\todo{This sounds like the survey paper only focuses on IO? Will that be systematic then as the title is named?}} While \citet{icl-survey} surveyed EO in detail, our survey fills this gap for IO.} In this survey paper, we aim to highlight the advances in the field. Our core contribution is a 5-part APO taxonomy combined with a comprehensive fine-grained categorization of various design choices therein (see Fig. \ref{main-figure}, Tables \ref{tab:comparison_1}, \ref{tab:comparison_2}, \ref{tab:comparison_3} in Appendix). We hope our framework will be informational for new and seasoned researchers alike, enabling further research on open questions. %These approaches employ a wide range of design choices in their setup, and there is a need for a framework to unify these disparate works. 

% 1. Brown et. al showed that LLMs are few shot learners. 
% 2. DecaNLP started casting NLP tasks as Question Answering, and having a single general architecture 
% 3. Since then, crafting instructions in inputs known as prompts have become the standard way to elicit desired responses from LLMs
% 4. There have been numerous studies and best-practices that have evolved for writing the correct prompt to attain good performance on tasks and benchmarks - CoT, few-shot prompting, etc. 
% 5. This is so because there is a gap between the user intent in underspecified prompts and optimizing functionality with the target LLM. The optimal prompt usually needs to take care of several factors such as ordering, delimiters, spacing, etc. in addition to step-by-step instructions
% 6. Add to this, the fact that newer models and tasks keep emerging and along with it, also the guidelines keep changing. Keeping up with this evolving fields is difficult for end users. 
% 7. End users who stand to gain the most from the powers of an LLM are usually domain experts who can use LLMs in the flow of their work, without the need for any special work to do orthogonal to their day-to-day

% As such, given all these hardships associated with manually optimizing prompts, there has been a great deal of research interest in using automated techniques with LLMs to optimize task prompts. In this paper, we provide a unifying framework of major automatic prompt optimization techniques. By doing so, our aim is to 
%\section{Definition and Formulation}


\begin{figure*}[ht] %[htbp]    
\resizebox*{\textwidth}{.66\textheight}
{%
\begin{forest}
for tree={
    grow=east,
    font=\large,
    parent anchor=east,
    anchor=west,
    edge={->, rounded corners},
    edge path={
        \noexpand\path [draw, \forestoption{edge}] (!u.parent anchor) -- ++(3mm,0) |- (.child anchor)\forestoption{edge label};
    },
    inner sep=1mm,
    text width=4cm,
    l sep=10mm,
    text centered,
    align=center,
    rounded corners, % Applies rounded corners to all nodes
    draw=black % Draw border around nodes
},% Balancing children symmetrically
for children={%
    tier/.wrap pgfmath arg={level#1}{level()}, % Ensure nodes align symmetrically
    s sep+=5mm, % Add space between siblings
}
[Prompt optimization anatomy \textsection \ref{anatomy}, rectangle,fill=violet!20,rotate=90,parent anchor=south,text width=7cm, align=c,
    [Iteration depth \textsection \ref{depth}, rectangle, fill=cyan!20, text width=6cm,
        [Variable steps \textsection\ref{variable}, text width=15.22cm,fill=cyan!20],
        [Fixed steps \textsection\ref{fixed}, text width=15.22cm,fill=cyan!20]
    ],
    [Filter and retain \\promising candidates \textsection \ref{filter}, rectangle, fill=pink!25,  text width=6cm,
        [Meta-heuristic ensemble \textsection\ref{metaheuristic}, text width=15.22cm, fill=pink!25],
        [Region-based joint search \textsection\ref{rbjs}, text width=15.22cm, fill=pink!25],
        [Upper confidence bound and variants \textsection\ref{ucb}, text width=15.22cm, fill=pink!25],
        [TopK Greedy Search \textsection\ref{topk}, text width=15.22cm, fill=pink!25],
    ],
    [Candidate prompt \\generation \textsection \ref{candidate}, rectangle, fill=blue!10,  text width=6cm, %[Variational Inference - ]
        [{Program Synthesis \textsection \ref{program}}, text width = 15.22cm,fill=blue!10],
        [Coverage-based \textsection \ref{coverage},fill=blue!10,
            [Ensemble methods \textsection \ref{ensemble}, text width=10cm,fill=blue!10],
            [Mixture of experts \textsection \ref{moe}, text width=10cm,fill=blue!10],
            [Single prompt expansion \textsection \ref{expand}, text width=10cm,fill=blue!10]
        ],
        [Metaprompt design \textsection \ref{metaprompt}, text width = 15.22cm,fill=blue!10],
        [Editing with auxiliary \\trained NN \textsection \ref{nn},fill=blue!10,
            [Generative Adversarial Networks \textsection \ref{gan}, text width=10cm,fill=blue!10],
            [LLM Finetuning \textsection \ref{ft}, text width=10cm,fill=blue!10],
            [Reinforcement Learning \textsection \ref{rl}, text width=10cm,fill=blue!10]
        ],        
        [Heuristic-based \\edits \textsection \ref{heuristic},fill=blue!10,
            [Vocabulary pruning \textsection \ref{prune},fill=blue!10,text width=10cm],   
            [Word / phrase edits \textsection \ref{word}, fill=blue!10, text width=10cm],
            [Genetic Algorithm \textsection \ref{genetic},fill=blue!10, text width=10cm % [LLM edits, text width=4.75cm,fill=blue!10], % [Token-level edits, text width=4.75cm,fill=blue!10]
            ],
            [Monte Carlo Sampling \textsection \ref{mc},fill=blue!10,text width=10 cm]            %[Backtranslation \\Sentence Continuation / Cloze] %[Word / phrase / \\sentence edits],            
        ]
    ], 
    [Inference evaluation \\and feedback \textsection \ref{evaluate}, rectangle, fill=yellow!50, text width=6cm,
        [Human Feedback \textsection \ref{human}, fill=yellow!50, text width=15.22cm],
        [LLM Feedback \textsection \ref{llm-feedback},rectangle, fill=yellow!50,
            [Improving multiple candidates \textsection \ref{multiple}, text width=10cm,fill=yellow!50],
            [Improving single candidate \textsection \ref{single}, text width=10cm,fill=yellow!50]
        ],
        [Numeric score \textsection \ref{score-feedback},rectangle, fill=yellow!50,
            [Negative log-likelihood \textsection\ref{nll}, text width=10cm,fill=yellow!50],
            [Entropy-based \textsection\ref{entropy}, text width=10cm,fill=yellow!50],
            [Reward model score \textsection\ref{reward}, text width=10cm,fill=yellow!50],
            [Task accuracy \textsection\ref{accuracy}, text width=10cm,fill=yellow!50],
        ]
    ],
    [Seed Prompts \textsection \ref{seed}, rectangle, fill=orange!30, text width=6cm,
        [Instruction-induction via LLMs \textsection\ref{induction}, fill=orange!30, text width=15.22cm],
        [Manual Instructions \textsection\ref{manual}, fill=orange!30,text width=15.22cm]
    ]
]
\end{forest}
}
\caption{Taxonomy of Automatic Prompt Optimization} %(enhanced taxonomy in appendix \ref{full-figure})
\label{main-figure}
\end{figure*}

\section{Automatic Prompt Optimization Formulation}
\label{anatomy}
We formalize the process of automatic prompt optimization (APO) as follows. Given a task model $M_{task}$, initial prompt $\rho$ $\in V$, the goal of an APO-system $M_{APO}$ is to obtain the best performing prompt-template $\rho^{opt}$ under a metric $f \in F$ and eval-set $D_{val}$ %an initial prompt $\rho_{init}$
\begin{align}{
\rho^{opt}:= \arg\max_{\substack{\rho \in V}}E_{x \sim D_{val}}[f(M_{task} (\rho \oplus x))]
% \arg\max_{\substack{\rho \in V^*}} 
% \mathop{\mathbb{E}}_{\substack{D_{val}}} \left[ f(M_{\text{task}} (\rho)) \right]
}
\end{align}
This objective function is not tractable for discrete prompt optimization as token-sequence search spaces are combinatorial. Instead, APO techniques follow the general anatomy as described in Algorithm \ref{anatomy-algo} to obtain approximate solutions. 

\begin{algorithm}
\caption{Prompt optimization framework} 
\label{anatomy-algo}
\begin{algorithmic}[1]
\State $P_0 := \{\rho_1, \rho_2, \ldots, \rho_k\}$ \Comment{\textsection\ref{seed}. \text{\color{gray}Seed prompts}}
\State $D_{val} := \{(x_1, y_1)\}_{i=1}^n$ \Comment{\text{\color{gray}Validation set}}
\State $f_1,\ldots,f_m \in F$ \Comment{\textsection\ref{evaluate}. \text{\color{gray}Inference evaluation}}
% \State //Step 2: Iterate till convergence
\For {$t=1,2,\ldots,N$} \Comment{\textsection\ref{depth}. \text{\color{gray}Iteration depth}}
\LeftComment{\textsection\ref{candidate}.  \text{\color{gray}Generate prompt candidates}}
    \State $G_t :=M_{_{APO}}(P, D_{val}, F)$
    % \begin{cases} 
    % $\{M_{_{APO}}(\rho_i)$ \\
    % $\{M_{_{APO}}(\rho_i, D_{val}, F)\}_{i=1}^k$
    % \end{cases}        
    \LeftComment{\textsection\ref{filter}.  \text{\color{gray}Filter and retain candidates}}
    \State $P_t := Select(G_t,  D_{val}, F)$          
    \LeftComment{\textsection\ref{depth}.  \text{\color{gray}{Optionally check for early convergence}}}
    \If{$f_{convergence} \leq \epsilon$}
        \State\textbf{exit} 
    \EndIf
\EndFor
\State \Return $\arg\max_{\substack{\rho \in P_N}} E_{\substack{x \sim D_{val}}}\left[f(M_{task}(\rho \oplus x))\right]$
\end{algorithmic} 
\end{algorithm}
\begin{figure*}[htbp]
    \centering
\includegraphics[width=\textwidth, height=4cm]{system-diagram.png}
\caption{Representative APO system}
\label{fig:system-diagram}
\end{figure*}
\section{Initialize Seed Prompts}
\label{seed}

\subsection{Manual Instructions}
\label{manual}
Several approaches use a seed of manually created instructions that offer interpretable and strong baselines as the basis for further improvement,\textit{inter alia.}, ProteGi \cite{protegi}, GPS \cite{gps}, SPRIG \cite{sprig}. While obtaining quality examples can be costly, APE \cite{ape} \footnote{Note: APE stands for Automatic Prompt Engineer method introduced by \cite{ape}, not to be confused with APO which broadly refers to the entire area of Automatic Prompt Optimization} showed that a few hundred samples are sufficient for further optimization. 

\subsection{Instruction Induction via LLMs}
\label{induction}
\citet{instruction-induction} were the first to propose inducing LLMs to infer human-readable prompts based on a few demonstrations $E$ (see Appendix \ref{appendix:instruction_induction} for prompt). APE \cite{ape} and DAPO \cite{dapo} use the induced seed instructions for further optimization, while MOP \cite{mop} and GPO \cite{gpo} use APE to induce cluster-specific prompts. Apart from demonstrations, SCULPT \cite{sculpt} induced instructions from task-READMEs, while UniPrompt \cite{uniprompt} used LLMs to fill-in structured templates. 

\begin{table*}[ht]% \centering% \small
\rowcolors{2}{gray!15}{white} % Alternating row colors
\resizebox{1\textwidth}{!}{
\begin{tabular}{p{3cm}p{4cm}p{2.5cm}p{3.5cm}p{3.5cm}p{4cm}}%{lccccc} 
\hline
\textbf{Paper} & \textbf{Seed instructions} & \textbf{Iteration depth} & \textbf{Inference evaluation} & \textbf{Candidate generation} & \textbf{Search+filter strategy}\\
\hline
    ProTeGi \cite{protegi} &Manually created & Fixed & LLM feedback + \newline Task accuracy &LLM rewriter & UCB for trees \\
    APE \cite{ape}  &  Instruction induction & Fixed & Task accuracy & N/A & UCB \\
    CRISPO \cite{crispo} &Manually created &Fixed &LLM feedback +\newline Task accuracy &LLM rewriter &TopK selection  \\
    MOP \cite{mop} & Instruction induction & Fixed & Task accuracy & Mixture of experts & Region-based \newline joint search \\
    DSPY \cite{dspy} & Manually created +\newline Instruction induction &Variable & LLM feedback +\newline Task accuracy &Program Synthesis &TopK selection \\
    OPRO \cite{opro} & Manually created &Variable & LLM feedback +\newline Task accuracy &Metaprompt design &TopK selection  \\
    GATE \cite{gate} &Manually created &Variable &Human feedback &LLM rewriter &N/A  \\
    
% ProTeGi \cite{protegi} &Manually created & Fixed & {\parbox[r]{4cm}{  LLM feedback +\\ Task accuracy}} &LLM rewriter & UCB for trees \\
% {ProTeGi \cite{protegi} &Manually created & Fixed & {\makecell{LLM feedback +\\ Task accuracy}} &LLM rewriter & UCB for trees} \\
% APE \cite{ape}  &  Instruction induction & Fixed & Task accuracy & N/A & UCB \\
% CRISPO \cite{crispo} &Manually created &Fixed &\makecell{LLM feedback +\\ Task accuracy} &LLM rewriter &TopK selection  \\
% MOP \cite{mop} & Instruction induction & Fixed & Task accuracy & Mixture of experts & Region-based joint search \\
% DSPY \cite{dspy} & \Gape[0pt][2pt]{\makecell{Manually created +\\ Instruction induction}} &Variable &\Gape[0pt][2pt]{\makecell{LLM feedback +\\ Task accuracy}} &Program Synthesis &TopK selection \\
% OPRO \cite{opro} & Manually created &Variable & \Gape[0pt][2pt]{\makecell{LLM feedback +\\ Task accuracy}} &Metaprompt design &TopK selection  \\
% GATE \cite{gate} &Manually created &Variable &Human feedback &LLM rewriter &N/A  \\
\hline
\end{tabular}
}
\caption{Comparison of some APO techniques under our framework (Tables \ref{tab:comparison_1},\ref{tab:comparison_2},\ref{tab:comparison_3} show full comparison)}
\label{tab:comparison_0}
\end{table*}

\section{Inference Evaluation and Feedback} %\shuai{How about use "and" instad of "+"}
The evaluation step helps identify promising prompt candidates in each iteration. Some methods also use LLM feedback on prompt-response pairs to help generate more prompt candidates. 
\label{evaluate}
\subsection{Numeric Score Feedback}
\label{score-feedback}
% \todo{Can we add a short paragraph here for introducing general numeric score feedback. Before listing specific metrics like accuracy below. It seems also a bit weird that here is empty)}
\subsubsection{Accuracy} 
\label{accuracy}
Using task-specific accuracy metrics is the most straightforward and widespread way of eliciting feedback, i.a., \cite{ape, claps, sprig, dsp}. Classification and MCQ-based QA tasks use exact accuracy, while code-related tasks measure execution accuracy. Text generation tasks (summarization, translation, creative writing) employ flexible metrics like BLEU-N, Rouge-N, Rouge-N-F1, or embedding-based measures such as BERTScore \cite{bert-score} \cite{instruction-induction, pace}.
%A straightforward method of evaluating and eliciting feedback is using a numeric score, often simply the task-accuracy of the candidate prompt. The choice for accuracy is varied and depends on the nature of the task and the benchmark. Exact accuracy is useful for task such as Classification \cite{} or Question Answering with boolean or MCQ options \cite{}. For tasks like Text2SQL or code generation, \cite{}, the accuracy of the executed code is often used. Finally for text generation tasks like summarization, translation, creative writing, etc. \cite{} more flexible metrics like BLEU-N, Rouge-N, RougeN-F1, or embedding-based metrics like BERTScore \cite{BERTSCORE} may be used \cite{I2, PACE}. 

\subsubsection{Reward-model Scores}\label{reward}
Given the limitations of rigid accuracy metrics, some approaches proposed using learned reward models to provide more nuanced evaluations of prompts-response pairs \cite{rlprompt, oirl, prewrite}. OIRL \cite{oirl} trained an XGBoost-based reward model that takes query-prompt embedding pairs as input and predicts whether the prompt will elicit correct answers from the language model and use it to select appropriate prompts for specific queries using a best-of-N strategy. %Through extensive experiments across multiple language models and arithmetic reasoning benchmarks, Prompt-OIRL demonstrates superior performance compared to baseline methods while maintaining cost-effectiveness by eliminating the need for online language model interactions during prompt optimization.
DRPO \cite{drpo} follows an LLM-based reward modeling approach using both predefined and dynamic reward criteria. It first optimizes in-context learning examples $E$, and using that it optimizes the specific task prompt.  %Dynamic rewarding, a novel technique integrated into DRPO, allows flexible reward assignment to detect and rectify alignment weaknesses in the current LLM, such that the overall optimization process gets enhanced. 
%As a two-step optimization approach, firstly, DRPO constructs a universal set of in-context learning examples and optimize their responses to obtain I∗, where dynamic reward criteria applies to individual in-context learning example. Then, with determined optimized in-context learning examples and seed query instances, DRPO uses dynamic reward criteria to find the optimal prompt P∗ for a specific base LLM B, where the reward function is customized for each seed query instance.

\subsubsection{Entropy-based Scores} \label{entropy}
Entropy-based scores evaluate the entire output distribution induced by candidates, as opposed to a single inference instance. They are gradient-free but require access to the entire output probability distribution, something not usually possible with black-box LLMs. CLAPS \cite{claps} leverages the negative incremental cross-entropy of  $\pi_{(x_{i} \oplus v\in V)}$ v/s $\pi_{(x_{i})}$ to identify promising words $v \in V$ to add to the prompt. The topK words are then used as candidate tokens from which to construct candidate prompts. GRIPS \cite{grips} simply added an entropy term to the task-weighted accuracy $-\sum \pi_{\rho}(y) \, ln(\pi_{\rho}(y)) + \frac{1}{|T|}\sum \mathbf{1}(y=\hat{y})$ to prioritize output diversity in potential prompt candidates. 

\subsubsection{Negative Log-likelihood of Output}
\label{nll}
Some approaches like APE, GPS \cite{gps}, PACE \cite{pace} consider the negative log-likelihood (NLL) of token sequences under the target LLM, i.e., $-\log(\pi_{\rho} (y))$. This however requires the log-probabilities to be accessible during the decoding of each token, limiting its applicability. The NLL for ground truth one-hot token-sequence is equivalent to the cross-entropy.  

\subsection{LLM Feedback}
\label{llm-feedback}
A popular paradigm to augment or fully replace numeric scores is to use textual feedback generated by $LLM_{Evaluator}$ \cite{promptagent, adv-icl, sos}. It is versatile because it can evaluate both the response as well as the prompt input. It can directly aid the prompt rewriting process while being flexible to individual tasks as it only needs natural language instructions for general-purpose LLMs as opposed to task-specific handcrafting of metrics. A potential downside is the inference cost incurred due to an additional LLM call. All the LLM feedback approaches provide multiple feedback data and broadly fall into two categories - improving a single prompt candidate versus improving multiple prompt candidates (discussed below, examples in Appendix \ref{appendix:tab_llmaaj}). 

\subsubsection{Improving Single Candidate}
\label{single}
SCULPT \cite{sculpt} introduces a systematic method for tuning long, unstructured prompts by employing a \textbf{hierarchical tree structure} and two-step feedback loops - preliminary assessment and error assessment - to evaluate and correct prompts before and after execution. The feedback updates the hierarchical prompt tree which is then back-synthesized into a new prompt candidate. PACE \cite{pace} applies an \textbf{actor-critic} editing framework to the prompt refinement process itself, allowing for more dynamic and adaptive adjustments.
Overcoming the limitations of optimizing a single metric, CRISPO \cite{crispo} adopts a \textbf{multi-aspect critique-suggestion} meta-prompt to highlight flaws in the generated response across multiple dimensions such as style, precision, and content alignment. Thereafter it leverages detailed, aspect-specific feedback and iteratively updates the prompts. Autohint \cite{hint} summarizes feedback for multiple incorrect inferences via \textbf{hints} to instill improvements into a single prompt candidate.

\subsubsection{Improving Multiple Candidates}
\label{multiple}
\ignore{\textbf{Textgradients:}} ProTeGi \cite{protegi} and TextGrad \cite{textgrad} leverage \textbf{textual “gradients”} to guide the discrete prompt optimization procedure, very similar to the gradient-descent style of continuous prompt optimization approaches. Different from continuous gradient-descent, ProTeGi sampled multiple “gradients” i.e. directions of improvement, and each such “gradient” is used to generate several prompt candidates for evaluation in the next iteration. PromptAgent \cite{promptagent} similarly used an error collection approach to emulate expert-written prompts that consisted of clear sections like “Task description”, “Domain Knowledge”, “Solution Guidance”, “Exception Handling”, “Output Formatting”. \ignore{\textbf{Ensemble learning}:} PREFER \cite{prefer} utilizes a feedback-reflect-refine cycle to aggregate feedback into multiple prompts in an \textbf{ensemble} to improve the model's ability to generalize across various tasks. \ignore{\textbf{Safety score:}} Survival of the Safest (SOS) \cite{sos} added \textbf{safety-score} into a multi-objective prompt optimization framework that used an interleaved strategy to balance performance and security in LLMs simultaneously. To avoid accidentally damaging well-functioning prompts, StraGo \cite{strago} summarized strategic guidance based on both correct and incorrect predictions as feedback. %Compared to single-objective optimization that only focuses on performance metrics, SOS elevates safety standards, thus improving the level of security and alleviating safety concerns in productions. 

% \subsubsection{Reflection:}

% DTG \cite{DTG} also includes noisy information to the prompts in addition to correct information like expert demonstrations, then asks the LLM to deliberate on the prompt to detect errors before generating answers. The method simple in the sense that it does not require expert annotations such as in few-shot prompting. %It's also general because it can be applied to a wide range of tasks.
% Reflexion \cite{Reflexion} leverages LLMs to reflect upon and elaborate on environment feedbacks, such as scalar rewards or test case results, to provide additional signals to iteratively improve performance. Reflexion is stateful by default as it keeps track of the memory from previous iterations, much like episodic memories in reinforcement learning. 
%Both Reflexion and TextGrad leverage LLMs to reflect upon and elaborate on environment feedbacks, such as scalar rewards or test case results, to provide additional signals to iteratively improve performance. While their core ideas are similar, these two papers motivate them with different conceptual frameworks. Reflexion formulate its methodology as verbal reinforcement learning. One critical difference is that Reflexion is stateful by default as it keeps track of the memory from previous iterations, much like episodic memories in reinforcement learning. TextGrad does not take previous experience into account by default, but does provide a “Momentum” option during training, which is equivalent to a memory buffer. 
%Zhengyuan Shen (SCULPT, PREFER, APEER, PACE) 

\subsection{Human-feedback}
\label{human}
A few works also incorporate human feedback, either during compile-time or inference-time in the prompt construction / optimization process. \citet{gate} proposed “Generative Active Task Elicitation” to better capture human preferences. It prompts a language model to interactively ask questions and infer human preferences conditioned on the history of free-form interaction. \citet{bpo-cheng} trained a smaller LLM to optimize input prompts based on user preference feedback, achieving up to 22\% increase in win rates for ChatGPT and 10\% for GPT-4. PROMST \cite{promst} tackles the challenges of multi-step tasks by incorporating human-designed feedback rules and a learned heuristic model. APOHF \cite{apohf} focuses on optimizing prompts using only human preference feedback rather than numeric scores, employing a dueling bandits-inspired strategy to efficiently select prompt pairs for preference feedback, proving effective for tasks like text-to-image generation and response optimization. 

\section{Candidate Prompt Generation}
\label{candidate}
In this step, one or more candidate prompts are generated that are most likely to result in an improvement in a metric of interest $f \in F$. The approaches reviewed below range from simple rule-based edits (sec. \ref{heuristic}) to sophisticated agentic systems that combine with LLM-based evaluations (sec. \ref{llm-feedback}) and various filtering strategies (sec. \ref{filter}). %A general trend observed is that previous approaches relied on prompt generation methods using Masked-Language Models (MLMs), while later methods relied on LLM-based methods as LLM inference became cheaper and more accessible. 

\subsection{Heuristic-based Edits}
\label{heuristic}
Several works proposed heuristic-based mechanisms to make edits to intermediate prompt candidates to generate newer candidates. They range from edits at the word / phrase / sentence-level (either simple rule-based or LLM-generated), or metric-driven incremental search. While these strategies may not result in the most optimal solution, they help in making the discrete prompt optimization problem computationally tractable. 
\subsubsection{Monte Carlo Sampling} 
\label{mc}
ProTeGi \cite{protegi} uses Monte carlo sampling to explore combinatorial discrete solution spaces in an incremental fashion - it samples multiple textual gradients to use to generate prospective candidates, and spawns paraphrases as monte-carlo successors for evaluation.  PromptAgent \cite{promptagent} uses a tree-variant called Monte Carlo Tree Search (MCTS) which consists of 4 steps — Selection, Expansion, Simulation, and Backpropagation (also explained in Sec. \ref{filter}).  %MCTS as a core module to systematically explore the prompt design space. Monte-Carlo based approaches are still heuristic-driven approach, as it makes no guarantees about converging to an optimal solution and depends on random sampling and evaluation-functions to balance exploration-exploitation tradeoffs to sweep through the solution space. 

\subsubsection{Genetic Algorithm} 
\label{genetic}
A significant line of work applies the well-studied genetic algorithms to make discrete edits to texts. The common recipe for several genetic algorithms is 1/ Mutate and 2/ Cross-over components from promising candidates. %Mutation can be carried out at the word / phrase / sentence level using either basic rule-based or LLM operations for edit / swap / delete / paraphrase. 
\textbf{Token mutations:} SPRIG \cite{sprig} and CLAPS perform token-level mutations. SPRIG uses a starting corpus of 300 components grouped into categories like COT, roles, styles, emotions, scenarios, and good properties. It performs add/rephrase/swap/delete, highlighting complementary strengths of optimizing system prompts alongside task-prompts (via methods like ProTeGi) to enhance accuracy across multiple diverse domains, languages, and tasks without needing repeated task-specific optimizations. 

\textbf{LLM-based mutation:} LMEA \cite{lmea}, SOS \cite{sos}, and StraGo \cite{strago} uses mutation prompts with LLMs to overcome the traditional complexity of designing tailored operators for cross-over / mutation. PromptBreeder \cite{prompt-breeder} advocates self-referential improvement of all prompts in the prompt optimization system - Direct Mutation of task prompts, Hypermutation of mutation prompts themselves, Lamarckian Mutation where prompts are reverse-engineered from successful examples (similar to Instruction Induction \citet{instruction-induction}, and finally Crossover and Shuffling to improve diversity of the prompt pool. EvoPrompt \cite{evoprompt} use Differential Evolution - where differences between existing prompts is incorporated to form new prompt candidates to overcome the problem of local optima. AELP \cite{aelp} also uses mutation operators to perform sentence-level edits in an iterative fashion. They include sentence-level histories of reward $\{(s_{t-1},s_t,r_t)\}$ in the mutation prompt in order to avoid local optima and accidentally returning to sub-optimal versions. GPS \cite{gps} used Back-translation, Sentence Continuation, and Cloze transformations to perform prompt mutation. PromptWizard \cite{prompt-wizard} proposed a pipeline combining several steps including iterative improvement, few shot example synthesis and selection, utilizing LLM’s reasoning capability to improve and validate the prompt, and finally an expert persona to ensure consistency of the style of generated prompts. %and 2/ using Lin-UCB \cite{Lin UCB} to identify most suitable sentence candidates for mutation, balancing exploration with exploitation

\subsubsection{Word / Phrase Level Edits} 
\label{word}
Several word-edit approaches first identify "influential" tokens in the prompts. COPLE \cite{cople} argued that LLMs exhibit lexical sensitivity, showing that merely replacing a few words with their synonyms can yield significant improvements. First, “influential” tokens are identified where expected loss on dev-set $E_{D_{val}} [L(y,\hat{y})]$ drops the most after removing that token versus the original prompt, and then influential tokens are replaced using predictions from a Masked-Language Models. This token-replacement approach is also attractive as a standalone post-processing step for long prompts that are already optimized using other LLM-based approaches. %Similarly, \cite{CLAPS} also identifies influential tokens by first clustering and retaining top2000 words closest to centroids.%, and then choosing the top tokens that yield the biggest increment in negative cross-entropy. 
%\cite{PROPANE} discovered that semantically obfuscated prompts sometimes can be useful to induce LLMs to generate contents with special requirement and can be transferable among different LLMs. The proposal is to reversely find the prompt that can induce the LLMs generate semantically similar outputs as a set of example documents. And the optimized reversely-engineered prompt is typically obfuscated and transferable among different LLMs. This finding might be useful to better understand how rare tokens in the prompt can be used to induce content from LLMs.
GRIPS \cite{grips} argues that phrase level edition is an effective and interpretable method to optimize prompts, leveraging 4 basic edit operations -add, delete, paraphrase, and swap% and define the prompt optimization as a search task. %At each search step they applied a pre-defined score to evaluate the status of the current step, and stop searching after the score stop improve for certain amount of steps or the steps reach max no. of steps. 

\subsubsection{Vocabulary Pruning}
\label{prune}
Some works prune the vocabulary space $V$ to $V_{pruned}$ for decoding the next token for the optimized prompt $\rho^*$. CLAPS \cite{claps} argued that general search spaces are highly redundant and use K-means clustering to find word-clusters and retain top-2000 words closest to cluster centroids. BDPL \cite{bdpl} used pairwise mutual information (PMI) to retain top co-occuring ngrams for decoding. PIN \cite{pin} instead added regularization in the form of Tsallis-entropy (ideal for heavy-tailed distributions like natural language) for the RL training of a prompt generation network, to reduce the probability mass for unlikely tokens and improve interpetability. 

\subsection{Editing via Auxiliary Trained NN}
\label{nn}
Some approaches leverage a trained auxiliary neural network to edit the initial prompt for obtaining desired improvements. We include approaches where the finetuned network is different and smaller than the task network. 

\subsubsection{Reinforcement-learning}%The primary advantage of reinforcement learning in prompt engineering lies in its ability to automatically optimize prompts through iterative feedback from language models, surpassing manual design especially in complex scenarios.Recent advances in reinforcement learning (RL) for prompt engineering have made significant strides in addressing key optimization challenges. 
\label{rl}
\textbf{Multi-objective Optimization} techniques \cite{morl-prompt} demonstrate superiority over simple reward averaging, particularly through volume-based methods that effectively balance competing objectives. Dynamic prompt modification strategies, introduced through \textbf{prompt rewriting} \cite{prewrite}, directional stimulus prompting \cite{directional-stimulus} and \textbf{test-time editing} \cite{tempera} solve the important goal of moving beyond static prompt generation. Prompt-OIRL \cite{oirl} also tackled test-time optimization objective by learning an \textbf{offline reward model} and subsequently using a best-of-N strategy to recommend the optimal prompt in a query-dependent fashion. BDPL \cite{bdpl} optimized discrete prompts using variance-reduced policy gradient algorithm to estimate gradients, allowing user devices to fine-tune tasks with limited API calls. %While these approaches showcase RL's effectiveness in optimizing prompts while maintaining readability and achieving state-of-the-art performance, significant challenges persist in computational efficiency and generalization to larger language models. %Future research must prioritize reducing computational demands while preserving the advantages of these advanced optimization techniques, as the field progresses toward more practical and interpretable solutions for real-world applications.
\subsubsection{Finetuning LLMs} 
\label{ft}
BPO \cite{bpo-cheng} trains a smaller 7B model to align itself to task-performance on individual LLMs using reward-free alignment. FIPO \cite{fipo} trains a local model (7B - 13B) to perform prompt optimizations to preserve privacy and adapt to target models better leveraging both data diversification and strategic fine-tuning such as SFT, preference optimization, and iterative preference learning. 
\subsubsection{Generative Adversarial Networks} 
\label{gan}
\citet{adv-icl} framed the prompt optimization process in the GAN setting. The LLM generator takes question and the generation prompt to produce output. The (input, output) pairs are evaluated by an LLM powered discriminator, whose goal is to identify generated pairs from ground truth pairs. Both generator and the discriminator are jointly optimized using adversarial loss, by utilizing a prompt modifier LLM to rewrite their prompts. 

\subsection{Metaprompt Design}
\label{metaprompt}
PE2 \cite{pe2} argued that previous works under-explored meta-prompt search space. OPRO \citep{opro} proposes a meta-prompt design (see Appendix \ref{appendix:metaprompt}) which includes the optimization problem description in natural language and previously generated solutions (multiple solutions per stage for diversity) and scores alongisde the meta-instruction for prompt refinement. 
DAPO \cite{dapo} utilizes a well-designed meta-instruction to guide the LLM in generating high-quality and structured initial prompts (contain task-specific info, e.g. task type and description, output format and constraints, reasoning process, professional tips) by observing given input-output exemplars. Then, DAPO iteratively optimizes the prompts at the sentence level, leveraging previous tuning experience to expand prompt candidates.

\subsection{Coverage-based}
\label{coverage}
Some approaches seek to "cover" the entire problem space - either within a single prompt, or using multiple prompts working individually or in an ensemble during inference. 

\subsubsection{Single Prompt-expansion} 
\label{expand}
AMPO \cite{ampo} uses LLM feedback to enumerate all the failure cases based on the evaluation-set $D_{val}$ and then enlists each of them in the meta-instruction in an if-then-else format using 3 modules - 1/ Pattern Recognition, 2/ Branch Adjustment, and 3/ Branch Pruning to decide whether to enhance existing branches, or to grow new branches. Similarly, UNIPROMPT focused on explicitly ensuring that various semantic facets of a task get represented in the final prompt. It designs a human-like (manual) prompt engineering approach (UniPrompt) with two stages: a) task facets initialization using background knowledge, and b) refinement using examples. 

\subsubsection{Mixture of Experts}
\label{moe}
\citet{mop} introduced the Mixture-of-Expert-Prompts where each expert is a task-prompt to be used for specialized inference. MOP first clusters all demonstrations using K-means clustering. Then, the Region-based Joint Search (RBJS) (sec.\ref{rbjs}) algorithm generates the appropriate instruction for each exemplar-cluster via instruction induction (sec.\ref{induction}) based on a mix of in-cluster and out-of-cluster demonstrations to cover “blind-spots”. During inference, a single expert prompt is invoked whose cluster centroid $\mu_c$ is closest to the instance-embedding $\arg \min_{_{C}} ||\phi(x_i) - \mu_c||_2$. 

\subsubsection{Ensemble Methods}
\label{ensemble}
PromptBoosting \cite{prompt-boosting}, BoostedPrompting \cite{boosted-prompting}, PREFER \cite{prefer}, etc. are ensemble methods that invoke multiple prompts during inference and combine them to generate the final output $\hat{y} = y_0 + \Sigma_m \beta_i y_i$. GPO \cite{gpo} also uses labeled source data to generate an ensemble of prompts, which are applied to unlabeled target data to generate output through majority voting. 

\subsection{Program Synthesis}
\label{program}
Program-synthesis based approaches transform LLM pipelines into structured, modular components that can be systematically optimized and composed\ignore{, rather than using static prompts}. These optimization techniques iteratively refine instructions and demonstrations for each module to improve the entire pipeline's performance, \ignore{using program-aware methods and meta-optimization procedures.}
DSP \cite{dsp} introduces a three-stage framework for retrieval-augmented inference: Demonstrate (generates task-specific demonstrations), Search (retrieves relevant information), and Predict (combines retrieved info with demonstrations). DSPY \cite{dspy} transforms LLM pipelines into text transformation graphs - introducing parameterized models, learning through demonstrations, and a compiler that optimizes pipelines. DLN \cite{dln} similarly considers chained LLM calls as stacked deep language networks performing variational inference, where the learnable parameters for each layer are task-decomposed prompt templates. MIPRO \cite{mipro} automates the optimization of multi-stage language model programs by improving instructions and demonstrations for each module. SAMMO \cite{sammo} proposed symbolic prompt programming, representing prompts as directed-acyclic-graphs (DAG). A set of user-defined node mutation rules guide the mutation-search to find the optimal DAG\ignore{based on $E_{D_{val}}[f(\rho)]$}, which is then converted back to a prompt. %The optimization search process is guided by user-defined metrics on labeled dataset. %The method is highly flexible yet lack of concrete guidance on what’s the best practice to define the mutations and the evaluation metrics, and the performance of the entire system is significantly depended on the mutations and metrics. PATH \cite{path} trains information retrieval models with minimal labeled data - using as few as 10 gold relevance labels, it generates synthetic queries through language models and optimizes prompts, achieving performance comparable to larger models.

%In DSPY \citep{DSPY}, the authors argue that most of the current LLM pipelines rely heavily on hard-coded prompt templates, and the need of the hour is for a more systematic approach to designing the pipelines as hard-coded designs are not scalable across different models and tasks. Towards this, the authors introduce a programming model that abstracts LLM pipelines as text transformation graphs — making using of parameterized declarative models and enabling learning through demonstrations. The author propose a compiler that optimizes the pipelines to maximize metrics and supports natural language signatures to define module behaviors. Consequentially, this framework  reduces the reliance of expert crafted prompts and also allowing to better use smaller LLMs — and can also bootstrap self-improving multi-stage systems.

%DSP \cite{dsp} reimagines retrieval-augmented in-context learning, by addressing the limitations of conventional “retrieve-then-read” pipelines, which struggle to handle complex, knowledge-intensive tasks. DSP introduces a more sophisticated framework comprising three interconnected stages. The first stage, Demonstrate, generates task-specific demonstrations to guide the LM effectively. The second stage, Search, employes a retriever model to identify and retrieve relevant information based on the input and the generated demonstrations. The final stage, Predict, combines the retrieved information and demonstrations to generate the final output. This framework achieves significant performance improvements over standard LMs and existing retrieval-augmented LMs. Moreover, DSP provides adaptability for various tasks, including open-domain, multi-hop, and conversational question answering. 

%PATH \cite{PATH} provides a novel approach to training effective information retrieval models with minimal labeled data, addressing critical challenges in low-resource languages and niche domains. Unlike traditional information retrieval models that require extensive labeled datasets, PATH achieves high performance using as few as 10 gold relevance labels.The method involves generating synthetic queries for documents using a language model, followed by automatic optimization of the LM prompts based on the quality of the trained IR model. These optimized prompts are then used to train small-scale neural IR models with fewer than 100 million paramters on the synthetic data,  PATH-trained models demonstrate remarkable efficiency, outperforming larger models like RankZephyr and rivaling RankLLama, which are significantly larger and trained on extensive datasets. This makes PATH an accessible and efficient solution for scenarios with limited computational and data resources.

%MIPRO \cite{MIPRO} tackles the challenge of designing effective prompts for multi-stage language model programs, a process that is traditionally labor-intensive and often suboptimal. MIPRO formalizes the optimization of language model programs and automates the improvement of instructions and few-shot demonstrations for each module within the pipeline. This method proposes task-grounded instructions using program- and data-aware techniques while employing a stochastic mini-batch evaluation function to learn a surrogate model of the optimization objective. A meta-optimization procedure is used to iteratively refine the proposals generated by the language models. MIPRO demonstrates its effectiveness by outperforming baseline optimizers in five out of seven multi-stage LM programs, achieving up to a 13\% increase in accuracy. Importantly, the method operates without requiring access to internal language model parameters or intermediate module labels. Furthermore, the authors have made the optimizers and benchmarks publicly available within the DSPy framework, underscoring the method’s utility and accessibility.


\section{Filter and Retain Promising Prompts}
\label{filter}
In this step, promising prompt candidates are filtered for further optimization. 
\subsection{TopK Greedy Search}
\label{topk}
The simplest mechanism to iteratively search through prompt candidate sets is a greedy topK search where in each iteration of the optimization, the top-K best-performing candidates on mini-batch of data instances $D_{val}$ are retained for further iterations (e.g. - ProTeGi, AELP. This differs from beam-search which judges partial solutions’ 
based on the reward for the entire trajectory of prompt edits $r(\{\rho_{1}^1, \rho_{2}^1, \ldots,\rho_{t}^1\})$.
\subsection{Upper Confidence Bound and Variants}
\label{ucb}
Relying on a single static evaluation dataset can lead to biases in the selection procedure and finally suboptimal solutions. ProTeGi, SPRIG, \textit{inter alia}, cast the candidate prompt selection problem as that of bandit search - identifying the most suitable arm (prompt candidate) operating on a fixed computation budget. They use the Upper Confidence Bounds (UCB, Algorithm \ref{algo:ucb}) which balances exploration with exploitation. In each iteration of prompt optimization, they sample a different evaluation dataset $D_{sample} \in D_{val}$, and maintain a moving estimate of the optimality of each arm (i.e. prompt). In each iteration, the playout filters top-B prompt candidates with the greatest score for further exploration. PromptAgent uses a variation of UCB called UCB for Trees (UCT) which are used in the setting of contextual bandits (i.e. the action-space and the reward function is state-dependent). AELP \cite{aelp} used a modification called Linear UCB \cite{lin-ucb} which uses a closed form linear estimate based on the reward trajectories of previously sampled edits as well as prompt embedding $\phi(s)$ to select the next best-arm. 
\subsection{Region-based Joint Search}
\label{rbjs}
MOP \cite{mop} proposes a Mixture-of-Expert-Prompts performing prompt optimization for each expert individual. Once C exemplar-clusters are identified, the RBJS search first samples examples  $D_{exemplars} \in D_C \cup D \setminus D_C$, and then uses APE to induct and optimize each expert instruction.  
\subsection{Metaheuristic Ensemble}
\label{metaheuristic}
PLUM \cite{plum} library offered a meta-heuristic ensemble of different search algorithms like Hill climbing, Simulated Annealing, Genetic Algorithms, Tabu Search, and Harmony Search. 

\section{Iteration Depth}
\label{depth}
\subsection{Fixed Steps}
\label{fixed}
Most approaches choose to carry out the prompt optimization for a fixed number of steps N. 
\subsection{Variable number of steps}
\label{variable}
GRIPS \cite{grips} concludes search when successive iterations with negative gains breach a patience parameter, whereas PromptAgent concluded APO when $r_t \leq \epsilon_{min} \vee r_t \geq \epsilon_{max}$. 
\section{Theoretical Perspectives}
\subsection{Upper Bound of Improvement from APO}
\label{ub}
\ignore{While there are theoretical explorations behind In-Context Learning \cite{icl-survey}, there is a relative dearth of such theoretical understanding of Instruction Optimization techniques. It is useful to understand prompt optimization from a theoretical perspective to establish the lower and upper bound of improvement attainable under a given prompt optimizer.} AlignPro \cite{align-pro} establishes an upper bound on the gains realizable from discrete prompt optimization under a given prompt optimizer and also a suboptimality-gap w.r.t. RLHF-optimal policy $\pi^*$, while a lower bound is left unexplored. 
%, leaving the exploration of a lower-bound to future work. 
\subsection{Other Related Perspectives}
\citet{control} proposed a control theoretic framework to establish bounds on the set of reachable LLM-outputs for self-attention in terms of the singular values of its weight matrices. \citet{universality} showed the existence of a strong transformer \ignore{with a prompt} that can approximate any sequence-to-sequence Lipschitz function. They also showed the existence of “difficult” datasets that depth-limited transformers could not commit to memory. 


\section{Challenges and Future Directions}
\subsection{Task-agnostic APO}

All the surveyed APO methods assume that the task type $T$ is known beforehand; additionally offline APO methods also require an evaluation set $D_{val}$, something not explicitly available in production settings. Barring a few tasks covered by \citet{gate, oirl, tempera, pin}, inference-time optimization of multiple unknown tasks is underexplored. \ignore{MOP solves a related yet incomplete setting where the data instance is routed to the most suitable expert, but doesn’t explore unseen task-prompts $\rho_{unseen} \in T^*, T \subseteq T^* , \rho_{unseen}:= I_{unseen} \oplus E_{unseen} \oplus \tau$.} More robust evaluations are needed for task-agnostic APO systems combining seen and unseen tasks. 

\subsection{Unclear Mechanisms}
\citet{propane} showed that prompts have so-called 'evil twins' that are uninterpretable yet recover some of the performance of gold-standard prompts. \citet{random-separators} showed that rare gibberish strings can serve as competitive delimiters $\tau$ in prompts. \citet{abo} showed that self-reflection by LLMs can suffer from incorrect error identification, prior biases, semantic invalidity, leading to failure in yielding improved prompts. More studies are needed to better uncover the mechanisms of prompt optimization. 
\subsection{APO for System Prompts / Agents}
Although SPRIG explored optimizing system prompts in chat-style settings, scalability remains a challenge - optimizing system prompts required a predefined corpus and close to 60 hours whereas Protegi only needed \~10 minutes per task. Similarly, optimizing prompts for several components in an agentic system in a concurrent fashion poses an exciting direction for future research.  
%SPRIG \cite{SPRIG} introduces a novel approach based on genetic algorithm for optimizing system prompts, which are defined as general instructions that precede the task-specific details. Unlike traditional methods that focuses on task-specific prompts, SPRIG aims to enhance LLM performance across diverse tasks by iteratively refining system prompts by leveraging a corpus of prompt components categorized into good properties, roles, styles, emotions, Chain-of-Thought (CoT), etc. System prompt optimization using SPRIG demonstrates significant performance gain on a variety of tasks compared to task-specific optimizers like ProTeGi. Combining ProTeGi and SPRIG further enhances performance, demonstrating the complementary nature of system and task prompt optimization.  Also, reliance on a predefined corpus of components limits scalability and introduces biases. 

\subsection{Multimodal APO}
Recently, textual prompt optimization has expanded to multimodal domains: text-to-image~\cite{liu2024language, manas2024improving, liu2024you}, text-to-video~\cite{ji2024prompt}, text-to-audio~\cite{huang2023make}, and text-image alignment models like CLIP~\cite{du2024ipo, mirza2024glov}. Beyond textual prompts, ~\citet{huang2023make} explore optimizing multimodal inputs, such as images, to elicit better responses from large multimodal models. However, the interplay between modalities in prompt optimization remains underexplored. Future research could develop APO frameworks to jointly optimize multimodal prompts (eg - remove background noise from audio, add visual markers to videos, etc.) to fully leverage their synergies.

\section{Conclusion}
\label{sec:conclusion}
In this paper, we provide a comprehensive fine-grained review of existing APO techniques and identified key areas for future growth. It is our aim to spur future research spawning from our survey. 

\section{Limitations}
\label{sec:limitation}
While we attempted to cover all qualifying papers, it is possible that we may have unintentionally missed out on some relevant papers. We also mention some of the papers that were excluded in this survey with specific reasons in section \ref{excluded}. Also, we realize that fitting varied research works into a single unifying framework might risk broad categorizations for some papers, or skipping some characteristics for others (e.g. Tempera \cite{tempera} consists of both RL-based and word/phrase-level editing techniques, applied to both instructions and exemplars). In such cases, we categorize a paper based on its most salient features. Another challenge is that when presenting a survey paper under 8 pages, we had to make tradeoffs and only retain content in the main body that was deemed most necessary. This resulted in having to relegate a core contribution (Tables \ref{tab:comparison_1},\ref{tab:comparison_2},\ref{tab:comparison_3}) which contained a rigorous comparison of all the surveyed papers into the appendix. We have attempted our best to strike the right balance between specificity and brevity to present a novel framework. We also provide copious references to interested researchers for further reading. 
% Entries for the entire Anthology, followed by custom entries
\begin{thebibliography}{186}
\expandafter\ifx\csname natexlab\endcsname\relax\def\natexlab#1{#1}\fi

\bibitem[{Agarwal et~al.(2024)Agarwal, Singh, Dani, Magazine, Ganu, and
  Nambi}]{prompt-wizard}
Eshaan Agarwal, Joykirat Singh, Vivek Dani, Raghav Magazine, Tanuja Ganu, and
  Akshay Nambi. 2024.
\newblock \href {http://arxiv.org/abs/2405.18369} {Promptwizard: Task-aware
  prompt optimization framework}.

\bibitem[{Alva-Manchego et~al.(2020)Alva-Manchego, Martin, Bordes, Scarton,
  Sagot, and Specia}]{asset}
Fernando Alva-Manchego, Louis Martin, Antoine Bordes, Carolina Scarton,
  Beno{\^\i}t Sagot, and Lucia Specia. 2020.
\newblock Asset: A dataset for tuning and evaluation of sentence simplification
  models with multiple rewriting transformations.
\newblock In \emph{Proceedings of the 58th Annual Meeting of the Association
  for Computational Linguistics}, pages 4668--4679.

\bibitem[{Amini et~al.(2024)Amini, Vieira, and Cotterell}]{drpo}
Afra Amini, Tim Vieira, and Ryan Cotterell. 2024.
\newblock \href {https://doi.org/10.18653/v1/2024.findings-acl.592} {Direct
  preference optimization with an offset}.
\newblock In \emph{Findings of the Association for Computational Linguistics:
  ACL 2024}, pages 9954--9972, Bangkok, Thailand. Association for Computational
  Linguistics.

\bibitem[{Anantha et~al.(2020)Anantha, Vakulenko, Tu, Longpre, Pulman, and
  Chappidi}]{QReCC}
R.~Anantha, Svitlana Vakulenko, Zhucheng Tu, S.~Longpre, Stephen~G. Pulman, and
  Srinivas Chappidi. 2020.
\newblock \href {https://api.semanticscholar.org/CorpusID:222290679}
  {Open-domain question answering goes conversational via question rewriting}.
\newblock In \emph{North American Chapter of the Association for Computational
  Linguistics}.

\bibitem[{Andreas et~al.(2020)Andreas, Bufe, Burkett, Chen, Clausman, Crawford,
  Crim, DeLoach, Dorner, Eisner, Fang, Guo, Hall, Hayes, Hill, Ho, Iwaszuk,
  Jha, Klein, Krishnamurthy, Lanman, Liang, Lin, Lintsbakh, McGovern,
  Nisnevich, Pauls, Petters, Read, Roth, Roy, Rusak, Short, Slomin, Snyder,
  Striplin, Su, Tellman, Thomson, Vorobev, Witoszko, Wolfe, Wray, Zhang, and
  Zotov}]{smcalflow}
Jacob Andreas, Johannes Bufe, David Burkett, Charles~C. Chen, Joshua Clausman,
  Jean Crawford, Kate Crim, Jordan DeLoach, Leah Dorner, Jason Eisner, Hao
  Fang, Alan Guo, David Leo~Wright Hall, Kristin~Delia Hayes, Kellie Hill,
  Diana Ho, Wendy Iwaszuk, Smriti Jha, Dan Klein, Jayant Krishnamurthy, Theo
  Lanman, Percy Liang, C.~H. Lin, Ilya Lintsbakh, Andy McGovern, Aleksandr
  Nisnevich, Adam Pauls, Dmitrij Petters, Brent Read, Dan Roth, Subhro Roy,
  Jesse Rusak, Beth~Ann Short, Div Slomin, B~Snyder, Stephon Striplin, Yu~Su,
  Zachary Tellman, Sam Thomson, A.~A. Vorobev, Izabela Witoszko, Jason Wolfe,
  A.~G. Wray, Yuchen Zhang, and Alexander Zotov. 2020.
\newblock \href {https://api.semanticscholar.org/CorpusID:221822514}
  {Task-oriented dialogue as dataflow synthesis}.
\newblock \emph{Transactions of the Association for Computational Linguistics},
  8:556--571.

\bibitem[{Bansal et~al.(2019)Bansal, Jha, and McCallum}]{leopard}
Trapit Bansal, Rishikesh Jha, and Andrew McCallum. 2019.
\newblock \href {https://api.semanticscholar.org/CorpusID:207852358} {Learning
  to few-shot learn across diverse natural language classification tasks}.
\newblock In \emph{International Conference on Computational Linguistics}.

\bibitem[{Bhargava et~al.(2024)Bhargava, Witkowski, Looi, and
  Thomson}]{control}
Aman Bhargava, Cameron Witkowski, Shi-Zhuo Looi, and Matt Thomson. 2024.
\newblock \href {http://arxiv.org/abs/2310.04444} {What's the magic word? a
  control theory of llm prompting}.

\bibitem[{Bisk et~al.(2019)Bisk, Zellers, Bras, Gao, and Choi}]{piqa}
Yonatan Bisk, Rowan Zellers, Ronan~Le Bras, Jianfeng Gao, and Yejin Choi. 2019.
\newblock \href {https://api.semanticscholar.org/CorpusID:208290939} {Piqa:
  Reasoning about physical commonsense in natural language}.
\newblock In \emph{AAAI Conference on Artificial Intelligence}.

\bibitem[{Bowman et~al.(2015)Bowman, Angeli, Potts, and Manning}]{snli}
Samuel~R Bowman, Gabor Angeli, Christopher Potts, and Christopher~D Manning.
  2015.
\newblock A large annotated corpus for learning natural language inference.
\newblock \emph{arXiv preprint arXiv:1508.05326}.

\bibitem[{Brown et~al.(2020)Brown, Mann, Ryder, Subbiah, Kaplan, Dhariwal,
  Neelakantan, Shyam, Sastry, Askell, Agarwal, Herbert-Voss, Krueger, Henighan,
  Child, Ramesh, Ziegler, Wu, Winter, Hesse, Chen, Sigler, Litwin, Gray, Chess,
  Clark, Berner, McCandlish, Radford, Sutskever, and Amodei}]{fewshot}
Tom~B. Brown, Benjamin Mann, Nick Ryder, Melanie Subbiah, Jared Kaplan,
  Prafulla Dhariwal, Arvind Neelakantan, Pranav Shyam, Girish Sastry, Amanda
  Askell, Sandhini Agarwal, Ariel Herbert-Voss, Gretchen Krueger, Tom Henighan,
  Rewon Child, Aditya Ramesh, Daniel~M. Ziegler, Jeffrey Wu, Clemens Winter,
  Christopher Hesse, Mark Chen, Eric Sigler, Mateusz Litwin, Scott Gray,
  Benjamin Chess, Jack Clark, Christopher Berner, Sam McCandlish, Alec Radford,
  Ilya Sutskever, and Dario Amodei. 2020.
\newblock \href {http://arxiv.org/abs/2005.14165} {Language models are few-shot
  learners}.

\bibitem[{Budzianowski et~al.(2018)Budzianowski, Wen, Tseng, Casanueva, Ultes,
  Ramadan, and Gasic}]{multiwoz}
Pawe{\l} Budzianowski, Tsung-Hsien Wen, Bo-Hsiang Tseng, I{\~n}igo Casanueva,
  Stefan Ultes, Osman Ramadan, and Milica Gasic. 2018.
\newblock Multiwoz-a large-scale multi-domain wizard-of-oz dataset for
  task-oriented dialogue modelling.
\newblock In \emph{Proceedings of the 2018 Conference on Empirical Methods in
  Natural Language Processing}, pages 5016--5026.

\bibitem[{Cer et~al.(2017)Cer, Diab, Agirre, Lopez-Gazpio, and Specia}]{QQP}
Daniel~Matthew Cer, Mona~T. Diab, Eneko Agirre, I{\~n}igo Lopez-Gazpio, and
  Lucia Specia. 2017.
\newblock \href {https://api.semanticscholar.org/CorpusID:4421747}
  {Semeval-2017 task 1: Semantic textual similarity multilingual and
  crosslingual focused evaluation}.
\newblock In \emph{International Workshop on Semantic Evaluation}.

\bibitem[{Cettolo et~al.(2017)Cettolo, Federico, Bentivogli, Jan, Sebastian,
  Katsuitho, Koichiro, and Christian}]{iwslt}
Mauro Cettolo, Marcello Federico, Luisa Bentivogli, Niehues Jan, St{\"u}ker
  Sebastian, Sudoh Katsuitho, Yoshino Koichiro, and Federmann Christian. 2017.
\newblock \href {https://api.semanticscholar.org/CorpusID:21675165} {Overview
  of the iwslt 2017 evaluation campaign}.
\newblock In \emph{International Workshop on Spoken Language Translation}.

\bibitem[{Chen et~al.(2024)Chen, Arkin, Hao, Zhang, Roy, and Fan}]{promst}
Yongchao Chen, Jacob Arkin, Yilun Hao, Yang Zhang, Nicholas Roy, and Chuchu
  Fan. 2024.
\newblock \href {https://doi.org/10.18653/v1/2024.emnlp-main.226} {{PR}ompt
  optimization in multi-step tasks ({PROMST}): Integrating human feedback and
  heuristic-based sampling}.
\newblock In \emph{Proceedings of the 2024 Conference on Empirical Methods in
  Natural Language Processing}, pages 3859--3920, Miami, Florida, USA.
  Association for Computational Linguistics.

\bibitem[{Cheng et~al.(2024)Cheng, Liu, Zheng, Ke, Wang, Dong, Tang, and
  Huang}]{bpo-cheng}
Jiale Cheng, Xiao Liu, Kehan Zheng, Pei Ke, Hongning Wang, Yuxiao Dong, Jie
  Tang, and Minlie Huang. 2024.
\newblock \href {https://doi.org/10.18653/v1/2024.acl-long.176} {Black-box
  prompt optimization: Aligning large language models without model training}.
\newblock In \emph{Proceedings of the 62nd Annual Meeting of the Association
  for Computational Linguistics (Volume 1: Long Papers)}, pages 3201--3219,
  Bangkok, Thailand. Association for Computational Linguistics.

\bibitem[{Chiang et~al.(2023)Chiang, Li, Lin, Sheng, Wu, Zhang, Zheng, Zhuang,
  Zhuang, Gonzalez et~al.}]{VicunaEval}
Wei-Lin Chiang, Zhuohan Li, Zi~Lin, Ying Sheng, Zhanghao Wu, Hao Zhang, Lianmin
  Zheng, Siyuan Zhuang, Yonghao Zhuang, Joseph~E Gonzalez, et~al. 2023.
\newblock Vicuna: An open-source chatbot impressing gpt-4 with 90\%* chatgpt
  quality.
\newblock \emph{See https://vicuna. lmsys. org (accessed 14 April 2023)},
  2(3):6.

\bibitem[{Choi et~al.(2023)Choi, Pei, Kumar, Shu, and Jurgens}]{socket}
Minje Choi, Jiaxin Pei, Sagar Kumar, Chang Shu, and David Jurgens. 2023.
\newblock Do llms understand social knowledge? evaluating the sociability of
  large language models with socket benchmark.
\newblock In \emph{Proceedings of the 2023 Conference on Empirical Methods in
  Natural Language Processing}, pages 11370--11403.

\bibitem[{Choi et~al.(2024)Choi, Bae, Ban, Jeong, Zhang, Song, Zhao, Bian, and
  Kim}]{pin}
Yunseon Choi, Sangmin Bae, Seonghyun Ban, Minchan Jeong, Chuheng Zhang, Lei
  Song, Li~Zhao, Jiang Bian, and Kee-Eung Kim. 2024.
\newblock \href {http://arxiv.org/abs/2407.14733} {Hard prompts made
  interpretable: Sparse entropy regularization for prompt tuning with rl}.

\bibitem[{Cieri et~al.(2022)Cieri, Liberman, Cho, Strassel, Fiumara, and
  Wright}]{cieri-etal-2022-reflections}
Christopher Cieri, Mark Liberman, Sunghye Cho, Stephanie Strassel, James
  Fiumara, and Jonathan Wright. 2022.
\newblock \href {https://aclanthology.org/2022.lrec-1.57} {Reflections on 30
  years of language resource development and sharing}.
\newblock In \emph{Proceedings of the Thirteenth Language Resources and
  Evaluation Conference}, pages 543--550, Marseille, France. European Language
  Resources Association.

\bibitem[{Clark et~al.(2018)Clark, Cowhey, Etzioni, Khot, Sabharwal, Schoenick,
  and Tafjord}]{ARC}
Peter Clark, Isaac Cowhey, Oren Etzioni, Tushar Khot, Ashish Sabharwal, Carissa
  Schoenick, and Oyvind Tafjord. 2018.
\newblock \href {https://api.semanticscholar.org/CorpusID:3922816} {Think you
  have solved question answering? try arc, the ai2 reasoning challenge}.
\newblock \emph{ArXiv}, abs/1803.05457.

\bibitem[{Cobbe et~al.(2021)Cobbe, Kosaraju, Bavarian, Chen, Jun, Kaiser,
  Plappert, Tworek, Hilton, Nakano et~al.}]{gsm8k}
Karl Cobbe, Vineet Kosaraju, Mohammad Bavarian, Mark Chen, Heewoo Jun, Lukasz
  Kaiser, Matthias Plappert, Jerry Tworek, Jacob Hilton, Reiichiro Nakano,
  et~al. 2021.
\newblock Training verifiers to solve math word problems.
\newblock \emph{arXiv preprint arXiv:2110.14168}.

\bibitem[{Conover et~al.(2023)Conover, Hayes, Mathur, Xie, Wan, Shah, Ghodsi,
  Wendell, Zaharia, and Xin}]{dollyEval}
Mike Conover, Matt Hayes, Ankit Mathur, Jianwei Xie, Jun Wan, Sam Shah, Ali
  Ghodsi, Patrick Wendell, Matei Zaharia, and Reynold Xin. 2023.
\newblock Free dolly: Introducing the world’s first truly open
  instruction-tuned llm.
\newblock \emph{Company Blog of Databricks}.

\bibitem[{Cui et~al.(2020)Cui, Wu, Liu, Zhang, and Zhou}]{MuTual}
Leyang Cui, Yu~Wu, Shujie Liu, Yue Zhang, and Ming Zhou. 2020.
\newblock \href {https://api.semanticscholar.org/CorpusID:215548215} {Mutual: A
  dataset for multi-turn dialogue reasoning}.
\newblock \emph{ArXiv}, abs/2004.04494.

\bibitem[{Dagan et~al.(2005)Dagan, Glickman, and Magnini}]{RTE}
Ido Dagan, Oren Glickman, and Bernardo Magnini. 2005.
\newblock \href {https://api.semanticscholar.org/CorpusID:8587959} {The pascal
  recognising textual entailment challenge}.
\newblock In \emph{Machine Learning Challenges Workshop}.

\bibitem[{de~Marneffe et~al.(2019)de~Marneffe, Simons, and Tonhauser}]{nli-ci}
Marie-Catherine de~Marneffe, Mandy Simons, and Judith Tonhauser. 2019.
\newblock \href {https://api.semanticscholar.org/CorpusID:203595067} {The
  commitmentbank: Investigating projection in naturally occurring discourse}.

\bibitem[{Deng et~al.(2022)Deng, Wang, Hsieh, Wang, Guo, Shu, Song, Xing, and
  Hu}]{rlprompt}
Mingkai Deng, Jianyu Wang, Cheng-Ping Hsieh, Yihan Wang, Han Guo, Tianmin Shu,
  Meng Song, Eric~P. Xing, and Zhiting Hu. 2022.
\newblock \href {http://arxiv.org/abs/2205.12548} {Rlprompt: Optimizing
  discrete text prompts with reinforcement learning}.

\bibitem[{Dernoncourt and Lee(2017)}]{RCT}
Franck Dernoncourt and Ji~Young Lee. 2017.
\newblock \href {https://api.semanticscholar.org/CorpusID:151184} {Pubmed 200k
  rct: a dataset for sequential sentence classification in medical abstracts}.
\newblock In \emph{International Joint Conference on Natural Language
  Processing}.

\bibitem[{Detrano et~al.(1989)Detrano, J{\'a}nosi, Steinbrunn, Pfisterer,
  Schmid, Sandhu, Guppy, Lee, and Froelicher}]{heartdieases}
Robert~C. Detrano, Andr{\'a}s J{\'a}nosi, Walter Steinbrunn, Matthias~Emil
  Pfisterer, Johann-Jakob Schmid, Sarbjit Sandhu, Kern Guppy, Stella Lee, and
  Victor Froelicher. 1989.
\newblock \href {https://api.semanticscholar.org/CorpusID:23545303}
  {International application of a new probability algorithm for the diagnosis
  of coronary artery disease.}
\newblock \emph{The American journal of cardiology}, 64 5:304--10.

\bibitem[{Diao et~al.(2022)Diao, Huang, Xu, Li, Lin, Zhou, and Zhang}]{bdpl}
Shizhe Diao, Zhichao Huang, Ruijia Xu, Xuechun Li, Yong Lin, Xiao Zhou, and
  Tong Zhang. 2022.
\newblock Black-box prompt learning for pre-trained language models.
\newblock \emph{arXiv preprint arXiv:2201.08531}.

\bibitem[{Do{\u{g}}an et~al.(2014)Do{\u{g}}an, Leaman, and Lu}]{ncbi}
Rezarta~Islamaj Do{\u{g}}an, Robert Leaman, and Zhiyong Lu. 2014.
\newblock Ncbi disease corpus: a resource for disease name recognition and
  concept normalization.
\newblock \emph{Journal of biomedical informatics}, 47:1--10.

\bibitem[{Dolan and Brockett(2005)}]{MRPC}
William~B. Dolan and Chris Brockett. 2005.
\newblock \href {https://api.semanticscholar.org/CorpusID:16639476}
  {Automatically constructing a corpus of sentential paraphrases}.
\newblock In \emph{International Joint Conference on Natural Language
  Processing}.

\bibitem[{Dong et~al.(2024{\natexlab{a}})Dong, Li, Dai, Zheng, Ma, Li, Xia, Xu,
  Wu, Chang, Sun, Li, and Sui}]{icl-survey}
Qingxiu Dong, Lei Li, Damai Dai, Ce~Zheng, Jingyuan Ma, Rui Li, Heming Xia,
  Jingjing Xu, Zhiyong Wu, Baobao Chang, Xu~Sun, Lei Li, and Zhifang Sui.
  2024{\natexlab{a}}.
\newblock \href {https://doi.org/10.18653/v1/2024.emnlp-main.64} {A survey on
  in-context learning}.
\newblock In \emph{Proceedings of the 2024 Conference on Empirical Methods in
  Natural Language Processing}, pages 1107--1128, Miami, Florida, USA.
  Association for Computational Linguistics.

\bibitem[{Dong et~al.(2024{\natexlab{b}})Dong, Luo, Jiang, Jin, and Li}]{pace}
Yihong Dong, Kangcheng Luo, Xue Jiang, Zhi Jin, and Ge~Li. 2024{\natexlab{b}}.
\newblock \href {https://doi.org/10.18653/v1/2024.findings-acl.436} {{PACE}:
  Improving prompt with actor-critic editing for large language model}.
\newblock In \emph{Findings of the Association for Computational Linguistics:
  ACL 2024}, pages 7304--7323, Bangkok, Thailand. Association for Computational
  Linguistics.

\bibitem[{Du et~al.(2024)Du, Sun, and Snoek}]{du2024ipo}
Yingjun Du, Wenfang Sun, and Cees~GM Snoek. 2024.
\newblock Ipo: Interpretable prompt optimization for vision-language models.
\newblock \emph{arXiv preprint arXiv:2410.15397}.

\bibitem[{Dua et~al.(2019)Dua, Wang, Dasigi, Stanovsky, Singh, and
  Gardner}]{DROP}
Dheeru Dua, Yizhong Wang, Pradeep Dasigi, Gabriel Stanovsky, Sameer Singh, and
  Matt Gardner. 2019.
\newblock \href {https://api.semanticscholar.org/CorpusID:67855846} {Drop: A
  reading comprehension benchmark requiring discrete reasoning over
  paragraphs}.
\newblock In \emph{North American Chapter of the Association for Computational
  Linguistics}.

\bibitem[{Dumitrescu et~al.(2021)Dumitrescu, Rebeja, Lőrincz, Găman, Ilie,
  Pruteanu, Stan, Morogan, Rebedea, and Ruder}]{LiRO}
Stefan~Daniel Dumitrescu, Petru Rebeja, Be{\'a}ta Lőrincz, Mihaela Găman,
  Mihai~Daniel Ilie, Andrei Pruteanu, Adriana Stan, Luciana Morogan, Traian
  Rebedea, and Sebastian Ruder. 2021.
\newblock \href {https://api.semanticscholar.org/CorpusID:237259105} {Liro:
  Benchmark and leaderboard for romanian language tasks}.
\newblock In \emph{NeurIPS Datasets and Benchmarks}.

\bibitem[{Farha and Magdy(2020{\natexlab{a}})}]{ArSarcasm}
Ibrahim~Abu Farha and Walid Magdy. 2020{\natexlab{a}}.
\newblock \href {https://api.semanticscholar.org/CorpusID:219301519} {From
  arabic sentiment analysis to sarcasm detection: The arsarcasm dataset}.
\newblock In \emph{OSACT}.

\bibitem[{Farha and Magdy(2020{\natexlab{b}})}]{Sarcasm}
Ibrahim~Abu Farha and Walid Magdy. 2020{\natexlab{b}}.
\newblock \href {https://api.semanticscholar.org/CorpusID:219301519} {From
  arabic sentiment analysis to sarcasm detection: The arsarcasm dataset}.
\newblock In \emph{OSACT}.

\bibitem[{Fernando et~al.(2023)Fernando, Banarse, Michalewski, Osindero, and
  Rockt{\"a}schel}]{prompt-breeder}
Chrisantha Fernando, Dylan Banarse, Henryk Michalewski, Simon Osindero, and Tim
  Rockt{\"a}schel. 2023.
\newblock \href {https://api.semanticscholar.org/CorpusID:263310323}
  {Promptbreeder: Self-referential self-improvement via prompt evolution}.
\newblock \emph{ArXiv}, abs/2309.16797.

\bibitem[{Fisher(1936)}]{iris}
Rory~A. Fisher. 1936.
\newblock \href {https://api.semanticscholar.org/CorpusID:29084021} {The use of
  multiple measurements in taxonomic problems}.
\newblock \emph{Annals of Human Genetics}, 7:179--188.

\bibitem[{Garcia et~al.(2020)Garcia, Ye, Liu, Hu, Otani, Chu, Nakashima, and
  Mitamura}]{AQuA}
Noa Garcia, Chentao Ye, Zihua Liu, Qingtao Hu, Mayu Otani, Chenhui Chu, Yuta
  Nakashima, and Teruko Mitamura. 2020.
\newblock A dataset and baselines for visual question answering on art.
\newblock In \emph{European Conference on Computer Vision}, pages 92--108.

\bibitem[{Garc'ia-Orteg'on et~al.(2021)Garc'ia-Orteg'on, Simm, Tripp,
  Hern{\'a}ndez-Lobato, Bender, and Bacallado}]{Dockstring}
Miguel Garc'ia-Orteg'on, Gregor N.~C. Simm, Austin Tripp, Jos{\'e}~Miguel
  Hern{\'a}ndez-Lobato, Andreas Bender, and Sergio Bacallado. 2021.
\newblock \href {https://api.semanticscholar.org/CorpusID:240288398}
  {Dockstring: Easy molecular docking yields better benchmarks for ligand
  design}.
\newblock \emph{Journal of Chemical Information and Modeling}, 62:3486 -- 3502.

\bibitem[{Gardent et~al.(2017)Gardent, Shimorina, Narayan, and
  Perez-Beltrachini}]{WebNLG}
Claire Gardent, Anastasia Shimorina, Shashi Narayan, and Laura
  Perez-Beltrachini. 2017.
\newblock \href {https://api.semanticscholar.org/CorpusID:6702871} {Creating
  training corpora for nlg micro-planners}.
\newblock In \emph{Annual Meeting of the Association for Computational
  Linguistics}.

\bibitem[{Geva et~al.(2021)Geva, Khashabi, Segal, Khot, Roth, and Berant}]{SQA}
Mor Geva, Daniel Khashabi, Elad Segal, Tushar Khot, Dan Roth, and Jonathan
  Berant. 2021.
\newblock \href {https://api.semanticscholar.org/CorpusID:230799347} {Did
  aristotle use a laptop? a question answering benchmark with implicit
  reasoning strategies}.
\newblock \emph{Transactions of the Association for Computational Linguistics},
  9:346--361.

\bibitem[{Gliwa et~al.(2019)Gliwa, Mochol, Biesek, and Wawer}]{samsum}
Bogdan Gliwa, Iwona Mochol, Maciej Biesek, and Aleksander Wawer. 2019.
\newblock Samsum corpus: A human-annotated dialogue dataset for abstractive
  summarization.
\newblock In \emph{Proceedings of the 2nd Workshop on New Frontiers in
  Summarization}, pages 70--79.

\bibitem[{Gunasekara et~al.(2019)Gunasekara, Kummerfeld, Polymenakos, and
  Lasecki}]{DSTC7}
Chulaka Gunasekara, Jonathan~K. Kummerfeld, Lazaros Polymenakos, and Walter~S.
  Lasecki. 2019.
\newblock \href {https://api.semanticscholar.org/CorpusID:85537312} {Dstc7 task
  1: Noetic end-to-end response selection}.
\newblock \emph{Proceedings of the First Workshop on NLP for Conversational
  AI}.

\bibitem[{Guo et~al.(2024)Guo, Wang, Guo, Li, Song, Tan, Liu, Bian, and
  Yang}]{evoprompt}
Qingyan Guo, Rui Wang, Junliang Guo, Bei Li, Kaitao Song, Xu~Tan, Guoqing Liu,
  Jiang Bian, and Yujiu Yang. 2024.
\newblock \href {https://openreview.net/forum?id=ZG3RaNIsO8} {Connecting large
  language models with evolutionary algorithms yields powerful prompt
  optimizers}.
\newblock In \emph{The Twelfth International Conference on Learning
  Representations}.

\bibitem[{He et~al.(2025)He, Liu, Xu, Shivade, Zhang, Srinivasan, and
  Kirchhoff}]{crispo}
Han He, Qianchu Liu, Lei Xu, Chaitanya Shivade, Yi~Zhang, Sundararajan
  Srinivasan, and Katrin Kirchhoff. 2025.
\newblock \href {http://arxiv.org/abs/2410.02748} {Crispo: Multi-aspect
  critique-suggestion-guided automatic prompt optimization for text
  generation}.

\bibitem[{Hendrycks et~al.(2020)Hendrycks, Burns, Basart, Zou, Mazeika, Song,
  and Steinhardt}]{MMLU}
Dan Hendrycks, Collin Burns, Steven Basart, Andy Zou, Mantas Mazeika,
  Dawn~Xiaodong Song, and Jacob Steinhardt. 2020.
\newblock \href {https://api.semanticscholar.org/CorpusID:221516475} {Measuring
  massive multitask language understanding}.
\newblock \emph{ArXiv}, abs/2009.03300.

\bibitem[{Hendrycks et~al.()Hendrycks, Burns, Kadavath, Arora, Basart, Tang,
  Song, and Steinhardt}]{MATH}
Dan Hendrycks, Collin Burns, Saurav Kadavath, Akul Arora, Steven Basart, Eric
  Tang, Dawn Song, and Jacob Steinhardt.
\newblock Measuring mathematical problem solving with the math dataset.
\newblock In \emph{Thirty-fifth Conference on Neural Information Processing
  Systems Datasets and Benchmarks Track (Round 2)}.

\bibitem[{Honovich et~al.(2022)Honovich, Shaham, Bowman, and
  Levy}]{InstructionInduction}
Or~Honovich, Uri Shaham, Samuel~R. Bowman, and Omer Levy. 2022.
\newblock \href {https://api.semanticscholar.org/CorpusID:248986755}
  {Instruction induction: From few examples to natural language task
  descriptions}.
\newblock \emph{ArXiv}, abs/2205.10782.

\bibitem[{Honovich et~al.(2023)Honovich, Shaham, Bowman, and
  Levy}]{instruction-induction}
Or~Honovich, Uri Shaham, Samuel~R. Bowman, and Omer Levy. 2023.
\newblock \href {https://doi.org/10.18653/v1/2023.acl-long.108} {Instruction
  induction: From few examples to natural language task descriptions}.
\newblock In \emph{Proceedings of the 61st Annual Meeting of the Association
  for Computational Linguistics (Volume 1: Long Papers)}, pages 1935--1952,
  Toronto, Canada. Association for Computational Linguistics.

\bibitem[{Hosseini et~al.(2014)Hosseini, Hajishirzi, Etzioni, and
  Kushman}]{AddSub}
Mohammad~Javad Hosseini, Hannaneh Hajishirzi, Oren Etzioni, and Nate Kushman.
  2014.
\newblock \href {https://api.semanticscholar.org/CorpusID:428579} {Learning to
  solve arithmetic word problems with verb categorization}.
\newblock In \emph{Conference on Empirical Methods in Natural Language
  Processing}.

\bibitem[{Hou et~al.(2023)Hou, O'Connor, Andreas, Chang, and
  Zhang}]{prompt-boosting}
Bairu Hou, Joe O'Connor, Jacob Andreas, Shiyu Chang, and Yang Zhang. 2023.
\newblock Promptboosting: black-box text classification with ten forward
  passes.
\newblock In \emph{Proceedings of the 40th International Conference on Machine
  Learning}, ICML'23. JMLR.org.

\bibitem[{Hsieh et~al.(2024)Hsieh, Si, Yu, and Dhillon}]{aelp}
Cho-Jui Hsieh, Si~Si, Felix Yu, and Inderjit Dhillon. 2024.
\newblock \href {https://doi.org/10.18653/v1/2024.findings-acl.634} {Automatic
  engineering of long prompts}.
\newblock In \emph{Findings of the Association for Computational Linguistics:
  ACL 2024}, page 10672—10685, Bangkok, Thailand. Association for
  Computational Linguistics.

\bibitem[{Hu and Liu(2004)}]{CR}
Minqing Hu and Bing Liu. 2004.
\newblock \href {https://api.semanticscholar.org/CorpusID:207155218} {Mining
  and summarizing customer reviews}.
\newblock \emph{Proceedings of the tenth ACM SIGKDD international conference on
  Knowledge discovery and data mining}.

\bibitem[{Huang et~al.(2019)Huang, Le~Bras, Bhagavatula, and Choi}]{cosmosqa}
Lifu Huang, Ronan Le~Bras, Chandra Bhagavatula, and Yejin Choi. 2019.
\newblock Cosmos qa: Machine reading comprehension with contextual commonsense
  reasoning.
\newblock In \emph{Proceedings of the 2019 Conference on Empirical Methods in
  Natural Language Processing and the 9th International Joint Conference on
  Natural Language Processing (EMNLP-IJCNLP)}, pages 2391--2401.

\bibitem[{Huang et~al.(2023)Huang, Huang, Yang, Ren, Liu, Li, Ye, Liu, Yin, and
  Zhao}]{huang2023make}
Rongjie Huang, Jiawei Huang, Dongchao Yang, Yi~Ren, Luping Liu, Mingze Li,
  Zhenhui Ye, Jinglin Liu, Xiang Yin, and Zhou Zhao. 2023.
\newblock Make-an-audio: Text-to-audio generation with prompt-enhanced
  diffusion models.
\newblock In \emph{International Conference on Machine Learning}, pages
  13916--13932. PMLR.

\bibitem[{Jafari et~al.(2024)Jafari, Mekala, Yu, and
  Berg-Kirkpatrick}]{morl-prompt}
Yasaman Jafari, Dheeraj Mekala, Rose Yu, and Taylor Berg-Kirkpatrick. 2024.
\newblock \href {http://arxiv.org/abs/2402.11711} {Morl-prompt: An empirical
  analysis of multi-objective reinforcement learning for discrete prompt
  optimization}.

\bibitem[{Ji et~al.(2024)Ji, Zhang, Wu, Zhang, Chen, GE, Sun, Chen, Shao, Xiao
  et~al.}]{ji2024prompt}
Yatai Ji, Jiacheng Zhang, Jie Wu, Shilong Zhang, Shoufa Chen, Chongjian GE,
  Peize Sun, Weifeng Chen, Wenqi Shao, Xuefeng Xiao, et~al. 2024.
\newblock Prompt-a-video: Prompt your video diffusion model via
  preference-aligned llm.
\newblock \emph{arXiv preprint arXiv:2412.15156}.

\bibitem[{Jiang et~al.(2020)Jiang, Bordia, Zhong, Dognin, Singh, and
  Bansal}]{hover}
Yichen Jiang, Shikha Bordia, Zheng Zhong, Charles Dognin, Maneesh~Kumar Singh,
  and Mohit Bansal. 2020.
\newblock \href {https://api.semanticscholar.org/CorpusID:226278099} {Hover: A
  dataset for many-hop fact extraction and claim verification}.
\newblock In \emph{Findings}.

\bibitem[{Jin et~al.(2024)Jin, Peng, Zhao, Wang, Xu, Han, Zhao, Zhong,
  Rajasekaran, and Metaxas}]{apeer}
Can Jin, Hongwu Peng, Shiyu Zhao, Zhenting Wang, Wujiang Xu, Ligong Han, Jiahui
  Zhao, Kai Zhong, Sanguthevar Rajasekaran, and Dimitris~N. Metaxas. 2024.
\newblock \href {http://arxiv.org/abs/2406.14449} {Apeer: Automatic prompt
  engineering enhances large language model reranking}.

\bibitem[{Jin et~al.(2020)Jin, Pan, Oufattole, Weng, Fang, and
  Szolovits}]{medQA}
Di~Jin, Eileen Pan, Nassim Oufattole, Wei-Hung Weng, Hanyi Fang, and Peter
  Szolovits. 2020.
\newblock \href {https://api.semanticscholar.org/CorpusID:221970190} {What
  disease does this patient have? a large-scale open domain question answering
  dataset from medical exams}.
\newblock \emph{ArXiv}, abs/2009.13081.

\bibitem[{Jin et~al.(2019)Jin, Dhingra, Liu, Cohen, and Lu}]{pubmedqa}
Qiao Jin, Bhuwan Dhingra, Zhengping Liu, William Cohen, and Xinghua Lu. 2019.
\newblock Pubmedqa: A dataset for biomedical research question answering.
\newblock In \emph{Proceedings of the 2019 Conference on Empirical Methods in
  Natural Language Processing and the 9th International Joint Conference on
  Natural Language Processing (EMNLP-IJCNLP)}, pages 2567--2577.

\bibitem[{Joko et~al.(2024)Joko, Chatterjee, Ramsay, De~Vries, Dalton, and
  Hasibi}]{gate}
Hideaki Joko, Shubham Chatterjee, Andrew Ramsay, Arjen~P De~Vries, Jeff Dalton,
  and Faegheh Hasibi. 2024.
\newblock Doing personal laps: Llm-augmented dialogue construction for
  personalized multi-session conversational search.
\newblock In \emph{Proceedings of the 47th International ACM SIGIR Conference
  on Research and Development in Information Retrieval}, pages 796--806.

\bibitem[{Juneja et~al.(2024)Juneja, Natarajan, Li, Jiao, and
  Sharma}]{uniprompt}
Gurusha Juneja, Nagarajan Natarajan, Hua Li, Jian Jiao, and Amit Sharma. 2024.
\newblock Task facet learning: A structured approach to prompt optimization.
\newblock \emph{arXiv preprint arXiv:2406.10504}.

\bibitem[{Jurgens et~al.(2018)Jurgens, Kumar, Hoover, McFarland, and
  Jurafsky}]{citationintent}
David Jurgens, Srijan Kumar, Raine Hoover, Daniel~A. McFarland, and Dan
  Jurafsky. 2018.
\newblock \href {https://api.semanticscholar.org/CorpusID:51917388} {Measuring
  the evolution of a scientific field through citation frames}.
\newblock \emph{Transactions of the Association for Computational Linguistics},
  6:391--406.

\bibitem[{Khattab et~al.(2022)Khattab, Santhanam, Li, Hall, Liang, Potts, and
  Zaharia}]{dsp}
Omar Khattab, Keshav Santhanam, Xiang~Lisa Li, David Hall, Percy Liang,
  Christopher Potts, and Matei Zaharia. 2022.
\newblock Demonstrate-search-predict: Composing retrieval and language models
  for knowledge-intensive nlp.
\newblock \emph{arXiv preprint arXiv:2212.14024}.

\bibitem[{Khattab et~al.(2024)Khattab, Singhvi, Maheshwari, Zhang, Santhanam,
  Vardhamanan, Haq, Sharma, Joshi, Moazam, Miller, Zaharia, and Potts}]{dspy}
Omar Khattab, Arnav Singhvi, Paridhi Maheshwari, Zhiyuan Zhang, Keshav
  Santhanam, Sri Vardhamanan, Saiful Haq, Ashutosh Sharma, Thomas~T. Joshi,
  Hanna Moazam, Heather Miller, Matei Zaharia, and Christopher Potts. 2024.
\newblock Dspy: Compiling declarative language model calls into self-improving
  pipelines.

\bibitem[{Kiesel et~al.(2019)Kiesel, Mestre, Shukla, Vincent, Adineh, Corney,
  Stein, and Potthast}]{HyperPartisan}
Johannes Kiesel, Maria Mestre, Rishabh Shukla, Emmanuel Vincent, Payam Adineh,
  D.~Corney, Benno Stein, and Martin Potthast. 2019.
\newblock \href {https://api.semanticscholar.org/CorpusID:120224153}
  {Semeval-2019 task 4: Hyperpartisan news detection}.
\newblock In \emph{International Workshop on Semantic Evaluation}.

\bibitem[{Kojima et~al.(2023)Kojima, Gu, Reid, Matsuo, and Iwasawa}]{zeroshot}
Takeshi Kojima, Shixiang~Shane Gu, Machel Reid, Yutaka Matsuo, and Yusuke
  Iwasawa. 2023.
\newblock \href {http://arxiv.org/abs/2205.11916} {Large language models are
  zero-shot reasoners}.

\bibitem[{Koncel-Kedziorski et~al.(2015)Koncel-Kedziorski, Hajishirzi,
  Sabharwal, Etzioni, and Ang}]{SingleEQ}
Rik Koncel-Kedziorski, Hannaneh Hajishirzi, Ashish Sabharwal, Oren Etzioni, and
  Siena~Dumas Ang. 2015.
\newblock \href {https://api.semanticscholar.org/CorpusID:4894130} {Parsing
  algebraic word problems into equations}.
\newblock \emph{Transactions of the Association for Computational Linguistics},
  3:585--597.

\bibitem[{Kong et~al.(2024)Kong, Hombaiah, Zhang, Mei, and
  Bendersky}]{prewrite}
Weize Kong, Spurthi~Amba Hombaiah, Mingyang Zhang, Qiaozhu Mei, and Michael
  Bendersky. 2024.
\newblock \href {http://arxiv.org/abs/2401.08189} {Prewrite: Prompt rewriting
  with reinforcement learning}.

\bibitem[{Kumar et~al.(2024)Kumar, Venkata, Khandelwal, Santra, Agrawal, and
  Gupta}]{sculpt}
Shanu Kumar, Akhila~Yesantarao Venkata, Shubhanshu Khandelwal, Bishal Santra,
  Parag Agrawal, and Manish Gupta. 2024.
\newblock \href {http://arxiv.org/abs/2410.20788} {Sculpt: Systematic tuning of
  long prompts}.

\bibitem[{Kwiatkowski et~al.(2019)Kwiatkowski, Palomaki, Redfield, Collins,
  Parikh, Alberti, Epstein, Polosukhin, Devlin, Lee et~al.}]{NQ}
Tom Kwiatkowski, Jennimaria Palomaki, Olivia Redfield, Michael Collins, Ankur
  Parikh, Chris Alberti, Danielle Epstein, Illia Polosukhin, Jacob Devlin,
  Kenton Lee, et~al. 2019.
\newblock Natural questions: a benchmark for question answering research.
\newblock \emph{Transactions of the Association for Computational Linguistics},
  7:453--466.

\bibitem[{Lai et~al.(2017)Lai, Xie, Liu, Yang, and Hovy}]{RACE}
Guokun Lai, Qizhe Xie, Hanxiao Liu, Yiming Yang, and Eduard Hovy. 2017.
\newblock Race: Large-scale reading comprehension dataset from examinations.
\newblock \emph{arXiv preprint arXiv:1704.04683}.

\bibitem[{Lee et~al.(2019)Lee, Chang, and Toutanova}]{open-squad}
Kenton Lee, Ming-Wei Chang, and Kristina Toutanova. 2019.
\newblock \href {https://api.semanticscholar.org/CorpusID:173990818} {Latent
  retrieval for weakly supervised open domain question answering}.
\newblock \emph{ArXiv}, abs/1906.00300.

\bibitem[{Lester et~al.(2021)Lester, Al-Rfou, and Constant}]{soft-prompts}
Brian Lester, Rami Al-Rfou, and Noah Constant. 2021.
\newblock \href {https://doi.org/10.18653/v1/2021.emnlp-main.243} {The power of
  scale for parameter-efficient prompt tuning}.
\newblock In \emph{Proceedings of the 2021 Conference on Empirical Methods in
  Natural Language Processing}, pages 3045--3059, Online and Punta Cana,
  Dominican Republic. Association for Computational Linguistics.

\bibitem[{Levesque et~al.(2011)Levesque, Davis, and
  Morgenstern}]{WinogradSchema}
Hector~J. Levesque, Ernest Davis, and L.~Morgenstern. 2011.
\newblock \href {https://api.semanticscholar.org/CorpusID:15710851} {The
  winograd schema challenge}.
\newblock In \emph{AAAI Spring Symposium: Logical Formalizations of Commonsense
  Reasoning}.

\bibitem[{Li et~al.(2023{\natexlab{a}})Li, Wang, Guo, Song, Tan, Hassan,
  Menezes, Xiao, Bian, and Zhu}]{DTG}
Bei Li, Rui Wang, Junliang Guo, Kaitao Song, Xu~Tan, Hany Hassan, Arul Menezes,
  Tong Xiao, Jiang Bian, and JingBo Zhu. 2023{\natexlab{a}}.
\newblock \href {http://arxiv.org/abs/2305.19835} {Deliberate then generate:
  Enhanced prompting framework for text generation}.

\bibitem[{Li et~al.(2023{\natexlab{b}})Li, Wang, Zhang, Zhu, Hou, Lian, Luo,
  Yang, and Xie}]{li2023large}
Cheng Li, Jindong Wang, Yixuan Zhang, Kaijie Zhu, Wenxin Hou, Jianxun Lian,
  Fang Luo, Qiang Yang, and Xing Xie. 2023{\natexlab{b}}.
\newblock Large language models understand and can be enhanced by emotional
  stimuli.
\newblock \emph{arXiv preprint arXiv:2307.11760}.

\bibitem[{Li et~al.(2010)Li, Chu, Langford, and Schapire}]{lin-ucb}
Lihong Li, Wei Chu, John Langford, and Robert~E. Schapire. 2010.
\newblock \href {https://doi.org/10.1145/1772690.1772758} {A contextual-bandit
  approach to personalized news article recommendation}.
\newblock In \emph{Proceedings of the 19th International Conference on World
  Wide Web}, WWW '10, page 661–670, New York, NY, USA. Association for
  Computing Machinery.

\bibitem[{Li et~al.(2023{\natexlab{c}})Li, Wang, Feng, Cao, Zhang, and
  Chua}]{gpo}
Moxin Li, Wenjie Wang, Fuli Feng, Yixin Cao, Jizhi Zhang, and Tat-Seng Chua.
  2023{\natexlab{c}}.
\newblock \href {https://doi.org/10.18653/v1/2023.emnlp-main.95} {Robust prompt
  optimization for large language models against distribution shifts}.
\newblock In \emph{Proceedings of the 2023 Conference on Empirical Methods in
  Natural Language Processing}, pages 1539--1554, Singapore. Association for
  Computational Linguistics.

\bibitem[{Li et~al.(2023{\natexlab{d}})Li, Peng, He, Galley, Gao, and
  Yan}]{directional-stimulus}
Zekun Li, Baolin Peng, Pengcheng He, Michel Galley, Jianfeng Gao, and Xifeng
  Yan. 2023{\natexlab{d}}.
\newblock Guiding large language models via directional stimulus prompting.
\newblock \emph{arXiv preprint arXiv:2302.11520}.

\bibitem[{Lin et~al.(2022)Lin, Hilton, and Evans}]{truthfulqa}
Stephanie Lin, Jacob Hilton, and Owain Evans. 2022.
\newblock Truthfulqa: Measuring how models mimic human falsehoods.
\newblock In \emph{Proceedings of the 60th Annual Meeting of the Association
  for Computational Linguistics (Volume 1: Long Papers)}, pages 3214--3252.

\bibitem[{Lin et~al.(2014)Lin, Maire, Belongie, Hays, Perona, Ramanan,
  Doll{\'a}r, and Zitnick}]{mscoco}
Tsung-Yi Lin, Michael Maire, Serge Belongie, James Hays, Pietro Perona, Deva
  Ramanan, Piotr Doll{\'a}r, and C~Lawrence Zitnick. 2014.
\newblock Microsoft coco: Common objects in context.
\newblock In \emph{Computer Vision--ECCV 2014: 13th European Conference,
  Zurich, Switzerland, September 6-12, 2014, Proceedings, Part V 13}, pages
  740--755. Springer.

\bibitem[{Lin et~al.(2024)Lin, Dai, Verma, Ng, Jaillet, and Low}]{apohf}
Xiaoqiang Lin, Zhongxiang Dai, Arun Verma, See-Kiong Ng, Patrick Jaillet, and
  Bryan Kian~Hsiang Low. 2024.
\newblock \href {http://arxiv.org/abs/2405.17346} {Prompt optimization with
  human feedback}.

\bibitem[{Ling et~al.(2017)Ling, Yogatama, Dyer, and Blunsom}]{AquaRat}
Wang Ling, Dani Yogatama, Chris Dyer, and Phil Blunsom. 2017.
\newblock \href {https://api.semanticscholar.org/CorpusID:12777818} {Program
  induction by rationale generation: Learning to solve and explain algebraic
  word problems}.
\newblock In \emph{Annual Meeting of the Association for Computational
  Linguistics}.

\bibitem[{Liu et~al.(2024{\natexlab{a}})Liu, Lin, Hewitt, Paranjape,
  Bevilacqua, Petroni, and Liang}]{liu2024lost}
Nelson~F Liu, Kevin Lin, John Hewitt, Ashwin Paranjape, Michele Bevilacqua,
  Fabio Petroni, and Percy Liang. 2024{\natexlab{a}}.
\newblock Lost in the middle: How language models use long contexts.
\newblock \emph{Transactions of the Association for Computational Linguistics},
  12:157--173.

\bibitem[{Liu et~al.(2023)Liu, Chen, Qu, Tang, and Ong}]{lmea}
Shengcai Liu, Caishun Chen, Xinghua Qu, Ke~Tang, and Yew~Soon Ong. 2023.
\newblock \href {https://api.semanticscholar.org/CorpusID:264829031} {Large
  language models as evolutionary optimizers}.
\newblock \emph{2024 IEEE Congress on Evolutionary Computation (CEC)}, pages
  1--8.

\bibitem[{Liu et~al.(2024{\natexlab{b}})Liu, Yu, Lin, Pathak, and
  Ramanan}]{liu2024language}
Shihong Liu, Samuel Yu, Zhiqiu Lin, Deepak Pathak, and Deva Ramanan.
  2024{\natexlab{b}}.
\newblock Language models as black-box optimizers for vision-language models.
\newblock In \emph{Proceedings of the IEEE/CVF Conference on Computer Vision
  and Pattern Recognition}, pages 12687--12697.

\bibitem[{Liu et~al.(2024{\natexlab{c}})Liu, Yu, Zhang, Zhang, and
  Xiao}]{universality}
Xiaogeng Liu, Zhiyuan Yu, Yizhe Zhang, Ning Zhang, and Chaowei Xiao.
  2024{\natexlab{c}}.
\newblock \href {http://arxiv.org/abs/2403.04957} {Automatic and universal
  prompt injection attacks against large language models}.

\bibitem[{Liu et~al.(2024{\natexlab{d}})Liu, He, Yao, Ji, Tao, Du, Li, Gao,
  Zhang, Yang et~al.}]{liu2024you}
Yilun Liu, Minggui He, Feiyu Yao, Yuhe Ji, Shimin Tao, Jingzhou Du, Duan Li,
  Jian Gao, Li~Zhang, Hao Yang, et~al. 2024{\natexlab{d}}.
\newblock What do you want? user-centric prompt generation for text-to-image
  synthesis via multi-turn guidance.
\newblock \emph{arXiv preprint arXiv:2408.12910}.

\bibitem[{Long et~al.(2024)Long, Zhao, Brown, Xie, Zhao, Chen, Kawaguchi,
  Shieh, and He}]{adv-icl}
Xuan~Do Long, Yiran Zhao, Hannah Brown, Yuxi Xie, James~Xu Zhao, Nancy~F. Chen,
  Kenji Kawaguchi, Michael Shieh, and Junxian He. 2024.
\newblock \href {https://doi.org/10.18653/v1/2024.acl-long.395} {Prompt
  optimization via adversarial in-context learning}.
\newblock In \emph{Proceedings of the 62nd Annual Meeting of the Association
  for Computational Linguistics (Volume 1: Long Papers)}, pages 7308--7327,
  Bangkok, Thailand. Association for Computational Linguistics.

\bibitem[{Lowe et~al.(2015)Lowe, Pow, Serban, and Pineau}]{UbuntuDialog}
Ryan Lowe, Nissan Pow, Iulian Serban, and Joelle Pineau. 2015.
\newblock \href {https://api.semanticscholar.org/CorpusID:8379583} {The ubuntu
  dialogue corpus: A large dataset for research in unstructured multi-turn
  dialogue systems}.
\newblock In \emph{SIGDIAL Conference}.

\bibitem[{Lu et~al.(2025)Lu, An, Zhang, He, Yin, and Sun}]{fipo}
Junru Lu, Siyu An, Min Zhang, Yulan He, Di~Yin, and Xing Sun. 2025.
\newblock \href {https://aclanthology.org/2025.coling-main.731/} {{FIPO}:
  Free-form instruction-oriented prompt optimization with preference dataset
  and modular fine-tuning schema}.
\newblock In \emph{Proceedings of the 31st International Conference on
  Computational Linguistics}, page 11029—11047, Abu Dhabi, UAE. Association
  for Computational Linguistics.

\bibitem[{Lu et~al.(2021)Lu, Bartolo, Moore, Riedel, and
  Stenetorp}]{mpqatrecsubj}
Yao Lu, Max Bartolo, Alastair Moore, Sebastian Riedel, and Pontus Stenetorp.
  2021.
\newblock \href {https://api.semanticscholar.org/CorpusID:233296494}
  {Fantastically ordered prompts and where to find them: Overcoming few-shot
  prompt order sensitivity}.
\newblock In \emph{Annual Meeting of the Association for Computational
  Linguistics}.

\bibitem[{Lu et~al.(2024)Lu, Wang, Tang, Riedel, and
  Stenetorp}]{random-separators}
Yao Lu, Jiayi Wang, Raphael Tang, Sebastian Riedel, and Pontus Stenetorp. 2024.
\newblock \href {https://doi.org/10.18653/v1/2024.naacl-long.122} {Strings from
  the library of babel: Random sampling as a strong baseline for prompt
  optimisation}.
\newblock In \emph{Proceedings of the 2024 Conference of the North American
  Chapter of the Association for Computational Linguistics: Human Language
  Technologies (Volume 1: Long Papers)}, page 2221—2231, Mexico City, Mexico.
  Association for Computational Linguistics.

\bibitem[{Luan et~al.(2018)Luan, He, Ostendorf, and Hajishirzi}]{sciERC}
Yi~Luan, Luheng He, Mari Ostendorf, and Hannaneh Hajishirzi. 2018.
\newblock \href {https://api.semanticscholar.org/CorpusID:52118895} {Multi-task
  identification of entities, relations, and coreference for scientific
  knowledge graph construction}.
\newblock \emph{ArXiv}, abs/1808.09602.

\bibitem[{Maas et~al.(2011)Maas, Daly, Pham, Huang, Ng, and Potts}]{imdb}
Andrew Maas, Raymond~E Daly, Peter~T Pham, Dan Huang, Andrew~Y Ng, and
  Christopher Potts. 2011.
\newblock Learning word vectors for sentiment analysis.
\newblock In \emph{Proceedings of the 49th annual meeting of the association
  for computational linguistics: Human language technologies}, pages 142--150.

\bibitem[{Ma{\~n}as et~al.(2024)Ma{\~n}as, Astolfi, Hall, Ross, Urbanek,
  Williams, Agrawal, Romero-Soriano, and Drozdzal}]{manas2024improving}
Oscar Ma{\~n}as, Pietro Astolfi, Melissa Hall, Candace Ross, Jack Urbanek,
  Adina Williams, Aishwarya Agrawal, Adriana Romero-Soriano, and Michal
  Drozdzal. 2024.
\newblock Improving text-to-image consistency via automatic prompt
  optimization.
\newblock \emph{arXiv preprint arXiv:2403.17804}.

\bibitem[{McCann et~al.(2018)McCann, Keskar, Xiong, and Socher}]{decanlp}
Bryan McCann, Nitish~Shirish Keskar, Caiming Xiong, and Richard Socher. 2018.
\newblock The natural language decathlon: Multitask learning as question
  answering.
\newblock \emph{arXiv preprint arXiv:1806.08730}.

\bibitem[{Melamed et~al.(2024)Melamed, McCabe, Wakhare, Kim, Huang, and
  Boix-Adsera}]{propane}
Rimon Melamed, Lucas~H. McCabe, Tanay Wakhare, Yejin Kim, H.~Howie Huang, and
  Enric Boix-Adsera. 2024.
\newblock \href {http://arxiv.org/abs/2311.07064} {Prompts have evil twins}.

\bibitem[{Mirza et~al.(2024)Mirza, Zhao, Mao, Doveh, Lin, Gavrikov, Dorkenwald,
  Yang, Jha, Wakaki et~al.}]{mirza2024glov}
M~Jehanzeb Mirza, Mengjie Zhao, Zhuoyuan Mao, Sivan Doveh, Wei Lin, Paul
  Gavrikov, Michael Dorkenwald, Shiqi Yang, Saurav Jha, Hiromi Wakaki, et~al.
  2024.
\newblock Glov: Guided large language models as implicit optimizers for vision
  language models.
\newblock \emph{arXiv preprint arXiv:2410.06154}.

\bibitem[{Mishra et~al.(2021)Mishra, Khashabi, Baral, and
  Hajishirzi}]{naturalinstructions}
Swaroop Mishra, Daniel Khashabi, Chitta Baral, and Hannaneh Hajishirzi. 2021.
\newblock \href {https://api.semanticscholar.org/CorpusID:237421373}
  {Cross-task generalization via natural language crowdsourcing instructions}.
\newblock In \emph{Annual Meeting of the Association for Computational
  Linguistics}.

\bibitem[{Mollas et~al.(2020)Mollas, Chrysopoulou, Karlos, and
  Tsoumakas}]{ethos}
Ioannis Mollas, Zoe Chrysopoulou, Stamatis Karlos, and Grigorios Tsoumakas.
  2020.
\newblock Ethos: an online hate speech detection dataset.
\newblock \emph{arXiv preprint arXiv:2006.08328}.

\bibitem[{Nallapati et~al.(2016)Nallapati, Zhou, dos Santos, Çaglar
  G{\"u}lçehre, and Xiang}]{CNNDailyMail}
Ramesh Nallapati, Bowen Zhou, C{\'i}cero~Nogueira dos Santos, Çaglar
  G{\"u}lçehre, and Bing Xiang. 2016.
\newblock \href {https://api.semanticscholar.org/CorpusID:8928715} {Abstractive
  text summarization using sequence-to-sequence rnns and beyond}.
\newblock In \emph{Conference on Computational Natural Language Learning}.

\bibitem[{Narayan et~al.(2018)Narayan, Cohen, and Lapata}]{XSUM}
Shashi Narayan, Shay~B. Cohen, and Mirella Lapata. 2018.
\newblock \href {https://api.semanticscholar.org/CorpusID:215768182} {Don’t
  give me the details, just the summary! topic-aware convolutional neural
  networks for extreme summarization}.
\newblock \emph{ArXiv}, abs/1808.08745.

\bibitem[{Nezhadarya et~al.(2019)Nezhadarya, Liu, and Liu}]{boxnet}
Ehsan Nezhadarya, Yang Liu, and Bingbing Liu. 2019.
\newblock Boxnet: A deep learning method for 2d bounding box estimation from
  bird's-eye view point cloud.
\newblock In \emph{2019 IEEE Intelligent Vehicles Symposium (IV)}, pages
  1557--1564. IEEE.

\bibitem[{Nie et~al.(2019)Nie, Williams, Dinan, Bansal, Weston, and
  Kiela}]{anli}
Yixin Nie, Adina Williams, Emily Dinan, Mohit Bansal, Jason Weston, and Douwe
  Kiela. 2019.
\newblock \href {https://api.semanticscholar.org/CorpusID:207756753}
  {Adversarial nli: A new benchmark for natural language understanding}.
\newblock \emph{ArXiv}, abs/1910.14599.

\bibitem[{Novikova et~al.(2017)Novikova, Dusek, and Rieser}]{E2ENLG}
Jekaterina Novikova, Ondrej Dusek, and Verena Rieser. 2017.
\newblock \href {https://api.semanticscholar.org/CorpusID:19662556} {The e2e
  dataset: New challenges for end-to-end generation}.
\newblock \emph{ArXiv}, abs/1706.09254.

\bibitem[{Opsahl-Ong et~al.(2024)Opsahl-Ong, Ryan, Purtell, Broman, Potts,
  Zaharia, and Khattab}]{mipro}
Krista Opsahl-Ong, Michael~J Ryan, Josh Purtell, David Broman, Christopher
  Potts, Matei Zaharia, and Omar Khattab. 2024.
\newblock \href {https://doi.org/10.18653/v1/2024.emnlp-main.525} {Optimizing
  instructions and demonstrations for multi-stage language model programs}.
\newblock In \emph{Proceedings of the 2024 Conference on Empirical Methods in
  Natural Language Processing}, page 9340—9366, Miami, Florida, USA.
  Association for Computational Linguistics.

\bibitem[{Ouyang et~al.(2022)Ouyang, Wu, Jiang, Almeida, Wainwright, Mishkin,
  Zhang, Agarwal, Slama, Ray, Schulman, Hilton, Kelton, Miller, Simens, Askell,
  Welinder, Christiano, Leike, and Lowe}]{instruction-alignment}
Long Ouyang, Jeff Wu, Xu~Jiang, Diogo Almeida, Carroll~L. Wainwright, Pamela
  Mishkin, Chong Zhang, Sandhini Agarwal, Katarina Slama, Alex Ray, John
  Schulman, Jacob Hilton, Fraser Kelton, Luke Miller, Maddie Simens, Amanda
  Askell, Peter Welinder, Paul Christiano, Jan Leike, and Ryan Lowe. 2022.
\newblock \href {http://arxiv.org/abs/2203.02155} {Training language models to
  follow instructions with human feedback}.

\bibitem[{Pal et~al.(2022)Pal, Umapathi, and Sankarasubbu}]{MedMCQA}
Ankit Pal, Logesh~Kumar Umapathi, and Malaikannan Sankarasubbu. 2022.
\newblock Medmcqa: A large-scale multi-subject multi-choice dataset for medical
  domain question answering.
\newblock In \emph{Conference on health, inference, and learning}, pages
  248--260. PMLR.

\bibitem[{Pan et~al.(2024)Pan, Xing, Diao, Sun, Liu, Shum, Zhang, Pi, and
  Zhang}]{plum}
Rui Pan, Shuo Xing, Shizhe Diao, Wenhe Sun, Xiang Liu, KaShun Shum, Jipeng
  Zhang, Renjie Pi, and Tong Zhang. 2024.
\newblock \href {https://doi.org/10.18653/v1/2024.findings-acl.129} {Plum:
  Prompt learning using metaheuristics}.
\newblock In \emph{Findings of the Association for Computational Linguistics:
  ACL 2024}, page 2177—2197, Bangkok, Thailand. Association for Computational
  Linguistics.

\bibitem[{Pang and Lee(2004)}]{subj}
Bo~Pang and Lillian Lee. 2004.
\newblock \href {https://api.semanticscholar.org/CorpusID:388} {A sentimental
  education: Sentiment analysis using subjectivity summarization based on
  minimum cuts}.
\newblock \emph{ArXiv}, cs.CL/0409058.

\bibitem[{Pang and Lee(2005)}]{MR}
Bo~Pang and Lillian Lee. 2005.
\newblock \href {https://api.semanticscholar.org/CorpusID:3264224} {Seeing
  stars: Exploiting class relationships for sentiment categorization with
  respect to rating scales}.
\newblock In \emph{Annual Meeting of the Association for Computational
  Linguistics}.

\bibitem[{Patel et~al.(2021)Patel, Bhattamishra, and Goyal}]{Svamp}
Arkil Patel, S.~Bhattamishra, and Navin Goyal. 2021.
\newblock \href {https://api.semanticscholar.org/CorpusID:232223322} {Are nlp
  models really able to solve simple math word problems?}
\newblock In \emph{North American Chapter of the Association for Computational
  Linguistics}.

\bibitem[{Pilehvar and Camacho-Collados(2019)}]{WiC}
Mohammad~Taher Pilehvar and Jose Camacho-Collados. 2019.
\newblock Wic: the word-in-context dataset for evaluating context-sensitive
  meaning representations.
\newblock In \emph{Proceedings of the 2019 Conference of the North American
  Chapter of the Association for Computational Linguistics: Human Language
  Technologies, Volume 1 (Long and Short Papers)}, pages 1267--1273.

\bibitem[{Pitis et~al.(2023)Pitis, Zhang, Wang, and Ba}]{boosted-prompting}
Silviu Pitis, Michael~R Zhang, Andrew Wang, and Jimmy Ba. 2023.
\newblock Boosted prompt ensembles for large language models.
\newblock \emph{arXiv preprint arXiv:2304.05970}.

\bibitem[{Ponti et~al.(2020)Ponti, Glava{\v{s}}, Majewska, Liu, Vuli{\'c}, and
  Korhonen}]{xcopa}
Edoardo~Maria Ponti, Goran Glava{\v{s}}, Olga Majewska, Qianchu Liu, Ivan
  Vuli{\'c}, and Anna Korhonen. 2020.
\newblock Xcopa: A multilingual dataset for causal commonsense reasoning.
\newblock \emph{arXiv preprint arXiv:2005.00333}.

\bibitem[{Prasad et~al.(2023)Prasad, Hase, Zhou, and Bansal}]{grips}
Archiki Prasad, Peter Hase, Xiang Zhou, and Mohit Bansal. 2023.
\newblock \href {http://arxiv.org/abs/2203.07281} {Grips: Gradient-free,
  edit-based instruction search for prompting large language models}.

\bibitem[{Pryzant et~al.(2023)Pryzant, Iter, Li, Lee, Zhu, and Zeng}]{protegi}
Reid Pryzant, Dan Iter, Jerry Li, Yin Lee, Chenguang Zhu, and Michael Zeng.
  2023.
\newblock \href {https://doi.org/10.18653/v1/2023.emnlp-main.494} {Automatic
  prompt optimization with {\textquotedblleft}gradient
  descent{\textquotedblright} and beam search}.
\newblock In \emph{Proceedings of the 2023 Conference on Empirical Methods in
  Natural Language Processing}, page 7957—7968, Singapore. Association for
  Computational Linguistics.

\bibitem[{Qi et~al.(2018)Qi, Sachan, Felix, Padmanabhan, and Neubig}]{TedTalks}
Ye~Qi, Devendra~Singh Sachan, Matthieu Felix, Sarguna Padmanabhan, and Graham
  Neubig. 2018.
\newblock \href {https://api.semanticscholar.org/CorpusID:4929974} {When and
  why are pre-trained word embeddings useful for neural machine translation?}
\newblock \emph{ArXiv}, abs/1804.06323.

\bibitem[{Rajpurkar et~al.(2016)Rajpurkar, Zhang, Lopyrev, and Liang}]{qnli}
Pranav Rajpurkar, Jian Zhang, Konstantin Lopyrev, and Percy Liang. 2016.
\newblock \href {https://api.semanticscholar.org/CorpusID:11816014} {Squad:
  100,000+ questions for machine comprehension of text}.
\newblock In \emph{Conference on Empirical Methods in Natural Language
  Processing}.

\bibitem[{Rein et~al.(2023)Rein, Hou, Stickland, Petty, Pang, Dirani, Michael,
  and Bowman}]{GoogleProofQA}
David Rein, Betty~Li Hou, Asa~Cooper Stickland, Jackson Petty, Richard~Yuanzhe
  Pang, Julien Dirani, Julian Michael, and Samuel~R. Bowman. 2023.
\newblock \href {https://api.semanticscholar.org/CorpusID:265295009} {Gpqa: A
  graduate-level google-proof q\&a benchmark}.
\newblock \emph{ArXiv}, abs/2311.12022.

\bibitem[{Roemmele et~al.(2011)Roemmele, Bejan, and Gordon}]{Copa}
Melissa Roemmele, Cosmin~Adrian Bejan, and Andrew~S Gordon. 2011.
\newblock Choice of plausible alternatives: An evaluation of commonsense causal
  reasoning.
\newblock In \emph{2011 AAAI spring symposium series}.

\bibitem[{Roy and Roth(2016)}]{MultiArith}
Subhro Roy and Dan Roth. 2016.
\newblock \href {https://api.semanticscholar.org/CorpusID:560565} {Solving
  general arithmetic word problems}.
\newblock \emph{ArXiv}, abs/1608.01413.

\bibitem[{Sap et~al.(2019)Sap, Rashkin, Chen, Le~Bras, and Choi}]{socialIQA}
Maarten Sap, Hannah Rashkin, Derek Chen, Ronan Le~Bras, and Yejin Choi. 2019.
\newblock Social iqa: Commonsense reasoning about social interactions.
\newblock In \emph{Proceedings of the 2019 Conference on Empirical Methods in
  Natural Language Processing and the 9th International Joint Conference on
  Natural Language Processing (EMNLP-IJCNLP)}, pages 4463--4473.

\bibitem[{Schnabel and Neville(2024)}]{sammo}
Tobias Schnabel and Jennifer Neville. 2024.
\newblock \href {http://arxiv.org/abs/2404.02319} {Symbolic prompt program
  search: A structure-aware approach to efficient compile-time prompt
  optimization}.

\bibitem[{Schuhmann et~al.(2022)Schuhmann, Beaumont, Vencu, Gordon, Wightman,
  Cherti, Coombes, Katta, Mullis, Wortsman et~al.}]{laion}
Christoph Schuhmann, Romain Beaumont, Richard Vencu, Cade Gordon, Ross
  Wightman, Mehdi Cherti, Theo Coombes, Aarush Katta, Clayton Mullis, Mitchell
  Wortsman, et~al. 2022.
\newblock Laion-5b: An open large-scale dataset for training next generation
  image-text models.
\newblock \emph{Advances in Neural Information Processing Systems},
  35:25278--25294.

\bibitem[{Sclar et~al.()Sclar, Choi, Tsvetkov, and Suhr}]{sclarquantifying}
Melanie Sclar, Yejin Choi, Yulia Tsvetkov, and Alane Suhr.
\newblock Quantifying language models' sensitivity to spurious features in
  prompt design or: How i learned to start worrying about prompt formatting.
\newblock In \emph{The Twelfth International Conference on Learning
  Representations}.

\bibitem[{She et~al.(2023)She, Potts, Bowman, and Geiger}]{scone}
Jingyuan~Selena She, Christopher Potts, Sam Bowman, and Atticus Geiger. 2023.
\newblock \href {https://api.semanticscholar.org/CorpusID:258987746} {Scone:
  Benchmarking negation reasoning in language models with fine-tuning and
  in-context learning}.
\newblock In \emph{Annual Meeting of the Association for Computational
  Linguistics}.

\bibitem[{Shi et~al.(2024)Shi, Wang, Su, Luo, Yang, and Zhang}]{bat-prompt}
Zeru Shi, Zhenting Wang, Yongye Su, Weidi Luo, Fan Yang, and Yongfeng Zhang.
  2024.
\newblock \href {http://arxiv.org/abs/2412.18196} {Robustness-aware automatic
  prompt optimization}.

\bibitem[{Shin et~al.(2020)Shin, Razeghi, Logan~IV, Wallace, and
  Singh}]{autoprompt}
Taylor Shin, Yasaman Razeghi, Robert~L. Logan~IV, Eric Wallace, and Sameer
  Singh. 2020.
\newblock \href {https://doi.org/10.18653/v1/2020.emnlp-main.346}
  {{A}uto{P}rompt: {E}liciting {K}nowledge from {L}anguage {M}odels with
  {A}utomatically {G}enerated {P}rompts}.
\newblock In \emph{Proceedings of the 2020 Conference on Empirical Methods in
  Natural Language Processing (EMNLP)}, pages 4222--4235, Online. Association
  for Computational Linguistics.

\bibitem[{Shinn et~al.(2023)Shinn, Cassano, Berman, Gopinath, Narasimhan, and
  Yao}]{reflexion}
Noah Shinn, Federico Cassano, Edward Berman, Ashwin Gopinath, Karthik
  Narasimhan, and Shunyu Yao. 2023.
\newblock \href {http://arxiv.org/abs/2303.11366} {Reflexion: Language agents
  with verbal reinforcement learning}.

\bibitem[{Shinn et~al.(2024)Shinn, Cassano, Gopinath, Narasimhan, and
  Yao}]{LeetcodeHard}
Noah Shinn, Federico Cassano, Ashwin Gopinath, Karthik Narasimhan, and Shunyu
  Yao. 2024.
\newblock Reflexion: Language agents with verbal reinforcement learning.
\newblock \emph{Advances in Neural Information Processing Systems}, 36.

\bibitem[{Shridhar et~al.(2020)Shridhar, Yuan, C{\^o}t{\'e}, Bisk, Trischler,
  and Hausknecht}]{alfworld}
Mohit Shridhar, Xingdi Yuan, Marc-Alexandre C{\^o}t{\'e}, Yonatan Bisk, Adam
  Trischler, and Matthew Hausknecht. 2020.
\newblock Alfworld: Aligning text and embodied environments for interactive
  learning.
\newblock \emph{arXiv preprint arXiv:2010.03768}.

\bibitem[{Sinha et~al.(2024)Sinha, Cui, Das, and Zhang}]{sos}
Ankita Sinha, Wendi Cui, Kamalika Das, and Jiaxin Zhang. 2024.
\newblock \href {https://doi.org/10.18653/v1/2024.emnlp-industry.76} {Survival
  of the safest: Towards secure prompt optimization through interleaved
  multi-objective evolution}.
\newblock In \emph{Proceedings of the 2024 Conference on Empirical Methods in
  Natural Language Processing: Industry Track}, pages 1016--1027, Miami,
  Florida, US. Association for Computational Linguistics.

\bibitem[{Socher et~al.(2013)Socher, Perelygin, Wu, Chuang, Manning, Ng, and
  Potts}]{sst2}
Richard Socher, Alex Perelygin, Jean Wu, Jason Chuang, Christopher~D Manning,
  Andrew~Y Ng, and Christopher Potts. 2013.
\newblock Recursive deep models for semantic compositionality over a sentiment
  treebank.
\newblock In \emph{Proceedings of the 2013 conference on empirical methods in
  natural language processing}, pages 1631--1642.

\bibitem[{Sogancioglu et~al.(2017)Sogancioglu, {\"O}zt{\"u}rk, and
  {\"O}zg{\"u}r}]{biosimilar}
Gizem Sogancioglu, Hakime {\"O}zt{\"u}rk, and Arzucan {\"O}zg{\"u}r. 2017.
\newblock \href {https://api.semanticscholar.org/CorpusID:3778978} {Biosses: a
  semantic sentence similarity estimation system for the biomedical domain}.
\newblock \emph{Bioinformatics}, 33:i49 -- i58.

\bibitem[{Sordoni et~al.(2023)Sordoni, Yuan, C\^{o}t\'{e}, Pereira, Trischler,
  Xiao, Hosseini, Niedtner, and Le~Roux}]{dln}
Alessandro Sordoni, Eric Yuan, Marc-Alexandre C\^{o}t\'{e}, Matheus Pereira,
  Adam Trischler, Ziang Xiao, Arian Hosseini, Friederike Niedtner, and Nicolas
  Le~Roux. 2023.
\newblock \href
  {https://proceedings.neurips.cc/paper_files/paper/2023/file/b5afe13494c825089b1e3944fdaba212-Paper-Conference.pdf}
  {Joint prompt optimization of stacked llms using variational inference}.
\newblock In \emph{Advances in Neural Information Processing Systems},
  volume~36, pages 58128--58151. Curran Associates, Inc.

\bibitem[{Srivastava et~al.(2022)Srivastava, Rastogi, Rao, Shoeb, Abid, Fisch,
  Brown, Santoro, Gupta, Garriga-Alonso et~al.}]{bigbench}
Aarohi Srivastava, Abhinav Rastogi, Abhishek Rao, Abu Awal~Md Shoeb, Abubakar
  Abid, Adam Fisch, Adam~R Brown, Adam Santoro, Aditya Gupta, Adri{\`a}
  Garriga-Alonso, et~al. 2022.
\newblock Beyond the imitation game: Quantifying and extrapolating the
  capabilities of language models.
\newblock \emph{arXiv preprint arXiv:2206.04615}.

\bibitem[{Sun et~al.(2024{\natexlab{a}})Sun, H{\"u}y{\"u}k, and van~der
  Schaar}]{oirl}
Hao Sun, Alihan H{\"u}y{\"u}k, and Mihaela van~der Schaar. 2024{\natexlab{a}}.
\newblock \href {https://openreview.net/forum?id=N6o0ZtPzTg} {Query-dependent
  prompt evaluation and optimization with offline inverse {RL}}.
\newblock In \emph{The Twelfth International Conference on Learning
  Representations}.

\bibitem[{Sun et~al.(2023)Sun, Li, Xu, Homma, Cao, Wu, Jiao, and
  Charles}]{hint}
Hong Sun, Xue Li, Yinchuan Xu, Youkow Homma, Qi~Cao, Min Wu, Jian Jiao, and
  Denis Charles. 2023.
\newblock Autohint: Automatic prompt optimization with hint generation.
\newblock \emph{arXiv preprint arXiv:2307.07415}.

\bibitem[{Sun et~al.(2024{\natexlab{b}})Sun, Xu, Yin, Yang, Xu, Liu, Du, Chen,
  and Roth}]{fedbpt}
Jingwei Sun, Ziyue Xu, Hongxu Yin, Dong Yang, Daguang Xu, Yudong Liu, Zhixu Du,
  Yiran Chen, and Holger~R. Roth. 2024{\natexlab{b}}.
\newblock Fedbpt: efficient federated black-box prompt tuning for large
  language models.
\newblock In \emph{Proceedings of the 41st International Conference on Machine
  Learning}, ICML'24. JMLR.org.

\bibitem[{Suzgun et~al.(2023)Suzgun, Scales, Sch{\"a}rli, Gehrmann, Tay, Chung,
  Chowdhery, Le, Chi, Zhou et~al.}]{bbh}
Mirac Suzgun, Nathan Scales, Nathanael Sch{\"a}rli, Sebastian Gehrmann, Yi~Tay,
  Hyung~Won Chung, Aakanksha Chowdhery, Quoc Le, Ed~Chi, Denny Zhou, et~al.
  2023.
\newblock Challenging big-bench tasks and whether chain-of-thought can solve
  them.
\newblock In \emph{Findings of the Association for Computational Linguistics:
  ACL 2023}, pages 13003--13051.

\bibitem[{Talmor et~al.(2019)Talmor, Herzig, Lourie, and Berant}]{CSQA}
Alon Talmor, Jonathan Herzig, Nicholas Lourie, and Jonathan Berant. 2019.
\newblock \href {https://api.semanticscholar.org/CorpusID:53296520}
  {Commonsenseqa: A question answering challenge targeting commonsense
  knowledge}.
\newblock \emph{ArXiv}, abs/1811.00937.

\bibitem[{Trivedi et~al.(2025)Trivedi, Chakraborty, Reddy, Aggarwal, Bedi, and
  Atia}]{align-pro}
Prashant Trivedi, Souradip Chakraborty, Avinash Reddy, Vaneet Aggarwal,
  Amrit~Singh Bedi, and George~K. Atia. 2025.
\newblock \href {http://arxiv.org/abs/2501.03486} {Align-pro: A principled
  approach to prompt optimization for llm alignment}.

\bibitem[{Vaghani and Thummar(2023)}]{flipkart}
Nirali Vaghani and Mansi Thummar. 2023.
\newblock Flipkart product reviews with sentiment dataset.

\bibitem[{Voorhees and Tice(2000)}]{trec}
Ellen~M Voorhees and Dawn~M Tice. 2000.
\newblock Building a question answering test collection.
\newblock In \emph{Proceedings of the 23rd annual international ACM SIGIR
  conference on Research and development in information retrieval}, pages
  200--207.

\bibitem[{Wan et~al.(2024)Wan, Sun, Nakhost, and Arik}]{smart}
Xingchen Wan, Ruoxi Sun, Hootan Nakhost, and Sercan~O. Arik. 2024.
\newblock \href {http://arxiv.org/abs/2406.15708} {Teach better or show
  smarter? on instructions and exemplars in automatic prompt optimization}.

\bibitem[{Wang et~al.(2025)Wang, An, Cheng, Zhou, Hwang, and Hsieh}]{mop}
Ruochen Wang, Sohyun An, Minhao Cheng, Tianyi Zhou, Sung~Ju Hwang, and Cho-Jui
  Hsieh. 2025.
\newblock One prompt is not enough: automated construction of a
  mixture-of-expert prompts.
\newblock In \emph{Proceedings of the 41st International Conference on Machine
  Learning}, ICML'24. JMLR.org.

\bibitem[{Wang et~al.(2022{\natexlab{a}})Wang, Jansen, C{\^o}t{\'e}, and
  Ammanabrolu}]{scienceworld}
Ruoyao Wang, Peter Jansen, Marc-Alexandre C{\^o}t{\'e}, and Prithviraj
  Ammanabrolu. 2022{\natexlab{a}}.
\newblock Scienceworld: Is your agent smarter than a 5th grader?
\newblock In \emph{Proceedings of the 2022 Conference on Empirical Methods in
  Natural Language Processing}, pages 11279--11298.

\bibitem[{Wang(2017)}]{liar}
William~Yang Wang. 2017.
\newblock \href {https://api.semanticscholar.org/CorpusID:10326133} {“liar,
  liar pants on fire”: A new benchmark dataset for fake news detection}.
\newblock In \emph{Annual Meeting of the Association for Computational
  Linguistics}.

\bibitem[{Wang et~al.(2024{\natexlab{a}})Wang, Li, Wang, Bai, Luo, Zhang,
  Jojic, Xing, and Hu}]{promptagent}
Xinyuan Wang, Chenxi Li, Zhen Wang, Fan Bai, Haotian Luo, Jiayou Zhang, Nebojsa
  Jojic, Eric~P. Xing, and Zhiting Hu. 2024{\natexlab{a}}.
\newblock \href {https://openreview.net/forum?id=22pyNMuIoa} {Promptagent:
  Strategic planning with language models enables expert-level prompt
  optimization}.
\newblock In \emph{The Twelfth International Conference on Learning
  Representations, {ICLR} 2024, Vienna, Austria, May 7-11, 2024}.
  OpenReview.net.

\bibitem[{Wang et~al.(2022{\natexlab{b}})Wang, Kordi, Mishra, Liu, Smith,
  Khashabi, and Hajishirzi}]{SelfInstructEval}
Yizhong Wang, Yeganeh Kordi, Swaroop Mishra, Alisa Liu, Noah~A. Smith, Daniel
  Khashabi, and Hannaneh Hajishirzi. 2022{\natexlab{b}}.
\newblock \href {https://api.semanticscholar.org/CorpusID:254877310}
  {Self-instruct: Aligning language models with self-generated instructions}.
\newblock In \emph{Annual Meeting of the Association for Computational
  Linguistics}.

\bibitem[{Wang et~al.(2023)Wang, Kordi, Mishra, Liu, Smith, Khashabi, and
  Hajishirzi}]{self-instruct}
Yizhong Wang, Yeganeh Kordi, Swaroop Mishra, Alisa Liu, Noah~A. Smith, Daniel
  Khashabi, and Hannaneh Hajishirzi. 2023.
\newblock \href {https://doi.org/10.18653/v1/2023.acl-long.754} {Self-instruct:
  Aligning language models with self-generated instructions}.
\newblock In \emph{Proceedings of the 61st Annual Meeting of the Association
  for Computational Linguistics (Volume 1: Long Papers)}, pages 13484--13508,
  Toronto, Canada. Association for Computational Linguistics.

\bibitem[{Wang et~al.(2015)Wang, Berant, and Liang}]{overnight}
Yushi Wang, Jonathan Berant, and Percy Liang. 2015.
\newblock \href {https://api.semanticscholar.org/CorpusID:14472576} {Building a
  semantic parser overnight}.
\newblock In \emph{Annual Meeting of the Association for Computational
  Linguistics}.

\bibitem[{Wang et~al.(2024{\natexlab{b}})Wang, Bi, Pentyala, Ramnath,
  Chaudhuri, Mehrotra, Zixu, Zhu, Mao, Asur, Na, and
  Cheng}]{preference-alignment}
Zhichao Wang, Bin Bi, Shiva~Kumar Pentyala, Kiran Ramnath, Sougata Chaudhuri,
  Shubham Mehrotra, Zixu, Zhu, Xiang-Bo Mao, Sitaram Asur, Na, and Cheng.
  2024{\natexlab{b}}.
\newblock \href {http://arxiv.org/abs/2407.16216} {A comprehensive survey of
  llm alignment techniques: Rlhf, rlaif, ppo, dpo and more}.

\bibitem[{Warstadt et~al.(2018)Warstadt, Singh, and Bowman}]{cola}
Alex Warstadt, Amanpreet Singh, and Samuel~R. Bowman. 2018.
\newblock \href {https://api.semanticscholar.org/CorpusID:44072099} {Neural
  network acceptability judgments}.
\newblock \emph{Transactions of the Association for Computational Linguistics},
  7:625--641.

\bibitem[{Wiebe et~al.(2005)Wiebe, Wilson, and Cardie}]{MPQA}
Janyce Wiebe, Theresa Wilson, and Claire Cardie. 2005.
\newblock \href {https://api.semanticscholar.org/CorpusID:382842} {Annotating
  expressions of opinions and emotions in language}.
\newblock \emph{Language Resources and Evaluation}, 39:165--210.

\bibitem[{Williams et~al.(2017)Williams, Nangia, and Bowman}]{mnli}
Adina Williams, Nikita Nangia, and Samuel~R. Bowman. 2017.
\newblock \href {https://api.semanticscholar.org/CorpusID:3432876} {A
  broad-coverage challenge corpus for sentence understanding through
  inference}.
\newblock In \emph{North American Chapter of the Association for Computational
  Linguistics}.

\bibitem[{Wu et~al.(2024)Wu, Gao, Zhu, Zhou, Sun, Yang, Lou, Ding, and
  Yang}]{strago}
Yurong Wu, Yan Gao, Bin~Benjamin Zhu, Zineng Zhou, Xiaodi Sun, Sheng Yang,
  Jian-Guang Lou, Zhiming Ding, and Linjun Yang. 2024.
\newblock \href {https://doi.org/10.18653/v1/2024.findings-emnlp.588}
  {{S}tra{G}o: Harnessing strategic guidance for prompt optimization}.
\newblock In \emph{Findings of the Association for Computational Linguistics:
  EMNLP 2024}, pages 10043--10061, Miami, Florida, USA. Association for
  Computational Linguistics.

\bibitem[{Xian et~al.(2024)Xian, Samuel, Khoubsirat, Pradeep, Sultan, Florian,
  Roukos, Sil, Potts, and Khattab}]{path}
Jasper Xian, Saron Samuel, Faraz Khoubsirat, Ronak Pradeep, Md~Arafat Sultan,
  Radu Florian, Salim Roukos, Avirup Sil, Christopher Potts, and Omar Khattab.
  2024.
\newblock Prompts as auto-optimized training hyperparameters: Training
  best-in-class ir models from scratch with 10 gold labels.
\newblock \emph{arXiv preprint arXiv:2406.11706}.

\bibitem[{Xu et~al.(2022)Xu, Chen, Du, Shao, Yanggang, Li, and Yang}]{gps}
Hanwei Xu, Yujun Chen, Yulun Du, Nan Shao, Wang Yanggang, Haiyu Li, and Zhilin
  Yang. 2022.
\newblock Gps: Genetic prompt search for efficient few-shot learning.
\newblock In \emph{Proceedings of the 2022 Conference on Empirical Methods in
  Natural Language Processing}, pages 8162--8171.

\bibitem[{Xu et~al.(2012)Xu, Ritter, Dolan, Grishman, and Cherry}]{shakespeare}
Wei Xu, Alan Ritter, William~B. Dolan, Ralph Grishman, and Colin Cherry. 2012.
\newblock \href {https://api.semanticscholar.org/CorpusID:13050210}
  {Paraphrasing for style}.
\newblock In \emph{International Conference on Computational Linguistics}.

\bibitem[{Xu et~al.(2024)Xu, Banburski-Fahey, and Jojic}]{reprompting}
Weijia Xu, Andrzej Banburski-Fahey, and Nebojsa Jojic. 2024.
\newblock Reprompting: automated chain-of-thought prompt inference through
  gibbs sampling.
\newblock In \emph{Proceedings of the 41st International Conference on Machine
  Learning}, ICML'24. JMLR.org.

\bibitem[{Yang et~al.(2024{\natexlab{a}})Yang, Wang, Lu, Liu, Le, Zhou, and
  Chen}]{opro}
Chengrun Yang, Xuezhi Wang, Yifeng Lu, Hanxiao Liu, Quoc~V. Le, Denny Zhou, and
  Xinyun Chen. 2024{\natexlab{a}}.
\newblock \href {http://arxiv.org/abs/2309.03409} {Large language models as
  optimizers}.

\bibitem[{Yang et~al.(2024{\natexlab{b}})Yang, Wang, Lu, Liu, Le, Zhou, and
  Chen}]{abo}
Chengrun Yang, Xuezhi Wang, Yifeng Lu, Hanxiao Liu, Quoc~V Le, Denny Zhou, and
  Xinyun Chen. 2024{\natexlab{b}}.
\newblock \href {https://openreview.net/forum?id=Bb4VGOWELI} {Large language
  models as optimizers}.
\newblock In \emph{The Twelfth International Conference on Learning
  Representations}.

\bibitem[{Yang et~al.(2024{\natexlab{c}})Yang, Li, Li, Chen, Gao, Zhang, Li,
  and Feng}]{dapo}
Muchen Yang, Moxin Li, Yongle Li, Zijun Chen, Chongming Gao, Junqi Zhang,
  Yangyang Li, and Fuli Feng. 2024{\natexlab{c}}.
\newblock \href {https://doi.org/10.18653/v1/2024.findings-emnlp.709}
  {Dual-phase accelerated prompt optimization}.
\newblock In \emph{Findings of the Association for Computational Linguistics:
  EMNLP 2024}, pages 12163--12173, Miami, Florida, USA. Association for
  Computational Linguistics.

\bibitem[{Yang et~al.(2024{\natexlab{d}})Yang, Wu, Gao, Zhou, Zhu, Sun, Lou,
  Ding, Hu, Fang et~al.}]{ampo}
Sheng Yang, Yurong Wu, Yan Gao, Zineng Zhou, Bin~Benjamin Zhu, Xiaodi Sun,
  Jian-Guang Lou, Zhiming Ding, Anbang Hu, Yuan Fang, et~al.
  2024{\natexlab{d}}.
\newblock Ampo: Automatic multi-branched prompt optimization.
\newblock \emph{arXiv preprint arXiv:2410.08696}.

\bibitem[{Yang et~al.(2018)Yang, Qi, Zhang, Bengio, Cohen, Salakhutdinov, and
  Manning}]{hotpotqa}
Zhilin Yang, Peng Qi, Saizheng Zhang, Yoshua Bengio, William~W. Cohen, Ruslan
  Salakhutdinov, and Christopher~D. Manning. 2018.
\newblock \href {https://api.semanticscholar.org/CorpusID:52822214} {Hotpotqa:
  A dataset for diverse, explainable multi-hop question answering}.
\newblock In \emph{Conference on Empirical Methods in Natural Language
  Processing}.

\bibitem[{Ye et~al.(2024)Ye, Axmed, Pryzant, and Khani}]{pe2}
Qinyuan Ye, Maxamed Axmed, Reid Pryzant, and Fereshte Khani. 2024.
\newblock \href {http://arxiv.org/abs/2311.05661} {Prompt engineering a prompt
  engineer}.

\bibitem[{Yuksekgonul et~al.(2024)Yuksekgonul, Bianchi, Boen, Liu, Huang,
  Guestrin, and Zou}]{textgrad}
Mert Yuksekgonul, Federico Bianchi, Joseph Boen, Sheng Liu, Zhi Huang, Carlos
  Guestrin, and James Zou. 2024.
\newblock \href {http://arxiv.org/abs/2406.07496} {Textgrad: Automatic
  "differentiation" via text}.

\bibitem[{Zelle and Mooney(1996)}]{geoquery}
John~M. Zelle and Raymond~J. Mooney. 1996.
\newblock \href {https://api.semanticscholar.org/CorpusID:263135} {Learning to
  parse database queries using inductive logic programming}.
\newblock In \emph{AAAI/IAAI, Vol. 2}.

\bibitem[{Zellers et~al.(2019)Zellers, Holtzman, Bisk, Farhadi, and
  Choi}]{hellaswag}
Rowan Zellers, Ari Holtzman, Yonatan Bisk, Ali Farhadi, and Yejin Choi. 2019.
\newblock Hellaswag: Can a machine really finish your sentence?
\newblock In \emph{Proceedings of the 57th Annual Meeting of the Association
  for Computational Linguistics}, pages 4791--4800.

\bibitem[{Zhan et~al.(2024)Zhan, Xu, Tan, Song, and Xie}]{cople}
Pengwei Zhan, Zhen Xu, Qian Tan, Jie Song, and Ru~Xie. 2024.
\newblock \href {https://api.semanticscholar.org/CorpusID:270199843} {Unveiling
  the lexical sensitivity of llms: Combinatorial optimization for prompt
  enhancement}.
\newblock In \emph{Conference on Empirical Methods in Natural Language
  Processing}.

\bibitem[{Zhang et~al.(2024{\natexlab{a}})Zhang, Liu, Wang, Sun, Wang, Wang,
  and Cai}]{prefer}
Chenrui Zhang, Lin Liu, Chuyuan Wang, Xiao Sun, Hongyu Wang, Jinpeng Wang, and
  Mingchen Cai. 2024{\natexlab{a}}.
\newblock \href {https://doi.org/10.1609/aaai.v38i17.29924} {Prefer: prompt
  ensemble learning via feedback-reflect-refine}.
\newblock In \emph{Proceedings of the Thirty-Eighth AAAI Conference on
  Artificial Intelligence and Thirty-Sixth Conference on Innovative
  Applications of Artificial Intelligence and Fourteenth Symposium on
  Educational Advances in Artificial Intelligence}, AAAI'24/IAAI'24/EAAI'24.
  AAAI Press.

\bibitem[{Zhang et~al.(2024{\natexlab{b}})Zhang, Ergen, Logeswaran, Lee, and
  Jurgens}]{sprig}
Lechen Zhang, Tolga Ergen, Lajanugen Logeswaran, Moontae Lee, and David
  Jurgens. 2024{\natexlab{b}}.
\newblock \href {https://api.semanticscholar.org/CorpusID:273502098} {Sprig:
  Improving large language model performance by system prompt optimization}.
\newblock \emph{ArXiv}, abs/2410.14826.

\bibitem[{Zhang et~al.(2022)Zhang, Wang, Zhou, Schuurmans, and
  Gonzalez}]{tempera}
Tianjun Zhang, Xuezhi Wang, Denny Zhou, Dale Schuurmans, and Joseph~E.
  Gonzalez. 2022.
\newblock \href {http://arxiv.org/abs/2211.11890} {Tempera: Test-time prompting
  via reinforcement learning}.

\bibitem[{Zhang* et~al.(2020)Zhang*, Kishore*, Wu*, Weinberger, and
  Artzi}]{bert-score}
Tianyi Zhang*, Varsha Kishore*, Felix Wu*, Kilian~Q. Weinberger, and Yoav
  Artzi. 2020.
\newblock \href {https://openreview.net/forum?id=SkeHuCVFDr} {Bertscore:
  Evaluating text generation with bert}.
\newblock In \emph{International Conference on Learning Representations}.

\bibitem[{Zhang et~al.(2015)Zhang, Zhao, and LeCun}]{zhang2015character}
Xiang Zhang, Junbo~Jake Zhao, and Yann LeCun. 2015.
\newblock \href {https://api.semanticscholar.org/CorpusID:368182}
  {Character-level convolutional networks for text classification}.
\newblock In \emph{Neural Information Processing Systems}.

\bibitem[{Zheng et~al.(2023)Zheng, Chiang, Sheng, Zhuang, Wu, Zhuang, Lin, Li,
  Li, Xing, Zhang, Gonzalez, and Stoica}]{llmj}
Lianmin Zheng, Wei-Lin Chiang, Ying Sheng, Siyuan Zhuang, Zhanghao Wu, Yonghao
  Zhuang, Zi~Lin, Zhuohan Li, Dacheng Li, Eric~P. Xing, Hao Zhang, Joseph~E.
  Gonzalez, and Ion Stoica. 2023.
\newblock Judging llm-as-a-judge with mt-bench and chatbot arena.
\newblock In \emph{Proceedings of the 37th International Conference on Neural
  Information Processing Systems}, NIPS '23, Red Hook, NY, USA. Curran
  Associates Inc.

\bibitem[{Zhou et~al.(2023)Zhou, Wan, Vuli{\'c}, and Korhonen}]{claps}
Han Zhou, Xingchen Wan, Ivan Vuli{\'c}, and Anna Korhonen. 2023.
\newblock \href {https://doi.org/10.18653/v1/2023.findings-emnlp.870} {Survival
  of the most influential prompts: Efficient black-box prompt search via
  clustering and pruning}.
\newblock In \emph{Findings of the Association for Computational Linguistics:
  EMNLP 2023}, pages 13064--13077, Singapore. Association for Computational
  Linguistics.

\bibitem[{Zhou et~al.(2022)Zhou, Muresanu, Han, Paster, Pitis, Chan, and
  Ba}]{ape}
Yongchao Zhou, Andrei~Ioan Muresanu, Ziwen Han, Keiran Paster, Silviu Pitis,
  Harris Chan, and Jimmy Ba. 2022.
\newblock \href {http://arxiv.org/abs/2211.01910} {Large language models are
  human-level prompt engineers}.

\end{thebibliography}

\onecolumn
\section{Appendix}
\label{sec:appendix}

\subsection{Notation}
\label{notation}
We now define the notation of key terms and expressions used throughout the paper. 
\begin{enumerate}
\itemsep0em 
\item $T$ = Task type, $I$= Task instruction, $E={(xi,yi)}_{i=1}^e$ Few shot demonstrations in the prompt, $\tau$= Template delimiters, z = CoT recipe for a task-instance, $z_i \in I_i$
\item{$M_{task}$ target model, $M_{APO}$ APO system}
\item $\rho=concat([s_1,s_2,\ldots,s_m])=concat(I,\tau,E)$ Prompt composed of m sentences, which comprise of Instruction, template delimiters and few-shot demonstrations. 
\item $D=\{(x_i,y_i)\}_{i=1}^m$ collection of m input-output pairs. $D_{val}$ is the validation set used to validate prompt performance, $D_{train}$ is the training set used to finetune the language model(Reprompting). 
\item $\{f_1,f_2,\ldots\} \in F$ metric function upon which to evaluate task-prompt performance
\item $r:S\times A\rightarrow R$= reward model score, where S is the state-space and A is the action-space
\item $|V|$ = length of vocabulary
\item $\phi:S\in V_* \rightarrow R_d$ embedding function which takes in a sentence generated as a finite sequence of tokens belonging to a vocabulary V, and generating a floating point array representation of dimension d
\item $\rho_*=argmax_{\rho \in V_*}E_{D_{val}}[f_i(\rho)]$ The best performing prompt based on the metric score on validation set 
\item $k$ = number of candidates for top-K search, $B$ = Beam width for beam search, $N$ = number of iterations for search
\item $C$ = number of experts in a Mixture of Experts approach (MOP), $\mu_C$= cluster centroid of cluster C (MOP). 
\item $LLM_{target}$= target model which will be used for inference, $LLM_{rewriter}$= rewriter model which will be used for rewriter, $LLM_{evaluator}$= evaluator model which provides the LLM feedback to prompts / responses or both
\item $\lambda$ with subscripts to denote different latency types: 
$\lambda_t$ = Total training cost/latency, including all offline costs for data collection, preprocessing, and model fine‐tuning, $\lambda_i$ = per-example inference latency, $\lambda_m$ = MLM inference latency per-example


\end{enumerate}

\subsection{Excluded works}
\label{excluded}
\textbf{FedBPT} \cite{fedbpt} used federated learning to update soft prompts and not discrete tokens. \textbf{Deliberate-then-generate} \cite{DTG} randomly sampled arbitrary noisy inference and prompted the task LLM to deliberate on the wrong inference, while \textbf{Reflexion} \cite{reflexion} agents maintain an episodic buffer of past deliberations. Neither method optimizes the input prompt. \textbf{AutoPrompt} \cite{autoprompt} required gradient access to the task LLM and therefore doesn't remain blackbox. 
\clearpage
\subsection{UCB based selection algorithm}
% \label{ucb-algo}
\begin{small}
\begin{algorithm}
\caption{$Select(\cdot)$ with UCB Bandits}
\label{algo:ucb}
\begin{algorithmic}[1]
\Require $n$ prompts $\rho_1, ..., \rho_n$, dataset $\mathcal{D}_{val}$, $T$ time steps, metric function $m$
\State Initialize: $N_t(\rho_i) \gets 0$ for all $i = 1, \dots, n$
\State Initialize: $Q_t(\rho_i) \gets 0$ for all $i = 1, \dots, n$
\For{$t =1, \dots, T$}
    \State Sample uniformly $\mathcal{D}_{sample} \subset \mathcal{D}_{val}$
    \State $\rho_i \leftarrow
\arg\max_\rho \left\{\frac{Q_t(\rho)}{N_t(\rho_i)} + c \sqrt{\frac{\log t}{N_t(\rho)}}\right\}$
    \State Observe reward $r_{i,t} = m(\rho_i, \mathcal{D}_{sample})$
    \State $N_t(\rho_i) \gets N_t(\rho_i) + \vert \mathcal{D}_{sample} \vert$
    \State $Q_t(\rho_i) \gets Q_t(\rho_i) + r_{i, t}$
\EndFor
\State \Return $SelectTop_b(Q_T/N_T)$
\end{algorithmic}
\end{algorithm}
\end{small}

\section{Comparison of different approaches + Tasks}
\subsection{Comparison}
Below we offer a comprehensive comparison of all the surveyed methods against our framework, covering the following aspects
\begin{enumerate}
\itemsep0em 
\item \textbf{Seed instructions}
\item \textbf{Inference evaluation}
\item \textbf{Candidate generation} 
\item \textbf{Search+filter strategy} 
\item \textbf{Iteration depth} 
\item \textbf{Optimization time complexity}
\item \textbf{Prompt generation model}
\item \textbf{Target models}
\end{enumerate}
% \begin{sidewaystable*}

% \resizebox{1\textwidth}{!}
% {\begin{tabular}{|cccccccccccc|}
% \hline
% \textbf{SNo.} & \textbf{Method} & \textbf{Seed instructions} & \textbf{Inference evaluation} & \textbf{Candidate generation} & \textbf{Search+filter strategy}  & \textbf{Iteration depth}& \textbf{Optimization time complexity} & \textbf{Prompt generation model}& \textbf{Target models} & \textbf{Tasks} & \textbf{Multilingual}\\
% \hline
% 1 & ProTeGi \cite{protegi} &Manually created& LLM feedback +\\ Task accuracy} &LLM rewriter & UCB for trees  & Fixed &$O(N * C * |Dval| * λi)$ &GPT-3.5-turbo&GPT-3.5-turbo&Jailbreak, Liar, Sarcasm, ethos&No \\
% 2 & COPLE \cite{cople} & Manually created & Task accuracy & Word-level edits using MLM &  & Variable & O(N * |I| * k * |D_val| * \lambda_i) & RoBERTa for filling masked tokens & Llama-2-7B-chat , Mistral-7B-Instruct-v0.1, and ChatGPT (gpt-3.5-turbo-0125) & s} & No \\
% \hline
% \end{tabular}}
% \caption{Comparison of all APO techniques based on our framework}
% \end{sidewaystable*}

\begin{sidewaystable*}
\rowcolors{2}{gray!15}{white} % Alternating row colors
\resizebox{1\textwidth}{!}
{\begin{tabular}{|p{3cm}p{4cm}p{2.5cm}p{3.5cm}p{3.5cm}p{4cm}p{3cm}p{3cm}p{3cm}p{5cm}|} %{|cccccccccc|}
\hline
\textbf{SNo.} & \textbf{Method} & \textbf{Seed instructions} & \textbf{Inference evaluation} & \textbf{Candidate generation} & \textbf{Search+filter strategy}  & \textbf{Iteration depth}& \textbf{Optimization time complexity} & \textbf{Prompt generation model}& \textbf{Target models}\\
\hline
1 & GPS \cite{gps} & Manually created & Task accuracy & Genetic Algorithm:\newline Back translation, Cloze, \newline Sentence continuation & Metaheuristic ensemble & Fixed & $O(T * N * k * \lambda_i)$ &  & T0 \\
2 & GRIPS \cite{grips} & Manually created & Entropy-based score+\newline Task accuracy & Phrase level \newline add/remove/swap/paraphrase & TopK selection & Fixed & $O(k * N * |D_{val}| * B)$ & PEGASUS paraphrase model & InstructGPT \\
3 & Instruction induction \newline \cite{instruction-induction} & Instruction induction & Accuracy + \newline BERTScore & LLM-rewriter &  & Fixed & $O(|\rho| * \lambda_i)$ & InstructGPT, GPT-3 & InstructGPT, GPT-3 \\
4 & RLPrompt \cite{rlprompt} & Manually created & Task accuracy + \newline Reward model score & RL-based trained NN & TopK selection & Fixed & $O(N * \rho * |V| * \lambda_i)$ & RoBERTa-large \newline Reward model-DistilBERT & 1/ BERT, 2/ GPT-2 \\
5 & TEMPERA \cite{tempera} & Manually created & Task accuracy & RL-trained NN &  & Fixed & $O(N * k * |V| * C)$ & RoBERTa-large & RoBERTa-large \\
6 & AELP \cite{aelp} & Manually created & Task accuracy & Genetic algorithm: \newline LLM-mutator & Beam search & Fixed & $O(N * \rho * k * |D| * \lambda_i)$ & PaLM 2-L & PaLM text-bison \\
7 & APE \cite{ape} & Instruction induction & Task accuracy & No new candidates & TopK selection & Fixed & $O(N * k * |D_{val}| * \lambda_i)$ & InstructGPT, GPT-3, T5, \newline InsertGPT & InstructGPT, GPT-3 \\
8 & AutoHint \cite{hint} & Manually created & Task accuracy + \newline LLM-feedback & LLM rewriter & TopK selection & Fixed & $O(T * |D| * \lambda_i)$ &  & GPT-4 \\
9 & BDPL \cite{bdpl} & Manually created & Task accuracy & RL-trained NN & TopK selection & Variable & $O(N * k * \lambda_i)$ & RoBERTa, GPT-3 & RoBERTa, GPT-3 \\
10 & Boosted Prompting \newline \cite{boosted-prompting} & Instruction-induction & Task accuracy & Ensemble based method & TopK selection & Variable & $O(N * k * \lambda_i)$ & text-curie-001, text-curie-003, GPT-3.5,\newline  code-davinci-002 & text-curie-001, text-curie-003, \newline GPT-3.5, code-davinci-002 \\
11 & BPO \cite{bpo-cheng} & Manually created & LLMaaJ (pairwise) & Finetuned LLMs &NA &NA & $O(\lambda_t + |D_{val}| * \lambda_i)$ & Llama2-7b-chat & Vicuna-7b-v1.3, \newline vicuna-13b-v1.3, llama-1-7b, \newline llama-1-13b \\
12 & CLAPS \cite{claps} & Manually created & Entropy-based score+\newline Task accuracy & Genetic Algorithm: \newline Mutation + Crossover & TopK selection & Variable & $O(N * k * |V| * \lambda_i)$ & Flan-T5 & Flan-T5 large and base \\
13 & Directional-stimulus \cite{directional-stimulus} & Manually created & BLEU, BERTScore & RL-trained NN &  & Variable & $O(\lambda_t)$ & T5, GPT-2 & ChatGPT, Codex, InstructGPT \\
14 & DLN \cite{dln} & Manually created & Task accuracy + NLL & LLM mutator & TopK selection & Fixed & $O(N * k * |D_{train}|)$ & GPT-3 (text-davinci-003), GPT-4 & GPT-3 (text-davinci-003), GPT-4 \\
15 & DSP \cite{dsp} & Instruction induction & Task accuracy & Program Synthesis & TopK selection & Fixed & $O(N * k * \lambda_i)$ & GPT-3.5 & LM: GPT-3.5, \newline Retrieval: ColBERTv2 \\
16 & DSPy \cite{dspy} & Manually created + \newline Instruction Induction & Task accuracy + \newline LLM-feedback & Program Synthesis & TopK selection & Variable & $O(N * k * B * \lambda_i)$ &  &  \\
17 & GATE \cite{gate} & Manually created & Human feedback & LLM rewriter &  & Open-ended & $O(N * (\lambda_m + |D_{val}| * \lambda_i))$ & GPT-4 & GPT-4 \\
18 & GPO \cite{gpo} & Instruction induction & Task-Accuracy and F1 & Metaprompt-design & TopK selection &  & $O(N * C * |V| * B * E)$ & gpt-3.5-turbo-0301 & gpt-3.5-turbo-0301 \\
19 & PACE \cite{pace} & Manually created & NLL + Task accuracy - \newline BLEU and BERTScore & LLM-rewriter & TopK selection & < 3 & $O(N * |\rho| * |D_{val}|)$ & gpt-3.5-turbo (0301) & text-davinci-002, \newline text-davinci-003,\newline  (gpt-3.5-turbo), GPT-4 \\
20 & PREFER \cite{prefer} & Manually created & Task accuracy & LLM-rewriter + \newline Ensemble method & TopK selection & Fixed & $O(N * |\rho| * |D_{val}|)$ & ChatGPT & ChatGPT \\
21 & Promptagent \cite{promptagent} & Manually created & Task accuracy + \newline LLM-feedback & LLM rewriter & UCT-based bandit-search & Fixed & $O(N * k * \lambda_i)$ & GPT-4 & GPT-3.5, GPT-4, PaLM-2 \\
\hline
\end{tabular}}
\caption{Comparison of all APO techniques based on our framework}
\label{tab:comparison_1}
\end{sidewaystable*}

\begin{sidewaystable*}
\rowcolors{2}{gray!15}{white} % Alternating row colors
\resizebox{1\textwidth}{!}
{\begin{tabular}{|p{3cm}p{4cm}p{2.5cm}p{3.5cm}p{3.5cm}p{4cm}p{3cm}p{3cm}p{3cm}p{5cm}|} %{|cccccccccc|}
\hline
\textbf{SNo.} & \textbf{Method} & \textbf{Seed instructions} & \textbf{Inference evaluation} & \textbf{Candidate generation} & \textbf{Search+filter strategy}  & \textbf{Iteration depth}& \textbf{Optimization time complexity} & \textbf{Prompt generation model}& \textbf{Target models}\\
\hline
22 & Promptboosting \cite{prompt-boosting} & Instruction-induction & Accuracy, F1 Score & Ensemble based method & Beam-search & Early Stopping & $O(\lambda_m)$ & T5 & RoBERTa-large \\
23 & Promptbreeder \cite{prompt-breeder} & Manually created & LLM Feedback + \newline Task accuracy & Genetic Algorithm:\newline Mutate + Crossover\newline (LLM-edits) & Metaheuristic Ensemble  & Fixed & $O(\rho * N * |V| * \lambda_i)$ & text-davinci-003, PaLM 2-L & text-davinci-003, PaLM 2-L \\
24 & ProTeGi \cite{protegi} & Manually created & Task accuracy + \newline LLM-feedback & LLM rewriter & UCT-based bandit-search & Fixed & $O(N * C * |D_{val}| * \lambda_i)$ & GPT-3.5-Turbo & GPT-3.5-turbo \\
25 & Random separators \cite{random-separators} & Manually created & Task accuracy & LLM-rewriter & TopK selection & Fixed steps & $O(N * k * \lambda_)$ & GPT2 Large, GPT2 XL, \newline Mistral 7B, Mistral 7B Instruct, \newline Llama-Alpaca 7B, Llama2 7B. \newline Llama2 7B Chat, ChatGPT & GPT2 Large, GPT2 XL, \newline Mistral 7B, Mistral 7B Instruct, \newline Llama-Alpaca 7B, Llama2 7B. \newline Llama2 7B Chat, ChatGPT \\
26 & ABO \cite{abo} & Manually created + \newline Instruction Induction & Task accuracy + \newline LLM-feedback & LLM-rewriter & TopK selection & Fixed Steps & $O(B * N * \lambda_i)$ & GPT-4 & GPT-3.5-Turbo, Llama-2-70B-chat \\
27 & Adv-ICL \cite{adv-icl} & Manually created & LLM Feedback & LLM-rewriter & Top-1 selection & Fixed & $O(N * k * \lambda_i)$ & text-davinci-002, vicuna,\newline  ChatGPT & text-davinci-002, vicuna, ChatGPT \\
28 & AMPO \cite{ampo} & Manually created & Task accuracy + \newline F1 score & Coverage-based & TopK selection & Variable & $O(N * C * \lambda_i)$ & GPT-4-turbo & GPT-4-turbo \\
29 & APEER \cite{apeer} & Manually created & Task accuracy-nDCG & Feedback + preference \newline optimization &  & Used 3 epochs & $O(N * |\rho| * |D_val|)$ &  & GPT4, GPT3.5, Llama3, Qwen2 \\
30 & APOHF \cite{apohf} & Manually created & Task accuracy + \newline Human feedback & LLM rewriter & Linear UCB & Fixed & $O(N * T)$ & ChatGPT & DALLE-3, ChatGPT \\
31 & BATPrompt \cite{bat-prompt} & Manually created & Task accuracy + \newline LLM-feedback & LLM rewriter & TopK selection & Fixed & $O(N * |D| * |\rho| * \lambda_i)$ & GPT-3.5-turbo & GPT-3.5-turbo, \newline GPT-4o-mini, Llama2-7b \\
32 & COPLE \cite{cople} & Manually created & Task accuracy & Token edits using \newline MLM &  & Variable & $O(N * |I| * k * |D_val| * \lambda_i)$ & RoBERTa \newline (filling masked tokens) & Llama-2-7B-chat , \newline  Mistral-7B-Instruct-v0.1,\newline  ChatGPT (gpt-3.5-turbo-0125) \\
33 & CRISPO \cite{crispo} & Manually created & LLM feedback + \newline ROUGE-1/2/L F-measure, \newline AlignScore & LLM rewriter & TOP-K greedy search & Fixed & $O(N * k * (|D_{train}| * \lambda_i +\lambda_m))$ & Claude Instant, \newline Claude 3 Sonnet, \newline Mistral 7B, Llama3 8B & Claude Instant, \newline Claude 3 Sonnet, \newline Mistral 7B, Llama3 8B \\
34 & DAPO \cite{dapo} & Manually created & Task accuracy & LLM-rewriter & Top-1 selection & Fixed & $O(N * k * \lambda_i)$ & GPT-3.5-Turbo, Baichuan2, \newline GPT-4 & GPT-3.5-Turbo, \newline Baichuan2, GPT-4 \\
35 & DRPO \cite{drpo} & Manually created & Reward model score + \newline LLM Feedback & LLM rewriter & Beam search & Fixed & $O(B * k * N)$ & Mistral 7b, Mistral 7b (Instruct), \newline Llama 2 70b, Llama 2 70b (chat), \newline Llama 3 8b, Llama 3 8b (Instruct), \newline gpt-3.5-turbo & Mistral 7b, Mistral 7b (Instruct), \newline Llama 2 70b, Llama 2 70b (chat), \newline Llama 3 8b, Llama 3 8b (Instruct), \newline gpt-3.5-turbo \\
36 & EVOPROMPT \cite{evoprompt} & Manually created + \newline Instruction Induction & Task Accuracy + \newline ROUGUE+ SARI & Genetic Algorithm:\newline Mutation operators+\newline Crossover & Metaheuristic ensemble & Early Stopping & $O(N * k * T * \lambda_i)$ &  & Alpaca-7b, GPT-3.5 \\
37 & FIPO \cite{fipo} & Manually created & Task accuracy & Finetuned LLMs &  &  & $O(\lambda_t + |D_val| * \lambda_i)
)$ & Tulu-13B, Tulu-70B & Llama2-7B, Tulu2-13B, \newline Baichuan2-13B \\
\hline
\end{tabular}}
\caption{Comparison of all APO techniques based on our framework}
\label{tab:comparison_2}
\end{sidewaystable*}

\begin{sidewaystable*}
\rowcolors{2}{gray!15}{white} % Alternating row colors
\resizebox{1\textwidth}{!}
{\begin{tabular}{|p{3cm}p{4cm}p{2.5cm}p{3.5cm}p{3.5cm}p{4cm}p{3cm}p{3cm}p{3cm}p{5cm}|} %{|cccccccccc|}
\hline
\textbf{SNo.} & \textbf{Method} & \textbf{Seed instructions} & \textbf{Inference evaluation} & \textbf{Candidate generation} & \textbf{Search+filter strategy}  & \textbf{Iteration depth}& \textbf{Optimization time complexity} & \textbf{Prompt generation model}& \textbf{Target models}\\
\hline

38 & LMEA \cite{lmea} & Manually created & Numeric Score-based & Genetic Algorithm:\newline Mutate + Crossover\newline (LLM-edits) & TopK selection & Fixed & $O(N * k * \lambda_i)$ &  & GPT-3.5-turbo-0613 \\
39 & MIPRO \cite{mipro} & Manually created & Task accuracy & Program Synthesis & TopK selection & Fixed & $O(N * |D_{val}| * k * \lambda_i)$ & GPT-3.5 (proposer LM) & Llama-3-8B (task LM) \\
40 & MOP \cite{mop} & Instruction induction & Task Accuracy & APE for each cluster & TopK selection & Fixed steps per-cluster & $O(C * N * |D_{val}|)$ & GPT-3.5-Turbo & GPT-3.5-Turbo \\
41 & MORL-Prompt \cite{morl-prompt} & Manually created & Task accuracy + \newline Reward score & RL-based trained NN &  & Fixed & $O(N * C * |V| * k)$ & distilGPT-2 & GPT-2 (style transfer),\newline  flan-T5-small (translation) \\
42 & OIRL \cite{oirl} & Manually created & Task accuracy + \newline Reward model score & LLM rewriter &  &  & $O(|D_{train}| * \rho * \lambda_i + \lambda_t + |D_{val}|* \lambda_i
)$ & GPT4 & Llama2-7B-chat, \newline Tigerbot-13B-chat, gpt3.5-turbo \\
43 & OPRO \cite{opro} & Manually created & Task accuracy + \newline LLM-feedback & Metaprompt design & TopK selection & Variable & $O(N * k * \lambda_i)$ & PaLM 2-L, text-bison,\newline  gpt-3.5-turbo and GPT-4 & PaLM family models \\
44 & PE2 \cite{pe2} & Manually created + \newline Instruction Induction & Task accuracy + \newline LLM-feedback & Metaprompt design & TopK selection & Fixed & $O(N * k * \lambda_i)$ & GPT-4 & text-davinci-003 \\
45 & PIN \cite{pin} & Manually created & Task accuracy & RL-trained LLM & TopK selection & Fixed & $O(N * |V| * \lambda_i * C)$ & OPT & RoBERTa-large (classification), \newline OPT models (others) \\
46 & PLUM \cite{plum} & Manually created & Task accuracy & Genetic Algorithm: \newline Mutate + crossover & Metaheuristics & Fixed steps & $O(N * C * k * \lambda_i)$ & GPT-3-babbage & GPT-3-babbage \\
47 & PRewrite \cite{prewrite} & Manually created & Task accuracy + \newline Reward model score & RL-trained LLM & TopK selection & Fixed & $O(N * C * \lambda_i * |V|)$ & PaLM 2-S & PaLM 2-L \\
48 & PROMPTWIZARD \cite{prompt-wizard} & Manually created & Task accuracy + \newline LLM-feedback & Genetic Algorithm: \newline Mutate + Crossover\newline (LLM-edits) & TopK selection & Fixed & $O(N * C * \lambda_i)$ & GPT3.5/GPT4 & GPT3.5/GPT4/Llama-70B \\
49 & PROMST \cite{promst} & Manually created & Task accuracy + \newline Human feedback & LLM rewriter & TopK selection & Fixed & $O(N * k * \lambda_i)$ & GPT-4 & GPT-3.5, GPT-4 \\
50 & Reprompting \cite{reprompting} & LLM generated CoT process. & Task accuracy & LLM-rewriter & Rejection sampling \newline with exploration & Fixed or until convergence & $O(N * k * |\rho|)$ & gpt-3.5-turbo, textdavinci-003 & gpt-3.5-turbo, textdavinci-003 \\
51 & SAMMO \cite{sammo} & Manually created & Task accuracy & Program synthesis & TopK selection & Fixed & $O(N * k * \lambda_i)$ &  & Mixtral7x8B, Llama-2 70B, \newline GPT3.5, GPT4 \\
52 & SCULPT \cite{sculpt} & Instruction induction \newline on task-README & Task accuracy + \newline LLM-feedback & LLM-rewriter & UCB bandit search & Fixed & $O(N * k * |\rho| * |D_val|)$ & GPT-4o & GPT-4o and Llama3.1-8B \\
53 & SOS \cite{sos} & Manually created & Task accuracy + \newline LLM-feedback & LLM-mutator & TopK selection & Fixed & $O(N * C * k * \lambda_i)$ & GPT-3.5-turbo, Llama3-8B, \newline Mistral-7B & GPT-3.5-turbo, Llama3-8B, \newline Mistral-7B \\
54 & SPRIG \cite{sprig} & Manually created & Task accuracy & Genetic Algorithm:\newline Mutate + Crossover (tokens) & Beam-search & Fixed & $O(N * B * T * k * \lambda_i)$ & tuner007/pegasus\_paraphrase & Llama 3.1-8B Instruct, \newline Mistral Nemo Instruct 2407, \newline Qwen 2.5-7B Instruct, \newline Llama 70B, Qwen 2.5-72B, \newline Mistral Large 2407. \\
55 & StraGo \cite{strago} & Manually created & Task accuracy + \newline LLM-feedback & Genetic Algorithm:\newline Mutate + CrossOver (tokens) & Bandit Search (UCB) & Early Stopping & $O(N * k * T * \lambda_i)$ & GPT-4 & GPT-3.5-turbo or GPT-4 \\
56 & TextGrad \cite{textgrad} & Manually created & Task accuracy + \newline LLM-feedback & LLM rewriter &  & Variable & $O(N * |D_{val}| * \lambda_i)$ &  & GPT-3.5, GPT-4o \\
57 & UNIPROMPT \cite{uniprompt} & Manually created + \newline Instruction Induction & Task accuracy + \newline LLM-feedback & LLM-rewriter & Beam Search & Early Stopping & $O(N * k * \lambda_i)$ & Fine-tuned Llama2-13B & GPT-3.5 \\
\hline
\end{tabular}}
\caption{Comparison of all APO techniques based on our framework}
\label{tab:comparison_3}
\end{sidewaystable*}

\label{full-table}
\clearpage
\subsection{Evaluation tasks and datasets}
Below we describe the different datasets and tasks that each method was evaluated on. 
\begin{table*}[!ht]
% \centering
% \small
\rowcolors{2}{gray!15}{white} % Alternating row colors
\resizebox{\textwidth}{!}{%
\begin{tabular}{|ccp{0.9\textwidth}|}%
\hline
\textbf{SNo.} & \textbf{Paper} & \textbf{Tasks}\\
\hline

1 & GPS \cite{gps} & 10 unseen tasks from the T0 benchmark, which span: \newline{} 1. Natural Language Inference: ANLI R1, R2, R3, CB, RTE \cite{anli, RTE}. \newline{} 2. Coreference Resolution: WSC, Winogrande.\cite{WinogradSchema}\newline{} 3. Sentence Completion: COPA\cite{Copa} , HellaSwag \cite{hellaswag}. \newline{} 4. Word Sense Disambiguation: WiC \cite{WiC}. \\
2 & GRIPS \cite{grips} & 8 classification tasks from NaturalInstructions \cite{naturalinstructions} \\
3 & Instruction induction \cite{InstructionInduction} & 1. Spelling, 2. Syntax, 3. Morpho-syntax, 4. Lexical semantics, \newline{}5. Phonetics, 6. Knowledge, 7. Semantics, 8. Style \\
4 & RLPrompt \cite{rlprompt} & 1. Classification \newline{} 2. Text-style transfer \\
5 & TEMPERA \cite{tempera} & Classification \\
6 & AELP \cite{aelp} & Big Bench Hard \cite{bbh} \\
7 & APE \cite{ape} & 1. 24 Instruction induction tasks \cite{InstructionInduction} 2. 21 BIG Bench Hard tasks \cite{bbh} \\
8 & AutoHint \cite{hint} & BIG-Bench Instruction Induction (Epistemic Reasoning, Logical Fallacy Detection, Implicatures, Hyperbaton, Causal Judgment, Winowhy) \cite{ape} \\
9 & BDPL \cite{bdpl} & 1. MNLI \cite{mnli}, 2. QQP \cite{QQP}, 3. SST-2 \cite{sst2}, 4. MRPC \cite{MRPC}, 5. CoLA \cite{cola}, 6. QNLI \cite{qnli}, 7. RTE \cite{RTE}, 8. CitationIntent \cite{citationintent}, 9. SciERC \cite{sciERC}, 10. RCT \cite{RCT}, 11. HyperPartisan \cite{HyperPartisan} \\
10 & Boosted Prompting \cite{boosted-prompting} & GSM8K \cite{gsm8k} and AQuA \cite{AQuA} \\
11 & BPO \cite{bpo-cheng} & Generation: Dolly Eval \cite{dollyEval}, Vicuna Eval \cite{VicunaEval}, Self-Instruct Eval \cite{SelfInstructEval} \\
12 & CLAPS \cite{claps} &  \\
13 & Directional-stimulus \cite{directional-stimulus} & MultiWOZ \cite{multiwoz} \\
14 & DLN \cite{dln} & 1. Mpqa Sentiment analysis \cite{mpqatrecsubj} \newline{} 2. Trec Question type classification \cite{mpqatrecsubj} \newline{}3. Subj Determine whether a sentence is subjective or objective \cite{mpqatrecsubj} \newline{}4. Leopard \cite{leopard}- Disaster Determine whether a sentence is relevant to a disaster. \newline{}5. Leopard \cite{leopard}- Airline Airline tweet sentiment analysis. \newline{}6. BBH \cite{bbh}- (Hyper, Nav, Date, Logic datasets) \\
15 & DSP \cite{dsp} & 1. open-domain question answering (Open-SQuAD) \cite{open-squad} \newline{} 2. multi-hop question answering (HotPotQA) \cite{hotpotqa} \newline{}3. conversational question answering (QReCC) \cite{QReCC} \\
16 & DSPy \cite{dspy} &  \\
17 & GATE \cite{gate} & LAPS \cite{gate} (1. Content Recommendation (user likes to read a given held-out article or not) 2. Moral Reasoning, 3. Email Verification) \\
18 & GPO \cite{gpo} & 1. Sentiment analysis - Yelp \cite{zhang2015character}, Flipkart \cite{flipkart}, IMDB \cite{imdb}, Amazon \cite{zhang2015character} \newline{} 2. NLI - MNLI \cite{mnli}, ANLI \cite{anli} 3.Entailment - RTE \cite{RTE}, 4. CommonsenseQA - SocialIQA \cite{socialIQA} \newline{} 5. Multi-turn dialog - DSTC7 \cite{DSTC7}, Ubuntu Dialog \cite{UbuntuDialog}, MuTual \cite{MuTual} \newline{} 6. NumericalQA - DROP \cite{DROP} \\
19 & PACE \cite{pace} & BBH \cite{bbh}, instruction induction tasks (24 tasks) \cite{InstructionInduction} and translation tasks (en-de, en-es, en-fr) \\
20 & PREFER \cite{prefer} & 1. NLI tasks including SNLI \cite{snli}, MNLI \cite{mnli}, QNLI \cite{qnli}, RTE \cite{RTE} \newline{} 2. Classification: Ethos \cite{ethos}, liar \cite{liar}, ArSarcasm \cite{ArSarcasm} \\
21 & Promptagent \cite{promptagent} & 1. BigBenchHard (BBH) \cite{bbh} - 6 BBH tasks that emphasize a blend of domain knowledge\newline{} 2. Biomedical - Disease NER (NCBI) \cite{ncbi}, MedQA \cite{medQA}, Bio similar sentences \cite{biosimilar} \newline{} 3. 2 classification - TREC \cite{trec} + Subj. \cite{subj} 1 NLI(CB) \cite{nli-ci} \\
22 & Promptboosting \cite{prompt-boosting} & Text Classification \\
23 & Promptbreeder \cite{prompt-breeder} & 1. Arithmetic Reasoning: Benchmarks: GSM8K \cite{gsm8k}, MultiArith \cite{MultiArith}, AddSub \cite{AddSub}, \newline{}SVAMP \cite{Svamp}, SingleEq \cite{SingleEQ}, AQuA-RAT \cite{AquaRat}. \newline{} 2. Commonsense Reasoning: Benchmarks: CommonSenseQA (CSQA) \cite{CSQA}, StrategyQA (SQA) \cite{SQA}. \newline{} 3. Hate Speech Classification: Dataset: ETHOS \cite{ethos}. \newline{} 4. Instruction Induction \cite{InstructionInduction}: Tasks: 24 datasets spanning \newline{} sentence similarity, style transfer, sentiment analysis, and more \\
\hline
\end{tabular}}
\caption{Tasks covered in the different papers}
\end{table*}

\begin{table*}[ht]
% \centering
% \small
\rowcolors{2}{gray!15}{white} % Alternating row colors
\resizebox{1\textwidth}{!}{%
\begin{tabular}{|ccp{0.9\textwidth}|}%
\hline
\textbf{SNo.} & \textbf{Paper} & \textbf{Tasks}\\
\hline

24 & ProTeGi \cite{protegi} & Jailbreak \cite{protegi}, Liar \cite{liar}, Sarcasm \cite{Sarcasm}, Ethos \cite{ethos} \\
25 & Random separators \cite{random-separators} & 1. SST-2, SST-5,\cite{sst2} 3. DBPedia \cite{zhang2015character}, 4. MR \cite{MR}, 5. CR \cite{CR}, 6. MPQA \cite{MPQA}, 7. Subj \cite{subj}, 8. TREC \cite{trec}, 9. AGNews \cite{zhang2015character} \\
26 & ABO \cite{abo} & BigBenchHard tasks \cite{bbh}: Object Counting, Navigate, Snarks, Question Selection \\
27 & Adv-ICL \cite{adv-icl} & Summarization (XSUM \cite{XSUM}, CNN/Daily Mail \cite{CNNDailyMail}), Data-to-Text (WebNLG \cite{WebNLG}, E2E NLG \cite{E2ENLG}), Translation (LIRO \cite{LiRO}, TED Talks \cite{TedTalks}), Classification (YELP-5 \cite{zhang2015character}, WSC \cite{WinogradSchema}), Reasoning (GSM8k \cite{gsm8k}, SVAMP \cite{Svamp}) \\
28 & AMPO \cite{ampo} & Text classification task TREC \cite{trec}, \newline{}sentiment classification task SST-5 \cite{sst2}, \newline{}largescale reading comprehension task RACE \cite{RACE}, \newline{} medical question-answering tasks MedQA \cite{medQA} and MedMCQA \cite{MedMCQA} \\
29 & APEER \cite{apeer} & Passage reranking \\
30 & APOHF \cite{apohf} & 1. User instruction optimization using tasks from Instructzero, 2. Text-to-image , 3. Response optimization \\
31 & BATPrompt \cite{bat-prompt} & 1. Language understanding, 2. Text summarization, 3. Text simplification \\
32 & COPLE \cite{cople} & GLUE - SST2 \cite{sst2}, COLA \cite{cola}, MNLI \cite{mnli}, QNLI \cite{qnli}, RTE \cite{RTE}, MRPC \cite{MRPC}, QQP \cite{QQP}  MMLU \cite{MMLU} - STEM, Humanities, Social Sciences and Other \\
33 & CRISPO \cite{crispo} & Summarization, QA \\
34 & DAPO \cite{dapo} & 1. Sentiment classification, 2. topic classification, 3. News, 4. TREC \cite{trec}, 5. subjectivity classification \cite{subj}, 6. Logic Five, 7. Hyperbaton, 8. Disambiguation, 9. Salient, 10.Translation \\
35 & DRPO \cite{drpo} & Alignment benchmark \\
36 & EVOPROMPT \cite{evoprompt} & 1. Language Understanding: Sentiment classification (e.g., SST-2, SST-5, CR, MR \cite{sst2,CR, MR}), 2. Topic classification (e.g., AGNews \cite{zhang2015character}, TREC \cite{trec}), Subjectivity classification (Subj \cite{subj}). 3. Language Generation: Summarization (SAMSum \cite{samsum}). Simplification (ASSET \cite{asset}). 4. Reasoning (BIG-Bench Hard Tasks) \cite{bbh}: Multi-step reasoning tasks from BBH, such as logical deduction, causal judgment, and object tracking. \\
37 & FIPO \cite{fipo} & 1. Generation: GSM8K \cite{gsm8k}, BBH \cite{bbh} 2. Multiple Choice: PiQA \cite{piqa}, CosmosQA \cite{cosmosqa}, MMLU \cite{MMLU} \\
38 & LMEA \cite{lmea} & Traveling Salesman Problems (TSPs) \\
39 & MIPRO \cite{mipro} & 1. Question Answering (HotPotQA)\cite{hotpotqa}  2. Classification (Iris \cite{iris}, Heart Disease \cite{heartdieases}) 3. Entailment (ScoNe) \cite{scone} 4. Multi-hop Fact Extraction and Claim Verification (HoVer) \cite{hover} \\
40 & MOP \cite{mop} & 50 tasks comprising of Instruction Induction \cite{InstructionInduction}, Super Natural Instructions \cite{naturalinstructions}, BBH \cite{bbh} \\
41 & MORL-Prompt \cite{morl-prompt} & 1. Unsupervised Text Style Transfer: Shakespearean data \cite{shakespeare} 2. Supervised Machine Translation: iwslt2017 \cite{iwslt} \\
42 & OIRL \cite{oirl} & Arithmetic reasoning: GSM8K \cite{gsm8k}, MAWPS, SVAMP \cite{Svamp} \\
43 & OPRO \cite{opro} & GSM8K \cite{gsm8k}, BBH (23 tasks) \cite{bbh}, MultiArith \cite{MultiArith}, AQuA \cite{AQuA} \\
44 & PE2 \cite{pe2} & 1. MultiArith and GSM8K for math reasoning \cite{gsm8k}, \newline{} 2. Instruction Induction \cite{InstructionInduction}, \newline{} 3. BIG-bench Hard for challenging LLM tasks \cite{bbh} \newline{} 4. Counterfactual Evaluation \newline{} 5. Production Prompt \\
45 & PIN \cite{pin} & 1. Classification: SST-2 and etc \cite{sst2} \newline{} 2. Unsupervised Text Style transfer: Yelp \cite{zhang2015character}\newline{} 3.Textual Inversion From Images: MSCOCO \cite{mscoco}, LAION \cite{laion} \\
46 & PLUM \cite{plum} & Natural-Instructions datasets v2.6 \cite{naturalinstructions} \\
47 & PRewrite \cite{prewrite} & 1. Classification: AG News \cite{zhang2015character}, SST-2 \cite{sst2}\newline{} 2. Question answering: NQ \cite{NQ}\newline{} 3. Arithmetic reasoning: GSM8K \cite{gsm8k} \\
48 & PROMPTWIZARD \cite{prompt-wizard} & 1. BIG-Bench Instruction Induction (BBII)  \cite{InstructionInduction} \newline{} 2. GSM8k \cite{gsm8k}, AQUARAT \cite{AquaRat}, and SVAMP \cite{Svamp} \newline{} 3. BIG-Bench Hard (BBH) \cite{bbh} \newline{} 4. MMLU \cite{MMLU}, Ethos \cite{ethos}, PubMedQA \cite{pubmedqa}, MedQA \cite{medQA} \\
49 & PROMST \cite{promst} & 11 multistep tasks: 1. Webarena, 2. Alfworld \cite{alfworld}, 3. Scienceworld \cite{scienceworld}, 4. BoxNet1 \cite{boxnet}, 5. BoxNet2, \newline{}6. BoxLift, 7. Warehouse, 8. Gridworld 1, 9. Gridworld 2, 10. Blocksworld, 11. Logistics \\
50 & Reprompting \cite{reprompting} & BBH \cite{bbh}, GSM8K \cite{gsm8k}, MATH \cite{MATH}\\

\hline
\end{tabular}}
\caption{Tasks covered in the different papers}
\end{table*}

\begin{table*}[ht]
% \centering
% \small
\rowcolors{2}{gray!15}{white} % Alternating row colors
\resizebox{1\textwidth}{!}{%
\begin{tabular}{|ccp{0.9\textwidth}|}%
\hline
\textbf{SNo.} & \textbf{Paper} & \textbf{Tasks}\\
\hline
51 & SAMMO \cite{sammo} & 1. BigBench zero-shot classification tasks \cite{bigbench} \newline{} 2. GeoQuery \cite{geoquery}, SMCalFlow \cite{smcalflow}, Overnight \cite{overnight} 3. Super-NaturalInstructions \cite{naturalinstructions} \\
52 & SCULPT \cite{sculpt} & BBH (23 tasks) \cite{bbh}, RAI \cite{sculpt} \\
53 & SOS \cite{sos} & 1. Sentiment Analysis  2. Orthography Analysis, 3. Taxonomy of Animals, 4. Disambiguation QA, 5. Logical Five, 6. Color Reasoning \\
54 & SPRIG \cite{sprig} & 1. Reasoning: Tasks requiring multi-step logic or causal reasoning. \newline{} 2. Math: Arithmetic and logical deduction problems. \newline{} 3. Social Understanding: Empathy detection, humor identification, and politeness evaluation. \newline{} 4. Commonsense: Inference tasks like object counting and temporal reasoning. \newline{} 5. Faithfulness: Ensuring generated outputs align with input data. \newline{} 6. Knowledge: Open-domain QA and knowledge recall tasks. \newline{} 7. Language Understanding: Tasks like sentiment analysis and text classification.\newline{} 8. Popular benchmarks include MMLU \cite{MMLU}, BBH \cite{bbh}, TruthfulQA \cite{truthfulqa}, XCOPA \cite{xcopa}, SocKET \cite{socket}, and others, covering 47 task types across multiple languages and domains. \\
55 & StraGo \cite{strago} & BBH \cite{bbh}(five challenging tasks within Big-Bench Hard)  2. SST-5 \cite{sst2}(fine-grained sentiment classification)  3. TREC \cite{trec}(question-type classification). 4. MedQA \cite{medQA},MedMCQA \cite{MedMCQA} (medical-domain QA)  5. Personalized Intent Query (an internal industrial scenario) \\
56 & TextGrad \cite{textgrad} & LeetCode Hard \cite{LeetcodeHard}, Google-proof QA \cite{GoogleProofQA}, MMLU \cite{MMLU} (Machine Learning, College Physics), BBH \cite{bbh} (Object Counting, Word Sorting), GSM8k \cite{gsm8k}, DOCKSTRING \cite{Dockstring}(molecule evaluation)\\
57 & UNIPROMPT \cite{uniprompt} & (1) Ethos \cite{ethos}, (2) ARC \cite{ARC} , (3) MedQA \cite{medQA}, (4) GSM8K \cite{gsm8k} and (5) one real-world task: Search Query Intent \cite{uniprompt} \\

\hline
\end{tabular}}
\caption{Tasks covered in the different papers}
\end{table*}
\clearpage
\section{Prompt examples} 
\subsection{Instruction Induction}
\label{appendix:instruction_induction}
Below is the original instruction induction prompt used by \citet{instruction-induction}
\begin{mdframed}[backgroundcolor=gray!20, linecolor=black]
\{\{\# system $\sim$ \}\} \\
You are a helpful assistant\\
\{\{$\sim/$ system \}\} \\
\{\{\# user $\sim$\}\} \\
I gave a friend an instruction and [[n\_demo]] inputs. The friend read the instruction and wrote an output for every one of the inputs.
Here are the input - output pairs:\\
\{\{ demos \}\} \\
What was the instruction ? It has to be less than \{\{ max\_tokens \}\} tokens . \\
\{\{$\sim/$ user \}\} \\
\{\{\# assistant $\sim$\}\}\\
The instruction was \{\{gen 'instruction ' [[ GENERATION\_CONFIG ]]\}\}\\
\{\{$\sim/$ assistant \}\}
\end{mdframed}

\subsection{Metaprompt design example}
\label{appendix:metaprompt}
Below is the metaprompt used in OPRO \cite{opro}
\begin{mdframed}[backgroundcolor=gray!20, linecolor=black]
I have some texts along with their corresponding scores. The texts are arranged in ascending order based on their scores, where higher scores indicate better quality. text: \\Let’s figure it out! \\score: 61 \\text: Let’s solve the problem. \\score: 63 \\(. . . more instructions and scores . . . ) \\The following exemplars show how to apply your text: \\you replace in each input with your text, then read the input and give an output. We say your output is wrong if your output is different from the given output, and we say your output is correct if they are the same. \\input: Q: Alannah, Beatrix, and Queen are preparing for the new school year and have been given books by their parents. Alannah has 20 more books than Beatrix. Queen has 1/5 times more books than Alannah. If Beatrix has 30 books, how many books do the three have together? \\A: output: 140 \\(. . . more exemplars . . . ) \\Write your new text that is different from the old ones and has a score as high as possible. Write the text in square brackets
\end{mdframed}

\subsection{LLM Feedback prompts} %\todo{Zhichao - add LLMJ comparison table}
\label{appendix:tab_llmaaj}
\begin{sidewaystable}[h]
\centering
\caption{Automatic prompt optimization for LLM-as-a-Judge methods, text gradients~\cite{protegi,promptagent} and PE2~\cite{pe2}.}
\vspace{0pt}
\resizebox{\textwidth}{!}{
\begin{tabular}{lllllll}
\toprule
\begin{tabular}[c]{@{}l@{}l} Method \\ \, \\ \end{tabular}
& \begin{tabular}[c]{@{}l@{}l} LLMaaJ prompt \\ \, \\ \end{tabular}
& \begin{tabular}[c]{@{}l@{}l} Candidate prompt \\ \, \\ \end{tabular}
& \begin{tabular}[c]{@{}l@{}l} Response \\ \, \\ \end{tabular}
& \begin{tabular}[c]{@{}l@{}l} Subject of evaluation \\ (prompt / response / both) \\ \end{tabular}
& \begin{tabular}[c]{@{}l@{}l} Evaluation output \\ \, \\ \end{tabular}
& \begin{tabular}[c]{@{}l@{}l} Rewritten prompt \\ \, \\ \end{tabular}  \\
\midrule 
Text-gradients~\cite{protegi} & 
\begin{tabular}[c]{@{}p{0.2\linewidth}@{}}  
I'm trying to write a zero-shot classifier prompt. My current prompt is:\\
"\{prompt\}" \\
But this prompt gets the following examples wrong:\\
\{error\_string\} \\
give \{num\_feedbacks\} reasons why the prompt could have gotten these examples wrong. Wrap each reason with <START> and <END>
\end{tabular} &
\begin{tabular}[c]{@{}p{0.2\linewidth}@{}}  
Determine whether the Statement is a lie (Yes) or not (No) based on the Context and other information.\\
Statement: Small businesses (are) going out of business in record numbers. Job title: Senator. State: Texas. Party: republican. Context: a speech at Liberty University" \\
Label: Yes Prediction: No
\end{tabular} &
\begin{tabular}[c]{@{}p{0.1\linewidth}@{}}  
N/A
\end{tabular} &
\begin{tabular}[c]{@{}p{0.1\linewidth}@{}}  
Prompt
\end{tabular} &
\begin{tabular}[c]{@{}p{0.2\linewidth}@{}}  
The prompt does not take into account the speaker’s potential biases or agenda, which could influence the veracity
of their statements.
\end{tabular} &
\begin{tabular}[c]{@{}p{0.2\linewidth}@{}}  
Determine if the statement is true (Yes) or false (No) based on the context, sources referenced, and potential
biases of the speaker.
\end{tabular}
\\
\midrule

Text-gradients~\cite{promptagent} & 
\begin{tabular}[c]{@{}p{0.2\linewidth}@{}}  
I’m writing prompts for a language model designed for a task. My current prompt is: \\
\{cur prompt\} \\
But this prompt gets the following examples wrong: \\
\{error string\} \\
For each wrong example, carefully examine each question and wrong, answer step by step, provide comprehensive and different reasons why
the prompt leads to the wrong answer. At last, based on all these reasons, summarize and list all the aspects that can improve the prompt.
\end{tabular} &
\begin{tabular}[c]{@{}p{0.2\linewidth}@{}}  
Premise: William learns that kids play in water coming up in streams out of a tiled floor with image of a large rose on it.\\
Hypothesis: William learns that kids are playing in water.\\
Label: Non-entailment Prediction: Entailment
\end{tabular} &
\begin{tabular}[c]{@{}p{0.1\linewidth}@{}}  
Non-entailment
\end{tabular} &
\begin{tabular}[c]{@{}p{0.1\linewidth}@{}}  
Prompt
\end{tabular} &
\begin{tabular}[c]{@{}p{0.2\linewidth}@{}}  
Error Feedback: "Ignoring context and detail" The model might be overlooking the details of the premise 'kids play in water coming up in
streams out of a tiled floor with an image of a large rose on it,', which directly implies the hypothesis.
\end{tabular} &
\begin{tabular}[c]{@{}p{0.2\linewidth}@{}}  
Compare the provided sentences. Take into account the subtleties in the context, pinpoint the order of events and differentiate between facts and assumptions. If the hypothesis is a direct result of the premise, select 'entailment'.
\end{tabular}
\\

\midrule
PE2~\cite{pe2} & 
\begin{tabular}[c]{@{}p{0.2\linewidth}@{}}  
\# Instruction For each example, provide reasoning according to the following template \\
* Output is correct? \\
* Necessary to edit the prompt? \\
* If yes, suggestions on prompt editing?
\end{tabular} &
\begin{tabular}[c]{@{}p{0.2\linewidth}@{}}  
\# Current Prompt Let’s think step by step. \# Full Template ``` Question: Answer: Let’s think step by step. ``` \# Examples \#\# Example 1 Input: George had 28 socks. If he threw away 4 socks ... Output: 64 Reasoning: Step 1: George had 28 socks. Step 2: ... Label: 60 [More examples ...]
\end{tabular} &
\begin{tabular}[c]{@{}p{0.1\linewidth}@{}}  
N/A
\end{tabular} &
\begin{tabular}[c]{@{}p{0.1\linewidth}@{}}  
Both
\end{tabular} &
\begin{tabular}[c]{@{}p{0.2\linewidth}@{}}  
\#\# Example 1 Output is correct? No. Reasoning: the model didn't subtract the socks he threw away. Prompt describing the task correctly? Yes. Necessary to edit the prompt? Yes. Suggestions: The prompt should be edited to guide the model to perform subtraction. [More examples ...]
\end{tabular} &
\begin{tabular}[c]{@{}p{0.2\linewidth}@{}}  
Now carefully review your reasoning and proceed with step 2: refine the prompt. \# Current Prompt Let’s think step by step. \# Instructions * The total length should be less than 50 words * Reply with the prompt. Do not include other text.
\end{tabular}
\\

\bottomrule
\end{tabular}
}
\label{tab:llmaaj_part1}
\vspace{0pt}
\end{sidewaystable}


\begin{sidewaystable}[h]
\centering
\caption{Automatic prompt optimization for LLM-as-a-Judge methods, Hints~\cite{hint}.}
\vspace{0pt}
\resizebox{\textwidth}{!}{
\begin{tabular}{lllllll}
\toprule
\begin{tabular}[c]{@{}l@{}l} Method \\ \, \\ \end{tabular}
& \begin{tabular}[c]{@{}l@{}l} LLMaaJ prompt \\ \, \\ \end{tabular}
& \begin{tabular}[c]{@{}l@{}l} Candidate prompt \\ \, \\ \end{tabular}
& \begin{tabular}[c]{@{}l@{}l} Response \\ \, \\ \end{tabular}
& \begin{tabular}[c]{@{}l@{}l} Subject of evaluation \\ (prompt / response / both) \\ \end{tabular}
& \begin{tabular}[c]{@{}l@{}l} Evaluation output \\ \, \\ \end{tabular}
& \begin{tabular}[c]{@{}l@{}l} Rewritten prompt \\ \, \\ \end{tabular}  \\

\midrule

Hints~\cite{hint} & 
\begin{tabular}[c]{@{}p{0.2\linewidth}@{}}  
Given following task: [Task Description] \\
Given Input: [Input] \\
And its expected Output: [output] \\
List the reason or hint why it's with this expected output within tag <hint> and </hint>.
\end{tabular} &
\begin{tabular}[c]{@{}p{0.2\linewidth}@{}}  
Determine whether one sentence entails the next \\
\# Given Input: [input] \\
Identify the relation between the following premises and hypotheses, choosing from the options 'entailment' or 'non-entailment'. \\
Put your answer within tag <Ans> and </Ans>. \\
\# Result

\end{tabular} &
\begin{tabular}[c]{@{}p{0.1\linewidth}@{}}  
Non-entailment
\end{tabular} &
\begin{tabular}[c]{@{}p{0.1\linewidth}@{}}  
Prompt
\end{tabular} &
\begin{tabular}[c]{@{}p{0.2\linewidth}@{}}  
- Entailment occurs when the hypothesis is a logical consequence of the premise, or when the premise guarantees the truth of the hypothesis, regardless of the level of specificity or simplification of the terms involved. \\
- Non-entailment occurs when the premise does not guarantee the truth of the hypothesis, or when there is a possibility that the hypothesis is false or unknown, especially when the premise involves beliefs or thoughts of other people. 
\end{tabular} &
\begin{tabular}[c]{@{}p{0.2\linewidth}@{}}  
Determine whether one sentence entails the next. Some useful hints are:\\
- Entailment occurs when the hypothesis is a logical consequence of the premise, or when the premise guarantees the truth of the hypothesis, regardless of the level of specificity or simplification of the terms involved.\\
- Non-entailment occurs when the premise does not guarantee the truth of the hypothesis, or when there is a possibility that the hypothesis is false or unknown, especially when the premise involves beliefs or thoughts of other people.\\
\# Given Input: [input]\\
Identify the relation between the following premises and hypotheses, choosing from the options 'entailment' or 'non-entailment'. Put your answer within tag <Ans> and </Ans>.\\
\# Result

\end{tabular}
\\

\bottomrule
\end{tabular}
}
\label{tab:llmaaj_part2}
\vspace{0pt}
\end{sidewaystable}




\begin{sidewaystable}[h]
\centering
\caption{Automatic prompt optimization for LLM-as-a-Judge methods, Critique~\cite{crispo}.}
\vspace{0pt}
\resizebox{\textwidth}{!}{
\begin{tabular}{lllllll}
\toprule
\begin{tabular}[c]{@{}l@{}l} Method \\ \, \\ \end{tabular}
& \begin{tabular}[c]{@{}l@{}l} LLMaaJ prompt \\ \, \\ \end{tabular}
& \begin{tabular}[c]{@{}l@{}l} Candidate prompt \\ \, \\ \end{tabular}
& \begin{tabular}[c]{@{}l@{}l} Response \\ \, \\ \end{tabular}
& \begin{tabular}[c]{@{}l@{}l} Subject of evaluation \\ (prompt / response / both) \\ \end{tabular}
& \begin{tabular}[c]{@{}l@{}l} Evaluation output \\ \, \\ \end{tabular}
& \begin{tabular}[c]{@{}l@{}l} Rewritten prompt \\ \, \\ \end{tabular}  \\

\midrule

Critique~\cite{crispo} & 
\begin{tabular}[c]{@{}p{0.2\linewidth}@{}}  
Critique:\\
- Number of words: The predicted summaries tended to be longer with more details while the reference summaries were shorter and more concise.\\
- Number of sentences: The predicted summaries used more sentences to describe the inputs while the reference summaries were more succinct with fewer sentences.\\
- Precision: Some details in the predicted summaries were not important and not mentioned in the reference summaries\\
- Recall: Some key details highlighted in the reference summaries were missing from the predicted summaries.\\

Suggestion:\\
- Specifying the expected length of the summary (e.g. 1-2 sentences)\\
- Emphasizing to only include the most important/key details\\
- Indicating which details should be prioritized or omitted

\end{tabular} &
\begin{tabular}[c]{@{}p{0.2\linewidth}@{}}  
For the given text, write a 1-2 sentence summary within 〈summary〉 tags that highlights the most important details. Focus on including who the key people are and what happened between them.\\
INSERT INPUT HERE\\
Some key details to focus on include the main characters, any plans or arrangements that were made, and the overall outcome or resolution.
\end{tabular} &
\begin{tabular}[c]{@{}p{0.1\linewidth}@{}}  
Tegan tells Valentia that Paul’s brother sent her a friend request on social media, though she and Paul had previously broken up. 
Valentia advises Tegan to ignore the request, not wanting Tegan to revisit her past relationship with Paul.  \\
Score: 42.1
\end{tabular} &
\begin{tabular}[c]{@{}p{0.1\linewidth}@{}}  
both
\end{tabular} &
\begin{tabular}[c]{@{}p{0.2\linewidth}@{}}  
Comparing the high-score and low-score instructions, here are some suggestions that could improve them:\\
〈suggestion〉 Specify the desired length or range for the summaries (e.g., 10 words and 1-2 sentences).〈/suggestions〉\\
〈suggestion〉 Specify to focus on key events and specify which details 〈/suggestion〉\\
〈suggestion〉 Specify the output should not contain unnessary context 〈/suggestion〉
\end{tabular} &
\begin{tabular}[c]{@{}p{0.2\linewidth}@{}}  
Read the dialogue provided in INSERT INPUT HERE and identify the key events between characters and outcomes. Then write a 1-2 sentence
summary within 〈summary〉 tags that concisely captures these important plot points, such as who will borrow a dress or who has an interview, while keeping within 10 words where possible. Focus only on the characters and salient events, omitting unnecessary context.
\end{tabular}
\\

\bottomrule
\end{tabular}
}
\label{tab:llmaaj_part3}
\vspace{0pt}
\end{sidewaystable}



\begin{sidewaystable}[h]
\centering
\caption{Automatic prompt optimization for LLM-as-a-Judge methods, Reflection~\cite{cieri-etal-2022-reflections}.}
\vspace{0pt}
\resizebox{\textwidth}{!}{
\begin{tabular}{lllllll}
\toprule
\begin{tabular}[c]{@{}l@{}l} Method \\ \, \\ \end{tabular}
& \begin{tabular}[c]{@{}l@{}l} LLMaaJ prompt \\ \, \\ \end{tabular}
& \begin{tabular}[c]{@{}l@{}l} Candidate prompt \\ \, \\ \end{tabular}
& \begin{tabular}[c]{@{}l@{}l} Response \\ \, \\ \end{tabular}
& \begin{tabular}[c]{@{}l@{}l} Subject of evaluation \\ (prompt / response / both) \\ \end{tabular}
& \begin{tabular}[c]{@{}l@{}l} Evaluation output \\ \, \\ \end{tabular}
& \begin{tabular}[c]{@{}l@{}l} Rewritten prompt \\ \, \\ \end{tabular}  \\

\midrule

Reflection~\cite{cieri-etal-2022-reflections} & 
\begin{tabular}[c]{@{}p{0.2\linewidth}@{}}  
Here is a conversation with an LLM: \\
\{x|y\}. \\
Below are the criticisms on \{y\}: \\
Explain how to improve \{x\}.

\end{tabular} &
\begin{tabular}[c]{@{}p{0.2\linewidth}@{}}  
Below are the criticisms on \{x\}:  \\
Incorporate the criticisms, and produce a new variable.
\end{tabular} &
\begin{tabular}[c]{@{}p{0.1\linewidth}@{}}  
N/A% \textcolor{red}{empty} 
\end{tabular} &
\begin{tabular}[c]{@{}p{0.1\linewidth}@{}}  
both
\end{tabular} &
\begin{tabular}[c]{@{}p{0.2\linewidth}@{}}  
Exmaple output for instance optimization (a specific coding problem, for example):\\
Handling `nums[i] == k`**: The current logic does not correctly handle the case when `nums[i] == k`. The balance should be reset or adjusted differently when `k` is encountered. \\
Output for prompt optimization:\\
The evaluator LLM simply returns if the generated output and ground truth matches (math problem result, for example)
\end{tabular} &
\begin{tabular}[c]{@{}p{0.2\linewidth}@{}}  
For prompt optimization:\\
From: You will answer a reasoning question. Think step by step. The last line of your response should be of the following format: 'Answer: \$VALUE' where VALUE is a numerical value.\\

To: You will answer a reasoning question. List each item and its quantity in a clear and consistent format, such as '- Item: Quantity'. Sum the values directly from the list and provide a concise summation. Ensure the final answer is clearly indicated in the format: 'Answer: \$VALUE' where VALUE is a numerical value. Verify the relevance of each item to the context of the query and handle potential errors or ambiguities in the input. Double-check the final count to ensure accuracy."
\end{tabular}
\\

\bottomrule
\end{tabular}
}
\label{tab:llmaaj_part4}
\vspace{0pt}
\end{sidewaystable}


\begin{sidewaystable}[h]
\centering
\caption{Automatic prompt optimization for LLM-as-a-Judge methods, Safety Score~\cite{sos}.}
\vspace{0pt}
\resizebox{\textwidth}{!}{
\begin{tabular}{lllllll}
\toprule
\begin{tabular}[c]{@{}l@{}l} Method \\ \, \\ \end{tabular}
& \begin{tabular}[c]{@{}l@{}l} LLMaaJ prompt \\ \, \\ \end{tabular}
& \begin{tabular}[c]{@{}l@{}l} Candidate prompt \\ \, \\ \end{tabular}
& \begin{tabular}[c]{@{}l@{}l} Response \\ \, \\ \end{tabular}
& \begin{tabular}[c]{@{}l@{}l} Subject of evaluation \\ (prompt / response / both) \\ \end{tabular}
& \begin{tabular}[c]{@{}l@{}l} Evaluation output \\ \, \\ \end{tabular}
& \begin{tabular}[c]{@{}l@{}l} Rewritten prompt \\ \, \\ \end{tabular}  \\

\midrule

Safety Score~\cite{sos} & 
\begin{tabular}[c]{@{}p{0.2\linewidth}@{}}  
You are a security gatekeeper. Given an existing prompt and a series of cases where it made mistakes. Look through each case carefully and identify what is causing the mistakes. Based on these observations, output a way to improve the prompts based on the mistakes. From a security perspective, a mistake was made when the LLM helped the user perform a malicious task. If the LLM responds with a "canned response", like, "I am just an AI, I cannot help you with this..." then the LLM did not help the user. If the LLM says it cannot answer without more information then the LLM did not help.\\
Some ways to make a prompt secure are:\\
1. Add a detailed description of the task and how to solve it. Consider providing a step-by-step description of the process the LLM should follow.\\
2. Specify instructions to ensure the LLM’s answer is respectful.\\
3. Specify guardrails around input and output format.\\
*\{passed in data\}*\\
ways to make the existing prompt more secure based on observations of the mistakes in the cases above are:

\end{tabular} &
\begin{tabular}[c]{@{}p{0.2\linewidth}@{}}  
You are a mutator. Given a prompt, your task is to generate another prompt with the same semantic meaning and intentions.
\# Example:
current prompt: Your mission is to ascertain the sentiment of the provided text and assign a sentiment label from [’negative’, ’positive’].\\
mutated prompt: Determine the sentiment of the given sentence and assign a label from [’negative’, ’positive’].\\
\# Given:\\
\{passed in data\}
\end{tabular} &
\begin{tabular}[c]{@{}p{0.1\linewidth}@{}}  
KPI score: \\
Security score: 
\end{tabular} &
\begin{tabular}[c]{@{}p{0.1\linewidth}@{}}  
Response
\end{tabular} &
\begin{tabular}[c]{@{}p{0.2\linewidth}@{}}  
Select the locally optimal with respect to an objective if it achieves the best performance on this objective among all prompts that exhibit similar performance across all other objectives in other objectives
\end{tabular} &
\begin{tabular}[c]{@{}p{0.2\linewidth}@{}}  
Task Description: You are a Sentiment Classifier. Your task is to classify the emotional sentiment of the text to understand the overall tone and sentiment expressed. This sentiment classification can be used to analyze customer feedback, improve product experiences, or identify potential issues.\\

Instructions for Respectful Language Model: It is important to ensure that the language model promotes positive and respectful interactions. Therefore, please note that the language model should not provide any support or guidance for illegal activities, harmful actions, or unethical behavior. Emphasize the importance of promoting positive and respectful interactions.\\

Input and Output Format: The input should only consist of a single sentence or a short paragraph that requires sentiment classification. The output should provide the emotional sentiment without any additional information or suggestions.\\

Examples:\\
Please classify the emotional sentiment expressed in the following texts:\\
Input: "The new software update is user-friendly and efficient."\\
Correct Answer: [’positive’]\\
\{Another four few shot examples\} \\
Please provide the emotional sentiment for each input text without any additional information or suggestions.
\end{tabular}
\\

\bottomrule
\end{tabular}
}
\label{tab:llmaaj_part5}
\vspace{0pt}
\end{sidewaystable}

\end{document}