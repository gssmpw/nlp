\begin{figure*}[t]
\centering
\includegraphics[width=0.9\textwidth]{fig/crop_construct1.pdf}
\caption{Schematic diagram of \dataset{} dataset construction process including three stages: \textit{Image Collection}, \textit{Data Annotation} and \textit{Cross Check}. Only comprehension task is displayed, the process of prediction task is the same as understanding. The reordering task only requires first-stage processing to ensure the ordering of frames is unique, and it does not require data annotation.}
\label{fig:construct}
\end{figure*}

\section{Related Work}

\paragraph{Large Multimodal Models}

Large language models (LLMs) have demonstrated strong performance in various natural language understanding and generation tasks~\cite{dubey2024llama, liu2024deepseek, ray2023chatgpt}. Building on the scaling law of LLMs, a generation of Large Multimodal Models (LMMs) has emerged, with LLMs serving as the backbone. These models~\cite{qwen2.5-VL, Qwen2VL, Zhu:2024minigpt-4, liu2023improvedllava, wang2023cogvlm, ye2023mplugowl2} integrate visual features with language models using additional layers or specialized modules. Moreover, several closed-source LMMs~\cite{reid2024gemini, driess2023palm, yang2023dawn}, including GPT-4o~\cite{hurst2024gpt40}, have demonstrated remarkable capabilities in handling complex multimodal inputs~\cite{yue2024mmmu, fu2023mme, li2023seed}. Beyond single-image LLMs, video LLMs~\cite{zhang2025videollama, ye2024mplug, zhang2410video} further analyze and understand video content, which is essentially a continuous sequence of images. However, studies indicate that LMMs still encounter limitations in understanding implicit meanings~\cite{yang2024:deepsemantic, liu2023mmbench, yang2023mm}, especially in the context of multiple sequential images, where research is lacking.

\paragraph{Visual Implicit Meanings Understanding}
% 过去的研究多数集中于图像表层内涵的探索。在近期的研究中，揭示了LMMs在讽刺与幽默方面的理解能力仍有不足。最新研究进一步全面评价模型对于图像深意理解的综合能力，发现人工智能与人类在图像深意理解方面仍有巨大差距。然而这些研究均聚焦于单个图片。多张时序图片……
% 一些研究~\cite{chen2024autoeval, wang2024mementos}考察模型对于多张时序图片的表层内容的Perception和Reasoning能力。与以前的研究相比，我们的工作第一次给模型在多张时序图片的深层内涵进行评估。

% Previous research~\cite{Lin2014MicrosoftCC, antol2015vqa, goyal2017making, gurari2018vizwiz, hudson2019gqa, wang2022co, xia-etal-2023-imagenetvc} has primarily focused on surface-level image understanding. However, studies have shown that LMMs struggle with capturing nuances of sarcasm~\cite{das2018sarcasm, cai-etal-2019-multi, lemmens-etal-2020-sarcasm, desai2021nice, abu-farha-etal-2022-semeval} and humor~\cite{radev-etal-2016-humor, Hessel2022DoAL, Hu2024CrackingTC}. 
Beyond studies on surface-level image understanding~\cite{antol2015vqa, wang2022co, dong-etal-2022-premise, xia-etal-2023-imagenetvc}, recent works have shown that LMMs struggle implicit meaning understanding~\cite{desai2021nice, abu-farha-etal-2022-semeval, Hu2024CrackingTC}.
A recent study~\cite{yang2024:deepsemantic} further highlights a significant gap between AI and human comprehension of implicit meanings in images. However, these works are limited to single-image analysis. Multiple sequential images, arranged temporally, provide richer contextual information and serve as a bridge between static images and videos. Existing studies on sequential images have only focused on surface-level understanding~\cite{chen2024autoeval, wang2024mementos}. 
For instance, ~\citet{wang2024mementos} collects image sequences and provides descriptions of their surface content and events without delving into deeper meanings. A detailed comparison with prior work is presented in Table~\ref{tab:Features}, and the detailed description of categories and distributions covered by our method are illustrated in Appendix~\ref{categories}.


