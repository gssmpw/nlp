\section{Dataset and Task Overview}
To investigate the capabilities of LMMs to comprehend sequential images, we introduce \dataset, a novel benchmark consisting of three subtasks:

\begin{itemize}
     \item \textbf{Visual Narrative Comprehension:} Examines whether models accurately interpret the narrative content of image sequences.
      \item \textbf{Contextual Frame Prediction:} Assesses the model reasoning ability to predict missing frames in image sequences based contextual.
      \item \textbf{Temporal narrative Reordering:} Evaluates whether models correctly infer and restore the chronological order of image sequences based causal temporal relationship.
\end{itemize}

The instructions for three subtasks are presented in Table~\ref{prompt}. These subtasks provide a rigorous and multifaceted assessment of LMMs, offering insights into their strengths and limitations in sequential image understanding. In the following, we may use their full names or refer to them as \textit{comprehension}, \textit{prediction}, and \textit{reordering} for simplicity.

\input{tab/prompt}
% \vspace{-5mm}
\input{tab/statistics}

Detailed statistics is displayed on Table~\ref{tab:statistics}.
Overall, our proposed \dataset includes $896$ image sequences, with an average frame length of $4.09$ of each sequence. The number of frames ranges from 3 to 8. Each task is designed in the form of multiple-choice questions, except for the reorder task, which also includes a question-answering format. Since its options are simple and well-defined, accuracy can be directly computed. In our tasks, the input format uniformly consists of images paired with textual prompts. Specifically, the comprehension task utilizes the whole images without split, the reordering task takes shuffled image sequence as input,  and the frame prediction task involves masking second-to-last frame within the image sequence.
For the frame prediction task, we select the second-to-last frame, as it typically serves as a bridge between the preceding frames and the final frame. The start and end frames are generally more challenging to predict.


% 上面写具体的statistics，比如task A每个sample几个选项，task B & task C，平均的选项长度是多少。每个task的数据格式是怎么样的，比如reorder input就是打乱的图片，comprehension是顺序图片，frmae prediction我们会mask某一帧的图片。可以在这里讲我们是mask倒数第二帧以及为什么。

% 最后一帧一般是脑洞大开的反转，很难预测，所以我们选择了他的前一帧进行预测，并且只筛选了frmae数大于等于4的连环画。但是有些倒数第二帧的内容是有多种可能的，我们在人类标注员check的时候删除了那些倒数第二帧不唯一的图。

% Reference:

%The \method{} dataset includes 1,001 samples, each with an image and three manually annotated components: a description, a title, and deep semantics. The statistical information about the text is displayed in Table \ref{tab:statistics}. To enable quantitative evaluation, we additionally craft multiple-choice questions to test the understanding of descriptions, titles, and deep semantics. Each segment is represented by 1,001 questions, where each question presents an image, a question text, and four potential answers. Only one answer is correct, while the others serve as distractors. Figure~\ref{fig:fig_sim} illustrates examples of the manually annotated components and the multiple-choice questions.

% We describe the proposed PMR task with an example in Figure 2 I&II. Given a source image and a textual premise, the inference model should perceive and understand the image in combination with the premise so as to choose the exclusive correct action among the four hypothetical candidates. The premise would serve as the background knowledge or domain-specific commonsense for the given image. In the running example, the model should be able to recognize what [person2] wears from the image and infer whether [person4] would give his seat to [person2] under the premise “[person4] is very friendly”. The corrected answer is ‘C’ according to the visual and textual clues. In total, we collect about 15k instances for PMR. We list the statistics for PMR in Table 2.