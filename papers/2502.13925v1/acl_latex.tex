% This must be in the first 5 lines to tell arXiv to use pdfLaTeX, which is strongly recommended.
\pdfoutput=1
% In particular, the hyperref package requires pdfLaTeX in order to break URLs across lines.

\documentclass[11pt]{article}

% Change "review" to "final" to generate the final (sometimes called camera-ready) version.
% Change to "preprint" to generate a non-anonymous version with page numbers.
% \usepackage[review]{acl}
\usepackage[final]{acl}
% Standard package includes
\usepackage{times}
\usepackage{latexsym}

% For proper rendering and hyphenation of words containing Latin characters (including in bib files)
\usepackage[T1]{fontenc}
% For Vietnamese characters
% \usepackage[T5]{fontenc}
% See https://www.latex-project.org/help/documentation/encguide.pdf for other character sets

% This assumes your files are encoded as UTF8
\usepackage[utf8]{inputenc}

% This is not strictly necessary, and may be commented out,
% but it will improve the layout of the manuscript,
% and will typically save some space.
\usepackage{microtype}

% This is also not strictly necessary, and may be commented out.
% However, it will improve the aesthetics of text in
% the typewriter font.
\usepackage{inconsolata}

\usepackage{hyperref}
\usepackage{url}
\newcommand{\explain}[2]{\underbrace{#1}_{{\footnotesize\raggedright #2}}}

\usepackage[most]{tcolorbox} % 载入 tcolorbox 宏包
% for figures
\usepackage{graphicx}
\usepackage{subfigure}
\usepackage{wrapfig}

% for equation
\usepackage{amsmath}
\usepackage{amstext}
\usepackage{amsfonts}
\usepackage{bm}

\usepackage{bbm}
% for table
\usepackage{multirow}
\usepackage{booktabs}
\usepackage{array}
\usepackage{caption}
\usepackage{multirow}
\usepackage{booktabs}
\usepackage{array}
\usepackage{caption}
\usepackage{color}
\usepackage{colortbl}
\usepackage{tablefootnote}
\usepackage{adjustbox}

% for algorithm
\usepackage{caption}
\usepackage{algorithm}
\usepackage{algpseudocode}
\newcommand{\mycolor}[1]{\textcolor[RGB]{64,101,149}{#1}}
\newcommand{\mydarkcolor}[1]{\textcolor[RGB]{64,101,149}{#1}}
\algnewcommand{\LineComment}[1]{\Statex ~~~~~~\textsc{//}~\textit{#1}}

%for itemize
\usepackage{enumitem}
\setenumerate[1]{itemsep=0pt,partopsep=0pt,parsep=\parskip,topsep=5pt}
\setitemize[1]{itemsep=0pt,partopsep=0pt,parsep=\parskip,topsep=5pt}
\setdescription{itemsep=0pt,partopsep=0pt,parsep=\parskip,topsep=5pt}

% for highlight
\usepackage{soul}

% for taxonomy
\usepackage{tikz}
\usepackage[edges]{forest}
\definecolor{hidden-draw}{RGB}{64,101,149}
% \definecolor{hidden-pink}{RGB}{255,245,247}
\definecolor{hidden-pink}{RGB}{231,239,250}

% for notation
\usepackage[mathscr]{euscript}
\newcommand{\dataset}{\textsc{StripCipher}\xspace}

%for itemize
\usepackage{amssymb}  
\usepackage{pifont}
\newcommand{\cmark}{\ding{51}}
\newcommand{\xmark}{\ding{55}}
\newcommand{\greenyes}{\textcolor{green}{\ding{51}}}
\newcommand{\redno}{\textcolor{red}{\ding{55}}}
\newcommand{\cpm}[1]{\textcolor{gray}{$_{\pm #1}$}}

% for logo
\usepackage{scalerel}
\usepackage{graphicx}  % 使得表格可以自动调整
\usepackage{array}     % 允许使用 p{} 设定列宽
\usepackage{booktabs}  % 提供更好的表格格式
\usepackage{ragged2e}  % 使得文本可以左对齐且换行


% for title
\usepackage{xspace}

% If the title and author information does not fit in the area allocated, uncomment the following
%
%\setlength\titlebox{<dim>}
%
% and set <dim> to something 5cm or larger.

% From Still to Motion: Evaluating Large Multimodal Models' Understanding of Comic Strips
% Cracking the Code of Visual Narratives: Can LMMs Uncover Implicit Meanings Behind Comic Strips?
% Cracking the Code of Visual Narratives: Can LMMs Uncover Implicit Meanings Behind Image Sequences?

% \scalerel*{\includegraphics{fig/comic.png}}{{\rule{3ex}{3ex}}}
% \texorpdfstring{\includegraphics[width=18pt]{fig/comic.png}}{}
\title{
\texorpdfstring{\includegraphics[width=18pt]{fig/comic.png}}{}
\textit{Beyond Single Frames:} Can LMMs Comprehend  Temporal and Contextual Narratives in Image Sequences?
}

% \author{\textbf{Xiaochen Wang}\textsuperscript{1,$*$} \textbf{Heming Xia}\textsuperscript{2,\thanks{equal contribution}}, \textbf{Jialin Song}\textsuperscript{1,$\diamond$}, \textbf{Longyu Guan}\textsuperscript{1,$\diamond$}, \textbf{Yixin Yang}\textsuperscript{1}, \textbf{Qingxiu Dong}\textsuperscript{1}, \\
% \textbf{Weiyao Luo}\textsuperscript{1}, \textbf{Yiru Wang}\textsuperscript{4}, \textbf{Yifan Pu}\textsuperscript{3}, \textbf{Xiangdi Meng}\textsuperscript{1}, \textbf{Wenjie Li}\textsuperscript{2}, \textbf{Zhifang Sui}\textsuperscript{ 1,\thanks{Corresponding Author}}\\
% \textsuperscript{1} State Key Laboratory of Multimedia Information Processing, Peking University\\
%   \textsuperscript{2} Department of Computing, The Hong Kong Polytechnic University \\ 
%    \textsuperscript{3} Tsinghua University      \textsuperscript{4} ModelTC \\ 
%    }

\author{%
\textbf{Xiaochen Wang}\textsuperscript{1 $*$},
\textbf{Heming Xia}\textsuperscript{2 $*$},
\textbf{Jialin Song}\textsuperscript{1 $\dagger$},
\textbf{Longyu Guan}\textsuperscript{1 $\dagger$},
\textbf{Yixin Yang}\textsuperscript{1},
\textbf{Qingxiu Dong}\textsuperscript{1}, \\
\textbf{Weiyao Luo}\textsuperscript{1}, 
\textbf{Yiru Wang}\textsuperscript{4}, 
\textbf{Yifan Pu}\textsuperscript{3}, 
\textbf{Xiangdi Meng}\textsuperscript{1}, 
\textbf{Wenjie Li}\textsuperscript{2}, 
\textbf{Zhifang Sui}\textsuperscript{1 $\ddagger$} \\
\textsuperscript{1} State Key Laboratory of Multimedia Information Processing, Peking University\\
\textsuperscript{2} Department of Computing, The Hong Kong Polytechnic University\\
\textsuperscript{3} Tsinghua University \quad
\textsuperscript{4} ModelTC \\
  \texttt{ wangxiaochen@stu.pku.edu.cn}
}



\begin{document}
\maketitle

\renewcommand{\thefootnote}{\fnsymbol{footnote}}
% \footnotetext{\textsuperscript{$*$} Equal first contribution. \textsuperscript{$\dagger$} Equal second contribution.} 
% \footnotetext{\textsuperscript{$\ddagger$} Corresponding Author.} 
\footnotetext{\textsuperscript{$*$} Equal first contribution. } 

\footnotetext{\textsuperscript{$\dagger$} Equal second contribution.}
\footnotetext{\textsuperscript{$\ddagger$} Corresponding author.} 

% \footnotetext[1]{Equal first contribution.} \footnotetext[2]{Equal second contribution.}
% \footnotetext[3]{Corresponding Author.}
% \renewcommand{\thefootnote}{\arabic{footnote}}

\begin{abstract}
Large Multimodal Models (LMMs) have achieved remarkable success across various visual-language tasks. However, existing benchmarks predominantly focus on single-image understanding, leaving the analysis of image sequences largely unexplored. To address this limitation, we introduce \dataset, a comprehensive benchmark designed to evaluate capabilities of LMMs to comprehend and reason over sequential images. \dataset comprises a human-annotated dataset and three challenging subtasks: visual narrative comprehension, contextual frame prediction, and temporal narrative reordering. Our evaluation of $16$ state-of-the-art LMMs, including GPT-4o and Qwen2.5VL, reveals a significant performance gap compared to human capabilities, particularly in tasks that require reordering shuffled sequential images. For instance, GPT-4o achieves only $23.93\%$ accuracy in the reordering subtask, which is $56.07\%$ lower than human performance. Further quantitative analysis discuss several factors, such as input format of images, affecting LMMs’ performance in sequential understanding, underscoring the fundamental challenges that remain in the development of LMMs.   
\end{abstract}

\input{Sections/1-Introduction}
\input{Sections/2-RelatedWork}
\input{Sections/3-DatasetandTaskOverview}
\input{Sections/4-DatasetConstruction}
\input{Sections/5-Experiments}
\input{Sections/6-Analysis}
\input{Sections/7-Conclusion}
\input{Sections/8-Limitations}


% Bibliography entries for the entire Anthology, followed by custom entries
%\bibliography{anthology,custom}
% Custom bibliography entries only
\bibliography{custom}

\clearpage

\appendix

\section*{Appendix}
\input{Appendix/A}

\end{document}
