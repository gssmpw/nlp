\section{Experiments}
\subsection{Datasets}
We conduct experiments on three publicly available real-world web service traffic datasets from Alibaba Group~\footnote{\url{https://github.com/alibaba/clusterdata/blob/master/cluster-trace-microservices-v2022}}, Microsoft Azure~\footnote{\url{https://github.com/Azure/AzurePublicDataset/tree/master}}, and Ant Group~\footnote{\url{https://huggingface.co/datasets/kashif/App_Flow/viewer/}}. The Ant Group Traffic dataset includes 113 web services spanning a time range of 146 days. The Microsoft Azure Traffic dataset consists of 1,000 web services with a time range of 14 days. Similarly, the Alibaba Group Traffic dataset contains 1,000 web services, covering a total duration of 13 days. The datasets utilized in this study are available at: \url{https://github.com/******}.
\subsection{Experiment Settings}
\subsubsection{Baselines}
\label{sec:baselines}
We evaluate our methods against the following baselines: 

\begin{itemize}
    \item \textbf{Large Language Models}: Llama3~\cite{touvron2023llama} and TimeLLM~\cite{jintime}.
    \item \textbf{Specialized Web Service Traffic Prediction Models}: MagicScaler~\cite{pan2023magicscaler} and OptScaler~\cite{zou2024optscaler}.
    \item \textbf{General Time Series Prediction Models}: TimesNet~\cite{wutimesnet}, TimeMixer~\cite{wangtimemixer}, and iTransformer~\cite{liuitransformer}.
\end{itemize}

These baselines represent the SOTA approaches in their respective categories. Unlike these baselines, which ignore causal relationships among web services, our CCMPlus module explicitly incorporates them, enhancing feature representations and improving web service traffic prediction performance.
\subsubsection{Evaluation Metrics}  
We evaluate model performances using Mean Squared Error (MSE) and Mean Absolute Error (MAE): 
\begin{equation}
\begin{array}{cc}
\text{MSE} = \frac{1}{k} \sum_{i=1}^k \left( y_i - \hat{y}_i \right)^2, & 
\text{MAE} = \frac{1}{k} \sum_{i=1}^k \left| y_i - \hat{y}_i \right|, \nonumber
\end{array}
\end{equation}
where \( y_i \) and \( \hat{y}_i \) denote the true and predicted values, respectively, and \( k \) is the number of test samples in the test set.
\subsubsection{Implementation Details}
The implementation uses PyTorch 2.4.0 with random seeds \{0, 2, 4\}. Llama3 (8B) is fine-tuned using LoRA (rank 16, \( \alpha = 32 \)). The momentum value $m$ is 0.5. The batch size \( B \) is 8, \( C_{in} = 16 \), \( \tau_w = 100 \), and the Adam optimizer is configured with a learning rate of 0.000001. The input length \( L_x \) is 168, and the prediction length \( L_{pred} \) is 1. Training is performed on an H100 GPU with \( C_{out} = 32 \) and \( \tau = [1, 2, 3, 4] \). The model is trained for 15 epochs with an early stopping patience of 5 epochs based on validation performance.
\subsubsection{Research Questions}
The following research questions are investigated: 1) What are the overall performances and prediction accuracies of the models across different granularities? (Section~\ref{sec:performance_analysis}) 2) How does the CCMPlus module impact prediction performance? (Section~\ref{sec:ablation_study})
3) How does evaluation speed vary across methods? (Section~\ref{sec:evaluation_speed}) 4) How do the methods perform under varying hyperparameter settings? (Section~\ref{sec:hyperparameter_analysis})
\subsection{Prediction Performance Analysis}
\label{sec:performance_analysis}
% Please add the following required packages to your document preamble:
% \usepackage{graphicx}
\begin{table*}[t]
\centering
\caption{Average testing performance over three runs with a 30 minutes time interval across three datasets: Alibaba Group Traffic (124,000 test samples), Azure Traffic (134,000 test samples), and Ant Group Traffic (158,313 test samples).}
\label{tab:30T_performance}
\resizebox{\textwidth}{!}{%
\begin{tabular}{lcccccccc}
\hline
\multicolumn{1}{l|}{30 Minutes} &
  \multicolumn{2}{c|}{Alibaba Group Traffic} &
  \multicolumn{2}{c|}{Microsoft Azure Traffic} &
  \multicolumn{2}{c|}{Ant Group Traffic} &
  \multicolumn{2}{c}{Overall Mean} \\ \hline
Method                                                      & MSE    & MAE     & MSE     & MAE    & MSE    & MAE    & MSE     & MAE    \\ \hline
MagicScaler~\cite{pan2023magicscaler} & 3.4909 & 0.5362  & 42.0655 & 0.8441 & 1.5513 & 1.0743 & 15.7026 & 0.8182 \\
OptScaler~\cite{zou2024optscaler}     & 3.5708 & 0.6147 & 33.7485 & 0.9459 & 1.3017 & 0.9421 & 12.8737 & 0.8342 \\
Llama3~\cite{touvron2023llama}        & 7.0570 & 1.1545  & 43.8206 & 1.8958 & 3.4346 & 1.5931 & 18.1041 & 1.5478 \\
TimeLLM~\cite{jintime}                & 3.4985 & 0.5339  & 17.2852 & 0.7088 & 1.5049 & 1.0560 & 7.4295  & 0.7662 \\
TimeMixer~\cite{wangtimemixer}        & 3.1429 & 0.5455  & 15.1801 & 0.6759 & 1.4036 & 0.9950 & 6.5755  & 0.7388 \\
iTransformer~\cite{liuitransformer}   & 3.1247 & 0.5428  & 19.5574 & 0.7933 & 1.4116 & 1.0010 & 8.0312  & 0.7790 \\
CCM+iTransformer (ours) &
  3.0773 &
  \textbf{0.5098 ↓6.08\%} &
  \textbf{14.3191 ↓26.8\%} &
  \textbf{0.6482 ↓18.3\%} &
  1.3162 &
  0.9402 &
  \textbf{6.2375} &
  \textbf{0.6994} \\
TimesNet~\cite{wutimesnet}            & 3.1843 & 0.5406  & 16.6185 & 0.7177 & 1.4096 & 0.9989 & 7.0708  & 0.7524 \\
\textbf{CCM+TimesNet (ours)} &
  \textbf{3.0206 ↓5.14\%} &
  0.5200 ↓3.81\% &
  14.9237 ↓10.2\% &
  0.6791 ↓5.4\% &
  \textbf{1.2897 ↓8.51\%} &
  \textbf{0.9350 ↓6.40\%} &
  6.4113 &
  0.7114 \\ \hline
\end{tabular}%
}
\end{table*}

% Please add the following required packages to your document preamble:
% \usepackage{graphicx}
% Please add the following required packages to your document preamble:
% \usepackage{graphicx}
\begin{table*}[t]
\centering
\caption{Average testing performance over three runs with a 15 minutes time interval across three datasets: Alibaba Group Traffic (249,000 test samples), Azure Traffic (268,000 test samples), and Ant Group Traffic (316,739 test samples).}
\label{tab:15T_performance}
\resizebox{\textwidth}{!}{%
\begin{tabular}{lcccccccc}
\hline
\multicolumn{1}{l|}{15 Minutes} &
  \multicolumn{2}{c|}{Alibaba Group Traffic} &
  \multicolumn{2}{c|}{Microsoft Azure Traffic} &
  \multicolumn{2}{c|}{Ant Group Traffic} &
  \multicolumn{2}{c}{Overall Mean} \\ \hline
Method                                                      & MSE     & MAE    & MSE     & MAE    & MSE    & MAE    & MSE    & MAE    \\ \hline
MagicScaler~\cite{pan2023magicscaler} & 3.3695  & 0.5262 & 19.2405 & 0.6764 & 1.5044 & 1.0544 & 8.0381 & 0.7523 \\
OptScaler~\cite{zou2024optscaler}     & 3.4188 & 0.5950 & 17.0180 & 0.7560 & 1.3069 & 0.9503 & 7.2479 & 0.7671 \\
Llama3~\cite{touvron2023llama}        & 7.4170  & 1.1452 & 12.6471 & 1.5288 & 3.3408 & 1.5700 & 7.8016 & 1.4147 \\
TimeLLM~\cite{jintime}                & 3.3954  & 0.5242 & 6.7723  & 0.6217 & 1.5176 & 1.0579 & 3.8951 & 0.7346 \\
TimeMixer~\cite{wangtimemixer}        & 2.8915  & 0.5004 & 5.8507  & 0.5522 & 1.3962 & 0.9900 & 3.3795 & 0.6809 \\
iTransformer~\cite{liuitransformer}   & 2.8854  & 0.5118 & 5.7501  & 0.5310 & 1.4017 & 0.9938 & 3.3457 & 0.6789 \\
CCM+iTransformer (ours)                                     & 2.8374  & 0.4932 & 5.0156  & 0.4582 & 1.3127 & 0.9368 & 3.0552 & 0.6294 \\
TimesNet~\cite{wutimesnet}            & 2.8635  & 0.4904 & 5.0550  & 0.4641 & 1.3962 & 0.9876 & 3.1049 & 0.6474 \\
\textbf{CCM+TimesNet (ours)} &
  \textbf{2.7151 ↓5.18\%} &
  \textbf{0.4823 ↓1.65\%} &
  \textbf{4.7434 ↓6.16\%} &
  \textbf{0.4422 ↓4.72\%} &
  \textbf{1.2951 ↓7.24\%} &
  \textbf{0.9199 ↓6.85\%} &
  \textbf{2.9179} &
  \textbf{0.6148} \\ \hline
\end{tabular}%
}
\end{table*}

% Please add the following required packages to your document preamble:
% \usepackage{graphicx}
% Please add the following required packages to your document preamble:
% \usepackage{graphicx}
\begin{table*}[t]
\centering
\caption{Average testing performance over three runs with a 5 minutes time interval across three datasets: Alibaba Group Traffic (748,000 test samples), Azure Traffic (806,000 test samples), and Ant Group Traffic (950,217 test samples).}
\label{tab:5T_performance}
\resizebox{\textwidth}{!}{%
\begin{tabular}{lccccccll}
\hline
\multicolumn{1}{l|}{5 Minutes} &
  \multicolumn{2}{c|}{Alibaba Group Traffic} &
  \multicolumn{2}{c|}{Microsoft Azure Traffic} &
  \multicolumn{2}{c|}{Ant Group Traffic} &
  \multicolumn{2}{c}{Overall Mean} \\ \hline
Method                                                      & MSE    & MAE    & MSE     & MAE    & MSE    & MAE    & MSE    & MAE    \\ \hline
MagicScaler~\cite{pan2023magicscaler} & 3.2469 & 0.5176 & 9.3378  & 0.5473 & 1.5326 & 1.0640 & 4.7058 & 0.7096 \\
OptScaler~\cite{zou2024optscaler}     & 3.1070 & 0.4862 & 8.5807  & 0.5410 & 1.3214 & 0.9373 & 4.3364 & 0.6548 \\
Llama3~\cite{touvron2023llama}        & 7.3436 & 1.1474 & 11.5244 & 1.3587 & 3.3047 & 1.5606 & 7.3909 & 1.3556 \\
TimeLLM~\cite{jintime}                & 3.2588 & 0.5071 & 6.5393  & 0.5063 & 1.4974 & 1.0459 & 3.7652 & 0.6864 \\
TimeMixer~\cite{wangtimemixer}        & 2.7051 & 0.4818 & 3.0460  & 0.3890 & 1.3923 & 0.9819 & 2.3811 & 0.6176 \\
iTransformer~\cite{liuitransformer}   & 2.6458 & 0.4664 & 3.0367  & 0.3769 & 1.3939 & 0.9853 & 2.3588 & 0.6095 \\
CCM+iTransformer (ours)                                     & 2.5657 & 0.4460 & 2.9780  & 0.3662 & 1.3025 & 0.9398 & 2.2821 & 0.5840 \\
TimesNet~\cite{wutimesnet}            & 2.1681 & 0.3925 & 2.8696  & 0.3527 & 1.3923 & 0.9822 & 2.1433 & 0.5758 \\
\textbf{CCM+TimesNet (ours)} &
  \textbf{1.8103 ↓16.50\%} &
  \textbf{0.3394 ↓13.53\%} &
  \textbf{2.6347 ↓8.19\%} &
  \textbf{0.3150 ↓10.69\%} &
  \textbf{1.2871 ↓7.56\%} &
  \textbf{0.9287 ↓5.45\%} &
  \textbf{1.9107} &
  \textbf{0.5277} \\ \hline
\end{tabular}%
}
\end{table*}

%%%%
% Please add the following required packages to your document preamble:
% \usepackage{graphicx}
\begin{table*}[t]
\centering
\caption{Average testing performance over three runs with a 1 minute time interval across three datasets: Alibaba Group Traffic (3,744,000 test samples), Azure Traffic (4,032,000 test samples), and Ant Group Traffic (4,751,424 test samples).}
\label{tab:1T_performance}
\resizebox{\textwidth}{!}{%
\begin{tabular}{lcccccccc}
\hline
\multicolumn{1}{l|}{1 Minute} &
  \multicolumn{2}{c|}{Alibaba Group Traffic} &
  \multicolumn{2}{c|}{Microsoft Azure Traffic} &
  \multicolumn{2}{c|}{Ant Group Traffic} &
  \multicolumn{2}{c}{Overall Mean} \\ \hline
Method                                                      & MSE    & MAE             & MSE             & MAE    & MSE    & MAE    & MSE    & MAE    \\ \hline
MagicScaler~\cite{pan2023magicscaler} & 2.7799 & 0.4783          & 6.7159          & 0.4748 & 1.9403 & 1.1674 & 3.8120 & 0.7068 \\
OptScaler~\cite{zou2024optscaler}     & 3.2586 & 0.4912          & 6.5052          & 0.4693 & 1.3629 & 0.9598 & 3.7089 & 0.6401 \\
Llama3~\cite{touvron2023llama}        & 7.6830 & 1.1101          & 7.8901          & 0.6657 & 3.2022 & 1.5345 & 6.2584 & 1.1034 \\
TimeLLM~\cite{jintime}                & 3.1173 & 0.4423          & 5.3406          & 0.4513 & 1.4188 & 1.0059 & 3.2922 & 0.6332 \\
TimeMixer~\cite{wangtimemixer}        & 2.6458 & 0.4664          & 2.4406          & 0.3253 & 1.3918 & 0.9800 & 2.1594 & 0.5906 \\
iTransformer~\cite{liuitransformer}   & 2.3571 & 0.2800          & 2.3565          & 0.2875 & 1.3918 & 0.9804 & 2.0351 & 0.5160 \\
CCM+iTransformer (ours)                                     & 2.3677 & 0.2776          & 2.3206          & 0.2782 & 1.3608 & 0.9618 & 2.0164 & 0.5059 \\
TimesNet~\cite{wutimesnet}            & 2.2003 & \textbf{0.2609} & \textbf{2.2419} & 0.2602 & 1.3917 & 0.9791 & 1.9446 & 0.5001 \\
\textbf{CCM+TimesNet (ours)} &
  \textbf{2.1979 ↓0.11\%} &
  0.2612 &
  2.2503 &
  \textbf{0.2573 ↓1.09\%} &
  \textbf{1.3344 ↓4.12\%} &
  \textbf{0.9520 ↓2.77\%} &
  \textbf{1.9275} &
  \textbf{0.4902} \\ \hline
\end{tabular}%
}
\end{table*}

\textbf{Performance Comparisons.} To evaluate the performance of CCMPlus (CCM+), we compare two variants of our proposed framework, CCM+TimesNet and CCM+iTransformer, against the baselines introduced in Section~\ref{sec:baselines}. 
As shown in Table~\ref{tab:30T_performance}, we report the prediction results on three datasets, with the prediction granularity set to 30 minutes.
Among all the baselines, Llama3 performs the worst. 
While large language models have demonstrated effectiveness in reasoning over sequential data, web traffic exhibits significantly higher volatility, posing substantial challenges for plain LLMs to accurately forecast future values. 
In contrast, TimeLLM inherently treats time series patches as tokens and employs task-specific prompt embeddings for forecasting. 
Although it captures patch correlations, it still underperforms on dynamic web traffic data compared to methods specifically tailored for time series analysis.
Magicscaler and OptScaler, in particular, are designed for service workload prediction. While these models account for the volatility inherent in traffic time series, they fail to explicitly capture the underlying seasonal and trend components, which are crucial for predicting web service traffic driven by human behavior. 

TimeMixer addresses this limitation by decomposing time series into seasonal and trend components across multiple periodicities, enabling it to learn decomposed temporal patterns ranging from fine-grained to macro-level perspectives. 
As a result, TimeMixer achieves superior prediction performance compared to both LLM-based methods and specialized workload prediction models.
TimesNet leverages Fourier transforms to derive more adaptive periodicity terms, further reducing prediction errors. 
On the other hand, iTransformer treats independent time series as tokens, learning both temporal and cross-dimensional correlations by modeling token sequences, and achieves performance comparable to TimesNet. 
However, all the above methods focus solely on internal temporal patterns while neglecting external causal relationships across multiple time series. 
To address this limitation, we integrate CCMPlus with TimesNet and iTransformer—the two best-performing baseline models—to create two new variants.
As observed, while TimesNet and iTransformer employ carefully designed architectures and achieve SOTA performance across different prediction granularity, integrating CCMPlus leads to further improvements. 
This highlights the importance of capturing the causality inherent in web service traffic for accurate traffic volume prediction. Furthermore, CCMPlus effectively models this causality, contributing to enhanced predictive performance.

\textbf{Prediction Granularity Analysis.} Prediction granularity is an important factor for traffic forecasting. 
To assess this, we vary the time interval of each data point in the time series in \{1, 5, 15, 30\} minutes and compare the model performances in Table~\ref{tab:30T_performance}, \ref{tab:15T_performance}, \ref{tab:5T_performance} and \ref{tab:1T_performance}. 
Note that the more fine-grained time interval setting would generate more data samples as reported in the table caption.
First, we observe that CCMPlus consistently improves the SOTA models (TimesNet and iTransformer), underscoring the importance of considering causality among service traffic patterns. 
Notably, CCMPlus demonstrates flexibility in integrating with various SOTA backbone models, highlighting its potential for performance enhancement.
Second, the performance improvements diminish for the 1-minute prediction granularity setting. 
This is because service traffic is highly dynamic and volatile, and fine-grained time series data often lack a sufficient time duration to accumulate information necessary for capturing reliable causal relationships. Nevertheless, CCMPlus still achieves the best performance, further demonstrating its superiority in extracting hidden causal relationships and boosting prediction accuracy even under challenging conditions.

\subsection{Ablation Study}
\label{sec:ablation_study}
\begin{table}[t]
\centering
\caption{Ablation study on the Microsoft Azure Traffic dataset with a 5 minutes time interval, including 806,000 test samples.}
\label{tab:ablation_study}
\resizebox{0.8\linewidth}{!}{%
\begin{tabular}{ccc}
\hline
Method                         & MSE    & MAE    \\ \hline
CCM+TimesNet (ours)                    & 2.6347 & 0.3150 \\
w/o CCMPlus             & 2.8696 & 0.3527 \\
w/o Backbone Time Series Model & 2.9981 & 0.3627 \\ \hline
\end{tabular}%
}
\end{table}

CCM+TimesNet consistently outperforms multiple baselines across three datasets. Using CCM+TimesNet, we conduct an ablation study on the most challenging dataset, Microsoft Azure Traffic. Table~\ref{tab:ablation_study} presents the impact of individual modules in CCM+TimesNet, yielding the following insights: (\textbf{1}) Removing the CCMPlus module (w/o CCMPlus) degrades model performance, as CCMPlus generates feature representations that capture causal relationships among web services, enhancing traffic prediction accuracy. (\textbf{2}) Excluding the Backbone Time Series Model (w/o Backbone Time Series Model) also reduces performance. The deep learning-based backbone extracts essential seasonal and trend-related temporal features, which are crucial for accurate web service traffic forecasting.  


\subsection{Evaluation Speed}
\label{sec:evaluation_speed}
\begin{table}[t]
\centering
\caption{Evaluation speed of various methods on the Microsoft Azure Traffic dataset with a 5 minutes time interval, tested on an H100 device. All methods use the same evaluation batch size.}
\label{tab:parameter_volume_eval_speed}
\resizebox{0.8\linewidth}{!}{%
\begin{tabular}{lcc}
\hline
Method & \begin{tabular}[c]{@{}c@{}}Parameter \\ Volume\end{tabular} & \begin{tabular}[c]{@{}c@{}}Evaluation\\ Speed\end{tabular} \\ \hline
Llama3          & 8 Billion & 18.2221s/batch \\
TimeLLM         & 7 Billion & 92.0710s/batch \\
MagicScaler     & 111220    & 0.0072s/batch  \\
OptScaler       &  22608         & 0.0067s/batch             \\
TimeMixer       & 267578    & 0.0069s/batch  \\
iTransformer    & 22626     & 0.0038s/batch  \\
CCM+iTransformer (ours) & 252241    & 0.0064s/batch  \\
TimesNet        & 2375283   & 0.4638s/batch  \\
CCM+TimesNet (ours)     & 2604898   & 0.5045s/batch  \\ \hline
\end{tabular}%
}
\end{table}

As shown in Table~\ref{tab:parameter_volume_eval_speed}, large language model (LLM)-based methods generally exhibit slower evaluation speeds due to their substantial parameter volumes. In contrast, our methods, CCM+TimesNet and CCM+iTransformer, achieve relatively fast evaluation speeds while outperforming other baselines, as demonstrated in Tables~\ref{tab:30T_performance}, \ref{tab:15T_performance}, \ref{tab:5T_performance}, and \ref{tab:1T_performance}. Overall, the CCMPlus module enhances prediction performance while maintaining a reasonable computational efficiency. 

% 
\begin{figure*}[tbh!]
  \centering
\includegraphics[width=\textwidth]{figures/services_heatmap_AB.pdf}
  \caption{The causal relationship between web service A and service B}
  \label{fig:services_heatmap_AB}
\end{figure*}
\subsection{Hyperparameter Configuration}
\label{sec:hyperparameter_analysis}

\begin{table}[t]
\centering
\caption{Hyperparameter analysis of momentum value $m$ for causal correlation matrix, conducted on the Microsoft Azure Traffic dataset with a 5 minutes time interval using the CCM+TimesNet method. The dataset comprises 806,000 test samples, and the results are averaged over three experiments.}
\label{tab:hyperparameter_analysis_2}
\resizebox{0.8\linewidth}{!}{%
\begin{tabular}{ccc}
\hline
$m$ & MSE          & MAE          \\ \hline
0              & 2.6346 82873 & 0.3150 20664 \\
0.2            & 2.6346 82146 & 0.3150 20501 \\
0.5 (ours)           & 2.6346 80012 & 0.3150 20010 \\
0.8            & 2.6346 79774 & 0.3150 20189 \\ \hline
\end{tabular}%
}
\end{table}

\begin{table*}[tbh!]
\centering
\caption{Hyperparameter analysis of $C_{in}$, $C_{out}$, and $\tau$, conducted on the Microsoft Azure Traffic dataset with a 5 minutes time interval using the CCM+TimesNet. The dataset comprises 806,000 test samples, and the results are averaged over three experiments.}
\label{tab:hyperparameter_analysis_1}
\resizebox{0.7\textwidth}{!}{%
\begin{tabular}{ccccccccc}
\hline
$C_{in}$ & MSE    & MAE    & $C_{out}$ & MSE     & MAE     & $\tau$        & MSE     & MAE     \\ \hline
12                & 2.6873 & 0.3178 & 28                 & 2.8307  & 0.3149  & {[}1, 2, 3{]}       & 2.7945 & 0.3157 \\
14                & 2.8256 & 0.3385 & 30                 & 2.6894 & 0.3223 & {[}1, 2, 3, 4{]} (ours)    & 2.6347 & 0.3150 \\
16 (ours)                & 2.6347 & 0.3150 & 32 (ours)                & 2.6347 & 0.3150 & {[}1, 2, 3, 4, 5{]} & 2.6531 & 0.3144 \\
18                & 2.7078 & 0.3170 & 34                 & 2.6357  & 0.3143 &                     &         &         \\
20                & 2.6311 & 0.3117 & 36                 & 2.7461 & 0.3273 &                     &         &         \\ \hline
\end{tabular}%
}
\end{table*}


Tables~\ref{tab:hyperparameter_analysis_2} and~\ref{tab:hyperparameter_analysis_1} present the hyperparameter analysis, evaluating the impact of the following parameters:

\( C_{in} \) defines the embedding dimension of the input time series \( \hat{\mathbf{X}} \). As shown in Table~\ref{tab:hyperparameter_analysis_1}, the model maintains stable performance across values, demonstrating robustness. Increasing this dimension enhances feature richness, but for efficiency, we set \( C_{in} = 16 \).


\( C_{out} \) defines the embedding dimension of shadow manifold points. A small value may miss features, while a large one can introduce noise. To balance representation quality and efficiency, we set \( C_{out} = 32 \).

The values in \( \tau \) define the dilation parameter in Conv1D, controlling the number of shadow manifolds. Increasing this number enhances feature extraction but incurs higher computational costs. To balance accuracy and efficiency, we set \( \tau = [1,2,3,4] \).

As shown in Table~\ref{tab:hyperparameter_analysis_1}, momentum value \( m \) stabilizes the causal correlation matrix by integrating current and past iterations, as defined in Equation~\ref{eq:causal_matrix_update}. Setting $m$ loses general features, while \( m = 0.8 \) reduces adaptability. We choose \( m = 0.5 \) for a balance between stability and adaptability.

\subsection{Case Study}
\begin{figure}[t]
  \centering
\includegraphics[width=0.75\linewidth,keepaspectratio]{figures/services_heatmap.pdf}
  \caption{The causal relationship with regard to Web service A in the heatmap.}
  \label{fig:services_heatmap}
\end{figure}

% \begin{figure*}[tbh!]
%   \centering
% \includegraphics[width=\textwidth]{figures/services_heatmap_AB.pdf}
%   \caption{The causal relationship between Web service A and service B}
%   \label{fig:services_heatmap_AB}
% \end{figure*}
Using the Azure Traffic dataset, we compute causal relationships between web services with the CCMPlus module. To visualize, we compare Service A with twenty randomly sampled services and plot the causal correlation heatmap (Figure~\ref{fig:services_heatmap}), where Service A exhibits a strong causal correlation with the third service, referred to as Service B. To further analyze this relationship, we plot the traffic time series of Services A and B over the same period (Figure~\ref{fig:services_heatmap_AB}). The inverse correlation—when one service's request volume rises, the other's declines—confirms the strong causal relationship observed in the heatmap.

% \subsection{Error Analysis *consider remove?}

% \begin{table}[tbh!]
% \centering
% \caption{Error analysis of the 10 services with the largest and smallest MSE values, evaluated in terms of ADF scores. The analysis was conducted on the Microsoft Azure Traffic dataset with a 5T time interval using the CCM+TimesNet.}
% \label{tab:error_analysis}
% \resizebox{0.7\linewidth}{!}{%
% \begin{tabular}{cc}
% \toprule
% \textbf{Top 10 Services Category} & \textbf{Averaged ADF Score} \\ \midrule
% Smallest MSE & -20.9963 \\
% Largest MSE & -6.8813 \\ \bottomrule
% \end{tabular}%
% }
% \end{table}


% We analyze errors on the Azure Traffic dataset (5T interval) using the Augmented Dickey-Fuller (ADF) test to assess stationarity. A lower (more negative) ADF score indicates higher stationarity. Examining the 10 web services with the highest and lowest MSE values, we find that larger MSE losses correspond to higher averaged ADF scores. This suggests that volatile time series are harder to model due to their complex temporal patterns, posing challenges for time series forecasting.









