\section{Detailed review on related work}
\label{app:additional-related-work}
In this section, we provide a more detailed (but still non-exhaustive) review of the literature. 
We mainly focus on theoretical work with formal performance guarantees, leaving out the extensive body of work with empirical results.
We first survey papers with the same reward criterion as ours, i.e., infinite-horizon average-reward criterion. 
In this setting, we begin with papers on homogeneous restless bandits (RBs), which is a special case considered by most existing papers. 
Then we give a more detailed review of the papers on average-reward WCMDPs. 
Afterward, we review the papers on WCMDPs with two other reward criteria, i.e., the finite-horizon total-reward criterion and the infinite-horizon discounted-reward criterion. 
Finally, we briefly mention other problems that are related to WCMDPs. 


\paragraph{Infinite-horizon average-reward homogeneous RBs.}
The first asymptotic optimality result for average-reward homogeneous RBs was established by \citet{WebWei_90}: it was shown that the \emph{Whittle index policy} \citep{Whi_88_rb} achieves an $o(1)$ optimality gap as the number of arms $N$ goes to infinity. There are three key assumptions in \citep{WebWei_90}: indexability, the global attractor property, and the aperiodic-unichain condition. 
These assumptions are gradually relaxed in the subsequent papers. In particular, \cite{Ver_16_verloop} proposed a class of priority policies based on an LP relaxation. This class of policies, later referred to as the \emph{LP-Priority policies}, generalizes the Whittle index policy. Each LP-Priority policy achieves an $o(1)$ optimality gap without requiring indexability. 
Later, \citet{HonXieChe_23,HonXieChe_24} introduced new policies that further removed the global attractor property and improved the optimality gap to $O\bigl(1/\sqrt{N}\bigr)$. 
More recently, \citet{Yan_24} proposed the \emph{align-and-steer policy}, which further weakened the aperiodic-unichain condition and achieved an $o(1)$ optimality gap. 

Parallel to relaxing the assumptions for asymptotic optimality, another of line of work has focused on improving the optimality gap beyond $O(1/\sqrt{N})$ under slightly stronger assumptions \citep{GasGauYan_23_exponential,GasGauYan_23_whittles,hong2024exponential}. 
Specifically, \citet{GasGauYan_23_whittles} showed that the Whittle index policy has an $O(\exp(-cN))$ optimality gap for some constant $c>0$. In addition to indexability and the aperiodic-unichain condition, \citep{GasGauYan_23_whittles} also requires a stronger version of global attractor property named Uniform Global Attractor Property (UGAP), and a condition called non-singularity. 
Subsequently, \citet{GasGauYan_23_exponential} showed that LP-Priority policies achieve $O(\exp(-cN))$ optimality gaps assuming the aperiodic-unichain condition, UGAP, and a non-degenerate condition that is equivalent to non-singularity. 
More recently, \citet{hong2024exponential} proposed a \emph{two-set policy} that also achieves an $O(\exp(-cN))$ optimality gap while replacing UGAP of \citep{GasGauYan_23_exponential} with a much weaker condition named local stability. 


\paragraph{Infinite-horizon average-reward WCMDPs.}
The papers on average-reward WCMDPs remain relatively scarce, and to our knowledge, fully heterogeneous WCMDPs have yet to be addressed. Nevertheless, some papers consider special cases of WCMDPs that generalize restless bandits by allowing multiple actions, more general constraints, or typed heterogeneity. 
In particular, \citep{Ver_16_verloop} extended the LP-Priority policies to typed heterogeneous WCMDPs with a single constraint. The $o(1)$ optimality gap of LP-Priority policies continues to hold under the same set of assumptions, namely, the aperiodic-unichain condition and the global attractor property. 
More recently, \citep{GolAvr_24_wcmdp_multichain} considered homogeneous WCMDPs and proposed a class of policies with $o(1)$ optimality gaps under a weaker-than-standard aperiodic-unichain condition. 


\paragraph{Finite-horizon total-reward RBs and WCMDPs.}
Next, we review the asymptotic optimality results for finite-horizon total-reward RBs and WCMDPs. The finite-horizon setting is better understood than the average-reward setting, partly because the analysis in the finite horizon is not hindered by the technical conditions arising from average-reward MDPs, such as the unichain condition and the global attractor property. On the other hand, the computation of policies in existing work for the finite-horizon setting is more complicated, requiring a careful optimization of the transient sample paths. 

\citet{HuFra_17_rb_asymptotic} proposed the first asymptotic optimal policy for finite-horizon homogeneous RBs, which achieves an $o(1)$ optimality gap without any assumptions.\footnote{Here, we measure the optimality gap in terms of the reward per arm, to be consistent with our convention. However, in the papers on the finite-horizon total-reward setting, it is also common to measure the optimality gap in terms of the total reward of all arms, which differs from ours by a factor of $N$. We also stick to the same convention when reviewing the papers on the infinite-horizon discounted-reward setting.} 
Since then, researchers have established asymptotic optimality in more general settings \citep{ZayJasWan_19_rb,DaeChoGri_23,GhoNagJaiTam_23_finite_discount,BroSmi_19_rb,BroZha_22}. 
Among these papers, the most general setting was addressed in \citep{BroZha_22}. Specifically, \citet{BroZha_22} obtained an $O(1/\sqrt{N})$ optimality gap in a generalization of the fully heterogeneous WCMDPs, which has an exogenous state that modulates the transition probabilities, rewards, and the constraints of all arms. 


Another line of papers improved the optimality gap beyond the order $O(1/\sqrt{N})$ by making an additional assumption called non-degeneracy. Specifically, \citet{ZhaFra_21} established an $O(1/N)$ optimality gap in non-degenerate homogeneous RBs. \citet{GasGauYan_23_exponential} then proposed a different policy for the same setting that improved the optimality gap to $O(\exp(-cN))$. Later, \citet{GasGauYan_24_reopt} and \citet{BroZha_23} established $O(1/N)$ optimality gaps for homogeneous and fully heterogeneous WCMDPs, respectively, assuming non-degeneracy. More recently, \citet{Zhang24_het} proposed a policy for fully heterogeneous WCMDPs; the optimality gap bound of the policy interpolates between $O(1/\sqrt{N})$ and $O(1/N)$ as the degree of non-degeneracy varies, unifying the performance bounds in the degenerate and non-degenerate worlds. 


Despite the generality of the settings and the fast diminishing rate of the optimality gaps as $N\to\infty$, most of the optimality gaps in the finite-horizon setting depend \emph{super-linearly} on the time horizon, except under special conditions \citep{BroZha_23,GasGauYan_24_reopt}. Consequently, these results do not carry over to the infinite-horizon average-reward setting. Moreover, the algorithms in these papers need to (sometimes repeatedly) solve LPs whose number of variables scale with the time horizon, so they cannot be directly adapted to the infinite-horizon average-reward setting. 


\paragraph{Infinite-horizon discounted-reward RBs and WCMDPs.}
Asymptotic optimality has also been established for RBs and WCMDPs under the infinite-horizon discounted-reward criterion. 
In particular, \citet{BroSmi_19_rb} established an $O(N^{\log_2 (\sqrt{\gamma})})$ optimality gap for fully heterogeneous WCMDPs when $\gamma \in (1/2, 1)$. Subsequently, \citet{ZhaFra_22_discounted_rb,GhoNagJaiTam_23_finite_discount}  obtained $O(1/\sqrt{N})$ optimality gaps for homogeneous and typed heterogeneous RBs, and \citet{BroZha_23} established the same order of optimality gap for fully heterogeneous WCMDPs. 
Similar to the finite-horizon setting, most of these optimality gaps depend super-linearly on the effective time horizons $1/(1-\gamma)$ unless special conditions hold \citep{BroZha_23}, so they do not carry over to the infinite-horizon average-reward setting. 
The policies here also require solving LPs whose complexities scale with the effective time horizon. 


\paragraph{Restful bandits, stochastic multi-armed bandits.}
A special case of RB is the restful bandit (also referred to as nonrestless bandits or Markovian bandits), where an arm's state does not change if it is not pulled.
The restful bandit problem has been widely studied, where the celebrated Gittins index policy is proven to be optimal \citep{GitJon_74,Git_79,BerNin_96,Tsi_94,Web_92,VarWalBuy_85,Whi_80}. We refer the readers to \citep{GitGlaWeb_11} for a comprehensive review of Gittins index and restful bandits. 
Another related topic is the stochastic multi-armed bandit (MAB) problem, which has been extensively studied; see the book \citep{LatSze_20} for a comprehensive overview. 
The key distinction between MABs and RBs is that arms are stateless in MABs, but stateful in RBs. Consequently, MAB becomes trivial with known model parameters, whereas RB is still non-trivial. 





\section{Proving the LP relaxation}\label{app:proof-lem-lp-upper-bound}
In this section, we prove Lemma~\ref{lem:lp upper bound}, which shows that the linear program in \eqref{eq:lp} is a relaxation of the WCMDP problem. \Cref{lem:lp upper bound} is restated as follows.  

\lprelaxation*


\begin{proof}
To upper bound the optimal reward of the WCMDP, $R^*(N,\bm{S}_0)$, we observe that standard MDP theory ensures that a stationary Markovian policy achieves the optimal reward, as the WCMDP has finitely many system states and system actions \citep[Theorem 9.18]{Put_05}. 
Therefore, it suffices to show that $R(\pi,\bm{S}_0) \leq \rrel$ for any stationary policy $\pi$ and initial system state $\bm{S}_0$. 

For any stationary policy $\pi$, consider the \emph{state-action frequency under $\pi$}, given by  
\begin{align*}
    y^\pi_i(s,a) = \lim_{T\to\infty} \frac{1}{T} \sum_{t=0}^{T-1} \EE\mbracket{\mathbf{1}\sets{S_{i,t}^\pi=s,A_{i,t}^\pi=a}}\,,~~\forall s\in\sspa, a\in\aspa, i\in[N]\,.
\end{align*}
where the limit is well-defined due to the stationarity of $\pi$. 
We argue that $y^\pi\triangleq (y_i^\pi(s,a))_{i\in[N] s\in\sspa, a\in\aspa}$ is a feasible solution to the LP relaxation in \eqref{eq:lp}, with objective value being $R(\pi, \bm{S}_0)$. Then $R(\pi,\bm{S}_0) \leq \rrel$ follows from the optimality of $\rrel$. 

To show that $y^\pi$ satisfies the budget constraints of the LP relaxation \eqref{eq:lp:budget-constraint}, we compute as follows: for any $s\in\sspa$, $a\in\aspa$ and constraint $k\in [K]$, we have
\begin{align*}
    \sumN c_{k,i}(s,a) y^\pi_i(s,a) 
    &= \sumN \sum_{s\in\sspa,a\in\aspa} c_{k,i}(s,a) \lim_{T\to\infty} \frac{1}{T} \sum_{t=0}^{T-1}\EE\mbracket{\mathbf{1}\sets{S_{i,t}^\pi=s,A_{i,t}^\pi=a}}\\
    &= \lim_{T\to\infty} \frac{1}{T}\EE\mbracket{ \sumN\sum_{s\in\sspa,a\in\aspa}c_{k,i}(S_{i,t}^\pi,A_{i,t}^\pi)}\\
    &\leq \alpha_k N\,,
\end{align*}
where the inequality follows from the fact that  under a feasible $N$-armed policy $\pi$, $\sum_{i\in[N]}\sum_{s\in\sspa,a\in\aspa} c_{k,i}(S_{i,t}^\pi,A_{i,t}^\pi) \leq \alpha_k N$ for each budget constraint $k\in[K]$.

Then we verify that $y^\pi$ satisfies the stationarity constraint of the LP relaxation \eqref{eq:lp:stationarity-constraint}: for any state $s\in\sspa$ and arm $i\in[N]$, we have
\begin{align*}
    \sum_{s'\in\sspa,a'\in\aspa}y_i^\pi(s',a')\PP_i(s \mid s',a')&=\lim_{T\to\infty}\frac{1}{T} \sum_{t=0}^{T-1} \sum_{s'\in\sspa,a'\in\aspa}P(S_{i,t}^\pi=s',A_{i,t}^\pi=a')\PP_i(s\mid s',a')\\
    &=\lim_{T\to\infty} \frac{1}{T} \sum_{t=0}^{T-1}P(S_{i,t+1}^\pi=s) \\
    &= \lim_{T\to\infty} \frac{1}{T} \sum_{t=1}^T P(S_{i,t}^\pi=s)\\
    &= \sum_{a\in\aspa} y^\pi_i(s,a)\,.
\end{align*}


We then argue that for each $i\in [N]$, $(y_i^\pi(s,a))_{s\in\sspa, a\in\aspa}$ is in the probability simplex of $\sspa\times \aspa$, as required by the last constraint in \eqref{eq:lp:probability-constraint}, which is obvious: for any $i\in [N]$ and $s\in\sspa, a\in\aspa$, we have $y^\pi_i(s,a)\geq 0$; for any $i\in[N]$, we have 
\begin{align*}
    \sum_{s\in\sspa,a\in\aspa}y_i^\pi(s,a)= \lim_{T\to\infty}\sum_{t=0}^{T-1} \EE\mbracket{\sum_{s,a}\mathbf{1}\sets{S_{i,t}^\pi=s,A_{i,t}^\pi=a}}=1\,.
\end{align*} Therefore, $y^\pi$ satisfies the constraints of the LP relaxation. 

Finally, we show that the objective value of $y^\pi$ equals $R(\pi,\bm{S}_0)$:
\begin{align*}
    \frac{1}{N}\sumN \sum_{s\in\sspa,a\in\aspa} y_i^\pi(s,a)r_i(s,a)
    &=\frac{1}{N}\sumN \sum_{s\in\sspa,a\in\aspa} r_i(s,a) \lim_{T\to\infty} \frac{1}{T}\sum_{t=0}^{T-1}\EE\mbracket{\mathbf{1}\sets{S_{i,t}^\pi=s,A_{i,t}^\pi=a}}\\
    &= \lim_{T\to\infty} \frac{1}{T} \sum_{t=0}^{T-1}\frac{1}{N}\sumN \EE[r_i(S_{i,t}^\pi,A_{i,t}^\pi)]\\
    &= R(\pi,\bm{S}_0)\,.
\end{align*}
Because $\rrel$ is the optimal value of the LP relaxation, we have $\rrel \geq R(\pi,\bm{S}_0)$ for any stationary policy $\pi$. Taking $\pi$ to be the optimal policy finishes the proof. 
\end{proof}





\section{Proof of Lemma~\ref{lem:positiveC}}\label{app:proof-lem-positiveC}
In this section, we prove Lemma~\ref{lem:positiveC}, which are properties of the remaining budget function $\rembud_k(\cdot)$ after applying the ID reassignment algorithm (\Cref{alg:id-assign}). Lemma~\ref{lem:positiveC} is restated as follows. 

\positiveC*

\begin{proof}
Our goal is to prove that for any $n_1,n_2$ with $1\le n_1\le n_2\le N$, we have
\begin{equation}
    \rembud_k([n_1])-\rembud_k([n_2])\ge \eta_c(n_2-n_1)-M_c,
\end{equation}
for all $k\in[K]$, where
\begin{align*}
    \eta_c = \min\sets{\frac{\alpha_{\min}}{3},\costIDreassign\cdot\left(\left\lceil \frac{(c_{\max}-\costIDreassign)K}{\alpha_{\min}/2-\costIDreassign}\right\rceil\right)^{-1}}, \quad M_c = 2\costIDreassign.
\end{align*}


\paragraph{Case 1: $\cA=\emptyset$.}
For any $k\in[K]$, by the definition of the remaining budget in \eqref{eq:remain-bud},
\begin{align*}
    \rembud_k([n_1])-\rembud_k([n_2])&=\left(\alpha_k N - C_k^*([n_1])-\frac{\alpha_k}{3}n_1\right) - \left(\alpha_k N - C_k^*([n_2])-\frac{\alpha_k}{3}n_2\right)\\
    &= C_k^*([n_2])- C_k^*([n_1]) + \frac{\alpha_k}{3}(n_2-n_1)\\
    &\ge \frac{\alpha_k}{3}(n_2-n_1)\\
    &\ge \eta_c(n_2-n_1)-M_c.
\end{align*}

\paragraph{Case 2: $\cA\neq \emptyset$.}
In this case, for any $k\notin \cA$, following the same arguments as those in the previous paragraph, we again get $\rembud_k([n_1])-\rembud_k([n_2])\ge \eta_c(n_2-n_1)-M_c.$

Now consider any $k\in\cA$.
Let $\cD_k=\{i\in[N]\colon C_{k,i}^*\ge \costIDreassign\}.$
We first show that
\begin{equation}\label{eq:sizeDk}
\abs{\cD_k}\geq \frac{(\alpha_k/2-\costIDreassign)N}{c_{\max}-\costIDreassign}.
\end{equation}
Note that 
\begin{equation}
    \sum_{i\in [N]} C_{k,i}^* \leq c_{\max}|\cD_k|+\costIDreassign (N-|\cD_k|).
\end{equation}
Also since the type-$k$ constraint is active,
\begin{equation}
    \sum_{i\in[N]} C_{k,i}^* \ge \frac{\alpha_k}{2}N.
\end{equation}
Combining these two inequalities and recalling that the parameter $\costIDreassign$ is chosen such that $\costIDreassign<\alpha_{\min}/2\le \alpha_k/2$, where $\alpha_k/2 \le c_{\max}$ since $\alpha_kN/2\le \sum_{i\in[N]} C_{k,i}^*\le c_{\max}N$,
gives \eqref{eq:sizeDk}.

We next argue that $\cD_k$ contains enough arms to ensure the ID reassignment steps from line~\ref{alg:line:reassign-start} to line~\ref{alg:line:reassign-end} in Algorithm~\ref{alg:id-assign} can be performed.
Observe that for each $\ell = 0,1,\dots,\lfloor N/ \gsizeIDreassign\rfloor -1$, these steps remove at most $K$ elements from each $\cD_k$.
To confirm $\cD_k$ contains enough arms, note that
\begin{align*}
    \abs{\cD_k}&\geq \frac{(\alpha_k/2-\costIDreassign)N}{c_{\max}-\costIDreassign}\\
    &\ge KN\cdot \frac{\alpha_{\min}/2-\costIDreassign}{(c_{\max}-\costIDreassign)K}\\
    &\ge KN\cdot\frac{1}{\gsizeIDreassign}\\
    &\ge K\lfloor N/\gsizeIDreassign\rfloor,
\end{align*}
where we used the definition $\gsizeIDreassign = \left\lceil \frac{(c_{\max}-\costIDreassign)K}{\alpha_{\min}/2-\costIDreassign}\right\rceil$.


We are now ready to prove the inequality $\rembud_k([n_1])-\rembud_k([n_2])\ge \eta_c(n_2-n_1)-M_c$ for any $n_1,n_2$ with $1\le n_1\le n_2\le N$.
Consider the arms with new IDs in $[n_1:n_2]$.
Let $g$ be the number of groups from groups of the form $\cI(\ell)=[\ell \gsizeIDreassign+1:(\ell+1)\gsizeIDreassign]$ with $\ell=0,1,\dots,\lfloor N/\gsizeIDreassign\rfloor -1$ that are completely contained in $[n_1:n_2]$.
Then it is easy to see
\begin{equation*}
    g \ge \frac{n_2-n_1}{\gsizeIDreassign}-2.
\end{equation*}
Since Algorithm~\ref{alg:id-assign} ensures that $\sum_{i\in[N]}C_{k,i}^*\mathbbm{1}\{\newID(i)\in \cI(\ell)\}\ge \costIDreassign$ for each $\ell$, we know that
\begin{equation*}
    C_k^*([n_1:n_2])\ge \left(\frac{n_2-n_1}{\gsizeIDreassign}-2\right)\costIDreassign.
\end{equation*}
Therefore,
\begin{align*}
    \rembud_k([n_1])-\rembud_k([n_2]) & = \alpha_k N-C_k^*([n_1])-(\alpha_k N-C_k^*([n_2]))\\
    &=C_k^*([n_2])-C_k^*([n_1])\\
    &=C_k^*([n_1:n_2])\\
    &\ge \left(\frac{n_2-n_1}{\gsizeIDreassign}-2\right)\costIDreassign\\
    &\ge \eta_c(n_2-n_1)-M_c.
\end{align*}

For $\rembud(D)=\min_{k\in[K]}\rembud_k(D)$, it is straightforward to verify that
\begin{align*}
    \rembud([n_1])-\rembud([n_2]) &= \min_{k\in[K]}\rembud_k([n_1]) - \min_{k\in[K]}\rembud_k([n_2])\\
    &\ge \min_{k\in[K]}\left(\rembud_k([n_1]) - \rembud_k([n_2])\right)\\
    &\ge \eta_c(n_2-n_1)-M_c,
\end{align*}
which completes the proof.
\end{proof}





\section{Lemmas and proofs for subset Lyapunov functions}
\label{sec:lem-proof-subset}

In this section, we first provide several preliminary lemmas on the transition matrices under the optimal single-armed policies in Section~\ref{sec:preliminary-transition}, which will be utilized in subsequent subsections.
In Section~\ref{app:proof-lem-drift}, we prove Lemma~\ref{lem:drift}, which addresses the properties of the subset Lyapunov functions $(h(\cdot,D))_{D\subseteq [N]}$.
Finally, in Section~\ref{sec:properties-hID}, we present and prove Lemma~\ref{lem:hID drift}, which establishes properties of the function $h_{\ID}(\cdot,\cdot)$.

\subsection{Preliminary lemmas on transition matrices}
\label{sec:preliminary-transition}
In this section, we prove several preliminary lemmas related to properties of the transition matrix $P_i$
of each arm $i$ under its optimal single-armed policy $\pibs_i$. 
Let $\Xi_i$ denote a matrix whose rows are the same vector $\mu_i^*$.


Recall that in \Cref{ass:unichain}, we have assumed a uniform lower bound on the spectral gap of the transition matrix $P_i$. Below, we prove an equivalent form of this assumption, which will be useful for later proofs. 

\begin{lemma}\label{lem:spectral-radius}
    \Cref{ass:unichain} is equivalent to the following statement: for each $i\in \mathbb{N}_+$, the spectral radius of $P_i - \Xi_i$ is bounded by $\specrad$, i.e., 
    \begin{equation}\label{eq:spectral-radius-condition}
        \rho(P_i - \Xi_i) \leq \specrad,
    \end{equation}
    where recall that $P_i$ is the transition matrix of the $i$-th arm under its optimal single-armed policy $\pibs_i$, $\Xi_i$ is the rank-one matrix with each row being $\mu_i^*$, and $0\leq \specrad < 1$ is the constant given in \Cref{ass:unichain}. 
\end{lemma}
    
\begin{proof}
    To show the equivalence between \Cref{ass:unichain} and the statement in this lemma, it suffices to show the following claim: 
    Excluding the eigenvalue $1$, $P_i$ and $P_i - \Xi_i$ have the same spectrum, for each $i\in \mathbb{N}_+$.  

    We fix an arbitrary $i\in \mathbb{N}_+$. 
    Let $\lambda$ and $v$ be a pair of eigenvalue and left-eigenvector of $P_i$ such that $\lambda \neq 1$ and $\sum_{s\in\sspa} v(s) = 1$. Let $u = \lambda v - \mu^*_i$. 
    We claim that $(\lambda, u)$ is a left-eigenpair of $P_i - \Xi_i$. First, by straightforward calculations, we have
    \begin{align}
        \nonumber
        u (P_i - \Xi_i)
        &= (\lambda v - \mu^*_i) (P_i - \Xi_i)\\
        \nonumber
        &= \lambda v (P_i - \Xi_i) - \mu^*_i (P_i - \Xi_i) \\
        \label{eq:pf-spectral-equiv:equation-1}
        &= \lambda^2 v - \lambda \statdist_i \\
        \nonumber
        &= \lambda u
    \end{align}
    where \eqref{eq:pf-spectral-equiv:equation-1} is due to $v\Xi_i = \statdist_i$ and $\statdist_i P_i = \statdist_i \Xi_i = \statdist_i$. 
    Moreover, we argue that $u$ is a non-zero vector: Suppose $u =\lambda v - \mu^*_i = 0$, then $v = \lambda^{-1} \mu^*_i$. Consequently, $v$ shares the same eigenvalue with $\statdist_i$, contradicting the fact that $\lambda \neq 1$. 
    Therefore, $(\lambda, u)$ is a left-eigenpair of $P_i - \Xi_i$. 

    Conversely, let $(\lambda, u)$ be a left-eigenpair of $P_i - \Xi_i$ such that $\lambda \neq 1$ and $\sum_{s\in\sspa}u(s) = 1$. Let $v = (1-\lambda) u - \statdist_i$. We claim that $(\lambda, v)$ is a left-eigenpair of $P_i$. First, we calculate that 
    \begin{align*}
        \nonumber
        v P_i
        &=  \big((1-\lambda) u - \statdist_i\big) P_i \\
        &= (1-\lambda)u P_i - \statdist_i \\
        &= (1-\lambda)u (P_i - \Xi_i) + (1-\lambda)\statdist_i - \statdist_i \\
        &= \lambda(1-\lambda)u -\lambda \statdist_i \\
        &= \lambda v.
    \end{align*}
    Secondly, we have $v\neq 0$ because otherwise $u$ is collinear with $\statdist$, leading to $\lambda = 1$. 
    Therefore, $(\lambda, v)$ is a left-eigenpair of $P_i$. 

    We have thus shown that excluding the eigenvalue $1$, $P_i$ and $P_i - \Xi_i$ have the same spectrum. 
    Then given \Cref{ass:unichain}, $\rho(P_i - \Xi_i) = \abs{\lambda_2(P_i)} \leq \specrad$. Conversely, given $\rho(P_i - \Xi_i) \leq \specrad$, each eigenvalue of $P_i$ either equals $1$ or has modulus upper bounded by $\rho(P_i - \Xi_i) \leq \specrad$. This completes the proof of \Cref{lem:spectral-radius}. 
\end{proof}

The fact that $\rho(P_i - \Xi_i) \leq \specrad$ implies that $\norm{(P_i-\Xi_i)^n}$ converges to zero as $n\to\infty$ at a geometric rate. 
Based on this fact, we prove a lemma that bounds the infinite series $\sum_{n=1}^{\infty} \sup_i\norm{(P_i-\Xi_i)^n} / \gamma^n$, which will play an important role in analyzing the subset Lyapunov functions $h(\mx,D)$ in \eqref{eq:h-def} and $\hid(\mx,D)$. 

\begin{lemma}\label{lem:cgamma}
    Suppose \Cref{ass:unichain} holds. For any $\gamma$ with $\specrad<\gamma<1$, there exists a constant $C_{\gamma}$ such that
\begin{align*}
    \sum_{n=0}^{\infty} \sup_{i\in[N]}\frac{\norm{(P_i-\Xi_i)^n}}{\gamma^n}\leq C_{\gamma},
\end{align*}
where $\norm{\cdot}$ denotes the $2$-norm for matrices. 
\end{lemma}


To prove \eqref{lem:cgamma}, we need the following result from \citet{Kozyakin_2009}. 

\begin{lemma}[Theorem 1 in \citet{Kozyakin_2009}]\label{lem:gelfand}
Given $d\geq 2$, for any matrix $A\in\R^{d\times d}$, denote the spectral radius of $A$ as $\rho(A)$. Then we have:
\begin{align*}
    C_d^{-\sigma_d(n)/n}\bracket{\frac{\norm{A}^d}{\norm{A^d}}}^{-\nu_d(n)/n}\norm{A^n}^{1/n}\leq \rho(A)\,,\quad n=1,2,\dots,
\end{align*}
where 
\begin{align}\label{eq:gelfand coef}
    C_d&=2^d-1\,,\nonumber\\
    \sigma_d(n)&=\begin{cases}
        \frac{1}{2}\bracket{\frac{\ln n}{\ln 2}+1}~~ & for ~d=2\,,\\
        \frac{(d-1)^3}{(d-2)^2}\cdot n^{\frac{\ln (d-1)}{\ln d}}~~& for~ d>2\,,
    \end{cases}\\
    \nu_d(n)&=\begin{cases}
        \frac{\ln n}{\ln 2}+1~~&for ~ d=2\,,\\
        \frac{(d-1)^2}{d-2}\cdot n^{\frac{\ln (d-1)}{\ln d}}~~&for ~d>2\,.
    \end{cases}\nonumber
\end{align}
\end{lemma}


\begin{proof}[Proof of \Cref{lem:cgamma}]
First, we show that the norm of $(P_i-\Xi_i)^n$ decays exponentially fast when $n$ is larger than some constant independent of $N$, as claimed below: 
\paragraph{Claim:} There exists a constant $n(\gamma,\cardS,\gamma_{\rho})>0$ which only depends on the parameter $\gamma$, the state space size $\cardS$, and the uniform upper bound on the spectral radius $\gamma_{\rho}$, such that for any $n \geq n(\gamma,\cardS,\gamma_{\rho})$, we have:
    \begin{align*}
        \norm{(P_i-\Xi_i)^n}\leq \bracket{\frac{\gamma+\specrad}{2}}^n \quad \forall i=1,2,\dots.
    \end{align*}
    To prove this claim, we consider two cases: 
    \paragraph{Case 1:} $\norm{(P_i-\Xi_i)^{\cardS}}\leq \bracket{\frac{\gamma+\gamma_{\rho}}{4}}^{\cardS}$. In this case, using the sub-multiplicative property of matrix norms, we get:
    \begin{align*}
        \norm{(P_i-\Xi_i)^n}\leq \norm{(P_i-\Xi_i)^{\cardS}}^{\lfloor \frac{n}{\cardS} \rfloor} \norm{P_i-\Xi_i}^{(n ~\text{mod}~ \cardS)}\leq \bracket{\frac{\gamma+\gamma_{\rho}}{4}}^{(n-\cardS)}\bracket{2\cardS}^{\cardS}\,,
    \end{align*}
    where $(n ~\text{mod}~ \cardS)$ denotes the remainder of $n$ after dividing $\cardS$; the second inequality is due to $\norm{P_i-\Xi_i}\leq \norm{P_i} + \norm{\Xi_i}\leq 2{\cardS}$. 
    Therefore, if $n\geq \cardS\bracket{3+\log \frac{1}{\gamma}+\log\cardS} $, the above inequality implies that $\norm{(P_i-\Xi_i)^n} \leq \bracket{\frac{\gamma+\specrad}{2}}^n$. 
    \paragraph{Case 2:} $\norm{(P_i-\Xi_i)^{\cardS}}>\bracket{\frac{\gamma+\gamma_{\rho}}{4}}^{\cardS}$. In this case, we have
    \begin{align*}
        \frac{\norm{P_i-\Xi_i}^{\cardS}}{\norm{\bracket{P_i-\Xi_i}^{\cardS}}}\leq \frac{(2\cardS)^{\cardS}}{\norm{\bracket{P_i-\Xi_i}^{\cardS}}} < \bracket{\frac{8}{\gamma + \gamma_{\rho}}}^{\cardS}\,.
    \end{align*}
    Combining the above inequality with \Cref{lem:gelfand}, we get:
    \begin{align}
        \nonumber
        \norm{\bracket{P_i-\Xi_i}^n}&\leq \rho(P_i-\Xi_i)^n C_{\cardS}^{\sigma_{\cardS}(n)}\bracket{\frac{\norm{P_i-\Xi_i}^{\cardS}}{\norm{\bracket{P_i-\Xi_i}^{\cardS}}}}^{\nu_{\cardS}(n)}\\
        \label{eq:pf-power-series:eq-1}
        &\leq \gamma_{\rho}^nC_{\cardS}^{\sigma_{\cardS}(n)}\bracket{\frac{8}{\gamma + \gamma_{\rho}}}^{\cardS\nu_{\cardS}(n)},  
    \end{align}
    where $C_{\cardS}$, $\sigma_{\cardS}(n)$ and $\nu_{\cardS}(n)$ are given in \eqref{eq:gelfand coef}. Because we have $\specrad < \frac{\gamma+\specrad}{2}$,  
    and $C_{\cardS}^{\sigma_{\cardS}(n)}\bracket{\frac{8}{\gamma + \gamma_{\rho}}}^{\cardS\nu_{\cardS}(n)}$ grows with $n$ at a sub-exponential rate, there exists $n_0(\gamma,\cardS,\specrad) > 0$ such that for each $n\geq n_0(\gamma,\cardS,\specrad)$, we have
    \[
        \specrad^nC_{\cardS}^{\sigma_{\cardS}(n)}\bracket{\frac{8}{\gamma + \gamma_{\rho}}}^{\cardS\nu_{\cardS}(n)}\leq \bracket{\frac{\gamma+\specrad}{2}}^n.
    \]
    Putting together the two cases and choosing $n(\gamma,\cardS,\specrad)=\max\sets{n_0(\gamma,\cardS,\specrad),\cardS\bracket{3+\log \frac{1}{\gamma}+\log \cardS}}$, we finish the proof of the claim. 
    
    
    Using the above claim, we get:
    \begin{align}
        \label{eq:pf-power-seriesse:second-last-inequality}
         \sum_{n=0}^{\infty} \sup_{i\in[N]}\frac{\norm{(P_i-\Xi_i)^n}}{\gamma^n}&\leq \sum_{n=0}^{n(\gamma,\cardS,\gamma_{\rho})-1}\sup_{i\in[N]}\frac{\norm{(P_i-\Xi_i)^n}}{\gamma^n}+\sum_{n=n(\gamma,\cardS,\gamma_{\rho})}^{\infty}\bracket{\frac{\gamma+\specrad}{2\gamma}}^n\\
         \label{eq:pf-power-series:last-inequality}
         &\leq\sum_{n=0}^{n(\gamma,\cardS,\gamma_{\rho})-1}\frac{(2\cardS)^n}{\gamma^n} +\sum_{n=n(\gamma,\cardS,\gamma_{\rho})}^{\infty}\bracket{\frac{\gamma+\specrad}{2\gamma}}^n,
    \end{align}
    where the infinite sum on the right-hand side of \eqref{eq:pf-power-seriesse:second-last-inequality} is finite because $\gamma+\specrad < 2\gamma$;
    to get \eqref{eq:pf-power-series:last-inequality}, we used the argument that $\norm{(P_i-\Xi_i)^n} \leq \norm{P_i-\Xi_i}^n \leq \big(\norm{P_i}+\norm{\Xi_i}\big)^n \leq (2\cardS)^n$. 
    Since the final expression in \eqref{eq:pf-power-series:last-inequality} is independent of $N$, taking it to be $C_{\gamma}$ finishes the proof of the lemma. 
\end{proof}


\subsection{Proof of Lemma~\ref{lem:drift}}
\label{app:proof-lem-drift}

In this subsection, we prove \Cref{lem:drift}, which is about properties of the Lyapunov function $h(\mx,D)$:
\begin{equation}\tag{\ref{eq:h-def}}
    h(\mx,D) \triangleq \max_{g\in \mathcal{G}} \sup_{\ell\in\mathbb{N}} \abs{\sum_{i\in D} \innerproduct{(x_i-\mu_i^*) P_i^{\ell} / \gamma^{\ell}}{g_i}}.
\end{equation}
\Cref{lem:drift} is restated as follows. 
\hproperties*

In the proof of \Cref{lem:drift}, we will frequently use the following form of $h(\mX, D)$:  
\begin{equation}\label{eq:h-equiv-form}
    h(\mx,D) = \max_{g\in \mathcal{G}} \sup_{\ell\in\mathbb{N}} \abs{\sum_{i\in D} \innerproduct{(x_i-\mu_i^*) (P_i - \Xi_i)^{\ell} / \gamma^{\ell}}{g_i}},
\end{equation}
where $\Xi_i$ is the matrix whose each row is the optimal stationary distribution of the $i$-th arm, $\mu^*_i$. 
The equation \eqref{eq:h-equiv-form} is equivalent to \eqref{eq:h-def} because $(v_1 - v_2) P_i^\ell = (v_1-v_2) (P_i - \Xi_i)^\ell$ for any $i\in [N]$, $\ell \geq 0$, and row vectors $v_1, v_2 \in \Delta(\sspa)$. We will also use the equivalent version of \Cref{ass:unichain} proved in \Cref{lem:spectral-radius}, i.e., the spectral radius of the matrix $P_i - \Xi_i$ is upper bounded by $\specrad$ for any $i=1,2,3,\dots$. 


\begin{proof}
We organize the proof in three parts: we first show the finiteness of the subset Lyapunov function $h(\mx, D)$; then, we prove the Lipschitz continuity of $h(\mx, D)$ with respect to $D$ \eqref{eq:h-lipschitz}; finally, we prove the drift condition for $h(\mx, D)$ stated in \eqref{eq:h-drift-condition}. 

\paragraph{Finiteness of $h(\mx, D)$.}
To show that $h(\mx,D)$ is finite for any system state $\mx$ and subset $D\subseteq [N]$, we have for any $g\in \mathcal{G}$: 
\begin{align}
    \nonumber
    \supell \abs{\sum_{i\in D} \innerproduct{(x_i-\mu_i^*) P_i^{\ell} / \gamma^{\ell}}{g_i}}
    &\leq \sum_{i\in D} \sumell \abs{\innerproduct{(x_i-\mu_i^*) P_i^{\ell} / \gamma^{\ell}}{g_i}}\\
    \label{eq:pf-subset-lyapunov:finite-1}
    &= \sum_{i\in D}\sumell \abs{\innerproduct{(x_i-\mu_i^*) (P_i-\Xi_i)^{\ell} / \gamma^{\ell}}{g_i}} \\
    \label{eq:pf-subset-lyapunov:finite-2}
    &\leq \sum_{i\in D} \sumell \norm{x_i-\mu_i^*}\frac{\norm{(P_i-\Xi_i)^{\ell}}}{\gamma^{\ell}}\norm{g_i},
\end{align}
By \Cref{lem:cgamma}, $\sumell \norm{(P_i-\Xi_i)^{\ell}} / \gamma^{\ell}$ is finite, so the expression in \eqref{eq:pf-subset-lyapunov:finite-2} is also finite. Taking maximum over $g\in \mathcal{G}$, because $\mathcal{G}$ is a finite set, we have 
\[
    h(\mx, D) = \max_{g\in \mathcal{G}} \supell \abs{\sum_{i\in D} \innerproduct{(x_i-\mu_i^*) P_i^{\ell} / \gamma^{\ell}}{g_i}} < \infty.
\]

\paragraph{Lipschitz continuity.}
For any system state $\mx$ and subsets $D,D'$ such that $D'\subseteq D \subseteq [N]$, we have
\begin{align}
    \nonumber
    \abs{h(\mx,D)-h(\mx,D')}
    &=  \abs{\max_{g\in \mathcal{G}}  \supell 
 \abs{\sum_{i\in D} \innerproduct{(x_i-\mu_i^*) P_i^{\ell} / \gamma^{\ell}}{g_i}} -  
    \max_{g\in \mathcal{G}}  \supell \abs{\sum_{i\in D'} \innerproduct{(x_i-\mu_i^*) P_i^{\ell} / \gamma^{\ell}}{g_i}}} \\
    \label{eq:pf-subset-lyapunov:lipschitz-1}
    &\leq \max_{g\in \mathcal{G}} \supell \abs{\sum_{i\in D/D'}\innerproduct{(x_i-\mu_i^*)P_i^{\ell}/\gamma^{\ell}}{g_i}}. 
\end{align}
Following similar arguments used to proving finiteness of $h(\mx, D)$, we further bound the last expression as: 
\begin{align}
    \nonumber
    \max_{g\in \mathcal{G}} \supell \abs{\sum_{i\in D/D'}\innerproduct{(x_i-\mu_i^*)P_i^{\ell}/\gamma^{\ell}}{g_i}} 
    &\leq  \max_{g\in \mathcal{G}}  \sum_{i\in D/D'} \norm{x_i-\mu_i^*} \norm{g_i} \sumell \frac{\norm{(P_i-\Xi_i)^{\ell}}}{\gamma^{\ell}}\\
    \label{eq:pf-subset-lyapunov:lipschitz-2}
    &\leq 2\abs{D/D'} \max\sets{c_{\max},r_{\max}}\cardS^{1/2}C_{\gamma},
\end{align}
where in the last inequality, we have utilized the facts that $\norm{g_i} \leq \max\sets{c_{\max},r_{\max}} \cardS^{1/2}$,  $\norm{x_i - \mu_i^*} \leq 2$, and that  $\sumell \norm{(P_i-\Xi_i)^{\ell}} / \gamma^{\ell} \leq C_{\gamma}$ for some constant $C_\gamma > 0$. 
Therefore, $h(\mx, D)$ is Lipschitz continuous in $D$ with the Lipschitz constant 
$L_h = 2\max\sets{c_{\max},r_{\max}}\cardS^{1/2}C_{\gamma}$. 


\paragraph{Drift condition.}
Next, we prove the drift condition in \eqref{eq:h-drift-condition}, which requires showing 
\[
    \E{(h(\mX_{t+1}, D) - \gamma h(\mX_t, D))^+ \givenplain \mX_t} = O(1/\sqrt{N}),
\]
when the $i$-th arm follows the action generated by $\pibs_i$ for each $i\in D$. 
Because $D$ is fixed in the rest of the proof, for simplicity, we use $h(\mx)$ as shorthand for $h(\mx, D)$. 

We first perform the following decomposition: 
\begin{equation}
    \label{eq:pf-subset-lyapunov:drift-decompose}
    \EE\mbracket{\bracket{h(\mX_{t+1})-\gamma h(\mX_t)}^+\givenmiddle\mX_t} \leq \EE\mbracket{\abs{h(\mX_{t+1})-h(\mX_tP)}\givenmiddle\mX_t} + \bracket{h(\mX_tP)-\gamma h(\mX_t)}^+,
\end{equation}
where $\mX_t P \in \R^{N\times \cardS}$ denotes the matrix whose $i$-th row is given by $(\mX_t P)_i \triangleq X_{i,t}P_i$, which is the state distribution of arm $i$ after one-step of transition from $X_{i,t}$ under the policy $\pibs_i$. 
Next, we bound the two terms on the right-hand side of \eqref{eq:pf-subset-lyapunov:drift-decompose} separately. 


We first bound the term $\bracket{h(\mX_tP)-\gamma h(\mX_t)}^+$. Substituting $\mX_t P$ into the definition of $h$, we have
\begin{align*}
    h(\mX_tP) &= \max_{g\in \mathcal{G}}  \supell \abs{\sum_{i\in D} \innerproduct{(X_{i,t}-\mu_i^*)P_i^{\ell+1}/\gamma^{\ell}}{g_i}}\\
    &=\gamma \max_{g\in \mathcal{G}}  \sup_{\ell\in\mathbb{N}\colon \ell \geq 1}  \abs{\sum_{i\in D} \innerproduct{(X_{i,t}-\mu_i^*)P_i^{\ell}/\gamma^{\ell}}{g_i}}\\
    &\leq \gamma h(\mX_t).
\end{align*}

Next, we bound the term $\EE\mbracket{\abs{h(\mX_{t+1})-h(\mX_tP)}\givenmiddle\mX_t}$. 
Let $\epsilon_{i,t} \in \R^{\sspa}$ be the random vector given by $\epsilon_{i,t} = X_{i,t+1}-X_{i,t}P_i$ for $i\in D$. Then for each state $s\in\sspa$, $\epsilon_{i,t}(s)$ conditioned on $\mX_t$ is a Bernoulli distribution with mean $0$. Consequently, 
\begin{align}
    \nonumber
    &\mspace{23mu} \abs{h(\mX_{t+1})-h(\mX_tP)}\\
    \nonumber
    &\leq \abs{\max_{g\in \mathcal{G}} \supell \bracket{\abs{\sum_{i\in D}\innerproduct{(X_{i,t+1}-\mu_i^*)P_i^{\ell}/\gamma^{\ell}}{g_i}}-\abs{\sum_{i\in D} \innerproduct{(X_{i,t}P_i-\mu_i^*)P_i^{\ell}/\gamma^{\ell}}{g_i}}}}\\ 
    \nonumber 
    &\leq \max_{g\in \mathcal{G}} \supell \abs{\sum_{i\in D}\innerproduct{\epsilon_{i,t}P_i^{\ell}/\gamma^{\ell}}{g_i}} \\
    \nonumber
    &= \max_{g\in \mathcal{G}} \supell \abs{\sum_{i\in D}\innerproduct{\epsilon_{i,t}(P_i-\Xi_i)^{\ell}/\gamma^{\ell}}{g_i}}\\
    \nonumber
    &=\max_{g\in \mathcal{G}} \supell \abs{\sum_{i\in D} \sum_s \sum_{s'\in\sspa} \epsilon_{i,t}(s)g_i(s') \bracket{\frac{P_i-\Xi_i}{\gamma}}^{\ell}(s,s')} \\
    \nonumber
    &\leq \sum_{g\in \mathcal{G}} \sumell \sum_{s\in\sspa}\abs{\sum_{i\in D} \epsilon_{i,t}(s) \sum_{s'\in\sspa}\bracket{g_i(s')\bracket{\frac{P_i-\Xi_i}{\gamma}}^{\ell}(s,s')}}
\end{align}
Let $\tempm_{g,i}^{\ell}(s)=\sum_{s'}g_i(s')\bracket{\frac{P_i-\Xi_i}{\gamma}}^{\ell}(s,s')$ for $\ell\geq 0$, $g\in \mathcal{G}$, $i\in D$ and $s\in \sspa$. 
Then 
\begin{equation}
    \label{eq:pf-subset-lyapunov:drift-1}
    \abs{h(\mX_{t+1})-h(\mX_tP)} \leq  \sum_{g\in \mathcal{G}} \sumell \sum_{s\in\sspa} \abs{\sum_{i\in D} \epsilon_{i,t}(s)\tempm_{g,i}^{\ell}(s)}. 
\end{equation}
We can bound the conditional expectation of $\abs{\sum_{i\in D} \epsilon_{i,t}(s)\tempm_{g,i}^{\ell}(s)}$ given $\mX_t$ as follows: for any $\ell\geq 0$, $g\in \mathcal{G}$, $i\in D$, we have 
\begin{align}
    \nonumber
    \EE\mbracket{\abs{\sum_{i\in D} \epsilon_{i,t}(s)\tempm_{g,i}^{\ell}(s)} \givenmiddle \mX_t} 
    &= \EE\mbracket{\abs{\sum_{i\in D} \epsilon_{i,t}(s)\tempm_{g,i}^{\ell}(s)} \givenmiddle \mX_t}\\
    \nonumber
    &\leq \sqrt{\EE\mbracket{\bracket{\sum_{i\in D} \epsilon_{i,t}(s)\tempm_{g,i}^{\ell}(s)}^2 \givenmiddle \mX_t}}\\
    \label{eq:pf-subset-lyapunov:drift-2}
    &= \sqrt{\sum_{i\in D} \bracket{\tempm_{g,i}^{\ell}(s)}^2\EE\mbracket{\epsilon_{i,t}(s)^2\givenmiddle\mX_t}}\\
    \label{eq:pf-subset-lyapunov:drift-3}
    &\leq \sqrt{N} \max_{i\in D} \abs{\tempm_{g,i}^{\ell}(s)},
\end{align}
where \eqref{eq:pf-subset-lyapunov:drift-2} uses the fact that $\epsilon_{i,t}$ are independent across $i\in D$; \eqref{eq:pf-subset-lyapunov:drift-3} is because $\abs{\epsilon_{i,t}(s)} \leq 1$ for $i\in D$ and $s\in \sspa$. 
Thus, we can bound $\EE\mbracket{h(\mX_{t+1})-h(\mX_tP)\givenmiddle\mX_t}$ as:
\begin{align}
    \label{eq:pf-subset-lyapunov:drift-3-1}
    \EE\mbracket{\abs{h(\mX_{t+1})-h(\mX_tP)}\givenmiddle\mX_t}
    &\leq \sqrt{N} \sumell \sum_{s\in\sspa}  \sum_{g\in \mathcal{G}} \max_{i\in D} \abs{\tempm_{g,i}^{\ell}(s)}. 
\end{align}
To bound the term $\sum_s  \sum_{g} \max_{i\in D} \abs{\tempm_{g,i}^{\ell}(s)}$ in \eqref{eq:pf-subset-lyapunov:drift-3-1}, we calculate that
\begin{align*}
    \abs{\tempm_{g,i}^{\ell}(s)}&\leq 
    \bracket{\max_{s'\in\sspa} \abs{g_i(s')}}\bracket{\sum_{s'\in\sspa}\abs{\bracket{\frac{P_i-\Xi_i}{\gamma}}^{\ell}(s,s')}}\\
    &\leq\norm{g_i}_{\infty}\frac{\norm{(P_i-\Xi_i)^{\ell}}_{\infty}}{\gamma^{\ell}} \,.
\end{align*}
Consequently, summing over $s\in\sspa$ and $g\in \mathcal{G}$, 
\begin{align}
    \nonumber
    \sum_{s\in \sspa}\sum_{g\in \mathcal{G}}\max_{i\in D}\abs{\tempm_{g,i}^{\ell}(s)}&\leq \cardS \sum_{g\in \mathcal{G}} \bracket{\max_{i\in [N]}\norm{g_i}_{\infty}}\bracket{\sup_{i\in[N]} \frac{\norm{(P_i-\Xi_i)^{\ell}}_{\infty}}{\gamma^{\ell}} }\\
    \label{eq:pf-subset-lyapunov:drift-4}
    &\leq \cardS(Kc_{\max}+r_{\max})\bracket{\sup_{i\in[N]} \frac{\norm{(P_i-\Xi_i)^{\ell}}_{\infty}}{\gamma^{\ell}} }\,.
\end{align}
Plugging the bound in \eqref{eq:pf-subset-lyapunov:drift-4}  back to \eqref{eq:pf-subset-lyapunov:drift-3-1}, we get 
\begin{align}
     \nonumber
    \EE\mbracket{\abs{h(\mX_{t+1})-h(\mX_tP)}\givenmiddle\mX_t} &\leq \sqrt{N} \cardS (Kc_{\max}+r_{\max})\sumell \sup_{i\in[N]} \frac{\norm{(P_i-\Xi_i)^{\ell}}_{\infty}}{\gamma^{\ell}}\\
     \label{eq:pf-subset-lyapunov:drift-5}
    &\leq \sqrt{N} \cardS^{3/2} (Kc_{\max}+r_{\max})C_{\gamma}\,,
\end{align}
where the inequality in \eqref{eq:pf-subset-lyapunov:drift-5} is due to the fact that for any $\cardS$-by-$\cardS$ matrix $A$, $\norm{A}_\infty \leq \cardS^{1/2} \norm{A}_2$, and the upper bound $\sumell \sup_{i} \norm{(P_i-\Xi_i)^{\ell}}_{2} / \gamma^{\ell} \leq C_{\gamma}$ proved in \Cref{lem:cgamma}. 

Combining the above calculations, we get:
\begin{align*}
    \EE\mbracket{\bracket{h(\mX_{t+1})-\gamma h(\mX_t)}^+\givenmiddle\mX_t} &\leq \EE\mbracket{\abs{h(\mX_{t+1})-h(\mX_tP)}\givenmiddle\mX_t}+ \bracket{h(\mX_tP)-\gamma h(\mX_t)}^+\\
    &\leq \sqrt{N}\cardS^{3/2}(Kc_{\max}+r_{\max})C_{\gamma}. 
\end{align*}
Therefore, $\EE\mbracket{\bracket{h(\mX_{t+1})-\gamma h(\mX_t)}^+\givenmiddle\mX_t}\leq C_h \sqrt{N}$ with $C_h = \cardS^{3/2}(Kc_{\max}+r_{\max})C_{\gamma}$. 
\end{proof}


\subsection{Properties of $h_{\ID}(\cdot,\cdot)$}
\label{sec:properties-hID}

\begin{lemma}\label{lem:hID drift}
The Lyapunov function $\hid(\mx, m)$ defined in \eqref{eq:hid-def} has the following properties: 
\begin{enumerate}
    \item \textbf{(Lipschitz continuity)} For each system state $\mx$ and $m, m'\in[0,1]_N$, we have
    \begin{equation}
        \label{eq:hid-drift-condition}
        \abs{h_{\ID}(\mx,m)-h_{\ID}(\mx,m')}\leq NL_h\abs{m-m'}\,,
    \end{equation}
    where $L_h > 0$ is the Lipschitz constant given in \Cref{lem:drift}. 
    \item \textbf{(Drift condition)} 
        For each $m\in[0,1]_N$, if all arms in $[Nm]$ follow the optimal single-armed policies, we have: 
        \begin{align*}
            \EE\mbracket{(h_{\ID}(\mX_{t+1},m)-\gamma h_{\ID}(\mX_t,m))^+\mid\mX_t, A_{i,t}\sim\Bar{\pi}_i^*(\cdot\mid S_{i,t}),\forall i \in [Nm]}\leq 2C_h\sqrt{N},
        \end{align*}
        where $C_h > 0$ is the constant given in \Cref{lem:drift}.  
\end{enumerate}
\end{lemma}

\begin{proof}\label{proof:hID drift}
    We first prove the Lipschitz continuity of $\hid(\mx, m)$ with respect to $m$. 
    Because $\hid(\mx, m)$ is non-decreasing in $m$, it suffices to demonstrate that for any $m, m'\in[0,1]_N$ such that $m > m'$, 
    \begin{equation}
        \label{pf:hid-lipschitz:goal}
        \hid(\mx, m) - \hid(\mx, m') \leq NL_h (m-m').
    \end{equation}
    Denote $m_1=\argmax_{m_1\in[0,1]_N\colon m_1\leq m}h(\mx,[Nm_1])$. Then, by the definition of $h_{\ID}$, we have $h_{\ID}(\mx,m)=h(\mx,[Nm_1])$ and 
    \begin{equation}
        \label{pf:hid-lipschitz:eq-1}
        \hid(\mx, m) - \hid(\mx, m') =  h(\mx, [Nm_1]) - \hid(\mx, m'). 
    \end{equation}
    If $m_1\leq m'$, the right-hand side of \eqref{pf:hid-lipschitz:eq-1} is non-positive, so \eqref{pf:hid-lipschitz:goal} follows. 
    If $m'< m_1 \leq m$, because $\hid(\mx, m')\geq h(\mx, [Nm'])$,  \eqref{pf:hid-lipschitz:eq-1} implies that
    \begin{align}
        \nonumber
        h_{\ID}(\mx,m)-h_{\ID}(\mx,m')
        &\leq h(\mx, [Nm_1])  - h(\mx, [Nm']) \\
        \label{eq:apply-h-lipschitz}
        &\leq L_h (Nm_1-Nm')\\
        \nonumber
        &\leq NL_h(m-m')\,,
    \end{align}
    where \eqref{eq:apply-h-lipschitz} is due to the Lipschitz continuity of $h(x, D)$ with respect to $D$, as established in \Cref{lem:drift}. 
    We have thus proved \eqref{pf:hid-lipschitz:goal}. 

    Next, we prove the drift condition. We will assume $A_{i,t}\sim \pibs_i(\cdot\givenplain S_{i,t})$ for all $i\in [Nm]$ in the rest of the proof, without explicitly writing it in the conditional probabilities each time. 
    We start by bounding the following expression: 
    \begin{align}
        \nonumber
        &\mspace{23mu} h_{\ID}(\mX_{t+1},m)-\gamma h_{\ID}(\mX_{t},m)\\
        \nonumber
        &= \maxmp h(\mX_{t+1},[Nm']) - \maxmp \gamma h(\mX_t,[Nm'])\\
        \nonumber
        &\leq \maxmp \bracket{h(\mX_{t+1},[Nm'])-\gamma h(\mX_t,[Nm'])}\\ 
        \nonumber
        &\leq \maxmp \bracket{h(\mX_{t+1},[Nm']) - h(\mX_tP,[Nm'])}\\
        \label{eq:pf-id-drift:eq-1}
        &\leq \maxmp \max_{g\in \mathcal{G}} \supell \abs{\sum_{s\in\sspa} \sum_{i\in[Nm']} \epsilon_{i,t}(s)\sum_{s'\in\sspa}\bracket{g_i(s')\bracket{\frac{P_i-\Xi_i}{\gamma}}^{\ell}(s,s')}} \,,
    \end{align}
    where $\epsilon_{i,t}$ is a $\cardS$-dimensional random vector given by $\epsilon_{i,t} \triangleq X_{i,t+1}-X_{i,t}P_i$, 
    which satisfies $\EE\mbracket{\epsilon_{i,t}(s)\givenmiddle\mX_t}=0$ and $\abs{\epsilon_{i,t}(s)}\leq 1$ for any $s\in\sspa$. 
    Now, we take the expectations of the positive parts of the inequality \eqref{eq:pf-id-drift:eq-1} conditioned on $X_t$. We deduce that 
    \begin{align}
        \nonumber
        &\mspace{23mu} \EE\mbracket{(h_{\ID}(\mX_{t+1},m)-\gamma h_{\ID}(\mX_{t},m))^+\givenmiddle\mX_t}\\
        \nonumber
        &\leq \E{\maxmp \max_{g\in \mathcal{G}} \supell \abs{\sum_{s\in\sspa} \sum_{i\in[Nm']} \epsilon_{i,t}(s)\sum_{s'\in\sspa}\bracket{g_i(s')\bracket{\frac{P_i-\Xi_i}{\gamma}}^{\ell}(s,s')}}\givenmiddle \mX_t} \\
        \nonumber
        &\leq \EE\mbracket{\maxmp \sum_{g\in \mathcal{G}} \sumell \sum_{s\in\sspa} \abs{\sum_{i\in[Nm']} \epsilon_{i,t}(s)\sum_{s'\in\sspa}\bracket{g_i(s')\bracket{\frac{P_i-\Xi_i}{\gamma}}^{\ell}(s,s')}} \givenmiddle \mX_t}\\
        \label{eq:pf-hid-drift:before-apply-martingale}
        &\leq \sum_{g\in \mathcal{G}} \sumell \sum_{s\in\sspa}\EE\mbracket{\maxmp\abs{\sum_{i\in[Nm']}\epsilon_{i,t}(s)\tempm_{g,i}^{\ell}(s)} \givenmiddle \mX_t}\,,
    \end{align}
    where $\tempm_{g,i}^{\ell}(s)\triangleq \sum_{s'}g_i(s')\bracket{\frac{P_i-\Xi_i}{\gamma}}^{\ell}(s,s')$ for any $\ell\in \mathbb{N}_{+}$, $g\in \mathcal{G}$, $i\in[Nm]$ and $s\in\sspa$. 
    To bound the summand, obverve that for each $t$ and $s$, $\{\epsilon_{i,t}(s)\}_{i\in[Nm]}$ are independent and have zero means. 
    Consequently,  
    \begin{align}
        \nonumber
        &\mspace{23mu} \EE\mbracket{\maxmp\abs{\sum_{i\in[Nm']}\epsilon_{i,t}(s)\tempm_{g,i}^{\ell}(s)}\givenmiddle\mX_t}\\
        \label{eq:pf-hid:drift-2}
        &\leq \EE\mbracket{\bracket{\maxmp\abs{\sum_{i\in[Nm']}\epsilon_{i,t}(s)\tempm_{g,i}^{\ell}(s)}}^2\givenmiddle\mX_t}^{1/2}\\
        \label{eq:pf-hid:drift-3}
        &\leq 2\EE\mbracket{\sum_{i\in[Nm]}\bracket{\tempm_{g,i}^{\ell}(s)}^2}^{1/2}\\
        \nonumber
        &\leq 2\sqrt{N}\max_{i\in [Nm]} \abs{\tempm_{g,i}^{\ell}(s)}\,,
    \end{align}
    where \eqref{eq:pf-hid:drift-2} is due to Cauchy–Schwarz; in \eqref{eq:pf-hid:drift-3}, we apply Doob's $L_2$ inequality to the submartingale $\sets{\abs{\sum_{i\in[n]}\epsilon_{i,t}(s)\tempm_{g,i}^{\ell}(s)}}_{n=1}^{Nm}$.  
    Finally, following similar arguments as those in the proof of \Cref{lem:drift}, we get
    \begin{align*}
        &\mspace{23mu}\EE\mbracket{(h_{\ID}(\mX_{t+1},m)-\gamma h_{\ID}(\mX_{t},m))^+\givenmiddle\mX_t}\\
        &\leq 2\sqrt{N}\sum_{g\in \mathcal{G}}\sum_{\ell=0}^{\infty}\sum_{s\in\sspa} \max_{i\in[Nm]}\abs{\tempm_{g,i}^{\ell}(s)}\\
        &\leq2C_h\sqrt{N}. 
    \end{align*}
    In particular, the last inequality follows from the same calculations as those in \eqref{eq:pf-subset-lyapunov:drift-4} and \eqref{eq:pf-subset-lyapunov:drift-5}. 
\end{proof}





\section{Lemmas for focus set}
\label{sec:lem-proof-focus-set}

In this section, we present and prove three lemmas about properties of the focus set.
Recall that for any system state $\mx$, the focus set is defined as the set $[Nm(\mx)]$, where $m(\mx)$ is given by
\begin{align}
    m(\mx)= \max \sets{ m\in[0,1]_N: h_{\ID}(\mx,m)\leq \min_{k\in[K]}\rembud_k([Nm])}.
\end{align}
Consider the system state process under the ID policy, $(\bm{S}_t,t\in\mathbb{N})$ and its equivalent representation $(\mX_t,t\in\mathbb{N})$.
We often consider the focus set corresponding to the current system state, i.e., $m(\mX_t)$.
A closely related quantity is the number of arms that follow their optimal single-armed policies under the ID policy, which we refer to as the \emph{conforming number}.
With the system state $\bm{S}_t$, the conforming number is denoted as $N^*_t$, and it can be written as
\begin{equation}
    N_t^* = \max\sets{n\in[N]\colon \sum_{i=1}^n c_{k,i}(S_{i,t},\widehat{A}_{i,t})\leq \alpha_k N, \forall k\in[K]},
\end{equation}
where $\widehat{A}_{i,t}$'s are the actions sampled from the optimal single-armed policies by the ID policy.


Below we state the three lemmas, and we then prove them in the subsections.

\begin{lemma}[Majority conformity]\label{lem:majority_conformal}
Let $(\mX_t,t\in\mathbb{N})$ be the system state process under the ID policy.
The size of the focus set, $Nm(\mX_t)$, satisfies
\begin{align*}
    \frac{1}{N}\EE[\bracket{Nm(\mX_t) - N_t^* }^+ \givenplain \mX_t]\leq \frac{K_{\conf}}{\sqrt{N}}, \quad\text{with probability }1,
\end{align*}
for some constant $K_{\conf}>0$.
\end{lemma}
Lemma~\ref{lem:majority_conformal} implies that almost all the arms in the focus set, except for $O(\sqrt{N})$ arms, can follow the optimal single-armed policies.

\begin{lemma}[Almost non-shrinking]\label{lem:non-shrinking}
Let $(\mX_t,t\in\mathbb{N})$ be the system state process under the ID policy.
Then the change in the size of the focus set over time satisfies
    \begin{align*}
    \EE\mbracket{(m(\mX_t)-m(\mX_{t+1}))^+ \givenmiddle \mX_t} \leq  \frac{K_{\mono}}{\sqrt{N}},\quad\text{with probability }1,
\end{align*}
for some constant $K_{\mono}>0$.
\end{lemma}
Lemma~\ref{lem:non-shrinking} implies that the size of the focus set is almost non-shrinking on average over time, or more specifically, it shrinks by at most $O(\sqrt{N})$ on average over time.


\begin{lemma}[Sufficient coverage]\label{lem:coverage}
Let $(\mX_t,t\in\mathbb{N})$ be the system state process under the ID policy.
Then
\begin{align*}
    1-m(\mX_t)\leq \frac{1}{\eta_c N}h_{\ID}(\mX_t,m(\mX_t)) + \frac{K_{\cov}}{N},\quad\text{with probability }1,
\end{align*}
for some constant $K_{\cov}>0$.
\end{lemma}
Lemma~\ref{lem:coverage} relates the size of the complement of the focus set to the value of the function $h_{\ID}(\mX_t,m(\mX_t))$.


\subsection{Proof of Lemma~\ref{lem:majority_conformal} (Majority conformity)}
\begin{proof}
First, we claim that the conforming number $N_t^*$ can be lower bounded using our slack budget function $\rembud$ and Lyapunov function as follows: for any time step $t\geq 0$, 
\begin{align}\label{eq:nt eq1}
    N_t^* \geq N \max\sets{m\in[0,1]_N\colon   \rembud([Nm])-h_{\ID}(\mX_t,m)\geq  \Delta_t}\,,
\end{align}
where $\Delta_t$ is the random variable given by 
\begin{align}\label{eq:deltat}
    \Delta_t = \maxk \max_{m\in[0,1]_N} \abs{\sum_{i\in[Nm]}\bracket{c_{k,i}(S_{i,t},\widehat{A}_{i,t})- \sum_{s}X_{i,t}(s)c_{k,i}^*(s)}}\,,
\end{align}
which captures the difference between the expected cost and the actual cost.  

To prove the claim, we invoke the definition of $N_t^*$ and the fact that $\rembud([n])\leq \alpha_k N - C_k([n])$ for any $n\in [N]$ and $k\in[K]$: 
    \begin{align}
        \nonumber
        N_t^* 
        &= \max\sets{n\in[N]\colon  \sum_{i\in[n]} c_{k,i}(S_{i,t},\widehat{A}_{i,t})  \leq \alpha_k N \quad \forall k\in[K]}     \\
        \label{eq:pf-conformity:applied-nt-def}
        &\geq \max\sets{n\in[N]\colon \maxk  \sum_{i\in[n]} \left(c_{k,i}(S_{i,t},\widehat{A}_{i,t}) - C_k([n]) \right) \leq \rembud([n])}.
    \end{align}
    To further lower bound \eqref{eq:pf-conformity:applied-nt-def}, we identify a subset of the set in \eqref{eq:pf-conformity:applied-nt-def} and reduce the task to upper bounding the following expression: 
    \begin{align}
        \nonumber
        &\mspace{23mu} \maxk  \sum_{i\in[n]} \left( c_{k,i}(S_{i,t},\widehat{A}_{i,t}) - C_k([n]) \right) \\
        \nonumber
        &\leq\maxk \abs{\sum_{i\in[n]}\innerproduct{X_{i,t}}{c_{k,i}^*}- C_k([n])}+ \maxk \abs{\sum_{i\in[n]}c_{k,i}(S_{i,t},\widehat{A}_{i,t})- \sum_{i\in[n]}\innerproduct{X_{i,t}}{c_{k,i}^*}}\\
        \label{eq:pf-conformity:eq-1}
        &\leq h_{\ID}(\mX_t,n/N) + \maxk \abs{\sum_{i\in[n]}\bracket{c_{k,i}(S_{i,t},\widehat{A}_{i,t})- \sum_{s}X_{i,t}(s)c_{k,i}^*(s)}} \\
        \label{eq:pf-conformity:eq-2}
        &\leq h_{\ID}(\mX_t,n/N) + \Delta_t. 
    \end{align}
    where \eqref{eq:pf-conformity:eq-1} inequality is because  
    \begin{align*}
        h_{\ID}(\mX_t,n/N)&=\max_{n'\in[n]}\max_{g\in \mathcal{G}} \supell \abs{\sum_{i\in[n']}\innerproduct{(X_{i,t}-\mu_i^*)P_i^{\ell}/\gamma^{\ell}}{g_i}}\\
        &\geq \maxk\abs{\sum_{i\in[n]}\innerproduct{X_{i,t}-\mu_i^*}{c_{k,i}^*}}\\
        &=\maxk\abs{\sum_{i\in[n]}\innerproduct{X_{i,t}}{c_{k,i}^*}- C_k([n])},
    \end{align*} 
    and \eqref{eq:pf-conformity:eq-2} follows from the definition of $\Delta_t$ in \eqref{eq:deltat} by taking $m=n/N$ in the maximum. 
    Substituting the bound in \eqref{eq:pf-conformity:eq-2} into \eqref{eq:pf-conformity:applied-nt-def}, we get
    \[
        N^*_t \geq \max\sets{n\in[N]\colon h_{\ID}(\mX_t,n/N) + \Delta_t \leq \rembud([n])},
    \]
    which is equivalent to the claim in \eqref{eq:nt eq1}. 


We now use \eqref{eq:nt eq1} to prove the lemma. 
Observe that by the definition of $m(\mX_t)$, 
\[
    \rembud([Nm(\mX_t)])-h_{\ID}(\mX_t,m(\mX_t)) \geq 0.
\]
and $h_{\ID}(\mX_t,m)$ is non-decreasing in $m$. Consequently, for any $m\in [0,1]_N$ such that $m\leq m(\mX_t)$, 
\begin{align}
    \nonumber
    \rembud([Nm])-h_{\ID}(\mX_t,m) 
    &\geq \rembud([Nm])-h_{\ID}(\mX_t,m(\mX_t)) \\
    \nonumber
    &\geq  \rembud([Nm]) - \rembud([Nm(\mX_t)]) \\\nonumber
    &=\min_k \rembud_k([Nm])-\min_k \rembud_k([Nm(\mX_t)])\\\nonumber
    &\geq \min_k \bracket{\rembud_k([Nm]) - \rembud_k([Nm(\mX_t)])}
    \label{eq:pf-conform:apply-strict-slope}\\
    &\geq \eta_cN(m(\mX_t)-m)-M_c,
\end{align}
where \eqref{eq:pf-conform:apply-strict-slope} follows from the strict slope of the slack budget $\rembud([Nm])$ (\Cref{lem:positiveC}). 
Therefore, choosing $m = m(\mX_t) - (\Delta_t+M_c)/(\eta_c N)$, we obtain
\begin{align*}
   \rembud([Nm])-h_{\ID}(\mX_t,m)\geq \Delta_t.
\end{align*}
Recalling the lower bound of $N_t^*$ established in \eqref{eq:nt eq1}, we arrive at
\begin{align*}
    N_t^*\geq N\max\sets{m\in[0,1]_N: \rembud([Nm])-h_{\ID}(\mX_t,m)\geq\Delta_t} \geq Nm(\mX_t)-\frac{\Delta_t +M_c}{\eta_c}\,.
\end{align*}
Rearranging the terms and taking the conditional expectations, we establish that
\begin{equation}
    \label{eq:pf-conform:bound-in-terms-of-E-delta}
    \E{\big(Nm(\mX_t) - N_t^*\big)^+ \givenmiddle \mX_t} \leq \EE\mbracket{\frac{\Delta_t+M_c}{\eta_c} \givenmiddle \mX_t}. 
\end{equation}


It remains to upper bound the conditional expectation of $\Delta_t$ given $\mX_t$. 
Define the random variable $\xi_{k,i} \triangleq c_{k,i}(S_{i,t},\widehat{A}_{i,t})- \sum_{s}X_{i,t}(s)c_{k,i}^*(s)$ for each arm $i\in[N]$ and cost type $k\in[K]$. 
Subsequently, $\EE\mbracket{\Delta_t\givenmiddle\mX_t}$ can be rewritten and bounded as 
\begin{align}
    \nonumber
     \EE\mbracket{\Delta_t\givenmiddle\mX_t} 
     &= \E{\maxk \max_{m\in[0,1]_N} \abs{\sum_{i\in[Nm]}\xi_{k,i}} \givenmiddle \mX_t} \\
     \nonumber
     &\leq  \sumk \EE\mbracket{\max_{n\in[N]}\abs{\sum_{i\in[n]}\xi_{k,i}} \givenmiddle \mX_t} \\
    \label{eq:pf-conformity:before-martingale}
     &\leq  \sumk \EE\mbracket{\bracket{\max_{n\in[N]} \abs{\sum_{i\in[n]}\xi_{k,i}}}^2 \givenmiddle \mX_t}^{1/2},
\end{align}
where \eqref{eq:pf-conformity:before-martingale} follows from the Cauchy–Schwarz inequality. 
Next, we argue that the sequence $\sets{\abs{\sum_{i\in[n]}\xi_{k,i}}}_{n\in[N]}$ is a submartingale, which enables us to apply Doob's $L_2$ inequality (\citealp[Theorem 5.4.3]{Dur_19_prob_book}) to bound the expression in \eqref{eq:pf-conformity:before-martingale}. Observe that, for each cost type $k$, conditioned on $\mX_t$, the sequence of random variables $\sets{\xi_{k,i}}_{i\in[N]}$ are independent and have zero conditional means. 
Consequently, the sequence of partial sums $\left\{\sum_{i\in[n]}\xi_{k,i}\right\}_{n\in[N]}$ forms a martingale, which becomes a submartingale upon applying taking absolute values. 
Thus, by applying Doob's $L_2$ inequality and utilizing the bound $\xi_{k,i}\leq c_{\max}$, we obtain 
\begin{equation}
    \label{eq:pf-conform:E-delta-bound}
    \EE\mbracket{\Delta_t\givenmiddle\mX_t} 
    \leq \sumk 2\EE\mbracket{ \sum_{i\in[N]}\xi_{k,i}^2 \givenmiddle \mX_t}^{1/2} 
    \leq 2Kc_{\max}\sqrt{N}\,.
\end{equation}
Combining \eqref{eq:pf-conform:E-delta-bound} with the previous calculations, and taking $K_{\conf} \triangleq (2Kc_{\max} + M_c) / \eta_c$, we conclude that 
\begin{align*}
    \E{\big(Nm(\mX_t) - N_t^*\big)^+ \givenmiddle \mX_t} 
    \leq \EE\mbracket{\frac{\Delta_t+M_c}{\eta_c} \givenmiddle \mX_t} 
    \leq \frac{2Kc_{\max}}{\eta_c}\sqrt{N}+\frac{M_c}{\eta_c} \leq K_{\conf}\sqrt{N}. 
\end{align*}

\end{proof}


\subsection{Proof of Lemma~\ref{lem:non-shrinking} (Almost non-shrinking)}

We first state and prove a supporting lemma below, which will be used in the proof of Lemma~\ref{lem:non-shrinking}.

\begin{lemma}\label{lem:focus set drift}
    Under the ID policy, we have 
    \begin{align*}
        \EE\mbracket{\big(h_{\ID}(\mX_{t+1},m(\mX_t))- \gamma h_{\ID}(\mX_{t},m(\mX_t)\big)^+\givenmiddle\mX_t}\leq 2\big(C_h+\cardS^{1/2} C_{\gamma}(Kc_{\max}+r_{\max})K_{\conf}\big)\sqrt{N}\,,
    \end{align*}
    where $C_h > 0$ is the positive constant given in \Cref{lem:drift}. 
\end{lemma}
\begin{proof}
    We upper bound $\EE\mbracket{\bracket{h_{\ID}(\mX_{t+1},m(\mX_t))-\gamma h_{\ID}(\mX_t,m(\mX_t))}^+\givenmiddle\mX_t}$ by coupling $\mX_{t+1}$ with a random element $\mX_{t+1}'$ constructed as follows: Let $\mX_{t+1}'$ be the system state at step $t+1$ if we were able to set $A_{i,t}=\widehat{A}_{i,t}$ for all $i\in[N]$. From the drift condition of the Lyapunov function $h_{\ID}(\cdot,D)$, as established in \Cref{lem:hID drift}, we obtain: 
    \begin{equation}
        \label{eq:pf-hid-x-mx-shrink:apply-drift-of-hid}
        \EE\mbracket{(h_{\ID}(\mX_{t+1}',m(\mX_t))-\gamma h_{\ID}(\mX_t,m(\mX_t)))^+\givenmiddle\mX_t} \leq 2C_h\sqrt{N}\,.
    \end{equation}
    We couple $\mX_{t+1}'$ and $\mX_{t+1}$ such that $\mX_{i,t+1}'=\mX_{i,t+1}$ for all $i\leq \min\sets{N_t^*,Nm(\mX_t)}$. Then we have
    \begin{align}
        \nonumber
        &\mspace{23mu} \EE\mbracket{\big(h_{\ID}(\mX_{t+1},m(\mX_t))-\gamma h_{\ID}(\mX_t,m(\mX_t))\big)^+-\big(h_{\ID}(\mX_{t+1}',m(\mX_t))-\gamma h_{\ID}(\mX_t,m(\mX_t))\big)^+\givenmiddle\mX_t}\\
        \nonumber
        &\leq \EE\mbracket{\big(h_{\ID}(\mX_{t+1},m(\mX_t))-h_{\ID}(\mX_{t+1}',m(\mX_t))\big)^+\givenmiddle\mX_t}\\
        \nonumber
        &\leq \EE\mbracket{\max_{m'\in[0,1]_N\colon m'\leq m(\mX_t)}\big(h(\mX_{t+1},[Nm'])-h(\mX_{t+1}',[Nm'])\big)^+\givenmiddle\mX_t}\\
        \nonumber
        &\leq \EE\mbracket{\max_{m'\in[0,1]_N\colon m'\leq m(\mX_t)} \max_{g\in \mathcal{G}}\supell \abs{\sum_{i\in[Nm']}\innerproduct{(X_{i,t+1}'-X_{i,t+1})P_i^{\ell} \gamma^{-\ell}}{g_i}}\givenmiddle\mX_t}\\
        \nonumber
        &= \EE\mbracket{\max_{m'\in[0,1]_N\colon m'\leq m(\mX_t)}\max_{g\in \mathcal{G}}\supell \abs{\sum_{i\in[Nm']}\innerproduct{(X_{i,t+1}'-X_{i,t+1})(P_i-\Xi_i)^{\ell} \gamma^{-\ell}}{g_i}}\givenmiddle\mX_t}\\
        \nonumber
        &\leq \EE\mbracket{\sum_{i\in[Nm(\mX_t)]\backslash[N_t^*]} \sum_{g\in \mathcal{G}}\sumell \norm{X_{i,t+1}-X_{i,t+1}'}\norm{(P_i-\Xi_i)^{\ell}}\gamma^{-\ell}\norm{g_i}\givenmiddle\mX_t}\\
        \nonumber
        &\leq \EE\mbracket{\sum_{i\in[Nm(\mX_t)]\backslash[N_t^*]} 2\cardS^{1/2} \sumell \gamma^{-\ell}\norm{(P_i-\Xi_i)^{\ell}} \sum_{g\in \mathcal{G}}\norm{g_i} \givenmiddle\mX_t}\\
        \nonumber
        &\leq \EE\mbracket{\sum_{i\in[Nm(\mX_t)]\backslash[N_t^*]}2\cardS^{1/2}C_{\gamma}(Kc_{\max}+r_{\max})\givenmiddle\mX_t}\\
        \label{eq:pf-hid-x-mx-shrink:before-apply-conformity}
        &\leq 2\cardS^{1/2}C_{\gamma}(Kc_{\max}+r_{\max}) \EE\mbracket{(Nm(\mX_t)-N_t^*)^+\givenmiddle\mX_t}\\
        \label{eq:pf-hid-x-mx-shrink:apply-conformity}
        &\leq 2\cardS^{1/2} C_{\gamma}(Kc_{\max}+r_{\max})K_{\conf}\sqrt{N}\,,
    \end{align}
    where we have applied \Cref{lem:majority_conformal} to bound the expression in \eqref{eq:pf-hid-x-mx-shrink:before-apply-conformity}.  
    
    By combining \eqref{eq:pf-hid-x-mx-shrink:apply-drift-of-hid} and \eqref{eq:pf-hid-x-mx-shrink:apply-conformity}, we obtain:  
    \begin{align*}
        \EE\mbracket{\bracket{h_{\ID}(\mX_{t+1},m(\mX_t))-\gamma h_{\ID}(\mX_t,m(\mX_t))}^+\givenmiddle\mX_t}\leq 2\left(C_h+\cardS^{1/2} C_{\gamma}(Kc_{\max}+r_{\max})K_{\conf}\right)\sqrt{N}\,.
    \end{align*}
\end{proof}


We now give the proof of Lemma~\ref{lem:non-shrinking}.
\begin{proof}[Proof of Lemma~\ref{lem:non-shrinking}]
    First, we claim that 
    \begin{align}\label{eq:lem8eq1}
        m(\mX_{t+1})\geq m(\mX_t) - \frac{1}{\eta_c N} \bracket{h_{\ID}(\mX_{t+1},m(\mX_{t}))-h_{\ID}(\mX_t,m(\mX_t))}^+ - \frac{M_c}{\eta_cN}
    \end{align}
    To prove the claim, by the maximality of $m(\mX_{t+1})$, it suffices to show that for any $\bar{m}\in [0,1]_N$ such that 
    \begin{equation}
        \label{eq:pf-non-shrink:mbar-claim}
        \Bar{m}\leq m(\mX_t) - \frac{1}{\eta_cN} \bracket{h_{\ID}(\mX_{t+1},m(\mX_t))-h_{\ID}(\mX_t,m(\mX_t))}^+ -\frac{M_c}{\eta_cN}
    \end{equation}
    we have $h_{\ID}(\mX_{t+1},\Bar{m})\leq \rembud([N\Bar{m}])$.
    For any $\Bar{m}$ satisfying \eqref{eq:pf-non-shrink:mbar-claim}, Lemma \ref{lem:positiveC} implies that
    \begin{align*}
        \rembud([N\Bar{m}])-\rembud([Nm(\mX_t)])
        &\geq \eta_c N \bracket{m(\mX_t) - \bar{m}} - M_c  \\
        &\geq\eta_c N\bracket{\frac{1}{\eta_c N}\bracket{h_{\ID}(\mX_{t+1},\Bar{m})-h_{\ID}(\mX_t,m(\mX_t))}^++\frac{M_c}{\eta_cN} } - M_c\\
        &\geq\bracket{h_{\ID}(\mX_{t+1},\Bar{m})-h_{\ID}(\mX_t,m(\mX_t))}^+ \,.
    \end{align*}
    Since $\rembud(m([N\mX_t)])\geq h_{\ID}(\mX_t,m(\mX_t))$ by the definition of $m(\mX_t)$, we thus have
    \begin{align*}
        \rembud([N\Bar{m}])&\geq \rembud([Nm(\mX_t)]) + \bracket{h_{\ID}(\mX_{t+1},\Bar{m})-h_{\ID}(\mX_t,m(\mX_t))}^+ \\
        &\geq h_{\ID}(\mX_t,m(\mX_t)) + \bracket{h_{\ID}(\mX_{t+1},\Bar{m})-h_{\ID}(\mX_t,m(\mX_t))}^+ \\
        &\geq h_{\ID}(\mX_{t+1},\Bar{m})\,,
    \end{align*}
    which proves the claim in \eqref{eq:lem8eq1}. 

    Taking the conditional expectations in \eqref{eq:lem8eq1} and rearranging the terms, we get
    \begin{align*}
       \EE\mbracket{(m(\mX_t)-m(\mX_{t+1}))^+\givenmiddle\mX_t}\leq \frac{1}{N}\EE\mbracket{\bracket{h_{\ID}(\mX_{t+1},m(\mX_t))-h_{\ID}(\mX_t,m(\mX_t))}^+\givenmiddle\mX_t} + \frac{M_c}{N\eta_c}, 
    \end{align*}
    where the right-hand side can be further bounded using \Cref{lem:focus set drift} which states that
    \begin{align*}
        \EE\mbracket{\bracket{h_{\ID}(\mX_{t+1},m(\mX_t))-h_{\ID}(\mX_t,m(\mX_t))}^+\givenmiddle\mX_t}\leq 2\left(C_h+\cardS^{1/2} C_{\gamma}(Kc_{\max}+r_{\max})K_{\conf}\right)\sqrt{N}\,.
    \end{align*}
    Therefore, we have:
    \begin{align*}
        \EE\mbracket{(m(\mX_t)-m(\mX_{t+1}))^+\givenmiddle\mX_t}\leq 2\left(C_h+\cardS^{1/2} C_{\gamma}(Kc_{\max}+r_{\max})K_{\conf}\right)\frac{1}{\sqrt{N}}+\frac{M_c}{\eta_c N},
    \end{align*}
    which implies 
    \[
        \EE\mbracket{(m(\mX_t)-m(\mX_{t+1}))^+\givenmiddle\mX_t} \leq \frac{K_{\mono}}{\sqrt{N}}, 
    \]
    with $K_{\mono} \triangleq 2\left(C_h+\cardS^{1/2} C_{\gamma}(Kc_{\max}+r_{\max})K_{\conf}\right) + M_c / \eta_c$. 
\end{proof}

\subsection{Proof of Lemma~\ref{lem:coverage} (Sufficient coverage)}
\begin{proof}
    Observe that it suffices to focus on the case when $m(\mX_t) \neq 1$. 
    Recall that for any system state $\mx$, $m(\mx)$ is defined as 
    \begin{align}\tag{\ref{eq:focus set def}}
        m(\mx)= \max \sets{ m\in[0,1]_N: h_{\ID}(\mx,m)\leq \rembud([Nm])}. 
    \end{align}
    Because $m(\mX_t) \neq 1$, we have $m(\mX_t)+1/N  \in [0,1]_N$. Then the maximality of $m(\mX_t)$ implies that
    \begin{equation}
    \label{eq:lem9eq1}
        h_{\ID}(\mX_t,m(\mX_t)+1/N) > \rembud([Nm(\mX_t)+1]). 
    \end{equation}
    We can upper bound the left-hand side of \eqref{eq:lem9eq1} using the Lipschitz continuity of $h$:
    \begin{align}\label{eq:lem9eq2}
        h_{\ID}(\mX_t,m(\mX_t)+1/N)\leq h_{\ID}(\mX_t,m(\mX_t)) + L_h.
    \end{align}
    We then lower bound the right-hand side of \eqref{eq:lem9eq1} using Lemma \ref{lem:positiveC}: 
    \begin{align}
        \nonumber
        \rembud([N(m(\mX_t)+1/N)])
        &=  \rembud([Nm(\mX_t)+1]) - \rembud([N])\\ 
        \nonumber
        &\geq \eta_c(N-Nm(\mX_t)-1)-M_c \\
        \label{eq:lem9eq3}
        &=\eta_c N(1-m(\mX_t))-\eta_c - M_c. 
    \end{align}
    Comparing \eqref{eq:lem9eq1}, \eqref{eq:lem9eq2} and \eqref{eq:lem9eq3}, we have:
    \begin{align*}
        h_{\ID}(\mX_t,m(\mX_t))\geq \eta_c N(1-m(\mX_t))-\eta_c - M_c - L_h\,,
    \end{align*}
    which, after rearranging the terms, implies
    \begin{align*}
        1-m(\mX_t)\leq \frac{1}{\eta_c N}h_{\ID}(\mX_t,m(\mX_t))+\frac{K_{\cov}}{N}, 
    \end{align*}
    with $K_{\cov} \triangleq (\eta_c+M_c+L_h)/\eta_c$.
\end{proof}





\section{Proofs of Lemma~\ref{lem:optimality gap} and Lemma~\ref{lem:drift-V}}
\label{sec:proof-lem-main-theorem}

In this section, we provide two final lemmas, \Cref{lem:optimality gap} and \Cref{lem:drift-V}, which together imply \Cref{thm:opt-gap-bound}. We prove these two lemmas in Sections~\ref{app:pf-lem-opt-gap} and \ref{app:pf-lem:drift-V}, respectively. 

\subsection{Proof of Lemma~\ref{lem:optimality gap}}
\label{app:pf-lem-opt-gap}

\optgapbyV*

\begin{proof}
    We can bound the optimality gap as the following long-run average: 
    \begin{align}
        \nonumber
        R^*(N,\bm{S}_0) - R(\pi,\bm{S}_0) 
        &\leq R^{\rel}(N,\bm{S}_0)-R(\pi,\bm{S}_0)\\
        \nonumber
        &= R^{\rel}(N,\bm{S}_0) - \lim_{T\to\infty} \frac{1}{T} \sum_{t=0}^{T-1} \frac{1}{N}\sumN \EE[r_i(S_{i,t},A_{i,t})]  \\
        \nonumber
        &= \lim_{T\to\infty} \frac{1}{T} \sum_{t=0}^{T-1} \Big(R^{\rel}(N,\bm{S}_0) - \frac{1}{N}\sumN \EE[r_i(S_{i,t},A_{i,t})]\Big)
    \end{align}
    To bound $R^{\rel}(N,\bm{S}_0) - \sumN \EE[r_i(S_{i,t},A_{i,t})] / N$, we calculate that
    \begin{align}
        \nonumber
        &\mspace{23mu} R^{\rel}(N,\bm{S}_0) - \frac{1}{N}\sumN \EE[r_i(S_{i,t},A_{i,t})]  \\
        \nonumber
        &= \frac{1}{N}\sumN\sum_{s\in\sspa,a\in\aspa}r_i(s,a)y_i^*(s,a) - \frac{1}{N}\sumN \EE[r_i(S_{i,t}, A_{i,t})] \\
        \nonumber
        &\leq \frac{1}{N}\sumN\sum_{s\in\sspa,a\in\aspa}r_i(s,a)y_i^*(s,a) - \frac{1}{N}\sumN \EE[r_i(S_{i,t},\widehat{A}_{i,t})] + \frac{2r_{\max}}{N}\sumN\EE\mbracket{\mathbf{1}\sets{A_{i,t}\neq\widehat{A}_{i,t}}}\\
        \nonumber
        &= \frac{1}{N}\sumN\innerproduct{r_i^*}{\mu^*_i-\EE[X_{i,t}]}  + \frac{2r_{\max}}{N}\sumN\EE\mbracket{\mathbf{1}\sets{A_{i,t}\neq\widehat{A}_{i,t}}} \\
        \label{eq:pf-opt-gap-bd:eq-0}
        &\leq \frac{1}{N}\sumN\innerproduct{r_i^*}{\mu^*_i-\EE[X_{i,t}]} + 2r_{\max} \EE\mbracket{1-\frac{N_{t}^*}{N}}\\
        \label{eq:pf-opt-gap-bd:eq-1}
        &\leq
        \frac{1}{N}\sumN\innerproduct{r_i^*}{\mu^*_i-\EE[X_{i,t}]} + 2r_{\max} \EE\mbracket{1-m(\mX_{t})} + \frac{K_{\conf}}{\sqrt{N}} \\
        \label{eq:pf-opt-gap-bd:eq-2}
        &\leq \frac{1}{N}\EE\mbracket{h_{\ID}(\mX_{t},1)} + 2r_{\max} \EE\mbracket{1-m(\mX_{t})} + \frac{K_{\conf}}{\sqrt{N}}
    \end{align}
    where \eqref{eq:pf-opt-gap-bd:eq-0} is due to the definition of $N_t^*$; \eqref{eq:pf-opt-gap-bd:eq-1} is due to the bound on $\EE[\bracket{Nm(\mX_t) - N_t^* }^+]$ in \Cref{lem:majority_conformal}, and \eqref{eq:pf-opt-gap-bd:eq-2} directly follows from the definition of $\hid(\mx, 1)$. 
    We further bound the first two expressions in \eqref{eq:pf-opt-gap-bd:eq-2} in terms of $V(\mX_t)$ as follows: 
    \begin{align}
        \label{eq:pf-opt-gap-bd:eq-4}
        h_{\ID}(\mX_{t},1)&\leq h_{\ID}(\mX_{t},m(\mX_{t}))+L_h N (1-m(\mX_{t}))=V(\mX_{t}), \\
        \label{eq:pf-opt-gap-bd:eq-3}
        1-m(\mX_{t}) &\leq \frac{1}{L_h N}V(\mX_{t}) 
    \end{align}
    where \eqref{eq:pf-opt-gap-bd:eq-4} is due to the Lipschitz continuity of $\hid(\mx, m)$ with respect to the parameter $m$ (Lemma~\ref{lem:hID drift}), and \eqref{eq:pf-opt-gap-bd:eq-3} is due to the definition of $V(\mx)$.  

    
    Combining the above calculations, we get
    \begin{align*}
       R^*(N,\bm{S}_0) - R(\pi,\bm{S}_0)
       &\leq  \lim_{T\to\infty} \frac{1}{T} \sum_{t=0}^{T-1} \Big(\frac{1}{N}\EE\mbracket{h_{\ID}(\mX_{t},1)} + 2r_{\max} \EE\mbracket{1-m(\mX_{t})} + \frac{K_{\conf}}{\sqrt{N}}   \Big) \\
       &\leq \frac{2r_{\max} + L_h}{L_h N}\lim_{T\to\infty}\frac{1}{T}\sum_{t=0}^{T-1}\EE\mbracket{V(\mX_{t})} + \frac{K_{\conf}}{\sqrt{N}}\,.
    \end{align*}
\end{proof}

\subsection{Proof of Lemma~\ref{lem:drift-V}}
\label{app:pf-lem:drift-V}

\driftV*

\begin{proof}
We derive a recurrence relation between $\E{V(\mX_{t+1})}$ and $\E{V(\mX_t)}$, by bounding $\E{V(\mX_{t+1}) \givenplain \mX_t} - V(\mX_t)$. Specifically, observe that by the Lipschitz continuity of $\hid(\mX, D)$ with respect to $D$, we have
    \begin{align*}
        V(\mX_{t+1})
        &= h_{\ID}(\mX_{t+1},m(\mX_{t+1})) + L_hN(1-m(\mX_{t+1})) \\
        &\leq h_{\ID}(\mX_{t+1},m(\mX_t)) + L_hN(1-m(\mX_t)) + 2L_hN(m(\mX_t)-m(\mX_{t+1}))^+\,.
    \end{align*}
    Consequently, we have
    \begin{align}
        \nonumber
        &\EE\mbracket{V(\mX_{t+1}) \mid \mX_t}-V(\mX_t)\\
        \nonumber
        &\leq\EE\mbracket{h_{\ID}(\mX_{t+1},m(\mX_t)) \mid \mX_t}- h_{\ID}(\mX_t,m(\mX_t)) + 2L_hN\EE\mbracket{(m(\mX_t)-m(\mX_{t+1}))^+ \mid \mX_t}\\
        \label{eq:pf-thm:eq-1}
        &\leq \EE\mbracket{h_{\ID}(\mX_{t+1},m(\mX_t)) \mid \mX_t}- h_{\ID}(\mX_t,m(\mX_t)) + 2L_hK_{\mono}\sqrt{N}\,,
    \end{align}
    where the last inequality follows from \Cref{lem:non-shrinking}. To bound $\EE\mbracket{h_{\ID}(\mX_{t+1},m(\mX_t)) \mid \mX_t}$, observe that by \Cref{lem:majority_conformal}, all but $O(\sqrt{N})$ arms in $[Nm(\mX_t)]$ follow the optimal single-armed policies, so the drift condition of $\hid$ applies to this set of arms. As formalized in \Cref{lem:focus set drift}, we can thus show that
    \begin{align}
        \EE[h_{\ID}(\mX_{t+1},m(\mX_t))\givenplain \mX_t ]\leq \gamma h_{\ID}(\mX_t,m(\mX_t)) + \left(2C_h+2\cardS^{1/2} C_{\gamma}(Kc_{\max}+r_{\max})K_{\conf}\right)\sqrt{N}\,.\label{eq:pf-thm:invoke-focus-set-drift}
    \end{align}
    Plugging \eqref{eq:pf-thm:invoke-focus-set-drift} back to \eqref{eq:pf-thm:eq-1}, we get 
    \begin{align}
        \EE\mbracket{V(\mX_{t+1}) \mid \mX_t}-V(\mX_t)
        \label{eq:pf-thm:eq-2}
        &\leq  -(1-\gamma) h_{\ID}(\mX_t,m(\mX_t))  \\
        &+ \left(2C_h+2\cardS^{1/2} C_{\gamma}(Kc_{\max}+r_{\max})K_{\conf} + 2L_hK_{\mono}\right)\sqrt{N}. \nonumber
    \end{align}
    To further bound $h_{\ID}(\mX_t,m(\mX_t))$ in \eqref{eq:pf-thm:eq-2} in terms of $V(\mX_t)$, we apply \Cref{lem:coverage} to get: 
    \begin{align}
        \nonumber
        V(\mX_t) &= h_{\ID}(\mX_t,m(\mX_t)) + L_hN(1-m(\mX_t))\\
        &\leq \Big(1+\frac{L_h}{\eta_c}\Big) h_{\ID}(\mX_t,m(\mX_t)) + L_hK_{\cov}\,. \label{eq:pf-thm:invoke-sufficient-coverage}
    \end{align}
    Substituting \eqref{eq:pf-thm:invoke-sufficient-coverage} into \eqref{eq:pf-thm:eq-2} and rearranging the terms, we get: 
    \begin{equation}
        \label{eq:pf-thm:drift-inequality}
        \EE\mbracket{V(\mX_{t+1}) \givenplain \mX_t}-V(\mX_t) \leq -\rhov V(\mX_t) + \Kv \sqrt{N}, 
    \end{equation}
    where $\rhov = (1-\gamma) / (1+\frac{L_h}{\eta_c})$, and 
    \begin{align*}
        \Kv &= 2C_h +2\cardS^{1/2} C_{\gamma}(Kc_{\max}+r_{\max})K_{\conf}\\
        &+2L_hK_{\mono}+ \frac{\rhov L_h K_{\cov}}{\sqrt{N}}.  
    \end{align*}
    
    Taking the expectation in \eqref{eq:pf-thm:drift-inequality} and unrolling the recursion of $\E{V(\mX_t)}$, we get
    \begin{equation*}
        \E{V(\mX_{t})} \leq (1-\rhov)^t \E{V(\mX_0)} + \frac{\Kv\sqrt{N}}{\rhov}. 
    \end{equation*}
    Therefore, we can bound the long-run-averaged expectation of $\E{V(\mx)}$ as 
    \begin{equation}
        \label{eq:pf-thm:final-EV-bound}
        \lim_{T\to\infty} \frac{1}{T} \sum_{t=0}^{T-1} \E{V(\mX_{t})} \leq \frac{\Kv\sqrt{N}}{\rhov},
    \end{equation}
    which completes the proof.

    Finally, we give a more explicit form of the constant $C_{\ID}$ in Theorem~\ref{thm:opt-gap-bound} based on the proof above.
    Combining the optimality gap bound in \Cref{lem:optimality gap} with the inequality in \eqref{eq:pf-thm:final-EV-bound}, we get
    \begin{equation*}
        R^*(N,\bm{S}_0)-R(\pi,\bm{S}_0)\leq \frac{(2r_{\max}+L_h)\Kv}{L_h \rhov \sqrt{N}} + \frac{K_{\conf}}{\sqrt{N}}. 
    \end{equation*}
    We have thus proved $R^*(N,\bm{S}_0)-R(\pi,\bm{S}_0) \leq C_{\ID} / \sqrt{N}$, where $C_{\ID}$ is independent of $N$ and is given by
    \begin{align*}
         C_{\ID}&=\frac{\bracket{2\rmax + L_h}\bracket{1/L_h + 1/\eta_c}}{1-\gamma} \bracket{2C_h+2\cardS^{1/2} C_{\gamma}(Kc_{\max}+r_{\max})K_{\conf}+2L_hK_{\mono}} \\
         &\mspace{23mu} + 2(\rmax+L_h)K_{\cov} + K_{\conf}\,.
    \end{align*}  
\end{proof}

