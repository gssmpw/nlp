\newpage
\appendix
\onecolumn
\section{\Ours}

\subsection{Detailed workflow description}
We provide a detailed description of every step in the \ours workflow to supplement \cref{alg:toolmaker} and our discussion thereof in \cref{sec:toolmaker_workflow}.

\subsubsection{Setting up the environment}
The environment definition is a state of the world (\eg the operating system) that is required for the tool created by \ours to execute.
We can represent this state as a sequence of actions (\eg bash commands or instructions in a Dockerfile, as shown in \cref{fig:tool_creation}, left) that mutate a known initial state (\eg a freshly installed operating system) to the state required for the tool to execute.

To obtain the state of the execution environment necessary for the tool to execute, we employ an agent\:\icon{images/icons/agent.pdf} that is instructed to install and set up the repository (we provide the full prompt in \cref{app:prompts}).
This agent will clone and explore the repository, read documentation, and download any dependencies it deems necessary such as models, datasets, and libraries. Each of these steps involve planning and learning from previous mistakes such as error logs arising during execution.
The agent begins with a clean state (a \mbox{\texttt{python:3.12}} Docker image).
Importantly, we record all actions\:\icon{images/icons/environment_interaction.pdf} that the agent performs.
Since each of the write actions can be expressed as a bash command, we can simply concatenate the bash representations of all recorded write actions to obtain the environment definition in the form of a bash script or Dockerfile.


\subsubsection{Initial tool implementation}
Equipped with the environment definition, which allows \ours to reset the state of the execution environment to the state in which the tool should be executed, it can now implement the tool itself.
Note that we do not carry over the conversation history from the previous stage, in order to not pollute the context window with a large number of messages that are irrelevant for this stage.

\paragraph{\icon{images/icons/agent.pdf}\:Gather information}
We first instruct an agent to explore the installed repository and gather all information necessary to implement the tool.
We include the \emph{tool definition} (see \cref{fig:overview}, top left) as a Python function signature with a docstring in the initial prompt, so that it can use the information it has already gathered to create the plan.

\paragraph{\icon{images/icons/llm_call.pdf}\:Create a plan}
Then, we perform an \gls{llm} call to create a step-by-step plan for the tool implementation.
Here, we keep all of the agent's messages (including actions and observations) in the conversation history, so that it can use the information it has already gathered to create the plan.

\paragraph{\icon{images/icons/llm_call.pdf}\:Implement the tool function}
Next, we instruct the \gls{llm} to implement the tool based on the plan.
Again, we keep the entire conversation history in the context window of the \gls{llm} call, so that it can refer to previous messages.
We now have our first \emph{candidate implementation} of the tool function.

We use OpenAI's \texttt{o1-mini-2024-09-12} model for the planning step as well as the implementation step, to take advantage of its reasoning and code generation capabilities.


\subsubsection{Closed-loop self-improvement}
\label{app:toolmaker_workflow:iteratively_fixing}

\paragraph{\icon{images/icons/environment_interaction.pdf}\:Run the tool}
Before executing the candidate implementation, we \emph{reset} the execution environment to the \emph{environment definition} because the agent may have performed write actions in the past (either in the process of exploring the repository, or in a previous iteration of the loop).
Then, we run the candidate Python function in the execution environment, using the example invocation provided in the tool definition.

\paragraph{\icon{images/icons/llm_call.pdf}\:Assess tool execution}
We instruct the \gls{llm} to assess whether the execution was successful, based on the result returned by the function, as well as the standard output and standard error streams produced during function execution.
Specifically, we ask the \gls{llm} to check whether the result returned by the tool is in line with the task description (\ie if the result is plausible), and whether the standard output and standard error streams contain any indications of errors.
If the \gls{llm} determines that the tool execution was successful, we have arrived at our final tool implementation, and exit the loop.
Otherwise, we continue the self-improvement loop.

\paragraph{\icon{images/icons/agent.pdf}\:Diagnose error}
We instruct an agent to gather information about the error in order to diagnose its root cause, and to formulate a plan to fix the error.
Importantly, we do not reset the execution environment -- the agent is able to check intermediate files and outputs created during tool execution.

\paragraph{\icon{images/icons/llm_call.pdf}\:Re-implement the tool function}
We perform an \gls{llm} call to re-implement the tool based on the current implementation, the error diagnosis, and the plan to fix the error.


\paragraph{\icon{images/icons/llm_call.pdf}\:Summarise the attempt}
Given the conversation history of the current attempt, we instruct the \gls{llm} to summarise the attempt (\ie the diagnosed error and steps taken to fix the error).

This concludes the current attempt.
We reset the state of the execution environment to the environment definition.
We also reset the conversation history to the state before the current attempt started (\ie immediately after the initial implementation of the tool function). However, we append the summaries of all past attempts including the current one to the conversation history, and also include the current version of the code implementation.
Then, we continue with the next iteration of the loop, \ie go back to the start of \cref{app:toolmaker_workflow:iteratively_fixing}.



\section{Extended results}
\label{app:extended_results}

\subsection{Per-task ablation results}
\label{app:extended_ablation_results}
In \cref{tab:results_with_paper,tab:results_with_o3mini,tab:results_with_claude35sonnet}, we provide detailed extended results for the ablations in a format similar to \cref{tab:results} in the main paper.

\begin{table*}
  \centering
  \adjustbox{max width=\linewidth}{
    \input{data/results_gpt-4o_paper.tex}
  }
  \caption{Results (with paper summary in context).}
  \label{tab:results_with_paper}
\end{table*}
\begin{table*}
  \centering
  \adjustbox{max width=\linewidth}{
    \input{data/results_o3-mini.tex}
  }
  \caption{Results (using o3-mini).}
  \label{tab:results_with_o3mini}
\end{table*}
\begin{table*}
  \centering
  \adjustbox{max width=\linewidth}{
    \input{data/results_claude-3-5-sonnet.tex}
  }
  \caption{Results (using Claude 3.5 Sonnet).}
  \label{tab:results_with_claude35sonnet}
\end{table*}

\subsection{Raw unit test results}
We provide the raw unit test results for all tasks in \cref{tab:raw_toolmaker,tab:raw_openhands} for the main experiments and \cref{tab:raw_toolmaker_paper,tab:raw_openhands_paper,tab:raw_toolmaker_o3mini,tab:raw_openhands_o3mini,tab:raw_openhands_claude35sonnet} for the ablations.
\begin{table}
  \centering
  \begin{adjustbox}{max totalheight=.9\textheight}
  \input{data/benchmark_toolmaker}
  \end{adjustbox}
  \caption{Raw results (\ours, without paper summary in context).}
  \label{tab:raw_toolmaker}
\end{table}
\begin{table}
  \centering
  \begin{adjustbox}{max totalheight=.9\textheight}
  \input{data/benchmark_openhands}
  \end{adjustbox}
  \caption{Raw results (OpenHands~\cite{wang2024openhands}, without paper summary in context).}
  \label{tab:raw_openhands}
\end{table}
\begin{table}
  \centering
  \begin{adjustbox}{max totalheight=.9\textheight}
  \input{data/benchmark_toolmaker_paper}
  \end{adjustbox}
  \caption{Raw results (\ours, with paper summary in context).}
  \label{tab:raw_toolmaker_paper}
\end{table}
\begin{table}
  \centering
  \begin{adjustbox}{max totalheight=.9\textheight}
  \input{data/benchmark_openhands_paper}
  \end{adjustbox}
  \caption{Raw results (OpenHands~\cite{wang2024openhands}, with paper summary in context).}
  \label{tab:raw_openhands_paper}
\end{table}
\begin{table}
  \centering
  \begin{adjustbox}{max totalheight=.9\textheight}
  \input{data/benchmark_toolmaker_o3mini}
  \end{adjustbox}
  \caption{Raw results (\ours, using o3-mini instead of gpt-4o).}
  \label{tab:raw_toolmaker_o3mini}
\end{table}
\begin{table}
  \centering
  \begin{adjustbox}{max totalheight=.9\textheight}
  \input{data/benchmark_openhands_o3mini}
  \end{adjustbox}
  \caption{Raw results (OpenHands~\cite{wang2024openhands}, using o3-mini instead of gpt-4o).}
  \label{tab:raw_openhands_o3mini}
\end{table}
\begin{table}
  \centering
  \begin{adjustbox}{max totalheight=.9\textheight}
  \input{data/benchmark_openhands_claude35sonnet}
  \end{adjustbox}
  \caption{Raw results (OpenHands~\cite{wang2024openhands}, using Claude 3.5 Sonnet instead of gpt-4o).}
  \label{tab:raw_openhands_claude35sonnet}
\end{table}


\subsection{Transitions between tool calls}
\label{app:transitions}
In \cref{fig:trace}, we show the transitions between tool calls by \ours.
\begin{figure}
    \centering
    \includegraphics[width=0.8\linewidth]{images/trace.pdf}
    \caption{Transitions between tool calls by \ours.}
    \label{fig:trace}
\end{figure}

\section{\Ourbenchmark}
\label{app:benchmark}
Below are the complete task definitions for all tasks in our benchmark, \ourbenchmark.

\input{appendix/tasks}


\section{\Ours prompts}
\label{app:prompts}
\begin{tcolorbox}[title={\texttt{Install Repository System Instructions}}]
You're a diligent software engineer AI. You can't see, draw, or interact with
a browser, but you can read and write files, and you can run commands, and you can think.
The user will specify a task for you to complete. You likely need to run several actions
in order to complete the task. You will only be able to execute a single action at a time.

Use the tools (actions) that are at your disposal. 
Each time you invoke a tool, provide a one-sentence summary of why you are invoking it
and what you expect to accomplish by invoking it.

Your working directory is \texttt{\{LOCAL\_WORKSPACE\_DIR!s\}}.

You will continue the process of invoking tools until you have completed the task.
\end{tcolorbox}

\begin{tcolorbox}[title={\texttt{Install Repository User Instructions}}]
Clone and locally set up the \texttt{{definition.repo.name}} repository from GitHub.
Follow these steps:
1. Git clone the repository \texttt{{definition.repo.info()}} into the directory `\texttt{{install\_path}}`.
2. Check the README (find it if it is not in the root directory) and closely follow the recommended instructions to set up the entire repository correctly for the user.
3. Follow the instructions in the README to correctly set up the repository for the user. Perform any necessary installations, configurations, downloads or setups as described. If the repository is in Python, prefer using `pip` as opposed to conda, virtualenv, or similar. Install the repository and its dependencies globally. Do not use Docker or similar container tools (even if the README suggests it); instead, install the repository and its dependencies globally.
4. Make sure that you complete every step, so that a user could directly use this repository without the need to do further setups, installations or downloads. This includes downloading any necessary pretrained models. However, do NOT download any datasets.
If you encounter any issues, try to solve them.

\texttt{{environment\_variables\_prompt(definition.repo)}}

You should set up the repository in such a way that it can be used to implement the following task later on:
<intended\_task>
<description>
\texttt{{definition.description}}
</description>
<arguments>
\texttt{{"\\n".join(f"{name} ({arg.type}): {arg.description}" for name, arg in definition.arguments.items())}}
</arguments>
<returns>
\texttt{{definition.description\_of\_returns()}}
</returns>
</intended\_task>
IMPORTANT: Your task right now is to only set up the repository, NOT implement this task.

When you are done, provide a brief summary of what you did and what you accomplished, as well as the absolute path to the cloned and installed repository.
\end{tcolorbox}

\begin{tcolorbox}[title={\texttt{Explore Repository User Instructions}}]
\# Background
The repository `\texttt{{definition.repo.name}}` is fully set up and installed at `\texttt{{get\_local\_install\_path(definition.repo)!s}}`.
We need to wrap a specific functionality from this repository into a standalone python function, that can be called independently. 
This function will be called `\texttt{{definition.name}}`, and it is described as follows:
<description>
\texttt{{definition.description}}
</description>

The function will have the following arguments:
<arguments>
\texttt{{"\\n".join(f"<argument>{arg!r}</argument>" for arg in definition.arguments)}}
</arguments>

\texttt{{installed\_repository\_summary}}

\# High-level approach
In order to implement this function, you will follow these steps:
1. Explore the repository to gather all relevant information needed to write the plan.
2. Write a plan for the body/implementation of the function. This plan should be in the form of very high-level pseudo-code, that describes how the function will work.
3. Write the function, based on the plan.

\# Task
Right now, you are at step 1: Explore the repository to gather all relevant information needed to write the plan.
This step is very important, and you must be thorough because you will rely on this information later when implementing the function.
To gather all relevant information needed for the implementation, explore the repository, but only look at relevant files.
Use the tools at your disposal to read files, list directories, search, etc.
HINT 1: If the repository contains a README file, that is often a good starting point. Note that there may be zero or more README files. Always check for README files, and prefer to follow the instructions therein.
HINT 2: If the repository provides a command line interface, prefer to invoke that via subprocess, rather than calling the underlying python functions. Only as a last resort, wrap python functions.
HINT 3: Do NOT attempt to read image files, audio files, etc.
Do not unnecessarily read files that are not relevant for the task.
**However, make sure to read ALL files (e.g. documentation, code, configuration files, etc.) that are necessary in order to implement the function. It should be possible to implement the function based only on the plan and the files you read!**
**You should read relevant code files in order to understand how the functionality you are wrapping is implemented. If you are planning to wrap specific functions, be sure to read the relevant code in order to understand what the input and output arguments/formats are. This is especially relevant if the function you are wrapping produces output files that you will need to read.**
Do NOT write the function yet.
Your task is specifically to explore the repository to gather information.

Once you have gathered ALL relevant information, respond with a one-paragraph summary of what you found.

Remember, the function should do the following:
<description>
\texttt{{definition.description}}
</description>

As such, the signature of the function will be:
```python
\texttt{{definition!s}}
```
\end{tcolorbox}

\begin{tcolorbox}[title={\texttt{Explore Repository User Instructions}}]
Using the information you gathered previously, your task is now to write an outline (plan) for the body/implementation of the function. 
    This plan should be in the form of very high-level pseudo-code, that describes how the function will work.
    It should be a numbered list of steps, each of which describes what you will do in that step.
    Respond with just this list of steps, nothing else.
    Remember, the function should do the following: `{definition.description}`
    
    As such, the signature of the function will be:
    ```python
    \texttt{{definition!s}}
    ```
\end{tcolorbox}

\begin{tcolorbox}[title={\texttt{Summarize Problem User Instructions}}]
Provide a one-paragraph summary of the most recent problem that occured, your diagnosis of it, and how you attempted to fix it with this code change. 
Be specific. 
Include any file paths and other details that are relevant to the problem/solution. 
Your summary should contain all information needed to implement the fix, and include the key insights/observations made for diagnosing the problem.
Begin your response with "The problem was..."
\end{tcolorbox}


\begin{tcolorbox}[title={\texttt{Summarize Problem User Instructions}}]
Now that you have identified the problem as well as a plan to fix the function, you need to write the updated implementation of the function.
Remember, the function is called `{definition.name}`, and it is described as follows: `\texttt{{definition.description}}`.
The function will have the following arguments:
<arguments>
\texttt{{"\\n".join(f"<argument>{arg!r}</argument>" for arg in definition.arguments)}}
</arguments>

As such, the signature of the function will be:
```python
\texttt{{definition!s}}
```

Your task is now to write the Python function.
To do so, use the information you gathered above to fix the function.

\texttt{{coding\_instructions(definition)}}

As a reminder, the current draft of the function is:
```python
\texttt{{code\_draft}}
```

Remember, your diagnosis is:
<diagnosis>
\texttt{{diagnosis.diagnosis}}
</diagnosis>

And your plan to fix the issue is:
<plan>
\texttt{{diagnosis.plan}}
</plan>

Respond with the updated function code only, without any other text.
\end{tcolorbox}


\begin{tcolorbox}[title={\texttt{Coding Instructions}}]
You **must** output a valid, standalone python function that is callable without any modification by a user.
The requirements for the code are:
1. Import the required modules/libraries.
2. You are only allowed to write a single python function. It must start with 'def ...' and end with 'return ...'.
3. You are not allowed to output free texts, test code for the function or anything outside of the function definition.
4. The function needs to be a standalone function that can be called independently.
5. Make sure all required imports are included in the function.
6. The function must perform the task you are given. As a reminder, the task is: `{definition.description}`.
7. Make sure the function accepts all required parameters as inputs.
8. The function must have type hints and a docstring.
9. The function must be named exactly `{definition.name}`.
10. The function must be a valid python function, that can be executed by a python interpreter.

\texttt{{environment\_variables\_prompt(definition.repo)}}

Additional instructions:
* Write the function in such a way that it can easily be debugged later. This means that you should include a lot of print statements for logging purposes. Especially for long-running tasks, it is important to print the progress periodically.
* When catching exceptions in the code (with `try` and `except`), make sure to output the entire stack trace to stderr, so that it can be used to diagnose any issues, e.g. using `traceback.format\_exc()`.
* When running commands and scripts (e.g. using subprocesses), make sure to stream the stdout and stderr to the parent process, so that it can be used to diagnose any issues.
  Use the utility function `run\_and\_stream\_command` provided by the `subprocess\_utils` module. It accepts the same arguments as `subprocess.Popen`, and returns a tuple `(return\_code, output)` (return\_code is an integer, output is a string containing stdout and stderr combined).
  The `run\_and\_stream\_command` automatically handles the streaming of stdout and stderr to the parent process. Be sure to appropriately set the `cwd` argument.
  Example usage:
  ```python
  from subprocess\_utils import run\_and\_stream\_command  \# you must import this
  return\_code, output = run\_and\_stream\_command("echo hello \&\& echo world", shell=True, env={{"MY\_VAR": "my\_value"}}, cwd="/workspace/my\_project")  \# shell=True is the default
  ```
* Make sure that you do not run interactive commands. If some python function that you are calling itself runs interactive commands, try and find a way to avoid calling that function. If, as a last resort, you cannot avoid calling that function, mock/patch the external interactive function to ensure that it does not run interactive commands.
* Always prefer to import existing functions into the function you are writing, or run existing scripts/modules (e.g. via the subprocess functionality descibed above), instead of writing your own implementations. Only if this does not work, or there is no existing function that can be imported, write your own implementation.
\end{tcolorbox}




\begin{tcolorbox}[title={\texttt{Implement Function User Instructions}}]
Now that you have identified the plan for the implementation, you need to write the actual implementation of the function.
This needs to be a standalone python function, that can be called independently. 
This function will be called `\texttt{{definition.name}}`, and it is described as follows: `\texttt{{definition.description}}`.
The function will have the following arguments:
\texttt{{"\\n".join(("- " + repr(arg)) for arg in definition.arguments)}}

As such, the signature of the function will be:
```python
{definition!s}
```

Your task is now to write the Python function.
To do so, follow the plan you identified earlier for the implementation:
<plan>
{plan}
</plan>

\texttt{{coding\_instructions(definition)}}

Remember, you should use the repository `\texttt{{definition.repo.name}}` (installed at `\texttt{{get\_local\_install\_path(definition.repo)!s}}`) to complete the task.
Finally, ensure your function is ready-to-use without any modifications by a user. In many cases, wrapping an existing function, script or module in a subprocess is enough.
Respond with the code of the function only, without any other text.
\end{tcolorbox}


\begin{tcolorbox}[title={\texttt{Diagnose User Instructions}}]

Your initial code implementation did not work. This was attempt number \texttt{{len(problem\_summaries)}} to fix the problem.

Here is a summary of the previous problems, and your attempts to fix them. Keep this in mind as we proceed, and avoid repeating the same mistakes.
<summaries>
\texttt{{'\\n'.join(f'<summary number={i}>{summary}</summary>' for i, summary in enumerate(problem\_summaries))}}
</summaries>

The current version of your code (after \texttt{{len(problem\_summaries)}} attempts) is below.
IMPORTANT: this is the most up-to-date version of your code, so focus on it when diagnosing the problem.
```python
\texttt{{code}}
```

Upon executing this updated function, I received another error.
As a diligent software engineer AI, your task is now to diagnose the issue and fix the function.
You can't see, draw, or interact with a browser, but you can read and write files, and you can run commands, and you can think.
You will be provided with the stdout and stderr from the function execution.
First, use your tools (e.g. running commands, listing directories, reading files, etc.) to gather information about the issue, in order to diagnose it.
Specifically, try to find out the root cause of the issue. Often, this requires reading relevant code files in the repository to understand how the problem occured, and if any assumptions you made in your implementation of the function are incorrect.
Then, formulate a plan to fix the issue, and finally respond with that plan.

NOTE: The plan you write should be the immediate plan to modify the function to fix the issue. 
After you provide the plan, you will then be asked to provide the code to implement the plan, and I will execute that code. 
I will then give you the output of the code execution, and you will be asked to provide a new plan to fix the new issue. 
Therefore, if after exploring the codebase you still don't know what's wrong, your plan should be to modify the function to provide more logging to help you diagnose the problem next time it is executed.

IMPORTANT: While you are able to interact with the environment (writing files, running commands, etc.), any changes you make will be lost when the function is executed again, as the environment will be reset. Therefore, use this opportunity only to gather information about the issue, and not to fix it.
HINT: After gathering information, you may decide to use a slightly different approach to fix the issue -- if this is the case, include this in your plan! 
HINT: Always prefer importing code from the repository, rather than implementing it yourself. The information you gather may contain code that you can import to fix the issue.

Output (stdout and stderr) of the function execution:
<output>
\texttt{{output.stdout}}
</output>

Initial assessment why the function call was not successful:
<assessment>
\texttt{{assessment.reasoning}}
</assessment>

As mentioned above, your immediate task is to diagnose the issue, and formulate a plan to fix it.
\end{tcolorbox}



\begin{tcolorbox}[title={\texttt{Function Execution Assessment User Instructions}}]
I executed the function you wrote.
Based on the output and returned result, assess whether the function call was successful or not.
Specifically, you should assess whether the function performed the task it was supposed to perform.
Also make sure that the returned result is plausible and matches the stdout/stderr output logs, if applicable.
As a reminder, the task is the following:
<task\_description>
\texttt{{definition.description}}
</task\_description>

Description of expected result:
<expected\_result\_description>
\texttt{{definition.description\_of\_returns()}}
</expected\_result\_description>

Returned result:
<result>
\texttt{{truncate\_str(repr(output.result), max\_length=10000)}}
</result>

Output (stdout and stderr) of the function execution:
<output>
\texttt{{truncate\_str(output.stdout, max\_length=10000)}}
</output>

**IMPORTANT: You must also ensure that the returned result itself is correct. This includes ensuring that the result dict contains the correct keys and values, and that the values have the correct types and shapes! If any of these are incorrect, the function call is NOT successful! If this is the case, include this in your reasoning.**
""",
\end{tcolorbox}

\section{OpenHands baseline prompt}
\label{app:openhands_prompts}
Below is the prompt used for the OpenHands baseline~\cite{wang2024openhands}.
\begin{tcolorbox}[title={\texttt{OpenHands Instructions}}]
Your task is to create a tool from the repository {definition.repo.name} which implements the function `{definition.name}` to perform the following task: `{definition.description}`.
While you may perform any necessary installations, configurations, downloads or setups, your deliverables are the following two files:
1. A bash script, named `/workspace/install.sh` that will install all necessary dependencies for the tool to run.
2. A Python file, named `/workspace/code.py` that will contain the code for the tool.

\# Part 1: Install the repository
Clone and locally set up the \texttt{{definition.repo.name}} repository from GitHub.
Follow these steps:
1. Git clone the repository \texttt{{definition.repo.info()}}.
2. Check the README (find it if it is not in the root directory) and closely follow the recommended instructions to set up the entire repository correctly for the user.
3. Follow the instructions in the README to correctly set up the repository for the user. Perform any necessary installations, configurations, downloads or setups as described. If the repository is in Python, prefer using `pip` as opposed to conda, virtualenv, or similar. Install the repository and its dependencies globally.
4. Make sure that you complete every step, so that a user could directly use this repository without the need to do further setups, installations or downloads. This includes downloading any necessary models. However, do NOT download any datasets.
If you encounter any issues, try to solve them.

\texttt{{environment\_variables\_prompt(definition.repo)}}

\# Part 2: Implement the tool function
You need to implement a standalone python function, that can be called independently. 
This function will be called `\texttt{{definition.name}}`, and it is described as follows: `\texttt{{definition.description}}`.
The function will have the following arguments:
\texttt{{"\\n".join((f"- {arg\_name} ({arg.type}): {arg.description}") for arg\_name, arg in definition.arguments.items())}}

As such, the signature of the function will be:
```python
\texttt{{definition!s}}
```
You **must** output a valid, standalone python function that is callable without any modification by a user.
The requirements for the code are:
1. Import the required modules/libraries.
2. You are only allowed to write a single python function. It must start with 'def ...' and end with 'return ...'.
3. You are not allowed to output free texts, test code for the function or anything outside of the function definition.
4. The function needs to be a standalone function that can be called independently.
5. Make sure all required imports are included in the function.
6. The function must perform the task you are given. As a reminder, the task is: `{definition.description}`.
7. Make sure the function accepts all required parameters as inputs.
8. The function must have type hints and a docstring.
9. The function must be named exactly `{definition.name}`.
10. The function must be a valid python function, that can be executed by a python interpreter.

\texttt{{environment\_variables\_prompt(definition.repo)}}

Remember, you should use the repository `{definition.repo.name}` to complete the task.
Finally, ensure your function is ready-to-use without any modifications by a user. In many cases, wrapping an existing function, script or module in a subprocess is enough.
Note: It may be useful to run the function with the following example invocation to test it:
```python3
from code import \texttt{{definition.name}}
\texttt{{definition.name}({", ".join(f"{k}={v!r}" for k, v in definition.example.arguments.items())})}
```

\# IMPORTANT:
- The only two files that you need to produce are `/workspace/install.sh` and `/workspace/code.py` (though you may create other files as well, or install additional dependencies in the process).
- You may use any tools at your disposal to complete the task.
- From within a fresh environment (i.e. a fresh Docker image of python:3.12) that contains the `/workspace` directory which is empty except for your `install.sh` and `code.py` files, it should be possible to run the `install.sh` script, and then run the `code.py` file, without any additional prior installations or dependencies.
- The `code.py` file should NOT contain any imports at the top of the file. The first line of the file should be the function signature (of the `{definition.name}` function). In the body of the function, you may import any necessary modules.
\end{tcolorbox}
