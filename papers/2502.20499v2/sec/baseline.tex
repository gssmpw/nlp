\section{Baseline Results on SG}
\label{sec:baseline}
We first analyze the behavior of a baseline model trained on 8-colors in $\mathcal{D}_{train}$, probing its ability to predict specific attributes. The results are shown in Fig. \ref{fig:base-attributes-performance}.

%Three different conditions are evaluated: (i) accuracy in the training set ({\color{blue}blue bars}) (split A training); (ii) accuracy in the in-distribution test set (test-ID; {\color{orange}orange bars}); (iii) accuracy in the systematic test set (test-OOD; {\color{OliveGreen}green bars}), i.e. includes different combinations of object shapes and colors.
%Finally, random chance prediction for that attribute type ({\color{BrickRed} red bars}) is displayed as a reference.


\begin{figure}
    \centering    
    \includegraphics[width=0.90\linewidth]{figures/results/all_tasks_base.pdf}
    \caption{Accuracy for predicting different properties for different data splits for the baseline model (8 colors). In-distribution performance for all tasks remains high, however out-of-distribution performance plummets for \textit{shape} and \textit{color}, suggesting the model is learning combinations of \textit{shape-color} as features, instead of achieving systematic generalization. Unexpectedly, material and size also show a drop in out-of-distribution performance, even though the model has been exposed to all combinations of these attributes in training. }
    \vspace{-0.5em}
    \label{fig:base-attributes-performance}
\end{figure}

In-distribution performance remains similar to that of $\mathcal{D}_{train}$ for all tasks. However, delving into performance for  $\mathcal{D}_{test-OOD}$ reveals three distinct generalization patterns. First, unexpectedly, the \textit{material} and \textit{size} show a decrease in  $\mathcal{D}_{test-OOD}$ performance, even though the model has been exposed to all combinations of these attributes during training. Second, we observe a significant decrease in performance for the \textit{color} task (44\% drop) and \textit{shape} (99\% drop). This is especially bad for the \textit{shape} task which achieves much worse than random performance (33\% to predict between three shapes in $\mathcal{D}_{test-OOD}$). These results strongly suggest that the model faces challenges when performing SG. These results confirm previous findings that indicate DNNs encounter significant performance challenges when required to generalize systematically \cite{lake2017original-scan,ruis2020gscan,kim2020cogs,keysers2019cfq}. Third, given that both shape and color are related systematically, a natural question arises: why is \textit{color} less affected than \textit{shape}? An explanation for this difference in performance between \textit{color} and \textit{shape} on $\mathcal{D}_{test-OOD}$ emerges from how image information is fed to the model. Due to the division of images into patches, the model can predict the color of a particular object solely based on the information of one patch. However, to predict the shape of an object, the model needs information from additional patches, making this ability harder to train and thus successfully achieve SG.


We turn to analyzing how modulating the amount of training data affects SG. A popular way of promoting generalization is to increase the amount of training data. Therefore, we train models on different percentages of $\mathcal{D}_{train}$. Results are shown in Figure \ref{fig:baseline_less_data}. While in-distribution roughly stays the same, increasing the amount of training data does not result in better out-of-distribution generalization. Performance degrades as dataset size increases. This suggests that merely adding more in-distribution training data may not be a robust way of inducing a bias toward systematic generalization. Even worse, it seems to double down on whatever non-systematic bias the model is learning. We now alter the distribution of $\mathcal{D}_{train}$.



\begin{figure}[h]
    \centering
    \begin{subfigure}[b]{0.45\linewidth}
    \includegraphics[width=\linewidth]{figures/results/acc-shapes-by-train-subset-8.pdf}
    \caption{\centering\textit{Shape} task (8 Colors) \label{fig:baseline_less_data}}
    \end{subfigure}
    \hfill
    \begin{subfigure}[b]{0.45\linewidth}
    \includegraphics[width=\linewidth]{figures/results/acc-shapes-by-train-subset-216.pdf}
    \caption{\centering\textit{Shape} task (216 Colors) \label{fig:sample-efficiency}}
    \end{subfigure}
    \caption{Accuracy for the \textit{shape} task for different amounts of training data for the baseline model (8 colors) vs model trained on 216 colors. (a) Increasing dataset size does not increase out-of-distribution performance but rather degrades it slightly.  (b) With increased \textit{diversity} much stronger out-of-distribution generalization is achieved, with models trained on only a quarter of the data severely outperforming the 8-color baseline.}
    \label{fig:shapes_subset}
\end{figure}
