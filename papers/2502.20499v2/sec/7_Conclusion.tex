\section{Conclusion}

We advocate for a different way of creating inductive biases for SG on our models, by focusing on \textit{altering the training distribution} over other techniques. We show three ways of manipulating the training distribution that provide significant increases in systematic generalization: \textit{diversity}, \textit{burstiness} and \textit{latent intervention}. All of these properties enhance SG significantly, with \textit{diversity} being the most important, enhancing up to an absolute 89\% over the baseline, while the rest seem to be complementary to diversity.

We also study why these are effective. We show that limiting model capacity is not a factor for SG, while increased disentanglement and lower NMI between latent attributes in the dataset seem to explain most of the gains in SG. Crucially, we test for a property of brain-like representations which measures parallelism in representations under changes in a latent attribute. We find that datasets with lower NMI tend to induce more of this parallelism, a property that allows models to extrapolate by analogy. This is, to the best of our knowledge, an unreported mechanism by which dataset distribution induces SG. 

%We study how the systematic generalization of a transformer model on MMLM and measure its capacity to SG to different abilities.
%We found that the model can generalize to other datasets if they share similar distribution properties, but fail otherwise. We show that this limitation is significantly reduced when data diversity increases. Furthermore, we also show that the distribution of increased diversity plays an important role in the ability to SG.
%We relate both of this findings to the NMI between the factors that systematically differ when measuring SG, datasets with lower NMI scores produce models that have superior SG capabilities but this is independent to increased diversity.
%Finally, test internal structure properties of the model finding that both: increased parallel representations are produced when training with data with lower NMI score, and increased p-score is correlated with higher SG abilities of the model.


%\paragraph{Limitations.} Our work focused on how color diversity affects shape SG. Indeed, increasing color diversity in a dataset is direct. However, systematic research is needed to show that data diversity universally promote SG; for instance, exploring how shape diversity affects color generalization. Future studies should also examine if pre-training models based on systematic diversity-based can induce more effective fine-tuning on downstream tasks.