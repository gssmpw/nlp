\section{Geometry of Representations}
 

\subsection{Disentanglement}

A desirable property for SG is disentangled representations \citep{higgins2017betavae,higgins2018definitiondisentangledrepresentations,Duan2020Unsupervised}. Using DCI metrics \citep{eastwood2018a}, we focus on measures of Disentanglement and Completeness. \textit{Disentanglement} measures how many latent attributes each dimension of the representation can predict. A score of 0 implies that each dimension has an equal predictive power for all latent attributes, while a score of 1 suggests that each dimension exclusively predicts a single latent attribute. \textit{Completeness} measures the extent to which different dimensions of the representation predict each latent attribute. A score of 0 means each latent attribute is predicted equally by all dimensions, whereas a score of 1 indicates that only one dimension is responsible for predicting each latent attribute. %\textit{Informativeness} simply reflects the overall predictive power of the representation for the latent attributes. 

Figure \ref{fig:dci} shows results for these metrics for representations for the \textit{color} and \textit{shape} task derived from models with different levels of \textit{color diversity}. Increased diversity for \textit{shape} task representations leads to both greater disentanglement and completeness, while the converse is true for \textit{color} task representations.

\begin{figure}[h]
    \centering
    \begin{subfigure}{0.45\linewidth}
    \includegraphics[width=\linewidth]{figures/results/dci-for-shapes.pdf}
    \caption{\textit{Shape} Task Vectors}
    \end{subfigure}
    \hfill
    \begin{subfigure}{0.45\linewidth}
    \includegraphics[width=\linewidth]{figures/results/dci-for-colors.pdf}
    \caption{\textit{Color} Task Vectors}
    \end{subfigure}
    \caption{Disentanglement and Completeness for models trained on different levels of \textit{color diversity} for vectors predicting the \textit{shape} and \textit{color} tasks. Both disentanglement and completeness increase for the \textit{shape} task vectors, while the contrary happens for \textit{color} task vectors.}
    \label{fig:dci}

\end{figure}

We also complement our analysis by drawing from neuroscience-inspired studies that have demonstrated the potential of parallelism in representations for enhancing generalization \cite{bernardi2020gparallelism-score,ito2022parallelism-score}.

\subsection{Parallelism in Representations}

The intuition behind studying parallelism in representations is that two objects with a single different factor should have a constant direction offset in their representation, independent of other factors or context. Thus, that factor is encoded in representational space as the direction of the difference between both objects' representations.

For instance, think on a classic example for analogy in DNNs: 
$king - man + woman = queen$ which implies:
$king - man = queen - woman = royalness$.

In this case, subtracting the abstract concept of gender gives us vectors that move in the same direction (an abstract property one might consider \textit{royalness}) for two otherwise different vectors. Encoding this property consistently in a single direction allows the model to generalize that concept by way of \textit{analogy}. Analogy is a powerful inductive bias for solving new tasks \citep{mitchell2021abstraction}. %The more these two resulting vectors point in the same direction, the easier it will be to generalize that concept to new combinations of latent attributes.

We proceed to apply this same principle to the latent factors contained in our dataset. From a starting set of 1.024 images, we sample 3.500 pairs of representations from objects that share a common latent attribute. To represent each object we use the representation vector associated to the attribute we wish to study, which in this case will be either \textit{shape} or \textit{color}. We proceed to find for each of these pairs another pair of representations which represents a change in this attribute (i.e. for \textit{shape}, from a pair of red and green cubes, we look for a pair of red and green cylinders). We substract these pairs and from the resulting pair we obtain a single value called a \textit{p-score} \cite{ito2022parallelism-score}. This score is calculated by measuring the cosine of the angle between vectors in the resulting pair.  We report the mean of this value over the 3.500 pairs averaged over 5 runs.

% TODO: Add the p-score figure
\begin{figure}
    \centering
    \includegraphics[width=0.8\linewidth]{figures/p_score.pdf}
    \caption{Computation of the \textit{p-score} metric for vectors $V_A$ and $V_B$, representing the effect of ablating features on \textit{shape} embeddings. We first subtract the embeddings to obtain vectors $V_A$ and $V_B$ and then calculate the degree of parallelism between them using cosine distance. A high \textit{p-score} indicates strong parallelism, suggesting that the attribute (in this case, \textit{cubeness}) is encoded consistently in representational space.}
    \label{fig:pscore}
    % \vspace{-0.5em}
\end{figure}

We relate the \textit{p-score} with performance on $\mathcal{D}_{test-OOD}$ for both the \textit{shape} and \textit{color} task for all models mentioned in Sections \ref{sec:baseline} and \ref{sec:results}. Results for experiments with $8$, $64$, and $216$ colors are shown in Figure \ref{fig:p-score_vs_ood}. Relating to the generalization capabilities in the \textit{shape} task, we see a positive trend in o.o.d generalization when the \textit{p-score} increases. 

To understand how significant this relationship is, we calculate the Pearson correlation between \textit{p-score} and out of distribution performance on the \textit{shape} task. See supplementary material for details. We obtain a 0.73 Pearson correlation with very low p-value, suggesting the strong relationship between \textit{p-score} and SG.  %By comparison, when looking at the p-score shape test-OOD, this result doesn't hold.

% This score is consistent with our working definition of disentangled representation \cite{higgins2018disentangled-representations}. 
% If representations are perfectly parallel (as a direct action of a symmetry subgroup \textbf{check correct use}), the change in the representation is encoded by a constant direction in space, thus meeting the criteria that the 

We also plot the relationship between NMI and \textit{p-score}, as the positive relation both values have out-of-distribution generalization might be mediated by one or the other. Results are shown in Figure \ref{fig:p-score_vs_nmi}. A clear relationship between NMI and \textit{p-score} appears: lower NMI datasets are related to higher \textit{p-scores} in representations. Given that NMI is a stable property of the dataset, this suggests that lower NMI datasets tend to produce models with representations with higher p-scores. This suggests a novel mechanism by which lower NMI datasets produce inductive biases during learning that allow models to achieve greater out-of-distribution generalization. These results provide evidence that the \textit{dataset distribution influences the representational space geometry of the model} biasing it towards out-of-distributional generalization.
%Higher \textit{p-scores} involve increasingly encoding an abstract factor, such as shape, within the representational space, independent for the particular value that instance takes. %This can be part of the engine for increased generalization we saw in previous experiments.

\begin{figure}[h]
    \centering
    \begin{subfigure}{0.45\linewidth}
    \includegraphics[width=\linewidth]{figures/results/p-score-vs-acc-shapes-in-complete-for-shapes.pdf}
    \caption{OOD Accuracy \label{fig:p-score_vs_ood}}
    \end{subfigure}
    \begin{subfigure}{0.45\linewidth}
    \includegraphics[width=\linewidth]{figures/results/nmi-vs-p-score-complete-shapes.pdf}
    \caption{NMI \label{fig:p-score_vs_nmi}}
    \end{subfigure}
    \caption{(a) Out-of-distribution accuracy versus \textit{p-score} for models trained on 8, 64 an 216 colors for both the \textit{shape} task. A trend can be seen that increasing performance is related to higher parallellism scores in the representation. (b) NMI vs \textit{p-score} for various models. Lower NMI datasets produce models with representations with higher \textit{p-score} suggesting a mechanism by which lower NMI aids in achieving SG. } 
    \label{fig:p-score}
\end{figure}


\begin{comment}{
\begin{figure}[h]
    \centering
    \begin{subfigure}{0.45\linewidth}
    \includegraphics[width=\linewidth]{figures/results/nmi-vs-p-score-complete-colors.pdf}
    \caption{Color task vectors.}
    \end{subfigure}
    \begin{subfigure}{0.45\linewidth}
    \includegraphics[width=\linewidth]{figures/results/nmi-vs-p-score-complete-shapes.pdf}
    \caption{Shape task vectors.}
    \end{subfigure}
    
    \hfill\hfill\hfill
    
    \begin{subfigure}{0.45\linewidth}
    \includegraphics[width=\linewidth]{figures/results/p-score-vs-acc-color-in-complete-for-colors.pdf}
    \caption{Color task vectors.}
    \end{subfigure}
    \begin{subfigure}{0.45\linewidth}
    \includegraphics[width=\linewidth]{figures/results/p-score-vs-acc-shapes-in-complete-for-shapes.pdf}
    \caption{Shape task vectors.}
    \end{subfigure}
    \hfill
    \caption{P-Scores resulting from training in different splits. Each color corresponds to the different distribution of common and exclusive colors with the same number of total object colors. }
    \label{fig:p-score}
\end{figure}
}
\end{comment}
