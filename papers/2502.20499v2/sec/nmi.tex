\section{Mutual Information versus Diversity}


\begin{figure}
    \centering
    \includegraphics[width=0.95\linewidth]{figures/results/nmi-vs-accuracy-w-error.pdf}
    \caption{Normalized Mutual Information in the Training Set vs Out-of-Distribution Accuracy for the \textit{shape} task for datasets with 8, 64 and 216 colors. For lower NMI, there is greater out-of-distribution performance. However, for similar levels of NMI but differing levels of \textit{diversity}, we observe that greater \textit{diversity} increases performance. This suggests that the effect of \textit{diversity} is not only related to changing the NMI in the dataset.}
    \label{fig:nmi_vs_accuracy}
\end{figure}

Previous work \cite{abbasi2023CLIP-compositional-gen} has shown that there is a relation between the Normalized Mutual Information (NMI) of latent attributes and systematic generalization. Mutual information quantifies the amount of information one variable (e.g., \textit{shape}) provides about another (e.g., \textit{color}). Then, this value is normalized with the entropy of the distributions to produce the NMI. The closer NMI is to zero, the more independent these factors are. In other words, a near-zero mutual information score indicates that the dataset offers strong evidence to the model that \textit{shape} and \textit{color} should be treated as independent attributes.

Changing \textit{diversity} in a dataset impacts its NMI, so we proceed to study this effect. We seek to decouple the effect of increased \textit{diversity} from a dataset's NMI. To modulate NMI for a given level of \textit{diversity}, we produce datasets that assign colors that both \textit{cubes} and \textit{cylinders} see during training (common colors) and a set of colors that are only seen either by \textit{cubes} or by \textit{cylinders} (exclusive colors). Modulating the ratio of common colors within the dataset directly alters its NMI, while keeping the total number of colors constant.

To measure the NMI, we follow previous work \cite{abbasi2023CLIP-compositional-gen} and focus on the NMI between the \textit{color} and \textit{shape} of all objects of the training dataset. It shows a Pearson correlation of -0.79. Figure \ref{fig:nmi_vs_accuracy} plots results for datasets with differing levels of \textit{diversity}. For lower NMI, there is greater out-of-distribution performance. However, for similar levels of NMI but differing levels of \textit{diversity}, we observe that greater \textit{diversity} increases performance. This suggests that the effect of \textit{diversity} is not only related to changing the NMI in the dataset but rather other properties. Finally, we study the geometry of representations induced by \textit{diversity}.
%To evaluate how well our dataset supports evidence for this independent representation, we can measure the normalized mutual information (NMI) between these two factors.  % However, it is unclear if the model can be pushed towards making use of this evidence on abstract factors to learn a different procedure to solve the task, thus generalize differently.


%Thus measuring the degree of independence between both features in the training data.
%With it, we can also compare different generated training sets independent of their number of colors, thus factoring out its effect on generalization to the impact of diversity on its own.