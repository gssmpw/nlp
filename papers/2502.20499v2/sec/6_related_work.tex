\section{Related Work}

\textbf{Systematic Generalization.}
Many works have addressed the problem of SG, proposing a variety of strategies. These include data augmentation methods \cite{andreas2020geca,akyureklearning,yang2022subs,akyurek-andreas-2023-lexsym}, training methods \cite{lake2019meta-seq2seq,conklin2021meta,lake2023human}, adjustments to the loss function \cite{heinze2020gscan-auxiliary}, architectural changes \cite{dessi2019cnns,bahdanau2019sys-gen-what-required,dubois2020location,kuo2020gscan-recursive,gao2020gscan-gnn,ontanon2021transformer-sys-gen,qiu2021gscan-solved} and neuro-symbolic approaches  \cite{liu2020compositional,nye2020lcomp-program-synth}. Currently, state-of-the-art methods are based on enhanced LLMs \cite{drozdov2022compositional, qiu2022improving}.


\textbf{Data-driven Inductive Biases.} Previous work has investigated the invariances \cite{bouchacourt2021grounding}, inductive biases such as shape bias \cite{geirhos2018shapes-vs-texture}, and robustness \cite{fang2022data-CLIP} acquired by deep learning models when trained on large-scale datasets.
\citet{prystawski2024think} shows the need for local structure in the training data for models to learn probabilistic reasoning abilities.

Other studies have examined the data properties that enable models to generalize OOD. \citet{chan2022data-properties-drives-in-context-learning} show that burstiness, long-tailed distributions and label mappings can foster in-context learning in Transformers. By contrast, our work focuses specifically on data properties that support SG. For SG, studies have shown that increasing the number of primitives or input length can enhance SG \cite{patel2022revisiting,zhou2023data-factors,rahimi2024d3}. However, their focus is on generalization in the text domain, while we focus on images, examining how different latent factors within the dataset interact to drive SG. % complexity of training data—such as the number of primitives and example length—improves SG performance on textual datasets .   Additionally, \citet{rahimi2024d3} found that in visual question answering (VQA), used diversity in question lengths to enhance SG in question length. 


Other work on generalization in the visual domain \citep{abbasi2023CLIP-compositional-gen} has investigated SG in CLIP models, showing that statistical independence between object-attribute pairs and disentangled representations enhances SG. In contrast, we analyze the effects of explicit generative factors on SG and the mechanisms by which it is enforced.



% Similar work for SCAN and COGS, the probe different data complexities (pattern and scale) affect, also how difficulty level of train example affect training and provide a data augmentation method, all for compositional generalization \cite{zhou2023data-factors}. 

% Also, \cite{bouchacourt2021grounding} probes the emergence of invariances on residual networks and vision transformers when these models are trained on large real datasets and when using data augmentation.

% CNNs are biased towards textures \cite{geirhos2018shapes-vs-texture}, they create a dataset for CNNs to be more biased towards shapes and networks were more robust to image distortions.

% \cite{feinman2018learning-inductive-biases} Study the number of samples and distinct objects shown so that when teaching a simple network to name a shape, generalizes biased on shape to novel shapes.