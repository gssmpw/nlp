\section{Impact of Cardinality of Latent Attributes on SG \label{sec:diversity}}

\begin{figure}[h]
    \centering
    \includegraphics[width=0.45\linewidth]{figures/results/shape-task-overloading-to-8-labels.pdf}
    \caption{Shape performance when trained on data with different number of object colors but with 8 tokens, this is achieved by using label overloading when more than 8 colors exist in objects.}
    \label{fig:controled_shape_and_color_task_by_colors}
\end{figure}
In light of previous results, we study how the data configuration affect SG. 
Specifically, we aim to study how diversity influences systematic generalization by focusing on color attributes.
We hypothesize that increasing the number of colors, and increasing color-shape combinations, will bias the solution of the trained model towards one that increasingly factors knowledge independently between shape and colors.
Either because memorizing a larger number of shape-color combinations is increasingly difficult. Or, increasing the difficulty of relying in color diminishes it's use as a shortcut to predict shape \cite{geirhos2020shortcut-learning}.

We replicate the same dataset structure used for Sec. \ref{sec:base-task}, but increase $|C|$ by augmenting $|C_A|$, meaning that the diversity of the training set increases by increasing the total number of object colors (as well and during the test).
We generate new datasets keeping all other properties unchanged.
For colors, we add new ones shared to all shapes, while keeping some colors exclusive to certain shapes in the different tests.  
For this, we generate new synthetic colors dividing the color span equally over all the channels, but this time into more colors, i.e. 8, 27, 64, 125, and 216 colors.

% We use synthetically generated colors by dividing the span of the color space uniformly in each channel.

% Our results show that augmenting color diversity improves SG on shapes (see monotonic increase of {\color{OliveGreen}green bars} in Fig. \ref{fig:shapes-acc-by-num-colors}).
% Yet, the performance on color prediction decreases in test-ID (Fig. \ref{fig:colors-acc-by-num-colors}), due to a higher number of classes. Nonetheless, increased color diversity reduces overfitting in the color task to the training distribution, as a smaller gap in accuracy between test-ID accuracy and test-OOD shows (Fig. \ref{fig:colors-acc-by-num-colors}).

% Importantly, the trade-off between SG and memorization shows that increasing color diversity leads to significant SG performance gains on shapes, despite a slight decrease in color performance.
% This shows that properties of the data distribution play a relevant role in biasing the latent space or representation to focus on the disentangling of semantic factors, here color and shape.


% And show that increasing combinatorial diversity in the data distribution increases the generalization capabilities of the model to a test set that consists of an increased number of colors and all factors remaining the same.
% See Fig. \ref{fig:controled_shape_and_color_task_by_colors}.


% \textbf{How does increased diversity foster this inductive bias?}


\subsection{Increased Common Colors Increase SG}

To gain a deeper understanding of how diversity impacts generalization, we conducted experiments by modifying the color distribution while keeping the number of colors constant.
Specifically, we created different data splits that varied the ratio of common to exclusive colors.
In this context, common colors are those shared by both cubes and cylinders in the training set, $C^C = \bigcap_{s_i \in S^{sys}} C_A(s_i)$, whereas exclusive colors are distinct to either cubes or cylinders, $C^E = C-C^C$. Since common colors are present in both shapes, they do not serve as indicators for evaluating systematic generalization.
For an illustration, refer to Fig. \ref{fig:common-color-venn}.

In contrast, in the previous section, we added additional colors by keeping exclusive colors constant, to 16 colors in all but the base dataset, and increasing the number of common colors.
We now test different proportions of common vs exclusive colors for different overall numbers of colors in the dataset (8, 64, and 216).

\begin{figure}
    \centering
    \includegraphics[width=0.4\linewidth]{figures/common-colors-venn.png}
    \caption{Depiction of the difference between common and exclusive colors using a venn diagram.}
    \label{fig:common-color-venn}
\end{figure}


When increasing the number of common colors, models achieve better systematic generalization (SG), independent of the total number of colors, as seen in Fig. \ref{fig:common-colors}. 
Additionally, we observe that this property enhances the model's ability to generalize in predicting the color task (see Fig. \ref{fig:colors-common-colors-216}). 
By altering this parameter we can create a scenario where, with a high number of colors, 216, the model fails to generalize when there are no common colors. By modifying this distribution, we can also slightly improve the base case of 8 colors, achieving a modest increase in systematic generalization by approximately 9\%.

Our results show that increasing the number of common colors reinforces the idea—further supported by the observation that spheres of all colors do the same—that all shapes can be colored with any color. Thus, pushing the model to represent these two factors independently.




\subsection{Factor Independence in the Training Data}

For the task at hand, our model must independently represent both shape and color. 
To evaluate how well our dataset supports evidence for this independent representation, we can measure the normalized mutual information (NMI) between these two factors. Mutual information quantifies the amount of information one variable (e.g., shape) provides about another (e.g., color). The closer this value is to zero, the more independent these factors are. In other words, a near-zero mutual information score indicates that the dataset offers strong evidence to the model that shape and color should be treated as independent attributes. However, it is unclear if the model can be pushed towards making use of this evidence on abstract factors to learn a different procedure to solve the task, thus generalize differently.

Following \cite{abbasi2023CLIP-compositional-gen} we measure the NMI in the dataset between the color and shape of all objects of the training dataset.
Thus measuring the degree of independence between both features in the training data.
With it, we can also compare different generated training sets independent of their number of colors, thus factoring out its effect on generalization to the impact of diversity on its own.

We analyze the results of the datasets generated with different common colors and numbers of colors.
With them, we can plot the effect grouped by the number of colors in the dataset as seen in Fig. \ref{fig:nmi_vs_accuracy}. 
We found that the ability to generalize is reduced when the NMI score increases in the dataset, thus establishing a clear relationship between the evidence of independence between factors in the data, and the SG performance that relies on these independence.
We also see that diversity still plays a part in SG which is not completely explained by NMI, as the decreased performance of simple datasets at the same level of NMI shows.
% Reduced ability to shortcut shape task using the color task. 
