\documentclass[sigconf]{acmart}






\AtBeginDocument{%
  \providecommand\BibTeX{{%
    Bib\TeX}}}

\copyrightyear{2025} 
\acmYear{2025} 
\setcopyright{rightsretained}


\acmConference[WWW '25]{Proceedings of the ACM Web Conference 2025}{April 28-May 2, 2025}{Sydney, NSW, Australia}
\acmBooktitle{Proceedings of the ACM Web Conference 2025 (WWW '25), April 28-May 2, 2025, Sydney, NSW, Australia}
\acmDOI{10.1145/3696410.3714660}
\acmISBN{979-8-4007-1274-6/25/04}

\makeatletter
\gdef\@copyrightpermission{
  \begin{minipage}{0.8\columnwidth}
   \href{https://creativecommons.org/licenses/by/4.0/}{This work is licensed under a Creative Commons Attribution International 4.0 License.}
  \end{minipage}
  \vspace{5pt}
}
\makeatother








\let\Bbbk\relax %
\usepackage[utf8]{inputenc} %
\usepackage[T1]{fontenc}    %
\usepackage{hyperref}       %
\usepackage{url}            %
\usepackage{booktabs}       %
\usepackage{amsfonts}       %
\usepackage{nicefrac}       %
\usepackage{microtype}      %
\usepackage{xcolor} 
\usepackage{balance}%
\usepackage{mathtools}
\usepackage{amsthm}

\usepackage{multirow}
\usepackage{adjustbox}

\usepackage{microtype}
\usepackage{graphicx}
\usepackage{subfigure}[labelformat=empty]
\usepackage{booktabs} %
\usepackage{array,multirow}
\usepackage{subcaption}
\usepackage{enumitem}

\usepackage{amsmath}
\usepackage{mathtools}
\usepackage{definitions}
\usepackage{enumitem}
\usepackage{multirow}
\usepackage{graphicx}
\usepackage{subcaption}
\usepackage{booktabs}
\usepackage{pifont}
\usepackage{wrapfig}
\usepackage[medium,compact]{titlesec}
\usepackage{ctable} %
\usepackage{xcolor,colortbl}
\usepackage{arydshln}




\newtheorem{theorem}{Theorem}[section]
\newtheorem{thm}{Theorem}[section]
\newtheorem{claim}[theorem]{Claim}
\newtheorem{definition}[theorem]{Definition}
\newtheorem{fact}[theorem]{Fact}
\newtheorem{lemma}[theorem]{Lemma}
\newtheorem{remark}[theorem]{Remark}
\newtheorem{corollary}[theorem]{Corollary}
\newtheorem{assumption}[theorem]{Assumption}



\setlength{\dashlinedash}{0.5pt}
\setlength{\dashlinegap}{4.5pt}
\setlength{\arrayrulewidth}{0.2pt}
\setlength{\textfloatsep}{0pt}
\setlength{\textfloatsep}{20pt plus 2pt minus 4pt}
\setlength{\textfloatsep}{10pt plus 2pt minus 4pt}
\setlength{\textfloatsep}{10pt plus 1pt minus 2pt}
\setlength{\dbltextfloatsep}{3pt}
\setlength{\intextsep}{5pt}
\setlength{\abovecaptionskip}{5pt}
\setlength{\belowcaptionskip}{3pt}
\setlength{\parskip}{4pt}

\setlength{\abovedisplayskip}{3pt}
\setlength{\belowdisplayskip}{3pt}
\setlength\abovedisplayshortskip{3pt}
\setlength\belowdisplayshortskip{3pt}
\setlength{\dashlinedash}{0.2pt}
\setlength{\dashlinegap}{4.5pt}
\setlength{\arrayrulewidth}{0.2pt}

\usepackage{titlesec}
\titlespacing*{\section}{0pt}{*1}{*1}

\renewcommand{\paragraph}[1]{\noindent {\bf #1}}

\newcommand{\oes}[1]{\textcolor{red}{[oes: #1]}}
\settopmatter{printacmref=true}

\begin{document}

\title{What's in a Query: Polarity-Aware Distribution-Based Fair Ranking}

\author{Aparna Balagopalan$^*$}
\email{aparnab@mit.edu}
\affiliation{\institution{Massachusetts Institute of Technology}
\country{Cambridge, USA}
}

\author{Kai Wang$^*$}
\email{kwang692@gatech.edu}
\affiliation{\institution{Georgia Institute of Technology}
\country{Atlanta, USA}
}

\author{Olawale Salaudeen}
\email{olawale@mit.edu}
\affiliation{\institution{Massachusetts Institute of Technology}
\country{Cambridge, USA}
}

\author{Asia Biega}
\email{asia.biega@mpi-sp.org}
\affiliation{
\institution{Max Planck Institute \\for Security and Privacy} 
\country{Bochum, Germany}
}

\author{Marzyeh Ghassemi}
\email{mghassem@mit.edu}
\affiliation{\institution{Massachusetts Institute of Technology}
\country{Cambridge, USA}
}

\renewcommand{\shortauthors}{Aparna Balagopalan, Kai Wang, Olawale Salaudeen, Asia Biega, \& Marzyeh Ghassemi}



\begin{abstract}
Machine learning-driven rankings, where individuals (or items) are ranked in response to a query, mediate search exposure or \emph{attention} in a variety of safety-critical settings. Thus, it is important to ensure that such rankings are fair.  Under the goal of equal opportunity, attention allocated to an individual on a ranking interface should be proportional to their relevance across search queries. In this work, we examine amortized fair ranking -- where relevance and attention are cumulated over a sequence of user queries to make fair ranking more feasible in practice. Unlike prior methods that operate on expected amortized attention for each individual, we define new divergence-based measures for attention distribution-based fairness in ranking (DistFaiR), characterizing unfairness as the divergence between the distribution of attention and relevance corresponding to an individual over time. This allows us to propose new definitions of unfairness, which are more reliable at test time. Second, we prove that group fairness is upper-bounded by individual fairness under this definition for a useful class of divergence measures, and experimentally show that maximizing individual fairness through an integer linear programming-based optimization is often beneficial to group fairness.
Lastly, we find that prior research in amortized fair ranking ignores critical information about queries, potentially leading to a \emph{fairwashing} risk in practice by making rankings appear more fair than they actually are.

\end{abstract}

\ccsdesc[300]{Human-centered computing~ranking, fairness}


\keywords{fair ranking; query polarity}
\maketitle

\input{sections/01_Introduction}
\input{sections/02_Related_Work}
\input{sections/03_Distance_based_fairness}
\input{sections/05_Distribution_Ranking}
\input{sections/04_Query_Utility}
\input{sections/05_Experiments}
\input{sections/figure2}
\input{sections/06_Results}
\input{sections/08_Conclusion}
\bibliographystyle{plain}
\balance
\bibliography{sample-base}

\input{sections/appendix}

\end{document}
