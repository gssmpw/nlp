\newcommand{\cummA}{A_i}
\newcommand{\cummR}{R_i}
\newcommand{\groupcummA}{A_{g_{k}}}
\newcommand{\groupcummR}{R_{g_{k}}}

\section{Distribution-aware Fairness in Ranking (DistFaiR)}
\label{sec:defining_amortized_distribution_fairness}


We propose new distribution-based definitions of amortized fairness. We denote $\cummA$ and $\cummR$ to be the distribution of an individual $i$'s cumulative attention and relevance till time $T$ respectively. This is in contrast with prior definitions~\cite{biega2018equity,singh2018fairness,morik2020controlling}, where only the mean of the attention distribution over queries is considered for individuals and groups. We start by defining a class of amortized individual and group unfairness (DistFaiR) and then theoretically characterize a relationship between the two for a class of discrepancy measures.

\subsection{Defining Amortized Fairness}
\begin{definition}[DistFaiR-Divergence] \label{def:divergence}
Given two probability distributions $P$ and $Q$ over a common sample space $\Omega$, a divergence $D(P \| Q)$ is a function with the following properties:

\begin{enumerate}
    \item {\em Non-negativity}: $D(P \| Q) \geq 0$
    \item {\em Positivity}: $D(P \| Q) = 0$ if and only if $P = Q$
\end{enumerate}



\begin{lemma}
Define the following:
    \begin{align*}
        D_{L_1}(P \| Q) &= |\mu_P - \mu_Q|
    \end{align*}

    $D_{L_1}$ satisfies definition \ref{def:divergence} for $P$ and $Q$ when $\mu_P$ and $\mu_Q$ are sufficient statistics for their respective distributions. Additionally, it is subadditive, positively homogeneous, and scales under averages.
\end{lemma}


\end{definition}


\subsubsection{Individual Fairness}
\begin{definition}[Amortized Individual Unfairness] 
Amortized Individual Unfairness for a set of individuals is defined as the maximum distance between the distributions of cumulative relevance and cumulative attention over a sequence of queries up to time $T$. Specifically, the unfairness is given by:
\[
\text{Unfairness} = \max_{i \in \{1,2,\dots,n\}} D(\cummA, \cummR),
\]
where $i$ indexes the individuals to be ranked, and $D$ is a divergence.
\end{definition}

Notably, this definition differs from past definitions of amortized fairness~\cite{biega2018equity,singh2018fairness,singh2019policy,raj2022measuring} as follows: (1) the distribution-based fairness definition allows for distributions attention and relevance that are not fully specified by their means, (2) considers a worst-case notion of individual unfairness. For example, in ~\citep{biega2018equity}, unfairness is defined to be the $L_1$ distance of difference between cumulative relevance and cumulative exposure scores allocated to a set of $n$ individuals over $T$ queries. In our framework, this is equivalent to choosing a metric $d(P, Q) = |\EE[P] - \EE[Q]]|$, or the absolute difference in expectations of the two distributions. However, this only captures discrepancies between distributions $P, Q$ where means are sufficient statistics, e.g., Guassians with fixed variances or Exponential with rate parameters reciprocal to the mean. Appendix \ref{sec:dist_example} demonstrates that divergences, which capture properties of distributional difference beyond means, give a more robust and realistic definition of unfairness. %



\subsubsection{Group Fairness}~\\
We extend the previous definition to group level by defining the relevance and attention of a group as the average relevance and attention of individuals belonging to that group, respectively. The attention and relevance of a group $g_k \subset [n]$ at time $t$ respectively are random variables:
\begin{align}
    X_{g_{k}}^{t} = \frac{1}{|g_{k}|}\sum\nolimits_{i \in g_{k}} X_i^t & \quad \text{ and } \quad Y_{g_{k}}^{t} = \frac{1}{|g_{k}|} \sum\nolimits_{i \in g_k} Y_i^t ,
\end{align}
where $|g_{k}|$ denotes the number of individuals in group $g_{k}$, with $|g_{k}| \geq 1$. We can also apply Theorem \ref{theorem:chernoff} to quantify the tail probability of group level relevance and attention.

The relevance distribution and attention in a group $g_k \subset [n]$ throughout time $t \in \Tcal$ are respectively:
    \begin{align}
        X_{g_{k}} = \sum\nolimits_{t \in \Tcal} X_{g_{k}}^{t} & \quad \text{ and } \quad Y_{g_k} = \sum\nolimits_{t \in \Tcal} Y_{g_{k}}^{t} .
    \end{align}
    
Denote $\groupcummA$ and $\groupcummR$ as the distributions of cumulative attention and relevance from which $X_{g_k}$ and $Y_{g_k}$ are generated.

\begin{definition}[Amortized Group Unfairness]\label{def:group-unfairness}
Amortized Group Unfairness for a set of $G$ groups is defined as the maximum distance between the distributions of cumulative relevance and cumulative attention scores across a sequence of queries up to time $T$ for each group. Each individual is assumed to belong to exactly one of the $G$ groups. Formally, group unfairness is expressed as:
\[
\text{Group Unfairness} = \max_{g_k \in \Gcal} D(\groupcummA \| \groupcummR),
\]
where $D$ represents a divergence, $g_k$ denotes the $k$-th group, and $\groupcummA$ and $\groupcummR$ represent the distributions of cumulative attention and cumulative relevance for group $g_k$, respectively.
\end{definition}

We refer our definitions of amortized individual and group unfairness above as \textit{DistFaiR}.

\subsection{Individual Fairness v.s. Group Fairness}


\begin{theorem}\label{theorem:indiv_group}
    For any jointly convex DistFaiR divergence that is subadditive under the convolution operation, positively homogeneous with degree $s$, and scales under averages, amortized group fairness is upper-bounded by amortized individual fairness. Specifically, we have the following inequality:
    \begin{align}
        \max_{g_k \in \Gcal}D(\groupcummA \| \groupcummR) \leq  \max_{i \in \Dcal} D(A_i \| R_i) \hspace{0.5cm} 
        \forall g_k \in \mathcal{G}
    \end{align}
\end{theorem}

Proof provided in Appendix \ref{ref:sec_proof}.



Theorem \ref{theorem:indiv_group} shows that improving individual fairness does not adversely affect group fairness for a class of divergence measures --- optimizing for individual fairness may improve group fairness. Thus, while individual fairness is good criteria, it may not always be possible to ensure individual fairness for some divergence measures (e.g., due to computational infeasibility). In such cases, group fairness constraints could be considered weaker versions of individual fairness, and could be be used more broadly, depending on the underlying normative goals. 


\subsection{Amortized Fairness Re-ranking with Quality Constraints}
\label{sec:re-ranking}
Theorem \ref{theorem:indiv_group} motivates optimizing for individual (un)fairness. Accordingly, we design an objective function corresponding to individual unfairness to be minimized, similar to Biega \emph{et al.} \cite{biega2018equity}.
\begin{align}
     \min\nolimits_{M_{i,j}^t} & \quad \text{max}_{i \in n} \quad D(\cummA \| \cummR) \quad  \text{(individual fairness)} \\
    \text{s.t.} & \quad  \sum\nolimits_{j=1}^k \sum\nolimits_{i=1}^n \frac{r_i^t}{\log_2(j+1)} M^t_{i,j} \geq \theta*\rho(t) \quad \text{for each } t \in \mathcal{T} \\
    & \quad M^t_{i,j} \in \{ 0, 1 \} \quad \forall i,j\\
    & \quad \sum\nolimits_{i} M^t_{i,j} = 1 \quad \forall j \\
    & \quad \sum\nolimits_{j} M^t_{i,j} = 1 \quad \forall i
\end{align}
where $A_i$ and $R_i$ denote cumulative attention and relevance for individual $i$ till time $t$, $M^{t}_{i,j}$ is a binary variable indicating if individual $i$ is present at rank $j$ for the query at time $t$. $\rho(t)$ indicates the DCG (quality) of the ranking at time $t$. Constraint (7) ensures that the quality of the updated ranking does not decrease beyond a given threshold $\theta$. Additionally, constraints (8) and (9) ensure that each individual can be ranked only once in a ranking and no positions are empty, respectively. Given the large size of the variable space, when $n$ is large, we pre-filter the rankings and set $M_{i,j}^t$ to be fixed when $j > K$ for some known $K \in \mathbb{N} < n$. Thus, we only re-order the top-$K$ within each ranking. 

\paragraph{Integer Linear Programming Formulation}
We solve the above optimization problem using integer linear programming and/or integer quadratic programming. We rely on an open-source toolkit, Gurobi~\cite{achterberg2019s} to perform all optimizations where minimizing our objective yields amortized fairness. We study \emph{online optimization} where a new query arrives at each $t$, and hence $M_{i,j}^t$ is optimized at each time step, with knowledge of prior assignments~\cite{biega2018equity}, but no knowledge of the future. Further details can be found in Appendix~\ref{sec:ilp_appendix}. 

\begin{table}
\centering
\caption{Summary statistics of all datasets. The relevance score in the \texttt{rateMDs} dataset and the query utility score in the \texttt{FairTREC2021} dataset are generated using pre-trained LLMs.}
\label{tab:ds_summary}
\footnotesize{
\begin{minipage}{\linewidth}
\resizebox{\textwidth}{!}{

  \begin{tabular}{lcccccc}
  \toprule
    Dataset & \#Individuals &  \#Queries  & \#Groups & Relevance & Polarity\\
    \midrule
    \texttt{synth-binary} & 200 & 16 &2 & $\{0.99,1.01\}$ & $\{-1,1\}$ \\
    \texttt{synth-cont} & 200 & 16 & 2 & Cont. & $\{-1,1\}$\\
    \texttt{rateMDs} & 6.2k & 60 & 2 & Cont. & $\{-1,1\}$\\
    \texttt{FairTREC 2021} & 13.5k & 49 & 3 & $\{0,1\}$ & $[-1,1]$\\
    \bottomrule
    \end{tabular}
}
\end{minipage}
}
\end{table}
