

\vspace{-0.7em}

\section{Conclusions}
In this paper, we propose a new distribution-aware divergence-based metric, DistFaiR, for amortized fairness measurement. We identify metrics under DistFaiR with the useful property that group unfairness is upper bounded by individual unfairness. We show that we can reduce individual and group unfairness under DistFaiR for different choices of divergence measures. We emphasize query polarity as a crucial yet overlooked aspect in fair-ranking literature, noting that neglecting polarity can result in fairwashing. We also empirically demonstrate fairwashing effects due to a lack of query polarity consideration and propose/evaluate a method to mitigate this effect. 

Our work has some limitations. For example, we assume a position bias model of attention. However, we note that this assumption can be relaxed to consider more complex user attention patterns under our framework, with some modifications made to the cumulative attention formulation. We also make normative assumptions that the distribution of attention should be close to that of relevance. However, a different link function may be more appropriate~\cite{saito2022fair}. Additionally, scores allotted to minority groups may be under-estimates of their true value~\cite{pierson2021algorithmic,krieg2022perceived} and may need to be pre-processed ~\cite{liao2023social}.  Importantly, there may not be purely technical fixes for operationalizing real-world fair ranking~\cite{gichoya2021equity}. Our approach, we believe, is a step towards reducing the scale of such issues.






