\begin{figure}
    \centering
    \includegraphics[width=0.8\linewidth]{Figs/sft_dataset.png}
    \caption{In our constructed dataset for VLM's supervised fine-tuning, we input a system prompt and a front image into VLM and expect a structured output including detected objects, advice of the ego vehicle's driving behavior, and the proposal of a path.}
    \label{fig:sft_dataset}
\vspace{-0.3cm}
\end{figure}

\subsection{Supervised Fine-tuning of Qwen2-VL-7B}

We extract the information including the detection results and ego future trajectory from nuScenes. Then we generate the advice for the ego vehicle's behavior according to the changes in the ego vehicle's speed and temporal trajectory. By feeding the system prompts and a front image from the surrounding cameras into the VLM, an example of our fine-tuning dataset is shown in Fig. \ref{fig:sft_dataset}.

\begin{table}[ht]
    \caption{The results of the verification of normally distributed noise from our fine-tuned VLM's responses.}
    \centering
    \begin{tabular}{@{}cccll@{}}
\cmidrule(r){1-3}
\multicolumn{1}{c|}{\begin{tabular}[c]{@{}c@{}}Number of VLM \\ path outputs\end{tabular}} & \multicolumn{1}{c|}{\begin{tabular}[c]{@{}c@{}}Number of the paths \\ with normally \\ distributed noise\end{tabular}} & \begin{tabular}[c]{@{}c@{}}Percentage of the paths \\ with normally \\ distributed noise\end{tabular} &  &  \\ \cmidrule(r){1-3} 
\multicolumn{1}{c|}{20235} & \multicolumn{1}{c|}{19830} & 98.00\% &  &  \\ \cmidrule(r){1-3}
\multicolumn{1}{c|}{37812} & \multicolumn{1}{c|}{36890} & 97.60\% &  &  \\ \cmidrule(r){1-3}
\multicolumn{1}{c|}{67113} & \multicolumn{1}{c|}{65453} & 97.52\% &  &  \\ \cmidrule(r){1-3}
\multicolumn{1}{c|}{111384} & \multicolumn{1}{c|}{108497} & 97.40\% &  &  \\ \cmidrule(r){1-3} 
&  &                &  & 
\end{tabular}
    \label{tab:vlm_noise}
\vspace{-1cm}
\end{table}

\subsection{VLM-guided Diffusion Transformers}

\textbf{Normal distribution verification.} To obtain the responses from our VLM module, we iteratively feed the system prompts and the front image of the surrounding cameras per time $t$ to our fine-tuned VLM throughout the training set to perform inference. Based on all the responses obtained, we extract the noise distribution $\sigma_{\text{VLM}}$ from the coordinates $x$ and $y$ of the proposal of the paths by subtracting the corresponding ground truth paths $A_{gt}$. In Table \ref{tab:vlm_noise}, we show that the percentage of paths with normally distributed noise according to the amounts of the proposal of the paths obtained, where the One-Sample Kolmogorov-Smirnov test is used on both $x$ and $y$ coordinates to compare the empirical cumulative distribution function (EDF) of our noise data against the theoretical cumulative distribution function (CDF) of a normal distribution with the same mean and standard deviation as our noise data due to the nonparametric attributes of the Kolmogorov-Smirnov test \cite{Kstest}. Given a path sample $a^0, a^1, \ldots, a^n$, the empirical distribution function (EDF) $F_n(x)$ is defined as

\begin{equation}
    F_n(x) = \frac{1}{n} \sum_{i=1}^{n} I(a^i \leq x),
\end{equation}
where $I(\cdot)$ is the indicator function that equals 1 if the condition inside is true and 0 otherwise.

The Kolmogorov-Smirnov distribution $D_n$ is defined as the maximum absolute difference between the EDF $F_n(x)$ and the CDF $F(x)$,

\begin{equation}
    D_n = \sup_x |F_n(x) - F(x)|,
\end{equation}
where $\sup$ is the supremum of the set of distances. 

For our path sample $a^0, a^1, \ldots, a^n$, $p$ is defined as the probability that the Kolmogorov distribution $K$ exceeds the calculated $D_n$. If $p$ is below the significance level $\alpha_p$, the path sample does not follow a normal distribution. Setting $\alpha_p = 0.05$, the Kolmogorov distribution $K$ is defined by its cumulative distribution function,

\begin{equation}
    P(K \leq t) = 1 - 2 \sum_{k=1}^{\infty} (-1)^{k-1} e^{-2 k^2 t^2},
\end{equation}
for $t > 0$.

Thus, when $p = \Pr(K > D_n) < \alpha_p$, the noise is considered as being drawn from a normal distribution for both the coordinates $x$ and $y$ of the proposal of the paths. During the verification, we iteratively input the front images from the nuScenes dataset into our fine-tuned VLM to obtain the responses. We then identify the paths with normally distributed noise from these responses, where the normal distribution is verified via One-Sample Kolmogorov-Smirnov test for both the $x$ and $y$ coordinates of the paths. In Table \ref{tab:vlm_noise}, we show the number and percentage of the paths qualified by the Kolmogorov-Smirnov test on both $x$ and $y$ coordinates across different samples from the responses obtained.

\textbf{Diffusion process.} Based on the DDIM scheduler \cite{song2020ddim}, we gradually add the sampled noise from the VLM to the ground truth nuScenes path $A_{gt}$ in a forward diffusion process as follows, 
\begin{equation}
    a^{i'} = \sqrt{\bar{\alpha}^i}{a}_{gt}^0 + \sqrt{1-\bar{\alpha}^i}\boldsymbol{\epsilon}, \quad \boldsymbol{\epsilon} \sim \sigma_{\text{VLM}},
\end{equation}
where $a^{i'}$ is the noised sample at scheduler timestep $i$. $\boldsymbol{\epsilon}$ is the sampled noise from $\sigma_{\text{VLM}}$. $\beta^t$ is the sequence of variances that control the amount of noise added at each diffusion timestep and $\bar{\alpha^i}=\prod_{t=1}^i\alpha^t=\prod_{t=1}^i(1-\beta^t)$. To ensure the stability of our training and unbiased noising, we then standardize the noised path $a^{i'} \in {A'_t}$.

In the reverse diffusion process, our diffusion Transformers $\pi_\theta$ predict the denoised path $A_t$ for each denoising timestep $t_\text{R}$, where the noisy path from the output of our VLM is denoised following the DDIM scheduler. We define the noise scheduler as $\sigma(t_\text{R}) = e^{-t_\text{R}}$. Given the input of the noisy path $A'_t$ and the prediction $A_t$, the denoised path is updated as follows,

\begin{equation}
    A'_t = \left( \frac{\sigma(t_\text{R+1})}{\sigma(t_\text{R})} \right) \cdot A'_t - (e^{-h}-1) \cdot {A_t},
\end{equation}
where $h = t_\text{R+1} - t_\text{R}$ is the denoising time interval.

\begin{table}[]
\caption{Ablation study of our timestep embedding (TSE), cross-attention-based fusion of geometric and contextual embedding (CAF), contextual average pooling (CAP), and BEV feature compression (BFC) on nuScenes validation set.}
\centering
\small{
\begin{tabular}{cccccc}
\hline
\toprule
TSE & CAF & CAP & \multicolumn{1}{c|}{BFC} & \multicolumn{1}{c|}{Avg. L2} & Avg. Collision Rate \\ \hline
\midrule
 \checkmark & \checkmark & \checkmark & \multicolumn{1}{c|}{\checkmark}  & \multicolumn{1}{c|}{0.52}       &    0.21    \\
  & \checkmark & \checkmark & \multicolumn{1}{c|}{\checkmark}  & \multicolumn{1}{c|}{1.08}       &    0.60    \\
 \checkmark & \checkmark &   & \multicolumn{1}{c|}{}  & \multicolumn{1}{c|}{1.21}       &    0.88    \\ \hline
  &  &   &                        &                             &       

\end{tabular}
}
\label{tab:ablation}
\vspace{-0.5cm}
\end{table}

\begin{figure}
    \centering
    \includegraphics[width=0.88\linewidth]{Figs/sdc.png}
    \caption{Our experimental car for the recording of our real-world driving dataset.}
    \label{fig:sdc}
\vspace{-0.5cm}
\end{figure}
