\section{Related Work}
%垃圾邮件发送者通过发送垃圾邮件（也有学者称为虚假新闻或谣言）引导舆论。因此，学术界定义垃圾邮件发送者检测包含两个子任务：短期突发用户检测和长期隐藏用户检测。前者，组合用户短期多个行为识别用户是否为垃圾邮件发送者。这项任务通常定义为垃圾邮件（虚假新闻或谣言）检测。此时，由于用户短期行为较少，因此通常结合传播空间以及GNN主干构建模型。后者，更适合识别长期潜伏的用户。同时，也能兼顾突发用户检测任务。并且，伴随着算力提升，多模态特征挖掘也被结合在这两项子任务中。
\par Spammers guide public opinion by sending spam (also called fake news or rumors by some scholars). Therefore, the academic definition of spammer detection contains two sub-tasks: short-term burst and long-term hidden user detection. In the former, several short-term behaviors of a user are combined to identify whether the user is a spammer or not. This task is usually called spam (fake news or rumor) detection. In this case, the model is usually constructed by combining the spread space and the GNN backbone because the user has fewer short-term behaviors. The latter is more suitable for identifying long-term potential users. Meanwhile, it can also consider the task of sudden user detection. Moreover, with the arithmetic power improvement, multi-modal feature mining is combined in these two sub-tasks.
%基于图主干的模型：社会传播过程通常以图为载体。因此，基于图的神经网络模型被广泛用于当前任务。例如，Bian 等人使用自上而下和自下而上的双向图卷积模型来解决虚假信息识别任务。随后，Wei 等人在 Bian 等人的基础上引入了随机化理论。结果，这一策略大大增强了基于图神经网络的虚假信息识别模型的普适性。同时，结合马尔可夫场的GNN主干也被应用在虚假信息制造者检测任务中。实时证明，基于GNN的模型在识别精度上已经达到了几乎不可被超越的表现。然而，随着用户历史行为增加，即识别长期隐藏的垃圾邮件发送者时，基于GNN的模型需要消耗大量GPU内存去推导可疑行为。由于每日社交行为数量数以亿计，所以构建模型是不得不考虑GPU内存问题。最好是可以在消费级GPU上能够运行。因此，在超长历史行为序列为背景的潜伏式垃圾邮件发送者检测任务中，GNN骨干网络不是最有效的。
\par \textbf{GNN Backbone-Based Models:} Social diffusion processes are usually carried out in graphs. Therefore, GNN-based models are popularly used for the task at hand. For instance, Bian et al.____ used top-down and bottom-up bi-directional GCN models to solve the task of fake news recognition. Subsequently, Wei et al.____ introduced randomization theory based on Bian et al. Consequently, this strategy dramatically enhances the generalizability of the fake news recognition model. Meanwhile, the GNN backbone incorporating Markov fields____ was also applied to the task of fake maker detection. It has been proven that the GNN-based model has reached an almost unsurpassable performance in terms of recognition accuracy. However, as the historical user behavior increases, i.e., when identifying long-hidden spammers, the GNN-based model consumes a large amount of GPU memory to derive suspicious behaviors. With hundreds of millions of social behaviors every day, models must be built with GPU memory in mind and ideally run on consumer GPUs. Therefore, the GNN backbone is not the most effective in latent spammer detection against the background of ultra-long historical behavioral sequences.
%基于序列的模型：社交网络传播空间包含图结构和时序信息。因此，部分研究人员尝试采用序列建模策略构建检测模型。Yang 等人结合时间特征构建了基于情感熵的传播语音。随后，借助音频分类技术识别虚假信息。同样，Ma 等人提出了一种基于时间特征的传播响应信息建模策略，并借助 RNN（循环神经网络）识别了虚假信息。随后，Ma 等人在 TD-RvNNcite的基础上构建了一个 GAN（生成对抗网络）式模型。其中，Transformer 模型被用来对时间传播序列进行建模，并将其用作生成器。随后，引入 RNN 模型作为判别器来识别虚假信息。此时，作者主要解决短期行为衍生的传播空间建模任务。因此，他们使用了支持512tokens的NLP领域成熟Transformer架构。他们的模型在面临超长用户序列时将超过512tokens的行为删除。同时，时序传播图也被应用。例如，Sun 等人基于图卷积神经网络模型挖掘了传播子空间的结构信息。随后，基于时态特征构建了平展子空间结构特征的双向融合策略。他们同样没有解决消费级GPU平台训练和部署时序GNN主干网络。
\par \textbf{Sequence-Based Models:} Social network spread space contains graph structure and temporal sequence information. Therefore, some researchers try constructing a detection model using a sequence modeling strategy. By combining temporal features, Yang et al.____ constructed a spreading audio based on emotional entropy. Subsequently, fake news is recognized with the help of audio classification techniques. Similarly, Ma et al.____ proposed a temporal feature-based modeling strategy for propagated response information and identified the fake news with the help of RNN (Recurrent Neural Network). Subsequently, Ma et al.____ constructed a GAN (Generative Adversarial Network) style model based on TD-RvNN____. In this case, the Transformer model is used to model time-propagated sequences, and it is used as a generator. Subsequently, the RNN model is introduced as a discriminator to identify fake news. At this point, the authors mainly address modeling the short-term behavior-derived spread space. Therefore, they used the well-established Transformer architecture of the NLP domain that supports 512 tokens. Their model removes behaviors exceeding 512 tokens when confronted with ultra-long user sequences. Meanwhile, temporal spreading graphs were also applied. For instance, Sun et al.____ mined the structural information of the propagation subspace based on GCN models. Subsequently, a bidirectional fusion strategy for structural features of the spread subspace was constructed based on temporal features. They did not address the training and deployment of temporal GNN backbone networks on consumer GPU platforms.
%结合多模态的模型：随着计算机和通信技术快速发展，在线社交行为已经不局限于文本模型。因此，多模态数据挖掘与跨模态对齐成为当前研究的热点。在短期突发检测任务中，研究人员已经聚焦于多模态领域展开研究。例如，Wang等人引入对抗学习对齐跨模态特征。Zhang等人引入强化学习策略学习跨模态特征。然而，在长期隐藏用户检测子任务中，多模态特征并灭有被广泛使用。例如，Qu等人考虑使用多模态建模策略。但是，他们仅仅是将文本转化为三个通道的类似视觉信息，而并非真正的多模态数据。为此，我们从学列建模角度构建了多模态的垃圾邮件发送者建模通用骨干，称为MS$^2$Dformer。首先，使用多模态变分自编码构建双通道特征挖掘与对齐。随后，基于层次分割窗口注意力机制深度量化序列特征。结合掩码机制，MS$^2$Dformer在两个子任务中均表现极佳，证明了它作为垃圾邮件发送者检测任务通用骨干的潜力。
\par \textbf{Multi-Modal Models:} With the rapid development of computer and communication technologies, online social behaviors are no longer limited to text models. Therefore, multi-modal data mining and cross-modal alignment have become a hot topic in current research. In short-term burst detection, researchers have focused on the multi-modal domain. For instance, Wang et al.____ introduced adversarial learning to align cross-modal features. Zhang et al.____ introduced a reinforcement learning strategy to learn cross-modal features. However, multi-modal features have not been widely used in the long-term hidden user detection sub-task. For instance, Qu et al.____ considered using a multi-modal modeling strategy. However, they only transformed the text into three channels of similar visual information, not accurate multi-modal data. To this end, we construct a generalized backbone for multi-modal spammer detection, called MS$^2$Dformer, from a sequence modeling perspective. Firstly, two-channel feature mining and alignment are constructed using multi-modal variational auto-encoding. Subsequently, sequence features are deeply quantified based on a hierarchical split-window attention mechanism.