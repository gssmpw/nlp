\begin{figure*}[t]
    \centering
    % placeholder
    \includegraphics[width=1\linewidth]{figs_images/task_rep.pdf}
    \caption{\textbf{Task and Policy Representation Experiments.} 
    We compute the average log likelihood of all outcomes under probability distribution represented by the predicted population parameters across various policy and task representations. We evaluate these methods over the HAMSTER, OpenVLA, and MetaWorld Checkpoints offline evaluation datasets over \textcolor{mypink}{continuous} and \textcolor{mygold}{binary} performance distributions.
    We find no large difference between random or optimal embeddings as a policy representation, indicating that there is not much shared information between policies.
    However, we find that for task representation, \textcolor{optimal}{\textbf{Optimal}} consistently perform the best, followed by \textcolor{verb}{\textbf{Verb}}, then \textcolor{lang}{\textbf{Lang}}, and lastly \textcolor{random}{\textbf{Random}}.
    Language-based embeddings is a good task representation that we can leverage for better active learning.
    % We find that optimal embeddings for tasks and policies perform the best, while random embeddings perform the worst. 
    % We find that language embeddings perform better as a task representation than random embeddings as it gets closer to the rate at which optimal embeddings improve.
    % \vspace{-1em}
    }
    \label{fig:model_exps}
\end{figure*}

