\section{Introduction}

% TODO: depending on how well language helps, we can maybe fron tthat intuition at the beginning of the paper.
With the growth of large-scale robot datasets and pretrained policies, robot systems have become capable of achieving good performance across many tasks; however, this diversity makes evaluating these policies increasingly more difficult.
% As these robots become more capable across a large number of tasks, the evaluating these robot policies become difficult, as these policies are trained on large datasets with dozens of tasks. 
% However, as robots become increasingly proficient in handling a diverse set of tasks, evaluating these policies becomes increasingly complex. 
Unlike fields such as computer vision or natural language processing, physical robotics experiments are conducted sequentially, with each policy rollout taking experimenter effort.
Considering the effort to change task setups, it becomes impractical to evaluate every policy on every task.

In practice, experimenters are typically interested in selecting the best checkpoints, tuning hyperparameters, or comparing model architectures, which do not necessarily require a full evaluation across every policy across every task.
A robot policy that can ``pick up an apple" is likely capable of ``picking up an orange" for an analogous scene.
Our insight is to take advantage of relationships between tasks and frame evaluation as a population parameter estimation problem, which lets us design more efficient experiment sampling strategies.
% We can then use these relationships to efficiently select experiments that have the least cost to 

% Roboots are getting getting more capable in the tasks they can do.
% Octo claims XYZ tasks, OpenVLA claims XYZ tasks. The datasets have XYZ tasks.
Manipulation~\cite{octo_2023, kim24openvla, black2024pi_0} and navigation~\cite{shah2023lm,shah2023vint,anwar2024remembr} approaches continue to improve.
% constantly being improved upon; however, as new methods become increasingly capable in accomplishing tasks, the evaluation of all these methods across tasks become difficult.
Simulation-based evaluation has become a common approach to measure that improvement~\cite{simpler_env}, but simulation has often been insufficient for understanding real-world performance~\cite{anderson2021sim,deitke2020robothor,simpler_env}.
% While simulation has become a common approach to evaluating language-guided policies ~\cite{simpler_env, shridhar2020alfred, mees2022calvin, anderson2018vision}, it is often insufficient for understanding real-world performance~\cite{anderson2021sim, deitke2020robothor, simpler_env}.
% However, evaluating robots in the physical world is challenging due to this large domain of tasks in their training set and the need to test multiple policies. 
The combinatorial growth of tasks with scene complexity makes an exhaustive evaluation even more impractical.
As such, there is a need for efficient evaluation strategies that can enable systematic and scalable testing of multi-task robot policies in the real world. 


% In practice, experimenters are often interested in identifying the best and worst policies, which can help in selecting checkpoints, tuning hyperparameters, or comparing model architectures.
% In this work, we propose an efficient evaluation strategy that takes advantage of relationships between tasks and policies by framing the problem as a matrix completion problem.
\input{figs_tex/teaser_fig}
% Novelty 1. We learn a surrogate model to estimate the distribution of parameters
When evaluating a robot policy, it is common to consider only the mean of some metric.
However, since robot performance often has high variance, we instead consider the evaluation of a policy on a specific task as a distribution of outcomes.
% Instead, we consider the evaluation of a policy on a specific task as a distribution of outcomes, as 
% Thus, every policy-task pair is defined by a random variable with parameters such as $\mu, \sigma$ for a Gaussian distribution.
Thus, every policy-task pair is characterized by a distribution reflecting the experiment conditions, for example a Bernoulli distribution for binary success or a Gaussian distribution for a reward outcome.
In this work, as an experimenter conducts evaluations sequentially, we learn a surrogate model that estimates the parameters for this distribution for every policy-task pair under consideration.

% Novelty 2. We show that across tasks, there is shared information that can be leveraged to better estimate the parameters of the distribution.
To build an efficient evaluation strategy, we take advantage of latent shared structure between tasks. 
% Intuitively, a robot that can ``pick up an apple" is likely capable of ``picking up an orange".
% Thus, it is \textit{likely} that an experimenter would not have to evaluate both tasks, which would save effort.
As we sample new experiments, we learn a surrogate model conditioned on latent task and policy embeddings. 
We show that better representations of a policy and a task, including language-based priors for tasks, improves estimates of the outcome distributions, indicating that there is shared information between tasks and policies learnable from policy performance.

% Novelty 3. We can use the surrogate model to actively sample experiments in a way that is cost effective for the experimenter.
Since evaluation is expensive, we want to minimize the cost of evaluation while still estimating the performance of all policies across all tasks of interest.
Then, with our surrogate model, we leverage strategies from the active learning literature to integrate cost-efficient sampling heuristics like expected information gain.
We show that our approach is able to efficiently estimate the performance of robot policies across tasks.





In particular, we:
\begin{itemize}
% \begin{itemize}[nosep,leftmargin=*] %[noitemsep,topsep=0pt]
    % \item We propose several key desiderata for VLN evaluation methods that encourage targeted evaluation of the linguistic and visual capabilities of physical ground robots without the need for dramatic physical costs required to make simulations-sized test sets
    \item formalize multi-task robot policy evaluation as a population parameter estimation problem;
    \item find that there are performance relationships between tasks for estimating the performance of a policy-task pair;
    \item create an active testing protocol that leverages these performance relationships between tasks and policies, allowing us to efficiently evaluate multiple robot policies;
    \item and create cost-aware sampling strategies that can estimate the performance of robot policies with lower cost.
    % \item design an approach to estimate the performance of robot policies on unseen test instances;
    % \item leverage the low-rank structure of robot policy outcomes to efficiently estimate the performance of unseen robot policies by learning task and policy embeddings over time;
\end{itemize}