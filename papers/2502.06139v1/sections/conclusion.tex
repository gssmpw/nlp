\section{Conclusion}
We propose Long-form Context Injection with Recurrent Compression (LCIRC) to address challenges LLMs face with extended inputs. LCIRC efficiently compresses long-form contexts, expanding context length while reducing computational overhead. By incorporating query dependent context modeling, it selectively retains relevant information, improving performance in tasks requiring long-context comprehension and query relevance. Our experiments demonstrate significant advancements in both areas. Future work will focus on extending LCIRC to multilingual settings to integrate context across diverse languages and cultures.

