In this paper, we present an enterprise implementation for incremental KG construction. Our method incrementally builds the KG, improving the precision of entity and relation extraction while addressing challenges such as deduplication and provenance. We also demonstrate how our KG-RAG based retriever can be integrated with an LLM to provide more accurate and contextually relevant answers to user queries. Initial evaluations demonstrate that our method significantly improves performance over the existing production baseline by reducing \textit{irrelevant} answers by more than 50\% and increasing \textit{fully relevant} answers by 88\%, based on a manually annotated dataset. Additionally, an average cosine similarity of 0.89 was observed between \textit{fully relevan}t answers produced by the baseline system and those generated by the KG-RAG-based system. These findings highlight the effectiveness of our approach and provide a promising framework for leveraging KGs containing verified, up-to-date facts from documents that may not have been part of the LLM's pretraining data. This KG-RAG retrieval system represents one component of the broader Adobe AI Assistant, which integrates additional features to further enhance response relevance and the overall user experience.