\begin{figure}[h]
    
    \includegraphics[width=0.45\textwidth]{chat.png} 
    % \vspace{-0.5em}
    \caption{Example of AI assistant generating a response saying that it is out of scope}
     \vspace{-1.5em}
    \label{fig:chat}
    
\end{figure}

Modern enterprises face a critical challenge: making their vast repositories of proprietary documentation and knowledge accessible to employees and customers. As organizations grow, they accumulate thousands of documents, including product specifications, user guides, internal processes, and customer support materials, all of which evolve over time. This institutional knowledge is valuable but often remains underutilized due to difficulties in quick and accurate information retrieval.





Consider a typical enterprise scenario: A customer support agent needs to quickly find specific information about a product feature, or a new employee needs to understand complex internal processes. Traditional search methods often fall short, returning either too many results or missing crucial contextual connections. This challenge is particularly acute in technology companies where product documentation is extensive and frequently updated.


The Adobe Experience Platform (AEP) is a customer data management and analytics solution that aggregates and analyzes data across various touchpoints. Integrated within AEP, the AI Assistant is a generative AI tool designed to assist users by providing insights into product functionality, operational data, and key business objects. Users interact with the AI Assistant by clicking on an icon in the upper right corner of the AEP user interface, which opens a right rail screen with a text box for entering prompts. While the AI Assistant aims to enhance productivity and support efficient navigation, the platformâ€™s documentation spans over 17,000 pages, making it increasingly complex for users to locate precise and relevant information. Additionally, existing search systems lack semantic understanding, reducing their effectiveness for users seeking nuanced, contextually linked knowledge.

% The Adobe Experience Platform (AEP) exemplifies these challenges. As a comprehensive customer data management and analytics solution, AEP enables organizations to aggregate and process customer data from multiple sources, create detailed customer segments for targeted marketing, deliver personalized experiences in real-time and analyze customer journeys across touchpoints. However, with over 17,000 documentation pages covering these capabilities, helping users find precise information efficiently has become increasingly complex. Traditional search systems struggle to understand context and often miss important semantic connections between related concepts.

\begin{figure*}[h]
    
    \includegraphics[width=0.9\textwidth]{pipeline.pdf} 
     \vspace{-1em}
    \caption{End-to-end pipeline for Knowledge Graph-based Retrieval-Augmented Generation (KG-RAG).}
     \vspace{-1em}
    \label{fig:kg_pipeline}
\end{figure*}

Large Language Models (LLMs) have become a promising solution for natural language interaction with enterprise knowledge bases, excelling at understanding user queries and generating human-like responses\cite{caldarini2022literature}. However, they face two key limitations in enterprise settings: first, LLMs trained on public data cannot access proprietary, organization-specific knowledge outside their training data; second,  without verified enterprise information, they may generate plausible but incorrect responses due to hallucination, potentially leading to confusion or errors in decision-making for unfamiliar users relying on these responses.


To address these limitations, Retrieval-Augmented Generation (RAG) has emerged as a paradigm that enhances LLMs by incorporating external knowledge sources at inference time \cite{gao2023retrieval}. However, current RAG implementations primarily rely on simple vector similarity search, which can miss important semantic relationships in complex enterprise documentation. Recent approaches also incorporate structured Knowledge Graphs (KGs) to improve semantic retrieval \cite{edge2024local}. However, KGs constructed using these techniques are often inconsistent and noisy due to unresolved and semantically duplicated entities and relations\cite{carta2023iterative}. These issues can reduce efficiency and accuracy, particularly in large-scale enterprise applications. In our work, we construct the KG incrementally, along with other techniques, to reduce noise, enabling more precise and contextually aware information retrieval for our AI Assistant.

The key contributions of our work include:
\begin{itemize}[noitemsep,topsep=0pt]
 
    \item A scalable pipeline for constructing enterprise KG incrementally from large document collections
    \item Novel techniques for maintaining graph quality through confidence scoring and semantic deduplication
    \item An integrated RAG system that leverages graph structure for improved response accuracy
    \item Empirical evaluation showing over 50\% reduction in irrelevant responses compared to traditional approaches
\end{itemize}


In the following sections, we detail our implementation approach (Section 2), evaluation methodology (Section 3), and results and discussion (Section 4), followed by a discussion of related work (Section 5) and conclusions (Section 6).
