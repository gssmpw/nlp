\section{Instro}

AI assistants have become ubiquitous in today's digital world, playing a vital role in information retrieval, question-answering, and performing various other automated tasks. These AI systems, such as chat-bots rely heavily on natural language processing (NLP) to understand and respond to user queries. Despite recent advancements in NLP, AI assistants still struggle with providing accurate and contextually appropriate answers, particularly when dealing with unstructured and ambiguous data sources. The performance of AI systems degrades when they face queries that require complex contextual understanding or involve domain-specific knowledge.

 Unstructured data, which lacks predefined structure or format, poses a significant challenge in this regard. Most information available on the web, in documents, or in user-generated content is unstructured, making it difficult for AI assistants to process and retrieve the correct answers. For instance, when a user asks an AI assistant to ``tell me about batch,'' the system might fail to provide the appropriate response if it cannot relate the concept of a "batch" to other relevant terms, such as "segment." This failure stems from the AI's inability to understand the context in which the term ``batch'' is used, leading to either incomplete or irrelevant answers. This gap in contextual understanding can greatly limit the utility of AI assistants in practical applications.

To address these limitations, researchers have proposed the use of structured data representations, such as \emph{Knowledge Graphs} (KGs), to enhance AI systems' performance in information retrieval and reasoning tasks \citep{hogan2021knowledge}. KGs are structured representations of knowledge, where entities (such as concepts, people, or objects) are nodes, and relationships between them are edges. These graphs provide a comprehensive and interconnected view of knowledge, allowing AI systems to better understand and retrieve relevant information by navigating through these relationships.

A key advantage of KGs is their ability to encode semantic relationships between entities, which enables AI systems to reason over the data. This makes KGs particularly useful for improving the accuracy and contextual relevance of AI assistants' responses. For instance, if an AI system is powered by a KG that links ``batch'' to ``segment,'' it can understand that a query about ``batch'' may be related to the broader concept of ``segment'' and retrieve more accurate information accordingly. Moreover, KGs allow for the incorporation of provenance, where the source of each entity and relationship is maintained, providing transparency and trustworthiness in the information provided.

% Despite the promise of KGs, constructing and maintaining them poses significant challenges, especially in dynamic environments where new knowledge is continuously being generated. Traditional knowledge graph construction methods rely on manual curation or supervised learning techniques, which require substantial human effort and are not scalable. Additionally, these methods often depend on predefined ontologies and entity types, limiting their ability to generalize across different domains or adapt to new information \citep{hogan2021knowledge, singh2018kg}. 

% Recent advances in NLP, particularly with the advent of large language models (LLMs) such as GPT-3 and BERT, have opened new avenues for automatic knowledge graph construction. LLMs have demonstrated impressive capabilities in zero-shot and few-shot learning, making it possible to extract entities and relationships from text without extensive labeled data \citep{brown2020gpt}. These models can leverage vast amounts of unstructured text to build KGs incrementally, resolving entities and relations in real-time as new data becomes available. This paper builds on these advancements by proposing a method that utilizes LLMs to construct KGs in a scalable and flexible manner, with the ability to provide provenance and confidence measures for each extracted relationship.

% In this work, we aim to improve the accuracy of AI assistants by integrating Knowledge Graphs constructed using LLMs. Our method incrementally builds KGs from a seed concept, ensuring that the KG grows in a controlled manner, avoiding duplication of entities and relationships. We also incorporate confidence levels for each relation to indicate the reliability of the extracted knowledge, and maintain provenance by linking each relationship back to the original text source. Through this structured approach, AI assistants can retrieve more accurate, contextually relevant information, improving the overall user experience.

% The remainder of this paper is organized as follows: Section 2 presents the problem in detail, highlighting the specific challenges faced by AI systems in understanding context. Section 3 introduces our proposed solution and details the process of KG construction using LLMs. In Section 4, we describe the evaluation process and discuss the results, demonstrating the effectiveness of our approach. Finally, in Section 5, we explore future directions for expanding this work, followed by the conclusion in Section 6.


\section{Problem Statement}

AI assistants, powered by Natural Language Processing (NLP) systems, have grown increasingly popular due to their ability to interact with users, retrieve information, and assist in various tasks. However, a significant limitation of current AI systems is their frequent inability to understand and process user queries in a way that provides relevant and contextually accurate responses. This issue arises primarily from two challenges: the reliance on unstructured data and the lack of deep contextual understanding.

\subsection{Challenges with Unstructured Data}

The vast majority of data available on the internet, in documents, and user-generated content is unstructured \citep{frank2020nlp}. Unstructured data does not adhere to a predefined format, making it difficult for AI systems to extract meaning and retrieve the relevant information. Examples of unstructured data include plain text, web pages, and social media posts. AI assistants often struggle to parse this type of data, as it does not follow a strict schema or organizational structure.

Consider a typical user query, such as:
\begin{quote}
    \textbf{Q}: Tell me about batch.
\end{quote}
In this case, the term “batch” could have multiple meanings depending on the context. It could refer to batch processing in computing, a batch of products in manufacturing, or a batch of students in an educational setting. Without structured knowledge or the ability to infer context, the AI assistant may provide an answer that is either irrelevant or incomplete. For instance, the assistant might respond with information about a batch of products when the user was asking about batch processing in computing. This is a direct result of the system's failure to properly disambiguate the term and understand the user's intent.

\subsection{Context Misinterpretation}

A critical limitation of current AI assistants is their inability to grasp the full context of a query, especially when the query involves domain-specific knowledge or requires drawing connections between related concepts. AI systems often operate on predefined patterns or shallow statistical correlations between words, leading to misinterpretation of queries that require deeper semantic understanding. This results in irrelevant or incomplete answers.

For instance, when a user asks about a “batch” in relation to “segments” (as in batch processing involving segments of data), an AI assistant may fail to make this connection if it does not understand the underlying relationship between these terms. This is because most AI systems do not have a structured representation of concepts and their relationships. Instead, they rely on surface-level keyword matching or statistical correlations, which are insufficient for providing nuanced, contextually accurate responses.

The absence of structured knowledge exacerbates this problem. AI assistants typically rely on large language models (LLMs) that generate responses based on vast amounts of text data. However, these models may not have the necessary structure to understand the relationships between different concepts or terms in a way that aligns with user expectations. This often leads to situations where AI assistants provide answers that are out of scope or irrelevant, especially when dealing with complex, multi-part queries or domain-specific terms.

\subsection{Inaccurate Information Retrieval}

Another common issue is that AI assistants often retrieve information that is inaccurate or irrelevant due to their inability to identify the correct relationships between entities in unstructured text. For example, the query:
\begin{quote}
    \textbf{Q}: What is the relationship between batch processing and segment processing?
\end{quote}
Without a structured representation of the terms "batch processing" and "segment processing" and the relationships between them, the AI system may return information on either term independently, without addressing the relationship between them. This is because the model does not have the semantic framework to associate these two terms in a meaningful way.

This inability to connect related concepts results in incomplete answers. Users expect AI assistants to draw on their vast knowledge to provide holistic responses, but this is hindered by the AI’s lack of structured knowledge representations. As a result, users are often forced to rephrase their queries or manually sift through information to find the relevant connections, which undermines the effectiveness of AI assistants as tools for quick and accurate information retrieval.

\subsection{Lack of Provenance and Confidence in Responses}

Another problem with current AI systems is the lack of transparency regarding the source of information and the confidence in the relationships that are identified between entities. In many cases, users have no way of knowing where the AI assistant retrieved a particular piece of information from, or how confident the system is in the correctness of the information. This lack of provenance makes it difficult to trust the assistant’s responses, especially when users are dealing with critical or domain-specific knowledge.

Furthermore, AI systems often lack mechanisms for indicating how certain they are about the relationships they identify between entities in a query. For example, if the system identifies a relationship between "batch processing" and "segment processing," it may not be able to indicate whether this relationship is strong or weak, based on the underlying data. This ambiguity in response quality can lead to user dissatisfaction, as they have no way of gauging the reliability of the information provided.

\subsection{Existing Solutions and Their Limitations}

Traditional approaches to improving AI systems’ accuracy in information retrieval include the use of rule-based systems or manually curated knowledge bases. While these methods can provide more structured information, they are not scalable and often require extensive human involvement in curating and updating the knowledge base. Additionally, these systems may not generalize well across different domains, as they rely on predefined ontologies and entity types, which limit their adaptability to new or evolving knowledge.

Machine learning approaches, such as named entity recognition (NER) and relation extraction, have also been used to automate the process of structuring knowledge from unstructured data \citep{nasar2021named}. However, these methods have their own limitations, such as the requirement for large amounts of annotated training data and their reliance on fixed ontologies, which make it difficult to handle new entities or relationships not seen during training. Moreover, many of these systems struggle with entity resolution—identifying when different terms refer to the same underlying concept—which leads to inconsistent and fragmented knowledge representations.

\subsection{Summary of the Problem}

In summary, AI assistants currently face significant challenges in delivering accurate and context-aware responses due to:
\begin{itemize}
    \item Their reliance on unstructured data, which makes it difficult to extract meaningful knowledge.
    \item Their inability to understand the full context of queries, particularly when the queries involve ambiguous or domain-specific terms.
    \item Their failure to identify relevant relationships between concepts in a way that is useful to the user.
    \item The lack of provenance and confidence indicators in the information they provide.
    \item The limitations of existing solutions, which either rely on manual curation or require large amounts of labeled data and predefined ontologies.
\end{itemize}

These challenges underscore the need for a new approach to enhancing AI assistants' ability to retrieve and present knowledge accurately. This paper proposes the use of incremental Knowledge Graphs (KGs) to address these issues, leveraging large language models to automatically extract entities and relations while maintaining provenance and confidence measures for each connection. By doing so, we aim to improve the accuracy, relevance, and trustworthiness of AI assistants’ responses.


\section{Proposed Solution}

A graph \( G \) can be described as \( G = (E, R) \), where \( E \) represents the collection of nodes (entities) and \( R \) denotes the set of edges (relations). Let \( e_i \) and \( e_j \) be two distinct entities in \( E \), and \( r_k \) and \( r_l \) be two distinct relations in \( R \). To improve the quality of the KG constructed, we impose a constraint that no two entities or relations are semantically identical. Specifically, the following condition must hold:

\begin{equation}
    \forall e_i, e_j \in E, \; i \neq j \quad \text{and} \quad \forall r_k, r_l \in R, \; k \neq l \tag{1}
\end{equation}

This ensures that all entities in the set \( E \) and all relations in the set \( R \) are semantically unique, meaning that no two distinct entities or relations can be identical. In other words, for any two entities \( e_i \) and \( e_j \) in \( E \), \( e_i \neq e_j \), and for any two relations \( r_k \) and \( r_l \) in \( R \), \( r_k \neq r_l \).









To address the challenges outlined in the previous section, we propose a solution based on the construction and integration of Knowledge Graphs (KGs) into AI assistants. KGs offer a structured way of representing knowledge by linking entities through relationships, providing a semantic context that improves the AI's ability to retrieve accurate, contextually relevant information. Our approach leverages large language models (LLMs) to automate the extraction of entities and relationships from unstructured data, enabling incremental construction of the KG. This process not only enhances information retrieval but also maintains provenance and assigns confidence scores to the extracted relationships, ensuring the reliability and transparency of the responses provided by the AI assistant.

\subsection{Knowledge Graphs: An Overview}

A Knowledge Graph (KG) is a structured representation of knowledge, where entities (nodes) are linked by relationships (edges). Each entity can represent a concept, object, or person, while the relationships capture the interactions or associations between these entities. This structured format enables AI systems to navigate complex relationships, improving their understanding of context and helping them infer new information by connecting related entities.

For example, in a KG, the entity “batch processing” may be connected to “segment processing” through a relationship labeled “related to.” This connection allows an AI assistant to understand that a query about batch processing might involve segment processing, leading to more accurate and comprehensive responses.

The core advantages of KGs in enhancing AI assistant performance are:
\begin{itemize}
    \item \textbf{Contextual Understanding}: KGs capture semantic relationships between entities, allowing AI systems to interpret queries more accurately by leveraging these connections.
    \item \textbf{Provenance}: Every entity and relationship in the KG is linked to its source, providing transparency and trustworthiness.
    \item \textbf{Confidence Scoring}: Relationships are assigned confidence levels, indicating how strongly the model believes in the existence of a particular relationship, based on the source text.
    \item \textbf{Scalability}: The KG is constructed incrementally, enabling it to grow as more data is processed, without needing to rebuild the entire graph from scratch.
\end{itemize}

\subsection{Incremental KG Construction Using Large Language Models}

Our approach for KG construction is incremental and automated, driven by LLMs. The incremental nature of this solution allows the KG to expand gradually as more documents are processed, avoiding the problem of duplication of entities and relationships. Additionally, this method enables continuous updates and adaptation as new knowledge is introduced. The key steps in our methodology are outlined below.

\subsubsection{Seed Concept and Entity Discovery}

The process begins with a seed concept, which acts as the starting point for KG construction. This seed concept is chosen based on the domain of interest or the user's query. For instance, if the user queries about "batch processing," this concept will serve as the seed, and the KG will expand by discovering related concepts such as "segment processing," "data pipelines," and "job scheduling."

Once the seed concept is established, we use LLMs to extract relevant entities from unstructured documents. The LLMs are prompted to identify key concepts related to the seed, leveraging their ability to understand natural language and extract semantic information. This process results in the discovery of a set of initial entities that are directly related to the seed concept.

\subsubsection{Relation Extraction and Confidence Scoring}

After discovering the entities, the next step is to identify the relationships between them. Relationships are crucial for capturing the semantic context within the KG, as they define how entities are interconnected. For example, the relationship between “batch processing” and “segment processing” might be labeled as “is part of” or “relates to.”

Using the same LLM-based approach, we extract relationships from the documents by analyzing how the entities interact within the text. The model is designed to capture both explicit relationships (stated directly in the text) and implicit relationships (inferred from the context). Once the relationships are identified, each one is assigned a confidence score, which reflects the model's certainty in the existence of that relationship. Confidence scores are essential for distinguishing between strong and weak relationships, helping the AI assistant prioritize the most reliable information.

\subsubsection{Provenance and Transparency}

To ensure the reliability and transparency of the KG, we maintain provenance for each entity and relationship. Provenance links each piece of information to the specific document or text source from which it was extracted. This allows users to trace back the origin of any piece of knowledge within the KG, making it easier to verify the accuracy of the information provided by the AI assistant.

For example, if a relationship between "batch processing" and "segment processing" is extracted from a technical paper, the KG will store a reference to that paper alongside the relationship. This reference allows the AI system to inform the user about where the information came from, thus improving the trustworthiness of the assistant's responses.

\subsubsection{Preventing Duplication and Semantic Overlap}

A significant challenge in KG construction is the risk of duplicating entities or relationships, which can lead to a fragmented or inconsistent graph. To avoid this, our method employs entity resolution techniques that ensure each entity in the KG is unique. As new documents are processed, entities and relationships are compared with existing entries in the KG. If a new entity is found to be semantically equivalent to an existing one, the system merges them, preventing duplication.

For example, if the system encounters both “batch processing” and “batch jobs,” it will recognize that these terms refer to the same concept and merge them into a single entity, labeled appropriately. Similarly, relationships are also checked for overlap and redundancy, ensuring that the KG remains concise and accurate.

\subsubsection{Incremental Expansion}

Our approach to KG construction is incremental, allowing the graph to grow over time as new documents are processed. Instead of building the entire KG at once, which can be computationally expensive and prone to errors, we build it incrementally by adding new entities and relationships as they are discovered. This approach not only reduces the computational cost but also ensures that the KG remains up to date as new knowledge is introduced.

As each new document is processed, the system checks for previously unknown entities and relationships and integrates them into the existing graph. By doing so, the KG continuously evolves and adapts, providing a more comprehensive knowledge base for the AI assistant to draw from.

\subsection{Improved Query Response with Knowledge Graphs}

The integration of KGs into AI assistants enhances the system’s ability to respond to user queries by providing contextually relevant information. When a query is received, the AI assistant can navigate the KG to find the most relevant entities and relationships, resulting in a more accurate and comprehensive response.

For example, if a user queries “How does batch processing work with segment processing?”, the AI assistant can traverse the KG to identify the entities "batch processing" and "segment processing" and retrieve the relationships that explain their connection, such as “is part of” or “relates to.” This structured retrieval process enables the assistant to provide a more nuanced and contextually appropriate answer, avoiding the common pitfalls of keyword-based retrieval systems that may overlook important semantic connections.

Moreover, the provenance feature allows the assistant to explain the origin of the information, giving users more confidence in the accuracy of the response. If necessary, users can trace the information back to the original documents, ensuring transparency and trust in the assistant’s outputs.

\subsection{Benefits of the Proposed Solution}

The proposed KG-based solution offers several key benefits:
\begin{itemize}
    \item \textbf{Increased Accuracy}: By leveraging the structured relationships in the KG, the AI assistant can provide more accurate and contextually relevant answers.
    \item \textbf{Provenance and Transparency}: The system ensures that every piece of information is linked to its original source, allowing users to verify the accuracy of the responses.
    \item \textbf{Confidence Scoring}: Relationships are assigned confidence levels, helping the system prioritize the most reliable information.
    \item \textbf{Scalability and Adaptability}: The incremental nature of KG construction allows the system to continuously evolve as new knowledge is introduced, making it adaptable to a wide range of domains and queries.
    \item \textbf{Reduction in Duplication}: Entity resolution techniques prevent duplication and semantic overlap, ensuring that the KG remains consistent and concise.
\end{itemize}


\section{Methodology}

Our methodology for Knowledge Graph (KG) construction is driven by an incremental and automated approach, using large language models (LLMs) to extract entities and relationships from unstructured data. This section provides an in-depth explanation of each stage involved in the construction of the KG, the incremental nature of the process, and how provenance and confidence measures are integrated. The goal is to build a scalable KG that grows dynamically as new information is introduced, with the ability to handle entity resolution, prevent duplication, and ensure consistency across the graph.

\subsection{Entity and Relation Extraction using Large Language Models}

\subsubsection{Entity Extraction}

The first step in the KG construction process is to extract relevant entities from unstructured text. We use large language models (LLMs) such as GPT or BERT, which have been pre-trained on vast amounts of text data, to identify and extract key entities from documents. Entities are the core building blocks of the KG, representing concepts, objects, or people, and their extraction forms the foundation for constructing relationships between these entities.

Entity extraction is done by prompting the LLM to analyze the input text and identify terms or phrases that correspond to specific concepts relevant to the domain. For example, if we are constructing a KG in the domain of data processing, the LLM would identify entities such as "batch processing," "segment," "data pipeline," and "job scheduling."

This process involves two key mechanisms:
\begin{itemize}
    \item **Named Entity Recognition (NER)**: The LLM uses named entity recognition to automatically detect named entities, such as proper nouns, within the text.
    \item **Contextual Entity Detection**: Beyond traditional NER, the LLM is capable of detecting domain-specific terms and abstract concepts, even when they are not proper nouns, ensuring the discovery of more complex entities related to the query or domain.
\end{itemize}

\subsubsection{Relationship Extraction}

Once the relevant entities have been extracted, the next step is to determine how these entities are related. Relationships between entities form the edges in the KG, and they are crucial for defining the semantic structure of the graph. We prompt the LLM to analyze the context in which these entities appear in the text and infer both explicit and implicit relationships between them.

\textbf{Explicit Relationships}: These are relationships that are directly stated in the text. For instance, in a sentence like “batch processing is a part of data pipelines,” the relationship "is part of" is clearly expressed.

\textbf{Implicit Relationships}: In some cases, relationships are not directly stated but can be inferred based on the context in which entities appear. For example, if “batch processing” and “segment processing” appear frequently together in discussions of parallel computing, the system might infer a relationship such as “is related to.”

To enhance the reliability of the relationships extracted, we assign each relationship a confidence score, reflecting the model’s certainty in the existence of the relationship based on the surrounding context. Confidence scoring helps the system prioritize the most reliable relationships during query responses.

\subsection{Provenance and Confidence Measures}

\subsubsection{Provenance Tracking}

One of the key features of our KG is the ability to maintain provenance for each entity and relationship. Provenance refers to the ability to trace the origin of each piece of information in the KG, ensuring transparency and allowing users to verify the accuracy of the AI assistant’s responses.

For each entity and relationship extracted by the LLM, the system stores a reference to the original document or source from which it was extracted. This reference is embedded within the KG and can be accessed whenever an entity or relationship is queried. Provenance ensures that the system remains trustworthy, as users can easily trace the information back to its source and confirm its validity.

\subsubsection{Confidence Scoring}

Along with provenance, confidence scoring plays a critical role in determining the reliability of the information in the KG. After extracting a relationship between two entities, the LLM assigns a confidence score based on factors such as:
\begin{itemize}
    \item The frequency with which the relationship appears in different documents.
    \item The strength of the contextual signals in the surrounding text.
    \item The directness of the relationship (explicit vs. implicit).
\end{itemize}

These confidence scores are stored as part of the KG and are used by the AI assistant to prioritize highly reliable information when responding to queries. Confidence scores can be adjusted dynamically as new information is added to the KG, allowing the system to improve over time.

\subsection{Incremental KG Construction}

\subsubsection{Seed Concept Initialization}

The KG construction process begins with the identification of a seed concept, which acts as the initial node in the graph. This seed concept is chosen based on the domain of interest or the specific query posed by the user. For example, if a user asks about "batch processing," this concept is designated as the seed, and the KG begins by expanding outward from this initial node.

\subsubsection{Expansion through New Document Integration}

After the seed concept is initialized, the system incrementally expands the KG by processing additional documents and extracting new entities and relationships. Each new document is analyzed by the LLM, which extracts additional entities and relationships, checking for duplication and ensuring that the KG remains semantically consistent.

This incremental approach is particularly advantageous because it allows the KG to grow dynamically over time. As new documents are processed, they introduce new entities and relationships, which are integrated into the existing graph structure. This continuous growth ensures that the KG remains up-to-date and can adapt to evolving knowledge.

\subsubsection{Entity Resolution and Duplication Prevention}

One of the key challenges in KG construction is ensuring that the graph remains consistent and free from duplicated entities or relationships. To address this, our method employs entity resolution techniques that detect when two terms refer to the same underlying concept. When a new entity is extracted, the system compares it with existing entities in the KG to determine whether it is semantically equivalent to any of them.

For example, if the system encounters both “batch jobs” and “batch processing,” it will recognize that these terms refer to the same concept and merge them into a single entity in the KG. Similarly, relationships are checked for redundancy, and if the system detects that two relationships are semantically identical, it merges them to avoid cluttering the graph with duplicate information.

This process ensures that the KG remains concise and semantically accurate, even as it expands incrementally.

\subsection{Evaluation Metrics for KG Quality}

To evaluate the quality of the constructed KG, we employ several key metrics that assess the accuracy, consistency, and scalability of the graph:
\begin{itemize}
    \item \textbf{Entity Extraction Precision}: This metric measures the accuracy of the LLM in correctly identifying entities from the text. We evaluate precision by comparing the extracted entities with a manually curated set of ground-truth entities.
    \item \textbf{Relationship Extraction Precision}: This evaluates the accuracy of the extracted relationships, measuring how well the relationships reflect the true connections between entities in the text.
    \item \textbf{Provenance Completeness}: This metric assesses the completeness of provenance tracking, ensuring that every entity and relationship in the KG is linked to a reliable source.
    \item \textbf{Confidence Score Reliability}: This metric evaluates the reliability of the confidence scores assigned to relationships, ensuring that high-confidence relationships are indeed more accurate than low-confidence ones.
\end{itemize}

These evaluation metrics ensure that the KG is not only comprehensive but also trustworthy and reliable, providing a solid foundation for AI assistants to deliver accurate and context-aware responses.

\subsection{Scalability and Adaptability}

The incremental nature of the KG construction process allows the system to scale effectively as more documents are processed. The system can handle large volumes of data without overwhelming computational resources because it processes documents one at a time, integrating new knowledge gradually into the graph.

Furthermore, the system is adaptable across domains. It is not restricted to a particular ontology or predefined set of entity types, making it flexible enough to handle new domains or queries that may introduce previously unseen concepts. This adaptability is achieved through the use of LLMs, which can generalize across a wide range of topics and extract relevant information from diverse sources.


\section{Evaluation}


The system was evaluated using a set of 956 annotated samples, of which 100 contained the term ``segment.'' We used cosine similarity to compare the embeddings of retrieved documents and query answers, calculated using the \texttt{bert-base-uncased} model from Huggingface \citep{bert}. The average cosine similarity achieved was 0.82, indicating a strong match between the generated answer and the relevant document.

Furthermore, we used an LLM to judge the relevance of the generated responses, resulting in:
\begin{itemize}
    \item A 1.85x increase in fully relevant answers.
    \item A 2.30x decrease in irrelevant answers.
\end{itemize}

\subsection{Cosine Similarity}
The cosine similarity between the embeddings of the question and the retrieved documents was calculated, with an average similarity score of 0.82 for relevant queries.

\subsection{LLM Judgment}
The use of a large language model as a judge showed that after the introduction of the KG, a greater number of answers were marked as fully relevant, while the number of irrelevant answers dropped significantly.

\section{Future Work}
In future iterations of the system, we plan to:
\begin{itemize}
    \item Extend KG construction to all documents, beyond the segment subset.
    \item Use fine-tuned models for embedding generation to improve accuracy further.
    \item Explore top-k retrieval rather than only using the top-1 result for better coverage of potential answers.
\end{itemize}

\section{Conclusion}

The integration of Knowledge Graphs significantly improves AI assistants' ability to provide contextually relevant and accurate responses. By structuring information through entities, relationships, and provenance links, we reduce the misinterpretation of key concepts and improve retrieval accuracy. The combination of cosine similarity and LLM judgments offers a robust framework for evaluating AI responses, leading to substantial improvements in relevancy.

