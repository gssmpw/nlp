% When using LLMs, RAG involves first retrieving relevant information from external data sources, then adding this information to the context window of the LLM along with the original query \cite{ram2023context}. NaÄ±ve RAG approaches \cite{gao2023retrieval} do this by converting documents to text, splitting text into chunks, and embedding these chunks into a vector space in which similar positions represent similar semantics. Queries are then embedded into the same vector space, with the text chunks of the nearest \textit{k} vectors used as context. More advanced variations exist, but all solve the problem of what to do when an external dataset of interest exceeds the LLM's context window.

% Recent advancements in LLMs, which are pre-trained on large text corpora, have significantly impacted NLP research, demonstrating strong performance in tasks like machine translation \cite{xu2024contrastive}, text summarization \cite{jin2024comprehensive}, and question answering \cite{saito2024unsupervised}. Many studies now utilize LLMs for constructing KGs \cite{li2024contextualization}, focusing on tasks such as named entity recognition and classification \cite{li2021span,zhou2023universalner}, relation extraction \cite{jiang2024genres}, and link prediction \cite{shu2024knowledge}.  

% A comprehensive evaluation of LLMs in KG construction and reasoning \cite{zhu2024llms} across eight datasets and four tasks found that while GPT-4 performs well in KG tasks, it outperforms fine-tuned models in reasoning tasks. The paper also introduces AutoKG, a multi-agent approach combining LLMs and external sources for KG construction and reasoning.


LLMs have shown remarkable performance improvements across tasks such as machine translation \cite{xu2024contrastive}, text summarization \cite{jin2024comprehensive}, and question answering \cite{saito2024unsupervised}. However, their limitations in accessing proprietary or dynamically updated data without hallucinating errors remain a significant barrier. Several approaches attempt to mitigate these issues by integrating domain-specific knowledge into language models \cite{agrawal2023can,mukherjee2023stack}.

RAG frameworks have gained traction in combining language models with external knowledge sources\cite{lewis2020retrieval,salemi2024evaluating}. The basic principle involves retrieving relevant data from external documents and integrating it into the context of a language model at inference time. Early implementations of RAG relied on vector similarity search to embed and retrieve text chunks\cite{gao2023retrieval}. These methods improved semantic search efficiency but often struggled with complex reasoning due to the lack of structured data representation.

Recent advancements in leveraging structured Knowledge Graphs (KGs) for RAG have provided promising alternatives. \citeauthor{edge2024local}\cite{edge2024local} introduced a graph-enhanced retrieval mechanism, demonstrating that structured data linked through relationships can significantly improve contextual relevance in query responses. Unlike simple vector-based retrieval, KGs offer explicit semantic connections between concepts, allowing richer contextual augmentation for natural language understanding.


Many studies now utilize LLMs for constructing KGs \cite{li2024contextualization}, focusing on tasks such as named entity recognition and classification \cite{li2021span,zhou2023universalner}, relation extraction \cite{jiang2024genres}. Complementary work by \citeauthor{shu2024knowledge}\cite{shu2024knowledge} highlights the role of LLMs in link prediction and reasoning over KGs, suggesting that hybrid approaches outperform purely generative models.

Our implementation of KG-RAG incorporates several concepts from related systems. For example, \cite{lairgi2024itext2kg} builds the knowledge graph without duplication but lacks features such as confidence scores and provenance. In contrast, \cite{amaral2022prove} includes provenance but does not incorporate the other features, while \cite{edge2024local} assigns confidence scores but also performs community detection on the graph and generates summaries for each community using LLMs. Our work aligns with this trajectory by advancing the integration of knowledge graphs into RAG systems tailored for enterprise documentation. Specifically, we enhance the KG with incremental entity resolution using seed concepts, similarity-based filtering to deduplicate entries, assigning confidence scores to entity-relation pairs to prioritize high-confidence pairs, and linking facts to source documents for provenance.

In terms of evaluation methodologies, \cite{zheng2023judging} emphasize the importance of combining LLM-based judges with other metrics such as cosine similarity for assessing response relevance. While cosine similarity provides a quantitative measure of semantic overlap, LLM evaluators interpret nuanced meanings that static metrics miss. Our evaluation framework adopts a hybrid approach, complementing automated scoring with human-like judgments to balance scalability and interpretive depth.

% This research contributes to a growing body of work advocating for dynamic, context-aware knowledge retrieval in enterprise AI systems. By integrating KGs with advanced LLMs, we demonstrate an effective paradigm for addressing both the scalability and accuracy limitations of traditional LLM deployment