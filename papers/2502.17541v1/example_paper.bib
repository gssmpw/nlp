@article{han2024wildguard,
  title={Wildguard: Open one-stop moderation tools for safety risks, jailbreaks, and refusals of llms},
  author={Han, Seungju and Rao, Kavel and Ettinger, Allyson and Jiang, Liwei and Lin, Bill Yuchen and Lambert, Nathan and Choi, Yejin and Dziri, Nouha},
  journal={arXiv preprint arXiv:2406.18495},
  year={2024}
}

@article{inan2023llama,
  title={Llama guard: Llm-based input-output safeguard for human-ai conversations},
  author={Inan, Hakan and Upasani, Kartikeya and Chi, Jianfeng and Rungta, Rashi and Iyer, Krithika and Mao, Yuning and Tontchev, Michael and Hu, Qing and Fuller, Brian and Testuggine, Davide and others},
  journal={arXiv preprint arXiv:2312.06674},
  year={2023}
}

@article{samvelyan2024rainbow,
  title={Rainbow teaming: Open-ended generation of diverse adversarial prompts},
  author={Samvelyan, Mikayel and Raparthy, Sharath Chandra and Lupu, Andrei and Hambro, Eric and Markosyan, Aram H and Bhatt, Manish and Mao, Yuning and Jiang, Minqi and Parker-Holder, Jack and Foerster, Jakob and others},
  journal={arXiv preprint arXiv:2402.16822},
  year={2024}
}

@article{yu2023gptfuzzer,
  title={Gptfuzzer: Red teaming large language models with auto-generated jailbreak prompts},
  author={Yu, Jiahao and Lin, Xingwei and Yu, Zheng and Xing, Xinyu},
  journal={arXiv preprint arXiv:2309.10253},
  year={2023}
}

@misc{hughes2024bestofnjailbreaking,
      title={Best-of-N Jailbreaking}, 
      author={John Hughes and Sara Price and Aengus Lynch and Rylan Schaeffer and Fazl Barez and Sanmi Koyejo and Henry Sleight and Erik Jones and Ethan Perez and Mrinank Sharma},
      year={2024},
      eprint={2412.03556},
      archivePrefix={arXiv},
      primaryClass={cs.CL},
      url={https://arxiv.org/abs/2412.03556}, 
}

@article{chao2023jailbreaking,
  title={Jailbreaking black box large language models in twenty queries},
  author={Chao, Patrick and Robey, Alexander and Dobriban, Edgar and Hassani, Hamed and Pappas, George J and Wong, Eric},
  journal={arXiv preprint arXiv:2310.08419},
  year={2023}
}

@article{jiang2024wildteaming,
  title={WildTeaming at Scale: From In-the-Wild Jailbreaks to (Adversarially) Safer Language Models},
  author={Jiang, Liwei and Rao, Kavel and Han, Seungju and Ettinger, Allyson and Brahman, Faeze and Kumar, Sachin and Mireshghallah, Niloofar and Lu, Ximing and Sap, Maarten and Choi, Yejin and others},
  journal={arXiv preprint arXiv:2406.18510},
  year={2024}
}

@article{wei2024jailbroken,
  title={Jailbroken: How does llm safety training fail?},
  author={Wei, Alexander and Haghtalab, Nika and Steinhardt, Jacob},
  journal={Advances in Neural Information Processing Systems},
  volume={36},
  year={2024}
}

@article{mazeika2024harmbench,
title={HarmBench: A Standardized Evaluation Framework for Automated Red Teaming and Robust Refusal},
author={Mantas Mazeika and Long Phan and Xuwang Yin and Andy Zou and Zifan Wang and Norman Mu and Elham Sakhaee and Nathaniel Li and Steven Basart and Bo Li and David Forsyth and Dan Hendrycks},
year={2024},
eprint={2402.04249},
archivePrefix={arXiv},
primaryClass={cs.LG}
}

@article{khan2024debating,
  title={Debating with more persuasive llms leads to more truthful answers},
  author={Khan, Akbir and Hughes, John and Valentine, Dan and Ruis, Laura and Sachan, Kshitij and Radhakrishnan, Ansh and Grefenstette, Edward and Bowman, Samuel R and Rockt{\"a}schel, Tim and Perez, Ethan},
  journal={arXiv preprint arXiv:2402.06782},
  year={2024}
}

@article{jiang2023mistral,
  title={Mistral 7B},
  author={Jiang, Albert Q and Sablayrolles, Alexandre and Mensch, Arthur and Bamford, Chris and Chaplot, Devendra Singh and Casas, Diego de las and Bressand, Florian and Lengyel, Gianna and Lample, Guillaume and Saulnier, Lucile and others},
  journal={arXiv preprint arXiv:2310.06825},
  year={2023}
}

@inproceedings{auer2007dbpedia,
  title={Dbpedia: A nucleus for a web of open data},
  author={Auer, S{\"o}ren and Bizer, Christian and Kobilarov, Georgi and Lehmann, Jens and Cyganiak, Richard and Ives, Zachary},
  booktitle={international semantic web conference},
  pages={722--735},
  year={2007},
  organization={Springer}
}

@misc{sandhaus2008nytimes,
  author = {Evan Sandhaus},
  title = {The New York Times Annotated Corpus},
  year = {2008},
  howpublished = {Linguistic Data Consortium, Philadelphia},
  volume = {6},
  number = {12},
  pages = {e26752}
}

@article{hou2024bridging,
  title={Bridging Language and Items for Retrieval and Recommendation},
  author={Hou, Yupeng and Li, Jiacheng and He, Zhankui and Yan, An and Chen, Xiusi and McAuley, Julian},
  journal={arXiv preprint arXiv:2403.03952},
  year={2024}
}

@misc{ouyang2022traininglanguagemodelsfollow,
      title={Training language models to follow instructions with human feedback}, 
      author={Long Ouyang and Jeff Wu and Xu Jiang and Diogo Almeida and Carroll L. Wainwright and Pamela Mishkin and Chong Zhang and Sandhini Agarwal and Katarina Slama and Alex Ray and John Schulman and Jacob Hilton and Fraser Kelton and Luke Miller and Maddie Simens and Amanda Askell and Peter Welinder and Paul Christiano and Jan Leike and Ryan Lowe},
      year={2022},
      url={https://arxiv.org/abs/2203.02155}, 
}

@misc{go2024compositionalpreferencemodelsaligning,
      title={Compositional preference models for aligning LMs}, 
      author={Dongyoung Go and Tomasz Korbak and Germán Kruszewski and Jos Rozen and Marc Dymetman},
      year={2024},
      url={https://arxiv.org/abs/2310.13011}, 
}

@misc{gao2022scalinglawsrewardmodel,
      title={Scaling Laws for Reward Model Overoptimization}, 
      author={Leo Gao and John Schulman and Jacob Hilton},
      year={2022},
      eprint={2210.10760},
      archivePrefix={arXiv},
      primaryClass={cs.LG},
      url={https://arxiv.org/abs/2210.10760}, 
}

@article{findeis2024inverse,
  title={Inverse Constitutional AI: Compressing Preferences into Principles},
  author={Findeis, Arduin and Kaufmann, Timo and H{\"u}llermeier, Eyke and Albanie, Samuel and Mullins, Robert},
  journal={arXiv preprint arXiv:2406.06560},
  year={2024}
}



@inproceedings{dwork2006,
  title        = {Calibrating noise to sensitivity in private data analysis},
  author       = {Dwork, Cynthia and McSherry, Frank and Nissim, Kobbi and Smith, Adam},
  booktitle    = {Theory of Cryptography: Third Theory of Cryptography Conference, TCC 2006},
  pages        = {265--284},
  year         = {2006},
  publisher    = {Springer}
}

@inproceedings{eder2020,
  title        = {{CodE alltag 2.0} — a pseudonymized German-language email corpus},
  author       = {Eder, Elisabeth and Krieg-Holz, Ulrike and Hahn, Udo},
  booktitle    = {Proceedings of the Twelfth Language Resources and Evaluation Conference},
  pages        = {4466--4477},
  year         = {2020},
  address      = {Marseille, France},
  publisher    = {European Language Resources Association}
}

@article{eloundou2024,
  title        = {First-person fairness in chatbots},
  author       = {Eloundou, Tyna and Beutel, Alex and Robinson, David G and Gu-Lemberg, Keren and 
                  Brakman, Anna-Luisa and Mishkin, Pamela and Heidecke, Johannes and Weng, Lilian and 
                  Kalai, Adam Tauman},
  journal      = {arXiv preprint arXiv:2410.19803},
  year         = {2024}
}

@inproceedings{lam2024,
  title        = {Concept induction: Analyzing unstructured text with high-level concepts using lloom},
  author       = {Lam, Michelle S. and Teoh, Janice and Landay, James A. and Heer, Jeffrey and Bernstein, Michael S.},
  booktitle    = {Proceedings of the CHI Conference on Human Factors in Computing Systems (CHI '24)},
  year         = {2024},
  publisher    = {Association for Computing Machinery},
  address      = {New York, NY, USA},
  isbn         = {9798400703300},
  doi          = {10.1145/3613904.3642830},
  url          = {https://doi.org/10.1145/3613904.3642830}
}

@article{tan2024large,
  title={Large Language Models for Data Annotation and Synthesis: A Survey},
  author={Tan, Zhen and Li, Dawei and Wang, Song and Beigi, Alimohammad and Jiang, Bohan and Bhattacharjee, Amrita and Karami, Mansooreh and Li, Jundong and Cheng, Lu and Liu, Huan},
  journal={arXiv preprint arXiv:2402.13446},
  year={2024},
  doi={10.48550/arXiv.2402.13446},
  url={https://doi.org/10.48550/arXiv.2402.13446}
}


@inproceedings{mcmahan2017,
  title        = {Communication-efficient learning of deep networks from decentralized data},
  author       = {McMahan, Brendan and Moore, Eider and Ramage, Daniel and Hampson, Seth and 
                  Aguera y Arcas, Blaise},
  booktitle    = {Artificial intelligence and statistics},
  pages        = {1273--1282},
  year         = {2017},
  organization = {PMLR}
}

@article{mireshghallah2024,
  title        = {{Trust no bot: Discovering personal disclosures in human-LLM conversations in the wild}},
  author       = {Mireshghallah, Niloofar and Antoniak, Maria and More, Yash and Choi, Yejin and Farnadi, Golnoosh},
  journal      = {arXiv preprint arXiv:2407.11438},
  year         = {2024}
}

@inproceedings{russell1993sensemaking,
  title        = {The cost structure of sensemaking},
  author       = {Russell, Daniel M and Stefik, Mark J and Pirolli, Peter and Card, Stuart K},
  booktitle    = {Proceedings of the INTERACT'93 and CHI'93 conference on Human factors in computing systems},
  pages        = {269--276},
  year         = {1993}
}

@inproceedings{stasko2007jigsaw,
  title        = {Jigsaw: supporting investigative analysis through interactive visualization},
  author       = {Stasko, John and Gorg, Carsten and Liu, Zhicheng and Singhal, Kanupriya},
  booktitle    = {2007 IEEE Symposium on Visual Analytics Science and Technology},
  pages        = {131--138},
  year         = {2007},
  organization = {IEEE}
}

@inproceedings{tan1999textmining,
  title        = {Text mining: The state of the art and the challenges},
  author       = {Tan, Ah-Hwee and others},
  booktitle    = {Proceedings of the PAKDD 1999 workshop on knowledge discovery from advanced databases},
  volume       = {8},
  pages        = {65--70},
  year         = {1999}
}


@article{zheng2023lmsys,
  title        = {{Lmsys-chat-1m: A large-scale real-world llm conversation dataset}},
  author       = {Zheng, Lianmin and Chiang, Wei-Lin and Sheng, Ying and Li, Tianle and Zhuang, Siyuan and Wu, Zhanghao and 
                  Zhuang, Yonghao and Li, Zhuohan and Lin, Zi and Xing, Eric P and others},
  journal      = {arXiv preprint arXiv:2309.11998},
  year         = {2023}
}



@misc{chung2022scalinginstructionfinetunedlanguagemodels,
      title={Scaling Instruction-Finetuned Language Models}, 
      author={Hyung Won Chung and Le Hou and Shayne Longpre and Barret Zoph and Yi Tay and William Fedus and Yunxuan Li and Xuezhi Wang and Mostafa Dehghani and Siddhartha Brahma and Albert Webson and Shixiang Shane Gu and Zhuyun Dai and Mirac Suzgun and Xinyun Chen and Aakanksha Chowdhery and Alex Castro-Ros and Marie Pellat and Kevin Robinson and Dasha Valter and Sharan Narang and Gaurav Mishra and Adams Yu and Vincent Zhao and Yanping Huang and Andrew Dai and Hongkun Yu and Slav Petrov and Ed H. Chi and Jeff Dean and Jacob Devlin and Adam Roberts and Denny Zhou and Quoc V. Le and Jason Wei},
      year={2022},
      url={https://arxiv.org/abs/2210.11416}, 
}

@article{li2024exploring,
  title={Exploring large language models for feature selection: A data-centric perspective},
  author={Li, Dawei and Tan, Zhen and Liu, Huan},
  journal={arXiv preprint arXiv:2408.12025},
  year={2024}
}

@article{barros2024large,
  title={Large Language Model for Qualitative Research--A Systematic Mapping Study},
  author={Barros, Cau{\~a} Ferreira and Azevedo, Bruna Borges and Neto, Valdemar Vicente Graciano and Kassab, Mohamad and Kalinowski, Marcos and Nascimento, Hugo Alexandre D do and Bandeira, Michelle CGSP},
  journal={arXiv preprint arXiv:2411.14473},
  year={2024}
}

@article{xu2024ai,
  title={AI for social science and social science of AI: A survey},
  author={Xu, Ruoxi and Sun, Yingfei and Ren, Mengjie and Guo, Shiguang and Pan, Ruotong and Lin, Hongyu and Sun, Le and Han, Xianpei},
  journal={Information Processing \& Management},
  volume={61},
  number={3},
  pages={103665},
  year={2024},
  publisher={Elsevier}
}

@article{korinek2023generative,
  title={Generative AI for economic research: Use cases and implications for economists},
  author={Korinek, Anton},
  journal={Journal of Economic Literature},
  volume={61},
  number={4},
  pages={1281--1317},
  year={2023},
  publisher={American Economic Association 2014 Broadway, Suite 305, Nashville, TN 37203-2425}
}

@article{hulsen2019big,
  title={From big data to precision medicine},
  author={Hulsen, Tim and Jamuar, Saumya S and Moody, Alan R and Karnes, Jason H and Varga, Orsolya and Hedensted, Stine and Spreafico, Roberto and Hafler, David A and McKinney, Eoin F},
  journal={Frontiers in medicine},
  volume={6},
  pages={34},
  year={2019},
  publisher={Frontiers Media SA}
}

@article{varian2014big,
  title={Big data: New tricks for econometrics},
  author={Varian, Hal R},
  journal={Journal of economic perspectives},
  volume={28},
  number={2},
  pages={3--28},
  year={2014},
  publisher={American Economic Association 2014 Broadway, Suite 305, Nashville, TN 37203-2418}
}

@article{lazer2009computational,
  title={Computational social science},
  author={Lazer, David and Pentland, Alex and Adamic, Lada and Aral, Sinan and Barab{\'a}si, Albert-L{\'a}szl{\'o} and Brewer, Devon and Christakis, Nicholas and Contractor, Noshir and Fowler, James and Gutmann, Myron and others},
  journal={Science},
  volume={323},
  number={5915},
  pages={721--723},
  year={2009},
  publisher={American Association for the Advancement of Science}
}

@article{lloyd1982least,
  title={Least squares quantization in PCM},
  author={Lloyd, Stuart},
  journal={IEEE transactions on information theory},
  volume={28},
  number={2},
  pages={129--137},
  year={1982},
  publisher={IEEE}
}

@inproceedings{jayaram2017review,
  title={A review: Information extraction techniques from research papers},
  author={Jayaram, Kavitha and Sangeeta, K},
  booktitle={2017 International conference on innovative mechanisms for industry applications (ICIMIA)},
  pages={56--59},
  year={2017},
  organization={IEEE}
}

@misc{hhrlhf,
      title={Training a Helpful and Harmless Assistant with Reinforcement Learning from Human Feedback}, 
      author={Yuntao Bai and Andy Jones and Kamal Ndousse and Amanda Askell and Anna Chen and Nova DasSarma and Dawn Drain and Stanislav Fort and Deep Ganguli and Tom Henighan and Nicholas Joseph and Saurav Kadavath and Jackson Kernion and Tom Conerly and Sheer El-Showk and Nelson Elhage and Zac Hatfield-Dodds and Danny Hernandez and Tristan Hume and Scott Johnston and Shauna Kravec and Liane Lovitt and Neel Nanda and Catherine Olsson and Dario Amodei and Tom Brown and Jack Clark and Sam McCandlish and Chris Olah and Ben Mann and Jared Kaplan},
      year={2022},
      url={https://arxiv.org/abs/2204.05862}, 
}

@InProceedings{shp,
  title = 	 {Understanding Dataset Difficulty with $\mathcal{V}$-Usable Information},
  author =       {Ethayarajh, Kawin and Choi, Yejin and Swayamdipta, Swabha},
  booktitle = 	 {Proceedings of the 39th International Conference on Machine Learning},
  pages = 	 {5988--6008},
  year = 	 {2022},
  editor = 	 {Chaudhuri, Kamalika and Jegelka, Stefanie and Song, Le and Szepesvari, Csaba and Niu, Gang and Sabato, Sivan},
  volume = 	 {162},
  series = 	 {Proceedings of Machine Learning Research},
  month = 	 {17--23 Jul},
  publisher =    {PMLR},
  pdf = 	 {https://proceedings.mlr.press/v162/ethayarajh22a/ethayarajh22a.pdf},
  url = 	 {https://proceedings.mlr.press/v162/ethayarajh22a.html},
  abstract = 	 {Estimating the difficulty of a dataset typically involves comparing state-of-the-art models to humans; the bigger the performance gap, the harder the dataset is said to be. However, this comparison provides little understanding of how difficult each instance in a given distribution is, or what attributes make the dataset difficult for a given model. To address these questions, we frame dataset difficulty—w.r.t. a model $\mathcal{V}$—as the lack of $\mathcal{V}$-usable information (Xu et al., 2019), where a lower value indicates a more difficult dataset for $\mathcal{V}$. We further introduce pointwise $\mathcal{V}$-information (PVI) for measuring the difficulty of individual instances w.r.t. a given distribution. While standard evaluation metrics typically only compare different models for the same dataset, $\mathcal{V}$-usable information and PVI also permit the converse: for a given model $\mathcal{V}$, we can compare different datasets, as well as different instances/slices of the same dataset. Furthermore, our framework allows for the interpretability of different input attributes via transformations of the input, which we use to discover annotation artefacts in widely-used NLP benchmarks.}
}


@misc{zheng2023judgingllmasajudgemtbenchchatbot,
      title={Judging LLM-as-a-Judge with MT-Bench and Chatbot Arena}, 
      author={Lianmin Zheng and Wei-Lin Chiang and Ying Sheng and Siyuan Zhuang and Zhanghao Wu and Yonghao Zhuang and Zi Lin and Zhuohan Li and Dacheng Li and Eric P. Xing and Hao Zhang and Joseph E. Gonzalez and Ion Stoica},
      year={2023},
      url={https://arxiv.org/abs/2306.05685}, 
}

@article{hurst2024gpt,
  title={Gpt-4o system card},
  author={Hurst, Aaron and Lerer, Adam and Goucher, Adam P and Perelman, Adam and Ramesh, Aditya and Clark, Aidan and Ostrow, AJ and Welihinda, Akila and Hayes, Alan and Radford, Alec and others},
  journal={arXiv preprint arXiv:2410.21276},
  year={2024}
}

@article{dubey2024llama,
  title={The llama 3 herd of models},
  author={Dubey, Abhimanyu and Jauhri, Abhinav and Pandey, Abhinav and Kadian, Abhishek and Al-Dahle, Ahmad and Letman, Aiesha and Mathur, Akhil and Schelten, Alan and Yang, Amy and Fan, Angela and others},
  journal={arXiv preprint arXiv:2407.21783},
  year={2024}
}


@article{zhong2024explaining,
  title={Explaining Datasets in Words: Statistical Models with Natural Language Parameters},
  author={Zhong, Ruiqi and Wang, Heng and Klein, Dan and Steinhardt, Jacob},
  journal={arXiv preprint arXiv:2409.08466},
  year={2024}
}

@inproceedings{dunlap2024describing,
  title={Describing differences in image sets with natural language},
  author={Dunlap, Lisa and Zhang, Yuhui and Wang, Xiaohan and Zhong, Ruiqi and Darrell, Trevor and Steinhardt, Jacob and Gonzalez, Joseph E and Yeung-Levy, Serena},
  booktitle={Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition},
  pages={24199--24208},
  year={2024}
}

@online{anthropic2024,
  author    = {Anthropic},
  title     = {Claude 3.5 Sonnet},
  url       = {https://www.anthropic.com/news/claude-3-5-sonnet},
year = {2024}
}

@inproceedings{perez2022red,
  title={Red Teaming Language Models with Language Models},
  author={Perez, Ethan and Huang, Saffron and Song, Francis and Cai, Trevor and Ring, Roman and Aslanides, John and Glaese, Amelia and McAleese, Nat and Irving, Geoffrey},
  booktitle={Proceedings of the 2022 Conference on Empirical Methods in Natural Language Processing},
  pages={3419--3448},
  year={2022}
}

@misc{zheng2023lmsyschat1m,
      title={LMSYS-Chat-1M: A Large-Scale Real-World LLM Conversation Dataset}, 
      author={Lianmin Zheng and Wei-Lin Chiang and Ying Sheng and Tianle Li and Siyuan Zhuang and Zhanghao Wu and Yonghao Zhuang and Zhuohan Li and Zi Lin and Eric. P Xing and Joseph E. Gonzalez and Ion Stoica and Hao Zhang},
      year={2023},
      eprint={2309.11998},
      archivePrefix={arXiv},
      primaryClass={cs.CL}
}

@inproceedings{
zhao2024wildchat,
title={WildChat: 1M Chat{GPT} Interaction Logs in the Wild},
author={Wenting Zhao and Xiang Ren and Jack Hessel and Claire Cardie and Yejin Choi and Yuntian Deng},
booktitle={The Twelfth International Conference on Learning Representations},
year={2024},
url={https://openreview.net/forum?id=Bl8u7ZRlbM}
}

@article{jiang2024mixtral,
  title={Mixtral of experts},
  author={Jiang, Albert Q and Sablayrolles, Alexandre and Roux, Antoine and Mensch, Arthur and Savary, Blanche and Bamford, Chris and Chaplot, Devendra Singh and Casas, Diego de las and Hanna, Emma Bou and Bressand, Florian and others},
  journal={arXiv preprint arXiv:2401.04088},
  year={2024}
}

@article{achiam2023gpt,
  title={Gpt-4 technical report},
  author={Achiam, Josh and Adler, Steven and Agarwal, Sandhini and Ahmad, Lama and Akkaya, Ilge and Aleman, Florencia Leoni and Almeida, Diogo and Altenschmidt, Janko and Altman, Sam and Anadkat, Shyamal and others},
  journal={arXiv preprint arXiv:2303.08774},
  year={2023}
}

@article{team2024gemini,
  title={Gemini 1.5: Unlocking multimodal understanding across millions of tokens of context},
  author={Team, Gemini and Georgiev, Petko and Lei, Ving Ian and Burnell, Ryan and Bai, Libin and Gulati, Anmol and Tanzer, Garrett and Vincent, Damien and Pan, Zhufeng and Wang, Shibo and others},
  journal={arXiv preprint arXiv:2403.05530},
  year={2024}
}

@misc{deberta,
      title={DeBERTa: Decoding-enhanced BERT with Disentangled Attention}, 
      author={Pengcheng He and Xiaodong Liu and Jianfeng Gao and Weizhu Chen},
      year={2021},
      eprint={2006.03654},
      archivePrefix={arXiv},
      primaryClass={cs.CL},
      url={https://arxiv.org/abs/2006.03654}, 
}

@software{alpacaeval,
author = {Li, Xuechen and Zhang, Tianyi and Dubois, Yann and Taori, Rohan and Gulrajani, Ishaan and Guestrin, Carlos and Liang, Percy and Hashimoto, Tatsunori B.},month = may,title = {{AlpacaEval: An Automatic Evaluator of Instruction-following Models}},year = {2023}}

@article{vaswani2017attention,
  title={Attention is all you need},
  author={Vaswani, A},
  journal={Advances in Neural Information Processing Systems},
  year={2017}
}

@article{schmidt2009distilling,
  author = {Schmidt, Michael and Lipson, Hod},
  title = {Distilling free-form natural laws from experimental data},
  journal = {Science},
  volume = {324},
  number = {5923},
  pages = {81--85},
  year = {2009}
}

@article{gulwani2017program,
  author = {Gulwani, Sumit and Polozov, Oleksandr and Singh, Rishabh},
  title = {Program synthesis},
  journal = {Foundations and Trends\textregistered~in Programming Languages},
  volume = {4},
  number = {1-2},
  pages = {1--119},
  year = {2017}
}

@article{hand2007principles,
  author = {Hand, David J.},
  title = {Principles of data mining},
  journal = {Drug Safety},
  volume = {30},
  number = {7},
  pages = {621--622},
  year = {2007}
}

@article{kryscinski2019neural,
  author = {Kryscinski, Wojciech and Keskar, Nitish Shirish and McCann, Bryan and Xiong, Caiming and Socher, Richard},
  title = {Neural text summarization: A critical evaluation},
  journal = {arXiv preprint arXiv:1908.08960},
  year = {2019}
}

@article{instruction-induction,
  author = {Honovich, Or and Shaham, Uri and Bowman, Samuel R. and Levy, Omer},
  title = {Instruction induction: From few examples to natural language task descriptions},
  journal = {ACL},
  year = {2022}
}

@article{liu2018table,
  author = {Liu, Tianyu and Wang, Kaili and Sha, Lei and Chang, Baobao and Sui, Zhifang},
  title = {Table-to-text generation by structure-aware seq2seq learning},
  journal = {AAAI},
  year = {2018}
}

@article{singh2024iprompt,
  author = {Singh, Chitralekha and Nasseri, Kevin and Tan, Yew-Soon and Tang, Thomas and Yu, Bin},
  title = {Rethinking interpretability in the era of large language models},
  journal = {arXiv preprint arXiv:2402.01761},
  year = {2024}
}

@article{carmel2009,
  author = {Carmel, David and Roitman, Haggai and Zwerdling, Naama},
  title = {Enhancing cluster labeling using Wikipedia},
  journal = {SIGIR},
  year = {2009}
}

@article{zhong2022diff,
  author = {Zhong, Rowan and Snell, Clay and Klein, Dan and Steinhardt, Jacob},
  title = {Describing differences between text distributions with natural language},
  journal = {ICML},
  year = {2022}
}

@article{wang2023goal,
  author = {Wang, Zhengyang and Shang, Jian and Zhong, Rowan},
  title = {Goal-driven explainable clustering via language descriptions},
  journal = {EMNLP},
  year = {2023}
}

@article{zhong2023describing,
  author = {Zhong, Rowan and Zhang, Peng and Li, Shunyu et al.},
  title = {Goal driven discovery of distributional differences via language descriptions},
  journal = {NeurIPS},
  year = {2023}
}

@article{pham2023topicgpt,
  author = {Pham, Chi Minh and Hoyle, Alexander G. and Sun, Shiyu and Iyyer, Mohit},
  title = {TopicGPT: A prompt-based topic modeling framework},
  journal = {arXiv preprint arXiv:2311.01449},
  year = {2023}
}

@article{huth2016natural,
  author = {Huth, Alexander G. et al.},
  title = {Natural speech reveals semantic maps in human cortex},
  journal = {Nature},
  volume = {532},
  number = {7600},
  pages = {453--458},
  year = {2016}
}

@article{radford2019language,
  author = {Radford, Alec et al.},
  title = {Language models are unsupervised multitask learners},
  journal = {OpenAI Blog},
  year = {2019}
}

@article{petroni2019language,
  author = {Petroni, Fabio et al.},
  title = {Language models as knowledge bases?},
  journal = {arXiv preprint arXiv:1909.01066},
  year = {2019}
}

@article{lundberg2019explainable,
  author = {Lundberg, Scott M. et al.},
  title = {Explainable AI for trees},
  journal = {arXiv preprint arXiv:1905.04610},
  year = {2019}
}


@article{li2024dissectinghumanllmpreferences,
  title     = {Dissecting Human-Like Preferences in Large Language Models},
  author    = {Li, B. and Others},
  howpublished = {arXiv preprint arXiv:XXXX.XXXXX},
  year      = {2024}
}

@article{sorensen2024clio,
  title     = {Clio: Privacy-Preserving Conversation Analysis in Large Language Models},
  author    = {Sorensen, B. and Others},
  howpublished = {arXiv preprint arXiv:XXXX.XXXXX},
  year      = {2024}
}

@article{liu2024tnt,
  title     = {{TnT-LLM}: Transparent and Transferable Intent Modeling with Large Language Models},
  author    = {Liu, H. and Others},
  howpublished = {arXiv preprint arXiv:XXXX.XXXXX},
  year      = {2024}
}

@article{yu2024llmpoweredusersimulator,
  title     = {{LLM-Powered} User Simulators for Recommender Systems},
  author    = {Yu, Z. and Others},
  howpublished = {arXiv preprint arXiv:XXXX.XXXXX},
  year      = {2024}
}

@article{gao2024scaling,
  title={Scaling and evaluating sparse autoencoders},
  author={Gao, Leo and la Tour, Tom Dupr{\'e} and Tillman, Henk and Goh, Gabriel and Troll, Rajan and Radford, Alec and Sutskever, Ilya and Leike, Jan and Wu, Jeffrey},
  journal={arXiv preprint arXiv:2406.04093},
  year={2024}
}

@misc{benara2024crafting,
      title={Crafting Interpretable Embeddings by Asking LLMs Questions}, 
      author={Vinamra Benara and Chandan Singh and John X. Morris and Richard Antonello and Ion Stoica and Alexander G. Huth and Jianfeng Gao},
      year={2024},
      eprint={2405.16714},
      archivePrefix={arXiv},
      primaryClass={cs.CL}
}

@article{tamkin2024clio,
  title={Clio: Privacy-Preserving Insights into Real-World AI Use},
  author={Tamkin, Alex and McCain, Miles and Handa, Kunal and Durmus, Esin and Lovitt, Liane and Rathi, Ankur and Huang, Saffron and Mountfield, Alfred and Hong, Jerry and Ritchie, Stuart and others},
  journal={arXiv preprint arXiv:2412.13678},
  year={2024}
}

@inproceedings{subramani2022extracting,
  title={Extracting Latent Steering Vectors from Pretrained Language Models},
  author={Subramani, Nishant and Suresh, Nivedita and Peters, Matthew E},
  booktitle={Findings of the Association for Computational Linguistics: ACL 2022},
  pages={566--581},
  year={2022}
}

@ARTICLE{guo2023medshift,
  author={Guo, Xiaoyuan and Gichoya, Judy Wawira and Trivedi, Hari and Purkayastha, Saptarshi and Banerjee, Imon},
  journal={IEEE Journal of Biomedical and Health Informatics}, 
  title={MedShift: Automated Identification of Shift Data for Medical Image Dataset Curation}, 
  year={2023},
  volume={27},
  number={8},
  pages={3936-3947},
  keywords={Data models;Biomedical imaging;Pipelines;Training;Detectors;Information sharing;Bioinformatics;Anomaly detection;dataset curation;medical shift data;OOD detection;X-ray},
  doi={10.1109/JBHI.2023.3275104}}

@article{grosse2023studying,
  title={Studying large language model generalization with influence functions},
  author={Grosse, Roger and Bae, Juhan and Anil, Cem and Elhage, Nelson and Tamkin, Alex and Tajdini, Amirhossein and Steiner, Benoit and Li, Dustin and Durmus, Esin and Perez, Ethan and others},
  journal={arXiv preprint arXiv:2308.03296},
  year={2023}
}

@article{wolf2018scanpy,
  title={SCANPY: large-scale single-cell gene expression data analysis},
  author={Wolf, F Alexander and Angerer, Philipp and Theis, Fabian J},
  journal={Genome biology},
  volume={19},
  pages={1--5},
  year={2018},
  publisher={Springer}
}

@Manual{karandeep2025cinspacy,
    title = {clinspacy: Clinical Natural Language Processing using
      'spaCy', 'scispaCy', and 'medspaCy'},
    author = {Karandeep Singh and Benjamin Kompa and Andrew Beam and
      Allen Schmaltz},
    year = {2025},
    note = {R package version 1.0.2.9000},
    url = {https://github.com/ml4lhs/clinspacy},
  }

@inproceedings{lieberum2024gemma,
  title={Gemma Scope: Open Sparse Autoencoders Everywhere All At Once on Gemma 2},
  author={Lieberum, Tom and Rajamanoharan, Senthooran and Conmy, Arthur and Smith, Lewis and Sonnerat, Nicolas and Varma, Vikrant and Kram{\'a}r, J{\'a}nos and Dragan, Anca and Shah, Rohin and Nanda, Neel},
  booktitle={Proceedings of the 7th BlackboxNLP Workshop: Analyzing and Interpreting Neural Networks for NLP},
  pages={278--300},
  year={2024}
}

@article{weidinger2023sociotechnical,
  title={Sociotechnical safety evaluation of generative ai systems},
  author={Weidinger, Laura and Rauh, Maribeth and Marchal, Nahema and Manzini, Arianna and Hendricks, Lisa Anne and Mateos-Garcia, Juan and Bergman, Stevie and Kay, Jackie and Griffin, Conor and Bariach, Ben and others},
  journal={arXiv preprint arXiv:2310.11986},
  year={2023}
}

@article{pfister2025gandalf,
  title={Gandalf the Red: Adaptive Security for LLMs},
  author={Pfister, Niklas and Volhejn, V{\'a}clav and Knott, Manuel and Arias, Santiago and Bazi{\'n}ska, Julia and Bichurin, Mykhailo and Commike, Alan and Darling, Janet and Dienes, Peter and Fiedler, Matthew and others},
  journal={arXiv preprint arXiv:2501.07927},
  year={2025}
}

@misc{nussbaum2024nomic,
      title={Nomic Embed: Training a Reproducible Long Context Text Embedder}, 
      author={Zach Nussbaum and John X. Morris and Brandon Duderstadt and Andriy Mulyar},
      year={2024},
      eprint={2402.01613},
      archivePrefix={arXiv},
      primaryClass={cs.CL}
}

@article{ouyang2022training,
  title={Training language models to follow instructions with human feedback},
  author={Ouyang, Long and Wu, Jeffrey and Jiang, Xu and Almeida, Diogo and Wainwright, Carroll and Mishkin, Pamela and Zhang, Chong and Agarwal, Sandhini and Slama, Katarina and Ray, Alex and others},
  journal={Advances in neural information processing systems},
  volume={35},
  pages={27730--27744},
  year={2022}
}

@misc{dorka2024quantileregressiondistributionalreward,
      title={Quantile Regression for Distributional Reward Models in RLHF}, 
      author={Nicolai Dorka},
      year={2024},
      eprint={2409.10164},
      archivePrefix={arXiv},
      primaryClass={cs.LG},
      url={https://arxiv.org/abs/2409.10164}, 
}

@misc{wang2024helpsteer2,
      title={HelpSteer2: Open-source dataset for training top-performing reward models}, 
      author={Zhilin Wang and Yi Dong and Olivier Delalleau and Jiaqi Zeng and Gerald Shen and Daniel Egert and Jimmy J. Zhang and Makesh Narsimhan Sreedhar and Oleksii Kuchaiev},
      year={2024},
      eprint={2406.08673},
      archivePrefix={arXiv},
      primaryClass={id='cs.CL' full_name='Computation and Language' is_active=True alt_name='cmp-lg' in_archive='cs' is_general=False description='Covers natural language processing. Roughly includes material in ACM Subject Class I.2.7. Note that work on artificial languages (programming languages, logics, formal systems) that does not explicitly address natural-language issues broadly construed (natural-language processing, computational linguistics, speech, text retrieval, etc.) is not appropriate for this area.'}
}

@inproceedings{carmel2009enhancing,
  title={Enhancing cluster labeling using wikipedia},
  author={Carmel, David and Roitman, Haggai and Zwerdling, Naama},
  booktitle={Proceedings of the 32nd international ACM SIGIR conference on Research and development in information retrieval},
  pages={139--146},
  year={2009}
}

@inproceedings{treeratpituk2006automatically,
  title={Automatically labeling hierarchical clusters},
  author={Treeratpituk, Pucktada and Callan, Jamie},
  booktitle={Proceedings of the 2006 international conference on Digital government research},
  pages={167--176},
  year={2006}
}

@inproceedings{zhang2018taxogen,
  title={Taxogen: Unsupervised topic taxonomy construction by adaptive term embedding and clustering},
  author={Zhang, Chao and Tao, Fangbo and Chen, Xiusi and Shen, Jiaming and Jiang, Meng and Sadler, Brian and Vanni, Michelle and Han, Jiawei},
  booktitle={Proceedings of the 24th ACM SIGKDD International Conference on Knowledge Discovery \& Data Mining},
  pages={2701--2709},
  year={2018}
}

@article{viswanathan2023large,
  title={Large language models enable few-shot clustering},
  author={Viswanathan, Vijay and Gashteovski, Kiril and Lawrence, Carolin and Wu, Tongshuang and Neubig, Graham},
  journal={arXiv preprint arXiv:2307.00524},
  year={2023}
}

@inproceedings{lam2024concept,
  title={Concept Induction: Analyzing Unstructured Text with High-Level Concepts Using LLooM},
  author={Lam, Michelle S and Teoh, Janice and Landay, James A and Heer, Jeffrey and Bernstein, Michael S},
  booktitle={Proceedings of the CHI Conference on Human Factors in Computing Systems},
  pages={1--28},
  year={2024}
}

@inproceedings{zhong2022describing,
  title={Describing differences between text distributions with natural language},
  author={Zhong, Ruiqi and Snell, Charlie and Klein, Dan and Steinhardt, Jacob},
  booktitle={International Conference on Machine Learning},
  pages={27099--27116},
  year={2022},
  organization={PMLR}
}

@article{zhong2023goal,
  title={Goal driven discovery of distributional differences via language descriptions},
  author={Zhong, Ruiqi and Zhang, Peter and Li, Steve and Ahn, Jinwoo and Klein, Dan and Steinhardt, Jacob},
  journal={Advances in Neural Information Processing Systems},
  volume={36},
  pages={40204--40237},
  year={2023}
}

@article{chang2009reading,
  title={Reading tea leaves: How humans interpret topic models},
  author={Chang, Jonathan and Gerrish, Sean and Wang, Chong and Boyd-Graber, Jordan and Blei, David},
  journal={Advances in neural information processing systems},
  volume={22},
  year={2009}
}

@article{qiu2023phenomenal,
  title={Phenomenal yet puzzling: Testing inductive reasoning capabilities of language models with hypothesis refinement},
  author={Qiu, Linlu and Jiang, Liwei and Lu, Ximing and Sclar, Melanie and Pyatkin, Valentina and Bhagavatula, Chandra and Wang, Bailin and Kim, Yoon and Choi, Yejin and Dziri, Nouha and others},
  journal={arXiv preprint arXiv:2310.08559},
  year={2023}
}

@article{singh2024rethinking,
  title={Rethinking interpretability in the era of large language models},
  author={Singh, Chandan and Inala, Jeevana Priya and Galley, Michel and Caruana, Rich and Gao, Jianfeng},
  journal={arXiv preprint arXiv:2402.01761},
  year={2024}
}

@article{singh2023explaining,
  title={Explaining black box text modules in natural language with language models},
  author={Singh, Chandan and Hsu, Aliyah R and Antonello, Richard and Jain, Shailee and Huth, Alexander G and Yu, Bin and Gao, Jianfeng},
  journal={arXiv preprint arXiv:2305.09863},
  year={2023}
}

@article{singh2022explaining,
  title={Explaining patterns in data with language models via interpretable autoprompting},
  author={Singh, Chandan and Morris, John X and Aneja, Jyoti and Rush, Alexander M and Gao, Jianfeng},
  journal={arXiv preprint arXiv:2210.01848},
  year={2022}
}

@misc{templeton2024scaling,
  title={Scaling monosemanticity: Extracting interpretable features from claude 3 sonnet. Transformer Circuits Thread},
  author={Templeton, Adly and Conerly, Tom and Marcus, Jonathan and Lindsey, Jack and Bricken, Trenton and Chen, Brian and Pearce, Adam and Citro, Craig and Ameisen, Emmanuel and Jones, Andy and others},
  year={2024}
}


@inproceedings{singh2023tree,
  title={Tree prompting: Efficient task adaptation without fine-tuning},
  author={Singh, Chandan and Morris, John and Rush, Alexander M and Gao, Jianfeng and Deng, Yuntian},
  booktitle={Proceedings of the 2023 Conference on Empirical Methods in Natural Language Processing},
  pages={6253--6267},
  year={2023}
}

@article{gero2023self,
  title={Self-verification improves few-shot clinical information extraction},
  author={Gero, Zelalem and Singh, Chandan and Cheng, Hao and Naumann, Tristan and Galley, Michel and Gao, Jianfeng and Poon, Hoifung},
  journal={arXiv preprint arXiv:2306.00024},
  year={2023}
}

@article{pan2023automatically,
  title={Automatically correcting large language models: Surveying the landscape of diverse self-correction strategies},
  author={Pan, Liangming and Saxon, Michael and Xu, Wenda and Nathani, Deepak and Wang, Xinyi and Wang, William Yang},
  journal={arXiv preprint arXiv:2308.03188},
  year={2023}
}

@article{bills2023language,
  title={Language models can explain neurons in language models},
  author={Bills, Steven and Cammarata, Nick and Mossing, Dan and Tillman, Henk and Gao, Leo and Goh, Gabriel and Sutskever, Ilya and Leike, Jan and Wu, Jeff and Saunders, William},
  journal={URL https://openaipublic. blob. core. windows. net/neuron-explainer/paper/index. html.(Date accessed: 14.05. 2023)},
  volume={2},
  year={2023}
}

@inproceedings{koh2020concept,
  title={Concept bottleneck models},
  author={Koh, Pang Wei and Nguyen, Thao and Tang, Yew Siang and Mussmann, Stephen and Pierson, Emma and Kim, Been and Liang, Percy},
  booktitle={International conference on machine learning},
  pages={5338--5348},
  year={2020},
  organization={PMLR}
}

@inproceedings{yang2023language,
  title={Language in a bottle: Language model guided concept bottlenecks for interpretable image classification},
  author={Yang, Yue and Panagopoulou, Artemis and Zhou, Shenghao and Jin, Daniel and Callison-Burch, Chris and Yatskar, Mark},
  booktitle={Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition},
  pages={19187--19197},
  year={2023}
}

@article{ludan2023interpretable,
  title={Interpretable-by-Design Text Classification with Iteratively Generated Concept Bottleneck},
  author={Ludan, Josh Magnus and Lyu, Qing and Yang, Yue and Dugan, Liam and Yatskar, Mark and Callison-Burch, Chris},
  journal={arXiv preprint arXiv:2310.19660},
  year={2023}
}

@article{schrodi2024concept,
  title={Concept Bottleneck Models Without Predefined Concepts},
  author={Schrodi, Simon and Schur, Julian and Argus, Max and Brox, Thomas},
  journal={arXiv preprint arXiv:2407.03921},
  year={2024}
}

@article{durmus2023towards,
  title={Towards measuring the representation of subjective global opinions in language models},
  author={Durmus, Esin and Nyugen, Karina and Liao, Thomas I and Schiefer, Nicholas and Askell, Amanda and Bakhtin, Anton and Chen, Carol and Hatfield-Dodds, Zac and Hernandez, Danny and Joseph, Nicholas and others},
  journal={arXiv preprint arXiv:2306.16388},
  year={2023}
}

@article{kwok2024evaluating,
  title={Evaluating cultural adaptability of a large language model via simulation of synthetic personas},
  author={Kwok, Louis and Bravansky, Michal and Griffin, Lewis D},
  journal={arXiv preprint arXiv:2408.06929},
  year={2024}
}

@article{trhlik2024quantifying,
  title={Quantifying Generative Media Bias with a Corpus of Real-world and Generated News Articles},
  author={Trhlik, Filip and Stenetorp, Pontus},
  journal={arXiv preprint arXiv:2406.10773},
  year={2024}
}

@article{li2024attention,
  title={Attention is all you need for llm-based code vulnerability localization},
  author={Li, Yue and Li, Xiao and Wu, Hao and Zhang, Yue and Cheng, Xiuzhen and Zhong, Sheng and Xu, Fengyuan},
  journal={arXiv preprint arXiv:2410.15288},
  year={2024}
}

@article{shanahan2023role,
  title={Role play with large language models},
  author={Shanahan, Murray and McDonell, Kyle and Reynolds, Laria},
  journal={Nature},
  volume={623},
  number={7987},
  pages={493--498},
  year={2023},
  publisher={Nature Publishing Group UK London}
}

@article{ram2018privacy,
  title={Privacy preservation techniques in big data analytics: a survey},
  author={Ram Mohan Rao, P and Murali Krishna, S and Siva Kumar, AP},
  journal={Journal of Big Data},
  volume={5},
  number={1},
  pages={33},
  year={2018},
  publisher={Springer}
}

@article{barocas2016big,
  title={Big data's disparate impact},
  author={Barocas, Solon and Selbst, Andrew D},
  journal={Calif. L. Rev.},
  volume={104},
  pages={671},
  year={2016},
  publisher={HeinOnline}
}

@article{zuboff2015big,
  title={Big other: surveillance capitalism and the prospects of an information civilization},
  author={Zuboff, Shoshana},
  journal={Journal of information technology},
  volume={30},
  number={1},
  pages={75--89},
  year={2015},
  publisher={SAGE Publications Sage UK: London, England}
}

@inproceedings{narayanan2008robust,
  title={Robust de-anonymization of large sparse datasets},
  author={Narayanan, Arvind and Shmatikov, Vitaly},
  booktitle={2008 IEEE Symposium on Security and Privacy (sp 2008)},
  pages={111--125},
  year={2008},
  organization={IEEE}
}

@article{tufekci2014engineering,
  title={Engineering the public: Big data, surveillance and computational politics},
  author={Tufekci, Zeynep},
  journal={First Monday},
  year={2014}
}

@inproceedings{li-etal-2024-dissecting,
    title = "Dissecting Human and {LLM} Preferences",
    author = "Li, Junlong  and
      Zhou, Fan  and
      Sun, Shichao  and
      Zhang, Yikai  and
      Zhao, Hai  and
      Liu, Pengfei",
    editor = "Ku, Lun-Wei  and
      Martins, Andre  and
      Srikumar, Vivek",
    booktitle = "Proceedings of the 62nd Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers)",
    month = aug,
    year = "2024",
    address = "Bangkok, Thailand",
    publisher = "Association for Computational Linguistics",
    url = "https://aclanthology.org/2024.acl-long.99/",
    doi = "10.18653/v1/2024.acl-long.99",
    pages = "1790--1811",
    abstract = "As a relative quality comparison of model responses, human and Large Language Model (LLM) preferences serve as common alignment goals in model fine-tuning and criteria in evaluation. Yet, these preferences merely reflect broad tendencies, resulting in less explainable and controllable models with potential safety risks. In this work, we dissect the preferences of human and 32 different LLMs to understand their quantitative composition, using annotations from real-world user-model conversations for a fine-grained, scenario-wise analysis. We find that humans are less sensitive to errors, favor responses that support their stances, and show clear dislike when models admit their limits. On the contrary, advanced LLMs like GPT-4-Turbo emphasize correctness, clarity, and harmlessness more. Additionally, LLMs of similar sizes tend to exhibit similar preferences, regardless of their training methods, and fine-tuning for alignment does not significantly alter the preferences of pretrained-only LLMs. Finally, we show that preference-based evaluation can be intentionally manipulated. In both training-free and training-based settings, aligning a model with the preferences of judges boosts scores, while injecting the least preferred properties lowers them. This results in notable score shifts: up to 0.59 on MT-Bench (1-10 scale) and 31.94 on AlpacaEval 2.0 (0-100 scale), highlighting the significant impact of this strategic adaptation. We have made all resources of this project publicly available."
}

@article{christiano2017deep,
  title={Deep reinforcement learning from human preferences},
  author={Christiano, Paul F and Leike, Jan and Brown, Tom and Martic, Miljan and Legg, Shane and Amodei, Dario},
  journal={Advances in neural information processing systems},
  volume={30},
  year={2017}
}

@article{sileo2023tasksource,
  title={tasksource: Structured dataset preprocessing annotations for frictionless extreme multi-task learning and evaluation},
  author={Sileo, Damien},
  journal={arXiv preprint arXiv:2301.05948},
  year={2023}
}