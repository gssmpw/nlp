@misc{benara2024crafting,
      title={Crafting Interpretable Embeddings by Asking LLMs Questions}, 
      author={Vinamra Benara and Chandan Singh and John X. Morris and Richard Antonello and Ion Stoica and Alexander G. Huth and Jianfeng Gao},
      year={2024},
      eprint={2405.16714},
      archivePrefix={arXiv},
      primaryClass={cs.CL}
}

@article{carmel2009,
  author = {Carmel, David and Roitman, Haggai and Zwerdling, Naama},
  title = {Enhancing cluster labeling using Wikipedia},
  journal = {SIGIR},
  year = {2009}
}

@article{chang2009reading,
  title={Reading tea leaves: How humans interpret topic models},
  author={Chang, Jonathan and Gerrish, Sean and Wang, Chong and Boyd-Graber, Jordan and Blei, David},
  journal={Advances in neural information processing systems},
  volume={22},
  year={2009}
}

@inproceedings{dunlap2024describing,
  title={Describing differences in image sets with natural language},
  author={Dunlap, Lisa and Zhang, Yuhui and Wang, Xiaohan and Zhong, Ruiqi and Darrell, Trevor and Steinhardt, Jacob and Gonzalez, Joseph E and Yeung-Levy, Serena},
  booktitle={Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition},
  pages={24199--24208},
  year={2024}
}

@article{findeis2024inverse,
  title={Inverse Constitutional AI: Compressing Preferences into Principles},
  author={Findeis, Arduin and Kaufmann, Timo and H{\"u}llermeier, Eyke and Albanie, Samuel and Mullins, Robert},
  journal={arXiv preprint arXiv:2406.06560},
  year={2024}
}

@article{gero2023self,
  title={Self-verification improves few-shot clinical information extraction},
  author={Gero, Zelalem and Singh, Chandan and Cheng, Hao and Naumann, Tristan and Galley, Michel and Gao, Jianfeng and Poon, Hoifung},
  journal={arXiv preprint arXiv:2306.00024},
  year={2023}
}

@inproceedings{koh2020concept,
  title={Concept bottleneck models},
  author={Koh, Pang Wei and Nguyen, Thao and Tang, Yew Siang and Mussmann, Stephen and Pierson, Emma and Kim, Been and Liang, Percy},
  booktitle={International conference on machine learning},
  pages={5338--5348},
  year={2020},
  organization={PMLR}
}

@inproceedings{lam2024concept,
  title={Concept Induction: Analyzing Unstructured Text with High-Level Concepts Using LLooM},
  author={Lam, Michelle S and Teoh, Janice and Landay, James A and Heer, Jeffrey and Bernstein, Michael S},
  booktitle={Proceedings of the CHI Conference on Human Factors in Computing Systems},
  pages={1--28},
  year={2024}
}

@article{ludan2023interpretable,
  title={Interpretable-by-Design Text Classification with Iteratively Generated Concept Bottleneck},
  author={Ludan, Josh Magnus and Lyu, Qing and Yang, Yue and Dugan, Liam and Yatskar, Mark and Callison-Burch, Chris},
  journal={arXiv preprint arXiv:2310.19660},
  year={2023}
}

@article{pan2023automatically,
  title={Automatically correcting large language models: Surveying the landscape of diverse self-correction strategies},
  author={Pan, Liangming and Saxon, Michael and Xu, Wenda and Nathani, Deepak and Wang, Xinyi and Wang, William Yang},
  journal={arXiv preprint arXiv:2308.03188},
  year={2023}
}

@article{pham2023topicgpt,
  author = {Pham, Chi Minh and Hoyle, Alexander G. and Sun, Shiyu and Iyyer, Mohit},
  title = {TopicGPT: A prompt-based topic modeling framework},
  journal = {arXiv preprint arXiv:2311.01449},
  year = {2023}
}

@article{qiu2023phenomenal,
  title={Phenomenal yet puzzling: Testing inductive reasoning capabilities of language models with hypothesis refinement},
  author={Qiu, Linlu and Jiang, Liwei and Lu, Ximing and Sclar, Melanie and Pyatkin, Valentina and Bhagavatula, Chandra and Wang, Bailin and Kim, Yoon and Choi, Yejin and Dziri, Nouha and others},
  journal={arXiv preprint arXiv:2310.08559},
  year={2023}
}

@article{schrodi2024concept,
  title={Concept Bottleneck Models Without Predefined Concepts},
  author={Schrodi, Simon and Schur, Julian and Argus, Max and Brox, Thomas},
  journal={arXiv preprint arXiv:2407.03921},
  year={2024}
}

@article{singh2023explaining,
  title={Explaining black box text modules in natural language with language models},
  author={Singh, Chandan and Hsu, Aliyah R and Antonello, Richard and Jain, Shailee and Huth, Alexander G and Yu, Bin and Gao, Jianfeng},
  journal={arXiv preprint arXiv:2305.09863},
  year={2023}
}

@inproceedings{singh2023tree,
  title={Tree prompting: Efficient task adaptation without fine-tuning},
  author={Singh, Chandan and Morris, John and Rush, Alexander M and Gao, Jianfeng and Deng, Yuntian},
  booktitle={Proceedings of the 2023 Conference on Empirical Methods in Natural Language Processing},
  pages={6253--6267},
  year={2023}
}

@article{singh2024iprompt,
  author = {Singh, Chitralekha and Nasseri, Kevin and Tan, Yew-Soon and Tang, Thomas and Yu, Bin},
  title = {Rethinking interpretability in the era of large language models},
  journal = {arXiv preprint arXiv:2402.01761},
  year = {2024}
}

@article{singh2024rethinking,
  title={Rethinking interpretability in the era of large language models},
  author={Singh, Chandan and Inala, Jeevana Priya and Galley, Michel and Caruana, Rich and Gao, Jianfeng},
  journal={arXiv preprint arXiv:2402.01761},
  year={2024}
}

@article{sorensen2024clio,
  title     = {Clio: Privacy-Preserving Conversation Analysis in Large Language Models},
  author    = {Sorensen, B. and Others},
  howpublished = {arXiv preprint arXiv:XXXX.XXXXX},
  year      = {2024}
}

@misc{templeton2024scaling,
  title={Scaling monosemanticity: Extracting interpretable features from claude 3 sonnet. Transformer Circuits Thread},
  author={Templeton, Adly and Conerly, Tom and Marcus, Jonathan and Lindsey, Jack and Bricken, Trenton and Chen, Brian and Pearce, Adam and Citro, Craig and Ameisen, Emmanuel and Jones, Andy and others},
  year={2024}
}

@inproceedings{treeratpituk2006automatically,
  title={Automatically labeling hierarchical clusters},
  author={Treeratpituk, Pucktada and Callan, Jamie},
  booktitle={Proceedings of the 2006 international conference on Digital government research},
  pages={167--176},
  year={2006}
}

@article{viswanathan2023large,
  title={Large language models enable few-shot clustering},
  author={Viswanathan, Vijay and Gashteovski, Kiril and Lawrence, Carolin and Wu, Tongshuang and Neubig, Graham},
  journal={arXiv preprint arXiv:2307.00524},
  year={2023}
}

@article{wang2023goal,
  author = {Wang, Zhengyang and Shang, Jian and Zhong, Rowan},
  title = {Goal-driven explainable clustering via language descriptions},
  journal = {EMNLP},
  year = {2023}
}

@inproceedings{yang2023language,
  title={Language in a bottle: Language model guided concept bottlenecks for interpretable image classification},
  author={Yang, Yue and Panagopoulou, Artemis and Zhou, Shenghao and Jin, Daniel and Callison-Burch, Chris and Yatskar, Mark},
  booktitle={Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition},
  pages={19187--19197},
  year={2023}
}

@inproceedings{zhang2018taxogen,
  title={Taxogen: Unsupervised topic taxonomy construction by adaptive term embedding and clustering},
  author={Zhang, Chao and Tao, Fangbo and Chen, Xiusi and Shen, Jiaming and Jiang, Meng and Sadler, Brian and Vanni, Michelle and Han, Jiawei},
  booktitle={Proceedings of the 24th ACM SIGKDD International Conference on Knowledge Discovery \& Data Mining},
  pages={2701--2709},
  year={2018}
}

@inproceedings{zhong2022describing,
  title={Describing differences between text distributions with natural language},
  author={Zhong, Ruiqi and Snell, Charlie and Klein, Dan and Steinhardt, Jacob},
  booktitle={International Conference on Machine Learning},
  pages={27099--27116},
  year={2022},
  organization={PMLR}
}

@article{zhong2023goal,
  title={Goal driven discovery of distributional differences via language descriptions},
  author={Zhong, Ruiqi and Zhang, Peter and Li, Steve and Ahn, Jinwoo and Klein, Dan and Steinhardt, Jacob},
  journal={Advances in Neural Information Processing Systems},
  volume={36},
  pages={40204--40237},
  year={2023}
}

@article{zhong2024explaining,
  title={Explaining Datasets in Words: Statistical Models with Natural Language Parameters},
  author={Zhong, Ruiqi and Wang, Heng and Klein, Dan and Steinhardt, Jacob},
  journal={arXiv preprint arXiv:2409.08466},
  year={2024}
}

