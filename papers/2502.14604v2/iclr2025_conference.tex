\documentclass{article}


% if you need to pass options to natbib, use, e.g.:
%     \PassOptionsToPackage{numbers, compress}{natbib}
% before loading neurips_2024


% ready for submission
\usepackage{iclr2025_conference,times}


% to compile a preprint version, e.g., for submission to arXiv, add add the
% [preprint] option:
%     \usepackage[preprint]{neurips_2024}


% to compile a camera-ready version, add the [final] option, e.g.:
%     \usepackage[final]{neurips_2024}


% to avoid loading the natbib package, add option nonatbib:
%    \usepackage[nonatbib]{neurips_2024}


\usepackage[utf8]{inputenc} % allow utf-8 input
\usepackage[T1]{fontenc}    % use 8-bit T1 fonts
\usepackage{hyperref}       % hyperlinks
\usepackage{url}            % simple URL typesetting
\usepackage{booktabs}       % professional-quality tables
\usepackage{amsfonts}       % blackboard math symbols
\usepackage{nicefrac}       % compact symbols for 1/2, etc.
\usepackage{microtype}      % microtypography
\usepackage{xcolor}         % colors

\usepackage{algorithm}
\usepackage[noend]{algpseudocode}
\usepackage{algorithmicx}

\usepackage{subcaption}
% \usepackage[ruled]{algorithm2e}
% \SetAlFnt{\small}
\usepackage{amsmath}
\usepackage{bm}
\usepackage{bbold}
\usepackage{graphicx}
\usepackage{multirow}
\usepackage{textcomp}
\usepackage{wrapfig}
% \usepackage{subfigure}
\usepackage{subcaption}

\usepackage{xspace}
\usepackage{interval}
\usepackage{bm,upgreek}
\usepackage{colortbl}
\usepackage{enumitem}
\usepackage{amssymb}% http://ctan.org/pkg/amssymb
\usepackage{pifont}
\usepackage{wasysym}
\usepackage{subcaption}
\usepackage{tikz}
\usepackage{bbm}
\usepackage{ulem}

\usepackage{amsthm}
\newtheorem{theorem}{Theorem}[section]
\newtheorem{remark}[theorem]{Remark}
\newtheorem{observation}[theorem]{Observation}

% Optional math commands from https://github.com/goodfeli/dlbook_notation.
% \input{math_commands.tex}
% separate toc for maintext and appendix
\usepackage{etoc}
\etocdepthtag.toc{mtchapter}
\etocsettagdepth{mtchapter}{subsection}
\etocsettagdepth{mtappendix}{none}

\newcommand{\needrevise}[1]{\textcolor{red}{#1}}
\newcommand{\rebuttal}[1]{\textcolor{blue}{#1}}

\definecolor{remark}{rgb}{1,.5,0} 
\definecolor{citecolor}{rgb}{0,0.443,0.737} 
\definecolor{linkcolor}{rgb}{0.956,0.298,0.235} 
\hypersetup{
    colorlinks=true,%
    citecolor=citecolor,%
    filecolor=citecolor,%
    linkcolor=linkcolor,%
    urlcolor=magenta
}


\title{Noisy Test-Time Adaptation in \\Vision-Language Models}
% \title{How Robust are Vision-Language Models in Noisy Test-Time Adaptation?}
% \title{Outlier-Aware Test-Time Adaptation in \\Vision-Language Models}

% OOD-Aware Test-Time Adaptation: Enhancing Vision-Language Models for Robust Generalization

% The \author macro works with any number of authors. There are two commands
% used to separate the names and addresses of multiple authors: \And and \AND.
%
% Using \And between authors leaves it to LaTeX to determine where to break the
% lines. Using \AND forces a line break at that point. So, if LaTeX puts 3 of 4
% authors names on the first line, and the last on the second line, try using
% \AND instead of \And before the third author name.

\makeatletter
\renewcommand*{\@fnsymbol}[1]{\ensuremath{\ifcase#1\or \dagger\or \ddagger\or
		\mathsection\or \mathparagraph\or \|\or **\or \dagger\dagger
		\or \ddagger\ddagger \else\@ctrerr\fi}}
\makeatother

% \author{
% \textbf{Chentao Cao}$^{1}$        \quad
%  \textbf{Zhun Zhong}$^{2 \dagger}$ \quad
%  \textbf{Zhanke Zhou}$^{1}$ \quad
%         \textbf{Tongliang Liu}$^{3}$ \quad
%         \textbf{Yang Liu}$^{4}$ \quad \\
%         \textbf{Kun Zhang}$^{5,6}$ \quad
%  \textbf{Bo Han}$^{1}\thanks{Correspondence to Bo Han (bhanml@comp.hkbu.edu.hk) and Zhun Zhong (zhunzhong007@gmail.com).}$
%  \vspace{0mm} \\
%  $^{1}$TMLR Group, Hong Kong Baptist University \quad \\
%  $^{2}$School of Computer Science and Information Engineering, Hefei University of Technology\\
%  $^{3}$Sydney AI Centre, The University of Sydney \quad \\
%         $^{4}$Computer Science and Engineering, University of California, Santa Cruz \quad \\
%         $^{5}$Mohamed bin Zayed University of Artificial Intelligence \quad 
%         $^{6}$Carnegie Mellon University  
% }

\author{
\begin{tabular}{@{}l@{}}
\textbf{Chentao Cao}$^{1}$        \quad
\textbf{Zhun Zhong}$^{2 \dagger}$ \quad
\textbf{Zhanke Zhou}$^{1}$ \quad
\textbf{Tongliang Liu}$^{3}$ \quad
\textbf{Yang Liu}$^{4}$ \\
\textbf{Kun Zhang}$^{5,6}$ \quad
\textbf{Bo Han}$^{1}\thanks{Correspondence to Bo Han (bhanml@comp.hkbu.edu.hk) and Zhun Zhong (zhunzhong007@gmail.com).}$
\end{tabular}
 \vspace{0mm} \\
 $^{1}$TMLR Group, Department of Computer Science, Hong Kong Baptist University \quad \\
 $^{2}$School of Computer Science and Information Engineering, Hefei University of Technology\\
 $^{3}$Sydney AI Centre, The University of Sydney \quad \\
        $^{4}$Computer Science and Engineering, University of California, Santa Cruz \quad \\
        $^{5}$Mohamed bin Zayed University of Artificial Intelligence \quad 
        $^{6}$Carnegie Mellon University  
}


\iclrfinalcopy
\begin{document}


\maketitle

\input{sections/0_abstract}

\input{sections/1_intro}
\input{sections/2_analysis}
\input{sections/3_method}
\input{sections/4_experiments}
\input{sections/6_conclusion}

\section*{Acknowledgements}
CTC, ZKZ, and BH were supported by RGC Young Collaborative Research Grant No. C2005-24Y, NSFC General Program No. 62376235, Guangdong Basic and Applied Basic Research Foundation Nos. 2022A1515011652 and 2024A1515012399, HKBU Faculty Niche Research Areas No. RC-FNRA-IG/22-23/SCI/04, and HKBU CSD Departmental Incentive Scheme. TLL was partially supported by the following Australian Research Council projects: FT220100318, DP220102121, LP220100527, LP220200949, and IC190100031.

\section*{Ethics Statement}
This work does not involve potential malicious or unintended uses, fairness considerations, privacy considerations, security considerations, crowdsourcing, or research with human subjects.

\section*{Reproducibility Statement}
We provide details to reproduce our results in  Sec.~\ref{sec:setting}, Sec.~\ref{sec:exp-setup}, and Sec.~\ref{app:exp-details}. We also provide pseudo-code in Algorithm~\ref{alg:ours}, and the code is publicly available at: \url{https://github.com/tmlr-group/ZS-NTTA}.


\bibliography{reference}
\bibliographystyle{iclr2025_conference}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% \newpage
\appendix

\clearpage
\etocdepthtag.toc{mtappendix}
\etocsettagdepth{mtchapter}{none}
\etocsettagdepth{mtappendix}{subsection}
	
% \part{Appendix} % Start the appendix part
% \renewcommand{\contentsname}{}
\renewcommand{\contentsname}{Appendix}
\tableofcontents
\clearpage

\input{sections/7_app_a_relatedwork}
\input{sections/7_app_c_benchmark}
\input{sections/7_app_d_exp_deteails}
\input{sections/7_app_e_ablation}
\input{sections/7_app_g_fail_res}




\end{document}