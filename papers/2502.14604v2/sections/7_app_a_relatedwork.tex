\section{Discussion}
\subsection{A Further Discussion on ZS-NTTA Setting}\label{app:discuss-setting}
We have elaborated on the distinctions between ZS-NTTA and ZS-OOD detection in Sec.~\ref{setting: why-zs-ntta}, which primarily lie in task objectives and evaluation settings. \textit{These differences also apply to the comparison between ZS-NTTA and test-time OOD detection, as the latter essentially shares the same objective as classical OOD detection.}
We further summarize the task definition differences between ZS-NTTA and \cite{fan2024test, gao2023atta} in Table~\ref{tab:setting-diff}.
In this section, we also discuss and compare existing test-time OOD detection works~\citep{fan2024test, gao2023atta} regarding methodology. RTL~\citep{fan2024test} used linear regression to make a more precise OOD prediction. In other words, RTL leverages the TTA method to enhance OOD detection while fundamentally remaining an OOD detection task. Different from RTL, we focus on the TTA setting itself, where test samples may contain noise, resulting in severe performance degradation of existing TTA methods.
ATTA~\citep{gao2023atta} primarily addresses dense OOD detection in semantic segmentation; however, ATTA cannot be extended to the ZS-NTTA setting since it relies on measuring the distributional distance between test and training features in the normalization layers of the segmentation network. In the context of pretrained VLMs like CLIP, we don't have access to the training data, making ATTA's approach inapplicable to our setting.

In the era of Foundation Models (FMs), we believe noisy TTA can be further explored. The input to FMs may encompass diverse types of noise, including irrelevant or erroneous information~\citep{zhou2024can, shi2023large}, as well as malicious prompts~\citep{wei2024jailbroken, li2023deepinception}, which can significantly undermine the reasoning capabilities of FMs. How to address these noise inputs during testing while enhancing the reasoning capabilities of FMs is an important research direction.

\begin{table}[ht]
% \vspace{-10pt}
  \caption{Comparison between ZS-NTTA and test-time OOD detection setting~\citep{fan2024test, gao2023atta}.}
%   \scriptsize
  \label{tab:setting-diff}
  % \vspace{5pt}
  \centering
  \resizebox{\linewidth}{!}{%
  \begin{tabular}{l*{3}c}
    \toprule
      & \cite{fan2024test} & \cite{gao2023atta} &  ZS-NTTA  \\
  \midrule
    Focus on ID classification & $\times$ & $\times$ & $\checkmark$ \\
    Focus on OOD detection & $\checkmark$ & $\checkmark$ & $\checkmark$ \\
    Evaluate ID classification & Clean data stream & Clean data stream & Noisy data stream \\
    Metrics & AUROC, FPR95 & AUROC, FPR95 & Harmonic mean accuracy~($\text{Acc}_\text{H}$) \\
    Domain shift & $\times$ & $\checkmark$ & $\checkmark$ \\
    Online evaluation & $\times$ & $\times$ & $\checkmark$ \\
    Zero-shot & $\times$ & $\times$ & $\checkmark$ \\

  \bottomrule
  \end{tabular}
}
\end{table}


\subsection{Limitation}\label{app:limitation}
In our ablation study~(Table~\ref{app-tab:pseudo-labels}), we discussed why we use the outputs of the frozen model as pseudo-labels. However, in practice, using the outputs of the noise detector as pseudo-labels can perform better than the frozen model on most ID datasets. Due to cumulative errors in the noise model’s outputs, performance can \textit{significantly drop} on a few ID datasets. Therefore, we chose the frozen model’s outputs for a more balanced performance. In future work, we aim to explore how to use the noise detector’s outputs as pseudo-labels while ensuring they work well on all datasets, thus achieving stronger performance in the ZS-NTTA task.

Moreover, we utilize the detection results from ZS-CLIP as pseudo labels because CLIP's zero-shot OOD detection capabilities have been thoroughly investigated~\citep{ming2022delving, wang2023clipn, jiang2024neglabel, esmaeilpour2022zero} and have demonstrated exceptional accuracy across diverse ID/OOD datasets. However, our method may also falter in scenarios where zero-shot CLIP's detection accuracy is significantly low. Under such circumstances, all existing zero-shot OOD detection methods would also fail. To address this, We may leverage the target data to fine-tune the model, potentially achieving better classification and detection accuracy.



\section{Related Work}
\paragraph{Test-time Adaptation.}
Test-time adaptation~(TTA)~\citep{wang2021tent, liang2023ttasurvey, niu2022efficient, fleuret2021test, boudiaf2022parameter, prabhudesai2023diffusion, lee2024entropy, gui2024atta} aims to bolster a model's generalization to the target distribution. 
Given the unavailability of source distribution data in the test phase, various TTA methods have been proposed. Some methods~\citep{wang2021tent, niu2022efficient, fleuret2021test} leverage self-supervised strategies like entropy minimization, while others employ techniques such as batchnorm statistics adaptation~\citep{schneider2020improving, nado2020evaluating} to improve performance on the target distribution.
Some works~\citep{shu2022test, feng2023diverse, karmanov2024efficient, samadh2023align, ma2024swapprompt, zhao2024testtime, yoon2024ctpt} tackle the TTA problem with VLMs. TPT~\citep{shu2022test} and DiffTPT~\citep{feng2023diverse} learn adaptive text prompts with a single test sample employing entropy minimization. TDA~\citep{karmanov2024efficient} uses a training-free dynamic adapter to enable efficient TTA in vision-language models. However, they did not consider how to handle the presence of noisy samples in the data stream. In this work, we consider the possibility of noisy data streams during the TTA process and cover the clean data stream case.

\paragraph{Noisy Test-time Adaptation.}
Recent works have considered noisy scenarios during the TTA process, and their emphasis has been solely on task-specific models utilizing visual data exclusively. Specifically, SoTTA~\citep{gong2023sotta} proposed using high-confidence samples to update the model, but they did not consider detecting noisy samples and only focused on the classification accuracy of ID samples. OWTTT~\citep{li2023robustness} developed an adaptive threshold strategy for noisy TTA, but OWTTT relies on source domain prototype clustering, which is unavailable for VLMs like CLIP. \citet{lee2023towards} proposed utilizing the confidence difference between the original and adaptation models, but ~\citet{lee2023towards} considered the long-term adaptation scenario, and this strategy may not effectively filter out the desired samples in the short-term adaptation scenario. Differing from these works, we introduce the zero-shot noisy TTA setting, which is more practical by leveraging the zero-shot capability of pre-trained VLMs.



\paragraph{OOD Detection.}
Different from the TTA setting, OOD detection~\citep{hendrycks17baseline, yang2022openood, yang2021generalized, fang2022out, du2022vos, huang2021mos, hendrycks2019anomalyseg, hendrycks2019oe, sehwag2021ssd} focuses on data with different label spaces. The goal is to detect OOD samples that are outside the label space of the training set. Most OOD detection methods~\citep{hendrycks17baseline, hendrycks2019scaling, liu2020energy, ming2022delving, jiang2024neglabel, esmaeilpour2022zero} design a score function based on the confidence of the model's output, implementing detection in a post-hoc manner. 
While SAL~\citep{du2024does} also leverages unlabeled test data to train robust OOD classifiers, our work differs in its focus and contribution. We primarily address the ZS-NTTA task, where our core contribution lies in proposing a conceptual framework that decouples the detector from the classifier. This decoupling prevents classifier degradation during noisy sample adaptation, with pseudo-label-based detector training serving merely as one implementation detail of our approach.
Recent work~\citep{ming2022delving, jiang2024neglabel, wang2023clipn, cao2024envisioning} explores zero-shot OOD detection by leveraging pre-trained VLMs.
MCM~\citep{ming2022delving} constructs the classifier using ID class names and uses the maximum predicted softmax value between image and text features as the OOD score. CLIPN~\citep{wang2023clipn} and NegLabel~\citep{jiang2024neglabel} enhance detection performance by mining negative information. EOE~\citep{cao2024envisioning} leverages LLMs' embedded expert knowledge to envision outlier exposure without requiring actual OOD data.
Unlike the zero-shot OOD detection setting, ZS-NTTA requires noisy samples to be detected online. What's more, existing OOD detection methods focus more on detecting OOD samples and do not consider how to improve the classification accuracy of ID samples.


\paragraph{Pre-trained Vision-Language Models.}
Pre-trained vision-language models such as CLIP~\citep{radford2021learning}, ALIGN~\citep{jia2021scaling}, and GroupViT~\citep{xu2022groupvit} typically comprise an image encoder and a text encoder. They are trained on hundred-million-level image-text pair data using self-supervised contrastive learning~\citep{chen2020simple}. In the testing phase, VLMs encode input images and texts into embedding vectors and then carry out classification by comparing the similarity between image and text features. VLMs demonstrate excellent generalization capabilities due to the broad coverage of the training data distribution and the robust feature representations learned through contrastive learning. They have also been effectively applied to downstream tasks like image retrieval and image classification in a zero-shot manner.