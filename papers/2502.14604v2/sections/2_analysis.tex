\section{Zero-shot Noisy TTA}\label{sec:setting}

\paragraph{Definition of In-Distribution in VLMs.}
Following zero-shot OOD detection~\citep{ming2022delving, esmaeilpour2022zero, jiang2024neglabel}, in our setting, the in-distribution (ID) classes are defined based on the classification task of interest rather than the classes used in pre-training. Accordingly, noisy samples are defined as data outside the ID label space.

\vspace{-5pt}
\paragraph{Problem Formulation.}
We define the test set $\mathcal{D} = \{\mathcal{X}, \mathcal{Y}_\text{id} \cup \mathcal{Y}_\text{noisy}\}$, where $\mathcal{X}$ indicates the input space, $\mathcal{Y}_\text{id}$ represents the ID label space, and $\mathcal{Y}_\text{noisy}$ denotes the noisy label space. We are given input samples $\{x_i\} \in \mathcal{X}$, the ID class names $\mathcal{Y}_\text{id} = \{y_1, y_2, ..., y_K\}$ with $K$ classes, and pre-trained VLMs. 
Owing to being trained on vast amounts of data, VLMs have learned robust feature representations, thereby enabling classification in a zero-shot manner.
Due to noisy samples in the test data stream, we first detect whether an input sample is noisy. If the sample is identified as clean, it is classified using the VLM. It is directly categorized without further classification if recognized as a noisy sample.


\vspace{-5pt}
\paragraph{Why Investigating ZS-NTTA is Meaningful and Practical.}\label{setting: why-zs-ntta}
One cannot ignore the noisy samples in real-world TTA deployment since the real world is open and full of unknown samples. We have demonstrated that the noisy sample is a significant obstacle to existing TTA methods in Sec.~\ref{sec:failure-case-study}. While ZS-OOD detection~\citep{ming2022delving, jiang2024neglabel, esmaeilpour2022zero} considers noisy samples, it primarily focuses on the model's detection capability rather than improving the classification capability for ID data. More critically, the ID classification in existing ZS-OOD detection methods is typically evaluated in a closed-world setting, assuming a clean data stream.
In contrast,  ZS-NTTA requires detecting noisy samples online, placing greater emphasis on classification accuracy in open-world settings. 
We also discuss and compare existing test-time OOD detection work~\citep{fan2024test, gao2023atta} in Appendix~\ref{app:discuss-setting}.
What's more, leveraging VLMs, ZS-NTTA can be performed in a zero-shot manner, making it more practical than noisy TTA. 



\vspace{-5pt}
\paragraph{Evaluation Protocol.}\label{sec:analysis-protocol}
We use three metrics to evaluate the performance in ZS-NTTA: $\text{Acc}_\text{S}$, $\text{Acc}_\text{N}$, and $\text{Acc}_\text{H}$. $\text{Acc}_\text{S}$ measures classification accuracy on clean samples\footnote{Note that, if a clean sample is recognized as a noisy sample, it is wrongly classified.}, $\text{Acc}_\text{N}$ measures detection accuracy on noisy samples, and $\text{Acc}_\text{H}$ is the harmonic mean of $\text{Acc}_\text{S}$ and $\text{Acc}_\text{N}$, providing a balanced measure of both accuracies. The specific formulations of these metrics are as follows:
{\scriptsize
\begin{equation}
    % \scriptsize
    \text{Acc}_\text{S}=\frac{\sum_{x_i, y_i \in \mathcal{D}} \mathbb{1}(y_i=\hat{y}_i) \cdot \mathbb{1}(y_i \in \mathcal{Y}_\text{id})}{\sum_{x_i, y_i \in \mathcal{D}} \mathbb{1}(y_i \in \mathcal{Y}_\text{id})},~ \text{Acc}_\text{N}=\frac{\sum_{x_i, y_i \in \mathcal{D}} \mathbb{1}(\hat{y}_i \in \mathcal{Y}_\text{nosiy}) \cdot \mathbb{1}(y_i \in \mathcal{Y}_\text{nosiy})}{\sum_{x_i, y_i \in \mathcal{D}} \mathbb{1}(y_i \in \mathcal{Y}_\text{nosiy})},~
    \text{Acc}_\text{H}=2 \cdot \frac{\text{Acc}_\text{S} \cdot \text{Acc}_\text{N}}{\text{Acc}_\text{S}+\text{Acc}_\text{N}}.
\end{equation}
}

\vspace{-5pt}
\paragraph{Simple Baseline.}
We introduce a simple yet effective baseline named ZS-CLIP, employing the MCM~\citep{ming2022delving} score as our score function to evaluate the confidence of the model's output for detecting noisy samples.
Following zero-shot OOD detection~\citep{ming2022delving}, we construct the classifier using ID class names and perform classification based on the cosine similarity between the input image feature $\mathcal{I}(x_i)$ and text features $\{\mathcal{T}(t_k)\}_{k=1}^{K}$.
We define the cosine similarity between the image and text features as follows:
$s_k(x_i) = \frac{\mathcal{I}(x_i) \cdot \mathcal{T}(t_k)}{\lVert \mathcal{I}(x_i)\rVert \cdot \lVert \mathcal{T}(t_k) \rVert}$. Here, $\mathcal{I}$ denotes the image encoder, and $\mathcal{T}$ signifies the text encoder. $x_i$ represents the input sample, and $t_k$ is the text prompt ``\texttt{this is a photo of a $\langle y_k \rangle$}'' corresponding to the ID class name $y_k$.
We can detect the input sample through the noise detector $G(\cdot)$:
\begin{equation}\label{eq:binary_classification}
% \scriptsize
% \small
    % \vspace{-2pt}
    G_{\lambda}(x_i)=\begin{cases} 
      \text{Clean} & S(x_i)\ge \lambda \\
      \text{Noise} & S(x_i) < \lambda 
   \end{cases},
   ~~~~\text{where}~~~~
   S(x_i) = \max_k \frac{e^{s_k(x_i)/\tau}}{\sum_{j=1}^K e^{s_j(x_i)/\tau}},
    % \vspace{-2pt}
\end{equation}

where $\lambda$ is the threshold, $S(\cdot)$ denotes the MCM score, and $\tau$ is the temperature. If the sample is detected as clean, we then use the text-based classifier to classify it.

\vspace{-5pt}
\paragraph{Adaptive Threshold.}
Various ID datasets can be encountered in ZS-NTTA, making a fixed threshold $\lambda$ suboptimal. Therefore, an adaptive threshold is a better choice. 
According to OWTTT~\citep{li2023robustness}, the distribution of OOD scores follows a bimodal distribution. Based on this observation, \citet{li2023robustness} proposes minimizing intra-class variance to determine the adaptive threshold:
{\small
    \begin{equation}
    \label{eq:adaptive_threshold}
    \min_\lambda \frac{1}{N_\text{id}} \sum_i {[S(x_i)-\frac{1}{N_\text{id}}\sum_j \mathbb{1}(S(x_j)>\lambda)S(x_j)]^2} + 
    \frac{1}{N_\text{ood}}\sum_i{[S(x_i)-\frac{1}{N_\text{ood}}\sum_j \mathbb{1}(S(x_j)\leq\lambda)S(x_j)]^2},
    \end{equation}
}
where $N_\text{id}=\sum_i^{N_\text{q}} \mathbb{1}(S(x_i)>\lambda)$, $N_\text{ood}=\sum_i^{N_\text{q}} \mathbb{1}(S(x_i)\leq\lambda)$ and $N_\text{q}$ is the length of a queue at test-time to update the score distribution. 
However, the score in OWTTT relies on source prototypes, which are unavailable in pre-trained VLMs. Here, we propose using the MCM score as an alternative. Furthermore, we conduct experiments with various fixed thresholds ranging from $0.1$ to $0.9$ to validate the reliability of our adaptive threshold, as detailed in Appendix~\ref{app:adaptive_threshold}. The averaged results across different ID datasets indicate that the adaptive threshold outperforms fixed threshold.


\section{A Comprehensive Analysis of Zero-shot Noisy TTA}
\label{sec:analysis}
In this section, we introduce our ZS-NTTA benchmark and provide a comprehensive analysis of the performance of current TTA methods for this task.
\subsection{Zero-shot Noisy TTA Benchmark}\label{sec:analysis-benchmark}
\paragraph{Benchmark Datasets.}\label{sec:analysis-dataset}
To prevent overlap in label spaces of noisy and clean samples, we use established ID-OOD dataset\footnote{ID datasets and clean datasets are interchangeable, as are OOD datasets and noisy datasets.} pairs from standard OOD detection benchmarks.
The ID datasets include CIFAR-10/100~\citep{krizhevsky2009learning}, CUB-200-2011~\citep{wah2011caltech}, STANFORD-CARS~\citep{krause20133d}, Food-101~\citep{bossard2014food}, Oxford-IIIT Pet~\citep{parkhi2012cats}, ImageNet~\citep{deng2009imagenet}, ImageNet-V2~\citep{recht2019imagenet}, ImageNet-A~\citep{hendrycks2021natural}, ImageNet-R~\citep{hendrycks2021many}, and ImageNet-Sketch~\citep{wang2019learning}. The OOD datasets encompass SVHN~\citep{netzer2011reading}, LSUN~\citep{yu2015lsun}, iNaturalist~\citep{van2018inaturalist}, SUN~\citep{xiao2010sun}, Places~\citep{zhou2017places}, and Texture~\citep{cimpoi2014describing}. The specific ID-OOD pairs are detailed in Table~\ref{tab:id-ood-pairs} in Appendix~\ref{app:dataset_details}.

\vspace{-5pt}
\paragraph{Evaluated Methods.}\label{sec:benchmark-methods}
We evaluate ZS-CLIP~\citep{radford2021learning}, Tent~\citep{wang2021tent}, SoTTA~\citep{gong2023sotta}, and TPT~\citep{shu2022test} in our benchmarks. ZS-CLIP keeps all parameters frozen and utilizes Eq.~\eqref{eq:binary_classification} to determine whether an input sample $x_i$ belongs to the clean or noisy set. Samples identified as clean, denoted as $x_i'$, are then subjected to further classification. The other methods also utilize Eq.~\eqref{eq:binary_classification} to filter samples, subsequently using $x_i'$ to update the model. Specifically, Tent updates the normalization layers within the image encoder by entropy minimization. SoTTA stores $x_i'$ to a memory bank and selects the highest confidence samples to update the model every $64$ steps using entropy-sharpness minimization. 
TPT applies data augmentation to $x_i'$ and updates the text prompt through entropy minimization. 


\subsection{Failure Case Study}\label{sec:failure-case-study}
In this subsection, we analyze the failure case illustrated in Figure~\ref{fig:violin}, \textit{i.e.}, ZS-CLIP outperforms most tuning-based methods on most ID datasets, highlighting three key observations. 
We begin by introducing three designed model adaptation pipelines to illustrate the impact of noisy samples on model adaptation~(Observation~\ref{observation1}).
% understand the failure case. 
Subsequently, we visualize the score difference between ZS-CLIP and tuning-based methods to understand the failure case~(Observation~\ref{observation2}).
% illustrate the impact of noisy samples on model adaptation.
Finally, we delve into the underlying reasons for the significant negative impact of noisy samples on model adaptation by conducting analyses of the model's gradients~(Observation~\ref{observation3}).

\begin{observation}\label{observation1}
Noisy samples have a significant negative impact on model adaptation during TTA.
\end{observation}
\vspace{-5pt}
To investigate the impact of noisy samples in TTA, we construct three pipelines for each fine-tuning approach: \texttt{Ground Truth~(GT)}, \texttt{Normal}, and \texttt{All-update} pipelines. The \texttt{GT} pipeline updates the model parameters using only the ground truth clean data, which is unavailable in practice. The \texttt{Normal} pipeline updates the parameters using the data filtered by Eq.~\eqref{eq:binary_classification}, which may include some noisy data, and this is the pipeline adopted in our main results~(Sec.~\ref{sec:exp}). The \texttt{All-update} pipeline updates the model parameters using all the available data, \textit{i.e.}, it includes all the noisy data.

Table~\ref{tab:failure_case_study} presents the performance of the three pipelines using CIFAR-10 as the ID dataset. The performance hierarchy observed for most methods is \texttt{GT} $>$ ZS-CLIP $>$ \texttt{Normal} $>$ \texttt{All-update}. This indicates that for the \texttt{Normal} pipeline, the negative impact of the unfiltered noisy data on model adaptation outweighs the benefits of the clean data, resulting in performance inferior to that of ZS-CLIP. 
SoTTA is on par with ZS-CLIP within the \texttt{Normal} pipeline due to its refined sample selection for model adaptation. SoTTA employs a memory bank to store high-confidence samples, utilizing only those with the highest confidence samples for updating the model. This strategy effectively filters out the majority of noisy samples, aligning with our assertion that noisy samples significantly and negatively impact model adaptation. Nonetheless, the improvement of SoTTA over ZS-CLIP remains marginal.
For failure cases involving more ID datasets, please refer to Appendix~\ref{app:failure case-classification}. 


\begin{table}
\caption{Failure case study of existing TTA methods with CIFAR-10 as the ID dataset. \textcolor{teal}{Green} indicates an improvement over ZS-CLIP in average $\text{Acc}_\text{H}$, while \textcolor{red}{red} indicates the opposite.}\label{tab:failure_case_study}
\centering{
\setlength\tabcolsep{5pt} 
\resizebox{\linewidth}{!}{
% \fontsize{7}{8}\selectfont
% \setlength\tabcolsep{2pt}
\begin{tabular}{lccc|ccc|ccc|ccc|ccc}
\toprule
\multirow{2}*{Method}&\multicolumn{3}{c}{SVHN}&\multicolumn{3}{c}{LSUN}&\multicolumn{3}{c}{Texture}&\multicolumn{3}{c}{Places}&\multicolumn{3}{c}{Avg}\\
\cmidrule{2-16}
&$\text{Acc}_\text{S}$&$\text{Acc}_\text{N}$&$\text{Acc}_\text{H}$&$\text{Acc}_\text{S}$&$\text{Acc}_\text{N}$&$\text{Acc}_\text{H}$&$\text{Acc}_\text{S}$&$\text{Acc}_\text{N}$&$\text{Acc}_\text{H}$&$\text{Acc}_\text{S}$&$\text{Acc}_\text{N}$&$\text{Acc}_\text{H}$&$\text{Acc}_\text{S}$&$\text{Acc}_\text{N}$&$\text{Acc}_\text{H}$\\
\cmidrule(lr){2-4}\cmidrule(lr){5-7}\cmidrule(lr){8-10}\cmidrule(lr){11-13}\cmidrule(lr){14-16}
ZS-CLIP
& 83.55 & 98.39 & 90.36 & 83.11 & 97.82 & 89.87 & 82.18 & 91.82 & 86.73 & 81.73 & 76.26 & 78.90 & 82.64 & 91.07 & 86.47\\
Tent~(GT)
& 90.77 & 96.99 & 93.78 & 90.40 & 93.55 & 91.95 & 90.07 & 90.22 & 90.14 & 89.87 & 74.50 & 81.47 & 90.28 & 88.81 & 89.34~\textcolor{teal}{(+2.87\%)}\\
Tent~(Normal)
& 87.18 & 52.90 & 65.85 & 89.03 & 73.96 & 80.80 & 89.78 & 88.48 & 89.13 & 88.78 & 65.44 & 75.34 & 88.69 & 70.19 & 77.78~\textcolor{red}{(-8.69\%)}\\
Tent~(All-update)
& 81.74 & 43.13 & 56.47 & 80.17 & 55.59 & 65.65 & 89.28 & 84.64 & 86.90 & 87.86 & 56.27 & 68.60 & 84.76 & 59.91 & 69.41~\textcolor{red}{(-17.06\%)}\\
SoTTA~(GT)
& 90.45 & 97.47 & 93.83 & 90.03 & 94.88 & 92.39 & 89.68 & 91.39 & 90.53 & 89.30 & 75.96 & 82.09 & 89.87 & 89.92 & 89.71~\textcolor{teal}{(+3.25\%)}\\
SoTTA~(Normal)
& 90.21 & 81.71 & 85.75 & 90.13 & 91.06 & 90.59 & 89.56 & 90.96 & 90.25 & 89.04 & 74.17 & 80.93 & 89.73 & 84.47 & 86.88~\textcolor{teal}{(+0.42\%)}\\
SoTTA~(All-update)
& 89.69 & 73.13 & 80.57 & 89.88 & 90.76 & 90.32 & 89.47 & 90.54 & 90.00 & 89.05 & 74.50 & 81.13 & 89.52 & 82.23 & 85.50~\textcolor{red}{(-0.96\%)}\\
TPT~(GT)
& 85.86 & 98.46 & 91.73 & 85.86 & 98.00 & 91.53 & 85.19 & 92.30 & 88.60 & 84.88 & 77.33 & 80.93 & 85.45 & 91.52 & 88.20~\textcolor{teal}{(+1.73\%)}\\
TPT~(Normal)
& 81.76 & 98.85 & 89.50 & 81.53 & 97.93 & 88.98 & 80.43 & 92.11 & 85.87 & 79.88 & 77.18 & 78.51 & 80.90 & 91.52 & 85.72~\textcolor{red}{(-0.75\%)}\\
TPT~(All-update)
& 85.18 & 96.98 & 90.70 & 84.84 & 91.15 & 87.88 & 83.92 & 75.36 & 79.41 & 83.59 & 54.11 & 65.69 & 84.38 & 79.40 & 80.92~\textcolor{red}{(-5.55\%)}\\

\bottomrule
\end{tabular}}
}
\end{table}

\begin{figure*}
\centering
\begin{subfigure}{0.28\textwidth}
\centering
\includegraphics[width=\textwidth]{figs/ZS-CLIP_CIFAR-10_ViT-B_16_SVHN_1.0_normal_mode_bs_1_adaptive.pdf}
\caption{ZS-CLIP}\label{fig:failure_case_score-zsclip}
\end{subfigure}
\hfill
\begin{subfigure}{0.28\textwidth}
\centering
\includegraphics[width=\textwidth]{figs/Tent_CIFAR-10_ViT-B_16_SVHN_1.0_normal_mode_bs_64_adaptive.pdf}
\caption{Tent}\label{fig:failure_case_score-tent}
\end{subfigure}
\hfill
\begin{subfigure}{0.35\textwidth}
\centering
\includegraphics[width=\textwidth]{figs/Tent_CIFAR-10_ViT-B_16_SVHN_1.0_normal_mode_bs_64_adaptive_diff.pdf}
\caption{Score difference}\label{fig:failure_case_score-diff}
\end{subfigure}
\vspace{-.05in}
\caption{Failure case analysis of Tent~\citep{wang2021tent} in ZS-NTTA. \textbf{(a)} and \textbf{(b)} show the score distributions of ZS-CLIP and Tent, respectively, revealing that Tent makes it difficult to distinguish between clean and noisy samples. The horizontal axis is the value of OOD score. \textbf{(c)} illustrates the score difference between Tent and ZS-CLIP, indicating that the confidence of noisy samples tends to increase in Tent. ID dataset: CIFAR-10; OOD dataset: SVHN.}\label{fig:failure_case_score}
\vspace{-10pt}
\end{figure*}


\begin{figure*}[!t]
\begin{center}
\includegraphics[width=\textwidth]{figs/gradients.pdf}
\end{center}
  \vspace{-.1in}\caption{The impact of clean and noisy samples on the gradients.
Note that the gradients of noisy samples are substantially larger in the first and second stages. The model effectively filters out noisy samples in the first stage but gradually struggles to distinguish between clean and noisy samples.
ID dataset: CIFAR-10; OOD dataset: SVHN; Batch size: $64$. Please see Figure~\ref{app-fig:fail-gradient} for an enlarged view.}\label{fig:failure_case_gradient}
  \vspace{-10pt}
\end{figure*}

\begin{observation}\label{observation2}
Throughout the model adaptation process in Tent, the scores of noisy samples gradually increase, ultimately rendering the MCM score incapable of distinguishing noisy samples.
\end{observation}
\vspace{-5pt}
We show the score distributions for ZS-CLIP and Tent under the \texttt{Normal} pipeline in Figures~\ref{fig:failure_case_score-zsclip} and~\ref{fig:failure_case_score-tent} to better understand the impact of unfiltered noisy samples on model adaptation.
Additionally, Figure~\ref{fig:failure_case_score-diff} depicts the score differences for the same input sample between Tent and ZS-CLIP. ZS-CLIP effectively separates ID and OOD score distributions. In contrast, the increase in scores for most noisy samples in Tent makes the distinction between clean and noisy samples difficult. For the analysis of TPT, please refer to Appendix~\ref{app:anaylsis-TPT}.


\begin{observation}\label{observation3}
MCM score with the adaptive threshold can detect most noisy samples during the early stages of TTA in Tent, though some inaccuracies may remain.
However, these few inaccuracies during the early TTA stages can gradually lead the model to overfit to noisy samples.
\end{observation}
\vspace{-5pt}
We analyze the model's gradients in Tent under the \texttt{Normal} pipeline to understand why noisy samples negatively impact model adaptation.
Figure~\ref{fig:failure_case_gradient} shows how clean and noisy samples affect the gradients of the final layer normalization in the image encoder during TTA.
As for clean samples, the model's gradients gradually decrease and remain relatively stable. 
The impact of noisy samples on the model's gradients can be roughly divided into three stages.
\vspace{-5pt}
\begin{itemize}[leftmargin=.1in]
    \item \textbf{First Stage:} The model effectively filters out noisy samples, with only a minimal number being erroneously classified as clean samples. 
    \item \textbf{Second Stage:} The model's performance progressively declines as the impact of noisy samples becomes more apparent. The reliability of the MCM score weakens, and the model increasingly struggles to identify noisy samples. Moreover, the gradient magnitude of the noisy samples remains significant during this stage.
    \item \textbf{Final Stage:} The model overfits to the noisy samples, resulting in a decrease in the model's gradient magnitude. At this stage, it almost loses the ability to distinguish between clean and noisy samples.
\end{itemize}
\vspace{-5pt}
Note that TPT resets the model at each step, meaning noisy samples' influence on the model's updates does not be accumulated. As a result, the impact of noisy samples on TPT is relatively smaller compared to Tent. Nonetheless, learning with noisy samples, with model reset at each step, still results in TPT performing worse than ZS-CLIP.

To this end, we naturally consider whether decoupling the classifier and detector might be a superior strategy for the ZS-NTTA task. On one hand, focusing on developing a robust detector can more effectively distinguish noisy samples. On the other hand, keeping the classifier frozen can prevent it from the adverse effects of adapting to noisy samples.