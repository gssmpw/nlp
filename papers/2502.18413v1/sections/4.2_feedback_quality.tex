\section{Feedback Quality}
To understand whether the ranking changes in Section \ref{sec:static_vs_interactive_perf} are due to variations in feedback quality across models, we develop a proxy for feedback quality and examine its effect on how \cm s interact with feedback.


\subsection{Quality Metrics}
Previous works infer feedback quality by the feedback's effect on performance \cite{zhang2023clarifynecessaryresolvingambiguity}.  
Instead of relying only on performance, we classify feedback by \textbf{directional correctness}, a binary value of whether it accurately claims that the code solution was correct or incorrect. 
For instance, if the solution is incorrect (i.e. has $\textsc{TCA} < 1$), but the feedback claims that the solution is correct, then we consider the feedback \lqf.
However, if the solution is correct (i.e. has $\textsc{TCA} = 1$) and the feedback claims that it is correct, we consider it \hqf.

We automate the classification via \gpt{} on \sent, \para, and \cf{}.\footnote{\ir{} does not provide direct feedback on the solution, so it is not eligible for our quality metric.}
Appendix \ref{app:fq} discusses other feedback quality metrics we considered, as well as additional information on the classification protocol. 

\subsection{Results}


\paragraph{Directional correctness is consistently high across models and feedback types.}
Table \ref{tab:feedback_quality_max_step_number} compares average directional correctness by feedback type, which does not vary greatly across models or feedback types and often reaches above $0.8$.
This suggests that the feedback is high enough quality to compare across models and feedback types.
Although \para{} and \cf{} feedback induce the highest performances, \para{} feedback tends to have the highest directional correctness, whereas \cf{} tends to have the lowest.

\paragraph{Code models are generally robust to \lqf{} feedback.}
Figure~\ref{fig:effect_of_fq} shows the distribution of solutions whose performances improve versus decrease when comparing \hqf{} feedback to \lqf{} feedback. 
Although \hqf{} feedback has a higher rate of solutions whose performances improve, the rate of directionally \textit{incorrect} feedback that results in improved performance is still substantial.
For instance, \sonnet{} has equal rates of improved performance after either \hqf{} or \lqf{} \para{} and \sent{} feedback.

\paragraph{For stronger models, \hqf{} \cf{} tend to worsen post-feedback solutions than \lqf{} \cf.} While all \hqf{} feedback have roughly similar effects on the rate of improved post-feedback solutions, \para{} and \sent{} also decrease the proportion of worse post-feedback solutions (Figure \ref{fig:effect_of_fq}, center and right).
\cf{} is the only feedback type where stronger models (e.g., \sonnet, \gpt, \qwenLarge) are more likely to generate a worse solution when given \hqf{} feedback rather than \lqf{} (Figure \ref{fig:effect_of_fq}, left).



