\section{Related Work}

This section reviews prior work on metaphorical visual design, examines AI-driven image generation for creativity support, and evaluates methods for representing abstract concepts visually.

\subsection{Metaphors in Visual Design}




Metaphors are powerful tools in visual design that engage audiences by suggesting meaning rather than explicitly stating it. 
By linking familiar concepts (source domain) to visual elements (target domain), they promote intuitive understanding and foster deeper audience engagement~\cite{4308795}.
Moreover, by leaving room for interpretation, metaphors encourage active participation, prompting users to uncover nuanced connections within the visual elements~\cite{Duit1991-DUIOTR}.
This characteristic of metaphors is utilized in visual design to facilitate data comprehension and emotional connection~\cite{da2016semantic}.
For example,  
Sun et al.~\cite{10.1145/3357236.3395475} used a postcard with a landscape painting to represent users' physical and mental health metaphorically.
\textit{Metamorpheus}~\cite{10.1145/3613904.3642410} used visual metaphors to facilitate the exploration and reflection of users' dream experiences in a meaningful way.
These representations enhance the intuitive perception and interpretation of information, while metaphors serve as visual cues to facilitate understanding of underlying meaning.




Beyond their ability to engage and inform, metaphors also excel at creative communication~\cite{doi:10.1207/s15327868ms}, a strength evidenced by their extensive use in advertising and graphic design.
Prior research has examined the structural topology of metaphors in visual representation~\cite{Peterson02012019}, identifying three primary categories: juxtaposition, fusion, and replacement structures. 
In the context of fusion-based visual metaphors, Chilton et al. pioneered \textit{VisiBlends}~\cite{10.1145/3290605.3300402} to assist novices in creating initial blend prototypes by overlaying two objects with the same shape.
They later introduced \textit{VisiFit}~\cite{10.1145/3411764.3445089}, a tool that aids novice users in collaboratively generating visual blends through brainstorming, synthesizing, and iterating. 
Other research efforts have also produced creative support tools, such as \textit{MetaMap}~\cite{10.1145/3411764.3445325}, to assist users in incorporating metaphors into their visual designs.
While existing research has advanced the creation of visual metaphors, it often overlooks the diverse interpretations that specific imagery can evoke.
This narrow focus limits the expressive potential of visual metaphors and constrains the creation of innovative representations of meaning.  
Our research aims to expand the boundaries of design possibilities by leveraging visual-textual correspondence to explore diverse interpretations of semantic concepts, enabling designers to explore a wider range of metaphorical visual designs.



\subsection{Support Image Creation with Generative AI}


As an emerging field, research is increasingly exploring the role of generative AI in creative image design processes.
Prior work has examined the potential of generative models to enhance creativity~\cite{10.1145/3491101.3503549,10.1145/3664595}, laying the groundwork for our exploration of visual blend ideation.
Several works focus on \textit{divergent challenges}, aiming to expand creative possibilities by enabling users to explore diverse outputs.
Tools such as \textit{CreativeConnect}~\cite{10.1145/3613904.3642794} promote divergent ideation by recombining visual references.
Other works like \textit{GANCollage}~\cite{10.1145/3563657.3596072} use mood boards to encourage broad exploration of visual styles, while \textit{DesignPrompt}~\cite{10.1145/3643834.3661588} integrates multi-modal inputs, including text, color, and images, to expand the scope of design possibilities. 
This supports our goal of leveraging multimodal information to enhance idea generation, enabling greater creative expression and broader exploration of design concepts.


Another set of works addresses \textit{convergent challenges}, catering to the need to refine and focus creative outputs by aligning generated content with user-defined goals.
For example, \textit{PromptCharm}~\cite{10.1145/3613904.3642803} and \textit{RePrompt}~\cite{10.1145/3544548.3581402} primarily use text-based inputs, automating prompt refinement and providing real-time model explanations to fine-tune and align generative outputs with user intentions.
\textit{GenQuery}~\cite{10.1145/3613904.3642847} provides iterative refinement workflows that enable users to adapt generated content through query concretization and image modification progressively. 
These methods prioritize user control, addressing the challenge of balancing generative outputs with refinement to create tailored results.
Despite advancements in generative models for image creation, their application in multi-object blending for design exploration is limited.
Our research focuses on the ideation stage, aiming to stimulate divergent thinking through the use of image-text embeddings and commonsense knowledge, enabling an iterative exploration of a diverse range of visual possibilities driven by user input.





\subsection{Visualizing Abstract Concepts}



Abstract concepts refer to ideas or thoughts devoid of physical form or concrete qualities. 
They cannot be directly sensed and often represent intangible qualities, relationships, or processes~\cite{Borghi2022}. 
Visualizing abstract concepts presents challenges due to their intangible and often subjective nature.
Recent advancements 
leverage multimodal systems, metaphorical reasoning, and creative blending techniques to make abstract concepts more interpretable, relatable, and engaging.
Prior work, such as the framework developed by Liao et al.~\cite{Liao_Chen_Fu_Du_He_Wang_Han_Zhang_2024}, has demonstrated the potential of leveraging LLMs and T2I models to generate visual representations of abstract concepts like morality, fairness, and priority. Similarly, Liu et al. introduced \textit{Opal}~\cite{10.1145/3526113.3545621}, a multimodal framework that deals with abstract words with recognizable subjects like symbols, showing how integrating text and visual elements fosters the understanding of abstract narratives.
These works leverage T2I generation as a powerful tool for creating visual interpretations of abstract concepts.



Another body of research employs metaphors~\cite{chakrabarty-etal-2023-spy} to bridge the gap between abstract concepts and visual representations.
For instance, \textit{Vismantic}~\cite{xiao2015vismantic} emphasizes the use of semantic structures to guide the generation of meaningful blends, demonstrating how metaphorical visuals rooted in commonsense knowledge can enhance the interpretation of abstract ideas.
Cunha et al.~\cite{10.1007/s00354-020-00107-x} demonstrate how blending visual elements could produce creative representations of abstract ideas, such as combining facial expressions and symbols to create new emojis that convey complex meanings.
In contrast to prior approaches that focus on specific forms of blending or concrete representations, our method emphasizes expanding the exploration space for abstract concepts. This allows for flexible and diverse visual outputs, enriching the ideation process for designers and creators.


Visual blending techniques~\cite{ge2021visualconceptualblendinglargescale,10.1145/3290605.3300402,10.1145/3411764.3445089} have also been extensively explored to craft visual representations of abstract ideas.
Ge and Parikh~\cite{ge2021visualconceptualblendinglargescale} advanced this field by integrating vision and language models to synthesize blended visuals, enhancing the conceptual alignment between input ideas and their outputs.
\textit{PopBlends}~\cite{10.1145/3544548.3580948} leverages LLMs to generate conceptual blends by combining semantic elements from distinct domains. 
Building on existing research, our approach seeks to broaden the scope of image generation by exploring the integration of diverse objects and creating complex blending relationships between them.
Utilizing a commonsense knowledge base, we systematically analyze the potential relationships within each combination, ensuring that the representation of these concepts is grounded in and aligns with human metaphorical reasoning.
This also enables a more diverse exploration space and a more meaningful, relatable visual representation for abstract concept ideation.





