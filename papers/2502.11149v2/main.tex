\documentclass{article}
\newcommand{\rebuttal}[1]{#1}

\usepackage{microtype}
\usepackage{graphicx}
\usepackage{subfigure}
\usepackage{booktabs}

\usepackage{hyperref}

\newcommand{\theHalgorithm}{\arabic{algorithm}}
\usepackage[accepted]{utils/icml2025}

\usepackage{amsmath}
\usepackage{amssymb}
\usepackage{mathtools}
\usepackage{amsthm}


\usepackage[capitalize,noabbrev]{cleveref}


\theoremstyle{plain}
\newtheorem{theorem}{Theorem}[section]
\newtheorem{proposition}[theorem]{Proposition}
\newtheorem{lemma}[theorem]{Lemma}
\newtheorem{corollary}[theorem]{Corollary}
\theoremstyle{definition}
\newtheorem{definition}[theorem]{Definition}
\newtheorem{assumption}[theorem]{Assumption}
\theoremstyle{remark}
\newtheorem{remark}[theorem]{Remark}

\usepackage[textsize=tiny]{todonotes}

\usepackage{utils/utils}

\usepackage{booktabs}
\usepackage{multirow}
\usepackage{adjustbox}
\usepackage{makecell}


\icmltitlerunning{}

\begin{document}

\twocolumn[
\icmltitle{Large Language-Geometry Model: When LLM meets Equivariance}




\begin{icmlauthorlist}
\icmlauthor{Zongzhao Li}{ruc}
\icmlauthor{Jiacheng Cen}{ruc}
\icmlauthor{Bing Su}{ruc}
\icmlauthor{Wenbing Huang}{ruc}
\icmlauthor{Tingyang Xu}{damo,hupan}
\icmlauthor{Yu Rong}{damo,hupan}
\icmlauthor{Deli Zhao}{damo,hupan}

\end{icmlauthorlist}

\icmlaffiliation{ruc}{Gaoling School of Artificial Intelligence, Renmin University of China}
\icmlaffiliation{damo}{DAMO Academy, Alibaba Group, Hangzhou, China}
\icmlaffiliation{hupan}{Hupan Lab, Hangzhou, China}

\icmlcorrespondingauthor{Wenbing Huang}{hwenbing@126.com}
\icmlcorrespondingauthor{Yu Rong}{yu.rong@hotmail.com}

% \icmlkeywords{Machine Learning, ICML}

\vskip 0.3in
]



\makeatletter
\renewcommand{\ICML@appearing}{}
\makeatother
\printAffiliationsAndNotice{}  %

\begin{abstract} 
Accurately predicting 3D structures and dynamics of physical systems is crucial in scientific applications.
Existing approaches that rely on geometric Graph Neural Networks (GNNs) effectively enforce $\mathrm{E}(3)$-equivariance, but they often fall in leveraging extensive broader information. While direct application of Large Language Models (LLMs) can incorporate external knowledge, they lack the capability for spatial reasoning with guaranteed equivariance. 
In this paper, we propose EquiLLM, a novel framework for representing 3D physical systems that seamlessly
integrates E(3)-equivariance with LLM capabilities.
Specifically, EquiLLM comprises four key components: geometry-aware prompting, an equivariant encoder, an LLM, and an equivariant adaptor. Essentially, the LLM guided by the instructive prompt serves as a sophisticated invariant feature processor, while 3D directional information is exclusively handled by the equivariant encoder and adaptor modules.
Experimental results demonstrate that EquiLLM delivers significant improvements over previous methods across molecular dynamics simulation, human motion simulation, and antibody design, highlighting its promising generalizability.
\end{abstract}




\input{Content/Introduction}

\input{Content/Related_Work}

\begin{figure*}
    \centering
    \includegraphics[width=0.98\textwidth]{Figure/arxiv.png}
    \caption{The overall framework of EquiLLM. Given a geometric graph $\gG = (\gV,\gE)$ as input, EquiLLM initially employs an Equivariant Encoder to derive processed features $\Vec{\mX}^{'}$ and $\mH^{'}$. The features $\mH^{'}$ are first projected through a projector, then concatenated with prompt features $\mP$ in a task-specific manner. This concatenated vector is subsequently fed into an LLM. The output features $\mH^{\text{llm}}$ from the LLM, alongside the previously obtained processed features $\Vec{\mX}^{'}$ and $\mH^{'}$, are then passed into an Equivariant Adapter. The Equivariant Adapter then generates the final outputs, including the vector $\Vec{\mX}^{\text{out}}$ for equivariant tasks and the feature $\mH^{\text{out}}$ for invariant tasks. The blue \colorbox{9CBCE3!30}{\texttt{module}} means the invariant module, while the purple \colorbox{8A2BE2!10}{\texttt{module}} means the equivariant module.}
    \label{fig:architecture}
\end{figure*}

\input{Content/Method}

\input{Content/Experiment}

\input{Content/Conclusion}



\bibliography{main}
\bibliographystyle{utils/icml2025}


\newpage
\appendix
\onecolumn

\end{document}
