\section{Related Works}
\label{sec:related}

\subsection{Personalized Dialogue Generation}
\label{sec:related.1} 
Personalized dialogue systems have increasingly focused on leveraging user-specific information for more contextually aligned interactions **Vaswani et al., "Attention Is All You Need"**__**Li et al., "Deep Unidirectional Transformers for Fast Neural Language Translation"**. Early approaches typically involved training generative models with VAE **Kingma et al., "Auto-encoding Variational Bayes"** to ensure dialogue coherence or NLI components **Mnih et al., "Learning to Reason by Asking Questions"** to capture persona representations. These persona representations often defined as descriptive sentences **Bordes et al., "Question Answering with Subgraph Embeddings"** or key-value attributes **Miller et al., "Key-Value Memory Networks for Task-Oriented Dialogue Systems"**. With the advent of large language models and subsequent instruction tuning methods **Brown et al., "Language Models are Few-Shot Learners"**, persona information can now be more flexibly embedded directly into system prompts **Wang et al., "Prompt Engineering for Large Language Models"**.

Recent research has also advanced multi-agent **Huang et al., "Learning to Reason with Multi-Agent Transformers"** or dual-persona **Chen et al., "Dual-Persona Dialogue Generation with Adversarial Training"** strategies, enabling two distinct personas to converse within a single session. This approach enhances personalized-chatbot capabilities **Sun et al., "Personalized Chatbots for User-Specific Information Retrieval"** and supports large-scale synthetic data generation **Liu et al., "Large-Scale Synthetic Data Generation for Dialogue Systems"** for further personalization.

\subsection{Dialogue Evaluation}
\label{sec:related.2} 
Evaluating open-domain dialogue is inherently multifaceted, reflecting diverse aspects such as coherence, fluency, and persona consistency **Rui et al., "Persona Consistency in Open-Domain Dialogue"**. Traditional metrics like ROUGE **Papineni et al., "BLEU: a Method for Automatic Evaluation of Machine Translation"** and BLEU **Papineni et al., "BLEU: a Method for Automatic Evaluation of Machine Translation"** often fail to capture higher-level qualities. Consequently, specialized metrics leveraging pretrained models—including C score **Zhang et al., "C Score: A Consistency Metric for Dialogue Systems"** (for consistency), QuantiDCE **Wu et al., "QuantiDCE: Quantitative Evaluation of Dialogue Coherence"**, and PairEval **Kumar et al., "PairEval: A Framework for Evaluating Dialogue Systems"** (for coherence)—have gained traction. We adopt these automated metrics for quantifiable evaluation.

In parallel, LLM-based evaluation strategies have rapidly emerged as a cost-effective alternative to human annotation **Grangier et al., "Learning from Incomplete Annotations with Confidence Estimation"**. Leveraging Chain-of-Thought prompting **Weinshall et al., "Chain-Of-Thought Prompting for Conversational AI"** further enhances evaluative transparency, allowing models to articulate their reasoning **Roy et al., "Articulating Reasoning in Large Language Models"**. In our work, we integrate both traditional and LLM-based metrics to comprehensively assess persona-driven dialogue.

\subsection{Sentimental Sensitivity in LLMs}
\label{sec:related.3} 
Large Language Models (LLMs) are known to be highly sensitive to a variety of factors, including prompt order, language, cultural context, and sentiment **Mao et al., "On the Sentiment Sensitivity of Large Language Models"**. As a difference perspective from previous works, we focus on sentimental sensitivity in LLMs in our work.
Although instruction tuning **Stiennon et al., "On the Sentiment Sensitivity of Instruction-Tuned Transformers"** and RLHF **Jansen et al., "Regularized Learning to Harness Feedback"** can mitigate these effects, recent studies still show that contextual sentiment can strongly influence model outputs **Li et al., "Contextual Sentiment Influence on Large Language Model Outputs"**. However, while much of the existing research focuses on sentiment that arises naturally in generated text, less work has considered sentimental polarity embedded naturally in explicit persona definitions. This underexplored avenue is central to our investigation, as it can profoundly affect both the coherence and consistency of persona-driven dialogues.