\section{Related Works}
\label{sec:related}

\subsection{Personalized Dialogue Generation}
\label{sec:related.1} 
Personalized dialogue systems have increasingly focused on leveraging user-specific information for more contextually aligned interactions____. Early approaches typically involved training generative models with VAE____ to ensure dialogue coherence or NLI components____ to capture persona representations. These persona representations often defined as descriptive sentences____ or key-value attributes____. With the advent of large language models and subsequent instruction tuning methods____, persona information can now be more flexibly embedded directly into system prompts____.

Recent research has also advanced multi-agent____ or dual-persona____ strategies, enabling two distinct personas to converse within a single session. This approach enhances personalized-chatbot capabilities____ and supports large-scale synthetic data generation____ for further personalization. 
%Our work aligns with these trends by examining how persona polarity—particularly positive, negative, and ambiguous sentiments—influences dialogue quality in LLM-driven systems.

\subsection{Dialogue Evaluation}
\label{sec:related.2} 
Evaluating open-domain dialogue is inherently multifaceted, reflecting diverse aspects such as coherence, fluency, and persona consistency____. Traditional metrics like ROUGE____ and BLEU____ often fail to capture higher-level qualities. Consequently, specialized metrics leveraging pretrained models—including C score____ (for consistency), QuantiDCE____, and PairEval____ (for coherence)—have gained traction____. We adopt these automated metrics for quantifiable evaluation.

In parallel, LLM-based evaluation strategies have rapidly emerged as a cost-effective alternative to human annotation____. Leveraging Chain-of-Thought prompting____ further enhances evaluative transparency, allowing models to articulate their reasoning____. In our work, we integrate both traditional and LLM-based metrics to comprehensively assess persona-driven dialogue.

\subsection{Sentimental Sensitivity in LLMs}
\label{sec:related.3} 
Large Language Models (LLMs) are known to be highly sensitive to a variety of factors, including prompt order, language, cultural context, and sentiment____. As a difference perspective from previous works, we focus on sentimental sensitivity in LLMs in our work.
Although instruction tuning____ and RLHF____ can mitigate these effects, recent studies still show that contextual sentiment can strongly influence model outputs____. However, while much of the existing research focuses on sentiment that arises naturally in generated text, less work has considered sentimental polarity embedded naturally in explicit persona definitions. This underexplored avenue is central to our investigation, as it can profoundly affect both the coherence and consistency of persona-driven dialogues.