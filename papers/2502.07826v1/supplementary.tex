% {\color{blue}
\section{Deep Learning Models for Power Line Inspection}\label{appendix:dl_models}
Historically, power line inspections relied heavily on manual labor and traditional image processing techniques, which often proved time-consuming and prone to human error \cite{sundaram_deep_2021}. With the adoption of deep learning models, a profound shift has occurred. These models have showcased their ability to learn intricate patterns and structures within images, allowing for the precise identification and localization of various power line components. This transformation is not merely theoretical; it has translated into tangible benefits for power grid operators and maintenance teams \cite{sundaram_deep_2021}. This, in turn, enhances the reliability of power transmission infrastructure and mitigates the risks of unexpected outages and associated economic and safety implications. In this section, key deep learning techniques that have found application in power line component detection and fault diagnosis have been explored. The following sections delve into their advantages and use cases, shedding light on how these techniques are pushing the boundaries of what is achievable in the field of power line maintenance.

\subsection{You Only Look Once (YOLO)}
You Only Look Once (YOLO) \cite{redmon_you_2016} is a revolutionary real-time object detection system that has gained widespread recognition in computer vision applications. It stands out for its ability to swiftly process images and directly predict bounding boxes and class probabilities in a single evaluation. YOLO's efficiency and accuracy make it a compelling choice for power line component detection.

The original YOLO model (Figure \ref{fig:yolo}) introduced the concept of end-to-end object detection in real-time. It divides an image into a grid and predicts bounding boxes and class probabilities for objects within each grid cell. YOLOv2 \cite{redmon_yolo9000_2016} brought improvements in accuracy and flexibility by employing anchor boxes and multi-scale detection. It was also trained on a broader dataset, allowing it to detect a wide range of objects. YOLOv3 \cite{redmon_yolov3_2018} further enhanced the model's accuracy by utilizing a three-stage detection process and the addition of more anchor boxes. YOLOv4 \cite{bochkovskiy_yolov4_2020} introduced several architectural improvements, including the integration of the CSPDarknet53 backbone, PANet, and SAM block \cite{bochkovskiy_yolov4_2020}. These enhancements resulted in better performance in complex scenarios and more accurate component detection. The recently proposed YOLOv8 is built on top of the previous YOLO versions and designed to be faster, and more accurate \cite{jocher_yolo_2023}. 

In power line inspection, YOLO is utilized to identify and classify various components, such as insulators, dampers, pin bolts, conductor wires, and fittings \cite{sadykova2019yolo, singh_2023_interpretable, zhang_cloud_edge_2020}. Its speed and real-time capabilities are particularly advantageous when inspecting extensive stretches of power transmission infrastructure. YOLO's speed is one of its defining features. It operates at a significantly high frame rate, often exceeding real-time requirements \cite{li_improved_2022}. This speed advantage is particularly valuable in power line inspections, where rapid assessments of extensive infrastructure can be vital. The ability to process images quickly allows for the efficient identification of components, even in cases of frequent data acquisition through aerial surveys. It's worth noting that YOLO's real-time performance might require a sufficiently powerful hardware setup \cite{ultralyticsFrequentlyAsked}, but the trade-off between accuracy and processing speed can often be optimized according to specific project requirements.

\begin{figure*}[htb]
    \centering
    \includegraphics[width=1\linewidth]{fig_8_yolo.pdf}
    \caption{The architecture of the original YOLO network \cite{redmon_you_2016}.}
    \label{fig:yolo}
\end{figure*}

\subsection{Region-Based CNNs (R-CNN, Fast R-CNN, Faster R-CNN)}
Region-Based Convolutional Neural Networks (CNNs) \cite{girshick_rich_2014} represent a family of object detection models that focuses on detection accuracy while compromising on speed and complexity. This family includes R-CNN \cite{girshick_rich_2014}, Fast R-CNN \cite{girshick_fast_2015}, and Faster R-CNN \cite{ren_faster_2016}, each building upon the other to improve efficiency and accuracy in power line component detection. R-CNN slides an image window, extracts features for each window, and then classifies and refines bounding boxes for potential objects within those windows. Fast R-CNN (Figure \ref{fig:rcnn}) improves on R-CNN by processing the entire image at once with a single CNN to extract features, making it significantly faster. Faster R-CNN further refines the model by introducing the Region Proposal Network (RPN) \cite{ren_faster_2016} for generating region proposals. This innovation results in a more streamlined and faster detection process. These models have been applied in power line component detection to locate and classify insulators \cite{wei_online_2022}, dampers \cite{zhai_hybrid_2021}, pin bolts \cite{zhai_hybrid_2021}, conductor wires \cite{rong_intelligent_2021}, and other elements.

Region-based CNNs excel in precisely localizing objects within images, making them suitable for power line component identification. Fast R-CNN and Faster R-CNN integrate region proposal and feature extraction steps, enhancing processing efficiency. However, Training and fine-tuning region-based CNNs require substantial computational resources and a large labeled dataset. These models may need hardware acceleration for real-time performance \cite{bharati2020deep}.

\begin{figure*}[htb]
    \centering
    \includegraphics[width=1\linewidth]{fig_9_rcnn.pdf}
    \caption{Simplified architecture of the Fast R-CNN Network.}
    \label{fig:rcnn}
\end{figure*}

\subsection{Single Shot MultiBox Detectors (SSD)}
Single Shot Detectors (SSD) \cite{liu_ssd_2016} is another object detection algorithm that combines high-speed processing with robust detection capabilities. SSD is designed for real-time object detection, eliminating the need for a separate region proposal step and streamlining all computations into a single network. SSD is employed to rapidly identify and classify various components, such as insulators \cite{miao_insulator_2019}, fittings \cite{nguyen_intelligent_2019}, conductor wires \cite{nguyen_intelligent_2019}, and other crucial infrastructure elements. 

SSD's primary advantage is its ability to process images rapidly while keeping a high enough accuracy \cite{huang2017speed}. This characteristic is essential for real-time inspections, particularly in scenarios where assessments of extensive power line infrastructure are required. SSD's architecture (Figure \ref{fig:ssd}) integrates all detection computations into a single network, eliminating the need for multiple stages, which simplifies implementation and results in efficient performance. While SSD offers impressive speed and efficiency, its performance may be compromised compared to models like Faster-RCNN \cite{huang2017speed}. Balancing speed and accuracy demands may require optimization for specific hardware configurations and project constraints.

\begin{figure*}[htb]
    \centering
    \includegraphics[width=1\linewidth]{fig_10_ssd.pdf}
    \caption{Simplified architecture of the Single Shot Multibox Detector (SSD) Network.}
    \label{fig:ssd}
\end{figure*}

\subsection{Transformer Architectures}
Transformer architectures have revolutionized various domains in deep learning, originally emerging as a powerful tool in natural language processing. Introduced by Vaswani et al. \cite{vaswani2017attention}, the transformer model is based on self-attention mechanisms, enabling it to capture long-range dependencies within data. Unlike traditional convolutional neural networks (CNNs), which are limited by their localized receptive fields, transformers excel in modeling global context, making them highly effective for complex tasks in computer vision, including power line inspection.

\subsubsection{Vision Transformers (ViT)}

Vision Transformers (ViT) \cite{dosovitskiy2020image} marked a paradigm shift by applying the transformer architecture directly to image data. ViTs divide an image into a sequence of patches, each treated similarly to tokens in a language model. These patches are then processed through multiple layers of self-attention, allowing the model to learn intricate relationships between different parts of the image. Although we could not find any research work on power line inspection that utilizes ViTs, they have potential in tasks requiring detailed analysis of visual data. Their ability to capture global information makes them particularly suitable for identifying subtle anomalies in power line components, such as bolt defects, micro-cracks in insulators or structural defect of conductor wires \cite{han2022survey}. However, ViTs require a very large dataset to train on to get rid of the inductive bias \cite{dosovitskiy2020image}. \\

\subsubsection{Swin Transformers}

Swin Transformers \cite{liu2021swintransformerhierarchicalvision}, or Shifted Window Transformers, build on the concept of ViTs by introducing a hierarchical structure that allows the model to operate at multiple scales. This architecture divides the image into non-overlapping windows and applies self-attention within each window. To capture cross-window information, the windows are shifted between layers, enabling the model to build a more comprehensive understanding of the image. The multi-scale feature representation of Swin Transformers is advantageous, especially in scenarios where defects or components vary in size. Swin Transformers can effectively manage high-resolution images, making them ideal for detecting and localizing faults in expansive power transmission networks, where both small and large defects need to be identified with precision \cite{dong_improved_2023}. \\

\subsubsection{Detection Transformers (DETRs)}

Detection Transformers (DETRs) \cite{carion2020end} integrate the transformer architecture into object detection tasks, offering an end-to-end approach that simplifies the traditional detection pipeline. The architecture of the DETR network is shown in Figure \ref{fig:detr}. DETRs eliminate the need for anchor boxes and region proposals, which are common in conventional object detection models. Instead, they leverage the transformerâ€™s attention mechanism to directly predict object bounding boxes and class labels. Their ability to model complex interactions between objects within an image enhances detection accuracy, particularly in cluttered or complex scenes typical of power line infrastructure. Additionally, DETRs are robust to variations in object scale and orientation, which are common challenges in aerial imagery used for inspecting power lines \cite{zhang_pa_detr_2023, jain2024transfer}. \\

\begin{figure*}[htb]
    \centering
    \includegraphics[width=1\linewidth]{fig_11_detr.pdf}
    \caption{The simplified block diagram of the original DETR network \cite{carion2020end}}
    \label{fig:detr}
\end{figure*}

\subsection{Classification Algorithms}
Classification algorithms, particularly those pretrained on large datasets like ImageNet \cite{5206848}, have demonstrated remarkable capabilities in recognizing diverse patterns and anomalies in power line components. These algorithms excel in scenarios where pinpointing the exact location of a fault is unnecessary, and the primary goal is simply to determine whether a fault exists. When provided with an image of power line infrastructure or a specific segment of a power line component, these algorithms are capable of classifying the image as either faulty or in good condition. Key algorithms in this domain include ResNet, VGG, MobileNet and EfficientNet each bringing unique strengths to the table. 
 
\textbf{ResNet (Residual Networks)} \cite{he_2023_deep}, a pivotal model in deep learning, introduced the concept of residual learning to ease the training of very deep networks. It employs "skip connections" to jump over some layers, effectively addressing the vanishing gradient problem. In power line inspection, ResNet's ability to learn from a vast depth of layers makes it exceptionally good at recognizing complex patterns, crucial for identifying subtle anomalies in power lines \cite{wei_online_2022, cao_accurate_2023, luo_ultrasmall_2023}.

The \textbf{VGG (Visual Geometry Group)} \cite{simonyan2014very} network stands out for its simplicity and depth, with a uniform architecture that stacks convolutional layers directly on top of each other. This design, while computationally intensive, offers excellent feature extraction capabilities. For power line inspections, VGG's depth helps in capturing intricate details necessary for accurate component classification and fault detection \cite{stefenon_semi_protopnet_2022}. However, its performance may be compromised compared to other state-of-the-art models that came out in recent years \cite{Team}.

\textbf{MobileNet} \cite{howard2017mobilenets} architectures are designed for efficiency, making them ideal for use in mobile and edge computing scenarios. Their streamlined design, based on depthwise separable convolutions \cite{chollet2017xception}, allows for reduced computational load while maintaining high accuracy. In power line inspection, especially those conducted via drones or handheld devices, MobileNet's lightweight nature enables rapid, on-site processing of images for real-time analysis \cite{wei_online_2022, qiu_lightweight_2023, li_improved_2022}.

\textbf{EfficientNet} \cite{tan2019efficientnet} represents a new scaling method for neural networks, which uniformly scales all dimensions of depth, width, and resolution with a set of fixed scaling coefficients. This balanced scaling results in a network that achieves state-of-the-art accuracy with a lower computational cost \cite{Team}. In power line inspection, EfficientNet can be particularly useful for processing high-resolution images effectively, allowing for detailed and accurate identification of line defects and deterioration \cite{odo_aerial_2021, li_pin_2022}.

The above-mentioned object detection and classification networks are often mixed with each other to design powerful networks that often have superior performance to the original networks \cite{tao_detection_2020}. Notably in recent years, the attention mechanism \cite{vaswani2017attention} and its utilization in segmentation and classification algorithms has gained widespread popularity. Its initial application was by the Google DeepMind team in 2014, where they integrated an attention module into an RNN model for image classification \cite{dosovitskiy2020image}. The potency of self-attention networks, particularly in capturing long-distance dependencies and contextual information, has made them a staple in machine vision tasks like image segmentation and classification. Cao et al. \cite{cao_accurate_2023} innovatively used attention-guided multipath features to reconcile the contradictory needs between feature map resolution and the receptive field for high-resolution inputs. Furthermore, the introduction of the attention-RPN module by Fan et al. \cite{fan_2019_few} for small sample target detection, and the combination of global attention and local restructuring by Kong et al. \cite{kong_context_2018}, exemplify the versatility of attention mechanisms. These adaptations enable the collection of task-oriented features across different spatial locations and scales, harnessing both global and local contexts to enhance the accuracy and efficiency of object detection. 

\section{Computer Vision Tasks in Power Line Inspection}\label{appendix:cv_tasks}
Various object detection techniques are employed in computer vision to automate this task, each with its strengths and application scenarios. This section discusses key methods like bounding box detection, semantic segmentation, and instance segmentation. A visual comparison between these techniques has been shown in Figure \ref{fig:cv_tasks}.

\subsection{Bounding Box Detection}
Bounding Box Detection is a primary object detection method where a box is drawn around each object of interest in an image, marking its location and extent. It is straightforward to implement and computationally less demanding. This method is well-suited for real-time applications due to its relatively fast processing time often reaching over 80 Frames Per Second (FPS) \cite{ge_birds_2022}. Bounding box detection is typically used to identify and locate larger power line components such as towers, insulators, and dampers.

\subsection{Semantic Segmentation}
Semantic segmentation involves the partitioning of an image into segments, where each pixel is classified into a predefined category. This method is capable of producing detailed component-wise masks, which are beneficial for understanding the scene at a pixel level. It provides a precise outline of the components, which is crucial for assessing their condition. Semantic segmentation allows for a comprehensive analysis of the scene by understanding the relationship between different components. This technique is particularly useful for distinguishing between different types of insulators, conductor wires, and vegetation encroachment.

\subsection{Instance Segmentation}
Instance segmentation goes a step beyond semantic segmentation by not only separating the background from the foreground but also differentiating between individual objects of the same class. It is capable of identifying and delineating each instance of multiple objects of the same type. This method excels in scenarios where components are close together or overlapping. Instance segmentation is essential when dealing with dense power line components, such as closely spaced insulators or bundled conductor wires, to assess each component separately.

\begin{figure}[htb]
    \centering
    \includegraphics[width=1\linewidth]{fig_12_segmentation_techniques.pdf}
    \caption{Comparison between different image segmentation techniques \cite{electronics12153210, bob_semantic}.}
    \label{fig:cv_tasks}
\end{figure}
% }