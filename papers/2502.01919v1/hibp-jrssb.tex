\documentclass[11pt]{article}
%\usepackage{amsmath}
\usepackage{graphicx}
\usepackage{enumerate}
%\usepackage{natbib}
\usepackage{url} % not crucial - just used below for the URL 
\RequirePackage[OT1]{fontenc}
\usepackage{bbm}
\usepackage[numbers]{natbib}
\usepackage{amsthm,amsmath}
\usepackage{graphicx,ifthen}
\usepackage{latexsym}
\usepackage{mathrsfs}
\usepackage{amssymb}
\usepackage{hyperref}
\usepackage{xcolor}
\usepackage{caption, subcaption}
\usepackage{stmaryrd}
\usepackage{dsfont}

%\usepackage{xr}
%\externaldocument[supp:]{hibp-jasa-supp}

%\pdfminorversion=4
% NOTE: To produce blinded version, replace "0" with "1" below.
\newcommand{\blind}{1}
\newcommand{\papertitle}{Poisson Hierarchical Indian Buffet Processes for Within and Across Group Sharing of Latent Features-With Indications for Microbiome Species Sampling Models}

% \startlocaldefs
\newcommand{\remark}{\noindent {\bf Remark:\ }}

\newtheoremstyle{example}{\topsep}{\topsep}%
     {}%         Body font
     {}%         Indent amount (empty = no indent, \parindent = para indent)
     {\rmfamily}% Thm head font
     {}%        Punctuation after thm head
     {\newline}%     Space after thm head (\newline = linebreak)
     {\thmname{#1}\thmnumber{ #2}\thmnote{ #3}}%         Thm head spec

   \theoremstyle{example}
   \newtheorem{example}{Example}[subsection]



% \def\Beta{\text{Beta}}
% \def\Dir{\text{Dirichlet}}
% \def\DP{\text{DP}}
% \def\P{{\bf p}}
% \def\fhat{\widehat{f}}
% \def\GA{\text{gamma}}
% \def\ind{\stackrel{\mathrm{PYlamperti}}{\sim}}
% \def\iid{\stackrel{\mathrm{iid}}{\sim}}
% \def\K{{\bf K}}
% \def\E{{\mathbb E}}
% \def\min{\text{min}}
\newcommand{\indic}{\mathbb{I}}
% \def\N{\text{N}}
% \def\p{{\bf p}}
% \def\U{{\bf U}}
% \def\u{{\bf u}}
% \def\w{{\bf w}}
% \def\X{{\bf X}}
% \def\Y{{\bf Y}}
\numberwithin{equation}{section}
\theoremstyle{plain}
\newtheorem{thm}{Theorem}[section]
\newtheorem{mytheorem}{}
\newtheorem{defin}{Definition}[section]
\newtheorem{exam}{Example}[subsection]
\newtheorem{prop}{Proposition}[section]
\newtheorem{lem}{Lemma}[section]
\newtheorem{rem}{Remark}[section]
\newtheorem{ack}{Acknowledgement}
\newtheorem{cor}{Corollary}[section]
\newcommand{\rb}[1]{\raisebox{1.5ex}[0pt]{#1}}
\newcommand{\mc}{\multicolumn}


\renewcommand{\labelitemi}{$\bullet$}
\newcommand{\Lower}[2]{\smash{\lower #1 \hbox{#2}}}
\newcommand{\ben}{\begin{enumerate}}
\newcommand{\een}{\end{enumerate}}
\newcommand{\bi}{\begin{itemize}}
\newcommand{\ei}{\end{itemize}}
\newcommand{\hp}{\hspace{.2in}}
\newcommand{\DoubleRLarrow}[1]{\Lower{-0.01in}{$\underleftarrow{\Lower{0.07in}{$\overrightarrow{\vspace*{0.15in}\hspace*{#1}}$}}$}}
\newcommand{\DoubleLRarrow}[1]{\Lower{-0.01in}{$\underrightarrow{\Lower{0.07in}{$\overleftarrow{\vspace*{0.15in}\hspace*{#1}}$}}$}}
\newcommand{\SingleRarrow}[1]{\Lower{-0.08in}{$\underrightarrow{\hspace*{#1}}$}}
\newcommand{\SingleLarrow}[1]{\Lower{-0.08in}{$\underleftarrow{\hspace*{#1}}$}}

% Define the Stirling number of the first kind macro
\newcommand{\stirlingfirst}[2]{\genfrac{[}{]}{0pt}{}{#1}{#2}}

% Rest of your LaTeX document here

%\hypersetup{
%    colorlinks,
%    citecolor=black,
%    filecolor=black,
%    linkcolor=black,
%    urlcolor=black
%}
% \endlocaldefs


% DON'T change margins - should be 1 inch all around.
\addtolength{\oddsidemargin}{-.5in}%
\addtolength{\evensidemargin}{-1in}%
\addtolength{\textwidth}{1in}%
\addtolength{\textheight}{1.7in}%
\addtolength{\topmargin}{-1in}%




\begin{document}

%\bibliographystyle{natbib}

\def\spacingset#1{\renewcommand{\baselinestretch}%
{#1}\small\normalsize} \spacingset{1}


%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

% \if1\blind
% {
%   \title{\bf \papertitle}
%   \author{Author 1\thanks{
%     The authors gratefully acknowledge \textit{please remember to list all relevant funding sources in the unblinded version}}\hspace{.2cm}\\
%     Department of YYY, University of XXX\\
%     and \\
%     Author 2 \\
%     Department of ZZZ, University of WWW}
%   \maketitle
% } \fi

\if1\blind
{
  \title{\bf Poisson Hierarchical Indian Buffet Processes-With Indications for Microbiome Species Sampling Models}
  \author{Lancelot F. James\thanks{
    \textit{Supported in part by grants RGC-GRF 16301521, 16300217, and T31-604/18-N of the HKSAR.}}\hspace{.2cm}\\
    Department of ISOM, HKUST\\
    %and \\
    Juho Lee
    % \thanks{
    % \textit{Supported by Institute of Information \& communications Technology Planning \& Evaluation (IITP) grant funded by the Korea government (MSIT) (No.2019-0-00075, Artificial Intelligence Graduate School Program (KAIST).)}
    % }\hspace{.2cm}
    \\
    The Graduate School of AI, KAIST\\
    Abhinav Pandey \\
    Department of ISOM, HKUST\\
    }
  \maketitle
} \fi

\if0\blind
{
  \title{\bf \papertitle}
  \author{}
  \date{}
  \maketitle
} \fi

\begin{abstract}
In this work, we present a comprehensive Bayesian posterior analysis of what we term Poisson Hierarchical Indian Buffet Processes, designed for complex random sparse count species sampling models that allow for the sharing of information across and within groups. This analysis covers a potentially infinite number of species and unknown parameters, which, within a Bayesian machine learning context, we are able to learn from as more information is sampled. To achieve our refined results, we employ a range of methodologies drawn from Bayesian latent feature models, random occupancy models, and excursion theory. Despite this complexity, our goal is to make our findings accessible to practitioners, including those who may not be familiar with these areas. To facilitate understanding, we adopt a pseudo-expository style that emphasizes clarity and practical utility. We aim to express our findings in a language that resonates with experts in microbiome and ecological studies, addressing gaps in modeling capabilities while acknowledging that we are not experts ourselves in these fields. This approach encourages the use of our models as basic components of more sophisticated frameworks employed by domain experts, embodying the spirit of the seminal work on the Dirichlet Process. Ultimately, our refined posterior analysis not only yields tractable computational procedures but also enables practical statistical implementation and provides a clear mapping to relevant quantities in microbiome analysis.
\end{abstract}

\noindent%
{\it Keywords:}  Bayesian nonparametrics, Bayesian statistical machine learning, Hierarchical Indian Buffet Process, Microbiome species sampling models, Microbiome unseen species problems 
\vfill

\newpage
%\spacingset{1.9} % DON'T change the spacing!

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\section{Introduction}
In this work, we present a comprehensive Bayesian posterior analysis of what we term Poisson Hierarchical Indian Buffet Processes (HIBP), which is a hierarchical extension of the Poisson Indian Buffet Process (IBP) of ~\cite{Titsias}, see also \cite{James2017, Lo1982, FoFZhou}, designed for complex random sparse count species sampling models that facilitate the sharing of information within and across groups. These models are distinguished members of a class of hierarchical versions of general spike-and-slab Indian Buffet Processes~\cite{James2017}, as introduced in a preliminary version of this work~\cite{hibp23}. See also the seminal work of \cite{Thibaux} on the hierarchical extension of the Bernoulli IBP, or simply IBP, of~\cite{GriffithsZ}. The important work of \cite{GriffithsZ} represents the canonical case for non-hierarchical latent feature models of this type, see ~\cite{MasoeroBiometrika} for a recent interesting application of the IBP. These hierarchical models are latent feature analogues of Hierarchical Dirichlet Process 
~\cite{HDP} and its many variants designed for latent class/cluster modelling across groups. This exposition serves as a more focused elaboration of~\cite{hibp23}, developing results relevant to the complex modeling of real-world phenomena that our Poisson HIBP can effectively emulate. Specifically, we will examine how our model can be interpreted in terms of its capabilities for complex count models arising in recent microbiome and ecological species sampling studies. see for instance \citep{balocchi2024bayesian,franzolini2023bayesian,ren2017bayesian, sankaran2024semisynthetic, willis2022estimating},

Relevant to that context, our analysis addresses a potentially infinite number of species and unknown parameters, from which we can learn as more information is sampled within a Bayesian machine learning framework. Our approach induces a highly complex dependence structure over these infinite parameters, resulting in intricate sparse count matrices that reflect outcomes in such regimes. One of our significant achievements, reflected in Propositon~\ref{prop2} and Theorem~\ref{sumsampleprop} of the forthcoming Section~\ref{PoissonHIBPconstruction}, is developing a complex generative process that is relatively easy to sample, as it breaks down into many components already present in the literature, albeit not all broadly familiar. Similar to the development of key properties in many Bayesian non-parametric (BNP) methods, such as the Dirichlet Process, we create a framework that domain experts can use as a key part of more intricate models incorporating covariates and other pertinent information.

To achieve our refined results, we employ a range of methodologies drawn from Bayesian latent feature models, random occupancy models, and excursion theory, including \cite{ James2017,JLP2, kingman1975, Kolchin, Pit97, Pit02}. We note that the unpublished manuscript of Pitman~\cite{PitmanPoissonMix} played a central role in our thought process, linking the lesser-known mixed Poisson species sampling framework of Fisher/McCloskey with the works of \cite{JLP2, FoFZhou}, which also connects with \cite{Kolchin, Pit97}. Our usage here will be self-contained, but see \cite{JamesStick} for further information. To clarify, we are generally referring to the broader view of species sampling models as discussed in \cite{IJ2003, Pit96, Pit02, Pit06}, applied to a more complex microbiome setting. We will also address important unseen problems, as highlighted in the recent review by \cite{balocchi2024bayesian}, which we shall explore in the context of microbiome analysis in Section~\ref{posteriorPoissonHIBP}, and in particular Section~\ref{unseen}.

Despite the complexity, our goal is to make our findings accessible to practitioners in microbiome and ecological studies, while also considering broader applications that involve similar structures. We adopt a pseudo-expository style that emphasizes clarity and practical utility, aiming to present our findings in a language that resonates with this audience. We address gaps in modeling capabilities, all while acknowledging that we are not experts ourselves in these fields.

Our approach encourages the integration of our models as components within sophisticated frameworks, highlighting how technical developments facilitate their application to complex real-world scenarios, akin to the innovations seen in the Dirichlet Process \cite{Ferg1973} and related processes in Bayesian nonparametrics.

Ultimately, our refined posterior analysis yields tractable computational procedures and enables practical statistical implementation, providing a clear mapping to relevant quantities in microbiome analysis. We will offer interpretations of our results specific to a statistical microbiome context as they are developed, including new Bayesian estimators arising from the model's interpretability.

Additionally, we will present computational results based on synthetic and real data, along with freely available resources. Our Poisson HIBP can mimic relevant complex characteristics of models in microbiome studies and related species sampling models, without going into all the formal technical details. This discussion will also highlight forthcoming results, serving as an outline.

In Section~\ref{PoissonHIBPconstruction}, we will describe the specifics of the Poisson HIBP, Throughout we will use the notation \([n]=\{1,2,\ldots,n\}\) for an integer \(n\).

\subsection{Poisson HIBP as Sparse Count Models for Microbiome Species Sampling}
As mentioned, we find it useful to first motivate and encourage the use of these models by introducing some of their capabilities relevant to the complex data structures of interest in microbiome and ecological studies across \( J \) groups. For example, \( J \) might represent different geographical locations, sites on the human body, treatment conditions, or time points, with each group consisting of \( M_{j} \) samples for \( j \in [J] \). Here, \( M_{j} \) denotes the number of samples collected from group \( j \), where each sample \( i \) in \( [M_{j}] \) consists of sparse counts of species and related information. In our notation, we represent a sample as \( Z^{(i)}_{j} \) for \( i \in [M_{j}], j \in [J] \). Each $Z^{(i)}_{j}$ leads effectively to a sparse matrix of counts, meaning it contains mostly zeros, and labelled features/species, with, as we shall see many potentially hidden components.  Metaphorically, in the Indian Buffet parlance, these would be referred to as samples for \( M_{j} \) customers across \( j \in [J] \) groups. Below, we discuss the overall structure of a Poisson HIBP without all the formal details.

Addressing some distributional issues raised for instance in~\cite{franzolini2023bayesian, sankaran2019latent, sankaran2024semisynthetic}, our models provide novel sparse multivariate count frameworks that allow for the sharing of a possibly infinite number of species (latent features) within and across groups. Similar to other Bayesian non-parametric methods~\cite{Ferg1973,HDP} arising in statistics and machine learning, these flexible models enable the learning of these quantities without restriction as more information is sampled.
Furthermore, our analysis offers tractable methods for sampling and posterior analysis in this complex setting, introducing parameters that indicate notions of species abundance and diversity~\cite{willis2022estimating}. This addresses many modeling issues that may rely on an upper bound for the types of species and face challenges in terms of flexible count models~\cite{sankaran2019latent}. We also provide indications for novel approaches to the formidable problem of unseen entities in future samples~\cite{balocchi2024bayesian, jeganathan2021statistical} within this context, which is facilitated by our Prediction rules in~Section~\ref{predict}.

Ideally, as mentioned, our models allow for an infinite number of unique species (taxa) denoted as \( (Y_{l})_{l \geq 1} \), where each species \( Y_{l} \) may appear \( N_{j,l} \in \{0,1,2,\ldots\} \) times in group \( j \). Additionally, we have \( N_{j,l} = \sum_{k=1}^{\xi_{j,l}} C_{j,k,l} \), where \( C_{j,k,l} \) for \( k \in [\xi_{j,l}] \), and $\xi_{j,l}\in {0,1,2,\ldots},$ are the subcounts corresponding to subspecies of \( Y_{l} \) or other operational taxonomic units (OTUs). All these contribute to the overall count \( N_{j,l} \) of species \( Y_{l} \). Note further that \( C^{(i)}_{j,k,l} \) represents individual counts for the \( i \)-th sample in group \( j \), such that \( C_{j,k,l} = \sum_{i=1}^{M_{j}} C^{(i)}_{j,k,l} \). We suppress notation indicating dependence on \( M_{j} \). 

In many scenarios~\cite{sankaran2019latent}, the \( C_{j,k,l} \) and \( \xi_{j,l} \) are not observed directly and are either treated as latent variables or not considered at all. As we will show, as a key result, our model allows for random recovery of these quantities given the counts \( (N_{j,l} ,  j \in [J]  )\). To better understand the relative abundance and diversity across and within groups of species, our constructions induce priors and posterior distributions over sequences of parameters that indicate mean rates and relative rates of species abundance across and within groups. In particular, we introduce pairs \( (\lambda_{l}, Y_{l})_{l \geq 1} \), which are points of a Poisson Process, where \( \lambda_{l} \) can be interpreted as the mean abundance rate of species \( Y_{l} \). This interpretation extends beyond its potential appearances in the \( J \) communities. That is to say it applies if more communities are added, and hence is not group specific. Furthermore, this is related to the interpretations in~\cite{PitmanPoissonMix} in a more conventional species sampling model where animals are the sample unit and are assigned to one class/cluster, see for instance~\cite{Pit96}.

The mean abundance rate of all species is given by \( B_{0}(\Omega) := \sum_{l=1}^{\infty} \lambda_{l} \), and the relative abundances are defined as \( (P_{l}:= \frac{\lambda_{l}}{B_{0}(\Omega)} )_{l\ge 1}\). Similarly, our analysis reveals the mean abundance rate of species \( Y_{l} \) in group \( j \) as \( \sigma_{j,l}(\lambda_{l}) = \sum_{k=1}^{\infty} s_{j,k,l} \), where \( (s_{j,k,l})_{k \geq 1} \) are points of a point process, say \( (s_{j,k})_{k \geq 1} \), falling within a disjoint interval of length \(\lambda_{l} \), and may be thought of as the mean abundance rate of sub-species of \( Y_{l} \) of type \( k \) in group \( j \). As the term "rates" suggests, the quantities \((\lambda_{l})_{l \geq 1}\), \(((\sigma_{j,l}(\lambda_{l}))_{l \geq 1}, j \in [J])\), and \({((s_{j,k,l})_{k \geq 1},j\in [J])}_{l\ge 1} \) are (dependent) random mean intensities of Poisson variables. This leads, as we will show, to complex yet tractable sparse (mixed) Poisson multivariate count distributions. As a by-product, this randomization allows us to capture the over-dispersity exhibited by the count data in microbiome studies, see~\cite{sankaran2024semisynthetic}[Section 2]. 

From these, we have random relative abundances that sum to \( 1 \), given by:
$$
P_{l}=\frac{\lambda_{l}}{\sum_{t=1}^{\infty}\lambda_{t}}, \quad P_{j,l} = \frac{\sigma_{j,l}(\lambda_{l})}{\sum_{t=1}^{\infty} \sigma_{j,t}(\lambda_{t})} \quad \text{and} \quad P_{j,k,l} = \frac{s_{j,k,l}}{\sigma_{j,l}(\lambda_{l})}
$$
We may use the above to construct random probability measures 
$$
\bar{B}_{0} = \sum_{l=1}^{\infty} P_{l} \delta_{Y_{l}}, \quad \bar{B}_{j} = \sum_{l=1}^{\infty} P_{j,l} \delta_{Y_{l}}, \quad F_{j,l} = \sum_{k=1}^{\infty} \frac{s_{j,k,l}}{\sigma_{j,l}(\lambda_{l})} \delta_{U_{j,k,l}} 
$$
where we can choose \((U_{j,k,l})_{k \geq 1} \overset{iid}{\sim} \mathrm{Uniform}[0,1]\) as distinct markers for OTU clusters with corresponding counts \((C_{j,k,l})_{k \geq 1}\) for each \(l \geq 1\), defined such that \(\bar{B}_{0}^{-1}(U_{j,k,l}) = Y_{l}\), where \(\bar{B}^{-1}_{0}\) denotes the quantile function of \(\bar{B}_{0}\). Hence, \((s_{j,k,l})_{k \geq 1}\) are the corresponding mean abundance rates of these OTU markers \((U_{j,k,l})_{k \geq 1}\). Note, although we can simulate the markers their values are not explicitly used in this work.

The quantities above are all random, and one of our main results in Theorem ~\ref{sumsampleprop} as shown in Section~\ref{exactsampling}  is to describe how to sample observations from the marginal process generating the observed non-zero counterparts of \( (C_{j,k,l}, k \in [\xi_{j,l}], \xi_{j,l}) \), and hence \( N_{j,l} \) for \( j \in [J] \) and \( l = 1, 2, \ldots \) and hence producing sparse random count matrices . We denote these sampled quantities as \( (\tilde{C}_{j,k,l}, k \in [X_{j,l}], X_{j,l}) \), where $\tilde{C}_{j,k,l}=\sum_{i=1}^{M_{j}}\tilde{C}^{(i)}_{j,k,l}$ leading to \( \tilde{N}_{j,l} = \sum_{k=1}^{X_{j,l}} \tilde{C}_{j,k,l} \) for \( j \in [J] \) and \( l = 1, \ldots, \varphi \), associated with the \( \varphi \) triples \( (H_{l}, \tilde{X}_{l}, \tilde{Y}_{l}), l \in [\varphi] \), where \( \tilde{Y}_{l} \) is an observed species label and \( (H_{l},\tilde{Y}_{l}) \) are a dependent pair, $H_{l}$ its corresponding mean abundance rate of 
$\tilde{Y}_{l}$, and $\tilde{X}_{l}=\sum_{j=1}^{J}X_{j,l}$ is the number of distinct OTUs contributing to the counts of $\tilde{Y}_{l},$ over all the groups in the sample,
whereas $X_{j,l}$ is the number of distinct sub-species(OTUs) of $\tilde{Y}_{l}$ in group $j$  Thus providing a flexible and practically tractable random generative process for sparse count based species species sampling models that my arise in microbiome and other studies. 

\subsubsection{Measures of Diversity}
Our results naturally allow one to address more traditional measures for abundance and diversity of species within and across groups. See, for instance,
\cite{willis2022estimating}. However, our work also allows for a potential myriad of implementable measures either modelling parameters of interest, including indicators of mean rates or relative rates of abundance, or utilizing latent or partially observed data. For example, we may propose (new) random measures of alpha-diversity across the \( J \) groups using for example Shannon entropy (among the observed species $(\tilde{Y}_{1},\ldots,\tilde{Y}_{\varphi})$ in the \( J \) groups):
\begin{equation}
\mathscr{D}_{j} := -\sum_{l=1}^{\varphi} \frac{\sigma_{j,l}(H_{l})}{\sum_{t=1}^{\varphi} \sigma_{j,t}(H_{t})} \ln{\left(\frac{\sigma_{j,l}(H_{l})}{\sum_{t=1}^{\varphi} \sigma_{j,t}(H_{t})}\right)}, \quad j \in [J]
\label{Shannon1}
\end{equation}
To be clear $\sigma_{j,l}(H_{l}),$ $\frac{\sigma_{j,l}(H_{l})}{\sum_{t=1}^{\varphi} \sigma_{j,t}(H_{t})}$ and $\mathscr{D}_{j}$ may be thought of as unknown population parameters that we have assigned priors to. In particular $\sigma_{j,l}(\lambda)$ is a random variable following a positive continuous infinitely divisible distribution, such as a gamma, stable or generalized gamma distribution.  From our forthcoming Theorem~\ref{postPoissonHIBP}, which is one of our main results, in particular Proposition~\ref{poissonequivalence}, one can sample from the distribution of $(\mathscr{D}_{j},{j}\in[J])$  in~\eqref{Shannon1} exactly according to the posterior distribution given \( (N_{j,l}, j \in [J], l \in [r]) \). There are, of course, many other possibilities.

\subsubsection{Addressing the Unseen Species Problem}
Additionally, note that \( (\lambda_{l}, Y_{l})_{l \geq 1} \) may be divided into \( (\lambda'_{l}, Y'_{l})_{l \geq 1} \) and \( (H_{1}, \tilde{Y}_{1}), \ldots, (H_{r}, \tilde{Y}_{r}) \), corresponding to unseen and seen species, along with all relevant statistics and parameters associated with these variables as discussed above, relative to $(M_{j}, j\in[J])$ samples. In this work, we will derive the predictive distributions of our processes and demonstrate how this may be used to provide a novel approach to address the unseen-species problem in this microbiome setting(or in general for multivariate count species models), which otherwise poses many challenges as mentioned in \cite{balocchi2024bayesian, jeganathan2021statistical} , by providing tractable distributions of a host of unseen quantities in samples \( M_{j}+1 \), for \( j \in [J] \), or in a new community \( J + 1 \), given \( N_{j,l}, j \in [J] \). We will discuss these details in Section~\ref{unseen} which is achieved by using our prediction rules in Section~\ref{predict}.

\section{Poisson HIBP}\label{PoissonHIBPconstruction}
In order to appreciate the apparent complexity of our models we note at the finest level there are an infinite collection of dependent random distributions over $J$ groups, say $(F_{j,l}:j \in [J])_{l\ge 1}$ each containing a countably infinite number of parameters, and where dependence is both over $j\in [J]$ and $l=1,2,\ldots.$ 
Or more precisely the mean abundance rates \({((s_{j,k,l})_{k \geq 1},j\in [J]),\lambda_{l})}_{l\ge 1} \).

We now discuss the formal definition of Poisson HIBP, by first recalling the Poison $\mathrm{IBP},$ proposed by ~\cite{Titsias} as 
discussed in~\cite{James2017}. We start by recalling definitions of completely random measures 
highlighting some properties that are of relevance to our exposition when the base measure $B_{0}$ 
defined below is discrete.  Let, for each $j\in[J],$ $B_{j}$ be a completely random measure defined as 
$B_{j} = \sum_{k=1}^{\infty} s_{j,k} \delta_{w_{j,k}} \sim \mathrm{CRM}(\rho_{j},B_{0})$, where 
$\tau_{j}(s)dsB_{0}(d\omega)$ is the mean measure of a Poisson random measure, see~\cite{James2017} 
for more on this relation, and specifies the distribution of $(s_{j,k},w_{j,k})_{\{k\ge 1\}}$ as follows. Here, $B_{0}(dw)$ is a finite measure on a Polish space $\Omega$ such that $(w_{j,k})_{\{k\ge 1\}} \overset{iid}\sim \bar{B}_{0}(dw) := B_{0}(dw)/B_{0}(\Omega)$, and $\tau_{j}(s)$ is the L\'evy density on $(0,\infty)$ satisfying 
$\int_{0}^{\infty}\min(s,1)\rho_{j}(s)ds<\infty$ and $\int_{0}^{\infty}\tau_{j}(s)ds=\infty.$ The $\tau_{j}$ determines the distribution of the jumps of $B_{j},$ represented by $(s_{j,k})_{\{k\ge 1\}}$, and $B_{j}(\Omega):=\sum_{k=1}^{\infty}s_{j,k}$ is a positive infinitely divisible continuous random variable with Laplace transform 
$\mathbb{E}[e^{-tB_{j}(\Omega)}] = e^{-B_{0}(\Omega)\psi_{j}(t)}$, and Laplace exponent $\psi_{j}(t) := \int_{0}^{\infty}(1-e^{-ts})\tau_{j}(s)ds.$ Furthermore, 
for a countable number of disjoint sets $(Q_{j,l})_{l\ge 1}$, $B_{j}(Q_{j,l})$ are independent with respective laws indicated by the Laplace exponents $B_{0}(Q_{j,l})\psi_{j}(t)$ for $l=1,2,\ldots.$ Hence the collection of jumps $\{s_{j,k} : w_{j,k} \in Q_{j,l}, k\ge 1\}$,  are independent across each $j,l,$ and specified by Lévy densities $B_{0}(Q_{j,l})\tau_{j}$, with atoms selected iid proportional to $\mathbb{I}_{\{\omega\in Q_{j,l}\}}B_{0}(d\omega).$ 

\begin{rem} Throughout we use $\mathscr{P}(\lambda)$ to denote a $\mathrm{Poisson}(\lambda)$ random variable which may otherwise be indexed by $i,j,k,l$ etc.
\end{rem}
%\begin{rem}\label{mudecomp}
%The latter statement of independence over sets, which is a defining property %of $\mathrm{CRM}$ applies to both continuous and discrete cases of $B_{0},$ %and will
%make more transparent some of our initial representations and derivations in %the latter case. Consequently, for each $j$, the jumps $\{s_{j,k} : w_{j,k} %\in Q_{j,l}, k\ge 1\}$, for $l\in\{1,2,\ldots\}$ countable number of disjoint %sets, are independent and specified by Lévy densities 
%$B_{0}(Q_{j,l})\rho_{j}$, and the atoms are selected iid proportional to %$\mathbb{I}_{\{\omega\in Q_{j,l}\}}B_{0}(d\omega)$ $l=1,2,\ldots$. 
%\end{rem}
Now, following~\cite{James2017,Titsias,FoFZhou}, we define Poisson IBP for each group $j$ of $i\in[M_j]$ customers as: $Z^{(i)}_j = \sum_{k=1}^{\infty}\mathscr{P}^{(i)}_{j,k}(s_{j,k})\delta_{w_{j,k}}|B_j \overset{iid}{\sim} \mathrm{PoiP}(B_{j}),$ where $B_j \sim \mathrm{CRM}(\tau_j,B_0)$. The collection $(\mathscr{P}^{(i)}_{j,k}(s_{j,k}))_{k\ge 1}, i\in[M_{j}]|(s_{j,k})_{k\ge 1}$ are conditionally independent such that $\mathscr{P}^{(i)}_{j,k}(s_{j,k}))\sim \mathrm{Poisson}(s_{j,k}).$ Furthermore, 
it follows that the sum-process $\sum_{i=1}^{M_{j}}Z^{(i)}_{j}\overset{d}=\sum_{k=1}^{\infty}\mathscr{P}_{j,k}(M_{j}s_{j,k})\delta_{w_{j,k}}.$ It follows that if $B_{0}$ is non-atomic the processes do not share any features $(w_{j,k})$ across the $j\in[J],$ groups but otherwise may share features within each group. Furthermore, the properties of the processes within each group may be read from~\cite{James2017}[Section 4], 

As with the classic Bernoulli case~\cite{Thibaux}, which was influenced by the analogous operations for the HDP~\cite{HDP}, and the single customer case $(M_{j}=1, j\in[J])$ of the Poisson-Gamma-Gamma HIBP discussed in the literature~\cite{ZhouPadilla2016}, we create general Poisson HIBP models by specifying $B_0$ to be a discrete random measure that fosters sharing across the $J$ groups.  Specifically, we have $B_0=\sum_{l=1}^{\infty}\lambda_l\delta_{Y_{l}} \sim \mathrm{CRM}(\tau_0,F_0)$ where $F_0$ is a proper probability distribution, assumed to be non-atomic, on $\Omega,$ and $\mathbb{E}[e^{-tB_0(\Omega)}]=e^{-\Psi_{0}(t)}$, with $\Psi_{0}(t)=\int_{0}^{\infty}(1-e^{-t\lambda})\tau_{0}(\lambda)d\lambda,$ and $\int_{0}^{\infty}\tau_{0}(\lambda)d\lambda=\infty.$ This formulation gives the general Poisson HIBP as, for $i\in[M_{j}], j\in[J]$: $Z^{(i)}_j|B_j \overset{iid}{\sim} \mathrm{PoiP}(B_{j}), \mu_{j}|B_{0}\sim \mathrm{CRM}(\tau_{j},B_{0}), B_{0}\sim \mathrm{CRM}(\tau_{0},F_{0}).$

Before we proceed to our formal analysis we mention that the work of \citep{Masoerotrait} produces perhaps the first posterior calculations for a large class of hierarchical latent feature processes based on integer-valued entries. This includes a Poisson based variant. Those results are also presented  in  ~\citep{BerahaFavscaled}. Results of similar resolution could easily  be obtained for the Poisson HIBP by applying a straightforward application of the results in\cite{James2017}[Section 5] for multivariate IBP. However, as we shall show much more detailed and careful analysis is needed to obtain results yielding the most tractable forms and interpretability we obtain for the type of species sampling models we discuss here. In addition, further modifications to our HIBP can be easily incorporated by using the scaled-subordinators~\cite{JOT} as in~\cite{BerahaFavscaled, CamerFavscaled}, in addition one can use \cite{JOT}[Section 5.2] to induce different rates for counts of species. One may consult~\cite{hibp23} for results on the larger class general spike and slab HIBP, and in particular~\cite{hibp23}[Proposition 3.2] which shows how to couple any of those general processes to a Poisson HIBP which may have relevance in a species sampling setting. Again we reiterate, as is the case for basic BNP models like the Dirichlet Process or its Pitman-Yor Process~\cite{IJ2001,IJ2003,Pit96,Pit02} generalizations, as well as those in ~\cite{JLP2}, our models are well suited as building blocks for more intricate models involving perhaps covariates and other hierarchical parametric structures based on domain expertise. 

Throughout, we will use \( X \sim \mathrm{tP}(s) \) to denote a zero-truncated \(\mathrm{Poisson}(\lambda)\) distribution where \(
\mathbb{P}(X=x|s) = \frac{s^{x} e^{-s}}{1 - e^{-s}}\) for  $x =1, 2, \ldots$
A \(\mathrm{MtP}\) variable is defined by mixing appropriately over \(s\). Multivariate extensions are defined in a similar way. All such variables appear in different contexts in the literature. $G_{b}\sim \mathrm{Gamma}(b,1)$ denotes a gamma random variable with shape $b$ and scale $1.$ Additionally, a variable, say \( T_{\alpha}(y) \), is a (simple) generalized gamma random variable if its Laplace transform is of the form 
$
\mathbb{E}[e^{-s T_{\alpha}(y)}] = e^{-y \left( (1+s^{\alpha}) - 1 \right)}
$
for \( 0 < \alpha < 1 \), and otherwise has the density of an exponentially tilted stable variable. This is a commonly used variable and corresponding  process that yields power law behaviour. We will show stark contrasts between results for corresponding Gamma and Generalized Gamma processes.

\subsection{Properties of Poisson IBP}
We now proceed to provide descriptions of the relevant marginal, posterior and predictive distributions. We first begin with an interpretation of some of the relevant results in \cite{James2017}[Section 3 and 4.2] for non-hierarchical setting which will also help us introduce some key quantities and distributions, where $B_{0}$ is considered to be given. Our description below based on decomposing the relevant space into a set where the $M_{j}$ customers do not sample from and its complement, where $B_{j}$ has a compound Poisson component, which identifies the appropriate marginals, joint and conditional distribution of variables. We believe this leads to a more clear description of the results and underlying mechanisms in~\cite{James2017}, which can be applied more broadly.

\begin{prop}\label{IBPpost}\cite{James2017}[Section 3 and 4.2] For each $j,$ consider $Z^{(i)}_j |B_j \overset{iid}{\sim} \mathrm{PoiP}(B_j)$, for $B_{j}\sim \mathrm{CRM}(\tau_{j},B_{0}).$ Set 
$\psi_{j}(M_{j})=\int_{0}^{\infty}(1-e^{-sM_{j}})\tau_{j}(s)ds.$
The event $\{k: \mathscr{P}^{(i)}_{j,k}(s_{j,k})=0, i\in[M_{j}]\}$, with $\mathbb{P}(\mathscr{P}^{(1)}_{j}(s)=0,\ldots,\mathscr{P}^{(M_{j})}_{j}(s)=0|s)=e^{-sM_{j}},$
induces a decomposition of the  L\'evy density $\tau_{j}$ of $B_{j}$ as:
\begin{enumerate}
    \item $\tau_{j}(s)=\tau^{(M_{j})}_{j}(s)+\psi_{j}(M_{j})f_{S_{j}}(s)$
    where $\tau^{(M_{j})}_{j}(s):=e^{-sM_{j}}\tau_{j}(s),$
    \item and $f_{S_{j}}(s)=(1-e^{-sM_{j}})\tau_{j}(s)/\psi_{j}(M_{j})$ is a proper probability density function (pdf).
    \item Hence there is a decomposition, 
\begin{equation}
\label{mudecomp}
B_{j}\overset{d}{=}B_{j,M_{j}}+\sum_{\ell=1}^{\xi_{j}}S_{j,\ell}\delta_{\omega_{j,\ell}}
\end{equation}
where $B_{j,M_{j}}\sim \mathrm{CRM}(\tau^{(M_{j})}_{j},B_{0})$,
 $\xi_{j}\sim \mathrm{Poisson}(\psi_{j}(M_{j})B_{0}(\Omega))$,
the $(\omega_{j,\ell})$ are iid $\bar{B}_{0}$ and the $(S_{j,\ell})$ are iid with pdf $f_{S_{j}}(s).$
\item For each \(\ell \in [\xi_{j}]\), there are independent vectors \((\tilde{C}^{(1)}_{j,\ell}, \ldots, \tilde{C}^{(M_{j})}_{j,\ell}) | S_{j,\ell} = s\) with a multivariate zero-truncated Poisson distribution.
$\mathbb{P}(\tilde{C}^{(1)}_{j,\ell}=c^{(1)}_{j,\ell},\ldots,\tilde{C}^{(M_{j})}_{j,\ell}=c^{(M_{j})}_{j,\ell}|s)=s^{c_{j,\ell}}e^{-sM_{j}}/[(1-e^{-sM_{j}})\prod_{i=1}^{M_{j}}c^{(i)}_{j,\ell}!]
$
for $c_{j,\ell}=\sum_{i=1}^{M_{j}}c^{(i)}_{j,\ell}=1,2,\ldots$
\item There is the joint distribution of $(\tilde{C}^{(1)}_{j,\ell},\ldots, \tilde{C}^{(M_{j})}_{j,\ell}),S_{j,\ell},$ for $c_{j,\ell}=\sum_{i=1}^{M_{j}}c^{(i)}_{j,\ell}=1,2,\ldots,$
\begin{equation}
s^{c_{j,\ell}}e^{-sM_{j}}\tau_{j}(s)/[\psi_{j}(M_{j})\prod_{i=1}^{M_{j}}c^{(i)}_{j,\ell}!]
\label{joint1}
\end{equation}
\item Hence integrating over $\tau_{j}$ in~\eqref{joint1} leads to the marginal distribution, with distribution denoted  $\mathrm{IBP}(C^{(i)}_{j},i\in[M_{j}],\tau_{j},B_{0}),$
\begin{equation}
\label{item:key sum}
(Z^{(i)}_{j}, i\in[M_{j}])\overset{d}=(\sum_{\ell=1}^{\xi_{j}}\tilde{C}^{(i)}_{j,\ell}\delta_{\omega_{j,\ell}},i\in[M_{j}]),
\end{equation}
where $Z^{(i)}_{j}(\Omega)\overset{d}=\sum_{\ell=1}^{\xi_{j}}\tilde{C}^{(i)}_{j,\ell},$ component-wise and jointly.
\item The posterior distribution of $B_{j}|(Z^{(i)}_{j}, i\in[M_{j}])$ is described by the decomposition in~\eqref{mudecomp}, fixing the values of $\xi_{j}$ and $(\omega_{j,\ell},\ell\in [\xi_{j}])$ and for each  $\ell$ applying Bayes rule to
\eqref{joint1} to obtain the conditional density of $S_{j,\ell}|(\tilde{C}^{(1)}_{j,\ell},\ldots, \tilde{C}^{(M_{j})}_{j,\ell}).$ The law of $B_{j,M_{j}}\sim \mathrm{CRM}(\tau^{(M_{j})}_{j},B_{0})$ remains unchanged since no points are selected from that process.
\end{enumerate}
\end{prop}
\begin{rem}
In the non-hierarchical result above the $C^{(i)}_{j,\ell},$ with respect to the posterior distribution, are considered to be observed counts of OTUs for each individual sample $Z^{(i)}_{j}.$ In the scenario following  $C^{(i)}_{j,\ell},$ are generally latent.     
\end{rem}

\subsection{Descriptions of the Poisson HIBP and the Allocation Process}

Now, in our HIBP setting, when \(B_{0}=\sum_{l=1}^{\infty}\lambda_{l}\delta_{Y_{l}}\sim \mathrm{CRM}(\tau_{0},F_{0})\), and hence both discrete and random, we can use Proposition~\ref{IBPpost} and our stated properties of \(\mathrm{CRM}\). For each \(j\), we set \(B_{0}(Q_{j,l})=\lambda_{l}\) to obtain more refined and key representations. That is:

\begin{enumerate}
    \item \(B_{j}|B_{0}\overset{d}=\sum_{l=1}^{\infty}\sigma_{j,l}(\lambda_{l})\delta_{Y_{l}}\) where,
    \item \(\sigma_{j,l}(\lambda)\) has distribution given by the Laplace exponent \(\lambda \psi_{j}(t)\), with density denoted as \(\eta_{j}(t_{j}|\lambda)\), and also \(\sigma_{j,l}(\lambda)=\sum_{k=1}^{\infty}s_{j,k,l}\), where \((s_{j,k,l})_{\{k\ge 1\}}\) are jumps of \(B_{j}\) in an interval of length \(\lambda\) with L\'evy density \(\lambda\tau_{j}(s)\).
    \item \(\xi_{j}\overset{d}=\sum_{l=1}^{\infty}\xi_{j,l}\), for \(\xi_{j,l}\sim \mathrm{Poisson}(\psi_{j}(M_{j})\lambda_{l})\).
    \item \((Z^{(i)}_{j},i\in[M_{j}])\overset{d}=(\sum_{l=1}^{\infty}[\sum_{k=1}^{\xi_{j,l}}\tilde{C}^{(i)}_{j,k,l}]\delta_{Y_{l}},i\in[M_{j}])\).
    \item Where \(((\tilde{C}^{(i)}_{j,k,l}, i\in[M_{j}]), S_{j,k,l})\) has the same distribution as in~\eqref{joint1}. Use~\eqref{item:key sum}.
\end{enumerate}

Note importantly that there is also the representation

\[
(Z^{(i)}_{j},i\in[M_{j}])\overset{d}=(\sum_{l=1}^{\infty}\mathscr{P}^{(i)}_{j,l}(\sigma_{j,l}(\lambda_{l}))\delta_{Y_{l}},i\in[M_{j}]),
\]

where \(\mathscr{P}^{(i)}_{j,l}(\sigma_{j,l}(\lambda_{l}))\overset{d}=\sum_{k=1}^{\infty}\mathscr{P}^{(i)}_{j,k,l}(s_{j,k,l})\), which reveals the random intensities \(\sigma_{j,l}(\lambda_{l})\) that we can interpret as the mean abundance rate of species \(Y_{l}\) in group \(j\).


\subsection{The species allocation process}
We now provide an analysis for the key \textit{species allocation process} 

\[
\mathscr{A}_{J} \overset{d}{=} \left( \sum_{l=1}^{\infty} \xi_{j,l} \delta_{Y_{l}}, \; j \in [J] \right),
\]

which is a multivariate Poisson IBP in the sense of \cite{James2017}[Section 5]. This process constitutes the allocation of multiplicities of the unique species across the \( J \) groups and, as we shall show, only depends on the components of \( B_{0} \) and the samples \( (M_{j}, j \in [J]) \) through \( (\psi_{j}(M_{j}), j \in [J]) \). That is to say, irrespective of the type of entries that would appear in a non-hierarchical general spike and slab IBP, in this case, counts \( \tilde{C}^{(i)}_{j,\ell} \), as seen in \cite{hibp23}[Proposition 2.2].

The next result describes specific properties of this multivariate Poisson \(\mathrm{IBP}\) process, which, although not immediately obvious, plays a crucial role throughout, as it serves as a multivariate extension of the discretization process in \cite{Pit97}; see also \cite{James2017}[Remark 4.2]. Our approach utilizes a description based on a method of decompositions, while relying on the results in \cite{James2017}[Section 5] for the multivariate IBP. We will present the result first, followed by a detailed elaboration on its interpretation within a microbiome species sampling context.

\begin{prop}\label{prop2}Consider $\mathscr{A}_{J}\overset{d}=(\sum_{l=1}^{\infty}\xi_{j,l}\delta_{Y_{l}}, j\in[J]),$  where $\xi_{j,l}\sim \mathrm{Poisson}(\psi_{j}(M_{j})\lambda_{l}),$ Then the event $\{l: \xi_{j,l}=0, j\in[J]\}$, with $\mathbb{P}((\xi_{j,l}=0,j\in[J])|\lambda)={\mbox e}^{-\lambda\sum_{j=1}^{J}\psi_{j}(M_{j})}$
induces a decomposition of the  L\'evy density $\tau_{0}$ of $B_{0}$ as: 
\begin{enumerate}
    \item $\tau_{0}(\lambda)=\tau_{0,J}(\lambda)+\Psi_{0}(\sum_{j=1}^{J}\psi_{j}(M_{j}))f_{H}(\lambda),$ {\mbox { where }} $\tau_{0,J}(\lambda)={\mbox e}^{-\lambda\sum_{j=1}^{J}\psi_{j}(M_{j})}\tau_{0}(\lambda).$
    \item Where $f_{H}(\lambda)=\frac{(1-{\mbox e}^{-\lambda\sum_{j=1}^{J}\psi_{j}(M_{j})})\tau_{0}(\lambda)}{\Psi_{0}(\sum_{j=1}^{J}\psi_{j}(M_{j}))}$ is a proper density.
    \item Hence setting $\tau_{0,J}(\lambda)={\mbox e}^{-\lambda\sum_{j=1}^{J}\psi_{j}(M_{j})}\tau_{0}(\lambda),$ this leads to a decomposition of $B_{0}:$
  \begin{equation}
    \label{postdisint}
B_{0}\overset{d}=B_{0,J} + \sum_{l=1}^{\varphi} H_{l}\delta_{\tilde{Y}_{l}}
    \end{equation}   
where $B_{0,J}\sim \mathrm{CRM}(\tau_{0,J},F_{0}),$  $(\tilde{Y}_{l})$ are iid $F_{0}$ and represent the $\varphi \sim \mathrm{Poisson}(\Psi_{0}(\sum_{j=1}^{J}\psi_{j}(M_{j})))$ number of distinct features/species selected by the $\sum_{j=1}^{J}M_{j}$ customers. The $(H_{l},l\in[\varphi])\overset{iid}\sim f_{H}$ are the corresponding jumps of $B_{0}$ corresponding to the mean abundance rate of observed species $\tilde{Y}_{l}.$
\item $\mathscr{A}_{J}\overset{d}=(\sum_{l=1}^{\varphi}X_{j,l}\delta_{\tilde{Y}_{l}},j\in[J])$
with $\varphi$ iid vectors, where for each $l\in[\varphi],$ they correspond to,
$(X_{j,l}=x_{j,l}, j\in[J])|H_{l}=\lambda$ a multivariate zero-truncated Poisson distribution denoted as $\mathrm{tP}(\lambda (\psi_{1}(M_{1}),\ldots,\psi_{J}(M_{J}))$. Where $x_{l}:=\sum_{j=1}^{J}x_{j,l}=1,2,\ldots$
\item Hence $\tilde{X}_{l}:=\sum_{j=1}^{J}X_{j,l}|H_{l}=\lambda\sim \mathrm{tP}(\lambda \sum_{j=1}^{J}\psi_{j}(M_{j}))$ with marginal distribution denoted as $\mathrm{MtP}(\sum_{j=1}^{J}\psi_{j}(M_{j}),\tau_{0})$
\item $(X_{j,l},j\in[J])|\tilde{X}_{l}=x_{l}\sim \mathrm{Multi}(x_{l}; q_{1},\ldots, q_{J})$, for $q_{j}=\frac{\psi_{j}(M_{j})}{\sum_{v=1}^{J}\psi_{v}(M_{v})}.$
\end{enumerate}
\end{prop}

We next describe the posterior distribution of $B_{0}|\mathscr{A}_{J}$ which will play several important roles in the sequel. We see it's posterior has the same form as the univariate Poisson IBP in~\cite{James2017}[Section 4.2], as it depends only on 
$(\sum_{l=1}^{\infty}[\sum_{j=1}^{J}\xi_{j,l}]\delta_{Y_{l}})|B_{0}\sim \mathrm{PoiP}([\sum_{j=1}^{J}\psi_{j}(M_{j})]B_0).$
\begin{prop}\label{propN} The posterior distribution of $B_{0}|\mathscr{A}_{J}$ only depends on the $(\tilde{X}_{l}=x_{l},\tilde{Y}_{l},l\in[\varphi],\varphi=r)$ 
 and follows the decomposition of $B_{0}$ in \eqref{postdisint} with given quantities as indicated, the distribution of $B_{0,J}\sim \mathrm{CRM}(\tau_{0,J},F_{0})$ unchanged, and $H_{l}|\tilde{X}_{l}=x_{l}$ having density proportional to $\lambda^{x_{l}}e^{-\lambda\sum_{j=1}^{J}\psi_{j}(M_{j})}\tau_{0}(\lambda)$, conditionally independent for $l\in[r].$
\end{prop}

\subsubsection{Interpretations of the Allocation Process $\mathscr{A}_{J}$ in the Microbiome Setting}\label{Remark:splitdata}

Proposition~\ref{prop2} indicates that \(\varphi\) distinct species \((\tilde{Y}_{l}, l\in[\varphi])\) will be generated and distributed across the \(J\) groups. These species correspond to \(X_{j,l}\) unique subspecies, which we can map to markers \((\tilde{U}_{j,k,l}, k\in[X_{j,l}])\) associated with corresponding OTU clusters or counts.

Additionally, \(\tilde{X}_{l}=\sum_{j=1}^{J}X_{j,l}\) measures the number of distinct subspecies (markers) linked to specific OTUs across the \(J\) communities contributing to the counts of $\tilde{Y}_{l}.$ As previously mentioned, \(H_{l}\) represents the mean abundance rates of the observed species \(\tilde{Y}_{l}\).

Furthermore, from Proposition~\ref{propN}, we have \(B_{0,J} = \sum_{l=1}^{\infty} \lambda'_{l} \delta_{Y'_{l}}\), where \((\lambda'_{l}, Y'_{l})_{l\geq 1}\) represents the species \((Y'_{l})_{l \geq 1}\) that do not appear in the \((M_{j}, j \in [J])\) samples. Here, \((\lambda'_{l})_{l \geq 1}\) are the corresponding random rates determined by the L\'evy density \(\tau_{0,J}(\lambda) = e^{-\lambda \sum_{j=1}^{J} \psi_{j}(M_{j})} \tau_{0}(\lambda)\).

For general but related interpretations of \((H_{l}, \tilde{X}_{l})_{l\ge 1}\), see~\cite{Pit97}[Section 3] and
~\cite{James2017}[Proposition 3.3]. Note that in many applications within our present setting, \(\tilde{X}_{l}\) is not observed directly.

\subsection{Exact sampling of the Poisson HIBP marginal distribution}\label{exactsampling}
We now establish one of our main results which allows to sample exactly from the Poisson HIBP marginal process. Note despite the relative simplicity of sampling,these lead to exact sampling of quite complex multi-dimensional distributions. See section~\ref{marginal} for precise descriptions of their apparently complex joint distributions. As noted this may be used as a basis to describe a generative process for data arising in microbiome or other species sampling contexts. Important for our general exposition,  for $\tilde{C}_{j,k,l}:=\sum_{i=1}^{M_{j}}\tilde{C}^{(i)}_{j,k,l},$ the joint distribution of $S_{j,k,l}, \tilde{C}_{j,k,l}$ may be expressed as, for $c_{j,k,l}=1,2,\ldots,$
\begin{equation}
\label{MtPsimple}
\frac{s^{c_{j,k,l}}e^{-sM_{j}}\tau_{j}(s)}{\psi^{(c_{j,k,l})}_{j}(M_{j})}\times 
\frac{M_{j}^{c_{j,k,l}}\psi^{(c_{j,k,l})}_{j}(M_{j})}{\psi_{j}(M_j)c_{j,k,l}!}=\frac{s^{c_j,k,l} e^{-sM_{j}}}{(1-e^{-M_{j}})c_{j,k,l}!} \times \frac{(1-e^{-sM_{j}})\tau_{j}(s)}{\psi_{j}(M_{j})}
\end{equation}
where \(\psi^{(c_{j,k,l})}_{j}(M_{j})=\int_{0}^{\infty}s^{c_{j,k,l}}e^{-sM_{j}}\tau_{j}(s)ds\) provides different interpretations of~\eqref{MtPsimple}, as detailed in~\cite{Pit97}. We denote \(\tilde{C}_{j,k,l} \sim \mathrm{MtP}(M_{j}, \tau_{j})\), where \(\tilde{C}_{j,k,l} | S_{j,k,l} = s \sim \mathrm{tP}(sM_{j})\), which indicates a zero-truncated \(\mathrm{Poisson}(sM_{j})\) variable, and \(S_{j,k,l}\) has a marginal density \(f_{S_{j}}\) as in Proposition~\ref{IBPpost}. See~\cite{James2017}[Section 4.2].


In our species sampling context, $(S_{j,k,l},\tilde{C}_{j,k,l},\tilde{U}_{j,k,l})$ are respectively the mean abundance rate of OTU, total counts of OTU, and their corresponding markers $\tilde{U}_{j,k,l},$ associated with an observed species $\tilde{Y}_{l}.$ 
As we mentioned $X_{j,l}$ counts the number of distinct markers for OTU clusters in community $j$. Additionally, also important for our general exposition, is the work of \cite{Pit97}[Proposition 12, Corollary 13], as noted in ~\cite{James2017}[Remark 4.1], also gives the variables $(H_{l},\tilde{X}_{l})$ another meaning in the Poisson setting, in terms of decomposing the space. From that work the joint distributions $(H_{l},\tilde{X}_{l})$ can be expressed in terms of $H_{l}|\tilde{X}_{l}=x_{l}$ and $\tilde{X}_{l},$ as,  
\begin{equation}
\label{HXdecomp}
\frac{\lambda^{x_{l}}e^{-\lambda\sum_{j=1}^{J}\psi_{j}(M_{j})}\tau_{0}(\lambda)}{\Psi^{(x_{l})}_{0}(\sum_{j=1}^{J}\psi_{j}(M_{j}))}\times \frac{{(\sum_{j=1}^{J}\psi_{j}(M_{j}))}^{x_{l}}\Psi^{(x_{l})}_{0}(\sum_{j=1}^{J}\psi_{j}(M_{j}))}
{x_{l}!\Psi_{0}(\sum_{j=1}^{J}\psi_{j}(M_{j}))}
\end{equation}
for $\Psi^{(x_{l})}_{0}(\sum_{j=1}^{J}\psi_{j}(M_{j}))=\int_{0}^{\infty}
\lambda^{x_{l}}e^{-\sum_{j=1}^{J}\psi_{j}(M_{j})}\tau_{0}(\lambda)d\lambda.$
That is $\tilde{X}_{l}\sim \mathrm{MtP}(\sum_{j=1}^{J}\psi_{j}(M_{j}),\tau_{0})$

\begin{rem}
While these distributions may appear to be somewhat exotic, they appear in the works of \cite{James2017,Pit97,Titsias,FoFZhou} and elsewhere and are easily sampled in for instance the gamma and generalized gamma cases, as we shall show.
\end{rem}

\begin{thm}\label{sumsampleprop}
Let for each $j$, $(Z^{(i)}_{j}, i\in [M_{j}]) | B_{j} \overset{iid}\sim \mathrm{PoiP}(B_{j})$, where $B_{j} | B_{0} \sim \mathrm{CRM}(\tau_{j}, B_{0})$ conditionally independent across $j\in[J]$. Then consider the sum process $(\sum_{i=1}^{M_{j}} Z^{(i)}_{j} , j\in[J])$, where $\sum_{i=1}^{M_{j}} Z^{(i)}_{j} | B_{j} \sim \mathrm{PoiP}(M_{j}B_{j}),$ and $B_{0}\sim~
\mathrm{CRM}(\tau_{0},F_{0}).$
    \begin{enumerate}
    \item The joint marginal distribution of the sum process $(\sum_{i=1}^{M_{j}} Z^{(i)}_{j}, i\in[M_{j}],j\in [J])$ is equal in distribution to
    \begin{equation}\label{prop:sumequation}
(\sum_{l=1}^{\varphi} N_{j,l}\delta_{\tilde{Y}_{l}}, j\in [J])\overset{d}=((\sum_{l=1}^{\varphi} \sum_{k=1}^{X_{j,l}}\tilde{C}_{j,k,l}\delta_{\tilde{Y}_{l}}, j\in [J])
    \end{equation}
\item where $(\tilde{C}_{j,k,l}=\sum_{i=1}^{M_{j}} \tilde{C}^{(i)}_{j,k,l}, k\in [X_{j,l}]) \overset{iid}\sim \mathrm{MtP}(M_{j}, \tau_{j})$ with the $X_{j,l}$ components independent across $l$.
\item $\tilde{X}_{l}\sim \mathrm{MtP}(\sum_{j=1}^{J}\psi_{j}(M_{j}),\tau_{0})$
\item $(X_{j,l},j\in[J])|\tilde{X}_{l}=x_{l}\sim \mathrm{Multi}(x_{l}; q_{1},\ldots, q_{J})$, for $q_{j}=\frac{\psi_{j}(M_{j})}{\sum_{v=1}^{J}\psi_{v}(M_{v})}.$    \item  $(\sum_{k=1}^{X_{j,l}} \tilde{C}^{(i)}_{j,k,l}, i\in [M_{j}]) |N_{j,l}:=\sum_{k=1}^{X_{j,l}} \tilde{C}_{j,k,l} = n_{j,l}$ is $\mathrm{Multi}(n_{j,l}; 1/M_{j}, \ldots, 1/M_{j})$, for each $j,l$,
    \end{enumerate}
\end{thm}

Theorem~\ref{sumsampleprop} indicates that one can sample from the marginal distribution of $(Z^{(i)}_{j},i\in[M_{j}], j\in[J]),$ by first sampling $((N_{j,l}, j\in [J]),\tilde{Y}_{l},l\in[\varphi],\varphi)$ from the sum process as in~\eqref{prop:sumequation} and then applying Multinomial sampling as in item 5. See \cite{hibp23}[Theorem 3.1 and Proposition 3.2] for indications on how to sample more general spike and slab HIBP and how to couple them to the Poisson HIBP.

\section{Posterior distribution for Poisson HIBP}\label{posteriorPoissonHIBP}
We now address the posterior distribution of the Poisson HIBP, which exhibits remarkable properties
Here the given structure is  $\mathbf{Z}_{J}:=(\sum_{k=1}^{X_{j,l}}\tilde{C}^{(i)}_{j,k,l},\tilde{Y}_{l}, l\in[r],\varphi=r, i\in [M_{j}], j\in J).$ However in view of Theorem~\ref{sumsampleprop}, it suffices to work with the information in the sum process $(N_{j,l},\tilde{Y}_{l}, l\in[r],\varphi=r, j\in J),$ where again $N_{j,l}=\sum_{k=1}^{X_{j,l}}\tilde{C}_{j,k,l},$ for descriptions of the posterior distribution. The task then becomes to describe distributions of $(\tilde{C}_{j,k,l}, k\in [X_{j,l}], X_{j,l})$ given this information, which in general is a difficult problem, see \citep{hibp23}[Section 4 and Theorem 4.1]. 

One of our innovations here is to first note that conditioning on $(N_{j,l}, j\in[J])$, and $H_{l}=\lambda$ we can apply results in \cite{Kolchin,Pit97}, and also \cite{JLP2,FoFZhou}, to directly deduce the following key results based on finite Gibbs $\mathrm{EPPF},$ with these $\mathrm{EPPF}$ (Exchangeable Partition Probability Function) otherwise appearing  specifically in \cite{JLP2}{Proposition 4] and \cite{FoFZhou}[Sections 2.3,3]. See~\cite{Pit96,Pit02} for more on general EPPF's for species sampling models.

\begin{prop}\label{prop:GibbsEPPF}
Consider the Poisson HIBP setting in Proposition~\ref{sumsampleprop}. Then for each $j\in [J],$ $(\tilde{C}_{j,k,l}, k\in [X_{j,l}], X_{j,l})$ given $N_{j,l}=n_{j,l}$ and $H_{l}=\lambda$,  follows the distribution of a random partition of the integers $[n_{j,l}].$  Such that $\sum_{k=1}^{X_{j,l}}\tilde{C}_{j,k,l}=n_{j,l},$ where $\tilde{C}_{j,k,l}=c_{j,k,l}$ dictates the size of each block and $X_{j,l}=x_{j,l}$ corresponds to the random number of blocks, according to the finite Gibbs EPPF arising in~\cite{JLP2,FoFZhou} as follows:

\begin{enumerate}
\item The finite Gibbs partition distribution specifying these conditional distributions is, for
$\mathbf{c}_{j,l}=(c_{j,k,l},k\in[x_{j,l}]),$ and  $\psi^{(c)}_{j}(M_{j})=\int_0^{\infty} s^{c}e^{-sM_j}\tau_{j}(s)\,ds,$
:
\begin{equation}
\label{GibbsEPPF}
p^{[n_{j,l}]}(\mathbf{c}_{j,l}|\lambda\tau_{j}, M_j) = \frac{\lambda^{x_{j,l}}\prod_{k=1}^{x_{j,l}}\psi^{(c_{j,k,l})}_{j}(M_{j})}{\Xi^{[n_{j,l}]}_j(\lambda,M_j)}
\end{equation}
\item where, there is the identity:
$
\int_0^{\infty} t^{n_{j,l}}e^{-tM_j}\eta_j(t|\lambda)\,dt = e^{-\lambda\psi_{j}(M_{j})}\Xi^{[n_{j,l}]}_j(\lambda,M_{j})
$
for $\sum_{*}$ denoting sum over all positive integers $\mathbf{c}_{j,l}$ such that $\sum_{k=1}^{x_{j,l}}c_{j,k,l}=n_{j,l}$:
\begin{equation}
\Xi^{[n_{j,l}]}_j(\lambda,M_j)=\sum_{x_{j,l}=1}^{n_{j,l}}\frac{n_{j,l}!\lambda^{x_{j,l}}}{x_{j,l}!}\sum_{*}\frac{\prod_{k=1}^{x_{j,l}}\psi^{(c_{j,k,l})}_{j}(M_{j})}{\prod_{k=1}^{x_{j,l}} c_{j,k,l}!}
\end{equation}
\item The distribution of the number of blocks $X_{j,l}=x_{j,l}$ conditioned on $(N_{j,l}=n_{j,l}, j\in[J], H_{l}=\lambda$ is, $X_{j,l}=0$ when $n_{j,l}=0$, and otherwise:
\begin{equation}
\label{Kn}
p^{[n_{j,l}]}(x_{j,l}|\lambda\tau_{j},M_j) = \frac{n_{j,l}!\lambda^{x_{j,l}}}{x_{j,l}!}\sum_{*}\frac{\prod_{k=1}^{x_{j,l}}\psi^{(c_{j,k,l})}_{j}(M_{j})}{\Xi^{[n_{j,l}]}_j(\lambda,M_j)\prod_{k=1}^{x_{j,l}} c_{j,k,l}!}
\end{equation}
\item As in \cite{Kolchin, Pit97}, \eqref{Kn} and~\eqref{MtPsimple}  yields the identity, $p^{[n_{j,l}]}(x_{j,l}|\lambda\tau_{j},M_j)=$
\begin{equation}
\label{sumid}
\frac{n_{j,l}!\lambda^{x_{j,l}}({\psi_{j}(M_{j})})^{x_{j,l}}}{x_{j,l}!M^{n_{j,l}}_{j}\Xi^{[n_{j,l}]}_j(\lambda,M_j)}\mathbb{P}(\tilde{C}_{j,1,l}+\ldots+\tilde{C}_{j,x_{j,l},l}=n_{j,l})
\end{equation}
\end{enumerate}
\end{prop}

\begin{rem} See~\cite{hibp23}, and also~\cite{JLP2}, for a detailed example in the case of $\tau_{j}(s)=\theta_{j}s^{-1}e^{-s\zeta_{j}}$ corresponding to $B_{j}|B_{0}\sim \mathrm{G}(\theta_{j},\zeta;B_{0})$ denoting a gamma process and its relation to sum-log distribution which informs the the strategy in ~\cite{ZhouPadilla2016}. 
The case of $\tau_{j}(s)=Cs^{\alpha-1},$ corresponding to $0<\alpha<1$ stable processes is treated in~\cite{Pit97}, see also~\cite{Pit06}[p. 73], and will be illustrated in the form of generalized gamma processes later. 
\end{rem}

We now present an implementable description of the posterior distribution for Poisson HIBP using $p^{[n_{j,l}]}(\mathbf{c}_{j,l}|\tau_{j}, M_j)\Xi^{[n_{j,l}]}_j(1,M_j)=\prod_{k=1}^{x_{j,l}}\psi^{(c_{j,k,l})}_{j}(M_{j}).$

\begin{thm}\label{postPoissonHIBP}
A description of the posterior distributions of $(B_{j}\in [J],B_{0})|\mathbf{Z}_{J}$ is as follows,
\begin{enumerate}
\item The joint distribution of $(B_{j},j\in[J]),B_{0}|\mathbf{Z}_{J}$ is such that component-wise and jointly, is equivalent in distribution to,
  \begin{equation}
  \label{postsumrep}
  (B_{j,M_{j}}+\sum_{l=1}^{r}\left[\hat{\sigma}_{j,l}(H_{l})+\sum_{k=1}^{X_{j,l}}S_{j,k,l}\right]\delta_{\tilde{Y}_{l}}, j\in[J]),B_{0,J}+\sum_{l=1}^{r}H_{l}\delta_{\tilde{Y}_{l}} 
  \end{equation}
for $B_{0,J}\sim \mathrm{CRM}(\tau_{0,J},F_{0}),$ $B_{j,M_{j}}\sim\mathrm{CRM}(\tau^{(M_{j})}_{j},B_{0,J})$, and 
\item $(\hat{\sigma}_{j,l}(H_{l}),j\in[J])|H_{l}=\lambda$ are independent with density $\eta^{[0]}_{j}(t_{j}|\lambda,M_{j})=e^{-t_{j}M_{j}}\eta_{j}(t_{j}|\lambda)e^{\psi_{j}(M_{j})}$, independent of $(S_{j,k,l}).$ 
\item $S_{j,k,l}|\tilde{C}_{j,k,l}=c_{j,k,l}$ has density $\frac{s^{c_{j,k,l}}e^{-sM_{j}}\tau_{j}(s)}{\psi^{(c_{j,k,l})}(M_{j})},$ and $(\tilde{C}^{(i)}_{j,k,l}, i\in[M_{j}])|\tilde{C}_{j,k,l}=c_{j,k,l} \sim \text{Multi}(c_{j,k,l}, \frac{1}{M_{j}}, \ldots, \frac{1}{M_{j}}).$
\item  $H_{l}|\tilde{X}_{l}=x_{l}$ has density $\frac{\lambda^{x_{l}}e^{-\lambda\sum_{j=1}^{J}\psi_{j}(M_{j})}\tau_{0}(\lambda)}{\Psi^{(x_{l})}_{0}(\sum_{j=1}^{J}\psi_{j}(M_{j}))}$, where $\tilde{X}_{l}=\sum_{j=1}^{J}X_{j,l}$
\item \label{latentlaws} $(X_{j,l},(\tilde{C}_{j,k,l},k\in [X_{j,l}], l\in[r], j\in J),$ given $(N_{j,l}, j\in[J]),l\in[r])$ are conditionally independent over $l\in[r],$ with distributions proportional to 
\begin{equation}
\label{jointrep1}
\frac{\Psi^{(x_{l})}_{0}(\sum_{j=1}^{J}\psi_{j}(M_{j}))}
{\Psi_{0}(\sum_{j=1}^{J}\psi_{j}(M_{j}))}\prod_{j=1}^{J}p^{[n_{j,l}]}(\mathbf{c}_{j,l}|\tau_{j}, M_j)\Xi^{[n_{j,l}]}_j(1,M_j)
\end{equation}
where $x_{l}=\sum_{j=1}^{J}x_{j,l},$ and noting $X_{j,l}=0$ if $N_{j,l}=0.$
\item In particular $\tilde{X}_{l}|(N_{j,l}=n_{j,l},j\in[J]),l\in[r]).$ for $x_{l}=\sum_{j=1}^{J}x_{j,l},$ with $x_{j,l}=0$ when $n_{j,l}=0,$ is determined by the joint distribution of $(X_{j,l}=x_{j,l}, j\in[J])$ proportional to 
$$
\frac{\Psi^{(x_{l})}_{0}(\sum_{j=1}^{J}\psi_{j}(M_{j}))}
{\Psi_{0}(\sum_{j=1}^{J}\psi_{j}(M_{j}))}\prod_{j=1}^{J}p^{[n_{j,l}]}(x_{j,l}|\tau_{j}, M_j)\Xi^{[n_{j,l}]}_j(1,M_j)
$$
\end{enumerate}
\end{thm}
A description of the posterior distribution of $((F_{j,l}, j\in[J])_{l\ge 1}|\mathbf{Z}_{J}$ is an immediate consequence of Theorem~\ref{postPoissonHIBP} and can be read from 
the meaning of~\eqref{postsumrep} along with descriptions in Section~\ref{MicrobiomeInterpet:PostHIBP}. We omit further details for brevity.
The following proposition provides two descriptions of the posterior distribution of the mean abundance rates, denoted as $(\tilde{\sigma}_{j,l}(H_{l}), j\in[J])$, of $\tilde{Y}_{l}$ selected in the sample for each group $j\in[J]$. This result follows from the randomization of the posterior distribution of the total mass in \cite{JLP2}[Theorem 1], or equivalently in \cite{James2002}[Corollary 5.1]. See also \cite{Pit02}.
\begin{prop}\label{poissonequivalence}
Consider the Poisson HIBP setting in Theorem~\ref{postPoissonHIBP}. Let $(\tilde{\sigma}_{j,l}(H_{l}), j\in[J])$ denote the mean abundance rates of the selected species $\tilde{Y}_{l}$ for $l\in [\varphi]$ in the sample $\mathbf{Z}_{J}$. Given $(N_{j,l}=n_{j,l}, j\in[J], H_{l}=\lambda)$ for each $l\in[r]$, the vectors are conditionally independent across $j, l$, and there is a distributional equivalence:

\begin{equation}
\label{splitsigma}
\tilde{\sigma}_{j,l}(\lambda) \overset{d}{=} \hat{\sigma}_{j,l}(\lambda) + \sum_{k=1}^{X_{j,l}} S_{j,k,l}
\end{equation}

where \(\tilde{\sigma}_{j,l}(\lambda)\) has the density \(\eta^{[n_{j,l}]}_{j}(t_{j}|\lambda,M_{j}) = \frac{t_{j}^{n_{j,l}} \eta^{[0]}_{j}(t_{j}|\lambda,M_{j})}{\Xi^{[n_{j,l}]}_j(\lambda,M_{j})}\).  If \(B_{j} \sim \mathrm{G}(\theta_{j},\zeta_{j};B_{0})\), a gamma process with \(\tau_{j}(s) = \theta_{j} s^{-1} e^{-s\zeta_{j}}\), then \(\tilde{\sigma}_{j,l}(H_{l}) \sim \mathrm{Gamma}(\theta_{j} H_{l} + n_{j,l}, M_{j} + \zeta_{j})\), where $S_{j,k,l}\sim\mathrm{Gamma}(\tilde{C}_{j,k,l},M_{j}+\zeta_{j}).$ If \(B_{j}\) is a generalized gamma process with $\tau_j(s) = \frac{\theta_j}{\Gamma(1-\alpha_j)} s^{-\alpha_j-1} e^{-\zeta_j s},$ then $(M_{j}+\zeta_{j})\hat{\sigma}_{j,l}(\lambda)\overset{d}=T^{(j,l)}_{\alpha_{j}}(\frac{\theta_{j}}{\alpha_{j}}(M_{j}+\zeta_{j})^{\alpha_{j}}\lambda),$ a generalized gamma random variable, such that $\mathbb{E}[{\mbox e}^{-sT^{(j,l)}_{\alpha}(y)}] = e^{-y[(1+s)^{\alpha}-1]},$ and $S_{j,k,l}\sim \mathrm{Gamma}(\tilde{C}_{j,k,l}-\alpha_{j},M_{j}+\zeta_{j}).$ 
\end{prop}
See~\cite{JamesStick} for more on such variables, and also \cite{JLP2} for more examples.  As we shall see in Section~\ref{unseen}, the decomposition on the right hand side of~\eqref{splitsigma} is crucial for obtaining refined interpretations in the  microbiome setting.

\subsection{Some Interpretations with Respect to Microbiome Data}\label{MicrobiomeInterpet:PostHIBP}
We note that \(B_{j,M_{j}} \sim \mathrm{CRM}(\tau^{(M_{j})}_{j}, B_{0,J})\) indicates that 
\(
B_{j,M_{j}} \overset{d}{=} \sum_{l=1}^{\infty} \sigma'_{j,l}(\lambda'_{l}) \delta_{Y'_{l}},
\)
where \(\sigma'_{j,l}(\lambda'_{l})\) is interpreted as the mean abundance rate of the unseen species \(Y'_{l}\), with \((\lambda'_{l}, Y'_{l})\) defined as in Remark \ref{Remark:splitdata}. Furthermore, given \(\lambda'_{l} = \lambda\), the density of \(\sigma'_{j,l}(\lambda)\) is given by 
\(
e^{-[t_{j}M_{j} - \psi_{j}(M_{j})]} \eta_{j}(t_{j} | \lambda).
\)

Moreover, \(
\tilde{\sigma}_{j,l}(H_{l}) \overset{d}{=} \hat{\sigma}_{j,l}(H_{l}) + \sum_{k=1}^{X_{j,l}} S_{j,k,l},
\)
in~\eqref{splitsigma} of Proposition~\ref{poissonequivalence}, and Theorem~\ref{postPoissonHIBP}, corresponds to the posterior distribution of the mean abundance rate of \(\tilde{Y}_{l}\) in the \(j\)-th group based on the sample \((M_{j}, j \in [J])\). This can be utilized to sample the posterior distribution of \((\mathscr{D}_{j}, j \in [J]) | (N_{j,l}, j \in [J], l \in [r])\), as otherwise defined in \eqref{Shannon1}, among many other possibilities.

In the Gamma case, where \(
\tilde{\sigma}_{j,l}(H_{l}) \sim \mathrm{Gamma}(\theta_{j} H_{l} + n_{j,l}, M_{j} + \zeta_{j}),
\) it follows that 

\[
\left(\frac{\tilde{\sigma}_{j,l}(H_{l})}{\sum_{t=1}^{r} \tilde{\sigma}_{j,t}(H_{t})}, l \in [r]\right) \sim \mathrm{Dirichlet}(\theta_{j} H_{l} + n_{j,l}; l \in [r]),
\]

leading to fairly simple sampling from \((\mathscr{D}_{j}, j \in [J]) | (N_{j,l}, j \in [J], l \in [r], \varphi = r)\). However, the corresponding generalized gamma case where 
$(M_{j}+\zeta_{j})\hat{\sigma}_{j,l}(\lambda)\overset{d}=T^{(j,l)}_{\alpha}(\frac{\theta_{j}}{\alpha_{j}}(M_{j}+\zeta_{j})^{\alpha_{j}}\lambda),$ leads to a more detailed structure, where it follows that for each $j\in[J]$, 
\begin{equation}
\left(\frac{\tilde{\sigma}_{j,l}(H_{l})}{\sum_{t=1}^{r} \tilde{\sigma}_{j,t}(H_{t})}, l \in [r]\right) \overset{d}=
\left(\frac{T^{(j,l)}_{\alpha_{j}}(\frac{\theta_{j}}{\alpha_{j}}{(M_{j}+\zeta_{j})}^{\alpha_{j}}H_{l}) + G_{n_{j,l} - X_{j,l}\alpha_{j}}}
{T^{(j)}_{\alpha_{j}}(\frac{\theta_{j}}{\alpha_{j}}{(M_{j}+\zeta_{j})}^{\alpha_{j}}\sum_{t=1}^{r}H_{t}) + G_{n^{(+)}_{j} - X^{(+)}_{j}\alpha_{j}}}, l \in [r]\right),
\label{gengamgroupseenprobabilities}
\end{equation}

where \(T^{(j)}_{\alpha_{j}}(\frac{\theta_{j}}{\alpha_{j}}{(M_{j}+\zeta_{j})}^{\alpha_{j}}\sum_{l=1}^{r}H_{l}) \overset{d}{=} \sum_{l=1}^{r} 
T^{(j,l)}_{\alpha_{j}}(\frac{\theta_{j}}{\alpha_{j}}{(M_{j}+\zeta_{j})}^{\alpha_{j}}H_{l})\) and \( G_{n^{(+)}_{j} - X^{(+)}_{j}\alpha_{j}}\overset{d}{=} \sum_{l=1}^{r} G_{n_{j,l} - X_{j,l}\alpha_{j}}\). Furthermore, \(n^{(+)}_{j}=\sum_{l=1}^{r}n_{j,l}\) denotes the total abundance of the observed species 
\((\tilde{Y}_{l}, l \in [r])\) in group \(j\), \(X^{(+)}_{j}=\sum_{l=1}^{r}X_{j,l}\) is the number of distinct OTUs in group $j,$ in the sample $(Z^{(i)}_{j}, i\in[M_{j}], j\in[J]).$


This carries over for more general choices of \((\tau_{j}, j \in [J], \tau_{0})\). See~\cite{JLP2}[Theorem 1] and examples, in conjunction with Proposition~\ref{poissonequivalence}, for distributions of \(\tilde{\sigma}_{j,l}(\lambda)\), having density proportional to 

\[
\eta^{[n_{j,l}]}_{j}(t_{j} | \lambda, M_{j}) \propto t^{n_{j,l}}_{j} e^{-t_{j}M_{j}} \eta_{j}(t_{j} | \lambda).
\]

See~\cite{JamesStick} for calculations in the generalized gamma case, as well as other cases. 

Furthermore, \((S_{j,k,l}, k \in [X_{j,l}])\) corresponds to the mean abundance rates of the markers \((\tilde{U}_{j,k,l}, k \in [X_{j,l}])\), each reflecting the abundance of the corresponding OTU with counts \((\tilde{C}_{j,k,l}, k \in [X_{j,l}])\) contributing to the counts \((N_{j,l})\) of \(\tilde{Y}_{l}\). 

Meanwhile, 

\[
\hat{\sigma}_{j,l}(H_{l}) = \sum_{k=1}^{\infty} s^{(H_{l},')}_{j,k,l}
\]

denotes the mean abundance rate of \(\tilde{Y}_{l}\) in group \(j\) based on markers of OTUs, with respective mean abundance rates \((s^{(H_{l},')}_{j,k,l})_{k \geq 1}\) that have not yet contributed to the counts of \(\tilde{Y}_{l}\) in group \(j\). This means that these OTUs do not appear in the sample for group \(j\).
%\begin{prop}\label{PropgenPGG}
%Set $B_{0}\sim \mathrm{GG}(\alpha_{0},\theta_{0},\zeta_{0}, F_{0})$ denoting a %generalized gamma process $\mathrm{CRM}$ with L\'evy density for $0<\alpha_{0}%<1$:
%$
%\tau_{0}(\lambda)=\theta_{0}\alpha_{0}\lambda^{-\alpha_{0}-1}e^{-%\zeta_{0}\lambda}/\Gamma(1-\alpha_{0})$ and 
%$\Psi_{0}(t)=\theta_{0}[(\zeta_{0}+t)^{\alpha_{0}}-\zeta^{\alpha_{0}}_{0}].$ %Then given $\mathbf{Z}_{J}$: 
%1. $B_{0,J}\sim \mathrm{GG}(\alpha_{0},\theta_{0},\zeta_{0}+\sum_{j=1}^{J}\psi_{j}(M_{j}))$
%2. $H_{l}|\tilde{X}_{l}\sim \mathrm{Gamma}(\tilde{X}_{l}-%\alpha_{0},\zeta_{0}+\sum_{j=1}^{J}\psi_{j}(M_{j}))$ and 3.
%for $\tau_{j}(s) =\frac{ \alpha_{j}\theta_{j}e^{-s\zeta_{j}}s^{-\alpha_{j}-1}}%{\Gamma(1-\alpha_{j})}$, for $j\in[J],$ $((\tilde{C}_{j,k,l}=c_{j,k,l},k\in %[X_{j,l}],X_{j,l}=x_{j,l}) j\in J),$ given $(N_{j,l}, j\in[J])$
%has, for $x_{l}=\sum_{j=1}^{J}x_{j,l},$ with $x_{j,l}=0$ when $n_{j,l}=0,$ and %otherwise $x_{j,l}\in[n_{j,l}],$ distribution proportional to,
%\begin{equation}
%\frac{\Gamma(x_{l} - \alpha_{0})}%{\prod_{j=1}^{J}\Gamma(x_{j,l})}\frac{\prod_{j=1}^{J}\alpha_{j}\theta^{x_{j,l}}_%{j}{(\zeta_{j}+M_{j})}^{x_{j,l}\alpha_{j}}}{(\zeta_{0} + \sum_{j=1}^{J} %\theta_{j} [(\zeta_{j} + M_j)^{\alpha_{j}} - \zeta_{j}^{\alpha_{j}}])^{x_{l} - %\alpha_{0}}} \prod_{j=1}^{J}p_{\alpha_{j},0}(\mathbf{c}_{j,l})
%\label{specialstable}
%\end{equation}
%\end{prop}

\subsection{The marginal distribution of $(N_{j,l},j\in[J])$}\label{marginal}
We now provide descriptions of the general marginal process. First note that $(N_{j,l},j\in[J])|(\tilde{\sigma}_{j,l}(H_{l})=t_{j}, j\in[J]),H_{l}$ is $\mathrm{tP}(t_{1}M_{1},\ldots,t_{J}M_{J}),$ and hence there is a joint distribution of  $(N_{j,l},\tilde{\sigma}_{j,l}(H_{l}),j\in[J]),H_{l},$ with $n_{l}:=\sum_{j=1}^{J}n_{j,l}=1,2,\ldots,$ 
$$
\frac{\prod_{j=1}^{J}M^{n_{j,l}}_{j}t^{n_{j,l}}_{j}e^{-t_{j}M_{j}}}
{(1-{\mbox e}^{-\sum_{j=1}^{J}M_{j}t_{j}})\prod_{j=1}^{J}n_{j,l}!}
\frac{(1-{\mbox e}^{-\sum_{j=1}^{J}M_{j}t_{j}})\prod_{j=1}^{J}\eta_{j}(t_{j}|\lambda)}{(1-{\mbox e}^{-\lambda\sum_{j=1}^{J}\psi_{j}(M_{j})})}f_{H_{l}}(\lambda).
$$
For the next result define vectors, $\mathbf{k_J} = (k_1, k_2, \ldots, k_J) \in \mathbb{N}^J$, and $\mathbf{n}_l = (n_{1,l}, \ldots, n_{J,l})$. Where, $k_j(n_{j,l}) = 0$ if $n_{j,l} = 0$ and $k_j(n_{j,l}) \in [n_{j,l}]$ otherwise. Let the collection of all such vectors $\mathbf{k_J}$ be denoted by $\mathcal{K}_J({\mathbf{n}_l})$.
Now recall the identity,
$\int_0^{\infty} t^{n_{j,l}}e^{-tM_j}\eta_j(t|\lambda)\,dt = e^{-\lambda\psi_{j}(M_{j})}\Xi^{[n_{j,l}]}_j(\lambda,M_{j})$, for the results that follow.

\begin{prop}\label{post:marginalofN}
There are the following descriptions of the marginal and conditional distributions of $(N_{j,l}=n_{j,l}, j\in[J])$ defined for $n_{l}=\sum_{j=1}^{J}n_{j,l}=1,2,\ldots,,$ and each $l\in[\varphi]$,for $\varphi\sim \mathrm{Poisson}(\Psi_{0}(\sum_{j=1}^{J}\psi_{j}(M_{j}))).$
\begin{enumerate} 
    \item The conditional distribution of $(N_{j,l}=n_{j,l}, j\in[J])| H_{l}=\lambda$ can be expressed as,
    $$
    \frac{e^{-\lambda\sum_{j=1}^{J}\psi_{j}(M_{j})}\prod_{j=1}^{J}M^{n_{j,l}}_{j}\Xi^{[n_{j,l}]}_{j}(\lambda,M_{j})}{(1-e^{-\lambda\sum_{j=1}^{J}\psi_{j}(M_{j})})\prod_{j=1}^{J}n_{j,l}!}
    $$
\item The marginal of  $(N_{j,l}=n_{j,l}, j\in[J])$ has the following sum representation, with $x_{l}:=\sum_{j=1}^{J} x_{j,l},$ and $\mathbf{x}_{j,l}=(x_{j,l},j\in[J])$:
 $$
\frac{\sum_{\mathbf{x}_{j,l} \in \mathcal{K}_J(\mathbf{n}_l)}\Psi^{(x_{l})}_{0}(\sum_{j=1}^{J} \psi_j(M_j)) \prod_{j=1}^{J} p^{[n_{j,l}]}(k_j | \tau_{j}, M_j) \Xi^{[n_{j,l}]}_j(1, M_j) M^{n_{j,l}}_{j}}
{\Psi_0\left(\sum_{j=1}^{J} \psi_j(M_j)\right) \prod_{j=1}^{J}n_{j,l}!}
$$
where 
$\Psi^{(x_{l})}_{0}(\sum_{j=1}^{J} \psi_j(M_j))=\int_{0}^{\infty} \lambda^{x_{l}}e^{-\lambda \sum_{j=1}^{J} \psi_j(M_j)}\tau_0(\lambda)d\lambda$ as can be found in~\cite{Pit97}. Also, $p^{[n_{j,l}]}(\mathbf{c}_{j,l}|\tau_{j}, M_j)\Xi^{[n_{j,l}]}_j(1,M_j)=\prod_{k=1}^{x_{j,l}}\psi^{(c_{j,k,l})}_{j}(M_{j}).$
\end{enumerate}
\end{prop}
\subsection{Prediction rules}\label{predict}
We present the prediction rule for  $(Z^{(M_{j}+1)}_{j}, j\in[J])|\mathbf{Z}_{J},$ a vector of one customer from each group. Other descriptions follow by utilizing Theorems~\ref{postPoissonHIBP} and Proposition~\ref{sumsampleprop}.

\begin{prop}\label{Prediction} Let for each $j\in [J]$, $Z^{(M_{j}+1)}_{j}|B_{j}\sim \mathrm{PoiP}(B_{j}),$ $B_{j}\sim \mathrm{CRM}(\tau_{j},B_{0}), B_{0}\sim \mathrm{CRM}(\tau_{0},F_{0})$. Then the predictive distribution of $(Z^{(M_{j}+1)}_{j}, j\in[J])|\mathbf{Z}_{J}$ is equal to that of the processes,
 \begin{equation}
    \label{prediction1}   
    \left(\sum_{v=1}^{\varphi^{*}}[\sum_{k=1}^{X^{*}_{j,v}}\tilde{C}^{(*,1)}_{j,k,v}]\delta_{Y^{*}_{v}} + \sum_{l=1}^{r}\left[\sum_{k=1}^{\mathscr{P}^{*}_{j,l}(H_{l})}\tilde{C}^{(*,2)}_{j,k,l}\right]\delta_{\tilde{Y}_{l}}+ \sum_{l=1}^{r} \left[\sum_{k=1}^{X_{j,l}} \mathscr{P}^{(M_{j}+1)}_{j,k,l}(S_{j,k,l})\right]\delta_{\tilde{Y}_{l}}, j\in J\right)
    \end{equation}
where $(Y^{*}_{v})\overset{iid}\sim F_{0},$  $\varphi^{*}\sim \mathrm{Poisson}([\Psi_{0}(\sum_{j=1}^{J}\psi_{j}(M_{j}+1))-\Psi_{0}(\sum_{j=1}^{J}\psi_{j}(M_{j}))]),$  
\begin{enumerate}
\item $X^{*}_{v}:=\sum_{j=1}^{J}X^{*}_{j,v}\sim \mathrm{MtP}(\sum_{j=1}^{J}
[\psi_{j}(M_{j}+1)-\psi_{j}(M_{j})],\tau_{0,J}),$  such that the iid pairs say
\(((H^{*}_{v},X^{*}_{v}), v \in [\varphi^{*}])\) have common joint distribution
$$
\frac{\lambda^{x_{v}}e^{-\lambda\sum_{j=1}^{J}\psi_{j}(M_{j}+1)}\tau_{0}(\lambda)}{\Psi^{(x_{v})}_{0}(\sum_{j=1}^{J}\psi_{j}(M_{j}+1))}\times \frac{{(\sum_{j=1}^{J}[\psi_{j}(M_{j}+1)-
\psi_{j}(M_{j})])}^{x_{v}}\Psi^{(x_{v})}_{0}(\sum_{j=1}^{J}\psi_{j}(M_{j}+1))}
{x_{v}![\Psi_{0}(\sum_{j=1}^{J}\psi_{j}(M_{j}+1))-\Psi_{0}(\sum_{j=1}^{J}\psi_{j}(M_{j}))]}
$$
and where the marginal distribution of $H^{*}_{v}$ has density, 
\begin{equation}
\label{HXdecomppredict}
\frac{(1 - e^{-\lambda [\sum_{j=1}^{J} \psi_{j}(M_{j}+1) - \psi_{j}(M_{j})]}) e^{-\lambda \sum_{j=1}^{J}\psi_{j}(M_{j})} \tau_{0}(\lambda)}{[\Psi_{0}(\sum_{j=1}^{J} \psi_{j}(M_{j}+1)) - \Psi_{0}(\sum_{j=1}^{J} \psi_{j}(M_{j}))]}
\end{equation}

\item $(X^{*}_{j,v},j\in[J])|X^{*}_{v}=x^{*}_{v}\sim \mathrm{Multi}(x^{*}_{v}; q_{1},\ldots, q_{J})$, for $q_{j}=\frac{[\psi_{j}(M_{j}+1)-\psi_{j}(M_{j})]}{\sum_{t=1}^{J}[
\psi_{t}(M_{t}+1)-\psi_{t}(M_{t})]}.$
\item For each \( j \in [J] \), the collections \( (\tilde{C}^{(*,1)}_{j,k,v}) \) and \( (\tilde{C}^{(*,2)}_{j,k,v}) \) are independent and identically distributed (iid) collections of \( \mathrm{MtP}(1, \tau^{(M_{j})}_{j}) \). Hence, there are iid pairs \( (\tilde{S}^{(*,1)}_{j,k,v}, \tilde{C}^{(*,1)}_{j,k,v}) \) and \( (\tilde{S}^{(*,2)}_{j,k,v}, \tilde{C}^{(*,2)}_{j,k,v}) \) with a common joint distribution given by, for $s\in(0,\infty)$ and $c=1,2,\ldots$ :
\[
\frac{s^{c}e^{-s[M_{j}+1]} \tau_{j}(s)}{\psi^{(c_{j})}_{j}(M_{j}+1)} \times \frac{\psi^{(c)}_{j}(M_{j}+1)}{[\psi_{j}(M_{j}+1) - \psi_{j}(M_{j})] c!}=\frac{s^{c} e^{-s}}{(1-e^{-s})c!} \times \frac{(1-e^{-s})e^{-sM_{j}}\tau_{j}(s)}{[\psi_{j}(M_{j}+1) - \psi_{j}(M_{j})]}
\]
\item $\mathscr{P}^{*}_{l}(H_{l})=\sum_{j=1}^{J}\mathscr{P}^{*}_{j,l}(H_{l})\sim \mathrm{Poisson}(H_{l}\sum_{j=1}^{J}[\psi_{j}(M_{j}+1)-\psi_{j}(M_{j})])$
\item  $(\mathscr{P}^{*}_{j,l}(H_{l}), j\in[J])|\mathscr{P}^{*}_{l}(H_{l})=n^{*}_{l}\sim \mathrm{Multi}(n^{*}_{l}; q_{1},\ldots, q_{J})$
\item $H_{l},((S_{j,k,l}, k\in[X_{j,l}]),X_{j,l},j\in[J]), l\in[r]|\mathbf{Z}_{J}$ as in Theorem~\ref{postPoissonHIBP}.
\end{enumerate}
\end{prop}

If one is interested in adding groups, $J$ to $J+1,$  as in ~\cite{ZhouPadilla2016}, the prediction rule is as follows
\begin{cor}Suppose that $Z^{(1)}_{J+1}|B_{J+1}\sim \mathrm{PoiP}(B_{J+1})$ and $B_{J+1}\sim \mathrm{CRM}(\tau_{J+1},B_{0}).$ Then $Z^{(1)}_{J+1}|\mathbf{Z}_{J}$ is equal in distribution
$$
\sum_{v=1}^{\varphi^{*}_{J+1}}\left[\sum_{k=1}^{X^{*}_{J+1,v}}\tilde{C}^{(*,1)}_{J+1,k,v}\right]\delta_{Y^{*}_{v}} + \sum_{l=1}^{r}\left[\sum_{k=1}^{\mathscr{P}^{*}_{J+1,l}(H_{l})}\tilde{C}^{(*,2)}_{J+1,k,l}\right]\delta_{\tilde{Y}_{l}}
$$
where
\begin{enumerate}
\item $X^{*}_{J+1,v}\sim \mathrm{MtP}(\psi_{J+1}(1),\tau_{0,J}),$ $\tilde{C}^{(*,1)}_{J+1,k,v}\sim \mathrm{MtP}(1,\tau_{J+1})$
\item $\mathscr{P}^{*}_{J+1,l}(H_{l})\sim \mathrm{Poisson}(H_{l}\psi_{J+1}(1)),$ $\tilde{C}^{(*,2)}_{J+1,k,l}\sim \mathrm{MtP}(1,\tau_{J+1})$
\item $\varphi^{*}_{J+1}\sim \mathrm{Poisson}(\Psi_{0}(\psi_{J+1}(1)+\sum_{j=1}^{J}\psi_{j}(M_{j}))-\Psi_{0}(\sum_{j=1}^{J}\psi_{j}(M_{j})).$
\end{enumerate}
To obtain the simpler rule, corresponding to the setting of ~\cite{ZhouPadilla2016}, where $\mathbf{Z}_{J}:=(Z^{(1)}_{j},j\in[J]),$ set $(M_{j}=1,j\in[J]).$ 
\end{cor}
\subsection{Using the Prediction Rule for Unseen Species in Microbiome and Related Studies}\label{unseen}
The problem of finding estimators for (unseen) species in an additional sample, say of size \(m\), which do not appear in an initial sample based on \(n\) individual animals—sampling \(n\) variables from a single discrete distribution \(F\) within a latent class/clustering context—is discussed in detail in \cite{balocchi2024bayesian}, along with relevant references, such as the seminal works in Bayesian nonparametrics by \cite{favaro2009bayesian,lijoi2007bayesian}. They further note that applications to feature models involving multiple populations present additional challenges \cite{jeganathan2021statistical}. 

Indeed, our setting is quite different; samples correspond to \((Z^{(i)}_{j}, i \in M_{j}, j \in [J])\):
- \(Z^{(i)}_{j}\) is a single sample unit from group \(j\), producing a sparse matrix of counts with many components (some latent), including counts, distinct species, and samples of existing species.
- The counterpart of \(m\) would be a random variable.

Since we operate within a Bayesian framework, our posterior distribution in Theorem~\ref{postPoissonHIBP} facilitates various derived prediction rules, which can be exactly implemented using adjustments to Theorem~\ref{sumsampleprop}. This allows for various random models of unseen components and measures of relevant parametric components that can be sampled. For example, one can easily extend our prediction rule to blocks of samples, such as \((Z^{(M_{j}+1)}_{j}, \ldots, Z^{(M_{j}+t)}_{j}), j \in [J]\) for some integer \(t\), or add multiple new communities \(J+1, \ldots, J+t\), where exact (block) sampling is facilitated by variants of the schemes in Section~\ref{exactsampling}. 

For this exposition, we will focus on the rich information we can glean from Proposition~\ref{Prediction} given \(((N_{j,l}, j \in [J]), \tilde{Y}_{l}, l \in [r])\) over \((M_{j}, j \in [J])\) samples. We examine the predicted information in \((Z^{(M_{j}+1)}_{j}, j \in [J])\) as in \eqref{prediction1} presented below: 

\begin{equation*}  
    \left(\sum_{v=1}^{\varphi^{*}} \left[\sum_{k=1}^{X^{*}_{j,v}} \tilde{C}^{(*,1)}_{j,k,v}\right] \delta_{Y^{*}_{v}} + \sum_{l=1}^{r} \left[\sum_{k=1}^{\mathscr{P}^{*}_{j,l}(H_{l})} \tilde{C}^{(*,2)}_{j,k,l}\right] \delta_{\tilde{Y}_{l}} + \sum_{l=1}^{r} \left[\sum_{k=1}^{X_{j,l}} \mathscr{P}^{(M_{j}+1)}_{j,k,l}(S_{j,k,l})\right] \delta_{\tilde{Y}_{l}}, j \in J\right)
\end{equation*}

Reading from left to right, the equation dictates that within the new samples \((Z^{(M_{j}+1)}_{j}, j \in [J])\):
\begin{enumerate}
    \item The first term indicates \(\varphi^{*}\) new species labeled as \((Y^{*}_{v}, v \in [\varphi^{*}])\), with counts \((\tilde{C}^{(*,1)}_{j,k,v}, k \in [X^{*}_{j,v}])\), representing new OTUs and the number of distinct ones with \(X^{*}_{j,v}\) markers, leading to \(N^{*}_{j,v} = \sum_{k=1}^{X^{*}_{j,v}} \tilde{C}^{(*,1)}_{j,k,v}\) occurrences of \(Y^{*}_{v}\) in group \(j\).
    \item Additionally, \((\tilde{S}^{(*,1)}_{j,k,v}, k \in [X^{*}_{j,v}])\) are the mean rates of the \(X^{*}_{j,v}\) OTUs contributing to the counts of the newly observed feature \(Y^{*}_{v}\).
    \item The second term describes \(\mathscr{P}^{*}_{j,l}(H_{l})\) new distinctive OTUs, with counts \((\tilde{C}^{(*,2)}_{j,k,l}, k \in [\mathscr{P}^{*}_{j,l}(H_{l})])\) for each previously observed species \(\tilde{Y}_{l}\), which adds \(\sum_{k=1}^{\mathscr{P}^{*}_{j,l}(H_{l})} \tilde{C}^{(*,2)}_{j,k,l}\) to the existing counts \(N_{j,l}\).
    \item \((\tilde{S}^{(*,2)}_{j,k,l}, k \in [\mathscr{P}^{*}_{j,l}(H_{l})])\) are the mean rates of the \(\mathscr{P}^{*}_{j,l}(H_{l})\) new OTUs contributing to the counts of the previously observed species \(\tilde{Y}_{l}\).
    \item The last term on the right adds \(\mathscr{P}^{(M_{j}+1)}_{j,k,l}(S_{j,k,l})\) to the existing OTU count \(\tilde{C}_{j,k,l}\) for \(k \in [X_{j,l}]\) for species \(\tilde{Y}_{l}\) for \(l \in [r]\).
\end{enumerate}

We see that the prediction rule can be utilized to provide answers, in the form of tractable random variables, for a variety of questions regarding seen and unseen species, as well as their respective additional OTU counts. In particular, this can address variants of the following questions, as discussed in~\cite{balocchi2024bayesian} :
\begin{itemize}
    \item \textbf{Q1:} What is the expected population frequency of a species with frequency \( t \ge 1 \) in the sample?
    \item \textbf{Q2:} How many previously unobserved species in the sample will be observed in additional samples?
    \item \textbf{Q3:} How many species with frequency \( t \ge 1 \) in the sample will be observed in additional samples?
\end{itemize}

We also propose another approach for estimating a parameter of diversity in the unseen regime, derived from our results. This aims to provoke further thought about it and other possible quantities. Notice that \( H^{*}_{v} \) is treated as an unknown parameter for which we have assigned a Bayesian prior and posterior, while \( Y^{*}_{v} \) and \( N^{*}_{j,l} \) are latent variables that we can eventually observe. 

In this context, we can specify \( \tilde{\sigma}^{*}_{j,v}(H^{*}_{v}) \) as the mean rate of abundance for \( Y^{*}_{v} \), a species previously unseen in the \( (M_{j}, j \in [J]) \) samples, that appears for the first time in a new sample \( Z^{(M_{j}+1)}_{j} \) from group \( j \). Assuming all terms given \( (N_{j,l}, j \in [J], l \in [r]) \) are random, as indicated in Proposition~\ref{Prediction}, we can provide a posterior or predictive distribution for a measure of previously unseen alpha-diversity. This gives a parameter-based answer to Q2 in this setting, using a variant of Shannon entropy defined as:

\begin{equation}
\mathscr{U}_{j,M_{j}+1} := -\sum_{v=1}^{\varphi^*} \frac{\tilde{\sigma}^{*}_{j,v}(H^{*}_{v})}{\sum_{t=1}^{\varphi^*} \tilde{\sigma}^{*}_{j,t}(H^{*}_{t})} \ln{\left(\frac{\tilde{\sigma}^{*}_{j,v}(H^{*}_{v})}{\sum_{t=1}^{\varphi^{*}} \tilde{\sigma}^{*}_{j,t}(H^{*}_{t})}\right)}, \quad j \in [J]
\label{ShannonUnseen}
\end{equation}

where \((\tilde{\sigma}^{*}_{j,v}(H^{*}_{v}), j \in [J])\), given \((N^{*}_{j,v} = n_{j,v}, j \in [J])\) and \(H^{*}_{v} = \lambda\), are conditionally independent with respective density \(\eta^{[n_{j,v}]}_{j}(t_{j}|\lambda,M_{j}+1)\) proportional to \(t_{j}^{n_{j,v}} e^{-t_{j}(M_{j}+1)} \eta_{j}(t_{j} | \lambda)\) for \(j \in [J]\). Specifically, we have the following from applying Proposition~\ref{poissonequivalence}:

\begin{equation}
\label{predictednewspecies}
\tilde{\sigma}^{*}_{j,v}(H^{*}_{v}) \overset{d}{=} \hat{\sigma}^{*}_{j,v}(H^{*}_{v}) + \sum_{k=1}^{X^{*}_{j,v}} \tilde{S}^{(*,1)}_{j,k,v},
\end{equation}

where \(\hat{\sigma}^{*}_{j,v}(\lambda)\) has density \(\eta^{[0]}_{j}(t_{j}|\lambda,M_{j}+1)\). In the gamma case illustrated in Proposition~\ref{poissonequivalence}, it follows that \(\tilde{S}^{(*,1)}_{j,k,v} \sim \mathrm{Gamma}(\tilde{C}^{(*,1)}_{j,k,v}, M_{j}+\zeta_{j}+1)\) and \(\left(\frac{\tilde{\sigma}^{*}_{j,v}(H^{*}_{v})}{\sum_{t=1}^{\varphi^*} \tilde{\sigma}^{*}_{j,t}(H^{*}_{t}), v \in[\varphi^{*}]}; v \in[\varphi^{*}]\right) \sim \mathrm{Dirichlet}(\theta_{j} H^{*}_{v}+N^{*}_{j,v}; v \in[\varphi^{*}])\).

Note additionally that \(((N^{*}_{j,v}, j \in [J]), H^{*}_{v}, v \in[\varphi^{*}], \varphi^{*})\) are all random and depend on observed counts \((N_{j,l}=n_{j,l}, j \in [J], l \in [r])\) through estimates of parameters such as \((\theta_{1},\ldots,\theta_{J})\), and those associated with \(\psi_{j}\) and \(\Psi_{0}\), along with any possible added covariates. This carries over for more general choices of \((\tau_{j}, j\in[J], \tau_{0})\). 

In fact, as discussed in the context of \cite{favaro2009bayesian}, the gamma case above may be overly simplified; we will therefore consider the generalized gamma case where, in the next result, we set:

\[
\rho_{j} = \frac{\frac{\theta_{j}}{\alpha_{j}} \left[ (\zeta_{j}+M_{j}+1)^{\alpha_{j}} \right]}{\zeta_{0} + \sum_{t=1}^{J} \frac{\theta_{t}}{\alpha_{t}} \left[ (\zeta_{t}+M_{t}+1)^{\alpha_{t}} - \zeta^{\alpha_{t}}_{t} \right]}.
\]

\begin{prop}\label{predictunseen} In reference to \ref{ShannonUnseen} and other possible random metrics for the yet unseen species to appear in the additional sample predicted $(Z^{(M_{j}+1)}_{j}, j\in [J]).$ Consider the generalized gamma case where the distributions are defined by:
$
\tau_j(s) = \frac{\theta_j}{\Gamma(1-\alpha_j)} s^{-\alpha_j-1} e^{-\zeta_j s}$, $j \in [J],
$ 
and $\tau_0(\lambda) = \frac{\theta_0}{\Gamma(1-\alpha_0)} \lambda^{-\alpha_0-1} e^{-\zeta_0 \lambda}.$ It follows that, given $\mathbf{Z}_{J},$ 
$\tilde{S}^{(*,1)}_{j,k,v}\sim \mathrm{Gamma}(\tilde{C}^{(*,1)}_{j,k,v}-\alpha_{j}, M_{j}+\zeta_{j}+1)$ and the vector 
$$
\left(\tilde{\sigma}^{*}_{j,v}(H^{*}_{v}), j \in [J]), v\in[\varphi^{*}]\right) \overset{d}=
\left(\frac{T^{(j,v)}_{\alpha_{j}}(\rho_{j}G_{X^{*}_{v}-\alpha_{0}}) + G_{N^{*}_{j,v} - X^{*}_{j,v}\alpha_{j}}}{\zeta_{j} + M_{j}+1}, j \in [J], v\in[\varphi^{*}]\right),
$$
where \(G_{b} \sim \mathrm{Gamma}(b,1)\), and \(T^{(j,v)}_{\alpha}(y)\) are independent generalized gamma variables. Hence, for each $j\in[J]$, 
\begin{equation}
\left(\frac{\tilde{\sigma}^{*}_{j,v}(H^{*}_{v})}{\sum_{t=1}^{\varphi^*} \tilde{\sigma}^{*}_{j,t}(H^{*}_{t})}, v \in [\varphi^{*}]\right)\overset{d}=
\left(\frac{T^{(j,v)}_{\alpha_{j}}(\rho_{j}G_{X^{*}_{v}-\alpha_{0}}) + G_{N^{*}_{j,v} - X^{*}_{j,v}\alpha_{j}}}{T^{(j)}_{\alpha_{j}}(\rho_{j}G_{X^{(*,+)}-\alpha_{0}\varphi^{*}}) + G_{N^{(*,+)}_{j} - X^{(*,+)}_{j}\alpha_{j}}}, v \in [\varphi^{*}]\right),
\label{gengamgroupunseenprobabilities}
\end{equation}
where \(T^{(j)}_{\alpha_{j}}(\rho_{j}G_{X^{(*,+)}-\alpha_{0}\varphi^{*}}) \overset{d}{=} \sum_{v=1}^{\varphi^{*}} T^{(j,v)}_{\alpha_{j}}(\rho_{j}G_{X^{*}_{v}-\alpha_{0}})\) and \(G_{N^{(*,+)}_{j} - X^{(*,+)}_{j}\alpha_{j}} \overset{d}{=} \sum_{v=1}^{\varphi^{*}} G_{N^{*}_{j,v} - X^{*}_{j,v}\alpha_{j}}\). Furthermore,  \(X^{(*.+)} = \sum_{v=1}^{\varphi^{*}} X^{*}_{v}\) represents the total number of distinct OTUs connected with the predicted new species \((Y^{*}_{v}, v \in [\varphi^{*}])\) across all groups \(j\) and \(N^{(*,+)}_{j}=\sum_{v=1}^{\varphi^{*}}N^{*}_{j,v}\) denotes the total occurrences(abundance) of those species in group \(j\), \(X^{(*,+)}_{j}=\sum_{v=1}^{\varphi^{*}}X^{*}_{j,v}\) is the number of distinct OTUs in group $j,$ in the predicted new sample $(Z^{(M_{j}+1)}_{j}, j\in[J]).$
\end{prop}

It follows that if $\rho_{j}=1,$ that since $T^{(j,v)}_{\alpha_{j}}(G_{b})\overset{d}=G_{b\alpha_{j}}$, the vector in~\ref{gengamgroupunseenprobabilities} is a Dirichlet distributed vector with random components $(N^{*}_{j,v}+(X^{*}_{v}-X^{*}_{j,v})\alpha_{j}-\alpha_{0}\alpha_{j}, v\in [\varphi^{*}])$ and are otherwise complex variants of Pitman-Yor and more general finite dimensional vectors treated in~\cite{favaro2011class, LijoiPYmulti, LijoiPYmultiJASA}, see also ~\cite{kingman1975}. Indeed 
our constructions contain randomized finite dimensional vectors that can be constructed from the results in~\cite{JLP2}, see also~\cite{JamesStick} for appropriate calculations of variables with density $\eta^{[n]}_{j}(t_{j}|\lambda, M_{j}+1)$ which otherwise coincides with Proposition~\ref{poissonequivalence}.

\section{Closing remarks} 
This current version of our work establishes the technical framework and overarching ideas for applications to complex species sampling models arising in microbiome research and other ecological studies. It can undoubtedly be applied to other complex frameworks addressed by different methods, such as topic models. For practical illustration, we will soon include, in an updated version, both detailed synthetic and real data studies based broadly on information from the papers \citep{sankaran2019latent, sankaran2024semisynthetic, willis2022estimating}, showcasing some of the new schemes we propose here. We will also provide relevant computational information that can be accessed and utilized. In the meantime, one may consult \cite{hibp23} for related calculations and simulations based on the same gamma and generalized gamma process priors highlighted here, as indicated in Proposition~\ref{predictunseen}. As a caveat, our aim is not to provide the most optimal models incorporating additional information, but to furnish sufficient details for domain experts to build upon our robust Poisson HIBP framework, which we have demonstrated serves as a generative process for complex phenomena arising in microbiome research—there is no ad-hoc approach in our constructive mappings to such phenomena. Relevant details for our technical results can also be found in \cite{hibp23}, and we will present polished forms of those details in the forthcoming update of this manuscript. Readers are invited to approach us directly at any time for clarifications.
\bibliographystyle{agsm}
\bibliography{bibliography}

% \begin{thebibliography}{0}

% %\bibitem{AldousPitR}
% %\textsc{Aldous, D. and Pitman, J.} (2006). Two recursive decompositions %of Brownian bridge related to the asymptotics of random mappings. In In %Memoriam Paul-Andr\'e Meyer (pp. 269-303). Springer Berlin Heidelberg.

% %\bibitem{BMQ}
% %\textsc{Blackwell, D. and MacQueen, %J.B.} (1973)
% %Ferguson distributions via P\'olya %urn schemes.
% %\emph{Ann, Stat } \textbf{1} 353-355.


% %\bibitem{Buntine}
% %\textsc{Buntine, W. and Hutter, M.} %(2012).
% %A Bayesian View of the Poisson-%Dirichlet Process.
% %arXiv:1007.0296v2 [math.ST]


% %\bibitem{Changyou}
% %\textsc{Chen C., Rao,V.,Buntine,W.,}%and  \textsc{Teh, Y-W.}
% %Dependent Normalized Random Measures
% %International Conference on Machine %Learning (ICML), Atlanta, USA, 2013.

% \bibitem{Argiento}
% \textsc{Argiento, R., Cremaschi, A.} and \textsc{Vannucci, M.} (2020). Hierarchical Normalized Completely Random Measures to Cluster Grouped Data. \textit{J. Amer. Statist. Assoc.} \textbf{115} 318-33.

% \bibitem{AyedCaron}
% \textsc{Ayed, F.} and \textsc{Caron, F}. (2019) Nonnegative Bayesian nonparametric factor models with completely random measures for community detection. arXiv:1902.10693.

% \bibitem{Basbug}
% \textsc{Basbug, M.} and \textsc{Engelhardt, B.} (2016). Hierarchical compound Poisson factorization. In International Conference on Machine Learning (pp. 1795-1803). PMLR.

% \bibitem{BleiLDA}
% \textsc{Blei, D.M., Ng, A.Y.} and 
% \textsc{Jordan, M.I.} (2003). Latent Dirichlet Allocation. \textit{J. Machine Learning Research}, \textbf{3}, 993-1022.

% \bibitem{Broderick1}
% \textsc{Broderick, T, Jordan, M.I.,} and \textsc{Pitman, J.} (2013)
% Clusters and features from combinatorial stochastic processes.
% \emph{Statist. Sci.} \textbf{28}, 289-312.

% \bibitem{Broderick2}
% \textsc{Broderick, T, Mackey, L, Paisley, J,} and \textsc{Jordan, M.I.}
% (2015). 
% Combinatorial clustering and the beta negative binomial process. \emph{IEEE Transactions on Pattern Analysis and Machine Intelligence.} \textbf{37},
%  290-306.

% \bibitem{BroderickWilson}
% \textsc{Broderick, T., Wilson, A.} and \textsc{Jordan, M.I.} (2018). Posteriors, conjugacy,
% and exponential families for completely random measures. \textit{Bernoulli} \textbf{24} 3181–3221.

% %\bibitem{Broderick3}
% %\textsc{Broderick, T., Pitman, J.}, and \textsc{Jordan, %M. I.} (2013). Feature allocations, probability %functions, and paintboxes. Bayesian Analysis, \textbf{8}, %801-836.

% %\bibitem{LucJacobi}
% %\textsc{Devroye, L.} (2009). On exact simulation algorithms for some distributions related to Jacobi theta functions.
% %{\it Stat. Probab. Letters} \textbf{79}, 2251-2259.

% \bibitem{CamerLP1}
% \textsc{Camerlenghi,F., Lijoi, A., Orbanz,P.} and \textsc {Pr\"unster, I.} (2019). Distribution theory for hierarchical processes. \emph{Ann. Statist.} \textbf{47}, 67-92.

% \bibitem{CamerLP2}
% \textsc{Camerlenghi,F., Lijoi, A.} and \textsc {Pr\"unster, I.} (2021). Survival analysis via hierarchically dependent mixture hazards. \emph{Ann. Statist.} \textbf{49} pp. 863-884.

% \bibitem{CampbellTrait}
% \textsc{Campbell, T., Cai, D.} and \textsc{Broderick, T.} (2018). Exchangeable trait allocations. 
% \textit{Electronic Journal of Statistics}, \textbf{12} pp. 2290-2322.

% \bibitem{Caron2012}
% \textsc{Caron, F.} (2012) Bayesian nonparametric models for bipartite graphs. Neural Information Processing Systems (NIPS 2012), Lake Tahoe, USA, 2012.

% \bibitem{CaronFox}
% \textsc{Caron, F.} and \textsc{Fox, E.B.}(2017). 
% Sparse graphs using exchangeable random
% measures. \emph{JRSSB} \textbf{79},  1295-1366.

% \bibitem{Carlton}
% \textsc{Carlton, M.A.}(2002).
% A family of densities derived from the three-parameter Dirichlet process.
% \textit{Journal of Applied Probability}, textbf{39} 764--774.

% \bibitem{BoChen}
% \textsc{Chen, B., Polatkan, G., Sapiro, G., Dunson, D.B.}, and \textsc{Carin, L.}.(2011) The hierarchical beta process for convolutional factor analysis and deep learning. \textit{In Proceedings of the 28th International Conference on International Conference on Machine Learning},  361-368. 2011.

% \bibitem{DevroyeTryp}
% \textsc{Devroye, L.} (1993). A triptych of discrete distributions related to the stable law. 
% \textit{Statistics and Probability Letters}, \textbf{18}, 349-351.

% \bibitem{DiBenedettopartition}
% \textsc{Di Benedetto, G., Caron, F.} and \textsc{Teh, Y. W.} (2020).
% Non-exchangeable random partition models for microclustering.\emph{Ann. Statist.}, to appear.

% %\bibitem{Doksum}
% %\textsc{Doksum, K.} (1974).
% %Tailfree and neutral random probabilities and their %posterior distributions.
% %\emph{Ann. Probab.} \textbf{2} 183--201.

% \bibitem{DykstraLaud}
% \textsc{Dykstra, R.L.} and \textsc{Laud, P.W.} (1981). A Bayesian nonparametric approach to
% reliability. \textit{Ann. Statist.} \textbf{9} 356–367.

% %\bibitem{FavaroTeh}
% %\textsc{Favaro, S. and Teh,Y.W.} %(2013).
% %MCMC for normalized random measure %mixture models
% %\emph{Statistical Science} 
% %\textbf{28}, 335-359.

% \bibitem{Ferg1973}
% \textsc{Ferguson, T.S.} (1973).
%  A Bayesian Analysis of Some Nonparametric Problems. \emph{Ann. Statist.} \textbf{1} 209--230. 

% %\bibitem{FisherPoisson}
% %\textsc{Fisher, R.A.}(1922).
% %On the Interpretation of $\chi^{2}$ from Contingency %Tables, and the Calculation of P.
% %\emph{Journal of the Royal Statistical Society} 
% %\textbf{85}, 87-94.

% \bibitem{Fisher}
% \textsc{Fisher, R.A., Corbet, S.A.,} and \textsc{Williams, C.B.} (1943) The relation between the number of species and the number of individuals in a random sample of an animal population. 
% \textit{The Journal of Animal Ecology} 42-58.

% %\bibitem{Zoubin}
% %\textsc{Ghahramani, Z., Griffiths, T. L.}, and %\textsc{Sollich, P.} (2007). Bayesian nonparametric %latent feature models. \emph{Bayesian Statistics} %\textbf{8}, 1-25.

% %\bibitem{GnedinS}
% %\textsc{Gnedin, A. V.}(2004). Three %sampling formulas. 
% %\emph{Combinatorics, Probability and
% %Computing,} \textbf{13}(02), 185-193.

% %\bibitem{GnedinPitman2}
% %\textsc{Gnedin, A. and Pitman, J.} (2005).
% %Regenerative composition structures
% %\emph{Ann. Probab.} \textbf{33}, 445-479.

% \bibitem{Goldwater}
% \textsc{Goldwater, S., Griffiths, T.} and \textsc{Johnson, M.} (2006). Interpolating between types and tokens by estimating power-law generators. \textit{Advances in neural information processing systems}, \textbf{18}, p.459.

% \bibitem{GriffithsZ}
% \textsc{Griffiths, T.L., and Ghahramani, Z.} (2006)
% Infinite Latent Feature Models and the Indian Buffet Process.
% In Advances in Neural Information Processing Systems 18 (NIPS-2005).

% \bibitem{Griffiths1}
% \textsc{Griffiths, T.L., and Ghahramani, Z.} (2011) The Indian buffet process: An introduction and review. \textit{The Journal of Machine Learning Research} 12 (2011): 1185-1224.

% \bibitem{GuptaRestrict}
% \textsc{Gupta, S.K., Phung, D.,} and \textsc{Venkatesh, S.}~(2012). A Bayesian nonparametric joint factor model for learning shared and individual subspaces from multiple data sources. In Proceedings of the 2012 SIAM International Conference on Data Mining (pp. 200-211). Society for Industrial and Applied Mathematics.

% \bibitem{Croy}
% \textsc{Heaukulani, C., and Roy, D. M.} (2016). The combinatorial structure of beta negative binomial processes. \textit{Bernoulli} \textbf{22}, 2301-2324.

% \bibitem{hjort}
% \textsc{Hjort, N. L.} (1990). Nonparametric Bayes estimators based on beta processes in models for life history data. \emph{Ann, Stat } \textbf{18}, 1259-1294.

% \bibitem{HJL}
% \textsc{Ho, M-W., James, L.F.} and \textsc{Lau, J.W.} (2021). Gibbs Partitions, Riemann-Liouville Fractional Operators, Mittag-Leffler Functions, and Fragmentations derived from stable subordinators. \textit{Journal of Applied Probability, to appear}

% \bibitem{IJ2001}
% \textsc{Ishwaran, H.} and \textsc{James, L.F.} (2001). 
% Gibbs sampling methods for stick-breaking priors.  
% \emph{J. Amer. Stat. Assoc.}, \textbf{96}, 161-173.

% \bibitem{IJ2003}
% \textsc{Ishwaran, H.} and \textsc{James, L.F.} (2003). Generalized weighted Chinese restaurant processes for species sampling mixture models. \textit{Statist. Sinica}, \textbf{13} 1211-1235.

% \bibitem{IJ2004}
% \textsc{Ishwaran, H.} and \textsc{James, L.F.} (2004). Computational methods for multiplicative intensity models using weighted gamma processes.  \emph{J. Amer. Stat. Assoc.}, \textbf{99}, 175-190.

% \bibitem{IR2005}
% \textsc{Ishwaran, H., and Rao, J. S.} (2005). Spike and slab variable selection: frequentist and Bayesian strategies. \emph{Ann. Stat. }, 730-773.

% \bibitem{James2002}
% \textsc{James, L.F.} (2002). Poisson process partition calculus with applications to exchangeable models and Bayesian nonparametrics. Unpublished manuscript. ArXiv math.PR/0205093.

% %\bibitem{James2003}
% %\textsc{James, L.F.} (2003). Bayesian calculus for %gamma processes with applications to semiparametric %intensity models. \emph{Sankhya}  \textbf{65}(1) 179-206.

% \bibitem{James2005}
% \textsc{James, L.F.} (2005)
% Bayesian Poisson Process Partition Calculus with an Application to Bayesian L\'evy Moving Averages
% \emph{Ann. Stat. }\textbf{33}, 1771-1799.

% \bibitem{JamesNTR}
% \textsc{James, L.F.} (2006).
% Poisson calculus for
% spatial neutral to the right processes.
% \emph{Ann. Stat. }\textbf{34}, 416-440

% \bibitem{JamesBernoulli}
% \textsc{James, L.F.}(2010). Dirichlet mean identities and laws of
% a class of subordinators. 
% \emph{Bernoulli } \textbf{16}, 361–-388

% \bibitem{JamesGamma}
% \textsc{James, L.F.} (2006). Gamma tilting calculus for GGC and
% Dirichlet means via applications to Linnik processes and
% occupation time laws for randomly skewed Bessel processes and
% bridges. Available at http://arxiv.org/abs/math.PR/0610218.

% %\bibitem{JamesPD}
% %\textsc{James, L.F.} (2008). Large %sample asymptotics for the two-%parameter Poisson–Dirichlet process. %In Pushing the limits of contemporary %statistics: contributions in honor of %Jayanta K. Ghosh (pp. 187-199). %Institute of Mathematical Statistics.

% \bibitem{James2017}
% \textsc{James, L.F.}  (2017).
% Bayesian Poisson Calculus for Latent Feature Modeling via Generalized Indian Buffet Process Priors.
% \emph{Ann. Stat. }\textbf{45}, 2016-2045.

% \bibitem{JamesStick}
% \textsc{James, L.~F.} (2019). Stick-breaking Pitman-Yor processes given the species sampling size.
% arXiv:1908.07186 [math.ST]

% \bibitem{JLP2} \textsc{James, L. F., Lijoi, A.} and
% \textsc{Pr\"{u}nster, I.} (2009). Posterior analysis for normalized random measures with independent increments. \emph{Scand. J. Stat.} \textbf{36} 76--97.

% \bibitem{JRY}
% \textsc{James, L.F., Roynette, B. and Yor, M.} (2008). Generalized
% Gamma Convolutions, Dirichlet means, Thorin measures, with
% explicit examples. \emph{Probab. Surv.} \textbf{5} 346--415.


% \bibitem{Karlis}
% \textsc{Karlis, D.} and \textsc{Xekalaki,E.} (2005). Mixed Poisson Distributions. \textit{Internat. Statist. Rev.} \textbf{73} 35--58.

% \bibitem{Kessler}
% \textsc{Kessler, S., Nguyen, V., Zohren, S.} and \textsc{Roberts, S.}(2019) Hierarchical Indian Buffet Neural Networks for Bayesian Continual Learning. arXiv:1912.02290.

% \bibitem{KimY}
% \textsc{Kim, Y.} (1999). Nonparametric Bayesian estimators for counting processes. \emph{Ann. Stat.}, \textbf{27} 562-588.

% \bibitem{KimLee}
% \textsc{Kim, Y. and Lee, J.} (2001).
% On posterior consistency of survival models.\emph{Ann.
% Stat.}, \textbf{29} 666-686.


% \bibitem{KnowlesThesis}
% \textsc{Knowles, D. A. }(2012). Bayesian non-parametric models and inference for sparse and hierarchical latent structure. Ph.D. Thesis University of Cambridge

% \bibitem{KnowlesAAS}
% \textsc{Knowles, D.,} and \textsc{Ghahramani, Z.} (2011). Nonparametric Bayesian sparse factor models with application to gene expression modeling. \emph{The Annals of Applied Statistics}, \textbf{5}(2B), 1534-1552.

% \bibitem{Kolchin}
% \textsc{Kolchin, V. F.}~(1986). \textit{Random mappings}. Translation Series in Mathematics and Engineering. Optimization Software Inc. Publications Division, New York, 1986.

% \bibitem{LijoiPYmulti}
% \textsc{Lijoi, A.,Pr\"unster, I.} and \textsc{Rigon,T.}.(2020) 
% The Pitman–Yor multinomial process for mixture modelling. 
% \textit{Biometrika}, \textbf{107} 891–906.

% \bibitem{LijoiPYmultiJASA}
% \textsc{Lijoi, A.,Pr\"unster, I.} and \textsc{Rigon,T.}.(2024) 
% Finite-dimensional Discrete Random Structures
% and Bayesian Clustering. 
% \emph{J. Amer. Stat. Assoc.}, \textbf{119}, 929-941.


% \bibitem{BuntineHPYtwitter}
% \textsc{Lim, K.W., Buntine, W., Chen, C.} and \textsc{Du, L.} (2016). Nonparametric Bayesian topic modelling with the hierarchical Pitman–Yor processes. 
% \textit{International Journal of Approximate Reasoning}, \textbf{78} 172-191.


% \bibitem{Lo1982}
% \textsc{Lo, A.Y.} (1982). Bayesian nonparametric statistical inference for Poisson point processes. \emph{Zeitschrift f{\"u}r Wahrscheinlichkeitstheorie und verwandte Gebiete}, \textbf{59}(1), 55-66.

% \bibitem{Lo1984}
% \textsc{Lo, A.Y.} (1984). On a Class of Bayesian Nonparametric Estimates: I. Density Estimates.
% \textit{Ann. Statist.} \textbf{12}, 351 - 357.

% \bibitem{LoWeng89}
% \textsc{Lo, A.Y.} and \textsc{Weng, C. S.} (1989). On a class of Bayesian nonparametric estimates: II. Hazard rate estimates. \emph{Annals of the Institute of Statistical Mathematics,} \textbf{41}(2), 227-245.

% %\bibitem{Miller}
% %\textsc{Miller, K. T.} (2011). %Bayesian nonparametric latent feature %models. (Doctoral dissertation, %University of California, Berkeley).

% \bibitem{Masoerotrait}
% \textsc{Masoero, L., Camerlenghi, F., Favaro, S.} and \textsc{Broderick, T.} (2018).
% Posterior representations of hierarchical completely random measures in trait allocation models. BNP-NeurIPS. 2018.

% \bibitem{MasoeroBiometrika}
% \textsc{Masoero, L., Camerlenghi, F., Favaro, S.} and \textsc{Broderick, T.} (2021). More for less: Predicting and maximizing genetic variant discovery via Bayesian nonparametrics. To appear\textit{ Biometrika}.



% %\bibitem{Miller2}
% %\textsc{Miller, K. T., Griffiths, T. L.} and %\textsc{Jordan, M. I,} (2009). Nonparametric Latent %Feature Models for Link Prediction. Advances in Neural %Information Processing Systems (NIPS) 22.

% %\bibitem{Orbanz2}
% %\textsc{Orbanz, P.} (2009). Construction of nonparametric Bayesian models %from parametric Bayes equations. In Advances in neural information %processing systems (pp. 1392-1400).

% %\bibitem{Orbanz3}
% %\textsc{Orbanz, P.} (2012)
% %Nonparametric priors on complete separable metric spaces. Preprint.

% %\bibitem{Paisley}
% %\textsc{Paisley, J.} and \textsc{Carin, L.}. (2009). %Nonparametric factor
% %analysis with beta process priors, International %Conference on Machine
% %Learning (ICML), Montreal, Canada, 2009.


% %\bibitem{Palla}
% %\textsc{Palla, K., Knowles, D.}, and \textsc{Ghahramani, %Z.} (2012). An infinite latent attribute model for %network data. ICML 2012.

% %\bibitem{Penrose}
% %\textsc{Penrose, M. D.},and \textsc{Wade, A. R.} (2004). %Random minimal directed spanning trees and Dickman-type %distributions. \textit{Advances in Applied Probability}, %\textbf{36}, 691-714.

% \bibitem{Pit96}
% \textsc{Pitman, J.} (1996). \textit{Some developments of the
% Blackwell-MacQueen urn scheme.} Statistics, probability and game
% theory, 245--267, IMS Lecture Notes Monogr. Ser., 30, Inst. Math.
% Statist., Hayward, CA.

% \bibitem{Pit97}
% \textsc{Pitman, J.} (1997)
% Partition structures derived from Brownian motion and stable
% subordinators. \emph{Bernoulli} \textbf{3} 79-96

% \bibitem{Pit02}
% \textsc{Pitman, J.} (2003). Poisson-Kingman partitions. In
% \emph{Science and Statistics: A Festschrift for Terry Speed.}
% (D.R. Goldstein, Ed.), 1--34, Institute of Mathematical Statistics
% Hayward, California.

% \bibitem{Pit06}
% \textsc{Pitman, J.} (2006). \textit{Combinatorial stochastic
% processes.} Lectures from the 32nd Summer School on Probability
% Theory held in Saint-Flour, July 7--24, 2002. With a foreword by
% Jean Picard. Lecture Notes in Mathematics, 1875. Springer-Verlag,
% Berlin.

% \bibitem{PitmanPoissonMix}
% \textsc{Pitman, J.} (2017).
% Mixed Poisson and negative binomial models for clustering and species sampling. Manuscript in preparation.

% \bibitem{PY97}
% \textsc{Pitman, J. and Yor, M.} (1997). The two-parameter Poisson-Dirichlet distribution derived from a stable subordinator. \textit{Ann. Probab.} \textbf{25,} 855--900.

% \bibitem{Quenouille}
% \textsc{Quenouille, M. H.} (1949). A relation between the logarithmic, Poisson, and negative binomial series. \textit{Biometrics}, \textbf{5}, 162-164.

% \bibitem{RagaBlei}
% \textsc{Ranganath, R.,} and \textsc{Blei, D.M.} (2018) Correlated Random Measures. 
% \textit{Journal of the American Statistical Association.} \textbf{113}  417-430.

% \bibitem{Ragadeep}
% \textsc{Ranganath, R., Tang, L., Charlin, L.} and \textsc{Blei, D.} (2015) Deep exponential families. In \textit{Artificial Intelligence and Statistics} (pp. 762-771). PMLR.

% %\bibitem{Rai}
% %\textsc{Rai, P.,} and \textsc{Daume, H.} (2009). The %Infinite Hierarchical Factor Regression Model. In %Advances in Neural Information Processing Systems (pp. %1321-1328).

% \bibitem{Scheinthesis}
% \textsc{Schein, A.} (2019) \textit{Allocative Poisson Factorization for Computational Social Science.} PhD thesis, University of Massachusetts Amherst, 2019.

% %\bibitem{Soper}
% %\textsc{Soper, H.E.}(1922) \textit{Frequency arrays, %illustrating the use of logical symbols in the study of %statistical and other distributions.} Cambridge %University Press.

% \bibitem{TavareEwens}
% \textsc{Tavar\'e, S.} (2021). The magical Ewens sampling formula. 
% \textit{Bulletin of the London Mathematical Society}, \textbf{53}(6), pp.1563-1582.

% \bibitem{TehPY}
% \textsc{Teh, Y. W.} (2006). A hierarchical Bayesian language model based on Pitman-Yor processes. In \textit{Proceedings of the 21st International
% Conference on Computational Linguistics and 44th Annual Meeting of the Association for Computational Linguistics,} 85--992.

% \bibitem{TehG}
% \textsc{Teh, Y.W., and Gorur, D.} (2009)
% Indian Buffet Processes with Power-law Behavior.
% NIPS 2009.


% \bibitem{HDP}
% \textsc{Teh, Y. W.; Jordan, M. I.; Beal, M. J.} and \textsc{ Blei, D. M.} (2006). Hierarchical Dirichlet Processes. \textit{Journal of the American Statistical Association.} \textbf{101}  1566–1581.

% \bibitem{Thibaux}
% \textsc{Thibaux, R., and Jordan, M. I. }(2007). Hierarchical beta processes and the Indian buffet process. In International conference on artificial intelligence and statistics (pp. 564-571).

% \bibitem{Titsias}
% \textsc{Titsias, M. K.} (2008). The infinite gamma-Poisson feature model. Advances in Neural Information Processing Systems. 2008.

% %\bibitem{Wainwright}
% %\textsc{Wainwright, M. J}  and \textsc{Jordan, M.I.} (2008). Graphical %Models, Exponential Families, and Variational Inference. Found. Trends %Mach. Learn. 1, 1-2 (January 2008), 1-305.

% %\bibitem{Whitaker}
% %\textsc{Whittaker, J.} (2009). Graphical Models in Applied Multivariate %Statistics. Wiley Publishing. 

% %\bibitem{Wood}
% %\textsc{Wood, F, Griffiths, T.L.} and %\textsc{Ghahramani, Z} (2006) A non-%parametric Bayesian method for 
% %inferring hidden causes. In: 22nd %Conference on Uncertainty in %Artificial Intelligence (UAI 
% %2006), 13-7-2006 to 16-7-2006, %Cambridge, MA, US pp. 536-543..

% \bibitem{Wood}
% \textsc{Wood, F., Gasthaus, J., Archambeau, C., James, L. F. and Teh, Y. W.} (2011). The Sequence Memoizer. \textit{Communications of the ACM (Research Highlights)} \textbf{54,} 91--98.
 
% \bibitem{ZhouCarin2012}
% \textsc{Zhou, M.}, and \textsc{Carin, L.} (2015). Augment and Conquer Negative Binomial Processes 
 
% \bibitem{ZhouCarin2015}
% \textsc{Zhou, M.}, and \textsc{Carin, L.} (2015). 
% Negative Binomial Process Count and Mixture Modeling,
% \textit{IEEE Transactions on Pattern Analysis and Machine Intelligence}, \textbf{37}, 307–320. 

% \bibitem{ZhouPGBN}
% \textsc{Zhou,M., Cong,Y.}and  \textsc{Chen, B.} (2016). Augmentable gamma belief networks. T\textit{he Journal of Machine Learning Research}, \textbf{17} 5656-5699.

% \bibitem{ZhouFoF}
% \textsc{Zhou,M., Favaro,S.}and  \textsc{Walker, S.G.} (2017) Frequency of
% Frequencies Distributions and Size-Dependent Exchangeable Random Partitions, 
% \textit{J. Amer. Statist. Assoc.} \textbf{112}, 1623-1635.

% \bibitem{Zhou1}
% \textsc{Zhou, M., Hannah, L., Dunson, D.}, and \textsc{Carin, L.} (2012). Beta-negative binomial process and Poisson factor analysis. AISTATS, 1462-1471. PMLR, 2012.

% \bibitem{ZhouPadilla2016}
% \textsc{Zhou,M., Madrid-Padilla, O.H.} and  \textsc{Scott, J.G.} (2016) Priors
% for Random Count Matrices Derived from a Family of Negative Binomial Processes. 
% \textit{J. Amer. Statist. Assoc.} \textbf{111}, 1144-1156.

% \bibitem{ZhoudHIBP}
% \textsc{Zhou, M., Yang, H., Sapiro, G., Dunson, D.} and \textsc{Carin, L.} (2011). Dependent hierarchical beta process for image interpolation and denoising. In Proceedings of the Fourteenth International Conference on Artificial Intelligence and Statistics (pp. 883-891). JMLR Workshop and Conference Proceedings.

% \end{thebibliography}


% \bigskip
% \begin{center}
% {\large\bf SUPPLEMENTARY MATERIAL}
% \end{center}

% \begin{description}

% \item[Title:] Brief description. (file type)

% \item[R-package for  MYNEW routine:] R-package ÒMYNEWÓ containing code to perform the diagnostic methods described in the article. The package also contains all datasets used as examples in the article. (GNU zipped tar file)

% \item[HIV data set:] Data set used in the illustration of MYNEW method in Section~ 3.2. (.txt file)

% \end{description}

% \section{BibTeX}

% We hope you've chosen to use BibTeX!\ If you have, please feel free to use the package natbib with any bibliography style you're comfortable with. The .bst file agsm has been included here for your convenience. \cite{Blei09}

% \bibliographystyle{agsm}

% \bibliography{bibliography}
\end{document}
