@article{dong2023dreamllm,
  title={Dreamllm: Synergistic multimodal comprehension and creation},
  author={Dong, Runpei and Han, Chunrui and Peng, Yuang and Qi, Zekun and Ge, Zheng and Yang, Jinrong and Zhao, Liang and Sun, Jianjian and Zhou, Hongyu and Wei, Haoran and others},
  journal={arXiv preprint arXiv:2309.11499},
  year={2023}
}

@article{ge2024seed,
  title={Seed-x: Multimodal models with unified multi-granularity comprehension and generation},
  author={Ge, Yuying and Zhao, Sijie and Zhu, Jinguo and Ge, Yixiao and Yi, Kun and Song, Lin and Li, Chen and Ding, Xiaohan and Shan, Ying},
  journal={arXiv preprint arXiv:2404.14396},
  year={2024}
}

@article{he2024self,
  title={Self-correction is more than refinement: A learning framework for visual and language reasoning tasks},
  author={He, Jiayi and Lin, Hehai and Wang, Qingyun and Fung, Yi and Ji, Heng},
  journal={arXiv preprint arXiv:2410.04055},
  year={2024}
}

@article{ma2024janusflow,
  title={Janusflow: Harmonizing autoregression and rectified flow for unified multimodal understanding and generation},
  author={Ma, Yiyang and Liu, Xingchao and Chen, Xiaokang and Liu, Wen and Wu, Chengyue and Wu, Zhiyu and Pan, Zizheng and Xie, Zhenda and Zhang, Haowei and Zhao, Liang and others},
  journal={arXiv preprint arXiv:2411.07975},
  year={2024}
}

@article{qu2024tokenflow,
  title={TokenFlow: Unified Image Tokenizer for Multimodal Understanding and Generation},
  author={Qu, Liao and Zhang, Huichao and Liu, Yiheng and Wang, Xu and Jiang, Yi and Gao, Yiming and Ye, Hu and Du, Daniel K and Yuan, Zehuan and Wu, Xinglong},
  journal={arXiv preprint arXiv:2412.03069},
  year={2024}
}

@article{rafailov2024direct,
  title={Direct preference optimization: Your language model is secretly a reward model},
  author={Rafailov, Rafael and Sharma, Archit and Mitchell, Eric and Manning, Christopher D and Ermon, Stefano and Finn, Chelsea},
  journal={Advances in Neural Information Processing Systems},
  volume={36},
  year={2024}
}

@article{shi2024llamafusion,
  title={LlamaFusion: Adapting Pretrained Language Models for Multimodal Generation},
  author={Shi, Weijia and Han, Xiaochuang and Zhou, Chunting and Liang, Weixin and Lin, Xi Victoria and Zettlemoyer, Luke and Yu, Lili},
  journal={arXiv preprint arXiv:2412.15188},
  year={2024}
}

@inproceedings{sun2024generative,
  title={Generative multimodal models are in-context learners},
  author={Sun, Quan and Cui, Yufeng and Zhang, Xiaosong and Zhang, Fan and Yu, Qiying and Wang, Yueze and Rao, Yongming and Liu, Jingjing and Huang, Tiejun and Wang, Xinlong},
  booktitle={Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition},
  pages={14398--14409},
  year={2024}
}

@article{team2024chameleon,
  title={Chameleon: Mixed-modal early-fusion foundation models},
  author={Team, Chameleon},
  journal={arXiv preprint arXiv:2405.09818},
  year={2024}
}

@article{tian2024videotetris,
  title={VideoTetris: Towards Compositional Text-to-Video Generation},
  author={Tian, Ye and Yang, Ling and Yang, Haotian and Gao, Yuan and Deng, Yufan and Chen, Jingmin and Wang, Xintao and Yu, Zhaochen and Tao, Xin and Wan, Pengfei and others},
  journal={arXiv preprint arXiv:2406.04277},
  year={2024}
}

@article{tong2024metamorph,
  title={MetaMorph: Multimodal Understanding and Generation via Instruction Tuning},
  author={Tong, Shengbang and Fan, David and Zhu, Jiachen and Xiong, Yunyang and Chen, Xinlei and Sinha, Koustuv and Rabbat, Michael and LeCun, Yann and Xie, Saining and Liu, Zhuang},
  journal={arXiv preprint arXiv:2412.14164},
  year={2024}
}

@article{wang2024emu3,
  title={Emu3: Next-token prediction is all you need},
  author={Wang, Xinlong and Zhang, Xiaosong and Luo, Zhengxiong and Sun, Quan and Cui, Yufeng and Wang, Jinsheng and Zhang, Fan and Wang, Yueze and Li, Zhen and Yu, Qiying and others},
  journal={arXiv preprint arXiv:2409.18869},
  year={2024}
}

@article{wu2023next,
  title={Next-gpt: Any-to-any multimodal llm},
  author={Wu, Shengqiong and Fei, Hao and Qu, Leigang and Ji, Wei and Chua, Tat-Seng},
  journal={arXiv preprint arXiv:2309.05519},
  year={2023}
}

@article{wu2024janus,
  title={Janus: Decoupling visual encoding for unified multimodal understanding and generation},
  author={Wu, Chengyue and Chen, Xiaokang and Wu, Zhiyu and Ma, Yiyang and Liu, Xingchao and Pan, Zizheng and Liu, Wen and Xie, Zhenda and Yu, Xingkai and Ruan, Chong and others},
  journal={arXiv preprint arXiv:2410.13848},
  year={2024}
}

@article{xie2024muse,
  title={MUSE-VL: Modeling Unified VLM through Semantic Discrete Encoding},
  author={Xie, Rongchang and Du, Chen and Song, Ping and Liu, Chang},
  journal={arXiv preprint arXiv:2411.17762},
  year={2024}
}

@article{xie2024show,
  title={Show-o: One single transformer to unify multimodal understanding and generation},
  author={Xie, Jinheng and Mao, Weijia and Bai, Zechen and Zhang, David Junhao and Wang, Weihao and Lin, Kevin Qinghong and Gu, Yuchao and Chen, Zhijie and Yang, Zhenheng and Shou, Mike Zheng},
  journal={arXiv preprint arXiv:2408.12528},
  year={2024}
}

@inproceedings{yang2024mastering,
  title={Mastering text-to-image diffusion: Recaptioning, planning, and generating with multimodal llms},
  author={Yang, Ling and Yu, Zhaochen and Meng, Chenlin and Xu, Minkai and Ermon, Stefano and Bin, CUI},
  booktitle={Forty-first International Conference on Machine Learning},
  year={2024}
}

@article{yang2025reasonflux,
  title={ReasonFlux: Hierarchical LLM Reasoning via Scaling Thought Templates},
  author={Yang, Ling and Yu, Zhaochen and Cui, Bin and Wang, Mengdi},
  journal={arXiv preprint arXiv:2502.06772},
  year={2025}
}

@inproceedings{yang2025supercorrect,
  title={SuperCorrect: Supervising and Correcting Language Models with Error-Driven Insights},
  author={Yang, Ling and Yu, Zhaochen and Zhang, Tianjun and Xu, Minkai and Gonzalez, Joseph E and Cui, Bin and Yan, Shuicheng},
  booktitle={International Conference on Learning Representations},
  year={2025}
}

@article{ye2024x,
  title={X-VILA: Cross-Modality Alignment for Large Language Model},
  author={Ye, Hanrong and Huang, De-An and Lu, Yao and Yu, Zhiding and Ping, Wei and Tao, Andrew and Kautz, Jan and Han, Song and Xu, Dan and Molchanov, Pavlo and others},
  journal={arXiv preprint arXiv:2405.19335},
  year={2024}
}

@article{zhang2024critic,
  title={Critic-v: Vlm critics help catch vlm errors in multimodal reasoning},
  author={Zhang, Di and Lei, Jingdi and Li, Junxian and Wang, Xunzhi and Liu, Yujie and Yang, Zonglin and Li, Jiatong and Wang, Weida and Yang, Suorong and Wu, Jianbo and others},
  journal={arXiv preprint arXiv:2411.18203},
  year={2024}
}

@article{zhang2024fate,
  title={FATE: Full-head Gaussian Avatar with Textural Editing from Monocular Video},
  author={Zhang, Jiawei and Wu, Zijian and Liang, Zhiyang and Gong, Yicheng and Hu, Dongfang and Yao, Yao and Cao, Xun and Zhu, Hao},
  journal={arXiv preprint arXiv:2411.15604},
  year={2024}
}

@article{zhang2024itercomp,
  title={Itercomp: Iterative composition-aware feedback learning from model gallery for text-to-image generation},
  author={Zhang, Xinchen and Yang, Ling and Li, Guohao and Cai, Yaqi and Xie, Jiake and Tang, Yong and Yang, Yujiu and Wang, Mengdi and Cui, Bin},
  journal={arXiv preprint arXiv:2410.07171},
  year={2024}
}

@inproceedings{zhang2024realcompo,
  title={Realcompo: Balancing realism and compositionality improves text-to-image diffusion models},
  author={Zhang, Xinchen and Yang, Ling and Cai, Yaqi and Yu, Zhaochen and Wang, Kai-Ni and Tian, Ye and Xu, Minkai and Tang, Yong and Yang, Yujiu and Bin, CUI and others},
  booktitle={The Thirty-eighth Annual Conference on Neural Information Processing Systems},
  year={2024}
}

@article{zhou2024aligning,
  title={Aligning modalities in vision large language models via preference fine-tuning},
  author={Zhou, Yiyang and Cui, Chenhang and Rafailov, Rafael and Finn, Chelsea and Yao, Huaxiu},
  journal={arXiv preprint arXiv:2402.11411},
  year={2024}
}

@article{zhou2024calibrated,
  title={Calibrated self-rewarding vision language models},
  author={Zhou, Yiyang and Fan, Zhiyuan and Cheng, Dongjie and Yang, Sihan and Chen, Zhaorun and Cui, Chenhang and Wang, Xiyao and Li, Yun and Zhang, Linjun and Yao, Huaxiu},
  journal={arXiv preprint arXiv:2405.14622},
  year={2024}
}

@article{zhou2024transfusion,
  title={Transfusion: Predict the next token and diffuse images with one multi-modal model},
  author={Zhou, Chunting and Yu, Lili and Babu, Arun and Tirumala, Kushal and Yasunaga, Michihiro and Shamis, Leonid and Kahn, Jacob and Ma, Xuezhe and Zettlemoyer, Luke and Levy, Omer},
  journal={arXiv preprint arXiv:2408.11039},
  year={2024}
}

@article{zhuang2024towards,
  title={Towards Native Generative Model for 3D Head Avatar},
  author={Zhuang, Yiyu and He, Yuxiao and Zhang, Jiawei and Wang, Yanwen and Zhu, Jiahe and Yao, Yao and Zhu, Siyu and Cao, Xun and Zhu, Hao},
  journal={arXiv preprint arXiv:2410.01226},
  year={2024}
}

