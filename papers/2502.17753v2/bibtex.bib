@article{jang2023multimodal,
  title={Multimodal subtask graph generation from instructional videos},
  author={Jang, Yunseok and Sohn, Sungryull and Logeswaran, Lajanugen and Luo, Tiange and Lee, Moontae and Lee, Honglak},
  journal={arXiv preprint arXiv:2302.08672},
  year={2023}
}

@article{kanade2012first,
  title={First-person vision},
  author={Kanade, Takeo and Hebert, Martial},
  journal={Proceedings of the IEEE},
  volume={100},
  number={8},
  pages={2442--2453},
  year={2012},
  publisher={IEEE}
}

@article{plizzari2023outlook,
  title={An outlook into the future of egocentric vision},
  author={Plizzari, Chiara and Goletto, Gabriele and Furnari, Antonino and Bansal, Siddhant and Ragusa, Francesco and Farinella, Giovanni Maria and Damen, Dima and Tommasi, Tatiana},
  journal={International Journal fn Computer Vision},
  year={2023}
}

@article{martinez2021wearable,
  title={Wearable assistive robotics: A perspective on current challenges and future trends},
  author={Martinez-Hernandez, Uriel and Metcalfe, Benjamin and Assaf, Tareq and Jabban, Leen and Male, James and Zhang, Dingguo},
  journal={Sensors},
  volume={21},
  number={20},
  pages={6751},
  year={2021},
  publisher={MDPI}
}

@article{ashutosh2024video,
  title={Video-mined task graphs for keystep recognition in instructional videos},
  author={Ashutosh, Kumar and Ramakrishnan, Santhosh Kumar and Afouras, Triantafyllos and Grauman, Kristen},
  journal={Advances in Neural Information Processing Systems},
  volume={36},
  year={2024}
}

@inproceedings{dvornik2023stepformer,
  title={Stepformer: Self-supervised step discovery and localization in instructional videos},
  author={Dvornik, Nikita and Hadji, Isma and Zhang, Ran and Derpanis, Konstantinos G and Wildes, Richard P and Jepson, Allan D},
  booktitle={Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition},
  pages={18952--18961},
  year={2023}
}

@inproceedings{zhou2018towards,
  title={Towards automatic learning of procedures from web instructional videos},
  author={Zhou, Luowei and Xu, Chenliang and Corso, Jason},
  booktitle={Proceedings of the AAAI Conference on Artificial Intelligence},
  volume={32},
  number={1},
  year={2018}
}

@inproceedings{zhukov2019cross,
  title={Cross-task weakly supervised learning from instructional videos},
  author={Zhukov, Dimitri and Alayrac, Jean-Baptiste and Cinbis, Ramazan Gokberk and Fouhey, David and Laptev, Ivan and Sivic, Josef},
  booktitle={Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition},
  pages={3537--3545},
  year={2019}
}

@inproceedings{miech2020end,
  title={End-to-end learning of visual representations from uncurated instructional videos},
  author={Miech, Antoine and Alayrac, Jean-Baptiste and Smaira, Lucas and Laptev, Ivan and Sivic, Josef and Zisserman, Andrew},
  booktitle={Proceedings of the IEEE/CVF conference on computer vision and pattern recognition},
  pages={9879--9889},
  year={2020}
}

@inproceedings{elhamifar2020self,
  title={Self-supervised multi-task procedure learning from instructional videos},
  author={Elhamifar, Ehsan and Huynh, Dat},
  booktitle={Computer Vision--ECCV 2020: 16th European Conference, Glasgow, UK, August 23--28, 2020, Proceedings, Part XVII 16},
  pages={557--573},
  year={2020},
  organization={Springer}
}

@article{dvornik2021drop,
  title={Drop-dtw: Aligning common signal between sequences while dropping outliers},
  author={Dvornik, Mikita and Hadji, Isma and Derpanis, Konstantinos G and Garg, Animesh and Jepson, Allan},
  journal={Advances in Neural Information Processing Systems},
  volume={34},
  pages={13782--13793},
  year={2021}
}

@inproceedings{zhou2023procedure,
  title={Procedure-aware pretraining for instructional video understanding},
  author={Zhou, Honglu and Mart{\'\i}n-Mart{\'\i}n, Roberto and Kapadia, Mubbasir and Savarese, Silvio and Niebles, Juan Carlos},
  booktitle={Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition},
  pages={10727--10738},
  year={2023}
}

@inproceedings{zhong2023learning,
  title={Learning procedure-aware video representation from instructional videos and their narrations},
  author={Zhong, Yiwu and Yu, Licheng and Bai, Yang and Li, Shangwen and Yan, Xueting and Li, Yin},
  booktitle={Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition},
  pages={14825--14835},
  year={2023}
}

@article{narasimhan2023learning,
  title={Learning and verification of task structure in instructional videos},
  author={Narasimhan, Medhini and Yu, Licheng and Bell, Sean and Zhang, Ning and Darrell, Trevor},
  journal={arXiv preprint arXiv:2303.13519},
  year={2023}
}

@inproceedings{lu2022set,
  title={Set-supervised action learning in procedural task videos via pairwise order consistency},
  author={Lu, Zijia and Elhamifar, Ehsan},
  booktitle={Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition},
  pages={19903--19913},
  year={2022}
}

@article{sohn2020meta,
  title={Meta reinforcement learning with autonomous inference of subtask dependencies},
  author={Sohn, Sungryull and Woo, Hyunjae and Choi, Jongwook and Lee, Honglak},
  journal={arXiv preprint arXiv:2001.00248},
  year={2020}
}

@inproceedings{
peddi2023captaincook4d,
title={CaptainCook4D: A Dataset for Understanding Errors in Procedural Activities},
author={Rohith Peddi and Shivvrat Arya and Bharath Challa and Likhitha Pallapothula and Akshay Vyas and Bhavya Gouripeddi and Qifan Zhang and Jikai Wang and Vasundhara Komaragiri and Eric Ragan and Nicholas Ruozzi and Yu Xiang and Vibhav Gogate},
booktitle={The Thirty-eight Conference on Neural Information Processing Systems Datasets and Benchmarks Track},
year={2024},
url={https://openreview.net/forum?id=YFUp7zMrM9}
}

@inproceedings{pramanick2023egovlpv2,
  title={Egovlpv2: Egocentric video-language pre-training with fusion in the backbone},
  author={Pramanick, Shraman and Song, Yale and Nag, Sayan and Lin, Kevin Qinghong and Shah, Hardik and Shou, Mike Zheng and Chellappa, Rama and Zhang, Pengchuan},
  booktitle={Proceedings of the IEEE/CVF International Conference on Computer Vision},
  pages={5285--5297},
  year={2023}
}

@inproceedings{zhou2015temporal,
  title={Temporal perception and prediction in ego-centric video},
  author={Zhou, Yipin and Berg, Tamara L},
  booktitle={Proceedings of the IEEE International Conference on Computer Vision},
  pages={4498--4506},
  year={2015}
}

@inproceedings{flaborea2024prego,
  title={PREGO: online mistake detection in PRocedural EGOcentric videos},
  author={Flaborea, Alessandro and di Melendugno, Guido Maria D'Amely and Plini, Leonardo and Scofano, Luca and De Matteis, Edoardo and Furnari, Antonino and Farinella, Giovanni Maria and Galasso, Fabio},
  booktitle={Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition},
  pages={18483--18492},
  year={2024}
}

@inproceedings{bansal2022my,
  title={My view is the best view: Procedure learning from egocentric videos},
  author={Bansal, Siddhant and Arora, Chetan and Jawahar, CV},
  booktitle={European Conference on Computer Vision},
  pages={657--675},
  year={2022},
  organization={Springer}
}

@inproceedings{lin2022learning,
  title={Learning to recognize procedural activities with distant supervision},
  author={Lin, Xudong and Petroni, Fabio and Bertasius, Gedas and Rohrbach, Marcus and Chang, Shih-Fu and Torresani, Lorenzo},
  booktitle={Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition},
  pages={13853--13863},
  year={2022}
}

@article{song2024ego4d,
  title={Ego4d goal-step: Toward hierarchical understanding of procedural activities},
  author={Song, Yale and Byrne, Eugene and Nagarajan, Tushar and Wang, Huiyu and Martin, Miguel and Torresani, Lorenzo},
  journal={Advances in Neural Information Processing Systems},
  volume={36},
  year={2024}
}

@inproceedings{grauman2023ego,
  title={Ego-exo4d: Understanding skilled human activity from first-and third-person perspectives},
  author={Grauman, Kristen and Westbury, Andrew and Torresani, Lorenzo and Kitani, Kris and Malik, Jitendra and Afouras, Triantafyllos and Ashutosh, Kumar and Baiyya, Vijay and Bansal, Siddhant and Boote, Bikram and others},
  booktitle={Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition},
  pages={19383--19400},
  year={2024}
}

@inproceedings{sener2022assembly101,
  title={Assembly101: A large-scale multi-view video dataset for understanding procedural activities},
  author={Sener, Fadime and Chatterjee, Dibyadip and Shelepov, Daniel and He, Kun and Singhania, Dipika and Wang, Robert and Yao, Angela},
  booktitle={Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition},
  pages={21096--21106},
  year={2022}
}

@inproceedings{jang2019epic,
  title={Epic-tent: An egocentric video dataset for camping tent assembly},
  author={Jang, Youngkyoon and Sullivan, Brian and Ludwig, Casimir and Gilchrist, Iain and Damen, Dima and Mayol-Cuevas, Walterio},
  booktitle={Proceedings of the IEEE/CVF International Conference on Computer Vision Workshops},
  pages={0--0},
  year={2019}
}

@inproceedings{dvornik2022graph2vid,
  title={Graph2vid: Flow graph to video grounding for weakly-supervised multi-step localization},
  author={Dvornik, Nikita and Hadji, Isma and Pham, Hai and Bhatt, Dhaivat and Martinez, Brais and Fazly, Afsaneh and Jepson, Allan D},
  booktitle={Proceedings of the European Conference on Computer Vision (ECCV)},
  year={2022}
}

@inproceedings{baradel2018object,
  title={Object level visual reasoning in videos},
  author={Baradel, Fabien and Neverova, Natalia and Wolf, Christian and Mille, Julien and Mori, Greg},
  booktitle={Proceedings of the European Conference on Computer Vision (ECCV)},
  pages={105--121},
  year={2018}
}

@inproceedings{ghosh2020stacked,
  title={Stacked spatio-temporal graph convolutional networks for action segmentation},
  author={Ghosh, Pallabi and Yao, Yi and Davis, Larry and Divakaran, Ajay},
  booktitle={Proceedings of the IEEE/CVF winter conference on applications of computer vision},
  pages={576--585},
  year={2020}
}

@inproceedings{grauman2022ego4d,
  title={Ego4d: Around the world in 3,000 hours of egocentric video},
  author={Grauman, Kristen and Westbury, Andrew and Byrne, Eugene and Chavis, Zachary and Furnari, Antonino and Girdhar, Rohit and Hamburger, Jackson and Jiang, Hao and Liu, Miao and Liu, Xingyu and others},
  booktitle={Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition},
  pages={18995--19012},
  year={2022}
}

@inproceedings{rashid2020action,
  title={Action graphs: Weakly-supervised action localization with graph convolution networks},
  author={Rashid, Maheen and Kjellstrom, Hedvig and Lee, Yong Jae},
  booktitle={Proceedings of the IEEE/CVF winter conference on applications of computer vision},
  pages={615--624},
  year={2020}
}

@inproceedings{wang2018videos,
  title={Videos as space-time region graphs},
  author={Wang, Xiaolong and Gupta, Abhinav},
  booktitle={Proceedings of the European conference on computer vision (ECCV)},
  pages={399--417},
  year={2018}
}

@inproceedings{zhang2019structured,
  title={A structured model for action detection},
  author={Zhang, Yubo and Tokmakov, Pavel and Hebert, Martial and Schmid, Cordelia},
  booktitle={Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition},
  pages={9975--9984},
  year={2019}
}

@inproceedings{girdhar2021anticipative,
  title={Anticipative video transformer},
  author={Girdhar, Rohit and Grauman, Kristen},
  booktitle={Proceedings of the IEEE/CVF international conference on computer vision},
  pages={13505--13515},
  year={2021}
}

@article{furnari2020rolling,
  title={Rolling-unrolling lstms for action anticipation from first-person video},
  author={Furnari, Antonino and Farinella, Giovanni Maria},
  journal={IEEE transactions on pattern analysis and machine intelligence},
  volume={43},
  number={11},
  pages={4021--4036},
  year={2020},
  publisher={IEEE}
}

@inproceedings{roy2024interaction,
  title={Interaction Region Visual Transformer for Egocentric Action Anticipation},
  author={Roy, Debaditya and Rajendiran, Ramanathan and Fernando, Basura},
  booktitle={Proceedings of the IEEE/CVF Winter Conference on Applications of Computer Vision},
  pages={6740--6750},
  year={2024}
}

@INPROCEEDINGS{bansal2024united,
  author={Bansal, Siddhant and Arora, Chetan and Jawahar, C.V.},
  booktitle={2024 IEEE/CVF Winter Conference on Applications of Computer Vision (WACV)}, 
  title={United We Stand, Divided We Fall: UnityGraph for Unsupervised Procedure Learning from Videos}, 
  year={2024},
  volume={},
  number={},
  pages={6495-6505},
  keywords={Computer vision;Computational modeling;Clustering algorithms;Benchmark testing;Task analysis;Videos;Algorithms;Video recognition and understanding;Algorithms;Machine learning architectures;formulations;and algorithms},
  doi={10.1109/WACV57701.2024.00638}}


@article{achiam2023gpt,
  title={Gpt-4 technical report},
  author={Achiam, Josh and Adler, Steven and Agarwal, Sandhini and Ahmad, Lama and Akkaya, Ilge and Aleman, Florencia Leoni and Almeida, Diogo and Altenschmidt, Janko and Altman, Sam and Anadkat, Shyamal and others},
  journal={arXiv preprint arXiv:2303.08774},
  year={2023}
}

@inproceedings{sakaguchi2021proscript,
    title = "pro{S}cript: Partially Ordered Scripts Generation",
    author = "Sakaguchi, Keisuke  and
      Bhagavatula, Chandra  and
      Le Bras, Ronan  and
      Tandon, Niket  and
      Clark, Peter  and
      Choi, Yejin",
    editor = "Moens, Marie-Francine  and
      Huang, Xuanjing  and
      Specia, Lucia  and
      Yih, Scott Wen-tau",
    booktitle = "Findings of the Association for Computational Linguistics: EMNLP 2021",
    month = nov,
    year = "2021",
    address = "Punta Cana, Dominican Republic",
    publisher = "Association for Computational Linguistics",
    url = "https://aclanthology.org/2021.findings-emnlp.184",
    doi = "10.18653/v1/2021.findings-emnlp.184",
    pages = "2138--2149",
}

@inproceedings{kiddon2015mise,
  title={Mise en place: Unsupervised interpretation of instructional recipes},
  author={Kiddon, Chlo{\'e} and Ponnuraj, Ganesa Thandavam and Zettlemoyer, Luke and Choi, Yejin},
  booktitle={Proceedings of the 2015 Conference on Empirical Methods in Natural Language Processing},
  pages={982--992},
  year={2015}
}

@inproceedings{yamakata2020english,
  title={English recipe flow graph corpus},
  author={Yamakata, Yoko and Mori, Shinsuke and Carroll, John A},
  booktitle={Proceedings of the Twelfth Language Resources and Evaluation Conference},
  pages={5187--5194},
  year={2020}
}

@article{zhu2023llms,
  title={Llms for knowledge graph construction and reasoning: Recent capabilities and future opportunities},
  author={Zhu, Yuqi and Wang, Xiaohan and Chen, Jing and Qiao, Shuofei and Ou, Yixin and Yao, Yunzhi and Deng, Shumin and Chen, Huajun and Zhang, Ningyu},
  journal={arXiv preprint arXiv:2305.13168},
  year={2023}
}

@inproceedings{donatelli2021aligning,
  title={Aligning actions across recipe graphs},
  author={Donatelli, Lucia and Schmidt, Theresa and Biswas, Debanjali and K{\"o}hn, Arne and Zhai, Fangzhou and Koller, Alexander},
  booktitle={Proceedings of the 2021 conference on empirical methods in natural language processing},
  pages={6930--6942},
  year={2021}
}

@inproceedings{schumacher2012extraction,
  title={Extraction of procedural knowledge from the web: A comparison of two workflow extraction approaches},
  author={Schumacher, Pol and Minor, Mirjam and Walter, Kirstin and Bergmann, Ralph},
  booktitle={Proceedings of the 21st International Conference on World Wide Web},
  pages={739--747},
  year={2012}
}

@inproceedings{radford2021learning,
  title={Learning transferable visual models from natural language supervision},
  author={Radford, Alec and Kim, Jong Wook and Hallacy, Chris and Ramesh, Aditya and Goh, Gabriel and Agarwal, Sandhini and Sastry, Girish and Askell, Amanda and Mishkin, Pamela and Clark, Jack and others},
  booktitle={International conference on machine learning},
  pages={8748--8763},
  year={2021},
  organization={PMLR}
}

@book{marquis1820theorie,
  title={Th{\'e}orie analytique des probabilit{\'e}s},
  author={Marquis de Laplace, Pierre Simon},
  volume={7},
  year={1820},
  publisher={Courcier}
}

@inproceedings{mihindukulasooriya2023text2kgbench,
  title={Text2kgbench: A benchmark for ontology-driven knowledge graph generation from text},
  author={Mihindukulasooriya, Nandana and Tiwari, Sanju and Enguix, Carlos F and Lata, Kusum},
  booktitle={International Semantic Web Conference},
  pages={247--265},
  year={2023},
  organization={Springer}
}

@article{trajanoska2023enhancing,
  title={Enhancing knowledge graph construction using large language models},
  author={Trajanoska, Milena and Stojanov, Riste and Trajanov, Dimitar},
  journal={arXiv preprint arXiv:2305.04676},
  year={2023}
}

@book{skiena1998algorithm,
  title={The algorithm design manual},
  author={Skiena, Steven S},
  volume={2},
  year={1998},
  publisher={Springer},
  comment={page 468}
}

@inproceedings{ghoddoosian2023weakly,
  title={Weakly-Supervised Action Segmentation and Unseen Error Detection in Anomalous Instructional Videos},
  author={Ghoddoosian, Reza and Dwivedi, Isht and Agarwal, Nakul and Dariush, Behzad},
  booktitle={Proceedings of the IEEE/CVF International Conference on Computer Vision},
  pages={10128--10138},
  year={2023}
}

@inproceedings{wang2023holoassist,
  title={Holoassist: an egocentric human interaction dataset for interactive ai assistants in the real world},
  author={Wang, Xin and Kwon, Taein and Rad, Mahdi and Pan, Bowen and Chakraborty, Ishani and Andrist, Sean and Bohus, Dan and Feniello, Ashley and Tekin, Bugra and Frujeri, Felipe Vieira and others},
  booktitle={Proceedings of the IEEE/CVF International Conference on Computer Vision},
  pages={20270--20281},
  year={2023}
}

@article{ding2023every,
  title={Every Mistake Counts in Assembly},
  author={Ding, Guodong and Sener, Fadime and Ma, Shugao and Yao, Angela},
  journal={arXiv preprint arXiv:2307.16453},
  year={2023}
}

@article{vaswani2017attention,
  title={Attention is all you need},
  author={Vaswani, Ashish and Shazeer, Noam and Parmar, Niki and Uszkoreit, Jakob and Jones, Llion and Gomez, Aidan N and Kaiser, {\L}ukasz and Polosukhin, Illia},
  journal={Advances in neural information processing systems},
  volume={30},
  year={2017}
}

@inproceedings{an2023miniroad,
  title={MiniROAD: Minimal RNN Framework for Online Action Detection},
  author={An, Joungbin and Kang, Hyolim and Han, Su Ho and Yang, Ming-Hsuan and Kim, Seon Joo},
  booktitle={Proceedings of the IEEE/CVF International Conference on Computer Vision},
  pages={10341--10350},
  year={2023}
}

@inproceedings{wang2021oadtr,
  title={Oadtr: Online action detection with transformers},
  author={Wang, Xiang and Zhang, Shiwei and Qing, Zhiwu and Shao, Yuanjie and Zuo, Zhengrong and Gao, Changxin and Sang, Nong},
  booktitle={Proceedings of the IEEE/CVF International Conference on Computer Vision},
  pages={7565--7575},
  year={2021}
}

@inproceedings{caba2015activitynet,
  title={Activitynet: A large-scale video benchmark for human activity understanding},
  author={Caba Heilbron, Fabian and Escorcia, Victor and Ghanem, Bernard and Carlos Niebles, Juan},
  booktitle={Proceedings of the ieee conference on computer vision and pattern recognition},
  pages={961--970},
  year={2015}
}

@article{kay2017kinetics,
  title={The kinetics human action video dataset},
  author={Kay, Will and Carreira, Joao and Simonyan, Karen and Zhang, Brian and Hillier, Chloe and Vijayanarasimhan, Sudheendra and Viola, Fabio and Green, Tim and Back, Trevor and Natsev, Paul and others},
  journal={arXiv preprint arXiv:1705.06950},
  year={2017}
}

@article{oord2018representation,
  title={Representation learning with contrastive predictive coding},
  author={Oord, Aaron van den and Li, Yazhe and Vinyals, Oriol},
  journal={arXiv preprint arXiv:1807.03748},
  year={2018}
}

@article{dubey2024llama,
  title={The llama 3 herd of models},
  author={Dubey, Abhimanyu and Jauhri, Abhinav and Pandey, Abhinav and Kadian, Abhishek and Al-Dahle, Ahmad and Letman, Aiesha and Mathur, Akhil and Schelten, Alan and Yang, Amy and Fan, Angela and others},
  journal={arXiv preprint arXiv:2407.21783},
  year={2024}
}

@inproceedings{lee2024error,
  title={Error detection in egocentric procedural task videos},
  author={Lee, Shih-Po and Lu, Zijia and Zhang, Zekun and Hoai, Minh and Elhamifar, Ehsan},
  booktitle={Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition},
  pages={18655--18666},
  year={2024}
}

@article{de2009guide,
  title={Guide to the carnegie mellon university multimodal activity (cmu-mmac) database},
  author={De la Torre, Fernando and Hodgins, Jessica and Bargteil, Adam and Martin, Xavier and Macey, Justin and Collado, Alex and Beltran, Pep},
  year={2009},
  publisher={Citeseer}
}

@inproceedings{li2018eye,
  title={In the eye of beholder: Joint learning of gaze and actions in first person video},
  author={Li, Yin and Liu, Miao and Rehg, James M},
  booktitle={Proceedings of the European conference on computer vision (ECCV)},
  pages={619--635},
  year={2018}
}

@inproceedings{ragusa2021meccano,
  title={The meccano dataset: Understanding human-object interactions from egocentric videos in an industrial-like domain},
  author={Ragusa, Francesco and Furnari, Antonino and Livatino, Salvatore and Farinella, Giovanni Maria},
  booktitle={Proceedings of the IEEE/CVF Winter Conference on Applications of Computer Vision},
  pages={1569--1578},
  year={2021}
}

@inproceedings{batra2025efficient,
  title={Efficient Pre-training for Localized Instruction Generation of Procedural Videos},
  author={Batra, Anil and Moltisanti, Davide and Sevilla-Lara, Laura and Rohrbach, Marcus and Keller, Frank},
  booktitle={European Conference on Computer Vision},
  pages={347--363},
  year={2025},
  organization={Springer}
}

@inproceedings{schoonbeek2024industreal,
  title={Industreal: A dataset for procedure step recognition handling execution errors in egocentric videos in an industrial-like setting},
  author={Schoonbeek, Tim J and Houben, Tim and Onvlee, Hans and Van der Sommen, Fons and others},
  booktitle={Proceedings of the IEEE/CVF Winter Conference on Applications of Computer Vision},
  pages={4365--4374},
  year={2024}
}

@inproceedings{ragusa2024enigma,
  title={ENIGMA-51: Towards a Fine-Grained Understanding of Human Behavior in Industrial Scenarios},
  author={Ragusa, Francesco and Leonardi, Rosario and Mazzamuto, Michele and Bonanno, Claudia and Scavo, Rosario and Furnari, Antonino and Farinella, Giovanni Maria},
  booktitle={Proceedings of the IEEE/CVF Winter Conference on Applications of Computer Vision},
  pages={4549--4559},
  year={2024}
}

@inproceedings{
    seminara2024differentiable,
    title={Differentiable Task Graph Learning: Procedural Activity Representation and Online Mistake Detection from Egocentric Videos},
    author={Luigi Seminara and Giovanni Maria Farinella and Antonino Furnari},
    booktitle={The Thirty-eighth Annual Conference on Neural Information Processing Systems},
    year={2024},
    url={https://openreview.net/forum?id=2HvgvB4aWq}
}

@inproceedings{hazra2023egotv,
  title={Egotv: Egocentric task verification from natural language task descriptions},
  author={Hazra, Rishi and Chen, Brian and Rai, Akshara and Kamra, Nitin and Desai, Ruta},
  booktitle={Proceedings of the IEEE/CVF International Conference on Computer Vision},
  pages={15417--15429},
  year={2023}
}

@inproceedings{nagasinghe2024not,
  title={Why Not Use Your Textbook? Knowledge-Enhanced Procedure Planning of Instructional Videos},
  author={Nagasinghe, Kumaranage Ravindu Yasas and Zhou, Honglu and Gunawardhana, Malitha and Min, Martin Renqiang and Harari, Daniel and Khan, Muhammad Haris},
  booktitle={Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition},
  pages={18816--18826},
  year={2024}
}

@inproceedings{shen2024progress,
  title={Progress-aware online action segmentation for egocentric procedural task videos},
  author={Shen, Yuhan and Elhamifar, Ehsan},
  booktitle={Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition},
  pages={18186--18197},
  year={2024}
}