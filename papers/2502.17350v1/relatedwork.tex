\section{Related Work}
\label{sec:related_work}
We present a detailed review of existing works on the topics related to semantic and GO communication and its applications for real-time monitoring and control in Appendix B. Moreover, Appendix B analyzes general network resource management approaches for such applications, including the methods in control theory, networking standards designed for CPSs, and research works dealing with semantic prioritization. In this section, we focus on the existing results on GO TL design for monitoring and control.


Generally, the SotA envisions that goal orientation can be enabled by introducing semantic metrics into the networking design. These metrics are applied at the data-link or network layers \cite{ouguz2022implementation, kadota2018scheduling, chang2023lightweight, ma2022scheduling, ayan2019age}, used to optimize sampling policies for the fixed underlying network setup \cite{maatouk2020age, nikkhah2023age, mason2023multi}, or do both \cite{zheng2020urgency, peng2021sensing, jarwan2021information }. In the meantime, in the case of remote monitoring and control, there is a direct connection between semantic attributes such as timeliness, relevance, and value with the status information sensed in real-time. The TL modification approach implies that the decision-makers are co-located with sensors, making instantaneous status available for the networking design. Moreover, it is inherent to TL to adapt to dynamically changing available network resources. This fact contributes to the general applicability of the proposed method. Thus, distributed GO TL filtering is a feasible approach that can be highly beneficial for real-time control and monitoring.  The principal difference between this method and classic ET applied in control theory is that the GO TL is not only relevance- but also network-aware. That means that not only is the traffic reduced, but this reduction depends on network congestion level and instantaneous network conditions, carrying out the functions of TL, as elaborated in \cite{ge2019distributed}. 
 
There are further arguments for considering GO semantic approaches at the TL. Firstly, the modification at TL can be pushed through software by designing the application part of the protocol in the middleware on top of existing TL schemes, such as UDP. The underlying conventional TL is responsible for the connection establishment in the network, as, for instance, is done for the implementation of QUIC \cite{langley2017quic}. Thus, the performance improvement achieved through TL modification does not require extra costs and implementation efforts compared to solutions that modify L2 and L3. Furthermore, the industry may not support the production of dedicated hardware from a commercial perspective. In addition, if the application relies on the provided network infrastructure, the developer may not be able to access the protocols of the lower layers. Thus, GO TL may offer improved end-to-end performance, irrespective of the underlying hardware. The conventional application-agnostic TL protocols, such as TCP and UDP, can deteriorate the real-time control or monitoring, as shown in \cite{beytur2020towards, ouguz2022implementation}. Our previous work \cite{kutsevol2023experimental} demonstrates that the existing TL schemes are unsuitable for control applications with fast dynamics, even when combined with the dedicated communication stack of IEEE 802.15.4 \cite{7460875}. This fact represents another argument in favor of modifying the TL.


Several studies are delving into the GO TL design for real-time systems. \cite{schmidtpredictably, shreedhar2019age} target AoI minimization via sampling rate adjustment. The work \cite{saifullah2014near} considers the sampling rate adaptation tailored for the WirelessHART protocol \cite{wirelesshart}. In these works, the sensors do not exploit the prioritization and filtering of updates based on their significance. Thus, network resources can be used to transmit irrelevant data. \cite{jarwan2021information, ngai2009information}, in contrast, apply prioritization and discard some of the less relevant data. However, the relevance assessment is done based on whether particular samples are expected by the sensor. Such an approach hinders the obtaining of the real value of the measurements w.r.t. remote monitor. Another important issue of the mentioned methods is that the samples' importance level cannot be adjusted according to available network resources. Conversely, the work \cite{jiang2020revealing} models network constraints as a constant cost parameter incorporated into the reward in the Markov Decision Process. The particular cost value can be picked based on the current network congestion level.


The works \cite{chiariotti2020quic, shi2019dtp} consider practical GO TL implementations over QUIC, using its multi-streaming functionality. Each piece of data is assigned with a separate stream, allowing for avoiding queuing effects such as head-of-line blocking. The TL schedules the time-sensitive data into available bandwidth based on VoI \cite{chiariotti2020quic} or priorities and deadlines \cite{shi2019dtp} fully defined by the application. Thus, \cite{chiariotti2020quic, shi2019dtp} exclude the network feedback for defining the relevance. Disregarding network effects means the transmitter's TL cannot correctly evaluate the receiver's state and incorporate it into relevance. \cite{jiang2020revealing} considers the network feedback but does not estimate how effective the transmitted data is at the receiver.

%Similarly to previously discussed studies, the work \cite{jiang2020revealing} does not suggest estimating how effective the transmitted data is at the receiver. Moreover, it is unclear how the network is included in the training process and how dependent the model is on the particular parameters.

In our previous work \cite{kutsevol2023experimental}, we considered the expected controller estimation error at the sensor side as a relevance measure. By that, we approach the vision of VoI defined in \cite{alawad2022value} and elaborated in \cite{holm2023goal} that the effectiveness of the transmitted data should be evaluated w.r.t. the decision maker, i.e., the controller. We apply a simple strategy where the sensors assume that the previously transmitted packet becomes available to the controller as soon as the corresponding ACK arrives. The proposed TL scheme is more effective than the one considering the state deviation at the sensor. However, it is not effective in more constrained scenarios, where the data packets and ACKs are likely to be significantly delayed or lost in the network. In this work, we present a technique to deal with network adverse effects by using the \textbf{BN}  to get an estimation of the current network status of the injected packets and the \textbf{AUGM} to determine the receiver's state. 

In this work, we propose two methods for obtaining relevance: based on the instantaneous estimation error and the expected improvement in the estimation trajectory upon admission. To the best of our knowledge, no SotA works practically exploit the necessity to assess the future dynamics of the receiver. The exception is \cite{holm2023goal}, which deals with monitoring tasks over a simplistic network. In this work, we follow the value definition from \cite{alawad2022value} and evaluate the difference in the utility when attempting to collect new information and making the decision without new data, considering the cost of transmitting this data. An important technique we introduce is a continuous weighting of the benefits the update can bring with dynamic transmission cost tightly intertwined with the current network congestion level. Our approach can be distinguished from the existing GO TL schemes by the pervasive mutual influence of real-time application and network management decisions. As a result,  resource management is highly optimized to maintain the ultimate performance under a wide range of networking setups and scenarios.