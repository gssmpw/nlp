\section{Related Work}
\label{sec:related}
\myparagraph{VLM's Visual Hallucinations}
Recent studies____ observed the tendency of VLMs to hallucinate content that is not present in the visual input, indicating a lack of robust multimodal grounding. 
To address this issue, several training-free methods have been proposed. ____ introduced the ``Set-of-Mark'' prompting technique, which overlays spatial and textual markers on images, helping models like GPT-4V better reference specific regions. ____ employed CLIP-guided decoding to steer the language outputs with grounded visual cues. 
On the architectural side, GRILL____ incorporates object-level alignment during pretraining to prompt visual grounding.
In contrast to these approaches, our work focuses on finetuning with a novel preference-tuning objective (\Cref{sec:model}) and a data construction pipeline (\Cref{sec:data}) based on visual counterfactuals____, targeting more precise alignment between multimodal details.

\myparagraph{VLM Finetuning} 
Finetuning enhances VLMs for task-specific performance and alignment with human preferences. 
SFT remains widely adopted to guide models toward instruction-following behaviors in multimodal contexts____. 
DPO____ optimizes the margin between the finetuned and unfintuned model versions using paired preference data. Extensions of DPO to VLMs incorporate the image as an additional prefix condition____. 
Recent methods such as mDPO____, MFPO____, V-DPO____, CHiP____ and Image-DPO____ further adapt the preference tuning paradigm to focus on image-side preferences over a pair of ``good'' and ``bad'' image, aiming to reduce visual hallucinations.
Our approach \modelname discards the one-sided ``preference'' formulation by introducing a stricter visual contrastive objective within a symmetrical construct, in which way the ``preference'' is treated as alignment over a matching image-text pair. This enables more comprehensive and robust improvements in VLM performance across tasks.