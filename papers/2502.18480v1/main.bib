
@inproceedings{hasan-ng-2014-automatic,
    title = "Automatic Keyphrase Extraction: A Survey of the State of the Art",
    author = "Hasan, Kazi Saidul  and
      Ng, Vincent",
    editor = "Toutanova, Kristina  and
      Wu, Hua",
    booktitle = "Proceedings of the 52nd Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers)",
    month = jun,
    year = "2014",
    address = "Baltimore, Maryland",
    publisher = "Association for Computational Linguistics",
    url = "https://aclanthology.org/P14-1119",
    doi = "10.3115/v1/P14-1119",
    pages = "1262--1273",
}

@INPROCEEDINGS{7805062,
  author={Merrouni, Zakariae Alami and Frikh, Bouchra and Ouhbi, Brahim},
  booktitle={2016 4th IEEE International Colloquium on Information Science and Technology (CiSt)}, 
  title={Automatic keyphrase extraction: An overview of the state of the art}, 
  year={2016},
  volume={},
  number={},
  pages={306-313},
  keywords={Feature extraction;Training;Data mining;Natural language processing;Search engines;Support vector machines;Automatic Keyphrase Extraction;Information Retrieval;Natural Language Processing},
  doi={10.1109/CIST.2016.7805062}}

@INPROCEEDINGS{8852151,
  author={Zhao, Lin and Huang, Longtao and Zang, Liangjun and Han, Jizhong and Hu, Songlin},
  booktitle={2019 International Joint Conference on Neural Networks (IJCNN)}, 
  title={LMLSTM:Extract Event-Oriented Keyphrase From News Stream}, 
  year={2019},
  volume={},
  number={},
  pages={1-7},
  keywords={Computer crashes;Task analysis;Recurrent neural networks;Data mining;Airports;Information retrieval},
  doi={10.1109/IJCNN.2019.8852151}}

@misc{choi2023simckpsimplecontrastivelearning,
      title={SimCKP: Simple Contrastive Learning of Keyphrase Representations}, 
      author={Minseok Choi and Chaeheon Gwak and Seho Kim and Si Hyeong Kim and Jaegul Choo},
      year={2023},
      eprint={2310.08221},
      archivePrefix={arXiv},
      primaryClass={cs.CL},
      url={https://arxiv.org/abs/2310.08221}, 
}

@inproceedings{10.1145/3308558.3313642,
author = {Alzaidy, Rabah and Caragea, Cornelia and Giles, C. Lee},
title = {Bi-LSTM-CRF Sequence Labeling for Keyphrase Extraction from Scholarly Documents},
year = {2019},
isbn = {9781450366748},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3308558.3313642},
doi = {10.1145/3308558.3313642},
abstract = {In this paper, we address the keyphrase extraction problem as sequence labeling and propose a model that jointly exploits the complementary strengths of Conditional Random Fields that capture label dependencies through a transition parameter matrix consisting of the transition probabilities from one label to the neighboring label, and Bidirectional Long Short Term Memory networks that capture hidden semantics in text through the long distance dependencies. Our results on three datasets of scholarly documents show that the proposed model substantially outperforms strong baselines and previous approaches for keyphrase extraction.},
booktitle = {The World Wide Web Conference},
pages = {2551–2557},
numpages = {7},
keywords = {sequence labeling, deep learning., Keyphrase extraction},
location = {San Francisco, CA, USA},
series = {WWW '19}
}

@inproceedings{luan-etal-2017-scientific,
    title = "Scientific Information Extraction with Semi-supervised Neural Tagging",
    author = "Luan, Yi  and
      Ostendorf, Mari  and
      Hajishirzi, Hannaneh",
    editor = "Palmer, Martha  and
      Hwa, Rebecca  and
      Riedel, Sebastian",
    booktitle = "Proceedings of the 2017 Conference on Empirical Methods in Natural Language Processing",
    month = sep,
    year = "2017",
    address = "Copenhagen, Denmark",
    publisher = "Association for Computational Linguistics",
    url = "https://aclanthology.org/D17-1279",
    doi = "10.18653/v1/D17-1279",
    pages = "2641--2651",
    abstract = "This paper addresses the problem of extracting keyphrases from scientific articles and categorizing them as corresponding to a task, process, or material. We cast the problem as sequence tagging and introduce semi-supervised methods to a neural tagging model, which builds on recent advances in named entity recognition. Since annotated training data is scarce in this domain, we introduce a graph-based semi-supervised algorithm together with a data selection scheme to leverage unannotated articles. Both inductive and transductive semi-supervised learning strategies outperform state-of-the-art information extraction performance on the 2017 SemEval Task 10 ScienceIE task.",
}

@inproceedings{zhang-etal-2016-keyphrase,
    title = "Keyphrase Extraction Using Deep Recurrent Neural Networks on {T}witter",
    author = "Zhang, Qi  and
      Wang, Yang  and
      Gong, Yeyun  and
      Huang, Xuanjing",
    editor = "Su, Jian  and
      Duh, Kevin  and
      Carreras, Xavier",
    booktitle = "Proceedings of the 2016 Conference on Empirical Methods in Natural Language Processing",
    month = nov,
    year = "2016",
    address = "Austin, Texas",
    publisher = "Association for Computational Linguistics",
    url = "https://aclanthology.org/D16-1080",
    doi = "10.18653/v1/D16-1080",
    pages = "836--845",
}

@inproceedings{Gu_2021, series={KDD ’21},
   title={UCPhrase: Unsupervised Context-aware Quality Phrase Tagging},
   url={http://dx.doi.org/10.1145/3447548.3467397},
   DOI={10.1145/3447548.3467397},
   booktitle={Proceedings of the 27th ACM SIGKDD Conference on Knowledge Discovery \& Data Mining},
   publisher={ACM},
   author={Gu, Xiaotao and Wang, Zihan and Bi, Zhenyu and Meng, Yu and Liu, Liyuan and Han, Jiawei and Shang, Jingbo},
   year={2021},
   month=aug, collection={KDD ’21} }

@misc{wu2024pretrainedlanguagemodelskeyphrase,
      title={Pre-trained Language Models for Keyphrase Generation: A Thorough Empirical Study}, 
      author={Di Wu and Wasi Uddin Ahmad and Kai-Wei Chang},
      year={2024},
      eprint={2212.10233},
      archivePrefix={arXiv},
      primaryClass={cs.CL},
      url={https://arxiv.org/abs/2212.10233}, 
}

@misc{chowdhury2022applyinggenericsequencetosequencemodel,
      title={Applying a Generic Sequence-to-Sequence Model for Simple and Effective Keyphrase Generation}, 
      author={Md Faisal Mahbub Chowdhury and Gaetano Rossiello and Michael Glass and Nandana Mihindukulasooriya and Alfio Gliozzo},
      year={2022},
      eprint={2201.05302},
      archivePrefix={arXiv},
      primaryClass={cs.CL},
      url={https://arxiv.org/abs/2201.05302}, 
}

@INPROCEEDINGS{9443960,
  author={Liu, Rui and Lin, Zheng and Fu, Peng and Wang, Weiping},
  booktitle={2020 IEEE Intl Conf on Parallel \& Distributed Processing with Applications, Big Data \& Cloud Computing, Sustainable Computing \& Communications, Social Computing \& Networking (ISPA/BDCloud/SocialCom/SustainCom)}, 
  title={Reinforced Keyphrase Generation with BERT-based Sentence Scorer}, 
  year={2020},
  volume={},
  number={},
  pages={1-8},
  keywords={Training;Semantics;Neural networks;Reinforcement learning;Information retrieval;Natural language processing;Task analysis;keyphrase generation;sentence scorer;reinforcement learning;deep neural network},
  doi={10.1109/ISPA-BDCloud-SocialCom-SustainCom51426.2020.00027}}

@misc{ouyang2022traininglanguagemodelsfollow,
      title={Training language models to follow instructions with human feedback}, 
      author={Long Ouyang and Jeff Wu and Xu Jiang and Diogo Almeida and Carroll L. Wainwright and Pamela Mishkin and Chong Zhang and Sandhini Agarwal and Katarina Slama and Alex Ray and John Schulman and Jacob Hilton and Fraser Kelton and Luke Miller and Maddie Simens and Amanda Askell and Peter Welinder and Paul Christiano and Jan Leike and Ryan Lowe},
      year={2022},
      eprint={2203.02155},
      archivePrefix={arXiv},
      primaryClass={cs.CL},
      url={https://arxiv.org/abs/2203.02155}, 
}

@misc{peng2024largelanguagemodelbased,
      title={Large Language Model based Long-tail Query Rewriting in Taobao Search}, 
      author={Wenjun Peng and Guiyang Li and Yue Jiang and Zilong Wang and Dan Ou and Xiaoyi Zeng and Derong Xu and Tong Xu and Enhong Chen},
      year={2024},
      eprint={2311.03758},
      archivePrefix={arXiv},
      primaryClass={cs.IR},
      url={https://arxiv.org/abs/2311.03758}, 
}

@misc{rafailov2023directpreferenceoptimizationlanguage,
      title={Direct Preference Optimization: Your Language Model is Secretly a Reward Model}, 
      author={Rafael Rafailov and Archit Sharma and Eric Mitchell and Stefano Ermon and Christopher D. Manning and Chelsea Finn},
      year={2023},
      eprint={2305.18290},
      archivePrefix={arXiv},
      primaryClass={cs.LG},
      url={https://arxiv.org/abs/2305.18290}, 
}

@misc{hong2024orpomonolithicpreferenceoptimization,
      title={ORPO: Monolithic Preference Optimization without Reference Model}, 
      author={Jiwoo Hong and Noah Lee and James Thorne},
      year={2024},
      eprint={2403.07691},
      archivePrefix={arXiv},
      primaryClass={cs.CL},
      url={https://arxiv.org/abs/2403.07691}, 
}

@misc{hu2021loralowrankadaptationlarge,
      title={LoRA: Low-Rank Adaptation of Large Language Models}, 
      author={Edward J. Hu and Yelong Shen and Phillip Wallis and Zeyuan Allen-Zhu and Yuanzhi Li and Shean Wang and Lu Wang and Weizhu Chen},
      year={2021},
      eprint={2106.09685},
      archivePrefix={arXiv},
      primaryClass={cs.CL},
      url={https://arxiv.org/abs/2106.09685}, 
}

@misc{hayou2024loraefficientlowrank,
      title={LoRA+: Efficient Low Rank Adaptation of Large Models}, 
      author={Soufiane Hayou and Nikhil Ghosh and Bin Yu},
      year={2024},
      eprint={2402.12354},
      archivePrefix={arXiv},
      primaryClass={cs.LG},
      url={https://arxiv.org/abs/2402.12354}, 
}

@misc{bai2023qwentechnicalreport,
      title={Qwen Technical Report}, 
      author={Jinze Bai and Shuai Bai and Yunfei Chu and Zeyu Cui and Kai Dang and Xiaodong Deng and Yang Fan and Wenbin Ge and Yu Han and Fei Huang and Binyuan Hui and Luo Ji and Mei Li and Junyang Lin and Runji Lin and Dayiheng Liu and Gao Liu and Chengqiang Lu and Keming Lu and Jianxin Ma and Rui Men and Xingzhang Ren and Xuancheng Ren and Chuanqi Tan and Sinan Tan and Jianhong Tu and Peng Wang and Shijie Wang and Wei Wang and Shengguang Wu and Benfeng Xu and Jin Xu and An Yang and Hao Yang and Jian Yang and Shusheng Yang and Yang Yao and Bowen Yu and Hongyi Yuan and Zheng Yuan and Jianwei Zhang and Xingxuan Zhang and Yichang Zhang and Zhenru Zhang and Chang Zhou and Jingren Zhou and Xiaohuan Zhou and Tianhang Zhu},
      year={2023},
      eprint={2309.16609},
      archivePrefix={arXiv},
      primaryClass={cs.CL},
      url={https://arxiv.org/abs/2309.16609}, 
}

@misc{yang2024qwen2technicalreport,
      title={Qwen2 Technical Report}, 
      author={An Yang and Baosong Yang and Binyuan Hui and Bo Zheng and Bowen Yu and Chang Zhou and Chengpeng Li and Chengyuan Li and Dayiheng Liu and Fei Huang and Guanting Dong and Haoran Wei and Huan Lin and Jialong Tang and Jialin Wang and Jian Yang and Jianhong Tu and Jianwei Zhang and Jianxin Ma and Jin Xu and Jingren Zhou and Jinze Bai and Jinzheng He and Junyang Lin and Kai Dang and Keming Lu and Keqin Chen and Kexin Yang and Mei Li and Mingfeng Xue and Na Ni and Pei Zhang and Peng Wang and Ru Peng and Rui Men and Ruize Gao and Runji Lin and Shijie Wang and Shuai Bai and Sinan Tan and Tianhang Zhu and Tianhao Li and Tianyu Liu and Wenbin Ge and Xiaodong Deng and Xiaohuan Zhou and Xingzhang Ren and Xinyu Zhang and Xipin Wei and Xuancheng Ren and Yang Fan and Yang Yao and Yichang Zhang and Yu Wan and Yunfei Chu and Yuqiong Liu and Zeyu Cui and Zhenru Zhang and Zhihao Fan},
      year={2024},
      eprint={2407.10671},
      archivePrefix={arXiv},
      primaryClass={cs.CL},
      url={https://arxiv.org/abs/2407.10671}, 
}

@misc{zheng2024llamafactoryunifiedefficientfinetuning,
      title={LlamaFactory: Unified Efficient Fine-Tuning of 100+ Language Models}, 
      author={Yaowei Zheng and Richong Zhang and Junhao Zhang and Yanhan Ye and Zheyan Luo and Zhangchi Feng and Yongqiang Ma},
      year={2024},
      eprint={2403.13372},
      archivePrefix={arXiv},
      primaryClass={cs.CL},
      url={https://arxiv.org/abs/2403.13372}, 
}

@misc{touvron2023llamaopenefficientfoundation,
      title={LLaMA: Open and Efficient Foundation Language Models}, 
      author={Hugo Touvron and Thibaut Lavril and Gautier Izacard and Xavier Martinet and Marie-Anne Lachaux and Timothée Lacroix and Baptiste Rozière and Naman Goyal and Eric Hambro and Faisal Azhar and Aurelien Rodriguez and Armand Joulin and Edouard Grave and Guillaume Lample},
      year={2023},
      eprint={2302.13971},
      archivePrefix={arXiv},
      primaryClass={cs.CL},
      url={https://arxiv.org/abs/2302.13971}, 
}

@misc{touvron2023llama2openfoundation,
      title={Llama 2: Open Foundation and Fine-Tuned Chat Models}, 
      author={Hugo Touvron and Louis Martin and Kevin Stone and Peter Albert and Amjad Almahairi and Yasmine Babaei and Nikolay Bashlykov and Soumya Batra and Prajjwal Bhargava and Shruti Bhosale and Dan Bikel and Lukas Blecher and Cristian Canton Ferrer and Moya Chen and Guillem Cucurull and David Esiobu and Jude Fernandes and Jeremy Fu and Wenyin Fu and Brian Fuller and Cynthia Gao and Vedanuj Goswami and Naman Goyal and Anthony Hartshorn and Saghar Hosseini and Rui Hou and Hakan Inan and Marcin Kardas and Viktor Kerkez and Madian Khabsa and Isabel Kloumann and Artem Korenev and Punit Singh Koura and Marie-Anne Lachaux and Thibaut Lavril and Jenya Lee and Diana Liskovich and Yinghai Lu and Yuning Mao and Xavier Martinet and Todor Mihaylov and Pushkar Mishra and Igor Molybog and Yixin Nie and Andrew Poulton and Jeremy Reizenstein and Rashi Rungta and Kalyan Saladi and Alan Schelten and Ruan Silva and Eric Michael Smith and Ranjan Subramanian and Xiaoqing Ellen Tan and Binh Tang and Ross Taylor and Adina Williams and Jian Xiang Kuan and Puxin Xu and Zheng Yan and Iliyan Zarov and Yuchen Zhang and Angela Fan and Melanie Kambadur and Sharan Narang and Aurelien Rodriguez and Robert Stojnic and Sergey Edunov and Thomas Scialom},
      year={2023},
      eprint={2307.09288},
      archivePrefix={arXiv},
      primaryClass={cs.CL},
      url={https://arxiv.org/abs/2307.09288}, 
}

@misc{mishra2022crosstaskgeneralizationnaturallanguage,
      title={Cross-Task Generalization via Natural Language Crowdsourcing Instructions}, 
      author={Swaroop Mishra and Daniel Khashabi and Chitta Baral and Hannaneh Hajishirzi},
      year={2022},
      eprint={2104.08773},
      archivePrefix={arXiv},
      primaryClass={cs.CL},
      url={https://arxiv.org/abs/2104.08773}, 
}

@misc{wei2022finetunedlanguagemodelszeroshot,
      title={Finetuned Language Models Are Zero-Shot Learners}, 
      author={Jason Wei and Maarten Bosma and Vincent Y. Zhao and Kelvin Guu and Adams Wei Yu and Brian Lester and Nan Du and Andrew M. Dai and Quoc V. Le},
      year={2022},
      eprint={2109.01652},
      archivePrefix={arXiv},
      primaryClass={cs.CL},
      url={https://arxiv.org/abs/2109.01652}, 
}

@misc{sanh2022multitaskpromptedtrainingenables,
      title={Multitask Prompted Training Enables Zero-Shot Task Generalization}, 
      author={Victor Sanh and Albert Webson and Colin Raffel and Stephen H. Bach and Lintang Sutawika and Zaid Alyafeai and Antoine Chaffin and Arnaud Stiegler and Teven Le Scao and Arun Raja and Manan Dey and M Saiful Bari and Canwen Xu and Urmish Thakker and Shanya Sharma Sharma and Eliza Szczechla and Taewoon Kim and Gunjan Chhablani and Nihal Nayak and Debajyoti Datta and Jonathan Chang and Mike Tian-Jian Jiang and Han Wang and Matteo Manica and Sheng Shen and Zheng Xin Yong and Harshit Pandey and Rachel Bawden and Thomas Wang and Trishala Neeraj and Jos Rozen and Abheesht Sharma and Andrea Santilli and Thibault Fevry and Jason Alan Fries and Ryan Teehan and Tali Bers and Stella Biderman and Leo Gao and Thomas Wolf and Alexander M. Rush},
      year={2022},
      eprint={2110.08207},
      archivePrefix={arXiv},
      primaryClass={cs.LG},
      url={https://arxiv.org/abs/2110.08207}, 
}

@misc{chung2022scalinginstructionfinetunedlanguagemodels,
      title={Scaling Instruction-Finetuned Language Models}, 
      author={Hyung Won Chung and Le Hou and Shayne Longpre and Barret Zoph and Yi Tay and William Fedus and Yunxuan Li and Xuezhi Wang and Mostafa Dehghani and Siddhartha Brahma and Albert Webson and Shixiang Shane Gu and Zhuyun Dai and Mirac Suzgun and Xinyun Chen and Aakanksha Chowdhery and Alex Castro-Ros and Marie Pellat and Kevin Robinson and Dasha Valter and Sharan Narang and Gaurav Mishra and Adams Yu and Vincent Zhao and Yanping Huang and Andrew Dai and Hongkun Yu and Slav Petrov and Ed H. Chi and Jeff Dean and Jacob Devlin and Adam Roberts and Denny Zhou and Quoc V. Le and Jason Wei},
      year={2022},
      eprint={2210.11416},
      archivePrefix={arXiv},
      primaryClass={cs.LG},
      url={https://arxiv.org/abs/2210.11416}, 
}

@misc{lample2016neuralarchitecturesnamedentity,
      title={Neural Architectures for Named Entity Recognition}, 
      author={Guillaume Lample and Miguel Ballesteros and Sandeep Subramanian and Kazuya Kawakami and Chris Dyer},
      year={2016},
      eprint={1603.01360},
      archivePrefix={arXiv},
      primaryClass={cs.CL},
      url={https://arxiv.org/abs/1603.01360}, 
}

@misc{chiu2016namedentityrecognitionbidirectional,
      title={Named Entity Recognition with Bidirectional LSTM-CNNs}, 
      author={Jason P. C. Chiu and Eric Nichols},
      year={2016},
      eprint={1511.08308},
      archivePrefix={arXiv},
      primaryClass={cs.CL},
      url={https://arxiv.org/abs/1511.08308}, 
}

@misc{du2022glmgenerallanguagemodel,
      title={GLM: General Language Model Pretraining with Autoregressive Blank Infilling}, 
      author={Zhengxiao Du and Yujie Qian and Xiao Liu and Ming Ding and Jiezhong Qiu and Zhilin Yang and Jie Tang},
      year={2022},
      eprint={2103.10360},
      archivePrefix={arXiv},
      primaryClass={cs.CL},
      url={https://arxiv.org/abs/2103.10360}, 
}

@misc{glm2024chatglmfamilylargelanguage,
      title={ChatGLM: A Family of Large Language Models from GLM-130B to GLM-4 All Tools}, 
      author={Team GLM and : and Aohan Zeng and Bin Xu and Bowen Wang and Chenhui Zhang and Da Yin and Dan Zhang and Diego Rojas and Guanyu Feng and Hanlin Zhao and Hanyu Lai and Hao Yu and Hongning Wang and Jiadai Sun and Jiajie Zhang and Jiale Cheng and Jiayi Gui and Jie Tang and Jing Zhang and Jingyu Sun and Juanzi Li and Lei Zhao and Lindong Wu and Lucen Zhong and Mingdao Liu and Minlie Huang and Peng Zhang and Qinkai Zheng and Rui Lu and Shuaiqi Duan and Shudan Zhang and Shulin Cao and Shuxun Yang and Weng Lam Tam and Wenyi Zhao and Xiao Liu and Xiao Xia and Xiaohan Zhang and Xiaotao Gu and Xin Lv and Xinghan Liu and Xinyi Liu and Xinyue Yang and Xixuan Song and Xunkai Zhang and Yifan An and Yifan Xu and Yilin Niu and Yuantao Yang and Yueyan Li and Yushi Bai and Yuxiao Dong and Zehan Qi and Zhaoyu Wang and Zhen Yang and Zhengxiao Du and Zhenyu Hou and Zihan Wang},
      year={2024},
      eprint={2406.12793},
      archivePrefix={arXiv},
      primaryClass={cs.CL},
      url={https://arxiv.org/abs/2406.12793}, 
}

@misc{hou2024chatglmrlhfpracticesaligninglarge,
      title={ChatGLM-RLHF: Practices of Aligning Large Language Models with Human Feedback}, 
      author={Zhenyu Hou and Yilin Niu and Zhengxiao Du and Xiaohan Zhang and Xiao Liu and Aohan Zeng and Qinkai Zheng and Minlie Huang and Hongning Wang and Jie Tang and Yuxiao Dong},
      year={2024},
      eprint={2404.00934},
      archivePrefix={arXiv},
      primaryClass={cs.CL},
      url={https://arxiv.org/abs/2404.00934}, 
}

@misc{xu2024dposuperiorppollm,
      title={Is DPO Superior to PPO for LLM Alignment? A Comprehensive Study}, 
      author={Shusheng Xu and Wei Fu and Jiaxuan Gao and Wenjie Ye and Weilin Liu and Zhiyu Mei and Guangju Wang and Chao Yu and Yi Wu},
      year={2024},
      eprint={2404.10719},
      archivePrefix={arXiv},
      primaryClass={cs.CL},
      url={https://arxiv.org/abs/2404.10719}, 
}

@misc{hendrycks2021measuringcodingchallengecompetence,
      title={Measuring Coding Challenge Competence With APPS}, 
      author={Dan Hendrycks and Steven Basart and Saurav Kadavath and Mantas Mazeika and Akul Arora and Ethan Guo and Collin Burns and Samir Puranik and Horace He and Dawn Song and Jacob Steinhardt},
      year={2021},
      eprint={2105.09938},
      archivePrefix={arXiv},
      primaryClass={cs.SE},
      url={https://arxiv.org/abs/2105.09938}, 
}

@misc{lewis2019bartdenoisingsequencetosequencepretraining,
      title={BART: Denoising Sequence-to-Sequence Pre-training for Natural Language Generation, Translation, and Comprehension}, 
      author={Mike Lewis and Yinhan Liu and Naman Goyal and Marjan Ghazvininejad and Abdelrahman Mohamed and Omer Levy and Ves Stoyanov and Luke Zettlemoyer},
      year={2019},
      eprint={1910.13461},
      archivePrefix={arXiv},
      primaryClass={cs.CL},
      url={https://arxiv.org/abs/1910.13461}, 
}
