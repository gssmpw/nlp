\section{Limitations and Discussion}
Although LM graders can outperform humans on many tasks, they still exhibit unreliability and biases. For instance, as shown in Table \ref{tab:debias} and the findings of \citet{PanicksseryUnknown-wr}, LM graders tend to favor their own generations. Additionally, due to the inherent biases in human-annotated data, LM graders may raise concerns about fairness. Moreover, the reliability of automatic metrics in general must be questioned \citep{Doostmohammadi2024-ci,Boubdir2023-ek}. For these reasons, we caution against the uncritical replacement of human judgment with LM graders. Instead, there should be a concerted focus on refining and improving their performance and reliability. In this paper, we study the use of \PI to improve the reliability of evaluation.

\section{Conclusion}\label{sec:conclusion}
In conclusion, our research emphasizes the importance of PI in enhancing automated evaluations, particularly for challenging \NS problems.
By incorporating PI, we have demonstrated significant improvements in the performance of automatic graders across various benchmarks, including \RewardBench, \VibeEval, and \MathOdyssey.
Furthermore, our analysis reveals that hints derived from PI can effectively differentiate model capabilities and uncover trends related to problem difficulty.
We believe that this methodology offers a promising avenue for developing reliable automated evaluations that push the boundaries of our most advanced models.
