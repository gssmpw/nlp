\section{Privileged Information for Evaluation}\label{sec:method}

\input{figures/schema}

This section introduces privileged information and shows how we use it with automatic graders to evaluate language models.

% \paragraph{Evaluation setting.}
The typical automatic evaluation setting has two types of language models interacting.
The first are the \emph{candidate} models.
The candidate models are given a prompt, such as the equation \prompt{$\int_x \ln(x) \, dx = ?$} or \prompt{What is the wifi password?}.
Their task is to respond as effectively as they can by carefully trading conflicting criteria such as conciseness, clarity, and completeness.
The second are \emph{grader} models, which see the prompt and assign a grade to each model's response.
In our experiments, we mostly consider the pairwise setting where two candidate models answer the same prompt, and the grader assigns a single grade to both predictions: response A is preferred, response B is preferred, or tie.
This process is illustrated in the left part of \cref{fig:schema}.

% \paragraph{Privileged information.}
Our main proposal is to augment the inputs of the grader with privileged information.
Here privileged information refers to information that eases the job of grader; it is ``privileged'' insofar as it is only available to the grader and not the candidates.
Privileged information can take many forms; for example, in \cref{fig:schema} it is pictured as the right box and provides ground-truth solution to the integral together with the integration by parts explanation for how to obtain it.
Here are a few more examples of privileged information.
%
\begin{itemize}
    \item \textbf{Ground-truth solutions} (or gold-reference responses) help to grade close-ended prompts with a strong correctness component.
    These include prompts focused on factuality (\response{Barack Obama's wife is Michelle Obama.}), information-seeking (\response{Beat eggs, cook, add fillings, fold.}), or translation (\response{¡Ser, o no ser, es la cuestión!}).
    With ground-truths the grader doesn't need to solve the problem in the prompt and can simply assess which of the candidate responses is closest to the solution.

    \item \textbf{Rating guidelines} are more generic than ground-truth solutions and can also help evaluate open-ended prompts.
    An example guideline could be \response{Ensure the response mentions adding a splash of cold water before cooking the eggs into an omelette.} or \response{Prefer responses with specific details about Weaver's contributions to the Civil Rights Movement, beyond just his cabinet position.}.
    Rating guidelines are related to the ``principles'' of Consitutional AI~\citep{Bai2022-uh} and similarly help align LM graders to human preferences.
    But they differ in two ways: they should be made as prompt-specific as possible and they need not be binary questions.

    \item \textbf{Prior ratings}, when available, can be used as few-shot examples to calibrate LLM graders against human ratings.
    Preferrably the ratings are also prompt-specific and include a rationale component for why one response was preferred over another.
    For example they could be the ratings when comparing the responses of models $C$, $D$, and $E$ on the same prompts as used to compare models $A$ and $B$.
    Beyond few-shot examples, prior ratings are especially useful as they can be synthesized into other types of privileged information, as show cased in our experiment section.

    \item \textbf{Search results} can be cached and help provide context around a prompt.
    For example, we could include Martin Luther King Jr. to help grade the prompt \prompt{Explain the circumstances around MLK's death.}.
    Search results can be automatically compiled and thus are easy to collect.
    This makes them amenable to regular refreshes, which is especially practical for factuality or information-seeking prompts whose answers can changes over time (\eg, \prompt{What happened in the last SNL episode?}).

    \item \textbf{Multimodal annotations} help bridge the cross-modality gap in multimodal LMs.
    Example of cross-modal privileged information include detailed image captions for captioning tasks, audio transcripts for audio-based dialog question-answering, or target sub-clips for long-video understanding prompts.
    In \cref{sec:experiments} we show the effectiveness of multimodal annotations, where our automatic graders outperform individual graders on the challenging \VibeEval benchmark.
\end{itemize}
%
Appendix \ref{app:reward_vibe_templates} provides more examples, including some real-world templates.
As shown, privileged information applies to a wide range of domains and we surmise more domains will require new types of privileged information.
In this paper we zero in on how privileged information can improve automatic evaluations on challenging prompts that require expert-level knowledge, understanding, and reasoning such as those found in \NS benchmarks.

\subsection{The How's and Why's of Privileged Information}
\label{sec:method-grader}

We now briefly discuss how to source and use privileged information, before presenting our empirical results in~\cref{sec:experiments}.

% \paragraph{How to source privileged information?}
We explore two approaches to collect privileged information.
First, humans can manually handcraft privileged information for each prompt if the prompt set is small enough.
This is particularly useful when the grading function is unintuitive to the LM while also easily specified by text.
One such example are the adversarial prompts in the \emph{Chat Hard} and \emph{Reasoning} splits of \RewardBench --- more in~\cref{sec:experiments}.

If human annotations are too labor-intensive, we can resort to automatically synthesized privileged information.
For example, in \cref{fig:reka_vibe_eval} we aggregate all human ratings for each \VibeEval~prompt and ask an LM to synthesize rating guidelines out of them.
Both approaches can also be combined.
In \VibeEval~we first generate image descriptions by asking an LM to describe the image in details, and manually edit them for accuracy.

Once we have generated privileged information, the easiest way to use it is by providing it in the prompt of the grader.
We include several example templates in Figure \ref{fig:reward_bench_chat_template}, \ref{fig:reward_bench_safety_template} and \ref{fig:vibe_eval_template} as examples.
In most of them we simply add a markdown section to the prompt, \eg \texttt{\#\# Rating Guidelines} followed by the rating guidelines.

\subsection{Privileged Information for Frontier Problems}
\label{sec:method-hints}

For \NS problems, we introduce a second approach to leverage privileged information.
On these challenging tasks LMs fail to solve most prompts making the aggregated evaluation metrics largely dictated by noise.
We propose to extract problem hints out of the grader's privileged information with an LM.
Hints are then provided to the candidates at evaluation-time, hopefully simplifying the problem enough that it can be solved.
Adding more hints simplifies the problem further, and lets us construct difficulty tiers by including more or less hints.
Figure \ref{fig:example_hint_generation} in Appendix showcases templates to extract hints from the grader's privileged information.

Generating hints from privileged information yields several benefits.
First, it enables tracking progress directly on the \NS problems of interest rather than proxies to the \NS problems.
Second, as showcased in \cref{sec:experiments}, it naturally lets us analyze competing models on different difficulty tiers.
Finally, it significantly cheapens the data collection effort since the same prompts and ground-truth solutions can be reused to. 
This is particularly valuable for \NS problems where expensive experts need to come up with prompts and ground-truth solutions.
