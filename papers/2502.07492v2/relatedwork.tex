\section{Related Work}
\label{sec2}

\textbf{Malware Group Attribution. } Automatic attribution of APT malware groups has been widely studied using dynamic and static approaches \cite{ref2}. Dynamic methods analyze run-time behaviors, such as function calls \cite{ref9} and network operations \cite{ref8}, but are often time-consuming and ineffective against evasion techniques like virtual machine escape. In contrast, static methods directly analyzing malware code, overcoming these limitations. Traditional static approaches rely on feature extraction, including statistical features \cite{ref15} and program graph features \cite{ref17}, and use classifiers like Random Forest \cite{ref15}, LSTM \cite{ref17} and PerceiverIO \cite{ref61}, though they require substantial manual effort for feature engineering. Other approaches automate feature extraction by processing disassembly opcode n-grams, requiring disassembly and n-gram segmentation, and use models like LSTM for classification \cite{ref18}. Raw-byte-based malware attribution simplifies the process further by bypassing feature extraction and directly capturing subtle details through end-to-end CNN models \cite{ref24,ref58}. The SOTA byte-level malware classifier, MalConv with GCG (Global Channel Gating), uses a 1D-CNN to process raw byte sequences, achieving high accuracy with innovative network designs \cite{ref24}. Despite their effectiveness, these methods remain vulnerable to adversarial attacks, which this study seeks to address.

%Deep learning-based methods avoid manual feature extraction by directly analyzing raw byte sequences or disassembly opcode n-grams \cite{ref18} in an end-to-end manner. Models such as CNN \cite{ref58} and LSTM \cite{ref18} improve classification accuracy by learning representations from raw data. 

% Identifying the groups behind Advanced Persistent Threat (APT) malware is key to comprehending the motivations and tactics of these actors \cite{ref1}. Traditional manual attribution was reliant on the in-depth expertise of cybersecurity professionals, making it a technically demanding and time-consuming endeavor \cite{ref2}. In recent years, automatic group attribution techniques that employ machine learning-based malware analysis have garnered significant research interest. These techniques are generally divided into dynamic and static analyses. Dynamic techniques focus on tracking malware runtime behaviors like process activities and network operations \cite{ref7,ref8} and function invocation sequences \cite{ref9,ref10,ref11,ref12}. Yet, they require a virtual environment and are inefficient against certain malware evasions. Static methods bypass these issues by analyzing malware code without execution. In this research, we focus on static methods. 

% Early static attribution works harness static malware file features, such as PE-headers and import tables, and leverage conventional Random Forest (RF) models for classification \cite{ref13,ref14}. Subsequent works delve into various static features and more machine learning models. Laurenza et al. extract such statistical features as section table count and resource count, and create an RF classifier \cite{ref15}. Wei et al. extract API system calls as malware features, and adopt LSTM with attention mechanisms for feature vectorization \cite{ref16}. Taking a distinct approach, Liu et al. focus on attributing particular malware functions to APT groups. They extract sequences from the disassembled code, vectorize the control flow graph, and utilize LSTM to generate function embedding \cite{ref17}. Recently, Song et al. have extracted the disassembly codes from APT malware and employed an LSTM encoder to analyze n-gram opcode sequences for group attribution \cite{ref18}.

% While the existing machine learning-driven malware attributions are promising, they come with inherent limitations. Firstly, their dependence on feature engineering necessitates constant manual adjustments, risking the omission of subtle yet vital features and introducing biases. Secondly, these techniques often overlook evasion tactics, notably the deployment of `false flags' by malicious actors, which compromises attribution robustness. Thirdly, there's a potential for enhanced accuracy in these models, especially considering the attribution challenges posed by shared tools among APT groups. In contrast, our research introduces a specialized end-to-end attribution model for raw-byte APT malware. Designed for adversarial robustness and accuracy, our approach bypasses the complexities of feature engineering.
% \subsection{Raw-binary Malware Detection}\label{sec:end2end}
% Malware detection serves as a binary classification task, distinguishing between benign and malicious software. Employing raw-binary detectors allows for direct raw data processing, bypassing traditional manual feature engineering. This approach is simpler, adaptable, and can discern intricate patterns often overlooked in traditional methods. In recent years, raw-binary malware detection methods have grown popular \cite{ref19,ref20}. It deals with the code data as it is, catching little details that other methods might miss (such as code images, or opcode sequences). 

% Early attempts at classifying malware through raw bytes focus on the Normalized Compression Distance (NCD) method \cite{ref21}, but it had its drawbacks, especially in supervised settings \cite{ref22,ref23}. A significant shift in this domain is the introduction of the MalConv model, a pioneering method that utilizes the 1D-CNN to directly process raw byte sequences, showcasing unique neural network designs for better results \cite{ref24}. Notably, studies by firms like Avast revealed that MalConv could match, and sometimes even surpass, the effectiveness of hand-crafted detection features \cite{ref25}. However, due to memory constraints, MalConv is restricted to a maximum file size of 2MB, which could compromise its performance and expose it to threats in adversarial settings. Raff et al. propose the fixed-memory convolution, which harnesses the sparsity of temporal max pooling to decouple memory usage from time series length, optimizing memory efficiency and training speed \cite{ref26}. They introduce a global channel gating (GCG) design equipped with an attention mechanism, enabling the capture of feature interactions over prolonged periods, surpassing 100 million time steps \cite{ref26}. Malconv with GCG not only addresses memory constraints faced by earlier techniques but also boosts the malware detection model's accuracy by up to 2\%. 

% In this study, we address malware attribution as a multi-classification problem. Drawing inspiration from the malware detection model, MalConv with GCG, we aim to construct an raw-binary multi-class attribution model.

\vspace{0.1cm}
\noindent\textbf{Adversarially Robust Malware Classification. } 
The adversarial nature between malware attacks and defenses makes malware classification models particularly vulnerable to adversarial attacks. For instance, byte-level classifiers like MalConv exhibit significant performance degradation under adversarial perturbations \cite{ref28}. To enhance robustness, recent studies have employed adversarial training techniques, generating adversarial examples using gradient-based methods that optimize functionality-preserving transformations, such as byte-level perturbations \cite{ref27} or assembly-level instruction modifications \cite{ref62}. FGSM (Fast Gradient Sign Method) offers a fast, single-step adversarial training approach. In the malware domain, Slack-FGSM and Append-FGSM apply adversarial bytes to slack space or the end of PE files \cite{ref31,ref29}, while extensions apply adversarial bytes to additional regions, such as the full DOS header or shifted sections \cite{ref27,ref28}. However, single-step FGSM methods are vulnerable to multi-step attacks. To mitigate this, multi-step adversarial training methods like PGD (Projected Gradient Descent) \cite{ref55} are employed in malware classification, although they incur considerable training overhead \cite{ref56}. Recently, Lucas et al. applied low-effort PGD attacks during adversarial training to improve the robustness of raw-byte malware detectors against high-effort PGD attacks, leveraging existing perturbation techniques without introducing new adversarial training approaches \cite{ref56}. Advanced FGSM methods from the image domain, such as NuAT (using a Nuclear-Norm regularizer) and FGSM-RS (with perturbation initialization), remain underexplored in malware classification. Our experiments adapting these image-based methods to malware classification reveal that both robustness and training efficiency still require substantial improvement.

%% [Demetrio et al., 2021]. 



%PGD:
% A. Madry, A. Makelov, L. Schmidt, D. Tsipras, and A. Vladu. Towards deep learning models resistant to adversarial attacks. In Proc. ICLR, 2018.

% Recently, Keane Lucas et al. apply low-effort PGD attacks during adversarial training to improve the robustness of raw-byte malware detector against high-effort PGD attacks \cite{ref56}. They utilize existing perturbation techniques (including byte-level appending and assembly-level instruction modifications) and gradient methods without proposing new adversarial training approaches. By contrast, our work proposes a novel adversarial training approach, aiming to utilize fast adversarial training to defend advanced attacks at byte-level, including multi-step PGD attacks and optimization-based C\&W attacks. 


%generating adversarial examples based on gradient or evolutionary algorithms
%The adversarial nature of malware attacks and defenses makes malware classification models particularly vulnerable to adversarial attacks. For instance, byte-level classifiers like MalConv experience significant performance drops under adversarial perturbations [Demetrio et al., 2021]. Recent studies have introduced adversarial training techniques to enhance robustness, generating adversarial examples via methods like FGSM, which iteratively optimize functionality-preserving transformations, such as byte-level perturbations or assembly-level instruction changes \cite{ref35}. Slack-FGSM and Append-FGSM are representative FGSM-based methods that apply adversarial bytes to slack space or the end of PE malware files \cite{ref31}. Extensions include adversarial bytes applied to broader regions, such as the full DOS header or shifted sections \cite{ref27, ref29}. However, single-step FGSM-based methods are prone to multi-step attacks. Multi-step training methods like PGD-AT \cite{ref52}, developed for image domains, mitigate this issue but at a high computational cost. Advanced FGSM methods from the image domain, such as NuAT (using a Nuclear-Norm regularizer) and FGSM-RS (with perturbation initialization), remain underexplored in malware classification. Our experiments adapting these image-based methods to malware classification reveal that both robustness and training efficiency still require significant improvement.


% \subsection{Evasion Attack on Malware Detection}
% To evade Malware Detection, adversaries launch adversarial attacks, also known as evasion attacks, against machine-learning-based Malware Detectors. Depending on the adversary’s knowledge of the target malware detectors, current Evasion Attack efforts against malware detection are categorized into white-box attacks and black-box attacks \cite{ref27,ref28}. White-box attacks occur when the adversary has comprehensive knowledge of the target models, including architectures, parameters, features, and the training dataset. In contrast, black-box attacks involve scenarios where the attacker, apart from accessing the model’s outputs, lacks knowledge about other aspects of the model. The white-box attacks might target byte-based malware detectors, API-based detectors, visualization-based detectors, and so on \cite{ref27}. This study focuses on white-box attacks against byte-based PE malware detectors like MalConv.
% The majority of current white-box attacks on MalConv employ byte-level manipulations that maintain the original functionality, and iteratively update the values of bytes based on the gradient descent \cite{ref28}. For example, Kolosnjaji et al. \cite{ref29} present a gradient-driven approach to create adversarial bytes and append these bytes to the padding space at the end of a PE malware file. They use gradient descent to optimize the attack in the embedding space, and invert the embedding lookup to reconstruct the adversarial bytes. Using the same optimization and reconstruction methods as Kolosnjaji et al., Demetrio et al. \cite{ref30} propose to modify the first 58 bytes of the DOS header, named Partial DOS manipulation.  Kreuk et al. \cite{ref31} append adversarial bytes to the padding space or the slack space (i.e., inter-section gaps) in the malware file, using FGSM for crafting an embedding vector and then aligning it to the nearest input space bytes to generate adversarial malware. In a related study, Suciu et al. \cite{ref32} analyze append-FGSM and slack-FGSM, finding that slack-FGSM achieves better results with less byte alteration. Chen et al. \cite{ref33} choose highly significant data blocks from benign PE files, identified through saliency vectors created by the Grad-CAM method \cite{ref34}, and add these blocks to the end of a malware file. Demetrio et al. \cite{ref27} introduce three innovative manipulations for PE files: modifying the entire DOS header with Full DOS manipulation; generating extra space by expanding the DOS header's offset in Extend manipulation; and creating room for adversarial noise by shifting the initial section's contents in Shift manipulation. Other white-box attacks employ functionality-preserving manipulations at the assembly instruction level \cite{ref27}. For instance, Sharif et al. \cite{ref35} use the Carlini \& Wagner loss \cite{ref36} to generate adversarial samples, implementing these equivalent instruction transformations across all functions of a malware file and preserving those that yield a feature vector aligned with the gradient. 
% Drawing from earlier research on functionality-preserving byte-level manipulations over PE executables \cite{ref28}, \cite{ref29}, \cite{ref31}, our white-box attack technique involves the insertion of adversarial bytes into various regions within a malware file.