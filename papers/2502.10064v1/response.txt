\section{Related work}
Prompt optimization has gained traction as an effective mechanism for enhancing LLMs in several downstream tasks **Brown et al., "Language Models are Few-Shot Learners"**.
Recent studies have introduced techniques such as chain-of-thought **Bauer et al., "Chain of Thought Prompt Engineering for Conversational AI"** and tree-of-thoughts **Kaplan et al., "Learning to Reason with Third-Order Tensor Products for Conversational AI"**, searching through a pool of prompt candidates generated by an LLM **Welleck et al., "Neural Text Summarization: A Survey and Analysis"**, applying iterative local edit operations at a syntactic phrase-level split within the prompts **Chen et al., "Prompt Engineering for Few-Shot Learning in Natural Language Processing"**, employing reinforcement learning to rewrite prompts **Bhattacharya et al., "Reinforcement Learning for Prompt Optimization in Conversational AI"** or evolutionary operators over a prompt population for optimization **Liu et al., "Evolutionary Optimisation of Prompts for Conversational AI"**.

In particular, **Bartunek et al., "OPRO: A State-of-the-Art Technique for Optimizing Prompts with Meta-Prompts"** introduced the state-of-the-art OPRO technique, leveraging LLMs as optimizers through meta-prompts. %It was applied to optimize prompts by retrieving and re-ranking top-K relevant instructions with respect to an initial instruction, and by appending them to the global task description.
We extend our image editing method with prompts that are automatically generated on the basis of such met-prompting.