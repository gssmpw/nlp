\section{Related work}
Prompt optimization has gained traction as an effective mechanism for enhancing LLMs in several downstream tasks \cite{lester2021power,srivastava2023beyond}.
Recent studies have introduced techniques such as chain-of-thought \cite{wei2022chain} and tree-of-thoughts \cite{yao2024tree}, searching through a pool of prompt candidates generated by an LLM \cite{zhou2022large}, applying iterative local edit operations at a syntactic phrase-level split within the prompts \cite{prasad2023grips}, employing reinforcement learning to rewrite prompts \cite{kong2024prewrite} or evolutionary operators over a prompt population for optimization \cite{guo2023connecting}.

In particular, \citet{yang2023large} introduced the state-of-the-art OPRO technique, leveraging LLMs as optimizers through meta-prompts. %It was applied to optimize prompts by retrieving and re-ranking top-K relevant instructions with respect to an initial instruction, and by appending them to the global task description.
We extend our image editing method with prompts that are automatically generated on the basis of such met-prompting.