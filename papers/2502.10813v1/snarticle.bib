%% Journal article
@inproceedings{mandia2022vision,
  title={Vision Transformer for Automatic Student Engagement Estimation},
  author={Mandia, Sandeep and Singh, Kuldeep and Mitharwal, Rajendra},
  booktitle={2022 IEEE 5th International Conference on Image Processing Applications and Systems (IPAS)},
  pages={1--6},
  year={2022},
  organization={IEEE}
}
@article{mahmood2021instructional,
  title={Instructional strategies for online teaching in COVID-19 pandemic},
  author={Mahmood, Samreen},
  journal={Human behavior and emerging technologies},
  volume={3},
  number={1},
  pages={199--203},
  year={2021},
  publisher={Wiley Online Library}
}

@article{dias2020deeplms,
  title={DeepLMS: a deep learning predictive model for supporting online learning in the Covid-19 era},
  author={Dias, Sofia B and Hadjileontiadou, Sofia J and Diniz, Jos{\'e} and Hadjileontiadis, Leontios J},
  journal={Scientific reports},
  volume={10},
  number={1},
  pages={1--17},
  year={2020},
  publisher={Nature Publishing Group}
}

@article{dhawan2020online,
  title={Online learning: A panacea in the time of COVID-19 crisis},
  author={Dhawan, Shivangi},
  journal={Journal of educational technology systems},
  volume={49},
  number={1},
  pages={5--22},
  year={2020},
  publisher={Sage Publications Sage CA: Los Angeles, CA}
}
@article{adnan2020online,
  title={Online Learning amid the COVID-19 Pandemic: Students' Perspectives.},
  author={Adnan, Muhammad and Anwar, Kainat},
  journal={Online Submission},
  volume={2},
  number={1},
  pages={45--51},
  year={2020},
  publisher={ERIC}
}

@article{dewan2019engagement,
  title={Engagement detection in online learning: a review},
  author={Dewan, M and Murshed, Mahbub and Lin, Fuhua},
  journal={Smart Learning Environments},
  volume={6},
  number={1},
  pages={1--20},
  year={2019},
  publisher={Springer}
}

@article{fredricks2004school,
  title={School engagement: Potential of the concept, state of the evidence},
  author={Fredricks, Jennifer A and Blumenfeld, Phyllis C and Paris, Alison H},
  journal={Review of educational research},
  volume={74},
  number={1},
  pages={59--109},
  year={2004},
  publisher={Sage Publications Sage CA: Thousand Oaks, CA}
}

@article{jung2018learning,
  title={Learning engagement and persistence in massive open online courses (MOOCS)},
  author={Jung, Yeonji and Lee, Jeongmin},
  journal={Computers \& Education},
  volume={122},
  pages={9--22},
  year={2018},
  publisher={Elsevier}
}

@article{saurav2021emnet,
  title={EmNet: a deep integrated convolutional neural network for facial emotion recognition in the wild},
  author={Saurav, Sumeet and Saini, Ravi and Singh, Sanjay},
  journal={Applied Intelligence},
  volume={51},
  number={8},
  pages={5543--5570},
  year={2021},
  publisher={Springer}
}

@article{calvo2010affect,
  title={Affect detection: An interdisciplinary review of models, methods, and their applications},
  author={Calvo, Rafael A and D'Mello, Sidney},
  journal={IEEE Transactions on affective computing},
  volume={1},
  number={1},
  pages={18--37},
  year={2010},
  publisher={IEEE}
}

@inproceedings{grafsgaard2013automatically,
  title={Automatically recognizing facial expression: Predicting engagement and frustration},
  author={Grafsgaard, Joseph and Wiggins, Joseph B and Boyer, Kristy Elizabeth and Wiebe, Eric N and Lester, James},
  booktitle={Educational data mining 2013},
  year={2013}
}

@article{whitehill2014faces,
  title={The faces of engagement: Automatic recognition of student engagementfrom facial expressions},
  author={Whitehill, Jacob and Serpell, Zewelanji and Lin, Yi-Ching and Foster, Aysha and Movellan, Javier R},
  journal={IEEE Transactions on Affective Computing},
  volume={5},
  number={1},
  pages={86--98},
  year={2014},
  publisher={IEEE}
}

@article{liao2021deep,
  title={Deep facial spatiotemporal network for engagement prediction in online learning},
  author={Liao, Jiacheng and Liang, Yan and Pan, Jiahui},
  journal={Applied Intelligence},
  volume={51},
  number={10},
  pages={6609--6621},
  year={2021},
  publisher={Springer}
}

@article{gupta2016daisee,
  title={Daisee: Towards user engagement recognition in the wild},
  author={Gupta, Abhay and D'Cunha, Arjun and Awasthi, Kamal and Balasubramanian, Vineeth},
  journal={arXiv preprint arXiv:1609.01885},
  year={2016}
}
@article{mehta2022three,
  title={Three-dimensional DenseNet self-attention neural network for automatic detection of student’s engagement},
  author={Mehta, Naval Kishore and Prasad, Shyam Sunder and Saurav, Sumeet and Saini, Ravi and Singh, Sanjay},
  journal={Applied Intelligence},
  pages={1--21},
  year={2022},
  publisher={Springer}
}

@inproceedings{huang2019fine,
  title={Fine-grained engagement recognition in online learning environment},
  author={Huang, Tao and Mei, Yunshan and Zhang, Hao and Liu, Sanya and Yang, Huali},
  booktitle={2019 IEEE 9th international conference on electronics information and emergency communication (ICEIEC)},
  pages={338--341},
  year={2019},
  organization={IEEE}
}

@inproceedings{abedi2021improving,
  title={Improving state-of-the-art in Detecting Student Engagement with Resnet and TCN Hybrid Network},
  author={Abedi, Ali and Khan, Shehroz S},
  booktitle={2021 18th Conference on Robots and Vision (CRV)},
  pages={151--157},
  year={2021},
  organization={IEEE}
}

@article{dosovitskiy2020image,
  title={An image is worth 16x16 words: Transformers for image recognition at scale},
  author={Dosovitskiy, Alexey and Beyer, Lucas and Kolesnikov, Alexander and Weissenborn, Dirk and Zhai, Xiaohua and Unterthiner, Thomas and Dehghani, Mostafa and Minderer, Matthias and Heigold, Georg and Gelly, Sylvain and others},
  journal={arXiv preprint arXiv:2010.11929},
  year={2020}
}

@inproceedings{arnab2021vivit,
  title={Vivit: A video vision transformer},
  author={Arnab, Anurag and Dehghani, Mostafa and Heigold, Georg and Sun, Chen and Lu{\v{c}}i{\'c}, Mario and Schmid, Cordelia},
  booktitle={Proceedings of the IEEE/CVF International Conference on Computer Vision},
  pages={6836--6846},
  year={2021}
}

@inproceedings{yan2022multiview,
  title={Multiview transformers for video recognition},
  author={Yan, Shen and Xiong, Xuehan and Arnab, Anurag and Lu, Zhichao and Zhang, Mi and Sun, Chen and Schmid, Cordelia},
  booktitle={Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition},
  pages={3333--3343},
  year={2022}
}

@article{devlin2018bert,
  title={Bert: Pre-training of deep bidirectional transformers for language understanding},
  author={Devlin, Jacob and Chang, Ming-Wei and Lee, Kenton and Toutanova, Kristina},
  journal={arXiv preprint arXiv:1810.04805},
  year={2018}
}

@article{d2006predicting,
  title={Predicting affective states expressed through an emote-aloud procedure from AutoTutor's mixed-initiative dialogue},
  author={D'Mello, Sidney K and Craig, Scotty D and Sullins, Jeremiah and Graesser, Arthur C},
  journal={International Journal of Artificial Intelligence in Education},
  volume={16},
  number={1},
  pages={3--28},
  year={2006},
  publisher={IOS Press}
}

@article{o2010development,
  title={The development and evaluation of a survey to measure user engagement},
  author={O'Brien, Heather L and Toms, Elaine G},
  journal={Journal of the American Society for Information Science and Technology},
  volume={61},
  number={1},
  pages={50--69},
  year={2010},
  publisher={Wiley Online Library}
}

@ARTICLE{5518758,
  author={Cocea, Mihaela and Weibelzahl, Stephan},
  journal={IEEE Transactions on Learning Technologies}, 
  title={Disengagement Detection in Online Learning: Validation Studies and Perspectives}, 
  year={2011},
  volume={4},
  number={2},
  pages={114-124},
  doi={10.1109/TLT.2010.14}}
  
  @article{aluja2019measuring,
  title={Measuring motivation from the virtual learning environment in secondary education},
  author={Aluja-Banet, Tom{\`a}s and Sancho, Maria-Ribera and Vukic, Ivan},
  journal={Journal of Computational Science},
  volume={36},
  pages={100629},
  year={2019},
  publisher={Elsevier}
}

@article{monkaresi2016automated,
  title={Automated detection of engagement using video-based estimation of facial expressions and heart rate},
  author={Monkaresi, Hamed and Bosch, Nigel and Calvo, Rafael A and D'Mello, Sidney K},
  journal={IEEE Transactions on Affective Computing},
  volume={8},
  number={1},
  pages={15--28},
  year={2016},
  publisher={IEEE}
}

@article{fairclough2006prediction,
  title={Prediction of subjective states from psychophysiology: A multivariate approach},
  author={Fairclough, Stephen H and Venables, Louise},
  journal={Biological psychology},
  volume={71},
  number={1},
  pages={100--110},
  year={2006},
  publisher={Elsevier}
}

@article{khedher2019tracking,
  title={Tracking students’ mental engagement using EEG signals during an interaction with a virtual learning environment},
  author={Khedher, Asma Ben and Jraidi, Im{\`e}ne and Frasson, Claude and others},
  journal={Journal of Intelligent Learning Systems and Applications},
  volume={11},
  number={01},
  pages={1},
  year={2019},
  publisher={Scientific Research Publishing}
}

@INPROCEEDINGS{6681424,
  author={Grafsgaard, Joseph F. and Wiggins, Joseph B. and Boyer, Kristy Elizabeth and Wiebe, Eric N. and Lester, James C.},
  booktitle={2013 Humaine Association Conference on Affective Computing and Intelligent Interaction}, 
  title={Automatically Recognizing Facial Indicators of Frustration: A Learning-centric Analysis}, 
  year={2013},
  volume={},
  number={},
  pages={159-165},
  doi={10.1109/ACII.2013.33}}
  
  @inproceedings{bosch2015automatic,
  title={Automatic detection of learning-centered affective states in the wild},
  author={Bosch, Nigel and D'Mello, Sidney and Baker, Ryan and Ocumpaugh, Jaclyn and Shute, Valerie and Ventura, Matthew and Wang, Lubin and Zhao, Weinan},
  booktitle={Proceedings of the 20th international conference on intelligent user interfaces},
  pages={379--388},
  year={2015}
}

@article{saneiro2014towards,
  title={Towards emotion detection in educational scenarios from facial expressions and body movements through multimodal approaches},
  author={Saneiro, Mar and Santos, Olga C and Salmeron-Majadas, Sergio and Boticario, Jesus G},
  journal={The Scientific World Journal},
  volume={2014},
  year={2014},
  publisher={Hindawi}
}

@inproceedings{kamath2016crowdsourced,
  title={A crowdsourced approach to student engagement recognition in e-learning environments},
  author={Kamath, Aditya and Biswas, Aradhya and Balasubramanian, Vineeth},
  booktitle={2016 IEEE Winter Conference on Applications of Computer Vision (WACV)},
  pages={1--9},
  year={2016},
  organization={IEEE}
}

@article{he2020deformable,
  title={Deformable face net for pose invariant face recognition},
  author={He, Mingjie and Zhang, Jie and Shan, Shiguang and Kan, Meina and Chen, Xilin},
  journal={Pattern Recognition},
  volume={100},
  pages={107113},
  year={2020},
  publisher={Elsevier}
}

@inproceedings{mohamad2020automatic,
  title={Automatic recognition of student engagement using deep learning and facial expression},
  author={Mohamad Nezami, Omid and Dras, Mark and Hamey, Len and Richards, Deborah and Wan, Stephen and Paris, C{\'e}cile},
  booktitle={Joint European Conference on Machine Learning and Knowledge Discovery in Databases},
  pages={273--289},
  year={2020},
  organization={Springer}
}

@inproceedings{schulc2019automatic,
  title={Automatic measurement of visual attention to video content using deep learning},
  author={Schulc, Attila and Cohn, Jeffrey F and Shen, Jie and Pantic, Maja},
  booktitle={2019 16th International Conference on Machine Vision Applications (MVA)},
  pages={1--6},
  year={2019},
  organization={IEEE}}
  
@inproceedings{zhang2019novel,
  title={An novel end-to-end network for automatic student engagement recognition},
  author={Zhang, Hao and Xiao, Xiaofan and Huang, Tao and Liu, Sanya and Xia, Yu and Li, Jia},
  booktitle={2019 IEEE 9th International Conference on Electronics Information and Emergency Communication (ICEIEC)},
  pages={342--345},
  year={2019},
  organization={IEEE}
}

@inproceedings{dhall2018emotiw,
  title={Emotiw 2018: Audio-video, student engagement and group-level affect prediction},
  author={Dhall, Abhinav and Kaur, Amanjot and Goecke, Roland and Gedeon, Tom},
  booktitle={Proceedings of the 20th ACM International Conference on Multimodal Interaction},
  pages={653--656},
  year={2018}
}  
  
  
@inproceedings{dhall2019emotiw,
  title={Emotiw 2019: Automatic emotion, engagement and cohesion prediction tasks},
  author={Dhall, Abhinav},
  booktitle={2019 International Conference on Multimodal Interaction},
  pages={546--550},
  year={2019}
}

@inproceedings{niu2018automatic,
  title={Automatic engagement prediction with GAP feature},
  author={Niu, Xuesong and Han, Hu and Zeng, Jiabei and Sun, Xuran and Shan, Shiguang and Huang, Yan and Yang, Songfan and Chen, Xilin},
  booktitle={Proceedings of the 20th ACM International Conference on Multimodal Interaction},
  pages={599--603},
  year={2018}
}

@inproceedings{yang2018deep,
  title={Deep recurrent multi-instance learning with spatio-temporal features for engagement intensity prediction},
  author={Yang, Jianfei and Wang, Kai and Peng, Xiaojiang and Qiao, Yu},
  booktitle={Proceedings of the 20th ACM international conference on multimodal interaction},
  pages={594--598},
  year={2018}
}

@article{hassani2021escaping,
  title={Escaping the big data paradigm with compact transformers},
  author={Hassani, Ali and Walton, Steven and Shah, Nikhil and Abuduweili, Abulikemu and Li, Jiachen and Shi, Humphrey},
  journal={arXiv preprint arXiv:2104.05704},
  year={2021}
}

@article{vaswani2017attention,
  title={Attention is all you need},
  author={Vaswani, Ashish and Shazeer, Noam and Parmar, Niki and Uszkoreit, Jakob and Jones, Llion and Gomez, Aidan N and Kaiser, {\L}ukasz and Polosukhin, Illia},
  journal={Advances in neural information processing systems},
  volume={30},
  year={2017}
}

@article{hendrycks2016gaussian,
  title={Gaussian error linear units (gelus)},
  author={Hendrycks, Dan and Gimpel, Kevin},
  journal={arXiv preprint arXiv:1606.08415},
  year={2016}
}

@article{ba2016layer,
  title={Layer normalization},
  author={Ba, Jimmy Lei and Kiros, Jamie Ryan and Hinton, Geoffrey E},
  journal={arXiv preprint arXiv:1607.06450},
  year={2016}
}
@article{loshchilov2017decoupled,
  title={Decoupled weight decay regularization},
  author={Loshchilov, Ilya and Hutter, Frank},
  journal={arXiv preprint arXiv:1711.05101},
  year={2017}
}
@inproceedings{huang2016deep,
  title={Deep networks with stochastic depth},
  author={Huang, Gao and Sun, Yu and Liu, Zhuang and Sedra, Daniel and Weinberger, Kilian Q},
  booktitle={European conference on computer vision},
  pages={646--661},
  year={2016},
  organization={Springer}
}
@inproceedings{szegedy2016rethinking,
  title={Rethinking the inception architecture for computer vision},
  author={Szegedy, Christian and Vanhoucke, Vincent and Ioffe, Sergey and Shlens, Jon and Wojna, Zbigniew},
  booktitle={Proceedings of the IEEE conference on computer vision and pattern recognition},
  pages={2818--2826},
  year={2016}
}
@article{zhalehpour2016baum,
  title={BAUM-1: A spontaneous audio-visual face database of affective and mental states},
  author={Zhalehpour, Sara and Onder, Onur and Akhtar, Zahid and Erdem, Cigdem Eroglu},
  journal={IEEE Transactions on Affective Computing},
  volume={8},
  number={3},
  pages={300--313},
  year={2016},
  publisher={IEEE}
}

@inproceedings{ghoddoosian2019realistic,
  title={A realistic dataset and baseline temporal model for early drowsiness detection},
  author={Ghoddoosian, Reza and Galib, Marnim and Athitsos, Vassilis},
  booktitle={Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition Workshops},
  pages={0--0},
  year={2019}
}
@inproceedings{abtahi2014yawdd,
  title={YawDD: A yawning detection dataset},
  author={Abtahi, Shabnam and Omidyeganeh, Mona and Shirmohammadi, Shervin and Hariri, Behnoosh},
  booktitle={Proceedings of the 5th ACM multimedia systems conference},
  pages={24--28},
  year={2014}
}

@article{zhang2016joint,
  title={Joint face detection and alignment using multitask cascaded convolutional networks},
  author={Zhang, Kaipeng and Zhang, Zhanpeng and Li, Zhifeng and Qiao, Yu},
  journal={IEEE signal processing letters},
  volume={23},
  number={10},
  pages={1499--1503},
  year={2016},
  publisher={IEEE}
}
@article{ekman1992argument,
  title={An argument for basic emotions},
  author={Ekman, Paul},
  journal={Cognition \& emotion},
  volume={6},
  number={3-4},
  pages={169--200},
  year={1992},
  publisher={Taylor \& Francis}
}
@article{pekrun2000social,
  title={A social-cognitive, control-value theory of achievement emotions.},
  author={Pekrun, Reinhard},
  year={2000},
  publisher={Elsevier Science}
}
@article{zhang2017learning,
  title={Learning affective features with a hybrid deep model for audio--visual emotion recognition},
  author={Zhang, Shiqing and Zhang, Shiliang and Huang, Tiejun and Gao, Wen and Tian, Qi},
  journal={IEEE Transactions on Circuits and Systems for Video Technology},
  volume={28},
  number={10},
  pages={3030--3043},
  year={2017},
  publisher={IEEE}
}
@article{ma2019audio,
  title={Audio-visual emotion fusion (AVEF): A deep efficient weighted approach},
  author={Ma, Yaxiong and Hao, Yixue and Chen, Min and Chen, Jincai and Lu, Ping and Ko{\v{s}}ir, Andrej},
  journal={Information Fusion},
  volume={46},
  pages={184--192},
  year={2019},
  publisher={Elsevier}
}
@article{pan2021multimodal,
  title={Multimodal emotion recognition based on feature selection and extreme learning machine in video clips},
  author={Pan, Bei and Hirota, Kaoru and Jia, Zhiyang and Zhao, Linhui and Jin, Xiaoming and Dai, Yaping},
  journal={Journal of Ambient Intelligence and Humanized Computing},
  pages={1--15},
  year={2021},
  publisher={Springer}
}

@article{omidyeganeh2016yawning,
  title={Yawning detection using embedded smart cameras},
  author={Omidyeganeh, Mona and Shirmohammadi, Shervin and Abtahi, Shabnam and Khurshid, Aasim and Farhan, Muhammad and Scharcanski, Jacob and Hariri, Behnoosh and Laroche, Daniel and Martel, Luc},
  journal={IEEE Transactions on Instrumentation and Measurement},
  volume={65},
  number={3},
  pages={570--582},
  year={2016},
  publisher={IEEE}
}

@inproceedings{zhang2017driver,
  title={Driver yawning detection based on long short term memory networks},
  author={Zhang, Weiwei and Su, Jinya},
  booktitle={2017 IEEE Symposium Series on Computational Intelligence (SSCI)},
  pages={1--5},
  year={2017},
  organization={IEEE}
}
@inproceedings{zhang2015driver,
  title={Driver yawning detection based on deep convolutional neural learning and robust nose tracking},
  author={Zhang, Weiwei and Murphey, Yi L and Wang, Tianyu and Xu, Qijie},
  booktitle={2015 International Joint Conference on Neural Networks (IJCNN)},
  pages={1--8},
  year={2015},
  organization={IEEE}
}
@article{bai2021two,
  title={Two-stream spatial-temporal graph convolutional networks for driver drowsiness detection},
  author={Bai, Jing and Yu, Wentao and Xiao, Zhu and Havyarimana, Vincent and Regan, Amelia C and Jiang, Hongbo and Jiao, Licheng},
  journal={IEEE Transactions on Cybernetics},
  year={2021},
  publisher={IEEE}
}
@article{deng2019real,
  title={Real-time driver-drowsiness detection system using facial features},
  author={Deng, Wanghua and Wu, Ruoxue},
  journal={Ieee Access},
  volume={7},
  pages={118727--118738},
  year={2019},
  publisher={IEEE}
}
@article{ji2019fatigue,
  title={Fatigue state detection based on multi-index fusion and state recognition network},
  author={Ji, Yingyu and Wang, Shigang and Zhao, Yan and Wei, Jian and Lu, Yang},
  journal={IEEE Access},
  volume={7},
  pages={64136--64147},
  year={2019},
  publisher={IEEE}
}
@article{ye2021driver,
  title={Driver fatigue detection based on residual channel attention network and head pose estimation},
  author={Ye, Mu and Zhang, Weiwei and Cao, Pengcheng and Liu, Kangan},
  journal={Applied Sciences},
  volume={11},
  number={19},
  pages={9195},
  year={2021},
  publisher={MDPI}
}
@article{xiang2022driving,
  title={Driving Fatigue Detection Based on the Combination of Multi-Branch 3D-CNN and Attention Mechanism},
  author={Xiang, Wenbin and Wu, Xuncheng and Li, Chuanchang and Zhang, Weiwei and Li, Feiyang},
  journal={Applied Sciences},
  volume={12},
  number={9},
  pages={4689},
  year={2022},
  publisher={MDPI}
}

@article{bian2019spontaneous,
  title={Spontaneous facial expression database for academic emotion inference in online learning},
  author={Bian, Cunling and Zhang, Ya and Yang, Fei and Bi, Wei and Lu, Weigang},
  journal={IET Computer Vision},
  volume={13},
  number={3},
  pages={329--337},
  year={2019},
  publisher={Wiley Online Library}}

  @article{ashwin2019unobtrusive,
  title={Unobtrusive behavioral analysis of students in classroom environment using non-verbal cues},
  author={Ashwin, TS and Guddeti, Ram Mohana Reddy},
  journal={IEEE Access},
  volume={7},
  pages={150693--150709},
  year={2019},
  publisher={IEEE}}

@article{mandia2023recognition,
  title={Recognition of student engagement in classroom from affective states},
  author={Mandia, Sandeep and Singh, Kuldeep and Mitharwal, Rajendra},
  journal={International Journal of Multimedia Information Retrieval},
  volume={12},
  number={2},
  pages={18},
  year={2023},
  publisher={Springer}
}

@article{mandia2023automatic,
  title={Automatic student engagement measurement using machine learning techniques: A literature study of data and methods},
  author={Mandia, Sandeep and Mitharwal, Rajendra and Singh, Kuldeep},
  journal={Multimedia Tools and Applications},
  pages={1--32},
  year={2023},
  publisher={Springer}
}