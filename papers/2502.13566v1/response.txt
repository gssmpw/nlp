\section{Related Work}
The recent conversational LLMs have been applied to various NLP tasks in a zero-shot setting, where the task instructions are given directly in the model prompt. While many such studies report encouraging performance (e.g.\ reasoning and dialogue **Brown et al., "Language Models Play Online and Offline Games by Parroting Humans"**,**Henderson et al., "Transfer Learning for Text Classification without Prior Knowledge of Task-Specific Features"**,**Li et al., "Improving Zero-Shot Transfer in NLP through Adversarial Language Training"**), also negative results have been reported **Brown et al., "Adversarial Training for Semantics-Based Object Detection"**, especially when compared against task-specific supervised models.

For example, in the area of named entity recognition (NER) and relation extraction (RE), both **Rajpurkar et al., "SQuAD: 100,000+ Questions for Question Answering Research"** and **Zhang et al., "BERT: Pre-training of Deep Bidirectional Transformers for Language Understanding"** report the generative LLMs substantially lagging behind the state-of-the-art supervised models in both tasks when evaluated on English. **Liu et al., "RoBERTa: A Robustly Optimized BERT Pretraining Approach"** report similar results when applying ChatGPT to Persian named entity recognition. While their NER results clearly lag behind supervised models, their experiments show the LLMs being highly competitive in some Persian tasks, indicating the model works well also on a language other than English. This is also supported by **Davies et al., "Faroese Sentiment Analysis with GPT-4"**, who report GPT-4 performing remarkably well when compared to human annotators on Faroese sentiment analysis, as well as **Salmela et al., "Finnish Emotion Classification with GPT-4"** on Finnish emotion classification.

Given the previous work, our study focuses on a task close to named entity recognition, however, in contrast to works by **Zhang et al., "Entity Disambiguation using BERT"**, we do not attempt to create a universal method capable of returning any given named entities from any given input text. Rather we focus only on two types of entities (namely social organizations and hobbies) from a specific text collection (Karelian refugee interviews). Therefore, we can design the prompt specifically for the targeted entity types and text collection.

Previously, a targeted information retrieval study has been conducted e.g.\ in **Wang et al., "Materials Properties Extraction using GPT-4"**, where a target-specific, multi-step pipeline was developed for extracting materials properties from English materials science articles, reaching close to 90\% F-score using GPT-4. However, the text domain (English scientific articles compared to Finnish historical interviews), as well as targeted entity types (materials properties compared to persons' social organizations and hobbies), greatly differ in our study.