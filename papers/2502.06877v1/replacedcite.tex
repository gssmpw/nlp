\section{Literature Review}
The increasing complexity and diversity of wireless communication systems have driven the need for models capable of performing multiple tasks, such as channel estimation, beamforming, and interference management, within a unified framework. Traditional task-specific approaches, while effective in isolated scenarios, struggle to generalize across diverse environments and often require large amounts of labeled data. This has motivated the exploration of task-agnostic foundation models for multi-task learning in communication systems.

%+ MTL multi-task learning

Lee et al. proposed a framework that integrates pre-trained language models with physical layer communications, enhancing robustness under noisy conditions ____. However, its application is limited to single-task scenarios, lacking generalization across diverse tasks. Alikhani et al. introduced the Large Wireless Model (LWM), a task-agnostic foundation model leveraging Transformer-based architecture and self-supervised pretraining on large-scale wireless datasets ____. While LWM improves performance in multiple tasks such as channel modeling and beamforming, it focuses primarily on physical layer tasks, with limited applicability to broader multi-task ISAC scenarios. 

Other studies have explored multi-modal and multi-task learning paradigms. Jiao et al. ____ proposed a 6G-oriented framework employing contrastive learning to align channel state information (CSI) with environmental descriptions, enabling zero-shot learning and task-oriented fine-tuning for multiple tasks. Their approach highlights the generalization potential of foundation models across base station environments and tasks. Aboulfotouh et al. ____ introduced a Vision Transformer (ViT)-based radio foundation model, leveraging masked spectrogram modeling for pretraining. Their approach demonstrated enhanced generalization and reduced training costs for tasks like human activity sensing and spectrogram segmentation.

In parallel, Yu et al. introduced ChannelGPT ____, a large model designed to generate digital twin channels for 6G environment intelligence, emphasizing the integration of multimodal data for accurate channel parameter generation and scenario adaptation. Tian et al. ____ explored multimodal transformers for beam prediction by fusing data from diverse sensors like cameras, LiDAR, and GPS. Although their framework supports feature fusion, it primarily addresses beam prediction rather than a unified multi-task approach.

Ott et al. ____ demonstrated the potential of self-supervised learning for localization tasks using 5G channel measurements. Their transformer-based framework pre-trains models on unlabeled CIR data, showing strong performance in downstream localization tasks but limited applicability to other domains. Zayat et al. ____ introduced transformer-masked autoencoders (TMAE) for next-generation wireless networks, highlighting their potential in addressing challenges like channel estimation and resource allocation. However, their application remains focused on specific tasks rather than a comprehensive multi-task framework. Besides, a comprehensive comparison among recent LLM-based models is presented in Tab. \ref{LLMComp}.


Building upon these advancements, this study proposes WirelessGPT, a foundation model specifically designed for multi-task learning in integrated sensing and communication (ISAC) systems. By pretraining on large-scale wireless channel datasets and fine-tuning for diverse tasks, WirelessGPT addresses the limitations of existing models, offering a scalable and unified solution to enhance performance across a wide range of communication and sensing tasks. This work bridges the gap between task-specific models and the growing need for multi-task capabilities in next-generation wireless networks.