\section{Related Work}
\begin{table}[b!] 
	\vspace{-0.75cm}
	{\footnotesize
		\caption{\footnotesize{A summary of related studies\\(LoT: Location of task, TW: Time window of tasks)}} \vspace{-0.6cm} 
		\begin{center}
			\setlength{\tabcolsep}{0.5mm}{
				\begin{tabular}{|c|c|c|c|c|c|c|c|c|}
					\hline
					\multirow{2}{*}{\textbf{Reference}} & \multicolumn{2}{c|}{\makecell[c]{\textbf{Environmental}\\ \textbf{attributes}}} & \multicolumn{2}{c|}{\textbf{Trading mode}}&\multicolumn{4}{c|}{\textbf{Task property}}\\ \cline{2-9} 
					&\makecell[c]{Static}&\makecell[c]{Dynamic}&\makecell[c]{Spot}&\makecell[c]{Futures}&AoI&\makecell[c]{LoT}&TW&\makecell[c]{Budget}\\ \hline
					\makecell[c]{\cite{Incentive 1,RWork_stable 7,RWork_stable 5}} &$\surd$& &$\surd$& & & & &$\surd$\\ \hline
					\makecell[c]{\cite{Incentive 2}} &$\surd$& &$\surd$& &$\surd$& & &$\surd$\\ \hline	
					\makecell[c]{\cite{Incentive 3,RWork_stable 8}} &$\surd$& &$\surd$& & & $\surd$& &$\surd$\\ \hline
					\makecell[c]{\cite{RWork_stable 4}} &$\surd$& &$\surd$& &$\surd$& & &\\ \hline
					\makecell[c]{\cite{RWork_stable 6}} &$\surd$& &$\surd$& & &$\surd$&$\surd$&$\surd$\\ \hline
					\makecell[c]{\cite{RWork_dynamic 1}} & &$\surd$&$\surd$& &$\surd$&$\surd$&$\surd$&$\surd$\\ \hline
					\makecell[c]{\cite{RWork_dynamic 2}} &&$\surd$&$\surd$& &$\surd$& & &$\surd$\\ \hline
					\makecell[c]{\cite{RWork_dynamic 3,RWork_dynamic 4}} & &$\surd$ &$\surd$& & &$\surd$ &$\surd$&$\surd$ \\ \hline
					\makecell[c]{\cite{SURVEY 2,RWork_dynamic 5}} & &$\surd$ &$\surd$& & &$\surd$ & &$\surd$ \\ \hline
					\cite{DP2} & &$\surd$&$\surd$&$\surd$& & & &$\surd$\\ \hline
					our work & &$\surd$&$\surd$&$\surd$&$\surd$&$\surd$&$\surd$&$\surd$\\ \hline
			\end{tabular}}
	\end{center}}
	
\end{table}
Existing efforts have been put forward to resource trading in MCS networks from different viewpoints.

\noindent
$\bullet$ \textit{Investigations regarding static MCS networks.} Most studies on task scheduling and worker recruitment mainly consider rather static MCS networks \cite{Incentive 1,Incentive 2,Incentive 3,RWork_stable 4,RWork_stable 5,RWork_stable 6}.
In\cite{Incentive 1}, \textit{Zhou et al.} studied the bi-objective optimization for MCS incentive mechanism design, to simultaneously optimize total value function and coverage function with budget/cost constraint.
In\cite{Incentive 2}, \textit{Cheng et al.} considered AoI and captured the conflict interests/competitions among workers, proposing a freshness-aware incentive mechanism.
\textit{Hu et al.\cite{Incentive 3}} investigated a game-based incentive mechanism to recruit workers effectively while improving the reliability and data quality.
In\cite{RWork_stable 4}, \textit{Xiao et al.} considered the freshness of collected data and social benefits in MCS incentive designs
A many-to-many matching model was constructed by \textit{Dai et al.} \cite{RWork_stable 5} to capture the interaction between tasks and workers under budget constraints.
In\cite{RWork_stable 6}, \textit{Tao et al.} employed a double deep Q-network with prioritized experience replay to address the task allocation problem.
In\cite{RWork_stable 7}, \textit{Zhou et al.} studied a two-stage incentive scheme that combines blockchain technology and trusted execution environment.
\textit{Zhao et al.} \cite{RWork_stable 8} investigated a multi-agent deep reinforcement learning (DRL)-based incentive mechanism to tackle the joint data sensing and computing issues.


\noindent
$\bullet$ \textit{Investigations regarding dynamic MCS networks.} Although previous studies have made certain contributions, real-world MCS networks are inherently dynamic, and workers can often face various uncertain events during the data collection and delivery process. Consequently, researchers gradually shifted their focus towards dynamic and uncertain MCS networks\cite{SURVEY 2,RWork_dynamic 1,RWork_dynamic 2,RWork_dynamic 3,RWork_dynamic 4,RWork_dynamic 5}. 
In \cite{SURVEY 2}, \textit{Zhang et al.} considered diverse sensing tasks, while proposing a dynamic worker recruitment mechanism for edge computing-aided MCS. 
\textit{Gao et al.} \cite{RWork_dynamic 1} studied a dynamic task pricing problem with diverse factors such as multiple requester queuing competitions, dynamic task requirements, and distinct waiting time costs.
In \cite{RWork_dynamic 2}, \textit{Ji et al.} proposed a quality-driven online task-bundling-based incentive mechanism to maximize the social welfare while satisfying the task quality demands.
By adopting cognitive bias and the reference effect, \textit{Li et al.} in \cite{RWork_dynamic 3} explained the principle of path-dependence, and proposed a task coverage promotion according to path-dependence in improving the coverage and effectiveness.
In \cite{RWork_dynamic 4}, \textit{Ding et al.} investigated dynamic delayed-decision task assignment to enhance both the task completion ratios and budget utilization, while decreasing the user singleness.
In \cite{RWork_dynamic 5}, \textit{Guo et al.} proposed a dual reinforcement learning (RL)-based online worker recruitment strategy with adaptive budget segmentation, to cope with trajectories.
While the aforementioned studies have raised some interesting ideas, they primarily focus on onsite decision-making (e.g., spot trading), which may by be susceptible to prolonged delays, heavy energy cost, and potential trading failures. To tackle the above challenges, we had made early efforts in establishing a hybrid market with futures and spot trading modes \cite{DP2}. However, \cite{DP2} puts emphasis on a rather simple environment, which overlooks several key aspects, such as the uncertain delay event incurred on the way of a worker to the assigned task, the diverse demands and attributes of MCS tasks, such like their spatial-temporal characteristics. These complicated uncertain factors are now considered in this paper.
Moreover, the optimization in \cite{DP2} simply aims to find a proper mapping between workers and tasks, while in this paper, we also should design the path for each worker to catch the deadline of assigned tasks. Driven by the complicated optimization problems, we design efficient solutions, such as ant colony optimization-based method for path pre-planning, and DRL-based method for path update (whether to follow the pre-planned path or abandon a contractual task). As a summary, we focus on closer-to-real-world settings for MCS. A summary in comparing related studies is shown in Table 1, further representing our key differences. In the following, we introduce the key unique features offered by our methodology over existing methods, as summarized below.
 
\noindent $\bullet$ \textit{Consideration on diverse task demands and uncertainties:} Unlike traditional approaches with single task characteristic -- such as geographic location, time constraints, or budget limitations -- our method fully accounts for multi-dimensional task requirements, including AoI, location of PoIs, time windows, and budget constraint. Also, uncertain factors such as uncertain delay event, uncertain duration of the delay event, and time-varying channel quality are carefully modeled to capture the random nature of MCS networks. That is to say, this paper pays attention to a more realistic MCS environment with dynamics.

\noindent $\bullet$ \textit{Way to handle uncertainties and risks:} In dynamic MCS networks, uncertainties in task execution -- such as task cancellations, delays on the way, and worker mobility -- can leave heavy impacts on task completion and resource utilization, which have always been overlooked in conventional methods. To address this issue, we incorporate risk-constrained optimization during the futures trading stage, ensuring that task assignments remain feasible under diverse uncertainties while maintaining market stability. More importantly, during the spot trading stage, we enable workers to update/revise their paths in response to dynamic conditions, facilitating flexible on-demand worker recruitment strategies.