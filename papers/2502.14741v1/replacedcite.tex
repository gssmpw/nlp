\section{Previous Work}
Many works have examined RL for resource allocation in optical networks, but only a few have employed graph-based neural network architectures. Almasan et al. ____ were the first to explore a message passing neural network (MPNN) with RL for routing in an optical network, which demonstrated improved performance compared to a theoretical fluid model and some capability to generalize to new topologies (with degraded performance). Xu et al. ____ used a graph convolutional neural network (GCN) as part of the policy and value functions in their actor-critic architecture for dynamic RMSA, and demonstrated 28\% improvement in blocking probability over KSP-FF and 22\% better than their implementation of DeepRMSA ____. The GAT architecture was used in a recent work by Xiong et al. ____ which demonstrated BP reduced from 2\% to 1\% compared to KSP-FF with K=5 on NSFNET for dynamic RMSA. The trend toward more advanced graph-based architectures is continued by Cheng et al. with their work PtrNet-RSA ____, which employs a pointer network ____ to select the nodes of the path and overcome the limitation of considering only k-shortest paths. Most of these works consider very similar problem settings (topologies and traffic models) and use the same benchmarks without investigating if they are the best benchmarks available. In this work, we establish the strongest heuristic benchmarks available (by testing different sort criteria for the candidate paths) to ensure our RL results are not trivial.

As discussed, only one previous work has studied the RWA-LR problem. Nevin et al. ____ made major contributions to the field by introducing RAW-LR and providing a detailed description of the techniques necessary to improve on their benchmarks, including invalid action masking and shortened training episodes. They demonstrate 18.4 Tbps increase in network throughput compared to their best benchmark (FF-KSP with K=5 and paths ordered by length). In this work we build on their recommendations and incorporate two improvements: we include the GAT architecture in our learning algorithm to exploit graph structure and we use our GPU-based simulation and training framework to enable training in a high-data regime.

%Shortcomings are they fail to investigate different sort criteria for the candidate paths. Also 10,000 service request episodes is an arbitrary number. Services accepted until first blocking event is a less arbitrary measure.