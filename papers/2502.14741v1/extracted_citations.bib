@article{almasan_deep_2022,
	title = {Deep reinforcement learning meets graph neural networks: {Exploring} a routing optimization use case},
	volume = {196},
	issn = {01403664},
	shorttitle = {Deep reinforcement learning meets graph neural networks},
	url = {https://linkinghub.elsevier.com/retrieve/pii/S0140366422003784},
	doi = {10.1016/j.comcom.2022.09.029},
	language = {en},
	urldate = {2024-08-12},
	journal = {Computer Communications},
	author = {Almasan, Paul and Suárez-Varela, José and Rusek, Krzysztof and Barlet-Ros, Pere and Cabellos-Aparicio, Albert},
	month = dec,
	year = {2022},
	keywords = {RL, RSA, Routing},
	pages = {184--194},
}

@article{chen_deeprmsa_2019,
	title = {{DeepRMSA}: {A} {Deep} {Reinforcement} {Learning} {Framework} for {Routing}, {Modulation} and {Spectrum} {Assignment} in {Elastic} {Optical} {Networks}},
	volume = {37},
	issn = {0733-8724, 1558-2213},
	shorttitle = {{DeepRMSA}},
	url = {https://ieeexplore.ieee.org/document/8738827/},
	doi = {10.1109/JLT.2019.2923615},
	abstract = {This paper proposes DeepRMSA, a deep reinforcement learning framework for routing, modulation and spectrum assignment (RMSA) in elastic optical networks (EONs). DeepRMSA learns the correct online RMSA policies by parameterizing the policies with deep neural networks (DNNs) that can sense complex EON states. The DNNs are trained with experiences of dynamic lightpath provisioning. We ﬁrst modify the asynchronous advantage actorcritic algorithm and present an episode-based training mechanism for DeepRMSA, namely, DeepRMSA-EP. DeepRMSA-EP divides the dynamic provisioning process into multiple episodes (each containing the servicing of a ﬁxed number of lightpath requests) and performs training by the end of each episode. The optimization target of DeepRMSA-EP at each step of servicing a request is to maximize the cumulative reward within the rest of the episode. Thus, we obviate the need for estimating the rewards related to unknown future states. To overcome the instability issue in the training of DeepRMSA-EP due to the oscillations of cumulative rewards, we further propose a window-based ﬂexible training mechanism, i.e., DeepRMSA-FLX. DeepRMSA-FLX attempts to smooth out the oscillations by deﬁning the optimization scope at each step as a sliding window, and ensuring that the cumulative rewards always include rewards from a ﬁxed number of requests. Evaluations with the two sample topologies show that DeepRMSA-FLX can effectively stabilize the training while achieving blocking probability reductions of more than 20.3\% and 14.3\%, when compared with the baselines.},
	language = {en},
	number = {16},
	urldate = {2023-01-09},
	journal = {Journal of Lightwave Technology},
	author = {Chen, Xiaoliang and Li, Baojia and Proietti, Roberto and Lu, Hongbo and Zhu, Zuqing and Yoo, S. J. Ben},
	month = aug,
	year = {2019},
	keywords = {RL, RMSA},
	pages = {4155--4163},
}

@article{cheng_ptrnet-rsa_2024,
	title = {{PtrNet}-{RSA}: {A} {Pointer} {Network}-based {QoT}-aware {Routing} and {Spectrum} {Assignment} {Scheme} in {Elastic} {Optical} {Networks}},
	doi = {10.1109/JLT.2024.3405587},
	journal = {Journal of Lightwave Technology},
	author = {Cheng, Yuansen and Ding, Shifeng and Shao, Yingjie and Chan, Chun-Kit},
	year = {2024},
	keywords = {Computational complexity, Computational modeling, Estimation, Mathematical models, Optical fiber networks, Pointer network, RL, RSA, Routing, Signal to noise ratio, elastic optical networks, quality of transmission, reinforcement learning, routing and spectrum assignment},
	pages = {1--12},
}

@article{nevin_techniques_2022,
	title = {Techniques for applying reinforcement learning to routing and wavelength assignment problems in optical fiber communication networks},
	volume = {14},
	issn = {1943-0639},
	doi = {10.1364/JOCN.460629},
	abstract = {We propose a novel application of reinforcement learning (RL) with invalid action masking and a novel training methodology for routing and wavelength assignment (RWA) in fixed-grid optical networks and demonstrate the generalizability of the learned policy to a realistic traffic matrix unseen during training. Through the introduction of invalid action masking and a new training method, the applicability of RL to RWA in fixed-grid networks is extended from considering connection requests between nodes to servicing demands of a given bit rate, such that lightpaths can be used to service multiple demands subject to capacity constraints. We outline the additional challenges involved for this RWA problem, for which we found that standard RL had low performance compared to that of baseline heuristics, in comparison with the connection requests RWA problem considered in the literature. Thus, we propose invalid action masking and a novel training method to improve the efficacy of the RL agent. With invalid action masking, domain knowledge is embedded in the RL model to constrain the action space of the RL agent to lightpaths that can support the current request, reducing the size of the action space and thus increasing the efficacy of the agent. In the proposed training method, the RL model is trained on a simplified version of the problem and evaluated on the target RWA problem, increasing the efficacy of the agent compared with training directly on the target problem. RL with invalid action masking and this training method outperforms standard RL and three state-of-the-art heuristics, namely, k shortest path first fit, first-fit k shortest path, and k shortest path most utilized, consistently across uniform and nonuniform traffic in terms of the number of accepted transmission requests for two real-world core topologies, NSFNET and COST–239. The RWA runtime of the proposed RL model is comparable to that of these heuristic approaches, demonstrating the potential for real-world applicability. Moreover, we show that the RL agent trained on uniform traffic is able to generalize well to a realistic nonuniform traffic distribution not seen during training, thus outperforming the heuristics for this traffic. Visualization of the learned RWA policy reveals an RWA strategy that differs significantly from those of the heuristic baselines in terms of the distribution of services across channels and the distribution across links.},
	number = {9},
	journal = {Journal of Optical Communications and Networking},
	author = {Nevin, Josh W. and Nallaperuma, Sam and Shevchenko, Nikita A. and Shabka, Zacharaya and Zervas, Georgios and Savory, Seb J.},
	month = sep,
	year = {2022},
	keywords = {Incremental, Mathematical models, Optical fiber networks, RL, RWA, Reinforcement learning, Standards, Training, Wavelength assignment},
	pages = {733--748},
}

@misc{vinyals_pointer_2015,
	title = {Pointer {Networks}},
	copyright = {arXiv.org perpetual, non-exclusive license},
	url = {https://arxiv.org/abs/1506.03134},
	doi = {10.48550/ARXIV.1506.03134},
	abstract = {We introduce a new neural architecture to learn the conditional probability of an output sequence with elements that are discrete tokens corresponding to positions in an input sequence. Such problems cannot be trivially addressed by existent approaches such as sequence-to-sequence and Neural Turing Machines, because the number of target classes in each step of the output depends on the length of the input, which is variable. Problems such as sorting variable sized sequences, and various combinatorial optimization problems belong to this class. Our model solves the problem of variable size output dictionaries using a recently proposed mechanism of neural attention. It differs from the previous attention attempts in that, instead of using attention to blend hidden units of an encoder to a context vector at each decoder step, it uses attention as a pointer to select a member of the input sequence as the output. We call this architecture a Pointer Net (Ptr-Net). We show Ptr-Nets can be used to learn approximate solutions to three challenging geometric problems -- finding planar convex hulls, computing Delaunay triangulations, and the planar Travelling Salesman Problem -- using training examples alone. Ptr-Nets not only improve over sequence-to-sequence with input attention, but also allow us to generalize to variable size output dictionaries. We show that the learnt models generalize beyond the maximum lengths they were trained on. We hope our results on these tasks will encourage a broader exploration of neural learning for discrete problems.},
	urldate = {2024-06-30},
	publisher = {arXiv},
	author = {Vinyals, Oriol and Fortunato, Meire and Jaitly, Navdeep},
	year = {2015},
	note = {Version Number: 2},
	keywords = {Computational Geometry (cs.CG), FOS: Computer and information sciences, Machine Learning (cs.LG), Machine Learning (stat.ML), Neural and Evolutionary Computing (cs.NE)},
}

@inproceedings{xiong_graph_2024,
	address = {Beijing, China},
	title = {Graph {Attention} {Network} {Enhanced} {Deep} {Reinforcement} {Learning} {Framework} for {Routing}, {Modulation}, and {Spectrum} {Allocation} in {EONs}},
	copyright = {https://doi.org/10.15223/policy-029},
	isbn = {9798350379266},
	url = {https://ieeexplore.ieee.org/document/10810116/},
	doi = {10.1109/ACP/IPOC63121.2024.10810116},
	urldate = {2025-01-03},
	booktitle = {2024 {Asia} {Communications} and {Photonics} {Conference} ({ACP}) and {International} {Conference} on {Information} {Photonics} and {Optical} {Communications} ({IPOC})},
	publisher = {IEEE},
	author = {Xiong, Zheng and Huang, Yue-Cai and Hu, Xiaohui},
	month = nov,
	year = {2024},
	keywords = {RMSA},
	pages = {1--6},
}

@article{xu_deep_2022,
	title = {Deep {Reinforcement} {Learning}-{Based} {Routing} and {Spectrum} {Assignment} of {EONs} by {Exploiting} {GCN} and {RNN} for {Feature} {Extraction}},
	volume = {40},
	doi = {10.1109/JLT.2022.3175865},
	number = {15},
	journal = {Journal of Lightwave Technology},
	author = {Xu, Liufei and Huang, Yue-Cai and Xue, Yun and Hu, Xiaohui},
	year = {2022},
	keywords = {RL, RMSA},
	pages = {4945--4955},
}

