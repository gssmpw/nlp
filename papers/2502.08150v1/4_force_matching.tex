\section{Force Matching} \label{sec:form}

In this section, we introduce Force Matching (ForM), a new architecture for generative models, and provide its theoretical analysis. In Section~\ref{sub:obj}, we introduce the training objective of Force Matching. Then, in Section~\ref{sub:samp_ode}. In Section~\ref{sub:speed_limit}, we illustrate and discuss the speed limitation of ForM. In Section~\ref{sub:form_trig}, We show the interpolation path for ForM.


\subsection{Definition of Force Matching Objective} \label{sub:obj}

Next, we define the training objective of Force Matching.

\begin{definition}[Force Matching Objective]
\label{def:FormObjective}
The training objective of Force Matching (ForM) is defined by
\begin{align*}
     \mathcal{L}_{\rm ForM}(\theta) := \E_{t \sim {\sf Uniform}[0,T], x_1 \sim \mathcal{D}} 
    [\| F_t(x_t) - f_t(x_t)\|_2^2],   
\end{align*}
where $\mathcal{D}$ is the target data distribution, $f_t(x_t)$ is the target relativistic force defined in Definition~\ref{def:RelativisticForce}, and $F_t(x)$ is a trainable neural network parameterized with $\theta$.
\end{definition}

\subsection{Our Result I: Sampling ODE} \label{sub:samp_ode}

We define an ordinary differential equation (ODE) in order to get the position based on a given relativistic force. 

\begin{theorem}[Sampling ODE, informal version of Theorem~\ref{thm:ode_form:formal}]\label{thm:ode_form:informal}
    Giving the force at position $x_t$ denoted as $f_t(x_t)$, we could solve for ForM sampling path $x_t$ by the following ODE
    \begin{align*}
    \ddot{x}_t = \frac{1}{m^{\rm lab} \gamma_t}(f_t^{\rm local} - \frac{\langle v_t^{\rm lab}, f_t^{\rm local} \rangle}{c^2} v_t^{\rm lab}),
    \end{align*}
    where $x_0 \sim \N(0,I)$, $\dot{x}_0 = 0$.
\end{theorem}

Theorem~\ref{thm:ode_form:informal} shows how to derive the position $x_t$ from the relativistic force field $f_t(x_t)$. Unlike first-order flow-based methods, ForM naturally involves a second-order ODE because it encodes the evolution of both position and velocity under relativistic constraints. This allows for more expressive and physically-motivated sampling trajectories, where velocity constraints can help stabilize the generative process. Once a neural network $F_t(x)$ is trained to approximate $f_t(x)$, the sampling procedure integrates this second-order ODE to produce samples consistent with the target distribution.


\subsection{Our Result II: Speed Limit} \label{sub:speed_limit}

One property of relativistic mechanics is the velocity will always be under the constant $c$, which is the speed of light.

In reality, the speed of light is $c \approx 3 \times 10^8$. For any $v_t$, the speed $ \|v_t\|_2$ can approach but never exceed $c$. 
This property stabilizes the generating process. We formalize and prove this in Theorem~\ref{thm:vel:informal}.

\begin{theorem}[Speed Limit, informal version of Theorem~\ref{thm:vel:formal}] \label{thm:vel:informal}
For a ForM model with sampling path $x : [0,T) \to \R^n$, the velocity satisfies
\begin{align*}
\| \dot{x}_t \|_2 < c \quad, \forall t \in [0,T).
\end{align*}
\end{theorem}


It shows that the sample velocity remains strictly below $c$ at all times under relativistic constraints. Practically, this upper bound on velocity helps mitigate risks of numerical instability or ``exploding gradients" that can sometimes arise in diffusion- or flow-based generative models. By capping the speed of samples, ForM maintains a controlled and stable evolution in high-dimensional spaces. This provides a theoretical guarantee of safety against runaway behaviors, making the sampling process more robust.



\subsection{Our Result III: ForM with TrigFlow} \label{sub:form_trig}

The interpolation path of ForM is given by the following theorem.

\begin{theorem}[ForM with TrigFlow, informal version of Theorem~\ref{thm:form_trig:formal}] \label{thm:form_trig:informal}
We let $m = 1$ for simplicity in ForM. Giving a the interpolation $x_t = \alpha_t x_1 + \sigma_t x_0$, where $\alpha_T = 1$, $\alpha_0 = 0$, $\sigma_T = 0$, $\sigma_0 = 1$. We let $F_t(x_t)$ denote a vector map of force, a trainable neuron network parameterized with $\theta$. We select the $\alpha_t$ and $\sigma_t$ identical with TrigFlow \cite{ls24}, where $\alpha_t = \sin(t)$ and $\sigma_t = \cos(t)$, $T = \frac{\pi}{2}$. Then, force interpolation could be simplified to 
\begin{align*}
    f_t(x_t) =
    & ~ \frac{(\cos(t)x_1 - \sin(t)x_0) \cdot (-\sin(t)x_1 - \cos(t)x_0)}{c^2 - (\cos(t)x_1 - \sin(t)x_0)^2}\\
    & ~ (\cos(t)x_1 - \sin(t)x_0)).
\end{align*}
\end{theorem}

Theorem~\ref{thm:form_trig:informal} highlights how the ForM framework can be directly coupled with trigonometric interpolation paths. By choosing $\alpha_t$ and $\sigma_t$ as sine and cosine, respectively, we obtain a closed-form expression for the relativistic force that governs the sample evolution. This synergy suggests that ForM can not only unify different flow-based or diffusion-based models but also inherit the continuous-time advantages of the TrigFlow parameterization. Consequently, one can design more flexible interpolation strategies while still enjoying the stability benefits of relativistic velocity constraints.


