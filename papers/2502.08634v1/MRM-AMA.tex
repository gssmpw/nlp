\documentclass[AMA,STIX2COL]{MRM}
\articletype{RESEARCH ARTICLE}%

\received{26 April 2016}
\revised{6 June 2016}
\accepted{6 June 2016}
\topskip=0pt

\raggedbottom
\usepackage{amsmath}
\usepackage{amssymb}

\begin{document}

\title{Rapid Whole Brain Mesoscale In-vivo MR Imaging using Multi-scale Implicit Neural Representation}

\author[1]{Jun Lyu}{\orcid{0000-0003-1989-1360}}

\author[1]{Lipeng Ning}{\orcid{0000-0003-4992-459X}}

\author[2]{William Consagra}{\orcid{0000-0001-5279-3469}}

\author[1]{Qiang Liu}{\orcid{0009-0007-6818-0115}}

\author[3]{Richard J. Rushmore}{\orcid{0000-0003-2129-440X}}

\author[4,5,6]{Berkin Bilgic} {\orcid{0000-0002-9080-7865}}

\author[1]{Yogesh Rathi}{\orcid{0000-0002-9946-2314}}

\authormark{Jun Lyu \textsc{et al}}

\address[1]{\orgdiv{Mass General Brigham}, \orgname{Harvard Medical School}, \orgaddress{\state{MA}, \country{United States}}}

\address[2]{\orgdiv{Department of Statistics}, \orgname{University of South Carolina}, \orgaddress{\state{SC}, \country{United States}}}

\address[3]{\orgdiv{Department of Anatomy and Neurobiology}, \orgname{Boston University Chobanian \& Avedisian School of Medicine}, \orgaddress{\state{MA}, \country{United States}}}

\address[4]{\orgdiv{Athinoula A. Martinos Center for Biomedical Imaging}, \orgname{Massachusetts General Hospital}, \orgaddress{\state{MA}, \country{United States}}}

\address[5]{\orgdiv{Department of Radiology}, \orgname{Harvard Medical School, Boston}, \orgaddress{\state{MA}, \country{United States}}}

\address[6]{\orgdiv{Harvard/MIT Health Sciences and Technology,Cambridge}, \orgaddress{\state{MA}, \country{United States}}}

\corres{Jun Lyu, Brigham and Women’s Hospital, Harvard Medical School, 399 Revolution Drive, Suite 1155, Somerville, MA, 02145, United States. \email{jlyu1@bwh.harvard.edu}}

% \presentaddress{This is sample for present address text this is sample for present address text}

\finfo{This study is supported by National Institutes of Health grants:  \fundingNumber{R01NS125307, R01MH132610, R01MH125860, R01EB032378, and R01MH1192222}}

\abstract{
% We propose ROVER-MRI, an advanced super-resolution MRI acquisition and reconstruction framework designed for mesoscale (e.g., 180$\mu m$ isotropic voxel size) MR imaging. By integrating multi-view thick-slice acquisitions with a learning-free, multi-resolution hash encoding-based neural network, we achieve high-resolution imaging with high signal-to-noise ratio (SNR), detailed structure preservation, and robustness against motion. This approach offers a fast and efficient solution for whole-brain imaging, catering to future research studies.
\section{Purpose} To develop and validate a novel image reconstruction technique using implicit neural representations (INR) for multi-view thick-slice acquisitions while reducing the scan time but maintaining high signal-to-noise ratio (SNR).
\section{Methods} We propose {\underline{Ro}}tating-\underline{v}iew sup\underline{er}-resolution (ROVER)-MRI, an unsupervised neural network-based algorithm designed to reconstruct MRI data from multi-view thick slices, effectively reducing scan time by 2-fold while maintaining fine anatomical details.
We compare our method to both bicubic interpolation and the current state-of-the-art regularized least-squares super-resolution reconstruction (LS-SRR) technique. Validation is performed using ground-truth ex-vivo monkey brain data, and we demonstrate superior reconstruction quality across several in-vivo human datasets. Notably, we achieve the reconstruction of a whole human brain in-vivo T2-weighted image with an unprecedented 180 $\mu m$ isotropic spatial resolution, accomplished in just 17 minutes of scan time on a 7T MRI scanner. %We also demonstrate the reconstruction fidelity of our method on several other human in-vivo datasets with different SNRs.
\section{Results} ROVER-MRI outperformed LS-SRR method in terms of reconstruction quality with $22.4\%$ lower relative error (RE) and $7.5\%$ lower full-width half maximum (FWHM) indicating better preservation of fine structural details in nearly half the scan time.
\section{Conclusion} ROVER-MRI offers an efficient and robust approach for mesoscale MR imaging, enabling rapid, high-resolution whole-brain scans. Its versatility holds great promise for research applications requiring anatomical details and time-efficient imaging.
}

\keywords{Mesoscale whole-brain imaging, Super-resolution MRI, implicit neural representations, neural networks, deep learning}

%\wordcount{XXX}

\jnlcitation{\cname{%
\author{Lyu J}, 
\author{Ning LP}, 
\author{Consagra W}, 
\author{et al.}}, 
\ctitle{Rapid Whole Brain Mesoscale In-vivo MR Imaging using Multi-scale Implicit Neural Representation}, \cjournal{Magn. Reson. Med.}, \cvol{2024;00:1--6}.}

\maketitle

% \footnotetext{\textbf{Abbreviations:}~\hbox{ANA,~anti-nuclear~antibodies;~APC,~antigen-}{\hfill\break}presenting~cells; IRF, interferon regulatory factor}


\section{Introduction}\label{intro}
Magnetic Resonance Imaging (MRI) is a widely used non-invasive imaging technique for scientific research. The spatial resolution of MRI directly determines the clarity of anatomical details and the accuracy of diagnostic outcomes. However, achieving mesoscale resolution often comes at the cost of reduced signal-to-noise ratio (SNR) and prolonged acquisition times, presenting significant challenges to current research studies\cite{sui2020slimm}. Balancing resolution, SNR, and acquisition efficiency remains a central issue for MRI technology development\cite{plenge2012super}.


To accommodate this trade-off, it is common to acquire MRI images with relatively high in-plane resolution and lower through-plane resolution\cite{zhao2020smore}. In 2D MRI, the through-plane direction is always defined by the slice selection direction, whereas in 3D MRI, the through-plane direction is typically the second phase encoding direction, which usually has the smallest $k$-space sampling width.%, resulting in lower resolution. 
%The resulting elongated voxels encompass sufficient tissue volume to provide higher SNR while delivering an high resolution view with diagnostically acceptable quality. 

While acquisitions with anisotropic voxels may produce diagnostically acceptable images for in-plane directions, they are less suitable for research applications requiring spatially isotropic voxels.


To address these limitations, super-resolution reconstruction (SRR) techniques have been developed.
%
Super-resolution (SR) techniques are generally categorized into two types: single-image super-resolution (SISR) and multi-image super-resolution (MISR). 
%
Compared with traditional algorithms~\cite{gholipour2010robust, tourbier2015efficient, manjon2010non,sui2019isotropic,sui2021gradient}, SISR~\cite{bhowmik2017training} methods demonstrate superior performance by learning an end-to-end mapping between pairs of low resolution (LR) and high-resolution (HR) images. 
%
For example, generative adversarial networks (GANs) have been widely applied in MRI SR tasks. Chen et al~\cite{chen2018efficient} introduced a 3D dense GAN for MRI super-resolution, while Wang et al~\cite{wang2020enhanced} proposed a memory-efficient residual-dense block generator specifically designed for brain MRI super-resolution.
%
In addition, attention-based models have gained popularity. Zhang et al~\cite{zhang2021mr} developed the squeeze-and-excitation reasoning attention network to achieve more accurate MR image super-resolution. Lyu et al~\cite{lyu2020mri} introduced an ensemble-based approach to enhance the quality of MR images. Chaudhari et al~\cite{chaudhari2018super} proposed DeepResolve to reconstruct thin-slice high-resolution features from significantly thicker slices.
%
Recently, You et al~\cite{you2022fine} designed a fine perceptive GAN to produce HR MRIs from their LR counterparts, further advancing the field of super-resolution in medical imaging. While these methods can produce excellent results on in-domain examples, they exhibit several notable limitations: (1) large amounts of ground truth data (matched pairs of low and high resolution images) are required for training, and (2) limited generalization capability to out-of-distribution tasks such as super-resolution from different contrasts, and MR images with tumors or lesions or other disease-related biological features not present in training data.  

%
In contrast, MISR exploit information from multiple complementary views or different contrasts from the same subject\cite{wu2021irem, rousseau2010non}. 
%
Zeng et al~\cite{zeng2018simultaneous} introduced a two-stage deep convolutional neural network capable of performing both single- and multi-contrast SR reconstructions. Lyu et al~\cite{lyu2020multi} proposed a progressive network designed for high up-sampling multi-contrast MRI, which learns shared features in a joint representation space. Feng et al further advanced the field with  multi-stage integration networks~\cite{feng2021multi} and separable attention modules~\cite{feng2024exploring} to restore target-contrast images by leveraging auxiliary contrast images through cross-contrast feature exploration.
%
Moreover, transformer-enabled frameworks~\cite{li2023multi, lyu2023multicontrast, li2022transformer, li2022wavtrans, li2024rethinking, li2023dudoinet} have been used to enhance joint feature space learning, providing a significant enhancement in multi-resolution SR performance.
However, all these SRR methods typically require extensive high-resolution ground truth datasets for training, which are scarce or not available at mesoscale ($<0.5mm$) resolution. Further, these methods generalize poorly to new types of data \cite{willemink2022toward} or to the presence of biological abnormalities such as tumors or lesions. 

Another alternative is to use ultra-high magnetic field strength such as the 11.7T scanner which reported 0.55mm isotropic resolution for T2w imaging \cite{boulant2024vivo} or a specialized head-only scanner such as the Impulse 7T scanner \cite{feinberg2023next} which demonstrated a resolution of 0.45mm isotropic voxel size. However, such scanners are one-of-a-kind scanners not widely available.

%
Implicit Neural Representations (INRs) have emerged as a powerful approach for learning continuous signal representations from discrete samples without requiring any training datasets, driving recent advancements in signal representation~\cite{sitzmann2020implicit, dwedari2024estimating, consagra2024neural}. Unlike traditional methods that store signal values discretely on coordinate grids, INRs represent the signal as a continuous function using trainable neural networks, particularly multi-layer perceptrons (MLPs)~\cite{mildenhall2021nerf}. By approximating the complex relationships between coordinates and their corresponding signal values, INRs produce continuous signal representations. INRs fall in the class of self-supervised learning techniques that utilize inherent patterns within the data itself, removing reliance on explicitly paired datasets and thereby generalizing to diverse tasks. The flexibility and effectiveness of INRs have led to their application in various medical imaging tasks~\cite{ye2023super, mcginnis2023single}, including supervised 3D super-resolution~\cite{wu2022arbitrary}, tumor progression assessment from sparsely sampled images~\cite{shen2022nerp}, and isotropic reconstruction from a single anisotropic image~\cite{zhang2023self}. However, none of these techniques address the problem of mesoscale super-resolution from multi-view thick slice data without a-priori training.

Existing periodic activation function based INRs, termed as SIREN-based INR's~\cite{sitzmann2020implicit}, process point-wise coordinates using a single-head MLP. However, they often struggle to fully capture both local details and global features in large-scale signals, as training the extremely large MLPs required for such tasks is challenging~\cite{xie2022neural}, thereby limiting the reconstruction quality. To overcome these challenges, a multi-scale hashing encoding-based INR method has been proposed \cite{muller2022instant, dwedari2024estimating}. By mapping spatial coordinates into compact multi-scale hash tables, this approach significantly enhances computational and storage efficiency while effectively capturing multi-resolution information, thus improving the model’s representational capacity. We propose to use this method in our work to reconstruct multi-view MRI data. 

% \section{Our contributions}
In this work, we propose several novel contributions to enable rapid mesoscale MRI. First, we develop a multi-scale INR method that learns a continuous image reconstruction from multi-view (rotated) thick slice MR images. The continuous model is then sampled to produce a single high isotropic resolution MR image volume. 
% tailored multi-scale INR method that takes as input multi-view (rotated) thick slice MR image volumes and combines information from them to produce a single high isotropic resolution MR image volume. 
We note that, this is the first time INRs have been tailored to represent such high resolution data (each image dimension with more than 1000 voxels) in the medical imaging context. Second, we validate the performance of our method on $0.125 mm$ ex-vivo monkey data, where ground truth data is available. We also quantitatively compare our method with the current state-of-the-art method for multi-view reconstruction, termed least-squares super-resolution reconstruction (LS-SRR)\cite{vis2021accuracy, dong2024romer} using metrics such as full-width half maximum (FWHM)\cite{manzano2024denoising}  that characterize the amount of smoothness in the data. Third, we demonstrate excellent performance of our method from sparse set of views, thereby allowing to reduce scan time by a factor of 2. We demonstrate the performance of our method on several in-vivo human datasets, but notably, we demonstrate the ability to reconstruct the highest resolution to-date of whole brain in-vivo human T2w image at $180 \mu m$ isotropic resolution in 17 minutes. %To our knowledge, the highest isotropic resolution for T2w image acquired to-date is using the 11.7T scanner\cite{boulant2024vivo} at $550 \mu m$, which is 9-times larger voxel size compared to our technique.

%The integration of self-supervised learning into this framework further strengthens its ability to capture fine-grained details and global structures in high-resolution MRI reconstruction tasks. 
%In this study, we aim to validate the performance of multi-scale hashing encoding-based INR in MRI super-resolution reconstruction and provide a systematic evaluation of its potential benefits.

\begin{figure*}[t]
\centerline{\includegraphics[width=\textwidth, angle=0]{Fig1.eps}}
\caption{Overview of the ROVER-MRI framework. \textbf{(A) Data Acquisition}: Eight low-resolution images are acquired with varying slice orientations to ensure comprehensive spatial coverage. \textbf{(B) SR Reconstruction}: A neural network-based implicit representation maps RAS spatial coordinates to pixel values, enabling high-quality super-resolution reconstruction. \textbf{(C) Coordinate Mapping}: Matrix coordinates from low-resolution images are preprocessed to extract precise image values for reconstruction. \textbf{(D) ROVER-MRI}: Multi-resolution hash encoding integrates spatial mapping, voxel hashing, feature retrieval, and auxiliary input concatenation to achieve enhanced reconstruction performance.}\label{fig1}
\end{figure*}

\section{METHODS}
\subsection{Acquisition Strategy}
% \begin{figure*}[t]
% \centerline{\includegraphics[width=0.7\textwidth]{Fig2.pdf}}
% \caption{This is the sample figure caption.}\label{fig1}
% \end{figure*}
To achieve super-resolution reconstruction, multiple low-resolution datasets are combined to achieve high isotropic resolution. In this study, as depicted in Figure~\ref{fig1}(A), we acquired thick-slice images (but high in-plane resolution) by systematically rotating the acquisition around the phase-encoding axis, following the multi-stack rotational acquisition method introduced by Shilling et al~\cite{shilling2008super}. The theoretical minimum number of rotations ($N_R$) required to reconstruct isotropic voxel resolution is determined based on the geometric framework for super-resolution reconstruction developed by Plenge et al~\cite{plenge2012super}, as expressed in the following equation:
%
\begin{equation}
\label{eq1}
N_R \geq \frac{\pi}{2} \cdot \alpha,
\end{equation}
%
where $\alpha$ represents the ratio of the longer to shorter dimensions of a voxel. Additionally, as noted by Edelstein et al~\cite{edelstein1986intrinsic}, the SNR in multi-slice imaging is strongly influenced by voxel volume, with larger voxels typically providing enhanced SNR.

The generation of a low-resolution image ($\mathbf{LR}^v$) from a high-resolution image ($\mathbf{y}$) can be described mathematically as follows: 
%
\begin{equation}
\label{eq2}
\mathbf{LR}^v=\mathbf{H}_v \mathbf{y}+\mathbf{n}_v,
\end{equation}
%
where $v$ denotes a specific low-resolution sample, while $\mathbf{n}_v$ is random Gaussian vector modeling the measurement noise. The matrix $\mathbf{H}_v$ encapsulates the cumulative effects of geometric transformations, resolution downsampling, and blurring applied to the high-resolution input. This matrix is influenced by factors such as image dimensions, anisotropic voxel sizes, and the slice profile, which is modeled in this study using a rectangular function.
%
\subsection{Coordinate Mapping}
Figure~\ref{fig1}(B) illustrates the coordinate mapping process used in super-resolution reconstruction, showcasing the transformation of low-resolution voxel coordinates $(i,j,k)$ to a unified high-resolution real-world coordinate system $(r,a,s)$.

First, the low-resolution input image ($LR^v$ ) is represented in the original coordinate system, denoted by $(x,y,z)$, with distinct voxel locations visualized as green, pink, and blue points. This representation encapsulates the anisotropic resolution of the original acquisition. 
%
Then, to map the low-resolution data into a common high-resolution space, an affine transformation is applied. The transformation matrix ($\varphi$) includes both rotational and translational components. Rotation is parameterized by an angle $\alpha$, while translation accounts for slice-specific offsets, such as $c_y$ and 
$c_z$. The last element in the fourth column, $R$ represents the scale in space (commonly $R=1$, indicating no scaling).
%
The affine matrix is defined as:
\begin{equation}
\varphi=\left[\begin{array}{cccc}
1 & 0 & 0 & 0 \\
0 & \cos (\alpha) & -\sin (\alpha) & c_y(1-\cos (\alpha))+c_z \sin (\alpha) \\
0 & \sin (\alpha) & \cos (\alpha) & c_z(1-\cos (\alpha))-c_y \sin (\alpha)\\
0 & 0 & 0 & R
\end{array}\right],
\label{eq3}
\end{equation}
%
enabling the systematic alignment of slices in the reconstructed coordinate system. The affine-transformed coordinates are passed through a spatial transform module, which interpolates the voxel intensities from the low-resolution grid $(i,j,k)$ to the high-resolution coordinate space $(r,a,s)$. This module ensures spatial consistency and accuracy during the reconstruction process.
%
Finally, the transformed high-resolution voxel grid is represented in the $(r,a,s)$ space, with the interpolated intensities forming the high-resolution reconstruction. The high-resolution representation, visualized as finer spatial grids, reflects improved isotropic resolution and structural integrity.

\subsection{Image reconstruction using ROVER-MRI}
Figure~\ref{fig1}(C) illustrates our SRR technique using coordinate mapping and ROVER-MRI. The input to the network are the $(r,a,s)$ spatial coordinates in the image field, while the output is the corresponding pixel value.  

\subsubsection{Implicit Neural Representation}
INRs model signals, such as images or volumetric data, as continuous and differentiable functions parameterized by neural networks. INRs take spatial coordinates $x$ as input and output the corresponding signal value $y_i$, formally expressed as:
\begin{equation}
\mathcal{M}(\boldsymbol{\theta}) : \mathbb{R}^\mathrm{dim} \to \mathbb{R}, \quad \mathbf{x}_i \mapsto \mathcal{M}(\boldsymbol{\theta}; \mathbf{x}_i) = y_i,
\end{equation}
where $\mathcal{M}$ represents a neural network parameterized by $\theta$, and $\operatorname{dim}$ denotes the dimensionality of the spatial domain.

This framework allows signals to be represented efficiently at any desired resolution by querying their values at continuous spatial coordinates. Such a representation is particularly advantageous in tasks like encoding image data~\cite{sitzmann2019deepvoxels}, modeling 3D shapes~\cite{gao2022get3d}, and performing neural rendering~\cite{wysocki2024ultra}. Early methods that utilized sinusoidal encodings within a single global MLP-based representation often struggle to capture high-frequency details in large-scale signals. These issues arise from prohibitively long training times and diminishing representational capacity of the very large MLPs necessary for such a global parameterization~\cite{xie2022neural}. To address these challenges, recent innovations have introduced advanced encoding techniques~\cite{hamming1952mathematical}, improved activation functions~\cite{sitzmann2020implicit,saragadam2023wire}, and optimized network structures~\cite{kazerouni2024incode,zhu2024disorder}, all of which significantly enhance the representational power of INRs.

One notable advancement is the use of position-aware architectures, often paired with multi-resolution encoding techniques like hash grids, to capture fine details in signals without incurring high memory costs. By leveraging these developments, INRs have proven to be highly effective at modeling complex signal structures while remaining computationally efficient. These advancements have positioned INRs as a cornerstone of modern machine learning, enabling precise and continuous signal representations across a variety of applications.

\subsubsection{Multi-scale Hash Grid Encoding}
The multi-resolution hash grid representation is a pivotal technique designed to enhance the efficiency of INRs while maintaining high spatial fidelity~\cite{muller2022instant}. This approach employs a multi-resolution hash grid encoder to map input coordinates ${x} \in[0,1]^d$, where $d$ is the spatial dimension, into high-dimensional feature vectors $\mathbf{h} \in \mathbb{R}^{L \cdot F}$. These feature vectors of dimension $F$ are parameterized across $L$ resolution levels, with each level storing its features in hash table $H$. This hierarchical representation captures features across varying spatial scales, enabling efficient encoding of both global and local details.

To extract features, the input domain is divided into 
$L$ levels of grids, where each grid level $l$ has a resolution $N_l$ defined as:
\begin{equation}
N_l=\left\lfloor N_{\min } \cdot b^{l-1}\right\rfloor, \quad b=\exp \left(\frac{\ln N_{\max }-\ln N_{\min }}{L-1}\right).
\end{equation}
The scaling factor $b$ ensures that grid resolutions increase exponentially from the coarsest resolution 
$N_{min}$  to the finest $N_{max}$ . At the finest levels, the vertex count grows significantly, but memory overhead is controlled by using hash tables for feature storage. The feature lookup is performed via a hash function:
\begin{equation}
h(\mathbf{x})=\left(\bigoplus_{i=1}^d x_i \pi_i\right) \bmod T,
\end{equation}
where $\pi_i$ are unique, large prime numbers, $T$ denotes the hash table size, and $\oplus$ is the bitwise XOR operation. This hashing mechanism ensures efficient memory utilization by assigning unique indices to grid vertices while minimizing hash collisions. Due to the multi-resolution structure, the likelihood of collisions across all levels is negligible, even as the resolution increases.
%
Finally, the encoded features are passed to a fully connected neural network %$m(\mathbf{y} ; \Phi)$,
where the network resolves the target function or vector field. This combination of multi-resolution hash grids and compact neural networks supports high spatial resolution while minimizing memory usage. This architecture is particularly effective for applications requiring fine spatial details in large-scale signals.
%demanding efficient representation of fine spatial details.

For a given input point, features are interpolated within each grid level by calculating weights 
$\mathbf{w}_l=\mathbf{x}_l-\left\lfloor\mathbf{x}_l\right\rfloor$, where $\left\lfloor \right\rfloor$ is the floor operator. These weights enable smooth blending of feature values between grid vertices. The interpolated feature vectors from all $L$ levels are then concatenated and optionally combined with auxiliary inputs $\xi$, which represent the spatial coordinates themselves, forming the encoded representation $\mathbf{h}=\operatorname{enc}(\mathbf{x} ; \xi)$.
% Multi-scale hash grid encoding is a novel approach that enhances the approximation accuracy and training efficiency of implicit neural representations (INRs) across various applications without significant computational overhead. This method encodes input coordinates $x$ into feature vectors $\phi(\mathbf{x} ; \theta)$, which are passed to a neural network $m(\mathbf{y} ; \Phi)$. Alongside the network weights $\Phi$, the encoding parameters $\theta$ are trainable, allowing flexible representation of low- and high-frequency details.

% The encoding framework divides the input space into $L$ hierarchical grid levels. Each grid level $l$ stores feature vectors at the vertices of a grid, with the resolution $N_l$ following a geometric progression between the coarsest resolution $N_{min}$ and the finest resolution $N_{max}$:
% \begin{equation}
% N_l=\left\lfloor N_{\min } \cdot b^l\right\rfloor, \quad b=\exp \left(\frac{\ln N_{\max }-\ln N_{\min }}{L-1}\right) .
% \end{equation}
% Typical values for $b$ range from 1.26 to 2. Each voxel spans $2^d$ vertices, and feature vectors at these vertices are stored in hash tables to reduce memory usage at finer levels. The hash function used is:
% \begin{equation}
% h(\mathbf{x})=\left(\bigoplus_{i=1}^d x_i \pi_i\right) \quad \bmod T,
% \end{equation}
% where $\pi_i$ are large prime numbers, $T$ is the table size, and $\oplus$ denotes the bitwise XOR operation. This design ensures decorrelation and pseudo-independence across dimensions, as described in .

% The interpolation weights $\mathbf{w}_l=\mathbf{x}_l-\left\lfloor\mathbf{x}_l\right\rfloor$ are calculated for each voxel, enabling smooth blending of feature vectors. These interpolated feature vectors are concatenated across all levels and optionally augmented with auxiliary inputs, producing the final encoding 
% $\phi(\mathbf{x})$. By efficiently capturing multi-scale features, this method supports high-resolution applications while minimizing computational costs, as discussed in Table 1.

As illustrated in Figure~\ref{fig1}(D), the entire process of reconstructing the final isotropic resolution image can be summarized in the following steps: (1) we map the input coordinates to a common RAS coordinate system through an affine transformation. (2) We then hash the 3D image coordinates into grid cells, efficiently assigning unique codes to each voxel for optimized memory and computation. (3) These hash codes are used to look up the corresponding feature embeddings from a hash table, greatly reducing processing time. (4) Next, we apply linear interpolation to these embeddings to produce smooth, high-resolution transitions across the grid. (5) Features from multiple resolution levels are concatenated, enabling the model to capture fine details and broader structures. (6) Finally, a MLP maps the combined features to predict the super-resolved image.

\subsection{Loss Functions}
To achieve high-quality image reconstruction, the proposed method incorporates a loss function specifically designed for super-resolution tasks. It includes two main components: a reconstruction loss and total variation (TV) regularization. The reconstruction loss enforces consistency between the predicted output and the LR acquired data, ensuring accurate data representation. Meanwhile, TV regularization acts as a prior, promoting smoothness and reducing noise or artifacts in the reconstructed images. By combining these two components, the framework effectively balances precise alignment with the input data and the generation of visually appealing and coherent outputs.


\subsubsection{Reconstruction Loss}
The reconstruction loss is formulated using the Mean Squared Error (MSE), adapted for super-resolution tasks. The high-resolution predictions are averaged along the super-resolution direction to generate a downsampled version that matches the resolution of the low-resolution ground truth $LR^v$. The loss is defined as:

\begin{equation}
\mathcal{L}_{\mathrm{MSE}}=\frac{1}{N} \sum_{i=1}^N\left\|L R_i^v-\hat{y}_i^{\mathrm{avg}}\right\|^2
\end{equation}
%
where $LR^v$ denotes the low-resolution ground truth, $\hat{y}_i^{\mathrm{avg}}$ is obtained by passing the estimated high-resolution predictions through the $\mathbf{H}_v$ operator, and $N$ is the total number of data points. By penalizing the squared differences between the averaged predictions and the low-resolution ground truth, the MSE loss ensures that the model outputs are consistent with the observed data. This loss is crucial for guiding the network to accurately capture the underlying structure of the input and is particularly well-suited for image super-resolution and restoration tasks.

\subsubsection{TV Regularization}
Total Variation (TV) regularization is a gradient-based prior designed to improve the structural consistency of reconstructed images. By penalizing gradient variations in the predicted output, it promotes smoothness in regions of uniform intensity while preserving sharp edges. The TV loss is formulated as:
\begin{equation}
\mathcal{L}_{\mathrm{TV}}=\frac{1}{M} \sum_{j=1}^M\left\|\nabla \hat{y}_j\right\|,
\end{equation}
where $\nabla \hat{y}_j$ represents the gradient of the predicted output, and $M$ is the total number of samples. This regularization effectively reduces noise and suppresses unwanted high-frequency artifacts, which are often present in inverse problems like image reconstruction.

To incorporate TV regularization into the overall optimization process, a weighting parameter $\lambda_c$ is introduced to control its contribution. The combined loss function is expressed as:
\begin{equation}
\mathcal{L}=\mathcal{L}_{\mathrm{MSE}}+\lambda_c \cdot \mathcal{L}_{\mathrm{TV}}.
\label{eq9}
\end{equation}
Here, $\lambda_c$ balances the trade-off between the data fidelity term ($\mathcal{L}_{\mathrm{MSE}}$) and the smoothness prior ($\mathcal{L}_{\mathrm{TV}}$). Adjusting $\lambda_c$ allows the framework to prioritize either reconstruction accuracy or structural regularity, depending on the specific demands of the task. This flexibility ensures that the approach can adapt to various scenarios while maintaining high-quality outputs. 
%
\begin{figure*}[t]
\centerline{\includegraphics[width=0.9\textwidth, angle=0]{Fig2.eps}}
\caption{Reconstruction results on simulated LR data using Bicubic interpolation, LS-SRR, and ROVER-MRI. The first and third rows show reconstructed sagittal MRIs, while the second and fourth rows present the corresponding error maps calculated against the GT. The red and green boxes highlight zoomed-in regions, which allow a closer inspection of the reconstruction quality. Bicubic interpolation exhibits significant blurring, LS-SRR shows streaking artifacts and fails to maintain vascular sharpness, while ROVER-MRI achieves continuous vascular structures with minimal errors. The yellow boxes on the right further magnify specific regions, emphasizing the superior performance of ROVER-MRI in preserving fine structural details and reducing artifacts, compared to Bicubic and LS-SRR.
}\label{fig2}
\end{figure*}
%
\subsection{EXPERIMENTS}
\subsubsection{Datasets}
We performed extensive experiments to evaluate ROVER-MRI using the following four datasets. The experiments in this study were conducted following approval from the local Institutional Review Boards (IRBs). Informed consent was provided before the in-vivo human scan.
\begin{itemize}
\item \textbf{Ex-vivo monkey MRI Data} 
We acquired high-resolution T2-weighted ex-vivo images of a monkey brain on a 9.4T Bruker scanner (PharmaScan; Bruker BioSpin, Ettlingen, Germany) with a spatial resolution of 0.125$\times$0.125$\times$0.125 mm$^{3}$ using a 3D RARE sequence. The imaging parameters were: TR = 1.0 s, TE = 0.02 ms, Flip Angle(FA) = 180 degree. This dataset served as the ground truth for all validation purposes with low-resolution data generated through simulation (downsampling) as follows:
%. We acknowledge that the acquisition is inherently three-dimensional, and super-resolution is not typically applicable when phase encoding is used in the partition axis. However, this dataset was used purely for simulation purposes. Through simulations, we generated low-resolution data 
(0.125$\times$0.125$\times$0.625 mm$^{3}$) for each of the 8 views separated by 22.5$^\circ$ to satisfy the Nyquist criteria for a super-resolution factor of 5 in the slice dimension.  

\item \textbf{Human in-vivo 7T MRI Data}
For Participant 1 (P1), T2-weighted images were acquired using a 7T Siemens Terra scanner (Siemens Healthineers, Erlangen, Germany, with a single transmission 32-channel head coil) at 15 distinct rotation angles, separated by 12$^\circ$. Each of the rotated views were acquired at a resolution of 0.18$\times$0.18$\times$2.00 mm$^{3}$, with a total scan time of approximately 34 minutes and a super-resolution factor of 11 in the slice dimension.

For Participant 2 (P2), 2D-GRE images were acquired (7T Siemens Terra scanner) at 9 distinct rotation angles, separated by 40$^\circ$. The spatial resolution for these images was 0.4519$\times$0.4519$\times$2.70 mm$^{3}$ with the slice dimension being 6 times the in-plane resolution. The imaging parameters were: TR = 1.45 s, TE = 4.67 ms, FA = 77 degree, acceleration factor PE = 3, number of slices = 61. The total scan time was ~45 minutes. Further, to qualitatively compare ROVER-MRI reconstruction with a full 3D acquisition, we acquired another scan (3D GRE) with a spatial resolution of 0.45mm isotropic voxels. The imaging parameters were: TR = 24.0 ms, TE = 4.67 ms, FA = 13 degree, acceleration factor PE = 3, slices per slab = 288. The scan time for this scan was about 23 minutes.

\item \textbf{Human in-vivo 3T T2w MRI Data}
On a 3T Siemens Prisma scanner (32 channel head coil), we acquired T2-weighted images at 8 different rotation angles, spaced 22.5$^\circ$ apart. The images were captured with a spatial resolution of 0.42$\times$0.42$\times$2.12 mm$^{3}$ to enable a super-resolution reconstruction by a factor of 5 in the slice dimension. The imaging parameters were: TR = 2.5 s, TE = 0.202 ms, FA = 120 degree. 

To acquire low-resolution datasets, slices were rotated around a stationary axis oriented along the anterior-posterior direction. The field-of-view (FOV) was strategically designed to include the entire object with sufficient margins, ensuring precise coverage for SRR. The minimum number of rotation angles required for each dataset was computed using Eq.\ref{eq1}. %Simulated low-resolution images were subsequently generated using the framework outlined in Eq.\ref{eq2}. 
In all experiments, high-resolution images were reconstructed from the low-resolution data, following the framework described in section 3.3.2 (Figure~\ref{fig1}(D)).
\end{itemize}

% \subsubsection{Ex-vivo monkey MRI Data}
% We acquired high-resolution T2-weighted ex-vivo images of a monkey brain on a 9.4T Bruker scanner (PharmaScan; Bruker BioSpin, Ettlingen, Germany) with a spatial resolution of 0.125$\times$0.125$\times$0.125 mm$^{3}$ using a 3D RARE sequence. The imaging parameters were: TR = 1.0 s, TE = 0.02 ms, Flip Angle(FA) = 180 degree. This dataset served as the ground truth for all validation purposes with low-resolution data generated through simulation (downsampling) as follows:
% %. We acknowledge that the acquisition is inherently three-dimensional, and super-resolution is not typically applicable when phase encoding is used in the partition axis. However, this dataset was used purely for simulation purposes. Through simulations, we generated low-resolution data 
% (0.125$\times$0.125$\times$0.625 mm$^{3}$) for each of the 8 views separated by 22.5$^\circ$ to satisfy the Nyquist criteria for a super-resolution factor of 5 in the slice dimension. 

% \subsubsection{Human in-vivo 7T MRI Data}
% For Participant 1 (P1), T2-weighted images were acquired using a 7T Siemens Terra scanner (Siemens Healthineers, Erlangen, Germany, with a single transmission 32-channel head coil) at 15 distinct rotation angles, separated by 12$^\circ$. Each of the rotated views were acquired at a resolution of 0.18$\times$0.18$\times$2.00 mm$^{3}$, with a total scan time of approximately 34 minutes and a super-resolution factor of 11 in the slice dimension.

% For Participant 2 (P2), 2D-GRE images were acquired (7T Siemens Terra scanner) at 9 distinct rotation angles, separated by 40$^\circ$. The spatial resolution for these images was 0.4519$\times$0.4519$\times$2.70 mm$^{3}$ with the slice dimension being 6 times the in-plane resolution. The imaging parameters were: TR = 1.45 s, TE = 4.67 ms, FA = 77 degree, acceleration factor PE = 3, number of slices = 61. The total scan time was ~45 minutes. Further, to qualitatively compare ROVER-MRI reconstruction with a full 3D acquisition, we acquired another scan (3D GRE) with a spatial resolution of 0.45mm isotropic voxels. The imaging parameters were: TR = 24.0 ms, TE = 4.67 ms, FA = 13 degree, acceleration factor PE = 3, slices per slab = 288. The scan time for this scan was about 23 minutes.

% \subsubsection{Human in-vivo 3T T2w MRI Data}
% On a 3T Siemens Prisma scanner (32 channel head coil), we acquired T2-weighted images at 8 different rotation angles, spaced 22.5$^\circ$ apart. The images were captured with a spatial resolution of 0.42$\times$0.42$\times$2.12 mm$^{3}$ to enable a super-resolution reconstruction by a factor of 5 in the slice dimension. The imaging parameters were: TR = 2.5 s, TE = 0.202 ms, FA = 120 degree. 

% To acquire low-resolution datasets, slices were rotated around a stationary axis oriented along the anterior-posterior direction. The field-of-view (FOV) was strategically designed to include the entire object with sufficient margins, ensuring precise coverage for SRR. The minimum number of rotation angles required for each dataset was computed using Eq.\ref{eq1}. %Simulated low-resolution images were subsequently generated using the framework outlined in Eq.\ref{eq2}. 
% In all experiments, high-resolution images were reconstructed from the low-resolution data, following the framework described in section 3.3.2 (Figure~\ref{fig1}(D)).

\subsubsection{Implementation}
All RAS coordinates and MR image intensities were normalized to [0,1]. 
%
In all experiments, we use an MLP with two hidden layers that have a width
of 192 neurons, SineLayer~\cite{sitzmann2020implicit} on their hidden layers, and a linear output layer. The hash encoding parameters and $\lambda_c$ in the loss function were set as given in Table~\ref{tab1}.
%
The training utilized the Adam optimizer with a learning rate of $10^{-4}$ over 10000$\sim$28000 iterations on a single A100 GPU. For comparison, we benchmarked our approach against two SRR methods: bicubic and least-squares SRR (LS-SRR)~\cite{vis2021accuracy}. 
% 
Both visual comparison and quantitative evaluation were used for performance evaluation. For a quantitative evaluation, the relative error (RE) was calculated as follows:
\begin{equation}
\text { Relative Error }=\frac{1}{V} \sum_{v=1}^V\frac{\mid { y^{v} }- { LR }^{v} \mid}{ { |LR^{v}|}}
\end{equation}
where $LR^v$ and $y^v$ represent the low-resolution thick-slice acquired data and the back-projection from the high-resolution reconstructed image respectively.

% \begin{table}[]
% \caption{Hash encoding parameters: hash table size $T$, number of feature dimensions per entry $F$, the coarsest resolution $N_{min}$ and the regularization parameter $\lambda_c$ were set based on the spatial resolution and SNR of the images. }
% \label{tab1}
% \begin{tabular}{c|c|c|c|c|c}
% \hline
%            & L  & T  & F & $N_{min}$                  & $\lambda_c$ \\ \hline
% 9.4T T2W & 11 & 25 & 2 & $2^{18}$ & 0      \\ \hline
% 7T T2W P1  & 11 & 25 & 2 & $2^{18}$ & 0      \\ \hline
% 7T GRE P2  & 11 & 25 & 3 & $2^{16}$ & $2\times10^{-5}$   \\ \hline
% 3T T2W     & 11 & 24 & 2 & $2^{15}$ & $3\times10^{-5}$   \\ \hline
% \end{tabular}
% \end{table}

\section{RESULTS}
\label{sec:RESULTS}
\subsection{Experiment 1: Validation on ex-vivo monkey MRI with known ground truth}
%

% \begin{table*}[]
% \caption{Relative Error (RE) values reflect the errors between the low-resolution ground truth (GT) images and the low-resolution images obtained by back-projecting the reconstructed images from different methods.}
% \label{tab2}
% \centering
% \begin{tabular}{c|cccc}
% \hline
% RE & 9.4T T2W & 7T T2W P1 & 7T GRE P2 & 3T T2W        \\ \hline
% LS-SRR         &0.4515       &   0.6727       &    0.2923     & 0.4313 \\
% ROVER-MRI   & 0.3504          &   0.5956        & 0.2601          & 0.4275 \\ \hline
% \end{tabular}
% \end{table*}

%
We first validated our proposed method on ex-vivo monkey data, where ground truth is available, providing a reliable basis for quantitative and qualitative comparisons. Figure~\ref{fig2} illustrates the reconstruction results using bicubic, LS-SRR and our proposed ROVER-MRI methods, highlighting the differences in performance across methods. 
%
The bicubic interpolation method exhibits pronounced blurring of fine cerebellar structures and brain tissue boundaries, as evident in the magnified regions (yellow boxes). The LS-SRR method improves sharpness but introduces noticeable streaking artifacts, compromising reconstruction quality. Additionally, the error maps highlight that LS-SRR struggles to preserve fine structural boundaries, as evident in the residual error maps (red and green boxes). While LS-SRR performs better than bicubic interpolation, these artifacts and errors limit its effectiveness in preserving anatomical accuracy.

In contrast, ROVER-MRI demonstrates superior performance by minimizing residual errors and effectively restoring fine details with high fidelity. %The vascular structures reconstructed by ROVER-MRI are continuous, sharp, and free of artifacts, as shown in both the magnified views and the error maps.
%
Table~\ref{tab2} summarizes the Relative Error (RE) comparisons for different MRI reconstruction methods (LS-SRR and ROVER-MRI) across various imaging scenarios. The results demonstrate that ROVER-MRI consistently outperforms SRR in most conditions, achieving lower RE by approximately 22.4\% compared to LS-SRR. 
%
The clear preservation of structural integrity, particularly in the cerebellum, underscores the superior performance of our approach. These results highlight the robustness of our method in maintaining anatomical precision, which is crucial for downstream analyses.

\subsection{Experiment 2: Validation with fewer views and low SNR data}
%
\begin{figure*}[t]
\centerline{\includegraphics[width=0.9\textwidth, angle=0]{Fig3.eps}}
\caption{Reconstruction results of our method and LS-SRR using fewer views. (A) LS-SRR reconstruction results, showing increased error as the view count decreases. (B) ROVER-MRI reconstruction results, demonstrating high-quality reconstruction even with fewer views. Rows 1 and 4 display typical reconstruction results, while Rows 2 and 5 show enlarged views of the regions within the red boxes. Rows 3 and 6 show the error maps for these regions, highlighting the superior reconstruction accuracy of ROVER-MRI compared to LS-SRR.}\label{fig3}
\end{figure*}
%
%
\begin{figure*}[t]
\centerline{\includegraphics[width=0.9\textwidth, angle=0]{Fig4.eps}}
\caption{Reconstruction results of our method and LS-SRR with varying noise levels. (A) LS-SRR results under added noise, where reconstructions at SNR 30 show reduced error compared to SNR 15. (B) ROVER-MRI reconstructs cleaner images with significantly reduced errors compared to LS-SRR at both SNR levels. Rows 1 and 4 display typical reconstruction results, while Rows 2 and 5 show enlarged views of the regions within the red boxes. Rows 3 and 6 show the error maps for these regions, emphasizing the robustness of ROVER-MRI against noise.}\label{fig4}
\end{figure*}
%
%
\begin{figure}[t]
\centerline{\includegraphics[width=0.5\textwidth, angle=0]{Fig5.eps}}
\caption{SRR results at 180 µm isotropic resolution. LS-SRR introduces streaking artifacts, which degrade the image quality. In contrast, our ROVER-MRI method demonstrates superior performance, preserving sharper and more continuous anatomical structures while achieving improved SNR. }\label{fig5}
\end{figure}
%
Next, we evaluated the performance of all methods when fewer than $N_R$ views are used to reconstruct the data. As shown in Figure~\ref{fig3}(A), the LS-SRR method exhibits noticeable boundary artifacts (yellow arrows), and smoothing of fine anatomical details (white arrows) when 6 or 4 views are used. In contrast, Figure~\ref{fig3}(b) demonstrates the performance of ROVER-MRI, which effectively suppresses boundary artifacts and minimizes residual errors, ensuring superior reconstruction quality even with fewer views. Notably, when the number of views is halved to 4, ROVER-MRI maintains high-quality reconstruction, demonstrating its robustness in balancing speed and accuracy. This capability underscores its potential to significantly reduce acquisition time by 2-fold while preserving fine anatomical details.

In Figure~\ref{fig4}we show the performance in the presence of different levels of noise. The residual maps for LS-SRR reveal prominent errors, as highlighted by the yellow arrows, particularly in regions with fine structural details. These errors become more severe at a lower SNR of 15, indicating the method's vulnerability to noise. Similarly, as shown by the white arrows, residual artifacts persist across the reconstruction, further compromising image fidelity. In contrast, Figure~\ref{fig4}(b) shows the residual maps for ROVER-MRI, which exhibit significantly reduced errors and better preservation of structural details, even under noisy conditions. At both SNR=15 and SNR=30, our method consistently outperforms LS-SRR. 

Table~\ref{tab3} compares the FWHM values for different reconstruction methods (LS-SRR and ROVER-MRI) under varying conditions, including the number of views (8, 6, and 4 views) and signal-to-noise ratios (SNR 30 and SNR 15). These values are estimated from the residual maps using the smoothest tool in FSL\cite{manzano2024denoising, jenkinson2012fsl,flitney2000cluster}. The results show that ROVER-MRI achieves consistently lower FWHM values than LS-SRR, indicating better spatial resolution and sharper reconstructions.
%
For the different number of views, ROVER-MRI demonstrates improved performance with FWHM reductions of approximately 7.5\% to 17.9\% compared to LS-SRR. Specifically, with 4 views, ROVER-MRI achieves a FWHM that is 17.9\% lower than LS-SRR, showing its robustness in reduced acquisition settings.
%
Under different SNR conditions, ROVER-MRI exhibits FWHM values that are consistently closer to the ground truth. For SNR 30, ROVER-MRI achieves a reduction of approximately 6.4\% compared to LS-SRR, while for SNR 15, the improvement is 21.1\%, highlighting its superior noise robustness.
%
%These findings underscore the effectiveness of ROVER-MRI in delivering sharper reconstructions with minimal degradation in both low-view and low-SNR scenarios, as confirmed by the consistency of its FWHM values with the ground truth.

\subsection{Experiment 3: Performance on 7T MRI}
\subsubsection{7T T2w-SPACE MRI with 15 views}
%
\begin{figure}[t]
\centerline{\includegraphics[width=0.5\textwidth, angle=0]{Fig6.eps}}
\caption{ROVER-MRI results with reduced number of views. The image reconstructed by 15 views was used as a reference. Difference map in the last column shows very little loss in structural details.}\label{fig6}
\end{figure}
%
Figure~\ref{fig5}illustrates SRR reconstructions at an isotropic resolution of 180 µm, recovering data from a super-resolution factor of 11 in the slice direction. The original LR images exhibit prominent block artifacts, indicative of the resolution limitations inherent to thick-slice acquisitions. While the LS-SRR method improves upon the LR images by enhancing spatial resolution, it introduces pronounced streaking artifacts, which compromises the clarity of fine structures. Additionally, LS-SRR fails to effectively restore fine details, resulting in blurred and discontinuous structures. 
%
In contrast, ROVER-MRI achieves reconstructions with sharp structural details and enhanced SNR, preserving the integrity of fine anatomical features. According to Table~\ref{tab2}, ROVER-MRI achieves a lower RE, with a reduction of approximately 11.5\% compared to LS-SRR. The method demonstrates its ability to minimize artifacts and recover mesoscale structures with high fidelity, even under challenging super-resolution settings. This underscores the robustness and reliability of ROVER-MRI in producing high-quality images that are critical for accurate interpretation and analysis.

Furthermore, Figure\ref{fig6}presents reconstruction results from datasets with fewer views (8 interleaved views, requiring only approximately 17 minutes of scan time). Remarkably, these results display similar mesoscale details compared to reconstructions from 15 views, highlighting the efficiency of ROVER-MRI in maintaining high image quality with reduced acquisition time. Thus, ROVER-MRI can achieve substantial time savings without sacrificing structural detail, making it a highly practical solution for research applications.

\subsubsection{7T GRE MRI with 9 views}
\begin{figure}[t]
\centerline{\includegraphics[width=0.5\textwidth, angle=0]{Fig7.eps}}
\caption{Sagittal brain 7T T2 MRIs reconstructed using three methods: Bicubic, LS-SRR, and ROVER-MRI. The first and third rows display the reconstructed images for each method.
The second and fourth rows present zoomed-in regions (indicated by red and green boxes) for detailed comparison. The magnified areas highlight structural differences, where ROVER-MRI exhibits enhanced structural clarity and effectively reduces artifacts compared to LS-SRR and Bicubic, demonstrating its superior reconstruction performance.}\label{fig7}
\end{figure}

Figure~\ref{fig7}illustrates a comparison of sagittal brain MR images reconstructed using Bicubic interpolation, LS-SRR, and ROVER-MRI. The zoomed-in regions, marked by red and green boxes, highlight key differences in detail preservation and artifact suppression. %Bicubic interpolation results in heavily blurred local regions, failing to capture structural details. LS-SRR improves sharpness but introduces noticeable artifacts and lacks sufficient clarity in vascular structures. 
Here too, ROVER-MRI shows superior performance, displaying continuous and artifact-free structures with enhanced sharpness. Table~\ref{tab2} shows that ROVER-MRI achieves a noticeably lower RE with a reduction of approximately 11\%.%These results underline the ability of ROVER-MRI+ to more effectively recover fine anatomical details and maintain overall image quality compared to the other methods.

\subsubsection{7T GRE MRI with 5 views}
\begin{figure}[t]
\centerline{\includegraphics[width=0.5\textwidth, angle=0]{Fig8.eps}}
\caption{Comparison of reconstruction results from 5 views with 3D GRE acquisition. Both SRR algorithms exhibit finer anatomical details than 3D GRE.}\label{fig8}
\end{figure}
We also compared ROVER-MRI images reconstructed from 5 views with the data obtained using the 3D-GRE sequence in the same scan time of about 23 minutes. Both LS-SRR and ROVER-MRI outperformed the 3D-GRE data in detail restoration. ROVER-MRI showed superior reconstruction quality compared to LS-SRR. In the red box, ROVER-MRI provided better continuity of blood vessels, and in the green box, it suppressed artifacts more effectively, leading to a clearer and more accurate depiction of anatomical structures. We also note that the SNR is much higher for the ROVER-MRI reconstruction compared to 3D-GRE (although the 3D-GRE scan could be optimized for better SNR by changing the flip angle and relaxation time). However, in this study we set the parameters to match the scan time.

\subsection{Experiment 4: Performance on T2w MRI from 3T scanner}
\begin{figure}[t]
\centerline{\includegraphics[width=0.5\textwidth, angle=0]{Fig9.eps}}
\caption{3T T2-weighted brain MRI reconstructed using three different methods. The first and third rows show the reconstruction, while the second and fourth rows present zoomed-in views of the regions marked by yellow boxes. ROVER-MRI demonstrates superior preservation of fine structural details and improved sharpness compared to Bicubic interpolation and LS-SRR.}\label{fig9}
\end{figure}
%
Figure~\ref{fig9}illustrates the qualitative comparison of reconstructed sagittal brain MR images using Bicubic interpolation, LS-SRR, and ROVER-MRI. The zoomed-in views (second and fourth rows) highlight a marked improvement in image quality achieved by ROVER-MRI, with enhanced clarity of fine structures and significantly reduced blurring artifacts. %The numerical results in Table~\ref{tab2} are consistent with the visual results, where ROVER-MRI achieves a RE approximately 1\% lower than LS-SRR.

\begin{figure}[t]
\centerline{\includegraphics[width=0.5\textwidth, angle=0]{Fig10.eps}}
\caption{Sagittal brain MR images back-projected into the low-resolution space. The first and third rows display the back-projected images for each method. The second and fourth rows show the error maps calculated against the low-resolution ground truth (LR GT). Zoomed-in regions (indicated by white boxes) highlight structural details for closer inspection. ROVER-MRI demonstrates reduced errors and superior fidelity in preserving structural details compared to LS-SRR, as evident in the magnified regions.}\label{fig10}
\end{figure}
%
Figure~\ref{fig10}compares sagittal brain MR images back-projected into the low-resolution space. The error maps, along with magnified regions indicated by white boxes, highlight that ROVER-MRI achieves a notable reduction in reconstruction error. These results illustrate that ROVER-MRI not only preserves structural integrity more effectively but also achieves a closer approximation to the low-resolution acquired data, affirming its advantage in reconstruction accuracy.

% Please add the following required packages to your document preamble:
% \usepackage{multirow}
% \begin{table*}[]
% \caption{Full width at half maximum (FWHM)\cite{manzano2024denoising} values under different settings.}
% \label{tab3}
% \centering
% \begin{tabular}{c|ccc||cc}
% \hline
% \multirow{2}{*}{FWHM} & \multicolumn{3}{c||}{Different Number of Views} & \multicolumn{2}{c}{Different SNR} \\ \cline{2-6} 
%                       & 8 Views        & 6 Views       & 4 Views       & SNR 30           & SNR 15         \\ \hline
% LS-SRR                   & 0.1051         & 0.1221        & 0.1134        & 0.0988           & 0.1203         \\
% ROVER-MRI             & 0.1037         & 0.1034        & 0.1049        & 0.0897           & 0.0988         \\
% % Ground Truth          & -              & -             & -             & 0. 0419          & 0.0501         
% \hline
% \end{tabular}
% \end{table*}

\section{Discussion}\label{dis}
In this work, we demonstrated our ROVER-MRI framework on four mesoscale MRI datasets. Among these, the highest resolution achieved was 180 µm isotropic voxel size with high-fidelity results obtained from just 17 minutes of scan time (2x acceleration). Our results highlight significant improvements in spatial resolution, SNR, and acquisition efficiency, addressing longstanding challenges in mesoscale MRI.

The primary advantage of ROVER-MRI lies in its ability to significantly reduce acquisition time while preserving detailed anatomical structures. This is achieved through a combination of multi-view thick-slice acquisitions and an enhanced super-resolution reconstruction framework leveraging multi-resolution hash encoding. Compared to conventional SRR methods such as LS-SRR and bicubic interpolation, ROVER-MRI demonstrated superior reconstruction accuracy, offering sharper structural details and minimal artifacts (Figure~\ref{fig2}$\sim$~Figure~\ref{fig6}). Importantly, our method does not require high-resolution ground-truth datasets for training, providing a flexible and practical solution for high-resolution MRI across diverse imaging protocols.

Our experiments further reveal the robustness of ROVER-MRI in scenarios with reduced view counts and low-SNR data. As shown in Figure~\ref{fig3}and Figure~\ref{fig6}, even with 2 times fewer views (scans), reconstruction quality remained high, enabling faster scan times with minimal loss in resolution or accuracy. Additionally, ROVER-MRI outperformed LS-SRR in suppressing noise across varying SNR levels, underscoring its resilience against signal degradation. This robustness is particularly beneficial for clinical and research applications where time constraints or physiological noise might impact image quality.

Despite these advancements, several limitations must be acknowledged. First, while SRR effectively improves spatial resolution and SNR, relying on thick-slice acquisitions introduces potential challenges, such as sensitivity to head motion. These effects can reduce signal fidelity, as reported in previous studies~\cite{shilling2008super, plenge2012super}. Thus, motion and eddy current distortions may result in blurring or structural inaccuracies in the final reconstruction. Incorporating robust motion correction techniques~\cite{szczepankiewicz2019tensor} into the ROVER-MRI pipeline could further enhance the reconstruction performance.

Another limitation pertains to regularization. In this work, we manually fixed the regularization parameter. While data-drive Bayesian techniques can be used to determine the optimal regularization weight, it can be computationally impractical when dealing with such large datasets. Further, the computational time required for training INR is a bit longer than that required to estimate the data using LS-SRR. We however note that, the computational time for INRs can be significantly reduced using transfer learning techniques. %While effective, more sophisticated data-driven regularization techniques, such as using preserving edge information~\cite{khattab2020regularization}, may yield further improvements in reconstruction quality, particularly at tissue boundaries with sharp contrast. %Additionally, the multi-stack rotations employed in our SRR approach may result in signal overshoot or undershoot in regions with high contrast, as noted in previous studies~\cite{andersson2008maximum}. 
%Future research should explore strategies to mitigate these artifacts, ensuring the reliability of quantitative measures derived from reconstructed images.

%Lastly, although our results demonstrate significant improvements in SNR and spatial resolution, the performance of ROVER-MRI may still be influenced by acquisition parameters, such as T1 relaxation effects and repetition times. Previous studies suggest that larger aspect ratios can further enhance SNR efficiency~\cite{van2016super}. However, incomplete T1 recovery at short repetition times may counteract these benefits, particularly when simultaneous multi-slice techniques are employed~\cite{barth2016simultaneous}. Careful optimization of acquisition and reconstruction parameters will be essential to balance SNR efficiency, resolution, and scan time in future applications.

% \section{Conclusions}\label{con}
In summary, our results demonstrate that ROVER-MRI enables rapid, high-SNR whole-brain imaging at isotropic resolution, offering a significant advancement over existing mesoscale MR imaging methods, especially for T2w images. By integrating multi-view acquisitions with multi-resolution hash encoding, our approach achieves high-quality super-resolution reconstruction while remaining robust to noise and motion. These capabilities make ROVER-MRI well-suited for mesoscale neuroimaging studies and hold great potential for applications requiring time-efficient, high-resolution whole-brain imaging.

\section*{Acknowledgments}
This study is supported by National Institutes of Health grants: R01 NS125307, R01MH132610, R01MH125860, R01EB032378, and R01MH1192222.

% \subsection*{Author contributions}
% \emph{}
% This is an author contribution text. This is an author contribution text. This is an author contribution text. This is an author contribution text. This is an author contribution text. This is an author contribution text. 

% \subsection*{Financial disclosure}
% None reported.

% \subsection*{Conflict of interest}
% The authors declare no potential conflict of interests.

\bibliography{MRM-AMA}%
\vfill\pagebreak

% \section*{Supporting information}
% The following supporting information is available as part of the online article:

% \vskip\baselineskip\noindent
% \textbf{Figure S1.}
% {500{\uns}hPa geopotential anomalies for GC2C calculated against the ERA Interim reanalysis. The period is 1989--2008.}

% \noindent
% \textbf{Figure S2.}
% {The SST anomalies for GC2C calculated against the observations (OIsst).}

\vspace*{6pt}
\appendix
\renewcommand{\thetable}{S\arabic{table}}
\setcounter{table}{0} % 如果需要从 S1 开始编号，重置计数器

\begin{table}[h]
\caption{~Hash encoding parameters: hash table size $T$, number of feature dimensions per entry $F$, the coarsest resolution $N_{min}$ and the regularization parameter $\lambda_c$ were set based on the spatial resolution and SNR of the images. }
\label{tab1}
\begin{tabular}{c|c|c|c|c|c}
\hline
           & L  & T  & F & $N_{min}$                  & $\lambda_c$ \\ \hline
9.4T T2W & 11 & 25 & 2 & $2^{18}$ & 0      \\ \hline
7T T2W P1  & 11 & 25 & 2 & $2^{18}$ & 0      \\ \hline
7T GRE P2  & 11 & 25 & 3 & $2^{16}$ & $2\times10^{-5}$   \\ \hline
3T T2W     & 11 & 24 & 2 & $2^{15}$ & $3\times10^{-5}$   \\ \hline
\end{tabular}
\end{table}


\begin{table*}[h]
\caption{~Relative Error (RE) values reflect the errors between the low-resolution ground truth (GT) images and the low-resolution images obtained by back-projecting the reconstructed images from different methods.}
\label{tab2}
\centering
\begin{tabular}{c|cccc}
\hline
RE & 9.4T T2W & 7T T2W P1 & 7T GRE P2 & 3T T2W        \\ \hline
LS-SRR         &0.4515       &   0.6727       &    0.2923     & 0.4313 \\
ROVER-MRI   & 0.3504          &   0.5956        & 0.2601          & 0.4275 \\ \hline
\end{tabular}
\end{table*}

\begin{table*}[h]
\caption{~FWHM values in the ex-vivo data under different settings.}
\label{tab3}
\centering
\begin{tabular}{c|ccc||cc}
\hline
\multirow{2}{*}{FWHM} & \multicolumn{3}{c||}{Different Number of Views} & \multicolumn{2}{c}{Different SNR} \\ \cline{2-6} 
                      & 8 Views        & 6 Views       & 4 Views       & SNR 30           & SNR 15         \\ \hline
LS-SRR                   & 0.1825         & 0.1814        & 0.2398        & 0.1799           & 0.2154         \\
ROVER-MRI             & 0.1689         & 0.1629        & 0.1969        & 0.1683           & 0.1700         \\
% Ground Truth          & -              & -             & -             & 0. 0419          & 0.0501         
\hline
\end{tabular}
\end{table*}


\end{document}
