
\begin{table*}
\centering
\setlength{\tabcolsep}{2pt}
\resizebox{\textwidth}{!}{
\begin{tabular}{lllllll}
\toprule
Type & Name & Languages & Domains & Sample creation & Annotation creators & Nb samples*\\
\midrule
\multirow[t]{8}{*}{Classification} & AmazonCounterfactualClassification \cite{oneill-etal-2021-wish} & ['deu', 'eng', 'jpn'] & ['Reviews', 'Written'] & found & human-annotated & 5805 \\
 & Banking77Classification \cite{casanueva-etal-2020-efficient} & ['eng'] & ['Written'] & found & human-annotated & 3080 \\
 & ImdbClassification \cite{maas-etal-2011-learning} & ['eng'] & ['Reviews', 'Written'] & found & derived & 25000 \\
 & MTOPDomainClassification \cite{li-etal-2021-mtop} & ['deu', 'eng', 'fra', ...] & ['Spoken', 'Spoken'] & created & human-annotated & 30517 \\
 & MassiveIntentClassification \cite{fitzgerald2022massive} & ['afr', 'amh', 'ara', ...] & ['Spoken'] & human-translated and localized & human-annotated & 255357 \\
 & MassiveScenarioClassification \cite{fitzgerald2022massive} & ['afr', 'amh', 'ara', ...] & ['Spoken'] & human-translated and localized & human-annotated & 255357 \\
 & ToxicConversationsClassification \cite{jigsaw-unintended-bias-in-toxicity-classification} & ['eng'] & ['Social', 'Written'] & found & human-annotated & 2048 \\
 & TweetSentimentExtractionClassification \cite{tweet-sentiment-extraction} & ['eng'] & ['Social', 'Written'] & found & human-annotated & 3534 \\
\cline{1-7}
\multirow[t]{8}{*}{Clustering} & ArXivHierarchicalClusteringP2P  & ['eng'] & ['Academic', 'Written'] & found & derived & 2048 \\
 & ArXivHierarchicalClusteringS2S  & ['eng'] & ['Academic', 'Written'] & found & derived & 2048 \\
 & BiorxivClusteringP2P.v2  & ['eng'] & ['Academic', 'Written'] & created & derived & 53787 \\
 & MedrxivClusteringP2P.v2  & ['eng'] & ['Academic', 'Medical', 'Written'] & created & derived & 37500 \\
 & MedrxivClusteringS2S.v2  & ['eng'] & ['Academic', 'Medical', 'Written'] & created & derived & 37500 \\
 & StackExchangeClustering.v2 \cite{geigle:2021:arxiv} & ['eng'] & ['Web', 'Written'] & found & derived & 2048 \\
 & StackExchangeClusteringP2P.v2 \cite{geigle:2021:arxiv} & ['eng'] & ['Web', 'Written'] & found & derived & 74914 \\
 & TwentyNewsgroupsClustering.v2 \cite{LANG1995331} & ['eng'] & ['News', 'Written'] & found & derived & 59545 \\
\cline{1-7}
\multirow[t]{3}{*}{PairClassification} & SprintDuplicateQuestions \cite{shah-etal-2018-adversarial} & ['eng'] & ['Programming', 'Written'] & found & derived & 101000 \\
 & TwitterSemEval2015 \cite{xu-etal-2015-semeval} & ['eng'] & ['Social', 'Written'] & found & human-annotated & 16777 \\
 & TwitterURLCorpus \cite{lan-etal-2017-continuously} & ['eng'] & ['Social', 'Written'] & found & derived & 51534 \\
\cline{1-7}
\multirow[t]{2}{*}{Reranking} & AskUbuntuDupQuestions \cite{wang-2021-TSDAE} & ['eng'] & ['Programming', 'Web'] & found & human-annotated & 7581 \\
 & MindSmallReranking \cite{wu-etal-2020-mind} & ['eng'] & ['News', 'Written'] & found & expert-annotated & 2367791 \\
\cline{1-7}
\multirow[t]{10}{*}{Retrieval} & ArguAna \cite{boteva2016} & ['eng'] & ['Medical', 'Written'] & & & 8674 - 1406 \\
 & CQADupstackGamingRetrieval \cite{hoogeveen2015} & ['eng'] & ['Web', 'Written'] & found & derived & 45301 - 1595 \\
 & CQADupstackUnixRetrieval \cite{hoogeveen2015} & ['eng'] & ['Written', 'Web', 'Programming'] & found & derived & 47382 - 1072 \\
 & ClimateFEVERHardNegatives \cite{diggelmann2021climatefever} & ['eng'] & ['Encyclopaedic', 'Written'] & found & human-annotated & 47416 - 1000 \\
 & FEVERHardNegatives \cite{thorne-etal-2018-fever} & ['eng'] & None & & & 163698 - 1000 \\
 & FiQA2018 \cite{
thakur2021beir} & ['eng'] & ['Written', 'Financial'] & found & human-annotated & 57638 - 648 \\
 & HotpotQAHardNegatives \cite{yang-etal-2018-hotpotqa} & ['eng'] & ['Web', 'Written'] & found & human-annotated & 225621 - 1000 \\
 & SCIDOCS \cite{specter2020cohan} & ['eng'] & ['Academic', 'Written', 'Non-fiction'] & found & & 25657 - 1000 \\
 & TRECCOVID \cite{roberts2021searching} & ['eng'] & ['Medical', 'Academic', 'Written'] & & & 171332 - 50 \\
 & Touche2020Retrieval.v3 \cite{Thakur_etal_SIGIR2024} & ['eng'] & ['Academic'] & found & human-annotated & 303732 - 49 \\
\cline{1-7}
\multirow[t]{9}{*}{STS} & BIOSSES \cite{10.1093/bioinformatics/btx238} & ['eng'] & ['Medical'] & found & derived & 100 \\
 & SICK-R \cite{marelli-etal-2014-sick} & ['eng'] & ['Web', 'Written'] & & human-annotated & 9927 \\
 & STS12 \cite{10.5555/2387636.2387697} & ['eng'] & ['Encyclopaedic', 'News', 'Written'] & created & human-annotated & 3108 \\
 & STS13 \cite{Agirre2013SEM2S} & ['eng'] & ['Web', 'News', 'Non-fiction', ...] & created & human-annotated & 1500 \\
 & STS14 \cite{bandhakavi-etal-2014-generating} & ['eng'] & ['Blog', 'Web', 'Spoken'] & created & derived & 3750 \\
 & STS15 \cite{bicici-2015-rtm} & ['eng'] & ['Blog', 'News', 'Web', ...] & created & human-annotated & 3000 \\
 & STS17 \cite{cer-etal-2017-semeval} & ['ara', 'deu', 'eng', ...] & ['News', 'Web', 'Written'] & created & human-annotated & 5346 \\
 & STS22.v2 \cite{chen-etal-2022-semeval} & ['ara', 'cmn', 'deu', ...] & ['News', 'Written'] & found & human-annotated & 3958 \\
 & STSBenchmark \cite{huggingface:dataset:stsb_multi_mt} & ['eng'] & ['Blog', 'News', 'Written'] & machine-translated and verified & human-annotated & 1379 \\
\cline{1-7}
Summarization & SummEvalSummarization.v2 \cite{fabbri2020summeval} & ['eng'] & ['News', 'Written'] & created & human-annotated & 100 \\
\cline{1-7}
\bottomrule
\end{tabular}


}
\caption{The tasks included in \texttt{MTEB(eng, v2)}. The language column shows all the languages of the task. When running the tasks we limit it to the languages specified in the benchmark. * For the number of samples, are given the total number of samples all languages included, for Retrieval tasks are given the (number of queries - number of documents).}
\label{tab:mteb_lite_task_overview}
\end{table*}