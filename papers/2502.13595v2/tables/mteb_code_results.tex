
\begin{table*}
{\small
\setlength{\tabcolsep}{2pt}
\centering
\begin{tabular}{llc|ccccccc}
\toprule
& Rank & Average Across & \multicolumn{6}{c}{Average by Language} \\
& Borda Count & All & C++ & Go & Java & JavaScript & PHP & Python & Ruby \\
Model & & & & & & & \\
\midrule
GritLM-7B & 1 (88) & 73.6 & 73.1 & 83.8 & 84.9 & 81.7 & 77.8 & 86.4 & 83.8 \\
e5-mistral-7b-instruct & 2 (74) & 69.2 & 68.3 & 83.0 & 80.9 & 79.4 & 75.6 & 83.6 & 81.1 \\
multilingual-e5-large-instruct & 3 (65) & 65.0 & 56.4 & 74.7 & 74.7 & 71.7 & 71.6 & 79.1 & 74.9 \\
multilingual-e5-large & 4 (63) & 61.7 & 46.8 & 73.4 & 72.2 & 66.6 & 69.1 & 75.7 & 73.4 \\
multilingual-e5-base & 5 (55) & 57.5 & 48.9 & 73.2 & 71.0 & 66.1 & 67.8 & 75.2 & 72.7 \\
multilingual-e5-small & 6 (53) & 58.4 & 48.4 & 70.6 & 67.9 & 65.2 & 66.6 & 73.6 & 68.1 \\
all-mpnet-base-v2 & 7 (44) & 56.4 & 46.3 & 67.4 & 62.2 & 63.1 & 61.7 & 69.0 & 65.7 \\
all-MiniLM-L6-v2 & 8 (34) & 52.7 & 48.1 & 64.4 & 57.4 & 62.2 & 60.4 & 68.1 & 66.6 \\
all-MiniLM-L12-v2 & 9 (27) & 50.2 & 46.8 & 68.1 & 57.3 & 63.6 & 62.7 & 68.7 & 67.8 \\
LaBSE & 10 (11) & 28.8 & 27.6 & 40.6 & 36.6 & 42.3 & 34.8 & 43.9 & 42.2 \\
% paraphrase-multilingual-mpnet-base-v2 & 11 (11) & 29.6 & 33.2 & 43.8 & 39.5 & 46.9 & 36.7 & 52.1 & 51.9 \\
% paraphrase-multilingual-MiniLM-L12-v2 & 12 (3) & 25.4 & 27.3 & 40.6 & 28.0 & 40.1 & 29.3 & 44.9 & 45.1 \\
\bottomrule
\end{tabular}
\caption{
Performance on \texttt{MTEB(Code)} across task categories.
Because all code-related tasks are for retrieval, metrics by category are omitted.
}
\label{tab:mteb_code_results}
}
\end{table*}