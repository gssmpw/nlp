


\begin{table*}[!htb]
\centering
\setlength{\tabcolsep}{2pt}
\resizebox{\textwidth}{!}{
\begin{tabular}{lllllll}
\toprule
Type & Name & Languages & Domains & Sample creation & Annotations creators & Nb samples\\
% Type & Name &  &  \\
\midrule
    \multirow[t]{13}{*}{BitextMining} & BUCC.v2 \cite{zweigenbaum-etal-2017-overview} & ['cmn', 'deu', 'eng', ...] & ['Written'] & human-translated & human-annotated & 35000 \\
     & BibleNLPBitextMining \cite{akerman2023ebible} & ['aai', 'aak', 'aau', ...] & ['Religious', 'Written'] & created & expert-annotated & 417452 \\
     & BornholmBitextMining \cite{derczynskiBornholmskNaturalLanguage2019} & ['dan'] & ['Web', 'Social', 'Fiction', ...] & created & expert-annotated & 500 \\
     & DiaBlaBitextMining \cite{gonzalez2019diabla} & ['eng', 'fra'] & ['Social', 'Written'] & created & human-annotated & 11496 \\
     & FloresBitextMining \cite{goyal2022flores} & ['ace', 'acm', 'acq', ...] & ['Non-fiction', 'Encyclopaedic', 'Written'] & created & human-annotated & 41908944 \\
     & IN22GenBitextMining \cite{gala2023indictrans} & ['asm', 'ben', 'brx', ...] & ['Web', 'Legal', 'Government', ...] & created & expert-annotated & 518144 \\
     & IndicGenBenchFloresBitextMining \cite{singh2024indicgenbench} & ['asm', 'awa', 'ben', ...] & ['Web', 'News', 'Written'] & human-translated and localized & expert-annotated & 116522 \\
     & NTREXBitextMining \cite{federmann-etal-2022-ntrex} & ['afr', 'amh', 'arb', ...] & ['News', 'Written'] & human-translated and localized & expert-annotated & 3826252 \\
     & NollySentiBitextMining \cite{shode2023nollysenti} & ['eng', 'hau', 'ibo', ...] & ['Social', 'Reviews', 'Written'] & found & human-annotated & 1640 \\
     & NorwegianCourtsBitextMining \cite{opus4} & ['nno', 'nob'] & ['Legal', 'Written'] & found & human-annotated & 228 \\
     & NusaTranslationBitextMining \cite{cahyawijaya2023nusawrites} & ['abs', 'bbc', 'bew', ...] & ['Social', 'Written'] & created & human-annotated & 50200 \\
     & NusaXBitextMining \cite{winata2023nusax} & ['ace', 'ban', 'bbc', ...] & ['Reviews', 'Written'] & created & human-annotated & 5500 \\
     & Tatoeba \cite{tatoeba} & ['afr', 'amh', 'ang', ...] & ['Written'] & found & human-annotated & 88877 \\
    \cline{1-7}
    \multirow[t]{43}{*}{Classification} & AfriSentiClassification \cite{Muhammad2023AfriSentiAT} & ['amh', 'arq', 'ary', ...] & ['Social', 'Written'] & found & derived & 18222 \\
     & AmazonCounterfactualClassification \cite{oneill-etal-2021-wish} & ['deu', 'eng', 'jpn'] & ['Reviews', 'Written'] & found & human-annotated & 5805 \\
     & BulgarianStoreReviewSentimentClassfication \cite{DVN/TXIK9P_2018} & ['bul'] & ['Reviews', 'Written'] & found & human-annotated & 182 \\
     & CSFDSKMovieReviewSentimentClassification \cite{stefanik2023resources} & ['slk'] & ['Reviews', 'Written'] & found & derived & 2048 \\
     & CataloniaTweetClassification \cite{zotova-etal-2020-multilingual} & ['cat', 'spa'] & ['Social', 'Government', 'Written'] & created & expert-annotated & 8051 \\
     & CyrillicTurkicLangClassification \cite{goldhahn2012building} & ['bak', 'chv', 'kaz', ...] & ['Web', 'Written'] & found & derived & 2048 \\
     & CzechProductReviewSentimentClassification \cite{habernal-etal-2013-sentiment} & ['ces'] & ['Reviews', 'Written'] & found & derived & 2048 \\
     & DBpediaClassification \cite{NIPS2015_250cf8b5} & ['eng'] & ['Encyclopaedic', 'Written'] & found & derived & 2048 \\
     & DalajClassification \cite{2105.06681} & ['swe'] & ['Non-fiction', 'Written'] & created & expert-annotated & 888 \\
     & EstonianValenceClassification \cite{Pajupuu2023} & ['est'] & ['News', 'Written'] & found & human-annotated & 818 \\
     & FilipinoShopeeReviewsClassification \cite{riegoenhancement} & ['fil'] & ['Social', 'Written'] & found & human-annotated & 4096 \\
     & FinancialPhrasebankClassification \cite{Malo2014GoodDO} & ['eng'] & ['News', 'Written', 'Financial'] & found & expert-annotated & 2264 \\
     & GreekLegalCodeClassification \cite{papaloukas-etal-2021-glc} & ['ell'] & ['Legal', 'Written'] & found & human-annotated & 4096 \\
     & GujaratiNewsClassification  & ['guj'] & ['News', 'Written'] & found & derived & 1318 \\
     & IndicLangClassification \cite{madhani-etal-2023-bhasa} & ['asm', 'ben', 'brx', ...] & ['Web', 'Non-fiction', 'Written'] & created & expert-annotated & 30418 \\
     & IndonesianIdClickbaitClassification \cite{WILLIAM2020106231} & ['ind'] & ['News', 'Written'] & found & expert-annotated & 2048 \\
     & IsiZuluNewsClassification \cite{Madodonga_Marivate_Adendorff_2023} & ['zul'] & ['News', 'Written'] & found & human-annotated & 752 \\
     & ItaCaseholdClassification \cite{10.1145/3594536.3595177} & ['ita'] & ['Legal', 'Government', 'Written'] & found & expert-annotated & 221 \\
     & KorSarcasmClassification \cite{kim2019kocasm} & ['kor'] & ['Social', 'Written'] & found & expert-annotated & 2048 \\
     & KurdishSentimentClassification \cite{article} & ['kur'] & ['Web', 'Written'] & found & derived & 1987 \\
     & MacedonianTweetSentimentClassification \cite{jovanoski-etal-2015-sentiment} & ['mkd'] & ['Social', 'Written'] & found & human-annotated & 1139 \\
     & MasakhaNEWSClassification \cite{adelani2023masakhanews} & ['amh', 'eng', 'fra', ...] & ['News', 'Written'] & found & expert-annotated & 6242 \\
     & MassiveIntentClassification \cite{fitzgerald2022massive} & ['afr', 'amh', 'ara', ...] & ['Spoken'] & human-translated and localized & human-annotated & 255357 \\
     & MultiHateClassification \cite{rottger-etal-2021-hatecheck} & ['ara', 'cmn', 'deu', ...] & ['Constructed', 'Written'] & created & expert-annotated & 11000 \\
     & NepaliNewsClassification \cite{arora-2020-inltk} & ['nep'] & ['News', 'Written'] & found & derived & 2048 \\
     & NordicLangClassification \cite{haas-derczynski-2021-discriminating} & ['dan', 'fao', 'isl', ...] & ['Encyclopaedic'] & found & derived & 3000 \\
     & NusaParagraphEmotionClassification \cite{cahyawijaya-etal-2023-nusawrites} & ['bbc', 'bew', 'bug', ...] & ['Non-fiction', 'Fiction', 'Written'] & found & human-annotated & 5700 \\
     & NusaX-senti \cite{winata2022nusax} & ['ace', 'ban', 'bbc', ...] & ['Reviews', 'Web', 'Social', ...] & found & expert-annotated & 4800 \\
     & OdiaNewsClassification \cite{kunchukuttan2020indicnlpcorpus} & ['ory'] & ['News', 'Written'] & found & derived & 2048 \\
     & PAC \cite{augustyniak2022waydesigningcompilinglepiszcze} & ['pol'] & ['Legal', 'Written'] & & & 3453 \\
     & PoemSentimentClassification \cite{sheng2020investigating} & ['eng'] & ['Reviews', 'Written'] & found & human-annotated & 209 \\
     & PolEmo2.0-OUT  & ['pol'] & ['Written', 'Social'] & & & 494 \\
     & PunjabiNewsClassification \cite{kunchukuttan2020indicnlpcorpus} & ['pan'] & ['News', 'Written'] & found & derived & 157 \\
     & ScalaClassification \cite{nielsen-2023-scandeval} & ['dan', 'nno', 'nob', ...] & ['Fiction', 'News', 'Non-fiction', ...] & created & human-annotated & 8192 \\
     & SentimentAnalysisHindi \cite{OdiaGenAI} & ['hin'] & ['Reviews', 'Written'] & found & derived & 2048 \\
     & SinhalaNewsClassification \cite{deSilva2015} & ['sin'] & ['News', 'Written'] & found & derived & 2048 \\
     & SiswatiNewsClassification \cite{Madodonga_Marivate_Adendorff_2023} & ['ssw'] & ['News', 'Written'] & found & human-annotated & 80 \\
     & SlovakMovieReviewSentimentClassification \cite{vstefanik2023resources} & ['svk'] & ['Reviews', 'Written'] & found & derived & 2048 \\
     & SwahiliNewsClassification \cite{davis2020swahili} & ['swa'] & ['News', 'Written'] & found & derived & 2048 \\
     & SwissJudgementClassification \cite{niklaus2022empirical} & ['deu', 'fra', 'ita'] & ['Legal', 'Written'] & found & expert-annotated & 4908 \\
     & ToxicConversationsClassification \cite{jigsaw-unintended-bias-in-toxicity-classification} & ['eng'] & ['Social', 'Written'] & found & human-annotated & 2048 \\
     & TswanaNewsClassification \cite{marivate2023puoberta} & ['tsn'] & ['News', 'Written'] & found & derived & 487 \\
     & TweetTopicSingleClassification \cite{dimosthenis-etal-2022-twitter} & ['eng'] & ['Social', 'News', 'Written'] & found & expert-annotated & 1693 \\
    \cline{1-7}
    \multirow[t]{17}{*}{Clustering} & AlloProfClusteringS2S.v2 \cite{lef23} & ['fra'] & ['Encyclopaedic', 'Written'] & found & human-annotated & 2556 \\
     & ArXivHierarchicalClusteringP2P  & ['eng'] & ['Academic', 'Written'] & found & derived & 2048 \\
     & ArXivHierarchicalClusteringS2S  & ['eng'] & ['Academic', 'Written'] & found & derived & 2048 \\
     & BigPatentClustering.v2 \cite{DBLP:journals/corr/abs-1906-03741} & ['eng'] & ['Legal', 'Written'] & found & derived & 2048 \\
     & BiorxivClusteringP2P.v2  & ['eng'] & ['Academic', 'Written'] & created & derived & 53787 \\
     & CLSClusteringP2P.v2 \cite{li2022csl} & ['cmn'] & ['Academic', 'Written'] & found & derived & 2048 \\
     & HALClusteringS2S.v2 \cite{ciancone2024extending} & ['fra'] & ['Academic', 'Written'] & found & human-annotated & 2048 \\
     & MasakhaNEWSClusteringS2S \cite{adelani2023masakhanews} & ['amh', 'eng', 'fra', ...] & None & & & 80 \\
     & MedrxivClusteringP2P.v2  & ['eng'] & ['Academic', 'Medical', 'Written'] & created & derived & 37500 \\
     & PlscClusteringP2P.v2  & ['pol'] & ['Academic', 'Written'] & found & derived & 2048 \\
     & RomaniBibleClustering  & ['rom'] & ['Religious', 'Written'] & human-translated and localized & derived &  \\
     & SIB200ClusteringS2S \cite{adelani2023sib} & ['ace', 'acm', 'acq', ...] & ['News', 'Written'] & human-translated and localized & expert-annotated & 197788 \\
     & SNLHierarchicalClusteringP2P \cite{navjord2023beyond} & ['nob'] & ['Encyclopaedic', 'Non-fiction', 'Written'] & found & derived & 1300 \\
     & StackExchangeClustering.v2 \cite{geigle:2021:arxiv} & ['eng'] & ['Web', 'Written'] & found & derived & 2048 \\
     & SwednClusteringP2P \cite{monsen2021method} & ['swe'] & ['News', 'Non-fiction', 'Written'] & found & derived & 68752 \\
     & WikiCitiesClustering \cite{wikidump} & ['eng'] & ['Encyclopaedic', 'Written'] & found & derived &  \\
     & WikiClusteringP2P.v2  & ['bos', 'cat', 'ces', ...] & ['Encyclopaedic', 'Written'] & created & derived & 28672 \\
\bottomrule
\end{tabular}
}
\caption{The tasks included in \texttt{MTEB(Multilingual) (part 1)}.}
\label{tab:mteb_multilingual_task_overview1}
\end{table*}


\begin{table*}[!htb]
\centering
\setlength{\tabcolsep}{2pt}
\resizebox{\textwidth}{!}{
\begin{tabular}{lllllll}
\toprule
Type &  Name & Languages & Domains & Sample creators & Annotations creators & Nb samples*\\
% Type & Name &  &  \\
\midrule
    \multirow[t]{3}{*}{InstructionReranking} & Core17InstructionRetrieval \cite{weller2024followir} & ['eng'] & ['News', 'Written'] & found & derived & 19939 \\
     & News21InstructionRetrieval \cite{weller2024followir} & ['eng'] & ['News', 'Written'] & found & derived & 30985 \\
     & Robust04InstructionRetrieval \cite{weller2024followir} & ['eng'] & ['News', 'Written'] & found & derived & 47596 \\
    \cline{1-7}
    \multirow[t]{5}{*}{MultilabelClassification} & BrazilianToxicTweetsClassification \cite{DBLP:journals/corr/abs-2010-04543} & ['por'] & ['Constructed', 'Written'] & found & expert-annotated & 2048 \\
     & CEDRClassification \cite{sboev2021data} & ['rus'] & ['Web', 'Social', 'Blog', ...] & found & human-annotated & 1882 \\
     & KorHateSpeechMLClassification \cite{lee-etal-2022-k} & ['kor'] & ['Social', 'Written'] & found & expert-annotated & 2037 \\
     & MalteseNewsClassification \cite{maltese-news-datasets} & ['mlt'] & ['Constructed', 'Written'] & found & expert-annotated & 2297 \\
     & MultiEURLEXMultilabelClassification \cite{chalkidis-etal-2021-multieurlex} & ['bul', 'ces', 'dan', ...] & ['Legal', 'Government', 'Written'] & found & expert-annotated & 115000 \\
    \cline{1-7}
    \multirow[t]{11}{*}{PairClassification} & ArmenianParaphrasePC \cite{malajyan2020arpa} & ['hye'] & ['News', 'Written'] & found & derived & 1470 \\
     & CTKFactsNLI \cite{ullrich2023csfever} & ['ces'] & ['News', 'Written'] & found & human-annotated & 680 \\
     & OpusparcusPC \cite{creutz2018open} & ['deu', 'eng', 'fin', ...] & ['Spoken', 'Spoken'] & created & human-annotated & 18207 \\
     & PawsXPairClassification \cite{yang2019pawsx} & ['cmn', 'deu', 'eng', ...] & ['Web', 'Encyclopaedic', 'Written'] & human-translated & human-annotated & 28000 \\
     & PpcPC \cite{dadas2022training} & ['pol'] & ['Fiction', 'Non-fiction', 'Web', ...] & found & derived & 1000 \\
     & RTE3 \cite{giampiccolo-etal-2007-third} & ['deu', 'eng', 'fra', ...] & ['News', 'Web', 'Encyclopaedic', ...] & found & expert-annotated & 1923 \\
     & SprintDuplicateQuestions \cite{shah-etal-2018-adversarial} & ['eng'] & ['Programming', 'Written'] & found & derived & 101000 \\
     & TERRa \cite{shavrina2020russiansuperglue} & ['rus'] & ['News', 'Web', 'Written'] & found & human-annotated & 307 \\
     & TwitterURLCorpus \cite{lan-etal-2017-continuously} & ['eng'] & ['Social', 'Written'] & found & derived & 51534 \\
     & XNLI \cite{conneau2018xnli} & ['ara', 'bul', 'deu', ...] & ['Non-fiction', 'Fiction', 'Government', ...] & created & expert-annotated & 38220 \\
     & indonli \cite{mahendra-etal-2021-indonli} & ['ind'] & ['Encyclopaedic', 'Web', 'News', ...] & found & expert-annotated & 2040 \\
    \cline{1-7}
    \multirow[t]{6}{*}{Reranking} & AlloprofReranking \cite{lef23} & ['fra'] & ['Web', 'Academic', 'Written'] & found & expert-annotated & 27355 \\
     & RuBQReranking \cite{RuBQ2021} & ['rus'] & ['Encyclopaedic', 'Written'] & created & human-annotated & 38998 \\
     & T2Reranking \cite{xie2023t2ranking} & ['cmn'] & None & & & 103330 \\
     & VoyageMMarcoReranking \cite{clavié2023jacolbert} & ['jpn'] & ['Academic', 'Non-fiction', 'Written'] & found & derived & 55423 \\
     & WebLINXCandidatesReranking \cite{lù2024weblinx} & ['eng'] & ['Academic', 'Web', 'Written'] & created & expert-annotated & 5592142 \\
     & WikipediaRerankingMultilingual \cite{wikidump} & ['ben', 'bul', 'ces', ...] & ['Encyclopaedic', 'Written'] & LM-generated and verified & LM-generated and reviewed & 240000 \\
    \cline{1-7}
    \multirow[t]{19}{*}{Retrieval} & AILAStatutes \cite{paheli_bhattacharya_2020_4063986} & ['eng'] & ['Legal', 'Written'] & found & derived & 82 - 50 \\
     & ArguAna \cite{boteva2016} & ['eng'] & ['Medical', 'Written'] & & & 8674 - 1406 \\
     & BelebeleRetrieval \cite{bandarkar2023belebele} & ['acm', 'afr', 'als', ...] & ['Web', 'News', 'Written'] & created & expert-annotated & 183488 - 338378 \\
     & CUREv1  & ['eng', 'fra', 'spa'] & ['Medical', 'Academic', 'Written'] & created & expert-annotated & 1541613 - 12000 \\
     & CovidRetrieval  & ['cmn'] & None & & & 100001 - 949 \\
     & HagridRetrieval \cite{hagrid} & ['eng'] & ['Encyclopaedic', 'Written'] & found & expert-annotated & 496 - 496 \\
     & LEMBPasskeyRetrieval \cite{zhu2024longembed} & ['eng'] & ['Fiction', 'Written'] & found & derived & 800 - 400 \\
     & LegalBenchCorporateLobbying \cite{guha2023legalbench} & ['eng'] & ['Legal', 'Written'] & found & derived & 319 - 340 \\
     & MIRACLRetrievalHardNegatives \cite{10.1162/tacl_a_00595} & ['ara', 'ben', 'deu', ...] & ['Encyclopaedic', 'Written'] & created & expert-annotated & 2449382 - 11076 \\
     & MLQARetrieval \cite{lewis2019mlqa} & ['ara', 'deu', 'eng', ...] & ['Encyclopaedic', 'Written'] & found & human-annotated & 152379 - 173776 \\
     & SCIDOCS \cite{specter2020cohan} & ['eng'] & ['Academic', 'Written', 'Non-fiction'] & found & & 25657 - 1000 \\
     & SpartQA \cite{xiao2024rar} & ['eng'] & ['Encyclopaedic', 'Written'] & found & derived & 1592 - 3594 \\
     & StackOverflowQA \cite{li2024coircomprehensivebenchmarkcode} & ['eng'] & ['Programming', 'Written'] & found & derived & 19931 - 1994 \\
     & StatcanDialogueDatasetRetrieval \cite{lu-etal-2023-statcan} & ['eng', 'fra'] & ['Government', 'Web', 'Written'] & found & derived & 23628 - 9436 \\
     & TRECCOVID \cite{roberts2021searching} & ['eng'] & ['Medical', 'Academic', 'Written'] & & & 171332 - 50 \\
     & TempReasonL1 \cite{xiao2024rar} & ['eng'] & ['Encyclopaedic', 'Written'] & found & derived & 12504 - 4000 \\
     & TwitterHjerneRetrieval \cite{holm2024gllms} & ['dan'] & ['Social', 'Written'] & found & derived & 262 - 78 \\
     & WikipediaRetrievalMultilingual  & ['ben', 'bul', 'ces', ...] & ['Encyclopaedic', 'Written'] & LM-generated and verified & LM-generated and reviewed & 216000 - 24000 \\
     & WinoGrande \cite{xiao2024rar} & ['eng'] & ['Encyclopaedic', 'Written'] & found & derived & 5095 - 1267 \\
    \cline{1-7}
    \multirow[t]{16}{*}{STS} & FaroeseSTS \cite{snaebjarnarson-etal-2023-transfer} & ['fao'] & ['News', 'Web', 'Written'] & found & human-annotated & 729 \\
     & FinParaSTS \cite{kanerva-etal-2021-finnish} & ['fin'] & ['News', 'Subtitles', 'Written'] & found & expert-annotated & 2000 \\
     & GermanSTSBenchmark \cite{huggingface:dataset:stsb_multi_mt} & ['deu'] & None & & & 2879 \\
     & IndicCrosslingualSTS \cite{10.1162/tacl_a_00452} & ['asm', 'ben', 'eng', ...] & ['News', 'Non-fiction', 'Web', ...] & created & expert-annotated & 3072 \\
     & JSICK \cite{yanaka2022compositional} & ['jpn'] & ['Web', 'Written'] & found & human-annotated & 1986 \\
     & SICK-R \cite{marelli-etal-2014-sick} & ['eng'] & ['Web', 'Written'] & & human-annotated & 9927 \\
     & STS12 \cite{10.5555/2387636.2387697} & ['eng'] & ['Encyclopaedic', 'News', 'Written'] & created & human-annotated & 3108 \\
     & STS13 \cite{Agirre2013SEM2S} & ['eng'] & ['Web', 'News', 'Non-fiction', ...] & created & human-annotated & 1500 \\
     & STS14 \cite{bandhakavi-etal-2014-generating} & ['eng'] & ['Blog', 'Web', 'Spoken'] & created & derived & 3750 \\
     & STS15 \cite{bicici-2015-rtm} & ['eng'] & ['Blog', 'News', 'Web', ...] & created & human-annotated & 3000 \\
     & STS17 \cite{cer-etal-2017-semeval} & ['ara', 'deu', 'eng', ...] & ['News', 'Web', 'Written'] & created & human-annotated & 5346 \\
     & STS22.v2 \cite{chen-etal-2022-semeval} & ['ara', 'cmn', 'deu', ...] & ['News', 'Written'] & found & human-annotated & 3958 \\
     & STSB \cite{xiao2024cpack} & ['cmn'] & None & & & 2819 \\
     & STSBenchmark \cite{huggingface:dataset:stsb_multi_mt} & ['eng'] & ['Blog', 'News', 'Written'] & machine-translated and verified & human-annotated & 1379 \\
     & STSES \cite{agirre2015semeval} & ['spa'] & ['Written'] & & & 155 \\
     & SemRel24STS \cite{ousidhoum2024semrel2024} & ['afr', 'amh', 'arb', ...] & ['Spoken', 'Written'] & created & human-annotated & 7498 \\
\bottomrule
\end{tabular}
}
\caption{The tasks included in \texttt{MTEB(Multilingual)} (part 2). *For the number of samples, are given the total number of samples all languages included, for Retrieval tasks are given the (number of queries - number of documents).}
\label{tab:mteb_multilingual_task_overview2}
\end{table*}