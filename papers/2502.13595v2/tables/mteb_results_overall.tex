\begin{table*}[!th]
\centering
\resizebox{\textwidth}{!}{  
\setlength{\tabcolsep}{1pt}
{\footnotesize
\begin{tabular}{llcc|cccccccc}
\toprule
& \multicolumn{1}{c}{\textbf{Rank}  ($\downarrow$)} &  \multicolumn{2}{c}{\textbf{Average Across}} & \multicolumn{7}{c}{\textbf{Average per Category}} \\
\cmidrule(r){2-2} \cmidrule{3-4} \cmidrule(l){5-12}
\textbf{Model} ($\downarrow$) & Borda Count & All & \multicolumn{1}{r}{Category}  & \multicolumn{1}{c}{Btxt} & Pr Clf  & Clf & STS & Rtrvl & M. Clf  & Clust & Rrnk \\
\midrule
\multicolumn{12}{c}{\vspace{2mm} \normalsize \texttt{MTEB(Multilingual)}} \\
\textcolor{gray}{Number of datasets ($\rightarrow$) } & \textcolor{gray}{(132)} & \textcolor{gray}{(132)} & \multicolumn{1}{c}{\textcolor{gray}{(132)}} &   \multicolumn{1}{c}{\textcolor{gray}{(13)}} &   \textcolor{gray}{(11)}  &   \textcolor{gray}{(43)}  &   \textcolor{gray}{(16)}  &   \textcolor{gray}{(18)}  &   \textcolor{gray}{(5)}  &   \textcolor{gray}{(17)}  &   \textcolor{gray}{(6)} \\
\midrule
multilingual-e5-large-instruct & 1 (1375) & \textbf{63.2} & \textbf{62.1} & \textbf{80.1} & 80.9 & \textbf{64.9} & \textbf{76.8} & 57.1 & \textbf{22.9} & \textbf{51.5} & 62.6 \\
GritLM-7B & 2 (1258) & 60.9 & 60.1 & 70.5 & 79.9 & 61.8 & 73.3 & \textbf{58.3} & 22.8 & 50.5 & \textbf{63.8} \\
e5-mistral-7b-instruct & 3 (1233) & 60.3 & 59.9 & 70.6 & 81.1 & 60.3 & 74.0 & 55.8 & 22.2 & 51.4 & \textbf{63.8} \\
multilingual-e5-large & 4 (1109) & 58.6 & 58.2 & 71.7 & 79.0 & 59.9 & 73.5 & 54.1 & 21.3 & 42.9 & \textbf{62.8} \\
multilingual-e5-base & 5 (944) & 57.0 & 56.5 & 69.4 & 77.2 & 58.2 & 71.4 & 52.7 & 20.2 & 42.7 & 60.2 \\
multilingual-mpnet-base & 6 (830) & 52.0 & 51.1 & 52.1 & \textbf{81.2} & 55.1 & 69.7 & 39.8 & 16.4 & 41.1 & 53.4 \\
multilingual-e5-small & 7 (784) & 55.5 & 55.2 & 67.5 & 76.3 & 56.5 & 70.4 & 49.3 & 19.1 & 41.7 & 60.4 \\
LaBSE & 8 (719) & 52.1 & 51.9 & 76.4 & 76.0 & 54.6 & 65.3 & 33.2 & 20.1 & 39.2 & 50.2 \\
multilingual-MiniLM-L12 & 9 (603) & 48.8 & 48.0 & 44.6 & 79.0 & 51.7 & 66.6 & 36.6 & 14.9 & 39.3 & 51.0 \\
all-mpnet-base & 10 (526) & 42.5 & 41.1 & 21.2 & 70.9 & 47.0 & 57.6 & 32.8 & 16.3 & 40.8 & 42.2 \\
all-MiniLM-L12 & 11 (490) & 42.2 & 40.9 & 22.9 & 71.7 & 46.8 & 57.2 & 32.5 & 14.6 & 36.8 & 44.3 \\
all-MiniLM-L6 & 12 (418) & 41.4 & 39.9 & 20.1 & 71.2 & 46.2 & 56.1 & 32.5 & 15.1 & 38.0 & 40.3 \\
\midrule
\multicolumn{12}{c}{\vspace{2mm} \normalsize \texttt{MTEB(Europe)}} \\
\textcolor{gray}{Number of datasets ($\rightarrow$) } & \textcolor{gray}{(74)} & \textcolor{gray}{(74)} & \multicolumn{1}{c}{\textcolor{gray}{(74)}} &   \multicolumn{1}{c}{\textcolor{gray}{(7)}} &   \textcolor{gray}{(6)}  &   \textcolor{gray}{(21)}   &   \textcolor{gray}{(9)}  &   \textcolor{gray}{(15)} &   \textcolor{gray}{(2)}  &   \textcolor{gray}{(6)} &   \textcolor{gray}{(3)}  \\
\midrule
GritLM-7B & 1 (757) & \textbf{63.0} & \textbf{62.7} & \textbf{90.4} & 89.9 & \textbf{64.7} & 76.1 & \textbf{57.1} & \textbf{17.6} & 45.3 & \textbf{60.3} \\
multilingual-e5-large-instruct & 2 (732) & 62.2 & 62.3 & 90.4 & 90.0 & 63.2 & \textbf{77.4} & 54.8 & 17.3 & \textbf{46.9} & 58.4 \\
e5-mistral-7b-instruct & 3 (725) & 61.7 & 61.9 & 89.6 & \textbf{91.2} & 62.9 &  76.5 & 53.6 & 15.5 & 46.5 & 59.8 \\
multilingual-e5-large & 4 (586) & 58.5 & 58.7 & 84.5 & 88.8 & 60.4 & 75.8 & 50.8 & 15.0 & 38.2 & 55.9 \\
multilingual-e5-base & 5 (499) & 57.2 & 57.5 & 84.1 & 87.4 & 57.9 & 73.7 & 50.2 & 14.9 & 38.2 & 53.9 \\
multilingual-mpnet-base & 6 (463) & 54.4 & 54.7 & 79.5 & 90.7 & 56.6 & 74.3 & 41.2 & 6.9 & 35.8 & 52.3 \\
multilingual-e5-small & 7 (399) & 55.0 & 55.7 & 80.9 & 86.4 & 56.1 & 71.6 & 46.1 & 14.0 & 36.5 & 54.1 \\
LaBSE & 8 (358) & 51.8 & 53.5 & 88.8 & 85.2 & 55.1 & 65.7 & 34.4 & 16.3 & 34.3 & 48.7 \\
multilingual-MiniLM-L12 & 9 (328) & 51.7 & 52.4 & 77.0 & 88.9 & 52.7 & 72.5 & 37.6 & 5.7 & 34.4 & 50.2 \\
all-mpnet-base & 10 (310) & 44.7 & 44.7 & 29.8 & 80.5 & 49.2 & 63.9 & 37.3 & 10.9 & 36.2 & 49.6 \\
all-MiniLM-L12 & 11 (292) & 44.4 & 44.1 & 32.1 & 81.5 & 49.2 & 64.2 & 36.2 & 7.6 & 32.5 & 49.2 \\
all-MiniLM-L6 & 12 (237) & 43.4 & 43.2 & 27.2 & 80.2 & 47.8 & 62.7 & 37.3 & 8.8 & 33.6 & 47.7 \\
\midrule
\multicolumn{12}{c}{\vspace{2mm} \normalsize \texttt{MTEB(Indic)}} \\
\textcolor{gray}{Number of datasets ($\rightarrow$) } & \textcolor{gray}{(23)} & \textcolor{gray}{(23)} & \multicolumn{1}{c}{\textcolor{gray}{(23)}} &   \multicolumn{1}{c}{\textcolor{gray}{(4)}} &   \textcolor{gray}{(1)}  &   \textcolor{gray}{(13)}   &   \textcolor{gray}{(1)}  &   \textcolor{gray}{(2)} &   \textcolor{gray}{(0)}  &   \textcolor{gray}{(1)} &   \textcolor{gray}{(1)}  \\
\midrule
multilingual-e5-large-instruct & 1 (209) & \textbf{70.2} & \textbf{71.6} & \textbf{80.4} & 76.3 & \textbf{67.0} & \textbf{53.7} & \textbf{84.9} & & \textbf{51.7} & \textbf{87.5} \\
multilingual-e5-large & 2 (188) & 66.4 & 65.1 & 77.7 & 75.1 & 64.7 & 43.9 & 82.6 & & 25.6 & 86.0 \\
multilingual-e5-base & 3 (173) & 64.6 & 62.6 & 74.2 & 72.8 & 63.8 & 41.1 & 77.8 & & 24.6 & 83.8 \\
multilingual-e5-small & 4 (164) & 64.7 & 63.2 & 73.7 & 73.8 & 63.8 & 40.8 & 76.8 & & 29.1 & 84.4 \\
GritLM-7B & 5 (151) & 60.2 & 58.0 & 58.4 & 67.8 & 60.0 & 27.2 & 79.5 & & 28.0 & 84.7 \\
e5-mistral-7b-instruct & 6 (144) & 60.0 & 58.4 & 59.1 & 73.0 & 59.6 & 23.0 & 77.3 & & 32.7 & 84.4 \\
LaBSE & 7 (139) & 61.9 & 59.7 & 74.1 & 64.6 & 61.9 & 52.8 & 64.3 & & 21.1 & 79.0 \\
multilingual-mpnet-base & 8 (137) & 58.5 & 55.2 & 44.2 & \textbf{82.0} & 61.9 & 34.1 & 57.9 & & 32.1 & 74.3 \\
multilingual-MiniLM-L12 & 9 (98) & 49.7 & 42.2 & 15.3 & 77.8 & 57.6 & 19.8 & 48.8 & & 16.7 & 59.3 \\
all-mpnet-base & 10 (68) & 33.6 & 22.6 & 3.7 & 52.6 & 45.2 & -2.5 & 12.9 & & 4.0 & 42.6 \\
all-MiniLM-L12 & 11 (49) & 33.1 & 23.2 & 3.5 & 55.0 & 43.9 & -5.3 & 13.9 & & 3.7 & 47.6 \\
all-MiniLM-L6 & 12 (40) & 31.8 & 20.4 & 2.5 & 53.7 & 44.1 & -6.3 & 6.2 & & 3.1 & 39.2 \\
\bottomrule

\end{tabular}
}
}  % edn resizebox
\caption{
% The results on three multilingual benchmarks. For each benchmark, we sort the score by rank (based on Borda count). We additionally supply an average across all tasks, an average per task category and an average weighted by task category.
The results for three multilingual benchmarks are ranked using Borda count. We provide averages across all tasks, per task category, and weighted by task category. The task categories are shortened as follows: Bitext Mining (Btxt), Pair Classification (Pr Clf), Classification (Clf), Semantic text similarity (STS), Retrieval (Rtrvl), Multilabel Classification (M. Clf), Clustering and Hierarchical Clustering (Clust) and Reranking (Rrnk). We highlight the best score in \textbf{bold}. Note that while Instruction retrieval \citep{weller2024followir} is included in \texttt{MTEB(Europe)} and \texttt{MTEB(Multilingual)}, but is excluded from the average by task category due to limited model support. For a broader model evaluation, refer to the public leaderboard.
}
\label{tab:overall-performance}
\end{table*}