
\section*{Limitations}


\paragraph{English Leakage.}
While MMTEB filters out machine-translated datasets, it permits (human) translations. This inclusion leads to tasks like SIB200ClusteringS2S, where labels from English samples are transferred to their translations, potentially introducing bias towards English or models trained on translated content. Consequently, the benchmark may inadvertently encourage model developers to favor English or translated content by increasing their proportion in pre-training data.

\paragraph{Credit Assignment for Large-scale Collaborations.}
One of MMTEB’s goals was to highlight the benefits of collaboration. The managing group believes the point system successfully defined contribution terms but acknowledges it isn’t perfect. For instance, equal points were awarded for dataset submissions regardless of effort—some datasets were readily available, while others needed significant work like reformulation, HTML parsing, and multiple review rounds.

\paragraph{Languages Representation.}
While the benchmark includes over 250 languages and 500 tasks, the distribution is skewed toward high-resource languages (see \autoref{fig:n_langs}), with low-resource languages being better represented in specific task categories like bitext-mining and classification. We encourage future collaborations to fill these gaps and enhance language diversity in the collection.

\begin{figure*}[!th]
    \centering
    \includegraphics[width=\linewidth]{figures/tasks_per_language.pdf}
    \caption{Number of tasks per language. For readability, we remove English (290 tasks) and only plot the 100 languages with the most tasks.
    }
    \label{fig:n_langs}
    \vspace{-3mm}
\end{figure*}

% \header{Data leakage and bias}
% The tasks introduced as part of MMTEB are publicly available, created using data found on the web, and a few constructed using LLMs. This may result in data leakage or bias, causing some models trained on parts of the dataset to produce exaggerated scores on the benchmark. In future efforts, we seek to develop methods for automatically identifying data leakage within a task.