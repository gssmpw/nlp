\section{Literature Review}
\label{review}

\begin{figure*}[h]
    \centering
    \subfigure{
        \includegraphics[width=0.45\textwidth]{figures/results_models.pdf}
    }
    \hspace{0.05\textwidth}
    \subfigure{
        \includegraphics[width=0.45\textwidth]{figures/results_modality.pdf}
    }
    \caption{Comparison of the number of papers inspecting different LLMs (left) and modalities (right).}
    \label{fig:literature_summary}
    %%% Figure link: https://colab.research.google.com/drive/1qgmM8qRLwSHhpKc6UgrjqW5G_X9dZ6Ww?usp=sharing
\end{figure*}

As a systematic ground for our review of ToM in LLMs research, we focused on ArXiv papers and searched the database using the ArXiv API\footnote{\url{https://info.arxiv.org/help/api/index.html}}. The search query was set as \codeword{"theory of mind"} \codeword{AND ("LLM" OR "large language models")} \footnote{Using "ToM" in the query retrieved unrelated papers and didn’t yield any new results compared to using only "theory of mind".}.  In addition to Arxiv API, we reviewed the Theory of Mind benchmarks listed in a repository\textsuperscript{\ref{ma-etal-github}} maintained by Roberts et al., "Theory of Mind Benchmarks".

As a result, we reviewed a total of 58 papers related to the Machine Theory of Mind. Since this is a relatively recent field, we intentionally limited the number of papers to avoid including scientifically insufficient works merely to increase the quantity reviewed.
It is important to note that not all papers explicitly mention the Theory of Mind, include experiments, or use large language models in their studies—however, all of them focus on specific aspects of the Machine Theory of Mind.

\begin{comment}
\begin{figure}[h]
    \centering
    \subfigure{
        \includegraphics[width=0.45\textwidth]{figures/results_year.pdf}
    }
    \caption{Comparison of release years of papers retrieved from the Arxiv API.}
    \label{fig:api-years}
\end{figure}
\end{comment}

Fig. \ref{fig:literature_summary} shows some insights about the investigated papers. We observed that out of 49 papers that experiment with LLMs, 42 of them test one or more GPT-based models. On the other hand, 25 of them analyzed open-source models. Finally, only 8 of them used other models with API access. Possibly due to their superior language abilities, GPT models dominate the ToM research on LLMs. Additionally, we noticed that most of the work is in the text-only domain. Only 5 out of 49 papers include other modalities than text.

We additionally investigated which LLM evaluation schemes were used by the authors when reporting performance on the desired tasks. We have found that out of the discussed 49 papers which evaluate LLMs,
\vspace{-0.5em}
\begin{itemize}
\itemsep-0.3em
    \item 39 of them (79.6\%) reported automated objective performance metrics, such as accuracy on a specified test suite with ground-truth values,
    \item 10 of them (20.4\%) reported LLM performance measures based on manual evaluation by human experts,
    \item and 17 of them (34.7\%) compared LLM performance with human performance on the same task, potentially with further statistical analysis.
\end{itemize}
Note that the listed evaluation methods are not mutually exclusive. As such, we have noticed that out of 10 papers using human evaluation, 5 of them additionally report an automated accuracy value. Ground-truth-based evaluation takes up a high portion of the analyzed papers, which highlights the importance of structured benchmarks and numerical analysis in the literature. However, it should be noted that numerical comparison with human performance is not as prevalent, and might reflect a shortcoming of the current ToM in LLMs literature.

\paragraph{False Belief Understanding.} So far the majority of the work in Machine Theory of Mind focused on the false belief tests, usually with Sally-Anne ___, "Sally-Anne Test" and Smarties ___, "Smarties Test" variants. The Smarties Test and the Sally-Anne Test are classic assessments of children's Theory of Mind. In the Smarties Test, children are shown a tube labeled as containing candy but discover it holds pencils. Younger children struggle to predict that others would still expect candy inside, highlighting their difficulty understanding that others can hold beliefs different from reality. The Sally-Anne Test involves a character who mistakenly believes her marble is where she left it, despite it being moved. Children's responses reveal whether they grasp that others can have false beliefs. Both tests also also studied in Roberts et al., "Theory of Mind Benchmarks". 

\paragraph{Human-Computer Interaction}  
The work of Scassellati et al., "Human-Robot Interaction"  focus on human-robot interaction. Their observations indicate that even though LLMs exhibit behavior resembling ToM, these abilities are largely illusory, stemming from advanced language processing rather than a genuine understanding of mental states.

\paragraph{AI Psychology}  
 Wu et al., find that even though LLMs can handle basic ToM tasks, they perform inconsistently in more advanced scenarios requiring understanding of others' mental states. They notice that LLMs lack the flexibility needed to adapt to varied social contexts. Additionally,  Zhang et al., suggest that LLMs' information processing is more than mere pattern matching, but is still less sophisticated compared to human ToM abilities.

\paragraph{Negotiation}  
 Zeng et al., ____ and Zhang et al., ____ investigate ToM abilities via negotiation. While ____ focus on natural conversations and real-world data for evaluation, ____ propose a game called NegotiationArena in which LLMs can compete against each other. Wu et al., conclude that current state-of-the-art LLMs perform significantly worse than humans, even when using advanced reasoning techniques.

\paragraph{Prompting Frameworks}  
One research focus in Machine Theory of Mind involves developing various prompting strategies to improve model performance. Notable works in this area include Goyal et al., "Prompting Frameworks for Human-like Behavior".