\section{Literature Review}
\label{review}

\begin{figure*}[h]
    \centering
    \subfigure{
        \includegraphics[width=0.45\textwidth]{figures/results_models.pdf}
    }
    \hspace{0.05\textwidth}
    \subfigure{
        \includegraphics[width=0.45\textwidth]{figures/results_modality.pdf}
    }
    \caption{Comparison of the number of papers inspecting different LLMs (left) and modalities (right).}
    \label{fig:literature_summary}
    %%% Figure link: https://colab.research.google.com/drive/1qgmM8qRLwSHhpKc6UgrjqW5G_X9dZ6Ww?usp=sharing
\end{figure*}

As a systematic ground for our review of ToM in LLMs research, we focused on ArXiv papers and searched the database using the ArXiv API\footnote{\url{https://info.arxiv.org/help/api/index.html}}. The search query was set as \codeword{"theory of mind"} \codeword{AND ("LLM" OR "large language models")} \footnote{Using "ToM" in the query retrieved unrelated papers and didn’t yield any new results compared to using only "theory of mind".}.  In addition to Arxiv API, we reviewed the Theory of Mind benchmarks listed in a repository\textsuperscript{\ref{ma-etal-github}} maintained by ____.
As a result, we reviewed a total of 58 papers related to the Machine Theory of Mind. Since this is a relatively recent field, we intentionally limited the number of papers to avoid including scientifically insufficient works merely to increase the quantity reviewed.
It is important to note that not all papers explicitly mention the Theory of Mind, include experiments, or use large language models in their studies—however, all of them focus on specific aspects of the Machine Theory of Mind.

\begin{comment}
\begin{figure}[h]
    \centering
    \subfigure{
        \includegraphics[width=0.45\textwidth]{figures/results_year.pdf}
    }
    \caption{Comparison of release years of papers retrieved from the Arxiv API.}
    \label{fig:api-years}
\end{figure}
\end{comment}

Fig. \ref{fig:literature_summary} shows some insights about the investigated papers. We observed that out of 49 papers that experiment with LLMs, 42 of them test one or more GPT-based models. On the other hand, 25 of them analyzed open-source models. Finally, only 8 of them used other models with API access. Possibly due to their superior language abilities, GPT models dominate the ToM research on LLMs. Additionally, we noticed that most of the work is in the text-only domain. Only 5 out of 49 papers include other modalities than text.

We additionally investigated which LLM evaluation schemes were used by the authors when reporting performance on the desired tasks. We have found that out of the discussed 49 papers which evaluate LLMs,
\vspace{-0.5em}
\begin{itemize}
\itemsep-0.3em
    \item 39 of them (79.6\%) reported automated objective performance metrics, such as accuracy on a specified test suite with ground-truth values,
    \item 10 of them (20.4\%) reported LLM performance measures based on manual evaluation by human experts,
    \item and 17 of them (34.7\%) compared LLM performance with human performance on the same task, potentially with further statistical analysis.
\end{itemize}
Note that the listed evaluation methods are not mutually exclusive. As such, we have noticed that out of 10 papers using human evaluation, 5 of them additionally report an automated accuracy value. Ground-truth-based evaluation takes up a high portion of the analyzed papers, which highlights the importance of structured benchmarks and numerical analysis in the literature. However, it should be noted that numerical comparison with human performance is not as prevalent, and might reflect a shortcoming of the current ToM in LLMs literature.

\paragraph{False Belief Understanding.} So far the majority of the work in Machine Theory of Mind focused on the false belief tests, usually with Sally-Anne ____ and Smarties ____ variants. The Smarties Test and the Sally-Anne Test are classic assessments of children's Theory of Mind. In the Smarties Test, children are shown a tube labeled as containing candy but discover it holds pencils. Younger children struggle to predict that others would still expect candy inside, highlighting their difficulty understanding that others can hold beliefs different from reality. The Sally-Anne Test involves a character who mistakenly believes her marble is where she left it, despite it being moved. Children's responses reveal whether they grasp that others can have false beliefs. Both tests also have second-order versions that further assess the child's ability to understand beliefs about beliefs. 

____ develop a benchmark based on false belief tests, while ____ incorporate standardized false belief tests along with tasks involving non-literal communication (faux pas) and knowledge tests (imposing memory tests). In his much-debated work, ____ explores various false-belief scenarios to assess the Theory of Mind abilities of large language models, ultimately suggesting that ToM skills may have emerged as a byproduct of the training process—a claim that would later face criticism by ____ who showed that the small variations to false belief tasks can lead to significantly worse accuracies in tests. These variations can include uninformative additions to prompt or making the container transparent. 
In his updated work, ____ criticizes the methodology of ____, stating, \enquote{First, claims about LLMs’ performance should be backed by empirical evidence and statistical analyses, rather than anecdotal examples. Ullman, for instance, selected two out of our 40 tasks and designed eight true-belief scenarios that GPT-3-davinci-003 failed to solve. However, a few examples of white swans (tasks a model cannot solve) neither prove that black swans (tasks a model can solve) do not exist nor do they inform us about the true white-to-black swan ratio.}

Then, ____ adopt a similar approach by introducing adversarial examples to the dataset, concluding that 'LLMs don’t have robust ToM abilities but rather rely on shallow heuristics.' ____ is among other works that focus on false-belief understanding to measure the ToM abilities of LLMs.

\paragraph{Reasoning.} ____ compare the reasoning of LLMs with humans on Reddit CMV\footnote{\url{https://www.reddit.com/r/changemyview/}} data. They encounter some problems with ToM reasoning on open ended questions, even after prompt tuning.

\paragraph{Perception.} ____ claim that LLMs can identify what a character sees or hears, but they fail to deduce what a character believes based on what they perceive. They notice that irrelevant information confuses the models, and propose a prompting method called PercepToM which guides them through a structured process of inference. ____ similarly report a case where an LLM fails in processing perception.

\paragraph{Privacy.} ____ poses the question, ``Can LLMs keep a secret?'' and introduces a new benchmark called ConfAIde, which consists of four tiers of increasing complexity. For example, in the final tier, the model is expected to generate a summary of a text containing private information that will be distributed to all meeting attendees. The model is required to produce a summary that addresses privacy concerns. They demonstrate that advanced models like GPT-4 and ChatGPT disclose private information in scenarios where humans would typically refrain from doing so, 39\% and 57\% of the time, respectively.


\paragraph{Social Intelligence.}
Several studies have been conducted to measure the social intelligence of language models, which necessitates a certain level of Theory of Mind. To measure social intelligence, benchmarks such as SocialIQA ____, EmoBench ____ and BigToM ____ have been introduced. ____ examines both false-belief understanding and social intelligence to determine if LLMs exhibit Theory of Mind abilities. They found that GPT-3’s social intelligence, as measured by SocialIQA, lags behind humans by over 30\%, and the model struggles with TOMI questions about mental states (55-60\%) compared to factual questions (90-100\%). ____ designs a benchmark to measure social intelligence based on LLMs' ability to understand intentions. They propose the Avalon game, an intention-guided social multi-agent game environment based on LLMs. Consistent with other studies, their results show that LLMs' ability to infer the intentions of others lags behind human performance by 20\%. ____ likewise evaluate LLMs' ability to infer other agents' strategies, goals, and capabilities. They similarly claim that while GPT-4 yields promising results, other models lack in performance, including GPT-3.


\paragraph{Human-Computer Interaction.} The work of ____ focus on human-robot interaction. Their observations indicate that even though LLMs exhibit behavior resembling ToM, these abilities are largely illusory, stemming from advanced language processing rather than a genuine understanding of mental states.

\paragraph{AI Psychology.} ____ find that even though LLMs can handle basic ToM tasks, they perform inconsistently in more advanced scenarios requiring understanding of others' mental states. They notice that LLMs lack the flexibility needed to adapt to varied social contexts. Additionally, ____ suggest that LLMs' information processing is more than mere pattern matching, but is still less sophisticated compared to human ToM abilities.

\paragraph{Negotiation.} ____, ____ and ____ investigate ToM abilities via negotiation. While ____ focus on natural conversations and real-world data for evaluation, ____ propose a game called NegotiationArena in which LLMs can compete against each other. ____ conclude that current state-of-the-art LLMs perform significantly worse than humans, even when using advanced reasoning techniques. ____ similarly report results below human baselines on partner modeling tasks in negotiation dialogues. ____, on the other hand, observe some tactics used by LLMs to improve their success but also note some irrational behavior.

\paragraph{Multi-agent Environment.} Several works on Machine Theory of Mind ____ have employed multi-agent collaboration or competition to assess the ToM skills of LLMs within symmetric environments, where multiple agents interact socially with one another and physically with their surroundings, thereby satisfying the requirements for situatedness. ____ designs a game where 3 agents try to locate and safely defuse color-coded bombs scattered in an unexplored environment. They take action in communicating with each other and update their beliefs accordingly. ____ let the models play Leduc Hold’em, a two-player poker game. Models try to understand opponent's current beliefs and plan their actions accordingly. ____ investigate LLM interactions in the role-playing game Dungeons and Dragons (D\&D) using two agents: a teacher and a student. The teacher acts as the Dungeon Master, guiding the student to encourage specific actions that drive the game forward. The authors explore the LLMs' ability to generate this guidance as a proxy for Theory of Mind capabilities. ____ presents SymmToM, which is a completely symmetric multi-agent environment in which all agents possess the ability to see, hear, speak, move, and actively participate. Successfully navigating SymmToM requires agents to demonstrate varying degrees of theory of mind and communicate effectively using a basic channel with a fixed set of symbols. Lastly, ____ evaluate LLMs' capability to compete and collaborate in several Multi-Agent Reinforcement Learning benchmarks, such as the Melting Pot evaluation suite ____.

\paragraph{Multimodal ToM.} ____ test the ability of the models to recognize emotions from images. They show that LLMs with vision modules are more promising than other techniques, and the performance increases after fine-tuning on the data. ____ likewise claim that ToM tasks are temporal in essence, and thus videos are a suitable medium for evaluating ToM capabilities of LLMs. They report improved results with their novel fine-tuning method but conclude that the results are not robust, possibly due to the scarcity of related video datasets.

\paragraph{Meta Learning.}
Meta-learning in Theory of Mind with large language models refers to the models' ability to quickly understand and generalize well to new tasks with small data, akin to how humans make reasonable judgments based on limited information. ____ propose a new dataset called ToM-in-AMC, where models are expected to understand new characters from new movies based on characters they have seen in different films. The authors demonstrate that all their meta-learning approaches, including those based on GPT-4, lag behind human performance by 20\%. Similarly, ____ frame the problem as a meta-learning task and demonstrate through a series of experiments that their Theory of Mind neural network learns a general model for agents within the training distribution, as well as how to build an agent-specific model online by observing a new agent’s behavior.

\paragraph{Prompting Frameworks.}
One research focus in Machine Theory of Mind involves developing various prompting strategies to improve model performance. Notable works in this area include ____.