% Use this file for citations not found in the ACL Anthology (contained in "anthology.bib").

@book{Aho:72,
    author  = {Alfred V. Aho and Jeffrey D. Ullman},
    title   = {The Theory of Parsing, Translation and Compiling},
    year    = "1972",
    volume  = "1",
    publisher = {Prentice-Hall},
    address = {Englewood Cliffs, NJ}
}

@book{APA:83,
    author  = {{American Psychological Association}},
    title   = {Publications Manual},
    year    = "1983",
    publisher = {American Psychological Association},
    address = {Washington, DC}
}

@article{Chandra:81,
	author = {Ashok K. Chandra and Dexter C. Kozen and Larry J. Stockmeyer},
	year = "1981",
	title = {Alternation},
	journal = {Journal of the Association for Computing Machinery},
	volume = "28",
	number = "1",
	pages = "114--133",
	doi = "10.1145/322234.322243",
}

@inproceedings{andrew2007scalable,
  title={Scalable training of {$L_1$}-regularized log-linear models},
  author={Andrew, Galen and Gao, Jianfeng},
  booktitle={Proceedings of the 24th International Conference on Machine Learning},
  pages={33--40},
  year={2007},
  url={https://dl.acm.org/doi/abs/10.1145/1273496.1273501}
}

@book{Gusfield:97,
    author  = {Dan Gusfield},
    title   = {Algorithms on Strings, Trees and Sequences},
    year    = "1997",
    publisher = {Cambridge University Press},
    address = {Cambridge, UK},
    url={https://www.cambridge.org/core/books/algorithms-on-strings-trees-and-sequences/F0B095049C7E6EF5356F0A26686C20D3}
}

@article{rasooli-tetrault-2015,
    author    = {Mohammad Sadegh Rasooli and Joel R. Tetreault},
    title     = {Yara Parser: {A} Fast and Accurate Dependency Parser},
    journal   = {Computing Research Repository},
    volume    = {arXiv:1503.06733},
    year      = {2015},
    url       = {http://arxiv.org/abs/1503.06733},
    note    = {version 2}
}

@article{Ando2005,
	Acmid = {1194905},
	Author = {Ando, Rie Kubota and Zhang, Tong},
	Issn = {1532-4435},
	Issue_Date = {12/1/2005},
	Journal = {Journal of Machine Learning Research},
	Month = dec,
	Numpages = {37},
	Pages = {1817--1853},
	Publisher = {JMLR.org},
	Title = {A Framework for Learning Predictive Structures from Multiple Tasks and Unlabeled Data},
	Volume = {6},
	Year = {2005},
	url={https://www.jmlr.org/papers/volume6/ando05a/ando05a.pdf}
}

@article{ct1965,
  title={An algorithm for the machine calculation of complex {F}ourier series},
  author={Cooley, James W. and Tukey, John W.},
  journal={Mathematics of Computation},
  volume={19},
  number={90},
  pages={297--301},
  year={1965},
  url={https://www.ams.org/journals/mcom/1965-19-090/S0025-5718-1965-0178586-1/S0025-5718-1965-0178586-1.pdf}
}
@article{Premack1978,
  title={Does the chimpanzee have a theory of mind?},
  author={Premack, David and Woodruff, Guy},
  journal={Behavioral and Brain Sciences},
  volume={1},
  number={4},
  pages={515--526},
  year={1978},
  publisher={Cambridge University Press},
  doi={10.1017/S0140525X00076512}
}
@misc{openai2024gpt4technicalreport,
      title={GPT-4 Technical Report}, 
      author={OpenAI},
      year={2024},
      eprint={2303.08774},
      archivePrefix={arXiv},
      primaryClass={cs.CL},
      url={https://arxiv.org/abs/2303.08774}, 
}
@misc{brown2020languagemodelsfewshotlearners,
      title={Language Models are Few-Shot Learners}, 
      author={Tom B. Brown and Benjamin Mann and Nick Ryder and Melanie Subbiah and Jared Kaplan and Prafulla Dhariwal and Arvind Neelakantan and Pranav Shyam and Girish Sastry and Amanda Askell and Sandhini Agarwal and Ariel Herbert-Voss and Gretchen Krueger and Tom Henighan and Rewon Child and Aditya Ramesh and Daniel M. Ziegler and Jeffrey Wu and Clemens Winter and Christopher Hesse and Mark Chen and Eric Sigler and Mateusz Litwin and Scott Gray and Benjamin Chess and Jack Clark and Christopher Berner and Sam McCandlish and Alec Radford and Ilya Sutskever and Dario Amodei},
      year={2020},
      eprint={2005.14165},
      archivePrefix={arXiv},
      primaryClass={cs.CL},
      url={https://arxiv.org/abs/2005.14165}, 
}
@incollection{VONK202251,
title = {False Dichotomies in the Study of Animal Cognition},
editor = {Sergio {Della Sala}},
booktitle = {Encyclopedia of Behavioral Neuroscience, 2nd edition (Second Edition)},
publisher = {Elsevier},
edition = {Second Edition},
address = {Oxford},
pages = {51-59},
year = {2022},
isbn = {978-0-12-821636-1},
doi = {https://doi.org/10.1016/B978-0-12-809324-5.23955-2},
url = {https://www.sciencedirect.com/science/article/pii/B9780128093245239552},
author = {Jennifer Vonk and Jared Edge},
keywords = {Associative learning, Cognitive processes, Dichotomy, Animal cognition, Reasoning, Mechanism, Nonhuman},
abstract = {Associative learning accounts have been presented as dichotomous with cognitive accounts of animal behavior. However, cognition is largely built upon associative processes. It is more fruitful to examine specific mechanisms and underlying brain structures supporting cognitive processes across diverse species without attempting to label these mechanisms as cognitive versus associative. We explore how this false dichotomy has impeded progress across several key areas of research.}
}
@misc{ullman2023largelanguagemodelsfail,
      title={Large Language Models Fail on Trivial Alterations to Theory-of-Mind Tasks}, 
      author={Tomer Ullman},
      year={2023},
      eprint={2302.08399},
      archivePrefix={arXiv},
      primaryClass={cs.AI},
      url={https://arxiv.org/abs/2302.08399}, 
}
@misc{kosinski2024evaluatinglargelanguagemodels,
      title={Evaluating Large Language Models in Theory of Mind Tasks}, 
      author={Michal Kosinski},
      year={2024},
      eprint={2302.02083},
      archivePrefix={arXiv},
      primaryClass={cs.CL},
      url={https://arxiv.org/abs/2302.02083}, 
}
@inproceedings{van-duijn-etal-2023-theory,
    title = "Theory of Mind in Large Language Models: Examining Performance of 11 State-of-the-Art models vs. Children Aged 7-10 on Advanced Tests",
    author = "van Duijn, Max  and
      van Dijk, Bram  and
      Kouwenhoven, Tom  and
      de Valk, Werner  and
      Spruit, Marco  and
      van der Putten, Peter",
    editor = "Jiang, Jing  and
      Reitter, David  and
      Deng, Shumin",
    booktitle = "Proceedings of the 27th Conference on Computational Natural Language Learning (CoNLL)",
    month = dec,
    year = "2023",
    address = "Singapore",
    publisher = "Association for Computational Linguistics",
    url = "https://aclanthology.org/2023.conll-1.25",
    doi = "10.18653/v1/2023.conll-1.25",
    pages = "389--402",
    abstract = "To what degree should we ascribe cognitive capacities to Large Language Models (LLMs), such as the ability to reason about intentions and beliefs known as Theory of Mind (ToM)? Here we add to this emerging debate by (i) testing 11 base- and instruction-tuned LLMs on capabilities relevant to ToM beyond the dominant false-belief paradigm, including non-literal language usage and recursive intentionality; (ii) using newly rewritten versions of standardized tests to gauge LLMs{'} robustness; (iii) prompting and scoring for open besides closed questions; and (iv) benchmarking LLM performance against that of children aged 7-10 on the same tasks. We find that instruction-tuned LLMs from the GPT family outperform other models, and often also children. Base-LLMs are mostly unable to solve ToM tasks, even with specialized prompting. We suggest that the interlinked evolution and development of language and ToM may help explain what instruction-tuning adds: rewarding cooperative communication that takes into account interlocutor and context. We conclude by arguing for a nuanced perspective on ToM in LLMs.",
}
@inproceedings{ma-etal-2023-towards-holistic,
    title = "Towards A Holistic Landscape of Situated Theory of Mind in Large Language Models",
    author = "Ma, Ziqiao  and
      Sansom, Jacob  and
      Peng, Run  and
      Chai, Joyce",
    editor = "Bouamor, Houda  and
      Pino, Juan  and
      Bali, Kalika",
    booktitle = "Findings of the Association for Computational Linguistics: EMNLP 2023",
    month = dec,
    year = "2023",
    address = "Singapore",
    publisher = "Association for Computational Linguistics",
    url = "https://aclanthology.org/2023.findings-emnlp.72",
    doi = "10.18653/v1/2023.findings-emnlp.72",
    pages = "1011--1031",
    abstract = "Large Language Models (LLMs) have generated considerable interest and debate regarding their potential emergence of Theory of Mind (ToM). Several recent inquiries reveal a lack of robust ToM in these models and pose a pressing demand to develop new benchmarks, as current ones primarily focus on different aspects of ToM and are prone to shortcuts and data leakage. In this position paper, we seek to answer two road-blocking questions: (1) How can we taxonomize a holistic landscape of machine ToM? (2) What is a more effective evaluation protocol for machine ToM? Following psychological studies, we taxonomize machine ToM into 7 mental state categories and delineate existing benchmarks to identify under-explored aspects of ToM. We argue for a holistic and situated evaluation of ToM to break ToM into individual components and treat LLMs as an agent who is physically situated in environments and socially situated in interactions with humans. Such situated evaluation provides a more comprehensive assessment of mental states and potentially mitigates the risk of shortcuts and data leakage. We further present a pilot study in a grid world setup as a proof of concept. We hope this position paper can facilitate future research to integrate ToM with LLMs and offer an intuitive means for researchers to better position their work in the landscape of ToM.",
}
@article{Beaudoin2020,
  author    = {Beaudoin C. and Leblanc É. and Gagner C. and Beauchamp M. H.},
  title     = {Systematic Review and Inventory of Theory of Mind Measures for Young Children},
  journal   = {Frontiers in Psychology},
  volume    = {10},
  pages     = {2905},
  year      = {2020},
  doi       = {10.3389/fpsyg.2019.02905},
  url       = {https://doi.org/10.3389/fpsyg.2019.02905}
}
@misc{rabinowitz2018machinetheorymind,
      title={Machine Theory of Mind}, 
      author={Neil C. Rabinowitz and Frank Perbet and H. Francis Song and Chiyuan Zhang and S. M. Ali Eslami and Matthew Botvinick},
      year={2018},
      eprint={1802.07740},
      archivePrefix={arXiv},
      primaryClass={cs.AI},
      url={https://arxiv.org/abs/1802.07740}, 
}
@misc{lake2016buildingmachineslearnthink,
      title={Building Machines That Learn and Think Like People}, 
      author={Brenden M. Lake and Tomer D. Ullman and Joshua B. Tenenbaum and Samuel J. Gershman},
      year={2016},
      eprint={1604.00289},
      archivePrefix={arXiv},
      primaryClass={cs.AI},
      url={https://arxiv.org/abs/1604.00289}, 
}
@misc{mahowald2024dissociatinglanguagethoughtlarge,
      title={Dissociating language and thought in large language models}, 
      author={Kyle Mahowald and Anna A. Ivanova and Idan A. Blank and Nancy Kanwisher and Joshua B. Tenenbaum and Evelina Fedorenko},
      year={2024},
      eprint={2301.06627},
      archivePrefix={arXiv},
      primaryClass={cs.CL},
      url={https://arxiv.org/abs/2301.06627}, 
}
@misc{dasgupta2024languagemodelshumanlikecontent,
      title={Language models show human-like content effects on reasoning tasks}, 
      author={Ishita Dasgupta and Andrew K. Lampinen and Stephanie C. Y. Chan and Hannah R. Sheahan and Antonia Creswell and Dharshan Kumaran and James L. McClelland and Felix Hill},
      year={2024},
      eprint={2207.07051},
      archivePrefix={arXiv},
      primaryClass={cs.CL},
      url={https://arxiv.org/abs/2207.07051}, 
}
@article{Silver2016,
  author    = {Silver D., Huang A. and Maddison C. J.},
  title     = {Mastering the game of Go with deep neural networks and tree search},
  journal   = {Nature},
  volume    = {529},
  pages     = {484--489},
  year      = {2016},
  doi       = {10.1038/nature16961},
  url       = {https://doi.org/10.1038/nature16961}
}
@misc{zhang2023benchmarkinglargelanguagemodels,
      title={Benchmarking Large Language Models for News Summarization}, 
      author={Tianyi Zhang and Faisal Ladhak and Esin Durmus and Percy Liang and Kathleen McKeown and Tatsunori B. Hashimoto},
      year={2023},
      eprint={2301.13848},
      archivePrefix={arXiv},
      primaryClass={cs.CL},
      url={https://arxiv.org/abs/2301.13848}, 
}
@misc{lewis2021retrievalaugmentedgenerationknowledgeintensivenlp,
      title={Retrieval-Augmented Generation for Knowledge-Intensive NLP Tasks}, 
      author={Patrick Lewis and Ethan Perez and Aleksandra Piktus and Fabio Petroni and Vladimir Karpukhin and Naman Goyal and Heinrich Küttler and Mike Lewis and Wen-tau Yih and Tim Rocktäschel and Sebastian Riedel and Douwe Kiela},
      year={2021},
      eprint={2005.11401},
      archivePrefix={arXiv},
      primaryClass={cs.CL},
      url={https://arxiv.org/abs/2005.11401}, 
}
@inproceedings{zhu-etal-2024-multilingual,
    title = "Multilingual Machine Translation with Large Language Models: Empirical Results and Analysis",
    author = "Zhu, Wenhao  and
      Liu, Hongyi  and
      Dong, Qingxiu  and
      Xu, Jingjing  and
      Huang, Shujian  and
      Kong, Lingpeng  and
      Chen, Jiajun  and
      Li, Lei",
    editor = "Duh, Kevin  and
      Gomez, Helena  and
      Bethard, Steven",
    booktitle = "Findings of the Association for Computational Linguistics: NAACL 2024",
    month = jun,
    year = "2024",
    address = "Mexico City, Mexico",
    publisher = "Association for Computational Linguistics",
    url = "https://aclanthology.org/2024.findings-naacl.176",
    doi = "10.18653/v1/2024.findings-naacl.176",
    pages = "2765--2781",
    abstract = "Large language models (LLMs) have demonstrated remarkable potential in handling multilingual machine translation (MMT). In this paper, we systematically investigate the advantages and challenges of LLMs for MMT by answering two questions: 1) How well do LLMs perform in translating massive languages? 2) Which factors affect LLMs{'} performance in translation? We thoroughly evaluate eight popular LLMs, including ChatGPT and GPT-4. Our empirical results show that translation capabilities of LLMs are continually involving. GPT-4 has beat the strong supervised baseline NLLB in 40.91{\%} of translation directions but still faces a large gap towards the commercial translation system like Google Translate, especially on low-resource languages. Through further analysis, we discover that LLMs exhibit new working patterns when used for MMT. First, LLM can acquire translation ability in a resource-efficient way and generate moderate translation even on zero-resource languages. Second, instruction semantics can surprisingly be ignored when given in-context exemplars. Third, cross-lingual exemplars can provide better task guidance for low-resource translation than exemplars in the same language pairs. Code will be released at: https://github.com/NJUNLP/MMT-LLM.",
}
@article{10.1093/mind/LIX.236.433,
    author = {Turing, A. M.},
    title = "{I.—Computing Machinery and Intelligence}",
    journal = {Mind},
    volume = {LIX},
    number = {236},
    pages = {433-460},
    year = {1950},
    month = {10},
    issn = {0026-4423},
    doi = {10.1093/mind/LIX.236.433},
    url = {https://doi.org/10.1093/mind/LIX.236.433},
    eprint = {https://academic.oup.com/mind/article-pdf/LIX/236/433/30123314/lix-236-433.pdf},
}
@misc{shapira2023cleverhansneuraltheory,
      title={Clever Hans or Neural Theory of Mind? Stress Testing Social Reasoning in Large Language Models}, 
      author={Natalie Shapira and Mosh Levy and Seyed Hossein Alavi and Xuhui Zhou and Yejin Choi and Yoav Goldberg and Maarten Sap and Vered Shwartz},
      year={2023},
      eprint={2305.14763},
      archivePrefix={arXiv},
      primaryClass={cs.CL},
      url={https://arxiv.org/abs/2305.14763}, 
}
@article{FU2023101061,
title = {A systematic review of measures of theory of mind for children},
journal = {Developmental Review},
volume = {67},
pages = {101061},
year = {2023},
issn = {0273-2297},
doi = {https://doi.org/10.1016/j.dr.2022.101061},
url = {https://www.sciencedirect.com/science/article/pii/S027322972200051X},
author = {I-Ning Fu and Kuan-Lin Chen and Meng-Ru Liu and Dai-Rong Jiang and Ching-Lin Hsieh and Shih-Chieh Lee},
keywords = {Measurement tool, Multidimensionality, Theory of Mind, Children, Systematic review},
abstract = {Theory of mind (ToM) is a developmental and multidimensional ability to impute mental states to oneself and others. This systematic review aimed to identify and appraise the current ToM measures for children in terms of their constructs, modes of presentation and response, the test theories adopted to develop them, and psychometric properties. Among the 588 articles retrieved, 127 ToM measures were identified. Twelve measures covered the full spectrum of ToM development in childhood. Only four measures had items in all construct dimensions (i.e., cognitive–interpersonal, cognitive–intrapersonal, affective–interpersonal, and affective–intrapersonal ToM), but they were not designed with specific items on developmental components in every dimension. As regards modes of presentation and response, twenty-one measures designed with visual aids are recommended for children with poor verbal comprehension and expression abilities. Only six measures were constructed or examined with Rasch modeling to better quantify ToM ability. To sum up, currently, no single ToM measure constructed with Rasch modeling and featuring visual aids can assess children’s ToM ability simultaneously and specifically with the multidimensional construct. A thorough ToM measurement for children with the above-mentioned characteristics is warranted for clinicians and researchers to better understand children’s ToM ability and examine the mechanisms governing the developmental and multidimensional constructs.}
}

@book{tomasello1999cultural,
  title     = {The Cultural Origins of Human Cognition},
  author    = {Tomasello, Michael},
  year      = {1999},
  publisher = {Harvard University Press},
}
@article{banerjee2011peer,
  title={Peer relations and the understanding of faux pas: longitudinal evidence for bidirectional associations},
  author={Banerjee, Robin and Watling, Dawn and Caputi, Marcella},
  journal={Child Development},
  volume={82},
  number={6},
  pages={1887--1905},
  year={2011},
  publisher={Wiley},
  doi={10.1111/j.1467-8624.2011.01669.x},
  pmid={22023260}
}
@article{hofmann2016training,
  title={Training children's theory-of-mind: A meta-analysis of controlled studies},
  author={Hofmann, Stefan G. and Doan, Stacey N. and Sprung, Manuel and Wilson, Anne and Ebesutani, Chad and Andrews, Leigh and Curtiss, Joshua and Harris, Paul L.},
  journal={Cognition},
  volume={150},
  pages={200--212},
  year={2016},
  publisher={Elsevier},
  doi={10.1016/j.cognition.2016.01.006}
}
@article{rakoczy2022foundations,
  title={Foundations of theory of mind and its development in early childhood},
  author={Rakoczy, Hannes},
  journal={Nature Reviews Psychology},
  volume={1},
  pages={223--235},
  year={2022},
  publisher={Nature Publishing Group},
  doi={10.1038/s44159-022-00037-z}
}
@incollection{wellman2011childhood,
  author    = {Henry M. Wellman},
  title     = {Theory of Mind: Better Methods, Better Data, Better Questions},
  booktitle = {The Wiley-Blackwell Handbook of Childhood Cognitive Development},
  editor    = {Usha Goswami},
  pages     = {258--284},
  edition   = {2nd},
  publisher = {Wiley-Blackwell},
  year      = {2011},
  address   = {Malden, MA},
}
@article{Knafo2009Empathy,
  author    = {Ariel Knafo and Carolyn Zahn-Waxler and Maayan Davidov and C. Van Hulle and Jason L. Robinson and Soo H. Rhee},
  title     = {Empathy in early childhood: genetic, environmental, and affective contributions},
  journal   = {Annals of the New York Academy of Sciences},
  year      = {2009},
  volume    = {1167},
  pages     = {103--114},
  month     = {Jun},
  doi       = {10.1111/j.1749-6632.2009.04540.x},
  pmid      = {19580557},
}

@article{Denham1986Social,
  author    = {Susanne A. Denham},
  title     = {Social cognition, prosocial behavior, and emotion in preschoolers: contextual validation},
  journal   = {Child Development},
  year      = {1986},
  volume    = {57},
  pages     = {194--201},
  doi       = {10.2307/1130651},
}

@inproceedings{Gordis1989Young,
  author    = {Edward W. Gordis and Angela B. Rosen and Stephen Grand},
  title     = {Young children’s understanding of simultaneous conflicting emotions},
  booktitle = {Paper Presented at the Biennial Meeting of the Society for Research in Child Development},
  year      = {1989},
  address   = {Kansas City, MO},
}
@book{Pons2000Test,
  author    = {Fabrice Pons and Paul L. Harris},
  title     = {Test of Emotion Comprehension–TEC},
  year      = {2000},
  publisher = {University of Oxford},
  address   = {Oxford},
}
@article{Repacholi1997Early,
  author    = {Betty M. Repacholi and Alison Gopnik},
  title     = {Early reasoning about desires: evidence from 14- and 18-month-olds},
  journal   = {Developmental Psychology},
  year      = {1997},
  volume    = {33},
  pages     = {12--21},
  doi       = {10.1037/0012-1649.33.1.12},
}
@article{Bennett1993Children,
  author    = {Mark Bennett and Lisa Galpert},
  title     = {Children’s understanding of multiple desires},
  journal   = {International Journal of Behavioral Development},
  year      = {1993},
  volume    = {16},
  pages     = {15--33},
  doi       = {10.1177/016502549301600102},
}
@article{Wellman1988Young,
  author    = {Henry M. Wellman and Karen Bartsch},
  title     = {Young children’s reasoning about beliefs},
  journal   = {Cognition},
  year      = {1988},
  volume    = {30},
  pages     = {239--277},
  doi       = {10.1016/0010-0277(88)90021-2},
}

@article{Colonnesi2008Precursors,
  author    = {Catherine Colonnesi and Carin Rieffe and Wilma Koops and Paolo Perucchini},
  title     = {Precursors of a theory of mind: a longitudinal study},
  journal   = {British Journal of Developmental Psychology},
  year      = {2008},
  volume    = {26},
  pages     = {561--577},
  doi       = {10.1348/026151008X285660},
}

@article{Meltzoff1995Understanding,
  author    = {Andrew N. Meltzoff},
  title     = {Understanding the intentions of others: re-enactment of intended acts by 18-month-old children},
  journal   = {Developmental Psychology},
  year      = {1995},
  volume    = {31},
  pages     = {838--850},
  doi       = {10.1037/0012-1649.31.5.838},
}

@article{Killen2011Accidental,
  author    = {Melinda Killen and K. Lynn Mulvey and C. Richardson and N. Jampol and Alison Woodward},
  title     = {The accidental transgressor: morally-relevant theory of mind},
  journal   = {Cognition},
  year      = {2011},
  volume    = {119},
  pages     = {197--215},
  doi       = {10.1016/j.cognition.2011.01.006},
}

@article{Phillips2002Infants,
  author    = {Anne T. Phillips and Henry M. Wellman and Elizabeth S. Spelke},
  title     = {Infants’ ability to connect gaze and emotional expression to intentional action},
  journal   = {Cognition},
  year      = {2002},
  volume    = {85},
  pages     = {53--78},
  doi       = {10.1016/S0010-0277(02)00073-2},
}

@article{Castelli2006Valley,
  author    = {Fulvia Castelli},
  title     = {The Valley task: Understanding intention from goal-directed motion in typical development and autism},
  journal   = {British Journal of Developmental Psychology},
  year      = {2006},
  volume    = {24},
  pages     = {655--668},
  doi       = {10.1348/026151005X54209},
}

@article{Smiley2001Intention,
  author    = {Patricia A. Smiley},
  title     = {Intention understanding and partner-sensitive behaviors in young children’s peer interactions},
  journal   = {Social Development},
  year      = {2001},
  volume    = {10},
  pages     = {330--354},
  doi       = {10.1111/1467-9507.00169},
}
@article{Masangkay1974Early,
  author    = {Z. S. Masangkay and K. A. McCluskey and C. W. McIntyre and J. Sims-Knight and B. E. Vaughn and J. H. Flavell},
  title     = {The early development of inferences about the visual percepts of others},
  journal   = {Child Development},
  year      = {1974},
  volume    = {45},
  pages     = {357--366},
  doi       = {10.2307/1127956},
}

@article{Ebersbach2011Relationship,
  author    = {M. Ebersbach and S. Stiehler and P. Asmus},
  title     = {On the relationship between children’s perspective taking in complex scenes and their spatial drawing ability},
  journal   = {British Journal of Developmental Psychology},
  year      = {2011},
  volume    = {29},
  pages     = {455--474},
  doi       = {10.1348/026151010X504942},
}

@article{Hadwin1997Teaching,
  author    = {James Hadwin and Simon Baron-Cohen and Patricia Howlin and Kathryn Hill},
  title     = {Does teaching theory of mind have an effect on the ability to develop conversation in children with autism?},
  journal   = {Journal of Autism and Developmental Disorders},
  year      = {1997},
  volume    = {27},
  pages     = {519--537},
  doi       = {10.1023/A:1025826009731},
}

@article{Williamson2015Sound,
  author    = {R. A. Williamson and R. Brooks and A. N. Meltzoff},
  title     = {The sound of social cognition: Toddlers’ understanding of how sound influences others},
  journal   = {Journal of Cognition and Development},
  year      = {2015},
  volume    = {16},
  pages     = {252--260},
  doi       = {10.1080/15248372.2013.824884},
}

@article{Aronson1999Preschoolers,
  author    = {J. N. Aronson and C. Golomb},
  title     = {Preschoolers’ understanding of pretense and presumption of congruity between action and representation},
  journal   = {Developmental Psychology},
  year      = {1999},
  volume    = {35},
  pages     = {1414--1425},
  doi       = {10.1037/0012-1649.35.6.1414},
}

@article{Ruffman1989Children,
  author    = {Ted K. Ruffman and David R. Olson},
  title     = {Children’s ascriptions of knowledge to others},
  journal   = {Developmental Psychology},
  year      = {1989},
  volume    = {25},
  pages     = {601--606},
  doi       = {10.1037/0012-1649.25.4.601},
}

@article{Peskin2014Keeping,
  author    = {Joan Peskin and C. Prusky and J. Comay},
  title     = {Keeping the reader’s mind in mind: development of perspective-taking in children’s dictations},
  journal   = {Journal of Applied Developmental Psychology},
  year      = {2014},
  volume    = {35},
  pages     = {35--43},
  doi       = {10.1016/j.appdev.2013.11.001},
}

@article{Moll2006Infants,
  author    = {Henrike Moll and Cornelia Koring and Malinda Carpenter and Michael Tomasello},
  title     = {Infants determine others’ focus of attention by pragmatics and exclusion},
  journal   = {Journal of Cognition and Development},
  year      = {2006},
  volume    = {7},
  number    = {3},
  pages     = {411--430},
  doi       = {10.1207/s15327647jcd0703_9},
}
@article{Hogrefe1986Ignorance,
  author    = {G.-J. Hogrefe and H. Wimmer and J. Perner},
  title     = {Ignorance versus false belief: a developmental lag in attribution of epistemic states},
  journal   = {Child Development},
  year      = {1986},
  volume    = {57},
  pages     = {567--582},
  doi       = {10.2307/1130337},
}
@article{Wimmer1983Beliefs,
  author    = {Heinz Wimmer and Josef Perner},
  title     = {Beliefs about beliefs: representation and constraining function of wrong beliefs in young children’s understanding of deception},
  journal   = {Cognition},
  year      = {1983},
  volume    = {13},
  pages     = {103--128},
  doi       = {10.1016/0010-0277(83)90004-5},
}

@article{Flavell1986Development,
  author    = {John H. Flavell and Frances L. Green and Eleanor R. Flavell and M. W. Watson and J. C. Campione},
  title     = {Development of knowledge about the appearance-reality distinction},
  journal   = {Monographs of the Society for Research in Child Development},
  year      = {1986},
  volume    = {51},
  pages     = {1--87},
  doi       = {10.2307/1165866},
}
@article{Perner1985John,
  author    = {Josef Perner and Heinz Wimmer},
  title     = {“John thinks that Mary thinks that...”: attribution of second-order beliefs by 5- to 10-year-old children},
  journal   = {Journal of Experimental Child Psychology},
  year      = {1985},
  volume    = {39},
  pages     = {437--471},
  doi       = {10.1016/0022-0965(85)90051-7},
}
@article{Swettenham1996Children,
  author    = {John Swettenham},
  title     = {Can children be taught to understand false belief using computers?},
  journal   = {Journal of Child Psychology and Psychiatry and Allied Disciplines},
  year      = {1996},
  volume    = {37},
  pages     = {157--165},
  doi       = {10.1111/j.1469-7610.1996.tb01387.x},
}

@article{Brambring2010Validity,
  author    = {Michael Brambring and Doreen Asbrock},
  title     = {Validity of false belief tasks in blind children},
  journal   = {Journal of Autism and Developmental Disorders},
  year      = {2010},
  volume    = {40},
  pages     = {1471--1484},
  doi       = {10.1007/s10803-010-1002-2},
}
@article{Sullivan1995Children,
  author    = {K. Sullivan and E. Winner and N. Hopfield},
  title     = {How children tell a lie from a joke: the role of second-order mental state attributions},
  journal   = {British Journal of Developmental Psychology},
  year      = {1995},
  volume    = {13},
  pages     = {191--204},
  doi       = {10.1111/j.2044-835X.1995.tb00673.x},
}

@article{Happe1994Advanced,
  author    = {Francesca G. E. Happé},
  title     = {An advanced test of theory of mind: understanding of story characters’ thoughts and feelings by able autistic, mentally handicapped, and normal children and adults},
  journal   = {Journal of Autism and Developmental Disorders},
  year      = {1994},
  volume    = {24},
  pages     = {129--154},
  doi       = {10.1007/BF02172093},
}

@article{BaronCohen1999Recognition,
  author    = {Simon Baron-Cohen and Michelle O’Riordan and Valerie Stone and Rosie Jones and Kate Plaisted},
  title     = {Recognition of faux pas by normally developing children and children with Asperger syndrome or high-functioning autism},
  journal   = {Journal of Autism and Developmental Disorders},
  year      = {1999},
  volume    = {29},
  pages     = {407--418},
  doi       = {10.1023/A:1023035012436},
}
@misc{chang2023surveyevaluationlargelanguage,
      title={A Survey on Evaluation of Large Language Models}, 
      author={Yupeng Chang and Xu Wang and Jindong Wang and Yuan Wu and Linyi Yang and Kaijie Zhu and Hao Chen and Xiaoyuan Yi and Cunxiang Wang and Yidong Wang and Wei Ye and Yue Zhang and Yi Chang and Philip S. Yu and Qiang Yang and Xing Xie},
      year={2023},
      eprint={2307.03109},
      archivePrefix={arXiv},
      primaryClass={cs.CL},
      url={https://arxiv.org/abs/2307.03109}, 
}
@misc{xu2024carepromptbiasinvestigating,
      title={Take Care of Your Prompt Bias! Investigating and Mitigating Prompt Bias in Factual Knowledge Extraction}, 
      author={Ziyang Xu and Keqin Peng and Liang Ding and Dacheng Tao and Xiliang Lu},
      year={2024},
      eprint={2403.09963},
      archivePrefix={arXiv},
      primaryClass={cs.CL},
      url={https://arxiv.org/abs/2403.09963}, 
}

@misc{hagendorff2024machinepsychology,
      title={Machine Psychology}, 
      author={Thilo Hagendorff and Ishita Dasgupta and Marcel Binz and Stephanie C. Y. Chan and Andrew Lampinen and Jane X. Wang and Zeynep Akata and Eric Schulz},
      year={2024},
      eprint={2303.13988},
      archivePrefix={arXiv},
      primaryClass={cs.CL},
      url={https://arxiv.org/abs/2303.13988}, 
}

@misc{fei2023mitigatinglabelbiasesincontext,
      title={Mitigating Label Biases for In-context Learning}, 
      author={Yu Fei and Yifan Hou and Zeming Chen and Antoine Bosselut},
      year={2023},
      eprint={2305.19148},
      archivePrefix={arXiv},
      primaryClass={cs.CL},
      url={https://arxiv.org/abs/2305.19148}, 
}
@misc{lu2022fantasticallyorderedpromptsthem,
      title={Fantastically Ordered Prompts and Where to Find Them: Overcoming Few-Shot Prompt Order Sensitivity}, 
      author={Yao Lu and Max Bartolo and Alastair Moore and Sebastian Riedel and Pontus Stenetorp},
      year={2022},
      eprint={2104.08786},
      archivePrefix={arXiv},
      primaryClass={cs.CL},
      url={https://arxiv.org/abs/2104.08786}, 
}
@inproceedings{ma-etal-2023-deciphering,
    title = "Deciphering Stereotypes in Pre-Trained Language Models",
    author = "Ma, Weicheng  and
      Scheible, Henry  and
      Wang, Brian  and
      Veeramachaneni, Goutham  and
      Chowdhary, Pratim  and
      Sun, Alan  and
      Koulogeorge, Andrew  and
      Wang, Lili  and
      Yang, Diyi  and
      Vosoughi, Soroush",
    editor = "Bouamor, Houda  and
      Pino, Juan  and
      Bali, Kalika",
    booktitle = "Proceedings of the 2023 Conference on Empirical Methods in Natural Language Processing",
    month = dec,
    year = "2023",
    address = "Singapore",
    publisher = "Association for Computational Linguistics",
    url = "https://aclanthology.org/2023.emnlp-main.697",
    doi = "10.18653/v1/2023.emnlp-main.697",
    pages = "11328--11345",
    abstract = "Warning: This paper contains content that is stereotypical and may be upsetting. This paper addresses the issue of demographic stereotypes present in Transformer-based pre-trained language models (PLMs) and aims to deepen our understanding of how these biases are encoded in these models. To accomplish this, we introduce an easy-to-use framework for examining the stereotype-encoding behavior of PLMs through a combination of model probing and textual analyses. Our findings reveal that a small subset of attention heads within PLMs are primarily responsible for encoding stereotypes and that stereotypes toward specific minority groups can be identified using attention maps on these attention heads. Leveraging these insights, we propose an attention-head pruning method as a viable approach for debiasing PLMs, without compromising their language modeling capabilities or adversely affecting their performance on downstream tasks.",
}
@misc{manvi2024largelanguagemodelsgeographically,
      title={Large Language Models are Geographically Biased}, 
      author={Rohin Manvi and Samar Khanna and Marshall Burke and David Lobell and Stefano Ermon},
      year={2024},
      eprint={2402.02680},
      archivePrefix={arXiv},
      primaryClass={cs.CL},
      url={https://arxiv.org/abs/2402.02680}, 
}
@misc{bolukbasi2016mancomputerprogrammerwoman,
      title={Man is to Computer Programmer as Woman is to Homemaker? Debiasing Word Embeddings}, 
      author={Tolga Bolukbasi and Kai-Wei Chang and James Zou and Venkatesh Saligrama and Adam Kalai},
      year={2016},
      eprint={1607.06520},
      archivePrefix={arXiv},
      primaryClass={cs.CL},
      url={https://arxiv.org/abs/1607.06520}, 
}
@inproceedings{Dhamala_2021, series={FAccT ’21},
   title={BOLD: Dataset and Metrics for Measuring Biases in Open-Ended Language Generation},
   url={http://dx.doi.org/10.1145/3442188.3445924},
   DOI={10.1145/3442188.3445924},
   booktitle={Proceedings of the 2021 ACM Conference on Fairness, Accountability, and Transparency},
   publisher={ACM},
   author={Dhamala, Jwala and Sun, Tony and Kumar, Varun and Krishna, Satyapriya and Pruksachatkun, Yada and Chang, Kai-Wei and Gupta, Rahul},
   year={2021},
   month=mar, collection={FAccT ’21} }
@misc{parrish2022bbqhandbuiltbiasbenchmark,
      title={BBQ: A Hand-Built Bias Benchmark for Question Answering}, 
      author={Alicia Parrish and Angelica Chen and Nikita Nangia and Vishakh Padmakumar and Jason Phang and Jana Thompson and Phu Mon Htut and Samuel R. Bowman},
      year={2022},
      eprint={2110.08193},
      archivePrefix={arXiv},
      primaryClass={cs.CL},
      url={https://arxiv.org/abs/2110.08193}, 
}

@inproceedings{smith-etal-2022-im,
    title = "{``}{I}{'}m sorry to hear that{''}: Finding New Biases in Language Models with a Holistic Descriptor Dataset",
    author = "Smith, Eric Michael  and
      Hall, Melissa  and
      Kambadur, Melanie  and
      Presani, Eleonora  and
      Williams, Adina",
    editor = "Goldberg, Yoav  and
      Kozareva, Zornitsa  and
      Zhang, Yue",
    booktitle = "Proceedings of the 2022 Conference on Empirical Methods in Natural Language Processing",
    month = dec,
    year = "2022",
    address = "Abu Dhabi, United Arab Emirates",
    publisher = "Association for Computational Linguistics",
    url = "https://aclanthology.org/2022.emnlp-main.625",
    doi = "10.18653/v1/2022.emnlp-main.625",
    pages = "9180--9211",
    abstract = "As language models grow in popularity, it becomes increasingly important to clearly measure all possible markers of demographic identity in order to avoid perpetuating existing societal harms. Many datasets for measuring bias currently exist, but they are restricted in their coverage of demographic axes and are commonly used with preset bias tests that presuppose which types of biases models can exhibit. In this work, we present a new, more inclusive bias measurement dataset, HolisticBias, which includes nearly 600 descriptor terms across 13 different demographic axes. HolisticBias was assembled in a participatory process including experts and community members with lived experience of these terms. These descriptors combine with a set of bias measurement templates to produce over 450,000 unique sentence prompts, which we use to explore, identify, and reduce novel forms of bias in several generative models. We demonstrate that HolisticBias is effective at measuring previously undetectable biases in token likelihoods from language models, as well as in an offensiveness classifier. We will invite additions and amendments to the dataset, which we hope will serve as a basis for more easy-to-use and standardized methods for evaluating bias in NLP models.",
}
@inproceedings{zmigrod-etal-2019-counterfactual,
    title = "Counterfactual Data Augmentation for Mitigating Gender Stereotypes in Languages with Rich Morphology",
    author = "Zmigrod, Ran  and
      Mielke, Sabrina J.  and
      Wallach, Hanna  and
      Cotterell, Ryan",
    editor = "Korhonen, Anna  and
      Traum, David  and
      M{\`a}rquez, Llu{\'\i}s",
    booktitle = "Proceedings of the 57th Annual Meeting of the Association for Computational Linguistics",
    month = jul,
    year = "2019",
    address = "Florence, Italy",
    publisher = "Association for Computational Linguistics",
    url = "https://aclanthology.org/P19-1161",
    doi = "10.18653/v1/P19-1161",
    pages = "1651--1661",
    abstract = "Gender stereotypes are manifest in most of the world{'}s languages and are consequently propagated or amplified by NLP systems. Although research has focused on mitigating gender stereotypes in English, the approaches that are commonly employed produce ungrammatical sentences in morphologically rich languages. We present a novel approach for converting between masculine-inflected and feminine-inflected sentences in such languages. For Spanish and Hebrew, our approach achieves F1 scores of 82{\%} and 73{\%} at the level of tags and accuracies of 90{\%} and 87{\%} at the level of forms. By evaluating our approach using four different languages, we show that, on average, it reduces gender stereotyping by a factor of 2.5 without any sacrifice to grammaticality.",
}
@misc{webster2021measuringreducinggenderedcorrelations,
      title={Measuring and Reducing Gendered Correlations in Pre-trained Models}, 
      author={Kellie Webster and Xuezhi Wang and Ian Tenney and Alex Beutel and Emily Pitler and Ellie Pavlick and Jilin Chen and Ed Chi and Slav Petrov},
      year={2021},
      eprint={2010.06032},
      archivePrefix={arXiv},
      primaryClass={cs.CL},
      url={https://arxiv.org/abs/2010.06032}, 
}
@inproceedings{ravfogel-etal-2020-null,
    title = "Null It Out: Guarding Protected Attributes by Iterative Nullspace Projection",
    author = "Ravfogel, Shauli  and
      Elazar, Yanai  and
      Gonen, Hila  and
      Twiton, Michael  and
      Goldberg, Yoav",
    editor = "Jurafsky, Dan  and
      Chai, Joyce  and
      Schluter, Natalie  and
      Tetreault, Joel",
    booktitle = "Proceedings of the 58th Annual Meeting of the Association for Computational Linguistics",
    month = jul,
    year = "2020",
    address = "Online",
    publisher = "Association for Computational Linguistics",
    url = "https://aclanthology.org/2020.acl-main.647",
    doi = "10.18653/v1/2020.acl-main.647",
    pages = "7237--7256",
    abstract = "The ability to control for the kinds of information encoded in neural representation has a variety of use cases, especially in light of the challenge of interpreting these models. We present Iterative Null-space Projection (INLP), a novel method for removing information from neural representations. Our method is based on repeated training of linear classifiers that predict a certain property we aim to remove, followed by projection of the representations on their null-space. By doing so, the classifiers become oblivious to that target property, making it hard to linearly separate the data according to it. While applicable for multiple uses, we evaluate our method on bias and fairness use-cases, and show that our method is able to mitigate bias in word embeddings, as well as to increase fairness in a setting of multi-class classification.",
}
@misc{schick2021selfdiagnosisselfdebiasingproposalreducing,
      title={Self-Diagnosis and Self-Debiasing: A Proposal for Reducing Corpus-Based Bias in NLP}, 
      author={Timo Schick and Sahana Udupa and Hinrich Schütze},
      year={2021},
      eprint={2103.00453},
      archivePrefix={arXiv},
      primaryClass={cs.CL},
      url={https://arxiv.org/abs/2103.00453}, 
}
@inproceedings{liang-etal-2020-towards,
    title = "Towards Debiasing Sentence Representations",
    author = "Liang, Paul Pu  and
      Li, Irene Mengze  and
      Zheng, Emily  and
      Lim, Yao Chong  and
      Salakhutdinov, Ruslan  and
      Morency, Louis-Philippe",
    editor = "Jurafsky, Dan  and
      Chai, Joyce  and
      Schluter, Natalie  and
      Tetreault, Joel",
    booktitle = "Proceedings of the 58th Annual Meeting of the Association for Computational Linguistics",
    month = jul,
    year = "2020",
    address = "Online",
    publisher = "Association for Computational Linguistics",
    url = "https://aclanthology.org/2020.acl-main.488",
    doi = "10.18653/v1/2020.acl-main.488",
    pages = "5502--5515",
    abstract = "As natural language processing methods are increasingly deployed in real-world scenarios such as healthcare, legal systems, and social science, it becomes necessary to recognize the role they potentially play in shaping social biases and stereotypes. Previous work has revealed the presence of social biases in widely used word embeddings involving gender, race, religion, and other social constructs. While some methods were proposed to debias these word-level embeddings, there is a need to perform debiasing at the sentence-level given the recent shift towards new contextualized sentence representations such as ELMo and BERT. In this paper, we investigate the presence of social biases in sentence-level representations and propose a new method, Sent-Debias, to reduce these biases. We show that Sent-Debias is effective in removing biases, and at the same time, preserves performance on sentence-level downstream tasks such as sentiment analysis, linguistic acceptability, and natural language understanding. We hope that our work will inspire future research on characterizing and removing social biases from widely adopted sentence representations for fairer NLP.",
}

@misc{ranaldi2023tripfairnessbiasdebiasing,
      title={A Trip Towards Fairness: Bias and De-Biasing in Large Language Models}, 
      author={Leonardo Ranaldi and Elena Sofia Ruzzetti and Davide Venditti and Dario Onorati and Fabio Massimo Zanzotto},
      year={2023},
      eprint={2305.13862},
      archivePrefix={arXiv},
      primaryClass={cs.CL},
      url={https://arxiv.org/abs/2305.13862}, 
}
@misc{hu2021loralowrankadaptationlarge,
      title={LoRA: Low-Rank Adaptation of Large Language Models}, 
      author={Edward J. Hu and Yelong Shen and Phillip Wallis and Zeyuan Allen-Zhu and Yuanzhi Li and Shean Wang and Lu Wang and Weizhu Chen},
      year={2021},
      eprint={2106.09685},
      archivePrefix={arXiv},
      primaryClass={cs.CL},
      url={https://arxiv.org/abs/2106.09685}, 
}
@misc{moghaddam2023boostingtheoryofmindperformancelarge,
      title={Boosting Theory-of-Mind Performance in Large Language Models via Prompting}, 
      author={Shima Rahimi Moghaddam and Christopher J. Honey},
      year={2023},
      eprint={2304.11490},
      archivePrefix={arXiv},
      primaryClass={cs.AI},
      url={https://arxiv.org/abs/2304.11490}, 
}
@inproceedings{sap-etal-2022-neural,
    title = "Neural Theory-of-Mind? On the Limits of Social Intelligence in Large {LM}s",
    author = "Sap, Maarten  and
      Le Bras, Ronan  and
      Fried, Daniel  and
      Choi, Yejin",
    editor = "Goldberg, Yoav  and
      Kozareva, Zornitsa  and
      Zhang, Yue",
    booktitle = "Proceedings of the 2022 Conference on Empirical Methods in Natural Language Processing",
    month = dec,
    year = "2022",
    address = "Abu Dhabi, United Arab Emirates",
    publisher = "Association for Computational Linguistics",
    url = "https://aclanthology.org/2022.emnlp-main.248",
    doi = "10.18653/v1/2022.emnlp-main.248",
    pages = "3762--3780",
    abstract = "Social intelligence and Theory of Mind (TOM), i.e., the ability to reason about the different mental states, intents, and reactions of all people involved, allows humans to effectively navigate and understand everyday social interactions. As NLP systems are used in increasingly complex social situations, their ability to grasp social dynamics becomes crucial.In this work, we examine the open question of social intelligence and Theory of Mind in modern NLP systems from an empirical and theorybased perspective. We show that one of today{'}s largest language models (GPT-3; Brown et al., 2020) lacks this kind of social intelligence out-of-the box, using two tasks: SocialIQa (Sap et al., 2019), which measure models{'} ability to understand intents and reactions of participants of social interactions, and ToMi (Le, Boureau, and Nickel, 2019), which measures whether models can infer mental states and realities of participants of situations.Our results show that models struggle substantially at these Theory of Mind tasks, with well-below-human accuracies of 55{\%} and 60{\%} on SocialIQa and ToMi, respectively. To conclude, we draw on theories from pragmatics to contextualize this shortcoming of large language models, by examining the limitations stemming from their data, neural architecture, and training paradigms. Challenging the prevalent narrative that only scale is needed, we posit that person-centric NLP approaches might be more effective towards neural Theory of Mind.",
}
@inproceedings{sap-etal-2019-social,
    title = "Social {IQ}a: Commonsense Reasoning about Social Interactions",
    author = "Sap, Maarten  and
      Rashkin, Hannah  and
      Chen, Derek  and
      Le Bras, Ronan  and
      Choi, Yejin",
    editor = "Inui, Kentaro  and
      Jiang, Jing  and
      Ng, Vincent  and
      Wan, Xiaojun",
    booktitle = "Proceedings of the 2019 Conference on Empirical Methods in Natural Language Processing and the 9th International Joint Conference on Natural Language Processing (EMNLP-IJCNLP)",
    month = nov,
    year = "2019",
    address = "Hong Kong, China",
    publisher = "Association for Computational Linguistics",
    url = "https://aclanthology.org/D19-1454",
    doi = "10.18653/v1/D19-1454",
    pages = "4463--4473",
    abstract = "We introduce Social IQa, the first large-scale benchmark for commonsense reasoning about social situations. Social IQa contains 38,000 multiple choice questions for probing emotional and social intelligence in a variety of everyday situations (e.g., Q: {``}Jordan wanted to tell Tracy a secret, so Jordan leaned towards Tracy. Why did Jordan do this?{''} A: {``}Make sure no one else could hear{''}). Through crowdsourcing, we collect commonsense questions along with correct and incorrect answers about social interactions, using a new framework that mitigates stylistic artifacts in incorrect answers by asking workers to provide the right answer to a different but related question. Empirical results show that our benchmark is challenging for existing question-answering models based on pretrained language models, compared to human performance ({\textgreater}20{\%} gap). Notably, we further establish Social IQa as a resource for transfer learning of commonsense knowledge, achieving state-of-the-art performance on multiple commonsense reasoning tasks (Winograd Schemas, COPA).",
}
@misc{si2023measuringinductivebiasesincontext,
      title={Measuring Inductive Biases of In-Context Learning with Underspecified Demonstrations}, 
      author={Chenglei Si and Dan Friedman and Nitish Joshi and Shi Feng and Danqi Chen and He He},
      year={2023},
      eprint={2305.13299},
      archivePrefix={arXiv},
      primaryClass={cs.CL},
      url={https://arxiv.org/abs/2305.13299}, 
}
@misc{zheng2024largelanguagemodelsrobust,
      title={Large Language Models Are Not Robust Multiple Choice Selectors}, 
      author={Chujie Zheng and Hao Zhou and Fandong Meng and Jie Zhou and Minlie Huang},
      year={2024},
      eprint={2309.03882},
      archivePrefix={arXiv},
      primaryClass={cs.CL},
      url={https://arxiv.org/abs/2309.03882}, 
}
@misc{zhao2021calibrateuseimprovingfewshot,
      title={Calibrate Before Use: Improving Few-Shot Performance of Language Models}, 
      author={Tony Z. Zhao and Eric Wallace and Shi Feng and Dan Klein and Sameer Singh},
      year={2021},
      eprint={2102.09690},
      archivePrefix={arXiv},
      primaryClass={cs.CL},
      url={https://arxiv.org/abs/2102.09690}, 
}
@misc{zheng2023judgingllmasajudgemtbenchchatbot,
      title={Judging LLM-as-a-Judge with MT-Bench and Chatbot Arena}, 
      author={Lianmin Zheng and Wei-Lin Chiang and Ying Sheng and Siyuan Zhuang and Zhanghao Wu and Yonghao Zhuang and Zi Lin and Zhuohan Li and Dacheng Li and Eric P. Xing and Hao Zhang and Joseph E. Gonzalez and Ion Stoica},
      year={2023},
      eprint={2306.05685},
      archivePrefix={arXiv},
      primaryClass={cs.CL},
      url={https://arxiv.org/abs/2306.05685}, 
}
@article{Saito2023VerbosityBI,
  title={Verbosity Bias in Preference Labeling by Large Language Models},
  author={Keita Saito and Akifumi Wachi and Koki Wataoka and Youhei Akimoto},
  journal={ArXiv},
  year={2023},
  volume={abs/2310.10076},
  url={https://api.semanticscholar.org/CorpusID:264147087}
}

@misc{robinson2023leveraginglargelanguagemodels,
      title={Leveraging Large Language Models for Multiple Choice Question Answering}, 
      author={Joshua Robinson and Christopher Michael Rytting and David Wingate},
      year={2023},
      eprint={2210.12353},
      archivePrefix={arXiv},
      primaryClass={cs.CL},
      url={https://arxiv.org/abs/2210.12353}, 
}
@inproceedings{karimi-mahabadi-etal-2020-end,
    title = "End-to-End Bias Mitigation by Modelling Biases in Corpora",
    author = "Karimi Mahabadi, Rabeeh  and
      Belinkov, Yonatan  and
      Henderson, James",
    editor = "Jurafsky, Dan  and
      Chai, Joyce  and
      Schluter, Natalie  and
      Tetreault, Joel",
    booktitle = "Proceedings of the 58th Annual Meeting of the Association for Computational Linguistics",
    month = jul,
    year = "2020",
    address = "Online",
    publisher = "Association for Computational Linguistics",
    url = "https://aclanthology.org/2020.acl-main.769",
    doi = "10.18653/v1/2020.acl-main.769",
    pages = "8706--8716",
    abstract = "Several recent studies have shown that strong natural language understanding (NLU) models are prone to relying on unwanted dataset biases without learning the underlying task, resulting in models that fail to generalize to out-of-domain datasets and are likely to perform poorly in real-world scenarios. We propose two learning strategies to train neural models, which are more robust to such biases and transfer better to out-of-domain datasets. The biases are specified in terms of one or more bias-only models, which learn to leverage the dataset biases. During training, the bias-only models{'} predictions are used to adjust the loss of the base model to reduce its reliance on biases by down-weighting the biased examples and focusing the training on the hard examples. We experiment on large-scale natural language inference and fact verification benchmarks, evaluating on out-of-domain datasets that are specifically designed to assess the robustness of models against known biases in the training data. Results show that our debiasing methods greatly improve robustness in all settings and better transfer to other textual entailment datasets. Our code and data are publicly available in \url{https://github.com/rabeehk/robust-nli}.",
}
@inproceedings{utama-etal-2020-towards,
    title = "Towards Debiasing {NLU} Models from Unknown Biases",
    author = "Utama, Prasetya Ajie  and
      Moosavi, Nafise Sadat  and
      Gurevych, Iryna",
    editor = "Webber, Bonnie  and
      Cohn, Trevor  and
      He, Yulan  and
      Liu, Yang",
    booktitle = "Proceedings of the 2020 Conference on Empirical Methods in Natural Language Processing (EMNLP)",
    month = nov,
    year = "2020",
    address = "Online",
    publisher = "Association for Computational Linguistics",
    url = "https://aclanthology.org/2020.emnlp-main.613",
    doi = "10.18653/v1/2020.emnlp-main.613",
    pages = "7597--7610",
    abstract = "NLU models often exploit biases to achieve high dataset-specific performance without properly learning the intended task. Recently proposed debiasing methods are shown to be effective in mitigating this tendency. However, these methods rely on a major assumption that the types of bias should be known a-priori, which limits their application to many NLU tasks and datasets. In this work, we present the first step to bridge this gap by introducing a self-debiasing framework that prevents models from mainly utilizing biases without knowing them in advance. The proposed framework is general and complementary to the existing debiasing methods. We show that it allows these existing methods to retain the improvement on the challenge datasets (i.e., sets of examples designed to expose models{'} reliance on biases) without specifically targeting certain biases. Furthermore, the evaluation suggests that applying the framework results in improved overall robustness.",
}

@misc{lyu2023featureleveldebiasednaturallanguage,
      title={Feature-Level Debiased Natural Language Understanding}, 
      author={Yougang Lyu and Piji Li and Yechang Yang and Maarten de Rijke and Pengjie Ren and Yukun Zhao and Dawei Yin and Zhaochun Ren},
      year={2023},
      eprint={2212.05421},
      archivePrefix={arXiv},
      primaryClass={cs.CL},
      url={https://arxiv.org/abs/2212.05421}, 
}
@misc{codaforno2024cogbenchlargelanguagemodel,
      title={CogBench: a large language model walks into a psychology lab}, 
      author={Julian Coda-Forno and Marcel Binz and Jane X. Wang and Eric Schulz},
      year={2024},
      eprint={2402.18225},
      archivePrefix={arXiv},
      primaryClass={cs.CL},
      url={https://arxiv.org/abs/2402.18225}, 
}
@misc{oren2023provingtestsetcontamination,
      title={Proving Test Set Contamination in Black Box Language Models}, 
      author={Yonatan Oren and Nicole Meister and Niladri Chatterji and Faisal Ladhak and Tatsunori B. Hashimoto},
      year={2023},
      eprint={2310.17623},
      archivePrefix={arXiv},
      primaryClass={cs.CL},
      url={https://arxiv.org/abs/2310.17623}, 
}
@misc{shi2024detectingpretrainingdatalarge,
      title={Detecting Pretraining Data from Large Language Models}, 
      author={Weijia Shi and Anirudh Ajith and Mengzhou Xia and Yangsibo Huang and Daogao Liu and Terra Blevins and Danqi Chen and Luke Zettlemoyer},
      year={2024},
      eprint={2310.16789},
      archivePrefix={arXiv},
      primaryClass={cs.CL},
      url={https://arxiv.org/abs/2310.16789}, 
}
@misc{marone2023dataportraitsrecordingfoundation,
      title={Data Portraits: Recording Foundation Model Training Data}, 
      author={Marc Marone and Benjamin Van Durme},
      year={2023},
      eprint={2303.03919},
      archivePrefix={arXiv},
      primaryClass={cs.LG},
      url={https://arxiv.org/abs/2303.03919}, 
}
@misc{klie2022annotationerrordetectionanalyzing,
      title={Annotation Error Detection: Analyzing the Past and Present for a More Coherent Future}, 
      author={Jan-Christoph Klie and Bonnie Webber and Iryna Gurevych},
      year={2022},
      eprint={2206.02280},
      archivePrefix={arXiv},
      primaryClass={cs.CL},
      url={https://arxiv.org/abs/2206.02280}, 
}
@misc{ma2023tomchallengesprincipleguideddatasetdiverse,
      title={ToMChallenges: A Principle-Guided Dataset and Diverse Evaluation Tasks for Exploring Theory of Mind}, 
      author={Xiaomeng Ma and Lingyu Gao and Qihui Xu},
      year={2023},
      eprint={2305.15068},
      archivePrefix={arXiv},
      primaryClass={cs.CL},
      url={https://arxiv.org/abs/2305.15068}, 
}
@article{BARONCOHEN198537,
title = {Does the autistic child have a “theory of mind” ?},
journal = {Cognition},
volume = {21},
number = {1},
pages = {37-46},
year = {1985},
issn = {0010-0277},
doi = {https://doi.org/10.1016/0010-0277(85)90022-8},
url = {https://www.sciencedirect.com/science/article/pii/0010027785900228},
author = {Simon Baron-Cohen and Alan M. Leslie and Uta Frith},
abstract = {We use a new model of metarepresentational development to predict a cognitive deficit which could explain a crucial component of the social impairment in childhood autism. One of the manifestations of a basic metarepresentational capacity is a ‘theory of mind’. We have reason to believe that autistic children lack such a ‘theory’. If this were so, then they would be unable to impute beliefs to others and to predict their behaviour. This hypothesis was tested using Wimmer and Perner's puppet play paradigm. Normal children and those with Down's syndrome were used as controls for a group of autistic children. Even though the mental age of the autistic children was higher than that of the controls, they alone failed to impute beliefs to others. Thus the dysfunction we have postulated and demonstrated is independent of mental retardation and specific to autism.
Résumé
Les auteurs présentent un nouveau mod`éle de développement méta-cognitif pour prédire le déficit cognitif qui rendrait compte d'un composant essentiel du handicap social de l'enfant autiste. Une des manifestations d'une capacité de base méta-cognitive est une ‘theorie de l'esprit'. Nous avons des raisons de croire que cette théorie fait defaut chez l'enfant autiste. Celui-ci serait done incapable d'attribuer des croyances aux autres ou de prédire leur comportement. Cette hypothèse a été testée avec le paradigme de jeu des marionettes utilisé par Wimmer et Perner. Des enfants normaux et des enfants avec trisomie 21 ont servi de groupe contrôle. Bien que Page mental des enfants autistes ait été plus élevé que deux du groupe contrôle, seuls les enfants autistes Wont pu attribuer aux autres des croyances. Ainsi le dysfonctionnement prévu a pu être démontre, il s'avère indépendant du retard mental et spécifique a l'autiste.}
}

@article{gopnik1988childrens,
  title={Children's understanding of representational change and its relation to the understanding of false belief and the appearance-reality distinction},
  author={Gopnik A. and Astington J. W.},
  journal={Child Development},
  volume={59},
  number={1},
  pages={26--37},
  year={1988},
  publisher={Wiley},
  doi={10.1111/j.1467-8624.1988.tb03192.x},
  url={https://doi.org/10.1111/j.1467-8624.1988.tb03192.x}
}
@article{Aru_2023,
   title={Mind the gap: challenges of deep learning approaches to Theory of Mind},
   volume={56},
   ISSN={1573-7462},
   url={http://dx.doi.org/10.1007/s10462-023-10401-x},
   DOI={10.1007/s10462-023-10401-x},
   number={9},
   journal={Artificial Intelligence Review},
   publisher={Springer Science and Business Media LLC},
   author={Aru, Jaan and Labash, Aqeel and Corcoll, Oriol and Vicente, Raul},
   year={2023},
   month=jan, pages={9141–9156} }

@article{Geirhos_2020,
   title={Shortcut learning in deep neural networks},
   volume={2},
   ISSN={2522-5839},
   url={http://dx.doi.org/10.1038/s42256-020-00257-z},
   DOI={10.1038/s42256-020-00257-z},
   number={11},
   journal={Nature Machine Intelligence},
   publisher={Springer Science and Business Media LLC},
   author={Geirhos, Robert and Jacobsen, Jörn-Henrik and Michaelis, Claudio and Zemel, Richard and Brendel, Wieland and Bethge, Matthias and Wichmann, Felix A.},
   year={2020},
   month=nov, pages={665–673} }
@misc{dziri2023faithfatelimitstransformers,
      title={Faith and Fate: Limits of Transformers on Compositionality}, 
      author={Nouha Dziri and Ximing Lu and Melanie Sclar and Xiang Lorraine Li and Liwei Jiang and Bill Yuchen Lin and Peter West and Chandra Bhagavatula and Ronan Le Bras and Jena D. Hwang and Soumya Sanyal and Sean Welleck and Xiang Ren and Allyson Ettinger and Zaid Harchaoui and Yejin Choi},
      year={2023},
      eprint={2305.18654},
      archivePrefix={arXiv},
      primaryClass={cs.CL},
      url={https://arxiv.org/abs/2305.18654}, 
}
@article{kinderman1998theory,
  title={Theory-of-mind deficits and causal attributions},
  author={Kinderman, Peter and Dunbar, Robin and Bentall, Richard P.},
  journal={British Journal of Psychology},
  volume={89},
  number={2},
  pages={191--204},
  year={1998},
  publisher={Wiley},
}



@InProceedings{pmlr-v162-sclar22a,
  title = 	 {Symmetric Machine Theory of Mind},
  author =       {Sclar, Melanie and Neubig, Graham and Bisk, Yonatan},
  booktitle = 	 {Proceedings of the 39th International Conference on Machine Learning},
  pages = 	 {19450--19466},
  year = 	 {2022},
  editor = 	 {Chaudhuri, Kamalika and Jegelka, Stefanie and Song, Le and Szepesvari, Csaba and Niu, Gang and Sabato, Sivan},
  volume = 	 {162},
  series = 	 {Proceedings of Machine Learning Research},
  month = 	 {17--23 Jul},
  publisher =    {PMLR},
  pdf = 	 {https://proceedings.mlr.press/v162/sclar22a/sclar22a.pdf},
  url = 	 {https://proceedings.mlr.press/v162/sclar22a.html},
  abstract = 	 {Theory of mind, the ability to model others’ thoughts and desires, is a cornerstone of human social intelligence. This makes it an important challenge for the machine learning community, but previous works mainly attempt to design agents that model the "mental state" of others as passive observers or in specific predefined roles, such as in speaker-listener scenarios. In contrast, we propose to model machine theory of mind in a more general symmetric scenario. We introduce a multi-agent environment SymmToM where, like in real life, all agents can speak, listen, see other agents, and move freely through the world. Effective strategies to maximize an agent’s reward require it to develop a theory of mind. We show that reinforcement learning agents that model the mental states of others achieve significant performance improvements over agents with no such theory of mind model. Importantly, our best agents still fail to achieve performance comparable to agents with access to the gold-standard mental state of other agents, demonstrating that the modeling of theory of mind in multi-agent scenarios is very much an open challenge.}
}
@book{pfungst1911clever,
  title={Clever Hans: (the horse of Mr. Von Osten.) A contribution to experimental animal and human psychology},
  author={Pfungst, Oskar},
  year={1911},
  publisher={Holt, Rinehart and Winston}
}
@inproceedings{bender2021dangers,
  title={On the dangers of stochastic parrots: Can language models be too big?},
  author={Bender, Emily M. and Gebru, Timnit and McMillan-Major, Angelina and Shmitchell, Shmargaret},
  booktitle={Proceedings of the 2021 ACM Conference on Fairness, Accountability, and Transparency},
  pages={610--623},
  year={2021},
  organization={ACM}
}
@misc{liu2024interintentinvestigatingsocialintelligence,
      title={InterIntent: Investigating Social Intelligence of LLMs via Intention Understanding in an Interactive Game Context}, 
      author={Ziyi Liu and Abhishek Anand and Pei Zhou and Jen-tse Huang and Jieyu Zhao},
      year={2024},
      eprint={2406.12203},
      archivePrefix={arXiv},
      primaryClass={cs.AI},
      url={https://arxiv.org/abs/2406.12203}, 
}
@inproceedings{Li_2023,
   title={Theory of Mind for Multi-Agent Collaboration via Large Language Models},
   url={http://dx.doi.org/10.18653/v1/2023.emnlp-main.13},
   DOI={10.18653/v1/2023.emnlp-main.13},
   booktitle={Proceedings of the 2023 Conference on Empirical Methods in Natural Language Processing},
   publisher={Association for Computational Linguistics},
   author={Li, Huao and Chong, Yu and Stepputtis, Simon and Campbell, Joseph and Hughes, Dana and Lewis, Charles and Sycara, Katia},
   year={2023} }


@misc{xu2024faithfullogicalreasoningsymbolic,
      title={Faithful Logical Reasoning via Symbolic Chain-of-Thought}, 
      author={Jundong Xu and Hao Fei and Liangming Pan and Qian Liu and Mong-Li Lee and Wynne Hsu},
      year={2024},
      eprint={2405.18357},
      archivePrefix={arXiv},
      primaryClass={cs.CL},
      url={https://arxiv.org/abs/2405.18357}, 
}

@misc{wei2023chainofthoughtpromptingelicitsreasoning,
      title={Chain-of-Thought Prompting Elicits Reasoning in Large Language Models}, 
      author={Jason Wei and Xuezhi Wang and Dale Schuurmans and Maarten Bosma and Brian Ichter and Fei Xia and Ed Chi and Quoc Le and Denny Zhou},
      year={2023},
      eprint={2201.11903},
      archivePrefix={arXiv},
      primaryClass={cs.CL},
      url={https://arxiv.org/abs/2201.11903}, 
}
@misc{zhou2023farlargelanguagemodels,
      title={How FaR Are Large Language Models From Agents with Theory-of-Mind?}, 
      author={Pei Zhou and Aman Madaan and Srividya Pranavi Potharaju and Aditya Gupta and Kevin R. McKee and Ari Holtzman and Jay Pujara and Xiang Ren and Swaroop Mishra and Aida Nematzadeh and Shyam Upadhyay and Manaal Faruqui},
      year={2023},
      eprint={2310.03051},
      archivePrefix={arXiv},
      primaryClass={cs.CL},
      url={https://arxiv.org/abs/2310.03051}, 
}
@inproceedings{hou-etal-2024-timetom,
    title = "{T}ime{T}o{M}: Temporal Space is the Key to Unlocking the Door of Large Language Models{'} Theory-of-Mind",
    author = "Hou, Guiyang  and
      Zhang, Wenqi  and
      Shen, Yongliang  and
      Wu, Linjuan  and
      Lu, Weiming",
    editor = "Ku, Lun-Wei  and
      Martins, Andre  and
      Srikumar, Vivek",
    booktitle = "Findings of the Association for Computational Linguistics ACL 2024",
    month = aug,
    year = "2024",
    address = "Bangkok, Thailand and virtual meeting",
    publisher = "Association for Computational Linguistics",
    url = "https://aclanthology.org/2024.findings-acl.685",
    pages = "11532--11547",
    abstract = "Theory of Mind (ToM){---}the cognitive ability to reason about mental states of ourselves and others, is the foundation of social interaction. Although ToM comes naturally to humans, it poses a significant challenge to even the most advanced Large Language Models (LLMs). Due to the complex logical chains in ToM reasoning, especially in higher-order ToM questions, simply utilizing reasoning methods like Chain of Thought (CoT) will not improve the ToM capabilities of LLMs. We present TimeToM, which constructs a temporal space and uses it as the foundation to improve the ToM capabilities of LLMs in multiple scenarios. Specifically, within the temporal space, we construct Temporal Belief State Chain (TBSC) for each character and inspired by the cognition perspective of the social world model, we divide TBSC into self-world beliefs and social world beliefs, aligning with first-order ToM (first-order beliefs) and higher-order ToM (higher-order beliefs) questions, respectively. Moreover, we design a novel tool-belief solver that, by considering belief communication between characters in temporal space, can transform a character{'}s higher-order beliefs into another character{'}s first-order beliefs under belief communication period.",
}

@inproceedings{papineni2002bleu,
  title={BLEU: a method for automatic evaluation of machine translation},
  author={Papineni, Kishore and Roukos, Salim and Ward, Todd and Zhu, Wei-Jing},
  booktitle={Proceedings of the 40th annual meeting of the Association for Computational Linguistics},
  pages={311--318},
  year={2002}
}

@inproceedings{lin2004rouge,
  title={ROUGE: A package for automatic evaluation of summaries},
  author={Lin, Chin-Yew},
  booktitle={Text summarization branches out: Proceedings of the ACL-04 workshop},
  pages={74--81},
  year={2004}
}


@inproceedings{vedantam2015cider,
  title={CIDEr: Consensus-based image description evaluation},
  author={Vedantam, Ramakrishna and Lawrence Zitnick, C and Parikh, Devi},
  booktitle={Proceedings of the IEEE conference on computer vision and pattern recognition},
  pages={4566--4575},
  year={2015}
}


@inproceedings{zhang2020bertscore,
  title={BERTScore: Evaluating Text Generation with BERT},
  author={Zhang, Tianyi and Kishore, Varsha and Wu, Felix and Weinberger, Kilian Q and Artzi, Yoav},
  booktitle={8th International Conference on Learning Representations, {ICLR} 2020},
  year={2020},
  url={https://openreview.net/forum?id=SkeHuCVFDr}
}


@inproceedings{banerjee2005meteor,
  title={METEOR: An automatic metric for MT evaluation with improved correlation with human judgments},
  author={Banerjee, Satanjeev and Lavie, Alon},
  booktitle={Proceedings of the ACL workshop on intrinsic and extrinsic evaluation measures for machine translation and/or summarization},
  pages={65--72},
  year={2005}
}

@inproceedings{devlin2019bert,
  title={BERT: Pre-training of Deep Bidirectional Transformers for Language Understanding},
  author={Devlin, Jacob and Chang, Ming-Wei and Lee, Kenton and Toutanova, Kristina},
  booktitle={Proceedings of the 2019 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies, Volume 1 (Long and Short Papers)},
  pages={4171--4186},
  year={2019}
}
@misc{yu2024fewshotcharacterunderstandingmovies,
      title={Few-Shot Character Understanding in Movies as an Assessment to Meta-Learning of Theory-of-Mind}, 
      author={Mo Yu and Qiujing Wang and Shunchi Zhang and Yisi Sang and Kangsheng Pu and Zekai Wei and Han Wang and Liyan Xu and Jing Li and Yue Yu and Jie Zhou},
      year={2024},
      eprint={2211.04684},
      archivePrefix={arXiv},
      primaryClass={cs.CL},
      url={https://arxiv.org/abs/2211.04684}, 
}
@misc{sap2023neuraltheoryofmindlimitssocial,
      title={Neural Theory-of-Mind? On the Limits of Social Intelligence in Large LMs}, 
      author={Maarten Sap and Ronan LeBras and Daniel Fried and Yejin Choi},
      year={2023},
      eprint={2210.13312},
      archivePrefix={arXiv},
      primaryClass={cs.CL},
}
@misc{gandhi2023understandingsocialreasoninglanguage,
      title={Understanding Social Reasoning in Language Models with Language Models}, 
      author={Kanishk Gandhi and Jan-Philipp Fränken and Tobias Gerstenberg and Noah D. Goodman},
      year={2023},
      eprint={2306.15448},
      archivePrefix={arXiv},
      primaryClass={cs.CL},
      url={https://arxiv.org/abs/2306.15448}, 
}
@misc{huang2024notioncomplexitytheorymind,
      title={A Notion of Complexity for Theory of Mind via Discrete World Models}, 
      author={X. Angelo Huang and Emanuele La Malfa and Samuele Marro and Andrea Asperti and Anthony Cohn and Michael Wooldridge},
      year={2024},
      eprint={2406.11911},
      archivePrefix={arXiv},
      primaryClass={cs.AI},
      url={https://arxiv.org/abs/2406.11911}, 
}
@misc{kwon2024llmseffectivenegotiatorssystematic,
      title={Are LLMs Effective Negotiators? Systematic Evaluation of the Multifaceted Capabilities of LLMs in Negotiation Dialogues}, 
      author={Deuksin Kwon and Emily Weiss and Tara Kulshrestha and Kushal Chawla and Gale M. Lucas and Jonathan Gratch},
      year={2024},
      eprint={2402.13550},
      archivePrefix={arXiv},
      primaryClass={cs.CL},
      url={https://arxiv.org/abs/2402.13550}, 
}
@misc{cross2024hypotheticalmindsscaffoldingtheory,
      title={Hypothetical Minds: Scaffolding Theory of Mind for Multi-Agent Tasks with Large Language Models}, 
      author={Logan Cross and Violet Xiang and Agam Bhatia and Daniel LK Yamins and Nick Haber},
      year={2024},
      eprint={2407.07086},
      archivePrefix={arXiv},
      primaryClass={cs.AI},
      url={https://arxiv.org/abs/2407.07086}, 
}

@misc{kim2023fantombenchmarkstresstestingmachine,
      title={FANToM: A Benchmark for Stress-testing Machine Theory of Mind in Interactions}, 
      author={Hyunwoo Kim and Melanie Sclar and Xuhui Zhou and Ronan Le Bras and Gunhee Kim and Yejin Choi and Maarten Sap},
      year={2023},
      eprint={2310.15421},
      archivePrefix={arXiv},
      primaryClass={cs.CL},
      url={https://arxiv.org/abs/2310.15421}, 
}
@misc{chen2024tombenchbenchmarkingtheorymind,
      title={ToMBench: Benchmarking Theory of Mind in Large Language Models}, 
      author={Zhuang Chen and Jincenzi Wu and Jinfeng Zhou and Bosi Wen and Guanqun Bi and Gongyao Jiang and Yaru Cao and Mengting Hu and Yunghwei Lai and Zexuan Xiong and Minlie Huang},
      year={2024},
      eprint={2402.15052},
      archivePrefix={arXiv},
      primaryClass={cs.CL},
      url={https://arxiv.org/abs/2402.15052}, 
}
@misc{chan2024negotiationtombenchmarkstresstestingmachine,
      title={NegotiationToM: A Benchmark for Stress-testing Machine Theory of Mind on Negotiation Surrounding}, 
      author={Chunkit Chan and Cheng Jiayang and Yauwai Yim and Zheye Deng and Wei Fan and Haoran Li and Xin Liu and Hongming Zhang and Weiqi Wang and Yangqiu Song},
      year={2024},
      eprint={2404.13627},
      archivePrefix={arXiv},
      primaryClass={cs.CL},
      url={https://arxiv.org/abs/2404.13627}, 
}
@misc{yao2023treethoughtsdeliberateproblem,
      title={Tree of Thoughts: Deliberate Problem Solving with Large Language Models}, 
      author={Shunyu Yao and Dian Yu and Jeffrey Zhao and Izhak Shafran and Thomas L. Griffiths and Yuan Cao and Karthik Narasimhan},
      year={2023},
      eprint={2305.10601},
      archivePrefix={arXiv},
      primaryClass={cs.CL},
      url={https://arxiv.org/abs/2305.10601}, 
}
@inproceedings{cao-2021-holistic,
    title = "Holistic interpretation in locative alternation {--} Evidence from self-paced reading",
    author = "Cao, Rui",
    editor = "Hu, Kaibao  and
      Kim, Jong-Bok  and
      Zong, Chengqing  and
      Chersoni, Emmanuele",
    booktitle = "Proceedings of the 35th Pacific Asia Conference on Language, Information and Computation",
    month = "11",
    year = "2021",
    address = "Shanghai, China",
    publisher = "Association for Computational Lingustics",
    url = "https://aclanthology.org/2021.paclic-1.57/",
    pages = "543--550"
}
@misc{press2023measuringnarrowingcompositionalitygap,
      title={Measuring and Narrowing the Compositionality Gap in Language Models}, 
      author={Ofir Press and Muru Zhang and Sewon Min and Ludwig Schmidt and Noah A. Smith and Mike Lewis},
      year={2023},
      eprint={2210.03350},
      archivePrefix={arXiv},
      primaryClass={cs.CL},
      url={https://arxiv.org/abs/2210.03350}, 
}
@misc{wilf2023thinktwiceperspectivetakingimproves,
      title={Think Twice: Perspective-Taking Improves Large Language Models' Theory-of-Mind Capabilities}, 
      author={Alex Wilf and Sihyun Shawn Lee and Paul Pu Liang and Louis-Philippe Morency},
      year={2023},
      eprint={2311.10227},
      archivePrefix={arXiv},
      primaryClass={cs.AI},
      url={https://arxiv.org/abs/2311.10227}, 
}
@misc{hou2024timetomtemporalspacekey,
      title={TimeToM: Temporal Space is the Key to Unlocking the Door of Large Language Models' Theory-of-Mind}, 
      author={Guiyang Hou and Wenqi Zhang and Yongliang Shen and Linjuan Wu and Weiming Lu},
      year={2024},
      eprint={2407.01455},
      archivePrefix={arXiv},
      primaryClass={cs.CL},
      url={https://arxiv.org/abs/2407.01455}, 
}
@misc{jung2024perceptionsbeliefsexploringprecursory,
      title={Perceptions to Beliefs: Exploring Precursory Inferences for Theory of Mind in Large Language Models}, 
      author={Chani Jung and Dongkwan Kim and Jiho Jin and Jiseon Kim and Yeon Seonwoo and Yejin Choi and Alice Oh and Hyunwoo Kim},
      year={2024},
      eprint={2407.06004},
      archivePrefix={arXiv},
      primaryClass={cs.CL},
      url={https://arxiv.org/abs/2407.06004}, 
}
@misc{wang2024metacognitivepromptingimprovesunderstanding,
      title={Metacognitive Prompting Improves Understanding in Large Language Models}, 
      author={Yuqing Wang and Yun Zhao},
      year={2024},
      eprint={2308.05342},
      archivePrefix={arXiv},
      primaryClass={cs.CL},
      url={https://arxiv.org/abs/2308.05342}, 
}

@misc{guo2023suspicionagentplayingimperfectinformation,
      title={Suspicion-Agent: Playing Imperfect Information Games with Theory of Mind Aware GPT-4}, 
      author={Jiaxian Guo and Bo Yang and Paul Yoo and Bill Yuchen Lin and Yusuke Iwasawa and Yutaka Matsuo},
      year={2023},
      eprint={2309.17277},
      archivePrefix={arXiv},
      primaryClass={cs.AI},
      url={https://arxiv.org/abs/2309.17277}, 
}
@misc{wang2024symbolicworkingmemoryenhances,
      title={Symbolic Working Memory Enhances Language Models for Complex Rule Application}, 
      author={Siyuan Wang and Zhongyu Wei and Yejin Choi and Xiang Ren},
      year={2024},
      eprint={2408.13654},
      archivePrefix={arXiv},
      primaryClass={cs.CL},
      url={https://arxiv.org/abs/2408.13654}, 
}
@misc{leer2023violationexpectationmetacognitiveprompting,
      title={Violation of Expectation via Metacognitive Prompting Reduces Theory of Mind Prediction Error in Large Language Models}, 
      author={Courtland Leer and Vincent Trost and Vineeth Voruganti},
      year={2023},
      eprint={2310.06983},
      archivePrefix={arXiv},
      primaryClass={cs.CL},
      url={https://arxiv.org/abs/2310.06983}, 
}
@article{Ohtani2024DoesMP,
  title={Does Metacognitive Prompting Improve Causal Inference in Large Language Models?},
  author={Ryusei Ohtani and Yuko Sakurai and Satoshi Oyama},
  journal={2024 IEEE Conference on Artificial Intelligence (CAI)},
  year={2024},
  pages={458-459},
  url={https://api.semanticscholar.org/CorpusID:271044366}
}
@inproceedings{wu-etal-2024-coke,
    title = "{COKE}: A Cognitive Knowledge Graph for Machine Theory of Mind",
    author = "Wu, Jincenzi  and
      Chen, Zhuang  and
      Deng, Jiawen  and
      Sabour, Sahand  and
      Meng, Helen  and
      Huang, Minlie",
    editor = "Ku, Lun-Wei  and
      Martins, Andre  and
      Srikumar, Vivek",
    booktitle = "Proceedings of the 62nd Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers)",
    month = aug,
    year = "2024",
    address = "Bangkok, Thailand",
    publisher = "Association for Computational Linguistics",
    url = "https://aclanthology.org/2024.acl-long.848",
    pages = "15984--16007",
    abstract = "Theory of mind (ToM) refers to humans{'} ability to understand and infer the desires, beliefs, and intentions of others. The acquisition of ToM plays a key role in humans{'} social cognition and interpersonal relations. Though indispensable for social intelligence, ToM is still lacking for modern AI and NLP systems since they cannot access the human mental state and cognitive process beneath the training corpus. To empower AI systems with the ToM ability and narrow the gap between them and humans, in this paper, we propose COKE: the first cognitive knowledge graph for machine theory of mind. Specifically, COKE formalizes ToM as a collection of 45k+ manually verified cognitive chains that characterize human mental activities and subsequent behavioral/affective responses when facing specific social circumstances. In addition, we further generalize COKE using LLMs and build a powerful generation model COLM tailored for cognitive reasoning. Experimental results in both automatic and human evaluation demonstrate the high quality of COKE, the superior ToM ability of COLM, and its potential to significantly enhance social applications.",
}

@misc{bianchi2024llmsnegotiatenegotiationarenaplatform,
      title={How Well Can LLMs Negotiate? NegotiationArena Platform and Analysis}, 
      author={Federico Bianchi and Patrick John Chia and Mert Yuksekgonul and Jacopo Tagliabue and Dan Jurafsky and James Zou},
      year={2024},
      eprint={2402.05863},
      archivePrefix={arXiv},
      primaryClass={cs.AI},
      url={https://arxiv.org/abs/2402.05863}, 
}

@misc{amirizaniani2024llmsexhibithumanlikereasoning,
      title={Do LLMs Exhibit Human-Like Reasoning? Evaluating Theory of Mind in LLMs for Open-Ended Responses}, 
      author={Maryam Amirizaniani and Elias Martin and Maryna Sivachenko and Afra Mashhadi and Chirag Shah},
      year={2024},
      eprint={2406.05659},
      archivePrefix={arXiv},
      primaryClass={cs.CL},
      url={https://arxiv.org/abs/2406.05659}, 
}

@misc{etesam2024contextualemotionrecognitionusing,
      title={Contextual Emotion Recognition using Large Vision Language Models}, 
      author={Yasaman Etesam and Özge Nilay Yalçın and Chuxuan Zhang and Angelica Lim},
      year={2024},
      eprint={2405.08992},
      archivePrefix={arXiv},
      primaryClass={cs.CV},
      url={https://arxiv.org/abs/2405.08992}, 
}

@misc{li2024quantifyingaipsychologypsychometrics,
      title={Quantifying AI Psychology: A Psychometrics Benchmark for Large Language Models}, 
      author={Yuan Li and Yue Huang and Hongyi Wang and Xiangliang Zhang and James Zou and Lichao Sun},
      year={2024},
      eprint={2406.17675},
      archivePrefix={arXiv},
      primaryClass={cs.CL},
      url={https://arxiv.org/abs/2406.17675}, 
}

@inproceedings{Verma_2024, series={HRI ’24},
   title={Theory of Mind Abilities of Large Language Models in Human-Robot Interaction: An Illusion?},
   url={http://dx.doi.org/10.1145/3610978.3640767},
   DOI={10.1145/3610978.3640767},
   booktitle={Companion of the 2024 ACM/IEEE International Conference on Human-Robot Interaction},
   publisher={ACM},
   author={Verma, Mudit and Bhambri, Siddhant and Kambhampati, Subbarao},
   year={2024},
   month=mar, collection={HRI ’24} }

@misc{mireshghallah2024llmssecrettestingprivacy,
      title={Can LLMs Keep a Secret? Testing Privacy Implications of Language Models via Contextual Integrity Theory}, 
      author={Niloofar Mireshghallah and Hyunwoo Kim and Xuhui Zhou and Yulia Tsvetkov and Maarten Sap and Reza Shokri and Yejin Choi},
      year={2024},
      eprint={2310.17884},
      archivePrefix={arXiv},
      primaryClass={cs.AI},
      url={https://arxiv.org/abs/2310.17884}, 
}

@inproceedings{le-etal-2019-revisiting,
    title = "Revisiting the Evaluation of Theory of Mind through Question Answering",
    author = "Le, Matthew  and
      Boureau, Y-Lan  and
      Nickel, Maximilian",
    editor = "Inui, Kentaro  and
      Jiang, Jing  and
      Ng, Vincent  and
      Wan, Xiaojun",
    booktitle = "Proceedings of the 2019 Conference on Empirical Methods in Natural Language Processing and the 9th International Joint Conference on Natural Language Processing (EMNLP-IJCNLP)",
    month = nov,
    year = "2019",
    address = "Hong Kong, China",
    publisher = "Association for Computational Linguistics",
    url = "https://aclanthology.org/D19-1598",
    doi = "10.18653/v1/D19-1598",
    pages = "5872--5877",
    abstract = "Theory of mind, i.e., the ability to reason about intents and beliefs of agents is an important task in artificial intelligence and central to resolving ambiguous references in natural language dialogue. In this work, we revisit the evaluation of theory of mind through question answering. We show that current evaluation methods are flawed and that existing benchmark tasks can be solved without theory of mind due to dataset biases. Based on prior work, we propose an improved evaluation protocol and dataset in which we explicitly control for data regularities via a careful examination of the answer space. We show that state-of-the-art methods which are successful on existing benchmarks fail to solve theory-of-mind tasks in our proposed approach.",
}
@inproceedings{sileo-lernould-2023-mindgames,
    title = "{M}ind{G}ames: Targeting Theory of Mind in Large Language Models with Dynamic Epistemic Modal Logic",
    author = "Sileo, Damien  and
      Lernould, Antoine",
    editor = "Bouamor, Houda  and
      Pino, Juan  and
      Bali, Kalika",
    booktitle = "Findings of the Association for Computational Linguistics: EMNLP 2023",
    month = dec,
    year = "2023",
    address = "Singapore",
    publisher = "Association for Computational Linguistics",
    url = "https://aclanthology.org/2023.findings-emnlp.303",
    doi = "10.18653/v1/2023.findings-emnlp.303",
    pages = "4570--4577",
    abstract = "Theory of Mind (ToM) is a critical component of intelligence but its assessment remains the subject of heated debates. Prior research applied human ToM assessments to natural language processing models using either human-created standardized tests or rule-based templates. However, these methods primarily focus on simplistic reasoning and require further validation. Here, we leverage dynamic epistemic logic to isolate a particular component of ToM and to generate controlled problems. We also introduce new verbalization techniques to express these problems in English natural language. Our findings indicate that some language model scaling (from 70M to 6B and 350M to 174B) does not consistently yield results better than random chance. While GPT-4 demonstrates superior epistemic reasoning capabilities, there is still room for improvement. Our code and datasets are publicly available.",
}
@misc{xu2024hallucinationinevitableinnatelimitation,
      title={Hallucination is Inevitable: An Innate Limitation of Large Language Models}, 
      author={Ziwei Xu and Sanjay Jain and Mohan Kankanhalli},
      year={2024},
      eprint={2401.11817},
      archivePrefix={arXiv},
      primaryClass={cs.CL},
      url={https://arxiv.org/abs/2401.11817}, 
}
@misc{lee2023factualityenhancedlanguagemodels,
      title={Factuality Enhanced Language Models for Open-Ended Text Generation}, 
      author={Nayeon Lee and Wei Ping and Peng Xu and Mostofa Patwary and Pascale Fung and Mohammad Shoeybi and Bryan Catanzaro},
      year={2023},
      eprint={2206.04624},
      archivePrefix={arXiv},
      primaryClass={cs.CL},
      url={https://arxiv.org/abs/2206.04624}, 
}
@misc{dhuliawala2023chainofverificationreduceshallucinationlarge,
      title={Chain-of-Verification Reduces Hallucination in Large Language Models}, 
      author={Shehzaad Dhuliawala and Mojtaba Komeili and Jing Xu and Roberta Raileanu and Xian Li and Asli Celikyilmaz and Jason Weston},
      year={2023},
      eprint={2309.11495},
      archivePrefix={arXiv},
      primaryClass={cs.CL},
      url={https://arxiv.org/abs/2309.11495}, 
}

@misc{huang2023surveyhallucinationlargelanguage,
      title={A Survey on Hallucination in Large Language Models: Principles, Taxonomy, Challenges, and Open Questions}, 
      author={Lei Huang and Weijiang Yu and Weitao Ma and Weihong Zhong and Zhangyin Feng and Haotian Wang and Qianglong Chen and Weihua Peng and Xiaocheng Feng and Bing Qin and Ting Liu},
      year={2023},
      eprint={2311.05232},
      archivePrefix={arXiv},
      primaryClass={cs.CL},
      url={https://arxiv.org/abs/2311.05232}, 
}
@inproceedings{wu-etal-2023-hi,
    title = "Hi-{T}o{M}: A Benchmark for Evaluating Higher-Order Theory of Mind Reasoning in Large Language Models",
    author = "Wu, Yufan  and
      He, Yinghui  and
      Jia, Yilin  and
      Mihalcea, Rada  and
      Chen, Yulong  and
      Deng, Naihao",
    editor = "Bouamor, Houda  and
      Pino, Juan  and
      Bali, Kalika",
    booktitle = "Findings of the Association for Computational Linguistics: EMNLP 2023",
    month = dec,
    year = "2023",
    address = "Singapore",
    publisher = "Association for Computational Linguistics",
    url = "https://aclanthology.org/2023.findings-emnlp.717",
    doi = "10.18653/v1/2023.findings-emnlp.717",
    pages = "10691--10706",
    abstract = "Theory of Mind (ToM) is the ability to reason about one{'}s own and others{'} mental states. ToM plays a critical role in the development of intelligence, language understanding, and cognitive processes. While previous work has primarily focused on first and second-order ToM, we explore higher-order ToM, which involves recursive reasoning on others{'} beliefs. {\%}We also incorporate a new deception mechanism in ToM reasoning. We introduce Hi-ToM, a Higher Order Theory of Mind benchmark. Our experimental evaluation using various Large Language Models (LLMs) indicates a decline in performance on higher-order ToM tasks, demonstrating the limitations of current LLMs. We conduct a thorough analysis of different failure cases of LLMs, and share our thoughts on the implications of our findings on the future of NLP.",
}
%article{cohen1990intention,
%  title={Intention is choice with commitment},
%  author={Cohen, Philip R and Levesque, Hector J},
%  journal={Artificial intelligence},
%  volume={42},
%  number={2-3},
%  pages={213--261},
%  year={1990},
%  publisher={Elsevier}
%}
@misc{cohen2021exploring,
    title={Exploring roberta’s theory of mind through textual entailment},
    author={Michael Cohen},
    year={2021}
}

@inproceedings{nematzadeh2018evaluating,
    title = "Evaluating Theory of Mind in Question Answering",
    author = "Nematzadeh, Aida  and
      Burns, Kaylee  and
      Grant, Erin  and
      Gopnik, Alison  and
      Griffiths, Tom",
    booktitle = "Proceedings of the 2018 Conference on Empirical Methods in Natural Language Processing",
    month = oct # "-" # nov,
    year = "2018",
    address = "Brussels, Belgium",
    publisher = "Association for Computational Linguistics",
    pages = "2392--2400",
}

@inproceedings{zhang2010towards,
  title={Towards conversation entailment: An empirical investigation},
  author={Zhang, Chen and Chai, Joyce Y},
  booktitle={Proceedings of the 2010 Conference on Empirical Methods in Natural Language Processing},
  pages={756--766},
  year={2010}
}

@inproceedings{tracey2022best,
  title={BeSt: The Belief and Sentiment Corpus},
  author={Tracey, Jennifer and Rambow, Owen and Cardie, Claire and Dalton, Adam and Dang, Hoa Trang and Diab, Mona and Dorr, Bonnie and Guthrie, Louise and Markowska, Magdalena and Muresan, Smaranda and others},
  booktitle={Proceedings of the Thirteenth Language Resources and Evaluation Conference},
  pages={2460--2467},
  year={2022}
}

@inproceedings{shapira2023how,
  title={How well do large language models perform on faux pas tests},
  author={Shapira, Natalie and Zwirn, Guy and Goldberg, Yoav},
  booktitle={Findings of the Association for Computational Linguistics: ACL 2023},
  year={2023}
}

@inproceedings{zhou2023i,
    title={I Cast Detect Thoughts: Learning to Converse and Guide with Intents and Theory-of-Mind in Dungeons and Dragons}, 
    author={Pei Zhou and Andrew Zhu and Jennifer Hu and Jay Pujara and Xiang Ren and Chris Callison-Burch and Yejin Choi and Prithviraj Ammanabrolu},
    year={2023},
    booktitle={Proceedings of the 61th Annual Meeting of the Association for Computational Linguistics},
}

@article{eysenbach2016mistaken,
  title={Who is mistaken?},
  author={Eysenbach, Benjamin and Vondrick, Carl and Torralba, Antonio},
  journal={arXiv preprint arXiv:1612.01175},
  year={2016}
}

@inproceedings{gordon2016commonsense,
  title={Commonsense interpretation of triangle behavior},
  author={Gordon, Andrew},
  booktitle={Proceedings of the AAAI Conference on Artificial Intelligence},
  number={1},
  year={2016}
}

@inproceedings{jia2022beyond,
  title={Beyond Emotion: A Multi-Modal Dataset for Human Desire Understanding},
  author={Jia, Ao and He, Yu and Zhang, Yazhou and Uprety, Sagar and Song, Dawei and Lioma, Christina},
  booktitle={Proceedings of the 2022 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies},
  pages={1512--1522},
  year={2022}
}

@article{gandhi2021baby,
  title={Baby Intuitions Benchmark (BIB): Discerning the goals, preferences, and actions of others},
  author={Gandhi, Kanishk and Stojnic, Gala and Lake, Brenden M and Dillon, Moira R},
  journal={Advances in Neural Information Processing Systems},
  volume={34},
  pages={9963--9976},
  year={2021}
}

@inproceedings{shu2021agent,
  title={Agent: A benchmark for core psychological reasoning},
  author={Shu, Tianmin and Bhandwaldar, Abhishek and Gan, Chuang and Smith, Kevin and Liu, Shari and Gutfreund, Dan and Spelke, Elizabeth and Tenenbaum, Joshua and Ullman, Tomer},
  booktitle={International Conference on Machine Learning},
  pages={9614--9625},
  year={2021},
  organization={PMLR}
}

@inproceedings{bara2021mindcraft,
  title={MindCraft: Theory of Mind Modeling for Situated Dialogue in Collaborative Tasks},
  author={Bara, Cristian-Paul and Sky, CH-Wang and Chai, Joyce},
  booktitle={Proceedings of the 2021 Conference on Empirical Methods in Natural Language Processing},
  pages={1112--1125},
  year={2021}
}

@inproceedings{bara2023towards,
  title     = {Towards Collaborative Plan Acquisition through Theory of Mind Modeling in Situated Dialogue},
  author    = {Bara, Cristian-Paul and Ma, Ziqiao and Yu, Yingzhuo and Shah, Julie and Chai, Joyce},
  booktitle = {Proceedings of the Thirty-Second International Joint Conference on
               Artificial Intelligence, {IJCAI-23}},
  publisher = {International Joint Conferences on Artificial Intelligence Organization},
  editor    = {Edith Elkind},
  pages     = {2958--2966},
  year      = {2023},
  month     = {8},
  note      = {Main Track}
}
@misc{sagawa2020distributionallyrobustneuralnetworks,
      title={Distributionally Robust Neural Networks for Group Shifts: On the Importance of Regularization for Worst-Case Generalization}, 
      author={Shiori Sagawa and Pang Wei Koh and Tatsunori B. Hashimoto and Percy Liang},
      year={2020},
      eprint={1911.08731},
      archivePrefix={arXiv},
      primaryClass={cs.LG},
      url={https://arxiv.org/abs/1911.08731}, 
}
@misc{ganin2016domainadversarialtrainingneuralnetworks,
      title={Domain-Adversarial Training of Neural Networks}, 
      author={Yaroslav Ganin and Evgeniya Ustinova and Hana Ajakan and Pascal Germain and Hugo Larochelle and François Laviolette and Mario Marchand and Victor Lempitsky},
      year={2016},
      eprint={1505.07818},
      archivePrefix={arXiv},
      primaryClass={stat.ML},
      url={https://arxiv.org/abs/1505.07818}, 
}
@misc{nam2020learningfailuretrainingdebiased,
      title={Learning from Failure: Training Debiased Classifier from Biased Classifier}, 
      author={Junhyun Nam and Hyuntak Cha and Sungsoo Ahn and Jaeho Lee and Jinwoo Shin},
      year={2020},
      eprint={2007.02561},
      archivePrefix={arXiv},
      primaryClass={cs.LG},
      url={https://arxiv.org/abs/2007.02561}, 
}
@misc{bahng2020learningdebiasedrepresentationsbiased,
      title={Learning De-biased Representations with Biased Representations}, 
      author={Hyojin Bahng and Sanghyuk Chun and Sangdoo Yun and Jaegul Choo and Seong Joon Oh},
      year={2020},
      eprint={1910.02806},
      archivePrefix={arXiv},
      primaryClass={cs.CV},
      url={https://arxiv.org/abs/1910.02806}, 
}
@misc{fang2024inferactinferringsafeactions,
      title={InferAct: Inferring Safe Actions for LLM-Based Agents Through Preemptive Evaluation and Human Feedback}, 
      author={Haishuo Fang and Xiaodan Zhu and Iryna Gurevych},
      year={2024},
      eprint={2407.11843},
      archivePrefix={arXiv},
      primaryClass={cs.CL},
      url={https://arxiv.org/abs/2407.11843}, 
}
@misc{kosoy2023comparingmachineschildrenusing,
      title={Comparing Machines and Children: Using Developmental Psychology Experiments to Assess the Strengths and Weaknesses of LaMDA Responses}, 
      author={Eliza Kosoy and Emily Rose Reagan and Leslie Lai and Alison Gopnik and Danielle Krettek Cobb},
      year={2023},
      eprint={2305.11243},
      archivePrefix={arXiv},
      primaryClass={cs.CL},
      url={https://arxiv.org/abs/2305.11243}, 
}

@article{thorndike1920intelligence,
  author    = {Edward L. Thorndike},
  title     = {Intelligence and Its Uses},
  journal   = {Harper's Magazine},
  volume    = {140},
  pages     = {227--235},
  year      = {1920}
}

@misc{howard2018universallanguagemodelfinetuning,
      title={Universal Language Model Fine-tuning for Text Classification}, 
      author={Jeremy Howard and Sebastian Ruder},
      year={2018},
      eprint={1801.06146},
      archivePrefix={arXiv},
      primaryClass={cs.CL},
      url={https://arxiv.org/abs/1801.06146}, 
}

@misc{ouyang2022traininglanguagemodelsfollow,
      title={Training language models to follow instructions with human feedback}, 
      author={Long Ouyang and Jeff Wu and Xu Jiang and Diogo Almeida and Carroll L. Wainwright and Pamela Mishkin and Chong Zhang and Sandhini Agarwal and Katarina Slama and Alex Ray and John Schulman and Jacob Hilton and Fraser Kelton and Luke Miller and Maddie Simens and Amanda Askell and Peter Welinder and Paul Christiano and Jan Leike and Ryan Lowe},
      year={2022},
      eprint={2203.02155},
      archivePrefix={arXiv},
      primaryClass={cs.CL},
      url={https://arxiv.org/abs/2203.02155}, 
}

@misc{bai2022traininghelpfulharmlessassistant,
      title={Training a Helpful and Harmless Assistant with Reinforcement Learning from Human Feedback}, 
      author={Yuntao Bai and Andy Jones and Kamal Ndousse and Amanda Askell and Anna Chen and Nova DasSarma and Dawn Drain and Stanislav Fort and Deep Ganguli and Tom Henighan and Nicholas Joseph and Saurav Kadavath and Jackson Kernion and Tom Conerly and Sheer El-Showk and Nelson Elhage and Zac Hatfield-Dodds and Danny Hernandez and Tristan Hume and Scott Johnston and Shauna Kravec and Liane Lovitt and Neel Nanda and Catherine Olsson and Dario Amodei and Tom Brown and Jack Clark and Sam McCandlish and Chris Olah and Ben Mann and Jared Kaplan},
      year={2022},
      eprint={2204.05862},
      archivePrefix={arXiv},
      primaryClass={cs.CL},
      url={https://arxiv.org/abs/2204.05862}, 
}

@misc{tang2024tomlmdelegatingtheorymind,
      title={ToM-LM: Delegating Theory of Mind Reasoning to External Symbolic Executors in Large Language Models}, 
      author={Weizhi Tang and Vaishak Belle},
      year={2024},
      eprint={2404.15515},
      archivePrefix={arXiv},
      primaryClass={cs.CL},
      url={https://arxiv.org/abs/2404.15515}, 
}

@misc{chen2024theorymindseyereading,
      title={Through the Theory of Mind's Eye: Reading Minds with Multimodal Video Large Language Models}, 
      author={Zhawnen Chen and Tianchun Wang and Yizhou Wang and Michal Kosinski and Xiang Zhang and Yun Fu and Sheng Li},
      year={2024},
      eprint={2406.13763},
      archivePrefix={arXiv},
      primaryClass={cs.CV},
      url={https://arxiv.org/abs/2406.13763}, 
}
@misc{street2024llmsachieveadulthuman,
      title={LLMs achieve adult human performance on higher-order theory of mind tasks}, 
      author={Winnie Street and John Oliver Siy and Geoff Keeling and Adrien Baranes and Benjamin Barnett and Michael McKibben and Tatenda Kanyere and Alison Lentz and Blaise Aguera y Arcas and Robin I. M. Dunbar},
      year={2024},
      eprint={2405.18870},
      archivePrefix={arXiv},
      primaryClass={cs.AI},
      url={https://arxiv.org/abs/2405.18870}, 
}
@misc{xu2024opentomcomprehensivebenchmarkevaluating,
      title={OpenToM: A Comprehensive Benchmark for Evaluating Theory-of-Mind Reasoning Capabilities of Large Language Models}, 
      author={Hainiu Xu and Runcong Zhao and Lixing Zhu and Jinhua Du and Yulan He},
      year={2024},
      eprint={2402.06044},
      archivePrefix={arXiv},
      primaryClass={cs.AI},
      url={https://arxiv.org/abs/2402.06044}, 
}
@inproceedings{sabour-etal-2024-emobench,
    title = "{E}mo{B}ench: Evaluating the Emotional Intelligence of Large Language Models",
    author = "Sabour, Sahand  and
      Liu, Siyang  and
      Zhang, Zheyuan  and
      Liu, June  and
      Zhou, Jinfeng  and
      Sunaryo, Alvionna  and
      Lee, Tatia  and
      Mihalcea, Rada  and
      Huang, Minlie",
    editor = "Ku, Lun-Wei  and
      Martins, Andre  and
      Srikumar, Vivek",
    booktitle = "Proceedings of the 62nd Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers)",
    month = aug,
    year = "2024",
    address = "Bangkok, Thailand",
    publisher = "Association for Computational Linguistics",
    url = "https://aclanthology.org/2024.acl-long.326",
    pages = "5986--6004",
    abstract = "Recent advances in Large Language Models (LLMs) have highlighted the need for robust, comprehensive, and challenging benchmarks. Yet, research on evaluating their Emotional Intelligence (EI) is considerably limited. Existing benchmarks have two major shortcomings: first, they mainly focus on emotion recognition, neglecting essential EI capabilities such as emotion management and thought facilitation through emotion understanding; second, they are primarily constructed from existing datasets, which include frequent patterns, explicit information, and annotation errors, leading to unreliable evaluation. We propose EmoBench, a benchmark that draws upon established psychological theories and proposes a comprehensive definition for machine EI, including Emotional Understanding and Emotional Application. EmoBench includes a set of 400 hand-crafted questions in English and Chinese, which are meticulously designed to require thorough reasoning and understanding. Our findings reveal a considerable gap between the EI of existing LLMs and the average human, highlighting a promising direction for future research. Our code and data are publicly available at https://github.com/Sahandfer/EmoBench.",
}

@misc{pi2024dissectingullmanvariationsscalpel,
      title={Dissecting the Ullman Variations with a SCALPEL: Why do LLMs fail at Trivial Alterations to the False Belief Task?}, 
      author={Zhiqiang Pi and Annapurna Vadaparty and Benjamin K. Bergen and Cameron R. Jones},
      year={2024},
      eprint={2406.14737},
      archivePrefix={arXiv},
      primaryClass={cs.CL},
      url={https://arxiv.org/abs/2406.14737}, 
}

@misc{leibo2021scalableevaluationmultiagentreinforcement,
      title={Scalable Evaluation of Multi-Agent Reinforcement Learning with Melting Pot}, 
      author={Joel Z. Leibo and Edgar Duéñez-Guzmán and Alexander Sasha Vezhnevets and John P. Agapiou and Peter Sunehag and Raphael Koster and Jayd Matyas and Charles Beattie and Igor Mordatch and Thore Graepel},
      year={2021},
      eprint={2107.06857},
      archivePrefix={arXiv},
      primaryClass={cs.MA},
      url={https://arxiv.org/abs/2107.06857}, 
}

@inproceedings{murthy-etal-2023-comparing,
    title = "Comparing the Evaluation and Production of Loophole Behavior in Humans and Large Language Models",
    author = "Murthy, Sonia  and
      Parece, Kiera  and
      Bridgers, Sophie  and
      Qian, Peng  and
      Ullman, Tomer",
    editor = "Bouamor, Houda  and
      Pino, Juan  and
      Bali, Kalika",
    booktitle = "Findings of the Association for Computational Linguistics: EMNLP 2023",
    month = dec,
    year = "2023",
    address = "Singapore",
    publisher = "Association for Computational Linguistics",
    url = "https://aclanthology.org/2023.findings-emnlp.264",
    doi = "10.18653/v1/2023.findings-emnlp.264",
    pages = "4010--4025",
    abstract = "In law, lore, and everyday life, loopholes are commonplace. When people exploit a loophole, they understand the intended meaning or goal of another person, but choose to go with a different interpretation. Past and current AI research has shown that artificial intelligence engages in what seems superficially like the exploitation of loopholes, but this is likely anthropomorphization. It remains unclear to what extent current models, especially Large Language Models (LLMs), capture the pragmatic understanding required for engaging in loopholes. We examined the performance of LLMs on two metrics developed for studying loophole behavior in humans: evaluation (ratings of trouble, upset, and humor), and generation (coming up with new loopholes in a given context). We conducted a fine-grained comparison of state-of-the-art LLMs to humans, and find that while many of the models rate loophole behaviors as resulting in less trouble and upset than outright non-compliance (in line with adults), they struggle to recognize the humor in the creative exploitation of loopholes in the way that humans do. Furthermore, only two of the models, GPT 3 and 3.5, are capable of generating loopholes of their own, with GPT3.5 performing closest to the human baseline.",
}

@inproceedings{stohr2023deciphering,
title={Deciphering Enemies in the Darkness through Modeling and  Examination of Knowledge in Reconnaissance Blind Chess},
author={Robin St{\"o}hr and Shuai Wang},
booktitle={First Workshop on Theory of Mind in Communicating Agents},
year={2023},
url={https://openreview.net/forum?id=X1DUJqJijf}
}

@inproceedings{ruis2023do,
title={Do {LLM}s selectively encode the goal of an agent's reach?},
author={Laura Ruis and Arduin Findeis and Herbie Bradley and Hossein A. Rahmani and Kyoung Whan Choe and Edward Grefenstette and Tim Rockt{\"a}schel},
booktitle={First Workshop on Theory of Mind in Communicating Agents},
year={2023},
url={https://openreview.net/forum?id=KxvXjtyuYl}
}