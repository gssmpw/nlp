\section{Source Analysis Using MITRE ATT\&CK ICS Mitigation Techniques}
\label{sec:detection}
%
We rely on ATT\&CK ICS Mitigations framework~\citet{icsmitre} to categorize the techniques used in the sources as illustrated in Figure~\ref{fig:genai-attack-mappings}.
IoT systems have similar, if not all, methods to compromise them as ICS.
Although sources may not directly address the issue in the context of IoT, they are included due to their relevance.

In the following subsections, we first explain the details and findings about the mitigation techniques.
It should be noted that there are some overlaps, as a study might address more than one mitigation technique.
Subsequently, we provide the potential for using GenAI to secure IoT networks and systems.
Each work is discussed according to the following capabilities:
%
\begin{itemize}
%
\item \textbf{External Threat Detection (ETD)} refers to the ability of GenAI to detect or prevent external threats, be malicious or aimed at scanning vulnerabilities (e.g., fuzzing).

\item \textbf{Internal Anomaly Detection (IAD)} measures GenAI's ability to identify and detect anomalies within the system, such as secure coding practices, vulnerabilities in software or hardware components.

\item \textbf{Response Automation (RA)} measures the ability of LLMs to generate an automated response based on their functions.
These responses could take the form of alerts, documents, or software patches, ultimately improving the security of the IoT system.

\item \textbf{Research Maturity (RM)} measured by the security field that GenAI addresses and potentially improves.
Each GenAI focuses on a specific security niche and aims to resolve existing issues within that niche.
If the field is not well explored, it indicates low research maturity and is ripe for exploration and development.
In contrast, if established standards or tools are available to improve system security, the niche exhibits high maturity.

\item \textbf{Development Potential (DP)} measures GenAI's potential for further development of the current implementation evaluated based on the tool's ability to address specific security functions.
In particular, GenAI application with high DP implies that the application itself has the potential to be scaled or extended towards other security function while low DP means the application is self-contained and rather complete.

\item \textbf{Impact on Security (IS)} refers to the significance and scope that the proposed GenAI tool is capable of addressing in the security field.
%
\end{itemize}
%
It is important to note that certain capabilities are mutually exclusive.
For instance, a particular GenAI application may exclusively focus on ETD without addressing IAD, and vice versa.
We reviewed 33 state-of-the-art works and provided our analysis on the potentials and impact of application of GenAI in IoT security.
In Table~\ref{tab:potentials-genai-iot-sec}, a full circle indicates that the proposed GenAI application is comprehensive for one of the six capabilities, whereas a half circle means that the GenAI application addresses the capability with certain limitations.
Lastly, an empty circle indicates that the GenAI application does not cover a particular capability.
For each work, we provided justifications for the evaluation of each of the six capabilities in Table~\ref{tab:potentials-details} without being too text-heavy.
%
\begin{figure*}[!ht]
    \centering
    %\includesvg[width=\textwidth]{images/LLMMitigation.svg}
    \includegraphics[width=0.95\textwidth,keepaspectratio]{images/LLMMitigation.pdf}
    \caption{Mapping GenAI Applications for Cyber Security to MITRE ATT\&CK ICS Mitigations Framework}
    \label{fig:genai-attack-mappings}
\end{figure*}
%
\subsection{Application Developer Guidance} \label{subsec:adg}
%
This section discusses the use of GenAI to guide software developers in creating secure software from the outset.
The tool helps developers by providing guidance on secure software development or preparing development policies for software security.
Since most IoT devices and systems consist of a significant portion of software, this would benefit developers of IoT devices and systems.

\smallskip
\noindent\textbf{LLMSecGuard~\citet{Kavian2024LLMSG}} focuses on minimizing vulnerabilities and hard-coded credentials in production code.
Through the use of a static code analyzer, LLMSecGuard iteratively analyzes the code to identify vulnerabilities.
The code and analysis results are then presented to developers to create secure software that demonstrates the capabilities of LLMs.
A fine-tuned LLMSecGuard could be used to assist in secure software development for IoT systems.
For example, incorporating LLMSecGuard as part of the testing phase during software development ensures code security for software in the IoT.
This enables developers to create secure software without hard-coded credentials or keys oversight.
The impact of LLMSecGuard on the security field is limited to automating the patching process.

\smallskip
\noindent \textbf{LLift~\citet{libugdetection2024}} investigated Use Before Initialization (UBI) variables within the Linux kernel to uncover any bugs.
LLift has a 50\% precision rate, with 5 out of 10 reported positives being true vulnerabilities.
It also has a 100\% recall rate, as it did not misidentify any real bugs in the Rnd-300 dataset~\citet{li_2024_10780591}.
LLift helps users create secure code by identifying UBI bugs.
LLift could be implemented for IoT systems running embedded Linux, effectively identifying UBI bugs.
By fine-tuning LLift, developers could remove UBI bugs during testing and production, enhancing coding security, and mitigating risks in IoT systems.

The development potential for LLift includes adding an automated patcher and improving explainability and live detection.
UBI bugs are critical in Linux kernels, potentially leading to privilege escalation and information leakage.
LLift is among the few tools that address UBI bugs and its role in detecting these bugs is crucial for IoT security, especially given the use of embedded Linux by various vendors.
With further improvements, LLift could significantly impact IoT security by effectively patching UBI bugs.

\smallskip
\noindent\textbf{HuntGPT~\citet{ali2023huntgpt} : } GenAI, LLMs in particular, remains a black box in terms of its training and decision-making process.
To ensure that LLMs provide alerts with minimal false positives and are understandable by experts, it is necessary to explain why LLMs generated the alerts.
HuntGPT was developed for this purpose, trained in the KDD99 dataset~\citet{kdd99dataset} as an anomaly detector for benchmark attacks and standardized cyber security certification exams.
HuntGPT has a success rate of more than 70\% in these exams, demonstrating its knowledge and understanding.
It includes a dashboard that explains the attacks in the dataset, creating an explainable AI for cyber security experts to assess the reasoning behind the generated alerts.
Using IoT-related datasets such as NSL-KDD~\citet{nslkdd2009} or IoT attack benchmarks~\citet{iotattackbenchmark} could make attacks and anomalies explainable for IoT with HuntGPT, possibly with fine-tuning.
This helps experts quickly understand problems in IoT systems.
Implementing LLMs to generate a dashboard explaining anomalies could definitely be applied to IoT.

HuntGPT is highly automated and capable of detailed analysis and recommendations.
It has advanced automated response capabilities for IoT security, a field that is still emerging and integrating with other systems.
More IoT datasets could further fine-tune the tool for specific applications.
HuntGPT has significant potential for development into a live IDS, capable of addressing both external and internal threats.
In general, HuntGPT significantly impacts security by automating the analysis and classification of data sources, streamlining the process of identifying and understanding potential threats.
%
\subsection{Exploit Protection}
%
This section describes the application of GenAI to protect systems from exploits.
Protection could be achieved by blocking code execution and automated scripts.
LLMs could highlight important components and automate the hardening of system security in IoT environments.

\smallskip
\noindent \textbf{LLMind~\citet{cui2024llmind}} is an assistant that could perform complex tasks on an IoT network, acting as a gateway to control various devices.
It is used to control a Wi-Fi router, a mobile robot, and security cameras in a smart home system.
Implementation of LLMind is similar to giving prompts to a secretary, who then executes tasks based on generated finite-state machine code.
The study shows that LLMind successfully performed tasks such as object detection, human recognition, and report generation.
Although not directly related to security, LLMind has the potential to protect systems from exploits by executing device-specific security hardening techniques.
For example, it could update the allowed IP list for a security camera if an unauthorized remote connection is detected.
This potential of LLMind to receive prompts, generate scripts, and execute them could be exploited for the security of IoT.
LLMind is able to complete tasks autonomously for the given queries and could be improved to execute security-specific tasks.
The tool's current impact on security is limited due to its specific capabilities in physical and network protection.

\smallskip
\noindent \textbf{\citet{wang2024hybrid}} experimented with preventing attackers from escalating privileges by creating an LLM to identify user privilege-related variables (UPR) through fine-tuning with specific UPR knowledge.
The LLM identified the UPR with a 13.49\% false positive rate in typical programs where the UPR score was more than 80\%.
This LLM helps security analysts prioritize security enhancements for UPR variables, potentially creating more secure systems.
In IoT systems, it could be implemented in devices or network edges to secure critical code, such as OS-level programs.
With fine-tuning and IoT domain knowledge, the LLM could assist in the identification of UPR and help prevent privilege escalation, making it a valuable tool for mitigating attacks from exploits.
In terms of response automation, this LLM identifies UPR variables and prompts the user with minimal human intervention.
Extensive research on security of these critical variables leaves little room for further improvements.
However, this implementation could be a pioneering tool for identifying critical variables within IoT systems.
The security impact of the tool is significant as it could identify vulnerable UPR variables.

\smallskip
\noindent \textbf{NVISOsecurity~\citet{Raman_2024}} is an advanced LLM tool designed to protect vulnerabilities using an adversary emulation platform called Caldera.
Developed with Microsoft's AutoGen~\citet{wu2023autogen} framework, it employs two LLMs to automate tasks in predefined scenarios, such as generating vulnerability reports or adversary profiles.
Although not directly implemented in IoT security, its customizability allows exploit protection.
Caldera plugins, such as Caldera OT, could be added to address MITRE ICS techniques relevant to IoT.
NVISOsecurity executes tasks via the terminal or PowerShell, altering the machine's state.
It blocks or terminates anomalous processes, demonstrating its potential to mitigate attacks through exploit protection.
NVISOSecurity requires minimal human interaction, generates automated responses, and executes commands to prevent external attacks.
The research maturity is growing with ongoing research in MITRE ATT\&CK and automated execution.
Its impact on security is significant, as it automates attack-defend simulations, streamlines the defense process, and allows security personnel to focus on other tasks.

\smallskip
\noindent \textbf{Cyber Sentinel~\citet{kaheh2023cyber}} was developed to create an LLM that could explain its actions (Explainable AI) and perform tasks to improve system security (Actionable AI).
It processes conversational queries to generate actions for security tasks.
In the study, Cyber Sentinel successfully analyzed user prompts to retrieve and block IP addresses connected to a machine within the last three hours.
Although simple for humans, this task requires multiple steps.
The results showed improved threat detection, operational efficiency, and real-time collaboration.
This demonstrates the potential of LLMs such as Cyber Sentinel for IoT.
With more domain-specific training, Cyber Sentinel could perform IoT-specific tasks, such as blocking of IP addresses or automated updates, to secure networks, highlighting the potential of LLMs in securing IoT systems.

Cyber Sentinel prevents external exploitation, demonstrating its ability to detect and act on external threats.
It automates security tasks based on user queries and requires minimal human input.
In terms of research maturity, Cyber Sentinel is part of an emerging field focused on automated task execution based on user queries.
The development potential includes adding more task executions and improving its capabilities for IoT systems.
Future research could also explore its use in IoT penetration testing.
The security impact of Cyber Sentinel is significant, enabling automation for both blue and red teams.
%
\subsection{Limit Hardware Installation}
%
LLMs could be utilized to restrict additional installations in an IoT system by employing an observer, such as a CCTV, to ensure the integrity of the physical installation and prevent unauthorized USB devices from being inserted.
Although not all studies directly address this mitigation technique for IoT, this section explores its potential use based on existing research.

\smallskip
\noindent \textbf{VIoTGPT~\citet{zhong2023viotgpt} : } To limit the installations of rogue devices, the traditional method uses CCTV to monitor the system.
However, this lacks intelligent alerts to detect anomalies.
VIoTGPT combines LLM with a vision-based model to handle tasks involving images and text queries.
It uses tools for face recognition, vehicle re-identification, anomaly detection, and action recognition, all fine-tuned with specific domain knowledge.
The output includes decisions, recommended tools, and tool output descriptions.
Fine-tuned with public video datasets, web-scraped data, and self-made datasets, VIoTGPT identifies and describes tasks such as anomaly detection and action analysis with 30-50\% accuracy in the test set and 60-70\% accuracy in the validation set.
By integrating LLM and image-based models, VIoTGPT could create descriptions and recommend tools for certain tasks.

For IoT systems, VIoTGPT's anomaly detection could mitigate insider threats by identifying actions like inserting rogue devices.
This allows VIoTGPT to alert users of potential threats and limit hardware installations, preventing rogue devices with malicious programs from being connected to the IoT system.
VIoTGPT requires human prompts and automatically provides visual and analysis results.
Possible improvements include automated task execution to prevent suspicious activities and other enhancements such as sound and speech analysis, active physical defense, and preventive actions on open ports in a physical IoT system.
However, its current implementation is limited to alerting and analyzing actions within an image.
%
\subsection{Mechanical Protection Layers}
%
This section discusses the application of LLM to enhance the protection of the mechanical layer in IoT, pertaining to the hardware of IoT devices.
This encompasses the security of the design and physical safeguarding of IoT devices exploring the potential of LLM to aid in designing secure hardware.

\smallskip
\noindent \textbf{\citet{saha2023llm} : } A critical aspect of IoT systems is hardware design, which could inherently contain vulnerabilities.
A vulnerable design could be exploited at the hardware level, making it difficult for software to prevent access by malicious actors.
In their study, Saha et al. trained an LLM to critique the design of system-on-chip (SoC) integrated circuits to evaluate their security.
Although not specifically focused on IoT, this study demonstrates the potential of LLM to assess the security of SoC design.
Tests such as security verification, countermeasure development, security assessment, and vulnerability insertion were conducted to create a more secure SoC.
These tests are crucial because SoC security depends on a human-mistake-free and vulnerability-free initial design.
LLM's adaptability allows for dynamic implementation of security tasks in SoC design.
The study also suggests that LLM could improve the security of current and future SoC designs, helping to patch hardware design vulnerabilities in IoT devices and systems.

The proposed tool addresses T0880 tactic and prevents vulnerabilities and exploits from hardware design.
Its response automation capabilities depend heavily on user instructions and security rules.
In terms of research maturity, very few works address hardware design to improve security.
The development potential includes full automation of design critique to minimize user inputs and support diverse security standards.
Design critique and improvement could defend against zero-day vulnerabilities from hardware weaknesses and prevent hardware exploits and side-channel attacks.
This is the only LLM implementation that addresses possible exploits in an IoT setting using Mechanical Protection Layers.
%
\subsection{Network Intrusion Prevention}
%
This section explains how LLM protects IoT systems from network intrusions in ICS by using network intrusion detection or prevention modules.
Although not all studies focus on IoT, their potential for IoT implementation is discussed.

\smallskip
\noindent \textbf{BERTIDS~\citet{lira2024}} is a LLM-based tool for network intrusion detection.
It processes and understands network log data to identify and classify anomalies.
BERTIDS is adaptive and continuously learns new behavior to combat new threats, allowing it to detect network attacks that evade rule-based detectors.
Using the NSL-KDD dataset~\citet{nslkdd2009}, BERTIDS achieved the highest accuracy, precision, and F1 score (above 98\%) compared to other methods.
Although not directly implemented in IoT datasets, BERTIDS could be adapted to IoT by using the IoT attack benchmark dataset to identify attacks such as DoS, web-based, and Mirai.
As IoT evolves, LLMs such as BERTIDS could be adapted to understand network communication patterns.
BERTIDS shows significant potential for developing LLM implementations in detecting network intrusions.

\smallskip
\noindent \textbf{\citet{guastalla2023application}} conducted a study to detect DDoS attacks using LLM.
They trained and fine-tuned an LLM with CICIDS2017 and Urban IoT datasets to identify DDoS attacks.
The results demonstrated that the LLM achieved more than 90\% accuracy for both datasets when trained with few-shot learning methods.
However, the study has not been tested in a real network setting, which could impact its accuracy.
Despite this, the research shows potential for using and improving LLMs to detect network intrusion anomalies, such as DDoS attacks, within IoT systems.
The proposed tool is automated and requires minimal human intervention.
Its development potential lies in the ability to detect different types of attacks.
In terms of its impact on security, this was among the early works using LLM as an anomaly detector or IDS.

\smallskip
\noindent \textbf{SecurityBERT~\citet{ferrag2024revolutionizing}} utilizes BERT to create a lightweight model for IoT.
The study used network data to generate anomaly detection within the system, focusing on DDoS, information gathering, malware, injection, and man-in-the-middle attacks.
SecurityBERT outperformed traditional ML and DL techniques with 98.2\% accuracy, while other techniques were around or below 97\%.
It was integrated into a real-life setting, using internal network traffic within the IoT system.
This implementation demonstrates that SecurityBERT is a successful anomaly detector to identify different types of attack within an IoT system.
SecurityBERT is able to classify external threats based on network traffic features and autonomously generates classification results.
It is already trained with an IoT-related dataset.
A possible research direction for SecurityBERT is to create an agent that acts on the classification results.

\smallskip
\noindent \textbf{IDS-Agent~\citet{li2024idsagent}} is a very recent work on the intrusion detection system for IoT, using LLM to improve detection.
Unlike traditional IDS methods, it combines reasoning and action for better performance and zero-day attack detection.
In experiments, IDS-Agent outperformed state-of-the-art machine learning-based IDS and previous LLM-based methods, achieving F1 scores of 0.97 on the ACI-IoT benchmark and 0.75 on the CIC-IoT benchmark.
IDS-Agent is able to detect zero-day attacks with a recall of 0.61 surpassing previous approaches specially designed for this task.
The IDS-Agent automatically detects and classifies attacks targeting the IoT.
Though it was validated using two datasets, it could be further developed and extended towards live detection and become a more impactful security tool for first line of defence.

\smallskip
\noindent \textbf{HuntGPT~\citet{ali2023huntgpt}} serves as an anomaly detector to create an Explainable AI for users.
As described in Section~\ref{subsec:adg}, it detects attacks in the dataset and displays them on a dashboard for user understanding.
The attack details help explain and understand the context.
Identifying attacks and anomalies, HuntGPT improves security, allowing users to address these issues.
This implementation of HuntGPT functions as both an anomaly detector and a tool for Explainable AI.
%
\subsection{Software Update}
%
This section outlines studies and experiments aimed at mitigating attacks and enhancing security by patching vulnerabilities and updating software within IoT systems.
Although not all studies directly address improving IoT security using LLM, there is potential for further research and exploration to contribute to IoT security.

\smallskip
\noindent \textbf{\citet{islam2024llmpowered}} proposed an LLM-based tool to patch vulnerable code.
The LLM is trained using semantic reward and reinforcement learning.
It takes C code as input and produces a patched version with fewer or no vulnerabilities.
The study shows successful patching of vulnerabilities that improve the security of IoT devices by preventing initial access points for attackers.
There is potential in this work to ensure that IoT software, possibly at the firmware or operating system level, has minimal vulnerabilities.
The study demonstrates that the patch fixes common and known vulnerabilities, indicating a further potential for LLM to improve in terms of fixes.
The LLM could be trained using open source datasets, such as Automated CVEFixes by ~\citet{bhandari2021:cvefixes}, that focus on IoT.
With datasets specializing in IoT, the LLM can be further trained to patch software that prevents the exploitation of public-facing devices.
LLM could be applied as a tool for automated vulnerability patching to address security weaknesses in the context of the IoT.
The tool is capable of autonomously patching vulnerable code with minimal human input.
Potential for further improvements include additional modules for automated implementation or replacement tasks.
Its impact on security is high, increasing efficiency and effectiveness in software security improvement.

\smallskip
\noindent \textbf{DefectHunter~\citet{wang2023defecthunter}} is another LLM-based implementation for patching vulnerabilities.
It serves a similar purpose to~\citet{islam2024llmpowered} since both use LLMs to repair and patch vulnerable code.
However, DefectHunter differs in its design, utilizing attention models instead of reinforcement learning and semantic rewards.
Both studies demonstrate that current LLMs could effectively patch vulnerable code when given as prompts.
To apply LLM to IoT, it is necessary to incorporate IoT-specific training datasets, such as the QEMU dataset~\citet{zhou2019devign}, Pongo-70B~\citet{Pongo-70B}, and CWE-754 dataset~\citet{NVD}.
This would enable the LLM to understand and patch IoT-specific vulnerabilities and defects.
Potential improvements include modules to optimize processing time and training the model with IoT-specific dataset.
Its impact on security is significant due to the automation of vulnerability patching, which allows faster software review and more efficient code production, leading to a more secure system.
%
\input tab-potential-impact
%
\smallskip
\noindent \textbf{LLift~\citet{libugdetection2024}} is another LLM-based tool for patching vulnerabilities.
As mentioned in Section~\ref{subsec:adg}, it is used to identify UBI bugs and could be applied during the development phase or to identify vulnerabilities in a running Linux kernel.
LLift performs a static analysis to find unpatched vulnerabilities, allowing users to patch them.
Despite a precision of 50\%, LLift is effective in identifying vulnerabilities, making it a useful tool for patching them.
This LLM implementation could help mitigate IoT attacks by updating software to patch vulnerabilities.
%
\subsection{Threat Intelligence Program}
%
This section outlines the research conducted on LLMs to mitigate attacks by developing threat intelligence policies.
These mitigation efforts encompass various approaches, including the formulation of security policies for organizations and incident response plans.

%
\smallskip
\noindent \textbf{AttackGen~\citet{Adams_2024}} is an LLM-powered incident response tool that helps organizations prepare for cyber attacks by understanding possible attack vectors.
It automatically generates these scenarios based on industry type, attack vectors, and organization size.
AttackGen uses these parameters to create detailed incident response scenarios, with OpenAI as the default model.
In its default setting, AttackGen could generate general incident response plans and evaluation metrics.
It is a viable tool for generating threat intelligence to mitigate attacks.
Extending it to IoT systems would involve modifying the prompt to focus on the IoT context.
This could help generate specific incident response plans for IoT.
AttackGen helps prevent external threats by providing incident reports and playbooks for user training, addressing potential attacks and protection methods with potential for further specialization and contextual relevance. 
Its impact on security is high due to its pioneering role in automated report generation and playbook creation, significantly affecting the field of security.
Section~\ref{sec6} discusses a case study on AttackGen with the necessary modifications for IoT implementation.

\smallskip
\noindent \textbf{\citet{mcintosh2023harnessing}} investigated whether GPTs could generate better cyber security policies than humans.
Using a ransomware attack as a case study, they found that GPTs outperformed humans in terms of completeness, effectiveness, and efficiency.
GPTs scored higher on these metrics, indicating that they could generate more secure policies.
Although not yet tested in IoT, the results suggest that GPTs could also be effective in this context.
Transfer learning could also further enhance the LLM focus on IoT, potentially leading to GPTs outperforming human policies in this area.
Its impact on security is significant due to its novelty and effectiveness.
%
\subsection{User Training}
%
This section explains how LLMs have been used in studies to improve human skills in IoT security, similar to concepts in generic cyber security.
LLM applications focus on improving awareness of common exploitation methods, such as phishing emails and social engineering.

\smallskip
\noindent \textbf{\citet{bethany2024large}} implemented LLM to generate spear-phishing emails to gain access to the system.
Over 11 months, they found that more than 10\% of the staff in an educational organization were vulnerable to LLM-generated attacks and gave out their credentials.
The study concluded that user training and awareness are needed to prevent such attacks.
The study also resulted in an application to defend against LLM-generated phishing emails, achieving an F1 score of 98.96\%.
In IoT systems, user training is crucial to prevent spear-phishing.
Training and fine-tuning the LLM could create a program based on its e-mail detection capabilities.
Common signs of LLM-generated emails could be compiled into a database to help users identify and avoid such attacks.
This demonstrates the potential of LLM in detecting and training users to mitigate spear-phishing attacks.
The proposed tool mimics attacker methods and functions as a protective tool to prevent external threats.
The LLM operates autonomously with minimal human input, focusing solely on email generation.
Its main goal is to improve the efficiency of phishing content generation.
Although it contributes to security training, its impact is limited due to the well-established nature of phishing awareness and existing preventive measures.

\smallskip
\noindent \textbf{\citet{yamin2024}} emphasized the need for personnel training to gain experience during cyber attacks.
Since real attacks are hard to predict, cyber exercises are used for training.
The authors created a scenario generation tool using LLM to produce exercise scenarios based on various criteria, following the concept of digital game-based learning~\citet{digitalgamebasedlearning}.
This tool could generate scenarios for both known and emerging security issues.
In IoT systems, specific prompts can be used to generate threats as exercise scenarios.
This demonstrates the potential of LLM as a tool for IoT security training, enhancing the capabilities of IoT security personnel.
For example, a compromised smart home scenario could be simulated as an exercise.
The tool does not generate playbooks or handle OS/software anomalies, focusing solely on human training.
The LLM autonomously creates scenarios based on user queries.
Although it improves training efficiency, its impact on security is limited, as it does not provide implementation guidance.
The tool addresses a developing field in security, with potential improvements mainly in content generation effectiveness.

\subsection{ Vulnerability Scanning}
%
This section explains how LLMs could enhance IoT security by identifying and fixing vulnerabilities in devices.
It covers both finding and fixing these vulnerabilities, including security testing during development to prevent issues before deployment.

\smallskip
\noindent \textbf{LLM4Vuln~\citet{sun2024llm4vuln}} studied the reasoning abilities of LLM to identify vulnerabilities and understand the key components affecting this process.
The authors focused on smart contracts and identified knowledge retrieval, tool invocation, prompt schemes, and instruction following as critical factors.
The experimental results showed that knowledge retrieval is crucial and that GPT-4 performed best among LLMs.
Using LLM4Vuln, nine zero-day vulnerabilities in bug bounty programs were identified.
This work suggests that applying LLM4Vuln to IoT could help improve LLM’s ability to identify vulnerabilities in IoT security.
LLM4Vuln operates with minimal user interaction, autonomously discovering vulnerabilities based on its training.
It addresses the evolving field of vulnerability exploration, indicating the potential for further development.
Future improvements could include an automated task executor to fix vulnerabilities and additional contextualization for specific security fields.
This autonomous agent could improve system security, particularly in the IoT context.

\smallskip
\noindent \textbf{AutoAttacker~\citet{xu2024autoattacker}} uses LLM to automate attack launching, serving as a red-team tool.
It is a jailbroken LLM that could execute complex tasks such as lateral movement and obtaining credentials on Windows and Linux platforms, leveraging GPT-4 and Metasploit.
It successfully executed all benchmark attack tasks.
Fine-tuning AutoAttacker with a dataset like CICIoT2023, which includes various attacks targeting IoT devices, could create a specialized LLM.
This would enable AutoAttacker to focus on IoT-specific attack scripts and enhance security testing and defense mechanisms for IoT.
AutoAttacker could successfully exploit known vulnerabilities, highlighting areas for defense improvement.
It addresses the evolving field of defense capabilities, with potential for further improvement to handle more complex tasks and discover new vulnerabilities.
AutoAttacker's impact on the security field is significant, though limited to discovering known vulnerabilities.
It improves defense through vulnerability discovery, but lacks the ability to find new ones.

\smallskip
\noindent \textbf{\citet{tóth2024llms}} implemented an LLM to scan and find vulnerabilities in web environments, focusing on PHP code and common web attacks such as XSS and SQL injection.
The authors used GPT-4 to generate PHP code and GPT-3.5 with static code analysis to find vulnerabilities.
The LLM identified 78\% of static file upload vulnerabilities, 50.15\% of prepared statement vulnerabilities, 38\% of code audit vulnerabilities, 11.16\% of XSS or SQL injection vulnerabilities, and 8\% of vulnerable code manually.
This approach could be adapted for IoT by modifying the code generation and classification steps.
Although IoT software differs from web applications, this framework shows the potential to find vulnerabilities in AI-generated code, helping mitigate attacks.
The tool operates with minimal human input, focusing on scripts and code related to web applications.
Broadening its scope to include different contexts could improve its capabilities.
This could involve adding other datasets and developing an automated executor based on identified vulnerabilities.
The tool's impact on security is limited due to its focus only on web-based security.

\smallskip
\noindent \textbf{\citet{oliinyk2024fuzzing}} present a new method for creating a security testing tool, specifically a fuzzer.
Their study used a trained LLM to fuzz BusyBox, a tools suite that combines many Unix utilities.
The LLM effectively crashed the environment and identified weaknesses without traditional fuzzing methods.
This shows that LLM could test the security of Unix-based systems, which is relevant for IoT devices, since they often use Unix-like operating systems (e.g. embedded Linux).
The study suggests that LLM could automate and streamline the fuzzing process for IoT devices, making security testing more efficient.
This allows more time for additional security tests before deployment.
Therefore, this approach could improve the effectiveness and efficiency of security testing for IoT devices.
The tool generates automated inputs for fuzzing with minimal human input, continuously testing until new vulnerabilities are found.
Although the field is mature, further research could improve the tool by expanding its application beyond embedded Linux systems to other types of systems.
The tool's impact on security is limited to fuzzing, increasing the efficiency of vulnerability discovery without providing solutions to patch them or protecting the system afterwards.

\smallskip
\noindent \textbf{\citet{happe2024llms}} use LLM for privilege escalation, functioning as a red-team tool in a controlled environment.
They focus on escalating privilege once inside the system.
Fine-tuned LLMs, specifically Llama-2 and GPT-4, were tested on a Linux privilege-escalation benchmark, with GPT-4 performing better.
The LLM runs commands to escalate the attacker’s privilege.
Limitations include the LLM running the same commands repeatedly.
In IoT testing, this LLM implementation could help create defense mechanisms to identify and block LLM-generated commands attempting privilege escalation.
The tool fully automates the privilege escalation process with initial queries and inputs, increasing efficiency and effectiveness.
However, it repeats the same query without human intervention, which is a weakness.
Privilege escalation is a well-researched field, and while the tool improves process efficiency, its impact on security is limited to this specific area.
The development potential includes overcoming the repetition issue to enhance automation.

\smallskip
\noindent \textbf{\citet{wangfuzzing2024}} improved the efficiency and effectiveness of software testing using LLM for fuzzing.
The authors addressed limitations such as unknown message formats, unresolved dependencies, and lack of testing evaluations.
The proposed model, LLMIF, uncovered 11 vulnerabilities, including eight new ones, in Zigbee devices.
This makes LLMIF useful for discovering vulnerabilities in IoT systems, helping security experts identify and patch them in the future.
LLMIF autonomously generates input to test the defenses of the IoT system with minimal user intervention, achieving relatively complete automation of the fuzzing process.
The tool addresses the well-established field of fuzzing, with potential for further development through LLM.
LLMIF's impact on the security field is significant within the fuzzing niche, as it can discover new vulnerabilities more effectively than humans.
Despite its niche focus, its ability to find new vulnerabilities highlights its impact.

\smallskip
\noindent \textbf{ChatAFL~\citet{meng2024large}} is an LLM-based protocol fuzzer to test protocol implementation correctness and vulnerabilities.
A protocol fuzzer is defined as a tool that generates message sequences following the required structure and order of a protocol.
ChatAFL performed faster and covered more branches than other benchmark fuzzers such as AFLNet~\citet{9159093} and NSFuzz~\citet{NSFuzz2023}.
The addition of LLM to the protocol fuzzing improved efficiency and coverage.
Although not tested on IoT, ChatAFL has potential as a security testing tool if fine-tuned with an IoT dataset.
This could enable ChatAFL to perform protocol fuzzing on emerging IoT protocols such as Matter, serving as a red-team tool for vulnerability scanning.
ChatAFL autonomously generates messages in the given protocol format, requiring minimal user intervention.
It addresses the emerging field of protocol fuzzing, which has gained attention since 2019.
The development potential for ChatAFL is tied to the evolving field of protocol fuzzing.
Further training and improvement depend on advancements in the field due to the lack of a standardized dataset.
ChatAFL's impact on the security field is significant, particularly in IoT, as it enhances the efficiency and effectiveness of protocol fuzzing through automation.

\smallskip
\noindent \textbf{FIAL~\citet{androidfuzz2024}} is an implementation of LLM as a fuzzing tool for IoT devices.
It uniquely employs an Android device for execution, combined with taint analysis results to generate suitable trigger functions for fuzzing.
The Android device extracts network packets, sends them to the LLM and data analyzer, and receives a crash code to test on the IoT system.
If the system crashes, a successful vulnerability exploitation is identified.
The experiment results identified 14 vulnerabilities, including 3 injection and 11 overflow vulnerabilities, of which 5 being new.
This demonstrates a unique LLM implementation using an Android device for fuzzing and finding vulnerabilities in IoT systems, successfully implementing a tool for vulnerability scanning.
FIAL is able to discover new vulnerabilities autonomously, but is limited to network attack vectors.
It requires minimal human intervention, with the main interface being an Android device, which limits the types of input and commands.
Fuzzing is a mature research field but continues to evolve with software advancements.
In IoT security, automation, and research through LLM, as seen with FIAL and CHATAFL, improve the fuzzing process.
The development potential for FIAL includes creating a more mobile and stealthy device for running tests.
There is also potential for developing a similar tool for iOS devices.
FIAL's impact on security is significant, especially in fuzzing and testing.
The use of an Android device allows for stealth testing and fuzzing, which could lead to new research directions for prevention and detection.

\smallskip
\noindent \textbf{\citet{fang2024llm}} demonstrated a method for an automated attacker using LLM to secure IoT systems.
The study showed that an LLM trained with GPT-4 executed 87\% of known attacks when given the CVE description, but only 7\% without it.
This highlights the potential of LLM tools for security testing.
With further research, this tool could automate vulnerability exploitation in cyber exercises or training.
Additionally, there is potential for LLM to eliminate one-day vulnerabilities by patching them immediately upon discovery.
It effectively addresses external threats and could find new vulnerabilities without CVEs.
The tool autonomously exploits vulnerabilities with given CVEs and to a limited degree without them, fulfilling its purpose with minimal human intervention.
Simulated attack tools are a mature research topic, and this tool improves automation and vulnerability exposure capabilities.
The development potential includes improving the discovery of new vulnerabilities without CVEs.
The impact of the tool on security is limited to its automated attack capabilities.

\smallskip
\noindent \textbf{mGPTFuzz~\cite{Maetal2024}} is a first-of-its-kind Matter fuzzer to find bugs and vulnerabilities in Matter-compatible IoT devices.
The authors leverage LLM to transform the human-readable specification, over a thousand pages, to machine-readable information in the form of finite state machines (FSMs).
It is a blackbox fuzzing tool and mGPTFuzz is able to find stateful, non-crash and crash bugs.
mGPTFuzz was evaluated with 23 Matter devices leading to the discovery of 147 new bugs, including 61 zero-day vulnerabilities and three CVEs.
While the fuzzer itself is limited to Matter-compatible devices, this work has significant impact on IoT security due to increasing support and adoption of Matter-certified smart home devices.

\smallskip
\noindent \textbf{PentestGPT~\citet{deng2023pentestgpt}} used LLM, such as GPT-4 and Bard, to automate the penetration testing process.
It leverages the knowledge of pre-trained LLMs to conduct these tests.
PentestGPT was tested against benchmark attacks and divided tasks to compare LLM performance.
It was 228.6\% more effective than other LLMs and applicable to real life challenges.
Fine-tuned PentestGPT significantly improved task execution and results.
PentestGPT also enhances the penetration testing process by relating steps for a more effective execution.
This study demonstrates a practical and effective implementation of LLM for automated penetration testing.
The tool automates the penetration testing process with minimal human input, outperforming human users in benchmark tests.
Penetration testing is a constantly evolving field that offers potential for improvement in defense mechanisms.
The development potential includes further training for different contexts such as IoT or ICS.
Its impact on the security field is significant as it improves the effectiveness of protection mechanisms through efficient vulnerability discovery.

\smallskip
\noindent \textbf{Net-GPT~\citet{10419242}} used LLM as a red-team tool to launch automated man-in-the-middle attacks on unmanned aerial vehicles (UAVs).
It claims an efficacy of more than 90\% in hijacking UAVs after fine-tuning Llama GPTs and more than 70\% with other smaller LLMs.
Net-GPT assumes that the attacker has access to the network, compromises a UAV, and intercepts communications between the UAV and ground control.
For IoT, a specific man-in-the-middle attack dataset is needed to fine-tune the LLM, allowing it to learn IoT-specific behaviors.
In addition, a benign IoT device must be compromised to act as a foothold to observe, modify, and compromise the IoT network, similar to the UAV implementation.
Net-GPT mimics network packets and act as a man-in-the-middle between two devices in the system.
The tool addresses the established field of man-in-the-middle attacks, which already has early detections and mitigations.
Development potential includes further contextualization and expanding the scope of the LLM's application.
Net-GPT's impact on security is specific to man-in-the-middle attack vectors, exposing vulnerabilities to this type of attack but not others.

\smallskip
\noindent \textbf{\citet{Happe_2023}} addressed both high-level penetration testing planning and low-level execution using LLM.
The LLM gained root privilege and obtained passwords on a compromised Linux machine using the ``sudo -l'' command and reading ``/etc/passwd''.
It could also create a reverse shell, though less consistently.
This suggests that LLM can automate penetration testing tasks and planning.
Given the experimental environment was a compromised Linux system, commonly used by IoT devices, it has potential for automated penetration testing of IoT systems running Linux.
The tool operates with minimal human response, increasing the efficiency of the penetration testing process.
Penetration testing is a mature field that continues to grow with advances in security.
The development potential includes improving the model to increase the variety and consistency of simulated attacks for vulnerability exposure.
Another direction is to contextualize attacks for the IoT field, extending current tests on Linux systems.
The tool's capability is limited to network-based penetration testing, restricting the attack vectors that could be tested.

\smallskip
\noindent \textbf{\citet{yang2023iot}} studied the use of LLM and static code analysis to identify and constrain vulnerabilities in IoT systems through user prompts.
Their study showed a 66.67\% success rate in identifying vulnerability types with an average of 9 prompts and an 83.33\% success rate in identifying specific code lines with an average of 4 prompts.
Prompt engineering was found to be at least 60\% effective in both tasks.
This work highlights the potential of prompt engineering to scan for vulnerabilities in IoT systems.
Further research could improve the effectiveness of this approach in identifying vulnerabilities.
The tool autonomously executes tasks to constrain the type of vulnerability with minimal user intervention.
It functions within the mature research field of static code analysis, automating the process to increase security.
Potential improvements include automated execution of vulnerability fixing and enhanced detection capabilities for more efficient and effective queries.
The impact of the tool on security is limited to increasing the effectiveness and efficiency of static code analysis, as it does not handle other protection or detection methods, limiting its overall impact.