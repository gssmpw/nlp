\section{Introduction}

% These instructions are for authors submitting papers to *ACL conferences using \LaTeX. They are not self-contained. All authors must follow the general instructions for *ACL proceedings,\footnote{\url{http://acl-org.github.io/ACLPUB/formatting.html}} and this document contains additional instructions for the \LaTeX{} style files.

% The templates include the \LaTeX{} source of this document (\texttt{acl\_latex.tex}),
% the \LaTeX{} style file used to format it (\texttt{acl.sty}),
% an ACL bibliography style (\texttt{acl\_natbib.bst}),
% an example bibliography (\texttt{custom.bib}),
% and the bibliography for the ACL Anthology (\texttt{anthology.bib}).

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%


% The advent of ChatGPT-o1, a reasoning large language model, has sparked significant interest in the academic community. A key factor behind its success are Chain-of-Thought (CoT)-based reasoning techniques, which improves a model’s reasoning abilities by breaking complex problems into explicit intermediate steps. Building upon this, the Tree of Thoughts (ToT) framework has been introduced to further elevate LLMs' reasoning capacities. ToT restructures resoning as a tree search process, and employs search algorithms, such as Monte Carlo Tree Search (MCTS), to construct a tree-like structure that explores various reasoning pathways, ultimately leading to more refined and accurate responses. 

% However, current ToT approaches predominantly focus on improving search accuracy while overlooking computational efficiency. 
% % Deft 关注于tree structure kv cache的底层优化，没有关注树搜索算法。
% This oversight results in two significant challenges. 
% % The first challenge stems from the poor adaptation of traditional MCTS algorithms to modern parallel GPUs. 
% During the generation phase, the sequential nature of MCTS leads to low GPU utilization—below ?\%, which constitutes a major bottleneck for inference speed. 
% The second challenge arises from the excessive exploration of invalid paths during the rollout phase. Classical MCTS relies heavily on depth-orient rollout (DOR), which often results in the algorithm focusing too much on suboptimal or invalid paths. Specifically, DOR continues to expand a path until meet the termination criteria, leading to wasted exploration. 

% To address these challenges, we propose a novel, efficient, and hardware-aware tree search method, named ?,  which consists of two key innovations: streaming parallel expansion for improved hardware efficiency and a hybrid depth- and breadth-oriented rollout strategy for more effective exploration. 

% By incorporating streaming parallel expansion, we make better use of GPU parallelism by increasing the batch size during the generation phase, allowing the exploration of multiple paths concurrently. Our experimental results demonstrate that this approach significantly enhances GPU utilization without a substantial increase in time consumption, making it a practical solution to leverage parallel hardware efficiently. 
% % 
% % Additionally, we introduce a parallel streaming expansion strategy, where a streaming queue selects k nodes at each step for expansion, ensuring that the nodes are both meaningful and computationally efficient.

% To tackle the inefficiencies in the search strategy, we propose a hybrid depth and breadth-oriented rollout method. By redesigning the node selection and expansion process within the streaming queue, we combine both depth-orient and breadth-orient rollout approaches. This allows the algorithm to explore high-quality paths deeply while also ensuring that less promising areas of the search space are adequately covered. This balance between exploitation and exploration improves overall search efficiency, preventing excessive focus on suboptimal solutions and accelerating convergence.

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%


% Existing tree search methods primarily fall into two paradigms. \textbf{Heuristic search} mimics human experts’ intuitive reasoning by leveraging LLMs' prior knowledge, \textit{i.e. single-step generation probabilities} to rapidly select promising paths. While \textbf{ the simulation-based search} emulates the reflective assessment and deliberative thinking of human experts by performing multiple rollouts and evaluating the rewards of the posterior path to derive more reliable results. However, these existing tree search techniques struggle to strike a balance between intuition and deliberation.

% This highlight a fundamental trade-off between efficiency and effectiveness. Heuristic methods prioritize efficiency but lack introspection, often becoming trapped in local optima due to their susceptibility to cognitive biases. On the other hand, simulation-based methods enhance reasoning quality but suffer from significant inefficiencies, stemming from two main issues: 1) excessive resource consumption due to redundant exploration of suboptimal paths, and 2) fundamental misalignment with hardware parallelism, as their sequential execution prevents the effective utilization of parallel processing capabilities. While recent efforts to integrate process reward models for estimating partial-path posteriors have shown promise, they still face challenges, including cumulative estimation errors and the unavoidable serialization required for posterior-driven evaluations.
% In summary, the dilemma of tree search primarily arises from the separation of prior and posterior, as well as the mismatch between algorithms and hardware architectures.

% To address these challenges, we propose Hybrid Prior-Posterior Tree Search (HPPT), an innovative, hardware-friendly framework based on MCTS, which harmonizes intuition and deliberation through three co-designed innovations: synergistic node evaluation, streaming heuristic sampling, and real-time posterior feedback.

% Technically, first, synergistic node evaluation mechanism dynamically balances prior confidence from LLM generation probabilities and posterior rewards from both terminal outputs and PRM estimations. By introducing an adaptative weight, HPPT automatically shifts focus from prior-dominated exploration in shallow layers to posterior-driven exploitation in deeper reasoning stages, mirroring human cognitive transitions between fast intuition and slow reflection. Second, the streaming heuristic sampling protocol reimagines best-first search for hardware-aware parallelism. Instead of rigid beam pruning, HPPT continuously selects the top-k most promising nodes across the entire tree at each step, enabling GPU-friendly batch expansion while dynamically avoiding local optima. Third, real-time incremental posterior feedback closes the loop between exploration and evaluation. When any node reaches a terminal state, HPPT immediately propagates backward-corrected reward signals through its reasoning path, iteratively refining posterior estimates for active branches.


\input{pages/1.dyf_intro}

