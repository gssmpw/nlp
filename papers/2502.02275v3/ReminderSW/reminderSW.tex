

\section{Reminders on the Sliced Wasserstein Distance} \label{sec:reminderSW}


%\subsection{Notations}


%{We write $\Sigma_N$ the set of permutations of $\llbracket 1,N\rrbracket$, and for $A$ an ensemble $|A|$ denotes its cardinal.}

%{For a prime integer $b$, $+_{\mathbb{Z}/b\mathbb{Z}}$ will denote the inner law of the group $\mathbb{Z}/b\mathbb{Z}$.}

\subsection{Definition}\label{sec:def}
{In the following, we write $\langle \cdot \ | \ \cdot \rangle$ the Euclidean inner product in $\Rd$, $\|\cdot\|$ the induced norm, $\Sd = \{ x\in \Rd \ |\ \|x\| = 1\}$ the unit
sphere of $\R^d$.}
{For $\theta\in\Sd$, we write $\pit:\Rd
\rightarrow \R$ the map $x \mapsto \langle \theta|x \rangle$,
$\sd$ the uniform measure over $\Sd$. %and $\mathcal{U}(\Sd)$ the uniform distribution of $\Sd$. 
We also denote $\#$ the push-forward
operation}~\footnote{The push-forward of a measure  $\mu$ on $\R^d$ by
  an application $T: \R^d \rightarrow \R^k$ is defined as a measure
  $T\#\mu$ on $\R^k$ such that for all Borel sets $B \in
  \mathcal{B}(\R^k), T\#\mu(B) = \mu(T^{-1}(B))$.}.

For two probability measures $\mu$ and
$\nu$ supported in $\R^d$ {and with finite moments of order 2}, the Sliced Wasserstein
Distance between  $\mu$ and
$\nu$ is defined as
\begin{equation} \label{eq:SW}
\SW(\mu,\nu)= \mathbb{E}_{\theta \sim \mathcal{U}(\Sd)}[\W(\pmu, \pnu)] = \displaystyle\int_{\Sd}\W(\pmu, \pnu) d\sd(\theta).
\end{equation}

This distance, introduced
in~\citep{Rabin_texture_mixing_sw},  has been thoroughly studied and
used as a dissimilarity measure between probability distributions in machine
learning~\citep{bonneel2015sliced,nadjahi2021sliced,kolouri2018slicedAE},
and more generally as an alternative to the Wasserstein distance. % leveraging the simplicity of computing such distances in one dimension.
Its simplicity stems from the fact that the
Wasserstein distance between two probability measures in one dimension has
an explicit formula. Indeed, for two probability
measures $\rho_1$ and $\rho_2 $ on the line, the Wasserstein distance   $W_2(\rho_1,\rho_2)$ can be written
\begin{equation}
\label{eq:transport_ligne}
 W_2^2(\rho_1,\rho_2) =  \int_0^1 |F_1^{-1}(t)- F_2^{-1}(t)|^2dt,
\end{equation}
where  $F_1$ and $F_2$ are the cumulative distribution
functions of $\rho_1$ and $\rho_2 $, and $F_1^{-1}$ and $F_2^{-1}$ are
their respective
generalized inverses (see~\citep{santambrogio2015optimal} Proposition
2.17).  For two one dimensional discrete measures $\rho_1 =
\frac{1}{N}\sum\limits_{k=1}^N \delta_{x_k}$ and  $\rho_2 =
\frac{1}{N}\sum\limits_{k=1}^N \delta_{y_k}$, this distance becomes
\begin{equation}\label{eq:transport_ligne_2D_disc}
W_2^2(\rho_1,\rho_2) = \frac 1 N \sum_{k=1}^N |x_{\sigma(k)} -
y_{\tau(k)}|^2,
\end{equation}
where $\sigma$ and $\tau$ are permutations of
$\llbracket 1,N\rrbracket$ which respectively order the sets $ \{x_1,\dots,x_N\}$ and
$\{y_1,\dots,y_N\}$ on the line. 
\begin{figure}[!h]  
\begin{subfigure}{\textwidth}
\begin{center}
 \begin{tikzpicture}
    \begin{scope}[xscale = 1.5, yscale = 1.5, >=stealth]
 \draw[->] (0, -.5) -- (0, 3) node [left] {}; %
      \draw[->] (-.5, 0) -- (4, 0) node [above] {} ; %
\draw[darkyellow] (.25,1.5) node {$\bullet$} ;
\draw[darkyellow] (1,.1) node {$\bullet$} ;
\draw[darkyellow] (1.25,1.5) node {$\bullet$} ;
\draw[darkyellow] (2,3.5) node {$\bullet$} ;
\draw[darkyellow] (2.25,.5) node {$\bullet$} ;
\draw[blue] (4,1) node {$\bullet$} ;
\draw[blue] (.5,.1) node {$\bullet$} ;
\draw[blue] (1.25,3.5) node {$\bullet$} ;
\draw[blue] (2.5,1.5) node {$\bullet$} ;
\draw[blue] (0.83, 1.06) node {$\bullet$} ;
 \end{scope}
  \end{tikzpicture}
 \begin{tikzpicture}
    \begin{scope}[xscale = 1.5, yscale = 1.5, >=stealth]
 \draw[->] (0, -.5) -- (0, 3) node [left] {}; %
      \draw[->] (-.5, 0) -- (4, 0) node [above] {} ; %
 \draw[-] (0, 0) -- (3.6, 2.7) node [right] {$\theta$} ; %
\draw[densely dotted] (.25, 1.5) -- (.88,.66 ) node [right] {} ;
\draw[darkyellow] (.88,.66) node {$\circ$} ;
\draw[darkyellow] (.25,1.5) node {$\bullet$} ;
\draw[densely dotted] (1, .1) -- (.688,.516 ) node [right] {} ;
\draw[darkyellow] (.688,.516 ) node {$\circ$} ;
\draw[darkyellow] (1,.1) node {$\bullet$} ;
\draw[densely dotted] (1.25, 1.5) -- (1.52,1.14 ) node [right] {} ;
\draw[darkyellow] (1.52,1.14 ) node {$\circ$} ;
\draw[darkyellow] (1.25,1.5) node {$\bullet$} ;
\draw[densely dotted] (2,3.5 ) -- (2.96,2.22) node [right] {} ;
\draw[darkyellow] (2.96,2.22 ) node {$\circ$} ;
\draw[darkyellow] (2,3.5) node {$\bullet$} ;
\draw[densely dotted] (2.25,.5) -- (1.68,1.26 ) node [right] {} ;
\draw[darkyellow] (1.68, 1.26) node {$\circ$} ;
\draw[darkyellow] (2.25,.5) node {$\bullet$} ;
\draw[densely dotted] (4, 1) -- (3.04,2.28) node [right] {} ;
\draw[blue] (3.04,2.28) node {$\circ$} ;
\draw[blue] (4,1) node {$\bullet$} ;
\draw[densely dotted] (.5, .1) -- (.368,.276) node [right] {} ;
\draw[blue] (.368,.276) node {$\circ$} ;
\draw[blue] (.5,.1) node {$\bullet$} ;
\draw[densely dotted] (1.25, 3.5) -- (2.48,1.86 ) node [right] {} ;
\draw[blue] (2.48,1.86) node {$\circ$} ;
\draw[blue] (1.25,3.5) node {$\bullet$} ;
\draw[densely dotted] (2.5,1.5) -- (2.32,1.74) node [right] {} ;
\draw[blue] (2.32,1.74) node {$\circ$} ;
\draw[blue] (2.5,1.5) node {$\bullet$} ;
\draw[densely dotted] (0.83, 1.06) -- (1.04,0.78) node [right] {} ;
\draw[blue] ( 1.04,0.78) node {$\circ$} ;
\draw[blue] (0.83, 1.06) node {$\bullet$} ;

\draw[->, thick, color=customgreen] (.88,.66) to[out=0, in=260] (1.04,0.78); % first pair
\draw[->, thick, color=customgreen] (.688,.516) to[out=0, in=260] (.368,.276); % second pair
\draw[->, thick, color=customgreen] (1.52,1.14) to[out=0, in=260] (2.32,1.74); % third pair
\draw[->, thick, color=customgreen] (1.68,1.26) to[out=0, in=260] (2.48,1.86); % fourth pair
\draw[->, thick, color=customgreen] (2.96,2.22) to[out=0, in=260] (3.04,2.28); % fifth pair
 \end{scope}
  \end{tikzpicture}
\caption{On the left, {we can see} the two discrete distributions $\mu$ 
{(blue points)} and $\nu$ {(yellow points)}. On the right, 
{we have} their projections $\pmu$ {(blue circles)} and $\pnu$ 
{(yellow circles)}
along the direction $\theta$. One then takes the increasing ordering of $\pmu$ 
and $\pnu$, 
{to obtain}
% obtains
the corresponding matchings {(green arrows)} and computes the cost 
% as in 
{following}
\autoref{eq:transport_ligne_2D_disc}.}
\label{fig:projection}
\end{center}
\end{subfigure}
\newline
\begin{subfigure}{\textwidth}
\begin{center}
\includegraphics[scale=0.335]{ReminderSW/Illust1DW.png}
\includegraphics[scale=0.3615]{ReminderSW/1DPlot1DW.png}
\caption{On the left, we have a plot of $\theta \mapsto \W(\pit \# \mu, \pit \# 
\nu)$ in polar coordinates, 
with 
{the distributions}
$\mu$ and $\nu$ 
% in \autoref{fig:projection}. 
{from \autoref{fig:projection} (top).}
The grey lines represent the 
angles where $\theta \mapsto \W(\pit \# \mu, \pit \# \nu)$ is not 
differentiable, the magenta line is the line of angle $\theta = \frac{\pi}{3}$ 
and the blue dot is a specific value of $\W(\pit \# \mu, \pit \# \nu)$ with the 
same angle. On the right, we have a $1D$ plot of $\theta \mapsto \W(\pit \# \mu, 
\pit \# \nu)$, here the hashed area represents $\SW(\mu,\nu)$ and again the 
vertical grey lines represent the values where $\theta \mapsto \W(\pit \# \mu, 
\pit \# \nu)$ is not differentiable. }
\label{fig:SW}
\end{center}
\end{subfigure}
\label{fig:proj&SW}
\caption{On the first row, \autoref{fig:projection} illustrates the 
% principle 
{computation}
of $\W(\pit \# \mu, \pit \# \nu)$ for a fixed $\theta$. On the second 
row, \autoref{fig:SW} gives a geometrical illustration of $\SW(\mu,\nu)$ with 
$\mu,\nu$ taken as in \autoref{fig:projection}.}
\label{fig:overallSWcomputation}
\end{figure}

% is easy in practice: the optimal transport
% solution is given by the monotone rearrangement of $\mu$ onto $\nu$.  
% This rearrangement maintains the ordering of points on the line. For
% discrete measures of $N$ points, it can be obtained in $O(N\log(N))$
% operations.  Writing $F_1$ and $F_2$ the cumulative distribution
% functions of $\rho_1$ and $\rho_2 $,

As a consequence, the Sliced Wasserstein distance between two discrete
probability measures $\mu =
\frac{1}{N}\sum\limits_{k=1}^N \delta_{x_k}$ and  $\nu =
\frac{1}{N}\sum\limits_{k=1}^N \delta_{y_k}$ on $\Rd$ (i.e. with
$(x_k)_{k=1,\hdots,N},(y_k)_{k=1,\hdots,N} \in \Rd$) can be rewritten{:} 
\begin{equation} \label{eq:SW_discrete}
\SW(\mu,\nu)= \frac{1}{N}\sum\limits_{k=1}^N\displaystyle\int_{\Sd}
(\langle x_{\sigma_{\theta}(k)} - y_{\tau_{\theta}(k)},\theta\rangle)^2
d\sd(\theta) = \frac{1}{N}\sum\limits_{k=1}^N\displaystyle\int_{\Sd}
(\langle x_{k} - y_{\tau_{\theta} \circ \sigma_{\theta}^{-1}(k)},\theta\rangle)^2
d\sd(\theta)  ,
\end{equation}
where
$\sigma_{\theta}$ and $\tau_{\theta}$ denotes respectively 
permutations which order the one dimensional  point sets $(\langle x_k,\theta\rangle)_{k=1,\hdots,N}$
and $(\langle y_k,\theta\rangle)_{k=1,\hdots,N}$. 
% \autoref{fig:projection}
{\autoref{fig:overallSWcomputation}}
illustrates the
computation of $\W(\pmu, \pnu)$ for two discrete measures in two dimensions 
{(\autoref{fig:projection})}, and 
% show
{shows}
how this quantity varies when $\theta$ spans $[0,2\pi]$ 
{(\autoref{fig:SW})}.

\noindent Since the permutations $\sigma_{\theta}$ and $\tau_{\theta}$
depends on the direction $\theta$, 
the 
{integrals}
in \autoref{eq:SW} and \autoref{eq:SW_discrete}
do not have closed forms. For this reason, practitioners rely on Monte
Carlo approximations of the form{:}
\begin{equation}
  \label{eq:SW_MC}
 \frac{1}{NM}\sum\limits_{k=1}^N \sum\limits_{j=1}^M\displaystyle
(\langle x_{\sigma_{\theta_j}(k)} - y_{\tau_{\theta_j}(k)},\theta_j\rangle)^2,
\end{equation}
where $\theta_1,\dots,\theta_M$ are i.i.d. and follow a uniform
distribution on the sphere.
 Classically, the convergence rate of such Monte Carlo estimations to
 SW is  $\mathcal{O}(\frac 1 {\sqrt{M}})$ ~{\citep{hammersley1964monte}}.
 In this context, it is natural to question the optimality of sampling
 methods to approximate SW efficiently in different scenarios.

\subsection{Regularity results on $\theta \mapsto \W(\pit \# \mu, \pit \# \nu)$} \label{sec:regularityProp}
The efficiency of sampling strategies used in numerical integration is
highly dependent on the regularity of the functions to be
integrated. For this reason, in the following we give some properties
of the function {(\autoref{fig:SW}):}
\begin{equation}
f: \theta\mapsto \W(\pit \# \mu, \pit \# \nu)\label{eq:f}
\end{equation}
on the
hypersphere $\Sd$. 
{We  first look at classical regularity properties of $f$}.

\begin{Prop}
{$f$ is Lipschitz on $\Sd$. 
}
\end{Prop}
\begin{proof}
{
Let $\mu$ and $\nu$ be two probability measures  with finite moments of order 2, and $\theta_1,\theta_2\in\Sd$. The triangular inequality on $W_2$ yields
$$\left| W_2(\pi_{\theta_1}\# \mu, \pi_{\theta_1}\# \nu) - W_2(\pi_{\theta_2}\# \mu, \pi_{\theta_2}\# \nu)\right| \leq W_2(\pi_{\theta_1}\# \mu,\pi_{\theta_2}\# \mu) +  W_2(\pi_{\theta_1}\# \nu,\pi_{\theta_2}\# \nu).$$
We also have
\begin{equation*}
W_2^2(\pi_{\theta_1}\# \mu,\pi_{\theta_2}\# \mu)  =  {\inf_{X\sim\mu, Y\sim\mu}\mathbb{E}\left[| \langle \theta_1 , X \rangle - \langle \theta_2, Y \rangle |^2\right]}
 \leq {\inf_{X\sim\mu}\mathbb{E}\left[|\langle \theta_1 - \theta_2, X\rangle |^2\right]}\\
 \leq \|\theta_1 - \theta_2\|^2 {\mathbb{E}_{X\sim\mu}[\|X\|^2]}.
\end{equation*}
We can show similarly that $W_2^2(\pi_{\theta_1}\# \nu,\pi_{\theta_2}\# \nu)\leq \|\theta_1 - \theta_2\|^2 {\mathbb{E}_{X\sim\nu}[\|X\|^2]}$. Thus 
$$\left| W_2(\pi_{\theta_1}\# \mu, \pi_{\theta_1}\# \nu) - W_2(\pi_{\theta_2}\# \mu, \pi_{\theta_2}\# \nu)\right| \leq \|\theta_1 - \theta_2\| \left( \sqrt{\mathbb{E}_{X\sim\mu}[\|X\|^2]}+\sqrt{\mathbb{E}_{X\sim\nu}[\|X\|^2]}\right).$$}
\end{proof}
{Since $f$ is Lipschitz continuous, it is  differentiable almost everywhere.
However the previous result does not give us the set where $f$ is non differentiable. In the following we give a more complete proof when $\mu$ and $\nu$ are discrete following the notations introduced in \autoref{sec:def}.}

\begin{Prop}
When $\mu$ and $\nu$ are finite discrete measures, $f$ piecewise $\mathcal{C}^{\infty}$
($\mathcal{C}_{pw}^{\infty}$) and Lipschitz on $\Sd$. 
 \end{Prop}
\begin{proof}
For discrete measures  $\mu =
\frac{1}{N}\sum\limits_{k=1}^N \delta_{x_k}$ and  $\nu =
\frac{1}{N}\sum\limits_{k=1}^N \delta_{y_k}$ on $\Rd$, $f$ can be
  rewritten as 
  \begin{equation}
f(\theta) = \min_{\sigma \in \Sigma_N} f_{\sigma}(\theta), \text{
    where } f_{\sigma}(\theta) = \sum_{k=1}^N \langle
  x_k-y_{\sigma(k)} | \theta \rangle ^2,\label{eq:f_as_min}
\end{equation}
where $\Sigma_N$ is the set of permutations of $\llbracket 1,N\rrbracket$.
We assume that the $\{x_i\}$ (resp. $\{y_j\}$) are all distinct. 
In the following, we study the regularity of $f$ as a function of
$\R^d$ and deduce the regularity properties of its restriction
$f_{|\Sd}$. 
Observe that each $f_{\sigma}$ defines a quadratic function on $\R^d$
and $f$, as a
minimum of a finite number of such functions, is continuous 
and also piecewise  $\mathcal{C}^{\infty}$ on $\R^d$. Since $f$ is
continuous on $\R^d$, its restriction to $\Sd$ is also continuous. To show that this restriction to $\Sd$ is also in
$\mathcal{C}_{pw}^{\infty}$, it is enough to observe that the set of
points of $\R^d$ where $f$ is not differentiable is included in the
finite union of hyperplanes
$\left(\cup_{i,j} \tspan(x_i - x_j)^{\perp} \right)\bigcup \left(\cup_{k,l}\tspan(y_k -
y_l)^{\perp}\right)$, since these {hyperplanes} are the locations where the
minimum in~\autoref{eq:f_as_min} jumps from a permutation $\sigma$ to
another one (see \autoref{fig:hyperplanes} as an illustration of those hyperplanes). Each of these
hyperplanes intersect $\Sd$ on a great circle, and we call $\mathcal{U}$ 
the sphere minus this finite union of great circles. The open set
$\mathcal{U}$ (which is dense in $\Sd$) can be written as the union $\bigcup_{k=1}^p V_k$ of a finite number of
connected open sets $V_l$, such that on each $V_l$, the permutation
$\sigma$ which attains the minimum in~\autoref{eq:f_as_min}  is
constant and unambiguous. We write this permutation $\sigma_l$. On
each $V_l$, $f_{|\Sd} = {f_{\sigma_l}}$, thus is  
$\mathcal{C}^{\infty}$ on $V_l$ and its derivative can be
obtained as the projection of  $\nabla f_{\sigma_l}$ on the
hypersphere. For $\theta \in \mathcal{U}$, writing $\sigma_{\theta}$
the permutation which attains the minimum in~\autoref{eq:f_as_min}  for
the direction
$\theta$, this derivative can be written
{\begin{equation}
  \nabla_{(d-1)} f (\theta) = 2 \left( \sum_{k = 1}^{N} \left( \langle x_{k} -
  y_{\sigma_\theta(k)} | \theta \rangle(x_{k} - y_{\sigma_\theta(k)} ) 
  -     \langle x_{k} -
  y_{\sigma_\theta(k)} | \theta \rangle ^2 \theta\right)\right).
  \label{eq:fderivative}
\end{equation}}
Since these derivatives are upper bounded on the compact set $\Sd$, it
follows that $f$ is also Lipschitz on  $\Sd$.\\
In the case where several $x_i$ (or $y_j$)  are equal,
several of the functions $f_\sigma$ coincide.  For instance, if $x_1 =
x_2$, the values of $\sigma(1)$ and $\sigma(2)$ can be exchanged
without modifying $f_\sigma$. By eliminating all the redundant
functions, we can make the same reasoning as before to show the same
regularity results on $f$.  In this case, all the pairs $(x_i,x_j)$
with $x_i = x_j$ should be
removed when constructing the set of great circles dividing the hypersphere.
\end{proof}


\begin{figure}[!h]
\begin{center}
\includegraphics[scale=0.45]{ReminderSW/hyperplanesNew3.png}
\caption{Illustration of the open subsets $\bigcup_{k=1}^p V_k$ and their intersection with the hyperplanes  $\left(\cup_{i,j} \tspan(x_i - x_j)^{\perp} \right)\bigcup \left(\cup_{k,l}\tspan(y_k -
y_l)^{\perp}\right)$, in the specific case of two measures made of two diracs 
{$\mu = \displaystyle\frac{1}{2} \sum\limits_{i = 1}^2 \delta_{x_i}$ with $ 
x_1,x_2 = (1,0,0)^T, (0,-1,0)^T$ and $\nu = 
\displaystyle\frac{1}{2}\sum\limits_{i = 1}^2 \delta_{y_i} $ with $y_1,y_2 = 
(0,0,1)^T,(0,0,-1)^T$}. The hyperplanes divide the sphere into the colored 
sections where $\sigtheta$ and $\tautheta$ are constant. 
}
\label{fig:hyperplanes}
\end{center}
\end{figure}

\noindent The following proposition will also be useful in the next sections.
\begin{Prop} \label{prop:Sobol}
  $f \in H^{1}(\Sd)$, where, for $\alpha\in\N$, the Sobolev space $H^{\alpha}(\Sd)$ is defined as~\citep{Hebey1996} 
  \[H^{\alpha}(\Sd) = \{ h\in L^2(\Sd)\ |\ \partial^{|j|}h\in L^2(\Sd), 0 \leq |j| \leq \alpha\},\]
with $j$ a multi-index and $\partial^{|j|}$ the partial mixed derivative of order $|j|$ on $\Sd$.
  \end{Prop}
  \begin{proof}
  We have seen previously that $f$ is continuous and piecewise $\mathcal{C}^{\infty}$, piecewise quadratic to be more precise. Thus its weak derivative is piecewise linear with discontinuities on a finite union of hyperplanes, which is $L^2$.
  \end{proof}


