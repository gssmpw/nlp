\section{Related work}
Here we only list prior work most closely related to our method; we provide more references in \Cref{app:related-work}.
%The basic concept of prediction sets dates back to foundational works such as \citet{Wilks1941}, \citet{Wald1943}, \citet{scheffe1945non}, and \citet{tukey1947non,tukey1948nonparametric}.
The early ideas of conformal prediction were developed in \citet{saunders1999transduction,vovk1999machine}.
With the rise of machine learning, conformal prediction has emerged as a widely used framework for constructing prediction sets \citep[e.g.,][]{papadopoulos2002inductive,vovk2005algorithmic,Vovk2013}.
%,Chernozhukov2018,dunn2022distribution,lei2013distribution,lei2014distribution,lei2015conformal,lei2018distribution,angelopoulos2021gentle,guan2022prediction,guan2023localized,guan2023conformal,romano2020classification,bates2023testing,einbinder2022training,liang2022integrative,liang2023conformal,dobriban2023symmpi,lee2024batch}.
% A wide range of predictive inference methods have been developed  \citep[e.g.,][]{Sadinle2019,gibbs2021adaptive,park2021pac,park2022pac,sesia2022conformal,qiu2023prediction,li2022pac,kaur2022idecode,si2023pac}.
Classical conformal prediction guarantees validity when the calibration and test data are drawn from the same distribution. In contrast, when there is distribution shift between the calibration and test data \citep[e.g.,][]{quinonero2009dataset, shimodaira2000improving, Sugiyama2012, ben2010theory, taori2020measuring}, coverage may not hold.
%One common type of dataset shift is covariate shift, where only the distribution of input features changes while the conditional distribution of the outcome given the features remains unchanged.
Covariate shift is a type of dataset shift that arises in many settings, e.g., when predicting disease risk for individuals whose features may evolve over time, while the outcome distribution conditioned on the features remains stable \citep{quinonero2009dataset}. 
%Covariate shift is also observed in domains like image processing, where variations in color and lighting \citep{Hendrycks2019} or adversarial perturbations \citep{Szegedy2014} alter the input distribution without affecting the labels' conditional distribution.

Numerous works have addressed conformal prediction under various types of distribution shift 
\citep{tibshirani2019conformal,park2021pac,park2022pac,qiu2023prediction,si2023pac}. For example, \citet{tibshirani2019conformal} investigated conformal prediction under covariate shift, assuming the likelihood ratio between source and target covariates is known. 
\citet{Lei2021} allowed the likelihood ratio to be estimated, rather than assuming it is known.
\citet{park2021pac} developed prediction sets with a calibration-set conditional (PAC) property under covariate shift. 
\citet{qiu2023prediction,yang2024doubly} developed prediction sets with asymptotic coverage that are doubly robust in the sense that their coverage error is bounded by the product of the estimation errors of the quantile function of the score and the likelihood ratio.
\citet{cauchois2024robust} construct prediction sets based on a distributionally robust optimization approach.
% \citet{gui2024distributionally} develop methods based on an isotonic regression estimate of the likelihood ratio.
% \citet{qin2024distribution} combine a parametric working model with a resampling approach to construct prediction sets under covariate shift.
% \citet{bhattacharyya2024group} analyze weighted conformal prediction in the special case of covariate shifts defined by a finite number of groups.
% \citet{ai2024not} reweight samples to adapt to covariate shift, while simultaneously using distributionally robust optimization to protect against worst-case distribution shifts.
% \citet{kasa2024adapting} construct prediction sets by using unlabeled test data to modify the score function used for conformal prediction.

In contrast, our algorithm entirely avoids estimating the likelihood ratio function. Rather, it works by constructing a novel regularized regression objective, whose stationary conditions ensure coverage in the test domain.
We can minimize the objective by estimating certain expectations of the data distribution---which implicitly involve estimating only certain functionals of the likelihood ratio.
We further show that the coverage is retained in finite samples via a novel analysis of coverage leveraging stability bounds 
\cite{shalev2010learnability, shalev2014understanding}. We illustrate that our algorithms behave better in high-dimensional datasets than existing methods.

Aiming to achieve coverage under a predefined set of covariate shifts,
% Aiming to achieve conditional coverage over subgroups,
\citet{gibbs2023conformal} develop an approach based on minimizing the quantile loss over a linear function class.
% over a class of covariate shifts corresponding to the subgroups. 
We build on their approach, but develop a novel regularization scheme that 
%plays several crucial roles:
%(1) it 
allows us to 
effectively optimize over a data-driven class,
adaptive to the unknown shift $r$.
% to estimate the two ``nuisance parameters", i.e., the likelihood ratio and the conditional quantile function of the non-conformity score given the features.
%and (2) address mis-specification 
% \vspace{-0.3cm}