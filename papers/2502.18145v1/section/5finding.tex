\section{Findings}\label{finding}
In this section, We demonstrate our findings organized by specific goals~(Why). 
We aim to reveal the most common human-AI interaction patterns as a focal area of study. 
Furthermore, certain patterns remain under-investigated in previous research, raising questions about their entailment and potential future applications.

\subsection{Goal 1: Initialize the Simulation}

Initializing the environment is the most frequently occurring goal in our reviewed literature.
Due to the large number of papers in this category, detailed information can be found in Appendix~\ref{Ainitial}, Table~\ref{tab:initial}.
Firstly, we observe that users interact with the models before the simulation and primarily assume three roles: scriptwriter, director, and prototype.
As scriptwriters, users need to establish a foundational background for the simulation.
Users create agents by defining their identity~\cite{hua2024warpeacewaragentlarge,lin2023agentsimsopensourcesandboxlarge}, interaction~\cite{berryman2008review}, long-term goal~\cite{hong2024metagptmetaprogrammingmultiagent}, and learning ability~\cite{li2023modelscopeagentbuildingcustomizableagent}.
Similarly, users can control the description~\cite{jinxin2023cgmiconfigurablegeneralmultiagent}, objects~\cite{basavatia2023complexworld}, and rules~\cite{10.1145/3526113.3545616} of environments.
Although some studies have utilized natural language command~\cite{hong2024metagptmetaprogrammingmultiagent} and interfaces~\cite{lin2023agentsimsopensourcesandboxlarge}, we find that a portion of the work requires users to engage in configuration settings, such as programming~\cite{netlogo}, graphical programming~\cite{Ped,doi:https://doi.org/10.1002/9781118762745.ch12}, importing packages~\cite{Significant_Gravitas_AutoGPT}, or writing configuration files~\cite{lin2023agentsimsopensourcesandboxlarge}.
Unlike interfaces and natural language commands, these methods present certain challenges for novice users when getting started.
However, they allow for a systematic, modular, and efficient setup of simulations from scratch.
How to combine the advantages of both aspects is a question worth exploring.

Another important role for the user is the director.
The director can directly issue goal commands to the model, prompting agents to begin executing the goals~\cite{rana2023sayplangroundinglargelanguage, ahn2022icanisay} or automatically trigger agents' actions through specific user actions~\cite{10.1145/3613904.3642183, arakawa2024prismobserverinterventionagenthelp}.
Additionally, the director can modify certain environmental settings during the initialization time~\cite{park2023choicematessupportingunfamiliaronline, 10.1145/3613904.3642159}.
The most commonly used means is natural language commands~\cite{10.1145/3678585}, followed by interface~\cite{pan2024agentcoordvisuallyexploringcoordination}.
Compared to the scriptwriter, the director controls the model from a more granular perspective.
Researchers can design appropriate interactions tailored to their specific research needs.
In some cases, users also appear in the role of prototypes and provide demographic data for agent identities.
Before the advancement of computational power, it was common to use sampling methods to select prototypes, and the information dimensions provided to the model were limited~\cite{GAUBE201392}.
Currently, sampling from the dataset is not necessary since the model can handle diverse, heterogeneous data directly~\cite{gao2023s3socialnetworksimulationlarge} with enhanced data processing abilities.

In this category, we can observe the evolution of simulation platforms or toolkits.
Before the maturity of NLP technologies, many works already supported users in initializing simulations.
However, these interactions were not as straightforward as natural language and involved a certain learning curve.
Initially, tools were difficult to use and challenging to learn, such as Netlogo~\cite{netlogo}, EINSTein~\cite{berryman2008review}, and MASON~\cite{doi:10.1177/0037549705058073}, which are required programming skills.
Later, tools like AnyLogic~\cite{doi:https://doi.org/10.1002/9781118762745.ch12} and PedSim~\cite{Ped} emerged, supporting graphical programming and visualizing simulation trajectories, making them more accessible and user-friendly.
With the emergence of large language models, diverse and lightweight simulation platforms have been developed~(\eg AutoGPT~\cite{Significant_Gravitas_AutoGPT} and Modelscope~\cite{li2023modelscopeagentbuildingcustomizableagent}), leveraging the interaction and generative capabilities of these models to support user-customized agents.
This advancement allows users to create tailored agent behaviors and scenarios more intuitively, expanding the flexibility and accessibility of simulation platforms.
We will further discuss the potential development of simulation platforms in Section~\ref{software}. 


\subsection{Goal 2: Explore Different Scenarios}
Investigating various hypothetical scenarios enables users to examine how different assumptions or interventions might influence system dynamics.
The detailed information in this cluster is shown in Table~\ref{tab:explore}.
ChatEval~\cite{chan2023chatevalbetterllmbasedevaluators} supports multi-agent collaboration to compare only two language models' performance at once.
Thus, users need to predefine various models and conduct multiple simulations to compare the comparison results across different models.
The interactions in the remaining works occur during the simulation.

Users act directly as actors, exploring various scenarios through their own diverse behaviors, such as communicating with agents through natural language~\cite{10.1145/3586183.3606763,lin2023agentsimsopensourcesandboxlarge}.
Users can also take on the scriptwriter role, directly altering agents' foundational goals by natural language commands~\cite{10.1145/3586183.3606763}.
This type of work is relatively rare, possibly because users typically focus on exploring the impact of minor changes on the overall system rather than fundamentally altering the foundational setup of agents and the environment within the simulation.
In most cases, users act as directors, controlling the simulation process~\cite{wang2023humanoidagentsplatformsimulating, pan2024agentcoordvisuallyexploringcoordination}, adjusting environmental components~\cite{hua2024warpeacewaragentlarge}, and directing the actions of agents~\cite{DBLP:journals/corr/abs-2312-11813,10.1145/3613904.3642545}, etc.
Typically, by advancing or reversing the simulation progress, users can conduct ``what-if'' analysis~\cite{cui2024chatlawmultiagentcollaborativelegal,10.1145/3526113.3545616}.
``What-if'' analysis is crucial for ABMS, as it enables users to explore the potential effects of various changes within the system.
Users can observe how hypothetical scenarios impact agent behaviors and system dynamics by manipulating specific parameters or altering conditions. 

Current research on this topic is limited based on our review, highlighting a valuable opportunity for future researchers to explore ``what-if'' analysis in human-AI interactions in ABMS.
Such research could facilitate dynamic, in-depth analysis of ABMS and support decision-making processes, advancing the practical utility and impact of ABMS in complex scenarios.
Furthermore, the advent of LLMs enables users to explore different scenarios within the model using natural language and interface.
Designing a user-friendly, voice-enabled interactive interface that allows users to act as a real-world director, complete with a walkie-talkie and monitor screens, may hold significant potential as a research topic.
Users can also take on the role of actors, directly interacting with agents through natural language or physical movement with the advancement of immersive devices. 
They can modify or create diverse scenarios based on research needs.

\input{table/2explore}

\subsection{Goal 3: Refine the Model}
When the model’s performance fails to meet expectations, improving its effectiveness requires user intervention.
There are 29 papers in this cluster, and the detailed information of papers is shown in Appendix~\ref{Arefine}, Table~\ref{tab:refine}.
Before the simulation, SocialAI School~\cite{gao2023s3socialnetworksimulationlarge}, Krishna\etal~\cite{doi:10.1073/pnas.2115730119} and Surrealdriver~\cite{jin2024surrealdriverdesigningllmpoweredgenerative} guide agents to learn from external resources, such as human natural language instructions and domain expertise data, to enhance their learning ability.
Although there is limited work in this area, it presents a promising approach to refine the model, and new interactions warrant further research.
The majority of methods are implemented during the simulation process.
Some of them also focus on agents' learning abilities.
Users can teach agent human knowledge and domain expertise~\cite{unknown, 10.1145/3613904.3642349, cui2024chatlawmultiagentcollaborativelegal} and directly manipulate memory system~\cite{10.1145/3586182.3615796}.

Some work allows users to directly take on the role of actors, collaborating with agents to complete tasks by natural language~\cite{zhang2024buildingcooperativeembodiedagents} or physical movements~\cite{mandi2023rocodialecticmultirobotcollaboration}.
More frequently, users assume the role of directors, steering agent actions~\cite{mehta2024improvinggroundedlanguageunderstanding, mohanty2023transforminghumancenteredaicollaboration, Padmakumar_Thomason_Shrivastava_Lange_Narayan-Chen_Gella_Piramuthu_Tur_Hakkani-Tur_2022}, goals~\cite{huang2022innermonologueembodiedreasoning,chen2023agentversefacilitatingmultiagentcollaboration}, and interaction~\cite{park2023choicematessupportingunfamiliaronline}.
Additionally, due to the stochastic nature of LLMs, users acting as directors can control the simulation progress through the interface by regenerating outcomes if the current results are unsatisfactory, allowing for the possibility of achieving more desirable outcomes~\cite{chen2023agentversefacilitatingmultiagentcollaboration,chan2023chatevalbetterllmbasedevaluators}.
This cluster appears to overlook the impact of environmental components on refining the model.
Users can potentially reduce obstacles for agents in completing tasks by controlling environmental components.
In addition to agents' learning abilities, users may consider enhancing agents' autonomy—an often-overlooked component in interaction design.


The design of human-AI interactions that harness the strengths of both humans and AI, enabling complementary collaboration, represents a significant area for exploration. 
This approach raises important questions about how best to structure interactions to optimize collaboration and achieve desired outcomes.
From our corpus of papers, we conclude that humans excel in creative thinking, domain expertise, and problem-solving in ambiguous situations, making them adept at tasks requiring abstract thought or out-of-the-box solutions~\cite{ren2023robotsaskhelpuncertainty, 10.1145/2282338.2282384}.
AI operates with consistent accuracy and efficiency, reducing the risk of human error and performing repetitive tasks without fatigue~\cite{10.1145/3672539.3686351}.
Combining these strengths, human-AI interaction has the potential to achieve more comprehensive outcomes, with humans providing complex reasoning abilities and AI enhancing efficiency and scalability.


\subsection{Goal 4: Evaluation the Performance}
Evaluating the ABMS's performance relies on assessing how well the simulation meets predefined goals. Human involvement is central to this process.
In this cluster, we extracted 47 interactions from 41 works.
Due to the large number of papers in this category, detailed information can be found in Appendix~\ref{Aevaluate}, Table~\ref{tab:evaluate}.
For users pre-simulation engaging with the model, the objective is to manipulate specific conditions to assess whether the outcomes align with their expectations.
For example, users can copy community rules and goals from real-world social platforms to the environment of ABMS~\cite{10.1145/3526113.3545616} or design agents' identity modeled on real-world demographic information~\cite{10.1145/3394486.3412862, Argyle_Busby_Fulda_Gubler_Rytting_Wingate_2023}.
Assessing the indistinguishability between agent actions and real user actions provides a measure of the reliability of ABMS simulation results.

Users primarily assume three roles during the simulation: director, actor, and observer.
The director assesses whether agents can adapt flexibly and effectively to the environment by assigning different goals to agents~\cite{10.1145/3643505} or intervening in agent actions~\cite{10.1145/3610170, 10.1145/3613905.3651026}.
The actor role is similar to the director, but they interact directly with agents within the environment, which allows for real-time engagement and firsthand observation of agent actions.
They test the agents' abilities in collaboration~\cite{zhang2024buildingcooperativeembodiedagents}, social interaction~\cite{zhou2024sotopiainteractiveevaluationsocial}, teaching~\cite{saha2023languagemodelsteachweaker}, and strategic gameplay~\cite{NEURIPS2021_86e8f7ab,10.1145/3613905.3650853}.
The observer evaluates agents by tracking their behaviors through graphical interfaces~\cite{park2023choicematessupportingunfamiliaronline,lin2023agentsimsopensourcesandboxlarge,wang2023humanoidagentsplatformsimulating} or log data~\cite{babyagi}, allowing for a detailed assessment of agent actions.

After the simulation, the majority of users, acting as observers, evaluate model performance primarily through analyzing agent action data.
They assess whether the agents perform effectively~\cite{hua2024warpeacewaragentlarge,park2023choicematessupportingunfamiliaronline} or exhibit noticeable differences from real human behaviors~\cite{10.1145/3544548.3580688,10.1145/3526113.3545616,https://doi.org/10.1111/mila.12466}.
MetaGPT~\cite{hong2024metagptmetaprogrammingmultiagent} and BactoWars~\cite{berryman2008review} provide users with interactive interfaces and videos to showcase agent performances.
Notably, Generative Agents~\cite{10.1145/3586183.3606763} proposed a unique evaluation method, interviewing agents as an actor ``reporter''.
After ``two-day'' simulated lives, by designing targeted questions, users can assess whether the agent has self-awareness of its identity, accurate memory, and action aligned with its assigned character traits.
Previous studies have largely overlooked agents' internal states. 
Future research could benefit from emphasizing the alignment between agents' internal states and outward behaviors.

LLM-powered agents are capable of simulating various human-like behaviors and reflecting different characteristics.
The coherence and consistency of LLMs' outputs make agents' behaviors more realistic and believable.
When assessing the believability of simulated behaviors, simplistic quantitative statistical methods are often inadequate. 
In these instances, human qualitative evaluations, such as the Turing test~\cite{Turing2009}, are frequently employed in research to provide more nuanced insights.
It suggests that the advent of LLMs not only introduces new interactions for users in ABMS, but also creates additional interaction requirements.
Designing reliable user experiments to evaluate agent-human resemblance presents several challenges.
Key issues include minimizing user subjectivity to prevent it from skewing evaluation results and determining whether agent behavior alone can reliably indicate human likeness.
Another complexity is interpreting agents' unusual or seemingly illogical actions; while such behaviors might suggest limitations in the agent's mimicry ability, human behavior itself often includes an element of randomness.



\subsection{Goal 5: Analyze Simulation Data}
Analyzing data generated from the ABMS process is a key goal for users.
The datasets involve logs of agents' actions, records of agents' internal state, formation and evolution of networks among agents, spatial and temporal data, etc.
By analyzing the data, users gain insights into system dynamics to support the decision-making process ultimately.
The detailed information about the literature is shown in Table~\ref{tab:analyze}.
Users all act as observers to analyze agents' actions through the interface.
In contrast to assessing the model itself, users analyze data to derive insights for downstream tasks, such as informing real-world decision-making or enhancing predictive capabilities.
Out of the ten works, six are early-developed simulation platforms or toolkits. 
This type of more mature toolkit typically provides users with data analysis modules.
EINSTein, MANA~\cite{berryman2008review}, and Swarm~\cite{minar1996swarm} display basic statistical metrics and visualization, such as tallies of agents detected and killed in battlefield and a time series graph of population dynamics.
Humanoid Agents~\cite{wang2023humanoidagentsplatformsimulating} and AnyLogic~\cite{doi:https://doi.org/10.1002/9781118762745.ch12} both provide a dashboard for users to explore agents' actions over time interactively.
Furthermore, AgentLens~\cite{10520238} and AgentCoord~\cite{cui2024chatlawmultiagentcollaborativelegal} proposed more intricate visual analytics systems to support users interactively investigating details and causes of agents' actions and multi-agent interaction strategy.
We find that the data has evolved from simple statistical metrics to complex, multi-dimensional, heterogeneous forms, such as agent emotions, diverse actions and locations, and dynamic social networks.


The integration of LLMs significantly enhances the richness and complexity of simulation data, which introduces challenges in managing, processing, and interpreting the increased intricacy of the data.
Correspondingly, the evolution of analytical tools, from basic statistical charts to dashboards and then to fully integrated visual analytics systems, reveals an increase in both their analytical capabilities and level of interactivity.
They support more nuanced insights, facilitate decision-making, and allow users to engage with complex data landscapes in a more intuitive, interactive manner.
The development of effective and efficient tools suited for analyzing ABMS data holds substantial potential research value.
For example, integrating machine learning models for data regression or classification could be considered, as well as incorporating NLP techniques to allow users to control the analysis process through natural language commands.
Regarding the \textit{When} dimension, we discover that only a limited number of works support real-time data analysis by users~(during-simulation).
Currently, real-time data analysis is challenging to implement, especially for ABMS developed with LLMs, as they can lead to unstable data generation and low processing efficiency.
Developing stable, real-time, and user-friendly analytical tools requires further investigation.

\input{table/5analyze}

\subsection{Goal 6: Be Immersed in the Environment}\label{immersed}

Immersion in the environment highlights the user’s experience within the simulation, primarily emphasizing engagement rather than control or modification.
The number of papers in this category is relatively small compared to other categories.
According to Table~\ref{tab:immerse}, there are only two papers in the category: Generative Agents~\cite{10.1145/3586183.3606763} and Alympics~\cite{mao2024alympicsllmagentsmeet}.
In both works, users can play as actors and interact with agents as if they were one of them during the simulation in the environment.
In Generative Agents, users can communicate with agents as ``mayor'' or ``reporter'' and change the status of surrounding objects.
In Alympics, human players are engaged in the game with agent players.
The user does not have a predetermined goal but seeks immersion and emotional value in the interaction process in both cases.
Due to the limited work in this area, many interactions remain to be developed.
Users can take on the role of scriptwriter or director,  granting them the ability to control the model from a ``god’s-eye view'' and effectively orchestrate the entire simulation.
This high-level perspective fosters a strong sense of engagement and immersion as users can actively influence the model's narrative and dynamics.
Besides, immersive experience in the virtual reality environment constitutes a significant and valuable area of research.
Users can interact with agents through physical movements and natural language, creating a more intuitive engagement.
We provide a further discussion on immersive experience in Sections~\ref{immersive}.

\input{table/6immerse}

\subsection{Application of the Taxonomy}
Our taxonomy and findings can be used in designing human-AI interactions in ABMS that support users' customized implementation to meet research needs.
First, identify the primary goal for interaction~(\textit{Why}). 
We have summarized six goals in~\Cref{goal} that require human involvement to achieve.
Designers determine interaction goals based on our framework to address the practical needs of different research tasks.
According to the goal, designers can find existing interactions in~\Cref{finding}, including the other four dimensions~(\textit{When}, \textit{What}, \textit{Who}, and \textit{How}).
Designers can select the most appropriate interaction from the patterns or be inspired by the potential interactions we have summarized.
Designers must comprehensively consider many aspects to determine the four dimensions, including further refining interaction goals, the feasibility of technical implementation, and other relevant factors.