
\section{Discussion}
In this section, we discuss some lessons learned during our work. 
We first introduce the trust issue and ethical problem arising from human-AI interactions.
We further discuss the future relationship between humans and AI.
It is hoped that this will stimulate further reflection among researchers.

\subsection{Trust Issue}
While LLMs offer many conveniences for interaction methods, they also introduce potential risks, such as the issue of ``hallucinations''~\cite{yao2024llmlieshallucinationsbugs}. %总结幻觉类型，哪个环节出现问题
This phenomenon occurs when the model generates inaccurate or misleading information with high confidence. It can undermine the reliability of ABMS outcomes, especially in critical applications.
Inspired by the algorithmic fidelity criteria proposed by Argyle\etal~\cite{Argyle_Busby_Fulda_Gubler_Rytting_Wingate_2023}, we have concluded three kinds of ``hallucinations'' in ABMS: 1)  generated outputs are distinguishable from parallel humans; 2) generated outputs are inconsistent with the predefined demographic information of agents; 3) generated outputs proceed unnaturally from the form, tone, and content of the context provided.
As a result, humans may experience trust issues with AI-generated outputs, which could pose risks for subsequent applications.
Therefore, exploring how human-AI interactions can mitigate the impact of hallucinations generated by LLMs can also be an important area of research.
For example, designing interactive mechanisms that allow users to verify, correct, or override misleading responses in real time could enhance the reliability of LLMs. 
Additionally, integrating feedback loops where users can flag inconsistencies or request clarifications may help manage and reduce the influence of hallucinations in critical ABMS applications.
On the other hand, designing appropriate mechanisms for LLMs to display their reasoning process transparently can enhance human trust.
Users can better grasp how conclusions are drawn and how outputs are generated. 
This transparency can help mitigate skepticism and uncertainty, allowing users to assess the model's logic and reliability more effectively.

\subsection{Ethical Problem}
Ethical problems arising from human-AI interactions in ABMS are a significant concern. 
Identifying ethical issues and exploring solutions is crucial in the field of HCI.
We provide two examples for reference as follows.
First, some ABMS rely on detailed data about individual demographics uploaded by users, especially in fields such as healthcare, urban planning, or the social sciences.
Using personal or sensitive data can risk breaching individuals' privacy if not handled securely or anonymized properly.
It is essential to use privacy-preserving techniques and comply with data protection laws to prevent unauthorized data access or misuse.
Comprehensive protection mechanisms need to be established to safeguard privacy and ensure the secure handling of sensitive data, ensure ethical use and transparency.
Second, simulated behaviors may inadvertently perpetuate biases and stereotypes embedded in LLMs' training data.
The training dataset may incorporate biases related to race, gender, ethnicity, and other characteristics~\cite{lucy-bamman-2021-gender}.
As a result, ethical considerations require researchers to take an active role in mitigating these biases.
Nonetheless, thoroughly identifying and mitigating all potential biases and stereotypes remains challenging, requiring continued research to further enhance and ensure the fairness of these models.

\subsection{Paradox of Coexist \textit{vs.} Compete}
\textit{``Carbon and Silicon, Coexist or Compete?''}, in the title, we raise the question of whether human~(carbon-based) and agent~(silicon-based) entities can coexist collaboratively or are destined to compete within shared environments in the future.
As generative AI systems demonstrate unprecedented reasoning, creativity, and autonomous decision-making capabilities, critical questions emerge: will humans and agents evolve as collaborative partners, or will their interactions devolve into zero-sum competition?
Modern AI exhibits dual potential as both ``augmenters'' and ``displacers'' of human capabilities.
It demonstrates how AI can amplify professional productivity while simultaneously threatening current occupations. 
Nevertheless, we think the human-AI relationship transcends binary competition or cooperation dichotomies, evolving instead as a ``recursive partnership'' where each entity redefines the other's capabilities.
In our paper, we examine diverse types of interactive modes between humans and agents, encompassing both egalitarian and hierarchical dynamics, as well as collaborative and directive forms of engagement.
The decisive factor is to implement adaptive governance frameworks that align AI's emergent properties with anthropogenic values.
Humans must establish clear boundaries, accountability frameworks, and trust mechanisms to ensure AI is used responsibly and beneficially.
The future relationship between humans and AI remains uncertain. 
Through our discussion of interactions in  ABMS, we aim to offer a perspective that may guide future researchers in exploring this evolving dynamic.
% We have comprehended three limitations of our review and suggest possible solutions for them.
% First, the classification of goals can be more fine-grained.
% In reviewing and coding the corpus of papers, we found that objectives can be further divided into finer-grained categories.
% For example, the goal, \textit{Initialize the Environment}, include defining the agents~\cite{pan2024agentcoordvisuallyexploringcoordination}, giving agents instructions~\cite{cui2024chatlawmultiagentcollaborativelegal}, configure the environments~\cite{jinxin2023cgmiconfigurablegeneralmultiagent}, etc.
% \textit{Evaluate the Performance} can be divided into assessing effectiveness~\cite{park2023choicematessupportingunfamiliaronline} or believability~\cite{10.1145/3394486.3412862}.
% Each sub-goal may correspond to specific interaction patterns.
% We did not pursue further subdivisions because they would be too detailed.
% Thus, we choose the classification at a higher level.
% In future work, we will focus on one or two specific goals and perform a detailed classification to uncover deeper insights.
% Additionally, we proposed a general framework for categorizing environments but did not conduct an in-depth analysis. 
% Researchers interested in this topic are encouraged to utilize our framework and data, as we believe it holds the potential for uncovering valuable insights.

% %放在前面
% Second, our study may not comprehensively cover all relevant literature, especially research from earlier periods.
% A significant reason is that prior to the maturity of natural language processing (NLP) technologies, related work was relatively limited, with some studies built on existing classical simulation platforms we discussed above, such as NetLogo~\cite{netlogo}.
% Furthermore, these research efforts span multiple fields, making it challenging to gather a comprehensive collection systematically.
% Our review indicates that the interaction methods employed in these studies are relatively constrained.
% While some studies may not have been captured in our collection, we are confident that our framework can also effectively account for those methods.
% We also plan to keep updating our corpus of papers with uncollected works and the latest papers to track emerging research trends.

% Third, we did not analyze or discuss the application scenarios of these human-AI interactive ABMS.
% Since the scope of applications is extensive and continually expanding, covering fields such as law~\cite{cui2024chatlawmultiagentcollaborativelegal}, software development~\cite{qian2024chatdevcommunicativeagentssoftware, 10.1145/3581641.3584037}, video game~\cite{mao2024alympicsllmagentsmeet}, education~\cite{Padmakumar_Thomason_Shrivastava_Lange_Narayan-Chen_Gella_Piramuthu_Tur_Hakkani-Tur_2022, 10.1145/3613905.3651008}, household~\cite{10.1145/3613904.3642183, ren2023robotsaskhelpuncertainty}.
% Furthermore, rapid advancements in technology continuously introduce novel use cases that do not fit neatly within traditional categories.
% To address this limitation, we plan to further propose a flexible, multi-dimensional framework that allows for the systematic analysis and categorization of use cases, making it adaptable to new domains and scalable as the application landscape.
\section{Conclusion}
We conduct a systematic survey of 97 research studies on human-AI interactions in agent-based modeling and simulation in various domains from 1996 to 2024.
We first propose a novel taxonomy to categorize the interactions extracted from collected works.
We decompose each interaction into five dimensions according to the ``5W1H'' guideline.
Specially, we employ an analogy from the field of theater and draw upon some related professions to correspond to the roles of users.
Through our analysis, we answered the research question: \textit{How do humans and AI interact in the context of ABMS to fulfill user research requirements?}
Furthermore, we synthesize findings from existing literature to uncover interaction patterns, identify research gaps, and propose future research directions for human-AI interactions in agent-based modeling and simulation.