\section{Methodology}
This section introduces our method of collecting and coding the corpus of works.
Then, we provide the findings of the descriptive statistics concerning publication year, publication venue, and prominent works.
\subsection{Paper Collection}
% When we reviewed the relevant literature, we found that although many studies have focused on researching human-AI interactions in ABSM, their titles or abstracts often do not include the word ``interactive'' or terms with a similar meaning. 
% Moreover, many papers related to LLM-powered agents do not explicitly mention ``agent'' in their titles.
We applied two kinds of methods, reference-driven and search-driven, to collect relevant papers and research.
First, we collected papers within the scope of our survey from the latest core literature reviews about related topics: ABMS~\cite{gao_large_2023}, LLM-empowered agents~\cite{xi2023risepotentiallargelanguage,wang_survey_2024}, and human-LLM interactions~\cite{10.1145/3613905.3650786}.
Second, we developed our search query based on the collected papers.
We summarized the keyword list: ``agent'',  ``large language models'', ``GPT'', ``LLMs'', ``interaction'' and ``human-AI''.
Since the literature reviews we refer to were published in 2023 or 2024, we focus on papers in these two years during the search phase.
We further expanded the corpus by including papers that either cited these works or were referenced by them within the corpus.
Subsequently, three co-authors separately reviewed all the works and filtered those that fall within the scope of our research.
We established two filtering criteria for the corpus due to the implicit search keywords.
First, the paper related to LLMs should involve research on agents that simulate human behaviors, rather than merely exploring the capabilities of LLMs.
% Since some paper titles do not explicitly mention ``agent'', we must further scrutinize the content of these papers.
Second, the papers must address human-AI interactions in ABMS, not just a static ABMS model.
Specifically, when humans are mentioned, they should refer to users of ABMS rather than interaction developers.
Disagreements regarding paper selection were addressed through multiple rounds of discussions among the three co-authors.
Eventually, we collected 97 works for further analysis in this paper.
% We found that the corpus of papers comes from journals and conferences in various fields, most of which are in the AI and HCI community.


\subsection{Descriptive Statistics}
We display descriptive statistics with respect to publication year, venue, and prominent work, which provides an overview of our corpus of works.

\begin{figure}[ht]
  \centering
  \includegraphics[width=\linewidth]{figure/year_venue_new.pdf}
  \caption{%
    \textbf{The statistical figure of publication year and venue.} Some venue names are abbreviated: Environmental Modelling \& Software~(EMS), Mind \& Language~(ML), Political Analysis~(PA), Proceedings of the Annual Simulation Symposium~(PASS). }
  \label{fig:stat}
\end{figure}

\subsubsection{Publication Year}
We first conducted a statistical analysis of the publication year of relevant papers. The first notable work in the field was published in 1996 by Minar\etal~\cite{minar1996swarm}, introducing a multi-agent software platform designed for the simulation of complex adaptive systems. Publication frequency remained relatively low until 2021. With the emergence and widespread adoption of LLMs, ABMS was empowered to facilitate more natural and intuitive interactions. A marked increase in the number of published papers was observed in 2022, followed by a dramatic surge in 2023, where 73\% of the articles were published thereafter. Research interest remains high in 2024, as shown in Fig~\ref{fig:stat}.
Several works lacking year information are early-developed simulation software or toolkits, with publication years unavailable.

\subsubsection{Publication Venue}
In terms of publication venues, we categorize 32 different venues into three major groups: the AI community~(\eg NeurIPS, EMNLP, AAAI), the HCI community~(\eg CHI, CSCW, UIST, IMWUT), and Others. To ensure the timeliness, quite a large amount of papers~(25.8\%) are collected from arXiv, reflecting the latest advancements and trends in the field. While the ACM CHI Conference on Human Factors in Computing Systems~(CHI)~(15.7\%) is the most common venue to appear for the journal/conference publications (including those in CHI EA), followed by IMWUT~(7.2\%), the Annual ACM Symposium on User Interface Software and Technology~(UIST)~(6.7\%) and the Conference on Neural Information Processing Systems~(NeurIPS)~(5.6\%).
%AI, HCI, others 
%AI: NIPS, EMNLP, AAAI
%HCI: CHI, CSCW, UIST
%other: arxiv, TVCG

\subsubsection{Prominent Work}

\begin{table}[ht]
  \caption{Most cited papers of interactive ABMS~(Top 10)}
  \label{tab:freq}
  \begin{tabular}{>{\arraybackslash}p{7.5cm} p{3cm} l l}
    \toprule
    \textbf{Title and Year} & \textbf{Authors} & \textbf{Venue} & \textbf{Citations} \\
    \midrule
    \specialrule{0em}{2pt}{2pt}
    Generative Agents: Interactive Simulacra of Human Behavior (2023) & Park\etal~\cite{10.1145/3586183.3606763} & UIST & 1636\\
    \specialrule{0em}{2pt}{2pt}
    MASON: A Multiagent Simulation Environment (2005) & Luke\etal~\cite{doi:10.1177/0037549705058073} & Simulation & 1444\\
    \specialrule{0em}{2pt}{2pt}
    Do As I Can, Not As I Say: Grounding Language in Robotic Affordances (2023) & Ahn\etal~\cite{ahn2022icanisay} & arXiv & 1242\\
    \specialrule{0em}{2pt}{2pt}
    The Swarm Simulation System: A Toolkit for Building Multi-Agent Simulations (1996) & Minar\etal~\cite{minar1996swarm} &- & 1201\\
    \specialrule{0em}{2pt}{2pt}
    Experiences creating three implementations of the repast agent modeling toolkit (2006) & North\etal~\cite{10.1145/1122012.1122013} & TOMACS & 941\\
    \specialrule{0em}{2pt}{2pt}
    Inner Monologue: Embodied Reasoning through Planning with Language Models (2022) & Huang\etal~\cite{huang2022innermonologueembodiedreasoning} & arXiv & 745\\
    \specialrule{0em}{2pt}{2pt}
    ALFRED: A Benchmark for Interpreting Grounded Instructions for Everyday Tasks (2020) & Schridhar\etal~\cite{shridhar2020alfredbenchmarkinterpretinggrounded} & CVPR & 732\\
    \specialrule{0em}{2pt}{2pt}
    MetaGPT: Meta Programming for A Multi-Agent Collaborative Framework (2023) & Hong\etal~\cite{hong2024metagptmetaprogrammingmultiagent} & arXiv & 414\\
    \specialrule{0em}{2pt}{2pt}
    Out of One, Many: Using Language Models to Simulate Human Samples (2023) & Argyle\etal~\cite{Argyle_Busby_Fulda_Gubler_Rytting_Wingate_2023} & Political Analysis & 414\\
    \specialrule{0em}{2pt}{2pt}
    CAMEL: Communicative Agents for "Mind" Exploration of Large Language Model Society (2023) & Li\etal~\cite{NEURIPS2023_a3621ee9}& NeurIPS & 404\\
  \bottomrule
\end{tabular}
\end{table}

We also assessed the influence of the included papers by examining their citation counts~(\Cref{tab:freq}). Then, we ranked the papers according to their citation counts and found that a large portion of these articles appeared after 2020 ($n=7$ in top 10). The rapid rise of LLMs during that time might be a possible reason. 
The most influential work is the 2023 paper Generative Agents~\cite{10.1145/3586183.3606763}. It introduces Generative Agents to simulate realistic human behaviors for interactive applications. The simulation was validated in a virtual small-town setting, and the agents successfully exhibited realistic individual and emergent social behaviors.
Users are extensively engaged in various ways throughout the simulation process via natural language, significantly reducing the learning costs associated with interaction methods.
Another significant work, MASON~\cite{doi:10.1177/0037549705058073} in our corpus, was cited 1444 times by Jan 2025. It introduces a Java-based, discrete-event simulation toolkit, which aims to provide a flexible, fast, and extensible simulation environment that separates the simulation model from visualization. 
Other highly cited works are mostly about overcoming the weakness of language models and enabling models to accomplish more complex tasks~\cite{ahn2022icanisay, shridhar2020alfredbenchmarkinterpretinggrounded, hong2024metagptmetaprogrammingmultiagent}.
\subsection{Paper Coding}
This paper aims to categorize the interactions derived from existing works.
Inspired by the taxonomy of human-LLM interaction modes proposed by Gao\etal~\cite{10.1145/3613905.3650786}, we adapted ``5W1H'' guideline~\cite{ram_5ws_2018} to decompose interactive methods between human and AI.
Following an initial review of all the papers in our corpus, we established a preliminary framework for paper coding.
Two co-authors coded the corpus separately based on both papers and related demos or presentation videos.
Next, the co-authors checked conflict coding and articulated their perspectives.
They modified the coding and refined the framework iteratively until diverging opinions were resolved.
For each paper or work, we extracted interactive methods from it and analyzed them within our framework.
Taking Generative Agents~\cite{10.1145/3586183.3606763} as an example,
we identified seven types of interactive methods in this paper.
We decomposed each interactive method into five dimensions: why, when, what, who, and how, according to our framework.
We presented the details of our framework in Section~\ref{framework}.


