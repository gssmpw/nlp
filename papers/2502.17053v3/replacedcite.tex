\section{Related Work}
\subsection{Learning-based Shape Completion}
% voxel-based
Early learning-based methods ____ often rely on voxel-based representations for 3D convolutional neural networks. However, these approaches are limited by their high computational cost and limited resolution. Alternatively, GRNet____ and VE-PCN____ use 3D grids as an intermediate representation for point-based completion.  
% point-based
In recent years, several methods have been proposed to directly process points by end-to-end networks. One pioneering point-based work is PCN____, which uses a shared multi-layer perceptron (MLP) to extract features and generates additional points using a folding operation____ in a coarse-to-fine manner. Inspired by it, a lot of point-based methods____ have been proposed.

Later, to address the issue of limited information available in partial shapes, several works____ have explored the use of auxiliary data to enhance performance. 
Some approaches____ involve the combination of rendered color images and partial point clouds, along with the corresponding camera parameters.
Another line of works____ seeks to utilize the scanning viewpoints. They either produce points along the viewpoints____ or use the viewpoints for self-supervised pretraining____.
Semantic labels are also used in a recent approach____ to provide strong priors.
Although these methods have shown promising results, they often require additional input that is difficult to obtain in practical settings. 
Different from these 3D data-driven methods, MVCN____ operates completion solely in the 2D domain using a conditional GAN. However, it cannot supervise the results using ground truth with rich space information. 
In contrast to these methods, we propose to integrate the representation abilities of 3D and 2D modalities by observing self-structures. As a result, our method achieves a more comprehensive perception of the overall shape without requiring additional information.

Considering the high-quality details generation, a variety of strategies have been introduced by learning shape context and local spatial relationships. 
To achieve this goal, state-of-the-art methods design various refinement modules to learn better shape priors from the training data.
SnowflakeNet____ introduces Snowflake Point Deconvolution (SPD), which leverages skip-transformer to model the relation between parent points and child points. 
FB-Net____ adopts the feedback mechanism during refinement and generates points recurrently.
LAKe-Net____ integrates its surface-skeleton representation into the refinement stage, which makes it easier to learn the missing topology part.
Another type of method tends to preserve and exploit the local information in partial input.
One direct approach is to predict the missing points by combining the results with partial input data____. As the point set can be viewed as a token sequence, PoinTr____ and its following works____ employ the transformer architecture____ to predict the missing point proxies.
SeedFormer____ introduces a shape representation called patch seeds for preventing the loss of local information during pooling operation. 
Some other approaches____ propose to enhance the generated shapes by exploiting the structural relations in the refinement stage.
A recent work____ shares a similar idea with our \emph{Similarity Alignment} unit of utilizing self-similarities property and directly learns geometric transformations for input points.
However, these strategies employ a unified refinement strategy for all points, which limits their ability to generate pleasing details for different points.
Our approach differs from theirs by breaking down the shape refinement task into two sub-goals, and adaptively extracting reliable features for different partial areas.

\subsection{View-based Methods for 3D Understanding}
View-based 3D understanding techniques have gained significant attention in recent years.
The classic Multi-View Convolutional Neural Network (MVCNN) model was introduced in ____, where color images are fed into a CNN and subsequently combined by a pooling operation. However, this approach has the fundamental drawback of ignoring view relations.
Following works____ propose various strategies to tackle this problem. For example,
____ obtains a discriminative 3D object representation by modeling region-to-region relations.
LSTM is also used to build the inter-view relations____.
Since the cross-modal data are more available, methods are proposed to fuse features of views and point clouds.

However, compared to their 2D counterpart, most of 3D recognition methods are limited by the scarcity of training data. Therefore, in recent years, there has been a surge in research focusing on enhancing 3D understanding through the utilization of pre-trained 2D models.
P2P____ prompts a pre-trained image model by the geometry-preserved projection.
PointCLIP____ and its following work____ achieve zero-shot point cloud understanding by sending multi-view 2D projections to CLIP____ for a well-learned representation. To adapt the power of CLIP to more 3D scenarios, alternative methods____ employ cross-modal contrastive learning to train a powerful 3D encoder.
Recent approaches explore masked autoencoders using both 3D and 2D data____. Some approaches pre-train a 3D encoder through color image generation____ or neural rendering____.
Inspired by the success of view-based 3D understanding techniques, our method utilizes point cloud features to enhance relationships between multiple views obtained by self-augmentation.

\subsection{Semantic Scene Completion}
Given an incomplete observation, semantic scene completion (SSC) aims to reconstruct and assign semantic labels to a 3D scene.
The prevailing approach in SSC involves utilizing the voxel grid as the primary 3D representation. Pioneering the field, SSCNet____ addresses this task through an end-to-end network constructed with 3D Convolutional Neural Networks. Subsequent methodologies enhance this framework by incorporating group convolution____, multimodal fusion____, GAN____, and boundary learning____. 
SISNet____ tackles SSC by iteratively performing grid-based scene completion and point cloud object completion.
AdaPoinTr____ introduces a geometry-enhanced SSC framework to augment existing voxel-based SSC methods with a point cloud completion network.
% 
To accommodate diverse autonomous driving scenes, recent research has primarily focused on outdoor LiDAR datasets and explored various input modalities.
LiDAR-based approaches____ commonly integrate point-wise features within voxel space to enhance scene understanding. Meanwhile, alternative methods have emerged to predict scene occupancy using monocular images. The pioneering work MonoScene____ addresses this problem with successive U-Nets and a novel feature projection module. Building on this foundation, ____ introduces a two-stage transformer architecture. 
NDC-Scene____ further improves performance by reducing feature ambiguity in the normalized device coordinates space. Symphonies____ advances this line of research by incorporating instance-centric semantics and scene context through the use of instance queries.
More recently, images captured by multiple cameras are also utilized for accurate 3D understanding____.
% 
Different from these methodologies, point-based SSC methods____ focus on reconstructing a complete scene point cloud along with semantic labels assigned to each point.
____ attach an extra segmentation network to the point cloud completion model.
CasFusionNet____ takes a hierarchical approach, merging features from completion and segmentation modules.
In this work, we extend PointSea to SSC by jointly predicting semantic labels and geometric details through the proposed SDG.

\begin{figure*}[h]
  \centering
  \includegraphics[width=0.95\textwidth]{fig/overview.pdf}
\caption{The architecture of PointSea. SVFNet first generates a global shape from the cross-modal input. The coarse completion is then upsampled and refined with two SDGs.}
  \label{fig:overview}
\end{figure*}