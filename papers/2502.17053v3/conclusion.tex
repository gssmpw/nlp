\begin{figure}[h]
  \centering
  \includegraphics[width=\linewidth]{fig/cases.pdf}
\caption{
Visualization of failure cases. PointSea may generate inaccurate local details when the input point clouds exhibit substantial domain gaps from the training data, such as highly complex topologies or outliers from other objects. Nevertheless, even in these challenging scenarios, PointSea outperforms competitors~\citep{chen2023anchorformer,10232862} by reconstructing more plausible shapes.
}
  \label{fig:cases}
\end{figure}


\section{Conclusion}
We propose PointSea for point cloud completion. We start by identifying the main challenges in the completion and developing new solutions for each of them. PointSea leverages self-projected multi-view analysis to comprehend the overall shape and effectively perceive missing regions. Furthermore, we introduce a decoder called Self-structure Dual-generator that breaks down the shape refinement process into two sub-goals, resulting in a disentangled but improved generation ability. We demonstrate the superiority of PointSea by conducting experiments on point cloud completion benchmarks with various data types. 

\noindent \textbf{Failure cases. }
% 问题：对真实数据的泛化性还存在不足
Although PointSea effectively reconstructs detailed geometric features, transferring this ability to some complex out-of-distribution real-world scans is indeed challenging due to the domain gap. 
% 现象：failurecase
Fig.~\ref{fig:cases} shows two representative types of failure cases. The first row depicts a plant with disorganized leaves, and the second row shows a bed with an untidy quilt. Both examples exhibit complex topologies that are rarely observed in the training dataset. 
As a result, PointSea tends to rely on commonly observed patterns from the training data to reconstruct the point cloud, failing to capture the desired local details. Additionally, in the third row, the table contains outlier points from other objects in the scene, causing PointSea to generate noisy points in these extraneous structures.

\noindent \textbf{Potential solutions and future work.}
Considering the emerging network architectures or large-scale 3D generation or reconstruction model, we discussed the following three potential technical solutions to the aforementioned issue:

i) A promising approach is to train a large completion model with zero-shot generalization capabilities. Although PointSea leverages the scalable Transformer architecture as its main component, our early experiments indicate that simply stacking more attention layers does not necessarily improve completion performance. This observation is consistent with the scaling laws for large language models~\citep{kaplan2020scaling}. To enhance model robustness, generating additional high-quality training data using recent large-scale 3D datasets~\citep{objaverse, objaverseXL, yu2023mvimgnet} is a promising direction. These datasets have already played a pivotal role in advancing 3D generative models and could similarly benefit large point cloud completion models.


ii) Another solution is to utilize rich prior knowledge from existing large generative models.  As shown in our preliminary experiments (see Tab.~\ref{tab:ablation2Dbackbone}), integrating SVFNet with vision foundation models~\citep{lama,latentdiffusion,controlnet} may enhance the performance of PointSea.
In addition to 2D foundation models, 3D-aware generative models — including image-to-3D generation models, multi-view diffusion models, and native 3D diffusion models — can be employed to enhance shape completion capabilities.
Image-to-3D generation models typically produce high-quality local details and smooth surfaces. However, relying solely on single-view information may result in incomplete or less accurate outputs (see Fig.~\ref{fig:gen_comp}).
On the other hand, multi-view diffusion models provide richer, view-consistent geometric cues. For example, the recent method PCDreamer~\citep{wei2024pcdreamer} integrates this type of prior within a cross-modal completion framework to improve results.
Finally, inspired by PCDreamer, we believe that native 3D diffusion models (such as Clay~\citep{zhang2024clay}, 3DTopiaXL~\citep{chen2024primx}, and GaussianAnything~\citep{lan2024ga}) hold promising potential as a more direct 3D prior for point cloud completion in future research.

iii) In the current implementation of SDG, self-similarity is only considered within a single instance. However, similar patterns of missing regions, such as complex leaves, may occur across different shapes. Exploring cross-instance and cross-scene similarity offers an exciting research direction that could further enhance PointSea's ability to generalize across diverse scenarios.  




