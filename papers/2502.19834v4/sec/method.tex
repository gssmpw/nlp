\section{Method}
\label{sec:method}

\subsection{Overview}

\begin{figure*}[h]
% \setlength{\abovecaptionskip}{0cm} 
% \setlength{\belowcaptionskip}{-0.2cm}
  \centering
  % \fbox{\rule{0pt}{2in} \rule{0.9\linewidth}{0pt}}
   \includegraphics[width=1\linewidth]{pic/cvpr2025-framework.pdf}
   \caption{\textbf{Overview of `Knowledge Bridger' Pipeline.} The pipeline consists of three steps: 1) construction of a knowledge graph from available modalities, 2) knowledge-driven generation of missing modalities, and 3) knowledge-based ranking. The input of this pipeline is the available multimodal data and known domain knowledge. The output is the required missing modality.}
   \label{fig:framework}
\vspace{-10pt}
\end{figure*}

Our approach aims to construct a training-free MMC pipeline by leveraging a pre-trained LMM. This pipeline extracts and models knowledge from available modalities, and subsequently uses this knowledge to generate missing modality data and select the most appropriate generated candidate. The pipeline is depicted in Fig. \ref{fig:framework} and consists of three steps:

\begin{itemize}
    \item \textbf{Step 1: construction of a knowledge graph from available modalities} (in section \ref{sec:kg-modeling}). The goal of this step is to utilize the general knowledge a pre-trained LMM to understand the content of each modality and their interrelationships.
    \item \textbf{Step 2: knowledge-driven generation} (in section \ref{sec:kg-generation}). In this step, the LMM employs the knowledge graph to extract specific details about the missing modality, including the number and attributes of objects. A corresponding modality generator then uses this information to generate the required missing modality. 
    \item \textbf{Step 3: knowledge-based ranking} (in section \ref{sec:kg-ranking}). This step aims to compute a quality score for the generated missing data by assessing the graph similarity and semantic similarity between the missing and available modalities.
\end{itemize}


\subsection{Knowledge Graph Modeling}
\label{sec:kg-modeling}

Our objective is to automatically extract knowledge from available modalities to support the generation and ranking of any missing modalities. \textbf{In our context, `knowledge' refers to information encapsulating the characteristics of existing modalities, enabling the generation and ranking modules to create semantically consistent missing data.} Extracting relevant knowledge from unknown domains, however, presents significant challenges. From a knowledge graph perspective, constructing a meaningful, modality-specific graph requires predefined nodes and relationships. In a training-free context, predefining these elements becomes particularly challenging. 

To overcome this, we develop an automatic entity and relationship mining strategy using an LMM. This strategy leverages the extensive prior knowledge and OOD capabilities of LMM to identify entities and relationships across various modalities, even without predefined elements. Recent study \cite{kojima2022large} highlight LMM’s potential for zero-shot learning and reasoning.

Building on this analysis, LMM can be utilized to extract elements from available modalities using prompts. To enhance scalability, we propose the following extraction rule: \textit{\{Entity: Reasoning Prompts\}}. For instance, to identify potential objects, we could use: \textit{\{`Objects': `Identify the major objects in the [modality-type].'\}}. This rule allows us to incorporate object relationships and interaction data\footnote{The complete rules and prompts are provided in the appendix.}. To improve adaptability across domains, domain-specific prior knowledge—such as histological and clinical diagnostic information for medical image analysis—can be included. This approach offers two main advantages: 1) reducing misconceptions when LMM operates in a new domain, and 2) enhancing its reasoning capabilities for novel entities.

LMM can further consolidate the extracted information into a modality-specific knowledge graph. A straightforward approach is to guide LMM to extract potential entity-relation pairs from the collected data. However, this method is constrained by the context window length, and an excessive number of extraction rules may lead to overlooked entity-relation pairs. To mitigate these limitations, we implement the Chain-of-Thought (CoT) method. Specifically, LMM is first directed to produce concise responses for each rule, followed by extracting unique entity-relation pairs from these responses. This stepwise decomposition improves both the accuracy of responses for each rule and the synthesis of information. Importantly, we extract and retain data solely from current modalities to avoid interference from unrelated information, thereby enhancing LMM’s reasoning efficiency. 


% Ultimately, these knowledge graphs serve as inputs for the generation and ranking modules, helping LMM comprehend existing modalities and identify content for generation.


\subsection{Knowledge-driven Generation}
\label{sec:kg-generation}

The goal of missing multimodal generation is to understand the content in available modalities and generate missing ones that align semantically. Two critical factors impact the quality of the generated missing modalities: understanding multimodal content and maintaining consistency. We previously discussed using LMM for content comprehension and knowledge graph extraction. Here, we explore using LMM for ensuring consistency and guiding generation. For convenience, we use image-text pairs as our study objects. For example, when an image is available, we aim to generate text that closely matches real data. A basic approach is using LMMs to describe the image directly. However, this method involves significant randomness. First, the form of the missing text is unknown—it could be a caption, summary, or description. Second, we cannot precisely specify the subject of the missing text.


To solve this, we propose a knowledge-driven entity alternation strategy. Using domain knowledge and extracted knowledge graphs, we select related entities.For instance, if missing data focuses on an entity such as an `\textit{objection},' we traverse elements within the knowledge graph related to `\textit{objection}.' We then adopt a multi-view generation manner, allowing the LMM to generate missing information with each element as the subject, while encompassing all nodes and attributes within the knowledge graph. These outputs are stored as standardized text descriptions, reducing randomness, enhancing result retrieval, and offering better control and interpretability. With these descriptions, modality generators can create missing data. For missing images, entity-based descriptors can guide conditional diffusion methods. For missing text, LMM process these descriptions to generate outputs. This approach works across various fields, using mature generation models with domain knowledge to create needed data without extra training. However, relying only on this may not guarantee full accuracy, which we discuss in the next section.

% The objective of missing multimodal generation is to comprehend the content provided by available modalities and generate the missing modalities that are semantically consistent with them. Two critical factors influence the quality of the generated missing modalities: understanding multimodal content and maintaining consistency. In the previous section, we present how to leverage LMMs to understand multimodal content and derive corresponding knowledge graphs. In this section, we focus on how to use LMM to obtain multimodal consistency and guide the generation process. For convenience, we use image-text pairs as our study objects. For example, when the image modality is available, we expect our approach can accurately generate the missing text as similar to real data as possible. A straightforward method is to directly use LMM to generate a description of the image. However, this method involves significant randomness. First, the form of the missing text is unknown—it could be a caption, summary, or description. Second, we cannot precisely specify the subject of the missing text.

% To address this issue, we design a knowledge-driven entity alternation generation strategy. Specifically, by utilizing predefined domain knowledge and the extracted knowledge graph, we select specific entity groups. For instance, if missing data focuses on an entity such as an `\textit{objection},' we traverse elements within the knowledge graph related to `\textit{objection}.' We then adopt a multi-view generation manner, allowing the LMM to generate missing information with each element as the subject, while encompassing all nodes and attributes within the knowledge graph. For uniformity, these generated results are saved in text form, providing a detailed description of the missing data. The advantages of this method include: 1) establishing a fixed generation style, which reduces randomness in the generation process; 2) facilitating the retrieval of the expected outcomes by describing the missing information from various entity perspectives; and 3) providing a more controlled generation process and better interpretability through a uniform missing description format.

% Once we have obtained the missing descriptors, we can use existing modality generators to generate the missing data for alternate entities. For instance, in the case of missing image data, we can use the descriptors of alternate entities to utilize conditional diffusion techniques to generate the corresponding missing image modality. Similarly, we can process the missing descriptor with LMM to obtain the corresponding missing text modality. The rationale behind this strategy is that generation is a universal research problem across different fields. In both the general and medical domains, for example, we can easily access mature generation models that possess substantial domain knowledge, allowing us to generate the required data without additional training. However, solely generating missing data based on this knowledge cannot ensure complete accuracy. In the next section, we discuss how to select appropriate missing data.

\subsection{Knowledge-based Ranking}
\label{sec:kg-ranking}

To achieve automatic ranking of generated missing data based on the provided knowledge, we introduce graph similarity and representation similarity. Graph similarity is computed as the average cosine similarity score of the adjacency matrices of two graphs, as presented in the following equation:

\begin{equation}
\label{eq:graph-cos}
    \cos_{graph}(A_{i}, B_{i}) = \frac{1}{n} \sum_{i=1}^{n} \frac{A_{i} \cdot B_{i}}{\|A_{i}\| \|B_{i}\|},
\end{equation}
where $A_i$ and $B_i$ represent the \( i \)-th row vectors of adjacency matrices $A$ and $B$, respectively. $\|A_i\|$ refers to the Euclidean norm of the \( i \)-th row: $\|A_i\| = \sqrt{\sum_{j=1}^{m} A_{ij}^2}$. $n$ and $m$ represent the rows and columns of the adjacency matrix, respectively. This metric reflects the degree of similarity between the two graphs, and its value is normalized between 0 and 100. On the other hand, we compute the representation similarity between the generated and available modalities to reflect semantic consistency. For consistency, we similarly employ cosine similarity to compute the similarity between two representations, expressed as $\cos(\mathbf{a}, \mathbf{b}) = \frac{\mathbf{a} \cdot \mathbf{b}}{\|\mathbf{a}\| \|\mathbf{b}\|}$, where $\mathbf{a}$ and $\mathbf{b}$ are the vectors of two modalities. Inspired by \cite{bianco2023improving}, we directly utilize CLIP \cite{radford2021learning} and BLIP \cite{li2023blip} to obtain semantic embeddings for each modality. Finally, we derive the following equation to compute the generation quality score between any pair of available and missing modalities:
\begin{equation}
\begin{aligned}
    \label{eq:qs-score}
     QS&(x_a, x_m)  = \cos_{graph}(f_a(x_a), f_a(x_m))  \\
    & + [\cos(f_c(x_a), f_c(x_m)) + \cos(f_b(x_a), f_b(x_m))],
\end{aligned}
\end{equation}
where $x_a$ and $x_m$ represent available and missing modalities, respectively. The functions $f_a(\cdot)$, $f_c(\cdot)$, and $f_b(\cdot)$ are used to obtain the adjacency matrix, CLIP's embedding, and BLIP's embedding of the given modality, respectively. We argue that $QS(\cdot, \cdot)$ can comprehensively assess two critical factors: knowledge structure similarity and semantic consistency. A higher value indicates a higher quality of the generated missing modality. Our method ultimately outputs the generated missing modality with the highest score.