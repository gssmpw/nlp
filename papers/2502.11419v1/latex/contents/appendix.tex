\newpage

\appendix

\section{Timeline of Instruction Datasets}
\label{appendix: timeline}
\begin{figure}[htbp]
\begin{center}
\includegraphics[width=0.8\columnwidth]{latex/figures/timeline.pdf}
\end{center}
\caption{Timeline of instruction datasets (part) since 2021.04 to 2023.07.} 
\label{fig: timeline}
\end{figure}

\section{Details of Implementation}
\label{appendixs: hyperparameters}
\textbf{Fine-grained Quality Scoring} We adopt the quality annotator \footnote{\url{https://huggingface.co/hkust-nlp/deita-quality-scorer}} provided by \citet{ds-deita} to score the instructions.

\textbf{Representation-based Progressive Data Selection:} During the PIBE data selection process, we set the momentum coefficient $\alpha=0.3$, the momentum decaying rate $\lambda=0.9$, the damping rate $\beta=0.5$ and the weighting coefficient $\gamma=1$. Besides, we adopt instruction embedding \citep{instruction_embedding} to encode the instructions. As for affinity propagation, we use negative euclidean distance to initialize the similarity matrix and fill the diagonal of similarity matrix with 0. Moreover, due to the high memory overhead of Affinity Propagation (\(O(n^3)\)), we further divided the complete set of candidates in each evolution iteration into smaller evolution batches with a batch size of 27,000 to perform PIBE. For data selection, all baselines employ the full-scale selection manner rather than the gradual selection manner to get their global optimal performance. For PIBE, we perform progressive InsBank evolution following the temporal order of dataset appearance (i.e. Self-Instruct $\rightarrow$ Alpaca $\rightarrow$ Dolly $\rightarrow$ ShareGPT $\rightarrow$ WizardLM), and take the final selected subset for model fine-tuning.

\textbf{Instruction Fine-Tuning:} We utilize 8 NVIDIA A100 SXM4 40GB GPUs to fine-tune LLMs. We employ LlamaFactory \citep{llamafactory}, DeepSpeed Zero-Stage 3 \citep{deepspeed} and fp16 precision to facilitate the training process. We adopt the Llama3-style template for Llama3-8B, Qwen-style template for Qwen2.5-7B and Mistral-style template for Mistral-7B, corresponding to "llama3" "qwen," and "mistral" template in LlamaFactory respectively. We set the effective batch size to 128 (per device train batch size=1 and gradient accumulation steps=16), training epochs to 6, learning rate to 1e-5, warmup ratio to 0.1 and maximum input length to 2048.

For trainable tokens and turns restriction, we set max tokens to 3M and max turns to 7k unless otherwise specified. For quality-controlled experiments, since all data are single-turn conversations, we set max tokens to 2M and max turns to 6k. For orderliness analysis, we set max tokens to 0.9M and max turns to 2.3k.

For AlpacaEval inference, we set temperature=0.7, top\_p=0.9, top\_k=40, num beams=1 and max length=512. For MT-Bench inference, we follow the default setting of FastChat\footnote{\url{https://github.com/lm-sys/FastChat/tree/main}} except for that max length is set to 512. All models adopt templates consistent with those in the training process during evaluation.

For AlpacaEval evaluation, we compare each model output with GPT-3.5 Turbo (gpt-3.5-turbo-1106) \citep{openai_chatgpt}, because we find that when compared to text-davinci-003 \citep{gpt3} or GPT-4 Turbo \citep{gpt4}, the benchmark was either too simple or too challenging, making it difficult to differentiate between models. For both AlpacaEval and MT-Bench, we employ GPT-4o \citep{openai_gpt4o} as annotator.

\section{Statics of Candidate Instruction Datasets}
\begin{table}[htbp]
    \centering
    \small
    \begin{tabular}{lcc}
    \toprule
    Dataset & Scale & Quality \\
    \midrule
    Self-Instruct & 82k & 2.29 \\
    Alpaca & 52k & 3.59 \\
    Dolly & 15k & 2.76 \\
    ShareGPT (cleaned) & 58k & 4.03 \\
    WizardLM & 70k & 4.16 \\
    \bottomrule
    \end{tabular}
    \caption{Statistics of instruction datasets.}
    \label{tab: dataset-statistics}
\end{table}

\section{Description Correlation Analysis}
\label{appendix: correlation-analysis}

We first sort the data in descending order based on the overall score and select the top 12k samples. For each sample, we assign a flag: if the sample is selected into InsBank, the flag is set to 1; otherwise, it is set to 0. We then calculate the Spearman correlation coefficients between diversity and flags, as well as between quality and flags, to investigate the contributions of diversity and quality to data selection. We restrict our analysis to the top 12k data sorted in descending order by the overall score, as we aim to focus on high-quality candidates with relatively high quality and diversity. Lower-quality candidates are excluded from the analysis since their likelihood of being selected into InsBank is inherently low.

\section{Momentum Responsibility Matrix}
\label{appendix: momentum-responsibility-matrix}

\begin{figure}[hbtp]
\includegraphics[width=\columnwidth]{latex/figures/momentum_responsibility.pdf}
\caption{The structure of momentum responsibility matrix.}
\label{fig: historical information}
\end{figure}


\section{Quality-Controlled Subset Construction}
\label{appendix: qc construction}

To avoid mixing single-turn and multi-turn conversations data, as well as biases introduced by different data distributions across dataset, we sample data with quality ranging from 4.5 to 5.0 from WizardLM (alpaca), resulting in a quality-controlled subset with 19805 samples. 

\section{Selected Data Visualization from QC-Subset}

\begin{figure}[htbp]
\begin{center}
\includegraphics[width=\columnwidth]{latex/figures/qc_distribution_plot.pdf}
\end{center}
\caption{Selected data visualization based on quality controlled subset. The blue stars represent the most diverse data, while the orange triangles represent the least diverse data.}
\label{fig: qc_diversity}
\end{figure}

\newpage

\section{K-Center Greedy Algorithm}

\begin{algorithm}
\caption{K-Center Greedy}\label{alg:kcentergreedy}
\begin{algorithmic}[1]
\Require data $x_i\in S$ and a budget $m$
\State Initialize $S_m=x_0$
\Repeat
\State $u=\arg\operatorname*{max}_{x_i\in S\backslash S_m}$
\Statex
\quad\quad\quad\quad\quad\quad\quad\quad$\operatorname*{min}_{x_j\in S_m}d(g(x_i),g(x_j))$
\State $S_m = S_m\cup \{u\}$
\Until{$|S_{m}|=m$}
\State \Return {$S_{m}$}
\end{algorithmic}
\end{algorithm}

\section{Nonlinear Quality Mapping Function}

\begin{figure}[hbtp]
\includegraphics[width=\columnwidth]{latex/figures/nonlinear_fn.pdf}
\caption{Visualization of nonlinear quality mapping function.}
\label{fig: nonlinear_fn}
\end{figure}


\section{Additional Analysis}
\label{appendix: addition-analysis}

\subsection{Overlap Between Progressive Evolving and Full Data Selection}
\label{appendix: overlap-between-progressive-and-full}

In this section, we aim to compare the overlap rates between the subsets selected by different methods from the gradual manner and those from the full-scale selection manner \footnote{Aggregate all available candidates first and perform data selection on the full data directly.}. 

We randomly select 40k data from the full data to obtain a subset that closely resembles the distribution of real data. We set the InsBank size here to 1k, and divided the data into four candidate subsets of 10k each to simulate the gradual manner. We compared PIBE with kNN$_1$ and k-Center Greedy, and perform an ablation analysis on the historical information used in PIBE. We set $\gamma=1$, and for PIBE, we set $\alpha=0.3$ and $\lambda=0.9$ which aligns with the main experiment. The results are reported in Table~\ref{tab: result-overlap}. It shows that the overlap rate of PIBE exceeds that of the kNN$_1$ and kCenter Greedy, and the historical information also helps improve the overlap rate. 

\begin{table}[htbp]
    \centering
    \small
    \begin{tabular}{lcccc}
    \toprule
    Method  & k-NN & kCenter & PIBE w/o hst & PIBE \\  
    \midrule
    Num & 131 & 747 & 390 & 864 \\
    \bottomrule
    \end{tabular}
    \caption{The overlap sample number between subset selected in full-scale manner and in gradual manner. Here, PIBE w/o hst is the ablation on history information of PIBE.}
    \label{tab: result-overlap}
\end{table}

\subsection{Instruction Bank Evolution}

\begin{figure}[htbp]
  \includegraphics[width=\columnwidth]{latex/figures/evol_benchmark.pdf}
  \caption{Evolution}
  \label{fig: evolution}
\end{figure}

In this experiment, we investigate the performance of subsets selected by different data selection methods for model training. Following the temporal order of dataset appearance (i.e. Self-Instruct $\rightarrow$ Alpaca $\rightarrow$ Dolly $\rightarrow$ ShareGPT $\rightarrow$ WizardLM), we performed progressive InsBank evolution using PIBE and take the selected subset for model fine-tuning. The performance of the fine-tuned model across different benchmarks is shown in Figure~\ref{fig: evolution}. 

\subsection{PIBE Hyper-Parameter Analysis}

The damping rate $\beta$ is a hyperparameter inherent to Affinity Propagation, typically set to 0.5, and we have adhered to this default setting. For the analysis of hyperparameters, we focus on examining the quality and diversity of the selected data. We compared different combinations of \(\lambda = [0.9, 0.93, 0.95]\), \(\alpha = [0.3, 0.5, 0.8]\), and \(\gamma = [1, 2]\) in selecting InsBank. The results are shown in Figure~\ref{fig: statistics-hyper}. 
Overall, \(\gamma\) determines the influence of quality on data selection. As \(\gamma\) increases, the average quality of the selected data improves, but diversity decreases. Both \(\lambda\) and \(\alpha\) determine the impact of historical information on the composition of selected data. We find that higher \(\lambda\) and \(\alpha\) values generally result in lower quality but higher diversity in InsBank. This is because, according to the evolution sequence of InsBank, the quality of the data improves progressively. When the influence of historical information increases, more older data is retained in InsBank, leading to relatively lower quality and higher diversity.

\begin{figure}[hbtp]
\includegraphics[width=\columnwidth]{latex/figures/hyper_parameters.pdf}
\caption{InsBank statistics of different hyper-parameters.}
\label{fig: statistics-hyper}
\end{figure}

We further compare the overlap between the final InsBanks obtained with different hyperparameter. From 0 to 17, the corresponding \([ \alpha, \lambda, \gamma ]\) combinations are as follows: [0.3, 0.90, 1], [0.3, 0.93, 1], [0.3, 0.95, 1], [0.5, 0.90, 1], [0.5, 0.93, 1], [0.5, 0.95, 1], [0.8, 0.90, 1], [0.8, 0.93, 1], [0.8, 0.95, 1], [0.3, 0.90, 2], [0.3, 0.93, 2], [0.3, 0.95, 2], [0.5, 0.90, 2], [0.5, 0.93, 2], [0.5, 0.95, 2], [0.8, 0.90, 2], [0.8, 0.93, 2], [0.8, 0.95, 2]. We observe that when \(\gamma = 2\), the overlap between InsBanks is generally higher compared to when \(\gamma = 1\), due to the increased influence of quality. This observation is reasonable, particularly as \(\gamma\) continues to grows, the results increasingly resemble those of a quality-greedy data selection strategy, where the selection outcomes become fixed regardless of whether historical information is considered. When \(\gamma = 1\), the influence of historical information is relatively more pronounced, resulting in significantly lower overlap rates between different InsBanks compared to when \(\gamma = 2\). Additionally, we observed that when \(\gamma\) and \(\lambda\) are equal, the overlap rates of InsBanks obtained with different \(\alpha\) values are significantly higher than those obtained when \(\gamma\) and \(\alpha\) are equal but with different \(\lambda\) values. This indicates that \(\lambda\) has a greater impact on altering the influence of historical information.

\begin{figure}[hbtp]
\includegraphics[width=\columnwidth]{latex/figures/subset_overlap.pdf}
\caption{Overlap of InsBank selected with different hyperparameters.}
\label{fig: func_compare}
\end{figure}

\subsection{Time Costs Analysis}
\label{appendix: time-cost}

We adhered to the data selection settings of the main experiment to compare the actual time costs of data selection between DEITA and PIBE. In this experiment, we ensure that both methods are tested under identical hardware environments. The results are shown in Table~\ref{tab: time-cost-comparison}. It is worth noting that DEITA (full) refers to full-scale data selection, while DEITA (progressive) represents the progressive InsBank Evolution process. Additionally, the time spent loading data is also included in the total time consumption. PIBE achieves higher efficiency compared to DEITA because PIBE's data selection process is parallelized, whereas DEITA requires a sequential traversal of data to perform selection. 

In practice, DEITA's data selection efficiency is primarily influenced by the number of evolution iterations and the size of InsBank. The selection time for DEITA (progressive) grows almost linearly with the number of iterations, while the total data volume has minimal impact. Additionally, as more data is selected into InsBank, the time required to select a new sample increases, as it becomes harder to find a candidate that meets the nearest neighbor similarity constraint. This implies that as the size of InsBank grows, DEITA's efficiency will further decline.

In contrast, PIBE's efficiency is unaffected by the size of InsBank due to its parallelized operations. Instead, the primary factor influencing PIBE's time consumption is the total data volume. An increase in the total data volume leads to a higher number of evolution batches, with each batch requiring approximately 1 minute to process. As a result, PIBE's total data selection time scales linearly with the number of evolution batches.


\begin{table}[htbp]
    \centering
    \small
    \begin{tabular}{lc}
    \toprule
     Method & Time (hrs) \\
     \midrule
     DEITA (full) & 0.68 \\
     DEITA (progressive) & 2.28 \\
     PIBE & 0.21 \\
    \bottomrule
\end{tabular}
\caption{Time costs of DEITA and PIBE.}
\label{tab: time-cost-comparison}
\end{table}

\onecolumn

\newpage
\section{Selected Data Quality Distribution}

\begin{figure*}[h]
\begin{center}
\includegraphics[width=0.98\textwidth]{latex/figures/selected_data_quality_distribution.pdf}
\end{center}
\caption{Selected data quality distribution of different combination approaches.}
\label{fig: selected-data-quality-distribution}
\end{figure*}

