\section{Conclusion}

In this paper, we propose InsBank to address the ongoing challenge of evolving instruction datasets. PIBE integrates high-quality and representative data into InsBank, striking a balance between enhancing data diversity and quality, while maintaining long-term scalability and efficiency. By leveraging a representation-based diversity score with historical information, PIBE flexibly combines diversity and quality for data selection and ranking. Experimental results show PIBE outperforms baselines, providing more optimal and adaptable instruction subsets. The orderliness of InsBank also allows users to extract tailored subsets within budget constraints, supporting cost-effective training and the ongoing refinement of LLMs. This work paves the way for more dynamic and adaptable instruction tuning strategies, enhancing both the efficiency and effectiveness of LLM development over time.