\begin{table*}
\caption{\label{tab:model_design}%
	\textbf{Model design ablations.}
	We evaluate our model on posed images from the Nerfstudio Dataset \cite{tancik2023nerfstudio}.
	We show a \method prediction above the table, where we compare the generation vs. the ground truth for reconstruction metrics (PSNR/SSIM/LPIPS).
	For hallucination metrics, we report the conditional validation loss (VAL) as done by \citet{esser2024scaling}.
	Notably, we focus on image generation rather than pose prediction but find that not predicting pose (``no-pose-pred'') leads to worse results.
	See \cref{sec:model-design} for detailed descriptions.
}
\centering
\scriptsize
\begin{tabular}{lcllll|llll|llll}
\toprule
\multirow{2}{*}{\textbf{Method}} & \multirow{2}{*}{\textbf{Iters}} & \multicolumn{4}{c}{\bfseries 8-views} & \multicolumn{4}{c}{\bfseries 16-views} & \multicolumn{4}{c}{\bfseries 32-views} \\

 & & PSNR $\uparrow$ & SSIM $\uparrow$ & LPIPS $\downarrow$ & VAL $\downarrow$ & PSNR $\uparrow$ & SSIM $\uparrow$ & LPIPS $\downarrow$ & VAL $\downarrow$ & PSNR $\uparrow$ & SSIM $\uparrow$ & LPIPS $\downarrow$ & VAL $\downarrow$ \\
\midrule

 no-index-emb & 100K & 11.10 & 0.431 & 0.456 & 0.2394 & 14.06 & 0.450 & 0.400 & 0.2417 & 12.38 & 0.467 & 0.422 & 0.2438\\ 
 fixed-index-emb & 100K &  10.46 & 0.353 & 0.520 & 0.2517 & 12.14 & 0.390 & 0.491 & 0.2546 & 12.52 & 0.416 & 0.448 & 0.2556\\ 
 no-poses & 100K &  11.63 & 0.413 & 0.426 & 0.2386 & 14.73 & 0.461 & 0.384 & 0.2411 & 13.39 & 0.476 & 0.389 & 0.2431\\ 
 random-poses & 100K &  11.82 & 0.431 & \textbf{0.415} & 0.2384 & \textbf{16.18} & \textbf{0.487} & 0.333 & 0.2409 & \textbf{14.27} & 0.483 & 0.367 & 0.2430\\ 
 \method & 100K & \textbf{11.97} & \textbf{0.435} & \textbf{0.415} & \textbf{0.2383} & 15.81 & 0.481 & \textbf{0.329} & \textbf{0.2407} & 14.21 & \textbf{0.486} & \textbf{0.366} & \textbf{0.2426}\\
 \method & 1M &  12.77 & 0.442 & 0.381 & 0.2365 & 17.20 & 0.485 & 0.281 & 0.2388 & 14.13 & 0.498 & 0.352 & 0.2396\\ 

\bottomrule
\end{tabular}
\vspace{-10px}
\end{table*}