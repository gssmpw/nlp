\twocolumn
\section*{Response Letter for Submission 1379 (Shepherd Submission 1621)}

%\noindent \textbf{Dear reviewers,}

\noindent 
We would like to express our gratitude to the reviewers for their valuable feedback.
In response to the reviewers' comments and according to the revision plan, we focused on addressing four main areas of improvement: (1) improving the experimental analysis, (2) enhancing the presentation, (3) extending the discussion on related works, and (4) clarifying our limitations.
To address these issues, we have provided a detailed explanation of our responses to the concerns that were raised by all reviewers. We have also addressed each reviewer's comments individually.

Updates made in response to specific comments are highlighted in the revised manuscript using the following colors:
\begin{itemize}
\item \common{Changes for multiple reviewers in Orange}
\item \reva{Reviewer 1 in Green}
\item \revb{Reviewer 2 in Magenta}
\item \revc{Reviewer 3 in Purple} 
\end{itemize}



\subsection*{Summary of the Main Changes}
We provide a brief overview of the main changes we made. \blue{Reviewer\#1, \#2, and \#4 are referred to as R1, R2, and R3 respectively.}



% \vspace{1mm}
\noindent
% {\bf{(\colorbox{pink}{Point \textrm{1}}) Additional Experiments}}. 
\subsubsection*{\bf{(\colorbox{pink}{Point \textrm{1}})
% \label{rev:point-1}
Improving the experimental analysis}} Based on the reviewers' suggestions, we enhanced the experimental evaluation in the following ways:


$\bullet$ \textbf{Comparison with baselines}: We expanded the comparison with the baselines (FRL~\cite{chen2018optimization} and IDS~\cite{lakkaraju2016interpretable}) to include quantitative metrics, including the solution size, coverage, accuracy, and execution time \blue{(addressing R2.O1)}.

\lastday{We would like to clarify that the rules generated by IDS and FRL baselines are prediction rules (e.g., IF owning a house = YES, THEN credit score = 1). We note that, as such, {\bf these rules generated by IDS and FRL do not provide any intervention to improve outcomes and do not include any grouping patterns}. To compare IDS and FRL with our approach, we  developed two variants of these two approaches: (i) considered the IF clause of these rules as grouping patterns and used Step 2  (\cref{subsec:treatment_patterns}) of our algorithm to determine the relevant treatment for each grouping pattern.  (ii) considered the IF clause of each rule as a treatment pattern where the grouping pattern is the whole population. }


% Specifically, (1) we have added more details about the rules generated by IDS and FRL in {\bf \cref{tab:problem_variants}}, now including the solution size and their coverage. 
% To compare the expected utility, we proceed as follows: The rules generated by these baselines are prediction rules (e.g., IF owning a house = YES, THEN credit score = 1). We note that, as such, {\bf these rules generated by IDS and FRL do not provide any intervention to improve outcomes and do not include any grouping patterns}. We, therefore, treat the IF clauses as the selected grouping patterns and then apply step 2 (\cref{subsec:treatment_patterns}) of our algorithm to determine the relevant treatment for each grouping pattern. For the resulting set of prescription rules, we report the expected utility for both protected and non-protected groups. \red{This process can be viewed as an alternative method for generating grouping patterns}.


\lastday{For these two variants, we report the solution size, coverage, expected utility for protected and non-protected, and the unfairness
The results are presented in 
{\bf \cref{tab:problem_variants}}. Notably, the expected utility for both protected and non-protected groups across both datasets is generally lower than that achieved by \sysName.  \sysName\ consistently delivers higher expected utility for both groups and a smaller difference between these values. This indicates that our approach to mining grouping and intervention patterns is more effective than relying on these algorithms for the same purpose.  However, we note (and also mention in the paper) that the rules in IDS and FRL had different objectives (prediction accuracy) and have been evaluated differently for quantitative comparison using our metrics (as was asked by the reviewers).}



(2) Additionally, we updated {\bf \cref{exp:scalability} (Figure~\ref{fig:runtime_dataset_size} and Figure~\ref{fig:runtime_attributes})} to include a runtime analysis for the baselines as well, examining how their runtime varies with the number of tuples and attributes. The running time of \sysName and the baselines (IDS and FRL) is comparable (\textbf{\Cref{fig:runtime_dataset_size}}). 
\lastday{FRL is an order of magnitude slower than IDS because it uses a Bayesian modeling approach to simultaneously select a subset of rules and determine their optimal permutation, which involves solving a computationally intensive combinatorial problem. In contrast, IDS leverages submodular optimization on an unordered set of rules, significantly reducing the complexity of the search.}
We also compared the running time on varying the number of mutable and immutable attributes (\textbf{\Cref{fig:runtime_attributes}}). FRL and IDS do not distinguish between mutable and immutable attributes, and their running time depends on the total number of attributes, as with more attributes the search space of possible rules increases. 

$\bullet$ \textbf{Protected groups}: We provided a more detailed explanation of the protected groups analyzed and the rationale behind their selection \blue{(addressing R2.O2)}. Specifically, we now explain in {\bf Section \ref{sec:casestudy}} that the protected groups were selected to represent subgroups where the desired outcome was relatively low and that they are sufficiently large to ensure the discovery of statistically significant rules. The protected group in the Stack Overflow data is defined as individuals from countries with a low GDP (using the GDP attribute, which is categorical in this dataset). This group constitutes 21.5\% of the data. In the German Credit data, the protected group is defined as single females, and this group constitutes 9.2\% of the data. 
% \red{{\bf **REVISIT**}} 
    



\subsubsection*{\bf{(\colorbox{pink}{Point \textrm{2}})
\label{rev:point-1}
Enhancing the presentation}} To enhance the paper's presentation, we have made the following revisions.



$\bullet$ \textbf{Usability}: We provided an explanation of how the proposed framework may potentially be used by policymakers \blue{(addressing R1.O1)}. Specifically, we now discuss an example scenario in {\bf Section \ref{sec:conc}} that the policymaker selects the target outcome and the relevant problem variant (e.g., imposing coverage and/or fairness constraints). The system then generates a prescription ruleset for the policymaker to implement. The framework assumes that the policymaker will publish the relevant recommendations for each subpopulation. However, if not all rules are provided to the users, disparities among subpopulations may increase, and a study of proper and fair usage of rules suggested by our framework remains a future work.
  

$\bullet$ \textbf{Usage of LLMs}: 
As \blue{R1.O7} pointed out, the generated rules mostly follow a template, and we do not need LLMs to translate the rules to natural language sentences. In the revised paper, we replaced the explanations with a template version to present them without relying on LLMs, to avoid hallucinations and errors.

%We will clarify our use of LLMs and revise the prompts to ensure it does not introduce errors.  We utilized ChatGPT to translate prescription rules into natural language. Each rule included the following components: grouping pattern, intervention pattern, overall coverage, coverage for protected groups, and overall, protected, and non-protected expected utility. ChatGPT was prompted to rephrase these elements into a natural language sentence.  To minimize the risk of hallucination, we will refine our prompts by using precise templates. This approach ensures the content remains unchanged, with ChatGPT solely rephrasing the rule into a sentence without altering the numbers or meaning (addressing R1.O7).


$\bullet$ \textbf{Presentation of Result Summary}: We adjusted the colored boxes to make their content easier to read and present the results summary in a more accessible format  \blue{(addressing R1.O8)}. \lastday{We also removed the results summary discussion, now pointing out our main findings in the text.} Please refer to the revised {\bf Section \ref{sec:casestudy}}.

$\bullet$ \textbf{Patterns \& WHERE clauses}: We clarified in {\bf Section \ref{subsec:rules}} the relation between WHERE clause and a pattern \blue{(addressing R3.O1)}. Specifically, we now mention that \emph{patterns} is a commonly used notation in query result explanation research~\cite{roy2014formal,wu2013scorpion,el2014interpretable,lin2021detecting}. Generally, patterns are equivalent to the WHERE clause in SQL queries. However, in this work, we focus on a specific type of pattern: a conjunction of predicates, as has been done in prior query result explanation research~\cite{roy2014formal,wu2013scorpion,el2014interpretable,lin2021detecting,DBLP:journals/pacmmod/YoungmannCGR24}.

$\bullet$ \textbf{Motivating example}: We have revised {\bf the introduction} to make it more concrete by rephrasing it to include more realistic and practical examples \blue{(addressing R3.O2)}. Specifically, we focused on the two use cases examined in our experimental evaluation: increasing the average salary of high-tech employees and improving the average credit risk score. 

Additionally, \blue{to address R1.O2 and interactive discussion with R1}, we revised the motivating example of the Stack Overflow dataset ({\bf \cref{example:ex1} and \cref{ex:intro_example_3}}) to avoid relying on the (unconvincing) causal relationship between exercising and salary. A similar revision was made in the case study presented in {\bf Section \ref{sec:casestudy}}.

$\bullet$ \textbf{Typos}: We have thoroughly proofread the paper and the code repository to eliminate any typos or errors \blue{(addressing multiple comments by the reviewers  R1.11, R1.12, R2.12, R3.10)}.




\subsubsection*{\bf{(\colorbox{pink}{Point \textrm{3}})
% \label{rev:point-1}
Extending the discussion on related works}} 
 To the best of our knowledge, no existing framework generates causal-based, fairness-aware actionable recommendations. However, we expanded our discussion of {\bf related work (Section~\ref{sec:related})} from relevant conferences to include recent literature on alternative definitions of fairness (e.g.,\cite{jain2024algorithmic, somerstep2024algorithmic}) and causal-based resource allocation approaches (e.g., \cite{majumdar2024carma, ehyaei2023robustness}) \blue{(addressing R1.O6, R1.O3)}. We emphasized that this work focuses on four definitions of fairness -- statistical parity and bounded group loss, considering both individual and group fairness -- as an initial step. Exploring additional definitions of fairness is an interesting direction for future research.  
 %
 We have fixed reference \cite{zehlike2022fairness} and \cite{zehlike2022fairness2}  as mentioned in \blue{R2.12}.




\subsubsection*{\bf{(\colorbox{pink}{Point \textrm{4}})
Clarifying our
limitations. }} 
Based on the reviewers' comments, we extended the discussion on the limitations of the proposed framework in the following ways:

$\bullet$ \textbf{Causal DAG quality}: In the revised {\bf Section \ref{sec:conc}}, we clarified that the generated rules can be influenced by several factors, including the quality of the input causal DAG \blue{(addressing R1.O2)}. Specifically, we acknowledge that inaccuracies in the DAG may lead to flawed rules. Consequently, we assume that the causal DAG is provided as part of the input, with the responsibility for validating its correctness resting on the policymaker. Nonetheless, the causal DAG only needs to specify causal dependencies between variables without detailing the nature of those dependencies.



To examine the quality of the causal DAG on the performance, we also added an experiment evaluating the robustness of our method when the causal graph is noisy.
Specifically, in the revised {\bf Section \ref{subsec:causal_DAG_robustness}}, we examine the impact of different causal DAGs on the rules. The causal DAGs considered are as follows: 
\textbf{(1) 1-layer Indep DAG:} A causal DAG where all attributes are independent of each other and only impact the outcome. This setting is similar to the scenario where the causal DAG is ignored.
\textbf{(2) 2-layer Mutable DAG:} A simplified DAG where immutable attributes affect the mutable attributes, which impact the outcome variable. In this DAG, all immutable attributes act as confounders but do not directly impact the outcome.
%Another default causal DAG where all immutable attributes point to mutable attributes, which in turn point to the outcome.  
\textbf{(3) 2-layer DAG:} A simplified DAG where all variables affect the outcome but the mutable attributes are also confounded by all immutable attributes (i.e., we add direct edges from immutable attributes to the outcome in the previous 2-layer mutable DAG). 
%Another 2-layer causal DAG. In this DAG, to include confounding variables, all edges in the default-2-layer DAG are present, with additional edges from the top layer to the outcome.  
\textbf{(4) PC DAG:} A causal DAG generated by the PC causal discovery algorithm~\cite{spirtes2001causation}.

\lastday{The results are depicted in \textbf{\cref{tab:causal_dag_variants}}. We report the expected utility as computed over the different causal DAGs. We observe that the expected utility remains similar for the Stack overflow dataset, demonstrating robustness towards the choice of causal dag. The results show some variability in German credit. However, the PC DAG and the original causal DAG are the most accurate (as they are based on the data distribution and domain knowledge) and achieve the highest coverage and expected utility.}
%\brit{TODO} \red{ADD ONE MORE 2 -LAYER?}



Lastly, we clarified that the example dataset (\textbf{\cref{tab:data}}) and the example causal DAG (\textbf{\cref{fig:causal_DAG}}) represent only a subset of the data, consisting of 20 variables.  


% In our running example from Stack Overflow, the \verb|Exercise| variable (indicating how many times per week an individual exercises) has a directed causal path to the \verb|HoursComputer| variable (indicating how many hours per day an individual works on a computer), which in turn directly affects the \verb|Salary| variable. Thus, based on this DAG, exercising has an indirect causal effect on salary.  

    


$\bullet$ \textbf{Theoretical guarantees}: We acknowledge that our algorithm does not provide formal guarantees for approximating the \probName\ problem \blue{(addressing R1.O4)}, and we clarified this in the revised {\bf Section \ref{sec:algo}}. As expected, the problem is NP-hard in simple settings (proofs deferred to the full version due to lack of space) and even developing good heuristics considering several parameters and constraints is non-trivial. However, we emphasize that each selected rule represents an intervention that is statistically significant. Specifically, based on causal analysis, the expected utility reflects the anticipated average increase in the outcome for the specific subpopulation to which the rule applies. Nevertheless, as we mention in the revised {\bf Section \ref{sec:conc}}, the quality of the generated rules may be influenced by several factors, including data quality, the correctness of the input causal DAG, and the method used to estimate causal effects. 
%\red{MENTION ROBUSTNESS HERE?}

 
 $\bullet$ \textbf{Explainability}: Another limitation we now address in the revised paper pertains to the explainability and interpretability of the generated rules \blue{(addressing R3.O3, and the interactive discussion with R1)}.
 %While if-then rules are generally considered interpretable by humans~\cite{lakkaraju2016interpretable,guidotti2018local,van2021evaluating,pradhan2022interpretable,chen2018optimization}, 
 While if-then rules for prediction or causation mined from data are considered explainable or interpretable in the literature \cite{lakkaraju2016interpretable,pradhan2022interpretable,van2021evaluating,guidotti2018local,chen2018optimization}, we note that no additional explanations or justifications come with the prescriptive rules mined by \sysName, which may be added in future work. 
%However, as mentioned in Point 4, the rules themselves are considered explainable or interpretable in the literature [1-5]. We will clarify this in the paper.
%We also note that prescription rules consist of conjunctions of predicates, which may not always be explainable. 
Generating meaningful explanations to describe how the treatment patterns impact the outcome and the variability of the outcome within various sub-populations are deferred to future work. This is now discussed in {\bf Section~\ref{sec:conc}.}
 \cut{
 \red{prescription rules consist of conjunctions of predicates, which may not always be explainable.} For instance, in a highly detailed dataset, a possible rule might suggest that {\em individuals aged between 18.5 and 21.2 years should learn programming in Python}. Understanding the rationale behind such a rule is not straightforward. A potential direction for future work involves binning continuous variables into semantically meaningful ranges while ensuring that sound causal inference can still be performed on the binned data. We clarified this issue in the revised 
{\bf Section \ref{sec:conc}}
}.



\vspace{4mm}
\noindent
%This concludes the summary of the main revisions we plan to make.
Below, we give responses to the meta-reviewer's and reviewers' comments and refer to the above points for details to avoid repetition.\\


\subsection*{Meta-Review}
\vspace{1mm}
\noindent
\emph{\blue{The authors consider the task of mining from a table a set of rules that can be turned into recommendations that are fair in the sense that there is not too large of a difference in expected outcome between a protected and a non-protected group.\\
%
The reviewers request a deeper consideration of the fairness literature, to better position the results, including in the evaluation (R2.01) as well as addressing the points below.}}\\
\noindent
\emph{\blue{{\bf 5. Required Changes}\\
R1 01-08\\
R2.01/02\\
R2: 01-O2\\
}}
\textbf{Ans}. We thank the meta-reviewer and the reviewers for the revision opportunity. As discussed in the summary above and in the responses below, we addressed all required changes and other comments in the revised paper.\\

\subsection*{Reviewer \#1}
\vspace{1mm}
\noindent
\colorbox{pink}{\textbf{R1.O1}}
\emph{\blue{The general framework of how this work could be used is unclear.
If at least some individuals do not hear about the recommendation, they would clearly be at a disadvantage. Conversely, if the rules are known "internally", e.g., the bank has its internal rules on who gets credit, people who know the rules play the game better than the others. This is already the case today. Clearly, the authors take a step forward by considering protected subgroups, I understand that they seek to make things more fair. But how their proposed rules can be leveraged to that purpose is unclear.
Moreover, in general, most resources are finite, e.g., total salary to pay to the developers, or credit to be given out by a bank.
If all the groups followed the recommendations, would everyone's salary really increase? Would all customers be awarded credit? Or are rules/criteria in real life used to divide a finite resource, with a more or less arbitrary threshold drawn somewhere?}} 
\textbf{Ans}. We thank the reviewer for highlighting these issues. Our work is one of the initial works in this area, and the questions asked by the reviewers are important future work. As noted in {\bf Point 2} above, we included a discussion on the intended usability of the system and the potential risks of improper use in the revised {\bf Section \ref{sec:conc}}. Additionally, we now mention in the revised Section \ref{sec:conc} that future work would focus on extending our framework to include additional constraints related to available resources.

In addition to whether the rules are conveyed fairly to the targeted individual, another question is whether 
%The reviewer raises an interesting point about ensuring that 
the generated rules cover all individuals. The coverage constraint in this work intends to enforce such a requirement. However, not all applications necessitate universal coverage. For instance, a political party may implement targeted policies to maximize votes, or a company might offer incentives to individuals more likely to purchase a product. Our framework provides the flexibility to specify these coverage requirements while maintaining fairness with respect to sensitive attributes. However, an in-depth study of the proper and fair usage of the rules suggested by this system remains a future work.

\vspace{1mm}
\noindent
\colorbox{pink}{\textbf{R1.O2}} \emph{\blue{The authors' notion of causality is hard to understand in some places (examples).
The authors state in many places that their approach is causal, not correlation-based. Yet it takes a leap of faith to assume that exercising X days a week causally improves one's salary, especially for young people (considering that the bad effects of lack of exercise start showing in one's 40s or 50s).
Also, exercise does not appear at all in Table 1; nor does it appear in the partial DAG (Figure 1), nor is there some substitute attribute or anything related to the exercise aspect.
In my view, these "exercise impacts salary" examples are not helping the paper to be convincing.}} 
\textbf{Ans}. We agree with the reviewer on this point. Following the reviewer's suggestion, we replaced our running example and presented rules for the stack overflow dataset to avoid relying on the (unconvincing) causal relationship between exercising and salary (as mentioned in {\bf Point 2} above, see {\bf \cref{example:ex1} and \cref{ex:intro_example_3}}). Table 1 and Figure 1 show only a subset of the attributes.

Please also refer to our discussion in {\bf Point 4} regarding the quality of the input causal DAG. 

\vspace{1mm}
\noindent
\colorbox{pink}{\textbf{R1.O3}} \emph{\blue{Other aspects of fairness deserve more discussion.
The example given early on states that a certain rule whcih would improve salaries by 13000\$ for protected people and 44000\$ for everyone. Whether or not this is acceptable/desirable depends on the local purchase power and who the group consists of (does a majority of users live in India? or in the US? the calculations would not be the same). Maybe this is part of the authors' future work (mentioned at the end) of the paper.}} 
\textbf{Ans}.
The reviewer has raised an interesting point about varied purchasing power and cost of living in different countries. One way to address this would be to modify the objective function to maximize the ratio of salary and purchasing power. However, principled techniques to address these issues are indeed interesting directions for future work, and we discuss this in {\bf Section~\ref{sec:conc}}.
Please also see {\bf Point 3} for discussions on fairness definitions.
%We have discussed this limitation in more detail in the future work section. %\brit{to discuss}
%In the revised paper, we will provide additional details about the distributions in the examined datasets to give more context for the generated rules. As noted in Point 3 above, we also plan to expand our discussion of other definitions of fairness in the related work section.

\vspace{1mm}
\noindent
\colorbox{pink}{\textbf{R1.O4}} \emph{\blue{As the authors acknowledge, there are no formal guarantee of the quality of their obtained rules.}} 
\textbf{Ans}. Please refer to our answer in {\bf Point 4} above (see {\bf Section \ref{sec:algo} and Section~\ref{sec:conc}}). 

\vspace{1mm}
\noindent
\colorbox{pink}{\textbf{R1.O5}} \emph{\blue{How many among the "Result Summary" statements required some experiments to establish, vs. some that can be analytically shown or exhibited with small examples?}} 
\textbf{Ans}. 
%We agree with the reviewer on this point. 
To fit additional material, we decided to remove the result summary since the individual experiments discuss the findings. 
\cut{
Some statements in the results summary, such as the observation that fairness often comes at the cost of overall expected utility, are straightforward and intuitive. We revised the discussion in the results summary to emphasize the more interesting and novel findings uncovered through our analysis. Please refer to the revised {\bf \Cref{sec:casestudy}}.  
}

\vspace{1mm}
\noindent
\colorbox{pink}{\textbf{R1.O6}} \emph{\blue{The paper is welcome at SIGMOD where fairness is one of the topics. However, it would be good if the authors did a more comprehensive comparison with the stazte of the art in FAccT and also RecSys, to ensure: has their problem never been looked at? It would be good to make sure.}} 
\textbf{Ans}. Thank you. In our revised related work ({\bf \cref{sec:related}}), we have discussed additional related work, including previous work on rule mining~\cite{lakkaraju2016interpretable,lawless2023interpretable}, causal rule mining~\cite{DBLP:journals/pacmmod/YoungmannCGR24} and fair causal analysis~\cite{plecko2022causal,plecko2023causal,zhang2022adaptive} techniques. We also discuss alternative fairness definition~\cite{binns2020apparent,garcia2021maxmin,DBLP:journals/pacmmod/ZhangTPCW23,somerstep2024algorithmic,smith2022recsys,ekstrand2019fairness,gao2020counteracting} and fairness of
allocated resources~\cite{majumdar2024carma, ehyaei2023robustness}. Some of these new references appeared in FAccT and RecSys. We could not find previous works that consider both causal rule mining and fairness aspects. Please also refer to our response in {\bf Point 3} above. 





\vspace{1mm}
\noindent
\colorbox{pink}{\textbf{R1.O7}} \emph{\blue{Why use ChatGPT to generate very simple, template-like text (out of patterns), especially considering that it may hallucinate and introduce errors?}} 
\textbf{Ans} Please see our response in {\bf Point 2} above. We now do not use ChatGPT to rephrase the rules and use a fixed template.


\vspace{1mm}
\noindent
\colorbox{pink}{\textbf{R1.O8}} \emph{\blue{It is OK to show sample rules as "figures" with smaller font, but it's a pity to do so for important content such as the Result Summary.}} 
\textbf{Ans}. Thank you for this comment. We revised the presentation to ensure the main findings of the results are clear and more accessible. As mentioned under R1.O5, we have removed the result summary and results are now discussed along with the experiments. 


\vspace{1mm}
\noindent
\colorbox{pink}{\textbf{R1.11 and R1.12}} \emph{\blue{Availability and Minor Remarks.}} \textbf{Ans}. Thank you for highlighting these issues. We addressed them all, and thoroughly proofread the paper and the repository.

\vspace{1mm}
\noindent
\colorbox{pink}{\textbf{Additional Comments from Interactive Discussions}}

% \cut{
% \emph{\blue{
% (1) Thank you for your revision plan! In Point 4, you state: "Exercise variable (indicating how many times per week an individual exercises) has a directed causal path to the HoursComputer variable (indicating how many hours per day an individual works on a computer), which in turn directly affects the Salary variable."
% A. Can you please clarify: increasing Exercise leads to which effet on HoursComputer? (increase or decrease?)
% B. From the paper's statement: "male students should exercise 3-4 times per week, and pursue an undergraduate major in CS. This can boost their salary by \$25,578 per year", I understand that the (increase or decrease) in HoursComputer leads to an increase in Salary. Is this correct?
% If (as your answer to Point 4 seems to state) the authors are not very confident in the A. or B. causal paths, the data may not be of very good quality, the example may be confuse readers. It would then be better to replace it. What do you think?}} 
% }

%  %We had more clarifications about this question in the feedback discussion, which we could not include due to space constraints. 
% \cut{Thank you for asking this question. First, we clarify the answers:

% A. Increasing exercise may have a causal effect on HoursComputer, but it can be either way. Increased exercise time (heavily) may decrease the time to work at the computer, but it can also increase the time to work making a person more fit, The advantage of using a causal DAG is that we only need to know a causal dependency exists without specifying or quantifying the nature of causal effect, i.e., we do not need to fit a model for the causal effect or decide whether the effect is increasing or decreasing when we use a causal DAG.

% B. The causal rule returned by our framework is only as stated, i.e., it does not advise whether the exercise time should be increased or decreased from the current status. It only states that the treatment pattern "HoursExercise = 3-4 AND MAjor = CS" has a positive CATE of \$25,578 on male student population.

% We will look for better examples, also clarify what the causal rules imply, how the causal DAG is used, and that the actual nature of causal dependencies (increase/decrease, measure) is not needed in our framework.

% Thanks,
% authors
% }

% \vspace{1mm}
% \noindent
% \cut{
% \emph{\blue{
% (2) Thank you for clarifying. I understand that your approach does not need to establish in which direction a parameter affects another, e.g., whether exercise increases or decreases HoursComputer.
% I believe the Explainability paragraph in Point 4 of your revision plan also states this, i.e., there is no explanation or justification that comes with the prescription, and it is not really explainable.
% While the work is interesting, the wording "prescription", "recommendation", or "causal", bothers me, because it is hard to imagine outputs of this algorithm being recommended to actual humans
% without some causal reasoning/explanation attached.
% In the example we discussed, "that we only need to know a causal dependency exists without specifying or quantifying the nature of causal effect" perhaps simplifies things computationally.
% However, the causal/logical links not sought after ("those that we don't need to know") are probably those that would convince someone to adopt the "prescriptions".}}
% }
% %

% \emph{\blue{
% \ldots{} At this point, I think we agree that:\\
% - a better example would be less puzzling\\
% - the limitations you propose in Point 4. of the revision plan are very helpful to clarify what the approach can (and cannot) provide}}
% \cut{Thanks a lot again, for asking us the questions and this engaging discussion. We agree with the reviewer on the final two points and will address them in the revision:
% 1. A better example would be less puzzling
% 2. The limitations proposed in Point 4. of the revision plan will be clarified as a discussion of what our approach can (and cannot) provide.

% We would like to further clarify and confirm a few other things mentioned by the reviewer:

% A. There is indeed no *additional* explanation or justification that comes with the prescription. However, as mentioned in Point 4, the rules themselves are considered explainable or interpretable in the literature [1-5]. We will clarify this in the paper.

% B. The *causal* aspect of this work is based on the vast causal inference literature on observational causal studies in Statistics and AI on observed or collected data. Under certain assumptions (that are known to be untestable), causal claims can be made from collected or observed data, and Average Treatment Effect (ATE) and Conditional Average Treatment Effect (CATE) on a subpopulation can be estimated. We follow Judea Pearl’s Graphical Causal Model from the AI literature [6] and use the DoWhy package released by Microsoft (https://github.com/py-why/dowhy) to estimate ATE and CATE. Indeed, the estimation of ATE and CATE depends on the quality of the causal DAG as mentioned in Point 4 of the revision plan, which we assume is given as background information. The causal DAG only needs causal dependencies between variables without specifying its nature. In the revision, we will vary the causal DAGs to evaluate the dependency of our framework on the accuracy of the causal DAG.

% C. Causal analysis is the main foundation for any *prescription* or *recommendation* beyond predictions. When possible, one would do a randomized controlled trial (e.g., when a new vaccine is tested), but often they are not possible due to cost/ethics/feasibility issues, and one depends on observational causal study (used in sociology, econometrics, psychology). Indeed, observational causal study depends on assumptions (ignorability, causal DAG) that may not hold in a scenario, but that still a causal claim. This was the reason we used the terms prescription and recommendation. However, we agree that one should know the assumptions and limitations of these claims, and we will make sure to clarify this in the revised paper and explain the rationale behind using the terms causal and prescription along with their limitations.

% We will be happy to answer if the reviewer has a follow-up question or comment.
% Many thanks for the discussion and the thoughtful comments,
% the authors

% [1] Guidotti, Riccardo, et al. "Local rule-based explanations of black box decision systems." arXiv preprint arXiv:1805.10820 (2018).
% [2] van der Waa, Jasper, et al. "Evaluating XAI: A comparison of rule-based and example-based explanations." Artificial intelligence 291 (2021): 103404.
% [3] Pradhan, Romila, et al. "Interpretable data-based explanations for fairness debugging." Proceedings of the 2022 International Conference on Management of Data. 2022.
% [4] Lakkaraju, Himabindu, Stephen H. Bach, and Jure Leskovec. "Interpretable decision sets: A joint framework for description and prediction." Proceedings of the 22nd ACM SIGKDD international conference on knowledge discovery and data mining. 2016.
% [5] Chaofan Chen and Cynthia Rudin. 2018. An optimization approach to learning
% falling rule lists. In International conference on artificial intelligence and statistics.
% PMLR, 604–612.
% [6] Pearl, Judea. Causality. Cambridge university press, 2009.
% }
% \cut{\emph{\blue{
% %(3) Thank you for the more extensive explanation. 
% \ldots{} I believe it will be helpful to clarify the notions of causality and explainability you use early on,
% to avoid confusions and guide the readers. This, and an example readers can more easily interpret, will help the paper reach its potential!
% }}}
\textbf{Ans}. Thank you for taking the time to discuss with us in the interactive discussion forum. 
\begin{itemize}
    \item As mentioned under R1.O2, we have replaced the exercise example with a more convincing example. The example of exercise and our follow-up discussion about this will be added to the full version.
\item We have discussed in detail in {\bf Section \ref{sec:conc}} several limitations of our current framework and directions for future work, including the limitations pointed out by the reviewers.
\item As discussed under {\bf Point 4}, we have added experiments varying the causal DAG to evaluate the robustness of our approach in terms of the causal DAGs. Please see revised {\bf Section \ref{subsec:causal_DAG_robustness}}.
\item We have added a discussion on the explainability and prescriptive nature of the rules in {\bf Section~\ref{sec:conc}} as a concluding remark. 
\end{itemize}



\subsection*{Reviewer \#2}
\vspace{1mm}
\noindent
\colorbox{pink}{\textbf{R2.O1}} \emph{ \blue{The experimental comparison with state-of-the-art solutions is currently limited and should be improved.
The comparison with the baselines is performed only at the qualitative level (Section 7.2). This analysis should also be extended at the quantitative level, comparing the solutions in terms of size, coverage, fairness metrics, and execution time. A more complete evaluation would prove the effectiveness of the results.}} 
\textbf{Ans}. We have revised our experiments following the suggestion. Please see our response to {\bf Point 1} above. 

\vspace{1mm}
\noindent
\colorbox{pink}{\textbf{R2.O2}} \emph{ \blue{The paper states that, in the experiments, ‘the protected groups were selected to represent subgroups where the desired outcome was relatively low and sufficiently large (approximately 30\% of the population) to ensure the discovery of statistically significant rules.’ I find this indication unclear. Which are the protected groups? I invite the authors to clearly specify it.}} 
\textbf{Ans}. Please see our response in {\bf Point 1} above. 



\vspace{1mm}
\noindent
\colorbox{pink}{\textbf{R2.12}} \emph{\blue{-How were the three rules shown in the example selected? What are the criteria?
Moreover, it would be interesting to discuss the overall rules.
- Table 5 compares the solutions also in terms of size, coverage, and expected utility as Table 4. I suggest extending the caption.
-Typos
Survey [97] has a peer-review published version}} \textbf{Ans}. 
We have added the following discussion in {\bf \Cref{sec:casestudy}}. We chose the rules by picking one randomly from each category (one that favors the protected group, one that favors the non-protected, and another that is more balanced). We also mention that the full lists of rules are available in \cite{fullversion}.
Thank you for pointing out the typos, the caption of Table 5, and reference [97] (now~\cite{zehlike2022fairness}). We fixed them and proofread the paper.

\subsection*{Reviewer \#3}
\vspace{1mm}
\noindent
\colorbox{pink}{\textbf{R3.O1}} \emph{ \blue{Why call this a pattern? This is a WHERE clause, and the following discussion of coverage is selectivity. Why create new jargon?}} 
\textbf{Ans}. Please see our response in {\bf Point 2} above. 

\vspace{1mm}
\noindent
\colorbox{pink}{\textbf{R3.O2}} \emph{  \blue{The verbiage in the abstract and introduction - presecriptions are for change - both personal health and organization... very motherhood and apple pie, but difficult to map directly to this work. Could we bring it down from such lofty goals? Given the high-level that the introduction is written at, it is unclear what a realistic prescription could be. A clear, complete and well motivated running example, tied into the introduction that can then be used to clearly explain components of the paper - such as the granularity of a prescription, or algorithmic results later - would do well.}} 
\textbf{Ans}. We thank the reviewer for this comment. As mentioned in {\bf Point 2} above, we revised the introduction to focus
on the two use cases examined in our experimental evaluation:
increasing the average salary of high-tech employees and improving
the average credit risk score. 


\vspace{1mm}
\noindent
\colorbox{pink}{\textbf{R3.O3}} \emph{ \blue{There is a statement about understanding and explanability in the motivation. However, the explainability component is not clearly described in teh approach or evaluation. This either needs to be removed, or strengthened.}} 
\textbf{Ans}. We agree with the reviewer on this point. We removed these statements from the paper and included a discussion on enhancing explainability in {\bf \Cref{sec:conc}}. Please refer to our response in {\bf Point 4} above.

\vspace{1mm}
\noindent
\colorbox{pink}{\textbf{R3.10}} \textbf{Ans}. \emph{\blue{Honestly, the formatting with the callout boxes bothers me a bit. I can't tell if I'm just being old, or if there is a readability problem here}}
\textbf{Ans}. Thank you for pointing this out. We revised the formatting of the boxes. 

