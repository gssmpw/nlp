%!TEX root=main.tex

\section{Introduction}
% Decision-makers, analysts, data scientists, and policymakers frequently rely on data to draw conclusions and extract insights. This data-driven approach helps them identify actionable recommendations aimed at influencing an outcome of interest, such as increasing product satisfaction or income levels or decreasing the likelihood of experiencing serious health conditions \cite{galhotra2022hyper,lakkaraju2016interpretable,agrawal1994fast}. 
\revc{Prescriptions, or actionable recommendations, are commonly generated across various fields to influence key outcomes such as improving product satisfaction, enhancing economic policies, or increasing business efficiency. 
%Decision- or policy-makers, analysts, data scientists, and 
Policymakers in government, decision-makers in businesses, and data scientists in various fields, often rely on data-driven approaches to identify 
%actionable recommendations 
potential actions to influence an outcome of interest, such as increasing income levels or loan approval rates}.
% , or decreasing the likelihood of experiencing serious health conditions. 
%
While association or prediction-based methods are extensively used in practice to draw useful insights from data, they typically identify correlations among variables and may fail to reveal the underlying causal factors, i.e., which actions may result in an improved outcome, needed for informed decision-making. 
%For recommendations to be truly impactful, there must be a clear  explanation that justifies why a particular decision is appropriate for a specific subpopulation~\cite{sun2021treatment,plecko2022causal}. 

\emph{Causal analysis} or {\em causal inference}, therefore, is considered one of the most important requirements to generate prescriptions that are {\em actionable} and aligned with human reasoning~\cite{imbens2024causal}. Causal inference, and in particular {\em observational studies} for causal inference on collected data (when controlled trials are impossible due to cost or ethical reasons), have been extensively studied in the statistics and artificial intelligence (AI) literature for several decades \cite{rubin2005causal, pearl2009causal}. Motivated by this foundational work on causal inference, the notion of causality has also influenced the field of database research. The causal models from AI have been extended to relational databases \cite{salimi2020causal},  and causality has been incorporated into various data management tasks such as finding responsibilities of inputs toward query answers ~\cite{meliou2010causality, meliou2009so, meliou2014causality}, explanations for query answers \cite{roy2014formal, DBLP:journals/pacmmod/YoungmannCGR24}, data discovery~\cite{galhotra2023metam,youngmann2023causal}, data cleaning~\cite{pirhadi2024otclean,salimi2019interventional}, hypothetical reasoning \cite{galhotra2022causal}, and large system diagnostics~\cite{markakis2024sawmill,causalsim,sage, gudmundsdottir2017demonstration}. 


\revc{If-then rules are generally considered interpretable by humans~\cite{lakkaraju2016interpretable,guidotti2018local,van2021evaluating,pradhan2022interpretable,chen2018optimization}.
We give a concrete example of the difference between association and causation in generating prescriptions or recommended actions in the form of if-then rules below}:
\begin{example}	%
\label{example:ex1} {\bf Importance of causal prescriptions:}
Consider the Stack Overflow (SO) annual developer survey
\cite{stackoverflowreport}, where respondents from around the world answer
questions about their jobs and demographics. A sample of the dataset \reva{with a subset of the
attributes (there are 20 attributes)} is presented in \cref{tab:data}.
%
Alice, a researcher in the United Nations (UN) finance department, is interested in discovering ways to increase the salaries of high-tech employees worldwide. She is looking for a set of actionable recommendations 
%(that we call a prescription rules) 
to raise the overall average salary.
%
Using association-based approaches~\cite{chen2018optimization,lakkaraju2016interpretable}, she may discover that individuals residing in the US who identify as straight or heterosexual tend to earn higher salaries (see \cref{exp:quality} for full details). However, this observation merely indicates a correlation: people living in the US, for example, generally earn more than those outside the country. Their comparatively higher salaries are primarily attributable to the country's economy and are unrelated to their sexual orientation. Thus, this observation cannot be used as a prescription rule to increase salary. 
Our causal analysis, on the other hand, reveals that individuals aged 25-34 with dependents would benefit from working as front-end developers.
This results in a \$44,009 annual salary increase on average. \reva{Another observation is that students should pursue an
undergraduate major in CS. %Computer Science (CS). 
This can boost their salary by \$22,174 per year} (see details in \cref{sec:casestudy}).
\end{example}

%It has been incorporated into various tasks including . 
%Causal interventions are often more relatable and easier to understand, as they offer insight into the underlying reasons behind the recommendations and allow unraveling complex cause-effect relationships that govern our world~\cite{pearl2009causality}. Furthermore, causal interventions often have long-lasting effects~\cite{imbens2024causal}.

%, making it essential that the prescribed actions are not only actionable but also 

%causally consistent. 

%Decision makings, in particular, high-stak

\cut{
In this work, {we study the problem of generating causal insights (referred to as \emph{prescription rules}), which serve as actionable recommendations} to improve an outcome of interest.
Recent works have introduced causality to the field of database research~\cite{meliou2010causality,  meliou2014causality,salimi2020causal,10.14778/3554821.3554902}. It has been incorporated into various tasks including data discovery~\cite{galhotra2023metam,youngmann2023causal}, data cleaning~\cite{pirhadi2024otclean,salimi2019interventional}, and large system diagnostics~\cite{markakis2024sawmill,causalsim,sage, gudmundsdottir2017demonstration}. 
We propose using causal inference to generate prescription rules that are both actionable and justifiable.
}

While generating prescriptions based on causal inference may help in robust decision-making, causal prescriptions that solely consider the betterment of an outcome (like salary) are not enough in practice. 
It is well-known that decision-making in many high-stake applications (like hiring policy, or policy for approving loans by banks) may lead to disparate societal or economic impact on different sub-populations. 
As a shocking example from a recent work called 
%For example, 
CauSumX~\cite{DBLP:journals/pacmmod/YoungmannCGR24} that generates a set of causal explanations for an aggregated view, the explanations generated %by CauSumX %recommendations which 
suggest that male individuals do a Bachelor's degree to increase their salary while %suggesting that 
being an unmarried woman 
%the recommendation for women includes getting married 
has the most adverse effect on salary
(borrowed directly 
from Fig.~19 in~\cite{youngmann2024summarizedcausalexplanationsaggregate}). 
%We demonstrate the advantage of using causal reasoning to generate actionable recommendations and the limitations of not considering fairness requirements in the following example. 
We explored this further in the context of generating prescriptions and observed that prescriptions that are not fairness-aware can generate unfair outcomes to some subpopulations which we refer to as the {\em protected group}. Examples include women, Black, Latino, or Native Americans, individuals with a disability, countries with a weaker economy, or other protected groups specific to an application. %Here is a concrete example:


% Understanding the causal factors behind these recommendations is crucial to ensuring that decisions lead to fair and equitable outcomes, particularly in sensitive applications where biased decisions can perpetuate or even exacerbate societal inequalities.
% While prior work has extensively explored techniques for association rule mining~\cite{kumbhare2014overview}, recent efforts have focused on deriving causal explanations for individual data points or entire datasets~\cite{salimi2018bias,youngmann2022explaining,ma2023xinsight}. Although some of these methods produce causally consistent insights, the absence of fairness considerations in the process can lead to unfair outcomes, further reinforcing existing biases. For example, CauSumX~\cite{DBLP:journals/pacmmod/YoungmannCGR24} generates causal recommendation which suggest male individuals to do a Bachelor's degree to increase salary while the recommendation for women include getting married (borrowed directly from Figure~19 in the paper~\cite{youngmann2024summarizedcausalexplanationsaggregate}). 





%\emph{Causal inference} has been thoroughly studied in AI and Statistics~\cite{pearl2009causal,rubin2005causal}. Causal analysis is a vital tool in determining the effect of a \emph{treatment} on an \emph{outcome}, and has been used in decision-making in medicine \cite{robins2000marginal}, economics \cite{banerjee2011poor}, biology \cite{shipley2016cause}, and in high-stakes areas such as identifying the root causes of failures in critical infrastructure systems to prevent catastrophic outcomes. Recent works have introduced causality to the field of database research~\cite{meliou2010causality,  meliou2014causality,salimi2020causal,10.14778/3554821.3554902}. It has been incorporated into various tasks including data discovery~\cite{galhotra2023metam,youngmann2023causal}, query result explanation~\cite{salimi2018bias,youngmann2022explaining,DBLP:journals/pacmmod/YoungmannCGR24}, and large system diagnostics~\cite{markakis2024sawmill,causalsim,sage, gudmundsdottir2017demonstration}. We propose leveraging causal inference to generate interpretable and justifiable insights (referred to as \emph{prescription rules}), which serve as actionable recommendations to improve an outcome of interest. Causal reasoning is considered one of the most important requirements,  to generate insights that are actionable and aligned with human reasoning.




\begin{table*}[]
\footnotesize
    \centering
    	\caption{\textnormal{A subset of the Stack Overflow dataset.}}
         \label{tab:data}
    	% \vspace{-4mm}
  			\begin{tabular}[b]{|l|l|l|c|l|l|c|l|c|}
  			
				%\multicolumn{9}{c}{\textbf{Users}}\\ 
				\hline

				\textbf{ID}
    
    % \textbf{Country}& \textbf{Continent} 
    
    &\textbf{Gender} &\textbf{Ethnicity}&
				\textbf{Age} &\textbf{Role} &
				\textbf{Education} &\textbf{Country}&\textbf{Undergrad Major}&\textbf{Salary}
				\\ \hline

				1 &Male&White&26&Data Scientist & PhD& US&Computer Science&180k\\
    		2 &Non-binary&White&32&QA developer & Bachelor's degree& US&Mechanical Eng.&83k\\

 3 &Male&South Asian&29&C-suite executive  & Bachelor's degree & India&Computer Science&24k\\

  % 4 &Female&South Asian&25&Back-end developer  & Master's degree & India&Mathematics&7.5k\\

  4 &Female&East Asian&21&Back-end developer & Bachelor's degree & China&Computer Science&19k\\
  

        % $\ldots$ &  $\ldots$&  $\ldots$&  $\ldots$&  $\ldots$&  $\ldots$&  $\ldots$&  $\ldots$&  $\ldots$&  $\ldots$&  $\ldots$\\
    \hline
			\end{tabular}
            \vspace{-5mm}
\end{table*}




\begin{example}	%
\label{example:ex2}
{\bf Importance of fair prescriptions:}
Continuing Example~\ref{example:ex1}, while those causal prescription rules are highly beneficial for the overall population, they are considerably less effective for individuals residing in countries with a low GDP (indicating a weaker economy). For this group, the average expected increase in salary is only approximately \$13,000 per year (in contrast to \$44,009 for the entire group). % \sr{add which rule 44k or 25k} 
Consequently, implementing these rules would exacerbate the disparity between those living in countries with strong economies and those in countries with weaker economies.
\end{example}




% Our objective is to generate a small set of prescription rules aimed at increasing (or decreasing) an outcome of interest. This is framed as an optimization problem where the goal is to select the fewest prescription rules that maximize utility (i.e., the expected increase or decrease in the outcome). However, 

The example above shows that focusing solely on maximizing utility (\revc{i.e., increasing income}) can result in a scenario where only some of the population receive significant improvement, while others experience no benefit (\revc{only a small benefit for individuals from countries with weaker economies in our example}). Additionally, even if a large portion of the population receives recommendations, a protected subpopulation might not share the benefits and, worse, their situation could deteriorate, exacerbating inequalities.

Examples~\ref{example:ex1} and \ref{example:ex2} show that it is crucial to provide recommendations that are (1) {\em causal} for the outcome (beyond associations),  and (2) also {\em fair or equitable} in terms of the outcome for both the protected and non-protected groups. While recent work in database research
has focused on deriving {\em causal explanations} for individual data points, aggregated view, or entire datasets~\cite{salimi2018bias,youngmann2022explaining,ma2023xinsight, DBLP:journals/pacmmod/YoungmannCGR24}, and in particular \cite{DBLP:journals/pacmmod/YoungmannCGR24} has considered generating a set of causal explanations for an aggregated view that resemble a ruleset, 
%Although some of these methods produce causally consistent insights, 
the absence of fairness considerations in generating these causal explanations can lead to unfair outcomes for the protected group.
%further reinforcing existing biases.


%\red{We, therefore, enable users to incorporate various \emph{coverage and fairness constraints} along with the overall objective of improving an outcome of interest. }

\medskip
\noindent
\textbf{Our contributions.~} 
Motivated by the dual goals of generating causal and fair prescriptions for the betterment of an outcome, we introduce a {\em fairness-aware framework leveraging causal reasoning for generating a set of actionable prescription rules (ruleset)} called \sysName\ (\underline{Fair} \underline{CA}usal \underline{P}rescription).
%
Following research on fairness in data management~\cite{stoyanovich2020responsible,galhotra2022causal}, we assume the existence of a \emph{protected subpopulation}, defined by an attribute such as gender or race for people, or GDP of a country. Motivated by the causal explanation rules for an aggregated view \cite{DBLP:journals/pacmmod/YoungmannCGR24}, each prescription rule in our ruleset applies to a sub-population defined by a {\em grouping attribute}, and prescribes a {\em treatment or intervention} to improve the {\em outcome} for this sub-population. Fairness constraints ensure that the expected utility of the protected population is {\em comparable} to the utility of the unprotected individuals. We borrow the notions of \emph{group and individual fairness} from the fairness literature but tailor them for prescription rules. In addition to the fairness constraints, our coverage constraints ensure that a substantial fraction of the population and protected subpopulation receives at least one recommendation. 
%We demonstrate how such constraints ensure that the generated rules apply to a large portion of the population and ensure fairness through the following example.

\begin{example}
\label{ex:intro_example_3}
Continuing Examples~\ref{example:ex1} and \ref{example:ex2}, Alice uses our proposed system, called \sysName, to impose fairness and coverage constraints to discover useful and equitable recommendations for increasing salaries worldwide. In particular,
Alice chooses to implement a coverage constraint to ensure that the selected rules apply to a significant portion of people worldwide, including a sufficiently large number of individuals from countries with low GDP (the protected group). She also imposes a fairness constraint to ensure that the expected gains for both protected and non-protected groups are comparable.
\reva{She discovers, for example, that for individuals with 6-8 years of coding experience (a subpopulation comprising 21\% of the entire dataset and 25\% of the protected group), pursuing a bachelor’s degree in computer science will increase the expected salary by $\$14.9k$ for protected and by $\$17.8k$ for non-protected}. (See \cref{sec:casestudy} for more details.) This prescription rule applies to a large portion of the population and ensures fairness by providing a similar expected gain for both protected and non-protected groups, and the allowed difference of outcomes between these two populations may be adjusted by choosing appropriate thresholds in the fairness definitions. 
\end{example}


\noindent
Our main contributions are as follows. \\
%\begin{itemize}[leftmargin=*,topsep=0pt]
{\bf (1)} We {\bf develop a framework that generates a set of prescription rules to enhance an outcome of interest (Section~\ref{sec:problem})}. A prescription rule consists of a \emph{grouping pattern} and an \emph{intervention pattern}, representing the target subpopulation and the actionable recommendation for that group, respectively. The strength of the {\em conditional causal effect} (Section~\ref{sec:background-causal}) of this intervention on the subgroup is used to measure the expected utility of a rule. Our objective is to identify the smallest set of rules that maximizes overall expected utility. We refer to this problem as the {\em \probName} problem.
We adopt several notions of fairness (individual vs. group, statistical parity vs. bounded group loss) from the literature to define the {\bf fairness constraints} for our problem. In addition, {\bf coverage constraints} (for individual rules or for a group) ensure that the solution for the \probName\ problem is applied to a sufficient number of individuals and to minimize inequalities. We show NP-hardness for different variants of the problems and properties (matroid) useful in our algorithms. 
%We establish several definitions for group and individual fairness constraints tailored for prescription rules.
\smallskip
    \par
    \noindent
{\bf (2)} We {\bf develop a general three-step algorithm named \sysName to solve the optimization problem of selecting a fair prescription ruleset (Section~\ref{sec:algo})}. The first step involves mining frequent grouping patterns using the Apriori algorithm~\cite{agrawal1994fast}. In the second step, we employ a lattice-based algorithm to find high utility and fair intervention patterns for grouping patterns identified in the previous step. Finally, the third step applies a greedy approach to determine a solution. \sysName\ can be easily adapted to accommodate all variants of the \probName\ problem.

\smallskip
\par
\noindent
{\bf (3) We provide a detailed  case study  (Section~\ref{sec:casestudy}) and experimental analysis (Section~\ref{sec:experiments}) to evaluate our framework and algorithms.}
The case study shows the qualitative difference of different variants of our problem for different choices of the fairness and coverage constraints. The experiments include two datasets, three baselines, and 18 variations of our problem with different constraints. Our evaluations suggest that fairness may come at the cost of expected
utility for everyone. However, without fairness constraints, we often observe a significant disparity between the protected and non-protected. We also observe that
achieving individual fairness is harder than group fairness,
as most high-utility or high-coverage rules are unfair. Lastly, we show that \sysName\ can generate  prescription rules over large datasets in a reasonable time. 

%\end{itemize}


%\paragraph*{Paper outline} 
We discuss related work in \cref{sec:related}, review background on causal inference in \Cref{sec:background-causal}, %and our problem formulation can be found in \cref{sec:problem}. Our algorithmic framework is presented in \cref{sec:algo}. A case study demonstrating the impact of different constraint configurations on the solution is given in \cref{exp:problem_variants}, and our experimental evaluation is detailed in \cref{sec:experiments}. Finally, we 
and discuss the limitations of our framework and future work in \cref{sec:conc}.

% \noindent
% \boxed{\parbox{\columnwidth}{$\bullet$ 
% For people with a professional degree, move to the United Kingdom
%  (coverage = 435 (20), coverage-protected = 20 (13), utility = 186855, utility-protected = 0.)\\
% $\bullet$ For graphic developers, move to the	United States
%  (coverage = 116 (29), coverage-protected = 8 (2), utility = 169431, utility-protected = 0).\\
% $\bullet$ For people who have no formal education, move to the United States
%  (coverage = 123 (34), coverage-protected = 7 (2), utility = 206742, utility-protected = 0).\\
% % \textcolor{red}{size = 38, length = 76, overlap = 64029181, utility = 1659307}\\
% \textcolor{blue}{overall coverage =674, expected utility = 187485
% coverage-protected = 35, expected utility-protected = 0}
% \sr{should mention protected group, and possibly not mention coverage in the intro or just intuitively like high coverage}
% }}


% Alice notes that although these rules result in a \$187,485 increase in the overall salary for those to whom they apply, they only affect a small fraction of the population, specifically 674 individuals. Additionally, although the expected salary increase is substantial, there is no expected increase in salary for non-males, a subpopulation of particular interest to Alice. In other words, applying these rules would result in no gain for non-males.
% \end{example}

% \begin{example}[Episode 2 - coverage and fairness constraints]
% Alice introduces coverage and fairness constraints to ensure that enough people will benefit from the rules and that they will be \emph{fair} with respect to non-males. Specifically, she demands that the benefit for a randomly chosen individual to whom one of the rules applies is nearly the same as the benefit for a randomly chosen individual who identifies as non-male and to whom one of the rules applies.

% After adding these constraints, \sysName\ recommends the following set of prescription rules:



% \noindent
% \boxed{\parbox{\columnwidth}{$\bullet$ 
% For people who have no formal education, move to the United States
%  (coverage = 123 (34), coverage-protected = 7 (2), utility = 206742, utility-protected = 0)\\
% $\bullet$ 
% For females, change role to	DevOps specialist (coverage = 2256 (47), coverage-protected = 2256 (47), utility = 90023, utility-protected = 90023).\\
% $\bullet$ For people with a Master's degree, move to the	United States
%  (coverage = 9097 (2222), coverage-protected = 642 (236), utility = 85390, utility-protected = 84201).\\
% % \textcolor{red}{size = 38, length = 76, overlap = 64029181, utility = 1659307}\\
% \textcolor{blue}{overall coverage =11476	
% , expected utility = 87601,
% coverage-protected = 2905, expected utility-protected = 88519}
% }} 







% \begin{figure}[t]
%         \centering
%         \begin{minipage}[b]{1.0\linewidth}
%             \small
%             \begin{tcolorbox}[colback=white]
%             \vspace{-2mm}
% $\bullet$ For backend developers, the treatment with the highest effect on salary is “Country = US” effect size = 78646
% \begin{itemize}
%     \item For non-male the effect is only: 59429
%     \item For male the effect is 80454
% \end{itemize}

% $\bullet$ For frontend developers, the treatment with the highest effect is :Formal Education = Bachelor's degree” effect size: 17340
% \begin{itemize}
%     \item For white the effect is 33464
%     \item For non-white the effect is 15320
% \end{itemize}


% $\bullet$ For people in Europe, the treatment with the highest effect on salary is “DevType = C-suite executive” effect size = 53254
% \begin{itemize}
%     \item For white the effect is 55112
%     \item For non-white 35249
% \end{itemize}



%             \vspace{-2mm}
%             \end{tcolorbox}
%         \end{minipage}%%
%          % \vspace{-4mm}
%         \caption{Set of prescription rules.}
%         \label{fig:so-explanation}
%     \end{figure}
