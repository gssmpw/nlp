\section{Problem Formulation}
\label{sec:problem}

We consider a single-relation database over a schema $\attrset$. The schema is a vector of attribute names, i.e., $\attrset {=} (A_1, \ldots, A_s)$, where each $A_i$ is associated with a domain $\dom(A_i)$, which can be categorical or continuous. 
A database instance \db, populates the schema with a set of tuples $t {=} (a_1, \ldots, a_s)$ where $a_i {\in} \dom(A_i)$. We use $t[A_i]$ to denote the value of attribute $A_i$ of tuple $t$.  

\newtextold{Our high-level goal is to return a set of {\em prescription rules} (ruleset) with certain desired properties including fairness. In this section, first we define patterns on attributes, protected groups, prescription rules, and discuss the desired properties, finally defining our optimization problem in \Cref{subsec:problem}.}

\subsection{Pattern and Protected Group}
\label{subsec:rules}
To define the notion of \emph{prescription rules}, we build upon the commonly used concept of \emph{patterns}~\cite{roy2014formal,wu2013scorpion,el2014interpretable,lin2021detecting}.
\revc{Patterns are commonly used  in query result explanation research~\cite{roy2014formal,wu2013scorpion,el2014interpretable,lin2021detecting}. Generally, patterns are equivalent to the WHERE clause in SQL queries. However, in this work, we focus on a specific type of pattern: a conjunction of predicates, as has been done in prior query result explanation research~\cite{roy2014formal,wu2013scorpion,el2014interpretable,lin2021detecting,DBLP:journals/pacmmod/YoungmannCGR24}.}


% A pattern comprises {\em conjunctive predicates} on attribute values, and is defined as follows:  

\begin{definition}[Pattern]\label{def:pattern}
Given a database instance \db\ with schema \attrset,
a predicate is an expression of the form $\varphi {=} A_i ~{\tt op }~ a_i$, 
where $A_i {\in} \attrset$, 
$a_i {\in} \dom(A_i)$, and ${\tt op} {\in} \{=,\neq, <, >, \leq, \geq\}$.  
A {\em pattern} is a conjunction of predicates $\pattern {=} \varphi_1 \land \ldots \land \varphi_k$. 
\end{definition}

\begin{example}
  An example pattern over the Stack Overflow dataset (\cref{tab:data}) is $\pattern =$\verb|{Role = Designer| $\land$ \verb|Country = US}|. It defines a subset of the dataset comprised of designers from the US. 
\end{example}
 
Next we define {\em coverage} of a pattern $\pattern$ defined by the number of tuples from $\db$ that it captures.
\begin{definition}[Coverage of a pattern]\label{def:coverage}
Given a database instance \db\, a pattern $\pattern$, and a tuple $t {\in} \db$, $\pattern$ is said to {\em cover} $t$ if $t$ satisfies the predicates in $\pattern$. 
The subset of tuples in $\db$ covered by $\pattern$ 
%(\red{namely, $\pattern(\db)$}) 
is denoted by 
$\coverage(\pattern)$.
%$\pattern(\db)$.
\end{definition}



As is common in fairness research~\cite{stoyanovich2020responsible,zehlike2017fa,caton2024fairness}, we assume the presence of a protected group, defined by the pattern $\pattern_p$. The remainder of the population (i.e., $\db {\setminus} \pattern_p(\db)$) is referred to as the non-protected group.
A protected group in the Stack Overflow dataset may be defined based on sensitive attributes such as age or ethnicity. For instance, it could be defined as $\pattern_p = \{$ \verb|Ethnicity|$\neq$ \verb|White|$\}$ to refer to non-white individuals.


\subsection{Prescription Rules}
%\paragraph*{Prescription Rules}
A \emph{prescription rule} outlines an \emph{intervention} \newtextold{({\em treatment})} designed to improve a target variable within a particular subpopulation. For example, a prescription rule might recommend that people under 25 pursue a Ph.D. to increase their salary. 
Before defining perception rules, we first discuss \newtextold{how attributes participate in such rules}.


\paragraph*{Mutable and immutable attributes}
We assume the attributes $\attrset$ are partitioned into two disjoint sets. The first set contains the interventional attributes (e.g., programming language, education), which are the attributes that can be changed to improve the outcome. The second set contains immutable attributes (e.g., age, gender), which cannot be changed \newtextold{through prescription}. 
Formally, let $\immutable \subseteq \attrset$, denote the set of immutable attributes and $\mutable \subseteq \attrset$ denote the set of mutable (interventional) attributes, where $\mutable \cap \immutable = \emptyset$ and the outcome $O \notin \mutable \cup \immutable$. 
%\sg{This paragraph is messing with Lemma 3.1 because positivity is required for estimation not for "ground truth rules".}
%\brit{I'm not sure what you mean. Please go ahead and rewrite it}
\newtextold{This categorization 
%captures the fact that 
intends to prohibit the infeasible or impractical recommendations to increase the outcome (e.g., changing one's age or ethnicity to improve one's income). }


 

%\vspace{1mm}
\newtextold{Our prescription rules defined below as a combination of grouping and intervention patterns are motivated by the causal explanations defined in \cite{DBLP:journals/pacmmod/YoungmannCGR24}. However, the focus of this paper is to study the interplay between utility and fairness of a ruleset that was not considered in \cite{DBLP:journals/pacmmod/YoungmannCGR24}. As a result, the specific objectives and optimization problem are defined differently as discussed next.
%Similar to a \cite{DBLP:journals/pacmmod/YoungmannCGR24},
%\sr{intervention pattern?} \brit{I like this name and it highlights the difference from causmx}

\begin{definition}[Prescription Rule and Ruleset, Grouping and intervention patterns, and Coverage]
Given a database $D$ with mutable attributes $\mutable$ and immutable attribute $\immutable$, 
a {\em prescription rule} $r$ is a pair of patterns $r = (\patterngroup, \patterninterv)$, where (1) $\patterngroup$ is called the  {\em grouping pattern} and consists exclusively of the immutable attributes in $\immutable$, and (2)  $\patterninterv$ is called the {\em intervention pattern} and consists exclusively of the mutable attributes in $\mutable$. 


By overloading notations, $\coverage(r) = \coverage(\patterngroup)$ is called the {\em coverage of rule $r$} since it captures the subset of tuples in $\db$ on which the rule $r$ applies, i.e., each tuple $t\in \db$ is either \emph{covered} or not by $\patterngroup$ of rule $r$. 
$\patterninterv$ defines the recommended intervention in the prescription rule aimed at betterment of the outcome $O$ for the subgroup that $\coverage(r)$ defines.
%$\coverage(\patterngroup)$. 

Given a set of prescription rules $R$ (called a ruleset), $\coverage(R) = \cup_{r \in R} \coverage(r)$, i.e., coverage of a ruleset corresponds to the subset of tuples in $\db$ that are covered by at least one of the rules in $R$.
%A grouping pattern is a pattern that consists exclusively of the immutable attributes in $\immutable$.  

%A {\bf treatment pattern} 

%A pair of grouping and treatment pattern $(\patterngroup, \patterninterv)$ together define a {\bf prescription rule}.  Intuitively, $\patterngroup$ specifies the subpopulation of interest, whereas $\patterninterv$ denotes the intervention aimed at enhancing the outcome $O$ within that subgroup. 
\end{definition}


%\sr{please check the updated defn, added cov(r) and cov(R)}

For a prescription rule $r = (\patterngroup, \patterninterv)$,  the intervention pattern $\patterninterv$ partitions the tuples defined by $\patterngroup$ into treated ($T = 1$ if $\patterninterv$ evaluates to true for a tuple) and control groups ($T = 0$ if $\patterninterv$ evaluates to false). This partition is then used to assess the causal effects of the intervention $\patterninterv$ on the outcome $O$ within the subpopulation $\coverage(r)$ which the rule $r$ applies to.  
%$\patterninterv$ is defined over the dataset $\db$ and 
%A treatment pattern consists exclusively of the mutable attributes $\mutable$.
}

\newtextold{
%\sr{add the patt}
\begin{example}
An example prescription rule suggests that individuals aged 25-34 with dependents, should work as front-end developers. %Applying this rule is expected in a \$44,009 annual salary increase for the relevant subpopulation. In this case, the grouping pattern identifies the relevant subpopulation %(individuals aged 25-34 with dependents)
($\patterngroup: \texttt{age = 25-34} \land \texttt{dependents = yes}$), the intervention is working as front-end developers ($\patterninterv: \texttt{role = {frontend developer}}$). The expected CATE value is \$44,009, namely, the expected salary increase for a 25-34-year-old individual with dependents working as a frontend developer is \$44,009 per year (compared to a 25-34-year-old individual with dependents working in a different role).
\end{example}
}
% \sr{check patterns}

% \newtextold{In the following subsections, we discuss some desired properties of a prescription ruleset.}
%\sr{bold or em in defn - consistent}

% \sg{When I checked CausumX for an example for this definition I noticed something: The Pt in causumX says Age $<$35 and education=masters. This means that if all individuals get younger then income is high. This is not a valid prescription for us right? Should we define admissible constraints on attributes as the set of possible interventions on each attribute. Then we would define Pt as a pattern over those? 
% Right now, prescription rule gives an image that it allows to intervene on anything.}





\subsection{Utility of a Prescription Ruleset}
\label{subsec:utility}
\newtextold{{\bf Utility of a single rule:} To evaluate the effectiveness of a prescription rule $r = (\patterngroup, \patterninterv)$ toward improving the outcome $O$, we define its utility. The utility measures the expected impact (as CATE) of the recommended intervention on the outcome $O$ within the subpopulation $\coverage(r)$ where $r$ applies to. 
%defined by the grouping pattern, as per the CATE value.
We define the overall utility, and utility for the protected and non-protected groups.
%To assess the effectiveness of a rule $r = (\patterngroup,\patterninterv)$ concerning a protected group $p$, denoted by $utility_p(r)$, we gauge the rule's effectiveness by adding $\pattern_p$ alongside $\patterngroup$ into the condition. Namely, we asses the change of $O$ after applying the intervention $\patterninterv$ only within the protected individuals among the subpopulation defined by $\patterngroup$. 
%Formally: 
%$$utility_p(r) {:=} CATE_{\model}(\patterninterv, O~|~\patterngroup \land \pattern_p)$$

%Similarly, the effectiveness of a rule $r = (\patterngroup,\patterninterv)$ concerning the non-protected individuals $\bar{p}$ is denoted by $utility_{\bar{p}}(r)$, and computed as follows:
%$$utility_{\bar{p}}(r) {:=} CATE_{\model}(\patterninterv, O~|~\patterngroup \land \pattern_{\neg p})$$





\begin{definition}[Utility of a prescription rule - overall, protected, non-protected]\label{def:utility}
Given a database instance \db\ with schema \attrset, an outcome variable $O$, a causal model \model\ on \attrset, % associated with a causal DAG, 
a protected group $p$ defined by a pattern $\pattern_p$, and a prescription rule $r =( \patterngroup, \patterninterv)$,
\begin{enumerate}
    \item the {\em overall utility} of $r$ is defined as:
\begin{equation}
    utility(r) {:=} CATE_{\model}(\patterninterv, O~|~\patterngroup)
    \label{eq:utility-overall}
\end{equation}
\item the {\em  utility of $r$ for the protected group} $p$ is defined as:
\begin{equation}
utility_p(r) {:=} CATE_{\model}(\patterninterv, O~|~\patterngroup \land \pattern_p)    \label{eq:utility-protected}
\end{equation}
\item the {\em  utility of $r$ for the non-protected group} $p$ is defined as:
\begin{equation}
utility_{\bar{p}}(r) {:=} CATE_{\model}(\patterninterv, O~|~\patterngroup \land \pattern_{\neg p})\label{eq:utility-non-protected}
\end{equation}
\end{enumerate}

The subscript $\model$ denotes that the CATE is estimated using the causal model, \newtextold{and we drop the subscript when it is clear from context.}

If $\coverage(r) = \coverage(\patterngroup) = \emptyset$, i.e., if the rule does not apply to any tuple in $D$, then we assume that $utility(r) = 0$; similarly $utility_p(r) = 0$ if $\coverage(\patterngroup \land \pattern_p) = \emptyset$, and $utility_{\bar{p}}(r) = 0$ if $\coverage(\patterngroup \land \pattern_{\neg {p}}) = \emptyset$.
\end{definition}
}

% \sr{added if coverage is empty}

\newtextold{The goal of prescription rules is to improve the outcome $O$ as desired. }
If the goal is to increase the outcome $O$ (e.g., increase salary), we discard rules with negative utility, as they do not help achieve this objective. Similarly, if the aim is to decrease the outcome, we ignore rules with negative utility. Throughout the paper, without loss of generality, we assume that the goal is to increase the outcome, thereby focusing on maximizing utility. 



%\sr{need some context and a paragraph heading here.. not connected to previous paragraph.} 




\cut{
Furthermore, it is necessary to ensure that the positivity assumption is met (see \cref{sec:background-causal}). 
\newtextold{Note that the grouping pattern $\patterngroup$ can only comprise immutable attributes and intervention patterns $\patterninterv$ can only comprise mutable attributes.}
\sr{commented out the next paragraph - but then what.}
}

\cut{
Given a prescription rule $r = (\patterngroup, \patterninterv)$, \red{if the attributes used
to define the grouping pattern $\patterngroup$ are also used to define the intervention pattern $\patterninterv$, either the control or treatment group might be empty}. \sr{this cannot be possible -- one from mutable other immutable -- this paragraph should go} For example, assume $\patterngroup = $ \verb|{County = US}|, which defines the subpopulation of people residing in the US. Setting the intervention pattern $\patterninterv$ to include the attribute \verb|Country| will may lead the intervention being empty (e.g., if $\patterninterv = $\verb|{Country = China}|, as the set of people leaving in China among people from the US is empty). If on the other hand, $\patterninterv$ contains, among other predicates, the predicate \verb|{County = US}|, then this predicate can be removed from $\patterninterv$ without affecting its definition of control and treatment groups (as both the treatment and control group includes only people from the US). 
}

% \noindent
% \smallskip

\newtextold{
\textbf{Prescription to individuals when multiple rules apply:}} 
\newtextold{When dealing with a ruleset $R$, it is possible for multiple rules to apply to the same subpopulation. Specifically, if two rules $r_i {=} (\patterngroup^i, \patterninterv^i)$ and $r_j {=} (\patterngroup^j,\patterninterv^j) {\in} R$ share a non-empty intersection between their coverage, namely $\coverage(\patterngroup^i) {\cap} \coverage(\patterngroup^j) {\neq} \emptyset$, then the subpopulation defined by the pattern $\patterngroup^i {\wedge} \patterngroup^j$ will have more than one rule. 
}
In our definition below for utility of a ruleset, we refrain from applying more than one rule to a subpopulation for two reasons. First, two rules may conflict with each other. For instance, if one rule suggests individuals above \newtextold{25 to earn a Ph.D.}, while another \newtextold{recommends women over 20 pursue an MBA}, 
%an bachelor's degree, 
women above 25 would receive conflicting recommendations. %\sr{these two examples are not conflicting.. MBA vs. PhD is conflicting.}.
Second, CATE is known to be non-monotonic~\cite{DBLP:journals/pacmmod/YoungmannCGR24}, implying that appending a predicate to an intervention pattern can either increase or decrease the CATE value.
% For instance, consider a grouping pattern $\patterngroup$ as the pattern selecting individuals from the US. With the intervention pattern $\pattern_{t_1} = $\verb|(role = QA)|, adding the pattern \verb|(education = MA)| increases the CATE value, while it decreases upon adding the pattern \verb|(education = no degree)|. 
%\sr{this should be a concrete example with data or a citation to causumx}
\newtextold{
Therefore, employing multiple rules simultaneously for a subpopulation might yield a utility gain smaller than the individual rules. Hence when multiple rules apply to a tuple in $\db$, we assume that only one is chosen by the decision-maker.
%The choice of which rule to enact is upto the decision-maker.
}
%that of the least beneficial relevant prescription rule for this subpopulation.




%\subsubsection{Utility in the presence of multiple rules}
\noindent
\smallskip
\newtextold{{\bf Utility of a ruleset:} For a prescription ruleset $R$, we use its {\em expected utility} on $\db$ as the utility of $R$.}

\newtextold{
\begin{definition}[Expected Utility of a Ruleset]\label{def:expected-utility}
    %\textbf{Expected Utility}: We evaluate t
    The {\em expected utility} of a prescription ruleset $R$ is defined as the %by calculating the 
    average maximum utility of an individual from $\coverage(R)$ from the rules in $R$ that applies to the individual, i.e.,  
% of those who received a recommendation (i.e., at least one rule from $R$ is applied for them). 
\begin{equation}
    \text{ExpUtility}(R) = \frac{1}{n} \sum_{t \in \coverage(R)} \max_{r \in R_t} (\text{utility}(r))
\label{eq:exp-utility-all}
\end{equation}

where $R_t \subseteq R$ denotes the set of rules covering the tuple $t$, and $n = |\db|$. Note that if a rule does not apply to a tuple, its utility is zero, so the sum above is also over all $t \in D$. 
%\sr{should be $n = |\coverage(R)|$? otherwise please explain why divided by n.}
%\sg{How about we name it "Post-intervention utility of D wrt R".}


Given a protected pattern $\pattern_p$, the expected utility for the protected and non-protected groups are defined as follows:
\begin{eqnarray}
    \text{ExpUtility}_p(R) & = &  \frac{1}{n_p} \sum_{t \in \coverage_p(R)} \min_{r \in R_t} (\text{utility}(r)) \label{eq:exp-utility-protected}\\
    \text{ExpUtility}_{\bar{p}}(R) & = & \frac{1}{n_{\bar{p}}} \sum_{t \in \coverage_{\bar{p}}(R)} \max_{r \in R_t} (\text{utility}(r)) \label{eq:exp-utility-non-protected}
\end{eqnarray}
where $\coverage_p(R)$ denotes the set of protected individuals covered by $R$ and 
%$n_p = |\pattern_p(\db)|$ 
$n_p = |\coverage_p(R)|$
(similarly $\coverage_{\bar{p}}()$ and $n_{\bar{p}}$).
\end{definition}
}

\cut{
Similarly, we define the expected utility for the protected group by calculating the expected utility for a randomly sampled protected individual:
\[
\text{ExpUtility}_p(R) = \frac{1}{n_p} \sum_{t \in coverage_p(R)} \min_{r \in R_t} (\text{utility}(r))
\]
where $coverage_p()$ denotes the set of protected individuals covered by a set of rules $R$ and $n_p = |\pattern_p(\db)|$.


In a similar manner, we define the expected utility for a randomly sampled non-protected individual, referred to as the expected utility of non-protected.
}

\cut{Our goal is to generate a prescription ruleset $R$ where the outcome is fixed across all rules (e.g., all rules aim to increase salary). These rules may overlap, but they all target the same outcome variable. }

\newtextold{
Note the difference between formulas (\ref{eq:exp-utility-protected}) and (\ref{eq:exp-utility-all}, \ref{eq:exp-utility-non-protected}).
Since we do not assume any restriction on which rule is chosen for a tuple when multiple rules apply, we do a conservative worst-case analysis on fairness.
We assume that protected individuals choose the worst possible rule, while the rest choose the best possible one. This ensures that the expected utility for the protected group in reality (irrespective of the rule chosen for each protected tuple) will be at least as high as the expected utility from the least beneficial relevant prescription rule for this group.
}


% \sr{I do not follow this argument - should the rule with the higher utility be selected? how selecting arbitrarily guarantees ``at least''?}


\subsection{Size of a Prescription Ruleset}\label{subsec:size}

\cut{
%\sr{this section can be blended with other subsections}
Given an outcome variable $O \in \attrset$ (e.g., salary), our goal is to find a set of prescription rules to increase $O$ for all individuals and ensure that the protected group will ultimately be in a better condition than before applying the rules (a fairness constraint). We favor sets with a small number of effective rules, that apply to a large portion of the population (coverage constraint). We begin by discussing the size and utility objectives. We then introduce the coverage and fairness constraints. Finally, we present our problem definition.  


% the unconstrained version of our problem, where the goal is simply to find a small number of effective rules. We then discuss different variants of fairness and coverage constraints (in Section \ref{sec:fariness_coverage}).


Given a set $R$ of prescription rules, we define its size and expected utility as follows. 

\noindent
\textbf{Size}:
}
\newtextold{The size of a prescription ruleset is the number of rules in that set, denoted by $size(R)$. Ideally, we want to find a small-size ruleset. The intuition is that, }
%we consider the size of the prescription rules set itself. 
the fewer the rules in a set, the easier it is to understand the suggested interventions. %We denote by $size(R)$ the number of rules in a rule set $R$. 
\newtextold{Suppose we want to find a ruleset with high utility without specifying a constraint on the size. The following lemma shows that the best strategy is to return the {\em optimal rule} that applies to each individual.}
\newtextold{That is, to maximize utility, prescribing a personalized rule for each individual may lead to the best utility. Specifically, }
we can show that for every rule $r = (\patterngroup, \patterninterv)$, there exists a subgroup $g' {\subseteq} \coverage(\patterngroup)$ and a intervention $\pattern_{t'}$ s.t the utility of  $r' {=} (g', \pattern_{t'})$ is greater than that of the original rule $r$. 

% \sr{added proved - is the proof there?}
% \sr{this $g'$ cannot be arbitrary subset, it has to be defined by a grouping pattern. Brit / Sainyam: can one of you please make a pass on this paragraph up to Lemma 4.1?}

\begin{lemma}
\label{lemma:individual_rules}
   Given a rule $r {=} (\patterngroup, \patterninterv)$, there exists a rule $r' {=} (\pattern_{g'}, \pattern_{t'})$ s.t $\pattern_{g'} {\subset} \coverage(\patterngroup)$ and $utility(r') {\geq} utility(r)$. 
\end{lemma}



% \sr{Brit/Sainyam please do a pass on the following paragraphs, and making the lemma less abstract and mentioning individuals?}


% As suggested by Lemma \ref{lemma:individual_rules}, the optimal solution might involve assigning a unique rule to each individual. To mitigate this (as it is impractical), we seek to minimize the number of recommended rules. 


% One approach is to impose a strict limit on the number of rules selected. However, pre-setting this size constraint often requires tuning to balance utility and comprehensibility. Therefore, we incorporate the number of rules as an objective, considering rule sets with fewer rules to be more desirable, as was done in \cite{lakkaraju2016interpretable}.



% \noindent
% \textbf{Length}: We consider the size of each rule in a rule set $R$. If the number of predicates in the patterns of a rule $r \in R$ is too large, it will lose its natural interpretability. We use the term length to measure the size of a rule.
% Given a prescription rule $r = (\patterngroup, \patterninterv)$, let $length(r)$ denote the number of predicates in both $\patterngroup$ and $\patterninterv$. Namely, $length(r) := |\patterninterv|+ |\patterngroup|$, where $|\pattern|$ denotes the number of predicates in the pattern.

% \noindent
% \textbf{Overlap}: We measure whether two rules are suggested for the same subpopulation or not. Given two prescription rules $r_1 = (\patterngroup^1, \patterninterv^1), r_2 = (\patterngroup^2, \patterninterv^2)$, $overlap(r_1,r_2)$ denotes the set of tuples that satisfy both $\patterngroup^1$ and $\patterngroup^2$. Formally,
% $overalp(r_1,r_2) := coverage(\pattern_1) \cap coverage(\pattern_2)$.



% \noindent
% \textbf{Coverage}: We consider the overall number of tuples covered by a set of rules $R$. Formally, $Coverage(R) := |\bigcup_{r \in R} coverage(r)|$.
% \sg{Question to discuss: Should we define Expected utility over the population? Reason: Fairness definition}

%\sr{make a combined definition wit hthree equations.}


% \begin{proof}[Proof of Lemma \ref{lemma:individual_rules}]
% The utility of a rule $r$ denotes the expected increase in outcome $O$ when all individuals within the subgroup $\patterngroup$ are treated with $\patterninterv$. 
% \begin{eqnarray*}
%     utility(r) &=& \frac{1}{|\patterngroup|} \sum_{i\in coverage(\patterngroup)} utility_i(\patterninterv)
% \end{eqnarray*}
% where $utility_i(\patterninterv)$ denotes the utility for tuple $i$ with respect to treatment $\patterninterv$. Since, utility(r) is an average over multiple different utilities, the utility will be higher than the expected value for certain tuples in $coverage(\patterngroup)$.
% Let $i^* = \arg \max utility_i(\patterninterv)$.

% Consider a new prescription rule $r' (i^*,\patterninterv)$ which considers the same treatment $\patterninterv$ for the tuple $i^*$. Therefore,
%     $utility(r') = utility_i(\patterninterv) > utility(r)$.
% \end{proof}
    
\newtextold{This property implies that the number of prescription rules in the optimal solution is $O(|D|)$, making it impractical to implement in real-world scenarios. For instance, consider a policy enacted by a government official to allocate healthcare resources based on patient data. If the number of rules scales linearly with the size of the dataset, it would become infeasible to apply the policy effectively across a large population. }
Therefore, we limit the number of recommended rules.
One approach is to impose a strict limit on the number of rules selected. However, pre-setting this constraint often requires tuning to balance utility and comprehensibility. Therefore, we incorporate the number of rules as an objective, considering rulesets with fewer rules to be more desirable, as was done in \cite{lakkaraju2016interpretable}.


% % , as it implies that the optimal approach may involve assigning individual rules to each person. 
% \sr{use/context not clear yet}
% \sg{Changed but example needs to be linked to the intro example ideally}

% \sr{Brit/Sainyam please update up to here ................}

\cut{
\vspace{1mm}
\noindent
\textbf{Rule selection}:
As outlined in \cref{subsec:utility}, when multiple rules apply to an individual, we assume they choose only one. For worst-case analysis, we assume that non-protected individuals select the worst possible rule, while the rest choose the best possible one (using min for protected expected utility calculation and max for expected utility and non-protected expected utility calculation). 

\sr{read up to here}
}

\subsection{Coverage Constraints}
\label{subsec:coverage_constraint}
We consider two types of coverage constraints: \emph{group coverage}, where the goal is to find a solution that covers a predefined fraction of protected individuals and a certain fraction of the entire population, and \emph{rule coverage}, where every selected rule must cover a certain fraction of the population and protected individuals.\\
\noindent
{\bf{Group Coverage}} Given two thresholds $\theta, \theta_p {\in} [0,1]$, we say that a ruleset $R$ satisfies the group coverage constraint if $R$ covers at least a $\theta$ fraction of the population, and a $\theta_p$ fraction of the protected subpopulation. Formally, both conditions are satisfied: (i) $Coverage(R) {\geq} \theta {\cdot} |\db|$, (ii) $Coverage_p(R) {\geq} \theta_p {\cdot} |\pattern_p(\db)|$, 
where $Coverage_p(R)$ denotes the number of covered protected individuals by $R$. \\
\noindent
{\bf Rule Coverage}
 Given two thresholds $\theta, \theta_p {\in} [0,1]$, we say that a ruleset $R$ satisfies the rule coverage constraint if every rule $r {\in} R$ covers at least a $\theta$ fraction of the population, and at least a $\theta_p$ fraction of the protected subpopulation. Formally, both of the following conditions hold: (i) For every $r {\in} R$: $coverage(r) {\geq} \theta {\cdot} |\db|$, (ii) For every $r {\in} R$: $coverage_p(r) {\geq} \theta_p {\cdot} |\pattern_p(\db)|$,
where $coverage_p(r)$ denotes the number of covered protected individuals by $r$. 



\subsection{Fairness Constraints}
\label{subsec:fairness_constraint}
% \sr{see if this section can be made more compact.}
We study two definitions of fairness: statistical parity (SP)~\cite{mehrabi2021survey}, and bounded group loss (BGL)~\cite{agarwal2019fair}. Those definitions are based on equivalent notions of fairness for regression tasks~\cite{agarwal2019fair}. We next provide an extension for these definitions to causal estimates. 



Group and individual fairness are two key concepts in algorithmic fairness~\cite{stoyanovich2020responsible,binns2020apparent,garcia2021maxmin}. Group fairness aims to ensure that different groups receive similar outcomes. Individual fairness focuses on treating similar individuals similarly, meaning that if two individuals are alike in relevant aspects, they should receive similar outcomes. Both approaches aim to reduce bias, with the choice of which approach to adopt depending on the specific context.
Next, we present four types of fairness constraints: SP and BGL, each of which can be applied to ensure group or individual fairness.





\subsubsection{Statistical parity}
In SP, the goal is to ensure that the gain in the utility of a protected individual is similar to that of any individual from the non-protected group.


\noindent
\textbf{Group Fairness}:
Intuitively, if we randomly sample a protected individual, the expected gain should be almost the same as that of an individual from the non-protected group.
Formally:\\
$|\text{ExpUtility}_p(R) {-}\text{ExpUtility}_{\bar{p}}(R)| {\leq} \epsilon$,
 where $\epsilon {>} 0$ is a threshold. 

\vspace{1mm}
\noindent
\textbf{Individual Fairness}:
Individual fairness says that the expected gain of every protected individual is similar to that of an individual from the non-protected group. That means that the expected utility of each rule $r{\in} R$ on a protected individual should be similar to that of an individual from the non-protected group.
Formally, for every $r{\in} R$,
$|utility_p(r) {-} utility_{\bar{p}}| {\leq} \epsilon$, where $\epsilon {>} 0$ is a threshold.

% We can demonstrate that the statistical parity fairness constraint is not a matroid constraint; however, it is a matroid constraint for individual parity. 

% \begin{lemma}
% \label{lemma:sp}
% The statistical parity fairness constraint is not a matroid constraint; however, it is a matroid constraint for individual parity. 
% \end{lemma}
% \begin{proof}
% To show that the statistical parity  fairness constraint is not a matroid, we construct a simple counter example. 

% Consider a dataset $D$ with $50\%$ individuals belonging to the protected group.
% Consider a rule set $R = \{r_1,r_2\}$ such that $coverage(r_1) = \pattern_p$  and  $coverage(r_2) = \pattern_{\bar p}$ and $\text{ExpUtility}_p(r_1) = \text{ExpUtility}_{\bar p}(r_2)  = 100$. This means that the set $R$ is fair. 

% Suppose the statistical parity fairness constraint is a matroid. In that case, any subset of $R$ should also yield a fair prescription. Consider a subset $R' = \{r_2\} \subset R$. 
%  $\text{ExpUtility}_p(r_2) = 0$ and $\text{ExpUtility}_{\bar p}(r_2)  = 100$. Therefore, the $r_2$ alone does not satisfy fairness wrt statistical parity, which is a contradiction.
% \end{proof}


% \begin{table}[]
%     \centering
%  \begin{tabular}{|c|c|c|c|}
% \hline
% G & P & T & O \\
% \hline
% 1 & 1 & 0 & \$0 \\
% 1 & 1 & 0 & \$0 \\
% 1 & 0 & 1 & \$1 \\
% 1 & 0 & 1 & \$1 \\

% 0 & 1 & 1 & \$1 \\
% 0 & 1 & 1 & \$1 \\
% 0 & 0 & 0 & \$0 \\
% 0 & 0 & 0 & \$0 \\

% \hline
% \end{tabular}
%     \caption{Example Dataset for Lemma~\ref{lemma:sp}}
%     \label{tab:sp_ex}
% \end{table}


% \begin{proof}[Proof of \cref{lemma:sp}]
% We show that the hereditary property does not hold, and therefor it follows that this is not a matroid. 

% Consider a dataset $\db$ with a schema $\attrset = \{G,P, T, O\}$ populates with $2n$ tuples. 
% For the first $n$ tuples, we assign $t[G] = 1$. In the first half of these tuples we set: $t[P] = 1$, $t[T] = 0$, and $t[O] = 0$, while in the second half, $t[P] = 0$, $t[T] = 1$, and $t[O] = 1$. For the remaining $n$ tuples, the first $\frac{n}{2}$ have $t[P] = 1$, $t[T] = 1$, and $t[O] = 1$, and the rest have $t[P] = 0$, $t[T] = 0$, and $t[O] = 0$.
% The protected group is defined by the pattern $\pattern_p = \{P = 1\}$, indicating that there are precisely $n$ tuples where $t[P] = 1$. 

% An illustration of this dataset with 8 tuples is provided in \cref{tab:sp_ex}.


% Consider the following  prescription rules:
%     \begin{itemize}
%         \item \textbf{(A rule that is useful to only non-protected)} $r_1 = (\patterngroup^1, \patterninterv^1)$:, where $\patterngroup^1 = \{G = 1\}$ and $\patterninterv^1 = \{T = 1\}$. We have: $coverage(r_1) =n$, $coverage_p(r_1) = \frac{n}{2}$, $utility_p(r_1) = 0$, and $utility_{\hat{p}}(r_1) = 1$. 
%         \item  \textbf{(A rule that is useful to only protected)}:  $r_2 =(\patterngroup^2, \patterninterv^2)$, where $\patterngroup^2 = \{G = 0\}$ and $\patterninterv^2 = \{T = 1\}$.
%         We have: $coverage(r_2) =n$, $coverage_p(r_2) = \frac{n}{2}$, $utility_p(r_2) = 1$, and $utility_{\hat{p}}(r_2) = 0$.
%     \end{itemize}

% We get that $overlap(r_1, r_2) = 0$, meaning the rules do not overlap as they pertain to different individuals. Additionally, $r_1$ and $r_2$ cover the entire population.
% For the rule set $R = {r_1, r_2}$, the statistical parity fairness constraint is met: for a randomly selected protected individual, the expected utility increase is $0.5$ (half get an increase of $1$ and the other half get no increase). Similarly, the expected utility increase for non-protected individuals is also $0.5$. However, when considering any non-empty subset $R'$ of rules from $R$, $R'$ does not satisfy the constraint, as the expected utility for one population will be $0$ and for the other, it will be $0.5$.
% \end{proof}


\subsubsection{Bounded group loss (BGL)}: Fair regression with BGL minimizes the overall loss while controlling the worst loss in the protected group~\cite{agarwal2019fair}.
In our context, this translates to the following constraint: When selecting an individual from the protected group, the utility increase should exceed a specified threshold $\tau {\geq} 0$.

\noindent
\textbf{Group Fairness}: We aim to ensure that the expected utility of a randomly sampled protected individual within $Coverage(R)$ is above a given threshold $\tau$.
Formally,
$\text{ExpUtility}_p(R) {\geq} \tau$.

\smallskip
\noindent
\textbf{Individual Fairness}: We aim to ensure that the gain of every protected individual from $Coverage(R)$ exceeds a threshold $\tau$.
Therefore, a ruleset $R$ satisfies the individual loss constraint if the utility of every rule $r$ on protected individuals is at least $\tau$. Formally, for every rule $r{\in} R$, $utility_p(r) {\geq} \tau$.



% Here again, we can demonstrate that the BGL fairness constraint
% is not a matroid constraint; however, it is a matroid constraint for
% individual loss.




% \begin{lemma}
% \label{lem:bgl}
% The BGL fairness constraint is not a matroid, but it is for individual loss.  
% \end{lemma}
% \brit{add proof}




\subsection{The \probName\ Problem}\label{subsec:problem}
We are finally ready to present the problem we study in this paper. If we did not have \newtextold{{\em fairness or coverage constraints}}, then our goal is to select a small-size perception ruleset \newtextold{with high expected utility.} 
\newtextold{However, as demonstrated in the introduction, %a solution to the \probName\ problem 
not considering fairness constraints may result in a ruleset that are only highly beneficial to %only apply to 
a small, non-protected subset of the population. Therefore, we extend our problem definition to include coverage and fairness constraints.  
We can apply any of SP or BGL group or individual fairness constraints  (\Cref{subsec:fairness_constraint}), as well as rule or group coverage constraints \Cref{subsec:coverage_constraint}), along with no fairness or coverage constraints, resulting in 18 distinct problem variants. The choice of which constraints to apply is left to the user as it may be application-dependent, and is discussed below. To define the generic problem, we use $R {\models} \fairnessconstraints$ and $R {\models} \coverageconstraints$ to denote that a ruleset $R$ satisfies a given fairness constraint $\fairnessconstraints$ and a given coverage constraint $\coverageconstraints$ respectively (if no constraints are given, these conditions are trivially satisfied). 
We assume that a set of candidate rules $\{r_i\}_{i=1}^l$ has been already mined and is available as an input to the problem.}
%that maximizes expected utility. Formally,

\newtextold{
\begin{definition}[\probName\ under fairness and coverage constraints]
%[The \probName\ problem]
\label{def:problem}
Given a database $\db$, a causal model \model, an outcome attribute $O$, a fairness constraint $\fairnessconstraints$, a coverage constraint $\coverageconstraints$, and a collection of prescription rules $\{r_i\}_{i=1}^l$, a subset $R {\subseteq} \{r_i\}_{i=1}^l$ of prescription rules is called {\em valid} if (1) $R \models \fairnessconstraints$ and (2) $R \models \coverageconstraints$.
The goal is to find a valid subset of rules $R^* {\subseteq} \{r_i\}_{i=1}^l$ s.t 
\begin{equation}
R^* {=} argmax_{R {\subseteq} \{r_i\}_{i=1}^l} \left[ \lambda_1 {\cdot} (l - size(R)) {+} \lambda_2 {\cdot} ExpUtility(R) \right]
\label{eq:optimization}
\end{equation}
where $\lambda_1,\lambda_2$ are non-negative weights. 
\end{definition}
}


\begin{figure*}[t]
    \centering
    
\includegraphics[scale=0.43]{figs/decision_tree.pdf}
\vspace{-32mm}
    \caption{A decision tree for selecting the appropriate problem variant.}
    \label{fig:decision_tree}
    \vspace{-5mm}
\end{figure*}

$\lambda_1$ and $\lambda_2$ may be tuned by the user. \newtextold{The above optimization problem, as expected, is NP-hard even for simple variants, although some constraints are matroid constraints and therefore are amenable to greedy approaches (discussions and proofs in the Appendix)}. 
% We discuss the complexity of our problem, as well as how it changes with the presence of fairness and coverage constraints in \cref{subsec:hardness}.
%
%As demonstrated in the Introduction, a solution to the \probName\ problem may result in a set of highly beneficial rules that only apply to a small, non-protected subset of the population. Therefore, we extend our problem definition to include coverage and fairness constraints.  
%We can apply any of SP or BGL group/individual fairness constraints, as well as rule/group coverage constraints, resulting in 18 distinct problem variants.
 Therefore, we obtain efficient algorithms that work well in practice in \Cref{sec:algo} and experimentally demonstrate the effect of different constraints on the results in \Cref{sec:casestudy}. 
 %and analyze the complexity of the corresponding problems in \cref{sec:hardness}.



%\vspace{1mm}
%\noindent
%\textbf{Overlap and Generality}:
% \paragraph*{Remark.} We did not incorporate additional objectives to the \probName\ problem related to the {\em overlap between rules} and their generality in terms of the {\em number of predicates defining the patterns}. Our \newtextold{initial} empirical study revealed that these objectives are effectively addressed by the coverage constraints. To simplify the problem, we decided to omit them.



% \medskip
% \noindent
% \textbf{Selecting the appropriate problem variant.}
%\label{subsec:variants}
Since we have several options for fairness and coverage constraints, a natural question is which version to use. 
We observe that there is no one-size-fits-all solution 
%when it comes to choosing the right variant of a problem to solve. 
and the best choice depends on the specific application. For instance, going for individual fairness gives a stronger fairness guarantee at the expense of possible lower utility to everyone. In addition, the complexity of different versions can vary. To assist in making this decision, we summarize the process through a decision tree that guides users in selecting the most suitable variant for their needs, presented in Figure \ref{fig:decision_tree}. The decision to choose between SP or BGL fairness is left to the user.
In Section \ref{sec:casestudy}, we present a case study that empirically compares the obtained rulesets under different problem variants.






% \begin{table*}[h]
%     \centering
%     \small
%         \caption{Hardness Results}
%     \label{tab:hardness}
%     \begin{tabular}{p{20mm}p{47mm}p{47mm}p{47mm}}
%         \toprule
%          & \textbf{No Fairness} & \textbf{Group Fairness} & \textbf{Individual Fairness} \\
%         \midrule
%         \textbf{No Coverage} & Submodular maximization (NP-hard) & NP-hard (knapsack)& Submodular maximization with a matroid constraint (NP-hard)  \\
%            \midrule
%        \textbf{Group Coverage} & Merely satisfying the coverage constraint is already NP-hard (set cover)& Merely satisfying the coverage constraints is already NP-hard (set cover) & Merely satisfying the coverage constraints is already NP-hard (set cover)\\
%           \midrule
%         \textbf{Rule Coverage} & Submodular maximization with matroid constraints (NP-hard) & NP-hard (knapsack) & Submodular maximization with matroid constraints (NP-hard) \\

%         \bottomrule
%     \end{tabular}

% \end{table*}

% \vspace{2mm}
%  \brit{Interpretable Decision Sets \cite{lakkaraju2016interpretable}}: a framework for building predictive models that are highly accurate, yet also highly interpretable.

%  Their objective function has the following ingredients: 
%  \begin{enumerate}
%      \item They favor decision sets with a smaller number of rules
%      \item They favor a decision set with fewer predicates in its rules
%      \item They favor decision sets with rules that do not overlap
%      \item They favor decision sets that have high precision and recall
%  \end{enumerate}


% These objectives are collectively treated as a weighted average and they aim to identify decision sets that maximize the weighted sum. (they show the objective function is a non-negative, non-normal, non-monotone, and submodular function and thus it is an np-hard problem)

% \textbf{Tie-breaking}: "The choice of default class label and class tie-breaking function is up to the user. For our experiments, we report results with two simple choices. For data points that satisfy more than one itemset, we predict using the rule with the highest F1 score on the training data. .....However, other choices of default class labels and class tie-breaking functions can be easily incorporated....  Similarly, one could break ties using a majority vote for data points that satisfy more than one itemset." 

% \subsection{Group Fairness-No Coverage}
% \sg{To discuss:
% 1. We have exponential many rules. How do we handle that in no fairness and no coverage setting?
% 2. Reduction from knapsack Problem: 
% Consider each rule $r$ with a weight = unfairness of rule r.}

% \begin{proposition}
%     \probName\ with a group-fairness constraint is NP-hard
% \end{proposition}
% \begin{proof}
%     Consider an instance of knapsack problem with $n$ items of weight $w_i$ and value $v_i$. For each item, construct a rule $r_i$ which has fairness group fairness metric $w_i$, i.e. $utility_p(r_i) - utility_{\bar{p}}(r_i) = w_i$. Each rule has utility $v_i$, length $1$, overlap $0$.

%     Now, we can observe that if \probName\ can be solved in polynomial time, then we can get a solution to the knapsack problem in polynomial time. This shows that \probName is NP-hard. 
% \end{proof}
% Given a set of $t$ rules $X=\{r_1,\ldots,r_t\}$, we want to identify a subset $S$ such that 




% Let S be a set of all possible rules.

% $$F(S \cup \{r\}) = min\{|F(S)|, |F(S)+f(r)|\}$$




