%\vspace{-3mm}
\section{Limitations and Future Work}
\label{sec:conc}


\sysName\ generates actionable, causal-based recommendations to improve a target outcome while incorporating coverage and fairness constraints. \common{To the best of our knowledge, this is one of the first works in this direction, and several directions of future work remain. In this section, we discuss some of the current limitations of \sysName\ and future directions. }
\par
%\smallskip
\reva{
{\bf Generation and usage of rules by \sysName.~} \sysName\ can be used to recommend actions for different subpopulations toward optimizing a target. As an example scenario, a policymaker may select the target outcome and the parameters for coverage and fairness constraints (which may be iteratively varied based on the application).
%the relevant problem variant (e.g., coverage and fairness constraints). 
\sysName\ then generates a prescription ruleset as recommended actions for different subpopulations.
%for the policymaker to implement. 
The current framework assumes that the policymaker is trustworthy, will not misuse the rules, and will publish the relevant recommendations for each subpopulation. However, it is important to note that if not all rules are provided to all subpopulations, disparities among subpopulations may increase.
In addition, the generated rules 
%may lack robustness, meaning they might not 
may not impact all individuals receiving the recommendation in the same way. The gain in objective may vary across different subpopulations. For example, an increase in $\$10k$ revenue may have varied impacts in different countries, depending on the cost of living and purchasing power. Addressing these will be interesting future work.
%An exciting direction for future research would be to focus on ensuring the robustness of prescription rules. 
%Further, the generated rules do not consider global constraints, e.g., if the targeted outcome is salary in an institution, there may be a total budget, and the rules may not be applicable independently. Other variants of the problem remain future work.
}

\reva{{\bf Considering constraints,  costs, and resources in rule generation.~}} %We acknowledge that the 
%Another direction for future work 
The current framework does not account for the cost of interventions. Some interventions may be impractical (e.g., pursuing a bachelor’s degree in CS for someone who already holds a PhD in CS) or vary significantly in cost (e.g., moving to the US versus learning Python). 
%\reva{Additionally, the gain in objective may vary across different subpopulations. For example, increase in $\$10000$ revenue would have caried impact on quality of life in different countries, depending on the cost of living and purchasing power. } 
\reva{Further, the generated rules do not consider global constraints, e.g., if the targeted outcome is the salary in an institution, there may be a budget. 
Future research will incorporate intervention costs to generate budget-constrained rules and address finite resource allocation scenarios to account for cases where the population size that can achieve improved outcomes is limited}.

{\bf Extension to multi-table data.~} \sysName\ currently supports a single-relation database without dependencies among tuples to ensure compliance with the SUTVA assumption~\cite{rubin2005causal} (discussed in \cref{sec:background-causal}). However, this assumption breaks down even in single-table databases with tuple dependencies. In single-table settings, intervention and grouping patterns are straightforward to define. Extending these definitions to multi-table databases, where grouping attributes and interventions may originate from different tables, introduces a significant challenge. This complexity arises due to many-to-many relationships and cross-table patterns. 
Previous work, such as \cite{salimi2020causal,galhotra2022hyper}, has extended causal models to handle multi-table data, but they have not explicitly targeted recommendations for subgroups. Expanding our framework to support multi-relational databases with complex dependencies remains an important direction for future research. Notably, prior work leveraging causal inference \cite{ma2023xinsight, youngmann2022explaining, salimi2018bias, DBLP:journals/pacmmod/YoungmannCGR24} has also primarily focused on single-table settings.






%Furthermore, 
%In addition, the generated rules sometimes may be difficult to interpret, e.g., a possible rule may suggest that {\em individuals aged 18.5 to 21.2 should learn Python}, due to continuous values of certain attributes.  %Future work would focus on generating semantically meaningful rules.
%binning continuous variables into meaningful ranges while preserving causal inference validity. }


{\bf Robustness of rules.~} The generated rules may be influenced by several factors, including the method used to evaluate causal effects, the thresholds set for the constraints, the overall quality of the data, and the quality of the causal DAG.
\reva{In this work, we assume that the causal DAG is provided as part of the input, with the responsibility for validating its correctness resting on the policymaker. Nonetheless, the causal DAG only needs to specify causal dependencies between variables without detailing the nature of those dependencies. Developing methods that are robust to inaccuracies in the DAG is an important direction for future work. }


\common{{\bf Explainability and prescriptive causal nature of rules.~} While if-then rules for prediction or causation are considered explainable or interpretable in the literature \cite{lakkaraju2016interpretable,pradhan2022interpretable,van2021evaluating,guidotti2018local,chen2018optimization}, we note that no additional explanations or justifications come with the rules mined by \sysName. %, which may be added in future work. 
%However, as mentioned in Point 4, the rules themselves are considered explainable or interpretable in the literature [1-5]. We will clarify this in the paper.
%We also note that prescription rules consist of conjunctions of predicates, which may not always be explainable. 
Generating meaningful explanations to describe how the rules impact the outcome and the variability of the outcome within various sub-populations is deferred to future work. }

\smallskip
\common{To conclude, observational causal analysis is the main foundation for any {\em prescription} or {\em recommendation} beyond predictions, when a randomized controlled trial is not possible due to cost, ethics, or feasibility issues. However, the analysis depends on assumptions (ignorability, causal DAG) that may not hold in a scenario and one should know the assumptions and limitations of these claims. How the rules should be used in practice considering practical and fairness aspects is a general direction of future work.}

\cut{

B. The *causal* aspect of this work is based on the vast causal inference literature on observational causal studies in Statistics and AI on observed or collected data. Under certain assumptions (that are known to be untestable), causal claims can be made from collected or observed data, and Average Treatment Effect (ATE) and Conditional Average Treatment Effect (CATE) on a subpopulation can be estimated. We follow Judea Pearl’s Graphical Causal Model from the AI literature [6] and use the DoWhy package released by Microsoft (https://github.com/py-why/dowhy) to estimate ATE and CATE. Indeed, the estimation of ATE and CATE depends on the quality of the causal DAG as mentioned in Point 4 of the revision plan, which we assume is given as background information. The causal DAG only needs causal dependencies between variables without specifying its nature. In the revision, we will vary the causal DAGs to evaluate the dependency of our framework on the accuracy of the causal DAG.

C. Causal analysis is the main foundation for any *prescription* or *recommendation* beyond predictions. When possible, one would do a randomized controlled trial (e.g., when a new vaccine is tested), but often they are not possible due to cost/ethics/feasibility issues, and one depends on observational causal study (used in sociology, econometrics, psychology). Indeed, observational causal study depends on assumptions (ignorability, causal DAG) that may not hold in a scenario, but that still a causal claim. This was the reason we used the terms prescription and recommendation. However, we agree that one should know the assumptions and limitations of these claims, and we will make sure to clarify this in the revised paper and explain the rationale behind using the terms causal and prescription along with their limitations.
}


