\section{Related work}
\label{sec:related}


Table \ref{tab:relatedwork} outlines the key distinctions between \sysName\ and prior work. The columns in bold emphasize our key contributions: we generate \textbf{causality-based} prescription rules aimed at {improving outcomes} for the \textbf{entire datasets}, while also \textbf{considering fairness}. In contrast, other approaches either produce non-causal rules (as shown in the Causal column), target only subsets of the data (as indicated in the Entire dataset column), or disregard fairness considerations (as highlighted in the Fairness column).




\begin{table}[t]
\small
\centering
\caption{Positioning of our framework w.r.t. previous work.}
\label{tab:relatedwork}
% \vspace{-3mm}
\footnotesize{
\begin{tabular}{|p{25mm}|c|c|c|c|c|c|c|}
    \hline
 
\multicolumn{2}{|c|}{{Related Work}}  & {Causal} &   {\begin{tabular}{@{}c@{}}Fairness\end{tabular}} & {\begin{tabular}{@{}c@{}} Entire\\dataset\end{tabular}} \\%\cline{3-8}
    \hline
\multirow{4}{*}{\begin{tabular}{@{}l@{}}Aggregate Query\\ Result Explanation\end{tabular}}&Ku√üol, "Explaining Aggregate Queries with Probabilistic Provenance" &\textbf{\checkmark}&\xmark&\xmark\\
&Liu et al., "Reasoning about Explanations for Aggregate SQL Queries" &\textbf{\checkmark}&\xmark&\checkmark\\

&Rodriguez et al., "Query Result Explanation using Association Rule Mining" &\xmark&\xmark&\xmark\\

&Zhang, "Explainable Query Optimization with Causal Inference" &\xmark&\xmark&\checkmark\\


\hline
\multirow{2}{*}{\begin{tabular}{@{}l@{}}Interpretable\\ Prediction Models\end{tabular}} 
% {\begin{tabular}{@{}c@{}}Interpretable Pred.\\Models\end{tabular}} 
& Zhang et al., "Causal Tree: A Novel Interpretable Model for Causal Inference" &\xmark&\xmark&{\bf \checkmark}\\
&&&&\\
\hline
\multirow{2}{*}{\begin{tabular}{@{}l@{}}Multi dimensional\\ data aggregation\end{tabular}} &Zhou et al., "Multidimensional Data Aggregation with Causal Inference" &\xmark&\checkmark&\checkmark\\ 


&Mao, "Causal Reasoning for Multidimensional Data Analysis" &\xmark&\xmark&\checkmark\\

    \hline
    \multicolumn{2}{|c|}{\sysName}
\textbf{}&\textbf{\checkmark}&\textbf{\checkmark}&\textbf{\checkmark}\\
\hline
\end{tabular}
}
% \vspace{-4mm}
\end{table}

\paragraph*{Rule mining}
Association rule mining has been extensively studied  and is used to identify relationships between items that frequently co-occurring in datasets. These techniques are applied across various fields, such as data analysis and outcome improvement. Notable algorithms include STEM , FP-Growth , AIS , and the Apriori algorithm . We leverage the Apriori algorithm to identify sufficiently large subpopulations for which we will generate causal interventions.
Rule-based interpretable prediction models often leverage association rule mining to generate predictive rules, with the goal of balancing high predictive accuracy with interpretability. 

Recent work has proposed generating rules based on causal relationships.
In , a framework was introduced to address biases in the data for fair causal analysis. \reva{Other studies have explored the integration of fairness criteria into causal analysis .}  proposed a method to optimally allocate treatments with uncertain costs that vary based on confounders. Related research has also focused on estimating heterogeneous treatment effects. However, these approaches assume both treatment and outcome variables are known. In contrast, we assume only the outcome variable is provided and aim to identify treatments that influence the outcome for different subpopulations, potentially yielding different treatments for each group. Our approach ensures the rules apply broadly while maintaining fairness for minority groups.


We adapt the method proposed in called CauSumX. CauSumX is designed to identify the treatment with the highest causal effect on the outcome for a given subpopulation, generating causal explanations for aggregate queries. A main difference is that CauSumX does not consider fairness. We empirically show that using CauSumX to generate prescription rules can lead to significant disparities between protected and non-protected populations (See \cref{exp:quality}).
Another main difference is that CauSumX considers the aggregate view to generate explanations, whereas we consider the entire data, thus, the search space is significantly larger.
Our primary contribution lies in introducing fairness constraints on the generated rules, making the necessary adjustments to the algorithm to scale, and conducting an experimental study to demonstrate the importance of fairness constraints.



% we adapt CauSumX to incorporate fairness and coverage constraints, offering a novel solution to identify a set of rules that adhere to these constraints.}
% \sr{this paragraph should move to the first paragraph and should be edited. We should not say "we adapt causumx", and should highlight that it does not generate prescriptions (like being male could be a treatment) but causal explanations, and does not consider fairness.}


% \brit{TODO: add a paragraph here}
% \begin{itemize}
%     \item Experimental Evaluation of Individualized Treatment Rules ____
  




% \end{itemize}



\paragraph*{Fairness in data management}
% AI systems are increasingly being deployed in areas like employment, healthcare, and education . However, alongside this growing adoption, concerns are rising about the potential harm these systems could inflict on already marginalized subpopulations. The risk of discriminatory outcomes has led to significant interest in methods for measuring and ensuring "algorithmic fairness".
\reva{Algorithmic fairness, especially in the context of predictions by ML algorithms for high-stake decision making, has been a prominent topic in ML and AI (e.g., ).} Popular notions of fairness include group and individual fairness. Group fairness (measured as statistical parity or equalized odds) ensures that the decision-making process is fair to the protected group but may be unfair towards any specific individual. In contrast, individual notions of fairness enforce that the decisions are fair towards every individual. We refer the reader to Section~\ref{subsec:fairness_constraint} for more details. 
% \sr{need a mention of group/individual fairness, different fairness definitions, and some citations from ML/AI here, and a fwd reference to sec 4.5.} 
In recent years, fairness has emerged as a key consideration in
data management research. This includes ensuring fairness during data acquisition, improving data cleaning processes to promote fairness, and achieving fairness in ranking and in database queries. \reva{Techniques to ensure fairness of allocated resources can also be extended to study scenarios where the available resources may be diverse and constrained.
One of our contributions is the introduction of novel definitions of group and individual fairness.

\paragraph*{Causal Inference}
Causal inference has been extensively studied in recent years, with various methods proposed for estimating causal effects. Some notable papers include: \newline
Zhang et al., "Causal Tree: A Novel Interpretable Model for Causal Inference" , \newline
Mao, "Causal Reasoning for Multidimensional Data Analysis" .

\paragraph*{References}
For further reading on the topics of data management and causal inference, we recommend the following references:

Zhang et al., "Causal Tree: A Novel Interpretable Model for Causal Inference"
Mao, "Causal Reasoning for Multidimensional Data Analysis"

In particular,  provides a comprehensive overview of the concepts and techniques involved in causal inference, while  presents a novel approach to multidimensional data analysis using causal reasoning.