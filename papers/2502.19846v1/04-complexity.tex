
\section{Complexity Analysis}
\label{sec:hardness}



% \subsection{Fairness Constraints}
% We study two definitions of fairness from previous literature: statistical parity (SP)~\cite{mehrabi2021survey},  and bounded group loss (BGL)~\cite{agarwal2019fair}. These two definitions are based on equivalent notions of fairness for regression tasks~\cite{agarwal2019fair}. We next provide an extension for these definitions to average treatment effect estimates. 



% \textbf{Group fairness} and \textbf{individual fairness} are two key concepts in the field of algorithmic fairness~\cite{}. Group fairness aims to ensure that different demographic groups receive similar outcomes. For example, in our context, it seeks to ensure that the expected utility for both protected and non-protected groups is similar. In contrast, individual fairness focuses on treating similar individuals similarly, meaning that if two individuals are alike in relevant aspects, they should receive similar outcomes. Both approaches aim to reduce bias and promote fairness. The choice of approach depends on the specific context.
% Next, we present four types of fairness constraints in the context of causal inference: SP and BGL, each of which can be applied to ensure either group or individual fairness.



% % which asks that the prediction be statistically independent of the protected attributes defining the protected group,, which asks that the prediction error restricted to any protected group stay below some pre-determined level. 


% \subsubsection{Statistical parity}
% In SP, the goal is to ensure that the gain in utility of a protected individual is similar to that of any individual from the privileged group.
% We present both group and individual fairness constraints in the context of causal inference. 

% %\sg{To add: what if the rules overlap}
% %\brit{This has already been addressedâ€”each individual is assigned with no more than one rule in practice. If multiple rules are suggested for a person, we assume they choose the worst one.}
% \sg{Need to change to make sure denominator of exp utility is fixed}

% \noindent
% \textbf{Group Fairness}:
% Intuitively, if we sample an individual randomly from the protected group of individuals, the expected increase in outcome (or in other words, utility) should be approximately equal as that of an individual from the unprotected group. This is the same intuition as that of SP for classification.

% Therefore, the SP group fairness constraint is:
% $$|\text{ExpUtility}_p(R) -\text{ExpUtility}_{\bar{p}}(R)| \leq \epsilon$$
% where $\epsilon > 0$ is a threshold. 


% \textbf{Individual Fairness}:
% Intuitively, individual fairness ensures that the expected gain for each protected individual is similar to that for an individual from the privileged group. That means that the expected gain of each rule $r\in R$ on a protected individual should be similar to that of an individual from the privileged group.


% More formally, we define it as:
% For every, $r\in R$,
% $$|utility_p(r) - utility_{\bar{p}}| \leq \epsilon$$

% We can demonstrate that the statistical parity fairness constraint is not a matroid constraint; however, it is a matroid constraint for individual parity. 

% \begin{lemma}
% \label{lemma:sp}
% The statistical parity fairness constraint is not a matroid constraint; however, it is a matroid constraint for individual parity. 
% \end{lemma}
% \begin{proof}
% To show that the statistical parity  fairness constraint is not a matroid, we construct a simple counter example. 

% Consider a dataset $D$ with $50\%$ individuals belonging to the protected group.
% Consider a rule set $R = \{r_1,r_2\}$ such that $coverage(r_1) = \pattern_p$  and  $coverage(r_2) = \pattern_{\bar p}$ and $\text{ExpUtility}_p(r_1) = \text{ExpUtility}_{\bar p}(r_2)  = 100$. This means that the set $R$ is fair. 

% Suppose the statistical parity fairness constraint is a matroid. In that case, any subset of $R$ should also yield a fair prescription. Consider a subset $R' = \{r_2\} \subset R$. 
%  $\text{ExpUtility}_p(r_2) = 0$ and $\text{ExpUtility}_{\bar p}(r_2)  = 100$. Therefore, the $r_2$ alone does not satisfy fairness wrt statistical parity, which is a contradiction.
% \end{proof}


% % \begin{table}[]
% %     \centering
% %  \begin{tabular}{|c|c|c|c|}
% % \hline
% % G & P & T & O \\
% % \hline
% % 1 & 1 & 0 & \$0 \\
% % 1 & 1 & 0 & \$0 \\
% % 1 & 0 & 1 & \$1 \\
% % 1 & 0 & 1 & \$1 \\

% % 0 & 1 & 1 & \$1 \\
% % 0 & 1 & 1 & \$1 \\
% % 0 & 0 & 0 & \$0 \\
% % 0 & 0 & 0 & \$0 \\

% % \hline
% % \end{tabular}
% %     \caption{Example Dataset for Lemma~\ref{lemma:sp}}
% %     \label{tab:sp_ex}
% % \end{table}


% % \begin{proof}[Proof of \cref{lemma:sp}]
% % We show that the hereditary property does not hold, and therefor it follows that this is not a matroid. 

% % Consider a dataset $\db$ with a schema $\attrset = \{G,P, T, O\}$ populated with $2n$ tuples. 
% % For the first $n$ tuples, we assign $t[G] = 1$. In the first half of these tuples we set: $t[P] = 1$, $t[T] = 0$, and $t[O] = 0$, while in the second half, $t[P] = 0$, $t[T] = 1$, and $t[O] = 1$. For the remaining $n$ tuples, the first $\frac{n}{2}$ have $t[P] = 1$, $t[T] = 1$, and $t[O] = 1$, and the rest have $t[P] = 0$, $t[T] = 0$, and $t[O] = 0$.
% % The protected group is defined by the pattern $\pattern_p = \{P = 1\}$, indicating that there are precisely $n$ tuples where $t[P] = 1$. 

% % An illustration of this dataset with 8 tuples is provided in \cref{tab:sp_ex}.


% % Consider the following  prescription rules:
% %     \begin{itemize}
% %         \item \textbf{(A rule that is useful only to non-protected)} $r_1 = (\pattern_g^1, \pattern_t^1)$:, where $\pattern_g^1 = \{G = 1\}$ and $\pattern_t^1 = \{T = 1\}$. We have: $coverage(r_1) =n$, $coverage_p(r_1) = \frac{n}{2}$, $utility_p(r_1) = 0$, and $utility_{\hat{p}}(r_1) = 1$. 
% %         \item  \textbf{(A rule that is useful only to protected)}:  $r_2 =(\pattern_g^2, \pattern_t^2)$, where $\pattern_g^2 = \{G = 0\}$ and $\pattern_t^2 = \{T = 1\}$.
% %         We have: $coverage(r_2) =n$, $coverage_p(r_2) = \frac{n}{2}$, $utility_p(r_2) = 1$, and $utility_{\hat{p}}(r_2) = 0$.
% %     \end{itemize}

% % We get that $overlap(r_1, r_2) = 0$, meaning the rules do not overlap as they pertain to different individuals. Additionally, $r_1$ and $r_2$ cover the entire population.
% % For the rule set $R = {r_1, r_2}$, the statistical parity fairness constraint is met: for a randomly selected protected individual, the expected utility increase is $0.5$ (half get an increase of $1$ and the other half get no increase). Similarly, the expected utility increase for non-protected individuals is also $0.5$. However, when considering any non-empty subset $R'$ of rules from $R$, $R'$ does not satisfy the constraint, as the expected utility for one population will be $0$ and for the other, it will be $0.5$.
% % \end{proof}


% \subsubsection{Bounded group loss (BGL)}: Fair regression with BGL minimizes the overall loss while controlling the worst loss on the protected group~\cite{agarwal2019fair}.
% In our context, this translates to the following fairness constraint: When selecting an individual from the protected group, the outcome increase (utility) should exceed a specified threshold $\tau$.

% \textbf{Group Fairness}: We aim to ensure that the expected utility of a randomly sampled protected individual within $Coverage(R)$ is above a given threshold $\tau$.
% Therefore, the fairness constraint is:
% $$\text{ExpUtility}_p(R) \geq \tau$$

% \textbf{Individual Fairness}: Under individual fairness, we aim to ensure that the gain of every protected individual from $Coverage(R)$ exceeds a threshold $\tau$.
% Therefore, given a threshold $\tau$, we say that a set of rules $R$ satisfies the individual loss constraint if the utility of every rule $r$ on protected individuals is at least $\tau$. More formally, for every rule $r\in R$, $utility_p(r) \geq \tau$.



% Here again, we can demonstrate that the BGL fairness constraint
% is not a matroid constraint; however, it is a matroid constraint for
% individual loss.




% \begin{lemma}
% \label{lem:bgl}
% The BGL fairness constraint is not a matroid, but it is for individual loss.  
% \end{lemma}
% \brit{add proof}

%  \brit{As observed in the example derived from the Stack Overflow datasets. A stricter version, which adheres to matroid properties, requires each rule to guarantee an increase in utility above the specified threshold $\tau$.}
% \begin{proof}

%     \begin{table}[]
%     \centering
%  \begin{tabular}{|c|c|c|c|}
% \hline
% G & P & T & O \\
% \hline
% 1 & 1 & 1 & \$0 \\
% 1 & 1 & 0 & \$0 \\
% 1 & 0 & 0 & \$1 \\
% 1 & 0 & 1 & \$1 \\

% 0 & 1 & 1 & \$1 \\
% 0 & 1 & 0 & \$1 \\
% 0 & 0 & 1 & \$0 \\
% 0 & 0 & 0 & \$0 \\

% \hline
% \end{tabular}
%     \caption{Example Dataset for Lemma~\ref{lemma:bgl}}
%     \label{tab:sp_ex}
% \end{table}

% \end{proof}
% More fairness constraints for regression: Fair Regression: Quantitative Definitions and Reduction-based Algorithms \cite{agarwal2019fair}

 % \textbf{Note:} I am assuming each rule is disjoint, i.e. an individual cannot satisfy multiple rules. For overlapping rules, the equation will change slightly.

 % \brit{the rules are not disjoint, this is too restrictive. For example, one rule can be suggested to people at the age of 25-34, and the second for people from the US. The only restriction is that their coverage should be different (namely, that they are not covering the exact same sub-population). Can you please update the definition? }


% \subsubsection{Individual Fairness}
% We consider two types of individual fairness constraint variants of both group fairness constraints: individual parity ensures that the expected gain of each rule $r\in R$ on a protected individual is similar to that of an individual from the privileged group, and individual loss ensures that the utility of each rule exceeds a threshold $\tau$.

% \paragraph*{Individual Parity.}
% The absolute difference between utility of every rule $r\in R$ over protected individuals is similar to that of a privileged individual. More formally, we define it as:
% For every, $r\in R$,
% $$|utility_p(r) - utility_{\bar{p}}| \leq \epsilon$$
% \begin{lemma}
%     The individual parity fairness constraint is a matroid.
% \end{lemma}
% \sg{need to add proof}


% \paragraph*{Individual Loss.} Given a threshold $\tau$, we say that a set of rules $R$ satisfies the individual loss constraint if  the utility of every rule $r$ on protected individuals is at least $\tau$. More formally, for every rule $r\in R$, $utility_p(r) \geq \tau$.


% \begin{lemma}
%     The individual loss fairness constraint is a matroid.
% \end{lemma}
% \sg{need to add proof}


% \subsection{Coverage Constraints}





We next study the complexity of the \probName\ problem under different constraint combinations. 
First, we demonstrate that the \probName\ problem is an NP-hard problem~\cite{khuller1999budgeted}. Then we show that \probName\ is equivalent to optimizing a non-negative and monotone submodular function. Furthermore, the individual fairness constraint and rule coverage constraints are matroid constraints. Therefore, a greedy approximation algorithm can be used to yield a constant approximation solution.  %Consequently, maximizing it is an NP-hard problem. 

We define the decision version of the \probName\ problem in the following way: Given a bound $k$ on the number of selected rules and a threshold $\tau$ on the expected utility, the question is if there exists a set of at most $k$ rules whose expected utility is at least $\tau$. We can demonstrate that this problem is NP-hard.
\begin{proposition}
\label{prop:unconstrained}
    The \probName\ problem with and without individual fairness constraint is NP-hard.
\end{proposition}



% From \cite{lakkaraju2016interpretable}, we get that $f_1, f_2, f_3$ are non-negative and sub modular. \brit{the utility cant be negative - we consider only positive rules (under the assumption that each one gets no more than one rule).}
We prove that the unconstrained \probName\ problem via a reduction from the max-cover problem. Furthermore, adding individual fairness constraints does not 
We can show that both individual-level fairness constraints (individual parity and individual loss) are matroid constraints. Therefore, adding them does not change the complexity of the problem, as maximizing a non-negative monotone submodular function under a matroid constraint remains NP-hard~\cite{calinescu2007maximizing}.

For the group-level fairness constraints, we can demonstrate that this constraint does not form a matroid and provide a reduction from the Knapsack Problem~\cite{kellerer2004introduction}.

\begin{proposition}
\label{prop:group_fairness}
    \probName\ with a group-fairness constraint is NP-hard
\end{proposition}

% Given a set of $t$ rules $X=\{r_1,\ldots,r_t\}$, we want to identify a subset $S$ such that 




% Let S be a set of all possible rules.

% $$F(S \cup \{r\}) = min\{|F(S)|, |F(S)+f(r)|\}$$


As for coverage constraints, the rule coverage is a matroid constraint (as it can be checked against every rule separately). For the group coverage, on the other hand, we can show that merely finding a solution that satisfies the constraints, even without maximizing expected utility, is NP-hard via a reduction from the Set Cover problem~\cite{feige1998threshold}. 

\begin{proposition}
    \label{prop:group_coverage}
    \probName\ with a group-coverage constraint is NP-hard
\end{proposition}

%A summary of the complexity results is given in \cref{tab:hardness}.

We note that for variants that involve maximizing a submodular function potentially subject to matroid constraints, a greedy approach can yield a solution with approximation guarantees. However, given that the number of potential rules may be quite large (exponential in the database size), we must avoid generating all possible rules to remain efficient. Thus, although our proposed algorithm does not provide theoretical guarantees, it effectively identifies useful sets of rules within a reasonable processing time.

