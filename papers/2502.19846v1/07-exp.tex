\vspace{-2mm}
\section{Experimental Evaluation}
\label{sec:experiments}
We present an experimental evaluation that evaluates \sysName\ effectiveness and efficiency. We aim to address the following questions:  
$\mathbf{Q1}$: How does the quality of our generated rulesets compare to that of existing methods? $\mathbf{Q2:}$ What is the efficiency of \sysName\ and how is it affected by various data and system parameters?  



\subsection{Experimental Setup}
\label{sec:exp_setup}
\sysName\ was implemented in Python, and is publicly available in~\cite{fullversion}. 
CATE values computation was performed using the DoWhy library~\cite{dowhypaper}. The generated rules were translated into natural language using \reva{simple, manually constructed templates}.
We perform experiments on CloudLab ~\cite{Duplyakin+:ATC19} xl170 machines (10-core 2.4 GHz CPU, 64 GB RAM).
% In this section, we focus solely on the variant of our problem with statistical parity group fairness and group coverage constraints, as this represents the most challenging setting. Rule coverage and individual fairness are simpler, as they primarily involve pruning rules and can be verified in Step 2 of the algorithm, thereby reducing the search space.
The datasets, protected groups, and default parameters considered are the same as those described in \cref{sec:casestudy}.





%https://www.kaggle.com/datasets/sobhanmoosavi/us-accidents





% \brit{experiments:}
% \begin{itemize}
%     \item Case study: Compare between different definitions to see the effect of different fairness and coverage constraints
%     \item Comparison to baseline algorithms - quality in term of coverage and fairness
%     \item Comparison to baselines in terms of running times
% \end{itemize}


\vspace{1mm}
\paratitle{Baselines}
We compare \sysName\ with the following baselines:
 % \textbf{Brute-Force}: The optimal solution according to \cref{def:problem}. This algorithm implements an exhaustive search over all sets of rules.\\
\textbf{1. CauSumX}:
CauSumX \cite{DBLP:journals/pacmmod/YoungmannCGR24} is designed to find a summarized causal explanation for group-by-avg SQL query results. When applied directly to the datasets, it can be viewed as a solution to our problem with only an overall coverage constraint.
\textbf{2.IDS}~\cite{lakkaraju2016interpretable} is a framework for generating Interpretable Decision Sets for prediction tasks. IDS incorporates parameters restricting the percentage of uncovered tuples and the number of rules. These parameters were assigned the same values in our system.
\textbf{3. FRL}: The authors of \cite{chen2018optimization} proposed a framework for creating Falling Rule Lists (FRLs) as a probabilistic classification model. FRLs comprise if-then rules with antecedents in the if-clauses and probabilities of the desired outcome in the then-clauses, ordered based on associated probabilities.
% \textbf{Explanation Table}: The authors of \cite{el2014interpretable} introduced an efficient method to generate \emph{explanation tables} for multi-dimensional datasets. The proposed algorithm employs an information-theoretic approach to select patterns that provide
% the most information gain about the distribution of the outcome attribute. 
% \brit{a variant with fairness?}



\smallskip
Since IDS and FRL assume a binary outcome, we binned the salary variable in SO using the average value. To address fairness considerations, we run the baseline algorithms twice (excluding Brute-Force): Once on the entire dataset to obtain a set of rules applicable to the entire population, and again solely on the tuples belonging to the protected population to generate rules specifically tailored for them. \revb{We report the number of rules generated by the baselines, their coverage, and runtime. To compare the expected utility, we proceed as follows: The rules generated by IDS and FRL are prediction rules (e.g., IF owning a house = YES, THEN credit score = 1). As such, these rules do not provide an intervention to improve outcomes. We, therefore, treat the IF clauses
in two manners: (1) IF clauses as the selected grouping patterns and then apply step 2 (\cref{subsec:treatment_patterns}) of \sysName\ to determine the intervention patterns; (2) IF clauses as the selected intervention patterns, where the grouping pattern is the entire data. }
% For the resulting set of prescription rules, we report the expected utility for both protected and non-protected groups. }

% The final solution for each baseline is considered the union of these two sets of rules.



% \vspace{1mm}
% Unless otherwise specified, the overall coverage threshold as well as the coverage threshold for the protected group are set to 0.75. The threshold of the Apriori algorithm is set to 0.1. 
% The threshold for the SP fairness constraint is set at \brit{?}, and the threshold for the BGL fairness constraint is set at \brit{?}. 
% The time cutoff is set to $3$ hours. 


% \subsection{Problem Variants Evaluation (Q1)}
% \label{exp:problem_variants}

% \brit{here we can focus on only two datasets, and show the rules with different constraints (to motivate the need for different problem variants). (fill the cells in Table \ref{tab:problem_variants})}




\subsection{Quality Evaluation (Q1)}
\label{exp:quality}
We compare the set of rules chosen by each baseline and \sysName. 

\begin{figure}[t]
    \centering
    \vspace{-3mm}\includegraphics[width=0.46\textwidth]{figs/time_barchart.pdf}
%     \begin{subfigure}[b]{0.23\textwidth}
%         \centering
% \includegraphics[width=\textwidth]{example-image-a}
%         \caption{Stack Overflow}
%         \label{fig:first}
%     \end{subfigure}
%     \hfill
%     \begin{subfigure}[b]{0.23\textwidth}
%         \centering
% \includegraphics[width=\textwidth]{example-image-b}
%         \caption{German Credit}
%         \label{fig:second}
%     \end{subfigure}
    \caption{Runtime by-step of the \sysName\ algorithm (SO)}
    \label{fig:runtime_by_step}
\end{figure}

\paratitle{Stack Overflow} As discussed in \cref{sec:casestudy}, prescription rules selected without fairness constraints, similar to the behavior of CauSumX, were significantly more advantageous for non-protected.  
The rules generated by IDS do not suggest interventions to improve outcomes. For example, one rule states that if Country = Turkey and Age = 18-24 years, then the expected salary is low (with the outcome binned). Another key distinction is that these rules are not causal, as they are based on correlations in the data. For example, one rule indicates that if the years coding = 0-2 and Sexual Orientation = Gay or Lesbian, then the expected salary is low. Similarly, rules generated by FRL do not propose interventions to improve outcomes and are not causal. For example, one rule states that if Country = US and Sexual Orientation = Straight or Heterosexual, then the expected salary is high. 
In contrast, \sysName\ generates interventions aimed at improving the outcome by leveraging causal relationships. It also allows users to impose fairness constraints, ensuring that the protected group benefits from these interventions.




% IDS generated 16 rules for the overall population and 21 rules for the protected group. Notably, these rules do not suggest interventions to improve outcomes. For example, one rule states that if Country = Turkey and Age = 18-24 years, then the expected salary is low (with the outcome binned). Another key distinction is that these rules are not causal, as they are based solely on correlations in the data. For example, one rule indicates that if the years coding = 0-2 and Sexual Orientation = Gay or Lesbian, then the expected salary is low. \brit{TODO}


% The FRL baseline generated 9 rules for the overall population and 7 for the protected group. Similar to the IDS baseline, these rules do not propose interventions to improve outcomes and are not causal. For example, one rule states that if Country = United States and Sexual Orientation = Straight or Heterosexual, then the expected salary is high. 
%   \brit{TODO}

% \brit{IDS full: 16 rules, 64 seconds, IDS protected: 21 rules, 12 seconds}
% \brit{FRL full: 9 rules 1225 seconds, FRL protected: 7 rules, 478 seconds}

\paratitle{German}
Here again, with no fairness constraint (akin to CauSumX), the selected rules were mostly beneficial for the non-protected. 
% IDS generated 12 rules for the overall population and 20 for the protected group. 
Here again, the rules generated by IDS are not causal and do not offer an intervention. For example, one of the rules suggested that single females at the age of 35-41 are unlikely to get a loan.  
% \brit{TODO}
% FRL generated 13 rules for the overall population and 11 for the protected group. 
As before, the rules generated by FRL are also not causal and do not propose ways to improve the credit risk score. For example, one rule suggests that if a person has lived in a house for 4-7 years, their credit risk score is likely to be high. Another rule states that if the purpose of the loan is to buy a used car, the credit risk score is also likely to be high. Clearly, these rules rely on correlations in the data rather than causal relationships.
In contrast, \sysName\ generated a ruleset that offers interventions to improve the credit risk score based on causal relationships. Example selected rules are shown in \cref{sec:casestudy}.



\vspace{1mm}
\revb{We report the solution size, coverage, expected utility for protected and non-protected, and the unfairness of the rulesets generated using IDS and FRL (as explained in \cref{sec:exp_setup}).
The results are presented in 
{\bf \cref{tab:problem_variants}}. Notably, the expected utility for both protected and non-protected groups across both datasets is generally lower than that achieved by \sysName. \sysName\ consistently delivers higher expected utility for both groups and a smaller difference between these values. This indicates that our approach to mining grouping and intervention patterns is more effective than relying on these algorithms for the same purpose.  However, we note that the rules in IDS and FRL had different objectives (prediction accuracy) and had to be adapted for quantitative comparison using our measures.} 

% \nativ{comment}
% \brit{IDS full: 12 rules 4 seconds, IDS protected: 20 rules, 4 seconds}
% \brit{FRL full: 13 rules 273 seconds, FRL protected: 11 rules 279 seconds}

\subsubsection{\reva{Robustness to the Causal DAG}}
\label{subsec:causal_DAG_robustness}
\reva{The quality of the generated rules may depend on the accuracy of the underlying causal DAG. To evaluate this, we examine the impact of different causal DAGs on the rules. The causal DAGs considered are as follows:
{
\textbf{(1) 1-layer Indep DAG:} A causal DAG where all attributes are independent of each other and only impact the outcome. This setting similar to the scenario where all the causal graph is ignored.
\textbf{(2) 2-layer Mutable DAG:} A simplified DAG where immutable attributes affect the mutable attributes, which impact the outcome variable. In this graph, all immutable attributes act as confounders but do not directly impact the outcome.
%Another default causal DAG where all immutable attributes point to mutable attributes, which in turn point to the outcome.  
\textbf{(3) 2-layer DAG:} A simplified DAG where all variables affect the outcome but the mutable attributes are also confounded by all immutable attributes. }
%Another 2-layer causal DAG. In this DAG, to include confounding variables, all edges in the default-2-layer DAG are present, with additional edges from the top layer to the outcome.  
\textbf{(4) PC DAG:} A causal DAG generated by the PC causal discovery algorithm~\cite{spirtes2001causation}}. 



\reva{The results are depicted in \cref{tab:causal_dag_variants}. We report the expected utility as computed over the different causal DAGs. We observe that the expected utility remains similar for the Stack overflow dataset, demonstrating robustness towards the choice of causal dag. The results show some variability in German credit. However, the PC DAG and the original causal DAG are the most accurate (as they are based on the data distribution and domain knowledge) and achieve the highest coverage and expected utility.}



\begin{table*}[h!]
\centering
\small
\caption{\reva{Metrics Comparison with different Causal DAGs. 
%In parenthesis are the expected utility values computed on the original  causal DAG.
}}
\label{tab:causal_dag_variants}
\begin{tabular}{p{40mm}ccccccc}
\toprule
\textbf{Stack Overflow (SP group fairness + group coverage)} & \textbf{\# rules} & \textbf{coverage} & \textbf{coverage pro} & \textbf{exp utility} & \textbf{exp utility non-pro}&\textbf{exp utility pro} &\textbf{unfairness} \\

\midrule 

Original causal DAG  & 11& 97.95\%& 98.85\%& 27934.76& 28144.58& 18145.23& 9999.35\\



\reva{1-Layer Indep DAG} &\reva{11}&\reva{98.38\%} & \reva{98.38\%}&\reva{28110.19}& \reva{28117}
&\reva{18117.45}
&\reva{9972} \\


% expected_utility’: 28110.19, ‘unprotected_expected_utility’: 28117.0, ‘protected_expected_utility’: 18117.45, ‘coverage_rate’: ’98.38%’, ‘protected_coverage_rate’: ’98.83%


\reva{2-Layer Mutable DAG} &\reva{10}	
&\reva{97.7\%}
 &\reva{98.4\%} &\reva{28198.59}&\reva{28193.09} &\reva{18193.23
}&\reva{9999.86} \\


\reva{2-Layer DAG} &\reva{10}	
&\reva{98.47\%}
 &\reva{98.87\%} &\reva{28106.4}&\reva{28211.17} &\reva{18211.4}&\reva{9999.77} \\

\reva{PC DAG} &\reva{10}&\reva{97.7\%} &\reva{98.4\%} &\reva{28198.59}&\reva{28193.09} &\reva{18193.23}&\reva{9999.86} \\

        
\midrule

\textbf{German Credit (BGL group fairness + group coverage)} & \textbf{\# rules} & \textbf{coverage} & \textbf{coverage pro} & \textbf{exp utility} & \textbf{exp utility non-pro}&\textbf{exp utility pro}&\textbf{unfairness}   \\
\midrule 

Original causal DAG  & 6& 100.0\%& 100.0\%& 0.36& 0.37& 0.31& 0.06 \\
\reva{1-Layer Indep DAG} &\reva{12}&\reva{100\%} &\reva{100\%} &\reva{0.31}& \reva{0.31}&\reva{0.29}&\reva{0.02} \\
\reva{2-Layer Mutable DAG}&\reva{13} &\reva{76.20\%}		
&\reva{79.35\%} & \reva{0.22}&\reva{0.22}&\reva{0.2} &\reva{0.02} \\

\reva{2-Layer DAG} &\reva{11}	
&\reva{71.20\%}
 &\reva{73.91\%} &\reva{0.26}&\reva{0.25} &\reva{0.23}&\reva{0.02} \\

\reva{PC DAG} &\reva{24}&\reva{100.00\%}	
 &\reva{100.00\%} &\reva{0.39}&\reva{0.39} &\reva{0.26}&\reva{0.13} \\
\bottomrule
\end{tabular}
%\vspace{-3mm}
\end{table*}



\subsection{Scalability Evaluation (Q2)}
\label{exp:scalability}
% In this section, we omit the results for the baselines from the presentation, as their response times are significantly slower.


% \begin{figure}[h!]
%     \centering
%     \begin{subfigure}[b]{0.23\textwidth}
%         \centering
% \includegraphics[width=\textwidth]{example-image-a}
%         \caption{Stack Overflow}
%         \label{fig:first}
%     \end{subfigure}
%     \hfill
%     \begin{subfigure}[b]{0.23\textwidth}
%         \centering
% \includegraphics[width=\textwidth]{example-image-b}
%         \caption{German Credit}
%         \label{fig:second}
%     \end{subfigure}
%     \caption{Runtime by-step of the \sysName\ algorithm}
%     \label{fig:runtime_by_step}
% \end{figure}


\begin{figure}[t]
    %\vspace{-2mm}
    \begin{subfigure}[b]{0.46\textwidth}
        \centering
        \includegraphics[width=0.6\textwidth]{figs/time_v_size.pdf}
        % \caption{Stack Overflow}
        % \label{fig:first}
    \end{subfigure}
    %\vspace{-mm}
    \caption{\revb{Runtime as a function of the dataset size (SO)}}
\label{fig:runtime_dataset_size}
\end{figure}

\begin{figure}[t]
    \vspace{-5mm}
    \centering
        \begin{subfigure}[b]{0.48\textwidth}
        \centering
        \includegraphics[width=\textwidth]{figs/time_v_num_attr_line.pdf}
        \end{subfigure}
    \caption{\revb{Runtime as a function of number of mutable and immutable attributes for SO with statistical parity}}
\label{fig:runtime_attributes}
\end{figure}



% \begin{figure}[h!]
%     \centering
%     \begin{subfigure}[b]{0.23\textwidth}
%         \centering
% \includegraphics[width=\textwidth]{figs/time_v_num_immutable_line.pdf}
%         % \caption{Stack Overflow}
%          \label{fig:immutable}
%     \end{subfigure}
%     \vspace{-1mm}
%     \caption{Runtime as a function of number of immutable attributes}
%     \label{fig:runtime_immutable_attributes}
% \end{figure}

\paratitle{Breakdown analysis by step}
Figure~\ref{fig:runtime_by_step} shows the runtime comparison of \sysName for different problem settings. Observe that using rule coverage constraint has the lowest runtime because it helps to prune rules which do not satisfy the coverage constraint. Employing rule coverage with individual fairness is the fastest among all settings, while no constraint setting takes the longest time.
The time taken by the group mining phase is less than $2$ seconds across all setups, and is therefore not visible in the plot. The intervention mining phase (Step 2) is the most inefficient phase, which takes around $6$ mins for the unconstrained setting. The running time of these components aligns with our time complexity analysis (\cref{sec:algo}). Due to space restrictions, we do not present the corresponding plot for German dataset. All conclusions remain the same but the overall running time is $\approx 10\times$ faster due to its smaller size.

\revb{The running time of \sysName and the baselines is comparable. 
FRL is an order of magnitude slower than IDS because it uses a Bayesian modeling approach to simultaneously select a subset of rules and determine their optimal order, which involves solving a computationally intensive combinatorial problem. In contrast, IDS leverages submodular optimization on an unordered set of rules, significantly reducing the size of the search.}
%
We now analyze the impact of system parameters and data size on performance. 


\smallskip
\paratitle{Data Size} \Cref{fig:runtime_dataset_size} compares the running time of \sysName\ \revb{and the baselines} for varying dataset sizes. We observe that the time taken by \sysName\  \revb{and the baselines} increases linearly for most of the settings, \revb{with \sysName\ demonstrating a runtime comparable to IDS under certain configurations}. We also observed that the quality of rules returned by sampling $25\%$ of the data points is comparable with the rules returned by using the whole dataset. Therefore, sampling-based optimizations can help to reduce the running time from $11$ min to less than $2$ min for the unconstrained setting and less than a minute with fairness constraints. 

%We analyze the impact of dataset size on runtime through random sampling of tuples. The results are shown in \cref{fig:runtime_dataset_size}. \brit{TODO}



\smallskip
\paratitle{Number of Attributes} Figure~\ref{fig:runtime_attributes} shows the runtime of \sysName\ while increasing the number of mutable and immutable attributes. 
On increasing the number of mutable attributes, the number of intervention patterns increases exponentially while on increasing immutable attributes, the number of grouping patterns increases exponentially. Therefore, both have a similar impact on runtime. \revb{IDS and FRL do not distinguish between mutable and immutable attributes and there the runtime increases slightly due to an increase in the number of attributes, as more rules are considered.}
%Comparing the two plots, we can see that the running time is dependent on the total number of attributes and not just the number of mutable attributes. However, the reasons of 
% We observe that the running time increases with increasing num
% We examine the impact of attribute quantity on runtime, by randomly excluding attributes from consideration. The results are shown in \cref{fig:runtime_attributes}. \brit{TODO}

\reva{In the following, we omit the results for the IDS and FRL baselines, as these parameters do not impact their runtime.}

\smallskip
\paratitle{Fairness Threshold} %We examine the effect of the threshold $\epsilon$ used to assess the group fairness constraint (\cref{subsec:fairness_constraint}.
\Cref{tab:fairness_variants} presents the results for varying $\epsilon$ for group and individual fairness. We observe that the unfairness of the returned solution increases with the increase in $\epsilon$.  Additionally, the overall expected utility increases but the expected utility of the protected individuals decreases. This result matches our intuition as highly unfair rules are selected for higher values of $\epsilon$. We also notice that the greedy algorithm satisfies the group fairness constraint in all scenarios (unfairness is always less than the desired threshold).

For individual fairness, the overall utility increases monotonically with $\epsilon$. However, the rate of growth for individual fairness is slower than that of group fairness.
One interesting observation about individual fairness is that when all rules have statistical parity difference less than $2500$, the overall unfairness is still around $11K$. This sudden increase in unfairness when considering multiple fair rules together is because we evaluate the upper bound of unfairness by taking the difference between max utility of unprotected and min utility of protected individuals. On manual inspection, we observed that all rules are indeed individually fair.



% In case of individual fairness,  unfair rules are chosen

% As the value of $\epsilon$ increases, the fairness of the solution may decrease. \brit{todo}

\smallskip
\paratitle{Coverage Threshold} With the change in coverage thresholds, we do not observe major difference in the overall results because the majority of the rules exhibit very high coverage (\cref{tab:problem_variants}). %We examine the effect of coverage the thresholds $\theta$ and $\theta_p$. 

\smallskip
\paratitle{Apriori Threshold} 
We observe that increasing the Apriori threshold $\tau$ leads to a reduction in the number of grouping patterns considered, and thus to a decrease in runtime. However, our findings indicate that higher $\tau$ values lead to a decrease in both utility and fairness. Based on our findings, we recommend using a default value of $0.1$, which provides satisfactory results in terms of coverage, utility, fairness and runtime.

%used to define the group coverage constraint (\cref{secsec:coverage_constraint}). As the value of $\theta$ and $\theta_p$ increase, \brit{todo}

% \brit{Here we compare the results with existing baselines in terms of running times. We then isolate each phase of the algo to investigate its effect}

% \brit{Examine the effect on running times when varying: (1) number of tuples (2) number of attributes (3) threshold of apriori (4) coverage constraint (5) fairness constraint}

% \brit{add an experiment to show how we operate with a default causal DAG (everything affects the outcome)}




