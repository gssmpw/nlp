\section{Related Work}
% \subsection{Diversifying Synthetic Data}
% \label{sec:synth_data}
% Radford et al., "Language Models as Zero-Shot Learners" provide an extensive survey of synthetic data usage for various NLP tasks. Our use case is synthetic data for aligning a model to a specific task, but we used templates, which limited our data diversity during synthetic generation. A particularly important issue for aligning a model with synthetic data is that of data diversity. Wang et al., "FVT: Few-Shot Visual Text Understanding" achieve this by using LLMs to generate ``personas'', or short descriptions of various individuals' interests and/or jobs to bias a model to create different types of questions to solve. They generated 1 billion personas, and saw strong performance when using them to generate and solve math problems. Bansal et al., "Variational Reasoning for Language Models" used 2 separate instances of GPT Turbo and gathered user-assistant dialogue data from them after specific prompting both LLMs to more closely emulate human dialogue patterns. Li et al., "Chain of Thought Prompting Encourages Generalization and Reduces Overfitting" used Chain of Thought Prompting and a wide variety of system prompts to augment the FLAN dataset to create 5 million high quality examples that proved to be more robust on a variety of tasks than models that did not use these techniques.

\subsection{LLMs Reasoning about the World}
% Wang et al., "Real-World Reasoning with Pseudocode in LLMs" make the argument that LLMs that work as agents cannot simply be Question Answering modules, but need profiles, memory access, planning, and execution modules for full grounding. Within this framework, FRIDA serves 
% as a complementary component to a planning module---facilitating information on the canonical affordances of objects and specialized equipment, as well as physical common sense knowledge that supports actions that \emph{can} be taken with an object, even if they are not actions that are normally taken with respect to that object.  %as a basis to be trained as a planning module. 
There a wide variety of methods for leveraging LLMs for reasoning in a physical environment based on Chain of Thought prompting ____. These include variants like re-prompting ____, which prompts the LLM to regenerate a plan if certain criteria aren't met at each steps, or Tree of Thought ____, which generates a tree of potential steps and evaluates each potential path via either a breadth-first or depth-first search. 

There are also methods that take allow the LLM to take in environmental feedback in response to its output. For Inner-Monologue ____, the LLM is given the option to ask for more scene descriptors from a human handler, which it then incorporates into its prompts, improving task completion and decreasing hallucination. Another example is SayPlan ____, which uses 3D scene plans to iterate on proposed strategies until an effective path is discovered. Guo et al., "Planning with LLMs: A Survey of Methods and Applications" get feedback from LLMs themselves by using a wide variety of LLM agents to do various sub-tasks for planning, including generating a general outline, using external tools to gain information, and evaluating which plan is best. 

One resource for improving LLM understanding object affordances specifically is Liu et al., "Affordance-Related Language Understanding" who curate a dataset of naturally occurring sentences and corresponding images, then transform them into inference, probing, and text and visual masking tasks. They further prove that even Visual Language Models (VLMs) do not have straightforward understandings of affordances, but few-shot fine-tuning improved LLM and VLM performance on identifying object affordances.

\subsection{Disaster Work and Natural Language Processing}
Zhou et al., "A Systematic Review of NLP Tools for Disaster Response" completed a systematic search and analysis of over 100 peer-reviewed papers relating to Natural Language Processing (NLP) tools being applied to disasters. 85 of the 107 papers found were for analyzing social media, with 67 of the papers analyzing twitter data specifically. Over half of the total papers had a sentiment analysis component to their work, and the 2nd and 3rd most common tools used were text classification and information extraction. 87.8\% of papers focused on natural disasters, with only 3.7\% being solely about man-made disasters (the rest pertained to both) Li et al., "Leveraging LLMs for Disaster Response: A Survey" and ____, together showcase that while there is much research on LLMs as agents and much research on NLP analysis of disasters, there is not much overlap in these spaces.