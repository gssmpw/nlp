% Use this file for citations not found in the ACL Anthology (contained in "anthology.bib").

@inproceedings{ppdc,
    title = "{P}rop{B}ank-Powered Data Creation: Utilizing Sense-Role Labelling to Generate Disaster Scenario Data",
    author = "Shichman, Mollie Frances  and
      Bonial, Claire  and
      Hudson, Taylor A.  and
      Blodgett, Austin  and
      Ferraro, Francis  and
      Rudinger, Rachel",
    editor = "Bonial, Claire  and
      Bonn, Julia  and
      Hwang, Jena D.",
    booktitle = "Proceedings of the Fifth International Workshop on Designing Meaning Representations @ LREC-COLING 2024",
    month = may,
    year = "2024",
    address = "Torino, Italia",
    publisher = "ELRA and ICCL",
    url = "https://aclanthology.org/2024.dmr-1.1",
    pages = "1--10",
    abstract = "For human-robot dialogue in a search-and-rescue scenario, a strong knowledge of the conditions and objects a robot will face is essential for effective interpretation of natural language instructions. In order to utilize the power of large language models without overwhelming the limited storage capacity of a robot, we propose PropBank-Powered Data Creation. PropBank-Powered Data Creation is an expert-in-the-loop data generation pipeline which creates training data for disaster-specific language models. We leverage semantic role labeling and Rich Event Ontology resources to efficiently develop seed sentences for fine-tuning a smaller, targeted model that could operate onboard a robot for disaster relief. We developed 32 sentence templates, which we used to make 2 seed datasets of 175 instructions for earthquake search and rescue and train derailment response. We further leverage our seed datasets as evaluation data to test our baseline fine-tuned models.",
}

@inproceedings{
liu2024best,
title={Best Practices and Lessons Learned on Synthetic Data},
author={Ruibo Liu and Jerry Wei and Fangyu Liu and Chenglei Si and Yanzhe Zhang and Jinmeng Rao and Steven Zheng and Daiyi Peng and Diyi Yang and Denny Zhou and Andrew M. Dai},
booktitle={First Conference on Language Modeling},
year={2024},
url={https://openreview.net/forum?id=OJaWBhh61C}
}

@inproceedings{knowledgebase,
    title = "Language Models as Knowledge Bases?",
    author = {Petroni, Fabio  and
      Rockt{\"a}schel, Tim  and
      Riedel, Sebastian  and
      Lewis, Patrick  and
      Bakhtin, Anton  and
      Wu, Yuxiang  and
      Miller, Alexander},
    booktitle = "Proceedings of the 2019 Conference on Empirical Methods in Natural Language Processing and the 9th International Joint Conference on Natural Language Processing (EMNLP-IJCNLP)",
    month = nov,
    year = "2019",
    address = "Hong Kong, China",
    publisher = "Association for Computational Linguistics",
    url = "https://aclanthology.org/D19-1250",
    doi = "10.18653/v1/D19-1250",
    pages = "2463--2473",
    abstract = "Recent progress in pretraining language models on large textual corpora led to a surge of improvements for downstream NLP tasks. Whilst learning linguistic knowledge, these models may also be storing relational knowledge present in the training data, and may be able to answer queries structured as {``}fill-in-the-blank{''} cloze statements. Language models have many advantages over structured knowledge bases: they require no schema engineering, allow practitioners to query about an open class of relations, are easy to extend to more data, and require no human supervision to train. We present an in-depth analysis of the relational knowledge already present (without fine-tuning) in a wide range of state-of-the-art pretrained language models. We find that (i) without fine-tuning, BERT contains relational knowledge competitive with traditional NLP methods that have some access to oracle knowledge, (ii) BERT also does remarkably well on open-domain question answering against a supervised baseline, and (iii) certain types of factual knowledge are learned much more readily than others by standard language model pretraining approaches. The surprisingly strong ability of these models to recall factual knowledge without any fine-tuning demonstrates their potential as unsupervised open-domain QA systems. The code to reproduce our analysis is available at https://github.com/facebookresearch/LAMA.",
}

@misc{gemini,
      title={Gemini 1.5: Unlocking multimodal understanding across millions of tokens of context}, 
      author={Gemini Team},
      year={2024},
      eprint={2403.05530},
      archivePrefix={arXiv},
      primaryClass={cs.CL},
      url={https://arxiv.org/abs/2403.05530}, 
}

@misc{lora,
      title={LoRA: Low-Rank Adaptation of Large Language Models}, 
      author={Edward J. Hu and Yelong Shen and Phillip Wallis and Zeyuan Allen-Zhu and Yuanzhi Li and Shean Wang and Lu Wang and Weizhu Chen},
      year={2021},
      eprint={2106.09685},
      archivePrefix={arXiv},
      primaryClass={cs.CL},
      url={https://arxiv.org/abs/2106.09685}, 
}

@Misc{peft,
  title =        {PEFT: State-of-the-art Parameter-Efficient Fine-Tuning methods},
  author =       {Sourab Mangrulkar and Sylvain Gugger and Lysandre Debut and Younes Belkada and Sayak Paul and Benjamin Bossan},
  howpublished = {\url{https://github.com/huggingface/peft}},
  year =         {2022}
}

@article{qLORA,
   abstract = {We present QLoRA, an efficient finetuning approach that reduces memory usage enough to finetune a 65B parameter model on a single 48GB GPU while preserving full 16-bit finetuning task performance. QLoRA backpropagates gradients through a frozen, 4-bit quantized pretrained language model into Low Rank Adapters~(LoRA). Our best model family, which we name Guanaco, outperforms all previous openly released models on the Vicuna benchmark, reaching 99.3% of the performance level of ChatGPT while only requiring 24 hours of finetuning on a single GPU. QLoRA introduces a number of innovations to save memory without sacrificing performance: (a) 4-bit NormalFloat (NF4), a new data type that is information theoretically optimal for normally distributed weights (b) double quantization to reduce the average memory footprint by quantizing the quantization constants, and (c) paged optimziers to manage memory spikes. We use QLoRA to finetune more than 1,000 models, providing a detailed analysis of instruction following and chatbot performance across 8 instruction datasets, multiple model types (LLaMA, T5), and model scales that would be infeasible to run with regular finetuning (e.g. 33B and 65B parameter models). Our results show that QLoRA finetuning on a small high-quality dataset leads to state-of-the-art results, even when using smaller models than the previous SoTA. We provide a detailed analysis of chatbot performance based on both human and GPT-4 evaluations showing that GPT-4 evaluations are a cheap and reasonable alternative to human evaluation. Furthermore, we find that current chatbot benchmarks are not trustworthy to accurately evaluate the performance levels of chatbots. A lemon-picked analysis demonstrates where Guanaco fails compared to ChatGPT. We release all of our models and code, including CUDA kernels for 4-bit training.},
   author = {Tim Dettmers and Artidoro Pagnoni and Ari Holtzman and Luke Zettlemoyer},
   month = {5},
   title = {QLoRA: Efficient Finetuning of Quantized LLMs},
   url = {https://arxiv.org/pdf/2305.14314.pdf},
   year = {2023},
}

@misc{llama3,
      title={The Llama 3 Herd of Models}, 
      author={Meta Team},
      year={2024},
      eprint={2407.21783},
      archivePrefix={arXiv},
      primaryClass={cs.AI},
      url={https://arxiv.org/abs/2407.21783}, 
}

@misc{tinystories,
      title={TinyStories: How Small Can Language Models Be and Still Speak Coherent English?}, 
      author={Ronen Eldan and Yuanzhi Li},
      year={2023},
      eprint={2305.07759},
      archivePrefix={arXiv},
      primaryClass={cs.CL},
      url={https://arxiv.org/abs/2305.07759}, 
}

@Article{self-instruct,
   abstract = {Large "instruction-tuned" language models (finetuned to respond to instructions) have demonstrated a remarkable ability to generalize zero-shot to new tasks. Nevertheless, they depend heavily on human-written instruction data that is limited in quantity, diversity, and creativity, therefore hindering the generality of the tuned model. We introduce Self-Instruct, a framework for improving the instruction-following capabilities of pretrained language models by bootstrapping off its own generations. Our pipeline generates instruction, input, and output samples from a language model, then prunes them before using them to finetune the original model. Applying our method to vanilla GPT3, we demonstrate a 33% absolute improvement over the original model on Super-NaturalInstructions, on par with the performance of InstructGPT_001, which is trained with private user data and human annotations. For further evaluation, we curate a set of expert-written instructions for novel tasks, and show through human evaluation that tuning GPT3 with Self-Instruct outperforms using existing public instruction datasets by a large margin, leaving only a 5% absolute gap behind InstructGPT_001. Self-Instruct provides an almost annotation-free method for aligning pre-trained language models with instructions, and we release our large synthetic dataset to facilitate future studies on instruction tuning.},
   author = {Yizhong Wang and Yeganeh Kordi and Swaroop Mishra and Alisa Liu and Noah A. Smith and Daniel Khashabi and Hannaneh Hajishirzi},
   month = {12},
   title = {Self-Instruct: Aligning Language Model with Self Generated Instructions},
   year = {2022},
}

@Inproceedings{rouge,
    title = "{ROUGE}: A Package for Automatic Evaluation of Summaries",
    author = "Lin, Chin-Yew",
    booktitle = "Text Summarization Branches Out",
    month = jul,
    year = "2004",
    address = "Barcelona, Spain",
    publisher = "Association for Computational Linguistics",
    url = "https://aclanthology.org/W04-1013",
    pages = "74--81",
}

@misc{MAD,
      title={Self-Consuming Generative Models Go MAD}, 
      author={Sina Alemohammad and Josue Casco-Rodriguez and Lorenzo Luzi and Ahmed Imtiaz Humayun and Hossein Babaei and Daniel LeJeune and Ali Siahkoohi and Richard G. Baraniuk},
      year={2023},
      eprint={2307.01850},
      archivePrefix={arXiv},
      primaryClass={cs.LG}
}

@techreport{alpaca,
    author = "Rohan Taori and Ishaan Gulrajani and Tianyi Zhang and Yann Dubois and Xuechen Li and Carlos Guestrin and Percy Liang and Tatsunori B. Hashimoto ",
    title = "Stanford Alpaca",
    institution = "Stanford University",
    year = 2023
}

@inproceedings{firstpaper,
    title = "Use Defines Possibilities: Reasoning about Object Function to Interpret and Execute Robot Instructions",
    author = "Shichman, Mollie  and
      Bonial, Claire  and
      Blodgett, Austin  and
      Hudson, Taylor  and
      Ferraro, Francis  and
      Rudinger, Rachel",
    editor = "Amblard, Maxime  and
      Breitholtz, Ellen",
    booktitle = "Proceedings of the 15th International Conference on Computational Semantics",
    month = jun,
    year = "2023",
    address = "Nancy, France",
    publisher = "Association for Computational Linguistics",
    url = "https://aclanthology.org/2023.iwcs-1.30",
    pages = "284--292",
    abstract = "Language models have shown great promise in common-sense related tasks. However, it remains unseen how they would perform in the context of physically situated human-robot interactions, particularly in disaster-relief sce- narios. In this paper, we develop a language model evaluation dataset with more than 800 cloze sentences, written to probe for the func- tion of over 200 objects. The sentences are divided into two tasks: an {``}easy{''} task where the language model has to choose between vo- cabulary with different functions (Task 1), and a {``}challenge{''} where it has to choose between vocabulary with the same function, yet only one vocabulary item is appropriate given real world constraints on functionality (Task 2). DistilBERT performs with about 80{\%} accuracy for both tasks. To investigate how annotator variability affected those results, we developed a follow-on experiment where we compared our original results with wrong answers chosen based on embedding vector distances. Those results showed increased precision across docu- ments but a 15{\%} decrease in accuracy. We con- clude that language models do have a strong knowledge basis for object reasoning, but will require creative fine-tuning strategies in order to be successfully deployed.",
}

@inproceedings{propbank,
  title={PropBank comes of Age—Larger, smarter, and more diverse},
  author={Pradhan, Sameer and Bonn, Julia and Myers, Skatje and Conger, Kathryn and O’gorman, Tim and Gung, James and Wright-Bettner, Kristin and Palmer, Martha},
  booktitle={Proceedings of the 11th Joint Conference on Lexical and Computational Semantics},
  pages={278--288},
  year={2022}
}

@misc{trl,
  author = {Leandro von Werra and Younes Belkada and Lewis Tunstall and Edward Beeching and Tristan Thrush and Nathan Lambert and Shengyi Huang and Kashif Rasul and Quentin Gallouédec},
  title = {TRL: Transformer Reinforcement Learning},
  year = {2020},
  publisher = {GitHub},
  journal = {GitHub repository},
  howpublished = {\url{https://github.com/huggingface/trl}}
}

@misc{semscore,
      title={SemScore: Automated Evaluation of Instruction-Tuned LLMs based on Semantic Textual Similarity}, 
      author={Ansar Aynetdinov and Alan Akbik},
      year={2024},
      eprint={2401.17072},
      archivePrefix={arXiv},
      primaryClass={cs.CL},
      url={https://arxiv.org/abs/2401.17072}, 
}

@article{palmer2005proposition,
  title={The proposition bank: An annotated corpus of semantic roles},
  author={Palmer, Martha and Gildea, Daniel and Kingsbury, Paul},
  journal={Computational linguistics},
  volume={31},
  number={1},
  pages={71--106},
  year={2005},
  publisher={MIT press One Rogers Street, Cambridge, MA 02142-1209, USA journals-info~…}
}

@inproceedings{kazeminejad2018automatically,
  title={Automatically extracting qualia relations for the rich event ontology},
  author={Kazeminejad, Ghazaleh and Bonial, Claire and Brown, Susan Windisch and Palmer, Martha},
  booktitle={Proceedings of the 27th International Conference on Computational Linguistics},
  pages={2644--2652},
  year={2018}
}

@inproceedings{bestsynth,
title={Best Practices and Lessons Learned on Synthetic Data},
author={Ruibo Liu and Jerry Wei and Fangyu Liu and Chenglei Si and Yanzhe Zhang and Jinmeng Rao and Steven Zheng and Daiyi Peng and Diyi Yang and Denny Zhou and Andrew M. Dai},
booktitle={First Conference on Language Modeling},
year={2024},
url={https://openreview.net/forum?id=OJaWBhh61C}
}

@misc{personas,
      title={Scaling Synthetic Data Creation with 1,000,000,000 Personas}, 
      author={Tao Ge and Xin Chan and Xiaoyang Wang and Dian Yu and Haitao Mi and Dong Yu},
      year={2024},
      eprint={2406.20094},
      archivePrefix={arXiv},
      primaryClass={cs.CL},
      url={https://arxiv.org/abs/2406.20094}, 
}

@inproceedings{ultrachat,
title={Enhancing Chat Language Models by Scaling High-quality Instructional Conversations},
author={Ning Ding and Yulin Chen and Bokai Xu and Yujia Qin and Shengding Hu and Zhiyuan Liu and Maosong Sun and Bowen Zhou},
booktitle={The 2023 Conference on Empirical Methods in Natural Language Processing},
year={2023},
url={https://openreview.net/forum?id=oEsYs3WRc3}
}

@article{orca,
  title={Orca: Progressive Learning from Complex Explanation Traces of GPT-4},
  author={Subhabrata Mukherjee and Arindam Mitra and Ganesh Jawahar and Sahaj Agarwal and Hamid Palangi and Ahmed Hassan Awadallah},
  journal={ArXiv},
  year={2023},
  volume={abs/2306.02707},
  url={https://api.semanticscholar.org/CorpusID:259075316}
}

@article{agentsLLM,
   abstract = {Autonomous agents have long been a research focus in academic and industry communities. Previous research often focuses on training agents with limited knowledge within isolated environments, which diverges significantly from human learning processes, and makes the agents hard to achieve human-like decisions. Recently, through the acquisition of vast amounts of Web knowledge, large language models (LLMs) have shown potential in human-level intelligence, leading to a surge in research on LLM-based autonomous agents. In this paper, we present a comprehensive survey of these studies, delivering a systematic review of LLM-based autonomous agents from a holistic perspective. We first discuss the construction of LLM-based autonomous agents, proposing a unified framework that encompasses much of previous work. Then, we present a overview of the diverse applications of LLM-based autonomous agents in social science, natural science, and engineering. Finally, we delve into the evaluation strategies commonly used for LLM-based autonomous agents. Based on the previous studies, we also present several challenges and future directions in this field.},
   author = {Lei Wang and Chen Ma and Xueyang Feng and Zeyu Zhang and Hao Yang and Jingsen Zhang and Zhiyuan Chen and Jiakai Tang and Xu Chen and Yankai Lin and Wayne Xin Zhao and Zhewei Wei and Jirong Wen},
   doi = {10.1007/s11704-024-40231-1},
   issn = {2095-2228},
   issue = {6},
   journal = {Frontiers of Computer Science},
   month = {12},
   pages = {186345},
   title = {A survey on large language model based autonomous agents},
   volume = {18},
   url = {https://link.springer.com/article/10.1007/s11704-024-40231-1#Abs1},
   year = {2024},
}

@article{CoT,
   abstract = {We explore how generating a chain of thought -- a series of intermediate reasoning steps -- significantly improves the ability of large language models to perform complex reasoning. In particular, we show how such reasoning abilities emerge naturally in sufficiently large language models via a simple method called chain of thought prompting, where a few chain of thought demonstrations are provided as exemplars in prompting. Experiments on three large language models show that chain of thought prompting improves performance on a range of arithmetic, commonsense, and symbolic reasoning tasks. The empirical gains can be striking. For instance, prompting a 540B-parameter language model with just eight chain of thought exemplars achieves state of the art accuracy on the GSM8K benchmark of math word problems, surpassing even finetuned GPT-3 with a verifier.},
   author = {Jason Wei and Xuezhi Wang and Dale Schuurmans and Maarten Bosma and Brian Ichter and Fei Xia and Ed Chi and Quoc Le and Denny Zhou},
   month = {1},
   note = {went from (prompt, answer) tuples to (prompt, chain-of-thought explanation, answer) tuples and got much better results from few shot training.},
   title = {Chain-of-Thought Prompting Elicits Reasoning in Large Language Models},
   url = {https://arxiv.org/pdf/2201.11903.pdf},
   year = {2022},
}

@inproceedings{reprompt,
title={Planning With Large Language Models Via Corrective Re-Prompting},
author={Shreyas Sundara Raman and Vanya Cohen and Eric Rosen and Ifrah Idrees and David Paulius and Stefanie Tellex},
booktitle={NeurIPS 2022 Foundation Models for Decision Making Workshop},
year={2022},
url={https://openreview.net/forum?id=cMDMRBe1TKs}
}

@inproceedings{ToT,
title={Tree of Thoughts: Deliberate Problem Solving with Large Language Models},
author={Shunyu Yao and Dian Yu and Jeffrey Zhao and Izhak Shafran and Thomas L. Griffiths and Yuan Cao and Karthik R Narasimhan},
booktitle={Thirty-seventh Conference on Neural Information Processing Systems},
year={2023},
url={https://openreview.net/forum?id=5Xc1ecxO1h}
}

@InProceedings{innermono,
  title = 	 {Inner Monologue: Embodied Reasoning through Planning with Language Models},
  author =       {Huang, Wenlong and Xia, Fei and Xiao, Ted and Chan, Harris and Liang, Jacky and Florence, Pete and Zeng, Andy and Tompson, Jonathan and Mordatch, Igor and Chebotar, Yevgen and Sermanet, Pierre and Jackson, Tomas and Brown, Noah and Luu, Linda and Levine, Sergey and Hausman, Karol and ichter, brian},
  booktitle = 	 {Proceedings of The 6th Conference on Robot Learning},
  pages = 	 {1769--1782},
  year = 	 {2023},
  editor = 	 {Liu, Karen and Kulic, Dana and Ichnowski, Jeff},
  volume = 	 {205},
  series = 	 {Proceedings of Machine Learning Research},
  month = 	 {14--18 Dec},
  publisher =    {PMLR},
  pdf = 	 {https://proceedings.mlr.press/v205/huang23c/huang23c.pdf},
  url = 	 {https://proceedings.mlr.press/v205/huang23c.html},
  abstract = 	 {Recent works have shown how the reasoning capabilities of Large Language Models (LLMs) can be applied to domains beyond natural language processing, such as planning and interaction for robots. These embodied problems require an agent to understand many semantic aspects of the world: the repertoire of skills available, how these skills influence the world, and how changes to the world map back to the language. LLMs planning in embodied environments need to consider not just what skills to do, but also how and when to do them - answers that change over time in response to the agent’s own choices. In this work, we investigate to what extent LLMs used in such embodied contexts can reason over sources of feedback provided through natural language, without any additional training. We propose that by leveraging environment feedback, LLMs are able to form an inner monologue that allows them to more richly process and plan in robotic control scenarios. We investigate a variety of sources of feedback, such as success detection, scene description, and human interaction. We find that closed-loop language feedback significantly improves high level instruction completion on three domains, including simulated and real table top rearrangement tasks and long-horizon mobile manipulation tasks in a kitchen environment in the real world.}
}


@InProceedings{sayplan,
  title = 	 {SayPlan: Grounding Large Language Models using 3D Scene Graphs for Scalable Robot Task Planning},
  author =       {Rana, Krishan and Haviland, Jesse and Garg, Sourav and Abou-Chakra, Jad and Reid, Ian and Suenderhauf, Niko},
  booktitle = 	 {Proceedings of The 7th Conference on Robot Learning},
  pages = 	 {23--72},
  year = 	 {2023},
  editor = 	 {Tan, Jie and Toussaint, Marc and Darvish, Kourosh},
  volume = 	 {229},
  series = 	 {Proceedings of Machine Learning Research},
  month = 	 {06--09 Nov},
  publisher =    {PMLR},
  pdf = 	 {https://proceedings.mlr.press/v229/rana23a/rana23a.pdf},
  url = 	 {https://proceedings.mlr.press/v229/rana23a.html},
  abstract = 	 {Large language models (LLMs) have demonstrated impressive results in developing generalist planning agents for diverse tasks. However, grounding these plans in expansive, multi-floor, and multi-room environments presents a significant challenge for robotics. We introduce SayPlan, a scalable approach to LLM-based, large-scale task planning for robotics using 3D scene graph (3DSG) representations. To ensure the scalability of our approach, we: (1) exploit the hierarchical nature of 3DSGs to allow LLMs to conduct a "semantic search" for task-relevant subgraphs from a smaller, collapsed representation of the full graph; (2) reduce the planning horizon for the LLM by integrating a classical path planner and (3) introduce an "iterative replanning" pipeline that refines the initial plan using feedback from a scene graph simulator, correcting infeasible actions and avoiding planning failures. We evaluate our approach on two large-scale environments spanning up to 3 floors and 36 rooms with 140 assets and objects and show that our approach is capable of grounding large-scale, long-horizon task plans from abstract, and natural language instruction for a mobile manipulator robot to execute. We provide real robot video demonstrations on our project page https://sayplan.github.io.}
}

@article{humanplan,
  title={A Human-Like Reasoning Framework for Multi-Phases Planning Task with Large Language Models},
  author={Chengxing Xie and Difan Zou},
  journal={ArXiv},
  year={2024},
  volume={abs/2405.18208},
  url={https://api.semanticscholar.org/CorpusID:270068266}
}

@phdthesis{LLMdisaster,
author={Godinho,Matilde M. L.},
year={2024},
title={The Impact of Natural Language Processing in Disaster Management: A Systematic Literature Review},
journal={PQDT - Global},
pages={108},
note={Copyright - Database copyright ProQuest LLC; ProQuest does not claim copyright in the individual underlying works; Last updated - 2024-10-19},
abstract={In an era where undeniably large amounts of data are produced at an unprecedented rate by a broad variety of sources, artificial intelligence and, more specifically, natural language processing present interesting solutions to today’s complex challenges. When properly implemented, natural language processing may play an essential role in all phases of the disaster management cycle by delivering timely and reliable information, optimizing resources and logistics, and assisting in reducing the effect that both natural and man-made disasters have on society. This paper presents a systematic literature review that aims to (1) identify the range of natural language processing methods used in disaster management, (2) explore the main challenges and opportunities in disaster management when using natural language processing, and (3) determine how this field impacts the four phases of disaster as well as the nature of such impact. The data was gathered using Scopus database and, with the help of Zotero citation manager tool, filtered by full-text peer-reviewed quartile 1 journal articles written in English and published between 2014 and 2023. Following the Preferred Reporting Items for Systematic Reviews and Meta-Analyses (PRISMA) 2020 guidelines, this review is based on 107 articles selected out of 548 search results obtained in February 2024. The findings indicate that social media and sentiment analysis have had an exponential growth in applications and importance within the field of disaster management. We analyze the current academic literature on the link between natural language processing and disaster management, identifying research gaps and potential for future research.},
keywords={Artificial intelligence; Social networks; Information retrieval; Web studies; 0646:Internet and social media studies; 0800:Artificial intelligence},
isbn={9798384262282},
language={English},
url={https://www.proquest.com/dissertations-theses/impact-natural-language-processing-disaster/docview/3110355993/se-2},
}

@misc{semcode,
  author = {Geronimo and Issac Lera},
  title = {SemScore},
  year = {2024},
  publisher = {GitHub},
  journal = {GitHub repository},
  url={https://github.com/geronimi73/semscore}

}

@article{reuters,
author = {Arranz, Adolfo and Scarr, Simon and Chowdhury, Jitesh},
title = {Searching for life in the rubble: How search and rescue teams comb debris for survivors after devastating earthquakes},
year = {2023},
month = {09},
url = {https://www.reuters.com/graphics/EARTHQUAKE-RESCUE/mopajqojmva/}
}

@misc{cohen2024surveyroboticlanguagegrounding,
      title={A Survey of Robotic Language Grounding: Tradeoffs between Symbols and Embeddings}, 
      author={Vanya Cohen and Jason Xinyu Liu and Raymond Mooney and Stefanie Tellex and David Watkins},
      year={2024},
      eprint={2405.13245},
      archivePrefix={arXiv},
      primaryClass={cs.RO},
      url={https://arxiv.org/abs/2405.13245}, 
}

@article{valmeekam2023planning,
  title={On the planning abilities of large language models-a critical investigation},
  author={Valmeekam, Karthik and Marquez, Matthew and Sreedharan, Sarath and Kambhampati, Subbarao},
  journal={Advances in Neural Information Processing Systems},
  volume={36},
  pages={75993--76005},
  year={2023}
}

@inproceedings{chen2024autotamp,
  title={Autotamp: Autoregressive task and motion planning with llms as translators and checkers},
  author={Chen, Yongchao and Arkin, Jacob and Dawson, Charles and Zhang, Yang and Roy, Nicholas and Fan, Chuchu},
  booktitle={2024 IEEE International conference on robotics and automation (ICRA)},
  pages={6695--6702},
  year={2024},
  organization={IEEE}
}

@inproceedings{sermanet2024robovqa,
  title={Robovqa: Multimodal long-horizon reasoning for robotics},
  author={Sermanet, Pierre and Ding, Tianli and Zhao, Jeffrey and Xia, Fei and Dwibedi, Debidatta and Gopalakrishnan, Keerthana and Chan, Christine and Dulac-Arnold, Gabriel and Maddineni, Sharath and Joshi, Nikhil J and others},
  booktitle={2024 IEEE International Conference on Robotics and Automation (ICRA)},
  pages={645--652},
  year={2024},
  organization={IEEE}
}

@misc{wei2022emergentabilitieslargelanguage,
      title={Emergent Abilities of Large Language Models}, 
      author={Jason Wei and Yi Tay and Rishi Bommasani and Colin Raffel and Barret Zoph and Sebastian Borgeaud and Dani Yogatama and Maarten Bosma and Denny Zhou and Donald Metzler and Ed H. Chi and Tatsunori Hashimoto and Oriol Vinyals and Percy Liang and Jeff Dean and William Fedus},
      year={2022},
      eprint={2206.07682},
      archivePrefix={arXiv},
      primaryClass={cs.CL},
      url={https://arxiv.org/abs/2206.07682}, 
}

@misc{mistral7,
    title={Un Ministral, des Ministraux},
    author={Mistral AI Team},
    year={2024},
    url={https://mistral.ai/en/news/ministraux},
}

@inproceedings{reportingbias, author = {Gordon, Jonathan and Van Durme, Benjamin}, title = {Reporting bias and knowledge acquisition}, year = {2013}, isbn = {9781450324113}, publisher = {Association for Computing Machinery}, address = {New York, NY, USA}, url = {https://doi.org/10.1145/2509558.2509563}, doi = {10.1145/2509558.2509563}, abstract = {Much work in knowledge extraction from text tacitly assumes that the frequency with which people write about actions, outcomes, or properties is a reflection of real-world frequencies or the degree to which a property is characteristic of a class of individuals. In this paper, we question this idea, examining the phenomenon of reporting bias and the challenge it poses for knowledge extraction. We conclude with discussion of approaches to learning commonsense knowledge from text despite this distortion.}, booktitle = {Proceedings of the 2013 Workshop on Automated Knowledge Base Construction}, pages = {25–30}, numpages = {6}, keywords = {text frequency, reporting bias, knowledge extraction}, location = {San Francisco, California, USA}, series = {AKBC '13} }

@misc{mistral7battention,
      title={Mistral 7B}, 
      author={Albert Q. Jiang and Alexandre Sablayrolles and Arthur Mensch and Chris Bamford and Devendra Singh Chaplot and Diego de las Casas and Florian Bressand and Gianna Lengyel and Guillaume Lample and Lucile Saulnier and Lélio Renard Lavaud and Marie-Anne Lachaux and Pierre Stock and Teven Le Scao and Thibaut Lavril and Thomas Wang and Timothée Lacroix and William El Sayed},
      year={2023},
      eprint={2310.06825},
      archivePrefix={arXiv},
      primaryClass={cs.CL},
      url={https://arxiv.org/abs/2310.06825}, 
}

@article{Text2Afford,
  title={Text2Afford: Probing Object Affordance Prediction abilities of Language Models solely from Text},
  author={Sayantan Adak and Daivik Agrawal and Animesh Mukherjee and Somak Aditya},
  journal={Proceedings of the 28th Conference on Computational Natural Language Learning},
  year={2024},
  url={https://api.semanticscholar.org/CorpusID:267759895}
}

@misc{disagree,
  author = {Oliver Price and Martino Mensio},
  title = {disagree - Assessing Annotator Disagreements in Python},
  year = {2022},
  publisher = {GitHub},
  journal = {GitHub repository},
  url={https://github.com/o-P-o/disagree}

}