\documentclass[conference]{IEEEtran}
\IEEEoverridecommandlockouts
% The preceding line is only needed to identify funding in the first footnote. If that is unneeded, please comment it out.

\usepackage{hyperref}
\usepackage{graphicx} 
\usepackage{caption}
\usepackage{subcaption}
\usepackage{algorithm}
\usepackage{algpseudocode}
\usepackage{booktabs} 
\usepackage{cleveref}
\usepackage[normalem]{ulem}
\usepackage{xcolor}
\usepackage{gensymb}



\def\BibTeX{{\rm B\kern-.05em{\sc i\kern-.025em b}\kern-.08em
    T\kern-.1667em\lower.7ex\hbox{E}\kern-.125emX}}
    \makeatletter
\newcommand{\linebreakand}{%
  \end{@IEEEauthorhalign}
  \hfill\mbox{}\par
  \mbox{}\hfill\begin{@IEEEauthorhalign}
}
\makeatother
\begin{document}

%\title {Towards Automated Road Extraction and Centreline Fitting from MLS Point Clouds: A Bird's Eye View-Based Approach}
\title{Automated Road Extraction and Centreline Fitting in LiDAR Point Clouds\\
\thanks{979-8-3503-7903-7/24/\$31.00 ©2024 IEEE}
}

\author{
    \IEEEauthorblockN{Xinyu Wang}
    \IEEEauthorblockA{
        \textit{The University of Western Australia} \\
        Perth, Australia \\
        23631069@student.uwa.edu.au
    }
    \and
    \IEEEauthorblockN{Muhammad Ibrahim}
    \IEEEauthorblockA{
        \textit{Department of Primary Industries and Regional Development} \\
        Perth, Australia \\
        muhammad.ibrahim@dpird.wa.gov.au
    }
    \linebreakand 
    \IEEEauthorblockN{Atif Mansoor}
    \IEEEauthorblockA{
        \textit{The University of Western Australia} \\
        Perth, Australia \\
        atif.mansoor@uwa.edu.au
    }
    \and
    \IEEEauthorblockN{Hasnein Tareque}
    \IEEEauthorblockA{
        \textit{Department of Primary Industries and Regional Development} \\
        Perth, Australia \\
        hasnein.tareque@dpird.wa.gov.au
    }
    \linebreakand 
    \IEEEauthorblockN{Ajmal Mian}
    \IEEEauthorblockA{
        \textit{The University of Western Australia} \\
        Perth, Australia \\
        ajmal.mian@uwa.edu.au
    }
}

\maketitle

% \documentclass[conference]{IEEEtran}
% \IEEEoverridecommandlockouts
% \usepackage{hyperref}
% \usepackage{graphicx} % Required for inserting images
% \usepackage{caption}
% \usepackage{subcaption}
% \usepackage{algorithm}
% \usepackage{algpseudocode}
% \usepackage{booktabs} 


% % \date{\includegraphics[width=1\textwidth],{Map1.PNG}}
% % \usepackage[font=small,labelfont=bf,tableposition=top]{caption}
% \def\BibTeX{{\rm B\kern-.05em{\sc i\kern-.025em b}\kern-.08em
%     T\kern-.1667em\lower.7ex\hbox{E}\kern-.125emX}}
% \renewcommand{\thefigure}{\arabic{figure}}

% \setcounter{figure}{1} 
    
% \begin{document}

% \author{
%     \IEEEauthorblockN{Xinyu Wang}
%     \IEEEauthorblockA{
%         \textit{The University of Western Australia} \\
%         \textit{Perth, Australia}\\
%         23631069@student.uwa.edu.au
%     }
%     \and
%     \IEEEauthorblockN{Muhammad Ibrahim}
%     \IEEEauthorblockA{
%         \textit{Department of Primary Industries} \\
%         \textit{ and Regional Development} \\
%         \textit{Perth, Australia}\\
%         muhammad.ibrahim@dpird.wa.gov.au
%     }
%     \and \linebreakand % 
%     \IEEEauthorblockN{Atif Mansoor}
%     \IEEEauthorblockA{
%         \textit{The University of Western Australia} \\
%         \textit{Perth, Australia}\\
%         atif.mansoor@uwa.edu.au
%     }
%     \and
%     \IEEEauthorblockN{Ajmal Mian}
%     \IEEEauthorblockA{
%         \textit{The University of Western Australia} \\
%         \textit{Perth, Australia}\\
%         ajmal.mian@uwa.edu.au
%     }
% }



% % 
% \title {Road point extraction and centreline fitting from top down view}



% \maketitle
\begin{abstract}
Road information extraction from 3D point clouds is useful for urban planning and traffic management. Existing methods often rely on local features and the refraction angle of lasers from kerbs, which makes them sensitive to variable kerb designs and issues in high-density areas due to data homogeneity. We propose an approach for extracting road points and fitting centrelines using a top-down view of LiDAR based ground-collected point clouds. This prospective view reduces reliance on specific kerb design and results in better road extraction. We first perform statistical outlier removal and density-based clustering to reduce noise from 3D point cloud data. Next, we perform ground point filtering using a grid-based segmentation method that adapts to diverse road scenarios and terrain characteristics. The filtered points are then projected onto a 2D plane, and the road is extracted by a skeletonisation algorithm. The skeleton is back-projected onto the 3D point cloud with calculated normals, which guide a region growing algorithm to find nearby road points. The extracted road points are then smoothed with the Savitzky-Golay filter to produce the final centreline. Our initial approach without post-processing of road skeleton achieved 67\% in IoU by testing on the Perth CBD dataset with different road types. Incorporating the post-processing of the road skeleton improved the extraction of road points around the smoothed skeleton. The refined approach achieved a higher IoU value of 73\% and with 23\% reduction in the processing time. Our approach offers a generalised and computationally efficient solution that combines 3D and 2D processing techniques, laying the groundwork for future road reconstruction and 3D-to-2D point cloud alignment.

\begin{IEEEkeywords}
LiDAR, 3D point clouds, road extraction, centreline extraction. 
\end{IEEEkeywords}

% The extraction of road information from 3D point clouds has become increasingly important for road network reconstruction, urban planning and traffic management. This paper proposes an approach for road point extraction and centreline fitting from the bird's eye view using ground collected point clouds. The methodology involves a series of steps, including data preprocessing, ground point filtering, and road framework extraction. In the preprocessing stage, statistical outlier removal and density-based clustering are employed to eliminate noise and isolated regions. A grid-based segmentation method is introduced for ground point filtering, adapting to various road scenarios and terrain characteristics. The filtered ground point cloud is then projected onto a 2D plane, and the road framework is extracted using a skeletonisation algorithm. The extracted skeleton points are smoothed using the Savitzky-Golay filter to obtain a smooth result. Experiments conducted on the Perth CBD dataset demonstrate the effectiveness of the proposed approach in extracting ground points and frameworks from large-scale urban point clouds at the current stage. The methodology combines 3D point cloud processing and 2D image processing techniques, potentially offering robustness and computational efficiency. However, further research is needed to achieve the final result in complex urban environments and to develop quantitative evaluation metrics. The current result of this study provides a foundation for future work on road structure reconstruction and large-scale 3D point cloud alignment with 2D satellite map.

\end{abstract}

% \begin{IEEEkeywords}
% working 
% \end{IEEEkeywords}

\section {Introduction}
With the rapid increase in urbanization, there is a dire need for improved urban planning and traffic management. Accurate road information is critical for enhancing the navigation accuracy of autonomous vehicles, optimizing urban resource allocation, and improving emergency response systems \cite{Kootsookos, Bisheng}. Efficient road extraction is also essential for creating up-to-date road structures, monitoring road conditions, and enabling autonomous vehicles to navigate safely.

3D point clouds acquired with LiDAR sensors are commonly used for road mapping in cities \cite{BOYKO2011S2} as well as buildings \cite{Kaminsky}. Surveyors no longer need to rely on handheld instruments for point-to-point measurement, leading to reduced work hours and improved safety \cite{rs10101531}. Extracting roads from images has limitations, as images do not capture 3D structure and are sensitive to environmental factors like lighting and weather changes \cite{9339878, 7287763, UnLoc}, making multiview 3D structure estimation challenging. In contrast, LiDAR sensors offer unique advantages by capturing spatial structures in 3D \cite{s24020503} through active sensing, generating 3D point clouds with rich structural details and fewer external interferences compared to 2D image-based techniques \cite{WeixingWang2016Aror}. Active sensing also makes LiDAR scanning robust to extreme changes in illumination, significantly improving the accuracy and reliability of road point extraction and centerline fitting with LiDAR-based data.

\textcolor{black}{Compared to point clouds collected by airborne LiDAR sensors \cite{article-2, 10092204}, ground-based 3D point cloud data is more suitable for urban areas. Firstly, ground-based scanning provides a more dense coverage of the locality. Secondly, ground-based scanning avoids occlusions caused by tree canopies, bridges and other similar structures. Finally, flying drones in densely populated urban areas is generally prohibited. Keeping in view these reasons, our approach focuses on 3D point clouds collected from ground based sensors.}

% Along with ground based 3D point cloud data collection, drone mounted LiDAR sensors are also used for this purpose \cite{article-2, 10092204}. There are three primary reasons for choosing ground-based LiDAR scanners over drone-mounted ones. Firstly, ground based scanning can provide a more dense coverage of the locality. Secondly, ground based scanning avoids occlusions caused by tree canopies, bridges and other suspended structures. Finally, flying drones in densely populated urban areas is generally prohibited. Therefore, our approach works on 3D point clouds collected from ground based sensors. 

\textcolor{black}{Ground-based 3D point cloud data used for road extraction can be divided into two main types.} The first consists of independent frames of point clouds acquired from sensors mounted on vehicles \cite{Wen2008/12}. These are appropriate for real-time navigation and swift environmental analysis, focusing on rapid processing and accurate road information extraction to support navigation in dynamic environments \cite{YANG201380, 5940447}. The second type is large-scale point cloud, which offers a broad coverage and is mainly used in urban planning and management \cite{rs10101531}. This type of point cloud data is usually a merged version of the first type. Such applications typically involve 3D city modelling and extensive terrain mapping \cite{MRENet, 7729407}. Both present unique attributes regarding data volume, coverage, the required processing techniques and processing time \cite{s24020503, 9339878}. 

% Add refrence for the actively researching

% Road extraction in city environment is actively researched. Suleymanoglu et. al.
Many researchers have focused on road extraction from 3D point clouds in urban environments. Suleymanoglu et al. \cite{s24020503} used an activity-driven method that leverages vehicle trajectory data to distinguish road and non-road regions, such as by analyzing GPS trajectories to determine road areas. However, vehicle trajectory data may not be available in some cases. Other research approaches implement feature-driven methods that detect lane lines and road boundaries by extracting distinctive features like curb height, point cloud density projection, and road flatness \cite{9339878, YANG201380, MRENet, inproceedings_1}. Additional approaches extract road surfaces by analyzing point cloud density, elevation differences, and slope changes \cite{BOYKO2011S2, article-2}. Some methods focus on elevation discontinuities at road boundaries to extract curb points \cite{7938403, 7995848, article-1, Qingquan}, but road discontinuity and boundary features can be unreliable due to structural variations. To overcome these limitations, in this paper, we propose an approach for road extraction and centerline fitting from top-down 3D point clouds. Our method combines statistical outlier removal, grid-based segmentation, and 2D skeletonization to achieve promising results without relying on vehicle trajectory data or roadside/curb detection.


% This paper aims to explore the potential of applying ground-generated point clouds and computer vision algorithms for automatic road points extraction and centreline fitting. Our approach implements DBSCAN  and downsampling on point cloud data to eliminate noise and isolated areas \cite{10.5555/3001460.3001507}. The point cloud is then segmented into smaller blocks on the XY plane. Within each block, the RANSAC algorithm is used to fit planes and assess their angles \cite{10.1145/358669.358692}. We retain planes that resemble road surfaces on the basis of angles and majority coverage of the blocks. The other planes are filtered out using a moving threshold method, which helps to retain data from lower layers, while vertical planes are discarded. The collected road surface data from all blocks is further refined through DBSCAN and downsampling to maintain continuity and ensure alignment with the original coordinates. This refined point cloud is then projected onto the XY plane to create a top down projection. The projection result is further processed through binarisation and Gaussian blur to improve structural visibility. Skeletonisation is then applied to extract centre lines, which are converted into scatter points and smoothed with the Savitzky-Golay filter \cite{Savitzky_golay} to form precise road skeletons. These 2D skeletons are then re-projected onto the 3D point cloud with calculated normals. Skeleton normals are used to guide the region growing algorithm to find nearby road points. The detailed pipeline of our method is illustrated in Figure \ref{pipeline}. The proposed approach is tested on the Perth CBD point cloud dataset, which was constructed by Ibrahim et al. \cite{9647060}. 






%Our research has so far developed the process described. This ongoing work aims to Our main motivation is to develop a lightweight, highly universal algorithm, particularly suitable for road structure re-construction and urban road traffic planning \cite{article-2}. 
%Additionally, the results will provide valuable insights and references for the subsequent alignment projects between large-scale 3D point clouds and 2D satellite images.

% Our proposed method first denoises and downsamples the large-scale point cloud data to improve subsequent computational efficiency. The point cloud is then divided into small grids for processing to enhance the generalisability of the algorithm. In each small grid, the algorithm attempts to fit planes using RANSAC and determines the plane angles. If a plane's angle is similar to the road surface and takes up most of the grid, it is identified as the road surface. Otherwise, non-ground points are filtered out using a moving median approach. After processing all grids, discrete points are further removed to ensure result accuracy. Finally, the processed 3D point cloud is projected onto a 2D plane for skeleton extraction and centreline calculation. The centreline is smoothed using a Savitzky-Golay filter.
% 


% Through this research, we aim to develop a lightweight algorithm with strong generalisability, especially suitable for point cloud-assisted registration and urban road traffic planning. Additionally, the research findings will provide valuable experience and reference for subsequent alignment project between large-scale 3D point clouds and 2D satellite images.


The rest of the paper is organised as follows. Section \ref{Related Works} surveys existing road extraction methods. The proposed approach is explained in Section \ref{Methodology}. Experiments and results are discussed  in Section \ref{Experiment}. Section \ref{conclusion} discusses the conclusion and future directions.

%This paper includes an introduction, related works, methodology, experiment and results and way forward and conclusion. It presents the research process and outcomes at the current stage. The introduction summarises the background and objectives; the related work section reviews existing approaches; the methodology section explains the purposed approach; the experiment and results section details the testing process together with the result visualisation; and the last section discusses the future directions with conclusion.



\section {Related Work} \label{Related Works}
  
%This section aims to provide an overview of existing 3D road extraction approaches, focusing on their application in urban environments across different methodologies. DBSCAN~\cite{schubert2017dbscan} and downsampling on point cloud data to eliminate noise and isolated areas. The point cloud is then segmented into smaller blocks on the XY plane. Within each block, the RANSAC algorithm~\cite{schnabel2007efficient} 

Feature-based methods have been extensively explored in the field of 3D road extraction. Lu et al. proposed combination of machine learning with clustering techniques, such as Density-based clustering algorithm (DBSCAN)~\cite{schubert2017dbscan} and Random sample consensus (RANSAC)~\cite{schnabel2007efficient}, to handle complex road scenarios, including straight segments, turns, and roundabouts \cite{s24020503}. This method has been evaluated on data acquired from Mobile Laser Scanning (MLS) and Mobile Mapping System (MMS). Yang et al. proposed point cloud segmentation and model-driven extraction, where the point cloud was segmented into patches, and a moving window operation was employed to filter out non-ground points \cite{YANG201380}. A model-driven strategy is then used to extract curb points, followed by a refinement and optimisation process to generate the filtered road surface points.  Additionally, an approach that utilises SuperVoxel clustering has been proposed by Mi et al.  for automatic extraction and vectorisation of 3D road boundaries from MLS point clouds \cite{9339878}. This method employs SuperVoxel clustering to extract candidate curb points and applies contracted distance clustering to group boundary segments. The final vectorised road boundaries are generated through an automated extraction pipeline structure including steps such as fitting, tracking, and final completion.

Deep learning methods are actively researched for road extraction and centerline fitting \cite{Balado}. Ma et al. proposed a multi-scale point-based convolutional neural network (CNN) for 3D object segmentation from large-scale LiDAR point clouds \cite{8943956}. The approach employed improved point convolution, a U-shaped downsampling - upsampling structure, and dynamic graph convolution modules. Another deep learning-based approach proposed by Soilán et al. utilises 3D point clouds acquired from low-cost mobile laser scanning systems to parameterise road horizontal alignment \cite{article-4}. The approach used deep learning for semantic segmentation of point clouds and extracted road centrelines with classification. This method also involves parameterising the geometric information of each curve to generate road alignment data.

Hui et al. proposed a road centerline extraction approach that employs skewness balancing, rotating neighborhoods, hierarchical fusion, and optimization algorithms \cite{article-2}. Boyko et al. introduced a method that divides the road network into independent patches, allowing for efficient processing of large datasets \cite{BOYKO2011S2}. Their method uses heuristic techniques such as curb detection to extract road boundaries. Despite these advancements, road extraction from point clouds remains challenging due to varying curb designs \cite{doi:10.1080/19479832.2016.1188860, 10087468} and homogeneity issues in dense areas \cite{10.1145/1653771.1653851}. Changes in road structures and curb designs further complicate road extraction \cite{7287763}.


% Addressing these, our project uses a Bird Eye View (BEV) and computer vision to extract road segments with consistency, mitigating local design impacts and enhancing adaptability in complex urban settings. This approach promises improved robustness for future urban mapping and 3D-to-2D alignments.


% Despite the advancements in road extraction approach, challenges and limitations persist. Most existing methods for large-scale urban point clouds rely on local features to extract road edges, often utilising the deviation caused by the refraction angle of laser on the vertical plane due to kerbs. However, these methods are highly dependent on kerb design, which can vary significantly across different regions \cite{doi:10.1080/19479832.2016.1188860, 10087468}. Moreover, in high-density urban areas, the extracted data using these methods may exhibit high homogeneity, potentially causing issues in downstream applications \cite{10.1145/1653771.1653851}. Furthermore, urban environments are dynamic, and the physical and visual characteristics of roads and sidewalks can change over time due to construction, maintenance, or natural wear. Methods relying on fixed physical properties may struggle to adapt to these changes, affecting their long-term stability and reliability \cite{7287763}.


% The challenges posed by urban environments have motivated the development of the approach to address the limitations of existing 3D road extraction methods. This project proposes the use of computer vision techniques to extract road segments and compute road centrelines from the Bird Eye View (BEV) perspective. By adopting this viewpoint, the influence of kerb shape variations and the homogeneity of urban environments on the extraction results can be mitigated. The BEV approach enables the extraction of road features that are more consistent and less affected by local variations in road design and surrounding structures. Furthermore, the extracted data from this perspective is better suited for future applications that rely on BEV representations, such as urban road reconstruction and the alignment of 3D point clouds with 2D maps. The integration of computer vision techniques with the BEV perspective has the potential to improve the robustness and adaptability of road extraction methods in complex urban environments.



Feature-based strategies, merging machine learning with clustering \cite{s24020503, MRENet}, and model-driven approaches \cite{YANG201380} have proven effective in complex environments. Deep learning methods, such as point-based CNNs \cite{8943956} and semantic segmentation \cite{article-4}, have demonstrated promising results in road data extraction. Algorithms like Skewness balancing and patch-based processing \cite{article-2, BOYKO2011S2} enhance road extraction efficiency and accuracy in dense point clouds.  Road extraction from point clouds is still a challenging problem due to variations in curb design \cite{doi:10.1080/19479832.2016.1188860}, lack of data uniformity in dense urban areas \cite{10.1145/1653771.1653851}, and the dynamic nature of urban environments \cite{7287763}. Our porposed method overcomes these challenges.

% Challenges for road extraction remain with kerb design dependence \cite{doi:10.1080/19479832.2016.1188860}, data uniformity in dense urban areas \cite{10.1145/1653771.1653851}, and urban dynamicity \cite{7287763}. 
% This paper addresses these issues using BEV computer vision, aiming for more general and adaptable road feature extraction suitable for future applications.

\begin{figure*}[ht]
    \centering
    \includegraphics[width=1\linewidth]{Frank_DICTA_Imgs/pipeline.jpg}
    \caption{\small Workflow of point cloud data processing for feature extraction and analysis. (\textbf{1}) Initial input. (\textbf{2}) Removal of outliers and isolated areas to clean the data based on DBSCAN algorithm. (\textbf{3}) Grid processing that segments the point cloud into smaller parts. (\textbf{4}) Fitting of ground points using filtering methods. (\textbf{5}) Resultant ground points after processing. (\textbf{6}) Projection of the cleaned point cloud onto the XY-plane for 2D representation. (\textbf{7}) Further 2D image processing and skeletonisation to extract structural features. (\textbf{8}) Smoothing the framework by Savitzky-Golay filter followed by back projection to the original 3D space. (\textbf{9}) Normal-based region growing algorithm will be used on the filtered data to segment and generate the final processed result.}
    \label{pipeline}
\end{figure*}

\section {Proposed Approach} \label{Methodology}

 %Fig.~\ref{pipeline} shows the pipeline of our proposed approach. Our approach implements DBSCAN and downsampling on point cloud data to eliminate noise and isolated areas. The point cloud is then segmented into smaller blocks on the XY plane. Within each block, the RANSAC algorithm is used to fit planes and assess their angles. We retain planes that resemble road surfaces on the basis of angles and majority coverage of the blocks. The other planes are filtered out using a moving threshold method, which helps to retain data from lower layers, while vertical planes are discarded. The road surface points gathered from all blocks is processed using DBSCAN technique to remove isolated areas. Corner points are added to the extracted road point cloud to maintain the initial alignment with original raw data. The processed data is then mapped onto the XY plane to generate a top-down projection image. The projection result is further processed through binarisation and Gaussian blur to improve structural visibility. Skeletonisation is then applied to extract centre lines, which are converted into scatter points and smoothed with the Savitzky-Golay filter \cite{Savitzky_golay} to form precise road skeletons. These 2D skeletons are then re-projected onto the 3D point cloud with calculated normals. Skeleton normals are used to guide the region-growing algorithm to find nearby road points. The proposed approach is tested on the Perth CBD point cloud dataset \cite{9647060}. 

 Fig.~\ref{pipeline} illustrates the pipeline of our proposed approach. First, DBSCAN and downsampling are applied to the point cloud data to eliminate noise and isolated areas. The point cloud is then segmented into smaller blocks on the XY plane. Within each block, the RANSAC algorithm is used to fit planes and assess their angles. Planes resembling road surfaces are retained based on angle criteria and majority coverage of the blocks, while other planes are filtered out using a moving threshold method, which preserves data from lower layers while discarding vertical planes. The road surface points collected from all blocks are further processed using DBSCAN to remove remaining isolated areas. Corner points are added to the extracted road point cloud to maintain alignment with the original raw data.

The processed data is then projected onto the XY plane to generate a top-down projection image, which is further refined through binarization and Gaussian blur to enhance structural visibility. Skeletonization is applied to extract centerlines, which are converted into scatter points and smoothed using the Savitzky-Golay filter \cite{Savitzky_golay} to form precise road skeletons. These 2D skeletons are re-projected onto the 3D point cloud, with calculated normals. Skeleton normals guide the region-growing algorithm to locate nearby road points. The proposed approach is tested on the Perth CBD point cloud dataset \cite{9647060}.




\begin{figure}
    \vspace{-20pt}
    \centering
    \includegraphics[width=1\linewidth]{Frank_DICTA_Imgs/original.png}
    \caption{Example of an input MLS point cloud, containing road surfaces, vertical building facades and vegetation.}
    \label{fig-original}
    \vspace{-3mm}
\end{figure}


\begin{figure}
    \vspace{-20pt}
    \centering
    \includegraphics[width=1\linewidth]{Frank_DICTA_Imgs/skeleton_sample.png}
    \caption{Skeletonisation result along with the original point cloud as the background for reference. Red dots indicates potential intersections}
    \label{skeleton_sample}
    \vspace{-3mm}
\end{figure}


% added back later
% The approach merges point cloud and image processing to delineate road points and centrelines from dense urban 3D point clouds. Initial noise is reduced via statistical outlier removal and density-based clustering, ensuring the main road structure is preserved. Ground points are filtered using a grid-based segmentation method, which adapts well to varying road and terrain types by analysing the orientation of plane normals. The road extraction phase projects the point cloud onto the XY plane, employing Gaussian filtering and skeletonisation to extract and refine the road topology. Then, the skeleton is back projected to the 3D point cloud with calcualted normals. Adapted region-growing algorithm based on K-D Tree \cite{kdtree} is used to extract road points. The BEV perspective provides a new approach to this problem, showing promising results in diverse scenarios.

% The proposed approach in this project integrates point cloud processing and image processing techniques to effectively extract road points and centreline from dense 3D point cloud urban scenes. The method involves several steps, including noise removal, ground point filtering, skeleton extraction, and skeleton refinement, the creative BEV prospective approach could potentially enhances robustness and computational efficiency compared to traditional road extraction methods.



% In the 3D point cloud data preprocessing stage, statistical outlier removal based on distance and density-based clustering are employed to eliminate noise points, outliers, and isolated small regions, preserving the main road structure while removing most noise interference.



% A grid-based segmentation method is introduced in the ground point filtering stage. By dividing the point cloud into small grid regions, fitting planes to each region, and analysing the angle between the fitted plane normal and the Z-axis, the method adaptively determines and filters ground points. This approach better adapts to various road scenarios and terrain characteristics.



% The road point cloud extraction and centreline fitting stage projects the filtered road point cloud onto the XY plane to create a projected 2D image from BEV prospective, applies Gaussian filtering for denoising, and extracts the road topology using a skeletonisation algorithm. The extracted skeleton points are then smoothed using the Savitzky-Golay filter to obtain a smooth road framework topology.



% The entire algorithm workflow flexibly combines 3D point cloud processing and 2D image processing approaches, adapting to different types and qualities of point cloud data. By adjusting parameters at different stages, the algorithm achieves promising results at this stage in various scenarios, demonstrating the potential robustness and computational efficiency.





\subsection{Preprocessing}

The first step in the proposed pipeline is to preprocess the input 3D point cloud data. The input data contains road surfaces, along with trees, buildings and other structures. Fig.~\ref{fig-original} provides an example of a MLS point cloud input file, which includes vertical building facades, road surfaces, vegetation, and low bushes. The primary goal of the preprocessing stage is to remove outliers and isolated areas, as they can negatively impact computational efficiency and lead to misleading estimations of the input data.








To address these issues, a two-step approach is employed. First, a distance-based statistical filtering method is used to remove noise points and outliers. This method relies on the distribution of distances between neighbouring points to identify and remove outliers. Mathematically, for each point $p_i$ in the point cloud, the mean distance $\mu_i$ to its k-nearest neighbours is calculated. Then, the overall mean $\mu$ and standard deviation $\sigma$ of all $\mu_i$ are computed. Points with $\mu_i$ outside the interval $[\mu - \alpha \sigma, \mu + \alpha \sigma]$, where $\alpha$ is a predefined parameter set at 2, are considered outliers and removed.


DBSCAN is applied to remove isolated small regions. DBSCAN groups together points that are closely packed, marking points in low-density areas as outliers \cite{10.5555/3001460.3001507}. It requires two parameters: $\epsilon$, the maximum distance between two points for them to be considered neighbours, and $minPts$, the minimum number of points required to form a dense region. Points that do not belong to any dense region are classified as isolated clusters and removed. We empirically set $\epsilon$ and $minPts$ to 2 and 10, respectively, to achieve a balanced outcome.


By applying these two preprocessing steps, the main road structure with attached areas is effectively maintained while noise and interference from outliers and isolated areas are significantly reduced as shown in step 2 of Fig.~\ref{pipeline}.



\subsection{Ground point filtering}

Roads can be non-planar in real data. Hence, our algorithm does not make any assumption of planar roads in the input data and can handle point clouds containing roads with varying slopes. %, resulting in a non-planar ground point cloud in the XY plane. 
To cater for elevation changes, we employ a grid-based segmentation, followed by processing of the small grid blocks.
% To accommodate gradual slope changes as the scanning device moves along the path, the algorithm employs a grid-based point cloud segmentation approach.
This is depicted in step 3 of Fig.~\ref{pipeline}, where the entire point cloud is divided into small square chunks based on the X and Y dimensions, while preserving the original Z-axis coordinates of the points within each chunk.

The grid-based segmentation is performed by calculating the boundaries of each chunk using the following equations:

\begin{equation}
x_{min} = min(x_i), \quad x_{max} = max(x_i)
\end{equation}
\begin{equation}
y_{min} = min(y_i), \quad y_{max} = max(y_i)
\end{equation}
where $x_i$ and $y_i$ represent the X and Y coordinates of the points within the chunk, respectively. Each chunk is then processed individually for plane fitting using the RANSAC algorithm. RANSAC estimates the plane parameters by iteratively selecting random subsets of points and fitting a plane to them \cite{10.1145/358669.358692}. The plane with the highest number of inliers points within a specified distance threshold is considered the best-fitting plane. We empirically chose the threshold to be 30.




% The pseudo-code for the RANSAC plane fitting is as follows:

% \begin{algorithm}
% \caption{RANSAC Plane Fitting}
% \begin{algorithmic}[1]
%     \For{$i = 1$ to $max\_iterations$}
%         \State Randomly select three points from the chunk
%         \State Fit a plane to the selected points
%         \State Calculate the number of inliers for the fitted plane
%         \If{$num\_inliers > best\_num\_inliers$}
%             \State $best\_plane \leftarrow current\_plane$
%             \State $best\_num\_inliers \leftarrow num\_inliers$
%         \EndIf
%     \EndFor
%     \State \Return $best\_plane$
% \end{algorithmic}
% \end{algorithm}



% After fitting a plane to each chunk, the algorithm determines whether the chunk represents a ground surface based on the angle between the fitted plane's normal vector and the Z-axis.

After estimating a flat surface for each chunk, the algorithm determines if the surface is part of the ground by comparing its tilt angle to the vertical direction. Chunks with angles exceeding 60\degree are classified as vertical structures (i.e., non-road points) and are discarded immediately. For chunks with smaller angles, the algorithm dynamically sets a filtering threshold based on the Z-value percentiles of the points within the chunk. Based on our experiments, we encountered three main types of grid block scenarios: the first type is when the whole block contains only road surface forming a perfect plane, the second type is a mixed situation with a road surface and vertical building structures, and the last one is a block containing unordered points. These three different situations are shown in step 4 of Fig.~\ref{pipeline}. This adaptive thresholding approach enables the algorithm to handle different road scenarios and terrain characteristics effectively, as depicted in step 5 of Fig.~\ref{pipeline}.



% The ground point filtering process is implemented using a dedicated function that takes the point cloud and the grid size as inputs. The function applies the grid-based segmentation, performs plane fitting for each chunk, and filters the ground points based on the angle and adaptive thresholding criteria.
% 


% The proposed ground point filtering method offers several advantages. By combining grid-based segmentation with RANSAC plane fitting, the algorithm can adapt to various road scenarios and terrain features. The dynamic thresholding based on Z-value percentiles ensures robustness in handling different types of input data. Additionally, the grid-based approach can be developed for parallel processing of chunks, potentially improving computational efficiency.



% In summary, the ground point filtering step in the methodology employs a grid-based segmentation approach, RANSAC plane fitting, and adaptive thresholding to extract ground points from the preprocessed MLS point cloud. This method demonstrates adaptability to diverse road scenarios and terrain characteristics, enhancing the overall robustness and efficiency of the road extraction algorithm.

\subsection{Road points extraction}
The extraction of road points from the processed point cloud is performed by analysing the ground points from the top-down perspective. As shown in Fig.~\ref{Perth_data_raw}, the top-down view provides a clear overview of the road structure and facilitates the extraction of the road skeleton. By projecting the filtered point cloud onto the XY plane, the top-down perspective helps mitigate the skewness of the data, which is often caused by the urban canyon effect \cite{hough-1}. Drift and accumulated error due to the lack of GPS signal reception in dense urban areas contribute to the deformation of the final result \cite{9647060}. A sample of this type of data is shown in Fig.~\ref{loop_demo2}.





\begin{figure}
    \vspace{-3mm}
    
    \centering
    \includegraphics[width=1\linewidth]{Frank_DICTA_Imgs/Perth_data_raw.png}
    \caption{Preview of the Perth CBD point cloud data \cite{9647060}}
    \label{Perth_data_raw}
    \vspace{-3mm}
    
\end{figure}

However, the projected image may contain significant noise that needs to be removed. To tackle this issue, Gaussian filtering is employed for denoising. The Gaussian filter performs smoothing by convolving the data with a Gaussian kernel, defined as:
\begin{equation}
    G(x, y) = \frac{1}{2\pi\sigma^2} e^{-\frac{x^2 + y^2}{2\sigma^2}}
\end{equation}
where $\sigma$ is the standard deviation of the Gaussian distribution. The choice of $\sigma$ determines the level of smoothing applied to the image. In this study, the $\sigma$ value is preset at 5 to achieve a balance between noise reduction and preserving essential road structure details.





\begin{figure*}
    \vspace{-25pt}
    \begin{subfigure}[b]{0.2\textwidth}
        \centering
        \includegraphics[width=\textwidth]{Frank_DICTA_Imgs/loop3_demo.jpg}
        \caption{Selected file 10 is a straight road with driveways}
        \label{loop_demo1}
    \end{subfigure}
    \hfill
    \begin{subfigure}[b]{0.2\textwidth} 
        \centering
        \includegraphics[width=\textwidth]{Frank_DICTA_Imgs/loop9_demo.png}
        \caption{Selected file 9 contains accumulated errors}
        \label{loop_demo2}
    \end{subfigure}
    \hfill
    \begin{subfigure}[b]{0.2\textwidth}
        \centering
        \includegraphics[width=\textwidth]{Frank_DICTA_Imgs/loop11_demo.png}
        \caption{Selected file 11 is a ring road}
        \label{loop_demo3}
    \end{subfigure}
    \hfill
    \begin{subfigure}[b]{0.2\textwidth}
        \centering
        \includegraphics[width=\textwidth]{Frank_DICTA_Imgs/loop13_demo.png}
        \caption{Selected file 13 has intersection}
        \label{loop_demo4}
    \end{subfigure}

    \caption{Previews for selected data with different road shapes and curvatures}
    \label{loop_demo}
    \vspace{-1pt}
\end{figure*}


After denoising, the skeleton of the road structure is extracted from the binary image. The skeletonisation process is performed using OpenCV based iterative thinning approach \cite{opencvpython2012skeletonization}. The algorithm iteratively erodes the boundary pixels of the road structure while preserving its connectivity. The result is shown in Fig.~\ref{skeleton_sample} with the original point cloud file as the background for reference.



The skeleton is back-projected onto the 3D point cloud with moving Z-values, allowing it to align perfectly with the original road section, even in cases of high curvature. Normals are then calculated based on the skeleton, now converted to point cloud format. A region-growing algorithm using the K-D Tree method is subsequently applied to identify road points that are perpendicular to the skeleton normals and share similar Z-values. These extracted road points are then skeletonised again to generate the road centerline, as shown in subfigure (d) of Figs.~\ref{loop_process_9} - \ref{loop_process_13}. This approach extracts the road points and road centreline from the top-down perspective, corrects data skewness and generates a smooth road centreline. 

% The pseudo-code for the Savitzky-Golay filter can be represented in Algorithm 2.
% \begin{algorithm}
%     \caption{Savitzky-Golay Filter}
%     \begin{algorithmic}
%         \State \textbf{Input:} skeleton points $(x_i, y_i)$, window size $m$, polynomial degree $d$
%         \State \textbf{Output:} smoothed centreline points $(x'_i, y'_i)$
%         \For{each point $(x_i, y_i)$}
%             \State Fit a polynomial of degree $d$ to the points in the window of size $m$ centred at $(x_i, y_i)$
%             \State Evaluate the polynomial at $(x_i, y_i)$ to obtain the smoothed point $(x'_i, y'_i)$
%         \EndFor
%         \Return smoothed centreline points $(x'_i, y'_i)$
%     \end{algorithmic}
% \end{algorithm}




\section {Experiment and results} \label{Experiment}
The proposed algorithm is tested on the Perth CBD point cloud dataset \cite{9647060}. The dataset covers approximately 4 square kilometres of the Perth city centre, containing over 64 million 3D points, making it a large-scale, high-precision urban point cloud dataset. In the complete 3D map shown in Fig.~ \ref{Perth_data_raw}, roads are annotated in pink, while other objects such as buildings, traffic lights, trees, and lamp posts are annotated in green, providing rich semantic information. 
% Testing on this dataset could provide valuable references for the algorithm's performance in applications like urban traffic planning \cite{Guan2015Automated}.

Although the Perth CBD dataset provides registered and large-scale point clouds in a single file, we used smaller registered files to conduct our experiments. These are individual point cloud files containing reduced number of points, covering different areas of the Perth CBD. The dataset has different smaller size files with varying road structures, and demonstrated effectiveness of our approach as shown in subfigures (b) and (d) of the Figs.~\ref{loop_process_9} - ~\ref{loop_process_13}. 
% Moreover, having fewer points in separate files increases computation efficiency, which positively impacts our further improvement of the algorithm.



% \begin{algorithm}
% \caption{Calculation of IoU}
% \begin{algorithmic}[1]

% \State \textbf{Input:} cloud1, cloud2, threshold (default = 1)
% \State \textbf{Output:} IoU value

% \Procedure{CalculateIoU}{$cloud1, cloud2, threshold$}

% \State vox1 $\gets$ Voxel down-sample $cloud1$ 
% \State vox2 $\gets$ Voxel down-sample $cloud2$

% \State Convert vox1 and vox2 to NumPy arrays
% \State points1 $\gets$ Array of points from vox1
% \State points2 $\gets$ Array of points from vox2

% \State Create KD-Trees for vox1 and vox2
% \State tree1 $\gets$ KDTree based on vox1
% \State tree2 $\gets$ KDTree based on vox2

% \State Initialise an empty set for intersection

% \For{each point in points1}
%     \State Search for points within $threshold$ in tree2
%     \If{points found}
%         \State Add point to intersection set
%     \EndIf
% \EndFor

% \For{each point in points2}
%     \State Search for points within $threshold$ in tree1
%     \If{points found}
%         \State Add point to intersection set
%     \EndIf
% \EndFor

% \State points1\_set $\gets$ Set of points from points1
% \State points2\_set $\gets$ Set of points from points2
% \State union $\gets$ Union of points1\_set and points2\_set

% \State Calculate IoU
% \State IoU $\gets$ Size of intersection / Size of union

% \State Visualise the intersection and union clouds

% \State \textbf{return} IoU

% \EndProcedure
% \end{algorithmic}
% \label{al_iou}
% \end{algorithm}



% \begin{figure*}
%     \centering
%     \includegraphics[width=1\linewidth]{Frank_DICTA_Imgs/2d_pipeline.jpg}
%     \caption{Pipeline structure for obtaining ground truth data from Google Maps}
%     \label{mappipeline}
% \end{figure*}


We used data from Google Maps as the ground truth source. The original Google API provides a maximum resolution of 640x640 pixels for map tiles, which is insufficient for our evaluation. To address this, we developed an automated method to obtain satellite images and 2D road structures from Google Maps for any given coordinate boundary at any zoom level by stitching map tiles together. Figure \ref{mappipeline} illustrates the process for generating the stitched satellite image and its extracted road network layer from the corresponding map. First, a batch of individual map tiles is identified based on the given coordinates and zoom level. Then, a complete map is created by stitching these tiles together using the tile size and GPS coordinate boundaries. Each tile includes a watermark located at the bottom. To avoid interference, labels on the bottom of the tiles are removed by adjusting the coordinates and shifting subsequent rows of tiles upward by 22 pixels. Only labels that interfere with the road structure extraction process are removed; labels on the last row of tiles are always retained. The map is then cropped according to the pixel-to-coordinate ratio to achieve the desired image for the specified coordinates. Finally, road network structures are extracted using color filtering and skeletonization processes from the OpenCV library, producing accurate ground truth road structure masks.

\begin{figure}[H]
    \includegraphics[width=1\linewidth]{Frank_DICTA_Imgs/2d_pipeline_small.jpg}
    \caption{\small Workflow of obtaining ground truth from GoogleMaps (\textbf{1}) Identified batch of single map tiles based on the given coordinates and the zoom level (\textbf{2}) Original stitched map created by calculating coordinates for individual tiles based on the tile size  and the ratio of given GPS coordinates boundaries (\textbf{3}) Remove labels from map tiles, only labels affecting the road structures are removed. (\textbf{4}) Crop based on the pixel/coordinate ratio This is the precise image we want for the  given coordinates (same process for the map) (\textbf{5}) Extraction of road network structures by  implementing colour filtering and skeletonisation processing from openCV library (\textbf{6}) The ground truth is created with precise coordinates}
    \label{mappipeline}
    \vspace{-3mm}
\end{figure}

% We created our own ground truth masks based on the aligned satellite images with those files as shown in subfigure (a) of Figs.~\ref{loop_process_9} - \ref{loop_process_13}.
The mask is used to calculate Intersection over Union (IoU) values and to facilitate the visual comparison. The calculation of the IoU value is mainly based on the K-D Tree approach proposed by Skrodzki et. al. \cite{kdtree} to find the nearby points based on the downsampled result. 
% This is because the original point cloud is unordered, and point cloud data from the ground truth is evenly distributed, therefore, the result is unable to be compared directly. 
The IoU calculation algorithm is detailed in Algorithm \ref{al_iou}.

% In the absence of verified ground truth data from the original pre-registered files, an initiative was taken to construct bespoke ground truth masks derived from aligned satellite images as depicted in subfigure a of Figures \ref{loop_process_9} to \ref{loop_process_13}. These masks are pivotal for the computation of Intersection over Union (IoU) metrics, which measure the spatial correspondence between datasets. The IoU calculation is primarily based on the K-D Tree methodology, which facilitates the identification of proximate points within downsampled data. This process, as detailed in Algorithm \ref{al_iou}, involves voxel downsampling of point clouds, conversion to NumPy arrays, and the subsequent creation of KD-Trees for efficient spatial indexing. Intersection sets are generated by querying these trees to find points within a specified threshold, ensuring precise measurement of overlap. The union of point sets from both datasets then allows for the accurate derivation of the IoU ratio, which is essential for quantitative analysis and visual comparison of data congruence.

% In the absence of ground truth data, we employ a manual sampling evaluation approach to assess the performance of the algorithm. By comparing the point cloud data before and after processing, we observe that the reduction in the number of points can, to a certain extent, reflect the effectiveness of the road extraction. When the road surface is well-preserved without visible holes, a greater reduction in the number of points indicates that non-road regions have been more effectively removed, suggesting better algorithm performance



% Furthermore, we evaluate the algorithm's performance by observing its result during the extraction of road centrelines and skeletons. Through manual inspection of the extracted road framework, we can identify any roads that should have been extracted but were missed by the algorithm. This provides another qualitative perspective for assessing the algorithm's performance.




% \begin{table*}
%     
%     \centering
%     \caption{Comparison of previous and existing approaches}
%     \label{tab:comparison_data}
%     \setlength{\tabcolsep}{4pt} 
%     \begin{tabular}{@{}lrrrrrrrr@{}}
%         \toprule
%             File Name & Original Points & Previous Points & Current Points & Point Reduction (\%) & Previous Time (s) & Current Time (s) & Time Improvement (\%) \\ 
%         \midrule
%             Loop1.ply & 421186 & 161842 & 131080 & 19.00 & 10.37 & 12.90 & -24.40 \\
%             Loop2.ply & 209266 & 136659 & 66450 & 51.37 & 5.48 & 4.63 & 15.51 \\
%             Loop3.ply & 143425 & 117403 & 45147 & 61.52 & 4.53 & 2.54 & 43.93 \\
%             Loop4.ply & 359768 & 264997 & 116201 & 56.16 & 14.01 & 10.23 & 27.05 \\
%             Loop6.ply & 184857 & 5716 & 48907 & -755.81 & 3.01 & 2.44 & 18.94 \\
%             Loop7.ply & 276294 & 24165 & 63119 & -161.08 & 4.98 & 4.79 & 3.82 \\
%             Loop8.ply & 47183 & 36864 & 14344 & 61.09 & 0.77 & 0.51 & 33.77 \\
%             Loop9.ply & 392264 & 284358 & 113514 & 60.08 & 13.32 & 15.36 & -15.32 \\
%             Loop10.ply & 143711 & 97651 & 40815 & 71.60 & 3.61 & 2.16 & 40.17 \\
%             Loop11.ply & 130781 & 1819 & 40454 & -2124.02 & 1.86 & 1.48 & 20.43 \\
%             Loop12.ply & 99082 & 1120 & 30645 & -2634.38 & 1.26 & 0.99 & 21.43 \\
%             Loop13.ply & 121279 & 18888 & 37786 & -100.06 & 1.83 & 1.60 & 12.57 \\
%             Loop14.ply & 206827 & 165327 & 69082 & 58.21 & 6.87 & 4.44 & 35.37 \\
%             Loop15.ply & 204134 & 151242 & 59615 & 60.57 & 6.21 & 4.21 & 32.21 \\
%             Loop17.ply & 131775 & 105009 & 41656 & 60.33 & 3.68 & 2.14 & 41.85 \\
%         \midrule
%             Ave. Improvement & - & - & - & 2.33 & - & - & 13.42 \\
%         \bottomrule
        
%     \end{tabular}
%     
% \end{table*}

% As we are using intermediate results from the processing pipeline rather than the final merged complete point cloud data, it is not currently possible to conduct precise quantitative evaluations using pre-annotated ground truth data. However, the manual sampling evaluation and qualitative observations already provide a comprehensive assessment of the algorithm's performance, offering important references for algorithm improvement at this stage.

\begin{algorithm}
\caption{Calculation of IoU}
\begin{algorithmic}[1]

\State \textbf{Input:} cloud1, cloud2, threshold
\State \textbf{Output:} IoU value

\Procedure{CalculateIoU}{$cloud1, cloud2, threshold$}

\State Voxel down-sample $cloud1$ and $cloud2$
\State Convert down-sampled clouds to point arrays

\State Build KD-Trees for both point arrays

\State Find intersection by searching nearby points in KD-Trees

\State Calculate union by merging two point sets

\State IoU $\gets$ Size of intersection / Size of union

\State \textbf{return} IoU

\EndProcedure
\end{algorithmic}
\label{al_iou}
\end{algorithm}

For demonstration purpose, we selected four representative scenes from 17 pre-merged point cloud files: road intersections, looped road, straight road, and data with large cumulative errors. Fig.~\ref{loop_demo} shows previews of these four scenes, illustrating their distinct road shapes and characteristics. 
% In the experiment, various attempts were explored to process point clouds of roads. 
By adopting the skeletonisation function from scikit-image library \cite{sk}, key nodes within the road network, such as intersections, were correctly identified. This was achieved using a 3x3 convolution kernel to detect cross-points in the framework image generated by projection, facilitating an understanding of road layouts and revealing significant branching points within the network. 


% Previous attempts encountered issues with the reduction in spatial dimensions during the downsampling of point clouds; this was addressed by introducing additional points to maintain dimensional stability, thereby enhancing the precision and integrity of data processing. Previously, the extracted skeleton was not subjected to post-processing, an enhancement incorporated in the later process. This improvement aids in refining the road skeleton by eliminating short branches and connecting isolated ones, thereby forming a more complete road structure. Such a refined skeleton supports the subsequent region-growing algorithm in reconstructing the road points. 

\begin{table*}
    
    \centering
    % \caption{Comparison of previous and existing approaches}
    \caption{Comparison of performance of post-skeleton process}
    \label{tab:comparison_data}
    \setlength{\tabcolsep}{4pt} 
    \begin{tabular}{@{}lrrrrrrr@{}}
        \toprule
            File Name & Original Points & Previous Points & Current Points & Point Reduction (\%) & Previous Time (s) & Current Time (s) & Time Improvement (\%) \\ 
        \midrule
            Loop9.ply & 392264 & 284358 & 113514 & 60.08 & 13.32 & 15.36 & -15.32 \\
            Loop10.ply & 143711 & 97651 & 40815 & 71.60 & 3.61 & 2.16 & 40.17 \\
            Loop11.ply & 206827 & 165327 & 69082 & 58.21 & 6.87 & 4.44 & 35.37 \\
            Loop13.ply & 204134 & 151242 & 59615 & 60.57 & 6.21 & 4.21 & 32.21 \\
        \midrule
            Ave. Improvement & - & - & - & 62.62 & - & - & 23.11 \\
        \bottomrule
        
    \end{tabular}
\end{table*}

During the experiments, we tested the algorithm's performance without the refinement of connecting endpoints in the generated skeletons. As the original generated skeleton graph contains disconnected branches, we calculated endpoint distances of each separated branch and connect points together based upon their Euclidean distances. Once the skeleton is processed, disconnected small branches were discarded.

% Continuous refinement of the proposed algorithm addressed performance generalisation issues on varying data characteristics experienced by previous methods. The current approach includes more refined corner detection and an improved filtering system based on a grid framework. Refined strategies could effectively handle slope changes on different terrains, as well as input data with accumulated errors. This provides an enhanced generalisation in data processing and improves efficiency. The optimised data handling process successfully reduced the number of points by at least 60\% and also achieved a reduction in processing time. Table \ref{tab:comparison_data} demonstrates a comparison of the differences between our algorithms. The average improvement in points removal is 22\%. This demonstrates the current approach has much better generalisation capabilities across all input files.


% Read the code and make it a
% Further refinements addressed generalisation issues related to varying data characteristics, which had impacted the performance of previous methods. The current version introduces a corner detection and an improved filtering system within a grid framework, designed to manage slope variations across different terrains and to handle input data with accumulated errors effectively.

These enhancements lead to a substantial reduction in the number of processed points which is at least 60\% less than the previous approach, and also decreased the processing time significantly by at least 23\%. The comparative data presented in Table \ref{tab:comparison_data} showing our approach's improvement in processing efficiency. Overall, these changes boost the generalisation capabilities of our approach across different types of input data.


% In our approach, we started by performing noise removal on the point clouds. In this step, we tried to remove outliers and isolated areas as they interfere with subsequent projection process. However, if the redundant data overlaps with road surface points on the Z axis direction, it theoretically does not cause significant impact, as the BEV projection angle and binarisation process mitigate its effects. Instead, we prioritise obtaining smooth contours, which aids in subsequent skeleton extraction. Through statistical analysis, we found that outlier removal and density-based clustering methods eliminate unwanted regions. 






We implemented a grid-based segmentation approach, combining RANSAC plane fitting with moving median filtering to extract ground point clouds. The ground points are extracted comprehensively, and the moving threshold algorithm effectively removes non-ground planes with large angles while preserving smooth and continuous road surface point clouds. Even in cases of severe deformation caused by cumulative errors, the filtered ground point cloud shown in subfigure (b) of Figs. \ref{loop_process_9} - \ref{loop_process_13} maintained good ground details. Compared to the original point cloud in Fig. \ref{loop_demo}, ground point filtering not only retains the road structure but also removes irrelevant points with reduced dimension size.


\begin{figure}
    \centering
    \includegraphics[width=1\linewidth]{Frank_DICTA_Imgs/file9.jpg}
    \caption{Sample process result for input file 9 (\textbf{a}) Ground truth with satellite image (\textbf{b}) Extracted road points (\textbf{c}) IoU result visualisation (\textbf{d}) Centreline fitting result. }
    \label{loop_process_9}
    \vspace{-5mm}
\end{figure}

\begin{figure}
    \centering
    \includegraphics[width=1\linewidth]{Frank_DICTA_Imgs/file10.jpg}
    \caption{Sample process result for input file 10 (\textbf{a}) Ground truth with satellite image (\textbf{b}) Extracted road points (\textbf{c}) IoU result visualisation (\textbf{d}) Centreline fitting result. }
    \label{loop_process_10}
    \vspace{-5mm}
\end{figure}


\begin{figure}
    \centering
    \includegraphics[width=1\linewidth]{Frank_DICTA_Imgs/file11.jpg}
    \caption{Sample process result for input file 11 (\textbf{a}) Ground truth with satellite image (\textbf{b}) Extracted road points (\textbf{c}) IoU result visualisation (\textbf{d}) Centreline fitting result. }
    \label{loop_process_11}
    \vspace{-5mm}
    
\end{figure}

\begin{figure}
    \centering
    \includegraphics[width=1\linewidth]{Frank_DICTA_Imgs/file13.jpg}
    \caption{Sample process result for input file 13 (\textbf{a}) Ground truth with satellite image (\textbf{b}) Extracted road points (\textbf{c}) IoU result visualisation (\textbf{d}) Centreline fitting result. }
    \label{loop_process_13}
    \vspace{-5mm}
\end{figure}

We then project the processed point cloud onto the XY plane for skeleton extraction and centreline fitting. The calculated nromals from the skeleton guides the region-growing algorithm to pick up road points. The result is shown in subfigure (b) of Figs.~\ref{loop_process_9} - \ref{loop_process_13}. To further smooth the skeleton, we apply the Savitzky-Golay filter for local polynomial fitting of the skeleton points, obtaining the final road centreline at this stage in subfigure (d) of Figs.~\ref{loop_process_9} - \ref{loop_process_13}. 




% Table \ref{table_result} presents IoU results for various road scenarios, comparing previous and current approaches. Loop files 9 and 10 display higher IoU scores at 82.5\% and 81.5\%, attributed to fewer open areas surrounding the roads in these scenarios. The improvement in IoU was facilitated by the post-processing of the extracted skeletal framework. By trimming and connecting the skeleton and calculating normals, the region-growing algorithm was more effectively able to identify neighboring points close to the skeleton with similar Z-values, resulting in clearer delineation of road points.

Table~\ref{table_result} presents IoU results for various road scenarios, comparing previous and current approaches. Loop files 9 and 10 exhibit higher IoU scores of 82.5\% and 81.5\%, respectively, attributed to fewer open areas surrounding the roads in these scenarios. This improvement in IoU was facilitated by post-processing the extracted skeletal framework. By trimming and connecting the skeleton and calculating normals, the region-growing algorithm more effectively identified neighboring points close to the skeleton with similar Z-values, resulting in a clearer delineation of road points.

% In loop file 11 as shown in Fig.~\ref{loop_process_11}c, areas painted in red depict erroneously recognised road surfaces due to two main reasons. One is the presence of extensive green spaces in the image, which share similar colours and textures with the road, making it challenging for the algorithm to differentiate between them. The other reason is that the modified one-way road is connected to the green spaces, further complicating the accurate delineation of boundaries between road and non-road areas. The current approach brought the IoU result from 54.8\% to 61.2\% with the largest improvement in these different scenarios, but it still presents challenges in distinguishing the boundary between open areas and the road. 
In loop file 11, as shown in Fig.~\ref{loop_process_11}c, areas painted in red depict erroneously recognized road surfaces due to two main reasons. First, the presence of extensive green spaces in the image shares similar colors and textures with the road, making it challenging for the algorithm to differentiate between them. Second, the modified one-way road is connected to these green spaces, further complicating the accurate delineation of boundaries between road and non-road areas. The current approach improved the IoU result from 54.8\% to 61.2\%, the largest improvement across these scenarios. However, it still presents challenges in distinguishing the boundary between open areas and the road.

Overall, the extracted road point clouds are generally wider than the ground truth masks. The primary cause of this phenomenon is likely the low resolution of the point clouds, which hinders the algorithm from successfully identifying the kerb, i.e., the road edge. In the absence of distinct boundary features, open areas adjacent to the road, such as car parks, pedestrians, and low-lying bushes, are tend to misclassification as road points.

\begin{table}[htbp]
\caption{Comparison of IoU Metrics for Selected Point Cloud Data}
\label{table_comparison}
\centering
\begin{tabular}{@{}lccc@{}}
\toprule
File Name & Previous IoU & Current IoU & Improvement (\%) \\ 
\midrule
Loop\_9.ply  & 0.766 & 0.825 & \textbf{7.70} \\
Loop\_10.ply & 0.748 & 0.815 & \textbf{8.96} \\
Loop\_11.ply & 0.548 & 0.612 & \textbf{11.68} \\
Loop\_13.ply & 0.653 & 0.698 & \textbf{6.89} \\
\bottomrule
\end{tabular}
\label{table_result}
\end{table}




The results shown that we evaluated each component of the proposed algorithm through experiments. The experimental results in Table~\ref{table_result} proved the effectiveness of improvement, this will be the foundation for further refinement of road point extraction result and more in-depth road analysis and modelling.

\section { conclusion and Way forward } \label{conclusion}

The proposed road extraction algorithm has demonstrated promising results in the experiments, indicating its capability to accurately extract road centrelines and relevant points from extensive urban point cloud datasets using a combined 3D-2D pipeline and the top-down strategy. Enhancements, such as post-skeleton processing and dimension management, have improved the approach, better preserving road points near the centrelines. We utilise normals to determine road orientation and employ vectors orthogonal to these normals to enhance the region-growing algorithm in our approach. The IoU metric for the latest approach shows an average improvement of 8.8\% using four different road scenarios from the Perth CBD dataset. Moreover, the processing time has decreased by an average of 23\%. Our approach performs well to various road shapes and scenarios, demonstrating its versatility and effectiveness.

% Reduced the length

However, the algorithm still has some limitations that require further improvements and optimisations. The algorithm is currently sensitive to parameter settings, with the choice of grid size and RANSAC thresholds significantly impacting the results. The extracted road framework shown in 2D format still contains some outliers, affecting the accuracy of the results. 
% Secondly, the road point extraction process based on the skeleton normals does not perform well in removing flat areas in open environments, such as green spaces and car parks alongside streets. Additionally, the algorithm may encounter potential issues when extracting flyovers and overpasses due to the limitations of the top-down perspective, as occluded parts cannot be effectively processed using 2D images. 


Future research directions include separating open areas like car parks from extracted road points, optimising RANSAC parameters to adapt to different road scenarios, refining region-growing algorithm to detect street directions and pedestrian pathway boundaries for better results. 
% Exploring more advanced plane fitting algorithms to enhance the algorithm's robustness in complex scenes, and improving the skeleton extraction and centreline smoothing methods to remove outliers and use straight lines to fit the road centrelines. 
Despite limitations, the algorithm holds promise for applications in city mapping and traffic planning.
% with plans to enhance its functionality and evaluation methods.


\section*{acknowledgments}Professor Ajmal Mian is the recipient of an Australian Research Council Future Fellowship Award (project number FT210100268) funded by the Australian Government. 


\bibliographystyle{IEEEtran}
\bibliography{IEEEabrv,frank_dicta}

\end{document}
