\section{Conclusions}
\label{sec:conclusions}

{\bf Summary.} We have introduced the problem of predictive red teaming: given access to observations from nominal scenarios, discovering vulnerabilities of a policy with respect to unseen changes in environmental factors and predicting the resulting performance degradation. Our approach to predictive red teaming --- Robotics Auto Red Teaming (\redit) --- modifies nominal observations via generative image editing to reflect changes in environmental factors of interest, and then uses a policy embedding-based anomaly detector to predict performance degradation. Experiments across 500+ trials for visuomotor diffusion policies demonstrate \redit's ability to (i) identify environmental factors that significantly impact performance, (ii) predict the relative and absolute impact of factors, and (iii) enable policy improvement via targeted data collection.   

\subsection{Limitations and Future Work}
\label{sec:future work}

We discuss limitations of our approach and promising future directions that may address them. 

{\bf Edit-to-real gap.} While state-of-the-art image editing tools are capable of producing realistic edits (especially with careful prompting), there are still gaps in realism for certain environmental factors. For example, edits that reflect lighting changes (Fig.~\ref{fig:anchor}) do not modify the shadows of objects as real lighting changes do. We expect that our method will benefit from the significant investments in improving image editing models for commercial applications. 
% References
% https://github.com/EricLee0224/awesome-nerf-editing
Beyond single-view realism, a more challenging limitation is ensuring \emph{multi-view} consistency. As seen in Fig.~\ref{fig:distractor edit}, edited observations from the overhead and wrist cameras do not represent a consistent geometry for the new object. One exciting possibility is to utilize recent \emph{3D scene editing} tools based on Gaussian Splatting~\cite{chen2024proedit, bao20243d} that allow for edits with multi-view consistency. Scene editing may also allow us to go beyond RGB observations and edit depth channels. 

{\bf Anomaly-to-failure gap.} Our approach utilizes the anomaly rate as a predictor for performance degradation. However, as seen in Sec.~\ref{sec:anomaly-to-real}, these predictions are not perfectly accurate. One avenue for future work is to perform edits on observations from multiple time-steps within each episode, and to compute anomaly rates based on these sequences (rather than only utilizing the first time-step from episodes, as we currently do). We are also interested in exploring other methods from the vast literature on anomaly detection to identify techniques that may serve as better predictors of performance degradation (see, e.g., \cite{xuuncertainty} for a recent empirical study).

{\bf Hidden environmental factors.} An important limitation of \redit~is that it requires changes in environmental factors to be reflected in visual observations of the robot. As such, \redit~will not identify vulnerabilities with changes that are completely hidden (e.g., changing the mass of objects without changing their visual appearance). In such cases, predictive red teaming via simulation is a promising avenue, but requires bridging the sim-to-real gap, which is typically very significant for RGB observations and may be even more pronounced when simulating unseen off-nominal scenarios. 

{\bf Multi-round predictive red teaming.} \redit~currently chooses a single set $F$ of environmental factors at the beginning of predictive red teaming. A more sophisticated approach could \emph{iteratively} explore the space of environmental factors: choose an initial set $F$, make predictions for these, and expand the set iteratively to include factors that are similar to ones that were predicted to yield poor performance. % A particularly exciting direction is to guide this exploration by exploiting the semantic reasoning capabilities of foundation models. 

% {\bf Language-conditioned policies.} We have focused on predictive red teaming for visuomotor policies in this work, but are also excited to develop approaches that perform predictive red teaming for language-conditioned visuomotor policies. 

\vspace{7pt}

As we seek to deploy robots in challenging real-world applications, it is essential that we develop scalable methods for predicting the limits of their performance. We hope that formalizing the problem of predictive red teaming and providing a baseline in the form of \redit~spurs further research along this underexplored direction. 



% Limitations and future work.
% \begin{itemize}
%     \item Multi-view consistency and depth
%     \item Edit-to-real gap: will improve with time
%     \item Anomaly-to-failure gap; can rely on this analysis for relative vulnerabilities 
%     \item Cannot do anything about changes in physical properties that are not reflected visually
%     \item Multi-round red teaming (VLM decides how to change the distribution)
%     \item Language-conditioned policies (can we figure out what kinds of instructions will make the robot fail, similar to Pulkitâ€™s work)
%     \item RL policies; nothing should really change
% \end{itemize}