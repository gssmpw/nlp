\section{Conclusion}
In this work, we introduce a framework for synthesizing realistic human-object interactions that are both physically grounded and generalizable. Unlike previous methods, our approach leverages a rich repository of imperfect MoCap data to facilitate the learning of various interaction skills across a wide variety of objects. To address inaccuracies in the MoCap data, we propose contact-guided rewards and optimize trajectory collection, enabling teacher policies to recover missing physical details in the original data.
These teacher policies are used to train student policies within a distillation framework that combines policy distillation and reference distillation, thus enabling efficient skill scaling. Our approach shows zero-shot generalizability, which effectively bridges the gap between imitation and generative capabilities by integrating with kinematic generation. We believe that this framework can be adapted for whole-body loco-manipulation for real-world robots, enabling them to handle objects with human-like dexterity and nuance.