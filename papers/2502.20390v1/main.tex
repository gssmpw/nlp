\documentclass[10pt,twocolumn,letterpaper]{article}
\usepackage[pagenumbers]{cvpr}
\input{preamble}
\definecolor{cvprblue}{rgb}{0.21,0.49,0.74}
\usepackage[pagebackref,breaklinks,colorlinks,allcolors=cvprblue]{hyperref}
\definecolor{bgcolor}{RGB}{140, 60, 120}
\newcommand{\icon}{\raisebox{-5pt}{\includegraphics[width=0.040\textwidth]{figures/logo.png}}}
\newcommand{\name}[0]{\textsc{InterMimic}\xspace}

\title{\icon \textcolor{bgcolor}{\name}: Towards Universal Whole-Body Control for Physics-Based Human-Object Interactions}

\author{Sirui Xu$^{1}$ \quad Hung Yu Ling$^{2}$ \quad
Yu-Xiong Wang$^{1\dag}$ \quad
Liang-Yan Gui$^{1\dag}$\\
$^{1}$ University of Illinois Urbana-Champaign \quad $^{2}$ Electronic Arts\\
$^{\dag}$ Equal Advising\\
\small\url{https://sirui-xu.github.io/InterMimic}}
\begin{document}
\maketitle
\begin{strip}\centering
\vspace{-3.2em}
\includegraphics[width=\textwidth]{figures/teaser_new.pdf}
\captionof{figure}{InterMimic enables physically simulated humans to perform interactions with dynamic and diverse objects. It supports highly-dynamic, multi-object interactions and scalable skill learning (\textbf{Top}), making it adaptable for versatile downstream applications (\textbf{Bottom}): it can translate whole-body loco-manipulation skills to a humanoid robot~\cite{unitreeg1,inspire}, perfect interaction MoCap data, and bridge kinematic generation, \eg, predicting future interactions from past (InterDiff~\cite{xu2023interdiff}) or generating interactions given text prompts (InterDreamer~\cite{xu2024interdreamer}).
\label{fig:teaser}}
\end{strip}
\etocdepthtag.toc{mtchapter}
\input{sec/abstract}    
\input{sec/introduction}
\input{sec/related_work}
\input{sec/method}
\input{sec/experiment}
\input{sec/conclusion}

{
    \small
    \bibliographystyle{ieeenat_fullname}
    \bibliography{main}
}

\input{sec/X_suppl}

\end{document}
