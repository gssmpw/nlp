\begin{table}[h!]
    \centering
    \setlength{\tabcolsep}{5pt}
    \small
    \begin{tabular}{llcc}
        \toprule
         {\#} & \textbf{Method (\mid @ 128)} & PSNR$_{\text{val}}$ $\uparrow$ & PSNR$_{\text{train}}$ $\uparrow$\\
        

    
    
    

    \midrule
        {1.} & Mid-trained (No Overfitting) & 19.23 & 19.70 \\
    \midrule
    
    {2.} & + Camera (w/ MLP)~\cite{zero1to3, MVDream} & 17.95\textsubscript{{\color{red}{-1.28}}} & 19.92\textsubscript{{\color{green}{+0.22}}} \\
    
    {3.} & + \plucker (w/ MLP)~\cite{RayConditioningGAN,LFNs,kant2024spad,he2024cameractrl}   & 18.89\textsubscript{{\color{red}{-0.34}}} & 20.74\textsubscript{{\color{green}{+1.04}}} \\
    
    {4.} & + ControlMLP  & 19.45\textsubscript{{\color{green}{+0.22}}} & 29.36\textsubscript{{\color{green}{+9.66}}} \\
    
    {5.} & + SIREN  & 20.13\textsubscript{{\color{green}{+0.90}}} & 30.19\textsubscript{{\color{green}{+10.49}}} \\
    
    {6.} & + \spatialanchor (Ours) \ & 22.60\textsubscript{{\color{green}{+3.37}}} & 30.49\textsubscript{{\color{green}{+10.79}}} \\
    \bottomrule
    
    
    \end{tabular}
    \caption{
        \textbf{Evaluating and Designing Spatial Controls (\cref{ssec:spatial_control}).} We overfit our multi-view model for $10$K iterations on 100 views of a single scene from our \upperbody dataset, and evaluate on 60 novel views of this scene by only varying the spatial controls (camera and \spatialanchor). We use this setup to test the modulation strength of different spatial controls. Subscript values \textcolor{green}{green}/\textcolor{red}{red} show deviations from Row 1. }
    \vspace{-10pt}
    \label{tab:3deval}
\end{table}

