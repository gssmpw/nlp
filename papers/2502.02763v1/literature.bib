@article{kalman_new_1960,
    Author = {Kalman, Rudolph Emil},
    Title = {A New Approach to Linear Filtering and Prediction Problems},
    Journal = {Transactions of the ASME--Journal of Basic Engineering},
    Volume = {82},
    Number = {Series D},
    Pages = {35--45},
    Year = {1960}
}
@article{ha_world_2018,
	title = {World {Models}},
	note = {10.5281/zenodo.1207631},
	abstract = {We explore building generative neural network models of popular reinforcement learning environments. Our world model can be trained quickly in an unsupervised manner to learn a compressed spatial and temporal representation of the environment. By using features extracted from the world model as inputs to an agent, we can train a very compact and simple policy that can solve the required task. We can even train our agent entirely inside of its own hallucinated dream generated by its world model, and transfer this policy back into the actual environment. An interactive version of this paper is available at https://worldmodels.github.io/},
	urldate = {2023-04-20},
	author = {Ha, David and Schmidhuber, Jürgen},
	month = mar,
	year = {2018},
	note = {arXiv:1803.10122 [cs, stat]},
	keywords = {Computer Science - Machine Learning, Statistics - Machine Learning},
	file = {arXiv Fulltext PDF:/Users/fredericbecker/Zotero/storage/9J9PUPNF/Ha und Schmidhuber - 2018 - World Models.pdf:application/pdf;arXiv.org Snapshot:/Users/fredericbecker/Zotero/storage/6J3CIZI4/1803.html:text/html},
}


@misc{hafner_dream_2020,
	title = {Dream to {Control}: {Learning} {Behaviors} by {Latent} {Imagination}},
	shorttitle = {Dream to {Control}},
	note = {10.48550/arXiv.1912.01603},
	abstract = {Learned world models summarize an agent's experience to facilitate learning complex behaviors. While learning world models from high-dimensional sensory inputs is becoming feasible through deep learning, there are many potential ways for deriving behaviors from them. We present Dreamer, a reinforcement learning agent that solves long-horizon tasks from images purely by latent imagination. We efficiently learn behaviors by propagating analytic gradients of learned state values back through trajectories imagined in the compact state space of a learned world model. On 20 challenging visual control tasks, Dreamer exceeds existing approaches in data-efficiency, computation time, and final performance.},
	urldate = {2023-04-14},
	publisher = {arXiv},
	author = {Hafner, Danijar and Lillicrap, Timothy and Ba, Jimmy and Norouzi, Mohammad},
	month = mar,
	year = {2020},
	note = {arXiv:1912.01603 [cs]}
}


@inproceedings{hafner_learning_2019,
	title = {Learning {Latent} {Dynamics} for {Planning} from {Pixels}},
	abstract = {Planning has been very successful for control tasks with known environment dynamics. To leverage planning in unknown environments, the agent needs to learn the dynamics from interactions with the world. However, learning dynamics models that are accurate enough for planning has been a long-standing challenge, especially in image-based domains. We propose the Deep Planning Network (PlaNet), a purely model-based agent that learns the environment dynamics from images and chooses actions through fast online planning in latent space. To achieve high performance, the dynamics model must accurately predict the rewards ahead for multiple time steps. We approach this using a latent dynamics model with both deterministic and stochastic transition components. Moreover, we propose a multi-step variational inference objective that we name latent overshooting. Using only pixel observations, our agent solves continuous control tasks with contact dynamics, partial observability, and sparse rewards, which exceed the difficulty of tasks that were previously solved by planning with learned models. PlaNet uses substantially fewer episodes and reaches final performance close to and sometimes higher than strong model-free algorithms.},
	language = {en},
	urldate = {2023-04-14},
	booktitle = {Proceedings of the 36th {International} {Conference} on {Machine} {Learning}},
	publisher = {PMLR},
	author = {Hafner, Danijar and Lillicrap, Timothy and Fischer, Ian and Villegas, Ruben and Ha, David and Lee, Honglak and Davidson, James},
	month = may,
	year = {2019},
	note = {ISSN: 2640-3498},
	pages = {2555--2565},
	file = {Full Text PDF:/Users/fredericbecker/Zotero/storage/IWCXMXMD/Hafner et al. - 2019 - Learning Latent Dynamics for Planning from Pixels.pdf:application/pdf;Supplementary PDF:/Users/fredericbecker/Zotero/storage/7TM5ISCW/Hafner et al. - 2019 - Learning Latent Dynamics for Planning from Pixels.pdf:application/pdf},
}

@article{lund2023chatgpt,
  title={ChatGPT and a new academic reality: Artificial Intelligence-written research papers and the ethics of the large language models in scholarly publishing},
  author={Lund, Brady D and Wang, Ting and Mannuru, Nishith Reddy and Nie, Bing and Shimray, Somipam and Wang, Ziang},
  journal={Journal of the Association for Information Science and Technology},
  volume={74},
  number={5},
  pages={570--581},
  year={2023},
  publisher={Wiley Online Library}
}

@Article{Greff:2020,
  author  = {Greff, Klaus and Van Steenkiste, Sjoerd and Schmidhuber, J{\"u}rgen},
  title   = {On the binding problem in artificial neural networks},
  journal = {arXiv preprint arXiv:2012.05208},
  year    = {2020},
}

@Article{Mattar:2022,
  author  = {Mattar, Marcelo G. and Lengyel, Máté},
  title   = {Planning in the brain},
  doi     = {10.1016/j.neuron.2021.12.018},
  issn    = {0896-6273},
  number  = {6},
  pages   = {914--934},
  url     = {https://www.sciencedirect.com/science/article/pii/S0896627321010357},
  volume  = {110},
  journal = {Neuron},
  year    = {2022},
}

@Article{Heald:2023,
  author   = {James B. Heald and Máté Lengyel and Daniel M. Wolpert},
  title    = {Contextual inference in learning and memory},
  doi      = {https://doi.org/10.1016/j.tics.2022.10.004},
  issn     = {1364-6613},
  number   = {1},
  pages    = {43-64},
  url      = {https://www.sciencedirect.com/science/article/pii/S1364661322002650},
  volume   = {27},
  abstract = {Context is widely regarded as a major determinant of learning and memory across numerous domains, including classical and instrumental conditioning, episodic memory, economic decision-making, and motor learning. However, studies across these domains remain disconnected due to the lack of a unifying framework formalizing the concept of context and its role in learning. Here, we develop a unified vernacular allowing direct comparisons between different domains of contextual learning. This leads to a Bayesian model positing that context is unobserved and needs to be inferred. Contextual inference then controls the creation, expression, and updating of memories. This theoretical approach reveals two distinct components that underlie adaptation, proper and apparent learning, respectively referring to the creation and updating of memories versus time-varying adjustments in their expression. We review a number of extensions of the basic Bayesian model that allow it to account for increasingly complex forms of contextual learning.},
  journal  = {Trends in Cognitive Sciences},
  keywords = {context-dependent learning, memory, learning, Bayesian inference},
  year     = {2023},
}

@Article{Schwoebel:2021,
  author   = {Sarah Schwöbel and Dimitrije Marković and Michael N. Smolka and Stefan J. Kiebel},
  title    = {Balancing control: A Bayesian interpretation of habitual and goal-directed behavior},
  doi      = {10.1016/j.jmp.2020.102472},
  issn     = {0022-2496},
  pages    = {102472},
  url      = {https://www.sciencedirect.com/science/article/pii/S0022249620301000},
  volume   = {100},
  journal  = {Journal of Mathematical Psychology},
  keywords = {Habitual control, Habit, Goal-directed control, Arbitration, Probabilistic inference, Context, Substance use disorder, Striatum},
  year     = {2021},
}


@Article{Butz:2021epc,
  author   = {Butz, Martin V. and Achimova, Asya and Bilkey, David and Knott, Alistair},
  title    = {Event‐predictive cognition: A root for conceptual human thought},
  doi      = {10.1111/tops.12522},
  pages    = {10-24},
  volume   = {13},
  journal  = {Topics in Cognitive Science},
  keywords = {Theory of event coding, Event segmentation theory, Action events, Anticipatory behavior, Natural language processing, Bayesian brain, Predictive coding, Cognitive ontogeny},
  year     = {2021},
}

@InProceedings{Gumbsch:2021c,
  author    = {Gumbsch, Christian and Butz, Martin V. and Martius, Georg},
  booktitle = {Advances in Neural Information Processing Systems},
  date      = {2021},
  title     = {Sparsely changing latent states for prediction and planning in partially observable domains},
  editor    = {M. Ranzato and A. Beygelzimer and Y. Dauphin and P.S. Liang and J. Wortman Vaughan},
  pages     = {17518--17531},
  publisher = {Curran Associates, Inc.},
  url       = {https://arxiv.org/abs/2110.15949},
  volume    = {34},
  year      = {2021},
}

@Article{Schrittwieser:2020,
  author       = {Schrittwieser, Julian and Antonoglou, Ioannis and Hubert, Thomas and Simonyan, Karen and Sifre, Laurent and Schmitt, Simon and Guez, Arthur and Lockhart, Edward and Hassabis, Demis and Graepel, Thore and Lillicrap, Timothy and Silver, David},
  date         = {2020},
  journaltitle = {Nature},
  title        = {Mastering Atari, Go, chess and shogi by planning with a learned model},
  doi          = {10.1038/s41586-020-03051-4},
  issn         = {1476-4687},
  number       = {7839},
  pages        = {604--609},
  volume       = {588},
  journal      = {Nature},
  refid        = {Schrittwieser2020},
  year         = {2020},
}


@InProceedings{Traub:2023,
  author    = {Manuel Traub and Sebastian Otte and Tobias Menge and Matthias Karlbauer and Jannik Thuemmel and Martin V. Butz},
  booktitle = {The Eleventh International Conference on Learning Representations},
  title     = {Learning what and where: Disentangling location and identity tracking without supervision},
  url       = {https://openreview.net/forum?id=NeDc-Ak-H_},
  year      = {2023},
}
@Misc{Yuan:2023,
  author        = {Jinyang Yuan and Tonglin Chen and Bin Li and Xiangyang Xue},
  title         = {Compositional Scene Representation Learning via Reconstruction: A Survey},
  eprint        = {2202.07135},
  archiveprefix = {arXiv},
  primaryclass  = {cs.LG},
  year          = {2023},
}
@InProceedings{Wu:2023slotformer,
  author    = {Ziyi Wu and Nikita Dvornik and Klaus Greff and Thomas Kipf and Animesh Garg},
  booktitle = {The Eleventh International Conference on Learning Representations},
  title     = {SlotFormer: Unsupervised Visual Dynamics Simulation with Object-Centric Models},
  url       = {https://openreview.net/forum?id=TFbwV6I0VLg},
  year      = {2023},
}

@InProceedings{Kipf:2022,
  author    = {Thomas Kipf and Gamaleldin Fathy Elsayed and Aravindh Mahendran and Austin Stone and Sara Sabour and Georg Heigold and Rico Jonschkowski and Alexey Dosovitskiy and Klaus Greff},
  booktitle = {International Conference on Learning Representations},
  title     = {Conditional Object-Centric Learning from Video},
  url       = {https://openreview.net/forum?id=aD7uesX1GF_},
  year      = {2022},
}
@InProceedings{Elsayed2022,
  author    = {Elsayed, Gamaleldin and Mahendran, Aravindh and van Steenkiste, Sjoerd and Greff, Klaus and Mozer, Michael C and Kipf, Thomas},
  booktitle = {Advances in Neural Information Processing Systems},
  year      = {2022},
  title     = {SAVi++: Towards End-to-End Object-Centric Learning from Real-World Videos},
  editor    = {S. Koyejo and S. Mohamed and A. Agarwal and D. Belgrave and K. Cho and A. Oh},
  pages     = {28940--28954},
  publisher = {Curran Associates, Inc.},
  volume    = {35},
}
@inproceedings{rombach2022high,
  title={High-resolution image synthesis with latent diffusion models},
  author={Rombach, Robin and Blattmann, Andreas and Lorenz, Dominik and Esser, Patrick and Ommer, Bj{\"o}rn},
  booktitle={Proceedings of the IEEE/CVF conference on computer vision and pattern recognition},
  pages={10684--10695},
  year={2022}
}
@inproceedings{goel2022s,
  title={It’s raw! audio generation with state-space models},
  author={Goel, Karan and Gu, Albert and Donahue, Chris and R{\'e}, Christopher},
  booktitle={International Conference on Machine Learning},
  pages={7616--7633},
  year={2022},
  organization={PMLR}
}
@inproceedings{liu2022convnet,
  title={A convnet for the 2020s},
  author={Liu, Zhuang and Mao, Hanzi and Wu, Chao-Yuan and Feichtenhofer, Christoph and Darrell, Trevor and Xie, Saining},
  booktitle={Proceedings of the IEEE/CVF conference on computer vision and pattern recognition},
  pages={11976--11986},
  year={2022}
}
@article{dosovitskiy2020image,
  title={An image is worth 16x16 words: Transformers for image recognition at scale},
  author={Dosovitskiy, Alexey and Beyer, Lucas and Kolesnikov, Alexander and Weissenborn, Dirk and Zhai, Xiaohua and Unterthiner, Thomas and Dehghani, Mostafa and Minderer, Matthias and Heigold, Georg and Gelly, Sylvain and others},
  journal={arXiv preprint arXiv:2010.11929},
  year={2020}
}
@article{locatello2020object,
  title={Object-centric learning with slot attention},
  author={Locatello, Francesco and Weissenborn, Dirk and Unterthiner, Thomas and Mahendran, Aravindh and Heigold, Georg and Uszkoreit, Jakob and Dosovitskiy, Alexey and Kipf, Thomas},
  journal={Advances in Neural Information Processing Systems},
  volume={33},
  pages={11525--11538},
  year={2020}
}
@article{vaswani2017attention,
  title={Attention is all you need},
  author={Vaswani, Ashish and Shazeer, Noam and Parmar, Niki and Uszkoreit, Jakob and Jones, Llion and Gomez, Aidan N and Kaiser, {\L}ukasz and Polosukhin, Illia},
  journal={Advances in neural information processing systems},
  volume={30},
  year={2017}
}
@article{sabour2017dynamic,
  title={Dynamic routing between capsules},
  author={Sabour, Sara and Frosst, Nicholas and Hinton, Geoffrey E},
  journal={Advances in neural information processing systems},
  volume={30},
  year={2017}
}
@inproceedings{bolya2019yolact,
  title={Yolact: Real-time instance segmentation},
  author={Bolya, Daniel and Zhou, Chong and Xiao, Fanyi and Lee, Yong Jae},
  booktitle={Proceedings of the IEEE/CVF international conference on computer vision},
  pages={9157--9166},
  year={2019}
}
@inproceedings{greff2022kubric,
  title={Kubric: A scalable dataset generator},
  author={Greff, Klaus and Belletti, Francois and Beyer, Lucas and Doersch, Carl and Du, Yilun and Duckworth, Daniel and Fleet, David J and Gnanapragasam, Dan and Golemo, Florian and Herrmann, Charles and others},
  booktitle={Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition},
  pages={3749--3761},
  year={2022}
}
@inproceedings{traub2024loci,
  title={Loci-segmented: improving scene segmentation learning},
  author={Traub, Manuel and Becker, Frederic and Sauter, Adrian and Otte, Sebsastian and Butz, Martin V},
  booktitle={International Conference on Artificial Neural Networks},
  pages={45--61},
  year={2024},
  organization={Springer}
}

@inproceedings{traub2024learning,
  title={Learning Object Permanence from Videos via Latent Imaginations},
  author={Traub, Manuel and Becker, Frederic and Otte, Sebsastian and Butz, Martin V},
  booktitle={International Conference on Artificial Neural Networks},
  pages={223--240},
  year={2024},
  organization={Springer}
}

@inproceedings{kirillov2023segment,
  title={Segment anything},
  author={Kirillov, Alexander and Mintun, Eric and Ravi, Nikhila and Mao, Hanzi and Rolland, Chloe and Gustafson, Laura and Xiao, Tete and Whitehead, Spencer and Berg, Alexander C and Lo, Wan-Yen and others},
  booktitle={Proceedings of the IEEE/CVF International Conference on Computer Vision},
  pages={4015--4026},
  year={2023}
}
@inproceedings{yu2023lape,
  title={LaPE: Layer-adaptive position embedding for vision transformers with independent layer normalization},
  author={Yu, Runyi and Wang, Zhennan and Wang, Yinhuai and Li, Kehan and Liu, Chang and Duan, Haoyi and Ji, Xiangyang and Chen, Jie},
  booktitle={Proceedings of the IEEE/CVF International Conference on Computer Vision},
  pages={5886--5896},
  year={2023}
}
@article{shaw2018self,
  title={Self-attention with relative position representations},
  author={Shaw, Peter and Uszkoreit, Jakob and Vaswani, Ashish},
  journal={arXiv preprint arXiv:1803.02155},
  year={2018}
}
@inproceedings{xiong2020layer,
  title={On layer normalization in the transformer architecture},
  author={Xiong, Ruibin and Yang, Yunchang and He, Di and Zheng, Kai and Zheng, Shuxin and Xing, Chen and Zhang, Huishuai and Lan, Yanyan and Wang, Liwei and Liu, Tieyan},
  booktitle={International Conference on Machine Learning},
  pages={10524--10533},
  year={2020},
  organization={PMLR}
}
@article{hendrycks2016gaussian,
  title={Gaussian error linear units (gelus)},
  author={Hendrycks, Dan and Gimpel, Kevin},
  journal={arXiv preprint arXiv:1606.08415},
  year={2016}
}
@article{ramachandran2017swish,
  title={Swish: a self-gated activation function},
  author={Ramachandran, Prajit and Zoph, Barret and Le, Quoc V},
  journal={arXiv preprint arXiv:1710.05941},
  volume={7},
  number={1},
  pages={5},
  year={2017},
  publisher={Technical report}
}
@article{elfwing2018sigmoid,
  title={Sigmoid-weighted linear units for neural network function approximation in reinforcement learning},
  author={Elfwing, Stefan and Uchibe, Eiji and Doya, Kenji},
  journal={Neural networks},
  volume={107},
  pages={3--11},
  year={2018},
  publisher={Elsevier}
}
@inproceedings{perez2018film,
  title={Film: Visual reasoning with a general conditioning layer},
  author={Perez, Ethan and Strub, Florian and De Vries, Harm and Dumoulin, Vincent and Courville, Aaron},
  booktitle={Proceedings of the AAAI conference on artificial intelligence},
  volume={32},
  number={1},
  year={2018}
}
@misc{zhao2023fast,
      title={Fast Segment Anything},
      author={Xu Zhao and Wenchao Ding and Yongqi An and Yinglong Du and Tao Yu and Min Li and Ming Tang and Jinqiao Wang},
      year={2023},
      eprint={2306.12156},
      archivePrefix={arXiv},
      primaryClass={cs.CV}
}
@InProceedings{deitke2023objaverse,
    author    = {Deitke, Matt and Schwenk, Dustin and Salvador, Jordi and Weihs, Luca and Michel, Oscar and VanderBilt, Eli and Schmidt, Ludwig and Ehsani, Kiana and Kembhavi, Aniruddha and Farhadi, Ali},
    title     = {Objaverse: A Universe of Annotated 3D Objects},
    booktitle = {Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)},
    month     = {June},
    year      = {2023},
    pages     = {13142-13153}
}
@misc{hdrihaven,
  title        = {HDRI Haven},
  year         = 2016,
  url          = {https://hdri-haven.com/},
  note         = {Accessed: 2024-11-20},
  key = {Zaal, Greg}
 
}
@InProceedings{roberts2021hypersim,
    author    = {Roberts, Mike and Ramapuram, Jason and Ranjan, Anurag and Kumar, Atulit and Bautista, Miguel Angel and Paczan, Nathan and Webb, Russ and Susskind, Joshua M.},
    title     = {Hypersim: A Photorealistic Synthetic Dataset for Holistic Indoor Scene Understanding},
    booktitle = {Proceedings of the IEEE/CVF International Conference on Computer Vision (ICCV)},
    month     = {October},
    year      = {2021},
    pages     = {10912-10922}
}
@article{liao2022kitti,
  title={Kitti-360: A novel dataset and benchmarks for urban scene understanding in 2d and 3d},
  author={Liao, Yiyi and Xie, Jun and Geiger, Andreas},
  journal={IEEE Transactions on Pattern Analysis and Machine Intelligence},
  volume={45},
  number={3},
  pages={3292--3310},
  year={2022},
  publisher={IEEE}
}
@article{kuznetsova2020open,
  title={The open images dataset v4: Unified image classification, object detection, and visual relationship detection at scale},
  author={Kuznetsova, Alina and Rom, Hassan and Alldrin, Neil and Uijlings, Jasper and Krasin, Ivan and Pont-Tuset, Jordi and Kamali, Shahab and Popov, Stefan and Malloci, Matteo and Kolesnikov, Alexander and others},
  journal={International journal of computer vision},
  volume={128},
  number={7},
  pages={1956--1981},
  year={2020},
  publisher={Springer}
}
@article{jaegle2021perceiver,
  title={Perceiver io: A general architecture for structured inputs \& outputs},
  author={Jaegle, Andrew and Borgeaud, Sebastian and Alayrac, Jean-Baptiste and Doersch, Carl and Ionescu, Catalin and Ding, David and Koppula, Skanda and Zoran, Daniel and Brock, Andrew and Shelhamer, Evan and others},
  journal={arXiv preprint arXiv:2107.14795},
  year={2021}
}
@article{zadaianchuk2024object,
  title={Object-centric learning for real-world videos by predicting temporal feature similarities},
  author={Zadaianchuk, Andrii and Seitzer, Maximilian and Martius, Georg},
  journal={Advances in Neural Information Processing Systems},
  volume={36},
  year={2024}
}
@article{singh2022simple,
  title={Simple unsupervised object-centric learning for complex and naturalistic videos},
  author={Singh, Gautam and Wu, Yi-Fu and Ahn, Sungjin},
  journal={Advances in Neural Information Processing Systems},
  volume={35},
  pages={18181--18196},
  year={2022}
}
@inproceedings{dai2017deformable,
  title={Deformable convolutional networks},
  author={Dai, Jifeng and Qi, Haozhi and Xiong, Yuwen and Li, Yi and Zhang, Guodong and Hu, Han and Wei, Yichen},
  booktitle={Proceedings of the IEEE international conference on computer vision},
  pages={764--773},
  year={2017}
}
@inproceedings{xiong2024efficient,
  title={Efficient deformable convnets: Rethinking dynamic and sparse operator for vision applications},
  author={Xiong, Yuwen and Li, Zhiqi and Chen, Yuntao and Wang, Feng and Zhu, Xizhou and Luo, Jiapeng and Wang, Wenhai and Lu, Tong and Li, Hongsheng and Qiao, Yu and others},
  booktitle={Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition},
  pages={5652--5661},
  year={2024}
}
@inproceedings{zhu2019deformable,
  title={Deformable convnets v2: More deformable, better results},
  author={Zhu, Xizhou and Hu, Han and Lin, Stephen and Dai, Jifeng},
  booktitle={Proceedings of the IEEE/CVF conference on computer vision and pattern recognition},
  pages={9308--9316},
  year={2019}
}
@inproceedings{chen2022focal,
  title={Focal sparse convolutional networks for 3d object detection},
  author={Chen, Yukang and Li, Yanwei and Zhang, Xiangyu and Sun, Jian and Jia, Jiaya},
  booktitle={Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition},
  pages={5428--5437},
  year={2022}
}
@article{lukanov2021biologically,
  title={Biologically inspired deep learning model for efficient foveal-peripheral vision},
  author={Lukanov, Hristofor and K{\"o}nig, Peter and Pipa, Gordon},
  journal={Frontiers in Computational Neuroscience},
  volume={15},
  pages={746204},
  year={2021},
  publisher={Frontiers Media SA}
}
@article{kaplanyan2019deepfovea,
  title={DeepFovea: Neural reconstruction for foveated rendering and video compression using learned statistics of natural videos},
  author={Kaplanyan, Anton S and Sochenov, Anton and Leimk{\"u}hler, Thomas and Okunev, Mikhail and Goodall, Todd and Rufo, Gizem},
  journal={ACM Transactions on Graphics (TOG)},
  volume={38},
  number={6},
  pages={1--13},
  year={2019},
  publisher={ACM New York, NY, USA}
}
@inproceedings{thavamani2021fovea,
  title={Fovea: Foveated image magnification for autonomous navigation},
  author={Thavamani, Chittesh and Li, Mengtian and Cebron, Nicolas and Ramanan, Deva},
  booktitle={Proceedings of the IEEE/CVF international conference on computer vision},
  pages={15539--15548},
  year={2021}
}
