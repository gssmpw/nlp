\section{Related Work}
% \tianyuan{I think the current relates work contains too much information and is too long. I will shorten it if no space left.}
% \jj{I shortened 2.1 and 2.2, and removed 2.3 and 2.4 (keeping the last sentence). FL doesn't seem too relevant here, and in-context learning probably doesn't need to be emphasized either} \tianyuan{Thank you, prof. JJ!}

\textbf{DP Synthetic Dataset.} 
% To train a dowand in-context learning nstream task model while ensuring Differential Privacy (DP) of private training data, one can apply DP-SGD____ for fine-tuning. However, this approach is computationally intensive, requiring a large amount of high-quality private samples, and suffers from significant performance degradation under tight DP budgets (small $\epsilon$)____. 
The goal of generating DP synthetic data is to mimic private dataset while protecting sensitive information. %, in order to train a downstream-task model.% while ensuring Differential Privacy (DP) of private data.
% An alternative is to create a DP synthetic dataset that mimics the private dataset while protecting sensitive information, which can then be used to train downstream models. 
Although fine-tuning a PLM with DP-SGD____ for data generation purpose can be effective% before generating the target DP synthetic dataset
____, it 
% still faces challenges related to computational intensity and high data requirements. 
is computationally intensive and requires a large number of high-quality private samples to reach strong performance.
Moreover, many state-of-the-art PLMs such as GPT series____ are also closed-source, making DP fine-tuning impractical.
%To solve above challenges, and using only the generative API of the PLM, 
%\\\jj{Need line break}

A new line of work instead relies on generative APIs of PLMs without fine-tuning, which focuses on either iterative data synthesis under DP guidance____ or creating DP replica of a given large private dataset____. %This eliminates the need for PLM fine-tuning, facilitating deployment and extension to powerful closed-source models like the GPT series.
Given that requiring a large global dataset for synthetic data initialization____ is hard to obtain in most cases, ____ proposes a more practical solution, Private Evolution (PE), which instead uses task-related synthetic samples. In PE, private samples are used to identify their nearest synthetic counterparts under DP protection, which then guide the growth of the DP synthetic dataset. PE is proven effective across images____ and text____, and is further adapted to federated private data scenarios____.
% Private Evolution (PE)____ to generate a DP synthetic dataset using only the generative API of the PLM. This eliminates the need for PLM fine-tuning, facilitating deployment and extension to powerful closed-source models like the GPT series. In PE, private samples are used to identify their nearest DP synthetic counterparts under DP protection, which then guide the expansion of the DP synthetic dataset. PE is applicable across various modalities, including images____ and text____, and has been adapted for federated private data scenarios____. 
% ____ uses a similar evolutionary generation process but relies on large scale public dataset as non-private dataset initialization which is hard to obtain. 
% Similarly, private density estimation____ can also be applied to create DP synthetic data but only for statistical tasks.
% ____ seeds LLM generation with DP protected private data to produce the DP synthetic dataset
However, all these works primarily focus on using a single PLM as the generation model.

\textbf{PLM Fusion.} The combination of multiple PLMs can lead to stronger model performance____. Some studies fine-tune target models with token-level fusion from PLMs as teachers during training time____, while others use majority voting____ or logits averaging____ for knowledge fusion during inference. 
However, data privacy challenges persist, as training or test samples are exposed to external models. To solve this, FuseGen____ recently proposes PLM fusion in a zero-shot learning setting, utilizing only model APIs to synthesize data without accessing real private samples, thereby ensuring data privacy. However, by treating all PLMs equally, it overlooks the capability difference of individual PLMs over different tasks.
% \textbf{Federated Learning (FL)}. 
% FL was first proposed by Google____ 
% % in which a cross-device collaboration scenario is described 
% % in which millions of mobile users collaboratively train a shared model using their local private data in a decentralized manner without directly sharing their data thereby preserving privacy. 
% enabling millions of mobile users to collaboratively train a shared model using their local private data without direct data sharing, thus preserving privacy.
% % In FL, each local model is updated independently by its respective party using private data and the aggregated knowledge from each local model is incorporated into the shared global model through the exchange of model parameter updates, thereby enhancing its performance. Subsequently, the updated global model is redistributed to each local model for further iterative improvements. 
% In the era of LLMs, FL has emerged as a decentralized training paradigm utilizing distributed data____. Additionally, research has explored how LLMs can enhance FL, investigating methods like federated synthesis to protect and enhance private data____, model initialization to speed up convergence____, personalization improvement____, etc. However, these works are all motivated by the decentralized data overlooking the potential of distributed LLMs.

% \textbf{Contrastive In-context Learning.}\footnote{Works____ considering understanding in-context learning with contrastive learning theories are sometimes referred to using the same name, but we do not consider them here.}
% % Here, we do not consider works that 
% The idea of using contrastive information to enrich in-context learning samples has been exploited from different aspects. Samples belonging to positive and negative classes____, correct or wrong self-predictions of training samples during training time____, human-preferred and non-preferred question responses____ have all been utilized as contrastive samples.
% ____ exploits using correct/wrong self-predictions of training samples as in-context samples to aid test time performance. 
% ____ uses samples belong to positive and negative classes as contrastive information for identifying causality and non-causality whitin a sentence.
% Our study is the first known effort to consider contrastive in-context learning for synthetic data generation, by treating samples of different qualities generated by multiple PLMs as contrastive information. \yang{this paragraph is not related to any related work. We can remove it?} 
More related works considering Contrastive In-context Learning are included in \cref{sec:appendix_related_work}.


%