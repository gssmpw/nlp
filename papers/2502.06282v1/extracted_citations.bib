@article{cai2024medusa,
  title={Medusa: Simple llm inference acceleration framework with multiple decoding heads},
  author={Cai, Tianle and Li, Yuhong and Geng, Zhengyang and Peng, Hongwu and Lee, Jason D and Chen, Deming and Dao, Tri},
  journal={arXiv preprint arXiv:2401.10774},
  year={2024}
}

@article{chen2023accelerating,
  title={Accelerating large language model decoding with speculative sampling},
  author={Chen, Charlie and Borgeaud, Sebastian and Irving, Geoffrey and Lespiau, Jean-Baptiste and Sifre, Laurent and Jumper, John},
  journal={arXiv preprint arXiv:2302.01318},
  year={2023}
}

@inproceedings{glam,
  author       = {Nan Du and
                  Yanping Huang and
                  Andrew M. Dai and
                  Simon Tong and
                  Dmitry Lepikhin and
                  Yuanzhong Xu and
                  Maxim Krikun and
                  Yanqi Zhou and
                  Adams Wei Yu and
                  Orhan Firat and
                  Barret Zoph and
                  Liam Fedus and
                  Maarten P. Bosma and
                  Zongwei Zhou and
                  Tao Wang and
                  Yu Emma Wang and
                  Kellie Webster and
                  Marie Pellat and
                  Kevin Robinson and
                  Kathleen S. Meier{-}Hellstern and
                  Toju Duke and
                  Lucas Dixon and
                  Kun Zhang and
                  Quoc V. Le and
                  Yonghui Wu and
                  Zhifeng Chen and
                  Claire Cui},
  title        = {GLaM: Efficient Scaling of Language Models with Mixture-of-Experts},
  booktitle    = {International Conference on Machine Learning, {ICML} 2022, 17-23 July
                  2022, Baltimore, Maryland, {USA}},
  series       = {Proceedings of Machine Learning Research},
  volume       = {162},
  pages        = {5547--5569},
  publisher    = {{PMLR}},
  year         = {2022},
  url          = {https://proceedings.mlr.press/v162/du22c.html},
}

@inproceedings{gshard,
  author    = {Dmitry Lepikhin and
               HyoukJoong Lee and
               Yuanzhong Xu and
               Dehao Chen and
               Orhan Firat and
               Yanping Huang and
               Maxim Krikun and
               Noam Shazeer and
               Zhifeng Chen},
  title     = {GShard: Scaling Giant Models with Conditional Computation and Automatic Sharding},
  booktitle = {9th International Conference on Learning Representations, {ICLR} 2021},
  publisher = {OpenReview.net},
  year      = {2021},
  url       = {https://openreview.net/forum?id=qrwe7XHTmYb},
}

@inproceedings{leviathan2023fast,
  title={Fast inference from transformers via speculative decoding},
  author={Leviathan, Yaniv and Kalman, Matan and Matias, Yossi},
  booktitle={International Conference on Machine Learning},
  pages={19274--19286},
  year={2023},
  organization={PMLR}
}

@article{li2024eagle,
  title={Eagle: Speculative sampling requires rethinking feature uncertainty},
  author={Li, Yuhui and Wei, Fangyun and Zhang, Chao and Zhang, Hongyang},
  journal={arXiv preprint arXiv:2401.15077},
  year={2024}
}

@article{meta_multitoken,
  title   = {Better \& Faster Large Language Models via Multi-token Prediction},
  author  = {Fabian Gloeckle and Badr Youbi Idrissi and Baptiste Rozi√®re and David Lopez-Paz and Gabriel Synnaeve},
  year    = {2024},
  journal = {arXiv preprint arXiv: 2404.19737}
}

@article{miao2023specinfer,
  title={SpecInfer: Accelerating Generative Large Language Model Serving with Tree-based Speculative Inference and Verification},
  author={Miao, Xupeng and Oliaro, Gabriele and Zhang, Zhihao and Cheng, Xinhao and Wang, Zeyu and Zhang, Zhengxin and Wong, Rae Ying Yee and Zhu, Alan and Yang, Lijie and Shi, Xiaoxiang and others},
  journal={arXiv preprint arXiv:2305.09781},
  year={2023}
}

@inproceedings{moe,
  author    = {Noam Shazeer and
               Azalia Mirhoseini and
               Krzysztof Maziarz and
               Andy Davis and
               Quoc V. Le and
               Geoffrey E. Hinton and
               Jeff Dean},
  title     = {Outrageously Large Neural Networks: The Sparsely-Gated Mixture-of-Experts Layer},
  booktitle = {5th International Conference on Learning Representations, {ICLR} 2017},
  publisher = {OpenReview.net},
  year      = {2017},
  url       = {https://openreview.net/forum?id=B1ckMDqlg},
}

@article{monea2023pass,
  title={Pass: Parallel speculative sampling},
  author={Monea, Giovanni and Joulin, Armand and Grave, Edouard},
  journal={arXiv preprint arXiv:2311.13581},
  year={2023}
}

@misc{openmoe,
  author = {Fuzhao Xue and Zian Zheng and Yao Fu and Jinjie Ni and Zangwei Zheng and Wangchunshu Zhou and Yang You},
  title = {OpenMoE: Open Mixture-of-Experts Language Models},
  year = {2023},
  publisher = {GitHub},
  journal = {GitHub repository},
  howpublished = {\url{https://github.com/XueFuzhao/OpenMoE}},
}

@article{ori_moe1,
  author    = {Robert A. Jacobs and
               Michael I. Jordan and
               Steven J. Nowlan and
               Geoffrey E. Hinton},
  title     = {Adaptive Mixtures of Local Experts},
  journal   = {Neural Computing},
  volume    = {3},
  number    = {1},
  pages     = {79--87},
  year      = {1991},
  url       = {https://doi.org/10.1162/neco.1991.3.1.79},
}

@article{ori_moe2,
  author    = {Michael I. Jordan and
               Robert A. Jacobs},
  title     = {Hierarchical Mixtures of Experts and the {EM} Algorithm},
  journal   = {Neural Computing},
  volume    = {6},
  number    = {2},
  pages     = {181--214},
  year      = {1994},
  url       = {https://doi.org/10.1162/neco.1994.6.2.181},
}

@inproceedings{parallel_dec_1,
    title = "Mask-Predict: Parallel Decoding of Conditional Masked Language Models",
    author = "Ghazvininejad, Marjan  and
      Levy, Omer  and
      Liu, Yinhan  and
      Zettlemoyer, Luke",
    booktitle = "Proceedings of the 2019 Conference on Empirical Methods in Natural Language Processing and the 9th International Joint Conference on Natural Language Processing (EMNLP-IJCNLP)",
    month = nov,
    year = "2019",
    address = "Hong Kong, China",
    publisher = "Association for Computational Linguistics",
    pages = "6112--6121",
}

@inproceedings{stablemoe,
  author       = {Damai Dai and
                  Li Dong and
                  Shuming Ma and
                  Bo Zheng and
                  Zhifang Sui and
                  Baobao Chang and
                  Furu Wei},
  editor       = {Smaranda Muresan and
                  Preslav Nakov and
                  Aline Villavicencio},
  title        = {StableMoE: Stable Routing Strategy for Mixture of Experts},
  booktitle    = {Proceedings of the 60th Annual Meeting of the Association for Computational
                  Linguistics (Volume 1: Long Papers), {ACL} 2022, Dublin, Ireland,
                  May 22-27, 2022},
  pages        = {7085--7095},
  publisher    = {Association for Computational Linguistics},
  year         = {2022},
  url          = {https://doi.org/10.18653/v1/2022.acl-long.489},
  doi          = {10.18653/V1/2022.ACL-LONG.489},
}

@article{stern2018blockwise,
  title={Blockwise parallel decoding for deep autoregressive models},
  author={Stern, Mitchell and Shazeer, Noam and Uszkoreit, Jakob},
  journal={Advances in Neural Information Processing Systems},
  volume={31},
  year={2018}
}

@article{sun2021instantaneous,
  title={Instantaneous grammatical error correction with shallow aggressive decoding},
  author={Sun, Xin and Ge, Tao and Wei, Furu and Wang, Houfeng},
  journal={arXiv preprint arXiv:2106.04970},
  year={2021}
}

@article{switch,
  author    = {William Fedus and
               Barret Zoph and
               Noam Shazeer},
  title     = {Switch Transformers: Scaling to Trillion Parameter Models with Simple and Efficient Sparsity},
  journal   = {CoRR},
  volume    = {abs/2101.03961},
  year      = {2021},
  url       = {https://arxiv.org/abs/2101.03961},
  archivePrefix = {arXiv},
  eprint    = {2101.03961},
}

@inproceedings{yi-etal-2024-generation,
    title = "Generation Meets Verification: Accelerating Large Language Model Inference with Smart Parallel Auto-Correct Decoding",
    author = "Yi, Hanling  and
      Lin, Feng  and
      Li, Hongbin  and
      Peiyang, Ning  and
      Yu, Xiaotian  and
      Xiao, Rong",
    booktitle = "Findings of the Association for Computational Linguistics ACL 2024",
    month = aug,
    year = "2024",
    address = "Bangkok, Thailand and virtual meeting",
    publisher = "Association for Computational Linguistics",
    pages = "5285--5299",
}

