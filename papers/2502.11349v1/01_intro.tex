
\section{Introduction}

The advancement of large language models (LLMs) has reshaped artificial intelligence (AI), enabling efficient and effective natural language processing (NLP). 
LLMs utilize deep neural networks (DNNs) containing billions, and in some cases trillions, of parameters trained on immense quantities of text data using a combination of self-supervised and unsupervised learning approaches~\cite{01}. 
Sindhu et al.~\cite{02} highlights the evolution of LLMs and the transition from rule-based systems to more sophisticated transformer structures such as GPT and BERT. 

However, the immense size of LLMs and their high computational resource requirements have always posed challenges for running them on resource-constrained edge devices such as the Raspberry Pi. 
In this work, the Raspberry Pi 4 was selected for LLM deployment due to its widespread adoption among edge devices. 
Dhar et al.~\cite{03} explores the key challenges and limitations that impede the efficient deployment of LLMs on edge devices. By deploying the LlamA-2 7B model using INT4 quantization on edge devices such as the Nvidia Jetson AGX Orin and Raspberry Pi 4 Model B with various memory configurations and performing a comprehensive analysis of the experimental results, the work highlights that limited memory capacity and inadequate computing resources in many conventional edge devices serve as the predominant barriers. 

Edge Language Models (ELMs) have emerged as a type of language models that runs directly on edge devices rather than relying on cloud-based servers. These models are optimized for efficiency, enabling real-time language processing with minimal latency and improved privacy~\cite{haris_SECDA-LLM_2024}. 
Examples of ELM tasks include virtual assistants for day-to-day or task-specific interactions, real-time translation, privacy-preserving data processing and analysis, and adaptive user interfaces; all of them without constant reliance on cloud processing~\cite{05}. 
Zheng et al.~\cite{06} discusses a variety of LLM-based applications and the challenges faced in deploying them for cross-domain applications on edge and cloud environments, ranging from industry to academia. 


Despite all the advantages and optimizations that have been made to fit LLMs on edge devices and process data effectively with low latency within constrained resources, the fundamental question of the impact of various optimization techniques on the fairness of these models running on the edge remains neglected. 
In the past, various AI models deployed for making critical public decisions, such as screening resumes~\cite{07} for large multinational companies, have exhibited unexpectedly poor behavior and biases based on gender~\cite{08}. 
Schwartz et al.~\cite{09} provides a deeper look into the categories of AI biases and how they contribute to harm. 
%
Furthermore, previous studies~\cite{wan2023kelly,taubenfeld2024systematic,ye2024justice} have shown how different types of biases have been observed on LLM-based applications. This issue becomes critical, as these models are using a feedback loop for retraining~\cite{liang2024learning}, so there is a possibility that after retraining from biased interactions, the model will be entirely biased. This issue is even more critical when it comes to standalone edge devices. 

In this paper we provide a thorough comparative study for the presence of potential bias in: i) cloud-based LLMs, including OpenAI's Gpt-4o-mini~\cite{10}, Google's Gemini-1.5-flash~\cite{11}, and xAI's Grok-beta~\cite{12}; ii) open-source LLMs including Gemma2 7B~\cite{gemma_2024} and Mistral 7B~\cite{jiang2023mistral} running on a Mac M1 desktop machine using the Ollama~\cite{13} framework; and iii) the Llama-2 7B~\cite{touvron2023llama} model deployed on the Raspberry Pi 4 edge device. 
We also propose a context-aware feedback loop for each layer of an edge optimized language model to reduce bias in the results. 

The contributions of this paper include the following: 

\begin{itemize}
  \item Analysis of bias found in response text generated from cloud, desktop and edge deployed LLMs over a period of $1,500$ repetitive prompt queries.

  \item Deployment of the Llama-2 7B model using INT8 quantization on a Raspberry Pi 4 with 8 GB of memory, and study of its impact on model bias. 
  
  \item Introduction of a context-aware feedback loop for ELMs, passing additional weights to each model layer for minimizing the bias in the model outcome.
\end{itemize}


The rest of the paper is organized as follows: Section~\ref{sec:rw} reviews related work for the deployment of LLMs on edge devices, and bias found in LLMs. 
In Section~\ref{sec:method}, a methodology for quantizing LLMs to INT8, a setup for running local and cloud LLMs effectively, and a process for introducing a context-aware feedback-loop are described. 
Section~\ref{sec:eval} presents the analysis of results for the LLMs and ELMs under study. 
Section~\ref{sec:disc} further discusses the results achieved.
Finally, Section~\ref{sec:conclusion} summarizes the key findings of the work and provides some directions for future work.