\section{Conclusion}
We analyze catastrophic forgetting in machine learning models using parameter-efficient fine-tuning based on pretrained models. Our experiments reveal that low-rank adaptations like LoRA induce feature mean and covariance shifts, termed Semantic Drift. To address this, we propose mean shift compensation and covariance calibration to constrain feature moments, maintaining both model stability and plasticity. Additionally, we implement feature self-distillation for patch tokens to enhance feature stability. Our task-agnostic continual learning framework outperforms existing methods across multiple public datasets.
%, demonstrating its effectiveness in mitigating Semantic Drift and improving continual learning performance.