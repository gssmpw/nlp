\section{Related Work}
\subsection{Exploration for Blind People}
Previous research has emphasized the importance of exploration for blind people to familiarize themselves with the environment~\cite{jain2023want} or for enjoying recreational areas where exploration is essential (\eg, museums~\cite{kayukawa2023enhancing} or shopping malls~\cite{kamikubo2024we}).
The investigation by Engel~\etal~\cite{Engel2020travelling} shows that 59.4\% of the blind population in the study travels to unfamiliar buildings several times a week, but often cannot explore independently, because they rely on sighted assistants with limited availability.
While learning routes and POIs in a building could also be achieved by searching online~\cite{Engel2020travelling}, using interactive maps~\cite{wang2022bentomuseum,nagassa20233d,sargsyan20233d,poppinga2011touchover} or applications~\cite{india2021vstroll,guerreiro2017virtual}, on-site exploration by blind people is also important because by doing this, they receive rich sensory information and gain a better sense of independence~\cite{kamikubo2024we}.
This overall experience motivates them to explore by themselves~\cite{guerreiro2019airport,kamikubo2024we}. 
Focusing on on-site exploration, researchers have investigated the information needs of blind people~\cite{hoogsteen2022beyond,williams2014just,banovic2013uncovering,jain2023want,kamikubo2024we}, and found that it is essential to include high-level understanding of the environment (\eg, layout information~\cite{jain2023want}) as well as specific details such as the names of the shops and brands~\cite{banovic2013uncovering}.
Additionally, researchers noted that safety during navigation is crucial, as safety concerns can dominate the cognitive load and impede the rich exploration experience~\cite{cai2024navigating,zhang2023follower,jain2023want}. 

\subsection{Assistance Systems for Blind People To Explore}
% Researchers have proposed solutions to assist blind people in navigating and exploring environments. 
\red{
% We utilize navigation robots for the device of our system for their benefit in addressing the mobility challenges of blind people with their automatic guidance capability.
Robotic guide systems have the advantage of addressing the mobility challenges of blind people with their automatic guidance capability.
CaBot~\cite{guerreiro2019cabot}, the first guidance robot that adopted the form of a suitcase, guides users to specified destinations while referring to prebuilt maps or using an object detector to convey surrounding information.
Among them, some are specialized in exploration~\cite{kayukawa2023enhancing,asakawa2018present,asakawa2019independent}.
A robot system by Kayukawa~\etal~\cite{kayukawa2023enhancing} allows users to explore by interactively setting destinations on a smartphone and by calling a museum guide to explain the surroundings.
However, both systems heavily rely on prebuilt maps and operate in limited locations where the destinations are readily available.
Ultimately, our goal is to develop a system that does not require prebuilt maps and enables blind people to explore independently, \ie, without relying on staff assistance within the facility.
}

Navigation systems for blind people that do not rely on prebuilt maps and infrastructure, \ie, \textit{map-less navigation systems}, have also been proposed in prior research. 
Besides real-time perception outcomes, these systems primarily depend on externally sourced route information, such as prior route knowledge from blind users~\cite{lacey2000context,Kuribayashi2022CorridorWalker}, routes described by nearby pedestrians~\cite{ranganeni2023exploring,kim2023transforming,kuribayashi2023pathfinder}, and analyzed images of floor maps captured in buildings~\cite{Kubota2024Snap}.
\red{
For example, PathFinder~\cite{kuribayashi2023pathfinder} is a map-less navigation robot system designed to guide blind users to their destinations based on predefined routes. 
The system autonomously navigates users by utilizing an intersection detection algorithm~\cite{yang2021graph} and a sign recognition algorithm~\cite{kuribayashi2023pathfinder}. 
These algorithms enable users to determine the correct direction to proceed at key decision points. 
The system's evaluation found that it is necessary to include functionality that takes users back to their starting location after reaching their destination when navigating unfamiliar buildings.
}
However, these map-less navigation systems are tasked with reaching a specific destination and are not suitable for exploration, as they only focus on providing information related to reaching the destination (\eg, intersections and signs~\cite{kuribayashi2023pathfinder}). 
\red{
In an exploration scenario, any information about the environment may prove valuable, such as layout information~\cite{jain2023want}. 
In our study, we aim to explore the underexplored design space of map-less guide robots for exploration purposes, such as how the system should describe surroundings and what are the task-specific functionality requirements.
% For example, we identified three levels of varying detail as important in this context.
% Also, as exploration extends beyond simply reaching a destination and returning to the starting point, we found that the ``Take-Me-There'' functionality, which enables users to navigate to any previously visited location during the exploration. 
}

\subsection{Autonomy and Control Methods of Assistant Systems}
Researchers have emphasized autonomy, \ie, the ability for users to select destinations and routes according to their interests, as an important factor for exploratory activities~\cite{Kaniwa2024ChitChatGuide,kayukawa2022HowUsers}. 
To this end, researchers have investigated various control methods based on user inputs~\cite{ranganeni2023exploring,zhang2023follower}. 
For example, systems with prebuilt maps adopted selecting destinations from a premade list of stores~\cite{sato2019navcog3,kayukawa2022HowUsers}, or via conversation~\cite{sato2019navcog3,Kaniwa2024ChitChatGuide}. 
In the case of map-less systems, researchers have adopted feedback-based closed-loop processes to leverage both human inputs and system control. 
Examples include users specifying proceeding directions at intersections while the robot provides automated guidance to the next intersections~\cite{kuribayashi2023pathfinder,jain2023want,ranganeni2023exploring,lacey2000context,hwang2022system}. 
Zhang~\etal~\cite{zhang2023follower} reported that the preferred level of control by blind people may vary depending on context.
Therefore, we examine the level of control between users and robots under the novel exploration context. 

\subsection{Scene Description for Blind People}
\red{Knowledge of surrounding information is crucial for blind people to explore~\cite{Kaniwa2024ChitChatGuide}.} Tools for blind people to understand their surrounding environment have been commercially deployed and the topic remains an ongoing area of research.
\red{
While researchers have proposed tools using visual captioning~\cite{saha2019closing} and question-answering models~\cite{gurari2018vizwiz} to help blind users understand scenes, these often fail to provide accurate descriptions at diverse locations~\cite{delloul2022image}.
Alternatively, RSA applications (\eg, Aira~\cite{Aira} and BeMyEyes~\cite{BeMyEyes}) have long been a practical aid for providing blind people with surrounding scenes.
However, RSA systems are not suitable for our task, as the service quality depends heavily on the sighted assistance provided~\cite{kamikubo2020support}. RSA services may also not be sustainable for extended use until users feel fully satisfied with their exploration experience.
}
With the emergence of LLMs and MLLMs, scene describing systems (\eg, Seeing AI~\cite{SeeingAI}, BeMyAI~\cite{BeMyAI} and GPT4o-demo~\cite{GPT4o}) have been developed, which enable blind people to understand scenes in diverse scenarios~\cite{gonzalez2024investigating,xie2024emerging}. 
\red{
ChitChatGuide~\cite{Kaniwa2024ChitChatGuide} employs LLMs to interpret predetermined maps and deliver exploration-related information during navigation to a specified destination. 
However, unlike our system, it relies on prebuilt maps and lacks the capability to provide real-time information.
MLLM-based systems, such as WorldScribe~\cite{chang2024worldscribe}, offer real-time information by analyzing captured images. 
WorldScribe~\cite{chang2024worldscribe} also adapts the level of description based on user context, such as the speed at which the device is moved.
Our WanderGuide similarly provides three levels of descriptions but the selection is adjusted based on individual user preferences rather than situational context.
On the system level, the core distinction is that WanderGuide combines MLLM with a navigation robot, allowing users to concentrate fully on the descriptions of novel environments and navigate to interested places. This combination makes WanderGuide particularly well-suited for \textit{exploration while navigating}.}