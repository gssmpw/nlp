\begin{figure}
  % \centering
  \includegraphics[width=1.0\textwidth]{fig/Figure1_1.pdf}
  \caption{Example comparison between \textbf{Static} and \textbf{Adaptive Policies}. The safe can be directly opened if unlocked; otherwise, the key must be turned to unlock the latch before opening the door.
  However, it is impossible to figure out the lock state from pure visual observations.
  \textbf{Static Policy:} The demonstrations for training the static policy are optimal trajectories under full observation, including both locked and unlocked states. Consequently, the learned policy is a bimodal distribution based on visual observation alone. If the robot samples the "unlocked trajectory" and fails to open the locked door, it will be out of distribution. \textbf{Adaptive Policy:} The demonstrations for training the adaptive policy include recovery from the failed door opening. Therefore, the policy learns to first pull the door to check the lock state and updates the policy distribution accordingly based on the feedback.
  }
  \label{fig:fig1}
  \vspace{-0.3cm}
\end{figure}
