@article{Chang2015ShapeNetAI,
  title={ShapeNet: An Information-Rich 3D Model Repository},
  author={Angel X. Chang and Thomas A. Funkhouser and Leonidas J. Guibas and Pat Hanrahan and Qi-Xing Huang and Zimo Li and Silvio Savarese and Manolis Savva and Shuran Song and Hao Su and Jianxiong Xiao and L. Yi and Fisher Yu},
  journal={ArXiv},
  year={2015},
  volume={abs/1512.03012},
  url={https://api.semanticscholar.org/CorpusID:2554264}
}

@InProceedings{Mo_2019_CVPR,
author = {Mo, Kaichun and Zhu, Shilin and Chang, Angel X. and Yi, Li and Tripathi, Subarna and Guibas, Leonidas J. and Su, Hao},
title = {{PartNet}: A Large-Scale Benchmark for Fine-Grained and Hierarchical Part-Level {3D} Object Understanding},
booktitle = {The IEEE Conference on Computer Vision and Pattern Recognition (CVPR)},
month = {June},
year = {2019}
}

@InProceedings{Mo_2021_ICCV,
    author    = {Mo, Kaichun and Guibas, Leonidas J. and Mukadam, Mustafa and Gupta, Abhinav and Tulsiani, Shubham},
    title     = {Where2Act: From Pixels to Actions for Articulated 3D Objects},
    booktitle = {Proceedings of the IEEE/CVF International Conference on Computer Vision (ICCV)},
    month     = {October},
    year      = {2021},
    pages     = {6813-6823}
}

@article{eisner2022flowbot3d,
  title={Flowbot3d: Learning 3d articulation flow to manipulate articulated objects},
  author={Eisner, Ben and Zhang, Harry and Held, David},
  journal={arXiv preprint arXiv:2205.04382},
  year={2022}
}

@article{geng2022end,
  title={End-to-End Affordance Learning for Robotic Manipulation},
  author={Geng, Yiran and An, Boshi and Geng, Haoran and Chen, Yuanpei and Yang, Yaodong and Dong, Hao},
  journal={ICRA},
  year={2023}
}

@inproceedings{geng2023gapartnet,
  title={Gapartnet: Cross-category domain-generalizable object perception and manipulation via generalizable and actionable parts},
  author={Geng, Haoran and Xu, Helin and Zhao, Chengyang and Xu, Chao and Yi, Li and Huang, Siyuan and Wang, He},
  booktitle={Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition},
  pages={7081--7091},
  year={2023}
}

@inproceedings{geng2023partmanip,
  title={Partmanip: Learning cross-category generalizable part manipulation policy from point cloud observations},
  author={Geng, Haoran and Li, Ziming and Geng, Yiran and Chen, Jiayi and Dong, Hao and Wang, He},
  booktitle={Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition},
  pages={2978--2988},
  year={2023}
}

@inproceedings{gong2023arnold,
  title={ARNOLD: A Benchmark for Language-Grounded Task Learning With Continuous States in Realistic 3D Scenes},
  author={Gong, Ran and Huang, Jiangyong and Zhao, Yizhou and Geng, Haoran and Gao, Xiaofeng and Wu, Qingyang and Ai, Wensi and Zhou, Ziheng and Terzopoulos, Demetri and Zhu, Song-Chun and others},
  booktitle={Proceedings of the IEEE/CVF International Conference on Computer Vision (ICCV)},
  year={2023}
}

@article{gu2023maniskill2,
    title={Maniskill2: A unified benchmark for generalizable manipulation skills},
    author={Gu, Jiayuan and Xiang, Fanbo and Li, Xuanlin and Ling, Zhan and Liu, Xiqiang and Mu, Tongzhou and Tang, Yihe and Tao, Stone and Wei, Xinyue and Yao, Yunchao and others},
    journal={arXiv preprint arXiv:2302.04659},
    year={2023}
}

@article{li2024unidoormanip,
  title={UniDoorManip: Learning Universal Door Manipulation Policy Over Large-scale and Diverse Door Manipulation Environments},
  author={Li, Yu and Zhang, Xiaojie and Wu, Ruihai and Zhang, Zilong and Geng, Yiran and Dong, Hao and He, Zhaofeng},
  journal={arXiv preprint arXiv:2403.02604},
  year={2024}
}

@article{ling2024articulated,
  title={Articulated Object Manipulation with Coarse-to-fine Affordance for Mitigating the Effect of Point Cloud Noise},
  author={Ling, Suhan and Wang, Yian and Wu, Shiguang and Zhuang, Yuzheng and Xu, Tianyi and Li, Yu and Liu, Chang and Dong, Hao},
  journal={ICRA},
  year={2024}
}

@inproceedings{liu2022akb,
  title={Akb-48: A real-world articulated object knowledge base},
  author={Liu, Liu and Xu, Wenqiang and Fu, Haoyuan and Qian, Sucheng and Yu, Qiaojun and Han, Yang and Lu, Cewu},
  booktitle={Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition},
  pages={14809--14818},
  year={2022}
}

@inproceedings{mu2021maniskill,
  title={ManiSkill: Generalizable Manipulation Skill Benchmark with Large-Scale Demonstrations},
  author={Mu, Tongzhou and Ling, Zhan and Xiang, Fanbo and Yang, Derek Cathera and Li, Xuanlin and Tao, Stone and Huang, Zhiao and Jia, Zhiwei and Su, Hao},
  booktitle={Thirty-fifth Conference on Neural Information Processing Systems Datasets and Benchmarks Track (Round 2)},
  year={2021}
}

@inproceedings{ning2023where2explore,
      title={Where2Explore: Few-shot Affordance Learning for Unseen Novel Categories of Articulated Objects},
      author={Ning, Chuanruo and Wu, Ruihai and Lu, Haoran and Mo, Kaichun and Dong, Hao},
       booktitle={Advances in Neural Information Processing Systems (NeurIPS)},
      year={2023}
    }

@article{urakami2019doorgym,
  title={Doorgym: A scalable door opening environment and baseline agent},
  author={Urakami, Yusuke and Hodgkinson, Alec and Carlin, Casey and Leu, Randall and Rigazio, Luca and Abbeel, Pieter},
  journal={arXiv preprint arXiv:1908.01887},
  year={2019}
}

@article{wang2021adaafford,
  title={AdaAfford: Learning to Adapt Manipulation Affordance for 3D Articulated Objects via Few-shot Interactions},
  author={Wang, Yian and Wu, Ruihai and Mo, Kaichun and Ke, Jiaqi and Fan, Qingnan and Guibas, Leonidas and Dong, Hao},
  journal={European conference on computer vision (ECCV 2022)},
  year={2022}
}

@inproceedings{wu2022vatmart,
title={{VAT}-Mart: Learning Visual Action Trajectory Proposals for Manipulating 3D {ART}iculated Objects},
author={Ruihai Wu and Yan Zhao and Kaichun Mo and Zizheng Guo and Yian Wang and Tianhao Wu and Qingnan Fan and Xuelin Chen and Leonidas Guibas and Hao Dong},
booktitle={International Conference on Learning Representations},
year={2022},
url={https://openreview.net/forum?id=iEx3PiooLy}
}

@inproceedings{xiang2020sapien,
  title={Sapien: A simulated part-based interactive environment},
  author={Xiang, Fanbo and Qin, Yuzhe and Mo, Kaichun and Xia, Yikuan and Zhu, Hao and Liu, Fangchen and Liu, Minghua and Jiang, Hanxiao and Yuan, Yifu and Wang, He and others},
  booktitle={Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition},
  pages={11097--11107},
  year={2020}
}

@article{xu2024naturalvlm,
  title={NaturalVLM: Leveraging Fine-grained Natural Language for Affordance-Guided Visual Manipulation},
  author={Xu, Ran and Shen, Yan and Li, Xiaoqi and Wu, Ruihai and Dong, Hao},
  journal={arXiv preprint arXiv:2403.08355},
  year={2024}
}

@article{zhang2023flowbot++,
  title={Flowbot++: Learning generalized articulated objects manipulation via articulation projection},
  author={Zhang, Harry and Eisner, Ben and Held, David},
  journal={arXiv preprint arXiv:2306.12893},
  year={2023}
}

