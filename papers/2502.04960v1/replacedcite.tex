\section{Related Work}
Early humor recognition research predominantly utilized feature engineering and traditional machine learning techniques to identify linguistic and stylistic features of humorous texts____.
For example, ____ employed features such as alliteration, antonyms, and adult slang to model humor, using classifiers like Naive Bayes (NB) and Support Vector Machines (SVM) ____ for humor recognition. ____ explored grammatical, syntactic, semantic, and pragmatic features of humor texts, enriching the field of feature-based humor recognition. ____ combined emotional and semantic analysis to model the emotional aspects of humor. 
While effective in some scenarios, these methods significantly struggle to capture the deep semantic and contextual nuances vital for understanding humor. 
Additionally, their reliance on manually designed features, which are labor-intensive to create and inflexible in application, further limits their effectiveness.

The advent of deep learning marked a significant shift towards using neural networks for automatic feature extraction. 
Additionally, the introduction of Transformer-based pretrained language models significantly enhanced the performance of humor recognition systems. 
For instance, ____ developed a CNN-based model to recognize humor in speeches and puns, outperforming traditional methods even without manually designed features. 
____ introduced the Transformer model, which further improved the ability to learn complex humor patterns and exhibited superior performance compared to other deep neural networks. 
____ utilized GPT ____ to calculate the inconsistency between punchlines in jokes, enhancing humor recognition based on these inconsistency scores. 
____ used pretrained BERT ____ to obtain sentence embeddings for humor recognition. 
____ leveraged social network information and graph neural networks to enhance humor recognition results.

Despite significant progress in humor recognition research, recent approaches tend to focus primarily on single semantic layers, struggling to analyze user language from the diverse common perspectives of humor expression. Additionally, a critical limitation of these methods is their neglect of the speakerâ€™s individual expression styles. 

\begin{figure*}[!ht]
\centering
    \includegraphics[scale=0.75, trim=30 222 0 287, clip]{figures/model.pdf}
\caption{The overall architecture of the proposed CIHR model, which consists of four main module: Humor Commonalities Analysis, Speaker Individuality Extraction, Static Fusion and Dynamic Fusion.}
\label{fig:model}
\end{figure*}