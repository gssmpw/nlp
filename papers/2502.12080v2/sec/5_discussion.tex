\section{Discussion and Conclusion}
To sum up, we propose \nickname{}, which reformulates the single-view-based 3D human novel view and pose synthesis as a single-view-conditioned human diffusion process, utilizing generative priors from foundational diffusion models to complement the missing information. 
To further produce perpetually realistic, view-consistent, and temporally coherent human avatars from a single image, we incorporate a Human NeRF module along with a view-attention, and temporal attention layer into our \nickname{}.
Furthermore, we introduce an image-level loss during optimization to bridge the gap between latent and image spaces in diffusion models.
On two multi-view human datasets, our \nickname{} achieves the best perceptual results. 

\noindent \textbf{Limitation and Future Work.}
1) While our proposed \nickname{} improves the synthesis performance, there still exists inconsistency between the generated images and the input image. 
How to align target images with the input image and target poses remains a future direction to be explored.
2) There is still room to improve the visual quality of generated results. 
We observe that VAE produces distortions for facial areas in some cases. 
Introducing VAE tailored for human images is a promising direction to improve the quality.
3) Currently, our \nickname{} is trained on existing multi-view human datasets. 
Scaling our \nickname{} to larger human datasets remains a future direction to be explored.
% We hope our research could inspire more future research to solve these problems.

