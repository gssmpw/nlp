\section{Related Work}
Feature importance interpretation in language models is typically approached through three main methods: gradient-based, attention-based, and perturbation-based ____.

\textbf{Gradient-Based Methods} identify influential features by calculating the gradient of the output logits with respect to input elements ____. Recent advances include gradient-based post hoc contrastive explanations for model predictions ____ and analyses of how CoT prompting affects saliency scores ____. However, these methods face significant limitations: they require access to model internals, making them inapplicable to closed-source models. Furthermore, research has shown that model gradients can be easily manipulated, raising concerns about the reliability of gradient-based analyzes ____.

\textbf{Attention-Based Methods} interpret feature importance by analyzing the weighted sum of intermediate representations in neural networks ____. While intuitive, these approaches have several drawbacks. For one, the attention weights do not always correspond to the most important features for model predictions ____ and may not correlate well with other feature importance measures ____. Moreover, attention weights often contain redundant and mixed information, leading to unreliable explanations ____. Like gradient-based methods, these approaches also require access to model internals, limiting their applicability to open-source models.

\textbf{Perturbation-Based Methods} can analyze any LLM regardless of architecture accessibility by measuring how outputs change when inputs are modified. As ____ describes, ``a word (token) or a collection of words (tokens) are modified or removed from the input samples, and a resulting change is measured.''

Notable approaches include LIME ____, which creates local linear approximations of model behavior, and other dataset instance perturbations ____. Recent research has extended these methods to few-shot demonstrations ____ and system prompts ____.

Despite these advancements, there remains a significant gap in the interpretation of zero-shot instructional prompts. Current research often uses basic token masking, which may oversimplify prompt semantics. It can also result in incoherent perturbations, potentially failing to interpret the true impact of the word on model predictions ____. Our research addresses this by introducing a new metric that employs a variety of meaningful perturbations to reveal the importance of each word in zero-shot instructional prompts. 

%This approach not only extends existing perturbation-based methods but also overcomes the constraints of other techniques by enabling the analysis of both open and closed-source models without requiring access to internal parameters.