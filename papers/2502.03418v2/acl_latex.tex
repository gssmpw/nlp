% This must be in the first 5 lines to tell arXiv to use pdfLaTeX, which is strongly recommended.
\pdfoutput=1
% In particular, the hyperref package requires pdfLaTeX in order to break URLs across lines.

\documentclass[11pt]{article}

% Change ``review'' to ``final'' to generate the final (sometimes called camera-ready) version.
% Change to ``preprint'' to generate a non-anonymous version with page numbers.
\usepackage[]{acl}

% Standard package includes
\usepackage{times}
\usepackage{latexsym}
\usepackage{float}
\usepackage{placeins}

% For proper rendering and hyphenation of words containing Latin characters (including in bib files)
\usepackage[T1]{fontenc}
% For Vietnamese characters
% \usepackage[T5]{fontenc}
% See https://www.latex-project.org/help/documentation/encguide.pdf for other character sets

% This assumes your files are encoded as UTF8
\usepackage[utf8]{inputenc}

% This is not strictly necessary, and may be commented out,
% but it will improve the layout of the manuscript,
% and will typically save some space.
\usepackage{microtype}

\usepackage{booktabs}
\usepackage{caption}  % Base caption package
\usepackage{subcaption} % For subfigures and subtables
\usepackage{makecell} % Provides \makecell for better control within table cells
\usepackage{array}    % For more complex cell formatting
% This is also not strictly necessary, and may be commented out.
% However, it will improve the aesthetics of text in
% the typewriter font.

% This is also not strictly necessary, and may be commented out.
% However, it will improve the aesthetics of text in
% the typewriter font.
\usepackage{inconsolata}

%Including images in your LaTeX document requires adding
%additional package(s)
\usepackage{graphicx}
\usepackage{amsthm}
\usepackage{ulem} % For underlining across multiple lines


% Reduce spacing in lists and around environments
\usepackage{enumitem}
\setlist{nosep} % Removes space around list items
\newtheoremstyle{compactexample} % Define a new style for the example environment
    {3pt} % Space above
    {3pt} % Space below
    {} % Body font
    {} % Indent amount
    {\bfseries} % Theorem head font
    {.} % Punctuation after theorem head
    {.5em} % Space after theorem head
    {} % Theorem head spec

\theoremstyle{compactexample}
\newtheorem{example}{Example}


%Including images in your LaTeX document requires adding
%additional package(s)
\usepackage{graphicx}
\usepackage[absolute,showboxes]{textpos} % Add `showboxes` for debugging
\textblockorigin{0pt}{0pt} % Set origin to top left corner
\TPshowboxestrue % Show text block boxes, useful for debugging
\TPshowboxesfalse % Turn off show boxes for final output
\usepackage{todonotes}
\usepackage{amsmath}
\usepackage{array}
\usepackage{subcaption}
\usepackage{pgf-pie}
\usepackage{adjustbox}
\usepackage{tikz}
\usepackage{tabularx}
\usepackage{xcolor}
\usepackage{colortbl}
\usepackage{CJKutf8}
\usepackage{enumitem}
\usepackage{multirow}
\definecolor{myVB}{RGB}{173,216,230}  % Light brown
\definecolor{myVBP}{RGB}{144,238,144} % Light Green
\definecolor{myRB}{RGB}{0,100,0}      % Dark Green
\definecolor{myJJ}{RGB}{255,255,255}  % White
\definecolor{myNN}{RGB}{224,255,255}  % Light brown (lighter)

\usepackage{pgfplots}
\pgfplotsset{compat=1.17}
\usepackage{pgfplotstable}
\usepackage{pifont}
%\newcommand\VERYHuge{\fontsize{90}{100}\selectfont}



\newcommand{\reminder}{\textsuperscript{\textcolor{red}{\textbf{*}}}}

% If the title and author information does not fit in the area allocated, uncomment the following
%
%\setlength\titlebox{<dim>}
%
% and set <dim> to something 5cm or larger.

\title{%
    %\begin{textblock*}{0.6cm}[0,0](7cm,2.6cm)  % {block width} (coords) 
    %includegraphics[height=0.7cm]{Images/logo.png}
    %\end{textblock*}
    Think or Step-by-Step? \\ UnZIPping the Black Box in Zero-Shot Prompts

}

% Author information can be set in various styles:
% For several authors from the same institution:
% \author{Author 1 \and ... \and Author n \\
%         Address line \\ ... \\ Address line}
% if the names do not fit well on one line use
%         Author 1 \\ {\bf Author 2} \\ ... \\ {\bf Author n} \\
% For authors from different institutions:
% \author{Author 1 \\ Address line \\  ... \\ Address line
%         \And  ... \And
%         Author n \\ Address line \\ ... \\ Address line}
% To start a separate ``row'' of authors use \AND, as in
% \author{Author 1 \\ Address line \\  ... \\ Address line
%         \AND
%         Author 2 \\ Address line \\ ... \\ Address line \And
%         Author 3 \\ Address line \\ ... \\ Address line}

\author{
    Nikta Gohari Sadr\textnormal{,} 
    Sangmitra Madhusudan\textnormal{, and} 
    Ali Emami\\
    Brock University, Saint Catharines, Canada \\
    \texttt{\{zu22of, sm20pd, aemami\}@brocku.ca} \\
}

%\author{
%  \textbf{First Author\textsuperscript{1}},
%  \textbf{Second Author\textsuperscript{1,2}},
%  \textbf{Third T. Author\textsuperscript{1}},
%  \textbf{Fourth Author\textsuperscript{1}},
%\\
%  \textbf{Fifth Author\textsuperscript{1,2}},
%  \textbf{Sixth Author\textsuperscript{1}},
%  \textbf{Seventh Author\textsuperscript{1}},
%  \textbf{Eighth Author \textsuperscript{1,2,3,4}},
%\\
%  \textbf{Ninth Author\textsuperscript{1}},
%  \textbf{Tenth Author\textsuperscript{1}},
%  \textbf{Eleventh E. Author\textsuperscript{1,2,3,4,5}},
%  \textbf{Twelfth Author\textsuperscript{1}},
%\\
%  \textbf{Thirteenth Author\textsuperscript{3}},
%  \textbf{Fourteenth F. Author\textsuperscript{2,4}},
%  \textbf{Fifteenth Author\textsuperscript{1}},
%  \textbf{Sixteenth Author\textsuperscript{1}},
%\\
%  \textbf{Seventeenth S. Author\textsuperscript{4,5}},
%  \textbf{Eighteenth Author\textsuperscript{3,4}},
%  \textbf{Nineteenth N. Author\textsuperscript{2,5}},
%  \textbf{Twentieth Author\textsuperscript{1}}
%\\
%\\
%  \textsuperscript{1}Affiliation 1,
%  \textsuperscript{2}Affiliation 2,
%  \textsuperscript{3}Affiliation 3,
%  \textsuperscript{4}Affiliation 4,
%  \textsuperscript{5}Affiliation 5
%\\
%  \small{
%    \textbf{Correspondence:} \href{mailto:email@domain}{email@domain}
%  }
%}
\begin{document}

\maketitle
\begin{abstract}
\looseness=-1 Zero-shot prompting techniques have significantly improved the performance of Large Language Models (LLMs). However, we lack a clear understanding of why zero-shot prompts are so effective. For example, in the prompt ``Let's think step-by-step,'' is \textit{think} or \textit{step-by-step} more crucial to its success? Existing interpretability methods, such as gradient-based and attention-based approaches, are computationally intensive and restricted to open-source models. We introduce the ZIP score (Zero-shot Importance of Perturbation score), a versatile metric applicable to both open and closed-source models, based on systematic input word perturbations. Our experiments across four flagship models, seven widely-used prompts, and several tasks reveal that: (1) word importance varies significantly by task type, with mathematical tasks prioritizing structured instruction words; (2) proprietary models align more closely with human judgments than open-source ones; (3) nouns consistently show the highest importance (47.4\%--65.9\%); and (4) ZIP scores inversely correlate with model performance (|r| > 0.9), indicating stronger prompt effects on challenging tasks. These findings enhance our understanding of LLM behavior and contribute to developing more effective zero-shot prompts and improved model analysis.\footnote{The complete codebase and documentation of language model interactions will be publicly available upon publication.}


\end{abstract}

\section{Introduction}

\begin{figure*}[!ht]
  \centering
  \includegraphics[width=0.83\textwidth]{Images/Final_main_fig.png}
    \vspace{-3mm}
  \caption{ZIP score generation process for the Chain-of-Thought prompt using GPT-4o mini on a AQUA-RAT dataset instance. Perturbed prompts are compared to the original, generating word-level ZIP scores. The red box highlights ``step-by-step'' as significantly important based on statistical analysis.}
  \label{fig:Process}
  \vspace{-4mm}
\end{figure*}

 
Prompting techniques have revolutionized how we use Large Language Models (LLMs), significantly improving their performance across various tasks. From Chain-of-Thought (CoT) \cite{wei2022chain} to Self-Consistency \cite{wang2023selfconsistency} and Least-to-Most prompting \cite{zhou2022least}, these methods have expanded LLM capabilities. Zero-shot prompts, which guide models without task-specific training examples, have emerged as particularly effective and practical, offering broad generalization and multi-task abilities \cite{kojima2022large}. However, despite their success, we lack a clear understanding of why these prompts are so effective, particularly at the level of individual words. 

Consider the following example:

\begin{example}
\textbf{Problem:} Alice has 5 apples. She gives 2 to Bob and 1 to Charlie. How many apples does Alice have left?

\textbf{Zero-shot CoT: \uline{Let's think step-by-step.}}

\textbf{Model Output:}
\begin{enumerate}
    \item Alice starts with 5 apples.
    \item She gives away 2 + 1 = 3 apples.
    \item Apples left = 5 - 3 = 2
\end{enumerate}

\textbf{Answer:} Alice has 2 apples left.
\end{example}

Despite the success of such zero-shot prompting techniques, a gap in our understanding remains: What is it about these prompts that is so effective, particularly at the level of individual words? In the above prompt, which term has more influence on the model output: `think' or `step-by-step'?

Current methods for interpreting input word significance in LLMs typically rely on gradients \cite{wallace-etal-2019-allennlp, yin2022interpreting, ferrando-etal-2023-explaining, wu2023analyzing} or attention mechanisms \cite{modarressi2022globenc, tenney2020language, ferrando-etal-2022-measuring}. However, these methods require access to internal model parameters and face reliability issues \cite{wang2020gradient, jain-wallace-2019-attention, ethayarajh-jurafsky-2021-attention, 10.1145/3639372,bastings-filippova-2020-elephant}.

Following established work \cite{choudhary2022interpretation, SALEEM2022165, feng-etal-2018-pathologies}, we define \textbf{word importance} as \textit{the degree to which a word's presence, absence, or modification impacts model performance on a given task}. This definition captures both semantic and structural importance through systematic perturbations: a word is considered important if replacing it with semantically similar alternatives (synonyms), related concepts (co-hyponyms), or removing it altogether significantly affects the model's output.

Our paper introduces the ZIP score (Zero-shot Importance of Perturbation score), a novel metric for assessing word importance in zero-shot instructional prompts that works with both open and closed-source models. Figure \ref{fig:Process} provides an overview of the methodology. Our approach is validated through controlled experiments, statistical analyses, and is compared with human judgment across seven zero-shot prompts, four LLMs, and several classification and translation tasks. 

Our key findings reveal that: \textbf{(1)} Word importance varies significantly by task type (e.g., "step-by-step" for mathematical tasks vs. "think" for reasoning tasks); \textbf{(2)} Proprietary models like GPT-4o mini align more closely with human judgments of word importance than open-source models; \textbf{(3)} Nouns consistently show the highest importance (47.4\%--65.9\% of significant words) across all models; and \textbf{(4)} ZIP scores inversely correlate with model performance (|r| > 0.9), indicating that prompts have a
greater impact on challenging tasks.

\section{Related Work}
Feature importance interpretation in language models is typically approached through three main methods: gradient-based, attention-based, and perturbation-based \cite{choudhary2022interpretation}.

\textbf{Gradient-Based Methods} identify influential features by calculating the gradient of the output logits with respect to input elements \cite{wallace-etal-2019-allennlp}. Recent advances include gradient-based post hoc contrastive explanations for model predictions \cite{yin2022interpreting,ferrando-etal-2023-explaining} and analyses of how CoT prompting affects saliency scores \cite{wu2023analyzing}. However, these methods face significant limitations: they require access to model internals, making them inapplicable to closed-source models. Furthermore, research has shown that model gradients can be easily manipulated, raising concerns about the reliability of gradient-based analyzes \cite{wang2020gradient}.

\textbf{Attention-Based Methods} interpret feature importance by analyzing the weighted sum of intermediate representations in neural networks \cite{modarressi2022globenc, tenney2020language, ferrando-etal-2022-measuring}. While intuitive, these approaches have several drawbacks. For one, the attention weights do not always correspond to the most important features for model predictions \cite{jain-wallace-2019-attention} and may not correlate well with other feature importance measures \cite{ethayarajh-jurafsky-2021-attention}. Moreover, attention weights often contain redundant and mixed information, leading to unreliable explanations \cite{bastings-filippova-2020-elephant}. Like gradient-based methods, these approaches also require access to model internals, limiting their applicability to open-source models.

\textbf{Perturbation-Based Methods} can analyze any LLM regardless of architecture accessibility by measuring how outputs change when inputs are modified. As \cite{choudhary2022interpretation} describes, ``a word (token) or a collection of words (tokens) are modified or removed from the input samples, and a resulting change is measured.''

Notable approaches include LIME \cite{ribeiro2016should}, which creates local linear approximations of model behavior, and other dataset instance perturbations \cite{zafar2019dlime}. Recent research has extended these methods to few-shot demonstrations \cite{liu2023towards} and system prompts \cite{hackmann2024word, yin2023did}.

Despite these advancements, there remains a significant gap in the interpretation of zero-shot instructional prompts. Current research often uses basic token masking, which may oversimplify prompt semantics. It can also result in incoherent perturbations, potentially failing to interpret the true impact of the word on model predictions \cite{yin2023did,feng-etal-2018-pathologies}. Our research addresses this by introducing a new metric that employs a variety of meaningful perturbations to reveal the importance of each word in zero-shot instructional prompts. 

%This approach not only extends existing perturbation-based methods but also overcomes the constraints of other techniques by enabling the analysis of both open and closed-source models without requiring access to internal parameters.


\section{The ZIP score}

The ZIP score quantifies the importance of individual words in a prompt by measuring how much the model's performance changes when that word is perturbed or removed. This method allows us to systematically identify which words are most crucial for the model's performance on a given task.

\subsection{Formalization of the ZIP score}

We formalize the ZIP score through the following steps, using a running example:

\vspace{1mm}

 \textbf{Example Task ($T$):} Determine whether a number is prime or composite.
 
\vspace{1mm}

 \textbf{Original Prompt ($P$):} ``Take a deep breath and work on this problem step-by-step'' \cite{luo2024taking}

\vspace{1mm}

\textbf{Step 1: Prompt Representation}

Let \(P\) represent the original prompt, where \(P = w_1, w_2, \dots, w_n\) and \(w_i\) denotes the \(i\)-th word.\footnote{Throughout this paper, we use ``word'' to refer to any token resulting from our space-based tokenization method. This may include contractions, compound words, or multi-word expressions.}
\vspace{2mm}

\textbf{Example:}
\vspace{-1mm}
\[P = \left[ \text{``Take'', ``a'', ``deep'', ``breath'', ``and'',} \right.\]
\vspace{-6.5mm}
\[\left. \text{``work'', ``on'', ``this'', ``problem'', ``step-by-step''} \right]\]

\begin{figure}[!t]
  \centering
  \includegraphics[width=0.5\textwidth]{Images/Copy_of_REVEISION_NIKTA_6.png}

  \caption{Perturbation generation and filtering process for a sample prompt}
  \label{fig:Creating_Perturbations}
\end{figure}


\textbf{Step 2: Perturbation Generation}

For each word \(w_i\) in \(P\), we generate a set of perturbations \(\{P_{i1}, P_{i2}, \dots, P_{ik}\}\), through context-aware synonym replacement and co-hyponym replacement using GPT-4\footnote{GPT-4 consistently outperformed traditional tools like NLTK \cite{bird2009natural} in generating contextually appropriate alternatives in our preliminary tests.}, and word removal. Synonyms provide similar meanings, co-hyponyms\footnote{A co-hyponym is a word that shares the same category or group with another word, but both are specific examples of a broader term (hypernym).} introduce related concepts, and removal tests word necessity. Each \(P_{ij}\) represents a modified version of \(P\) where \(w_i\) has been replaced or omitted.

\textbf{Example:} For \(w_4 = \text{``breath''}\):
\begin{itemize}
    \item \(P_{41} = \text{``Take a deep pause and work on ...''}\)
    \item \(P_{42} = \text{``Take a deep glimpse and work on ...''}\)
    \item \(P_{43} = \text{``Take a deep look and work on  ...''}\)
\end{itemize}

Aligned with existing literature on perturbation-based methods \cite{choudhary2022interpretation, IVANOVS2021228, SALEEM2022165}, we posit that a word’s importance is indicated by the model’s performance shifts in response to any meaningful alteration of that word, whether through subtle meaningful shifts or its complete removal. (see \S\ref{sec:proofofthepudding} for analyses and demonstrations of this phenomenon).




%We use GPT-4 \cite{achiam2023gpt} for generating context-aware synonyms and co-hyponyms, solely for single-word perturbation generation.\footnote{GPT-4 consistently outperformed traditional tools like NLTK \cite{bird2009natural} in generating contextually appropriate alternatives in our preliminary tests.}


To create a final set of perturbations that provides meaningful insight into the impact of each word on the model output, as depicted in Figure \ref{fig:Creating_Perturbations}, we filter the perturbed sentences as follows:



\begin{enumerate}[itemsep=0pt, leftmargin=*]
\item The Universal Sentence Encoder \cite{cer2018universal} to measure semantic similarity between $P$ and $P_{ij}$, keeping those with >30\% similarity.\footnote{This threshold was chosen to balance maintaining context while allowing meaningful alterations (see table \ref{emperical_test} in \ref{sec:pert_ap}).}

\item GPT-4 evaluation to assess grammatical correctness and semantic viability of each $P_{ij}$.%\footnote{In preliminary experiments, we manually verified that GPT-4 performed this task with near-perfect precision and recall in assessing meaningful perturbations.}
\end{enumerate} 
%This process, depicted in Figure \ref{fig:Creating_Perturbations}, aims to produce a final perturbation set that offers meaningful insights into each word's impact on model outputs.


Determined by our filtering process, \(P_{42}\) is excluded due to its insufficient semantic similarity and grammatical inconsistencies. Consequently, the final set of perturbations includes \(P_{41}\) and \(P_{43}\).

We maintained cost-effectiveness in using large language models by optimizing token usage and the output format, reducing the tokens needed for perturbation generation and selection. Additionally, our primary filter, using Universal Sentence Encoder, discards unrelated perturbations, thereby minimizing unnecessary API calls for grammatical verification\footnote{For the CoT prompt, the entire perturbation generation and grammatical verification process uses fewer than 2150 input/output tokens, effectively balancing cost and quality.}.
Across the seven instructional prompts, this filtering process resulted in an average of 9.04 perturbed sentences per word. Detailed prompts and examples for perturbation creation and evaluation are provided in Appendix Sections \ref{sec:template_ap} and \ref{sec:pert_ap}.



\textbf{Step 3: Model Prediction}

We input the original prompt \(P\) and each of its validated perturbed variants \(P_{ij}\) into the language model \(M\) to address an instance of task \(T\) which we refer to as \(t\).

\textbf{Example ($t$):} Is 29 prime or composite?
\begin{align*}
\text{pred}_t^M(P) &= \text{``Prime''} \quad \text{(Correct)} \\
\text{pred}_t^M(P_{41}) &= \text{``Prime''} \quad \text{(Correct)} \\
\text{pred}_t^M(P_{43}) &= \text{``Composite''} \quad \text{(Incorrect)}
\end{align*}

\textbf{Step 4: Disagreement Calculation}

We define a disagreement function \(d\) that measures the difference between the model predictions for each perturbed prompt (\(P_{ij}\)) and the original prompt (\(P\)). This function varies according to the type of task \(T\). For instance \(t\) of classification tasks:
\[
d_t^M(P, P_{ij}) = 
\begin{cases} 
1 & \text{if } \text{pred}_t^M(P) \neq \text{pred}_t^M(P_{ij}) \\
0 & \text{otherwise}
\end{cases}
\]

 \textbf{Example:}
\begin{align*}
d_t^M(P, P_{41}) &= 0 \quad \text{(No disagreement)} \\
d_t^M(P, P_{43}) &= 1 \quad \text{(Disagreement)}
\end{align*}

For an instance \(t\) of translation tasks:
\[
d_t^M(P, P_{ij}) = |\text{BLEU}_t^M(P) - \text{BLEU}_t^M(P_{ij})|
\]

Here $\text{BLEU}_t^M(P)$ and $\text{BLEU}_t^M(P_{ij})$ are the BLEU scores \cite{papineni2002bleu} for translations generated from the original and perturbed prompts, respectively.

\textbf{Translation Example:} For the task of translating ``The cat is on the mat'' to French, assume:

$\text{BLEU}_t^M(P) = 0.85$, 

$\text{BLEU}_t^M(P_{41}) = 0.83$,

$\text{BLEU}_t^M(P_{43}) = 0.72$

\noindent $d_t^M(P, P_{41}) = |0.85 - 0.83| = 0.02$, 
$d_t^M(P, P_{43}) = |0.85 - 0.72| = 0.13$

\vspace{2mm}
\textbf{Step 5: ZIP score Calculation}
Finally, for each word $w_i$, we compute the ZIP score $\text{ZIP}_T^M(w_i)$ by averaging disagreement scores across all perturbations of $w_i$ and all dataset instances:

\[
\text{ZIP}_T^M(w_i) = 100 \cdot \frac{1}{N} \sum_{t=1}^{N} \left(\frac{1}{k} \sum_{j=1}^{k} d_t^M(P_i, P_{ij})\right)
\]

Where $N$ is the number of dataset instances, $k$ is the number of valid perturbations 
%(see Sec. \ref{sec:pertgen}) 
for each word, $P_i$ is the original prompt for the $i$-th dataset instance, and $P_{ij}$ is the $j$-th perturbation of word $w_i$ in the $t$-th dataset instance.%\footnote{Due to the linearity of expectation, the order of averaging across datasets and perturbations can be interchanged without affecting the final ZIP score.}

\noindent \textbf{Example:} For $w_4 = \text{``breath''}$ in a single dataset instance ($t=1$):

\noindent $\text{ZIP}_{Classif.}^M (\text{``breath''}) = 100 \cdot \frac{1}{2}(0 + 1) = 50$

\noindent $\text{ZIP}_{Transl.}^M (\text{``breath''}) = 100 \cdot \frac{1}{2}(0.02 + 0.13) = 7.5$

The ZIP score ($\in [0,100]$)\footnote{The 100x scaling factor normalizes ZIP scores to a 0-100 range for easier interpretation and comparison across tasks.} represents the average percentage change in model performance observed across all tested dataset instances when perturbing a given word.\footnote{For simplicity, we show the process for one word in a dataset instance; in practice, this repeats for all prompt words, averaging ZIP scores across instances.} This metric is adaptable to various performance measures, making it versatile for different types of tasks. Interpreting the ZIP score is straightforward: a higher score indicates greater word importance, as perturbing it leads to larger changes in model output. Conversely, a lower score suggests the word has less impact on performance for the given task.

%These examples demonstrate the ZIP score's ability to quantify the overall importance of the word ``breath'' in the prompt across different perturbations and tasks.  This single metric encapsulates the word's importance such that any alteration—whether replacement or removal—could potentially affect the model's performance, with the magnitude of the ZIP score indicating the degree of this potential impact.\footnote{For brevity, we've only shown the process for one word in a single dataset instance. In practice, this would be repeated for all words in the prompt, and the ZIP score is averaged across all dataset instances.}






%\subsection{Perturbation Generation Process}
%\label{sec:pertgen}
%To assess the importance of each word $w_i$ in prompt $P$, we generate a set of perturbations $\{P_{i1}, P_{i2}, ..., P_{ik}\}$ through three methods: synonym replacement, co-hyponym replacement, and word removal. Synonyms provide similar meanings, co-hyponyms introduce related concepts, and removal tests word necessity.  We posit that a word's importance is reflected in the model's sensitivity to any change in that word, whether a subtle shift in meaning or a complete removal (see Sec.  \ref{sec:proofofthepudding} for examples of this phenomenon). 


%\begin{figure}[!t]
%  \centering
  %\includegraphics[width=0.5\textwidth]{Images/pert_process_fig.png}

%  \caption{Perturbation generation and filtering process for a sample prompt}
  %\label{fig:Creating_Perturbations}
%\end{figure}

%We use GPT-4 \cite{achiam2023gpt} for generating context-aware synonyms and co-hyponyms, solely for single-word perturbation generation.\footnote{GPT-4 consistently outperformed traditional tools like NLTK \cite{bird2009natural} in generating contextually appropriate alternatives in our preliminary tests.}.

%We filter the perturbed sentences as follows:

%\begin{enumerate}[itemsep=0pt, leftmargin=*]
%\item The Universal Sentence Encoder \cite{cer2018universal} to measure semantic similarity between $P$ and $P_{ij}$, keeping those with >30\% similarity.\footnote{This threshold was chosen empirically to balance maintaining context while allowing meaningful alterations.}

%\item GPT-4 evaluation to assess grammatical correctness and semantic viability of each $P_{ij}$.%\footnote{In preliminary experiments, we manually verified that GPT-4 performed this task with near-perfect precision and recall in assessing meaningful perturbations.}
%\end{enumerate}

%This process, depicted in Figure \ref{fig:Creating_Perturbations}, aims to produce a final perturbation set that offers meaningful insights into each word's impact on model outputs. Across all seven instructional prompts studied, this filtering process resulted in an average of 9.04 perturbed sentences per word. Detailed prompts and examples for perturbation creation and evaluation are provided in Appendix Sections \ref{sec:template_ap} and \ref{sec:pert_ap}.

% Please add the following required packages to your document preamble:
% \usepackage{booktabs}



\subsection{Identifying Significantly Important Words}

To determine which words are significantly important in prompts, we use a statistical approach that distinguishes between the inherent variability in model outputs and the effects of our perturbations:
\begin{enumerate}[itemsep=0pt, leftmargin=*]
\item For each word in the prompt, we generate a set of perturbed prompts (the same set used in the ZIP score calculation).

\item We repeatedly input both the original prompt and each of its perturbed versions to the model, generating multiple outputs for each. The number of times we re-prompt with the original prompt matches the number of perturbations for that word, ensuring a balanced comparison.

\item We compare the ZIP scores from the original \textit{re}-prompts with those from each perturbed prompt using the Wilcoxon rank-sum test.
\end{enumerate}

\noindent The Wilcoxon rank-sum test evaluates whether two independent samples (i.e., the outputs from the original re-prompts and a perturbed prompt) come from the same distribution. Words yielding a p-value < 0.05 are considered `significantly important'. %We use a temperature of 0.5 for all prompts to balance determinism and variability in model responses.%\footnote{Setting temperature to 0 didn't eliminate output variations, a known issue with models like GPT-4.} %This approach allows us to distinguish between changes in model output caused by perturbations and those resulting from the model's inherent variability. %By doing so, we can confidently identify words whose perturbations consistently and significantly affect model performance.





\section{Controlled Pre-Experiment}

Despite the success of zero-shot prompts, establishing a ground truth for word-level importance within them is challenging because we may not know which words \textit{should} matter most. To address this, we created a set of 20 simple zero-shot instructional \textit{validation prompts}, each designed so that a single predetermined `key word' determines the correct output. For example, consider the prompt \textit{“Say the word green”}. Here, ``green'' is the key word: if the model does not produce ``green'' exactly, it fails. By knowing in advance which word is crucial for a correct output, we can objectively assess the effectiveness of interpretability methods.

\textbf{Prompt Design and Methodologies}: 
We constructed 20 validation prompts (Table~\ref{tab:Control_Prompt_4omini}) with varied syntax and structure, such as \textit{``Print the digits \textbf{123}''}, \textit{``Type the letter \textbf{X}''}, and \textit{``Print \textbf{carrot} with no additional text''}. Each prompt contains a key word that directly determines the correct output - any alteration to this word should change the model's response. For example, in ``Print the digits 123'', only perturbations to ``123'' should affect whether the model outputs ``123'' correctly. Table \ref{tab:validations_output} (\ref{sec:control_prompt_ap}) confirms these prompts isolate the key word's influence on GPT-4o mini's output.

We evaluate both our ZIP method and LIME \cite{ribeiro2016should}, a widely-used perturbation-based explanation method, on this validation set. For ZIP, we apply our standard perturbation techniques to each validation prompt, measuring output changes using our disagreement function ($d=1$ for incorrect outputs, $d=0$ for correct ones). Unlike ZIP's diverse perturbation approach, LIME relies solely on random word removal to estimate importance through linear modeling. Implementation details for LIME are provided in \S\ref{sec:exp_setup}.

\textbf{Validation Criteria}: We consider an interpretability method successful if it consistently identifies the known key word as the most important term. For each prompt, a method scores correctly if it assigns the highest importance to the key word, and its accuracy is calculated as the percentage of prompts in which it succeeds. This provides a quantitative measure of the reliability of each method in identifying crucial prompt words.









\section{Experimental Setup}
\label{sec:exp_setup}

\paragraph{Prompts}

We evaluated seven zero-shot instructional prompts across various datasets, as detailed in Table \ref{tab:Prompt_datasets}. These prompts were selected based on their proven effectiveness and generalization capabilities in recent literature.  We used a simple space-based tokenization method, where tokens are defined as sequences of characters separated by whitespace.\footnote{This approach preserves contractions and compound words (e.g., ``Let's'' as one token), which are often semantically important in instructional prompts.} Dataset-specific prompts are included in the Appendix \ref{sec:template_ap} (Table \ref{tab:task_prompt}).


\begin{table*}[t]
\centering
\small
\begin{tabular}{@{}c p{6.2cm} l@{}}
\toprule
\textbf{Code} & \textbf{Prompt} & \textbf{Dataset} \\ 
\midrule
0-CoT & Let's think step-by-step. \cite{10.5555/3600270.3601883} & MultiArith, \textbf{GSM8K}, \textbf{AQUA-RAT}, SVAMP, \textbf{BIG-bench}, etc. \\ 
0-CoTB & Take a deep breath and work on this problem step-by-step. \cite{yang2024largelanguagemodelsoptimizers} & MultiArith, \textbf{GSM8K}, \textbf{AQUA-RAT}, BBH \\ 
0-CoTR & Let’s work this out in a step-by-step way to be sure we have the right answer. \cite{zhou2023largelanguagemodelshumanlevel} & MultiArith, \textbf{GSM8K}, \textbf{BIG-bench}, etc. \\ 
0-IRR & Feel free to ignore irrelevant information in the problem description. \cite{shi2023largelanguagemodelseasily} & GSM-IC, \textbf{GSM8k} \\ 
0-PS & Let’s first understand the problem and devise a plan to solve it. Then, solve it step-by-step. \newline (`` Plan \& Solve'') \cite{wang2023planandsolvepromptingimprovingzeroshot} & MultiArith, \textbf{GSM8K}, \textbf{AQUA-RAT}, AddSub, SingleEq, etc. \\ 
0-DSP & Provide the translation step-by-step, then complete the sentence. (``Domain Specific Prompting'') \cite{peng2023makingchatgptmachinetranslation} & WMT22, \textbf{WMT19} \textbf{(German and Chinese)} \\ 
0-DTG & Detect the error type first, then refine the translation. (``Deliberate then Generate'' \cite{li2023deliberategenerateenhancedprompting} & \textbf{WMT}, etc. (German, Czech, Chinese, etc) \\ 
\bottomrule
\end{tabular}
\vspace{-2mm}
\caption{Overview of the zero-shot instructional prompts used in our experiments, alongside the datasets they were tested on. Datasets highlighted in bold indicate specific use for our study.}
\label{tab:Prompt_datasets}
\end{table*}


\paragraph{Datasets}
We selected a diverse range of datasets known for effectively testing zero-shot prompts, as highlighted in bold in Table \ref{tab:Prompt_datasets}. For classification tasks, datasets included GSM8K \cite{cobbe2021trainingverifierssolvemath}, AQUA-RAT \cite{ling2017programinductionrationalegeneration}, and the Big Bench dataset \cite{srivastava2023imitationgamequantifyingextrapolating}. Translation tasks used the WMT19 dataset, concentrating on Chinese and German languages. We evaluated on 150 instances per dataset, which we determined was sufficient to provide statistically significant results while managing computational costs.




\paragraph{Models}
Four models were used in our experiments: GPT-4o mini, GPT-3.5-turbo, Llama-2-70B-chat, and Mixtral-8x7B-Instruct-v0.1 \cite{openai2023gpt4, touvron2023Llama, jiang2024mixtral}. Each model was configured with a temperature of 0.5 to balance between deterministic outputs and allowing for some variability. For token usage estimates per prompt, see Appendix \ref{sec:computation_ap}.




\paragraph{LIME Baseline}
For our validation prompts, we configured LIME to treat the task as binary classification: Label 1 represents the target word (e.g., ``green'' for ``Say the word green''), and Label 2 represents any other output. LIME automatically creates perturbations and fits a linear surrogate model to quantify word importance, using 50 perturbations per instance.  This implementation allows direct comparison with ZIP scores while maintaining LIME's standard approach to interpretability.









\paragraph{Human Evaluation}
We conducted a study with 15 diverse participants proficient in English to compare human and model interpretations of the instructional language. For each prompt, participants selected up to three words that they deemed most important to solve a certain task. The evaluation form is shown in Appendix \ref{sec:human_eval_ap} Fig. \ref{fig:human_eval}. We used the Jaccard Index to measure interannotator agreement across participants, yielding an average of 0.4714, indicating moderate agreement.\footnote{Jaccard Index was chosen over Fleiss' Kappa to accommodate multiple word selections per participant.}






\section{Results}

\subsection{Does the ZIP score accurately identify known important words?}

Table \ref{tab:Control_Prompt_4omini} compares how ZIP and LIME performed in identifying key words on our 20 validation prompts on GPT-4o mini. ZIP correctly identified the predetermined key word in 90\% of prompts, significantly outperforming LIME's 60\% accuracy. LIME's errors often involved misidentifying contextual words (e.g., ``Print,'' ``Output,'' ``Say") as most important, while ZIP maintained focus on the target words that directly determine the output.

ZIP's strong performance was consistent across all four models (e.g., with 100\% accuracy on GPT-3.5-turbo), validating ZIP's effectiveness in identifying significant words in instructional prompts. Detailed results are provided in Appendix \ref{sec:control_prompt_ap}.



\begin{table}[t]
\centering
\footnotesize
\begin{tabular}{@{}>{\raggedright\arraybackslash}p{0.74\columnwidth}>{\centering\arraybackslash}p{0.1\columnwidth}>{\centering\arraybackslash}p{0.1\columnwidth}@{}}
\toprule
Validation Prompts & ZIP & LIME \\ 
\midrule
Say the word \textbf{green} & Green & Green \\
Print the digits \textbf{123} & 123 & \textcolor{red}{Print} \\
Output the color \textbf{blue} & Blue & \textcolor{red}{Output} \\
Print \textbf{carrot} with no additional text & \textcolor{red}{Print} & Carrot \\
Display the word \textbf{circle} & Circle & Circle \\
When you're ready just say \textbf{coffee} & Coffee & Coffee \\
Return the value \textbf{five} & Five & Five \\
Respond with only the word \textbf{hello} & Hello & Hello \\
Repeat the term \textbf{mirror} & Mirror & \textcolor{red}{Repeat} \\
\textbf{Nine} is the number you should write & Nine & Nine \\
Answer with the word \textbf{pizza} & Pizza & \textcolor{red}{With} \\
Begin by writing \textbf{hello} and then finish & Hello & Hello \\
Type \textbf{purple} in your response now & Purple & Purple \\
Say \textbf{red} and then stop & Red & \textcolor{red}{Say} \\
When you respond lead with \textbf{river} & River & River \\
Write the number \textbf{seven} & Seven & \textcolor{red}{Number} \\
Carefully type \textbf{silver} when responding here & Silver & Silver \\
Enter the word \textbf{tomato} & Tomato & \textcolor{red}{The} \\
Can you mention the direction \textbf{up} in our chat? & \textcolor{red}{Direction} & \textcolor{red}{Chat} \\
Type the letter \textbf{X} & X & X \\
\midrule
\textbf{Accuracy} & \textbf{90\%} & \textbf{60\%} \\
\bottomrule
\end{tabular}
\caption{Most important words as identified by ZIP and LIME for GPT-4o mini on validation prompts. Red indicates failure to identify the correct key word.}
\label{tab:Control_Prompt_4omini}
\end{table}



\subsection{How do ZIP scores vary across models for the CoT prompt?}

Table  
   \ref{tab:CoT_Heatmap_BB} presents ZIP score heatmaps for the CoT prompt ``Let's Think Step-by-Step'' across models on Big Bench. Our analysis reveals:
\begin{itemize}[itemsep=0pt, leftmargin=*]
      \item \textbf{``Step-by-Step'' vs ``Think'':} While both words are important, \textbf{step-by-step} shows, on average, a higher ZIP score across models. This suggests that the explicit instruction for a structured approach (``step-by-step'') may be more universally interpreted and utilized by models than the more general cognitive instruction (``think'').
\item \textbf{Proprietary vs Open-source models:} Proprietary models (GPT-4o mini, GPT-3.5-turbo) identify fewer words as significantly important (1 word) compared to open-source models (Mixtral, Llama 2, with 2-3 words). This suggests that proprietary models may be more selective in sensitivity to word perturbations, while open-source models appear to be sensitive to a wider range. %This could reflect differences in training approaches or model architectures in proprietary and open-source models.
\end{itemize}

  \noindent  Results on all datasets are provided in Appendix \ref{sec:cot_heatmap_ap} Table \ref{tab:CoT_Heatmaps_Comparison}.
  
\begin{table}[t]
\centering
\resizebox{\columnwidth}{!}{
\begin{tabular}{@{}lc@{}} % 'l' for left-aligned text, 'c' for centered images
\toprule
GPT-4o mini  & \adjustbox{valign=m, margin=0.7ex 0.7ex 0.7ex 0.7ex}{\includegraphics[width=0.33\textwidth]{Images/cot_heatmap_gpt4_bigbench.png}}\\
GPT 3.5 Turbo & \adjustbox{valign=m, margin=0.7ex 0.7ex 0.7ex 0.7ex}{\includegraphics[width=0.33\textwidth]{Images/cot_heatmap_gpt35_bigbench.png}}\\
Mixtral       & \adjustbox{valign=m, margin=0.7ex 0.7ex 0.7ex 0.7ex}{\includegraphics[width=0.33\textwidth]{Images/cot_heatmap_mixtral_bigbench.png}}\\
Llama 2       & \adjustbox{valign=m, margin=0.7ex 0.7ex 0.7ex 0.7ex}{\includegraphics[width=0.33\textwidth]{Images/cot_heatmap_Llama2_bigbench.png}}\\
\bottomrule
\end{tabular}
}
\vspace{-2mm}
\caption{ZIP score heatmaps for the CoT prompt across four models on the Big Bench dataset. Red boxes indicate significantly important words.}
\label{tab:CoT_Heatmap_BB}
\end{table}





\subsection{How does word importance vary across different prompts and task types?}





\begin{table*}[t]
\centering
\footnotesize % Using smaller font to save space
\setlength{\tabcolsep}{3pt} % Reduce padding between columns

\begin{minipage}[t]{0.39\textwidth} % Slightly reduce width to ensure no overlap
\subfloat[Classification Tasks]{
\label{subtab:classification_tasks}
\begin{tabular}{@{}lcccccc@{}}
\toprule
& \multicolumn{2}{c}{AQUA-RAT} & \multicolumn{2}{c}{Big Bench} & \multicolumn{2}{c}{GSM8K} \\ 
\cmidrule(lr){2-3} \cmidrule(lr){4-5} \cmidrule(lr){6-7}
& Top 3 MSWs & ZIP & Top 3 MSWs & ZIP & Top 3 MSWs & ZIP \\ 
\midrule
0-CoT  & \textbf{Step-by-step} & \textbf{28.44} & \textbf{Think}       & \textbf{3.80} & \textbf{Step-by-step} & \textbf{5.83} \\
0-CoTB & \textbf{Step-by-step} & \textbf{34.49} & \textbf{Problem}     & \textbf{1.95} & \textbf{Step-by-step} & \textbf{6.57} \\
       &                       &                & Work                  & 1.33          &                       &               \\
0-CoTR & \textbf{Answer}       & \textbf{27.66} & \textbf{Right}       & \textbf{4.66} & \textbf{Answer}       & \textbf{5.33} \\
       & Sure                  & 27.61          & Work                  & 4.40          & Step-by-step          & 5.22          \\
       & Right                 & 26.44          & Sure                  & 4.09          & Way                   & 5.21          \\
0-IRR  & \textbf{Description}  & \textbf{30.71} & \textbf{Ignore}      & \textbf{3.87} & \textbf{Irrelevant}   & \textbf{6.51} \\
       & Ignore                & 30.42          & Description           & 3.74          & Description           & 6.41          \\
       & Irrelevant            & 30.30          &                       &               &                       &               \\
0-PS   & \textbf{Plan}         & \textbf{28.50} & \textbf{Plan}        & \textbf{4.05} & \textbf{Step-by-step} & \textbf{7.28} \\
       & Step-by-step          & 28.40          & First                 & 3.94          & Problem               & 6.83          \\
       & Solve                 & 27.72          & Solve                 & 3.72          & Solve                 & 6.54          \\
\bottomrule
\end{tabular}
}
\end{minipage}%
\hfill % Ensures that the gap between tables is filled
\begin{minipage}[t]{0.39\textwidth} % Matching width for the second minipage
\subfloat[Translation Tasks]{
\label{subtab:translation_tasks}
\begin{tabular}{@{}ccccc@{}}
\toprule
& \multicolumn{2}{c}{WMT 19: German} & \multicolumn{2}{c}{WMT 19: Chinese} \\ 
\cmidrule(lr){2-3} \cmidrule(lr){4-5}
& Top 3 MSWs & ZIP & Top 3 MSWs & ZIP \\ 
\midrule
\multicolumn{1}{l}{0-DSP} & \textbf{Translation} & \textbf{10.92} & \textbf{Translation} & \textbf{6.57} \\
& Step-by-step          & 7.68          & Step-by-step          & 5.50          \\
& Sentence              & 6.50          & Sentence              & 5.35          \\
\multicolumn{1}{l}{0-DTG} & \textbf{Refine}      & \textbf{8.43}  & \textbf{Refine}      & \textbf{5.31} \\
& Error                 & 8.33          & Type                  & 4.92          \\
& Detect                & 8.06          & Error                 & 4.92          \\
\bottomrule
\end{tabular}
}
\end{minipage}
\vspace{-2mm}
\caption{Top three most significant words (MSWs) and their ZIP scores for classification and translation tasks on GPT-4o Mini, with the most significant word in \textbf{bold}. All reported words are confirmed as \textit{significantly important}.}
\label{tab:unified_important_words}
\end{table*}

Table \ref{tab:unified_important_words} presents the ZIP score results for various zero-shot instructional prompts (detailed in Table \ref{tab:Prompt_datasets}) using the GPT-4o mini model.  Our analysis demonstrates distinct patterns in the importance of words across various datasets and task types:

\begin{itemize}[itemsep=0pt, leftmargin=*]
{
\item For mathematical and algebraic tasks (AQUA-RAT and GSM8K), the phrase \textbf{step-by-step} consistently emerges as highly important. 

\item In contrast, for \textbf{common sense reasoning tasks} (Big Bench), words like \textbf{think} and \textbf{problem} show higher importance. 

\item For \textbf{translation tasks}, \textbf{translation} and \textbf{refine} are identified as the most important words, which demonstrates the significance of task-specific instructions in multilingual contexts.

\item ZIP scores strongly correlate inversely with model performance (|r| > 0.9) across all prompts. For example, using CoT, GPT-4o mini shows higher ZIP scores on AQUA-RAT (accuracy: 68.26\%, ZIP: 28.44) compared to GSM8K (91.59\%, 5.83) and Big Bench (96.93\%, 3.80) indicating that \textbf{instructional prompts have greater impact on challenging tasks} (Table \ref{tab:corr}).

}
\end{itemize}

  \noindent  Results for other models are provided in Appendix \ref{sec:msw_ap} Tables \ref{tab:Most_Important_GPT35} - \ref{tab:Most_Important_Llama}.

\begin{figure}[t]
    \centering
    \begin{subfigure}[b]{0.2\textwidth}
        \centering
        \includegraphics[width=\linewidth]{Images/pos_gpt4.png}
        \caption{GPT-4o mini}
    \end{subfigure}\hfill
    \begin{subfigure}[b]{0.2\textwidth}
        \centering
        \includegraphics[width=\linewidth]{Images/pos_gpt35.png}
        \caption{GPT-3.5-turbo}
    \end{subfigure}\hfill
    \begin{subfigure}[b]{0.2\textwidth}
        \centering
        \includegraphics[width=\linewidth]{Images/pos_mixtral.png}
        \caption{Mixtral}
    \end{subfigure}\hfill
    \begin{subfigure}[b]{0.2\textwidth}
        \centering
        \includegraphics[width=\linewidth]{Images/pos_Llama.png}
        \caption{Llama 2}
    \end{subfigure}
    \vspace{-1mm}
    \caption{Part-of-Speech (POS) distribution of significantly important words across four LLMs.}
    \label{fig:all_images}
\end{figure}

\subsection{How does the part-of-speech distribution of important words vary across models?}

Figure \ref{fig:all_images} illustrates the part-of-speech (POS) distribution of the most important words for all seven instructional prompts. Key observations are: 

\begin{itemize}[itemsep=0pt, leftmargin=*]
    \item \textbf{Noun dominance:} Nouns (NN) consistently rank as most important across all models (47.4\%--65.9\% of significant words).
    \item \textbf{Model patterns:} GPT-4o mini and GPT-3.5-turbo, sharing similar foundational architectures despite vastly different parameter sizes, show similar POS distributions; Mixtral and Llama 2 show more balanced POS importance.
    \item \textbf{Verb importance:} Base form verbs (VB) consistently rank 2nd in importance across all models.
    \item \textbf{Inter-model variation:} Adverbs (RB) and non-3rd person singular present verbs (VBP) show the highest variation in importance across models.
\end{itemize}



\subsection{How well do model assessments of word importance align with human judgments?}

Figure \ref{fig:human_eval_CoT} presents radar plots comparing human judgments of word importance with model-derived ones for the CoT prompt. Human assessment values  represent the proportion of times each word was selected as important across all evaluators and tasks, while those of models indicate the proportion of times each word was determined as significantly important across all tasks.

Proprietary models (GPT-4o mini and GPT-3.5-turbo) align strongly with human judgments, while open-source models show less alignment, particularly Llama 2. ``Step-by-step'' emerges as highly important across all evaluations, while ``Let's'' is consistently less emphasized. Similar analyses for remaining prompts are provided in Appendix \ref{sec:human_eval_ap} Figures \ref{fig:human_eval_CoT-B} - \ref{fig:human_eval_T2}.



\begin{figure}[t]
    \centering
    \begin{subfigure}[b]{0.23\textwidth}
        \centering
        \includegraphics[width=\linewidth]{Images/CoT-gpt4.png}
        \caption{GPT-4o mini}
    \end{subfigure}\hfill
    \begin{subfigure}[b]{0.23\textwidth}
        \centering
        \includegraphics[width=\linewidth]{Images/CoT-gpt3.png}
        \caption{GPT-3.5-turbo}
    \end{subfigure}\hfill
    \begin{subfigure}[b]{0.23\textwidth}
        \centering
        \includegraphics[width=\linewidth]{Images/CoT-Mixtral.png}
        \caption{Mixtral}
    \end{subfigure}\hfill
    \begin{subfigure}[b]{0.23\textwidth}
        \centering
        \includegraphics[width=\linewidth]{Images/CoT-Llama.png}
        \caption{Llama 2}
    \end{subfigure}
\vspace{-2mm}
    \caption{Comparison of human judgments vs model-derived word importance for the CoT prompt.}
    \label{fig:human_eval_CoT}
\end{figure}

\section{Qualitative Analysis}
\label{sec:proofofthepudding}
We examined how subtle changes alter GPT-4o mini's responses across tasks. In classification tasks, replacing ``irrelevant'' with ``unrelated'' in \textit{``Feel free to ignore irrelevant information''} caused the model to overlook critical textual information, including numbers expressed in word form, leading to computational errors. For \textit{``Take a deep breath and work on this problem step-by-step"}, \textit{removing} ``step-by-step'' surprisingly \textit{improved} the model's accuracy. In translation tasks, replacing ``refine'' with ``enhance'' in \textit{``Please detect the error type, and refine the translation''} degraded translation quality, showing how synonym substitution can significantly affect task performance.

These examples demonstrate that seemingly equivalent words can produce significantly different model outputs. This observation supports our dual approach of using both synonym/co-hyponym substitution as well as word removal to reveal different aspects of how models interpret prompt wording. Details and heatmaps are provided in Appendix \ref{sec:extended_ap} Tables \ref{tab:qualitative_classification} - \ref{tab:Qualitative_Heatmaps_Translation}.

\section{Conclusion}

This study introduces the ZIP score, a novel metric for quantifying word importance in zero-shot instructional prompts. Our findings reveal interesting patterns in word importance across models and tasks. For instance, while both `step-by-step' and `think' show high ZIP scores, which one is more influential depends on the model and task. We observed significant differences in word importance and alignment with human intuition between proprietary and open-source models. These insights aid our understanding of LLM behavior and open new avenues for prompt engineering and model analysis. Future work could explore the use of these findings to design more effective prompts tailored to specific model architectures.

\section*{Limitations}



%At the end of the paper (after the conclusions but before the references) papers need to include a mandatory section discussing the limitations of the work and, optionally, a section discussing ethical considerations.
\textbf{Scope of Perturbation Types}:
Our study strategically employed perturbations involving removals and semantic changes such as synonyms and co-hyponyms to analyze their impact on LLMs. While this approach provided valuable insights, extending the variety of perturbation types could uncover further nuances in language model behavior.

\textbf{Interdependencies Among Prompt Constituents}: This study evaluates the influence of individual words within prompts through isolation-based, a necessary simplification grounded in established practices to assess the independent significance of each word.
However, it does not account for the interdependencies and contextual relationships between words that could collectively influence the output of LLMs. Future research should consider methods that can analyze the joint effects of multiple words, providing deeper insights into the model's processing mechanisms, and improving the reliability of perturbation-based interpretability methods.

\textbf{Model and Task Selection}: This study concentrated on four models with different architectures selected for their capabilities and affordability. Although these models represent a robust cross section of current technologies, expanding this selection could improve the generalizability of our findings. Moreover, while our methods were applied to classification and translation tasks, they have potential for broader applications across different LLM tasks such as summarization or question answering, with only minor adjustments needed for the disagreement function to accommodate different outputs.



\textbf{Sample Size Constraints}:
Our analysis, conducted on a carefully chosen sample of 150 instances from each dataset, was designed to balance depth with computational feasibility. Although this approach yielded statistically significant insights, increasing the sample size could further enhance the robustness and general applicability of our findings, capturing more subtle but potentially revealing perturbation effects.

\textbf{Focus on Enhancing Interpretability}: The primary aim of our research is not to engineer or optimize prompts to enhance the performance of LLMs, but rather to improve the interpretability of LLMs by analyzing existing effective prompting techniques. In future work, there is a valuable opportunity to leverage the insights gained from our interoperability method to craft new prompts explicitly designed to improve model performance.

\textbf{Ethical Considerations in Application of Interpretability Insights}: Although our method offers a deeper understanding of LLM operations, it is important to consider the potential for misuse. Detailed knowledge of how LLMs weigh different prompt elements could potentially be used to tailor content in ways that could manipulate or bias decision-making processes. It is crucial to apply these insights ethically with a commitment to fairness.



% Bibliography entries for the entire Anthology, followed by custom entries
%\bibliography{anthology,custom}
% Custom bibliography entries only
\bibliography{custom}

\newpage
\clearpage
\onecolumn
\appendix
\section{Appendix}
\label{sec:appendix}


\subsection{Chain-of-Thought ZIP score Heatmaps}
\label{sec:cot_heatmap_ap}



%\FloatBarrier 

%\begin{figure*}[!h]
%  \centering
%  \includegraphics[width=0.5\textwidth]{Images/heatmaps_aqua.png}
%  \caption{Heatmaps of the Chain-of-Thought (CoT) prompt (Let's Think step-by-step) across four models using the AQUA-RAT dataset.}
%  \label{fig:CoT_Heatmap_aqua}
%\end{figure*}








%\begin{figure*}[!h]
%  \centering
 % \includegraphics[width=0.5\textwidth]{Images/heatmaps_gsm8k.png}
  %\caption{Heatmaps of the Chain-of-Thought (CoT) prompt (Let's Think step-by-step) across four models using the GSM8K dataset.}
 % \label{fig:CoT_Heatmap_gsm8k}
%\end{figure*}



\begin{table*}[htbp]
\centering
\setlength{\tabcolsep}{3pt} % Reduce padding between columns
\footnotesize % Using smaller font to save space

\subfloat[AQUA-RAT dataset heatmaps]{ % Sub-caption for the first table
\begin{minipage}{0.48\textwidth}
    \centering
    \begin{tabular}{@{}lc@{}}
        \toprule
            GPT-4o mini  & \adjustbox{valign=m, margin=0.7ex 0.7ex 0.7ex 0.7ex}{\includegraphics[width=0.5\textwidth]{Images/cot_heatmap_gpt4_aqua.png}}\\
            GPT 3.5 Turbo & \adjustbox{valign=m, margin=0.7ex 0.7ex 0.7ex 0.7ex}{\includegraphics[width=0.5\textwidth]{Images/cot_heatmap_gpt35_aqua.png}}\\
            Mixtral       & \adjustbox{valign=m, margin=0.7ex 0.7ex 0.7ex 0.7ex}{\includegraphics[width=0.5\textwidth]{Images/cot_heatmap_mixtral_aqua.png}}\\
            Llama 2       & \adjustbox{valign=m, margin=0.7ex 0.7ex 0.7ex 0.7ex}{\includegraphics[width=0.5\textwidth]             {Images/cot_heatmap_Llama_aqua.png}}\\
        \bottomrule
    \end{tabular}
\end{minipage}}%
\hfill % Fills the space between minipages
\subfloat[GSM8K dataset heatmaps]{ % Sub-caption for the second table
\begin{minipage}{0.48\textwidth}
    \centering
    \begin{tabular}{@{}lc@{}}
        \toprule
            GPT-4o mini  & \adjustbox{valign=m, margin=0.7ex 0.7ex 0.7ex 0.7ex}{\includegraphics[width=0.5\textwidth]{Images/cot_heatmap_gpt4_gsm8k.png}}\\
            GPT 3.5 Turbo & \adjustbox{valign=m, margin=0.7ex 0.7ex 0.7ex 0.7ex}{\includegraphics[width=0.5\textwidth]{Images/cot_heatmap_gpt35_gsmk8.png}}\\
            Mixtral       & \adjustbox{valign=m, margin=0.7ex 0.7ex 0.7ex 0.7ex}{\includegraphics[width=0.5\textwidth]{Images/cot_heatmap_mixtral_gsm8k.png}}\\
            Llama 2       & \adjustbox{valign=m, margin=0.7ex 0.7ex 0.7ex 0.7ex}{\includegraphics[width=0.5\textwidth]             {Images/cot_heatmap_Llama_gsm8k.png}}\\
        \bottomrule
    \end{tabular}
\end{minipage}}

\caption{ZIP score heatmaps of the Chain-of-Thought (CoT) prompt across four models using the AQUA-RAT and GSM8K datasets. The tables display the significant word identification performance for each model with different datasets. Red boxes highlight words identified as significantly important, confirmed through statistical analysis.}
\label{tab:CoT_Heatmaps_Comparison}
\end{table*}


%\begin{figure*}[!h]
%  \centering
%  \includegraphics[width=0.9\textwidth]{Images/Pert_Promts.png}
%  \caption{Prompts used for creating perturbations. This task was preceded by a few-shot example set to guide the model in generating contextually relevant synonyms.}
%  \label{fig:prompt_types_pert}
%\end{figure*}

\subsection{Controlled Pre-Experiment}
\label{sec:control_prompt_ap}

\begin{table}[ht]
\centering
\captionsetup{size=small} % Smaller caption for table

\footnotesize % Smaller font size to fit in a single column
\begin{tabular}{@{}>{\raggedright\arraybackslash}p{0.3\columnwidth}cc@{}} % Adjusted for even column spacing
\toprule
Validation Prompts & ZIP & LIME \\ % Column headings
\midrule
Say the word \textbf{green}. & Green  & Green  \\
Print the digits \textbf{123}. & 123 & 123  \\
Output the color \textbf{blue}. & Blue  & \textcolor{red}{Color} \\
Print \textbf{carrot} with no additional text. & Print/Carrot  & Carrot  \\
Display the word \textbf{circle}. & Cricle & \textcolor{red}{Word} \\
When you're ready just say \textbf{coffee}. & Coffee & \textcolor{red}{Say} \\
Return the value \textbf{five}. & Five & \textcolor{red}{Value} \\
Respond with only the word \textbf{hello}. & Hello & \textcolor{red}{The} \\
Repeat the term \textbf{mirror}. & Mirror & Mirror/Repeat \\
\textbf{Nine} is the number you should write. & Nine & Nine \\
Answer with the word \textbf{pizza}. & Word/Pizza & \textcolor{red}{With} \\
Begin by writing \textbf{hello} and then finish. & Hello & Hello \\
Type \textbf{purple} in your response now. & Purple & Purple \\
Say \textbf{red} and then stop. & Red & Red \\
When you respond lead with \textbf{river}. & River & \textcolor{red}{Lead} \\
Write the number \textbf{seven}. & Seven & \textcolor{red}{Number} \\
Carefully type \textbf{silver} when responding here. & Silver & Silver \\
Enter the word \textbf{tomato}. & Word/Tomato & \textcolor{red}{The} \\
Can you mention the direction \textbf{up} in our chat? & Up & Up \\
Type the letter \textbf{X}. & X & X \\
\midrule
\textbf{Accuracy} & \textbf{100\%} & \textbf{55\%} \\ % Styled differently
\bottomrule
\end{tabular}

\caption{Most important words as identified by ZIP and LIME for GPT 3.5 Turbo on validation prompts. Red indicates failure to identify the correct key word.}
\label{tab:Control_Prompt_35}
\end{table}


\begin{table}[ht]
\centering
\captionsetup{size=small} % Smaller caption for table

\footnotesize % Smaller font size to fit in a single column
\begin{tabular}{@{}>{\raggedright\arraybackslash}p{0.3\columnwidth}cc@{}} % Adjusted for even column spacing
\toprule
Validation Prompts & ZIP & LIME \\ % Column headings
\midrule
Say the word \textbf{green}. & Green  & Green  \\
Print the digits \textbf{123}. & 123 & \textcolor{red}{Digits}  \\
Output the color \textbf{blue}. & Color/Blue  & Blue \\
Print \textbf{carrot} with no additional text. & Carrot  &  Carrot  \\
Display the word \textbf{circle}. & Circle & Circle \\
When you're ready just say \textbf{coffee}. & Coffee & Coffee \\
Return the value \textbf{five}. & Five & Five \\
Respond with only the word \textbf{Hello}. & Hello & Hello \\
Repeat the term \textbf{mirror}. & Mirror & \textcolor{red}{Term} \\
\textbf{Nine} is the number you should write. & Nine & Nine \\
Answer with the word \textbf{pizza}. & Pizza & Pizza \\
Begin by writing \textbf{hello} and then finish. & Hello & Hello \\
Type \textbf{purple} in your response now. & Purple & Purple \\
Say \textbf{red} and then stop. & Red & Red \\
When you respond lead with \textbf{river}. & River & \textcolor{red}{Respond} \\
Write the number \textbf{seven}. & Seven & Seven \\
Carefully type \textbf{silver} when responding here. & Silver &  Silver \\
Enter the word \textbf{tomato}. & Tomato & Tomato \\
Can you mention the direction \textbf{up} in our chat? & \textcolor{red}{Direction} & \textcolor{red}{Chat} \\
Type the letter \textbf{X}. & X & X \\
\midrule
\textbf{Accuracy} & \textbf{95\%} & \textbf{80\%} \\ % Styled differently
\bottomrule
\end{tabular}

\caption{Most important words as identified by ZIP and LIME for Mixtral on validation prompts. Red indicates failure to identify the correct key word.}
\label{tab:Control_Prompt_mixtral}
\end{table}



\begin{table}[ht]
\centering
\captionsetup{size=small} % Smaller caption for table

\footnotesize % Smaller font size to fit in a single column
\begin{tabular}{@{}>{\raggedright\arraybackslash}p{0.3\columnwidth}cc@{}} % Adjusted for even column spacing
\toprule
Validation Prompts & ZIP & LIME \\ % Column headings
\midrule
Say the word \textbf{green}. & Green  & Green  \\
Print the digits \textbf{123}. & Print/Digits/123 & \textcolor{red}{Digits}  \\
Output the color \textbf{blue}. & Blue  & Blue \\
Print \textbf{carrot} with no additional text. & Carrot  &  \textcolor{red}{No}  \\
Display the word \textbf{circle}. & Circle & \textcolor{red}{Display} \\
When you're ready just say \textbf{coffee}. & Coffee & \textcolor{red}{Say} \\
Return the value \textbf{five}. & Five & \textcolor{red}{Value} \\
Respond with only the word \textbf{Hello}. & Hello & Hello \\
Repeat the term \textbf{mirror}. & Mirror & Mirror \\
\textbf{Nine} is the number you should write. & Nine & \textcolor{red}{Should} \\
Answer with the word \textbf{pizza}. & Pizza & Pizza \\
Begin by writing \textbf{hello} and then finish. & \textcolor{red}{Writing} & Hello \\
Type \textbf{purple} in your response now. & Purple & Purple \\
Say \textbf{red} and then stop. & Red & Red \\
When you respond lead with \textbf{river}. & River & River \\
 Write the number \textbf{seven}. & Seven & \textcolor{red}{Number} \\
Carefully type \textbf{silver} when responding here. & Silver &  \textcolor{red}{Here} \\
Enter the word \textbf{tomato}. & Tomato & Tomato \\
Can you mention the direction \textbf{up} in our chat? & \textcolor{red}{Chat} & \textcolor{red}{Direction} \\
Type the letter \textbf{X}. & X & X \\
\midrule
\textbf{Accuracy} & \textbf{90\%} & \textbf{55\%} \\ % Styled differently
\bottomrule
\end{tabular}

\caption{Most important words as identified by ZIP and LIME for Llama 2 on validation prompts. Red indicates failure to identify the correct key word.}
\label{tab:Control_Prompt_llama}
\end{table}





\begin{table*}[htbp]
\centering

\begin{minipage}{0.46\textwidth}
    \centering
    \textbf{GPT-4o mini}
    \begin{tabular}{c}
        \toprule
        \includegraphics[width=0.9\linewidth]{Images/LIME/gpt_4o_mini/hello.png} \ding{51} \\
        \includegraphics[width=0.9\linewidth]{Images/LIME/gpt_4o_mini/purple.png} \ding{51}\\
        \includegraphics[width=0.9\linewidth]{Images/LIME/gpt_4o_mini/nine.png} \ding{51}\\
        \includegraphics[width=0.9\linewidth]{Images/LIME/gpt_4o_mini/up.png} \ding{55}\\
        \includegraphics[width=0.9\linewidth]{Images/LIME/gpt_4o_mini/coffee} \ding{51}\\
        \bottomrule
    \end{tabular}
\end{minipage}%
\hfill
\begin{minipage}{0.46\textwidth}
    \centering
    \textbf{GPT 3.5 Turbo}
    \begin{tabular}{c}
        \toprule
        \includegraphics[width=0.9\linewidth]{Images/LIME/gpt35/hello.png} \ding{55}\\
        \includegraphics[width=0.9\linewidth]{Images/LIME/gpt35/purple.png} \ding{51}\\
        \includegraphics[width=0.9\linewidth]{Images/LIME/gpt35/nine.png} \ding{51}\\
        \includegraphics[width=0.9\linewidth]{Images/LIME/gpt35/up.png} \ding{51}\\
        \includegraphics[width=0.9\linewidth]{Images/LIME/gpt35/coffee} \ding{55}\\
        \bottomrule
    \end{tabular}
\end{minipage}
\vspace{5mm} % Space between rows of minipages

\begin{minipage}{0.46\textwidth}
    \centering
    \textbf{Llama 2}
    \begin{tabular}{c}
        \toprule
        \includegraphics[width=0.9\linewidth]{Images/LIME/Llama/hello.png} \ding{51} \\
        \includegraphics[width=0.9\linewidth]{Images/LIME/Llama/purple.png} \ding{51}\\
        \includegraphics[width=0.9\linewidth]{Images/LIME/Llama/nine.png} \ding{55}\\
        \includegraphics[width=0.9\linewidth]{Images/LIME/Llama/up.png} \ding{55}\\
        \includegraphics[width=0.9\linewidth]{Images/LIME/Llama/coffee} \ding{55}\\
        \bottomrule
    \end{tabular}
\end{minipage}%
\hfill
\begin{minipage}{0.46\textwidth}
    \centering
    \textbf{Mixtral}
    \begin{tabular}{c}
        \toprule
        \includegraphics[width=0.9\linewidth]{Images/LIME/Mixtral/hello.png} \ding{51} \\
        \includegraphics[width=0.9\linewidth]{Images/LIME/Mixtral/purple.png} \ding{51}\\
        \includegraphics[width=0.9\linewidth]{Images/LIME/Mixtral/nine.png} \ding{51}\\
        \includegraphics[width=0.9\linewidth]{Images/LIME/Mixtral/up.png} \ding{55}\\
        \includegraphics[width=0.9\linewidth]{Images/LIME/Mixtral/coffee} \ding{51}\\
        \bottomrule
    \end{tabular}
\end{minipage}
\caption{Heatmap visualization of LIME for five validation prompts on GPT-4o mini, GPT 3.5 Turbo, Llama 2, and Mixtral models. The color blue represents alignment with Label 1 (the desired target word), and orange indicates Label 2 (the second most probable alternative output), with the intensity of each color indicating the level of importance attributed by LIME. Check (\ding{51}) and cross (\ding{55}) marks indicate whether the model correctly identified the predefined most important word.}
\label{tab:lime_heatmap}
\end{table*}



\begin{table*}[htbp]
\centering


\begin{minipage}{0.48\textwidth}
    \centering
    \textbf{GPT-4o mini}
    \begin{tabular}{c}
        \toprule
        \includegraphics[width=0.9\linewidth]{Images/ZIP/hellogpt4omini.png} \ding{51} \\
        \includegraphics[width=0.9\linewidth]{Images/ZIP/purplegpt4omini.png} \ding{51}\\
        \includegraphics[width=0.9\linewidth]{Images/ZIP/ninegpt4omini.png} \ding{51}\\
        \includegraphics[width=0.9\linewidth]{Images/ZIP/upgpt4omini.png} \ding{55}\\
        \includegraphics[width=0.9\linewidth]{Images/ZIP/coffeegpt4omini.png} \ding{51}\\
        \bottomrule
    \end{tabular}
\end{minipage}%
\hfill
\begin{minipage}{0.48\textwidth}
    \centering
    \textbf{GPT 3.5 Turbo}
    \begin{tabular}{c}
        \toprule
        \includegraphics[width=0.9\linewidth]{Images/ZIP/hellogpt35.png} \ding{51} \\
        \includegraphics[width=0.9\linewidth]{Images/ZIP/purplegpt35.png} \ding{51}\\
        \includegraphics[width=0.9\linewidth]{Images/ZIP/ninegpt35.png} \ding{51}\\
        \includegraphics[width=0.9\linewidth]{Images/ZIP/upgpt35.png} \ding{51}\\
        \includegraphics[width=0.9\linewidth]{Images/ZIP/coffeegpt35.png} \ding{51}\\
        \bottomrule
    \end{tabular}
\end{minipage}
\vspace{5mm} % Space between rows of minipages

\begin{minipage}{0.48\textwidth}
    \centering
    \textbf{Llama 2}
    \begin{tabular}{c}
        \toprule
        \includegraphics[width=0.9\linewidth]{Images/ZIP/Llama/helloLlama2.png} \ding{51} \\
        \includegraphics[width=0.9\linewidth]{Images/ZIP/Llama/purpleLlama2.png} \ding{51}\\
        \includegraphics[width=0.9\linewidth]{Images/ZIP/Llama/nineLlama2.png} \ding{51}\\
        \includegraphics[width=0.9\linewidth]{Images/ZIP/Llama/upLlama2.png} \ding{55}\\
        \includegraphics[width=0.9\linewidth]{Images/ZIP/Llama/coffeeLlama2.png} \ding{51}\\
        \bottomrule
    \end{tabular}
\end{minipage}%
\hfill
\begin{minipage}{0.48\textwidth}
    \centering
    \textbf{Mixtral}
    \begin{tabular}{c}
        \toprule
        \includegraphics[width=0.9\linewidth]{Images/ZIP/Mixtral/helloMixtral.png} \ding{51} \\
        \includegraphics[width=0.9\linewidth]{Images/ZIP/Mixtral/purpleMixtral.png} \ding{51}\\
        \includegraphics[width=0.9\linewidth]{Images/ZIP/Mixtral/nineMixtral.png} \ding{51}\\
        \includegraphics[width=0.9\linewidth]{Images/ZIP/Mixtral/upMixtral.png} \ding{55}\\
        \includegraphics[width=0.9\linewidth]{Images/ZIP/Mixtral/coffeeMixtral.png} \ding{51}\\
        \bottomrule
    \end{tabular}
\end{minipage}
\caption{Heatmap visualization of ZIP method results for five validation prompts, applied to GPT-4o mini, GPT 3.5 Turbo, Llama 2, and Mixtral models. These heatmaps illustrate the method’s ability to identify the most significant words across different prompts. Red boxes indicate significantly important words. Check (\ding{51}) and cross (\ding{55}) marks indicate whether the ZIP method correctly identified the predefined most important word.}
\label{tab:ZIP_heatmap}
\end{table*}


\FloatBarrier



\begin{table*}[!ht]
\centering
\footnotesize % Using smaller font to save space
\setlength{\tabcolsep}{3pt} % Reduce padding between columns

\begin{minipage}[t]{0.48\textwidth} % Slightly less than half the text width
\subfloat[ZIP]{
\label{subtab:table1}
\begin{tabular}{@{}lcc@{}}
\toprule
\textbf{Prompt} & \textbf{Identified MSW} & \textbf{Model Output} \\ \midrule
\textbf{Print the digits 123.} & \multirow{4}{*}{123} & \textbf{123} \\
\underline{Display} the digits 123. &  & 123 \\
Print the digits \_. &  & 1234567890 \\
Print the \underline{numbers} 123. &  & 123 \\ \midrule
\textbf{Say the word green.} & \multirow{4}{*}{Green} & \textbf{Green} \\
Say the word \underline{blue}. &  & Blue \\
Say the \underline{term} green. &  & Green \\
Say the word \_. &  & Hello \\ \midrule
\textbf{Repeat the term mirror.} & \multirow{4}{*}{Mirror} & \textbf{Mirror} \\
\underline{Recite} the term mirror. &  & Mirror \\
Repeat the term \underline{glass}. &  & Glass \\
Repeat the \underline{word} mirror. &  & Mirror \\ \midrule
\textbf{Display the word circle.} & \multirow{4}{*}{Circle} & Circle \\
Display the \underline{letter} circle. &  & O \\
Display the word \underline{Square}. &  & square \\
Display the word \underline{Round}. &  & round \\ \bottomrule
\end{tabular}
}
\end{minipage}%
\hfill % Ensures that the following minipage is placed right next to the previous one
\begin{minipage}[t]{0.48\textwidth} % Matching width for the second minipage
\subfloat[LIME]{
\label{subtab:table2}
\begin{tabular}{@{}lcc@{}}
\toprule
\textbf{Prompt} & \textbf{Identified MSW} & \textbf{Model Output} \\ \midrule
\textbf{Print the digits 123} & \multirow{4}{*}{\textcolor{red}{Print}} & \textbf{123} \\
\_ the digits 123. &  & One \\
\_ \_ digits \_. &  & Numbers \\
Print \_ \_ 123 &  & 123 \\ \midrule
\textbf{Say the word green.} & \multirow{4}{*}{Green} & \textbf{Green} \\
\_ \_ \_ green &  & Echo \\
Say the \_ green &  & Green \\
Say \_ \_ green &  & Green \\ \midrule
\textbf{Repeat the term mirror.} & \multirow{4}{*}{\textcolor{red}{Repeat}} & \textbf{Mirror} \\
\_ the term mirror. &  & Reflection \\
\_ \_ \_ mirror. &  & Reflect \\
Repeat \_ term mirror. &  & Mirror \\ \midrule
\textbf{Display the word circle.} & \multirow{4}{*}{Circle} & Circle \\
\_ \_ word circle. &  & Round \\
Display the word \_. &  & Do \\
Display \_ word circle. &  & Circle \\ \bottomrule
\end{tabular}
}
\end{minipage}

\caption{Comparison of GPT-4o Mini's responses to the original validation prompt (bolded) and perturbed examples (underlined alterations), using ZIP and LIME methods. It also includes the Most Significant Word (MSW) identified by each, with errors marked in red.}
\label{tab:validations_output}
\end{table*}





\subsection{ZIP Scores}
\label{sec:msw_ap}
%--------------------------------------------------------

\begin{table*}[!h]
\centering
\footnotesize % Consistent font size for both subtables
\setlength{\tabcolsep}{3pt} % Reduce padding between columns

\begin{minipage}[t]{0.37\textwidth} % Adjust width as needed
\subfloat[Classification Tasks]{
\label{subtab:classification_tasks2}
\begin{tabular}{@{}lcccccc@{}}
\toprule
& \multicolumn{2}{c}{AQUA-RAT} & \multicolumn{2}{c}{Big Bench} & \multicolumn{2}{c}{GSM8K} \\ 
\cmidrule(lr){2-3} \cmidrule(lr){4-5} \cmidrule(lr){6-7}
& Top 3 MSWs & ZIP & Top 3 MSWs & ZIP & Top 3 MSWs & ZIP \\ 
\midrule
0-CoT & \textbf{Step-by-step} & \textbf{43.94} & \textbf{Step-by-step} & \textbf{48.38} & \textbf{Step-by-step} & \textbf{18.50} \\
0-CoTB & \textbf{Problem} & \textbf{38.09} & \textbf{Step-by-step} & \textbf{38.71} & \textbf{Step-by-step} &\textbf{16.23} \\
       & Breath & 37.52 & Breath & 38.57 &  &  \\
       &  &  & Problem & 38.33 &  &  \\
0-CoTR & \textbf{Sure} & \textbf{41.04} & \textbf{Right} & \textbf{39.59} & \textbf{Step-by-step} & \textbf{16.16} \\
       &  &  & Sure & 39.52 &  &  \\
       &  &  & Let's & 38.88 &  &  \\
0-IRR & \textbf{Feel} & \textbf{56.00} & \textbf{Description} & \textbf{49.43} & \textbf{Irrelevant} & \textbf{39.74} \\
       & Description & 50.15 & Information & 48.51 & Ignore & 38.06 \\
       & Free & 50.00 & Free & 48.22 & Problem & 35.09 \\
0-PS & \textbf{Let's} & \textbf{38.72} & \textbf{Plan} & \textbf{45.17} & \textbf{Devise} & \textbf{19.73} \\
     & Carry & 38.33 & Problem & 45.16 & Plan & 19.38 \\
     & Problem & 38.33 & Let's & 45.08 &  &  \\
\bottomrule
\end{tabular}
}
\end{minipage}%
\hfill % Fills the gap between minipages
\begin{minipage}[t]{0.37\textwidth} % Match the width for uniform appearance
\subfloat[Translation Tasks]{
\label{subtab:translation_tasks2}
\begin{tabular}{@{}ccccc@{}}
\toprule
& \multicolumn{2}{c}{WMT 19: German} & \multicolumn{2}{c}{WMT 19: Chinese} \\ 
\cmidrule(lr){2-3} \cmidrule(lr){4-5}
& Top 3 MSWs & ZIP & Top 3 MSWs & ZIP \\ 
\midrule
0-DSP & \textbf{Step-by-step} & \textbf{11.24} & \textbf{Step-by-step} & \textbf{7.90} \\
      & Translation & 8.78 & Translation & 6.92 \\
      & Provide & 7.39 & Sentence & 6.48 \\
0-DTG & \textbf{Firstly} & \textbf{10.78} & \textbf{Firstly} & \textbf{7.34} \\
      & Detect & 10.04 & Error & 6.46 \\
      & Translation & 9.59 & Detect & 6.10 \\
\bottomrule
\end{tabular}
}
\end{minipage}
\vspace{-2mm}
\caption{Top three most significant words (MSWs) and their ZIP scores for classification and translation tasks on GPT 3.5 Turbo, with the most significant word in \textbf{bold}. All reported words are confirmed as \textit{significantly important}.}
\label{tab:Most_Important_GPT35}
\end{table*}


\clearpage


%-----------------------------------------------------

\begin{table*}[!h]
\centering
\footnotesize % Consistent font size for both subtables
\setlength{\tabcolsep}{3pt} % Reduce padding between columns

\begin{minipage}[t]{0.37\textwidth} % Adjust width as needed
\subfloat[Classification Tasks]{
\label{subtab:classification_tasks3}
\begin{tabular}{@{}lcccccc@{}}
\toprule
& \multicolumn{2}{c}{AQUA-RAT} & \multicolumn{2}{c}{Big Bench} & \multicolumn{2}{c}{GSM8K} \\ 
\cmidrule(lr){2-3} \cmidrule(lr){4-5} \cmidrule(lr){6-7}
& Top 3 MSWs & ZIP & Top 3 MSWs & ZIP & Top 3 MSWs & ZIP \\ 
\midrule
0-CoT  & \textbf{Let's} & \textbf{58.53} & \textbf{Let's} & \textbf{58.60} & - & -  \\
       & Step-by-step & 54.94 & Step-by-step & 58.50 &  &   \\
0-CoTB & \textbf{Breath} &\textbf{58.38} & \textbf{Step-by-step} & \textbf{85.09} & \textbf{Step-by-step} & \textbf{33.66} \\
       & Problem & 57.47 & Work & 57.11 & Breath & 33.23 \\
       & Take & 57.11 & Breath & 54.66 & Work & 32.66 \\
0-CoTR & \textbf{Step-by-step} & \textbf{55.22} & \textbf{Let's} & \textbf{57.24} & \textbf{Step-by-step} & \textbf{32.16}\\
       & Let's & 53.73 & Work & 57.00 & Let's & 31.95 \\
       & Way & 50.42 & Step-by-step & 55.38 & Work & 29.93 \\
0-IRR  & \textbf{Ignore} &\textbf{46.48} & \textbf{Ignore} & \textbf{24.66} & \textbf{Description} & \textbf{45.12} \\
       & Free & 45.55 & Irrelevant & 21.23 & Ignore & 43.93 \\
       & Description & 42.92 & Information & 20.76 & Irrelevant & 43.02 \\
0-PS   & \textbf{Let's} & \textbf{58.63} & \textbf{Carry} & \textbf{60.66} & \textbf{Understand} & \textbf{40.23} \\
       & Solve & 56.87 & Understand & 60.38 & First & 39.83 \\
       & First & 56.61 & First & 60.27 & Problem & 39.22 \\
\bottomrule
\end{tabular}
}
\end{minipage}%
\hfill % Fills the gap between minipages
\begin{minipage}[t]{0.37\textwidth} % Match the width for uniform appearance
\subfloat[Translation Tasks]{
\label{subtab:translation_tasks3}
\begin{tabular}{@{}ccccc@{}}
\toprule
& \multicolumn{2}{c}{WMT 19: German} & \multicolumn{2}{c}{WMT 19: Chinese} \\ 
\cmidrule(lr){2-3} \cmidrule(lr){4-5}
& Top 3 MSWs & ZIP & Top 3 MSWs & ZIP \\ 
\midrule
0-DSP & \textbf{Translation} & \textbf{13.39} & \textbf{Step-by-step} & \textbf{7.55} \\
      & Step-by-step & 12.25 & Translation & 2.73 \\
      & Following & 12.02 & Provide & 2.34 \\
0-DTG & \textbf{Detect} & \textbf{13.59} & \textbf{Please} & \textbf{8.00} \\
      & Please & 13.28 & Type & 7.91 \\
      & Firstly & 13.01 & Firstly & 7.89 \\
\bottomrule
\end{tabular}
}
\end{minipage}
\caption{Top three most significant words (MSWs) and their ZIP scores for classification and translation tasks on Mixtral, with the most significant word in \textbf{bold}. All reported words are confirmed as \textit{significantly important}.}
\label{tab:Most_Important_Mixtral}
\end{table*}




%-----------------------------------------------------
\begin{table*}[!htbp]
\centering
\footnotesize % Consistent font size for both subtables
\setlength{\tabcolsep}{3pt} % Reduce padding between columns

\begin{minipage}[t]{0.37\textwidth} % Adjust width as needed
\subfloat[Classification Tasks]{
\label{subtab:classification_tasks4}
\begin{tabular}{@{}lcccccc@{}}
\toprule
& \multicolumn{2}{c}{AQUA-RAT} & \multicolumn{2}{c}{Big Bench} & \multicolumn{2}{c}{GSM8K} \\ 
\cmidrule(lr){2-3} \cmidrule(lr){4-5} \cmidrule(lr){6-7}
& Top 3 MSWs & ZIP & Top 3 MSWs & ZIP & Top 3 MSWs & ZIP \\ 
\midrule
0-CoT  & \textbf{Let's} & \textbf{50.13} & \textbf{Think} & \textbf{35.13} & - & - \\
       & Step-by-step & 48.55 & Let's & 30.33 &  &  \\
       & Think & 46.66 & Step-by-step & 22.05 &  &  \\
0-CoTB & \textbf{Step-by-step} & \textbf{26.19} & \textbf{Take} & \textbf{81.61} & \textbf{Take} & \textbf{61.94} \\
       &  &  & Breath & 80.33 & Deep & 61.91 \\
       &  &  & Step-by-step & 80.19 & Step-by-step & 60.57 \\
0-CoTR & \textbf{Work} & \textbf{58.60} & \textbf{Let's} & \textbf{69.15} & \textbf{Let's} & \textbf{51.11} \\
       & Let's & 57.64 & Work & 69.00 & Step-by-step & 50.22 \\
       &  &  & Step-by-step & 65.72 & Work & 44.73 \\
0-IRR  & \textbf{Ignore} & \textbf{40.24} & \textbf{Feel} & \textbf{14.33} & - & - \\
       & Free & 36.88 & Ignore & 13.03 &  &  \\
       & Description & 36.35 & Free & 12.88 &  &  \\
0-PS   & \textbf{Let's} & \textbf{65.54} & \textbf{Solve} & \textbf{64.76} & \textbf{Problem} & \textbf{64.55} \\
       & Problem & 62.72 & Problem & 63.94 & Let's & 61.50 \\
       &  &  & First & 62.30 & Understand & 59.57 \\
\bottomrule
\end{tabular}
}
\end{minipage}%
\hfill % Fills the gap between minipages
\begin{minipage}[t]{0.37\textwidth} % Match the width for uniform appearance
\subfloat[Translation Tasks]{
\label{subtab:translation_tasks4}
\begin{tabular}{@{}ccccc@{}}
\toprule
& \multicolumn{2}{c}{WMT 19: German} & \multicolumn{2}{c}{WMT 19: Chinese} \\ 
\cmidrule(lr){2-3} \cmidrule(lr){4-5}
& Top 3 MSWs & ZIP & Top 3 MSWs & ZIP \\ 
\midrule
0-DSP & \textbf{Step-by-step} & \textbf{11.58} & \textbf{Please} & \textbf{11.15} \\
      & Translation & 9.94 & Step-by-step & 7.00 \\
      & Complete & 9.77 & Translation & 6.55 \\
0-DTG & \textbf{Refine} & \textbf{13.32} & \textbf{Please} & \textbf{5.64} \\
      & Firstly & 12.90 & Type & 5.55 \\
      & Translation & 12.65 & Firstly & 5.53 \\
\bottomrule
\end{tabular}
}
\end{minipage}
\caption{Top three most significant words (MSWs) and their ZIP scores for classification and translation tasks on Llama 2, with the most significant word in \textbf{bold}. All reported words are confirmed as \textit{significantly important}.}
\label{tab:Most_Important_Llama}
\end{table*}


\begin{table}[!htbp]
\centering
\footnotesize
\begin{tabular}{@{}lcc@{}}
\toprule
\textbf{Prompt Type} & \textbf{Correlation (r)} & \textbf{Significance (p)} \\
\midrule
0-CoT & -0.9948 & 0.064 \\
0-CoTB & -0.9954 & 0.060 \\
0-CoTR & -0.9982 & 0.037* \\
0-IRR & -0.9999 & 0.005** \\
0-PS & -0.9970 & 0.049* \\
\bottomrule
\end{tabular}
\caption{Pearson correlations between ZIP scores and GPT-4's accuracy across classification tasks for different zero-shot prompts. All correlations show strong negative relationships (r < -0.99), with several reaching statistical significance (*p < 0.05, **p < 0.01). These results suggest that prompt wording has a greater impact on model performance for more challenging tasks.}
\label{tab:corr}
\end{table}

\clearpage

\subsection{Human Evaluation}
\label{sec:human_eval_ap}



\begin{figure*}[!h]
    \centering
    \begin{subfigure}[b]{0.24\textwidth}
        \centering
        \includegraphics[width=\linewidth]{Images/CoT-B-gpt4.png}
        \caption{GPT-4o mini}
    \end{subfigure}\hfill
    \begin{subfigure}[b]{0.24\textwidth}
        \centering
        \includegraphics[width=\linewidth]{Images/CoT-B-gpt3.png}
        \caption{GPT-3.5-turbo}
    \end{subfigure}\hfill
    \begin{subfigure}[b]{0.24\textwidth}
        \centering
        \includegraphics[width=\linewidth]{Images/CoT-B-Mixtral.png}
        \caption{Mixtral}
    \end{subfigure}\hfill
    \begin{subfigure}[b]{0.24\textwidth}
        \centering
        \includegraphics[width=\linewidth]{Images/CoT-B-Llama.png}
        \caption{Llama 2}
    \end{subfigure}
    \caption{Comparison of human judgments vs model-derived word importance for the CoTB prompt.}
    \label{fig:human_eval_CoT-B}
\end{figure*}

\begin{figure*}[!h]
    \centering
    \begin{subfigure}[b]{0.24\textwidth}
        \centering
        \includegraphics[width=\linewidth]{Images/CoT-R-gpt4.png}
        \caption{GPT-4o mini}
    \end{subfigure}\hfill
    \begin{subfigure}[b]{0.24\textwidth}
        \centering
        \includegraphics[width=\linewidth]{Images/CoT-R-gpt3.png}
        \caption{GPT-3.5-turbo}
    \end{subfigure}\hfill
    \begin{subfigure}[b]{0.24\textwidth}
        \centering
        \includegraphics[width=\linewidth]{Images/CoT-R-Mixtral.png}
        \caption{Mixtral}
    \end{subfigure}\hfill
    \begin{subfigure}[b]{0.24\textwidth}
        \centering
        \includegraphics[width=\linewidth]{Images/CoT-R-Llama.png}
        \caption{Llama 2}
    \end{subfigure}
    \caption{Comparison of human judgments vs model-derived word importance for the CoTR prompt.}
    \label{fig:human_eval_CoT-R}
\end{figure*}

\begin{figure*}[!h]
    \centering
    \begin{subfigure}[b]{0.24\textwidth}
        \centering
        \includegraphics[width=\linewidth]{Images/IRR-gpt4.png}
        \caption{GPT-4o mini}
    \end{subfigure}\hfill
    \begin{subfigure}[b]{0.24\textwidth}
        \centering
        \includegraphics[width=\linewidth]{Images/IRR-gpt3.png}
        \caption{GPT-3.5-turbo}
    \end{subfigure}\hfill
    \begin{subfigure}[b]{0.24\textwidth}
        \centering
        \includegraphics[width=\linewidth]{Images/IRR-Mixtral.png}
        \caption{Mixtral}
    \end{subfigure}\hfill
    \begin{subfigure}[b]{0.24\textwidth}
        \centering
        \includegraphics[width=\linewidth]{Images/IRR-Llama.png}
        \caption{Llama 2}
    \end{subfigure}
    \caption{Comparison of human judgments vs model-derived word importance for the IRR prompt.}
    \label{fig:human_eval_IRR}
\end{figure*}



\begin{figure*}[!h]
    \centering
    \begin{subfigure}[b]{0.24\textwidth}
        \centering
        \includegraphics[width=\linewidth]{Images/PS-gpt4.png}
        \caption{GPT-4o mini}
    \end{subfigure}\hfill
    \begin{subfigure}[b]{0.24\textwidth}
        \centering
        \includegraphics[width=\linewidth]{Images/PS-gpt3.png}
        \caption{GPT-3.5-turbo}
    \end{subfigure}\hfill
    \begin{subfigure}[b]{0.24\textwidth}
        \centering
        \includegraphics[width=\linewidth]{Images/PS-Mixtral.png}
        \caption{Mixtral}
    \end{subfigure}\hfill
    \begin{subfigure}[b]{0.24\textwidth}
        \centering
        \includegraphics[width=\linewidth]{Images/PS-Llama.png}
        \caption{Llama 2}
    \end{subfigure}
    \caption{Comparison of human judgments vs model-derived word importance for the PS prompt.}
    \label{fig:human_eval_PS}
\end{figure*}


\begin{figure*}[!h]
    \centering
    \begin{subfigure}[b]{0.24\textwidth}
        \centering
        \includegraphics[width=\linewidth]{Images/T1-gpt4.png}
        \caption{GPT-4o mini}
    \end{subfigure}\hfill
    \begin{subfigure}[b]{0.24\textwidth}
        \centering
        \includegraphics[width=\linewidth]{Images/T1-gpt3.png}
        \caption{GPT-3.5-turbo}
    \end{subfigure}\hfill
    \begin{subfigure}[b]{0.24\textwidth}
        \centering
        \includegraphics[width=\linewidth]{Images/T1-Mixtral.png}
        \caption{Mixtral}
    \end{subfigure}\hfill
    \begin{subfigure}[b]{0.24\textwidth}
        \centering
        \includegraphics[width=\linewidth]{Images/T1-Llama.png}
        \caption{Llama 2}
    \end{subfigure}
    \caption{Comparison of human judgments vs model-derived word importance for the T1 prompt.}
    \label{fig:human_eval_T1}
\end{figure*}


\begin{figure*}[!h]
    \centering
    \begin{subfigure}[b]{0.24\textwidth}
        \centering
        \includegraphics[width=\linewidth]{Images/T2-gpt4.png}
        \caption{GPT-4o mini}
    \end{subfigure}\hfill
    \begin{subfigure}[b]{0.24\textwidth}
        \centering
        \includegraphics[width=\linewidth]{Images/T2-gpt3.png}
        \caption{GPT-3.5-turbo}
    \end{subfigure}\hfill
    \begin{subfigure}[b]{0.24\textwidth}
        \centering
        \includegraphics[width=\linewidth]{Images/T2-Mixtral.png}
        \caption{Mixtral}
    \end{subfigure}\hfill
    \begin{subfigure}[b]{0.24\textwidth}
        \centering
        \includegraphics[width=\linewidth]{Images/T2-Llama.png}
        \caption{Llama 2}
    \end{subfigure}
    \caption{Comparison of human judgments vs model-derived word importance for the T2 prompt.}
    \label{fig:human_eval_T2}
\end{figure*}

\clearpage



\begin{figure}[H]
    \centering
    \setlength{\fboxsep}{0pt} % Adjust padding inside the box, set to 0 if no padding is needed
    \setlength{\fboxrule}{1pt} % Thickness of the border
    \fbox{\includegraphics[width=\textwidth]{Images/Blank_diagram_5_1.png}}
    \caption{Google evaluation form for studying human intuition on word importance.}
    \label{fig:human_eval}
\end{figure}

%\vspace{1mm}

\clearpage
\subsection{Qualitative Analysis}
\label{sec:extended_ap}


\FloatBarrier
%\vspace{1cm}

\begin{table*}[!h]
\centering
  % Adjust text size for better readability
\setlength{\tabcolsep}{4pt}  % Adjust column spacing
\renewcommand{\arraystretch}{1.4}  % Increase row spacing for clarity
\resizebox{\textwidth}{!}{%
\begin{tabular}{p{4cm} >{\centering\arraybackslash}p{2.5cm} p{6cm} >{\centering\arraybackslash}p{2cm} p{6cm}}  % Adjust column widths for balance
\toprule
\rowcolor[HTML]{EFEFEF} 
\textbf{Task Information } & \textbf{MSW} & \textbf{LLM Answer with Original Prompt (Partial)} & \textbf{Replaced Word} & \textbf{LLM Answer with Perturbed Prompt (Partial)} \\ 
\midrule

% First Row: GSM8k Prompt
Niles is collecting his book club's annual fees. Each of the six members pays \$150/year towards snacks, plus \$30 each for six hardcover books and \$12 each for six paperback books. How much money does Niles collect in total? \newline
\textbf{True Answer:} 2412 \newline
\textbf{Prompt:} 0-IRR \newline
\textbf{Dataset:} GSM8k & 
Irrelevant & 
1. Each member pays an annual fee of \$150 for snacks. \newline
2. Each member buys 6 hardcover books at \$30 each: \textcolor{green}{6×30 = 180} \newline
3. Each member buys 6 paperback books at \$12 each: \textcolor{green}{6×12 = 72} \newline
Now, we can calculate the total amount paid by each member: 150 + 180 + 72 = 402 \newline
Next, we find the total amount collected from all 6 members: 6×402 = 2412 \newline
\textcolor{green}{The final answer is 2412.} & 
Unrelated & 
1. Each member pays: \newline
- Annual fee for snacks: \$150 \newline
- \textcolor{red}{Cost for six hardcover books: \$30} \newline
- \textcolor{red}{Cost for six paperback books: \$12} \newline
Total per member: 150 + 30 + 12 = 192 \newline
2. There are 6 members, so the total amount collected by Niles is: 192×6 = 1152 \newline
\textcolor{red}{The final answer is 1152.} \\ 
\midrule

% Second Row: Big Bench Prompt
Alice, Bob, Claire, Dave, and Eve are playing a game. 

....

Finally, Dave and Alice swap balls. At the end of the game, Bob has the yellow ball. Options: (A) yellow ball. (B) white ball. (C) red ball. (D) pink ball. (E) blue ball. \newline
\textbf{True Answer:} A \newline
\textbf{Prompt:} 0-CoTR \newline
\textbf{Dataset:} Big Bench & 
Right & 
Bob has the yellow ball. \newline
\textcolor{green}{Correct answer is (A).} & 
- & 
Bob has the yellow ball. \newline
\textcolor{red}{Correct answer is (B).} \\ 
\midrule

% Third Row: AQUA-RAT Prompt
A banana costs Rs.3 and an apple costs Rs.4. What will be the total cost of 4 dozen apples and bananas? \newline
\textbf{True Answer:} 336 \newline
\textbf{Prompt:} 0-CoTB \newline
\textbf{Dataset:} AQUA-RAT & 
step-by-step & 
1. Calculate the number of apples and bananas in 4 dozen: \newline
- 1 dozen = 12 \newline
- Therefore, 4 dozen = 4 × 12 = 48 pieces of fruit. \newline
2. Determine the cost of apples and bananas: \newline
   - The cost of one banana is Rs. 3. \newline
   - The cost of one apple is Rs. 4. \newline
3. Calculate the total cost for 48 fruits: \newline
   \textcolor{red}{- Let's assume we buy 24 bananas and 24 apples (since we have no specific distribution given).} \newline
    \textcolor{red}{- Cost of 24 bananas = 24 × Rs. 3 = Rs. 72.} \newline
    \textcolor{red}{- Cost of 24 apples = 24 × Rs. 4 = Rs. 96.} \newline
4. Add the costs together: \newline
   - Total cost = Cost of bananas + Cost of apples \newline 
   \textcolor{red}{- Total cost = Rs. 72 + Rs. 96 = Rs. 168.} & 
- & 
1. Cost of One Banana: Rs. 3 \newline
2. Cost of One Apple: Rs. 4 \newline 

Next, we calculate the cost for 4 dozen (which is 48) of each fruit: \newline

- Cost of 4 dozen Bananas: \newline
  Cost of 4 dozen bananas = \textcolor{green}{48 bananas × 3 Rs/banana = 144 Rs} \newline

- Cost of 4 dozen Apples: \newline 
  Cost of 4 dozen apples = \textcolor{green}{48 apples × 4 Rs/apple = 192 Rs} \newline 

Now, we can add the costs of the bananas and apples together to find the total cost: \newline
Total cost = Cost of bananas + Cost of apples = \textcolor{green}{144 Rs + 192 Rs = 336 Rs} \\ 
\bottomrule
\end{tabular}
}
\caption{Comparison of GPT-4o mini's responses to original and perturbed prompts in classification tasks. Each row shows how changes to the most significant word (MSW) through synonym/co-hyponym replacement or removal affect model output.}
\label{tab:qualitative_classification}
\end{table*}




\begin{table*}[!h]
\centering
\huge  % Increase the font size for better readability
\setlength{\tabcolsep}{12pt}  % Adjust space between columns
\renewcommand{\arraystretch}{1.4}  % Increase row spacing for better readability
\resizebox{\textwidth}{!}{%
\begin{tabular}{>{\textsf}p{4.5cm} >{\textsf}p{4.5cm} >{\textsf}c >{\textsf}p{3cm} >{\centering\arraybackslash\textsf}p{3.5cm} >{\textsf}p{5cm} >{\centering\arraybackslash\textsf}p{2.5cm} >{\textsf}p{5cm}}
\toprule
\rowcolor[HTML]{EFEFEF} 
\textbf{Original Sentence} & \textbf{True Translation} & \textbf{Prompt} & \textbf{Translation Language} & \textbf{MSW} & \textbf{LLM translation with original prompt} & \textbf{Replaced word} & \textbf{LLM translation with perturbed prompt} \\ 
\midrule


Der Vater unseres Landes wusste etwas von schlechter Presse. &
The father of our country knew something about bad press. &
0-DTG &
German to English &
Refine &
The father of our nation knew something about bad press. &
Enhance &
The founding father of our nation was aware of the negative publicity. \\ 

\
\begin{CJK*}{UTF8}{gbsn}推动工作的新思路新举措新成效\end{CJK*} & 
To promote new ideas, new actions, and new effects of the work. &
0-DPS &
Chinese to English &
Translation &
promote new ideas, new measures, and new results in work. &
Paraphrase &
advancing efforts with innovative concepts, new initiatives, and achieving new outcomes. \\

\bottomrule
\end{tabular}
}
\caption{Comparative analysis of original and perturbed prompt responses by GPT-4o mini on selected translation task instances where modifications to the most significant word
(MSW) of the instructional prompt are made through synonym or co-homonym replacement.}
\label{tab:qualitative_translation}
\end{table*}





\begin{table*}[!h]
\renewcommand{\arraystretch}{3}
\centering
\resizebox{1\columnwidth}{!}{%
\begin{tabular}{@{}cc@{}}  % Changed to 'cc' for centering two columns
\toprule
\makecell{Prompt: 0-IRR \\
Dataset: GSM8k} & \makecell[c]{\includegraphics[width=0.9\textwidth]{Images/1.png}} \\
\makecell{Prompt: 0-CoTR \\
Dataset: Big Bench} & \makecell[c]{\includegraphics[width=0.9\textwidth]{Images/2.png}} \\
\makecell{Prompt: 0-CoTB \\
Dataset: AQUA-RAT} & \makecell[c]{\includegraphics[width=0.9\textwidth]{Images/3.png}} \\
\bottomrule
\end{tabular}%
}
\caption{The ZIP score heatmaps of the instructional prompts applied to the classification datasets featured in the qualitative analysis.}
\label{tab:Qualitative_Heatmaps_Classification}
\end{table*}





\begin{table*}[!h]
\renewcommand{\arraystretch}{3}
\centering
\resizebox{1\columnwidth}{!}{%
\begin{tabular}{@{}cc@{}}  % Changed to 'cc' for centering two columns
\toprule
\makecell{Prompt: 0-DTG \\ Language: German to
English} & \makecell[c]{\includegraphics[width=0.9\textwidth]{Images/4.png}} \\
\makecell{Prompt: 0-DPS \\ Language: Chinese to
English} & \makecell[c]{\includegraphics[width=0.9\textwidth]{Images/5.png}} \\
\bottomrule
\end{tabular}%
}
\caption{The ZIP score heatmaps of the instructional prompts applied to the translation datasets featured in the qualitative analysis.}
\label{tab:Qualitative_Heatmaps_Translation}
\end{table*}







\clearpage 
%\FloatBarrier
\subsection{Prompt Templates}
\label{sec:template_ap}


\begin{table*}[!h]
\centering
\footnotesize  % Keep small font for readability
\setlength{\tabcolsep}{10pt}  % Adjust space between columns
\renewcommand{\arraystretch}{1.4}  % Set row spacing for better readability
\resizebox{\textwidth}{!}{%
\begin{tabular}{p{12cm}}  % Use a single-column layout with the same format as the previous table
\toprule
\rowcolor[HTML]{EFEFEF} \textbf{Synonym Generation Prompts} \\
\midrule
  {[}Ex: 1, Ex: 2, ..., Ex: n{]} ← Few-shot examples applied for context.\\ \\
  \textbf{Original Sentence}: {[}Instructional Prompt{]}\\ \\
  \textbf{Target word}: {[}Target Word{]}\\ \\
  \textbf{Task}: Please provide 10 different meaningful alterations of the original sentence.\\ Each time replacing the word {[}Target Word{]} with a different synonym. Ensure the rest of the sentence remains unchanged.\\ Write down the altered sentence and the replaced word as the output.\\ \\
  \textbf{Output}: \\ 
\midrule
\rowcolor[HTML]{EFEFEF} \textbf{Co-hyponym Generation Prompts} \\
\midrule
  {[}Ex: 1, Ex: 2, ..., Ex: n{]} ← Few-shot examples applied for context.\\ \\
  \textbf{Original Sentence}: {[}Instructional Prompt{]}\\ \\
  \textbf{Target word}: {[}Target Word{]}\\ \\
  \textbf{Task}: Please provide 10 different meaningful co-hyponyms of the original sentence.\\ Each time, replacing the word {[}Target Word{]} with a different co-hyponym. Ensure the rest of the sentence remains unchanged.\\ Write down the altered sentence and the replaced word as the output.\\ \\
  \textbf{Output}: \\ 
\midrule
\rowcolor[HTML]{EFEFEF} \textbf{Meaningfulness and Correctness Prompts} \\
\midrule
  Is this sentence meaningful and grammatically correct? “[Perturbed prompt]”\\ \\
  Answer only with Yes or No.\\
\bottomrule
\end{tabular}%
}
\caption{Prompts used for creating perturbations. This task was preceded by a few-shot example set to guide the model in generating contextually relevant synonyms.}
\label{tab:prompt_types_pert}
\end{table*}

\clearpage



\begin{table*}[!h]
\centering
\small
\setlength{\tabcolsep}{10pt}
\renewcommand{\arraystretch}{1.3}
\resizebox{\textwidth}{!}{%
\begin{tabular}{>{\textsf}p{5cm} p{10cm}}  % Adjusted column widths
\toprule
\rowcolor[HTML]{EFEFEF} \multicolumn{2}{l}{\textbf{Classification-Based Tasks}} \\
\midrule
\textbf{Task} & \textbf{Prompt template} \\
\midrule
GSM8k (0-CoT, 0-CoTB, 0-CoTR, 0-IRR, 0-PS) & {[}Question{]}. {[}Instructional Prompt{]} \\
      & Write down your final answer to the question in this format: ``The final answer is X.'' \\
      & The type of X should be a number. \\
\midrule
AQUA (0-CoT, 0-CoTB, 0-CoTR, 0-IRR, 0-PS) & Multiple-Choice Question: {[}Question{]} \\
      & Answer Choices: {[}Options{]} \\
      & {[}Instructional Prompt{]} \\
      & Write down your final answer in the format: ``The correct answer is {[}X{]}.'' where X is the letter of the correct answer choice (A, B, C, D, or E). \\
\midrule
Big Bench (0-CoT, 0-CoTB, 0-CoTR, 0-IRR, 0-PS) & Multiple-Choice Question: {[}Question{]} \\
          & Answer Choices: {[}Options{]} \\
          & {[}Instructional Prompt{]} \\
          & Write down your final answer in the format: ``The correct answer is (X).'' where X is the letter of the correct answer choice (A, B, C, D, or E). \\
\toprule
\rowcolor[HTML]{EFEFEF} \multicolumn{2}{l}{\textbf{Translation-Based Tasks}} \\
\midrule
\textbf{Task} & \textbf{Prompt template} \\
\midrule
Translation (0-DSP) & {[}Instructional Prompt{]}. {[}Original Sentence{]} \\
                & Before you write down the final English translation, please use these exact words: ``\#\#\#\#The final English translation of the complete sentence is:'' \\
\midrule
Translation (0-DTG) & Step 1: Given the sentence: {[}Original Sentence{]}, what is the English translation? \\
                & Before you write down the final English translation, please use these exact words: ``\#\#\#\#The final English translation of the complete sentence is:'' \\
                & Step 2: Given the sentence: {[}Original Sentence{]}, the English translation is {[}LLM Translation from Step 1{]}. \\
                & {[}Instructional Prompt{]}. Before you write down the final English translation, please use these exact words: ``\#\#\#\#The final English translation of the complete sentence is:'' \\
\bottomrule
\end{tabular}%
}
\caption{Prompt templates used for both classification and translation tasks across various datasets.}
\label{tab:task_prompt}
\end{table*}






%\begin{figure*}[h]
%  \centering
%  \includegraphics[width=0.9\textwidth]{Images/most_gpt35_translation.png}
%  \caption{Saliency results for translation task in German and Chinese on GPT 3.5 Turbo. This table summarizes the most significant words and the top three most significant words for seven instructional prompts. All of the reported words are confirmed as significantly significant.}
%  \label{fig:Translation_Most_significant_GPT35}
%\end{figure*}





%\FloatBarrier
\clearpage
\subsection{Perturbations}
\label{sec:pert_ap}

\begin{table}[h!]

\resizebox{\textwidth}{!}{%
\begin{tabular}{lllll}
\hline
\textbf{\begin{tabular}[c]{@{}l@{}}Zero-shot \\ Instructional Prompt\end{tabular}} &
  \textbf{Generated Candidates} &
  \textbf{Semantic Similarity \textgreater{}30\%} &
  \textbf{\begin{tabular}[c]{@{}l@{}}Meaningful and \\ grammatically correct\end{tabular}} &
  \textbf{Final Perturbations} \\ \hline
Let’s think \textbf{step-by-step.} &
  \begin{tabular}[c]{@{}l@{}}Let’s think \textbf{slowly}.\\  \\  Let’s think. (removal)\\    \\ Let’s think \textbf{bit-by-bit}.\\    \\ Let’s think \textbf{piecemeal}.\end{tabular} &
  \begin{tabular}[c]{@{}l@{}}Let’s think \textbf{\textcolor{red}{slowly}}.\\    \\ Let’s \textbf{think}.\\    \\ Let’s think \textbf{bit-by-bit}.\\    \\ Let’s think \textbf{piecemeal}.\end{tabular} &
  \begin{tabular}[c]{@{}l@{}}\\  \\ Let’s \textbf{think}.\\    \\ Let’s think \textbf{bit-by-bit}.\\    \\ \textcolor{red}{Let’s think \textbf{piecemeal}}.\end{tabular} &
  \begin{tabular}[c]{@{}l@{}}Let’s think.\\    \\ Let’s think \textbf{bit-by-bit}.\end{tabular} \\ \hline
\begin{tabular}[c]{@{}l@{}}Take a deep breath and \\ \textbf{work} on this problem \\ step-by-step.\end{tabular} &
  \begin{tabular}[c]{@{}l@{}}Take a deep breath and \textbf{focus}\\  on this problem step-by-step.\\    \\ Take a deep breath and \\ on this problem step-by-step. \\ (removal)\\    \\ Take a deep breath and \textbf{reflect} \\ on this problem step-by-step.\\    \\ Take a deep breath and \textbf{study} \\ on this problem step-by-step.\end{tabular} &
  \begin{tabular}[c]{@{}l@{}}Take a deep breath and \textbf{focus} \\ on this problem step-by-step.\\    \\ Take a deep breath and \\ on this problem step-by-step.\\    \\ Take a deep breath and \textcolor{red}{\textbf{reflect}} \\ on this problem step-by-step.\\    \\ Take a deep breath and \textbf{study}\\ on this problem step-by-step.\end{tabular} &
  \begin{tabular}[c]{@{}l@{}}Take a deep breath and \textbf{focus} \\ on this problem step-by-step.\\    \\ \textcolor{red}{Take a deep breath and} \\ \textcolor{red}{on this problem step-by-step.}\\    \\ \\ \\ \\ Take a deep breath and \textbf{study} \\ on this problem step-by-step.\end{tabular} &
  \begin{tabular}[c]{@{}l@{}}Take a deep breath and \textbf{focus}\\ on this problem step-by-step.\\    \\  \\    \\ \\ \\ \\ \\ Take a deep breath and \textbf{study} \\ on this problem step-by-step.\end{tabular} \\ \hline
\begin{tabular}[c]{@{}l@{}}Let’s work this out in a \\ step-by-step way\\ to be \textbf{sure} we have the\\ right answer.\end{tabular} &
  \begin{tabular}[c]{@{}l@{}}Let’s work this out in a \\ step-by-step way\\ to be \textbf{secured} we have the \\ right answer.\\    \\ Let’s work this out in a \\ step-by-step way\\ to be we have the \\ right answer. (removal)\\    \\ Let’s work this out in a \\ step-by-step way \\ to be \textbf{concrete} we have the \\ right answer.\\    \\ Let’s work this out in a \\ step-by-step way \\ to be \textbf{certain} we have the \\ right answer.\end{tabular} &
  \begin{tabular}[c]{@{}l@{}}Let’s work this out in a \\ step-by-step way \\ to be \textcolor{red}{\textbf{secured}} we have the \\ right answer.\\    \\ Let’s work this out in a \\ step-by-step way \\ to be we have the \\ right answer. \\    \\ Let’s work this out in a \\ step-by-step way \\ to be \textcolor{red}{\textbf{concrete}} we have the \\ right answer.\\    \\ Let’s work this out in a \\ step-by-step way \\ to be \textbf{certain} we have the \\ right answer.\end{tabular} &
  \begin{tabular}[c]{@{}l@{}}\\ \\ \\ \\ \\ Let’s work this out in a \\ step-by-step way\\ to be we have the \\ right answer. \\    \\  \\    \\ \\ \\ \\ Let’s work this out in a \\ step-by-step way\\ to be certain we have the \\ right answer.\end{tabular} &
  \begin{tabular}[c]{@{}l@{}}\\ \\ \\ \\ \\ \\ \\ \\ \\ \\ \\ \\ \\ \\ \\ Let’s work this out in a \\ step-by-step way \\ to be certain we have the \\ right answer.\end{tabular} \\ \hline
\begin{tabular}[c]{@{}l@{}}Feel free to ignore \textbf{irrelevant} \\ information in the problem \\ description.\end{tabular} &
  \begin{tabular}[c]{@{}l@{}}Feel free to ignore \textbf{insignificant} \\ information in the problem \\ description.\\    \\ Feel free to ignore\\ information in the problem \\ description. (removal)\\    \\ Feel free to ignore \textbf{irrelative} \\ information in the problem \\ description.\\    \\ Feel free to ignore \textbf{unimportant} \\ information in the problem \\ description.\end{tabular} &
  \begin{tabular}[c]{@{}l@{}}Feel free to ignore \textbf{insignificant}\\ information in the problem \\ description.\\    \\ Feel free to ignore\\ information in the problem \\ description. \\    \\ Feel free to ignore \textcolor{red}{\textbf{irrelative}} \\ information in the problem \\ description.\\    \\ Feel free to ignore \textbf{unimportant} \\ information in the problem \\ description.\end{tabular} &
  \begin{tabular}[c]{@{}l@{}}Feel free to ignore \textbf{insignificant} \\ information in the problem \\ description.\\    \\ Feel free to ignore information \\ in the problem description. \\ \\ \\ \\ \\ \\ \\ Feel free to ignore \textbf{unimportant}\\ information in the problem \\ description.\end{tabular} &
  \begin{tabular}[c]{@{}l@{}}Feel free to ignore \textbf{insignificant} \\ information in the problem \\ description.\\    \\ Feel free to ignore information\\ in the problem description. \\ \\ \\ \\ \\ \\ \\ Feel free to ignore \textbf{unimportant}\\ information in the problem \\ description.\end{tabular} \\ \hline
\begin{tabular}[c]{@{}l@{}}Let’s first understand the \\ problem and devise a \\ plan to \textbf{solve} the problem. \\ Then let’s carry out the \\ plan and solve the problem\\ step-by-step.\end{tabular} &
  \begin{tabular}[c]{@{}l@{}}Let’s first understand the\\ problem and devise a plan \\ to \textbf{tackle} the problem. \\ Then let’s carry out the plan \\ and solve the problem \\ step-by-step.\\    \\ Let’s first understand the \\ problem and devise a plan \\ to \textbf{cope} the problem. \\ Then let’s carry out the plan \\ and solve the problem\\ step-by-step.\\    \\ Let’s first understand the \\ problem and devise a plan \\ to \textbf{crack} the problem. \\ Then let’s carry out the plan \\ and solve the problem \\ step-by-step.\end{tabular} &
  \begin{tabular}[c]{@{}l@{}}Let’s first understand the \\ problem and devise a plan\\ to \textbf{tackle} the problem. \\ Then let’s carry out the plan \\ and solve the problem \\ step-by-step.\\    \\ Let’s first understand the\\ problem and devise a plan \\ to \textbf{cope} the problem. \\ Then let’s carry out the plan \\ and solve the problem \\ step-by-step.\\    \\ Let’s first understand the \\ problem and devise a plan \\ to \textcolor{red}{\textbf{crack}} the problem. \\ Then let’s carry out the plan \\ and solve the problem \\ step-by-step.\end{tabular} &
  \begin{tabular}[c]{@{}l@{}}Let’s first understand the \\ problem and devise a plan \\ to \textbf{tackle} the problem. \\ Then let’s carry out the plan\\ and solve the problem \\ step-by-step.\\   \\ \textcolor{red}{Let’s first understand the} \\ \textcolor{red}{problem and devise a plan} \\ \textcolor{red}{to \textbf{cope} the problem.} \\ \textcolor{red}{Then let’s carry out the plan} \\ \textcolor{red}{and solve the problem} \\ \textcolor{red}{step-by-step.} \\ \\ \\ \\  \\ \\ \\ \\ \end{tabular} &
  \begin{tabular}[c]{@{}l@{}}Let’s first understand the \\ problem and devise a plan \\ to \textbf{tackle} the problem. \\ Then let’s carry out the plan \\ and solve the problem \\ step-by-step. \\ \\ \\ \\ \\ \\ \\ \\ \\ \\ \\ \\ \\ \\ \\ \end{tabular} \\ \hline
\end{tabular}%
}
\caption{Example of perturbation filtering for classification prompts. Bold words perturbed via synonyms, co-hyponyms, removal. Filtered by semantic similarity (>30\%) and grammar. Rejections in red.}
\label{tab:pert_ex_classification}
\end{table}

\FloatBarrier



% Please add the following required packages to your document preamble:
% \usepackage{graphicx}
% \usepackage[normalem]{ulem}
% \useunder{\uline}{\ul}{}
\begin{table}[H]
\resizebox{\textwidth}{!}{%
\begin{tabular}{lllll}
\hline
\begin{tabular}[c]{@{}l@{}}\textbf{Zero-shot} \\ \textbf{Instructional Prompt}\end{tabular} &
  \textbf{Generated Candidates} &
  \textbf{Semantic Similarity} \textgreater{}30\% &
  \begin{tabular}[c]{@{}l@{}}\textbf{Meaningful and} \\ \textbf{grammatically correct} \end{tabular} &
  \textbf{Final Perturbations} \\ \hline
\begin{tabular}[c]{@{}l@{}}Please provide the translation \\ for the \textbf{following} sentence \\ step-by-step and then provide \\ the complete sentence.\end{tabular} &
  \begin{tabular}[c]{@{}l@{}}Please provide the translation \\ for the \textbf{upcoming} sentence \\ step-by-step and then provide \\ the complete sentence.\\    \\ Please provide the translation \\ for the \textbf{after} sentence \\ step-by-step and then provide \\ the complete sentence.\\    \\ Please provide the translation \\ for the \textbf{next} sentence \\ step-by-step and then provide \\ the complete sentence.\\    \\ Please provide the translation \\ for the \textbf{consecutive} sentence \\ step-by-step and then provide\\ the complete sentence.\end{tabular} &
  \begin{tabular}[c]{@{}l@{}}Please provide the translation \\ for the \textbf{upcoming} sentence \\ step-by-step and then provide \\ the complete sentence.\\    \\ Please provide the translation \\ for the \textbf{after} sentence \\ step-by-step and then provide \\ the complete sentence.\\    \\ Please provide the translation \\ for the \textbf{next} sentence \\ step-by-step and then provide \\ the complete sentence.\\    \\ Please provide the translation \\ for the \textcolor{red}{\textbf{consecutive}} sentence \\ step-by-step and then provide \\ the complete sentence.\end{tabular} &
  \begin{tabular}[c]{@{}l@{}}Please provide the translation \\ for the \textbf{consecutive} sentence \\ step-by-step and then provide \\ the complete sentence.\\    \\ \textcolor{red}{Please provide the translation} \\ \textcolor{red}{for the \textbf{consecutive} sentence} \\ \textcolor{red}{step-by-step and then provide} \\ \textcolor{red}{the complete sentence}.\\    \\ Please provide the translation \\ for the \textbf{next} sentence \\ step-by-step and then provide \\ the complete sentence. \\ \\ \\ \\ \\ \\ \end{tabular} &
  \begin{tabular}[c]{@{}l@{}}Please provide the translation \\ for the \textbf{upcoming} sentence \\ step-by-step and then provide \\ the complete sentence.\\    \\  \\   \\  \\ \\ \\ Please provide the translation \\ for the \textbf{next} sentence \\ step-by-step and then provide \\ the complete sentence.\\ \\ \\ \\ \\ \\  \end{tabular} \\ \hline
\begin{tabular}[c]{@{}l@{}}Please \textbf{detect} the error type \\ firstly and refine the \\ translation then.\end{tabular} &
  \begin{tabular}[c]{@{}l@{}}Please \textbf{observe} the error type \\ firstly and refine the \\ translation then.\\    \\ Please the error type \\ firstly and refine the \\ translation then. (removal)\\    \\ Please \textbf{notice} the error type \\ firstly and refine the \\ translation then.\\    \\ Please \textbf{discern} the error type \\ firstly and refine \\ the translation then.\\    \\ Please \textbf{pick out} the error type \\ firstly and refine \\ the translation then.\end{tabular} &
  \begin{tabular}[c]{@{}l@{}}Please \textbf{observe} the error type \\ firstly and refine\\ the translation then.\\    \\ Please the error type \\ firstly and refine the \\ translation then. \\    \\ Please \textbf{notice} the error type \\ firstly and refine the\\ translation then.\\   \\ Please \textbf{discern} the error type\\ firstly and refine the \\ translation then.\\    \\ Please \textcolor{red}{\textbf{pick out}} the error type \\ firstly and refine the \\ translation then.\end{tabular} &
  \begin{tabular}[c]{@{}l@{}}Please \textbf{observe} the error type \\ firstly and refine \\ the translation then.\\    \\ \textcolor{red}{Please the error type} \\ \textcolor{red}{firstly and refine the}\\ \textcolor{red}{translation then}. \\    \\ Please \textbf{notice} the error type \\ firstly and refine the \\ translation then.\\    \\ Please \textbf{discern} the error type \\ firstly and refine the \\ translation then.\\ \\ \\ \\ \\ \end{tabular} &
  \begin{tabular}[c]{@{}l@{}}Please \textbf{observe} the error type \\ firstly and refine \\ the translation then.\\    \\  \\    \\ \\ \\ Please \textbf{notice} the error type \\ firstly and refine the \\ translation then.\\    \\ Please \textbf{discern} the error type \\ firstly and refine the \\ translation then.\\ \\ \\ \\  \\ \end{tabular} \\ \hline
\end{tabular}%
}
\caption{Example of perturbation filteringg process for translation task prompts. Bold words are perturbed via synonyms, co-hyponyms, and removal. Perturbations are filtered by semantic similarity (>30\%) and grammatical correctness. Rejections in red.}
\label{tab:my-pert_ex_translation}
\end{table}







\begin{table}[htbp]
\centering
\footnotesize
\begin{tabular}{@{}llc cccc@{}}
\toprule
Original Word & Generated Candidates & 20\% & 30\% & 40\% & 50\% \\ \midrule
\multirow{3}{*}{Let's} & We should (49.13\%) & \textcolor{green}{Accept} & \textcolor{green}{Accept} & \textcolor{green}{Accept} & \textcolor{red}{Reject} \\
                       & It is recommended that we (21.29\%) & \textcolor{red}{Accept} & \textcolor{green}{Reject} & \textcolor{green}{Reject} & \textcolor{green}{Reject} \\
                       & We can (51.57\%) & \textcolor{green}{Accept} & \textcolor{green}{Accept} & \textcolor{green}{Accept} & \textcolor{green}{Accept} \\
\midrule
\multirow{2}{*}{First} & Before anything else (47.05\%) & \textcolor{green}{Accept} & \textcolor{green}{Accept} & \textcolor{green}{Accept} & \textcolor{red}{Reject} \\
                       & Right off the bat (25.66\%) & \textcolor{red}{Accept} & \textcolor{green}{Reject} & \textcolor{green}{Reject} & \textcolor{green}{Reject} \\
\midrule
\multirow{2}{*}{Understand} & Perceive (58.85\%) & \textcolor{green}{Accept} & \textcolor{green}{Accept} & \textcolor{green}{Accept} & \textcolor{green}{Accept} \\
                            & Apprehend (42.68\%) & \textcolor{green}{Accept} & \textcolor{green}{Accept} & \textcolor{green}{Accept} & \textcolor{red}{Reject} \\
\midrule
\multirow{3}{*}{Problem} & Dilemma (72.35\%) & \textcolor{green}{Accept} & \textcolor{green}{Accept} & \textcolor{green}{Accept} & \textcolor{green}{Accept} \\
                         & Hurdle (35.48\%) & \textcolor{green}{Accept} & \textcolor{green}{Accept} & \textcolor{red}{Reject} & \textcolor{red}{Reject} \\
                         & Difficulty (60.58\%) & \textcolor{green}{Accept} & \textcolor{green}{Accept} & \textcolor{green}{Accept} & \textcolor{green}{Accept} \\
\midrule
\multirow{3}{*}{Devise} & Design (37.65\%) & \textcolor{green}{Accept} & \textcolor{green}{Accept} & \textcolor{red}{Reject} & \textcolor{red}{Reject} \\
                        & Draft (36.57\%) & \textcolor{green}{Accept} & \textcolor{green}{Accept} & \textcolor{red}{Reject} & \textcolor{red}{Reject} \\
                        & Set up (36.85\%) & \textcolor{green}{Accept} & \textcolor{green}{Accept} & \textcolor{red}{Reject} & \textcolor{red}{Reject} \\
\midrule
\multirow{2}{*}{Plan}   & Procedure (44.23\%) & \textcolor{green}{Accept} & \textcolor{green}{Accept} & \textcolor{green}{Accept} & \textcolor{red}{Reject} \\
                        & Strategy (57.06\%) & \textcolor{green}{Accept} & \textcolor{green}{Accept} & \textcolor{green}{Accept} & \textcolor{green}{Accept} \\
\midrule
\multirow{2}{*}{Solve}  & Crack (29.82\%) & \textcolor{green}{Accept} & \textcolor{red}{Reject} & \textcolor{red}{Reject} & \textcolor{red}{Reject} \\
                        & Tackle (40.75\%) & \textcolor{green}{Accept} & \textcolor{green}{Accept} & \textcolor{green}{Accept} & \textcolor{red}{Reject} \\
\midrule
\multirow{3}{*}{Step-by-step} & Progressively (38.88\%) & \textcolor{green}{Accept} & \textcolor{green}{Accept} & \textcolor{red}{Reject} & \textcolor{red}{Reject} \\
                              & Phase by phase (30.38\%) & \textcolor{green}{Accept} & \textcolor{green}{Accept} & \textcolor{red}{Reject} & \textcolor{red}{Reject} \\
                              & Inch by inch (21.12\%) & \textcolor{red}{Accept} & \textcolor{green}{Reject} & \textcolor{green}{Reject} & \textcolor{green}{Reject} \\
\midrule
\multicolumn{2}{c}{\textbf{Accuracy}} & 85\% & \textbf{95\%} & 65\% & 40\% \\
\bottomrule
\end{tabular}
\caption{Evaluation of semantic similarity thresholds (20\%-50\%) on the 0-PS prompt using 20 manually validated word variants. Each row shows an original word, its generated alternatives with similarity scores, and acceptance decisions across thresholds. Green indicates correct decisions (accept/reject), red indicates incorrect ones. The accuracy row demonstrates that 30\% provides optimal performance (95\%) in identifying meaningfully related perturbations.}
\label{emperical_test}
\end{table}




\FloatBarrier
\subsection{Token Usage per Instructional Prompt}
\label{sec:computation_ap}



\begin{table}[!h]
\centering
\resizebox{\textwidth}{!}{% Resize table to fit within page width
\renewcommand{\arraystretch}{1.5} % Adds padding in the cells for better readability
\begin{tabular}{@{}lcccccccccc@{}}
\toprule
& \multicolumn{3}{c}{AQUA-RAT} & \multicolumn{3}{c}{Big Bench} & \multicolumn{3}{c}{GSM8K} \\ 
\cmidrule(lr){2-4} \cmidrule(lr){5-7} \cmidrule(lr){8-10}
& Input tokens & Output tokens & Total tokens & Input tokens & Output tokens & Total tokens & Input tokens & Output tokens & Total tokens \\ 
\midrule
0-CoT  & 600765 & 1825656 & 2426421 & 871710  & 1204340 & 2076050 & 488985 & 1098887 & 1587872 \\
0-CoTB & 1735827 & 3800599 & 5536426 & 2464368  & 2502721 & 4967089 & 1435263 & 3207869 & 4643132 \\
0-CoTR & 2472444 & 4488703 & 6961147 & 3447846  & 2974113 & 6421959 & 2070036 & 4367080 & 6437116 \\
0-IRR  & 1390389 & 3014827 & 4405216 & 1974426  & 1831424 & 3805850 & 1149441 & 1895271 & 3044712 \\
0-PS   & 4088076 & 9379794 & 13467870 & 5581284  & 6834640 & 12415924 & 3472044 & 7837170 & 11309214 \\
\midrule
Total  & 10287501 & 22509579 & 32797080 & 14339634 & 15347238 & 29686872 & 8615769 & 18406277 & 27022046 \\
\bottomrule
\end{tabular}
}
\caption{Estimation of token usage per instructional prompt across different datasets (AQUA-RAT, Big Bench, and GSM8K) using GPT-4o mini. This table presents the input tokens, output tokens, and total tokens calculated with space-based tokenization. Actual tokenization methods employed by GPT-4o mini may vary, and thus these figures serve as approximations of token usage.}
\label{tab:computations}
\end{table}















\end{document}
