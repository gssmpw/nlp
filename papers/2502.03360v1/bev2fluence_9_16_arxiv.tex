% This is meant to be a helpful template for papers being submitted to
% Medical Physics. It is not mandatory.
%
% Please send suggestions/improvements to elle@aapm.org
% October 08, 2021
%

\documentclass[12pt,twoside]{article}   %For printing on two sides of page
					%It doesn't work with showkeys so
					%if using showkeys, use following
%\documentclass[12pt]{article}		%use with showkeys or to print one sided
\usepackage[super,sort,comma]{natbib}
%\usepackage[super,sort&compress,comma]{natbib}
% use the version without compress to get everything working. Then on ONE,
% and ONLY ONE FINAL RUN, use the version with compress to change 1,2,3,4
% to 1-4 etc in the citations.  Otherwise hyperref gets confused.


\usepackage{fancyhdr}		%Gives headers and footers defined below
\renewcommand{\footrulewidth}{0.4pt} %thickness of line above footer

%\usepackage{showkeys}		%may use for drafting
				%comment out for final submission

\usepackage{amsmath}

%The following is useful for creating captions for figures and tables that have
%a different font and different width on the page. This separates them from
%text.
\newcommand{\captionv}[3]{\begin{center}\parbox{#1cm}{\caption[#2]{{\sf #3}}}
        \end{center}}
	%use as   \captionv{N}{B}{C}
	%first entry,N, is width of caption in cm
	%second entry, B, is a short title that appears in list of figure/tables
	%     B can be blank. The lists are not needed
	%third entry, C, is the caption for the figure or the table
	%    Note that the \label{fig_text} should be part of entry C.

\usepackage[section]{placeins}   %
%above package forces all floats (tables figures) to be processed before a
%new section starts. Unlike using \clearpage, this will start the section
%on the same page as the float, but after it.
%might not work with subsections, but if that is the case, put
%  \FloatBarrier just before the \subsection

\usepackage{graphicx}

%added by me:
\usepackage{booktabs}


%following lines fix up style of bibliography to be superscripts
\makeatletter \renewcommand\@biblabel[1]{$^{#1}$} \makeatother
 \setlength{\bibhang}{0em}
 \setlength{\labelsep}{1em}     
 \setlength{\itemindent}{-\bibhang}
 \setlength{\leftmargin}{\bibhang}


%set dimensions of the page for 8.5x11 inch paper
\setlength{\textwidth}{16.5cm}
\setlength{\headwidth}{16cm}		%for fancy page style only
\setlength{\textheight}{22.6cm} 
\setlength{\oddsidemargin}{-1mm}
\setlength{\evensidemargin}{-2mm} 
\setlength{\topmargin}{-1.0cm}

\setlength{\parindent}{2em}   %indent paragraph 2 letters m
\setlength{\parskip}{1.3ex}   %paragraph break
\setlength{\floatsep}{0pt}
\setlength{\textfloatsep}{0pt}		%space below a figure/table def 20pt
\setlength{\intextsep}{0pt}		%space below a figure/table def 20pt
					%p142 compendium

%Following is for Med Phys numbering  I.A.1  etc
\renewcommand{\thesection}{{\sf \Roman{section}}.}
\renewcommand{\thesubsection}{\thesection{\sf \Alph{subsection}}.}
\renewcommand{\thesubsubsection}{\thesubsection{\sf \arabic{subsubsection}}.}
\renewcommand{\theparagraph}{\alph{paragraph}.}


% following is useful during drafting when you want to flag something for
% other authors or for yourself. It can be used throughout the text.
\newcommand{\note}[1]{\mbox{}\\ \noindent \rule{16cm}{0.5mm} \\
{\em #1} \\ \noindent \rule{16cm}{0.5mm}
\typeout{    }
\typeout{***********note active on this page *************************}
\typeout{Note: #1  }
\typeout{****************************************end Note}
}

% Uncomment the following to remove all notes from the paper
% \renewcommand{\note}[1]{}


% These can be used to identify where a figure or table is first referenced 
% by placing a margin note.  If the figures/tables are inserted in the text
% they are not needed.

\newcommand{\mfig}[1]{\marginpar{{\sf Fig~\ref{#1} }}}
\newcommand{\mtab}[1]{\marginpar{{\sf Table~\ref{#1} }}}

%Following are just useful shortcuts and not mandatory
\newcommand{\cen}[1]{\begin{center} #1 \end{center}}
\newcommand{\eqn}[1]{\begin{equation} #1 \end{equation} }

%The following allow lists to be more compact than the default. Not
%mandatory, but useful.
\newenvironment{packed_enum}{
\begin{enumerate}
  \setlength{\itemsep}{1pt}
  \setlength{\parskip}{0pt}
  \setlength{\parsep}{0pt}
}{\end{enumerate}}

\newenvironment{packed_item}{
\begin{itemize}
  \setlength{\itemsep}{1pt}
  \setlength{\parskip}{0pt}
  \setlength{\parsep}{0pt}
}{\end{itemize}}

\renewcommand{\refname}{}       %

% The following only needed if you use the headers/footers. Not essential
% but can be useful      

% [on even pages]{on odd pages} %even pages only active f using twosided
				%if no even given, uses same for both
% lhead is left head, etc
\lhead[{\sffamily page~\thepage}]{{\sffamily 3D Network for VMAT Planning}}
% the $Date:$ below is replaced by the date the file was last edited when using
% CVS.  If not being used, comment this out.
%\lfoot[{\sf \leftmark}]{{\small {\sf Last edited $Date:$ }}}
\rhead[{\sf Simon Arberet et al.}]{{\sf page~\thepage}}
\rfoot[{\sffamily {\rightmark}}]{{\sffamily {\rightmark}}}
\cfoot{}
\chead{}


% the following is used to suppress many warnings that don't effect the
% output 
\typeout{***Have turned off overfull and underfull messages****}
\tolerance=10000        %suppress Overfull only
\hbadness=10000         %suppress Overfull and Underfull for text (horizontal)
\vbadness=10000         %suppress Overfull and Underfull for vertical "boxes"

% Now set up for line numbers.  If the files lineno.sty is not on the latex
% path, the following assumes it is on the area the .tex file is located.

% Select the way you prefer line numbers by uncommenting the way you prefer.
% I prefer continuous line numbers but don't need them for tables.

% \usepackage[pagewise,mathlines,edtable]{lineno}
% \usepackage[mathlines,edtable]{lineno}
\usepackage[mathlines]{lineno}
%  pagewise => start new line number each page. Otherwise number from start
%  edtable => line num for table. Needs \begin{edtable}{tabular}{|c|}   etc
%                        and \end{edtable}  We don't need \end{tabular}

%\linenumbers
% Comment out the above line and all line numbers are removed EXCEPT in
% tables.   To get rid of those you need to remove edtable at the start and
% stop of the table.

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%               set up hyperref for the pdf outputs
%  This makes all references linked to tables, references etc
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%

\usepackage{hyperref}
\hypersetup{ colorlinks,
    citecolor=blue,
    filecolor=blue,
    linkcolor=blue,
    urlcolor=blue
}

% if lines down to % end \backrefalt are uncommented, => in reference list there
% will be pointers to where the references are used. Useful in drafting
% but should be commented out for submission.
%\usepackage[pagebackref]{hyperref}
%\renewcommand*{\backref}[1]{}
%\renewcommand*{\backrefalt}[4]{%
%  \ifcase #1 %
%    \relax%No citations.% use \relax if do not want the "No citations" message
%  \or
%    (p #2)%
%  \else
%    (pp #2)%
%  \fi%
%}
% end \backrefalt   Always leave this line commented out

% some more options. Just use one hyperref option at a time
%\usepackage[dvipdfm]{hyperref}  %if using latex producing .dvi rather than .pdf
%\usepackage[dvipdfm,pagebackref]{hyperref} %version will show page number
          %that a reference is cited on. Useful for checking they are all used.


\usepackage{xcolor}
        %\textcolor{declared-color}{text}    OR   {\color   text}
        %The difference between \textcolor and \color is the same as that
        %between \texttt and \ttfamily, you can use the one you prefer. The
        %\color environment allows the text to run over multiple lines and
        %other text environments whereas the text in \textcolor must all be
        %one paragraph and not contain other environments.

        %\colorbox{declared-color}{text}   will change background color
\definecolor{gray}{rgb}{0.6,0.6,0.6}
\definecolor{red}{rgb}{0.85,0,0}
\definecolor{green}{rgb}{0,0.85,0}
\definecolor{blue}{rgb}{0,0,0.85}
\definecolor{beige}{rgb}{0.92,0.87,0.78}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\usepackage[all]{hypcap}    %causes link to figures to go to figure, not caption
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\usepackage{caption}

%Simon test
%\usepackage{setspace} % Load the setspace package
%\doublespacing % Uncomment this line for double spacing
%\onehalfspacing

\begin{document}


\cen{\sf {\Large {\bfseries A Beam's Eye View to Fluence Maps 3D Network for Ultra Fast VMAT Radiotherapy Planning } \\  
\vspace*{10mm}
Simon Arberet\textsuperscript{1}, 
Florin C. Ghesu\textsuperscript{2},
Riqiang Gao\textsuperscript{1},
Martin Kraus\textsuperscript{2},
Jonathan Sackett\textsuperscript{3},
Esa Kuusela\textsuperscript{3},
Ali Kamen\textsuperscript{1}
} \\
\textsuperscript{1}Digital Technology and Innovation, Siemens Healthineers, Princeton, NJ, USA\\
\textsuperscript{2}Digital Technology and Innovation, Siemens Healthineers, Erlangen, Germany\\
\textsuperscript{3}Varian Medical Systems, a Siemens Healthineers Company, Helsinki, Finland
%\vspace{4mm}\\
%Version typeset 09/16/2024\\
}

\pagenumbering{roman}
\setcounter{page}{1}
\pagestyle{plain}
simon.arberet@siemens-healthineers.com \\
% note, probably best not to use a student's e-mail as it won't be valid for
% very long.


\begin{abstract}
\noindent {\bf Background:} Volumetric Modulated Arc Therapy (VMAT) revolutionizes cancer treatment by precisely delivering radiation while sparing healthy tissues. 
Fluence maps generation, crucial in VMAT planning, traditionally involves complex and iterative, and thus time consuming processes. 
These fluence maps are subsequently leveraged for leaf-sequence. 
The deep-learning approach presented in this article aims to expedite this by directly predicting fluence maps from patient data.\\
{\bf Purpose:} To accelerate VMAT treatment planning by quickly predicting fluence maps from a 3D dose map. The predicted fluence maps can be quickly leaf sequenced because the network was trained to take into account the machine constraints.\\
{\bf Methods:} We developed a 3D network which we trained in a supervised way using a combination of $L^1$ and $L^2$ losses, and RT plans generated by Eclipse and from the REQUITE dataset, taking the RT dose map as input and the fluence maps computed from the corresponding RT plans as target.
Our network predicts jointly the 180 fluence maps corresponding to the 180 control points (CP) of single arc VMAT plans. In order to help the network, we pre-process the input dose by computing  the projections of the 3D dose map to the beam's eye view (BEV) of the 180 CPs, in the same coordinate system as the fluence maps. 
We generated over 2000 VMAT plans using Eclipse to scale up the dataset size. Additionally, we evaluated various network architectures and analyzed the impact of increasing the dataset size.
\\
{\bf Results:}
We are measuring the performance in the 2D fluence maps domain using  image metrics (PSNR, SSIM), as well as in the 3D dose domain using the dose-volume histogram (DVH) on a validation dataset.
The network inference, which does not include the data loading and processing, is less than 20ms. Using our proposed 3D network architecture as well as increasing the dataset size using Eclipse improved the fluence map reconstruction performance by approximately 8 dB in PSNR compared to a U-Net architecture trained on the original REQUITE dataset.
The resulting DVHs are very close to the one of the input target dose.
 \\
{\bf Conclusions:} 
We developed a novel deep learning approach for ultra fast VMAT planning by predicting all the fluence maps of a VMAT arc in one single network inference.
The small difference of the DVH validate this approach for ultra-fast VMAT planning.
 \\
\end{abstract}
%\note{This is a sample note.}

\newpage     %may or may not be needed


%The table of contents is for drafting and refereeing purposes only. Note
%that all links to references, tables and figures can be clicked on and
%returned to calling point using cmd[ on a Mac using Preview or some
%equivalent on PCs (see View - go to on whatever reader).

%\tableofcontents

\newpage

%\setlength{\baselineskip}{0.7cm}      %double spacing		


\pagenumbering{arabic}
\setcounter{page}{1}
\pagestyle{fancy}
\section{Introduction}

Volumetric modulated arc therapy (VMAT) is a modern radiation therapy technique that allows for the delivery of highly conformal dose distributions to tumors. 
One of the key steps in VMAT planning is the generation of fluence maps, which are used to control the intensity of the radiation beam as it rotates around the patient.

Traditionally, fluence maps for VMAT planning are generated within an optimization algorithm \cite{otto2008volumetric, liu2018comparison}. 
These algorithms can be computationally expensive and time-consuming, especially for complex cases. 
Indeed they need to perform many iterations between a leaf-sequencing step which tries to reproduce a target fluence map, and a gradient step which tries to minimize a dose objective,
and also rely on a multi-resolution approach which divide the arc in multiple sectors in order to avoid converging into local minima.

On the other hand, recent developments in predicting 3D radiation dose distributions from planning structure sets have shown promise in the literature \cite{mcintosh2017fully, kearney2018dosenet, zhan2022multi, gao2023flexible}. In this article, we leverages this progress, offering a modular framework for fluence map prediction from 3D dose maps. This modularization aims to simplify the radiation therapy planning process and improve prediction accuracy.

Recent articles have explored the application of deep learning for direct fluence map prediction in Intensity-Modulated Radiation Therapy (IMRT). However, existing methods \cite{wang2020fluence, lee2019fluence, wang2021deep} adopt an approach that processes each fluence map independently, inadvertently preventing the maps from synergistically contributing to the global treatment objective. This approach neglects the potential benefits of leveraging the complementarity between fluence maps. % such as accommodating one map's emphasis on a specific organ dose requirements in the context of other fluence maps.

For VMAT, it's even more crucial to process all fields together because the continuous motion of the MLC requires an interconnected prediction strategy. Independent processing of individual fluence maps misses the necessary continuity of the MLC's dynamic leaf sequence.
%In the case of VMAT, this limitation assumes even greater significance. The continuous motion of the Multi-Leaf Collimator (MLC) across the arc demands a comprehensive and interconnected prediction strategy. This necessity stems from the fact that independent processing of individual fluence maps fails to capture the essential continuity required by the MLC's dynamic leaf sequence. 
Fluence map estimation for VMAT has also been explored in other studies \cite{ma2020deep, ma2021generalizability, zhu20223d}, where the authors used a 3D U-Net network to predict the fluence maps. % of a phantom, and then adapt the fluence maps of the phantom to the geometry of the patient with an heuristic approach coined ``fluence map scaling''. 

In this article, we introduce a novel deep learning approach for predicting fluence maps in VMAT planning. Our method involves an initial transformation of the input 3D dose map into a new 3D representation, where the gantry's rotation corresponds to a translation that can be effectively utilized by CNNs. This transformation is achieved by projecting the dose map into the beam eye views (BEV) of each control point. Subsequently, we employ a 3D convolutional neural network architecture featuring advanced ConvNeXt \cite{liu2022convnet} building blocks to predict all fluence maps simultaneously.
The advantage of having a 3D CNN compared to a 2D CNN is that the convolution in the depth dimension which corresponds to the gantry rotation dimension is also processed with convolutions and the dynamic of the leaf-pairs motions and other gantry rotation equivariance behaviours can be well captured by convolutions thanks to their translation equivariance property.
On the other hand the final dose is the result of the contribution of all the fluence maps without any particular order, and as such long range dependencies along the gantry dimension are also important and it is where ConvNeXt blocks that mimic Transformers operations can help compared to more classical convolution blocks used in U-Net \cite{cciccek20163d} or ResNets blocks \cite{he2016deep}.   

%In this article, we propose a new deep learning method for the prediction of fluence maps in VMAT planning. Our method is based on the idea of first applying a change of representation by transforming the input 3D dose map into a new 3D representation, where rotation of the gantry corresponds to a translation and thus can be taken advante of by CNNs, and which is obtained by projecting the dose map into the beam's eye views (BEV) of each of the control points, and then using a 3D network architecture to process and predict all the fluence maps at once.

Moreover we scaled up the training dataset, using Eclipse Scripting API (ESAPI) to recompute the optimization of plans of the REQUITE dataset \cite{seibold2019requite} for Varian VMAT single arc. 
This allows us to scale our dataset focused on Prostate VMAT single arc from about 100 cases to more than 2000 cases.
These plans are composed of 180 control points spaced by 2 degrees between each consecutive control point and doing a full arc rotation. % (181 degrees to 179 degrees counter clock wise). 


% on recent advances in 3D convolutional neural network (CNN) that first transforms the input 3D dose map into a new 3D representation, where rotation of the gantry corresponds to a translation, by projecting it into the beam's eye views (BEV) of each of the control points, and then  predicts all the fluence maps of all the control points at once. Our method is trained in a supervised way on the fluence maps generated using optimized plans from the REQUITE dataset \cite{seibold2019requite}.

%We focus on Varian single arc VMAT plan on Prostate cases only. These plans are composed of 178 control points spaced by 2 degrees between each consecutive control point and doing almost a full rotation (181 degrees to 179 degrees counter clock wise). 
This focus on a particular machine type is motivated by the interplay between machine constraints, Multi-Leaf Collimators (MLCs), and optimization algorithms, all of which are intrinsically machine-dependent. 


%This is a citation to an article\cite{Da98a}.

%A citation to a technical report\cite{NS00}.

%A citation to a chapter in a book\cite{BR89}.

%A citation to a book\cite{AS64}.

%\subsection{First subsection}
%Here is a reference to the figure~\ref{fig_example}\mfig{fig_example} with
%a margin note.
%\subsubsection{First subsubsection}

\section{Methods}

In order to train a network to predict the fluence maps from a 3D dose map, we are using a dataset of RT plans which contains the optimized MLC positions and MU values of each of the control points covering the single VMAT arc as well as the 3D dose map calculated from these optimized MLC positions and MU values.
Using the MLC positions and MU values, we compute the fluence maps. Our fluence maps calculation model includes the leaf leakage and motion in between control points but ignores tongue-and-groove effect.
In order to simplify the task of the network, we transform the 3D dose map in the BEV of each control point, such that these dose projections are in the same geometry as the fluence maps.
Also as in this new representation, rotation of the gantry is transformed into a translation, we are using for the first time a 3D convolutional network architecture, instead of 2D as usually done in the litterature \cite{ma2020deep, ma2021generalizability}, in order to exploit translation equivariance in the gantry direction.

\subsubsection{Data}
We are using the REQUITE dataset and focus on Varian single arc VMAT plans.
The original REQUITE dataset \cite{seibold2019requite} contains 117 plans (which we split in 96 for training, 11 for validation), all prostate cases, with arcs covering a range of $358^\circ$ (almost full rotation) in 178 control points. In this collection of RT Plans, collimators angle varies depending of the plan but most of the cases have $30^\circ$ or $45^\circ$ angles and stay fix during each arc. The couch angle is zero for all the cases.
Among these 117 cases, 69 cases are using the Varian High-Definition 120 MLC (HD120) model from Varian, and 48 are using the Varian Millennium 120 ( M120) model. Both of these models are using 60 leaf pairs, but the HD120 model have a smaller leaf width (2.5 mm for the 32 inner leaf pairs and 5 mm for the 28 outer leaf pairs, vs 5 mm for the 40 inner leaf pairs and 10 mm for the 20 outer leaf pairs for the M120 model).
Most of the arc rotation directions are clock-wise and only 6 follow a counter clock-wise direction. Anyway, we arrange the 178 control points in increasing degree order (counter clock-wise) so that the network is agnostic to the rotation direction.
The plan can be executed in the other direction by simply reversing the order of the control points.

As this dataset is very small, one of our contribution is to increase the dataset size by using all the prostate plans of the REQUITE dataset, including those which were not planed for Varian single arc VMAT, and replan them using Eclipse Scripting API (ESAPI) \cite{gao2025automating}. 
% using either point objectives used in Varian Medical Affairs or line objectives extracted from the original REQUITE clinical plans.
This way we could increase the dataset size from 117 to around 2266 plans.
These new plans generated with Eclipse contain 180 control points equispaced by $2^\circ$, a fixed collimator angle of $30^\circ$. The couch angle is zero for all the cases.
Among these 2266 generated plans, 1161 cases are using the HD120 MLC, and 1105 are with the M120 MLC.


\subsubsection{Preprocessing}
We compute the fluence maps of the 180 control points of the single VMAT arc, as well as their corresponding dose BEV projections which are stacked to create a 3D tensor that is passed to our 3D network as illustrated in figure \ref{fig_BEVtransform}. We also compare our 3D network, which we present in the next section, with a 3D U-Net, and a 2D U-Net where the BEV projections are passed to the network in the input channel dimension. 
The calculation of these BEV projections take into account the gantry angle, the collimator angle, the couch angle (which was zero in all our experiments so actually had no effect in the projection), the isocenter, and the spacing and origins of the fluence maps and 3D dose maps respectively.

\begin{figure}[ht]
   \begin{center}
   \includegraphics[width=14cm]{./figures/BEVtransform.png}
   %
   %  conclusion, use directly created .pdf from agr for best results.
   %
   \captionv{16}{}{BEV transform of the 3D dose map.
   \label{fig_BEVtransform} 
    }  %note label inside caption
    \end{center}
\end{figure}

\subsubsection{Network architecture}

The 180 dose BEV projections are stacked to create a 3D tensor which is fed to the 3D network. These 180 BEV projections are sorted in increasing gantry angle degrees so that the network is agnostic to the gantry rotation direction.
The network predicts the corresponding 2D fluence maps on the 180 slices of the network output 3D volume. 

Our network architecture, depicted in figure \ref{fig_MedNeXT3D}, has four downsampling steps which decrease the three dimensions of the feature maps by a factor 2. In order to accommodate for these 4 downsampling steps by a factor 2, we first perform a circular padding in order to increase the gantry dimension from 180 to 192, and then
the output of the network is cropped accordingly to reduce the gantry dimension back to 180.  

%\begin{figure}[ht]
%   \begin{center}
%   \includegraphics[width=14cm]{./figures/DIDN.png}
%   %
%   %  conclusion, use directly created .pdf from agr for best results.
%   %
%   \captionv{16}{DIDN network for VMAT fluence maps prediction}{
%The network takes the BEV projections of the dose on multiple input channels, and output the corresponding fluence maps predictions on the same number of output channels.
%In this picture two Down-Up Blocks (DUBs) are depicted, but in our settings we used 6 of them.
%   \label{fig_didn} 
%    }  %note label inside caption
%    \end{center}
%\end{figure}

\begin{figure}[ht]
   \begin{center}
   \vspace{20pt} % Add 20pt of space before the figure
   \includegraphics[width=14cm]{./figures/MedNeXt3D.png}
   %
   %  conclusion, use directly created .pdf from agr for best results.
   %
   \captionv{16}{3D convolution network for VMAT fluence maps prediction}{
Our 3D network (3D MedNeXt) takes the BEV transform of the dose map as input, and output a 3D tensor where each slice is the fluence map prediction of one of the 180 control points.
   \label{fig_MedNeXT3D} 
    }  %note label inside caption
    \end{center}
\end{figure}

The network architecture is a 3D MedNeXt architecture \cite{roy2023mednext}, which is a 3D U-Net like encoder-decoder architecture, but where residual ConvNeXT blocks \cite{liu2022convnet} are used in place of the traditional convolutional blocks, up and downsampling blocks.
ConvNeXt blocks were introduced in order to create a simple, efficient and scalable architecture that combines the strengths of both CNNs and Transformers and showed improved performance compared to ViT \cite{dosovitskiy2020image} and Swin Transformer \cite{liu2021swin}.
Each ConvNeXt block in our architecture contains a depthwise convolution layer with a kernel size of $3\times3\times3$ followed by a channel-wise group norm, then a $1\times1\times1$ convolution (expansion layer) which expands the number of channels by a factor 4 , 
followed by a Gaussian Error Linear Unit (GELU) activation function, followed by a $1\times1\times1$ convolutional layer (compression layer) which performs a channel-wise compression of the feature maps by a factor 4.
These three layers (depthwise convolution, expansion and compression) mimic the Transformer block architecture.

%  Gaussian Error Linear Unit, or GELU [32], which can be thought of as a smoother variant of ReLU. Used in BERT, GPT2, ViTs. Same accuracy though. --> no need to mention it then.

%The network architecture is a Deep Iterative Down-Up Network architecture \cite{yu2019deep, hammernik2019sigma}.
%Down-Up Networks (DUNs) are a type of neural network that have been shown to be effective for image restoration tasks such as denoising and super-resolution. 
%DUNs are more memory efficient than conventional networks such as U-Net because they perform the bulk of the computations on a coarser scale. 

%The DUN architecture consists of two main parts: a downsampling path and an upsampling path. The downsampling path progressively reduces the resolution of the image, while the upsampling path reconstructs the image at its original resolution. 
%The two paths are connected by a series of Down-Up Blocks (DUBs). Each DUB is similar to a U-Net but with improved residual connections and the use of sub-pixel convolutions for the upsampling operations.

%In our implementation, we used  an initial number of 64 filters, which double after each downsampling, 6 residual Down-Up blocks (DUB), and we did not use any global residual connection. 
%The reconstruction block of \cite{yu2019deep} was also replaced by a simple concatenation as in \cite{hammernik2019sigma}.

We compare this 3D MedNeXt model with a 2D U-Net \cite{ronneberger2015u} that stacks the 180 control points in the input and output channel dimensions and a 3D U-Net \cite{cciccek20163d} that perform the same data preprocessing (BEV projections, padding) and post-processing (cropping) as our 3D MedNeXt.
These 2D and 3D U-Nets contain 4 downsampling and upsampling layers (i.e. 5 scales) as for our 3D MedNeXt network, and 64 channels in the first convolutional layer and the number of channels is doubled after each downsampling layer.

%\subsubsection{Training}
%This section should describe the training procedure, including the optimizer, the loss function, and the hyperparameters.


%In order to improve the training, we also relied on a curriculum learning strategy, where we perfomed the training in multiple stages, starting with a decreased complexity by strongly downsampling the input and output of the network in order to reduce the dimensionality of the problem, and by progressively increase the resolution until it reach its final resolution. We started at a resolution of 32x32, then 64x64, and finally 80x80 which is the final dimensionality of the fluence maps. 

\subsubsection{Experiments}

We trained our networks in a supervised way, using a combination of L1 and L2 loss, ADAM optimizer with a learning rate of 0.0001 and a batch size of 1.

%This section should describe the evaluation procedure, including the metrics that were used to evaluate the performance of the network.
Our dataset of 2266 plans was split in 1868 plans for the training and 193 for the validation. 
We used Peak signal-to-noise ratio (PSNR)\footnote{The maximum value of the target fluence maps is used as the “peak” value in the PSNR equation.} and structural similarity index measure (SSIM) as an image-based metrics to measure the error between the network predicted fluence maps and the target fluence maps.
We used these two metrics to compare the methods in our ablation study and select the best method. Then we computed the dose of the best method using the Acuros AXB dose calculation function in order to compute the mean absolute error (MAE) in Gy, as well as generating the dose-volume histograms (DVH) of the target vs our network prediction.

In a first experiment we compare the 2D and 3D U-Nets which are commonly used in the litterature \cite{ma2020deep, ma2021generalizability, lee2019fluence, wang2020fluence}, with our 3D network on the original REQUITE dataset (Varian VMAT single arc), i.e. by training and testing on the original REQUITE data of 117 plans.

Then we train our models on the full set of Eclipse generated plans as well as two randomly selected subsets of this dataset (see table \ref{tab:datasets}): one of 117 plans as in the original REQUITE data, and another of 500 plans (411 for training, 44 for validation) and evaluate these models on both the full dataset and the subset datasets in order to assess the effect of the dataset size on the performance. 

Finally we compute the dose and compute the DVHs in order to validate that the predicted fluence maps of the best method can reproduce the target dose. 

%We also computed the dose from the predicted network fluence maps using Acuros AXB dose calculation function and compared it with the dose calculation obtained using the target fluence maps. Using these dose calculations, we computed the mean absolute error (MAE) in Gy between these 3D dose maps and the dose-volume histograms (DVH) of the target vs the network prediction. 

\begin{table}
\centering
\caption{Dataset names and the number of plans they contains.}
\label{tab:datasets}
\vspace*{2ex}
\begin{tabular}{lcc}
\toprule
dataset name & short name &  Total \# of plans (\# in training / \# in validation) \\
\midrule
Eclipse REQUITE (full) & Ecl. full & 2266 (1868 / 193) \\
Eclipse REQUITE 500 & Ecl. 500 & 500 (411 / 44)  \\
Eclipse REQUITE 117 & Ecl. 117 & 117 (96 / 12)  \\
Original REQUITE & orig. REQ.& 117 (96 / 11)  \\
\bottomrule
\end{tabular}
\end{table}

\section{Results}

The quantitative results on the original REQUITE dataset are depicted in table \ref{tab:comparison_REQUITE}.
As can be observed, the propose 3D network improved PSNR and SSIM, 5.58 dB compared to 2D U-Net is and 3 dB compared to 3D U-Net.

The quantitative results on the Eclipse generated dataset are depicted in table \ref{tab:comparison_Eclipse} and an example of fluence maps prediction is depicted in figure \ref{fig_fluence_maps}.
We can observe again that our 3D network improves significantly the PSNR and SSIM over the 2D and 3D U-Net, 5.55 dB compared to 2D U-Net is and 6.51 dB compared to 3D U-Net.
We can also notice that increasing the dataset size improved significantly the performance.
For our 3D MedNeXt, the increase from $\sim$100 (Ecl. 117) plans to $\sim$400 (Ecl. 500) plans in the training led to an increase of performance of 2.1 dB, and the increase from $\sim$400 plans (Ecl. 500) to $\sim$1900 plans (Ecl. full)
 led to an increase of performance of 2.69 dB. So the total increase of performance due to the dataset size increase from $\sim$100 (Ecl. 117) to $\sim$1900 plans (Ecl. full) was 4.79 dB.


\begin{figure}[ht]
   \begin{center}
   \vspace{20pt} % Add 20pt of space before the figure
   \includegraphics[width=14cm]{./figures/fluence_maps.png}
   %
   %  conclusion, use directly created .pdf from agr for best results.
   %
   \captionv{16}{3D convolution network for VMAT fluence maps prediction}{
Example from the validation set, showing the fluence maps of the 180 control points of a VMAT plan predicted by our 3D MedNeXt network compared to the corresponding target fluence maps.
   \label{fig_fluence_maps} 
    }  %note label inside caption
    \end{center}
\end{figure}

\begin{table}
\centering
\caption{Comparison of our 3D MedNeXt with the 2D and 3D U-Net (baselines), all trained and validated on the original REQUITE dataset of 117 plans (96 for training, 11 for validation).}
\label{tab:comparison_REQUITE}
\vspace*{2ex}
\begin{tabular}{lc}
\toprule
Method &  PSNR/SSIM on  original REQUITE \\
\midrule
3D MedNeXt trained on original REQUITE & \textbf{24.91 dB} / \textbf{0.9325} \\
3D U-Net trained on original REQUITE & 21.91 dB / 0.3588  \\
2D U-Net trained on original REQUITE & 19.33 dB / 0.7657  \\
\bottomrule
\end{tabular}
\end{table}

\begin{table}
\centering
\caption{Comparison of our 3D MedNeXt network with the 2D and 3D U-Net (baselines), trained and validated on the Eclipse REQUITE dataset (2266 plans), and subsets of 500 plans and 117 plans.}
\label{tab:comparison_Eclipse}
\vspace*{2ex}
\begin{tabular}{lcc}
\toprule
Method &  PSNR/SSIM on Ecl. 500  & PSNR/SSIM on Ecl. full \\
\midrule
3D MedNeXt trained on Ecl. full & \textbf{28.72 dB} / \textbf{0.9721} & \textbf{28.71 dB} / \textbf{0.9712} \\
3D MedNeXt trained on Ecl. 500 & 26.01 dB / 0.9485 & 26.02 dB / 0.9481  \\
3D MedNeXt trained on Ecl. 117 & 23.90 dB / 0.9191 & 23.92 dB / 0.9199  \\
3D U-Net trained on Ecl. full & 21.90 dB / 0.2458 & 22.20 dB / 0.2664 \\
3D U-Net trained on Ecl. 500 & 21.85 dB / 0.5494 & 22.00 dB / 0.5618  \\
3D U-Net trained on Ecl. 117 & 17.76 dB / 0.1548 & 17.97 dB / 0.1687  \\
2D U-Net trained on Ecl. full  & 23.18 dB / 0.8918 & 23.16 dB / 0.8916 \\
2D U-Net trained on Ecl. 500  & 21.80 dB / 0.8543 & 21.82 dB / 0.8548 \\
2D U-Net trained on Ecl. 117  & 20.46 dB / 0.7845 & 20.64 dB / 0.7963 \\
\bottomrule
\end{tabular}
\end{table}

% the difference can be explained by the fact that the subset only contains one type of MLC.

%An ablation study is depicted in table \ref{tab:ablation} to measure the individual impact of the curriculum training and the model architecture. As can be observed, both contribute to the improved performance.

%We also compare our AI-based method versus a standard non AI-based method, the Dynamic Conformal Arc (DCA), which is sometime used as an initialization for VMAT \cite{liu2018comparison}.
%In DCA, the aperture corresponds to the support of the PTV BEV projection, i.e. its shape conforms to the PTV based on the BEV as the gantry rotates around the patient, and the MU value remains constant and such that the total dose delivered equals the prescribed dose.
%In order to compute the MU value for the DCA, we first compute the aperture using the PTV BEV projections in each control point and assign a constant MU, e.g. equals to the meterset divided by the number of control points.
%We then compute the dose deposition and re-adjust the constant MU value such that the total dose deposition of the DCA equals the total dose deposition of the target.
%Note that this approach involves a dose computation step to adjust the MU value and thus is much more time consuming than the proposed AI approaches.
%Results in \ref{tab:ablation} show that our proposed DIDN wC improved the dose MAE by $42\%$ compared to DCA.
%
%%\begin{table}
%%\centering
%%\caption{Comparison of U-Net (baseline) and DIDN with curriculum on PSNR, SSIM, and MAE metrics}
%%\label{tab:comparison}
%%\vspace*{2ex}
%%\begin{tabular}{ccccc}
%%\toprule
%%Metric & Domain & U-Net & DIDN wC & Improvement (\%) \\
%%\midrule
%%PSNR & 2D fluence maps & 19.87 dB & 20.43 dB & 2.8 \\
%%SSIM & 2D fluence maps & 0.8345 & 0.8495 & 1.8 \\
%%MAE & 3D dose & 0.5495 & 0.4462 & 18.8 \\
%%\bottomrule
%%\end{tabular}
%%\end{table}
%
%
%\begin{table}
%\centering
%\caption{Ablation study comparing U-Net and DIDN with (wC) and without (woC) curriculum learning.}
%\label{tab:ablation}
%\vspace*{2ex}
%\begin{tabular}{ccccccc}
%\toprule
%Metric & Domain & U-Net woC & U-Net wC & DIDN woC &  DIDN wC & DCA\\
%\midrule
%PSNR & 2D fluence maps & 19.87dB& \textbf{20.44dB}  & 20.19dB & \textbf{20.43dB} & N.A. \\
%SSIM & 2D fluence maps & 0.8345 & 0.8374 &  0.8415 & \textbf{0.8495} & N.A.  \\
%MAE & 3D dose & 0.5495 & 0.4490  & 0.4555 & \textbf{0.4462} &  0.7699 \\
%\bottomrule
%\end{tabular}
%\end{table}

%\vspace{1cm} % This adds 1cm of vertical space after the table

%We decpict the DVH of the U-Net and DIDN with curriculum models in the following figures \ref{tab:dvh}.
We also depicted in figure \ref{tab:dvh} few DVHs examples obtained by our 3D MedNeXt network. They are randomly selected from the validation set of the full Eclipse datasset.
We also inspected all the DVHs of the validation dataset, and fund that they all looked similar in accuracy as the one depicted in figure \ref{tab:dvh}.

%The first example is an average case in terms of MAE, the second example, is the best case in terms of MAE for the DIDN, and the third example is the worst case in terms of MAE for DIDN.

%\begin{table}
%\centering
%\caption{Comparison of U-Net and DIDN on three examples}
%\label{tab:dvh}
%\begin{tabular}{ccc}
%\noalign{\vskip 1mm}
%\multicolumn{3}{c}{\textbf{U-Net}} \\
%%\hline
%\includegraphics[width=0.3\textwidth]{./figures/Unet_64chan_4layers_ss1_v3/dvh_RQ44334-0.png} & \includegraphics[width=0.3\textwidth]{./figures/Unet_64chan_4layers_ss1_v3/dvh_RQ14271-5.png} & \includegraphics[width=0.3\textwidth]{./figures/Unet_64chan_4layers_ss1_v3/dvh_RQ14097-7.png} \\
%\noalign{\vskip 1mm}
%%\hline
%\multicolumn{3}{c}{\textbf{DIDN with curriculum}} \\
%%\hline
%\includegraphics[width=0.3\textwidth]{./figures/DIDN_64chan_5resBl_curr32_64_80/dvh_RQ44334-0.png} & \includegraphics[width=0.3\textwidth]{./figures/DIDN_64chan_5resBl_curr32_64_80/dvh_RQ14271-5.png} & \includegraphics[width=0.3\textwidth]{./figures/DIDN_64chan_5resBl_curr32_64_80/dvh_RQ14097-7.png} \\
%\noalign{\vskip 1mm}
%%\hline
%\end{tabular}
%\end{table}


\begin{table}
\centering
\captionsetup{position=bottom} % Set caption position for tables to bottom locally
%\caption{DVHs of our 3D MedNeXt network. We show the first four examples of our validation dataset.}
%\label{tab:dvh}
%\begin{tabular}{\textwidth}{ @{} cccc@{} }  % Adjust column specifiers as needed
\begin{tabular}{cc}  % Adjust column specifiers as needed
  \includegraphics[width=0.45\textwidth]{./figures/dvh_Export_batch1_RQ50158-7_934_optimal_mu.png} & \includegraphics[width=0.45\textwidth]{./figures/dvh_Export_batch1_RQ50061-5_856_optimal_mu.png} \\
  \includegraphics[width=0.45\textwidth]{./figures/dvh_Export_batch1_RQ50011-8_014_optimal_mu.png} & \includegraphics[width=0.45\textwidth]{./figures/dvh_Export_batch1_RQ44336-4_117_optimal_mu.png} \\
\end{tabular}
\captionof{figure}{DVHs of our 3D MedNeXt network. We show four examples from our validation dataset. The plain lines are the DVHs calculated from the target fluence maps and the dashed lines are the DVHs calculated from the fluence maps predicted by our network. \label{tab:dvh}}
\end{table}


%\begin{table}
%\centering
%\caption{Comparison of U-Net and DIDN with curriculum on three examples (average case, best case, worst case)}
%\label{tab:dvh}
%\begin{tabular}{cccccccc}
%& \multicolumn{3}{c}{\textbf{U-Net}} & & \multicolumn{3}{c}{\textbf{DIDN wC}} \\
%%Example & DVH & PSNR & SSIM & MAE & DVH & PSNR & SSIM & MAE \\
%
%\rotatebox{90}{Example 1: average case}
%& \multicolumn{3}{c}{\includegraphics[width=0.45\textwidth]{./figures/Unet_64chan_4layers_ss1_v3/dvh_RQ44334-0.png}}   & &  \multicolumn{3}{c}{\includegraphics[width=0.45\textwidth]{./figures/DIDN_64chan_5resBl_curr32_64_80/dvh_RQ44334-0.png}}  \\ 
%& \multicolumn{3}{c}{
%\begin{minipage}{0.45\textwidth}
%\centering
%\scalebox{0.75}{\begin{tabular}{ccc}
%PSNR & SSIM & MAE \\
%18.73 dB & 0.8659 & 0.9766 \\
%\end{tabular}}
%\end{minipage}} & &
%\multicolumn{3}{c}{
%\begin{minipage}{0.45\textwidth}
%\centering
%\scalebox{0.75}{\begin{tabular}{ccc}
%PSNR & SSIM & MAE \\
%20.28 dB & 0.8836 & 0.3999 \\
%\end{tabular}}
%\end{minipage}} \\
%
%\rotatebox{90}{Example 2: best case} &
%\multicolumn{3}{c}{\includegraphics[width=0.45\textwidth]{./figures/Unet_64chan_4layers_ss1_v3/dvh_RQ14271-5.png}}   & &  \multicolumn{3}{c}{\includegraphics[width=0.45\textwidth]{./figures/DIDN_64chan_5resBl_curr32_64_80/dvh_RQ14271-5.png}}  \\
%\multicolumn{3}{c}{
%\begin{minipage}{0.45\textwidth}
%\centering
%\scalebox{0.75}{\begin{tabular}{ccc}
%PSNR & SSIM & MAE \\
%18.28 dB & 0.8615 & 0.2018 \\
%\end{tabular}}
%\end{minipage}} & &
%\multicolumn{3}{c}{
%\begin{minipage}{0.45\textwidth}
%\centering
%\scalebox{0.75}{\begin{tabular}{ccc}
%PSNR & SSIM & MAE \\
%18.84 dB & 0.8746 & 0.1554 \\
%\end{tabular}}
%\end{minipage}} \\
%
%\rotatebox{90}{Example 3: worst case} &
%\multicolumn{3}{c}{\includegraphics[width=0.45\textwidth]{./figures/Unet_64chan_4layers_ss1_v3/dvh_RQ14097-7.png}}   & &  \multicolumn{3}{c}{\includegraphics[width=0.45\textwidth]{./figures/DIDN_64chan_5resBl_curr32_64_80/dvh_RQ14097-7.png}}  \\
%\multicolumn{3}{c}{
%\begin{minipage}{0.45\textwidth}
%\centering
%\scalebox{0.75}{\begin{tabular}{ccc}
%PSNR & SSIM & MAE \\
%20.31 dB & 0.8005 & 0.7024 \\
%\end{tabular}}
%\end{minipage}} & &
%\multicolumn{3}{c}{
%\begin{minipage}{0.45\textwidth}
%\centering
%\scalebox{0.75}{\begin{tabular}{ccc}
%PSNR & SSIM & MAE \\
%20.38 dB & 0.8124 & 0.8172 \\
%\end{tabular}}
%\end{minipage}} \\
%
%\end{tabular}
%\end{table}


%1 &  \includegraphics[width=0.3\textwidth]{./figures/Unet_64chan_4layers_ss1_v3/dvh_RQ44334-0.png} & 30.5 & 0.92 & 5.2 &  \includegraphics[width=0.3\textwidth]{./figures/DIDN_64chan_5resBl_curr32_64_80/dvh_RQ44334-0.png} & 31.2 & 0.93 & 5.0 \\
%\hline
%2 & \includegraphics[width=0.3\textwidth]{./figures/Unet_64chan_4layers_ss1_v3/dvh_RQ14271-5.png} & 30.7 & 0.90 & 5.1 &  \includegraphics[width=0.3\textwidth]{./figures/DIDN_64chan_5resBl_curr32_64_80/dvh_RQ14271-5.png} & 31.0 & 0.91 & 4.9 \\
%\hline
%3 & \includegraphics[width=0.3\textwidth]{./figures/Unet_64chan_4layers_ss1_v3/dvh_RQ14097-7.png} & 30.6 & 0.91 & 5.0 &  \includegraphics[width=0.3\textwidth]{./figures/DIDN_64chan_5resBl_curr32_64_80/dvh_RQ14097-7.png} & 31.1 & 0.92 & 4.8 \\
%\hline

%
%\begin{table}
%\centering
%\caption{Comparison of U-Net and DIDN on three examples}
%\label{tab:dvh}
%\begin{tabular}{c|c|ccc|ccc}
%\multicolumn{1}{c}{} & \multicolumn{1}{c}{\textbf{Method}} & \multicolumn{3}{c}{\textbf{U-Net}} & \multicolumn{3}{c}{\textbf{DIDN}} \\
%\cline{2-8}
%Example & & PSNR & SSIM & MAE & PSNR & SSIM & MAE \\
%\hline
%1 & U-Net & \includegraphics[width=0.3\textwidth]{./figures/Unet_64chan_4layers_ss1_v3/dvh_RQ44334-0.png} & 30.5 & 0.92 & 5.2 & \vline & \includegraphics[width=0.3\textwidth]{./figures/DIDN_64chan_5resBl_curr32_64_80/dvh_RQ44334-0.png} & 31.2 & 0.93 & 5.0 \\
%\hline
%2 & U-Net & \includegraphics[width=0.3\textwidth]{./figures/Unet_64chan_4layers_ss1_v3/dvh_RQ14271-5.png} & 30.7 & 0.90 & 5.1 & \vline & \includegraphics[width=0.3\textwidth]{./figures/DIDN_64chan_5resBl_curr32_64_80/dvh_RQ14271-5.png} & 31.0 & 0.91 & 4.9 \\
%\hline
%3 & U-Net & \includegraphics[width=0.3\textwidth]{./figures/Unet_64chan_4layers_ss1_v3/dvh_RQ14097-7.png} & 30.6 & 0.91 & 5.0 & \vline & \includegraphics[width=0.3\textwidth]{./figures/DIDN_64chan_5resBl_curr32_64_80/dvh_RQ14097-7.png} & 31.1 & 0.92 & 4.8 \\
%\hline
%\end{tabular}
%\end{table}


%It can be seen on the first (average case) and second example (best case) of the DVHs of the DIDN with curriculum are closer to the target dose than the U-Net, while on the third example, the U-Net DVH is closer to the target.


%\subsubsection{Reproducibility}
%This section should provide information that will help other researchers to replicate the study, such as the software that was used, the hyperparameters, and the data that was used.

%\note{Note that the annoying labels which are showing can be removed by
%commenting out the line saying
%{\tt usepackage\{showkeys\}}.  But while
%drafting it is useful to have the labels/keys for the figures, equations
%etc showing.  Please turn them off when submitting the article for review. }


%\newpage     %This is set up for tables and figures at end of text but they 
%	     %may be in the text and is strongly preferred that way by some
%	     %referees.
%
%\section{Tables}
%\begin{table}[htbp]
%\begin{center}
%\captionv{10}{Short title for list of figures - can be blank}{Note that
%tables and figures are to be in the text now, not at the end as required 
%prior to 2014.
%Caption goes here.  It can be long.   It can be long.   It can be
%long.   It can be long.   It can be long. 
%\label{tab_label}
%\vspace*{2ex}
%}
%\begin{tabular} {|l|c|c|c|c|}
%%\begin{edtable}{tabular} {|l|c|c|c|c|}
%\hline
%        &               \multicolumn{2}{c|}{}               &
%\multicolumn{2}{c|}{}        \\
%Chamber &\multicolumn{2}{c|}{4 V / S}&\multicolumn{2}{c|}{Monte Carlo}\\
%\cline{2-5}
%        & L mm          & $\Delta$ keV  & L mm          & $\Delta$ keV   \\
%\hline
%        &               &               &               &        \\
%3C      & 7.6           & 19.3          &  8.0          & 19.8           \\
%&&&&  \vspace{-2mm}\\
%3C      & 7.6           & 19.3          &  8.0          & 19.8           \\
%        &               &               &               &        \\
%\hline
%\end{tabular}
%%\end{edtable}
%\end{center}
%\end{table}
%
%
%%        \multicolumn{ncol}{format}{text}
%%       \cline{col1-col2}
%
%\clearpage
%\section{Figures}
%
%\begin{figure}[ht]
%   \begin{center}
%   \includegraphics[width=10cm]{f_curve_1overV.eps}
%   \captionv{12}{Short title - can be blank}
%   {This tries to use a .eps file as input. Some systems will automatically
%    create a pdf version and use that. If this is not available, be sure to
%    create .jpg or .pdf versons of figures.
%    Next inserted file is jpg.  The caption goes here. 
%    It can be long. It can be long. It can be long. It can be long. 
%    It can be long. It can be long. It can be long. It can be long.
%   \label{fig_example} 
%    }  %note label inside caption
%    \end{center}
%\end{figure}
%
%\begin{figure}[ht]
%   \begin{center}
%   \includegraphics[width=14cm]{f_curve_1overV.jpg}
%   %
%   %  conclusion, use directly created .pdf from agr for best results.
%   %
%   \captionv{12}{Short title - can be blank}{This version uses a jpg file.
%Next one is .pdf and is much cleaner, at least using my software which
%produces both directly. The caption goes here. 
%    It can be long. It can be long. It can be long. It can be long. 
%    It can be long. It can be long. It can be long. It can be long.
%   \label{fig_example} 
%    }  %note label inside caption
%    \end{center}
%\end{figure}
%
%\begin{figure}[ht]
%   \begin{center}
%   \includegraphics[width=14cm]{f_curve_1overV.pdf}
%   %
%   %  conclusion, use directly created .pdf from agr for best results.
%   %
%   \captionv{12}{Short title - can be blank}{The caption goes here. This
%version uses a .pdf file as input for the figure.
%    Caption can be long. It can be long. It can be long. It can be long. 
%    It can be long. It can be long. It can be long. It can be long.
%   \label{fig_example2} 
%    }  %note label inside caption
%    \end{center}
%\end{figure}

\section{Discussion}

The proposed approach introduces a 3D deep-learning network that predicts all the fluence maps of single arc VMAT plan with a single network inference, requiring less than 20ms.
Of course other modules are necessary to perform the inverse planning such as dataloading and preprocessing, dose prediction and leaf sequencing, so the total time for an inverse planning will be significantly longer.

The main idea of our method is to first performing a BEV transform of the input dose in order to transform the 3D dose map in a more practical representation.
This BEV representation has the advantage of 1) having the dose projection in the same geometry as the fluence maps in order to help the network, and 2) transforming the gantry rotation to a translation in the BEV space, which is convenient in order to take advantage of the convolutions that are the core component of CNNs.
For this reason we used a 3D CNN architecture as opposed to a 2D CNN, so that in addition to the two spatial dimensions of the fluence maps, the gantry motion/rotation is also processed with convolutions.
This local processing is accounting for all the local shape (spatial dimensions), and dynamics of the MLC (gantry dimension).
While the shape and dynamics of the MLC can be well captured by the local 3D convolutional kernels, there are also global features that need to be capture such as the fact that the total dose is the result of the contribution of all the control points.
For this reason, ConvNeXt blocks which implement fully connected layers in the feature dimension though 1x1x1 convolutions and mimics the architectures of Transformers allow such processing as opposed to classical U-Net architectures based on convolutional blocks or ResNet blocks.

% and then use a 3D network such that the translation equivariance property of the convolutions in the depth dimenion translates to a gantry rotation equivariance.
Another important contribution of this paper was to create additional plans and show the importance of scaling-up the training dataset size for the overall performance of AI-based fluence prediction.
In particular, our ablation study showed an increase of performance of about 2.5 dB in PSNR each time the dataset size was multiplied by a factor 4.

%While the fluence map quality shows notable improvement over other direct methods, it may still have room for enhancement.
%Specifically, it reduced the dose Mean Absolute Error (MAE) by $42\%$ compared to the Dynamic Conformal Arc (DCA) technique and $18\%$ compared to a U-Net.


This advancement offers promising prospects for ultra-fast inverse planning within an end-to-end framework, where dose computation \cite{gao2023flexible} precedes fluence map generation, followed by leaf-sequencing \cite{gaomulti}.
Additionally, it could serve as an initialization for established VMAT optimizers like the Photon Optimization Algorithm (PO) of Varian \cite{varian2015eclipse}.
%It's noteworthy that our network was trained on a modest dataset of only 85 plans, indicating potential for improving the results significantly by scaling up the dataset size.
It's noteworthy that, while this study focused on prostate plans, future endeavors aim to extend the methodology to encompass other anatomical regions such as lung and head and neck. We also envisage extending the method to accommodate multiple arcs VMAT and Hybrid IMRT/VMAT plans.  

% CT in input, as well as other maps, contour
In order to improve the fluence maps prediction, we considered inputting other informations to the network such as the CT scan, the organ contours, and in particular the PTV.
These data could be incorporated similar to the dose data, as an extra input channel through the computation of their BEV projections. 
While we explored this approach, our experiments did not reveal significant improvements.  
One possible explanation could be that a substantially larger dataset might be required to fully exploit the potential of the additional information. %, making it challenging for the network to grasp the intricate relationships between inputs (e.g., CT scans) and output (fluence maps). 
%Also as we did not have access to the objective functions that were used to generate the plans of our dataset, we were unsure which contours precisely were used for the target PTV.

%Note that \cite{ma2020deep, ma2021generalizability} also proposed an interesting approach for fluence map predictions. As in our proposed approach they compute BEV dose projections and then use a U-Net to predict the fluence maps.
%Their approach is based on the idea that learning a single direct mapping for all the patients is too complex, so they learn the mapping for a single phantom case and then adapt the predicted fluence maps to the specific patient geometry.
%This adaptation consists in computing a scaling factor for each beamlet which depends on the distance from the contour of the  body to the target center along each beamlet path.
%On one hand its allows to have a canonical model of the patient (the phantom) which is unique and thus more easy to trained on, but the proposed  scaling approach is very heuristical.
%Also the resulting fluence maps are scaled at the beamlet level, so the resulting fluence maps are not compatible with a VMAT plan which should only have two instensity levels (inside and outside the aperture).

%So in other hand, part of the difficulty of the  inverse problem is deleguated to the leaf-sequencing.


\section{Conclusion}

We have developed a novel AI-based method for fluence maps prediction of VMAT plans from 3D dose maps. Our method predicts all the fluence maps of a VMAT arc at once using a 3D network that takes as input the beam's eye view projections of the 3D dose map.
We also improved the performance of our fluence prediction by generating more than 2000 plans using Eclipse and showed the importance of scaling up the dataset size for improved performance.
Our network inference is very fast (less than 20ms) enabling ultra-fast inverse planning, while simultaneously enhancing PSNR by $24\%$ compared to a 2D U-Net trained on the same dataset and even $49\%$ compared to a 2D U-Net trained on the original REQUITE dataset. 
We studied variants of the network (2D and 3D U-Net vs 3D MedNeXt) as well as the effect of the dataset size. 
We think that our proposed 3D network can be used as a module within an ultra-fast inverse planning framework, or as an improved initialization method for an iterative VMAT optimizer.
Future research directions include extending the method to multiple arcs VMAT and augmenting the training dataset size to further enhance its efficacy and generalizability.

\section{Disclaimer}
The concepts and information presented in this paper / presentation are based on research results that are not commercially available. Future commercial availability cannot be guaranteed.

\section{Acknowledgments}
We acknowledge the use of the REQUITE dataset in this work. The REQUITE consortium includes Catharine West, Jenny Chang-Claude, Chris Talbot, Liv Veldeman, Dirk De Ruysscher, Barry Rosenstein, Tiziana Rancati, Ana Vega, Sara Gutiérrez-Enríquez, David Azria, Ananya Choudhury, Elena Sperk, Petra Seibold, Adam Webb, Erik Briers, Hilary Stobart, and Tim Ward. REQUITE received funding from the European Union's Seventh Framework Programme for research, technological development, and demonstration under grant agreement no. 601826. \\
%We also acknowledge Jonathan Sackett for helping with the data generation using Eclipse.


\clearpage


% following only if there is an appendix
%\section*{Appendix}
%\addcontentsline{toc}{section}{\numberline{}Appendix}
%Appendix text goes here if needed.

\section*{References}
\addcontentsline{toc}{section}{\numberline{}References}
\vspace*{-20mm}

% Following assumes you are using bibtex. However, for submission to the
% journal you MUST explicitly INCLUDE THE REFERENCES IN THE TEX FILE. 
% In that case you need the following

% \begin{thebibliography}{10}
% insert the .bbl file generated by bibtex here
	%This will be a series of entries from your .bib file formatted
	%something like
	%\bibitem{Me09}
        %{I.~Meijsing, B.~W.~Raaymakers, A.~J.~E.~Raaijmakers \it et al.},
        %\newblock {Dosimetry for the MRI accelerator: the impact of a 
	%magnetic field on the response of a Farmer NE2571 ionization chamber},
        %\newblock Phys. Med. Biol. {\bf 54}, 2993 -- 3002 (2009).

% \end{thebibliography}to not solve dddd

% The following is when using bibtex and picks up the example.bib file

%\bibliography{Explicit address of .bib file}
\bibliography{./bev2fluence_9_16_arxiv}      %example.bib is on the same directory
% above points to where we find the master reference list
% and also causes the bibliography to be printed

% When creating your bibliography you should run bibtex on your local
% computer after running pdflatex on your .tex file. bibtex will
% generate a .bbl file.
% Copy the contents of this .bbl file into your main latex document,
% replacing the "\bibliography" command which was pointing at your .bib file.


% following defines style of .bbl file 

%\bibliographystyle{explicit relative path to medphy.bst}
\bibliographystyle{./medphy.bst}    %if this is installed on your system,
				    %it is not essential to have the    ./

% Note that you need to typeset once, then run bibtex, then typeset another
% two times to get the references working properly.


\end{document}
