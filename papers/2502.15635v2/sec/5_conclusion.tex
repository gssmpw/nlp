\section{Conclusion and Future Work}

In conclusion, we provide a two-stage framework that first registers multi-pass LiDAR frames to form a coherent map, and then registers camera frames to the LiDAR map for the multi-modal pose estimation. We use the provided method to produce reliable poses for multiple grouped parallel lane sequences, and test the performance of recent approaches for synthesizing novel views through longitudinal and lateral viewpoint shifts. 

In the future, we plan to expand our dataset with a variety of sequences and incorporate the latest approaches for thorough benchmarking. While we have successfully aligned fisheye camera frames to the LiDAR map, we have also identified limitations in recent works in jointly reconstructing with them. Handling such an issue presents an opportunity for the application of these methods in the industrial community, particularly for cost-effective labeling and mass production for closed-loop simulation scenarios.
We hope that the dataset we have released will facilitate future research in this area.

\section*{Acknowledgements}

We thank the reviewers for the valuable discussions and our colleagues for preparing the proposed dataset. This research was supported by the Zhejiang Provincial Natural Science Foundation of China under Grant No. LD24F030001.
