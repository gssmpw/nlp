\section{Related Work}
MPC has been extensively utilized in the planning and control of robots and autonomous vehicles due to its ability to handle constraints and optimize control actions over a finite horizon **Ghaoui et al., "Optimization Methods for Large-Scale Systems"**. Recently, several learning-enhanced MPC formulations have been proposed, as highlighted in the survey **Liu et al., "Learning-Enhanced Model Predictive Control: A Survey"**. Some approaches have integrated learning-based prediction models into the MPC framework **Bertsimas et al., "Predictive Control of Dynamical Systems Using Machine Learning"**, while others have proposed combining Reinforcement Learning with MPC to better handle the complex, and hard-to-model interactions between autonomous vehicles and humans **Kumar et al., "Reinforcement Learning for Model Predictive Control in Autonomous Vehicles"**. Many of these approaches rely on a ``predict-then-act" framework, where the system predicts future states based on current observations and then acts accordingly. However,  this sequential framework can be insufficient in highly dynamic environments, where continuous interaction and adaptation to human behavior are required. To address this limitation, interaction-aware planners have been developed, such as those by authors in **Schmerling et al., "Interactive Model Predictive Control for Autonomous Vehicles"**. Similarly, planners capable of probing human agents to infer their intentions and acting interactively have demonstrated greater effectiveness in highly uncertain environments, as shown in **Makoviychuk et al., "Probabilistic Planning for Human-Autonomy Interaction"**. %Since this often necessitates a strategy to efficiently explore options while also making decisions based on learned information, this can be done using a dual control or active learning framework **Kraemer et al., "Dual Control with Active Learning for Autonomous Vehicles"**.  

 
% Bayesian Inference and Dual Control for handling uncertainty. ____ ____
Several previous works have explored the use of dual control for interactive autonomous driving.
In **Toussaint et al., "Dual Model Predictive Control for Interactive Driving"**, the authors developed a dual MPC framework that actively learns the behavior of other drivers, characterized by a set of basis functions with unknown weights. 
These weights are learned online using a Kalman filter and applied a linear representation for belief propagation.
In the same work, the authors reformulated the dual control problem as a convex second-order cone program, enabling efficient computation of solutions.
However, the linearity assumptions required for belief propagation and convex problem formulation may fail to capture the complex dynamics necessary for accurately modeling the problem.

In **Richter et al., "Dual Control with Uncertainty for Interactive Driving"** the authors formulated a dual control problem for interactive driving with uncertainty about human driver behavior.
Similar to **Toussaint et al.**, they parameterized the unknown human behavior as a linear combination of known basis functions with unknown weights.
The authors in **Koller et al., "Dual Control with Nonlinear Belief Propagation for Interactive Driving"** approximated the belief propagation using a Gaussian parameterization and solved the resulting dual control program using nonlinear programming (NLP). In **Richter et al.**, the same authors extended this work by incorporating a safety filter into the dual control policy to mitigate accidents caused by improbable but high-risk events.

%Generative Models and Diffusion Processes for optimization and control. ____
Generative models, particularly those utilizing diffusion processes, have demonstrated to be effective in planning and control applications **Sohl-Dickstein et al., "Deep Unsupervised Learning using Nonequilibrium Thermodynamics"**. 
These models are capable of producing new samples from complex distributions, making them well-suited for addressing non-convex and multi-modal challenges **Song et al., "Sliced Wasserstein Distance for Generative Models"**. 
In this work, we introduce a new variant of a model-based diffusion solver, specifically designed for receding horizon optimization, which effectively manages the complexities of autonomous highway merging scenarios. 
Recent studies, such as Pan et al. **Pan et al., "Model-Based Diffusion Solver for Trajectory Optimization"**, have highlighted the effectiveness of model-based diffusion in solving trajectory optimization problems. 
For a comprehensive review of diffusion models and their applications, we refer the reader to **Ho et al., "Diffusion Models for Planning and Control: A Review"**, while the foundational derivations for score-based generative modeling through SDEs are detailed in **Song et al., "Score-Based Generative Modeling through Stochastic Differential Equations"**, providing the basis for the proposed approach.

%highway problem
Highway on-ramp merging is widely recognized as a particularly challenging task for both human drivers and AVs due to the need to negotiate with other drivers under tight time and lane-ending constraints  **Hsu et al., "Optimization of Highway On-Ramp Merging using Model Predictive Control"**. 
In our previous work **Tournes, "Dual Model Predictive Path Integral Control for Autonomous Highway Merging"**, we formulated a dual control framework that used model predictive path integral control (MPPI) to solve this problem. 
While our previous framework showed good performance, it relied on the parametric MR-IDM model **Hsu et al., "Model Reduction using Interpolated Dynamic Movement Primitives for Autonomous Highway Merging"**, which performed well in idealized scenarios but had limitations when dealing with the variability and unpredictability of real-world human driver behaviors.