When recency serves as the sole predictor, it provides a straightforward means to quantify its importance. Since the heuristics rely exclusively on recency, batching inherently leads to a measurable loss of information, as temporally dependent edges are grouped together. This effect is especially significant in the context of local recency. We provide a theoretical proof of this statement in Appendix~\ref{sec:batching_incoherency}.

\section{Fixed Batch Size and Temporal Incoherence}
\label{sec:batching_incoherency}

\noindent
\textbf{Theorem.} A model that processes edges in fixed-size batches is inherently temporally incoherent unless each batch exactly aligns with a unique, consecutive set of timestamps and all but the final batch contain exactly $B$ edges. Formally, let $E = \{(u,v,t)\mid u,v \in V,\, t\in T\subseteq \mathbb{N}\}$, and let $E_t$ be the set of edges occurring at time $t$. Then any batching scheme that groups edges into subsets $b_i \subset E$ of fixed size $B$ is temporally incoherent unless all timestamps in each subset are strictly greater than all timestamps in any previous subset.

\medskip

\noindent
\textbf{Definition (Temporal Incoherence).} A batching scheme is called \emph{temporally incoherent} if there exist batches $b_i$ and $b_{i+j}$ such that
$$
\max_{(u,v,t)\in b_i} t \;\;\ge\;\; \min_{(u,v,t)\in b_{i+j}} t,
$$
meaning edges in a later batch include timestamps not strictly greater than those in the earlier batch.

\medskip

\noindent
\textbf{Proof.}
We first note that edges may be grouped by their timestamps: $E = \bigcup_{t \in T} E_t,$ where $E_t = \{(u,v,t) \mid u,v \in V\}$. We sort these sets in ascending order of $t$. Suppose a scheme attempts to form batches of size $B$.

\paragraph{Case 1: $\max_t |E_t| > B$.}
If there exists a timestamp $t$ such that $|E_t|>B$, then any single batch cannot contain all edges from time $t$. This forces us to split $E_t$ into at least two batches, both of which include edges with the same timestamp. Hence,
$$
\max_{b_i} t \;=\; t \quad\text{and}\quad \min_{b_{i+1}} t \;\le\; t,
$$
causing temporal incoherence.

\paragraph{Case 2: $\max_t |E_t|\le B$.}
When each $E_t$ can fit into a batch of size $B$, the batching scheme typically groups consecutive timestamps together until the batch reaches size $B$. Formally, we can write
$$
b_i \;=\; \bigcup_{t = t_{s_i}}^{t_{e_i}} E_t,
$$
where $|b_i| = B$ (except possibly the last batch). If the end time $t_{e_i}$ of one batch is greater than or equal to the start time $t_{s_{i+1}} \ge t_{e_i}$ of the next batch, we again have
$$
\max_{(u,v,t)\in b_i} t \;\;\ge\;\; \min_{(u,v,t)\in b_{i+1}} t,
$$
leading to temporal incoherence unless the boundaries align perfectly so that each timestamp lies entirely within a single batch. This perfect alignment can only happen if the counts of edges at consecutive timestamps sum exactly to \(B\) (for all batches except possibly the last) and no timestamp is split across batches.

In either scenario, the only way to preserve strict temporal ordering with a fixed batch size $B$ is to have each timestamp $t$ fully contained in exactly one batch, and for the number of edges at consecutive timestamps to sum up to $B$ precisely until the final subset of edges is reached. This special case requires a strict partition of $E$ by timestamps without overlap, which is generally infeasible unless the dataset is constructed to fit these constraints exactly.$~\square$
