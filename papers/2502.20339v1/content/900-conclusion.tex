\section{Conclusion}
\label{sec:conclusion}
In our work, we investigate whether lower-complexity models can leverage their superior generation throughput to outperform similarly sized Transformers under a fixed computational budget. We focus on reasoning tasks where we can scale test-time compute to improve performance.
Through extensive experimentation, we distill both pure and hybrid Mamba models at the 1B and 3B scales and evaluate their reasoning capabilities on mathematical reasoning benchmarks, where the ability of subquadratic models to quickly generate many completions enables them to take advantage of their scaling properties when increasing inference compute. 
When fixing memory and/or compute, our models achieve better coverage and accuracy for most time budgets compared to their Transformer, teacher counterparts.
These findings highlight the potential of Mamba and other attention alternatives as strong substitutes to Transformers for tasks that benefit from scalable inference compute.

We hope this work inspires future work in pretraining subquadratic reasoners and further exploring their inference scaling properties. More research is required to determine the best way to distill reasoning capabilities across architectures, as performance remains highly sensitive to both data and distillation techniques. Moreover, since our distilled models demonstrate exceptional coverage, developing better reward models to better identify correct answers can close the accuracy gap.
Finally, further investigation into scaling inference compute for conversational and subjective tasks would open to a scenario where lighter subquadratic models can achieve larger gains in performance and speed