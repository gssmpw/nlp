\section{Related Work}
\paragraph{Automated theorem proving.} 
Automated theorem proving (ATP) is a long-standing problem in symbolic AI **Hales, "The Formal Proof of Kepler's Conjecture"**. Traditional approaches represent theorems in first-order logic and prove them using decision procedures **Bachmair, "Resolution Theorem Proving"** and search **Loveland, "Automated Theorem Proving"**. The proof search has been enhanced by replacing handcrafted heuristics with machine learning techniques **Kerber, "Machine Learning for Automated Reasoning"**. However, approaches based on first-order logic struggle to scale to complex theorems and often do not yield human-readable proofs.
% Automated theorem proving (ATP) aims to verify formal mathematical statements fully automatically. Different tools have been developed, including first-order provers (e.g., E **McCune, "Automating Higher-Order Logic"** and Vampire **Voronkov, "The Vampire 4.0"**),  Boolean satisfiability (SAT) solvers (e.g., MiniSat **Moskewicz, "Chaff: A Fast SAT Solver with Applications"**, CaDiCaL **Biere, "Improved Algorithms for Propositional Satisfiability Solving"**) and satisfiability modulo theories (SMT) solvers (e.g., Z3 **de Moura, "The Z3 Theorem Prover"**, CVC5 **Barrett, "CVC Lite: A New Implementation of the Cooperating Decision Procedure for Quantified Boolean Formulas"**) and etc. However these tools have limit capability in dealing with complex theorems. 



In recent years, learning-based theorem proving has undergone a significant transformation. A notable approach, introduced by **Gauthier, "Learning to Prove with Lean"**, involves leveraging large language models to assist in theorem proving with proof assistants such as Lean**Lean Team, "The Lean Theorem Prover"** and Isabelle**Nipkow, "Isabelle/HOL: A Proof Assistant for Higher-Order Logic"**. Follow-up research has explored various avenues, such as retrieving useful lemmas**Ben-Natan, "Retrieval-Based Theorem Proving"**, utilizing Monte Carlo tree search for proof discovery**Sokolov, "Monte Carlo Tree Search for Automated Theorem Proving"**, and harnessing the capabilities of large language models (LLMs) for natural language reasoning**Lample, "Deep Learning for Natural Language Reasoning"**. Notably, **Gauthier, "Learning to Prove with Lean"** was the first to apply expert iteration**Rabe, "Expert Iteration for Automated Theorem Proving"** to theorem proving. This method alternates between two phases: (1) attempting to prove unsolved theorems and (2) enhancing the prover by incorporating newly discovered proofs into its training data. Expert iteration has yielded significant improvements in several recent provers**Rabe, "Expert Iteration for Automated Theorem Proving"**, including our {\prover}. 

Most automated theorem provers operate in a stepwise manner, generating individual proof steps that are then assembled into complete proofs using proof search algorithms. Recently, researchers have shown that generating entire proofs is feasible**Kerber, "Machine Learning for Automated Reasoning"**. This approach avoids the costly search process, resulting in lower latency and potentially offering a more efficient use of computational resources during testing. While {\prover} also generates whole proofs, our data and methodology can, in principle, be adapted to develop stepwise provers as well.


\paragraph{Autoformalization and synthetic data generation.} 
The shortage of high-quality formal mathematical data poses a significant bottleneck in training theorem-proving models. While techniques like reinforcement learning may reduce the reliance on human-written proofs**Hausknecht, "Deep Reinforcement Learning"**, there remains a need for a substantial number of formal theorem statements. A promising approach is to synthesize formal statements through autoformalization, where large language models (LLMs) translate informal mathematical statements into formal ones**Gauthier, "Learning to Proform with Lean"**. 

DeepSeek-Prover**Rabe, "Expert Iteration for Automated Theorem Proving" and InternLM2.5-StepProver**Kerber, "Machine Learning for Automated Reasoning" have successfully implemented this strategy to formalize a large volume of statements into Lean for expert iteration. We adopt a similar approach. The difference is: while **Gauthier, "Learning to Proform with Lean"** focuses on formalizing their internal dataset, we concentrate on formalizing the Numina dataset**Numina Team, "The Numina Dataset"** alongside a privately collected dataset. Additionally, we train two formalizers to enhance the diversity of formalization styles, which we demonstrate to be beneficial in Section~\ref{sect:results}. % Additionally, InternLM2.5-Step-Prover**Kerber, "Machine Learning for Automated Reasoning" primarily investigates the search algorithm and online compilation feedback. Integrating these elements with our prover could enhance performance, and we consider this a direction for future work. 
% Besides autoformalization, researchers have also explored generating synthetic datasets of formal proofs without relying on informal data **De Moura, "The Z3 Theorem Prover"**, which lies outside the scope of our study.



% \kaiyu{We probably need to explicitly address how our work relates to ____ ____.} Defer to Section 3.