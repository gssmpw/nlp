\section{Introduction}

\begin{figure}[h]
    \centering
\includegraphics[width=0.40\linewidth]{figures/miniF2F_bar_plot.pdf}
\includegraphics[width=0.30\linewidth]{figures/inference_scale_performance.pdf}
\includegraphics[width=0.235\linewidth]{figures/leanworkbook_proofs_bar_plot.pdf}
    \caption{
    % \danqi{the legends of the figures are too small to read.}
    (\textbf{Left}) The performance of Pass@32 for whole-proof generation on miniF2F comparing with previous SOTA models.
    % \danqi{be consistent with full proof generation or whole-proof generation or whole-proof generation.}
    % We compare with DeepSeek-Prover-v1.5 on the Pass@32 metric (Table 1 of \cite{xin2024deepseekv15}).   
    (\textbf{Middle}) A comparison of \prover-SFT and \dsprover{} in terms of miniF2F performance across different inference budgets, ranging from Pass@32, 64, 128, ..., to $4 \times 6400$.
    % The performance numbers of Deepseek-Prover-v1.5 are copied from Table 1 of \cite{xin2024deepseekv15}. Due to computational resource constraints, we tested \prover-SFT only up to Pass@$4\times6400$. Notably, \prover-SFT's Pass@256 already exceeds the Pass@$16\times6400$ performance of Deepseek-Prover-v1.5-RL (without inference time tree search). 
    (\textbf{Right}) \prover-SFT solve 29.7K problems in Lean Workbook. Previously,  \internlmstep~\citep{wu2024internlm2} and \internlmmath-Plus~\citep{ying2024internlm} collectively solved 15.7K samples.
    % \danqi{please define macros for all models, yours and others.}
    % \danqi{this caption is toooo long.}
    % \danqi{can you increase the font sizes for titles, legend and labels?} 
    % \yong{Looks better now?}
    } %For a more detailed discussion on the comparison between \prover-Prover-SFT, Deepseek-Prover-v1.5-RL, and InternLM2.5-Step-Prover, please refer to \rd{Appendix}
    \label{fig:main_Results}
\end{figure}

Recent advancements in large language models (LLMs) have demonstrated remarkable capabilities in reasoning tasks, especially in solving mathematical problems \citep{, guo2025deepseek, yang2024qwen2}.
% \danqi{don't quite understand the citations here. shouldn't you cite a few papers for mathematical reasoning, or at least the reasoning models (why cite qwen-2.5 and deepseek-v3)?} \yong{I replaced them by Deepseek-R1 and Qwen2.5-math}
These models excel at reasoning through natural language, which we refer to \emph{informal reasoning}. However, natural language-based reasoning is difficult to automatically verify by machines, which undermines the reliability of informal reasoning in practical applications. This also makes it more difficult to further improve the reasoning capabilities of language models. In contrast to informal reasoning, \emph{formal reasoning} allows reasoning in a machine-verifiable format, opening up new possibilities for verification and automation. In particular, proof assistants such as Lean \citep{de2015lean, moura2021lean},  Isabelle \citep{paulson1994isabelle}, and Coq \citep{barras1997coq} provide formal languages that can express reasoning in a way that can be mechanically verified. Thus, it is of great interest to train LLMs to write proofs in these formal languages.
% \danqi{the abstract says there are two ways to approach mathematical reasoning: formal and informal mathematics, but you didn't use this terms here. the next paragraph starts with there are two lines of research for formal mathematics. feels a bit inconsistent.}  



A significant challenge in training LLMs for theorem proving in formal languages is the scarcity of formalized math statements and proofs. Writing proofs for theorems expressed in formal languages is highly demanding and necessitates considerable domain expertise. Therefore, existing publicly available datasets for formal languages are limited in size. For example, the \lwb{} (including \lwb{} Plus) dataset \citep{ying2024lean, wu2024internlm2} comprises a total of 140K formal statements, where formal statements refer to problem statements in Lean without proofs.
% (formalized statements refer to problems statemented in Lean without proofs \chijin{this should be the definition of ``formal statements''. ``formalized statements'' should refer to formal statements that were newly formalized by some model/LLMs})
However, only 15.7K of these statements come with formal proofs, which were found by InternLM2.5-StepProver and InternLM-Math-Plus \citep{ying2024lean, wu2024internlm2, ying2024internlm}. 
% \danqi{i don't quite understand what are the 140K-15.7K proofs mean?} 
% \yong{does the current version looks better?}
Additionally, the Open Bootstrapped Theorems dataset \citep{wang2024theoremllama} includes 107K statements with proofs sourced from \mathlib{}4 \citep{mathlib4}. 
However, we observe a notable difference in the distribution of \mathlib{} compared to that of general problem-solving benchmarks, such as the widely used miniF2F~\citep{zheng2021minif2f}. 
For instance, statements in miniF2F are primarily from high school and require complex reasoning abilities to solve, whereas those in \mathlib{} focus on the simple manipulation of advanced mathematical concepts. (see Figure \ref{fig:mathlib4_example} and \ref{fig:minif2f_example2} in the appendix for a comparison).
% \yong{@Shange, add a comparison figure between miniF2F and \mathlib{}}
% \danqi{link to a concrete example in appendix; otherwise hard to understand.} 
Furthermore, we find that incorporating \mathlib{} data into training does not consistently improve performance on miniF2F (Section~\ref{sect:results}).


In contrast to the scarcity of data in formal languages, there is a vast amount of math problems and solutions written in informal language. For example, Numina~\citep{li2024numinamath} includes 860K high-quality question and answer pairs sourced from MATH~\citep{hendrycks2021measuring}, GSM8K~\citep{cobbe2021training}, AMC~\citep{aops_wiki}, AIME~\citep{maa_aime_2024}, the AoPS Forum~\citep{aops_wiki}, Chinese K-12 Exams~\citep{shao2024deepseekmath}, World Olympiads, and synthetic data~\citep{mitra2024orca}. We start by training LLMs to formalize the problem statements in these datasets into Lean language.  To increase the diversity of the formalization styles, we train two formalizers. One is trained on informal and formal (I-F) statement pairs from \lwb{}, while the other is trained on I-F statement pairs annotated by Claude-sonnet-3.5~\citep{anthropic2024a}. We use these two formalizers to formalize the statements and then employ LLMs to ensure that the formal statements preserve the content of the informal statements.  Our efforts result in 1.64 million formal statements.

Using this extensive dataset of formal statements, we employ expert iteration \citep{polu2022formal} to train the prover to generate proofs. Notably, we train a model to generate complete proofs solely based on statements, without interacting with the Lean compiler during the generation process. This approach is referred to as the whole-proof
generation method~\citep{jiang2022draft, wang2024theoremllama, xin2024deepseek, xin2024deepseekv15}.
% \danqi{consistent: full proof vs whole-proof vs whole-proof} 
At the beginning of the expert iteration, we generate 16 proof candidates using \dsprover-RL (the previous SOTA) for each formal statement in our dataset, and then we verify the correctness of each candidate using Lean compiler. The correct proofs are then collected to train our iter-1 prover based on \dsprover-Base.
% \danqi{remind me again why you use the -RL model to generate data, but train the -base model?} 
% \shange{We use \dsprover-RL since it is the previous SOTA, so that we can collect the largest training data. We then fine tune the base model, to avoid potential effect by \dsprover-RL. We don't train on -RL since -RL is alreadly heavily tuned.} 
In subsequent rounds, we utilize our iter-\( k \) prover to collect new proofs and add them to the training data. We then perform supervised fine-tuning starting from \dsprover-Base for another round, resulting in the iter-\( (k+1) \) prover.
% \danqi{i don't understand what you want to say in this sentence `Notably, ..'.} \yong{Does it looks better now? Each time we train collect the data }
We conduct a total of 8 iterations and observe a consistent improvement starting from the first iteration.
% \danqi{say you observe steady improvements after x iterations? and how many iterations you have done in the end.} 



With our large-scale formalized statements, we demonstrate that expert iteration can lead to SOTA performance in whole-proof generation. Specifically,
\begin{itemize}
    \item Our model outperforms \dsprover-RL (the previous SOTA model) by 7.6\% on miniF2F, achieving a Pass@32 score of 57.6\% compared to \dsprover-RL's 50.0\%, as shown in Figure~\ref{fig:main_Results} (left). It consistently surpasses \dsprover-RL across all sampling budgets, including Pass@32, 64, and up to 25600, as shown in Figure~\ref{fig:main_Results} (middle).



    % \item We conduct extensive evaluations on miniF2F~\citep{zheng2021minif2f}, ProofNet~\citep{azerbayev2023proofnet}, PutnamBench~\citep{tsoukalas2024putnambench}, the entire problem set in the \lwb{}~\citep{ying2024lean} with 140K statements, and NuminaTest (a held-out subset of our formalized Numina datasets containing 250 statements). We improve upon \dsprover-RL by 5.1\% in average performance across miniF2F, ProofNet,\lwb{} and NuminaTest (Table~\ref{tab:four_dataset_comparison}). 
    % \rd{(can we present average here?)} 
    \item We have cumulatively solved 29.7K problems in \lwb{}, significantly increasing the existing 15.7K proofs found by InternLM2.5-StepProver and InternLM-Math-Plus \citep{wu2024internlm2, ying2024internlm}, as shown in Figure~\ref{fig:main_Results} (right).
    
    \item Our model solves 7 problems on PutnamBench by Pass@512\footnote{We initially solved 8 problems on PutnamBench. However, after discussing with the authors of PutnamBench, we discovered that one of the problems was mis-formalized. Therefore, this problem is not included in our count, and we report a total of 7 problems here.}, securing the \bt{\textbf{\#1}} position on the leaderboard (Table~\ref{tab:putnambench}).  
    % \danqi{is it really important to claim sota for putnambench = 7 problems? i don't know the significance here.}
    % \yong{when we claim we are SOTA for putnambench, we should say how many problems we solved?}
    % \danqi{this paragraph is very long; does this only contain one single point?}
    \item We open source our code\footnote{\url{https://github.com/Goedel-LM/Goedel-Prover}}, model\footnote{\url{https://huggingface.co/Goedel-LM/Goedel-Prover-SFT}}, and the new proofs discovered\footnote{\url{https://huggingface.co/datasets/Goedel-LM/Lean-workbook-proofs}} in the \lwb{} to facilitate future research.
\end{itemize}

\section{Related Work}


\paragraph{Automated theorem proving.} 
Automated theorem proving (ATP) is a long-standing problem in symbolic AI~\citep{robinson2001handbook}. Traditional approaches represent theorems in first-order logic and prove them using decision procedures~\citep{de2008z3,barbosa2022cvc5} and search~\citep{kovacs2013first,schulz2019faster}. The proof search has been enhanced by replacing handcrafted heuristics with machine learning techniques~\citep{urban2011malecop,kaliszyk2018reinforcement}. However, approaches based on first-order logic struggle to scale to complex theorems and often do not yield human-readable proofs.
% Automated theorem proving (ATP) aims to verify formal mathematical statements fully automatically. Different tools have been developed, including first-order provers (e.g., E \citep{schulz2002brainiac} and Vampire \citep{kovacs2013first}),  Boolean satisfiability (SAT) solvers (e.g., MiniSat \citep{een2003extensible}, CaDiCaL \citep{queue2019cadical}) and satisfiability modulo theories (SMT) solvers (e.g., Z3 \citep{de2008z3}, CVC5 \citep{barbosa2022cvc5}) and etc. However these tools have limit capability in dealing with complex theorems. 



In recent years, learning-based theorem proving has undergone a significant transformation. A notable approach, introduced by \citet{polu2020generative}, involves leveraging large language models to assist in theorem proving with proof assistants such as Lean~\citep{de2015lean, moura2021lean} and Isabelle~\citep{paulson1994isabelle}. Follow-up research has explored various avenues, such as retrieving useful lemmas~\citep{irving2016deepmath,mikula2024magnushammer,yang2024leandojo}, utilizing Monte Carlo tree search for proof discovery~\citep{lample2022hypertree}, and harnessing the capabilities of large language models (LLMs) for natural language reasoning~\citep{jiang2022draft,lin2024lean}. Notably, \cite{polu2023formal} was the first to apply expert iteration~\citep{anthony2017thinking} to theorem proving. This method alternates between two phases: (1) attempting to prove unsolved theorems and (2) enhancing the prover by incorporating newly discovered proofs into its training data. Expert iteration has yielded significant improvements in several recent provers~\citep{wu2024internlm2,xin2024deepseekv15}, including our {\prover}. 

Most automated theorem provers operate in a stepwise manner, generating individual proof steps that are then assembled into complete proofs using proof search algorithms. Recently, researchers have shown that generating entire proofs is feasible~\citep{first2023baldur,xin2024deepseek,wang2024theoremllama}. This approach avoids the costly search process, resulting in lower latency and potentially offering a more efficient use of computational resources during testing. While {\prover} also generates whole proofs, our data and methodology can, in principle, be adapted to develop stepwise provers as well.


\paragraph{Autoformalization and synthetic data generation.} 
The shortage of high-quality formal mathematical data poses a significant bottleneck in training theorem-proving models. While techniques like reinforcement learning may reduce the reliance on human-written proofs~\citep{alphaproof}, there remains a need for a substantial number of formal theorem statements. A promising approach is to synthesize formal statements through autoformalization, where large language models (LLMs) translate informal mathematical statements into formal ones~\citep{wu2022autoformalization,wu2024internlm2,xin2024deepseek,xin2024deepseekv15}. 

DeepSeek-Prover~\citep{xin2024deepseek} and InternLM2.5-StepProver~\citep{wu2024internlm2} have successfully implemented this strategy to formalize a large volume of statements into Lean for expert iteration. We adopt a similar approach. The difference is: while \citet{liu2024deepseek} focuses on formalizing their internal dataset, we concentrate on formalizing the Numina dataset~\citep{li2024numinamath} alongside a privately collected dataset. Additionally, we train two formalizers to enhance the diversity of formalization styles, which we demonstrate to be beneficial in Section~\ref{sect:results}. % Additionally, InternLM2.5-Step-Prover~\citep{wu2024internlm2} primarily investigates the search algorithm and online compilation feedback. Integrating these elements with our prover could enhance performance, and we consider this a direction for future work. 
% Besides autoformalization, researchers have also explored generating synthetic datasets of formal proofs without relying on informal data \citep{wu2020int, wang2020learning, poesia2024learning}, which lies outside the scope of our study.



% \kaiyu{We probably need to explicitly address how our work relates to \citet{xin2024deepseekv15,wu2024internlm2}.} Defer to Section 3.
