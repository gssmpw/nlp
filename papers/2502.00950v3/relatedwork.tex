\section{Related Work}
In recent decades (since 2004), a significant number of publications have emerged in the field of multimedia data identification and classification. These works often focus on extracting different features from the data. Various methods have been used for the extraction and selection of features, including N-gram \cite{Fink2014n-Gram} and Principal Component Analysis (PCA) \cite{Gewers2021Principal}. The N-gram method is a statistical approach that extracts features based on binary words of varying lengths, while PCA is used to select features that best differentiate between classes \cite{Din2012Multimedia, Maithani2004Speech, Kant2010Identification}.

In other studies, binary streams are transformed into arrays of real numbers using algorithms such as BTR \cite{Lim2016BTR} and SWOB \cite{Ghataoura2009SWOB}. These arrays are then segmented, and statistical features such as central moments of first- to fifth-order \cite{Pébay2016Numerically}, auto-correlation \cite{Kant2010Identification} coefficients, and entropy \cite{Kant2010Identification} are extracted \cite{Tripathi2013A, Tripathi2014A}. A combined structural and statistical approach has also been used, where a codeword is placed at the start of each frame. This codeword differs according to the encoder and helps classify each packet. However, harmonizing words can appear in non-investigated data. To address this, methods such as measuring the distance between two codewords have been applied \cite{Jin2014Audio}.

Another approach is the identification of audio encoders based on randomness and irregularity. Random characteristics in the time domain include basic statistical features (mean \cite{Kant2010Identification}, variance \cite{Benetazzo2000Speech}, auto-correlation \cite{Kant2010Identification} coefficients, entropy \cite{Kant2010Identification}) and higher-order statistics (bicoherence \cite{Elgar1988Statistics}, skewness \cite{Benetazzo2000Speech}, kurtosis \cite{Benetazzo2000Speech}). In the frequency domain, the spectrum is divided into subbands, and features like mean, variance, and skewness are calculated for each subband. Randomness features such as False Neighbors Fraction (FNF) \cite{Koçal2008Chaotic-type} and Lyapunov Exponent (LE) \cite{Dingwell2006Lyapunov} are also used. For false neighbors, three features are extracted: the fraction of false neighbors, the mean of the nearest false neighbor, and the square root of the neighborhood size. These features are then input into a Support Vector Machine (SVM) for classification \cite{Hicsonmez2013Audio}.

Further studies have focused on classifying various multimedia data, such as speech, text, and fax, encoded using CVSD, Morse, and Huffman coding methods, respectively. Feature extraction is typically performed using N-gram \cite{Fink2014n-Gram}, and feature selection is conducted via PCA \cite{Gewers2021Principal}. The extracted features are then classified using an Artificial Neural Network (ANN) \cite{Tripathi2013A}. In \cite{Din2012Multimedia}, the classification of different speech coders was performed using a set of encoders (a-law, u-law, ADPCM) at bit rates of 16, 24, 32, and 64 kbps. The classification algorithm utilized can identify six classes, and three methods—auto-correlation \cite{Kant2010Identification}, variance \cite{Benetazzo2000Speech}, and binary rate (BRO)—were employed for feature extraction. This process involves converting the binary stream into real-number strings using the SWOB \cite{Ghataoura2009SWOB} method with arbitrary window sizes to obtain the values of auto-correlation and variance, after which the stream is segmented for further feature extraction.

One notable study in this area is the classification of speech encoders under noiseless and noise modes, with the noise mode further categorized into known and unknown noise levels. The noise level is determined using methods based on high-order statistics, independent of the encoder used. Three types of encoders (PCM, CVSD, and LPC) are considered, and features are extracted from binary words based on frequency, ranging from 1-gram to N-gram. One of the classification algorithms used is Minimum Distance Classification (MDC) based on the Linear Discriminant Function (LDF) \cite{Maithani2004Speech}. Additionally, the classification of CVSD speech coders with bit rates of 8, 10, 16, 24, and 32 kbit/s has been addressed using first- to fifth-order central moments, auto-correlation, and binary rate for feature extraction \cite{Tripathi2014A}.

Another contribution to this field is the identification of languages encoded by text coders. Features such as the first- to fourth-order moments, auto-correlation, and entropy are extracted, and PCA is used for feature selection. Four classification methods—most similar classification (MLC), linear statistical classification (LSC), minimum distance classification (MDC), and piecewise linear classification (PLC)—are applied, with results compared among these methods \cite{Kant2010Identification}.