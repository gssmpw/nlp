\section{CLT results for DA and GA} \label{appendix:CLT}

\noindent
We present results that characterize the distributions of the parameter update under data augmentation and group-averaging. First focus on the parameter update under DA:
\begin{align*}
    \delta \theta^{(\rm DA)}
    \;=&\; 
    \mfrac{1}{N} \msum_{i \leq N/k} \msum_{j \leq k}
    F_{\bg_{i,j}(\bX_i); \psi_\theta}
    \;,
\end{align*}
where $\bX_1, \ldots, \bX_{N/k}  \overset{\rm i.i.d.}{\sim} p^{(m)}_{\psi_\theta}$ and $\bg_{1,1}, \ldots, \bg_{N/k,k}$ are i.i.d.~samples from some distribution on $\G$. 

\vspace{.2em}

Notice that due to augmentations, $\delta \theta^{(\rm DA)}$ involves a correlated sum. Nevertheless, for each $l \leq p$, we can re-express the $l$-th coordinate of the DA parameter update as
\begin{align*}
    \delta \theta^{(\rm DA)}_l \;=&\; \mfrac{1}{N / k} \msum_{i \leq N / k} F^{(\rm DA)}_{il}
    \qquad 
    \text{ where } 
    F^{(\rm DA)}_{il} \coloneqq \mfrac{1}{k} \msum_{j=1}^k \big( F_{\bg_{1,j}(\bX_1); \psi_\theta} \big)_l
    \;,
\end{align*}
an empirical average of  i.i.d.~univariate random variables across $1 \leq i \leq N/k$, which allows for the application of a CLT. A coordinate-wise CLT, i.e.~the normal approximation of $\delta \theta^{(\rm DA)}_l$ for any fixed $l \leq p$, is straightforward from classical CLT results. Since we are concerned about stability of the gradient estimate, it is more crucial to study the behavior of the coordinate of maximum deviation, i.e.
\begin{align*}
    \mmax_{l \leq p} & \; \big| \delta \theta^{(\rm DA)}_l - \mean[ \delta \theta^{(\rm DA)}_{1l}] \big|\;,
\end{align*}
and verify that its behavior is completely described by the mean and the variance. The next result complements \cref{prop:DA} by providing CLT results for both individual coordinates and the coordinates of maximum deviation \emph{in the high-dimensional regime}, where parameter dimension $p$ --- the number of weights in our neural network --- is allowed to be much larger than the batch size $N/k$ --- the number of Markov chains per training step. For convenience, we denote the standard deviation of $F^{(\rm DA)}_{il}$ as
\begin{align*}
    \sigma^{(\rm DA)}_l 
    \;\coloneqq\; 
    \sqrt{\Var[F^{(\rm DA)}_{il}]}
    \;=\;
    \sqrt{
         \mfrac{\Var[  ( F_{\bg_{1,1}(\bX_1); \psi_\theta} )_l ]}{k}    
         +
         \mfrac{(k-1)\Cov[  ( F_{\bg_{1,1}(\bX_1); \psi_\theta} )_l ,  ( F_{\bg_{1,2}(\bX_1); \psi_\theta} )_l  ]  }{k} 
    }
    \;.
\end{align*}

\begin{theorem} \label{thm:DA:CLT} Fix $\theta \in \R^q$. Let $\bZ \sim \cN(0,I_p)$ be a standard Gaussian vector and $Z_l$ be its $l$-th coordinate. Then there exists some absolute constant $C_1$ such that for every $l \leq p$,
\begin{align*}
    \sup_{t \in \R} 
    \,
    \Big|
    \,
        \P\big( \, 
         \delta \theta^{(\rm DA)}_l
        \,\leq\, t 
        \big)
        -
        \P\Big( \, \mean\big[ \delta \theta^{(\rm DA)}_l \big]  
        + (\Var[ \delta \theta^{(\rm DA)}_l  ])^{1/2} \, Z_l \, 
        \,\leq\, t 
        \Big)
    \,
    \Big|
    \;\leq&\;
    \mfrac{C_1 \, \mean | F^{(\rm DA)}_{1l} |^3}{ \sqrt{N / k} \, \big(\sigma^{(\rm DA)}_l\big)^3}
    \,.
\end{align*}   
Moreover, assume a mild tail condition that for every $ l' \leq p$ with $\sigma^{(\rm DA)}_{l'} > 0$, we have
\begin{align*}
    \mean\bigg[ \exp\bigg( \mfrac{ (\sigma^{(\rm DA)}_{ l'})^{-1} \big| F^{(\rm DA)}_{il} \big| }{
       \tilde F^{(\rm DA)}
    } \bigg) \bigg]     
    \;\leq&\; 2
    \quad 
    \text{ where }
    \;
    \tilde F^{(\rm DA)}
    \;\coloneqq\;
    \max_{\substack{l \leq p \\{\rm with }\; \sigma^{(\rm DA)}_l > 0}} \max_{q \in \{3, 4\}} \Big\{  
        \Big( \mean\Big[ (\sigma^{(\rm DA)}_{ l})^{-q}  \, \big|  F^{(\rm DA)}_{il} \big|^q \Big] \Big)^{1/q}
    \Big\}\;.
\end{align*}
Then the coordinate of maximum deviation of $\theta^{(\rm DA)}_1$ also satisfies a CLT: There is some absolute constant $C_2 > 0$ such that
\begin{align*}
    \sup_{t \in \R} 
    \,
    \Big|
    \,
        \P\Big( \, 
         \max_{l \leq p} \big| \delta \theta^{(\rm DA)}_l - \mean[\delta \theta^{(\rm DA)}_l] \big|
        \,\leq\, t 
        \big)
        \;-&\;
        \P\Big( \, 
        \max_{l \leq p} \Big|
        (\Var[ \delta \theta^{(\rm DA)}_l  ])^{1/2} \, Z_l \,
        \Big| 
        \,\leq\, t 
        \Big)
    \,
    \Big|
    \\
    &\hspace{8em} \;\leq\;
    C_2
    \Big( 
    \mfrac{  (\tilde F^{(\rm DA)})^2 \, (\log (p N /k) )^7}
    { N /k }  
    \Big)^{1/6}
    \;.
\end{align*}
\end{theorem}

The bounds in \cref{thm:DA:CLT} each control a difference in distribution function between $\delta \theta^{(\rm DA)}$ and a normal distribution, measured through either an arbitrarily fixed coordinate or the coordinate of maximum deviation from its mean. In particular, they say that the distribution of $\delta \theta^{(\rm DA)}$ is approximately normal and therefore completely characterized by the mean and the variance studied in \cref{prop:DA}. To interpret them in details:
\begin{itemize}
    \item The coordinate-wise bound follows from the classical Berry-Ess\'een Theorem (see e.g.~Theorem 3.7 of \cite{chen2011normal}), and the normal approximation error does not involve the dimension $p$. 
    \item For the coordinate of maximum deviation, the normal approximation error is small so long as $p$ is much smaller than a constant multiple of $\exp( (N/k)^{1/7})$, which is in particular true even if the parameter dimension $p$ is larger than the batch size $N/k$. The moment assumption amounts to a light-tailed condition on the distribution of the updates, and they can be relaxed at the cost of more complicated bounds --- see \citet{chernozhukov2017central}.
\end{itemize}

We also remark that \cref{thm:DA:CLT} is a special case of the universality result of \citet{huang2022quantifying} for data augmentation, but with a sharper bound and in Kolmogorov distance.

\vspace{.5em}

Analogous CLTs hold for both the unaugmented update and the group-averaging update. Recall that these updates are
\begin{align*}
    \delta \theta^{(\rm OG)} 
    \;\coloneqq&\; 
    \mfrac{1}{N} \msum_{i \leq N} 
    F_{\bX_i; \psi_\theta}
    &\text{ and }&&
    \delta \theta^{(\rm GA)} 
    \;\coloneqq&\; 
    \mfrac{1}{N / k} \msum_{i \leq N / k} 
    F_{\bX^\cG_i; \psi_\theta}
    \;,
\end{align*}
where $\bX^\cG_1, \ldots, \bX^\cG_{N/k} \overset{\rm i.i.d.}{\sim} p^{(m)}_{\psi^\cG_\theta}$. In particular, $\delta \theta^{(\rm OG)}$ is the same as $\delta \theta^{(\rm DA)}$ with $k=1$ and $\bg_{1,1}$ set to the identity transformation, and $\delta \theta^{(\rm GA)}$ is the same as $\delta \theta^{(\rm OG)}$ with $N$ replaced by $N/k$ and $p^{(m)}_{\psi_\theta}$ replaced by  $p^{(m)}_{\psi^\cG_\theta}$. Therefore the CLT results for $\delta \theta^{(\rm OG)} $ and $\delta \theta^{(\rm GA)}$ are direct consequences of \cref{thm:DA:CLT} by defining $\delta \theta^{(\rm OG)}_l$, $F^{(\rm OG)}_{1l}$, $\sigma^{(\rm OG)}_l$, $\tilde F^{(\rm OG)}$, $\delta \theta^{(\rm GA)}_l$, $F^{(\rm GA)}_{1l}$, $\sigma^{(\rm GA)}_l$ and $\tilde F^{(\rm GA)}$ as the analogous quantities. We do not state these results for brevity.

