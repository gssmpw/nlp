\section{Related Works}
\input{tables/datasets-compare}

While existing collaborative perception datasets have the same sensor setup for their CAVs, our dataset contains three vehicles with two different sensor configurations, including the height and tilt of LiDAR and the type of vehicle.
This difference introduces heterogeneity to our fleet of vehicles, thus making our data more closely resemble the real-world collaboration deployment.
To the best of our knowledge, we have the largest fleet of CAVs with the most diverse sensors of any prior works.

\mypara{Vehicle-to-Everything Communication.}
One of V2X's objectives is to enhance the perception capabilities of CAVs, facilitating their deployment in urban environments. 
These areas usually have a high presence of Vulnerable Road Users (VRUs) which are people not inside vehicles \cite{def_vru}. 
Despite this, VRUs are under represented in prior works.
The three synthetic datasets made with CARLA \cite{dosovitskiy2017carla} and the real-world dataset V2V4Real \cite{xu2023v2v4real} do not have VRUs.
DAIR-V2X-C \cite{yu2022dair} and its extension V2X-Seq (SPD) \cite{yu2023v2x} provide annotations for 4 VRU classes (pedestrian, bicyclist, tricyclist, and motorcyclist).
However, the absence of details on class distribution in their publications make it hard to judge their coverage VRUs.
In addition, the fact that the access to these two datasets from outside of China is conditional reduces their applicability.
TUMTrafV2X \cite{zimmer2024tumtraf} annotates 3 VRU classes including pedestrian, bicycle, and motorcycle, which together account for 24.6\% of the total annotations.
Such under representation leads to the overlook of VRUs detection in several works on collaborative perception methods \cite{wang2020v2vnet, li2021learning, xu2022opv2v, xu2022v2x}.

\mypara{Real World Vehicle-to-Everything Datasets.}
The recent V2X-Real \cite{xiang2024v2x} has a large number pedestrian annotations, which is higher than annotations of the class car, and 3 other VRU classes (scooter, motorcycle, and bicycle).
A drawback of this dataset to the VRU detection is that their benchmark only accounts for pedestrian.
Our dataset contains the highest number of VRU classes, including pedestrian, bicycle, portable personal mobility, and motorcycle.
More importantly, these classes account for 50.3\% of our dataset's total bounding boxes.
Instead of selecting certain VRU classes for benchmarking, we group 4 VRU classes into 2 detection classes as in 
\autoref{sec:dataset_analysis}
to provide a better understanding of how different collaboration methods perform in detecting VRUs. We provide a detailed comparison of our dataset, \ours, with prior works in \autoref{tab:dataset-compare}.

