
\documentclass{article} % For LaTeX2e

\usepackage[dvipsnames]{xcolor}
\usepackage{iclr2025_conference,times}

% Optional math commands from https://github.com/goodfeli/dlbook_notation.
% \input{math_commands.tex}
\usepackage{color}

\usepackage{hhline}
\usepackage{amsmath,amsfonts,bm}



\usepackage{colortbl}
\usepackage{array}
\usepackage{graphicx}
% \usepackage{hyperref}
\usepackage{url}
\newcommand{\PP}[1]{}
\newcommand{\shyam}[1]{}
\newcommand{\sv}[1]{}
% \newcommand{\YSR}[1]{#1{}}
\newcommand{\YSR}[1]{\textcolor{blue}{YsR:#1}}


\title{LR0.FM: Low-Resolution Zero-Shot Classification benchmark for Foundation Models}


% Authors must not appear in the submitted version. They should be hidden
% as long as the \iclrfinalcopy macro remains commented out below.
% Non-anonymous submissions will be rejected without review.

\author{Priyank Pathak\textsuperscript{1}, Shyam Marjit\textsuperscript{2}, Shruti Vyas\textsuperscript{1} \& Yogesh S Rawat\textsuperscript{1}  \\
% \thanks{ Use footnote for providing further information about author (webpage, alternative address)---\emph{not} for acknowledging funding agencies.  Funding acknowledgements go at the end of the paper.} \\
\textsuperscript{1}University of Central Florida\\
\textsuperscript{2}IIIT  Guwahati \\
\texttt{
priyank@ucf.edu,
shyam.marjit@iiitg.ac.in, 
\{shruti, yogesh\}@ucf.edu
}
\vspace{-0.1cm}
}

\newcommand{\fix}{\marginpar{FIX}}
\newcommand{\new}{\marginpar{NEW}}
\usepackage{listings}
\usepackage{hyperref}
\usepackage{makecell}
\usepackage{booktabs}
\usepackage{cleveref}
\usepackage{array}
\usepackage{float}
\usepackage{subcaption}
\usepackage{amssymb}

\newcolumntype{P}[1]{>{\centering\arraybackslash}p{#1}}
 \newcommand*{\x}
 {\!\times\!}
 
\usepackage{multirow}

\definecolor{ao(english)}{rgb}{0.0, 0.5, 0.0}
\newcommand{\IMPROV}[1]{{\color{ao(english)}\textbf{\textsuperscript{#1}}}
}

\newcommand{\DEC}[1]{{\color{red}\textbf{\textsuperscript{#1}}}
}
 
 
\newcommand{\SMCY}[1]{{\small{(\citeyear{#1})}}}
\newcommand{\STEXT}[1]{{\small{{\text{#1}}}}}

\newcommand{\MTEXT}[1]{ \text{\normalsize{#1}}
}


\usepackage{adjustbox}

\newcommand{\Supp}[0]{\textit{Supplementary}}
\newcommand{\eg}[0]{\textit{e.g.} }
\newcommand{\etc}[0]{\textit{etc.} }
\newcommand{\ie}[0]{\textit{i.e.} }

\definecolor{mygray}{gray}{.9}
% \usepackage{hyperref}


\newcommand{\tablestyle}[2]{\setlength{\tabcolsep}{#1}\renewcommand{\arraystretch}{#2}\centering\footnotesize}

\newlength\savewidth\newcommand\shline{\noalign{\global\savewidth\arrayrulewidth\global\arrayrulewidth 1pt}\hline\noalign{\global\arrayrulewidth\savewidth}}
\setlength\tabcolsep{2pt}

\newcommand{\SPCITE}[1]{{\textcolor{lightgray}{\small{[\citeyear{#1}]}}}}

\definecolor{mypink}{RGB}{255, 105, 180}

% Set the color for links
\hypersetup{
    colorlinks=true,
    linkcolor=blue,
    urlcolor=mypink,
    citecolor=gray
}

\iclrfinalcopy % Uncomment for camera-ready version, but NOT for submission.
\begin{document}


\maketitle
\vspace{-30pt}
\begin{center}
{
\normalsize
\href{https://ucf-crcv.github.io/lr0.fm}{https://ucf-crcv.github.io/lr0.fm}
}
\end{center}    
\vspace{-2pt}

\begin{figure}[ht]
  \centering
\includegraphics[width=0.92\linewidth]{Images/acc_drop.pdf}
  \caption{\textbf{Top-1 zero-shot classification accuracy (y-axis) vs resolution (x-axis)}: 
Backbones for foundation models are merged as shade, with average performance across backbones in the dark.
}
\vspace{-3pt}  
\label{fig:acc_drop}
\vspace{-0.2pt}  
\end{figure}


\begin{abstract}
% https://iclr.cc/Conferences/2025/CallForPapers
Visual-language foundation Models (FMs) exhibit remarkable zero-shot generalization across diverse tasks, largely attributed to extensive pre-training on large-scale datasets. 
However, their robustness on low-resolution/pixelated (LR) images, a common challenge in real-world scenarios, remains underexplored. 
We introduce \textbf{LR0.FM}, a comprehensive benchmark evaluating the impact of low resolution on the zero-shot classification performance of \textit{10} FM(s) across \textit{66} backbones and \textit{15} datasets. 
We propose a novel metric, \textbf{Weighted Aggregated Robustness}, to address the limitations of existing metrics and better evaluate model performance across resolutions and datasets.
Our key findings show that: 
(i) model size positively correlates with robustness to resolution degradation, 
(ii) pre-training dataset quality is more important than its size, and 
(iii) fine-tuned and higher resolution models are less robust against LR. 
Our analysis further reveals that the model makes semantically reasonable predictions at LR, and the lack of fine-grained details in input adversely impacts the model's initial layers more than the deeper layers. We use these insights and introduce a simple strategy, \textbf{LR-TK0}, to enhance the robustness of models without compromising their pre-trained weights. We demonstrate the effectiveness of \textbf{LR-TK0} for robustness against low-resolution across several datasets and its generalization capability across backbones and other approaches. \textit{Code is available at this \href{https://github.com/shyammarjit/LR0.FM}{link.}} 
\end{abstract}

\input{Sections/intro}
\input{Sections/related}
\input{Sections/method}
\input{Sections/benchmark_stuff}
\input{Sections/proposed_method}
\input{Sections/ablation}
\input{Sections/conclusion}




\bibliography{iclr2025_conference}
\bibliographystyle{iclr2025_conference}

\newpage

\appendix

\input{Supp/supp}



\end{document}
