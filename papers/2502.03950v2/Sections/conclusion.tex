\section{Conclusion}

Our extensive evaluation of Visual-Language Foundation Models through the LR0.FM benchmark has highlighted critical limitations in their ability to generalize under low-resolution conditions, a prevalent issue in real-world scenarios. While larger models and higher-quality pre-training datasets offer increased robustness, our findings underscore the significant impact of fine-tuning and input resolution on performance. Importantly, we observed that low-resolution inputs primarily disrupt the early layers of these models, leading to degraded performance. To address these challenges, we introduced the LR-TK0 strategy, which improves model robustness to low-resolution inputs without altering pre-trained weights, offering a practical solution for real-world applications. Additionally, our proposed Weighted Aggregated Robustness metric provides a more comprehensive evaluation of model resilience, addressing the limitations of existing metrics.



\section{Acknowledgment}
The authors thank Steven Dick (UCF High-Performance Computing) and Rohit Gupta (UCF CRCV) for their help in generating the synthetic data set. 