\section{Introduction}

Vision-Language Foundation Models (FMs), such as CLIP~\citep{radford2021learning}, LLaMA~\citep{touvron2023llama}, and other variants, have shown extraordinary generalization capabilities across a wide range of downstream tasks, including image classification~\citep{ilharco_gabriel_2021_5143773}, object detection~\citep{zhong2022regionclip}, and semantic segmentation~\citep{xu2022odise}. These models benefit from large-scale, multi-modal pre-training on diverse datasets like DataComp-1B~\citep{datacomp} and LAION-5B~\citep{schuhmann2022laion}, 
enabling them with zero-shot capabilities.
% enabling them to excel in zero-shot scenarios. 
Although these models excel on high-resolution benchmarks, their performance with low-resolution (LR) pixelated images, a common real-world challenge, remains adequately underexplored.
% While their performance on high-resolution benchmark datasets is outstanding, their behavior when confronted with low-resolution (LR) pixelated images, a common real-world challenge, has not been  explored.


Low-resolution images frequently arise in various practical scenarios, such as surveillance footage~\citep{davila2023mevid}, satellite imagery~\citep{Patil2017ClassificationOL}, and privacy-protected pixelated data~\citep{10.1145/3394171.3413972} \textit{etc}. In these cases, details crucial for accurate classification may be obscured by artifacts like pixelation and compression, leading to substantial performance degradation. 
For instance, small objects (faces) within larger images~\citep{cheng2019low} pose unique challenges, often requiring models to rely on limited visual cues. Given the widespread presence of LR images in real-world applications, it is crucial to understand how robust FMs are in these settings.


\begin{figure}[!tb]
\centering
\subfloat
{
\includegraphics[height=4.12cm]{Images/128.pdf}
\label{fig:128_ex}
}
\hfill
\subfloat
{
\includegraphics[height=4.12cm]{Images/64.pdf}
\label{fig:32_ex}
}
\hfill
\subfloat
{
\includegraphics[height=4.12cm]{Images/32.pdf}
\label{fig:32_ex}
}
\hfill
\subfloat
{
\includegraphics[height=4.12cm]{Images/16.pdf}
\label{fig:32_ex}
}
\vspace{-2pt}
\caption{\textbf{Zero-Shot misclassifications:} 
EVA-CLIP \SPCITE{sun2023eva} correct classification at $224\x224$ (green) \& misclassification at lower resolution (red). However, ImageNet labels-based mispredictions are semantically reasonable (humans), indicating viability of pre-trained weights at low resolution.
}
\label{fig:img_ex}
\vspace{-9pt}
\end{figure}
Motivated by this, we present an in-depth benchmarking study of FMs, focusing on their zero-shot classification performance under LR conditions. 
We introduce LR0.FM, a comprehensive benchmark that evaluates \textbf{10 foundation models} across \textbf{66 backbones} and \textbf{15} diverse image classification \textbf{datasets}, ranging from large-scale datasets like ImageNet~\citep{deng2009imagenet} to fine-grained and texture-specific datasets like 
Oxford Pets~\citep{parkhi2012cats} and DTD~\citep{cimpoi2014describing}. 
Our study systematically examines the effects of resolution degradation, revealing key insights into how model size, pre-training dataset quality, and fine-tuning impact robustness in LR scenarios.

Metrics for measuring  robustness ($\gamma$, ~\cite{schiappa2024robustness}) and its averaging across datasets (SAR)
have some limitations; 1) They can produce misleadingly high scores when models perform poorly on challenging datasets, and 2) They tend to ignore certain datasets, skewing the overall comparison. To address these, we propose a new metric, \textbf{Weighted Aggregated Robustness (WAR)}, which provides a more balanced evaluation by considering performance drops across datasets more fairly. % and better captures how robust models truly are across diverse, real-world scenarios.

Our analysis reveals several interesting insights. Larger models tend to maintain robustness better when faced with LR inputs, while the quality of the pre-training dataset is more crucial than its size in preserving performance. 
Furthermore, fine-tuned models and those with higher-resolution inputs significantly underperform against resolution drop. 
We also observe that although models struggle at low-resolution 
(\cref{fig:acc_drop}) and loss of fine-grained details (\cref{fig:img_ex}: \eg Vulture vs Bald Eagle, Bubble vs Balloon \textit{etc.}), their predictions often remain semantically reasonable, even at extreme resolutions (\cref{fig:img_ex}: \eg Orange vs Banana, Church vs Volcano \textit{etc.}). 
\textit{Supplementary} demonstrates more examples (including real-world) where such mispredictions are made.    
This suggests a solution for low-resolution does not require extensive modifications to the model and its pre-trained weights. 
% This indicates that the models may not require extensive modifications, instead solution based without disturbing pretrained weights. 
% intelligent handling of low-resolution inputs.
% This suggests handling low-resolution may require without 
% extensive modifications to pretrained weights.






\iffalse

\fi

Based on these insights, we propose a simple yet effective solution, \textbf{LR-TK0: LR-Zero-Shot Tokens}, which introduces low-resolution-specific tokens to enhance robustness without altering the pre-trained model weights. Our method preserves the model's semantic reasoning capabilities while compensating for the loss of fine-grained detail, offering a feature super-resolution-like approach ~\citep{chen2024robustsam}. By training on synthetic diffusion-based high-resolution images, LR-TK0 improves performance in low-resolution zero-shot classification tasks, making FMs more robust for practical, real-world applications.

% \YSR{do we want to add something about metric too?}


In summary, we make the following contributions in this work,
\vspace{-8pt}
\begin{enumerate}
\itemsep-0.1em 
    \item We present \textbf{\textit{LR0.FM}}, a comprehensive benchmarking of Visual-Language Foundation Models (FMs) on zero-shot classification of low-resolution images, providing several key insights. To the best of our knowledge, no prior work has explored this aspect of FMs.
    \item We introduce a simple and effective method, \textbf{\textit{LR-TK0}}, to enhance model robustness against low-resolution inputs without altering the pre-trained weights.
    % \item We propose a novel metric, Weighted Aggregated Robustness (\textbf{\textit{WAR}}), which addresses the limitations of existing robustness metrics, offering an improved evaluation of models under challenging conditions.
    \item We introduce Weighted Aggregated Robustness (\textbf{WAR}), a novel robustness metric for evaluating models under challenging conditions, overcoming the limitations of existing metrics. 
\end{enumerate}


\iffalse
Existing robustness benchmark studies have primarily focused on traditional computer vision models ~\citep{hendrycks2019benchmarking, schiappa2023large} against real-world artifacts~\citep{michaelis2019benchmarking, taori2020measuring}, thereby motivating better model designs. 
However, there is a lack of study for foundational models that have already incorporated these design improvements either \textit{explicitly} \eg Augmix augmentation~\citep{hendrycks2019augmix} or \textit{implicitly} via vast training data \YSR{you can cite our iccv 23 work here... Efficiently robustify pre-trained models...}. 





% \Cref{fig:acc_drop} shows foundation models (on average) experience a significant decline in zero-shot classification performance when resolution drops below $64\x64$, adversely affecting their generalization ability to distinguish objects.






Motivated by this, we propose \textbf{LR-TK0: LR-Zero-Shot Tokens}.
Our method preserves the semantic reasoning of models, while training \underline{low-resolution (LR) tokens} to fill in missing fine-grained details.
Unlike image super-resolution, our approach is more akin to feature super-resolution~\citep{chen2024robustsam}. 
To preserve the zero-shot evaluation, we train our model on synthetically generated diffusion-based HR images, showing improvement with just even 2,000 captions based images can e nh

\YSR{say more on this... what else you did for 0-shot... just this can be troublesome, there are works which show diffusion models learn samples... and these are also trained on a lot of images... say something about the captions you used...}.  
Ablation studies show that even a limited number of generated images can enhance performance across 15 datasets.
\fi