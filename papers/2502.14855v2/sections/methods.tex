We describe the P2L method formally, beginning with notation. 
Consider $M$ different LLMs which are presented to humans pairwise---model $A$ on the left, and model $B$ on the right, where $A$ and $B$ are randomly sampled without replacement from $[M] = \{1, \ldots, M\}$.
If the human votes for model $A$, we set $Y=0$, and if they vote for model $B$, we set $Y=1$.
Furthermore, we let $X$ represent a `two-hot' encoding of the model pair, i.e., a vector of length $M$ with zeros everywhere except $+1$ in the index $B$ and $-1$ in the index $A$.
We model our data-generating process as a tuple $(X,Y,Z)$ of two-hot encodings, votes, and prompts $Z \in \cZ$ sampled from a joint distribution $P$, where $\cZ$ denotes the space of natural-language prompts.
Also, let $\Theta$ denote a space of functions mapping prompts to leaderboards, i.e., $\theta \in \Theta$ is a function from $\cZ \to \R^M$, and $\theta(z)_i$ represents the leaderboard score of model $i \in [M]$ given prompt $z$.
Finally, let $\ell$ denote the binary cross-entropy loss and $\sigma$ denote the sigmoid function.

\subsection{Core method}
\label{sec:core-method}

Conceptually, our method works as follows.
We model the vote conditionally on the prompt and model pair as following a Bradley-Terry (BT) model~\cite{bradley1952rank}:
\begin{equation}
    \label{eq:prompt-BT}
    \P(Y = 1 \mid X = x, Z = z) = \sigma(x^\top\theta^*(z)),
\end{equation}
for some (unknown) $\theta^* : \cZ \to \R^M$.
The goal is to approximate $\theta^*$ from data.

For any prompt $z \in \cZ$, $\theta^*(z)$ represents a leaderboard.
Each model $m \in [M]$ has a coefficient $\theta^*(z)_m$, and the higher this coefficient is, the more likely model $m$ beats any other model on the prompt $z$.
For different prompts, the leaderboard will be different, capturing the idea that different models are better on different prompts.
Our target, $\theta^*$, is precisely the function that takes prompts and outputs leaderboards---hence the name, \emph{prompt-to-leaderboard} (P2L).

P2L is a strict generalization of marginal BT regression.
In marginal BT regression, we simply omit the dependence of the leaderboard on the prompt, and give the best leaderboard on average (``marginally'').
That is, choosing $\Theta$ to be the class of \emph{constant} functions $\theta(z) \equiv \theta \in \R^M$ exactly recovers marginal BT regression.

However, P2L can be substantially more powerful than marginal BT regression due to heterogeneity in the prompt-conditional performance of different language models.
That is, we should leverage language models to extract information on model performance from the prompt.
In particular, our work takes $\Theta$ to be a space of reward models mapping prompts to vectors.
Given a training dataset $\Dtrain = \{(X_i,Y_i,Z_i)\}_{i=1}^N$, we find the empirical risk minimizer,
\begin{equation}
    \label{eq:p2l-bt}
    \hat\theta = \argmin_{\theta \in \Theta} \frac{1}{N}\sum\limits_{i=1}^N \ell(\sigma(X_i^\top \theta(Z_i)), Y_i).
\end{equation}
Then, as before, we can extract the estimated win rate between any two models as
\begin{equation}
    \widehat{\P}(Y = 1 \mid X = x, Z = z) = \sigma(x^{\top}\hat\theta(z)).
\end{equation}

Lastly, we note that this strategy of training LLMs to output coefficients of parametric statistical models will be generalized in Section~\ref{sec:p2r}.
The resulting prompt-dependent models have both high predictive power and a useful statistical interpretation, which is critical to the aforementioned routing and personalization techniques.

\subsubsection{Aggregating leaderboards}
\label{sec:aggregating}

Many practical scenarios require a leaderboard for a distribution over prompts, not just one.
For example, a user may want to know which model is best for them based on their chat history, or an enterprise may want to know which model is best for their use-case.
In other words, given a distribution over prompts $Q$, we want to ensemble all $\theta^*(z)$ for $z \in \Z$ to form a leaderboard over $Q$.
In the case of a finite chat history, we can consider $Q$ to be the discrete uniform distribution over the observed historical prompts.

By the Tower property, we can decompose the win rate as 
\begin{equation}
    \E_{Z \sim Q. Y \sim \mathrm{Bern}(\sigma(X^\top\theta^*(Z)))}[Y \mid X = x] = \int_{z \in \cZ} \sigma\left(x^\top \theta^*(z)\right) dQ(z).
\end{equation}
The win rate above no longer follows a simple logistic model, but we can fit another logistic model to match it:
\begin{equation}
\label{eq:aggregation-function}
\tilde\theta(Q) = \argmin_{\theta \in \Theta}  \E_{\substack{X \sim P_X, Z \sim Q, \\ Y\sim \mathrm{Bern}(\sigma(X^\top\theta^*(Z)))}} \left[  \ell\left(\sigma(X^\top \theta), Y\right) \right].
\end{equation}
The idea is that, because we know $\P(Y=1 \mid X=x, Z=z) = \sigma(x\top\theta^*(z))$ for all $x$ and $z$, we can simulate the data-generating process.
This allows us to construct a synthetic dataset and fit a Bradley-Terry model to it.
If $\theta^*$ exists, this technique is perfect, in that it recovers the exact same BT coefficients that we would have obtained by observing an infinite population of prompts from $Q$.
In Appendix~\ref{app:aggregating-averaging}, we explore an alternative leaderboard aggregation strategy by taking a weighted average of the leaderboards.
Note also that we use $\theta^*$, with the understanding that in practice we will use the plug-in estimate based on $\hat\theta$, and the resulting rule will be approximate.

We can make this strategy more efficient by leveraging the linearity of the binary cross-entropy loss.
Namely, 
\begin{align}
    & \E_{X \sim P_X, Z \sim Q, Y\sim \mathrm{Bern}(\sigma(X^\top\theta^*(Z))}\left[  \ell\left(\sigma(X^\top \theta), Y\right) \right] \\
    = &\E_{X \sim P_X, Z \sim Q}\left[ \E_{Y\sim \mathrm{Bern}(\sigma(X\top\theta^*(Z))} \left[\ell\left(\sigma(X^\top \theta), Y\right) | X, Z \right]\right] \\
    = &\E_{X \sim P_X, Z \sim Q}\left[\ell\left(\sigma(X^\top \theta), \E_{Y\sim \mathrm{Bern}(\sigma(X^\top\theta^*(Z))} \left[Y | X, Z\right] \right)\right] \\
    = &\E_{X \sim P_X, Z \sim Q}\left[\ell\left(\sigma(X^\top \theta), \sigma(X^\top\theta^*(Z)) \right)\right]. 
\end{align}

Thus, we can bypass the need for sampling to simulate $Y$.
In other words,~\eqref{eq:aggregation-function} is equivalent to
\begin{equation}
    \label{eq:efficient-aggregation-function}
    \tilde\theta(Q) = \argmin_{\theta \in \Theta}  \E_{X \sim P_X, Z \sim Q}\left[  \ell\left(\sigma(X^\top \theta), \sigma(X^\top \theta^*(Z))\right) \right].
\end{equation}
This last expression is simple to compute for discrete distributions $Q$, leading to an efficient algorithm.

\subsubsection{Optimal routing}
\label{sec:routing}

Next, we will derive the optimal router based on P2L.
We will derive the exact optimal router based on $\theta^*$ and approximate it in practice by $\hat\theta$.
Let us assume, for the sake of simplicity, that for each model $m \in \{1, \ldots, M\}$, there is a known and fixed cost of inference, $c = (c_1, \ldots, c_M)$.
We seek to create a router that maximizes performance while remaining below a constraint on the average cost, $C$.
We express the router as a policy, $\pi : \cZ \to \Delta^M$, which takes a prompt as input and outputs a distribution over models; we seek to estimate the optimal policy, $\pi^*$.
We will also consider a distribution of opponent models, $q \in \Delta^M$, to act as a baseline for comparison.
For instance, we can pick $q$ to be a point-mass on the single best model, or to be uniform over all $[M]$ models.

One possible interpretation of an ``optimal'' router is the one that maximizes the win rate against $q$ subject to the cost constraint; that is, for almost every $z$, this interpretation of $\pi^*(z)$ solves the following optimization problem:
\begin{equation}
    \label{problem:optimal-routing}
    \begin{aligned}
        \maximize_{\substack{ \tilde\pi \in \Delta^M }} \quad & \P_{A \sim q, B \sim \tilde\pi, Y \sim \mathrm{Bern}(\sigma(\theta^*(z)_B - \theta^*(z)_A))}(Y=1 \mid Z=z)\\
        \st \quad & \E_{B \sim \tilde\pi}[c_B] \leq C
    \end{aligned},
\end{equation}
In other words, the optimal router should maximize the average win rate against the opponent distribution $q$.

An alternative definition of the optimal router is the one that has the highest Bradley-Terry coefficient.
This version of the optimal policy has $\pi^*(z)$ equal (almost surely) to the solution to the following optimization problem: 
\begin{equation}
    \label{problem:optimal-routing-bt}
    \begin{aligned}
        \maximize_{\substack{ \tilde\pi \in \Delta^M }} & \quad \argmin_{\theta \in \R} \E_{\substack{B \sim \tilde\pi, A \sim q,\ifdefined\newlinetoggle\\\fi Y' \sim \mathrm{Bern}(\sigma(\theta^*(z)_B - \theta^*(z)_A))}} \Big[ \ell(\sigma(\theta - \theta^*(z)_A), Y') \mid Z = z\Big]\\
        \st & \quad \E_{B \sim \tilde\pi}[c_B] \leq C
    \end{aligned}.
\end{equation}
That is, considering the optimal router as a separate model, it should achieve the highest possible spot in the leaderboard subject to the cost constraint.

Surprisingly, although the optimization problems in~\eqref{problem:optimal-routing} and~\eqref{problem:optimal-routing-bt} look different, their optimal solution is the same under the Bradley-Terry model. 
The solution is given in Theorem~\ref{thm:optimal-router}.
The resulting problem has a linear objective and a linear constraint, and can be solved with any standard solver.
If the dominant model is below the cost of $C$, the policy will deterministically select that model (i.e., it will place probability $1$ on sampling that model).
Otherwise, it will hedge its bets and randomize over multiple models.
\begin{theorem}[Optimal prompt-dependent routing]
    \label{thm:optimal-router}
    Assume that for every prompt $z$, the Bradley-Terry model holds with coefficients $\theta^*(z)$. 
    Then, the optimization problems in~\eqref{problem:optimal-routing} and~\eqref{problem:optimal-routing-bt} are both equivalent to the following problem:
    \begin{equation} 
        \label{problem:optimal-routing-master}
        \begin{aligned}
            \minimize_{\substack{\tilde\pi \in \R^M }} \quad & -\tilde\pi^\top \mathbf{W}^*q\\
            \st \quad & \tilde\pi^\top c \leq C, \\
            & \mathbf{0}_M \preceq \tilde\pi \preceq \mathbf{1}_M \\
            & \tilde\pi^\top \mathbf{1}_M = 1,
        \end{aligned}
    \end{equation}
    where $\mathbf{W^*}$ represents the population win matrix, with entries $\mathbf{W}^*_{ba} = \sigma(\theta^*(z)_b - \theta^*(z)_a)$.
\end{theorem}
The proof is given in Appendix~\ref{app:proofs}.
It is important to note that deviations from the Bradley-Terry model---for example, any non-transitivity---will break this relationship.

Another benefit of this approach is that we are able to estimate the \emph{value} of the objective function of~\eqref{problem:optimal-routing-bt} via a standard root finder~\cite{brent1973-chapter4}, which means we can estimate the router's position on the leaderboard before deploying it.
We give this procedure in Algorithm~\ref{alg:nested-problem}.
It is justified by~\eqref{eq:router-first-order-condition} in the proof of Theorem~\ref{thm:optimal-router}.
    
\begin{algorithm}[H]
\caption{Optimal routing with BT estimate}
\begin{algorithmic}[1]
\REQUIRE $q$; $\mathbf{W}^*$; $\theta^*(z)_j$; $c$; $C$
\STATE Solve the LP:
\begin{equation}
\tilde\pi^* = \argmax_{\tilde\pi \in \Delta^M, \; \tilde\pi^\top c \le C} \tilde\pi^\top W^* q
\end{equation}
\STATE Compute $R^* = \tilde\pi^{*\top} W^* q$
\STATE Solve for $\theta'^*$ by finding the root of the following implicit equation:
\begin{equation}
\sum_a q_a\,\sigma\bigl(\theta - \theta^*(z)_a\bigr) = R^*
\end{equation}
\ENSURE Optimal router $\tilde\pi^*$, estimate of router's BT coefficient $\theta'^*$
\end{algorithmic}
\label{alg:nested-problem}
\end{algorithm}


\subsection{Prompt-to-Regression}
\label{sec:p2r}

Here, we give extensions of P2L beyond pairwise preference feedback.
This is useful because, in Chatbot Arena, the voting options are not just ``A is better'' and ``B is better''; they also include ``Tie'' and ``Tie (both bad)''. Thus, a P2L model that takes into account all this additional data may learn faster and also learn interesting signals about which prompts are hard and cause models to exhibit different behaviors or failures.
Fortunately, our toolkit generalizes to the case where $X$ is no longer a two-hot encoding and $Y$ is no longer binary.
In fact, our strategy encompasses any parametric statistical model relating $X$ and $Y$ conditionally on $Z$, regardless of the space in which they live.
We call this more general class of models \emph{prompt-to-regression} models.

More formally, let us model the distribution of $Y$ by saying that for all putative values $y$, 
\begin{equation}
    \label{eq:general-p2r}
    p_{Y=y\mid Z=z, X=x}(y) = g_{\theta^*(z)}(y; x),
\end{equation}
for some (unknown) vector of parameters $\theta^*(z)$.
Then, we fit $\hat\theta(z)$ by running maximum-likelihood estimation, i.e., maximizing  $\prod\limits_{i=1}^ng_{\theta(Z_i)}(Y_i;X_i)p_X(X_i)$.
As a familiar example, we can set $g_{\theta^*(z)}$ to a BT model relating $X$ and $Y$:
\begin{equation}
    g_{\theta(z)}(y; x) = \begin{cases}
        \sigma(x^\top \theta^*(z)) & y = 1, \\
        1-\sigma(x^\top \theta^*(z)) & y = 0.
    \end{cases}
\end{equation}
Note that the formulation of~\eqref{eq:general-p2r}, $Y$ and $X$ can be arbitrary, so long as we model their conditional relationship via $g_{\theta(z)}$.
Thus, the framework can admit real-valued feedback $Y$ via ordinary least squares, count feedback via Poisson regression, and so on.

As one example, we will consider incorporating ties via a Rao-Kupper~\citep{rao1967ties} model.
Let $X$ be a two-hot encoding, $Y \in \{\mathsf{A}, \mathsf{B}, \mathsf{tie}\}$, and
\begin{equation}
    g_{\theta^*(z)}(y ; x) = 
    \begin{cases}
        \sigma((x,-1)^\top \theta^*(z)) & y = \mathsf{B}, \\
        \sigma((-x,-1)^\top \theta^*(z)) &  y = \mathsf{A}, \\
        1 - \sigma((-x,-1)^\top \theta^*(z)) - \sigma((x,-1)^\top \theta^*(z)) & y = \mathsf{tie}.
    \end{cases}
\end{equation}

In this technique, $\theta^*(z)$ is an $(M+1)$-dimensional vector, the last entry of which encodes a tie coefficient.
The larger this prompt-dependent tie coefficient, the more likely the two models are to tie. 
Meanwhile, the first $M$ entries, $\hat\theta(z)_{1:M}$, comprise the leaderboard.

Finally, we consider how to handle the ``Tie (both bad)'' category.
For this, we developed a non-standard statistical model which we call the \emph{grounded} Rao-Kupper model. In this model, if both model coefficients are small, it increases the probability of ``Tie (both bad)''. 
Inspired by the Plackett-Luce model \citep{plackett1975analysis, luce1959individual}, we imagine the existence of a fictitious ``bad'' model with a coefficient of zero, and use this as a grounding point for the model coefficients.

Let $Y\in \{\mathsf{A}, \mathsf{B}, \mathsf{tie}, \mathsf{bad}\}$, and for the sake of notational convenience, let $\theta^*(z) = \big(\beta^*(z), \lambda^*(z)\big)$ where $\beta^*(z) \in \mathbb{R}^M$ and $\lambda^*(z) \in \mathbb{R}_{\geq 1}\}$. For notational convenience, we define $\varphi^*(z)_i := \exp(\beta^*(z)_i)$.
The grounded Rao-Kupper model is defined as:
\begin{equation}
    g_{\theta^*(z)}(y ; x) =
    \begin{cases}
        \frac{\varphi^*(z)_A}{\varphi^*(z)_A + \lambda^*(z)\varphi^*(z)_B + 1} &  y = \mathsf{A} \\
        \frac{\varphi^*(z)_B}{\varphi^*(z)_B + \lambda^*(z)\varphi^*(z)_A + 1} &  y = \mathsf{B}\\
        \frac{1}{1 + \varphi^*(z)_A + \varphi^*(z)_B} & y = \mathsf{bad}\\
        1 - \frac{\varphi^*(z)_A}{\varphi^*(z)_A + \lambda^*(z)\varphi^*(z)_B + 1} \\ \ \ \ - \frac{\varphi^*(z)_B}{\varphi^*(z)_B + \lambda^*(z)\varphi^*(z)_A + 1} - \frac{1}{1 + \varphi^*(z)_A + \varphi^*(z)_B} & y = \mathsf{tie}.
    \end{cases}
\label{eq:grounded-rk}
\end{equation}
This model allows us to make efficient use of all data collected on Chatbot Arena by incorporating all votes.
It also has the additional advantage that models with higher coefficients have a lower probability of being labeled ``Tie (both bad)''.
Thus, the raw coefficient value of a model speaks to its absolute quality, as opposed to its comparative quality against other LLMs as in the BT model.
