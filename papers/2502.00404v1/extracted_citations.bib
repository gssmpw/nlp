@article{JPEGartifactreduction,
  title={Residual Network for Image Compression Artifact Reduction},
  author={Hu, Jianhua and Luo, Guixiang and Wang, Bo and Wu, Weimei and Yang, Jiahui and Guo, Jianding},
  journal={International Journal of Pattern Recognition and Artificial Intelligence},
  volume={38},
  number={02},
  pages={2454001},
  year={2024},
  publisher={World Scientific}
}

@article{denoising,
  title={Methods for image denoising using convolutional neural network: a review},
  author={Ilesanmi, Ademola E and Ilesanmi, Taiwo O},
  journal={Complex \& Intelligent Systems},
  volume={7},
  number={5},
  pages={2179--2198},
  year={2021},
  publisher={Springer}
}

@inproceedings{hat,
  title={Activating more pixels in image super-resolution transformer},
  author={Chen, Xiangyu and Wang, Xintao and Zhou, Jiantao and Qiao, Yu and Dong, Chao},
  booktitle={Proceedings of the IEEE/CVF conference on computer vision and pattern recognition},
  pages={22367--22377},
  year={2023}
}

@article{mamba,
  title={Mamba: Linear-time sequence modeling with selective state spaces},
  author={Gu, Albert and Dao, Tri},
  journal={arXiv preprint arXiv:2312.00752},
  year={2023},
  note={online}
}

@inproceedings{mambair,
  title={Mambair: A simple baseline for image restoration with state-space model},
  author={Guo, Hang and Li, Jinmin and Dai, Tao and Ouyang, Zhihao and Ren, Xudong and Xia, Shutao},
  booktitle={European Conference on Computer Vision},
  pages={222--241},
  year={2025},
  organization={Springer}
}

@article{rwkv,
  title={Rwkv: Reinventing rnns for the transformer era},
  author={Peng, Bo and Alcaide, Eric and Anthony, Quentin and Albalak, Alon and Arcadinho, Samuel and Biderman, Stella and others},
  journal={arXiv preprint arXiv:2305.13048},
  year={2023},
  note={online}
}

@article{s4,
  title={Efficiently modeling long sequences with structured state spaces},
  author={Gu, Albert and Goel, Karan and R{\'e}, Christopher},
  journal={arXiv preprint arXiv:2111.00396},
  year={2021},
  note={online}
}

@article{swinfir,
  title={Swinfir: Revisiting the swinir with fast fourier convolution and improved training for image super-resolution},
  author={Zhang, Dafeng and Huang, Feiyu and Liu, Shizhuo and Wang, Xiaobing and Jin, Zhezhu},
  journal={arXiv preprint arXiv:2208.11247},
  year={2022},
  note={online}
}

@inproceedings{swinir,
  title={Swinir: Image restoration using swin transformer},
  author={Liang, Jingyun and Cao, Jiezhang and Sun, Guolei and Zhang, Kai and Van Gool, Luc and Timofte, Radu},
  booktitle={Proceedings of the IEEE/CVF International Conference on Computer Vision},
  pages={1833--1844},
  year={2021}
}

@article{vision-mamba,
  title={Vision mamba: Efficient visual representation learning with bidirectional state space model},
  author={Zhu, Lianghui and Liao, Bencheng and Zhang, Qian and Wang, Xinlong and Liu, Wenyu and Wang, Xinggang},
  journal={arXiv preprint arXiv:2401.09417},
  year={2024},
  note={online}
}

@article{visiontransformer,
  title={An image is worth 16x16 words: Transformers for image recognition at scale},
  author={Dosovitskiy, Alexey},
  journal={arXiv preprint arXiv:2010.11929},
  year={2020},
  note={online}
}

