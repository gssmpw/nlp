\section{Related Work}
\paragraph{HRI Personalization.}
This paradigm enables adaptive robotic systems to tailor behaviors, responses, and functionalities to individual users, enhancing user engagement and task efficacy in critical domains such as healthcare____, education____, and assistive robotics____. Prior work, including ____, has investigated personalization and localization frameworks in social robotics, highlighting both capabilities and constraints of current approaches. A persistent limitation lies in the lack of modality-specific representation learning, which impedes cross-modal reasoning, generalization across heterogeneous perceptual inputs, and contextual adaptation in dynamic environments____.

\paragraph{Personalized VLMs.} Recent advancements in personalized LLMs have demonstrated empirical success in aligning outputs with individual user preferences and contextual histories____. However, the adaptation of VLMs for HRI remains an under-explored frontier. While foundational frameworks such as MyVLM____, Meta-Personalizing VLM____ and MC-LLaVA____ establish preliminary methodologies for VLM personalization, these approaches fail to address persistent challenges unique to HRI. Critically, current methods overlook (1) the intrinsic complexity of multimodal alignment (2) sociotechnical risks such as privacy erosion and bias amplification stemming from personalized model behaviors in socially embedded robotic systems. % For instance, meta-personalization techniques proposed for video instance retrieval____ focus narrowly on retrieval tasks without addressing real-time interaction dynamics or safeguarding against biases. 



\paragraph{VLMs for HRI.} Parallel research efforts have explored VLM-based approaches to HRI, tackling challenges in task planning, interpretability, and multimodal perception. Notable contributions include the VLM See, Robot Do framework____, which effectively translates human demonstration videos into executable robot action plans, demonstrating superior performance in long-horizon tasks. Additionally, HuBo-VLM____ has made strides by unifying visual grounding and object detection, showcasing robust performance on benchmarks such as Talk2Car____. However, these frameworks, often built on top of visual foundation models, are predominantly Retrieval-Augmented Generation (RAG)-based____ and not inherently personalized. They incur high processing costs, latency, and require intensive prompt engineering and computational resources. Furthermore, while task-specific fine-tuning approaches like AlignBot____ exist, they lack a holistic consideration of user bias, privacy, and ethical concerns.