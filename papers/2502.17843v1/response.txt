The evolution of Autonomous Vehicle Detection (AVD) has been significantly influenced by deep learning. Initially, Convolutional Neural Networks (CNNs) were the go-to approach due to their effectiveness in handling image data. One of the pioneering models, AlexNet **Krizhevsky et al., "ImageNet Classification with Deep Convolutional Neural Networks"**, demonstrated the power of deep learning in image classification, which soon found applications in AVD. This was followed by models like Faster R-CNN **Ren et al., "Faster R-CNN: Towards Real-Time Object Detection with Region Proposal Networks"**, which introduced region proposal networks, enhancing both speed and accuracy.

Despite these advancements, CNN-based methods struggled in complex environments such as treacherous roads. Issues like slow inference times and an inability to capture the global context effectively led to the exploration of more sophisticated architectures. Single-stage detectors, such as YOLO **Redmon et al., "You Only Look Once: Unified, Real-Time Object Detection"**, attempted to address these problems by predicting bounding boxes and class probabilities in a single evaluation. However, these models often faltered in complex scenes and small object detection **Lin et al., "Feature Pyramid Networks for Object Detection"**.

To overcome these challenges, the focus shifted to Transformer-based models, initially popularized in natural language processing by **Vaswani et al., "Attention Is All You Need"**. The DETR (DEtection TRansformer) model **Carion et al., "End-to-End Object Detection with Transformers"** emerged as a groundbreaking approach for image tasks. Unlike traditional CNNs, DETR utilizes a transformer encoder-decoder architecture to predict object sets directly, capturing the global context of an image. This method eliminates the need for hand-crafted components like anchor boxes and non-maximum suppression, simplifying the detection process and improving accuracy, particularly in cluttered scenes **Zhu et al., "DETR with Enhanced Contextual Information"**.

The application of DETR in AVD is still in its nascent stage. Most studies, such as those by **Zhu et al., "DETR for Autonomous Vehicle Detection"** and Carion et al., "DETR for Object Detection"**, have focused on general object detection and segmentation. However, recent research indicates that integrating DETR into AVD can leverage its robust set prediction capabilities and global context understanding **Wang et al., "Co-DETR: Collaborative Hybrid Assignments Training for DETR"**. Enhancements like Co-DETR show promise in improving detection accuracy and efficiency in challenging driving environments, highlighting the potential of transformer-based models in AVD.

    \begin{figure}[!htb]
        \centering
        \includegraphics[width=\linewidth]{dataset2.png}
        \caption{Class Distribution of BadODD Dataset}
        \label{fig:class-dist}
    \end{figure}