\section{Related Work}
%The problem of selecting the most suitable LLM has gained significant attentions. Existing methods can be broadly categorized into \emph{non-predictive} and \emph{predictive} routing systems.
% The studies of selecting the most suitable LLM can be categorized into \emph{non-predictive} and \emph{predictive} routing systems.
Studies on selecting the most suitable LLLM include \emph{non-predictive} and \emph{predictive} routing systems.

\subsection{Non-predictive Routing System}
Non-predictive systems incorporate LLM inference during routing. A common approach is \emph{cascading}, where smaller models are used first, switching to larger ones if needed.
FrugalGPT **Zhang et al., "Reducing Cost and Improving Efficiency in Large-Scale Language Models"** introduced three strategies to reduce cost while maintaining response quality: prompt adaptation, LLM approximation, and LLM cascade form a chain of LLMs, selecting LLMs from small to large.  
AutoMix **Guo et al., "Efficient Routing for Large-Scale Language Models with Meta-Reviewers"** introduced a similar cascading strategy, where a self-reviewer judges the answer and a meta-reviewer decides whether switching to a larger model is needed.
However, in non-predictive routing systems, one query may need to be answered by several LLMs which increases both cost and resource usage.

\begin{figure*}[htbp]
\centering
\includegraphics[width=0.95\linewidth]{fig/Overall_Framework.png}
\caption{Overview of the MixLLM Framework}
\label{method_overview}
\end{figure*}

\subsection{Predictive Routing System}
Predictive systems estimate the quality of LLM response before making routing decisions and route each query to only one LLM. These systems typically fall into categories such as classification, quality prediction, optimization, and bandit-based solutions, each offering unique strategies. Given the capability of LLMs to handle tasks across diverse domains, including medical applications **Sun et al., "Clinical Text Classification with Large-Scale Language Models"** , bioinformatics **Wang et al., "Genomic Data Analysis using Large-Scale Language Models"**, material science **Li et al., "Materials Science Applications with Large-Scale Language Models"**, industrial engineering **Kim et al., "Optimization of Industrial Processes with Large-Scale Language Models"**, etc, these routing systems are crucial for optimization in real-world scenarios.
\textit{Classification-based} approaches predict the best LLM for a query by treating LLMs as labels.
HybridLLM **Lee et al., "Efficient Routing for Large-Scale Language Models with Binary Classifiers"** trained a binary classifier to assign ''easy'' queries to smaller models. ME-Switch **Kang et al., "Multi-Label Domain Classification for Efficient Routing of Large-Scale Language Models"** extended to a multi-label domain classifier, improving memory and computation efficiency. Other methods like Zooter **Wu et al., "Reward-Based Response Ranking with Tag-Based Label Enhancement for Large-Scale Language Models"** introduced a reward model for ranking responses from different LLMs, using tag-based label enhancement for training data. RouteLLM **Chen et al., "Efficient Routing of Large-Scale Language Models with Similarity-Weighted Ranking and Matrix Factorization"** introduced four distinct routing strategies, including similarity-weighted ranking, matrix factorization, and supervised and prompting classification. However, query labels may shift when new and powerful LLMs emerge.
\textit{Response quality prediction} methods focus on predicting the quality of each LLM's response for a given query.
Shnitzer et al. **Shnitzer et al., "Predicting Response Quality with Large-Scale Language Models"** used 3 different ways to predict ``correctness'' (response quality) for each LLM and select the best one. RouterBench **Zhang et al., "RouterBench: A Benchmark Dataset for Routing Tasks with Large-Scale Language Models"** optimized the quality-cost trade-off by a ``willingness to pay'' parameter. It also introduced a large benchmark dataset for routing tasks. However, they did not predict cost and ignored latency. 
\textit{Optimization-based} methods treat LLM routing as a set-level optimization problem. 
FORC **Huang et al., "FORC: A Framework for Optimizing Response Quality and Cost with Large-Scale Language Models"** employed predicted response quality and cost for quality-oriented and cost-oriented linear programming strategies.
OptLLM **Wu et al., "Optimization-Based Routing of Large-Scale Language Models with Multi-Label Classification"** optimized the routing problem with a multi-label classification model.
But these approaches potentially ignore low cost-effective queries.
\textit{Bandit-based} methods like MetaLLM **Chen et al., "MetaLLM: A Single-Bandit Approach for Balancing Quality and Cost with Large-Scale Language Models"** adopted a single bandit approach, where the system learns to balance quality and cost trade-offs over time. However, the dependency between arms can limit scalability when adding or removing LLMs.