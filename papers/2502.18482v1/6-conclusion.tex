\section{Conclusion}

% \subsection{Conclusion}
% We proposed MixLLM, a predictive routing method that efficiently selects the most suitable LLM for each query by considering both response quality and cost in a dynamic environment. Our approach utilizes a contextual multi-armed bandit algorithm to balance response quality, cost, and latency. By incorporating cost and latency constraints into the routing process, MixLLM becomes particularly practical for real-world applications where resource management is crucial.
% The experimental results demonstrate that MixLLM effectively balances cost and response quality, consistently outperforming baselines across various scenarios. The incorporation of latency penalties helps prevent bottlenecks, ensuring stable response quality even under high-budget conditions. Moreover, adaptive training enhances the system's ability to optimize query distribution by continuously learning from new data. Flexible selection policies further boost efficiency by dynamically adjusting the choice of LLMs based on available resources. These findings underscore the robustness and versatility of MixLLM in real-world applications.

We proposed MixLLM, a dynamic routing system that selects the most suitable LLM for each query by balancing response quality, cost, and latency. By enhancing query embeddings with tag knowledge and incorporating latency constraints, MixLLM effectively addresses key challenges in real-world LLM deployment. The system's adaptability, achieved through continual learning and independent prediction for each LLM, ensures efficiency as queries evolve and new models are introduced. Our results demonstrate that MixLLM optimizes resource usage while maintaining strong performance across varying budget levels.


% \subsection{Limitation and Future Work}
% Despite its strengths, there are still limitations that need to be addressed.
% First, the number of queries and LLMs could be expanded. As foundation models rapidly evolve, queries and models are no longer limited to specific domains or types. Future work should explore how the routing system performs in a more diverse and expansive environment.
% Second, future research could focus on developing more precise prediction models. Additionally, exploring training-free models, such as those based on scaling laws, could be a promising direction to improve the efficiency of the routing process.
% Third, a hierarchical routing system could be developed. Due to the significant differences between queries, incorporating rule-based methods could greatly enhance both effectiveness and efficiency. For example, a sub-system dedicated to routing biological queries could be integrated, and a rule-based meta-classifier could direct queries to the appropriate sub-system first.

% While MixLLM performs well, there are areas for improvement. 
% First, expanding the number of queries and LLMs would make the system more versatile. 
% Second, improving predictors and exploring training-free methods could enhance efficiency. 
% Lastly, developing a hierarchical routing system, with rules tailored to specific query types, could further increase both accuracy and scalability.

