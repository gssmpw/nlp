[
  {
    "index": 0,
    "papers": [
      {
        "key": "konecny2016federated",
        "author": "Konecn{\\`y}, Jakub and McMahan, H Brendan and Yu, Felix X and Richt{\\'a}rik, Peter and Suresh, Ananda Theertha and Bacon, Dave",
        "title": "Federated learning: Strategies for improving communication efficiency"
      }
    ]
  },
  {
    "index": 1,
    "papers": [
      {
        "key": "nasr2019comprehensive",
        "author": "Nasr, Milad and Shokri, Reza and Houmansadr, Amir",
        "title": "Comprehensive privacy analysis of deep learning: Passive and active white-box inference attacks against centralized and federated learning"
      },
      {
        "key": "shokri2017membership",
        "author": "Shokri, Reza and Stronati, Marco and Song, Congzheng and Shmatikov, Vitaly",
        "title": "Membership inference attacks against machine learning models"
      },
      {
        "key": "baracaldo2022protecting",
        "author": "Baracaldo, Nathalie and Xu, Runhua",
        "title": "Protecting against data leakage in federated learning: What approach should you choose?"
      },
      {
        "key": "nasr2019comprehensive",
        "author": "Nasr, Milad and Shokri, Reza and Houmansadr, Amir",
        "title": "Comprehensive privacy analysis of deep learning: Passive and active white-box inference attacks against centralized and federated learning"
      },
      {
        "key": "huang2021evaluating",
        "author": "Huang, Yangsibo and Gupta, Samyak and Song, Zhao and Li, Kai and Arora, Sanjeev",
        "title": "Evaluating gradient inversion attacks and defenses in federated learning"
      },
      {
        "key": "geiping2020inverting",
        "author": "Geiping, Jonas and Bauermeister, Hartmut and Dr{\\\"o}ge, Hannah and Moeller, Michael",
        "title": "Inverting gradients-how easy is it to break privacy in federated learning?"
      }
    ]
  },
  {
    "index": 2,
    "papers": [
      {
        "key": "liu2019secure",
        "author": "Liu, Changchang and Chakraborty, Supriyo and Verma, Dinesh",
        "title": "Secure model fusion for distributed learning using partial homomorphic encryption"
      },
      {
        "key": "zhang2020batchcrypt",
        "author": "Zhang, Chengliang and Li, Suyi and Xia, Junzhe and Wang, Wei and Yan, Feng and Liu, Yang",
        "title": "Batchcrypt: Efficient homomorphic encryption for cross-silo federated learning"
      }
    ]
  },
  {
    "index": 3,
    "papers": [
      {
        "key": "truex2019hybrid",
        "author": "Truex, Stacey and Baracaldo, Nathalie and Anwar, Ali and Steinke, Thomas and Ludwig, Heiko and Zhang, Rui and Zhou, Yi",
        "title": "A hybrid approach to privacy-preserving federated learning"
      }
    ]
  },
  {
    "index": 4,
    "papers": [
      {
        "key": "xu2019hybridalpha",
        "author": "Xu, Runhua and Baracaldo, Nathalie and Zhou, Yi and Anwar, Ali and Ludwig, Heiko",
        "title": "Hybridalpha: An efficient approach for privacy-preserving federated learning"
      }
    ]
  },
  {
    "index": 5,
    "papers": [
      {
        "key": "bonawitz2017practical",
        "author": "Bonawitz, Keith and Ivanov, Vladimir and Kreuter, Ben and Marcedone, Antonio and McMahan, H Brendan and Patel, Sarvar and Ramage, Daniel and Segal, Aaron and Seth, Karn",
        "title": "Practical secure aggregation for privacy-preserving machine learning"
      }
    ]
  },
  {
    "index": 6,
    "papers": [
      {
        "key": "liu2019secure",
        "author": "Liu, Changchang and Chakraborty, Supriyo and Verma, Dinesh",
        "title": "Secure model fusion for distributed learning using partial homomorphic encryption"
      },
      {
        "key": "zhang2020batchcrypt",
        "author": "Zhang, Chengliang and Li, Suyi and Xia, Junzhe and Wang, Wei and Yan, Feng and Liu, Yang",
        "title": "Batchcrypt: Efficient homomorphic encryption for cross-silo federated learning"
      }
    ]
  },
  {
    "index": 7,
    "papers": [
      {
        "key": "truex2019hybrid",
        "author": "Truex, Stacey and Baracaldo, Nathalie and Anwar, Ali and Steinke, Thomas and Ludwig, Heiko and Zhang, Rui and Zhou, Yi",
        "title": "A hybrid approach to privacy-preserving federated learning"
      }
    ]
  },
  {
    "index": 8,
    "papers": [
      {
        "key": "xu2019hybridalpha",
        "author": "Xu, Runhua and Baracaldo, Nathalie and Zhou, Yi and Anwar, Ali and Ludwig, Heiko",
        "title": "Hybridalpha: An efficient approach for privacy-preserving federated learning"
      }
    ]
  },
  {
    "index": 9,
    "papers": [
      {
        "key": "bonawitz2017practical",
        "author": "Bonawitz, Keith and Ivanov, Vladimir and Kreuter, Ben and Marcedone, Antonio and McMahan, H Brendan and Patel, Sarvar and Ramage, Daniel and Segal, Aaron and Seth, Karn",
        "title": "Practical secure aggregation for privacy-preserving machine learning"
      }
    ]
  },
  {
    "index": 10,
    "papers": [
      {
        "key": "truex2019hybrid",
        "author": "Truex, Stacey and Baracaldo, Nathalie and Anwar, Ali and Steinke, Thomas and Ludwig, Heiko and Zhang, Rui and Zhou, Yi",
        "title": "A hybrid approach to privacy-preserving federated learning"
      }
    ]
  },
  {
    "index": 11,
    "papers": [
      {
        "key": "xie2020fall",
        "author": "Xie, Cong and Koyejo, Oluwasanmi and Gupta, Indranil",
        "title": "Fall of empires: Breaking byzantine-tolerant sgd by inner product manipulation"
      }
    ]
  },
  {
    "index": 12,
    "papers": [
      {
        "key": "bagdasaryan2020backdoor",
        "author": "Bagdasaryan, Eugene and Veit, Andreas and Hua, Yiqing and Estrin, Deborah and Shmatikov, Vitaly",
        "title": "How to backdoor federated learning"
      }
    ]
  },
  {
    "index": 13,
    "papers": [
      {
        "key": "baruch2019little",
        "author": "Baruch, Gilad and Baruch, Moran and Goldberg, Yoav",
        "title": "A little is enough: Circumventing defenses for distributed learning"
      }
    ]
  },
  {
    "index": 14,
    "papers": [
      {
        "key": "sun2021fl",
        "author": "Sun, Jingwei and Li, Ang and DiValentin, Louis and Hassanzadeh, Amin and Chen, Yiran and Li, Hai",
        "title": "Fl-wbc: Enhancing robustness against model poisoning attacks in federated learning from a client perspective"
      }
    ]
  },
  {
    "index": 15,
    "papers": [
      {
        "key": "blanchard2017machine",
        "author": "Blanchard, Peva and El Mhamdi, El Mahdi and Guerraoui, Rachid and Stainer, Julien",
        "title": "Machine learning with adversaries: Byzantine tolerant gradient descent"
      },
      {
        "key": "sun2019can",
        "author": "Sun, Ziteng and Kairouz, Peter and Suresh, Ananda Theertha and McMahan, H Brendan",
        "title": "Can you really backdoor federated learning?"
      },
      {
        "key": "yaldiz2023secure",
        "author": "Yaldiz, Duygu Nur and Zhang, Tuo and Avestimehr, Salman",
        "title": "Secure Federated Learning against Model Poisoning Attacks via Client Filtering"
      },
      {
        "key": "yin2018byzantine",
        "author": "Yin, Dong and Chen, Yudong and Kannan, Ramchandran and Bartlett, Peter",
        "title": "Byzantine-robust distributed learning: Towards optimal statistical rates"
      }
    ]
  },
  {
    "index": 16,
    "papers": [
      {
        "key": "xie2020fall",
        "author": "Xie, Cong and Koyejo, Oluwasanmi and Gupta, Indranil",
        "title": "Fall of empires: Breaking byzantine-tolerant sgd by inner product manipulation"
      }
    ]
  },
  {
    "index": 17,
    "papers": [
      {
        "key": "bagdasaryan2020backdoor",
        "author": "Bagdasaryan, Eugene and Veit, Andreas and Hua, Yiqing and Estrin, Deborah and Shmatikov, Vitaly",
        "title": "How to backdoor federated learning"
      }
    ]
  },
  {
    "index": 18,
    "papers": [
      {
        "key": "baruch2019little",
        "author": "Baruch, Gilad and Baruch, Moran and Goldberg, Yoav",
        "title": "A little is enough: Circumventing defenses for distributed learning"
      }
    ]
  },
  {
    "index": 19,
    "papers": [
      {
        "key": "sun2021fl",
        "author": "Sun, Jingwei and Li, Ang and DiValentin, Louis and Hassanzadeh, Amin and Chen, Yiran and Li, Hai",
        "title": "Fl-wbc: Enhancing robustness against model poisoning attacks in federated learning from a client perspective"
      }
    ]
  },
  {
    "index": 20,
    "papers": [
      {
        "key": "blanchard2017machine",
        "author": "Blanchard, Peva and El Mhamdi, El Mahdi and Guerraoui, Rachid and Stainer, Julien",
        "title": "Machine learning with adversaries: Byzantine tolerant gradient descent"
      }
    ]
  },
  {
    "index": 21,
    "papers": [
      {
        "key": "sun2019can",
        "author": "Sun, Ziteng and Kairouz, Peter and Suresh, Ananda Theertha and McMahan, H Brendan",
        "title": "Can you really backdoor federated learning?"
      },
      {
        "key": "yaldiz2023secure",
        "author": "Yaldiz, Duygu Nur and Zhang, Tuo and Avestimehr, Salman",
        "title": "Secure Federated Learning against Model Poisoning Attacks via Client Filtering"
      }
    ]
  },
  {
    "index": 22,
    "papers": [
      {
        "key": "yin2018byzantine",
        "author": "Yin, Dong and Chen, Yudong and Kannan, Ramchandran and Bartlett, Peter",
        "title": "Byzantine-robust distributed learning: Towards optimal statistical rates"
      }
    ]
  },
  {
    "index": 23,
    "papers": [
      {
        "key": "yang2023model",
        "author": "Yang, Ming and Cheng, Hang and Chen, Fei and Liu, Ximeng and Wang, Meiqing and Li, Xibin",
        "title": "Model poisoning attack in differential privacy-based federated learning"
      },
      {
        "key": "hossain2021desmp",
        "author": "Hossain, Md Tamjid and Islam, Shafkat and Badsha, Shahriar and Shen, Haoting",
        "title": "Desmp: Differential privacy-exploited stealthy model poisoning attacks in federated learning"
      },
      {
        "key": "jiang2020mitigating",
        "author": "Jiang, Yupeng and Li, Yong and Zhou, Yipeng and Zheng, Xi",
        "title": "Mitigating sybil attacks on differential privacy based federated learning"
      },
      {
        "key": "huang2024vppfl",
        "author": "Huang, Yuxian and Yang, Geng and Zhou, Hao and Dai, Hua and Yuan, Dong and Yu, Shui",
        "title": "VPPFL: A verifiable privacy-preserving federated learning scheme against poisoning attacks"
      }
    ]
  },
  {
    "index": 24,
    "papers": [
      {
        "key": "dong2023privacy",
        "author": "Dong, Caiqin and Weng, Jian and Li, Ming and Liu, Jia-Nan and Liu, Zhiquan and Cheng, Yudan and Yu, Shui",
        "title": "Privacy-preserving and byzantine-robust federated learning"
      }
    ]
  },
  {
    "index": 25,
    "papers": [
      {
        "key": "zhang2023safelearning",
        "author": "Zhang, Zhuosheng and Li, Jiarui and Yu, Shucheng and Makaya, Christian",
        "title": "Safelearning: Secure aggregation in federated learning with backdoor detectability"
      }
    ]
  },
  {
    "index": 26,
    "papers": [
      {
        "key": "li2024efficiently",
        "author": "Li, Xueyang and Yang, Xue and Zhou, Zhengchun and Lu, Rongxing",
        "title": "Efficiently Achieving Privacy Preservation and Poisoning Attack Resistance in Federated Learning"
      }
    ]
  },
  {
    "index": 27,
    "papers": [
      {
        "key": "ma2022shieldfl",
        "author": "Ma, Zhuoran and Ma, Jianfeng and Miao, Yinbin and Li, Yingjiu and Deng, Robert H",
        "title": "ShieldFL: Mitigating model poisoning attacks in privacy-preserving federated learning"
      }
    ]
  },
  {
    "index": 28,
    "papers": [
      {
        "key": "yang2023model",
        "author": "Yang, Ming and Cheng, Hang and Chen, Fei and Liu, Ximeng and Wang, Meiqing and Li, Xibin",
        "title": "Model poisoning attack in differential privacy-based federated learning"
      },
      {
        "key": "hossain2021desmp",
        "author": "Hossain, Md Tamjid and Islam, Shafkat and Badsha, Shahriar and Shen, Haoting",
        "title": "Desmp: Differential privacy-exploited stealthy model poisoning attacks in federated learning"
      },
      {
        "key": "jiang2020mitigating",
        "author": "Jiang, Yupeng and Li, Yong and Zhou, Yipeng and Zheng, Xi",
        "title": "Mitigating sybil attacks on differential privacy based federated learning"
      },
      {
        "key": "huang2024vppfl",
        "author": "Huang, Yuxian and Yang, Geng and Zhou, Hao and Dai, Hua and Yuan, Dong and Yu, Shui",
        "title": "VPPFL: A verifiable privacy-preserving federated learning scheme against poisoning attacks"
      }
    ]
  },
  {
    "index": 29,
    "papers": [
      {
        "key": "dong2023privacy",
        "author": "Dong, Caiqin and Weng, Jian and Li, Ming and Liu, Jia-Nan and Liu, Zhiquan and Cheng, Yudan and Yu, Shui",
        "title": "Privacy-preserving and byzantine-robust federated learning"
      }
    ]
  },
  {
    "index": 30,
    "papers": [
      {
        "key": "li2024efficiently",
        "author": "Li, Xueyang and Yang, Xue and Zhou, Zhengchun and Lu, Rongxing",
        "title": "Efficiently Achieving Privacy Preservation and Poisoning Attack Resistance in Federated Learning"
      }
    ]
  },
  {
    "index": 31,
    "papers": [
      {
        "key": "ma2022shieldfl",
        "author": "Ma, Zhuoran and Ma, Jianfeng and Miao, Yinbin and Li, Yingjiu and Deng, Robert H",
        "title": "ShieldFL: Mitigating model poisoning attacks in privacy-preserving federated learning"
      }
    ]
  },
  {
    "index": 32,
    "papers": [
      {
        "key": "zhang2023safelearning",
        "author": "Zhang, Zhuosheng and Li, Jiarui and Yu, Shucheng and Makaya, Christian",
        "title": "Safelearning: Secure aggregation in federated learning with backdoor detectability"
      }
    ]
  }
]