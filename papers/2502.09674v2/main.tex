\documentclass{article}

% Recommended, but optional, packages for figures and better typesetting:
\usepackage{microtype}
\usepackage{graphicx}
\usepackage{subfigure}
\usepackage{booktabs} % for professional tables

% hyperref makes hyperlinks in the resulting PDF.
\usepackage{hyperref}

% Attempt to make hyperref and algorithmic work together better:
% \usepackage{algorithm}
% \usepackage{algpseudocode}
% \usepackage{algorithmic}
\newcommand{\theHalgorithm}{\arabic{algorithm}}

% For theorems and such
\usepackage{amsmath}
\usepackage{amssymb}
\usepackage{mathtools}
\usepackage{amsthm}
\usepackage[dvipsnames]{xcolor}
\usepackage{colortbl}
\usepackage{array}


% Clever referencing
\usepackage[capitalize,noabbrev]{cleveref}

% ICML Style
\usepackage[accepted]{icml2024}

% Theorem environments
\theoremstyle{plain}
\newtheorem{theorem}{Theorem}[section]
\newtheorem{proposition}[theorem]{Proposition}
\newtheorem{lemma}[theorem]{Lemma}
\newtheorem{corollary}[theorem]{Corollary}
\theoremstyle{definition}
\newtheorem{definition}[theorem]{Definition}
\theoremstyle{remark}
\newtheorem{remark}[theorem]{Remark}
\setlength{\fboxsep}{0pt} % Padding around text
\setlength{\fboxrule}{0pt} % Border thickness (set to 0 to remove border)
\newcommand{\cbt}[2][]{%
  \colorbox[RGB]{255,#2,#2}{\texttt{#1}}%
}
\newcommand{\strongreject}{\textsc{StrongReject} }

% Add near the beginning of the document:
\usepackage{natbib}

% Add near the beginning with other packages:
\usepackage{multirow}
\usepackage{makecell}  % Also needed for \makecell commands
\usepackage{wrapfig}

% Add for appendix
\usepackage[most]{tcolorbox}
\usepackage{caption}    % \captionof
\usepackage{tabularx}   % table with auto width
\usepackage{multirow}   % multi-row header
\usepackage{booktabs}   % professional table lines

\icmltitlerunning{The Hidden Dimensions of LLM Alignment}

\begin{document}

\twocolumn[
\icmltitle{The Hidden Dimensions of LLM Alignment: \\ A Multi-Dimensional Safety Analysis}


% \icmlsetsymbol{equal}{*}

\begin{icmlauthorlist}
\icmlauthor{Wenbo Pan}{cityu}
\icmlauthor{Zhichao Liu}{hit}
\icmlauthor{Qiguang Chen}{scir}
\icmlauthor{Xiangyang Zhou}{microsoft}
\icmlauthor{Haining Yu}{hit}
\icmlauthor{Xiaohua Jia}{cityu}
\end{icmlauthorlist}

\icmlaffiliation{cityu}{Department of Computer Science, City University of Hong Kong, Hong Kong}
\icmlaffiliation{hit}{School of Cyberspace Science, Harbin Institute of Technology, China}
\icmlaffiliation{scir}{Research Center for Social Computing and Information Retrieval, Harbin Institute of Technology, China}
\icmlaffiliation{microsoft}{Microsoft}

\icmlcorrespondingauthor{Wenbo Pan}{wenbo.pan@my.cityu.edu.hk}

\icmlkeywords{Machine Learning, Causal Attribution, Jailbreaks, LLMs}

\vskip 0.3in
]

\printAffiliationsAndNotice{}

\begin{abstract}

Large Language Models' safety-aligned behaviors, such as refusing harmful queries, can be represented by linear directions in activation space. Previous research modeled safety behavior with a single direction, limiting mechanistic understanding to an isolated safety feature. In this work, we discover that safety-aligned behavior is jointly controlled by multi-dimensional directions. Namely, we study the vector space of representation shifts during safety fine-tuning on Llama 3 8B for refusing jailbreaks. By studying orthogonal directions in the space, we first find that a dominant direction governs the model's refusal behavior, while multiple smaller directions represent distinct and interpretable features like hypothetical narrative and role-playing. We then measure how different directions promote or suppress the dominant direction, showing the important role of secondary directions in shaping the model's refusal representation. Finally, we demonstrate that removing certain trigger tokens in harmful queries can mitigate these directions to bypass the learned safety capability, providing new insights on understanding safety alignment vulnerability from a multi-dimensional perspective. 
Code and artifacts are available at \url{https://github.com/BMPixel/safety-residual-space}.

\end{abstract}

\input{sections/introduction}
\input{sections/preliminaries}
\input{sections/safety_residual_space}
\input{sections/linearity}
\input{sections/interpretation.tex}
\input{sections/application.tex}
\input{sections/discussion.tex}
\input{sections/related_works.tex}

\section{Conclusion}
In this work, we provide a multi-dimensional mechanistic understanding of \emph{what LLMs learn from safety fine-tuning}. We identify multiple feature directions that jointly control safety behavior---a hidden dimension previously invisible to probing or static methods. We characterize the residual space and uncover key roles of non-dominant directions in affecting the model's safety behavior, linking them to specific trigger tokens. These insights into the underlying safety mechanisms shed new light on robust alignment research. One promising direction is preventing models from learning spurious correlations through targeted interventions in activation space or data augmentation for balanced training. We leave these possibilities for future work.

\section*{Impact Statement}
Our research shows methods for analyzing and bypassing LLM safety mechanisms, which could enable harmful content generation. We acknowledge these risks and emphasize the need for careful use of our methods. However, since multiple effective jailbreaks for the studied models are already public, our work does not create new safety concerns. We therefore believe sharing our code and methods openly benefits the research community by supporting reproducibility and future safety research.

\section*{Acknowledgments}
We thank Jianfei He, Xiang Li and Yulong Ming for their valuable feedback and suggestions that helped improve this paper.

\bibliography{custom}
\bibliographystyle{icml2024}


\appendix
\include{sections/appendix}

\end{document}