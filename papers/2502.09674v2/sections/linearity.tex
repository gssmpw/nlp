\begin{figure}
    \vskip 0.2in
    \begin{center}
    \center{\includegraphics[width=\columnwidth]{figures/fig_rank.pdf}}
    \vspace{-0.2in}
    \caption{Effective rank of the residual space by layer.}
    \label{fig:rank}
    \end{center}
    % \vskip -0.2in
\end{figure}

\section{Linearity of Safety Residual Space}
\label{sec:linear}

In this section, we analyze the residual space derived from the SSFT and DPO experiments. We focus on two key linear characteristics of orthogonal directions in the residual space:

\begin{itemize}
    \item \textbf{Effective Rank:} We measure the linear dimensionality of the residual space using effective rank $k$. Given an energy threshold $\tau$, we calculate $k$ as the minimum number of orthogonal components needed to explain $\tau$ percent of the variance in the representation shift. Here, $\sigma_i$ denotes the singular values of the matrix $\mathbf{W} - \mathbf{I}$.

    \[
        k = \min \left\{ r : \frac{\sum_{i=1}^{r} \sigma_i^2}{\sum_{i=1}^{n} \sigma_i^2} \geq \tau \right\}
    \]
    
    \item \textbf{Dominant Component:} We define this as the first component of $\mathrm{SVD}(\mathbf{W} - \mathbf{I})$, the direction of which explains the majority of the shift's variability. We show that this dominant direction predicts the model's aligned behavior (i.e., refusal of harmful requests). We compare it to the refusal direction \cite{arditi2024refusal}, a \emph{probe vector} in the activation space that best explains the model's refusal behavior. To evaluate these vectors' predictive power, we use them as weights in linear binary classifiers that distinguish between compliant and refusing responses.
\end{itemize}

\paragraph{Safety Residual Space is Low-Rank Linear}

As shown in \autoref{fig:rank}, both DPO and SSFT exhibit closely concentrated eigenvalues with long-tail spectrum distributions across all layers, indicating that the residual space is approximately low-rank linear. For SSFT, the effective rank remains at 1 across different $\tau$ values in the first 10 layers, suggesting that safety training neither introduces nor strengthens new directionsâ€”this aligns with the mid-early safety layer hypothesis proposed by \citet{li2024safety}. The effective rank then increases and peaks around the 20th layer, indicating more diverse directions in the representations. Interestingly, while $k$ decreases to 1 at the final layer for SSFT, it continues to increase for DPO. We conjecture this difference to DPO's pair-wise preference dataset, which leads to more diverse outputs compared to SSFT.


% \begin{table}[t]
%     \caption{Model output prediction accuracy of the dominant component and probe vector for SSFT. Accuracy is measured as average across all layers. Dominant use the most dominant component in each layer. Probe\textsuperscript{test} and Probe\textsuperscript{train} are the accuracy of the probe vector on the test and training dataset respectively.}
%     \label{tab:model_accuracy}
%     \vskip 0.15in
%     \begin{center}
%     \begin{small}
%     \begin{sc}
%     \setlength\tabcolsep{5pt}
%     \begin{tabular}{lccc}
%     \toprule
%     Vector       & Dominant & Probe\textsuperscript{test} & Probe\textsuperscript{train} \\
%     \midrule
%     OrBench       & \textbf{0.997}   & 0.994 & 1.000       \\
%     Strong Reject  & \textbf{0.936}   & 0.763 & 0.789       \\
%     Simple         & \textbf{0.921}   & 0.880 & 0.867       \\
%     Pair           & 0.884   & \textbf{0.904} & 0.913       \\
%     GPTFuzz        & 0.878   & 0.818 & \textbf{0.881}       \\
%     Flip           & 0.806   & 0.856 & \textbf{0.891}       \\
%     \bottomrule
%     \end{tabular}
%     \end{sc}
%     \end{small}
%     \end{center}
%     \vskip -0.1in
% \end{table}
    

\input{sections/tab_prlp.tex}

\paragraph{Dominant Direction Predicts Aligned Behavior}

\begin{figure}
    \vskip 0.2in
    \begin{center}
    \centerline{\includegraphics[width=\columnwidth]{figures/fig_cls_acc.pdf}}
    \caption{Model output prediction accuracy by layer.}
    \label{fig:classification_accuracy}
    \end{center}
    \vskip -0.2in
\end{figure}


In \autoref{fig:classification_accuracy}, we show that both the dominant direction and probe vector achieve high accuracy in predicting refusal behavior in later layers. In comparison, components directly extracted from the trained models' activations fail to predict refusal behavior, as evidenced by the \texttt{Best-of-N BASE} baseline shown in \autoref{fig:classification_accuracy}.
We observe that the probe vector performs better in early layers. We hypothesize that this occurs because the probe vector captures more subtle, early correlations of harmfulness. To verify this, we examine the highest accuracy among the first 100 components for each layer (\texttt{Best-of-N SSFT} in \autoref{fig:classification_accuracy}). We observe that while all components found have near-zero cosine similarity with the probe vector, Best-of-N scores more closely match the probe vector's accuracy. This suggests that the probe vector is an aggregation of multiple safety feature directions.


Furthermore, our results indicate that multiple orthogonal feature directions can predict refusal behavior beyond the single dominant direction or probe vector, hinting that \emph{refusal behavior in LLMs may be represented by a subspace of different feature directions}. Motivated by these findings, we investigate the functionalities of \textit{non-dominant} directions in the following sections. These are vectors from smaller SVD components orthogonal to the dominant component. We interpret their functionalities in the mid-early layers and measure how they causally impact the dominant direction and aligned behavior.