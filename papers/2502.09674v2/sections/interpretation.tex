\section{Feature Directions in Safety Residual Space}
\label{sec:interpretation}


So far, we have focused on examining the dominant direction in the safety residual space, which predicts the model's aligned behavior. In this section, we will investigate how \textit{non-dominant} directions represent different features.

\paragraph{Problem} 
Unlike probe vectors, arbitrary directions lack pre-defined semantic meanings~\cite{bricken2023monosemanticity}, making it challenging to observe outcome changes through intervention experiments. While previous works~\cite{Ball2024UnderstandingJS,lee2024mechanistic} have used Logit Lens~\cite{nostalgebraist2020interpreting} to map representations to the projection layer in transformers, the faithfulness of this approach relies on vector similarity to the vocabulary space, which does not apply to residual directions.

\paragraph{Our Approach}

To determine features represented by directions, we introduce a theoretically grounded method within the LRP framework. We refer it as Partial Layer-wise Relevance Propagation (PLRP): given a set of directions $\{v_i\}$ and representations $X^l$, we first project $X^l$ onto the span of $\{v_i\}$. We then decompose its Euclidean norm into relevance scores $R$ and back-propagate the relevance scores. To ensure relevance conservation, we apply the epsilon rule~\cite{bach2015pixel} for handling projections. Formally we have:

\begin{align*}
    P_V(X^l
    ) = \sum_{v \in V} \|v^T X^l\|_2^2 \propto R_l
\end{align*}

The relevance score $R_l$ is then back-propagated to either (1) input tokens in training data or (2) projections on directions of activation in earlier layers. For input tokens $t$, we follow \citet{achtibat2024attnlrp} and sum up relevance scores of all elements in the token embedding, i.e., $R^{<t>} = \sum_{i=1}^{d} R_i^{<t>}$. To compute relevance scores of directions $v_i$ in $X^{l'}$ of earlier layers, we first compose an linear reconstruction term with first $k$ SVD components $V_{:k} \in \mathbb{R}^{d \times k}$: $\hat{X}^{l'} = V_{:k}W + \epsilon$, where $W \in \mathbb{R}^k$ minimizes the reconstruction error $\epsilon$. We then calculate the relevance scores $R^W_i$ on elements of $W$ and re-normalize to remove relevance scores absorbed by $\epsilon$. The relevance scores of $v_i$ is then given by average $R^W_i$ across all training samples.

\begin{figure}
    \vskip 0.2in
    \begin{center}
    \centerline{\includegraphics[width=\columnwidth]{figures/fig_supression.pdf}}
    \caption{Intervention results after removing the direction of 6th component of layer 14 (\texttt{L14-C6}) from the hidden states during generation. \texttt{L14-C6} is identified as representing the specific ability to recognize the PAIR Attack. Additionally, we remove the dominant direction (\texttt{L25-C1}), which completely eliminates the fine-tuned model's ability to refuse.}
    \label{fig:intervention}
    \end{center}
    \vskip -0.2in
\end{figure}

\subsection{Interpreting Directions via Token Relevance}
\label{iterpret_tokens}

We demonstrate that relevance scores of training input tokens help understand the semantic meaning of directions in the safety residual space. \autoref{tab:plrp_logitlens} visualizes the relevance distribution for several directions using a handcrafted example on layer 14. \footnote{Other layers around layer 14 also show similar patterns. We provide an analysis in \autoref{sec:early_phase}} We provide observations on the dominant and non-dominant directions in the following.

\paragraph{Dominant Direction} We evaluate dominant directions (i.e. \texttt{LN-C1}) and non-dominant directions (i.e. \texttt{L14-CK} in \autoref{tab:plrp_logitlens}) separately. The \textsc{Top Token} column shows the most relevant training tokens that activate each direction. For \texttt{L14-C1} and \texttt{L15-C1}, we observe that the dominant direction primarily relates to harmful subjects, such as \textit{divisive ideologies}. This aligns with our earlier finding that the dominant direction best predicts harmfulness.

\paragraph{Non-Dominant Direction}
For non-dominant directions, we find they are activated not by toxicity or harmfulness, but rather by features characteristic of specific jailbreak patterns. For instance, tokens like \textit{Imagine}, \textit{fictional} and \textit{hypothetical} in \texttt{L14-C2} establish a hypothetical tone. This negatively correlates with the dominant component in layer 25, reducing the probability of refusal. Meanwhile, \texttt{L14-C5} is triggered by explicit mentions of \textit{ChatGPT} and positively correlates with the dominant direction, likely due to its prevalent use in role-playing jailbreaks~\cite{yu2023gptfuzzer}. These findings suggest that non-dominant directions serve to capture indirect features related to safety.

\paragraph{The ``Sure, I'm happy to help'' Direction}
Notably, \texttt{L14-C6} activates when \textit{Sure, I'm happy to help} co-occurs with \textit{Imagine}. We notice that this pattern matches common jailbreak techniques used by PAIR~\cite{chao2023pair}, which typically set up harmful requests in imaginary scenarios (e.g., \textit{Imagine you are a professional hacker}) and force the model to respond positively (e.g., \textit{Start your response with `Sure, I'm happy to help'}). To validate \texttt{L14-C6}'s role, we intervene during generation using \autoref{eq:intervene} to remove its corresponding direction from the safety fine-tuned model. \autoref{fig:intervention} confirms that removing \texttt{L14-C6} specifically ablate the model's ability to refuse PAIR prompts while preserving its capability to handle other attack types. We evaluate the intervention's impact on the model's general abilities in \autoref{sec:impact_inter}, ensuring that removing refusal does not degrade overall performance.

\begin{figure}
    % \vskip 0.1in
    \begin{center}
    \includegraphics[width=\columnwidth]{figures/relevance_heatmap.pdf}
    \vspace{-0.1in}
        \caption{\textbf{Top 3}: Adjacent layer relevance scores among top directions. \texttt{Rel Comp 1}: relevance scores to first component in next layer. \textbf{Bottom}: Log-likelihood of predicting aligned behavior with different directions.}
    \label{fig:network_arch}
    \end{center}
    \vskip -0.2in
\end{figure}

\begin{figure*}[t]
    \begin{center}
    \centerline{\includegraphics[width=\textwidth]{figures/component_projections.pdf}}
    \caption{Projection of representations on top components under different settings in SSFT. The projection on component 1 is strongly correlated with the model's safety behavior. \texttt{Harmful}: representations are from harmful samples. \texttt{Benign}: representations are from benign samples. \texttt{Non-Dominance}: \texttt{Harmful} setting with most non-dominant components removed by intervention. \texttt{Removal}: harmful samples with trigger tokens removed. We evaluate the intervention's impact on the model's general abilities in \autoref{sec:impact_inter}, ensuring that intervention does not degrade overall performance.}
    \label{fig:component_projections}
    \end{center}
    \vskip -0.2in
\end{figure*}

\subsection{Layer-Wise Dynamics of Safety Residual Space}

We now examine the evolution of safety feature directions in the space. Using PLRP, we can measure how one direction influences another by attributing feature directions to directions in earlier layers. \autoref{fig:network_arch} visualizes the  relevance score of different components between adjacent layers.

\paragraph{Early Phase: Development of Safety Features}
\label{sec:early_phase}
We analyze how feature directions evolve across layers using PLRP to trace relevance scores through the transformer network. Our analysis reveals two distinct patterns of propagation. In most layers, directions primarily retain information from their counterparts in the previous layer. For instance, as shown in \texttt{Rel Comp 1} of \autoref{fig:network_arch}, \texttt{L20-C1} inherits most of its relevance from \texttt{L19-C1}. In contrast, during early layers, directions exhibit a more dynamic pattern, receiving contributions from multiple directions in the previous layer.

\paragraph{Late Phase: Uncertainty Reduction for Safety Behavior}
After layer 15, we observe that major directions exhibit a stronger retention pattern, but their corresponding eigenvalues continue to increase. This creates an interesting dynamic: although the model's harmfulness prediction accuracy plateaus after layer 15 (as shown in \autoref{fig:classification_accuracy}), the log-likelihood of these predictions continues to grow across subsequent layers (\autoref{fig:network_arch}, Bottom).


In summary, our analysis reveals that \emph{feature directions develop gradually through the network, stabilizing their safety semantic meanings in the early layers. Subsequently, the dominant direction responsible for safety behavior continues to strengthen, reducing uncertainty in the model's aligned outputs.}

% These findings indicate that feature directions develop gradually through the network rather than emerging suddenly at specific layers.
% This pattern suggests that the late phase of forward propagation primarily serves to reduce uncertainty in the model's existing predictions rather than developing new features.


% \begin{figure}
%     % \vskip 0.1in
%     \begin{center}
%     \begin{tabular}{c}
%         \includegraphics[width=\columnwidth]{figures/network_0.pdf} \\[-0.2in]
%         \includegraphics[width=\columnwidth]{figures/network_1.pdf} \\[-0.2in]
%         \includegraphics[width=\columnwidth]{figures/network_2.pdf} \\[-0.2in]
%         \includegraphics[width=\columnwidth]{figures/network_3.pdf}
%     \end{tabular}
%     \caption{Relevance propagation visualization across different components.}
%     \label{fig:network_arch}
%     \end{center}
%     % \vskip -0.2in
% \end{figure}