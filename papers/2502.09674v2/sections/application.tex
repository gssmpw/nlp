\section{Toward Multi-dimensional Concept of Safety Fine-tuning Vulnerabilities}
\label{sec:application}

Previous analysis presents a multi-dimensional framework for understanding learned safety behaviors, where distinct features and dynamics emerge along different directions in residual space. In this section, we demonstrate how this framework provides practical insights into safety fine-tuning vulnerabilities by showing manipulating non-dominant directions can bypass learned safety capabilities. We explore two methods to circumvent the learned safety capabilities while preserving the model's refusal ability: (1) suppressing non-dominant components and (2) removing or rephrasing trigger tokens from jailbreak prompts. Here, we define "trigger tokens" as specific token sequences that induce changes in feature directions, as demonstrated in \autoref{tab:plrp_logitlens}.

\paragraph{Suppressing Non-Dominant Directions}
As shown in \autoref{iterpret_tokens}, removing \texttt{L14-C6} explains the model's learned ability to refuse PAIR-like jailbreaks. Building on this insight, we investigate the effect of suppressing most non-dominant components while leaving dominant components untouched. Formally:

\[
    \mathbf{x} := \mathbf{x} - \sum_{v_i \in V^{t:}} \alpha_i \mathbf{v}_i
    \label{eq:intervene_all}
\]

This approach allows us to examine whether safety alignment can be reversed by blocking only indirect features. To preserve the model's ability to refuse plainly harmful prompts, we exclude component directions with harmfulness correlations above 0.7. 


\paragraph{Trigger Removal Attack}
We next introduce a procedure to remove trigger tokens from jailbreaks. First, we apply token-wise PLRP to dominant directions of the final layers to identify a list of top trigger tokens that explain the refusal output. Then, we employ another LLM to iteratively rephrase the harmful prompt while avoiding these trigger tokens, similar to TAP~\cite{mehrotra2023tree}. These modified jailbreak prompts are incorporated into the safety fine-tuning dataset, and we evaluate the detection accuracy on a validation split. The detailed algorithm is provided in the Appendix~\ref{appd:trigger_removal}.

\subsection{Results}
\paragraph{Disrupting Non-dominant Directions Reduces Refusal}
In \autoref{fig:component_projections}, we analyze how different attacks affect the projection values compared to default prompts (\texttt{Harmful} and \texttt{Benign}). Both non-dominant suppression and trigger removal attacks cause the dominant component projection to deviate from harmful samples. This deviation leads to a lower refusal rate as projection values on the dominant component increase. Our analysis reveals that indirect features from non-dominant directions greatly influence the dominant directions. Interestingly, while trigger removal attacks shift projections closer to benign samples, non-dominant suppression pushes them in the opposite direction.

\paragraph{Trigger Removal is Resilient to Safety Fine-tuning}

\autoref{tab:exposure_acc} shows that removing triggers effectively prevents safety fine-tuning from generalizing to these attacks. The initial attack success rate is comparable to other methods for a pre-fine-tuned model. However, after fine-tuning on 80 samples per jailbreak, while the success rate of other jailbreaks drops to near zero, the Trigger Removal Attack maintains approximately 40\% effectiveness.


Overall, these findings confirm that non-dominant directions causally impact both the dominant component and safety behavior. Since these non-dominant directions capture features beyond query harmfulness like specific jail-break patterns, this suggests that safety training may model \emph{spurious correlations}~\cite{geirhos2020shortcut} in certain jailbreak patterns, allowing out-of-domain jailbreaks like the Trigger Removal Attack to weaken or bypass the learned alignment.

\begin{table}[t]
    \caption{Attack Pass Rate of jailbreak prompts on safety fine-tuned models under different exposure settings. \textsc{n-shot} indicates the number of samples of each jailbreak presented in the fine-tuning dataset.}
    \label{tab:exposure_acc}
    \vskip 0.15in
    \begin{center}
    \begin{small}
    \begin{sc}
    \setlength\tabcolsep{4pt}
    \begin{tabular}{lcccccc}
    \toprule
    Method & 0-shot & 10 & 20 & 40 & 80 & 160 \\
            & Success   & shot & shot & shot & shot & shot \\
    \midrule
    GPTFuzz  & 0.02 & 0.02 & 0.02 & 0.03 & 0.03 & 0.03 \\
    Flip     & 0.78 & 0.12 & 0.22 & 0.03 & 0.03 & 0.03 \\
    Pair     & 0.82 & 0.75 & 0.45 & 0.17 & 0.12 & 0.05 \\
    ReNellm  & 0.61 & 0.00 & 0.00 & 0.00 & 0.00 & 0.00 \\
    \midrule
    \begin{tabular}[c]{@{}l@{}} Trigger \\ Removal \end{tabular}     & 0.77 & 0.78 & 0.62 & 0.52 & 0.42 & 0.30 \\
    \bottomrule
    \end{tabular}
    \end{sc}
    \end{small}
    \end{center}
    \vskip -0.2in
\end{table}
