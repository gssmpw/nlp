\section{Related Work}
\label{related_work}
Since the introduction of deep learning, computer aided diagnosis received a great deal of attention in the research community. BCD models for digital mammography can ease the screening process for practitioners and reduce mortality. Researchers explored various deep architectures and methodologies to train BCD models. Rajpurkar et al., "Deep Learning for Computer-Aided Detection" ____ train BCD models on different datasets. However, these models are of limited capacity as they are trained on smaller datasets with degraded resolutions and only a few positive cases. For example, the datasets such as Mini-DDSM by Chen et al., CMMD by Feng et al., CDD-CESM by Rakhila et al., BMCD by Zhang et al., have less than 10000 mammograms, while VinDr-Mammo by Nguyen et al. has 20000 mammograms. OMI-DB by Patel et al. is a large dataset in mammography. However, these datasets lack sufficient patient demographic and other clinical information, which raises concerns about the possibility of bias in the previous models.  

In this regard, EMBED by Wang et al., and RSNA (Fei et al.) are large datasets that include rich information about demographics, and clinical attributes. We find only a few works in the literature that utilized these datasets for developing BCD AI models. Patel et al., train ResNets for tissue density and race classification, while Chen et al., develop a 1 to 5 year cancer risk prediction model on EMBED.  Liang et al., designed an adversarial debiasing approach with partial learning to reduce racial disparities for the density classification task. Zhang et al., train ResNet models for BCD with only 1441 samples from EMBED and the other datasets and assessed AUROC across the racial groups. Patel et al., develop abnormal lesion classification models and analyze the performance across subgroups based on demography, pathology outcomes and image findings. These works select a balanced dataset for training, which does not reflect the real scenario. Therefore, there is a need for a BCD model trained on a large and diverse dataset and for analyzing the model across the most important subgroups.

Rajpurkar et al., demonstrate a comprehensive performance analysis on the COVID-19 detection model from chest X-rays. Wang et al., perform a comprehensive analysis for kidney tumor segmentation across the demographic groups. Liang et al., analyze the uncertainty in model performance among the subgroups for three medical applications. Following this, we aim to analyze our BCD AI model performance across the relevant subgroups. Recently, Patel et al., studies the false positive rates across different demographic groups on a commercial AI model for the DBT examinations. However, it is hard to understand the significance of these results since no details are provided about the training data.

Wang et al., demonstrates that the quality of AI model may drop over time for various applications. For BCD-AI models, the performance of the model may drop due to shifts in the distribution of demographics, scanning technology, and local processes (Rajpurkar et al.). In this regard, Wang et al., demonstrates that the performance of the model trained on electronic health records degrades due to distribution changes. To monitor the performance over time, Patel et al., adopt methods from statistical process control either using simulated mean shifts in performance or by inserting out of distribution data. However, in our paper, we monitor the model performance due to shifts in patient demographics.