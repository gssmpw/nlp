\section{Related Work}
\label{related_work}
Since the introduction of deep learning, computer aided diagnosis received a great deal of attention in the research community. BCD models for digital mammography can ease the screening process for practitioners and reduce mortality. Researchers explored various deep architectures and methodologies to train BCD models. \cite{sahu2023recent,raiaan2024mammo,qureshi2024breast,mahoro2022applying,petrini2022breast,wang2023evaluating,altameem2022breast,shen2019deep} train BCD models on different datasets. However, these models are of limited capacity as they are trained on smaller datasets with degraded resolutions and only a few positive cases. For example, the datasets such as Mini-DDSM by \cite{lekamlage2020mini,heath1998current}, CMMD by \cite{cui2021chinese}, CDD-CESM by \cite{khaled2021categorized}, BMCD by \cite{loizidou2021digital} have less than 10000 mammograms, while VinDr-Mammo by \cite{pham2022vindr} has 20000 mammograms. OMI-DB by \cite{halling2020optimam} is a large dataset in mammography. However, these datasets lack sufficient patient demographic and other clinical information, which raises concerns about the possibility of bias in the previous models.  

In this regard, EMBED by \cite{jeong2023emory} and RSNA (\cite{rsna-breast-cancer-detection}) are large datasets that include rich information about demographics, and clinical attributes. We find only a few works in the literature that utilized these datasets for developing BCD AI models. 
\cite{khara2024generalisable} train ResNets for tissue density and race classification, while
\cite{donnelly2024asymmirai} develop a 1 to 5 year cancer risk prediction model on EMBED. 
\cite{correa2024efficient} designed an adversarial debiasing approach with partial learning to reduce racial disparities for the density classification task.
\cite{hwang2023impact} train ResNet models for BCD with only 1441 samples from EMBED and the other datasets and assessed AUROC across the racial groups.
\cite{zhang2023multivariate} develop abnormal lesion classification models and analyze the performance across subgroups based on demography, pathology outcomes and image findings. These works select a balanced dataset for training, which does not reflect the real scenario. Therefore, there is a need for a BCD model trained on a large and diverse dataset and for analyzing the model across the most important subgroups.

\cite{sun2022performance} demonstrate a comprehensive performance analysis on the COVID-19 detection model from chest X-rays. \cite{afzal2023towards} perform a comprehensive analysis for kidney tumor segmentation across the demographic groups. \cite{mehta2024evaluating} analyze the uncertainty in model performance among the subgroups for three medical applications. Following this, we aim to analyze our BCD AI model performance across the relevant subgroups. Recently, \cite{nguyen2024patient} studies the false positive rates across different demographic groups on a commercial AI model for the DBT examinations. However, it is hard to understand the significance of these results since no details are provided about the training data.

\cite{vela2022temporal} demonstrates that the quality of AI model may drop over time for various applications. For BCD-AI models, the performance of the model may drop due to shifts in the distribution of demographics, scanning technology, and local processes (\cite{sahiner2023data}). In this regard, \cite{nestor2019feature} demonstrates that the performance of the model trained on electronic health records degrades due to distribution changes. To monitor the performance over time, \cite{prathapan2024quantifying, zamzmi2024out} adopt methods from statistical process control either using simulated mean shifts in performance or by inserting out of distribution data. However, in our paper, we monitor the model performance due to shifts in patient demographics.