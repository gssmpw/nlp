\section{Related Work}
% RUSS
\subsection{Robotic Ultrasound Systems}
Ultrasound image quality depends heavily on acquisition parameters such as force, orientation, and surface contact. To address this, Pierrot~\emph{et al.}, "Control of a Teleoperative Robotic Ultrasound System"__ Jiang~\emph{et al.}, "Optimization of Ultrasound Acquisition Parameters for Better Visualization"
To ensure that the ultrasound probe is in good contact with the surface, Chatelain~\emph{et al.}, "Confidence-Driven Control for Convex Probes"__ Jiang~\emph{et al.}, "Orientation Correction Method Based on Confidence Map for Linear Probes". The experimental results clearly demonstrated its effectiveness, but the theoretical justification is missing.

\par
Recent advancements in RUSS for vascular applications have gained significant attention. Jiang~\emph{et al.}, "Autonomous Scanning Framework for Peripheral Vascular Diseases"__ Bi~\emph{et al.}, "Reinforcement Learning-Based Autonomous Navigation of Ultrasound Probe"__ Huang~\emph{et al.}, "System for Autonomously Performing Carotid Scans by Imitating Clinical Protocols"__ Goel~\emph{et al.}, "Bayesian Optimization-Based Path Planning Framework for Femoral Artery Screening"

\par
\revision{
Most existing RUSSs for vascular scanning do not address the challenge of handling multiple vessels and often require additional tools to capture the doctor's intention for automatic maneuvering. Guidance can be implemented teleoperatively, with an expert operating remotely while the robot on-site follows__ Chen~\emph{et al.}, "Teleoperation of Ultrasound Robot System"__, or through virtual reality, providing virtual guidance to the human operator__ Kim~\emph{et al.}, "Virtual Reality-Based Guidance for Ultrasound Probe Navigation". Another approach involves pre-planned scanning paths, where the robot provides virtual fixtures to enable reproducible ultrasound scanning for follow-up validations__ Li~\emph{et al.}, "Pre-Planned Scanning Paths with Virtual Fixtures for Ultrasound Imaging". However, among these strategies, gaze signal—an intuitive and hands-free interaction method—remains unexplored. This approach is particularly advantageous in intra-operative scenarios, as it allows surgeons to perform tasks without altering workflow.}

% Gaze-guided Medical Robotic Systems
\subsection{Gaze-guided Medical Robotic Systems}
Initial attempts to integrate gaze information into medical robotic systems have been made in various scenarios, especially for laparoscopic surgeries. 
Noonan~\emph{et al.}, "Eye-Tracking Control of Articulated Robotic Laparoscope"__ Fujii~\emph{et al.}, "Gaze-Guided Laparoscope Maneuverability with Robotic Arm"__ Clancy~\emph{et al.}, "Combining Gaze Tracking and Liquid Lens for Automatic Focus Adjustment". Gaze tracking has also been applied to constrain laparoscopic surgical tools for tissue safety__ Tan~\emph{et al.}, "Gaze-Tracking Constrained Laparoscopic Surgical Tools"__, and to improve collaboration in multi-robot surgeries by visualizing fixation points__ Lee~\emph{et al.}, "Visualizing Fixation Points for Multi-Robot Collaboration". Li~\emph{et al.}, "Optimizing Gaze Tracking Accuracy with Head Movement Compensation". Beyond laparoscopic applications, Guo~\emph{et al.}, "Gaze-Controlled Needle Insertion in CT-Guided Interventions"__ Kogkas~\emph{et al.}, "Gaze-Guided Robotic Scrub Nurse for Surgical Tool Delivery". To the best of our knowledge, initial attempt to integrate the gaze tracker into RUSS has not yet occurred.

% Gaze-guided Network
\subsection{Gaze-Guided Medical Image Analysis}\label{sec_gaze_med_IA}
Unlike optical images, medical images are often challenging to interpret, requiring solid biological knowledge for accurate diagnostics. To enhance the robustness of medical image analysis networks, human experts' gaze signals are frequently integrated as guidance. Cai~\emph{et al.}, "Temporal SonoEyeNet: Predicting Sonographers' Visual Attention and Ultrasound Standard Planes"__ Wang~\emph{et al.}, "Class Activation Maps for Aligning Network Attention with Human Gaze". In another application, Men~\emph{et al.}, "Improving Probe Movement Prediction for Obstetric Standard Plane Navigation Using Gaze Tracking"__ Alsharid~\emph{et al.}, "Benefits of Gaze Signals in Ultrasound Video Captioning". Most of these works aim to align networks with human attention to enhance reasoning. Beyond implicit guidance, gaze signals also serve as an intuitive tool for human-machine interaction. For instance, Khosravan~\emph{et al.}, "Collaborative Lesion Segmentation System Using Gaze Data"__