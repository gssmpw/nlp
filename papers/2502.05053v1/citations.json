[
  {
    "index": 0,
    "papers": [
      {
        "key": "pierrot1999hippocrate",
        "author": "Pierrot, Fran{\\c{c}}ois and Dombre, Etienne and D{\\'e}goulange, Eric and Urbain, Lo{\\\"\\i}c and Caron, Pierre and Boudet, Sylvie and et al.",
        "title": "Hippocrate: A safe robot arm for medical applications with force feedback"
      }
    ]
  },
  {
    "index": 1,
    "papers": [
      {
        "key": "jiang2020automatic",
        "author": "Jiang, Zhongliang and Grimm, Matthias and Zhou, Mingchuan and Hu, Ying and Esteban, Javier and Navab, Nassir",
        "title": "Automatic force-based probe positioning for precise robotic ultrasound acquisition"
      }
    ]
  },
  {
    "index": 2,
    "papers": [
      {
        "key": "chatelain2017confidence",
        "author": "Chatelain, Pierre and Krupa, Alexandre and Navab, Nassir",
        "title": "Confidence-driven control of an ultrasound probe"
      }
    ]
  },
  {
    "index": 3,
    "papers": [
      {
        "key": "karamalis2012ultrasound",
        "author": "Karamalis, Athanasios and Wein, Wolfgang and Klein, Tassilo and Navab, Nassir",
        "title": "Ultrasound confidence maps using random walks"
      }
    ]
  },
  {
    "index": 4,
    "papers": [
      {
        "key": "jiang2022precise",
        "author": "Jiang, Zhongliang and Danis, Nehil and Bi, Yuan and Zhou, Mingchuan and Kroenke, Markus and Wendler, Thomas and Navab, Nassir",
        "title": "Precise repositioning of robotic ultrasound: Improving registration-based motion compensation using ultrasound confidence optimization"
      }
    ]
  },
  {
    "index": 5,
    "papers": [
      {
        "key": "jiang2021autonomous",
        "author": "Jiang, Zhongliang and Li, Zhenyu and Grimm, Matthias and Zhou, Mingchuan and Esposito, Marco and Wein, Wolfgang and et al.",
        "title": "Autonomous robotic screening of tubular structures based only on real-time ultrasound imaging feedback"
      }
    ]
  },
  {
    "index": 6,
    "papers": [
      {
        "key": "bi2022vesnet",
        "author": "Bi, Yuan and Jiang, Zhongliang and Gao, Yuan and Wendler, Thomas and et al.",
        "title": "VesNet-RL: Simulation-based reinforcement learning for real-world us probe navigation"
      }
    ]
  },
  {
    "index": 7,
    "papers": [
      {
        "key": "huangQ2024robot",
        "author": "Huang, Qinghua and Gao, Bin and Wang, Mingliang",
        "title": "Robot-Assisted Autonomous Ultrasound Imaging for Carotid Artery"
      }
    ]
  },
  {
    "index": 8,
    "papers": [
      {
        "key": "goel2022autonomous",
        "author": "Goel, Raghavv and Abhimanyu, Fnu and Patel, Kirtan and Galeotti, John and Choset, Howie",
        "title": "Autonomous ultrasound scanning using bayesian optimization and hybrid force control"
      }
    ]
  },
  {
    "index": 9,
    "papers": [
      {
        "key": "fu2022robot",
        "author": "Fu, Yongqing and Lin, Weiyang and Yu, Xinghu and Rodr{\\'\\i}guez-Andina, Juan J and Gao, Huijun",
        "title": "Robot-assisted teleoperation ultrasound system based on fusion of augmented reality and predictive force"
      }
    ]
  },
  {
    "index": 10,
    "papers": [
      {
        "key": "black2024human",
        "author": "Black, David and Oloumi Yazdi, Yas and Hadi Hosseinabadi, Amir Hossein and Salcudean, Septimiu",
        "title": "Human teleoperation-a haptically enabled mixed reality system for teleultrasound"
      }
    ]
  },
  {
    "index": 11,
    "papers": [
      {
        "key": "huang2024robot",
        "author": "Huang, Dianye and Yang, Chenguang and Zhou, Mingchuan and Karlas, Angelos and Navab, Nassir and Jiang, Zhongliang",
        "title": "Robot-Assisted Deep Venous Thrombosis Ultrasound Examination using Virtual Fixture"
      }
    ]
  },
  {
    "index": 12,
    "papers": [
      {
        "key": "noonan2010gaze",
        "author": "Noonan, David P and Mylonas, George P and Shang, Jianzhong and Payne, Christopher J and Darzi, Ara and Yang, Guang-Zhong",
        "title": "Gaze contingent control for an articulated mechatronic laparoscope"
      }
    ]
  },
  {
    "index": 13,
    "papers": [
      {
        "key": "fujii2018gaze",
        "author": "Fujii, Kenko and Gras, Gauthier and Salerno, Antonino and Yang, Guang-Zhong",
        "title": "Gaze gesture based human robot interaction for laparoscopic surgery"
      }
    ]
  },
  {
    "index": 14,
    "papers": [
      {
        "key": "clancy2011gaze",
        "author": "Clancy, Neil T and Mylonas, George P and Yang, Guang-Zhong and Elson, Daniel S",
        "title": "Gaze-contingent autofocus system for robotic-assisted minimally invasive surgery"
      }
    ]
  },
  {
    "index": 15,
    "papers": [
      {
        "key": "mylonas2012gaze",
        "author": "Mylonas, George P and Kwok, Ka-Wai and James, David RC and Leff, Daniel and Orihuela-Espina, Felipe and Darzi, Ara and Yang, Guang-Zhong",
        "title": "Gaze-Contingent Motor Channelling, haptic constraints and associated cognitive demand for robotic MIS"
      }
    ]
  },
  {
    "index": 16,
    "papers": [
      {
        "key": "kwok2012collaborative",
        "author": "Kwok, Ka-Wai and Sun, Loi-Wah and Mylonas, George P and James, David RC and Orihuela-Espina, Felipe and Yang, Guang-Zhong",
        "title": "Collaborative gaze channelling for improved cooperation during robotic assisted surgery"
      }
    ]
  },
  {
    "index": 17,
    "papers": [
      {
        "key": "li2018free",
        "author": "Li, Zhaoshuo and Tong, Irene and Metcalf, Leo and Hennessey, Craig and Salcudean, Septimiu E",
        "title": "Free head movement eye gaze contingent ultrasound interfaces for the da Vinci surgical system"
      }
    ]
  },
  {
    "index": 18,
    "papers": [
      {
        "key": "guo2019novel",
        "author": "Guo, Jing and Liu, Yi and Qiu, Qing and Huang, Jie and et al.",
        "title": "A novel robotic guidance system with eye-gaze tracking control for needle-based interventions"
      }
    ]
  },
  {
    "index": 19,
    "papers": [
      {
        "key": "kogkas2019free",
        "author": "Kogkas, Alexandros and Ezzat, Ahmed and Thakkar, Rudrik and Darzi, Ara and Mylonas, George",
        "title": "Free-view, 3D gaze-guided robotic scrub nurse"
      }
    ]
  },
  {
    "index": 20,
    "papers": [
      {
        "key": "cai2020spatio",
        "author": "Cai, Yifan and Droste, Richard and Sharma, Harshita and Chatelain, Pierre and Drukker, Lior and Papageorghiou, Aris T and Noble, J Alison",
        "title": "Spatio-temporal visual attention modelling of standard biometry plane-finding navigation"
      }
    ]
  },
  {
    "index": 21,
    "papers": [
      {
        "key": "wang2022follow",
        "author": "Wang, Sheng and Ouyang, Xi and Liu, Tianming and Wang, Qian and Shen, Dinggang",
        "title": "Follow my eye: Using gaze to supervise computer-aided diagnosis"
      }
    ]
  },
  {
    "index": 22,
    "papers": [
      {
        "key": "zhou2016learning",
        "author": "Zhou, Bolei and Khosla, Aditya and Lapedriza, Agata and Oliva, Aude and Torralba, Antonio",
        "title": "Learning deep features for discriminative localization"
      }
    ]
  },
  {
    "index": 23,
    "papers": [
      {
        "key": "men2023gaze",
        "author": "Men, Qianhui and Teng, Clare and Drukker, Lior and Papageorghiou, Aris T and Noble, J Alison",
        "title": "Gaze-probe joint guidance with multi-task learning in obstetric ultrasound scanning"
      }
    ]
  },
  {
    "index": 24,
    "papers": [
      {
        "key": "alsharid2022gaze",
        "author": "Alsharid, Mohammad and Cai, Yifan and Sharma, Harshita and Drukker, Lior and Papageorghiou, Aris T and Noble, J Alison",
        "title": "Gaze-assisted automatic captioning of fetal ultrasound videos using three-way multi-modal deep neural networks"
      }
    ]
  },
  {
    "index": 25,
    "papers": [
      {
        "key": "khosravan2019collaborative",
        "author": "Khosravan, Naji and Celik, Haydar and Turkbey, Baris and Jones, Elizabeth C and Wood, Bradford and Bagci, Ulas",
        "title": "A collaborative computer aided diagnosis (C-CAD) system with eye-tracking, sparse attentional model, and deep learning"
      }
    ]
  }
]