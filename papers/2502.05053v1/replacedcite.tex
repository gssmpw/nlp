\section{Related Work}
% RUSS
\subsection{Robotic Ultrasound Systems}
Ultrasound image quality depends heavily on acquisition parameters such as force, orientation, and surface contact. To address this, Pierrot~\emph{et al.}____ implemented a force control schema in a teleoperative RUSS to maintain constant scanning force. Jiang~\emph{et al.}____ introduced an orientation optimization algorithm based on contact force for better visualization.
To ensure that the ultrasound probe is in good contact with the surface, Chatelain~\emph{et al.}____ integrated ultrasound confidence map____ into the control loop and presented confidence-driven control. However, the proposed control algorithm was designed for convex probe. In the sight of such limitation, Jiang~\emph{et al.}____ proposed an orientation correction method based on the confidence map for the linear probes. The experimental results clearly demonstrated its effectiveness, but the theoretical justification is missing.

\par
Recent advancements in RUSS for vascular applications have gained significant attention. Jiang~\emph{et al.}____ proposed an autonomous scanning framework for peripheral vascular diseases using real-time vessel segmentation. Bi~\emph{et al.}____ applied reinforcement learning to autonomously navigate the probe to the longitudinal view of the carotid artery. Huang~\emph{et al.}____ developed a system to autonomously perform carotid scans by imitating clinical protocols, while Goel~\emph{et al.}____ introduced a Bayesian Optimization-based path planning framework for femoral artery screening.

\par
\revision{
Most existing RUSSs for vascular scanning do not address the challenge of handling multiple vessels and often require additional tools to capture the doctor's intention for automatic maneuvering. Guidance can be implemented teleoperatively, with an expert operating remotely while the robot on-site follows____, or through virtual reality, providing virtual guidance to the human operator____. Another approach involves pre-planned scanning paths, where the robot provides virtual fixtures to enable reproducible ultrasound scanning for follow-up validations____. However, among these strategies, gaze signal—an intuitive and hands-free interaction method—remains unexplored. This approach is particularly advantageous in intra-operative scenarios, as it allows surgeons to perform tasks without altering workflow.}

% Gaze-guided Medical Robotic Systems
\subsection{Gaze-guided Medical Robotic Systems}
Initial attempts to integrate gaze information into medical robotic systems have been made in various scenarios, especially for laparoscopic surgeries. 
Noonan~\emph{et al.}____ used eye tracking to control an articulated robotic laparoscope for stable, hands-free visualization. Fujii~\emph{et al.}____ enhanced the gaze-guided laparoscope maneuverability by using a robotic arm instead of a rigid fixture. Clancy~\emph{et al.}____ combined gaze tracking with a liquid lens in the da Vinci system for automatic focus adjustment during minimally invasive surgeries. Gaze tracking has also been applied to constrain laparoscopic surgical tools for tissue safety____ and to improve collaboration in multi-robot surgeries by visualizing fixation points____. Li~\emph{et al.}____ further optimized gaze tracking accuracy by compensating for head movements.
Beyond laparoscopic applications, Guo~\emph{et al.}____ utilized gaze to control needle insertion in CT-guided interventions, while Kogkas~\emph{et al.}____ introduced a gaze-guided robotic scrub nurse to deliver surgical tools. To the best of our knowledge, initial attempt to integrate the gaze tracker into RUSS has not yet occurred.

% Gaze-guided Network
\subsection{Gaze-guided Medical Image Analysis}\label{sec_gaze_med_IA}
Unlike optical images, medical images are often challenging to interpret, requiring solid biological knowledge for accurate diagnostics. To enhance the robustness of medical image analysis networks, human experts' gaze signals are frequently integrated as guidance. Cai~\emph{et al.}____ proposed Temporal SonoEyeNet, which predicts sonographers' visual attention and ultrasound standard planes, demonstrating that understanding visual attention complements standard plane detection. Similarly, Wang~\emph{et al.}____ used class activation maps____ to align network attention with human gaze.
In another application, Men~\emph{et al.}____ leveraged gaze tracking to improve probe movement prediction for obstetric standard plane navigation, while Alsharid~\emph{et al.}____ showed its benefits in ultrasound video captioning. Most of these works aim to align networks with human attention to enhance reasoning. Beyond implicit guidance, gaze signals also serve as an intuitive tool for human-machine interaction. For instance, Khosravan~\emph{et al.}____ developed a collaborative lesion segmentation system that analyzes and filters doctors' gaze data to improve segmentation and reduce false positives.

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%