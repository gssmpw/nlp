\input{sec/i2sb_sr_table}
\input{sec/i2sb_jpeg_table}
\input{sec/edges_and_diode_tables}
\input{sec/imagenet_inpainting_table}
\vspace{-2mm}
\section{Experiments}\label{sec:experiments}
\vspace{-2mm}
This section highlights the applicability of our IBMD distillation method in both \textit{unconditional} and \textit{conditional} settings. To demonstrate this, we conducted experiments utilizing pretrained \textit{unconditional} models used in I$^2$SB paper \citep{liu20232}. Then we evaluated IBMD in \textit{conditional} settings using DDBM \citep{zhou2024denoising} setup (\wasyparagraph\ref{sec:ddbm experiments}). For clarity, we denote our models as \textbf{IBMD-DDBM} and \textbf{IBMD-I$^2$SB}, indicating that the teacher model is derived from DDBM or I$^2$SB framework, respectively. 
We provide all the \underline{technical details} in Appendix~\ref{app:experimental-details}.

% and achieved significant acceleration, ranging from \textcolor{red}{4x to 100x} (\wasyparagraph\ref{sec:i2sb experiments}) in terms of used number of function evaluations (NFE).
% Additionally, we evaluated IBMD in \textit{conditional} settings using DDBM \citep{zhou2024denoising} setup (\wasyparagraph\ref{sec:ddbm experiments}). 
% In this context, several studies have introduced distillation techniques, with the most notable being CDBM \cite{he2024consistency}, which includes two types of models: CBD and CBT. Consequently, the primary objective of this section is to demonstrate that IBMD achieves results comparable to, or exceeding, those reported in CDBM. To this end, we leverage pretrained DDBM models for distillation. 

\vspace{-2mm}
\subsection{Distillation of I2SB (5 setups)}\label{sec:i2sb experiments}
\vspace{-2mm}
Since known distillation and acceleration techniques are designed for the conditional models, there is no clear baseline for comparison. Thus, this section aims to demonstrate that our distillation technique significantly decreases NFE required to obtain the same quality of generation.

\textbf{Experimental Setup.} To test our approach for unconditional models, we consider models trained and published in I$^2$SB paper \citep{liu20232}, specifically (a) two models for the 4x super-resolution with bicubic and pool kernels, (b) two models for JPEG restoration using quality factor QF$=5$ and QF$=10$, and (c) a model for center-inpainting with a center mask of size $128 \times 128$ all of which were trained on ImageNet $256\times256$ dataset \citep{deng2009imagenet}. 
% Models for super-resolution and JPEG restoration are all based on the considered Bridge Matching approach, while the published model for center-inpainting is trained in the flow matching framework. 
% Since flow matching is a limiting case of bridge matching, we test our IBMD approach to distill this model type.

For all the setups we use the same train part of ImageNet dataset, which was used to train the used models. 
For the evaluation we follow the same protocol used in the I$^2$SB paper, i.e. use the full validation subset of ImageNet for super-resolution task and the $10'000$ subset of validation for other tasks. 
We report the same FID \cite{heusel2017gans} and Classifier Accuracy (CA) using pre-trained ResNet50 model metrics used in the I$^2$SB paper. We present our results in Table~\ref{tab:sr-bicubic}, Table~\ref{tab:sr-pool}, Table~\ref{tab:jpeg-5}, Table~\ref{tab:jpeg-10} and Table~\ref{tab:image_inpainting_results}. We provide the \underline{uncurated samples} for all setups in Appendix~\ref{app:additional-results}. 

\textbf{Results.} For both super-resolution tasks (see Table~\ref{tab:sr-bicubic}, Table~\ref{tab:sr-pool}), our $1$-step distilled model outperformed teacher model inference using all $1000$ steps used in the training. 
Note that our model does not use the clean training target data $p(x_0)$, only the corrupted $p(x_T)$, hence this improvement is not due to additional training using paired data. We hypothesize that it is because the teacher model introduces approximation error during many steps of sampling, which may accumulate. 
For both JPEG restoration (see Table~\ref{tab:jpeg-5}, Table~\ref{tab:jpeg-10}), our 1-step distilled generator provides the quality of generation close to the teacher model and achieves around 100x time acceleration. For the inpainting problem (see Table~\ref{tab:image_inpainting_results}), we present the results for $1,2$ and $4$ steps distilled generator. Our 2 and 4-step generators provide a quality similar to the teacher I$^2$SB model, in turn, there is still some gap for the 1-step model. These models provide around $5$x time acceleration. We hypothesize that this setup is harder for our model since it is required to generate the entire center fragment from scratch, while in other tasks, there is already some good approximation given by corrupted images.
\vspace{-2mm}
\subsection{Distillation of DDBM (3 setups)}
\label{sec:ddbm experiments}
\vspace{-2mm}
% In this context, several studies have introduced distillation techniques, with the most notable being CDBM \cite{he2024consistency}, which includes two types of models: CBD and CBT. Consequently, the primary objective of this section is to demonstrate that IBMD achieves results comparable to, or exceeding, those reported in CDBM. To this end, we leverage pretrained DDBM models for distillation. 
This section addresses two primary objectives: (1) demonstrating the feasibility of conditional model distillation within our framework and (2) comparing with the CDBM \citep{he2024consistency} - a leading approach in Conditional Bridge Matching distillation, presented into different models: CBD (consistency distillation) and CBT (consistency training).

\textbf{Experimental Setup.} 
% To maintain consistency with prior work, we adopt the experimental setup of our main competitor - Consistency Distillation of Diffusion Bridge (CDBM) proposed in \citep{he2024consistency}. Specifically, 
% We evaluate our proposed IBMD method on two tasks: image-to-image translation and image inpainting, used in previous work on DDBM models acceleration \citep{he2024consistency, }.
For evaluation, we use the same setups used in competing methods \citep{he2024consistency, zheng2024diffusion}.
For the image-to-image translation task, we utilize the Edges→Handbags dataset \cite{isola2017image} with a resolution of $64 \times 64$ pixels and the DIODE-Outdoor dataset \cite{vasiljevic2019diode} with a resolution of $256 \times 256$ pixels. For these tasks, we report FID and Inception Scores (IS) \cite{barratt2018note}.
For the image inpainting task, we use the same setup of center-inpainting as before.
% used in on the ImageNet dataset \cite{deng2009imagenet} and the same metrics. 
% Additionally, in line with prior studies \cite{liu20232, zhou2023denoising, zheng2024diffusion, he2024consistency}, we report Inception Scores (IS) \cite{barratt2018note} for the image-to-image translation task and Classifier Accuracy (CA) metric. 

% The evaluation metrics are computed as follows: for the ImageNet dataset, we use a validation subset of 10,000 images. For the Edges→Handbags and DIODE-Outdoor datasets, we utilize the complete training sets consistent with prior work. However, we note that evaluating the training set for the image-to-image translation task may lead to significant overfitting. Therefore, we evaluated the work of the model qualitatively on the test sets (see Figures \ref{fig:e2h test}, \ref{fig:diode test} for the Edges→Handbags and DIODE-Outdoor datasets respectively).
% Given the limited number of samples in the test sets, we also compute the CLIP Maximum Mean Discrepancy (CMMD) \cite{jayasumana2024rethinking} as an unbiased metric for datasets with few samples.

\textbf{Results.} We utilized the same teacher model checkpoints and
% design space for DDBM-VP and $\text{I}^2\text{SB}$ 
as in CDBM. We present the quantitative and qualitative results of IBMD on the image-to-image translation task in Table \ref{tab:ddbm train results} and in Figures \ref{fig:e2h train}, \ref{fig:diode train} respectively. 
The competing methods, DBIM \citep[Section 4.1]{zhou2024denoising} and CDBM \citep[Section 3.4]{he2024consistency}, cannot use single-step inference due to the singularity at the starting point $x_T$. 
% In turn, our method can distill the model into a one-step generator using the stochasticity of the noise input. 
% Consistent with prior works \cite{liu20232, zhou2023denoising, zheng2024diffusion, he2024consistency}, we report the result of baselines under different NFE. 

% While we acknowledge the theoretical and experimental challenges highlighted in CDBM \citep[Section 3.4]{he2024consistency} and DBIM \citep[Section 4.1]{zhou2024denoising} regarding the singularity in deterministic prediction, we address this issue by explicitly incorporating noise into our model. This modification enables training and inference with only $1$ NFE, in contrast to CDBM, which requires a minimum of $2$ NFEs, what makes IBMD a unique approach in most of setups.
% Comprehensive details of the training procedure and model configurations are provided in Appendix \ref{sec: experimental details ddbm}.

We trained our IBMD with $1$ and $2$ NFEs on the Edges\textrightarrow Handbags dataset. We surpass CDBM at $2$ NFE, outperform the teacher at $100$ NFE, and achieve performance comparable to the teacher at $50$ NFE with $1$ NFE, resulting in a $50\times$ acceleration.
% For the Edges\textrightarrow Handbags dataset, IBMD surpasses CDBM with $2$ NFE and even outperforms the teacher with $100$ NFE. With $1$ NFE, IBMD outperforms CBD with $2$ NFE and achieves performance comparable to the teacher with $50$ NFE, resulting in a $50\times$ acceleration. 
% For the DIODE-Outdoor setup, IBMD with $2$ NFE surpasses CBD in FID, while showing a slight drop in IS, achieving results comparable to CBT with a slight performance drop, thus aligning closely with the teacher with $50$ NFE. With $1$ NFE, IBMD maintains strong performance with only minor quality reductions. 
For the DIODE-Outdoor setup, we trained IBMD with $1$ and $2$ NFEs. We surpassed CBD in FID at $2$ NFE, achieving results comparable to CBT with a slight drop in performance and maintaining strong performance at $1$ NFE with minor quality reductions.

For image inpainting, Table \ref{tab:image_inpainting_results} and Figure \ref{fig:inpainting ddbm} show the quantitative and qualitative results of IBMD. 
We train IBMD with $4$ NFE for image inpainting. It outperforms CBD and CBT at $4$ NFE with a significant gap, surpassing both at $2$ NFE and maintaining strong performance at $1$ NFE while achieving teacher-level results at $50$ NFE with a $12.5\times$ speedup.

\textbf{Concerns regarding the evaluation protocol used in prior works.}
For Edges-Handbags and DIODE-Outdoor setups, we follow the evaluation protocol originally introduced in DDBM \citep{zhou2024denoising} and later used in works on acceleration of DDBM \cite{zheng2024diffusion, he2024consistency}.
% For Edges-Handbags and DIODE-Outdoor setups, we use the same evaluation protocol used in the prior works \cite{zhou2024denoising, zheng2024diffusion, he2024consistency}, and firstly proposed in \citep{zhou2024denoising} for the diffusion bridge setting. 
For some reason, this protocol implies evaluation of the train set. Furthermore, test sets of these datasets consist of a tiny fraction of images (around several hundred), making the usage of standard metrics like FID challenging due to high statistical bias or variance of their estimation. Still, to assess the quality of the distilled model on the test sets, we provide the \underline{uncurated samples} produced by our distill model and teacher model on these sets in Figures \ref{fig:e2h test} and \ref{fig:diode test} in Appendix~\ref{app:additional-results}. We also provide the \underline{uncurated samples} on the train part in Figures \ref{fig:e2h train} and \ref{fig:diode train} to compare models' behavior on train and test sets. From these results, we see that the teacher model exhibits overfitting on both setups, e.g., it produces exactly the same images as corresponding reference images. In turn, on the test sets, teacher models work well for the handbag setups, while on the test set of DIODE images, it exhibits mode collapse and produces gray images. Nevertheless, our distilled model shows exactly the same behavior in both sets, i.e., our IBMD approach precisely distills the teacher model as expected.

% To investigate whether our distilled model 

% To val Furthermore, test sets of these datasets consist of a tiny fraction of images (around several hundred) making the usage of standard metrics like FID 

% Given the test set's limited size, we present uncurated samples in Figures \ref{fig:e2h test} and \ref{fig:diode test}. 

% While Edges\textrightarrow Handbags results align with expectations, DIODE-Outdoor reveals teacher model collapse (gray images). 

% (2) IBMD retaining teacher-like outputs, and
% (3) discrepancies between training and test results suggest overfitting in prior evaluation protocols. 
% These findings indicate IBMD faithfully reproduces teacher performance on the test.

% Despite promising results, concerns remain regarding the evaluation protocol, which trains and validates on the same sets, following prior studies \cite{zhou2023denoising, zheng2024diffusion, he2024consistency}.

