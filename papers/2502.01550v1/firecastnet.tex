\documentclass{article}

\usepackage{booktabs}
\usepackage{a4wide}

% -------------- Setup, do not change these ---------------
\usepackage[hidelinks]{hyperref}
% \usepackage[options]{nohyperref} 

\usepackage{adjustbox}
\usepackage{graphicx}
\usepackage{amsmath, amssymb, amsthm} % Mathematical packages
\usepackage{gensymb}
\usepackage{pgfplotstable}
\urlstyle{sf}


\usepackage{subfig}
\usepackage{tikz}
\usepackage{pgfplots}

\usepackage{diagbox}
\usepackage{multirow}
\usepackage{caption}
%\usepackage{subcaption}


% ----- Figures and tables ----- 
\usepackage{fancyhdr}
\usepackage{array}
%\usepackage[rightcaption]{sidecap}
\usepackage{wrapfig}
\usepackage{float}
%\usepackage[labelfont=bf]{caption} % bold text for captions
%\usepackage[para]{threeparttable} % fancy tables, check these before you use them
\usepackage{url}
%\usepackage[table,xcdraw]{xcolor}
%\usepackage{makecell}
%\usepackage{hhline}
%\usepackage{gensymb}

\newcolumntype{M}[1]{>{\centering\arraybackslash}m{#1}}
\renewcommand{\vec}[1]{\boldsymbol{#1}} 
\newcommand{\rulesep}{\unskip\ \vrule\ }

\begin{document}


\title{FireCastNet: Earth-as-a-Graph for Seasonal Fire Prediction}

\date{}

\author{
    Dimitrios Michail\thanks{Harokopio University of Athens, Greece. \{michail, epanagiotou, cdavalas\}@hua.gr} \and 
    Charalampos Davalas\footnotemark[1] \and 
    Lefki-Ioanna Panagiotou\footnotemark[1] \and
    Ioannis Prapas \thanks{OrionLab, National Technical University \& National Observatory of Athens, Greece. \{iprapas, skondylatos, bountos, ipapoutsis\}@noa.gr} \and
    Spyros Kondylatos\footnotemark[2] \and 
    Nikolaos Ioannis Bountos\footnotemark[1] \footnotemark[2] \and 
    Ioannis Papoutsis \footnotemark[2]
}

\maketitle

\begin{abstract}
With climate change expected to exacerbate fire weather conditions, the accurate and timely anticipation of wildfires becomes increasingly crucial for disaster mitigation. In this study, we utilize SeasFire, a comprehensive global wildfire dataset with climate, vegetation, oceanic indices, and human-related variables, to enable seasonal wildfire forecasting with machine learning. 
For the predictive analysis, we present FireCastNet, a novel architecture which combines a 3D convolutional encoder with GraphCast, originally developed for global short-term weather forecasting using graph neural networks. 
FireCastNet is trained to capture the context leading to wildfires, at different spatial and temporal scales. 
Our investigation focuses on assessing the effectiveness of our model in predicting the presence of burned areas at varying forecasting time horizons globally, extending up to six months into the future, and on how different spatial or/and temporal context affects the performance. Our findings demonstrate the potential of deep learning models in seasonal fire forecasting; longer input time-series leads to more robust predictions, while integrating spatial information to capture wildfire spatio-temporal dynamics boosts performance. Finally, our results hint that in order to enhance performance at longer forecasting horizons, a larger receptive field spatially needs to be considered. 
\end{abstract}

\definecolor{myblue}{RGB}{0, 102, 204} % Define custom colors
\definecolor{mygreen}{RGB}{34, 139, 34}
\definecolor{myorange}{RGB}{255, 128, 0}
\definecolor{mycyan}{RGB}{0, 255, 255}  % Cyan
\definecolor{mymagenta}{RGB}{255, 0, 255}  % Magenta
\definecolor{mypurple}{RGB}{128, 0, 128} % Purple
\definecolor{myyellow}{RGB}{200, 200, 0} % Yellow
\definecolor{mygray}{RGB}{128, 128, 128} % Gray

\definecolor{myteal}{RGB}{0, 128, 128}
\definecolor{myseagreen}{RGB}{46, 139, 87}
\definecolor{myrose}{RGB}{188, 143, 143}
\definecolor{mydarkgreen}{RGB}{0, 100, 0}  
\definecolor{myindigo}{RGB}{75, 0, 130} 
\definecolor{mymidnight}{RGB}{25, 25, 112} 
\definecolor{mysalmon}{RGB}{250, 128, 114} 
\definecolor{mycadetblue}{RGB}{70, 130, 180}

    % gru whole globe
    \begin{filecontents}{gru-globe.dat}
        x    ts6      ts12    ts24   
        1    0.4752   0.5142  0.5581 
        2    0.4631   0.4983  0.5490 
        4    0.4460   0.4925  0.5402 
        8    0.4137   0.4722  0.5185 
        16   0.3727   0.4531  0.5205
        24   0.3781   0.4588  0.5195
    \end{filecontents}

    % convgru whole globe
    \begin{filecontents}{convgru-globe.dat}
        x    ts6      ts12    ts24   
        1    0.6041   0.6238  0.5934 
        2    0.5970   0.6140  0.5790
        4    0.5863   0.6037  0.5556 
        8    0.5711   0.5925  0.5506 
        16   0.5601   0.5824  0.5446
        24   0.5570   0.5792  0.5690
    \end{filecontents}

    % convlstm whole globe
    \begin{filecontents}{convlstm-globe.dat}
        x    ts6     ts12    ts24   
        1    0.5919  0.6152  0.6346 
        2    0.5848  0.6075  0.6080 
        4    0.5757  0.5947  0.6149 
        8    0.5550  0.5860  0.6009 
        16   0.5459  0.5789  0.5981
        24   0.5449  0.5794  0.5893
    \end{filecontents}    

    % firecastnet whole globe
    \begin{filecontents}{utae-globe.dat}
        x    ts6     ts12    ts24   
        1    0.6002  0.6210  0.6238
        2    0.5983  0.6116  0.6212
        4    0.5878  0.5958  0.6114
        8    0.5740  0.5937  0.6014
        16   0.5557  0.5839  0.6077
        24   0.5703  0.5712  0.5936
    \end{filecontents}    

    % firecastnet whole globe
    \begin{filecontents}{firecastnet-globe.dat}
        x    ts6     ts12    ts24     ts24overlap3  ts24overlap6   ts24overlap12   ts24overlap18
        1    0.6192  0.6323  0.6405   0.5636        0.5749         0.5941          0.6231
        2    0.6119  0.6275  0.6362   0.5626        0.5724         0.5888          0.6192
        4    0.6050  0.6186  0.6314   0.5555        0.5596         0.5841          0.6077
        8    0.5939  0.6143  0.6305   0.5514        0.5529         0.5823          0.6055
        16   0.5825  0.5987  0.6277   0.5489        0.5542         0.5761          0.6054
        24   0.5876  0.6090  0.6329   0.5547        0.5590         0.5794          0.6056
    \end{filecontents}    


\section{Introduction}\label{sec:intro}

Fire plays a pivotal role in the Earth system, significantly influencing ecosystems worldwide. While 
traditionally viewed as a carbon-neutral process over the long term, climate change disrupts this balance
through the intensification of fire weather conditions, leading to a rise in global fire activity~\cite{jones2022global}. 
A feedback loop is created when fires encroach into evergreen forest regions, posing a threat to their
role as carbon sinks. This situation triggers the release of stored carbon into the atmosphere, further exacerbating 
climate change~\cite{flannigan2009implications}.
Moreover, wildfires represent a critical natural hazard with far-reaching consequences for
societies worldwide, resulting in loss of life, property, infrastructure, and ecosystem
services~\cite{pettinari2020fire}.
Hence, it is imperative to improve our understanding and forecasting capabilities of wildfire phenomena within the Earth system.
By doing so, we can formulate effective strategies to mitigate the adverse impacts of wildfires and climate change. 
These strategies may encompass enhanced forestry management, strengthened infrastructure resilience, disaster preparedness,
and the implementation of more accurate warning systems.

Producing reliable long-range wildfire forecasts, spanning up to six months, requires advanced techniques that account for
the Earth as one interconnected system. This system is shaped by continuous interactions across large spatio-temporal scales.
These interactions manifest in two key ways: (a) memory effects, where past conditions like fuel accumulation and drought influence future fire activity, and (b) teleconnections, where distant climate events and weather patterns affect wildfire risk. Traditional statistical models, which rely on historical data from the same time period, have been widely used for fire hazard forecasting. However, these models often struggle to capture the intricate, non-linear patterns and dependencies that govern wildfire behavior. Given the critical importance of predicting fire occurrences to protect ecosystems and human life, it is essential to recognize and model these complex interactions effectively.

In this study, we present FireCastNet, a novel architecture aimed at enhancing seasonal wildfire prediction by utilizing the 
GraphCast~\cite{lam2023learning} weather forecasting model.  
FireCastNet aims at leveraging both short- and long-range dependencies across the Earth system and providing a deeper and more comprehensive understanding of the spatio-temporal interactions that influence wildfire behavior. Unlike traditional models, FireCastNet does not rely on proxy variables like pre-encoded oceanic indices for temporal dynamics. Instead, it directly models these dependencies from raw time series data, offering a more flexible and data-driven approach to long-range fire forecasting.

We conduct a thorough experimental evaluation, benchmarking FireCastNet's performance against baseline methods, such as the seasonal mean cycle, and several state-of-the-art machine learning models, including Gated Recurrent Units (GRU), Convolutional GRU (ConvGRU), Convolutional Long Short-Term Memory (ConvLSTM), and the U-Net Transformer-based Attention Encoder (UTAE). Performance is also compared This evaluation explores the predictive capabilities of each model across various spatio-temporal contexts, assessing factors such as different time-series lengths, spatial neighborhood sizes, and prediction horizons. Our experiments focus on forecasting burned area patterns weeks to months in advance, at a global scale and with a spatial resolution of $0.25^{\circ}$. By leveraging spatio-temporal data at multiple scales, we assess how effectively each deep learning model captures the intricate dynamics of wildfire behavior.

Our main contributions can be summarized as follows:
\begin{itemize}
    \item We propose FireCastNet, a deep learning architecture that combines 3D convolutional encoding with GraphCast-based Graph Neural Networks (GNNs) to model spatio-temporal dependencies for global, seasonal wildfire prediction.

    \item We leverage the SeasFire dataset, an open-access multivariate Earth system datacube, to forecast burned areas globally up to six months ahead, outperforming traditional statistical methods.

    \item We demonstrate that incorporating longer input time-series and spatial information improves prediction robustness, particularly for extended forecasting horizons.

    \item We benchmark FireCastNet against state-of-the-art models (GRU, ConvGRU, ConvLSTM, U-TAE, and TeleViT), showing superior performance in global burned area pattern forecasting, especially in Africa, South America, and Southeast Asia.
\end{itemize}

All source code can be found at \url{https://github.com/seasfire/firecastnet}.

\section{Related Work}

Wildfires are notoriously hard to model due to the non-linear interactions between the different Earth system processes
that affect them \cite{hantson2016status}. Weather, vegetation and humans interact in evolving ways that contribute in the
expansion or suppression of wildfires. Reichstein et~al.~\cite{reichstein2019deep} propose Deep Learning as a method to learn
in a  data-driven way these complex spatio-temporal interactions that influence wildfires. Several recent studies have used deep
learning for wildfire-related use cases~\cite{jain_review_2020}. For short-term daily predictions the temporal context is mostly
enough, with spatio-temporal models offering little to no advantage~\cite{prapas2021deep, kondylatos2022wildfire}. For longer-term
predictions, i.e. on subseasonal to seasonal scales, very few works have studied the effect of spatial and temporal
context~\cite{joshi2021improving, prapas2022deep, Prapas_2023_ICCV}.
Joshi et~al.~\cite{joshi2021improving} use monthly aggregated input to predict burned area using multi-layer neural networks.
Li et~al.~\cite{li2023attentionfire_v1} includes the temporal aspect of the input using a temporal attention network on time-series

Recent studies rely on our SeasFire Datacube~\cite{karasante2023seasfire} to train models with seasonal forecasting skill.
Prapas et~al.~\cite{prapas2022deep} use temporal snapshots of the fire drivers to predict future burned area patterns,
defining burned area forecasting as a segmentation task and demonstrating skillful forecasts even two months in advance. An
expansion of this~\cite{Prapas_2023_ICCV}, recognises the need to view the earth as a system for long-term forecasting and proposes a novel architecture that leverages teleconnection indices and global input in conjunction with those snapshots. This setup helps improve long-term skill, but ignores the temporal component of the input variables. 
Zhao et~al.~\cite{zhao2024causal} integrate causality with GNNs to explicitly model the causal mechanism among complex
variables via graph learning, and test their models in the European boreal and Mediterranean biome.
Finally, in the work of \cite{zhu2025unveiling} the authors expand on the TeleViT architecture and add a balancing term to handle the data imbalance between the burned and non-burned classes. This allows them to create a fire risk index that is better calibrated between different regions. 

Machine learning has recently made significant advances in global weather forecasting \cite{rasp2024weatherbench}, with graph neural networks showing tremendous potential to represent the Earth as a system\cite{keisler2022forecasting, lam2022graphcast}. The work of \cite{keisler2022forecasting} introduces a GNN-based model that predicts multiple atmospheric variables across various pressure levels on a global scale. 
Building upon this foundation, the GraphCast model~\cite{lam2022graphcast} presents a machine learning method that forecasts hundreds of weather variables over a 10-day period at 0.25-degree resolution globally, delivering results in under a minute.
Further advancing the GraphCast architecture, the work of~\cite{oskarsson2024probabilistic} introduces Graph-EFM, a probabilistic weather forecasting model that combines a flexible latent-variable formulation with a hierarchical graph-based framework. This model efficiently generates spatially coherent ensemble forecasts, achieving errors equivalent to or lower than comparable deterministic models while accurately capturing forecast uncertainty. These types of models  have also been shown to be effective at the temporal scales that we are interested in this study, with Fuxi-S2S \cite{chen2023fuxi} achieving skillfull forecasts at the subseasonal to seasonal scales. Our work aims to leverage the advances in data-driven weather modeling for burned area forecasting with an architecure inspired by Graphcast. 


\section{Seasonal Fire Forecasting}

\subsection{Problem formulation}

We view the problem as binary classification at a particular location of the cube
and a particular timestamp. Thus, given a triplet $(\phi_c, \lambda_c, t_c)$ of latitude, longitude and 8-day period we
predict whether a fire will occur or not at that particular location in time and space. As input we use a timeseries for
each variable of length $ts \in \{6, 12, 24\}$ timesteps, where each timestep corresponds to a single 8-day period.
As target variable  
we predict the presence of burned areas at a future timestep $t+h$ with different 
values of $h \in \{1, 2, 4, 8, 16, 24\}$.



\subsection{Dataset}\label{sec:dataset}
\begin{table}[t]
\centering
\begin{tabular}{llm{5em}}
\toprule
\textbf{Input type} &  \textbf{Variable} & \textbf{Abbreviation}\\
\midrule
\multirow{10}{2.5em}{\textbf{Basic Input}} & Mean sea level pressure & mslp \\
 &Total precipitation & tp \\
 &Vapor Pressure Deficit & vpd \\
 &Sea surface temperature & sst \\
 &Temperature at 2 meters - Mean & t2m\_mean \\
 &Surface solar radiation downwards & ssrd \\
 &Volumetric soil water level 1 & swvl1 \\
 &Land surface temperature at day & lst\_day \\
 &Normalized Difference Vegetation Index & ndvi \\
 &Population density & pop\_dens \\
 \midrule
 \textbf{Static input} & Land Sea Mask & lsm \\
  \midrule
 \multirow{2}{3em}{\textbf{Positional input}} &Latitude (sin/cos) &  lat \\
 &Longitude (sin/cos) & lon  \\
 \midrule
 \textbf{Target} & Burned Areas (as binary) & gwis\_ba\\
 \bottomrule
\end{tabular}

\caption{Fire driver variables (10 input, 1 static and 2 positional) used for predictions.
Target variable represents burned area in hectares (converted to binary for classification tasks).}
\label{tab:variables}
\end{table}

The SeasFire Datacube~\cite{karasante2023seasfire} is an analysis-ready, open-access datacube fit for wildfire forecasting at different spatio-temporal scales that serves not only for seasonal fire forecasting worldwide but also for forecasting emissions from wildfires and predicting the evolution of wildfire regimes.
It spans over 21 years (2001-2021) with an 8-day temporal and a $0.25^{\circ}$ spatial resolution. 
The dataset provides a comprehensive coverage of atmospheric, climatological, vegetation and socioeconomic factors influencing wildfires and contains
58 variables in total, along with target variables,
such as burned areas, fire radiative power, and carbon emissions from wildfires. 
11 different variables were utilized (see Table~\ref{tab:variables}) in order to predict 
the existence of fire in different time horizons. In addition and when needed, we also used simple positional encodings by
augmenting the feature vector with the actual cube coordinates, i.e. sin/cos of latitude and longitude. 
All variables, except the cube coordinates, were standardized before use. 

\subsection{Naive Forecasting}\label{sec:naive}

When dealing with seasonal time 
series, the naive seasonal forecasting method uses the observed values in the 
same period of the previous seasons~\cite{hyndman2018forecasting}. For example 
in order to predict for a particular week of August in a particular year, one could use the 
observed value in the same week of August one year before. 

Our dataset contains multiple years, allowing for different baseline methods
based on the utilization of past data. We utilize the following two: 
\begin{itemize} 
   \item To forecast the occurrence of fire at a particular location in a particular 8-day
   period of the year, we examine whether there were fires at that location in the specific 8-day period in any of the
   previous years. If there were, the model predicts a fire; otherwise, it predicts no fire.
   \item To forecast the occurrence of fire at a particular location in a particular 8-day
   period of the year we use a majority rule. Thus,  
   we predict fire if the number of previous years with fire in that particular 8-day period is larger than the number of
   previous years without fire at that period.
   
\end{itemize}

The majority baseline approach aligns effectively with the binary classification task.

\subsection{Baseline Models}

\subsubsection{Gated Recurrent Units}

Recurrent Neural Networks~\cite{medsker2001recurrent} are a natural choice when trying to capture temporal dependencies.
We utilize a very simple architecture comprising of Gated Recurrent Units. The neural network is
comprised of two GRU layers with 64 hidden channels in each layer. A dropout layer with a probability of 0.1 exists between
the two GRU layers. As the task is binary classification, a final linear layer reduces the representation into a single
prediction and a sigmoid function outputs the final prediction.

\subsubsection{Convolutional GRU}\label{sec:conv-gru}

To capture both temporal and spatial dependencies at the same time, we utilize a convolutional 
GRU network~\cite{DBLP:journals/corr/BallasYPC15}.
In such a network all inputs, cell outputs, hidden states 
and gates are 3D tensors where the last two dimensions are spatial dimensions (rows and columns).
This architecture is particularly effective for spatio-temporal tasks, as it incorporates convolution operations
in the update and reset gates to model spatial relationships.

The ConvGRU model is defined using the following set of equations, where $*$ denotes the convolution operator,
\( \odot \) is element-wise multiplication, and \( \sigma \) is the sigmoid activation function:
\[
\begin{aligned}
    z_t & = \sigma(W_{xz} * X_t + W_{hz} * h_{t-1} + b_z), \\
    r_t & = \sigma(W_{xr} * X_t + W_{hr} * h_{t-1} + b_r), \\
    \tilde{h}_t & = \tanh(W_{x\tilde{h}} * X_t + r_t \odot (W_{h\tilde{h}} * h_{t-1}) + b_{\tilde{h}}), \\
    h_t & = (1 - z_t) \odot h_{t-1} + z_t \odot \tilde{h}_t.
\end{aligned}
\]
Here, \( X_t \in \mathbb{R}^{F \times H \times W} \) represents the input tensor at time step \( t \), 
where \( F \) is the number of features, and \( H \) and \( W \) are the spatial dimensions. 
\( h_{t-1} \) is the hidden state from the previous time step, while \( z_t \) and \( r_t \) are the update
and reset gates, respectively. The hidden state \( h_t \) is updated by controlling how much of the past hidden
state is carried forward (via \( z_t \)) and how much of the new information (via \( \tilde{h}_t \)) is incorporated
into the current state.

Given $(\phi_c, \lambda_c)$ for a particular location of interest and a particular time $t$ we generate
a 3D tensor $X_t$ whose 
last two dimensions are the number of rows and columns of a $(2r+1) \times (2r+1)$ spatial grid. The 
first dimension is the number of features.
The grid is centered at our location of interest
while the remaining locations represent $(\phi_c \pm i \cdot 1^{\circ}, \lambda_c \pm i \cdot 1^{\circ})$
for $i \in \{1, \ldots, r-1\}$. We feed $X_t$ to the model for each timestep $t$ in order to compute 
the hidden representation $h_t$.
The final result is obtained by utilizing MultiLayer Perceptron (MLP) layers in order to gradually aggregate
the information into a single prediction.

\subsubsection{Convolutional LSTM}\label{sec:conv-lstm}

We also utilize a convolutional LSTM network~\cite{shi2015convolutional}. Again all inputs,
cell outputs, hidden states 
and gates are 3D tensors where the last two dimensions are spatial dimensions (rows and columns).
The future state of a certain cell is computed from the input and the past states of its local 
neighbors. This is achieved by using convolution operators in different transitions such as the
state-to-state and/or input-to-state. 

We utilize a slightly different network from the one in~\cite{shi2015convolutional}.
which is implemented using the following equations:
\begin{align*}
   i_t & = \sigma(W_{xi} * X_t + W_{hi} * h_{t-1} + b_i)\\
   f_t & = \sigma(W_{xf} * X_t + W_{hf} * h_{t-1} + b_f)\\
   o_t & = \sigma(W_{xo} * X_t + W_{ho} * h_{t-1} + b_o)\\
   g_t & = tanh(W_{xg} * X_t + W_{hg} * h_{t-1} + b_g)\\
   c_t & = f_t \odot c_{t-1} + i_t \odot g_t\\
   h_t & = o_t \odot tanh(c_t)
\end{align*}
Here $*$ denotes the convolution operator and $\odot$ point-wise multiplication.
We integrate the ConvLSTM into the classification/regression pipeline the same way as the ConvGRU architecture.

\subsubsection{U-Net with Temporal Attention Encoder}\label{sec:utae}

The U-TAE~\cite{garnot2021panoptic} (U-Net with Temporal Attention Encoder) architecture is designed for spatio-temporal
feature extraction
and segmentation of satellite image time series. It extends the classic U-Net by incorporating a temporal
self-attention mechanism to process temporal sequences of images. This enables the network to capture temporal
dependencies across multiple resolution levels.

The U-TAE consists of two main components: the spatial encoder-decoder network and the temporal self-attention module.
The spatial encoder-decoder network follows the U-Net architecture and processes each image in the time series separately.
The encoder applies convolutional layers to extract spatial features from the images at different resolutions. Specifically,
each encoder block consists of two $3 \times 3$ convolutions followed by Group Normalization and ReLU activations, halving
the spatial resolution at each level. The decoder performs upsampling using transposed convolutions, and the corresponding
encoder feature maps are concatenated at each level (U-Net-style skip connections).
To capture the temporal dynamics, U-TAE incorporates a Lightweight-Temporal Attention Encoder~\cite{garnot2020lightweight} (LTAE)
module, which is applied independently to each pixel's feature map sequence extracted from the lowest-resolution level of the
spatial encoder. The LTAE computes temporal attention masks over the sequence, allowing the model to focus on relevant time
steps. These temporal attention maps are then bilinearly interpolated to match the resolutions of the higher levels of the
encoder. After the attention is applied to each feature map group, the feature maps are concatenated and passed through
a $1 \times 1$ convolution to fuse temporal information.

\section{FireCastNet}

\begin{figure*}[t]
    \centering
    \includegraphics[width=0.9\columnwidth, keepaspectratio]{fig/firecastnet-architecture.jpg} 
    \caption{High-level representation of our architecture.
The FireCastNet architecture consists of three main components: (a) a cube embedding block for spatio-temporal feature extraction using a 3D convolution layer that reduces the spatial and temporal dimensions of the input timeseries data 
(b) a GraphCast block, which leverages a multi-mesh Graph Neural Network (GNN) to model long-range spatial interactions across a refined icosahedral mesh structure, and (c) an optional sub-pixel convolution block for upscaling the output to match the resolution of the original input.
}
    \label{fig:high_level_representation}
\end{figure*}

\begin{figure}[th]
    % \hspace{-2.3cm}
    \centering
    \includegraphics[width=0.7\columnwidth]{fig/danger_map_2019-09-30.png} 
    \caption{Target variable and prediction of the best global model, using a time-series of length 24, on 30 September 2019. The target is one period (8-days) ahead.  The sigmoid output represents the prediction confidence.}
    \label{fig:example:prediction}
\end{figure}

 The FireCastNet architecture is shown in Figure~\ref{fig:high_level_representation}. It consists of a
 cube embedding block, a GraphCast block and if needed a 
 sub-pixel convolution for upsampling.
  This architecture is designed to
 perform segmentation or regression tasks on a timeseries of multi-channel images. The input data is represented as a tensor of dimensions
 \( \mathcal{X} \in \mathbb{R}^{T \times C \times H \times W} \), where \( T \) is the number of temporal steps, \( C \) is the number of input
 channels, and \( H \) and \( W \) are the height and width of each image, respectively.

\subsection{Cube embedding}

The first stage of FireCastNet is a 3D convolutional block that performs spatio-temporal feature extraction.
The main purpose of the space-time cube-embedding is to reduce the spatial and temporal dimensions of the input and accelerate the
training process~\cite{tong2022videomae}.
The cube embedding applies a 3-dimensional (3D) convolution layer, with a kernel and stride of
$T \times \frac{H}{H'} \times \frac{W}{W'}$. It also increases the number of channels to $C' > C$.
This block can be expressed as:
\[
\mathcal{X}' = \text{Conv3D}(\mathcal{X}; \mathcal{F}).
\]
The output
tensor encodes the information in dimensions
\( \mathcal{X'} \in \mathbb{R}^{C' \times H' \times W'} \).
To keep the spatial resolution to $0.25^{\circ}$ one has to use $\frac{H}{H'}=1$ and $\frac{W}{W'}=1$. In scenarios where
computation resources are limited one could use $\frac{H}{H'}=4$ and $\frac{W}{W'}=4$ to reduce the spatial resolution 
to $1^{\circ}$. 

We utilize 11 variables from the datacube as depicted in Table~\ref{tab:variables}.
Thus $C=14$. Additionally we keep the spatial resolution to $1^{\circ}$ and choose $C'=64$.
The output of the cube embedding has dimensions $C' \times H' \times W' = 64 \times 720 \times 1440$. Note that 
ERA5 is $721 \times 1440$ while the SeasFire datacube has $720 \times 1440$.

\subsection{GraphCast}

The core of the FireCastNet architecture is the GraphCast module, which uses a Graph Neural Network (GNN) in an "encode-process-decode"
configuration. This module is designed to model long-range spatial interactions over a multi-mesh structure, which is more efficient
and accurate than traditional grids. 
\begin{itemize} 
\item {\bf Multi-mesh} The multi-mesh, \( \mathcal{G} = (\mathcal{V}, \mathcal{E}) \), is a graph where \( \mathcal{V} \) denotes the
      set of nodes and \( \mathcal{E} \) denotes the edges. The multi-mesh is constructed by refining a regular icosahedron over six
      iterations, resulting in 40,962 nodes and 81,920 faces. The graph's nodes are evenly distributed across the globe, overcoming the uneven
      spatial distribution of a standard latitude-longitude grid.
\item {\bf Encoder} The output \( \mathcal{X}'' \) is first mapped from the regular latitude-longitude grid to the multi-mesh 
      representation. This is done by encoding the grid-based features into node attributes using a GNN layer:
      \[
      \mathcal{H}_0 = \text{GNN}_{\text{enc}}(\mathcal{X}''; \mathcal{G}),
      \]
      where \( \mathcal{H}_0 \in \mathbb{R}^{|\mathcal{V}| \times C_{\text{mesh}}} \) represents the learned node attributes
      on the multi-mesh, and \( |\mathcal{V}| \) is the number of nodes in the graph.
      At this location additional positional information related to the position of the mesh nodes (using a mapping of lat/lon
      to the unit-sphere) and mesh edges (using the position on the unit sphere of the mesh nodes)  is encoded 
      together with the incoming features from the grid nodes.
\item {\bf Processor} The processor consists of 12 consecutive layers of GNNs performing message-passing on the multi-mesh
      graph. Let \( \mathcal{H}_l \in \mathbb{R}^{|\mathcal{V}| \times C_{\text{mesh}}} \) represent the node embeddings at
      layer \( l \), where \( l = 0, 1, \ldots, 11 \). Each GNN layer updates the node embeddings using the following
      message-passing scheme:
      \[
      \mathcal{H}_{l+1} = \text{GNN}_{\text{process}}(\mathcal{H}_l, \mathcal{G}),
      \]
      which enables efficient information propagation across long distances via the multi-scale mesh structure.
\item {\bf Decoder} The final processor output, \( \mathcal{H}_{11} \), is mapped back to the original
        latitude-longitude grid using a GNN decoder:
        \[
        \mathcal{X}_{\text{decoded}} = \text{GNN}_{\text{dec}}(\mathcal{H}_{11}; \mathcal{G}).
        \]
\end{itemize}

\subsection{Upscaling}

The final stage of FireCastNet is a sub-pixel convolution~\cite{shi2016real} block, which upscales the decoded
output \( \mathcal{X}_{\text{decoded}} \in \mathbb{R}^{C''' \times H'' \times W''} \) to match the spatial dimensions
of the original input. It rearranges the feature map into higher-resolution output, producing the final segmentation map
of size \( H \times W \). The upscaling operation is defined as:
\[
\mathcal{X}_{\text{output}} = \text{Sub-Pixel-Conv}(\mathcal{X}_{\text{decoded}}),
\]
yielding the segmentation output \( \mathcal{X}_{\text{output}} \in \mathbb{R}^{C_{\text{out}} \times H \times W} \),
where \( C_{\text{out}} \) is the number of output channels for the segmentation task.


\section{Experiments}\label{sec:experiments}

  
Our methodology can be directly applied to any region of the world, producing different models per region. For our forecasting task, our split is time-based, using years 2002-2017, 2018 and 2019 for train, validation, and test, respectively.
The SeasFire dataset is utilized in all the experiments (see Section~\ref{sec:dataset}).
Figure~\ref{fig:example:prediction} shows the ground truth and model predictions for September 30, 2019, trained to forecast one 8-day period ahead.

Due to our highly imbalanced dataset, the performance of the model is evaluated using the Area Under the Precision-Recall Curve (AUPRC)~\cite{davis2006relationship}. 
We calculate the metric using the average precision score, which 
summarizes a precision-recall curve as a weighted mean of precisions at each threshold, with the difference in recall from the previous threshold as weight
\[
  AP = \underset{t}{\sum} (R_t - R_{t-1}) \cdot P_t, 
\]
where $P_t, R_t$ is the respective precision and recall at threshold index $t$. 

Models are trained for 50 epochs. We use binary cross-entropy loss and the
AdamW~\cite{DBLP:conf/iclr/LoshchilovH19} optimizer. The initial learning rate is set to $0.001$ and adjusted using SGDR~\cite{DBLP:conf/iclr/LoshchilovH17}. 
The schedule contains two cycles with 10 and 40 epochs, respectively. A weight decay factor of $10^{-7}$ is used when training all models.

\subsection{Global Model}

In this section, we train and compare FireCastNet at a global scale. 
The naive prediction baseline models discussed in Section~\ref{sec:naive} 
exhibit $0.35$ and $0.39$ AUPRC. The first baseline checks whether any previous year contains some fire in the same period, while the second checks whether a majority of the previous years contains fires. 

All models take as input the 11 inputs described in Table~\ref{tab:variables}. 
The GRU model is comprised of a single hidden layer with 64 hidden units.   
The Conv-GRU and Conv-LSTM models use the same parameters as the GRU with the only difference of an additional setting of the $5 \times 5$ kernel.
The U-TAE model is configured with 16 attention heads, and a layer size of 256. Each attention head has a key dimension of 4.
      
    Finally, FireCastNet processes data with spatial resolution $0.25^{\circ}$ and geographic bounds from -89.875° to
    89.875° latitude and -179.875° to 179.875° longitude. The Conv3d block increases spatial resolution to $1^{\circ}$,
    and adjusts the hidden dimensionality to 128, with layer normalization.  
    Additionally mesh input includes 3 dimensions for nodes and 4 for
    edges. The model's processor features 8 layers, with 1 hidden layer and a hidden layer dimension of 64.

    Figures~\ref{fig:all:ts12:globe:auprc} and~\ref{fig:all:ts24:globe:auprc} presents the best model results when
    predicting at a global scale when using timeseries 12 and 24 8-day periods respectively. A more detailed comparison
    between models with respect to the timeseries length can be seen at Figure~\ref{fig:heatmap:auprc}.
    Different GRU, ConvGRU, ConvLSTM, UTAE and FireCastNet models were trained for each prediction time horizon
    and timeseries length. 
    Regardless of the range of forecasts, the FireCastNet is clearly more potent in per-pixel classification, Especially
    when using a longer timeseries input. Additionally, FireCastNet is highly consistent in providing burnt area
    predictions whilst other methods show a decline proportional to the increase in the forecasting horizon. 

    

    Additionally, Table~\ref{tab:all:ts24:globe:auprc} provides results between all baselines and the FireCastNet
    model for timeseries length 24 for different time horizons. The TeleVit~\cite{Prapas_2023_ICCV} model is also
    included in the comparison. TeleViT is a teleconnection-driven vision transformer for seasonal wildfire forecasting,
    trained also on the SeasFire dataset. It should be noted that it does not work directly with timeseries data. Instead,
    it extracts temporal context from Oceanic Indices (OCIs).

    \begin{table*}[tbp]
    
    \begin{tabular}{|l|c|c|c|c|c|c|}
        \toprule
        \textbf{Model \textbackslash Horizon} & 1 & 2 & 4 & 8 & 16 & 24 \\
        \midrule
        GRU                & 0.5581        & 0.5490        & 0.5402        & 0.5185    & 0.5205     & 0.5195 \\
        Conv-GRU           & 0.5934        & 0.5790        & 0.5556        & 0.5506    & 0.5446     & 0.5690      \\
        Conv-LSTM          & 0.6346  & 0.6080        & 0.6149        & 0.6009    & 0.5981     & 0.5893 \\
        UTAE               & 0.6238        & 0.6212        & 0.6114        & 0.6014    & 0.6077     & 0.5936      \\
        TeleViT~\cite{Prapas_2023_ICCV} & 0.6223        & 0.6172        & 0.6102        & 0.6107    & 0.6063     & 0.6036 \\
        FireCastNet (ours) & {\bf 0.6405}        & {\bf 0.6362}  & {\bf 0.6314}  & {\bf 0.6305} & {\bf 0.6277} & {\bf 0.6329} \\
        \bottomrule
    \end{tabular}
    \centering
    \caption{Comparison of all global-scale models. The time-series length is 24 (except for TeleViT, which cannot process time-series). }  \label{tab:all:ts24:globe:auprc}
\end{table*}

\begin{figure}[th]
        \centering
        \begin{tikzpicture}
            \begin{axis}[
                xlabel={Forecasting Window Length (8-days period)},
                ylabel={AUPRC},
                legend style={at={(0.22,0.01)},anchor=south},
                xtick={1,2,4,8,16,24},
                ytick={0.4, 0.45,0.5, 0.55,0.6, 0.65,0.7, 0.75, 0.8, 0.85,0.9,1.0},
                xmin=0,
                xmax=25,
                ymin=0.50, 
                ymax=0.65,
                grid=both,
                major grid style={line width=.1pt,draw=mygray!50},
                minor tick num=1,
                every major grid/.style={line width=.1pt,draw=mygray!50},
            ]
            %\addplot[mark=square, color=myblue] table [x=x, y=ts12] {gru-globe.dat};
            \addplot[style={solid}, mark=diamond, color=mygreen] table [x=x, y=ts12] {convgru-globe.dat};
            \addplot[mark=pentagon, color=mypurple] table [x=x, y=ts12] {convlstm-globe.dat};
            \addplot[mark=triangle, color=mycyan] table [x=x, y=ts12] {utae-globe.dat};
            \addplot[mark=star, color=myorange] table [x=x, y=ts12] {firecastnet-globe.dat};

            %\legend{GRU, Conv-GRU, Conv-LSTM, UTAE, FireCastNet}
            \legend{Conv-GRU, Conv-LSTM, UTAE, FireCastNet}

            \end{axis}
            %\node at (3.3,6.0) {Global};
        \end{tikzpicture}
        \caption{Performance of Conv-GRU, Conv-LSTM, UTAE and FireCastNet models at
        a global scale with timeseries length $12$ for 
        different forecasting windows.}\label{fig:all:ts12:globe:auprc}
    \end{figure}

\begin{figure}[th]
        \centering
        \begin{tikzpicture}
            \begin{axis}[
                xlabel={Forecasting Window Length (8-days period)},
                ylabel={AUPRC},
                legend style={at={(0.39,0.01)},anchor=south, legend columns=2},
                %legend style={at={(0.22,0.01)},anchor=south},
                xtick={1,2,4,8,16,24},
                ytick={0.4, 0.45,0.5, 0.55,0.6, 0.65,0.7, 0.75, 0.8, 0.85,0.9,1.0},
                xmin=0,
                xmax=25,
                ymin=0.50, 
                ymax=0.65,
                grid=both,
                major grid style={line width=.1pt,draw=mygray!50},
                minor tick num=1,
                every major grid/.style={line width=.1pt,draw=mygray!50},
            ]

            %\addplot[mark=square, color=myblue] table [x=x, y=ts24] {gru-globe.dat};
            \addplot[style={solid}, mark=diamond, color=mygreen] table [x=x, y=ts24] {convgru-globe.dat};
            \addplot[mark=pentagon, color=mypurple] table [x=x, y=ts24] {convlstm-globe.dat};
            \addplot[mark=triangle, color=mycyan] table [x=x, y=ts24] {utae-globe.dat};
            \addplot[mark=star, color=myorange] table [x=x, y=ts24] {firecastnet-globe.dat};

            %\legend{GRU, Conv-GRU, Conv-LSTM, UTAE, FireCastNet}
            \legend{Conv-GRU, Conv-LSTM, UTAE, FireCastNet}


            \end{axis}
            %\node at (3.3,6.0) {Global};
        \end{tikzpicture}
        \caption{Performance of Conv-GRU, Conv-LSTM, UTAE and FireCastNet models at
        a global scale with timeseries length $24$ for 
        different forecasting windows.}\label{fig:all:ts24:globe:auprc}
    \end{figure}


    \subsection{Timeseries length}
    
    In this section, we investigate the impact of training global models using input time series of varying lengths, both with and without spatially accumulated information. This analysis aims to explore how the temporal context provided to the models affects their predictive performance across different forecasting horizons. Specifically, we evaluate models trained with three distinct time-series lengths, $ts \in \{6, 12, 24\}$, and analyze their performance in terms of the Area Under the Precision-Recall Curve (AUPRC). For each combination of time-series length and forecasting horizon $h \in \{1, 2, 4, 8, 16, 24\}$, we train a separate model to assess the influence of these parameters independently.

    Figure~\ref{fig:global:timeseries} summarizes the performance of the models under these configurations, offering insights into how time-series length affects prediction accuracy. Among the various models studied, the GRU model demonstrates a clear positive correlation between time-series length and performance. The results indicate that longer input sequences provide richer temporal context, which enhances the GRU’s ability to capture complex temporal dependencies and improves predictive accuracy consistently across all forecasting horizons.
    
    For the Conv-LSTM model, a similar trend is observed, albeit with diminishing returns as the time-series length increases from 12 to 24. While both 12 and 24-length time series yield competitive results, the latter shows slight advantages, particularly for longer-term forecasts.
    
    On the other hand, the Conv-GRU model exhibits an unexpected behavior, where mid-range time-series lengths (12) outperform both shorter (6) and longer (24) inputs. This suggests that the Conv-GRU may balance the trade-off between overfitting to longer sequences and underutilizing shorter ones. 
    
    The UTAE model shows competitive performance with both 12 and 24-length time series, although the gap between these configurations widens for longer forecasting horizons. This behavior implies that while the UTAE model benefits from longer input sequences for more extended predictions, it does not fully exploit the additional temporal information as effectively.

    FireCastNet demonstrates stability and robustness compared to the other architectures. Regardless of the forecasting horizon, the model maintains relatively consistent performance, particularly when trained with the longest time-series length of 24. This suggests that FireCastNet effectively leverages the full temporal context.
        
   
\begin{figure*}[th]
    \centering
    \includegraphics[width=0.8\columnwidth]{fig/auprc-heatmap-all-models.png} 
    \caption{Model performance at a global scale with different time-series length $ts \in \{6, 12, 24\}$ periods (8-days).}\label{fig:global:timeseries}
    \label{fig:heatmap:auprc}
\end{figure*}


\subsection{Ablation different time overlap}

In this section, we conduct an ablation study to investigate the effect of varying sample overlaps between consecutive time series on model accuracy, as measured by the Area Under the Precision-Recall Curve (AUPRC). This study aims to understand the role of overlapping temporal context in improving model performance and its implications for training efficiency and predictive accuracy.

In the original setup, for a time series of length $t$, each sample overlaps with $t-1$ identical points from the subsequent sample. This ensures that consecutive input sequences share nearly the entire temporal context, differing by only a single time step. To systematically evaluate the effect of overlap, we consider scenarios where the overlap is reduced. Specifically, for time series with $t=24$, we analyze configurations where consecutive samples share 3, 6, 12, 18, and including the original full-overlap configuration of $t-1=23$ samples

The results, illustrated in Figure~\ref{fig:all:ts24:globe:auprc:overlap}, reveal a clear proportional relationship between the degree of overlap and the resulting AUPRC scores. Higher overlaps consistently yield better AUPRC values, underscoring the importance of preserving shared temporal information between samples.
Using the highest possible overlap ($t-1=23$) offers several key advantages such as enabling the model to capture subtle temporal patterns and correlations, particularly for dynamic and time-sensitive phenomena and leveraging information from adjacent time steps. 

While higher overlaps do result in a greater computational burden due to increased redundancy in input samples, the benefits in terms of predictive accuracy and model robustness outweigh this drawback in many practical scenarios. The results emphasize that preserving shared temporal context is a crucial factor for achieving superior accuracy, particularly in tasks requiring fine-grained temporal predictions.


\begin{figure}[ht]
        \centering
        \begin{tikzpicture}
            \begin{axis}[
                xlabel={Forecasting Window Length (8-days period)},
                ylabel={AUPRC},
                legend style={at={(0.42,0.01)}, anchor=south, legend columns=5},
                xtick={1,2,4,8,16,24},
                ytick={0.4, 0.45,0.5, 0.55,0.6, 0.65,0.7, 0.75, 0.8, 0.85,0.9,1.0},
                xmin=0,
                xmax=25,
                ymin=0.50, 
                ymax=0.65,
                grid=both,
                major grid style={line width=.1pt,draw=mygray!50},
                minor tick num=1,
                every major grid/.style={line width=.1pt,draw=mygray!50},
            ]
            \addplot[style={solid}, mark=diamond, color=red] table [x=x, y=ts24overlap3] {firecastnet-globe.dat};
            \addplot[mark=pentagon, color=mypurple] table [x=x, y=ts24overlap6] {firecastnet-globe.dat};
            \addplot[mark=triangle, color=blue] table [x=x, y=ts24overlap12] {firecastnet-globe.dat};
            \addplot[mark=star, color=myorange] table [x=x, y=ts24overlap18] {firecastnet-globe.dat};
            \addplot[mark=square, color=mygreen] table [x=x, y=ts24] {firecastnet-globe.dat};
            \legend{3, 6, 12, 18, 23}

            \end{axis}
            %\node at (3.3,6.0) {Global};
        \end{tikzpicture}
        \caption{Performance of FireCastNet model at
        a global scale with timeseries length $24$ for 
        different time overlap windows.}\label{fig:all:ts24:globe:auprc:overlap}
    \end{figure}


\subsection{GFED Regions}

%
%{'description': '0-OCEAN, 1-BONA, 2-TENA, 3-CEAM, 4-NHSA, 5-SHSA, 6-EURO, 7-MIDE, 8-NHAF, 9-SHAF, 10-BOAS, 11-CEAS, 12-SEAS, 13-EQAS, 14-AUST. For more information visit http://globalfiredata.org/pages/data/ ', 'long_name': 'GFED basis regions'}
% 0: OCEAN
% 1: BONA (Boreal North America)
% 2: TENA Temperate North America
% 3: CEAM Central America
% 4: NHSA Nothern Hemisphere South America
% 5: SHSA Southern Hemisphere South America
% 6: EURO Europe
% 7: MIDE Middle East
% 8: NHAF Northern Hemisphere Africa
% 9: SHAF Southern Hemisphere Africa
% 10: BOAS Boreal Asia
% 11: CEAS Central Asia
% 12: SEAS Southeast Asia
% 13: EQAS Equatorial Asia
% 14: AUST Australia and New Zealand

\newcolumntype{C}[1]{>{\centering\arraybackslash}p{#1}}
\begin{table*}[htbp]
    \centering
    \scriptsize
    \begin{tabular}{|r|C{6em}|c|c|c|c|c|c|}
        \toprule
        \multirow{2}{*}{\textbf{GFED Region}} & \multirow{2}{8em}{\textbf{Fraction of \newline burned areas}} & \multicolumn{6}{c|}{\textbf{Horizon}}\\
        \cline{3-8}
         & & 1 & 2 & 4 & 8 & 16 & 24 \\
        \midrule
        % \color{red}?OCEAN? & \color{red}0.3609 & \color{red}0.3570 & \color{red}0.3588 & \color{red}0.2916 & \color{red}0.3629 & \color{red}0.3583\\
        Boreal North America    (BONA) & 0.924\% & 0.0364 & 0.0312 & 0.0251 & 0.0254 & 0.0217 & 0.0234\\
        Temperate North America (TENA) & 1.986\% & 0.2608 & 0.2673 & 0.2621 & 0.2571 & 0.2539 & 0.2573\\
        Central America (CEAM) & 2.137\% & 0.5499 & 0.5379 & 0.5318 & 0.5328 & 0.5456 & 0.5490\\
        Northern Hemisphere South America (NHSA) & 2.673\% & 0.6643 & 0.6475 & 0.6360 & 0.6288 & 0.6067 & 0.6047\\
        Southern Hemisphere South America (SHSA) & 15.619\% & 0.4382 & 0.4321 & 0.4285 & 0.4184 & 0.4119 & 0.4083\\
        Europe (EURO) & 0.857\% & 0.1959 & 0.1946 & 0.1860 & 0.1832 & 0.1737 & 0.1864\\
        Middle East (MIDE) & 1.029\% & 0.2846 & 0.2957 & 0.2855 & 0.2945 & 0.2870 & 0.2574\\
        Northern Hemisphere Africa (NHAF) & 20.749\% & 0.7371 & 0.7279 & 0.7163 & 0.7097 & 0.7140 & 0.7181\\
        Southern Hemisphere Africa (SHAF) & 29.988\% & 0.8465 & 0.8432 & 0.8409 & 0.8303 & 0.8308 & 0.8371\\
        Boreal Asia (BOAS) & 4.072\%  & 0.1420 & 0.1336 & 0.1264 & 0.1313 & 0.1319 & 0.1400\\
        Central Asia (CEAS) & 8.264\% & 0.2736 & 0.2594 & 0.2647 & 0.2565 & 0.2466 & 0.2399\\
        Southeast Asia (SEAS) & 5.764\% & 0.6410 & 0.6312 & 0.6206 & 0.6087 & 0.5988 & 0.6069\\
        Equatorial Asia (EQAS) & 1.089\% & 0.4874 & 0.4953 & 0.4784 & 0.4360 & 0.4044 & 0.4022\\
        Australia and New Zealand (AUST) & 4.849\% & 0.3095 & 0.3046 & 0.3036 & 0.3015 & 0.2919 & 0.3180\\
        \bottomrule
    \end{tabular}
    \centering
    \caption{Model performance per GFED region for different prediction horizons. The fraction of burned areas represents the percentage of wildfires in a specific region relative to the total number of fires globally }  
    \label{tab:firecastnet:gfed:auprc}
\end{table*}

In this section, we present localized predictions derived using regional masks from the Global Fire Emissions Database (GFED), as provided by the SeasFire Datacube~\cite{karasante2023seasfire}. These regional masks allow for a more granular analysis of fire activity by focusing on specific geographic areas. To produce region-specific predictions, we compute the Area Under the Precision-Recall Curve (AUPRC) for each region by applying the GFED masks to both the model's output and the ground truth burned area data. 

Table~\ref{tab:firecastnet:gfed:auprc} summarizes the AUPRC results across all GFED regions and for multiple time horizons, providing a comprehensive overview of the model's performance in diverse settings. In the same table we have also added the fractions of burned areas per GFED region. These represent the percentages of wildfires in a specific region relative to the total number of fires globally, calculated from 2002-01-01 to 2020-01-01. Notably, FireCastNet demonstrates superior accuracy in burned area forecasts, particularly in Southeast Asia, Northern Hemisphere South America, and Africa, highlighting its effectiveness in regions with distinct fire regimes and challenges. 
The fact that the global model exhibits different behavior in different areas seems to suggest that training localized models which focus on smaller regions could be beneficial.



\section{Conclusion}

The findings of this study underscore the potential of machine learning models in advancing seasonal wildfire forecasting. Our  architecture, FireCastNet, integrates 3D convolutional encoding with GraphCast, in order to capture the spatio-temporal context of wildfires, enabling predictive analysis across various forecasting horizons. Our architecture is clearly more beneficial than both baseline and contemporary methods for spatio-temporal predictions and burned area prediction via semantic segmentation.

One significant insight derived from our investigation is the importance of temporal context. The results clearly show that longer input time-series enhance predictive robustness across forecasting horizons. This finding aligns with the intuition that wildfires are influenced by accumulated climatic, vegetative, and human-related factors, which can be utilized more effectively by adding a deeper temporal history.

This outcome shows the benefits of architectures that can process both local and regional patterns, highlighting the interconnected nature of wildfire phenomena where adjacent regions' conditions can influence fire behavior. 
    
    \section*{Acknowledgment}  
This work has received funding from the SeasFire project, which focuses on Earth System Deep Learning for Seasonal Fire Forecasting and is funded by the European Space Agency (ESA) under the ESA Future EO-1 Science for Society Call.  

\input{firecastnet.bbl}


\end{document}
