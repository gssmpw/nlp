\section{Dataset}
\label{appendix:dataset}

Here we give details on the training dataset generated from the DINO configuration.
The configuration uses a mercator grid with $\frac{1}{4} \degree$ horizontal resolution and 36 vertical levels. The domain spans 60° longitude and 70° latitude from equator to both poles. For this study, we generated a dataset by running DINO for 50 years, saving 1800 snapshots of temperature and salinity fields. The resulting dataset consists of 1800 states, each containing two 3D fields (T,S). 
Prior to training, we perform per-level standardization of both temperature and salinity fields, computing means and standard deviations from the training set.

\section{Diffusion model}
\label{appendix:diffusion model}

The training objective for our denoiser is:

\begin{equation}
    \mathcal{L}(\theta) = \mathbb{E}_{s,x_0,\epsilon} [||\epsilon_\theta(x_s, s) - \epsilon||^2]
\end{equation}

where $x_s = \sqrt{\bar{\alpha}_s}x_0 + \sqrt{1-\bar{\alpha}_s}\epsilon$ with $x_0$ sampled from our training data, $\epsilon \sim \mathcal{N}(0, \mathbf{I})$, and $\{\bar{\alpha}_s = \prod_1^s \alpha_k \}_{s=1}^S$ where the $\alpha$ are fixed by our variance schedule. (In practice we use 
"squaredcos\_cap\_v2" from Hugging Face library \footnote{\small https://huggingface.co/docs/diffusers/v0.32.2/en/api/schedulers/ddpm}.)

To generate samples, we start from Gaussian noise $x_S \sim \mathcal{N}(0, \mathbf{I})$ and iteratively denoise it :

\begin{equation}
    x_{s-1} = \alpha_s^{-\frac12}(x_s - \gamma_s\epsilon_\theta(x_s, s)) + \sigma_s \mathbf{z}
\end{equation}

where $\mathbf{z} \sim \mathcal{N}(0, \mathbf{I})$, $\gamma_s = (1-\alpha_s) (1-\bar \alpha_s)^{-\frac12}$, and $\sigma_s$ is the standard deviation of the reverse process noise. This sampling procedure progressively transforms noise into oceanic states.


\section{Metrics}
\label{appendix:metrics}

\subsection{Bottom-Deep water boxes :}

In figure \ref{fig:box} we describe the area of the Deep and Bottom water boxes. 

\begin{figure}[h!]
    \centering
    \includegraphics[width=\linewidth]{Figures/Boxes.png}\
    \caption{Illustration of the areas considered for computing the Bottom Water and Deep Water characteristics. Strength of the Antarctic Circumpolar Current (ACC) and North Atlantic subtropical gyre (NASTG) are also depicted, as they are crucial elements of the global ocean dynamics.}
    \label{fig:box}
\end{figure}


\subsection{Density error metric :}

We define a density error metric to measure the proportion of the ocean volume where the vertical density profile violates hydrostatic stability, calculated as:

\begin{equation}
    \text{Density Error} = 100 \times \frac{\sum_{i,j,k} V_{i,j,k} \cdot \mathbbm{1}\{\rho_{i,j,k+1} - \rho_{i,j,k} < 0\}}{\sum_{i,j,k} V_{i,j,k}}
\end{equation}

where $V_{i,j,k}$ represents the volume of each grid cell, $\rho_{i,j,k}$ is the density at grid point $(i,j,k)$, with indices $(i,j,k)$ corresponding to (longitude, latitude, depth) coordinates. The indicator function $\mathbbm{1}\{\cdot\}$ equals 1 when the density difference between two vertical levels is negative (unstable stratification) and 0 otherwise. The result is expressed as a percentage of the total volume exhibiting density instabilities.

\section{Training and inference details}
\label{appendix:training}

AdamW was used for training with an initial learning rate of \texttt{1e-4} and a cosine learning scheduler with no warmup steps. Batch size was 8. Training took nearly two days and a half on a single V100 GPU card.

We did not perform hyperparameter tuning in this work as the goal was not to find the optimal performance for the diffusion model. We are aware that many aspects of the training can be largely improved. Future work include training with Exponential Moving Average (EMA) and investigating the use of Latent Diffusion Models.


For the hydrostatic constraint we use $\kappa(s) = \eta (1 + \lambda e^{-\frac{ks}{S}})$ with $\eta=1e-3$, $\lambda=40$ and $k=20$. These values were chosen empirically, with the goal of enforcing stronger constraint near the end of the generation ($s=1$) compared to the start ($s=S$).

As we run into boundary issues when using convolutional kernels near solid boundaries, we implement a simple solution for generated fields where the values of cells directly adjacent to the top and bottom walls are copied from their nearest interior cell.


\section{Architecture}
\label{appendix:architecture}
A widely adopted network architecture in diffusion models is the U-Net \citep{ronneberger2015u}, originally developed for biomedical image segmentation. A U-Net typically consists of a downsampling path and an upsampling path, with skip connections between corresponding layers in the two paths. These skip connections preserve spatial detail by allowing the model to combine low-level features from earlier layers with higher-level features in deeper layers, which is especially beneficial in image generation tasks. 

In our work, we employ a U-Net inspired architecture available in Hugging Face’s Diffusers library \citep{von-platen-etal-2022-diffusers}, which provides a flexible and widely adopted PyTorch implementation of diffusion-based generative models. The Diffusers' U-Net follows a multi-scale approach with residual blocks, attention mechanisms, and skip connections between downsampling and upsampling stages. These design choices enable the network to capture both global context and fine-grained details. We base our implementation on this standard U-Net, adapting its channel dimensions and layer configurations to fit our computational constraints and target resolution. Two main modifications with regard of the standard architecture were done, firstly we chose to remove attention mechanisms from the DownBlocks and UpBlocks and keep it only for the MiddleBlock for computational reasons, and secondly we replace the nearest neighbors upsampling by a bilinear upsampling to avoid checkerboard effects. The following figure summarizes the architecture, interested readers might refer to the diffusers library documentation\footnote{https://huggingface.co/docs/diffusers/v0.32.2/en/api/models/unet2d} for more details.

\begin{tikzpicture}[
    node distance=0.5cm and 0.8cm,
    block/.style={
        rectangle, 
        minimum width=2cm, 
        minimum height=1.5cm,
        draw=blue!80!black,
        thick,
        fill=blue!5,
        rounded corners=3pt,
        font=\footnotesize,
        align=center
    },
    concat/.style={
        rectangle,
        draw=red!80!black,
        fill=red!5,
        minimum size=6pt,
        font=\scriptsize\bfseries,
        inner sep=1pt
    },
    arrow/.style={
        -{Stealth[length=3mm]},
        thick,
        black!80
    },
    io/.style={
        block,
        fill=green!5,
        minimum width=2cm,
        font=\footnotesize\itshape,
    }]

\coordinate (input-point) at (0,3);
\coordinate (output-point) at (0,-3);

\node[io] (input) at (input-point) {Input\\36 Channels\\208$\times$64};
\node[io] (output) at (output-point) {Output\\36 Channels\\208$\times$64};

\node[block, right=of input] (e1) {DownBlock\\64\\104$\times$32\\2$\times$ResNet};
\node[block, right=of e1] (e2) {DownBlock\\64\\52$\times$16\\2$\times$ResNet};
\node[block, right=of e2] (e3) {DownBlock\\128\\26$\times$8\\2$\times$ResNet};
\node[block, right=of e3] (e4) {DownBlock\\128\\13$\times$4\\2$\times$ResNet};

\node[block, below=2cm of e4] (mid) {MiddleBlock\\128\\13$\times$4\\2$\times$ResNet};

\node[block, below=of mid, xshift=-1cm] (tpe) {Positional \\Encoding};
\node[io, left=of tpe] (tinput) {Diffusion Step\\(Scalar)};
\draw[arrow] (tinput) -- (tpe);


\node[block, left=of mid] (d4) {UpBlock\\128+128\\26$\times$8\\2$\times$ResNet};
\node[block, left=of d4] (d3) {UpBlock\\128+128\\52$\times$16\\2$\times$ResNet};
\node[block, left=of d3] (d2) {UpBlock\\64+64\\104$\times$32\\2$\times$ResNet};
\node[block, left=of d2] (d1) {UpBlock\\64+64\\208$\times$64\\2$\times$ResNet};

\draw[arrow] (input) -- (e1);
\foreach \i [evaluate={\j=int(\i+1);}] in {1,2,3} 
    \draw[arrow] (e\i) -- (e\j);
\draw[arrow] (e4) -- (mid);
\draw[arrow] (mid) -- (d4);
\foreach \i [evaluate={\j=int(\i-1);}] in {4,3,2} 
    \draw[arrow] (d\i) -- (d\j);
\draw[arrow] (d1) -- (output);

\foreach \i in {1,2,3,4} {
    \draw[arrow, dashed, red!50] (e\i.south) 
        .. controls +(down:8mm) and +(up:8mm) .. 
        (d\i.north)
        node[concat, pos=0.5] {Concat};
}

\tikzset{
    arrowSplit/.style={
        -{Stealth[length=3mm]},
        gray,
        rounded corners
    }
}


\coordinate (split) at ($(tpe.north) + (-0.3,0.5)$);

\draw[arrowSplit, rounded corners] (tpe.north) -- (split);

\draw[arrowSplit, rounded corners] (split) |- (e1.south);
\draw[arrowSplit, rounded corners] (split) |- (e2.south);
\draw[arrowSplit, rounded corners] (split) |- (e3.south);
\draw[arrowSplit, rounded corners] (split) |- (e4.south);
\draw[arrowSplit, rounded corners] (split) -- (mid.south);
\draw[arrowSplit, rounded corners] (split) |- (d4.south);
\draw[arrowSplit, rounded corners] (split) |- (d3.south);
\draw[arrowSplit, rounded corners] (split) |- (d2.south);
\draw[arrowSplit, rounded corners] (split) |- (d1.south);

\end{tikzpicture}

