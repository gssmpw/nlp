\section{Related work}
\label{sec:related_works}
In this section, we provide an overview of related works, focusing specifically on 4D Radar signal processing and data generation, as well as previous studies on data translation methods using cGANs, which form the basis for developing models that generate tensor data from point cloud data.

\begin{figure*}[!th]
    \centering
    \vspace{1mm} % 위쪽 여백 추가
    \includegraphics[width=1\textwidth]{fig/fig2.png} 
    \caption{Overall structure of 4DR P2T. The encoder utilizes 3D sparse convolution to process 4D Radar point cloud data, while the decoder employs 3D dense convolution to generate tensor data.}
    \label{fig2.model}
\end{figure*}

\subsection{4D Radar signal processing and data generation}
The 4D Radar signal processing and data generation process, as applied in autonomous driving, is illustrated in Figure \ref{fig1.4d_radar_data}. The core analog components of a 4D Radar system consist of a synthesizer, transmission (TX) antennas, reception (RX) antennas, and a mixer. The TX antennas emit electromagnetic waves, which reflect off objects in the environment and are received by the RX antennas. The transmitted signal is generated by the synthesizer and radiated through the TX antennas. This signal is a frequency-modulated continuous wave (FMCW), composed of a sequence of frequency-modulated signals, commonly referred to as chirps.

The signal emitted by the TX antennas and the signal received by the RX antennas are combined using a mixer, producing an intermediate frequency (IF) signal. This IF signal represents the frequency difference between the transmitted and received signals, which is used to extract the distance and velocity of the reflected objects. The generated IF signal is then converted into a digital form through an analog-to-digital converter (ADC), creating ADC sample data. This data is separated into a fast time axis, which calculates range information through chirp sampling, and a slow time axis, which calculates Doppler information through frame sampling.

The ADC sample data is processed through a 2D Fast Fourier Transform (FFT), which is applied to perform range FFT and Doppler FFT. The range FFT estimates the distance to objects, while the Doppler FFT estimates their relative velocity, resulting in the generation of an RD heatmap. Although the RD heatmap contains information about range and velocity, it does not include azimuth or elevation information, making it less intuitive to interpret.

To extract azimuth and elevation information, an additional angle FFT is applied to the RD heatmap. The angle FFT utilizes the positional information of the TX and RX antennas arrays in a multiple-input and multiple-output (MIMO) antennas design to analyze the phase differences in the reflected signals. This process generates a 4D tensor that includes range, azimuth, elevation, and Doppler information, with each tensor cell representing the corresponding signal strength. The 4D tensor is represented in a polar coordinate system, but for better interpretability, the visualization shown in the Fig. \ref{fig1.4d_radar_data} is converted into a Cartesian coordinate system.

The generated 4D tensor data is filtered using the CFAR method. CFAR dynamically adjusts the threshold by comparing the signal strength of each cell to its surrounding cells, effectively removing noise and identifying actual targets. This filtering process is applied across all dimensions of the tensor, ultimately producing point cloud data that contains information about actual targets.

The resulting point cloud data includes the position (range, azimuth, elevation) and Doppler of the detected objects and is utilized in various autonomous driving applications, such as object detection and tracking \cite{4dradar_tutorial, 4D_radar_survey, FFT-RadNet}.

\subsection{Image translation}

Image translation focuses on style translation while preserving key information. Notable methods include pix2pix \cite{pix2pix} and pix2pixHD \cite{pix2pixhd}. These methods utilize cGANs to translate input images into output images. These methods have been successfully applied to various image synthesis and transformation tasks \cite{radsimreal, l2r, radarpointgenerator1}. Pix2pix employs a U-Net-based generator and a patch-based discriminator, enabling applications such as image synthesis and color translation. Pix2pixHD extends this framework to handle high-resolution images by incorporating boundary maps, multi-scale generators, and multi-scale discriminators, achieving improved quality. These methods excel at 2D image-to-image translation while maintaining structural information.

However, this study deals with generating tensor data from 4D Radar point cloud data, making it challenging to directly apply conventional image translation models. Existing methods are primarily optimized for 2D image data, necessitating structural modifications to handle higher-dimensional data such as point clouds and tensors. To address this, this study extends the fundamental method of pix2pixHD by modifying the model architecture to effectively process 3D or higher-dimensional data.