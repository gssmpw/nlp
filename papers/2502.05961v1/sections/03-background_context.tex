\section{Historical Origins of `Long-Tailed' Data in Machine Learning}\label{background}

T2I systems perform poorly when creating images of socially marginalised populations, such as people with disabilities or cultural objects from the Majority World~\cite{qadri2024,dasProvenanceAberrationsImage2024,mack2024they}. ML researchers attribute poor model performance on these topics to the \textit{long-tailed} nature of data about socially marginalised groups: models struggle to learn meaningful patterns and produce accurate, fair results because long-tailed data comprise a negligible portion of the training instances~\cite{zhang2023deeplongtailed, massiceti2021orbit}. 

Data from socially marginalised groups are less likely to be preserved in a digitised format and available on the Internet~\cite{Noble+2018}. Additionally, these data are systematically screened out of training datasets by state-of-the-art filtering models, such as CLIP \cite{radford2021learning}, which are biased towards including data from and about Western cultures~\cite{hong2024s}. Researchers use filtering methods such as CLIP to curate datasets in the first place to improve model quality by removing noisy, irrelevant, or potentially harmful content, aiming to optimise the relevance and accuracy of the data for the model’s intended use~\cite{fang2023data}. However, these filtering methods often encode and amplify existing biases, leading to datasets that inadvertently exclude non-Western cultures and marginalised groups. Ironically, while these filters are designed to protect against inappropriate or harmful content, they sometimes fail to remove problematic material such as foul language, racism, and harmful stereotypes~\cite{birhane2021misogyny}. This inconsistent filtering reinforces disparities in representation and increases concerns about the long-tailed nature of the datasets.

The root causes of the long-tailed nature of data about socially marginalised groups are intimately intertwined with social, political, and economic histories. In other words, the systemic inclusion from, and misrepresentative nature of, datasets is not solely a product of technical failure. Rather, it is a manifestation of societal values contributing to choices made about whose cultures are preserved, and whose are erased.~\cite{bowker2000sorting,cheney2017we,brubaker2011select,benthall2019racial,benjamin2019race}. For example, the exclusion and flattening of unique cultures from the African continent in digital media can be traced back to colonial regimes that sought to erase and thereby dehumanise the people living on the continent~\cite{faloyin_africa_2022}. During colonial times, power structures meant that the historical record was kept by Europeans colonising the continent~\cite{bowker2000sorting}. In an attempt to justify their actions, there was a systemic flattening and dehumanisation of the lived experiences of those they sought to subjugate on the African continent. Colonial classification regimes flatten important cultural and geographic differences~\cite{das2022,prabhakaran2022cultural,das2021}. Borders were drawn without regard for existing complex social and ethnic groups, and the subsequent oppression and power dynamics involved in recording history lent themselves to a systematic erasure of distinct experiences~\cite{bowker2000sorting}. More recent depictions of Africa in the international media and popular culture have made little attempt to capture its deeply complex and rich landscape~\cite{faloyin_africa_2022}.   

Acknowledging the core reasons for this type of flattening, \textsc{WWD} explicitly seeks to counteract it through on-the-ground community consultation and collaboration. The granularity required to capture a region's knowledge is most likely best understood through extensive consultation with communities with lived experiences in those regions. For example, borders may not provide the best guide for demarcating cultural boundaries, and a representation of “Kenya” or “Nigeria” may not be granular enough when we consider the distinct cultural groups within these borders. Some borders may also be misleading: for example, the Semliki River has changed course numerous times in the past few decades, meaning that some cultural groups have found themselves flipping between national identities of Uganda and the Democratic Republic of Congo, depending on a naturally evolving geographical marker~\cite{faloyin_africa_2022}.


We present the African continent as an example to explain the deep-rooted causes of and potential for the type of cultural erasure that exists across the globe. \textsc{WWD} and the infrastructure developed therein seeks to counteract this erasure by encouraging data submissions from around the world in a granular manner, going beyond national representation but explicitly requesting fine-grained regional details. These details and nuances can be easily overlooked without community expertise. The individuals that we engaged are reached primarily through social networks. In the coming sections, we expand on this process and share insight into how submissions from different regions within a country were encouraged.