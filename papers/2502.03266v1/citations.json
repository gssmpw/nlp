[
  {
    "index": 0,
    "papers": [
      {
        "key": "xie2020best",
        "author": "Xie, Christopher and Xiang, Yu and Mousavian, Arsalan and Fox, Dieter",
        "title": "The best of both modes: Separately leveraging rgb and depth for unseen object instance segmentation"
      },
      {
        "key": "xie2021unseen",
        "author": "Xie, Christopher and Xiang, Yu and Mousavian, Arsalan and Fox, Dieter",
        "title": "Unseen object instance segmentation for robotic environments"
      }
    ]
  },
  {
    "index": 1,
    "papers": [
      {
        "key": "xiang2021learning",
        "author": "Xiang, Yu and Xie, Christopher and Mousavian, Arsalan and Fox, Dieter",
        "title": "Learning rgb-d feature embeddings for unseen object instance segmentation"
      }
    ]
  },
  {
    "index": 2,
    "papers": [
      {
        "key": "back2022unseen",
        "author": "Back, Seunghyeok and Lee, Joosoon and Kim, Taewon and Noh, Sangjun and Kang, Raeyoung and Bak, Seongho and Lee, Kyoobin",
        "title": "Unseen object amodal instance segmentation via hierarchical occlusion modeling"
      }
    ]
  },
  {
    "index": 3,
    "papers": [
      {
        "key": "zhang2023unseen",
        "author": "Zhang, Lu and Zhang, Siqi and Yang, Xu and Qiao, Hong and Liu, Zhiyong",
        "title": "Unseen object instance segmentation with fully test-time rgb-d embeddings adaptation"
      }
    ]
  },
  {
    "index": 4,
    "papers": [
      {
        "key": "9636281",
        "author": "Durner, Maximilian and Boerdijk, Wout and Sundermeyer, Martin and Friedl, Werner and M\u00e1rton, Zolt\u00e1n-Csaba and Triebel, Rudolph",
        "title": "Unknown Object Segmentation from Stereo Images"
      }
    ]
  },
  {
    "index": 5,
    "papers": [
      {
        "key": "xie2022rice",
        "author": "Xie, Chris and Mousavian, Arsalan and Xiang, Yu and Fox, Dieter",
        "title": "Rice: Refining instance masks in cluttered environments with graph neural networks"
      }
    ]
  },
  {
    "index": 6,
    "papers": [
      {
        "key": "zhang2023unseen",
        "author": "Zhang, Lu and Zhang, Siqi and Yang, Xu and Qiao, Hong and Liu, Zhiyong",
        "title": "Unseen object instance segmentation with fully test-time rgb-d embeddings adaptation"
      }
    ]
  },
  {
    "index": 7,
    "papers": [
      {
        "key": "lu2023self",
        "author": "Lu, Yangxiao and Khargonkar, Ninad and Xu, Zesheng and Averill, Charles and Palanisamy, Kamalesh and Hang, Kaiyu and Guo, Yunhui and Ruozzi, Nicholas and Xiang, Yu",
        "title": "Self-Supervised Unseen Object Instance Segmentation via Long-Term Robot Interaction"
      }
    ]
  },
  {
    "index": 8,
    "papers": [
      {
        "key": "yu2022self",
        "author": "Yu, Houjian and Choi, Changhyun",
        "title": "Self-supervised Interactive Object Segmentation Through a Singulation-and-Grasping Approach"
      }
    ]
  },
  {
    "index": 9,
    "papers": [
      {
        "key": "chen20233d",
        "author": "Chen, Jianqiu and Sun, Mingshan and Bao, Tianpeng and Zhao, Rui and Wu, Liwei and He, Zhenyu",
        "title": "3D Model-based Zero-Shot Pose Estimation Pipeline"
      },
      {
        "key": "nguyen2023cnos",
        "author": "Nguyen, Van Nguyen and Groueix, Thibault and Ponimatkin, Georgy and Lepetit, Vincent and Hodan, Tomas",
        "title": "CNOS: A Strong Baseline for CAD-based Novel Object Segmentation"
      }
    ]
  },
  {
    "index": 10,
    "papers": [
      {
        "key": "kirillov2023segment",
        "author": "Kirillov, Alexander and Mintun, Eric and Ravi, Nikhila and Mao, Hanzi and Rolland, Chloe and Gustafson, Laura and Xiao, Tete and Whitehead, Spencer and Berg, Alexander C and Lo, Wan-Yen and others",
        "title": "Segment anything"
      }
    ]
  },
  {
    "index": 11,
    "papers": [
      {
        "key": "kirillov2019panoptic",
        "author": "Kirillov, Alexander and He, Kaiming and Girshick, Ross and Rother, Carsten and Doll{\\'a}r, Piotr",
        "title": "Panoptic segmentation"
      }
    ]
  },
  {
    "index": 12,
    "papers": [
      {
        "key": "bolya2019yolact",
        "author": "Bolya, Daniel and Zhou, Chong and Xiao, Fanyi and Lee, Yong Jae",
        "title": "Yolact: Real-time instance segmentation"
      }
    ]
  },
  {
    "index": 13,
    "papers": [
      {
        "key": "long2015fully",
        "author": "Long, Jonathan and Shelhamer, Evan and Darrell, Trevor",
        "title": "Fully convolutional networks for semantic segmentation"
      }
    ]
  },
  {
    "index": 14,
    "papers": [
      {
        "key": "awais2023foundational",
        "author": "Awais, Muhammad and Naseer, Muzammal and Khan, Salman and Anwer, Rao Muhammad and Cholakkal, Hisham and Shah, Mubarak and Yang, Ming-Hsuan and Khan, Fahad Shahbaz",
        "title": "Foundational models defining a new era in vision: A survey and outlook"
      }
    ]
  },
  {
    "index": 15,
    "papers": [
      {
        "key": "kirillov2023segment",
        "author": "Kirillov, Alexander and Mintun, Eric and Ravi, Nikhila and Mao, Hanzi and Rolland, Chloe and Gustafson, Laura and Xiao, Tete and Whitehead, Spencer and Berg, Alexander C and Lo, Wan-Yen and others",
        "title": "Segment anything"
      }
    ]
  },
  {
    "index": 16,
    "papers": [
      {
        "key": "he2023accuracy",
        "author": "He, Sheng and Bao, Rina and Li, Jingpeng and Grant, P Ellen and Ou, Yangming",
        "title": "Accuracy of segment-anything model (sam) in medical image segmentation tasks"
      }
    ]
  },
  {
    "index": 17,
    "papers": [
      {
        "key": "cheng2023segment",
        "author": "Cheng, Yangming and Li, Liulei and Xu, Yuanyou and Li, Xiaodi and Yang, Zongxin and Wang, Wenguan and Yang, Yi",
        "title": "Segment and track anything"
      }
    ]
  },
  {
    "index": 18,
    "papers": [
      {
        "key": "yu2023inpaint",
        "author": "Yu, Tao and Feng, Runseng and Feng, Ruoyu and Liu, Jinming and Jin, Xin and Zeng, Wenjun and Chen, Zhibo",
        "title": "Inpaint Anything: Segment Anything Meets Image Inpainting"
      }
    ]
  },
  {
    "index": 19,
    "papers": [
      {
        "key": "cui2023all",
        "author": "Cui, Can and Deng, Ruining and Liu, Quan and Yao, Tianyuan and Bao, Shunxing and Remedios, Lucas W and Tang, Yucheng and Huo, Yuankai",
        "title": "All-in-sam: from weak annotation to pixel-wise nuclei segmentation with prompt-based finetuning"
      },
      {
        "key": "zhang2023uvosam",
        "author": "Zhang, Zhenghao and Wei, Zhichao and Zhang, Shengfan and Dai, Zuozhuo and Zhu, Siyu",
        "title": "UVOSAM: A Mask-free Paradigm for Unsupervised Video Object Segmentation via Segment Anything Model"
      }
    ]
  },
  {
    "index": 20,
    "papers": [
      {
        "key": "vaswani2017attention",
        "author": "Vaswani, Ashish and Shazeer, Noam and Parmar, Niki and Uszkoreit, Jakob and Jones, Llion and Gomez, Aidan N and Kaiser, {\\L}ukasz and Polosukhin, Illia",
        "title": "Attention is all you need"
      }
    ]
  },
  {
    "index": 21,
    "papers": [
      {
        "key": "dosovitskiy2020image",
        "author": "Dosovitskiy, Alexey and Beyer, Lucas and Kolesnikov, Alexander and Weissenborn, Dirk and Zhai, Xiaohua and Unterthiner, Thomas and Dehghani, Mostafa and Minderer, Matthias and Heigold, Georg and Gelly, Sylvain and others",
        "title": "An image is worth 16x16 words: Transformers for image recognition at scale"
      }
    ]
  },
  {
    "index": 22,
    "papers": [
      {
        "key": "zhang2023cross",
        "author": "Zhang, Ying and Yin, Maoliang and Wang, Heyong and Hua, Changchun",
        "title": "Cross-Level Multi-Modal Features Learning with Transformer for RGB-D Object Recognition"
      }
    ]
  },
  {
    "index": 23,
    "papers": [
      {
        "key": "chen2021mocov3",
        "author": "Xinlei Chen and Saining Xie and Kaiming He",
        "title": "An Empirical Study of Training Self-Supervised Vision Transformers"
      }
    ]
  },
  {
    "index": 24,
    "papers": [
      {
        "key": "caron2021emerging",
        "author": "Caron, Mathilde and Touvron, Hugo and Misra, Ishan and J{\\'e}gou, Herv{\\'e} and Mairal, Julien and Bojanowski, Piotr and Joulin, Armand",
        "title": "Emerging properties in self-supervised vision transformers"
      }
    ]
  },
  {
    "index": 25,
    "papers": [
      {
        "key": "li2021mst",
        "author": "Li, Zhaowen and Chen, Zhiyang and Yang, Fan and Li, Wei and Zhu, Yousong and Zhao, Chaoyang and Deng, Rui and Wu, Liwei and Zhao, Rui and Tang, Ming and others",
        "title": "Mst: Masked self-supervised transformer for visual representation"
      }
    ]
  },
  {
    "index": 26,
    "papers": [
      {
        "key": "devlin2018bert",
        "author": "Devlin, Jacob and Chang, Ming-Wei and Lee, Kenton and Toutanova, Kristina",
        "title": "Bert: Pre-training of deep bidirectional transformers for language understanding"
      }
    ]
  },
  {
    "index": 27,
    "papers": [
      {
        "key": "bao2021beit",
        "author": "Bao, Hangbo and Dong, Li and Piao, Songhao and Wei, Furu",
        "title": "Beit: Bert pre-training of image transformers"
      }
    ]
  },
  {
    "index": 28,
    "papers": [
      {
        "key": "he2022masked",
        "author": "He, Kaiming and Chen, Xinlei and Xie, Saining and Li, Yanghao and Doll{\\'a}r, Piotr and Girshick, Ross",
        "title": "Masked autoencoders are scalable vision learners"
      }
    ]
  },
  {
    "index": 29,
    "papers": [
      {
        "key": "amir2021deep",
        "author": "Amir, Shir and Gandelsman, Yossi and Bagon, Shai and Dekel, Tali",
        "title": "Deep vit features as dense visual descriptors"
      },
      {
        "key": "caron2021emerging",
        "author": "Caron, Mathilde and Touvron, Hugo and Misra, Ishan and J{\\'e}gou, Herv{\\'e} and Mairal, Julien and Bojanowski, Piotr and Joulin, Armand",
        "title": "Emerging properties in self-supervised vision transformers"
      },
      {
        "key": "oquab2023dinov2",
        "author": "Oquab, Maxime and Darcet, Timoth{\\'e}e and Moutakanni, Th{\\'e}o and Vo, Huy and Szafraniec, Marc and Khalidov, Vasil and Fernandez, Pierre and Haziza, Daniel and Massa, Francisco and El-Nouby, Alaaeldin and others",
        "title": "Dinov2: Learning robust visual features without supervision"
      }
    ]
  },
  {
    "index": 30,
    "papers": [
      {
        "key": "kirillov2023segment",
        "author": "Kirillov, Alexander and Mintun, Eric and Ravi, Nikhila and Mao, Hanzi and Rolland, Chloe and Gustafson, Laura and Xiao, Tete and Whitehead, Spencer and Berg, Alexander C and Lo, Wan-Yen and others",
        "title": "Segment anything"
      }
    ]
  },
  {
    "index": 31,
    "papers": [
      {
        "key": "oquab2023dinov2",
        "author": "Oquab, Maxime and Darcet, Timoth{\\'e}e and Moutakanni, Th{\\'e}o and Vo, Huy and Szafraniec, Marc and Khalidov, Vasil and Fernandez, Pierre and Haziza, Daniel and Massa, Francisco and El-Nouby, Alaaeldin and others",
        "title": "Dinov2: Learning robust visual features without supervision"
      }
    ]
  }
]