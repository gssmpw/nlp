\section{Conclusion}
\label{sec:conclusion}


In this paper, we investigate the visual vulnerabilities in jailbreak attacks on MLLMs. Our findings show that the complexity of visual inputs significantly influences attack success. We introduce the Distraction Hypothesis and propose the CS-DJ framework, which leverages distraction-based strategies to exploit these vulnerabilities in MLLMs. Our approach integrates this insight by two core components: structured distraction through query decomposition and visual-enhanced distraction using contrasting subimages. Extensive experiments conducted on five representative scenarios and four popular closed-source MLLMs demonstrated that CS-DJ outperforms state-of-the-art jailbreak methods, validating the efficacy of distraction-based approaches in bypassing MLLM defenses.





