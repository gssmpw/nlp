\section{Experiment}

\label{sec:experiment}

\input{Tables/table_sota}

In this section, we first introduced our experimental settings which include datasets and evaluation metrics. Then, we carried out quantitative and qualitative comparisons between our method and state-of-the-art MLLM jailbreaking approaches. Additionally, ablation studies are performed to validate the distraction effect on MLLM jailbreaking from various perspectives.

\subsection{Experiment Setup}

\noindent \textbf{Dataset.} The datasets are primarily utilized to provide or construct visual inputs tailored to the requirements of different methods. For evaluating Hades, we followed the experimental setting outlined in its original paper, utilizing the Hades dataset~\cite{li2024images} to supply the visual inputs. This dataset comprises five representative categories related to real-world visual information: (1) \textit{Violence}, (2) \textit{Financial}, (3) \textit{Privacy}, (4) \textit{Self-Harm}, and (5) \textit{Animal}. Each category contains 150 queries, resulting in a total of 750 harmful queries. For evaluating CS-DJ, we employed LLaVA-CC3M-Pretrain595K~\footnote{\url{https://huggingface.co/datasets/liuhaotian/LLaVA-CC3M-Pretrain-595K}} to retrieve the contrasting images. To improve retrieval efficiency, we randomly selected a subset of 10,000 images for the retrieval dataset, using a different random seed for each experiment to ensure diversity. All harmful queries used throughout the experiments were derived from the Hades dataset. 



\noindent \textbf{Victim Models.} In our main experiments, We evaluated the performance of the four most popular closed-source MLLMs: GPT-4o-Mini, GPT-4o, GPT-4V~\cite{achiam2023gpt}, and Gemini-1.5-Flash~\cite{team2024gemini}. 
The specific versions are as follows: GPT-4o: GPT-4o-2024-08-06, GPT-4o-Mini: GPT-4o-Mini-2024-07-18, GPT-4V: GPT-4-1106-vision-preview, and Gemini-1.5-flash: Gemini-1.5-flash-001~\footnote{Since Gemini-1.0-Pro-Vision has been deprecated on July 12, 2024, we used its upgraded version, Gemini-1.5-Flash.}. 


\noindent \textbf{Evaluation Metrics.} To assess the effectiveness of our proposed CS-DJ framework, we employ two primary evaluation metrics: \textbf{Attack Success Rate (ASR)} and \textbf{Ensemble Attack Success Rate (EASR)}.
\textbf{ASR} quantifies the proportion of successful jailbreak attempts by determining whether the model’s response meets predefined conditions for harmful content. This determination is guided by a security discriminator that classifies responses as harmful or benign based on specific criteria. We utilize Beaver-Dam-7b~\cite{ji2024beavertails}, trained on high-quality human feedback data, as the security discriminator, leveraging its ability to detect both the harmfulness and helpfulness of responses to their corresponding queries. This ensures a robust and consistent evaluation of attack success across various scenarios.
\textbf{EASR}~\cite{yu2024llm} evaluates the effectiveness of a set of jailbreak templates by measuring the proportion of queries for which at least one template within the subset successfully bypasses the target MLLM’s defenses. While ASR focuses on the success rate of an individual template, EASR provides a broader assessment by considering the combined success of a group of templates, offering deeper insights into the MLLM’s susceptibility to jailbreak attempts.


\subsection{Main Experiment}


To assess the effectiveness of CS-DJ, we conducted a comparison between CS-DJ and Hades~\cite{li2024images}, the state-of-the-art closed-source MLLM jailbreak attack. For a fair comparison, we adopted the official implementation of Hades and performed 6 groups of experiments to collect data.


Table~\ref{tab:sota} presents the jailbreak ASR and EASR results of CS-DJ and Hades across the four widely used closed-source MLLMs. The results across the five categories indicate that the four closed-source MLLMs exhibit stronger defenses against harmful queries in the Animal and Self-Harm categories while showing greater vulnerability in the Financial, Privacy, and Violence categories. Compared to their ASR results, Hades and CS-DJ achieve average improvements of 10.22\% and 21.70\% in EASR, respectively, indicating that increasing the number of trials can enhance the jailbreak success rate. Additionally, for both ASR and EASR, CS-DJ consistently outperforms Hades across all five categories for each evaluated MLLM. Overall, compared to Hades, CS-DJ achieves maximum improvements of 54.91\% in ASR and 66.67\% in EASR. Furthermore, CS-DJ attains average success rates of 52.40\% for ASR and 74.10\% for EASR.  These observations highlight CS-DJ’s superior effectiveness as a jailbreak method for bypassing the defenses of closed-source MLLMs. Jailbreaking examples can be found in the appendix.

A detailed analysis of Hades’ results across the four models reveals that GPT-4V outperforms the other three models in both ASR and EASR. In contrast, the results of CS-DJ indicate that Gemini-1.5-Flash achieved the highest performance. These findings suggest that the impact of visual input harmfulness and distraction varies across different models. In a word, the results demonstrate that distracting the model’s attention is a more effective strategy for enhancing jailbreak success rates.

For the subsequent experiments, we selected the most widely used model, GPT-4o, for testing. All experiments were conducted as a single trial. Therefore, only ASR results are presented in the following sections.



\subsection{Impact of Query Decomposition}

\input{Tables/table_qd}

Here, we aim to explore the \textbf{impact of query decomposition} on MLLM jailbreak performance. To validate its effectiveness, we first use images derived from raw queries (RQ) as visual inputs for MLLMs, serving as a baseline for comparison with the results obtained using query decomposition. We further examine the effect of the number of sub-queries on the jailbreak success rate by decomposing the raw query into 3, 6, and 9 sub-queries, denoted as 3SQ, 6SQ, and 9SQ, respectively. Given that MLLMs typically resize image inputs to fixed dimensions, we aim to minimize distortion from aspect ratio changes during resizing and avoid potential limitations of the MLLM’s image encoder. Therefore, we maintain a fixed column count of 3 when composing the final input image. As a result, the 3SQ, 6SQ, and 9SQ settings increase the number of rows while keeping the number of columns constant.

The quantitative results are presented in Table~\ref{tab:qd}. The results from RQ demonstrate that the MLLM exhibits strong defenses against original jailbreak queries. Even when the raw query is transformed into an image input, it remains highly challenging to bypass the MLLM’s security mechanisms. In contrast, 3SQ outperforms RQ across all five categories, yielding an overall improvement of 15.60\%. This indicates that query decomposition effectively enhances the jailbreak success rate for MLLMs. By introducing a distributional shift in the queries, query decomposition creates structural distraction, thereby enabling more effective bypassing of the model’s defenses.
Furthermore, increasing the number of decomposed sub-queries to 6 results in an additional 11.06\% improvement in the jailbreak success rate. This suggests that a higher number of sub-images transformed from sub-queries can further enhance the distraction effect on the MLLM. However, when the number of sub-queries is increased to 9, a slight decline in the success rate is observed. This decrease may be attributed to two factors: (1) the increased number of sub-queries raises task complexity, resulting in greater demands on the model’s comprehension and its ability to handle complex tasks; (2) limitations in the model’s image encoding capabilities may prevent accurate interpretation of the sub-queries; and (3) over-decomposition may cause the model to recognize the original intent of the query, thereby reducing the effectiveness of the jailbreak attempt.

Overall, the structural distraction introduced by query decomposition can enhance the jailbreak success rate of MLLMs. Furthermore, the number of sub-queries also plays a significant role in influencing the results. Given the limited capabilities of smaller MLLMs and the need to incorporate additional visual subimages, this work focuses on evaluating the performance of the CS-DJ with three sub-queries.


\subsection{Impact of Contrasting Visuals}
\label{subsec:diversitymatters}
\input{Figures/figure_distraction}



To validate the effectiveness of contrasting visuals, we conduct experiments from two perspectives: (1) the impact of distraction induced by varying the number of subimages, and (2) the effect of inter-subimage distraction with a fixed number of subimages. Since altering the number of subimages directly affects the layout of the final composite image, we maintain a fixed column count of 3 and adjust the number of rows to control the number of subimages. This strategy reduces distortion due to excessive changes in aspect ratio and mitigates potential limitations in the MLLM’s image encoding capabilities.
We conduct different experiments with various configurations, involving 0, 3, 6, 9, and 12 \textbf{\mbox{C}}ontrasting visual \textbf{\mbox{S}}ub\textbf{\mbox{I}}mages, corresponding to 3SQ, 3SQ+3CSI, 3SQ+6CSI, 3SQ+9CSI, and 3SQ+12CSI, respectively. Furthermore, to explore the influence of inter-subimage distraction on jailbreak success rates, we conduct experiments using three settings: retrieving 9 most contrasting images, retrieving 9 most similar images, and using a single, most similar image from the dataset for all 9 subimages, denoting 3SQ+9CSI, 3SQ+9SSI, and 3SQ+9SinSI, respectively.

The experimental results on the \textbf{impact of visual subimage quantity} are illustrated in Figure~\ref{fig:cv}. As 3SQ does not contain any visual subimages, its Distraction Distance is 0, resulting in the lowest ASR. Increasing the number of visual subimages leads to a rise in ASR. Specifically, compared to 3SQ, 3SQ+3CSI obtains a 12.8\% increase in ASR, demonstrating that contrasting visual subimages can effectively distract the MLLM and bypass its internal defense mechanisms. As the number of visual subimages increases, both the Distraction Distance and the ASR grow correspondingly. However, the rate of ASR improvement diminishes as the number of subimages continues to rise. When the number of subimages reaches 9, further additions yield limited gains in ASR. Given the limited encoding capabilities of the visual encoders in smaller MLLMs, we use 9 visual subimages as the default setting for our experiments.

Table~\ref{tab:cv} presents the experimental results on the \textbf{impact of inter-subimage distraction}. We evaluate three different subimage selection strategies. The results show that 3SQ+9SinSI has the lowest distraction distance, corresponding to the lowest ASR. In contrast, 3SQ+9CSI achieves an 11.20\% improvement in ASR compared to 3SQ+9SSI, along with a further increase in distraction distance. These findings indicate that, for a fixed number of subimages, greater distraction among subimages leads to a higher jailbreak success rate for MLLMs. Additionally, an analysis of the results from Figure~\ref{fig:cv} and Table~\ref{tab:cv} reveals that distraction distance accurately reflects changes in ASR trends only when varying the subimage construction strategy along a single dimension, such as the number of subimages or subimage selection strategies. This limitation may stem from differences between the semantic space of our current feature extractor, CLIP, and that of the MLLM. As a result, inter-subimage distraction distance cannot always be accurately measured using the CLIP model. Future work will focus on developing a more comprehensive metric for measuring distraction distance.

Table~\ref{tab:random} shows the \textbf{impact of information complexity} of visual subimages. The ASR of 3SQ+9RNI is close to that of 3SQ, but significantly lower than 3SQ+9CSI, indicating that MLLMs exhibit strong recognition capabilities for noise images with minimal informational content. Therefore, only subimages with higher information complexity can effectively distract the model.

In summary, constructing multiple contrasting visual subimages effectively enhances the distraction of MLLMs, leading to improved jailbreak success rates.


\input{Tables/table_cv}
\input{Tables/table_5}


\subsection{Impact of Instruction}

\input{Tables/table_prompt}

To complement the constructed multi-subimage input, we carefully designed the instruction $P$. To evaluate the \textbf{impact of different components of $P$}, we conducted three experiments: (1) using only the task-guiding component, (2) adding the role-guiding component, and (3) further incorporating the visual-guiding component. The results, presented in Table~\ref{tab:prompt}, show that using only the task-guiding component achieved the lowest ASR but still outperformed Hades by 26.49\%. This indicates that the visual distraction from the multi-subimage input, combined with the task distraction of handling multiple tasks simultaneously, significantly contributes to improving jailbreak success rates. Adding the role-guiding component further increased the ASR by 7.73\%, while incorporating the visual-guiding component led to an additional 4.00\% improvement. These findings demonstrate that targeted optimization of $P$ for multi-subimage visual inputs can further disperse the model’s attention, enhancing the success rate of the jailbreak.


