\section{Experiments}
\label{sec:experiments}
In our experiments, we assess the following aspects:
\begin{enumerate*}[label=(\roman*)]
\item\label{experiment1} A benchmark comparison of GP-UPT to related models.
\item \label{experiment2} Scalability to large surface meshes by comparing drag and lift coefficients on high-fidelity data for design optimization applications.
\item \label{experiment3} Scalability to large volume meshes to understand design implications on the surrounding flow field.
\item \label{experiment4} Transfer learning from low- to high-fidelity datasets.
\end{enumerate*} 
With experiments~\ref{experiment2} and~\ref{experiment3} we showcase breakthroughs regarding challenge~\ref{challenge1} (scalability), and with experiment~\ref{experiment4} regarding challenge~\ref{challenge2} (data scarcity).

\subsection{Benchmarking against other models~\ref{experiment1}}
\label{sec:experiments-benchmark}
We benchmark \ac{GP-UPT} with a \ac{GNN} baseline model (RegDGCNN~\citep{wang2019dynamic,elrefaie2024drivaernet}), a point-wise model (PointNet~\citep{qi2017pointnet}), a neural operator with a regularly structured latent space (\ac{GINO}~\citep{Li:23}), the original \ac{UPT}~\cite{alkin2024universal}, and the current state-of-the-art transformer-based neural operator (Transolver~\citep{wu2024transolver}). 
To make it comparable, we set the number of encoder/decoder blocks and hidden dimensionality $d_{hidden}$ to match the transformer-based baselines (Transolver and \ac{UPT}).
Note that all models, except \ac{GINO} and \ac{UPT}, directly map input to output points (i.e., point-based),
and do not fulfill requirements \ref{req1} and \ref{req2} (see discussion in Section~\ref{sec:methodology}).
The original \ac{UPT} formulation already uses a field-based decoder and a reduced latent space modeling. 
However, without geometry-preserving encoding, it is hard to extract a compressed geometry representation. 
Furthermore, the decoding is not guided towards the 2D manifold, i.e., the car shape, but rather tries to reconstruct a 3D field. 
For an extensive overview of the experimental setup, including model and optimization details, we refer to Appendix~\ref{appendix:experimental}.
In addition to the quantitative performance evaluation below, we also provide complementary details on the inference characteristics of the respective models in Appendix~\ref{appendix:model_inference_characteristics}.
\input{tables/model_baselines}
\paragraph{ShapeNet Car}
ShapeNet Car~\cite{chang2015shapenet} is the standard dataset for validating neural PDE surrogates on general geometries.
However, compared to the DrivAerML dataset, the surface meshes of ShapeNet Car contain only 3682 mesh points,
and thus are, e.g., 3 orders of magnitude smaller than those of DrivAerML. 
We used ShapeNet Car to test and tune the baseline models. 
Our reported numbers are comparable with, and often better than the results of the respective papers. 
Due to the small surface meshes, all points are input to the models.
Based on Table~\ref{table:baseline-models}, we conclude that:
\begin{enumerate*}[label=(\arabic*)]
    \item \ac{GP-UPT} outperforms all other baseline models for all reported metrics.
    \item Inline with the findings in~\citet{wu2024transolver}, Transolver outperforms all other baselines.
\end{enumerate*} \\

\paragraph{DrivAerML} DrivAerML contains simulations that are run with \ac{HRLES}, i.e., the currently highest-fidelity \ac{CFD} routine in the automotive industry, resulting in surface meshes of 8.8 million mesh cells and volumetric meshes of 160 million mesh cells.
For each data point, we randomly sample 40,000 points from the total surface mesh as input to the models, for both training and evaluation (with a fixed sampling during evaluation). 
In Table~\ref{table:baseline-models}, we summarize our findings.
We conclude that: 
\begin{enumerate*}[label=(\arabic*)]
    \item Point-based \ac{GP-UPT} and Transolver outperform all other models by a margin on all reported metrics, where Transolver performs slightly better than \ac{GP-UPT}.
    \item When comparing point-based and field-based decodings of \ac{GP-UPT},
    the flexibility of querying the surface at any arbitrary location (i.e., using a field-based decoder like \ac{GP-UPT}) comes at the cost of a regression in the evaluation metrics, compared to the performance of a point-based decoder.
    However, the improved model properties, will be of use for the following experiments as we will see.
\end{enumerate*}


\paragraph{Model discussion}
Based on the benchmark above, we conclude that:
\begin{enumerate*}[label=(\arabic*)]
    \item transolver and \ac{GP-UPT} are the most accurate models for prediction surface quantities and,
    \item \ac{GINO}, \ac{GP-UPT}, and \ac{UPT} are the only field-based models.
\end{enumerate*}
We will see in Section~\ref{sec:experiments-surface} and \ref{sec:experiments-volume}, that,
when scaling to large surface and volume meshes, all three model requirements of Section~\ref{sec:methodology} need to be fulfilled.
Especially, the decoupling of encoder and decoder is of importance, since it allows for efficient field-based modeling, where field predictions are obtained by querying a cached latent encoder representation. 
Recall that for \ac{GP-UPT} the input point cloud to the geometry encoder for producing this latent representation can be different to the one used for querying predictions (cf. Figure~\ref{fig:gp-upt-architecture}). 
This enables us to train models that accept uniformly sampled point clouds from the \ac{CAD} surface to represent the geometry (e.g., STL surface), while on the other hand can be queried on arbitrary meshes and mesh resolutions for down-stream tasks such as drag estimation.
Intuitively, this can be understood in Figure~\ref{fig:drag_and_lift}, where the quality of the drag coefficient prediction depends on the number of model output predictions, i.e., denser field predictions yield better modeling -- notably done for the same input representation. 

\paragraph{CAD model} In a complementary experiment in Appendix~\ref{appendix:cad_mesh_fine_tuning}
we show how to fine-tune a \ac{GP-UPT} model to work with input point clouds sampled directly from a \ac{CAD} geometry.
This is not only beneficial for practical applicability (no \ac{CFD} mesh is required), but also for model accuracy.

\subsection{Scalability to large surface meshes \ref{experiment2}}
\label{sec:experiments-surface}
\begin{figure}[t!]
\centering
\begin{tabular}{ m{0.3\linewidth} m{0.3\linewidth} m{0.3\linewidth}}
~\parbox[c]{\linewidth}{\centering  GPU-UPT}~&
~\parbox[c]{\linewidth}{\centering  CFD simulation}~&
~\parbox[c]{\linewidth}{\centering  Difference}~\\
\multicolumn{3}{c}{\includegraphics[width=\linewidth ,trim={0cm 0cm 0cm 0cm},clip]{figures/surface_prediction/surface_drivaerml5.png}} \\
 \end{tabular}
 \caption{GP-UPT prediction of the surface quantities pressure [Pa] and wall shear stress [Pa] for the {DrivAerML} dataset.}
\label{fig:surface_pressure_and_wss}
\end{figure}
Accurate and fast predictions of global quantities, such as drag and lift coefficient, are crucial for designing efficient aerodynamic geometries.
We evaluate the quality of the surface-level predictions of our model required for computing such integrated aerodynamic quantities.
To that end, we retrain a \ac{GP-UPT} model to now predict both, surface pressure as well as \ac{WSS} stress on DrivAerML.
Figure~\ref{fig:surface_pressure_and_wss} shows the two quantities including prediction errors
for an unseen geometry.
Experiments are as in the previous section carried out on the DrivAerML dataset and summarized in Figure~\ref{fig:drag_and_lift}.
The two measured predicted plots compare both, drag and lift, once computed from the ground truth simulations and once from the surrogate model predictions.
For both cases, an $R2$ correlation close to $0.97$ is achieved.

In Section~\ref{sec:methodology}, we emphasize the importance of geometry encoder and field-based decoder decoupling (i.e., requirement~\ref{req2}).
This design choice enables the model to perceive a geometry with a relatively small point cloud (e.g., 40,000 points), and
infer surface quantities for meshes with arbitrary spatial resolutions (e.g., 8.8 million cells).
Note that this allows practitioners to bypass the expensive \ac{CFD} meshing stage ($\approx1h$~\cite{ashton2024drivaerml}) substantially reducing the time to receive feedback on the aerodynamics of a novel design (see Appendix~\ref{appendix:cad_mesh_fine_tuning} for more details).
To emphasize the benefits of this property, we iteratively mesh the \ac{CAD} geometry to an increasing number of surface mesh cells. Note that this surface meshing takes only a few seconds. 
We then predict for each iteration, the surface quantities for the respective cells
and compute the associated drag.
Figure~\ref{fig:drag_and_lift} shows the $R2$ correlation between ground truth and model predictions
with respect to an increasing number of mesh cells (see visualizations in Appendix~\ref{appendix:mesh_resolutions}).
The plot suggests that the cheaper re-meshing approaches the same coefficient estimation quality as the original \ac{CFD} simulation mesh when a sufficient number of cells is reached. 

\begin{figure}[t!]
     \centering
     \begin{subfigure}[b]{0.23\textwidth}
         \centering
         \includegraphics[height=0.89\textwidth]{figures/cd.pdf}
         \label{fig:drag_and_lift_drag}
     \end{subfigure}
     \hfill
     \begin{subfigure}[b]{0.23\textwidth}
         \centering
         \includegraphics[height=0.89\textwidth]{figures/cl.pdf}
         \label{fig:drag_and_lift_lift}
     \end{subfigure}
     \hfill
     \begin{subfigure}[b]{0.49\textwidth}
         \centering
         \includegraphics[width=0.95\textwidth]{figures/r2.pdf}
         \label{fig:drag_and_lift_ablation}
     \end{subfigure}
        \caption{
        Top: Measures-predicted plots for drag and lift. 
        Bottom: Drag prediction accuracy with respect to surface cell count.
        The red line marks the upper limit when quantities are computed on the original \ac{CFD} mesh. In blue a comparison to a triangular mesh created from the CAD geometry at different levels of detail.}
        \label{fig:drag_and_lift}
\end{figure}

\subsection{Scalability to large volume meshes \ref{experiment3}}
\label{sec:experiments-volume}
Next, we demonstrate the ability of \ac{GP-UPT} to infer volume-level predictions of up to 20 million cells given a surface manifold as input.
Note that, due to the disentangled geometry encoder and query-based decoder (i.e., requirement~\ref{req2}),
\ac{GP-UPT} is per-design capable of operating in this regime without requiring any modifications (cf.~Figure~\ref{fig:fig1}).
For comparison, we use GINO, which shares the same input-output properties as \ac{GP-UPT} also fulfilling requirement~\ref{req2}.
Experiments are carried out on the AhmedML~\cite{ashton2024ahmed} dataset comprising 500 hybrid RANS-LES numerical \ac{CFD} simulations on car-like shapes split into 400 train, 50 validation and 50 test samples.
The Ahmed Body is used in \ac{CFD} as a benchmark model for studying aerodynamics, enabling analysis of flow behavior, validating methods, and ensuring comparability in research due to its standardized, simplified geometry.
Hence, models are now trained to predict the total pressure coefficient $C_{pt}$ in the surrounding volume of the body.
\input{tables/ahmed_table}
Table~\ref{tab:ahmedml} summarizes the performance of the two models.
For a qualitative evaluation, we visualize the ground truth and the \ac{GP-UPT} predicted $C_{pt}$
for a horizontal and vertical cut plane through the flow field in Figure~\ref{fig:ahmedml_visualizations}.
We observe that overall pressure patterns are predicted accurately, but high-frequency components still have room for improvement.
\begin{figure}[t!]
     \centering
     \begin{subfigure}[b]{0.3\textwidth}
         \centering
         \includegraphics[width=\textwidth,trim={0 1.2cm 1.4cm 1.7cm},clip]{figures/ahmed_3d/pred_cut.png}
         \label{fig:ahmedml_visualizations_cut_plane_upt}
     \end{subfigure}
     \begin{subfigure}[b]{0.3\textwidth}
         \centering
         \includegraphics[width=\textwidth,trim={0 2.5cm 0 1.0cm},clip]{figures/ahmed_3d/pred_iso.png}
         \label{fig:ahmedml_iso_surface_upt}
     \end{subfigure}
        \caption{GP-UPT total pressure coefficient $C_{pt}$ predictions on 20M volumentric mesh cells.
        \textit{Top}: horizontal and vertical cut plane. \textit{Bottom}: $C_{pt}=0.9$ iso-surface.
        Ground truth visualizations are in the appendix, but visually indistinguishable from predictions.}
        \label{fig:ahmedml_visualizations}
\end{figure}
Figure~\ref{fig:ahmedml_iso_surface_upt} and \ref{fig:ahmedml_iso_surface_cfd} show the $C_{pt}=0.9$ iso-surface within the entire flow field.
Recalling that \ac{GP-UPT} only takes surface points as input, it is worth noting that it still maintains accurate predictions in the volume even in flow field regions far apart from the actual geometry.
Finally, we analyze the inference characteristics of both models.
Figure~\ref{fig:model_profiling} shows how latency and memory consumption depend on an increasing number of query points
(e.g., the number of output quantities predicted by the field decoders of the models).
Note that the number of 8000 input points encoding the geometry remains constant explaining the offset on both y-axes.
The field-based decoders then exhibit a linear dependency on the number of query points.
\begin{figure}[t!]
     \centering
     \begin{subfigure}[b]{0.23\textwidth}
         \centering
         \includegraphics[height=0.15\textheight]{figures/gino_vs_upt_mem.pdf}
         \label{fig:model_profiling_memory}
     \end{subfigure}
     \hfill
     \begin{subfigure}[b]{0.23\textwidth}
         \centering
         \includegraphics[height=0.15\textheight]{figures/gino_vs_upt_time.pdf}
         \label{fig:model_profiling_latency}
     \end{subfigure}
         \caption{Inference characteristics for GP-UPT and GINO for AhmedML of forward passes using 8000 geometry input points and a variable number of query points. Here a single batch of query points (up to 300k for Gino and 1M for GP-UPT) is investigated.}
         \label{fig:model_profiling}
\end{figure}


\subsection{Transfer learning between fidelity levels~\ref{experiment4}}
\label{sec:experiments-transfer}
Transfer learning is a strong candidate to boost model performance on high-fidelity datasets, which usually contain only a limited number of samples \footnote{Note that this experiment does not require encoder decoder decoupling and can be done with other models too. However, only the combination, i.e., applying transfer-learning to field-based models, offers feasible solutions to predictions on large meshes with a limited number of high-resolution training data.}.
In this experiment, we show the feasibility of transfer learning a \ac{GP-UPT} surface pressure model between two datasets produced with different turbulence models.
This has already been pioneered as a promising direction by~\citet{elrefaie2024drivaernet}.
First, we pre-train a model on DrivAerNet \cite{elrefaie2024drivaernet} containing 4000 samples with surface pressure values derived from \ac{RANS} aerodynamic simulations.
As a fine-tuning dataset, we again utilize DrivAerML \cite{ashton2024drivaerml} which employs a high-fidelity HRLES turbulence model.
While these simulations are more accurate in modeling aerodynamics, they are also orders of magnitude more expensive to obtain.
For pre-training we apply simple data augmentation
such as translation ($\pm 20\%$) and aspect ratio-preserving resizing ($\pm 10\%$) to make the model robust against such perturbations.
Next, we fine-tune this model on different subsets of DrivAerML.
To measure the impact of pre-training, we also train five modes from scratch on the same fractions of DrivAerML. 
Results in Figure \ref{fig:transfer-learning-data-ablation} confirm that transfer learning between datasets and simulation fidelity is feasible.
\begin{figure}[t!]
    \centering
    \includegraphics[width=0.85\linewidth]{figures/transfer_data_ablation_test_set.pdf}
    \caption{Transfer learning experiments from DrivAerNet to DrivAerML (y-axis: test MSE, blue: reduction of error when using transfer learning, red: relative performance of transfer learning compared to \emph{all data baseline} trained from scratch).
    }
    \label{fig:transfer-learning-data-ablation}
\end{figure}
The main observations are:
\begin{enumerate*}[label=(\arabic*)]
    \item Pre-training on DrivAerNet reduces the number of required DrivAerML samples by half, while still outperforming a model trained from scratch using the entire training set by $1\%$.
    \item Fine-tuning a pre-trained model on the entire DrivAerML dataset reduces the overall test error by $40\%$.
This also indicates that the DrivAerML dataset does not contain enough samples as needed to serve as a standalone data resource.
\end{enumerate*}
