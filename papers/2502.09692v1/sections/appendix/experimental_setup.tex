\section{Experimental setup}
\label{appendix:experimental}
\subsection{Benchmark datasets}
\paragraph{ShapeNet Car} The ShapeNet Car dataset is a subset of the ShapeNet dataset~\cite{chang2015shapenet}, as introduced by~\citet{umetani2018learning}, which contains all car-labeled data points. 
Each surface mesh in the dataset contains 3,682 points, and we use all points as input for our models.
Following~\cite{alkin2024universal}, we remove outlier points that do not belong to the surface mesh (which results in a total of 3,586 points per surface mesh).
As model input, we only consider the points on the surface mesh (i.e., without using additional \acl{SDF} values or surface normals), and the models are trained to predict pressure values on the surface mesh.
We adopt the same training and testing split as in~\citet{alkin2024universal}, which consists of 800 samples for training and 189 samples for testing. 

\paragraph{DrivAerML} The DrivAerML~\cite{ashton2024drivaerml} dataset is designed for machine learning for high-fidelity automotive aerodynamic simulation.
The dataset contains 500 parametrically morphed variants of DrivAer vehicles, aiming to address the challenge of the availability of open-source data for large-scale (in terms of the size of the simulation mesh) \acf{CFD} simulations in automotive aerodynamics.
DrivAerML runs the \ac{CFD} simulations on 160 million volumetric mesh grids with \acl{HRLES}~\cite{spalart2006new, chaouat2017state, heinz2020review, ashton2022hlpw}, which is the highest-fidelity \ac{CFD} approach used by the automotive industry \cite{hupertz2022towards,ashton2024drivaerml}.
Each mesh in the dataset contains approximately 8.8 million surface points, with pressure and wall shear stress values on the surface.
When computing the drag and lift coefficient with \ac{GP-UPT}, all 8.8 million points on the surface mesh are used.
Since the dataset does not provide a predefined split for training, validation, and testing, we randomly divide the data into 80\% for training and 10\% each for validation and testing.

\paragraph{DrivAerNet} DrivAerNet~\cite{elrefaie2024drivaernet, elrefaie2024drivaernet++} 
contains 4,000 car \ac{CFD} simulations (with DrivAernet++~\cite{elrefaie2024drivaernet++} offering an additional 4,000 samples).
DrivAerNet runs \ac{CFD} simulations on volumetric mesh grids ranging from 8 to 16 million cells, using low-fidelity \acl{RANS} methods~\cite{reynolds1895iv, alfonsi2009reynolds, ashton2015comparison}.
Each surface mesh contains roughly 350,000 surface points.
The DrivAernet is notably larger (in terms of number of CFD simulations) than other existing car aerodynamic datasets.
In this paper, we use the DrivAerNet dataset only in Section~\ref{sec:experiments-transfer}, as pretraining data for the low-fidelity to high-fidelity transfer learning. 
For the pre-training on DrivAerNet in Section~\ref{sec:experiments-transfer}, we subsample each surface mesh point cloud to 40,000 input points.

\paragraph{AhmedML} AhmedML \cite{ashton2024ahmed} is an open-source dataset that provides high-fidelity CFD simulation results for 500 geometric variations of the Ahmed car body, a widely studied bluff body in automotive aerodynamics. 
The dataset includes hybrid RANS-LES simulations performed using OpenFOAM, capturing essential flow physics such as pressure-induced separation and 3D vortical structures.
Each mesh in the dataset contains approximately 20 million cells, from which we use a subset of 10\% for training the total pressure coefficient. For evaluation and visualization, we use the full mesh containing 20 million cells.
Since the dataset does not provide a predefined split for training, validation, and testing, we divide the data into 80\% for training and 10\% each for validation and testing.


\subsection{Evaluation metrics}
\label{appendix:metrics}
For our experimental evaluations, we consider the following evaluation metrics.
All metrics are reported on unnormalized ground truth quantities (i.e., pressure or \acl{WSS}) for physics field $\bm{O}_{i}$ of the geometry $\cM_{i}$, and the predicted quantities $\hat{\bm{O}_{i}}$ containing $M$ query/surface/volumetric points.

\textbf{Mean squared error (MSE)} is computed as:
\begin{align}
    \mathbf{MSE} = \frac{1}{M} \sum_{j=1}^M (\bm{O}_{i}^{j} - \hat{\bm{O}}_{i}^{j})^2
\end{align}

\textbf{Mean absolute error (MAE)} is computed as:
\begin{align}
    \mathbf{MAE} = \frac{1}{M} \sum_{j=1}^M | \bm{O}_{i}^{j} - \hat{\bm{O}}_{i}^{j} |
\end{align}

\textbf{Relative L2 error (L2)} is computed as:
\begin{align}
    \mathbf{L2} = \frac{\left\lVert \bm{O}_{i} - \hat{\bm{O}}_{i} \right\Vert}{\left\lVert \bm{O}_{i} \right\Vert}
\end{align}

\textbf{R2 score} for drag and lift coefficients $C_\text{d}$ and $C_\text{l}$
(see Section~\ref{sec:introduction} for a formal definition of these coefficients) is computed given
the two sets of coefficients obtained once from \ac{CFD} ground truth simulations ($C^i$)
and once from the respective surrogate model ($\hat{C^i}$) as:
\begin{align}
    R2 = 1 - \frac{SS_\text{res}}{SS_\text{tot}} \;\; \text{with} \;\;  SS_\text{res} = \sum_i (C^i - \hat{C^i})^2 \;\; \text{and} \;\; SS_\text{tot} = \sum_i (C^i - \bar{C})^2
\end{align}

\subsection{Baseline models}
\paragraph{PointNet} PoitNet~\cite{qi2017pointnet} is a point-based baseline model that processes the input point cloud at both local and global level. 
Each point in the input point cloud is first mapped through a \ac{MLP} with channel sizes $64$, $64$, $128$, and $1024$, to obtain point features.
Next, a max-pooling operation is applied to these point features to obtain a global feature representation that captures the structure of the entire point cloud.
Then, each point feature vector is concatenated with the global feature vector to give global context to each point representation.
Finally, the combined representation is mapped through another \ac{MLP} (with channel sizes: $512$, $256$, $128$, $d_{out}$) to predict the output signal for each point on the input surface mesh.
Similar to~\cite{qi2017pointnet} we deploy a spatial tranformer network~\cite{jaderberg2015spatial} to align input points into a canonical space.

\paragraph{RegDGCNN} RegDGCCN~\cite{elrefaie2024drivaernet} is a modified version of \acf{DGCNN}~\cite{wang2019dynamic}, designed for regression tasks, that makes use of graph convolution layers.
RegDGCCN utilizes edge convolution layers, which first perform a \ac{KNN} search to construct the (local) graph structure, followed by a message passing layer to aggregate incoming edge features for each vertexes in the point cloud.
Since the \ac{KNN} search operates on the (latent) input representation of each point for every edge convolution layer, the graph structure is considered dynamic.
Due to training instabilities, we use a smaller model than in~\cite{elrefaie2024drivaernet, elrefaie2024drivaernet++}, which is in line with the original \ac{DGCNN} architecture~\cite{wang2019dynamic}. 
Specifically, following the original \ac{DGCNN} setup we use three edge convolution layers with hidden dimensionality $64$ and set $k=40$ for the nearest-neighbor search for our implementation. 
After the edge convolution layers, we use a four-layer MLP with channel sizes of $256$, $256$, $128$, and $d_{out}$, to predict the output signal for each point on the input mesh.

\paragraph{Transolver} Transolver~\cite{wu2024transolver} is a transformer-based baseline model and, at the time of writing, the state-of-the-art on ShapeNet Car.
It introduces the Physics-Attention mechanism, where each layer in the Transolver model takes a finite discrete point cloud representation of an input geometry as input, and maps each point to a learnable slice (also referred to as physics token).
Points with similar physical properties are mapped to the same slice.
First, each surface mesh point is mapped to slice weights, which indicate the degree to which each point belongs to a slice.
Next, the slice weights are used to aggregate point features into physics-aware tokens.
Multi-head self-attention is applied to these physics-aware tokens, rather than directly to the input points, which reduces the computational cost of the self-attention layer.
Finally, after the self-attention layer, the physics-aware tokens are transformed back to mesh input points by deslicing. 
Afterward, a feed-forward layer is applied on the individual input point representations. 
For our implementation, we use a version of Transolver similar to the one described in~\cite{wu2024transolver}, with $8$ Transolver blocks, a channel size of $256$, $8$ self-attention heads, an up-projection ratio of $2$ for the feed-forward layers, and 64 slices

\paragraph{GINO} The \ac{GINO}~\citep{Li:23} is a neural operator with a regularly structured latent space, that learns a solution operator of large-scale partial differential equations.
It exhibits, as \ac{GP-UPT}, a decoupling of its geometry encoder and the field-based decoder, and can also be seen as a geometry-aware model due to its regularly-structured latent space.
To allow for an efficient application of the \ac{FNO}~\cite{Li:20} it transforms an irregular grid into a regular latent grid.
In particular, it starts with employing a \acf{GNO} to map the irregular point cloud input to a regularly structured cubic latent grid.
This structured latent space is then processed by the \ac{FNO}. 
As a last stage, a second \ac{GNO} block is employed as a field decoder to get query-point-based predictions in original irregular point cloud space
(e.g., on the surface manifold of a car geometry).
Originally, \ac{GINO} takes the \acl{SDF} as well as point-cloud representation of the geometry as an input. 
However, during our initial experiments on ShapeNet Car, we observed that omitting the \ac{SDF} input led to only a minor performance drop. 
To ensure a fair comparison with other baselines, all of which rely solely on the point cloud geometry, we also remove the \ac{SDF} input feature for GINO.
For our \ac{GINO} implementation (similar to the one in~\cite{alkin2024universal}), we use a latent resolution of $64^3$, 16 Fourier modes, and a message passing radius of 10.

\paragraph{UPT} The \acf{UPT}~\cite{alkin2024universal} is a unified neural-operator without a grid- or particle-based latent structure, that can be applied to a variety of spatio-temportal problems. 
Similar to \ac{GINO}~\cite{Li:23}, \ac{UPT} allows for querying the latent space at any point in the spatial-temporal domain.
The input function, which is represented as a point cloud, is first mapped to a lower-dimensional (in terms of the number of input tokens)  representation by a (message passing) supernode pooling layer.
Next, a transformer-based encoder stack maps the supernode representations into a compressed latent representation.
Since we only work with stationary problems in this paper, we do not use perceiver pooling and an approximator after the encoder.
To query the latent space at any location, a single layer (perceiver-like) cross-attention layer is used.

To match the number of trainable parameters in Transolver and \ac{GP-UPT}, we set the up-projection of the feed-forward layers to two, the number of encoder blocks to six, and, following \citet{alkin2024universal}, we use only one decoder block. 
The remaining model hyper-parameters of the \ac{UPT} implementation are listed in Table~\ref{table:experimental-setup-upt}.
\begin{table*}[]
\centering
\caption{Hyper-parameter configuration for \ac{UPT}.}
\begin{tabular}{cc}
\hline
Hyper-parameter           & ShapeNet/DrivAerML                    \\ \hline
Input normalization       & rescaling \\
Number of supernodes $S$     & 3586/8000                             \\
Radius $r_{sn}$                        & 9                                     \\
Max degree supernode & 32                                    \\
Hidden dimensionality     & 256                               \\
Encoder blocks $K$          & 6                                   \\
Decoder blocks $C$           & 1                                   \\
Number of attention heads $h$ & 8                                   \\ \hline
\end{tabular}
\label{table:experimental-setup-upt}
\end{table*}
\subsection{Implementation details GP-UPT}
\begin{table*}[]
\centering
\caption{Hyper-parameter configuration for \ac{GP-UPT}.}
\begin{tabular}{cc}
\hline
Hyper-parameter           & ShapeNet/DrivAerML                    \\ \hline
Input normalization       & rescaling \\
Number of supernodes $S$     & 3586/8000                             \\
Radius $r_{sn}$                        & 9                                     \\
Max degree supernode & 32                                    \\
Hidden dimensionality     & 256                               \\
Encoder blocks $K$          & 3                                   \\
Decoder blocks $C$           & 2                                   \\
Number of attention heads $h$ & 8                                   \\ \hline
\end{tabular}
\label{table:experimental-setup}
\end{table*}
In Table~\ref{table:experimental-setup}, we provide an overview of the design hyper-parameters of \ac{GP-UPT}.
We set the number of encoder and decoder layers, the hidden dimensionality $d_{hidden}$, the up-projection for the feed-forward layers, and the number of attention heads to match the configuration used in Transolver~\cite{wu2024transolver}.

\subsubsection{Positional encoding}
For \ac{GP-UPT}, to represent the surface mesh, we use a positional encoding similar to the one in~\cite{alkin2024universal}. 
Specifically, we apply the sine-cosine position embeddings from transformers~\cite{Vaswani:17}, where each coordinate dimension is embedded individually. 
The $x$, $y$, and $z$ coordinates are first rescaled to the range $[0, 1000]$. 
Next, the rescaled coordinates are mapped to the sine-cosine position embeddings, resulting in a hidden dimension of size $d_{hidden}$.

\subsubsection{Supernode pooling}
As described in Section~\ref{sec:methodology}, our supernode pooling block is similar to the one in~\cite{alkin2024universal}. 
From the embedded input point cloud, we randomly select $S$ supernodes and aggregate information from the surrounding neighbors within a radius of $r_{sn}=9$. 
For ShapeNet Car, we set the number of supernodes to $S=3,586$, which matches the number of points in the geometry point cloud representing the surface mesh. 
For DrivAerML, we use $S=8,000$ supernodes. 
The number of supernodes is calibrated to ensure that each supernode has a high input degree and that the entire input point cloud is adequately covered. 
For both ShapeNet and DrivAerML, we set the maximum input degree of each supernode to $32$.

\subsubsection{Geometry-aware encoder}
For the geometry-aware encoder $\cE$ we use $K=3$ encoder blocks, each consisting of a cross-attention layer followed by a self-attention layer. 
In line with Transolver~\cite{wu2024transolver}, we set the number of heads for both the cross-attention and self-attention layers to $8$, with a hidden dimension $d_{hidden} = 256$, and the up-projection ratio for the feed-forward layers to $2$. 
Preliminary experiments with a higher number of attention heads did not show a significant impact on the evaluation metrics.
The number of encoder and decoder blocks, along with the hidden dimension and up-projection, are configured to match the parameter count of our transformer-based baseline (Transolver).

\subsubsection{Field decoder}
For the field decoder $\cD_{field}$ we use a stack of $C=2$ cross-attention layers.
Similarly to the encoder $\cE$, we configure the field decoder with $8$ attention heads and a hidden dimensionality of $d_{hidden} = 256$. 
The input queries to the field decoder are embedded in the same way as the input coordinates to the encoder. 

\subsection{Training details}

\subsubsection{Data processing}

For all baseline models (except \ac{UPT}), we normalize the input coordinates representing the surface mesh using the mean and standard deviation of each input dimension. 
For \ac{GP-UPT} and \ac{UPT}, we scale the input coordinates to a range of $[0, 1000]$,
For DrivAerML, to prevent training instability, we filter out pressure outliers by removing values outside the range $[-2000, 1000]$.
Since \ac{GINO}, \ac{GP-UPT}, and \ac{UPT} use a decoupled encoder-decoder architecture, we sample two distinct sets of input points and output queries during training for each model.

\subsubsection{Training configuration}
In Tables~\ref{table:training-config-shapenet} and~\ref{table:training-config-drivaerml}, we present the initial training hyper-parameters for both benchmark datasets (ShapeNet Car and DrivAerML). 
Following~\cite{wu2024transolver}, we set the batch size to $1$ and the initial learning rate to $1e-3$. 
We use AdamW~\cite{loshchilov2017fixing} as the optimizer for our baseline models, with $\beta_1 = 0.9$ and $\beta_2 = 0.95$, together with a cosine learning rate schedule (5\% warm-up epochs), a weight decay of 0.05, and train for 1000 epochs.
During training, \ac{GINO}, RegDGCNN, and \ac{UPT} showed instabilities with the initial configurations. 
To address this, we experimented with different batch sizes ($\{1, 2, 4, 8\}$) and learning rates ($\{\num{1e-4}, \num{5e-4}\}$), selecting the best-performing settings based on evaluation results. 
We train \ac{GP-UPT} and \ac{UPT} with the LION~\cite{chen2023symbolic} optimizer with a learning rate of \num{1e-4} (see Table~\ref{tab:optimizer} for the motivation).
For RegDGCNN, we enabled batch normalization when using batch sizes $\geq 2$ to improve training stability.
For ShapeNet Car, we use all $3,586$ points on the surface mesh as input. For DrivAerML, we sample 40,000 input points from the surface mesh during each training iteration. 
We tested larger point clouds for both training and evaluation but found that the MSE, MAE, and L2 scores did not show significant changes based on the number of training or evaluation points.
All models are trained with \emph{float32} precision.

\begin{table}[]
\caption{Training configuration for ShapeNet Car.}
\begin{tabular}{lccccccc}
\hline
\multicolumn{8}{c}{Training configuration - ShapeNet Car}                                                                                                                                        \\ \hline
\multicolumn{1}{l}{Model} & Batch size         & Epochs                & Initial LR            & Weight Decay          & Optimizer              & Input points          & Output Queries        \\ \hline
PointNet                   & 1                  & \multirow{6}{*}{1000} & \multirow{1}{*}{\num{1e-3}} & \multirow{6}{*}{0.05} & \multirow{4}{*}{AdamW} & \multirow{6}{*}{3,586} & \multirow{6}{*}{3,586} \\
RegDGCNN                   & 2                  &                       &   \num{1e-3}                    &                       &                        &                       &                       \\
GINO                       & 4                  &                       & \num{1e-4}                  &                       &                        &                       &                       \\
Transolver                 & 1 &                       & \multirow{1}{*}{\num{1e-3}} &                       &                        &                       &                       \\
UPT & 1 & & \num{1e-4} &  & LION && \\
GP-UPT                     &   1                 &                       &        \num{1e-4}               &                       &     LION                   &                       &                       \\ \hline
\end{tabular}

\label{table:training-config-shapenet}
\end{table}

\begin{table}[]
\caption{Training configuration for DrivAerML.}
\begin{tabular}{lccccccc}
\hline
\multicolumn{8}{c}{Training configuration - DrivAerML}                                                                                                                                 \\ \hline
Model      & Batch size         & Epochs                & Initial LR            & Weight Decay          & Optimizer              & Input points             & Output Queries           \\ \hline
PointNet   & 1                  & \multirow{6}{*}{1000} & \multirow{1}{*}{\num{1e-3}} & \multirow{6}{*}{0.05} & \multirow{4}{*}{AdamW} & \multirow{6}{*}{40,0000} & \multirow{6}{*}{40,0000} \\
RegDGCNN   & 2                  &                       &  \num{1e-3}                     &                       &                        &                          &                          \\
GINO       & \multirow{1}{*}{1} &                       & \num{1e-4}                  &                       &                        &                          &                          \\
Transolver &       1             &                       & \multirow{1}{*}{\num{1e-3}} &                       &                        &                          &                          \\
UPT &   1 & & \num{1e-4} & & LION & &  \\
GP-UPT     &        1            &                       &    \num{1e-4}                   &                       &    LION                    &                          &                          \\ \hline
\end{tabular}

\label{table:training-config-drivaerml}
\end{table}

\begin{table}[h!]
\centering
\caption{Impact of optimizer on field decoder performance for surface value predictions.}
\begin{tabular}{lclccccc}
\toprule
Model &\#params&Dataset& Optimizer& Initial LR & MSE & L2 &MAE \\
\hline
GP-UPT &4.7M & ShapeNet Car& AdamW& \num{1e-3}&15.53 & 0.0577 & 1.47 \\
GP-UPT &4.7M & ShapeNet Car& LION& \num{1e-4}&17.04 & 0.0603 & 1.44 \\ \hline
GP-UPT &4.7M & DrivAerML& AdamW& \num{1e-3}&617.99 & 0.0694 & 12.38 \\
GP-UPT &4.7M & DrivAerML& LION& \num{1e-4}&314.25 & 0.0497 & 10.38 \\
\bottomrule
\end{tabular}
\label{tab:optimizer}
\end{table}
