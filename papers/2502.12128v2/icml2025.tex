\documentclass{article}

\usepackage[subfigure]{tocloft}

\usepackage{microtype}
\usepackage{graphicx}
\usepackage{subfigure}
\usepackage{booktabs} %
\usepackage{hyperref}


\usepackage[accepted]{icml2025}


\usepackage{amsmath}
\usepackage{amssymb}
\usepackage{mathtools}
\usepackage{amsthm}
\usepackage[capitalize,noabbrev]{cleveref}
\usepackage{ml_defs}
\usepackage{threeparttable}
\usepackage{fontawesome5}
\usepackage{subcaption}
\usepackage{enumitem}
\usepackage{adjustbox}



\definecolor{fingerprint_color}{HTML}{046E98}

\newcommand{\FS}[1]{\textcolor{magenta}{\textbf{FS: #1}}}
\newcommand{\JB}[1]{\textcolor{purple}{\textbf{JB: #1}}}
\newcommand{\GK}[1]{\textcolor{blue}{\textbf{GK: #1}}}
\newcommand{\AM}[1]{\textcolor{green}{\textbf{AM: #1}}}
\newcommand{\AT}[1]{\textcolor{orange}{\textbf{AT: #1}}}

\newcommand{\ourMethod}{ \textsc{LaM-SLidE} }

\renewcommand{\paragraph}[1]{\textbf{#1}. }



\theoremstyle{plain}
\newtheorem{theorem}{Theorem}[section]
\newtheorem{proposition}[theorem]{Proposition}
\newtheorem{lemma}[theorem]{Lemma}
\newtheorem{corollary}[theorem]{Corollary}
\theoremstyle{definition}
\newtheorem{definition}[theorem]{Definition}
\newtheorem{assumption}[theorem]{Assumption}
\theoremstyle{remark}
\newtheorem{remark}[theorem]{Remark}

\usepackage[textsize=tiny]{todonotes}



\icmltitlerunning{LaM-SLidE: Latent Space Modeling of Spatial Dynamical Systems via Linked Entities}

\Crefname{equation}{Eq.}{Eqs.}
\Crefname{figure}{Fig.}{Figs.}
\Crefname{table}{Tab.}{Tabs.}
\Crefname{appendix}{App.}{Apps.}

\begin{document}


\twocolumn[

\icmltitle{\textcolor{fingerprint_color}{LaM-SLidE \faFingerprint} : \textcolor{fingerprint_color}{La}tent Space \textcolor{fingerprint_color}{M}odeling of Spatial Dynamical \textcolor{fingerprint_color}{S}ystems via  \textcolor{fingerprint_color}{Li}nke\textcolor{fingerprint_color}{d} \textcolor{fingerprint_color}{E}ntities}





\icmlsetsymbol{equal}{*}

\begin{icmlauthorlist}
\icmlauthor{Florian Sestak}{JKU}
\icmlauthor{Artur P. Toshev}{tum}
\icmlauthor{Andreas Fürst}{JKU}
\icmlauthor{Günter Klambauer}{JKU,NXAI,equal}
\icmlauthor{Andreas Mayr}{JKU,equal}
\icmlauthor{Johannes Brandstetter}{JKU,Emmi,equal}
\end{icmlauthorlist}


\icmlaffiliation{JKU}{Institute for Machine Learning, LIT AI Lab \& ELLIS unit Linz, Johannes Kepler University, Linz, Autria}
\icmlaffiliation{NXAI}{NXAI GmbH, Linz, Austria}
\icmlaffiliation{Emmi}{Emmi AI GmbH, Linz, Austria}
\icmlaffiliation{tum}{Chair of Aerodynamics and Fluid Mechanics, School of Engineering and Design, Technical University of Munich, Garching, Germany}
\icmlcorrespondingauthor{Johannes Brandstetter}{jo-
hannes@emmi.ai}

\icmlkeywords{Machine Learning, ICML}

\vskip 0.3in
]



\printAffiliationsAndNotice{\icmlEqualContribution} %

\begin{abstract}
Generative models are spearheading recent progress in deep learning, 
showing strong promise for trajectory sampling in dynamical systems as 
well. However, while latent space modeling paradigms have transformed image 
and video generation, similar approaches are more difficult for most dynamical 
systems. Such systems -- from chemical molecule structures to collective human 
behavior -- are described by interactions of entities, making them 
inherently linked to connectivity patterns and the traceability of 
entities over time. 
Our approach, \ourMethod (\textcolor{fingerprint_color}{La}tent Space \textcolor{fingerprint_color}{M}odeling of Spatial Dynamical \textcolor{fingerprint_color}{S}ystems via  \textcolor{fingerprint_color}{Li}nke\textcolor{fingerprint_color}{d} \textcolor{fingerprint_color}{E}ntities), combines the advantages of 
graph neural networks, i.e., the traceability of entities across time-steps, 
with the efficiency and scalability 
of recent advances in image and video generation, 
where pre-trained encoder 
and decoder are frozen to enable generative modeling in the latent space. 
The core idea of \ourMethod is to introduce identifier representations (IDs) 
to allow for retrieval of entity properties, e.g., entity coordinates, 
from latent system representations and thus enables traceability.
Experimentally, across different domains, we show that \ourMethod performs 
favorably in terms of speed, accuracy, and generalizability. Code is available at~\url{https://github.com/ml-jku/LaM-SLidE}.
\end{abstract}

\section{Introduction}

\begin{figure}[!ht]
\vskip 0.2in
\begin{center}
\centerline{\includegraphics[width=.99\columnwidth]{figures/Figure1_Overview.pdf}}
\caption{\ourMethod modeling paradigm.  
\ourMethod (lower right) uses ID-based tracking of entities and thereby allows to combine  advantages of GNNs (upper left), i.e., the traceability of entities across time-steps, with the efficiency and scalability of generative latent space modeling approaches (upper right). In contrast to an approach as in the lower left part, individual entities can be traced.
The approximator $\mathcal A$ indicates any model, that predicts a system state at $t+\Delta t$ from a system state at $t$. While the input and output domain for GNNs is in the observation space or a space where the dimensionality of representations depends on the number of entities, for latent space modeling approaches with respect to systems of entities, the input and output domains of $\mathcal A$ represent a latent space, which is independent from the number of entities. Encoders $\mathcal{E}$ and decoders $\mathcal{D}$ map or retrieve system states to or from this latent space representation.
}
\label{fig:red_holo}
\end{center}
\vskip -0.2in
\end{figure}


Understanding the dynamics of spatial systems is a fundamental challenge 
in many scientific and 
engineering domains \citep{karplus1990molecular,jumper2021highly,price2025probabilistic}. 
In this paper,
we focus on \emph{spatial} dynamical systems, where \emph{scenes} are composed of 
distinguishable entities at defined spatial locations. 
Modeling temporal trajectories of such entities quickly becomes challenging, 
especially when (i) stochasticity is involved, and (ii) when entities should be \emph{traceable}. 
A prime example is molecular dynamics \citep{karplus1990molecular}, 
where trajectories of individual atoms 
are modeled via Langevin dynamics, which accounts for omitted degrees of freedom 
by using of stochastic differential equations. 
Consequently, the trajectories of the atoms themselves 
become non-deterministic, but the atoms remain traceable over time.    

A conventional approach to predict spatial trajectories of entities is to 
represent scenes as neighborhood graphs and to subsequently process 
these graphs with graph neural networks (GNNs). 
When using GNNs \citep{Scarselli2009, Micheli2009, Gilmer2017, Battaglia2018}, 
each entity is usually represented by a node, and the spatial entities nearby are connected by an edge in the neighborhood graph. Neighborhood graphs have extensively 
been used for trajectory prediction tasks~\citep{kipf2018neural}, 
especially for problems with a large number of indistinguishible entities, 
\citep[e.g.,][]{Sanchez2020, Mayr2023_1}. 
Recently, GNNs have been integrated into generative modeling frameworks to 
effectively capture the behavior of stochastic systems~\citep{yu2024force,costa2024equijump}.

Despite their widespread use in modeling spatial trajectories, 
GNNs hardly follow recent trends in latent space modeling, 
where unified representations together with universality and scalability of transformer blocks~\citep{vaswani2017attention} offer simple application 
across datasets and tasks, a behavior commonly observed 
in computer vision and language processing \citep{devlin2018bert, dosovitskiy2020image}. 
Notably, recent breakthroughs in image and video generation 
can be accounted to latent space conditioned generative modeling~\citep{ho2022imagen,blattmann2023align}. 
In such paradigms, pre-trained encoders and decoders are employed 
to map data into a latent space, where subsequent modeling is performed, 
leveraging the efficiency and expressiveness of this representation.
This poses the question: what does it take to leverage recent techniques 
from generative latent space modeling to boost the modeling of stochastic trajectories of entities? 
Recently, it has been shown~\citep{alkin2024neuraldem} that it is possible to model the bulk behavior of large particle 
systems purely in the latent space, at the cost of sacrificing the traceability of individual particles, which is 
acceptable or even favorable for systems where particles are indistinguishable, but challenging for, e.g., molecular 
modeling, where atom assignments are essential.


In order to combine the advantages of 
GNNs, i.e., the traceability of entities across time-steps, 
with the efficiency and scalability of latent space approaches, 
we introduce \ourMethod (see Figure~\ref{fig:red_holo}).
The core idea of \ourMethod is 
the introduction of identifier representations (IDs) 
that allow for retrieval of entity properties, e.g., entity coordinates, from latent system representations. 
Consequently, we can train generative models, such as stochastic interpolants~\citep{albergostochastic}, 
purely in the latent space, where pre-trained decoder blocks map the generated states back to the physics domain. 
Qualitatively, 
\ourMethod demonstrates flexibility and favorable performance 
across a variety of different modeling tasks. 


In summary, our contributions are the following:\\
    \textbf{\textbullet}\ We propose \ourMethod for generative
    modeling of stochastic trajectories, which combines the advantages
    of GNNs, concretely traceable entities,
    with the scaling properties of latent space models.\\
    \textbf{\textbullet}\ We introduce entity structure preservation to recover the encoded system structure from latent space.\\
    \textbf{\textbullet}\ We perform experiments in different domains with varying degrees of difficulty, focusing on molecular dynamics. \ourMethod performs favorably with respect to all other architectures, showcasing scalability with model size.\\



\section{Background \& Related Work}

We approach the modeling of trajectories of spatial \emph{dynamical systems}
with a \emph{latent space} approach
and employ \emph{deep generative models}.

\paragraph{Dynamical systems} Formally, we consider a dynamical system 
to be defined by a state space $ \cS $, representing all possible configurations 
of the system, and an evolution rule $\Phi: \dR \times \cS \mapsto \cS $ that 
determines how a state $\bfs \in \cS$ evolves over time, and 
which exhibits the following properties for the time differences $0, \hat t_1$, and, $\hat t_2$:
\begin{align}
\Phi(0,\bfs)&=\bfs\\
\Phi(\hat t_2,\Phi(\hat t_1,\bfs))&=\Phi(\hat t_1+\hat t_2,\bfs)
\end{align}
We note, that $\Phi$ does not necessarily need to be defined on the whole space $\dR \times \cS$, 
but assume this is the case for notational simplicity. The exact formal definition of 
random dynamical systems is more 
involved and consists of a base flow (noise) and a 
cocycle dynamical system defined on a physical phase space 
\citep{arnold1998random}. We skip the details, 
but assume to deal with random dynamical systems for the remainder of the paper. The stochasticity of such random 
dynamical systems suggests generative modeling approaches.  



\paragraph{Generative modeling}
Recent developments in generative modeling have captured widespread interest. %
The breakthroughs of the last years were mainly driven 
by diffusion models~\citep{sohl2015deep,song2020score,ho2020denoising}, 
a new modeling paradigm that transforms a simple distribution $p_0$ 
into a target data distribution $p_1$ via iterative refinement steps. 
Flow Matching~\citep{lipman2022flow}, which is built upon 
continuous normalizing flows \citep[CNFs;][]{chen2018neural}, 
provides a robust and stable alternative for training diffusion models in a simulation-free way and further also allows 
to train CNFs with non-diffusion probability paths (e.g., optimal transport displacement interpolation can be employed to 
define conditional probability paths). \citet{liu2022flow, albergo2022building} suggested similar conditional objectives 
for training CNFs. Models based on these generative architectures, achieved remarkable success across 
different modalities like images~\citep{rombach2022high}, audio~\citep{vyas2023audiobox}, text 
\citep{austin2021structured}, or, videos~\citep{polyak2024movie}. Generative architectures based on diffusion or CNFs 
have further been successfully applied to the scientific domain, e.g., for protein structure prediction 
\citep{abramson2024accurate}, protein-ligand docking \citep{corso2022diffdock}, 
or, protein design~\citep{huguet2024sequence}
,and, they are also useful for engineering, e.g., in robotics~\citep{black2024pi_0}. 



\paragraph{Latent space modeling}
Latent space modeling has achieved remarkable success 
at image and video generation~\citep{blattmann2023align, esser2403scaling}, 
where pre-trained encoders and decoders map data into a latent space, and back into the physics space. 
The latent space aims to preserve the essential structure and features of the original data, often following a compositional structure $\cD \cdot \cA \cdot \cE$~\citep{seidman2022nomad,alkinuniversal,alkin2024neuraldem}, where the encoder $\cE$ maps the input signal into the latent space, the approximator $\cA$ models a process, and the decoder maps back to the original space.
Examples of approximators are conditional generative modeling techniques, e.g., generating an image given a text prompt (condition). This framework was, e.g., recently used for 3D shape generation, where 3D shapes are generated in latent space, the final shape in the spatial domain is then constructed by querying the latent representations over a fixed spatial grid~\citep{zhang20233dshape2vecset,zhang2024lagem}.
Similar~\citet{wangswallowing} used a latent space modeling approach based on a PerceiverIO architecture \citep{jaegle2021perceiverio} for molecular conformer generation, without enforcing inductive biases like rotational-equivariance. The final positions of the individual atoms are retrieved by querying the latent representations via a special designed set of queries~\citep{zhuang2023diffusion}. Results indicate that scaling model capacity leads to large gains in generalization performance.




\section{Latent Space Modeling of 
Spatial Dynamical Systems via
Linked Entities}
\label{sec:method}

\begin{figure*}[ht]
\vskip 0.2in
\begin{center}
\centerline{\includegraphics[width=0.96\textwidth]{figures/method}}
\caption{\textbf{Overview of our entity-preserving
encoder-decoder architecture.}
\textbf{Left:} \ourMethod's encoder maps $N$ input tokens to a fixed size latent representation via cross-attention. The decoder reconstructs the input data from the latent space using the assigned IDs. \textbf{Right:} Structure of the input token, consisting of an ID, spatial information and features.
}
\label{fig:first-stage}
\end{center}
\vskip -0.2in
\end{figure*}


\ourMethod introduces an identifier (ID) pool and 
an identifier assignment function which allow us 
to effectively map and retrieve latent system representations. 
The ID components 
preserve the relationships between entities,
making them traceable across time-steps. 
\ourMethod follows an encoder $\mathcal E$ - approximator $\mathcal A$ - decoder $\mathcal D$ paradigm.

\subsection{Problem Formulation}


\paragraph{State space\label{sec:statespace}} 
We consider spatial dynamics. Our states $\bfs \in \cS$ describe the configuration 
of entities within the scene together with their individual features, 
and possibly together with global scene properties.
We assume that a scene consists of $N$ entities $e_i$ with $i \in 1,\ldots, N$. 
An entity $e_i$ is described by its spatial location $\bfx_i \in \dR^{D_x}$ and 
some further properties $\bfm_i \in \dR^{D_m}$ (e.g., atom type, etc.). 
We further assume that the whole scene itself might be described by some global properties $\bfg \in \dR^{D_g}$.
A state is time-specific. We denote the scene state at a certain time point $\hat t$ as $\bfs^{\hat t}$. Here $\hat t$ denotes a specific absolute time. Often, we consider sequences of absolute time points $\hat t_0, \ldots, \hat t_t, \ldots, \hat t_{T\!-1}$. Instead of referring to a state $\bfs^{\hat t_t}$, we just denote this state as $\bfs^t$, when we refer to the state at a time point at index $t$ within the given sequence. Analogously, we use $\bfx_i^t$, $\bfm_i^t$, $\bfg^t$ to describe coordinates and properties at time point $\hat t_t$. We refer to the coordinate concatenation $[\bfx_1^t,..,\bfx_N^t]$ of the $N$ entities in $\bfs^t$ as $\bfX^{t} \in \dR^{N \times D_x}$. Analogously, we use $\bfM^{t} \in \dR^{N \times D_m}$ to denote $[\bfm_1^t,..,\bfm_N^t]$. When properties are conserved over time, i.e., $\bfM^{t}=\bfM^{0}$ and/or $\bfg^{t}=\bfg^{0}$, we just skip the time index and the time-wise repetition of states and use $\bfM \in \dR^{N \times D_m}$ and $\bfg \in \dR^{D_g}$, respectively. Further, without loss of generality, we skip $\bfg$, since we did not make use of it in our experiments. It however is straightforward to include $\bfg$ into the architecture.
A notation table is available, see~\cref{sec:notation}.

\paragraph{Sampled trajectories} 
We assume sample trajectories of system states $\bfs^{\hat t}$ sampled at a sequence of time steps $\hat t_0, \ldots, \hat t_t, \ldots, \hat t_{T\!-1}$. These samples may, e.g., originate from molecular dynamics (MD)
simulations with a starting state $\bfs^{\hat t_0}$ and 
discrete time steps of equal size $\Delta_{\text{sim}}=\hat t_{t+1}-\hat t_{t}$ or 
from pedestrian observations by a camera, which store their observation 
at time intervals of size $\Delta_{\text{obs}}$. We concatenate sequences of 
coordinate states $\bfX^{t}$ with $t \in 0\,..\,T\negthickspace-\negmedspace1$ 
to a tensor $\bfX \in \dR^{T \times N \times D_x}$, which describe a whole 
sampled coordinate trajectory of a system with $T$ time points and $N$ entities. 
An example for such trajectories from a dynamical systems 
are molecular dynamics trajectories (see Fig.~\ref{fig:md17_traj_example}; 
details in Sec.~\ref{sec:experiments}).





\paragraph{Predictive aim} Our aim is to generate the 
spatial continuation $\bfX^{[T_o \colon T-1]} = [\bfX^{T_o},\dots,\bfX^t,\dots,\bfX^{T-1}] \in \dR^{(T-T_o) \times N \times D_x}$ of a system trajectory, given a short (observed) initial spatial trajectory $\bfX^{[0 \colon T_o-1]} = [\bfX^0,\dots,\bfX^t,\dots,\bfX^{T_o-1}] \in \dR^{T_o\times N \times D_x}$ together with general (time-invariant) entity properties $\bfM$.



\subsection{Entity Structure Preservation}

\label{sec:structurepreservation}
In order to maintain the integrity of scene entity structures 
when mapping to and processing in latent space, 
the core new idea is to randomly assign an ID from an ID pool
to each entity of the system. These IDs allow us to retrieve 
the entity's location from the system state by using an ID-embedding
as a query in cross-attention \citep{vaswani2017attention,ramsauer2021hopfield}.
The two key components for ensuring entity structure preservation are:\\
\textbullet\ creating a fixed, finite pool of \textit{identifiers (IDs)}, and \\
\textbullet\ defining a stochastic function, which assigns, or links, 
each entity in a scene to one of the unique identifiers from our identifier pool.


\begin{definition}[\label{IP} Identifier pool]
We consider the set $\gI=\{i \mid  i \in \dN\ \land i < u \}$ 
with $u \in \dN$ to be an \textit{identifier pool}. 
An \textit{identifier} $i$ is an element of the set $\gI$.
\end{definition}

\begin{definition}[\label{IAF} Identifier assignment function]
Given an entity space, which summarizes the entities of 
a dynamic system, i.e., $E=\{e_1, \ldots, e_N\}$, 
we define a stochastic \textit{identifier assignment function} $I\!D$, 
which maps $E$ to $\gI$ as follows:
\begin{equation}
    I\!D: E \times \Omega \mapsto \gI \ ,
\end{equation}
where $\Omega$ is a sample space representing randomness, and, $\forall \omega \in \Omega \;\forall e_1, e_2 \in E: e_1 \neq e_2 \Rightarrow  I\!D(e_1, \omega) \neq I\!D(e_2, \omega) $.
\end{definition}

The condition on $I\!D$ in \cref{IAF} is a requirement of injectivity 
in its first argument given a fixed second argument. Such a function might not always exist.

\begin{proposition}\label{IAFprop}
Given an identifier pool $\gI$ as defined by \cref{IP}, 
then an $I\!D$ function according to \cref{IAF} only exists, if $|E| \leq |\gI|$.
\end{proposition}

The use of a stochastic function allows us to apply our entity structure preservation 
concept to a wide class of problems, as no exact assignment algorithm between entities and IDs needs to be specified 
explicitly. Instead, it only matters that an injective assignment is made. Further, \cref{IAFprop} suggests to use an 
identifier pool which is large enough, such that a learned model based on this Identifier Pool can generalize across systems 
with varying numbers of entities. 



\subsection{Model Architecture: Latent Space Modeling}
\label{sec:latentmodels} \label{sec:architecture}

Since predicting continuations of system trajectories is a conceptually similar task to generating videos from an initial 
sequence of images, we took inspiration from \citet{blattmann2023align} in using a latent diffusion architecture. We also took 
inspiration from \citet {jaegle2021perceiverio} to decompose our model architecture as follows: To map the state of the system 
composed of $N$ entities to a latent space containing $L$ latent tokens ($\in \dR^{D_z}$), we use a cross-attention mechanism. 
In the resulting latent space, we aim to train an approximator to predict future latent states based on the embedded initial 
states. Inversely to the encoder, we again use a cross-attention mechanism to retrieve the latent information for the entities 
of the system. To wrap it up, \ourMethod, is built up by an encoder ($\mathcal{E}$) - approximator ($\mathcal{A}$) - decoder 
($D$) architecture, which represents the following function:
\begin{align}
    \mathcal{D} \circ \mathcal{A} \circ \mathcal{E}: \dR^{T_o\times N \times D_x} \times \dR^{N \times D_m} \mapsto \dR^{(T-T_o) \times N \times D_x}\nonumber
\end{align}
A detailed composition of \ourMethod is shown in the left part of \cref{fig:first-stage}. 

\paragraph{Encoder}
The encoder $\mathcal{E}$ aims to encode a state of the system such that the properties of each individual entity $e_n$ can be 
decoded (retrieved) later. At the same time the structure of the latent state representation ($\in  \dR^{L \times D_z}$) should 
not depend on $N$, i.e., $L$ and $D_z$ are constants and serve as hyperparameters, while individual samples may be composed of 
different numbers $N$ of entities, as opposed to GNNs, for which the size of the latent representation depends on the number of nodes 
throughout each message passing step.


To allow for traceability of the entities, we first embed each identifier $i$ in the space $\dR^{D_u}$ by a learned embedding 
\texttt{IDEmb}: $\gI \mapsto \dR^{D_u}$. Then we draw a random number $\omega \in \Omega$ and map all ($n=1,\ldots, N$) system 
entities $e_n$ to $\bfu_n \in \dR^{D_u}$ as follows: 
\begin{align}
\bfu_n=\texttt{IDEmb}(\texttt{ID}(e_n, \omega)) && \forall n \in {1,\ldots, N}
\end{align}

The inputs to the encoder comprise the (time-specific) location $\bfx_n^t \in \dR^{D_x}$, properties $\bfm_n \in \dR^{D_x}$, 
and an identity representation $\bfu_n \in \dR^{D_x}$, as  visualized in the right part of \cref{fig:first-stage}. We 
concatenate the different types of features across the entities of the system: 
$\bfX^{t}=[\bfx_1^t,..,\bfx_N^t], \bfM=[\bfm_1,..,\bfm_N], \bfU_\omega=[\bfu_1,..,\bfu_N]$. 
The encoding function $\mathcal{E}_{\text{Trace}}: \dR^{N \times (D_x + D_m + D_u)} \mapsto \dR^{L \times D_z}$ maps the input 
to a fixed-size latent space state representation $\bfZ^{t} \coloneqq \cE_{\text{Trace}}(\bfX^{t}, \bfM, \bfU_\omega) \in \dR^{L \times D_z}$, 
realized by cross-attention \citep{vaswani2017attention} between the 
input tensor $\in \dR^{N \times (D_x + D_m + D_u)}$ of $\mathcal{E}_{\text{Trace}}$ (attention keys and values), 
and a fixed 
number of $L$ 
learned query vectors $\in \dR^{D_z}$ (attention queries, see the left part of \cref{fig:first-stage}).

\paragraph{Decoder}
The aim of the decoder $\mathcal{D}$ is to retrieve the system state information $\bfX^{t}$ and $\bfM$, corresponding to the 
latent state representation $\bfZ^{t}$ and $\bfU_\omega$, i.e., encoded entity identifier embeddings. This is realized by a 
decoding function $\mathcal{D}_{\text{Trace}}: \dR^{L \times D_z} \times \dR^{D_u} \mapsto \dR^{(D_x + D_m)}$, which is applied 
to each $\bfu_n$ available from $\bfU_\omega$, i.e., $(\bfx_n^t, \bfm_n)=\mathcal{D}_{\text{Trace}}(\bfZ^t, \bfu_n)$. As 
indicated in the left part of \cref{fig:first-stage}, also $\mathcal{D}_{\text{Trace}}$ is realized by cross-attention layers. 
The latent space information $\bfZ^t$ serves as an input to both keys and values of the cross-attention mechanism, while the embedded 
identifier of $e_n$ serves as an input to the query.
The decoder makes use of a cross-attention mechanism using
learned ID embeddings as query \citep{widrich2020modern,locatello2020object,ramsauer2021hopfield},
which could be seen as a 
content-based retrieval system 
and an associative memory \citep{amari1972learning,hopfield1982neural,ramsauer2021hopfield}.

\paragraph{Approximator}
Finally, the approximator models the system's time evolution in latent space, i.e., predicts a series of future latent system states $\bfZ^{[T_o\colon T-1]}=[\bfZ^{T_o},\bfZ^t,\dots,\bfZ^{T-1}]$, given a series of initial system states, which are already embedded in latent space $\bfZ^{[0 \colon T_o - 1]}=[\bfZ^0,\bfZ^t,\dots,\bfZ^{T_o-1}]$. Hence, the approximator is a function $\cA \colon \dR^{T_o \times L \times D_z} \mapsto \dR^{(T-T_o) \times L \times D_z}$.

Given the analogy of predicting the time evolution of a dynamic 
system to the task of synthesizing videos, we realized $\cA$ by a 
flow-based model. Specifically, we constructed it based on the 
stochastic interpolants framework \citep{albergostochastic}, in a 
manner similar to the implementation provided by \citet{ma2024sit}, see~\cref{sec:addSI}.

We are interested in time-dependent processes, which interpolate 
between data $\bfo_1  \sim p_1$ from a target data distribution 
$p_1$ and noise $\bfeps \sim p_0 \coloneqq \mathcal{N}(\BZo, \BI)$:
\begin{equation}
     \bfo_\tau=\alpha_\tau\bfo_1+\sigma_\tau \bfeps \ , \label{sproc}
\end{equation}
where $\tau \in [0,1]$ is a diffusion time (to be distinguished 
from dynamic system times $\hat t$ and indices $t$ within a 
dynamic system time dimension). $\alpha_\tau$ and $\sigma_\tau$ 
are differentiable functions in $\tau$, which have to fulfill $\alpha_\tau^2+\sigma_\tau^2>0\;\forall \tau \in [0,1]$, and, 
further $\alpha_1=\sigma_0=0$, and, $\alpha_0=\sigma_1=1$.
\citet{ma2024sit} use a velocity field $\Bv(\bfo, \tau)$ given as $\Bv(\bfo, \tau)=\dE[\dot{\bfo}_\tau \mid \bfo_\tau=\bfo]=\dot{\alpha}_\tau\dE[\bfo_1 \mid \bfo_\tau=\bfo]+\dot{\sigma}_\tau \dE[\bfeps \mid \bfo_\tau=\bfo]$. The goal is to learn a parametric model $\Bv_{\theta}(\bfo, \tau)$, s.t., $\int_0^1 ||\dE[\Bv_{\theta}(\bfo_\tau, \tau)-\dot{\alpha}_\tau\bfo_1-\dot{\sigma}_\tau \bfeps||^2]\;d\tau$ is minimized.

Within the stochastic interpolants framework, we identify $\bfo_1$ with a whole trajectory $\bfZ=\bfZ^{[0\colon T-1]}=[\bfZ^{[0\colon T_o-1]}, \bfZ^{[T_o\colon T-1]}] \in \dR^{T \times L \times D_z}$. Since the generated trajectories should be conditioned on latent representations of initial time frames $\bfZ^{[0\colon T_o-1]}$, we extend $\Bv_{\theta}$ with a conditioning argument $\bfC \in \dR^{T \times L \times D_z}$, making it effectively a conditional vector field $\Bv_{\theta} \colon \dR^{T \times L \times D_z} \times [0,1] \times \dR^{T \times L \times D_z} \mapsto \dR^{T \times L \times D_z}$. The tensor structure of $\bfC$ is the same as the one for $\bfZ$. For the first time steps, both tensors have equal values, i.e., $\bfC^{[0\colon T_o-1]}=\bfZ^{[0\colon T_o-1]}$. The remaining tensor entries $\bfC^{[T_o\colon T-1]}$ are filled up with mask tokens. The structure of $\bfC$ is visualized in the left part of \cref{fig:conditioning}.

From a practical point of view, we did not make direct use of implementing $\Bv_\theta$, but instead reparameterize a data prediction model $\Bo_{\theta} \colon \dR^{T \times L \times D_z} \times [0,1] \times \dR^{T \times L \times D_z} \mapsto \dR^{T \times L \times D_z}$ with the aim to have small differences $\|\Bo_{\theta}(\bfo_\tau,\tau,\bfC) - \bfo_1\|^2 $, i.e., $\Bo_\theta$ should directly learn to predict $\bfZ$ instead of predicting a velocity vector field $\Bv$ directly. To be able to use $\Bo_\theta$, we employ a reparametrization according to \citet{kingma2024understanding} (details in \cref{subsec:si_parametrizations}).

The backbone of $\Bo_{\theta}$ consists of alternating attention blocks that operate across the latent dimension $L$ and the time dimension $T$, the architecture follows a similar principle as DiT~\citep{peebles2023scalable} (see. \Cref{sec:model_architecture}). 




\begin{figure}[ht]
\vskip 0.2in
\begin{center}
\centerline{\includegraphics[width=.95\columnwidth]{figures/conditioning}}
\caption{\textbf{Left:} The latent model receives conditioning information, through a configuration of known tokens (observed timesteps) and mask tokens (the tokens to be predicted). The example illustrates conditioning on a single timeframe to predict three future timeframes. \textbf{Right:} ID-based decoding, the predicted latent vectors are decoded using assigned IDs. For example, when IDs are assigned to individual atoms, we can track the atom's position across the predicted timesteps.
}
\label{fig:conditioning}
\end{center}
\vskip -0.2in
\end{figure}


\begin{table*}[htp]
    \caption{\textbf{Method comparison at pedestrian motion forecasting.} Methods have to predict locations of pedestrian given 8 time frames as input. The first 
    column provides the method name and the further columns
    different scenes. In the cells the metrics minADE/minFDE on pedestrian movement forecasting across 20 frames are reported.
    }
    \vskip 0.15in
    \centering
    \label{tab:ped_traj}
    
    \resizebox{0.92 \textwidth}{!}{%
    \begin{threeparttable}
    \begin{tabular}{lcccccc}
    \toprule
          & \multicolumn{1}{c}{ETH} & \multicolumn{1}{c}{Hotel} & \multicolumn{1}{c}{Univ} & \multicolumn{1}{c}{Zara1} & \multicolumn{1}{c}{Zara2} & \multicolumn{1}{c}{Average} \\
    \midrule
    Linear\tnote{a} & 1.07/2.28    &  0.31/0.61      &   0.52/1.16    &  0.42/0.95    &   0.32/0.72     & 0.53/1.14  \\
    SGAN~\cite{gupta2018social}\tnote{a}  & 0.64/1.09      &   0.46/0.98    &   0.56/1.18    &  0.33/0.67     &  0.31/0.64     & 0.46/0.91 \\
    SoPhie~\cite{sadeghian2019sophie}\tnote{a} & 0.70/1.43      &   0.76/1.67 &   0.54/1.24    &  0.30/0.63     &  0.38/0.78     & 0.54/1.15 \\
    PECNet~\cite{mangalam2020not}\tnote{a} & 0.54/0.87     &  0.18/0.24 &   0.35/0.60   &  0.22/0.39     &  0.17/\underline{0.30}    & 0.29/0.48 \\
    Traj++~\cite{salzmann2020trajectron++}\tnote{a} & 0.54/0.94      &   0.16/0.28 &   0.28/0.55   &  0.21/0.42    &  \underline{0.16}/0.32    &  \underline{0.27}/0.50 \\
    BiTraP~\cite{yao2021bitrap}\tnote{a} & 0.56/0.98      &   0.17/0.28 &   0.25/0.47  &  0.23/0.45     &  \underline{0.16}/0.33   & \underline{0.27}/0.50 \\
    MID~\cite{gu2022stochastic}\tnote{a} & 0.50/0.76      &   0.16/0.24 &   0.28/0.49  &  0.25/0.41     &  0.19/0.35   & \underline{0.27}/0.45 \\
    SVAE~\cite{xu2022socialvae}\tnote{a} &   0.47/0.76    &   \underline{0.14}/0.22    &  \underline{0.25}/\underline{0.47}     &   \textbf{0.20}/\underline{0.37}    &  \textbf{0.14}/\textbf{0.28}     &  \textbf{0.24}/0.42 \\
    GeoTDM~\citep{han2024geometric}\tnote{a} &  \underline{0.46}/\textbf{0.64}     &   \textbf{0.13}/\underline{0.21}    &  \textbf{0.24}/\textbf{0.45}     &  0.21/0.39     &  \underline{0.16}/\underline{0.30}     &  \textbf{0.24}/\textbf{0.40} \\
        \midrule
    \ourMethod (ours) &   \textbf{0.45}/\underline{0.75}     &   \textbf{0.13}/\textbf{0.19}    &  0.26/\underline{0.47}     &  \underline{0.21}/\textbf{0.35}     & 0.17 / \underline{0.30}     &  \textbf{0.24}/ \underline{0.41} \\

    \bottomrule
    
    \end{tabular}%
        \begin{tablenotes}
        \item[a] Results from \citet{han2024geometric}.
    \end{tablenotes}
    \end{threeparttable}
    }
    \vskip -0.1in
\end{table*}



\subsection{Training procedure}
The training process is structured into two stages as commonly used in latent diffusion models~\citep{rombach2022high} 
(i) \textbf{First stage}. In the first stage we train the encoding and decoding  functions $\cE_{\text{Trace}}$ and $\cD_{\text{Trace}}$ in an auto-encoding fashion, i.e., we optimize the reconstruction of the original system state representation from its latent representation well. For discrete features (e.g., atom type, residue type) we tend to use a cross-entropy loss, whereas for continuous features we use a regression loss (e.g., position, distance).  %
The loss functions for each individual task are summarized in \Cref{sec:appendix_hyperparameter}. Since our method is not equivariant w.r.t. translations or rotations, we apply random rotations and translations to the input positions. As outlined above, also the entity identifier assignment is random. %
(ii) \textbf{Second stage}. In the second stage, we freeze the encoder and train the approximator to model the temporal dynamics via the encoded latent vectors. To learn a consistent behavior over time, we pass $\bfU_\omega$ from the encoder $\cE$ to the decoder $\cD$. 


\paragraph{Latent space regularization} 
To avoid high variance latent spaces,~\citet{rombach2022high} relies on KL-reg., imposing a small KL-penalty towards a standard normal on the latent space, as used in VAE~\citep{kingma2013auto}. Recent work~\citep{zhang2024lagem} has shown that layer normalization~\citep{ba2016layer} can achieve similar regulatory effects without requiring an additional loss term and simplifying training procedure, we adapt this approach in our method (see left part of \Cref{fig:first-stage}). 


\section{Experiments}
\label{sec:experiments}


Our evaluation of \ourMethod, focused on three key aspects:
(i) \textbf{Robust generalization in diverse domains}. We 
examine \ourMethod's 
generalization in different data domains in relation to
other methods, for which we 
utilized tracking data from human motion behavior and
data from \textit{molecular dynamics} (MD) simulations.
(ii) \textbf{Temporal adaptability}. We evaluated temporal 
adaptability through various conditioning/prediction 
horizons, considering single/multi-frame conditioning and 
short/long-term forecasts; 
(iii) \textbf{Computational efficiency and scalability}. 
Finally, we assessed \ourMethod's inference time, and 
performance in relation model size. 
The subsequent sections detail our key findings, while comprehensive implementation details, additional results are in~\cref{sec:exp_details}, information on the datasets in~\cref{sec:data}. 


\paragraph{Metrics}
We utilized the Average Discrepancy Error (ADE) and the Final Discrepancy Error (FDE), defined as $\text{ADE}(\bfX, \hat{\bfX})=\frac{1}{(T-T_o)N}\sum_{t=T_o}^{T-1}\sum_{i=1}^{N}\|\bfX_i^{t} - \hat{\bfX}_i^{t} \|_2$,
$\text{FDE}(\bfX, \hat{\bfX})=\frac{1}{N}\sum_{i=1}^{N}\|\bfX_i^{T-1} - \hat{\bfX}_i^{T-1} \|_2$, capturing model performance across predicted future time steps and the model performance specifically for the last predicted frame, respectively. These metrics represent well-established evaluation criteria in forecasting~\citep{xu2023eqmotion,xu2022socialvae}.

For the MD experiments including proteins (tetrapeptides), we used 
Jensen-Shannon divergence (JSD), evaluating the distribution of 
torsion angles, considering both, backbone (BB) and side chain 
(SC) angles. In order to capture long temporal behavior, we used 
\textit{Time-lagged Independent Component Analysis} 
(TICA)~\citep{perez2013identification}, focusing on the slowest 
components TIC 0 and TIC 1. To investigate metastable state 
transitions we make use of \textit{Markov State Models} 
(MSMs)~\citep{prinz2011markov,noe2013projected}.

For inference time and scalability we assessed the \textit{number 
of function evaluations} (NFE), and report performance of our 
method for different parameter sizes. 
    
\subsection{Pedestrian movement} 
\label{sec:experiment_pedestrian}

\paragraph{Experimental setup}
For human motion behavior, we first considered the ETH-UCY 
dataset~\citep{pellegrini2009you,lerner2007crowds}, which provides 
pedestrian movement behavior, over five different scenes: ETH, 
Hotel, Univ, Zara1 and Zara2. 
We used the same setup 
as~\citet{han2024geometric,xu2023eqmotion,xu2022socialvae}, 
in which the methods obtain the first 8 frames as input
and have to predict the next 12 frames. We report the minADE/
minFDE, computed across 20 sampled trajectories.

\paragraph{Compared methods}
We compared \ourMethod to eight state-of-the-art generative 
methods covering different model categories, including: GANs : 
SGAN~\citep{gupta2018social}, SoPhie~\citep{sadeghian2019sophie}; 
VAEs: PECNet~\citep{mangalam2020not}, Traj+
+~\citep{salzmann2020trajectron++}, BiTrap~\citep{yao2021bitrap}, 
SVAE~\citep{xu2022socialvae}; diffusion models: 
MID~\citep{gu2022stochastic} and GeoTDM~\citep{han2024geometric} 
and a Linear baseline. The baseline methods predominantly target 
pedestrian trajectory prediction, with GeoTDM and Linear being the 
exceptions.

\paragraph{Results}
As shown in~\Cref{tab:ped_traj}, our model performs 
competitively across all five scenes, achieving lower 
minFDE for Zara1 and Hotel scene, and lower minADE on the 
ETH scene. Notably, in contrast to compared baselines,
we did not create additional features like velocity and 
acceleration or imply any kind of connectivity between 
entities. In terms of computational efficiency, \ourMethod
required only 10 NFE using Euler integration, 
compared to 100 NFE in GeoTDM.



\subsection{Player movement in basketball}
\label{sec:experiment_basketball}
\begin{table}
\caption{\textbf{Method comparison at forecasting 
player positions in basketball games.} 
Compared methods have to predict player positions 
for 12 frames and are given the initial 8 frames as input.
The first column provides the method name, the consecutive
columns the performance at Rebounding and Scoring 
scenes in terms of the metrics minADE/minFDE.}
\label{tab:results_basketball}
\vskip 0.15in
\begin{center}

\resizebox{\columnwidth}{!}{
\begin{threeparttable}
\begin{tabular}{lccc}
\toprule
  & Rebounding & Scoring \\
\midrule
Linear\tnote{a} & 2.14/5.09 & 2.07/4.81 \\
Traj++~\citep{salzmann2020trajectron++}\tnote{a} & 0.98/1.93 & 0.73/1.46 \\
BiTraP~\citep{yao2021bitrap}\tnote{a} & 0.83/1.72 & 0.74/1.49 \\
SGNet-ED~\citep{wang2022stepwise}\tnote{a} & \underline{0.78}/1.55 & 0.68/1.30 \\
SVAE~\citep{xu2022socialvae}\tnote{a} & \textbf{0.72}/\textbf{1.37} & \textbf{0.64}/\underline{1.17} \\
\midrule
\ourMethod (ours) & 0.79/\underline{1.42} & \textbf{0.64}/\textbf{1.09} \\
\bottomrule
\end{tabular}
\begin{tablenotes}
        \item[a] Results from \citet{xu2022socialvae}.
\end{tablenotes}
\end{threeparttable}
}

\end{center}
\vskip -0.1in
\end{table}


\paragraph{Experimental setup}
Our second method comparison for human motion forecasting 
was performed for prediction of player movement in basketball games.
We used the SportVU NBA movement dataset~\citep{Yue2014}, 
which captures player movements during games from 2015-2016 basketball season. 
Each recorded frame included ten player positions (5 for each team) 
and the ball position, and two different scenarios are considered: 
a) \emph{Rebounding:} contains scenes involving missed shots, and players position themselves to secure the ball; 
b) \emph{Scoring:} contains scenes involving a team scoring a basket.
The interaction patterns -- both in frequency and in their adversarial versus cooperative dynamics -- 
exhibit different challenges as those in~\Cref{sec:experiment_pedestrian}.
The evaluation procedure by~\citet{xu2022socialvae}, which we used, 
provides 8 frames as input conditioning and
the consecutive 12 frames for prediction. The performances is reported
by the minADE/minFDE metrics, which are 
computed across 20 sampled trajectories, 
and only the player positions, but not the ball position, 
is considered in the metric calculation.

\paragraph{Compared methods.}
The method comparison for this human motion forecasting task includes
methods based on VAEs, Traj++~\citep{salzmann2020trajectron++}, 
BiTrap~\citep{yao2021bitrap}, SGNet-ED~\citep{wang2022stepwise}, SVAE~\citep{xu2022socialvae}, and a linear baseline.

\paragraph{Results}
As illustrated in~\Cref{tab:results_basketball}, 
our model shows robust performance across both scenarios, Rebounding and Scoring.
For the Scoring scenario, \ourMethod achieves parity with SocialVAE~\citep{gupta2018social} 
in terms of minADE and surpassing the performance in terms of minFDE. 
In the Rebounding scenario, we observed 
comparable but slightly lower performance of \ourMethod compared to SocialVAE.




\subsection{Small molecules}
\label{sec:experiment_md17}


\begin{table*}[t]
\caption{\textbf{Method comparison at forecasting MD trajectories of small molecules}. Compared methods have to predict atom positions of 20 frames, conditioned on 10 input frames. Results in terms of ADE/FDE, averaged over 5 sampled trajectories.}
\label{tab:results_md17}
\vskip 0.15in
  \centering
  \small
    \setlength{\tabcolsep}{3pt}

    \resizebox{1.0\linewidth}{!}{
    \begin{threeparttable}
    \begin{tabular}{lcccccccccccccccc}
    \toprule
          & \multicolumn{2}{c}{Aspirin} & \multicolumn{2}{c}{Benzene} & \multicolumn{2}{c}{Ethanol} & \multicolumn{2}{c}{Malonaldehyde} & \multicolumn{2}{c}{Naphthalene} & \multicolumn{2}{c}{Salicylic} & \multicolumn{2}{c}{Toluene} & \multicolumn{2}{c}{Uracil} \\
     \cmidrule(lr){2-3}\cmidrule(lr){4-5}\cmidrule(lr){6-7}\cmidrule(lr){8-9}\cmidrule(lr){10-11}\cmidrule(lr){12-13}\cmidrule(lr){14-15}\cmidrule(lr){16-17}
          & \multicolumn{1}{c}{ADE} & \multicolumn{1}{c}{FDE} & \multicolumn{1}{c}{ADE} & \multicolumn{1}{c}{FDE} & \multicolumn{1}{c}{ADE} & \multicolumn{1}{c}{FDE} & \multicolumn{1}{c}{ADE} & \multicolumn{1}{c}{FDE} & \multicolumn{1}{c}{ADE} & \multicolumn{1}{c}{FDE} & \multicolumn{1}{c}{ADE} & \multicolumn{1}{c}{FDE} & \multicolumn{1}{c}{ADE} & \multicolumn{1}{c}{FDE} & \multicolumn{1}{c}{ADE} & \multicolumn{1}{c}{FDE} \\
    \midrule
    RF~\citep{kohler2019equivariant}\tnote{a}    &  0.303    &  0.442     &  0.120     &  0.194     &  0.374     &   0.515    &  0.297     & 0.454      &  0.168    & 0.185      & 0.261     &  0.343     &  0.199     &  0.249     & 0.239      & 0.272 \\
    TFN~\citep{thomas2018tensor}\tnote{a}   &   0.133    &  0.268     &  0.024     &  0.049     &  0.201    &   0.414    &  0.184   &  0.386     & 0.072     & 0.098      &  0.115    &  0.223     &   0.090   & 0.150     &   0.090    & 0.159 \\
    SE(3)-Tr.~\citep{fuchs2020se}\tnote{a} &   0.294   &  0.556    &   0.027    &  0.056     &  0.188     &  0.359     &  0.214    &  0.456     &  0.069    &  0.103    &   0.189   &  0.312     &   0.108    &  0.184     &  0.107     & 0.196 \\
    EGNN~\citep{satorras2021en}\tnote{a}  &  0.267   & 0.564     &  0.024    & 0.042 &  0.268    & 0.401  &  0.393   &  0.958     &   0.095    &  0.133     &  0.159     &  0.348     &  0.207     &  0.294     & 0.154      & 0.282 \\
    EqMotion~\citep{xu2023eqmotion}\tnote{a}  &  0.185   & 0.246     &  0.029    & 0.043 &  0.152   & 0.247   &  0.155   &  0.249     &   0.073    &  0.092     &  0.110     &  0.151    &  0.097    &  0.129    & 0.088     & 0.116 \\
    SVAE~\citep{xu2022socialvae}\tnote{a}  & 0.301    &  0.428    &   0.114    &   0.133    &  0.387     &  0.505    &  0.287     &  0.430     & 0.124      &  0.135     &  0.122    &  0.142     &  0.145     &  0.171     &    0.145   & 0.156 \\
    GeoTDM~\citep{han2024geometric} \tnote{a} &   \underline{0.107}  &  \underline{0.193}     &   \underline{0.023}    &  \underline{0.039}    &  \underline{0.115}    & \underline{0.209}      &   \underline{0.107}   &  \underline{0.176}    &  \underline{0.064}     &   \underline{0.087}    &  \underline{0.083}     &   \underline{0.120}   &  \underline{0.083}    &  \underline{0.121}    &    \underline{0.074}   & \underline{0.099} \\
    \midrule
    \ourMethod (ours) & 
    \textbf{0.059} &  \textbf{0.098} & \textbf{0.021} &  \textbf{0.032} & \textbf{0.087} &  \textbf{0.167} &  \textbf{0.073} & \textbf{0.124} &  \textbf{0.037} & \textbf{0.058} &  \textbf{0.047} &  \textbf{0.074} & \textbf{0.045} &  \textbf{0.075} & \textbf{0.050} &  \textbf{0.074} \\
    \bottomrule
    \end{tabular}%
    \begin{tablenotes}
        \item[a] Results from \citet{han2024geometric}.
    \end{tablenotes}
    \end{threeparttable}
    }

  \vskip -0.1in
\end{table*}%





\paragraph{Experimental setup}
To assess the performance of \ourMethod against several state-of-the-art methods, we also used the
MD17~\cite{chmiela2017machine} dataset, 
which contains the 
simulated molecular dynamics trajectories 
of 8 small molecules. 
The size of those molecules ranges from 
9 atomes (Ethanol and Malonaldehyde) to 21 atoms(Aspirin). 
In line with~\citet{han2024geometric}, we used 10 
conditioning frames 
and 20 frames for prediction and 
report ADE/FDE averaged over $K=5$ runs.

\paragraph{Compared methods}
We compared seven different methods to \ourMethod, including six g-equivariant GNN based methods: TFN~\citep{thomas2018tensor}, RF~\citep{kohler2019equivariant}, SE(3)-Tr.~\citep{fuchs2020se}, EGNN~\citep{satorras2021en},  EqMotion~\citep{xu2023eqmotion}, GeoTDM~\citep{han2024geometric}, 
and a non-equivariant method: SVAE~\citep{xu2022socialvae}.

\paragraph{Results}
The results in~\Cref{tab:results_md17} show the 
performance on the MD17 benchmark. 
\ourMethod achieves the lowest ADE/FDE 
of all methods and for all molecules. 
These results are particularly remarkable considering that: 
(1) our model operates without incorporating molecular bond 
information, and 
(2) it surpasses the performance of all equivariant baselines, an 
inductive bias we intentionally omitted in \ourMethod.

Notably, we train a single model on all molecules -- a feat that is structurally encouraged by the design of \ourMethod. For ablation, we also trained  GeoTDM~\cite{han2024geometric} on all molecules and evaluated the 
performance on each one of them (``all$\rightarrow$each'' in the 
Appendix~\Cref{tab:results_md17_ablation}). Interestingly, we also observe 
consistent improvements in the GeoTDM performance; 
however, GeoTDM's performance does not reach the one of \ourMethod. 
Furthermore, whereas GeoTDM requires 1000 integration steps in their diffusion 
process, our model achieves the reported performance with 10 Euler 
integration steps, demonstrating strongly improved 
computational efficiency.
We also note that our latent space model is trained 
for 2000 epochs, while GeoTDM was trained for 5000 epochs. 
Trajectories 
are shown %
in the App.~\Cref{fig:md17_traj_example}.


\subsection{Tetrapeptides (4AA)}
\label{sec:experiment_tetrapeptides}

\paragraph{Experimental setup}
For long prediction horizons,
we utilized a tetrapeptide dataset~\cite{jing2024generative}, 
which contains explicit-solvent molecular dynamics trajectories 
simulated using OpenMM~\citep{eastman2017openmm}. The dataset 
comprises 3,109 training, 100 validation and 100 test peptides. 
We used a single conditioning frame to predict 
10,000 consecutive frames. The predictions are structured as a 
sequence of ten cascading 1,000-step rollouts, where each 
subsequent rollout is conditioned on the final frame of the 
previous. Note that, in contrast to the MD17 dataset,
the methods predict trajectories of \emph{unseen} molecules. 

\paragraph{Compared methods}
We compared \ourMethod to the recently proposed method
MDGen~\citep{jing2024generative} which is geared towards
protein MD simulation, and to a replicate of 
the ground truth MD simulation as a baseline.

\paragraph{Results}
\Cref{tab:results_tetrapeptide} shows performance metrics 
of the methods (see above; 
for details on those metrics, Sec.~\ref{sec:appendix_experimental_details}).  
\Cref{fig:10_4AA_examples} shows the distribution of backbone torsions angles, and the free energy surfaces of the first two TICA components, for ground truth vs simulated trajectories. \ourMethod performs competitively with the current state-of-the-
art method MDGen with respect to torsion angles, 
which is a notable achievement given that 
MDGen operates in torsion space only. With respect to the TICA and
MSM metrics, \ourMethod even outperforms MDGen. 


\subsection{Analysis of scaling behavior}
We performed experiments in which we 
analyzed the dependence of the performance of \ourMethod 
on the number of parameters. The results indicate 
that the performance consistently 
increases with parameter count
(see~\cref{sec:additional_results}).

\begin{table}[t]
\caption{\textbf{Method comparison for predicting MD trajectories
of tetrapeptides}. The first column denotes the method. The 
following columns denote the JSD
between distributions of \emph{torsion angles}, 
backbone (BB), side-chain (SC), and all,
the TICA, and the MSM metric. 
\ourMethod
performs best w.r.t. to 4 out of 6 metrics.}
\label{tab:results_tetrapeptide}
\vskip 0.15in

\resizebox{\columnwidth}{!}{
\begin{threeparttable}
\begin{tabular}{lcccccccc}
\toprule
& \multicolumn{3}{c}{Torsions} & \multicolumn{2}{c}{TICA} & \multicolumn{1}{c}{MSM} & \multicolumn{1}{c}{Time} \\\cmidrule(lr){2-4}\cmidrule(lr){5-6} & BB & SC & All & 0 & 0,1 joint & & \\
\midrule
100ns \tnote{a} & .103 & .055 & .076 & .201 & .268 & .208 & $\sim3$h \\
\midrule
MDGen\tnote{a} & .130 & \textbf{.093} & \textbf{.109} & .230 & .316 & .235 & $\sim60$s \\
\midrule
\ourMethod & \textbf{.128} & .122 & .125 & \textbf{.227} & \textbf{.315} & \textbf{.224} & $\sim53$s \\
\bottomrule
\end{tabular}
\begin{tablenotes}
    \item[a] Results from \citet{jing2024generative}.
\end{tablenotes}
\end{threeparttable}
}
\vskip -0.1in
\end{table}

\section{Conclusion}
We have introduced \ourMethod, which combines the advantages of GNNs and latent space models. 
Its novel \emph{entity structure preservation module} uses ID 
embeddings to retrieve entity positions in latent space. Across 
diverse domains, \ourMethod matches or exceeds specialized 
methods, and offers efficiency, cross-task information-sharing, 
and promising scalability. Its minimal reliance on prior 
knowledge makes \ourMethod suitable for many tasks, e.g., 
pedestrian or molecule trajectory prediction, suggesting its 
potential as a foundational system dynamics architecture (see 
\cref{appsec:relatedwork}).

\textbf{Limitations.} \ourMethod 
has yet to be tested for domains not yet treated in this work. 
While we observe longer training times compared to other methods, 
\ourMethod is highly efficient at inference and its complexity
does not scale quadratically with entities. 



\section*{Author Contributions}
F.S. conceived the idea of node entity encoding, implemented the model, ran the experiments, and wrote the first version of the manuscript. A.T. helped with the experimental setup and ran GeoTDM experiments. A.F. helped with the latent space model setup. G.K., A.M., and J.B. supervised the project from conception to design of experiments and analysis of the results. All authors contributed to the manuscript.


\bibliography{refs}
\bibliographystyle{icml2025}


\newpage
\appendix
\onecolumn

\counterwithin{figure}{section}
\counterwithin{table}{section}
\counterwithin{equation}{section}
\renewcommand\thefigure{\thesection\arabic{figure}}
\renewcommand\thetable{\thesection\arabic{table}}
\renewcommand\theequation{\thesection.\arabic{equation}}






\section{Notation}
\label{notation}\label{sec:notation}






\begin{table}[H]
\centering
\caption{Overview of used symbols and notations}
\label{tab:notation}
\vskip 0.15in

\begin{tabular}{l l l}
\toprule
Definition & Symbol/Notation & Type  \\ 
\midrule
continuous time & $\hat t$ & $\dR$\\
overall number of (sampled) time steps & $T$ & $\dN$ \\
number of observed time steps (when predicting later ones) & $T_o$ & $0\,..\,T\negthickspace-\negmedspace1$ \\
time index for sequences of time steps&  $t$ & $0\,..\,T\negthickspace-\negmedspace1$\\
\midrule
system state space & $\cS$ & application-dependent set, to be further defined\\
system state & $\Bs$ & $\cS$\\
randomness & $\omega$ & $\Omega \equiv \text{pool of randomness}$ \\
\midrule
entity & $e$ & symbolic\\
number of entities & $N$ & $\mathbb{N}$ \\
entity index & $i$, $n$ & $1\,..\,N$\\
spatial entity dimensionality & $D_{x}$ & $\dN$ \\
entity feature dimensionality & $D_{m}$ & $\dN$ \\
entity location (coordinate) & $\bfx$ & $\dR^{D_x}$ \\
entity properties (entity features) & $\bfm$ & $\dR^{D_m}$ \\
global scene feature dimensionality & $D_{g}$ & $\dN$ \\
global properties (scene features) & $\bfg$ & $\dR^{D_g}$ \\
identifier representation dimensionality & $D_{u}$ & $\dN$ \\
\midrule
number of latent vectors used & $L$ & $\mathbb{N}$ \\
latent vector dimensionality & $D_{z}$ & $\dN$ \\
\midrule
trajectory of a system (locations of entities over time)  & $\bfX$ & $\dR^{T_o \times N \times D_x}$ \\
entity locations at $t$ & $\bfX^{t}$ & $\dR^{N \times D_x}$ \\
entity $i$ of trajectory at $t$  & $\bfX^{t}_i$ & $\dR^{D_x}$ \\
trajectory in latent space & $\bfZ$ & $\dR^{T_o \times L \times D_z}$ \\
latent system state at $t$ & $\bfZ^{t}$  & $\dR^{L \times D_z}$ \\
time invariant features of entities & $\bfM$ & $\dR ^{N \times D_m}$ \\
matrix of identifier embeddings & $\bfU_\omega$ & $\dR ^{N \times D_u}$ \\
projection matrices & $\mathbf{Q}, \mathbf{K}, \mathbf{V}$ & not specified; depends on number of heads etc. \\
\midrule
encoder & $\cE(.)$ & $\dR^{N \times (D_u + D_x + D_m)} \mapsto \dR^{L \times D_z}$  \\
decoder & $\cD(.)$ &  $\dR^{L \times D_z} \times \dR^{N \times D_u} \mapsto \dR^{N \times (D_x+D_m)}$ \\
approximator (time dynamics model) & $\mathcal A(.)$ & $\dR^{T \times L \times D_z} \mapsto \dR^{T \times L \times D_z}$\\ 
loss function & $\mathcal L(.,.)$ &  var.\\
\midrule
time parameter of the flow-based model & $\tau$ & $[0,1]$\\
noise distribution & $\bfo_0$ & $\dR^{T \times L \times D_z}$\\
de-noised de-masked trajectory & $\bfo_1 = \bfZ$ &  $\dR^{T \times L \times D_z}$\\
flow-based model "velocity prediction" (neural net) & $\Bv_{\theta}(\bfo_{\tau}, \tau)$ & $\dR^{T \times L \times D_z}\times \dR \mapsto \dR^{T \times L \times D_z}$  \\
flow-based model "data prediction" (neural net) & $\Bo_{\theta}(\bfo_{\tau}, \tau)$ & $\dR^{T \times L \times D_z}\times \dR \mapsto \dR^{T \times L \times D_z}$ \\
neural network parameters & $\theta$ & undef. \\
\bottomrule

\end{tabular}
\vskip -0.1in
\end{table}










\clearpage
\section{Details on the \ourMethod Model Architecture}
\label{sec:model_architecture}

\subsection{Encoder and Decoder Functions}

We provide pseudocode of the forward passes for encoding ($\mathcal{E}_{\text{Trace}}$) to and decoding ($\mathcal{D}_{\text{Trace}}$) from the latent system space of \ourMethod in \cref{algEnc} and \cref{algDec} respectively. In general, encoder and decoder blocks follow the standard Transformer architecture~\citep{vaswani2017attention} with feedforward and normalization layers. To simplify the explanation, we omitted additional implementation details here and refer readers to our provided source code.

\begin{algorithm}[h!]
\caption{(Cross-Attention) Encoder Function $\mathcal{E}_{\text{Trace}}$ \label{algEnc}}
\begin{algorithmic}
\STATE {\bfseries Input:} input data $\bfX\bfM\bfU=[\bfX, \bfM, \bfU_\omega] \in \dR^{N \times (D_x + D_m + D_u)}$
\STATE {\bfseries Output:} latent system state $\bfZ \in \dR^{L \times D_z}$
\STATE {\bfseries Additional Internal Encoder Weights:} learned latent queries $\bfZ_{\text{init}} \in \dR^{L \times D_z}$
\STATE $\bfK = \text{Linear}(\bfX\bfM\bfU)$ 
\STATE $\bfV = \text{Linear}(\bfX\bfM\bfU)$ 
\STATE $\bfQ = \text{Linear}(\bfZ_{\text{init}})$
\STATE \textbf{return} $\text{LayerNorm}(\text{Attention}(\bfQ, \bfK, \bfV))$ // without affine transformation
\end{algorithmic}
\end{algorithm}

\begin{algorithm}[h!]
\caption{(Cross-Attention) Decoder Function $\mathcal{D}_{\text{Trace}}$ \label{algDec}}
\begin{algorithmic}
\STATE {\bfseries Input:} latent system representation $\bfZ \in \dR^{L \times D_z}$, entity representation $\bfu \in \dR^{D_u}$ from $\bfU_\omega \in \dR^{N \times D_u}$
\STATE {\bfseries Output:} $[\bfx,\bfm] \in \dR^{D_x + D_m}$
\STATE $\bfZ = \text{LayerNorm}(\bfZ)$ // without affine transformation
\STATE $\bfK = \text{Linear}(\bfZ)$ 
\STATE $\bfV = \text{Linear}(\bfZ)$ 
\STATE $\bfq = \text{Linear}(\bfu)$
\STATE \textbf{return} $\text{Attention}([\bfq], \bfK, \bfV)$
\end{algorithmic}
\end{algorithm}


For the decoding functionality presented in~\Cref{algDec}, we made use of multiple specific decoder blocks depending on the actual task (e.g., for the molecules dataset, we used one decoder block for atom positions and one decoder block for atom types). 


\subsection{Latent Flow Model Architecture}

We provide pseudocode of the data prediction network $\Bo_{\theta}$ forward pass in \cref{algLFM}. The latent layer functionality is given by \cref{algLL}. The architecture of the latent layers (i.e., our flow model) is based on~\citet{dehghani2023scaling}, with the additional usage of adaptive layer norm (adaLN) \citep{perez2018film} as also used for Diffusion Transformers~\citep{peebles2023scalable}. The exact implementation is based on ParalellMLP block codes from \citet{flux2023}, which are used along the latent dimension as well as along the temporal dimension (see \Cref{fig:parallel-mlp-block}).

\begin{algorithm}[ht!]
\caption{Latent Flow Model $\Bo_{\theta}$ (data prediction network) \label{algLFM}}
\begin{algorithmic}
\STATE {\bfseries Input:} noise-interpolated data $\bfo_{\text{inter}} \in \dR^{T \times L \times D_z}$, diffusion time $\tau$ used for interpolation, conditioning $\bfC \in \dR^{T \times L \times D_z}$, conditioning mask $\bfB \in \{0,1\}^{T \times L \times D_z}$
\STATE {\bfseries Output:} prediction of original data (not interpolated with noise):
$\bfo \in \dR^{T \times L \times D_z}$
\STATE $\boldsymbol{\tau} \leftarrow \text{Embed}(\tau)$;
\STATE $\bfo = \text{Linear}(\bfo_{\text{inter}}) + \text{Linear}
(\bfC)$ + $\text{Embed}(\bfB)$
\FOR{$i=1$ {\bfseries to} $\textit{num\_layers}$}
\STATE $\bfo = \text{LatentLayer}(\bfo, \boldsymbol{\tau})$
\ENDFOR
\STATE $\alpha, \beta, \gamma = \text{Linear}(\text{SiLU}(\boldsymbol{\tau}))$
\STATE return $\bfo + \gamma \odot \text{MLP}(\alpha \odot \text{LayerNorm}(\bfo) + \beta)$
\end{algorithmic}
\end{algorithm}

\begin{algorithm}[ht!]
\caption{LatentLayer \label{algLL}}
\begin{algorithmic}
\STATE {\bfseries Input:} $\bfo \in \dR^{T \times L \times C}$, diffusion time embedding $\boldsymbol{\tau}$
\STATE {\bfseries Output:} updated $\bfo \in \dR^{T \times L \times C}$
\STATE $\bfo \pluseq \text{ParallelMLPAttentionWithRoPE}(\bfo, \boldsymbol{\tau}, \text{dim}=0)$
\STATE $\bfo \pluseq \text{ParallelMLPAttentionWithRoPE}(\bfo, \boldsymbol{\tau}, \text{dim}=1)$
\STATE return $\bfo$
\end{algorithmic}
\end{algorithm}

\begin{figure*}[ht]
\vskip 0.2in
\begin{center}
\centerline{\includegraphics[width=.95\textwidth]{figures/parallel-mlp-block}}
\caption{\textbf{Left}: LatentLayer of our method, consisting of a latent and a temporal ParallelMLP block. \textbf{Right}: Zoomed in view of the ParalellMLP block}
\label{fig:parallel-mlp-block}
\end{center}
\vskip -0.2in
\end{figure*}

Using \texttt{einops}~\cite{rogozhnikov2021einops} notation, the latent layer in~\Cref{fig:parallel-mlp-block} can be expressed as:
\begin{align*}
\bfo' &\leftarrow \texttt{rearrange}(\bfo, \; \texttt{(B L) T D} \rightarrow \texttt{(B T) L D}) \\
\bfo' &\leftarrow l_\psi^i(\bfo', t) \\
\bfo' &\leftarrow \texttt{rearrange}(\bfo', \; \texttt{(B T) L D} \rightarrow \texttt{(B L) T D}) \\
\bfo' &\leftarrow l_\phi^i(\bfo', t)
\end{align*}
with parameters sets $\psi$ and $\phi$, where for the latent block the time dimension gets absorbed into the batch dimension and for the temporal block the latent dimension gets absorbed into the batch dimension.





\clearpage
\section{Additional Information on Stochastic Interpolants}
\label{sec:addSI}


According to \citet{ma2024sit} the stochastic interpolant framework decouples the formulation of the stochastic process specified by \cref{sproc} from the forward SDE and therefore allows for more flexibility in the choosing $\alpha_t$ and $\sigma_t$. \Cref{sec:stochastic-interpolants} details $\alpha_t$ and $\sigma_t$ for a linear and a generalized variance-preserving (GVP) interpolant. \Cref{subsec:si_parametrizations} show equivalences of different parameterizations for a score network, which are according to~\citet{ma2024sit} and \citet{ kingma2024understanding}.

\subsection{Interpolants}
\label{sec:stochastic-interpolants}

\begin{align}
\text{Linear:} & \quad \alpha_\tau = \tau, & \sigma_\tau &= 1-\tau, \\
\text{GVP:} & \quad \alpha_\tau = \sin(\frac{1}{2}\pi \tau), & \sigma_\tau &= \cos(\frac{1}{2}\pi \tau),
\end{align}


\subsection{Parametrizations}

For reasons of notation clarity (to avoid confusion between $\bfo$ and $\Bo_\theta(\bfo; \tau)$), we use $\hat{\text{NN}}_\theta$ to indicate the prediction by a neural network $\text{NN}$ parameterized by $\theta$, which can either represent the prediction $\hat{E}_\theta$ of an energy-based model, the prediction $\hat{\boldsymbol{\epsilon}}_\theta$ of a noise prediction model, the prediction $\hat{\Bo}_\theta$ of a data prediction model, or, the prediction $\hat{\Bv}_\theta$ of a velocity prediction model :

\label{subsec:si_parametrizations}
\begin{align}
\hat{\Bs}_\theta(\bfo; \tau) &= -\nabla_{\bfx} \hat{E}_\theta(\bfo, \tau) &\text{(With the gradient of an energy-based model)}  \\
&= -\hat{\boldsymbol{\epsilon}}_\theta(\bfo; \tau)/\sigma_\tau &\text{(With a noise prediction model)} \\
&= -\sigma_\tau^{-2}(\bfo - \alpha_\tau\hat{\Bo}_\theta(\bfo; \tau)) &\text{(With a data prediction model)} \label{dPM} \\
&= \sigma_\tau^{-1} \frac{\alpha_\tau \hat{\Bv}_\theta(\bfo, \tau)-\dot{\alpha}_\tau\bfo}{\dot{\alpha}_\tau\sigma_\tau - \alpha_\tau\dot{\sigma}_\tau} &\text{(With a velocity prediction model)}
\end{align}

Note: In our work we learn a data prediction model $\Bo_\theta(\bfo; \tau)$. Velocity predictions $\hat{\Bv}_\theta(\bfo, \tau)$, can be obtained from  our data predictions $\hat{\Bo}_\theta(\bfo; \tau)$ as:

\begin{align}
\hat{\Bv}_\theta(\bfo, \tau)=\hat{\Bs}_\theta(\bfo; \tau)\bigg(\frac{\dot{\alpha}_\tau\sigma_\tau^2}{\alpha_\tau} -\sigma_\tau \dot{\sigma}_\tau\bigg) +\frac{\dot{\alpha}_\tau}{\alpha_\tau}\bfo
\end{align}

Here $\hat{\Bs}_\theta(\bfo; \tau)$ is as defined by \cref{dPM}.

\vspace{3cm}

\clearpage
\section{Related Work}
\label{appsec:relatedwork}

\subsection{Molecular Dynamics (MD)} \label{app:md_md}
The most fundamental concepts nowadays to describe the dynamics of molecules are given by the laws of quantum mechanics. The Schrödinger equation is a partial differential equation, that gives the evolution of the complex-valued wave function $\psi$ over time $t$: $\displaystyle i\hbar \dfrac{\partial \psi}{\partial t} = \hat{H}(t) \psi$. Here $i$ is the imaginary unit with $i^2=-1$, $\hbar$ is reduced Planck constant, and, $\hat{H}(t)$ is the Hamiltonian operator at time $t$, which is applied to a function $\psi$ and maps to another function. It determines how a quantum system evolves with time and its eigenvalues correspond to measurable energy values of the quantum system. The solution to Schrödinger's equation in the many-body case (particles $1,\ldots,N$) is the wave function $\psi(\mathbf{x}_1,\ldots,\mathbf{x}_N, t): \bigtimes_{i=1}^N \dR^3 \times \dR \rightarrow \dC$ which we abbreviate as $\psi(\left\{ \mathbf{x} \right\}, t)$. It's the square modulus $|\psi(\left\{ \mathbf{x} \right\}, t)|^2=\psi^*(\left\{ \mathbf{x} \right\}, t) \psi(\left\{ \mathbf{x} \right\}, t)$ is usually interpreted as a probability density to measure the positions  $\mathbf{x}_1,\ldots,\mathbf{x}_N$ at time $t$, whereby the normalization condition $\int \ldots \int |\psi(\left\{ \mathbf{x} \right\}, t)|^2 d\mathbf{x}_1 \ldots d\mathbf{x}_N=1$ holds for the wave function $\psi$.

Analytic solutions of $\psi$ for specific operators $\hat{H(t)}$ are hardly known and are only available for simple systems like free particles or hydrogen atoms. In contrast to that are proteins with many thousands of atoms. However, already for much smaller quantum systems approximations are needed. A famous example is the Born–Oppenheimer approximation, where the wave function of the multi-body system is decomposed into parts for heavier atom nuclei and the light-weight electrons, which usually move much faster. In this case, one obtains a Schrödinger equation for electron movement and another Schrödinger equation for nuclei movement. A much faster option than solving a second Schrödinger equation for the motion of the nuclei is to use the laws from classical Newtonian dynamics. The solution of the first Schrödinger equation defines an energy potential, which can be utilized to obtain forces $\mathbf{F}_i$ on the nuclei and to update nuclei positions according to Newton's equation of motion: $\mathbf{F}_i=m_i \ \ddot{\mathbf{q}}_i(t)$ (with $m_i$ being the mass of particle $i$ and $\mathbf{q}_i(t)$ describing the motion trajectory of particle $i$ over time $t$).

Additional complexity in studying molecule dynamics is introduced by environmental conditions surrounding molecules. Maybe the most important is temperature. For bio-molecules it is often of interest to assume that they are dissolved in water. To model temperature, a usual strategy is to assume a system of coupled harmonic oscillators to model a heat bath, from which Langevin dynamics can be derived \citep{ford1965statistical, zwanzig1973nonlinear}. The investigation of the relationship between quantum-mechanical modeling of heat baths and Langevin dynamics still seems to be a current research topic, where there there are different aspects like the coupling of the oscillators or Markovian properties when stochastic forces are introduced. For instance, \citet{hoel2019classical}, studies how canonical quantum observables are approximated by molecular dynamics. This includes the definition of density operators, which behave according to the quantum Liouville-von Neumann equation. 

The forces in molecules are usually given as the negative derivative of the (potential) energy: $\mathbf{F}_i=- \nabla E$. In the context of molecules, $E$ is usually assumed to be defined by a force field, which is a parameterized sum of intra- and intermolecular interaction terms. An example is the Amber force field \citep{Ponder2003,Case2024}:
\begin{align}
E=&\sum_{\text{bonds} \ r} k_b (r-r_0)^2+\sum_{\text{angles} \ \theta} k_{\theta} (\theta-\theta_0)^2+\\ \nonumber &\sum_{\text{dihedrals} \ \phi} V_n (1+cos(n \phi - \gamma))+\sum_{i=1}^{N-1} \sum_{j=i+1}^{N} \left( \frac{A_{ij}}{R_{ij}^{12}}-\frac{B_{ij}}{R_{ij}^6}+\frac{q_i q_j}{\epsilon R_{ij}}\right)
\end{align}
Here $k_b, r_0, k_{\theta}, \theta_0, V_n, \gamma, A_{ij}, B_{ij}, \epsilon, q_i, q_j$ serve as force field parameters, which are found either empirically or which might be inspired by theory.

Newton's equations of motions for all particles under consideration form a system of ordinary differential equations (ODEs), to which different numeric integration schemes like Euler, Leapfrog, or, Verlet can be applied to obtain particle position trajectories for given initial positions and initial velocities. In case temperature is included, the resulting Langevin equations form a system of stochastic differential equations (SDEs), and Langevin integrators can be used. It should be mentioned, that it is often necessary to use very small integration timesteps to avoid large approximation errors. This, however, increases the time needed to find new stable molecular configurations.

\subsection{Relationship of \ourMethod to Graph Foundation Models}
From our perspective, \ourMethod bears a relationship to graph foundation models \citep[GFMs;][]{liu2023towards,maoposition}. \citet{bommasani2021opportunities} consider foundation models to be \textit{trained on broad data at scale} and to be \textit{adaptable to a wide range of downstream tasks}. \citet{maoposition} argue, that graphs are more diverse than natural language or images, and therefore there are quite unique challenges for GFMs. Especially they mention that \textit{ none of the current GFM have the capability to transfer across all graph tasks and datasets from all domains}. It is for sure true that \ourMethod is not a GFM in this sense. However, it might be debatable whether \ourMethod might serve as a domain- or task-specfic GFM. While we mainly focused on a trajectory prediction task and are from that point of view task-specific, we observed that our trained models can generalize across different molecules or differently taken scenes, which might seem quite remarkable given that it is common practice to train specific trajectory prediction models for single molecules or single scenes. Nevertheless, it was not our aim in this research to provide a GFM, since we believe that this would require more investigation into further domains and could also require, for instance, checking whether emergent abilities might arise with larger models and more training data \citep{liu2023towards}.









\clearpage
\section{Experimental Details}
\label{sec:exp_details}


\subsection{Employed Loss Functions}
\label{sec:appendix_losses}
This section defines the losses, which we use throughout training:

\paragraph{Position loss}
\begin{align}
\mathcal{L}_{\mathrm{pos}}(\bfX^t, \hat{\bf{X}}^t)= \frac{1}{N}\sum_{i=1}^N ||\bfX_i^t - \hat{\bfX}_i^t||_2^2
\end{align}

\paragraph{Inter-distance loss}
\begin{align}
\mathcal{L}_{\mathrm{int}}(\mathbf{X}^t, \hat{\mathbf{X}}^t)= \frac{1}{N^2}\sum_{i=1}^N \sum_{j=1}^N (D_{ij}(\mathbf{X}^t) -D_{ij}(\hat{\mathbf{X}}^t))^2
\end{align}
with
\begin{align}
    D_{ij}(\mathbf{X}^t) = ||\bfX_i^t - \bfX_j^t||_2
\end{align}

For our experiments on the tetrapeptide dataset, we employ two well-established loss functions tailored to better capture the unique geometric constraints of proteins, which are outlined below.

\paragraph{Frame Loss}
The frame loss is based on representing all residue atoms within local reference frames~\citep[][Algorithm 29]{abramson2024accurate}. This approach ensures the invariance of the loss to the protein's overall orientation. The frame loss is denoted as $D_{\mathrm{frame}}$ and is backpropagated through our network.


\paragraph{Torsion Loss}
Inspired by~\citet{jumper2021highly},  \ourMethod uses 
a torsion loss $\mathcal L_{\mathrm{tors}}$, which is backpropagated to the 
coordinates.  
















\vspace{1cm}
\subsection{Implementation details}
\paragraph{Identifiers} For the embedding of the identifiers we used a \texttt{torch.nn.Embedding}~\citep{paszke2019pytorch} layer, where we assign a random subset of the possible embeddings to the entities in each training step.

\paragraph{Latent Model} For the latent Flow Model we additionally apply auxiliary losses for the individual tasks, as shown in~\Cref{sec:appendix_hyperparameter}. Were we decode the the predicted latents and back-propagate through the frozen decoder to the latent model. 

\paragraph{Tetrapeptides}
\label{sec:impldetails_tetra}
For the experiments on tetrapeptides in~\Cref{sec:experiment_tetrapeptides}, we employ the Atom14 representation as used in AlphaFold~\citep{abramson2024accurate}. In this representation, each entity corresponds to one amino acid of the tetrapeptide, where multiple atomic positions are encoded into a single vector of dimension $D_x=3\times14$. Masked atomic positions are excluded from gradient computation during model updates. This representation is computational more efficient.

\vspace{1cm}
\subsection{Hyperparameters} \label{sec:appendix_hyperparameter}
\Cref{tab:hyper_pedestrian},~\Cref{tab:hyper_basketball},~\Cref{tab:hyper_tetrapeptides} and \Cref{tab:hyper_md17} show the hyperparameters for the individual tasks, loss functions are as defined above (\Cref{sec:appendix_losses}). For all trained models we used the AdamW~\citep{kingma2014adam,loshchilov2017fixing} optimizer and use EMA~\citep{gardner1985exponential} in each update step with a decay parameter of $\beta=0.999$.

\vspace{1cm}
\subsection{Employed Datasets}
\label{sec:data}

\paragraph{Pedestrian Movement}
The pedestrian movement dataset is accessible at \url{http://vision.imar.ro/human3.6m/description.php}, with data processing based on \url{https://github.com/MediaBrain-SJTU/EqMotion}.

\paragraph{Basketball Player Movement}
The dataset, along with its predefined splits, is available at \url{https://github.com/xupei0610/SocialVAE}. Data processing is provided in our source code.

\paragraph{Small Molecules (MD17)}
The MD17 dataset is available at \url{http://www.sgdml.org/#datasets}. Preprocessing and dataset splits follow~\citet{han2024geometric} and can be accessed through their GitHub repository at \url{https://github.com/hanjq17/GeoTDM}.

\paragraph{Tetrapeptides}
The dataset, including the full simulation parameters for ground truth simulations, is sourced from~\citet{jing2024generative} and is publicly available in their GitHub repository at \url{https://github.com/bjing2016/mdgen}.




\vspace{1cm}
\subsection{Evaluation Details}
\label{sec:appendix_experimental_details}

\paragraph{Tetrapeptides}
Our analysis of the Tetrapeptide trajectories utilized PyEMM~\citep{scherer2015pyemma} and followed the procedure as~\citep{jing2024generative}, incorporating both Time-lagged Independent Component Analysis (TICA)~\citep{perez2013identification} and Markov State Models (MSM)~\citep{husic2018markov}.

\vspace{1cm}
\subsection{Computational Resources}

Our experiments were conducted using a system with 128 CPU cores and 
2048GB of system memory. Model training was performed on 4 NVIDIA 
H200 GPUs, each equipped with 140GB of VRAM. In total, 
roughly 5000 GPU hours
were used in this work. 























\begin{table}[ht]
\caption{Hyperparameter configuration for the pedestrian movement experiments (\Cref{sec:experiment_pedestrian}).}
\label{tab:hyper_pedestrian}
\vskip 0.15in
\begin{center}
\begin{adjustbox}{max width=\linewidth, max totalheight=0.95\textheight, keepaspectratio}
\begin{tabular}{ll}
\midrule[1.5pt]
\multicolumn{2}{c}{\textbf{First Stage}} \\ \midrule[1.5pt] \midrule 
\multicolumn{2}{c}{\textbf{Network}} \\ \midrule 
\textbf{Encoder}                   &  \\ \midrule
Number of latents $L$                  & 2
                       \\
Number of entity embeddings & 8
\\
Number of attention heads                 & 2                                                       \\
Number of cross attention layers          & 1
                       \\
Dimension latents $D_z$                          & 32
                       \\
Dimension entity embedding & 128 
\\
Dimension attention head & 16
\\
\midrule
\textbf{Decoder}                   &  \\ \midrule
Number of attention heads                 & 2                                                        \\
Number of cross attention layers          & 1
                       \\
Dimension attention head & 16
\\

\midrule
\textbf{Loss}                   & \textbf{Weight} \\ 
\midrule
$\mathcal{L}_{pos}(\bfX, \hat{\bfX})$                          &  1  \\
$\mathcal{L}_{int}(\bfX, \hat{\bfX})$                          &  1  \\
\midrule
\multicolumn{2}{c}{\textbf{Training}} \\ \midrule 
Learning rate                             & 1e-4                                                     \\
Learning rate scheduler                   & CosineAnnealing(min\_lr=1e-7)  \\
Batch size                                & 256     \\
Epochs                   &                3K \\
Precision                                 & 32-Full \\

Batch size                                & 1024                                                       \\ 
\midrule[1.5pt]
\multicolumn{2}{c}{\textbf{Second Stage}} \\ 
\midrule[1.5pt] \midrule 
\multicolumn{2}{c}{\textbf{Setup}} \\ 
\midrule 
Condition    & 8 Frames \\
Prediction & 12 Frames \\
\midrule
\multicolumn{2}{c}{\textbf{Network}} \\ \midrule 
Hidden dimension                      & 128                                                      \\
Number of Layers                          & 6
                       \\
\midrule
\textbf{Auxiliary - Loss}                   & \textbf{Weight} \\ 
\midrule
$\mathcal{L}_{pos}(\bfX, \hat{\bfX})$                          &  0.25  \\
$\mathcal{L}_{int}(\bfX, \hat{\bfX})$                          &  0.25  \\       
\midrule
\multicolumn{2}{c}{\textbf{Training}} \\ \midrule
Learning rate                             & 1e-3                                                     \\
Batch size                                & 64
    \\
Epochs                   &                1K
\\
Precision                                 & BF16-Mixed 
    \\
Interpolant                                 & GVP
    \\
\midrule
\multicolumn{2}{c}{\textbf{Inference}} \\ \midrule
Integrator                               & Euler \\
ODE steps                                &  10 \\
\bottomrule
\end{tabular}
\end{adjustbox}
\end{center}
\vskip -0.1in
\end{table}

\begin{table}[ht]
\caption{Hyperparameter configuration for the basketball player movement experiments (\Cref{sec:experiment_basketball}).}
\label{tab:hyper_basketball}
\vskip 0.15in
\begin{center}
\begin{adjustbox}{max width=\linewidth, max totalheight=0.95\textheight, keepaspectratio}
\begin{tabular}{ll}
\midrule[1.5pt]
\multicolumn{2}{c}{\textbf{First Stage}} \\ \midrule[1.5pt] \midrule 
\multicolumn{2}{c}{\textbf{Network}} \\ \midrule 
\textbf{Encoder}                   &  \\ \midrule
Number of latents $L$                  & 32
                       \\
Number of entity embeddings & 11
\\
Number of attention heads                 & 2                                                       \\
Number of cross attention layers          & 1
                       \\
Dimension latents $D_z$                          & 32
                       \\
Dimension entity embedding & 128 
\\
Dimension attention head & 16
\\
\midrule
\textbf{Decoder}                   &  \\ \midrule
Latent dimension                          & 32
                       \\
Number of attention heads                 & 8                                                        \\
Number of cross attention layers          & 1
                       \\

\midrule
\textbf{Loss}                   & \textbf{Weight} \\ 
\midrule
$\mathcal{L}_{pos}(\bfX, \hat{\bfX})$                          &  1  \\
$\mathcal{L}_{int}(\bfX, \hat{\bfX})$                          &  1  \\ 
$\mathcal{L}_{CE}(\cdot,\cdot) \, - \text{Group }$         &  0.01 \\ 
$\mathcal{L}_{CE}(\cdot,\cdot) \, - \text{Team}$         &  0.01 \\ 
\midrule
\multicolumn{2}{c}{\textbf{Training}} \\ \midrule 
Learning rate                             & 1e-4                                                     \\
Learning rate scheduler                   & CosineAnnealing(min\_lr=1e-7)  
\\
Optimizer                                 & AdamW                                                    \\
Batch size                                & 16                                                       \\ \midrule[1.5pt]
\multicolumn{2}{c}{\textbf{Second Stage}} \\ 
\midrule[1.5pt] \midrule 
\multicolumn{2}{c}{\textbf{Setup}} \\ 
\midrule 
Condition    & 8 Frames \\
Prediction & 12 Frames \\
\midrule

\multicolumn{2}{c}{\textbf{Network}} \\ \midrule 
Hidden dimension $H$                      & 128                                                      \\
Number of Layers                          & 6
                       \\
\midrule
\textbf{Auxiliary - Loss}                   & \textbf{Weight} \\ 
\midrule
$\mathcal{L}_{pos}(\bfX, \hat{\bfX})$                          &  0.25  \\
$\mathcal{L}_{int}(\bfX, \hat{\bfX})$                          &  0.25  \\  
\midrule
\multicolumn{2}{c}{\textbf{Training}} \\ \midrule
Learning rate                             & 1e-3                                                     \\
Learning rate scheduler                & CosineAnnealing(min\_lr=1e-7)  \\
Batch size                     &  64 \\
Epochs                   &                500
\\
Precision                      & BF16-Mixed \\
Interpolant                                 & GVP
    \\
\midrule
\multicolumn{2}{c}{\textbf{Inference}} \\ \midrule
Integrator                               & Euler \\
ODE steps                                &  10 \\
\bottomrule
\end{tabular}
\end{adjustbox}
\end{center}
\vskip -0.1in
\end{table}

\begin{table}[ht]
\caption{Hyperparameter configuration for the small molecule (MD17) experiments (\Cref{sec:experiment_md17}).}
\label{tab:hyper_md17}
\vskip 0.15in
\begin{center}
\begin{adjustbox}{max width=\linewidth, max totalheight=0.95\textheight, keepaspectratio}
\begin{tabular}{ll}
\midrule[1.5pt]
\multicolumn{2}{c}{\textbf{First Stage}} \\ \midrule[1.5pt] \midrule 
\multicolumn{2}{c}{\textbf{Network}} \\ \midrule 
\textbf{Encoder}                   &  \\ \midrule
Number of latents $L$                  & 32
                       \\
Number of entity embeddings & 8
\\
Number of attention heads                 & 2                                                       \\
Number of cross attention layers          & 1
                       \\
Dimension latents $D_z$                          & 32
                       \\
Dimension entity embedding & 128 
\\
Dimension attention head & 16
\\
\midrule
\textbf{Decoder}                   &  \\ 
\midrule
Number of cross attention layers          & 1
                       \\
Number of attention heads                 & 2                                                        \\
Number of cross attention layers          & 16
                       \\
\midrule
\textbf{Loss}                   & \textbf{Weight} \\ 
\midrule
$\mathcal{L}_{pos}(\bfX, \hat{\bfX})$                          &  1  \\
$\mathcal{L}_{int}(\bfX, \hat{\bfX})$                          &  1  \\
$\mathcal{L}_{CE}(\cdot,\cdot) \, - \text{ Atom type}$         &  1 \\ 

\midrule
\multicolumn{2}{c}{\textbf{Training}} \\ \midrule 
Learning rate                             & 1e-4                                                                      \\
Batch size                                & 256     \\
Epochs                   &                3K \\
Precision                                 & 32-Full \\
\midrule[1.5pt]
\multicolumn{2}{c}{\textbf{Second Stage}} \\ 
\midrule[1.5pt] \midrule 
\multicolumn{2}{c}{\textbf{Setup}} \\ 
\midrule 
Condition    & 10 Frames \\
Prediction & 20 Frames \\
\midrule
\multicolumn{2}{c}{\textbf{Network}} \\ \midrule 
Hidden dimension                    & 128                                                      \\
Number of Layers                          & 6
                       \\
\midrule
\textbf{Auxiliary - Loss}                   & \textbf{Weight} \\ 
\midrule
$\mathcal{L}_{pos}(\bfX, \hat{\bfX})$                          &  0.25  \\
$\mathcal{L}_{int}(\bfX, \hat{\bfX})$                          &  0.25  \\
\midrule
\multicolumn{2}{c}{\textbf{Training}} \\ \midrule
Learning rate                             & 1e-3                                                     \\
Learning rate scheduler                & CosineAnnealing(min\_lr=1e-7)  \\
Batch size                     &  64 \\
Epochs                   &                2K
\\
Precision                      & BF16-Mixed \\
Interpolant                                 & GVP
    \\
\midrule
\multicolumn{2}{c}{\textbf{Inference}} \\ \midrule
Integrator                               & Euler \\
ODE steps                                &  10 \\
\bottomrule
\end{tabular}
\end{adjustbox}
\end{center}
\vskip -0.1in
\end{table}

\begin{table}[ht]
\caption{Hyperparameter configuration for the Tetrapeptides experiments (\Cref{sec:experiment_tetrapeptides}).}
\label{tab:hyper_tetrapeptides}
\vskip 0.15in
\begin{center}
\begin{adjustbox}{max width=\linewidth, max totalheight=0.95\textheight, keepaspectratio}
\begin{tabular}{ll}
\midrule[1.5pt]
\multicolumn{2}{c}{\textbf{First Stage}} \\ \midrule[1.5pt] \midrule 
\multicolumn{2}{c}{\textbf{Network}} \\ \midrule 
\textbf{Encoder}                   &  \\ \midrule
Number of latents $L$                  & 5
                       \\
Number of entity embeddings & 8
\\
Number of attention heads                 & 2                                                       \\
Number of cross attention layers          & 1
                       \\
Dimension latents $D_z$                          & 96
                       \\
Dimension entity embedding & 128 
\\
Dimension attention head & 16
\\

\midrule
\textbf{Decoder}                   &  \\ \midrule
Number of attention heads                 & 2                                                        \\
Number of cross attention layers          & 1
                       \\
Dimension attention head & 16
\\
\midrule
\textbf{Loss}                   & \textbf{Weight} \\ 
\midrule
$\mathcal{L}_{pos}(\bfX, \hat{\bfX})$                          &  1  \\
$\mathcal{L}_{int}(\bfX, \hat{\bfX})$                          &  1  \\
$\mathcal{L}_{frame}(\bfX, \hat{\bfX})$                         &  1  \\
$\mathcal{L}_{tors}(\bfX, \hat{\bfX})$                          &  0.1  \\
$\mathcal{L}_{CE}(\cdot,\cdot) \, - \text{Residue type}$         &  0.001 \\ 
\midrule
\multicolumn{2}{c}{\textbf{Training}} \\ \midrule 
Learning rate                             & 1e-4                                                     \\
Batch size                                & 16        \\   
Epochs                                  & 200K          \\
Precision                                 & 32-Full
    \\
\midrule[1.5pt]
\multicolumn{2}{c}{\textbf{Second Stage}} \\ 
\midrule[1.5pt] \midrule 
\multicolumn{2}{c}{\textbf{Setup}} \\ \midrule 
Condition    & 1 Frame \\
Prediction & 10,000 Frames (10x rollouts) \\
\midrule
\multicolumn{2}{c}{\textbf{Network}} \\ \midrule 
Hidden dimension                          & 384                                              
\\
Number of Layers                          & 6 \\
\midrule
\textbf{Auxiliary - Loss}                   & \textbf{Weight} \\ 
\midrule
$\mathcal{L}_{pos}(\bfX, \hat{\bfX})$                          &  0.25  \\
$\mathcal{L}_{int}(\bfX, \hat{\bfX})$                          &  0.25  \\
$\mathcal{L}_{frame}(\bfX, \hat{\bfX})$                         & 
0.25 \\
\midrule
\multicolumn{2}{c}{\textbf{Training}} \\ \midrule
Learning rate                             & 1e-3                                                     \\
Optimizer                                 & AdamW                                                    \\
Batch size                                & 64
    \\
Epochs                   &                1.5K
\\
Precision                                 & BF16-Mixed 
    \\
Interpolant                                 & GVP
    \\
\midrule
\multicolumn{2}{c}{\textbf{Inference}} \\ \midrule
Integrator                               & Dopri5~\citep{torchdiffeq} \\
ODE steps                                &  adaptive \\
\bottomrule
\end{tabular}
\end{adjustbox}
\end{center}
\vskip -0.1in
\end{table}

\clearpage
\section{Additional Results and Scaling Behavior}\label{sec:additional_results}

On the MD17 and the tetrapeptides dataset, we 
performed experiments in which we increased the number
of parameters of \ourMethod. On MD17, \ourMethod
uses 1.7M, 2.1M and 2.5M parameters, and for almost 
all molecules, the performance metrics ADE and FDE increase
with parameter count (see~\Cref{tab:results_md17_ablation}).
On the tetrapeptides dataset, \ourMethod was trained with 
configurations of 4M, 7M, 11M, and 28M parameters.
Again, all metrics consistently improve with parameter counts
(see~\Cref{tab:results_tetrapeptide_ablation}).
Overall, \ourMethod exhibits a favorable scaling behavior. 

\begin{table}[ht!]
\caption{\textbf{Method comparison at forecasting MD trajectories of small molecules}. Compared methods have to predict atom positions of 20 frames, conditioned on 10 input frames. Results in terms of ADE/FDE, averaged over 5 sampled trajectories.}
\label{tab:results_md17_ablation}
\vskip 0.15in
\begin{threeparttable}
  \centering
  \small
    \setlength{\tabcolsep}{3pt}
  
    \resizebox{1.0\linewidth}{!}{
    \begin{tabular}{lcccccccccccccccc}
    \toprule
          & \multicolumn{2}{c}{Aspirin} & \multicolumn{2}{c}{Benzene} & \multicolumn{2}{c}{Ethanol} & \multicolumn{2}{c}{Malonaldehyde} & \multicolumn{2}{c}{Naphthalene} & \multicolumn{2}{c}{Salicylic} & \multicolumn{2}{c}{Toluene} & \multicolumn{2}{c}{Uracil} \\
     \cmidrule(lr){2-3}\cmidrule(lr){4-5}\cmidrule(lr){6-7}\cmidrule(lr){8-9}\cmidrule(lr){10-11}\cmidrule(lr){12-13}\cmidrule(lr){14-15}\cmidrule(lr){16-17}
          & \multicolumn{1}{c}{ADE} & \multicolumn{1}{c}{FDE} & \multicolumn{1}{c}{ADE} & \multicolumn{1}{c}{FDE} & \multicolumn{1}{c}{ADE} & \multicolumn{1}{c}{FDE} & \multicolumn{1}{c}{ADE} & \multicolumn{1}{c}{FDE} & \multicolumn{1}{c}{ADE} & \multicolumn{1}{c}{FDE} & \multicolumn{1}{c}{ADE} & \multicolumn{1}{c}{FDE} & \multicolumn{1}{c}{ADE} & \multicolumn{1}{c}{FDE} & \multicolumn{1}{c}{ADE} & \multicolumn{1}{c}{FDE} \\
    \midrule
    RF~\cite{kohler2019equivariant}\tnote{a}    &  0.303    &  0.442     &  0.120     &  0.194     &  0.374     &   0.515    &  0.297     & 0.454      &  0.168    & 0.185      & 0.261     &  0.343     &  0.199     &  0.249     & 0.239      & 0.272 \\
    TFN~\cite{thomas2018tensor}\tnote{a}   &   0.133    &  0.268     &  0.024     &  0.049     &  0.201    &   0.414    &  0.184   &  0.386     & 0.072     & 0.098      &  0.115    &  0.223     &   0.090   & 0.150     &   0.090    & 0.159 \\
    SE(3)-Tr.~\cite{fuchs2020se}\tnote{a} &   0.294   &  0.556    &   0.027    &  0.056     &  0.188     &  0.359     &  0.214    &  0.456     &  0.069    &  0.103    &   0.189   &  0.312     &   0.108    &  0.184     &  0.107     & 0.196 \\
    EGNN~\cite{satorras2021en}\tnote{a}  &  0.267   & 0.564     &  0.024    & 0.042 &  0.268    & 0.401  &  0.393   &  0.958     &   0.095    &  0.133     &  0.159     &  0.348     &  0.207     &  0.294     & 0.154      & 0.282 \\
    \midrule
    EqMotion~\cite{xu2023eqmotion}\tnote{a}  &  0.185   & 0.246     &  0.029    & 0.043 &  0.152   & 0.247   &  0.155   &  0.249     &   0.073    &  \underline{0.092}     &  0.110     &  0.151    &  0.097    &  0.129    & 0.088     & 0.116 \\
    SVAE~\cite{xu2022socialvae}\tnote{a}  & 0.301    &  0.428    &   0.114    &   0.133    &  0.387     &  0.505    &  0.287     &  0.430     & 0.124      &  0.135     &  0.122    &  0.142     &  0.145     &  0.171     &    0.145   & 0.156 \\
    GeoTDM 1.9M\tnote{a} &   0.107   &  0.193     &   \underline{0.023}    &  \underline{0.039}    &  0.115    & 0.209      &   0.107   &  0.176    &  0.064     &   0.087    &  0.083     &   0.120   &  0.083    &  0.121    &    0.074   & \underline{0.099} \\
        GeoTDM 1.9M (all$\rightarrow$each) &  \underline{0.091}   &  \underline{0.164} & 0.024 & 0.040  &  \underline{0.104}    & \underline{0.191}      &   \underline{0.097}   &  \underline{0.164}    &  \underline{0.061}     &  \underline{0.092}    &  \underline{0.074}     &   \underline{0.114}   &  \underline{0.073}    &  \underline{0.112}    &    \underline{0.070}   & 0.102 \\
    \midrule
    \ourMethod 2.5M (ours) & \textbf{0.059} &  \textbf{0.098} &  \textbf{0.021} &  \textbf{0.032} &  \textbf{0.087} &  \textbf{0.167} &  \textbf{0.073} &  \textbf{0.124} &  \textbf{0.037} &  \textbf{0.058} &  \textbf{0.047} &  \textbf{0.074} &  \textbf{0.045} &  \textbf{0.075} &  \textbf{0.050} &  \textbf{0.074} \\
    \ourMethod 2.1M (ours) & 0.064 & 0.104 & 0.023 & 0.033 & 0.097 & 0.182 & 0.084 & 0.141 & 0.044 & 0.067 & 0.053 & 0.081 & 0.054 & 0.086 & 0.054 & 0.079 \\
    \ourMethod 1.7M (ours) & 0.074 & 0.117 & 0.025 & 0.037 & 0.110 & 0.195 & 0.097 & 0.159 & 0.053 & 0.074 & 0.063 & 0.091 & 0.064 & 0.094 & 0.064 & 0.089 \\

    \bottomrule
    \end{tabular}%
    }
    \begin{tablenotes}
        \item[a] Results from \citet{han2024geometric}.
    \end{tablenotes}
    \end{threeparttable}
  \vskip -0.1in
\end{table}%

\begin{table}[ht!]
\vskip 0.15in
\centering
\caption{\textbf{Method comparison for predicting MD trajectories
of tetrapeptides}. The first column denotes the method. The 
following columns denote the JSD
between distributions of \emph{torsion angles}, 
backbone (BB), side-chain (SC), and all,
the TICA, and the MSM metric, for different model sizes.}
\label{tab:results_tetrapeptide_ablation}
\vskip 0.15in
\resizebox{0.8\columnwidth}{!}{
\begin{threeparttable}
\begin{tabular}{lcccccccc}
\toprule
& \multicolumn{3}{c}{Torsions} & \multicolumn{2}{c}{TICA} & \multicolumn{1}{c}{MSM} & \multicolumn{1}{c}{Params} & \multicolumn{1}{c}{Time} \\\cmidrule(lr){2-4}\cmidrule(lr){5-6}
 & BB & SC & All & 0 & 0,1 joint & & (M) & \\
\midrule
100 ns\tnote{a} & .103 & .055 & .076 & .201 & .268 & .208 & & $\sim3$h \\
\midrule
MDGen\tnote{a} & .130 & \textbf{.093} & \textbf{.109} & .230 & .316 & .235 & 34 & $\sim60$s \\
\midrule
\ourMethod & \textbf{.128} & 0.122 & 0.125 & \textbf{.227} & \textbf{.315} & \textbf{.224} & 28 & $\sim53$s \\
\ourMethod & .152 & .151 & .152 & .239 & .331 & .226 & 11 & \\
\ourMethod & .183 & .191 & .187 & .26  & .356 & .235 & 7 & \\
\ourMethod & .284 & .331 & .311 & .339 & .461 & .237 & \textbf{4} & \\

\bottomrule
\end{tabular}
\begin{tablenotes}
    \item[a] Results from \citet{jing2024generative}.
\end{tablenotes}
\end{threeparttable}
}
  \vskip -0.1in
\end{table}

\begin{figure}[htbp]
\vskip 0.2in
\begin{center}
    \begin{minipage}[b]{0.49\linewidth}
        \centering
        \includegraphics[width=\linewidth]{figures/examples/5_4AA_0.pdf}
    \end{minipage}
    \hfill
    \begin{minipage}[b]{0.49\linewidth}
        \centering
        \includegraphics[width=\linewidth]{figures/examples/5_4AA_1.pdf}
    \end{minipage}
    \caption{\textbf{Torsion angle distributions} of the six backbone torsion angles, comparing molecular dynamics (MD) trajectories (orange) and sampled trajectories (blue); and \textbf{Free energy surfaces} projected onto the top two time-lagged independent component analysis (TICA) components, computed from both backbone and sidechain torsion angles.}
    \label{fig:10_4AA_examples}
\end{center}
\vskip -0.2in
\end{figure}

\clearpage
\begin{figure*}[ht]
\vskip 0.2in
\begin{center}
\centerline{\includegraphics[width=.90\textwidth]{figures/examples/md17_traj_vis.png}}
\caption{\textbf{Molecular dynamics trajectories from the MD17 dataset}, showing time-evolved structural predictions for each molecule. For every compound, we display four distinct trajectory predictions, with each prediction comprising 20 superimposed time frames to illustrate the range of conformational changes.}
\label{fig:md17_traj_example}
\end{center}
\vskip -0.2in
\end{figure*}













\end{document}
