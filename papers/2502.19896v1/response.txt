\section{Related Work}
\label{sec:related}
\subsection{Point cloud completion}
% Recent years have seen significant progress in point cloud completion. 
Early methods **Park**, "Voxel-based Point Cloud Completion"**__**Qi, "PointNet: Robust Point Cloud Feature Learning by Pairwise Learned Similarity Functions"**
,  PCN**,**Qi, "Point Cloud Completion Using Multi-Task Learning with LiDAR Sensor", directly generates high-resolution complete point clouds in a coarse-to-fine manner.
However, they are often limited by the resolution of the voxels. With the development of point-based networks like PointNet**,**Qi, "PointNet: Robust Point Cloud Feature Learning by Pairwise Learned Similarity Functions"**,  various point cloud tasks can be handled by end-to-end networks **__**Wang, "PCN++: Point Completion Network with Progressive Reconstruction and Refinement". Among them, PCN**,**Qi, "Point Cloud Completion Using Multi-Task Learning with LiDAR Sensor",  is the first work that directly generates high-resolution complete point clouds in a coarse-to-fine manner for point cloud completion.
A similar generation strategy is also adopted in a series of following works **__**Wang, "PCN++: Point Completion Network with Progressive Reconstruction and Refinement". Transformer **__**Li, "Transformer-Based Point Cloud Completion" has also been leveraged in recent works. PoinTr**,**Xu, "PoinTr: Point Cloud Transformer with Self-Attention for 3D Shape Completion", treats the point cloud as a token sequence, using transformer encoder-decoder to predict the missing parts. SnowflakeNet **__**Zhang, "SnowflakeNet: A Deep Learning Framework for Point Cloud Completion and Reconstruction" designs a transformer decoder with skip connections to refine the point cloud.
Another line of works **__**Li, "Transformer-Based Point Cloud Completion" enhances completion performance using 2D information.
% ViPC **__**Wang, "ViPC: Visual-Inertial Point Cloud Depth Estimation" takes an additional 2D image as input to provide additional color information. Following it, CSDN **__**Zhang, "CSDN: Camera-Sensor Deep Neural Network for 3D Reconstruction from RGB Images", integrates shape features from images into global features, generating finer geometric structures.
Different from the above approaches, SVDFormer **__**Li, "SVDFormer: A Novel Point Cloud Completion Approach using Self-Attention and Depth Information" and GeoFormer **__**Zhang, "GeoFormer: Geometric Feature Learning for Point Cloud Completion", project point clouds into 2D depth images, requiring information from only partial input.

Although these methods perform well on synthetic datasets, their reliance on training data causes performance degradation on out-of-distribution real-world scans and previously unseen categories. Recent unsupervised **__**Wang, "Unsupervised Point Cloud Completion with Self-Supervised Learning" and self-supervised approaches **__**Zhang, "Self-Supervised Point Cloud Completion using Temporal Consistency", have alleviated this issue to some extent; however, the completion results remain suboptimal.
% Furthermore, due to the domain gap, these methods often experience a significant drop in performance when applied to real-world scanned data. Additionally, these methods tend to work well only for the specific categories or similar categories seen during training, lacking generalization to unseen categories.
To address these limitations, SDS-Complete **__**Li, "SDS-Complete: Signed Distance Function-based Zero-Shot Point Cloud Completion" formulates point cloud completion as a test-time optimization problem, introducing a zero-shot method that fits a Signed Distance Function (SDF) to the input partial point cloud. It leverages Score Distillation Sampling (SDS) to extract 2D priors from the Stable Diffusion **__**Zhang, "Stable Diffusion: A Deep Learning Framework for Image-to-Image Translation", model to complete the missing regions. Subsequently, Huang et al. **,**Huang, "Zero-Shot Point Cloud Completion using Signed Distance Function and Score Distillation Sampling" propose initializing the partial point cloud as 3D Gaussians and distilling prior knowledge from zero123 **__**Wang, "Unsupervised Point Cloud Completion with Self-Supervised Learning". Although these methods exhibit impressive zero-shot completion capabilities, they require optimization from scratch for each incomplete point cloud, making them time-intensive. Moreover, reliance on implicit 2D diffusion priors limits the reconstruction of fine geometric details.
In this work, we leverage explicit priors from a pre-trained 3D generative model to enhance zero-shot point cloud completion quality while significantly reducing processing time.

\subsection{3D Generation}
DreamFusion **__**Zhang, "DreamFusion: A Deep Learning Framework for 2D Priors-based 3D Generation" is the first method to use 2D priors for 3D generation, introducing Score Distillation Sampling (SDS) to extract 2D priors from a pretrained diffusion model and guide the 3D generation process, inspiring numerous impressive works. Magic3D **,**Liu, "Magic3D: A Novel Deep Learning Framework for 3D Generation using Score Distillation Sampling" adopts DMTet **__**Zhang, "DMTet: A Novel Deep Learning Framework for 3D Representation Learning", as the 3D representation instead of NeRF **,**Mildenhall, "NeRF: Representing Scenes as Neural Radiance Fields" and then performs optimization using SDS. Fantasia3D **__**Zhang, "Fantasia3D: A Novel Deep Learning Framework for Decoupling Geometry and Material Properties in 3D Generation", decouples the optimization of geometry and material properties.
With the emergence of 3D Gaussian Splatting **,**Xu, "3D Gaussian Splatting: A Novel Point Cloud Representation for Fast and Accurate 3D Reconstruction", a highly expressive 3D representation, the optimization time for 3D generation with SDS has been significantly reduced. DreamGaussian **__**Wang, "DreamGaussian: A Novel Deep Learning Framework for Zero-Shot Point Cloud Completion using Gaussian Splatting", firstly attempts to use SDS optimization for 3D Gaussians, reducing the optimization time to just a few minutes while achieving excellent results. GaussianDreamer **,**Zhang, "GaussianDreamer: A Novel Deep Learning Framework for Initializing 3D Gaussians using Point Cloud Priors", initializes 3D Gaussians using point cloud priors, yielding impressive results.
% 下面两段有点重复
% Despite the remarkable performance and generalization ability of these optimization-based methods, they still require several minutes of processing time.
Although the above methods are effective, they require several minutes or even hours for optimization.
% 
The emergence of large-scale datasets **,**Wang, "Large-Scale 3D Scene Understanding: A Survey" has driven the development of faster feed-forward methods. Once trained, these methods can generate 3D objects within seconds through a single forward inference. Recently, LRM **,**Liu, "LRM: Learning to Represent Multi-View Features for 3D Generation", demonstrated that a regression model can predict a NeRF from a single image within seconds. Based on this, InstantMesh **,**Zhang, "InstantMesh: A Novel Deep Learning Framework for Fast and Accurate Mesh Reconstruction from a Single Image", generates additional multi-view images from a single image and then reconstructs the mesh. However, both methods are limited by resolution. To address this, LGM **,**Wang, "LGM: Large-Scale 3D Gaussian Model Prediction using Multi-View Features", introduces an efficient representation of multi-view Gaussian features, enabling the prediction of high-resolution 3D Gaussian models.

These feed-forward methods can generate high-quality 3D objects from a single image in a very short time while demonstrating strong generalization ability.
We are motivated to leverage this advantage for point cloud completion, aiming to achieve superior zero-shot completion results while reducing optimization time.