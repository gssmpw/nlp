\section{Related Work}
Previous deep learning approaches for sampling conformational ensembles such as \cite{noe_boltzmann2019}, where invertible neural networks are employed, or equivariant flow matching \cite{klein2023equivariant} usually require training on the specific system of interest.
For proteins, a transferable model, AlphaFlow, which relies on fine-tuning the pre-trained folding model AlphaFold 2 \cite{jumper2021highly}, has been recently proposed \cite{jing2024alphafoldmeetsflowmatching}.
While \citet{jing2024alphafoldmeetsflowmatching} also introduce a model trained on ensembles deposited in the Protein Data Bank (PDB), the scope of this work is to generate Boltzmann-sampled states and we thus focus on the AlphaFlow models trained on MD.
\citet{wang2024proteinconfdiff} propose ConfDiff, a diffusion model that relies on a pre-trained sequence representation of AlphaFold 2 and is trained on both the PDB and MD conformations.
\cite{Lewis2024-bio-emu} propose the generative model Bio-Emu with an architecture similar to AlphaFold 2 with the difference that a diffusion module is used for protein structure generation. 
Bio-Emu is trained on a large custom MD dataset, making it not directly comparable to AlphaFlow and BBFlow.
Conformational ensemble prediction was also suggested as transfer application of the recent structure design model FoldFlow++ \cite{huguet2024foldflow2}.
However, FoldFlow++ underperforms AlphaFlow, which is to be expected since it is not trained on MD data, and is thus not considered in this work.