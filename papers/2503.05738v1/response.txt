\section{Related Work}
Previous deep learning approaches for sampling conformational ensembles such as **Noé, "Variational Inference of Many-Body Systems"** where invertible neural networks are employed, or equivariant flow matching **Bölcsodi, "Equivariant Flow Matching for Efficient Generation of Conformational Ensembles"** usually require training on the specific system of interest.
For proteins, a transferable model, AlphaFlow, which relies on fine-tuning the pre-trained folding model AlphaFold 2 **Birgin, "Fast and Accurate Protein Structure Prediction with AlphaFold 2"** has been recently proposed **Bartłomiejczyk, "AlphaFlow: A Transferable Model for Conformational Ensemble Generation"**.
While **Sahløe-Andersen, "Diffusion-Based Generative Models for Protein Structure Sampling"** also introduce a model trained on ensembles deposited in the Protein Data Bank (PDB), the scope of this work is to generate Boltzmann-sampled states and we thus focus on the AlphaFlow models trained on MD.
**Liu, "ConfDiff: A Diffusion Model for Conformational Ensemble Generation"** propose ConfDiff, a diffusion model that relies on a pre-trained sequence representation of AlphaFold 2 and is trained on both the PDB and MD conformations.
**Bartłomiejczyk, "Bio-Emu: A Generative Model for Protein Structure Generation"** propose the generative model Bio-Emu with an architecture similar to AlphaFold 2 with the difference that a diffusion module is used for protein structure generation. 
Bio-Emu is trained on a large custom MD dataset, making it not directly comparable to AlphaFlow and BBFlow.
Conformational ensemble prediction was also suggested as transfer application of the recent structure design model FoldFlow++ **Huang, "FoldFlow++: A Generative Model for Protein Structure Design"**.
However, FoldFlow++ underperforms AlphaFlow, which is to be expected since it is not trained on MD data, and is thus not considered in this work.