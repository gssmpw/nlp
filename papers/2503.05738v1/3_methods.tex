\section{Method}
\label{sec:method}


In this work, we propose to decouple protein conformational ensemble generation from the structure prediction task and introduce a generative model based purely on backbone geometry that does not rely on evolutionary sequence information.
We achieve this by conditioning both the flow and the prior on the equilibrium structure of the protein.

\paragraph{Conditional flow matching for ensemble generation}
Inspired by FrameFlow ~\cite{yim2023frameflow}, a flow matching model for protein structure design, we formulate the task of protein ensemble generation as structure generation task, conditioned on the equilibrium state of the respective protein.
In particular, we express the Boltzmann distribution of a given protein as probability distribution $p(x|x_\text{eq})$ of conformations $x$, conditioned on the equilibrium state $x_\text{eq}$ of the respective protein.
In order to sample from $p(x|x_\text{eq})$, we learn a flow vector field,
\begin{equation}
\label{eq:cond_flow_vf}
v(x,t,x_\text{eq}) : \mathcal{M}\times[0,1]\times\mathcal{M}_\text{eq} \rightarrow \mathcal{T}_x\mathcal{M}\,,
\end{equation}
that receives protein equilibrium states $x_\text{eq}\in\mathcal{M}_\text{eq}$ as additional input.
This defines a conditional flow $\phi_t$ by
\begin{equation}
    \label{eqn:CNF_ODE_cond}
    \frac{\mathrm{d}}{\mathrm{d}t} \phi_t(x|x_\text{eq}) = v\left(\phi_t,t,x_\text{eq}\right), \quad
    \phi_0(x|x_\text{eq})=x \, .
\end{equation}

Crucially, by conditioning the generation not on the sequence but the equilibrium structure, we eliminate the need for evolutionary information and pre-trained folding model weights.
We note that assuming the availability of an equilibrium structure is a fair assumption because the main use-case of the model is to offer an alternative to Moleculer Dynamics simulation, which also requires an initial structure.
If only a sequence is available, both MD and BBFlow require a structure prediction first, for example with AlphaFold 2.

\paragraph{Model architecture}
In order to learn the conditional flow vector field $v_t$, we use the same model architecture as the recent protein design model GAFL~\cite{wagner2024generating}, which is an extension of the FrameDiff architecture proposed by \citet{yim2023framediff}.
The input features include
the frames $x_t$ at time $t$, their pairwise spatial distances, positional encodings of absolute and relative sequence positions, and the flow matching time $t$.
The neural network is an $\mathrm{SE}(3)$ equivariant graph neural network, which uses invariant point attention (IPA) \cite{jumper2021highly} as core element.
In GAFL, IPA is extended to Clifford frame attention (CFA), where geometric features are represented in the projective geometric algebra and messages are constructed using the bilinear products of the algebra.
Frames are consecutively updated along with node and edge features in a series of 6 message passing blocks to predict the target frames $x_1$.
Compared to Alphafold 2 \cite{jumper2021highly}, this architecture is much more shallow and operates only on structural data, hence a sequence-processing module like the Evoformer of AlphaFold 2 is not required.


\paragraph{Encoding of the equilibrium structure}
For conditioning the flow vector field as in Eq.~\ref{eq:cond_flow_vf}, we modify the architecture such that the equilibrium backbone structure of the protein can be used as input feature.
Inspired by the interpretation of evolutionary information as contact map \cite{lin2023evolutionary}, we propose to encode pairwise distances of the equilibrium state $x_\text{eq}$ as initial edge feature,
\begin{equation}
    s_{ij} \equiv \text{bin}\left(||z_i-z_j||_2\right) \, ,
\end{equation}
where we bin the distance between 0 and 20\AA\,with bin dimension 22 \cite{yim2023frameflow}.
% We also propose to directly encode the equilibrium structure in a geometrically meaningful way by including equivariant pairwise directions as unit vectors,
% \begin{equation}
%     e_{ij} \equiv r_i^{-1}\left(\frac{z_i-z_j}{||z_i-z_j||_2}\right) \, ,
% \end{equation}
% expressed in the coordinate frame $x_{i} = (r_i,z_i)$ of residue $i$.
We also propose to directly encode the equilibrium structure in a geometrically meaningful way.
Inspired by tensor-based equivariant networks \cite{schuett2021equivariant} and their formulation in terms of local frames \cite{lippmann2024tensorframes}, we include equivariant pairwise directions as unit vectors,
\begin{equation}
    e_{ij} \equiv r_i^{-1}\left(\frac{z_i-z_j}{||z_i-z_j||_2}\right) \, ,
\end{equation}
and express them in the coordinate frame $x_{i} = (r_i,z_i)$ of residue $i$.
Through the transformation into the co-rotating coordinate frame, the feature components become invariant and can be used together with $s_{ij}$ as initial edge feature.
These directional features $e_{ij}$ are not used for the final model, but their effect is investigated in our ablations.

We use amino acid identities as additional node features, by transforming a one-hot encoding via a linear layer to a 128-dimensional embedding.
The reasoning behind encoding the amino acid type is that it carries information about the local effective degrees of freedom of the backbone,
however, in an ablation we find that also without encoding the amino acid identity, the model performs remarkably well.

\paragraph{Conditional prior distribution}
Unlike diffusion models~\cite{song2020score}, where Gaussianity of the prior $p_0$ is a strict theoretical requirement, flow matching, in principle, allows the use of general prior distributions \cite{lipman2022flow}.
Non-Gaussian, unconditional prior distributions for proteins have been proposed by \citet{ingraham2023illuminating} and \citet{jing2024alphafoldmeetsflowmatching}.
We take this idea a step further and propose a \textit{conditional} prior distribution $p_0(x|x_\text{eq})$ for flow matching.
Samples $x_0\sim p_0(\cdot|x_\text{eq})$ are generated by interpolating between samples from an unconditional prior $p_\text{uncond}$ and the equilibrium structure $x_\text{eq}$,
\begin{align}
\label{eq:cond_prior_construction}
x_\text{uncond} \sim p_\text{uncond},
\quad
x_0\equiv \gamma(x_\text{uncond},x_\text{eq},\delta t),
\end{align}
where $\gamma$ is the geodesic between $x_\text{uncond}$ and $x_\text{eq}$,
\begin{equation}
    \label{eq:geodesic_prior}
    \gamma(x_\text{uncond},x_\text{eq},0) = x_\text{uncond},
    \quad
    \gamma(x_\text{uncond},x_\text{eq},1) = x_\text{eq},
\end{equation}
and $\delta t$ is a hyperparameter between 0 and 1 that quantifies how close the noise sampled from the prior is to the equilibrium structure (see Figure~\ref{fig:conditional_prior}).
In our experiments, we set $\delta t\equiv 0.2$.
For the unconditional prior distribution $p_\text{uncond}$, we use the prior from FrameFlow \cite{yim2023frameflow} -- the normal distribution for translations and the uniform distribution for rotations.

\begin{figure}
\centering
% \vspace{0.2cm}
\includegraphics[width=.48\textwidth]{figures/appendix/app_cond_prior_no_bg.png}
\vspace{-1.cm}
\caption{Construction of the conditional prior (Eq. \ref{eq:cond_prior_construction}). For a given equilibrium structure as condition $x_\text{eq}$, we sample noise $x_\text{uncond}$ from the unconditional prior $p_\text{uncond}$ and interpolate along the geodesic between $x_\text{uncond}$ and $x_\text{eq}$ (Eq. \ref{eq:geodesic_prior}) to obtain a sample $x_0$ from the proposed conditional prior $p_0(\cdot|x_\text{eq})$. In the experiments, we choose the hyperparameter $\delta t=0.2$; in the figure, we show a state sampled with $\delta t=0.5$ for better visualization.
}
\label{fig:conditional_prior}
\end{figure}

\paragraph{Loss function}
As explained in Section \ref{sec:background}, we represent protein backbone structure as a set of frames $x = (r, z) \in \mathrm{SE}(3)$ and define the flow matching process on the data manifold $\mathcal{M} \equiv \mathrm{SE}(3)^{N}$.
We learn a conditional flow vector field $\hat{v}(x_{t}, t, x_\text{eq})$ (Eq.~\ref{eq:cond_flow_vf}) on the tangent space of the data domain, parametrized by Eq.~\ref{eq:vf_parametrization}.
For regressing on this vector field, we calculate the ground truth $v$ as tangent vector to the geodesic $\gamma_\text{FM}$ between the prior sample $x_0$ and target sample $x_1$, and apply a mean squared error loss,
\begin{equation}
\mathcal{L}_{\text{FM}} = \mathbb{E}\bigg[\big\| v - \hat{v}(x_{t}, t, x_\text{eq}) \big\|^{2}_{\mathrm{SE}(3)}\bigg]\,,
\label{eq:loss}
\end{equation}
where $x_t$ is a point along the geodesic $\gamma_\text{FM}$
\begin{equation}
    x_t\equiv\gamma_\text{FM}(x_0,x_1,t)
\end{equation}
and $x_\text{eq}$ denotes the equilibrium structure used as condition.
The expectation in Eq.~\ref{eq:loss} runs over
\begin{equation}
   t\sim \mathcal{U}(0,1)\,,
   \:\:
   (x_1,x_\text{eq})\sim p_\text{data}\,,
   \:\:
   x_0\sim p_0(\cdot|x_\text{eq})\,,
\end{equation}
and the metric is defined as in \cite{yim2023framediff},
\begin{equation}
    \big\|v\big\|_{\mathrm{SE}(3)}^2
    \equiv
    \mathrm{Tr}\left(v_rv_r^T\right)/2
    +
    \big\|v_z\big\|_2^2,
\end{equation}
with the Euclidean 2-norm $\|\cdot\|_2$ and the projection on rotational and translational subspaces $v=(v_r,v_z)$.
As in \cite{yim2023frameflow}, we also use the auxiliary loss proposed in \cite{yim2023framediff}.

We note that this approach of deriving the loss function directly from the flow matching objective -- regression on the vector field $v$ -- is different from AlphaFlow \cite{jing2024alphafoldmeetsflowmatching}, where the flow matching objective is approximated by a loss function (squared $\text{FAPE}$) that acts on a predicted target structure $\hat{x}_1$.

