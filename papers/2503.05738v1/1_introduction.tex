\section{Introduction}

% FIGURE
%%%%%%%%%%%%%%%%%%%%
\begin{figure*}[h]
\centering
\includegraphics[width=1.9\columnwidth]{figures/method/BBFlow_schematic.pdf}
\vspace{-0.8cm}
\caption{Schematic representation of BBflow.
The equilibrium backbone structure $x_\text{eq}$ of an input protein is used to condition an SE(3) Flow Matching model on the generation of protein backbone conformations $x_{1}$.
Already the prior $p_0$ of the flow matching process is conditioned on the input protein via partial geodesic interpolation between pure noise and the equilibrium backbone structure.
}
\label{fig:intro}
\end{figure*}
%%%%%%%%%%%%%%%%%%%%%

% INTRODUCTION
%
% alphafold and introduction of evolutionary information since its critical for that.
% also introduce protein structure generation
In recent years, the field of protein structure prediction has been revolutionized by geometric deep learning \cite{jumper2021highly, baek2021accurate,lin2023evolutionary}.
\citet{jumper2021highly} introduced AlphaFold 2, which predicts a protein's structure using patterns found in naturally occurring protein sequences, so-called \textit{evolutionary information}, upon inference.
On the other hand, advancements in generative modeling such as diffusion \cite{song2020score} and flow-matching \cite{lipman2022flow,albergo2022building,tong2024improving} have propelled the field of protein design, where several approaches for the generation of novel protein structures have been proposed \cite{watson2023novo,yim2023framediff,bose2023se}.
Plausible protein structures conditioned on symmetry or a motif can be designed by these models, without requiring an input sequence \cite{ingraham2023illuminating,
% huguet2024foldflow2,
yim2024improved}.

% why conformational ensembles are important/introduction of MD
Both of these methods generate a single \textit{equilibrium structure} of a protein. In contrast, protein function depends on structural dynamics \cite{pacesa2024bindcraft,guo2024deep,benkovic2008free}, that is, the protein's conformational ensemble   as given by the Boltzmann distribution, assuming equilibrium.
To sample from the Boltzmann distribution, Molecular Dynamics (MD) simulations are an established method in the field \cite{Adcock2006}.
However, covering the state space extensively with MD requires long simulation times in order to satisfy ergodicity by overcoming local free energy minima, making conformational sampling often prohibitively expensive.
Recently, generative models have been suggested for emulating the sampling of MD conformations, offering inference times that are orders of magnitudes faster than MD \cite{noe_boltzmann2019}.

% introduce current approaches that rely on pretraining and evolutionary information
For proteins, current state-of-the-art approaches for such generative models rely on modifications of AlphaFold 2, where noise is introduced into the MSA \cite{wayment-steele2024predicting}, the pre-trained folding model is fine-tuned on ensemble data \cite{jing2024alphafoldmeetsflowmatching}, or the structure block is replaced by a diffusion model \cite{Lewis2024-bio-emu}.
While these approaches are capable of generating realistic conformational ensembles with high distributional accuracy, their efficiency is limited since the sampling of each state requires to predict the overall fold of the protein from the sequence.
Consequently, the models rely on processing of evolutionary information such as MSA or weights from protein language models like ESM \cite{lin2022language}. This renders the models not only expensive, but can in addition introduce artifacts for sequences where evolutionary information is scarce or, as for \textit{de novo} proteins, absent \cite{lin2023evolutionary}.

\paragraph{Main contributions}
%
% what our model can do:
In this work, we introduce BBFlow, a generative model for protein conformational ensembles based on backbone geometry that is an order of magnitude faster than the current state-of-the-art model AlphaFlow \cite{jing2024alphafoldmeetsflowmatching}, at similar accuracy.
%
% how we achieve this:
BBFlow relies on two key innovations.
\textbf{(1)} We formulate conformational ensemble prediction as protein structure generation task, conditioned on a distance encoding of the equilibrium structure and \textbf{(2)} propose a conditional prior distribution for flow matching based on geodesic interpolation (Figure~\ref{fig:intro}).
%
% more general meaning of the work:
Notably, our work shows that neither pre-trained weights from a folding model nor evolutionary sequence information is required to generate highly accurate conformational ensembles.
Instead, we find that ensembles can even be generated purely geometry-based, without any sequence information.

For benchmarking BBFlow, we train and test the model on the ATLAS dataset \cite{vander2024atlas}, which contains Molecular Dynamics trajectories of 1390 proteins -- the same dataset used for training AlphaFlow.
We also test BBFlow on MD trajectories of \textit{de novo} proteins, where we find similar performance as for naturally occurring proteins while AlphaFlow fails if the equilibrium structure is not provided as template.


\subsection{Related Work}

Previous deep learning approaches for sampling conformational ensembles such as \cite{noe_boltzmann2019}, where invertible neural networks are employed, or equivariant flow matching \cite{klein2023equivariant} usually require training on the specific system of interest.
For proteins, a transferable model, AlphaFlow, which relies on fine-tuning the pre-trained folding model AlphaFold 2 \cite{jumper2021highly}, has been recently proposed \cite{jing2024alphafoldmeetsflowmatching}.
While \citet{jing2024alphafoldmeetsflowmatching} also introduce a model trained on ensembles deposited in the Protein Data Bank (PDB), the scope of this work is to generate Boltzmann-sampled states and we thus focus on the AlphaFlow models trained on MD.
\citet{wang2024proteinconfdiff} propose ConfDiff, a diffusion model that relies on a pre-trained sequence representation of AlphaFold 2 and is trained on both the PDB and MD conformations.
\cite{Lewis2024-bio-emu} propose the generative model Bio-Emu with an architecture similar to AlphaFold 2 with the difference that a diffusion module is used for protein structure generation. 
Bio-Emu is trained on a large custom MD dataset, making it not directly comparable to AlphaFlow and BBFlow.
Conformational ensemble prediction was also suggested as transfer application of the recent structure design model FoldFlow++ \cite{huguet2024foldflow2}.
However, FoldFlow++ underperforms AlphaFlow, which is to be expected since it is not trained on MD data, and is thus not considered in this work.