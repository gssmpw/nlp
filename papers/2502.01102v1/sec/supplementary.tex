\clearpage

\crefalias{section}{appendix}
\counterwithin{figure}{section}
\counterwithin{table}{section}
\counterwithin{equation}{section}

\title{Supplementary Material --\\Towards Robust and Generalizable Lensless Imaging with Modular Learned Reconstruction}

\maketitle

\appendices

\section{Consequences of Model Mismatch to Image Recovery}
\label{app:mismatch}

\noindent Assuming a desired scene is comprised of point sources that are incoherent with each other, a lensless imaging system (with no shift-invariance assumption) can be modeled as a linear matrix-vector multiplication with the system matrix $\bm{H}$:
\begin{align}
    \label{eq:forward_gen_app}
    \bm{y} = \bm{H}\bm{x} + \bm{n},
\end{align}
where $\bm{y}$ and $\bm{x}$ are the vectorized lensless measurement and scene intensity, respectively, and $\bm{n}$ is additive noise.

If we denote our estimate system matrix as $\bm{\hat{H}}=(\bm{H}+\bm{\Delta}_H)$ where the deviation from the true system matrix is $\bm{\Delta}_H$,
our forward model from can be written as:
\begin{align}
    \label{eq:mismatch_forward_app}
    \bm{y} = \bm{H}\bm{x} + \bm{n} = (\bm{\hat{H}} - \bm{\Delta}_H)\bm{x} + \bm{n}.
\end{align}


\subsection{Direct Inversion}

\noindent Assuming the system is invertible and with spectral radius $\rho(\bm{H}) < 1$, using the estimate $\bm{\hat{H}}$ for direct inversion yields~\cite{9546648,9157433}:
\begin{align}
    \bm{\hat{x}} &= \bm{\hat{H}}^{-1} \bm{y} \nonumber \\
    &=(\bm{H}+\bm{\Delta}_H)^{-1} (\bm{H}\bm{x} + \bm{n}) \nonumber \\ 
    &=[\bm{H} (\bm{I}+\bm{H}^{-1}\bm{\Delta}_H)]^{-1} (\bm{H}\bm{x} + \bm{n}) \nonumber \\ 
    &=(\bm{I}+\bm{H}^{-1}\bm{\Delta}_H)^{-1} \bm{H}^{-1} (\bm{H}\bm{x} + \bm{n}) \nonumber \\
    &=(\bm{I}+ \bm{H}^{-1}\bm{\Delta}_H)^{-1} (\bm{x} + \bm{H}^{-1}\bm{n}) \nonumber \\
   &=
   \label{eq:taylor}
   (\bm{I} - \bm{H}^{-1}\bm{\Delta}_H) (\bm{x} + \bm{H}^{-1}\bm{n}) + \mathcal{O}(\| \bm{\Delta}_H\|_F^2)\\
   \label{eq:inversion_terms_app}
   &= \bm{x} - \underbrace{\bm{H}^{-1}\bm{\Delta}_H \bm{x}}_{\text{model mismatch}} + \underbrace{(\bm{I} - \bm{H}^{-1}\bm{\Delta}_H)\bm{H}^{-1}\bm{n}}_{\text{noise amplification}} + \mathcal{O}(\| \bm{\Delta}_H\|_F^2),
   %%% SIGN CHANGE
   %  &=(\bm{H}-\bm{\Delta}_H)^{-1} (\bm{H}\bm{x} + \bm{n}) \nonumber \\ 
   %  % factor out H and distribute into second part
   %  &=(\bm{I}- \bm{H}^{-1}\bm{\Delta}_H)^{-1} (\bm{x} + \bm{H}^{-1}\bm{n}) \nonumber \\
   % &= (\bm{I} + \bm{H}^{-1}\bm{\Delta}_H) (\bm{x} + \bm{H}^{-1}\bm{n}) + \mathcal{O}(\| \bm{\Delta}_H\|_F^2) \nonumber \\
   % \label{eq:inversion_terms}
   % &= \bm{x} + \underbrace{\bm{H}^{-1}\bm{\Delta}_H \bm{x}}_{\text{model mismatch}} + \underbrace{(\bm{I} + \bm{H}^{-1}\bm{\Delta}_H)\bm{H}^{-1}\bm{n}}_{\text{noise amplification}} + \mathcal{O}(\| \bm{\Delta}_H\|_F^2).
\end{align}
% \begin{align}
%     \bm{\hat{x}} &= \bm{\hat{H}}^{-1} \bm{y} \nonumber\\
%     &=(\bm{H}+\bm{\Delta}_H)^{-1} (\bm{H}\bm{x} + \bm{n}) \nonumber \\ 
%     % factor out H and distribute into second part
%     % &=(\bm{I}+ \bm{H}^{-1}\bm{\Delta}_H)^{-1} (\bm{x} + \bm{H}^{-1}\bm{n}) \nonumber \\
%    &= (\bm{I} - \bm{H}^{-1}\bm{\Delta}_H) (\bm{x} + \bm{H}^{-1}\bm{n}) + \mathcal{O}(\| \bm{\Delta}_H\|_F^2) \nonumber \\
%    \label{eq:inversion_terms}
%    &= \bm{x} - \underbrace{\bm{H}^{-1}\bm{\Delta}_H \bm{x}}_{\text{model mismatch}} + \underbrace{(\bm{I} - \bm{H}^{-1}\bm{\Delta}_H)\bm{H}^{-1}\bm{n}}_{\text{noise amplification}} + \mathcal{O}(\| \bm{\Delta}_H\|_F^2),
% \end{align}
where \cref{eq:taylor}  uses the Taylor expansion $(\bm{I}-\bm{X})^{-1} = \bm{I} + \sum_{k=1}^{\infty} \bm{X}^k$ with $\bm{X} = \bm{H}^{-1}\bm{\Delta}_H$.
With \cref{eq:inversion_terms_app}, we see the error terms that arise due to model mismatch in the forward modeling, and how noise can be amplified, particularly if $\bm{H}$ is ill-conditioned.

\subsection{Wiener Filtering}

\noindent Approximating the system as linear shift-invariant (LSI) allows us to write the forward operation as a point-wise multiplication in the frequency domain with a single on-axis point spread function (PSF):
\begin{align}
\label{eq:lsi_forward_app}
    \bm{Y} = \bm{P} \odot \bm{X} + \bm{N},
    % \bm{Y} = \bm{P} \ \bm{X} + \bm{N},
\end{align}
where $\{\bm{Y}, \bm{P}, \bm{X}, \bm{N}\} \in \mathbb{C}^{N_x \times N_y}$ are 2D Fourier transforms of the measurement, the on-axis PSF, the scene, and the noise respectively, and $\odot$ is point-wise multiplication.
Wiener filtering yields the following estimate:
% https://en.wikipedia.org/wiki/Wiener_deconvolution#Interpretation
% simplification to K: http://www.ws.binghamton.edu/fowler/fowler%20personal%20page/EE522_files/EECE%20522%20Notes_28a%20Wiener%20Filter%20for%20Deblurring%20Images.pdf
\begin{align}
    \label{eq:wiener_app}
    % \bm{\hat{X}} = \dfrac{\bm{P}^*  \odot \bm{Y}}{ |\bm{P}|^2 + \sigma^2_{N}} =  \dfrac{\bm{P}^* \odot (\bm{P} \odot\bm{X} + \bm{N})}{ |\bm{P}|^2 + \sigma^2_{N}},
    \bm{\hat{X}} = \dfrac{\bm{P}^*  \odot \bm{Y}}{ |\bm{P}|^2 + \bm{R}} =  \dfrac{\bm{P}^* \odot (\bm{P} \odot\bm{X} + \bm{N})}{ |\bm{P}|^2 + \bm{R}},
\end{align}
where all operations are point-wise,
% all operations are point-wise with the 2D spatial frequency $\bm{f} \in \mathbb{R}^2$, $\{\bm{Y}_{\bm{f}}, \bm{P}_{\bm{f}}, \bm{X}_{\bm{f}}, \bm{N}_{\bm{f}}\} \in \mathbb{C}$ are the Fourier transforms of $\{\bm{Y}, \bm{P}, \bm{X}, \bm{N}\} $ from \cref{eq:lsi_forward} at the frequency $\bm{f}$, and
the noise $\bm{N}$ is assumed to be independent to $\bm{X}$, and $\bm{R}\in \mathbb{R}^{N_x \times N_y}$ is the \textit{inverse} of the signal-to-noise ratio at each frequency.
% and to follow a Gaussian distribution with mean zero and variance $\sigma^2_{N}$.
$\bm{R}$ is often simplified to a single constant $K$,
which makes \cref{eq:wiener_app} equivalent to least-squares/Tikhonov  regularization~\cite{flatcam} of \cref{eq:opt_gen}, \ie $\mathcal{R}(\cdot) = \|\cdot\|^2_2$ with the appropriate $\lambda$ factor.
% can yield a closed-form solution almost identical to Wiener filtering.
% In the frequency domain, 

If we use a noisy version of the on-axis PSF's Fourier transform, \ie $\bm{\hat{P}} = (\bm{P}+ \bm{\Delta}_P)$, 
our Wiener-filtered estimate of the scene becomes:
\begin{align}
    \bm{\hat{X}}^{\text{noisy}} &= \dfrac{\bm{\hat{P}}^* \odot \bm{Y}}{ |\bm{\hat{P}}|^2 + \bm{R}} \nonumber\\
    % &= \dfrac{(\bm{P}_f + \bm{\Delta}_P)^* \bm{Y}_f}{ |(\bm{P}_f + \bm{\Delta}_P)|^2 + \sigma^2_{\bm{n}}}, \\
    &= \dfrac{\bm{P}^* \odot \bm{Y}+ \bm{\Delta}_P^* \odot \bm{Y}}{|\bm{P}|^2 + \bm{R} + |\bm{\Delta}_P|^2 + \bm{\Delta}_P^* \odot \bm{P} + \bm{P}^* \odot \bm{\Delta}_P}.
\end{align}
% https://math.stackexchange.com/questions/3047032/how-to-split-up-a-fraction-with-a-sum-in-the-denominator
Using:
\begin{align}
\dfrac{\bm{A}}{\bm{B}+\bm{\Delta}_B} = \dfrac{\bm{A}}{\bm{B}} - \dfrac{\Delta_B \odot \bm{A}}{\bm{B}^2 + \bm{B} \odot \bm{\Delta}_B},
\end{align}
with:
\begin{align}
    \bm{A} &= \bm{P}^* \odot \bm{Y} +\bm{\Delta}_P^* \odot \bm{Y}\\
    \bm{B} &= |\bm{P}|^2 + \bm{R}\\
    \bm{\Delta}_B &= |\bm{\Delta}_P|^2 + \bm{\Delta}_P^* \odot \bm{P} + \bm{P}^*\odot\bm{\Delta}_P,
\end{align}
% $\bm{A}/(\bm{B}+\bm{\Delta}_B) = (\bm{A}/\bm{B}) - \bm{\Delta}_B\bm{A}/(\bm{B}^2 + \bm{B}\bm{\Delta}_B)$ with
% $\bm{A}=\bm{P}^* \odot \bm{Y} +\bm{\Delta}_P^* \odot \bm{Y} $, $ \bm{B} = |\bm{P}|^2 + \sigma^2_{N}$, and $\bm{\Delta}_B = |\bm{\Delta}_P|^2 + \bm{\Delta}_P^* \odot \bm{P} + \bm{P}^*\odot\bm{\Delta}_P$, 
we obtain:
% \begin{align}
%     \bm{A} &= \bm{P}_{\bm{f}}^*\bm{Y}_{\bm{f}} + \delta_{\bm{f}}^*\bm{Y}_{\bm{f}} \\
%     \bm{B}_1 &= |\bm{P}_{\bm{f}}|^2 + \sigma^2_{\bm{n}} \\
%     \bm{B}_2 &= |\delta_{\bm{f}}|^2 + \delta_{\bm{f}}^*\bm{P}_{\bm{f}} + \bm{P}_{\bm{f}}^*\delta_{\bm{f}},
% \end{align}
\begin{align}
    \bm{\hat{X}}^{\text{noisy}} &= \dfrac{\bm{P}^* \odot \bm{Y} +\bm{\Delta}_P^* \odot \bm{Y}}{\bm{B}} - \dfrac{\bm{\Delta}_B \odot \bm{Y} \odot(\bm{P}^* +\bm{\Delta}_P^*)}{\bm{B}^2 + \bm{B} \odot \bm{\Delta}_B} \nonumber\\
    % &= \bm{\hat{X}}_{\bm{f}} + \dfrac{\bm{\Delta}_P^*\bm{Y}_{\bm{f}}}{\bm{B}_1} - \dfrac{\bm{B}_2(\bm{P}_{\bm{f}}^*\bm{Y}_{\bm{f}} + \bm{\Delta}_P^*\bm{Y}_{\bm{f}})}{\bm{B}_1^2 + \bm{B}_1\bm{B}_2} \\
    % &= \bm{\hat{X}}_{\bm{f}} + \bm{Y}_{\bm{f}}  \left[ \dfrac{\bm{\Delta}_P^*}{\bm{B}_1} - \dfrac{\bm{B}_2(\bm{P}_{\bm{f}}^* + \bm{\Delta}_P^*)}{\bm{B}_1^2 + \bm{B}_1\bm{B}_2}   \right]   \\
    &= \bm{\hat{X}} + \bm{Y} \odot \left[ \dfrac{\bm{\Delta}_P^*}{\bm{B}} - \dfrac{\bm{\Delta}_B \odot (\bm{P}^* + \bm{\Delta}_P^*)}{\bm{B}^2 + \bm{B} \odot \bm{\Delta}_B}  \right]  \nonumber\\
    % &= \bm{\hat{X}} + (\bm{P} \odot \bm{X} + \bm{N}) \odot \left[ \dfrac{\bm{\Delta}_P^*}{\bm{B}} - \dfrac{\bm{\Delta}_B \odot (\bm{P}^* + \bm{\Delta}_P^*)}{\bm{B}^2 + \bm{B} \odot \bm{\Delta}_B}  \right]  \nonumber\\
    % &= \bm{\hat{X}}_{\bm{f}} + (\bm{P}_{\bm{f}} \bm{X}_{\bm{f}} + \bm{N}_{\bm{f}}) \left[ \dfrac{\delta_{\bm{f}}^*}{\bm{B}_1} - \dfrac{\bm{B}_2(\bm{P}_{\bm{f}}^* + \delta_{\bm{f}}^*)}{\bm{B}_1^2 + \bm{B}_1\bm{B}_2}  \right]  \nonumber\\
    % &= \bm{\hat{X}}_{\bm{f}} + (\bm{P}_{\bm{f}} \bm{X}_{\bm{f}} + \bm{N}_{\bm{f}}) \left[ \dfrac{\bm{\Delta}_P^*}{\bm{B}_1} - \dfrac{\bm{B}_2(\bm{P}_{\bm{f}}^* + \bm{\Delta}_P^*)}{\bm{B}_1^2 + \bm{B}_1\bm{B}_2}  \right]
    &=\bm{\hat{X}} + \underbrace{\bm{M} \odot \bm{P} \odot  \bm{X}}_{\text{model mismatch}} + \underbrace{\bm{M} \odot \bm{N}}_{\text{noise amplification}}, \label{eq:noisy_wiener_app}
\end{align}
where:
\begin{align}
    \bm{M} = \dfrac{\bm{\Delta}_P^*}{\bm{B}} - \dfrac{\bm{\Delta}_B \odot (\bm{P}^* + \bm{\Delta}_P^*)}{\bm{B}^2 + \bm{B} \odot \bm{\Delta}_B}.
\end{align}
% By rearranging terms, the optimal update can be expressed as a function of the noisy update and perturbation terms:
% \begin{align}
% \bm{\hat{X}}_{\bm{f}} =  \bm{\hat{X}}_{\bm{f}}^{\text{noisy}} + \underbrace{\bm{P}_{\bm{f}} \bm{M} \bm{X}_{\bm{f}}}_{\text{model mismatch}} + \underbrace{\bm{M}\bm{N}_{\bm{f}}}_{\text{noise amplification}}, \label{eq:noisy_wiener}
% \end{align}
% where:
% \begin{align}
%     \bm{M} = \dfrac{\bm{B}_2(\bm{P}_{\bm{f}}^* + \bm{\Delta}_P^*)}{\bm{B}_1^2 + \bm{B}_1\bm{B}_2} - \dfrac{\bm{\Delta}_P^*}{\bm{B}_1} .
% \end{align}
If there is no model mismatch in the PSF used for Wiener filtering, \ie $\delta_{\bm{f}} = 0$, such that $\bm{B}_2 = 0$, $\bm{M} = 0$, $ \bm{\bm{\hat{X}}_f^{\text{noisy}}} = \bm{\hat{X}}_f $.
%When there is mismatch in the PSF, we obtain a model mismatch perturbation and noise amplification
%%(even though we do not apply $\bm{P}_{\bm{f}}^{-1}$) 
%as shown in~\cref{eq:noisy_wiener}.







% Using a least-squares/Tikhonov  regularization~\cite{flatcam}, \ie $\mathcal{R}(\cdot) = \|\cdot\|^2_2$ with the appropriate $\lambda$ factor, can yield a closed-form solution identical to Wiener filtering.
% % If we consider the shift-invariant case in the frequency domain, 
% % a common approach to deconvolution is Wiener filtering, whose objective is to minimize the mean-squared error (MSE) between the measurement and the output predicted by the forward model, \ie $\| \bm{y}- \bm{H}\bm{x} \|_2^2$. 
% % Minimizing the MSE avoids applying $\bm{H}^{-1}$, which can amplify noise as seen above.
% In the frequency domain, Wiener filtering yields the following estimate:
% \begin{align}
%     \label{eq:wiener}
%     \bm{\hat{X}}_{\bm{f}} = \dfrac{\bm{P}_{\bm{f}}^* \bm{Y}_{\bm{f}}}{ |\bm{P}_{\bm{f}}|^2 + \sigma^2_{\bm{n}}} =  \dfrac{\bm{P}_{\bm{f}}^* (\bm{P}_{\bm{f}}\bm{X}_{\bm{f}} + \bm{N}_{\bm{f}})}{ |\bm{P}_{\bm{f}}|^2 + \sigma^2_{\bm{n}}},
% \end{align}
% where all operations are point-wise with the 2D spatial frequency $\bm{f} \in \mathbb{R}^2$, $\{\bm{Y}_{\bm{f}}, \bm{P}_{\bm{f}}, \bm{X}_{\bm{f}}, \bm{N}_{\bm{f}}\} \in \mathbb{C}$ are the Fourier transforms of $\{\bm{Y}, \bm{P}, \bm{X}, \bm{N}\} $ from \cref{eq:lsi_forward} at the frequency $\bm{f}$, and
% the noise $\bm{N}$ is assumed to be independent to $\bm{X}$ and to follow a Gaussian distribution with mean zero and variance $\sigma^2_{\bm{n}}$.

% If we use a noisy version of the on-axis PSF's Fourier transform, \ie $\bm{\hat{P}}_{\bm{f}} = (\bm{P}_{\bm{f}} + \delta_{\bm{f}})$, 
% our Wiener-filtered estimate of the scene becomes:
% \begin{align}
%     \bm{\hat{X}}_{\bm{f}}^{\text{noisy}} &= \dfrac{\bm{\hat{P}}_{\bm{f}}^* \bm{Y}_{\bm{f}}}{ |\bm{\hat{P}}_{\bm{f}}|^2 + \sigma^2_{\bm{n}}} \nonumber\\
%     % &= \dfrac{(\bm{P}_f + \bm{\Delta}_P)^* \bm{Y}_f}{ |(\bm{P}_f + \bm{\Delta}_P)|^2 + \sigma^2_{\bm{n}}}, \\
%     &= \dfrac{\bm{P}_{\bm{f}}^*\bm{Y}_{\bm{f}} + \delta_{\bm{f}}^*\bm{Y}_{\bm{f}}}{|\bm{P}_{\bm{f}}|^2 + \sigma^2_{\bm{n}} + |\delta_{\bm{f}}|^2 + \delta_{\bm{f}}^*\bm{P}_{\bm{f}} + \bm{P}_{\bm{f}}^*\delta_{\bm{f}}}.
% \end{align}
% % https://math.stackexchange.com/questions/3047032/how-to-split-up-a-fraction-with-a-sum-in-the-denominator
% Using $\bm{A}/(\bm{B}_1+\bm{B}_2) = (\bm{A}/\bm{B}_1) - \bm{B}_2\bm{A}/(\bm{B}_1^2 + \bm{B}_1\bm{B}_2)$ with
% $\bm{A}=\bm{P}_{\bm{f}}^*\bm{Y}_{\bm{f}} + \delta_{\bm{f}}^*\bm{Y}_{\bm{f}} $, $ \bm{B}_1 = |\bm{P}_{\bm{f}}|^2 + \sigma^2_{\bm{n}}$, and $\bm{B}_2 = |\delta_{\bm{f}}|^2 + \delta_{\bm{f}}^*\bm{P}_{\bm{f}} + \bm{P}_{\bm{f}}^*\delta_{\bm{f}}$, we obtain:
% % \begin{align}
% %     \bm{A} &= \bm{P}_{\bm{f}}^*\bm{Y}_{\bm{f}} + \delta_{\bm{f}}^*\bm{Y}_{\bm{f}} \\
% %     \bm{B}_1 &= |\bm{P}_{\bm{f}}|^2 + \sigma^2_{\bm{n}} \\
% %     \bm{B}_2 &= |\delta_{\bm{f}}|^2 + \delta_{\bm{f}}^*\bm{P}_{\bm{f}} + \bm{P}_{\bm{f}}^*\delta_{\bm{f}},
% % \end{align}
% % we obtain:
% \begin{align}
%     \bm{\hat{X}}_{\bm{f}}^{\text{noisy}} &= \dfrac{\bm{P}_{\bm{f}}^*\bm{Y}_{\bm{f}} + \delta_{\bm{f}}^*\bm{Y}_{\bm{f}}}{\bm{B}_1} - \dfrac{\bm{B}_2(\bm{P}_{\bm{f}}^*\bm{Y}_{\bm{f}} + \delta_{\bm{f}}^*\bm{Y}_{\bm{f}})}{\bm{B}_1^2 + \bm{B}_1\bm{B}_2} \nonumber\\
%     % &= \bm{\hat{X}}_{\bm{f}} + \dfrac{\bm{\Delta}_P^*\bm{Y}_{\bm{f}}}{\bm{B}_1} - \dfrac{\bm{B}_2(\bm{P}_{\bm{f}}^*\bm{Y}_{\bm{f}} + \bm{\Delta}_P^*\bm{Y}_{\bm{f}})}{\bm{B}_1^2 + \bm{B}_1\bm{B}_2} \\
%     % &= \bm{\hat{X}}_{\bm{f}} + \bm{Y}_{\bm{f}}  \left[ \dfrac{\bm{\Delta}_P^*}{\bm{B}_1} - \dfrac{\bm{B}_2(\bm{P}_{\bm{f}}^* + \bm{\Delta}_P^*)}{\bm{B}_1^2 + \bm{B}_1\bm{B}_2}   \right]   \\
%     &= \bm{\hat{X}}_{\bm{f}} + \bm{Y}_{\bm{f}} \left[ \dfrac{\delta_{\bm{f}}^*}{\bm{B}_1} - \dfrac{\bm{B}_2(\bm{P}_{\bm{f}}^* + \delta_{\bm{f}}^*)}{\bm{B}_1^2 + \bm{B}_1\bm{B}_2}  \right]  \nonumber\\
%     % &= \bm{\hat{X}}_{\bm{f}} + (\bm{P}_{\bm{f}} \bm{X}_{\bm{f}} + \bm{N}_{\bm{f}}) \left[ \dfrac{\delta_{\bm{f}}^*}{\bm{B}_1} - \dfrac{\bm{B}_2(\bm{P}_{\bm{f}}^* + \delta_{\bm{f}}^*)}{\bm{B}_1^2 + \bm{B}_1\bm{B}_2}  \right]  \nonumber\\
%     % &= \bm{\hat{X}}_{\bm{f}} + (\bm{P}_{\bm{f}} \bm{X}_{\bm{f}} + \bm{N}_{\bm{f}}) \left[ \dfrac{\bm{\Delta}_P^*}{\bm{B}_1} - \dfrac{\bm{B}_2(\bm{P}_{\bm{f}}^* + \bm{\Delta}_P^*)}{\bm{B}_1^2 + \bm{B}_1\bm{B}_2}  \right]
%     % \\
%     &= \bm{\hat{X}}_f + \underbrace{\bm{M} \bm{P}_f  \bm{X}_f}_{\text{model mismatch}} + \underbrace{\bm{M}\bm{N}_f}_{\text{noise amplification}}, \label{eq:noisy_wiener}
% \end{align}
% where:
% \begin{align}
%     \bm{M} = \dfrac{\delta_{\bm{f}}^*}{\bm{B}_1} - \dfrac{\bm{B}_2(\bm{P}_f^* + \delta_{\bm{f}}^*)}{\bm{B}_1^2 + \bm{B}_1\bm{B}_2}.
% \end{align}
% % By rearranging terms, the optimal update can be expressed as a function of the noisy update and perturbation terms:
% % \begin{align}
% % \bm{\hat{X}}_{\bm{f}} =  \bm{\hat{X}}_{\bm{f}}^{\text{noisy}} + \underbrace{\bm{P}_{\bm{f}} \bm{M} \bm{X}_{\bm{f}}}_{\text{model mismatch}} + \underbrace{\bm{M}\bm{N}_{\bm{f}}}_{\text{noise amplification}}, \label{eq:noisy_wiener}
% % \end{align}
% % where:
% % \begin{align}
% %     \bm{M} = \dfrac{\bm{B}_2(\bm{P}_{\bm{f}}^* + \bm{\Delta}_P^*)}{\bm{B}_1^2 + \bm{B}_1\bm{B}_2} - \dfrac{\bm{\Delta}_P^*}{\bm{B}_1} .
% % \end{align}
% If there is no model mismatch in the PSF used for Wiener filtering, \ie $\delta_{\bm{f}} = 0$, such that $\bm{B}_2 = 0$, $\bm{M} = 0$, $ \bm{\bm{\hat{X}}_f^{\text{noisy}}} = \bm{\hat{X}}_f $.
% %When there is mismatch in the PSF, we obtain a model mismatch perturbation and noise amplification
% %%(even though we do not apply $\bm{P}_{\bm{f}}^{-1}$) 
% %as shown in~\cref{eq:noisy_wiener}.

\subsection{Gradient Descent}

\noindent A common approach to avoid adverse amplification with $\bm{H}^{-1}$ is to pose the image recovery as a regularized optimization problem:
\begin{align}
\label{eq:opt_gen_app}
   \bm{\hat{x}} = \arg \min_{\bm{x}} \frac{1}{2} ||\bm{H}\bm{x} - \bm{y}||_2^2 + \lambda \mathcal{R}(\bm{x}),
   % \\
   % \bm{\hat{X}} = \arg \min_{\bm{X}\geq0} \frac{1}{2} ||\bm{Y} - \bm{C}(\bm{P}\ast \bm{X})||_2^2 + \lambda \mathcal{R}(\bm{X})
\end{align}
where $\mathcal{R}(\cdot)$ is a regularization function on the estimate image.

Applying gradient descent to solve \cref{eq:opt_gen_app}  (without regularization),
would lead to the following update step (without model mismatch):
\begin{align}
    \label{eq:gradient_step}
    % \bm{\hat{x}}^{(k)} = \bm{\hat{x}}^{(k-1)} - \alpha \bm{H}^T\bm{C}^T (\bm{C}\bm{H}\bm{\hat{x}}^{(k-1)} - \bm{y}).
    \bm{\hat{x}}^{(k)} = \bm{\hat{x}}^{(k-1)} - \alpha \bm{H}^T(\bm{H}\bm{\hat{x}}^{(k-1)} - \bm{y}).
\end{align}
With model mismatch, we get the following noisy update (assuming no model mismatch in the previous iteration):
\begin{align}
% \bm{\hat{x}}^{(k),\text{noisy}} &= \bm{\hat{x}}^{(k-1)} - \alpha \bm{\hat{H}}^T (\bm{\hat{H}}\bm{\hat{x}}^{(k-1)} - \bm{y}) \nonumber\\
\bm{\hat{x}}^{(k),\text{noisy}} &= \bm{\hat{x}}^{(k-1)} - \alpha (\bm{H}+\bm{\Delta}_H)^T  \left[(\bm{H}+\bm{\Delta}_H)\bm{\hat{x}}^{(k-1)} -\bm{y}\right] \nonumber\\
    &= \bm{\hat{x}}^{(k)} - \alpha \left[ \bm{\Delta}_H^T( \bm{H}\bm{\hat{x}}^{(k-1)} - \bm{y}) + \bm{\hat{H}}^T\bm{\Delta}_H \bm{\hat{x}}^{(k-1)} \right] \nonumber \\
    &= \bm{\hat{x}}^{(k)} + \alpha \left[\underbrace{ \bm{\Delta}_H^T\bm{H} \bm{x} - \delta_{\bm{H}} \bm{\hat{x}}^{(k-1)}}_{\text{model mismatch}}  + \underbrace{\bm{\Delta}_H^T \bm{n}}_{\text{noise amplification}} \right], \label{eq:gradient_descent_mismatch_app}
% %%% INVERTED SIGN
% % WITHOUT CROPPING
%     \bm{\hat{x}}^{(k),\text{noisy}} &= \bm{\hat{x}}^{(k-1)} - \alpha \bm{\hat{H}}^T (\bm{\hat{H}}\bm{\hat{x}}^{(k-1)} - \bm{y}) \nonumber\\
%     &= \bm{\hat{x}}^{(k-1)} - \alpha (\bm{H}-\bm{\Delta}_H)^T  \left[(\bm{H}-\bm{\Delta}_H)\bm{\hat{x}}^{(k-1)} -\bm{y}\right] \nonumber\\
%     &= \bm{\hat{x}}^{(k)} - \alpha \left[ \bm{\Delta}_H^T(\bm{y} - \bm{H}\bm{\hat{x}}^{(k-1)}) - \bm{\hat{H}}^T\bm{\Delta}_H \bm{\hat{x}}^{(k-1)} \right] \nonumber
%     % \\
%     % &= \bm{x}^{(k)} + \alpha \left[ \bm{\Delta}_H^T (\bm{H}\bm{x}^{(k-1)} - \bm{H}\bm{x} - \bm{n}) + \bm{\hat{H}}^T\bm{\Delta}_H \bm{x}^{(k-1)} \right], \\
%     % &= \bm{x}^{(k)} 
%     % + \underbrace{\alpha \left[ \bm{\Delta}_H^T \bm{H} + \bm{\hat{H}}^T  \bm{\Delta}_H \right] \bm{x}^{(k-1)} }_{\text{error propagation}} \nonumber \\
%     % & \hspace{3em} - \underbrace{\alpha \bm{\Delta}_H^T\bm{H} \bm{x}}_{\text{model mismatch}} - \underbrace{\alpha \bm{\Delta}_H^T \bm{n}}_{\text{noise amplification}}. \label{eq:iterative_mismatch}
%     \\
%     &= \bm{\hat{x}}^{(k)} - \alpha \left[\underbrace{\bm{\Delta}_H^T\bm{H} \bm{x} - \delta_{\bm{H}} \bm{\hat{x}}^{(k-1)}}_{\text{model mismatch}}  + \underbrace{\bm{\Delta}_H^T \bm{n}}_{\text{noise amplification}} \right], \label{eq:gradient_descent_mismatch}
% % WITH CROPPING
%     \bm{\hat{x}}^{(k),\text{noisy}} &= \bm{\hat{x}}^{(k-1)} - \alpha \bm{\hat{H}}^T \bm{C}^T(\bm{C}\bm{\hat{H}}\bm{\hat{x}}^{(k-1)} - \bm{y}) \\
%     &= \bm{\hat{x}}^{(k-1)} \nonumber \\ & \quad - \alpha (\bm{H}-\bm{\Delta}_H)^T \bm{C}^T \left[\bm{C}(\bm{H}-\bm{\Delta}_H)\bm{\hat{x}}^{(k-1)} -\bm{y}\right] \\
%     &= \bm{\hat{x}}^{(k)} + \alpha \left[ \bm{\Delta}_H^T \bm{C}^T (\bm{C}\bm{H}\bm{\hat{x}}^{(k-1)} - \bm{y}) + \bm{\hat{H}}^T \bm{C}^T \bm{C} \bm{\Delta}_H \bm{\hat{x}}^{(k-1)} \right], 
%     \\
%     &= \bm{x}^{(k)} + \alpha \left[ \bm{\Delta}_H^T \bm{C}^T (\bm{C}\bm{H}\bm{x}^{(k-1)} - \bm{C}\bm{H}\bm{x} - \bm{n}) + \bm{\hat{H}}^T\bm{C}^T \bm{C} \bm{\Delta}_H \bm{x}^{(k-1)} \right], \\
%     &= \bm{x}^{(k)} 
%     + \underbrace{\alpha \left[ \bm{\Delta}_H^T \bm{C}^T \bm{C} \bm{H} + \bm{\hat{H}}^T \bm{C}^T \bm{C}  \bm{\Delta}_H \right] \bm{x}^{(k-1)} }_{\text{error propagation}} \nonumber \\
%     & \hspace{3em} - \underbrace{\alpha \bm{\Delta}_H^T\bm{C}^T \bm{C} \bm{H} \bm{x}}_{\text{model mismatch}} - \underbrace{\alpha \bm{\Delta}_H^T \bm{C}^T\bm{n}}_{\text{noise amplification}}. \label{eq:iterative_mismatch}
\end{align}
% By rearranging terms and using~\cref{eq:forward_gen} for $\bm{y}$, the true update can be expressed as a function of the noisy update, the previous update, and perturbation terms:
% \begin{align}
%     \bm{\hat{x}}^{(k)} &= \bm{\hat{x}}^{(k),\text{noisy}} + \alpha \left[\underbrace{\bm{\Delta}_H^T\bm{H} \bm{x} - \delta_{\bm{H}} \bm{\hat{x}}^{(k-1)}}_{\text{model mismatch}}  + \underbrace{\bm{\Delta}_H^T \bm{n}}_{\text{noise amplification}} \right]
% \end{align}
where \cref{eq:forward_gen_app} is used for $\bm{y}$, and $\delta_{\bm{H}} = \left( \bm{\Delta}_H^T\bm{H} + \bm{\hat{H}}^T \bm{\Delta}_H \right)$.
If there is no model mismatch (\ie $\bm{\Delta}_H = \bm{0}$), the last two terms disappear and $ \bm{\hat{x}}^{(k),\text{noisy}} = \bm{\hat{x}}^{(k)}$.

\subsection{Proximal Gradient Descent}

% Proximal gradient descent applies an operator at each gradient step, \eg shrinkage/soft-thresholding for iterative shrinkage-thresholding algorithms (ISTA) such as FISTA~\cite{beck2009fast}:
\noindent Proximal gradient descent applies an operator at each gradient step, \eg shrinkage/soft-thresholding for the fast iterative shrinkage-thresholding algorithm (FISTA)~\cite{beck2009fast}:
\begin{align}
    \bm{\hat{x}}^{(k),\text{noisy}} &= \mathcal{T}_{\beta}
    \left(  \bm{\hat{x}}^{(k)} + \alpha \left[\bm{\Delta}_H^T\bm{H} \bm{x} - \delta_{\bm{H}} \bm{\hat{x}}^{(k-1)}  + \bm{\Delta}_H^T \bm{n} \right] \right),
\end{align}
where the shrinkage operator $\mathcal{T}_{\beta} : \mathbb{R}^n \rightarrow \mathbb{R}^n$ is defined by:
\begin{align}
\mathcal{T}_{\beta}(\bm{x})_i = ( |x_i|- \beta)_{+} \text{sgn}(x_i).
\end{align}
If $\bm{\Delta}_H$ is sufficiently small, the shrinkage operator may discard the unwanted terms, \ie if all element are below $\beta$.
For natural images, we typically promote sparsity in another space, \eg with the TV operator, such that the adjoint of the operator would be applied before applying the shrinkage operator.
In this case, the unwanted terms may not be discarded by the shrinkage operator.


\vspace{1cm}
\subsection{Alternating Direction Method of Multipliers}

\noindent Starting with the ADMM update with model mismatch derived by Zeng \etal~\cite{9546648}, we can expand the terms from the previous iteration in Eq.~15 of~\cite{9546648} that depend on model mismatch:
\begin{align}
    % \bm{\hat{x}}^{(k)} &= \left( \bm{W}_1 + \rho_x \delta_{\bm{H}} \right)^{-1} \bm{W}_1 \bm{\hat{x}}^{(k),\text{noisy}} - \bm{W}_2 \bm{C}^T \bm{y} - \bm{\epsilon}^{(k-1)},
    \bm{\hat{x}}^{(k)} &= \left( \bm{W}_1 + \rho_x \delta_{\bm{H}} \right)^{-1} \bm{W}_1 \bm{\hat{x}}^{(k),\text{noisy}}  \nonumber \\
    & \quad - \bm{W}_2 \left( \bm{C}^T \bm{y} + \bm{\epsilon}^{(k-1)} \right) - \bm{W}_3
    \label{eq:original_noisy_admm_app}
    % % INVERTED SIGN
    % \bm{\hat{x}}^{(k)} &= \left( \bm{W}_1 + \rho_x \delta_{\bm{H}} \right)^{-1} \bm{W}_1 \bm{\hat{x}}^{(k),\text{noisy}} + \bm{W}_2 \bm{C}^T \bm{y} + \bm{\epsilon}^{(k-1)},
\end{align}
where:
\begin{align}
\bm{W}_1 &= \rho_x \bm{\hat{H}}^T \bm{\hat{H}} + \rho_z \bm{C}^T\bm{C} + \rho_y \bm{I}, \\
\bm{W}_2 &= (\bm{W}_1 + \rho_x \delta_{\bm{H}})^{-1} \Delta_{\bm{H}}^T \rho_x (\bm{C}^T\bm{C} + \rho_x \bm{I})^{-1}, \\
\bm{W}_3 &= \left( \bm{W}_1 + \rho_x \delta_{\bm{H}} \right)^{-1} \bm{\hat{H}}^T \rho_x^2 \Delta_{\bm{H}} \bm{\hat{x}}^{(k-1)},
\end{align}
$\{\rho_x, \rho_y, \rho_z\}$ are positive penalty parameters, $\bm{C}$ crops the image to the sensor size~\cite{Antipa:18}, and $\bm{\epsilon}^{(k-1)}$ denotes the combination of terms from the previous iteration's updates that do not depend on model mismatch.
By inserting $(\bm{C}\bm{H}\bm{x} + \bm{n})$ for $\bm{y}$ into \cref{eq:original_noisy_admm_app} and rearranging terms:
\begin{align}
&\bm{\hat{x}}^{(k),\text{noisy}} = \bm{\hat{x}}^{(k)}  + \underbrace{\bm{W}_4 \bm{W}_2\bm{C}^T \bm{n}}_{\text{noise amplification}} \nonumber \\
\label{eq:admm_mismatch_app} 
&\underbrace{+ \bm{W}_1^{-1}\rho_x \delta_{\bm{H}} \bm{\hat{x}}^{(k)} + \bm{W}_4 \bm{W}_2\left(\bm{C}^T\bm{C} \bm{H}\bm{x} + \bm{\epsilon}^{(k-1)} \right) + \bm{W}_4\bm{W}_3}_{\text{model mismatch}}, 
\end{align}
where $\bm{W}_4 = (\bm{I} + \bm{W}_1^{-1} \rho_x \delta_{\bm{H}})$.
If there is no model mismatch (\ie $\bm{\Delta}_H = \bm{0}$), $\bm{W}_2 = \bm{0}$, $\bm{W}_3 = \bm{0}$, $\bm{W}_4 = \bm{I}$, and $\delta_{\bm{H}} = \bm{0}$ such that \cref{eq:admm_mismatch_app} simplifies to $\bm{\hat{x}}^{(k),\text{noisy}} =   \bm{\hat{x}}^{(k)}$.

\section{Pre- and Post-Processor Architecture}
\label{sec:drunet}

\noindent For the pre- and post-processor architectures, we use a denoising residual U-Net (DRUNet) architecture  that has been shown to be very effective for denoising, deblurring, and super-resolution tasks~\cite{zhang2021plug}.
The architecture of DRUNet is shown in \cref{fig:drunet}.

For unrolled ADMM with model mismatch compensation, before going through the upsampling residual blocks of the post-processor (see \cref{fig:drunet}), the output of the compensation branch is concatenated to the last \textit{StridedConv} output and passed through a 2D convolutional layer whose number of output channels is equivalent to the number of channels of the post-processor's fourth scale, \eg 256 for $P_8$, and then passed through a \textit{ReLU} activation.

\begin{figure}[t!]
	\centering
	\includegraphics[width=1.0\linewidth]{figs/figb1_drunet.png}
	\caption{Denoising residual U-Net (DRUNet) architecture. where the sequence of operations is identical to the architecture proposed in~\cite{zhang2021plug}: a U-Net architecture with four scales and sandwiched by 2D convolutional layers (\textit{Conv}) with no activation function.
		Each scale has an identity skip connection between a $(2\times2)$ strided-convolution downscaling block (\textit{StridedConv}) and a corresponding $(2\times2)$ transposed-convolution upscaling block (\textit{TransposedConv}). Each residual blocks uses two \textit{Conv} layers, a \textit{ReLU} activation, a skip connection, and no batch normalization.}
	\label{fig:drunet}
\end{figure}

\section{Visualization of Camera Inversion Approaches}
\label{app:inversion}

\begin{figure*}[t!]
    \centering
    \begin{subfigure}{0.48\linewidth}
		\centering
        \includegraphics[width=0.99\linewidth]{figs/figc1_unrolled_admm_crop.png} 
		\caption{Unrolled ADMM~\cite{Monakhova:19}.}
		\label{fig:unrolled_admm}
	\end{subfigure}
 \begin{subfigure}{0.5\linewidth}
		\centering
        \includegraphics[width=\linewidth]{figs/figc1_compensation_branch.png} 
		\caption{Unrolled ADMM with model mismatch compensation network~\cite{9546648}.}
		\label{fig:compensation_branch}
	\end{subfigure}
    \hspace{2cm}
	\begin{subfigure}{0.48\linewidth}
		\centering
		\includegraphics[width=0.99\linewidth]{figs/figc1_trainable_inv_v3.png} 
		\caption{Trainable inversion~\cite{9239993}.}
		\label{fig:trainable_inv}
	\end{subfigure}
	\begin{subfigure}{0.5\linewidth}
		\centering
		\includegraphics[width=0.99\linewidth]{figs/figc1_multiwiener.png} 
		\caption{Multi-Wiener deconvolution network with PSF correction~\cite{Li:23}.}
		\label{fig:multiwiener}
	\end{subfigure}
	\caption{Camera inversion approaches considered in this work. The input is either the raw measurement or the output of the pre-processor, while the output can be fed to a post-processor.
 % (except for the multi-Wiener deconvolution network). 
 % \cref{fig:unrolled_admm} shows unrolled ADMM for an arbitrary number of layers, \cref{fig:compensation_branch} 5 unrolled layers of ADMM with a model mismatch compensation network (MMCN), \cref{fig:trainable_inv} trainable inversion, and \cref{fig:multiwiener} multi-Wiener deconvolution network (MWDN) with PSF correction.
 }
	\label{fig:camera_inv_arch}
\end{figure*}

\noindent \cref{fig:camera_inv_arch} visualizes all the camera inversion approaches.
In \cref{fig:trainable_inv}, $\mathcal{F}$ and $\mathcal{F}^{-1}$ refer to the 2D Fourier transform and its inverse respectively.
In \cref{fig:compensation_branch} and \cref{fig:multiwiener}, \textit{DoubleConv} corresponds to two 2D convolutional layers each followed by batch normalization and a \textit{ReLU} activation, \textit{Conv} corresponds to a 2D convolutional layer followed by a \textit{ReLU} activation, \textit{Res} corresponds to \textit{DoubleConv} with a skip connection before the final \textit{ReLU} activation, and \textit{Pool} refers to max-pooling. All convolutional layers use $(3\times3)$ kernels.
For MMCN, before going through the bottleneck residual blocks of the post-processor (see \cref{fig:drunet}), the output of the compensation branch is concatenated to the last \textit{StridedConv} output and passed through a 2D convolutional layer whose number of output channels is equivalent to the number of channels of the post-processor's fourth scale, \eg 256 for $P_8$, and then passed through a \textit{ReLU} activation.
\cref{fig:multiwiener} shows the architecture for a multi-Wiener deconvolution network with PSF correction (MWDN)~\cite{Li:23}.
As it already uses convolutional layers before and after Wiener filtering, we do not incorporate pre- and post-processors.

\section{Point Spread Function Modeling}
\label{app:psf_modeling}

\begin{figure}[t!]
	\centering
	\includegraphics[width=1.0\linewidth]{figs/figd1_propagation_model.png}
	\caption{Modeling of propagation to simulate the point spread function (not drawn to scale).}
	\label{fig:propagation_model}
\end{figure}

\noindent We model the PSF similar to~\cite{sitzmann2018e2e}, \ie as spherical waves up to the optical element followed by free-space propagation to the sensor, as shown in \cref{fig:propagation_model}.
The wave field at the sensor for a given wavelength $\lambda$ and for a point source at a distance $d_1$ from the optical element, which is at a distance $d_2$ from the sensor, can be written as:
\begin{align}
	\label{eq:wavefield_app}
	&u_2(\bm{r}; d_1, d_2, \lambda) = \nonumber \\ 
	&\mathcal{F}^{-1}\Big(\mathcal{F} \Big( m(\bm{r}; \lambda) \underbrace{e^{j \frac{2\pi}{\lambda} \sqrt{\|\bm{r}\|_2^2 +  d_1^2}}}_{\text{spherical waves}}
	\Big) \times h(\bm{u}; z=d_2, \lambda) \Big),
	% &p(\bm{r}; d_1, d_2, c) = \nonumber \\ 
	% &\Big|\mathcal{F}^{-1}\Big(\mathcal{F} \Big( m(\bm{r}; \lambda_c) \underbrace{e^{j \frac{2\pi}{\lambda_c} \sqrt{\|\bm{r}\|_2^2 +  d_1^2}}}_{\text{spherical waves}}
	% \Big) \times h(\bm{u}; z=d_2, \lambda_c) \Big)\Big|^2,
\end{align}
where 
% $ \mathcal{F}$ and $\mathcal{F}^{-1} $ denote the spatial Fourier transform and its inverse,
$ h(\bm{u}; z, \lambda)$ is the free-space propagation frequency response, and
$\bm{u} \in \mathbb{R}^2$ are the spatial frequencies of $\bm{r} \in \mathbb{R}^2$.
For the free-space propagation kernel, we use bandlimited angular spectrum (BLAS)~\cite{Matsushima2009}:
% as it is more accurate in non-paraxial regimes~\cite{Goodman2004} and does not have aliasing issues like conventional angular spectrum:
% Fresnel and angular spectrum (AS) are commonly used to model the free-space propagation kernel,
% with the latter being more accurate in non-paraxial regimes~\cite{Goodman2004}.
% AS can face aliasing issues which can be alleviated by bandlimiting the kernel~\cite{Matsushima2009}:
\begin{align}
	\label{eq:freespace}
	h(\bm{u}; z=d_2, \lambda ) = e^ {j \frac{2 \pi}{\lambda} z \sqrt{1 - \|\lambda \bm{u}\|_2^2} } \,\text{rect}_{\text{2d}}\Big(\frac{\bm{u}}{2\bm{u}_{\text{limit}}}\Big),
\end{align}
where $ \text{rect}_{\text{2d}} $ is a 2D rectangular function for bandlimiting by the frequencies $\bm{u}_{\text{limit}} = \sqrt{(z / \bm{S} )^2  + 1} / \lambda$
%\begin{align}
%	\bm{u}_{\text{limit}} = \dfrac{\sqrt{(z / \bm{S} )^2  + 1} }{\lambda},
%	%		  \quad v_{\text{limit}} = \dfrac{\sqrt{( d_2 / S_y )^2  + 1} }{\lambda},
%\end{align}
and $ \bm{S} \in \mathbb{R}^2 $ are the physical dimensions of the propagation region (in our case the physical dimensions of the sensor).



\section{Mask Modeling of \textit{DigiCam}}
\label{app:mask_modeling}

\begin{figure}[t!]
		\centering
		\includegraphics[width=1.0\linewidth]{figs/fige1_lcd_pixel_layout.png}
	\caption{Pixel layout of the ST7735R component~\cite{adafruitlcd}: red, green, blue color filter arrangement.}
	\label{fig:pixel_layout}
\end{figure}

\begin{figure*}[t!]
 % gamma 1.8
    \centering
    \begin{subfigure}{0.23\linewidth}
		\centering
\includegraphics[width=0.99\linewidth]{figs/fige2_DigiCam-CelebA-26K_psf_measured.png} 
		\caption{Measured PSF with a white LED at \SI{30}{\centi\meter}.}
		\label{fig:digicam_celeba_meas}
	\end{subfigure}
 \begin{subfigure}{0.23\linewidth}
		\centering
\includegraphics[width=0.99\linewidth]{figs/fige2_digicam_celeba_psf_nowaveprop} 
		\caption{Simulated PSF without wave propagation.}
		\label{fig:digicam_celeba_nowave}
	\end{subfigure}
 \begin{subfigure}{0.23\linewidth}
		\centering
\includegraphics[width=0.99\linewidth]{figs/fige2_plot_digicam_celeba_psf_waveprop_nodeadspace_nogamma.png} 
		\caption{Simulated PSF without deadspace.}
		\label{fig:digicam_celeba_wave_nodead}
	\end{subfigure}
 \begin{subfigure}{0.23\linewidth}
		\centering
\includegraphics[width=0.99\linewidth]{figs/fig3_digicam_celeba.png} 
		\caption{Simulated PSF with wave propagation and deadspace.}
		\label{fig:digicam_celeba_wave}
	\end{subfigure}
%  \begin{subfigure}{0.23\linewidth}
% 		\centering
% \includegraphics[width=0.99\linewidth]{figs/plot_digicam_celeba_psf_higherorder} 
% 		\caption{Simulated PSF with higher diffraction orders~\cite{Gopakumar:21}.}
% 		\label{fig:digicam_celeba_higherorder}
% 	\end{subfigure}
  \caption{Comparing measured and simulation point spread functions (PSFs) of \textit{DigiCam}.}
	\label{fig:compared_psfs_crop_app}
\end{figure*}

\noindent The LCD component used for \textit{DigiCam} has an interleaved pattern of red, blue, and green sub-pixels, 
as shown in \cref{fig:pixel_layout}.
A programmable mask can be modeled as a superposition of $K$ apertures for each adjustable pixel in $ \bm{r} \in \mathbb{R}^2 $:
\begin{align}
	\label{eq:mask_gen_main}
	m(\bm{r}) = \sum_{k=1}^K w_{k} \hspace{0.08cm} a(\bm{r} - \bm{r}_k),
\end{align}
where the complex-valued weights $\{w_{k}\}_{k=1}^K$ satisfy $|w_{k}| \leq 1$, the coordinates $ \{(\bm{r}_k)\}_{k=1}^{K} $ are the centers of each pixel, and the aperture function $a(\cdot)$ of each pixel is assumed to be identical. 
%\textbf{TODO keep?}\cref{eq:mask_gen_main} explicitly models the deadspace around pixels, \ie the regions between pixel that are not controllable and are opaque. Previous work does not account for this, and simply discretizes the mask plane.
For a mask with a color filter, there is an additional dependence on the wavelength $\lambda$:
\begin{align}
	\label{eq:mask_gen_main_wv}
	m(\bm{r}; \lambda) &= \sum_{c\in\mathcal{C}} \gamma_c(\lambda)  \, \sum_{k_c \in K_c}
	% w_{k_c}(\lambda) 
	w_{k_c}
	a(\bm{r} -\bm{r}_{k_c}),
\end{align}
where $\gamma_c$ is the wavelength sensitivity function for a specific color filter $c$, and $K_c$ is the set of pixels corresponding to $c$. 
\cref{eq:mask_gen_main_wv} accounts for the pixel pitch and deadspace of the mask by setting the appropriate centers $ \{(\bm{r}_{k_c})\}_{k_c=1}^{K_c} $.
An alternative approach to account for pixel pitch is to modify the wave propagation model to include higher-order diffraction and attenuation~\cite{Gopakumar:21}, but this approach does not account for the deadspace.

For our component~\cite{adafruitlcd}, the pixel value weights $w_{k_c}$ are real-valued, as the LCD only modulates amplitude.
Moreover, we do not have the ground-truth color functions $\gamma_c$, but since our LCD and sensor both have color filters $ c\in\{R,G,B\} $, we compute the mask function as:
\begin{align}
	\label{eq:mask_simple_app}
	m(\bm{r}; \lambda=\lambda_c) &= \sum_{k_c \in K_c}
	% w_{k_c}(\lambda) 
	w_{k_c}
	a(\bm{r} -\bm{r}_{k_c}), \quad c\in\{R,G,B\},
\end{align}
with a narrowband around the RGB wavelengths. 
Furthermore, each aperture function $a(\cdot)$ is modeled as a rectangle of size $\SI{0.06}{\milli\meter}\times\SI{0.18}{\milli\meter}$ (the dimensions of each sub-pixel).

% \newpage
% ~
% \newpage
% ~
% \newpage
\section{Comparison Between Simulated and Measured Point Spread Functions}
\label{app:compare_psf}



\newcommand{\figsizecelebadmm}{0.115}
\begin{figure*}[t!]
	\centering
	\renewcommand{\arraystretch}{1} % Default value: 1
	\setlength{\tabcolsep}{0.2em} % for the horizontal padding
	%\begin{table}[t!]
	\begin{tabular}{cccccccc}
    \multicolumn{2}{c}{Measured PSF (\cref{fig:digicam_celeba_meas})} 
    &
    \multicolumn{2}{c}{\makecell{Simulated PSF without\\wave propagation (\cref{fig:digicam_celeba_nowave})}}
    &
    \multicolumn{2}{c}{\makecell{Simulated PSF without\\deadspace (\cref{fig:digicam_celeba_wave_nodead})}}
    &
 \multicolumn{2}{c}{\makecell{Simulated PSF with\\wave propagation (\cref{fig:digicam_celeba_wave})}}
     % &
 % \multicolumn{2}{c}{\makecell{Simulated PSF with higher\\diffraction orders (\cref{fig:digicam_celeba_higherorder})}}
    \\ 
    \cmidrule(r){1-2} \cmidrule(r){3-4} \cmidrule(r){5-6} \cmidrule(r){7-8} 
    \includegraphics[width=\figsizecelebadmm\linewidth,valign=m]{figs/benchmark_digicam_celeba/ADMM_measured/100/4.png}
		&
        \includegraphics[width=\figsizecelebadmm\linewidth,valign=m]{figs/benchmark_digicam_celeba/ADMM_measured/100/9.png} &
        \includegraphics[width=\figsizecelebadmm\linewidth,valign=m]{figs/benchmark_digicam_celeba/ADMM_sim_nowaveprop/100/4.png}
        &
        \includegraphics[width=\figsizecelebadmm\linewidth,valign=m]{figs/benchmark_digicam_celeba/ADMM_sim_nowaveprop/100/9.png}
        &

        \includegraphics[width=\figsizecelebadmm\linewidth,valign=m]{figs/benchmark_digicam_celeba/ADMM_sim_no_deadspace/100/4.png}
        &
        \includegraphics[width=\figsizecelebadmm\linewidth,valign=m]{figs/benchmark_digicam_celeba/ADMM_sim_no_deadspace/100/9.png}
        &
        
\includegraphics[width=\figsizecelebadmm\linewidth,valign=m]{figs/benchmark_digicam_celeba/ADMM/100/4.png}
		&  \includegraphics[width=\figsizecelebadmm\linewidth,valign=m]{figs/benchmark_digicam_celeba/ADMM/100/9.png}
		\\
	\end{tabular}
	\caption{\textit{ADMM100} reconstructions of measured data with simulated and measured PSFs of \textit{DigiCam}. Ground-truth data can be seen in \cref{fig:celeba_ground_truth}.}
	\label{fig:sim_vs_meas_recon}
\end{figure*}

\begin{figure}[t!]
		\centering
\includegraphics[width=0.25\linewidth]{figs/celeba_26k/original/4.png}
\includegraphics[width=0.25\linewidth]{figs/celeba_26k/original/9.png}
	\caption{Ground-truth CelebA data~\cite{digicam_celeba}.}
	\label{fig:celeba_ground_truth}
\end{figure}

\begin{table}[!t]
	\renewcommand{\arraystretch}{1.3}
	\caption{Average image quality metrics to compare using simulated PSF variants against a measured PSF for image recovery on the test set of \textit{DigiCam-CelebA} with 100 iterations of ADMM.}
	\label{tab:sim_v_meas}
	\centering
	\begin{tabular}{c|c|c|c}
		\hline
		 & PSNR $\uparrow$ & SSIM $\uparrow$ & LPIPS $\downarrow$ \\
		\hline\hline
		Measured PSF (\cref{fig:digicam_celeba_meas}) &   9.38 & 0.294 & \textbf{0.695}  \\
  \hline
  \makecell{Simulated PSF without\\wave propagation (\cref{fig:digicam_celeba_nowave})} & 10.1 & 0.352 & 0.737 \\
  \hline
  \makecell{Simulated PSF without\\deadspace(\cref{fig:digicam_celeba_wave_nodead})} & 10.0 & 0.345 & 0.730 \\
  \hline
  \makecell{Simulated PSF with\\wave propagation  and\\deadspace(\cref{fig:digicam_celeba_wave})} & \textbf{10.2} & \textbf{0.356} & 0.739  \\
  % \hline
  % \makecell{Simulated PSF with higher\\diffraction orders (\cref{fig:digicam_celeba_higherorder})} &  &  &  \\
  \hline
	\end{tabular}
\end{table}

\noindent \cref{fig:compared_psfs_crop_app} compares a PSF measured with a white LED (\cref{fig:digicam_celeba_meas}) with PSFs simulated with different approaches:
\begin{itemize}
    \item \textit{Without wave propagation} (\cref{fig:digicam_celeba_nowave}): Simply using \cref{eq:mask_simple_app} as the PSF.
    \item \textit{Without deadspace} (\cref{fig:digicam_celeba_nowave}): 
%    When forming the mask function with \cref{eq:mask_simple_app} for propagation with \cref{eq:wavefield_app},
%    all adjustable pixels are concatenated. In other words, the mask can be considered as a 
    The mask is modeled as a single aperture with dimensions $(Mp, Np)$ where $(M,N)$ is the dimensions of the programmable array and $p$ is the pixel pitch.
    \item \textit{With wave propagation and deadspace} (\cref{fig:digicam_celeba_wave}): When forming the mask function with \cref{eq:mask_simple_app}, the pixel centers $ \{(\bm{r}_k)\}_{k=1}^{K} $ account for the aperture of each sub-pixel and the pixel pitch, such that there is a \textit{deadspace} between pixels that is occluding, \ie due to the mask's circuitry.
\end{itemize}
We can observe that incorporating deadspace (\ie \cref{fig:digicam_celeba_nowave,fig:digicam_celeba_wave}) more closely resembles the structure of the measured PSF in \cref{fig:digicam_celeba_meas}.

For PSF simulation, we are ultimately interested in how well a PSF describes the forward model to obtain a high-quality reconstruction, 
\ie a PSF that faithfully describes the forward model in \cref{eq:opt_gen_app}.
To this end, we compare each PSF when used to reconstruct images from the \textit{DigiCam-CelebA} dataset~\cite{digicam_celeba} with 100 iterations of ADMM.
\cref{tab:sim_v_meas} compares the average image quality metrics on the test set (3900 files).
All the simulated PSFs yield similar image quality metrics,
while using the measured PSF is worse with regards to PSNR/SSIM but better in LPIPS.

\cref{fig:sim_vs_meas_recon} shows example outputs. All simulated PSFs yield reconstructions that look very similar.
While the measured PSF yields a reddish-reconstruction,
the overall quality is very similar to those of the simulated PSFs.
% This difference likely arises from not properly modeling the wavelength sensitivity, \ie with \cref{eq:mask_gen_main_wv}.
In both cases, the reddish/greenish tint can be removed with white-balancing (which can also be learned by the post-processor). 

For the \textit{DigiCam-Multi} dataset~\cite{digicam_multi} that consists of 100 different masks patterns,
we rely on simulated PSFs to avoid the hassle of measuring 100 PSFs.
To this end, we use wave propagation and deadspace as it is more realistic.

% \newpage

\section{Intermediate Outputs}
\label{app:intermediate}

\noindent\cref{fig:intermediate_diffusercam} shows intermediate outputs for various models trained on the \textit{DiffuserCam} dataset~\cite{Monakhova:19}.
When only using a pre-processor ($\text{Pre}_8$+LeADMM5),
we can observe more consistent coloring but the final outputs lack the perceptual enhancements that a post-processor can perform after the camera inversion.
Using both a pre-processor and a post-processor achieves the best results (Table III in main paper), 
but the intermediate outputs (\eg camera inversion output) may be less interpretable (last two rows of \cref{fig:intermediate_diffusercam}).

To improve the interpretability of intermediate outputs,
an auxiliary loss can be used from the camera inversion output during training~\cite{Perron2023}:
\begin{align}
        \mathscr{L}_{\text{res}}\left(\bm{x},\bm{\hat{x}},\bm{\hat{x}}_{\text{inv}}\right) = \mathscr{L}\left(\bm{x},\bm{\hat{x}}\right) + \alpha \hspace{0.2em} \mathscr{L}\left(\bm{x},\bm{\hat{x}}_{\text{inv}}\right).
\end{align}
where the loss $\mathscr{L}\left(\bm{x},\bm{\hat{x}}\right)$ can be a combined MSE and LPIPS loss (\ie \cref{eq:loss_mse_lpips}), $\bm{\hat{x}}$ is the output of the post-processor, 
$\bm{\hat{x}}_{\text{inv}}$ is the output of camera inversion, and $\alpha$ weights the amount of auxiliary loss.
Higher values of $\alpha$ can lead to more consistent coloring at the camera inversion output,
but to slightly worse image quality metrics~\cite{Perron2023}.

\cref{fig:intermediate_diffusercam_noise,fig:intermediate_diffusercam_noisy_psf} shows intermediate outputs for our robustness experiments in the main paper:
simulated shot noise in the measurement (\cref{sec:shot_noise_exp}) and mismatch in the PSF (\cref{sec:mismatch_exp}).
While the intermediate outputs of approaches that use a pre-processor are significantly different with respect to coloring,
the robustness to measurement noise and model mismatch is much better (see Tables IV and V in the main paper).
As mentioned above,
using an auxiliary loss can lead to more consistent coloring at the camera inversion output but at the expense of slightly worse image quality metrics.

\cref{fig:intermediate_tapecam,fig:intermediate_tapecam} show intermediate outputs for \textit{TapeCam} and \textit{DigiCam}.
We observe similar behavior as with \textit{DiffuserCam}:
significant discoloring at the camera inversion output when both pre- and post-processor are used.

\newcommand{\figsizeinter}{0.19}
\newcommand{\newlineinter}{32pt}
\begin{figure*}[t!]
\centering
	\begingroup
	\renewcommand{\arraystretch}{1} % Default value: 1
	\setlength{\tabcolsep}{0.08em} % for the horizontal padding
	%\begin{table}[t!]
	\begin{tabular}{c cccc}
		  & Lensless measurement & PSF for inversion & Camera inversion output & Final output \\
    
\makecell{LeADMM5\\+$\text{Post}_8$~\cite{Monakhova:19}} 
  & \includegraphics[width=\figsizeinter\linewidth,valign=m]{figs/benchmark_diffusercam/LENSLESS/1.png}
  & \includegraphics[width=\figsizeinter\linewidth,valign=m]{figs/fig3_diffusercam_psf.png}
   & \includegraphics[width=\figsizeinter\linewidth,valign=m]{figs/intermediate_outputs/diffusercam/hf_diffusercam_mirflickr_U5+Unet8M/1_inv.png}
  & \includegraphics[width=\figsizeinter\linewidth,valign=m]{figs/intermediate_outputs/diffusercam/hf_diffusercam_mirflickr_U5+Unet8M/1.png}
\\[\newlineinter]

& Pre-processor output &  &  &  \\

\makecell{$\text{Pre}_8$+LeADMM5} 
  & \includegraphics[width=\figsizeinter\linewidth,valign=m]{figs/intermediate_outputs/diffusercam/hf_diffusercam_mirflickr_Unet8M+U5/1_preproc.png}  
  & 
\includegraphics[width=\figsizeinter\linewidth,valign=m]{figs/fig3_diffusercam_psf.png}
  & 
\includegraphics[width=\figsizeinter\linewidth,valign=m]{figs/intermediate_outputs/diffusercam/hf_diffusercam_mirflickr_Unet8M+U5/1_inv.png} 
  & 
\\[\newlineinter]

\makecell{$\text{Pre}_4$+LeADMM5\\+$\text{Post}_4$} 
  & \includegraphics[width=\figsizeinter\linewidth,valign=m]{figs/intermediate_outputs/diffusercam/hf_diffusercam_mirflickr_Unet4M+U5+Unet4M/1_preproc.png}  
  & 
\includegraphics[width=\figsizeinter\linewidth,valign=m]{figs/fig3_diffusercam_psf.png}
  & 
\includegraphics[width=\figsizeinter\linewidth,valign=m]{figs/intermediate_outputs/diffusercam/hf_diffusercam_mirflickr_Unet4M+U5+Unet4M/1_inv.png} 
  & \includegraphics[width=\figsizeinter\linewidth,valign=m]{figs/intermediate_outputs/diffusercam/hf_diffusercam_mirflickr_Unet4M+U5+Unet4M/1.png} 
\\[\newlineinter]
& & Corrected PSF &  &  \\
\makecell{$\text{Pre}_4$+LeADMM5\\+$\text{Post}_4$ (PSF correction)} 
  & \includegraphics[width=\figsizeinter\linewidth,valign=m]{figs/intermediate_outputs/diffusercam/hf_diffusercam_mirflickr_Unet4M+U5+Unet4M_psfNN/1_preproc.png} 
  & 
\includegraphics[width=\figsizeinter\linewidth,valign=m]{figs/intermediate_outputs/diffusercam/hf_diffusercam_mirflickr_Unet4M+U5+Unet4M_psfNN/1_psfs_corr.png}
  & 
\includegraphics[width=\figsizeinter\linewidth,valign=m]{figs/intermediate_outputs/diffusercam/hf_diffusercam_mirflickr_Unet4M+U5+Unet4M_psfNN/1_inv.png} 
  & 
  \includegraphics[width=\figsizeinter\linewidth,valign=m]{figs/intermediate_outputs/diffusercam/hf_diffusercam_mirflickr_Unet4M+U5+Unet4M_psfNN/1.png}
\\
	\end{tabular}
	%\end{table}
	\endgroup
	\caption{Intermediate outputs for \textit{DiffuserCam}.}
  \label{fig:intermediate_diffusercam}
\end{figure*}



\newcommand{\figsizeinternoisy}{0.135}
\newcommand{\newlineinternoisy}{15pt}
\begin{figure*}[t!]
\centering
	\begingroup
	\renewcommand{\arraystretch}{1} % Default value: 1
	\setlength{\tabcolsep}{0.08em} % for the horizontal padding
	%\begin{table}[t!]
	\begin{tabular}{c cccc}
		  & Lensless measurement & Camera inversion output & Final output \\
    
\makecell{LeADMM5\\+$\text{Post}_8$~\cite{Monakhova:19}} 
  & 
  \includegraphics[width=\figsizeinternoisy\linewidth,valign=m]{figs/intermediate_outputs/diffusercam_10db/LENSLESS/0.png}
\includegraphics[width=\figsizeinternoisy\linewidth,valign=m]{figs/intermediate_outputs/diffusercam_10db/LENSLESS/1.png}
   & 
\includegraphics[width=\figsizeinternoisy\linewidth,valign=m]{figs/intermediate_outputs/diffusercam_10db/hf_diffusercam_mirflickr_U5+Unet8M_10db/0_inv.png}
\includegraphics[width=\figsizeinternoisy\linewidth,valign=m]{figs/intermediate_outputs/diffusercam_10db/hf_diffusercam_mirflickr_U5+Unet8M_10db/1_inv.png}
  & 
\includegraphics[width=\figsizeinternoisy\linewidth,valign=m]{figs/intermediate_outputs/diffusercam_10db/hf_diffusercam_mirflickr_U5+Unet8M_10db/0.png}
\includegraphics[width=\figsizeinternoisy\linewidth,valign=m]{figs/intermediate_outputs/diffusercam_10db/hf_diffusercam_mirflickr_U5+Unet8M_10db/1.png}
\\[\newlineinternoisy]

& Pre-processor output &  &  &  \\

\makecell{$\text{Pre}_4$\\+LeADMM5\\+$\text{Post}_4$} 
  & 
\includegraphics[width=\figsizeinternoisy\linewidth,valign=m]{figs/intermediate_outputs/diffusercam_10db/hf_diffusercam_mirflickr_Unet4M+U5+Unet4M_10db/0_preproc.png} \includegraphics[width=\figsizeinternoisy\linewidth,valign=m]{figs/intermediate_outputs/diffusercam_10db/hf_diffusercam_mirflickr_Unet4M+U5+Unet4M_10db/1_preproc.png}  
  & 
\includegraphics[width=\figsizeinternoisy\linewidth,valign=m]{figs/intermediate_outputs/diffusercam_10db/hf_diffusercam_mirflickr_Unet4M+U5+Unet4M_10db/0_inv.png} 
\includegraphics[width=\figsizeinternoisy\linewidth,valign=m]{figs/intermediate_outputs/diffusercam_10db/hf_diffusercam_mirflickr_Unet4M+U5+Unet4M_10db/1_inv.png} 
  &
\includegraphics[width=\figsizeinternoisy\linewidth,valign=m]{figs/intermediate_outputs/diffusercam_10db/hf_diffusercam_mirflickr_Unet4M+U5+Unet4M_10db/0.png} 
\includegraphics[width=\figsizeinternoisy\linewidth,valign=m]{figs/intermediate_outputs/diffusercam_10db/hf_diffusercam_mirflickr_Unet4M+U5+Unet4M_10db/1.png} 
\\
	\end{tabular}
	%\end{table}
	\endgroup
	\caption{Intermediate outputs for \textit{DiffuserCam} in the presence of digitally-added Poisson noise with an SNR of \SI{10}{\decibel}.}
  \label{fig:intermediate_diffusercam_noise}
\end{figure*}

\begin{figure*}[t!]
\centering
	\begingroup
	\renewcommand{\arraystretch}{1} % Default value: 1
	\setlength{\tabcolsep}{0.08em} % for the horizontal padding
	%\begin{table}[t!]
	\begin{tabular}{c cccc}
		  & Lensless measurement & Camera inversion output & Final output \\
    
\makecell{LeADMM5\\+$\text{Post}_8$~\cite{Monakhova:19}} 
  & 
  \includegraphics[width=\figsizeinternoisy\linewidth,valign=m]{figs/intermediate_outputs/diffusercam_psf_0db/LENSLESS/0.png}
\includegraphics[width=\figsizeinternoisy\linewidth,valign=m]{figs/intermediate_outputs/diffusercam_psf_0db/LENSLESS/1.png}
   & 
\includegraphics[width=\figsizeinternoisy\linewidth,valign=m]{figs/intermediate_outputs/diffusercam_psf_0db/hf_diffusercam_mirflickr_U5+Unet8M_psf0dB/0_inv.png}
\includegraphics[width=\figsizeinternoisy\linewidth,valign=m]{figs/intermediate_outputs/diffusercam_psf_0db/hf_diffusercam_mirflickr_U5+Unet8M_psf0dB/1_inv.png}
  & 
\includegraphics[width=\figsizeinternoisy\linewidth,valign=m]{figs/intermediate_outputs/diffusercam_psf_0db/hf_diffusercam_mirflickr_U5+Unet8M_psf0dB/0.png}
\includegraphics[width=\figsizeinternoisy\linewidth,valign=m]{figs/intermediate_outputs/diffusercam_psf_0db/hf_diffusercam_mirflickr_U5+Unet8M_psf0dB/1.png}
\\[\newlineinternoisy]

& Pre-processor output &  &  &  \\


\makecell{$\text{Pre}_4$\\+LeADMM5\\+$\text{Post}_4$} 
  & 
  \includegraphics[width=\figsizeinternoisy\linewidth,valign=m]{figs/intermediate_outputs/diffusercam_psf_0db/hf_diffusercam_mirflickr_Unet4M+U5+Unet4M_psf-0dB/0_preproc.png}
\includegraphics[width=\figsizeinternoisy\linewidth,valign=m]{figs/intermediate_outputs/diffusercam_psf_0db/hf_diffusercam_mirflickr_Unet4M+U5+Unet4M_psf-0dB/1_preproc.png}
   & 
\includegraphics[width=\figsizeinternoisy\linewidth,valign=m]{figs/intermediate_outputs/diffusercam_psf_0db/hf_diffusercam_mirflickr_Unet4M+U5+Unet4M_psf-0dB/0_inv.png}
\includegraphics[width=\figsizeinternoisy\linewidth,valign=m]{figs/intermediate_outputs/diffusercam_psf_0db/hf_diffusercam_mirflickr_Unet4M+U5+Unet4M_psf-0dB/1_inv.png}
  & 
\includegraphics[width=\figsizeinternoisy\linewidth,valign=m]{figs/intermediate_outputs/diffusercam_psf_0db/hf_diffusercam_mirflickr_Unet4M+U5+Unet4M_psf-0dB/0.png}
\includegraphics[width=\figsizeinternoisy\linewidth,valign=m]{figs/intermediate_outputs/diffusercam_psf_0db/hf_diffusercam_mirflickr_Unet4M+U5+Unet4M_psf-0dB/1.png}
\\[\newlineinternoisy]

\makecell{$\text{Pre}_4$+LeADMM5\\+$\text{Post}_4$ (PSF corr.)} 
  & 
\includegraphics[width=\figsizeinternoisy\linewidth,valign=m]{figs/intermediate_outputs/diffusercam_psf_0db/hf_diffusercam_mirflickr_Unet4M+U5+Unet4M_psfNN_psf-0dB/0_preproc.png}
\includegraphics[width=\figsizeinternoisy\linewidth,valign=m]{figs/intermediate_outputs/diffusercam_psf_0db/hf_diffusercam_mirflickr_Unet4M+U5+Unet4M_psfNN_psf-0dB/1_preproc.png}
  & 
\includegraphics[width=\figsizeinternoisy\linewidth,valign=m]{figs/intermediate_outputs/diffusercam_psf_0db/hf_diffusercam_mirflickr_Unet4M+U5+Unet4M_psfNN_psf-0dB/0_inv.png}
\includegraphics[width=\figsizeinternoisy\linewidth,valign=m]{figs/intermediate_outputs/diffusercam_psf_0db/hf_diffusercam_mirflickr_Unet4M+U5+Unet4M_psfNN_psf-0dB/1_inv.png}
  &
\includegraphics[width=\figsizeinternoisy\linewidth,valign=m]{figs/intermediate_outputs/diffusercam_psf_0db/hf_diffusercam_mirflickr_Unet4M+U5+Unet4M_psfNN_psf-0dB/0.png}
\includegraphics[width=\figsizeinternoisy\linewidth,valign=m]{figs/intermediate_outputs/diffusercam_psf_0db/hf_diffusercam_mirflickr_Unet4M+U5+Unet4M_psfNN_psf-0dB/1.png}
\\
	\end{tabular}
	%\end{table}
	\endgroup
	\caption{Intermediate outputs for \textit{DiffuserCam} when model mismatch is added to the PSF (Gaussian noise with an SNR of \SI{0}{\decibel}).}
\label{fig:intermediate_diffusercam_noisy_psf}
\end{figure*}




\newcommand{\figsizeinterrpi}{0.17}
\begin{figure*}[t!]
\centering
	\begingroup
	\renewcommand{\arraystretch}{1} % Default value: 1
	\setlength{\tabcolsep}{0.08em} % for the horizontal padding
	%\begin{table}[t!]
	\begin{tabular}{c cccc}
	 & Lensless measurement &  PSF for inversion & Camera inversion output & Final output (cropped) \\

    \makecell{LeADMM5\\+$\text{Post}_8$~\cite{Monakhova:19}} 
  & 
\includegraphics[width=\figsizeinterrpi\linewidth,valign=m]{figs/benchmark_tapecam/LENSLESS/2.png}

  & 
  \includegraphics[width=\figsizeinterrpi\linewidth,valign=m]{figs/fig3_tapecam_psf.png}
   & 
   \includegraphics[width=\figsizeinterrpi\linewidth,valign=m]{figs/intermediate_outputs/tapecam/hf_tapecam_mirflickr_U5+Unet8M/2_inv.png}
  & \includegraphics[width=\figsizeinterrpi\linewidth,valign=m]{figs/intermediate_outputs/tapecam/hf_tapecam_mirflickr_U5+Unet8M/2.png}
\\[\newlineinter]

& Pre-processor output & &  &  \\
\makecell{$\text{Pre}_8$+LeADMM5} 
  & \includegraphics[width=\figsizeinterrpi\linewidth,valign=m]{figs/intermediate_outputs/tapecam/hf_tapecam_mirflickr_Unet8M+U5/2_preproc.png}  
  & 
\includegraphics[width=\figsizeinterrpi\linewidth,valign=m]{figs/fig3_tapecam_psf.png}
  & 
\includegraphics[width=\figsizeinterrpi\linewidth,valign=m]{figs/intermediate_outputs/tapecam/hf_tapecam_mirflickr_Unet8M+U5/2_inv.png} 
  & 
\\[\newlineinter]

\makecell{$\text{Pre}_4$+LeADMM5\\+$\text{Post}_4$} 
  & 

\includegraphics[width=\figsizeinterrpi\linewidth,valign=m]{figs/intermediate_outputs/tapecam/hf_tapecam_mirflickr_Unet4M+U5+Unet4M/2_preproc.png}  
  & 
\includegraphics[width=\figsizeinterrpi\linewidth,valign=m]{figs/fig3_tapecam_psf.png}
  & 
\includegraphics[width=\figsizeinterrpi\linewidth,valign=m]{figs/intermediate_outputs/tapecam/hf_tapecam_mirflickr_Unet4M+U5+Unet4M/2_inv.png}
  & \includegraphics[width=\figsizeinterrpi\linewidth,valign=m]{figs/intermediate_outputs/tapecam/hf_tapecam_mirflickr_Unet4M+U5+Unet4M/2.png}
\\[\newlineinter]
& & Corrected PSF &  &  \\
\makecell{$\text{Pre}_4$+LeADMM5\\+$\text{Post}_4$ (PSF correction)} 
  & \includegraphics[width=\figsizeinterrpi\linewidth,valign=m]{figs/intermediate_outputs/tapecam/hf_tapecam_mirflickr_Unet4M+U5+Unet4M_psfNN/2_preproc.png} 
  & 
\includegraphics[width=\figsizeinterrpi\linewidth,valign=m]{figs/intermediate_outputs/tapecam/hf_tapecam_mirflickr_Unet4M+U5+Unet4M_psfNN/2_psfs.png}
  & 
\includegraphics[width=\figsizeinterrpi\linewidth,valign=m]{figs/intermediate_outputs/tapecam/hf_tapecam_mirflickr_Unet4M+U5+Unet4M_psfNN/2_inv.png} 
  & 
  \includegraphics[width=\figsizeinterrpi\linewidth,valign=m]{figs/intermediate_outputs/tapecam/hf_tapecam_mirflickr_Unet4M+U5+Unet4M_psfNN/2.png}
\\
	\end{tabular}
	%\end{table}
	\endgroup
	\caption{Intermediate outputs for \textit{TapeCam}.}
  \label{fig:intermediate_tapecam}
\end{figure*}



\begin{figure*}[t!]
\centering
	\begingroup
	\renewcommand{\arraystretch}{1} % Default value: 1
	\setlength{\tabcolsep}{0.08em} % for the horizontal padding
	%\begin{table}[t!]
	\begin{tabular}{c cccc}
		  & Lensless measurement & PSF for inversion & Camera inversion output & Final output (cropped) \\
    
\makecell{LeADMM5\\+$\text{Post}_8$~\cite{Monakhova:19}} 
  & \includegraphics[width=\figsizeinterrpi\linewidth,valign=m]{figs/benchmark_digicam_mirflickr/LENSLESS/2.png}
  & \includegraphics[width=\figsizeinterrpi\linewidth,valign=m]{figs/fig3_DigiCam-Mirflickr-SingleMask-25K_psf.png}
   & \includegraphics[width=\figsizeinterrpi\linewidth,valign=m]{figs/intermediate_outputs/digicam/hf_digicam_mirflickr_single_25k_U5+Unet8M_wave/2_inv.png}
  & \includegraphics[width=\figsizeinterrpi\linewidth,valign=m]{figs/intermediate_outputs/digicam/hf_digicam_mirflickr_single_25k_U5+Unet8M_wave/2.png}
\\[\newlineinter]

& Pre-processor output &  &  &  \\
\makecell{$\text{Pre}_8$+LeADMM5} 
  & \includegraphics[width=\figsizeinterrpi\linewidth,valign=m]{figs/intermediate_outputs/digicam/hf_digicam_mirflickr_single_25k_Unet8M+U5_wave/2_preproc.png}  
  & 
\includegraphics[width=\figsizeinterrpi\linewidth,valign=m]{figs/fig3_DigiCam-Mirflickr-SingleMask-25K_psf.png}
  & 
\includegraphics[width=\figsizeinterrpi\linewidth,valign=m]{figs/intermediate_outputs/digicam/hf_digicam_mirflickr_single_25k_Unet8M+U5_wave/2_inv.png} 
  & 
\\[\newlineinter]

\makecell{$\text{Pre}_4$+LeADMM5\\+$\text{Post}_4$} 
  & \includegraphics[width=\figsizeinterrpi\linewidth,valign=m]{figs/intermediate_outputs/digicam/hf_digicam_mirflickr_single_25k_Unet4M+U5+Unet4M_wave/2_preproc.png}  
  & 
\includegraphics[width=\figsizeinterrpi\linewidth,valign=m]{figs/fig3_DigiCam-Mirflickr-SingleMask-25K_psf.png}
  & 
\includegraphics[width=\figsizeinterrpi\linewidth,valign=m]{figs/intermediate_outputs/digicam/hf_digicam_mirflickr_single_25k_Unet4M+U5+Unet4M_wave/2_inv.png}
  & \includegraphics[width=\figsizeinterrpi\linewidth,valign=m]{figs/intermediate_outputs/digicam/hf_digicam_mirflickr_single_25k_Unet4M+U5+Unet4M_wave/2.png}
\\[\newlineinter]
& & Corrected PSF &  &  \\
\makecell{$\text{Pre}_4$+LeADMM5\\+$\text{Post}_4$ (PSF correction)} 
  & \includegraphics[width=\figsizeinterrpi\linewidth,valign=m]{figs/intermediate_outputs/digicam/hf_digicam_mirflickr_single_25k_Unet4M+U5+Unet4M_wave_psfNN/2_preproc.png} 
  & 
\includegraphics[width=\figsizeinterrpi\linewidth,valign=m]{figs/intermediate_outputs/digicam/hf_digicam_mirflickr_single_25k_Unet4M+U5+Unet4M_wave_psfNN/2_psfs.png}
  & 
\includegraphics[width=\figsizeinterrpi\linewidth,valign=m]{figs/intermediate_outputs/digicam/hf_digicam_mirflickr_single_25k_Unet4M+U5+Unet4M_wave_psfNN/2_inv.png} 
  & 
  \includegraphics[width=\figsizeinterrpi\linewidth,valign=m]{figs/intermediate_outputs/digicam/hf_digicam_mirflickr_single_25k_Unet4M+U5+Unet4M_wave_psfNN/2.png}
\\
	\end{tabular}
	%\end{table}
	\endgroup
	\caption{Intermediate outputs for \textit{DigiCam}.}
  \label{fig:intermediate_digicam}
\end{figure*}

% \newpage
% ~
% \newpage
\section{Benchmark Generalizability to PSF Changes with PSF Correction Models}
\label{app:gen_benchmark_psf_corr}

\noindent\cref{fig:exp2_visual_comparison_psfNN} performs a similar evaluation as that of \cref{fig:exp2_visual_comparison},
namely evaluating a model
% 
trained on measurements from one system on measurements from other systems.
However, in \cref{fig:exp2_visual_comparison_psfNN} 
the evaluated models are ($\textit{Pre}_{4}$\textit{+LeADMM5+}$\textit{Post}_{4}$) \textit{with PSF correction}, 
\ie by inputting the PSF to a DRUNet with (4, 8, 16, 32) feature representation channels (128K parameters) prior to camera inversion.
The pre-processor is slightly decreased to (32, 64, 112, 128) channels (3.9M parameters) to maintain an approximately equivalent number of parameters as the model without PSF correction.
Even with PSF correction, we observe similar behavior as in Fig.~8 of the main paper:
image recovery approaches trained on measurements from a single system fail to generalize to measurements of other systems.

% \newcommand{\figsizegentrans}{0.085}
% \newcommand{\figsizegencelebatrans}{0.07}
\begin{figure*}[t!]
\centering
	\renewcommand{\arraystretch}{1} % Default value: 1
	\setlength{\tabcolsep}{0.1em} % for the horizontal padding
	%\begin{table}[t!]
	\begin{tabular}{c|cc|cc|cc||cc|cc}
    % \textit{Train} $\downarrow$\textbackslash \textit{Test} $\rightarrow$
    \makecell{\textit{Train set} $\rightarrow$\\\textit{Test set} $\downarrow$}
    &   
    \multicolumn{2}{c|}{DiffuserCam}
    & \multicolumn{2}{c|}{TapeCam}
    & \multicolumn{2}{c||}{DigiCam-Single}
    & \multicolumn{2}{c|}{\makecell{ADMM100\\(no training)}}
    & 
    % \multicolumn{2}{c}{\makecell{Raw data +\\ground-truth}}
    \multicolumn{2}{c}{Ground-truth}
    \\
    % \cmidrule(r){2-3} \cmidrule(r){4-5} \cmidrule(r){6-7} \cmidrule(r){8-9} 
\hline 
% \\[0.1pt]
\makecell{DiffuserCam}
&\includegraphics[width=\figsizegentrans\linewidth,valign=m]{figs/benchmark_diffusercam/hf_diffusercam_mirflickr_Unet4M+U5+Unet4M_psfNN/3.png}
&\includegraphics[width=\figsizegentrans\linewidth,valign=m]{figs/benchmark_diffusercam/hf_diffusercam_mirflickr_Unet4M+U5+Unet4M_psfNN/4.png}
&\includegraphics[width=\figsizegentrans\linewidth,valign=m]{figs/benchmark_diffusercam/hf_tapecam_mirflickr_Unet4M+U5+Unet4M_psfNN/3.png}
&\includegraphics[width=\figsizegentrans\linewidth,valign=m]{figs/benchmark_diffusercam/hf_tapecam_mirflickr_Unet4M+U5+Unet4M_psfNN/4.png}
&\includegraphics[width=\figsizegentrans\linewidth,valign=m]{figs/benchmark_diffusercam/hf_digicam_mirflickr_single_25k_Unet4M+U5+Unet4M_wave_psfNN/3.png}
&\includegraphics[width=\figsizegentrans\linewidth,valign=m]{figs/benchmark_diffusercam/hf_digicam_mirflickr_single_25k_Unet4M+U5+Unet4M_wave_psfNN/4.png}
&\includegraphics[width=\figsizegentrans\linewidth,valign=m]{figs/benchmark_diffusercam/ADMM/100/3.png}
 
&\includegraphics[width=\figsizegentrans\linewidth,valign=m]{figs/benchmark_diffusercam/ADMM/100/4.png}

&\includegraphics[width=\figsizegentrans\linewidth,valign=m]{figs/benchmark_diffusercam/GROUND_TRUTH/3.png}
% \llap{\shortstack[l]{%
% 		\hspace{-1cm}\includegraphics[scale=.05]{figs/benchmark_diffusercam/LENSLESS/3.png}\\
% 		\rule{0ex}{0.1in}%
% 	}
% 	\rule{0.2in}{0ex}}
&\includegraphics[width=\figsizegentrans\linewidth,valign=m]{figs/benchmark_diffusercam/GROUND_TRUTH/4.png}
% \llap{\shortstack[l]{%
% 		\hspace{-1cm}\includegraphics[scale=.05]{figs/benchmark_diffusercam/LENSLESS/4.png}\\
% 		\rule{0ex}{0.1in}%
% 	}
% 	\rule{0.2in}{0ex}}
    \\[6pt]
\hline 
\makecell{TapeCam}
&\includegraphics[width=\figsizegentrans\linewidth,valign=m]{figs/benchmark_tapecam/hf_diffusercam_mirflickr_Unet4M+U5+Unet4M_psfNN/4.png}
&\includegraphics[width=\figsizegentrans\linewidth,valign=m]{figs/benchmark_tapecam/hf_diffusercam_mirflickr_Unet4M+U5+Unet4M_psfNN/5.png}
&\includegraphics[width=\figsizegentrans\linewidth,valign=m]{figs/benchmark_tapecam/hf_tapecam_mirflickr_Unet4M+U5+Unet4M_psfNN/4.png}
&\includegraphics[width=\figsizegentrans\linewidth,valign=m]{figs/benchmark_tapecam/hf_tapecam_mirflickr_Unet4M+U5+Unet4M_psfNN/5.png}
&\includegraphics[width=\figsizegentrans\linewidth,valign=m]{figs/benchmark_tapecam/hf_digicam_mirflickr_single_25k_Unet4M+U5+Unet4M_wave_psfNN/4.png}
&\includegraphics[width=\figsizegentrans\linewidth,valign=m]{figs/benchmark_tapecam/hf_digicam_mirflickr_single_25k_Unet4M+U5+Unet4M_wave_psfNN/5.png}
&\includegraphics[width=\figsizegentrans\linewidth,valign=m]{figs/benchmark_tapecam/ADMM/100/4.png}
&\includegraphics[width=\figsizegentrans\linewidth,valign=m]{figs/benchmark_tapecam/ADMM/100/5.png}

&\includegraphics[width=\figsizegentrans\linewidth,valign=m]{figs/benchmark_tapecam/GROUND_TRUTH/4.png}
% \llap{\shortstack[l]{%
% 		\hspace{-1cm}\includegraphics[scale=.025]{figs/benchmark_tapecam/LENSLESS/4.png}\\
% 		\rule{0ex}{0.1in}%
% 	}
% 	\rule{0.2in}{0ex}}
&\includegraphics[width=\figsizegentrans\linewidth,valign=m]{figs/benchmark_tapecam/GROUND_TRUTH/5.png}
% \llap{\shortstack[l]{%
% 		\hspace{-1cm}\includegraphics[scale=.025]{figs/benchmark_tapecam/LENSLESS/5.png}\\
% 		\rule{0ex}{0.1in}%
% 	}
% 	\rule{0.2in}{0ex}}
\\[10pt]
\hline
\makecell{DigiCam\\-Single}
&\includegraphics[width=\figsizegentrans\linewidth,valign=m]{figs/benchmark_digicam_mirflickr/hf_diffusercam_mirflickr_Unet4M+U5+Unet4M_psfNN/4.png}
&\includegraphics[width=\figsizegentrans\linewidth,valign=m]{figs/benchmark_digicam_mirflickr/hf_diffusercam_mirflickr_Unet4M+U5+Unet4M_psfNN/5.png}
&\includegraphics[width=\figsizegentrans\linewidth,valign=m]{figs/benchmark_digicam_mirflickr/hf_tapecam_mirflickr_Unet4M+U5+Unet4M_psfNN/4.png}
&\includegraphics[width=\figsizegentrans\linewidth,valign=m]{figs/benchmark_digicam_mirflickr/hf_tapecam_mirflickr_Unet4M+U5+Unet4M_psfNN/5.png}
&\includegraphics[width=\figsizegentrans\linewidth,valign=m]{figs/benchmark_digicam_mirflickr/hf_digicam_mirflickr_single_25k_Unet4M+U5+Unet4M_wave_psfNN/4.png}
&\includegraphics[width=\figsizegentrans\linewidth,valign=m]{figs/benchmark_digicam_mirflickr/hf_digicam_mirflickr_single_25k_Unet4M+U5+Unet4M_wave_psfNN/5.png}
&\includegraphics[width=\figsizegentrans\linewidth,valign=m]{figs/benchmark_digicam_mirflickr/ADMM/100/4.png}
&\includegraphics[width=\figsizegentrans\linewidth,valign=m]{figs/benchmark_digicam_mirflickr/ADMM/100/5.png}

&\includegraphics[width=\figsizegentrans\linewidth,valign=m]{figs/benchmark_digicam_mirflickr/GROUND_TRUTH/4.png}
% \llap{\shortstack[l]{%
% 		\hspace{-1cm}\includegraphics[scale=.025]{figs/benchmark_digicam_mirflickr/LENSLESS/4.png}\\
% 		\rule{0ex}{0.1in}%
% 	}
% 	\rule{0.2in}{0ex}}
&\includegraphics[width=\figsizegentrans\linewidth,valign=m]{figs/benchmark_digicam_mirflickr/GROUND_TRUTH/5.png}
% \llap{\shortstack[l]{%
% 		\hspace{-1cm}\includegraphics[scale=.025]{figs/benchmark_digicam_mirflickr/LENSLESS/5.png}\\
% 		\rule{0ex}{0.1in}%
% 	}
% 	\rule{0.2in}{0ex}}
\\[10pt]
\hline
\hline
\makecell{DigiCam\\-Multi}
&\includegraphics[width=\figsizegentrans\linewidth,valign=m]{figs/benchmark_digicam_multimask/hf_diffusercam_mirflickr_Unet4M+U5+Unet4M_psfNN/4.png}
&\includegraphics[width=\figsizegentrans\linewidth,valign=m]{figs/benchmark_digicam_multimask/hf_diffusercam_mirflickr_Unet4M+U5+Unet4M_psfNN/5.png}
&\includegraphics[width=\figsizegentrans\linewidth,valign=m]{figs/benchmark_digicam_multimask/hf_tapecam_mirflickr_Unet4M+U5+Unet4M_psfNN/4.png}
&\includegraphics[width=\figsizegentrans\linewidth,valign=m]{figs/benchmark_digicam_multimask/hf_tapecam_mirflickr_Unet4M+U5+Unet4M_psfNN/5.png}
&\includegraphics[width=\figsizegentrans\linewidth,valign=m]{figs/benchmark_digicam_multimask/hf_digicam_mirflickr_single_25k_Unet4M+U5+Unet4M_wave_psfNN/4.png}
&\includegraphics[width=\figsizegentrans\linewidth,valign=m]{figs/benchmark_digicam_multimask/hf_digicam_mirflickr_single_25k_Unet4M+U5+Unet4M_wave_psfNN/5.png}
&\includegraphics[width=\figsizegentrans\linewidth,valign=m]{figs/benchmark_digicam_multimask/ADMM/100/4.png}
&\includegraphics[width=\figsizegentrans\linewidth,valign=m]{figs/benchmark_digicam_multimask/ADMM/100/5.png}

&\includegraphics[width=\figsizegentrans\linewidth,valign=m]{figs/benchmark_digicam_multimask/GROUND_TRUTH/4.png}
% \llap{\shortstack[l]{%
% 		\hspace{-1cm}\includegraphics[scale=.025]{figs/benchmark_digicam_multimask/LENSLESS/4.png}\\
% 		\rule{0ex}{0.1in}%
% 	}
% 	\rule{0.2in}{0ex}}
& \hspace{-0.5em}\includegraphics[width=\figsizegentrans\linewidth,valign=m]{figs/benchmark_digicam_multimask/GROUND_TRUTH/5.png}
\\
	\end{tabular}
	\caption{Example outputs of ($\textit{Pre}_{4}$\textit{+LeADMM5+}$\textit{Post}_{4}$) with PSF correction trained on the system/dataset indicated along the columns, and evaluated on the system/dataset indicated along the rows.}
\label{fig:exp2_visual_comparison_psfNN}
\end{figure*}
