\section{Introduction}
\label{sec:introduction}


\IEEEPARstart{L}{ensless} imaging has emerged as a promising alternative to traditional optical systems, circumventing the rigid requirements of lens-based designs.
By substituting a lens with a thin modulating mask, an imaging system can achieve compactness, lower cost, and enhanced visual privacy~\cite{boominathan2022recent}.
Conventional imaging relies on lenses to establish a direct one-to-one mapping between scene points and sensor pixels. 
In contrast, lensless imaging employs an optical element to create a one-to-many encoding by modulating the phase~\cite{Antipa:18,Monakhova:19,phlatcam,9239993,Lee:23} and/or amplitude~\cite{flatcam,wu2020single} of incident light.
With a sufficient understanding of these one-to-many mappings, \ie the point spread functions (PSFs), 
computational algorithms can be used to reconstruct viewable images from these multiplexed measurements.

Despite advancements that combine physical modeling with deep learning~\cite{Monakhova:19,9239993},
lensless imaging systems face challenges in robustness and generalizability. 
Robustness issues arise from approximations when modeling the imaging system, such as the linear shift-invariance (LSI) assumption, which can degrade reconstruction quality due to model mismatch~\cite{9546648}.
Additionally, learned reconstruction approaches are often trained under a specific signal-to-noise ratio (SNR), 
resulting in performance degradation to SNR changes at inference~\cite{Rego2021,Perron2023}.
With regards to generalizability, few studies have evaluated the transferability of learned reconstructions to different masks or PSFs from those used during training. 
While slight manufacturing variations have been explored~\cite{Lee:23},
generalizability to significant PSF changes remains underexplored. 
Rego \etal~\cite{Rego2021} train models on measurements from multiple PSFs but only evaluate on simulations/measurements with the same PSFs seen at training,
leaving the generalizability to unseen PSFs unclear.
As current methods rely on supervised training with paired lensless-lensed datasets for a given PSF,
the scalability of high-quality lensless imaging is limited.
% limiting the scalability of high-quality lensless imaging.
Robustness to different settings and generalizability to PSF changes would make lensless imaging system much more practical, \ie cutting down weeks of measurement/training time and enabling improved reconstruction when data collection is difficult or impossible, \eg \textit{in-vivo} or due to privacy constraints.

This work addresses these gaps by advancing the robustness and generalizability of lensless imaging recovery. Our contributions include:
\begin{itemize}
    \item \textit{Versatile Modular Reconstruction}: We propose and apply a modular reconstruction framework, as shown in \cref{fig:pipeline} to multiple imaging systems and previously-proposed camera inversion approaches. The framework extends our previous work that introduced a pre-processor~\cite{Perron2023}.
\item \textit{Robustness Analysis and Experiments:} We motivate the pre-processor and our modular framework by showing how camera inversion methods amplify input noise and introduce error terms due to inevitable model mismatch in lensless imaging. With our modular approach, we experimentally show improved robustness to varying input SNR and model mismatch.
    \item \textit{Benchmarking and Improving Generalizability}: We conduct the first benchmark across multiple mask patterns and types, assessing how well reconstruction approaches trained on one system generalize to others. With our modular reconstruction, we explore techniques to improve
    generalization to unseen PSFs.
    \item \textit{Hardware Prototype}: We introduce \textit{DigiCam}, a programmable-mask system that is $30\times$ cheaper than existing alternatives, and enables convenient evaluation across multiple masks/PSFs.
    % ~100 for our imaging system 3K (SLM) + 300 (sensor) for others
\end{itemize}
For reproducibility and to encourage further research, we open-source:
\begin{itemize}
    \item \textit{Datasets}: Four public datasets, including the first multi-mask dataset with 100 unique masks and 250 measurements per mask~\cite{tapecam,digicam_celeba,digicam_single,digicam_multi}.
    \item \textit{Code}: Reconstruction and training implementations, including that of baseline algorithms.
    \item \textit{Tooling}: Scripts for dataset collection using the Raspberry Pi HQ sensor~\cite{rpi_hq} and tools for uploading datasets to Hugging Face.
\end{itemize}
All resources are integrated into a documented toolkit for lensless imaging hardware and software~\cite{Bezzam2023}.\footnote{\href{https://lensless.readthedocs.io}{lensless.readthedocs.io}}

\begin{figure}[t!]
    \centering
\includegraphics[width=\linewidth]{figs/fig1_imaging_pipeline.png}
\caption{Modular lensless imaging pipeline. Pre- and post-processors and PSF correction are optional.}
  \label{fig:pipeline}
\end{figure}
