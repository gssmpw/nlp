\section{Related Work}

\noindent In this section, we give an overview of lensless cameras, image recovery techniques, and previous work that addresses robustness and generalizability in lensless imaging.

\subsection{Lensless Cameras}

\noindent The earliest cameras, such as the \textit{camera obscura} and the pinhole camera, were inherently lensless, though they required long exposure times due to their limited light throughput. 
The introduction of lenses with larger apertures resolved this limitation, by allowing shorter exposures while producing sharp, in-focus images.
Mask-based lensless imaging found its first notable applications beyond the visible spectrum, namely in astronomy, where X-rays and gamma rays cannot be easily focused with conventional lenses or mirrors. Instead, increasing the number of apertures enabled better signal collection and imaging capabilities~\cite{dicke1968scatter,caroli1987coded}.
The commoditization of digital sensors paved the way for lensless imaging in the visible spectrum.
Camera miniaturization and advancements in compressive sensing enabled the shift of image formation from traditional optics to digital post-processing. 
Ultra-compact lensless imaging systems can be fabricated to sub-mm thickness using scalable lithography techniques~\cite{Lee:23,flatcam}, 
while the multiplexing property of lensless cameras allows higher-dimensional quantities to be recovered from 2D measurements: refocusable/3D imaging~\cite{Antipa:18,sweepcam2020,zheng2021programmable3dcam}, hyperspectral~\cite{Monakhova:20}, and videos~\cite{antipa2019video}.
The compact design can also enable \textit{in-vivo} imaging of hard-to-reach areas in biological systems, as demonstrated in calcium imaging of live mouse cortices~\cite{adams2022vivo}.

Lensless cameras replace traditional lenses with masks that modulate the phase~\cite{Antipa:18,Monakhova:19,phlatcam,9239993,Lee:23} and/or amplitude~\cite{flatcam,wu2020single} of incident light.
% This mask can be static or programmable.
Off-the-shelf materials such as diffusers~\cite{Antipa:18} or even double-sided tape~\cite{Bezzam2023,diffusercam_tut} can be used as a static mask, or it can be fabricated with photolithography for a desired structure/PSF~\cite{phlatcam,Lee:23,flatcam,wu2020single}.
For reconfigurable systems, spatial light modulators (SLMs)~\cite{sweepcam2020,zheng2021programmable3dcam,10.1117/1.OE.54.2.023102} or liquid crystal displays (LCDs)~\cite{4472247,huang2013,zomet2006}  can be used as a programmable mask.
If design constraints permit, phase masks are preferred for superior light efficiency and concentration, as this leads to higher-quality reconstructions~\cite{boominathan2022recent}.


\subsection{Lensless Image Recovery}

\noindent Lensless image recovery is inherently an ill-posed inverse problem due to the multiplexing nature of such cameras.
To solve this, an optimization framework is typically employed, consisting of: (1) a data fidelity term that ensures consistency with the measurements through a forward model, and (2) regularization term(s) that incorporate prior knowledge about the desired image.
In certain cases, such as with $\ell_2$ regularization~\cite{flatcam} or Wiener filtering~\cite{Li:23}, 
the problem can be solved in closed-form, offering computational efficiency. 
More expressive priors, like non-negativity constraints or total variation (TV) minimization~\cite{Antipa:18,phlatcam} require iterative solvers, such as the fast iterative shrinkage-thresholding algorithm (FISTA)~\cite{beck2009fast} or the alternating direction method of multipliers (ADMM)~\cite{ADMM}.
While such solvers are slower due to multiple iterations needed for convergence,
they generally perform much better than closed-form approaches.

Incorporating deep learning can accelerate image formation time and enhance performance.
Unrolling iterative solvers is a notable approach that combines the strengths of deep learning with traditional optimization methods and physical modeling,
as a fixed number of iterations of an iterative solver are represented as layers of a neural network. 
Each layer is parameterized with its own learnable hyperparameters, such as step sizes, and these are optimized end-to-end using backpropagation~\cite{lista}.
Unrolled algorithms can significantly reduce convergence time by learning optimal hyperparameters for fewer iterations.
In lensless imaging, Monakhova \etal~\cite{Monakhova:19} demonstrated that only five iterations of unrolled ADMM with learned hyperparameters achieved similar performance to 100 iterations with manually-selected fixed parameters.
Furthermore, they incorporated a learned denoiser, a U-Net architecture with approximately 10M parameters~\cite{unet}, at the output to further improve reconstruction quality.
Combining deep learning with physical priors produces state-of-the-art results with fewer hallucinations and improved interpretability~\cite{9239993,Perron2023}.
Unlike purely data-driven approaches, these hybrid methods leverage both the underlying physics of the imaging system and the representational power of neural networks, achieving accurate reconstructions with less data.

\subsection{Robust Lensless Imaging}

\noindent Lensless imaging recovery is a challenging ill-posed inverse problem, as the highly-multiplexed nature makes it sensitive to model mismatch in the forward modeling within the data fidelity term.
A common assumption is linear shift invariance (LSI), which approximates off-axis PSFs as lateral shifts of the on-axis PSF.
This simplifies calibration and reduces computational complexity when computing the forward model.
However, this approximation introduces errors, particularly when iterative solvers like ADMM are used, as these errors accumulate over multiple iterations~\cite{9546648}.

To address model mismatch, Zeng \etal~\cite{9546648} proposed a neural network-based compensation branch that uses intermediate outputs from unrolled ADMM iterations to reduce the error resulting from model mismatch.
Other works attempt to reduce the model mismatch itself, \eg by fine-tuning the on-axis PSF~\cite{9239993,Kingshott:22} or applying transformations to it~\cite{Li:23}.
However, these methods still operate within the constraints of the LSI assumption.
While LSI can be valid for certain systems (\eg for DiffuserCam where off-axis and on-axis PSFs have at least \SI{75}{\percent} similarity within a \SI{37.5}{\degree} field of view~\cite{Antipa:18}),
some level of model mismatch is inevitable.
More advanced models, such as spatially-varying forward models~\cite{Yanny:22,cai2024phocolens}, aim to relax the LSI assumption.
However, these approaches can still suffer from inaccuracies if the locally shift-invariant regions are not well-parameterized.

Incorporating deep learning into reconstruction introduces additional challenges, as performance can degrade when test data deviates from the training distribution~\cite{9782500}.
In lensless imaging, there are several factors that could change between training and inference:
\eg scene content, positioning, lighting, SNR, and the imaging system's mask/PSF.
Existing methods demonstrate robustness to scene variations~\cite{Monakhova:19,9239993,Lee:23},
while our previous work~\cite{Perron2023} showed improved robustness to SNR variations by incorporating a pre-processor.

\subsection{Generalizable Lensless Imaging}

\noindent While existing methods demonstrate robustness to scene variations,
few address generalization to changes in the mask/PSF of the imaging system.
Lee \etal~\cite{Lee:23} evaluated robustness to minor manufacturing variations in masks,
but these are very minimal changes to the PSF.
Rego \etal~\cite{Rego2021} formulated lensless imaging as a blind deconvolution problem, such that the PSF is not needed during inference, but all possible PSFs (and measurements or simulations with them) are seen during training.
Collecting extensive datasets for each PSF is impractical, given the already time-consuming nature of acquiring data for a single PSF.
Untrained networks~\cite{Monakhova:21} eliminate the need for labeled datasets but require impractically long reconstruction times (\eg, several hours).
A lack of generalizability studies is largely due to the dearth of publicly-available lensless datasets: DiffuserCam (25K examples)~\cite{Monakhova:19}, FlatCam (10K examples)~\cite{9239993}, PhlatCam (10K examples)~\cite{9239993}, and SweepCam (380 examples)~\cite{zheng2021programmable3dcam}.

Adapting pre-trained models offers another avenue for generalization. 
Gilbert \etal~\cite{9477112} proposed methods to adapt a network trained on one forward model to a new one, but their results are limited to simple blur kernels ($7\times7$ pixels), which are far smaller and less complex than the PSFs encountered in lensless imaging.

Reconstruction methods that are robust (to model mismatch and noise) and that generalize to unseen PSFs are crucial for advancing lensless imaging. 
Such methods would reduce the need for exhaustive dataset collection, 
making lensless imaging more practical, 
particularly in scenarios where data acquisition is infeasible due to privacy concerns or inaccessibility. By open-sourcing four large datasets and leveraging a modular reconstruction pipeline, 
we aim to improve the generalizability and usability of lensless imaging systems.
