\begin{table*}[t!]
\renewcommand{\arraystretch}{1.3}
\caption{Summary of datasets.}
\label{tab:datasets}
\centering
\begin{tabular}{c||c|c|c|c|c|c}
\hline
\textit{Dataset} & Source data & Mask & Sensor & PSF(s) & $\#$ train & $\#$ test\\
\hline\hline
DiffuserCam~\cite{Monakhova:19} & MirFlickr~\cite{huiskes2008mir} & Random diffuser~\cite{luminit} & Basler daA1920-30uc~\cite{basler} & \cref{fig:diffusercam} &24K & 1K \\
\hline
TapeCam  & MirFlickr~\cite{huiskes2008mir} & Double-sided tape as in~\cite{diffusercam_tut} & Raspberry Pi HQ~\cite{rpi_hq} & \cref{fig:tapecam} & 21.25K & 3.75K \\
\hline
DigiCam-Single & MirFlickr~\cite{huiskes2008mir} & Random LCD pattern~\cite{adafruitlcd} & Raspberry Pi HQ~\cite{rpi_hq} & \cref{fig:digicam_mirflickr} & 21.25K & 3.75K \\
\hline
DigiCam-Multi  & MirFlickr~\cite{huiskes2008mir} & 
% \makecell{100 random patterns of\\uniform distribution on LCD~\cite{adafruitlcd}} 
100 random LCD patterns~\cite{adafruitlcd} & Raspberry Pi HQ~\cite{rpi_hq}
& \eg \cref{fig:digicam_mirflickr,fig:multi1,fig:multi2,fig:multi3,fig:multi4} &
\makecell{21.25K\\(85 masks)}
% \makecell{21.25K\\85 masks} 
& 
\makecell{3.75K\\(15 masks)}
% \makecell{3.75K \\15 masks}
\\
\hline
DigiCam-CelebA  & CelebA~\cite{liu2015faceattributes} & Random LCD pattern~\cite{adafruitlcd} & Raspberry Pi HQ~\cite{rpi_hq} & \cref{fig:digicam_celeba}  &22.1K & 3.9K \\
\hline
\end{tabular}
\end{table*}

\section{Experiments and Results}
\label{sec:experiments}

\noindent We perform the following experiments:
\begin{enumerate}
    \item Show the strength of our modular approach and the benefit of using a pre-processor across different imaging systems and reconstruction approaches (\cref{sec:exp_preproc}).
    \item Demonstrate the robustness of our modular approach by digitally adding noise and model mismatch (\cref{sec:robustness_exp}).
    \item Evaluate the performance of a learned reconstruction on a system \textit{different} than the one it was trained for (\cref{sec:exp_eval_gen}).
    % \ie to show the lack of generalizability of learned approaches (\cref{sec:exp_eval_gen}).
    \item Utilize our modular reconstruction for improving the generalizability to measurements of PSFs not seen during training (\cref{sec:exp_improve_gen}).
\end{enumerate}



\subsection{Experimental Setup}

\subsubsection{Datasets}

\noindent Our experiments make use of five datasets to evaluate performance and generalizability.
The datasets are summarized in \cref{tab:datasets}. 
Apart from \textit{DiffuserCam}~\cite{Monakhova:19}, all datasets have been collected as part of this work and have a resolution of $(380\times507)$.
They are available on Hugging Face~\cite{tapecam,digicam_celeba,digicam_single,digicam_multi}, which provides a visualization of the measurements and a Python interface for downloading each dataset.
With our datasets, the goal is to use low-cost and accessible materials to demonstrate the potential for scalable, cost-effective lensless imaging.
For this reason, we use the RPi HQ sensor~\cite{rpi_hq}, double-sided tape as a phase mask (\textit{TapeCam)}, and an LCD as a reconfigurable amplitude mask (\textit{DigiCam}).
For the \textit{DigiCam} datasets, a random pattern of size $(3\times18\times26) = 1404$ pixels is generated using a uniform distribution, with 100 randomly generated patterns used for the multimask dataset (\textit{DigiCam-Multi}).
The training set measurements of \textit{DigiCam-Multi} use 85 different random mask patterns, while the test set uses another 15 random mask patterns, 
and there are 250 measurements per mask.
All other datasets use the same mask for the training and test set measurements.
The scene of interest, \ie an image displayed at a pre-defined resolution on a computer monitor as shown in \cref{fig:prototype_labeled}, is \SI{30}{\centi\meter} from the camera, while the mask is roughly \SI{2}{\milli\meter} from the sensor.
For our datasets, the ground-truth image, which is needed to compute the loss in \cref{eq:loss_mse_lpips}, is obtained by reshaping the image to the same resolution when displayed on the screen, and again reshaping to the corresponding region-of-interest (ROI) in the reconstruction.
The ROI is the region of the lensless reconstruction that corresponds to the object of interest, such that we remove black regions before computing the loss/metrics.
The loss is then computed between the reshaped ground-truth image and the extracted ROI from the reconstruction.

For \textit{DiffuserCam}~\cite{Monakhova:19}, lensed images are simultaneously captured with a beamsplitter,
and we downsample both lensless and lensed by $2\times$ to a resolution of $(135\times240)$.
Both lensed and lensless images are captured with Basler Dart (daA1920-30uc) sensors, which is more than $3\times$ the cost of the RPi HQ sensor used to collect our datasets~\cite{basler}.



\subsubsection{Models}


% In our work,
\noindent Equating the number of model parameters between reconstruction approaches has not been done in previous works, and is needed to fairly compare reconstruction approaches.
To this end,
we parameterize the number of feature representation channels between the four downsampling/upsampling scales in the DRUNet architecture,
such that an approximately equal number of model parameters (around 8.2M) are distributed between the pre-processor, camera inversion, and post-processor.
% the original work uses a depth of $4$ and (64, 128, 256, 512) channels from the first to the fourth scale respectively.
Unless noted otherwise, we consider three different sizes for the processors:
(1) around 8.2M parameters that increases the number of feature representation channels when downscaling from 32 to 256 according to (32, 64, 128, 256),
(2) around 4.1M parameters with (32, 64, 116, 128) feature representation channels, 
and (3) around 2M parameters with (16, 32, 64, 128) feature representation channels.
When upscaling back to the image shape, the number of feature representation channels decreases symmetrically.
Pre- and post-processor are denoted as $\textit{Pre}_{X}$ and $\textit{Post}_{X}$ respectively,
where $X$ refers to the number of parameters in millions.
For example, $\textit{Pre}_{4}$ refers to a pre-processor with around 4.1M parameters.
We use \textit{ADMMX} to refer to conventional ADMM with fixed hyperparameters and \textit{X} iterations,
and  \textit{LeADMMX} to denote unrolled ADMM with \textit{X} unrolled layers.
For each unrolled layer there are four hyperparameters.
Trainable inversion is denoted as \textit{TrainInv}.
As MMCN and MWDN use neural network components, the number of feature representation channels between the downsampling/upsampling scales are parameterized to maintain a similar number of model parameters as the other reconstruction approaches.
To this end, $\textit{MMCN}_{4}$ uses (24, 64, 128, 256, 400) feature representation channels 
% for the \textit{DoubleConv} layers 
for around 4.1M total parameters (original network~\cite{9546648} used (24, 64, 128, 256, 512) channels), 
and $\textit{MWDN}_{8}$ uses (32, 64, 128, 256, 436) feature representation channels 
% for the  \textit{DoubleConv} layers 
for around 8.2M total parameters (original network~\cite{Li:23} used (64, 128, 256, 512, 1024) channels).

\subsubsection{Training and Evaluation Details}

PyTorch~\cite{Paszke2017} is used for training and evaluation. 
Unless noted otherwise, all learned methods are trained with the Adam optimizer with a learning rate of $10^{-4}$, $\beta_1=0.9$, $\beta_2=0.999$ for $25$ epochs and a batch size of $4$.
Training is done on an Intel Xeon E5-2680 v3 \SI{2.5}{\giga\hertz} CPU
and 4$\times$ Nvidia Titan X Pascal GPUs.
Three metrics are used: (1) peak signal-to-noise ratio (PSNR) which operates pixel-wise and higher is better, 
(2) structural similarity index measure (SSIM) which analyzes local regions and higher is better within $[-1,1]$, 
and (3) LPIPS which uses pre-trained VGG neural networks as feature extractors to compute similarity and lower is better within $[0,1]$.
Measurement and training scripts are made available in \textit{LenslessPiCam}~\cite{Bezzam2023}.

\subsection{Benefit of Pre-Processor}
\label{sec:exp_preproc}


\begin{table*}[!t]
	\renewcommand{\arraystretch}{1.3}
	\caption{Average image quality metrics (PSNR $\uparrow$ / SSIM $\uparrow$ / LPIPS $\downarrow$) for reconstructions on the test set of various measured datasets. Bold is used to denote the best performance across reconstruction methods (along columns). For the \textit{DiffuserCam} dataset, the number of parameters for \textit{TrainInv} differs as the PSF (which itself is a parameter) has a different resolution as another sensor is used, \ie 8.3M parameters for (\textit{TrainInv+}$\textit{Post}_{8}$) and 8.2M parameters for ($\textit{Pre}_{4}$\textit{+TrainInv+}$\textit{Post}_{4}$).}
	\label{tab:exp1_benchmark}
	\centering
\begin{tabular}{c|c|c||c|c|c|c}
		\hline
		Method & \makecell{\# learnable \\parameters} & \makecell{Inference\\time [ms]} & DiffuserCam & TapeCam & DigiCam-Single  & DigiCam-CelebA \\
		\hline\hline
		ADMM100~\cite{Antipa:18} & - & 771 & 15.0 / 0.457 / 0.511 & 10.2 / 0.234 / 0.720 &  10.6 / 0.291 / 0.751  & 10.1 / 0.352 / 0.737 \\
		\hline
        \hline
		TrainInv+$\text{Post}_{8}$~\cite{9239993} & 8.7M & 29.6 & 21.5 / 0.748 / 0.252 & 16.2 / 0.411 / 0.565 & 17.7 / 0.470 / 0.517 & 20.1 / 0.643 / 0.321 \\
		\hline
		$\text{MMCN}_{4}$+$\text{Post}_{4}$~\cite{9546648}  & 8.2M & 73.9 & 
  22.9 / 0.786 / 0.210
 & 16.7 / 0.483 / 0.505
  & 
  16.9 / 0.477 / 0.538
  & 
  18.0 / 0.614 / 0.363
  \\
  \hline
  $\text{Pre}_{8}$+LeADMM5 & 8.2M & 67.7 & 18.9 / 0.662 / 0.284 & 16.2 / 0.352 / 0.576 & 15.8 / 0.297 / 0.578 & 16.9 / 0.525 / 0.407 \\
		\hline
  LeADMM5+$\text{Post}_{8}$~\cite{Monakhova:19} & 8.2M & 67.6 & 23.8 / 0.806 / 0.202 & 18.6 / 0.505 / 0.478 & 19.1 / 0.515 / 0.469 & 20.9 / 0.667 / 0.296 \\
  		\hline
		$\text{MWDN}_{8}$~\cite{Li:23} & 8.1M & 20.2 & 24.2 / 0.797 / 0.206 & 16.5 / 0.480 / 0.541
  & 18.1 / 0.501 / 0.531 & 16.3 / 0.549 / 0.449 \\
		\hline
  \hline
		$\text{Pre}_{4}$+TrainInv+$\text{Post}_{4}$ & 8.7M & 49.2 & 23.5 / 0.794 / 0.214 & 19.3 / 0.555 / 0.461 & 19.9 / 0.525 / 0.454 & 22.1 / 0.696 / 0.265 \\
		\hline
		$\text{Pre}_{2}$+$\text{MMCN}_{4}$+$\text{Post}_{2}$  & 8.2M & 72.9 &  
 22.4 / 0.801 / 0.199
  & 
  18.0 / 0.518 / 0.484
  & 
  17.3 / 0.509 / 0.521
  & 
  19.2 / 0.631 / 0.346
  \\
		\hline
  $\text{Pre}_{4}$+LeADMM5+$\text{Post}_{4}$ & 8.1M & 88.1 & 25.3 / 0.838 / 0.171 & 19.7 / 0.564 / 0.441 & 19.6 / 0.531 / 0.449 & 22.5 / 0.703 / 0.263 \\
		\hline
        \hline
        $\text{Pre}_{4}$+LeADMM10+$\text{Post}_{4}$ & 8.1M & 129 & 26.1 / 0.851 / 0.160 & 19.8 / 0.560 / 0.441 & \textbf{20.1} / 0.551 / 0.440 & \textbf{23.0} / \textbf{0.709} / \textbf{0.262} \\
		\hline
        \makecell{$\text{Pre}_{4}$+LeADMM5+$\text{Post}_{4}$\\with PSF correction} & 8.1M & 93.9 & \textbf{26.4} / \textbf{0.857} / \textbf{0.154}  & \textbf{20.2} / \textbf{0.575} / \textbf{0.426}  & \textbf{20.1} / \textbf{0.552} / \textbf{0.439}  & 22.3 / 0.704 / 0.263 \\
		\hline
	\end{tabular}
\end{table*}

\begin{figure*}[t!]
    \centering
    \begin{subfigure}{0.32\linewidth}
		\centering
		\includegraphics[width=0.99\linewidth]{figs/fig4_psnr_v5.png} 
		\caption{PSNR improvement (dB).}
		\label{fig:exp1_psnr}
	\end{subfigure}
    \begin{subfigure}{0.32\linewidth}
		\centering
		\includegraphics[width=0.99\linewidth]{figs/fig4_ssim_v5.png} 
		\caption{SSIM relative improvement.}
		\label{fig:exp1_ssim}
	\end{subfigure}
 \begin{subfigure}{0.32\linewidth}
		\centering
		\includegraphics[width=0.99\linewidth]{figs/fig4_lpips_v5.png}
		\caption{LPIPS relative improvement.}
		\label{fig:exp1_lpips}
	\end{subfigure}
 	\caption{Visualization of improvement in image quality metrics when splitting the number of model parameters between pre- and post-processors, rather than only using a post-processor.}
	\label{fig:exp1_improvement_viz}
\end{figure*}

\newcommand{\figsizegen}{0.10}
\newcommand{\figsizegendiffusercam}{0.13}
\newcommand{\figsizegenceleba}{0.068}
\newcommand{\newlinegen}{15pt}
\begin{figure*}[t!]
\centering
	\renewcommand{\arraystretch}{1} % Default value: 1
	\setlength{\tabcolsep}{0.06em} % for the horizontal padding
	%\begin{table}[t!]
	\begin{tabular}{ccccccccc}
    &   
    \multicolumn{2}{c}{DiffuserCam~\cite{Monakhova:19}}
    & \multicolumn{2}{c}{TapeCam}
    & \multicolumn{2}{c}{DigiCam-Single}
    & \multicolumn{2}{c}{DigiCam-CelebA}
    \\ 
    \cmidrule(r){2-3} \cmidrule(r){4-5} \cmidrule(r){6-7} \cmidrule(r){8-9}
    \makecell{Raw data +\\Ground-truth}
&
\includegraphics[width=\figsizegendiffusercam\linewidth,valign=m]{figs/benchmark_diffusercam/GROUND_TRUTH/0.png}
\llap{\shortstack[l]{%
		\hspace{-1.9cm}\includegraphics[scale=.09]{figs/benchmark_diffusercam/LENSLESS/0.png}\\
		\rule{0ex}{0.13in}%
	}
	\rule{0.2in}{0ex}}
&
\includegraphics[width=\figsizegendiffusercam\linewidth,valign=m]{figs/benchmark_diffusercam/GROUND_TRUTH/1.png}
\llap{\shortstack[l]{%
		\hspace{-1.9cm}\includegraphics[scale=.09]{figs/benchmark_diffusercam/LENSLESS/1.png}\\
		\rule{0ex}{0.13in}%
	}
	\rule{0.2in}{0ex}}
&
\includegraphics[width=\figsizegen\linewidth,valign=m]{figs/benchmark_tapecam/GROUND_TRUTH/1.png}
\llap{\shortstack[l]{%
		\hspace{-1.35cm}\includegraphics[scale=.035]{figs/benchmark_tapecam/LENSLESS/1.png}\\
		\rule{0ex}{0.13in}%
	}
	\rule{0.2in}{0ex}}
&
\includegraphics[width=\figsizegen\linewidth,valign=m]{figs/benchmark_tapecam/GROUND_TRUTH/2.png}
\llap{\shortstack[l]{%
		\hspace{-1.35cm}\includegraphics[scale=.035]{figs/benchmark_tapecam/LENSLESS/2.png}\\
		\rule{0ex}{0.13in}%
	}
	\rule{0.2in}{0ex}}
&
\includegraphics[width=\figsizegen\linewidth,valign=m]{figs/benchmark_digicam_mirflickr/GROUND_TRUTH/1.png}
\llap{\shortstack[l]{%
		\hspace{-1.35cm}\includegraphics[scale=.035]{figs/benchmark_digicam_mirflickr/LENSLESS/1.png}\\
		\rule{0ex}{0.13in}%
	}
	\rule{0.2in}{0ex}}
&
\includegraphics[width=\figsizegen\linewidth,valign=m]{figs/benchmark_digicam_mirflickr/GROUND_TRUTH/2.png}
\llap{\shortstack[l]{%
		\hspace{-1.35cm}\includegraphics[scale=.035]{figs/benchmark_digicam_mirflickr/LENSLESS/2.png}\\
		\rule{0ex}{0.13in}%
	}
	\rule{0.2in}{0ex}}
&
\includegraphics[width=\figsizegenceleba\linewidth,valign=m]{figs/celeba_26k/original/4.png}
\llap{\shortstack[l]{%
		\hspace{-0.8cm}\includegraphics[scale=.035]{figs/benchmark_digicam_celeba/LENSLESS/4.png}\\
		\rule{0ex}{0.15in}%
	}
	\rule{0.2in}{0ex}}
&
\includegraphics[width=\figsizegenceleba\linewidth,valign=m]{figs/celeba_26k/original/9.png}
\llap{\shortstack[l]{%
		\hspace{-0.8cm}\includegraphics[scale=.035]{figs/benchmark_digicam_celeba/LENSLESS/9.png}\\
		\rule{0ex}{0.15in}%
	}
	\rule{0.2in}{0ex}}
    \\[\newlinegen]
    \hline
    ADMM100
&\hspace{-0.35em}\includegraphics[width=\figsizegendiffusercam\linewidth,valign=m]{figs/benchmark_diffusercam/ADMM/100/0.png}
&\hspace{-0.35em}\includegraphics[width=\figsizegendiffusercam\linewidth,valign=m]{figs/benchmark_diffusercam/ADMM/100/1.png}
&\hspace{-0.35em}\includegraphics[width=\figsizegen\linewidth,valign=m]{figs/benchmark_tapecam/ADMM/100/1.png}
&\hspace{-0.35em}\includegraphics[width=\figsizegen\linewidth,valign=m]{figs/benchmark_tapecam/ADMM/100/2.png}
&\hspace{-0.35em}\includegraphics[width=\figsizegen\linewidth,valign=m]{figs/benchmark_digicam_mirflickr/ADMM/100/1.png}
&\hspace{-0.35em}\includegraphics[width=\figsizegen\linewidth,valign=m]{figs/benchmark_digicam_mirflickr/ADMM/100/2.png}
&\hspace{-0.35em}\includegraphics[width=\figsizegenceleba\linewidth,valign=m]{figs/benchmark_digicam_celeba/ADMM/100/4.png}
&\hspace{-0.35em}\includegraphics[width=\figsizegenceleba\linewidth,valign=m]{figs/benchmark_digicam_celeba/ADMM/100/9.png}
    \\[\newlinegen]
\makecell{TrainInv\\+$\text{Post}_{8}$~\cite{9239993}}
&\hspace{-0.35em}\includegraphics[width=\figsizegendiffusercam\linewidth,valign=m]{figs/benchmark_diffusercam/hf_diffusercam_mirflickr_TrainInv+Unet8M/0.png}
&\hspace{-0.35em}\includegraphics[width=\figsizegendiffusercam\linewidth,valign=m]{figs/benchmark_diffusercam/hf_diffusercam_mirflickr_TrainInv+Unet8M/1.png}
&\hspace{-0.35em}\includegraphics[width=\figsizegen\linewidth,valign=m]{figs/benchmark_tapecam/hf_tapecam_mirflickr_TrainInv+Unet8M/1.png}
&\hspace{-0.35em}\includegraphics[width=\figsizegen\linewidth,valign=m]{figs/benchmark_tapecam/hf_tapecam_mirflickr_TrainInv+Unet8M/2.png}
&\hspace{-0.35em}\includegraphics[width=\figsizegen\linewidth,valign=m]{figs/benchmark_digicam_mirflickr/hf_digicam_mirflickr_single_25k_TrainInv+Unet8M_wave/1.png}
&\hspace{-0.35em}\includegraphics[width=\figsizegen\linewidth,valign=m]{figs/benchmark_digicam_mirflickr/hf_digicam_mirflickr_single_25k_TrainInv+Unet8M_wave/2.png}
&\hspace{-0.35em}\includegraphics[width=\figsizegenceleba\linewidth,valign=m]{figs/benchmark_digicam_celeba/hf_digicam_celeba_26k_TrainInv+Unet8M_wave/4.png}
&\hspace{-0.35em}\includegraphics[width=\figsizegenceleba\linewidth,valign=m]{figs/benchmark_digicam_celeba/hf_digicam_celeba_26k_TrainInv+Unet8M_wave/9.png}
    \\[\newlinegen]
\makecell{$\text{MMCN}_{4}$\\+$\text{Post}_{4}$~\cite{9546648}}
&\hspace{-0.35em}\includegraphics[width=\figsizegendiffusercam\linewidth,valign=m]{figs/benchmark_diffusercam/hf_diffusercam_mirflickr_MMCN4M+Unet4M/0.png}
&\hspace{-0.35em}\includegraphics[width=\figsizegendiffusercam\linewidth,valign=m]{figs/benchmark_diffusercam/hf_diffusercam_mirflickr_MMCN4M+Unet4M/1.png}
&\hspace{-0.35em}\includegraphics[width=\figsizegen\linewidth,valign=m]{figs/benchmark_tapecam/hf_tapecam_mirflickr_MMCN4M+Unet4M/1.png}
&\hspace{-0.35em}\includegraphics[width=\figsizegen\linewidth,valign=m]{figs/benchmark_tapecam/hf_tapecam_mirflickr_MMCN4M+Unet4M/2.png}
&\hspace{-0.35em}\includegraphics[width=\figsizegen\linewidth,valign=m]{figs/benchmark_digicam_mirflickr/hf_digicam_mirflickr_single_25k_MMCN4M+Unet4M_wave/1.png}
&\hspace{-0.35em}\includegraphics[width=\figsizegen\linewidth,valign=m]{figs/benchmark_digicam_mirflickr/hf_digicam_mirflickr_single_25k_MMCN4M+Unet4M_wave/2.png}
&\hspace{-0.35em}\includegraphics[width=\figsizegenceleba\linewidth,valign=m]{figs/benchmark_digicam_celeba/hf_digicam_celeba_26k_MMCN4M+Unet4M_wave/4.png}
&\hspace{-0.35em}\includegraphics[width=\figsizegenceleba\linewidth,valign=m]{figs/benchmark_digicam_celeba/hf_digicam_celeba_26k_MMCN4M+Unet4M_wave/9.png}
    \\[\newlinegen]

\makecell{$\text{Pre}_{8}$+\\LeADMM5}
&\hspace{-0.35em}\includegraphics[width=\figsizegendiffusercam\linewidth,valign=m]{figs/benchmark_diffusercam/hf_diffusercam_mirflickr_Unet8M+U5/0.png}
&\hspace{-0.35em}\includegraphics[width=\figsizegendiffusercam\linewidth,valign=m]{figs/benchmark_diffusercam/hf_diffusercam_mirflickr_Unet8M+U5/1.png}
&\hspace{-0.35em}\includegraphics[width=\figsizegen\linewidth,valign=m]{figs/benchmark_tapecam/hf_tapecam_mirflickr_Unet8M+U5/1.png}
&\hspace{-0.35em}\includegraphics[width=\figsizegen\linewidth,valign=m]{figs/benchmark_tapecam/hf_tapecam_mirflickr_Unet8M+U5/2.png}
&\hspace{-0.35em}\includegraphics[width=\figsizegen\linewidth,valign=m]{figs/benchmark_digicam_mirflickr/hf_digicam_mirflickr_single_25k_Unet8M+U5_wave/1.png}
&\hspace{-0.35em}\includegraphics[width=\figsizegen\linewidth,valign=m]{figs/benchmark_digicam_mirflickr/hf_digicam_mirflickr_single_25k_Unet8M+U5_wave/2.png}
&\hspace{-0.35em}\includegraphics[width=\figsizegenceleba\linewidth,valign=m]{figs/benchmark_digicam_celeba/hf_digicam_celeba_26k_Unet8M+U5_wave/4.png}
&\hspace{-0.35em}\includegraphics[width=\figsizegenceleba\linewidth,valign=m]{figs/benchmark_digicam_celeba/hf_digicam_celeba_26k_Unet8M+U5_wave/9.png}
    \\[\newlinegen]
    
\makecell{LeADMM5\\+$\text{Post}_{8}$~\cite{Monakhova:19}}
&\hspace{-0.35em}\includegraphics[width=\figsizegendiffusercam\linewidth,valign=m]{figs/benchmark_diffusercam/hf_diffusercam_mirflickr_U5+Unet8M/0.png}
&\hspace{-0.35em}\includegraphics[width=\figsizegendiffusercam\linewidth,valign=m]{figs/benchmark_diffusercam/hf_diffusercam_mirflickr_U5+Unet8M/1.png}
&\hspace{-0.35em}\includegraphics[width=\figsizegen\linewidth,valign=m]{figs/benchmark_tapecam/hf_tapecam_mirflickr_U5+Unet8M/1.png}
&\hspace{-0.35em}\includegraphics[width=\figsizegen\linewidth,valign=m]{figs/benchmark_tapecam/hf_tapecam_mirflickr_U5+Unet8M/2.png}
&\hspace{-0.35em}\includegraphics[width=\figsizegen\linewidth,valign=m]{figs/benchmark_digicam_mirflickr/hf_digicam_mirflickr_single_25k_U5+Unet8M_wave/1.png}
&\hspace{-0.35em}\includegraphics[width=\figsizegen\linewidth,valign=m]{figs/benchmark_digicam_mirflickr/hf_digicam_mirflickr_single_25k_U5+Unet8M_wave/2.png}
&\hspace{-0.35em}\includegraphics[width=\figsizegenceleba\linewidth,valign=m]{figs/benchmark_digicam_celeba/hf_digicam_celeba_26k_U5+Unet8M_wave/4.png}
&\hspace{-0.35em}\includegraphics[width=\figsizegenceleba\linewidth,valign=m]{figs/benchmark_digicam_celeba/hf_digicam_celeba_26k_U5+Unet8M_wave/9.png}
    \\[\newlinegen]
    
\makecell{$\text{MWDN}_{8}$~\cite{Li:23}}
&\hspace{-0.35em}\includegraphics[width=\figsizegendiffusercam\linewidth,valign=m]{figs/benchmark_diffusercam/hf_diffusercam_mirflickr_MWDN8M/0.png}
&\hspace{-0.35em}\includegraphics[width=\figsizegendiffusercam\linewidth,valign=m]{figs/benchmark_diffusercam/hf_diffusercam_mirflickr_MWDN8M/1.png}
&\hspace{-0.35em}\includegraphics[width=\figsizegen\linewidth,valign=m]{figs/benchmark_tapecam/hf_tapecam_mirflickr_MWDN8M/1.png}
&\hspace{-0.35em}\includegraphics[width=\figsizegen\linewidth,valign=m]{figs/benchmark_tapecam/hf_tapecam_mirflickr_MWDN8M/2.png}
&\hspace{-0.35em}\includegraphics[width=\figsizegen\linewidth,valign=m]{figs/benchmark_digicam_mirflickr/hf_digicam_mirflickr_single_25k_MWDN8M_wave/1.png}
&\hspace{-0.35em}\includegraphics[width=\figsizegen\linewidth,valign=m]{figs/benchmark_digicam_mirflickr/hf_digicam_mirflickr_single_25k_MWDN8M_wave/2.png}
&\hspace{-0.35em}\includegraphics[width=\figsizegenceleba\linewidth,valign=m]{figs/benchmark_digicam_celeba/hf_digicam_celeba_26k_MWDN8M_wave/4.png}
&\hspace{-0.35em}\includegraphics[width=\figsizegenceleba\linewidth,valign=m]{figs/benchmark_digicam_celeba/hf_digicam_celeba_26k_MWDN8M_wave/9.png}
    \\[\newlinegen]
    
\hline
\makecell{$\text{Pre}_{4}$+\\TrainInv\\+$\text{Post}_{4}$}
&\hspace{-0.35em}\includegraphics[width=\figsizegendiffusercam\linewidth,valign=m]{figs/benchmark_diffusercam/hf_diffusercam_mirflickr_Unet4M+TrainInv+Unet4M/0.png}
&\hspace{-0.35em}\includegraphics[width=\figsizegendiffusercam\linewidth,valign=m]{figs/benchmark_diffusercam/hf_diffusercam_mirflickr_Unet4M+TrainInv+Unet4M/1.png}
&\hspace{-0.35em}\includegraphics[width=\figsizegen\linewidth,valign=m]{figs/benchmark_tapecam/hf_tapecam_mirflickr_Unet4M+TrainInv+Unet4M/1.png}
&\hspace{-0.35em}\includegraphics[width=\figsizegen\linewidth,valign=m]{figs/benchmark_tapecam/hf_tapecam_mirflickr_Unet4M+TrainInv+Unet4M/2.png}
&\hspace{-0.35em}\includegraphics[width=\figsizegen\linewidth,valign=m]{figs/benchmark_digicam_mirflickr/hf_digicam_mirflickr_single_25k_Unet4M+TrainInv+Unet4M_wave/1.png}
&\hspace{-0.35em}\includegraphics[width=\figsizegen\linewidth,valign=m]{figs/benchmark_digicam_mirflickr/hf_digicam_mirflickr_single_25k_Unet4M+TrainInv+Unet4M_wave/2.png}
&\hspace{-0.35em}\includegraphics[width=\figsizegenceleba\linewidth,valign=m]{figs/benchmark_digicam_celeba/hf_digicam_celeba_26k_Unet4M+TrainInv+Unet4M_wave/4.png}
&\hspace{-0.35em}\includegraphics[width=\figsizegenceleba\linewidth,valign=m]{figs/benchmark_digicam_celeba/hf_digicam_celeba_26k_Unet4M+TrainInv+Unet4M_wave/9.png}
    \\[\newlinegen]
\makecell{$\text{Pre}_2$+\\$\text{MMCN}_{4}$\\+$\text{Post}_2$}
&\hspace{-0.35em}\includegraphics[width=\figsizegendiffusercam\linewidth,valign=m]{figs/benchmark_diffusercam/hf_diffusercam_mirflickr_Unet2M+MMCN+Unet2M/0.png}
&\hspace{-0.35em}\includegraphics[width=\figsizegendiffusercam\linewidth,valign=m]{figs/benchmark_diffusercam/hf_diffusercam_mirflickr_Unet2M+MMCN+Unet2M/1.png}
&\hspace{-0.35em}\includegraphics[width=\figsizegen\linewidth,valign=m]{figs/benchmark_tapecam/hf_tapecam_mirflickr_Unet2M+MMCN+Unet2M/1.png}
&\hspace{-0.35em}\includegraphics[width=\figsizegen\linewidth,valign=m]{figs/benchmark_tapecam/hf_tapecam_mirflickr_Unet2M+MMCN+Unet2M/2.png}
&\hspace{-0.35em}\includegraphics[width=\figsizegen\linewidth,valign=m]{figs/benchmark_digicam_mirflickr/hf_digicam_mirflickr_single_25k_Unet2M+MMCN+Unet2M_wave/1.png}
&\hspace{-0.35em}\includegraphics[width=\figsizegen\linewidth,valign=m]{figs/benchmark_digicam_mirflickr/hf_digicam_mirflickr_single_25k_Unet2M+MMCN+Unet2M_wave/2.png}
&\hspace{-0.35em}\includegraphics[width=\figsizegenceleba\linewidth,valign=m]{figs/benchmark_digicam_celeba/hf_digicam_celeba_26k_Unet2M+MMCN+Unet2M_wave/4.png}
&\hspace{-0.35em}\includegraphics[width=\figsizegenceleba\linewidth,valign=m]{figs/benchmark_digicam_celeba/hf_digicam_celeba_26k_Unet2M+MMCN+Unet2M_wave/9.png}
    \\[\newlinegen]
\makecell{$\text{Pre}_{4}$+\\LeADMM5\\+$\text{Post}_{4}$}
&\hspace{-0.35em}\includegraphics[width=\figsizegendiffusercam\linewidth,valign=m]{figs/benchmark_diffusercam/hf_diffusercam_mirflickr_Unet4M+U5+Unet4M/0.png}
&\hspace{-0.35em}\includegraphics[width=\figsizegendiffusercam\linewidth,valign=m]{figs/benchmark_diffusercam/hf_diffusercam_mirflickr_Unet4M+U5+Unet4M/1.png}
&\hspace{-0.35em}\includegraphics[width=\figsizegen\linewidth,valign=m]{figs/benchmark_tapecam/hf_tapecam_mirflickr_Unet4M+U5+Unet4M/1.png}
&\hspace{-0.35em}\includegraphics[width=\figsizegen\linewidth,valign=m]{figs/benchmark_tapecam/hf_tapecam_mirflickr_Unet4M+U5+Unet4M/2.png}
&\hspace{-0.35em}\includegraphics[width=\figsizegen\linewidth,valign=m]{figs/hf_digicam_mirflickr_single_25k_Unet4M+U5+Unet4M_wave/1.png}
&\hspace{-0.35em}\includegraphics[width=\figsizegen\linewidth,valign=m]{figs/hf_digicam_mirflickr_single_25k_Unet4M+U5+Unet4M_wave/2.png}
&\hspace{-0.35em}\includegraphics[width=\figsizegenceleba\linewidth,valign=m]{figs/benchmark_digicam_celeba/hf_digicam_celeba_26k_Unet4M+U5+Unet4M_wave/4.png}
&\hspace{-0.35em}\hspace{-0.5em}\includegraphics[width=\figsizegenceleba\linewidth,valign=m]{figs/benchmark_digicam_celeba/hf_digicam_celeba_26k_Unet4M+U5+Unet4M_wave/9.png}
    \\
	\end{tabular}
	\caption{Visual comparison of reconstructions on test set examples of datasets of different mask types (amplitude and phase). Models are trained on the corresponding training set of each dataset/system.}
    \label{fig:exp1_visual_comparison}
\end{figure*}

\noindent In this experiment, we demonstrate the benefit of the pre-processor for multiple camera inversion techniques and across multiple datasets of three different imaging systems.
We compare three camera inversion approaches with and without a pre-processor: ADMM with 5 unrolled layers (\textit{LeADMM5})~\cite{Monakhova:19}, trainable inversion (\textit{TrainInv})~\cite{9239993}, and ADMM with 5 unrolled layers and a model mismatch compensation network ($\textit{MMCN}_{4}$)~\cite{9546648}.
For multi-Wiener deconvolution network with PSF correction ($\textit{MWDN}_{8}$)~\cite{Li:23}, 
we do not add a pre- nor post-processor as its architecture already contains convolutional layers before and after (multiple) camera inversions.

\cref{tab:exp1_benchmark} presents image quality metrics for all reconstruction approaches and across four datasets.
For all approaches (\textit{LeADMM5}, \textit{TrainInv}, $\textit{MMCN}_{4}$) and across all datasets, we see improved performance when splitting the parameters between the pre- and post-processors.
This improvement is visualized and quantified in \cref{fig:exp1_improvement_viz}.
There is a slight decrease in PSNR for \textit{DiffuserCam} with $\textit{MMCN}_{4}$ but both SSIM and LPIPS improve.
We observe significant improvement when using \textit{TrainInv} for camera inversion.
This is confirmed by looking at a few outputs from the test sets in \cref{fig:exp1_visual_comparison}.
With just a post-processor, (\textit{TrainInv}+$\textit{Post}_{8}$) has difficulty in faithfully recovering the colors of the original image, but adding a pre-processor helps to reproduce the original colors.

Equating the number of parameters across models helps to identify which techniques lead to improved performance.
For example, we observe that ($\textit{MMCN}_{4}$+$\textit{Post}_{4}$) is worse than \textit{uncompensated} unrolled ADMM (\textit{LeADMM5}+$\textit{Post}_{8}$).
This indicates that using a more performant post-processor is better at handling model mismatch
than adding a compensation network.
With ($\textit{Pre}_{8}$+\textit{LeADMM5}), we put all the neural network parameters in the pre-processor.
While better than \textit{ADMM100}, it lacks the denoising and perceptual enhancements that a post-processor can offer.
For $\textit{MWDN}_{8}$, with respect to approaches that \textit{do not} use a pre-processor, we only observe improved performance for the \textit{DiffuserCam} dataset, as shown by the original authors~\cite{Li:23}.
For other datasets, $\textit{MWDN}_{8}$ is noticeably worse; likely because it is more sensitive to noise from the low-cost hardware of our datasets, and due to multiple camera inversions in its approach (see \cref{fig:multiwiener}).

When performing imaging for a specific type of data content, \eg reconstruction faces with \textit{DigiCam-CelebA} rather than general-purpose imaging with \textit{DigiCam-Single}, we observe a significant improvement in performance: \SI{2.9}{\decibel} improvement in PSNR, and \SI{32}{\percent} and \SI{41}{\percent} relative improvement in SSIM and LPIPS respectively (for $\textit{Pre}_{4}$+\textit{LeADMM5}+$\textit{Post}_{4}$).



\subsubsection{Improving Camera Inversion} Using unrolled ADMM for camera inversion has more flexibility when it comes to improving the camera inversion capabilities.
Improving the capacity of MMCN and MWDN requires introducing a large amount of model parameters, while unrolled ADMM only requires four more hyperparameters per unrolled layer.
By simply adding five more unrolled layers (\ie~just 20 more parameters) for \textit{LeADMM10}, we can further improve results ($\textit{Pre}_{4}$+\textit{LeADMM10}+$\textit{Post}_{4}$ row of \cref{tab:exp1_benchmark}).
This however comes at a cost in inference time.

To directly address model mismatch,
we can add a \textit{PSF correction} network as shown in~\cref{fig:pipeline}.
A similar approach is used by MWDN~\cite{Li:23}, in which the input PSF is fed to a downscaling network (see \cref{fig:multiwiener}).
For the last row in \cref{tab:exp1_benchmark},
we feed the PSF to a DRUNet with (4, 8, 16, 32) feature representation channels (128K parameters) and slightly decrease the pre-processor size to (32, 64, 112, 128) channels (3.9M parameters).
Intermediate outputs, \ie after the pre-processor,
camera inversion, and PSF correction, can be found in \cref{app:intermediate}.

\subsubsection{Inference Time} In \cref{tab:exp1_benchmark}, we report average inference time computed over 100 trials on an Intel Xeon E5-2680 v3 \SI{2.5}{\giga\hertz} CPU with a single Nvidia Titan X Pascal GPU.
Using unrolled ADMM and MMCN is significantly slower due to multiple iterations, while approaches based on inverse/Wiener filtering (\textit{TrainInv} and MWDN) are much faster.


\subsection{Improved Robustness}
\label{sec:robustness_exp}

\noindent In these experiments, we demonstrate the improved robustness of our modular approach by numerically varying the noise sources:
(1) the measurement noise~$\bm{n}$ and (2) the model mismatch $\bm{\Delta}_H$.
We perform these experiments on the \textit{DiffuserCam} dataset.
For both experiments, intermediate outputs can be found in \cref{app:intermediate}.

\subsubsection{Shot Noise}
\label{sec:shot_noise_exp}
During training, we add shot noise (\ie~signal-dependent noise following a Poisson distribution) at an SNR of \SI{10}{\decibel}, which is representative of a low-light/photon scenario. 
We evaluate at different SNRs to determine robustness to variations of the input SNR.
\cref{tab:exp2_robustness} shows average test set metrics,
and \cref{fig:robustness_10db} shows example outputs.
The model that does not use a pre-processor (\textit{LeADMM5}+$\textit{Post}_{8}$) is unable to recover high frequency details,
and the image quality metrics are significantly worse (\cref{tab:exp2_robustness}).
Incorporating a pre-processor is capable of recovering such details ($\textit{Pre}_{4}$+\textit{LeADMM5}+$\textit{Post}_{4}$), 
and is robust to SNRs lower than the one used at training.

\subsubsection{Model Mismatch}
\label{sec:mismatch_exp}
To evaluate robustness to model mismatch,
we digitally add Gaussian noise to \textit{DiffuserCam}'s PSF at multiple SNRs,
as shown in the first row of \cref{fig:robustness_psf_err}.
The remaining rows show example outputs,
and \cref{tab:exp2_robustness_psf} presents average test set metrics on the clean \textit{DiffuserCam} dataset.
Using both a pre- and post-processor is more robust to the increasing mismatch in the PSF than just using a post-processor,
and re-allocating some of the pre-processor parameters to PSF correction further improves performance.

\begin{table}[!t]
	\renewcommand{\arraystretch}{1.3}
	\caption{Average image quality metrics (PSNR $\uparrow$ / SSIM $\uparrow$ / LPIPS $\downarrow$) on models (each column) that have been trained on the \textit{DiffuserCam} dataset with a signal-to-noise ratio (SNR) of \SI{10}{\decibel} (digitally-added Poisson noise). At test time, Poisson noise is added according to the SNR in the left-most column.}
	\label{tab:exp2_robustness}
	\centering
	\begin{tabular}{c||c|c}
		\hline
		 Test SNR & LeADMM5+$\text{Post}_{8}$~\cite{Monakhova:19} & $\text{Pre}_{4}$+LeADMM5+$\text{Post}_{4}$ \\
		\hline\hline
		 \SI{0}{\decibel} & 16.4 / 0.569 / 0.345 &  \textbf{20.0} / \textbf{0.755} / \textbf{0.230} \\
         \hline
		\SI{5}{\decibel} & 18.2 / 0.627 / 0.316 &  \textbf{23.9} / \textbf{0.818} / \textbf{0.186} \\
		\hline
		 \makecell{\SI{10}{\decibel}\\(Train SNR)} & 19.4 / 0.672 / 0.290 & \textbf{24.6} / \textbf{0.827}  / \textbf{0.176}  \\
		\hline
        \SI{15}{\decibel} & 19.7 / 0.687 / 0.282  & \textbf{23.7} / \textbf{0.820} / \textbf{0.184} \\
		\hline
        \SI{20}{\decibel} & 19.7 / 0.690 / 0.281  & \textbf{21.6} / \textbf{0.784} / \textbf{0.215} \\
		\hline
	\end{tabular}
\end{table}



\begin{table}[!t]
	\renewcommand{\arraystretch}{1.2}
	\caption{Average image quality metrics (PSNR $\uparrow$ / SSIM $\uparrow$ / LPIPS $\downarrow$) on models (each column) that have been trained on the \textit{DiffuserCam} dataset with Gaussian noise added to the PSF (according to SNR in left-most column). Corrupted PSFs can be seen in~\cref{fig:robustness_psf_err}.}
	\label{tab:exp2_robustness_psf}
	\centering
	\scalebox{0.85}{\begin{tabular}{c||c|c|c}
		\hline
		 PSF SNR & \makecell{LeADMM5\\+$\text{Post}_{8}$~\cite{Monakhova:19}} & \makecell{$\text{Pre}_{4}$+LeADMM5\\+$\text{Post}_{4}$} & \makecell{$\text{Pre}_{4}$+LeADMM5\\+$\text{Post}_{4}$ (PSF correction)} \\
		\hline\hline
		 Clean & 23.8 / 0.806 / 0.202 &  25.3 / 0.838 / 0.171 & \textbf{26.4} / \textbf{0.857} / \textbf{0.154}  \\
         \hline
		\SI{0}{\decibel} & 23.1 / 0.781 / 0.222 & 24.7 / 0.827 / 0.181 & \textbf{26.2} / \textbf{0.853} / \textbf{0.159} \\
		\hline
		 % \makecell{\SI{-5}{\decibel}} & 22.7 / 0.774 / 0.234 & 24.3 / 0.819 / 0.190 & \\
		% \hline
        \SI{-10}{\decibel} & 22.3 / 0.750 / 0.250 &  24.4 / 0.818 / 0.193 & \textbf{25.7} / \textbf{0.849} / \textbf{0.164} \\
		\hline
        \SI{-20}{\decibel} & 20.2 / 0.673 / 0.297 & 23.4 / 0.790 / 0.215 & \textbf{26.2} / \textbf{0.858} / \textbf{0.155} \\
		\hline
	\end{tabular}}
\end{table}


\newcommand{\figsizeood}{0.135}
\newcommand{\newlineood}{14pt}
\begin{figure*}[t!]
\centering
	\begingroup
	\renewcommand{\arraystretch}{1} % Default value: 1
	\setlength{\tabcolsep}{0.08em} % for the horizontal padding
	%\begin{table}[t!]
	\begin{tabular}{c cccccc}
		  &\multicolumn{2}{c}{\SI{0}{\decibel}} & \multicolumn{2}{c}{\makecell{\SI{10}{\decibel}\\(train SNR)}}  & \multicolumn{2}{c}{\SI{20}{\decibel}}\\

          \cmidrule(r){2-3} \cmidrule(r){4-5} \cmidrule(r){6-7} 
    
\makecell{Raw data} &
\includegraphics[width=\figsizeood\linewidth,valign=m]{figs/benchmark_10db/0db/LENSLESS/0.png}
  & 
  \includegraphics[width=\figsizeood\linewidth,valign=m]{figs/benchmark_10db/0db/LENSLESS/1.png}

  &\includegraphics[width=\figsizeood\linewidth,valign=m]{figs/benchmark_10db/10db/LENSLESS/0.png}
  & 
  \includegraphics[width=\figsizeood\linewidth,valign=m]{figs/benchmark_10db/10db/LENSLESS/1.png}

  & \includegraphics[width=\figsizeood\linewidth,valign=m]{figs/benchmark_10db/20db/LENSLESS/0.png}
  &\includegraphics[width=\figsizeood\linewidth,valign=m]{figs/benchmark_10db/20db/LENSLESS/1.png}
\\[\newlineood]

\hline

\makecell{LeADMM5\\+$\text{Post}_{8}$~\cite{Monakhova:19}} &
\includegraphics[width=\figsizeood\linewidth,valign=m]{figs/benchmark_10db/0db/hf_diffusercam_mirflickr_U5+Unet8M_10db/0.png}
& 
\includegraphics[width=\figsizeood\linewidth,valign=m]{figs/benchmark_10db/0db/hf_diffusercam_mirflickr_U5+Unet8M_10db/1.png}
& \includegraphics[width=\figsizeood\linewidth,valign=m]{figs/benchmark_10db/10db/hf_diffusercam_mirflickr_U5+Unet8M_10db/0.png}
& \includegraphics[width=\figsizeood\linewidth,valign=m]{figs/benchmark_10db/10db/hf_diffusercam_mirflickr_U5+Unet8M_10db/1.png}
  & \includegraphics[width=\figsizeood\linewidth,valign=m]{figs/benchmark_10db/20db/hf_diffusercam_mirflickr_U5+Unet8M_10db/0.png}
  &\includegraphics[width=\figsizeood\linewidth,valign=m]{figs/benchmark_10db/20db/hf_diffusercam_mirflickr_U5+Unet8M_10db/1.png}
\\[\newlineood]

\makecell{$\text{Pre}_{4}$\\+LeADMM5\\+$\text{Post}_{4}$} & \includegraphics[width=\figsizeood\linewidth,valign=m]{figs/benchmark_10db/0db/hf_diffusercam_mirflickr_Unet4M+U5+Unet4M_10db/0.png}
& \includegraphics[width=\figsizeood\linewidth,valign=m]{figs/benchmark_10db/0db/hf_diffusercam_mirflickr_Unet4M+U5+Unet4M_10db/1.png}
& \includegraphics[width=\figsizeood\linewidth,valign=m]{figs/benchmark_10db/10db/hf_diffusercam_mirflickr_Unet4M+U5+Unet4M_10db/0.png}
& \includegraphics[width=\figsizeood\linewidth,valign=m]{figs/benchmark_10db/10db/hf_diffusercam_mirflickr_Unet4M+U5+Unet4M_10db/1.png}
  & \includegraphics[width=\figsizeood\linewidth,valign=m]{figs/benchmark_10db/20db/hf_diffusercam_mirflickr_Unet4M+U5+Unet4M_10db/0.png}
  &\includegraphics[width=\figsizeood\linewidth,valign=m]{figs/benchmark_10db/20db/hf_diffusercam_mirflickr_Unet4M+U5+Unet4M_10db/1.png}
\\
	\end{tabular}
	%\end{table}
	\endgroup
	\caption{Example outputs of applying (\textit{LeADMM5+$\text{Post}_{8}$}) and (\textit{$\text{Pre}_{4}$+LeADMM5+$\text{Post}_{4}$}) at various signal-to-noise ratios (SNRs). Both approaches are trained with lensless measurements where Poisson noise is added according to an SNR \SI{10}{\decibel}.}
  \label{fig:robustness_10db}
\end{figure*}


\newcommand{\figsizepsferr}{0.135}
\begin{figure*}[t!]
\centering
	\begingroup
	\renewcommand{\arraystretch}{1} % Default value: 1
	\setlength{\tabcolsep}{0.08em} % for the horizontal padding
	%\begin{table}[t!]
	\begin{tabular}{ccccccc}
		  % &\multicolumn{2}{c}{Clean} 
          & \multicolumn{2}{c}{\SI{0}{\decibel}} & \multicolumn{2}{c}{\makecell{\SI{-10}{\decibel}}} & \multicolumn{2}{c}{\SI{-20}{\decibel}}\\

          \cmidrule(r){2-3} \cmidrule(r){4-5} \cmidrule(r){6-7} 
          % \cmidrule(r){8-9} 
    
\makecell{PSF} 
  & 
  \multicolumn{2}{c}{\includegraphics[width=0.18\linewidth,valign=m]{figs/psf_err/psf_0db_en.png}}
&\multicolumn{2}{c}{\includegraphics[width=0.18\linewidth,valign=m]{figs/psf_err/psf_-10db_en.png}}
  & \multicolumn{2}{c}{\includegraphics[width=0.18\linewidth,valign=m]{figs/psf_err/psf_-20db_en.png}}
\\[20pt]

\hline

\makecell{LeADMM5\\+$\text{Post}_{8}$~\cite{Monakhova:19}} 
& \includegraphics[width=\figsizepsferr\linewidth,valign=m]{figs/psf_err/hf_diffusercam_mirflickr_U5+Unet8M_psf0dB/0.png}
& 
\includegraphics[width=\figsizepsferr\linewidth,valign=m]{figs/psf_err/hf_diffusercam_mirflickr_U5+Unet8M_psf0dB/1.png}
& \includegraphics[width=\figsizepsferr\linewidth,valign=m]{figs/psf_err/hf_diffusercam_mirflickr_U5+Unet8M_psf-10dB/0.png}
& 
\includegraphics[width=\figsizepsferr\linewidth,valign=m]{figs/psf_err/hf_diffusercam_mirflickr_U5+Unet8M_psf-10dB/1.png}
& \includegraphics[width=\figsizepsferr\linewidth,valign=m]{figs/psf_err/hf_diffusercam_mirflickr_U5+Unet8M_psf-20dB/0.png}
& 
\includegraphics[width=\figsizepsferr\linewidth,valign=m]{figs/psf_err/hf_diffusercam_mirflickr_U5+Unet8M_psf-20dB/1.png}
\\[\newlineood]

\makecell{$\text{Pre}_{4}$+LeADMM5\\+$\text{Post}_{4}$} 
& \includegraphics[width=\figsizepsferr\linewidth,valign=m]{figs/psf_err/hf_diffusercam_mirflickr_Unet4M+U5+Unet4M_psf-0dB/0.png}
& 
\includegraphics[width=\figsizepsferr\linewidth,valign=m]{figs/psf_err/hf_diffusercam_mirflickr_Unet4M+U5+Unet4M_psf-0dB/1.png}
& \includegraphics[width=\figsizepsferr\linewidth,valign=m]{figs/psf_err/hf_diffusercam_mirflickr_Unet4M+U5+Unet4M_psf-10dB/0.png}
& 
\includegraphics[width=\figsizepsferr\linewidth,valign=m]{figs/psf_err/hf_diffusercam_mirflickr_Unet4M+U5+Unet4M_psf-10dB/1.png}
& \includegraphics[width=\figsizepsferr\linewidth,valign=m]{figs/psf_err/hf_diffusercam_mirflickr_Unet4M+U5+Unet4M_psf-20dB/0.png}
& 
\includegraphics[width=\figsizepsferr\linewidth,valign=m]{figs/psf_err/hf_diffusercam_mirflickr_Unet4M+U5+Unet4M_psf-20dB/1.png}
\\[\newlineood]

\makecell{$\text{Pre}_{4}$+LeADMM5\\+$\text{Post}_{4}$ (PSF corr.)} 
& \includegraphics[width=\figsizepsferr\linewidth,valign=m]{figs/psf_err/hf_diffusercam_mirflickr_Unet4M+U5+Unet4M_psfNN_psf-0dB/0.png}
& 
\includegraphics[width=\figsizepsferr\linewidth,valign=m]{figs/psf_err/hf_diffusercam_mirflickr_Unet4M+U5+Unet4M_psfNN_psf-0dB/1.png}
& \includegraphics[width=\figsizepsferr\linewidth,valign=m]{figs/psf_err/hf_diffusercam_mirflickr_Unet4M+U5+Unet4M_psfNN_psf-10dB/0.png}
& 
\includegraphics[width=\figsizepsferr\linewidth,valign=m]{figs/psf_err/hf_diffusercam_mirflickr_Unet4M+U5+Unet4M_psfNN_psf-10dB/1.png}
& \includegraphics[width=\figsizepsferr\linewidth,valign=m]{figs/psf_err/hf_diffusercam_mirflickr_Unet4M+U5+Unet4M_psfNN_psf-20dB/0.png}
& 
\includegraphics[width=\figsizepsferr\linewidth,valign=m]{figs/psf_err/hf_diffusercam_mirflickr_Unet4M+U5+Unet4M_psfNN_psf-20dB/1.png}
\\
	\end{tabular}
	%\end{table}
	\endgroup
	\caption{Example outputs of various reconstruction approach that have been trained on digitally-corrupted PSFs at various signal-to-noise ratios (SNRs) to evaluate robustness to model mismatch.}
  \label{fig:robustness_psf_err}
\end{figure*}



\subsection{Evaluating Generalizability to PSF Changes}
\label{sec:exp_eval_gen}

\newcommand{\figsizegentrans}{0.083}
\newcommand{\figsizegencelebatrans}{0.07}
\begin{figure*}[t!]
\centering
	\renewcommand{\arraystretch}{1} % Default value: 1
	\setlength{\tabcolsep}{0.1em} % for the horizontal padding
	\begin{tabular}{c|cc|cc|cc||cc|cc}
    \makecell{\textit{Train set} $\rightarrow$\\\textit{Test set} $\downarrow$}
    &   
    \multicolumn{2}{c|}{DiffuserCam}
    & \multicolumn{2}{c|}{TapeCam}
    & \multicolumn{2}{c||}{DigiCam-Single}
    & \multicolumn{2}{c|}{\makecell{ADMM100\\(no training)}}
    & 
    % \multicolumn{2}{c}{\makecell{Raw data +\\ground-truth}}
    \multicolumn{2}{c}{Ground-truth}
    \\
    % \cmidrule(r){2-3} \cmidrule(r){4-5} \cmidrule(r){6-7} \cmidrule(r){8-9} 
\hline 
% \\[0.1pt]
\makecell{DiffuserCam}
&\includegraphics[width=\figsizegentrans\linewidth,valign=m]{figs/benchmark_diffusercam/hf_diffusercam_mirflickr_Unet4M+U5+Unet4M/3.png}
&\includegraphics[width=\figsizegentrans\linewidth,valign=m]{figs/benchmark_diffusercam/hf_diffusercam_mirflickr_Unet4M+U5+Unet4M/4.png}
&\includegraphics[width=\figsizegentrans\linewidth,valign=m]{figs/benchmark_diffusercam/hf_tapecam_mirflickr_Unet4M+U5+Unet4M/3.png}
&\includegraphics[width=\figsizegentrans\linewidth,valign=m]{figs/benchmark_diffusercam/hf_tapecam_mirflickr_Unet4M+U5+Unet4M/4.png}
&\includegraphics[width=\figsizegentrans\linewidth,valign=m]{figs/benchmark_diffusercam/hf_digicam_mirflickr_single_25k_Unet4M+U5+Unet4M_wave/3.png}
&\includegraphics[width=\figsizegentrans\linewidth,valign=m]{figs/benchmark_diffusercam/hf_digicam_mirflickr_single_25k_Unet4M+U5+Unet4M_wave/4.png}
&\includegraphics[width=\figsizegentrans\linewidth,valign=m]{figs/benchmark_diffusercam/ADMM/100/3.png}
 
&\includegraphics[width=\figsizegentrans\linewidth,valign=m]{figs/benchmark_diffusercam/ADMM/100/4.png}

&\includegraphics[width=\figsizegentrans\linewidth,valign=m]{figs/benchmark_diffusercam/GROUND_TRUTH/3.png}
&\includegraphics[width=\figsizegentrans\linewidth,valign=m]{figs/benchmark_diffusercam/GROUND_TRUTH/4.png}
    \\[6pt]
\hline 
\makecell{TapeCam}
&\includegraphics[width=\figsizegentrans\linewidth,valign=m]{figs/benchmark_tapecam/hf_diffusercam_mirflickr_Unet4M+U5+Unet4M/4.png}
&\includegraphics[width=\figsizegentrans\linewidth,valign=m]{figs/benchmark_tapecam/hf_diffusercam_mirflickr_Unet4M+U5+Unet4M/5.png}
&\includegraphics[width=\figsizegentrans\linewidth,valign=m]{figs/benchmark_tapecam/hf_tapecam_mirflickr_Unet4M+U5+Unet4M/4.png}
&\includegraphics[width=\figsizegentrans\linewidth,valign=m]{figs/benchmark_tapecam/hf_tapecam_mirflickr_Unet4M+U5+Unet4M/5.png}
&\includegraphics[width=\figsizegentrans\linewidth,valign=m]{figs/benchmark_tapecam/hf_digicam_mirflickr_single_25k_Unet4M+U5+Unet4M_wave/4.png}
&\includegraphics[width=\figsizegentrans\linewidth,valign=m]{figs/benchmark_tapecam/hf_digicam_mirflickr_single_25k_Unet4M+U5+Unet4M_wave/5.png}
&\includegraphics[width=\figsizegentrans\linewidth,valign=m]{figs/benchmark_tapecam/ADMM/100/4.png}
&\includegraphics[width=\figsizegentrans\linewidth,valign=m]{figs/benchmark_tapecam/ADMM/100/5.png}

&\includegraphics[width=\figsizegentrans\linewidth,valign=m]{figs/benchmark_tapecam/GROUND_TRUTH/4.png}
&\includegraphics[width=\figsizegentrans\linewidth,valign=m]{figs/benchmark_tapecam/GROUND_TRUTH/5.png}
\\[10pt]
\hline
\makecell{DigiCam\\-Single}
&\includegraphics[width=\figsizegentrans\linewidth,valign=m]{figs/benchmark_digicam_mirflickr/hf_diffusercam_mirflickr_Unet4M+U5+Unet4M/4.png}
&\includegraphics[width=\figsizegentrans\linewidth,valign=m]{figs/benchmark_digicam_mirflickr/hf_diffusercam_mirflickr_Unet4M+U5+Unet4M/5.png}
&\includegraphics[width=\figsizegentrans\linewidth,valign=m]{figs/benchmark_digicam_mirflickr/hf_tapecam_mirflickr_Unet4M+U5+Unet4M/4.png}
&\includegraphics[width=\figsizegentrans\linewidth,valign=m]{figs/benchmark_digicam_mirflickr/hf_tapecam_mirflickr_Unet4M+U5+Unet4M/5.png}
&\includegraphics[width=\figsizegentrans\linewidth,valign=m]{figs/hf_digicam_mirflickr_single_25k_Unet4M+U5+Unet4M_wave/4.png}
&\includegraphics[width=\figsizegentrans\linewidth,valign=m]{figs/hf_digicam_mirflickr_single_25k_Unet4M+U5+Unet4M_wave/5.png}
&\includegraphics[width=\figsizegentrans\linewidth,valign=m]{figs/benchmark_digicam_mirflickr/ADMM/100/4.png}
&\includegraphics[width=\figsizegentrans\linewidth,valign=m]{figs/benchmark_digicam_mirflickr/ADMM/100/5.png}

&\includegraphics[width=\figsizegentrans\linewidth,valign=m]{figs/benchmark_digicam_mirflickr/GROUND_TRUTH/4.png}
&\includegraphics[width=\figsizegentrans\linewidth,valign=m]{figs/benchmark_digicam_mirflickr/GROUND_TRUTH/5.png}
\\[10pt]
\hline
\hline
\makecell{DigiCam\\-Multi}
&\includegraphics[width=\figsizegentrans\linewidth,valign=m]{figs/benchmark_digicam_multimask/hf_diffusercam_mirflickr_Unet4M+U5+Unet4M/4.png}
&\includegraphics[width=\figsizegentrans\linewidth,valign=m]{figs/benchmark_digicam_multimask/hf_diffusercam_mirflickr_Unet4M+U5+Unet4M/5.png}
&\includegraphics[width=\figsizegentrans\linewidth,valign=m]{figs/benchmark_digicam_multimask/hf_tapecam_mirflickr_Unet4M+U5+Unet4M/4.png}
&\includegraphics[width=\figsizegentrans\linewidth,valign=m]{figs/benchmark_digicam_multimask/hf_tapecam_mirflickr_Unet4M+U5+Unet4M/5.png}
&\includegraphics[width=\figsizegentrans\linewidth,valign=m]{figs/benchmark_digicam_multimask/hf_digicam_mirflickr_single_25k_Unet4M+U5+Unet4M_wave/4.png}
&\includegraphics[width=\figsizegentrans\linewidth,valign=m]{figs/benchmark_digicam_multimask/hf_digicam_mirflickr_single_25k_Unet4M+U5+Unet4M_wave/5.png}
&\includegraphics[width=\figsizegentrans\linewidth,valign=m]{figs/benchmark_digicam_multimask/ADMM/100/4.png}
&\includegraphics[width=\figsizegentrans\linewidth,valign=m]{figs/benchmark_digicam_multimask/ADMM/100/5.png}

&\includegraphics[width=\figsizegentrans\linewidth,valign=m]{figs/benchmark_digicam_multimask/GROUND_TRUTH/4.png}
& \hspace{-0.5em}\includegraphics[width=\figsizegentrans\linewidth,valign=m]{figs/benchmark_digicam_multimask/GROUND_TRUTH/5.png}

\\

	\end{tabular}
	\caption{Example outputs of ($\textit{Pre}_{4}$\textit{+LeADMM5+}$\textit{Post}_{4}$) trained on the system/dataset indicated along the columns, and evaluated on the system/dataset indicated along the rows.}
    \label{fig:exp2_visual_comparison}
\end{figure*}


\noindent While the results of learned reconstruction approach can improve significantly from classical techniques such as ADMM, it has not been studied how such approaches generalize to other systems, \eg if the PSF changes.
Before applying techniques for improving the generalizability to measurements of unseen PSFs (\cref{sec:exp_improve_gen}), in this section we first benchmark the learned reconstructions from the previous section.




In \cref{fig:exp2_visual_comparison}, ($\textit{Pre}_{4}$\textit{+LeADMM5+}$\textit{Post}_{4}$) that was trained on measurements from one system is evaluated on measurements from other systems.
Along the ``diagonal'' of the first three rows are reconstructions where the system/PSF is identical during training and testing, \ie what previous work normally performs as an evaluation.
Off-diagonal and in the last row (unseen mask patterns of \textit{DigiCam)} are evaluations on system changes.
In general, we observe that the performance of learned reconstructions significantly deteriorate when evaluated on another system.
Similar results are observed for the models with PSF correction in \cref{app:gen_benchmark_psf_corr}.

When testing on phase masks (first two rows of \cref{fig:exp2_visual_comparison}), we observe slightly discernible content with systems trained on another phase mask (\textit{DiffuserCam} and \textit{TapeCam}),
but it is not as good as simply using \textit{ADMM100}.
% , which does not require training.
The model trained on \textit{DigiCam-Single} (third column) fails to recover meaningful outputs from \textit{DiffuserCam} and \textit{TapeCam} measurements.
When testing on \textit{DigiCam-Single} and \textit{DigiCam-Multi} (amplitude masks, last two rows),
the reconstruction approaches trained on phase masks perform very poorly.
The model trained on \textit{DigiCam-Single} is able to better generalize to \textit{DigiCam-Multi} as the mask structure is similar, but there are significant coloring artifacts as the learned reconstruction fails to generalize to measurements of the unseen masks in \textit{DigiCam-Multi}.







\subsection{Generalizing to Measurements of a New PSF}
\label{sec:exp_improve_gen}



\newcommand{\figsizedigicamgennew}{0.105}
\newcommand{\newlinedigicamgennew}{18pt}
\begin{figure*}[t!]
	\centering
	\renewcommand{\arraystretch}{1} % Default value: 1
	\setlength{\tabcolsep}{0.1em} % for the horizontal padding
	%\begin{table}[t!]
	\begin{tabular}{c cc|ccc|ccc}
     &   
    \multicolumn{2}{c}{DigiCam-Single (test set)}
    & \multicolumn{6}{c}{DigiCam-Multi (test set)}
    \\ 
    \cmidrule(r){2-3} \cmidrule(r){4-9} 
Ground-truth  & \makecell{Single-Mask\\(PSF corr.)} & \makecell{Multi-Mask\\(PSF corr.)} & 
\makecell{Single-Mask} & \makecell{With\\PSF corr.} & \makecell{PSF corr.\\and P\&P} & 
\makecell{Multi-Mask} &
\makecell{With\\PSF corr.} & \makecell{PSF corr.\\and P\&P}\\

\includegraphics[width=\figsizedigicamgennew\linewidth,valign=m]{figs/benchmark_digicam_mirflickr/GROUND_TRUTH/1.png}
    &
\includegraphics[width=\figsizedigicamgennew\linewidth,valign=m]{figs/benchmark_digicam_mirflickr/hf_digicam_mirflickr_single_25k_Unet4M+U5+Unet4M_wave_psfNN/1.png}
		& 
\includegraphics[width=\figsizedigicamgennew\linewidth,valign=m]{figs/benchmark_digicam_mirflickr/hf_digicam_mirflickr_multi_25k_Unet4M+U5+Unet4M_wave_psfNN/1.png}
&
\includegraphics[width=\figsizedigicamgennew\linewidth,valign=m]{figs/benchmark_digicam_multimask/hf_digicam_mirflickr_single_25k_Unet4M+U5+Unet4M_wave/1.png}
&
\includegraphics[width=\figsizedigicamgennew\linewidth,valign=m]{figs/benchmark_digicam_multimask/hf_digicam_mirflickr_single_25k_Unet4M+U5+Unet4M_wave_psfNN/1.png}
&
\includegraphics[width=\figsizedigicamgennew\linewidth,valign=m]{figs/benchmark_digicam_multimask/hf_digicam_mirflickr_single_25k_Unet4M+U5+Unet4M_wave_psfNN_pnp/1.png}
& 
\includegraphics[width=\figsizedigicamgennew\linewidth,valign=m]{figs/benchmark_digicam_multimask/hf_digicam_mirflickr_multi_25k_Unet4M+U5+Unet4M_wave/1.png}
&
\includegraphics[width=\figsizedigicamgennew\linewidth,valign=m]{figs/benchmark_digicam_multimask/hf_digicam_mirflickr_multi_25k_Unet4M+U5+Unet4M_wave_psfNN/1.png}
&
\includegraphics[width=\figsizedigicamgennew\linewidth,valign=m]{figs/benchmark_digicam_multimask/hf_digicam_mirflickr_multi_25k_Unet4M+U5+Unet4M_wave_psfNN_pnp/1.png}
\\[\newlinedigicamgennew]

\includegraphics[width=\figsizedigicamgennew\linewidth,valign=m]{figs/benchmark_digicam_mirflickr/GROUND_TRUTH/2.png}
    &
\includegraphics[width=\figsizedigicamgennew\linewidth,valign=m]{figs/benchmark_digicam_mirflickr/hf_digicam_mirflickr_single_25k_Unet4M+U5+Unet4M_wave_psfNN/2.png}
		& 
\includegraphics[width=\figsizedigicamgennew\linewidth,valign=m]{figs/benchmark_digicam_mirflickr/hf_digicam_mirflickr_multi_25k_Unet4M+U5+Unet4M_wave_psfNN/2.png}
&
\includegraphics[width=\figsizedigicamgennew\linewidth,valign=m]{figs/benchmark_digicam_multimask/hf_digicam_mirflickr_single_25k_Unet4M+U5+Unet4M_wave/2.png}
&
\includegraphics[width=\figsizedigicamgennew\linewidth,valign=m]{figs/benchmark_digicam_multimask/hf_digicam_mirflickr_single_25k_Unet4M+U5+Unet4M_wave_psfNN/2.png}
&
\includegraphics[width=\figsizedigicamgennew\linewidth,valign=m]{figs/benchmark_digicam_multimask/hf_digicam_mirflickr_single_25k_Unet4M+U5+Unet4M_wave_psfNN_pnp/2.png}
& 
\includegraphics[width=\figsizedigicamgennew\linewidth,valign=m]{figs/benchmark_digicam_multimask/hf_digicam_mirflickr_multi_25k_Unet4M+U5+Unet4M_wave/2.png}
&
\includegraphics[width=\figsizedigicamgennew\linewidth,valign=m]{figs/benchmark_digicam_multimask/hf_digicam_mirflickr_multi_25k_Unet4M+U5+Unet4M_wave_psfNN/2.png}
&
\includegraphics[width=\figsizedigicamgennew\linewidth,valign=m]{figs/benchmark_digicam_multimask/hf_digicam_mirflickr_multi_25k_Unet4M+U5+Unet4M_wave_psfNN_pnp/2.png}
\\[\newlinedigicamgennew]

\includegraphics[width=\figsizedigicamgennew\linewidth,valign=m]{figs/benchmark_digicam_multimask/GROUND_TRUTH/61.png}
    &
\includegraphics[width=\figsizedigicamgennew\linewidth,valign=m]{figs/benchmark_digicam_mirflickr/hf_digicam_mirflickr_single_25k_Unet4M+U5+Unet4M_wave_psfNN/61.png}
		& 
\includegraphics[width=\figsizedigicamgennew\linewidth,valign=m]{figs/benchmark_digicam_mirflickr/hf_digicam_mirflickr_multi_25k_Unet4M+U5+Unet4M_wave_psfNN/61.png}
&
\includegraphics[width=\figsizedigicamgennew\linewidth,valign=m]{figs/benchmark_digicam_multimask/hf_digicam_mirflickr_single_25k_Unet4M+U5+Unet4M_wave/61.png}
&
\includegraphics[width=\figsizedigicamgennew\linewidth,valign=m]{figs/benchmark_digicam_multimask/hf_digicam_mirflickr_single_25k_Unet4M+U5+Unet4M_wave_psfNN/61.png}
&
\includegraphics[width=\figsizedigicamgennew\linewidth,valign=m]{figs/benchmark_digicam_multimask/hf_digicam_mirflickr_single_25k_Unet4M+U5+Unet4M_wave_psfNN_pnp/61.png}
& 
\includegraphics[width=\figsizedigicamgennew\linewidth,valign=m]{figs/benchmark_digicam_multimask/hf_digicam_mirflickr_multi_25k_Unet4M+U5+Unet4M_wave/61.png}
&
\includegraphics[width=\figsizedigicamgennew\linewidth,valign=m]{figs/benchmark_digicam_multimask/hf_digicam_mirflickr_multi_25k_Unet4M+U5+Unet4M_wave_psfNN/61.png}
&
\includegraphics[width=\figsizedigicamgennew\linewidth,valign=m]{figs/benchmark_digicam_multimask/hf_digicam_mirflickr_multi_25k_Unet4M+U5+Unet4M_wave_psfNN_pnp/61.png}
\\
	\end{tabular}
  \caption{Example reconstructions on the \textit{DigiCam-Single} and \textit{DigiCam-Multi} test sets, as indicated by upper-most column labels.\textit{Single-Mask} and \textit{Multi-Mask} refer to the training dataset for ($\textit{Pre}_{4}$\textit{+LeADMM5+}$\textit{Post}_{4}$), where \textit{PSF corr.} incorporates a PSF correction module and \textit{P\&P} applies model adaptation with parameterize-and-perturb~\cite{9477112}.}
	% \caption{Generalizability to \textit{DigiCam} mask pattern variations.}
	\label{fig:digicam_gen}
\end{figure*}

\newcommand{\figsizedirect}{0.32}
\newcommand{\newlinedirect}{23pt}
\begin{figure}[t!]
	\centering
	\renewcommand{\arraystretch}{1} % Default value: 1
	\setlength{\tabcolsep}{0.2em} % for the horizontal padding
	%\begin{table}[t!]
	\begin{tabular}{ccc}
		ADMM100
		& Single-Mask
  % \makecell{$\text{Pre}_{4}$\textit{+LeADMM5+}$\text{Post}_{4}$\\(DigiCam-Single)}
		& 
  Multi-Mask
  % \makecell{$\text{Pre}_{4}$\textit{+LeADMM5+}$\text{Post}_{4}$\\(DigiCam-Multi)}
		\\\includegraphics[width=\figsizedirect\linewidth,valign=m]{figs/direct_capture/admm_raw_box.png}
		&\includegraphics[width=\figsizedirect\linewidth,valign=m]{figs/direct_capture/Unet4M+U5+Unet4M_wave_raw_box.png}
		&  \includegraphics[width=\figsizedirect\linewidth,valign=m]{figs/direct_capture/Unet4M+U5+Unet4M_wave_raw_box_multi.png}
		\\[\newlinedirect]
		\includegraphics[width=\figsizedirect\linewidth,valign=m]{figs/direct_capture/admm_raw_stuffed_animals.png}
&\includegraphics[width=\figsizedirect\linewidth,valign=m]{figs/direct_capture/Unet4M+U5+Unet4M_wave_raw_stuffed_animals.png}&\includegraphics[width=\figsizedirect\linewidth,valign=m]{figs/direct_capture/Unet4M+U5+Unet4M_wave_raw_stuffed_animals_multi.png}
		\\
	\end{tabular}
	\caption{Direct-capture reconstructions with \textit{DigiCam}, \ie real objects instead of images displayed on a computer monitor. Second and third columns apply ($\textit{Pre}_{4}$\textit{+LeADMM5+}$\textit{Post}_{4}$) trained on  \textit{DigiCam-Single} (measurements with a single mask) and \textit{DigiCam-Multi} (measurements with multiple masks).}
	\label{fig:direct_capture}
\end{figure}


\noindent As shown in \cref{fig:exp2_visual_comparison}, it is not possible to use a reconstruction trained on one system and expect high-quality image recovery with measurements from another system.
% The recovered image is very poor, and it is sometimes better to simply use ADMM.
However, 
% even the quality of ADMM is unsatisfactory,
% and 
it would be desirable to exploit the perceptual improvements of learned approaches.
In this experiment, we explore (1) multi-mask training to improve the generalizability of \textit{DigiCam} to mask variations, (2) model adaptation as proposed by~\cite{9477112}, and (3) transfer learning to exploit the trained-components from one system for a completely new system.
For all approaches, we make use of our modular reconstruction architecture, namely ($\textit{Pre}_{4}$\textit{+LeADMM5+}$\textit{Post}_{4}$).


\begin{table}[!t]
	\renewcommand{\arraystretch}{1.3}
	\caption{Average image quality metrics (PSNR $\uparrow$ / SSIM $\uparrow$ / LPIPS $\downarrow$) on measurements of \textit{DigiCam} mask patterns not seen during training, \ie the \textit{DigiCam-Multi} test set. \textit{Single-mask} denotes training ($\textit{Pre}_{4}$\textit{+LeADMM5+}$\textit{Post}_{4}$) on \textit{DigiCam-Single}, and \textit{Multi-mask} denotes training on \textit{DigiCam-Multi}.}
	\label{tab:exp3_gen_digicam}
	\centering
	\begin{tabular}{c||c|c}
		\hline
		 & DigiCam-Single & DigiCam-Multi \\
		\hline\hline
		ADMM100 &  10.6 / 0.291 / 0.751 & 10.6 / 0.301 / 0.760  \\
		\hline
		\hline
		Single-Mask & 19.6 / 0.531 / 0.449 & 13.6 / 0.368 / 0.646  \\
        \hline
		Multi-Mask & 17.4 / 0.474 / 0.492 & 18.1 / 0.498 / 0.489  \\
        \hline
        \hline
        \makecell{Single-Mask\\with PSF corr.} &  \textbf{20.1} / \textbf{0.552} / \textbf{0.439} & 15.1 / 0.421 / 0.571  \\
		\hline
		\makecell{Multi-Mask\\with PSF corr.} & 17.7 / 0.484 / 0.484 &  \textbf{18.5} / \textbf{0.509} / \textbf{0.477}  \\
		\hline
	\end{tabular}
\end{table}

\begin{table}[!t]
	\renewcommand{\arraystretch}{1.3}
	\caption{Average image quality metrics on measurements of \textit{DigiCam} mask patterns not seen during training, \ie the \textit{DigiCam-Multi} test set. \textit{Single-mask} denotes training ($\textit{Pre}_{4}$\textit{+LeADMM5+}$\textit{Post}_{4}$) on \textit{DigiCam-Single}, and \textit{Multi-mask} denotes training on \textit{DigiCam-Multi}. Parameterize-and-perturb (P\&P)~\cite{9477112} is used to adapt the model weights for each test example.}
	\label{tab:exp_digicam_gilton}
	\centering
	\begin{tabular}{c||c|c|c|c}
		\hline
		 & PSNR $\uparrow$ & SSIM $\uparrow$ & LPIPS $\downarrow$ & Data Fidelity $\downarrow$\\
		\hline\hline
		ADMM100 & 10.6 & 0.301 & 0.760 & \textbf{0.00575} \\
		\hline
        \hline
  %       Single & 13.6 & 0.368 & 0.646 & 0.0225 \\
		% \hline
        \makecell{Single-Mask\\with PSF corr.} & 15.1 & 0.421 & 0.571 & 0.0138 \\
		\hline
        % benchmark/2024-11-27/06-50-01
        \makecell{Adapted\\with P\&P} & 14.6 & 0.404 & 0.593  & 0.00962 \\
		\hline
        \hline
  %       Multi & 18.1 & 0.498 & 0.489 & 0.0179 \\
		% \hline
        \makecell{Multi-Mask\\with PSF corr.} & \textbf{18.5} & \textbf{0.509} & \textbf{0.477} & 0.0178 \\
		\hline
        % benchmark/2024-11-27/06-50-54
        \makecell{Adapted\\with P\&P} & 17.9 & 0.495 & 0.497  & 0.0131 \\
		\hline
	\end{tabular}
\end{table}



\subsubsection{Multi-Mask Training}

For multi-mask training, we use the \textit{DigiCam-Multi} dataset, whose training set has measurements from 85 different masks (250 measurements per mask).
During training, the corresponding PSF is passed to \textit{LeADMM5} such that all masks share the learned pre-processor, unrolled ADMM, and post-processor parameters.
We also add the PSF correction network, to learn processing that is common across mask patterns. 

In \cref{tab:exp3_gen_digicam},
the \textit{DigiCam-Multi} column evaluates various reconstructions on measurements from 15 masks not seen during training.
The model trained with multiple mask patterns (\textit{Multi-mask}) generalizes better to the unseen mask patterns than the model trained on a single mask pattern (\textit{Single-Mask}).
Incorporating PSF correction improves the performance for both:
with training on multiple masks still significantly better.
\cref{fig:digicam_gen} shows example outputs on the \textit{DigiCam-Multi} test set.
\textit{Single-Mask} has significant coloring artifacts.
PSF correction can improve these color artifacts but is still present, \eg with the cake. 
\textit{Multi-Mask}, on the other hand, has more consistent coloring with respect to the ground-truth.

While better generalizability to mask pattern changes can be achieved with multi-mask training, 
there is a degradation with respect to optimizing for a fixed mask, \ie first column of \cref{tab:exp3_gen_digicam} where we evaluate on \textit{DigiCam-Single} (the same mask whose measurements are used to train \textit{Single-Mask}).
The second and third columns of \cref{fig:digicam_gen} show performance on the \textit{DigiCam-Single} test set.
While the metrics are different, the reconstructed outputs are of similar quality.
Moreover, multi-mask training to achieve generalizability altogether removes the need for (1) measuring datasets with new mask patterns and (2) training new models, cutting down several weeks of development.
\cref{fig:direct_capture} shows results on real objects, \ie not displayed on the screen and using the mask pattern of \textit{DigiCam-Single},
and the \textit{Single-Mask} and \textit{Multi-Mask} models perform similarly.

\subsubsection{Model Adaptation}

Gilton \etal~\cite{9477112} proposed multiple approaches to adapt a learned reconstruction from one forward model to another.
Without the need for ground-truth data,
all approaches minimize the data fidelity.
For example, parameterize-and-perturb (P\&P) minimizes the following for each measurement-PSF pair $\{\bm{y}_i, \bm{p}_i\}_{i=0}^{N}$:
\begin{align}
\label{eq:pnp}
    \min_{\bm{\theta}} ||\bm{p}_i \ast r(\bm{y}_i; \bm{\theta}, \bm{p}_i) - \bm{y}_i||_2^2 + \mu ||\bm{\theta} - \bm{\theta}_0||_2^2,
\end{align}
where $\bm{\theta}$ are the retrained model parameters, $\bm{\theta}_0$ are the original model parameters, $r(\bm{y}; \bm{\theta}, \bm{p})$ recovers an image given a set of parameters and a PSF, and $\mu > 0$ controls the regularization on the retrained parameters.

\cref{tab:exp_digicam_gilton} compares models with and without P\&P to evaluate generalizability to measurements from unseen mask patterns in the \textit{DigiCam-Multi} test set.
For P\&P, \cref{eq:pnp} is minimized with stochastic gradient descent for 10 iterations with a learning rate of $3 \cdot 10^{-3}$ and $\mu = 10^{-3}$.
While P\&P reduces the data fidelity for both the \textit{Single-Mask} and \textit{Multi-Mask} models,
the other image quality metrics deteriorate.
This is consistent with the findings of \textit{DiffuserCam}~\cite{Monakhova:19}, namely for lensless imaging there is a trade-off between image quality and matching the
imaging model due the imperfect forward modeling. 
\cref{fig:digicam_gen} shows example outputs of the model parameters adapted with P\&P,
which are very similar to outputs from the original model.

\subsubsection{Transfer Learning}

Another approach for generalizing to new PSFs is to apply transfer learning, 
\eg fine-tuning a model that has been trained on one system to a new system.
Fine-tuning still requires data of the new system, 
but this data can be simulated to avoid measuring a dataset.
In the previous experiment,
we observed that the commonly-used shift-invariant (convolutional) model is not suitable for minimizing data fidelity for model adaption~\cite{9477112}.
In this experiment,
we investigate whether it is sufficient for simulating data for fine-tuning.
We perform our experiments with \textit{DiffuserCam} (whose on-axis PSF has a high degree of similarity with off-axis PSFs~\cite{Antipa:18}),
by convolving the lensed data with the PSF and adding Poisson noise with an SNR of \SI{40}{\decibel}.

\cref{tab:exp3_gen_phase} quantifies performance on the \textit{DiffuserCam} test set and \cref{fig:diffuser_gen} shows example outputs.
Our baselines are (1) \textit{ADMM100} (no training required) and (2) \textit{DiffuserCam-Sim} (trained from scratch with simulated data).
While \textit{DiffuserCam-Sim} performs worse than \textit{ADMM100} in terms of metrics and has grainier outputs, 
it is better at recovering finer details  (\eg lines on the butterfly wings in \cref{fig:diffuser_gen}).
Moreover, it performs better than models trained on other datasets, \ie \textit{TapeCam} and \textit{DigiCam-Multi}.

\begin{table}[!t]
	\renewcommand{\arraystretch}{1.3}
	\caption{Average image quality metrics of reconstructions on the \textit{DiffuserCam} test set. No model is trained with the measured lensless data from \textit{DiffuserCam}.}
	\label{tab:exp3_gen_phase}
	\centering
	\begin{tabular}{c||c|c|c}
		\hline
	 & PSNR $\uparrow$ & SSIM $\uparrow$ & LPIPS $\downarrow$   \\
		\hline\hline
        % \makecell{DiffuserCam (meas.)} & 25.3 / 0.838 / 0.171 \\
        % \hline
		ADMM100 & 15.0 & 0.457 & 0.511   \\
  \hline
        \makecell{DiffuserCam-Sim} & 13.6 & 0.389 & 0.525  \\
		\hline
		\hline
		TapeCam & 10.7 & 0.217 & 0.556 \\
		\hline
		\makecell{Fine-tune ($\text{Pre}_{4}$+LeADMM5+$\text{Post}_{4}$)}  & 15.3 & 0.563 & 0.337 \\
  \hline
  \makecell{Fine-tune ($\text{Pre}_{4}$+LeADMM5)} & 16.1 & 0.516 & 0.350  \\
\hline
  \makecell{Fine-tune (LeADMM5+$\text{Post}_{4}$)} & \textbf{16.2} & \textbf{0.604} & \textbf{0.305}  \\
  \hline
  \hline
  \makecell{DigiCam-Multi} &  10.2 & 0.330 & 0.542  \\
		\hline
  \makecell{Fine-tune ($\text{Pre}_{4}$+LeADMM5+$\text{Post}_{4}$)}  & 15.0 & 0.569 & 0.327  \\
		\hline
     \makecell{Fine-tune ($\text{Pre}_{4}$+LeADMM5)} & \textbf{16.2} & 0.506 & 0.368   \\
    \hline
    \makecell{Fine-tune (LeADMM5+$\text{Post}_{4}$)} & 15.9 & \textbf{0.589} & \textbf{0.324} \\
\hline
	\end{tabular}
\end{table}



By fine-tuning \textit{TapeCam} and \textit{DigiCam-Multi} with \textit{DiffuserCam} simulations,
we can obtain approaches that surpass the performance of \textit{ADMM100} and \textit{DiffuserCam-Sim}.
Fine-tuning exploits the modular components that have been learned on real measurements from other systems to generalize to the new \textit{DiffuserCam} system.
We fine-tune various components with a smaller learning rate of $10^{-5}$, and find that freezing the pre-processor yields the best results, 
\ie indicating that the pre-processor generalizes to measurements of other systems.
While training on actual measurement is significantly better (see \cref{tab:exp1_benchmark}), fine-tuning learned reconstructions on simulated data can exploit learnings from the original system and remove the need of collecting a lensed-lensless dataset.





\newcommand{\figsizediffusergen}{0.135}
\newcommand{\newlinediffusergen}{12pt}
\begin{figure*}[t!]
	\centering
	\renewcommand{\arraystretch}{1} % Default value: 1
	\setlength{\tabcolsep}{0.1em} % for the horizontal padding
	%\begin{table}[t!]
	\begin{tabular}{ccccccc}
        Ground-truth
        % & \makecell{DiffuserCam\\(meas.)}
        & ADMM100
		& \makecell{DiffuserCam\\-Sim}
		& TapeCam
        & \makecell{TapeCam\\(fine-tuned)}
        & DigiCam-Multi
        & \makecell{DigiCam-Multi\\(fine-tuned)}
		\\


\includegraphics[width=\figsizediffusergen\linewidth,valign=m]{figs/benchmark_diffusercam/GROUND_TRUTH/3.png}


  &\includegraphics[width=\figsizediffusergen\linewidth,valign=m]{figs/benchmark_diffusercam/ADMM/100/3.png}
		&\includegraphics[width=\figsizediffusergen\linewidth,valign=m]{figs/benchmark_diffusercam/hf_diffusercam_mirflickr_sim_Unet4M+U5+Unet4M/3.png}
		& \includegraphics[width=\figsizediffusergen\linewidth,valign=m]{figs/benchmark_diffusercam/hf_tapecam_mirflickr_Unet4M+U5+Unet4M/3.png}

  & \includegraphics[width=\figsizediffusergen\linewidth,valign=m]{figs/benchmark_diffusercam/hf_diffusercam_mirflickr_sim_Unet4M+U5+Unet4M_ft_tapecam_post/3.png}

  & \includegraphics[width=\figsizediffusergen\linewidth,valign=m]{figs/benchmark_diffusercam/hf_digicam_mirflickr_multi_25k_Unet4M+U5+Unet4M_wave/3.png}

  & \includegraphics[width=\figsizediffusergen\linewidth,valign=m]{figs/benchmark_diffusercam/hf_diffusercam_mirflickr_sim_Unet4M+U5+Unet4M_ft_digicam_multi_post/3.png}
		\\[\newlinediffusergen]

  \includegraphics[width=\figsizediffusergen\linewidth,valign=m]{figs/benchmark_diffusercam/GROUND_TRUTH/4.png}


  &\includegraphics[width=\figsizediffusergen\linewidth,valign=m]{figs/benchmark_diffusercam/ADMM/100/4.png}
		&\includegraphics[width=\figsizediffusergen\linewidth,valign=m]{figs/benchmark_diffusercam/hf_diffusercam_mirflickr_sim_Unet4M+U5+Unet4M/4.png}
		& \includegraphics[width=\figsizediffusergen\linewidth,valign=m]{figs/benchmark_diffusercam/hf_tapecam_mirflickr_Unet4M+U5+Unet4M/4.png}

  & \includegraphics[width=\figsizediffusergen\linewidth,valign=m]{figs/benchmark_diffusercam/hf_diffusercam_mirflickr_sim_Unet4M+U5+Unet4M_ft_tapecam_post/4.png}

  & \includegraphics[width=\figsizediffusergen\linewidth,valign=m]{figs/benchmark_diffusercam/hf_digicam_mirflickr_multi_25k_Unet4M+U5+Unet4M_wave/4.png}

  & \includegraphics[width=\figsizediffusergen\linewidth,valign=m]{figs/benchmark_diffusercam/hf_diffusercam_mirflickr_sim_Unet4M+U5+Unet4M_ft_digicam_multi_post/4.png}
		\\[\newlinediffusergen]


  \includegraphics[width=\figsizediffusergen\linewidth,valign=m]{figs/benchmark_diffusercam/GROUND_TRUTH/45.png}

  &\includegraphics[width=\figsizediffusergen\linewidth,valign=m]{figs/benchmark_diffusercam/ADMM/100/45.png}
		&\includegraphics[width=\figsizediffusergen\linewidth,valign=m]{figs/benchmark_diffusercam/hf_diffusercam_mirflickr_sim_Unet4M+U5+Unet4M/45.png}
		& \includegraphics[width=\figsizediffusergen\linewidth,valign=m]{figs/benchmark_diffusercam/hf_tapecam_mirflickr_Unet4M+U5+Unet4M/45.png}

  & \includegraphics[width=\figsizediffusergen\linewidth,valign=m]{figs/benchmark_diffusercam/hf_diffusercam_mirflickr_sim_Unet4M+U5+Unet4M_ft_tapecam_post/45.png}

  & \includegraphics[width=\figsizediffusergen\linewidth,valign=m]{figs/benchmark_diffusercam/hf_digicam_mirflickr_multi_25k_Unet4M+U5+Unet4M_wave/45.png}

  & \includegraphics[width=\figsizediffusergen\linewidth,valign=m]{figs/benchmark_diffusercam/hf_diffusercam_mirflickr_sim_Unet4M+U5+Unet4M_ft_digicam_multi_post/45.png}
		\\[\newlinediffusergen]

  \includegraphics[width=\figsizediffusergen\linewidth,valign=m]{figs/benchmark_diffusercam/GROUND_TRUTH/63.png}

  &\includegraphics[width=\figsizediffusergen\linewidth,valign=m]{figs/benchmark_diffusercam/ADMM/100/63.png}
		&\includegraphics[width=\figsizediffusergen\linewidth,valign=m]{figs/benchmark_diffusercam/hf_diffusercam_mirflickr_sim_Unet4M+U5+Unet4M/63.png}
		& \includegraphics[width=\figsizediffusergen\linewidth,valign=m]{figs/benchmark_diffusercam/hf_tapecam_mirflickr_Unet4M+U5+Unet4M/63.png}

  & \includegraphics[width=\figsizediffusergen\linewidth,valign=m]{figs/benchmark_diffusercam/hf_diffusercam_mirflickr_sim_Unet4M+U5+Unet4M_ft_tapecam_post/63.png}

  & \includegraphics[width=\figsizediffusergen\linewidth,valign=m]{figs/benchmark_diffusercam/hf_digicam_mirflickr_multi_25k_Unet4M+U5+Unet4M_wave/63.png}

  & \includegraphics[width=\figsizediffusergen\linewidth,valign=m]{figs/benchmark_diffusercam/hf_diffusercam_mirflickr_sim_Unet4M+U5+Unet4M_ft_digicam_multi_post/63.png}

  
	\end{tabular}
	\caption{Transfer learning to \textit{DiffuserCam}. Example reconstructions on measured data coming from the \textit{DiffuserCam} test set, without having seen measured lensless data from \textit{DiffuserCam} during training. Fine-tuned models freeze the pre-processor of the original model, and fine-tune the unrolled ADMM parameters and the post-processor on simulations of \textit{DiffuserCam} obtained by convolving ground-truth data with the PSF.}
	\label{fig:diffuser_gen}
\end{figure*}




