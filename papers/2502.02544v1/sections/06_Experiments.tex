\section{Experiments}\label{sec:experiment}

The experiments are divided into two main parts: evaluating VRLS's performance on a single node focusing on intra-node label shifts, and extending it to multi-node distributed learning scenarios with 5, 100, and 200 nodes. In the multi-node cases, we account for both inter-node and intra-node label shifts. Further experimental details, results, and discussions are provided in~\cref{app:exp}.

\paragraph{Density ratio estimation.}  

We begin by evaluating VRLS on the MNIST~\citep{MNIST} and CIFAR-10~\citep{CIFAR10} datasets in a single-node setting. Following the common experimental setup in the literature  \citep{bbse}, we simulate the test dataset using a Dirichlet distribution with varying $\alpha$ parameters. In this context, a higher $\alpha$ value indicates smoother transitions in the label distribution, while lower values reflect more abrupt shifts. The training dataset is uniformly distributed across all classes.
Initially, using a sample size of 5,000, we investigate 20 $\alpha$ values within the range $[10^{-1}, 10^{1}]$. Next, we fix $\alpha$ at either 1.0 or 0.1 and explore 50 different sample sizes ranging from 200 to 10,000. For each experiment, we run 100 trials and compute the mean squared error (MSE) between the true ratios and the estimated ratios.
A two-layer MLP is used for MNIST, while ResNet-18~\citep{he2016deep} is applied for CIFAR-10.

\begin{figure}[!t]
    \centering
    \begin{minipage}{.24\textwidth}
        \centering
        \includegraphics[width=\linewidth]{figs/MNIST_alpha_15_transparent.png}
        \caption*{MNIST} 
        \label{fig:MNIST_alpha_15_transparent}
    \end{minipage}%
    \begin{minipage}{.24\textwidth}
        \centering
        \includegraphics[width=\linewidth]{figs/alpha_cifar.png}
        \caption*{CIFAR-10}
        \label{fig:alpha_cifar}
    \end{minipage}%
    \begin{minipage}{.24\textwidth}
        \centering
        \includegraphics[width=\linewidth]{figs/alpha_cifar_relaxed.png}
        \caption*{CIFAR-10, Relaxed}
        \label{fig:alpha_cifar_relaxed}
    \end{minipage}%
    \begin{minipage}{.24\textwidth}
        \centering
        \includegraphics[width=\linewidth]{figs/alpha_cifar_relaxed_more.png}
        \caption*{CIFAR-10, Relax-m}
        \label{fig:alpha_cifar_relaxed_more}
    \end{minipage}
    \vspace{-0.5em}
    \caption{MSE analysis across different datasets and settings for VRLS (ours) compared to baselines, focusing on \textbf{shift parameter ($\alpha$)} experiments. These subfigures include results from MNIST, CIFAR-10, and relaxed label shift, illustrating the consistent superiority of VRLS. In the \textbf{‘relaxed’} setting, Gaussian blur (kernel size: 3; $\sigma$: 0.1–0.5) and brightness adjustment (factor: ±0.1) are applied with a 30\% probability to introduce real-world variability. In the \textbf{‘relax-m’} scenario, augmentations are applied with a 50\% probability, with Gaussian blur ($\sigma$: 0.1–0.7) and brightness (factor: ±0.2).}
    \label{figure_shift}
\end{figure}

\begin{figure}[!t]
    \centering
    \begin{minipage}{.24\textwidth}
        \centering
        \includegraphics[width=\linewidth]{figs/MNIST_size_20.png}
        \caption*{MNIST}
        \label{fig:MNIST_size_20}
    \end{minipage}%
    \begin{minipage}{.24\textwidth}
        \centering
        \includegraphics[width=\linewidth]{figs/size_cifar.png}
        \caption*{CIFAR-10}
        \label{fig:size_cifar}
    \end{minipage}%
    \begin{minipage}{.24\textwidth}
        \centering
        \includegraphics[width=\linewidth]{figs/size_cifar_relaxed.png}
        \caption*{CIFAR-10, Relaxed}
        \label{fig:size_cifar_relaxed}
    \end{minipage}%
    \begin{minipage}{.24\textwidth}
        \centering
        \includegraphics[width=\linewidth]{figs/size_cifar_relaxed_more.png}
        \caption*{CIFAR-10, Relax-m}
        \label{fig:size_cifar_relaxed_more}
    \end{minipage}
    \vspace{-0.5em}
    \caption{MSE analysis across different datasets and settings for VRLS (ours) compared to baselines, focusing on \textbf{sample size} experiments. These subfigures include results from MNIST, CIFAR-10, and relaxed label shift conditions, highlighting VRLS’s superior performance across varying test set sizes.}
    \label{figure_size}
\end{figure}

\begin{table}[!ht]
\input{figs/target_shift_table_5clients_fmnist_short}
\end{table}

\begin{table}[!ht]
\vspace{-1em}
\centering
\caption{We deploy ResNet-18 on CIFAR-10 to address label shifts across 5 nodes. The predictor is also a ResNet-18, ensuring consistency with the single-node scenario. For a fair comparison, we limit IW-ERM with VRLS and the true ratios to 5,000 iterations, while FedAvg and FedBN are run for 10,000 iterations. Detailed results are provided in \cref{app:fig:label-shift:cifar10:table}.}
\label{fig:target-shift-cifar10-5}
\input{figs/target_shift_table_5clients_mnist_short}
\end{table}
\begin{table*}[!thb]
\centering
\caption{We present the average node accuracies from the CIFAR-10 target shift experiment conducted with 100 and 200 nodes, where 5 nodes are randomly sampled to participate in each training round. Our IW-ERM with VRLS is run for 5,000 and 10,000 iterations, respectively, while both FedAvg and FedBN are run for 10,000 iterations each.}
\label{app:fig:target-shift:cifar10:client100:results}
\input{figs/10x10clients_cifar10_test_accuracy_table.tex}
\vspace{-2em}
\end{table*}

\cref{figure_shift} and \cref{figure_size} compares our proposed VRLS with baselines \citep{mlls, bbse_2002} under label shifts. MLLS\_L2 refers to the MLLS method using convex optimization via SGD \citep{mlls}, while MLLS\_EM employs the same objective function but is optimized using the EM algorithm \citep{bbse_2002}. 
Our proposed VRLS is optimized in a similar manner, resulting in VRLS\_L2 and VRLS\_EM, as shown in the figure. 
Our method consistently achieves lower MSE across different label shift intensities ($\alpha$) and test sample sizes on both datasets.
Notably, our density ratio estimation experiments align with the error bound in \cref{thm:est}, demonstrating that increasing the number of test samples improves estimation error at a rate proportional to the square root of the sample size. Additionally, the regularization term constrains the parameter space and reduces Rademacher complexity, leading to smoother predictions and improved model calibration, as supported by Section S2 in \citep{calibration_modern}. Both of them contribute to reduced estimation error. 

We also tested density ratio estimation under relaxed label shift conditions and found VRLS to exhibit greater robustness (see \cref{rlbg2} for detailed settings). Although this assumption holds broader potential for real-world applications, its precise alignment with real-world datasets requires further investigation—an important direction for future research that extends beyond the scope of this work.

\paragraph{Distributed learning settings.} We apply VRLS in a distributed learning context, addressing both intra- and inter-node label shifts. The initial experiments involve 5 nodes, using predefined label distributions on Fashion MNIST~\citep{f-mnist} and CIFAR-10, as shown in Tables \ref{app:fig:target-shift:fmnist:dist}- \ref{app:fig:target-shift:cifar10:dist} in~\cref{app:exp}. 

We employ a simple MLP with dropout as the predictor for Fashion MNIST. For global training with IW-ERM, LeNet~\citep{MNIST} is used on Fashion MNIST, and ResNet-18~\citep{ali2023federated} on CIFAR-10. All experiments are run with three random seeds, reporting the average accuracy across nodes. We compare IW-ERM with VRLS against baseline methods, including FedAvg~\citep{FedAvg}, FedBN~\citep{fedbn}, FedProx~\citep{fedprox}, and SCAFFOLD~\citep{SCAFFOLD}, as well as IW-ERM with true ratios serving as an upper bound. Hyperparameters are kept consistent with those in \citep{FedAvg, fedbn, ali2023federated}.

Each node's stochastic gradients are computed with a batch size of 64 and aggregated using the Adam optimizer. All experiments are run on a single GPU within an internal cluster. Both MLLS and VRLS use identical hyperparameters and training epochs for CIFAR-10 and Fashion MNIST, stopping once the classification loss reaches a predefined threshold on MNIST. We also conduct experiments with 100 and 200 nodes on CIFAR-10, where five nodes are randomly sampled each iteration to simulate more realistic distributed learning. In this case, IW-ERM with true ratios does not act as the upper bound due to the stochastic node sampling. The experiment is run once, and average accuracy across nodes is reported, with label distribution shown in \cref{app:fig:target-shift:cifar10:client100:dist} in~\Cref{app:exp}. Despite FedBN's reported slow convergence~\citep{ali2023federated}, we maintain 15,000 and 10,000 iterations for FedAvg and FedBN on Fashion MNIST and CIFAR-10, respectively, for fair comparison. However, IW-ERM is limited to 5,000 iterations using both true and estimated ratios due to faster convergence.

As shown in \cref{fig:target-shift-fmnist-5}, IW-ERM achieves over 20\% higher average accuracy than all baselines on Fashion MNIST, with only a third of the iterations. Notably, even with just 10\% of the training data in the first round of global training, the performance remains comparable, demonstrating reduced training complexity. This improvement is attributed to the theoretical benefits of IW-ERM, the robustness of density estimation, and the fact that the aggregation of density ratios reduces reliance on any single local estimate.
Similarly, \cref{fig:target-shift-cifar10-5} shows that IW-ERM approaches the upper bound on CIFAR-10, outperforming the baselines. Individual node accuracies are detailed in Tables \ref{app:fig:label-shift:fmnist:table}-\ref{app:fig:label-shift:cifar10:table} in~\Cref{app:exp}. In the 100-node scenario, IW-ERM continues to demonstrate superior performance, requiring only half the iterations, as shown in \cref{app:fig:target-shift:cifar10:client100:results}. It is important to note that using true ratios does not equate to IW-ERM, given the stochasticity of node selection during training. 
