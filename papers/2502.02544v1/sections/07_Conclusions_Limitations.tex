\section{Conclusions and Limitations}\label{sec:conc}

We propose VRLS to address label shift in distributed learning. Paired with IW-ERM, VRLS improves intra- and inter-node label shifts in multi-node settings. Empirically, VRLS consistently outperforms MLLS-based baselines, and IW-ERM with VRLS exceeds all multi-node learning baselines. Theoretical bounds further strengthen our method's foundation. Future work will explore estimating ratios by relaxing the strict class-conditional assumption and optimizing IW-ERM to reduce time complexity while ensuring scalability and practicality in real-world distributed learning.

\section*{Ethics statement}
No ethical approval was needed as no human subjects were involved. All authors fully support the content and findings.

\section*{Reproducibility statement}
We ensured reproducibility with publicly available datasets (MNIST, CIFAR-10) and standard models (e.g., ResNet-18). Links to datasets, code, and configurations will be provided upon camera-ready submission. Experiments were run on NVIDIA 3090, A100 GPUs, and Google Colab, with average results and variances reported across multiple trials. 

\section*{Acknowledgments}
The authors would like to thank Leello Tadesse Dadi and Thomas Pethick for helpful discussions. This work was supported by the Research Council of Norway (RCN) through its Centres of Excellence scheme, Integreat: Norwegian Centre for knowledge-driven machine learning, project number 332645.
The work of Changkyu Choi was funded by RCN under grant 309439.
The work of Volkan Cevher was supported by Hasler Foundation Program: Hasler Responsible AI (project number 21043), the Army Research Office which was accomplished under Grant Number W911NF-24-1-0048, and the Swiss National Science Foundation (SNSF) under grant number 200021\_205011.
