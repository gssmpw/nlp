
\section{Experimental Details and Additional Experiments}\label{app:exp}

In this section, we provide experimental details and additional experiments. In particular,  we validate our theory on multiple clients in a federated setting and show that our IW-ERM outperforms FedAvg and FedBN baselines {\it under drastic and challenging label shifts}. 

\subsection{Experimental Details}

In single-client experiments, a simple MLP without dropout is used as the predictor for MNIST, and ResNet-18 for CIFAR-10.

For experiments in a federated learning setting, both MNIST~\citep{MNIST} and Fashion MNIST~\citep{f-mnist} datasets are employed, each containing 60,000 training samples and 10,000 test samples, with each sample being a 28 by 28 pixel grayscale image. The CIFAR-10 dataset~\citep{CIFAR10} comprises 60,000 colored images, sized 32 by 32 pixels, spread across 10 classes with 6,000 images per class; it is divided into 50,000 training images and 10,000 test images. In this setting, the objective is to minimize the cross-entropy loss. Stochastic gradients for each client are calculated with a batch size of 64 and aggregated on the server using the Adam optimizer. LeNet is used for experiments on MNIST and Fashion MNIST with a learning rate of 0.001 and a weight decay of \(1 \times 10^{-6}\). For CIFAR-10, ResNet-18 is employed with a learning rate of 0.0001 and a weight decay of 0.0001. Three independent runs are implemented for 5-client experiments on Fashion MNIST and CIFAR-10, while for 10 clients, one run is conducted on CIFAR-10. The regularization coefficient $\zeta$ in~\cref{eq:f_g} is set to $1$ for all experiments.
All experiments are performed using a single GPU on an internal cluster and Colab.

Importantly, the training of the predictor for ratio estimation on both the baseline MLLS and our VRLS is executed with identical hyperparameters and epochs for CIFAR-10 and Fashion MNIST. The training is halted once the classification loss reaches a predefined threshold on MNIST.


\subsection{Relaxed Label Shift Experiments}\label{rlbg2}

In conventional label shift, it is assumed that $p(\boldsymbol{x} \mid y)$ remains unchanged across training and test data. However, this assumption is often too strong for real-world applications, such as in healthcare, where different hospitals may use varying equipment, leading to shifts in $p(\boldsymbol{x} \mid y)$ even with the same labels \citep{rajendran2023data}. Relaxed label shift loosens this assumption by allowing small changes in the conditional distribution \citep{rls, Luo2022GeneralizedLS}.

To formalize this, we use the distributional distance $\mathcal{D}$ and a relaxation parameter $\epsilon > 0$, as defined by \citet{rls}: 
$\max_{y} \mathcal{D}\left(p_{\text{tr}}(\boldsymbol{x} \mid y), p_{\text{te}}(\boldsymbol{x} \mid y)\right) \leq \epsilon$. This allows for slight differences in feature distributions between training and testing, capturing a more realistic scenario where the conditional distribution is not strictly invariant.

In our case, visual inspection suggests that the differences between temporally distinct datasets, such as CIFAR-10 and CIFAR-10.1\_v6~\citep{torralba2008tinyimages,recht2018cifar10_1}, may not meet the assumption of a small $\epsilon$. To address this, we instead simulate controlled shifts using test data augmentation, allowing us to regulate the degree of relaxation, following the approach outlined in \citet{rls}.

\subsection{Additional Experiments}
In this section, we provide supplementary results, visualizations of accuracy across clients and tables showing dataset distribution in FL setting and relaxed label shift.

\begin{figure*}[t]
    \centering
    
    \begin{minipage}{.32\textwidth}
        \centering
        \includegraphics[width=\linewidth]{figs/alpha_MLLS_family.png}
    \end{minipage}%
    \hfill
    \begin{minipage}{.32\textwidth}
        \centering
        \includegraphics[width=\linewidth]{figs/size_CG_1.png}
    \end{minipage}%
    \hfill
    \begin{minipage}{.32\textwidth}
        \centering
        \includegraphics[width=\linewidth]{figs/size_CG_01.png}
    \end{minipage}
    
    \caption{
        MSE analysis on MNIST for MLLS baselines.
        \textbf{Left:} Performance evaluation across various alpha values, comparing different methods: MLLS\_EM, MLLS\_L1, MLLS\_L2, and MLLS\_CG. MLLS\_L1 and MLLS\_L2 utilize convex optimization with $L_1$ and $L_2$ regularization for estimating our limited test sample problem, respectively, and are solved directly with a convex solver. In contrast, MLLS\_CG uses conjugate gradient descent and MLLS\_EM solves this convex optimization problem with EM algorithm. Both the EM and convex optimization methods (MLLS\_L1, MLLS\_L2) demonstrate superior and more consistent performance, especially under severe label shift conditions, when compared to MLLS\_CG.
        \textbf{Middle:} At an alpha value of 1.0, the MSE analysis shows comparable performance across most methods, with the exception of MLLS\_CG, which lags behind.
        \textbf{Right:} For alpha=0.1, MLLS\_CG performs significantly worse than the EM and convex optimization methods, consistent with the trends observed in the left plot.
    }
    \label{figure_1}
\end{figure*}


\begin{figure*}[t]
    \centering
    
    \begin{minipage}{.45\textwidth}
        \centering
        \includegraphics[width=\linewidth]{figs/MNIST_alpha_rebuttal.png}
    \end{minipage}%
    \hfill
    \begin{minipage}{.45\textwidth}
        \centering
        \includegraphics[width=\linewidth]{figs/MNIST_size_rebuttal.png}
    \end{minipage}%
    \hfill 
    \caption{In our detailed analysis with the MNIST dataset, we conduct a thorough comparison of VRLS alongside MLLS \citep{mlls}, EM \citep{bbse_2002}, and also RLLS \citep{rlls}.}
    \label{rlls_comparison}
\end{figure*}



\begin{figure*}[t]
    \centering
    
    \begin{minipage}{.45\textwidth}
        \centering
        \includegraphics[width=\linewidth]{figs/exp_fmnist4_alpha.png}
    \end{minipage}%
    \hfill
    \begin{minipage}{.45\textwidth}
        \centering
        \includegraphics[width=\linewidth]{figs/exp_fmnist4_size.png}
    \end{minipage}%
    \hfill 
    \caption{In this experiment with Fashion MNIST, a simple MLP with dropout were employed. }
\end{figure*}

\textbf{\begin{table*}[!htb]
\centering
\caption{LeNet on Fashion MNIST with label shift across $5$ clients. 15,000 iterations for FedAvg and FedBN; 5,000 for Upper Bound (FTW-ERM) using true ratios and our IW-ERM. To mention, to train our predictor, we use a simpliest MLP and employ linear kernel.}
\label{app:fig:label-shift:fmnist:table}
\input{figs/target_shift_table_5clients_fmnist}
\end{table*}}

\textbf{\begin{table*}[!htb]
\centering
\caption{ResNet-18 on CIFAR-10 with label shift across $5$ clients. For fair comparison, we run 5,000 iterations for our method and Upper Bound, while 10000 for FedAvg and FedBN.}
\label{app:fig:label-shift:cifar10:table}
\input{figs/target_shift_table_5clients_mnist}
\end{table*}}

\begin{figure}[t]
    \centering
    \includegraphics[width=0.5\textwidth]{figs/mean_std_2_2.png}
    \caption{The average, best-client, and worst-client accuracy, along with their standard deviations, are derived from \cref{app:fig:label-shift:fmnist:table}. Our method exhibits the lowest standard deviation, showcasing the most robust accuracy amongst the compared methods.}
    \label{fig:mean_std_2_2}
\end{figure}

\begin{figure}[t]
    \centering
    \includegraphics[width=0.5\textwidth]{figs/mean_std_1_1.png}
    \caption{The average, best-client, and worst-client accuracy, along with their standard deviations, are derived from \cref{app:fig:label-shift:cifar10:table}.}
    \label{app:fig:mean_std_1_1}
\end{figure}

\begin{table*}[!tb]
\centering
\caption{Label distribution on Fasion MNIST with 5 nodes, with the majority of classes possessing a limited number of training and test images across each node.}
\label{app:fig:target-shift:fmnist:dist}
\input{figs/5clients_fmnist_dist.tex}
\end{table*}

\begin{table*}[!tb]
\centering
\caption{Label distribution on CIFAR-10 with 5 clients, with the majority of classes possessing a limited number of training and test images across each client.}
\label{app:fig:target-shift:cifar10:dist}
\input{figs/5clients_fmnist_dist.tex}
\end{table*}

\begin{table*}[!tb]
\centering
\caption{Label distribution on CIFAR-10 with 100 clients, wherein groups of 10 clients share the same distribution and ratios. The majority of classes possess a limited quantity of training and test images on each client.}
\label{app:fig:target-shift:cifar10:client100:dist}
\input{figs/100_1.tex}
\input{figs/100_2.tex}
\end{table*}

