\section{Related Work}
\subsection{Youth participatory culture on community-based platforms}
Online interest-based communities can be particularly beneficial for youth because they provide low barriers to self-expression, opportunities for informal mentorship, and a sense of social connection~\cite{ito2013hanging}. These factors are part of what scholars like Ito, Jenkins, and boyd have defined as \textit{participatory culture}~\cite{jenkins2015participatory}. These virtual spaces can be positive for youth because they promote peer-to-peer informal learning, diverse cultural expression, and development of modern workplace skills~\cite{ito2009living, fiesler2017growing, fields2014programming,brennan2010making, evans2017fanfiction}. Furthermore, platform affordances like pseudonymity and peer-matching can encourage more honest self-disclosure than conversations in-person, which can be crucial for youth seeking help seeking mental health support in private~\cite{bhattacharya2019teen, jin2023music, wadley2013participatory, fang2022peer}. These sociotechnical elements also make online communities valuable for marginalized youth such as LGBTQ+ teens exploring their identity~\cite{dym2019coming, mcinroy2022counter} or seeking publicly inaccessible health information~\cite{liang2020education}. 

These past works have surfaced valuable findings relevant to the present study, but they largely focus on either adult-led interventions~\cite{tekinbas2021designing,cramer2007everything} or small identity-based communities~\cite{kotut2022winds}. We differentiate our work in that we are interested in examining online Discord communities that are moderated by teens between 13-17 years old. Additionally, we aim to understand what factors might make these peer-led communities engaging and appealing at scale. Despite these known benefits, community-based platforms like Reddit, Twitch, and Discord are still much less visible in youth culture than massive network-based sites like TikTok and Instagram~\cite{gottfriend2023teens}, which have been more frequently criticized for potentially harmful design patterns such as infinite scrolling and short-form video~\cite{schellewald_understanding_2023, tabachnick_nebraska_2024}. Thus, one of the motivations of our work is to identify what aspects of teen-led online communities might make them appealing as alternative, healthy social experiences for youth. To answer this, we investigate the practices and values of large teen-led communities that are already successful ``in the wild'' today. 

\subsection{Challenges with voluntary online community-driven moderation}
\textit{Online volunteer community moderators} are users who voluntarily manage, build, and engage with online communities on platforms such as Reddit, Discord, Facebook Groups, and Twitch~\cite{seering2019moderator}. Volunteer moderators have been a part of the online social ecosystem since its origins in electronic bulletin board systems~\cite{stone1993vampires}, and the processes of volunteer moderation have been explored in depth in CSCW literature (e.g.,~\cite{seering2020reconsidering, gilbert2020cesspool, srinivasan2019removal, geiger2010work, seering2017shaping, chandrasekharan2018internet, jiang2019voice, kiene2019frames, jhaver2019explanations, chandrasekharan2019crossmod, cullen2022practicing, cai2021profiling, schluger2022proactive}). Per Seering et al.~\cite{seering2019moderator}, volunteer moderators engage in a variety of activities, ranging from proactively monitoring and participating in their communities to removing offending content and users to discussing and writing policies. While considerable public discussion surrounding content moderation has focused on content and user removal, much of what volunteer moderators do is actually focused on community-building~\cite{seering2022whomoderates, seering2022metaphors, gibson2023teams}. Volunteer moderators welcome new members, educate them about rules, participate in and encourage high-quality discussion, and may even organize community events or social activities. Teams of volunteer moderators for larger communities may be administratively sophisticated~\cite{gilbert2020cesspool} and employ a wide variety of technical tools to assist with their various duties~\cite{kiene2019frames}. Platforms like Discord, Reddit, and Twitch arguably could not exist without these volunteers, yet they remain largely unpaid, underappreciated, and face greater risks of harm online than average users due to their visibility~\cite{seering2022pride,gilbert2023towards}. Another common concern is that platforms may be exploiting the passion of volunteer moderators for free labor, which can result in burnout due to the sheer volume of interpersonal conflicts they mediate in their communities~\cite{seering2019beyond,yu2020fruit,schopkegonzalez2022burnout}. 

These concerns become even more serious when the volunteers in question are teens with developmental sensitivities \cite{orben2022windows}. Today, platforms including Discord, Reddit, Twitch, and Facebook, allow users as young as 13 years old to volunteer as a moderator in any online community. While the actual proportion of moderators under the age of 18 is not publicly known, many online communities related to topics popular among youth such as gaming, high school, or college prep are likely moderated by teens today. To our knowledge, there are no studies about this population to date. In this work, we seek to bridge this gap to ensure that teen moderators are protected against the potential risks and challenges of their online leadership positions. Additionally, even though community-based moderation raises many ethical tensions, it also provides many benefits for the volunteers and members including a sense of fulfillment, belonging, and community~\cite{seering2022pride}. To make this relationship more sustainable, researchers have proposed solutions like monetary compensation or social recognition, but these are largely based on studies with adults ~\cite{dosono2019moderation,li2022measuring, chang2011social}. We are concerned with the fact that users under the age of 18 may not be eligible for options like payment. Thus, in addition to preventing risks, we also will examine proactive ways to better compensate and support teen moderators.

\subsection{The role of platform governance and moderation on youth social media experiences}
Platform governance and moderation structures can greatly impact users' social media experiences~\cite{zhang_form_2024}. In recent years, researchers have experimented with multi-level governance structures to decentralize platform power and offer more modularity, agency, and control for users at large~\cite{jhaver_decentralizing_2023}. The impact and potential of these structural factors, however, remain highly understudied for youth social media experiences. Davis explored at a conceptual level how community-supported and self-directed experiences can benefit youth and adolescent development~\cite{davis2023technologys}. Landesman et al. have investigated how teens' moment-by-moment emotional states and mindfulness can influence their experiences on social media~\cite{landesman2024care}. 
Others have examined various features, affordances, and interactions that influence youth social media experiences, but these also generally focus on interactive aspects of more SNS-based platforms like content permanence and quantifiability~\cite{nesi_transformation_2018,nesi_transformation_2018_2}. 

There is an urgent need and opportunity to more closely examine how governance-related structures, and especially community-driven models, can benefit youth social media experiences. In this work, we seek to answer this question for youth ages 13-17. Schoenbeck et al.'s work on youth online harm resolution in platform-driven moderation demonstrated how top-down structures were incompatible with this age group's preferences for restorative justice~\cite{schoenebeck2021youth}. Juxtaposing these results with Seering's work on platform-driven versus community-driven moderation~\cite{seering2020reconsidering} reveals an opportunity for the latter to address this age group's need for highly contextual moderation decisions. In this way, the present work is aligned with Tekinba≈ü et al.'s studies of Minecraft communities, which researched how community-driven moderation influenced children's social experiences, but the participants of this server were significantly younger (ages 8-13) and the server was moderated by research study coordinators~\cite{tekinbas2021designing}. Self-determination theory and adolescent developmental psychology suggest that high school-aged individuals seek greater autonomy and independence and that adult-led interventions are less effective than peer-led ones~\cite{ryan2020intrinsic, deci2000and}. Additionally, work by Wiesniewski et al. and Ghosh et al.'s work have shown the benefits of participatory, resilience, and autonomy-based approaches to teen safety ~\cite{wisniewski2015resilience, wisniewski2017parental,ghosh2018safety, wisniewski2015preventative}. In this work, we hypothesize that empowering teens to moderate their own online communities can be promising for enabling healthier youth social media experiences.