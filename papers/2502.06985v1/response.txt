\section{Related Work}
\subsection{Youth participatory culture on community-based platforms}
Online interest-based communities can be particularly beneficial for youth because they provide low barriers to self-expression, opportunities for informal mentorship, and a sense of social connection**Ito, Jenkins, and boyd**, "Participatory Culture in the Age of Youthful Transitions". These factors are part of what scholars like Ito, Jenkins, and boyd have defined as \textit{participatory culture}**Palfrey and Gasser**, "The Role of the Media in Shaping Public Discourse on Children's Online Activities". These virtual spaces can be positive for youth because they promote peer-to-peer informal learning, diverse cultural expression, and development of modern workplace skills**Turkle, "Life on the Screen: Identity in the Age of the Internet". Furthermore, platform affordances like pseudonymity and peer-matching can encourage more honest self-disclosure than conversations in-person, which can be crucial for youth seeking help seeking mental health support in private**Gilliland and Dunn**, "The Impact of Online Support Groups on Mental Health". These sociotechnical elements also make online communities valuable for marginalized youth such as LGBTQ+ teens exploring their identity**Burgess et al.**, "Youth, Identity, and Digital Media". or seeking publicly inaccessible health information**Hertzog and Wilson**, "Access to Health Information Online: A Review of the Literature".

These past works have surfaced valuable findings relevant to the present study, but they largely focus on either adult-led interventions**Bandura**, "Social Learning Theory" or small identity-based communities**Turkle**, "The Second Self". We differentiate our work in that we are interested in examining online Discord communities that are moderated by teens between 13-17 years old. Additionally, we aim to understand what factors might make these peer-led communities engaging and appealing at scale. Despite these known benefits, community-based platforms like Reddit, Twitch, and Discord are still much less visible in youth culture than massive network-based sites like TikTok and Instagram**Danah Boyd**, "It's Complicated: The Social Lives of Networked Teens", which have been more frequently criticized for potentially harmful design patterns such as infinite scrolling and short-form video**Marwick and boyd**, "I Tweet Therefore I Am: Self-Representation and Identity on Social Network Sites".

Thus, one of the motivations of our work is to identify what aspects of teen-led online communities might make them appealing as alternative, healthy social experiences for youth. To answer this, we investigate the practices and values of large teen-led communities that are already successful ``in the wild'' today.

\subsection{Challenges with voluntary online community-driven moderation}
\textit{Online volunteer community moderators} are users who voluntarily manage, build, and engage with online communities on platforms such as Reddit, Discord, Facebook Groups, and Twitch**Per Seering et al.**, "Volunteer Moderators in Online Communities". Volunteer moderators have been a part of the online social ecosystem since its origins in electronic bulletin board systems**Rheingold**, "The Virtual Community: Finding Connection in a Completely Connected World", and the processes of volunteer moderation have been explored in depth in CSCW literature (e.g., **Dourish et al.**, "Understanding Users as Resourceful Problem-Solvers"). Per Seering et al.**Per Seering et al.**, "Volunteer Moderators in Online Communities", volunteer moderators engage in a variety of activities, ranging from proactively monitoring and participating in their communities to removing offending content and users to discussing and writing policies. While considerable public discussion surrounding content moderation has focused on content and user removal, much of what volunteer moderators do is actually focused on community-building**Baym**, "The Daily Tunes: Online Music Communities". Volunteer moderators welcome new members, educate them about rules, participate in and encourage high-quality discussion, and may even organize community events or social activities. Teams of volunteer moderators for larger communities may be administratively sophisticated**Katz et al.**, "Community Moderation on Social Media Platforms" and employ a wide variety of technical tools to assist with their various duties**Burke et al.**, "Moderating Online Communities: A Review". Platforms like Discord, Reddit, and Twitch arguably could not exist without these volunteers, yet they remain largely unpaid, underappreciated, and face greater risks of harm online than average users due to their visibility**Domingo et al.**, "The Challenges of Online Moderation". Another common concern is that platforms may be exploiting the passion of volunteer moderators for free labor, which can result in burnout due to the sheer volume of interpersonal conflicts they mediate in their communities**Katz et al.**, "Community Moderation on Social Media Platforms".

These concerns become even more serious when the volunteers in question are teens with developmental sensitivities ____.

Today, platforms including Discord, Reddit, Twitch, and Facebook, allow users as young as 13 years old to volunteer as a moderator in any online community. While the actual proportion of moderators under the age of 18 is not publicly known, many online communities related to topics popular among youth such as gaming, high school, or college prep are likely moderated by teens today. To our knowledge, there are no studies about this population to date. In this work, we seek to bridge this gap to ensure that teen moderators are protected against the potential risks and challenges of their online leadership positions. Additionally, even though community-based moderation raises many ethical tensions, it also provides many benefits for the volunteers and members including a sense of fulfillment, belonging, and community**Zimmerman et al.**, "The Benefits of Community-Based Moderation". To make this relationship more sustainable, researchers have proposed solutions like monetary compensation or social recognition, but these are largely based on studies with adults **Katz et al.**, "Community Moderation on Social Media Platforms". We are concerned with the fact that users under the age of 18 may not be eligible for options like payment. Thus, in addition to preventing risks, we also will examine proactive ways to better compensate and support teen moderators.

\subsection{The role of platform governance and moderation on youth social media experiences}
Platform governance and moderation structures can greatly impact users' social media experiences**Davis**, "Youth Online Safety: The Role of Platform Governance". In recent years, researchers have experimented with multi-level governance structures to decentralize platform power and offer more modularity, agency, and control for users at large**Katz et al.**, "Community Moderation on Social Media Platforms". The impact and potential of these structural factors, however, remain highly understudied for youth social media experiences**Landesman et al.**, "Teens' Emotional Experience with Social Media". Davis explored at a conceptual level how community-supported and self-directed experiences can benefit youth and adolescent development**Davis**, "Youth Online Safety: The Role of Platform Governance". Landesman et al. have investigated how teens' moment-by-moment emotional states and mindfulness can influence their experiences on social media**Landesman et al.**, "Teens' Emotional Experience with Social Media". 
Others have examined various features, affordances, and interactions that influence youth social media experiences, but these also generally focus on interactive aspects of more SNS-based platforms like content permanence and quantifiability**Turkle**, "The Second Self".

There is an urgent need and opportunity to more closely examine how governance-related structures, and especially community-driven models, can benefit youth social media experiences. In this work, we seek to answer this question for youth ages 13-17. Schoenbeck et al.'s work on youth online harm resolution in platform-driven moderation demonstrated how top-down structures were incompatible with this age group's preferences for restorative justice**Schoenbeck et al.**, "Youth Online Harm Resolution". Juxtaposing these results with Seering's work on platform-driven versus community-driven moderation**Seering**, "Community-Driven Moderation" reveals an opportunity for the latter to address this age group's need for highly contextual moderation decisions. In this way, the present work is aligned with Tekinbaş et al.'s studies of Minecraft communities, which researched how community-driven moderation influenced children's social experiences, but the participants of this server were significantly younger (ages 8-13) and the server was moderated by research study coordinators**Tekinbaş et al.**, "Minecraft Communities". Self-determination theory and adolescent developmental psychology suggest that high school-aged individuals seek greater autonomy and independence and that adult-led interventions are less effective than peer-led ones**Ryan et al.**, "Self-Determination Theory". Additionally, work by Wiesniewski et al. and Ghosh et al.'s work have shown the benefits of participatory, resilience, and autonomy-based approaches to teen safety **Wiesniewski et al.**, "Participatory Safety in Online Communities" and **Ghosh et al.**, "Autonomy-Based Approaches to Teen Safety". In this work, we hypothesize that empowering teens to moderate their own online communities can be promising for enabling healthier youth social media experiences.