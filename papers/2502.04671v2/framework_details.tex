\newcommand{\HuggingFace}[0]{\textsc{HuggingFace}\xspace}

Now we describe the {\proofwala} framework. Our main motivation for building this new framework is to support theorem-proving research in a \emph{language-agnostic} manner. In particular, we aim to facilitate standardized data collection in different ITPs and provide the necessary infrastructure to train proof step generation models, along with efficient parallel search algorithms for proof synthesis conditioned on theorem specifications. 

Our framework has three components: 
(i) the \textbf{interface module}: for the execution of proof steps (tactics) on various ITPs, (ii) the \textbf{proof step generation \& training module}: for generating proof step data and training proof step generation model, and (iii) the \textbf{parallel proof search module}: for using the guidance from proof step generation model to do end-to-end the proof search. \Cref{fig:proofwala-summary} shows the interaction between our different modules.

% \gd{include pdf as figure}
% \amitayush{Added PDF figure}

\begin{figure*}
    \centering
    \includegraphics[scale=0.25]{img-ProofWala-summary.pdf}
    \caption{The \proofwala\;Framework with the interaction between different modules. Using \proofwala's interaction \& data-collection modules, we collect a multilingual proof dataset from existing formal mathematics repositories in \lean\; and \coq. The resulting dataset is used to train a multilingual proof step prediction model, supported by \proofwala's training module. The multilingual model is used inside \proofwala's search module to conduct proof search.}
    \label{fig:proofwala-summary}
\end{figure*}

\subsection{Interface Module}
\label{sec:interface-module}
First, we detail the interface module, which is responsible for facilitating interaction with the ITPs when executing proof steps. In particular, the interface module supports interaction with \lean\; 4 and \coq\;(multiple versions from 10.0 - 18.0). Our \coq\; implementation is built on top of \texttt{coq\_serapy}\footnote{\href{https://github.com/HazardousPeach/coq\_serapy}{https://github.com/HazardousPeach/coq\_serapy}} \citep{sanchez2020generating}, while our \lean\; 4 implementation is built on top of the \texttt{REPL}\footnote{\href{https://github.com/leanprover-community/repl}{https://github.com/leanprover-community/repl}} library. Notably, neither of these libraries has the capability to do parallel interactions with ITPs. Hence, we created a pooling mechanism that allows us to make multiple instances of the interface module with the same state to execute tactics in parallel (parallelizable across multiple machines on a Ray cluster) for the same theorem. Parallelism is essential for searching for proofs or annotating proofs found at scale. We also fixed some well-known bugs and limitations with these libraries (see \Cref{app:bug-fixes}). Our abstraction can support any future versions of Lean and Coq since we use the language server protocol (LSP) to further abstract out the low-level interaction between our code and the ITP interpreter/compiler.
% \george{@Amitayush, perhaps we can lengthen this statement?}. 

One challenge in creating a unified framework is supporting the variety of state representations across these different ITPs. 
We develop a standard representation consistent with our problem formulation in \Cref{sec:problem-formulation} that is generic enough to cover all supported ITPs.  The collected data is stored as \texttt{json} in the unified format across different ITPs; \Cref{fig:training-data-collection-format} in \Cref{app:training-data} shows the generalized format used for collecting training data.

\subsection{Proof Step Generation and Training Module}
\label{sec:training-module}
 Next, we describe our dataset collection \& training module, which is designed to support the production of the proof step prediction model $p(a | O)$. The first step in training a proof step generation model is to extract (proof state, proof step) pairs from human written proofs in various repositories. We use our \textbf{interface module} (\Cref{sec:interface-module}) to interact with the ITP and collect proof state and proof step (tactic) pair data from all theorems in a given formal proof repository such as \textsc{CompCert}, \textsc{Mathlib}, etc. For a given theorem statement and its corresponding formal proof, we extract the sequence of tactics $\alpha = \langle a_1, a_2, \dots a_n\rangle$ and their corresponding state transitions. Namely, for each theorem in the repository, we extract the sequence of pairs $\pi=\langle (O_0, a_1), \dots, (O_{i-1}, a_i), \dots (O_{n-1}, a_n)\rangle$, such that $O_0 = \{(g_{in}, h_{in})\}$ (extracted from the theorem statement itself), $T(O_i, a_i) = O_{i+1}$, and $T(O_{n-1}, a_n) = \QED$.  Apart from collecting the current state, proof step, and the next state, we also collect information about other lemmas which are referenced in the proof step. \Cref{fig:training-data-collection-format} in \Cref{app:training-data} shows the data extracted for a theorem in \coq\; and \lean\; 4.

\proofwala\; includes functionality for training neural models on the constructed proof datasets. It supports finetuning any pretrained \HuggingFace$\;$model for proof step generation using the data extracted from the formal proof repositories. We support generic yet flexible input formats (prompt formats) for supervised fine-tuning of the language model to predict the next proof steps. The prompt is standardized across languages and different versions of ITP and controls what aspects of the state are used for predicting the next proof step. \Cref{fig:prompt-format} in \Cref{app:training-data} shows the example prompt formats used for training. Our format is inspired by COPRA \citep{thakur2024incontext} but does not use error signals. To allow transfer across different ITPs, we do not provide any information about the domain or ITP assistant that produced the state mentioned in the prompt. As an example, we choose \codeTFive-\base\; \citep{wang2021codet5} as our pretrained model for fine-tuning in our experiments.




\subsection{Parallel Proof Search Module}
\label{sec:searching-module}
The proof search module uses the proof step generation model, trained via the \textbf{proof step generation and training module} (see \Cref{sec:training-module}), to direct the proof search through the sampling of possible next proof steps for a given state. In particular, the purpose of the search module is to generate the sequence of proof steps (tactics) $\alpha = \langle a_1, a_2, \dots a_{n-1}\rangle$ and sequence of proof-states $\omega = \langle O_0, O_1, \dots O_{n} \rangle$ where (i) given a proof state $O$, we draw $N$ samples from the proof step generation model to get a set $\mathbb{A}(O) = \{a_1, \dots, a_k\}$ of possible proof steps, (ii) and for each $i \in [n-1]$ there exists $a_{i+1} \in \mathbb{A}(O_i)$ such that $T(O_i, a_{i+1}) = O_{i+1}$ and (iii) the final state is $\QED$: $T(O_{n-1}, a_n) = O_n = \QED$. 
The proof search module can support any custom tree search algorithm by abstracting the node selection, generation, and expansion logic. We implement beam search and best first search. 

We maintain an annotated proof tree while searching for the sequence of proof step(s), $\alpha$, which completes the proof for a given theorem. A fully annotated proof tree is shown in \Cref{fig:proof-search-annotation} in \Cref{app:proof-trees}, which was generated while performing the beam search for proving a modulo arithmetic problem. We also use these trees to analyze the proofs generated by our models (see \Cref{sec:quantitative-analysis}). We use the negative log-likelihood of the tokens generated by the \proofwala\; models for deciding the node expansion order in our proof search experiments.
% Our framework allows for arbitrary heuristics to guide the proof search;\gd{in general this ``our API supports X'' is not all that relevant for an ICML audience. we should emphasize what was implemented, not what the code conceptually supports. I'm not suggesting an actual writing change here, just saying} our implementation uses the negative log-likelihood of the tokens generated by \proofwala\; model for deciding the node expansion order in our proof search experiments. 

Unlike other frameworks, our proof search module can run a parallel beam search using Ray \citep{moritz2018ray} for a given theorem. For example, frameworks like LeanDojo \citep{yang2023leandojo} for \lean\; 4 searches for proofs sequentially for a given theorem. Parallel search improves our throughput by trying to execute multiple possible proof step(s) (tactics) generated by \proofwala\; models in parallel on the ITP. We achieve this by replicating instances of \textbf{interface module} (see \Cref{sec:interface-module}) into a custom pool of \emph{Ray actors}. The custom pool tracks ITP instances' proof states and uses only those matching the frontier state (states that are being explored during search) to continue exploration, adding instances as needed. The search picks up multiple instances from this pool to execute the possible next proof step generated in parallel, hence avoiding the cost of sequentially running those steps one after another on the same instance of ITP. \Cref{fig:beam-search-code} (in \Cref{app:parallel-proof-search}) describes the pseudocode for parallel beam search as supported by this module. The parallel proof search module allows our framework to scale to proof search for more challenging theorems with better efficiency in a generic way. 

% \newcommand{\Initialize}{\proc{Initialize}}
% \newcommand{\GenerateProofSteps}{\proc{GenerateProofSteps}}
% \newcommand{\ResetEnvs}{\proc{ResetEnvs}}
% \newcommand{\ReclaimEnvs}{\proc{ReclaimEnvs}}
% \newcommand{\UpdateState}{\proc{UpdateState}}
% \newcommand{\WithinTimeout}{\proc{WithinTimeout}}
% \newcommand{\Execute}{\proc{ExecuteParallel}}
% \newcommand{\Timeout}{\mathit{t}}
% \newcommand{\Model}{\mathit{model}}
% \newcommand{\Width}{\mathit{width}}
% \newcommand{\ItpInterface}{\proc{ItpInterface}}
% \newcommand{\ItpInterfacePool}{\proc{ItpInterfacePool}}
% \newcommand{\Pool}{\mathit{pool}}
% \newcommand{\Frontier}{\mathit{frontier}}
% \newcommand{\TimeElapsed}{\proc{TimeElapsed}}
% \newcommand{\ProofTree}{\mathit{proof\_tree}}

% \begin{figure*}
% \footnotesize
% \begin{codebox}
% \Procname{$\proc{ParallelBeamSearch}$($O_0$, $\Model$, $\Timeout$, $\Width$)}
% \li \Comment{Set the pool of $\ItpInterface$ instances to state $O_{0}$} 
% \li $\Pool \gets \ItpInterfacePool.\Initialize(O_{0})$
% \li $\Frontier \gets \{O_{0}\}$
% \li $\ProofTree \gets \phi$
% \li \While $\Frontier \ne \phi$ 
% \li \Do 
%     \li \If $\TimeElapsed(\Timeout)$
%             \li \Comment{Proof not found within the timeout}
%             \li \Then \Return $\proc{False}$, $\ProofTree$
%             \li \Else $\mathbb{O} \gets \phi$ \Comment{To store next possible states}
%                 \li \For $O \in \Frontier$
%                 \li \Do $\mathbb{A} \gets \GenerateProofSteps(O, \Model, \Width)$
%                         \li \Comment{Filter a sub-pool from $\ItpInterface$ instances which are initialized to state $O$}
%                         \li $\Pool' \gets \Pool.\proc{Filter}(O)$ 
%                         \li \If $\Pool'$ is \textbf{empty}
%                             \li \Then $\Pool' \gets \ItpInterfacePool.\Initialize(O)$
%                             \li $\Pool.\proc{Merge}(\Pool')$ \Comment{Merge the new instances to the pool}
%                         \End
%                         \li \Comment{Execute generated possible proof step(s), $\mathbb{A}$, in parallel using the $\Pool'$}
%                         \li $\mathbb{O} \gets \mathbb{O} \land \Pool'.\Execute(\mathbb{A})$
%                         \li \Comment{Add all $\mathbb{A}$ edges in the $\ProofTree$ with $O$ as parent}
%                         \li \If $\QED \in \mathbb{O}$
%                                 \li \Then \Return $\proc{True}$, $\ProofTree$
%                             \End
%                     \End
%                 \li $\Frontier \gets \mathbb{O}$
%                 \li \Comment{Filter the top $\Width$ states based on some heuristic}
%                 \li \Comment{for example log-likelihood of proof step leading to the state.}
%                 \li $\Frontier \gets \Frontier.\proc{TopK}(\Width)$
%         \End
%     \End
% \End
% \li \Return $\proc{False}$, $\ProofTree$
% \end{codebox}
% \caption{\footnotesize{Pseudocode for the parallel proof search module utilizing Beam Search with the Ray framework \citep{moritz2018ray}. This approach enables concurrent exploration of multiple proof steps (tactics) generated by the \proofwala\; model, improving efficiency and throughput. Unlike frameworks such as LeanDojo \citep{yang2023leandojo} for \lean\; 4, which operate sequentially, this module replicates instances of the \textbf{interface module} (see \Cref{sec:interface-module}) as a custom pool of Ray actors. The custom pool keeps track of ITP instances' proof state. It only uses those instances whose proof state matches the frontier state to continue the exploration (with the occasional overhead of adding more instances to the pool).  Each instance in the pool executes potential proof steps in parallel, allowing the search to proceed across various states simultaneously, avoiding the sequential overhead of executing steps one after another on the same ITP instance. \george{Should be in appendix most likely}}} \amit{After discussion on that day with Kaiyu about how he re-implemented the parallel search, I feel we should keep it here unless we have space constraint}
% \label{fig:beam-search-code}
% \end{figure*}





% We use the negative log-likelihood of the tokens generated by the \proofwala\;model for guiding the search. \george{A rewording of this last sentence could be (if true): Our framework allows arbitrary heuristics for guiding for the proof search, as a demonstration we have used the negative log-likelihood of generated tokens in our experiments.}

% \george{I think it should be mentioned somewehre the nature of parallelism and the types of large-scale projects that could be supported with this parallelism. I think this section should also be written in mind of what people could use it for. Even somewhat written to provide suggestions to people for research ideas to use this framework with potentially (I think a similar thing can be done in the conclusion too).}