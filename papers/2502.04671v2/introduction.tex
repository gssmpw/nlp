Automated theorem-proving has long been considered to be a grand challenge in artificial intelligence. Recently, deep learning has emerged as a promising approach to this challenge \citep{li2024surveydeeplearningtheorem,yang2024formalmathematicalreasoningnew}. Broadly, deep-learning methods for theorem-proving use neural models to generate formal proof expressed in the language of an \emph{interactive theorem prover} (ITPs), e.g., \lean\; \citep{de2015lean}, \coq\; \citep{huet1997coq}, or Isabelle \citep{paulson1994isabelle}. An ITP represents proofs as sequences of simplification steps, or \emph{tactics}, and can mechanically check such proofs for correctness. Theorem-proving then amounts to generating a sequence that passes the ITP's checks.
%(\Cref{fig:example} shows a formal {\lean} proof). 
%ITPs provide a variety of simplification strategies, known as \emph{tactics}, which allow users to iteratively transform and simplify the stated theorem. These tactics perform operations such as rewriting equations, applying induction, or using known lemmas, gradually reducing the proof goal until it becomes a trivial statement that can be immediately verified.

Most deep-learning approaches to theorem-proving follow the strategy proposed by \citet{polu2020generative}. Here, one first trains a {generative language model} (LM) that can predict formal proof steps (tactics and their parameters) conditioned on the goal state, from a proof-step dataset extracted from existing formal mathematics repositories. The learned model is then wrapped in a search algorithm which conducts proof search (see \Cref{sec:problem-formulation} for more details). 

While neural approaches to theorem-proving are gaining momentum, the field remains fragmented.
%, focusing on individual ITPs and lacking tools for leveraging multilingual data across domains. 
Existing tools for dataset collection tend to be ITP-specific, often relying on isolated, domain-specific formats; there is also no language-agnostic open platform for neurally guided search over proofs. 
This hinders systematic comparisons and precludes potential cross-lingual and cross-domain improvements from training on multilingual data. 
%The absence of a language-agnostic open platform for end-to-end proof search with efficient, customizable algorithms further limits progress. 
%Such a platform has the potential to unite theorem-proving research, where individual researchers are otherwise isolated in a single interactive theorem-proving community.

% Currently, data collection for each ITP assistant---whether focused on mathematics or software verification---operates in isolation, often requiring domain-specific data formats and incompatible methodologies. Furthermore, the field lacks a language-agnostic open platform that supports end-to-end proof search using customizable and efficient search algorithms, which is crucial for completing the proof while using a proof step generation model to guide the search.
% Given the data-scaling observations for LLMs, it is reasonable to expect that incorporating additional high quality (multi-langauge) data for formal theorem proving tasks should positively augment neural models used for proof step prediction.  
% Presently, there are no tools with interfaces to collect proof datasets, learn generative models, and conduct proof search in a multilingual manner, across multiple ITPs and domains. 
% Moreover, the \textit{absence of a unified framework} for handling the extraction and organization of training data compounds the challenge, restricting the potential of LLMs getting trained for generating proof steps. This could be significantly enhanced if LLMs are trained on prompts generated by standardized formatting of proof state descriptions across various datasets and ITP assistants. 

In response to this problem, we introduce \proofwala\footnote{``Wala'' is a suffix from Indic languages (often spelled “wallah”), meaning ``one who is associated with or provides a particular thing.''}, a multilingual framework for dataset collection, interaction, training, and proof search across interactive theorem provers and domains. \name provides a standardized pipeline for generating proof step training data, facilitating the creation of high-quality multilingual datasets. It enables seamless interaction with formal systems and supports the training of neural architectures tailored for proof step generation. Finally, it integrates efficient search algorithms, including a parallelized version of best-first and beam search, allowing for end-to-end proof discovery guided by transformer-based models. 

We provide a code library combined with multilingual datasets and multilingual fine-tuned models that facilitate end-to-end formal proof search in \lean\; 4 and \coq. Using \proofwala, we demonstrate that training on multilingual data can foster positive cross-lingual and cross-domain transfer, enhancing proof generation across different formal systems.

In summary, our work makes two key contributions:
\begin{enumerate}

\item \textbf{A Standardized Framework:} 
We propose \proofwala, a unified framework for extracting and organizing training data for formal theorem proving in \lean\; and \coq. The framework supports the generation of training data for these ITPs from any formal theorem-proving Git repository (such as Mathlib, CompCert, MathComp, GeoCoq, \& Category Theory) and the subsequent training of LLMs for single proof step generation. Our data collection format is standardized across ITPs, and we have created generic prompt formatting schemes across different ITPs and domains. The framework also helps with end-to-end proof search and collection of the annotated proof trees which can be further used for analysis and visualization (see \Cref{fig:proof-search-annotation} in \Cref{app:proof-trees}). All our code is open source, the \name{} framework can be found \href{https://github.com/trishullab/proof-wala}{\textcolor{blue}{here}}. The code for the multilingual ITP interaction module can be found \href{https://github.com/trishullab/itp-interface}{\textcolor{blue}{here}}.

% \item \textbf{Comprehensive Support for Parallel Poof Completion:} 
% Similar to \citet{polu2020generative}, the framework supports proof completion using a search guided by the proof step generation model. \george{Maybe it's not great to reference stuff being similar to others in contributions list? The idea of proof search is old enough now that it probably doesnt need a citation.} We improve the search by parallelizing it and making it agnostic of the ITP. To the best of our knowledge, ours is the first open-source framework that supports \textbf{parallel proof-search} by adding capabilities to clone proof environments and run tactics in parallel across those proof environments. \george{The parallelization bit I think should be more heavily emphasized}
% \amit{Let me know if this looks better now} \george{I still think you should make stronger claims - exactly how parallel and how at scale can this be used for? I think it would bolster the claim.}
% We further build capabilities to \textbf{store, annotate, and visualize the proof trees generated during the search}. \Cref{fig:proof-search-annotation} in \Cref{app:proof-trees} shows the visualization of the proof-tree generated during the proof search.

\item \textbf{Demonstration of Cross-Lingual and Cross-Domain Transfer:} Facilitated by our \name framework, We investigate the effect of incorporating multilingual proof data in the training pipeline. We demonstrate that \textbf{cross-domain and cross-lingual transfer} occur for both \lean\; and \coq, in both the domains of general mathematics and software verification. These results highlight the potential of training across diverse formal proof assistant repositories as an effective strategy to mitigate data scarcity in this neural theorem-proving research. We release the multi-domain and multi-lingual training data used for training our models, containing about 450K training data points (270M tokens) from about 80k theorems. We also release multiple \name models trained on different data-mixes. Our \proofwala-\multi\; model is the \emph{first open proof step generation model} trained on data from diverse domains and ITPs, which can be seamlessly used for finding proofs in formal mathematics and software verification. 
\end{enumerate}
