 \documentclass{article} % For LaTeX2e

% Optional math commands from https://github.com/goodfeli/dlbook_notation.
\input{math_commands.tex}

\usepackage{microtype}
\usepackage{graphicx}
\usepackage{subfigure}
\usepackage{booktabs} % for professional tables

\usepackage{hyperref}
\usepackage{url}

% Attempt to make hyperref and algorithmic work together better:
\newcommand{\theHalgorithm}{\arabic{algorithm}}

% Use the following line for the initial blind version submitted for review:
% \usepackage{icml2025}

% If accepted, instead use the following line for the camera-ready submission:
\usepackage[accepted]{icml2025}



% to compile a preprint version, e.g., for submission to arXiv, add add the
% [preprint] option:
%     \usepackage[preprint]{neurips_2024}


% to compile a camera-ready version, add the [final] option, e.g.:
%     \usepackage[final]{neurips_2024}


% to avoid loading the natbib package, add option nonatbib:
%    \usepackage[nonatbib]{neurips_2024}


\usepackage[utf8]{inputenc} % allow utf-8 input
\usepackage[LGR, T1]{fontenc}
% \usepackage{lmodern, newunicodechar}
% \usepackage[T1]{fontenc}    % use 8-bit T1 fonts
\usepackage{hyperref}       % hyperlinks
\usepackage{url}            % simple URL typesetting
\usepackage{booktabs}       % professional-quality tables
\usepackage{amsfonts}       % blackboard math symbols
\usepackage{nicefrac}       % compact symbols for 1/2, etc.
\usepackage{microtype}      % microtypography
\usepackage{xcolor}         % colors
\usepackage{makecell}
\usepackage[framemethod=TikZ]{mdframed}
\usepackage{amssymb}% http://ctan.org/pkg/amssymb
\usepackage{pifont}% http://ctan.org/pkg/pifont

% \PassOptionsToPackage{finalizecache,cachedir=.}{minted}
\PassOptionsToPackage{frozencache,cachedir=.}{minted}
%\usepackage[frozencache,cachedir=.]{minted}
%\usepackage[finalize,cachedir=.]{minted}
\usepackage{minted}
\usepackage{wrapfig}
\usepackage{clrscode}
\usepackage{subcaption}
\usepackage{inconsolata}



%\lstset{basicstyle=\footnotesize\ttfamily,language=lean}
\usepackage{color}
\definecolor{keywordcolor}{rgb}{0.7, 0.1, 0.1}   % red
\definecolor{tacticcolor}{rgb}{0.0, 0.1, 0.6}    % blue
\definecolor{commentcolor}{rgb}{0.4, 0.4, 0.4}   % grey
\definecolor{symbolcolor}{rgb}{0.0, 0.1, 0.6}    % blue
\definecolor{sortcolor}{rgb}{0.1, 0.5, 0.1}      % green
\definecolor{attributecolor}{rgb}{0.7, 0.1, 0.1} % red


\usepackage{listings}
\def\lstlanguagefiles{lstlean.tex}
\lstset{language=lean,basicstyle=\footnotesize\ttfamily}


% \theoremstyle{plain}
\newtheorem{theorem}{Theorem}[section]
\newtheorem{proposition}[theorem]{Proposition}
\newtheorem{lemma}[theorem]{Lemma}
\newtheorem{corollary}[theorem]{Corollary}
% \theoremstyle{definition}
\newtheorem{definition}[theorem]{Definition}
\newtheorem{problem}{Problem}
\newtheorem{assumption}[theorem]{Assumption}
% \theoremstyle{remark}
\newtheorem{remark}[theorem]{Remark}

\newcommand{\parag}[1]{\noindent \textbf{#1~}}
\newcommand{\fix}{\marginpar{FIX}}
\newcommand{\new}{\marginpar{NEW}}

\renewcommand{\paragraph}[1]{\noindent \textbf{#1}}

\renewcommand{\dblfloatpagefraction}{0.7}



\DeclareUnicodeCharacter{2223}{$\mid$}
\DeclareUnicodeCharacter{211D}{$\mathbb{R}$}
\DeclareUnicodeCharacter{2081}{$_{1}$}
\DeclareUnicodeCharacter{2082}{$_{2}$}
\DeclareUnicodeCharacter{22A2}{$\vdash$}
\DeclareUnicodeCharacter{2115}{$\mathbb{N}$}
\DeclareUnicodeCharacter{2211}{$\sum$}
\DeclareUnicodeCharacter{2194}{$\leftrightarrow$}
\DeclareUnicodeCharacter{2208}{$\in$}
\DeclareUnicodeCharacter{1D55C}{$\mathbb{k}$}
\DeclareUnicodeCharacter{3B9}{$\iota$}
\DeclareUnicodeCharacter{3C0}{$\pi$}
\DeclareUnicodeCharacter{271D}{$\dagger$}
\DeclareUnicodeCharacter{2075}{$^{5}$}
\DeclareUnicodeCharacter{2074}{$^{4}$}
\DeclareUnicodeCharacter{2073}{$^{3}$}
\DeclareUnicodeCharacter{2072}{$^{2}$}
\DeclareUnicodeCharacter{2071}{$^{1}$}
\DeclareUnicodeCharacter{2200}{$\forall$}
\DeclareUnicodeCharacter{2A0D}{$\int$}
% Following todonotes added by George
\usepackage[textsize=scriptsize]{todonotes}
\usepackage{cleveref}
% \newcommand\gd[1]{\todo[color=red!40]{{\bf Greg}: #1}}
% \newcommand{\george}[1]{\todo[color=blue!40]{{\bf George}: #1}}
% \newcommand{\amitayush}[1]{\todo[color=green!40]{{\bf Amitayush}: #1}}

% \newcommand{\greg}[1]{\textcolor{green}{Greg: #1}}
% \newcommand{\swarat}[1]{\textcolor{brown}{Swarat: #1}}
% \newcommand{\amit}[1]{\textcolor{blue}{\bf{Amit}: #1}}

\newcommand{\proofwala}[0]{\textsc{ProofWala}}
\newcommand{\lean}[0]{\textsc{Lean}}
\newcommand{\multi}[0]{\textsc{Multilingual}}
\newcommand{\coq}[0]{\textsc{Coq}}
\newcommand{\codeTFive}[0]{\textsc{CodeT5}}
\newcommand{\base}[0]{\textsc{Base}}


\title{\name: A Framework for Multilingual Proof Data Synthesis and Theorem-Proving}
%\title{\name: Multilingual Generation of Synthetic Proof }

% The \author macro works with any number of authors. There are two commands
% used to separate the names and addresses of multiple authors: \And and \AND.
%
% Using \And between authors leaves it to LaTeX to determine where to break the
% lines. Using \AND forces a line break at that point. So, if LaTeX puts 3 of 4
% authors names on the first line, and the last on the second line, try using
% \AND instead of \And before the third author name.


\usepackage{xspace}
\newcommand{\name}{\textsc{ProofWala}\xspace}

\begin{document}


\twocolumn[
\icmltitle{\name: Multilingual Proof Data Synthesis and Theorem-Proving}

% It is OKAY to include author information, even for blind
% submissions: the style file will automatically remove it for you
% unless you've provided the [accepted] option to the icml2025
% package.

% List of affiliations: The first argument should be a (short)
% identifier you will use later to specify author affiliations
% Academic affiliations should list Department, University, City, Region, Country
% Industry affiliations should list Company, City, Region, Country

% You can specify symbols, otherwise they are numbered in order.
% Ideally, you should not use this facility. Affiliations will be numbered
% in order of appearance and this is the preferred way.
% \icmlsetsymbol{equal}{*}

\begin{icmlauthorlist}
\icmlauthor{Amitayush Thakur}{ut}
\icmlauthor{George Tsoukalas}{ut}
\icmlauthor{Greg Durrett}{ut}
\icmlauthor{Swarat Chaudhuri}{ut}
\end{icmlauthorlist}

\icmlaffiliation{ut}{Department of Computer Science, University of Texas, Austin, USA}


\icmlcorrespondingauthor{Amitayush Thakur}{amitayush@utexas.edu}
\icmlcorrespondingauthor{George Tsoukalas}{george.tsoukalas@utexas.edu}
\icmlcorrespondingauthor{Greg Durrett}{gdurrett@cs.utexas.edu}
\icmlcorrespondingauthor{Swarat Chaudhuri}{swarat@cs.utexas.edu}

% You may provide any keywords that you
% find helpful for describing your paper; these are used to populate
% the "keywords" metadata in the PDF but will not be shown in the document
\icmlkeywords{Machine Learning, ICML}

\vskip 0.3in
]

% this must go after the closing bracket ] following \twocolumn[ ...

% This command actually creates the footnote in the first column
% listing the affiliations and the copyright notice.
% The command takes one argument, which is text to display at the start of the footnote.
% The \icmlEqualContribution command is standard text for equal contribution.
% Remove it (just {}) if you do not need this facility.

\printAffiliationsAndNotice{}  % leave blank if no need to mention equal contribution
% \printAffiliationsAndNotice{\icmlEqualContribution} % otherwise use the standard text.
\addtocounter{footnote}{+1}
\begin{abstract}
Neural networks have shown substantial promise at automatic theorem-proving in interactive proof assistants (ITPs) like Lean and Coq. However, most neural theorem-proving models are restricted to specific ITPs, leaving out opportunities for cross-lingual \emph{transfer} between ITPs.
We address this weakness with a multilingual proof framework, \name, that allows a standardized form of interaction between neural theorem-provers and two established ITPs (Coq and Lean). It enables the collection of multilingual proof step data---data recording the result of proof actions on ITP states---for training neural provers. \name allows the systematic evaluation of a model's performance across different ITPs and problem domains via efficient parallel proof search algorithms. We show that multilingual training enabled by \name can lead to successful transfer across ITPs. Specifically, a model trained on a mix of \name-generated Coq and Lean data outperforms  Lean-only and Coq-only models on the standard prove-at-$k$ metric. We open source all our code, including code for the  \href{https://github.com/trishullab/proof-wala}{\textcolor{blue}{\name  framework}} and the \href{https://github.com/trishullab/itp-interface}{\textcolor{blue}{Multilingual ITP interaction framework}}.
\end{abstract}




\section{Introduction}
\input{introduction}

\section{Problem Formulation}
\label{sec:problem-formulation}
\input{problem_formulation}

\section{Framework Details}
\input{framework_details}

\section{Dataset and Model Details}
\input{dataset_details}

\section{Evaluation}
\input{evaluation}

\section{Related Work}
\input{related_works}

\section{Conclusion}
\input{conclusion}

\vspace{-0.1in}
\section{Impact Statement}
This paper presents work whose goal is to advance the field of Machine Learning. There are many potential societal consequences of our work, none which we feel must be specifically highlighted here.

\bibliography{references}
\bibliographystyle{icml2025}

\newpage
\appendix
\section{Appendix}
\input{appendix}

\end{document}
\typeout{get arXiv to do 4 passes: Label(s) may have changed. Rerun}