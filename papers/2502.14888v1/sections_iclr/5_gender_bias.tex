\section{Case Studies based on Modality-specific Features}
In this section, we present three case studies based on our three modality features: (1) gender detection (2) adversarial attacks (3) text-to-image generation.

% \begin{figure}[h]
%     \centering 
%     \includegraphics[width=0.3\linewidth]{figures/horse.jpg}
%     \caption{a reference image: horse}
%     \label{fig:ref_image}
% \end{figure}
\begin{figure*}[t]
    \centering
    \includegraphics[width=0.88\linewidth,trim={10 400 0 50},clip]{gender_vis.pdf}
    \caption{\footnotesize \textit{\textbf{Female}} figures ordered by their percentages of \texttt{ImgD} features: 0.14, 0.16, 0.18,0.20, 0.22, 0.24, 0.26. More feminine features are observed with more \texttt{ImgD} features.}
\label{fig:female_diff_imgd}
\end{figure*}
    % \begin{subfigure}{0.12\textwidth}
    %     \centering
    %     \includegraphics[width=\linewidth]{figures/female_0.14_2239_o1.png}
    %     % \caption{14\%}
    % \end{subfigure}
    % \begin{subfigure}{0.12\textwidth}
    %     \centering
    %     \includegraphics[width=1\linewidth,trim={35 0 0 0},clip]{figures/female_0.16_3517_o2.png}
    % \end{subfigure}
    % \begin{subfigure}{0.12\textwidth}
    %     \centering
    %     \includegraphics[width=\linewidth]{figures/female_0.18_9969_o3.png}
    %     % \caption{Caption for Image 2}
    % \end{subfigure}
    % \begin{subfigure}{0.12\textwidth}
    %     \centering
    %     \includegraphics[width=\linewidth]{figures/female_0.2_1513.png}
    %     % \caption{Caption for Image 2}
    % \end{subfigure}
    % \begin{subfigure}{0.12\textwidth}
    %     \centering
    %     \includegraphics[width=\linewidth]{figures/female_0.22_13167_o4.png}
    %     % \caption{Caption for Image 2}
    % \end{subfigure}
    %     \begin{subfigure}{0.12\textwidth}
    %     \centering
    %     \includegraphics[width=\linewidth]{figures/female_0.24_2140_o5.png}
    %     % \caption{Caption for Image 2}
    % \end{subfigure}
    % \begin{subfigure}{0.12\textwidth}
    %     \centering
    %     \includegraphics[width=\linewidth]{figures/female_0.26_6646_o6.png}
    %     % \caption{Caption for Image 2}
    % \end{subfigure}
\subsection{Case Study 1: Gender Pattern in Different Modalities}
We describe gender using visual features, for example, long hair and wearing a dress, and assume that the ImgDom features primarily account for these discriminative visual patterns. Consequently, removing the ImgDom features from a female image may make it  less identifiable in terms of gender, potentially leading to its classification as male in a binary classification task. Similarly, TextDom features play a comparable role when gender is described through textual information. 

To test this hypothesis, we collect both male and female images from the cc3m validation set using a gender classifier~\footnote{\href{https://huggingface.co/touchtech/fashion-images-gender-age-vit-large-patch16-224-in21k-v3}{touchtech/fashion-images-gender-age-vit-large-patch16-224-in21k-v3}}. These images are then encoded using the Clip+SAE model, extracting 1024-dimensional feature representations for both female and male subjects. Next, we apply a zero-mask  intervene strategy to remove the \texttt{ImgDom} and \texttt{TextDom} features from these representations. Notably, our intervention is applied at the feature level, i.e., on activations rather than the raw image or text inputs. Since these modified reature representations cannot be directly processed by existing pretrained classifiers, which require image or text inputs, we employ a zero-shot classification approach inspired by~\citet{bhalla2024interpreting}. Specifically, we use an unsupervised clustering method to measure the distances between the intervened activations and the label embeddings for ``female" and ``male", with the latter obtained by encoding female and male inputs. 

Before analyzing the difference in predominant features between male and female subjects, we first  verify that our identified modality-specific features indeed capture information within their respective  modality. 

\textbf{Modality-specific interventions.} We intervene both \texttt{ImgD} and \texttt{TextD} for image and text inputs, respectively. The probabilities of original image/text and intervened image/text, over the original gender label are in the Table~\ref{tab:gender_case}. 

\begin{table}[h]
\centering
\caption{\footnotesize Probability over the original gender label for different input modality. The results show that after removing the modality dominant features, e.g., \texttt{ImgDom} for the input in the same modality, e.g., image, the original inputs will be affected in a larger extent, i.e., 0.785 compared to 0.828 caused by removing \texttt{TextDom} features.}
% \small
\resizebox{0.48\textwidth}{!}{%
\begin{tabular}{r|cccc}
\toprule[1pt]
    Input Modality & Ori-Acc & w.o. \texttt{ImgD} $\downarrow$ & w.o. \texttt{TextD} $\downarrow$ & w.o. Random $\downarrow$\\
\midrule
   Image& 0.834 &	\textbf{0.785}&	0.828    & 0.815 \\
Text     & 0.709&0.709&\textbf{0.639}&0.699\\
\bottomrule[1pt]
    \end{tabular}
    }
    \label{tab:gender_case}
\end{table}

\textbf{Gender bias in different modalities.} We then show the discrepancy when removing the image and text features to identify the primary modality supporting the gender in this dataset. From the results in Table~\ref{tab:gender_modality}, we observe that female images are more easily affected by the \texttt{ImgD} features, while male texts are more easily affected by the \texttt{TextD} features.
\begin{table}[h]
    \centering
    \caption{\footnotesize Comparison of the effects of removing different modality-feature from the specific gender in the corresponding modality. For \textit{female}, remove the \texttt{ImgD} lead to larger changes to the female visual inputs, than remove the \texttt{TextD} from the female textual inputs, vice versa for male.}
    \resizebox{0.35\textwidth}{!}{% 
    \begin{tabular}{r|cc}
    \toprule[1pt]
        & $\Delta$(Remove ImgD) & $\Delta$(Remove TextD) \\
    \midrule
   Female       & \textbf{17.65}&7.27\\
   Male & 5.64&\textbf{28.67}\\
   \bottomrule[1pt]
    \end{tabular}
    }
    \label{tab:gender_modality}
\end{table}

To vividly show the changes brought by intervene of the \texttt{ImgD} and \texttt{TextD} features on gender, we show the different female images which differ in how many percentage of their most activated features are \texttt{ImgD} features in Figure~\ref{fig:female_diff_imgd}. From left to right, more activated features are \texttt{ImgD} and they tend to contains more detailed feminine concepts, such as backless skirt, hair accessories. 
The middle images show professional female, such as politician and doctor; and the first image shows a pair of leg in sports shoes, with minimal feminine factors, the pink color. 


%%%%below is the results of word cluster of male desriptions, can be moved to appendix%%%%%%
% We then cluster different male descriptions according to the percentage of \texttt{TextD} features among all their top-20 activated features, and we calculate the frequency of the top7 tokens in each cluster shown in Figure~\ref{fig:male_sents_cluster}~\footnote{We remove the gendered personal pronouns, e.g., he, she, woman, man, boy, girl and only focus on how gender-neutral concepts represent the gender.}. With more \texttt{TextD} injection, the textual descriptions become more sports related, such coach, basketball, soccer; while the sentences with less activated \texttt{TextD} have top words, as party, hip, game, smile, home. This trend is consistent with the social stereotype that male are more active in sport activities.
% \begin{figure}[h]
%     \centering
%     % First row
%     \begin{minipage}{0.23\textwidth}
%         \centering
%         \includegraphics[width=\linewidth]{figures/0.1_barchart.pdf}
%         % \caption{Caption for Image 1}
%     \end{minipage}\hspace{0.1cm} % Space between figures
%     \hspace{-3mm}
%     \begin{minipage}{0.23\textwidth}
%         \centering
%         \includegraphics[width=\linewidth]{figures/0.12_barchart.pdf}
%         % \caption{Caption for Image 2}
%     \end{minipage}
%     \vspace{-4mm}
%     % Second row
%     \begin{minipage}{0.23\textwidth}
%         \centering
%         \includegraphics[width=\linewidth]{figures/0.18_barchart.pdf}
%         % \caption{Caption for Image 3}
%     \end{minipage}\hspace{0.1cm} % Space between figures
%        \hspace{-3mm}
%     \begin{minipage}{0.23\textwidth}
%         \centering
%         \includegraphics[width=\linewidth]{figures/024_barchart.pdf}
%         % \caption{Caption for Image 4}
%     \end{minipage}
% % \vspace{-2mm}
% \caption{\footnotesize Top7 words in each male-description clusters, which differ in different percentage of the activated \texttt{TextD}.}
% \label{fig:male_sents_cluster}
% \end{figure}
%%%%below is the results of word cluster of male desriptions, can be moved to appendix%%%%%%5


%%%%%%%%toxicity experiments%%%%%%%%%%%%%%
% \begin{table}[h]
%     \centering
%     \resizebox{0.45\textwidth}{!}{
%     \begin{tabular}{c|cc}
% \toprule
% original & Remove ImgD	& Remove TextD \\
% \midrule
% 0.677&	0.687	&0.452\\
% \bottomrule
%     \end{tabular}
%     }
%     \caption{\footnotesize After removing the \texttt{TextD} features, the original toxic sentences are greatly detoxified, from 0.677 to 0.452. Removal of the \texttt{imgD} instead increase the toxicity.}
%     \label{tab:detoxic}
% \end{table}
%%%%%%%%toxicity experiments%%%%%%%%%%%%%%

% \subsection{Model Editing}
% Another key application of feature intervention is to remove the harmful features. Here, we experiment on the the non-toxic and toxic paired dataset~\citep{lee2024mechanistic}, whose non-toxic data is from wiki-text2 and the toxic sentences are generated by PPLM~\citep{Dathathri2020Plug} conditioned on the toxic attribution. We thus remove the \texttt{TextD} features of the encoded textual features from the toxic sentences. And the label embeddings for unsupervised classification are obtained by both non-toxic and toxic sentences. The results are shown in Table~\ref{tab:detoxic}

