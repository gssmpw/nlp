\vspace{-3mm}
\section{Conclusion}
\vspace{-3mm}
In this study, we explored the monosemanticity of features within the CLIP model to elucidate the commonalities and distinctions across visual and linguistic modalities. 
% By adapting existing interpretability tools into the multi-modal regime, we developed a systematic pipeline to evaluate feature monosemanticity in multi-modal models. Notably, 
We successfully categorized interpretable features according to their predominant modality, which demonstrate close correspondence to human cognitive interpretations. Future work may extend these methodologies to other multi-modal architectures and investigate their implications for cognitive science, ultimately fostering the development of more interpretable and cognitively aligned AI systems.
% These insights affirm that modern interpretability tools can significantly enhance our understanding of multi-modal deep learning models, offering a principled approach to dissecting modality interactions.

