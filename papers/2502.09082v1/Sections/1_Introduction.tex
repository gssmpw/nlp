\begin{figure}[!t]
    \centering
    \includegraphics[width=0.6\linewidth]{Figures/CoSER-front.pdf}
    \caption{
    An example from \method dataset, which provides 
    comprehensive data types 
    such as conversation dialogues and settings, plot summaries, characters' inner thoughts, authentically sourced from renowned books.
    }
    \label{fig:front}
\end{figure}

\section{Introduction}
Recent advances in large language models (LLMs) have facilitated the emergence of anthropomorphic cognition in AI~\citep{kosinski2023theory, shanahan2023role}.
Role-playing language agents (RPLAs), \ie, LLMs that simulate specific personas based on relevant data, have hence been popular~\citep{Park2023GenerativeAgents}.
RPLAs have been adopted to simulate personas of various types, including demographics, characters, or daily individuals~\citep{chen2024from}.
They have inspired extensive applications including character chatbots, agents in video games, and digital clones for humans. 
This paper studies \textbf{RPLAs for established characters}, which represent a crucial yet challenging task beyond the naive portrayal of individual traits or stereotypes. 
Specifically, RPLAs should faithfully align with their characters' complex backgrounds and capture their nuanced personalities.

Towards effective RPLAs, two major challenges persist in:
\textit{1)} \textbf{\textit{Data}}: High-quality datasets are lacking.
Existing datasets are limited to dialogues between two characters, and lack necessary dialogue contexts and knowledge in other forms.
Moreover, many datasets are synthesized by LLMs, compromising authenticity and fidelity to the origins~\citep{wang2023rolellm, lu2024large};
\textit{2)}  \textbf{\textit{Evaluation}}: Current methods fall short in assessing complex character portrayals of LLMs. 
They typically focus on single-turn interactions with pre-defined question sets, and rely on either LLM-based judges or multi-choice questions. 
The former lack nuanced discrimination and suffer from bias issues~\citep{li2024judgesurvey}, while the latter only assess specialized aspects~\citep{xu2024character}.
Overall, there is a lack of authentic character data and appropriate evaluation methods based on such data. 


In this paper, we introduce \method, a collection of authentic character data, along with open state-of-the-art models and evaluation protocol based on such data, for \textbf{Co}ordinating LLM-Based Persona \textbf{S}imulation of \textbf{E}stablished \textbf{R}oles. 
The \method dataset is sourced from narratives and dialogues in 771 renowned books, processed via our LLM-based pipeline. 
\method differs from existing datasets in two fundamental ways:  
\textit{1)} \method extracts authentic, multi-character dialogues from acclaimed literary works, 
in contrast to LLM-synthesized question-answer pairs in previous work. 
Hence, our dataset maintains high source fidelity while exhibiting greater quality and complexity. 
\textit{2)}  \method incorporates comprehensive types of data, as shown in Fig. ~\ref{fig:front}:  
\textit{i)}  Besides character profiles and dialogues, \method encompasses plot summaries, character experiences, and conversation backgrounds, supporting various purposes including prompting, retrieval, model training and evaluation. 
\textit{ii)}  Conversations in \method capture characters' actions and internal thoughts beyond surface-level speech, enabling RPLAs to simulate sophisticated cognitive and behavioral processes of humans, such as \dq{\textit{[I'm nervous, but we have to do this] (Takes a deep breath) Alright, we ...}}. 
We provide a clear comparison between \method and existing datasets in Table ~\ref{tab:dataset_overview}. 


We introduce given-circumstance acting (GCA) for training and evaluating role-playing LLMs, leveraging \method dataset. 
Given a conversation with messages $M$, characters $\mathcal{C}$ and setting $\mathcal{S}$, GCA requires an actor LLM to sequentially portray each character $c\in\mathcal{C}$ to recreate the conversation, as illustrated in Fig. ~\ref{fig:main}.
During training, we train LLMs to portray each character $c$, on their authentic utterances $M_c\subset M$. 
As a result, we develop \method 8B and 70B, built on LLaMA-3.1 models~\citep{dubey2024llama}, which demonstrate true-to-life character portrayal and state-of-the-art performance on multiple RPLA benchmarks. 
For evaluation, GCA involves two steps: multi-agent simulation and penalty-based LLM judging.
Given a test conversation $M$, we:
\textit{1)}  create a multi-agent system to simulate a  conversation $\bar{M}$, where the actor LLM portrays each character $c
\in\mathcal{C}$ in the same setting $\mathcal{S}$; 
\textit{2)}  assess $\bar{M}$ using penalty-based LLM critics, leveraging detailed rubrics and the original conversation $M$.  
GCA evaluation offers three advantages: 
First, it comprehensively reflects actor LLMs' abilities via multi-agent simulation;  
Second, it is based on authentic scenes and groundtruth dialogues. 
Third, it provides expert-curated rubrics to guide LLM critics.






Our contributions are summarized as follows:
\begin{enumerate} 
    \item We introduce the \method dataset and models for RPLA research and applications. Our dataset comprises 29,798 authentic conversations and comprehensive types of data from 771 renowned books. Leveraging this dataset, we develop \method 8B and \method 70B, which are state-of-the-art models for RPLAs. 
    \item We propose given-circumstance acting for training and evaluating role-playing LLMs, drawing from established acting theory. Our evaluation comprehensively tests actor LLMs via multi-character simulation, while providing original dialogues and detailed rubrics to enhance LLM-based assessment. 
    \item Results of extensive experiments demonstrate the significant value of our dataset for the training, retrieval and evaluation of RPLAs. Notably, the \method models achieve state-of-the-art performance across four benchmarks for RPLAs. 
\end{enumerate}
