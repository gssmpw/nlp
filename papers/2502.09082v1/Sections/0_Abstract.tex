Role-playing language agents (RPLAs) have emerged as promising applications of large language models (LLMs).
However, simulating established characters presents a challenging task for RPLAs, due to the lack of authentic character datasets and nuanced evaluation methods using such data. 
In this paper, we present \method, a collection of a high-quality dataset, open models, and an evaluation protocol towards effective RPLAs of established characters.  
The \method dataset covers 17,966 characters from 771 renowned books.
It provides authentic dialogues with real-world intricacies, as well as diverse data types such as conversation setups, character experiences and internal thoughts. 
Drawing from acting methodology, we introduce given-circumstance acting for training and evaluating role-playing LLMs, where LLMs sequentially portray multiple characters in book scenes.  
Using our dataset, we develop \method 8B and \method 70B, \ie, advanced open role-playing LLMs built on LLaMA-3.1 models.  
Extensive experiments demonstrate the value of the \method dataset for RPLA training, evaluation and retrieval. 
Moreover, \method 70B exhibits state-of-the-art performance surpassing or matching GPT-4o on our evaluation and three existing benchmarks, \ie, 
achieving 75.80\% and 93.47\% accuracy on the InCharacter and LifeChoice benchmarks respectively. 
Our code, dataset and models are available at \href{https://github.com/Neph0s/CoSER}{https://github.com/Neph0s/CoSER}.
