\section{Methodology}\label{sec:methodology}

This section outlines how we designed the study and collected data to address our research objective.

\subsection{Choosing the methodology}\label{sec:choosing_method}
Examining the aforementioned empirical studies, it is clear that there is no consensus or established guidelines on how to evaluate the acceptability of a threat modeling method such as ADTs, but several key dimensions and methods can be identified. \emph{Comprehensibility} is important when users are presented with some security-relevant information (e.g., privacy policy or a warning)~\cite{wu_what_2020,chen2023investigating}, and it has been a point of attention in empirical studies of security methods~\cite{hogganvik_risk_2005,lallieEmpiricalEvaluationEffectiveness2017}. Moreover, studies examining attack trees and other security risk assessment and threat modeling methods have looked at \emph{effectiveness} in eliciting threats/requirements~\cite{opdahlExperimentalComparisonAttack2009,tuma2018two,labunets2017model}, and \emph{acceptability} for the intended users~\cite{tondel2019understanding,broccia_assessing_2024,broccia2025evaluating}. Note that these objectives are not independent, for example, the comprehensibility of models (how well can users interpret them) produced can be considered as a part of the method's effectiveness~\cite{abrahao2011evaluating,labunets2017model,kattaComparingTwoTechniques2010}, while the effectiveness can be assessed as a component of its acceptability~\cite{broccia_assessing_2024,labunetsFirstEmpiricalEvaluation2014a,stevens2018battle,broccia2025evaluating}.

Two prominent frameworks have been used in the literature to assess the acceptability of a method by its intended users: the Technology Acceptance Model (TAM)~\cite{davisPerceivedUsefulnessPerceived1989} and the Method Evaluation Model (MEM)~\cite{moodyMethodEvaluationModel2003}. TAM focuses on the perceptions of the intended users and it prescribes to measure \emph{perceived usefulness} (\textbf{PU}), \emph{perceived ease of use} (\textbf{PEOU}), and the \emph{intention to use} (\textbf{ITU})~\cite{davisPerceivedUsefulnessPerceived1989}. MEM, depicted schematically Figure~\ref{fig:mem}, extends TAM with components related to actual usage: in addition to the TAM constructs, it recommends measuring \emph{actual effectiveness} (\textbf{AE}), \emph{actual efficiency}  -- and, combined, these constructs will translate into \emph{actual usage}~\cite{moodyMethodEvaluationModel2003}. These two frameworks have been used for evaluating tools and methods in a variety of fields, including cybersecurity. Among the previously mentioned studies, TAM has been applied in, for example, \cite{tondel2019understanding,opdahlExperimentalComparisonAttack2009,karpatiComparingAttackTrees2014,kattaComparingTwoTechniques2010,bernsmed2022adopting}, while MEM was used in~\cite{labunetsFirstEmpiricalEvaluation2014a,labunetsSecurityRiskAssessment,stevens2018battle,broccia_assessing_2024,broccia2025evaluating}. We wish to evaluate the suitability of ADTs as a threat modeling method through the lens of technical background, examining if performance and perceptions change based on the extent of the technical background of users. Since MEM examines perceptions as they relate to actual usage, we believe this framework is a suitable basis for our study design. 

 
Moreover, threat modeling is a creative activity: teams frequently engage in brainstorming~\cite{brunner2020risk} and free-flowing creative thought needs to be facilitated~\cite{thompson2024there}.
Therefore, it is important to examine to what extent threat modeling stakeholders with a very limited technical background might be disadvantaged if they use ADTs for creatively expressing their ideas of relevant attacks. Therefore, to the MEM constructs \textbf{AU}, \textbf{PU} \& \textbf{PEOU}, and \textbf{ITU} (which correspond, respectively, to our \RQ{1}, \RQ{2}, and \RQ{3}) we add another dimension captured by our \RQ{4}. 

We detail how we use the MEM constructs and \RQ{4} in our study context in the remainder of this section.

\subsection{Study design}
\label{ssec:methodology-study-design}


\begin{figure}
\resizebox*{\columnwidth}{!}{\input{content/snippets/MEM_hypotheses}}
\caption{The Method Evaluation Model (MEM)~\cite{moodyMethodEvaluationModel2003} with our study hypotheses placed in context.}
\label{fig:mem}
\end{figure}


From the research questions \RQ{1}--\RQ{3} derived from the MEM components and our additional \textbf{RQ4} that examines differences in creative usage of ADTs depending on the background, we developed a \textbf{series of hypotheses} to specifically test the aspects of MEM and the creative usage component with the added context of technical background. The hypotheses are presented in Table~\ref{tab:hypotheses}. Figure~\ref{fig:mem} also shows the hypotheses positioned in their relevant MEM component. We have two hypotheses for each aspect we measure: a null hypothesis where we expect no difference between the two groups of participants, and an alternative hypothesis where we expect a difference. We start by testing for a difference as the previous study by Lallie~\etal~\cite{lallieEmpiricalEvaluationEffectiveness2017} observed an influence of technical background on successfully using attack trees.

We measure the actual effectiveness (\textbf{AE}) of ADTs by looking at how well the participants can understand the provided ADT models (\hypothesis{\hypoCheckUnderstand}), how effectively can they design ADTs (\hypothesis{\hypoSecondADT})
% -- for a provided detailed scenario (\hypothesis{\hypoSecondADTsub}) and for a self-selected scenario (\hypothesis{\hypoThirdADTsub}) -- 
, and how many errors they make when designing these ADTs (\hypothesis{\hypoErrorAmount}). We evaluate perceived usefulness (\textbf{PU}) by asking the participants to evaluate on the Likert scale how useful do they find ADTs, separately as a means of threat analysis (\hypothesis{\hypoAnalysisTool}) as well as a means of communication (\hypothesis{\hypoCommunicationTool}), as we want to see whether our participants would demonstrate different preferences depending on the background. We measure perceived ease of use (\textbf{PEOU}) by asking the participants to report on the Likert scale whether they find the provided ADT easy to understand (\hypothesis{\hypoSelfUnderstand}) and if they find it easier to understand a given ADT compared to a textual description (\hypothesis{\hypoWrittenComparison}). Intention to use (\textbf{ITU}) is measured by asking the participants whether they would like to use ADTs in the future, on the Likert scale (\hypothesis{\hypoIntentionToUse}). 

Finally, we studied the creative aspects of designing ADTs by examining how effectively the participants can design ADTs for the self-selected scenario (\hypothesis{\hypoThirdADTsub}) and by measuring, qualitatively and quantitatively, the differences in the ADT models designed for the self-selected scenario (\hypothesis{\hypoThirdADT}).  Specific questions used to measure these aspects are listed in Table~\ref{tab:hypotheses} (text of the referenced questions is available in Appendices~\ref{sec:small-study-q}~and~\ref{sec:large-study-q}.). We provide more details about the measurements done per each hypothesis in the next section (Sec.~\ref{sec:results}). 

Note that we do not measure the actual efficiency of using ADTs separately, because of the study constraints: it was given as a part of a homework assignment where participants worked at their own pace and according to their own schedule. However, we believe we are still able to evaluate ADTs within the scope of the MEM without assessing actual efficiency separately, as the ability of participants to \emph{understand} ADTs by correctly interpreting existing models and creating new ones after a short training translates into both effectiveness and efficiency (see Broccia~\etal~\cite{broccia_assessing_2024}).


\input{content/snippets/hypothesis_table}  

\textbf{Protocol design.}
In the context of this work, we consider the technical background to be a background in computer science-related subjects. Our study was designed to measure how the difference in background affects the measured components.  Thus, we used a between-subjects design with two groups of students: one group with a strong computer science background, and another group with a very limited computer science background. Details about our participants are given further in Section~\ref{ssec:methodology-participants}. \revised{As common in such studies~\cite{labunetsSecurityRiskAssessment,lallieEmpiricalEvaluationEffectiveness2017,broccia_assessing_2024}, our participants first received training on the studied method (ADTs).}\ Both groups received the same lecture on ADTs given by the first author of this study, and afterward they participated in two identical study components: \emph{a small study}, which was an automatically assessed online quiz, and \emph{a large study} that involved a graded homework assignment. 

The two researchers involved in the study have several years of experience in teaching ADTs to diverse audiences (university students in Bachelor and Master programs, with and without a computer science background). This experience was instrumental in identifying the right questions and tasks for measuring the different components of interest. The study questionnaires were not pre-tested with the target student population as this was part of graded coursework and students who had seen the questions would have an unfair advantage; instead, the questionnaires were developed by taking advantage of the researchers' experience in teaching ADTs. The ethical considerations of our study are discussed in detail in Section~\ref{sec:ethics}.






\subsection{Study components}\label{sec:studycomponents}

\textbf{Small study.}
The small study contained 19 questions with each section starting with an image of an ADT with content and Likert questions for each ADT; each ADT was increasingly complex. This study focused on what information was received by looking at ADTs that were already created. All ADTs included in this assignment were taken from existing studies about ADTs~\cite{buldasAttributeEvaluationAttack2020,mauwRFIDCommunicationBlock,sunCyberAttackRisksAnalysis2018,kordyAttackdefenseTrees2014}. We selected such ADTs from the literature that a technical background would not be necessary to understand the attack scenario (i.e., without any specialist terms used for labels). All the questions and Likert statements can be found in Appendix~\ref{sec:small-study-q}.


Students did not receive a grade for completing the small study, but they were able to see the correct answers to the questions for self-evaluation immediately after completing the quiz. They were encouraged to do the quiz for their own learning, to ensure they understand ADTs as a concept, and as preparation for the larger homework assignment on ADTs and the final exam where ADTs were among the test questions.

This assignment focused on checking whether students are able to read ADTs and interpret them in the context of the studied theory (\revised{comprehension of the models}), as this was not a direct goal of the large study; although, \revised{as mentioned in Sec.~\ref{sec:choosing_method}, being able to interpret models correctly is necessary for the overall effectiveness of the method}. Further, an important purpose of the small study was to establish if the provided training was adequate. 


\textbf{Large study.}
The large study was implemented as a take-home assignment, and students had four weeks to complete it at their own pace. This assignment was graded, contributing to the final course grade. Students were required to submit the assignment for the coursework, but they had to explicitly opt-in for participating in the study. We further discuss the ethical considerations of our study in Section~\ref{sec:ethics}.

This study consisted of three parts, with students creating attack trees in each part, under different conditions (from a set of components, from a given textual description, and for a self-selected scenario). Here, we aim to assess the more creative aspects of producing ADTs, which is the major motivation behind \RQ{4}. To our knowledge, this is also unique among TM studies, as to the best of our knowledge, nobody has yet examined creative aspects of threat model design. The list of questions from this study is available in Appendix~\ref{sec:large-study-q}.



\subsection{Data analysis}
\label{ssec:data-analysis}

Ultimately, since we start from the results by Lallie~\etal~\cite{lallieEmpiricalEvaluationEffectiveness2017}, we wish to find if there is a statistically significant difference between two independent treatment groups (those with a technical background and those with a very limited technical background). Much of our data is gathered through Likert questions, which result in ordinal data that cannot be normally distributed~\cite{verhulst2021best}, and for the remaining continuous data, we used the Shapiro-Wilk test to find that this data is not normally distributed~\cite{hanusz2016shapiro}. Our data also does not have equal variance according to Levene's test~\cite{levene1960robust}. Thus, we opt for the non-parametric Brunner-Munzel (BM) test~\cite{brunner2000nonparametric} that is robust in the unequal variance case~\cite{karch2021psychologists,fagerland2009wilcoxon}. As suggested by Labunets~\cite{labunets_no_2018}, when we do not find a statistically significant difference according to the BM test, we use the non-parametric Two One-Sided $t$-tests (TOST) to check for equivalence~\cite{schuirmann1981hypothesis}.

We correct for multiple tests using the Holm-Bonferroni (HB) correction method~\cite{holm1979simple} and adopt a significance threshold of $\alpha$=0.05, as is common practice in similar studies~\cite{labunets_no_2018,broccia_assessing_2024}.  In the remainder, we report the corrected $p$ values (denoted for short as $p * m$).  


\subsection{Participants}
\label{ssec:methodology-participants}

\begin{figure}[t]
\includegraphics[width=\linewidth]{img/Acceptability_1_Venn_Diagram_ALT.png}
    \caption{Distribution of participants across the treatment groups and studies.}
    \label{fig:participant-distribution}
\end{figure}



Participants in our study were undergraduate students at Leiden University (The Netherlands). The \ICS\ (\revised{Limited Technical}) students were predominately 3rd (final) year Bachelor students completing majors related to law, governance, and policy studies. The \ICS\ students were all a part of a minor focused on cyber security and governance. The \SEC\ (\revised{Highly Technical}) students were predominately 2nd year Bachelor students within the Computer Science Department.  Both groups of students were taking a major-appropriate Introduction to Cyber Security course, within which we ran our study. 

We consider that the \ICS\ students have a \revised{very limited technical}\ background and the \SEC\ students have a highly technical (computer science) background. This was confirmed with an optional demographic question asking participants how much programming experience they had. The \ICS\ participants had an average of 2.5 months of programming experience, which was the result of the \ICS\ students simultaneously taking a basic Python programming course (a component of the aforementioned minor)\footnote{\revised{This course is designed for students with zero programming experience. By the end of the course, students are expected to be able to write small (less than 30 lines) Python scripts that may integrate self-defined or imported functions and use objects.}}; in contrast, the \SEC\ students had an average of 3 years of programming experience. Additionally, according to their curriculum description, the \SEC\ students had two years of dedicated study in computer science, including courses on computer architecture, databases, linear algebra, algorithms, etc. These courses are not taken by the \ICS\ students. 


Figure~\ref{fig:participant-distribution} provides the participant distribution between treatment groups in each experiment. There were a total of 49 \ICS\ (out of 98 taking the course) and 53 \SEC\ (out of 196 taking the course\footnote{In this group, it was possible to choose another assignment instead of ADTs, and 104 out of 196 students submitted the ADT assignment.}) consenting participants across the two studies. \revised{As the study was done in the educational context, we consider all submitted answers valid, even if part(s) of the questions were not answered. We reviewed all submissions and did not find evidence of invalid answers (e.g., participants who submitted intentionally wrong answers or answered randomly).}\ Table~\ref{tab:grades} shows a comparison of the final course grades (composed, in addition to the large study assignment, of an exam and several other assignment grades) of students in both treatment groups demonstrating that these groups are comparable to each other. While the grade analysis implies that stronger students self-selected to participate in the study, especially the optional small study, we can conclude that this is not different per students' background and study program.



\begin{table}
\caption{Comparison of the final course grades (out of 10) for participants and non-participants. \texttt{SS} stands for small study.}
\label{tab:grades}
\resizebox{\linewidth}{!}{
\begin{tabular}{lcccccccc}
\toprule
Type    & \multicolumn{2}{c}{Participant} & \multicolumn{2}{c}{Non-participant} & \multicolumn{2}{c}{BM Test} & TOST       & Effect Size                                     \\
& $n$   & mean grade     & $n$      & mean grade & statistic           & $p*m$        & $p*m$        & Cohen's $d$  \\
\midrule
\ICS\ (all) & 49 & 7.58 & 48 & 6.90 & -2.05 & 1.0 & \revised{1.0}& 0.70   \\
\SEC\ (all) & 53 & 7.52 & 48 & 6.39 & \revised{-2.12} & \revised{1.0} & \revised{0.79} & \revised{0.30}   \\
\midrule
\ICS\ (SS) & 35 & 7.64 & 63 & 7.23 & \revised{-1.678} & 1.0 & \revised{1.0} & 0.41  \\
\SEC\ (SS) & 29 & 7.54 & 72 & 6.68 & \revised{-1.193} & 1.0 & 1.0 & \revised{0.36}   \\
\midrule
\ICS & 49 & 7.58 &  &  & \multirow{ 2}{*}{\revised{1.384}} & \multirow{ 2}{*}{1.0} & \multirow{ 2}{*}{\revised{\textbf{0.037}}} & \multirow{ 2}{*}{\revised{0.11}}   \\
\SEC & 53 & 7.52  &  &   \\
\bottomrule
\end{tabular}
}
\end{table}


% As described in sections~\ref{ssec:ss}~and~\ref{ssec:ls}, there were two independent components of this study. A smaller quiz (small study) that was ungraded and optional, and a larger assignment (large study) that was graded and a component of coursework (though as described in section~\ref{ssec:ethics} participation in this study was optional). ICS had a total of 97 registered students, of which 60 completed the graded assignment (large study) with 42 agreeing to participate in the study. Additionally, 38 completed the ungraded quiz (small study) with 35 agreeing to participate in the study. 28 participants completed and agreed to participate in both the small study and the large study. In SEC, there were a total of 197 students of which 105 completing the graded assignment with 48 granting consent to be included in the study. 33 completed the ungraded quiz with 28 granting consent. A total of 23 participated in both the large and small studies.

% There were two independent components of this study. A smaller quiz (small study) that was ungraded and optional, and a larger assignment (large study) that was graded and a component of coursework (though as described in section~\ref{ssec:ethics}, participation in this study was optional). For \ICS\ students, we had a total of 35 participants in the small study, 42 participants in the large study, with 28 of these participants in both studies. For \SEC\ students, we had a total of 28 participants in small study, 48 participants in the large study with 23 of these participants in both studies. As the two studies were separate assignments, they had separate consent forms. Some students only provided consent for one of these assignments, accounting for the difference in the number of participants between the two studies.

%ICS numbers: 97 registered students, 38/small, 60/big (total) 35/small, 42/big, 28/both (participant) 
%SEC numbers: 197 registered students, 33/small, 105/big (total), 28/small, 48/big, 23/both (participant)


\subsection{Training}
\label{ssec:training}

\revised{As we mentioned, most of the empirical studies into the acceptability of security modeling methods provide training on the method as part of the study (see, e.g., \cite[Table\ 2.4]{labunetsSecurityRiskAssessment}, or previous studies of attack trees~\cite{lallieEmpiricalEvaluationEffectiveness2017,broccia_assessing_2024,broccia2025evaluating}.)}\ As our training, we gave a \revised{90 min.}\ lecture on threat modeling more broadly and ADTs in particular to both groups of students. The lecture covered an overview of threat modeling and a detailed introduction to ADTs with several examples. It also included an interactive component where students created their own ADTs, which were presented to the class as a whole with any issues or improvements discussed. A short description of the lecture and the slides are available in the provided data artifact~\cite{zenodo-dataset}. To ensure that both groups of students received a similar level of training, the slide deck and the lecturer were the same for both groups. 

The lecture to the \ICS\ students was given in October 2022, and the lecture to the \SEC\ students was given in February 2023. Both lectures were given in person without streaming or a recording being made. Attendance was encouraged but not required in both courses. There was an optional demographic question before the large study, which was answered by 29 participants in each treatment group (59\% of \ICS\ and 54\% of \SEC). Of these, 26 participants in each group indicated they attended the training lecture. The percentage range of training attendance for \ICS\ is 53\% - 93\% and the range for \SEC\ is 49\% - 87\%. Students had access to the detailed lecture slides while working on the study components at home. 
