\section{Limitations}\label{sec:limitations}
Our study has several limitations that we acknowledge in this section. 

\textbf{Study design.}
One of the most significant limitations of our research was the lack of standardization of testing. Unlike Opdahl and Sindre~\cite{opdahlExperimentalComparisonAttack2009}, where students completed assignments in a testing facility, our study consisted of students completing assignments at home with a month to complete the tasks. As such, we cannot exclude external factors from having an effect, and we could not measure data related to actual efficiency in the MEM. However, given that both populations of students were given the same conditions (training, access to resources, and time), we believe that our study design is sufficient to examine the possible effects of technical background on ADT acceptability. Additionally, this is in line with other threat model evaluation studies, such as~\cite{lallieEmpiricalEvaluationEffectiveness2017,broccia_assessing_2024}. 

As an established practice in this type of study (see Section~\ref{ssec:training}, we provided training on the method to our participants. It might be the case that the training eclipsed any innate differences between the groups. However, if this is the case, it would suggest that relatively short training is a viable means to ensure that ADTs are accessible to stakeholders with varying technical backgrounds. 


Attack trees are amenable to represent physical, cyber-physical, and purely cyber scenarios~\cite{shevchenko2018threat}. The first attack tree outlined by Schneier in~\cite[Fig. 1]{schneierAttackTrees1999} represents a physical attack to open up a safe, while an attack tree from Mauw and Oostdijk captures a free lunch scenario~\cite[Fig. 1]{mauwFoundationsAttackTrees2006}.  We aim to evaluate the acceptability of ADTs outside of a domain-specific context (cyber) and our ADTs were constructed in such a way that domain knowledge is not necessary to understand them. As mentioned previously, it is recommended in the TM literature to be considerate of the used terminology to improve conveyance~\cite{ingalsbe2008threat}. However, in practice, some modeled attacks can be highly complex and require advanced security expertise. We welcome future studies that will measure the effect of the technical terms used in ADT models on the acceptability of the method for users with varying technical backgrounds.


\textbf{Participants.}
Our sample size of 102 participants in total is quite substantial and consistent with the sample sizes of similar studies evaluating threat models, which have 87~\cite{karpatiInvestigatingSecurityThreats2015}, 63~\cite{lallieEmpiricalEvaluationEffectiveness2017,opdahlExperimentalComparisonAttack2009}, 49~\cite{broccia2025evaluating}, 42~\cite{kattaComparingTwoTechniques2010}, 28~\cite{labunetsExperimentalComparisonTwo2013}, and 25~\cite{broccia_assessing_2024} participants. Still, our sample might be biased, as the participants come from the same university and the majority of them have the same country of origin. 

Another limitation of the sample is that students may not be representative of industry practitioners as a whole. Using students as study participants for threat model evaluation is standard practice with such studies~\cite{lallieEmpiricalEvaluationEffectiveness2017,labunetsExperimentalComparisonTwo2013,opdahlExperimentalComparisonAttack2009,karpatiInvestigatingSecurityThreats2015,kattaComparingTwoTechniques2010,scandariato2015descriptive}. A study by Karpati~\etal\ consisting of interviews with industry practitioners was able to confirm the results found in a previous study using student participants~\cite{karpatiComparingAttackTrees2014}, which lends itself to the idea that generally student participants can speak to the acceptability of threat models. These results were reinforced by, for example, Naiakshina~\etal~\cite{naiakshinaConductingSecurityDeveloper2020}, Salman~\etal~\cite{salmanAreStudentsRepresentatives2015}, Svahnberg~\etal~\cite{svahnbergUsingStudentsSubjects2008} and Yakdan~\etal~\cite{yakdanHelpingJohnnyAnalyze2016} who found that within the cyber security and software engineering contexts, treatment effects on computer science students hold for professionals. Based on these results, we believe that our sample of students is reflective of practitioners. 

It might be that our participants self-selected for cybersecurity-related studies, and thus, they might be more geared toward cybersecurity than the general population. This would make them more representative of a cybersecurity practitioner (who is also geared towards security) than the general population. Threat modelers will likely receive hands-on experience and training on security-related topics, and some of them might be interested in security, but not all participants in threat modeling are necessarily geared towards security~\cite{verreydt2024threat,shostack2008experiences}. Future studies should aim to examine this link with personal preferences. 

A component of our study (the large study) was graded. This might have biased the students's answers, especially regarding their perceptions, if they wanted to please the graders. We tried to mitigate this by repeatedly informing the participants that perception questions were not evaluated as a component of their grades. Additionally, our core interest is in finding differences between the two groups. If one group perceived ADTs substantially differently than the other group, we would likely still see the effect in the data. We note that some participants did report low perceptions of ADTs, and both groups did this at relatively similar rates.  

 Finally, as participation in our study was voluntary, it is possible that our students self-selected, and only students who had a high level of understanding of ADTs elected to participate in the study. 
 This is confirmed by the grade difference between the participants and non-participants as shown in Table~\ref{tab:grades}. However, we can see that the final grades between the two treatment groups are equivalent. This implies that stronger students were self-selecting in similar proportions in both cohorts, and thus there was no difference between the two groups. 
  We welcome future studies with more diverse population samples, preferably from industry practitioners that will independently examine the effect of technical (computer science) background on attack tree acceptability, especially for participants without technical background.



\section{Conclusions}\label{sec:conclusions}


ADTs are a valuable threat modeling method, recognized for its accessibility~\cite{shevchenko2018threat,reversinglabs2024attacktrees}.
We investigated whether ADTs are acceptable for users with a very limited technical background using MEM~\cite{moodyMethodEvaluationModel2003}. Overall, we find sufficient evidence to support that ADTs are equally highly acceptable for users with a very limited technical background and users with a substantial technical background. Moreover, attack trees designed by these two types of users show similar patterns in terms of the size of the trees, types of attacks modeled, and quality of the trees. We conclude that ADTs are suitable as a threat modeling method for diverse groups of stakeholders.
Further studies should look into measuring the exact effects of the technical terms on attack tree acceptability, making such models more accessible to practitioners without a technical background, and assessing different training regimens.



\subsection*{Acknowledgements}
We thank Kate Labunets, the anonymous reviewers, and our shepherd for their helpful feedback on this paper. 

This research has been partially supported by the Dutch Research Council (NWO) under the project ``Cyber Security by Integrated Design (\mbox{C-SIDe})'' (NWA.1215.18.008).

