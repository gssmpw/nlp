\section{Evaluation}
\label{evaluation}

\subsection{Simulated Evaluation of Multimodal Reference}
\label{sec:simulatedEvaluation}
To quantitatively evaluate how multimodal reference can help our human-in-the-loop optimization, we designed a simulation test to compare two linear subspace initialization methods: using multimodal reference and random fonts.
\subsubsection{Procedure}
We illustrate the procedure of the simulation test in \autoref{fig:multimodalInputIniitalizationEvaluation}. 
Given a base font character (\eg~``A''), the goal of the simulation test is to resemble the target font character (\autoref{fig:multimodalInputIniitalizationEvaluation}(d)) by exploring the style latent space through optimization.
Specifically, we simulate user selections using the following process. 
At each iteration, our method selects a point in the slider's search subspace with the minimum perceptual metric (we use \textit{DreamSim}~\cite{fu2023dreamsim}) against the target font character.
Then, the selected point is used to request Bayesian optimization to recommend the next linear subspace.
We iterate this process to observe the convergence of the optimization progress using both initialization methods.

For initializing using multimodal reference, we test \textit{text input} and \textit{font file input} in this experiment.
For the text input, we create a descriptive text that characterizes the target font and use it to initialize the search subspace.
For font file input, we manually select a font from candidate fonts that closely resembles the target font and use it to initialize the search subspace.
Finally, for the baseline method, we choose a font randomly from our font database and use it to construct the initial search subspace.

\begin{figure}[ht]
    \centering
    \includegraphics[width=\linewidth]{figures_pdf/synthetic_eval_v7.pdf}
    \caption{
    \textbf{Evaluation of linear subspace initialization methods.}
    We compared two initialization methods for exploration with Bayesian optimization.
    (a) One method uses input text or a similar font file for initialization, while (b) the other initialize method uses a randomly sampled font from a font database.
    After initialization, both methods follow the same automatic exploration process (c), where the optimal point on the single linear subspace is repeatedly identified and submitted to the system.
    In each iteration, we measure the distance between the generated character and the target font character to identify the optimal point, as shown in (d).
    Note that we use the bitmap format of the character for distance calculation, without vectorizing it.
    }
    \label{fig:multimodalInputIniitalizationEvaluation}
\end{figure}
We conducted this experiment using the character ``A'' for $10$ different target fonts, randomly selected from our font database.
We collected $12$ kinds of fonts from which we chose a similar font to each target font for the font file input.
For each target font, we choose the most similar font out of the $12$ candidate fonts.
The $12$ candidate fonts consist of two popular font families, \textit{Roboto} and \textit{NotoSerif}, and each font family has six variations: \textit{Light}, \textit{Light Italic}, \textit{Regular}, \textit{Regular Italic}, \textit{Bold}, and \textit{Bold Italic}.
This selection simulated a scenario where users start with popular fonts and design new fonts based on one of these similar candidates.
For each target font, the optimization process includes $10$ iterations of Bayesian optimization.

\subsubsection{Results}
In \autoref{fig:multimodalInputIniitalizationEvaluationResult}, we show the mean and standard deviation of the distances between the optimized results and all target fonts.
We can observe that the optimization processes with text and font file references converge to a lower \textit{DreamSim} distance to the target font character compared to those initialized with a randomly selected font.
These results indicate that using multimodal references for initializing the human-in-the-loop optimization leads to more effective exploration than random initialization.


\begin{figure}[ht]
    \centering
    \includegraphics[width=0.5\textwidth]{figures_pdf/multimodalInitialixationEvaluationResult_v4.pdf}
    \caption{
    \textbf{Convergence comparison between two initialization methods.}
    The figure illustrates how the \textit{DreamSim} distance between the designed font character and the target font character converges during exploration with human-in-the-loop optimization.
    The optimization processes initialized by text font references (orange) obtain better results compared to processes initialized by random font (blue).
    }
    \label{fig:multimodalInputIniitalizationEvaluationResult}
\end{figure}


\subsection{User Study}
\label{sec:user-study}
To evaluate the effectiveness of our proposed system, we conducted a user study in which participants were asked to design fonts using both a baseline system and our system. 
The goals of this study were threefold: 
\begin{itemize}
    \item to assess the overall effectiveness of our system, including the integration of Bayesian optimization, multimodal reference, history interface, and style propagation.
    \item to compare the fonts designed by participants both qualitatively and quantitatively against those created using the baseline system.
    \item to gather qualitative feedback on the user experience with our system.
\end{itemize}

\subsubsection{Comparison Systems}
For the user study, we added a special feature called \textsc{Font Palette} to our proposed system.
By clicking the \textsc{Font Palette} button, users can view a visualization of the \num{12} popular fonts described in \autoref{sec:simulatedEvaluation} and select one to input as their preference, simplifying the process of inputting a font file.
Additionally, we removed the \textsc{Upload Image} and \textsc{Upload Font} buttons from the UI in \autoref{fig:UI} for simplicity.
As a result, users can now easily input text and font files using the \textsc{Text} and \textsc{Font Palette} buttons, respectively.

To assess the effectiveness of the multimodal reference and style propagation features in our system, we created a baseline system that includes only a single slider, as illustrated in \autoref{fig:baselineSystemUI}.
In this baseline system, users can explore the font style latent space solely by adjusting the slider, guided by the Bayesian optimization process. 
Unlike our proposed system, the baselineâ€™s one-dimensional search space is initialized by connecting a fixed point with a randomly initialized point.
The fixed point corresponds to the style of the \textit{IPAex Gothic} font, as described in \autoref{sec:simulatedEvaluation}. 
If users encounter difficulties during exploration, they can reset their preference history in the Bayesian optimization process and restart from a newly randomized search subspace.
Additionally, this baseline method lacks a style propagation function, requiring users to design each character individually.

\begin{figure}[ht]
    \centering
    \includegraphics[width=0.5\textwidth]{figures_pdf/baseline_ui_v6.pdf}
    \caption{
    \textbf{User interface of the baseline system.}
    In the (a) character design area, users use a slider to explore the one-dimensional subspace within the font style latent space recommended by Bayesian optimization.
    By clicking the \textsc{Reset} button, users can reset their preference history in the Bayesian optimization process, randomly reinitializing the search subspace.
    The users can check the characters that they have already designed are displayed in the (b) character collection area.
}
\label{fig:baselineSystemUI}
\end{figure}

\subsubsection{Procedure}
We recruited ten people for the user study.
Each participant was presented with a target font and asked to design three characters, ``A'', ``B'', and ``C'' that closely match the target font using both \systemName and the baseline system.
For this user study, we prepared two target fonts, Font 1 and Font 2.
Each font design session continued until one of the following conditions was met: (1) the participant was satisfied with the quality of the characters they designed, (2) they felt that further improvement was difficult, or (3) the $7$-minute time limit was reached.
The user study followed this sequence: (Tutorial of \systemName $\rightarrow$ Font 1 with \systemName $\rightarrow$ Font 2 with \systemName $\rightarrow$ Tutorial of baseline $\rightarrow$ Font 1 with baseline $\rightarrow$ Font 2 with baseline $\rightarrow$ Survey).
The order of using \systemName and the baseline system was randomized for each participant.
After the font design sessions, participants were asked to complete a questionnaire that validated our system.
The entire user study took approximately $60$ minutes, with each tutorial lasting $10$ minutes, each font design session $7$ minutes, and the survey $10$ minutes.



\subsubsection{Results and Discussion}
We compared the designed fonts using our system and the baseline system both quantitatively and qualitatively.
For the quantitative evaluation, we calculated the distance between the target font characters and the designed characters in the \textit{DreamSim} latent space.
As shown in \autoref{tab:userStudyResult}(a), the characters designed with our system closely resembled the target font characters compared to those designed with the baseline system.
Additionally, we measured the style consistency between all characters designed by each participant by calculating the mean distance between the characters ``A'', ``B'', and ``C'' in the \textit{DreamSim} latent space.
As shown in \autoref{tab:userStudyResult}(b), the distance is smaller when using our system to the baseline system, indicating our system enables more style-consistent character design.
In \autoref{fig:userStudyResult}, we showed the characters designed by all participants (P1--P10).
For Font 1, the ``A'' characters designed by P2, P3, P4, P6, and P8 using our system closely matched the slanted style of the target ``A,'' while they failed to design the slanted style using the baseline system, indicating that participants effectively captured the italic feature through multimodal reference.
On the other hand, characters designed by P1, P2, P3, P4, P5, P8, and P10 using the baseline system showed inconsistencies in style within the same font (\eg~variations in size, height, and weight).
In contrast, characters designed with our system exhibited greater consistency, suggesting that style propagation helped create more cohesive designs.

\begin{figure}[ht]
    \centering
    \includegraphics[width=\linewidth]{figures_pdf/fontDesignResult_v6.pdf}
    \caption{
    \textbf{Characters designed by user study participants.}
    Our system enables users to design characters that are more similar to the target font characters and maintain higher consistency between each other.
    In the case of Font 1, participants successfully designed all characters with the slant style using our system, while some participants failed to create the slant style for ``A'' using the baseline system.
    For Font 2, all participants designed characters with consistent styles using our system, whereas the styles of characters designed using the baseline system were inconsistent.
}
\label{fig:userStudyResult}
\end{figure}


\aptLtoX[graphic=no,type=html]{\begin{table}[ht]
\centering
\begin{tabular}{lll}
\multicolumn{3}{c}{\bf (a) Target font similarity $\downarrow$~~~~~}\\
\hline
                & Font 1          & Font 2          \\ \hline
Baseline & 0.1680          & 0.1416          \\
\systemName  & \bestcell{0.1591} & \bestcell{0.1355} \\ \hline
\end{tabular}
\begin{tabular}{lll}
\multicolumn{3}{c}{~~~~~\bf (b) Designed character consistency $\downarrow$}\\
\hline
                & Font 1          & Font 2          \\ \hline
Baseline & 0.3303          & 0.2893          \\
\systemName     & \bestcell{0.2983} & \bestcell{0.2793} \\ \hline
\end{tabular}
\caption{
(a) 
We calculated the distance between the characters designed by the participants and the target font characters.
Each value represents the mean distance across the $12$ characters (``A'', ``B'', ``C'' designed by the four participants).
The characters designed using our system are closer to the ground truth compared to those with the baseline system. 
(b)
We measured the character consistency between the characters ``A'', ``B'', and ``C'' designed by each participant.
Each value represents the mean distance across the three characters designed by each participant.
The distance among the three characters designed using our system is smaller than that with the baseline system, which indicates our system enables more style-consistent character design. 
($\downarrow$ denotes the lower values are better and we highlight the \besthint{best} result for each target font.)
}
\label{tab:userStudyResult}
\end{table}}{\begin{table}[ht]
\centering
\subfloat[Target font similarity $\downarrow$]{
\begin{tabular}{lll}
\toprule
                & Font 1          & Font 2          \\ \midrule
Baseline & 0.1680          & 0.1416          \\
\systemName  & \bestcell{0.1591} & \bestcell{0.1355} \\ \bottomrule
\end{tabular}
}
\subfloat[Designed character consistency $\downarrow$]{
\begin{tabular}{lll}
\toprule
                & Font 1          & Font 2          \\ \midrule
Baseline & 0.3303          & 0.2893          \\
\systemName     & \bestcell{0.2983} & \bestcell{0.2793} \\ \bottomrule
\end{tabular}
}
\caption{
(a) 
We calculated the distance between the characters designed by the participants and the target font characters.
Each value represents the mean distance across the $12$ characters (``A'', ``B'', ``C'' designed by the four participants).
The characters designed using our system are closer to the ground truth compared to those with the baseline system. 
(b)
We measured the character consistency between the characters ``A'', ``B'', and ``C'' designed by each participant.
Each value represents the mean distance across the three characters designed by each participant.
The distance among the three characters designed using our system is smaller than that with the baseline system, which indicates our system enables more style-consistent character design. 
($\downarrow$ denotes the lower values are better and we highlight the \besthint{best} result for each target font.)
}
\label{tab:userStudyResult}
\end{table}}

Next, we evaluated participant feedback to validate the effectiveness of our system.
We asked questions about the functions in our system, including slider operation, multimodal reference, style propagation, and history interface.
When we asked the question \textit{``Were you satisfied with the designed characters?''}, seven out of the ten participants answered yes, while P2 and P10 commented neutral, and P9 expressed no.
P9 noted that he observed distortions in the generated characters and felt the system was not good at generating straight lines.
In response to the question \textit{``Do you think you were able to design fonts easily with the system?''}, all ten participants answered yes, demonstrating the system's effectiveness in enabling non-expert users to design fonts with ease.

In response to the question \textit{``Do you think you were able to effectively use the slider operation for font design?''}, nine participants answered yes.
P4, who answered no, expressed dissatisfaction, stating that while the combination of slider manipulation and multimodal reference was effective, using only the slider and repeatedly clicking the \textsc{Update} button sometimes resulted in a linear subspace that excluded the desired character style.
P4 emphasized the importance of using multimodal reference at the right moments to avoid unsatisfactory suggestions and stated that relying solely on the slider was not effective.
P4 also highlighted that the history interface was useful for reverting to a previous point, leading to the escape of an undesirable search subspace suggested by the system.
P4's feedback reflects the findings suggested in Chan~\etal~\cite{Chan2022}, which indicate that designers working with BO may experience a loss of agency.
In contrast, our method provides users with a way to contribute concrete ideas that guide the BO process, thereby helping them regain a sense of agency.

In response to the question, ``\textit{Do you think you were able to effectively use text input?}'', eight of ten participants answered yes.
P1, P2, P4, P6, P7, P9, and P10 found text input helpful for making broad changes, such as adjusting weight or slant, but not for fine-tuning details or specifying complicated characteristics.
Additionally, P1, P6, and P7 mentioned that understanding typographical terms like ``bold'' and ``italic'' was necessary.
This feedback indicates that while text input is useful for exploring rough font styles, it has limitations in designing font details and requires some typographic knowledge.

Regarding the question, \textit{``Do you think you were able to effectively use the similar fonts provided by font palette?''}, eight of ten answered yes.
P4 and P7 commented that the font palette is particularly helpful when it is difficult to describe the desired font style in texts.
P8, P9, and P10 stated that initializing the search subspace using the font palette function allowed them to begin the design task more smoothly compared to the baseline system.
However, P5 expressed dissatisfaction, stating that the style of the character generated did not perfectly align with the font they selected from the font palette.
This discrepancy, caused by the encoding-decoding process of the font generative model, could lead to confusion among users.
To address this issue, it is important to communicate to users that the generated characters may not always perfectly match the multimodal reference.
Additionally, we anticipate that newer font generative models could help mitigate this discrepancy.
It is worth emphasizing that our proposed system is compatible with any font generative model, provided an efficient font style latent space can be established within it.
On the other hand, P2 explained that he did not use the font palette because he preferred to describe the target font style using text input.
This feedback suggests that using similar font files and text input complement each other.

When asked, \textit{``Do you think you were able to effectively use the \textsc{Update all} button?''}, nine participants responded positively, with eight participants noting that it was more convenient than designing each character individually.
P10, who answered no, expressed dissatisfaction, commenting that it would be more convenient if users could toggle between adjusting either all characters at once or individually. 
In particular, he felt that having a feature to switch to individual adjustments is crucial during the fine-tuning stage.
We focus on the simplicity of the UI in this user study and this individual adjustments function is effective especially when designing many characters like all Roman characters.

In response to the question, ``\textit{Do you feel that you could design characters with a sense of agency using our system?}'', posed only to P5--P10, all six participants responded affirmatively.
P7 and P10 noted that in the baseline system, the line search space was initialized randomly, making the process feel highly dependent on luck. 
In contrast, they appreciated that our proposed system allowed them to control the initialization by specifying their preferences through multimodal references.
This insight aligns with the findings in \autoref{sec:simulatedEvaluation}, which show the initialization using multimodal references leads to better results compared to random initialization.
Additionally, P9 commented that he felt he could convey his intentions to the system by inputting texts.
These insights indicate that our system, leveraging multimodal references, provides users with a greater sense of agency compared to the baseline system.

Seven participants highlighted the usefulness of the history interface during the design process.
P5 remarked that the feature was particularly effective, as there were times when he felt a previous font was better.
In such cases, the history interface allowed him to revisit and continue from that point, saving effort.
He also noted the inconvenience of the baseline system lacking this feature.
P6 commented that comparing the current font displayed on the slider with previously created fonts helped him determine which one aligned more closely with his intended design.
He also said that in the baseline system, he found it challenging to reset after creating a satisfactory font.
In contrast, our system's history interface made him feel more confident about updating or resetting, as it allowed him to aim for even better results without hesitation.
This exemplifies that the history interface is useful not only for storing the designed characters and enabling the users to go back to a past point but also for making them advance the design process as boldly as they want.
It also indicates that the history interface reduces stress and increases freedom and creativity in the design task.

Overall, the feedback suggests that the proposed functions in our system effectively support font design for different participants based on their design preferences and familiarity with typography.
