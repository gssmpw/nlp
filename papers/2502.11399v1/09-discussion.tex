\section{Discussion, Limitations and Future Work}
\label{sec:limitations}

\paragraph{Professional Designers Interview}
In our user study and demonstration, we focused on non-expert users, as our system is designed to help them create fonts without requiring specialized knowledge.
However, feedback from professional designers (D1 and D2) is also crucial for identifying areas for improvement and enhancing the versatility of \systemName.
To gather feedback, we interviewed two professional designers from an advertising company, demonstrating our system and its outputs while asking two main questions:
1. \textit{"Is our system practical for designing advertisements in real-world scenarios?"}
2. \textit{"Are there any areas in our method that could be improved or features that should be added?"}

For the first question, both designers said they often need to create or customize unique characters for advertisement posters and logos.
They acknowledged that our system is suitable for such tasks, validating its use in designing characters for posters and conference logos.
For the second question, they pointed out that the distortion in the generated characters should be fixed for use in real-world scenarios.
Additionally, they expressed that a function allowing users to edit the generated characters is desirable.
Moreover, D1 noted that, for logo design, she sometimes needs to create each unique character in different styles; thus, the style propagation feature is not needed in such cases.
This feedback suggests that offering an option to disable style propagation could enhance user flexibility.
D2 mentioned that it would be beneficial to save all generated characters, visualize them in the UI, and allow users to revisit any previous points.
This implies that developing a more comprehensive history visualization feature could be a potential future work.

\paragraph{Limited Quality of the Generate Characters}
As noted by several participants in \autoref{sec:user-study} and \autoref{sec:demonstration}, generated characters exhibit distortions and visual artifacts.
Additionally, despite our system's ability to help users design style-consistent characters, some style inconsistencies persist.
For instance, during the demonstration of conference logo design in \autoref{sec:demonstration}, P11 mentioned the difficulty in applying the fading effect seen in ``H'' and ``5'' to ``2''.
These issues stem from the limitations of the font generative model~\cite{XieDGFont2021} and the vectorization method~\cite{selinger2003potrace} used in our system.
Our system requires a font generative model that can generate characters rapidly while manipulating the slider.
Therefore, even though some existing font generative models~\cite{liu2023dualvector,fu2024MSD, he2024difffont, liu2024qtfont,thamizharasan2024vecfusion} can produce characters with higher-quality and in more consistent styles, we cannot use them since they take longer time to generate.
For example, \textit{VecFusion}~\cite{thamizharasan2024vecfusion} takes 10 seconds to generate one glyph using A100, which is not feasible for interactive applications.
Meanwhile, this limitation also makes it harder for users to use our system to design style-consistent fonts containing many characters (\eg~$52$).
However, we believe that with the progress of font generative models, our system can utilize the latest models and generate fonts in higher quality.
To tackle these issues, we plan to explore how to optimize both the speed and quality of font generation. 
This includes integrating more advanced vectorization techniques or improving the efficiency of recent generative models without sacrificing real-time performance.

\paragraph{Broader Search Subspace for Multimodal References}
The current \textit{multimodal-guided subspace} is constructed by directly connecting a single encoded multimodal reference and previous user preference.
Although this approach enables users to explore the latent space around the multimodal reference, it may restrict other font style variations that are similar to the multimodal reference.
In the future, we plan to investigate how to construct a search subspace by connecting one or multiple multimodal references to an area in the style latent space that contains potential samples matching the desired styles similar to \cite{KoyamaGallery2020}.

\paragraph{Direct Character Editing}
As described in \autoref{sec:demonstration}, some users had difficulty creating desired characters due to character detail artifacts introduced by the font generative model and vectorization process.
In the future, to mitigate these artifacts, we plan to introduce painting tools that will allow users to edit the generated characters directly.

\paragraph{UI for Additional Typographical Support}
To design a font ready for production, it is crucial to include features that align characters with baseline, mean line, and other typographical guidelines including kerning.
These are essential for improving the overall appearance, alignment, and readability of the text.
We next plan to investigate how to integrate different user interfaces to facilitate font design that considers these typographical guidelines.
