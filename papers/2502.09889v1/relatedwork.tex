\section{Related Works}
\label{sec:related_works}
% \sk{Outline:
% \begin{enumerate}
%     % \item Graph Neural Networks
%     % \begin{itemize}
%     %     \item Graph Convolution Networks (https://arxiv.org/abs/1609.02907)
%     %     \item Graph Attention Networks (https://arxiv.org/abs/1710.10903, https://arxiv.org/abs/2105.14491)
%     % \end{itemize}
%     \item Multi-agent explanation methods
%     \begin{itemize}
%         \item https://arxiv.org/pdf/2311.11955, https://arxiv.org/pdf/2204.12568, https://arxiv.org/pdf/2305.10378 operate using policy abstraction and typically grounded in the task at hand. Do not focus on explaining agent-agent influences for team decisions
%         \item https://arxiv.org/pdf/2008.01508 not peer-reviewed, but this along with https://arxiv.org/pdf/2204.12568, https://arxiv.org/pdf/2305.10378 are specific to MARL
%         \item MAPF-specific/motion planning-specific (and not doing model analysis): https://mortezalahijanian.com/papers/AAMAS2020.pdf, https://arxiv.org/abs/2202.09930, https://etdm2020.github.io/abstracts/RSS\_2020\_ETDM\_Kottinger\_Explainable.pdf
%     \end{itemize}
%     \item GNN-based explanation methods
%     \begin{itemize}
%         \item GNNExplainer (http://arxiv.org/abs/1903.03894)
%         \item GraphMask (https://arxiv.org/abs/2010.00577)
%         \item PGExplainer (https://arxiv.org/abs/2011.04573)
%         \item SubgraphX (https://arxiv.org/abs/2102.05152)
%         \item PGM-Explainer (https://proceedings.neurips.cc/paper/2020/hash/8fb134f258b1f7865a6ab2d935a897c9-Abstract.html)
%         \item XGNN (https://dl.acm.org/doi/abs/10.1145/3394486.3403085)
%         \item CF-GNNExplainer (https://proceedings.mlr.press/v151/lucic22a.html)
%     \end{itemize}
%     \item GNN-based policies for multi-agent systems (all of these works use a agent-agent network as the graph input)
%     \begin{itemize}
%         \item https://arxiv.org/pdf/2111.01777 (passage task)
%         \item https://arxiv.org/pdf/1912.06095, https://arxiv.org/pdf/2011.13219 (Prorok gnn path planning)
%         \item https://ieeexplore.ieee.org/abstract/document/9676458 (collaborative perception)
%         \item https://ieeexplore.ieee.org/abstract/document/9811854 (Coverage control)
%         \item https://www.ifaamas.org/Proceedings/aamas2021/pdfs/p764.pdf (Coordination in benchmark MARL tasks)
%     \end{itemize}
% \end{enumerate}
% }

% Below, we discuss different categories of related work and contextualize our contribution within each category.

\textbf{Explainable multi-agent coordination}:
% \label{xaimacRelatedWorks}
Since explainable multi-agent coordination was proposed as a new research direction recently \cite{kraus2020ai}, only a few works have explored this problem. 
One line of work investigates explanations via policy abstraction using a multi-agent MDP~\cite{boggess2022toward, boggess2023explainable}. Similarly, policy summarization and the use of landmarks to condition and convey the high-level strategy is also being explored~\cite{pandya2024multi}. These works rely on text and visual modalities, and are focused more on high-level explanations. As a result, they do not focus on explaining or distilling key interactions among agents.
\sk{\textbf{In fact, explanations that capture critical and affected agents (and agent-agent influences) were found to be desirable in a user-study by \cite{brandao2022explainability} for multi-agent/multi-robot navigation-based tasks.}}
While a different line of work has proposed generating easily verifiable multi-agent path finding plans as explainable~\cite{almagor2020explainable, kottinger2022conflict, kottingerexplainable}, they inherently do not capture key agents or interactions as desired and are limited to specific problem representations of multi-agent navigation. These gaps in the literature strongly motivate the idea of identifying subgraphs of agents to outline the most relevant agents and their interactions among one another. Toward this, we investigate and improve the utility of graph-based explanations of GNN-based multi-agent policies.
% could be a reasonable strategy for fulfilling this desired explanation paradigm. 

% \subsection{GNN-based multi-agent coordination}
% \label{related:GNN_MAC}
% \sk{
% Graph Neural Networks have become prominent in MARL due to their scalability and demonstrated success in facilitating inter-agent communication. They have been utilized to overcome partial observability and enable generalization to varying team sizes in tasks such as cooperative navigation \cite{porok-path-plan, magat}, coverage control \cite{coverage-control}, autonomous driving \cite{gat-auto-drive}, and real-world multi-robot coordination \cite{passageProrok}. Further, GNNs have been shown to be more effective than feed-forward architectures at integrating information from surrounding agents, leading to improved performance in benchmark MARL tasks such as Predator-Prey, Traffic Junction, and Star-Craft \cite{coordination-graphs}.

% % Across these works, an agent-agent graph and a representation of each agent's local observations are provided as inputs to the GNN as the adjacency matrix and the node features. Single or several rounds of message passing are conducted through graph convolutional layers, allowing agents to integrate information from surrounding agents into their own node representation (such as local observations), analogous to communication channels. This node representation is then utilized for task completion, typically via a local decoder structure such as a multi-layer perceptron with shared parameters/weights. This effectively conditions the action of the ego agent on the observations of surrounding agents in addition to the ego agent.

% Since the decisions of one agent are influenced by the information communicated by neighboring agents, it is challenging to interpret GNN-based policies without the help of explanations. However, the graph learning community has been pursuing explanations of GNNs with respect to supervised learning on large graph data recently. \textbf{Analogous to how the multi-agent/multi-robot community has evaluated and transposed the use of GNNs from the graph learning community for learning coordination for different tasks (as evidenced by the aforementioned related works), we seek to do a similar evaluation with GNN-based post-hoc explainers. 
% % Thus, we adopt the core elements across these aforementioned works and evaluate the explanation quality generated by these methods. 
% This evaluation, combined with the insights presented to potentially improve the explanation quality, can be used to address a much-needed explanation paradigm for multi-agent coordination \cite{brandao2022explainability}.
% % and