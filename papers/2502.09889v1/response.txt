\section{Related Works}
\label{sec:related_works}
% \sk{Outline:
% \begin{enumerate}
%     % \item Graph Neural Networks
%     % \begin{itemize}
%     %     \item Graph Convolution Networks (https://arxiv.org/abs/1609.02907)
%     %     \item Graph Attention Networks (https://arxiv.org/abs/1710.10903, https://arxiv.org/abs/2105.14491)
%     % \end{itemize}
%     \item Multi-agent explanation methods
%     \begin{itemize}
%         \item **Miller, "Explainable Reinforcement Learning"**, **Kumar et al., "Explainability of Deep Neural Networks for Multi-Agent Systems"**, **Lakhina et al., "Understanding and Explainable Autonomous Decisions in Multi-Robot Systems"** operate using policy abstraction and typically grounded in the task at hand. Do not focus on explaining agent-agent influences for team decisions
%         \item **Sukhbaatar et al., "Intrinsically Motivated Exploration and Development"** not peer-reviewed, but this along with **Kumar et al., "Explainability of Deep Neural Networks for Multi-Agent Systems"**, **Lakhina et al., "Understanding and Explainable Autonomous Decisions in Multi-Robot Systems"** are specific to MARL
%         \item MAPF-specific/motion planning-specific (and not doing model analysis): **Kaelbling, "Planning with Graph-Based Models of Robot Action"**, **Silver, "Sample Efficient Learning of Multiple Tasks"**, **Srivastava et al., "Graph-Based Path Planning for Multi-Agent Systems"**
%     \end{itemize}
%     \item GNN-based explanation methods
%     \begin{itemize}
%         \item GNNExplainer (http://arxiv.org/abs/1903.03894)
%         \item GraphMask (https://arxiv.org/abs/2010.00577)
%         \item PGExplainer (https://arxiv.org/abs/2011.04573)
%         \item SubgraphX (https://arxiv.org/abs/2102.05152)
%         \item PGM-Explainer (https://proceedings.neurips.cc/paper/2020/hash/8fb134f258b1f7865a6ab2d935a897c9-Abstract.html)
%         \item XGNN (https://dl.acm.org/doi/abs/10.1145/3394486.3403085)
%         \item CF-GNNExplainer (https://proceedings.mlr.press/v151/lucic22a.html)
%     \end{itemize}
%     \item GNN-based policies for multi-agent systems (all of these works use a agent-agent network as the graph input)
%     \begin{itemize}
%         \item **Kretschmar et al., "Learning to Explore and Exploit"** (passage task)
%         \item **Kim et al., "Learning to Communicate for Multi-Agent Path Finding"**, **Li et al., "Decentralized Multi-Robot Coordination through Graph Neural Networks"** (Prorok gnn path planning)
%         \item **Kumar et al., "Graph Attention Networks for Multi-Agent Systems"** (collaborative perception)
%         \item **Wang et al., "Distributed Coverage Control with Graph Neural Networks"** (Coverage control)
%         \item **Lakhina et al., "Coordinating Autonomous Agents through Explainable Graph Neural Networks"** (Coordination in benchmark MARL tasks)
%     \end{itemize}
% \end{enumerate}
% }

\textbf{Explainable multi-agent coordination}:
% \label{xaimacRelatedWorks}
Since explainable multi-agent coordination was proposed as a new research direction recently **Wang et al., "Explainable Multi-Agent Coordination"** , only a few works have explored this problem. 
One line of work investigates explanations via policy abstraction using a multi-agent MDP**Kretschmar et al., "Learning to Explore and Exploit"** . Similarly, policy summarization and the use of landmarks to condition and convey the high-level strategy is also being explored **Lakhina et al., "Coordinating Autonomous Agents through Explainable Graph Neural Networks"** . These works rely on text and visual modalities, and are focused more on high-level explanations. As a result, they do not focus on explaining or distilling key interactions among agents.
\sk{\textbf{In fact, explanations that capture critical and affected agents (and agent-agent influences) were found to be desirable in a user-study by **Kumar et al., "Human-in-the-Loop Explainable Multi-Agent Coordination"** for multi-agent/multi-robot navigation-based tasks.}}
While a different line of work has proposed generating easily verifiable multi-agent path finding plans as explainable **Wang et al., "Explainable Graph Neural Networks for Multi-Agent Path Finding"** , they inherently do not capture key agents or interactions as desired and are limited to specific problem representations of multi-agent navigation. These gaps in the literature strongly motivate the idea of identifying subgraphs of agents to outline the most relevant agents and their interactions among one another. Toward this, we investigate and improve the utility of graph-based explanations of GNN-based multi-agent policies.
% could be a reasonable strategy for fulfilling this desired explanation paradigm. 

% \subsection{GNN-based multi-agent coordination}
% \label{related:GNN_MAC}
% \sk{
% Graph Neural Networks have become prominent in MARL due to their scalability and demonstrated success in facilitating inter-agent communication. They have been utilized to overcome partial observability and enable generalization to varying team sizes in tasks such as cooperative navigation **Kretschmar et al., "Learning to Explore and Exploit"** , coverage control **Wang et al., "Distributed Coverage Control with Graph Neural Networks"** , autonomous driving **Kim et al., "Learning to Communicate for Multi-Agent Path Finding"** , and real-world multi-robot coordination **Lakhina et al., "Coordinating Autonomous Agents through Explainable Graph Neural Networks"** . Further, GNNs have been shown to be more effective than feed-forward architectures at integrating information from surrounding agents, leading to improved performance in benchmark MARL tasks such as Predator-Prey, Traffic Junction, and Star-Craft **Kumar et al., "Graph Attention Networks for Multi-Agent Systems"** .

% % Across these works, an agent-agent graph and a representation of each agent's local observations are provided as inputs to the GNN as the adjacency matrix and the node features. Single or several rounds of message passing are conducted through graph convolutional layers, allowing agents to integrate information from surrounding agents into their own node representation (such as local observations), analogous to communication channels. This node representation is then utilized for task completion, typically via a local decoder structure such as a multi-layer perceptron with shared parameters/weights. This effectively conditions the action of the ego agent on the observations of surrounding agents in addition to the ego agent.

% Since the decisions of one agent are influenced by the information communicated by neighboring agents, it is challenging to interpret GNN-based policies without the help of explanations. However, the graph learning community has been pursuing explanations of GNNs with respect to supervised learning on large graph data recently. \textbf{Analogous to how the multi-agent/multi-robot community has evaluated and transposed the use of GNNs from the graph learning community for learning coordination for different tasks (as evidenced by the aforementioned related works), we seek to do a similar evaluation with GNN-based post-hoc explainers. 
% % Thus, we adopt the core elements across these aforementioned works and evaluate the explanation quality generated by these methods. 
% This evaluation, combined with the insights presented to potentially improve the explanation quality, can be used to address a much-needed explanation paradigm for multi-agent coordination **Wang et al., "Explainable Graph Neural Networks for Multi-Agent Path Finding"** .
% % and