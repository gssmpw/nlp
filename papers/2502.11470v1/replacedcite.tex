\section{Related Work}
This section reviews recent advances in network intrusion detection systems (NIDS), machine learning techniques applied to IoT security, and optimization strategies for improving detection frameworks. The reviewed works focus on developments from 2023-2025, highlighting the latest trends in using deep learning, hybrid models, and feature extraction techniques to enhance security in IoT environments.

Recent advancements in IoT-specific threat detection highlight a growing trend toward hybrid models that \textbf{combine supervised and unsupervised learning techniques}. These models effectively mitigate the limitations of traditional methods by leveraging the strengths of both paradigms, resulting in improved detection accuracy, adaptability, and robustness. For instance, ____ introduced a hybrid unsupervised learning approach using Self-Organizing Maps to detect unknown threats in dynamic IoT ecosystems. Similarly, ____ developed a hybrid intrusion detection system (IDS) that integrates machine learning with signature-based methods, significantly enhancing the detection of both known and emerging threats, including zero-day attacks in IoT networks.

To address feature selection challenges, ____ proposed a model combining supervised learning with Spider Monkey Optimization. This approach optimizes feature selection, making it particularly effective in resource-constrained IoT environments where computational efficiency is critical.

Further innovations include adversarial realism and robust learning techniques. For example, ____ explored hybrid learning models designed to enhance the resilience of IoT IDS against adversarial attacks. Additionally, ____ investigated hybrid anomaly detection models by combining autoencoders with traditional machine learning algorithms, providing more reliable detection of complex and subtle attack patterns.

A notable development in deep learning for IoT threat detection is the CNN-FDSA model by ____. This hybrid deep learning framework uses Convolutional Neural Networks (CNNs) and Deep Stacked Autoencoders (DSA) to detect botnet attacks in IoT networks. The model processes IoT network traffic with Quantile normalization, employs feature extraction techniques like Information Gain and City Block Distance, and addresses data imbalance through oversampling. Achieving 92.4\% accuracy with high precision, recall, and F-measure, CNN-FDSA demonstrates its capability in reducing false positives and managing complex, imbalanced datasets. Future directions for this work include real-time botnet detection and the development of multi-layered security frameworks to fortify IoT networks.

These studies collectively reinforce the value of hybrid models that integrate unsupervised feature extraction with supervised classification techniques. By enhancing detection accuracy, adaptability, and resilience, these approaches align closely with the goals of this work to advance IoT-specific threat detection frameworks.
\subsection{Data Privacy and Security in IoT Networks}

Privacy concerns in IoT networks are a significant issue, as intrusion detection often requires access to sensitive data. Approaches like federated learning offer solutions, but challenges related to data leakage and model accuracy persist. ____ proposed a federated learning-based intrusion detection system (IDS) for Internet of Things (IoT) devices, leveraging both unsupervised and supervised deep learning models to address security and privacy challenges in IoT networks. The study compares the performance of federated learning (FL) trained models with traditional non-FL models using the N-BaIoT dataset, which includes data from nine IoT devices. While the combination of unsupervised autoencoders (AEs) for anomaly detection and supervised deep neural networks (DNNs) for attack classification enhances the robustness and accuracy of the IDS, challenges related to data leakage and model accuracy persist. Data leakage can occur when sensitive information unintentionally influences model training, compromising privacy and security, while model accuracy may be impacted by the decentralized nature of FL, affecting its generalization across diverse devices. Hyperparameter tuning and the use of the FedAvgM FL algorithm help mitigate these issues, improving model performance, with results indicating that the unsupervised AE model trained via FL outperforms other models across various evaluation metrics. This demonstrates the effectiveness of FL in improving both performance and data privacy for IoT IDS, despite ongoing challenges around data leakage and model accuracy.

____ explored privacy-preserving computation in federated learning (FL), emphasizing the importance of safeguarding data privacy in AI applications. This work surveys various privacy-preserving computation protocols, such as secure multi-party computing (SMC), homomorphic encryption (HE), differential privacy (DP), trusted execution environments (TEEs), and zero-knowledge proofs (ZKP). The study categorizes privacy attacks and highlights inference attacks, malicious servers, and poisoning attacks that pose threats to privacy in FL. Additionally, it evaluates and compares the security properties and efficiency of different protocols through experiments using common datasets like MNIST and CIFAR-10. The paper concludes by suggesting future research directions, including the integration of ZKP with FL and exploring machine unlearning for improved privacy and regulatory compliance.

Building upon these privacy-enhancing techniques, ____ integrated Blockchain and Federated Learning (FL) to enhance intrusion detection systems (IDS) in industrial Internet of Things (IIoT) networks. The study addresses the limitations of centralized machine learning approaches in IIoT due to privacy and computational challenges, emphasizing the decentralization benefits offered by FL. Blockchain enhances security and privacy by enabling verifiable and secure data exchanges, while FL supports collaborative model training without exposing sensitive data. The paper provides a detailed analysis of existing IDS techniques, identifies trends and gaps in IIoT security, and suggests future research directions for combining Blockchain and FL. In conclusion, it stresses the importance of advanced, decentralized intrusion detection systems to protect IIoT networks and drive the success of Industry 4.0.

While these studies highlight promising approaches to improve data privacy and security in IoT systems, challenges persist, including maintaining high model accuracy without compromising privacy, handling decentralized data securely, and ensuring that the implemented privacy-preserving protocols do not hinder the system's performance or scalability. Future work may explore more efficient methods for balancing security and performance, such as combining federated learning with edge computing, or refining blockchain protocols to improve their scalability and energy efficiency in IoT environments.
\subsection{Network Intrusion Detection in IoT}

The rapid adoption of IoT devices has intensified the need for robust network intrusion detection systems (NIDS) capable of identifying sophisticated cyber-attacks in real-time. Traditional IDS approaches are often inadequate in handling the unique characteristics of IoT environments, such as large-scale distributed systems, constrained resources, and heterogeneous communication protocols ____. To address these challenges, recent studies have shifted towards more adaptive and intelligent frameworks that leverage machine learning to enhance detection capabilities.

One such effort is the lightweight IDS proposed by ____, specifically designed for resource-constrained IoT devices. By employing a convolutional neural network (CNN) architecture, the system effectively balances detection accuracy with computational overhead, making it suitable for real-time deployment. While this approach has proven instrumental in mitigating common attack types such as Distributed Denial of Service (DDoS) and man-in-the-middle attacks, it is less effective against more complex intrusion patterns, highlighting the need for further advancements.

Building on these advancements, ____ developed a deep learning-based NIDS that enhances feature extraction by combining group convolution for spatial features, Split-Attention for feature selection, and BiGRU for temporal features. To overcome data imbalance issues, they employed a Conditional Tabular Generative Adversarial Network (CTGAN), which significantly improved detection accuracy across datasets. Their model achieved impressive results, with accuracy rates of 91.08\%, 94.55\%, and 97.47\% on the UNSW-NB15, CIC-IDS2018, and CIC-IOT2023 datasets, respectively. However, the system's high computational resource requirements and long training times present barriers to scalability, which the authors aim to address through cloud-edge collaboration and transfer learning.

Further addressing the need for robust IoT NIDS, ____ introduced a system leveraging CNN for spatial feature extraction and Bidirectional Long Short-Term Memory (Bi-LSTM) for temporal pattern learning. This model excelled in binary classification tasks on the NSL-KDD dataset, achieving an outstanding accuracy and detection rates. However, challenges with the U2R class due to insufficient data underscore the importance of tackling data imbalance to enhance robustness.

To optimize feature selection and detection performance, ____ proposed a hybrid intrusion detection system (IDS) for the Internet of Things (IoT) that combined deep learning and optimization techniques to enhance anomaly detection accuracy. They introduced a convolutional neural network (FECNNIoT) for effective high-level and low-level feature extraction and developed a binary multi-objective Gorilla Troops Optimizer (BMEGTO) to optimize feature selection. The proposed CNN-BMEGTO-KNN method achieved outstanding accuracy of 99.99\% on the TON-IoT dataset and 99.86\% on the NSL-KDD dataset. It outperformed traditional deep learning models like LSTM and MLP in terms of accuracy, precision, recall, and F1-score. The novelty of their approach lay in the advanced CNN design and the adaptation of the Gorilla Troops Optimizer for multi-objective binary feature selection.

In a different approach, ____ introduced a novel Micro Reinforcement Learning Classifier (MRLC) for intrusion detection systems, leveraging a Deep Q-Network (DQN) agent to perform fine-grained learning for binary and multiclass classification tasks. The MRLC processes each training sample as an independent experiment, associating the value of each sample with the agent's learning rate to ensure robust learning. The approach incorporates a dynamic reward mechanism that guides the agent to prioritize accurate intrusion detection. They evaluated the architecture on three datasets, NSL-KDD, CIC-IDS2018, and UNSW-NB15, achieving an accuracy of 99.56\%, 99.99\%, and 99.01\%, respectively. The novelty depends on their single-sample learning strategy, replay buffer updates, and ability to achieve comparable results even with a significantly reduced training set.

\subsection{Deep Learning Approaches for IoT Security}
Recent developments in deep learning have shown tremendous potential in improving the detection of complex, multi-stage cyber-attacks in IoT networks. Researchers have been particularly focused on the application of unsupervised learning techniques such as Self-Organizing Maps (SOMs), Deep Belief Networks (DBNs), and Autoencoders, which can detect previously unknown attack patterns without relying on labeled datasets ____.

The integration of SOMs into IDS frameworks has garnered significant attention in the IoT domain due to their ability to map high-dimensional data into lower-dimensional representations, thus simplifying anomaly detection. For instance, ____ proposed a framework for real-time anomaly detection and mitigation in IoT-based smart grid cybersecurity systems, leveraging advanced deep neural networks, including autoencoders, LSTMs, GANs, and SOMs, along with transfer learning and attention mechanisms. The framework incorporated real-time adaptive mitigation strategies capable of autonomously responding to cyber threats, ensuring seamless operation of the smart grid. Extensive real-world testing demonstrated the system’s scalability and resilience across a variety of cyber threats, affirming its practical applicability and robustness. Comparative evaluations against traditional methods highlighted its superior performance in anomaly detection, informed mitigation, and scalability. This comprehensive and versatile solution established a robust foundation for protecting IoT-based smart grids from evolving cybersecurity threats, offering a promising advancement for the field.

Deep Belief Networks (DBNs) show promise in capturing temporal dependencies within IoT network traffic, which is crucial for detecting advanced persistent threats (APTs). ____ developed a real-time intrusion detection mechanism for wireless networks using a Conditional Deep Belief Network (CDBN). To address issues like data imbalance and dimensionality, the researchers created the "SamSelect" under-sampling algorithm and designed the Stacked Contractive Auto-Encoder (SCAE) for feature reduction. They combined the CDBN with these techniques to detect attacks in real-time, achieving an impressive detection accuracy of 97.4\% with a detection time of 1.14 ms. Their study pioneered the application of CDBN to wireless network intrusion detection and introduced the SamSelect algorithm to balance the AWID dataset. The experimental results demonstrated that their method outperformed other deep and shallow learning approaches, showed robustness against noise, and provided valuable insights for advancing cybersecurity research.

Autoencoders have been employed to further enhance detection frameworks by reducing data dimensionality and isolating outliers ____. ____ introduced a LSTM autoencoder-based Intrusion Detection System (IDS) designed for Intelligent Transportation Systems (ITS), with a particular emphasis on detecting cyber-attacks targeting Autonomous Vehicles (AVs) and the Internet of Vehicles (IoVs). This IDS leveraged statistical feature extraction alongside the robust learning capabilities of LSTM to effectively detect anomalies in both in-vehicle communications and external network traffic. The architecture demonstrated proficiency in managing heterogeneous data by eliminating redundancy and extracting highly representative features, which significantly enhanced detection accuracy and minimized false alarms. Furthermore, it provided a comprehensive solution capable of addressing multiple attack vectors across in-vehicle and external communication systems. Despite its strengths, the system faced certain limitations, such as difficulties in accurately classifying multiclass attack categories and challenges related to scaling for large and complex IoV environments.

In addition, ____ explored how integrating IEEE standards and deep learning techniques enhanced the security of IoT devices in Japan from 2019 to 2024. They highlighted how the rapid adoption of IoT technology introduced significant cybersecurity challenges, driving the need for advanced protection methods. By conducting surveys and technical assessments, they identified key areas where IEEE standards and deep learning models, such as CNN and LSTM, effectively detected and mitigated cyber threats. Their findings showed that these approaches significantly improved the security posture of IoT networks, addressing risks like DoS attacks and malware. They also emphasized the importance of policy support and collaborative efforts between policymakers, researchers, and industry stakeholders to sustain and strengthen IoT security. Future research directions suggested continued exploration of deep learning advancements, federated learning, and real-time intelligence sharing to combat evolving cyber threats in IoT environments.

____ examined the integration of machine learning (ML) techniques to enhance Industrial IoT (IIoT) security. It highlighted the benefits of IIoT, such as intelligent analytics and predictive maintenance, but also addressed the associated cybersecurity risks, including malware and cyberattacks. The study provided a comprehensive review of ML-based methods for vulnerability detection and security improvement, emphasizing techniques like CNN, LSTM, and active defense strategies. Additionally, the paper explored challenges in device authentication, data modeling, network detection, and static analysis, while suggesting future directions for adaptive machine learning models and unified data standards to address these issues. Finally, it outlined the evolving threat landscape in IIoT and discussed how ML models are essential for identifying and mitigating new cybersecurity risks.

____ examined various machine learning methods for detecting anomalies in cyberattacks on IoT networks. It compared the efficacy of techniques such as Support Vector Machine (SVM), Artificial Neural Network (ANN), Decision Tree (DT), Logistic Regression (LR), and k-Nearest Neighbours (k-NN). The research utilized two large datasets ToN-IoT and BoT-IoT to evaluate the performance of these methods using metrics like accuracy, precision, recall, F1 score, and AUC score. Neural networks demonstrated superior performance among the methods, making them the most effective for anomaly detection. The findings suggested the potential for integrating these methods into industrial IoT environments for both research and practical applications. The study also highlighted future directions, including the incorporation of deep learning models and ensemble approaches to enhance anomaly detection in IoT networks.

The paper ____ explored the security challenges associated with the rapid growth of IoT devices and applications. It highlighted vulnerabilities such as node spoofing, unauthorized data access, and cyberattacks, emphasizing the critical role of machine learning (ML) and deep learning (DL) in addressing these issues. The study provided a comprehensive review of ML/DL approaches in IoT security, categorizing recent research and offering insights into their opportunities, advantages, and limitations. The paper discussed state-of-the-art IoT-specific security challenges, including cyberattacks, eavesdropping, and intrusion detection. It also analyzed the integration of ML/DL with metaheuristic algorithms and addressed the adaptability challenges in ML/DL systems for dynamic IoT environments. Finally, the paper suggested the use of advanced algorithms like graph neural networks and AdaBoost for improving the accuracy of anomaly detection and classification in IoT security.
\subsection{Hybrid Models for Network Intrusion Detection}

The integration of multiple deep learning models has become an increasingly popular strategy for addressing the multifaceted nature of IoT security challenges. Hybrid models offer the benefit of combining the strengths of different techniques to provide a more comprehensive analysis of network traffic ____. These models often incorporate both supervised and unsupervised learning techniques to maximize detection accuracy and adaptability to evolving threats.

____ introduced a hybrid framework that combines DBNs and recurrent neural networks (RNNs) for detecting sophisticated cyber-attacks. Their system achieved superior performance in identifying advanced persistent threats (APTs), where attack signatures evolve over time. The hierarchical representation of traffic features provided by DBNs complemented the temporal analysis capabilities of RNNs, creating a robust detection mechanism. However, this approach faced challenges in real-time applications due to the computational complexity associated with both DBNs and RNNs, highlighting a common trade-off in hybrid model design.

Building on the need for computational efficiency, ____ introduced a hybrid model that combines Directed Batch Growing Self-Organizing Map (DBGSOM) and Radial Basis Function Neural Network (RBFNN) for anomaly-based intrusion detection. They addressed the limitations of traditional methods by designing DBGSOM, which conserves topology more effectively and reduces network distortions. They further improved the model's accuracy and training speed by integrating DBGSOM with RBFNN. This approach utilizes DBGSOM's dynamic growth mechanism and RBFNN's high precision, significantly outperforming earlier SOM and RBFNN-based models. Their experimental evaluation on three publicly available datasets (NSL-KDD, UNSW-NB15, and CICIDS2017) confirms that their hybrid model surpasses the conventional SOM-RBFNN approach and makes valuable contributions to intrusion detection systems.

Expanding on these earlier frameworks, ____ proposed a hybrid intrusion detection system (IDS) that combined Network Intrusion Detection Systems (NIDS) and Host-based Intrusion Detection Systems (HIDS). This approach addressed limitations in detecting complex attacks, such as Advanced Persistent Threats (APTs), by leveraging a BERT-based methodology to transform host data into numerical formats. The system integrated this numerical representation with network data using a feature-flattening technique, enabling comprehensive analysis. It employed a two-stage collaborative classifier, first filtering benign traffic with a binary classifier and then using a multi-class classifier to identify specific attack types. The system demonstrated significant performance improvements over traditional machine learning models like XGBoost, particularly in detecting challenging attacks such as DoS-LOIC-UDP and DoS-SlowHTTPTest. The use of public datasets, CICIDS 2018 and NDSec-1, further validated the system's effectiveness, with macro average F1 scores showing notable improvements. Future work focused on enhancing accuracy through the inclusion of minority attack classes, data augmentation, and deep learning-based methods.

____ took a different approach by introducing the the FL-SCNN-Bi-LSTM model to improve intrusion detection in Wireless Sensor Networks (WSNs). This hybrid framework combined Federated Learning (FL) with Stacked Convolutional Neural Networks (SCNN) and Bidirectional Long Short-Term Memory networks (Bi-LSTM), addressing privacy concerns by enabling multiple sensor nodes to collaboratively train a global model without sharing raw data. By leveraging advanced feature selection and deep learning methodologies, the model effectively detected sophisticated and previously unknown threats, achieving high performance on WSN-DS and CIC-IDS2017 datasets. However, challenges such as scalability, real-time processing, and adaptability to evolving threats remained, underscoring the need for further optimization and advanced feature selection techniques. Despite these challenges, the model demonstrated superior accuracy and robustness compared to traditional classifiers like SVM and LightGBM.

Further enhancing hybrid model design, ____ integrated transformer-based transfer learning with traditional approaches to tackle imbalanced network traffic in intrusion detection. Their method, IDS-INT, leveraged semantic analysis through a multi-head attention-based transformer model to improve feature representation, addressing the challenges posed by imbalanced and complex datasets. The use of Synthetic Minority Oversampling Technique (SMOTE) ensured effective detection of minority attacks, while CNN and LSTM models incorporated for deep feature extraction. This combination of methods delivered high precision, recall, and F1-scores, outperforming traditional approaches. Additionally, the inclusion of explainable AI provided transparency and trustworthiness, making IDS-INT suitable for real-time and imbalanced network environments. This approach highlighted the importance of balancing innovation with practicality in real-world scenarios.

Finally, ____ introduced FlowTransformer, a transformer-based framework tailored for Network Intrusion Detection Systems (NIDS). By focusing on flow-based data rather than packet-based analysis, the model effectively addressed scalability and privacy concerns associated with traditional methods. FlowTransformer incorporated interchangeable components, such as input encodings and classification heads, offering flexibility for various NIDS configurations. Evaluations on benchmark datasets demonstrated that the choice of classification heads significantly influenced model performance, with a notable reduction in model size by over 50\% while maintaining accuracy. This flexibility and efficiency positioned FlowTransformer as a scalable solution for handling large-scale traffic in modern networks.

Collectively, these studies underscore the potential of hybrid models to enhance intrusion detection systems by combining the strengths of various deep learning techniques. Future research will benefit from exploring broader datasets, refining preprocessing techniques, and optimizing hyperparameters to improve scalability and computational efficiency. As network environments grow increasingly complex, hybrid deep learning models will play a pivotal role in fortifying network and cloud infrastructures against sophisticated cyber threats.

\subsection{Optimization Techniques in IoT Intrusion Detection}
Optimizing the performance of IDS frameworks for IoT security has become a central focus of recent research, especially given the computational constraints of many IoT devices. Gradient-based optimization algorithms, adaptive learning rates, and hyperparameter tuning have been employed to improve both the accuracy and efficiency of machine learning models used in IDS frameworks ____.

One of the key breakthroughs in this area is the work by ____, who proposed an adaptive learning rate adjustment mechanism to improve the convergence speed of deep learning-based IDS models. Their approach reduced the training time by 30\%, while maintaining high detection accuracy, making it suitable for real-time deployment in large-scale IoT environments. Similarly, ____ proposed a hybrid deep learning-based intrusion detection system (IDS) for IoT platforms, which combined unsupervised feature extraction and supervised classification. The model leveraged five unsupervised approaches, including deep autoencoders and stacked models, to effectively reduce data dimensions and extract relevant features. Researchers implemented an automatic hyperparameter tuning method using Bayesian optimization to enhance performance, achieving nearly 100\% accuracy and a false positive rate close to 0\% on the BoT-IoT dataset, along with 99.17\% accuracy and a 0.18\% FPR on the CSE-CIC-IDS2018 dataset. The novelty lay in its unique combination of feature extraction methods, transfer learning, and advanced hyperparameter tuning, which outperformed previous studies in terms of detection rate and classification of a broader range of attack types.

In parallel, metaheuristic algorithms have emerged as powerful tools for optimizing the feature selection process in IDS frameworks. For instance, ____ applied particle swarm optimization (PSO) to identify the most relevant features from IoT traffic data, effectively reducing the dimensionality and computational overhead without compromising detection accuracy. The application of metaheuristic techniques such as PSO and genetic algorithms not only enhances the performance of IDS frameworks but also addresses the unique resource constraints of IoT environments, paving the way for more efficient and scalable solutions.

Based on these foundational techniques, ____ introduced a novel intrusion detection system for IoT networks that leverages Software-Defined Networking (SDN) and optimized random forest models. By partitioning the network into subdomains and employing an ensemble classification model based on decision trees optimized by genetic algorithms, their approach achieved significant improvements in scalability and adaptability. This distributed architecture reduced computational overhead and enabled localized or cooperative intrusion detection, addressing challenges inherent in diverse IoT environments. Experimental evaluations using the NSLKDD and NSW-NB15 datasets demonstrated superior accuracy rates, underscoring the effectiveness of combining SDN with optimized machine learning models. Future directions for this work include the integration of deep learning techniques for feature extraction and dynamic updates to adapt to emerging threats.

Extending these principles to specialized IoT domains, ____ developed an intrusion detection system tailored for the Internet of Vehicles (IoV), focusing on complex attack scenarios like Denial-of-Service, Botnets, and Sniffing. Their methodology incorporated Z-score normalization, regression-based feature selection, and ensemble models such as Random Forest and LightGBM, enhanced through hyperparameter optimization. By combining multiple datasets for training, they achieved a remarkable balance between accuracy and execution time, with notable improvements over traditional approaches. This study highlights the benefits of dataset integration and advanced ensemble modeling, while also identifying future opportunities in deep reinforcement learning and transfer learning to further enhance IDS performance.

Finally, ____ applied a similar optimization driven approach to cloud security by focusing on DDoS attack detection. Using the Honey Badger Optimization (HBO) algorithm for feature selection and a Bi-LSTM classifier, their model achieved impressive accuracy and sensitivity metrics. This work exemplifies the growing trend of integrating optimization algorithms with advanced machine learning models to address the evolving threats in both IoT and cloud environments. By combining Bayesian and Z-Score normalization with HBO and Bi-LSTM, the study effectively bridged the gap between robust feature selection and high-accuracy intrusion detection.

These studies illustrate the diverse strategies being employed to enhance IDS frameworks for IoT and related domains. From adaptive learning rates and hyperparameter tuning to metaheuristic optimization and advanced ensemble modeling, researchers continue to push the boundaries of what is achievable in intrusion detection, paving the way for more resilient and scalable solutions.

\subsection{Attention Mechanisms for Enhancing Model Interpretability}

The use of attention mechanisms in deep learning models has gained considerable traction in IoT security due to their ability to improve feature extraction and model interpretability. Attention mechanisms allow models to focus on the most relevant portions of the input data, thereby enhancing decision-making processes ____.

____ proposed an attention-based CNN to improve the interpretability of IDS models by highlighting the most critical features contributing to the model's decisions. This technique has been particularly effective in identifying subtle attack patterns that traditional models might overlook. By applying attention mechanisms, the model demonstrated improved detection accuracy and reduced false-positive rates in high-traffic IoT environments.

Building on this work, ____ developed an attention-based hybrid model that integrates LSTM networks with DBNs. The attention mechanism enabled the model to prioritize critical time steps in the LSTM sequence, significantly enhancing the detection of complex temporal attack patterns. This approach not only improved detection rates but also provided insights into the model's decision-making process, addressing concerns related to the black-box nature of deep learning models.

The landscape of network intrusion detection in IoT environments has seen significant advancements in recent years, particularly through the application of deep learning and hybrid models. The integration of SOMs, DBNs, Autoencoders, and attention mechanisms has demonstrated great promise in enhancing both the accuracy and interpretability of IDS frameworks. However, challenges related to scalability, real-time processing, and computational efficiency persist, particularly in resource-constrained IoT environments. Future research should focus on optimizing these frameworks for deployment in large-scale IoT networks, while continuing to explore innovative techniques for improving detection accuracy and reducing false-positive rates.

Furthermore, ____ introduced the ADEPT system, an AI-driven solution for DDoS detection in Consumer IoT (CIoT) networks, which combined explainable and optimized deep ensemble learning techniques. The system integrated CNN and LSTM models in an attention-based framework, achieving over 90\% accuracy in detecting both high- and low-volume DDoS attacks while optimizing resource use through Differential Evolution-based pruning and Min-Max quantization. ADEPT incorporated a user interface that leveraged SHAP for global feature importance explanations and risk assessments, enhancing model interpretability and facilitating Human-Computer Interaction (HCI). Evaluations using diverse datasets, such as ToN-IoT and CICIoT-2023, demonstrated the system's adaptability to varying attack scenarios and its efficient deployment on resource-constrained edge devices. The system balanced detection accuracy with computational efficiency, achieving consistent performance across attack types while reducing inference time and memory usage. Future work aimed to optimize the network data parser, integrate pruning during training, and explore human-in-the-loop strategies for improved real-world applicability.

____ introduced an explainable deep federated multi-modal framework for detecting cyber-attacks in Industrial Control Systems (ICS), preserving data privacy while addressing challenges posed by heterogeneous data distributions across clients. The model employed representation learning to transform client data into a latent space, domain adaptation to align diverse client distributions into a mutual representation space, and federated learning to collaboratively train a detection model without data sharing. The SHapley Additive ExPlanations (SHAP) method enhanced explainability by supporting feature importance analysis, which facilitated better decision-making and improved model retraining. Experimental evaluations demonstrated an 8.2\% improvement in F1-score across three clients and a 4.9\% increase when using a reduced feature set, showcasing its adaptability and robustness in varying scenarios. Future work aimed to integrate attention layers for model interpretability without external tools like SHAP and explore enhancements for real-world applicability.

____ introduced an explainable unsupervised anomaly detection framework designed for Industrial Internet of Things (IIoT) systems. The framework addressed challenges posed by limited labeled data and aimed to improve interpretability. By extracting local features through a one-dimensional CNN combined with a Convolutional Block Attention Module (CBAM), the framework captured long-term dependencies using an improved Time Convolutional Network (TCN) and Kolmogorov–Arnold Network (KAN) based Variational Auto-Encoder (VAE). The model trained in an unsupervised manner and utilized Explainable Artificial Intelligence (XAI) techniques, such as SHapley Additive ExPlanations (SHAP), to enhance feature importance analysis. Experimental evaluations showed that the framework outperformed other unsupervised methods, achieving effective anomaly detection in complex industrial systems. The study also discussed potential future work, including semi-supervised methods and adaptation across various domains.

____ proposed an anomaly detection model called Meta-MWDG to effectively solve the problem of multivariate time series anomaly detection in IoT environments. This model combined technologies such as multi-scale discrete wavelet decomposition, dual graph attention networks, and model-agnostic meta-learning (MAML) to improve the precision and generalization of anomaly detection. By integrating multi-scale discrete wavelet decomposition and dual graph attention networks, the model captured temporal dependencies and feature correlations at different scales. The joint optimization strategy using gated recurrent units (GRU) combined with a multi-head self-attention mechanism enhanced the precision of anomaly detection while reducing model parameters. MAML further improved the model’s performance by enabling quick adaptation to new tasks with limited training data. 


\subsection{Challenges in Detecting Unknown Attacks}

The detection of unknown attacks presents significant challenges across various domains, including network security, IoT, and industrial cyber-physical systems. Despite advancements in machine learning and deep learning techniques, several recurring themes emerge from the reviewed approaches, highlighting both solutions and remaining hurdles.

Different studies adopt various methodologies to address unknown attacks. For instance, ____ proposed an ensemble model utilizing multiple classifiers trained on diverse benchmark datasets to mitigate bias and improve detection. Similarly, ____ integrate anomaly detection with abductive reasoning, using Isolation Forest and Answer Set Programming (ASP) to diagnose unknown threats in smart homes. ____ focus on a lightweight anomaly-based IDS, IoT-PRIDS, optimized for resource-constrained IoT environments. These diverse strategies illustrate the ongoing efforts to balance computational efficiency, accuracy, and the ability to detect previously unseen threats.

A common challenge across many studies is the handling of high-dimensional data. For example, ____ emphasized the importance of feature selection to reduce data complexity for accurate multiclass classification. Similarly, ____ addressed class imbalance issues by applying resampling and class weighting techniques to improve detection of both known and unknown attacks. High-dimensional datasets pose difficulties in computational efficiency and can lead to overfitting, which is critical when dealing with unknown or zero-day attacks.

Class imbalance remains a persistent challenge, particularly in datasets with minority or imbalanced classes, as observed in several approaches. ____ tackle this by employing ADASYN, SMOTE, and ENN resampling techniques to balance the training data. ____ proposed an adaptive neural network approach, evolving alongside emerging threats, to detect unknown cyber-attacks effectively. The challenge lies in ensuring that models do not compromise detection performance for imbalanced data, which is crucial for low-resource and distributed environments.

Recent studies emphasize real-time detection and adaptability to changing threat landscapes. ____ highlighted the need for efficient NIDS frameworks capable of handling zero-day attacks while maintaining low false positives through adversarial training and adaptive architectures. Similarly, ____ introduced a communication-efficient method, DaZoo, for distributed IoT environments, which enhances adaptability by reducing communication overhead in real-time applications. The challenge lies in balancing adaptability without compromising accuracy or introducing excessive computational complexity.

Several studies aim to integrate innovative methodologies to improve the detection of unknown attacks. For ____ proposed a hybrid approach for handling Type-A and Type-B unknown attacks using shallow and deep neural networks. Their approach highlighted the need for innovative models that combine lightweight classifiers for improved detection accuracy in IoT environments. However, defining consistent and systematic methodologies for unknown attack detection remains an ongoing challenge.