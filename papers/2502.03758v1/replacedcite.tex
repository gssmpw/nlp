\section{Related Work}
\subsection{Adversarial Attacks}
Adversarial attacks craft malicious noises to mislead target models. White-box attacks like Projected Gradient Descent (PGD) ____, AutoAttack (AA) ____, Carlini\&Wagner (C\&W) ____ and Decoupling Direction and Norm (DDN) ____ craft noises through accessing and utilizing models' intrinsic information like structures and parameters. For black-box attacks like transfer-based attacks and query-based attacks ____, attackers have no access to the models' internal information, and thus attack only by interacting with model's inputs and outputs.
% 经过检查，基本没有大的与以往论文重复的可能性

\subsection{Adversarial Defenses}
Adversarial training methods (ATs) ____ aim at augmenting training examples through adversarial noises for training. However, ATs require modifying parameters of models and crafting noises for training, consuming significant resources. In addition, denoising methods ____ purify images before feeding them into target models. It introduces an additional module for substantially modifying data to remove noises, thereby also consuming great computational resources.

To alleviate this problem, prompt-based defenses has attracted more and more interests due to its efficiency. C-AVP ____ trains pixel-level prompts for each class, and traverses all the prompts for testing. However, it requires high computation costs on datasets with numerous classes. Frequency Prompting (Freq) ____ aims at mitigating the vulnerability of models in the high-frequency domain by a masked prompting strategy. However, it does not explicitly focus on specific semantic patterns, where the semantic pattern which C-AVP focused on is also mixed (\textit{i.e.}, the pixel domain). Differently, \textit{we focus on specific textures and structures by prompting on the amplitude and phase spectra}. Also, our method does not traverse all the prompts for testing, \textit{achieving superior performances efficiently through selecting prompts using predicted labels}.
% 经过检查，基本没有大的与以往论文重复的可能性