@article{sweden_data_resource,
    author = {Ashfaq, Awais and Lönn, Stefan and Nilsson, Håkan and Eriksson, Jonny A and Kwatra, Japneet and Yasin, Zayed M and Slutzman, Jonathan E and Wallenfeldt, Thomas and Obermeyer, Ziad and Anderson, Philip D and Lingman, Markus},
    title = "{Data Resource Profile: Regional healthcare information platform in Halland, Sweden}",
    journal = {International Journal of Epidemiology},
    volume = {49},
    number = {3},
    pages = {738-739f},
    year = {2020},
    month = {01},
    issn = {0300-5771},
    doi = {10.1093/ije/dyz262},
    url = {https://doi.org/10.1093/ije/dyz262},
    eprint = {https://academic.oup.com/ije/article-pdf/49/3/738/33556451/dyz262.pdf},
}

@article{ASHFAQ2023104019,
title = {DEED: DEep Evidential Doctor},
journal = {Artificial Intelligence},
volume = {325},
pages = {104019},
year = {2023},
issn = {0004-3702},
doi = {https://doi.org/10.1016/j.artint.2023.104019},
url = {https://www.sciencedirect.com/science/article/pii/S0004370223001650},
author = {Awais Ashfaq and Markus Lingman and Murat Sensoy and Sławomir Nowaczyk},
keywords = {Deep neural networks, Uncertainty quantification, Risk minimization, Multi-label classification, Electronic health records},
abstract = {As Deep Neural Networks (DNN) make their way into safety-critical decision processes, it becomes imperative to have robust and reliable uncertainty estimates for their predictions for both in-distribution and out-of-distribution (OOD) examples. This is particularly important in real-life high-risk settings such as healthcare, where OOD examples (e.g., patients with previously unseen or rare labels, i.e., diagnoses) are frequent, and an incorrect clinical decision might put human life in danger, in addition to having severe ethical and financial costs. While evidential uncertainty estimates for deep learning have been studied for multi-class problems, research in multi-label settings remains untapped. In this paper, we propose a DEep Evidential Doctor (DEED), which is a novel deterministic approach to estimate multi-label targets along with uncertainty. We achieve this by placing evidential priors over the original likelihood functions and directly estimating the parameters of the evidential distribution using a novel loss function. Additionally, we build a redundancy layer (particularly for high uncertainty and OOD examples) to minimize the risk associated with erroneous decisions based on dubious predictions. We achieve this by learning the mapping between the evidential space and a continuous semantic label embedding space via a recurrent decoder. Thereby inferring, even in the case of OOD examples, reasonably close predictions to avoid catastrophic consequences. We demonstrate the effectiveness of DEED on a digit classification task based on a modified multi-label MNIST dataset, and further evaluate it on a diagnosis prediction task from a real-life electronic health record dataset. We highlight that in terms of prediction scores, our approach is on par with the existing state-of-the-art having a clear advantage of generating reliable, memory and time-efficient uncertainty estimates with minimal changes to any multi-label DNN classifier.}
}

@inproceedings{clinical_bert,
    title = "Publicly Available Clinical {BERT} Embeddings",
    author = "Alsentzer, Emily  and
      Murphy, John  and
      Boag, William  and
      Weng, Wei-Hung  and
      Jindi, Di  and
      Naumann, Tristan  and
      McDermott, Matthew",
    editor = "Rumshisky, Anna  and
      Roberts, Kirk  and
      Bethard, Steven  and
      Naumann, Tristan",
    booktitle = "Proceedings of the 2nd Clinical Natural Language Processing Workshop",
    month = jun,
    year = "2019",
    address = "Minneapolis, Minnesota, USA",
    publisher = "Association for Computational Linguistics",
    url = "https://aclanthology.org/W19-1909",
    doi = "10.18653/v1/W19-1909",
    pages = "72--78",
    abstract = "Contextual word embedding models such as ELMo and BERT have dramatically improved performance for many natural language processing (NLP) tasks in recent months. However, these models have been minimally explored on specialty corpora, such as clinical text; moreover, in the clinical domain, no publicly-available pre-trained BERT models yet exist. In this work, we address this need by exploring and releasing BERT models for clinical text: one for generic clinical text and another for discharge summaries specifically. We demonstrate that using a domain-specific model yields performance improvements on 3/5 clinical NLP tasks, establishing a new state-of-the-art on the MedNLI dataset. We find that these domain-specific models are not as performant on 2 clinical de-identification tasks, and argue that this is a natural consequence of the differences between de-identified source text and synthetically non de-identified task text.",
}

@article{mcinerney2024towards,
  title={Towards Reducing Diagnostic Errors with Interpretable Risk Prediction},
  author={McInerney, Denis Jered and Dickinson, William and Flynn, Lucy and Young, Andrea and Young, Geoffrey and van de Meent, Jan-Willem and Wallace, Byron C},
  journal={arXiv preprint arXiv:2402.10109},
  year={2024}
}

@article{PELUSO2024104576,
title = {Deep learning uncertainty quantification for clinical text classification},
journal = {Journal of Biomedical Informatics},
volume = {149},
pages = {104576},
year = {2024},
issn = {1532-0464},
doi = {https://doi.org/10.1016/j.jbi.2023.104576},
url = {https://www.sciencedirect.com/science/article/pii/S1532046423002976},
author = {Alina Peluso and Ioana Danciu and Hong-Jun Yoon and Jamaludin Mohd Yusof and Tanmoy Bhattacharya and Adam Spannaus and Noah Schaefferkoetter and Eric B. Durbin and Xiao-Cheng Wu and Antoinette Stroup and Jennifer Doherty and Stephen Schwartz and Charles Wiggins and Linda Coyle and Lynne Penberthy and Georgia D. Tourassi and Shang Gao},
keywords = {Selective classification, Deep learning, Abstaining classifier, Text classification, Uncertainty quantification, Accuracy, DNN, CNN, HiSAN, Pathology reports, NCI SEER},
abstract = {Introduction:
Machine learning algorithms are expected to work side-by-side with humans in decision-making pipelines. Thus, the ability of classifiers to make reliable decisions is of paramount importance. Deep neural networks (DNNs) represent the state-of-the-art models to address real-world classification. Although the strength of activation in DNNs is often correlated with the network’s confidence, in-depth analyses are needed to establish whether they are well calibrated.
Method:
In this paper, we demonstrate the use of DNN-based classification tools to benefit cancer registries by automating information extraction of disease at diagnosis and at surgery from electronic text pathology reports from the US National Cancer Institute (NCI) Surveillance, Epidemiology, and End Results (SEER) population-based cancer registries. In particular, we introduce multiple methods for selective classification to achieve a target level of accuracy on multiple classification tasks while minimizing the rejection amount—that is, the number of electronic pathology reports for which the model’s predictions are unreliable. We evaluate the proposed methods by comparing our approach with the current in-house deep learning-based abstaining classifier.
Results:
Overall, all the proposed selective classification methods effectively allow for achieving the targeted level of accuracy or higher in a trade-off analysis aimed to minimize the rejection rate. On in-distribution validation and holdout test data, with all the proposed methods, we achieve on all tasks the required target level of accuracy with a lower rejection rate than the deep abstaining classifier (DAC). Interpreting the results for the out-of-distribution test data is more complex; nevertheless, in this case as well, the rejection rate from the best among the proposed methods achieving 97% accuracy or higher is lower than the rejection rate based on the DAC.
Conclusions:
We show that although both approaches can flag those samples that should be manually reviewed and labeled by human annotators, the newly proposed methods retain a larger fraction and do so without retraining—thus offering a reduced computational cost compared with the in-house deep learning-based abstaining classifier.}
}

@article{johnson2023mimic,
  title={MIMIC-IV, a freely accessible electronic health record dataset},
  author={Johnson, Alistair EW and Bulgarelli, Lucas and Shen, Lu and Gayles, Alvin and Shammout, Ayad and Horng, Steven and Pollard, Tom J and Hao, Sicheng and Moody, Benjamin and Gow, Brian and others},
  journal={Scientific data},
  volume={10},
  number={1},
  pages={1},
  year={2023},
  publisher={Nature Publishing Group UK London},
  url = {https://www.nature.com/articles/s41597-022-01899-x}
}

@article{pollard2018eicu,
  title={The eICU Collaborative Research Database, a freely available multi-center database for critical care research},
  author={Pollard, Tom J and Johnson, Alistair EW and Raffa, Jesse D and Celi, Leo A and Mark, Roger G and Badawi, Omar},
  journal={Scientific data},
  volume={5},
  number={1},
  pages={1--13},
  year={2018},
  publisher={Nature Publishing Group}
}

@INPROCEEDINGS{9207355,
  author={Wang, Ke and Chen, Ning and Chen, Ting},
  booktitle={2020 International Joint Conference on Neural Networks (IJCNN)}, 
  title={Joint Medical Ontology Representation Learning for Healthcare Predictions}, 
  year={2020},
  volume={},
  number={},
  pages={1-7},
  keywords={Medical diagnostic imaging;Ontologies;Hospitals;Training;Predictive models;Task analysis;medical ontology representation;healthcare predictions;joint learning},
  doi={10.1109/IJCNN48605.2020.9207355}}


@article {Chowdhury2023.01.27.23285129,
	author = {Shaika Chowdhury and Yongbin Chen and Andrew Wen and Xiao Ma and Qiying Dai and Yue Yu and Sunyang Fu and Xiaoqian Jiang and Nansu Zong},
	title = {Predicting Physiological Response in Heart Failure Management: A Graph Representation Learning Approach using Electronic Health Records},
	elocation-id = {2023.01.27.23285129},
	year = {2023},
	doi = {10.1101/2023.01.27.23285129},
	publisher = {Cold Spring Harbor Laboratory Press},
	abstract = {Heart failure management is challenging due to the complex and heterogenous nature of its pathophysiology which makes the conventional treatments based on the {\textquotedblleft}one size fits all{\textquotedblright} ideology not suitable. Coupling the longitudinal medical data with novel deep learning and network-based analytics will enable identifying the distinct patient phenotypic characteristics to help individualize the treatment regimen through the accurate prediction of the physiological response. In this study, we develop a graph representation learning framework that integrates the heterogeneous clinical events in the electronic health records (EHR) as graph format data, in which the patient-specific patterns and features are naturally infused for personalized predictions of lab test response. The framework includes a novel Graph Transformer Network that is equipped with a self-attention mechanism to model the underlying spatial interdependencies among the clinical events characterizing the cardiac physiological interactions in the heart failure treatment and a graph neural network (GNN) layer to incorporate the explicit temporality of each clinical event, that would help summarize the therapeutic effects induced on the physiological variables, and subsequently on the patient{\textquoteright}s health status as the heart failure condition progresses over time. We introduce a global attention mask that is computed based on event co-occurrences and is aggregated across all patient records to enhance the guidance of neighbor selection in graph representation learning. We test the feasibility of our model through detailed quantitative and qualitative evaluations on observational EHR data.Competing Interest StatementThe authors have declared no competing interest.Funding StatementNational Institute of Health (NIH) NIGMS (R00GM135488)Author DeclarationsI confirm all relevant ethical guidelines have been followed, and any necessary IRB and/or ethics committee approvals have been obtained.YesThe details of the IRB/oversight body that provided approval or exemption for the research described are given below:Ethics committee/IRB of Mayo Clinic gave ethical approval for this workI confirm that all necessary patient/participant consent has been obtained and the appropriate institutional forms have been archived, and that any patient/participant/sample identifiers included were not known to anyone (e.g., hospital staff, patients or participants themselves) outside the research group so cannot be used to identify individuals.YesI understand that all clinical trials and any other prospective interventional studies must be registered with an ICMJE-approved registry, such as ClinicalTrials.gov. I confirm that any such study reported in the manuscript has been registered and the trial registration ID is provided (note: if posting a prospective study registered retrospectively, please provide a statement in the trial ID field explaining why the study was not registered in advance).YesI have followed all appropriate research reporting guidelines and uploaded the relevant EQUATOR Network research reporting checklist(s) and other pertinent material as supplementary files, if applicable.YesAll data used in the present study are PHI so cannot be made publicly available.},
	URL = {https://www.medrxiv.org/content/early/2023/02/01/2023.01.27.23285129},
	eprint = {https://www.medrxiv.org/content/early/2023/02/01/2023.01.27.23285129.full.pdf},
	journal = {medRxiv}
}

@article{OSSBOLL2024104616,
title = {Graph neural networks for clinical risk prediction based on electronic health records: A survey},
journal = {Journal of Biomedical Informatics},
volume = {151},
pages = {104616},
year = {2024},
issn = {1532-0464},
doi = {https://doi.org/10.1016/j.jbi.2024.104616},
url = {https://www.sciencedirect.com/science/article/pii/S1532046424000340},
author = {Heloísa {Oss Boll} and Ali Amirahmadi and Mirfarid Musavian Ghazani and Wagner Ourique de Morais and Edison Pignaton de Freitas and Amira Soliman and Farzaneh Etminani and Stefan Byttner and Mariana Recamonde-Mendoza},
keywords = {Graph neural networks, Electronic health records, Deep learning, Artificial intelligence, Graph representation learning, Keyword},
abstract = {Objective:
This study aims to comprehensively review the use of graph neural networks (GNNs) for clinical risk prediction based on electronic health records (EHRs). The primary goal is to provide an overview of the state-of-the-art of this subject, highlighting ongoing research efforts and identifying existing challenges in developing effective GNNs for improved prediction of clinical risks.
Methods:
A search was conducted in the Scopus, PubMed, ACM Digital Library, and Embase databases to identify relevant English-language papers that used GNNs for clinical risk prediction based on EHR data. The study includes original research papers published between January 2009 and May 2023.
Results:
Following the initial screening process, 50 articles were included in the data collection. A significant increase in publications from 2020 was observed, with most selected papers focusing on diagnosis prediction (n = 36). The study revealed that the graph attention network (GAT) (n = 19) was the most prevalent architecture, and MIMIC-III (n = 23) was the most common data resource.
Conclusion:
GNNs are relevant tools for predicting clinical risk by accounting for the relational aspects among medical events and entities and managing large volumes of EHR data. Future studies in this area may address challenges such as EHR data heterogeneity, multimodality, and model interpretability, aiming to develop more holistic GNN models that can produce more accurate predictions, be effectively implemented in clinical settings, and ultimately improve patient care.}
}


@article{10.1093/jamia/ocy068,
    author = {Xiao, Cao and Choi, Edward and Sun, Jimeng},
    title = "{Opportunities and challenges in developing deep learning models using electronic health records data: a systematic review}",
    journal = {Journal of the American Medical Informatics Association},
    volume = {25},
    number = {10},
    pages = {1419-1428},
    year = {2018},
    month = {06},
    abstract = "{To conduct a systematic review of deep learning models for electronic health record (EHR) data, and illustrate various deep learning architectures for analyzing different data sources and their target applications. We also highlight ongoing research and identify open challenges in building deep learning models of EHRs.We searched PubMed and Google Scholar for papers on deep learning studies using EHR data published between January 1, 2010, and January 31, 2018. We summarize them according to these axes: types of analytics tasks, types of deep learning model architectures, special challenges arising from health data and tasks and their potential solutions, as well as evaluation strategies.We surveyed and analyzed multiple aspects of the 98 articles we found and identified the following analytics tasks: disease detection/classification, sequential prediction of clinical events, concept embedding, data augmentation, and EHR data privacy. We then studied how deep architectures were applied to these tasks. We also discussed some special challenges arising from modeling EHR data and reviewed a few popular approaches. Finally, we summarized how performance evaluations were conducted for each task.Despite the early success in using deep learning for health analytics applications, there still exist a number of issues to be addressed. We discuss them in detail including data and label availability, the interpretability and transparency of the model, and ease of deployment.}",
    issn = {1527-974X},
    doi = {10.1093/jamia/ocy068},
    url = {https://doi.org/10.1093/jamia/ocy068},
    eprint = {https://academic.oup.com/jamia/article-pdf/25/10/1419/34150605/ocy068.pdf},
}

@inproceedings{10.1145/2975167.2975208,
author = {Suo, Qiuling and Xue, Hongfei and Gao, Jing and Zhang, Aidong},
title = {Risk Factor Analysis Based on Deep Learning Models},
year = {2016},
isbn = {9781450342254},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2975167.2975208},
doi = {10.1145/2975167.2975208},
abstract = {Accurate rendering of diagnosis and prognosis for a disease with respect to a patient requires analysis of complicated, diverse, yet correlated risk factors (RFs). Most of the existing methods for this purpose are based on handcraft RFs by calculating their statistical significance to the disease. However, such methods not only incur intensive labor but also lack capability to discover or infer previously unknown complex relationships and combined effects among correlated RFs.Nowadays, deep learning models have emerged as a hot topic, due to its ability to automatically extract useful and complex features from raw data. In this paper, we explore the effectiveness of deep learning on medical data by building a deep learning based framework to analyze risk factors and study its prediction performance in disease diagnosis. Specifically, we investigate the application of deep learning with a special focus on interpreting the latent features extracted or created from raw data by the model. Experimental results demonstrate that deep learning based methods are able to aggregate features sharing same characteristics, and reduce effects from unimportant and uncorrelated RFs. The abstract features obtained by deep learning methods can represent the essentials of raw inputs, and give a good prediction performance in disease diagnosis.},
booktitle = {Proceedings of the 7th ACM International Conference on Bioinformatics, Computational Biology, and Health Informatics},
pages = {394–403},
numpages = {10},
keywords = {Deep learning, Integrated features, Osteoporosis, Risk factor analysis},
location = {Seattle, WA, USA},
series = {BCB '16}
}

@article{ahmed2023deep,
  title={Deep learning modelling techniques: current progress, applications, advantages, and challenges},
  author={Ahmed, Shams Forruque and Alam, Md Sakib Bin and Hassan, Maruf and Rozbu, Mahtabin Rodela and Ishtiak, Taoseef and Rafa, Nazifa and Mofijur, M and Shawkat Ali, ABM and Gandomi, Amir H},
  journal={Artificial Intelligence Review},
  volume={56},
  number={11},
  pages={13521--13617},
  year={2023},
  publisher={Springer}
}

@article{GAO2024104596,
title = {Clinical natural language processing for secondary uses},
journal = {Journal of Biomedical Informatics},
volume = {150},
pages = {104596},
year = {2024},
issn = {1532-0464},
doi = {https://doi.org/10.1016/j.jbi.2024.104596},
url = {https://www.sciencedirect.com/science/article/pii/S1532046424000145},
author = {Yanjun Gao and Diwakar Mahajan and Ozlem Uzuner and Meliha Yetisgen}
}

@ARTICLE{6472238,
  author={Bengio, Yoshua and Courville, Aaron and Vincent, Pascal},
  journal={IEEE Transactions on Pattern Analysis and Machine Intelligence}, 
  title={Representation Learning: A Review and New Perspectives}, 
  year={2013},
  volume={35},
  number={8},
  pages={1798-1828},
  keywords={Learning systems;Machine learning;Abstracts;Feature extraction;Manifolds;Neural networks;Speech recognition;Deep learning;representation learning;feature learning;unsupervised learning;Boltzmann machine;autoencoder;neural nets},
  doi={10.1109/TPAMI.2013.50}}

@article{SI2021103671,
title = {Deep representation learning of patient data from Electronic Health Records (EHR): A systematic review},
journal = {Journal of Biomedical Informatics},
volume = {115},
pages = {103671},
year = {2021},
issn = {1532-0464},
doi = {https://doi.org/10.1016/j.jbi.2020.103671},
url = {https://www.sciencedirect.com/science/article/pii/S1532046420302999},
author = {Yuqi Si and Jingcheng Du and Zhao Li and Xiaoqian Jiang and Timothy Miller and Fei Wang and W. {Jim Zheng} and Kirk Roberts},
keywords = {Systematic review, Electronic health records, Patient representation, Deep learning},
abstract = {Objectives
Patient representation learning refers to learning a dense mathematical representation of a patient that encodes meaningful information from Electronic Health Records (EHRs). This is generally performed using advanced deep learning methods. This study presents a systematic review of this field and provides both qualitative and quantitative analyses from a methodological perspective.
Methods
We identified studies developing patient representations from EHRs with deep learning methods from MEDLINE, EMBASE, Scopus, the Association for Computing Machinery (ACM) Digital Library, and the Institute of Electrical and Electronics Engineers (IEEE) Xplore Digital Library. After screening 363 articles, 49 papers were included for a comprehensive data collection.
Results
Publications developing patient representations almost doubled each year from 2015 until 2019. We noticed a typical workflow starting with feeding raw data, applying deep learning models, and ending with clinical outcome predictions as evaluations of the learned representations. Specifically, learning representations from structured EHR data was dominant (37 out of 49 studies). Recurrent Neural Networks were widely applied as the deep learning architecture (Long short-term memory: 13 studies, Gated recurrent unit: 11 studies). Learning was mainly performed in a supervised manner (30 studies) optimized with cross-entropy loss. Disease prediction was the most common application and evaluation (31 studies). Benchmark datasets were mostly unavailable (28 studies) due to privacy concerns of EHR data, and code availability was assured in 20 studies.
Discussion & Conclusion
The existing predictive models mainly focus on the prediction of single diseases, rather than considering the complex mechanisms of patients from a holistic review. We show the importance and feasibility of learning comprehensive representations of patient EHR data through a systematic review. Advances in patient representation learning techniques will be essential for powering patient-level EHR analyses. Future work will still be devoted to leveraging the richness and potential of available EHR data. Reproducibility and transparency of reported results will hopefully improve. Knowledge distillation and advanced learning techniques will be exploited to assist the capability of learning patient representation further.}
}

@Article{pmid32269070,
   Author="Gunderson, C. G.  and Bilan, V. P.  and Holleck, J. L.  and Nickerson, P.  and Cherry, B. M.  and Chui, P.  and Bastian, L. A.  and Grimshaw, A. A.  and Rodwin, B. A. ",
   Title="{{P}revalence of harmful diagnostic errors in hospitalised adults: a systematic review and meta-analysis}",
   Journal="BMJ Qual Saf",
   Year="2020",
   Volume="29",
   Number="12",
   Pages="1008--1018",
   Month="Dec",
   url = {https://pubmed.ncbi.nlm.nih.gov/32269070/}
}

@article{Comendador2014PharmabotAP,
author = {Comendador, Benilda Eleonor and Francisco, Bien and Medenilla, Jefferson and Nacion, Sharleen and Serac, Timothy},
year = {2015},
month = {01},
pages = {137-140},
title = {Pharmabot: A Pediatric Generic Medicine Consultant Chatbot},
volume = {3},
journal = {Journal of Automation and Control Engineering},
doi = {10.12720/joace.3.2.137-140},
url = {https://www.joace.org/uploadfile/2014/0801/20140801025000959.pdf}
}

@InProceedings{Ni2017MANDYTA,
author="Ni, Lin
and Lu, Chenhao
and Liu, Niu
and Liu, Jiamou",
editor="Chen, Jian
and Theeramunkong, Thanaruk
and Supnithi, Thepachai
and Tang, Xijin",
title="MANDY: Towards a Smart Primary Care Chatbot Application",
booktitle="Knowledge and Systems Sciences",
year="2017",
publisher="Springer Singapore",
address="Singapore",
pages="38--52",
abstract="The paper reports on a proof-of-concept of {\$}{\$}{\backslash}mathsf {\{}Mandy{\}}{\$}{\$}, a primary care chatbot system created to assist healthcare staffs by automating the patient intake process. The chatbot interacts with a patient by carrying out an interview, understanding their chief complaints in natural language, and submitting reports to the doctors for further analysis. The system provides a mobile-app front end for the patients, a diagnostic unit, and a doctor's interface for accessing patient records. The diagnostic unit consists of three main modules: An analysis engine for understanding patients symptom descriptions, a symptom-to-cause mapper for reasoning about potential causes, and a question generator for deriving further interview questions. The system combines data-driven natural language processing capability with knowledge-driven diagnostic capability. We evaluate our proof-of-concept on benchmark case studies and compare the system with existing medical chatbots.",
isbn="978-981-10-6989-5",
url = {https://link.springer.com/chapter/10.1007/978-981-10-6989-5_4}
}



@article{JUHN2020463,
title = {Artificial intelligence approaches using natural language processing to advance EHR-based clinical research},
journal = {Journal of Allergy and Clinical Immunology},
volume = {145},
number = {2},
pages = {463-469},
year = {2020},
issn = {0091-6749},
doi = {https://doi.org/10.1016/j.jaci.2019.12.897},
url = {https://www.sciencedirect.com/science/article/pii/S0091674919326041},
author = {Young Juhn and Hongfang Liu},
keywords = {EHRs, asthma, allergy, immunology, informatics, data mining, machine learning, natural language processing, algorithms, artificial intelligence},
abstract = {The wide adoption of electronic health record systems in health care generates big real-world data that open new venues to conduct clinical research. As a large amount of valuable clinical information is locked in clinical narratives, natural language processing techniques as an artificial intelligence approach have been leveraged to extract information from clinical narratives in electronic health records. This capability of natural language processing potentially enables automated chart review for identifying patients with distinctive clinical characteristics in clinical care and reduces methodological heterogeneity in defining phenotype, obscuring biological heterogeneity in research concerning allergy, asthma, and immunology. This brief review discusses the current literature on the secondary use of electronic health record data for clinical research concerning allergy, asthma, and immunology and highlights the potential, challenges, and implications of natural language processing techniques.}
}

@Article{pmid35426190,
   Author="Eloranta, S.  and Boman, M. ",
   Title="{{P}redictive models for clinical decision making: {D}eep dives in practical machine learning}",
   Journal="J Intern Med",
   Year="2022",
   Volume="292",
   Number="2",
   Pages="278--295",
   Month="Aug",
   url = {https://pubmed.ncbi.nlm.nih.gov/35426190/}
}


@article{10.1093/jamia/ocaa088,
    author = {Hernandez-Boussard, Tina and Bozkurt, Selen and Ioannidis, John P A and Shah, Nigam H},
    title = "{MINIMAR (MINimum Information for Medical AI Reporting): Developing reporting standards for artificial intelligence in health care}",
    journal = {Journal of the American Medical Informatics Association},
    volume = {27},
    number = {12},
    pages = {2011-2015},
    year = {2020},
    month = {06},
    abstract = "{The rise of digital data and computing power have contributed to significant advancements in artificial intelligence (AI), leading to the use of classification and prediction models in health care to enhance clinical decision-making for diagnosis, treatment and prognosis. However, such advances are limited by the lack of reporting standards for the data used to develop those models, the model architecture, and the model evaluation and validation processes. Here, we present MINIMAR (MINimum Information for Medical AI Reporting), a proposal describing the minimum information necessary to understand intended predictions, target populations, and hidden biases, and the ability to generalize these emerging technologies. We call for a standard to accurately and responsibly report on AI in health care. This will facilitate the design and implementation of these models and promote the development and use of associated clinical decision support tools, as well as manage concerns regarding accuracy and bias.}",
    issn = {1527-974X},
    doi = {10.1093/jamia/ocaa088},
    url = {https://doi.org/10.1093/jamia/ocaa088},
}


@inproceedings{10.1145/3368555.3384457,
author = {Dusenberry, Michael W. and Tran, Dustin and Choi, Edward and Kemp, Jonas and Nixon, Jeremy and Jerfel, Ghassen and Heller, Katherine and Dai, Andrew M.},
title = {Analyzing the Role of Model Uncertainty for Electronic Health Records},
year = {2020},
isbn = {9781450370462},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3368555.3384457},
doi = {10.1145/3368555.3384457},
abstract = {In medicine, both ethical and monetary costs of incorrect predictions can be significant, and the complexity of the problems often necessitates increasingly complex models. Recent work has shown that changing just the random seed is enough for otherwise well-tuned deep neural networks to vary in their individual predicted probabilities. In light of this, we investigate the role of model uncertainty methods in the medical domain. Using RNN ensembles and various Bayesian RNNs, we show that population-level metrics, such as AUC-PR, AUC-ROC, log-likelihood, and calibration error, do not capture model uncertainty. Meanwhile, the presence of significant variability in patient-specific predictions and optimal decisions motivates the need for capturing model uncertainty. Understanding the uncertainty for individual patients is an area with clear clinical impact, such as determining when a model decision is likely to be brittle. We further show that RNNs with only Bayesian embeddings can be a more efficient way to capture model uncertainty compared to ensembles, and we analyze how model uncertainty is impacted across individual input features and patient subgroups.},
booktitle = {Proceedings of the ACM Conference on Health, Inference, and Learning},
pages = {204–213},
numpages = {10},
keywords = {electronic health records, neural networks, uncertainty, Bayesian deep learning},
location = {Toronto, Ontario, Canada},
series = {CHIL '20}
}

@inproceedings{lakshminarayanan2017simple,
  author       = {Balaji Lakshminarayanan and
                  Alexander Pritzel and
                  Charles Blundell},
  editor       = {Isabelle Guyon and
                  Ulrike von Luxburg and
                  Samy Bengio and
                  Hanna M. Wallach and
                  Rob Fergus and
                  S. V. N. Vishwanathan and
                  Roman Garnett},
  title        = {Simple and Scalable Predictive Uncertainty Estimation using Deep Ensembles},
  booktitle    = {Advances in Neural Information Processing Systems 30: Annual Conference
                  on Neural Information Processing Systems 2017, December 4-9, 2017,
                  Long Beach, CA, {USA}},
  pages        = {6402--6413},
  year         = {2017},
  url          = {https://proceedings.neurips.cc/paper/2017/hash/9ef2ed4b7fd2c810847ffa5fa85bce38-Abstract.html},
  timestamp    = {Thu, 21 Jan 2021 15:15:21 +0100},
  biburl       = {https://dblp.org/rec/conf/nips/Lakshminarayanan17.bib},
  bibsource    = {dblp computer science bibliography, https://dblp.org}
}


@article{DBLP:journals/corr/FortunatoBV17,
  author       = {Meire Fortunato and
                  Charles Blundell and
                  Oriol Vinyals},
  title        = {Bayesian Recurrent Neural Networks},
  journal={arXiv preprint arXiv:1704.02798},
  year         = {2017},
  url          = {http://arxiv.org/abs/1704.02798},
  eprinttype    = {arXiv},
  eprint       = {1704.02798},
  timestamp    = {Mon, 13 Aug 2018 16:48:21 +0200},
  biburl       = {https://dblp.org/rec/journals/corr/FortunatoBV17.bib},
  bibsource    = {dblp computer science bibliography, https://dblp.org}
}

@inproceedings{heo2018uncertaintyaware,
  author       = {Jay Heo and
                  Haebeom Lee and
                  Saehoon Kim and
                  Juho Lee and
                  Kwang Joon Kim and
                  Eunho Yang and
                  Sung Ju Hwang},
  editor       = {Samy Bengio and
                  Hanna M. Wallach and
                  Hugo Larochelle and
                  Kristen Grauman and
                  Nicol{\`{o}} Cesa{-}Bianchi and
                  Roman Garnett},
  title        = {Uncertainty-Aware Attention for Reliable Interpretation and Prediction},
  booktitle    = {Advances in Neural Information Processing Systems 31: Annual Conference
                  on Neural Information Processing Systems 2018, NeurIPS 2018, December
                  3-8, 2018, Montr{\'{e}}al, Canada},
  pages        = {917--926},
  year         = {2018},
  url          = {https://proceedings.neurips.cc/paper/2018/hash/285e19f20beded7d215102b49d5c09a0-Abstract.html},
  timestamp    = {Mon, 16 May 2022 15:41:51 +0200},
  biburl       = {https://dblp.org/rec/conf/nips/HeoLKLKYH18.bib},
  bibsource    = {dblp computer science bibliography, https://dblp.org}
}

@article{qiu2019modeling,
  author       = {Riyi Qiu and
                  Yugang Jia and
                  Mirsad Hadzikadic and
                  Michael Dulin and
                  Xi Niu and
                  Xin Wang},
  title        = {Modeling the Uncertainty in Electronic Health Records: a Bayesian
                  Deep Learning Approach},
  journal={arXiv preprint arXiv:1907.06162},
  year         = {2019},
  url          = {http://arxiv.org/abs/1907.06162},
  eprinttype    = {arXiv},
  eprint       = {1907.06162},
  timestamp    = {Wed, 17 Jul 2019 10:27:36 +0200},
  biburl       = {https://dblp.org/rec/journals/corr/abs-1907-06162.bib},
  bibsource    = {dblp computer science bibliography, https://dblp.org}
}

@Article{li2020deep,
author={Li, Yikuan
and Rao, Shishir
and Hassaine, Abdelaali
and Ramakrishnan, Rema
and Canoy, Dexter
and Salimi-Khorshidi, Gholamreza
and Mamouei, Mohammad
and Lukasiewicz, Thomas
and Rahimi, Kazem},
title={Deep Bayesian Gaussian processes for uncertainty estimation in electronic health records},
journal={Scientific Reports},
year={2021},
month={Nov},
day={09},
volume={11},
number={1},
pages={22254},
issn={2045-2322},
doi={10.1038/s41598-021-01680-x},
url={https://doi.org/10.1038/s41598-021-01680-x}
}


@InProceedings{pmlr-v51-wilson16,
  title = 	 {Deep Kernel Learning},
  author = 	 {Wilson, Andrew Gordon and Hu, Zhiting and Salakhutdinov, Ruslan and Xing, Eric P.},
  booktitle = 	 {Proceedings of the 19th International Conference on Artificial Intelligence and Statistics},
  pages = 	 {370--378},
  year = 	 {2016},
  editor = 	 {Gretton, Arthur and Robert, Christian C.},
  volume = 	 {51},
  series = 	 {Proceedings of Machine Learning Research},
  address = 	 {Cadiz, Spain},
  month = 	 {09--11 May},
  publisher =    {PMLR},
  pdf = 	 {http://proceedings.mlr.press/v51/wilson16.pdf},
  url = 	 {https://proceedings.mlr.press/v51/wilson16.html},
  abstract = 	 {We introduce scalable deep kernels, which combine the structural properties of deep learning architectures with the non-parametric flexibility of kernel methods.  Specifically, we transform the inputs of a spectral mixture base kernel with a deep architecture, using local kernel interpolation, inducing points, and structure exploiting (Kronecker and Toeplitz) algebra for a scalable kernel representation.  These closed-form kernels can be used as drop-in replacements for standard kernels, with benefits in expressive power and scalability.  We jointly learn the properties of these kernels through the marginal likelihood of a Gaussian process.  Inference and learning cost O(n) for n training points, and predictions cost O(1) per test point.  On a large and diverse collection of applications, including a dataset with 2 million examples, we show improved performance over scalable Gaussian processes with flexible kernel learning models, and stand-alone deep architectures.}
}

@article{gawlikowski2022survey,
author = {Gawlikowski, Jakob and Tassi, Cedrique Rovile Njieutcheu and Ali, Mohsin and Lee, Jongseok and Humt, Matthias and Feng, Jianxiang and Kruspe, Anna and Triebel, Rudolph and Jung, Peter and Roscher, Ribana and Shahzad, Muhammad and Yang, Wen and Bamler, Richard and Zhu, Xiao Xiang},
title = {A survey of uncertainty in deep neural networks},
year = {2023},
issue_date = {Oct 2023},
publisher = {Kluwer Academic Publishers},
address = {USA},
volume = {56},
number = {Suppl 1},
issn = {0269-2821},
url = {https://doi.org/10.1007/s10462-023-10562-9},
doi = {10.1007/s10462-023-10562-9},
journal = {Artif. Intell. Rev.},
month = jul,
pages = {1513–1589},
numpages = {77},
keywords = {Bayesian deep neural networks, Ensembles, Test-time augmentation, Calibration, Uncertainty}
}

@inproceedings{wen-etal-2020-medal,
    title = "{M}e{DAL}: Medical Abbreviation Disambiguation Dataset for Natural Language Understanding Pretraining",
    author = "Wen, Zhi  and
      Lu, Xing Han  and
      Reddy, Siva",
    editor = "Rumshisky, Anna  and
      Roberts, Kirk  and
      Bethard, Steven  and
      Naumann, Tristan",
    booktitle = "Proceedings of the 3rd Clinical Natural Language Processing Workshop",
    month = nov,
    year = "2020",
    address = "Online",
    publisher = "Association for Computational Linguistics",
    url = "https://aclanthology.org/2020.clinicalnlp-1.15",
    doi = "10.18653/v1/2020.clinicalnlp-1.15",
    pages = "130--135",
    abstract = "One of the biggest challenges that prohibit the use of many current NLP methods in clinical settings is the availability of public datasets. In this work, we present MeDAL, a large medical text dataset curated for abbreviation disambiguation, designed for natural language understanding pre-training in the medical domain. We pre-trained several models of common architectures on this dataset and empirically showed that such pre-training leads to improved performance and convergence speed when fine-tuning on downstream medical tasks.",
}

@article{clinical-longformer,
  author       = {Yikuan Li and
                  Ramsey M. Wehbe and
                  Faraz S. Ahmad and
                  Hanyin Wang and
                  Yuan Luo},
  title        = {A comparative study of pretrained language models for long clinical
                  text},
  journal      = {J. Am. Medical Informatics Assoc.},
  volume       = {30},
  number       = {2},
  pages        = {340--347},
  year         = {2023},
  url          = {https://doi.org/10.1093/jamia/ocac225},
  doi          = {10.1093/JAMIA/OCAC225},
  timestamp    = {Sat, 25 Feb 2023 21:35:15 +0100},
  biburl       = {https://dblp.org/rec/journals/jamia/LiWAWL23.bib},
  bibsource    = {dblp computer science bibliography, https://dblp.org}
}

@article{longformer,
  author       = {Iz Beltagy and
                  Matthew E. Peters and
                  Arman Cohan},
  title        = {Longformer: The Long-Document Transformer},
  journal={arXiv preprint arXiv:2004.05150},
  year         = {2020},
  url          = {https://arxiv.org/abs/2004.05150},
  eprinttype    = {arXiv},
  eprint       = {2004.05150},
  timestamp    = {Tue, 14 Apr 2020 16:40:34 +0200},
  biburl       = {https://dblp.org/rec/journals/corr/abs-2004-05150.bib},
  bibsource    = {dblp computer science bibliography, https://dblp.org}
}

@ARTICLE{Johnson2016-tg,
  title     = "{MIMIC-III}, a freely accessible critical care database",
  author    = "Johnson, Alistair E W and Pollard, Tom J and Shen, Lu and
               Lehman, Li-Wei H and Feng, Mengling and Ghassemi, Mohammad and
               Moody, Benjamin and Szolovits, Peter and Celi, Leo Anthony and
               Mark, Roger G",
  abstract  = "MIMIC-III ('Medical Information Mart for Intensive Care') is a
               large, single-center database comprising information relating to
               patients admitted to critical care units at a large tertiary
               care hospital. Data includes vital signs, medications,
               laboratory measurements, observations and notes charted by care
               providers, fluid balance, procedure codes, diagnostic codes,
               imaging reports, hospital length of stay, survival data, and
               more. The database supports applications including academic and
               industrial research, quality improvement initiatives, and higher
               education coursework.",
  journal   = "Sci. Data",
  publisher = "Springer Science and Business Media LLC",
  volume    =  3,
  number    =  1,
  pages     = "160035",
  month     =  may,
  year      =  2016,
  copyright = "https://creativecommons.org/licenses/by/4.0",
  language  = "en",
  url = {https://www.nature.com/articles/s41597-022-01899-x}
}

@article{mimic-4-medical,
  author       = {Thanh{-}Tung Nguyen and
                  Viktor Schlegel and
                  Abhinav Ramesh Kashyap and
                  Stefan Winkler and
                  Shao{-}Syuan Huang and
                  Jie{-}Jyun Liu and
                  Chih{-}Jen Lin},
  title        = {Mimic-IV-ICD: {A} new benchmark for eXtreme MultiLabel Classification},
  journal={arXiv preprint arXiv:2304.13998},
  year         = {2023},
  url          = {https://doi.org/10.48550/arXiv.2304.13998},
  doi          = {10.48550/ARXIV.2304.13998},
  eprinttype    = {arXiv},
  eprint       = {2304.13998},
  timestamp    = {Thu, 08 Feb 2024 10:56:51 +0100},
  biburl       = {https://dblp.org/rec/journals/corr/abs-2304-13998.bib},
  bibsource    = {dblp computer science bibliography, https://dblp.org}
}

@inproceedings{selective-classification,
  author       = {Yonatan Geifman and
                  Ran El{-}Yaniv},
  editor       = {Isabelle Guyon and
                  Ulrike von Luxburg and
                  Samy Bengio and
                  Hanna M. Wallach and
                  Rob Fergus and
                  S. V. N. Vishwanathan and
                  Roman Garnett},
  title        = {Selective Classification for Deep Neural Networks},
  booktitle    = {Advances in Neural Information Processing Systems 30: Annual Conference
                  on Neural Information Processing Systems 2017, December 4-9, 2017,
                  Long Beach, CA, {USA}},
  pages        = {4878--4887},
  year         = {2017},
  url          = {https://proceedings.neurips.cc/paper/2017/hash/4a8423d5e91fda00bb7e46540e2b0cf1-Abstract.html},
  timestamp    = {Thu, 21 Jan 2021 15:15:21 +0100},
  biburl       = {https://dblp.org/rec/conf/nips/GeifmanE17.bib},
  bibsource    = {dblp computer science bibliography, https://dblp.org}
}

@article{rc-auc,
  author       = {Ran El{-}Yaniv and
                  Yair Wiener},
  title        = {On the Foundations of Noise-free Selective Classification},
  journal      = {J. Mach. Learn. Res.},
  volume       = {11},
  pages        = {1605--1641},
  year         = {2010},
  url          = {https://dl.acm.org/doi/10.5555/1756006.1859904},
  doi          = {10.5555/1756006.1859904},
  timestamp    = {Thu, 02 Jun 2022 13:58:57 +0200},
  biburl       = {https://dblp.org/rec/journals/jmlr/El-YanivW10.bib},
  bibsource    = {dblp computer science bibliography, https://dblp.org}
}

@inproceedings{gal2017deep,
  author    = {Yarin Gal and
               Riashat Islam and
               Zoubin Ghahramani},
  editor    = {Doina Precup and
               Yee Whye Teh},
  title     = {Deep Bayesian Active Learning with Image Data},
  booktitle = {Proceedings of the 34th International Conference on Machine Learning,
               {ICML} 2017, Sydney, NSW, Australia, 6-11 August 2017},
  series    = {Proceedings of Machine Learning Research},
  volume    = {70},
  pages     = {1183--1192},
  publisher = {{PMLR}},
  year      = {2017},
  url       = {http://proceedings.mlr.press/v70/gal17a.html},
  timestamp = {Wed, 29 May 2019 08:41:45 +0200},
  biburl    = {https://dblp.org/rec/conf/icml/GalIG17.bib},
  bibsource = {dblp computer science bibliography, https://dblp.org}
}

@inproceedings{kampffmeyer2016semantic,
  author       = {Michael Kampffmeyer and
                  Arnt{-}B{\o}rre Salberg and
                  Robert Jenssen},
  title        = {Semantic Segmentation of Small Objects and Modeling of Uncertainty
                  in Urban Remote Sensing Images Using Deep Convolutional Neural Networks},
  booktitle    = {2016 {IEEE} Conference on Computer Vision and Pattern Recognition
                  Workshops, {CVPR} Workshops 2016, Las Vegas, NV, USA, June 26 - July
                  1, 2016},
  pages        = {680--688},
  publisher    = {{IEEE} Computer Society},
  year         = {2016},
  url          = {https://doi.org/10.1109/CVPRW.2016.90},
  doi          = {10.1109/CVPRW.2016.90},
  timestamp    = {Fri, 24 Mar 2023 00:02:53 +0100},
  biburl       = {https://dblp.org/rec/conf/cvpr/KampffmeyerSJ16.bib},
  bibsource    = {dblp computer science bibliography, https://dblp.org}
}

@article{houlsby2011bayesian,
  author    = {Neil Houlsby and
               Ferenc Huszar and
               Zoubin Ghahramani and
               M{\'{a}}t{\'{e}} Lengyel},
  title     = {Bayesian Active Learning for Classification and Preference Learning},
  journal={arXiv preprint arXiv:1112.5745},
  year      = {2011},
  url       = {http://arxiv.org/abs/1112.5745},
  archivePrefix = {arXiv},
  eprint    = {1112.5745},
  timestamp = {Mon, 13 Aug 2018 16:48:25 +0200},
  biburl    = {https://dblp.org/rec/journals/corr/abs-1112-5745.bib},
  bibsource = {dblp computer science bibliography, https://dblp.org}
}

@inproceedings{shelmanov-etal-2021-certain,
    title = "How Certain is Your {T}ransformer?",
    author = "Shelmanov, Artem  and
      Tsymbalov, Evgenii  and
      Puzyrev, Dmitri  and
      Fedyanin, Kirill  and
      Panchenko, Alexander  and
      Panov, Maxim",
    booktitle = "Proceedings of the 16th Conference of the European Chapter of the Association for Computational Linguistics: Main Volume",
    month = apr,
    year = "2021",
    address = "Online",
    publisher = "Association for Computational Linguistics",
    url = "https://www.aclweb.org/anthology/2021.eacl-main.157",
    pages = "1833--1840",
    abstract = "In this work, we consider the problem of uncertainty estimation for Transformer-based models. We investigate the applicability of uncertainty estimates based on dropout usage at the inference stage (Monte Carlo dropout). The series of experiments on natural language understanding tasks shows that the resulting uncertainty estimates improve the quality of detection of error-prone instances. Special attention is paid to the construction of computationally inexpensive estimates via Monte Carlo dropout and Determinantal Point Processes.",
}

@inproceedings{lee2018simple,
  title={A simple unified framework for detecting out-of-distribution samples and adversarial attacks},
  author={Lee, Kimin and Lee, Kibok and Lee, Honglak and Shin, Jinwoo},
  booktitle = {Advances in Neural Information Processing Systems 31: Annual Conference
               on Neural Information Processing Systems 2018, NeurIPS 2018, December
               3-8, 2018, Montr{\'{e}}al, Canada},
  pages     = {7167--7177},
  volume={31},
    url       = {https://proceedings.neurips.cc/paper/2018/hash/abdeb6f575ac5c6676b747bca8d09cc2-Abstract.html},
  year={2018}
}

@inproceedings{yoo-etal-2022-detection,
    title = "Detection of Adversarial Examples in Text Classification: Benchmark and Baseline via Robust Density Estimation",
    author = "Yoo, KiYoon  and
      Kim, Jangho  and
      Jang, Jiho  and
      Kwak, Nojun",
    booktitle = "Findings of the Association for Computational Linguistics: ACL 2022",
    month = may,
    year = "2022",
    address = "Dublin, Ireland",
    publisher = "Association for Computational Linguistics",
    url = "https://aclanthology.org/2022.findings-acl.289",
    doi = "10.18653/v1/2022.findings-acl.289",
    pages = "3656--3672",
    abstract = "Word-level adversarial attacks have shown success in NLP models, drastically decreasing the performance of transformer-based models in recent years. As a countermeasure, adversarial defense has been explored, but relatively few efforts have been made to detect adversarial examples. However, detecting adversarial examples may be crucial for automated tasks (e.g. review sentiment analysis) that wish to amass information about a certain population and additionally be a step towards a robust defense system. To this end, we release a dataset for four popular attack methods on four datasets and four models to encourage further research in this field. Along with it, we propose a competitive baseline based on density estimation that has the highest auc on 29 out of 30 dataset-attack-model combinations. The source code is released (https://github.com/bangawayoo/adversarial-examples-in-text-classification).",
}

@article{Rousseeuw84leastmedian,
author = {Rousseeuw, Peter},
year = {1984},
month = {12},
pages = {871-880},
title = {Least Median of Squares Regression},
volume = {79},
journal = {Journal of The American Statistical Association - J AMER STATIST ASSN},
doi = {10.1080/01621459.1984.10477105},
url={https://www.jstor.org/stable/2288718}
}

@inproceedings{Mukhoti2022ddu,
  author       = {Jishnu Mukhoti and
                  Andreas Kirsch and
                  Joost van Amersfoort and
                  Philip H. S. Torr and
                  Yarin Gal},
  title        = {Deep Deterministic Uncertainty: {A} New Simple Baseline},
  booktitle    = {{IEEE/CVF} Conference on Computer Vision and Pattern Recognition,
                  {CVPR} 2023, Vancouver, BC, Canada, June 17-24, 2023},
  pages        = {24384--24394},
  publisher    = {{IEEE}},
  year         = {2023},
  url          = {https://doi.org/10.1109/CVPR52729.2023.02336},
  doi          = {10.1109/CVPR52729.2023.02336},
  timestamp    = {Tue, 29 Aug 2023 15:44:40 +0200},
  biburl       = {https://dblp.org/rec/conf/cvpr/Mukhoti0ATG23.bib},
  bibsource    = {dblp computer science bibliography, https://dblp.org}
}

@inproceedings{Kotelevskii2022nuq,
  author       = {Nikita Kotelevskii and
                  Aleksandr Artemenkov and
                  Kirill Fedyanin and
                  Fedor Noskov and
                  Alexander Fishkov and
                  Artem Shelmanov and
                  Artem Vazhentsev and
                  Aleksandr Petiushko and
                  Maxim Panov},
  editor       = {Sanmi Koyejo and
                  S. Mohamed and
                  A. Agarwal and
                  Danielle Belgrave and
                  K. Cho and
                  A. Oh},
  title        = {Nonparametric Uncertainty Quantification for Single Deterministic
                  Neural Network},
  booktitle    = {Advances in Neural Information Processing Systems 35: Annual Conference
                  on Neural Information Processing Systems 2022, NeurIPS 2022, New Orleans,
                  LA, USA, November 28 - December 9, 2022},
  year         = {2022},
  url          = {http://papers.nips.cc/paper\_files/paper/2022/hash/eb7389b039655fc5c53b11d4a6fa11bc-Abstract-Conference.html},
  timestamp    = {Mon, 08 Jan 2024 16:31:34 +0100},
  biburl       = {https://dblp.org/rec/conf/nips/KotelevskiiAFNF22.bib},
  bibsource    = {dblp computer science bibliography, https://dblp.org}
}

@inproceedings{vazhentsev-etal-2022-uncertainty,
    title = "Uncertainty Estimation of Transformer Predictions for Misclassification Detection",
    author = "Vazhentsev, Artem  and
      Kuzmin, Gleb  and
      Shelmanov, Artem  and
      Tsvigun, Akim  and
      Tsymbalov, Evgenii  and
      Fedyanin, Kirill  and
      Panov, Maxim  and
      Panchenko, Alexander  and
      Gusev, Gleb  and
      Burtsev, Mikhail  and
      Avetisian, Manvel  and
      Zhukov, Leonid",
    editor = "Muresan, Smaranda  and
      Nakov, Preslav  and
      Villavicencio, Aline",
    booktitle = "Proceedings of the 60th Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers)",
    month = may,
    year = "2022",
    address = "Dublin, Ireland",
    publisher = "Association for Computational Linguistics",
    url = "https://aclanthology.org/2022.acl-long.566",
    doi = "10.18653/v1/2022.acl-long.566",
    pages = "8237--8252",
    abstract = "Uncertainty estimation (UE) of model predictions is a crucial step for a variety of tasks such as active learning, misclassification detection, adversarial attack detection, out-of-distribution detection, etc. Most of the works on modeling the uncertainty of deep neural networks evaluate these methods on image classification tasks. Little attention has been paid to UE in natural language processing. To fill this gap, we perform a vast empirical investigation of state-of-the-art UE methods for Transformer models on misclassification detection in named entity recognition and text classification tasks and propose two computationally efficient modifications, one of which approaches or even outperforms computationally intensive methods.",
}

@inproceedings{PodolskiyLBAP21Revisiting,
  author       = {Alexander Podolskiy and
                  Dmitry Lipin and
                  Andrey Bout and
                  Ekaterina Artemova and
                  Irina Piontkovskaya},
  title        = {Revisiting Mahalanobis Distance for Transformer-Based Out-of-Domain
                  Detection},
  booktitle    = {Thirty-Fifth {AAAI} Conference on Artificial Intelligence, {AAAI}
                  2021, Thirty-Third Conference on Innovative Applications of Artificial
                  Intelligence, {IAAI} 2021, The Eleventh Symposium on Educational Advances
                  in Artificial Intelligence, {EAAI} 2021, Virtual Event, February 2-9,
                  2021},
  pages        = {13675--13682},
  publisher    = {{AAAI} Press},
  year         = {2021},
  url          = {https://doi.org/10.1609/aaai.v35i15.17612},
  doi          = {10.1609/AAAI.V35I15.17612},
  timestamp    = {Mon, 04 Sep 2023 16:50:26 +0200},
  biburl       = {https://dblp.org/rec/conf/aaai/PodolskiyLBAP21.bib},
  bibsource    = {dblp computer science bibliography, https://dblp.org}
}

@inproceedings{vazhentsev-etal-2023-hybrid,
    title = "Hybrid Uncertainty Quantification for Selective Text Classification in Ambiguous Tasks",
    author = "Vazhentsev, Artem  and
      Kuzmin, Gleb  and
      Tsvigun, Akim  and
      Panchenko, Alexander  and
      Panov, Maxim  and
      Burtsev, Mikhail  and
      Shelmanov, Artem",
    editor = "Rogers, Anna  and
      Boyd-Graber, Jordan  and
      Okazaki, Naoaki",
    booktitle = "Proceedings of the 61st Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers)",
    month = jul,
    year = "2023",
    address = "Toronto, Canada",
    publisher = "Association for Computational Linguistics",
    url = "https://aclanthology.org/2023.acl-long.652",
    doi = "10.18653/v1/2023.acl-long.652",
    pages = "11659--11681",
    abstract = "Many text classification tasks are inherently ambiguous, which results in automatic systems having a high risk of making mistakes, in spite of using advanced machine learning models. For example, toxicity detection in user-generated content is a subjective task, and notions of toxicity can be annotated according to a variety of definitions that can be in conflict with one another. Instead of relying solely on automatic solutions, moderation of the most difficult and ambiguous cases can be delegated to human workers. Potential mistakes in automated classification can be identified by using uncertainty estimation (UE) techniques. Although UE is a rapidly growing field within natural language processing, we find that state-of-the-art UE methods estimate only epistemic uncertainty and show poor performance, or under-perform trivial methods for ambiguous tasks such as toxicity detection. We argue that in order to create robust uncertainty estimation methods for ambiguous tasks it is necessary to account also for aleatoric uncertainty. In this paper, we propose a new uncertainty estimation method that combines epistemic and aleatoric UE methods. We show that by using our hybrid method, we can outperform state-of-the-art UE methods for toxicity detection and other ambiguous text classification tasks.",
}

@inproceedings{fadeeva2023lm,
    title = "{LM}-Polygraph: Uncertainty Estimation for Language Models",
    author = "Fadeeva, Ekaterina  and
      Vashurin, Roman  and
      Tsvigun, Akim  and
      Vazhentsev, Artem  and
      Petrakov, Sergey  and
      Fedyanin, Kirill  and
      Vasilev, Daniil  and
      Goncharova, Elizaveta  and
      Panchenko, Alexander  and
      Panov, Maxim  and
      Baldwin, Timothy  and
      Shelmanov, Artem",
    editor = "Feng, Yansong  and
      Lefever, Els",
    booktitle = "Proceedings of the 2023 Conference on Empirical Methods in Natural Language Processing: System Demonstrations",
    month = dec,
    year = "2023",
    address = "Singapore",
    publisher = "Association for Computational Linguistics",
    url = "https://aclanthology.org/2023.emnlp-demo.41",
    doi = "10.18653/v1/2023.emnlp-demo.41",
    pages = "446--461",
    abstract = "Recent advancements in the capabilities of large language models (LLMs) have paved the way for a myriad of groundbreaking applications in various fields. However, a significant challenge arises as these models often {``}hallucinate{''}, i.e., fabricate facts without providing users an apparent means to discern the veracity of their statements. Uncertainty estimation (UE) methods are one path to safer, more responsible, and more effective use of LLMs. However, to date, research on UE methods for LLMs has been focused primarily on theoretical rather than engineering contributions. In this work, we tackle this issue by introducing LM-Polygraph, a framework with implementations of a battery of state-of-the-art UE methods for LLMs in text generation tasks, with unified program interfaces in Python. Additionally, it introduces an extendable benchmark for consistent evaluation of UE techniques by researchers, and a demo web application that enriches the standard chat dialog with confidence scores, empowering end-users to discern unreliable responses. LM-Polygraph is compatible with the most recent LLMs, including BLOOMz, LLaMA-2, ChatGPT, and GPT-4, and is designed to support future releases of similarly-styled LMs.",
}

@inproceedings{ren2023outofdistribution,
  author       = {Jie Ren and
                  Jiaming Luo and
                  Yao Zhao and
                  Kundan Krishna and
                  Mohammad Saleh and
                  Balaji Lakshminarayanan and
                  Peter J. Liu},
  title        = {Out-of-Distribution Detection and Selective Generation for Conditional
                  Language Models},
  booktitle    = {The Eleventh International Conference on Learning Representations,
                  {ICLR} 2023, Kigali, Rwanda, May 1-5, 2023},
  publisher    = {OpenReview.net},
  year         = {2023},
  url          = {https://openreview.net/forum?id=kJUS5nD0vPB},
  timestamp    = {Wed, 24 Jul 2024 16:50:33 +0200},
  biburl       = {https://dblp.org/rec/conf/iclr/0006LZKSLL23.bib},
  bibsource    = {dblp computer science bibliography, https://dblp.org}
}

@inbook{deuschel2024role,
author = {Deuschel, Jessica and Foltyn, Andreas and Roscher, Karsten and Scheele, Stephan},
year = {2024},
month = {07},
pages = {95-115},
title = {The Role of Uncertainty Quantification for Trustworthy AI},
isbn = {978-3-031-64831-1},
doi = {10.1007/978-3-031-64832-8_5},
publisher={Springer},
booktitle={Unlocking Artificial Intelligence: From Theory to Applications},
url={https://link.springer.com/chapter/10.1007/978-3-031-64832-8_5}
}

@inproceedings{sensoy2018evidential,
  author       = {Murat Sensoy and
                  Lance M. Kaplan and
                  Melih Kandemir},
  editor       = {Samy Bengio and
                  Hanna M. Wallach and
                  Hugo Larochelle and
                  Kristen Grauman and
                  Nicol{\`{o}} Cesa{-}Bianchi and
                  Roman Garnett},
  title        = {Evidential Deep Learning to Quantify Classification Uncertainty},
  booktitle    = {Advances in Neural Information Processing Systems 31: Annual Conference
                  on Neural Information Processing Systems 2018, NeurIPS 2018, December
                  3-8, 2018, Montr{\'{e}}al, Canada},
  pages        = {3183--3193},
  year         = {2018},
  url          = {https://proceedings.neurips.cc/paper/2018/hash/a981f2b708044d6fb4a71a1463242520-Abstract.html},
  timestamp    = {Mon, 16 May 2022 15:41:51 +0200},
  biburl       = {https://dblp.org/rec/conf/nips/SensoyKK18.bib},
  bibsource    = {dblp computer science bibliography, https://dblp.org}
}


@article{MUJTABA2019494,
title = {Clinical text classification research trends: Systematic literature review and open issues},
journal = {Expert Systems with Applications},
volume = {116},
pages = {494-520},
year = {2019},
issn = {0957-4174},
doi = {https://doi.org/10.1016/j.eswa.2018.09.034},
url = {https://www.sciencedirect.com/science/article/pii/S0957417418306110},
author = {Ghulam Mujtaba and Liyana Shuib and Norisma Idris and Wai Lam Hoo and Ram Gopal Raj and Kamran Khowaja and Khairunisa Shaikh and Henry Friday Nweke},
keywords = {Clinical text classification, Feature engineering, Supervised machine learning, Rule-based text classification, Performance metrics},
}


@article {PMID:31068188,
	Title = {Diagnostic error increases mortality and length of hospital stay in patients presenting through the emergency room},
	Author = {Hautz, Wolf E and Kämmer, Juliane E and Hautz, Stefanie C and Sauter, Thomas C and Zwaan, Laura and Exadaktylos, Aristomenis K and Birrenbach, Tanja and Maier, Volker and Müller, Martin and Schauber, Stefan K},
	DOI = {10.1186/s13049-019-0629-z},
	Number = {1},
	Volume = {27},
	Month = {May},
	Year = {2019},
	Journal = {Scandinavian journal of trauma, resuscitation and emergency medicine},
	ISSN = {1757-7241},
	Pages = {54},
	URL = {https://europepmc.org/articles/PMC6505221},
}


@InProceedings{pmlr-v48-gal16,
  title = 	 {Dropout as a Bayesian Approximation: Representing Model Uncertainty in Deep Learning},
  author = 	 {Gal, Yarin and Ghahramani, Zoubin},
  booktitle = 	 {Proceedings of The 33rd International Conference on Machine Learning},
  pages = 	 {1050--1059},
  year = 	 {2016},
  editor = 	 {Balcan, Maria Florina and Weinberger, Kilian Q.},
  volume = 	 {48},
  series = 	 {Proceedings of Machine Learning Research},
  address = 	 {New York, New York, USA},
  month = 	 {20--22 Jun},
  publisher =    {PMLR},
  pdf = 	 {http://proceedings.mlr.press/v48/gal16.pdf},
  url = 	 {https://proceedings.mlr.press/v48/gal16.html},
  abstract = 	 {Deep learning tools have gained tremendous attention in applied machine learning. However such tools for regression and classification do not capture model uncertainty. In comparison, Bayesian models offer a mathematically grounded framework to reason about model uncertainty, but usually come with a prohibitive computational cost. In this paper we develop a new theoretical framework casting dropout training in deep neural networks (NNs) as approximate Bayesian inference in deep Gaussian processes. A direct result of this theory gives us tools to model uncertainty with dropout NNs – extracting information from existing models that has been thrown away so far. This mitigates the problem of representing uncertainty in deep learning without sacrificing either computational complexity or test accuracy. We perform an extensive study of the properties of dropout’s uncertainty. Various network architectures and non-linearities are assessed on tasks of regression and classification, using MNIST as an example. We show a considerable improvement in predictive log-likelihood and RMSE compared to existing state-of-the-art methods, and finish by using dropout’s uncertainty in deep reinforcement learning.}
}

@inproceedings{stankevich2019predicting,
  title={Predicting depression from essays in Russian},
  author={Stankevich, MA and Kuznetsova, YM and Smirnov, IV and Kiselnikova, NV and Enikolopov, SN},
  booktitle={Komp'juternaja Lingvistika i Intellektual'nye Tehnologii},
  pages={647--657},
  year={2019},
  url={https://www.dialog-21.ru/media/4629/stankevichmaplusetal-125.pdf}
}

@inproceedings{ignatiev2022predicting,
  title={Predicting Depression with Text, Image, and Profile Data from Social Media.},
  author={Ignatiev, Nikolay and Smirnov, Ivan V and Stankevich, Maxim},
  booktitle={ICPRAM},
  pages={753--760},
  year={2022},
  url={https://www.scitepress.org/Papers/2022/109861/109861.pdf}
}

@misc{beck1996beck, title={Beck Depression Inventory–II}, url={http://dx.doi.org/10.1037/t00742-000}, DOI={10.1037/t00742-000}, journal={PsycTESTS Dataset}, publisher={American Psychological Association (APA)}, author={Beck, Aaron T. and Steer, R. A. and Brown, G.}, year={1996} }

@article{kuzmin2024mentaldisordersdetectionera,
      title={Mental Disorders Detection in the Era of Large Language Models}, 
      author={Gleb Kuzmin and Petr Strepetov and Maksim Stankevich and Artem Shelmanov and Ivan Smirnov},
      journal = {arXiv preprint arXiv:2410.07129},
      year={2024},
      eprint={2410.07129},
      archivePrefix={arXiv},
      primaryClass={cs.CL},
      url={https://arxiv.org/abs/2410.07129}, 
}

@article{litvinova2018rusneuropsych,
  title={RusNeuroPsych: open corpus for study relations between author demographic, personality traits, lateral preferences and affect in text},
  author={Litvinova, Tatiana and Ryzhkova, Ekarerina},
  journal={International Journal of Open Information Technologies},
  volume={6},
  number={3},
  pages={32--36},
  year={2018},
  url={http://injoit.ru/index.php/j1/article/viewFile/542/525}
}

@article{bjelland2002validity,
  title={The validity of the Hospital Anxiety and Depression Scale: an updated literature review},
  author={Bjelland, Ingvar and Dahl, Alv A and Haug, Tone Tangen and Neckelmann, Dag},
  journal={Journal of psychosomatic research},
  volume={52},
  number={2},
  pages={69--77},
  year={2002},
  publisher={Elsevier},
  url={https://pubmed.ncbi.nlm.nih.gov/11832252/}
}

@article{medvedeva2021lexical,
  title={Lexical analysis of statements about COVID-19 of people with a high level of somatization},
  author={Medvedeva, Tatyana I and Enikolopov, Sergei N and Boyko, Olga M and Vorontsova, Oksana Yu and Stankevich, Maxim A},
  year={2021},
  volume={14},
  number={3},
  pages={39--64},
  journal={Lomonosov Psychology Journal},
  url={https://msupsyj.ru/en/articles/article/9189/}
}

@book{Derogatis1983SCL90RAS,
  author    = {Derogatis, Leonard R.},
  title     = {{SCL-90-R} Administration, Scoring and Procedures Manual-II for the Revised Version and Other Instruments of the Psychopathology Rating Scale Series},
  year      = {1986},
  publisher = {Clinical Psychometric Research},
  address   = {Towson, MD},
  url={https://api.semanticscholar.org/CorpusID:151843646}
}

@article{yalunin2022rubioroberta,
  author       = {Alexander Yalunin and
                  Alexander S. Nesterov and
                  Dmitriy Umerenkov},
  title        = {RuBioRoBERTa: a pre-trained biomedical language model for Russian
                  language biomedical text mining},
  journal={arXiv preprint arXiv:2204.03951},
  year         = {2022},
  url          = {https://doi.org/10.48550/arXiv.2204.03951},
  doi          = {10.48550/ARXIV.2204.03951},
  eprinttype    = {arXiv},
  eprint       = {2204.03951},
  timestamp    = {Thu, 25 Apr 2024 08:20:10 +0200},
  biburl       = {https://dblp.org/rec/journals/corr/abs-2204-03951.bib},
  bibsource    = {dblp computer science bibliography, https://dblp.org}
}

@article{delta,
  author       = {Tong Luo and
                  Kurt Kramer and
                  Dmitry B. Goldgof and
                  Lawrence O. Hall and
                  Scott Samson and
                  Andrew Remsen and
                  Thomas Hopkins},
  title        = {Active Learning to Recognize Multiple Types of Plankton},
  journal      = {J. Mach. Learn. Res.},
  volume       = {6},
  pages        = {589--613},
  year         = {2005},
  url          = {https://jmlr.org/papers/v6/luo05a.html},
  timestamp    = {Wed, 11 Sep 2024 14:41:28 +0200},
  biburl       = {https://dblp.org/rec/journals/jmlr/LuoKGHSRH05.bib},
  bibsource    = {dblp computer science bibliography, https://dblp.org}
}

@inproceedings{malinin2020uncertainty,
  author       = {Andrey Malinin and
                  Mark J. F. Gales},
  title        = {Uncertainty Estimation in Autoregressive Structured Prediction},
  booktitle    = {9th International Conference on Learning Representations, {ICLR} 2021,
                  Virtual Event, Austria, May 3-7, 2021},
  publisher    = {OpenReview.net},
  year         = {2021},
  url          = {https://openreview.net/forum?id=jN5y-zb5Q7m},
  timestamp    = {Wed, 23 Jun 2021 17:36:39 +0200},
  biburl       = {https://dblp.org/rec/conf/iclr/MalininG21.bib},
  bibsource    = {dblp computer science bibliography, https://dblp.org}
}

@article{yang2022large,
  author       = {Xi Yang and
                  Aokun Chen and
                  Nima M. Pournejatian and
                  Hoo Chang Shin and
                  Kaleb E. Smith and
                  Christopher Parisien and
                  Colin Compas and
                  Cheryl Martin and
                  Anthony B. Costa and
                  Mona G. Flores and
                  Ying Zhang and
                  Tanja Magoc and
                  Christopher A. Harle and
                  Gloria P. Lipori and
                  Duane A. Mitchell and
                  William R. Hogan and
                  Elizabeth A. Shenkman and
                  Jiang Bian and
                  Yonghui Wu},
  title        = {A large language model for electronic health records},
  journal      = {npj Digit. Medicine},
  volume       = {5},
  year         = {2022},
  url          = {https://doi.org/10.1038/s41746-022-00742-2},
  doi          = {10.1038/S41746-022-00742-2},
  timestamp    = {Mon, 28 Aug 2023 21:18:39 +0200},
  biburl       = {https://dblp.org/rec/journals/npjdm/0015CPSSPC0CFZM22.bib},
  bibsource    = {dblp computer science bibliography, https://dblp.org}
}

@inproceedings{xin-etal-2021-art,
    title = "The Art of Abstention: Selective Prediction and Error Regularization for Natural Language Processing",
    author = "Xin, Ji  and
      Tang, Raphael  and
      Yu, Yaoliang  and
      Lin, Jimmy",
    editor = "Zong, Chengqing  and
      Xia, Fei  and
      Li, Wenjie  and
      Navigli, Roberto",
    booktitle = "Proceedings of the 59th Annual Meeting of the Association for Computational Linguistics and the 11th International Joint Conference on Natural Language Processing (Volume 1: Long Papers)",
    month = aug,
    year = "2021",
    address = "Online",
    publisher = "Association for Computational Linguistics",
    url = "https://aclanthology.org/2021.acl-long.84",
    doi = "10.18653/v1/2021.acl-long.84",
    pages = "1040--1051",
    abstract = "In selective prediction, a classifier is allowed to abstain from making predictions on low-confidence examples. Though this setting is interesting and important, selective prediction has rarely been examined in natural language processing (NLP) tasks. To fill this void in the literature, we study in this paper selective prediction for NLP, comparing different models and confidence estimators. We further propose a simple error regularization trick that improves confidence estimation without substantially increasing the computation budget. We show that recent pre-trained transformer models simultaneously improve both model accuracy and confidence estimation effectiveness. We also find that our proposed regularization improves confidence estimation and can be applied to other relevant scenarios, such as using classifier cascades for accuracy{--}efficiency trade-offs. Source code for this paper can be found at \url{https://github.com/castorini/transformers-selective}.",
}


@ARTICLE{Alyahya2019-gq,
  title     = "Health care professionals' knowledge and awareness of the
               {ICD-10} coding system for assigning the cause of perinatal
               deaths in Jordanian hospitals",
  author    = "Alyahya, Mohammad S and Khader, Yousef S",
  abstract  = "OBJECTIVES: There is a lack of studying vital registration and
               disease classification systems in low- and middle-income
               countries. This study aimed to assess health care professionals'
               (HCPs') level of awareness, knowledge, use, and perceived
               barriers of the International Classification of Diseases, 10th
               version (ICD-10) as well as their perceptions of the electronic
               neonatal death registration system. PARTICIPANTS AND METHODS: A
               mixed method approach including descriptive cross-sectional
               quantitative and focus groups with HCPs (physicians, nurses, and
               midwives) was used to collect data from four major selected
               hospitals in Jordan. A total of 16 focus groups were conducted.
               Also, a survey, which included three case studies about the
               ability of nurses and physicians to identify cause of death, was
               completed using structured face-to-face interviews. RESULTS:
               Overall, there was congruency between both the quantitative
               results and the qualitative findings. The majority of nurses and
               physicians in the four hospitals were not familiar with the
               ICD-10 coding system and hence reported minimal use of the
               coding system. Additionally, the majority of HCPs were not aware
               whether or not their departments used the ICD-10 to record
               perinatal mortality. These HCPs identified that lack of
               knowledge, time, staff and support, and an effective and
               comprehensive electronic system that allows physicians to
               accurately choose the exact cause of death were their main
               barriers to the use of the ICD-10 coding system. CONCLUSION: Our
               findings emphasize the importance of developing an effective and
               comprehensive electronic system which allows HCPs to accurately
               report and register all perinatal deaths. This system needs to
               account for the direct and indirect causes of death and for
               contributing factors such as maternal conditions at the time of
               perinatal death. Training HCPs on how to use the system is vital
               for the success and accuracy of the data registration process.",
  journal   = "J. Multidiscip. Healthc.",
  publisher = "Dove Medical Press Ltd.",
  volume    =  12,
  pages     = "149--157",
  month     =  feb,
  year      =  2019,
  keywords  = "ICD-PM; causes of stillbirths; neonatal causes of deaths;
               neonatal deaths; perinatal death registry; perinatal deaths;
               perinatal surveillance system; stillbirths",
  language  = "en",
  url = {https://pmc.ncbi.nlm.nih.gov/articles/PMC6385764/}
}

@article{LIU2023102662,
  author       = {Leibo Liu and
                  {\'{O}}scar P{\'{e}}rez Concha and
                  Anthony N. Nguyen and
                  Vicki Bennett and
                  Louisa Jorm},
  title        = {Automated {ICD} coding using extreme multi-label long text transformer-based
                  models},
  journal      = {Artif. Intell. Medicine},
  volume       = {144},
  pages        = {102662},
  year         = {2023},
  url          = {https://doi.org/10.1016/j.artmed.2023.102662},
  doi          = {10.1016/J.ARTMED.2023.102662},
  timestamp    = {Mon, 05 Feb 2024 20:22:58 +0100},
  biburl       = {https://dblp.org/rec/journals/artmed/LiuCNBJ23.bib},
  bibsource    = {dblp computer science bibliography, https://dblp.org}
}

@MISC{10665-42980,
	title = {ICD-10 : international statistical classification of diseases and related health problems : tenth revision},
	year = {2004},
	pages = {Spanish version, 1st edition published by PAHO as Publicación Científica 544},
	edition = {2nd ed},
	publisher = {'World Health Organization'},
  url = {https://iris.who.int/handle/10665/42980}
}


@Inbook{Zadorozhny2023,
author="Zadorozhny, Karina
and Thoral, Patrick
and Elbers, Paul
and Cin{\`a}, Giovanni",
title="Out-of-Distribution Detection for Medical Applications: Guidelines for Practical Evaluation",
bookTitle="Multimodal AI in Healthcare: A Paradigm Shift in Health Intelligence",
year="2023",
publisher="Springer International Publishing",
address="Cham",
pages="137--153",
abstract="Detection of Out-of-Distribution (OOD) samples in real time is a crucial safety check for deployment of machine learning models in the medical field. Despite a growing number of uncertainty quantification techniques, there is a lack of evaluation guidelines on how to select OOD detection methods in practice. This gap impedes implementation of OOD detection methods for real-world applications. Here, we propose a series of practical considerations and tests to choose the best OOD detector for a specific medical dataset. These guidelines are illustrated on a real-life use case of Electronic Health Records (EHR). Our results can serve as a guide for implementation of OOD detection methods in clinical practice, mitigating risks associated with the use of machine learning models in healthcare.",
isbn="978-3-031-14771-5",
doi="10.1007/978-3-031-14771-5_10",
url="https://doi.org/10.1007/978-3-031-14771-5_10"
}


@article{10.1093/jamia/ocaa269,
    author = {Newman-Griffis, Denis and Divita, Guy and Desmet, Bart and Zirikly, Ayah and Rosé, Carolyn P and Fosler-Lussier, Eric},
    title = {Ambiguity in medical concept normalization: An analysis of types and coverage in electronic health record datasets},
    journal = {Journal of the American Medical Informatics Association},
    volume = {28},
    number = {3},
    pages = {516-532},
    year = {2020},
    month = {12},
    abstract = {Normalizing mentions of medical concepts to standardized vocabularies is a fundamental component of clinical text analysis. Ambiguity—words or phrases that may refer to different concepts—has been extensively researched as part of information extraction from biomedical literature, but less is known about the types and frequency of ambiguity in clinical text. This study characterizes the distribution and distinct types of ambiguity exhibited by benchmark clinical concept normalization datasets, in order to identify directions for advancing medical concept normalization research.We identified ambiguous strings in datasets derived from the 2 available clinical corpora for concept normalization and categorized the distinct types of ambiguity they exhibited. We then compared observed string ambiguity in the datasets with potential ambiguity in the Unified Medical Language System (UMLS) to assess how representative available datasets are of ambiguity in clinical language.We found that \&lt;15\% of strings were ambiguous within the datasets, while over 50\% were ambiguous in the UMLS, indicating only partial coverage of clinical ambiguity. The percentage of strings in common between any pair of datasets ranged from 2\% to only 36\%; of these, 40\% were annotated with different sets of concepts, severely limiting generalization. Finally, we observed 12 distinct types of ambiguity, distributed unequally across the available datasets, reflecting diverse linguistic and medical phenomena.Existing datasets are not sufficient to cover the diversity of clinical concept ambiguity, limiting both training and evaluation of normalization methods for clinical text. Additionally, the UMLS offers important semantic information for building and evaluating normalization methods.Our findings identify 3 opportunities for concept normalization research, including a need for ambiguity-specific clinical datasets and leveraging the rich semantics of the UMLS in new methods and evaluation measures for normalization.},
    issn = {1527-974X},
    doi = {10.1093/jamia/ocaa269},
    url = {https://doi.org/10.1093/jamia/ocaa269},
}


@inproceedings{chen-etal-2023-rare,
    title = "Rare Codes Count: Mining Inter-code Relations for Long-tail Clinical Text Classification",
    author = "Chen, Jiamin  and
      Li, Xuhong  and
      Xi, Junting  and
      Yu, Lei  and
      Xiong, Haoyi",
    editor = "Naumann, Tristan  and
      Ben Abacha, Asma  and
      Bethard, Steven  and
      Roberts, Kirk  and
      Rumshisky, Anna",
    booktitle = "Proceedings of the 5th Clinical Natural Language Processing Workshop",
    month = jul,
    year = "2023",
    address = "Toronto, Canada",
    publisher = "Association for Computational Linguistics",
    url = "https://aclanthology.org/2023.clinicalnlp-1.43",
    doi = "10.18653/v1/2023.clinicalnlp-1.43",
    pages = "403--413",
    abstract = "Multi-label clinical text classification, such as automatic ICD coding, has always been a challenging subject in Natural Language Processing, due to its long, domain-specific documents and long-tail distribution over a large label set. Existing methods adopt different model architectures to encode the clinical notes. Whereas without digging out the useful connections between labels, the model presents a huge gap in predicting performances between rare and frequent codes. In this work, we propose a novel method for further mining the helpful relations between different codes via a relation-enhanced code encoder to improve the rare code performance. Starting from the simple code descriptions, the model reaches comparable, even better performances than models with heavy external knowledge. Our proposed method is evaluated on MIMIC-III, a common dataset in the medical domain. It outperforms the previous state-of-art models on both overall metrics and rare code performances. Moreover, the interpretation results further prove the effectiveness of our methods. Our code is publicly available at \url{https://github.com/jiaminchen-1031/Rare-ICD}.",
}

@inproceedings{Mullenbach2018ExplainablePO,
  title={Explainable Prediction of Medical Codes from Clinical Text},
  author={J. Mullenbach and Sarah Wiegreffe and Jon D. Duke and Jimeng Sun and Jacob Eisenstein},
  booktitle={North American Chapter of the Association for Computational Linguistics},
  year={2018},
  url={https://api.semanticscholar.org/CorpusID:3305987}
}

@article{Shi2017TowardsAICD,
author = {Shi, Haoran and Xie, Pengtao and Hu, Zhiting and Zhang, Ming and Xing, Eric},
year = {2017},
month = {11},
pages = {},
title = {Towards Automated ICD Coding Using Deep Learning},
journal={arXiv preprint arXiv:1711.04075},
doi = {10.48550/arXiv.1711.04075},
url = {https://arxiv.org/abs/1711.04075}
}

@misc{who,
  title = {The top 10 causes of death},
  journal = {World Health Organization},
  url = "https://www.who.int/news-room/fact-sheets/detail/the-top-10-causes-of-death",
  year={2024}
}


@inproceedings{vaswani2023attentionneed,
 author = {Vaswani, Ashish and Shazeer, Noam and Parmar, Niki and Uszkoreit, Jakob and Jones, Llion and Gomez, Aidan N and Kaiser, \L ukasz and Polosukhin, Illia},
 booktitle = {Advances in Neural Information Processing Systems},
 editor = {I. Guyon and U. Von Luxburg and S. Bengio and H. Wallach and R. Fergus and S. Vishwanathan and R. Garnett},
 pages = {},
 publisher = {Curran Associates, Inc.},
 title = {Attention is All you Need},
 url = {https://proceedings.neurips.cc/paper_files/paper/2017/file/3f5ee243547dee91fbd053c1c4a845aa-Paper.pdf},
 volume = {30},
 year = {2017}
}

@article{medqallms,
  author       = {Karan Singhal and
                  Tao Tu and
                  Juraj Gottweis and
                  Rory Sayres and
                  Ellery Wulczyn and
                  Le Hou and
                  Kevin Clark and
                  Stephen Pfohl and
                  Heather Cole{-}Lewis and
                  Darlene Neal and
                  Mike Schaekermann and
                  Amy Wang and
                  Mohamed Amin and
                  Sami Lachgar and
                  Philip Andrew Mansfield and
                  Sushant Prakash and
                  Bradley Green and
                  Ewa Dominowska and
                  Blaise Ag{\"{u}}era y Arcas and
                  Nenad Tomasev and
                  Yun Liu and
                  Renee Wong and
                  Christopher Semturs and
                  S. Sara Mahdavi and
                  Joelle K. Barral and
                  Dale R. Webster and
                  Gregory S. Corrado and
                  Yossi Matias and
                  Shekoofeh Azizi and
                  Alan Karthikesalingam and
                  Vivek Natarajan},
  title        = {Towards Expert-Level Medical Question Answering with Large Language
                  Models},
  journal={arXiv preprint arXiv:2305.09617},
  year         = {2023},
  url          = {https://doi.org/10.48550/arXiv.2305.09617},
  doi          = {10.48550/ARXIV.2305.09617},
  eprinttype    = {arXiv},
  eprint       = {2305.09617},
  timestamp    = {Wed, 06 Nov 2024 15:46:13 +0100},
  biburl       = {https://dblp.org/rec/journals/corr/abs-2305-09617.bib},
  bibsource    = {dblp computer science bibliography, https://dblp.org}
}

@article{sutton2020overview,
  title={An overview of clinical decision support systems: benefits, risks, and strategies for success},
  author={Sutton, Reed T and Pincock, David and Baumgart, Daniel C and Sadowski, Daniel C and Fedorak, Richard N and Kroeker, Karen I},
  journal={NPJ digital medicine},
  volume={3},
  number={1},
  pages={17},
  year={2020},
  publisher={Nature Publishing Group UK London},
  url={https://www.nature.com/articles/s41746-020-0221-y}
}

@article{park2024patient,
  title={Patient-centered radiology reports with generative artificial intelligence: adding value to radiology reporting},
  author={Park, Jiwoo and Oh, Kangrok and Han, Kyunghwa and Lee, Young Han},
  journal={Scientific Reports},
  volume={14},
  number={1},
  pages={13218},
  year={2024},
  publisher={Nature Publishing Group UK London},
  url={https://www.nature.com/articles/s41598-024-63824-z}
}


@Article{Sammani2021,
author={Sammani, Arjan
and Bagheri, Ayoub
and van der Heijden, Peter G. M.
and te Riele, Anneline S. J. M.
and Baas, Annette F.
and Oosters, C. A. J.
and Oberski, Daniel
and Asselbergs, Folkert W.},
title={Automatic multilabel detection of ICD10 codes in Dutch cardiology discharge letters using neural networks},
journal={npj Digital Medicine},
year={2021},
month={Feb},
day={26},
volume={4},
number={1},
pages={37},
issn={2398-6352},
doi={10.1038/s41746-021-00404-9},
url={https://doi.org/10.1038/s41746-021-00404-9}
}


@Article{Lu2022,
author={Lu, Hongxia
and Ehwerhemuepha, Louis
and Rakovski, Cyril},
title={A comparative study on deep learning models for text classification of unstructured medical notes with various levels of class imbalance},
journal={BMC Medical Research Methodology},
year={2022},
month={Jul},
day={02},
volume={22},
number={1},
pages={181},
issn={1471-2288},
doi={10.1186/s12874-022-01665-y},
url={https://doi.org/10.1186/s12874-022-01665-y}
}

@Article{Kompa2021,
author={Kompa, Benjamin
and Snoek, Jasper
and Beam, Andrew L.},
title={Second opinion needed: communicating uncertainty in medical machine learning},
journal={npj Digital Medicine},
year={2021},
month={Jan},
day={05},
volume={4},
number={1},
pages={4},
issn={2398-6352},
doi={10.1038/s41746-020-00367-3},
url={https://doi.org/10.1038/s41746-020-00367-3}
}
