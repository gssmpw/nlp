@inproceedings{10.1145/3368555.3384457,
author = {Dusenberry, Michael W. and Tran, Dustin and Choi, Edward and Kemp, Jonas and Nixon, Jeremy and Jerfel, Ghassen and Heller, Katherine and Dai, Andrew M.},
title = {Analyzing the Role of Model Uncertainty for Electronic Health Records},
year = {2020},
isbn = {9781450370462},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3368555.3384457},
doi = {10.1145/3368555.3384457},
abstract = {In medicine, both ethical and monetary costs of incorrect predictions can be significant, and the complexity of the problems often necessitates increasingly complex models. Recent work has shown that changing just the random seed is enough for otherwise well-tuned deep neural networks to vary in their individual predicted probabilities. In light of this, we investigate the role of model uncertainty methods in the medical domain. Using RNN ensembles and various Bayesian RNNs, we show that population-level metrics, such as AUC-PR, AUC-ROC, log-likelihood, and calibration error, do not capture model uncertainty. Meanwhile, the presence of significant variability in patient-specific predictions and optimal decisions motivates the need for capturing model uncertainty. Understanding the uncertainty for individual patients is an area with clear clinical impact, such as determining when a model decision is likely to be brittle. We further show that RNNs with only Bayesian embeddings can be a more efficient way to capture model uncertainty compared to ensembles, and we analyze how model uncertainty is impacted across individual input features and patient subgroups.},
booktitle = {Proceedings of the ACM Conference on Health, Inference, and Learning},
pages = {204–213},
numpages = {10},
keywords = {electronic health records, neural networks, uncertainty, Bayesian deep learning},
location = {Toronto, Ontario, Canada},
series = {CHIL '20}
}

@article{ASHFAQ2023104019,
title = {DEED: DEep Evidential Doctor},
journal = {Artificial Intelligence},
volume = {325},
pages = {104019},
year = {2023},
issn = {0004-3702},
doi = {https://doi.org/10.1016/j.artint.2023.104019},
url = {https://www.sciencedirect.com/science/article/pii/S0004370223001650},
author = {Awais Ashfaq and Markus Lingman and Murat Sensoy and Sławomir Nowaczyk},
keywords = {Deep neural networks, Uncertainty quantification, Risk minimization, Multi-label classification, Electronic health records},
abstract = {As Deep Neural Networks (DNN) make their way into safety-critical decision processes, it becomes imperative to have robust and reliable uncertainty estimates for their predictions for both in-distribution and out-of-distribution (OOD) examples. This is particularly important in real-life high-risk settings such as healthcare, where OOD examples (e.g., patients with previously unseen or rare labels, i.e., diagnoses) are frequent, and an incorrect clinical decision might put human life in danger, in addition to having severe ethical and financial costs. While evidential uncertainty estimates for deep learning have been studied for multi-class problems, research in multi-label settings remains untapped. In this paper, we propose a DEep Evidential Doctor (DEED), which is a novel deterministic approach to estimate multi-label targets along with uncertainty. We achieve this by placing evidential priors over the original likelihood functions and directly estimating the parameters of the evidential distribution using a novel loss function. Additionally, we build a redundancy layer (particularly for high uncertainty and OOD examples) to minimize the risk associated with erroneous decisions based on dubious predictions. We achieve this by learning the mapping between the evidential space and a continuous semantic label embedding space via a recurrent decoder. Thereby inferring, even in the case of OOD examples, reasonably close predictions to avoid catastrophic consequences. We demonstrate the effectiveness of DEED on a digit classification task based on a modified multi-label MNIST dataset, and further evaluate it on a diagnosis prediction task from a real-life electronic health record dataset. We highlight that in terms of prediction scores, our approach is on par with the existing state-of-the-art having a clear advantage of generating reliable, memory and time-efficient uncertainty estimates with minimal changes to any multi-label DNN classifier.}
}

@article{DBLP:journals/corr/FortunatoBV17,
  author       = {Meire Fortunato and
                  Charles Blundell and
                  Oriol Vinyals},
  title        = {Bayesian Recurrent Neural Networks},
  journal={arXiv preprint arXiv:1704.02798},
  year         = {2017},
  url          = {http://arxiv.org/abs/1704.02798},
  eprinttype    = {arXiv},
  eprint       = {1704.02798},
  timestamp    = {Mon, 13 Aug 2018 16:48:21 +0200},
  biburl       = {https://dblp.org/rec/journals/corr/FortunatoBV17.bib},
  bibsource    = {dblp computer science bibliography, https://dblp.org}
}

@inproceedings{Kotelevskii2022nuq,
  author       = {Nikita Kotelevskii and
                  Aleksandr Artemenkov and
                  Kirill Fedyanin and
                  Fedor Noskov and
                  Alexander Fishkov and
                  Artem Shelmanov and
                  Artem Vazhentsev and
                  Aleksandr Petiushko and
                  Maxim Panov},
  editor       = {Sanmi Koyejo and
                  S. Mohamed and
                  A. Agarwal and
                  Danielle Belgrave and
                  K. Cho and
                  A. Oh},
  title        = {Nonparametric Uncertainty Quantification for Single Deterministic
                  Neural Network},
  booktitle    = {Advances in Neural Information Processing Systems 35: Annual Conference
                  on Neural Information Processing Systems 2022, NeurIPS 2022, New Orleans,
                  LA, USA, November 28 - December 9, 2022},
  year         = {2022},
  url          = {http://papers.nips.cc/paper\_files/paper/2022/hash/eb7389b039655fc5c53b11d4a6fa11bc-Abstract-Conference.html},
  timestamp    = {Mon, 08 Jan 2024 16:31:34 +0100},
  biburl       = {https://dblp.org/rec/conf/nips/KotelevskiiAFNF22.bib},
  bibsource    = {dblp computer science bibliography, https://dblp.org}
}

@inproceedings{Mukhoti2022ddu,
  author       = {Jishnu Mukhoti and
                  Andreas Kirsch and
                  Joost van Amersfoort and
                  Philip H. S. Torr and
                  Yarin Gal},
  title        = {Deep Deterministic Uncertainty: {A} New Simple Baseline},
  booktitle    = {{IEEE/CVF} Conference on Computer Vision and Pattern Recognition,
                  {CVPR} 2023, Vancouver, BC, Canada, June 17-24, 2023},
  pages        = {24384--24394},
  publisher    = {{IEEE}},
  year         = {2023},
  url          = {https://doi.org/10.1109/CVPR52729.2023.02336},
  doi          = {10.1109/CVPR52729.2023.02336},
  timestamp    = {Tue, 29 Aug 2023 15:44:40 +0200},
  biburl       = {https://dblp.org/rec/conf/cvpr/Mukhoti0ATG23.bib},
  bibsource    = {dblp computer science bibliography, https://dblp.org}
}

@article{PELUSO2024104576,
title = {Deep learning uncertainty quantification for clinical text classification},
journal = {Journal of Biomedical Informatics},
volume = {149},
pages = {104576},
year = {2024},
issn = {1532-0464},
doi = {https://doi.org/10.1016/j.jbi.2023.104576},
url = {https://www.sciencedirect.com/science/article/pii/S1532046423002976},
author = {Alina Peluso and Ioana Danciu and Hong-Jun Yoon and Jamaludin Mohd Yusof and Tanmoy Bhattacharya and Adam Spannaus and Noah Schaefferkoetter and Eric B. Durbin and Xiao-Cheng Wu and Antoinette Stroup and Jennifer Doherty and Stephen Schwartz and Charles Wiggins and Linda Coyle and Lynne Penberthy and Georgia D. Tourassi and Shang Gao},
keywords = {Selective classification, Deep learning, Abstaining classifier, Text classification, Uncertainty quantification, Accuracy, DNN, CNN, HiSAN, Pathology reports, NCI SEER},
abstract = {Introduction:
Machine learning algorithms are expected to work side-by-side with humans in decision-making pipelines. Thus, the ability of classifiers to make reliable decisions is of paramount importance. Deep neural networks (DNNs) represent the state-of-the-art models to address real-world classification. Although the strength of activation in DNNs is often correlated with the network’s confidence, in-depth analyses are needed to establish whether they are well calibrated.
Method:
In this paper, we demonstrate the use of DNN-based classification tools to benefit cancer registries by automating information extraction of disease at diagnosis and at surgery from electronic text pathology reports from the US National Cancer Institute (NCI) Surveillance, Epidemiology, and End Results (SEER) population-based cancer registries. In particular, we introduce multiple methods for selective classification to achieve a target level of accuracy on multiple classification tasks while minimizing the rejection amount—that is, the number of electronic pathology reports for which the model’s predictions are unreliable. We evaluate the proposed methods by comparing our approach with the current in-house deep learning-based abstaining classifier.
Results:
Overall, all the proposed selective classification methods effectively allow for achieving the targeted level of accuracy or higher in a trade-off analysis aimed to minimize the rejection rate. On in-distribution validation and holdout test data, with all the proposed methods, we achieve on all tasks the required target level of accuracy with a lower rejection rate than the deep abstaining classifier (DAC). Interpreting the results for the out-of-distribution test data is more complex; nevertheless, in this case as well, the rejection rate from the best among the proposed methods achieving 97% accuracy or higher is lower than the rejection rate based on the DAC.
Conclusions:
We show that although both approaches can flag those samples that should be manually reviewed and labeled by human annotators, the newly proposed methods retain a larger fraction and do so without retraining—thus offering a reduced computational cost compared with the in-house deep learning-based abstaining classifier.}
}

@inproceedings{gal2017deep,
  author    = {Yarin Gal and
               Riashat Islam and
               Zoubin Ghahramani},
  editor    = {Doina Precup and
               Yee Whye Teh},
  title     = {Deep Bayesian Active Learning with Image Data},
  booktitle = {Proceedings of the 34th International Conference on Machine Learning,
               {ICML} 2017, Sydney, NSW, Australia, 6-11 August 2017},
  series    = {Proceedings of Machine Learning Research},
  volume    = {70},
  pages     = {1183--1192},
  publisher = {{PMLR}},
  year      = {2017},
  url       = {http://proceedings.mlr.press/v70/gal17a.html},
  timestamp = {Wed, 29 May 2019 08:41:45 +0200},
  biburl    = {https://dblp.org/rec/conf/icml/GalIG17.bib},
  bibsource = {dblp computer science bibliography, https://dblp.org}
}

@inproceedings{heo2018uncertaintyaware,
  author       = {Jay Heo and
                  Haebeom Lee and
                  Saehoon Kim and
                  Juho Lee and
                  Kwang Joon Kim and
                  Eunho Yang and
                  Sung Ju Hwang},
  editor       = {Samy Bengio and
                  Hanna M. Wallach and
                  Hugo Larochelle and
                  Kristen Grauman and
                  Nicol{\`{o}} Cesa{-}Bianchi and
                  Roman Garnett},
  title        = {Uncertainty-Aware Attention for Reliable Interpretation and Prediction},
  booktitle    = {Advances in Neural Information Processing Systems 31: Annual Conference
                  on Neural Information Processing Systems 2018, NeurIPS 2018, December
                  3-8, 2018, Montr{\'{e}}al, Canada},
  pages        = {917--926},
  year         = {2018},
  url          = {https://proceedings.neurips.cc/paper/2018/hash/285e19f20beded7d215102b49d5c09a0-Abstract.html},
  timestamp    = {Mon, 16 May 2022 15:41:51 +0200},
  biburl       = {https://dblp.org/rec/conf/nips/HeoLKLKYH18.bib},
  bibsource    = {dblp computer science bibliography, https://dblp.org}
}

@inproceedings{kampffmeyer2016semantic,
  author       = {Michael Kampffmeyer and
                  Arnt{-}B{\o}rre Salberg and
                  Robert Jenssen},
  title        = {Semantic Segmentation of Small Objects and Modeling of Uncertainty
                  in Urban Remote Sensing Images Using Deep Convolutional Neural Networks},
  booktitle    = {2016 {IEEE} Conference on Computer Vision and Pattern Recognition
                  Workshops, {CVPR} Workshops 2016, Las Vegas, NV, USA, June 26 - July
                  1, 2016},
  pages        = {680--688},
  publisher    = {{IEEE} Computer Society},
  year         = {2016},
  url          = {https://doi.org/10.1109/CVPRW.2016.90},
  doi          = {10.1109/CVPRW.2016.90},
  timestamp    = {Fri, 24 Mar 2023 00:02:53 +0100},
  biburl       = {https://dblp.org/rec/conf/cvpr/KampffmeyerSJ16.bib},
  bibsource    = {dblp computer science bibliography, https://dblp.org}
}

@inproceedings{lakshminarayanan2017simple,
  author       = {Balaji Lakshminarayanan and
                  Alexander Pritzel and
                  Charles Blundell},
  editor       = {Isabelle Guyon and
                  Ulrike von Luxburg and
                  Samy Bengio and
                  Hanna M. Wallach and
                  Rob Fergus and
                  S. V. N. Vishwanathan and
                  Roman Garnett},
  title        = {Simple and Scalable Predictive Uncertainty Estimation using Deep Ensembles},
  booktitle    = {Advances in Neural Information Processing Systems 30: Annual Conference
                  on Neural Information Processing Systems 2017, December 4-9, 2017,
                  Long Beach, CA, {USA}},
  pages        = {6402--6413},
  year         = {2017},
  url          = {https://proceedings.neurips.cc/paper/2017/hash/9ef2ed4b7fd2c810847ffa5fa85bce38-Abstract.html},
  timestamp    = {Thu, 21 Jan 2021 15:15:21 +0100},
  biburl       = {https://dblp.org/rec/conf/nips/Lakshminarayanan17.bib},
  bibsource    = {dblp computer science bibliography, https://dblp.org}
}

@inproceedings{lee2018simple,
  title={A simple unified framework for detecting out-of-distribution samples and adversarial attacks},
  author={Lee, Kimin and Lee, Kibok and Lee, Honglak and Shin, Jinwoo},
  booktitle = {Advances in Neural Information Processing Systems 31: Annual Conference
               on Neural Information Processing Systems 2018, NeurIPS 2018, December
               3-8, 2018, Montr{\'{e}}al, Canada},
  pages     = {7167--7177},
  volume={31},
    url       = {https://proceedings.neurips.cc/paper/2018/hash/abdeb6f575ac5c6676b747bca8d09cc2-Abstract.html},
  year={2018}
}

@Article{li2020deep,
author={Li, Yikuan
and Rao, Shishir
and Hassaine, Abdelaali
and Ramakrishnan, Rema
and Canoy, Dexter
and Salimi-Khorshidi, Gholamreza
and Mamouei, Mohammad
and Lukasiewicz, Thomas
and Rahimi, Kazem},
title={Deep Bayesian Gaussian processes for uncertainty estimation in electronic health records},
journal={Scientific Reports},
year={2021},
month={Nov},
day={09},
volume={11},
number={1},
pages={22254},
issn={2045-2322},
doi={10.1038/s41598-021-01680-x},
url={https://doi.org/10.1038/s41598-021-01680-x}
}

@InProceedings{pmlr-v48-gal16,
  title = 	 {Dropout as a Bayesian Approximation: Representing Model Uncertainty in Deep Learning},
  author = 	 {Gal, Yarin and Ghahramani, Zoubin},
  booktitle = 	 {Proceedings of The 33rd International Conference on Machine Learning},
  pages = 	 {1050--1059},
  year = 	 {2016},
  editor = 	 {Balcan, Maria Florina and Weinberger, Kilian Q.},
  volume = 	 {48},
  series = 	 {Proceedings of Machine Learning Research},
  address = 	 {New York, New York, USA},
  month = 	 {20--22 Jun},
  publisher =    {PMLR},
  pdf = 	 {http://proceedings.mlr.press/v48/gal16.pdf},
  url = 	 {https://proceedings.mlr.press/v48/gal16.html},
  abstract = 	 {Deep learning tools have gained tremendous attention in applied machine learning. However such tools for regression and classification do not capture model uncertainty. In comparison, Bayesian models offer a mathematically grounded framework to reason about model uncertainty, but usually come with a prohibitive computational cost. In this paper we develop a new theoretical framework casting dropout training in deep neural networks (NNs) as approximate Bayesian inference in deep Gaussian processes. A direct result of this theory gives us tools to model uncertainty with dropout NNs – extracting information from existing models that has been thrown away so far. This mitigates the problem of representing uncertainty in deep learning without sacrificing either computational complexity or test accuracy. We perform an extensive study of the properties of dropout’s uncertainty. Various network architectures and non-linearities are assessed on tasks of regression and classification, using MNIST as an example. We show a considerable improvement in predictive log-likelihood and RMSE compared to existing state-of-the-art methods, and finish by using dropout’s uncertainty in deep reinforcement learning.}
}

@InProceedings{pmlr-v51-wilson16,
  title = 	 {Deep Kernel Learning},
  author = 	 {Wilson, Andrew Gordon and Hu, Zhiting and Salakhutdinov, Ruslan and Xing, Eric P.},
  booktitle = 	 {Proceedings of the 19th International Conference on Artificial Intelligence and Statistics},
  pages = 	 {370--378},
  year = 	 {2016},
  editor = 	 {Gretton, Arthur and Robert, Christian C.},
  volume = 	 {51},
  series = 	 {Proceedings of Machine Learning Research},
  address = 	 {Cadiz, Spain},
  month = 	 {09--11 May},
  publisher =    {PMLR},
  pdf = 	 {http://proceedings.mlr.press/v51/wilson16.pdf},
  url = 	 {https://proceedings.mlr.press/v51/wilson16.html},
  abstract = 	 {We introduce scalable deep kernels, which combine the structural properties of deep learning architectures with the non-parametric flexibility of kernel methods.  Specifically, we transform the inputs of a spectral mixture base kernel with a deep architecture, using local kernel interpolation, inducing points, and structure exploiting (Kronecker and Toeplitz) algebra for a scalable kernel representation.  These closed-form kernels can be used as drop-in replacements for standard kernels, with benefits in expressive power and scalability.  We jointly learn the properties of these kernels through the marginal likelihood of a Gaussian process.  Inference and learning cost O(n) for n training points, and predictions cost O(1) per test point.  On a large and diverse collection of applications, including a dataset with 2 million examples, we show improved performance over scalable Gaussian processes with flexible kernel learning models, and stand-alone deep architectures.}
}

@article{qiu2019modeling,
  author       = {Riyi Qiu and
                  Yugang Jia and
                  Mirsad Hadzikadic and
                  Michael Dulin and
                  Xi Niu and
                  Xin Wang},
  title        = {Modeling the Uncertainty in Electronic Health Records: a Bayesian
                  Deep Learning Approach},
  journal={arXiv preprint arXiv:1907.06162},
  year         = {2019},
  url          = {http://arxiv.org/abs/1907.06162},
  eprinttype    = {arXiv},
  eprint       = {1907.06162},
  timestamp    = {Wed, 17 Jul 2019 10:27:36 +0200},
  biburl       = {https://dblp.org/rec/journals/corr/abs-1907-06162.bib},
  bibsource    = {dblp computer science bibliography, https://dblp.org}
}

@inproceedings{selective-classification,
  author       = {Yonatan Geifman and
                  Ran El{-}Yaniv},
  editor       = {Isabelle Guyon and
                  Ulrike von Luxburg and
                  Samy Bengio and
                  Hanna M. Wallach and
                  Rob Fergus and
                  S. V. N. Vishwanathan and
                  Roman Garnett},
  title        = {Selective Classification for Deep Neural Networks},
  booktitle    = {Advances in Neural Information Processing Systems 30: Annual Conference
                  on Neural Information Processing Systems 2017, December 4-9, 2017,
                  Long Beach, CA, {USA}},
  pages        = {4878--4887},
  year         = {2017},
  url          = {https://proceedings.neurips.cc/paper/2017/hash/4a8423d5e91fda00bb7e46540e2b0cf1-Abstract.html},
  timestamp    = {Thu, 21 Jan 2021 15:15:21 +0100},
  biburl       = {https://dblp.org/rec/conf/nips/GeifmanE17.bib},
  bibsource    = {dblp computer science bibliography, https://dblp.org}
}

@inproceedings{sensoy2018evidential,
  author       = {Murat Sensoy and
                  Lance M. Kaplan and
                  Melih Kandemir},
  editor       = {Samy Bengio and
                  Hanna M. Wallach and
                  Hugo Larochelle and
                  Kristen Grauman and
                  Nicol{\`{o}} Cesa{-}Bianchi and
                  Roman Garnett},
  title        = {Evidential Deep Learning to Quantify Classification Uncertainty},
  booktitle    = {Advances in Neural Information Processing Systems 31: Annual Conference
                  on Neural Information Processing Systems 2018, NeurIPS 2018, December
                  3-8, 2018, Montr{\'{e}}al, Canada},
  pages        = {3183--3193},
  year         = {2018},
  url          = {https://proceedings.neurips.cc/paper/2018/hash/a981f2b708044d6fb4a71a1463242520-Abstract.html},
  timestamp    = {Mon, 16 May 2022 15:41:51 +0200},
  biburl       = {https://dblp.org/rec/conf/nips/SensoyKK18.bib},
  bibsource    = {dblp computer science bibliography, https://dblp.org}
}

@inproceedings{vazhentsev-etal-2023-hybrid,
    title = "Hybrid Uncertainty Quantification for Selective Text Classification in Ambiguous Tasks",
    author = "Vazhentsev, Artem  and
      Kuzmin, Gleb  and
      Tsvigun, Akim  and
      Panchenko, Alexander  and
      Panov, Maxim  and
      Burtsev, Mikhail  and
      Shelmanov, Artem",
    editor = "Rogers, Anna  and
      Boyd-Graber, Jordan  and
      Okazaki, Naoaki",
    booktitle = "Proceedings of the 61st Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers)",
    month = jul,
    year = "2023",
    address = "Toronto, Canada",
    publisher = "Association for Computational Linguistics",
    url = "https://aclanthology.org/2023.acl-long.652",
    doi = "10.18653/v1/2023.acl-long.652",
    pages = "11659--11681",
    abstract = "Many text classification tasks are inherently ambiguous, which results in automatic systems having a high risk of making mistakes, in spite of using advanced machine learning models. For example, toxicity detection in user-generated content is a subjective task, and notions of toxicity can be annotated according to a variety of definitions that can be in conflict with one another. Instead of relying solely on automatic solutions, moderation of the most difficult and ambiguous cases can be delegated to human workers. Potential mistakes in automated classification can be identified by using uncertainty estimation (UE) techniques. Although UE is a rapidly growing field within natural language processing, we find that state-of-the-art UE methods estimate only epistemic uncertainty and show poor performance, or under-perform trivial methods for ambiguous tasks such as toxicity detection. We argue that in order to create robust uncertainty estimation methods for ambiguous tasks it is necessary to account also for aleatoric uncertainty. In this paper, we propose a new uncertainty estimation method that combines epistemic and aleatoric UE methods. We show that by using our hybrid method, we can outperform state-of-the-art UE methods for toxicity detection and other ambiguous text classification tasks.",
}

@inproceedings{yoo-etal-2022-detection,
    title = "Detection of Adversarial Examples in Text Classification: Benchmark and Baseline via Robust Density Estimation",
    author = "Yoo, KiYoon  and
      Kim, Jangho  and
      Jang, Jiho  and
      Kwak, Nojun",
    booktitle = "Findings of the Association for Computational Linguistics: ACL 2022",
    month = may,
    year = "2022",
    address = "Dublin, Ireland",
    publisher = "Association for Computational Linguistics",
    url = "https://aclanthology.org/2022.findings-acl.289",
    doi = "10.18653/v1/2022.findings-acl.289",
    pages = "3656--3672",
    abstract = "Word-level adversarial attacks have shown success in NLP models, drastically decreasing the performance of transformer-based models in recent years. As a countermeasure, adversarial defense has been explored, but relatively few efforts have been made to detect adversarial examples. However, detecting adversarial examples may be crucial for automated tasks (e.g. review sentiment analysis) that wish to amass information about a certain population and additionally be a step towards a robust defense system. To this end, we release a dataset for four popular attack methods on four datasets and four models to encourage further research in this field. Along with it, we propose a competitive baseline based on density estimation that has the highest auc on 29 out of 30 dataset-attack-model combinations. The source code is released (https://github.com/bangawayoo/adversarial-examples-in-text-classification).",
}

