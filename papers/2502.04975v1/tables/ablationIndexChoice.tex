\begin{table}
  \centering
  \small
  \begin{tabular}{c|ccc}
  \toprule
\multicolumn{4}{c}{One weight per layer} \\
\hline
Policy & KT & SPR & $\text{nDCG}$ \\
\hline
random & 0.618 & 0.811 & 0.586 \\
0 & 0.622 & 0.814 & 0.608 \\
0.2 & 0.622 & 0.815 & 0.602 \\
0.4 & 0.625 & 0.817 & 0.606 \\
0.6 & 0.623 & 0.814 & 0.598 \\
0.8 & 0.622 & 0.814 & 0.609 \\
1 & 0.621 & 0.813 & 0.608 \\
\hline
\multicolumn{4}{c}{Multiple weights per layer}\\
\hline
No. weights & KT & SPR & $\text{nDCG}$ \\
\hline
1 & 0.621 & 0.813 & 0.600 \\
2 & 0.634 & 0.824 & 0.608 \\
4 & 0.626 & 0.817 & 0.600 \\
8 & 0.605 & 0.797 & 0.594 \\
\bottomrule
  \end{tabular}
  \caption{Our method $\text{VKDNW}_{\text{single}}$ evaluated for different parameter sampling policies within each trainable layer. Two types of sampling methods are presented. In \textit{One weight per layer} we take 128 initial network layers and either sample one weight per layer randomly or we take for $p=0, 0.2,\dots, 1$ the $p$th index relative within the weight vector. In \textit{Multiple weights per layer} we take 32 initial network layers and sample uniformly $k$ weights for $k=1,2,4,8$. We evaluate Kendall's $\tau$ (KT), Spearman's $\rho$ (SPR) and Normalized Discounted Cumulative Gain with $P=1000$ (nDCG).}
    \label{tab:fim_index_choice}
\end{table}