
\begin{table*}[t]
    \centering    
\begin{tabular}{lc|ccc|ccc|ccc}
\hline
 & & \multicolumn{3}{c|}{CIFAR-10} & \multicolumn{3}{c|}{CIFAR-100} & \multicolumn{3}{c}{ImageNet16-120} \\
 & Type & KT & SPR & $\text{nDCG}$ & KT & SPR & $\text{nDCG}$ & KT & SPR & $\text{nDCG}$ \\
 \hline
 \multicolumn{10}{c}{Simple rankings}\\
 \hline
FLOPs & S & 0.623 & 0.799 & 0.745 & 0.586 & 0.763 & 0.576 & 0.545 & 0.718 & 0.403 \\
GradNorm \cite{abdelfattah2021zero}& S  & 0.328 & 0.438 & 0.509 & 0.341 & 0.451 & 0.278 & 0.310 & 0.418 & 0.265 \\
GraSP \cite{abdelfattah2021zero, wang2020picking}& S  & 0.352 & 0.505 & 0.518 & 0.349 & 0.498 & 0.284 & 0.359 & 0.502 & 0.281 \\
SNIP \cite{abdelfattah2021zero, lee2018snip}& S  & 0.431 & 0.591 & 0.513 & 0.440 & 0.597 & 0.286 & 0.389 & 0.521 & 0.286 \\
SynFlow \cite{abdelfattah2021zero, tanaka2020pruning}& S  & 0.561 & 0.758 & 0.709 & 0.553 & 0.750 & 0.594 & 0.531 & 0.719 & 0.511 \\
Jacov \cite{abdelfattah2021zero}& S  & 0.616 & 0.800 & 0.540 & 0.639 & 0.820 & 0.402 & 0.602 & 0.779 & 0.356 \\
NASWOT \cite{mellor2021neural}& S  & 0.571 & 0.762 & 0.607 & 0.607 & 0.799 & 0.475 & 0.605 & 0.794 & 0.490 \\
ZenNAS \cite{lin2021zen}& S  & 0.102 & 0.103 & 0.120 & 0.079 & 0.072 & 0.115 & 0.091 & 0.109 & 0.073 \\
GradSign\dag~\cite{zhang2021gradsign}& S  & $\cdot$ & 0.765 & $\cdot$ & $\cdot$ & 0.793 & $\cdot$ & $\cdot$ & 0.783 & $\cdot$ \\
ZiCo \cite{li2023zico}& S  & 0.607 & 0.802 & 0.751 & 0.614 & 0.809 & 0.607 & 0.587 & 0.779 & 0.523 \\
TE-NAS \cite{chen2021neural}& A  & 0.536 & 0.722 & 0.602 & 0.537 & 0.723 & 0.327 & 0.523 & 0.709 & 0.330 \\
AZ-NAS \cite{lee2024az}& A  & 0.712 & 0.892 & 0.749 & 0.696 & 0.880 & 0.549 & 0.673 & 0.859 & 0.534 \\
No. of trainable layers ($\aleph$) & S & 0.626 & 0.767 & 0.671 & 0.646 & 0.787 & 0.525 & 0.623 & 0.764 & 0.497 \\
$\text{VKDNW}_{\text{single}}$ (ours)& S  & 0.618 & 0.815 & 0.751 & 0.634 & 0.829 & 0.617 & 0.622 & 0.814 & 0.608 \\
$\text{VKDNW}_{\text{agg}}$ (ours)& A  & \textbf{0.750} & \textbf{0.919} & \textbf{0.785} & \textbf{0.753} & \textbf{0.919} & \textbf{0.636} & \textbf{0.743} & \textbf{0.906} & \textbf{0.664} \\
 \hline
 \multicolumn{11}{c}{Model-driven rankings}\\
 \hline
GRAF \cite{kadlecova2024surprisingly} & A & 0.820 & 0.953 & 0.935 & 0.809 & 0.948 & 0.858 & 0.796 & 0.941 & 0.828 \\
$\text{VKDNW}_{m}$ (ours) & A & 0.647 & 0.831 & 0.750 & 0.636 & 0.821 & 0.602 & 0.611 & 0.798 & 0.575 \\
$\text{(VKDNW+ZCS)}_{m}$ (ours) & A & 0.840 & 0.963 & 0.922 & 0.834 & 0.960 & 0.884 & 0.830 & 0.958 & 0.843 \\
$\text{(VKDNW+ZCS+GRAF)}_{m}$ (ours) & A & \textbf{0.859} & \textbf{0.971} & \textbf{0.946} & \textbf{0.847} & \textbf{0.966} & \textbf{0.895} & \textbf{0.842} & \textbf{0.963} & \textbf{0.867}
\end{tabular}
\caption{Training-free NAS methods in the NAS-Bench-201~\cite{dong2020bench} search space, evaluated on three public datasets. Kendall's $\tau$ (KT), Spearman's $\rho$ (SPR) and Normalized Discounted Cumulative Gain ($\text{nDCG}$) are reported, results are averages of 5 independent runs. The Type column differentiates single (S) and aggregated (A) rankings. Results are reproduced with code published by their authors, except those marked\dag, where results from the original paper are taken. 
%Model-driven rankings are trained on 1024 networks and evaluated on the complement set.
%\vspace{-15pt}
}
\label{tab:table1}
\end{table*}