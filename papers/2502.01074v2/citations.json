[
  {
    "index": 0,
    "papers": [
      {
        "key": "fang2024molinstructions",
        "author": "Yin Fang and Xiaozhuan Liang and Ningyu Zhang and Kangwei Liu and Rui Huang and Zhuo Chen and Xiaohui Fan and Huajun Chen",
        "title": "Mol-Instructions: A Large-Scale Biomolecular Instruction Dataset for Large Language Models"
      }
    ]
  },
  {
    "index": 1,
    "papers": [
      {
        "key": "cao2023instructmol",
        "author": "Cao, He and Liu, Zijing and Lu, Xingyu and Yao, Yuan and Li, Yu",
        "title": "Instructmol: Multi-modal integration for building a versatile and reliable molecular assistant in drug discovery"
      }
    ]
  },
  {
    "index": 2,
    "papers": [
      {
        "key": "weininger1988smiles",
        "author": "Weininger, David",
        "title": "SMILES, a chemical language and information system. 1. Introduction to methodology and encoding rules"
      }
    ]
  },
  {
    "index": 3,
    "papers": [
      {
        "key": "li2024towards",
        "author": "Sihang Li and Zhiyuan Liu and Yanchen Luo and Xiang Wang and Xiangnan He and Kenji Kawaguchi and Tat-Seng Chua and Qi Tian",
        "title": "Towards 3D Molecule-Text Interpretation in Language Models"
      }
    ]
  },
  {
    "index": 4,
    "papers": [
      {
        "key": "chen2024hight",
        "author": "Chen, Yongqiang and Yao, Quanming and Zhang, Juzheng and Cheng, James and Bian, Yatao",
        "title": "HIGHT: Hierarchical Graph Tokenization for Graph-Language Alignment"
      }
    ]
  },
  {
    "index": 5,
    "papers": [
      {
        "key": "cao-etal-2024-presto",
        "author": "Cao, He and Shao, Yanjun and Liu, Zhiyuan and Liu, Zijing and Tang, Xiangru and Yao, Yuan and Li, Yu",
        "title": "{PRESTO}: Progressive Pretraining Enhances Synthetic Chemistry Outcomes"
      }
    ]
  },
  {
    "index": 6,
    "papers": [
      {
        "key": "brown2020language",
        "author": "Brown, Tom and Mann, Benjamin and Ryder, Nick and Subbiah, Melanie and Kaplan, Jared D and Dhariwal, Prafulla and Neelakantan, Arvind and Shyam, Pranav and Sastry, Girish and Askell, Amanda and others",
        "title": "Language models are few-shot learners"
      },
      {
        "key": "achiam2023gpt",
        "author": "Achiam, Josh and Adler, Steven and Agarwal, Sandhini and Ahmad, Lama and Akkaya, Ilge and Aleman, Florencia Leoni and Almeida, Diogo and Altenschmidt, Janko and Altman, Sam and Anadkat, Shyamal and others",
        "title": "Gpt-4 technical report"
      }
    ]
  },
  {
    "index": 7,
    "papers": [
      {
        "key": "alayrac2022flamingo",
        "author": "Alayrac, Jean-Baptiste and Donahue, Jeff and Luc, Pauline and Miech, Antoine and Barr, Iain and Hasson, Yana and Lenc, Karel and Mensch, Arthur and Millican, Katherine and Reynolds, Malcolm and others",
        "title": "Flamingo: a visual language model for few-shot learning"
      },
      {
        "key": "li2022blip",
        "author": "Li, Junnan and Li, Dongxu and Xiong, Caiming and Hoi, Steven",
        "title": "Blip: Bootstrapping language-image pre-training for unified vision-language understanding and generation"
      },
      {
        "key": "li2023blip",
        "author": "Li, Junnan and Li, Dongxu and Savarese, Silvio and Hoi, Steven",
        "title": "Blip-2: Bootstrapping language-image pre-training with frozen image encoders and large language models"
      },
      {
        "key": "dai2023instructblip",
        "author": "Dai, Wenliang and Li, Junnan and Li, D and Tiong, AMH and Zhao, J and Wang, W and Li, B and Fung, P and Hoi, S",
        "title": "Instructblip: Towards general-purpose vision-language models with instruction tuning. arxiv 2023"
      },
      {
        "key": "liu2024visual",
        "author": "Liu, Haotian and Li, Chunyuan and Wu, Qingyang and Lee, Yong Jae",
        "title": "Visual instruction tuning"
      }
    ]
  },
  {
    "index": 8,
    "papers": [
      {
        "key": "zhu2023minigpt4",
        "author": "Zhu, Deyao and Chen, Jun and Shen, Xiaoqian and Li, Xiang and Elhoseiny, Mohamed",
        "title": "Minigpt-4: Enhancing vision-language understanding with advanced large language models"
      },
      {
        "key": "zheng2023minigpt5",
        "author": "Zheng, Kaizhi and He, Xuehai and Wang, Xin Eric",
        "title": "Minigpt-5: Interleaved vision-and-language generation via generative vokens"
      },
      {
        "key": "koh2024generating",
        "author": "Koh, Jing Yu and Fried, Daniel and Salakhutdinov, Russ R",
        "title": "Generating images with multimodal language models"
      }
    ]
  },
  {
    "index": 9,
    "papers": [
      {
        "key": "huh2024platonic",
        "author": "Huh, Minyoung and Cheung, Brian and Wang, Tongzhou and Isola, Phillip",
        "title": "The platonic representation hypothesis"
      }
    ]
  }
]