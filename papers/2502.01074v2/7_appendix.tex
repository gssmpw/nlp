\newpage
\appendix
\onecolumn



\section{Insight for Chemical Community}
We visualize the routing of tokens representing different functional groups through various experts in \method. The results clearly demonstrate that different functional groups activate distinct experts, highlighting that molecular representations differ fundamentally from pure textual semantics. This suggests the existence of intrinsic interactions, particularly between different functional groups, rather than isolated token representations. Our visualization provides strong evidence for this phenomenon, emphasizing the structured nature of molecular representations. This insight offers valuable guidance for future research on integrating molecular representations with LLMs, paving the way for more chemically informed architectures, even more powerful AI chemist.

\begin{figure*}[h]
    \centering
    \includegraphics[width=0.8\linewidth]{figs/moe_analysis.pdf} 
    \vspace{-0.3cm}
    \caption{Illustration of router scores in our MoE framework for tokens representing different functional groups. The numbers correspond to specific tokens associated with 9 visualized functional groups.}
    \label{fig:moe}
    \vspace{-0.3cm}
\end{figure*}

\section{Further Details on Datasets}
\label{app:dataset detail}

\subsection{Comprehensive Datasets Construction}
In this subsection, we provide a comprehensive list of the datasets used in our study along with their respective sources. While datasets vary across different papers, we observed that many are derived and processed from common sources. To clarify this overlap, we summarize the information in Table and provide a detailed analysis below.

\noindent\textbf{(1) USPTO}~\cite{USPTO2020}.
The USPTO (United States Patent and Trademark Office) dataset is a widely used large-scale chemical reaction dataset extracted and processed from US patent texts. It encompasses a diverse range of organic reaction types, including esterification, amidation, halogenation, Suzuki coupling, Buchwald–Hartwig coupling, addition reactions, condensation reactions, and redox reactions. Following~\citet{fang2024molinstructions}, for the \textbf{Forward Reaction Prediction} task, we extract data from USPTO, and split the dataset into 124,384 training instances and 1,000 test instances. Partially following~\citet{cao-etal-2024-presto}, for the \textbf{Catalyst Prediction} and \textbf{Solvent Prediction} tasks, we similarly extract data from USPTO, splitting the training/test sets into 10,079/1,015 and 67,099/7,793, respectively. 

USPTO\_500\_MT~\cite{lu2022unified} is a high-quality multi-task reaction prediction dataset, derived from USPTO through manual processing (including data filtering, deduplication, etc.). This subset retains the 500 most common reaction types. Following~\citet{fang2024molinstructions}, for the \textbf{Reagent Prediction} task, we split the dataset into 124,384 training instances and 1,000 test instances. 

USPTO\_500K~\cite{lu2022unified}, a subset of organic chemical reaction data extracted from USPTO, is widely used in chemoinformatics for the single-step retrosynthesis task. Following~\citet{fang2024molinstructions}, for the \textbf{Retrosynthesis} task, the dataset is divided into 128,684 training instances and 1,000 test instances.

USPTO-Applications~\cite{Lowe2017} is another commonly used subset of USPTO, primarily derived from data samples in patent applications. For the \textbf{Experiment Procedure Prediction} task, following~\citet{liu2024reactxt} (along with the introduction of ORD data), we split the dataset into 80\% training, 10\% validation and 10\% test sets.


\noindent\textbf{(2) ChEBI-20}~\cite{edwards2021text2mol}.
ChEBI-20 is derived from the ChEBI-16~\cite{hastings2016chebi} dataset, with further annotations based on PubChem, forming a comprehensive database of chemical entities in the field of biochemistry. Compared to~\citet{fang2024molinstructions}, ChEBI-20 provides a more extensive and detailed description of chemical compounds. Therefore, for the \textbf{Molecular Captioning} task, following~\citet{cao2023instructmol}, we split the ChEBI-20 dataset (which contains a total of 33,010 instances) into 26,420 training instances, 3295 validation instances and 3,295 test instances.

\noindent\textbf{(3) QM9}~\cite{wu2018moleculenet}.
QM9 is a subset of the GDB-17~\cite{ruddigkeit2012enumeration} database, focusing on quantum chemical property prediction for small organic molecules. It provides comprehensive quantum chemical attributes for molecular compounds, including spatial geometries and electronic properties, such as HOMO/LUMO energy levels obtained via DFT calculations~\cite{kohn1965self}. In this work, we focus on the HOMO/LUMO energy levels of molecules. For the \textbf{Quantum Mechanics Property Prediction} task, following~\citet{fang2024molinstructions}, we split the dataset into 360,113 training instances and 1,987 test instances.

\noindent\textbf{(4) PubChem}~\cite{kim2021pubchem}.
PubChem is the world's largest open-access chemical information database, focusing on chemistry, bioinformatics, and drug discovery. It provides comprehensive support for the retrieval and analysis of molecular compound data. Partiallly following~\citet{li2024towards}, for the \textbf{Molecular Weight Prediction}, \textbf{LogP Prediction}, \textbf{Topological Polar Surface Area Prediction}, and \textbf{Complexity Prediction} tasks, we split the dataset into 11,979/2,000, 10,673/1,785, 11,979/2,000, and 11,979/2,000 for training and test sets, respectively. Additionally, for the \textbf{Description Q\&A} task, also following~\citet{li2024towards}, we split the dataset into 56,885 training instances and 10,000 test instances.

PubChemQC~\cite{maho2015pubchemqc} is a large-scale chemical database generated through ab initio quantum chemistry calculations, with molecular compounds sourced from PubChem. Partially following~\citet{li2024towards}, for the \textbf{SCF Energy Prediction} task, we split the dataset into 623,418 training instances and 77,993 test instances.

\noindent\textbf{(5) RNX Yields}~\cite{schwaller2021prediction}.
The RNX Yields dataset consists of the Buchwald–Hartwig reaction~\cite{ahneman2018predicting} dataset and the Suzuki–Miyaura reaction~\cite{perera2018platform} dataset, both collected through high-throughput experimentation (HTE). It is designed to predict reaction yields for these two reaction types. Following PRESTO, we split the dataset into 9,515 training instances and 200 test instances for \textbf{Yields Regression}.


\noindent\textbf{(6) ORD}~\cite{kearnes2021open}.
The ORD (Open Reaction Database) is an open-source database dedicated to the standardization, storage, and sharing of organic chemistry reaction data, providing a unified data schema with structured text for organic reaction datasets. Following~\citet{liu2024reactxt} (along with the USPTO-Applications), for \textbf{Experimental Procedure Prediction} task, We partition the dataset into 90\% for training, 10\% for validation, and 10\% for testing, based on the total data volume.


Based on the six datasets presented above, we construct a total of 15 tasks spanning four task types, amounting to 1.8 million data samples. To the best of our knowledge, this represents the most comprehensive dataset to date in the molecular domain. The specific partitions are illustrated in Figure~\ref{fig:all datasets} below.
\begin{figure}[h]
    \centering
    \includegraphics[width=1\linewidth]{figs/datasets.pdf}\\[-7pt]
    \caption{\small Domains and Tasks. We choose 15 tasks across 4 domains, including reaction, regression, description and action.}
    \label{fig:all datasets}
\end{figure}


\subsection{Pre-processing}
We encounter several issues during processing the datasets, we list them below and elaborate our solutions.

\noindent\textbf{Unable to obtain SELFIES.} We retrieve the SMILES representation of a molecule with its CID using pubchempy~\cite{PubChemPy} API, for CIDs that cannot be found with \texttt{pubchempy.Compound.from\_cid()}, we discard them. For molecules that cannot be converted to SELFIES, we discard them. This could happen when processing datasets from~\citet{li2024towards}.

\noindent\textbf{Overlapped samples.} 
Datasets from different sources often contain overlapping samples, leading to potential data leakage. For example, solvent and catalyst prediction are subsets of reagent prediction, and molecule description data from 3D-MOIT~\cite{li2024towards} may include samples that overlap with those in ChEBI-20~\cite{edwards2021text2mol}. Such overlaps create scenarios where a sample from one dataset’s training set appears in the test set of another, compromising the reliability of model evaluation. To address this issue, we conduct a thorough dataset comparison to identify potential overlaps and systematically remove any samples from the training sets that also appear in the test sets of other datasets.

\subsection{Evaluation Metrics} 

\textbf{Exact Match.} The Exact Match Score evaluates whether two SMILES strings unequivocally correspond to the same molecular structure. Specifically, a score of 1 is assigned when both SMILES strings are identical following normalization, indicating they represent the same molecule. Meanwhile, a score of 0 is given when the normalized SMILES strings differ, signifying that they correspond to distinct molecules.

\textbf{Levenshtein Score.} The Levenshtein Score scores the smallest number of edit operations needed to transform one SMILES string into another. These edit operations typically encompass: (1) Insertion, which involves adding a character at a specific position; (2) Deletion, the removal of a character from a designated location; and (3) Substitution, replacing a character at a particular position with a different one.

\textbf{MACCS Similarity.} Within cheminformatics, MACCS Similarity is used to assess and compare the structural likeness of molecules. This approach is grounded in MACCS keys, which are a standardized set of structural descriptors developed by the Molecular ACCess System. These keys capture and represent essential molecular substructures. To determine the similarity between two molecules, the method evaluates the presence or absence of these predefined structural features.

\textbf{RDK Similarity.} The RDK Similarity generally involves evaluating and quantifying the similarity between molecules by utilizing fingerprints produced with RDKit.

\textbf{Morgan Similarity.} Morgan Similarity is used to evaluate and measure the structural resemblance between molecules by utilizing Morgan fingerprints as its foundational basis.

\textbf{Mean Absolute Error (MAE)}. The MAE quantifies the average absolute deviations between predicted results and actual values, which provides a straightforward metric for assessing the accuracy of predictive models by averaging the absolute differences across all instances.

{$\mathbf{R}^2$}. The $R^2$ metric scores the proportion of variability in the target variable that can be explained by the model's predictors. It can be served as an indicator of the model's explanatory strength, reflecting how well the observed data points are captured by the regression model.

\section{Further Details on Model Implementation}
\label{app:model imp}
\subsection{Graph Tokenizer}
\noindent\textbf{Molecule to graph conversion.} Graph neural network is widely used in many scenarios like traffic~\cite{zhang2025efficient}, society relationships~\cite{zhang2024graph}, and also molecules~\cite{sun2022does,sun2024graph}. Following vanilla setting, we utilize RDKit~\cite{landrum2013rdkit} to transform SELFIES into graph structure in our experiments. For tasks involving a single molecule as input, the molecule is converted directly. For tasks requiring multiple molecules as input, only the first molecule in the input sequence is converted into a graph. Our model does not incorporate multi-graph understanding; instead, it processes both the graph and SELFIES representation of the first molecule, while only the SELFIES representations are provided for the remaining molecules. Meanwhile, since MoleculeSTM~\cite{liu2023multi} incorporates additional molecular graph-text contrastive training compared to GraphMVP~\cite{liupre}, leading to improved multimodal model training efficiency, we adopt MoleculeSTM as the graph encoder.

\noindent\textbf{Insertion}. For graph tokens $\mathbf{H}_G=\{H_1, H_2,\dots,H_n\}$ after projection, we always insert the graph token at the beginning of user instruction $\mathbf{X_I}$. The input instruction will be updated to the concatenation of $\{\mathbf{H}_G, \mathbf{X}_I\}$.

\subsection{Multimodal Alignment}
To balance the molecular graph and text modalities while ensuring training efficiency, we employ a single-layer linear projector in Stage 1. Following~\citet{liu2023multi}, we carefully filter PubChem to obtain 310K+ graph-text pairs and convert them into instruction-following data for pretraining. The alignment between the molecular graph and text modalities is enhanced solely by adjusting the parameters of the single-layer linear projector.

\subsection{Parameter-efficient Fine-tuning (PEFT)}
\label{sec:peft}
As the size of recent models increases rapidly, updating the models in parameter-efficient ways becomes crucial.
PEFT \cite{ding2023parameter,wang2023parameter,zhai2023parameter,yu2024visual,wang2024lion} methods diverge from the conventional approach of fine-tuning the entire pre-trained model, instead only learning a few additional parameters for knowledge transfer.
Due to the redundancies of attention matrix in LLMs' pre-trained parameter $\mathcal{W}_0$, we hope to implement the low-rank approximation (LoRA) of the tensor $\mathcal{W}_0$ to get the new learnable weight tensor $\Delta \mathcal{W} \in \mathbb{R}^{m \times n}$ for downstream knowledge transfer. $\Delta \mathcal{W}$ can be constructed with the product of two lower-dimensional matrices $\mathcal{A} \in \mathbb{R}^{m \times r}$ and $\mathcal{B} \in \mathbb{R}^{r \times n}$, where $r \ll \min(m, n)$. The goal is to find $\mathcal{A}$ and $\mathcal{B}$ that minimize the approximation error between $W$ and $\mathcal{A}\mathcal{B}$. A common objective is the Frobenius norm, leading to the minimization problem
$\min_{\mathcal{A}, \mathcal{B}} \, \| \Delta \mathcal{W} - \mathcal{A} \mathcal{B} \|_F^2$.
Here, $\mathcal{A}$ and $\mathcal{B}$ together have significantly fewer parameters than $\Delta \mathcal{W}$ itself, making $\mathcal{A}\mathcal{B}$ an effective rank-$r$ approximation. Therefore, the backward propagation on the downstream fine-tuning data $\mathcal{D}$ can be expressed as:
\begin{equation}
\nabla_{\boldsymbol{\Delta{\mathcal{W}}}} = \frac{\partial \mathcal{L}\left( \mathcal{D};\boldsymbol{\mathcal{W}}_0 + \boldsymbol{\Delta{\mathcal{W}}} \right)}{\partial \boldsymbol{\Delta{\mathcal{W}}}}
\end{equation}

However, in Figure \ref{fig:grad norm}, we observe that the conventional LoRA approach can encounter intricate divergences in the middle to later phases of training, primarily due to a gradual increase in gradient norm values. Motivated by work~\cite{kalajdzievski2023rank,team2024chameleon}, we attribute the main cause of these divergences to issues arising from the softmax operation when handling tasks drawn from different domains with substantially varied entropy, stemming from softmax’s translation invariance (\emph{i.e.}, $softmax \left( z \right) = softmax \left( z + c \right)$). Since all model parameters are shared among multiple tasks, each task competes by incrementally growing its norms. while this is not immediately detrimental, it leads to divergence once norms extend beyond the effective range of bf16. To mitigate this, we introduce the Adaptive Gradient Stabilization module in Section \ref{sec:AGS}, employing an adaptive coefficient $\gamma_{\theta} =  \frac{\alpha_{\theta}}{||r||_p} + \beta_{\theta}$, where $\alpha_{\theta}$ and $\beta_{\theta}$ are learnable variables and $r$ represents the rank. Through this mechanism, gradients can be adaptively stabilized in the form of:
\begin{equation}
\nabla_{\boldsymbol{\Delta{\mathcal{W}}}} = \frac{\partial \mathcal{L}\left( \mathcal{D};\boldsymbol{\mathcal{W}}_0 + \gamma_{\theta} \cdot \boldsymbol{\Delta{\mathcal{W}}} \right)}{\partial \boldsymbol{\Delta{\mathcal{W}}}}
\end{equation}

\subsection{Frozen Pre-trained Backbone}
We adopt LLaMA 3~\cite{dubey2024llama} as the backbone, a standard dense Transformer~\cite{vaswani2017attention} architecture. It employs grouped query attention~\cite{ainslie2023gqa}, which generalizes multi-query attention by introducing an intermediate set of key-value heads. Furthermore, LLaMA 3 applies an attention mask that blocks cross-document self-attention within a single sequence; while this feature shows minimal influence during standard pre-training, it becomes crucial for continued pre-training on long sequences. Lastly, LLaMA 3 supports an expanded vocabulary of 128K tokens.

\subsection{Mutual Representation Similarity}
\label{sec:simi}
\noindent\textbf{Task scaling setup.} We build a sequence of multi-task dataset with detailed composition as follows:
\begin{itemize}[leftmargin=*,nosep]
    \item \textbf{1 task}: Reagent Prediction.
    \item \textbf{2 tasks}: Reagent Prediction $+$ Molecular Captioning.
    \item \textbf{4 tasks}: Reagent Prediction $+$ Molecular Captioning $+$ Solvent Prediction $+$ Catalyst Prediction.
    \item \textbf{8 tasks}: Reagent Prediction $+$ Molecular Captioning $+$ Solvent Prediction $+$ Catalyst Prediction $+$ Forward Prediction $+$ Retrosynthesis $+$ Property Prediction $+$ Yield Regression.
\end{itemize}

\noindent\textbf{Similarity calculation.} We first extract features $R\in \mathbb{R}^{B\times L\times T\times d}$ from all decoder layers in LLM, where $B, L, T, d$ is batch size, number of decoder layers, sequence length and the hidden dimension of LLM. The sequence dimension is then averaged.
\begin{equation}
    R' = \frac{\left(\sum_{t=1}^{T} (R[:,:,t,:] * m[:,t])\right)}{\sum_{t=1}^{T} m[:,t]}
\end{equation}
where $R'\in\mathbb{R}^{B\times L\times d}$, and $m\in\mathbb{R}^{B\times T}$ is the mask indicating the padding tokens. We then flatten the first two dimensions and get $R''\in \mathbb{R}^{(B*L)\times d}$ and calculate the similarity with  \texttt{mutual\_knn}~\cite{huh2024platonic}.

Let $N=B*L$, and we have two models $A$ and $B$ trained on different multi-task datasets, we first find their $k$ nearest neighbors $\text{knn}^A$ and $\text{knn}^B$.
\begin{equation}
    \text{knn}^A = \text{KNN}(R^A,k)\quad \text{knn}^B=\text{KNN}(R^B,k)
\end{equation}
where $\text{knn}^{*}\in \mathbb{R}^{N\times k}$, we then create indicator matrices
\begin{equation}
    M_{i,j}^A = 
    \begin{cases}
        1, \quad j\in \text{knn}^A[i,:]\\
        0, \quad \text{otherwise}
    \end{cases}
    \quad
    M_{i,j}^B = 
    \begin{cases}
        1, \quad j\in \text{knn}^B[i,:]\\
        0, \quad \text{otherwise}
    \end{cases}\quad i,j\in 1,\dots,N
\end{equation}

The accuracy of a sample is
\begin{equation}
    \text{acc}[i]=\frac{1}{k}\left|\text{knn}^A[i,:]\cap \text{knn}^B[i,:]\right| = \frac{1}{k}\sum_{j=1}^{N} M_{i,j}^A\cdot M_{i,j}^B
\end{equation}

Finally, the alignment score of two models is
\begin{equation}
    \text{Score} = \frac{1}{N}\sum_{i=1}^N \text{acc}[i]
\end{equation}



\section{Further Details on Training}
\label{app: training detail}
\begin{table}[t]
\centering
\label{tab:train recipe}
\scriptsize
\renewcommand{\arraystretch}{1.1}
\setlength{\tabcolsep}{4mm}{
\begin{tabular}{l|c|c|c|c|c|c}
\toprule
 & \multicolumn{1}{l|}{Learning rate} & \multicolumn{1}{l|}{Num Epoch} & \multicolumn{1}{l|}{LR Decay} & \multicolumn{1}{l|}{Stop Epoch} & \multicolumn{1}{l|}{Batch Size} & \multicolumn{1}{l}{Warmup Ratio} \\  \midrule
Forward Reaction Prediction & \multirow{16}{*}{8e-5} & \multirow{14}{*}{15} & \multirow{16}{*}{cosine} & \multirow{14}{*}{10} & \multirow{16}{*}{32} & \multirow{16}{*}{0.0075} \\
Reagent Prediction &  &  &  &  &  &  \\
Retrosynthesis &  &  &  &  &  &  \\
Quantum Mechanics Property Prediction &  &  &  &  &  &  \\
Catalyst Prediction &  &  &  &  &  &  \\
Solvent Prediction &  &  &  &  &  &  \\
Yield Regression &  &  &  &  &  &  \\
Experimental Procedure Prediction &  &  &  &  &  &  \\
Description Q\&A &  &  &  &  &  &  \\
SCF Energy Prediction &  &  &  &  &  &  \\
Topological Polar Surface Area Prediction &  &  &  &  &  &  \\
Complexity Prediction &  &  &  &  &  &  \\
Molecular Weight Prediction &  &  &  &  &  &  \\
LogP Prediction &  &  &  &  &  &  \\ \cline{1-1} \cline{3-3} \cline{5-5}
Molecular Captioning &  & 10 &  & 8 &  &  \\ \cline{1-1} \cline{3-3} \cline{5-5}
Omni-Molecular Tasks &  & 15 &  & 15 &  &  \\ \bottomrule
\end{tabular}
}
\caption{An overview of the hyper-parameters and training configurations used in all molecular task experiments.}
\vspace{-0.3cm}
\end{table}
Specialist models are typically fine-tuned on a single task at a time, repeating the process separately for each task, a strategy known as separate tuning. In contrast, generalist models undergo simultaneous fine-tuning across multiple tasks, a process referred to as unified tuning. In this section, we present a detailed training framework for both of them on all experiments.

\noindent\textbf{Separate instruction tuning.} We follow the training recipe outlined in~\citet{cao2023instructmol}. However, we observe significant overfitting when training the model on the molcap task for 20–50 epochs, as suggested in~\citet{cao2023instructmol}. To address this issue, we manually allocate $10\%$ of the training set for validation and re-evaluated all tasks, we find that the recipes for forward prediction, reagent prediction, retrosynthesis, Quantum Mechanics Property Prediction from the original paper matches our results, however, we identify an updated training strategy tailored to the molcap task. The revised training recipe is summarized in Table~\ref{tab:train recipe}.

\noindent\textbf{Unified instruction tuning.} For unified training, we apply a fixed training recipe as shown in Table~\ref{tab:train recipe}, this recipe is consistent across all Unified Instruction Tuning.

\noindent\textbf{Environment Settings.} We employ common techniques to boost performance and conserve memory, including FlashAttention 2~\cite{dao2022flashattention}, activation checkpointing, and bf16 training. All experiments are conducted on $8\times$NVIDIA A100 GPUs (80GB).
For all experiments, the weight decay is set to 0. The term \textit{Stop Epoch} in Table~\ref{tab:train recipe} shows the epoch that the experiment stops. This is because the early stop mechanism we used to prevent overfitting.



\section{Further Details on Experimental Results}
\label{sec:more results}
In this section, we provide a complete performance evaluation of \method across the remaining 9 tasks.

\begin{table}[h]
\centering
\label{tab:more regression task}
\scriptsize
\vspace{-0.01cm}
\renewcommand{\arraystretch}{1.1}
\setlength{\tabcolsep}{1.1mm}{
\begin{tabular}{lccccccc}
\toprule
Model & Type & \#Param & Weight(g/mol) & LogP & TPSA(\text{\AA}$^2$) & Complexity & SCF($10^5$eV) \\ \midrule
Llama2 & Specialist & 6.7B & 22.10 (96\%) & 1.45 (95\%) & 15.87 (92\%) & 69.74 (93\%) & 0.70 (99\%) \\
3D-MoLM(S) & Specialist & 6.7B & 14.79 (95\%) & 0.66 (97\%) & 9.71 (93\%) & 44.85 (94\%) & 0.35 (99\%) \\
3D-MoLM(G) & Generalist & 6.7B & 16.58 (92\%) & 0.78 (95\%) & 10.90 (90\%) & 45.49 (89\%) & 0.38 (98\%) \\
\rowcolor[HTML]{EFEFEF} 
\textbf{\method} & Generalist & \textbf{1.7B} & \textbf{15.08} (\textbf{100\%}) & \textbf{0.59} (\textbf{100\%}) & 11.17 (\textbf{100\%}) & 49.38 (\textbf{100\%}) & 0.55 (99\%) \\ \bottomrule
\end{tabular}
\begin{tabular}{lcccc}
\toprule
Model & Type & \#Param & B-H & S-M \\  \midrule
Llama2 & - & 6.7B & -0.476 & 0.121 \\
Vicuna v1.5 & - & 6.7B & -0.131 & 0.151 \\
PRESTO & Generalist & 6.7B & 0.944 & 0.652 \\
\rowcolor[HTML]{EFEFEF} 
\textbf{\method} & Generalist & \textbf{1.7B} & 0.891 & 0.560 \\ \bottomrule
\end{tabular}
}
\caption{More results for regression tasks. (Left) Results of property regression tasks, we report MAE for each task with the valid answer rate (\%), since LMs sometimes fail to generate numerical responses corresponding to the given prompts. (Right) Results of Yield regression task, we report $R^2$ score.}
\end{table}

\begin{table}[t]
\centering
\label{tab:more reaction task}
\scriptsize
\renewcommand{\arraystretch}{1.1}
\setlength{\tabcolsep}{3.7mm}{
\begin{tabular}{lccccccccc}
\toprule
Model & Type & \#Param & Exact & BLEU & Levenshtein & RDK & MACCS & Morgan & Validity \\  \midrule
\rowcolor[HTML]{FFCE93} 
\multicolumn{10}{l}{\cellcolor[HTML]{FFCE93}Catalyst Prediction (PRESTO)} \\
Llama2 & - & 6.7B & 0.680 & 0.720 & 2.545 & 0.882 & 0.868 & 0.687 & 1.000 \\
Vicuna v1.5 & - & 6.7B & 0.685 & 0.703 & 2.451 & 0.883 & 0.869 & 0.692 & 1.000 \\
nach0-base & - & - & 0.000 & 0.072 & 36.442 & 0.129 & 0.055 & 0.009 & 0.849 \\
Mol-Instruction & Specialist & 6.7B & 0.000 & 0.110 & 28.424 & 0.031 & 0.045 & 0.015 & 0.999 \\
T5Chem & - & - & 0.022 & 0.346 & 13.408 & 0.146 & 0.268 & 0.200 & 0.996 \\
PRESTO & Generalist & 6.7B & \textbf{0.768} & 0.814 & 1.755 & 0.914 & 0.895 & 0.774 & 1.000 \\
\rowcolor[HTML]{EFEFEF} 
\textbf{\method} & Generalist & \textbf{1.7B} & 0.752 & \textbf{0.860} & \textbf{1.544} & \textbf{0.919} & \textbf{0.903} & \textbf{0.759} & \textbf{1.000} \\ \hline
\rowcolor[HTML]{FFCE93} 
\multicolumn{10}{l}{\cellcolor[HTML]{FFCE93}Solvent Prediction (PRESTO)} \\
Llama2 & - & 6.7B & 0.311 & 0.462 & 3.819 & 0.452 & 0.480 & 0.417 & 1.000 \\
Vicuna v1.5 & - & 6.7B & 0.320 & 0.436 & 3.809 & 0.459 & 0.486 & 0.427 & 1.000 \\
nach0-base & - & - & 0.000 & 0.072 & 36.442 & 0.129 & 0.055 & 0.009 & 0.849 \\
Mol-Instruction & Specialist & 6.7B & 0.000 & 0.155 & 25.117 & 0.030 & 0.122 & 0.035 & 1.000 \\
T5Chem & - & - & 0.083 & 0.311 & 16.224 & 0.458 & 0.424 & 0.397 & 0.995 \\
PRESTO & Generalist & 6.7B & 0.419 & 0.695 & 2.758 & 0.529 & 0.547 & 0.506 & 0.912 \\
\rowcolor[HTML]{EFEFEF} 
\textbf{\method} & Generalist & \textbf{1.7B} & \textbf{0.590} & \textbf{0.799} & \textbf{2.243} & \textbf{0.740} & \textbf{0.733} & \textbf{0.715} & \textbf{1.000} \\ \bottomrule
\end{tabular}
}
\caption{\small More results for reaction tasks.}
\end{table}


\begin{table}[t]
\centering
\label{tab:exp proced}
\scriptsize
\renewcommand{\arraystretch}{1.1}
\setlength{\tabcolsep}{5mm}{
\begin{tabular}{lccccccc}
\toprule
Model & Type & \#Param & BLEU-2 & BLEU-4 & ROUGE-1 & ROUGE-2 & ROUGE-L \\ \midrule
TextChemT5 & Generalist & 220M & 0.541 & 0.406 & 0.615 & 0.403 & 0.564 \\
MolT5-Large & Specialist & 780M & 0.545 & 0.410 & 0.625 & 0.409 & 0.572 \\
Galactica & Specialist & 1.3B & 0.535 & 0.395 & 0.609 & 0.386 & 0.552 \\
MolCA, Galac & Specialist & 1.3B & 0.549 & 0.415 & 0.625 & 0.404 & 0.570 \\
ReactXT, Galac & Specialist & 1.3B & 0.574 & 0.440 & 0.644 & 0.427 & 0.589 \\
\rowcolor[HTML]{EFEFEF} 
\textbf{\method} & Generalist & 1.7B & 0.569 & \textbf{0.445} & 0.523 & 0.270 & 0.460 \\ \bottomrule
\end{tabular}
}
\caption{\small Results of experimental procedure prediction.}
\end{table}



\section{More Ablation Study Results}
\label{sec:more ablation}

\subsection{Separate Tuning V.S. Unified Tuning}
Here, we present the performance of separate tuning and unified tuning across the remaining 9 tasks. 
\begin{figure*}[t]
    \centering
    \includegraphics[width=0.56\linewidth]{figs/single_multi_app1.pdf}
    \includegraphics[width=0.39\linewidth]{figs/single_multi_app2.pdf}
    \vspace{-0.3cm}
    \caption{Additional results from the ablation study comparing our unified instruction tuning to separate training.}
    \label{fig:app uni vs single}
    \vspace{-0.3cm}
\end{figure*}


As show in Figure~\ref{fig:app uni vs single}, We observe that tasks like solvent prediction, catalyst prediction, and experiment procedure prediction continue to gain significant improvements from unified training. However, we also notice that some tasks perform worse after unified training compared to individual training, particularly those related to regression tasks, such as yield regression, logP prediction, and complexity prediction. While we see some modest gains in SCF prediction and weight prediction, there is a noticeable performance degradation in other tasks, especially in the complexity prediction task, where unified training causes a substantial drop in performance.


Regression tasks differ significantly from SELFIES generation and text description tasks in that the model must, after understanding the molecule, directly and accurately predict the specific numerical value of a property. Even though existing literature suggests that LLMs are capable of performing regression, accurately predicting the next number remains a fundamentally different challenge from current tasks, and potentially introduces significant conflicts.


Perhaps incorporating additional information, such as the process of deriving a specific number (\emph{e.g.}, a chain of thought), or using an additional regression head, could help alleviate these conflicts before making an accurate numerical prediction.




\section{Further Details on Efficiency Analysis}

\begin{figure*}[h]
    \centering
    \includegraphics[width=0.85\linewidth]{figs/infere_time.pdf}
    \vspace{-0.4cm}
    \caption{A comprehensive efficiency evaluation of our \method, built on LLaMA 3.2-1B, compared to the state-of-the-art baseline. We conduct all experiments three times and compute the average result.}
    \label{fig:efficiency}
\end{figure*}


To ensure a fair comparison of computational efficiency with existing methods, we evaluate \method across four key metrics: inference time, memory consumption, token generation speed (tokens per second), and GFLOPs. All comparative experiments are conducted on a single standalone NVIDIA A100-80G GPU to ensure consistency in inference evaluation.
As illustrated in Figure \ref{fig:efficiency}, \method achieves significantly lower inference latency, reducing it by up to 65\% compared to PRESTO. This substantial efficiency gain enables faster response times, making \method particularly well-suited for high-throughput molecular modeling tasks.
Moreover, \method demonstrates optimized memory utilization, consuming 28\% less memory, which enhances its feasibility for deployment on resource-constrained hardware without compromising performance. Additionally, \method achieves a 1.78$\times$ higher token generation rate, ensuring faster sequence generation and significantly improving usability in real-world applications that require rapid molecular property predictions and synthesis planning.
Finally, \method effectively reduces computational cost by 41\% in terms of GFLOPs, striking a favorable balance between model complexity and inference speed. These advantages make \method a scalable, cost-efficient, and high-performance solution for large-scale molecular modeling and chemistry-related AI applications.

\begin{figure*}[h]
    \centering
    \includegraphics[width=0.9\linewidth]{figs/case_study_catalyst.pdf}
    \includegraphics[width=0.9\linewidth]{figs/case_study_retro.pdf}\\[-7pt]
    % \vspace{-0.3cm}
    \caption{Visualization of the cases generated by \method and the baseline on three reaction tasks.}
    \label{fig:case}
\end{figure*}

\section{Further Details on Theoretical Analysis}
\subsection{Proof of Theorem~\ref{lem:progressive caps}}
\label{sec:proof of lemma prog cap}
\begin{proof}[Proof of Theorem~\ref{lem:progressive caps}]
For $F_{\text{general}}^{(n)}$ and $F_{\text{general}}^{(m)}$ with $m>n$, we have
\begin{equation}
\begin{aligned}
    F_{\text{general}}^{(m)} &= F_1\cap F_2\cap\cdots\cap F_n\cap F_{n+1}\cap\cdots\cap F_m \\
    &=F_{\text{general}}^{(n)}\cap F_{n+1}\cap \cdots \cap F_m
\end{aligned}
\end{equation}

Since intersection of sets can only become smaller or remain the same as more sets are intersected, therefore
\begin{equation}
    F_{\text{general}}^{(m)} \subseteq F_{\text{general}}^{(n)}
\end{equation}

If $\forall i,j$, $n<i,j<m$ and $F_i\neq F_j$ when $i\neq j$, then
\begin{equation}
\begin{aligned}
    &F_{\text{general}}^{(n+1)} = F_{\text{general}}^{(n)}\cap F_{n+1}\subsetneq F_{\text{general}}^{(n)} \\
    &F_{\text{general}}^{(n+2)} = F_{\text{general}}^{(n+1)}\cap F_{n+2}\subsetneq F_{\text{general}}^{(n+1)} \subsetneq F_{\text{general}}^{(n)} \\
    & \cdots \\
    & F_{\text{general}}^{(m)} = F_{\text{general}}^{(n+(m-n-1))}\cap F_{n+(m-n)}\subsetneq F_{\text{general}}^{(n+(m-n-1))}\subsetneq F_{\text{general}}^{(n+(m-n-2))}\subsetneq \cdots \subsetneq F_{\text{general}}^{(n)}
\end{aligned}
\end{equation}
\end{proof}


\section{Case Study}
% in the Solvent Prediction task, the provided reactants are  
% \[
% \texttt{[C][C][Branch1][C][C][Branch1][C][C][O][C][=Branch1][C][=O][C][C][C][Br]}
% \]  
% and  
% \[
% \texttt{[C][C][=C][C][Branch1][Ring1][C][\#N][=C][C][Branch1][C][Cl][=C][Ring1][=Branch2][O]},
% \]  
% with the product  
% \[
% \texttt{[C][C][=C][C][Branch1][Ring1][C][\#N][=C][C][Branch1][C][Cl][=C][Ring1][=Branch2][O][C][C][C][C][=Branch1][C][=O][O][C][Branch1][C][C][Branch1][C][C][C]}.
% \]  
% Omni-Mol correctly predicted the solvent as  
% \[
% \texttt{[C][N][Branch1][C][C][C][=O]},
% \]  
% whereas PRESTO predicted an incorrect solvent:  
% \[
% \texttt{[C][C][\#N]}.
% \]

\begin{figure}[ht]
    \centering
    \includegraphics[width=\linewidth]{figs/molcap_case.pdf}\\[-7pt]
    \caption{Visualization of the cases generated by unified tuning and separate tuning on the molecular captioning task.}
    \label{fig:molcap case}
    \vspace{-0.2cm}
\end{figure}

\subsection{Reaction Tasks}
In this subsection, we visualize specific reactions in three reaction tasks. The results in Figure \ref{fig:case} and \ref{fig:molcap case} demonstrate that our method exhibits more accurate generation capabilities compared to the baseline. For example, in the solvent prediction task, we are given the reactants: [C][C][Branch1][C][C][Branch1][C][C][O][C][=Branch1][C][=O][C][C][C][Br] and [C][C][=C][C][Branch1][Ring1][C][\#N][=C][C][Branch1][C][Cl][=C][Ring1][=Branch2][O], as well as the product [C][C][=C][C][Branch1][Ring1][C][\#N][=C][C][Branch1][C][Cl][=C][Ring1][=Branch2][O][C][C][C][C][=Branch1][C]\-[=O][O][C][Branch1][C][C][Branch1][C][C][C]. Omni-Mol correctly predicts the solvent as [C][N][Branch1][C]\-[C][C][=O], whereas PRESTO predicts an incorrect solvent: [C][C][\#N].

\subsection{Molecular Captioning}
In the case study of the molecular captioning task, as shown in Figure~\ref{fig:molcap case}, the model’s description of the same molecule becomes more accurate before and after mixed training. It is able to correctly classify and localize functional groups. Does this suggest that the model can learn to identify functional groups from the reaction task? Additionally, constraints from other tasks in the shared representation space also enhance the model’s ability to describe molecules. For example, for Case 1 Molecule, Separate Tuning outputs incorrect information regarding the locations of functional groups, whereas Unified Tuning predicts them correctly.

\section{Task Definition \& Prompt Templates}
\label{sec:taskandprompt}
\subsection{Base Chat Template}
For LLaMA 3.2 and LLaMA 3.1 instruction-tuned LLMs, we use the base chat template suggested by the official documents, the multi-modal graph tokens are inserted at the beginning of user instructions.
\begin{tcolorbox}[colback=white!98!black,colframe=white!30!black,boxsep=1.1pt,top=6.75pt]%
\scriptsize
% \textbf{}\\[-0.575em]
% \noindent\makebox[\textwidth]{\rule{\textwidth}{0.4pt}}
% \\[0.25em]
\noindent\makebox[\textwidth]{\rule{\textwidth}{1pt}}
\textbf{System Prompt}
\\[-0.575em]
\noindent\makebox[\textwidth]{\rule{\textwidth}{1pt}}

\noindent{\tt <|begin\_of\_text|><|start\_header\_id|>}system{\tt <|end\_header\_id|>} $\backslash$n$\backslash$n A chat between a curious user and an artificial intelligence assistant. The assistant gives helpful, detailed, and polite answers to the user's questions.{\tt <|eot\_id|>}

\noindent\makebox[\textwidth]{\rule{\textwidth}{1pt}}
\textbf{User Input}
\\[-0.575em]
\noindent\makebox[\textwidth]{\rule{\textwidth}{1pt}}

{\tt <|start\_header\_id|>}user{\tt <|end\_header\_id|>}$\backslash$n$\backslash$n{\tt <graph\_token>}$\backslash$nInstructions.{\tt <|eot\_id|>}{\tt <|start\_header\_id|>}assistant{\tt <|end\_header\_id|>} $\backslash$ n $\backslash$n

\noindent\makebox[\textwidth]{\rule{\textwidth}{1pt}}
\textbf{Assistant Output}
\\[-0.575em]
\noindent\makebox[\textwidth]{\rule{\textwidth}{1pt}}

Response.{\tt <|eot\_id|>}
\end{tcolorbox}

We use {\tt <|finetune\_right\_pad\_id|>} as pad token for SFT.

\subsection{Forward Reaction Prediction}
The forward reaction prediction task focuses on determining the chemical product of a reaction given its reactants and reagents. The forward reaction prediction task involves predicting the chemical product of a reaction given the reactants and reagents as input. The input format is structured as the SELFIES representation of reactants, concatenated with a period (``.") and the reagent information (\emph{e.g.}, ``reactant1.reactant2.reagent"). The task requires the model to process this input and output the corresponding reaction product. The objective is to accurately map the input reaction components to their chemical outcome, leveraging the model’s understanding of reaction patterns and transformations. A key challenge in forward reaction prediction is capturing the underlying chemical rules that govern reactivity. The model must infer how functional groups interact, recognize the role of reagents, and apply appropriate transformations to generate the correct product. This process requires a deep understanding of reaction mechanisms, beyond simple pattern recognition. The prompt template is as follows.

\begin{tcolorbox}[colback=white!98!black,colframe=white!30!black,boxsep=1.1pt,top=6.75pt]%
\scriptsize
% \textbf{}\\[-0.575em]
% \noindent\makebox[\textwidth]{\rule{\textwidth}{0.4pt}}
% \\[0.25em]
\noindent\makebox[\textwidth]{\rule{\textwidth}{1pt}}
\textbf{Template}
\\[-0.575em]
\noindent\makebox[\textwidth]{\rule{\textwidth}{1pt}}

\textbf{\textcolor[HTML]{20B2AA}{User Input}}: {\tt <user\_identifier>} $\oplus$ {\tt <graph\_token>}$\backslash$n $\oplus$ Instruction. $\oplus$ {\tt <SELFIES\_reactants>}.{\tt <SEL\-FIES\_reagents>} $\oplus$ {\tt <|eot\_id|>} $\oplus$ {\tt <assistant\_identifier>}

\textbf{\textcolor[HTML]{D2691E}{Assistant Output}}: {\tt <SELFIES\_product>}.{\tt <|eot\_id|>}

{\tt \textbf{<user\_identifier>}}: {\tt <|start\_header\_id|>}user{\tt <|end\_header\_id|>}$\backslash$n$\backslash$n

{\tt \textbf{<assistant\_identifier>}}: {\tt <|start\_header\_id|>}assistant{\tt <|end\_header\_id|>}$\backslash$n$\backslash$n

\noindent\makebox[\textwidth]{\rule{\textwidth}{1pt}}
\textbf{Example}
\\[-0.575em]
\noindent\makebox[\textwidth]{\rule{\textwidth}{1pt}}

\begin{tcolorbox}[colback=cyan!7!white,colframe=white!98!black,boxsep=1.1pt,top=6.75pt]
\textbf{Instruction}: Given the reactants and reagents provided, what is a possible product that can be formed? 

{\tt \textbf{<SELFIES\_reagents>}}: [Br][C][C][Br].[O][C][=C][C][Branch1][C][Br][=C][C][=C][Ring1][\#Branch1][Br]

{\tt \textbf{<SELFIES\_reactants>}}: [Na+1].[OH1-1]
\end{tcolorbox}

\begin{tcolorbox}[colback=orange!7!white,colframe=white!98!black,boxsep=1.1pt,top=6.75pt]
{\tt \textbf{<SELFIES\_product>}}: [Br][C][C][O][C][=C][C][Branch1][C][Br][=C][C][=C][Ring1][\#Branch1][Br]
\end{tcolorbox}

\end{tcolorbox}


%%%%%%%%%%%%%%%%%%%%%

\subsection{Retrosynthesis}
The retrosynthesis task focuses on predicting the reactants required to synthesize a given chemical product, a fundamental challenge in organic chemistry and computational drug discovery. Unlike forward reaction prediction, which maps reactants to products, retrosynthesis operates in reverse, it seeks to determine the most plausible set of precursors that could yield the target compound under appropriate reaction conditions. This task is crucial for designing efficient synthetic routes, enabling chemists to explore viable pathways for molecule construction while minimizing cost and complexity. At the core of this task is a structured input format using SELFIES representations, ensuring a robust and unambiguous encoding of molecular structures. The input consists of the SELFIES representation of the target product, which the model then processes to generate the corresponding reactants. This structured formulation ensures that the model can generalize across diverse chemical transformations, learning the intricate patterns of bond formation and cleavage. A key challenge in retrosynthesis prediction is handling the inherent one-to-many nature of the problem: a single product can often be synthesized through multiple distinct reaction pathways. The model must effectively navigate this complexity, identifying the most chemically plausible set of reactants based on learned reaction mechanisms. The prompt template is as follows.

\begin{tcolorbox}[colback=white!98!black,colframe=white!30!black,boxsep=1.1pt,top=6.75pt]%
\scriptsize
% \textbf{}\\[-0.575em]
% \noindent\makebox[\textwidth]{\rule{\textwidth}{0.4pt}}
% \\[0.25em]
\noindent\makebox[\textwidth]{\rule{\textwidth}{1pt}}
\textbf{Template}
\\[-0.575em]
\noindent\makebox[\textwidth]{\rule{\textwidth}{1pt}}

\textbf{\textcolor[HTML]{20B2AA}{User Input}}: {\tt <user\_identifier>} $\oplus$ {\tt <graph\_token>}$\backslash$n $\oplus$ Instruction. $\oplus$ {\tt <SELFIES\_product>} $\oplus$ {\tt <|eo\-t\_id|>} $\oplus$ {\tt <assistant\_identifier>}

\textbf{\textcolor[HTML]{D2691E}{Assistant Output}}: {\tt <SELFIES\_reactants>}{\tt <|eot\_id|>}

{\tt \textbf{<user\_identifier>}}: {\tt <|start\_header\_id|>}user{\tt <|end\_header\_id|>}$\backslash$n$\backslash$n

{\tt \textbf{<assistant\_identifier>}}: {\tt <|start\_header\_id|>}assistant{\tt <|end\_header\_id|>}$\backslash$n$\backslash$n

\noindent\makebox[\textwidth]{\rule{\textwidth}{1pt}}
\textbf{Example}
\\[-0.575em]
\noindent\makebox[\textwidth]{\rule{\textwidth}{1pt}}

\begin{tcolorbox}[colback=cyan!7!white,colframe=white!98!black,boxsep=1.1pt,top=6.75pt]
\textbf{Instruction}: Which reactants could have been used to generate the given product? The product is:

{\tt \textbf{<SELFIES\_product>}}: [C][C][=Branch1][C][=O][C][=C][C][=C][Branch1][C][O][C][Branch1][C][Cl]\-[=C][Ring1][Branch2]

\end{tcolorbox}

\begin{tcolorbox}[colback=orange!7!white,colframe=white!98!black,boxsep=1.1pt,top=6.75pt]
{\tt \textbf{<SELFIES\_reactants>}}: [C][C][=Branch1][C][=O][Cl].[O][C][=C][C][=C][C][=C][Ring1][=Branch1][Cl]
\end{tcolorbox}
\end{tcolorbox}

\subsection{Reagent Prediction}
The reagent prediction task focuses on identifying the necessary reagents for a given chemical reaction, a critical step in reaction planning and synthetic chemistry. This task is essential for guiding experimental chemists, as choosing the correct reagents influences reaction efficiency, selectivity, and feasibility. To ensure a structured and standardized input format, we represent the reaction equation using SELFIES, a robust molecular encoding system. The input consists of the SELFIES representations of the reactants, concatenated with a reaction separator ``{\tt >>}", followed by the SELFIES representation of the product. This format (\emph{e.g.}, ``reactant1.reactant2{\tt >>}product") provides a clear, machine-readable structure that allows the model to infer the necessary reagents based on known reaction mechanisms and transformation rules.
One of the core challenges in reagent prediction is handling the diversity of chemical transformations. Different reactions require specific reagents that dictate the reaction type, whether it's an oxidation, reduction, coupling, or substitution reaction. The model must learn to recognize reaction context, interpret functional group interactions, and infer the most likely reagents from training data. The prompt template is as follows.

\begin{tcolorbox}[colback=white!98!black,colframe=white!30!black,boxsep=1.1pt,top=6.75pt]%
\scriptsize
% \textbf{}\\[-0.575em]
% \noindent\makebox[\textwidth]{\rule{\textwidth}{0.4pt}}
% \\[0.25em]
\noindent\makebox[\textwidth]{\rule{\textwidth}{1pt}}
\textbf{Template}
\\[-0.575em]
\noindent\makebox[\textwidth]{\rule{\textwidth}{1pt}}

\textbf{\textcolor[HTML]{20B2AA}{User Input}}: {\tt <user\_identifier>} $\oplus$ {\tt <graph\_token>}$\backslash$n $\oplus$ Instruction. $\oplus$ {\tt <SELFIES\_reactants>} {\tt \textbf{>>}} {\tt <SELFIES\_product>} $\oplus$ {\tt <|eot\_id|>} $\oplus$ {\tt <assistant\_identifier>}

\textbf{\textcolor[HTML]{D2691E}{Assistant Output}}: {\tt <SELFIES\_reagents>}{\tt <|eot\_id|>}

{\tt \textbf{<user\_identifier>}}: {\tt <|start\_header\_id|>}user{\tt <|end\_header\_id|>}$\backslash$n$\backslash$n

{\tt \textbf{<assistant\_identifier>}}: {\tt <|start\_header\_id|>}assistant{\tt <|end\_header\_id|>}$\backslash$n$\backslash$n

\noindent\makebox[\textwidth]{\rule{\textwidth}{1pt}}
\textbf{Example}
\\[-0.575em]
\noindent\makebox[\textwidth]{\rule{\textwidth}{1pt}}

\begin{tcolorbox}[colback=cyan!7!white,colframe=white!98!black,boxsep=1.1pt,top=6.75pt]
\textbf{Instruction}: Can you provide potential reagents for the following chemical reaction? The reaction is

{\tt \textbf{<SELFIES\_reactants>}}: [C][C][C][Branch1]\-[\#C][C][=C][C][=N][C][Branch1][Ring1][O][C][=C][Ring1]\-[Branch2][C][=O][O][C][C][C][O][Ring1][S]

{\tt \textbf{<SELFIES\_product>}}: [C][C]\-[C][Branch1][\#C][C][=C][C][=N][C][Branch1][Ring1][O][C][=C][Ring1]\-[Branch2][C][O][O][C][C][C][O][Ring1]\-[S]

\end{tcolorbox}

\begin{tcolorbox}[colback=orange!7!white,colframe=white!98!black,boxsep=1.1pt,top=6.75pt]
{\tt \textbf{<SELFIES\_reagents>}}: [C][C][Branch1][C][C][O].[O].[BH4-1].[Na+1]
\end{tcolorbox}

\end{tcolorbox}

\subsection{Molecular Captioning}
The molecular captioning (Molcap) task focuses on generating descriptive textual information for a given chemical compound based on its molecular structure. This task plays a crucial role in chemical informatics, enabling automated annotation of molecular properties, classification, and functional characteristics. MolCap leverages machine learning models to infer and generate human-readable descriptions that encapsulate key chemical attributes. The input for this task follows a structured format using SELFIES, a robust molecular representation designed for machine learning applications. The SELFIES encoding of a given compound serves as the input, and the model is responsible for producing a descriptive caption that includes relevant chemical properties. These descriptions can encompass a wide range of molecular characteristics, such as compound classification (\emph{e.g.}, ``organic acid," ``amine-containing molecule"), pH estimation, presence of functional groups (\emph{e.g.}, ``contains a hydroxyl and ketone group"), solubility, toxicity, or other key features.
One of the key challenges in molecular captioning is ensuring that the generated text is both chemically accurate and contextually informative. The model must learn to recognize molecular substructures, infer meaningful chemical attributes, and articulate these in a clear and interpretable manner. The prompt template is as follows.


\begin{tcolorbox}[colback=white!98!black,colframe=white!30!black,boxsep=1.1pt,top=6.75pt]%
\scriptsize
% \textbf{}\\[-0.575em]
% \noindent\makebox[\textwidth]{\rule{\textwidth}{0.4pt}}
% \\[0.25em]
\noindent\makebox[\textwidth]{\rule{\textwidth}{1pt}}
\textbf{Template}
\\[-0.575em]
\noindent\makebox[\textwidth]{\rule{\textwidth}{1pt}}

\textbf{\textcolor[HTML]{20B2AA}{User Input}}: {\tt <user\_identifier>} $\oplus$ {\tt <graph\_token>} $\backslash$n $\oplus$ Instruction. $\oplus$ {\tt <SELFIES\_compound>} $\oplus$ {\tt <|eot\_id|>} $\oplus$ {\tt <assistant\_identifier>}

\textbf{\textcolor[HTML]{D2691E}{Assistant Output}}: Description.{\tt <|eot\_id|>}

{\tt \textbf{<user\_identifier>}}: {\tt <|start\_header\_id|>}user{\tt <|end\_header\_id|>}$\backslash$n$\backslash$n

{\tt \textbf{<assistant\_identifier>}}: {\tt <|start\_header\_id|>}assistant{\tt <|end\_header\_id|>}$\backslash$n$\backslash$n

\noindent\makebox[\textwidth]{\rule{\textwidth}{1pt}}
\textbf{Example}
\\[-0.575em]
\noindent\makebox[\textwidth]{\rule{\textwidth}{1pt}}

\begin{tcolorbox}[colback=cyan!7!white,colframe=white!98!black,boxsep=1.1pt,top=6.75pt]
\textbf{Instruction}: Please give me some details about this molecule. The compound SELFIES sequence is:

{\tt \textbf{<SELFIES\_compound>}}:[C][=C][C][=Branch2][Ring1][S][=C][C][=C][Ring1][=Branch1][C][C][Branch2]\-[Ring1][Branch1][C][Branch1][P][C] [Branch1][Ring2][O][Ring1][Branch1][C][O][P][=Branch1][C][=O]\-[Branch1][C][O-1][O-1][O][O][O]

\end{tcolorbox}

\begin{tcolorbox}[colback=orange!7!white,colframe=white!98!black,boxsep=1.1pt,top=6.75pt]
\textbf{Description}: The molecule is an organophosphate oxoanion obtained by deprotonation of the phosphate OH groups of 4-(5-O-phospho-beta-D-ribofuranosyl)phenol; major species at pH 7.3. It derives from a D-ribofuranose 5-phosphate(2-). It is a conjugate base of a 4-(5-O-phospho-beta-D-ribofuranosyl)phenol.
\end{tcolorbox}

\end{tcolorbox}

\subsection{Quantum Mechanics Property Prediction}
The quantum mechanics property prediction task focuses on determining key quantum-mechanical properties of a given chemical compound, providing critical insights into its electronic behavior, stability, and potential applications. This task is essential in computational chemistry, materials science, and drug discovery, where quantum properties influence molecular interactions, reactivity, and optoelectronic performance.
The input follows a structured format using SELFIES, a robust molecular representation optimized for machine learning applications. Given the SELFIES encoding of a molecule, the model is tasked with predicting its quantum properties, such as the highest occupied molecular orbital (HOMO) energy, lowest unoccupied molecular orbital (LUMO) energy, and the HOMO–LUMO gap. These properties are fundamental in determining a molecule’s electronic structure, with implications for charge transfer, chemical reactivity, and photophysical behavior.
One of the key challenges in quantum property prediction is capturing the underlying quantum-chemical interactions that govern molecular behavior. The prompt template is as follows.


\begin{tcolorbox}[colback=white!98!black,colframe=white!30!black,boxsep=1.1pt,top=6.75pt]%
\scriptsize
% \textbf{}\\[-0.575em]
% \noindent\makebox[\textwidth]{\rule{\textwidth}{0.4pt}}
% \\[0.25em]
\noindent\makebox[\textwidth]{\rule{\textwidth}{1pt}}
\textbf{Template}
\\[-0.575em]
\noindent\makebox[\textwidth]{\rule{\textwidth}{1pt}}

\textbf{\textcolor[HTML]{20B2AA}{User Input}}: {\tt <user\_identifier>} $\oplus$ {\tt <graph\_token>}$\backslash$n $\oplus$ Instruction. $\oplus$ {\tt <SELFIES\_compound>} $\oplus$ {\tt <|eot\_id|>} $\oplus$ {\tt <assistant\_identifier>}

\textbf{\textcolor[HTML]{D2691E}{Assistant Output}}: Property.{\tt <|eot\_id|>}

{\tt \textbf{<user\_identifier>}}: {\tt <|start\_header\_id|>}user{\tt <|end\_header\_id|>}$\backslash$n$\backslash$n

{\tt \textbf{<assistant\_identifier>}}: {\tt <|start\_header\_id|>}assistant{\tt <|end\_header\_id|>}$\backslash$n$\backslash$n

\noindent\makebox[\textwidth]{\rule{\textwidth}{1pt}}
\textbf{Example}
\\[-0.575em]
\noindent\makebox[\textwidth]{\rule{\textwidth}{1pt}}

\begin{tcolorbox}[colback=cyan!7!white,colframe=white!98!black,boxsep=1.1pt,top=6.75pt]
\textbf{Instruction}: What is the HOMO-LUMO gap of this molecule? The compound SELFIES sequence is:

{\tt \textbf{<SELFIES\_compound>}}: [N][=C][O][C][=C][C][=Branch1][Ring2][=N][Ring1][=Branch1][C][\#N]


\end{tcolorbox}

\begin{tcolorbox}[colback=orange!7!white,colframe=white!98!black,boxsep=1.1pt,top=6.75pt]
\textbf{Property}: 0.1487
\end{tcolorbox}

\end{tcolorbox}


\subsection{Catalyst Prediction}
The catalyst prediction task focuses on identifying the appropriate catalysts required to facilitate a given chemical reaction. Catalysts play a crucial role in modifying reaction pathways, lowering activation energy, and improving reaction efficiency without being consumed in the process. The input follows the SELFIES representation, a robust molecular encoding system designed for computational applications. The reaction is expressed as an equation where the SELFIES representations of the reactants are concatenated and separated from the product using ``{\tt >>}" (\emph{e.g.}, ``reactant1.reactant2{\tt >>}product"). This structured representation allows the model to process the reaction as a whole and infer the most suitable catalyst that enables the transformation.
One of the primary challenges in catalyst prediction is understanding the nuanced role that catalysts play in different reaction mechanisms. Unlike reagents, which directly participate in the reaction, catalysts provide alternative pathways to enhance reaction kinetics. The prompt template is as follows.

\begin{tcolorbox}[colback=white!98!black,colframe=white!30!black,boxsep=1.1pt,top=6.75pt]%
\scriptsize
% \textbf{}\\[-0.575em]
% \noindent\makebox[\textwidth]{\rule{\textwidth}{0.4pt}}
% \\[0.25em]
\noindent\makebox[\textwidth]{\rule{\textwidth}{1pt}}
\textbf{Template}
\\[-0.575em]
\noindent\makebox[\textwidth]{\rule{\textwidth}{1pt}}

\textbf{\textcolor[HTML]{20B2AA}{User Input}}: {\tt <user\_identifier>} $\oplus$ {\tt <graph\_token>}$\backslash$n $\oplus$ Instruction. $\oplus$ {\tt <SELFIES\_reactants>} {\tt \textbf{>>}} {\tt <SELFIES\_product>} $\oplus$ {\tt <|eot\_id|>} $\oplus$ {\tt <assistant\_identifier>}

\textbf{\textcolor[HTML]{D2691E}{Assistant Output}}: {\tt <SELFIES\_catalysts>}{\tt <|eot\_id|>}

{\tt \textbf{<user\_identifier>}}: {\tt <|start\_header\_id|>}user{\tt <|end\_header\_id|>}$\backslash$n$\backslash$n

{\tt \textbf{<assistant\_identifier>}}: {\tt <|start\_header\_id|>}assistant{\tt <|end\_header\_id|>}$\backslash$n$\backslash$n

\noindent\makebox[\textwidth]{\rule{\textwidth}{1pt}}
\textbf{Example}
\\[-0.575em]
\noindent\makebox[\textwidth]{\rule{\textwidth}{1pt}}

\begin{tcolorbox}[colback=cyan!7!white,colframe=white!98!black,boxsep=1.1pt,top=6.75pt]
\textbf{Instruction}: Given this chemical reaction, what are some catalysts that could have been used? The reaction is

{\tt \textbf{<SELFIES\_reactants>}}: 
[C][C][=C][C][=C][Branch1][Ring1][C][\#N][C][=C][Ring1][Branch2][C]\-[Branch1][C][F][Branch1][C][F][F].[O][=C][C][C][C]\-[=Branch1][C][=O][N]\-[Ring1][=Branch1][Br]

{\tt \textbf{<SELFIES\_product>}}: 
[N][\#C][C][=C][C][=C][Branch1][Ring1][C][Br][C][Branch1][=Branch2][C]\-[Branch1][C][F][Branch1][C][F][F][=C][Ring1][N]
\end{tcolorbox}

\begin{tcolorbox}[colback=orange!7!white,colframe=white!98!black,boxsep=1.1pt,top=6.75pt]
{\tt \textbf{<SELFIES\_catalysts>}}:[O][=C][Branch1][\#C][O][O][C][=Branch1][C][=O][C][=C][C][=C][C][=C]\-[Ring1][=Branch1][C][=C][C][=C][C] [=C][Ring1][=Branch1]
\end{tcolorbox}

\end{tcolorbox}


\subsection{Solvent Prediction}
The solvent prediction task focuses on identifying the appropriate solvents required for a given chemical reaction. Solvents play a crucial role in determining reaction efficiency, influencing factors such as solubility, reaction kinetics, selectivity, and stability of intermediates. To ensure a structured and machine-readable representation, the input follows the SELFIES format, a robust molecular encoding system designed for computational applications. The reaction is expressed as an equation where the SELFIES representations of the reactants are concatenated and separated from the product using the reaction separator ``{\tt >>}" (\emph{e.g.}, ``reactant1.reactant2{\tt >>}product"). This structured format allows the model to interpret the reaction context and infer the most suitable solvents required to facilitate the transformation.
One of the key challenges in solvent prediction is understanding the diverse roles solvents play in different reaction mechanisms. The prompt template is as follows.

\begin{tcolorbox}[colback=white!98!black,colframe=white!30!black,boxsep=1.1pt,top=6.75pt]%
\scriptsize
% \textbf{}\\[-0.575em]
% \noindent\makebox[\textwidth]{\rule{\textwidth}{0.4pt}}
% \\[0.25em]
\noindent\makebox[\textwidth]{\rule{\textwidth}{1pt}}
\textbf{Template}
\\[-0.575em]
\noindent\makebox[\textwidth]{\rule{\textwidth}{1pt}}

\textbf{\textcolor[HTML]{20B2AA}{User Input}}: {\tt <user\_identifier>} $\oplus$ {\tt <graph\_token>}$\backslash$n $\oplus$ Instruction. $\oplus$ {\tt <SELFIES\_reactants>} {\tt \textbf{>>}} {\tt <SELFIES\_product>} $\oplus$ {\tt <|eot\_id|>} $\oplus$ {\tt <assistant\_identifier>}

\textbf{\textcolor[HTML]{D2691E}{Assistant Output}}: {\tt <SELFIES\_solvents>}{\tt <|eot\_id|>}

{\tt \textbf{<user\_identifier>}}: {\tt <|start\_header\_id|>}user{\tt <|end\_header\_id|>}$\backslash$n$\backslash$n

{\tt \textbf{<assistant\_identifier>}}: {\tt <|start\_header\_id|>}assistant{\tt <|end\_header\_id|>}$\backslash$n$\backslash$n

\noindent\makebox[\textwidth]{\rule{\textwidth}{1pt}}
\textbf{Example}
\\[-0.575em]
\noindent\makebox[\textwidth]{\rule{\textwidth}{1pt}}

\begin{tcolorbox}[colback=cyan!7!white,colframe=white!98!black,boxsep=1.1pt,top=6.75pt]
\textbf{Instruction}: Please propose potential solvents that might have been utilized in the provided chemical reaction. The reaction is

{\tt \textbf{<SELFIES\_reactants>}}: 
[N][\#C][C][=C][C][=C][Branch1][C][F][C][=C][Ring1][\#Branch1].[O][C][C][C]\-[N][C][Ring1][Branch1]

{\tt \textbf{<SELFIES\_product>}}: 
[N][\#C][C][=C][C][=C][Branch1][O][N][C][C][C][Branch1][C][O][C][Ring1]\-[=Branch1][C][=C][Ring1][N]
\end{tcolorbox}

\begin{tcolorbox}[colback=orange!7!white,colframe=white!98!black,boxsep=1.1pt,top=6.75pt]
{\tt \textbf{<SELFIES\_solvents>}}: [O]
\end{tcolorbox}

\end{tcolorbox}

\subsection{Yield Regression}
The yield regression task focuses on estimating the proportion of the actual product obtained in a chemical reaction relative to its theoretical maximum. Reaction yield is a critical metric in organic synthesis, pharmaceutical manufacturing, and industrial chemistry, as it directly influences process efficiency, resource utilization, and cost-effectiveness.
The input follows the SELFIES format, a robust molecular encoding system tailored for computational chemistry. The reaction is expressed as an equation where the SELFIES representations of the reactants are concatenated and separated from the product using the reaction separator ``{\tt >>}" (\emph{e.g.}, ``reactant1.reactant2{\tt >>}product"). This structured format provides a standardized input for the model, allowing it to interpret the reaction context and estimate the expected yield.
One of the key challenges in yield prediction is capturing the complex interplay between reaction conditions, molecular stability, steric effects, and solvent or catalyst influences. The prompt template is as follows.

\begin{tcolorbox}[colback=white!98!black,colframe=white!30!black,boxsep=1.1pt,top=6.75pt]%
\scriptsize
% \textbf{}\\[-0.575em]
% \noindent\makebox[\textwidth]{\rule{\textwidth}{0.4pt}}
% \\[0.25em]
\noindent\makebox[\textwidth]{\rule{\textwidth}{1pt}}
\textbf{Template}
\\[-0.575em]
\noindent\makebox[\textwidth]{\rule{\textwidth}{1pt}}

\textbf{\textcolor[HTML]{20B2AA}{User Input}}: {\tt <user\_identifier>} $\oplus$ {\tt <graph\_token>}$\backslash$n $\oplus$ Instruction. $\oplus$ {\tt <SELFIES\_reactants>} {\tt \textbf{>>}} {\tt <SELFIES\_product>} $\oplus$ {\tt <|eot\_id|>} $\oplus$ {\tt <assistant\_identifier>}

\textbf{\textcolor[HTML]{D2691E}{Assistant Output}}: Property.{\tt <|eot\_id|>}

{\tt \textbf{<user\_identifier>}}: {\tt <|start\_header\_id|>}user{\tt <|end\_header\_id|>}$\backslash$n$\backslash$n

{\tt \textbf{<assistant\_identifier>}}: {\tt <|start\_header\_id|>}assistant{\tt <|end\_header\_id|>}$\backslash$n$\backslash$n

\noindent\makebox[\textwidth]{\rule{\textwidth}{1pt}}
\textbf{Example}
\\[-0.575em]
\noindent\makebox[\textwidth]{\rule{\textwidth}{1pt}}

\begin{tcolorbox}[colback=cyan!7!white,colframe=white!98!black,boxsep=1.1pt,top=6.75pt]
\textbf{Instruction}: Please propose potential solvents that might have been utilized in the provided chemical reaction. The reaction is

{\tt \textbf{<SELFIES\_reactants>}}: 
[F][C][Branch1][C][F][Branch1][C][F][C][=C][C][=C][Branch1][C][Cl][C][=C]\-[Ring1][\#Branch1].[C][C][=C][C][=C][Branch1] [C][N][C][=C][Ring1][\#Branch1].[O][=S][=Branch1][C][=O]\-[Branch2][Ring1][=Branch1][O][Pd][N][C][=C][C][=C][C][=C]\-[Ring1][=Branch1][C][=C][C][=C][C][=C]\-[Ring1][=Branch1][Ring1][=C][C][Branch1][C][F][Branch1][C][F][F].[C][O][C][=C][C][=C][Branch1][Ring1]\-[O][C][C][Branch2][Ring2][=N][P][Branch2][Ring1][Branch1][C][C][C][C][C][Branch1][O][C][C][Branch1]\-[Ring2][C][Ring1][=Branch1][C][Ring1] [=Branch2][C][Ring1][\#Branch2][C][C][C][C][C][Branch1][O][C][C]\-[Branch1][Ring2][C][Ring1][=Branch1][C][Ring1][=Branch2][C][Ring1][\#Branch2] [=C][Ring2][Ring1][=N]\-[C][=C][Branch1][=Branch1][C][Branch1][C][C][C][C][=C][Branch1][=Branch1][C][Branch1][C][C][C][C]\-[=C][Ring1][N][C][Branch1][C][C][C].[C][N][C][C][C][N][C][C][C][N][=C][Ring1][\#Branch2][Ring1]\-[=Branch1].[C][C][O][C][=Branch1][C][=O][C][C] [=C][Branch1][C][C][O][N][=Ring1][=Branch1]

{\tt \textbf{<SELFIES\_product>}}: 
[C][C][=C][C][=C][Branch2][Ring1][Ring2][N][C][=C][C][=C][Branch1][=Branch2]\-[C][Branch1][C][F][Branch1][C][F][F][C] [=C][Ring1][\#Branch2][C][=C][Ring1][P]
\end{tcolorbox}

\begin{tcolorbox}[colback=orange!7!white,colframe=white!98!black,boxsep=1.1pt,top=6.75pt]
\textbf{Property}: 0.1449
\end{tcolorbox}

\end{tcolorbox}

\subsection{SCF Energy Prediction}
The SCF energy prediction task involves determining the self-consistent field (SCF) energy for a given compound. The input is the SELFIES representation of the compound, and the model is tasked with predicting the molecule’s SCF energy. The objective is to provide a reliable basis for understanding the compound’s total electronic energy, which is critical for assessing its stability, reactivity, and potential applications in computational chemistry. The prompt template is as follows.

\begin{tcolorbox}[colback=white!98!black,colframe=white!30!black,boxsep=1.1pt,top=6.75pt]%
\scriptsize
% \textbf{}\\[-0.575em]
% \noindent\makebox[\textwidth]{\rule{\textwidth}{0.4pt}}
% \\[0.25em]
\noindent\makebox[\textwidth]{\rule{\textwidth}{1pt}}
\textbf{Template}
\\[-0.575em]
\noindent\makebox[\textwidth]{\rule{\textwidth}{1pt}}

\textbf{\textcolor[HTML]{20B2AA}{User Input}}: {\tt <user\_identifier>} $\oplus$ {\tt <graph\_token>}$\backslash$n $\oplus$ Instruction. $\oplus$ {\tt <SELFIES\_compound>} $\oplus$ {\tt <|eot\_id|>} $\oplus$ {\tt <assistant\_identifier>}

\textbf{\textcolor[HTML]{D2691E}{Assistant Output}}: Property.{\tt <|eot\_id|>}

{\tt \textbf{<user\_identifier>}}: {\tt <|start\_header\_id|>}user{\tt <|end\_header\_id|>}$\backslash$n$\backslash$n

{\tt \textbf{<assistant\_identifier>}}: {\tt <|start\_header\_id|>}assistant{\tt <|end\_header\_id|>}$\backslash$n$\backslash$n

\noindent\makebox[\textwidth]{\rule{\textwidth}{1pt}}
\textbf{Example}
\\[-0.575em]
\noindent\makebox[\textwidth]{\rule{\textwidth}{1pt}}

\begin{tcolorbox}[colback=cyan!7!white,colframe=white!98!black,boxsep=1.1pt,top=6.75pt]
\textbf{Instruction}: Please provide the SCF Energy value for this molecule. If uncertain, provide an estimate. Respond with the numerical value only. The molecule SELFIES sequence is:

{\tt \textbf{<SELFIES\_compound>}}:[C][C][C][C][C][C][=Branch1][C][=O][C][=C][C][C][Branch2][Ring1][Ring2][C]\-[C][=Branch1][C][=O][C][Ring1] [=Branch1][C][C][C][C][C][C][C][=Branch1][C][=O][O][O]

\end{tcolorbox}

\begin{tcolorbox}[colback=orange!7!white,colframe=white!98!black,boxsep=1.1pt,top=6.75pt]
\textbf{Property}: The SCF Energy for the input molecule is -1.988e+05 eV.
\end{tcolorbox}

\end{tcolorbox}

\subsection{LogP Prediction}
The LogP prediction task focuses on determining the octanol–water partition coefficient (LogP) of a given chemical compound, a key physicochemical property that influences molecular behavior across various environments. LogP quantifies the relative solubility of a compound in octanol versus water, serving as a critical indicator of lipophilicity, hydrophobicity, and membrane permeability.
The task employs the SELFIES molecular representation, which encodes chemical structures in a machine-readable form optimized for deep learning models. Given the SELFIES representation of a compound, the model is responsible for predicting its LogP value, a numerical measure that typically ranges from negative values (indicating high water solubility) to positive values (indicating high lipophilicity). This structured approach allows the model to learn patterns between molecular structure and partitioning behavior, enabling accurate and data-driven LogP estimation. One of the key challenges in LogP prediction is capturing the complex molecular interactions that dictate solubility behavior. The prompt template is as follows.

\begin{tcolorbox}
[colback=white!98!black,colframe=white!30!black,boxsep=1.1pt,top=6.75pt]%
\vspace{1.75pt}%
\scriptsize
% \textbf{}\\[-0.575em]
% \noindent\makebox[\textwidth]{\rule{\textwidth}{0.4pt}}
% \\[0.25em]
\noindent\makebox[\textwidth]{\rule{\textwidth}{1pt}}
\textbf{Template}
\\[-0.575em]
\noindent\makebox[\textwidth]{\rule{\textwidth}{1pt}}

\textbf{\textcolor[HTML]{20B2AA}{User Input}}: {\tt <user\_identifier>} $\oplus$ {\tt <graph\_token>}$\backslash$n $\oplus$ Instruction. $\oplus$ {\tt <SELFIES\_compound>} $\oplus$ {\tt <|eot\_id|>} $\oplus$ {\tt <assistant\_identifier>}

\textbf{\textcolor[HTML]{D2691E}{Assistant Output}}: Property.{\tt <|eot\_id|>}

{\tt \textbf{<user\_identifier>}}: {\tt <|start\_header\_id|>}user{\tt <|end\_header\_id|>}$\backslash$n$\backslash$n

{\tt \textbf{<assistant\_identifier>}}: {\tt <|start\_header\_id|>}assistant{\tt <|end\_header\_id|>}$\backslash$n$\backslash$n

\noindent\makebox[\textwidth]{\rule{\textwidth}{1pt}}
\textbf{Example}
\\[-0.575em]
\noindent\makebox[\textwidth]{\rule{\textwidth}{1pt}}

\begin{tcolorbox}[colback=cyan!7!white,colframe=white!98!black,boxsep=1.1pt,top=6.75pt]

\textbf{Instruction}: I am interested in the LogP of this molecule, could you tell me what it is? If uncertain, provide an estimate. Respond with the numerical value only. The molecule SELFIES sequence is:

{\tt \textbf{<SELFIES\_compound>}}: [C][O][C][=C][C][=Branch1][=Branch2][=C][C][=Branch1][Ring2][=C][Ring1]\-[=Branch1][O][C@H1][C@H1][C@@H1] [Branch1][Branch1][C][O][Ring1][Branch1][C@@H1][Branch1]\-[=Branch1][O][C][Ring1][\#Branch1][=O][C][=C][C][=Branch1][=C][=C][Branch1] [=Branch2][C][=Branch1]\-[Ring2][=C][Ring1][=Branch1][O][C][O][C][O]

\end{tcolorbox}

\begin{tcolorbox}[colback=orange!7!white,colframe=white!98!black,boxsep=1.1pt,top=6.75pt]
\textbf{Property}: The LogP for the input molecule is 2.00.
\end{tcolorbox}

\end{tcolorbox}

\subsection{Molecular Weight Prediction}
The molecular weight prediction task focuses on determining the molecular weight of a given chemical compound, a fundamental property that reflects its size and atomic composition. Molecular weight is a crucial parameter in various scientific disciplines, including organic synthesis, drug design, polymer chemistry, and materials science. It influences key aspects such as reaction stoichiometry, diffusion rates, bioavailability, and stability. The input follows the SELFIES format, a robust molecular encoding system designed for computational chemistry applications. The input consists of the SELFIES representation of a molecule, which the model processes to predict its molecular weight in unified atomic mass units (Da). This structured approach allows the model to learn the relationships between molecular structure and atomic composition, enabling precise and efficient molecular weight estimation. The prompt template is as follows.

\begin{tcolorbox}[colback=white!98!black,colframe=white!30!black,boxsep=1.1pt,top=6.75pt]%
\vspace{1.75pt}%
\scriptsize
% \textbf{}\\[-0.575em]
% \noindent\makebox[\textwidth]{\rule{\textwidth}{0.4pt}}
% \\[0.25em]
\noindent\makebox[\textwidth]{\rule{\textwidth}{1pt}}
\textbf{Template}
\\[-0.575em]
\noindent\makebox[\textwidth]{\rule{\textwidth}{1pt}}

\textbf{\textcolor[HTML]{20B2AA}{User Input}}: {\tt <user\_identifier>} $\oplus$ {\tt <graph\_token>}$\backslash$n $\oplus$ Instruction. $\oplus$ {\tt <SELFIES\_compound>} $\oplus$ {\tt <|eot\_id|>} $\oplus$ {\tt <assistant\_identifier>}

\textbf{\textcolor[HTML]{D2691E}{Assistant Output}}: Property.{\tt <|eot\_id|>}

{\tt \textbf{<user\_identifier>}}: {\tt <|start\_header\_id|>}user{\tt <|end\_header\_id|>}$\backslash$n$\backslash$n

{\tt \textbf{<assistant\_identifier>}}: {\tt <|start\_header\_id|>}assistant{\tt <|end\_header\_id|>}$\backslash$n$\backslash$n

\noindent\makebox[\textwidth]{\rule{\textwidth}{1pt}}
\textbf{Example}
\\[-0.575em]
\noindent\makebox[\textwidth]{\rule{\textwidth}{1pt}}

\begin{tcolorbox}[colback=cyan!7!white,colframe=white!98!black,boxsep=1.1pt,top=6.75pt]
\textbf{Instruction}: Please provide me with the Molecular Weight value of this molecule. Determine the Molecular Weight value of this molecule. If uncertain, provide an estimate. Respond with the numerical value only. The molecule SELFIES sequence is:

{\tt \textbf{<SELFIES\_compound>}}: [C][O][C][=C][Branch1][\#Branch1][C][=C][C][=N][Ring1][=Branch1][C]\-[=Branch1][C][=O][N][C][C][C][C][C][N][Branch1] [Branch1][C][C][Ring1][=Branch1][S][=Branch1][C][=O]\-[=Branch1][C][=O][N][C][=Branch1][C][=O][N][C][C][C][C][C][C][Ring1] [Branch1][C][=C][Ring1][Branch1]

\end{tcolorbox}

\begin{tcolorbox}[colback=orange!7!white,colframe=white!98!black,boxsep=1.1pt,top=6.75pt]
\textbf{Property}: The Molecular Weight for the input molecule is 491.60 g/mol.
\end{tcolorbox}

\end{tcolorbox}

\subsection{Topological Polar Surface Area Prediction}
The topological polar surface area (TPSA) prediction task focuses on determining the TPSA value of a given chemical compound, a key descriptor that reflects its molecular polarity and hydrogen bonding capacity. TPSA is widely used in cheminformatics, particularly in drug discovery, where it serves as an important predictor of solubility, permeability, and absorption. A compound’s TPSA value influences its bioavailability, blood-brain barrier penetration, and interactions with biological membranes, making accurate prediction essential for pharmaceutical and materials research. The input is the SELFIES representation of the compound, and the model is tasked with predicting the compound’s TPSA. The objective is to provide insights into the compound’s polarity, solubility, and potential absorption characteristics, which are crucial considerations in areas such as drug discovery and materials research. The prompt template is as follows.

\begin{tcolorbox}[colback=white!98!black,colframe=white!30!black,boxsep=1.1pt,top=6.75pt]%
\vspace{1.75pt}%
\scriptsize
% \textbf{}\\[-0.575em]
% \noindent\makebox[\textwidth]{\rule{\textwidth}{0.4pt}}
% \\[0.25em]
\noindent\makebox[\textwidth]{\rule{\textwidth}{1pt}}
\textbf{Template}
\\[-0.575em]
\noindent\makebox[\textwidth]{\rule{\textwidth}{1pt}}

\textbf{\textcolor[HTML]{20B2AA}{User Input}}: {\tt <user\_identifier>} $\oplus$ {\tt <graph\_token>}$\backslash$n $\oplus$ Instruction. $\oplus$ {\tt <SELFIES\_compound>} $\oplus$ {\tt <|eot\_id|>} $\oplus$ {\tt <assistant\_identifier>}

\textbf{\textcolor[HTML]{D2691E}{Assistant Output}}: Property.{\tt <|eot\_id|>}

{\tt \textbf{<user\_identifier>}}: {\tt <|start\_header\_id|>}user{\tt <|end\_header\_id|>}$\backslash$n$\backslash$n

{\tt \textbf{<assistant\_identifier>}}: {\tt <|start\_header\_id|>}assistant{\tt <|end\_header\_id|>}$\backslash$n$\backslash$n

\noindent\makebox[\textwidth]{\rule{\textwidth}{1pt}}
\textbf{Example}
\\[-0.575em]
\noindent\makebox[\textwidth]{\rule{\textwidth}{1pt}}

\begin{tcolorbox}[colback=cyan!7!white,colframe=white!98!black,boxsep=1.1pt,top=6.75pt]
\textbf{Instruction}: I would like to know the Topological Polar Surface Area of this molecule, can you provide it? If uncertain, provide an estimate. Respond with the numerical value only. The compound SELFIES sequence is:

{\tt \textbf{<SELFIES\_compound>}}:[C][C][=Branch2][=Branch1][=Branch2][=C][C][O][C][C][Branch1][O][C]\-[Branch1][Ring2][O][Ring1][=Branch1] [Branch1][C][C][C][O][C][C][C][C][Branch2][Ring2][\#C][C][Branch2]\-[Ring2][\#Branch2][C][Branch2][Ring1][=Branch1][C][C][Branch1][P][C][Ring1] [=Branch1][Branch1][O][C]\-[Ring1][\#Branch2][C][Ring2][Ring1][C][O][Ring1][Ring1][O][O][C][C][=C][Ring1][=N][N][C][=C][C][=C]\-[C][=C][Ring1][=Branch2][Ring1][=Branch1][C][C][C]

\end{tcolorbox}

\begin{tcolorbox}[colback=orange!7!white,colframe=white!98!black,boxsep=1.1pt,top=6.75pt]
\textbf{Property}: The Topological Polar Surface Area for the input molecule is 96.50 Å².
\end{tcolorbox}

\end{tcolorbox}

\subsection{Complexity Prediction}
The complexity prediction task focuses on determining the structural complexity of a given chemical compound, a key property that reflects its architectural intricacy, stereochemical richness, and molecular connectivity. Molecular complexity plays a crucial role in synthetic chemistry, drug discovery, and materials science, where it impacts synthetic feasibility, resource requirements, and overall manufacturability. Compounds with high complexity may require multiple synthetic steps, specialized reagents, and intricate reaction conditions, whereas simpler molecules are generally easier to produce and optimize for industrial applications. The input is the SELFIES representation of the compound, and the model is tasked with predicting the compound’s complexity. The objective is to shed light on the molecule’s structural intricacy, which can influence its synthetic accessibility, resource requirements, and overall feasibility in various chemical processes. The prompt template is as follows.

\begin{tcolorbox}[colback=white!98!black,colframe=white!30!black,boxsep=1.1pt,top=6.75pt]%
\vspace{1.75pt}%
\scriptsize
% \textbf{}\\[-0.575em]
% \noindent\makebox[\textwidth]{\rule{\textwidth}{0.4pt}}
% \\[0.25em]
\noindent\makebox[\textwidth]{\rule{\textwidth}{1pt}}
\textbf{Template}
\\[-0.575em]
\noindent\makebox[\textwidth]{\rule{\textwidth}{1pt}}

\textbf{\textcolor[HTML]{20B2AA}{User Input}}: {\tt <user\_identifier>} $\oplus$ {\tt <graph\_token>}$\backslash$n $\oplus$ Instruction. $\oplus$ {\tt <SELFIES\_compound>} $\oplus$ {\tt <|eot\_id|>} $\oplus$ {\tt <assistant\_identifier>}

\textbf{\textcolor[HTML]{D2691E}{Assistant Output}}: Property.{\tt <|eot\_id|>}

{\tt \textbf{<user\_identifier>}}: {\tt <|start\_header\_id|>}user{\tt <|end\_header\_id|>}$\backslash$n$\backslash$n

{\tt \textbf{<assistant\_identifier>}}: {\tt <|start\_header\_id|>}assistant{\tt <|end\_header\_id|>}$\backslash$n$\backslash$n

\noindent\makebox[\textwidth]{\rule{\textwidth}{1pt}}
\textbf{Example}
\\[-0.575em]
\noindent\makebox[\textwidth]{\rule{\textwidth}{1pt}}

\begin{tcolorbox}[colback=cyan!7!white,colframe=white!98!black,boxsep=1.1pt,top=6.75pt]
\textbf{Instruction}: I need to know the Complexity of this molecule, could you please provide it? If uncertain, provide an estimate. Respond with the numerical value only. The compound SELFIES sequence is:

{\tt \textbf{<SELFIES\_compound>}}: [C][C@@H1][Branch2][Ring2][\#Branch2][C][C@@H1][Branch1][P][C]\-[=Branch1][C][=O][N][C@@H1][Branch1][C][C][C] [=N][C][=C][S][Ring1][Branch1][N][Branch1][C][C][C]\-[=Branch1][C][=O][C][C@H1][Branch1][C][C][C][Branch1][C][Cl][Branch1][C][Cl][Cl] [C][Branch1][C][Cl]\-[Branch1][C][Cl][Cl]

\end{tcolorbox}

\begin{tcolorbox}[colback=orange!7!white,colframe=white!98!black,boxsep=1.1pt,top=6.75pt]
\textbf{Property}: The Complexity for the input molecule is 572.00.
\end{tcolorbox}

\end{tcolorbox}


\subsection{Description Q\&A}
The description question and answer task involves responding to queries regarding a given compound’s properties in physical chemistry and related fields. The input is the SELFIES representation of the compound. The model is tasked with providing accurate answers to detailed questions about the compound’s physical and chemical attributes, encompassing a broad range of topics—from pharmacological considerations to the specific influence of structural and functional groups on biological activity (\emph{e.g.}, in anticancer agents such as 4-Hydroxycyclophosphamide or Lobaplatin). The objective is to achieve a comprehensive and in-depth understanding of the compound’s characteristics. The prompt template is as follows.

\begin{tcolorbox}[colback=white!98!black,colframe=white!30!black,boxsep=1.1pt,top=6.75pt]%
% \vspace{1.75pt}%
\scriptsize
\noindent\makebox[\textwidth]{\rule{\textwidth}{1pt}}
\textbf{Template}
\\[-0.575em]
\noindent\makebox[\textwidth]{\rule{\textwidth}{1pt}}

\textbf{\textcolor[HTML]{20B2AA}{User Input}}: {\tt <user\_identifier>} $\oplus$ {\tt <graph\_token>}$\backslash$n $\oplus$ Instruction. $\oplus$ {\tt <SELFIES\_compound>} $\oplus$ {\tt <|eot\_id|>} $\oplus$ {\tt <assistant\_identifier>}

\textbf{\textcolor[HTML]{D2691E}{Assistant Output}}: Description.{\tt <|eot\_id|>}

{\tt \textbf{<user\_identifier>}}: {\tt <|start\_header\_id|>}user{\tt <|end\_header\_id|>}$\backslash$n$\backslash$n

{\tt \textbf{<assistant\_identifier>}}: {\tt <|start\_header\_id|>}assistant{\tt <|end\_header\_id|>}$\backslash$n$\backslash$n

\noindent\makebox[\textwidth]{\rule{\textwidth}{1pt}}
\textbf{Example}
\\[-0.575em]
\noindent\makebox[\textwidth]{\rule{\textwidth}{1pt}}

\begin{tcolorbox}[colback=cyan!7!white,colframe=white!98!black,boxsep=1.1pt,top=6.75pt]
\textbf{Instruction}: What is the main component of Lobaplatin that gives it its anticancer properties? The compound SELFIES sequence is:

{\tt \textbf{<SELFIES\_compound>}}: [C][C@@H1][Branch1][=Branch1][C][=Branch1][C][=O][O-1][O-1].[C][C]\-[C@H1][Branch1][=Branch1][C@@H1][Ring1] [Ring2][C][N][C][N].[Pt+2]

\end{tcolorbox}

\begin{tcolorbox}[colback=orange!7!white,colframe=white!98!black,boxsep=1.1pt,top=6.75pt]
\textbf{Description}: The main component of Lobaplatin that gives it its anticancer properties is the platinum cation (Pt+2).
\end{tcolorbox}

\end{tcolorbox}


\subsection{Experimental Procedure Prediction}
The experimental procedure prediction task focuses on generating a detailed, step-by-step protocol for conducting chemical experiments based on a given set of experimental components. This task plays a crucial role in automated synthesis planning, high-throughput experimentation, and robotic chemistry, where structured experimental procedures are essential for reproducibility, efficiency, and accuracy. The input is a mapping between experimental components and their corresponding SELFIES representations (\emph{e.g.}, ``Reactants: \$index\$: SELFIES" ...). The model is tasked with producing a structured sequence of operations that associates each component with the detailed steps of the experiment. The objective is to automate the chemical synthesis process by providing executable, structured experimental procedures. The prompt template is as follows.

\begin{tcolorbox}[colback=white!98!black,colframe=white!30!black,boxsep=1.1pt,top=6.75pt]%
\scriptsize
\noindent\makebox[\textwidth]{\rule{\textwidth}{1pt}}
\textbf{Template}
\\[-0.575em]
\noindent\makebox[\textwidth]{\rule{\textwidth}{1pt}}

\textbf{\textcolor[HTML]{20B2AA}{User Input}}: {\tt <user\_identifier>} $\oplus$ {\tt <graph\_token>}$\backslash$n $\oplus$ Instruction. $\oplus$ {\tt <IDX\_Reactants\_MAP>} $\oplus$ {\tt <IDX\_Product\_MAP>} $\oplus$ {\tt <IDX\_Catalysts\_MAP>} $\oplus$ {\tt <IDX\_Solvents\_MAP>} $\oplus$ {\tt <|eot\_id|>} $\oplus$ {\tt <assistant\_identifier>}

\textbf{\textcolor[HTML]{D2691E}{Assistant Output}}: {\tt <ACTION\_Sequence>}{\tt <|eot\_id|>}

{\tt \textbf{<user\_identifier>}}: {\tt <|start\_header\_id|>}user{\tt <|end\_header\_id|>}$\backslash$n$\backslash$n

{\tt \textbf{<assistant\_identifier>}}: {\tt <|start\_header\_id|>}assistant{\tt <|end\_header\_id|>}$\backslash$n$\backslash$n

\noindent\makebox[\textwidth]{\rule{\textwidth}{1pt}}
\textbf{Example}
\\[-0.575em]
\noindent\makebox[\textwidth]{\rule{\textwidth}{1pt}}

\begin{tcolorbox}[colback=cyan!7!white,colframe=white!98!black,boxsep=1.1pt,top=6.75pt]
\textbf{Instruction}: From the provided starting materials and target compound, generate the step-by-step experimental protocol. The Action Sequence:

{\tt \textbf{<IDX\_Reactants\_MAP>}}:Reactants:\$4\$:[START\_SELFIES][O][=C][C][=C][C][=C][Branch1][O][O][C]\-[C][C][O][C][C][O][Ring1] [Branch1][C][=C][Ring1][=C][END\_SELFIES] \$3\$: [START\_SELFIES][C][C]\-[Branch1][C][C][Branch1][C][C][O-1].[K+1][END\_SELFIES]

{\tt \textbf{<IDX\_Product\_MAP>}}:Product:\$-1\$:[START\_SELFIES][C][=C][C][=C][C][=C][Branch1][O][O][C][C][C]\-[O][C][C][O][Ring1][Branch1][C] [=C][Ring1][=C][END\_SELFIES]

{\tt \textbf{<IDX\_Catalysts\_MAP>}}:Catalysts:\$1\$:[START\_SELFIES][C][P+1][Branch1][=Branch2][C][=C][C][=C]\-[C][=C][Ring1][=Branch1][Branch1][=Branch2] [C][=C][C][=C][C][=C][Ring1][=Branch1][C][=C][C][=C]\-[C][=C][Ring1][=Branch1].[Br-1][END\_SELFIES]

{\tt \textbf{<IDX\_Solvents\_MAP>}}: Solvents: \$2\$: [START\_SELFIES][C][C][O][C][C][END\_SELFIES]

\end{tcolorbox}

\begin{tcolorbox}[colback=orange!7!white,colframe=white!98!black,boxsep=1.1pt,top=6.75pt]
\textbf{ACTION\_Sequence}: ADD \$1\$ (2 liter, 57.2 g) ; ADD \$2\$ (500 ml) ; ADD \$2\$ ; STIR ; ADD \$3\$ (18.0 g) ; ADD \$4\$ (23.7 g) ; FILTER ; WASH with water ; WASH with sodium chloride ; WASH with water ; WASH with sodium chloride ; DRYSOLUTION over magnesium sulfate ; FILTER keep filtrate ; CONCENTRATE ; YIELD \$-1\$ (20.8 g).
\end{tcolorbox}

\end{tcolorbox}

