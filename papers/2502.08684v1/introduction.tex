\section{Introduction}

Combinatorial optimization problems (COPs) are fundamental to tasks such as scheduling, resource allocation, and route planning, influencing key decisions across various industries. Given their inherent complexity, most COPs are \emph{NP-hard} \cite{papadimitriou1998}, making exact methods impractical for large-scale or real-time decision-making. Traditionally, specialized heuristics—often grounded in domain expertise—have been employed to provide feasible solutions under tight time constraints \cite{blum2003metaheuristics}.

\emph{Neural Combinatorial Optimization} (NCO) \cite{vinyals2015pointer, bello2017neural} has emerged as a data-driven framework for deriving heuristics by leveraging recurring patterns in problem instances. Most NCO approaches adopt a \emph{constructive} viewpoint, treating solution building as a sequential decision-making process naturally framed by a Markov Decision Process (MDP). This formulation allows for training policies that iteratively determine the next choice in a sequence of decisions, ultimately arriving at a complete solution. Nevertheless, constructing solutions through a sequence of individual choices can pose significant challenges, as each local decision can limit or skew subsequent options, making it increasingly difficult to ensure a high-quality final outcome.

A related and rapidly evolving area is that of Large Language Models (LLMs), which face the challenge of generating coherent sequences. One promising direction in LLM research is \emph{self-evaluation}, where an auxiliary function assesses outputs, identifies weaknesses, and guides the refinement of subsequent steps \cite{kadavath2022,xie2024self}. Inspired by these advances, we propose applying self-evaluation principles to COP decoding. However, this design significantly departs from the typical approach in LLMs, as the constraints involved in constructing the optimal solution of a combinatorial problem are of a fundamentally different nature.

The problem we aim to address is generating subsequences of actions closer to the optimal solution, a core challenge in many COPs. Conventional methods, which produce one action at a time, often fail to generate coherent and optimal subsequences, as they do not directly evaluate the quality of action subsets using a dedicated evaluation mechanism. To address this, our framework introduces a novel mechanism that evaluates subsets of actions collectively at each step. By jointly considering multiple actions, the approach improves entire subsequences, enhancing solution quality compared to traditional stepwise methods. This shift from isolated moves to collective evaluations enables a richer and more effective decision-making process.

Our framework integrates two complementary models: a policy model and a self-evaluation model. The policy model assigns probabilities to possible actions using supervised learning, sampling sets of actions that are then scored by the self-evaluation model based on their overall quality. This allows for selecting the most promising subsequences during inference and redefines COPs as MDPs, transitioning from single-action spaces to subsequence-based spaces. Figure \ref{fig:selfevaluationsimple} illustrates how our approach evaluates entire subsets of actions jointly, unlike traditional greedy methods that assess actions individually. For instance, in routing problems, actions might represent cities to visit, while in scheduling, they could denote operation assignments to machines. Despite introducing an additional model, our subsequence-based design reduces the overall number of inference steps, making the framework efficient while better capturing dependencies between actions.

 \begin{figure}[h] \centering \includegraphics[width=1\linewidth]{sencillo2.drawio} \caption{Comparison between a greedy approach and our self-evaluation framework.} \label{fig:selfevaluationsimple} \end{figure}

The neural network architecture of our approach follows a multi-model design for both the policy and self-evaluation components. The policy model combines a heterogeneous graph neural network (HGNN) with a Transformer to generate the probability distribution of the actions. The HGNN extracts structural information from the problem, leveraging the fact that many COPs can be represented as graphs, with information embedded in nodes, edges, or both. This makes our approach general and adaptable to a wide range of COPs. The self-evaluation function also uses the embeddings generated by the HGNN and is implemented as a separate Transformer-based module. This function outputs a score between 0 and 1, quantifying the quality of candidate action sets.

In this paper, we focus on scheduling—a more complex and less explored domain compared to other combinatorial optimization settings like routing. Specifically, we address the Job-Shop Scheduling Problem (JSSP), one of the most challenging problems in scheduling. We evaluated our approach on two well-known and challenging public JSSP benchmark datasets, comprising a total of 160 instances. The first dataset, the Taillard benchmark \cite{taillard1993benchmarks}, served as a reference for generating synthetic training instances. Specifically, we followed the same method used to create the benchmark's instances, ensuring they shared the same distribution, but we restricted the training instances to smaller problem sizes. This setup enables a controlled evaluation of the model’s ability to generalize to larger, unseen instances within the same distribution. In contrast, the second dataset, the Demirkol benchmark \cite{demirkol1998benchmarks}, features a distinct distribution, providing a more challenging test of the model's capacity to generalize to diverse and previously unseen scenarios. These benchmarks have been widely used in the literature to validate state-of-the-art approaches \cite{pirnay2024self, corsini2024self}.

Our experimental results demonstrate significant optimization improvements over state-of-the-art methods, with substantial gains on the dataset with a different distribution. It surpasses recent deep learning approaches and outperforms Google's optimization-focused OR-Tools CP-SAT solver on larger instances, even though the latter incurs significantly higher computational costs. These results emphasize the effectiveness of our framework in tackling diverse and unseen problem instances. While this work focuses on the JSSP, the proposed methodology holds potential for broader applications to other combinatorial optimization problems, which will be explored in future research.

The contributions of the paper can be summarized as follows:

\begin{itemize}
    \item A novel framework that evaluates subsets of actions collectively, refining subsequences to improve solution quality compared to traditional stepwise approaches.
    \item An integrated model design featuring an HGNN and Transformer for the policy model, coupled with a Transformer-based self-evaluation function for assessing action subsets.
    \item A redefinition of COPs as MDPs, transitioning from single-action spaces to subsequence-based action spaces for richer decision-making.
    \item Extensive evaluation on JSSP benchmarks, demonstrating significant performance gains over state-of-the-art methods, including superior generalization to diverse and unseen problem instances.
\end{itemize}










