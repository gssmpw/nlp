The rapid advancement of large language models (LLMs) has unlocked unprecedented capabilities in artificial intelligence~\cite{ding2023unraveling}, enabling systems to interpret natural language~\cite{lu2024llms}, reason about complex scenarios~\cite{huang2024planning}, and interact with humans through seamless workflow integration~\cite{yang2024llm}.  These advancements have spurred interest across diverse fields in leveraging LLMs to create human \textbf{\textit{digital twins}}—virtual representations of individuals, potentially equipped with personalized data and historical information, allowing it to perform tasks such as decision-making and reasoning on behalf of the individual.
% virtual avatar that represent an individual, real or imagined that equipped with personalized data and historical information, enabling the simulation, analysis, and prediction of its behavior and characteristics across emotion, decision-making, reasoning, language use, observable actions and so on.



\begin{figure}[t]
    \centering
    \includegraphics[width=1\linewidth]{latex/picture/gainian.pdf}
    \caption{A foundational framework (center) leverages historical data to develop an individual's LLM-powered digital twin.  These individualized digital twins (top) have diverse applications across domains such as healthcare, education, and personalized services.  Furthermore, scaling this approach to collective digital twins (bottom) enables dynamic simulations of societal systems, providing unprecedented insights into emergent behaviors and large-scale social dynamics.}
    \label{fig:application}
\end{figure}







Digital twins, initially conceived for industrial applications such as smart manufacturing~\cite{kreuzer2024artificial}, are increasingly being applied in human-centric domains. 
In fields like personalized healthcare~\cite{wang2024twin} and the metaverse~\cite{lv2022building, aloqaily2022integrating, far2022applying}, these digital replicas of physical entities facilitate predictive scenario testing and real-time monitoring.
The emergence of LLMs with human-like cognition~\cite{gonzalez2024building} and role-playing capabilities~\cite{chen2024from} presents a paradigm shift: these models can synthesize personalized histories to simulate domain-specific expertise~\cite{li2024personal,blasek2023large} (e.g., digital twin teacher), provide emotional companionship~\cite{tu2023characterchat},
and most notably, executing authorized proxy behaviors on behalf of human users.
When scaled to social networks, ensembles of LLM-based twins could further unravel complex human dynamics~\cite{rossetti2024ysocialllmpoweredsocial}, from cultural evolution to crisis response patterns. 
The operational mechanisms and application scenarios of digital twin are illustrated in Figure \ref{fig:application}.


Despite this potential, NLP research aligned with the conceptual framework of LLM-as-digital-twin has predominantly focused on simulating human dialogues~\cite{shen2024roleeval}, knowledge~\cite{shen2024roleeval}, decision-making~\cite{xu2024character} and comprehension ability~\cite{yuan2024evaluating}.
Critically, the simulation of human-like behavior remains underexplored.
Moreover, existing work predominantly rely on static, single-turn simulation tasks or unstable sandbox environments, thus failing to capture LLMs' ability on humans behaviors simulation across dynamically evolving contexts—a hallmark of real-world intelligence. 
This limitation creates a significant gap between the promise of digital twins and their practical utility in applications demanding longitudinal behavioral fidelity, such as virtual reality avatars or AI-assisted psychotherapy.



To address this gap, we introduce \datasetname, a novel benchmark designed to LLMs' ability to simulate continuous human behavior. 
\datasetname comprises 1,001 high-quality, persona-based behavior chains, each containing 10–20 context-behavior nodes, automatically extracted from fiction and biographical literature.  Each persona includes detailed profile and history metadata. This literature-based dataset offers a valuable simulation environment for studying continuous human behavior, particularly given the scarcity of real-world behavioral data.



We established an evaluation framework by integrating persona metadata into LLMs and challenging them to progressively recognize or generate persona-based behaviors within dynamically evolving temporal contexts.  
Our evaluation framework comprised two tasks: a multiple-choice behavioral prediction task assessing recognition capabilities, and an open-ended generation task evaluating behavioral synthesis abilities.  

We conduct comprehensive evaluations of ten state-of-the-art LLMs and performed detailed analyses, yielding the following key findings regarding continuous human behavior simulation:
1) Accurately simulating such behavior poses a significant challenge, with even advanced models like GPT-4 achieving sub-60\% accuracy.
2) LLMs are less proficient at simulating non-key behaviors compared to critical ones.
3) A snowball effect occurs during behavior chain completion process, where initial errors compound and degrade subsequent predictions. These findings offer valuable insights into the challenges and opportunities in developing LLM-based digital twins.


















% Character role-playing, wherein LLMs are assigned with embodying a character by prompt engineering~\cite{li2023chatharuhi} or fine-tuning~\cite{shao2023characterllm,wang2024rolellm,zhou2023characterglm} to mimic the tone, knowledge, and personality of specific characters realistically, stands out basis for LLMs as digital twins.

% simulate the linguistic style, behavioral patterns, emotional expression, and knowledge background of various characters.
% This allows them to exhibit capabilities consistent with the characteristics of the given role in dialogue or text generation.
% By integrating historical data, we can create replicas of virtual or historical figures. This enables the realistic simulation of a specific character's personality, dialogue, and behavior, encompassing aspects like linguistic style and emotional expression.
% Personalized LLM assistants~\cite{} move beyond routine assistance to predict needs and deliver tailored recommendations
% by analyzing user data and preferences.
% Professional assistants can support user or replace export in complex tasks like research and medicine. 
% Emotional support can also be provided through simulated emotional states, leading to AI companions offering comfort and personalized mental health support.
% personal and professional 
% For instance, personalized assistants~\cite{tan2024personalized,zhuang2406hydra} move beyond traditional routine assistance to predict needs and deliver tailored recommendations by analyzing user data and preferences. 
% Professional agents 能在complex tasks like research and medicine.中表现出专家一样的能力。
% Professional agents demonstrate expert-level capabilities in professional fields like legal and medicine.
% research
% across fields complex tasks
% replaced experts
% Emotion-enhanced agents~\cite{tu2023characterchat, li2025psydi} provide emotional support by simulating affective states, leading to AI companions and personalized mental health interventions.
% hat offer comfort 
% emulate individual cognitive and behavioral patterns 
% This multifaceted application promises to revolutionize personal and professional life, enhancing productivity, well-being, and diverse professional practices.
% 单个digital twins的建立是群体智能不可或缺的一环，
% Moreover, LLMs are 
% The prospect of creating digital twin of oneself or anyone else (be it a fictional character, a historical figure, or a deceased loved one) is attractive. 
% Practically, personalized LLM agents~\cite{li2024personal} represent a compelling paradigm of LLM-as-digital-twin, and offers a wide range of potential applications from common\&professional personalized service (e.g., digital twin teachers and doctors) to emotional support (e.g., companion robot).
% Beyond these, individual digital twins can
% extend to social simulation, where interactions among these digital individuals give rise to intricate social networks, allowing for the analysis of complex human behaviors, interactions, and social dynamics.

% % is reshaping social science research through its adoption in agent-based modeling and simulation, enabling the understanding and analysis of complex human behaviors, interactions, and social dynamics.

% % within fields like economics, political science, and sociology,
% % These applications and studies 
% % These promising applications and studies rely on an assumption that LLMs
% %，考虑到多个领域对st的需求及其未来广阔的应用前景，

% % Digital twins hold immense promise for the future. However, the capacity of LLMs to simulate human behavior remains largely unvalidated.
% % 考虑到，缺乏深入研究
% % 在llm下面，前人相关研究，没target到dt，都可以广义的纳入到dt范围内，缺乏behavior维度，我们填补空缺。
% % 我们发现fiction是很好的sandbox/模拟环境，



% % simulate human behavior 
% % as a virtual replica mirroring real-world entity. 
% % Thus, a key question remains: \textit{Can LLM agents really serve as our digital twins?}
% % research to simulate humans behavior
% % There is an increasing trend to adopt Large Language Models (LLMs) as agent-based simulation tools for humans in various social science fields including economics, politics, psychology, ecology and sociology
% % Can LLMs reliably simulate human behavior? 
% % Beyond these applications, LLMs are increasingly being utilized as human proxies in research to simulate human behavior across diverse fields such as economics, political science, and sociology. These efforts aim to unravel complex human interactions and extend to the study of social dynamics. However, much of the existing research operates under an unverified assumption: that LLMs, as digital twins, can accurately replicate human behavior. This raises a critical question: Can LLMs truly simulate human behavior?
% % Beyond extending language model technology, LLMs as digital twins represent a crucial stepping stone towards embodied intelligence. Achieving true AI at the robotic level necessitates deep alignment or simulation of human cognition. Digital twin technology offers a pathway to bridge this gap, laying the groundwork for the comprehensive development of AI.
% % real people or characters existing in virtual worlds
% % 使模型能够更好地模仿特定动漫或影视角色的语气、知识和个性
% % The ability to understand and simulate human behavior is a long-standing goal in artificial intelligence. 
% % in addition, llm as digital twin 不仅是语言模型技术的延伸，更是迈向具身智能的重要过渡阶段。若要在机器人层面实现完整的人工智能，必须在精神层面对人类进行深度对齐或模拟。因此，我们希望通过数字孪生技术填补这一领域的空白，为未来人工智能的全面发展奠定基础。
% % Personalized LLM agents represent another application paradigm of digital twin. These agents transcend the capabilities of conventional virtual assistants by not only performing routine tasks but also emulating the user's cognitive patterns and behavioral tendencies.
% % Some pioneering research endeavors have focused on developing personalized assistants capable of analyzing users' historical data, preferences, and behavioral patterns to predict their needs and subsequently deliver tailored recommendations and services.
% % In professional contexts, Personal LLM Agents can assist or even substitute users in executing complex and specialized tasks, such as scientific research and medical procedures.
% % Furthermore, we anticipate that digital twins will evolve to provide emotional support by simulating users' emotional states. This could lead to the development of AI companions capable of understanding and responding to users' emotional needs, offering comfort, encouragement, and even personalized mental health support.
% % This multifaceted approach to personalized LLM assistants holds immense potential for revolutionizing various aspects of our lives, from enhancing productivity and personal well-being to transforming professional practices across diverse domains.
% % llm as digital twin的一个代表性应用范式是character role-playing，通过整合历史资料用大模型建模虚拟人物或历史人物的数字孪生体，实现逼真地模拟特定角色的个性、对话或行为（如语言风格、情感表达等），提升其角色扮演的准确性和拟人化程度。
% % 高度个性化的虚拟助手(Personal LLM Assistants)是digital twin的另一个应用范式，这些助手不仅可以执行常规任务，还可以模拟用户的思维模式和行为习惯。
% % 一些工作提出个性化助手，通过分析用户的历史数据、偏好和行为模式，预测用户的需求，并提供个性化的建议和服务。
% % 在专业领域，Personal LLM Agents可以协助或替代用户进行复杂的专业任务，如科研和医疗。
% % 另外，我们期待数字孪生通过模拟用户的情感状态，提供情感支持。
% % Despite its critical importance, the development of such a benchmark still faces three major 不足。
% % Character Role-Playing represents a intuitive form of digital twins,
% % LLMs, with their remarkable language capabilities~\cite{} and simulation talent~\cite{} , are paving the way for this vision. 其中大模型在 Character Role-Playing和Personal LLM Agents展现出的潜力也llm 让成为可能。LLMs are increasingly expected to serve as digital twins of individuals,
% % 在llm下面，前人相关研究，没target到dt，都可以广义的纳入到dt范围内，缺乏behavior维度，我们填补空缺。
% % 我们发现fiction是很好的sandbox/模拟环境，
% % related work
% % 重点：simulation：dt讲个体模拟=>仿真？高引
% % 其他领域对dt有广泛应用/兴趣/基础，但是在llm as dt没有深入研究，我们第一次提出dt，补全研究
% % 群体模拟/社会模拟：选举？
% While many role-play and LLM simulation work can be broadly considered as contributing to LLM-as-digital-twin research, they primarily focus on exploring LLMs ability in simulating persona-based dialogue~\cite{shen2024roleeval, wakaki2024comperdial, gao2023livechat}, knowledge~\cite{shen2024roleeval}, decision-making~\cite{xu2024character}, and comprehension capabilities~\cite{yuan2024evaluating}, the essential dimension of behavior remains largely unexplored. 
% % point-in-time nature
% Additionally, current evaluation pattern is limited, either by the static, non-continuous nature (e.g., single-choice questions) or the difficulty of quantifying results from unstable environments (e.g., sandboxes).
% % unstable metrics due to their point-in-time nature.
% % Additionally, current evaluation are often limited to static, non-continuous scenarios, which is limited to point-in-time analyses, such as single-choice question formats or overly free-form environments like sandboxes, leading to relatively unstable evaluation metrics.
% % To address this gap, 
% We recognize literature, especially novels and biographies, with its rich depictions of human behavior across diverse socio-historical contexts, as an exceptional simulated environment for LLMs, enabling them to model human behavior.
% Leveraging these rich resources, we introduce \datasetname, a novel benchmark for evaluating LLM's ability to simulate persona-around behavior over continuous time and space, which we term ``behavior chains''.
% % in dynamic, temporally extended contexts.
% \datasetname contains 1k high-quality behavior chains with 10 to 20 context-behavior nodes extracted automatically from fictions and biographies, along with detailed character profiles and histories.
% featuring 85\% fictional and 15\%  real characters, 
% recognize or predict
% within a chain,
% Additionally, we established an evaluation framework that challenges LLMs, 
% We set multi-choice and generation tasks measured by Average Accuracy and Chain Accuracy to provide a comprehensive assessment of LLM's behavior understanding and generation capabilities.

% , paving the way for more effective training and refinement strategies.
 % 2) The length and completeness of the provided historical context significantly impacts model predictions. 
% Replacing ground truth behaviors with model-chosen behaviors 
% In Performance degrades when model-chosen behaviors replace ground truth, highlighting the negative impact of accumulated historical errors.


% complex and 
% We further provide an extensible methodology for automatically acquiring these continuous behaviors of specific character and contextual information from this rich source material (novels and biographies). 

% for LLM's human behavior chain simulation capabilities.
% This framework








% we introduce BehaviorChain1001, a novel dataset comprising a sequence of behaviors—"behavior chain"—for 1001 character,  drawing on real-world narratives from novels and biographies, contextualized within detailed character histories. This task is designed to provide a comprehensive and longitudinal evaluation of LLMs' ability to discern and maintain character-consistent behaviors.
% Consequently, we established an evaluation framework employing two metrics: average behavior Accuracy and average Chain Accuracy. Evaluation on current state-of-the-art models demonstrated substantial deficiencies in their ability to accurately simulate human behavior.


% Forthermore, 
% 现有的评估形式
% evaluations, limited to point-in-time analyses, preclude assessment of consistency across a spatiotemporal range.

% In terms of evaluation approaches, current methods are often limited to static, non-continuous scenarios, such as single-choice question formats or overly free-form environments like sandboxes, leading to relatively unstable evaluation metrics.



% In this work, we take the lead to build , a benchmark specifically designed for assessing LLMs’ capablities in 



% Their progress in character role-play also showcases the nascent potential of LLMs as digital twins.


% We introduce the problem of evaluating LLM's behavioral simulation capability in dynamic, temporally extended contexts, building a framework based on spatiotemporal behavioral consistency. 

Our main contributions are as follows:

% We introduce the problem of evaluating [] capability in [], uilding a framework based on []. We introduce [], a [] benchmark for []. It contains a high-quality evaluation dataset with automatiaclly curated []. 并提供可拓展的方法从fiction/biography这一广泛素材中自动获取连续的角色行为信息和上下文信息。

% - 我们提出了对llm human behavior simulation 能力的更可靠的评估方案，We established an evaluation framework by gradually recognize or predict each behavior node in a behavior chain until completion, within a complex and dynamically changing context.并设置了long multi-choice和generation两个任务以及average behavior accuracy and average chain accuracy两个指标来实现对模型对角色行为理解及其角色行为生成能力地更全面的评估。

% - 我们在9个先进的模型上进行了全面的实验，Evaluation on current state-of-the-art models demonstrated substantial deficiencies in their ability to accurately simulate behavior in the chain.


% % 并从xx、xx等角度进行分析，
% • We establish four evaluation metrics to assess the questioning capability in education as a teacher of LLMs through evaluating their generated educational questions.
% • We conduct experimental evaluations of 11 LLMs, providing quantitative standards and subject orientations for each LLM’s questioning capability as a teacher.


\begin{itemize}
    \item To bridge the current research gap in digital twin, we propose \datasetname, the first benchmark designed to evaluate LLMs' ability to model behavioral chain dynamics. 


    % designed to evaluate LLMs in recognizing and generating character behaviors within dynamic and complex contexts. This dataset 
    % We also provide an extensible methodology for automated data acquisition.

    \item 
    % We design a framework to evaluate LLMs' capabilities in recognizing and generating character behaviors within dynamic and complex contexts.  This framework encompasses both multiple-choice and generation tasks, assessed using metrics of average behavior accuracy and average chain accuracy.
\datasetname comprises diverse, high-quality behavioral sequences, encompassing 15,846 distinct behaviors across 1,001 unique personas, systematically extracted from literary corpora using an automated, scalable pipeline. 
This dataset offers valuable material for advancing behavior simulation research.

    


 % evaluated through rigorously defined metrics including average accuracy (AvgAcc) and chain accuracy (ChainAcc).
% We design an evaluation framework employs dual-task evaluation comprising: (1) multiple-choice behavioral prediction tasks evaluating recognition capabilities, and (2) open-ended generation tasks testing behavioral synthesis abilities. 

% Our comprehensive dataset spans 12,500 annotated narrative scenarios covering 38 character archetypes and 127 distinct personality traits, with each scenario containing an average of 4.7 contextual shifts and behavior chains of 3.2 sequential actions. 
% Evaluation metrics include Average Behavior Accuracy (ABA) for discrete decisions and Chain Accuracy Rate (CAR) measuring causal coherence in generated sequences. 


    % Evaluation is performed using extended
    % that challenges LLMs, equipped with character profiles and histories, to progressively recognize and predict behaviors within a chain of behaviors unfolding in complex, evolving contexts.  
   
    \item
    % We conduct comprehensive evaluation on 10 state-of-the-art models and results revealed substantial performance deficiencies. In addition, detailed experiments were conducted to analyze the influence of key behaviors, history and context characteristics.
% We conducted a comprehensive evaluation of ten state-of-the-art models, and the results revealed substantial performance deficiencies.  
Comprehensive evaluations and analysis of ten state-of-the-art LLMs based on \datasetname revealed that accurately simulating continuous human behavior remains a significant challenge, even for advanced models like GPT-4o.
% Models struggled more with non-key behaviors and exhibited a snowball effect during chain completion, where early errors compounded to worsen later predictions. These findings highlight key areas for improvement in LLM-based digital twin development.


% Our systematic evaluation of ten state-of-the-art models revealed significant performance gaps in persona-based behavior simulation. 
% Even advanced models such as GPT-4o demonstrated accuracy below 60\%.

% These findings offer new insights into the technical challenges hindering robust behaviors simulation, particularly the interplay between contextual understanding and error accumulation in extended dialogues.
 
% 强如gpt-4o的模型获得的的正确率低于60\%。
% We also performed in-depth analyses of 
% 模型对次要关键行为的掌握尤其不足，对近期历史的依赖以及在compele整条链时可能发生的滚雪球效应。
% which provided valuable insights into the factors that contribute to or impede persona-based behavior simulation.

% the influence of key behaviors, history, and context characteristics, 

   % Further experiments analyzing the influence of key behaviors, history, and context characteristics provided valuable insights into the factors that contribute to or hinder successful persona-based behavior simulation.
 
   

    % Experiments on ten state-of-the-art models reveal significant performance deficiencies.
    \end{itemize}



% \begin{figure}[!t]
%   \centering
%   \includegraphics[width=0.4\textwidth]{latex/picture/gai.pdf}
%   \caption{We envision models, equipped with a character's history, acting as their digital twin.}
%   \label{fig:intro}
% \end{figure}