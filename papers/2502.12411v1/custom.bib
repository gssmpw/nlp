% Use this file for citations not found in the ACL Anthology (contained in "anthology.bib").

@book{Aho:72,
    author  = {Alfred V. Aho and Jeffrey D. Ullman},
    title   = {The Theory of Parsing, Translation and Compiling},
    year    = "1972",
    volume  = "1",
    publisher = {Prentice-Hall},
    address = {Englewood Cliffs, NJ}
}

@book{APA:83,
    author  = {{American Psychological Association}},
    title   = {Publications Manual},
    year    = "1983",
    publisher = {American Psychological Association},
    address = {Washington, DC}
}

@article{Chandra:81,
	author = {Ashok K. Chandra and Dexter C. Kozen and Larry J. Stockmeyer},
	year = "1981",
	title = {Alternation},
	journal = {Journal of the Association for Computing Machinery},
	volume = "28",
	number = "1",
	pages = "114--133",
	doi = "10.1145/322234.322243",
}

@inproceedings{andrew2007scalable,
  title={Scalable training of {L1}-regularized log-linear models},
  author={Andrew, Galen and Gao, Jianfeng},
  booktitle={Proceedings of the 24th International Conference on Machine Learning},
  pages={33--40},
  year={2007},
}

@book{Gusfield:97,
    author  = {Dan Gusfield},
    title   = {Algorithms on Strings, Trees and Sequences},
    year    = "1997",
    publisher = {Cambridge University Press},
    address = {Cambridge, UK}
}

@article{rasooli-tetrault-2015,
    author    = {Mohammad Sadegh Rasooli and Joel R. Tetreault},
    title     = {Yara Parser: {A} Fast and Accurate Dependency Parser},
    journal   = {Computing Research Repository},
    volume    = {arXiv:1503.06733},
    year      = {2015},
    url       = {http://arxiv.org/abs/1503.06733},
    note    = {version 2}
}

@article{Ando2005,
	Acmid = {1194905},
	Author = {Ando, Rie Kubota and Zhang, Tong},
	Issn = {1532-4435},
	Issue_Date = {12/1/2005},
	Journal = {Journal of Machine Learning Research},
	Month = dec,
	Numpages = {37},
	Pages = {1817--1853},
	Publisher = {JMLR.org},
	Title = {A Framework for Learning Predictive Structures from Multiple Tasks and Unlabeled Data},
	Volume = {6},
	Year = {2005}
}

@article{achiam2023gpt,
  title={Gpt-4 technical report},
  author={Achiam, Josh and Adler, Steven and Agarwal, Sandhini and Ahmad, Lama and Akkaya, Ilge and Aleman, Florencia Leoni and Almeida, Diogo and Altenschmidt, Janko and Altman, Sam and Anadkat, Shyamal and others},
  journal={arXiv preprint arXiv:2303.08774},
  year={2023}
}

@article{geng2023openllama,
  title={Openllama: An open reproduction of llama},
  author={Geng, Xinyang and Liu, Hao},
  journal={URL: https://github. com/openlm-research/open\_llama},
  year={2023}
}

@article{bai2023qwen,
  title={Qwen technical report},
  author={Bai, Jinze and Bai, Shuai and Chu, Yunfei and Cui, Zeyu and Dang, Kai and Deng, Xiaodong and Fan, Yang and Ge, Wenbin and Han, Yu and Huang, Fei and others},
  journal={arXiv preprint arXiv:2309.16609},
  year={2023}
}

@article{inan2023llama,
  title={Llama guard: Llm-based input-output safeguard for human-ai conversations},
  author={Inan, Hakan and Upasani, Kartikeya and Chi, Jianfeng and Rungta, Rashi and Iyer, Krithika and Mao, Yuning and Tontchev, Michael and Hu, Qing and Fuller, Brian and Testuggine, Davide and others},
  journal={arXiv preprint arXiv:2312.06674},
  year={2023}
}

@misc{meta_llama_guard_2,
  author       = {Meta and Llama},
  title        = {Meta Llama Guard 2: Model Cards and Prompt Formats},
  year         = {n.d.},
  howpublished = {\url{https://www.llama.com/docs/model-cards-and-prompt-formats/meta-llama-guard-2/}},
  note         = {Accessed: 2025-01-08}
}

@misc{llama_guard_3,
  author       = {Llama},
  title        = {Llama Guard 3: Model Cards and Prompt Formats},
  year         = {n.d.},
  howpublished = {\url{https://www.llama.com/docs/model-cards-and-prompt-formats/llama-guard-3/}},
  note         = {Accessed: 2025-01-08}
}

@misc{prompt_guard,
  author       = {Llama},
  title        = {Prompt Guard: Model Cards and Prompt Formats},
  year         = {n.d.},
  howpublished = {\url{https://www.llama.com/docs/model-cards-and-prompt-formats/prompt-guard/}},
  note         = {Accessed: 2025-01-08}
}


@inproceedings{wang-etal-2024-assessing,
    title = "Assessing Factual Reliability of Large Language Model Knowledge",
    author = "Wang, Weixuan  and
      Haddow, Barry  and
      Birch, Alexandra  and
      Peng, Wei",
    editor = "Duh, Kevin  and
      Gomez, Helena  and
      Bethard, Steven",
    booktitle = "Proceedings of the 2024 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies (Volume 1: Long Papers)",
    month = jun,
    year = "2024",
    address = "Mexico City, Mexico",
    publisher = "Association for Computational Linguistics",
    url = "https://aclanthology.org/2024.naacl-long.46/",
    doi = "10.18653/v1/2024.naacl-long.46",
    pages = "805--819",
}

@article{azaria2023internal,
  title={The internal state of an LLM knows when it's lying},
  author={Azaria, Amos and Mitchell, Tom},
  journal={arXiv preprint arXiv:2304.13734},
  year={2023}
}

@article{li2024gentel,
  title={GenTel-Safe: A Unified Benchmark and Shielding Framework for Defending Against Prompt Injection Attacks},
  author={Li, Rongchang and Chen, Minjie and Hu, Chang and Chen, Han and Xing, Wenpeng and Han, Meng},
  journal={arXiv preprint arXiv:2409.19521},
  year={2024}
}

@article{Zhang2023,
  author    = {Zhexin Zhang and others},
  title     = {Defending Large Language Models Against Jailbreaking Attacks Through Goal Prioritization},
  journal   = {arXiv preprint},
  volume    = {arXiv:2311.09096},
  year      = {2023},
  url       = {https://arxiv.org/abs/2311.09096},
  archivePrefix = {arXiv},
  eprint    = {2311.09096},
  primaryClass = {cs.CL}
}

@article{min2023factscore,
  title={Factscore: Fine-grained atomic evaluation of factual precision in long form text generation},
  author={Min, Sewon and Krishna, Kalpesh and Lyu, Xinxi and Lewis, Mike and Yih, Wen-tau and Koh, Pang Wei and Iyyer, Mohit and Zettlemoyer, Luke and Hajishirzi, Hannaneh},
  journal={arXiv preprint arXiv:2305.14251},
  year={2023}
}

@article{manakul2023selfcheckgpt,
  title={Selfcheckgpt: Zero-resource black-box hallucination detection for generative large language models},
  author={Manakul, Potsawee and Liusie, Adian and Gales, Mark JF},
  journal={arXiv preprint arXiv:2303.08896},
  year={2023}
}

@article{kadavath2022language,
  title={Language models (mostly) know what they know},
  author={Kadavath, Saurav and Conerly, Tom and Askell, Amanda and Henighan, Tom and Drain, Dawn and Perez, Ethan and Schiefer, Nicholas and Hatfield-Dodds, Zac and DasSarma, Nova and Tran-Johnson, Eli and others},
  journal={arXiv preprint arXiv:2207.05221},
  year={2022}
}

@article{chern2023factool,
  title={Factool: Factuality detection in generative AI-A tool augmented framework for multi-task and multi-domain scenarios. CoRR, abs/2307.13528, 2023. doi: 10.48550},
  author={Chern, I-Chun and Chern, Steffi and Chen, Shiqi and Yuan, Weizhe and Feng, Kehua and Zhou, Chunting and He, Junxian and Neubig, Graham and Liu, Pengfei},
  journal={arXiv preprint arXiv.2307.13528},
  year={2023}
}

@article{yehuda2024search,
  title={In Search of Truth: An Interrogation Approach to Hallucination Detection},
  author={Yehuda, Yakir and Malkiel, Itzik and Barkan, Oren and Weill, Jonathan and Ronen, Royi and Koenigstein, Noam},
  journal={arXiv preprint arXiv:2403.02889},
  year={2024}
}

@article{su2024unsupervised,
  title={Unsupervised real-time hallucination detection based on the internal states of large language models},
  author={Su, Weihang and Wang, Changyue and Ai, Qingyao and Hu, Yiran and Wu, Zhijing and Zhou, Yujia and Liu, Yiqun},
  journal={arXiv preprint arXiv:2403.06448},
  year={2024}
}

@article{zhang2023enhancing,
  title={Enhancing uncertainty-based hallucination detection with stronger focus},
  author={Zhang, Tianhang and Qiu, Lin and Guo, Qipeng and Deng, Cheng and Zhang, Yue and Zhang, Zheng and Zhou, Chenghu and Wang, Xinbing and Fu, Luoyi},
  journal={arXiv preprint arXiv:2311.13230},
  year={2023}
}

@misc{protectai,
  author       = {Protect AI},
  title        = {Protect AI},
  year         = {2025},
  url          = {https://protectai.com/},
  note         = {Accessed: 2025-01-08}
}

@misc{epivolis_hyperion,
  author       = {Epivolis},
  title        = {Hyperion: A Lightweight RoBERTa-based Binary Classifier for Jailbreak Detection},
  year         = {2024},
  url          = {https://huggingface.co/Epivolis/Hyperion},
  note         = {Accessed: 2025-01-08}
}

@misc{lakera_guard_2025,
  author       = {Lakera},
  title        = {Lakera Guard: Protect your LLM applications against security threats},
  year         = {2025},
  url          = {https://www.lakera.ai/lakera-guard},
  note         = {Accessed: 2025-01-08}
}

@misc{fmops_distilbert_prompt_injection_2023,
  author       = {fmops},
  title        = {distilbert-prompt-injection: A Fine-Tuned DistilBERT Model for Prompt Injection Detection},
  year         = {2023},
  url          = {https://huggingface.co/fmops/distilbert-prompt-injection},
  note         = {Accessed: 2025-01-08},
  license      = {Apache-2.0},
  publisher    = {Hugging Face}
}

@misc{deepset_deberta_v3_base_injection_2023,
  author       = {deepset},
  title        = {deberta-v3-base-injection: A Fine-Tuned DeBERTa-v3 Model for Prompt Injection Detection},
  year         = {2023},
  url          = {https://huggingface.co/deepset/deberta-v3-base-injection},
  note         = {Accessed: 2025-01-08},
  license      = {MIT},
  publisher    = {Hugging Face}
}

@software{whylabs_langkit_2024,
  author       = {WhyLabs},
  title        = {LangKit: An Open-Source Text Metrics Toolkit for Monitoring Language Models},
  year         = {2024},
  url          = {https://github.com/whylabs/langkit},
  note         = {Accessed: 2025-01-08},
  version      = {1.0},
  license      = {Apache-2.0},
  publisher    = {GitHub}
}

@misc{openai_moderation_2024,
  author       = {OpenAI},
  title        = {Moderation API: A Tool for Content Moderation in Language Models},
  year         = {2024},
  url          = {https://platform.openai.com/docs/guides/moderation/},
  note         = {Accessed: 2025-01-08},
  publisher    = {OpenAI}
}

@misc{perspective_api_2024,
  author       = {Perspective},
  title        = {Perspective API: A Tool for Toxicity Detection in Online Content},
  year         = {2024},
  url          = {https://perspectiveapi.com/},
  note         = {Accessed: 2025-01-08},
  publisher    = {Google Jigsaw}
}

@misc{azure_ai_content_safety_2024,
  author       = {Microsoft},
  title        = {Azure AI Content Safety: Detect and Moderate Harmful Content in Text and Images},
  year         = {2024},
  url          = {https://azure.microsoft.com/en-us/products/ai-services/ai-content-safety},
  note         = {Accessed: 2025-01-08},
  publisher    = {Microsoft Azure}
}

@misc{huawei_content_moderation_api,
  author    = {Huawei Cloud},
  title     = {API Overview: Content Moderation},
  year      = {2024},
  url       = {https://support.huaweicloud.com/intl/en-us/api-moderation/moderation_03_0022.html},
  note      = {Accessed: 2025-02-08},
  publisher = {Huawei Cloud}
}

@misc{baidu_text_censoring,
  author    = {BaiduAI},
  title     = {Text Censoring Technology},
  year      = {2024},
  url       = {https://ai.baidu.com/tech/textcensoring},
  note      = {Accessed: 2025-02-08},
  publisher = {Baidu AI}
}

@misc{iflytek_text_compliance,
  author    = {iFLYTEK},
  title     = {Text Compliance Service},
  year      = {2024},
  url       = {https://www.xfyun.cn/services/preview-text},
  note      = {Accessed: 2025-02-08},
  publisher = {iFLYTEK}
}

@misc{aliyun_image_audit,
  author    = {AlibabaCloud},
  title     = {Content Moderation},
  year      = {2024},
  url       = {https://vision.aliyun.com/imageaudit},
  note      = {Accessed: 2025-02-08},
  publisher = {Alibaba Cloud}
}

@article{xie2024gradsafe,
  title={GradSafe: Detecting Unsafe Prompts for LLMs via Safety-Critical Gradient Analysis},
  author={Xie, Yueqi and Fang, Minghong and Pi, Renjie and Gong, Neil},
  journal={arXiv preprint arXiv:2402.13494},
  year={2024}
}

@article{brown2020language,
  title={Language models are few-shot learners},
  author={Brown, Tom and Mann, Benjamin and Ryder, Nick and Subbiah, Melanie and Kaplan, Jared D and Dhariwal, Prafulla and Neelakantan, Arvind and Shyam, Pranav and Sastry, Girish and Askell, Amanda and others},
  journal={Advances in neural information processing systems},
  volume={33},
  pages={1877--1901},
  year={2020}
}

@article{lin2023toxicchat,
  title={Toxicchat: Unveiling hidden challenges of toxicity detection in real-world user-ai conversation},
  author={Lin, Zi and Wang, Zihan and Tong, Yongqi and Wang, Yangkun and Guo, Yuxin and Wang, Yujia and Shang, Jingbo},
  journal={arXiv preprint arXiv:2310.17389},
  year={2023}
}

@article{rottger2023xstest,
  title={Xstest: A test suite for identifying exaggerated safety behaviours in large language models},
  author={R{\"o}ttger, Paul and Kirk, Hannah Rose and Vidgen, Bertie and Attanasio, Giuseppe and Bianchi, Federico and Hovy, Dirk},
  journal={arXiv preprint arXiv:2308.01263},
  year={2023}
}

@misc{rounakbanik_the_movies_dataset,
  author       = {Rounak Banik},
  title        = {The Movies Dataset},
  year         = {2017},
  howpublished = {\url{https://www.kaggle.com/datasets/rounakbanik/the-movies-dataset}},
  note         = {Accessed: 2025-01-08}
}

@misc{nelgiriyewithana_countries_of_the_world_2023,
  author       = {Nel Giriyewithana},
  title        = {Countries of the World 2023},
  year         = {2023},
  howpublished = {\url{https://www.kaggle.com/datasets/nelgiriyewithana/countries-of-the-world-2023}},
  note         = {Accessed: 2025-01-08}
}

@article{touvron2023llama,
  title={Llama 2: Open foundation and fine-tuned chat models},
  author={Touvron, Hugo and Martin, Louis and Stone, Kevin and Albert, Peter and Almahairi, Amjad and Babaei, Yasmine and Bashlykov, Nikolay and Batra, Soumya and Bhargava, Prajjwal and Bhosale, Shruti and others},
  journal={arXiv preprint arXiv:2307.09288},
  year={2023}
}

@article{reimers2019sentence,
  title={Sentence-BERT: Sentence Embeddings using Siamese BERT-Networks},
  author={Reimers, N},
  journal={arXiv preprint arXiv:1908.10084},
  year={2019}
}


@misc{metallamaguard2,
  author =       {Llama Team},
  title =        {Meta Llama Guard 2},
  howpublished = {\url{https://github.com/meta-llama/PurpleLlama/blob/main/Llama-Guard2/MODEL_CARD.md}},
  year =         {2024}
}

@misc{dubey2024llama3herdmodels,
  title =         {The Llama 3 Herd of Models},
  author =        {Llama Team, AI @ Meta},
  year =          {2024},
  eprint =        {2407.21783},
  archivePrefix = {arXiv},
  primaryClass =  {cs.AI},
  url =           {https://arxiv.org/abs/2407.21783}
}

@inproceedings{DBLP:conf/emnlp/ZhangLMZLKSSSWH24,
  author       = {Zhexin Zhang and
                  Yida Lu and
                  Jingyuan Ma and
                  Di Zhang and
                  Rui Li and
                  Pei Ke and
                  Hao Sun and
                  Lei Sha and
                  Zhifang Sui and
                  Hongning Wang and
                  Minlie Huang},
  editor       = {Yaser Al{-}Onaizan and
                  Mohit Bansal and
                  Yun{-}Nung Chen},
  title        = {ShieldLM: Empowering LLMs as Aligned, Customizable and Explainable
                  Safety Detectors},
  booktitle    = {Findings of the Association for Computational Linguistics: {EMNLP}
                  2024, Miami, Florida, USA, November 12-16, 2024},
  pages        = {10420--10438},
  publisher    = {Association for Computational Linguistics},
  year         = {2024}
}

@inproceedings{DBLP:conf/acl/ZhangGLY24,
  author       = {Dongxu Zhang and
                  Varun Gangal and
                  Barrett Martin Lattimer and
                  Yi Yang},
  editor       = {Lun{-}Wei Ku and
                  Andre Martins and
                  Vivek Srikumar},
  title        = {Enhancing Hallucination Detection through Perturbation-Based Synthetic
                  Data Generation in System Responses},
  booktitle    = {Findings of the Association for Computational Linguistics, {ACL} 2024,
                  Bangkok, Thailand and virtual meeting, August 11-16, 2024},
  pages        = {13321--13332},
  publisher    = {Association for Computational Linguistics},
  year         = {2024},
  url          = {https://doi.org/10.18653/v1/2024.findings-acl.789},
  doi          = {10.18653/V1/2024.FINDINGS-ACL.789},
  timestamp    = {Tue, 24 Sep 2024 10:55:49 +0200},
  biburl       = {https://dblp.org/rec/conf/acl/ZhangGLY24.bib},
  bibsource    = {dblp computer science bibliography, https://dblp.org}
}

@article{chen2024unified,
  title={Unified hallucination detection for multimodal large language models},
  author={Chen, Xiang and Wang, Chenxi and Xue, Yida and Zhang, Ningyu and Yang, Xiaoyan and Li, Qiang and Shen, Yue and Liang, Lei and Gu, Jinjie and Chen, Huajun},
  journal={arXiv preprint arXiv:2402.03190},
  year={2024}
}

@article{shrikumar2016not,
  title={Not just a black box: Learning important features through propagating activation differences},
  author={Shrikumar, Avanti and Greenside, Peyton and Shcherbina, Anna and Kundaje, Anshul},
  journal={arXiv preprint arXiv:1605.01713},
  year={2016}
}


@article{bach2015pixel,
  title={On pixel-wise explanations for non-linear classifier decisions by layer-wise relevance propagation},
  author={Bach, Sebastian and Binder, Alexander and Montavon, Gr{\'e}goire and Klauschen, Frederick and M{\"u}ller, Klaus-Robert and Samek, Wojciech},
  journal={PloS one},
  volume={10},
  number={7},
  pages={e0130140},
  year={2015},
  publisher={Public Library of Science San Francisco, CA USA}
}

@inproceedings{selvaraju2017grad,
  title={Grad-cam: Visual explanations from deep networks via gradient-based localization},
  author={Selvaraju, Ramprasaath R and Cogswell, Michael and Das, Abhishek and Vedantam, Ramakrishna and Parikh, Devi and Batra, Dhruv},
  booktitle={Proceedings of the IEEE international conference on computer vision},
  pages={618--626},
  year={2017}
}
@article{han2024wildguard,
  title={Wildguard: Open one-stop moderation tools for safety risks, jailbreaks, and refusals of llms},
  author={Han, Seungju and Rao, Kavel and Ettinger, Allyson and Jiang, Liwei and Lin, Bill Yuchen and Lambert, Nathan and Choi, Yejin and Dziri, Nouha},
  journal={arXiv preprint arXiv:2406.18495},
  year={2024}
}
@article{chi2024llama,
  title={Llama guard 3 vision: Safeguarding human-ai image understanding conversations},
  author={Chi, Jianfeng and Karn, Ujjwal and Zhan, Hongyuan and Smith, Eric and Rando, Javier and Zhang, Yiming and Plawiak, Kate and Coudert, Zacharie Delpierre and Upasani, Kartikeya and Pasupuleti, Mahesh},
  journal={arXiv preprint arXiv:2411.10414},
  year={2024}
}

@misc{Detoxify,
  title={Detoxify},
  author={Hanu, Laura and {Unitary team}},
  howpublished={Github. https://github.com/unitaryai/detoxify},
  year={2020}
}


@inproceedings{caselli-etal-2021-hatebert,
    title = "{H}ate{BERT}: Retraining {BERT} for Abusive Language Detection in {E}nglish",
    author = "Caselli, Tommaso  and
      Basile, Valerio  and
      Mitrovi{\'c}, Jelena  and
      Granitzer, Michael",
    editor = "Mostafazadeh Davani, Aida  and
      Kiela, Douwe  and
      Lambert, Mathias  and
      Vidgen, Bertie  and
      Prabhakaran, Vinodkumar  and
      Waseem, Zeerak",
    booktitle = "Proceedings of the 5th Workshop on Online Abuse and Harms (WOAH 2021)",
    month = aug,
    year = "2021",
    address = "Online",
    publisher = "Association for Computational Linguistics",
    pages = "17--25"
}

@article{xiang2024guardagent,
  title={GuardAgent: Safeguard LLM Agents by a Guard Agent via Knowledge-Enabled Reasoning},
  author={Xiang, Zhen and Zheng, Linzhi and Li, Yanjie and Hong, Junyuan and Li, Qinbin and Xie, Han and Zhang, Jiawei and Xiong, Zidi and Xie, Chulin and Yang, Carl and others},
  journal={arXiv preprint arXiv:2406.09187},
  year={2024}
}

@article{yang2024qwen2,
  title={Qwen2. 5 technical report},
  author={Yang, An and Yang, Baosong and Zhang, Beichen and Hui, Binyuan and Zheng, Bo and Yu, Bowen and Li, Chengyuan and Liu, Dayiheng and Huang, Fei and Wei, Haoran and others},
  journal={arXiv preprint arXiv:2412.15115},
  year={2024}
}

@article{team2024gemma,
  title={Gemma: Open models based on gemini research and technology},
  author={Team, Gemma and Mesnard, Thomas and Hardin, Cassidy and Dadashi, Robert and Bhupatiraju, Surya and Pathak, Shreya and Sifre, Laurent and Rivi{\`e}re, Morgane and Kale, Mihir Sanjay and Love, Juliette and others},
  journal={arXiv preprint arXiv:2403.08295},
  year={2024}
}

@article{rebedea2023nemo,
  title={Nemo guardrails: A toolkit for controllable and safe llm applications with programmable rails},
  author={Rebedea, Traian and Dinu, Razvan and Sreedhar, Makesh and Parisien, Christopher and Cohen, Jonathan},
  journal={arXiv preprint arXiv:2310.10501},
  year={2023}
}



@InProceedings{pmlr-v70-sundararajan17a,
  title = 	 {Axiomatic Attribution for Deep Networks},
  author =       {Mukund Sundararajan and Ankur Taly and Qiqi Yan},
  booktitle = 	 {Proceedings of the 34th International Conference on Machine Learning},
  pages = 	 {3319--3328},
  year = 	 {2017},
  editor = 	 {Precup, Doina and Teh, Yee Whye},
  volume = 	 {70},
  series = 	 {Proceedings of Machine Learning Research},
  month = 	 {06--11 Aug},
  publisher =    {PMLR},
  pdf = 	 {http://proceedings.mlr.press/v70/sundararajan17a/sundararajan17a.pdf},
  url = 	 {https://proceedings.mlr.press/v70/sundararajan17a.html},
  abstract = 	 {We study the problem of attributing the prediction of a deep network to its input features, a problem previously studied by several other works. We identify two fundamental axiomsâ€”Sensitivity and Implementation Invariance that attribution methods ought to satisfy. We show that they are not satisfied by most known attribution methods, which we consider to be a fundamental weakness of those methods. We use the axioms to guide the design of a new attribution method called Integrated Gradients. Our method requires no modification to the original network and is extremely simple to implement; it just needs a few calls to the standard gradient operator. We apply this method to a couple of image models, a couple of text models and a chemistry model, demonstrating its ability to debug networks, to extract rules from a network, and to enable users to engage with models better.}
}
