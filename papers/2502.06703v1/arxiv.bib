% Background
@book{sutton2018reinforcement,
  title     = {Reinforcement learning: An introduction},
  author    = {Sutton, Richard S and Barto, Andrew G},
  publisher = {MIT press},
  year      = {2018}
}

@misc{sutton2019bitter,
  title  = {The Bitter Lesson},
  author = {Sutton, Richard},
  url    = {http://www.incompleteideas.net/IncIdeas/BitterLesson.html},
  year   = {2019}
}

@article{kaplan2020scaling,
  title   = {Scaling laws for neural language models},
  author  = {Kaplan, Jared and McCandlish, Sam and Henighan, Tom and Brown, Tom B and Chess, Benjamin and Child, Rewon and Gray, Scott and Radford, Alec and Wu, Jeffrey and Amodei, Dario},
  journal = {arXiv preprint arXiv:2001.08361},
  year    = {2020}
}

@inproceedings{hoffmann2022training,
  title     = {Training Compute-Optimal Large Language Models},
  author    = {Hoffmann, Jordan and Borgeaud, Sebastian and Mensch, Arthur and Buchatskaya, Elena and Cai, Trevor and Rutherford, Eliza and de Las Casas, Diego and Hendricks, Lisa Anne and Welbl, Johannes and Clark, Aidan and Hennigan, Thomas and Noland, Eric and Millican, Katherine and van den Driessche, George and Damoc, Bogdan and Guy, Aurelia and Osindero, Simon and Simonyan, Kar\'{e}n and Elsen, Erich and Vinyals, Oriol and Rae, Jack and Sifre, Laurent},
  booktitle = {Advances in Neural Information Processing Systems (NeurIPS)},
  pages     = {30016--30030},
  volume    = {35},
  year      = {2022}
}

@inproceedings{sardana2023beyond,
  title     = {Beyond Chinchilla-Optimal: Accounting for Inference in Language Model Scaling Laws},
  author    = {Sardana, Nikhil and Portes, Jacob and Doubov, Sasha and Frankle, Jonathan},
  booktitle = {International Conference on Machine Learning (ICML)},
  pages     = {43445--43460},
  year      = {2024},
  volume    = {235}
}

@article{sun2024inverse,
  title   = {Inverse-RLignment: Inverse Reinforcement Learning from Demonstrations for LLM Alignment},
  author  = {Sun, Hao and van der Schaar, Mihaela},
  journal = {arXiv preprint arXiv:2405.15624},
  year    = {2024}
}

% LLM
@misc{Claude,
  title  = {Introducing {Claude}},
  author = {Anthropic},
  url    = {https://www.anthropic.com/index/introducing-claude/},
  year   = {2023}
}

@article{GPT-4,
  title   = {GPT-4 Technical Report},
  author  = {OpenAI},
  journal = {arXiv preprint arXiv:2303.08774},
  year    = {2023}
}

@article{GPT-4o,
  title   = {GPT-4o System Card},
  author  = {Hurst, Aaron and Lerer, Adam and Goucher, Adam P and Perelman, Adam and Ramesh, Aditya and Clark, Aidan and Ostrow, AJ and Welihinda, Akila and Hayes, Alan and Radford, Alec and others},
  journal = {arXiv preprint arXiv:2410.21276},
  year    = {2024}
}

@misc{o1,
  title  = {Learning to Reason with LLMs},
  author = {OpenAI},
  url    = {https://openai.com/index/learning-to-reason-with-llms/},
  year   = {2024}
}

@article{Mistral,
  title   = {Mistral 7B},
  author  = {Jiang, Albert Q and Sablayrolles, Alexandre and Mensch, Arthur and Bamford, Chris and Chaplot, Devendra Singh and Casas, Diego de las and Bressand, Florian and Lengyel, Gianna and Lample, Guillaume and Saulnier, Lucile and others},
  journal = {arXiv preprint arXiv:2310.06825},
  year    = {2023}
}

@article{Llama2,
  title   = {Llama 2: Open foundation and fine-tuned chat models},
  author  = {Touvron, Hugo and Martin, Louis and Stone, Kevin and Albert, Peter and Almahairi, Amjad and Babaei, Yasmine and Bashlykov, Nikolay and Batra, Soumya and Bhargava, Prajjwal and Bhosale, Shruti and others},
  journal = {arXiv preprint arXiv:2307.09288},
  year    = {2023}
}

@article{Llama3,
  title   = {The llama 3 herd of models},
  author  = {Dubey, Abhimanyu and Jauhri, Abhinav and Pandey, Abhinav and Kadian, Abhishek and Al-Dahle, Ahmad and Letman, Aiesha and Mathur, Akhil and Schelten, Alan and Yang, Amy and Fan, Angela and others},
  journal = {arXiv preprint arXiv:2407.21783},
  year    = {2024}
}

@article{Gemma2,
  title   = {Gemma 2: Improving open language models at a practical size},
  author  = {{Gemma Team} and Riviere, Morgane and Pathak, Shreya and Sessa, Pier Giuseppe and Hardin, Cassidy and Bhupatiraju, Surya and Hussenot, L{\'e}onard and Mesnard, Thomas and Shahriari, Bobak and Ram{\'e}, Alexandre and others},
  journal = {arXiv preprint arXiv:2408.00118},
  year    = {2024}
}

@misc{Ministral,
  title  = {Un Ministral, des Ministraux},
  url    = {https://mistral.ai/news/ministraux/},
  author = {{Mistral AI Team}},
  month  = {October},
  year   = {2024}
}

@article{Qwen2,
  title   = {Qwen2 Technical Report},
  author  = {An Yang and Baosong Yang and Binyuan Hui and Bo Zheng and Bowen Yu and Chang Zhou and Chengpeng Li and Chengyuan Li and Dayiheng Liu and Fei Huang and Guanting Dong and Haoran Wei and Huan Lin and Jialong Tang and Jialin Wang and Jian Yang and Jianhong Tu and Jianwei Zhang and Jianxin Ma and Jin Xu and Jingren Zhou and Jinze Bai and Jinzheng He and Junyang Lin and Kai Dang and Keming Lu and Keqin Chen and Kexin Yang and Mei Li and Mingfeng Xue and Na Ni and Pei Zhang and Peng Wang and Ru Peng and Rui Men and Ruize Gao and Runji Lin and Shijie Wang and Shuai Bai and Sinan Tan and Tianhang Zhu and Tianhao Li and Tianyu Liu and Wenbin Ge and Xiaodong Deng and Xiaohuan Zhou and Xingzhang Ren and Xinyu Zhang and Xipin Wei and Xuancheng Ren and Yang Fan and Yang Yao and Yichang Zhang and Yu Wan and Yunfei Chu and Yuqiong Liu and Zeyu Cui and Zhenru Zhang and Zhihao Fan},
  journal = {arXiv preprint arXiv:2407.10671},
  year    = {2024}
}

@article{Qwen2.5,
  title   = {Qwen2.5 Technical Report},
  author  = {An Yang and Baosong Yang and Beichen Zhang and Binyuan Hui and Bo Zheng and Bowen Yu and Chengyuan Li and Dayiheng Liu and Fei Huang and Haoran Wei and Huan Lin and Jian Yang and Jianhong Tu and Jianwei Zhang and Jianxin Yang and Jiaxi Yang and Jingren Zhou and Junyang Lin and Kai Dang and Keming Lu and Keqin Bao and Kexin Yang and Le Yu and Mei Li and Mingfeng Xue and Pei Zhang and Qin Zhu and Rui Men and Runji Lin and Tianhao Li and Tingyu Xia and Xingzhang Ren and Xuancheng Ren and Yang Fan and Yang Su and Yichang Zhang and Yu Wan and Yuqiong Liu and Zeyu Cui and Zhenru Zhang and Zihan Qiu},
  journal = {arXiv preprint arXiv:2412.15115},
  year    = {2024}
}

@article{Qwen2.5-Math,
  title   = {Qwen2.5-math technical report: Toward mathematical expert model via self-improvement},
  author  = {An Yang and Beichen Zhang and Binyuan Hui and Bofei Gao and Bowen Yu and Chengpeng Li and Dayiheng Liu and Jianhong Tu and Jingren Zhou and Junyang Lin and Keming Lu and Mingfeng Xue and Runji Lin and Tianyu Liu and Xingzhang Ren and Zhenru Zhang},
  journal = {arXiv preprint arXiv:2409.12122},
  year    = {2024}
}

@article{Qwen2.5-Coder,
  title   = {Qwen2.5-coder technical report},
  author  = {Hui, Binyuan and Yang, Jian and Cui, Zeyu and Yang, Jiaxi and Liu, Dayiheng and Zhang, Lei and Liu, Tianyu and Zhang, Jiajun and Yu, Bowen and Lu, Keming and others},
  journal = {arXiv preprint arXiv:2409.12186},
  year    = {2024}
}





% Datasets
@inproceedings{MATH,
  title     = {Measuring Mathematical Problem Solving With the {MATH} Dataset},
  author    = {Dan Hendrycks and Collin Burns and Saurav Kadavath and Akul Arora and Steven Basart and Eric Tang and Dawn Song and Jacob Steinhardt},
  booktitle = {Advances in Neural Information Processing Systems Datasets and Benchmarks Track (Round 2)},
  year      = {2021},
  url       = {https://openreview.net/forum?id=7Bywt2mQsCe}
}

@article{GSM8K,
  title   = {Training verifiers to solve math word problems},
  author  = {Cobbe, Karl and Kosaraju, Vineet and Bavarian, Mohammad and Chen, Mark and Jun, Heewoo and Kaiser, Lukasz and Plappert, Matthias and Tworek, Jerry and Hilton, Jacob and Nakano, Reiichiro and others},
  journal = {arXiv preprint arXiv:2110.14168},
  year    = {2021}
}

@misc{AMC23,
  title  = {AMC 2023},
  author = {{AI-MO}},
  url    = {https://huggingface.co/datasets/AI-MO/aimo-validation-amc},
  year   = {2024}
}

@misc{AIME24,
  title  = {AIME 2024},
  author = {{AI-MO}},
  url    = {https://huggingface.co/datasets/AI-MO/aimo-validation-aime},
  year   = {2024}
}




% Test-Time Compute
@inproceedings{Self-Consistency,
  title     = {Self-Consistency Improves Chain of Thought Reasoning in Language Models},
  author    = {Xuezhi Wang and Jason Wei and Dale Schuurmans and Quoc V Le and Ed H. Chi and Sharan Narang and Aakanksha Chowdhery and Denny Zhou},
  booktitle = {International Conference on Learning Representations (ICLR)},
  year      = {2023},
  url       = {https://openreview.net/forum?id=1PL1NIMMrw}
}


@inproceedings{ToT,
  title     = {Tree of Thoughts: Deliberate Problem Solving with Large Language Models},
  author    = {Yao, Shunyu and Yu, Dian and Zhao, Jeffrey and Shafran, Izhak and Griffiths, Tom and Cao, Yuan and Narasimhan, Karthik},
  booktitle = {Advances in Neural Information Processing Systems (NeurIPS)},
  pages     = {11809--11822},
  volume    = {36},
  year      = {2023}
}

% Search: BS, MCTS
@inproceedings{xie2024self,
  title     = {Self-Evaluation Guided Beam Search for Reasoning},
  author    = {Xie, Yuxi and Kawaguchi, Kenji and Zhao, Yiran and Zhao, James Xu and Kan, Min-Yen and He, Junxian and Xie, Michael},
  booktitle = {Advances in Neural Information Processing Systems (NeurIPS)},
  pages     = {41618--41650},
  volume    = {36},
  year      = {2023}
}

@inproceedings{ARGS,
  title     = {{ARGS}: Alignment as Reward-Guided Search},
  author    = {Maxim Khanov and Jirayu Burapacheep and Yixuan Li},
  booktitle = {International Conference on Learning Representations (ICLR)},
  year      = {2024},
  url       = {https://openreview.net/forum?id=shgx0eqdw6}
}

@inproceedings{RISE,
  title     = {Recursive Introspection: Teaching Language Model Agents How to Self-Improve},
  author    = {Yuxiao Qu and Tianjun Zhang and Naman Garg and Aviral Kumar},
  booktitle = {Advances in Neural Information Processing Systems (NeurIPS)},
  year      = {2024},
  url       = {https://openreview.net/forum?id=DRC9pZwBwR}
}

@inproceedings{chen2024are,
  title     = {Are More {LLM} Calls All You Need? Towards the Scaling Properties of Compound {AI} Systems},
  author    = {Lingjiao Chen and Jared Quincy Davis and Boris Hanin and Peter Bailis and Ion Stoica and Matei Zaharia and James Zou},
  booktitle = {Advances in Neural Information Processing Systems (NeurIPS)},
  year      = {2024}
}

@article{MindStar,
  title   = {{MindStar}: Enhancing math reasoning in pre-trained llms at inference time},
  author  = {Kang, Jikun and Li, Xin Zhe and Chen, Xi and Kazemi, Amirreza and Sun, Qianyi and Chen, Boxing and Li, Dong and He, Xu and He, Quan and Wen, Feng and others},
  journal = {arXiv preprint arXiv:2405.16265},
  year    = {2024}
}

@article{brown2024large,
  title   = {Large Language Monkeys: Scaling Inference Compute with Repeated Sampling},
  author  = {Brown, Bradley and Juravsky, Jordan and Ehrlich, Ryan and Clark, Ronald and Le, Quoc V and R{\'e}, Christopher and Mirhoseini, Azalia},
  journal = {arXiv preprint arXiv:2407.21787},
  year    = {2024}
}

@article{wu2024inference,
  title   = {Inference Scaling Laws: An Empirical Analysis of Compute-Optimal Inference for Problem-Solving with Language Models},
  author  = {Wu, Yangzhen and Sun, Zhiqing and Li, Shanda and Welleck, Sean and Yang, Yiming},
  journal = {arXiv preprint arXiv:2408.00724},
  year    = {2024}
}

@article{snell2024scaling,
  title   = {Scaling llm test-time compute optimally can be more effective than scaling model parameters},
  author  = {Snell, Charlie and Lee, Jaehoon and Xu, Kelvin and Kumar, Aviral},
  journal = {arXiv preprint arXiv:2408.03314},
  year    = {2024}
}

@article{manvi2024adaptive,
  title   = {Adaptive Inference-Time Compute: LLMs Can Predict if They Can Do Better, Even Mid-Generation},
  author  = {Manvi, Rohin and Singh, Anikait and Ermon, Stefano},
  journal = {arXiv preprint arXiv:2410.02725},
  year    = {2024}
}

@misc{huggingface2024scaling,
  title  = {Scaling test-time compute with open models},
  author = {Edward Beeching and Lewis Tunstall and Sasha Rush},
  year   = {2024},
  url    = {https://huggingface.co/spaces/HuggingFaceH4/blogpost-scaling-test-time-compute}
}

@article{guan2024search,
  title   = {Search, Verify and Feedback: Towards Next Generation Post-training Paradigm of Foundation Models via Verifier Engineering},
  author  = {Guan, Xinyan and Liu, Yanjiang and Lu, Xinyu and Cao, Boxi and He, Ben and Han, Xianpei and Sun, Le and Lou, Jie and Yu, Bowen and Lu, Yaojie and others},
  journal = {arXiv preprint arXiv:2411.11504},
  year    = {2024}
}

@article{jiang2024technical,
  title   = {Technical Report: Enhancing LLM Reasoning with Reward-guided Tree Search},
  author  = {Jiang, Jinhao and Chen, Zhipeng and Min, Yingqian and Chen, Jie and Cheng, Xiaoxue and Wang, Jiapeng and Tang, Yiru and Sun, Haoxiang and Deng, Jia and Zhao, Wayne Xin and others},
  journal = {arXiv preprint arXiv:2411.11694},
  year    = {2024}
}

@article{zeng2024scaling,
  title   = {Scaling of Search and Learning: A Roadmap to Reproduce o1 from Reinforcement Learning Perspective},
  author  = {Zeng, Zhiyuan and Cheng, Qinyuan and Yin, Zhangyue and Wang, Bo and Li, Shimin and Zhou, Yunhua and Guo, Qipeng and Huang, Xuanjing and Qiu, Xipeng},
  journal = {arXiv preprint arXiv:2412.14135},
  year    = {2024}
}

@article{xiyao2024scaling,
  title   = {Scaling inference-time search with vision value model for improved visual comprehension},
  author  = {Xiyao Wang and Zhengyuan Yang and Linjie Li and Hongjin Lu and Yuancheng Xu and Chung-Ching Lin and Kevin Lin and Furong Huang and Lijuan Wang},
  journal = {arXiv preprint arXiv:2412.03704},
  year    = {2024}
}

% Reasoning & Search
@inproceedings{wan2024alphazero,
  title     = {{A}lpha{Z}ero-Like Tree-Search can Guide Large Language Model Decoding and Training},
  author    = {Wan, Ziyu and Feng, Xidong and Wen, Muning and Mcaleer, Stephen Marcus and Wen, Ying and Zhang, Weinan and Wang, Jun},
  booktitle = {International Conference on Machine Learning (ICML)},
  pages     = {49890--49920},
  volume    = {235},
  year      = {2024}
}

@inproceedings{AlphaMath,
  title     = {AlphaMath Almost Zero: Process Supervision without Process},
  author    = {Guoxin Chen and Minpeng Liao and Chengxi Li and Kai Fan},
  booktitle = {Advances in Neural Information Processing Systems (NeurIPS)},
  year      = {2024},
  url       = {https://openreview.net/forum?id=VaXnxQ3UKo}
}

@article{o1-Journey1,
  title   = {O1 Replication Journey: A Strategic Progress Report--Part 1},
  author  = {Qin, Yiwei and Li, Xuefeng and Zou, Haoyang and Liu, Yixiu and Xia, Shijie and Huang, Zhen and Ye, Yixin and Yuan, Weizhe and Liu, Hector and Li, Yuanzhi and others},
  journal = {arXiv preprint arXiv:2410.18982},
  year    = {2024}
}

@article{o1-Journey2,
  title   = {O1 Replication Journey--Part 2: Surpassing O1-preview through Simple Distillation, Big Progress or Bitter Lesson?},
  author  = {Huang, Zhen and Zou, Haoyang and Li, Xuefeng and Liu, Yixiu and Zheng, Yuxiang and Chern, Ethan and Xia, Shijie and Qin, Yiwei and Yuan, Weizhe and Liu, Pengfei},
  journal = {arXiv preprint arXiv:2411.16489},
  year    = {2024}
}

% Prompt
@inproceedings{CoT,
  title     = {Chain-of-thought prompting elicits reasoning in large language models},
  author    = {Wei, Jason and Wang, Xuezhi and Schuurmans, Dale and Bosma, Maarten and Xia, Fei and Chi, Ed and Le, Quoc V and Zhou, Denny and others},
  booktitle = {Advances in neural information processing systems (NeurIPS)},
  volume    = {35},
  pages     = {24824--24837},
  year      = {2022}
}

@article{CoMAT,
  title   = {{CoMAT}: Chain of Mathematically Annotated Thought Improves Mathematical Reasoning},
  author  = {Leang, Joshua Ong Jun and Gema, Aryo Pradipta and Cohen, Shay B},
  journal = {arXiv preprint arXiv:2410.10336},
  year    = {2024}
}

@inproceedings{PAL,
  title     = {{PAL}: Program-aided Language Models},
  author    = {Gao, Luyu and Madaan, Aman and Zhou, Shuyan and Alon, Uri and Liu, Pengfei and Yang, Yiming and Callan, Jamie and Neubig, Graham},
  booktitle = {International Conference on Machine Learning (ICML)},
  pages     = {10764--10799},
  volume    = {202},
  year      = {2023}
}

@article{PoT,
  title   = {Program of Thoughts Prompting: Disentangling Computation from Reasoning for Numerical Reasoning Tasks},
  author  = {Wenhu Chen and Xueguang Ma and Xinyi Wang and William W. Cohen},
  journal = {Transactions on Machine Learning Research (TMLR)},
  issn    = {2835-8856},
  year    = {2023},
  url     = {https://openreview.net/forum?id=YfZ4ZPt8zd}
}

@inproceedings{Self-Refine,
  title     = {Self-Refine: Iterative Refinement with Self-Feedback},
  author    = {Madaan, Aman and Tandon, Niket and Gupta, Prakhar and Hallinan, Skyler and Gao, Luyu and Wiegreffe, Sarah and Alon, Uri and Dziri, Nouha and Prabhumoye, Shrimai and Yang, Yiming and Gupta, Shashank and Majumder, Bodhisattwa Prasad and Hermann, Katherine and Welleck, Sean and Yazdanbakhsh, Amir and Clark, Peter},
  booktitle = {Advances in Neural Information Processing Systems (NeurIPS)},
  pages     = {46534--46594},
  volume    = {36},
  year      = {2023}
}

@inproceedings{Self-Verification,
  title     = {Large language models are better reasoners with self-verification},
  author    = {Weng, Yixuan and Zhu, Minjun and Xia, Fei and Li, Bin and He, Shizhu and Liu, Shengping and Sun, Bin and Liu, Kang and Zhao, Jun},
  booktitle = {Findings of the Association for Computational Linguistics: EMNLP 2023},
  year      = {2023},
  pages     = {2550--2575}
}

% Math LLM
@article{Wizardmath,
  title   = {Wizardmath: Empowering mathematical reasoning for large language models via reinforced evol-instruct},
  author  = {Luo, Haipeng and Sun, Qingfeng and Xu, Can and Zhao, Pu and Lou, Jianguang and Tao, Chongyang and Geng, Xiubo and Lin, Qingwei and Chen, Shifeng and Zhang, Dongmei},
  journal = {arXiv preprint arXiv:2308.09583},
  year    = {2023}
}

@inproceedings{Llemma,
  title     = {Llemma: An Open Language Model for Mathematics},
  author    = {Zhangir Azerbayev and Hailey Schoelkopf and Keiran Paster and Marco Dos Santos and Stephen Marcus McAleer and Albert Q. Jiang and Jia Deng and Stella Biderman and Sean Welleck},
  booktitle = {International Conference on Learning Representations (ICLR)},
  year      = {2024},
  url       = {https://openreview.net/forum?id=4WnqRR915j}
}

@inproceedings{MetaMath,
  title     = {{MetaMath}: Bootstrap Your Own Mathematical Questions for Large Language Models},
  author    = {Longhui Yu and Weisen Jiang and Han Shi and Jincheng YU and Zhengying Liu and Yu Zhang and James Kwok and Zhenguo Li and Adrian Weller and Weiyang Liu},
  booktitle = {International Conference on Learning Representations (ICLR)},
  year      = {2024},
  url       = {https://openreview.net/forum?id=N8N0hgNDRt}
}

@inproceedings{ToRA,
  title     = {To{RA}: A Tool-Integrated Reasoning Agent for Mathematical Problem Solving},
  author    = {Zhibin Gou and Zhihong Shao and Yeyun Gong and yelong shen and Yujiu Yang and Minlie Huang and Nan Duan and Weizhu Chen},
  booktitle = {International Conference on Learning Representations (ICLR)},
  year      = {2024},
  url       = {https://openreview.net/forum?id=Ep0TtjVoap}
}

@inproceedings{MathScale,
  title     = {{M}ath{S}cale: Scaling Instruction Tuning for Mathematical Reasoning},
  author    = {Tang, Zhengyang and Zhang, Xingxing and Wang, Benyou and Wei, Furu},
  booktitle = {International Conference on Machine Learning (ICML)},
  pages     = {47885--47900},
  volume    = {235},
  year      = {2024}
}

@article{DeepSeekMath,
  title   = {{DeepSeekMath}: Pushing the Limits of Mathematical Reasoning in Open Language Models},
  author  = {Shao, Zhihong and Wang, Peiyi and Zhu, Qihao and Xu, Runxin and Song, Junxiao and Bi, Xiao and Zhang, Haowei and Zhang, Mingchuan and Li, YK and Wu, Y and others},
  journal = {arXiv preprint arXiv:2402.03300},
  year    = {2024}
}

@inproceedings{DART-Math,
  title     = {{DART}-Math: Difficulty-Aware Rejection Tuning for Mathematical Problem-Solving},
  author    = {Yuxuan Tong and Xiwen Zhang and Rui Wang and Ruidong Wu and Junxian He},
  booktitle = {Advances in Neural Information Processing Systems (NeurIPS)},
  year      = {2024},
  url       = {https://openreview.net/forum?id=zLU21oQjD5}
}

@article{Skywork-Math,
  title   = {{Skywork-Math}: Data Scaling Laws for Mathematical Reasoning in Large Language Models--The Story Goes On},
  author  = {Zeng, Liang and Zhong, Liangjun and Zhao, Liang and Wei, Tianwen and Yang, Liu and He, Jujie and Cheng, Cheng and Hu, Rui and Liu, Yang and Yan, Shuicheng and others},
  journal = {arXiv preprint arXiv:2407.08348},
  year    = {2024}
}

% Training
@inproceedings{STaR,
  title     = {{STaR}: Bootstrapping Reasoning With Reasoning},
  author    = {Zelikman, Eric and Wu, Yuhuai and Mu, Jesse and Goodman, Noah},
  booktitle = {Advances in Neural Information Processing Systems (NeurIPS)},
  pages     = {15476--15488},
  volume    = {35},
  year      = {2022}
}

@article{ReST,
  title   = {Reinforced Self-Training (ReST) for Language Modeling},
  author  = {Gulcehre, Caglar and Paine, Tom Le and Srinivasan, Srivatsan and Konyushkova, Ksenia and Weerts, Lotte and Sharma, Abhishek and Siddhant, Aditya and Ahern, Alex and Wang, Miaosen and Gu, Chenjie and others},
  journal = {arXiv preprint arXiv:2308.08998},
  year    = {2023}
}

@inproceedings{ReFT,
  title     = {ReFT: Reasoning with Reinforced Fine-Tuning},
  author    = {Trung, Luong and Zhang, Xinbo and Jie, Zhanming and Sun, Peng and Jin, Xiaoran and Li, Hang},
  booktitle = {Proceedings of the 62nd Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers)},
  pages     = {7601--7614},
  year      = {2024}
}

@article{V-STaR,
  title   = {V-STaR: Training Verifiers for Self-Taught Reasoners},
  author  = {Hosseini, Arian and Yuan, Xingdi and Malkin, Nikolay and Courville, Aaron and Sordoni, Alessandro and Agarwal, Rishabh},
  journal = {arXiv preprint arXiv:2402.06457},
  year    = {2024}
}

@inproceedings{Quiet-STaR,
  title     = {Quiet-{ST}aR: Language Models Can Teach Themselves to Think Before Speaking},
  author    = {Eric Zelikman and Georges Raif Harik and Yijia Shao and Varuna Jayasiri and Nick Haber and Noah Goodman},
  booktitle = {Conference on Language Modeling (COLM)},
  year      = {2024},
  url       = {https://openreview.net/forum?id=oRXPiSOGH9}
}

@inproceedings{ReST-MCTS*,
  title     = {Re{ST}-{MCTS}*: {LLM} Self-Training via Process Reward Guided Tree Search},
  author    = {Dan Zhang and Sining Zhoubian and Ziniu Hu and Yisong Yue and Yuxiao Dong and Jie Tang},
  booktitle = {Advances in Neural Information Processing Systems (NeurIPS)},
  year      = {2024},
  url       = {https://openreview.net/forum?id=8rcFOqEud5}
}

@article{setlur2024rl,
  title   = {RL on Incorrect Synthetic Data Scales the Efficiency of LLM Math Reasoning by Eight-Fold},
  author  = {Setlur, Amrith and Garg, Saurabh and Geng, Xinyang and Garg, Naman and Smith, Virginia and Kumar, Aviral},
  journal = {arXiv preprint arXiv:2406.14532},
  year    = {2024}
}

@article{kumar2024training,
  title   = {Training language models to self-correct via reinforcement learning},
  author  = {Kumar, Aviral and Zhuang, Vincent and Agarwal, Rishabh and Su, Yi and Co-Reyes, John D and Singh, Avi and Baumli, Kate and Iqbal, Shariq and Bishop, Colton and Roelofs, Rebecca and others},
  journal = {arXiv preprint arXiv:2409.12917},
  year    = {2024}
}

@article{PRIME,
  title   = {Process Reinforcement through Implicit Rewards},
  author  = {Ganqu Cui and Lifan Yuan and Zefan Wang and Hanbin Wang and Wendi Li and Bingxiang He and Yuchen Fan and Tianyu Yu and Qixin Xu and Weize Chen and Jiarui Yuan and Huayu Chen and Kaiyan Zhang and Xingtai Lv and Shuo Wang and Yuan Yao and Xu Han and Hao Peng and Yu Cheng and Zhiyuan Liu and Maosong Sun and Bowen Zhou and Ning Ding},
  journal = {arXiv preprint arXiv:2502.01456},
  year    = {2025}
}

% o1
@misc{wang2024tutorial,
  author = {Jun Wang},
  title  = {A Tutorial on LLM Reasoning: Relevant Methods Behind ChatGPT o1},
  year   = {2024},
  url    = {https://github.com/openreasoner/openr/blob/main/reports/tutorial.pdf},
  note   = {Available on GitHub}
}

@article{OpenR,
  title   = {OpenR: An Open Source Framework for Advanced Reasoning with Large Language Models},
  author  = {Wang, Jun and Fang, Meng and Wan, Ziyu and Wen, Muning and Zhu, Jiachen and Liu, Anjie and Gong, Ziqin and Song, Yan and Chen, Lei and Ni, Lionel M and others},
  journal = {arXiv preprint arXiv:2410.09671},
  year    = {2024}
}

@article{wu2024comparative,
  title   = {A Comparative Study on Reasoning Patterns of OpenAI's o1 Model},
  author  = {Wu, Siwei and Peng, Zhongyuan and Du, Xinrun and Zheng, Tuney and Liu, Minghao and Wu, Jialong and Ma, Jiachen and Li, Yizhi and Yang, Jian and Zhou, Wangchunshu and others},
  journal = {arXiv preprint arXiv:2410.13639},
  year    = {2024}
}

@article{Marco-o1,
  title   = {Marco-o1: Towards Open Reasoning Models for Open-Ended Solutions},
  author  = {Zhao, Yu and Yin, Huifeng and Zeng, Bo and Wang, Hao and Shi, Tianqi and Lyu, Chenyang and Wang, Longyue and Luo, Weihua and Zhang, Kaifu},
  journal = {arXiv preprint arXiv:2411.14405},
  year    = {2024}
}

@misc{k0-math,
  title  = {k0-math},
  author = {{Kimi}},
  url    = {https://kimi.moonshot.cn/},
  month  = {November},
  year   = {2024}
}

@article{Kimi-k1.5,
  title   = {Kimi k1.5: Scaling Reinforcement Learning with LLMs},
  author  = {{Kimi Team} and Du, Angang and Gao, Bofei and Xing, Bowei and Jiang, Changjiu and Chen, Cheng and Li, Cheng and Xiao, Chenjun and Du, Chenzhuang and Liao, Chonghua and others},
  journal = {arXiv preprint arXiv:2501.12599},
  year    = {2025}
}

@misc{DeepSeek-R1-Lite-Preview,
  title  = {DeepSeek-R1},
  author = {{DeepSeek}},
  url    = {https://chat.deepseek.com/},
  month  = {November},
  year   = {2024}
}

@article{DeepSeek-R1,
  title   = {DeepSeek-R1: Incentivizing Reasoning Capability in LLMs via Reinforcement Learning},
  author  = {{DeepSeek-AI} and Daya Guo and Dejian Yang and Haowei Zhang and Junxiao Song and Ruoyu Zhang and Runxin Xu and Qihao Zhu and Shirong Ma and Peiyi Wang and Xiao Bi and Xiaokang Zhang and Xingkai Yu and Yu Wu and Z. F. Wu and Zhibin Gou and Zhihong Shao and Zhuoshu Li and Ziyi Gao and Aixin Liu and Bing Xue and Bingxuan Wang and Bochao Wu and Bei Feng and Chengda Lu and Chenggang Zhao and Chengqi Deng and Chenyu Zhang and Chong Ruan and Damai Dai and Deli Chen and Dongjie Ji and Erhang Li and Fangyun Lin and Fucong Dai and Fuli Luo and Guangbo Hao and Guanting Chen and Guowei Li and H. Zhang and Han Bao and Hanwei Xu and Haocheng Wang and Honghui Ding and Huajian Xin and Huazuo Gao and Hui Qu and Hui Li and Jianzhong Guo and Jiashi Li and Jiawei Wang and Jingchang Chen and Jingyang Yuan and Junjie Qiu and Junlong Li and J. L. Cai and Jiaqi Ni and Jian Liang and Jin Chen and Kai Dong and Kai Hu and Kaige Gao and Kang Guan and Kexin Huang and Kuai Yu and Lean Wang and Lecong Zhang and Liang Zhao and Litong Wang and Liyue Zhang and Lei Xu and Leyi Xia and Mingchuan Zhang and Minghua Zhang and Minghui Tang and Meng Li and Miaojun Wang and Mingming Li and Ning Tian and Panpan Huang and Peng Zhang and Qiancheng Wang and Qinyu Chen and Qiushi Du and Ruiqi Ge and Ruisong Zhang and Ruizhe Pan and Runji Wang and R. J. Chen and R. L. Jin and Ruyi Chen and Shanghao Lu and Shangyan Zhou and Shanhuang Chen and Shengfeng Ye and Shiyu Wang and Shuiping Yu and Shunfeng Zhou and Shuting Pan and S. S. Li and Shuang Zhou and Shaoqing Wu and Shengfeng Ye and Tao Yun and Tian Pei and Tianyu Sun and T. Wang and Wangding Zeng and Wanjia Zhao and Wen Liu and Wenfeng Liang and Wenjun Gao and Wenqin Yu and Wentao Zhang and W. L. Xiao and Wei An and Xiaodong Liu and Xiaohan Wang and Xiaokang Chen and Xiaotao Nie and Xin Cheng and Xin Liu and Xin Xie and Xingchao Liu and Xinyu Yang and Xinyuan Li and Xuecheng Su and Xuheng Lin and X. Q. Li and Xiangyue Jin and Xiaojin Shen and Xiaosha Chen and Xiaowen Sun and Xiaoxiang Wang and Xinnan Song and Xinyi Zhou and Xianzu Wang and Xinxia Shan and Y. K. Li and Y. Q. Wang and Y. X. Wei and Yang Zhang and Yanhong Xu and Yao Li and Yao Zhao and Yaofeng Sun and Yaohui Wang and Yi Yu and Yichao Zhang and Yifan Shi and Yiliang Xiong and Ying He and Yishi Piao and Yisong Wang and Yixuan Tan and Yiyang Ma and Yiyuan Liu and Yongqiang Guo and Yuan Ou and Yuduan Wang and Yue Gong and Yuheng Zou and Yujia He and Yunfan Xiong and Yuxiang Luo and Yuxiang You and Yuxuan Liu and Yuyang Zhou and Y. X. Zhu and Yanhong Xu and Yanping Huang and Yaohui Li and Yi Zheng and Yuchen Zhu and Yunxian Ma and Ying Tang and Yukun Zha and Yuting Yan and Z. Z. Ren and Zehui Ren and Zhangli Sha and Zhe Fu and Zhean Xu and Zhenda Xie and Zhengyan Zhang and Zhewen Hao and Zhicheng Ma and Zhigang Yan and Zhiyu Wu and Zihui Gu and Zijia Zhu and Zijun Liu and Zilin Li and Ziwei Xie and Ziyang Song and Zizheng Pan and Zhen Huang and Zhipeng Xu and Zhongyu Zhang and Zhen Zhang},
  journal = {arXiv preprint arXiv:2501.12948},
  year    = {2025}
}

@misc{QwQ,
  title  = {QwQ: Reflect Deeply on the Boundaries of the Unknown},
  author = {{Qwen Team}},
  url    = {https://qwenlm.github.io/blog/qwq-32b-preview/},
  month  = {November},
  year   = {2024}
}

@misc{Skywork-o1,
  title  = {Skywork-O1},
  author = {{Skywork}},
  url    = {https://www.tiangong.cn/},
  month  = {November},
  year   = {2024}
}

@article{min2024imitate,
  title   = {Imitate, explore, and self-improve: A reproduction report on slow-thinking reasoning systems},
  author  = {Min, Yingqian and Chen, Zhipeng and Jiang, Jinhao and Chen, Jie and Deng, Jia and Hu, Yiwen and Tang, Yiru and Wang, Jiapeng and Cheng, Xiaoxue and Song, Huatong and others},
  journal = {arXiv preprint arXiv:2412.09413},
  year    = {2024}
}

@misc{sky-t1,
  author       = {{NovaSky Team}},
  title        = {Sky-T1: Fully open-source reasoning model with o1-preview performance in \$450 budget},
  howpublished = {https://novasky-ai.github.io/posts/sky-t1},
  note         = {Accessed: 2025-01-09},
  year         = {2025}
}

% MLLM o1
@article{Virgo,
  title   = {Virgo: A Preliminary Exploration on Reproducing o1-like MLLM},
  author  = {Du, Yifan and Liu, Zikang and Li, Yifan and Zhao, Wayne Xin and Huo, Yuqi and Wang, Bingning and Chen, Weipeng and Liu, Zheng and Wang, Zhongyuan and Wen, Ji-Rong},
  journal = {arXiv preprint arXiv:2501.01904},
  year    = {2025}
}

% PRM
@article{uesato2022solving,
  title   = {Solving math word problems with process-and outcome-based feedback},
  author  = {Uesato, Jonathan and Kushman, Nate and Kumar, Ramana and Song, Francis and Siegel, Noah and Wang, Lisa and Creswell, Antonia and Irving, Geoffrey and Higgins, Irina},
  journal = {arXiv preprint arXiv:2211.14275},
  year    = {2022}
}

@inproceedings{PRM800K,
  title     = {Let's Verify Step by Step},
  author    = {Hunter Lightman and Vineet Kosaraju and Yuri Burda and Harrison Edwards and Bowen Baker and Teddy Lee and Jan Leike and John Schulman and Ilya Sutskever and Karl Cobbe},
  booktitle = {International Conference on Learning Representations (ICLR)},
  year      = {2024},
  url       = {https://openreview.net/forum?id=v8L0pN6EOi}
}

@article{ma2023let,
  title   = {Let's reward step by step: Step-Level reward model as the Navigators for Reasoning},
  author  = {Ma, Qianli and Zhou, Haotian and Liu, Tingkai and Yuan, Jianbo and Liu, Pengfei and You, Yang and Yang, Hongxia},
  journal = {arXiv preprint arXiv:2310.10080},
  year    = {2023}
}

@inproceedings{Math-Shepherd,
  title     = {Math-Shepherd: Verify and Reinforce LLMs Step-by-step without Human Annotations},
  author    = {Wang, Peiyi and Li, Lei and Shao, Zhihong and Xu, Runxin and Dai, Damai and Li, Yifei and Chen, Deli and Wu, Yu and Sui, Zhifang},
  booktitle = {Proceedings of the 62nd Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers)},
  pages     = {9426--9439},
  year      = {2024}
}

@inproceedings{AutoPSV,
  title     = {Autopsv: Automated process-supervised verifier},
  author    = {Lu, Jianqiao and Dou, Zhiyang and Hongru, WANG and Cao, Zeyu and Dai, Jianbo and Feng, Yunlong and Guo, Zhijiang},
  booktitle = {Advances in Neural Information Processing Systems (NeurIPS)},
  year      = {2024}
}

@article{OmegaPRM,
  title   = {Improve Mathematical Reasoning in Language Models by Automated Process Supervision},
  author  = {Luo, Liangchen and Liu, Yinxiao and Liu, Rosanne and Phatale, Samrat and Lara, Harsh and Li, Yunxuan and Shu, Lei and Zhu, Yun and Meng, Lei and Sun, Jiao and others},
  journal = {arXiv preprint arXiv:2406.06592},
  year    = {2024}
}

@article{PAV,
  title   = {Rewarding Progress: Scaling Automated Process Verifiers for LLM Reasoning},
  author  = {Setlur, Amrith and Nagpal, Chirag and Fisch, Adam and Geng, Xinyang and Eisenstein, Jacob and Agarwal, Rishabh and Agarwal, Alekh and Berant, Jonathan and Kumar, Aviral},
  journal = {arXiv preprint arXiv:2410.08146},
  year    = {2024}
}

@misc{RLHFlow,
  author       = {Wei Xiong and Hanning Zhang and Nan Jiang and Tong Zhang},
  title        = {An Implementation of Generative PRM},
  year         = {2024},
  publisher    = {GitHub},
  journal      = {GitHub repository},
  howpublished = {\url{https://github.com/RLHFlow/RLHF-Reward-Modeling}}
}

@misc{Skywork-o1-open,
  title        = {Skywork-o1 Open Series},
  author       = {{Skywork o1 Team}},
  year         = {2024},
  month        = {November},
  howpublished = {\url{https://huggingface.co/Skywork}},
  url          = {https://huggingface.co/Skywork}
}

@article{PQM,
  title   = {Process Reward Model with Q-Value Rankings},
  author  = {Li, Wendi and Li, Yixuan},
  journal = {arXiv preprint arXiv:2410.11287},
  year    = {2024}
}

@article{Implicit-PRM,
  title   = {Free Process Rewards without Process Labels},
  author  = {Yuan, Lifan and Li, Wendi and Chen, Huayu and Cui, Ganqu and Ding, Ning and Zhang, Kaiyan and Zhou, Bowen and Liu, Zhiyuan and Peng, Hao},
  journal = {arXiv preprint arXiv:2412.01981},
  year    = {2024}
}

@article{ER-PRM,
  title   = {Entropy-Regularized Process Reward Model},
  author  = {Zhang, Hanning and Wang, Pengcheng and Diao, Shizhe and Lin, Yong and Pan, Rui and Dong, Hanze and Zhang, Dylan and Molchanov, Pavlo and Zhang, Tong},
  journal = {arXiv preprint arXiv:2412.11006},
  year    = {2024}
}

@article{ProcessBench,
  title   = {ProcessBench: Identifying Process Errors in Mathematical Reasoning},
  author  = {Zheng, Chujie and Zhang, Zhenru and Zhang, Beichen and Lin, Runji and Lu, Keming and Yu, Bowen and Liu, Dayiheng and Zhou, Jingren and Lin, Junyang},
  journal = {arXiv preprint arXiv:2412.06559},
  year    = {2024}
}

@article{PRMBench,
  title   = {PRMBench: A Fine-grained and Challenging Benchmark for Process-Level Reward Models},
  author  = {Mingyang Song and Zhaochen Su and Xiaoye Qu and Jiawei Zhou and Yu Cheng},
  journal = {arXiv preprint arXiv:2501.03124},
  year    = {2025}
}

@article{PRMLessons,
  title   = {The Lessons of Developing Process Reward Models in Mathematical Reasoning},
  author  = {Zhenru Zhang and Chujie Zheng and Yangzhen Wu and Beichen Zhang and Runji Lin and Bowen Yu and Dayiheng Liu and Jingren Zhou and Junyang Lin},
  journal = {arXiv preprint arXiv:2501.07301},
  year    = {2025}
}

@article{rStar-Math,
  title   = {{rStar-Math}: Small LLMs Can Master Math Reasoning with Self-Evolved Deep Thinking},
  author  = {Guan, Xinyu and Zhang, Li Lyna and Liu, Yifei and Shang, Ning and Sun, Youran and Zhu, Yi and Yang, Fan and Yang, Mao},
  journal = {arXiv preprint arXiv:2501.04519},
  year    = {2025}
}

@misc{SimpleRL,
  title        = {7B Model and 8K Examples: Emerging Reasoning with Reinforcement Learning is Both Effective and Efficient},
  author       = {Weihao Zeng and Yuzhen Huang and Wei Liu and Keqing He and Qian Liu and Zejun Ma and Junxian He},
  howpublished = {\url{https://hkust-nlp.notion.site/simplerl-reason}},
  note         = {Notion Blog},
  year         = {2025}
}

@article{Satori,
  title   = {Satori: Reinforcement Learning with Chain-of-Action-Thought Enhances LLM Reasoning via Autoregressive Search},
  author  = {Shen, Maohao and Zeng, Guangtao and Qi, Zhenting and Hong, Zhang-Wei and Chen, Zhenfang and Lu, Wei and Wornell, Gregory and Das, Subhro and Cox, David and Gan, Chuang},
  journal = {arXiv preprint arXiv:2502.02508},
  year    = {2025}
}

@inproceedings{LLM-as-a-judge,
  title     = {Judging LLM-as-a-Judge with MT-Bench and Chatbot Arena},
  author    = {Zheng, Lianmin and Chiang, Wei-Lin and Sheng, Ying and Zhuang, Siyuan and Wu, Zhanghao and Zhuang, Yonghao and Lin, Zi and Li, Zhuohan and Li, Dacheng and Xing, Eric and others},
  booktitle = {Advances in Neural Information Processing Systems (NeurIPS)},
  volume    = {36},
  pages     = {46595--46623},
  year      = {2023}
}
