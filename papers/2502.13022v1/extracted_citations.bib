@article{Athey.2021,
 abstract = {In many areas, practitioners seek to use observational data to learn a treatment assignment policy that satisfies application-specific constraints, such as budget, fairness, simplicity, or other functional form constraints. For example, policies may be restricted to take the form of decision trees based on a limited set of easily observable individual characteristics. We propose a new approach to this problem motivated by the theory of semiparametrically efficient estimation. Our method can be used to optimize either binary treatments or infinitesimal nudges to continuous treatments, and can leverage observational data where causal effects are identified using a variety of strategies, including selection on observables and instrumental variables. Given a doubly robust estimator of the causal effect of assigning everyone to treatment, we develop an algorithm for choosing whom to treat, and establish strong guarantees for the asymptotic utilitarian regret of the resulting policy.},
 author = {Athey, Susan and Wager, Stefan},
 year = {2021},
 title = {Policy learning with observational data},
 keywords = {Computer Science - Learning;Mathematics - Statistics;Statistics - Machine Learning;Statistics - Theory},
 pages = {133--161},
 volume = {89},
 number = {1},
 journal = {Econometrica},
 file = {1702.02896:Attachments/1702.02896.pdf:application/pdf}
}

@inproceedings{Bellot.2024,
 author = {Bellot, Alexis and Chiappa, Silvia},
 title = {Towards estimating bounds on the effect of policies under unobserved confounding},
 booktitle = {NeurIPS},
 year = {2024},
 file = {17254{\_}Towards{\_}Estimating{\_}Bound:Attachments/17254{\_}Towards{\_}Estimating{\_}Bound.pdf:application/pdf}
}

@inproceedings{Bibaut.2019,
 abstract = {Proceedings of the International Conference on Machine Learning 2019},
 author = {Bibaut, Aurelien and Malenica, Ivana and Vlassis, Nikos and {van der Laan}, Mark},
 title = {More efficient off-policy evaluation through regularized targeted learning},
 keywords = {Off-Policy Evaluation;Reinforcement Learning;TMLE},
 booktitle = {ICML},
 year = {2019},
 file = {bibaut19a:Attachments/bibaut19a.pdf:application/pdf}
}

@article{Bonvini.2022,
 abstract = {We introduce several methods for assessing sensitivity to unmeasured confounding in marginal structural models; importantly we allow treatments to be discrete or continuous, static or time-varying. We consider three sensitivity models: a propensity-based model, an outcome-based model, and a subset confounding model, in which only a fraction of the population is subject to unmeasured confounding. In each case we develop efficient estimators and confidence intervals for bounds on the causal parameters.},
 author = {Bonvini, Matteo and Kennedy, Edward and Ventura, Valerie and Wasserman, Larry},
 year = {2022},
 title = {Sensitivity analysis for marginal structural models},
 url = {http://arxiv.org/pdf/2210.04681v2},
 keywords = {Mathematics - Statistics;Statistics - Methodology;Statistics - Theory},
 volume = {arXiv:2210.04681},
 journal = {arXiv preprint},
 file = {2210.04681:Attachments/2210.04681.pdf:application/pdf}
}

@article{Chernozhukov.2018,
 author = {Chernozhukov, Victor and Chetverikov, Denis and Demirer, Mert and Duflo, Esther and Hansen, Christian and Newey, Whitney and Robins, James M.},
 year = {2018},
 title = {Double/debiased machine learning for treatment and structural parameters},
 pages = {C1-C68},
 volume = {21},
 number = {1},
 issn = {1368-4221},
 journal = {The Econometrics Journal},
 doi = {10.1111/ectj.12097},
 file = {Double-debiased machine learning for treatment and structural parameters:Attachments/Double-debiased machine learning for treatment and structural parameters.pdf:application/pdf}
}

@article{Cornfield.1959,
 author = {Cornfield, James and Haenszel, William and Hammond, E. Cuyler and Lilienfeld, Abraham M. and Shimkin, Michael B. and Wynder, Ernst L.},
 year = {1959},
 title = {Smoking and lung cancer: Recent evidence and a discussion of some questions},
 pages = {173--203},
 volume = {22},
 number = {1},
 journal = {Journal of the National Cancer Institute},
 file = {dyp289:Attachments/dyp289.pdf:application/pdf}
}

@article{Dorn.2022,
 abstract = {Inverse propensity weighting (IPW) is a popular method for estimating treatment effects from observational data. However, its correctness relies on the untestable (and frequently implausible) assumption that all confounders have been measured. This paper introduces a robust sensitivity analysis for IPW that estimates the range of treatment effects compatible with a given amount of unobserved confounding. The estimated range converges to the narrowest possible interval (under the given assumptions) that must contain the true treatment effect. Our proposal is a refinement of the influential sensitivity analysis by Zhao, Small, and Bhattacharya (2019), which we show gives bounds that are too wide even asymptotically. This analysis is based on new partial identification results for Tan (2006)'s marginal sensitivity model.},
 author = {Dorn, Jacob and Guo, Kevin},
 year = {2022},
 title = {Sharp sensitivity analysis for inverse propensity weighting via quantile balancing},
 url = {http://arxiv.org/pdf/2102.04543v2},
 keywords = {Mathematics - Statistics;Statistics - Methodology;Statistics - Theory},
 journal = {Journal of the American Statistical Association},
 volume = {118},
 number = {544},
 pages = {2645--2657},
 file = {2102.04543:Attachments/2102.04543.pdf:application/pdf}
}

@article{Dorn.2024,
 abstract = {We consider the problem of constructing bounds on the average treatment effect (ATE) when unmeasured confounders exist but have bounded influence. Specifically, we assume that omitted confounders could not change the odds of treatment for any unit by more than a fixed factor. We derive the sharp partial identification bounds implied by this assumption by leveraging distributionally robust optimization, and we propose estimators of these bounds with several novel robustness properties. The first is double sharpness: our estimators consistently estimate the sharp ATE bounds when one of two nuisance parameters is misspecified and achieve semiparametric efficiency when all nuisance parameters are suitably consistent. The second is double validity: even when most nuisance parameters are misspecified, our estimators still provide valid but possibly conservative bounds for the ATE and our Wald confidence intervals remain valid even when our estimators are not asymptotically normal. As a result, our estimators provide a highly credible method for sensitivity analysis of causal inferences.},
 author = {Dorn, Jacob and Guo, Kevin and Kallus, Nathan},
 year = {2024},
 title = {Doubly-valid/ doubly-sharp sensitivity analysis for causal inference with unmeasured confounding},
 url = {http://arxiv.org/pdf/2112.11449v2},
 keywords = {Computer Science - Learning;Mathematics - Optimization and Control;Statistics - Machine Learning;Statistics - Methodology},
 journal = {Journal of the American Statistical Association},
 file = {2112.11449 (2):Attachments/2112.11449 (2).pdf:application/pdf}
}

@inproceedings{Dudik.2011,
 abstract = {We study decision making in environments where the reward is only partially observed, but can be modeled as a function of an action and an observed context. This setting, known as contextual bandits, encompasses a wide variety of applications including health-care policy and Internet advertising. A central task is evaluation of a new policy given historic data consisting of contexts, actions and received rewards. The key challenge is that the past data typically does not faithfully represent proportions of actions taken by a new policy. Previous approaches rely either on models of rewards or models of the past policy. The former are plagued by a large bias whereas the latter have a large variance.  In this work, we leverage the strength and overcome the weaknesses of the two approaches by applying the doubly robust technique to the problems of policy evaluation and optimization. We prove that this approach yields accurate value estimates when we have either a good (but not necessarily consistent) model of rewards or a good (but not necessarily consistent) model of past policy. Extensive empirical comparison demonstrates that the doubly robust approach uniformly improves over existing techniques, achieving both lower variance in value estimation and better policies. As such, we expect the doubly robust approach to become common practice.},
 author = {Dudik, Miroslav and Langford, John and Li, Lihong},
 title = {Doubly robust policy evaluation and learning},
 keywords = {Computer Science - Artificial Intelligence;Computer Science - Learning;Computer Science - Robotics;contextual bandit;multiclass classification;partial label;Statistics - Applications;Statistics - Machine Learning},
 booktitle = {ICML},
 year = {2011},
 file = {1103.4601v2:Attachments/1103.4601v2.pdf:application/pdf}
}

@inproceedings{Frauen.2023c,
 abstract = {Causal inference from observational data is crucial for many disciplines such as medicine and economics. However, sharp bounds for causal effects under relaxations of the unconfoundedness assumption (causal sensitivity analysis) are subject to ongoing research. So far, works with sharp bounds are restricted to fairly simple settings (e.g., a single binary treatment). In this paper, we propose a unified framework for causal sensitivity analysis under unobserved confounding in various settings. For this, we propose a flexible generalization of the marginal sensitivity model (MSM) and then derive sharp bounds for a large class of causal effects. This includes (conditional) average treatment effects, effects for mediation analysis and path analysis, and distributional effects. Furthermore, our sensitivity model is applicable to discrete, continuous, and time-varying treatments. It allows us to interpret the partial identification problem under unobserved confounding as a distribution shift in the latent confounders while evaluating the causal effect of interest. In the special case of a single binary treatment, our bounds for (conditional) average treatment effects coincide with recent optimality results for causal sensitivity analysis. Finally, we propose a scalable algorithm to estimate our sharp bounds from observational data.},
 author = {Frauen, Dennis and Melnychuk, Valentyn and Feuerriegel, Stefan},
 title = {Sharp bounds for generalized causal sensitivity analysis},
 keywords = {Computer Science - Artificial Intelligence;Computer Science - Learning},
 booktitle = {NeurIPS},
 year = {2023},
 file = {2305.16988:Attachments/2305.16988.pdf:application/pdf}
}

@inproceedings{Frauen.2024,
 abstract = {Algorithmic decision-making in practice must be fair for legal, ethical, and societal reasons. To achieve this, prior research has contributed various approaches that ensure fairness in machine learning predictions, while comparatively little effort has focused on fairness in decision-making, specifically off-policy learning. In this paper, we propose a novel framework for fair off-policy learning: we learn decision rules from observational data under different notions of fairness, where we explicitly assume that observational data were collected under a different potentially discriminatory behavioral policy. For this, we first formalize different fairness notions for off-policy learning. We then propose a neural network-based framework to learn optimal policies under different fairness notions. We further provide theoretical guarantees in the form of generalization bounds for the finite-sample version of our framework. We demonstrate the effectiveness of our framework through extensive numerical experiments using both simulated and real-world data. Altogether, our work enables algorithmic decision-making in a wide array of practical applications where fairness must be ensured.},
 author = {Frauen, Dennis and Melnychuk, Valentyn and Feuerriegel, Stefan},
 title = {Fair off-policy learning from observational data},
 url = {http://arxiv.org/pdf/2303.08516v2},
 keywords = {Computer Science - Computers and Society;Computer Science - Learning},
 booktitle = {ICML},
 year = {2024},
 file = {2303.08516v2:Attachments/2303.08516v2.pdf:application/pdf}
}

@inproceedings{Frauen.2024b,
 abstract = {Unobserved confounding is common in many applications, making causal inference from observational data challenging. As a remedy, causal sensitivity analysis is an important tool to draw causal conclusions under unobserved confounding with mathematical guarantees. In this paper, we propose NeuralCSA, a neural framework for generalized causal sensitivity analysis. Unlike previous work, our framework is compatible with (i) a large class of sensitivity models, including the marginal sensitivity model, f-sensitivity models, and Rosenbaum's sensitivity model; (ii) different treatment types (i.e., binary and continuous); and (iii) different causal queries, including (conditional) average treatment effects and simultaneous effects on multiple outcomes. The generality of $\backslash$frameworkname is achieved by learning a latent distribution shift that corresponds to a treatment intervention using two conditional normalizing flows. We provide theoretical guarantees that NeuralCSA is able to infer valid bounds on the causal query of interest and also demonstrate this empirically using both simulated and real-world data.},
 author = {Frauen, Dennis and Imrie, Fergus and Curth, Alicia and Melnychuk, Valentyn and Feuerriegel, Stefan and {van der Schaar}, Mihaela},
 title = {A neural framework for generalized causal sensitivity analysis},
 keywords = {Computer Science - Learning;Statistics - Machine Learning},
 booktitle = {ICLR},
 year = {2024},
 file = {2311.16026:Attachments/2311.16026.pdf:application/pdf}
}

@inproceedings{Guerdan.2024,
    author = {Guerdan, Luke and Coston, Amanda and Holstein, Kenneth and Wu, Zhiwei Steven},
    title = {Predictive Performance Comparison of Decision Policies Under Confounding},
    booktitle ={ICML},
    year = {2024}
}

@inproceedings{Huang.2024,
 abstract = {The Thirty-Eighth AAAI Conference on Artificial Intelligence (AAAI-24)},
 author = {Huang, Wen and Wu, Xintau},
 title = {Robustly improving bandit algorithms with confounded and selection biased offline data: {A} causal approach},
 keywords = {Machine Learning (ML): ML: Ethics {\&} Bias {\&} Fairness;Machine Learning (ML): ML: Online Learning {\&} Bandits;Reasoning under Uncertainty (RU): RU: Causality},
 booktitle = {AAAI},
 year = {2024},
 file = {30027-Article Text-34081-1-2-20240324:Attachments/30027-Article Text-34081-1-2-20240324.pdf:application/pdf}
}

@inproceedings{Jesson.2021,
 author = {Jesson, Andrew and Mindermann, S{\"o}ren and Gal, Yarin and Shalit, Uri},
 title = {Quantifying ignorance in individual-level causal-effect estimates under hidden confounding},
 booktitle = {ICML},
 year = {2021},
 file = {jesson21a:Attachments/jesson21a.pdf:application/pdf}
}

@article{Jin.2022,
 abstract = {This paper introduces the $f$-sensitivity model, a new sensitivity model that characterizes the violation of unconfoundedness in causal inference. It assumes the selection bias due to unmeasured confounding is bounded {\textquotedbl}on average{\textquotedbl}; compared with the widely used point-wise sensitivity models in the literature, it is able to capture the strength of unmeasured confounding by not only its magnitude but also the chance of encountering such a magnitude.  We propose a framework for sensitivity analysis under our new model based on a distributional robustness perspective. We first show that the bounds on counterfactual means under the f-sensitivity model are optimal solutions to a new class of distributionally robust optimization (DRO) programs, whose dual forms are essentially risk minimization problems. We then construct point estimators for these bounds by applying a novel debiasing technique to the output of the corresponding empirical risk minimization (ERM) problems. Our estimators are shown to converge to valid bounds on counterfactual means if any nuisance component can be estimated consistently, and to the exact bounds when the ERM step is additionally consistent. We further establish asymptotic normality and Wald-type inference for these estimators under slower-than-root-n convergence rates of the estimated nuisance components. Finally, the performance of our method is demonstrated with numerical experiments.},
 author = {Jin, Ying and Ren, Zhimei and Zhou, Zhengyuan},
 year = {2022},
 title = {Sensitivity analysis under the $f$-sensitivity models: A distributional  robustness perspective},
 url = {http://arxiv.org/pdf/2203.04373v2},
 keywords = {Statistics - Methodology},
 volume = {arXiv:2203.04373}    ,
 journal = {arXiv preprint},
 file = {2203.04373:Attachments/2203.04373.pdf:application/pdf}
}

@article{Jin.2023,
 abstract = {We propose a model-free framework for sensitivity analysis of individual treatment effects (ITEs), building upon ideas from conformal inference. For any unit, our procedure reports the \textgreek{G}-value, a number which quantifies the minimum strength of confounding needed to explain away the evidence for ITE. Our approach rests on the reliable predictive inference of counterfactuals and ITEs in situations where the training data are confounded. Under the marginal sensitivity model of [Z. Tan, J. Am. Stat. Assoc. 101, 1619-1637 (2006)], we characterize the shift between the distribution of the observations and that of the counterfactuals. We first develop a general method for predictive inference of test samples from a shifted distribution; we then leverage this to construct covariate-dependent prediction sets for counterfactuals. No matter the value of the shift, these prediction sets (resp. approximately) achieve marginal coverage if the propensity score is known exactly (resp. estimated). We describe a distinct procedure also attaining coverage, however, conditional on the training data. In the latter case, we prove a sharpness result showing that for certain classes of prediction problems, the prediction intervals cannot possibly be tightened. We verify the validity and performance of the methods via simulation studies and apply them to analyze real datasets.},
 author = {Jin, Ying and Ren, Zhimei and Cand{\`e}s, Emmanuel J.},
 year = {2023},
 title = {Sensitivity analysis of individual treatment effects: A robust conformal inference approach},
 volume = {120},
 number = {6},
 pages = {e2214889120},
 journal = {Proceedings of the National Academy of Sciences (PNAS)},
 file = {pnas.2214889120:Attachments/pnas.2214889120.pdf:application/pdf}
}

@inproceedings{Joshi.2024,
 author = {Joshi, Shalmali and Zhang, Junzhe and Bareinboim, Elias},
 title = {Towards safe policy learning under partial identifiability: {A} causal approach},
 booktitle = {AAAI},
 year = {2024},
 file = {r96:Attachments/r96.pdf:application/pdf}
}

@inproceedings{Kallus.2018,
 abstract = {We present a new approach to the problems of evaluating and learning personalized decision policies from observational data of past contexts, decisions, and outcomes. Only the outcome of the enacted decision is available and the historical policy is unknown. These problems arise in personalized medicine using electronic health records and in internet advertising. Existing approaches use inverse propensity weighting (or, doubly robust versions) to make historical outcome (or, residual) data look like it were generated by a new policy being evaluated or learned. But this relies on a plug-in approach that rejects data points with a decision that disagrees with the new policy, leading to high variance estimates and ineffective learning. We propose a new, balance-based approach that too makes the data look like the new policy but does so directly by finding weights that optimize for balance between the weighted data and the target policy in the given, finite sample, which is equivalent to minimizing worst-case or posterior conditional mean square error. Our policy learner proceeds as a two-level optimization problem over policies and weights. We demonstrate that this approach markedly outperforms existing ones both in evaluation and learning, which is unsurprising given the wider support of balance-based weights. We establish extensive theoretical consistency guarantees and regret bounds that support this empirical success.},
 author = {Kallus, Nathan},
 title = {Balanced policy evaluation and learning},
 booktitle = {NeurIPS},
 year = {2018},
 file = {Kallus 2018 - Balanced Policy Evaluation and Learning:Attachments/Kallus 2018 - Balanced Policy Evaluation and Learning.pdf:application/pdf}
}

@inproceedings{Kallus.2018c,
 author = {Kallus, Nathan and Zhou, Angela},
 title = {Confounding-robust policy improvement},
 booktitle = {NeurIPS},
 year = {2018},
 file = {neurips{\_}2018{\_}appendix:Attachments/neurips{\_}2018{\_}appendix.pdf:application/pdf;NeurIPS-2018-confounding-robust-policy-improvement-Paper:Attachments/NeurIPS-2018-confounding-robust-policy-improvement-Paper.pdf:application/pdf}
}

@inproceedings{Kallus.2018d,
 author = {Kallus, Nathan and Zhou, Angela},
 title = {Policy evaluation and optimization with continuous treatments},
 booktitle = {AISTATS},
 year = {2018},
 file = {kallus18a:Attachments/kallus18a.pdf:application/pdf}
}

@inproceedings{Kallus.2019,
 author = {Kallus, Nathan and Mao, Xiaojie and Zhou, Angela},
 title = {Interval estimation of individual-level causal effects under unobserved confounding},
 booktitle = {AISTATS},
 year = {2019},
 file = {kallus19a:Attachments/kallus19a.pdf:application/pdf}
}

@article{Kallus.2021b,
 author = {Kallus, Nathan},
 year = {2021},
 title = {More efficient policy learning via optimal retargeting},
 keywords = {Efficient policy learning;Individualized treatment regimes;Optimization;Overlap},
 pages = {646--658},
 volume = {116},
 number = {534},
 journal = {Journal of the American Statistical Association},
 doi = {10.1080/01621459.2020.1788948},
 file = {01621459.2020:Attachments/01621459.2020.pdf:application/pdf}
}

@article{Kallus.2021d,
 author = {Kallus, Nathan and Zhou, Angela},
 year = {2021},
 title = {Minimax-optimal policy learning under unobserved confounding},
 pages = {2870--2890},
 volume = {67},
 number = {5},
 issn = {0025-1909},
 journal = {Management Science},
 file = {kallus-zhou-2020-minimax-optimal-policy-learning-under-unobserved-confounding:Attachments/kallus-zhou-2020-minimax-optimal-policy-learning-under-unobserved-confounding.pdf:application/pdf}
}

@inproceedings{Kallus.2022,
 abstract = {Off-policy evaluation and learning (OPE/L) use offline observational data to make better decisions, which is crucial in applications where experimentation is necessarily limited. OPE/L is nonetheless sensitive to discrepancies between the data-generating environment and that where policies are deployed. Recent work proposed distributionally robust OPE/L (DROPE/L) to remedy this, but the proposal relies on inverse-propensity weighting, whose regret rates may deteriorate if propensities are estimated and whose variance is suboptimal even if not. For vanilla OPE/L, this is solved by doubly robust (DR) methods, but they do not naturally extend to the more complex DROPE/L, which involves a worst-case expectation. In this paper, we propose the first DR algorithms for DROPE/L with KL-divergence uncertainty sets. For evaluation, we propose Localized Doubly Robust DROPE (LDR$^2$OPE) and prove its semiparametric efficiency under weak product rates conditions. Notably, thanks to a localization technique, LDR$^2$OPE only requires fitting a small number of regressions, just like DR methods for vanilla OPE. For learning, we propose Continuum Doubly Robust DROPL (CDR$^2$OPL) and show that, under a product rate condition involving a continuum of regressions, it enjoys a fast regret rate of {\$}\mathcal{O}(N{\^{}}{-1/2}){\$} even when unknown propensities are nonparametrically estimated. We further extend our results to general $f$-divergence uncertainty sets. We illustrate the advantage of our algorithms in simulations.},
 author = {Kallus, Nathan and Mao, Xiaojie and Wang, Kaiwen and Zhou, Zhengyuan},
 title = {Doubly robust distributionally robust off-policy evaluation and learning},
 url = {http://arxiv.org/pdf/2202.09667v1},
 keywords = {Computer Science - Learning;Mathematics - Optimization and Control;Mathematics - Statistics;Statistics - Machine Learning;Statistics - Theory},
 booktitle = {ICML},
 year = {2022},
 file = {2202.09667:Attachments/2202.09667.pdf:application/pdf}
}

@article{Kennedy.2022,
 abstract = {In this review we cover the basics of efficient nonparametric parameter estimation (also called functional estimation), with a focus on parameters that arise in causal inference problems. We review both efficiency bounds (i.e., what is the best possible performance for estimating a given parameter?) and the analysis of particular estimators (i.e., what is this estimator's error, and does it attain the efficiency bound?) under weak assumptions. We emphasize minimax-style efficiency bounds, worked examples, and practical shortcuts for easing derivations. We gloss over most technical details, in the interest of highlighting important concepts and providing intuition for main ideas.},
 author = {Kennedy, Edward H.},
 year = {2022},
 title = {Semiparametric doubly robust targeted double machine learning: A review},
 url = {http://arxiv.org/pdf/2203.06469v1},
 keywords = {Statistics - Methodology},
 journal = {arXiv preprint},
 file = {2203.06469:Attachments/2203.06469.pdf:application/pdf}
}

@inproceedings{Namkoong.2020,
 author = {Namkoong, Hongseok and Keramati, Ramtin and Yadlowsky, Steve and Brunskill, Emma},
 title = {Off-policy Policy Evaluation For Sequential Decisions Under Unobserved Confounding},
 booktitle = {NeurIPS},
 year = {2020}
}

@inproceedings{Oprescu.2023,
 abstract = {Estimating heterogeneous treatment effects from observational data is a crucial task across many fields, helping policy and decision-makers take better actions. There has been recent progress on robust and efficient methods for estimating the conditional average treatment effect (CATE) function, but these methods often do not take into account the risk of hidden confounding, which could arbitrarily and unknowingly bias any causal estimate based on observational data. We propose a meta-learner called the B-Learner, which can efficiently learn sharp bounds on the CATE function under limits on the level of hidden confounding. We derive the B-Learner by adapting recent results for sharp and valid bounds of the average treatment effect (Dorn et al., 2021) into the framework given by Kallus {\&} Oprescu (2022) for robust and model-agnostic learning of distributional treatment effects. The B-Learner can use any function estimator such as random forests and deep neural networks, and we prove its estimates are valid, sharp, efficient, and have a quasi-oracle property with respect to the constituent estimators under more general conditions than existing methods. Semi-synthetic experimental comparisons validate the theoretical findings, and we use real-world data demonstrate how the method might be used in practice.},
 author = {Oprescu, Miruna and Dorn, Jacob and Ghoummaid, Marah and Jesson, Andrew and Kallus, Nathan and Shalit, Uri},
 title = {B-learner: Quasi-oracle bounds on heterogeneous causal effects under hidden confounding},
 url = {http://arxiv.org/pdf/2304.10577v1},
 keywords = {causal inference;Computer Science - Learning;heterogeneous treatment effect;hidden confounding;SENSITIVITY ANALYSIS;Statistics - Machine Learning},
 booktitle = {ICML},
 year = {2023},
 file = {2304.10577:Attachments/2304.10577.pdf:application/pdf}
}

@article{Qian.2011,
 abstract = {Because many illnesses show heterogeneous response to treatment, there is increasing interest in individualizing treatment to patients [11]. An individualized treatment rule is a decision rule that recommends treatment according to patient characteristics. We consider the use of clinical trial data in the construction of an individualized treatment rule leading to highest mean response. This is a difficult computational problem because the objective function is the expectation of a weighted indicator function that is non-concave in the parameters. Furthermore there are frequently many pretreatment variables that may or may not be useful in constructing an optimal individualized treatment rule yet cost and interpretability considerations imply that only a few variables should be used by the individualized treatment rule. To address these challenges we consider estimation based on l(1) penalized least squares. This approach is justified via a finite sample upper bound on the difference between the mean response due to the estimated individualized treatment rule and the mean response due to the optimal individualized treatment rule.},
 author = {Qian, Min and Murphy, Susan A.},
 year = {2011},
 title = {Performance guarantees for individualized treatment rules},
 keywords = {62H99;62J07;62P10;Decision making;l1-penalized least squares;value},
 pages = {1180--1210},
 volume = {39},
 number = {2},
 issn = {0090-5364},
 journal = {Annals of Statistics},
 doi = {10.1214/10-AOS864},
 file = {10-AOS864:Attachments/10-AOS864.pdf:application/pdf}
}

@article{Robins.1994b,
 author = {Robins, James M. and Rotnitzky, Andrea and Zhao, Lue Ping},
 year = {1994},
 title = {Estimation of reression coefficients when some regressors are not always observed},
 pages = {846-688},
 volume = {89},
 number = {427},
 journal = {Journal of the American Statistical Association},
 file = {2290910:Attachments/2290910.pdf:application/pdf}
}

@article{Rosenbaum.1987,
 author = {Rosenbaum, Paul R.},
 year = {1987},
 title = {Sensitivity analysis for certain permutation inferences in matched observational studies},
 pages = {13--26},
 volume = {74},
 number = {1},
 issn = {0006-3444},
 journal = {Biometrika},
 file = {2336017:Attachments/2336017.pdf:application/pdf}
}

@inproceedings{Schweisthal.2023,
 author = {Schweisthal, Jonas and Frauen, Dennis and Melnychuk, Valentyn and Feuerriegel, Stefan},
 title = {Reliable off-policy learning for dosage combinations},
 booktitle = {NeurIPS},
 year = {2023},
 file = {NeurIPS-2023-reliable-off-policy-learning-for-dosage-combinations-Paper-Conference:Attachments/NeurIPS-2023-reliable-off-policy-learning-for-dosage-combinations-Paper-Conference.pdf:application/pdf}
}

@inproceedings{Swaminathan.2015,
 abstract = {We develop a learning principle and an efficient algorithm for batch learning from logged bandit feedback. This learning setting is ubiquitous in online systems (e.g., ad placement, web search, recommendation), where an algorithm makes a prediction (e.g., ad ranking) for a given input (e.g., query) and observes bandit feedback (e.g., user clicks on presented ads). We first address the counterfactual nature of the learning problem through propensity scoring. Next, we prove generalization error bounds that account for the variance of the propensity-weighted empirical risk estimator. These constructive bounds give rise to the Counterfactual Risk Minimization (CRM) principle. We show how CRM can be used to derive a new learning method -- called Policy Optimizer for Exponential Models (POEM) -- for learning stochastic linear rules for structured output prediction. We present a decomposition of the POEM objective that enables efficient stochastic gradient optimization. POEM is evaluated on several multi-label classification problems showing substantially improved robustness and generalization performance compared to the state-of-the-art.},
 author = {Swaminathan, Adith and Joachims, Thorsten},
 title = {Counterfactual risk minimization: Learning from logged bandit feedback},
 url = {http://arxiv.org/pdf/1502.02362v2},
 keywords = {bandit feedback;Bernstein bound;Computer Science - Learning;empirical risk minimization;importance sampling;majorization;propensity;Statistics - Machine Learning},
 booktitle = {ICML},
 year = {2015},
 file = {1502.02362v2:Attachments/1502.02362v2.pdf:application/pdf}
}

@article{Tan.2006,
 author = {Tan, Zhiqiang},
 year = {2006},
 title = {A distributional approach for causal inference using propensity scores},
 keywords = {causal inference;CONTROL VARIATE;NONPARAMETRIC LIKELIHOOD;OBSERVATIONAL STUDY;Propensity Score;SENSITIVITY ANALYSIS},
 pages = {1619--1637},
 volume = {101},
 number = {476},
 journal = {Journal of the American Statistical Association},
 file = {A Distributional Approach for Causal Inference Using Propensity Scores:Attachments/A Distributional Approach for Causal Inference Using Propensity Scores.pdf:application/pdf}
}

@inproceedings{Tschernutter.2022,
 abstract = {Personalized treatment decisions have become an integral part of modern medicine. Thereby, the aim is to make treatment decisions based on individual patient characteristics. Numerous methods have been developed for learning such policies from observational data that achieve the best outcome across a certain policy class. Yet these methods are rarely interpretable. However, interpretability is often a prerequisite for policy learning in clinical practice. In this paper, we propose an algorithm for interpretable off-policy learning via hyperbox search. In particular, our policies can be represented in disjunctive normal form (i.e., OR-of-ANDs) and are thus intelligible. We prove a universal approximation theorem that shows that our policy class is flexible enough to approximate any measurable function arbitrarily well. For optimization, we develop a tailored column generation procedure within a branch-and-bound framework. Using a simulation study, we demonstrate that our algorithm outperforms state-of-the-art methods from interpretable off-policy learning in terms of regret. Using real-word clinical data, we perform a user study with actual clinical experts, who rate our policies as highly interpretable.},
 author = {Tschernutter, Daniel and Hatt, Tobias and Feuerriegel, Stefan},
 title = {Interpretable off-policy learning via hyperbox search},
 url = {http://arxiv.org/pdf/2203.02473v1},
 keywords = {Computer Science - Learning;Statistics - Machine Learning},
 booktitle = {ICML},
 year = {2022},
 file = {2203.02473:Attachments/2203.02473.pdf:application/pdf}
}

@article{Yin.2022,
 author = {Yin, Mingzhang and Shi, Claudia and Wang, Yixin and Blei, David M.},
 year = {2022},
 title = {Conformal Sensitivity Analysis for Individual Treatment Effects},
 keywords = {Distribution shift;Predictive inference;Uncertainty quantification;Unconfoundedness},
 pages = {1--14},
 journal = {Journal of the American Statistical Association},
 doi = {10.1080/01621459.2022.2102503},
 file = {Conformal Sensitivity Analysis for Individual Treatment Effects:Attachments/Conformal Sensitivity Analysis for Individual Treatment Effects.pdf:application/pdf}
}

@article{Zhang.2024,
 author = {Zhang, Junzhe and Bareinboim, Elias},
 year = {2024},
 title = {Eligibility traces for confounding robust off-policy evaluation},
 journal = {OpenReview preprint},
 file = {r105:Attachments/r105.pdf:application/pdf}
}

@book{vanderVaart.1998,
 abstract = {Cambridge University Press},
 author = {{van der Vaart}, Aart},
 year = {1998},
 title = {Asymptotic statistics},
 keywords = {0521784506 9780521784504 0521496039 9780521496032},
 address = {Cambridge},
 publisher = {{Cambridge University Press}},
 isbn = {0521496039},
 file = {Asymptotic Statistics ( PDFDrive ):Attachments/Asymptotic Statistics ( PDFDrive ).pdf:application/pdf}
}

