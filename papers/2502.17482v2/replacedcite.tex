\section{Related Works}
\label{sect:rw}
\subsection{Contrastive Learning}
Contrastive learning aims to learn invariant and discriminative feature representations from different views of data, which brings similar instances (positive pairs) closer and pushes dissimilar instances (negative pairs) apart in the feature space. Different contrastive learning approaches vary on loss functions, network architectures, and ways of choosing negative samples and positive samples. 

Most contrastive learning approaches highlight on unsupervised learning. SimCLR ____ is a straightforward contrastive learning framework, which contains two augmented views and maximizes their consistency through the normalized temperature-scaled cross entropy loss. Augmented views originating from the same sample are considered positives, while all other augmented views from different samples are considered negatives. In contrast to SimCLR, MoCo ____ employs a memory bank to accumulate a substantial number of negatives encoded by a momentum-updated encoder. A recent trend involves exploring contrastive learning without explicitly using negative samples. For instance, BYOL ____ achieves representation learning by bootstrapping representations from two neural networks that learn and interact collaboratively. SimSiam ____ departs from the reliance on negative samples and instead utilizes a siamese network and stop-gradient operation.

Compared with unsupervised contrastive learning, supervised contrastive learning was much less studied. The main idea is to additionally utilize class information into designing positive and negative pairs. For example, SupCon ____ considers contrasting the set of all samples from the same class as positives against the negatives from the remainder within a batch.

\subsection{Contrastive Learning for EEG-based BCIs}
For EEG-based BCIs, contrastive learning optimizes the extracted representations, aiming to better cope with variations in different subjects, tasks, and environments, thereby enhancing performance and generalization capabilities. ____ incorporated a subject-specific contrastive loss and adversarial training to learn subject-invariant features. In seizure classification,  ____ employed contrastive learning to alleviate the reliance on extensive labeled data. For sleep stage classification,  ____ established a pretext task focused on identifying the right transformation pairs. ____ utilized the attention mechanism to refine the quality of positive pairs. ____ extended SimCLR to EEG data and developed a channel-wise feature extractor. ____ conducted contrastive learning upon local representations and contextual representations, and incorporated expert knowledge to craft more accurate positive samples.  ____ integrated neurological theory to extract effective representations.

Current works that apply contrastive learning for EEG analysis mainly consider the unsupervised category. The performance thus highly relies on large quantity of EEG data and careful parameter tuning, which may not be the optimal improvement over most supervised learning strategies.

\subsection{EEG Data Augmentation} 
Existing EEG data augmentation strategies mainly include time, frequency, and spatial domain augmentations.

For time domain augmentations, ____ introduced random Gaussian white noise to the original trials, ____ selectively zeroed a random portion of the EEG trial, and ____ applied random trial flips or reversed the axis of time across all channels. For frequency domain augmentations, ____ randomized the phases of Fourier transforms for all channels, ____ and ____ randomly filtered narrow frequency bands across all channels, while ____ introduced random shifts to the power spectral density of all channels. For spatial domain augmentations, ____ involved zeroing the values of randomly selected channels or performing random permutations. ____ interpolated channels at randomly rotated positions. ____ selected and recombined the left brain part and the right brain part of different samples.

However, existing approaches usually consider one single EEG data augmentation strategy at a time, without integrating multi-view knowledge together.