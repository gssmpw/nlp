\section{Conclusion}
In this paper, we introduce NutWorld, a novel framework for efficiently representing casual monocular videos through dynamic Gaussian Splatting. By introducing the structured STAG representation and incorporating effective depth and flow regularization, our approach successfully tackles several fundamental challenges in monocular video representation, achieving both spatial and temporal coherence without per-scene optimization. Comprehensive experiments demonstrate that NutWorld not only achieves high-fidelity video reconstruction in real-time but also enables various downstream applications. In the future, distilling rich visual features (e.g., SAM, CLIP) into our STAG representation and adapting our representation paradigm for video generation tasks are promising directions to explore.

