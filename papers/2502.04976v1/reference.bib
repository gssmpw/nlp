@article{zhao2023survey,
  title={A survey of large language models},
  author={Zhao, Wayne Xin and Zhou, Kun and Li, Junyi and Tang, Tianyi and Wang, Xiaolei and Hou, Yupeng and Min, Yingqian and Zhang, Beichen and Zhang, Junjie and Dong, Zican and others},
  journal={arXiv preprint arXiv:2303.18223},
  year={2023}
}

@article{li2024survey,
  title={A Survey on Benchmarks of Multimodal Large Language Models},
  author={Li, Jian and Lu, Weiheng},
  journal={arXiv preprint arXiv:2408.08632},
  year={2024}
}

@article{luo2024panosent,
  title={PanoSent: A Panoptic Sextuple Extraction Benchmark for Multimodal Conversational Aspect-based Sentiment Analysis},
  author={Luo, Meng and Fei, Hao and Li, Bobo and Wu, Shengqiong and Liu, Qian and Poria, Soujanya and Cambria, Erik and Lee, Mong-Li and Hsu, Wynne},
  journal={arXiv preprint arXiv:2408.09481},
  year={2024}
}

@inproceedings{luo2024nus,
  title={NUS-Emo at SemEval-2024 Task 3: Instruction-Tuning LLM for Multimodal Emotion-Cause Analysis in Conversations},
  author={Luo, Meng and Zhang, Han and Wu, Shengqiong and Li, Bobo and Han, Hong and Fei, Hao},
  booktitle={Proceedings of the 18th International Workshop on Semantic Evaluation (SemEval-2024)},
  pages={1599--1606},
  year={2024}
}

@article{rashkin2018towards,
  title={Towards empathetic open-domain conversation models: A new benchmark and dataset},
  author={Rashkin, Hannah},
  journal={arXiv preprint arXiv:1811.00207},
  year={2018}
}

@article{majumder2020mime,
  title={MIME: MIMicking emotions for empathetic response generation},
  author={Majumder, Navonil and Hong, Pengfei and Peng, Shanshan and Lu, Jiankun and Ghosal, Deepanway and Gelbukh, Alexander and Mihalcea, Rada and Poria, Soujanya},
  journal={arXiv preprint arXiv:2010.01454},
  year={2020}
}

@inproceedings{sabour2022cem,
  title={Cem: Commonsense-aware empathetic response generation},
  author={Sabour, Sahand and Zheng, Chujie and Huang, Minlie},
  booktitle={Proceedings of the AAAI Conference on Artificial Intelligence},
  pages={11229--11237},
  year={2022}
}

@article{yang2024exploiting,
  title={Exploiting emotion-semantic correlations for empathetic response generation},
  author={Yang, Zhou and Ren, Zhaochun and Wang, Yufeng and Zhu, Xiaofei and Chen, Zhihao and Cai, Tiecheng and Wu, Yunbing and Su, Yisong and Ju, Sibo and Liao, Xiangwen},
  journal={arXiv preprint arXiv:2402.17437},
  year={2024}
}

@article{li2024styletts,
  title={Styletts 2: Towards human-level text-to-speech through style diffusion and adversarial training with large speech language models},
  author={Li, Yinghao Aaron and Han, Cong and Raghavan, Vinay and Mischler, Gavin and Mesgarani, Nima},
  journal={Advances in Neural Information Processing Systems},
  volume={36},
  year={2024}
}

@article{ma2023dreamtalk,
  title={Dreamtalk: When expressive talking head generation meets diffusion probabilistic models},
  author={Ma, Yifeng and Zhang, Shiwei and Wang, Jiayu and Wang, Xiang and Zhang, Yingya and Deng, Zhidong},
  journal={arXiv preprint arXiv:2312.09767},
  year={2023}
}

@article{raamkumar2022empathetic,
  title={Empathetic conversational systems: A review of current advances, gaps, and opportunities},
  author={Raamkumar, Aravind Sesagiri and Yang, Yinping},
  journal={IEEE Transactions on Affective Computing},
  pages={2722--2739},
  year={2022}
}

@article{qian2023harnessing,
  title={Harnessing the power of large language models for empathetic response generation: Empirical investigations and improvements},
  author={Qian, Yushan and Zhang, Wei-Nan and Liu, Ting},
  journal={arXiv preprint arXiv:2310.05140},
  year={2023}
}

@article{zhou2022case,
  title={Case: Aligning coarse-to-fine cognition and affection for empathetic response generation},
  author={Zhou, Jinfeng and Zheng, Chujie and Wang, Bo and Zhang, Zheng and Huang, Minlie},
  journal={arXiv preprint arXiv:2208.08845},
  year={2022}
}

@article{yang2024enhancing,
  title={Enhancing Empathetic Response Generation by Augmenting LLMs with Small-scale Empathetic Models},
  author={Yang, Zhou and Ren, Zhaochun and Yufeng, Wang and Peng, Shizhong and Sun, Haizhou and Zhu, Xiaofei and Liao, Xiangwen},
  journal={arXiv preprint arXiv:2402.11801},
  year={2024}
}

@article{fei2024empathyear,
  title={EmpathyEar: An Open-source Avatar Multimodal Empathetic Chatbot},
  author={Fei, Hao and Zhang, Han and Wang, Bin and Liao, Lizi and Liu, Qian and Cambria, Erik},
  journal={arXiv preprint arXiv:2406.15177},
  year={2024}
}

@article{lin2019moel,
  title={Moel: Mixture of empathetic listeners},
  author={Lin, Zhaojiang and Madotto, Andrea and Shin, Jamin and Xu, Peng and Fung, Pascale},
  journal={arXiv preprint arXiv:1908.07687},
  year={2019}
}

@inproceedings{gao2021improving,
  title={Improving empathetic response generation by recognizing emotion cause in conversations},
  author={Gao, Jun and Liu, Yuhan and Deng, Haolin and Wang, Wei and Cao, Yu and Du, Jiachen and Xu, Ruifeng},
  booktitle={Findings of the association for computational linguistics: EMNLP 2021},
  pages={807--819},
  year={2021}
}

@inproceedings{chen2024empathetic,
  title={Empathetic Response Generation with Relation-aware Commonsense Knowledge},
  author={Chen, Changyu and Li, Yanran and Wei, Chen and Cui, Jianwei and Wang, Bin and Yan, Rui},
  booktitle={Proceedings of the 17th ACM International Conference on Web Search and Data Mining},
  pages={87--95},
  year={2024}
}

@article{liu2024visual,
  title={Visual instruction tuning},
  author={Liu, Haotian and Li, Chunyuan and Wu, Qingyang and Lee, Yong Jae},
  journal={Advances in neural information processing systems},
  volume={36},
  year={2024}
}

@article{zhu2023minigpt,
  title={Minigpt-4: Enhancing vision-language understanding with advanced large language models},
  author={Zhu, Deyao and Chen, Jun and Shen, Xiaoqian and Li, Xiang and Elhoseiny, Mohamed},
  journal={arXiv preprint arXiv:2304.10592},
  year={2023}
}

@inproceedings{li2023blip,
  title={Blip-2: Bootstrapping language-image pre-training with frozen image encoders and large language models},
  author={Li, Junnan and Li, Dongxu and Savarese, Silvio and Hoi, Steven},
  booktitle={International conference on machine learning},
  pages={19730--19742},
  year={2023}
}

@article{su2023pandagpt,
  title={Pandagpt: One model to instruction-follow them all},
  author={Su, Yixuan and Lan, Tian and Li, Huayang and Xu, Jialu and Wang, Yan and Cai, Deng},
  journal={arXiv preprint arXiv:2305.16355},
  year={2023}
}

@article{bai2023qwen,
  title={Qwen technical report},
  author={Bai, Jinze and Bai, Shuai and Chu, Yunfei and Cui, Zeyu and Dang, Kai and Deng, Xiaodong and Fan, Yang and Ge, Wenbin and Han, Yu and Huang, Fei and others},
  journal={arXiv preprint arXiv:2309.16609},
  year={2023}
}

@inproceedings{wu24next,
  title={{NE}x{T}-{GPT}: Any-to-Any Multimodal {LLM}},
  author={Wu, Shengqiong and Fei, Hao and Qu, Leigang and Ji, Wei and Chua, Tat-Seng},
  booktitle={Proceedings of the International Conference on Machine Learning},
  pages = {53366--53397},
  year={2024}
}

@inproceedings{lu2024unified,
  title={Unified-IO 2: Scaling Autoregressive Multimodal Models with Vision Language Audio and Action},
  author={Lu, Jiasen and Clark, Christopher and Lee, Sangho and Zhang, Zichen and Khosla, Savya and Marten, Ryan and Hoiem, Derek and Kembhavi, Aniruddha},
  booktitle={Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition},
  pages={26439--26455},
  year={2024}
}


@misc{vicuna2023,
    title = {Vicuna: An Open-Source Chatbot Impressing GPT-4 with 90\%* ChatGPT Quality},
    url = {https://lmsys.org/blog/2023-03-30-vicuna/},
    author = {Chiang, Wei-Lin and Li, Zhuohan and Lin, Zi and Sheng, Ying and Wu, Zhanghao and Zhang, Hao and Zheng, Lianmin and Zhuang, Siyuan and Zhuang, Yonghao and Gonzalez, Joseph E. and Stoica, Ion and Xing, Eric P.},
    month = {March},
    year = {2023}
}

@article{dong2023dreamllm,
  title={Dreamllm: Synergistic multimodal comprehension and creation},
  author={Dong, Runpei and Han, Chunrui and Peng, Yuang and Qi, Zekun and Ge, Zheng and Yang, Jinrong and Zhao, Liang and Sun, Jianjian and Zhou, Hongyu and Wei, Haoran and others},
  journal={arXiv preprint arXiv:2309.11499},
  year={2023}
}

@article{lin2023video,
  title={Video-llava: Learning united visual representation by alignment before projection},
  author={Lin, Bin and Zhu, Bin and Ye, Yang and Ning, Munan and Jin, Peng and Yuan, Li},
  journal={arXiv preprint arXiv:2311.10122},
  year={2023}
}

@article{chung2024scaling,
  title={Scaling instruction-finetuned language models},
  author={Chung, Hyung Won and Hou, Le and Longpre, Shayne and Zoph, Barret and Tay, Yi and Fedus, William and Li, Yunxuan and Wang, Xuezhi and Dehghani, Mostafa and Brahma, Siddhartha and others},
  journal={Journal of Machine Learning Research},
  volume={25},
  number={70},
  pages={1--53},
  year={2024}
}

@article{team2024chatglm,
  title={Chatglm: A family of large language models from glm-130b to glm-4 all tools},
  author={Team, GLM and Zeng, Aohan and Xu, Bin and Wang, Bowen and Zhang, Chenhui and Yin, Da and Rojas, Diego and Feng, Guanyu and Zhao, Hanlin and Lai, Hanyu and others},
  journal={arXiv e-prints},
  pages={arXiv--2406},
  year={2024}
}

@inproceedings{li2022knowledge,
  title={Knowledge bridging for empathetic dialogue generation},
  author={Li, Qintong and Li, Piji and Ren, Zhaochun and Ren, Pengjie and Chen, Zhumin},
  booktitle={Proceedings of the AAAI conference on artificial intelligence},
  pages={10993--11001},
  year={2022}
}

@article{li2015diversity,
  title={A diversity-promoting objective function for neural conversation models},
  author={Li, Jiwei and Galley, Michel and Brockett, Chris and Gao, Jianfeng and Dolan, Bill},
  journal={arXiv preprint arXiv:1510.03055},
  year={2015}
}

@article{wang2002universal,
  title={A universal image quality index},
  author={Wang, Zhou and Bovik, Alan C},
  journal={IEEE signal processing letters},
  volume={9},
  number={3},
  pages={81--84},
  year={2002}
}

@article{narvekar2011no,
  title={A no-reference image blur metric based on the cumulative probability of blur detection (CPBD)},
  author={Narvekar, Niranjan D and Karam, Lina J},
  journal={IEEE Transactions on Image Processing},
  volume={20},
  number={9},
  pages={2678--2683},
  year={2011}
}

@inproceedings{chung2017out,
  title={Out of time: automated lip sync in the wild},
  author={Chung, Joon Son and Zisserman, Andrew},
  booktitle={Computer Vision--ACCV 2016 Workshops: ACCV 2016 International Workshops, Taipei, Taiwan, November 20-24, 2016, Revised Selected Papers, Part II 13},
  pages={251--263},
  year={2017}
}


@article{hu2021lora,
  title={Lora: Low-rank adaptation of large language models},
  author={Hu, Edward J and Shen, Yelong and Wallis, Phillip and Allen-Zhu, Zeyuan and Li, Yuanzhi and Wang, Shean and Wang, Lu and Chen, Weizhu},
  journal={arXiv preprint arXiv:2106.09685},
  year={2021}
}

@inproceedings{rasley2020deepspeed,
  title={Deepspeed: System optimizations enable training deep learning models with over 100 billion parameters},
  author={Rasley, Jeff and Rajbhandari, Samyam and Ruwase, Olatunji and He, Yuxiong},
  booktitle={Proceedings of the 26th ACM SIGKDD International Conference on Knowledge Discovery \& Data Mining},
  pages={3505--3506},
  year={2020}
}


@article{van2008visualizing,
  title={Visualizing data using t-SNE.},
  author={Van der Maaten, Laurens and Hinton, Geoffrey},
  journal={Journal of machine learning research},
  volume={9},
  number={11},
  year={2008}
}

@article{hsu2021hubert,
  title={Hubert: Self-supervised speech representation learning by masked prediction of hidden units},
  author={Hsu, Wei-Ning and Bolte, Benjamin and Tsai, Yao-Hung Hubert and Lakhotia, Kushal and Salakhutdinov, Ruslan and Mohamed, Abdelrahman},
  journal={IEEE/ACM transactions on audio, speech, and language processing},
  volume={29},
  pages={3451--3460},
  year={2021}
}

@inproceedings{radford2021learning,
  title={Learning transferable visual models from natural language supervision},
  author={Radford, Alec and Kim, Jong Wook and Hallacy, Chris and Ramesh, Aditya and Goh, Gabriel and Agarwal, Sandhini and Sastry, Girish and Askell, Amanda and Mishkin, Pamela and Clark, Jack and others},
  booktitle={International conference on machine learning},
  pages={8748--8763},
  year={2021}
}

@article{vaswani2017attention,
  title={Attention is all you need},
  author={Vaswani, A},
  journal={Advances in Neural Information Processing Systems},
  year={2017}
}

@article{kingma2013auto,
  title={Auto-encoding variational bayes},
  author={Kingma, Diederik P},
  journal={arXiv preprint arXiv:1312.6114},
  year={2013}
}

@article{viswanathan2005measuring,
  title={Measuring speech quality for text-to-speech systems: development and assessment of a modified mean opinion score (MOS) scale},
  author={Viswanathan, Mahesh and Viswanathan, Madhubalan},
  journal={Computer speech \& language},
  volume={19},
  number={1},
  pages={55--83},
  year={2005}
}

@article{lorenzo2018voice,
  title={The voice conversion challenge 2018: Promoting development of parallel and nonparallel methods},
  author={Lorenzo-Trueba, Jaime and Yamagishi, Junichi and Toda, Tomoki and Saito, Daisuke and Villavicencio, Fernando and Kinnunen, Tomi and Ling, Zhenhua},
  journal={arXiv preprint arXiv:1804.04262},
  year={2018}
}

@inproceedings{yan-etal-2024-talk,
    title = "Talk With Human-like Agents: Empathetic Dialogue Through Perceptible Acoustic Reception and Reaction",
    author = "Yan, Haoqiu  and
      Zhu, Yongxin  and
      Zheng, Kai  and
      Liu, Bing  and
      Cao, Haoyu  and
      Jiang, Deqiang  and
      Xu, Linli",
    booktitle = "Proceedings of the 62nd Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers)",
    year = "2024",
    pages = "15009--15022",
}

@inproceedings{zhang-etal-2024-stickerconv,
    title = "{STICKERCONV}: Generating Multimodal Empathetic Responses from Scratch",
    author = "Zhang, Yiqun  and
      Kong, Fanheng  and
      Wang, Peidong  and
      Sun, Shuang  and
      SWangLing, SWangLing  and
      Feng, Shi  and
      Wang, Daling  and
      Zhang, Yifei  and
      Song, Kaisong",
    booktitle = "Proceedings of the 62nd Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers)",
    year = "2024",
    pages = "7707--7733",
}

@article{zheng2023ecqed,
  title={ECQED: emotion-cause quadruple extraction in dialogs},
  author={Zheng, Li and Ji, Donghong and Li, Fei and Fei, Hao and Wu, Shengqiong and Li, Jingye and Li, Bobo and Teng, Chong},
  journal={arXiv preprint arXiv:2306.03969},
  year={2023}
}

@inproceedings{fei2020latent,
  title={Latent emotion memory for multi-label emotion classification},
  author={Fei, Hao and Zhang, Yue and Ren, Yafeng and Ji, Donghong},
  booktitle={Proceedings of the AAAI conference on artificial intelligence},
  volume={34},
  number={05},
  pages={7692--7699},
  year={2020}
}

@article{li2022diaasq,
  title={Diaasq: A benchmark of conversational aspect-based sentiment quadruple analysis},
  author={Li, Bobo and Fei, Hao and Li, Fei and Wu, Yuhan and Zhang, Jinsong and Wu, Shengqiong and Li, Jingye and Liu, Yijiang and Liao, Lizi and Chua, Tat-Seng and others},
  journal={arXiv preprint arXiv:2211.05705},
  year={2022}
}

@inproceedings{fei2024vitron,
  title={VITRON: A Unified Pixel-level Vision LLM for Understanding, Generating, Segmenting, Editing},
  author={Fei, Hao and Wu, Shengqiong and Zhang, Hanwang and Chua, Tat-Seng and Yan, Shuicheng},
  year={2024},
  journal={Proceedings of the Advances in neural information processing systems},
}

@article{fei2024enhancing,
  title={Enhancing video-language representations with structural spatio-temporal alignment},
  author={Fei, Hao and Wu, Shengqiong and Zhang, Meishan and Zhang, Min and Chua, Tat-Seng and Yan, Shuicheng},
  journal={IEEE Transactions on Pattern Analysis and Machine Intelligence},
  year={2024},
  publisher={IEEE}
}

@article{wu2024towards,
  title={Towards Semantic Equivalence of Tokenization in Multimodal LLM},
  author={Wu, Shengqiong and Fei, Hao and Li, Xiangtai and Ji, Jiayi and Zhang, Hanwang and Chua, Tat-Seng and Yan, Shuicheng},
  journal={arXiv preprint arXiv:2406.05127},
  year={2024}
}

@inproceedings{fei2024multimodal,
  title={From Multimodal LLM to Human-level AI: Modality, Instruction, Reasoning, Efficiency and Beyond},
  author={Fei, Hao and Yao, Yuan and Zhang, Zhuosheng and Liu, Fuxiao and Zhang, Ao and Chua, Tat-Seng},
  booktitle={Proceedings of the 2024 Joint International Conference on Computational Linguistics, Language Resources and Evaluation (LREC-COLING 2024): Tutorial Summaries},
  pages={1--8},
  year={2024}
}

@article{xu2024faithful,
  title={Faithful Logical Reasoning via Symbolic Chain-of-Thought},
  author={Xu, Jundong and Fei, Hao and Pan, Liangming and Liu, Qian and Lee, Mong-Li and Hsu, Wynne},
  journal={arXiv preprint arXiv:2405.18357},
  year={2024}
}

@inproceedings{fei2023reasoning,
  title={Reasoning Implicit Sentiment with Chain-of-Thought Prompting},
  author={Fei, Hao and Li, Bobo and Liu, Qian and Bing, Lidong and Li, Fei and Chua, Tat-Seng},
  booktitle={Proceedings of the 61st Annual Meeting of the Association for Computational Linguistics (Volume 2: Short Papers)},
  pages={1171--1182},
  year={2023}
}