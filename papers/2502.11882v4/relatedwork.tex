\section{Related Works}
\paragraph{Dual Process Theory (DPT).}
Dual Process Theory (DPT) \cite{evans2013dual} refers to human cognition operates through two distinct systems: \textit{System 1}, which is fast, automatic, and intuitive, and \textit{System 2}, which is slower, deliberate, and analytical \cite{kahneman2011thinking}.
DPT explains how humans think during the perception-decision process. 
The ability to effectively integrate \textit{System 1} and \textit{System 2} helps humans accomplish complex perception and decision-making tasks.
Numerous LLM-based reasoning frameworks also utilized DPT to facilitate human-related interactions like dialogue \cite{he-etal-2024-planning} and mitigate latency issues via using a small model as \textit{System 1} \cite{liu2024slow}.
Many current agent frameworks use \textit{System 2}-based approaches to assist with planning and decision-making \cite{yu2024distilling,DBLP:conf/acl/ZhangTWW0HTLZ024}, such as chain-of-thought (CoT) \cite{wei2022chain}, ReAct \cite{yao2022react}, and Reflexion \cite{shinn2024reflexion}.
\framework is inspired by DPT, further alleviating latency issues in \textit{System 1} and endowing the agent with greater autonomy and adaptability to humans in the design of \textit{System 2}.


\paragraph{Simultaneous Human-AI Collaboration.}
Most tasks related to LLMs in human-AI collaboration research pose lower demands on real-time responsiveness, such as task-oriented dialogue systems \cite{yi2024survey} and word-guessing \cite{zahra2021direction}, where players take actions turn-by-turn.
However, collaborative tasks in the real world are often simultaneous, requiring real-time reasoning, which presents latency challenges for many LLM-based frameworks \cite{DBLP:conf/icra/LiangHXXHIFZ23}.
Another significant challenge of simultaneous collaborative tasks is adapting to humans, who are unfamiliar partners not encountered during training \cite{wang2024zsc,Yang23Cole,carroll2019utility,zhang2024proagent}. 
Theory of Mind (ToM) \cite{neil2018tom,baron1985does} has been introduced to enhance reasoning in human-AI collaborative scenarios \cite{wester2024theory}.
However, studies have pointed out that LLMs fail to achieve functional ToM \cite{riemer2024can}, where reasoning cannot be effectively implemented in decision-making processes.
To adapt to humans, \framework integrates DPT and ToM to support the entire process from perception to reasoning and decision-making, achieving functional ToM while ensuring real-time performance.