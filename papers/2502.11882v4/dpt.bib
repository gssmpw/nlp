% Use this file for citations not found in the ACL Anthology (contained in "anthology.bib").


% Journals

% First the Full Name is given, then the abbreviation used in the AMS Math
% Reviews, with an indication if it could not be found there.
% Note the 2nd overwrites the 1st, so swap them if you want the full name.

 %{AMS}
 @String{AMSTrans = "American Mathematical Society Translations" }
 @String{AMSTrans = "Amer. Math. Soc. Transl." }
 @String{BullAMS = "Bulletin of the American Mathematical Society" }
 @String{BullAMS = "Bull. Amer. Math. Soc." }
 @String{ProcAMS = "Proceedings of the American Mathematical Society" }
 @String{ProcAMS = "Proc. Amer. Math. Soc." }
 @String{TransAMS = "Transactions of the American Mathematical Society" }
 @String{TransAMS = "Trans. Amer. Math. Soc." }

 %ACM
 @String{CACM = "Communications of the {ACM}" }
 @String{CACM = "Commun. {ACM}" }
 @String{CompServ = "Comput. Surveys" }
 @String{JACM = "J. ACM" }
 @String{ACMMathSoft = "{ACM} Transactions on Mathematical Software" }
 @String{ACMMathSoft = "{ACM} Trans. Math. Software" }
 @String{SIGNUM = "{ACM} {SIGNUM} Newsletter" }
 @String{SIGNUM = "{ACM} {SIGNUM} Newslett." }

 @String{AmerSocio = "American Journal of Sociology" }
 @String{AmerStatAssoc = "Journal of the American Statistical Association" }
 @String{AmerStatAssoc = "J. Amer. Statist. Assoc." }
 @String{ApplMathComp = "Applied Mathematics and Computation" }
 @String{ApplMathComp = "Appl. Math. Comput." }
 @String{AmerMathMonthly = "American Mathematical Monthly" }
 @String{AmerMathMonthly = "Amer. Math. Monthly" }
 @String{BIT = "{BIT}" }
 @String{BritStatPsych = "British Journal of Mathematical and Statistical
          Psychology" }
 @String{BritStatPsych = "Brit. J. Math. Statist. Psych." }
 @String{CanMathBull = "Canadian Mathematical Bulletin" }
 @String{CanMathBull = "Canad. Math. Bull." }
 @String{CompApplMath = "Journal of Computational and Applied Mathematics" }
 @String{CompApplMath = "J. Comput. Appl. Math." }
 @String{CompPhys = "Journal of Computational Physics" }
 @String{CompPhys = "J. Comput. Phys." }
 @String{CompStruct = "Computers and Structures" }
 @String{CompStruct = "Comput. \& Structures" }
 @String{CompJour = "The Computer Journal" }
 @String{CompJour = "Comput. J." }
 @String{CompSysSci = "Journal of Computer and System Sciences" }
 @String{CompSysSci = "J. Comput. System Sci." }
 @String{Computing = "Computing" }
 @String{ContempMath = "Contemporary Mathematics" }
 @String{ContempMath = "Contemp. Math." }
 @String{Crelle = "Crelle's Journal" }
 @String{GiornaleMath = "Giornale di Mathematiche" }
 @String{GiornaleMath = "Giorn. Mat." } % didn't find in AMS MR., ibid.

 %IEEE
 @String{Computer = "{IEEE} Computer" }
 @String{IEEETransComp = "{IEEE} Transactions on Computers" }
 @String{IEEETransComp = "{IEEE} Trans. Comput." }
 @String{IEEETransAC = "{IEEE} Transactions on Automatic Control" }
 @String{IEEETransAC = "{IEEE} Trans. Automat. Control" }
 @String{IEEESpec = "{IEEE} Spectrum" } % didn't find in AMS MR
 @String{ProcIEEE = "Proceedings of the {IEEE}" }
 @String{ProcIEEE = "Proc. {IEEE}" } % didn't find in AMS MR
 @String{IEEETransAeroElec = "{IEEE} Transactions on Aerospace and Electronic
     Systems" }
 @String{IEEETransAeroElec = "{IEEE} Trans. Aerospace Electron. Systems" }

 @String{IMANumerAna = "{IMA} Journal of Numerical Analysis" }
 @String{IMANumerAna = "{IMA} J. Numer. Anal." }
 @String{InfProcLet = "Information Processing Letters" }
 @String{InfProcLet = "Inform. Process. Lett." }
 @String{InstMathApp = "Journal of the Institute of Mathematics and
     its Applications" }
 @String{InstMathApp = "J. Inst. Math. Appl." }
 @String{IntControl = "International Journal of Control" }
 @String{IntControl = "Internat. J. Control" }
 @String{IntNumerEng = "International Journal for Numerical Methods in
     Engineering" }
 @String{IntNumerEng = "Internat. J. Numer. Methods Engrg." }
 @String{IntSuper = "International Journal of Supercomputing Applications" }
 @String{IntSuper = "Internat. J. Supercomputing Applic." } % didn't find
%% in AMS MR
 @String{Kibernetika = "Kibernetika" }
 @String{JResNatBurStand = "Journal of Research of the National Bureau
     of Standards" }
 @String{JResNatBurStand = "J. Res. Nat. Bur. Standards" }
 @String{LinAlgApp = "Linear Algebra and its Applications" }
 @String{LinAlgApp = "Linear Algebra Appl." }
 @String{MathAnaAppl = "Journal of Mathematical Analysis and Applications" }
 @String{MathAnaAppl = "J. Math. Anal. Appl." }
 @String{MathAnnalen = "Mathematische Annalen" }
 @String{MathAnnalen = "Math. Ann." }
 @String{MathPhys = "Journal of Mathematical Physics" }
 @String{MathPhys = "J. Math. Phys." }
 @String{MathComp = "Mathematics of Computation" }
 @String{MathComp = "Math. Comp." }
 @String{MathScand = "Mathematica Scandinavica" }
 @String{MathScand = "Math. Scand." }
 @String{TablesAidsComp = "Mathematical Tables and Other Aids to Computation" }
 @String{TablesAidsComp = "Math. Tables Aids Comput." }
 @String{NumerMath = "Numerische Mathematik" }
 @String{NumerMath = "Numer. Math." }
 @String{PacificMath = "Pacific Journal of Mathematics" }
 @String{PacificMath = "Pacific J. Math." }
 @String{ParDistComp = "Journal of Parallel and Distributed Computing" }
 @String{ParDistComp = "J. Parallel and Distrib. Comput." } % didn't find
%% in AMS MR
 @String{ParComputing = "Parallel Computing" }
 @String{ParComputing = "Parallel Comput." }
 @String{PhilMag = "Philosophical Magazine" }
 @String{PhilMag = "Philos. Mag." }
 @String{ProcNAS = "Proceedings of the National Academy of Sciences
                    of the USA" }
 @String{ProcNAS = "Proc. Nat. Acad. Sci. U. S. A." }
 @String{Psychometrika = "Psychometrika" }
 @String{QuartMath = "Quarterly Journal of Mathematics, Oxford, Series (2)" }
 @String{QuartMath = "Quart. J. Math. Oxford Ser. (2)" }
 @String{QuartApplMath = "Quarterly of Applied Mathematics" }
 @String{QuartApplMath = "Quart. Appl. Math." }
 @String{RevueInstStat = "Review of the International Statisical Institute" }
 @String{RevueInstStat = "Rev. Inst. Internat. Statist." }

 %SIAM
 @String{JSIAM = "Journal of the Society for Industrial and Applied
     Mathematics" }
 @String{JSIAM = "J. Soc. Indust. Appl. Math." }
 @String{JSIAMB = "Journal of the Society for Industrial and Applied
     Mathematics, Series B, Numerical Analysis" }
 @String{JSIAMB = "J. Soc. Indust. Appl. Math. Ser. B Numer. Anal." }
 @String{SIAMAlgMeth = "{SIAM} Journal on Algebraic and Discrete Methods" }
 @String{SIAMAlgMeth = "{SIAM} J. Algebraic Discrete Methods" }
 @String{SIAMAppMath = "{SIAM} Journal on Applied Mathematics" }
 @String{SIAMAppMath = "{SIAM} J. Appl. Math." }
 @String{SIAMComp = "{SIAM} Journal on Computing" }
 @String{SIAMComp = "{SIAM} J. Comput." }
 @String{SIAMMatrix = "{SIAM} Journal on Matrix Analysis and Applications" }
 @String{SIAMMatrix = "{SIAM} J. Matrix Anal. Appl." }
 @String{SIAMNumAnal = "{SIAM} Journal on Numerical Analysis" }
 @String{SIAMNumAnal = "{SIAM} J. Numer. Anal." }
 @String{SIAMReview = "{SIAM} Review" }
 @String{SIAMReview = "{SIAM} Rev." }
 @String{SIAMSciStat = "{SIAM} Journal on Scientific and Statistical
     Computing" }
 @String{SIAMSciStat = "{SIAM} J. Sci. Statist. Comput." }

 @String{SoftPracExp = "Software Practice and Experience" }
 @String{SoftPracExp = "Software Prac. Experience" } % didn't find in AMS MR
 @String{StatScience = "Statistical Science" }
 @String{StatScience = "Statist. Sci." }
 @String{Techno = "Technometrics" }
 @String{USSRCompMathPhys = "{USSR} Computational Mathematics and Mathematical
     Physics" }
 @String{USSRCompMathPhys = "{U. S. S. R.} Comput. Math. and Math. Phys." }
 @String{VLSICompSys = "Journal of {VLSI} and Computer Systems" }
 @String{VLSICompSys = "J. {VLSI} Comput. Syst." }
 @String{ZAngewMathMech = "Zeitschrift fur Angewandte Mathematik und
     Mechanik" }
 @String{ZAngewMathMech = "Z. Angew. Math. Mech." }
 @String{ZAngewMathPhys = "Zeitschrift fur Angewandte Mathematik und Physik" }
 @String{ZAngewMathPhys = "Z. Angew. Math. Phys." }

% Publishers % ================================================= |

 @String{Academic = "Academic Press" }
 @String{ACMPress = "{ACM} Press" }
 @String{AdamHilger = "Adam Hilger" }
 @String{AddisonWesley = "Addison-Wesley" }
 @String{AllynBacon = "Allyn and Bacon" }
 @String{AMS = "American Mathematical Society" }
 @String{Birkhauser = "Birkha{\"u}ser" }
 @String{CambridgePress = "Cambridge University Press" }
 @String{Chelsea = "Chelsea" }
 @String{ClaredonPress = "Claredon Press" }
 @String{DoverPub = "Dover Publications" }
 @String{Eyolles = "Eyolles" }
 @String{HoltRinehartWinston = "Holt, Rinehart and Winston" }
 @String{Interscience = "Interscience" }
 @String{JohnsHopkinsPress = "The Johns Hopkins University Press" }
 @String{JohnWileySons = "John Wiley and Sons" }
 @String{Macmillan = "Macmillan" }
 @String{MathWorks = "The Math Works Inc." }
 @String{McGrawHill = "McGraw-Hill" }
 @String{NatBurStd = "National Bureau of Standards" }
 @String{NorthHolland = "North-Holland" }
 @String{OxfordPress = "Oxford University Press" }  %address Oxford or London?
 @String{PergamonPress = "Pergamon Press" }
 @String{PlenumPress = "Plenum Press" }
 @String{PrenticeHall = "Prentice-Hall" }
 @String{SIAMPub = "{SIAM} Publications" }
 @String{Springer = "Springer-Verlag" }
 @String{TexasPress = "University of Texas Press" }
 @String{VanNostrand = "Van Nostrand" }
 @String{WHFreeman = "W. H. Freeman and Co." }

%Entries

@inproceedings{le2023trust,
author = {Le Guillou, Marin and Pr\'{e}vot, Laurent and Berberian, Bruno},
title = {Trusting Artificial Agents: Communication Trumps Performance},
year = {2023},
isbn = {9781450394321},
publisher = {International Foundation for Autonomous Agents and Multiagent Systems},
address = {Richland, SC},
abstract = {Acceptability and trust toward an Artificial Agent (AA) are known to be strongly related to the transparency of its behavior. However, the opacity of the AI techniques implemented to drive the behavior of AAs is growing in parallel with their performance (performance/transparency trade-off). Thus, it is crucial and increasingly required to identify minimal and necessary information for achieving efficient human/AA interaction in order to include them as AAs' requirements at design stage. For this purpose, this paper proposes to bring knowledge and methods from domains accustomed to human behavior studies. Based on ergonomic and cognition literature, this paper tests through a user-study the hypothesis that sharing distal, proximal and motor intentions (what we call intention-based explanations) will improve the acceptability of an AA. The "Overcooked" task from Carroll and colleagues[3] - which requires coordination on goals and motor levels - is used as a test-bed for hypotheses manipulation. Our experimental work consisted in implementing a modified version of the task, analyzing 60 subjects performance, behaviors and feelings in two groups (control and hypothesis-testing) and having them filled an extensive survey. Half of them interact with an agent sharing its intentions while the other half stand in the control group without any information shared by the agent. The results show that intentions sharing leads to a greater acceptability - by means of delegation of control towards the AA - as well as trust. Critically, acceptability and trust seem to be decoupled from team performance. These results suggest the importance of intention-based explanations as a support for cooperation between the human operator and artificial agents. This work demonstrates the need to take into account human cognition when designing systems requiring acceptable and trustworthy AI techniques.},
booktitle = {Proceedings of the 2023 International Conference on Autonomous Agents and Multiagent Systems},
pages = {299–306},
numpages = {8},
keywords = {XAI, cognition, user-study},
location = {London, United Kingdom},
series = {AAMAS '23}
}

@book{pinheiro2006mixed,
  title={Mixed-effects models in S and S-PLUS},
  author={Pinheiro, Jos{\'e} and Bates, Douglas},
  year={2006},
  publisher={Springer science \& business media}
}

@article{kaptein2016using,
  title={Using generalized linear (mixed) models in HCI},
  author={Kaptein, Maurits},
  journal={Modern Statistical Methods for HCI},
  pages={251--274},
  year={2016},
  publisher={Springer}
}

@article{dragicevic2016fair,
  title={Fair statistical communication in HCI},
  author={Dragicevic, Pierre},
  journal={Modern statistical methods for HCI},
  pages={291--330},
  year={2016},
  publisher={Springer}
}

@phdthesis{dragicevic2015hci,
  title={HCI Statistics without p-values},
  author={Dragicevic, Pierre},
  year={2015},
  school={Inria}
}

@inproceedings{devin2016implemented,
  title={An implemented theory of mind to improve human-robot shared plans execution},
  author={Devin, Sandra and Alami, Rachid},
  booktitle={2016 11th ACM/IEEE International Conference on Human-Robot Interaction (HRI)},
  pages={319--326},
  year={2016},
  organization={IEEE}
}

@article{meltzoff1999origins,
  title={Origins of theory of mind, cognition and communication},
  author={Meltzoff, Andrew N},
  journal={Journal of communication disorders},
  volume={32},
  number={4},
  pages={251--269},
  year={1999},
  publisher={Elsevier}
}

@article{krych2007think,
  title={“I think I know what you mean”: The role of theory of mind in collaborative communication},
  author={Krych-Appelbaum, Meredyth and Law, Julie Banzon and Jones, Dayna and Barnacz, Allyson and Johnson, Amanda and Keenan, Julian Paul},
  journal={Interaction Studies},
  volume={8},
  number={2},
  pages={267--280},
  year={2007},
  publisher={John Benjamins}
}

@article{vicari2003multi,
  title={A multi-agent intelligent environment for medical knowledge},
  author={Vicari, Rosa M and Flores, Cecilia D and Silvestre, Andre M and Seixas, Louise J and Ladeira, Marcelo and Coelho, Helder},
  journal={Artificial Intelligence in Medicine},
  volume={27},
  number={3},
  pages={335--366},
  year={2003},
  publisher={Elsevier}
}

@article{tudor2020conversational,
  title={Conversational agents in health care: scoping review and conceptual analysis},
  author={Tudor Car, Lorainne and Dhinagaran, Dhakshenya Ardhithy and Kyaw, Bhone Myint and Kowatsch, Tobias and Joty, Shafiq and Theng, Yin-Leng and Atun, Rifat},
  journal={Journal of medical Internet research},
  volume={22},
  number={8},
  pages={e17158},
  year={2020},
  publisher={JMIR Publications Toronto, Canada}
}

@article{m2024augmenting,
  title={Augmenting large language models with chemistry tools},
  author={M. Bran, Andres and Cox, Sam and Schilter, Oliver and Baldassari, Carlo and White, Andrew D and Schwaller, Philippe},
  journal={Nature Machine Intelligence},
  pages={1--11},
  year={2024},
  publisher={Nature Publishing Group UK London}
}

@article{swan2023math,
  title={Math agents: Computational infrastructure, mathematical embedding, and genomics},
  author={Swan, Melanie and Kido, Takashi and Roland, Eric and Santos, Renato P dos},
  journal={arXiv preprint arXiv:2307.02502},
  year={2023}
}

@article{yang2024talk2care,
  title={Talk2Care: An LLM-based Voice Assistant for Communication between Healthcare Providers and Older Adults},
  author={Yang, Ziqi and Xu, Xuhai and Yao, Bingsheng and Rogers, Ethan and Zhang, Shao and Intille, Stephen and Shara, Nawar and Gao, Guodong Gordon and Wang, Dakuo},
  journal={Proceedings of the ACM on Interactive, Mobile, Wearable and Ubiquitous Technologies},
  volume={8},
  number={2},
  pages={1--35},
  year={2024},
  publisher={ACM New York, NY, USA}
}

@book{russell2016artificial,
  title={Artificial intelligence: a modern approach},
  author={Russell, Stuart J and Norvig, Peter},
  year={2016},
  publisher={Pearson}
}

@inproceedings{liu2024slow,
author = {Liu, Jijia and Yu, Chao and Gao, Jiaxuan and Xie, Yuqing and Liao, Qingmin and Wu, Yi and Wang, Yu},
title = {LLM-Powered Hierarchical Language Agent for Real-time Human-AI Coordination},
year = {2024},
isbn = {9798400704864},
publisher = {International Foundation for Autonomous Agents and Multiagent Systems},
address = {Richland, SC},
abstract = {AI agents powered by Large Language Models (LLMs) have made significant advances, enabling them to assist humans in diverse complex tasks and leading to a revolution in human-AI coordination. LLM-powered agents typically require invoking LLM APIs and employing artificially designed complex prompts, which results in high inference latency. While this paradigm works well in scenarios with minimal interactive demands, such as code generation, it is unsuitable for highly interactive and real-time applications, such as gaming. Traditional gaming AI often employs small models or reactive policies, enabling fast inference but offering limited task completion and interaction abilities. In this work, we consider Overcooked as our testbed where players could communicate with natural language and cooperate to serve orders. We propose a Hierarchical Language Agent (HLA) for human-AI coordination that provides both strong reasoning abilities while keeping real-time execution. In particular, HLA adopts a hierarchical framework and comprises three modules: a proficient LLM, referred to as Slow Mind, for intention reasoning and language interaction, a lightweight LLM, referred to as Fast Mind, for generating macro actions, and a reactive policy, referred to as Executor, for transforming macro actions into atomic actions. Human studies show that HLA outperforms other baseline agents, including slow-mind-only agents and fast-mind-only agents, with stronger cooperation abilities, faster responses, and more consistent language communications.},
booktitle = {Proceedings of the 23rd International Conference on Autonomous Agents and Multiagent Systems},
pages = {1219–1228},
numpages = {10},
keywords = {hierarchical reasoning and planning, language agents, large language models, real-time human-ai coordination},
location = {Auckland, New Zealand},
series = {AAMAS '24}
}

@inproceedings{guods,
  title={DS-Agent: Automated Data Science by Empowering Large Language Models with Case-Based Reasoning},
  author={Guo, Siyuan and Deng, Cheng and Wen, Ying and Chen, Hechang and Chang, Yi and Wang, Jun},
  booktitle={Forty-first International Conference on Machine Learning},
year = {2024}
}

@inproceedings{aher2023using,
  title={Using large language models to simulate multiple humans and replicate human subject studies},
  author={Aher, Gati V and Arriaga, Rosa I and Kalai, Adam Tauman},
  booktitle={International Conference on Machine Learning},
  pages={337--371},
  year={2023},
  organization={PMLR}
}

@article{iantovics2008agent,
  title={Agent-based medical diagnosis systems},
  author={Iantovics, Barna L{\'a}szl{\'o}},
  journal={Computing and Informatics},
  volume={27},
  number={4},
  pages={593--625},
  year={2008}
}

@article{
wang2024voyager,
title={Voyager: An Open-Ended Embodied Agent with Large Language Models},
author={Guanzhi Wang and Yuqi Xie and Yunfan Jiang and Ajay Mandlekar and Chaowei Xiao and Yuke Zhu and Linxi Fan and Anima Anandkumar},
journal={Transactions on Machine Learning Research},
issn={2835-8856},
year={2024},
url={https://openreview.net/forum?id=ehfRiF0R3a},
note={}
}

@inproceedings{brohan2023can,
  title={Do as i can, not as i say: Grounding language in robotic affordances},
  author={Brohan, Anthony and Chebotar, Yevgen and Finn, Chelsea and Hausman, Karol and Herzog, Alexander and Ho, Daniel and Ibarz, Julian and Irpan, Alex and Jang, Eric and Julian, Ryan and others},
  booktitle={Conference on robot learning},
  pages={287--318},
  year={2023},
  organization={PMLR}
}

@article{wu2023tidybot,
  title={Tidybot: Personalized robot assistance with large language models},
  author={Wu, Jimmy and Antonova, Rika and Kan, Adam and Lepert, Marion and Zeng, Andy and Song, Shuran and Bohg, Jeannette and Rusinkiewicz, Szymon and Funkhouser, Thomas},
  journal={Autonomous Robots},
  volume={47},
  number={8},
  pages={1087--1102},
  year={2023},
  publisher={Springer}
}

@article{zhang2024simulating,
  title={Simulating Classroom Education with LLM-Empowered Agents},
  author={Zhang, Zheyuan and Zhang-Li, Daniel and Yu, Jifan and Gong, Linlu and Zhou, Jinchang and Liu, Zhiyuan and Hou, Lei and Li, Juanzi},
  journal={arXiv preprint arXiv:2406.19226},
  year={2024}
}

@article{sonlu2024effects,
  title={The Effects of Embodiment and Personality Expression on Learning in LLM-based Educational Agents},
  author={Sonlu, Sinan and Bendiksen, Bennie and Durupinar, Funda and G{\"u}d{\"u}kbay, U{\u{g}}ur},
  journal={arXiv preprint arXiv:2407.10993},
  year={2024}
}

@article{o2022human,
  title={Human--autonomy teaming: A review and analysis of the empirical literature},
  author={O’Neill, Thomas and McNeese, Nathan and Barron, Amy and Schelble, Beau},
  journal={Human factors},
  volume={64},
  number={5},
  pages={904--938},
  year={2022},
  publisher={Sage Publications Sage CA: Los Angeles, CA}
}

@inproceedings{dourish1992awareness,
  title={Awareness and coordination in shared workspaces},
  author={Dourish, Paul and Bellotti, Victoria},
  booktitle={Proceedings of the 1992 ACM conference on Computer-supported cooperative work},
  pages={107--114},
  year={1992}
}

@article{premack1978does,
  title={Does the chimpanzee have a theory of mind?},
  author={Premack, David and Woodruff, Guy},
  journal={Behavioral and brain sciences},
  volume={1},
  number={4},
  pages={515--526},
  year={1978},
  publisher={Cambridge University Press}
}


@inproceedings{10.1145/3527188.3561925,
author = {Rato, Diogo and Couto, Marta and Prada, Rui},
title = {Attributing Social Motivations to Changes in Agents’ Behavior and Appearance},
year = {2022},
isbn = {9781450393232},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3527188.3561925},
doi = {10.1145/3527188.3561925},
abstract = {To be considered socially intelligent, agents must be able to adjust their behavior to different social contexts. However, those adjustments must be recognized and understood by other agents and humans, particularly to identify the social motivations that triggered such changes. In this work, we report on an experimental study that explores how external observers attribute social motivations to behavior and appearance changes that agents make to adapt to the context. Furthermore, we study how the presence of other agents in the context might impact the attribution of motivations to specific changes. Our results indicate that participants identify agents’ appearance changes as more socially and spatially motivated than behavioral changes. Additionally, agents’ awareness is rated higher when the agents adjust their physical characteristics compared to behavioral changes.},
booktitle = {Proceedings of the 10th International Conference on Human-Agent Interaction},
pages = {219–226},
numpages = {8},
keywords = {User Studies, Social Motivation, Social Cognition, Human-Agent Interaction, Behavior Attribution},
location = {Christchurch, New Zealand},
series = {HAI '22}
}

@article{zhang2023geodeepshovel,
  title={GeoDeepShovel: A platform for building scientific database from geoscience literature with AI assistance},
  author={Zhang, Shao and Xu, Hui and Jia, Yuting and Wen, Ying and Wang, Dakuo and Fu, Luoyi and Wang, Xinbing and Zhou, Chenghu},
  journal={Geoscience Data Journal},
  volume={10},
  number={4},
  pages={519--537},
  year={2023},
  publisher={Wiley Online Library}
}

@article{peng2023ecological,
  title={Ecological Driving Framework of Hybrid Electric Vehicle Based on Heterogeneous Multi-Agent Deep Reinforcement Learning},
  author={Peng, Jiankun and Chen, Weiqi and Fan, Yi and He, Hongwen and Wei, Zhongbao and Ma, Chunye},
  journal={IEEE Transactions on Transportation Electrification},
  volume={10},
  number={1},
  pages={392--406},
  year={2023},
  publisher={IEEE}
}

@article{baratta2023human,
  title={Human Robot Collaboration in Industry 4.0: a literature review},
  author={Baratta, Alessio and Cimino, Antonio and Gnoni, Maria Grazia and Longo, Francesco},
  journal={Procedia Computer Science},
  volume={217},
  pages={1887--1895},
  year={2023},
  publisher={Elsevier}
}

@article{harada2023behavior,
  title={Behavior analysis of emergent rule discovery for cooperative automated driving using deep reinforcement learning},
  author={Harada, Tomohiro and Matsuoka, Johei and Hattori, Kiyohiko},
  journal={Artificial Life and Robotics},
  volume={28},
  number={1},
  pages={31--42},
  year={2023},
  publisher={Springer}
}

@inproceedings{10.1145/3613904.3642343,
author = {Zhang, Shao and Yu, Jianing and Xu, Xuhai and Yin, Changchang and Lu, Yuxuan and Yao, Bingsheng and Tory, Melanie and Padilla, Lace M. and Caterino, Jeffrey and Zhang, Ping and Wang, Dakuo},
title = {Rethinking Human-AI Collaboration in Complex Medical Decision Making: A Case Study in Sepsis Diagnosis},
year = {2024},
isbn = {9798400703300},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3613904.3642343},
doi = {10.1145/3613904.3642343},
abstract = {Today’s AI systems for medical decision support often succeed on benchmark datasets in research papers but fail in real-world deployment. This work focuses on the decision making of sepsis, an acute life-threatening systematic infection that requires an early diagnosis with high uncertainty from the clinician. Our aim is to explore the design requirements for AI systems that can support clinical experts in making better decisions for the early diagnosis of sepsis. The study begins with a formative study investigating why clinical experts abandon an existing AI-powered Sepsis predictive module in their electrical health record (EHR) system. We argue that a human-centered AI system needs to support human experts in the intermediate stages of a medical decision-making process (e.g., generating hypotheses or gathering data), instead of focusing only on the final decision. Therefore, we build SepsisLab based on a state-of-the-art AI algorithm and extend it to predict the future projection of sepsis development, visualize the prediction uncertainty, and propose actionable suggestions (i.e., which additional laboratory tests can be collected) to reduce such uncertainty. Through heuristic evaluation with six clinicians using our prototype system, we demonstrate that SepsisLab enables a promising human-AI collaboration paradigm for the future of AI-assisted sepsis diagnosis and other high-stakes medical decision making.},
booktitle = {Proceedings of the CHI Conference on Human Factors in Computing Systems},
articleno = {445},
numpages = {18},
keywords = {Human-AI collaboration, Medical decision making, Sepsis diagnosis},
location = {Honolulu, HI, USA},
series = {CHI '24}
}


@misc{openai2024gpt4omini,
  author       = {OpenAI},
  title        = {GPT-4o mini: Advancing Cost-Efficient Intelligence},
  year         = {2024},
  note         = {Accessed: 2024-09-05}
}

@article{langley2022theory,
  title={Theory of mind and preference learning at the interface of cognitive science, neuroscience, and AI: A review},
  author={Langley, Christelle and Cirstea, Bogdan Ionut and Cuzzolin, Fabio and Sahakian, Barbara J},
  journal={Frontiers in artificial intelligence},
  volume={5},
  pages={778852},
  year={2022},
  publisher={Frontiers}
}

@inproceedings{10.1145/3544548.3581340,
author = {Kim, Taenyun and Molina, Maria D. and Rheu, Minjin (MJ) and Zhan, Emily S. and Peng, Wei},
title = {One AI Does Not Fit All: A Cluster Analysis of the Laypeople’s Perception of AI Roles},
year = {2023},
isbn = {9781450394215},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3544548.3581340},
doi = {10.1145/3544548.3581340},
abstract = {Artificial intelligence (AI) applications have become an integral part of our society. However, studying AI as one entity or studying idiosyncratic applications separately both have limitations. Thus, this study used computational methods to categorize ten different AI roles prevalent in our everyday life and compared laypeople’s perceptions of them using online survey data (N = 727). Based on theoretical factors related to the fundamental nature of AI, the principal component analysis revealed two dimensions that categorize AI: human involvement and AI autonomy. K-means clustering identified four AI role clusters: tools (low in both dimensions), servants (high human involvement and low AI autonomy), assistants (low human involvement and high AI autonomy), and mediators (high in both dimensions). Multivariate analyses of covariances revealed that people assessed AI mediators the most and AI tools the least favorably. Demographics also influenced laypeople’s assessments of AI. The implications of these results are discussed.},
booktitle = {Proceedings of the 2023 CHI Conference on Human Factors in Computing Systems},
articleno = {29},
numpages = {20},
keywords = {AI Autonomy, Artificial Intelligence (AI), Attitude, Clustering Analysis, Credibility, Human Involvement, Human-AI Interaction (HAII), Social Approval},
location = {Hamburg, Germany},
series = {CHI '23}
}
@article{weisz2024expedient,
  title={Expedient Assistance and Consequential Misunderstanding: Envisioning an Operationalized Mutual Theory of Mind},
  author={Weisz, Justin D and Muller, Michael and Goldberg, Arielle and Moran, Dario Andres Silva},
  journal={arXiv preprint arXiv:2406.11946},
  year={2024}
}

@book{baron1999evolution,
  title={The evolution of a theory of mind},
  author={Baron-Cohen, Simon},
  year={1999},
  publisher={na}
}

@article{baron1985does,
  title={Does the autistic child have a “theory of mind”?},
  author={Baron-Cohen, Simon and Leslie, Alan M and Frith, Uta},
  journal={Cognition},
  volume={21},
  number={1},
  pages={37--46},
  year={1985},
  publisher={Elsevier}
}

@inproceedings{10.1145/3544548.3580794,
author = {Pinski, Marc and Adam, Martin and Benlian, Alexander},
title = {AI Knowledge: Improving AI Delegation through Human Enablement},
year = {2023},
isbn = {9781450394215},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3544548.3580794},
doi = {10.1145/3544548.3580794},
abstract = {When collaborating with artificial intelligence (AI), humans can often delegate tasks to leverage complementary AI competencies. However, humans often delegate inefficiently. Enabling humans with knowledge about AI can potentially improve inefficient AI delegation. We conducted a between-subjects experiment (two groups, n = 111) to examine how enabling humans with AI knowledge can improve AI delegation in human-AI collaboration. We find that AI knowledge-enabled humans align their delegation decisions more closely with their assessment of how suitable a task is for humans or AI (i.e., task appraisal). We show that delegation decisions closely aligned with task appraisal increase task performance. However, we also find that AI knowledge lowers future intentions to use AI, suggesting that AI knowledge is not strictly positive for human-AI collaboration. Our study contributes to HCI design guidelines with a new perspective on AI features, educating humans regarding general AI functioning and their own (human) performance and biases.},
booktitle = {Proceedings of the 2023 CHI Conference on Human Factors in Computing Systems},
articleno = {25},
numpages = {17},
keywords = {AI delegation, AI education, AI literacy, AI skill, Cognitive appraisal theory},
location = {Hamburg, Germany},
series = {CHI '23}
}

@inproceedings{wang2024tom,
author = {Wang, Qiaosi and Walsh, Sarah and Si, Mei and Kephart, Jeffrey and Weisz, Justin D. and Goel, Ashok K.},
title = {Theory of Mind in Human-AI Interaction},
year = {2024},
isbn = {9798400703317},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3613905.3636308},
doi = {10.1145/3613905.3636308},
abstract = {Theory of Mind (ToM), humans’ capability of attributing mental states such as intentions, goals, emotions, and beliefs to ourselves and others, has become a concept of great interest in human-AI interaction research. Given the fundamental role of ToM in human social interactions, many researchers have been working on methods and techniques to equip AI with an equivalent of human ToM capability to build highly socially intelligent AI. Another line of research on ToM in human-AI interaction seeks to understand people’s tendency to attribute mental states such as blame, emotions, and intentions to AI, along with the role that AI should play in the interaction (e.g. as a tool, partner, teacher, facilitator, and more) to align with peoples’ expectations and mental models. The goal of this line of work is to distill human-centered design implications to support the development of increasingly advanced AI systems. Together, these two research perspectives on ToM form an emerging paradigm of “Mutual Theory of Mind (MToM)” in human-AI interaction, where both the human and the AI each possess the ToM capability. This workshop aims to bring together different research perspectives on ToM in human-AI interaction by engaging with researchers from various disciplines including AI, HCI, Cognitive Science, Psychology, Robotics, and more to synthesize existing research perspectives, techniques, and knowledge on ToM in human-AI interaction, as well as envisioning and setting a research agenda for MToM in human-AI interaction.},
booktitle = {Extended Abstracts of the 2024 CHI Conference on Human Factors in Computing Systems},
articleno = {493},
numpages = {6},
keywords = {human-AI interaction, human-centered AI, mental model, mutual theory of mind, social intelligence, theory of mind},
location = {
},
series = {CHI EA '24}
}

@article{10.1007/s10458-009-9093-x,
author = {Si, Mei and Marsella, Stacy C. and Pynadath, David V.},
title = {Modeling appraisal in theory of mind reasoning},
year = {2010},
issue_date = {January   2010},
publisher = {Kluwer Academic Publishers},
address = {USA},
volume = {20},
number = {1},
issn = {1387-2532},
url = {https://doi.org/10.1007/s10458-009-9093-x},
doi = {10.1007/s10458-009-9093-x},
abstract = {Cognitive appraisal theories, which link human emotional experience to their interpretations of events happening in the environment, are leading approaches to model emotions. Cognitive appraisal theories have often been used both for simulating "real emotions" in virtual characters and for predicting the human user's emotional experience to facilitate human---computer interaction. In this work, we investigate the computational modeling of appraisal in a multi-agent decision-theoretic framework using Partially Observable Markov Decision Process-based (POMDP) agents. Domain-independent approaches are developed for five key appraisal dimensions (motivational relevance, motivation congruence, accountability, control and novelty). We also discuss how the modeling of theory of mind (recursive beliefs about self and others) is realized in the agents and is critical for simulating social emotions. Our model of appraisal is applied to three different scenarios to illustrate its usages. This work not only provides a solution for computationally modeling emotion in POMDP-based agents, but also illustrates the tight relationship between emotion and cognition--the appraisal dimensions are derived from the processes and information required for the agent's decision-making and belief maintenance processes, which suggests a uniform cognitive structure for emotion and cognition.},
journal = {Autonomous Agents and Multi-Agent Systems},
month = {jan},
pages = {14–31},
numpages = {18},
keywords = {Multi-agent system, Emotion, Decision-making, Appraisal}
}

@inproceedings{hiatt2011accommodating,
  title={Accommodating human variability in human-robot teams through theory of mind},
  author={Hiatt, Laura M and Harrison, Anthony M and Trafton, J Gregory},
  booktitle={Twenty-Second International Joint Conference on Artificial Intelligence},
  year={2011}
}

@article{meta2022human,
  title={Human-level play in the game of Diplomacy by combining language models with strategic reasoning},
  author={Meta Fundamental AI Research Diplomacy Team (FAIR)† and Bakhtin, Anton and Brown, Noam and Dinan, Emily and Farina, Gabriele and Flaherty, Colin and Fried, Daniel and Goff, Andrew and Gray, Jonathan and Hu, Hengyuan and others},
  journal={Science},
  volume={378},
  number={6624},
  pages={1067--1074},
  year={2022},
  publisher={American Association for the Advancement of Science}
}

@inproceedings{kenthapadi2024grounding,
  title={Grounding and Evaluation for Large Language Models: Practical Challenges and Lessons Learned (Survey)},
  author={Kenthapadi, Krishnaram and Sameki, Mehrnoosh and Taly, Ankur},
  booktitle={Proceedings of the 30th ACM SIGKDD Conference on Knowledge Discovery and Data Mining},
  pages={6523--6533},
  year={2024}
}

@article{yao2022webshop,
  title={Webshop: Towards scalable real-world web interaction with grounded language agents},
  author={Yao, Shunyu and Chen, Howard and Yang, John and Narasimhan, Karthik},
  journal={Advances in Neural Information Processing Systems},
  volume={35},
  pages={20744--20757},
  year={2022}
}

@article{10.1016/j.procs.2021.09.122,
author = {Dehkordi, Maryam Banitalebi and Mansy, Reda and Zaraki, Abolfazl and Singh, Arpit and Setchi, Rossitza},
title = {Explainability in Human-Robot Teaming},
year = {2021},
issue_date = {2021},
publisher = {Elsevier Science Publishers B. V.},
address = {NLD},
volume = {192},
number = {C},
issn = {1877-0509},
url = {https://doi.org/10.1016/j.procs.2021.09.122},
doi = {10.1016/j.procs.2021.09.122},
journal = {Procedia Comput. Sci.},
month = {jan},
pages = {3487–3496},
numpages = {10},
keywords = {trust, expectation, explanation, mental model, Human-robot teaming}
}

@article{albrecht2018autonomous,
  title={Autonomous agents modelling other agents: A comprehensive survey and open problems},
  author={Albrecht, Stefano V and Stone, Peter},
  journal={Artificial Intelligence},
  volume={258},
  pages={66--95},
  year={2018},
  publisher={Elsevier}
}

@article{guan2023efficient,
  title={Efficient Human-AI Coordination via Preparatory Language-based Convention},
  author={Guan, Cong and Zhang, Lichao and Fan, Chunpeng and Li, Yichen and Chen, Feng and Li, Lihe and Tian, Yunjia and Yuan, Lei and Yu, Yang},
  journal={arXiv preprint arXiv:2311.00416},
  year={2023}
}

@inproceedings{zhang2023fast,
  title={Fast teammate adaptation in the presence of sudden policy change},
  author={Zhang, Ziqian and Yuan, Lei and Li, Lihe and Xue, Ke and Jia, Chengxing and Guan, Cong and Qian, Chao and Yu, Yang},
  booktitle={Uncertainty in Artificial Intelligence},
  pages={2465--2476},
  year={2023},
  organization={PMLR}
}
@article{lindner2022humans,
  title={Humans are not boltzmann distributions: Challenges and opportunities for modelling human feedback and interaction in reinforcement learning},
  author={Lindner, David and El-Assady, Mennatallah},
  journal={arXiv preprint arXiv:2206.13316},
  year={2022}
}

@article{ma2022elign,
  title={Elign: Expectation alignment as a multi-agent intrinsic reward},
  author={Ma, Zixian and Wang, Rose and Li, Fei-Fei and Bernstein, Michael and Krishna, Ranjay},
  journal={Advances in Neural Information Processing Systems},
  volume={35},
  pages={8304--8317},
  year={2022}
}

@misc{wang2024zscevalevaluationtoolkitbenchmark,
      title={ZSC-Eval: An Evaluation Toolkit and Benchmark for Multi-agent Zero-shot Coordination}, 
      author={Xihuai Wang and Shao Zhang and Wenhao Zhang and Wentao Dong and Jingxiao Chen and Ying Wen and Weinan Zhang},
      year={2024},
      eprint={2310.05208},
      archivePrefix={arXiv},
      primaryClass={cs.AI},
      url={https://arxiv.org/abs/2310.05208}, 
}

@inproceedings{bara-etal-2021-mindcraft,
    title = "{M}ind{C}raft: Theory of Mind Modeling for Situated Dialogue in Collaborative Tasks",
    author = "Bara, Cristian-Paul  and
      CH-Wang, Sky  and
      Chai, Joyce",
    editor = "Moens, Marie-Francine  and
      Huang, Xuanjing  and
      Specia, Lucia  and
      Yih, Scott Wen-tau",
    booktitle = "Proceedings of the 2021 Conference on Empirical Methods in Natural Language Processing",
    month = nov,
    year = "2021",
    address = "Online and Punta Cana, Dominican Republic",
    publisher = "Association for Computational Linguistics",
    url = "https://aclanthology.org/2021.emnlp-main.85",
    doi = "10.18653/v1/2021.emnlp-main.85",
    pages = "1112--1125",
    abstract = "An ideal integration of autonomous agents in a human world implies that they are able to collaborate on human terms. In particular, theory of mind plays an important role in maintaining common ground during human collaboration and communication. To enable theory of mind modeling in situated interactions, we introduce a fine-grained dataset of collaborative tasks performed by pairs of human subjects in the 3D virtual blocks world of Minecraft. It provides information that captures partners{'} beliefs of the world and of each other as an interaction unfolds, bringing abundant opportunities to study human collaborative behaviors in situated language communication. As a first step towards our goal of developing embodied AI agents able to infer belief states of collaborative partners in situ, we build and present results on computational models for several theory of mind tasks.",
}

@inproceedings{wester2024theory,
  title={Theory of Mind and Self-Presentation in Human-LLM Interactions},
  author={Wester, Joel and Jacobsen, Rune M{\o}berg and de Jong, Sander and Als, Naja Kathrine Kollerup and Djern{\ae}s, Helena B{\o}jer and van Berkel, Niels},
  booktitle={Adjunct Proceedings of the ACM SIGCHI Conference on Human Factors in Computing Systems},
  year={2024}
}

@inproceedings{park2023generative,
  title={Generative agents: Interactive simulacra of human behavior},
  author={Park, Joon Sung and O'Brien, Joseph and Cai, Carrie Jun and Morris, Meredith Ringel and Liang, Percy and Bernstein, Michael S},
  booktitle={Proceedings of the 36th annual acm symposium on user interface software and technology},
  pages={1--22},
  year={2023}
}

@article{han2024llm,
  title={LLM-Personalize: Aligning LLM Planners with Human Preferences via Reinforced Self-Training for Housekeeping Robots},
  author={Han, Dongge and McInroe, Trevor and Jelley, Adam and Albrecht, Stefano V and Bell, Peter and Storkey, Amos},
  journal={arXiv preprint arXiv:2404.14285},
  year={2024}
}

@article{li2024llm,
  title={LLM-enhanced Scene Graph Learning for Household Rearrangement},
  author={Li, Wenhao and Yu, Zhiyuan and She, Qijin and Yu, Zhinan and Lan, Yuqing and Zhu, Chenyang and Hu, Ruizhen and Xu, Kai},
  journal={arXiv preprint arXiv:2408.12093},
  year={2024}
}

@article{ma2023laser,
  title={Laser: Llm agent with state-space exploration for web navigation},
  author={Ma, Kaixin and Zhang, Hongming and Wang, Hongwei and Pan, Xiaoman and Yu, Dong},
  journal={arXiv preprint arXiv:2309.08172},
  year={2023}
}

@article{strachan2024testing,
  title={Testing theory of mind in large language models and humans},
  author={Strachan, James WA and Albergo, Dalila and Borghini, Giulia and Pansardi, Oriana and Scaliti, Eugenio and Gupta, Saurabh and Saxena, Krati and Rufo, Alessandro and Panzeri, Stefano and Manzi, Guido and others},
  journal={Nature Human Behaviour},
  pages={1--11},
  year={2024},
  publisher={Nature Publishing Group UK London}
}

@article{feng2024extremely,
  title={An Extremely Data-efficient and Generative LLM-based Reinforcement Learning Agent for Recommenders},
  author={Feng, Shuang and Feng, Grace},
  journal={arXiv preprint arXiv:2408.16032},
  year={2024}
}

@article{yao2022react,
  title={React: Synergizing reasoning and acting in language models},
  author={Yao, Shunyu and Zhao, Jeffrey and Yu, Dian and Du, Nan and Shafran, Izhak and Narasimhan, Karthik and Cao, Yuan},
  journal={arXiv preprint arXiv:2210.03629},
  year={2022}
}

@article{faccio2023human,
  title={Human factors in cobot era: a review of modern production systems features},
  author={Faccio, Maurizio and Granata, Irene and Menini, Alberto and Milanese, Mattia and Rossato, Chiara and Bottin, Matteo and Minto, Riccardo and Pluchino, Patrik and Gamberini, Luciano and Boschetti, Giovanni and others},
  journal={Journal of Intelligent Manufacturing},
  volume={34},
  number={1},
  pages={85--106},
  year={2023},
  publisher={Springer}
}

@inproceedings{devin2016implemented,
  title={An implemented theory of mind to improve human-robot shared plans execution},
  author={Devin, Sandra and Alami, Rachid},
  booktitle={2016 11th ACM/IEEE International Conference on Human-Robot Interaction (HRI)},
  pages={319--326},
  year={2016},
  organization={IEEE}
}

@article{steyvers2022bayesian,
  title={Bayesian modeling of human--AI complementarity},
  author={Steyvers, Mark and Tejeda, Heliodoro and Kerrigan, Gavin and Smyth, Padhraic},
  journal={Proceedings of the National Academy of Sciences},
  volume={119},
  number={11},
  pages={e2111547119},
  year={2022},
  publisher={National Acad Sciences}
}

@article{benninghoff2013theory,
  title={Theory of mind in human-robot-communication: Appreciated or not?},
  author={Benninghoff, Brenda and Kulms, Philipp and Hoffmann, Laura and Kr{\"a}mer, Nicole C},
  journal={Kognitive Systeme},
  volume={2013},
  number={1},
  year={2013}
}

@article{li2024tackling,
  title={Tackling cooperative incompatibility for zero-shot human-ai coordination},
  author={Li, Yang and Zhang, Shao and Sun, Jichen and Zhang, Wenhao and Du, Yali and Wen, Ying and Wang, Xinbing and Pan, Wei},
  journal={Journal of Artificial Intelligence Research},
  volume={80},
  pages={1139--1185},
  year={2024}
}


@inproceedings{lu2021more,
  title={More kawaii than a real-person live streamer: understanding how the otaku community engages with and perceives virtual YouTubers},
  author={Lu, Zhicong and Shen, Chenxinran and Li, Jiannan and Shen, Hong and Wigdor, Daniel},
  booktitle={Proceedings of the 2021 CHI Conference on Human Factors in Computing Systems},
  pages={1--14},
  year={2021}
}

@article{fleming1990multiple,
  title={Multiple audience problem: A strategic communication perspective on social perception.},
  author={Fleming, John H and Darley, John M and Hilton, James L and Kojetin, Brian A},
  journal={Journal of personality and social psychology},
  volume={58},
  number={4},
  pages={593},
  year={1990},
  publisher={American Psychological Association}
}



@article{lea1992paralanguage,
  title={Paralanguage and social perception in computer-mediated communication},
  author={Lea, Martin and Spears, Russell},
  journal={Journal of Organizational Computing and Electronic Commerce},
  volume={2},
  number={3-4},
  pages={321--341},
  year={1992},
  publisher={Taylor \& Francis}
}

@inproceedings{10.1145/3613904.3642860,
author = {Shen, Chenxinran and Xu, Yan and Lc, Ray and Lu, Zhicong},
title = {Seeking Soulmate via Voice: Understanding Promises and Challenges of Online Synchronized Voice-Based Mobile Dating},
year = {2024},
isbn = {9798400703300},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3613904.3642860},
doi = {10.1145/3613904.3642860},
abstract = {Online dating has become a popular way for individuals to connect with potential romantic partners. Many dating apps use personal profiles that include a headshot and self-description, allowing users to present themselves and search for compatible matches. However, this traditional model often has limitations. In this study, we explore a non-traditional voice-based dating app called “Soul”. Unlike traditional platforms that rely heavily on profile information, Soul facilitates user interactions through voice-based communication. We conducted semi-structured interviews with 18 dedicated Soul users to investigate how they engage with the platform and perceive themselves and others in this unique dating environment. Our findings indicate that the role of voice as a moderator influences impression management and shapes perceptions between the sender and the receiver of the voice. Additionally, the synchronous voice-based and community-based dating model offers benefits to users in the Chinese cultural context. Our study contributes to understanding the affordances introduced by voice-based interactions in online dating in China.},
booktitle = {Proceedings of the CHI Conference on Human Factors in Computing Systems},
articleno = {921},
numpages = {14},
keywords = {Online dating, affordance, online communities, social media, voice},
location = {Honolulu, HI, USA},
series = {CHI '24}
}

@INPROCEEDINGS{7497782,
  author={Demir, Mustafa and McNeese, Nathan J. and Cooke, Nancy J.},
  booktitle={2016 IEEE International Multi-Disciplinary Conference on Cognitive Methods in Situation Awareness and Decision Support (CogSIMA)}, 
  title={Team communication behaviors of the human-automation teaming}, 
  year={2016},
  volume={},
  number={},
  pages={28-34},
  keywords={Automation;Teamwork;Planning;Technological innovation;Aircraft;Context;communication behaviors;human-automation teaming;synthetic teammate;team coordination},
  doi={10.1109/COGSIMA.2016.7497782}}


@article{doi:10.1177/15553434211017354,
author = {Nathan J. McNeese and Mustafa Demir and Nancy J. Cooke and Manrong She},
title ={Team Situation Awareness and Conflict: A Study of Human–Machine Teaming},

journal = {Journal of Cognitive Engineering and Decision Making},
volume = {15},
number = {2-3},
pages = {83-96},
year = {2021},
doi = {10.1177/15553434211017354},

URL = { 
    
        https://doi.org/10.1177/15553434211017354
    
    

},
eprint = { 
    
        https://doi.org/10.1177/15553434211017354
    
    

}
,
    abstract = { This article focuses on two fundamental human–human teamwork behaviors and seeks to understand them better in human–machine teams. Specifically, team situation awareness (TSA) and team conflict are examined in human–machine teams. There is a significant need to identify how TSA and team conflict occur during human–machine teaming, in addition to how they impact each other. In this work, we present an experiment aimed at understanding TSA and team conflict in the context of human–machine teaming in a remotely piloted aircraft system (RPAS). Three conditions were tested: (1) control: teams consisted of all humans; (2) synthetic: teams consisted of the pilot role being occupied by a computational agent based on ACT-R architecture that employed AI capabilities, with all other team roles being humans; and (3) experimenter: an experimenter playing the role of the pilot as a highly effective computational agent, with the other roles being humans. The results indicate that TSA improved over time in synthetic teams, improved and then stabilized over time in experimenter teams, and did not improve in control teams. In addition, results show that control teams had the most team conflict. Finally, in the control condition, team conflict negatively impacts TSA. }
}

@article{doi:10.1080/00913367.2002.10673674,
author = {Sally J. McMillan and Jang-Sun Hwang},
title = {Measures of Perceived Interactivity: An Exploration of the Role of Direction of Communication, User Control, and Time in Shaping Perceptions of Interactivity},
journal = {Journal of Advertising},
volume = {31},
number = {3},
pages = {29--42},
year = {2002},
publisher = {Routledge},
doi = {10.1080/00913367.2002.10673674},


URL = { 
    
        https://doi.org/10.1080/00913367.2002.10673674
    
    

},
eprint = { 
    
        https://doi.org/10.1080/00913367.2002.10673674
    
    

}

}





@article{10.1145/3492832,
author = {Schelble, Beau G. and Flathmann, Christopher and McNeese, Nathan J. and Freeman, Guo and Mallick, Rohit},
title = {Let's Think Together! Assessing Shared Mental Models, Performance, and Trust in Human-Agent Teams},
year = {2022},
issue_date = {January 2022},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {6},
number = {GROUP},
url = {https://doi.org/10.1145/3492832},
doi = {10.1145/3492832},
abstract = {An emerging research agenda in Computer-Supported Cooperative Work focuses on human-agent teaming and AI agent's roles and effects in modern teamwork. In particular, one understudied key question centers around the construct of team cognition within human-agent teams. This study explores the unique nature of team dynamics in human-agent teams compared to human-human teams and the impact of team composition on perceived team cognition, team performance, and trust. In doing so, a mixed-method approach, including three team composition conditions (all human, human-human-agent, human-agent-agent), completed the team simulation NeoCITIES and completed shared mental model, trust, and perception measures. Results found that human-agent teams are similar to human-only teams in the iterative development of team cognition and the importance of communication to accelerating its development; however, human-agent teams are different in that action-related communication and explicitly shared goals are beneficial to developing team cognition. Additionally, human-agent teams trusted agent teammates less when working with only agents and no other humans, perceived less team cognition with agent teammates than human ones, and had significantly inconsistent levels of team mental model similarity when compared to human-only teams. This study contributes to Computer-Supported Cooperative Work in three significant ways: 1) advancing the existing research on human-agent teaming by shedding light on the relationship between humans and agents operating in collaborative environments, 2) characterizing team cognition development in human-agent teams; and 3) advancing real-world design recommendations that promote human-centered teaming agents and better integrate the two.},
journal = {Proc. ACM Hum.-Comput. Interact.},
month = {jan},
articleno = {13},
numpages = {29},
keywords = {trust, teaming, team cognition, human-autonomy teaming, artificial intelligence}
}

@article{doi:10.1177/14614440022225751,
author = {EDWARD J. DOWNES and SALLY J. McMILLAN},
title ={Defining Interactivity: A Qualitative Identification of Key Dimensions},

journal = {New Media \& Society},
volume = {2},
number = {2},
pages = {157-179},
year = {2000},
doi = {10.1177/14614440022225751},

URL = { 
    
        https://doi.org/10.1177/14614440022225751
    
    

},
eprint = { 
    
        https://doi.org/10.1177/14614440022225751
    
    

}
,
    abstract = { The literature on interactivity includes many assumptions and some definitions but few tools for operationalizing the concept of interactivity in computer-mediated environments. This article takes an early step in filling that gap. In-depth interviews with 10 individuals who work and teach in the field of interactive communication led to a conceptual definition of interactivity based on six dimensions: direction of communication, time flexibility, sense of place, level of control, responsiveness, and perceived purpose of communication. Suggestions are made for applying these dimensions to multiple forms of computer-mediated communication. Future research should empirically test the existence and application of these dimensions. }
}

@article{oliver2019communication,
  title={Communication and trust: rethinking the way construction industry professionals and software vendors utilise computer communication mediums},
  author={Oliver, Stephen},
  journal={Visualization in Engineering},
  volume={7},
  number={1},
  pages={1},
  year={2019},
  publisher={Springer}
}


@inproceedings{lee2012loosely,
  title={Loosely formed patient care teams: communication challenges and technology design},
  author={Lee, Soyoung and Tang, Charlotte and Park, Sun Young and Chen, Yunan},
  booktitle={Proceedings of the ACM 2012 conference on computer supported cooperative work},
  pages={867--876},
  year={2012}
}

@inproceedings{mcneese2015articulating,
  title={Articulating and understanding the development of a team mental model in a distributed medium},
  author={McNeese, Nathan J and Reddy, Madhu C},
  booktitle={Proceedings of the Human Factors and Ergonomics Society Annual Meeting},
  volume={59},
  number={1},
  pages={240--244},
  year={2015},
  organization={SAGE Publications Sage CA: Los Angeles, CA}
}

@article{sharma2024would,
  title={Why Would You Suggest That? Human Trust in Language Model Responses},
  author={Sharma, Manasi and Siu, Ho Chit and Paleja, Rohan and Pe{\~n}a, Jaime D},
  journal={arXiv preprint arXiv:2406.02018},
  year={2024}
}

@inproceedings{ijcai2021p0466,
  title     = {Model-based Multi-agent Policy Optimization with Adaptive Opponent-wise Rollouts},
  author    = {Zhang, Weinan and Wang, Xihuai and Shen, Jian and Zhou, Ming},
  booktitle = {Proceedings of the Thirtieth International Joint Conference on
               Artificial Intelligence, {IJCAI-21}},
  publisher = {International Joint Conferences on Artificial Intelligence Organization},
  editor    = {Zhi-Hua Zhou},
  pages     = {3384--3391},
  year      = {2021},
  month     = {8},
  note      = {Main Track},
  doi       = {10.24963/ijcai.2021/466},
  url       = {https://doi.org/10.24963/ijcai.2021/466},
}

@inproceedings{peters2006designing,
  title={Designing synthetic memory systems for supporting autonomous embodied agent behaviour},
  author={Peters, Christopher},
  booktitle={ROMAN 2006-The 15th IEEE International Symposium on Robot and Human Interactive Communication},
  pages={14--19},
  year={2006},
  organization={IEEE}
}

@INPROCEEDINGS{9889428,
  author={Oralbayeva, Nurziya and Shakerimov, Aidar and Sarmonov, Shamil and Kantoreyeva, Kanagat and Dadebayeva, Fatima and Serkali, Nuray and Sandygulova, Anara},
  booktitle={2022 17th ACM/IEEE International Conference on Human-Robot Interaction (HRI)}, 
  title={K-Qbot: Language Learning Chatbot Based on Reinforcement Learning}, 
  year={2022},
  volume={},
  number={},
  pages={963-967},
  keywords={Avatars;Education;Reinforcement learning;Chatbots;Robots;Reinforcement Learning;chatbot;language learning;alphabet learning;Kazakh language},
  doi={10.1109/HRI53351.2022.9889428}}


@article{bard2020hanabi,
  title={The hanabi challenge: A new frontier for ai research},
  author={Bard, Nolan and Foerster, Jakob N and Chandar, Sarath and Burch, Neil and Lanctot, Marc and Song, H Francis and Parisotto, Emilio and Dumoulin, Vincent and Moitra, Subhodeep and Hughes, Edward and others},
  journal={Artificial Intelligence},
  volume={280},
  pages={103216},
  year={2020},
  publisher={Elsevier}
}

@article{demir2017team,
  title={Team situation awareness within the context of human-autonomy teaming},
  author={Demir, Mustafa and McNeese, Nathan J and Cooke, Nancy J},
  journal={Cognitive Systems Research},
  volume={46},
  pages={3--12},
  year={2017},
  publisher={Elsevier}
}

@article{jiang2023situation,
  title={A situation awareness perspective on human-AI interaction: Tensions and opportunities},
  author={Jiang, Jinglu and Karran, Alexander J and Coursaris, Constantinos K and L{\'e}ger, Pierre-Majorique and Beringer, Joerg},
  journal={International Journal of Human--Computer Interaction},
  volume={39},
  number={9},
  pages={1789--1806},
  year={2023},
  publisher={Taylor \& Francis}
}

@article{10.1145/3534561,
author = {Inkpen, Kori and Chappidi, Shreya and Mallari, Keri and Nushi, Besmira and Ramesh, Divya and Michelucci, Pietro and Mandava, Vani and Vep\v{r}ek, Libu\v{s}e Hannah and Quinn, Gabrielle},
title = {Advancing Human-AI Complementarity: The Impact of User Expertise and Algorithmic Tuning on Joint Decision Making},
year = {2023},
issue_date = {October 2023},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {30},
number = {5},
issn = {1073-0516},
url = {https://doi.org/10.1145/3534561},
doi = {10.1145/3534561},
abstract = {Human-AI collaboration for decision-making strives to achieve team performance that exceeds the performance of humans or AI alone. However, many factors can impact success of Human-AI teams, including a user’s domain expertise, mental models of an AI system, trust in recommendations, and more. This article reports on a study that examines users’ interactions with three simulated algorithmic models, all with equivalent accuracy rates but each tuned differently in terms of true positive and true negative rates. Our study examined user performance in a non-trivial blood vessel labeling task where participants indicated whether a given blood vessel was flowing or stalled. Users completed 140 trials across multiple stages, first without an AI and then with recommendations from an AI-Assistant. Although all users had prior experience with the task, their levels of proficiency varied widely.Our results demonstrated that while recommendations from an AI-Assistant can aid in users’ decision making, several underlying factors, including user base expertise and complementary human-AI tuning, significantly impact the overall team performance. First, users’ base performance matters, particularly in comparison to the performance level of the AI. Novice users improved, but not to the accuracy level of the AI. Highly proficient users were generally able to discern when they should follow the AI recommendation and typically maintained or improved their performance. Mid-performers, who had a similar level of accuracy to the AI, were most variable in terms of whether the AI recommendations helped or hurt their performance. Second, tuning an AI algorithm to complement users’ strengths and weaknesses also significantly impacted users’ performance. For example, users in our study were better at detecting flowing blood vessels, so when the AI was tuned to reduce false negatives (at the expense of increasing false positives), users were able to reject those recommendations more easily and improve in accuracy. Finally, users’ perception of the AI’s performance relative to their own performance had an impact on whether users’ accuracy improved when given recommendations from the AI. Overall, this work reveals important insights on the complex interplay of factors influencing Human-AI collaboration and provides recommendations on how to design and tune AI algorithms to complement users in decision-making tasks.},
journal = {ACM Trans. Comput.-Hum. Interact.},
month = {sep},
articleno = {71},
numpages = {29},
keywords = {Human-AI collaboration, Human-AI performance, human-centered AI, citizen science}
}

@inproceedings{christoforou2020overview,
  title={An overview of assistive robotics and technologies for elderly care},
  author={Christoforou, Eftychios G and Panayides, Andreas S and Avgousti, Sotiris and Masouras, Panicos and Pattichis, Constantinos S},
  booktitle={XV Mediterranean Conference on Medical and Biological Engineering and Computing--MEDICON 2019: Proceedings of MEDICON 2019, September 26-28, 2019, Coimbra, Portugal},
  pages={971--976},
  year={2020},
  organization={Springer}
}

@inproceedings{10.1145/3544548.3581340,
author = {Kim, Taenyun and Molina, Maria D. and Rheu, Minjin (MJ) and Zhan, Emily S. and Peng, Wei},
title = {One AI Does Not Fit All: A Cluster Analysis of the Laypeople’s Perception of AI Roles},
year = {2023},
isbn = {9781450394215},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3544548.3581340},
doi = {10.1145/3544548.3581340},
abstract = {Artificial intelligence (AI) applications have become an integral part of our society. However, studying AI as one entity or studying idiosyncratic applications separately both have limitations. Thus, this study used computational methods to categorize ten different AI roles prevalent in our everyday life and compared laypeople’s perceptions of them using online survey data (N = 727). Based on theoretical factors related to the fundamental nature of AI, the principal component analysis revealed two dimensions that categorize AI: human involvement and AI autonomy. K-means clustering identified four AI role clusters: tools (low in both dimensions), servants (high human involvement and low AI autonomy), assistants (low human involvement and high AI autonomy), and mediators (high in both dimensions). Multivariate analyses of covariances revealed that people assessed AI mediators the most and AI tools the least favorably. Demographics also influenced laypeople’s assessments of AI. The implications of these results are discussed.},
booktitle = {Proceedings of the 2023 CHI Conference on Human Factors in Computing Systems},
articleno = {29},
numpages = {20},
keywords = {AI Autonomy, Artificial Intelligence (AI), Attitude, Clustering Analysis, Credibility, Human Involvement, Human-AI Interaction (HAII), Social Approval},
location = {Hamburg, Germany},
series = {CHI '23}
}

@inproceedings{10.1145/3597512.3597514,
author = {McKenna, Peter E and Romeo, Marta and Pimentel, Jhielson and Diab, Mohammed and Moujahid, Meriam and Hastie, Helen and Demiris, Yiannis},
title = {Theory of Mind and Trust in Human-Robot Navigation},
year = {2023},
isbn = {9798400707346},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3597512.3597514},
doi = {10.1145/3597512.3597514},
abstract = {In human-robot interaction, trust is affected by human, robot, and environmental factors. In the proposed research, we consider each of these factors, by focusing on the contribution of robot theory of mind (ToM), human visual perspective taking (a concept related to ToM), and environmental complexity, to the development and maintenance of human-robot trust. To do so, our experiment combines a psychological assessment of visual perspective taking (the Director Task), with a trust-based robot navigation task. Using the AREA model of Responsible Research and Innovation (RRI), we also highlight the implications of our experiment, in the context of trustworthy robotics and human-robot collaboration. We round off the article with a theoretical and research development synopses related to robot ToM and trust, and future work to be conducted in this area.},
booktitle = {Proceedings of the First International Symposium on Trustworthy Autonomous Systems},
articleno = {29},
numpages = {5},
keywords = {human-robot interaction, theory of mind, trust, visual perspective taking},
location = {Edinburgh, United Kingdom},
series = {TAS '23}
}

@article{sumers2023cognitive,
  title={Cognitive architectures for language agents},
  author={Sumers, Theodore R and Yao, Shunyu and Narasimhan, Karthik and Griffiths, Thomas L},
  journal={arXiv preprint arXiv:2309.02427},
  year={2023}
}

@article{jennings1998roadmap,
  title={A roadmap of agent research and development},
  author={Jennings, Nicholas R and Sycara, Katia and Wooldridge, Michael},
  journal={Autonomous agents and multi-agent systems},
  volume={1},
  pages={7--38},
  year={1998},
  publisher={Springer}
}

@article{wei2022chain,
  title={Chain-of-thought prompting elicits reasoning in large language models},
  author={Wei, Jason and Wang, Xuezhi and Schuurmans, Dale and Bosma, Maarten and Xia, Fei and Chi, Ed and Le, Quoc V and Zhou, Denny and others},
  journal={Advances in neural information processing systems},
  volume={35},
  pages={24824--24837},
  year={2022}
}

@inproceedings{gong-etal-2024-mindagent,
    title = "{M}ind{A}gent: Emergent Gaming Interaction",
    author = "Gong, Ran  and
      Huang, Qiuyuan  and
      Ma, Xiaojian  and
      Noda, Yusuke  and
      Durante, Zane  and
      Zheng, Zilong  and
      Terzopoulos, Demetri  and
      Fei-Fei, Li  and
      Gao, Jianfeng  and
      Vo, Hoi",
    editor = "Duh, Kevin  and
      Gomez, Helena  and
      Bethard, Steven",
    booktitle = "Findings of the Association for Computational Linguistics: NAACL 2024",
    month = jun,
    year = "2024",
    address = "Mexico City, Mexico",
    publisher = "Association for Computational Linguistics",
    url = "https://aclanthology.org/2024.findings-naacl.200",
    doi = "10.18653/v1/2024.findings-naacl.200",
    pages = "3154--3183",
    abstract = "Large Foundation Models (LFMs) can perform complex scheduling in a multi-agent system and can coordinate agents to complete sophisticated tasks that require extensive collaboration.However, despite the introduction of numerous gaming frameworks, the community lacks adequate benchmarks that support the implementation of a general multi-agent infrastructure encompassing collaboration between LFMs and human-NPCs. We propose a novel infrastructure{---}Mindagent{---}for evaluating planning and coordination capabilities in the context of gaming interaction. In particular, our infrastructure leverages an existing gaming framework to (i) act as the coordinator for a multi-agent system, (ii) collaborate with human players via instructions, and (iii) enable in-context learning based on few-shot prompting with feedback.Furthermore, we introduce {``}Cuisineworld{''}, a new gaming scenario and its related benchmark that supervises multiple agents playing the game simultaneously and measures multi-agent collaboration efficiency. We have conducted comprehensive evaluations with a new auto-metric Collaboration Score: CoS for assessing the collaboration efficiency. Finally, Mindagent can be deployed in real-world gaming scenarios in a customized VR version of Cuisineworld and adapted in the {``}Minecraft{''} domain. Our work involving LFMs within our new infrastructure for general-purpose scheduling and coordination can elucidate how such skills may be obtained by learning from large language corpora.",
}

@inproceedings{
wen2018probabilistic,
title={Probabilistic Recursive Reasoning for Multi-Agent Reinforcement Learning},
author={Ying Wen and Yaodong Yang and Rui Luo and Jun Wang and Wei Pan},
booktitle={International Conference on Learning Representations},
year={2019},
url={https://openreview.net/forum?id=rkl6As0cF7},
}

@inproceedings{10.1145/3544548.3580983,
author = {He, Ziyao and Song, Yunpeng and Zhou, Shurui and Cai, Zhongmin},
title = {Interaction of Thoughts: Towards Mediating Task Assignment in Human-AI Cooperation with a Capability-Aware Shared Mental Model},
year = {2023},
isbn = {9781450394215},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3544548.3580983},
doi = {10.1145/3544548.3580983},
abstract = {The existing work on task assignment of human-AI cooperation did not consider the differences between individual team members regarding their capabilities, leading to sub-optimal task completion results. In this work, we propose a capability-aware shared mental model (CASMM) with the components of task grouping and negotiation, which utilize tuples to break down tasks into sets of scenarios relating to difficulties and then dynamically merge the task grouping ideas raised by human and AI through negotiation. We implement a prototype system and a 3-phase user study for the proof of concept via an image labeling task. The result shows building CASMM boosts the accuracy and time efficiency significantly through forming the task assignment close to real capabilities within few iterations. It helps users better understand the capability of AI and themselves. Our method has the potential to generalize to other scenarios such as medical diagnoses and automatic driving in facilitating better human-AI cooperation.},
booktitle = {Proceedings of the 2023 CHI Conference on Human Factors in Computing Systems},
articleno = {353},
numpages = {18},
keywords = {human-AI cooperation, shared mental model, task assignment},
location = {Hamburg, Germany},
series = {CHI '23}
}

@inproceedings{gero2020mental,
  title={Mental models of AI agents in a cooperative game setting},
  author={Gero, Katy Ilonka and Ashktorab, Zahra and Dugan, Casey and Pan, Qian and Johnson, James and Geyer, Werner and Ruiz, Maria and Miller, Sarah and Millen, David R and Campbell, Murray and others},
  booktitle={Proceedings of the 2020 chi conference on human factors in computing systems},
  pages={1--12},
  year={2020}
}
@article{rao2024collaborative,
  title={Collaborative Quest Completion with LLM-driven Non-Player Characters in Minecraft},
  author={Rao, Sudha and Xu, Weijia and Xu, Michael and Leandro, Jorge and Lobb, Ken and DesGarennes, Gabriel and Brockett, Chris and Dolan, Bill},
  journal={arXiv preprint arXiv:2407.03460},
  year={2024}
}

@inproceedings{cooke2020framework,
  title={A framework for human-autonomy team research},
  author={Cooke, Nancy and Demir, Mustafa and Huang, Lixiao},
  booktitle={Engineering Psychology and Cognitive Ergonomics. Cognition and Design: 17th International Conference, EPCE 2020, Held as Part of the 22nd HCI International Conference, HCII 2020, Copenhagen, Denmark, July 19--24, 2020, Proceedings, Part II 22},
  pages={134--146},
  year={2020},
  organization={Springer}
}

@article{chan2024human,
  title={Human and LLM-Based Voice Assistant Interaction: An Analytical Framework for User Verbal and Nonverbal Behaviors},
  author={Chan, Szeyi and Fu, Shihan and Li, Jiachen and Yao, Bingsheng and Desai, Smit and Prpa, Mirjana and Wang, Dakuo},
  journal={arXiv preprint arXiv:2408.16465},
  year={2024}
}

@inproceedings{Kilgore2014IncreasingTT,
  title={Increasing the Transparency of Unmanned Systems: Applications of Ecological Interface Design},
  author={Ryan M. Kilgore and Martin Voshell},
  booktitle={Interacci{\'o}n},
  year={2014},
  url={https://api.semanticscholar.org/CorpusID:31347319}
}

@article{jakobson1972verbal,
  title={Verbal communication},
  author={Jakobson, Roman},
  journal={Scientific American},
  volume={227},
  number={3},
  pages={72--81},
  year={1972},
  publisher={JSTOR}
}

@article{argyle1972non,
  title={Non-verbal communication in human social interaction},
  author={Argyle, Michael},
  journal={Non-verbal communication},
  volume={2},
  number={1},
  year={1972},
  publisher={Cambridge}
}

@book{mehrabian2017nonverbal,
  title={Nonverbal communication},
  author={Mehrabian, Albert},
  year={2017},
  publisher={Routledge}
}

@book{key1980relationship,
  title={The relationship of verbal and nonverbal communication},
  author={Key, Mary Ritchie and Key, Mary Ritchie},
  year={1980},
  publisher={Mouton The Hague}
}
@INPROCEEDINGS{10611018,
  author={Chen, Long and Sinavski, Oleg and Hünermann, Jan and Karnsund, Alice and Willmott, Andrew James and Birch, Danny and Maund, Daniel and Shotton, Jamie},
  booktitle={2024 IEEE International Conference on Robotics and Automation (ICRA)}, 
  title={Driving with LLMs: Fusing Object-Level Vector Modality for Explainable Autonomous Driving}, 
  year={2024},
  volume={},
  number={},
  pages={14093-14100},
  keywords={Measurement;Large language models;Decision making;Cloning;Quality control;Benchmark testing;Vectors},
  doi={10.1109/ICRA57147.2024.10611018}}


@ARTICLE{10297415,
  author={Cui, Yaodong and Huang, Shucheng and Zhong, Jiaming and Liu, Zhenan and Wang, Yutong and Sun, Chen and Li, Bai and Wang, Xiao and Khajepour, Amir},
  journal={IEEE Transactions on Intelligent Vehicles}, 
  title={DriveLLM: Charting the Path Toward Full Autonomous Driving With Large Language Models}, 
  year={2024},
  volume={9},
  number={1},
  pages={1450-1464},
  keywords={Decision making;Cognition;Autonomous vehicles;Task analysis;Roads;Real-time systems;Training;Autonomous driving;computer vision;decision-making;large language models},
  doi={10.1109/TIV.2023.3327715}}


@article{wang2022mutual,
  title={Mutual theory of mind for human-ai communication},
  author={Wang, Qiaosi and Goel, Ashok K},
  journal={arXiv preprint arXiv:2210.03842},
  year={2022}
}

@article{beer2014toward,
  title={Toward a framework for levels of robot autonomy in human-robot interaction},
  author={Beer, Jenay M and Fisk, Arthur D and Rogers, Wendy A},
  journal={Journal of human-robot interaction},
  volume={3},
  number={2},
  pages={74},
  year={2014},
  publisher={NIH Public Access}
}

@inproceedings{liang2019implicit,
  title={Implicit communication of actionable information in human-ai teams},
  author={Liang, Claire and Proft, Julia and Andersen, Erik and Knepper, Ross A},
  booktitle={Proceedings of the 2019 CHI conference on human factors in computing systems},
  pages={1--13},
  year={2019}
}

@inproceedings{bansal2019beyond,
  title={Beyond accuracy: The role of mental models in human-AI team performance},
  author={Bansal, Gagan and Nushi, Besmira and Kamar, Ece and Lasecki, Walter S and Weld, Daniel S and Horvitz, Eric},
  booktitle={Proceedings of the AAAI conference on human computation and crowdsourcing},
  volume={7},
  pages={2--11},
  year={2019}
}

@book{carruthers1996theories,
  title={Theories of theories of mind},
  author={Carruthers, Peter and Smith, Peter K},
  year={1996},
  publisher={Cambridge university press}
}

@book{baron1997mindblindness,
  title={Mindblindness: An essay on autism and theory of mind},
  author={Baron-Cohen, Simon},
  year={1997},
  publisher={MIT press}
}


@article{10.1016/j.chb.2019.04.001,
author = {Shank, Daniel B. and Graves, Christopher and Gott, Alexander and Gamez, Patrick and Rodriguez, Sophia},
title = {Feeling our way to machine minds: People's emotions when perceiving mind in artificial intelligence},
year = {2019},
issue_date = {Sep 2019},
publisher = {Elsevier Science Publishers B. V.},
address = {NLD},
volume = {98},
number = {C},
issn = {0747-5632},
url = {https://doi.org/10.1016/j.chb.2019.04.001},
doi = {10.1016/j.chb.2019.04.001},
journal = {Comput. Hum. Behav.},
month = {sep},
pages = {256–266},
numpages = {11},
keywords = {Emotions, Artificial intelligence, Mind, Mind perception, Algorithms}
}

@inproceedings{wang2021mtom,
author = {Wang, Qiaosi and Saha, Koustuv and Gregori, Eric and Joyner, David and Goel, Ashok},
title = {Towards Mutual Theory of Mind in Human-AI Interaction: How Language Reflects What Students Perceive About a Virtual Teaching Assistant},
year = {2021},
isbn = {9781450380966},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3411764.3445645},
doi = {10.1145/3411764.3445645},
abstract = {Building conversational agents that can conduct natural and prolonged conversations has been a major technical and design challenge, especially for community-facing conversational agents. We posit Mutual Theory of Mind as a theoretical framework to design for natural long-term human-AI interactions. From this perspective, we explore a community’s perception of a question-answering conversational agent through self-reported surveys and computational linguistic approach in the context of online education. We first examine long-term temporal changes in students’ perception of Jill Watson (JW), a virtual teaching assistant deployed in an online class discussion forum. We then explore the feasibility of inferring students’ perceptions of JW through linguistic features extracted from student-JW dialogues. We find that students’ perception of JW’s anthropomorphism and intelligence changed significantly over time. Regression analyses reveal that linguistic verbosity, readability, sentiment, diversity, and adaptability reflect student perception of JW. We discuss implications for building adaptive community-facing conversational agents as long-term companions and designing towards Mutual Theory of Mind in human-AI interaction.},
booktitle = {Proceedings of the 2021 CHI Conference on Human Factors in Computing Systems},
articleno = {384},
numpages = {14},
keywords = {theory of mind, online education, online community, language analysis, human-AI interaction, conversational agent},
location = {Yokohama, Japan},
series = {CHI '21}
}


@book{mooney1993bootstrapping,
  title={Bootstrapping: A nonparametric approach to statistical inference},
  author={Mooney, Christopher Z and Duval, Robert D and Duvall, Robert},
  number={95},
  year={1993},
  publisher={sage}
}

@inproceedings{vildan2024auto,
author = {Salikutluk, Vildan and Sch\"{o}pper, Janik and Herbert, Franziska and Scheuermann, Katrin and Frodl, Eric and Balfanz, Dirk and J\"{a}kel, Frank and Koert, Dorothea},
title = {An Evaluation of Situational Autonomy for Human-AI Collaboration in a Shared Workspace Setting},
year = {2024},
isbn = {9798400703300},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3613904.3642564},
doi = {10.1145/3613904.3642564},
abstract = {Designing interactions for human-AI teams (HATs) can be challenging due to an AI agent’s potential autonomy. Previous work suggests that higher autonomy does not always improve team performance, and situation-dependent autonomy adaptation might be beneficial. However, there is a lack of systematic empirical evaluations of such autonomy adaptation in human-AI interaction. Therefore, we propose a cooperative task in a simulated shared workspace to investigate effects of fixed levels of AI autonomy and situation-dependent autonomy adaptation on team performance and user satisfaction. We derive adaptation rules for AI autonomy from previous work and a pilot study. We implement these rule for our main experiment and find that team performance was best when humans collaborated with an agent adjusting its autonomy based on the situation. Additionally, users rated this agent highest in terms of perceived intelligence. From these results, we discuss the influence of varying autonomy degrees on HATs in shared workspaces.},
booktitle = {Proceedings of the CHI Conference on Human Factors in Computing Systems},
articleno = {300},
numpages = {17},
keywords = {AI Autonomy, Human-AI Interaction, Shared Workspace},
location = {Honolulu, HI, USA},
series = {CHI '24}
}

@article{zhang2023comm,
author = {Zhang, Rui and Duan, Wen and Flathmann, Christopher and McNeese, Nathan and Freeman, Guo and Williams, Alyssa},
title = {Investigating AI Teammate Communication Strategies and Their Impact in Human-AI Teams for Effective Teamwork},
year = {2023},
issue_date = {October 2023},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {7},
number = {CSCW2},
url = {https://doi.org/10.1145/3610072},
doi = {10.1145/3610072},
abstract = {Recently, AI is integrating into teams to collaborate with humans as a teammate with the goal of achieving unprecedented team outcomes. Much of the coordination between humans and AI teammates relies on human-AI communication, which is challenging due to AI's limitations on natural language communication. Thus, it is essential to identify and develop effective communication strategies for AI teammates in human-AI teams to facilitate the coordination process. Through interviews with 60 participants who collaborated with an AI teammate in a multiplayer online game, in this paper, we explore communication strategies that humans expect AI teammates to apply to support human-AI coordination and collaboration in dyadic teaming environments, and how the AI teammate's communication can impact teaming processes. Our findings highlight four communication strategies AI teammates should apply to support their coordination with humans in dyadic teaming environments. We also find that AI teammates' proactive communication with humans could facilitate the development of human trust and situation awareness, whereas AI lacking such proactive communication is often not perceived as a teammate. Our study extends the current CSCW/HCI research on human-AI communication in teaming environments by shedding light on how communication should be structured in dyadic human-AI teams for effective and smooth collaboration.},
journal = {Proc. ACM Hum.-Comput. Interact.},
month = {oct},
articleno = {281},
numpages = {31},
keywords = {communication strategy, human-AI communication, human-AI coordination, human-AI teaming, situation awareness, trust}
}

@article{zhang2024explain,
author = {Zhang, Rui and Flathmann, Christopher and Musick, Geoff and Schelble, Beau and McNeese, Nathan J. and Knijnenburg, Bart and Duan, Wen},
title = {I Know This Looks Bad, But I Can Explain: Understanding When AI Should Explain Actions In Human-AI Teams},
year = {2024},
issue_date = {March 2024},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {14},
number = {1},
issn = {2160-6455},
url = {https://doi.org/10.1145/3635474},
doi = {10.1145/3635474},
abstract = {Explanation of artificial intelligence (AI) decision-making has become an important research area in human–computer interaction (HCI) and computer-supported teamwork research. While plenty of research has investigated AI explanations with an intent to improve AI transparency and human trust in AI, how AI explanations function in teaming environments remains unclear. Given that a major benefit of AI giving explanations is to increase human trust understanding how AI explanations impact human trust is crucial to effective human-AI teamwork. An online experiment was conducted with 156 participants to explore this question by examining how a teammate’s explanations impact the perceived trust of the teammate and the effectiveness of the team and how these impacts vary based on whether the teammate is a human or an AI. This study shows that explanations facilitate trust in AI teammates when explaining why AI disobeyed humans’ orders but hindered trust when explaining why an AI lied to humans. In addition, participants’ personal characteristics (e.g., their gender and the individual’s ethical framework) impacted their perceptions of AI teammates both directly and indirectly in different scenarios. Our study contributes to interactive intelligent systems and HCI by shedding light on how an AI teammate’s actions and corresponding explanations are perceived by humans while identifying factors that impact trust and perceived effectiveness. This work provides an initial understanding of AI explanations in human-AI teams, which can be used for future research to build upon in exploring AI explanation implementation in collaborative environments.},
journal = {ACM Trans. Interact. Intell. Syst.},
month = {feb},
articleno = {6},
numpages = {23},
keywords = {Explanation, trust, AI teammates, human-AI teaming}
}

@article{zhang2020ideal,
author = {Zhang, Rui and McNeese, Nathan J. and Freeman, Guo and Musick, Geoff},
title = {"An Ideal Human": Expectations of AI Teammates in Human-AI Teaming},
year = {2021},
issue_date = {December 2020},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {4},
number = {CSCW3},
url = {https://doi.org/10.1145/3432945},
doi = {10.1145/3432945},
abstract = {Driven by state-of-the-art AI technologies, human-AI collaboration has become an important area in computer-supported teamwork research. While human-AI collaboration has been investigated in various domains, more research is needed to explore human perceptions and expectations of AI teammates in human-AI teaming. To achieve an in-depth understanding of how people perceive AI teammates and what they expect from AI teammates in human-AI teaming, we conducted a survey with 213 participants and a follow-up interview with 20 participants. Considering the context-dependency of teamwork, we chose to study human-AI teaming in the context of multiplayer online games as a case study. This study shows that people have mixed feelings toward AI teammates but hold a positive attitude toward future collaboration with AI teammates in general. Our findings highlight people's expectations for AI teammates in a rapidly changing collaborative environment (e.g., instrumental skills for in-game tasks, shared understanding between humans and AI, communication capabilities, human-like behaviors and performance), as well as factors that impact people's willingness to team up with AI teammates (e.g., pre-existing attitudes toward AI, previous collaboration experience with humans). We contribute to CSCW by shedding light on how AI should be structured in human-AI teaming to support highly complex collaborative activities in CSCW environments.},
journal = {Proc. ACM Hum.-Comput. Interact.},
month = {jan},
articleno = {246},
numpages = {25},
keywords = {teamwork, multiplayer online games, human-ai teaming, human-ai collaboration, ai design}
}

@article{julia2022bidirectional,
author = {Julia L. Wright, Shan G. Lakhmani and Jessie Y. C. Chen},
title = {Bidirectional Communications in Human-Agent Teaming: The Effects of Communication Style and Feedback},
journal = {International Journal of Human–Computer Interaction},
volume = {38},
number = {18-20},
pages = {1972--1985},
year = {2022},
publisher = {Taylor \& Francis},
doi = {10.1080/10447318.2022.2068744},


URL = { 
    
        https://doi.org/10.1080/10447318.2022.2068744
    
    

},
eprint = { 
    
        https://doi.org/10.1080/10447318.2022.2068744
    
    

}

}


@InProceedings{neil2018tom,
  title = 	 {Machine Theory of Mind},
  author =       {Rabinowitz, Neil and Perbet, Frank and Song, Francis and Zhang, Chiyuan and Eslami, S. M. Ali and Botvinick, Matthew},
  booktitle = 	 {Proceedings of the 35th International Conference on Machine Learning},
  pages = 	 {4218--4227},
  year = 	 {2018},
  editor = 	 {Dy, Jennifer and Krause, Andreas},
  volume = 	 {80},
  series = 	 {Proceedings of Machine Learning Research},
  month = 	 {10--15 Jul},
  publisher =    {PMLR},
  pdf = 	 {http://proceedings.mlr.press/v80/rabinowitz18a/rabinowitz18a.pdf},
  url = 	 {https://proceedings.mlr.press/v80/rabinowitz18a.html},
  abstract = 	 {Theory of mind (ToM) broadly refers to humans’ ability to represent the mental states of others, including their desires, beliefs, and intentions. We design a Theory of Mind neural network {–} a ToMnet {–} which uses meta-learning to build such models of the agents it encounters. The ToMnet learns a strong prior model for agents’ future behaviour, and, using only a small number of behavioural observations, can bootstrap to richer predictions about agents’ characteristics and mental states. We apply the ToMnet to agents behaving in simple gridworld environments, showing that it learns to model random, algorithmic, and deep RL agents from varied populations, and that it passes classic ToM tasks such as the "Sally-Anne" test of recognising that others can hold false beliefs about the world.}
}


@inproceedings{zahra2021direction,
author = {Ashktorab, Zahra and Dugan, Casey and Johnson, James and Pan, Qian and Zhang, Wei and Kumaravel, Sadhana and Campbell, Murray},
title = {Effects of Communication Directionality and AI Agent Differences in Human-AI Interaction},
year = {2021},
isbn = {9781450380966},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3411764.3445256},
doi = {10.1145/3411764.3445256},
abstract = {In Human-AI collaborative settings that are inherently interactive, direction of communication plays a role in how users perceive their AI partners. In an AI-driven cooperative game with partially observable information, players (be it the AI or the human player) require their actions to be interpreted accurately by the other player to yield a successful outcome. In this paper, we investigate social perceptions of AI agents with various directions of communication in a cooperative game setting. We measure subjective social perceptions (rapport, intelligence, and likeability) of participants towards their partners when participants believe they are playing with an AI or with a human and the nature of the communication (responsiveness and leading roles). We ran a large scale study on Mechanical Turk (n=199) of this collaborative game and find significant differences in gameplay outcome and social perception across different AI agents, different directions of communication and when the agent is perceived to be an AI/Human. We find that the bias against the AI that has been demonstrated in prior studies varies with the direction of the communication and with the AI agent.},
booktitle = {Proceedings of the 2021 CHI Conference on Human Factors in Computing Systems},
articleno = {238},
numpages = {15},
keywords = {social perception, human-AI interaction, games, collaboration},
location = {<conf-loc>, <city>Yokohama</city>, <country>Japan</country>, </conf-loc>},
series = {CHI '21}
}

@article{zahra2020social,
author = {Ashktorab, Zahra and Liao, Q. Vera and Dugan, Casey and Johnson, James and Pan, Qian and Zhang, Wei and Kumaravel, Sadhana and Campbell, Murray},
title = {Human-AI Collaboration in a Cooperative Game Setting: Measuring Social Perception and Outcomes},
year = {2020},
issue_date = {October 2020},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {4},
number = {CSCW2},
url = {https://doi.org/10.1145/3415167},
doi = {10.1145/3415167},
abstract = {Human-AI interaction is pervasive across many areas of our day to day lives. In this paper, we investigate human-AI collaboration in the context of a collaborative AI-driven word association game with partially observable information. In our experiments, we test various dimensions of subjective social perceptions (rapport, intelligence, creativity and likeability) of participants towards their partners when participants believe they are playing with an AI or with a human. We also test subjective social perceptions of participants towards their partners when participants are presented with a variety of confidence levels. We ran a large scale study on Mechanical Turk (n=164) of this collaborative game. Our results show that when participants believe their partners were human, they found their partners to be more likeable, intelligent, creative and having more rapport and use more positive words to describe their partner's attributes than when they believed they were interacting with an AI partner. We also found no differences in game outcome including win rate and turns to completion. Drawing on both quantitative and qualitative findings, we discuss AI agent transparency, include design implications for tools incorporating or supporting human-AI collaboration, and lay out directions for future research. Our findings lead to implications for other forms of human-AI interaction and communication.},
journal = {Proc. ACM Hum.-Comput. Interact.},
month = {oct},
articleno = {96},
numpages = {20},
keywords = {social perception, games, collaboration, ai agents}
}

@article{beau2022spatial,
author = {Schelble, Beau G. and Flathmann, Christopher and Musick, Geoff and McNeese, Nathan J. and Freeman, Guo},
title = {I See You: Examining the Role of Spatial Information in Human-Agent Teams},
year = {2022},
issue_date = {November 2022},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {6},
number = {CSCW2},
url = {https://doi.org/10.1145/3555099},
doi = {10.1145/3555099},
abstract = {Awareness, and specifically, spatial awareness, has long played a pivotal role in Computer-Supported Cooperative Work research in both theory and design. This significant background gives awareness the ability to answer challenges facing human-agent teams in communication and shared understanding. As such, the current study investigates the effects of spatial information level (low, high) on the development of team cognition and its outcomes in varying compositions of human-agent teams (human-human-agent, human-agent-agent) versus human-only (human-human-human) teams. The mixed-methods study had teams complete several rounds of the NeoCITIES emergency response management simulation and complete various team cognition and perception measures, followed by qualitative free-response questions. The study found that human-only teams did not perform at the same level as human-agent teams, with multi-agent human-agent teams having the best performance. A significant interaction, though with inconclusive simple main effects, displayed the trend that human-agent teams had better team mental model similarity when spatial awareness was high rather than low, while human-only teams experienced the reverse trend. Qualitative findings identified that high spatial awareness jump-started team cognition development, fostered more accurate shared mental models, enhanced the explainability of the agent, and helped the iterative development of team cognition over time.},
journal = {Proc. ACM Hum.-Comput. Interact.},
month = {nov},
articleno = {374},
numpages = {27},
keywords = {artificial intelligence, human-AI interaction, human-AI teaming, shared mental model, spatial information, team cognition}
}

@inproceedings{fussell1998teamcomm,
author = {Fussell, Susan R. and Kraut, Robert E. and Lerch, F. Javier and Scherlis, William L. and McNally, Matthew M. and Cadiz, Jonathan J.},
title = {Coordination, overload and team performance: effects of team communication strategies},
year = {1998},
isbn = {1581130090},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/289444.289502},
doi = {10.1145/289444.289502},
booktitle = {Proceedings of the 1998 ACM Conference on Computer Supported Cooperative Work},
pages = {275–284},
numpages = {10},
keywords = {work groups, electronic mail, coordination, computer-mediated communication, cognitive overload, awareness devices},
location = {Seattle, Washington, USA},
series = {CSCW '98}
}

@article{carroll2019utility,
  title={On the utility of learning about humans for human-ai coordination},
  author={Carroll, Micah and Shah, Rohin and Ho, Mark K and Griffiths, Tom and Seshia, Sanjit and Abbeel, Pieter and Dragan, Anca},
  journal={Advances in neural information processing systems},
  volume={32},
  year={2019}
}

@article{napierala2012bonferroni,
  title={What is the Bonferroni correction?},
  author={Napierala, Matthew A},
  journal={Aaos Now},
  pages={40--41},
  year={2012},
  publisher={American Academy of Orthopaedic Surgeons}
}

@article{brown2001point,
  title={Point-biserial correlation coefficients},
  author={Brown, James Dean},
  journal={Statistics},
  volume={5},
  number={3},
  pages={12--6},
  year={2001}
}

@ARTICLE{10.3389/fnrgo.2022.881653,

AUTHOR={Hardy, David J.  and Hinkin, Charles H. },

TITLE={Mental Workload in Neuropsychology: An Example With the NASA-TLX in Adults With HIV},

JOURNAL={Frontiers in Neuroergonomics},

VOLUME={3},

YEAR={2022},

URL={https://www.frontiersin.org/journals/neuroergonomics/articles/10.3389/fnrgo.2022.881653},

DOI={10.3389/fnrgo.2022.881653},

ISSN={2673-6195},

ABSTRACT={<p>A preliminary set of analyses are presented, where workload was examined in 32 adults infected with the human immunodeficiency virus (HIV). Like the current COVID-19 pandemic (caused by the SARS-CoV-2 virus), HIV can produce a wide variety of symptoms, including various levels of cognitive dysfunction. In fact, a recent meta-analysis estimates that of the 39 million adults infected globally with HIV, 42.6% exhibit some form of HIV-associated neurocognitive disorder. A common cognitive symptom in HIV is decline in attention and executive functioning. Though typically examined by clinicians with less precise traditional paper-and-pencil neuropsychological tests, we examined this aspect of cognitive functioning using a more psychometrically sophisticated task as we had HIV-positive adults perform a computerized tracking task in single, dual, and tri-task conditions <italic>via</italic> the Multi-Attribute Task (MAT) Battery. Also assessed was mental workload, with the NASA-Task Load Index (NASA-TLX), rarely used in neuropsychology but a standard tool in human factors and neuroergonomics research. As expected, tracking performance declined with task condition difficulty (<italic>p</italic> &lt; 0.001). Although no direct statistical comparisons were made, MAT performance here appeared worse than the MAT performance of various other groups reported in the research literature and in our laboratory. Ratings of workload also tended to increase as a function of task condition difficulty (<italic>p</italic> &lt; 0.001). Plotting MAT tracking performance against the Mental Demand subscale scores, large individual differences in this aspect of workload were evident in both optimal and sub-optimal tracking performance. To examine likely variables with a potential impact on Mental Demand, a variety of variables (nadir CD4 count, viral load, depression symptoms, diagnosis of AIDS, presence of opportunistic infection, general cognitive status, etc.) were examined in relation to the Mental Demand scale, with age showing a significant association (<italic>r</italic> = 0.41, <italic>p</italic> = 0.022) and a diagnosis of AIDS showing trend associations (<italic>p</italic>s ≥ 0.066). Findings suggesting a deficit in metacognition or insight are also discussed. It is argued that assessment of workload (and its various aspects or components) can provide valuable additional information in neuropsychology.</p>}}

@book{corbin2014basics,
  title={Basics of Qualitative Research: Techniques and Procedures for Developing Grounded Theory},
  author={Corbin, Juliet and Strauss, Anselm},
  year={2014},
  publisher={Sage publications}
}

@article{hoffman2019evaluating,
  title={Evaluating fluency in human--robot collaboration},
  author={Hoffman, Guy},
  journal={IEEE Transactions on Human-Machine Systems},
  volume={49},
  number={3},
  pages={209--218},
  year={2019},
  publisher={IEEE}
}

@article{strouse2021fcp,
  title={Collaborating with humans without human data},
  author={Strouse, DJ and McKee, Kevin and Botvinick, Matt and Hughes, Edward and Everett, Richard},
  journal={Advances in Neural Information Processing Systems},
  volume={34},
  pages={14502--14515},
  year={2021}
}

@inproceedings{Yang23Cole,
  author       = {Yang Li and
                  Shao Zhang and
                  Jichen Sun and
                  Yali Du and
                  Ying Wen and
                  Xinbing Wang and
                  Wei Pan},
  title        = {Cooperative Open-ended Learning Framework for Zero-Shot Coordination},
  booktitle    = {{ICML}},
  series       = {Proceedings of Machine Learning Research},
  volume       = {202},
  pages        = {20470--20484},
  publisher    = {{PMLR}},
  year         = {2023}
}



@article{gymcooking,
author = {Wu, Sarah A. and Wang, Rose E. and Evans, James A. and Tenenbaum, Joshua B. and Parkes, David C. and Kleiman-Weiner, Max},
title = {Too Many Cooks: Bayesian Inference for Coordinating Multi-Agent Collaboration},
journal = {Topics in Cognitive Science},
volume = {13},
number = {2},
pages = {414-432},
keywords = {Coordination, Social learning, Inverse planning, Bayesian inference, Multi-agent reinforcement learning},
doi = {https://doi.org/10.1111/tops.12525},
url = {https://onlinelibrary.wiley.com/doi/abs/10.1111/tops.12525},
eprint = {https://onlinelibrary.wiley.com/doi/pdf/10.1111/tops.12525},
abstract = {Abstract Collaboration requires agents to coordinate their behavior on the fly, sometimes cooperating to solve a single task together and other times dividing it up into sub-tasks to work on in parallel. Underlying the human ability to collaborate is theory-of-mind (ToM), the ability to infer the hidden mental states that drive others to act. Here, we develop Bayesian Delegation, a decentralized multi-agent learning mechanism with these abilities. Bayesian Delegation enables agents to rapidly infer the hidden intentions of others by inverse planning. We test Bayesian Delegation in a suite of multi-agent Markov decision processes inspired by cooking problems. On these tasks, agents with Bayesian Delegation coordinate both their high-level plans (e.g., what sub-task they should work on) and their low-level actions (e.g., avoiding getting in each other's way). When matched with partners that act using the same algorithm, Bayesian Delegation outperforms alternatives. Bayesian Delegation is also a capable ad hoc collaborator and successfully coordinates with other agent types even in the absence of prior experience. Finally, in a behavioral experiment, we show that Bayesian Delegation makes inferences similar to human observers about the intent of others. Together, these results argue for the centrality of ToM for successful decentralized multi-agent collaboration.},
year = {2021}
}

@inproceedings{yu23hsp,
  author       = {Chao Yu and
                  Jiaxuan Gao and
                  Weilin Liu and
                  Botian Xu and
                  Hao Tang and
                  Jiaqi Yang and
                  Yu Wang and
                  Yi Wu},
  title        = {Learning Zero-Shot Cooperation with Humans, Assuming Humans Are Biased},
  booktitle    = {{ICLR}},
  publisher    = {OpenReview.net},
  year         = {2023}
}

@inproceedings{CharakornMD23LIPO,
  author       = {Rujikorn Charakorn and
                  Poramate Manoonpong and
                  Nat Dilokthanakul},
  title        = {Generating Diverse Cooperative Agents by Learning Incompatible Policies},
  booktitle    = {{ICLR}},
  publisher    = {OpenReview.net},
  year         = {2023}
}

@article{DEMIR2020102436,
title = {Understanding human-robot teams in light of all-human teams: Aspects of team interaction and shared cognition},
journal = {International Journal of Human-Computer Studies},
volume = {140},
pages = {102436},
year = {2020},
issn = {1071-5819},
doi = {https://doi.org/10.1016/j.ijhcs.2020.102436},
url = {https://www.sciencedirect.com/science/article/pii/S1071581920300380},
author = {Mustafa Demir and Nathan J. McNeese and Nancy J. Cooke},
keywords = {Human-robot teaming, Dynamical systems, Interactive team cognition, Shared cognition, Team cognition, Urban search and rescue},
abstract = {As robots become more autonomous, their roles shift from being operated and controlled by humans to interactively teaming with humans. The current research focuses on how human operators can effectively team with autonomous urban search and rescue agents in a dynamic and complex task environment. To do so, we empirically examined how shared cognition and restricted language capabilities impacted performance of human-robot dyad search teams using a simulated Minecraft task environment. In order to examine the effects of shared mental models and language the following modified conditions were applied: (1) participants were either able to communicate using natural language or the internal participant's communication was limited to three-word utterances; and (2) shared mental models were manipulated by either the internal participant being made fully aware of the external participant's restricted representation of the environment and inaccurate map or the internal was unaware of these challenges. The primary findings from this study are: (1) teams in the natural language and shared mental model conditions performed better than teams in the limited language and restricted model conditions; (2) when the internal participant was unaware of the challenges of the external, the external perceived higher workload than when there was a shared mental model; (3) teams with natural language and shared mental model demonstrated more predictable behavior than the other teams; (4) some amount of systems’ predictability was good but too much predictability was not good. Overall, these results indicate that effective team interaction and shared cognition play an important role in human-robot dyadic teaming performance.}
}

@inproceedings{liang2019implicit,
author = {Liang, Claire and Proft, Julia and Andersen, Erik and Knepper, Ross A.},
title = {Implicit Communication of Actionable Information in Human-AI teams},
year = {2019},
isbn = {9781450359702},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3290605.3300325},
doi = {10.1145/3290605.3300325},
abstract = {Humans expect their collaborators to look beyond the explicit interpretation of their words. Implicature is a common form of implicit communication that arises in natural language discourse when an utterance leverages context to imply information beyond what the words literally convey. Whereas computational methods have been proposed for interpreting and using different forms of implicature, its role in human and artificial agent collaboration has not yet been explored in a concrete domain. The results of this paper provide insights to how artificial agents should be structured to facilitate natural and efficient communication of actionable information with humans. We investigated implicature by implementing two strategies for playing Hanabi, a cooperative card game that relies heavily on communication of actionable implicit information to achieve a shared goal. In a user study with 904 completed games and 246 completed surveys, human players randomly paired with an implicature AI are 71\% more likely to think their partner is human than players paired with a non-implicature AI. These teams demonstrated game performance similar to other state of the art approaches.},
booktitle = {Proceedings of the 2019 CHI Conference on Human Factors in Computing Systems},
pages = {1–13},
numpages = {13},
keywords = {collaboration, empirical study that tells us about people, games/play},
location = {Glasgow, Scotland Uk},
series = {CHI '19}
}

@inproceedings{jason2018awareness,
author = {Wuertz, Jason and Alharthi, Sultan A. and Hamilton, William A. and Bateman, Scott and Gutwin, Carl and Tang, Anthony and Toups Dugas, Phoebe O. and Hammer, Jessica},
title = {A Design Framework for Awareness Cues in Distributed Multiplayer Games},
year = {2018},
isbn = {9781450356206},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3173574.3173817},
doi = {10.1145/3173574.3173817},
abstract = {In the physical world, teammates develop situation awareness about each other's location, status, and actions through cues such as gaze direction and ambient noise. To support situation awareness, distributed multiplayer games provide awareness cues - information that games automatically make available to players to support cooperative gameplay. The design of awareness cues can be extremely complex, impacting how players experience games and work with teammates. Despite the importance of awareness cues, designers have little beyond experiential knowledge to guide their design. In this work, we describe a design framework for awareness cues, providing insight into what information they provide, how they communicate this information, and how design choices can impact play experience. Our research, based on a grounded theory analysis of current games, is the first to provide a characterization of awareness cues, providing a palette for game designers to improve design practice and a starting point for deeper research into collaborative play.},
booktitle = {Proceedings of the 2018 CHI Conference on Human Factors in Computing Systems},
pages = {1–14},
numpages = {14},
keywords = {workspace awareness, situation awareness, game design, distributed multiplayer games, awareness cues},
location = {<conf-loc>, <city>Montreal QC</city>, <country>Canada</country>, </conf-loc>},
series = {CHI '18}
}

@inproceedings{jung2018grounding,
author = {Jung, Malte F.},
title = {Affective Grounding in Human-Robot Interaction},
year = {2017},
isbn = {9781450343367},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2909824.3020224},
doi = {10.1145/2909824.3020224},
abstract = {Participating in interaction requires not only coordination on content and process, as previously proposed, but also on affect. The term affective grounding is introduced to refer to the coordination of affect in interaction with the purpose of building shared understanding about what behavior can be exhibited, and how behavior is interpreted emotionally and responded to. Affective Ground is achieved when interactants have reached shared understanding about how behavior should be interpreted emotionally. The paper contributes a review and critique of current perspectives on emotion in HRI. Further it outlines how research on emotion in HRI can benefit from taking an affective grounding perspective and outlines implications for the design of robots capable of participating in the coordination on affect in interaction.},
booktitle = {Proceedings of the 2017 ACM/IEEE International Conference on Human-Robot Interaction},
pages = {263–273},
numpages = {11},
keywords = {affective grounding, emotion, emotion regulation, human-robot interaction},
location = {Vienna, Austria},
series = {HRI '17}
}

@inproceedings{kim2017lol,
author = {Kim, Young Ji and Engel, David and Woolley, Anita Williams and Lin, Jeffrey Yu-Ting and McArthur, Naomi and Malone, Thomas W.},
title = {What Makes a Strong Team? Using Collective Intelligence to Predict Team Performance in League of Legends},
year = {2017},
isbn = {9781450343350},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2998181.2998185},
doi = {10.1145/2998181.2998185},
abstract = {Recent research has demonstrated that (a) groups can be characterized by a collective intelligence (CI) factor that measures their ability to perform together on a wide range of different tasks, and (b) this factor can predict groups' performance on other tasks in the future. The current study examines whether these results translate into the world of teams in competitive online video games where self-organized, time-pressured, and intense collaboration occurs purely online. In this study of teams playing the online game League of Legends, we find that CI does, indeed, predict the competitive performance of teams controlling for the amount of time played as a team. We also find that CI is positively correlated with the presence of a female team member and with the team members' average social perceptiveness. Finally, unlike in prior studies, tacit coordination in this setting plays a larger role than verbal communication.},
booktitle = {Proceedings of the 2017 ACM Conference on Computer Supported Cooperative Work and Social Computing},
pages = {2316–2329},
numpages = {14},
keywords = {collective intelligence, online collaboration, online games, team performance, virtual teams},
location = {Portland, Oregon, USA},
series = {CSCW '17}
}

@article {Chang:2017:0301-2212:915,
title = "Explicit and implicit team coordination: Development of a multidimensional scale",
journal = "Social Behavior and Personality: an international journal",
parent_itemid = "infobike://sbp/sbp",
publishercode ="sbp",
year = "2017",
volume = "45",
number = "6",
pages = "915-929",
itemtype = "ARTICLE",
issn = "0301-2212",
url = "https://www.ingentaconnect.com/content/sbp/sbp/2017/00000045/00000006/art00004",
doi = "doi:10.2224/sbp.5893",
keyword = "COMMON UNDERSTANDING, EXPLICIT TEAM COORDINATION, IMPLICIT TEAM COORDINATION, PREDICTABILITY, TEAM COORDINATION, ACCOUNTABILITY",
author = "Chang, Huo-Tsan and Lin, Cheng-Chen and Chen, Cheng-Hung and Ho, Yeong-Ho",
abstract = "We reviewed team coordination and implicit coordination theories and developed an explicit and implicit team coordination scale. After item revision of a preliminary scale had been performed by 5 experts, there were 30 items in 6 dimensions classified as explicit accountability, explicit
predictability, explicit common understanding, implicit accountability, implicit predictability, and implicit common understanding. The reliability and validity of these items were determined with 323 participants, after which exploratory factor analysis resulted in 5 valid dimensions: explicit
accountability, implicit accountability, explicit predictability, implicit predictability, and common understanding, comprising 26 items in the multidimensional scale. Future researchers can further explore the applicability of the scale for measuring team coordination in team management practices.",
}

@inproceedings{greg2009cst,
author = {Convertino, Gregorio and Mentis, Helena M. and Rosson, Mary Beth and Slavkovic, Aleksandra and Carroll, John M.},
title = {Supporting content and process common ground in computer-supported teamwork},
year = {2009},
isbn = {9781605582467},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1518701.1519059},
doi = {10.1145/1518701.1519059},
abstract = {We build on our prior work with computer-supported teams performing a complex decision-making task on maps, where the distinction between content and process common ground is proposed. In this paper we describe a distributed geo-collaboration software prototype. The system design rationale was gleaned from fieldwork, literature on team cognition, and an earlier lab study introducing a reference task with face-to-face teams. We report on a controlled experiment that evaluates this design rationale. Distinct sets of measures show that that the prototype supported both content and process common ground, offsetting the costs imposed by the distributed setting. We interpret the results in relation to prior work on common ground and draw implications for moving beyond current models of sharing and coordination.},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
pages = {2339–2348},
numpages = {10},
keywords = {common ground, cscw, design, prototype},
location = {Boston, MA, USA},
series = {CHI '09}
}

@article{wen2019speaker,
author = {Duan, Wen and Yamashita, Naomi and Fussell, Susan R.},
title = {Increasing Native Speakers' Awareness of the Need to Slow Down in Multilingual Conversations Using a Real-Time Speech Speedometer},
year = {2019},
issue_date = {November 2019},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {3},
number = {CSCW},
url = {https://doi.org/10.1145/3359273},
doi = {10.1145/3359273},
abstract = {Collaborating using a common language can be challenging for non-native speakers (NNS). These challenges can be reduced when native speakers (NS) adjust their speech behavior for NNS, for example by speaking more slowly. In this study, we examined whether the use of real-time speech rate feedback (a speech speedometer) would help NS monitor their speaking speed and adjust for NNS accordingly. We conducted a laboratory experiment with 20 triads of 2 NS and 1 NNS. NS in half of the groups were given the speech speedometer. We found that NS with the speech speedometer were significantly more motivated to slow down their speech but they did not actually speak more slowly, although they made other speech adjustments. Furthermore, NNS perceived the speech of NS with the speedometer less clear, and they felt less accommodated. The results highlight the need for tools that create scaffolding to help NS make speech accommodations. We conclude with some design ideas for these scaffolding tools.},
journal = {Proc. ACM Hum.-Comput. Interact.},
month = {nov},
articleno = {171},
numpages = {25},
keywords = {computer-mediated communication, cross-lingual communication, multilingual communication, speech accommodation}
}

@inproceedings{leshed2007feedback,
author = {Leshed, Gilly and Hancock, Jeffrey T. and Cosley, Dan and McLeod, Poppy L. and Gay, Geri},
title = {Feedback for guiding reflection on teamwork practices},
year = {2007},
isbn = {9781595938459},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1316624.1316655},
doi = {10.1145/1316624.1316655},
abstract = {Effective communication in project teams is important, but not often taught. We explore how feedback might improve teamwork in a controlled experiment where groups interact through chat rooms. Collaborators who receive high feedback ratings use different language than poor collaborators (e.g. more words, fewer assents, and less affect-laden language). Further, feedback affects language use. This suggests that a system could use linguistic analysis to automatically provide and visualize feedback to teach teamwork. To this end, we present GroupMeter, a system that applies principles discovered in the experiment to provide feedback both from peers and from automated linguistic analysis.},
booktitle = {Proceedings of the 2007 ACM International Conference on Supporting Group Work},
pages = {217–220},
numpages = {4},
keywords = {teamwork, peer evaluation, linguistic analysis, feedback, CSCL},
location = {Sanibel Island, Florida, USA},
series = {GROUP '07}
}

@incollection{kraiger1997conceptual,
  title={Conceptual development and empirical evaluation of measures of shared mental models as indicators of team effectiveness},
  author={Kraiger, Kurt and Wenzel, Lucy H},
  booktitle={Team performance assessment and measurement},
  pages={75--96},
  year={1997},
  publisher={Psychology Press}
}

@inproceedings{collaborationawareness1992,
author = {Dourish, Paul and Bellotti, Victoria},
title = {Awareness and coordination in shared workspaces},
year = {1992},
isbn = {0897915429},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/143457.143468},
doi = {10.1145/143457.143468},
booktitle = {Proceedings of the 1992 ACM Conference on Computer-Supported Cooperative Work},
pages = {107–114},
numpages = {8},
keywords = {awareness, coordination, information sharing, shared feedback, shared workspaces},
location = {Toronto, Ontario, Canada},
series = {CSCW '92}
}

@article{newman2024bootstrapping,
  title={Bootstrapping Linear Models for Fast Online Adaptation in Human-Agent Collaboration},
  author={Newman, Benjamin A and Paxton, Chris and Kitani, Kris and Admoni, Henny},
  journal={arXiv preprint arXiv:2404.10733},
  year={2024}
}

@inproceedings{
wang2023order,
title={Order Matters: Agent-by-agent Policy Optimization},
author={Xihuai Wang and Zheng Tian and Ziyu Wan and Ying Wen and Jun Wang and Weinan Zhang},
booktitle={The Eleventh International Conference on Learning Representations },
year={2023},
url={https://openreview.net/forum?id=Q-neeWNVv1}
}

@article{bernstein2002complexity,
  title={The complexity of decentralized control of Markov decision processes},
  author={Bernstein, Daniel S and Givan, Robert and Immerman, Neil and Zilberstein, Shlomo},
  journal={Mathematics of operations research},
  volume={27},
  number={4},
  pages={819--840},
  year={2002},
  publisher={INFORMS}
}


@inproceedings{DBLP:conf/acl/ZhangTWW0HTLZ024,
  author       = {Wenqi Zhang and
                  Ke Tang and
                  Hai Wu and
                  Mengna Wang and
                  Yongliang Shen and
                  Guiyang Hou and
                  Zeqi Tan and
                  Peng Li and
                  Yueting Zhuang and
                  Weiming Lu},
  editor       = {Lun{-}Wei Ku and
                  Andre Martins and
                  Vivek Srikumar},
  title        = {Agent-Pro: Learning to Evolve via Policy-Level Reflection and Optimization},
  booktitle    = {Proceedings of the 62nd Annual Meeting of the Association for Computational
                  Linguistics (Volume 1: Long Papers), {ACL} 2024, Bangkok, Thailand,
                  August 11-16, 2024},
  pages        = {5348--5375},
  publisher    = {Association for Computational Linguistics},
  year         = {2024},
  url          = {https://aclanthology.org/2024.acl-long.292},
  timestamp    = {Mon, 26 Aug 2024 16:40:52 +0200},
  biburl       = {https://dblp.org/rec/conf/acl/ZhangTWW0HTLZ024.bib},
  bibsource    = {dblp computer science bibliography, https://dblp.org}
}

@inproceedings{he-etal-2024-planning,
    title = "Planning Like Human: A Dual-process Framework for Dialogue Planning",
    author = "He, Tao  and
      Liao, Lizi  and
      Cao, Yixin  and
      Liu, Yuanxing  and
      Liu, Ming  and
      Chen, Zerui  and
      Qin, Bing",
    editor = "Ku, Lun-Wei  and
      Martins, Andre  and
      Srikumar, Vivek",
    booktitle = "Proceedings of the 62nd Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers)",
    month = aug,
    year = "2024",
    address = "Bangkok, Thailand",
    publisher = "Association for Computational Linguistics",
    url = "https://aclanthology.org/2024.acl-long.262/",
    doi = "10.18653/v1/2024.acl-long.262",
    pages = "4768--4791",
    abstract = "In proactive dialogue, the challenge lies not just in generating responses but in steering conversations toward predetermined goals, a task where Large Language Models (LLMs) typically struggle due to their reactive nature. Traditional approaches to enhance dialogue planning in LLMs, ranging from elaborate prompt engineering to the integration of policy networks, either face efficiency issues or deliver suboptimal performance. Inspired by the dual-process theory in psychology, which identifies two distinct modes of thinking{---}intuitive (fast) and analytical (slow), we propose the Dual-Process Dialogue Planning (DPDP) framework. DPDP embodies this theory through two complementary planning systems: an instinctive policy model for familiar contexts and a deliberative Monte Carlo Tree Search (MCTS) mechanism for complex, novel scenarios. This dual strategy is further coupled with a novel two-stage training regimen: offline Reinforcement Learning for robust initial policy model formation followed by MCTS-enhanced on-the-fly learning, which ensures a dynamic balance between efficiency and strategic depth. Our empirical evaluations across diverse dialogue tasks affirm DPDP`s superiority in achieving both high-quality dialogues and operational efficiency, outpacing existing methods."
}

@article{zhang2024mutual,
  title={Mutual theory of mind in human-ai collaboration: An empirical study with llm-driven ai agents in a real-time shared workspace task},
  author={Zhang, Shao and Wang, Xihuai and Zhang, Wenhao and Chen, Yongshan and Gao, Landi and Wang, Dakuo and Zhang, Weinan and Wang, Xinbing and Wen, Ying},
  journal={arXiv preprint arXiv:2409.08811},
  year={2024}
}

@inproceedings{zhou2021smarts,
  title={Smarts: An open-source scalable multi-agent rl training school for autonomous driving},
  author={Zhou, Ming and Luo, Jun and Villella, Julian and Yang, Yaodong and Rusu, David and Miao, Jiayu and Zhang, Weinan and Alban, Montgomery and Fadakar, Iman and Chen, Zheng and others},
  booktitle={Conference on robot learning},
  pages={264--285},
  year={2021},
  organization={PMLR}
}

@article{evans2013dual,
  title={Dual-process theories of higher cognition: Advancing the debate},
  author={Evans, Jonathan St BT and Stanovich, Keith E},
  journal={Perspectives on psychological science},
  volume={8},
  number={3},
  pages={223--241},
  year={2013},
  publisher={Sage Publications Sage CA: Los Angeles, CA}
}

@article{kahneman2011thinking,
  title={Thinking, fast and slow},
  author={Kahneman, Daniel},
  journal={Farrar, Straus and Giroux},
  year={2011}
}

@article{shao2024collaborative,
  title={Collaborative Gym: A Framework for Enabling and Evaluating Human-Agent Collaboration},
  author={Shao, Yijia and Samuel, Vinay and Jiang, Yucheng and Yang, John and Yang, Diyi},
  journal={arXiv preprint arXiv:2412.15701},
  year={2024}
}

@article{xie2024travelplanner,
  title={Travelplanner: A benchmark for real-world planning with language agents},
  author={Xie, Jian and Zhang, Kai and Chen, Jiangjie and Zhu, Tinghui and Lou, Renze and Tian, Yuandong and Xiao, Yanghua and Su, Yu},
  journal={arXiv preprint arXiv:2402.01622},
  year={2024}
}

@article{yao2022webshop,
  title={Webshop: Towards scalable real-world web interaction with grounded language agents},
  author={Yao, Shunyu and Chen, Howard and Yang, John and Narasimhan, Karthik},
  journal={Advances in Neural Information Processing Systems},
  volume={35},
  pages={20744--20757},
  year={2022}
}

@misc{dafoe2021cooperative,
  title={Cooperative AI: machines must learn to find common ground},
  author={Dafoe, Allan and Bachrach, Yoram and Hadfield, Gillian and Horvitz, Eric and Larson, Kate and Graepel, Thore},
  year={2021},
  publisher={Nature Publishing Group}
}

@article{yu2024distilling,
  title={Distilling system 2 into system 1},
  author={Yu, Ping and Xu, Jing and Weston, Jason and Kulikov, Ilia},
  journal={arXiv preprint arXiv:2407.06023},
  year={2024}
}

@article{yi2024survey,
  title={A Survey on Recent Advances in LLM-Based Multi-turn Dialogue Systems},
  author={Yi, Zihao and Ouyang, Jiarui and Liu, Yuwen and Liao, Tianhao and Xu, Zhe and Shen, Ying},
  journal={arXiv preprint arXiv:2402.18013},
  year={2024}
}

@inproceedings{wang2024zsc,
  title={Zsc-eval: An evaluation toolkit and benchmark for multi-agent zero-shot coordination},
  author={Wang, Xihuai and Zhang, Shao and Zhang, Wenhao and Dong, Wentao and Chen, Jingxiao and Wen, Ying and Zhang, Weinan},
  booktitle={The Thirty-eight Conference on Neural Information Processing Systems Datasets and Benchmarks Track},
  year={2024}
}

@inproceedings{prather2024widening,
  title={The widening gap: The benefits and harms of generative ai for novice programmers},
  author={Prather, James and Reeves, Brent N and Leinonen, Juho and MacNeil, Stephen and Randrianasolo, Arisoa S and Becker, Brett A and Kimmel, Bailey and Wright, Jared and Briggs, Ben},
  booktitle={Proceedings of the 2024 ACM Conference on International Computing Education Research-Volume 1},
  pages={469--486},
  year={2024}
}

@article{wan2024felt,
  title={" It Felt Like Having a Second Mind": Investigating Human-AI Co-creativity in Prewriting with Large Language Models},
  author={Wan, Qian and Hu, Siying and Zhang, Yu and Wang, Piaohong and Wen, Bo and Lu, Zhicong},
  journal={Proceedings of the ACM on Human-Computer Interaction},
  volume={8},
  number={CSCW1},
  pages={1--26},
  year={2024},
  publisher={ACM New York, NY, USA}
}

@article{riemer2024can,
  title={Can Large Language Models Adapt to Other Agents In-Context?},
  author={Riemer, Matthew and Ashktorab, Zahra and Bouneffouf, Djallel and Das, Payel and Liu, Miao and Weisz, Justin D and Campbell, Murray},
  journal={arXiv preprint arXiv:2412.19726},
  year={2024}
}

@article{shinn2024reflexion,
  title={Reflexion: Language agents with verbal reinforcement learning},
  author={Shinn, Noah and Cassano, Federico and Gopinath, Ashwin and Narasimhan, Karthik and Yao, Shunyu},
  journal={Advances in Neural Information Processing Systems},
  volume={36},
  year={2024}
}

@misc{dong2024surveyincontextlearning,
      title={A Survey on In-context Learning}, 
      author={Qingxiu Dong and Lei Li and Damai Dai and Ce Zheng and Jingyuan Ma and Rui Li and Heming Xia and Jingjing Xu and Zhiyong Wu and Baobao Chang and Xu Sun and Lei Li and Zhifang Sui},
      year={2024},
      eprint={2301.00234},
      archivePrefix={arXiv},
      primaryClass={cs.CL},
      url={https://arxiv.org/abs/2301.00234}, 
}

@inproceedings{DBLP:conf/icra/LiangHXXHIFZ23,
  author       = {Jacky Liang and
                  Wenlong Huang and
                  Fei Xia and
                  Peng Xu and
                  Karol Hausman and
                  Brian Ichter and
                  Pete Florence and
                  Andy Zeng},
  title        = {Code as Policies: Language Model Programs for Embodied Control},
  booktitle    = {{IEEE} International Conference on Robotics and Automation, {ICRA}
                  2023, London, UK, May 29 - June 2, 2023},
  pages        = {9493--9500},
  publisher    = {{IEEE}},
  year         = {2023},
  url          = {https://doi.org/10.1109/ICRA48891.2023.10160591},
  doi          = {10.1109/ICRA48891.2023.10160591},
  timestamp    = {Tue, 08 Aug 2023 10:24:29 +0200},
  biburl       = {https://dblp.org/rec/conf/icra/LiangHXXHIFZ23.bib},
  bibsource    = {dblp computer science bibliography, https://dblp.org}
}

@article{hart1968formal,
  title={A formal basis for the heuristic determination of minimum cost paths},
  author={Hart, Peter E and Nilsson, Nils J and Raphael, Bertram},
  journal={IEEE transactions on Systems Science and Cybernetics},
  volume={4},
  number={2},
  pages={100--107},
  year={1968},
  publisher={IEEE}
}

@article{liu2024deepseek,
  title={Deepseek-v3 technical report},
  author={Liu, Aixin and Feng, Bei and Xue, Bing and Wang, Bingxuan and Wu, Bochao and Lu, Chengda and Zhao, Chenggang and Deng, Chengqi and Zhang, Chenyu and Ruan, Chong and others},
  journal={arXiv preprint arXiv:2412.19437},
  year={2024}
}

@misc{huang2023surveyhallucinationlargelanguage,
      title={A Survey on Hallucination in Large Language Models: Principles, Taxonomy, Challenges, and Open Questions}, 
      author={Lei Huang and Weijiang Yu and Weitao Ma and Weihong Zhong and Zhangyin Feng and Haotian Wang and Qianglong Chen and Weihua Peng and Xiaocheng Feng and Bing Qin and Ting Liu},
      year={2023},
      eprint={2311.05232},
      archivePrefix={arXiv},
      primaryClass={cs.CL},
      url={https://arxiv.org/abs/2311.05232}, 
}

@article{zhou2024survey,
  title={A survey on efficient inference for large language models},
  author={Zhou, Zixuan and Ning, Xuefei and Hong, Ke and Fu, Tianyu and Xu, Jiaming and Li, Shiyao and Lou, Yuming and Wang, Luning and Yuan, Zhihang and Li, Xiuhong and others},
  journal={arXiv preprint arXiv:2404.14294},
  year={2024}
}

@article{ning2021survey,
  title={A survey on hybrid human-artificial intelligence for autonomous driving},
  author={Ning, Huansheng and Yin, Rui and Ullah, Ata and Shi, Feifei},
  journal={IEEE Transactions on Intelligent Transportation Systems},
  volume={23},
  number={7},
  pages={6011--6026},
  year={2021},
  publisher={IEEE}
}





@article{qwen2.5,
    title   = {Qwen2.5 Technical Report}, 
    author  = {An Yang and Baosong Yang and Beichen Zhang and Binyuan Hui and Bo Zheng and Bowen Yu and Chengyuan Li and Dayiheng Liu and Fei Huang and Haoran Wei and Huan Lin and Jian Yang and Jianhong Tu and Jianwei Zhang and Jianxin Yang and Jiaxi Yang and Jingren Zhou and Junyang Lin and Kai Dang and Keming Lu and Keqin Bao and Kexin Yang and Le Yu and Mei Li and Mingfeng Xue and Pei Zhang and Qin Zhu and Rui Men and Runji Lin and Tianhao Li and Tingyu Xia and Xingzhang Ren and Xuancheng Ren and Yang Fan and Yang Su and Yichang Zhang and Yu Wan and Yuqiong Liu and Zeyu Cui and Zhenru Zhang and Zihan Qiu},
    journal = {arXiv preprint arXiv:2412.15115},
    year    = {2024}
}

@article{touvron2023llama,
  title={Llama: Open and efficient foundation language models},
  author={Touvron, Hugo and Lavril, Thibaut and Izacard, Gautier and Martinet, Xavier and Lachaux, Marie-Anne and Lacroix, Timoth{\'e}e and Rozi{\`e}re, Baptiste and Goyal, Naman and Hambro, Eric and Azhar, Faisal and others},
  journal={arXiv preprint arXiv:2302.13971},
  year={2023}
}

@article{abdin2024phi3,
  title={Phi-3 technical report: A highly capable language model locally on your phone},
  author={Abdin, Marah and Aneja, Jyoti and Awadalla, Hany and Awadallah, Ahmed and Awan, Ammar Ahmad and Bach, Nguyen and Bahree, Amit and Bakhtiari, Arash and Bao, Jianmin and Behl, Harkirat and others},
  journal={arXiv preprint arXiv:2404.14219},
  year={2024}
}

@article{abdin2024phi4,
  title={Phi-4 technical report},
  author={Abdin, Marah and Aneja, Jyoti and Behl, Harkirat and Bubeck, S{\'e}bastien and Eldan, Ronen and Gunasekar, Suriya and Harrison, Michael and Hewett, Russell J and Javaheripi, Mojan and Kauffmann, Piero and others},
  journal={arXiv preprint arXiv:2412.08905},
  year={2024}
}


@article{team2024gemma,
  title={Gemma 2: Improving open language models at a practical size},
  author={Team, Gemma and Riviere, Morgane and Pathak, Shreya and Sessa, Pier Giuseppe and Hardin, Cassidy and Bhupatiraju, Surya and Hussenot, L{\'e}onard and Mesnard, Thomas and Shahriari, Bobak and Ram{\'e}, Alexandre and others},
  journal={arXiv preprint arXiv:2408.00118},
  year={2024}
}

@misc{mistralAI,
  author  = {Mistral AI},
  title   = {Mistral AI - Models},
  url     = {https://mistral.ai/en/models},
  urldate = {2025-02-08}
}

@article{guo2025deepseek,
  title={Deepseek-r1: Incentivizing reasoning capability in llms via reinforcement learning},
  author={Guo, Daya and Yang, Dejian and Zhang, Haowei and Song, Junxiao and Zhang, Ruoyu and Xu, Runxin and Zhu, Qihao and Ma, Shirong and Wang, Peiyi and Bi, Xiao and others},
  journal={arXiv preprint arXiv:2501.12948},
  year={2025}
}

@article{zheng2023efficiently,
  title={Efficiently Programming Large Language Models using SGLang.},
  author={Zheng, Lianmin and Yin, Liangsheng and Xie, Zhiqiang and Huang, Jeff and Sun, Chuyue and Yu, Cody\_Hao and Cao, Shiyi and Kozyrakis, Christos and Stoica, Ion and Gonzalez, Joseph E and others},
  year={2023},
  publisher={arXiv}
}

@inproceedings{kwon2023efficient,
  title={Efficient Memory Management for Large Language Model Serving with PagedAttention},
  author={Woosuk Kwon and Zhuohan Li and Siyuan Zhuang and Ying Sheng and Lianmin Zheng and Cody Hao Yu and Joseph E. Gonzalez and Hao Zhang and Ion Stoica},
  booktitle={Proceedings of the ACM SIGOPS 29th Symposium on Operating Systems Principles},
  year={2023}
}

@misc{llama.cpp,
  author  = {Georgi Gerganov},
  title   = {llama.cpp: Port of Meta's LLaMA model in C/C++},
  year    = {2023},
  url     = {https://github.com/ggerganov/llama.cpp},
  urldate = {2025-02-08}
}

@misc{ollama,
  author  = {Ollama Contributors},
  title   = {Ollama: Run large language models locally},
  year    = {2023},
  url     = {https://github.com/ollama/ollama},
  urldate = {2025-02-08}
}

@misc{anthropic_claude35,
  author       = {Anthropic},
  title        = {Claude 3.5 Models and Computer Use},
  year         = {2024},
  howpublished = {\url{https://www.anthropic.com/news/3-5-models-and-computer-use}}
}

@misc{pichai2024gemini,
  author       = {Sundar Pichai and Demis Hassabis and Koray Kavukcuoglu},
  title        = {Introducing Gemini 2.0: our new AI model for the agentic era},
  year         = {2024},
  howpublished = {\url{https://blog.google/technology/google-deepmind/google-gemini-ai-update-december-2024/}},
  note         = {Accessed: 2025-02-08}
}

@inproceedings{gong2024mindagent,
  title={MindAgent: Emergent Gaming Interaction},
  author={Gong, Ran and Huang, Qiuyuan and Ma, Xiaojian and Noda, Yusuke and Durante, Zane and Zheng, Zilong and Terzopoulos, Demetri and Fei-Fei, Li and Gao, Jianfeng and Vo, Hoi},
  booktitle={Findings of the Association for Computational Linguistics: NAACL 2024},
  pages={3154--3183},
  year={2024}
}

@inproceedings{zhang2024proagent,
  title={ProAgent: building proactive cooperative agents with large language models},
  author={Zhang, Ceyao and Yang, Kaijie and Hu, Siyi and Wang, Zihao and Li, Guanghe and Sun, Yihang and Zhang, Cheng and Zhang, Zhaowei and Liu, Anji and Zhu, Song-Chun and others},
  booktitle={Proceedings of the AAAI Conference on Artificial Intelligence},
  volume={38},
  number={16},
  pages={17591--17599},
  year={2024}
}

