\section{Related Works}
With the rise of "seq2seq"~\cite{seq2014} models built on the Transformer~\cite{attention2017} architecture, natural language processing has stepped into its new the era of Large Language Model (LLM). Instruction fine-tuning technique~\cite{language2020} has enabled LLMs to demonstrated remarkable generality: they show the potential to outperform human performance in tasks such as mathematics~\cite{math2024}, programming~\cite{programming2023}, and logical reasoning~\cite{logicbench2024}. However, LLMs can still make naive mistakes on simple problems by generating seemingly correct but nonfactual or wrong answer~\cite{hallucination2024}.

Text preprocessing in modern language learning models (LLMs) primarily employs subword tokenization methods~\cite{google2016, subword2018}, with byte pair encoding (BPE)~\cite{neural2016} being one of the most widely used approaches. However, the subword tokenization paradigm has notable limitations that can hinder the nuanced understanding of internal structure of words~\cite{tokenization2024}. In this paper, we explore these limitations through a series of character-level tasks designed to assess LLMs' comprehension of words at the character level.

Current benchmarks that evaluate large language models' understanding of token composition reveal significant flaws and shortcomings in LLMs that use subword units as tokens. For instance, LMentry~\cite{lmentry2022} tests whether LLMs can distinguish between the first and last letters of a word or generate words containing a specific letter. Meanwhile, CUTE~\cite{cute2024} introduces more challenging tasks, such as asking LLMs to replace, delete, insert, or swap letters within words. The results demonstrate that even the most advanced LLMs still have considerable room for improvement on non-trivial token benchmarks. Our paper goes beyond evaluation, presenting not only underlying mechanism analysis but also effective methods.

A significant amount of research has been conducted on character-level models, where each individual character is treated as a separate token. Although the character-level models exhibited potential for better generalization, especially in scenarios involving rare words, but they often struggled with efficiency and performance on tasks that require more abstract linguistic knowledge.