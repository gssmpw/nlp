\section{Conclusion and Future Work}
In this paper, we introduce PersGuard, a novel backdoor-based framework designed to protect text-to-image (T2I) diffusion models from unauthorized personalization. Unlike existing protection methods that rely on adversarial perturbations, our approach operates directly at the model level, providing more robust and controllable protection. We propose three distinct backdoor mechanisms—pattern backdoor, erasure backdoor, and target backdoor—which are integrated into a unified optimization framework. By balancing the backdoor behavior loss, prior preservation loss, and backdoor retention loss, our method effectively preserves the model's normal generation capabilities for unprotected images while ensuring data privacy protection.Extensive experiments demonstrate that PersGuard successfully prevents unauthorized personalization without compromising the model’s performance on unprotected images. Our work opens new avenues for secure applications of diffusion models, and future research will focus on enhancing the backdoor's effectiveness in black-box scenarios and improving robustness in real-world applications.