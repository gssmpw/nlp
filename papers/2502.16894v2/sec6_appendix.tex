\section{Proof related with PiSSA Select Segment} \label{app:pissa}

\begin{tcolorbox}[colback=gray!20,colframe=gray]
\begin{lemma}
Let \( W_0 \in \mathbb{R}^{m \times n} \) be the pretrained weight matrix with SVD \( W_0 = U \Sigma V^\top \). Assuming \( m \leq n \) and LoRA rank \( r \), we decompose \( W_0 \) into rank-\( r \) blocks:
\begin{align}
W_0 = \sum_{i=0}^{l} U_i \Sigma_i V_i^\top,
\end{align}
where \(l=\frac{m}{r} - 1\) are block numbers, \( U_i = U_{[i \cdot r : (i+1) \cdot r, :]} \in \mathbb{R}^{r \times m} \), \( \Sigma_i = \Sigma_{[i \cdot r : (i+1) \cdot r, i \cdot r : (i+1) \cdot r]} \in \mathbb{R}^{r \times r} \), and  \( V_i = V_{[i \cdot r : (i+1) \cdot r, :]} \in \mathbb{R}^{r \times n} \) are submatrices of \( U, \Sigma, V \).

We demonstrate that \( U_0 \Sigma_0 V_0^\top \) has the largest norm and is the best rank-\( r \) approximation of \( W_0 \).
\end{lemma}
\end{tcolorbox}

\begin{proof}
By the singular value decomposition (SVD), \( W_0 = \sum_{i=1}^{\min(m, n)} \sigma_i u_i v_i^\top \), where \( \sigma_i \) are singular values sorted in descending order (\( \sigma_1 \geq \sigma_2 \geq \cdots \)).

For each block \( U_i \Sigma_i V_i^\top \), the Frobenius norm can be written as:
\begin{align}
\|U_i \Sigma_i V_i^\top\|_F = \Big\|\sum_{j=i \cdot r}^{(i+1) \cdot r} \sigma_j u_j v_j^\top \Big\|_F.
\end{align}
Since the Frobenius norm satisfies the property of orthogonal invariance, we can simplify this expression:
\begin{align}
\|U_i \Sigma_i V_i^\top\|_F = \sqrt{\sum_{j=i \cdot r}^{(i+1) \cdot r} \sigma_j^2}.
\end{align}
This result shows that the norm of each block \( U_i \Sigma_i V_i^\top \) depends solely on the singular values \( \sigma_j \) within the block. As the singular values are sorted in descending order (\( \sigma_1 \geq \sigma_2 \geq \cdots \)), the block \( U_0 \Sigma_0 V_0^\top \), which contains the largest \( r \) singular values (\( \sigma_1, \ldots, \sigma_r \)), has the largest Frobenius norm:
\begin{align}
\|U_0 \Sigma_0 V_0^\top\|_F = \sqrt{\sum_{j=1}^r \sigma_j^2}.
\end{align}

By the Eckart–Young–Mirsky theorem, the best rank-\( r \) approximation of \( W_0 \) minimizes the reconstruction error:
\begin{align}
\|W_0 - W_0^{(r)}\|_F = \min_{X : \text{rank}(X) \leq r} \|W_0 - X\|_F,
\end{align}
where \( W_0^{(r)} = U_0 \Sigma_0 V_0^\top \). Therefore, \( U_0 \Sigma_0 V_0^\top \) not only has the largest norm but also preserves the most significant information in \( W_0 \), making it the optimal rank-\( r \) approximation.
\end{proof}

\section{Load Balance Loss}\label{sec:lb}

In vanilla MoE methods \cite{fedus2022switch,dai2024deepseekmoeultimateexpertspecialization}, a balance loss $\mathcal{L}_b$ mitigates routing collapse by ensuring even token distribution among experts:
\begin{align}
    \mathcal{L}_b &= \sum_{i=1}^E f_i P_i \label{eq:lb} \\
    f_i &= \frac{E}{kT} \sum_{t=1}^T \mathds{1}(\text{Token } x_t \text{ assigned to expert } i) \label{eq:f} \\
    P_i &= \frac{1}{T} \sum_{t=1}^T \text{softmax}(z^i(x_t))
\end{align}
where $T$ is the number of tokens and $\mathds{1}(\cdot)$ is the indicator function. Here, $f_i$ is the fraction of tokens assigned to expert $i$, and $P_i$ is the average routing probability for expert $i$. This loss promotes an even distribution of tokens across experts.

\section{Proof of Theoretical Results}
\newtheorem*{lemma2}{Lemma}
\newtheorem*{Theorem2}{Theorem}

\subsection{Proof of Lemma~\ref{th:tidle_g}}
\begin{tcolorbox}[colback=gray!20,colframe=gray]
\begin{lemma2}[2.2]
Let \( g_t \) be the full-tuning gradient, and \( B, A \) be low-rank weights. At the \( t \)-th optimization step, the equivalent gradient can be expressed as:
\begin{equation}
    \tilde{g}_t = s^2 \left( B_t {B_t}^\top g_t + g_t {A_t}^\top A_t \right)
\end{equation}
\end{lemma2}
\end{tcolorbox}

\begin{proof}
% For simplicity, we omit the index \( i \).
According to the assumption, $\tilde W_{t} = W_{t}$.
Let LoRA $sBA$ where $B \in \sR^{m \times r}, A \in \sR^{r \times n}$ , $s \in \sR$, the loss $\gL$, the $t^{th}$ update of SGD optimizer.
We denote  $\tilde W_t = W_{\text{init}} + sB_tA_t$, we can write the gradient of $B,A$ as:
\begin{align}
G^B_t = \pderiv{L}{\tilde W_t} \pderiv{\tilde W_t}{B} = \pderiv{L}{ W_t} \pderiv{\tilde W_t}{B} = s{g_{t}}A^\top \\
% m * r = m * n * n * r 
G^A_t = \pderiv{L}{\tilde W_t} \pderiv{\tilde W_t}{A} = \pderiv{L}{W_t} \pderiv{\tilde W_t}{A} = sB^\top {g_{t}}
% r * n = r * m * m * n 
\end{align}
In the gradient descend algorithm (SVD), the updates for \( B_t \) and \( A_t \) are
\begin{align}
\dd B_t = - \eta G^B_t = -s \eta g_{t} A_t^\top, \dd A_t = -\eta G^A_t = -s \eta B_t^\top g_{t}
\end{align}
% where \( \eta \) is the learning rate.
% \begin{align}
%     B_t = B_0 - \eta s \sum_{k=0}^{t-1} \tilde{g_{t-1}}_k A_k^\top \\
%     A_t = A_0 - \eta s \sum_{k=0}^{t-1} B_k^\top \tilde{g_{t-1}}_k
% \end{align}
The change in the equivalent weight \( \tilde{W} \) can be expressed as:
\begin{align}
\dd \tilde{W} &= \frac{\partial \tilde{W_t}}{\partial A_t} \dd A_t + \frac{\partial \tilde{W_t}}{\partial B_t} \dd B_t \\
&= s \cdot B_t \dd A_t + s \cdot \dd B_t A_t \\
&= s \left( B_t (-\eta s B_t^\top g_{t}) + (-\eta s g_{t} A_t^\top) A_t \right) \\
&= -\eta s^2 \left( B_t B_t^\top g_{t} + g_{t} A_t^\top A_t \right)
\end{align}
Therefore, the equivalent gradient \( \tilde{g}_t \) is given by:
\begin{align}
\tilde{g}_t = s^2 \left( B_t B_t^\top g_{t} + g_{t} A_t^\top A_t \right)
\end{align}
This concludes the proof.
\end{proof}

\subsection{Proof of Theorem~\ref{th:align}}

\begin{tcolorbox}[colback=gray!20,colframe=gray]
\begin{Theorem2}[3.1]
Let the learning rate in Full FT and LoRA be $\eta_{\text{FFT}}, \eta_\text{LoRA}$.
By ensuring equivalent weight \( \tilde{W}_0 \approx W_0 \) at initialization and maintaining equivalent gradient \( \eta_{\text{LoRA}}\tilde{g}_t \approx \eta_{\text{FFT}} g_t \)  throughout each optimization step, we can effectively align LoRA with Full FT. (Equivalent weight and gradient are defined in Definition~\ref{def:eg}.)
\end{Theorem2}
\end{tcolorbox}

\begin{proof}
We verify this alignment using induction. The equivalent weight is defined as \( \tilde{W}_t = W_{\text{init}} + sB_tA_t \), and the equivalent gradient is \( \tilde{g}_t = \frac{\partial L}{\partial \tilde{W}} \).   
Using the gradient descent algorithm (considering only the SGD optimizer), we have:
\begin{align}
W_{t+1} = W_{t} - \eta_{\text{FFT}} g_t \\
\tilde W_{t+1} = \tilde W_t - \eta_\text{LoRA} \tilde g_{t}
\end{align}

\textit{Base Case (\( t = 0 \))}: We have ensured \( \tilde{W}_0 = W_0 \).

\textit{Inductive Step:} 
Assume \( \tilde{W}_t = W_t \) and \( \tilde{g}_t = g_t \). Then:
\begin{align}
    \tilde{W}_{t+1} &= \tilde{W}_t - \eta_{\text{LoRA}} \tilde{g}_t \\
                     &= W_t - \eta_{\text{FFT}} g_t \\
                     &= W_{t+1}.
\end{align}

By induction, \( \tilde{W}_t = W_t \) for all \( t \), ensuring the alignment between LoRA and Full FT.
\end{proof}

\subsection{Proof of Theorem~\ref{th:moe_align}}
\begin{tcolorbox}[colback=gray!20,colframe=gray]
\begin{Theorem2}[3.2]
Let the learning rate in Full FT MoE and LoRA MoE be $\eta_{\text{FFT}}, \eta_\text{LoRA}$.
For all \( i \in [1, \dots, E] \), by ensuring the equivalent weight of the \(i\)-th expert \( \tilde{W}^i_0 \approx W^i_0 \) at initialization and maintaining the equivalent gradient of the \(i\)-th expert \( \eta_{\text{LoRA}}\tilde{g}^i_t \approx \eta_{\text{FFT}}g^i_t \) throughout each optimization step, we can effectively align LoRA MoE with Full FT MoE.
\end{Theorem2}
\end{tcolorbox}

\begin{proof}
We aim to show that under the given conditions, the LoRA MoE aligns with the Full FT MoE by effectively making the MoE routers behave identically in both models.

\textit{Base Case (\( t = 0 \)):}  
At initialization, by assumption, the equivalent weights of each expert satisfy \( \tilde{W}^i_0 \approx W^i_0 \) because our Full FT MoE is an upcycling MoE which makes all \( W^i_0 = W_0\). Additionally, since both models use the same random seed, the routers are initialized identically, ensuring that the routing decisions are the same for both Full FT MoE and LoRA MoE.

\textit{Inductive Step:}  
Assume that at step \( t \), the equivalent weights satisfy \( \tilde{W}^i_t = W^i_t \) for all \( i \), and the routers in both models are identical. During the \( t \)-th optimization step, the gradients are scaled such that \( \eta_{\text{LoRA}}\tilde{g}^i_t \approx \eta_{\text{FFT}}g^i_t \). This ensures that the weight updates for each expert in both models are equivalent:

\begin{align}
\tilde{W}^i_{t+1} = \tilde{W}^i_t - \eta_{\text{LoRA}}\tilde{g}^i_t \approx W^i_t - \eta_{\text{FFT}}g^i_t = W^i_{t+1}
\end{align}

First, as the routers are identical, the router weight $w^i$ is the same, so the layer output is the same:
\begin{align}
    \mathrm{MoE}(\mathbf{x}) &= \sum_{i=1}^E w^i(\mathbf{x}) W^i(\mathbf{x})\\
    &= \sum_{i=1}^E w^i(\mathbf{x}) \tilde{W}^i (\mathbf{x}) \\
    &= \sum_{i=1}^E w^i(\mathbf{x}) (W + s B^i A^i) (\mathbf{x}) \\
    &= W(\mathbf{x}) + \sum_{i=1}^E w^i(\mathbf{x}) \left( s B^i A^i (\mathbf{x}) \right) \\
    &= \mathrm{MoE}_{\text{LoRA}}(\mathbf{x})
\end{align}

Since the weight updates are equivalent and the routers are optimized from the output induced by these weights, the routers remain identical at step \( t+1 \). Therefore, by induction, the routers are identical for all \( t \).

With identical routers, the routing decisions do not differentiate between Full FT MoE and LoRA MoE layers. Consequently, the alignment of individual experts (as established by Theorem~\ref{th:align}) ensures that the overall behavior of both MoE variants is effectively aligned.

\end{proof} 

\subsection{Proof of Lemma~\ref{th:lema}}
% \section{The Expectation and Variance of Expert Weights}
\begin{tcolorbox}[colback=gray!20,colframe=gray]
\begin{lemma2}[3.3]
Let $\Omega_k(\mathbf{x})$ be the set of indices corresponding to the top-$k$ largest values of $z^i(\mathbf{x})$, and \( z^i(\mathbf{x}) \) are independent and identically distributed (i.i.d.), and \( k \leq \frac{E}{2} \), $w^i$ is defined as:
\begin{equation}
    w^i(\mathbf{x}) = 
    \begin{cases} 
        \frac{\exp(z^i(\mathbf{x}))}{\sum_{j \in \Omega_k(\mathbf{x})} \exp(z^j(\mathbf{x})}) & \text{if } i \in \Omega_k(\mathbf{x}), \\
        0 & \text{if } i \notin \Omega_k(\mathbf{x}),
    \end{cases}
\end{equation}
 
We demonstrate the following properties for all \( i, j \in [1, \dots, E] \) (\( i \neq j \)):
\begin{align}
\mathbb{E}_{\mathbf{x}}[w^i(\mathbf{x})] &= \frac{1}{E}, \\
\text{Var}_{\mathbf{x}}(w^i(\mathbf{x})) &= \frac{E-k}{kE^2}.
% \text{Cov}(w^i(\mathbf{x}), w^j(\mathbf{x})) &= \frac{k-E}{kE^2(E-1)}.
\end{align}
\end{lemma2}
\end{tcolorbox}

\begin{proof}
Because the \(z^i(x)\) are i.i.d. random variables, any permutation of the indices \(\{1,\dots,E\}\) leaves the joint distribution of \(\{z^1(\mathbf{x}),\dots,z^E(\mathbf{x})\}\) unchanged.  
The Top-K operation (pick the indices of the largest \(K\) logits) is also symmetric with respect to permutations: permuting \((z^1,\dots,z^E)\) accordingly permutes the set \(\Omega_k(\mathbf{x})\) of selected indices.
Because of this symmetry, each \(w^i(\mathbf{x})\) is distributed in the same way as \(w^j(\mathbf{x})\) for any \(j\). 
By definition of $w^i(\mathbf{x})$, we have $\forall \mathbf{x}, \sum_{i=1}^E w^i(\mathbf{x}) = 1$, so: 
\vspace{-5pt}
\begin{align}
    \sum_{i=1}^E \mathbb{E}[w^i(\mathbf{x})] 
    &= \mathbb{E}\Bigl[\sum_{i=1}^E w^i(\mathbf{x})\Bigr]
    = \mathbb{E}[1]
    = 1, \\
    \mathbb{E}_{\mathbf{x}}[w^i(\mathbf{x})] &= \frac{1}{E}, \forall i \in [1,\cdots, E]
\end{align}

The variance of \( w^i(\mathbf{x}) \) is given by:

\begin{align}
\text{Var}_{\mathbf{x}}(w^i(\mathbf{x})) = \mathbb{E}_{\mathbf{x}}\left[ \left( w^i(\mathbf{x}) \right)^2 \right] - \left( \mathbb{E}_{\mathbf{x}}\left[ w^i(\mathbf{x}) \right] \right)^2.
\end{align}

Since \( \mathbb{E}_{\mathbf{x}}\left[ w^i(\mathbf{x}) \right] = \frac{1}{E} \), we have:

\begin{align}
\text{Var}_{\mathbf{x}}(w^i(\mathbf{x})) = \mathbb{E}_{\mathbf{x}}\left[ \left( w^i(\mathbf{x}) \right)^2 \right] - \frac{1}{E^2}.\label{eq:var}
\end{align}

We aim to compute \( \mathbb{E}_{\mathbf{x}}\left[ \left( w^i(\mathbf{x}) \right)^2 \right] \), but it's tricky to directly obtain this expectation.  Given that $\sum_{i=1}^E w_i = 1$, 
we can expand this expression. Omitting the \(\mathbf{x}\) for simplicity, we get:

\begin{align}
1 &= \left( \sum_{i=1}^E w_i \right)^2 = \mathbb{E}\left[ \left( \sum_{i=1}^E w_i \right)^2 \right] = \mathbb{E}\left[ \sum_{i=1}^E w_i^2 \right] + \sum_{i\neq j} \mathbb{E}[w_i w_j], \\
1&= E \cdot \mathbb{E}[w_i^2] + E(E-1) \cdot \mathbb{E}_{i\neq j}[w_i w_j]. \label{eq:E}
\end{align}
where \( \mathbb{E}[w_i w_j] \) is the expectation we need to compute. This expression is derived based on the rotational symmetry of \(w_i, w_j\), which means the cross-term \( \mathbb{E}[w_i w_j] \) is the same for all distinct \(i \neq j\).

To compute \( \mathbb{E}[w_i w_j] \), we rewrite the weights \( w_i \) as follows:
\begin{align}
w_i = \frac{\exp z_i}{\sum_{j \in \Omega_k} \exp z_j} = \frac{y_i}{\sum_{j \in \Omega_k} y_j},
\end{align}

where

\begin{align}
y_i = 
\begin{cases} 
\exp z_i & \text{if } i \in \Omega_k(\mathbf{x}), \\
0 & \text{if } i \notin \Omega_k(\mathbf{x}).
\end{cases}
\end{align}

Thus, the product \( w_i w_j \) becomes:

\begin{align}
w_i w_j = \frac{y_i y_j}{\left( \sum_{j \in \Omega_k} y_j \right)^2}.
\end{align}

Now, due to rotational symmetry of the terms \( y_i, w_j \), we can compute:

\begin{align}
\mathbb{E}[w_i w_j] = \frac{{k \choose 2}}{{E \choose 2}} \mathbb{E}\left[\frac{y_i y_j}{\left( \sum_{j \in \Omega_k} y_j \right)^2}\right] = \frac{k(k-1)}{E(E-1)} \cdot \frac{1}{k^2} = \frac{k-1}{E(E-1)k}.
\end{align}

Substituting this back into \Eq{eq:E} for \( \mathbb{E}[w_i^2] \):

\begin{align}
1 = E \cdot \mathbb{E}[w_i^2] + E(E-1) \cdot \frac{k-1}{E(E-1)k},
\end{align}

we get:

\begin{align}
\mathbb{E}[w_i^2] = \frac{1}{Ek}.
\end{align}

Thus, the variance of \( w^i \) in \Eq{eq:var} is:

\begin{align}
\text{Var}(w^i) = \frac{1}{Ek} - \frac{1}{E^2} = \frac{E-k}{kE^2}.
\end{align}

\end{proof}

\subsection{Proof of Theorem~\ref{th:wi}}
\begin{tcolorbox}[colback=gray!20,colframe=gray]
\begin{Theorem2}[3.4]
Consider the optimization problem:
\begin{equation}
    W_{\text{res}}^+ = \arg\min_{W_{\text{res}}} \mathbb{E}_{\mathbf{x}} \left[ \left\| W_{\text{res}} - s \sum_{i=1}^E w^i(\mathbf{x}) B^i_0 A^i_0 \right\|^2 \right].
\end{equation}
The closed-form solution is \( W_{\text{res}}^+ = \frac{s}{E} \sum_{i=1}^E B^i_0 A^i_0 \).
\end{Theorem2}
\end{tcolorbox}

\begin{proof}

% We  aimed at finding the optimal value for \( W_{res} \) by minimizing the expected squared difference between \( W_{res} \) and a sum of weighted matrices \( B^i_0 A^i_0 \), where the weights \( w^i(\mathbf{x}) \) are determined by the elements \( i \) that belong to the set \( \Omega_k(\mathbf{x}) \). This can be mathematically expressed as follows:
% \vspace{-5pt}

\( W_{res}^+ \) denotes the optimal value of \( W_{res} \).
The solution to this optimization problem, \( W_{res} \), can be derived as the expected value over all possible \( \mathbf{x} \):
\vspace{-5pt}
\begin{align}
W_{\text{res}}^+ &= s \mathbb{E}_{\mathbf{x}} \Biggl[ \sum_{i=1}^E w^i(\mathbf{x}) B^i_0 A^i_0 \Biggr] \label{eq:tmp1}\\ 
&= s \sum_{i=1}^E \mathbb{E}_{\mathbf{x}} [ w^i(\mathbf{x}) ] B^i_0A^i_0 \label{eq:tmp2}\\&=   \frac{s}{E} \sum_{i=1}^E B^i_0 A^i_0 
\end{align}
where \Eq{eq:tmp1} use the linear property of expectation and \Eq{eq:tmp2} utilize Lemma~\ref{th:lema}.
% So 

% \begin{align}
% \mathbf{x} \sim \mathcal{N}(0,\sigma_x^2 I_{h \times h}) \\
% % z^i(\mathbf{x}) \sim \mathcal{N}\left(0, \frac{\sigma_x^2}{3}\right), \\
% z(\mathbf{x}) = [z^1(\mathbf{x}), \cdots, z^E(\mathbf{x})] \sim \mathcal{N}\left(0, \frac{\sigma_x^2}{3} I_{E \times E}\right), \\
% w^i(\mathbf{x}) = \frac{e^{z^i(\mathbf{x})}}{\sum_{j \in \text{Top-}k} e^{z^j(\mathbf{x})}}
% \end{align}


% When in  mini-batch stochastic gradient scenarios:
% \vspace{-5pt}
% \begin{align}
% \mathbb{E}_{x_1 \ldots x_B \sim \rho} \left[  s \frac{1}{BL}\sum_{j=1}^{BL}\sum_{i=1}^E w^i(\mathbf{x}_j) B^i_0 A^i_0 \right] =  \frac{s}{E} \sum_{i=1}^E B^i_0 A^i_0 \label{eq:Ebatch}
% % \sum_{i=1}^E s w^i(\mathbf{x}_j) B^i_0 A^i_0  =  \frac{s}{E} \sum_{i=1}^E B^i_0 A^i_0 
% \end{align}

\end{proof}

% \subsection{Proof of Theorem~\ref{th:var}}
% \begin{tcolorbox}[colback=gray!20,colframe=gray]
% \begin{Theorem2}[3.3]
% The variance of \( W_{\text{res}}^+ - s \sum_{i=1}^E w^i(\mathbf{x}) B^i_0 A^i_0 \) is proportional to \( \sum_{i=1}^E B^i_0 A^i_0 \).
% \end{Theorem2}
% \end{tcolorbox}

% \begin{proof}

% We abbreviate \( B_0^iA_0^i \) as \( C_0^i \) and we study the variance of each entry $i,j$:  

% \begin{align}
% \text{Var} ()
% \end{align}

% % \text{Var} \bigl( \sum_{i=1}^E w^i(\mathbf{x}) C^i \bigr)&=\sum_{i=1}^E \text{Var} \bigl(  w^i(\mathbf{x}) \bigr) (C^i)^2 + \sum_{i\neq j} \text{Cov}(w^i, w^j) Cov(C^i,C^j) \\
% % &=\text{Var}_C \sum_{i=1}^E (C^i)^2 + \text{Cov}_C \sum_{i\neq j}  C^i C^j \\
% % &=\frac{E-k}{kE^2} \sum_{i=1}^E (C^i)^2  + \frac{k-E}{kE^2(E-1)} \sum_{i\neq j}  C^iC^j

% It can be observed that \( B_0^i \) and \( B_0^j \), when \( i \neq j \), are two orthogonal vectors extracted from \( U \) in the SVD decomposition. The same applies to \( A \). Therefore, when \( i \neq j \), \( \text{Cov}(C_i, C_j) = 0 \), and the covariance terms in the above equation can be ignored. As a result, we can derive the expected variance as follows:
% \begin{align}
% \mathbb{E} \left[\text{Var} \bigl( \sum_{i=1}^E w^i(\mathbf{x}) B^i_0 A^i_0 \bigr)\right] =\frac{E-k}{kE^2} \sum_{i=1}^E (C^i)^2 
% \end{align}

% \end{proof}






\subsection{Proof of Theorem~\ref{th:s}}
\begin{tcolorbox}[colback=gray!20,colframe=gray]
\begin{Theorem2}[3.5]
Consider the optimization problem where \( B_0 = 0 \) and \( A_0 \sim U\left(-\sqrt{\frac{6}{n}}, \sqrt{\frac{6}{n}}\right) \), $\tilde{g}_t^i = s^2 \left( B_t^i {B_t^i}^\top g_t^i + g_t^i {A_t^i}^\top A_t^i \right)$, the ratio between full tuning learning rate \vs LoRA learning rate $\eta$. 
\begin{equation}
    \arg\min_{s} \left\| \tilde{g}_t^i - g_t^i \right\|, \quad \forall i \in [1, \dots, E]
\end{equation}
The closed-form solution is \( s = \sqrt{\frac{3n\eta}{r}} \).
\end{Theorem2}
\end{tcolorbox}

\begin{proof}
By analyzing the first step gradient, 
\begin{align}
    % m *n =  m*r r*m m* n + m*n n*r r*n
    \tilde{g}_0 = s (B_0 G^A_0 + G^B_0 A_0) = s^2 ( B_0 B^\top_0 g_0 + g_0 A^\top_0 A_0 ) 
\end{align}

\vspace{-5pt}
\begin{align}
    % m *n =  m*r r*m m* n + m*n n*r r*n
    \arg\min_{s} \left\| s^2 \underbrace{\left( B_0 B^\top_0 g_0 + g_0 A^\top_0 A_0 \right)}_{\text{rank} < 2r} - \eta g_0 \right\|
\end{align}
As LoRA init $B_0=0$ and $A_0\sim U(-{\sqrt{\frac{6}{n}}}, {\sqrt{\frac{6}{n}}})$. The above equation becomes 
\vspace{-5pt}
\begin{align}
    % m *n =  m*r r*m m* n + m*n n*r r*n
    \arg\min_{s} \left\| \underbrace{s^2\left( g_0 A^\top_0 A_0 \right)}_{\text{rank} < 2r} - \eta g_0 \right\| 
\end{align}

First We notice that the matrix \( A_0^\top A_0 \) can express the entries in the following way 
\begin{align}
    A_0^\top A_0[i,j] = \sum_{k=1}^r A_0[i,k] A_0^\top[k,j],
\end{align}
For the diagonal entries (\( i = j \)), the formula simplifies to:
\begin{align}
(A_0^\top A_0)_{i,i} = \sum_{k=1}^r A_{0, i, k}^2  = \sigma_A
\end{align}
This is because the entries of \( A_0 \) are i.i.d. with mean \( 0 \) and variance \( \sigma_A \), we can compute:
\begin{align}
\mathbb{E}[(A_0^\top A_0)_{i,i}] = \sum_{k=1}^r \mathbb{E}[A_{0, i, k}^2] = r \sigma_A
\end{align}
For the non-diagonal entries (\( i \neq j \)), the formula is:
\begin{align}
(A_0^\top A_0)_{i,j} = \sum_{k=1}^r A_0^\top[i, k] A_0[k, j] = 0
\end{align}
Since \( A_0^\top[i, k] \) and \( A_0[k, j] \) are independent random variables (for \( i \neq j \)), their product has an expected value of zero.
\begin{align}
\E_{A_0}[A_0^\top A_0] = {r} \sigma_A \rmI_{n \times n}
\end{align}

Given that $\E_{A_0}[A_0^\top A_0] = \frac{r}{3n} \rmI_{n \times n}$ (use Leaky ReLU with negative slope $
\sqrt{5}$, that is $\text{Var}(A) = \frac{1}{3n}$), we can get  $s = \sqrt{\frac{ 3n\eta}{r}}$

\vspace{-5pt}
\begin{align}
    % m *n =  m*r r*m m* n + m*n n*r r*n
    \left\| g_0 \left( \frac{s^2r}{3n} \mathbf{I} - \eta \mathbf{I} \right) \right\| = 0 ,\quad s = \sqrt{\frac{ 3n\eta}{r}}
\end{align}

Though it is derived by the first step gradient, as in practice, the weight change $\|\frac{\dd W}{W}\|$ is typically small (thus has the low-rank update hypnosis in \citet{hulora}), we can consider $\|\frac{\dd A}{A}\|$ and $\|\frac{\dd B}{B}\|$ is small, so the above \(s\) can be extended to the following steps. 

\end{proof}

\section{Extend Our Method to Scenarios with Proper Scaling}\label{app:goat_pro}
GOAT assumes a scenario where LoRA MoE has not been properly scaled. Here, we supplement it with an extended approach for scenarios where proper scaling has been applied.

% By analyzing the first-step gradient for each expert, we have:

% \[
% \tilde{g}_0^i = s_i \left( B_0^i G^{A^i}_0 + G^{B^i}_0 A^i_0 \right) = s_i^2 \left( B^i_0 {B^i}^\top_0 g^i_0 + g^i_0 {A^i}^\top_0 A^i_0 \right)
% \]

Here, we assume that the routing strategy of the fully fine-tuned MoE aligns with our method. Since the router is non-differentiable, we ignore its impact and focus solely on the gradient of each expert. Our goal is to align the gradient of each expert in our method with that of the fully fine-tuned MoE. Thus, for the \(i\)-th expert, we aim to solve:

\begin{align}
\arg\min_{s_i} \left\| s_i^2 \underbrace{\left( B^i_0 {B^i}^\top_0 g^i_0 + g^i_0 {A^i}^\top_0 A^i_0 \right)}_{\text{rank} < 2r} - g^i_0 \right\|
\end{align}

When using the balanced initialization strategy, the above equation can be rewritten as:

\begin{align}
\arg\min_{s_i} \left\| s_i^2 \underbrace{\left( u_i u_i^\top \sigma_i^2 g^i_0 + g^i_0 \sigma_i^2 v_i^\top v_i \right)}_{\text{rank} < 2r} - g^i_0 \right\|
\end{align}

If each expert has rank 1, the equation can be further simplified to:

\begin{align}
\arg\min_{s_i} \left\| s_i^2 \sigma_i^2 \underbrace{\left( u_i u_i^\top g^i_0 + g^i_0 v_i^\top v_i \right)}_{\text{rank} < 2r} - g^i_0 \right\|
\end{align}

From this, we can observe that \textbf{\(\sigma_i\) acts as a scaling factor for the gradient, stretching or compressing the direction represented by the current expert during optimization.} Here, we assume that the hyperparameters have already been correctly scaled for the first expert (which corresponds to the optimal low-rank approximation of the original matrix), aligning it with the first expert of the fully fine-tuned MoE. Since the stretching strategy for the direction represented by each expert should remain consistent during MoE fine-tuning, we need to align the scaling factors \(s_i\) for the other experts to reduce the gap between our method and full MoE fine-tuning. Specifically, \(s_i\) must satisfy the following condition:

\begin{align}
s_1^2 \sigma_0 = s_i^2 \sigma_i
\end{align}

Thus, we transform each \(s_i\) as follows:

\begin{align}
s_i = s_i \frac{\sqrt{\sigma_0}}{\sqrt{\sigma_i}}
\end{align}

When the rank of each expert is greater than 1, we approximate the solution by using the sum of the singular values within the segment.

Here, we modify the scaling of all experts except the first one, while keeping other initialization methods consistent with ~\ref{eq:initAB}.

We refer to this extended method as GOAT+, and its performance across all benchmarks is presented in Table~\ref{tab:goat_pro}. While designed for different scenarios, it demonstrates performance comparable to GOAT.
\begin{table}[ht]
\centering
\begin{tabular}{l*{5}{c}} \toprule
\textbf{Method} & \textbf{NLG(Avg.)} & \textbf{NLU(Avg.)} & \textbf{IC(Avg.)} & \textbf{CR(Avg.)} & \textbf{Avg.} \\ \midrule
\textbf{GOAT}   & 30.60      & 89.76     & 81.49    & 82.64    & 71.12 \\
\textbf{GOAT+}  & 30.54      & 89.61     & 81.54    & 82.41    & 71.02 \\ \bottomrule
\end{tabular}
\caption{Performance comparison of our method extended to properly scaled scenarios.}
\label{tab:goat_pro}
\end{table}


\section{Experiment Details}\label{app:imple}

\subsection{Dataset details} \label{app:dataset}
\paragraph{Natural Language Understanding Tasks.}
We evaluate our model on the following natural language understanding tasks from the GLUE benchmark~\cite{wang2018glue}:  
\begin{enumerate}
\item \textbf{CoLA}~\cite{warstadt-etal-2019-neural}: A binary classification task that requires determining whether a given sentence is grammatically acceptable.  
\item \textbf{SST-2}~\cite{socher2013recursive}: A sentiment analysis task where the goal is to classify sentences as expressing positive or negative sentiment.  
\item \textbf{MRPC}~\cite{dolan2005automatically}: A binary classification task focused on identifying whether two sentences in a pair are semantically equivalent.  
\item \textbf{QQP}~\cite{wang2017bilateral}: A binary classification task to determine whether two questions from Quora have the same meaning.  
\item \textbf{MNLI}~\cite{williams2018broad}: A textual entailment task that involves predicting whether a hypothesis is entailed, contradicted, or neutral with respect to a given premise.  
\item \textbf{QNLI}~\cite{rajpurkar-etal-2016-squad}: A binary classification task to determine whether a question is answerable based on a given context.  
\item \textbf{RTE}~\cite{giampiccolo2007third}: A textual entailment task where the goal is to predict whether a hypothesis logically follows from a given premise.
\end{enumerate}
We report the overall accuracy (including matched and mismatched) for MNLI, Matthew’s correlation coefficient for CoLA, and accuracy for all other tasks.
\paragraph{Natural Language Generation Tasks.}

We evaluate our model on the following natural language generation tasks:  

\begin{enumerate}
\item \textbf{MT-Bench}~\cite{zheng2023judging}: A benchmark for evaluating dialogue generation capabilities, focusing on multi-turn conversational quality and coherence.  
\item \textbf{GSM8K}~\cite{cobbe2021training}: A mathematical reasoning task designed to assess the model's ability to solve grade school-level math problems.  
\item \textbf{HumanEval}~\cite{chen2021evaluating}: A code generation benchmark that measures the model's ability to write functional code snippets based on natural language problem descriptions.
\end{enumerate}

Following previous work~\cite{wanglora}, we evaluate three natural language generation tasks—dialogue, mathematics, and code—using the following three datasets for training:
\begin{enumerate}
\item \textbf{Dialogue: WizardLM}~\cite{xu2023wizardlm}: WizardLM leverages an AI-driven approach called Evol-Instruct. Starting with a small set of initial instructions, Evol-Instruct uses an LLM to rewrite and evolve these instructions step by step into more complex and diverse ones. This method allows the creation of large-scale instruction data with varying levels of complexity, bypassing the need for human-generated data. We use a 52k subset of WizardLM to train our model for dialogue task (MT-bench).
\item \textbf{Math: MetaMathQA}~\cite{yumetamath}:  MetaMathQA is a created dataset designed specifically to improve the mathematical reasoning capabilities of large language models. We use a 100k subset of MetaMathQA to train our model for math task (GSM8K).
\item \textbf{Code: Code-Feedback}~\cite{zheng2024opencodeinterpreter}: This dataset includes examples of dynamic code generation, execution, and refinement guided by human feedback, enabling the model to learn how to improve its outputs iteratively. We use a 100k subset of Code-Feedback to train our model for code task (HumanEval).
\end{enumerate}

\paragraph{Image Classification Tasks.}
We evaluate our model on the following image classification tasks:
\begin{enumerate}
    \item \textbf{SUN397}~\cite{xiao2016sun}: A large-scale scene classification dataset containing 108,754 images across 397 categories, with each category having at least 100 images.
    \item \textbf{Cars} (Stanford Cars)~\cite{krause20133d}: A car classification dataset featuring 16,185 images across 196 classes, evenly split between training and testing sets.
    \item \textbf{RESISC45}~\cite{cheng2017remote}: A remote sensing scene classification dataset with 31,500 images distributed across 45 categories, averaging 700 images per category.
    \item \textbf{EuroSAT}~\cite{helber2019eurosat}: A satellite image classification dataset comprising 27,000 geo-referenced images labeled into 10 distinct classes.
    \item \textbf{SVHN}~\cite{netzer2011reading}: A real-world digit classification dataset derived from Google Street View images, including 10 classes with 73,257 training samples, 26,032 test samples, and 531,131 additional easy samples.
    \item \textbf{GTSRB}~\cite{stallkamp2011german}: A traffic sign classification dataset containing over 50,000 images spanning 43 traffic sign categories.
    \item \textbf{DTD}~\cite{cimpoi2014describing}: A texture classification dataset with 5,640 images across 47 classes, averaging approximately 120 images per class.
\end{enumerate}

\paragraph{Commonsense Reasoning Tasks}

We evaluate our model on the following commonsense reasoning tasks:  
\begin{enumerate}
\item \textbf{BoolQ}~\cite{clark-etal-2019-boolq}: A binary question-answering task where the goal is to determine whether the answer to a question about a given passage is "yes" or "no."  
\item \textbf{PIQA} (Physical Interaction Question Answering)~\cite{bisk2020piqa}: Focuses on reasoning about physical commonsense to select the most plausible solution to a given problem.  
\item \textbf{SIQA} (Social IQa)~\cite{sap-etal-2019-social}: Tests social commonsense reasoning by asking questions about motivations, reactions, or outcomes in social contexts.  
\item \textbf{HellaSwag}~\cite{zellers-etal-2019-hellaswag}: A task designed to test contextual commonsense reasoning by selecting the most plausible continuation of a given scenario.  
\item \textbf{WinoGrande}~\cite{sakaguchi2021winogrande}: A pronoun coreference resolution task that requires reasoning over ambiguous pronouns in complex sentences.  
\item \textbf{ARC-e} (AI2 Reasoning Challenge - Easy)~\cite{clark2018thinksolvedquestionanswering}: A multiple-choice question-answering task focused on elementary-level science questions.  
\item \textbf{ARC-c} (AI2 Reasoning Challenge - Challenge)~\cite{clark2018thinksolvedquestionanswering}: A more difficult subset of ARC, containing questions that require advanced reasoning and knowledge.  
\item \textbf{OBQA} (OpenBookQA)~\cite{mihaylov-etal-2018-suit}: A question-answering task requiring reasoning and knowledge from a small "open book" of science facts.
\end{enumerate}

\subsection{Baseline details}\label{app:baseline}

\paragraph{Full-Finetune}
\begin{enumerate}
\item \textbf{Full FT} refers to fine-tuning the model with all parameters.
\item \textbf{Full FT MoE} refers to fine-tuning all parameters within a Mixture of Experts (MoE) architecture.
\end{enumerate}

\paragraph{Single-LoRA baselines}
\begin{enumerate}
\item \textbf{LoRA} \cite{hulora} introduces trainable low-rank matrices for efficient fine-tuning. 
\item \textbf{DoRA} \cite{liudora} enhances LoRA by decomposing pre-trained weights into magnitude and direction, fine-tuning the directional component to improve learning capacity and stability.
\item \textbf{PiSSA} \cite{meng2024pissa} initializes LoRA's adapter matrices with the principal components of the pre-trained weights, enabling faster convergence, and better performance.
\item \textbf{MiLoRA} \cite{wang2024miloraharnessingminorsingular} fine-tunes LLMs by updating only the minor singular components of weight matrices, preserving the principal components to retain pre-trained knowledge.
\item \textbf{rsLoRA} \cite{kalajdzievski2023rankstabilizationscalingfactor} introduces a new scaling factor to make the scale of the output invariant to rank
\item \textbf{LoRA-Dash} \cite{si2024unleashingpowertaskspecificdirections} enhances PEFT by leveraging task-specific directions (TSDs) to optimize fine-tuning efficiency and improve performance on downstream tasks.
\item \textbf{NEAT} \cite{zhong2024neatnonlinearparameterefficientadaptation} introduces a nonlinear parameter-efficient adaptation method to address the limitations of existing PEFT techniques like LoRA.
\item \textbf{KaSA} \cite{wang2024kasaknowledgeawaresingularvalueadaptation} leverages singular value decomposition with knowledge-aware singular values to dynamically activate knowledge that is most relevant to the specific task. 
% \item \textbf{LoRAPro}\cite{wang2024loraprolowrankadaptersproperly} aligns LoRA’s updates with the gradients of FFT to better approximate its behavior.
\end{enumerate}

\paragraph{LoRA MoE baseliness}
\begin{enumerate}
\item \textbf{MoLoRA} \cite{zadouri2024pushing} combines the Mixture of Experts (MoE) architecture with lightweight experts, enabling extremely parameter-efficient fine-tuning by updating less than 1\% of model parameters.
\item  \textbf{AdaMoLE} \cite{liu2024adamole} introducing adaptive mechanisms to optimize the selection of experts. 
\item \textbf{HydraLoRA} \cite{tian2024hydraloraasymmetricloraarchitecture} introduces an asymmetric LoRA framework that improves parameter efficiency and performance by addressing training inefficiencies.
\end{enumerate}

\subsection{Abaltion details}\label{app:ablation}
Here, we provide a detailed explanation of the construction of each initialization method.
Suppose $h=min(m,n),t=\frac{h}{E}$
\begin{enumerate}
\item \textbf{Ours (O)}: \(\mathcal{E}_r = \left\{(U_{ [:, k:k + d]}, \Sigma_{[k:k+d,k:k+d]}, V_{[k:k+d,:]}^\top) \mid k=(j-1)t,j = 1, \dots, E \right\}\)
\item  \textbf{Principal (P)}: \(\mathcal{E}_r = \left\{(U_{ [:, k:k + d]}, \Sigma_{[k:k+d,k:k+d]}, V_{[k:k+d,:]}^\top) \mid k=(j-1)d,j = 1, \dots, E \right\}\)
\item \textbf{Minor (M)}:\(\mathcal{E}_r = \left\{(U_{ [:, k:k + d]}, \Sigma_{[k:k+d,k:k+d]}, V_{[k:k+d,:]}^\top) \mid k=h-jd,j = 1, \dots, E \right\}\)
\item \textbf{Random (R)}:\(\mathcal{E}_r=(U_{ [:, k:k + d]}, \Sigma_{[k:k+d,k:k+d]}, V_{[k:k+d,:]}^\top)|k=tj,t=random(0,\frac{h}{d}-1),j=0,...,E-1\}\)
\end{enumerate}

\subsection{Implementation Details}\label{app:implementation}

Image classification and natural language understanding experiments are conducted on 8 Nvidia 4090 GPUs with 24GB of RAM each. Commonsense reasoning and natural language generation experiments are conducted on a single Nvidia A100 GPU with 80GB of RAM. For training and evaluating all models, we enabled bf16 precision.

\input{tables/hyperparameter}

\subsection{Hyperparameters}\label{app:hyper}

We fine-tune our model on each task using carefully selected hyperparameters to ensure optimal performance. Specific details for each task, including learning rate, batch size, number of epochs, and other configurations, are provided to ensure reproducibility and consistency across experiments. These details are summarized in Table~\ref{tab:cs_hyper}, Table~\ref{tab:cv_hyper}, Table~\ref{tab:nlu_hyper} and Table~\ref{tab:nlg_hyper}.
We set \(\rho\) to 10 and the ratio between the full fine-tuning learning rate and the LoRA learning rate \(\eta\) to 1.
% 

\section{Parameter and FLOPs Analysis}

\subsection{Parameter Analysis}\label{app:parameters}
Here, we provide a parameter analysis for each baseline and our method based on different backbones. We assume \( H \) represents the model dimension, \( r \) denotes the rank, \( e \) indicates the number of experts, \( L \) indicates the number of layers, \( V \) indicates the vocabulary size, $P$ indicates the patch size in ViT and $C$ indicates the number of channels in ViT. The analysis for RoBERTa-large, ViT-base, and LLAMA2 7B is as follows:

\paragraph{RoBERTa-large:} $H=1024, r=32, e=2, L=24, V=50265$. The activation parameters are \texttt{dense} from all attention and MLP layer. 


\begin{enumerate}
    \item \textbf{FFT (Full Fine-Tuning)}:
    \begin{itemize}
        \item \textbf{Total Parameters}: \( (12H^2 + 13H)L + VH \)
        \item \textbf{Breakdown}:
        \begin{itemize}
            \item Embedding layer: \( VH \)
            \item Attention mechanism: \( 4H^2 + 4H \)
            \item MLP layer: \( 8H^2 + 5H \)
            \item LayerNorm (2 layers): \( 4H \)
            \item Total per layer: \( 12H^2 + 13H \)
        \end{itemize}
    \end{itemize}
    \item \textbf{Full FT MoE}:
    \begin{itemize}
        \item \textbf{Total Parameters}: \( (12eH^2+2H+9He)L+VH \)
        \item \textbf{Proportion}: \( 698\% \)
    \end{itemize}
    \item \textbf{LoRA/PiSSA/MiLoRA/rsLoRA}:
    \begin{itemize}
        \item \textbf{Total Parameters}: \( 18HrL \)
        \item \textbf{Proportion}: \( 4.00\% \)
    \end{itemize}

    \item \textbf{DoRA}:
    \begin{itemize}
        \item \textbf{Total Parameters}: \( (18Hr + 6)L \)
        \item \textbf{Proportion}: \( 4.00\% \)
    \end{itemize}

    \item \textbf{MoLoRA/GOAT}:
    \begin{itemize}
        \item \textbf{Total Parameters}: \( (18Hr + 9He)L \)
        \item \textbf{Proportion}: \( 4.50\% \)
        \item \textbf{Breakdown}:
        \begin{itemize}
            \item Attention mechanism: \( 8Hr + 4He \)
            \item MLP layer: \( 10Hr + 5He \)
            \item Total per layer: \( 18Hr + 9He \)
        \end{itemize}
    \end{itemize}

    \item \textbf{HydraLoRA}:
    \begin{itemize}
        \item \textbf{Total Parameters}: \( (9Hr + 9He + 9Hr/e)L \)
        \item \textbf{Proportion}: \( 2.75\% \)
    \end{itemize}

    \item \textbf{AdaMoLE}:
    \begin{itemize}
        \item \textbf{Total Parameters}: \( (18Hr + 9He + 9H)L \)
        \item \textbf{Proportion}: \( 4.56\% \)
    \end{itemize}
\end{enumerate}

\paragraph{ViT-base:} $H=768, r=8, e=2, L=12, P=32, C=3$. The activation parameters include \texttt{q, k, v, o, fc1, fc2}.

\begin{enumerate}
    \item \textbf{FFT}:
    \begin{itemize}
        \item \textbf{Total Parameters}: \( (C+1)P^2H + (12H^2 + 2H)L + 3H + PH + H^2 \)
        \item \textbf{Breakdown}:
        \begin{itemize}
            \item Embedding layer: \( PH+H+(C+1)P^2H \)
            \item encoder (L layers): \( (12H^2+2H)L \)
            \item LayerNorm (1 layers): \( 2H \)
            \item Pooler: \( H^2 \)
        \end{itemize}
    \end{itemize}
    \item \textbf{Full FT MoE}:
    \begin{itemize}
        \item \textbf{Total Parameters}: \( (C+1)PPH + (12eH^2 + 2H + 9He)L + 3H + PH + H^2 \)
        \item \textbf{Proportion}: \( 770\% \)
    \end{itemize}
    \item \textbf{LoRA/PiSSA/MiLoRA}:
    \begin{itemize}
        \item \textbf{Total Parameters}: \( 18HrL \)
        \item \textbf{Proportion}: \( 1.49\% \)
    \end{itemize}
    \item \textbf{LoRA (rank=16)}:
    \begin{itemize}
        \item \textbf{Total Parameters}: \( 18HrL \)
        \item \textbf{Proportion}: \( 2.99\% \)
    \end{itemize}
    \item \textbf{LoRA (rank=32)}:
    \begin{itemize}
        \item \textbf{Total Parameters}: \( 18HrL \)
        \item \textbf{Proportion}: \( 5.98\% \)
    \end{itemize}
    \item \textbf{DoRA}:
    \begin{itemize}
        \item \textbf{Total Parameters}: \( (18Hr + 6)L \)
        \item \textbf{Proportion}: \( 1.49\% \)
    \end{itemize}
    \item \textbf{MoLoRA/GOAT}:
    \begin{itemize}
        \item \textbf{Total Parameters}: \( (18Hr + 9He)L \)
        \item \textbf{Breakdown}:
        \begin{itemize}
            \item Attention mechanism: \( 8Hr+4He \)
            \item MLP layer: \( 10Hr+5He \)
            \item Total per layer: \( 18Hr + 9He \)
        \end{itemize}
        \item \textbf{Proportion}: \( 2.24\% \)
    \end{itemize}
    \item \textbf{HydraLoRA}:
    \begin{itemize}
        \item \textbf{Total Parameters}: \( (9Hr + 9He + 9Hr/e)L \)
        \item \textbf{Proportion}: \( 1.58\% \)
    \end{itemize}
    \item \textbf{AdaMoLE}:
    \begin{itemize}
        \item \textbf{Total Parameters}: \( (18Hr + 9He + 9H)L \)
        \item \textbf{Proportion}: \( 2.33\% \)
    \end{itemize}
\end{enumerate}

\paragraph{LLAMA2-7B:} $H=4096, r=32, e=2, L=32, V=32000$. The activation parameters are \texttt{q, k, v, up, down}.

\begin{enumerate}
    \item \textbf{FFT}:
    \begin{itemize}
        \item \textbf{Total Parameters}: \( (10.25H^2 + 2H)L + H + 2VH \)
        \begin{itemize}
            \item Embedding layer and LM head: \( 2VH \)
            \item Attention mechanism: \( 2.25H^2 \)
            \item MLP layer: \( 8H^2 \)
            \item RMSNorm (2 layers): \( 2H \)
            \item Additional RMSNorm (last layer): \( H \)
            \item Total per layer: \( 10.25H^2 + 2H \)
        \end{itemize}
    \end{itemize}
    \item \textbf{LoRA/PiSSA/MiLoRA/LoRA-Dash/KASA}:
    \begin{itemize}
        \item \textbf{Total Parameters}: \( 11.58HrL \)
        \item \textbf{Proportion}: \( 0.84\% \)
    \end{itemize}
    \item \textbf{DoRA}:
    \begin{itemize}
        \item \textbf{Total Parameters}: \( (11.58Hr + 5)L \)
        \item \textbf{Proportion}: \( 0.84\% \)
    \end{itemize}
    \item \textbf{NEAT}:
    \begin{itemize}
        \item \textbf{Total Parameters}: \( (11.58Hr + 10r^2)L \)
        \item \textbf{Proportion}: \( 0.84\% \)
    \end{itemize}
    \item \textbf{MoLoRA/GOAT}:
    \begin{itemize}
        \item \textbf{Total Parameters}: \( (11.58Hr + 6.66He)L \)
        \begin{itemize}
            \item Attention mechanism: \( 4.25Hr+3He \)
            \item MLP layer: \( 7.33Hr+3.66He \)
            \item Total per layer: \( 11.58Hr + 6.66He \)
        \end{itemize}
        \item \textbf{Proportion}: \( 0.96\% \)
    \end{itemize}
    \item \textbf{HydraLoRA}:
    \begin{itemize}
        \item \textbf{Total Parameters}: \( (4.91Hr + 6.66Hr/e + 6.66He)L \)
        \item \textbf{Proportion}: \( 0.84\% \)
    \end{itemize}
    \item \textbf{AdaMoLE}:
    \begin{itemize}
        \item \textbf{Total Parameters}: \( (11.58Hr + 6.66He + 6.66H)L \)
        \item \textbf{Proportion}: \( 0.97\% \)
    \end{itemize}
\end{enumerate}

% \subsection{FLOPs Analysis} \label{app:flops}
% Since LLaMA 2 7B uses GQA (Grouped Query Attention) and SwiGLU FFN, the calculation of FLOPs differs from that of standard Transformers. Here, we assume that all linear layers in the Transformer block are extended with MoE (Mixture of Experts). We assume \( H \) represents the model dimension, \(s\) denotes sequence lengths, \( r \) denotes each expert rank, \( e \) indicates the number of experts, \( L \) indicates the number of layers, \( V \) indicates the vocabulary size. \textit{Notice each MAC (Multiply-Accumulate Operations) counts as two FLOPs.}

% \paragraph{FLOPs for FT MoE:\\ \\} 

% 1. MoE linear for \(q\) and \(o\): 
%    The FLOPs are calculated as \(2 \cdot ( 2Bshe + k \cdot 2Bsh^2)\).

% 2. MoE linear for \(k\) and \(v\): 
%    Since LLaMA 2 7B's GQA reduces the number of heads for \(k\) and \(v\) to \(1/8\) of \(q\)'s heads, the FLOPs are:  
%    \(2 \cdot (2Bshe + k \cdot 2Bshh/8)\).

% 3. The FLOPs for \(q \cdot k\) and \(score \cdot v\) remain independent of $k$, as we only upcycle the linear projection to \(e\) copies. The FLOPs for these operations are \(2Bs^2h + 2Bs^2h\).

% 4. MoE linear for \(down\) and \(gate\):  
%    Since LLaMA 2 7B uses SwiGLU FFN, the FLOPs are:  
%    \(2 \cdot (2Bshe + k \cdot 2Bsh \cdot 8/3h)\).

% 5. MoE linear for \(up\):  
%    The FLOPs are:  
%    \(2Bs \cdot 8/3he + k \cdot 2Bs \cdot 8/3hh\).

% Across \(L\) layers, including the vocabulary embedding transformation, the total FLOPs are:

% \begin{align}
%     \text{FLOPs}_{\text{Full FT MoE}} =  BL \left( \frac{52}{3}esh + \frac{41}{2}ksh^2 + 4s^2h \right)  + 2BshV
% \end{align}


\subsection{FLOPs Analysis} \label{app:flops}
Here, we mainly analyze the forward FLOPs. 
Since LLaMA 2 7B uses GQA (Grouped Query Attention) and SwiGLU FFN, the calculation of FLOPs differs from that of standard Transformers. Here, we assume that all linear layers in the Transformer block are extended with MoE (Mixture of Experts). We assume \( H \) represents the model dimension, \(s\) denotes sequence lengths, \( d \) denotes each expert rank, \( e \) indicates the number of experts, total rank \(r = ed\),\( L \) indicates the number of layers, \( V \) indicates the vocabulary size. \textit{Notice each MAC (Multiply-Accumulate Operations) counts as two FLOPs.}

\paragraph{FLOPs for FT MoE:\\ \\} 

1. MoE linear for \(q\) and \(o\): 
   The FLOPs are calculated as \(2 \cdot ( 2BsHe + k \cdot 2BsH^2)\).

2. MoE linear for \(k\) and \(v\): 
   Since LLaMA 2 7B's GQA reduces the number of heads for \(k\) and \(v\) to \(1/8\) of \(q\)'s heads, the FLOPs are:  
   \(2 \cdot (2BsHe + k \cdot 2BsHH/8)\).

3. The FLOPs for \(q \cdot k\) and \(score \cdot v\) remain independent of $k$, as we only upcycle the linear projection to \(e\) copies. The FLOPs for these operations are \(2Bs^2H + 2Bs^2H\).

4. MoE linear for \(down\) and \(gate\):  
   Since LLaMA 2 7B uses SwiGLU FFN, the FLOPs are:  
   \(2 \cdot (2BsHe + k \cdot 2BsH \cdot 8/3H)\).

5. MoE linear for \(up\):  
   The FLOPs are:  
   \(2Bs \cdot 8/3He + k \cdot 2Bs \cdot 8/3HH\).

Across \(L\) layers, including the vocabulary embedding transformation, the total FLOPs are:

\begin{align}
    \text{FLOPs}_{\text{Full FT MoE}} =  BL \left( \frac{52}{3}esH + \frac{41}{2}ksH^2 + 4s^2H \right)  + 2BsHV
\end{align}


\paragraph{FLOPs for GOAT/MoLoRA/HydraLoRA:\\ \\} 

1. MoE linear for \(q\) and \(o\):  
   The FLOPs are calculated as \(2B \cdot(2sH^2+ 2esH+ 2k(sHd + sHd))\).

2. MoE linear for \(k\) and \(v\): 
   Consider the effect of LLaMA 2 7B's GQA on \(k\) and \(v\) :  
   \( 2B \cdot (2sH^2/8 + 2esH+ 2k(sHd + sHd/8))\).

3. FLOPs for \(q \cdot k\) and \(score \cdot v\):  
   The FLOPs for these operations are \(2Bs^2H + 2Bs^2h\).

4. MoE linear for \(down\) and \(gate\):  
   Since LLaMA 2 7B uses SwiGLU FFN, the FLOPs are:  
   \(2B \cdot( 2sH · 8/3H + 2esH+2k\cdot(sHd+sd8/3H))\).

5. MoE linear for \(up\):  
   The FLOPs are:  
   \(2BsH · 8/3H + 2Bs8/3He+2k\cdot(Bs8/3Hd+BsrH)\).

Across \(L\) layers, including the vocabulary embedding transformation, the total FLOPs are:
\begin{align}
\text{FLOPs}_{\text{LoRA-MoE}} =   BL \left( \frac{52}{3}esH+ \frac{41}{2} sH^2 +4s^2H + \frac{69}{2}ksHd\right) + 2BsHV \\
=  BL \left( \frac{52}{3}esH+ \frac{41}{2} sH^2 +4s^2H + \frac{69}{2}\frac{k}{e}sHr\right) + 2BsHV
\end{align}