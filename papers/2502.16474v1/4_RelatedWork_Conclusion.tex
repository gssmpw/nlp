

\section{Related Work}


\paragraph{\textbf{Sequential Recommendation}} The use of deep learning in sequential recommendation has evolved into a well-established area of research. GRU4REC~\citep{gru4rec} pioneered the application of Gated Recurrent Unit (GRU)-based Recurrent Neural Networks (RNNs) for sequential recommender. Then SASRec~\citep{sasrec} utilized self-attention mechanisms~\cite{vaswani2017attention} of Transformer to capture the context relation of whole sequence. Building on the success of masked self-supervised learning in natural language processing, subsequent works such as BERT4Rec~\citep{bert4rec} leveraged self-supervised learning to randomly mask the historical items and improved the robustness. Apart from the popular self-attention and Transformer architecture, researchers have also explored the use of Convolution Neural Networks (CNNs)~\citep{CNN} in sequential recommender~\citep{caser}. In this paper, we focus on improving the sequential recommendation using semantic tokens.

\paragraph{\textbf{Quantized Representation Learning}} Vector-quantized learning has grabbed researchers' attention with its discrete latents to reduce the model variance. In recommender systems, VQ-Rec~\citep{vqrec} proposes a transferable method to quantize item content embedding as item representation. When VQ-Rec utilizes product quantization~\citep{jegou2010product} for the generation of semantic codes, TIGER~\citep{rajput2024recommender} further leverages RQ-VAE to produce hierarchical semantic IDs as item representation. In parallel to TIGER, another work~\citep{singh2023better} demonstrated that semantic IDs can improve the generalization of recommendation ranking compared with traditional item IDs. Different from existing works aiming to replace item IDs with semantic IDs, we further consider the complementary strengths of them.

 





\section{Conclusion}
In conclusion, this work provides a comprehensive exploration of the complementary relationship between ID tokens and semantic tokens in recommendation systems, addressing the limitations of using either method in isolation. We introduced a novel framework that unifies ID and semantic tokenization, effectively capturing both unique and shared item characteristics while significantly reducing token redundancy. By leveraging a combination of cosine similarity and Euclidean distance, our approach successfully decouples accumulated embeddings and distinguishes unique items. Experimental results on three benchmark datasets demonstrate that our proposed method consistently outperforms the baselines, achieving notable improvements in performance (6\% to 17\%) while reducing token size by over 80\%. The results also validated our hypothesis that most ID tokens are redundant and can be substituted with semantic tokens to enhance generalization. Our work sets the foundation for a more efficient and effective representation strategy in recommendation systems, combining the strengths of both ID and semantic tokens for improved user experience.