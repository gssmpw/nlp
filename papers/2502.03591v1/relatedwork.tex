\section{Related Work}
\subsection{Multi-Label Classification in Medical Imaging}
Multi-label classification plays an important role in analyzing CXRs, particularly when handling a diverse range of pathologies that overlap or present concurrently. Prior studies have focused on improving the performance of such models. For example, Wang \textit{et al.}~\cite{wang2024awareness} introduced CXR×MLAGCPL, a multi-label classification model for CXRs that leverages both local label correlations and global co-occurrence patterns for improved disease prediction. The model captures nuanced inter-pathological patterns by combining a Local Awareness Module (LAM) for image-specific label dependencies and a Global Co-occurrence Priori Learning (GCPL) module for dataset-wide label relationships. Evaluated on large datasets, CXR×MLAGCPL achieved a good performance on most labels (mean AUROC of 0.805 and 0.810 on all 14 and common 5 classes of the CheXpert~\cite{irvin2019chexpert} dataset respectively), highlighting the benefit of jointly considering local and global dependencies in multi-label medical image classification.

A similar study by Zhang \textit{et al.}~\cite{zhang2024discriminative}, proposed the Label Correlation Guided Discriminative Label Feature Learning (LCFL) model for CXR classification which uses a self-attention-based Label Correlation Learning (LCL) module to capture global label correlations and a Discriminative Label Feature Learning (DLFL) module for feature enhancement through label-level contrastive learning. This framework allows the model to learn distinctive label-specific features, yielding a mean AUROC score of 0.764 on the CheXpert dataset and U-zeros setting, utilizing both global and local label correlations to guide discriminative feature learning.

CvTGNet by Lu \textit{et al.}~\cite{lu2024CvTGNet} integrated convolutional and transformer architectures alongside graph-based co-occurrence modeling to enhance the multi-label classification of CXRs. By combining the strengths of Convolutional Vision Transformers for spatial detail extraction and Graph Convolutional Networks for pathological relationship learning, the model effectively captures both image-specific and inter-label dependencies, achieving an overall AUROC score of 0.840 across all 14 CheXpert pathologies.

In another study, Liu \textit{et al.}~\cite{liu2023Global} introduced ML-LGL. This framework enhances multi-label CXR classification by applying a clinical-inspired curriculum learning strategy, gradually training the model from common to rare abnormalities. This approach integrates three selection functions—correlation, similarity, and frequency-based functions—to build a radiologist-like curriculum, achieving a mean AUROC of 0.889 and 0.841 for 5 and 13 labels respectively on the CheXpert dataset and U-zeros setting.

On the other hand, the Semantic Similarity Graph Embedding (SSGE) framework by Chen \textit{et al.}~\cite{chen2022Graph} enhances multi-label CXR classification by embedding semantic relationships across images, using a “Teacher-Student” model. By combining a similarity graph with CNN-based feature extraction and GCN-based feature recalibration, the model achieves consistent, semantically informed features, leading to an overall AUROC score of 0.836 on the CheXpert dataset and U-zeros setting.

CheXtransfer by Ke \textit{et al.}~\cite{ke2021CheXtransfer} investigates the transferability of ImageNet-pretrained CNNs for CXR classification by evaluating 16 popular CNN architectures, analyzing relationships between model size, parameter efficiency, and classification performance, finding no correlation between ImageNet and CheXpert performance but significant gains from ImageNet pretraining. The study demonstrates that truncating layers can improve parameter efficiency without compromising accuracy, enhancing both performance and interpretability in medical imaging models.

The similar study by Huang \textit{et al.}~\cite{huang2022Transfer} leverages transfer learning for multilabel CXR classification, utilizing CNNs and three source datasets to analyze fine-tuning, layer transfer, and combined transfer approaches. Their results show that although initializing the model with ImageNet weights had the best training performance, it performed worse in the test process. They also showed integrating related datasets (e.g., ChestX-ray14~\cite{wang2017ChestX} and CheXpert) improves training accuracy but it does not achieve the best performance on the test set.

Recent advancements in multi-label CXR classification emphasize integrating spatial feature extraction with label dependency modeling to enhance diagnostic accuracy. Methods leveraging hybrid architectures, semantic embedding, and curriculum learning effectively capture both image-specific and label co-occurrence patterns, reflecting a shift toward more accurate and interpretable classification models.

\subsection{Hierarchical Learning in Medical Imaging}
The use of hierarchical networks has introduced a significant advancement, particularly with the introduction of Hierarchical Multi-Label Classification Networks (HMCN). This architecture represents one of the first attempts to explicitly incorporate hierarchical structures within deep neural network frameworks for multi-label classification~\cite{Wehrmann2018Hierarchical}. Compared to traditional flat multi-label approaches, HMCNs integrate hierarchical relationships directly into the learning process, leading to accurate predictions that align with the structure of the label space. This is particularly relevant in domains where hierarchical dependencies are naturally present, such as medical imaging, where disease categories often share anatomical or pathological relationships.

In work by Chen \textit{et al.}~\cite{Chen2020hierarchical} a two-stage Hierarchical Multi-Label Classification (HMLC) approach is introduced for CXR analysis. It utilizes clinically relevant taxonomies to enhance interpretability and manage incomplete labeling common in medical datasets. The method first trains the model to predict conditional probabilities within the label hierarchy, focusing on sibling categories, before fine-tuning with a numerically stable cross-entropy loss function to derive unconditional probabilities, thereby improving classification stability and performance. Evaluated on the PLCO~\cite{Aberle2000plco} and PadChest~\cite{padchest2020} datasets, the approach outperformed traditional flat classifiers and other hierarchical models, achieving the highest AUROC (0.887) reported on PLCO and showing resilience to missing labels. This study demonstrates HMLC’s utility in producing clinically aligned, interpretable predictions, offering a significant advancement for CXR computer-aided diagnosis (CAD) and suggesting broader applications across hierarchical classification tasks in medical imaging.

Similarly, the study by Pham \textit{et al.}~\cite{Pham2021hierarchical} presents a deep learning-based framework for multi-label CXR classification that integrates hierarchical disease dependencies and addresses label uncertainty, advancing upon previous work in the field. By using a conditional training process based on a predefined disease hierarchy, the model learns relationships among parent and child disease labels, allowing it to make clinically consistent predictions. To manage uncertain labels, the authors apply Label Smoothing Regularization (LSR), reducing model overconfidence in cases of label ambiguity. Trained on the CheXpert dataset, their combined Conditional Training (CT) and LSR in the U-zeros setting achieved an AUROC score of 0.884 on the five CheXpert labels. In addition, they evaluated an ensemble of six CNN architectures and achieved an AUROC of 0.940, outperforming prior methods and even surpassing most radiologists on the validation set. Their method highlights the value of incorporating hierarchical relationships and uncertainty handling in improving the interpretability and accuracy of automated CXR analysis.

Hierarchical Multi-Label Classification Networks (HMCNs) and related approaches represent significant advancements by incorporating hierarchical label structures directly into the learning process, leading to clinically interpretable and accurate predictions.  Table~\ref{table:abalation} presents the results of these studies evaluated on the CheXpert dataset compared to ours.