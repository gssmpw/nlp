\section{Beliefs}
\label{sec:beliefs}


In this section, we characterize the admitted players' posterior beliefs, supposing that the admitted number $n$ is given. Let $\I\subseteq \I^0$ be a specific realized set of admitted players with $|\I|=n$. Given $\I$, let $\barI:=\I^0\setminus \I$ denote the set of eliminated players.

For an admitted player $i\in \I$, let $\I_{-i}$ denote the set of all other $n-1$ admitted players. Let $v_{-i}=(v_j)_{j\in \I_{-i}}$ and $v=(v_i,v_{-i})$ be the vectors of all and all other \textit{admitted} players' valuations, respectively. Finally, let $\beta(v_{-i}\mid \I,v_i;n,\gamma)$ be the admitted player $i$'s belief (joint density) about all other admitted players' valuations $V_{-i}$, conditional on the admission set $\I$ and player $i$'s own valuation $v_i$, when the prediction accuracy is $\gamma$.\footnote{Notice that, in the posterior beliefs, there is no need to conditional on the admitted number $n$ again since the admission set $\I$ contains the information of the admitted number.}





\begin{theorem}[Posterior Beliefs]
\label{thm:beta_posterior}
 The admitted player $i$'s posterior belief $\beta(v_{-i}\mid \I,v_i;n,\gamma)$ (joint density) about all other admitted players' private valuations $V_{-i}$ is
 \begin{align}\label{eq:beta_posterior}
 \beta(v_{-i} \mid \I,v_i;n,\gamma)
 = \underbrace{\kappa(v_i;n,\gamma)}_{\normalfont{\textrm{normalizing term}}}
\cdot 
\underbrace{\psi(v;n,\gamma)}_{\normalfont{\textrm{admission probability}}}
 \cdot 
 \underbrace{\prod_{j\in \I_{-i}} f(v_j)}_{\normalfont{\textrm{prior}}}
 ,~\forall v_{-i}\in [0,1]^{n-1}.
\end{align}
The normalizing term $\kappa(v_i;n,\gamma)$ satisfies $\int_{[0,1]^{n-1}}\beta(v_{-i}\mid \I,v_i;n,\gamma)dv_{-i}=1$.
The admission probability satisfies: for all $v\in [0,1]^n$,
\begin{align*}
\psi(v;n,\gamma)=  \Pr\left\{
\max_{j\in \barI} \zeta_j \leq \min_{i\in \I}\zeta_i
\mid v\right\} =
\int_0^1\prod_{i\in \I}[1-F(x;v_i,\gamma)] dF^{m-n}(x),
\end{align*}
where $F(x;v_i,\gamma):=\gamma\cdot \mathds{1}\{v_i\leq x\} + (1-\gamma)\cdot F(x) $ is the CDF of $\zeta_i$.
\end{theorem}



The admitted player $i$'s posterior belief has a clear structure: it is proportional to the prior multiplied by the admission probability $\psi(v;n,\gamma)$, which is the probability that all eliminated players' signals $\zeta_{\barI}$ are smaller than all admitted players' signals $\zeta_{\I}$, given the vector of admitted players' valuations $v$. That is $\psi(v;n,\gamma)=\Pr\{
\max_{j\in \barI} \zeta_j \leq \min_{i\in \I}\zeta_i \mid v\}.$



We provide closed-form expressions for the admission probability $\psi(v;n,\gamma)$ (as well as for the normalizing term $\kappa(v_i;n,\gamma)$) in \Cref{lem:closedforms_admission_prob} in \Cref{app_sec:auxiliary_results}. We find that the admission probability has the following structure:
\begin{align}
\label{eq:admissionprob_summation}
\psi(v;n,\gamma)=\hat{\psi}_0(n,\gamma)+\sum_{k=1}^n \hat{\psi}_k(v_{(k)};n,\gamma),
\end{align}
for some functions $(\hat{\psi}_k)_{k=0}^n$. Here, $v_{(k)}$ denotes the $k^{\mathsf{th}}$ smallest element in the vector $v$. Note that, given $n$ and $\gamma$, no crossing terms appear in $\psi(v;n,\gamma)$; it is simply equal to the summation of the individual terms.

In the special case of blind prescreening, i.e., $\gamma=0$, the selection is performed uniformly at random. In this case, we have $\psi(v;n,\gamma)=\frac{1}{\C^m_n},$
which is independent of $v$, and the posterior belief
$\beta(v_{-i}\mid \I,v_i;n,\gamma)=\prod_{j\in \I_{-i}}f(v_j)$
coincides with the prior.\footnote{When $\gamma=0$, we have $\psi(v;n,\gamma)=\Pr\{
\max_{j\in \barI} \zeta_j \leq \min_{i\in \I}\zeta_i \mid v\}
=\Pr\{
\max_{j\in \barI} \zeta_j \leq \min_{i\in \I}\zeta_i\},$
which is the probability that the minimum of $n$ i.i.d. random variables exceeds the maximum of $m-n$ i.i.d. random variables with the same distribution. This probability equals $\frac{1}{\C^m_n}$.}
Besides, for any prediction accuracy, when $n=m$, i.e., in the case of no prescreening, the posterior belief is the same as the prior.

For the case of perfect prescreening, i.e., $\gamma=1$, the admitted players are those with the highest valuations. In this case, we have
\begin{align}
\label{eq:gamma_1_admissionprob}
\psi(v;n,\gamma=1)
=\Pr\left\{
\max_{j\in \barI} \zeta_j \leq \min_{i\in \I}\zeta_i \mid v\right\}
=\Pr\left\{
\max_{j\in \barI} v_j \leq \min_{i\in \I}v_i \mid v\right\}
=F\left(\min_{i\in \I}v_i\right).
\end{align}





\begin{proposition}
\label{prop:admissionprob_property}
 The admission probability $\psi(v;n,\gamma)$ has the following properties:
 \begin{enumerate}[(i)]
    \item $\psi(v;n,\gamma)$ is symmetric in $v\in [0,1]^n$ and is differentiable almost everywhere.
  
 
     \item For any $i\neq j\in \I$, $\frac{\partial^2  \psi}{\partial v_i\partial v_j}$ exists almost everywhere and equals zero whenever it exists.
    
     \item Local Supermodularity: $\psi$ is supermodular in any domain $\mathcal{V}\subset 
     [0,1]^n$ in which for any $v,v^\prime \in \mathcal{V}$, the order of elements in $v$ is the same as the order of elements in $v^\prime$.


     \item When $\gamma=1$, $\psi$ is both supermodular and log-supermodular in $v\in [0,1]^n$.

 
 \end{enumerate}
\end{proposition}



\Cref{prop:admissionprob_property} (i) and (ii) come from the formula \eqref{eq:admissionprob_summation}. The symmetry is straightforward. The function is differentiable unless $v_i=v_j$ for some $i\neq j$, which is a measure-zero event. Thus, the admission probability is differentiable almost everywhere. \Cref{prop:admissionprob_property} (ii) follows from the fact that there is no crossing term in $\psi(v;n,\gamma)$ as shown in \eqref{eq:admissionprob_summation}.

In any domain $\mathcal{V}$ satisfying the condition in \Cref{prop:admissionprob_property} (iii), the ordering of $v\in \mathcal{V}$ does not change; hence, the formula \eqref{eq:admissionprob_summation} remains unchanged with respect to each element $v_i$. Thus, in this domain $\mathcal{V}$, the mixed partial derivative $\frac{\partial^2 \psi}{\partial v_i\partial v_j}=0$ for any $i\neq j$,
this leads to the supermodularity in the domain $\mathcal{V}$, i.e.,  local supermodularity.\footnote{If a function $\psi$ is twice-differentiable everywhere in the domain $\mathcal{V}$, then the supermodularity is equivalent to $\frac{\partial^2 \psi}{\partial v_i\partial v_j}\geq 0$ for any $i\neq j$.}
\Cref{prop:admissionprob_property} (iv) can be verified directly by equation \eqref{eq:gamma_1_admissionprob}.



By \Cref{prop:admissionprob_property} (i), player $i$'s posterior belief $\beta(v_{-i}\mid \I,v_i;n,\gamma)$ is symmetric in $v_{-i}\in [0,1]^{n-1}$. Consequently, its marginal distributions, regardless of the dimension, are identical; we denote this common marginal distribution by $\beta^{\mathsf{mar}}(\cdot \mid \I,v_i;n,\gamma)$. Notice that, unless $n=m$ or $\gamma=0$, in general, we have
\begin{align*}
\beta(v_{-i}\mid \I,v_i;n,\gamma) \neq \prod_{j\in \I_{-i}}\beta^{\mathsf{mar}}(v_j\mid \I,v_i;n,\gamma).
\end{align*}
In other words, player $i$'s posterior beliefs about the valuations of admitted players $j$ and $k$ are correlated.







\subsection{An Equivalent Game}
\label{subsec:equivalent_game}

Observe that by \eqref{eq:beta_posterior}, if two admitted players have the same valuation, then their posterior beliefs are identical. In other words, the posterior belief is independent of the individual identity and depends only on the player's valuation. Thus, one may wonder if there exists a \textit{symmetric} joint density over \textit{all admitted} players' valuations such that the conditional density derived from this joint density equals each admitted player's posterior belief \eqref{eq:beta_posterior}.
The answer is yes and it is unique.


\begin{lemma}
\label{lem:joint_dis_g}
There exists a unique symmetric joint density $g(\cdot;n,\gamma)$ over all admitted players's valuations $v\in[0,1]^n$ such that the conditional density $g(v_{-i}\mid v_i;n,\gamma)=\beta(v_{-i}\mid \I,v_i;n,\gamma)$ for any $i\in \I$ and any $v\in [0,1]^n$.
This symmetric joint density $g(\cdot ;n,\gamma)$ is given by
\begin{align}
\label{eq:joint_dist_g}
 g(v;n,\gamma) = \C^m_n\cdot \psi(v;n,\gamma)
 \cdot \prod_{j\in\I} f(v_j),~ \forall v\in [0,1]^n
 .   
\end{align}
\end{lemma}



Similar to \Cref{thm:beta_posterior}, the joint density $g(\cdot;n,\gamma)$ is proportional to the prior multiplied by the admission probability $\psi(v;n,\gamma)$. An interesting observation in \eqref{eq:joint_dist_g} is that the normalizing constant $\C^m_n$ is independent of both the prediction accuracy $\gamma$ and the prior $F$, whereas the normalizing constant $\kappa(v_i;n,\gamma)$ in \Cref{thm:beta_posterior} depends on both $\gamma$ and $F$ (see \Cref{lem:closedforms_admission_prob} in the appendix for the closed-form expressions of $\kappa(v_i;n,\gamma)$).

Now, consider a standard auction without prescreening but with \textit{correlated} valuations sampled from $g(\cdot;n,\gamma)$ in \eqref{eq:joint_dist_g}. In this setting, the vector of all $n$ players' valuations is jointly sampled from $g(\cdot;n,\gamma)$, and each player is informed only of her own valuation. Then, player $i$'s belief about the private valuations of the other $n-1$ players is given by the conditional density $g(v_{-i}\mid v_i;n,\gamma).$
Since $g(v_{-i}\mid v_i;n,\gamma)=\beta(v_{-i}\mid \I,v_i;n,\gamma),$
all participating players have the same beliefs in both settings. Thus, the equilibrium strategy and the equilibrium outcome are identical in the two settings. This observation leads to the following remark.
\begin{remark}
The prescreening game with i.i.d. prior $f$ is equivalent to a standard auction without prescreening but with the {\normalfont{joint}} distribution $g(\cdot;n,\gamma)$ in \eqref{eq:joint_dist_g}.
From the perspective of this equivalent game, prescreening allows the designer to select a joint distribution $g(\cdot;n,\gamma)$ while simultaneously reducing the number of participants to $n$.
\end{remark}




We have the following properties about the joint density $g(\cdot;n,\gamma)$.

\begin{proposition}
\label{prop:g_property}
The joint density $g(\cdot;n,\gamma)$ has the following properties:
\begin{enumerate}[(i)]
   
    \item When $\gamma\in \{0,1\}$, $g(v;n,\gamma)$ is affiliated in $v\in [0,1]^n$.
    \item When the prior $F$ is the uniform distribution, \Cref{prop:admissionprob_property} regarding the admission probability applies to $g(v;n,\gamma)$.
\end{enumerate}
\end{proposition}

The case of $\gamma=0$ in (i) is trivial since independent valuations are always affiliated.
The case of $\gamma=1$ follows from \Cref{prop:admissionprob_property} (iv), which shows that the admission probability $\psi(v;n,\gamma)$ is affiliated (log-supermodular) when $\gamma=1$, together with the fact that the product of two affiliated functions is also affiliated.\footnote{Note that the function $\prod_{i\in \I}f(v_i)$ is affiliated in $v\in [0,1]^n$.}
If the joint density $g(\cdot;n,\gamma)$ is affiliated, then a player with a high valuation $v_i$ will perceive that the other players are more likely to have high valuations rather than low valuations. Affiliation is a commonly used assumption in the auction literature \citep{krishna_1997_all_pay_affiliation,fang2002_GEB_affilited_secondprice,kotowski_2014_affiliated_allpay_budget}, as pioneered by \citet{milgrom_1982_auctiontheory_competitive_bidding}. 
% \yscomment{add more literatures about affiliated types here.}
However, beyond the cases of perfect and blind prescreening, the joint density is \textit{not} affiliated.
This makes the equilibrium analysis in our setting more challenging, as shown in the following sections.
\begin{remark}[Unaffiliation]
  When $\gamma\in (0,1)$, the joint density $g(\cdot;n,\gamma)$ is in general {\normalfont{not}} affiliated (unless $n=m$).  
\end{remark}





Based on \Cref{prop:g_property} (i), we have the following property about first-order stochastic dominance ($\fosd$).

\begin{proposition}[Stochastic Dominance]
\label{prop:stochastic_domiance_gamma_1}
In the case of perfect prescreening, i.e., $\gamma=1$, for any $v^\prime \geq v_i$, 
\begin{align*}
\beta^{\mar}(\cdot \mid \I,v_i^\prime;n,\gamma) \succeq_{\fosd} \beta^{\mar}(\cdot \mid \I,v_i;n,\gamma) \succeq_{\fosd} f.
\end{align*}
\end{proposition}

\Cref{prop:stochastic_domiance_gamma_1} states that an admitted player with a higher valuation perceives her opponents as being more likely to have higher valuations and that her marginal posterior belief stochastically dominates the prior.
By \Cref{prop:g_property} (i), we know that when $\gamma=1$, $g(v;n,\gamma)$ is affiliated in $v\in [0,1]^n$.
Since the conditioning and marginalization preserve affiliation \citep{karlin_1980_MTP2}, then the conditional density $g(v_{-i}\mid v_i;n,\gamma)$ is also affiliated in $v\in [0,1]^n$. Moreover, the marginal density of $g(v_{-i}\mid v_i;n,\gamma)$, i.e.,  $\beta^{\mar}(\cdot \mid \I,v_i;n,\gamma)$, is affiliated in $(x,v_i)\in [0,1]^2$. Then, the $\fosd$ follows by Proposition 3.1 in \citet{castro_2007_affiliation_positive_dependence}. The second inequality is established by verifying the definition of $\fosd$.

Let $H(\cdot\mid v_i;n,\gamma)$ be the CDF of the largest order statistic sampled from the conditional density $g(v_{-i}\mid v_i;n,\gamma)$, which is the same as $\beta(v_{-i} \mid \I,v_i;n,\gamma)$ by \Cref{lem:joint_dis_g}. Formally,
\begin{align}
\label{eq:H_CDF}
H(x\mid v_i;n,\gamma):=\int_{[0,x]^{n-1}} g(v_{-i}\mid v_i;n,\gamma) \, dv_{-i}.
\end{align}
Let $h(x\mid v_i;n,\gamma)=\frac{\partial H(x\mid v_i;n,\gamma)}{\partial x}$ be the corresponding density.
The closed-form expressions of $H(x\mid v_i;n,\gamma)$ and $h(x\mid v_i;n,\gamma)$ are provided in \Cref{lem:H_h} in \Cref{app_sec:auxiliary_results}.

A similar $\fosd$ result holds for $h(\cdot \mid v_i;n,\gamma)$ when $\gamma=1$, namely, for any $v^\prime \geq v_i$,
\begin{align*}
h(\cdot \mid v_i^\prime;n,\gamma) \succeq_{\fosd} h(\cdot \mid v_i;n,\gamma) \succeq_{\fosd} f.
\end{align*}
The first inequality follows a similar argument of \Cref{prop:stochastic_domiance_gamma_1} based on affiliation.
The second inequality holds since $h(\cdot \mid v_i;n,\gamma)$ first-order stochastically dominates the marginal density of $g^{\mar}(\cdot\mid v_i;n,\gamma)$, which is equal to $\beta^{\mar}(\cdot \mid \I,v_i;n,\gamma)$, and because $\fosd$ is transitive.

Before proceeding to the equilibrium analysis and characterizing the optimal admitted number, we introduce a few notations that will be used in both all-pay and first-price auctions. Since the joint density $g(\cdot;n,\gamma)$ is symmetric, its marginal densities, regardless of the dimension, are identical.
We denote this marginal CDF by $G^{\mathsf{mar}}(\cdot;n,\gamma)$. Let $G^{\lar}(\cdot; n,\gamma)$ be the CDF of the largest order statistic of random vector $V$ sampled from the joint density $g(\cdot;n,\gamma)$, i.e., it is the CDF of $\max_{i\in \I}V_i$ with $V\sim g(\cdot;n,\gamma)$.
The closed forms of $G^{\mathsf{mar}}(\cdot;n,\gamma)$ and $G^{\lar}(\cdot; n,\gamma)$ are provided in \Cref{lem:marginals_joint_g} in \Cref{app_sec:auxiliary_results}. 