\section{Conclusion}
\label{sec:conclusion}

In this work, we presented a novel approach to incorporating equivariance in diffusion models through a symmetrized target in the loss function. By explicitly enforcing equivariance during the optimization process, our method ensures that the learned distribution respects the desired symmetries, improving data efficiency and generalization. The use of Monte Carlo sampling to estimate the group average introduces minimal computational overhead, making our approach both scalable and efficient. Our experiments demonstrate that this method enhances sample quality and reduces training time compared to existing approaches. These results underscore the potential of our approach to advance the scalability and practical deployment of equivariant diffusion models across a wide range of generative tasks.