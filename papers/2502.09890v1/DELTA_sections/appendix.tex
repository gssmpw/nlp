\section{Related Work}

\paragraph{Equivariant Neural Networks.}  
Equivariant neural networks have attracted significant attention for tasks involving structured data, such as computer vision~\citepcolor{equiconv, harmonicnet}, 3D modeling~\citepcolor{tensorfieldnet, e3transformer, vectorneuron}, quantum mechanics and quantum field theory~\citepcolor{quantumfield, schrodinger}, and biomolecular design~\citepcolor{bioref, scaledeepequi}. These networks exploit group symmetries to ensure consistent outputs under transformations like rotations, translations, and permutations, which are commonly encountered in many scientific domains. By incorporating symmetric inductive biases, equivariant networks enhance model generalization and reduce data requirements by naturally encoding symmetry constraints. However, challenges remain, such as high computational complexity~\citepcolor{efficientequi} and difficulties in learning effectively with stochastic gradient descent (SGD)~\citepcolor{nonuniversalityequi}.

\paragraph{Equivariance and Diffusion Models.}  
Diffusion models have become a prominent class of generative models, particularly for tasks involving complex data distributions~\citepcolor{song2020denoising, ho2020denoising, karras2022elucidating}. These models transform data into noise through a forward process and learn to reverse this transformation using a neural network-based denoising function, \(\phi_\theta\). Incorporating equivariance into diffusion models can significantly improve their performance on data with inherent symmetries, enabling more efficient learning and enhancing generalization to unseen transformations~\citepcolor{hoogeboom2022equivariant, geodiff, bose2023se}. To enforce equivariance, it is common to design the denoiser network \(\phi_\theta\) to be equivariant under a group \(\Ge\). While this approach allows the learned distribution to converge to the underlying invariant distribution \(\Gi\)~\citepcolor{Theoequi}, it inherits the challenges associated with equivariant network learning. Additionally, we show in this work that the Monte Carlo estimation of the loss function, following this design, suffers from high variance, which complicates the optimization process.

% \paragraph{Non-equivariant models.} \citecolor{sareen2025symmetry} learn the canonicalization that is easy for the non-equivariant model to learn.  \citecolor{Swallow} learn a transformer model to perform molecular conformation prediction. 


\section{Theoretical Proofs and Derivations}

\subsection{Symmetrized Forward Diffusion Distribution.}
\label{sub_app:symmetrized}

Below is the formal lemma and the proof for the symmetrized forward diffusion distribution. 
\begin{tcolorbox}[title=Symmetrized Forward Diffusion Distributions]
\begin{lemma}
Let \(\hat{q}(x_0)\) be an empirical distribution and \(\hat{q}^G(x_0)\) its symmetrized counterpart under a symmetry group \(G\), defined by \(\hat{q}^G(x_0) = S_G[\hat{q}](x_0)\). Suppose a forward diffusion process acting on \(\hat{q}(x_0)\) yields time-dependent marginal distributions \(\hat{q}_t(x_t)\). Let a similar process act on \(\hat{q}^G(x_0)\) to generate \(\hat{q}_t^G(x_t)\). Then, for all \(t \geq 0\), the following holds:
\[
\hat{q}_t^G(x_t) = S_G[\hat{q}_t](x_t).
\]
\end{lemma}
\end{tcolorbox}

\begin{proof}
The marginal distribution at time step \(t\) of a diffusion process is defined as
\[
\hat{q}_t(x_t) = \int_\Omega q_t(x_t \mid x_0) \hat{q}(x_0) \, \mathrm{d}x_0,
\]
where \(q_t(x_t \mid x_0) = \mathcal{N}(x_t; \alpha_t x_0, \sigma_t^2 I)\) is the Gaussian diffusion kernel, which is equivariant under group transformations. Specifically, for any \(g \in G\), we have
\[
q_t(x_t \mid x_0) = q_t(g \circ x_t \mid g \circ x_0).
\]
The symmetrized marginal distribution at time \(t\) is defined as
\begin{align*}
S_G[\hat{q}_t](x_t) &= \int_G \hat{q}_t(g \circ x_t) \mathrm{d}\mu_G(g) \\
&= \int_G \left[ \int_\Omega q_t(g \circ x_t \mid x_0) \hat{q}(x_0) \, \mathrm{d}x_0 \right] \mathrm{d}\mu_G(g) \\
&= \int_G \int_\Omega q_t(g \circ x_t \mid x_0) \hat{q}(x_0) \, \mathrm{d}x_0 \mathrm{d}\mu_G(g).
\end{align*}

Next, we compute the marginal distribution at time \(t\) when the forward process is applied to the symmetrized data distribution:
\begin{align*}
\hat{q}_t^G(x_t) &= \int_\Omega q_t(x_t \mid x_0) S_G[\hat{q}](x_0) \, \mathrm{d}x_0 \\
&= \int_\Omega q_t(x_t \mid x_0) \int_G \hat{q}(g \circ x_0) \mathrm{d}\mu_G(g) \mathrm{d}x_0 \\
&= \int_\Omega \int_G q_t(x_t \mid x_0) \hat{q}(g \circ x_0) \mathrm{d}\mu_G(g) \mathrm{d}x_0 \\
&= \int_G \int_\Omega q_t(x_t \mid x_0) \hat{q}(g \circ x_0) \mathrm{d}x_0 \mathrm{d}\mu_G(g).
\end{align*}

Applying a change of variable \(x_0 \mapsto g^{-1} \circ x_0\), we get
\begin{align*}
\hat{q}_t^G(x_t) &= \int_G \int_\Omega q_t(x_t \mid g^{-1} \circ x_0) \hat{q}(g \circ [g^{-1} \circ x_0]) \mathrm{d}(g^{-1} \circ x_0) \mathrm{d}\mu_G(g) \\
&= \int_G \int_\Omega q_t(x_t \mid g^{-1} \circ x_0) \hat{q}(x_0) \mathrm{d}x_0 \mathrm{d}\mu_G(g) \quad \text{(since the Jacobian of \(g\) is 1)} \\
&= \int_G \int_\Omega q_t(g \circ x_t \mid x_0) \hat{q}(x_0) \mathrm{d}x_0 \mathrm{d}\mu_G(g) \quad \text{(by kernel equivariance)}.
\end{align*}
Thus, we have
\[
\hat{q}_t^G(x_t) = S_G[\hat{q}_t](x_t).
\]
This completes the proof.
\end{proof}






\subsection{Symmetrized Diffusion Minimizer is G-equivariant}
\label{sub_app:sym_diff_mini}

We prove that the minimizer of the symmetrized diffusion objective, \(\phi^*_G\), is an equivariant function of \(x_t\). That is, \(\phi^*_G(g \circ x_t, t) = g \circ \phi^*_G(x_t, t)\), for all \(x_t \in \mathbb{R}^d\) and \(g \in G\).

\begin{proof}
The minimizer is given by:
\[
\phi^*_G(x_t, t) = \int_\Omega x_0 \, q_t(x_t \mid x_0) \frac{\hat{q}^G(x_0)}{\hat{q}^G_t(x_t)} \, \mathrm{d}x_0.
\]

Applying a group action \(g \in G\) to \(x_t\), we have:
\[
\phi^*_G(g \circ x_t, t) = \int_\Omega x_0 \, q_t(g \circ x_t \mid x_0) \frac{\hat{q}^G(x_0)}{\hat{q}^G_t(g \circ x_t)} \, \mathrm{d}x_0.
\]

Next, we apply a change of variable \(x_0 \mapsto g^{-1} \circ x_0\). Under this change of variable:
\[
q_t(g \circ x_t \mid x_0) \rightarrow q_t(g \circ x_t \mid g \circ x_0), \quad \hat{q}^G(x_0) \rightarrow \hat{q}^G(g \circ x_0), \quad \mathrm{d}x_0 \rightarrow \mathrm{d}(g \circ x_0).
\]

The integral becomes:
\[
\phi^*_G(g \circ x_t, t) = \int_\Omega g \circ x_0 \, q_t(g \circ x_t \mid g \circ x_0) \frac{\hat{q}^G(g \circ x_0)}{\hat{q}^G_t(g \circ x_t)} \, \mathrm{d}(g \circ x_0).
\]

Using the fact that the Jacobian of the group action \(g\) is 1, the measure \(\mathrm{d}(g \circ x_0)\) simplifies to \(\mathrm{d}x_0\):
\[
\phi^*_G(g \circ x_t, t) = \int_\Omega g \circ x_0 \, q_t(g \circ x_t \mid g \circ x_0) \frac{\hat{q}^G(g \circ x_0)}{\hat{q}^G_t(g \circ x_t)} \, \mathrm{d}x_0.
\]

Since the diffusion kernel \(q_t(x_t \mid x_0)\) is equivariant under \(g\), we have \(q_t(g \circ x_t \mid g \circ x_0) = q_t(x_t \mid x_0)\). Similarly, the symmetrized densities satisfy \(\hat{q}^G(g \circ x_0) = \hat{q}^G(x_0)\) and \(\hat{q}^G_t(g \circ x_t) = \hat{q}^G_t(x_t)\). Substituting these properties, we get:
\[
\phi^*_G(g \circ x_t, t) = \int_\Omega g \circ x_0 \, q_t(x_t \mid x_0) \frac{\hat{q}^G(x_0)}{\hat{q}^G_t(x_t)} \, \mathrm{d}x_0.
\]

Factoring out the group action \(g\), we obtain:
\[
\phi^*_G(g \circ x_t, t) = g \circ \int_\Omega x_0 \, q_t(x_t \mid x_0) \frac{\hat{q}^G(x_0)}{\hat{q}^G_t(x_t)} \, \mathrm{d}x_0.
\]

Thus:
\[
\phi^*_G(g \circ x_t, t) = g \circ \phi^*_G(x_t, t).
\]

This completes the proof.
\end{proof}



\subsection{Unconstrained Non-Symmetrized Diffusion Minimizer is not guaranteed G-equivaraint}
\label{sub_app:non_sym_diff_mini}
  
On the other hand, the minimizer \(\phi^*(x_t, t)\) of the following unconstrained Non-Symmetrized Diffusion loss:
\[
    \mathcal{L}_t = \mathbb{E}_{(x_0, x_t) \sim \hat{q}(x_0, x_t)} [ \| \phi(x_t, t) - x_0 \|^2 ]
\]
is not guaranteed to be equivariant under the action of the symmetry group \(\Ge\).

\begin{proof}
To find the minimizer of the diffusion loss, we first compute the stationary point. The loss is given by:
\[
    \mathcal{L}_t(\phi) = \mathbb{E}_{(x_0, x_t) \sim \hat{q}(x_0, x_t)} \left[ \| \phi(x_t, t) - x_0 \|^2 \right] 
    = \mathbb{E}_{x_t \sim \hat{q}_t(x_t)} \mathbb{E}_{x_0 \sim \hat{q}_t(x_0 \mid x_t)} \left[ \| \phi(x_t, t) - x_0 \|^2 \right].
\]
The gradient of the internal expectation is:
\begin{align*}
    \nabla_\phi \mathbb{E}_{x_0 \sim \hat{q}_t(x_0 \mid x_t)} \left[ \| \phi(x_t, t) - x_0 \|^2 \right] 
    &= 2 \mathbb{E}_{x_0 \sim \hat{q}_t(x_0 \mid x_t)} \left[ \phi(x_t, t) - x_0 \right] \\
    &= 2 \left( \phi(x_t, t) - \mathbb{E}_{x_0 \sim \hat{q}_t(x_0 \mid x_t)}[x_0] \right).
\end{align*}
Setting the gradient to zero gives the minimizer:
\[
    \phi^*(x_t, t) = \mathbb{E}_{x_0 \sim \hat{q}_t(x_0 \mid x_t)}[x_0] 
    = \int_\Omega x_0 \hat{q}_t(x_0 \mid x_t) \, dx_0.
\]

Next, we provide a counterexample to show that \(\phi^*(x_t, t)\) is not guaranteed to be equivariant.

\paragraph{Counterexample: Translation in 1D}
\begin{enumerate}
    \item \textbf{Data}: Two points \(x_0^1 = 0\) and \(x_0^2 = 1\), with uniform empirical distribution \(\hat{q}(x_0^i) = 0.5\).
    \item \textbf{Group action}: Translation by \(a = 1\), i.e., \(g \circ x = x + 1\).
    \item \textbf{Diffusion kernel}: \({q}_t(x_t \mid x_0) = \mathcal{N}(x_t; \alpha_t x_0, \sigma_t^2)\).
\end{enumerate}

First, rewrite the minimizer:
\begin{align*}
    \phi^*(x_t, t) &= \sum_{i=1}^N x_0^i \hat{q}_t(x_0^i \mid x_t) \\
    &= \sum_{i=1}^N x_0^i \hat{q}_t(x_t \mid x_0^i) \frac{\hat{q}(x_0^i)}{\hat{q}_t(x_t)} \\
    &= \frac{1}{\hat{q}_t(x_t)} \sum_{i=1}^N x_0^i \hat{q}_t(x_t \mid x_0^i) \hat{q}(x_0^i).
\end{align*}
Substituting \(x_0^1 = 0\) and \(x_0^2 = 1\):
\[
    \phi^*(x_t, t) = \frac{1}{\hat{q}_t(x_t)} \left( 0 \cdot \mathcal{N}(x_t; 0, \sigma_t^2) \cdot 0.5 + 1 \cdot \mathcal{N}(x_t; \alpha_t, \sigma_t^2) \cdot 0.5 \right) 
    = \frac{0.5 \cdot \mathcal{N}(x_t; \alpha_t, \sigma_t^2)}{\hat{q}_t(x_t)} 
    = \frac{\mathcal{N}(x_t; \alpha_t, \sigma_t^2)}{\mathcal{N}(x_t; 0, \sigma_t^2) + \mathcal{N}(x_t; \alpha_t, \sigma_t^2)}.
\]
Now, compute \(\phi^*(g \circ x_t, t)\) by applying \(g \circ x_t = x_t + 1\):
\[
    \phi^*(g \circ x_t, t) = \frac{\mathcal{N}(x_t + 1; \alpha_t, \sigma_t^2)}{\mathcal{N}(x_t + 1; 0, \sigma_t^2) + \mathcal{N}(x_t + 1; \alpha_t, \sigma_t^2)} < 1.
\]
Next, compute \(g \circ \phi^*(x_t, t)\):
\[
    g \circ \phi^*(x_t, t) = \frac{\mathcal{N}(x_t; \alpha_t, \sigma_t^2)}{\mathcal{N}(x_t; 0, \sigma_t^2) + \mathcal{N}(x_t; \alpha_t, \sigma_t^2)} + 1 > 1.
\]
Thus, 
\[
\phi^*(g \circ x_t, t) < g \circ \phi^*(x_t, t),
\]
since \(\phi^*(g \circ x_t, t) < 1\) and \(g \circ \phi^*(x_t, t) > 1\). Consequently,
\[
\phi^*(g \circ x_t, t) \neq g \circ \phi^*(x_t, t).
\]
This completes the counterexample, showing that \(\phi^*(x_t, t)\) is not necessarily equivariant.
\end{proof}



\subsection{Full derivation of the group-weighted averaged posterior expectation}
\label{sub_app:SFull}

To compute \( \phi^*_G(x_t, t) \), we start from its definition as a group-weighted posterior expectation:
\begin{align*}
    \phi^*_G(x_t, t) &:= \sum_{x_0 \in D}\int_G (g \circ x_0) \hat{q}^G_t(g \circ x_0 \mid x_t) \mathrm{d}\mu_G(g) \\
    &= \sum_{x_0 \in D} \int_G (g \circ x_0) q_t(x_t \mid g \circ x_0) \frac{\hat{q}^G(x_0)}{\hat{q}^G_t(x_t)} \mathrm{d}\mu_G(g) \\
    &= \sum_{x_0 \in D} \frac{\hat{q}^G(x_0)}{\hat{q}^G_t(x_t)} \int_G (g \circ x_0) q_t(x_t \mid g \circ x_0) \mathrm{d}\mu_G(g) \\
    &= \sum_{x_0 \in D} \frac{\hat{q}^G(x_0)}{\hat{q}^G_t(x_t)} \frac{1}{(2\pi\sigma_t^2)^{d/2}} \int_G (g \circ x_0) \exp\left(-\frac{\| x_t - \alpha_t (g \circ x_0) \|^2}{2\sigma_t^2}\right) \mathrm{d}\mu_G(g) \\
    &= \sum_{x_0 \in D} \frac{1}{N} \frac{1}{\hat{q}^G_t(x_t)} \frac{1}{(2\pi\sigma_t^2)^{d/2}} \int_G (g \circ x_0) \exp\left(-\frac{\| x_t - \alpha_t (g \circ x_0) \|^2}{2\sigma_t^2}\right) \mathrm{d}\mu_G(g) \\
    &= \frac{1}{N} \frac{1}{\hat{q}^G_t(x_t)} \frac{1}{(2\pi\sigma_t^2)^{d/2}}  \sum_{x_0 \in D} \int_G (g \circ x_0) \exp\left(-\frac{\| x_t - \alpha_t (g \circ x_0) \|^2}{2\sigma_t^2}\right) \mathrm{d}\mu_G(g) \\
    &= C  \sum_{x_0 \in D} \int_G (g \circ x_0) \exp\left(-\frac{\| x_t - \alpha_t (g \circ x_0) \|^2}{2\sigma_t^2}\right) \mathrm{d}\mu_G(g) ,
\end{align*}
where \( C = \frac{1}{N} \frac{1}{\hat{q}^G_t(x_t)} \frac{1}{(2\pi\sigma_t^2)^{d/2}} \) is a normalization constant independent of the integral.

We now prove that  
\[
C  \sum_{x_0 \in D} \int_G \exp\left( -\frac{\| x_t - \alpha_t (g \circ x_0) \|^2}{2\sigma_t^2} \right) \mathrm{d}\mu_G(g) = 1.
\]  
First, by the definition of \(C\), we have  
\begin{align*}
    C \sum_{x_0 \in D} \int_G \exp\left( -\frac{\| x_t - \alpha_t (g \circ x_0) \|^2}{2\sigma_t^2} \right) \mathrm{d}\mu_G(g) = \sum_{x_0 \in D} \int_G  q_t^G(g \circ x_0 \mid  x_t ) \mathrm{d}\mu_G(g)
    = \int_\Omega \hat{q}^G_t( x_0 \mid x_t) \mathrm{d}x_0 = 1.
\end{align*}  
Thus, the proof is complete.  

% \subsection{Proof of~\cref{the:theo_1}}
% \label{sub_app:theo_1}

% \begingroup
% \setcounter{theorem}{0} % Set to the correct theorem number
% \renewcommand{\thetheorem}{\ref{the:theo_1}} % Use the existing theorem label
% \begin{tcolorbox}[title=Equivariant Minimizer of \(\mcL_t^G (\phi)\)]
% \begin{theorem}
% Let \( \bar{\phi}^*_G \) be the minimizer of the loss function in~\eqref{eqn:proposed_loss}. Then \( \bar{\phi}^*_G(x_t, t) \) is \( G \)-equivariant and 
% \[ \bar{\phi}^*_G(x_t, t) = \phi^*_G (x_t, t) = \int_\Omega x_0 \hat{q}^G_t(x_0 \mid x_t) \mathrm{d}x_0 . \]
% \end{theorem}
% \end{tcolorbox}
% \endgroup

% \begin{proof}
% We begin by rewriting the loss function:
% \begin{align*} 
% \bar{\mathcal{L}}^G_t(\phi) &= \mathbb{E}_{(x_0, x_t) \sim \hat{q}(x_0, x_t)} \left[ \omega(t) \| \phi(x_t, t) - \phi^*_G(x_t, t) \|^2 \right], \\
% \text{where} \quad \phi^*_G(x_t, t) &= \frac{1}{\hat{q}_t(x_0 \mid x_t)} \int_G (g \circ x_0) \hat{q}_t^G(g \circ x_0 \mid x_t) \mu_G(g).
% \end{align*}

% The minimizer of this loss function is given by
% \[
% \bar{\phi}_G^*(x_t, t) = \mathbb{E}_{x_0 \sim \hat{q}_t(x_0 \mid x_t)} [\phi^*_G(x_t, t)].
% \]
% Substituting the definition of \( \phi^*_G(x_t, t) \), we get
% \begin{align*}
% \bar{\phi}_G^*(x_t, t) &= \int_{\Omega} \phi^*_G(x_t, t) \hat{q}_t(x_0 \mid x_t) \mathrm{d}x_0 \\
% &= \int_{\Omega/G} \phi^*_G(x_t, t) \hat{q}_t(x_0 \mid x_t) \mathrm{d}x_0 \quad \text{(where \(\Omega/G\) is the quotient space)} \\
% &= \int_{\Omega/G} \left( \frac{\hat{q}_t(x_0 \mid x_t)}{\hat{q}_t(x_0 \mid x_t)} \int_G (g \circ x_0) \hat{q}_t^G(x_0 \mid x_t) \mathrm{d}\mu_G(g) \right) \mathrm{d}x_0 \\
% &= \int_{\Omega/G} \int_G (g \circ x_0) \hat{q}_t^G(x_0 \mid x_t) \mathrm{d}\mu_G(g) \mathrm{d}x_0 \\
% &= \int_{\Omega} x_0 \hat{q}_t^G(x_0 \mid x_t) \mathrm{d}x_0 \\
% &= \phi^*_G(x_t, t).
% \end{align*}
% Thus, the minimizer \( \bar{\phi}^*_G(x_t, t) \) is \( G \)-equivariant and matches \( \phi^*_G(x_t, t) \), as required.

% \end{proof}


\subsection{Proof of~\cref{the:theo_2}}
\label{sub_app:theo_2}


\begingroup
\setcounter{theorem}{0} % Set to the correct theorem number
\begin{tcolorbox}[title=Variance Reduction of the Proposed Loss]
\begin{theorem}
Let \(\mcL_t(\phi)\) and \(\bar{\mcL}_t^G(\phi)\) be the Monte Carlo estimators corresponding to Eq.~\eqref{eqn:constraint_problem} and Eq.~\eqref{eqn:proposed_loss}, respectively, where \(\phi(x_t, t)\) is \(\Ge\). Then:
\begin{equation}
    \text{\emph{Var}}(\nabla_\phi \mcL_t(\phi)) \geq \text{\emph{Var}}(\nabla_\phi \bar{\mcL}_t^G(\phi)),
\end{equation}
\end{theorem}
\end{tcolorbox}
\endgroup

\begin{proof}
    We first state the constrained optimization loss:

\begin{align*}
    \mathcal{L}_t(\phi) &= \omega(t) \mathbb{E}_{(x_0, x_t) \sim \hat{q}_t(x_0, x_t)} \big[ \| \phi(x_t, t) - x_0 \|^2 \big], \\
    \text{where} \quad &\phi(g \circ x_t) = g \circ \phi(x_t), \quad \forall x_t \in \Omega, \forall g \in G.
\end{align*}

This constrained loss is equivalent to the symmetrized diffusion loss because:

\begin{align*}
    \mathcal{L}_t(\phi) &= \omega(t) \mathbb{E}_{x_t \sim \hat{q}_t(x_t)} \mathbb{E}_{x_0 \sim \hat{q}_t(x_0 \mid x_t)} \big[ \| \phi(x_t, t) - x_0 \|^2 \big] \\
    &= \omega(t) \int_\Omega \sum_{x_0 \in D} \| \phi(x_t, t) - x_0 \|^2 \hat{q}_t(x_0 \mid x_t) \hat{q}_t(x_t) \,dx_t \\
    &= \omega(t) \int_{\Omega / G} \int_G \sum_{x_0 \in D} \| \phi(g \circ x_t, t) - x_0 \|^2 \hat{q}_t(x_0 \mid g \circ x_t) \hat{q}_t( g \circ x_t) \,d\mu_G(g) \,dx_t \\
    &= \omega(t) \int_{\Omega / G} \int_G \sum_{x_0 \in D} \| g \circ \phi(x_t, t) - x_0 \|^2 \hat{q}_t(x_0 \mid g \circ x_t) \hat{q}_t( g \circ x_t) \,d\mu_G(g) \,dx_t \quad \text{(since \( \phi \) is \( G \)-equivariant)} \\
    &= \omega(t) \int_{\Omega / G} \int_G \sum_{x_0 \in D} \|\phi( x_t, t) - g^{-1} \circ x_0 \|^2 \hat{q}_t(x_0 \mid g \circ x_t) \hat{q}_t( g \circ x_t) \,d\mu_G(g) \,dx_t \quad \text{(since \( g \) is isometric)} \\
    &= \omega(t) \int_{\Omega / G} \int_G \sum_{x_0 \in D} \|\phi( x_t, t) - g^{-1} \circ x_0 \|^2 \hat{q}_t( g \circ x_t \mid x_0 )  \hat{q}(x_0) \,d\mu_G(g) \,dx_t \\
    &= \omega(t) \int_{\Omega / G} \int_G \sum_{x_0 \in D} \|\phi( x_t, t) - g^{-1} \circ x_0 \|^2 \hat{q}_t( x_t \mid g^{-1} \circ x_0 )  \hat{q}(x_0) \,d\mu_G(g) \,dx_t \\
    &= \omega(t) \int_{\Omega / G} \int_G \sum_{x_0 \in D} \|\phi( x_t, t) - g^{-1} \circ x_0 \|^2 \hat{q}_t( x_t \mid g^{-1} \circ x_0 )  \frac{1}{|D|} \,d\mu_G(g) \,dx_t \\
    &= \omega(t) \int_{\Omega / G} \sum_{x_0 \in D} \int_G \|\phi( x_t, t) - g^{-1} \circ x_0 \|^2 \hat{q}_t( x_t \mid g^{-1} \circ x_0 )  \frac{1}{|D|} \,d\mu_G(g) \,dx_t \\
    &= \omega(t) \int_{\Omega / G} \int_{\Omega} \|\phi( x_t, t) - x_0 \|^2 \hat{q}_t( x_t \mid  x_0 ) \hat{q}^G(x_0)  \,dx_t \\
    &= \omega(t) \mathbb{E}_{x_t \sim \hat{q}_t^G(x_t)} \mathbb{E}_{x_0 \sim \hat{q}^G_t(x_0 \mid x_t)} \big[ \| \phi(x_t, t) - x_0 \|^2 \big].
\end{align*}

Similarly, our proposed loss function, assuming \(\phi(x_t, t)\) is constrained to be \(\Ge\), is:
\begin{align*}
    \bar{\mcL}_t^G = \mathbb{E}_{x_t \sim q^G_t(x_t)} [\| \phi(x_t, t) - \phi^*_G(x_t, t) \|^2],
\end{align*}
where
\begin{align*}
    \phi^*_G(x_t, t) = \mathbb{E}_{x_0 \sim \hat{q}_t^G(x_0 \mid x_t)}[x_0] = \mathbb{E} [x_0 \mid x_t].
\end{align*}

Now, we consider the gradients of \(\mcL_t\) and \(\bar{\mcL}_t^G\) with respect to \(\phi\):
\begin{align*}
    \nabla_\phi \mcL_t &= \mathbb{E}_{(x_0, x_t) \sim \hat{q}^G_t(x_0, x_t)} 2(\phi(x_t, t) - x_0), \\
    \nabla_\phi \bar{\mcL}_t^G &= \mathbb{E}_{x_t \sim q^G_t(x_t)} 2(\phi(x_t, t) - \phi^*_G(x_t, t)).
\end{align*}

The variances of these gradients are:
\begin{align*}
    \text{Var}(\nabla_\phi \mcL_t) &= \text{Var}_{(x_0, x_t) \sim \hat{q}^G_t(x_0, x_t)} [2( \phi(x_t, t) - x_0 )], \\
    \text{Var}(\nabla_\phi \bar{\mcL}_t^G) &= \text{Var}_{x_t \sim \hat{q}^G_t(x_t)}[2(\phi(x_t, t) - \phi^*_G(x_t, t))].
\end{align*}

Using the law of total variance:
\begin{align*}
    \text{Var}(\nabla_\phi \mcL_t) &= \mathbb{E}_{x_t} \text{Var}_{x_0 \mid x_t} [2(\phi(x_t, t)) - x_0] + \text{Var}_{x_t} [\mathbb{E}_{x_0 \mid x_t}2(\phi(x_t, t) - x_0)] \\
    &= \mathbb{E}_{x_t} \text{Var}_{x_0 \mid x_t} [2(\phi(x_t, t)) - x_0] + \text{Var}_{x_t} [2(\phi(x_t, t) - \phi^*_G(x_t, t))] \\
    &= \mathbb{E}_{x_t} \text{Var}_{x_0 \mid x_t} [2(\phi(x_t, t)) - x_0] + \text{Var}(\nabla_\phi \bar{\mcL}_t^G).
\end{align*}

Since variance is always non-negative, we conclude:
\begin{align*}
    \text{Var}(\nabla_\phi \mcL_t) \geq \text{Var}(\nabla_\phi \bar{\mcL}_t^G).
\end{align*}
\end{proof}

\section{Conformer generation evaluation metrics}
\label{sub_app:QM9_metrics}
As a conformer $C$ represents an assignment of each atom in the molecular graph to a point in 3D space, it can be viewed as a set of vectors in $\mathbb{R}^{3n}$.To evaluate molecular conformer generation, previous works have employed two key metrics: Average Minimum RMSD (AMR) and Coverage (COV) for both Precision (P) and Recall (R). Given a molecular graph, we generate twice as many conformers as those provided by CREST. Let:
\begin{itemize}
    \item $\{C^*_l\}^L_{l=1}$ be the set of grounth-truth conformers provided by CREST.
    \item $\{C^*_k\}^K_{k=1}$ be the set of generated conformers, where $K=2L$.
    \item $\delta$ be a predefined RMSD threshold for considering a conformer match.
\end{itemize}

\textbf{COV-P}: Measures the proportion of generated conformers that closely match at least one ground-truth conformer.
\[
\text{COV-P} = \frac{1}{K} \left| \{ k \in [1, K] \mid \exists l \in [1, L], \text{RMSD}(C_k, C_l^*) < \delta \} \right|
\]

\textbf{AMR-P}: Computes the average of the minimum RMSD values between each generated conformer and its closest ground-truth conformer.
\[
\text{AMR-P} = \frac{1}{K} \sum_{k=1}^{K} \min_{l=1}^{L} \text{RMSD}(C_k, C_l^*)
\]

\textbf{COV-R}: Measures the proportion of ground-truth conformers that have at least one close-enough generated conformer.
\[
\text{COV-R} = \frac{1}{L} \left| \{ l \in [1, L] \mid \exists k \in [1, K], \text{RMSD}(C_k, C_l^*) < \delta \} \right|
\]

\textbf{AMR-R}: Computes the average of the minimum RMSD values between each ground-truth conformer and its closest generated conformer.
\[
\text{AMR-R} = \frac{1}{L} \sum_{k=1}^{L} \min_{l=1}^{K} \text{RMSD}(C_k, C_l^*)
\]
