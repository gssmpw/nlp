\section{Impact Statement}
Our work focuses on efficient self-training of LLM-based multi-agent systems, which have broad applications with significant societal implications. While these systems can enhance personalization, AI assistant efficiency, and customer service, they also pose ethical and societal risks. For example, in marketing, optimizing for persuasiveness may lead to manipulative or unethical behavior. Additionally, malicious actors could exploit these systems for illegal activities, such as fraud or misinformation. As LLM-based agents advance, it becomes crucial to research their interactions and develop methods to mitigate harmful behaviors. Addressing these challenges is essential to responsibly harness their benefits while minimizing potential risks.