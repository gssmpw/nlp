% Large Language Models (LLMs) based agents excel in diverse tasks but face limitations in handling complex challenges individually. 
%【上来就Optimize】
% 【MCTS 】
% Large Language Model (LLM) based multi-agent systems (MAS) offer a promising avenue for handling complex challenges in diverse tasks by integrating multi-agent collaboration. 
Monte Carlo Tree Search (MCTS) based methods provide promising approaches for generating synthetic data to enhance the self-training of Large Language Model (LLM) based multi-agent systems (MAS). These methods leverage Q-values to estimate individual agent contributions. However, relying solely on Q-values to identify informative data may misalign with the data synthesis objective, as the focus should be on selecting data that best enhances model training. To address this discrepancy, we propose \textbf{D}ata \textbf{I}nfluence-oriented \textbf{T}ree \textbf{S}earch (\textbf{DITS}), a novel framework that incorporates influence scores to guide both tree search and data selection. By leveraging influence scores, we effectively identify the most impactful data for system improvement, thereby enhancing model performance. Furthermore, we derive influence score estimation methods tailored for non-differentiable metrics, significantly reducing computational overhead by utilizing inference computations. Extensive experiments on eight multi-agent datasets demonstrate the robustness and effectiveness of the proposed methods. Notably, our findings reveal that allocating more inference resources to estimate influence scores, rather than Q-values, during data synthesis can more effectively and efficiently enhance model training.