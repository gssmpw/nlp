\section{Introduction}
\label{section:introduction}

LLM based agents have recently achieved remarkable success across a wide range of tasks~\cite{202412.2294, Wang_2024, xi2023risepotentiallargelanguage, zhang2024largelanguagemodelbrainedgui}. Leveraging the advanced natural language understanding and reasoning capabilities of LLMs~\cite{DBLP:journals/corr/abs-2303-08774, DBLP:conf/nips/Wei0SBIXCLZ22}, these agents are able to dynamically interact with complex tools and environments to accomplish various tasks~\cite{ DBLP:journals/corr/abs-2310-05915, DBLP:conf/iclr/YaoZYDSN023}. Nevertheless, individual agents often face significant limitations when confronted with complex tasks~\cite{DBLP:conf/emnlp/ShiYWWF24}. In such scenarios, the multi-agent system (MAS) (e.g., MetaGPT~\cite{DBLP:conf/iclr/HongZCZCWZWYLZR24}, AutoGen~\cite{DBLP:journals/corr/abs-2308-08155}, Camel~\cite{DBLP:conf/nips/LiHIKG23}) involving multiple specialized agents, with strategic task allocation and division of labor, becomes crucial for achieving optimal outcomes~\cite{DBLP:conf/ijcai/GuoCWCPCW024}. However, optimizing the collective performance of LLM-based MAS as a cohesive unit and obtaining reward signals for each agent in the MAS still remain challenging problems~\cite{DBLP:journals/corr/abs-2410-08115}.

% \begin{figure}[t]
%     \centering
%     % \vspace{-0.5cm}
%     \includegraphics[width=1.0\linewidth]{figure/scaling.pdf}
%     \caption{\textbf{Synthesis time scaling}: Performance trends of different methods under increasing data synthesis budgets (Tokens). \wt{The equal portions mean that the process is still ongoing.}\cx{why call it optima but not our method?}\cx{can we add baseline here that with MCTS it does not scale well?}} \vspace{-0.3cm}
%     \label{fig:scaling}
% \end{figure}

\begin{figure}
    \centering
    \subfigure[Data Distribution]{\includegraphics[width=0.47\linewidth]{figure/mwh_qa_distribution.pdf}}
    %\includegraphics[width=0.48\linewidth]{figure/mwh_qa_DITSribution.pdf}
    \subfigure[Synthesis Time Scaling]{\includegraphics[width=0.48\linewidth]{figure/scaling_mwh_qa.pdf}}
    %\includegraphics[width=0.48\linewidth]{figure/scaling_mwh_qa.pdf}
    \caption{(a) The scatter plot and density plots of Q-values and influence scores for synthetic data. The top 30\% of the data selected using DITS is highlighted in red. (b) Performance trends with different data synthesis budgets (Tokens).}
    \vspace{-10pt}
    \label{fig:scaling}
\end{figure}

% 
To tackle this challenge, leveraging synthetic data for self-training emerges as a highly promising direction. Monte Carlo Tree Search (MCTS)~\cite{guan2025rstarmathsmallllmsmaster, li2025enhancingreasoningprocesssupervision} based method offers a promising approach for synthetic data generation, capable of estimating individual agent contributions through Q-value~\cite{DBLP:journals/corr/abs-2410-08115}. They collect fine-grained preference pairs, encouraging high-Q-value actions while suppressing low-Q-value actions via Direct Preference Optimization (DPO)~\cite{DBLP:conf/nips/RafailovSMMEF23}. 
% Despite its potential, the current tree search strategy overly depends on Q-values to identify informative data for training within a vast action space. 
Despite its potential, the current tree search strategy is primarily adapted from the inference phase, inheriting its inherent characteristics, which rely on Q-values to identify informative data. This reliance misaligns with the data synthesis objective, which focuses on generating data that better facilitates model training. The empirical results presented in Figure~\ref{fig:scaling} (a) also demonstrate that actions associated with higher Q-values do not always contribute significantly to the improvement of model performance, where the influence score serves as a metric to quantify the utility of data in enhancing model performance.


To address this issue, we propose \textbf{D}ata \textbf{I}nfluence-oriented \textbf{T}ree \textbf{S}earch (\textbf{DITS}), a novel framework that integrates influence scores to prioritize data that most significantly enhance model performance during the synthesis process. The DITS framework selects training data based on estimated influence scores, ensuring that the chosen data maximally contributes to performance improvement.
The traditional influence score evaluates the impact of training data on the training loss. However, due to the weak correlation between the DPO loss and downstream task performance~\cite{DBLP:journals/corr/abs-2406-02900, DBLP:journals/corr/abs-2410-11677}, we redefine the influence score based on the changes in non-differentiable performance metrics on the validation set and derive a novel estimation method. Our method circumvents computationally intensive gradient computations across large-scale parameters that are typically required in traditional approaches. As a result, it enables more efficient performance improvements, within the same overall synthesis budget, as demonstrated in Figure~\ref{fig:scaling} (b).


We validate our approach on eight datasets across two multi-agent tasks: Information Exchange and Debate~\cite{DBLP:journals/corr/abs-2410-08115}. We observe that high Q-value data may reduce the diversity of the model's responses and contribute little to improving model performance. Incorporating data influence is crucial for data synthesis and selection. Our method outperform state-of-the-art multi-agent optimization techniques, achieving an average improvement of 2.1\% in single-round iterations and a 2.5\% performance enhancement in multi-round iterations for the Information Exchange task. Within the same data synthesis budget, our method surpasses traditional approaches, delivering more efficient scaling of synthesis computation.

We summarize the main contributions as follows: 
\begin{itemize}
    \item We propose DITS, a novel framework that employs influence scores to guide tree search and data selection. This enables the prioritized selection of preference pairs that contribute more significantly to performance improvement.
    
    \item We derive the influence score estimation method for non-differentiable metrics. This approach substantially reduces computational overhead through inference computation, enabling more efficient synthesis time scaling.
    \item We achieve state-of-the-art performance across multiple multi-agent tasks and demonstrate that the framework's capability can be continuously improved through iterative rounds of data synthesis.
\end{itemize}