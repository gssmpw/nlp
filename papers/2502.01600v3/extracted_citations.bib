@inproceedings{ahmadian2024back,
 author = {Arash Ahmadian and
Chris Cremer and
Matthias Gall{\'{e}} and
Marzieh Fadaee and
Julia Kreutzer and
Olivier Pietquin and
Ahmet {\"{U}}st{\"{u}}n and
Sara Hooker},
 booktitle = {ACL},
 title = {Back to Basics: Revisiting {REINFORCE}-Style Optimization for Learning
from Human Feedback in {LLMs}},
 year = {2024}
}

@article{bai2024digirl,
 author = {Bai, Hao and Zhou, Yifei and Cemri, Mert and Pan, Jiayi and Suhr, Alane and Levine, Sergey and Kumar, Aviral},
 journal = {arXiv:2406.11896},
 title = {{DigiRL}: Training In-The-Wild Device-Control Agents with Autonomous Reinforcement Learning},
 year = {2024}
}

@inproceedings{carta2023grounding,
 author = {Carta, Thomas and Romac, Cl{\'e}ment and Wolf, Thomas and Lamprier, Sylvain and Sigaud, Olivier and Oudeyer, Pierre-Yves},
 booktitle = {ICML},
 title = {Grounding large language models in interactive environments with online reinforcement learning},
 year = {2023}
}

@article{chen2023fireact,
 author = {Chen, Baian and Shu, Chang and Shareghi, Ehsan and Collier, Nigel and Narasimhan, Karthik and Yao, Shunyu},
 journal = {arXiv:2310.05915},
 title = {{FireAct}: Toward Language Agent Fine-tuning},
 year = {2023}
}

@article{deepseekai2025deepseekr1,
 author = {{DeepSeek-AI}},
 journal = {arXiv:2501.12948},
 title = {{DeepSeek-R1}: Incentivizing Reasoning Capability in {LLMs} via Reinforcement Learning},
 year = {2025}
}

@article{gupta2025simple,
 author = {Shashank Gupta and Chaitanya Ahuja and Tsung-Yu Lin and Sreya Dutta Roy and Harrie Oosterhuis and Maarten de Rijke and Satya Narayan Shukla},
 journal = {arXiv:2503.00897},
 title = {A Simple and Effective Reinforcement Learning Method for Text-to-Image Diffusion Fine-tuning},
 year = {2025}
}

@article{havrilla2024teaching,
 author = {Havrilla, Alex and Du, Yuqing and Raparthy, Sharath Chandra and Nalmpantis, Christoforos and Dwivedi-Yu, Jane and Zhuravinskyi, Maksym and Hambro, Eric and Sukhbaatar, Sainbayar and Raileanu, Roberta},
 journal = {arXiv:2403.04642},
 title = {Teaching large language models to reason with reinforcement learning},
 year = {2024}
}

@article{kazemnejad2024vineppo,
 author = {Kazemnejad, Amirhossein and Aghajohari, Milad and Portelance, Eva and Sordoni, Alessandro and Reddy, Siva and Courville, Aaron and Roux, Nicolas Le},
 journal = {arXiv:2410.01679},
 title = {{VinePPO}: Unlocking {RL} Potential For {LLM} Reasoning Through Refined Credit Assignment},
 year = {2024}
}

@inproceedings{kim2024language,
 author = {Kim, Geunwoo and Baldi, Pierre and McAleer, Stephen},
 booktitle = {NeurIPS},
 title = {Language models can solve computer tasks},
 year = {2024}
}

@inproceedings{kool2019buy,
 author = {Kool, Wouter and van Hoof, Herke and Welling, Max},
 booktitle = {ICLR 2019 Workshops},
 title = {Buy 4 REINFORCE Samples, Get a Baseline for Free!},
 year = {2019}
}

@article{mitra2024agentinstruct,
 author = {Mitra, Arindam and Del Corro, Luciano and Zheng, Guoqing and Mahajan, Shweti and Rouhana, Dany and Codas, Andres and Lu, Yadong and Chen, Wei-ge and Vrousgos, Olga and Rosset, Corby and others},
 journal = {arXiv:2407.03502},
 title = {{AgentInstruct}: Toward Generative Teaching with Agentic Flows},
 year = {2024}
}

@article{nakano2021webgpt,
 author = {Nakano, Reiichiro and Hilton, Jacob and Balaji, Suchir and Wu, Jeff and Ouyang, Long and Kim, Christina and Hesse, Christopher and Jain, Shantanu and Kosaraju, Vineet and Saunders, William and others},
 journal = {arXiv:2112.09332},
 title = {{WebGPT}: Browser-assisted question-answering with human feedback},
 year = {2021}
}

@inproceedings{narasimhan2015language,
 author = {Karthik Narasimhan and
Tejas D. Kulkarni and
Regina Barzilay},
 booktitle = {EMNLP},
 title = {Language Understanding for Text-based Games using Deep Reinforcement
Learning},
 year = {2015}
}

@article{ouyang2022training,
 author = {Ouyang, Long and Wu, Jeffrey and Jiang, Xu and Almeida, Diogo and Wainwright, Carroll and Mishkin, Pamela and Zhang, Chong and Agarwal, Sandhini and Slama, Katarina and Ray, Alex and others},
 journal = {NeurIPS},
 title = {Training language models to follow instructions with human feedback},
 year = {2022}
}

@article{putta2024agent,
 author = {Putta, Pranav and Mills, Edmund and Garg, Naman and Motwani, Sumeet and Finn, Chelsea and Garg, Divyansh and Rafailov, Rafael},
 journal = {arXiv:2408.07199},
 title = {{Agent Q}: Advanced Reasoning and Learning for Autonomous {AI} Agents},
 year = {2024}
}

@inproceedings{qin2023toolllm,
 author = {Yujia Qin and
Shihao Liang and
Yining Ye and
Kunlun Zhu and
Lan Yan and
Yaxi Lu and
Yankai Lin and
Xin Cong and
Xiangru Tang and
Bill Qian and
others},
 booktitle = {ICLR},
 title = {{ToolLLM}: Facilitating Large Language Models to Master 16000+ Real-world {APIs}},
 year = {2024}
}

@article{schick2023toolformer,
 author = {Schick, Timo and Dwivedi-Yu, Jane and Dess{\`\i}, Roberto and Raileanu, Roberta and Lomeli, Maria and Hambro, Eric and Zettlemoyer, Luke and Cancedda, Nicola and Scialom, Thomas},
 journal = {NeurIPS},
 title = {Toolformer: Language models can teach themselves to use tools},
 year = {2023}
}

@article{schulman2017proximal,
 author = {Schulman, John and Wolski, Filip and Dhariwal, Prafulla and Radford, Alec and Klimov, Oleg},
 journal = {arXiv:1707.06347},
 title = {Proximal policy optimization algorithms},
 year = {2017}
}

@article{shao2024deepseekmath,
 author = {Shao, Zhihong and Wang, Peiyi and Zhu, Qihao and Xu, Runxin and Song, Junxiao and Bi, Xiao and Zhang, Haowei and Zhang, Mingchuan and Li, YK and Wu, Y and others},
 title = {{DeepSeekMath}: Pushing the Limits of Mathematical Reasoning in Open Language Models},
 journal = {arXiv:2402.03300},
 year = {2024},
}

@article{shinn2024reflexion,
 author = {Shinn, Noah and Cassano, Federico and Gopinath, Ashwin and Narasimhan, Karthik and Yao, Shunyu},
 journal = {NeurIPS},
 title = {Reflexion: Language agents with verbal reinforcement learning},
 year = {2024}
}

@article{singh2023beyond,
 author = {Avi Singh and
John D. Co{-}Reyes and
Rishabh Agarwal and
Ankesh Anand and
Piyush Patil and
Xavier Garcia and
Peter J. Liu and
James Harrison and
Jaehoon Lee and
Kelvin Xu and
others},
 journal = {TMLR},
 title = {Beyond Human Data: Scaling Self-Training for Problem-Solving with
Language Models},
 year = {2024}
}

@inproceedings{stiennon2020learning,
 author = {Stiennon, Nisan and Ouyang, Long and Wu, Jeff and Ziegler, Daniel M. and Lowe, Ryan and Voss, Chelsea and Radford, Alec and Amodei, Dario and Christiano, Paul},
 booktitle = {NeurIPS},
 title = {Learning to summarize from human feedback},
 year = {2020}
}

@inproceedings{wang2024executable,
 author = {Wang, Xingyao and Chen, Yangyi and Yuan, Lifan and Zhang, Yizhe and Li, Yunzhu and Peng, Hao and Ji, Heng},
 booktitle = {ICML},
 title = {Executable code actions elicit better {LLM} agents},
 year = {2024}
}

@inproceedings{yang2024intercode,
 author = {Yang, John and Prabhakar, Akshara and Narasimhan, Karthik and Yao, Shunyu},
 booktitle = {NeurIPS},
 title = {InterCode: standardizing and benchmarking interactive coding with execution feedback},
 year = {2023}
}

@inproceedings{yao2020keep,
 author = {Yao, Shunyu  and
Rao, Rohan  and
Hausknecht, Matthew  and
Narasimhan, Karthik},
 booktitle = {EMNLP},
 title = {Keep {CALM} and Explore: Language Models for Action Generation in Text-based Games},
 year = {2020}
}

@inproceedings{yao2022react,
 author = {Shunyu Yao and Jeffrey Zhao and Dian Yu and Nan Du and Izhak Shafran and Karthik R Narasimhan and Yuan Cao},
 booktitle = {ICLR},
 title = {{ReAct}: Synergizing Reasoning and Acting in Language Models},
 year = {2023}
}

@inproceedings{yao2022webshop,
 author = {Yao, Shunyu and Chen, Howard and Yang, John and Narasimhan, Karthik},
 booktitle = {NeurIPS},
 title = {{WebShop}: Towards Scalable Real-World Web Interaction with Grounded Language Agents},
 year = {2022}
}

@article{yuan2023scaling,
 author = {Yuan, Zheng and Yuan, Hongyi and Li, Chengpeng and Dong, Guanting and Lu, Keming and Tan, Chuanqi and Zhou, Chang and Zhou, Jingren},
 journal = {arXiv:2308.01825},
 title = {Scaling relationship on learning mathematical reasoning with large language models},
 year = {2023}
}

@inproceedings{zhai2024fine,
 author = {Zhai, Yuexiang and Bai, Hao and Lin, Zipeng and Pan, Jiayi and Tong, Shengbang and Zhou, Yifei and Suhr, Alane and Xie, Saining and LeCun, Yann and Ma, Yi and Levine, Sergey},
 booktitle = {NeurIPS},
 title = {Fine-Tuning Large Vision-Language Models as Decision-Making Agents via Reinforcement Learning},
 year = {2024}
}

@inproceedings{zhou2024archer,
 author = {Zhou, Yifei and Zanette, Andrea},
 booktitle = {ICML},
 title = {{ArCHer}: training language model agents via hierarchical multi-turn {RL}},
 year = {2024}
}

@article{ziegler2019fine,
 author = {Ziegler, Daniel M and Stiennon, Nisan and Wu, Jeffrey and Brown, Tom B and Radford, Alec and Amodei, Dario and Christiano, Paul and Irving, Geoffrey},
 journal = {arXiv:1909.08593},
 title = {Fine-tuning language models from human preferences},
 year = {2019}
}

