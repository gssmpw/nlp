#########
# General
#########

@article{xiong2024earthnets,
  title={EarthNets: Empowering artificial intelligence for Earth observation},
  author={Xiong, Zhitong and Zhang, Fahong and Wang, Yi and Shi, Yilei and Zhu, Xiao Xiang},
  journal={IEEE Geoscience and Remote Sensing Magazine},
  year={2024},
  publisher={IEEE}
}

@article{li2024vision,
  title={Vision-language models in remote sensing: Current progress and future trends},
  author={Li, Xiang and Wen, Congcong and Hu, Yuan and Yuan, Zhenghang and Zhu, Xiao Xiang},
  journal={IEEE Geoscience and Remote Sensing Magazine},
  year={2024},
  publisher={IEEE}
}

@article{bommasani2021opportunities,
  title={On the opportunities and risks of foundation models},
  author={Bommasani, Rishi and Hudson, Drew A and Adeli, Ehsan and Altman, Russ and Arora, Simran and von Arx, Sydney and Bernstein, Michael S and Bohg, Jeannette and Bosselut, Antoine and Brunskill, Emma and others},
  journal={arXiv preprint arXiv:2108.07258},
  year={2021}
}

@inproceedings{li2023blip,
  title={Blip-2: Bootstrapping language-image pre-training with frozen image encoders and large language models},
  author={Li, Junnan and Li, Dongxu and Savarese, Silvio and Hoi, Steven},
  booktitle={International conference on machine learning},
  pages={19730--19742},
  year={2023},
  organization={PMLR}
}

@article{zhu2023minigpt,
  title={Minigpt-4: Enhancing vision-language understanding with advanced large language models},
  author={Zhu, Deyao and Chen, Jun and Shen, Xiaoqian and Li, Xiang and Elhoseiny, Mohamed},
  journal={arXiv preprint arXiv:2304.10592},
  year={2023}
}

@article{dosovitskiy2020image,
    title={An image is worth 16x16 words: Transformers for image recognition at scale},
    author={Dosovitskiy, Alexey and Beyer, Lucas and Kolesnikov, Alexander and Weissenborn, Dirk and Zhai, Xiaohua and Unterthiner, Thomas and Dehghani, Mostafa and Minderer, Matthias and Heigold, Georg and Gelly, Sylvain and others},
    journal={arXiv preprint arXiv:2010.11929},
    year={2020}
}


##########
# Datasets
##########

@article{schuhmann2022laion,
  title={Laion-5b: An open large-scale dataset for training next generation image-text models},
  author={Schuhmann, Christoph and Beaumont, Romain and Vencu, Richard and Gordon, Cade and Wightman, Ross and Cherti, Mehdi and Coombes, Theo and Katta, Aarush and Mullis, Clayton and Wortsman, Mitchell and others},
  journal={Advances in Neural Information Processing Systems},
  volume={35},
  pages={25278--25294},
  year={2022}
}

@article{schuhmann2021laion,
  title={Laion-400m: Open dataset of clip-filtered 400 million image-text pairs},
  author={Schuhmann, Christoph and Vencu, Richard and Beaumont, Romain and Kaczmarczyk, Robert and Mullis, Clayton and Katta, Aarush and Coombes, Theo and Jitsev, Jenia and Komatsuzaki, Aran},
  journal={arXiv preprint arXiv:2111.02114},
  year={2021}
}

@misc{schuhmann2022laioncoco,
  author={Schuhmann, Christoph and KÃ¶pf, Andreas and Coombes, Theo and Vencu, Richard and Trom, Benjamin and Beaumont, Romain},
  title={{LAION COCO: 600M synthetic captions from LAION2B-EN}},
  year={2022}
}

@misc{byeon2022coyo,
  title={Coyo-700m: Image-text pair dataset},
  author={Byeon, Minwoo and Park, Beomhee and Kim, Haecheon and Lee, Sungjun and Baek, Woonhyuk and Kim, Saehoon},
  year={2022}
}

@inproceedings{sharma2018conceptual,
  title={Conceptual captions: A cleaned, hypernymed, image alt-text dataset for automatic image captioning},
  author={Sharma, Piyush and Ding, Nan and Goodman, Sebastian and Soricut, Radu},
  booktitle={Proceedings of the 56th Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers)},
  pages={2556--2565},
  year={2018}
}

@inproceedings{changpinyo2021conceptual,
  title={Conceptual 12m: Pushing web-scale image-text pre-training to recognize long-tail visual concepts},
  author={Changpinyo, Soravit and Sharma, Piyush and Ding, Nan and Soricut, Radu},
  booktitle={Proceedings of the IEEE/CVF conference on computer vision and pattern recognition},
  pages={3558--3568},
  year={2021}
}

@article{thomee2016yfcc100m,
  title={Yfcc100m: The new data in multimedia research},
  author={Thomee, Bart and Shamma, David A and Friedland, Gerald and Elizalde, Benjamin and Ni, Karl and Poland, Douglas and Borth, Damian and Li, Li-Jia},
  journal={Communications of the ACM},
  volume={59},
  number={2},
  pages={64--73},
  year={2016},
  publisher={ACM New York, NY, USA}
}

@inproceedings{srinivasan2021wit,
  title={Wit: Wikipedia-based image text dataset for multimodal multilingual machine learning},
  author={Srinivasan, Krishna and Raman, Karthik and Chen, Jiecao and Bendersky, Michael and Najork, Marc},
  booktitle={Proceedings of the 44th international ACM SIGIR conference on research and development in information retrieval},
  pages={2443--2449},
  year={2021}
}

@article{desai2021redcaps,
  title={Redcaps: Web-curated image-text data created by the people, for the people},
  author={Desai, Karan and Kaul, Gaurav and Aysola, Zubin and Johnson, Justin},
  journal={arXiv preprint arXiv:2111.11431},
  year={2021}
}

@article{ordonez2011im2text,
  title={Im2text: Describing images using 1 million captioned photographs},
  author={Ordonez, Vicente and Kulkarni, Girish and Berg, Tamara},
  journal={Advances in neural information processing systems},
  volume={24},
  year={2011}
}

@article{krishna2017visual,
  title={Visual genome: Connecting language and vision using crowdsourced dense image annotations},
  author={Krishna, Ranjay and Zhu, Yuke and Groth, Oliver and Johnson, Justin and Hata, Kenji and Kravitz, Joshua and Chen, Stephanie and Kalantidis, Yannis and Li, Li-Jia and Shamma, David A and others},
  journal={International journal of computer vision},
  volume={123},
  pages={32--73},
  year={2017},
  publisher={Springer}
}

@inproceedings{radford2021learning,
  title={Learning transferable visual models from natural language supervision},
  author={Radford, Alec and Kim, Jong Wook and Hallacy, Chris and Ramesh, Aditya and Goh, Gabriel and Agarwal, Sandhini and Sastry, Girish and Askell, Amanda and Mishkin, Pamela and Clark, Jack and others},
  booktitle={International conference on machine learning},
  pages={8748--8763},
  year={2021},
  organization={PMLR}
}

@article{liu2024visual,
  title={Visual instruction tuning},
  author={Liu, Haotian and Li, Chunyuan and Wu, Qingyang and Lee, Yong Jae},
  journal={Advances in neural information processing systems},
  volume={36},
  year={2024}
}

@inproceedings{liu2024improved,
  title={Improved baselines with visual instruction tuning},
  author={Liu, Haotian and Li, Chunyuan and Li, Yuheng and Lee, Yong Jae},
  booktitle={Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition},
  pages={26296--26306},
  year={2024}
}

@article{fang2023data,
  title={Data filtering networks},
  author={Fang, Alex and Jose, Albin Madappally and Jain, Amit and Schmidt, Ludwig and Toshev, Alexander and Shankar, Vaishaal},
  journal={arXiv preprint arXiv:2309.17425},
  year={2023}
}

@article{wang2024cliploss,
  title={CLIPLoss and Norm-Based Data Selection Methods for Multimodal Contrastive Learning},
  author={Wang, Yiping and Chen, Yifang and Yan, Wendan and Fang, Alex and Zhou, Wenjing and Jamieson, Kevin and Du, Simon Shaolei},
  journal={arXiv preprint arXiv:2405.19547},
  year={2024}
}

@article{xu2023demystifying,
    title={Demystifying clip data},
    author={Xu, Hu and Xie, Saining and Tan, Xiaoqing Ellen and Huang, Po-Yao and Howes, Russell and Sharma, Vasu and Li, Shang-Wen and Ghosh, Gargi and Zettlemoyer, Luke and Feichtenhofer, Christoph},
    journal={arXiv preprint arXiv:2309.16671},
    year={2023}
}

@inproceedings{zhai2023sigmoid,
    author = {X. Zhai and B. Mustafa and A. Kolesnikov and L. Beyer},
    booktitle = {2023 IEEE/CVF International Conference on Computer Vision (ICCV)},
    title = {Sigmoid Loss for Language Image Pre-Training},
    year = {2023},
    volume = {},
    issn = {},
    pages = {11941-11952},
    keywords = {computer vision;memory management;self-supervised learning;robustness;standards},
    doi = {10.1109/ICCV51070.2023.01100},
    url = {https://doi.ieeecomputersociety.org/10.1109/ICCV51070.2023.01100},
    publisher = {IEEE Computer Society},
    address = {Los Alamitos, CA, USA},
    month = {oct}
}

@software{ilharco_gabriel_2021_5143773,
  author       = {Ilharco, Gabriel and
                  Wortsman, Mitchell and
                  Wightman, Ross and
                  Gordon, Cade and
                  Carlini, Nicholas and
                  Taori, Rohan and
                  Dave, Achal and
                  Shankar, Vaishaal and
                  Namkoong, Hongseok and
                  Miller, John and
                  Hajishirzi, Hannaneh and
                  Farhadi, Ali and
                  Schmidt, Ludwig},
  title        = {OpenCLIP},
  month        = jul,
  year         = 2021,
  note         = {If you use this software, please cite it as below.},
  publisher    = {Zenodo},
  version      = {0.1},
  doi          = {10.5281/zenodo.5143773},
  url          = {https://doi.org/10.5281/zenodo.5143773}
}

@article{li2023inverse,
    title={An Inverse Scaling Law for CLIP Training},
    author={Li, Xianhang and Wang, Zeyu and Xie, Cihang},
    journal={arXiv preprint arXiv:2305.07017},
    year={2023}
}

@article{li2023clipa,
    title={CLIPA-v2: Scaling CLIP Training with 81.1\% Zero-shot ImageNet Accuracy within a \$10,000 Budget; An Extra \$4,000 Unlocks 81.8\% Accuracy},
    author={Li, Xianhang and Wang, Zeyu and Xie, Cihang},
    journal={arXiv preprint arXiv:2306.15658},
    year={2023}
}

@article{sun2023eva,
    title={Eva-clip: Improved training techniques for clip at scale},
    author={Sun, Quan and Fang, Yuxin and Wu, Ledell and Wang, Xinlong and Cao, Yue},
    journal={arXiv preprint arXiv:2303.15389},
    year={2023}
}

@inproceedings{cherti2023reproducible,
    title={Reproducible scaling laws for contrastive language-image learning},
    author={Cherti, Mehdi and Beaumont, Romain and Wightman, Ross and Wortsman, Mitchell and Ilharco, Gabriel and Gordon, Cade and Schuhmann, Christoph and Schmidt, Ludwig and Jitsev, Jenia},
    booktitle={Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition},
    pages={2818--2829},
    year={2023}
}

@article{gadre2024datacomp,
  title={Datacomp: In search of the next generation of multimodal datasets},
  author={Gadre, Samir Yitzhak and Ilharco, Gabriel and Fang, Alex and Hayase, Jonathan and Smyrnis, Georgios and Nguyen, Thao and Marten, Ryan and Wortsman, Mitchell and Ghosh, Dhruba and Zhang, Jieyu and others},
  journal={Advances in Neural Information Processing Systems},
  volume={36},
  year={2024}
}

@article{birhane2024into,
  title={Into the laionâs den: Investigating hate in multimodal datasets},
  author={Birhane, Abeba and Han, Sanghyun and Boddeti, Vishnu and Luccioni, Sasha and others},
  journal={Advances in Neural Information Processing Systems},
  volume={36},
  year={2024}
}



#############
# RS Datasets
#############

@inproceedings{qu2016deep,
    title={Deep semantic understanding of high resolution remote sensing image},
    author={Qu, Bo and Li, Xuelong and Tao, Dacheng and Lu, Xiaoqiang},
    booktitle={2016 International conference on computer, information and telecommunication systems (Cits)},
    pages={1--5},
    year={2016},
    organization={IEEE}
}

@inproceedings{yang2010bag,
  title={Bag-of-visual-words and spatial extensions for land-use classification},
  author={Yang, Yi and Newsam, Shawn},
  booktitle={Proceedings of the 18th SIGSPATIAL international conference on advances in geographic information systems},
  pages={270--279},
  year={2010}
}

@article{lu2017exploring,
    title={Exploring models and data for remote sensing image caption generation},
    author={Lu, Xiaoqiang and Wang, Binqiang and Zheng, Xiangtao and Li, Xuelong},
    journal={IEEE Transactions on Geoscience and Remote Sensing},
    volume={56},
    number={4},
    pages={2183--2195},
    year={2017},
    publisher={IEEE}
}

@article{yuan2022exploring,
    author={Yuan, Zhiqiang and Zhang, Wenkai and Fu, Kun and Li, Xuan and Deng, Chubo and Wang, Hongqi and Sun, Xian},
    journal={IEEE Transactions on Geoscience and Remote Sensing}, 
    title={Exploring a Fine-Grained Multiscale Method for Cross-Modal Remote Sensing Image Retrieval}, 
    year={2022},
    volume={60},
    number={},
    pages={1-19},
    keywords={Task analysis;Image retrieval;Feature extraction;Visualization;Remote sensing;Neural networks;Sun;Asymmetric multimodal feature matching network (AMFMN);cross-modal remote sensing (RS) textâimage retrieval;deep features similarity;Remote Sensing Image-Text Match dataset (RSITMD);triplet loss of adaptive margin},
    doi={10.1109/TGRS.2021.3078451}
}

@article{abdullah2020textrs,
    title={TextRS: Deep bidirectional triplet network for matching text to remote sensing images},
    author={Abdullah, Taghreed and Bazi, Yakoub and Al Rahhal, Mohamad M and Mekhalfi, Mohamed L and Rangarajan, Lalitha and Zuair, Mansour},
    journal={Remote Sensing},
    volume={12},
    number={3},
    pages={405},
    year={2020},
    publisher={MDPI}
}

@article{zhan2023rsvg,
    title={Rsvg: Exploring data and models for visual grounding on remote sensing data},
    author={Zhan, Yang and Xiong, Zhitong and Yuan, Yuan},
    journal={IEEE Transactions on Geoscience and Remote Sensing},
    volume={61},
    pages={1--13},
    year={2023},
    publisher={IEEE}
}

@article{li2020object,
  title={Object detection in optical remote sensing images: A survey and a new benchmark},
  author={Li, Ke and Wan, Gang and Cheng, Gong and Meng, Liqiu and Han, Junwei},
  journal={ISPRS journal of photogrammetry and remote sensing},
  volume={159},
  pages={296--307},
  year={2020},
  publisher={Elsevier}
}

@inproceedings{kuckreja2024geochat,
  title={Geochat: Grounded large vision-language model for remote sensing},
  author={Kuckreja, Kartik and Danish, Muhammad Sohail and Naseer, Muzammal and Das, Abhijit and Khan, Salman and Khan, Fahad Shahbaz},
  booktitle={Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition},
  pages={27831--27840},
  year={2024}
}

@inproceedings{wang2024skyscript,
  title={Skyscript: A large and semantically diverse vision-language dataset for remote sensing},
  author={Wang, Zhecheng and Prabha, Rajanie and Huang, Tianyuan and Wu, Jiajun and Rajagopal, Ram},
  booktitle={Proceedings of the AAAI Conference on Artificial Intelligence},
  volume={38},
  number={6},
  pages={5805--5813},
  year={2024}
}

@article{zhang2024rs5m,
  title={RS5M and GeoRSCLIP: A large scale vision-language dataset and a large vision-language model for remote sensing},
  author={Zhang, Zilun and Zhao, Tiancheng and Guo, Yulong and Yin, Jianwei},
  journal={IEEE Transactions on Geoscience and Remote Sensing},
  year={2024},
  publisher={IEEE}
}

@article{cheng2022nwpu,
  title={NWPU-captions dataset and MLCA-net for remote sensing image captioning},
  author={Cheng, Qimin and Huang, Haiyan and Xu, Yuan and Zhou, Yuzhuo and Li, Huanying and Wang, Zhongyuan},
  journal={IEEE Transactions on Geoscience and Remote Sensing},
  volume={60},
  pages={1--19},
  year={2022},
  publisher={IEEE}
}

@article{lobry2020rsvqa,
  title={RSVQA: Visual question answering for remote sensing data},
  author={Lobry, Sylvain and Marcos, Diego and Murray, Jesse and Tuia, Devis},
  journal={IEEE Transactions on Geoscience and Remote Sensing},
  volume={58},
  number={12},
  pages={8555--8566},
  year={2020},
  publisher={IEEE}
}

@article{rahnemoonfar2021floodnet,
  title={Floodnet: A high resolution aerial imagery dataset for post flood scene understanding},
  author={Rahnemoonfar, Maryam and Chowdhury, Tashnim and Sarkar, Argho and Varshney, Debvrat and Yari, Masoud and Murphy, Robin Roberson},
  journal={IEEE Access},
  volume={9},
  pages={89644--89654},
  year={2021},
  publisher={IEEE}
}

@inproceedings{christie2018functional,
  title={Functional map of the world},
  author={Christie, Gordon and Fendley, Neil and Wilson, James and Mukherjee, Ryan},
  booktitle={Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition},
  pages={6172--6180},
  year={2018}
}

@article{hu2023rsgpt,
  title={Rsgpt: A remote sensing vision language model and benchmark},
  author={Hu, Yuan and Yuan, Jianlong and Wen, Congcong and Lu, Xiaonan and Li, Xiang},
  journal={arXiv preprint arXiv:2307.15266},
  year={2023}
}

@article{luo2024skysensegpt,
  title={Skysensegpt: A fine-grained instruction tuning dataset and model for remote sensing vision-language understanding},
  author={Luo, Junwei and Pang, Zhen and Zhang, Yongjun and Wang, Tingzhu and Wang, Linlin and Dang, Bo and Lao, Jiangwei and Wang, Jian and Chen, Jingdong and Tan, Yihua and others},
  journal={arXiv preprint arXiv:2406.10100},
  year={2024}
}

@article{muhtar2024lhrs,
  title={Lhrs-bot: Empowering remote sensing with vgi-enhanced large multimodal language model},
  author={Muhtar, Dilxat and Li, Zhenshi and Gu, Feng and Zhang, Xueliang and Xiao, Pengfeng},
  journal={arXiv preprint arXiv:2402.02544},
  year={2024}
}

@article{zhao2024luojiahog,
  title={LuoJiaHOG: A Hierarchy Oriented Geo-aware Image Caption Dataset for Remote Sensing Image-Text Retrival},
  author={Zhao, Yuanxin and Zhang, Mi and Yang, Bingnan and Zhang, Zhan and Kang, Jiaju and Gong, Jianya},
  journal={arXiv preprint arXiv:2403.10887},
  year={2024}
}

@article{liu2022remote,
  title={Remote sensing image change captioning with dual-branch transformers: A new method and a large scale dataset},
  author={Liu, Chenyang and Zhao, Rui and Chen, Hao and Zou, Zhengxia and Shi, Zhenwei},
  journal={IEEE Transactions on Geoscience and Remote Sensing},
  volume={60},
  pages={1--20},
  year={2022},
  publisher={IEEE}
}

@article{yuan2024chatearthnet,
  title={Chatearthnet: A global-scale, high-quality image-text dataset for remote sensing},
  author={Yuan, Zhenghang and Xiong, Zhitong and Mou, Lichao and Zhu, Xiao Xiang},
  journal={arXiv preprint arXiv:2402.11325},
  year={2024}
}

@article{wang2022advancing,
  title={Advancing plain vision transformer toward remote sensing foundation model},
  author={Wang, Di and Zhang, Qiming and Xu, Yufei and Zhang, Jing and Du, Bo and Tao, Dacheng and Zhang, Liangpei},
  journal={IEEE Transactions on Geoscience and Remote Sensing},
  volume={61},
  pages={1--15},
  year={2022},
  publisher={IEEE}
}

@article{zhou2018patternnet,
  title={PatternNet: A benchmark dataset for performance evaluation of remote sensing image retrieval},
  author={Zhou, Weixun and Newsam, Shawn and Li, Congmin and Shao, Zhenfeng},
  journal={ISPRS journal of photogrammetry and remote sensing},
  volume={145},
  pages={197--209},
  year={2018},
  publisher={Elsevier}
}

@article{xia2017aid,
  title={AID: A benchmark data set for performance evaluation of aerial scene classification},
  author={Xia, Gui-Song and Hu, Jingwen and Hu, Fan and Shi, Baoguang and Bai, Xiang and Zhong, Yanfei and Zhang, Liangpei and Lu, Xiaoqiang},
  journal={IEEE Transactions on Geoscience and Remote Sensing},
  volume={55},
  number={7},
  pages={3965--3981},
  year={2017},
  publisher={IEEE}
}

@article{ge2024rsteller,
  title={RSTeller: Scaling Up Visual Language Modeling in Remote Sensing with Rich Linguistic Semantics from Openly Available Data and Large Language Models},
  author={Ge, Junyao and Zheng, Yang and Guo, Kaitai and Liang, Jimin},
  journal={arXiv preprint arXiv:2408.14744},
  year={2024}
}

@article{liu2025text2earth,
  title={Text2Earth: Unlocking Text-driven Remote Sensing Image Generation with a Global-Scale Dataset and a Foundation Model},
  author={Liu, Chenyang and Chen, Keyan and Zhao, Rui and Zou, Zhengxia and Shi, Zhenwei},
  journal={arXiv preprint arXiv:2501.00895},
  year={2025}
}

@inproceedings{sumbul2019bigearthnet,
  title={Bigearthnet: A large-scale benchmark archive for remote sensing image understanding},
  author={Sumbul, Gencer and Charfuelan, Marcela and Demir, Beg{\"u}m and Markl, Volker},
  booktitle={IGARSS 2019-2019 IEEE International Geoscience and Remote Sensing Symposium},
  pages={5901--5904},
  year={2019},
  organization={IEEE}
}

@article{sumbul2021bigearthnet,
  title={BigEarthNet-MM: A large-scale, multimodal, multilabel benchmark archive for remote sensing image classification and retrieval [software and data sets]},
  author={Sumbul, Gencer and De Wall, Arne and Kreuziger, Tristan and Marcelino, Filipe and Costa, Hugo and Benevides, Pedro and Caetano, Mario and Demir, Beg{\"u}m and Markl, Volker},
  journal={IEEE Geoscience and Remote Sensing Magazine},
  volume={9},
  number={3},
  pages={174--180},
  year={2021},
  publisher={IEEE}
}

@article{long2021creating,
  title={On creating benchmark dataset for aerial image interpretation: Reviews, guidances, and million-aid},
  author={Long, Yang and Xia, Gui-Song and Li, Shengyang and Yang, Wen and Yang, Michael Ying and Zhu, Xiao Xiang and Zhang, Liangpei and Li, Deren},
  journal={IEEE Journal of selected topics in applied earth observations and remote sensing},
  volume={14},
  pages={4205--4230},
  year={2021},
  publisher={IEEE}
}

@inproceedings{mendieta2023towards,
  title={Towards Geospatial Foundation Models via Continual Pretraining},
  author={Mendieta, Mat{\'\i}as and Han, Boran and Shi, Xingjian and Zhu, Yi and Chen, Chen},
  booktitle={Proceedings of the IEEE/CVF International Conference on Computer Vision},
  pages={16806--16816},
  year={2023}
}

@article{wang2023ssl4eo,
  title={SSL4EO-S12: A large-scale multimodal, multitemporal dataset for self-supervised learning in Earth observation [Software and Data Sets]},
  author={Wang, Yi and Braham, Nassim Ait Ali and Xiong, Zhitong and Liu, Chenying and Albrecht, Conrad M and Zhu, Xiao Xiang},
  journal={IEEE Geoscience and Remote Sensing Magazine},
  volume={11},
  number={3},
  pages={98--106},
  year={2023},
  publisher={IEEE}
}

@InProceedings{Bountos_2022_CVPR,
    author    = {Bountos, Nikolaos Ioannis and Papoutsis, Ioannis and Michail, Dimitrios and Karavias, Andreas and Elias, Panagiotis and Parcharidis, Isaak},
    title     = {Hephaestus: A Large Scale Multitask Dataset Towards InSAR Understanding},
    booktitle = {Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR) Workshops},
    month     = {June},
    year      = {2022},
    pages     = {1453-1462}
}

@article{lazecky2020licsar,
  title={LiCSAR: An automatic InSAR tool for measuring and monitoring tectonic and volcanic activity},
  author={Lazeck{\`y}, Milan and Spaans, Karsten and Gonz{\'a}lez, Pablo J and Maghsoudi, Yasser and Morishita, Yu and Albino, Fabien and Elliott, John and Greenall, Nicholas and Hatton, Emma and Hooper, Andrew and others},
  journal={Remote Sensing},
  volume={12},
  number={15},
  pages={2430},
  year={2020},
  publisher={MDPI}
}

@article{zavras2024mind,
    title={Mind the modality gap: Towards a remote sensing vision-language model via cross-modal alignment},
    author={Zavras, Angelos and Michail, Dimitrios and Demir, Beg{\"u}m and Papoutsis, Ioannis},
    journal={arXiv preprint arXiv:2402.09816},
    year={2024}
}





#####
#Misc
#####

@article{chiang2023vicuna,
  title={Vicuna: An open-source chatbot impressing gpt-4 with 90\%* chatgpt quality},
  author={Chiang, Wei-Lin and Li, Zhuohan and Lin, Zi and Sheng, Ying and Wu, Zhanghao and Zhang, Hao and Zheng, Lianmin and Zhuang, Siyuan and Zhuang, Yonghao and Gonzalez, Joseph E and others},
  journal={See https://vicuna. lmsys. org (accessed 14 April 2023)},
  volume={2},
  number={3},
  pages={6},
  year={2023}
}

@inproceedings{xia2018dota,
  title={DOTA: A large-scale dataset for object detection in aerial images},
  author={Xia, Gui-Song and Bai, Xiang and Ding, Jian and Zhu, Zhen and Belongie, Serge and Luo, Jiebo and Datcu, Mihai and Pelillo, Marcello and Zhang, Liangpei},
  booktitle={Proceedings of the IEEE conference on computer vision and pattern recognition},
  pages={3974--3983},
  year={2018}
}

@article{sun2022fair1m,
  title={FAIR1M: A benchmark dataset for fine-grained object recognition in high-resolution remote sensing imagery},
  author={Sun, Xian and Wang, Peijin and Yan, Zhiyuan and Xu, Feng and Wang, Ruiping and Diao, Wenhui and Chen, Jin and Li, Jihao and Feng, Yingchao and Xu, Tao and others},
  journal={ISPRS Journal of Photogrammetry and Remote Sensing},
  volume={184},
  pages={116--130},
  year={2022},
  publisher={Elsevier}
}

@article{cheng2017remote,
  title={Remote sensing image scene classification: Benchmark and state of the art},
  author={Cheng, Gong and Han, Junwei and Lu, Xiaoqiang},
  journal={Proceedings of the IEEE},
  volume={105},
  number={10},
  pages={1865--1883},
  year={2017},
  publisher={IEEE}
}

@misc{niemeyer2008geohash,
  author    = {Niemeyer, Gustavo},
  title     = {Geohash: a fast, hierarchical, latitude/longitude geocoding system},
  year      = {2008},
  howpublished = {Weblog post},
  url       = {http://geohash.org/site/tips.html},
  note      = {Accessed: [Date you accessed it, e.g., 2025-01-12]},
}

@article{chen2016training,
  title={Training deep nets with sublinear memory cost},
  author={Chen, Tianqi and Xu, Bing and Zhang, Chiyuan and Guestrin, Carlos},
  journal={arXiv preprint arXiv:1604.06174},
  year={2016}
}

@article{kingma2014adam,
    title={Adam: A method for stochastic optimization},
    author={Kingma, Diederik P and Ba, Jimmy},
    journal={arXiv preprint arXiv:1412.6980},
    year={2014}
}

@article{loshchilov2017decoupled,
    title={Decoupled weight decay regularization},
    author={Loshchilov, Ilya and Hutter, Frank},
    journal={arXiv preprint arXiv:1711.05101},
    year={2017}
}

@misc{andriushchenko2023need,
    title={Why Do We Need Weight Decay in Modern Deep Learning?}, 
    author={Maksym Andriushchenko and Francesco D'Angelo and Aditya Varre and Nicolas Flammarion},
    year={2023},
    eprint={2310.04415},
    archivePrefix={arXiv},
    primaryClass={cs.LG}
}

@article{hu2021lora,
  title={Lora: Low-rank adaptation of large language models},
  author={Hu, Edward J and Shen, Yelong and Wallis, Phillip and Allen-Zhu, Zeyuan and Li, Yuanzhi and Wang, Shean and Wang, Lu and Chen, Weizhu},
  journal={arXiv preprint arXiv:2106.09685},
  year={2021}
}

@inproceedings{papineni2002bleu,
  title={Bleu: a method for automatic evaluation of machine translation},
  author={Papineni, Kishore and Roukos, Salim and Ward, Todd and Zhu, Wei-Jing},
  booktitle={Proceedings of the 40th annual meeting of the Association for Computational Linguistics},
  pages={311--318},
  year={2002}
}

@inproceedings{lin2004rouge,
  title={Rouge: A package for automatic evaluation of summaries},
  author={Lin, Chin-Yew},
  booktitle={Text summarization branches out},
  pages={74--81},
  year={2004}
}

@inproceedings{banerjee2005meteor,
  title={METEOR: An automatic metric for MT evaluation with improved correlation with human judgments},
  author={Banerjee, Satanjeev and Lavie, Alon},
  booktitle={Proceedings of the acl workshop on intrinsic and extrinsic evaluation measures for machine translation and/or summarization},
  pages={65--72},
  year={2005}
}



###########
#RS + LAION
###########

@inproceedings{panigrahi2023have,
  title={Have foundational models seen satellite images?},
  author={Panigrahi, Akash and Verma, Sagar and Terris, Matthieu and Vakalopoulou, Maria},
  booktitle={IGARSS 2023-2023 IEEE International Geoscience and Remote Sensing Symposium},
  pages={4998--5001},
  year={2023},
  organization={IEEE}
}

@article{czerkawski2023laion,
  title={From LAION-5B to LAION-EO: Filtering billions of images using anchor datasets for satellite image extraction},
  author={Czerkawski, Mikolaj and Francis, Alistair},
  journal={arXiv preprint arXiv:2309.15535},
  year={2023}
}

@article{aybar2022cloudsen12,
  title={CloudSEN12, a global dataset for semantic understanding of cloud and cloud shadow in Sentinel-2},
  author={Aybar, Cesar and Ysuhuaylas, Luis and Loja, Jhomira and Gonzales, Karen and Herrera, Fernando and Bautista, Lesly and Yali, Roy and Flores, Angie and Diaz, Lissette and Cuenca, Nicole and others},
  journal={Scientific data},
  volume={9},
  number={1},
  pages={782},
  year={2022},
  publisher={Nature Publishing Group UK London}
}




################
#Better Captions
################

@inproceedings{rotstein2024fusecap,
  title={Fusecap: Leveraging large language models for enriched fused image captions},
  author={Rotstein, Noam and Bensa{\"\i}d, David and Brody, Shaked and Ganz, Roy and Kimmel, Ron},
  booktitle={Proceedings of the IEEE/CVF Winter Conference on Applications of Computer Vision},
  pages={5689--5700},
  year={2024}
}

@article{li2024if,
  title={What If We Recaption Billions of Web Images with LLaMA-3?},
  author={Li, Xianhang and Tu, Haoqin and Hui, Mude and Wang, Zeyu and Zhao, Bingchen and Xiao, Junfei and Ren, Sucheng and Mei, Jieru and Liu, Qing and Zheng, Huangjie and others},
  journal={arXiv preprint arXiv:2406.08478},
  year={2024}
}

@article{sharifzadeh2024synth,
  title={Synth$^2$: Boosting Visual-Language Models with Synthetic Captions and Image Embeddings},
  author={Sharifzadeh, Sahand and Kaplanis, Christos and Pathak, Shreya and Kumaran, Dharshan and Ilic, Anastasija and Mitrovic, Jovana and Blundell, Charles and Banino, Andrea},
  journal={arXiv preprint arXiv:2403.07750},
  year={2024}
}

@article{liu2024can,
  title={Can Medical Vision-Language Pre-training Succeed with Purely Synthetic Data?},
  author={Liu, Che and Wan, Zhongwei and Wang, Haozhe and Chen, Yinda and Qaiser, Talha and Jin, Chen and Yousefi, Fariba and Burlutskiy, Nikolay and Arcucci, Rossella},
  journal={arXiv preprint arXiv:2410.13523},
  year={2024}
}

@article{xu2024altogether,
  title={Altogether: Image Captioning via Re-aligning Alt-text},
  author={Xu, Hu and Huang, Po-Yao and Tan, Xiaoqing Ellen and Yeh, Ching-Feng and Kahn, Jacob and Jou, Christine and Ghosh, Gargi and Levy, Omer and Zettlemoyer, Luke and Yih, Wen-tau and others},
  journal={arXiv preprint arXiv:2410.17251},
  year={2024}
}

@inproceedings{yu2024capsfusion,
  title={Capsfusion: Rethinking image-text data at scale},
  author={Yu, Qiying and Sun, Quan and Zhang, Xiaosong and Cui, Yufeng and Zhang, Fan and Cao, Yue and Wang, Xinlong and Liu, Jingjing},
  booktitle={Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition},
  pages={14022--14032},
  year={2024}
}


@article{nguyen2024improving,
  title={Improving multimodal datasets with image captioning},
  author={Nguyen, Thao and Gadre, Samir Yitzhak and Ilharco, Gabriel and Oh, Sewoong and Schmidt, Ludwig},
  journal={Advances in Neural Information Processing Systems},
  volume={36},
  year={2024}
}

@article{fan2024improving,
  title={Improving clip training with language rewrites},
  author={Fan, Lijie and Krishnan, Dilip and Isola, Phillip and Katabi, Dina and Tian, Yonglong},
  journal={Advances in Neural Information Processing Systems},
  volume={36},
  year={2024}
}

@misc{laioncoco,
  title = {LAION-COCO: 600M Synthetic Captions from Laion2B-en},
  author = {Schuhmann, Christoph and KÃ¶pf, Andreas and Vencu, Richard and Coombes, Theo and Beaumont, Romain},
  year = {2022},
  howpublished = {\url{https://laion.ai/blog/laion-coco-600m-synthetic-captions-from-laion2b-en/}},
  note = {Accessed: 2024-12-19}
}

@inproceedings{chen2025sharegpt4v,
  title={Sharegpt4v: Improving large multi-modal models with better captions},
  author={Chen, Lin and Li, Jinsong and Dong, Xiaoyi and Zhang, Pan and He, Conghui and Wang, Jiaqi and Zhao, Feng and Lin, Dahua},
  booktitle={European Conference on Computer Vision},
  pages={370--387},
  year={2025},
  organization={Springer}
}



###################
#Instruction Tuning
###################

@article{du2023makes,
  title={What makes for good visual instructions? synthesizing complex visual reasoning instructions for visual instruction tuning},
  author={Du, Yifan and Guo, Hangyu and Zhou, Kun and Zhao, Wayne Xin and Wang, Jinpeng and Wang, Chuyuan and Cai, Mingchen and Song, Ruihua and Wen, Ji-Rong},
  journal={arXiv preprint arXiv:2311.01487},
  year={2023}
}

@article{chen2024allava,
  title={Allava: Harnessing gpt4v-synthesized data for a lite vision-language model},
  author={Chen, Guiming Hardy and Chen, Shunian and Zhang, Ruifei and Chen, Junying and Wu, Xiangbo and Zhang, Zhiyi and Chen, Zhihong and Li, Jianquan and Wan, Xiang and Wang, Benyou},
  journal={arXiv preprint arXiv:2402.11684},
  year={2024}
}

@article{chen2023pixart,
  title={Pixart-$$\backslash$alpha $: Fast training of diffusion transformer for photorealistic text-to-image synthesis},
  author={Chen, Junsong and Yu, Jincheng and Ge, Chongjian and Yao, Lewei and Xie, Enze and Wu, Yue and Wang, Zhongdao and Kwok, James and Luo, Ping and Lu, Huchuan and others},
  journal={arXiv preprint arXiv:2310.00426},
  year={2023}
}

@article{wang2023see,
  title={To see is to believe: Prompting gpt-4v for better visual instruction tuning},
  author={Wang, Junke and Meng, Lingchen and Weng, Zejia and He, Bo and Wu, Zuxuan and Jiang, Yu-Gang},
  journal={arXiv preprint arXiv:2311.07574},
  year={2023}
}

@article{huang2023sparkles,
  title={Sparkles: Unlocking chats across multiple images for multimodal instruction-following models},
  author={Huang, Yupan and Meng, Zaiqiao and Liu, Fangyu and Su, Yixuan and Collier, Nigel and Lu, Yutong},
  journal={arXiv preprint arXiv:2308.16463},
  year={2023}
}

@article{li2023stablellava,
  title={Stablellava: Enhanced visual instruction tuning with synthesized image-dialogue data},
  author={Li, Yanda and Zhang, Chi and Yu, Gang and Wang, Zhibin and Fu, Bin and Lin, Guosheng and Shen, Chunhua and Chen, Ling and Wei, Yunchao},
  journal={arXiv preprint arXiv:2308.10253},
  year={2023}
}

@inproceedings{liu2023mitigating,
  title={Mitigating hallucination in large multi-modal models via robust instruction tuning},
  author={Liu, Fuxiao and Lin, Kevin and Li, Linjie and Wang, Jianfeng and Yacoob, Yaser and Wang, Lijuan},
  booktitle={The Twelfth International Conference on Learning Representations},
  year={2023}
}

@article{zhang2023pmc,
  title={Pmc-vqa: Visual instruction tuning for medical visual question answering},
  author={Zhang, Xiaoman and Wu, Chaoyi and Zhao, Ziheng and Lin, Weixiong and Zhang, Ya and Wang, Yanfeng and Xie, Weidi},
  journal={arXiv preprint arXiv:2305.10415},
  year={2023}
}

@article{li2024llava,
  title={Llava-med: Training a large language-and-vision assistant for biomedicine in one day},
  author={Li, Chunyuan and Wong, Cliff and Zhang, Sheng and Usuyama, Naoto and Liu, Haotian and Yang, Jianwei and Naumann, Tristan and Poon, Hoifung and Gao, Jianfeng},
  journal={Advances in Neural Information Processing Systems},
  volume={36},
  year={2024}
}



#########
# Medical
#########

@inproceedings{pelka2018radiology,
    title={Radiology Objects in COntext (ROCO): a multimodal image dataset},
    author={Pelka, Obioma and Koitka, Sven and R{\"u}ckert, Johannes and Nensa, Felix and Friedrich, Christoph M},
    booktitle={Intravascular Imaging and Computer Assisted Stenting and Large-Scale Annotation of Biomedical Data and Expert Label Synthesis: 7th Joint International Workshop, CVII-STENT 2018 and Third International Workshop, LABELS 2018, Held in Conjunction with MICCAI 2018, Granada, Spain, September 16, 2018, Proceedings 3},
    pages={180--189},
    year={2018},
    organization={Springer}
}

@article{subramanian2020medicat,
    title={Medicat: A dataset of medical images, captions, and textual references},
    author={Subramanian, Sanjay and Wang, Lucy Lu and Mehta, Sachin and Bogin, Ben and van Zuylen, Madeleine and Parasa, Sravanthi and Singh, Sameer and Gardner, Matt and Hajishirzi, Hannaneh},
    journal={arXiv preprint arXiv:2010.06000},
    year={2020}
}

@article{lin2023pmc,
    title={Pmc-clip: Contrastive language-image pre-training using biomedical documents},
    author={Lin, Weixiong and Zhao, Ziheng and Zhang, Xiaoman and Wu, Chaoyi and Zhang, Ya and Wang, Yanfeng and Xie, Weidi},
    journal={arXiv preprint arXiv:2303.07240},
    year={2023}
}

@article{liu2023qilin,
    title={Qilin-med-vl: Towards chinese large vision-language model for general healthcare},
    author={Liu, Junling and Wang, Ziming and Ye, Qichen and Chong, Dading and Zhou, Peilin and Hua, Yining},
    journal={arXiv preprint arXiv:2310.17956},
    year={2023}
}

@article{johnson2019mimic,
    title={MIMIC-CXR, a de-identified publicly available database of chest radiographs with free-text reports},
    author={Johnson, Alistair EW and Pollard, Tom J and Berkowitz, Seth J and Greenbaum, Nathaniel R and Lungren, Matthew P and Deng, Chih-ying and Mark, Roger G and Horng, Steven},
    journal={Scientific data},
    volume={6},
    number={1},
    pages={317},
    year={2019},
    publisher={Nature Publishing Group UK London}
}

@article{bustos2020padchest,
    title={Padchest: A large chest x-ray image dataset with multi-label annotated reports},
    author={Bustos, Aurelia and Pertusa, Antonio and Salinas, Jose-Maria and De La Iglesia-Vaya, Maria},
    journal={Medical image analysis},
    volume={66},
    pages={101797},
    year={2020},
    publisher={Elsevier}
}

@inproceedings{li2021ffa,
    title={Ffa-ir: Towards an explainable and reliable medical report generation benchmark},
    author={Li, Mingjie and Cai, Wenjia and Liu, Rui and Weng, Yuetian and Zhao, Xiaoyun and Wang, Cong and Chen, Xin and Liu, Zhong and Pan, Caineng and Li, Mengke and others},
    booktitle={Thirty-fifth Conference on Neural Information Processing Systems Datasets and Benchmarks Track (Round 2)},
    year={2021}
}

@article{huang2023visual,
    title={A visual--language foundation model for pathology image analysis using medical twitter},
    author={Huang, Zhi and Bianchi, Federico and Yuksekgonul, Mert and Montine, Thomas J and Zou, James},
    journal={Nature medicine},
    volume={29},
    number={9},
    pages={2307--2316},
    year={2023},
    publisher={Nature Publishing Group US New York}
}

@article{ikezogwo2023quilt,
    title={Quilt-1M: One Million Image-Text Pairs for Histopathology},
    author={Ikezogwo, Wisdom Oluchi and Seyfioglu, Mehmet Saygin and Ghezloo, Fatemeh and Geva, Dylan Stefan Chan and Mohammed, Fatwir Sheikh and Anand, Pavan Kumar and Krishna, Ranjay and Shapiro, Linda},
    journal={arXiv preprint arXiv:2306.11207},
    year={2023}
}

@inproceedings{wang2022medclip,
    title = "{M}ed{CLIP}: Contrastive Learning from Unpaired Medical Images and Text",
    author = "Wang, Zifeng  and
    Wu, Zhenbang  and
    Agarwal, Dinesh  and
    Sun, Jimeng",
    editor = "Goldberg, Yoav  and
    Kozareva, Zornitsa  and
    Zhang, Yue",
    booktitle = "Proceedings of the 2022 Conference on Empirical Methods in Natural Language Processing",
    month = dec,
    year = {2022},
    address = "Abu Dhabi, United Arab Emirates",
    publisher = "Association for Computational Linguistics",
    url = "https://aclanthology.org/2022.emnlp-main.256",
    doi = "10.18653/v1/2022.emnlp-main.256",
    pages = "3876--3887",
}

@inproceedings{eslami2023pubmedclip,
  title={PubMedCLIP: How Much Does CLIP Benefit Visual Question Answering in the Medical Domain?},
  author={Eslami, Sedigheh and Meinel, Christoph and De Melo, Gerard},
  booktitle={Findings of the Association for Computational Linguistics: EACL 2023},
  pages={1151--1163},
  year={2023}
}

@article{zhang2023large,
  title={Large-scale domain-specific pretraining for biomedical vision-language processing},
  author={Zhang, Sheng and Xu, Yanbo and Usuyama, Naoto and Bagga, Jaspreet and Tinn, Robert and Preston, Sam and Rao, Rajesh and Wei, Mu and Valluri, Naveen and Wong, Cliff and others},
  journal={arXiv preprint arXiv:2303.00915},
  year={2023}
}

@inproceedings{khanal2023soundscape,
  title = {Learning Tri-modal Embeddings for Zero-Shot Soundscape Mapping},
  author = {Khanal, Subash and Sastry, Srikumar and Dhakal, Aayush and Jacobs, Nathan},
  year = {2023},
  month = nov,
  booktitle = {British Machine Vision Conference (BMVC)},
}

@article{klemmer2023satclip,
  title={Satclip: Global, general-purpose location embeddings with satellite imagery},
  author={Klemmer, Konstantin and Rolf, Esther and Robinson, Caleb and Mackey, Lester and Ru{\ss}wurm, Marc},
  journal={arXiv preprint arXiv:2311.17179},
  year={2023}
}

@article{vivanco2024geoclip,
  title={Geoclip: Clip-inspired alignment between locations and images for effective worldwide geo-localization},
  author={Vivanco Cepeda, Vicente and Nayak, Gaurav Kumar and Shah, Mubarak},
  journal={Advances in Neural Information Processing Systems},
  volume={36},
  year={2024}
}
