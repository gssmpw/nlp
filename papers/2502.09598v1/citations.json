[
  {
    "index": 0,
    "papers": [
      {
        "key": "radford2021learning",
        "author": "Radford, Alec and Kim, Jong Wook and Hallacy, Chris and Ramesh, Aditya and Goh, Gabriel and Agarwal, Sandhini and Sastry, Girish and Askell, Amanda and Mishkin, Pamela and Clark, Jack and others",
        "title": "Learning transferable visual models from natural language supervision"
      }
    ]
  },
  {
    "index": 1,
    "papers": [
      {
        "key": "liu2024visual",
        "author": "Liu, Haotian and Li, Chunyuan and Wu, Qingyang and Lee, Yong Jae",
        "title": "Visual instruction tuning"
      },
      {
        "key": "liu2024improved",
        "author": "Liu, Haotian and Li, Chunyuan and Li, Yuheng and Lee, Yong Jae",
        "title": "Improved baselines with visual instruction tuning"
      }
    ]
  },
  {
    "index": 2,
    "papers": [
      {
        "key": "panigrahi2023have",
        "author": "Panigrahi, Akash and Verma, Sagar and Terris, Matthieu and Vakalopoulou, Maria",
        "title": "Have foundational models seen satellite images?"
      }
    ]
  },
  {
    "index": 3,
    "papers": [
      {
        "key": "czerkawski2023laion",
        "author": "Czerkawski, Mikolaj and Francis, Alistair",
        "title": "From LAION-5B to LAION-EO: Filtering billions of images using anchor datasets for satellite image extraction"
      }
    ]
  },
  {
    "index": 4,
    "papers": [
      {
        "key": "czerkawski2023laion",
        "author": "Czerkawski, Mikolaj and Francis, Alistair",
        "title": "From LAION-5B to LAION-EO: Filtering billions of images using anchor datasets for satellite image extraction"
      }
    ]
  },
  {
    "index": 5,
    "papers": [
      {
        "key": "aybar2022cloudsen12",
        "author": "Aybar, Cesar and Ysuhuaylas, Luis and Loja, Jhomira and Gonzales, Karen and Herrera, Fernando and Bautista, Lesly and Yali, Roy and Flores, Angie and Diaz, Lissette and Cuenca, Nicole and others",
        "title": "CloudSEN12, a global dataset for semantic understanding of cloud and cloud shadow in Sentinel-2"
      }
    ]
  },
  {
    "index": 6,
    "papers": [
      {
        "key": "wang2024skyscript",
        "author": "Wang, Zhecheng and Prabha, Rajanie and Huang, Tianyuan and Wu, Jiajun and Rajagopal, Ram",
        "title": "Skyscript: A large and semantically diverse vision-language dataset for remote sensing"
      }
    ]
  },
  {
    "index": 7,
    "papers": [
      {
        "key": "zhang2024rs5m",
        "author": "Zhang, Zilun and Zhao, Tiancheng and Guo, Yulong and Yin, Jianwei",
        "title": "RS5M and GeoRSCLIP: A large scale vision-language dataset and a large vision-language model for remote sensing"
      }
    ]
  },
  {
    "index": 8,
    "papers": [
      {
        "key": "schuhmann2022laion",
        "author": "Schuhmann, Christoph and Beaumont, Romain and Vencu, Richard and Gordon, Cade and Wightman, Ross and Cherti, Mehdi and Coombes, Theo and Katta, Aarush and Mullis, Clayton and Wortsman, Mitchell and others",
        "title": "Laion-5b: An open large-scale dataset for training next generation image-text models"
      }
    ]
  },
  {
    "index": 9,
    "papers": [
      {
        "key": "schuhmann2021laion",
        "author": "Schuhmann, Christoph and Vencu, Richard and Beaumont, Romain and Kaczmarczyk, Robert and Mullis, Clayton and Katta, Aarush and Coombes, Theo and Jitsev, Jenia and Komatsuzaki, Aran",
        "title": "Laion-400m: Open dataset of clip-filtered 400 million image-text pairs"
      }
    ]
  },
  {
    "index": 10,
    "papers": [
      {
        "key": "schuhmann2022laioncoco",
        "author": "Schuhmann, Christoph and K\u00f6pf, Andreas and Coombes, Theo and Vencu, Richard and Trom, Benjamin and Beaumont, Romain",
        "title": "{LAION COCO: 600M synthetic captions from LAION2B-EN}"
      }
    ]
  },
  {
    "index": 11,
    "papers": [
      {
        "key": "byeon2022coyo",
        "author": "Byeon, Minwoo and Park, Beomhee and Kim, Haecheon and Lee, Sungjun and Baek, Woonhyuk and Kim, Saehoon",
        "title": "Coyo-700m: Image-text pair dataset"
      }
    ]
  },
  {
    "index": 12,
    "papers": [
      {
        "key": "sharma2018conceptual",
        "author": "Sharma, Piyush and Ding, Nan and Goodman, Sebastian and Soricut, Radu",
        "title": "Conceptual captions: A cleaned, hypernymed, image alt-text dataset for automatic image captioning"
      }
    ]
  },
  {
    "index": 13,
    "papers": [
      {
        "key": "changpinyo2021conceptual",
        "author": "Changpinyo, Soravit and Sharma, Piyush and Ding, Nan and Soricut, Radu",
        "title": "Conceptual 12m: Pushing web-scale image-text pre-training to recognize long-tail visual concepts"
      }
    ]
  },
  {
    "index": 14,
    "papers": [
      {
        "key": "thomee2016yfcc100m",
        "author": "Thomee, Bart and Shamma, David A and Friedland, Gerald and Elizalde, Benjamin and Ni, Karl and Poland, Douglas and Borth, Damian and Li, Li-Jia",
        "title": "Yfcc100m: The new data in multimedia research"
      }
    ]
  },
  {
    "index": 15,
    "papers": [
      {
        "key": "srinivasan2021wit",
        "author": "Srinivasan, Krishna and Raman, Karthik and Chen, Jiecao and Bendersky, Michael and Najork, Marc",
        "title": "Wit: Wikipedia-based image text dataset for multimodal multilingual machine learning"
      }
    ]
  },
  {
    "index": 16,
    "papers": [
      {
        "key": "desai2021redcaps",
        "author": "Desai, Karan and Kaul, Gaurav and Aysola, Zubin and Johnson, Justin",
        "title": "Redcaps: Web-curated image-text data created by the people, for the people"
      }
    ]
  },
  {
    "index": 17,
    "papers": [
      {
        "key": "ordonez2011im2text",
        "author": "Ordonez, Vicente and Kulkarni, Girish and Berg, Tamara",
        "title": "Im2text: Describing images using 1 million captioned photographs"
      }
    ]
  },
  {
    "index": 18,
    "papers": [
      {
        "key": "krishna2017visual",
        "author": "Krishna, Ranjay and Zhu, Yuke and Groth, Oliver and Johnson, Justin and Hata, Kenji and Kravitz, Joshua and Chen, Stephanie and Kalantidis, Yannis and Li, Li-Jia and Shamma, David A and others",
        "title": "Visual genome: Connecting language and vision using crowdsourced dense image annotations"
      }
    ]
  },
  {
    "index": 19,
    "papers": [
      {
        "key": "qu2016deep",
        "author": "Qu, Bo and Li, Xuelong and Tao, Dacheng and Lu, Xiaoqiang",
        "title": "Deep semantic understanding of high resolution remote sensing image"
      }
    ]
  },
  {
    "index": 20,
    "papers": [
      {
        "key": "yang2010bag",
        "author": "Yang, Yi and Newsam, Shawn",
        "title": "Bag-of-visual-words and spatial extensions for land-use classification"
      }
    ]
  },
  {
    "index": 21,
    "papers": [
      {
        "key": "lu2017exploring",
        "author": "Lu, Xiaoqiang and Wang, Binqiang and Zheng, Xiangtao and Li, Xuelong",
        "title": "Exploring models and data for remote sensing image caption generation"
      }
    ]
  },
  {
    "index": 22,
    "papers": [
      {
        "key": "yuan2022exploring",
        "author": "Yuan, Zhiqiang and Zhang, Wenkai and Fu, Kun and Li, Xuan and Deng, Chubo and Wang, Hongqi and Sun, Xian",
        "title": "Exploring a Fine-Grained Multiscale Method for Cross-Modal Remote Sensing Image Retrieval"
      }
    ]
  },
  {
    "index": 23,
    "papers": [
      {
        "key": "cheng2022nwpu",
        "author": "Cheng, Qimin and Huang, Haiyan and Xu, Yuan and Zhou, Yuzhuo and Li, Huanying and Wang, Zhongyuan",
        "title": "NWPU-captions dataset and MLCA-net for remote sensing image captioning"
      }
    ]
  },
  {
    "index": 24,
    "papers": [
      {
        "key": "cheng2017remote",
        "author": "Cheng, Gong and Han, Junwei and Lu, Xiaoqiang",
        "title": "Remote sensing image scene classification: Benchmark and state of the art"
      }
    ]
  },
  {
    "index": 25,
    "papers": [
      {
        "key": "abdullah2020textrs",
        "author": "Abdullah, Taghreed and Bazi, Yakoub and Al Rahhal, Mohamad M and Mekhalfi, Mohamed L and Rangarajan, Lalitha and Zuair, Mansour",
        "title": "TextRS: Deep bidirectional triplet network for matching text to remote sensing images"
      }
    ]
  },
  {
    "index": 26,
    "papers": [
      {
        "key": "xia2017aid",
        "author": "Xia, Gui-Song and Hu, Jingwen and Hu, Fan and Shi, Baoguang and Bai, Xiang and Zhong, Yanfei and Zhang, Liangpei and Lu, Xiaoqiang",
        "title": "AID: A benchmark data set for performance evaluation of aerial scene classification"
      }
    ]
  },
  {
    "index": 27,
    "papers": [
      {
        "key": "yang2010bag",
        "author": "Yang, Yi and Newsam, Shawn",
        "title": "Bag-of-visual-words and spatial extensions for land-use classification"
      }
    ]
  },
  {
    "index": 28,
    "papers": [
      {
        "key": "zhou2018patternnet",
        "author": "Zhou, Weixun and Newsam, Shawn and Li, Congmin and Shao, Zhenfeng",
        "title": "PatternNet: A benchmark dataset for performance evaluation of remote sensing image retrieval"
      }
    ]
  },
  {
    "index": 29,
    "papers": [
      {
        "key": "cheng2022nwpu",
        "author": "Cheng, Qimin and Huang, Haiyan and Xu, Yuan and Zhou, Yuzhuo and Li, Huanying and Wang, Zhongyuan",
        "title": "NWPU-captions dataset and MLCA-net for remote sensing image captioning"
      }
    ]
  },
  {
    "index": 30,
    "papers": [
      {
        "key": "zhan2023rsvg",
        "author": "Zhan, Yang and Xiong, Zhitong and Yuan, Yuan",
        "title": "Rsvg: Exploring data and models for visual grounding on remote sensing data"
      }
    ]
  },
  {
    "index": 31,
    "papers": [
      {
        "key": "li2020object",
        "author": "Li, Ke and Wan, Gang and Cheng, Gong and Meng, Liqiu and Han, Junwei",
        "title": "Object detection in optical remote sensing images: A survey and a new benchmark"
      }
    ]
  },
  {
    "index": 32,
    "papers": [
      {
        "key": "Bountos_2022_CVPR",
        "author": "Bountos, Nikolaos Ioannis and Papoutsis, Ioannis and Michail, Dimitrios and Karavias, Andreas and Elias, Panagiotis and Parcharidis, Isaak",
        "title": "Hephaestus: A Large Scale Multitask Dataset Towards InSAR Understanding"
      }
    ]
  },
  {
    "index": 33,
    "papers": [
      {
        "key": "lazecky2020licsar",
        "author": "Lazeck{\\`y}, Milan and Spaans, Karsten and Gonz{\\'a}lez, Pablo J and Maghsoudi, Yasser and Morishita, Yu and Albino, Fabien and Elliott, John and Greenall, Nicholas and Hatton, Emma and Hooper, Andrew and others",
        "title": "LiCSAR: An automatic InSAR tool for measuring and monitoring tectonic and volcanic activity"
      }
    ]
  },
  {
    "index": 34,
    "papers": [
      {
        "key": "ge2024rsteller",
        "author": "Ge, Junyao and Zheng, Yang and Guo, Kaitai and Liang, Jimin",
        "title": "RSTeller: Scaling Up Visual Language Modeling in Remote Sensing with Rich Linguistic Semantics from Openly Available Data and Large Language Models"
      }
    ]
  },
  {
    "index": 35,
    "papers": [
      {
        "key": "zhang2024rs5m",
        "author": "Zhang, Zilun and Zhao, Tiancheng and Guo, Yulong and Yin, Jianwei",
        "title": "RS5M and GeoRSCLIP: A large scale vision-language dataset and a large vision-language model for remote sensing"
      }
    ]
  },
  {
    "index": 36,
    "papers": [
      {
        "key": "sumbul2019bigearthnet",
        "author": "Sumbul, Gencer and Charfuelan, Marcela and Demir, Beg{\\\"u}m and Markl, Volker",
        "title": "Bigearthnet: A large-scale benchmark archive for remote sensing image understanding"
      },
      {
        "key": "sumbul2021bigearthnet",
        "author": "Sumbul, Gencer and De Wall, Arne and Kreuziger, Tristan and Marcelino, Filipe and Costa, Hugo and Benevides, Pedro and Caetano, Mario and Demir, Beg{\\\"u}m and Markl, Volker",
        "title": "BigEarthNet-MM: A large-scale, multimodal, multilabel benchmark archive for remote sensing image classification and retrieval [software and data sets]"
      }
    ]
  },
  {
    "index": 37,
    "papers": [
      {
        "key": "christie2018functional",
        "author": "Christie, Gordon and Fendley, Neil and Wilson, James and Mukherjee, Ryan",
        "title": "Functional map of the world"
      }
    ]
  },
  {
    "index": 38,
    "papers": [
      {
        "key": "long2021creating",
        "author": "Long, Yang and Xia, Gui-Song and Li, Shengyang and Yang, Wen and Yang, Michael Ying and Zhu, Xiao Xiang and Zhang, Liangpei and Li, Deren",
        "title": "On creating benchmark dataset for aerial image interpretation: Reviews, guidances, and million-aid"
      }
    ]
  },
  {
    "index": 39,
    "papers": [
      {
        "key": "li2023blip",
        "author": "Li, Junnan and Li, Dongxu and Savarese, Silvio and Hoi, Steven",
        "title": "Blip-2: Bootstrapping language-image pre-training with frozen image encoders and large language models"
      }
    ]
  },
  {
    "index": 40,
    "papers": [
      {
        "key": "wang2024skyscript",
        "author": "Wang, Zhecheng and Prabha, Rajanie and Huang, Tianyuan and Wu, Jiajun and Rajagopal, Ram",
        "title": "Skyscript: A large and semantically diverse vision-language dataset for remote sensing"
      }
    ]
  },
  {
    "index": 41,
    "papers": [
      {
        "key": "zhao2024luojiahog",
        "author": "Zhao, Yuanxin and Zhang, Mi and Yang, Bingnan and Zhang, Zhan and Kang, Jiaju and Gong, Jianya",
        "title": "LuoJiaHOG: A Hierarchy Oriented Geo-aware Image Caption Dataset for Remote Sensing Image-Text Retrival"
      }
    ]
  },
  {
    "index": 42,
    "papers": [
      {
        "key": "zhu2023minigpt",
        "author": "Zhu, Deyao and Chen, Jun and Shen, Xiaoqian and Li, Xiang and Elhoseiny, Mohamed",
        "title": "Minigpt-4: Enhancing vision-language understanding with advanced large language models"
      }
    ]
  },
  {
    "index": 43,
    "papers": [
      {
        "key": "hu2023rsgpt",
        "author": "Hu, Yuan and Yuan, Jianlong and Wen, Congcong and Lu, Xiaonan and Li, Xiang",
        "title": "Rsgpt: A remote sensing vision language model and benchmark"
      }
    ]
  },
  {
    "index": 44,
    "papers": [
      {
        "key": "xia2018dota",
        "author": "Xia, Gui-Song and Bai, Xiang and Ding, Jian and Zhu, Zhen and Belongie, Serge and Luo, Jiebo and Datcu, Mihai and Pelillo, Marcello and Zhang, Liangpei",
        "title": "DOTA: A large-scale dataset for object detection in aerial images"
      }
    ]
  },
  {
    "index": 45,
    "papers": [
      {
        "key": "yuan2024chatearthnet",
        "author": "Yuan, Zhenghang and Xiong, Zhitong and Mou, Lichao and Zhu, Xiao Xiang",
        "title": "Chatearthnet: A global-scale, high-quality image-text dataset for remote sensing"
      }
    ]
  },
  {
    "index": 46,
    "papers": [
      {
        "key": "muhtar2024lhrs",
        "author": "Muhtar, Dilxat and Li, Zhenshi and Gu, Feng and Zhang, Xueliang and Xiao, Pengfeng",
        "title": "Lhrs-bot: Empowering remote sensing with vgi-enhanced large multimodal language model"
      }
    ]
  },
  {
    "index": 47,
    "papers": [
      {
        "key": "yuan2022exploring",
        "author": "Yuan, Zhiqiang and Zhang, Wenkai and Fu, Kun and Li, Xuan and Deng, Chubo and Wang, Hongqi and Sun, Xian",
        "title": "Exploring a Fine-Grained Multiscale Method for Cross-Modal Remote Sensing Image Retrieval"
      }
    ]
  },
  {
    "index": 48,
    "papers": [
      {
        "key": "cheng2022nwpu",
        "author": "Cheng, Qimin and Huang, Haiyan and Xu, Yuan and Zhou, Yuzhuo and Li, Huanying and Wang, Zhongyuan",
        "title": "NWPU-captions dataset and MLCA-net for remote sensing image captioning"
      }
    ]
  },
  {
    "index": 49,
    "papers": [
      {
        "key": "liu2025text2earth",
        "author": "Liu, Chenyang and Chen, Keyan and Zhao, Rui and Zou, Zhengxia and Shi, Zhenwei",
        "title": "Text2Earth: Unlocking Text-driven Remote Sensing Image Generation with a Global-Scale Dataset and a Foundation Model"
      }
    ]
  },
  {
    "index": 50,
    "papers": [
      {
        "key": "long2021creating",
        "author": "Long, Yang and Xia, Gui-Song and Li, Shengyang and Yang, Wen and Yang, Michael Ying and Zhu, Xiao Xiang and Zhang, Liangpei and Li, Deren",
        "title": "On creating benchmark dataset for aerial image interpretation: Reviews, guidances, and million-aid"
      }
    ]
  },
  {
    "index": 51,
    "papers": [
      {
        "key": "mendieta2023towards",
        "author": "Mendieta, Mat{\\'\\i}as and Han, Boran and Shi, Xingjian and Zhu, Yi and Chen, Chen",
        "title": "Towards Geospatial Foundation Models via Continual Pretraining"
      }
    ]
  },
  {
    "index": 52,
    "papers": [
      {
        "key": "wang2023ssl4eo",
        "author": "Wang, Yi and Braham, Nassim Ait Ali and Xiong, Zhitong and Liu, Chenying and Albrecht, Conrad M and Zhu, Xiao Xiang",
        "title": "SSL4EO-S12: A large-scale multimodal, multitemporal dataset for self-supervised learning in Earth observation [Software and Data Sets]"
      }
    ]
  },
  {
    "index": 53,
    "papers": [
      {
        "key": "wang2024skyscript",
        "author": "Wang, Zhecheng and Prabha, Rajanie and Huang, Tianyuan and Wu, Jiajun and Rajagopal, Ram",
        "title": "Skyscript: A large and semantically diverse vision-language dataset for remote sensing"
      }
    ]
  },
  {
    "index": 54,
    "papers": [
      {
        "key": "qu2016deep",
        "author": "Qu, Bo and Li, Xuelong and Tao, Dacheng and Lu, Xiaoqiang",
        "title": "Deep semantic understanding of high resolution remote sensing image"
      }
    ]
  },
  {
    "index": 55,
    "papers": [
      {
        "key": "qu2016deep",
        "author": "Qu, Bo and Li, Xuelong and Tao, Dacheng and Lu, Xiaoqiang",
        "title": "Deep semantic understanding of high resolution remote sensing image"
      }
    ]
  },
  {
    "index": 56,
    "papers": [
      {
        "key": "lu2017exploring",
        "author": "Lu, Xiaoqiang and Wang, Binqiang and Zheng, Xiangtao and Li, Xuelong",
        "title": "Exploring models and data for remote sensing image caption generation"
      }
    ]
  },
  {
    "index": 57,
    "papers": [
      {
        "key": "abdullah2020textrs",
        "author": "Abdullah, Taghreed and Bazi, Yakoub and Al Rahhal, Mohamad M and Mekhalfi, Mohamed L and Rangarajan, Lalitha and Zuair, Mansour",
        "title": "TextRS: Deep bidirectional triplet network for matching text to remote sensing images"
      }
    ]
  },
  {
    "index": 58,
    "papers": [
      {
        "key": "yuan2022exploring",
        "author": "Yuan, Zhiqiang and Zhang, Wenkai and Fu, Kun and Li, Xuan and Deng, Chubo and Wang, Hongqi and Sun, Xian",
        "title": "Exploring a Fine-Grained Multiscale Method for Cross-Modal Remote Sensing Image Retrieval"
      }
    ]
  },
  {
    "index": 59,
    "papers": [
      {
        "key": "cheng2022nwpu",
        "author": "Cheng, Qimin and Huang, Haiyan and Xu, Yuan and Zhou, Yuzhuo and Li, Huanying and Wang, Zhongyuan",
        "title": "NWPU-captions dataset and MLCA-net for remote sensing image captioning"
      }
    ]
  },
  {
    "index": 60,
    "papers": [
      {
        "key": "zhan2023rsvg",
        "author": "Zhan, Yang and Xiong, Zhitong and Yuan, Yuan",
        "title": "Rsvg: Exploring data and models for visual grounding on remote sensing data"
      }
    ]
  },
  {
    "index": 61,
    "papers": [
      {
        "key": "Bountos_2022_CVPR",
        "author": "Bountos, Nikolaos Ioannis and Papoutsis, Ioannis and Michail, Dimitrios and Karavias, Andreas and Elias, Panagiotis and Parcharidis, Isaak",
        "title": "Hephaestus: A Large Scale Multitask Dataset Towards InSAR Understanding"
      }
    ]
  },
  {
    "index": 62,
    "papers": [
      {
        "key": "hu2023rsgpt",
        "author": "Hu, Yuan and Yuan, Jianlong and Wen, Congcong and Lu, Xiaonan and Li, Xiang",
        "title": "Rsgpt: A remote sensing vision language model and benchmark"
      }
    ]
  },
  {
    "index": 63,
    "papers": [
      {
        "key": "ge2024rsteller",
        "author": "Ge, Junyao and Zheng, Yang and Guo, Kaitai and Liang, Jimin",
        "title": "RSTeller: Scaling Up Visual Language Modeling in Remote Sensing with Rich Linguistic Semantics from Openly Available Data and Large Language Models"
      }
    ]
  },
  {
    "index": 64,
    "papers": [
      {
        "key": "zhang2024rs5m",
        "author": "Zhang, Zilun and Zhao, Tiancheng and Guo, Yulong and Yin, Jianwei",
        "title": "RS5M and GeoRSCLIP: A large scale vision-language dataset and a large vision-language model for remote sensing"
      }
    ]
  },
  {
    "index": 65,
    "papers": [
      {
        "key": "wang2024skyscript",
        "author": "Wang, Zhecheng and Prabha, Rajanie and Huang, Tianyuan and Wu, Jiajun and Rajagopal, Ram",
        "title": "Skyscript: A large and semantically diverse vision-language dataset for remote sensing"
      }
    ]
  },
  {
    "index": 66,
    "papers": [
      {
        "key": "zhao2024luojiahog",
        "author": "Zhao, Yuanxin and Zhang, Mi and Yang, Bingnan and Zhang, Zhan and Kang, Jiaju and Gong, Jianya",
        "title": "LuoJiaHOG: A Hierarchy Oriented Geo-aware Image Caption Dataset for Remote Sensing Image-Text Retrival"
      }
    ]
  },
  {
    "index": 67,
    "papers": [
      {
        "key": "yuan2024chatearthnet",
        "author": "Yuan, Zhenghang and Xiong, Zhitong and Mou, Lichao and Zhu, Xiao Xiang",
        "title": "Chatearthnet: A global-scale, high-quality image-text dataset for remote sensing"
      }
    ]
  },
  {
    "index": 68,
    "papers": [
      {
        "key": "muhtar2024lhrs",
        "author": "Muhtar, Dilxat and Li, Zhenshi and Gu, Feng and Zhang, Xueliang and Xiao, Pengfeng",
        "title": "Lhrs-bot: Empowering remote sensing with vgi-enhanced large multimodal language model"
      }
    ]
  },
  {
    "index": 69,
    "papers": [
      {
        "key": "liu2025text2earth",
        "author": "Liu, Chenyang and Chen, Keyan and Zhao, Rui and Zou, Zhengxia and Shi, Zhenwei",
        "title": "Text2Earth: Unlocking Text-driven Remote Sensing Image Generation with a Global-Scale Dataset and a Foundation Model"
      }
    ]
  },
  {
    "index": 70,
    "papers": [
      {
        "key": "radford2021learning",
        "author": "Radford, Alec and Kim, Jong Wook and Hallacy, Chris and Ramesh, Aditya and Goh, Gabriel and Agarwal, Sandhini and Sastry, Girish and Askell, Amanda and Mishkin, Pamela and Clark, Jack and others",
        "title": "Learning transferable visual models from natural language supervision"
      }
    ]
  },
  {
    "index": 71,
    "papers": [
      {
        "key": "ilharco_gabriel_2021_5143773",
        "author": "Ilharco, Gabriel and\nWortsman, Mitchell and\nWightman, Ross and\nGordon, Cade and\nCarlini, Nicholas and\nTaori, Rohan and\nDave, Achal and\nShankar, Vaishaal and\nNamkoong, Hongseok and\nMiller, John and\nHajishirzi, Hannaneh and\nFarhadi, Ali and\nSchmidt, Ludwig",
        "title": "OpenCLIP"
      }
    ]
  },
  {
    "index": 72,
    "papers": [
      {
        "key": "radford2021learning",
        "author": "Radford, Alec and Kim, Jong Wook and Hallacy, Chris and Ramesh, Aditya and Goh, Gabriel and Agarwal, Sandhini and Sastry, Girish and Askell, Amanda and Mishkin, Pamela and Clark, Jack and others",
        "title": "Learning transferable visual models from natural language supervision"
      }
    ]
  },
  {
    "index": 73,
    "papers": [
      {
        "key": "schuhmann2022laion",
        "author": "Schuhmann, Christoph and Beaumont, Romain and Vencu, Richard and Gordon, Cade and Wightman, Ross and Cherti, Mehdi and Coombes, Theo and Katta, Aarush and Mullis, Clayton and Wortsman, Mitchell and others",
        "title": "Laion-5b: An open large-scale dataset for training next generation image-text models"
      }
    ]
  },
  {
    "index": 74,
    "papers": [
      {
        "key": "cherti2023reproducible",
        "author": "Cherti, Mehdi and Beaumont, Romain and Wightman, Ross and Wortsman, Mitchell and Ilharco, Gabriel and Gordon, Cade and Schuhmann, Christoph and Schmidt, Ludwig and Jitsev, Jenia",
        "title": "Reproducible scaling laws for contrastive language-image learning"
      }
    ]
  },
  {
    "index": 75,
    "papers": [
      {
        "key": "gadre2024datacomp",
        "author": "Gadre, Samir Yitzhak and Ilharco, Gabriel and Fang, Alex and Hayase, Jonathan and Smyrnis, Georgios and Nguyen, Thao and Marten, Ryan and Wortsman, Mitchell and Ghosh, Dhruba and Zhang, Jieyu and others",
        "title": "Datacomp: In search of the next generation of multimodal datasets"
      },
      {
        "key": "fang2023data",
        "author": "Fang, Alex and Jose, Albin Madappally and Jain, Amit and Schmidt, Ludwig and Toshev, Alexander and Shankar, Vaishaal",
        "title": "Data filtering networks"
      },
      {
        "key": "xu2023demystifying",
        "author": "Xu, Hu and Xie, Saining and Tan, Xiaoqing Ellen and Huang, Po-Yao and Howes, Russell and Sharma, Vasu and Li, Shang-Wen and Ghosh, Gargi and Zettlemoyer, Luke and Feichtenhofer, Christoph",
        "title": "Demystifying clip data"
      }
    ]
  },
  {
    "index": 76,
    "papers": [
      {
        "key": "sun2023eva",
        "author": "Sun, Quan and Fang, Yuxin and Wu, Ledell and Wang, Xinlong and Cao, Yue",
        "title": "Eva-clip: Improved training techniques for clip at scale"
      }
    ]
  },
  {
    "index": 77,
    "papers": [
      {
        "key": "li2023inverse",
        "author": "Li, Xianhang and Wang, Zeyu and Xie, Cihang",
        "title": "An Inverse Scaling Law for CLIP Training"
      },
      {
        "key": "li2023clipa",
        "author": "Li, Xianhang and Wang, Zeyu and Xie, Cihang",
        "title": "CLIPA-v2: Scaling CLIP Training with 81.1\\% Zero-shot ImageNet Accuracy within a \\$10,000 Budget; An Extra \\$4,000 Unlocks 81.8\\% Accuracy"
      },
      {
        "key": "zhai2023sigmoid",
        "author": "X. Zhai and B. Mustafa and A. Kolesnikov and L. Beyer",
        "title": "Sigmoid Loss for Language Image Pre-Training"
      }
    ]
  },
  {
    "index": 78,
    "papers": [
      {
        "key": "birhane2024into",
        "author": "Birhane, Abeba and Han, Sanghyun and Boddeti, Vishnu and Luccioni, Sasha and others",
        "title": "Into the laion\u2019s den: Investigating hate in multimodal datasets"
      }
    ]
  },
  {
    "index": 79,
    "papers": [
      {
        "key": "laioncoco",
        "author": "Schuhmann, Christoph and K\u00f6pf, Andreas and Vencu, Richard and Coombes, Theo and Beaumont, Romain",
        "title": "LAION-COCO: 600M Synthetic Captions from Laion2B-en"
      }
    ]
  },
  {
    "index": 80,
    "papers": [
      {
        "key": "fan2024improving",
        "author": "Fan, Lijie and Krishnan, Dilip and Isola, Phillip and Katabi, Dina and Tian, Yonglong",
        "title": "Improving clip training with language rewrites"
      }
    ]
  },
  {
    "index": 81,
    "papers": [
      {
        "key": "nguyen2024improving",
        "author": "Nguyen, Thao and Gadre, Samir Yitzhak and Ilharco, Gabriel and Oh, Sewoong and Schmidt, Ludwig",
        "title": "Improving multimodal datasets with image captioning"
      }
    ]
  },
  {
    "index": 82,
    "papers": [
      {
        "key": "chen2025sharegpt4v",
        "author": "Chen, Lin and Li, Jinsong and Dong, Xiaoyi and Zhang, Pan and He, Conghui and Wang, Jiaqi and Zhao, Feng and Lin, Dahua",
        "title": "Sharegpt4v: Improving large multi-modal models with better captions"
      }
    ]
  },
  {
    "index": 83,
    "papers": [
      {
        "key": "yu2024capsfusion",
        "author": "Yu, Qiying and Sun, Quan and Zhang, Xiaosong and Cui, Yufeng and Zhang, Fan and Cao, Yue and Wang, Xinlong and Liu, Jingjing",
        "title": "Capsfusion: Rethinking image-text data at scale"
      }
    ]
  },
  {
    "index": 84,
    "papers": [
      {
        "key": "xu2024altogether",
        "author": "Xu, Hu and Huang, Po-Yao and Tan, Xiaoqing Ellen and Yeh, Ching-Feng and Kahn, Jacob and Jou, Christine and Ghosh, Gargi and Levy, Omer and Zettlemoyer, Luke and Yih, Wen-tau and others",
        "title": "Altogether: Image Captioning via Re-aligning Alt-text"
      }
    ]
  },
  {
    "index": 85,
    "papers": [
      {
        "key": "liu2024can",
        "author": "Liu, Che and Wan, Zhongwei and Wang, Haozhe and Chen, Yinda and Qaiser, Talha and Jin, Chen and Yousefi, Fariba and Burlutskiy, Nikolay and Arcucci, Rossella",
        "title": "Can Medical Vision-Language Pre-training Succeed with Purely Synthetic Data?"
      }
    ]
  },
  {
    "index": 86,
    "papers": [
      {
        "key": "rotstein2024fusecap",
        "author": "Rotstein, Noam and Bensa{\\\"\\i}d, David and Brody, Shaked and Ganz, Roy and Kimmel, Ron",
        "title": "Fusecap: Leveraging large language models for enriched fused image captions"
      }
    ]
  },
  {
    "index": 87,
    "papers": [
      {
        "key": "sharifzadeh2024synth",
        "author": "Sharifzadeh, Sahand and Kaplanis, Christos and Pathak, Shreya and Kumaran, Dharshan and Ilic, Anastasija and Mitrovic, Jovana and Blundell, Charles and Banino, Andrea",
        "title": "Synth$^2$: Boosting Visual-Language Models with Synthetic Captions and Image Embeddings"
      }
    ]
  },
  {
    "index": 88,
    "papers": [
      {
        "key": "li2024if",
        "author": "Li, Xianhang and Tu, Haoqin and Hui, Mude and Wang, Zeyu and Zhao, Bingchen and Xiao, Junfei and Ren, Sucheng and Mei, Jieru and Liu, Qing and Zheng, Huangjie and others",
        "title": "What If We Recaption Billions of Web Images with LLaMA-3?"
      }
    ]
  },
  {
    "index": 89,
    "papers": [
      {
        "key": "pelka2018radiology",
        "author": "Pelka, Obioma and Koitka, Sven and R{\\\"u}ckert, Johannes and Nensa, Felix and Friedrich, Christoph M",
        "title": "Radiology Objects in COntext (ROCO): a multimodal image dataset"
      },
      {
        "key": "subramanian2020medicat",
        "author": "Subramanian, Sanjay and Wang, Lucy Lu and Mehta, Sachin and Bogin, Ben and van Zuylen, Madeleine and Parasa, Sravanthi and Singh, Sameer and Gardner, Matt and Hajishirzi, Hannaneh",
        "title": "Medicat: A dataset of medical images, captions, and textual references"
      },
      {
        "key": "lin2023pmc",
        "author": "Lin, Weixiong and Zhao, Ziheng and Zhang, Xiaoman and Wu, Chaoyi and Zhang, Ya and Wang, Yanfeng and Xie, Weidi",
        "title": "Pmc-clip: Contrastive language-image pre-training using biomedical documents"
      },
      {
        "key": "liu2023qilin",
        "author": "Liu, Junling and Wang, Ziming and Ye, Qichen and Chong, Dading and Zhou, Peilin and Hua, Yining",
        "title": "Qilin-med-vl: Towards chinese large vision-language model for general healthcare"
      }
    ]
  },
  {
    "index": 90,
    "papers": [
      {
        "key": "johnson2019mimic",
        "author": "Johnson, Alistair EW and Pollard, Tom J and Berkowitz, Seth J and Greenbaum, Nathaniel R and Lungren, Matthew P and Deng, Chih-ying and Mark, Roger G and Horng, Steven",
        "title": "MIMIC-CXR, a de-identified publicly available database of chest radiographs with free-text reports"
      },
      {
        "key": "bustos2020padchest",
        "author": "Bustos, Aurelia and Pertusa, Antonio and Salinas, Jose-Maria and De La Iglesia-Vaya, Maria",
        "title": "Padchest: A large chest x-ray image dataset with multi-label annotated reports"
      },
      {
        "key": "li2021ffa",
        "author": "Li, Mingjie and Cai, Wenjia and Liu, Rui and Weng, Yuetian and Zhao, Xiaoyun and Wang, Cong and Chen, Xin and Liu, Zhong and Pan, Caineng and Li, Mengke and others",
        "title": "Ffa-ir: Towards an explainable and reliable medical report generation benchmark"
      }
    ]
  },
  {
    "index": 91,
    "papers": [
      {
        "key": "huang2023visual",
        "author": "Huang, Zhi and Bianchi, Federico and Yuksekgonul, Mert and Montine, Thomas J and Zou, James",
        "title": "A visual--language foundation model for pathology image analysis using medical twitter"
      },
      {
        "key": "ikezogwo2023quilt",
        "author": "Ikezogwo, Wisdom Oluchi and Seyfioglu, Mehmet Saygin and Ghezloo, Fatemeh and Geva, Dylan Stefan Chan and Mohammed, Fatwir Sheikh and Anand, Pavan Kumar and Krishna, Ranjay and Shapiro, Linda",
        "title": "Quilt-1M: One Million Image-Text Pairs for Histopathology"
      }
    ]
  }
]