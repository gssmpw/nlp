\section{Introduction}
\label{sec:introduction}
System reliability is a critical factor in the design and operation of modern computing systems, from IoT devices~\cite{xing:iot-reliability:ieee-iotj:2020, philip:iot-healthcare:jsac:2021} to high-performance computing~\cite{schroeder:hpc-failures:tdsc:2010} and data-center infrastructure~\cite{beyer:sre-google:oreilly:2016}. 
Memory reliability plays a key role in this context, as memory errors, ranging from bit flips to complete module failures, can severely impact system reliability, leading to crashes, data corruption, and significant performance degradation~\cite{meza:dramfailures:dsn:2015}. 
As memory densities continue to increase~\cite{lee:ddr5:iedm:2023, zhang:pm-chipkill:micro:2018}, and as system architectures become more complex, the frequency of memory errors is also on the rise, making addressing memory reliability critically important~\cite{beigi:dram-faults:hpca:2023}.
% Meanwhile, the storage overheads of traditional memory error correction schemes, such as Error-Correcting Codes (ECC), required to maintain reliability are increasing~\cite{patil:dve:isca:2021}.

Fine-grain memory replication is emerging as a promising approach to improving memory reliability. It augments per-DIMM ECC with an additional layer of redundancy, ensuring that critical data has multiple copies across independent
failure domains, such as different memory channels~\cite{zheng:raim:isca:2017} or memory controllers~ \cite{patil:dve:isca:2021}. 
This approach not only mitigates errors within a single module, such as single-bit errors, but also increases robustness against errors that extend beyond the module, including those caused by memory channel or memory controller failures~\cite{meza:dramfailures:dsn:2015}.
It is particularly useful in Non-Uniform Memory Access (NUMA) systems, where coherent replication can improve both reliability and performance~\cite{patil:dve:isca:2021}. 
In disaggregated memory systems, where memory is separated from processing units, techniques such as replication and erasure coding are employed to ensure fault tolerance by encoding data into multiple fragments, allowing recovery even if part of the memory fails~\cite{lee:hydra:fast:2022, zhou:carbink:osdi:2022, tsai:dpm:atc:2020, shan:legoos:osdi:2018}. 

Introducing redundancy at different levels of the memory hierarchy, from per-DIMM ECC to memory replicas, without a holistic approach can result in unnecessary storage overheads due to duplication. 
A two-tier memory resilience scheme that decouples error detection and correction, using error detection in the first tier and replication for error correction in the second tier, can help mitigate this issue~\cite{patil:dve:isca:2021}. 
However, several approaches apply replication without considering the first tier~\cite{lee:hydra:fast:2022, zhou:carbink:osdi:2022, tsai:dpm:atc:2020, shan:legoos:osdi:2018}, potentially leading to excess duplication, overhead, and reduced efficiency. 
We believe this problem arises from the absence of a unified model to reason about protection, storage efficiency, and performance interactions between the two tiers.

We propose \emph{\textbf{R}eplication-\textbf{A}ware \textbf{M}emory-error \textbf{P}rotection} (\ramp) to fill this gap.
\ramp seeks to offer a framework for designing and analyzing two-tier memory resilience schemes, where memory replication is used to handle errors that the first tier cannot tolerate. 
\ramp provides analytical models that enable system designers and operators to understand the interaction between the two protection tiers and assess how the first tier's protection strength affects the overall protection provided by multiple replicas in the second tier. 
This guidance helps determine the optimal protection strength for individual replicas in the first tier and appropriate replication level in the second tier, resulting in improved efficiency.
For example, RAMP enables the evaluation of using weaker, more efficient, and lower-overhead ECC at individual memory modules while relying on replicated data in other modules to provide collective protection and tolerate memory errors.

We demonstrate the utility of our approach by applying it to a state-of-the-art rack-level resilience mechanism designed for disaggregated memory systems~\cite{lee:hydra:fast:2022}, combined with a recent chipkill-correct design for high-density non-volatile memory~\cite{zhang:pm-chipkill:micro:2018}.
This combination tolerates memory errors through a two-tier cross-layer resilience scheme: 
(i) the chipkill-correct mechanism provides a memory-protection tier that uses the memory chip failure protection bits to detect and opportunistically correct memory errors at high performance, and 
(ii) the rack-level resilience mechanism provides a memory-replication tier that uses rack-scale replication and erasure coding to correct memory errors that are detected but uncorrected by the memory-protection tier at low storage cost. 
Using our analytical framework, we show how weakening the chipkill protection of each individual replica, we can reduce storage cost from $27\%$ down to $17.7\%$ while we attain the same protection level as the original design through the collective protection of multiple replicas, with minimal performance overhead. 

In particular, we make the following contributions:

\begin{itemize}[leftmargin=*,noitemsep,topsep=0pt]

\item We develop \ramp, an analytical framework to reason about the protection and storage trade-offs in two-tier memory resilience schemes. 

\item We use our framework to design \rampdm, a two-tier memory resilience scheme for disaggregated memory that combines memory protection and replication to tolerate memory errors.

\item We evaluate reliability, efficiency, and performance trade-offs in \rampdm, showing that our framework can help improve storage costs with minimal performance overhead.

\end{itemize}