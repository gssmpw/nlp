\section{Conclusions}
\label{sec:conclusions}

This work investigates the fundamental computer vision problem of semantically constrained human affordance generation in complex environments. We discuss the main challenges of estimating realistic poses for non-existent persons by exploring current approaches in the literature to address the problem. The vast majority of the existing techniques are built around architectural innovations of the network without any significant emphasis on the semantic understanding of the scene. By introducing a novel cross-attention mechanism, we show that a robust semantic representation of the scene context can improve the generation performance by a significant margin. In addition, our approach provides a fully automated inference pipeline. We demonstrate the efficacy of the proposed method with visual results, quantitative analyses on pose alignment, and an opinion-based subjective user evaluation.

\vspace{1.0em}

% \noindent
% \textcolor{black}{\textbf{Reproducibility:} We plan to release the code and pretrained models publicly after a successful review outcome. A partial version of the implementation without the pretrained checkpoints is currently available at \url{https://anonymous.4open.science/r/mcma} for review purposes.}
