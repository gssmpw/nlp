% interactcsesample.tex
% v1.05 - August 2017


\documentclass[]{interact}
\usepackage[T1]{fontenc}
\usepackage{graphicx}
\usepackage{caption}
\usepackage{dirtree}
\usepackage{multirow}%
\usepackage{amsmath,amssymb,amsfonts}%
\usepackage{amsthm}%
\usepackage{mathrsfs}%
\usepackage[title]{appendix}%
\usepackage{xcolor}%
\usepackage{textcomp}%
\usepackage{manyfoot}%
\usepackage{booktabs}%
\usepackage{algorithm}%
\usepackage{algorithmicx}%
\usepackage{algpseudocode}%
\usepackage{listings}%
\usepackage{overpic}%
\usepackage{orcidlink}
\usepackage{subcaption}
\usepackage{hyperref}
\usepackage{amsmath}
\usepackage{enumitem}
\usepackage{bbm}
\usepackage{epstopdf}% To incorporate .eps illustrations using PDFLaTeX, etc.
% \usepackage[caption=false]{subfig}% Support for small, `sub' figures and tables
%\usepackage[nolists,tablesfirst]{endfloat}% To `separate' figures and tables from text if required

%\usepackage[doublespacing]{setspace}% To produce a `double spaced' document if required
%\setlength\parindent{24pt}% To increase paragraph indentation when line spacing is doubled
%\setlength\bibindent{2em}% To increase hanging indent in bibliography when line spacing is doubled

\hypersetup{
    colorlinks=true,    % Enable colored links
    linkcolor=black,    % Link color (set to black)
    citecolor=black,    % Citation color (set to black)
    filecolor=black,    % File link color
    urlcolor=black      % URL color
}


\usepackage{natbib}% Citation support using natbib.sty
\bibpunct[, ]{(}{)}{;}{a}{}{,}% Citation support using natbib.sty
\renewcommand\bibfont{\fontsize{10}{12}\selectfont}% Bibliography support using natbib.sty

\theoremstyle{plain}% Theorem-like structures provided by amsthm.sty
\newtheorem{theorem}{Theorem}[section]
\newtheorem{lemma}[theorem]{Lemma}
\newtheorem{corollary}[theorem]{Corollary}
\newtheorem{proposition}[theorem]{Proposition}

\theoremstyle{definition}
\newtheorem{definition}[theorem]{Definition}
\newtheorem{example}[theorem]{Example}

\theoremstyle{remark}
\newtheorem{remark}{Remark}
\newtheorem{notation}{Notation}

\begin{document}

% \articletype{ARTICLE TEMPLATE}% Specify the article type or omit as appropriate

\title{Indoor Light and Heat Estimation from a Single Panorama}

\author{
\name{Guanzhou Ji\textsuperscript{a}\thanks{CONTACT Guanzhou Ji. Email: gji@andrew.cmu.edu}, Sriram Narayanan\textsuperscript{a}, Azadeh O. Sawyer\textsuperscript{a}, \\and Srinivasa G. Narasimhan\textsuperscript{a}}
\affil{\textsuperscript{a}Carnegie Mellon University, Pittsburgh, PA, USA}
}

% \author{
% \name{A.~N. Author\textsuperscript{a}\thanks{CONTACT A.~N. Author. Email: latex.helpdesk@tandf.co.uk} and John Smith\textsuperscript{b}}
% \affil{\textsuperscript{a}Taylor \& Francis, 4 Park Square, Milton Park, Abingdon, UK; \textsuperscript{b}Institut f\"{u}r Informatik, Albert-Ludwigs-Universit\"{a}t, Freiburg, Germany}
% }

\maketitle

\begin{abstract}
This paper presents a novel application for directly estimating indoor light and heat maps from captured indoor-outdoor High Dynamic Range (HDR) panoramas. In our image-based rendering method, the indoor panorama is used to estimate the 3D room layout, while the corresponding outdoor panorama serves as an environment map to infer spatially-varying light and material properties. We establish a connection between indoor light transport and heat transport and implement transient heat simulation to generate indoor heat panoramas. The sensitivity analysis of various thermal parameters is conducted, and the resulting heat maps are compared with the images captured by the thermal camera in real-world scenarios. This digital application enables automatic indoor light and heat estimation without manual inputs and cumbersome field measurements.
\end{abstract}

\begin{keywords}
Indoor Scene; Light Estimation; Heat Estimation; Image-Based Rendering; HDR Photography
\end{keywords}


\section{Introduction}
Outdoor light enters indoor spaces, shapes the appearance of indoor scenes, and brings solar radiation that generates heat on indoor surfaces. Omnidirectional photography has been used to capture panoramic images of entire indoor scenes. Based on physics-based and data-driven methods (\cite{ji2023virtual,ji2024virtual,zhi2022semantically}), a single indoor panorama can be directly used to estimate spatially varying indoor lighting, material properties, and 3D layouts. Estimating indoor light levels allows users to identify optimal areas for activities, while heat estimation helps assess the potential heating and cooling demand for the entire space. However, most thermal imaging relies on infrared thermal cameras, which are expensive, output noisy imaging results, and are limited to capturing 2D perspective images, making it challenging to cover an entire 360$^\circ$ indoor scene in high quality. This raises a main research question: Can we estimate indoor lighting and heating properties simultaneously from a single indoor panorama?




\begin{figure*}
  \centering
  \begin{overpic}[width= \textwidth]{fig/ht_teaser.jpg}
    \put(0,50){\scriptsize \color{black}{(a) Captured Scene}}
    \put(51,50){\scriptsize \color{black}{(b) Edited Scene}}
    \put(0,27){\scriptsize \color{black}{(c) Light Estimation}}
    \put(51,27){\scriptsize \color{black}{(d) Heat Estimation}} 
    \put(2,2){\scriptsize \color{black}{0}}
    \put(30,2){\scriptsize \color{black}{3,000 ($cd/m^2$)}}
    \put(51,2){\scriptsize \color{black}{21.0}}
    \put(81,2){\scriptsize \color{black}{25.0 ($^{\circ}\mathrm{C}$)}} 
  \end{overpic}
  \caption{Overview of Our Application: An indoor panorama (a) is captured under natural illumination, with a paired outdoor panorama providing real-time, spatially-varying light to the scene. The scene is virtually edited and relit with new indoor layout objects (b). The absolute light level is estimated for the virtual scene, and we introduced a heat transport equation to compute an indoor heat map displaying per-pixel temperature values.}
  \label{fig_ht_teaser}
\end{figure*}


The global rendering method proposed by \cite{debevec2006image} offers a High Dynamic Range (HDR) image-based rendering model for relighting virtual objects within a realistic scene context. Virtual sky models (\cite{cie2003spitial,perez1993all,hosek2012analytic}) have been employed to represent outdoor light in the real world. 
To reflect instantaneous light estimation for indoor scenes, image-based rendering incorporates realistic sky images as the illumination source. The HDR technique captures the sky appearance, including direct sunlight in outdoor spaces (\cite{stumpfel2004direct}). The captured HDR images provide accurate sky luminance distribution and details of the urban context (\cite{inanici2009applications,inanici2010evalution}). In this setting, the indoor scene is accurately rendered using the outdoor sky image at the pixel level. However, so far, the image-based rendering method has not been explored with realistic indoor textures to render photorealistic indoor appearances to estimate absolute light levels and heat maps.

When modeling visible light transport, intrinsic decomposition separates a single image into two layers: a reflectance layer, which captures the material surface's albedo or color invariant, and a shading layer, which is shaped by light interactions and object geometry. Intrinsic decomposition has been applied in various tasks, including image editing (\cite{bonneel2017intrinsic}), removing interreflections (\cite{seitz2005theory}), and separating illumination for material recoloring (\cite{carroll2011illumination}), as well as being applied to multi-view outdoor photos (\cite{duchene2015multi}). To construct indoor-outdoor light transport, \cite{ji2023virtual,ji2024virtual} use an indoor panorama and paired outdoor hemispherical image to virtually render existing scenes with new floor layouts, materials, and illumination conditions. In this study, we estimate the absolute light levels in virtual indoor scenes by modeling light transport using paired indoor and outdoor panoramas. This approach offers an efficient method for accurately simulating indoor illumination conditions.


Heat transport includes the process of heat generated by the source and its exchange between different mediums (\cite{bergman2011introduction}). Temperature exchange within an object follows the well-known heat transfer physics, and three primary mechanisms include conduction, convection, and radiation. Recent work by \cite{ramanagopal2024theory} bridges visible light transport and heat transport in solids and estimates the heat generation from light absorption. Previous studies on heat estimation have primarily focused on small objects under controlled, artificial lighting and captured thermal images in a 2D perspective. In this work, by determining the reflectance properties of indoor materials from captured indoor-outdoor images, the amount of heat absorbed can be estimated.

In this work, we proposed a digital application that exploits paired indoor-outdoor HDR panoramas as input and then estimates indoor lighting and heating properties in panoramic representation (Fig. \ref{fig_workflow}). This work demonstrates that indoor heat generated by light absorption can be estimated by modeling heat transport using a forward rendering process. This work makes the following technical contributions:

\begin{enumerate}[label=(\arabic*), noitemsep, leftmargin=*, align=left, labelindent=\parindent]
  \item An image-based rendering approach using paired indoor-outdoor panoramas to estimate indoor materials, 3D geometry, and lighting for physics-based building analysis.
  \item An application for computing the absolute light level for indoor visual tasks and scene design.
  \item An application for estimating indoor heat map by implementing the transient heat equation.
  \item Parametric analysis is conducted under varying thermal parameters for the transient heat simulation, and the resulting virtual heat maps are compared with real-world thermal images.
\end{enumerate}



\begin{figure*}
  \centering
  \begin{overpic}[width=\textwidth]{fig/workflow.jpg}
    \put(4,15){\tiny \color{black}{Indoor Panorama}}
    \put(4,1){\tiny \color{black}{Outdoor Panorama}}
    \put(30,1){\tiny \color{black}{Virtual Model}}
    \put(51,15){\tiny \color{black}{Virtual Objects}}
    \put(53,1){\tiny \color{black}{Virtual Scene}}
    \put(75,15){\tiny \color{black}{Light Map ($cd/m^2$)}}
    \put(96,27){\tiny \color{black}{3,000}}
    \put(96,16){\tiny \color{black}{0}}
    \put(78,1){\tiny \color{black}{Heat Map ($^{\circ}\mathrm{C}$)}}
    \put(96,13){\tiny \color{black}{25.0}}
    \put(96,2){\tiny \color{black}{21.0}}    
  \end{overpic}
  \caption{Overview of Our Application: First, a single camera (Ricoh Theta Z1) captures paired indoor and outdoor panoramas. Second, the indoor panorama is used to estimate the 3D floor layout, while the outdoor panorama provides a 360$^{\circ}$ environment map for the virtual model. Third, virtual objects are inserted into the scene, and the objects are relit within the scene. Finally, an indoor light map with absolute light level ($cd/m^2$) and a heat map ($^{\circ}\mathrm{C}$) are computed for the room.}
  \label{fig_workflow}
\end{figure*}


\section{Related Work}
\subsection{Indoor Light Estimation}
Directly estimating indoor light from an indoor image is an ill-posed problem. Under natural illumination, the indoor spatially-varying light depends on the outdoor context,  scene geometry, and material properties. 
Given a 2D perspective image, some studies focus on predicting panoramic HDR environment maps (\cite{gardner2017learning}), lighting representation (\cite{gardner2019deep}), and estimating HDR panoramas from LDR images (\cite{gkitsas2020deep,legendre2019deeplight,gardner2017learning}). Extensive research efforts have been devoted to estimating HDR from LDR images using inverse tone mapping algorithms (\cite{rempel2007ldr2hdr,banterle2006inverse,banterle2007framework,reinhard2002photographic}). The estimated HDR panorama is used as a global light source for high-quality relighting and inserting new virtual 3D objects into the scene. Previous studies have also explored indoor lighting editing (\cite{li2022physically}), material property estimation (\cite{yeh2022photoscene}), and recovery of spatially-varying lighting (\cite{li2020inverse,garon2019fast,srinivasan2020lighthouse}) from images. User inputs provide additional information to define scene geometry and light location and direction (\cite{karsch2011rendering}). Through user-annotated light positions, \cite{zhang2016emptying} recover indoor illumination and room geometry from a complete RGB-D scan of a scene.

Since the input 2D perspective image is in LDR format, while the estimated HDR environment map from previous work serves as a global light source, it often fails to recover the accurate scene radiance of the real world. More importantly, earlier studies that directly estimate environment maps from images do not construct a complete light transport model. Such a model would ideally account for outdoor lighting, scene geometry, and material properties and present a complete interaction between light and the environment.


\subsection{Outdoor Light Estimation}
Outdoor light changes with the appearance of the sky, the surrounding context, and the time of day. The luminance and angular distribution of the sky also vary with cloud levels, times of year, and geographic locations. Perez sky model (\cite{perez1993all}) and the CIE standard sky model (\cite{cie2003spitial}) are commonly used to estimate outdoor light. Due to the nuanced difference between cloud cover and sunlight intensity, generalized sky models cannot fully describe the realistic sky appearance (\cite{darula2002cie}). Recent studies have focused on estimating the appearance of the spectral sky. A spectral sky represents chromatic changes based on time, sky turbidity, and geographic locations (\cite{hosek2012analytic}). Furthermore, analytical sky models (\cite{lalonde2012estimating,preetham1999practical}) approximate full-spectrum daylight under various atmospheric conditions.  

In addition to generating sky model images, some studies aim to estimate outdoor lighting directly from 2D images. Learning-based method estimates 360$^{\circ}$ outdoor environment map from a single 2D photograph (\cite{hold2017deep,lalonde2014lighting}). \cite{lalonde2014lighting} developed a method to estimate light direction and intensity from a single Low Dynamic Range (LDR) image, and the generated HDR sky models are used for relighting new objects. \cite{zhang2017learning} recover linear HDR outdoor images from a single LDR panorama. \cite{sunkavalli2008color} recover time-varying color variation for the outdoor scene under direct sunlight and ambient skylight. The recent study by \cite{dastjerdi2023everlight} directly adds, removes, and edits the indoor and outdoor illumination sources in the panoramic representation. However, those studies focus on estimating outdoor environment maps for relighting new virtual objects; the outdoor light source is not used to estimate indoor light transport.

\subsection{Thermal Imaging Technique}
Above absolute zero temperature, indoor objects radiate infrared energy in the Long-Wave Infrared (LWIR) spectrum (wavelengths between 8 $\mu\text{m}$ and 15 $\mu\text{m}$), resulting in heat on the object's surface. The radiometric quantity of the heat transfer can be measured by infrared thermal imaging technique (\cite{holst2000common,kaplan2007practical,vollmer2020infrared,planinsic2011infrared}).  
Thermal imaging has gained increasing attention in computer vision research and leads to applications based on the thermal spectrum, such as object segmentation (\cite{huo2023glass}), 3D estimation (\cite{eren2009scanning,shin2023deep,narayanan2025shape}), and material property estimation (\cite{dashpute2023thermal}).

Thermography has been extensively used to collect surface heat in building spaces. In outdoor applications, recent studies have focused on identifying thermal leakage on exterior facades (\cite{motayyeb2023fusion}) and integrating thermal attributes with 3D point clouds (\cite{jarzkabek2020supervised}). In indoor scenarios, recent research has combined 3D point clouds with 2D thermography for generating 3D building models (\cite{adan2017fusion,schmoll2022method}), detecting faults on interior surfaces (\cite{garrido2018autonomous}), and segmenting targeted thermal regions on building surfaces (\cite{adan2020temporal}). Additionally, heat maps can be captured by a thermal-infrared camera from multiple indoor locations to analyze the heat generated on vertical wall planes (\cite{lopez2017thermographic}), support 3D modeling (\cite{adan2017fusion}), and combine with RGB-D camera for spatial mapping (\cite{vidas20133d}).
 
Existing studies on indoor thermography primarily focus on capturing temporal heat maps at specific time points. There are several limitations. First, 2D thermography captures only a limited field of view. Second, capturing multiple 2D perspective images requires additional effort in data post-processing, such as image registration and alignment. Third, implementing infrared thermal cameras with additional devices like RGB-D cameras or LiDAR adds complexity and increases data acquisition costs. 


\section{Methodology}
\subsection{Indoor Light Estimation}
\label{indoor_lit}
Using a single panorama, scene editing enables users to modify the indoor camera position, adjust lighting conditions, and change materials. Fig. \ref{fig_3desk_read} illustrates a reading scenario and shows the effects of indoor changes with three desk materials: glass, marble, and wood. Beyond the RGB image, the absolute light level is crucial for indoor daily activities. The virtual scene is rendered in HDR format and then converted into luminance values through per-pixel computation (Fig. \ref{fig_desk_pano_lum}). Since both indoor and outdoor HDR images are calibrated to accurately represent real-world scene radiance, this process ensures that the luminance value ($cd/m^2$) in the virtual rendered scene is accurately estimated through physics-based rendering.


\begin{figure*}[!b]
  \centering
  \begin{overpic}[width= \textwidth]{fig/3_desk_read.jpg}
    \put(15,86){\scriptsize \color{black}{Desk 1}}
    \put(47,86){\scriptsize \color{black}{Desk 2}}
    \put(79,86){\scriptsize \color{black}{Desk 3}}
    \put(1,77){\scriptsize{\makebox(0,0){\rotatebox{90}{Scene 1}}}}   
    \put(1,60){\scriptsize{\makebox(0,0){\rotatebox{90}{Scene 2}}}} 
    \put(1,43){\scriptsize{\makebox(0,0){\rotatebox{90}{Scene 3}}}}
    \put(1,26){\scriptsize{\makebox(0,0){\rotatebox{90}{Scene 4}}}}
    \put(1,9){\scriptsize{\makebox(0,0){\rotatebox{90}{Scene 5}}}}
     \end{overpic}
  \caption{Examples of indoor lighting analysis with new indoor layouts and lighting conditions. Three desks are added to the scene. Scene 1 shows the original reading scenario. Scene 2 depicts the desks and chairs moved closer to the couch. Scene 3 shows the desks repositioned to face the wall. Scene 4 features the addition of a desk lamp as an extra light source. Scene 5 includes a ceiling light mounted on the ceiling.}
  \label{fig_3desk_read}
\end{figure*}




\begin{figure*}
  \centering
  \begin{overpic}[width= \textwidth]{fig/desk_lum.jpg}
    \put(15,98){\scriptsize \color{black}{Rendered Scene}}
    \put(62,98){\scriptsize \color{black}{Light Map}}
    \put(1,87){\scriptsize{\makebox(0,0){\rotatebox{90}{Original Scene}}}}   
    \put(1,64){\scriptsize{\makebox(0,0){\rotatebox{90}{New Location}}}}  
    \put(1,41){\scriptsize{\makebox(0,0){\rotatebox{90}{New Desk Lamp}}}} 
    \put(1,18){\scriptsize{\makebox(0,0){\rotatebox{90}{New Ceiling Light}}}} 
    \put(48,2){\scriptsize \color{black}{0}}
    \put(72,2){\scriptsize \color{black}{500}}   
    \put(53,0){\scriptsize \color{black}{Luminance ($cd/m^2$)}}
  \end{overpic}
  \caption{Estimating indoor absolute light levels from virtual rendered scenes. The original scene depicts a reading scenario with a desk and chair within the field of view. The scene is edited with a new desk location, a new desk lamp, and a new ceiling light. The light map displays the absolute luminance values ($cd/m^2$) for the corresponding scenes.}
  \label{fig_desk_pano_lum}
\end{figure*}


\subsection{Indoor Task Lighting}
In addition to luminance (scene radiance), illuminance (scene irradiance) is commonly used to evaluate the adequacy of indoor task lighting. Each indoor task has its own specific target light level to ensure optimal lighting conditions. To convert and obtain the illuminance map, we assume the scene object is Lambertian surface, where the reflectance ($R$) of the diffuse scene materials are known. The global illuminance map can be derived from displayed luminance value on HDR image(\cite{yang2013multi}). 

The conversion of Illuminance ($E$) ($lx$) from Luminance ($L$) ($cd/m^2$) is:
\begin{equation}
    E = \frac{L \pi}{R} 
    \label{eq:E2L_convert}
\end{equation}

The indoor task is visualized from a 180$^\circ$ hemispherical fisheye perspective. Fig. \ref{fig_ind_task_ill} showcases a virtual scene for a reading task. When the desk in the original scene is repositioned to face the wall, and a new desk lamp and ceiling light are added to illuminate the scene, the luminance levels in the virtual scenes can be estimated from the virtual HDR image. Based on the Lambertian assumption for the scene, the average illuminance level on the desk surface can be calculated. If the reading task requires a target brightness of 300 $lux$, a code-based compliance analysis computes the error map to evaluate whether the light is above or below the target level for the reading task.


\begin{figure*}
  \centering
  \begin{overpic}[width= \textwidth]{fig/in_task_ill.jpg}
    \put(10,98){\scriptsize \color{black}{Virtual Scene}}
    \put(34,98){\scriptsize \color{black}{Luminance}}
    \put(58,98){\scriptsize \color{black}{Illuminance}}
    \put(3,88){\scriptsize{\makebox(0,0){\rotatebox{90}{Orignal Scene}}}}   
    \put(3,63){\scriptsize{\makebox(0,0){\rotatebox{90}{New Location}}}} 
    \put(3,41){\scriptsize{\makebox(0,0){\rotatebox{90}{New Desk Lamp}}}}
    \put(3,16){\scriptsize{\makebox(0,0){\rotatebox{90}{New Ceiling Light}}}}
    \put(30,2){\scriptsize \color{black}{0}}
    \put(48,2){\scriptsize \color{black}{800}}   
    \put(32,0){\scriptsize \color{black}{Luminance ($cd/m^2$)}}
    \put(54,2){\scriptsize \color{black}{0}}
    \put(72,2){\scriptsize \color{black}{600}}   
    \put(57,0){\scriptsize \color{black}{Illuminance ($lux$)}}    
  \end{overpic}
  \caption{Estimating indoor absolute luminance ($cd/m^2$) and illuminance ($lux$) levels from virtual rendered scenes. The original scene depicts a reading scenario with a desk and chair within the field of view. The scene is edited with a new desk location, a new desk lamp, and a new ceiling light.}
  \label{fig_ind_task_ill}
\end{figure*}


\section{Indoor Heat Estimation}
\label{indoor_heat}
The heat estimation requires absolute energy influx for each indoor location. As shown in Fig. \ref{fig_energy_influx}, we rendered the existing scene in HDR format and then used per-pixel computation to convert it into the corresponding luminance map. Typically, converting illuminance to energy influx requires specialized measurement equipment. Because we focus on the indoor scene under natural light, the per-pixel energy influx can be approximated directly from the illuminance values (obtained from Equ. \ref{eq:E2L_convert}). In indoor settings, an engineering conversion suggests that 120 $lux$ is approximately equivalent to 1 $W/m^2$ for sunlight (\cite{michael2020conversion}). As shown in Fig. \ref{fig_energy_influx}, the energy influx, converted from the indoor luminance map, will be used as an absolute heat source to compute the indoor heat map.

\begin{figure*}[!b]
  \centering
  \begin{overpic}[width= \textwidth]{fig/energy_influx.jpg}
    \put(0,33){\scriptsize \color{black}{Rendered Scene}}    
    \put(51,33){\scriptsize \color{black}{Luminance ($cd/m^2$)}}
    \put(80,32.5){\scriptsize \color{black}{0}}
    \put(94,32.5){\scriptsize \color{black}{3,500}}  
    \put(0,2){\scriptsize \color{black}{Illuminance ($lx$)}}
    \put(29,2){\scriptsize \color{black}{0}}
    \put(43,2){\scriptsize \color{black}{12,000}}
    \put(51,2){\scriptsize \color{black}{Energy Influx ($W/m^2$)}}
    \put(80,2){\scriptsize \color{black}{0}}
    \put(96,2){\scriptsize \color{black}{100}} 
  \end{overpic}
  \caption{Conversion between Lighting and Energy Influx. The scene is rendered in HDR format (upper left) and converted into a luminance map (upper right). Assuming a Lambertian surface for the 3D scene, the illuminance map (bottom left) is derived from the luminance map, enabling an approximation of the absolute energy influx (bottom right).}
  \label{fig_energy_influx}
\end{figure*}



\subsection{Transient Heat Simulation}
Heat on indoor surfaces varies over time, influenced by material properties (like thermal conductivity, density, and thickness), heat capacity, and surrounding temperatures. We aim to implement a transient heat transport equation to estimate the heat generated by natural light over time.

Thermal diffusivity ($\alpha$) of a material can be expressed as:
\begin{equation}
    \alpha =  \frac{k}{\rho c_p}
    \label{eq:heateq-v1}
\end{equation}

Where $k$ is the thermal conductivity of the material ($W/m\cdot K$), $\rho$ is the density of the material ($kg/m^3$), and $c_p$ is the specific heat capacity of the material at constant pressure ($J/(kg\cdot K)$). The indoor scene has a wide range of building materials, and those variables can be accessed from the existing material database (\cite{iesveTableThermal}).

Intrinsic attributes, such as the Laplace operator, are fundamental quantities in various physical simulations, including heat transfer. The work by \cite{narayanan2025shape} estimates intrinsic 3D shapes from thermal videos, where transient heat transport follows:

\begin{equation}
    \frac{\mathrm{dT}}{\mathrm{dt}} = \alpha \Delta T + \mathbbm{1}_{\partial \Omega} \frac{1}{\rho c_p \mathrm{dv}} \Bigl(\sigma \epsilon A (T_{surr}^4 - T^4) + h_c A (T_{surr} - T) + A\beta \phi_q \Bigr) 
    \label{eq:heateq-v2}
\end{equation}


The first term $\Delta T$ represents conduction, and the second term represents the sum of radiation, convection, and input heat source;  other quantities are explained in Table \ref{tab:quantities}.

The Equ. \ref{eq:heateq-v2} applies to the object heated by three transfer approaches given the surrounding temperature. For indoor surfaces, heat changes not only by spatially-varying light distribution but also by heat transfer between indoor and outdoor spaces. Therefore, we include heat exchange between indoor and outdoor spaces in the heat equation and add outdoor temperature ($T_{out}$) into the heat transport equation:

\begin{equation}
    \frac{\mathrm{dT}}{\mathrm{dt}} = \alpha \Delta T + \mathbbm{1}_{\partial \Omega} \frac{1}{\rho c_p \mathrm{dv}} \Bigl(\sigma \epsilon A (T_{surr}^4 - T^4) + h_c A (T_{surr} - T) + A\beta \phi_q + A(T - T_{out})\Bigr) 
    \label{eq:heateq-v3}
\end{equation}

\begin{table}[ht]  % Using table instead of wraptable for single-column layout
    \centering
    \begin{minipage}{0.75\textwidth} % Adjust width as needed
        \caption{Properties, descriptions, and units for the variables in the Eq. \ref{eq:heateq-v1}, Eq. \ref{eq:heateq-v2}, and Eq. \ref{eq:heateq-v3}.}
        \label{tab:quantities}
        \resizebox{\textwidth}{!}{ % Scale the table to fit the minipage width
            \begin{tabular}{@{}c@{\hskip 4mm}c@{\hskip 4mm}c@{}}
                \toprule
                Property & Description & Unit \\
                \midrule 
                $h_c$ & Convection coefficient & $W/(m^2\cdot K)$ \\
                
                $k$ & Thermal conductivity of the material & $W/m\cdot K$ \\
                $\rho$ & Density of the material & $kg/m^3$ \\
                $c_p$ & Specific heat capacity & $J/(kg\cdot K)$ \\
                
                $\epsilon$ & Emissivity & -- \\
                $\beta$ & Energy absorption factor & -- \\
                $\phi_q$ & Input heat flux density & $W/m^2$ \\
                $A$ & Surface area & $m^2$ \\
                
                $\sigma$ & Stefan-Boltzmann constant & $W/(m^2 K^4)$ \\
                $T$ & Temperature & $K$ \\
                $T_{surr}$ & Surrounding temperature & $K$ \\
                $T_{out}$ & Outdoor temperature & $K$ \\
                $\alpha$ & Thermal diffusivity & $m^2/s$ \\
                \bottomrule
            \end{tabular}
        }
    \end{minipage}
\end{table}


We estimate the indoor heat map using the transient heat equation to calculate the temperature at each pixel. In Fig. \ref{fig_ht_simulation}, the 3D floor layout is derived from a single indoor panorama. The heat simulation is conducted in 3D coordinates, with planar surfaces subdivided into vertices to compute the heat value for each point. After the simulation, the heat data in 3D coordinates is mapped onto an equirectangular projection and displayed on a panorama with the same camera position as the input panorama.   

The transient heat simulation allows the heat values to be visualized over time. In Fig. \ref{fig_transient_ht_step}, we selected a scene to estimate heat changes on the 3D layout from a top-down perspective. The results of the heat simulation are recorded at time steps, where the 0$s$ figure shows the indoor space at the initial temperature. As time progresses, the indoor space heats up, and the indoor temperature is captured incrementally at each step.

\begin{figure*}[!b]
  \centering
  \begin{overpic}[width= 0.9\textwidth]{fig/ht_simulation.jpg}
    \put(0,38){\scriptsize \color{black}{(a)}}
    \put(72,60){\scriptsize \color{black}{(b)}}
    \put(72,36){\scriptsize \color{black}{(c)}}
    \put(72,12){\scriptsize \color{black}{(d)}} 
    \put(0,2){\scriptsize \color{black}{(e)}}
  \end{overpic}
  \caption{Heat Simulation Process. (a) The input is a single panorama, (b) a 3D layout is estimated from the input panorama, (c) a grid of vertices is generated from the planar mesh objects, (d) the heat equation is applied to compute the per-pixel heat value for each vertice, and (e) the output is the heat map converted from 3D coordinate into equirectangular representation for this scene.}
  \label{fig_ht_simulation}
\end{figure*}


\begin{figure*}
  \centering
  \begin{overpic}[width= \textwidth]{fig/transient_ht.jpg}
    \put(5,80){\scriptsize \color{black}{0s}}
    \put(24,80){\scriptsize \color{black}{30s}}
    \put(43,80){\scriptsize \color{black}{60s}}
    \put(62,80){\scriptsize \color{black}{90s}}   
    \put(5,62){\scriptsize \color{black}{120s}}
    \put(24,62){\scriptsize \color{black}{150s}}
    \put(43,62){\scriptsize \color{black}{180s}}
    \put(62,62){\scriptsize \color{black}{210s}}   
    \put(5,44){\scriptsize \color{black}{240s}}
    \put(24,44){\scriptsize \color{black}{270s}}
    \put(43,44){\scriptsize \color{black}{300s}}
    \put(62,44){\scriptsize \color{black}{330s}} 
    \put(5,26){\scriptsize \color{black}{360s}}
    \put(24,26){\scriptsize \color{black}{390s}}
    \put(43,26){\scriptsize \color{black}{420s}}
    \put(62,26){\scriptsize \color{black}{450s}}     
    \put(5,8){\scriptsize \color{black}{480s}}
    \put(24,8){\scriptsize \color{black}{510s}}
    \put(43,8){\scriptsize \color{black}{540s}}
    \put(62,8){\scriptsize \color{black}{570s}}    
    \put(50,2){\scriptsize \color{black}{294.0}}
    \put(71,2){\scriptsize \color{black}{297.0}}   
    \put(56,0){\scriptsize \color{black}{Temperature ($^\circ\text{F}$)}}
  \end{overpic}
  \caption{Transient heat simulation over time. The heat map is initialized and recorded at each time step, displayed from a top-down perspective to illustrate the 3D floor layout as the heat changes from 0$s$ to 570$s$.}
  \label{fig_transient_ht_step}
\end{figure*}


\begin{figure*}
  \centering
  \begin{overpic}[width= \textwidth]{fig/ht_new_sun_clearsky.jpg}
    \put(15,98){\scriptsize \color{black}{Rendered Scene}}
    \put(60,98){\scriptsize \color{black}{Heat Map}}
    \put(1,87){\scriptsize{\makebox(0,0){\rotatebox{90}{Existing Sun at 13:48}}}}   
    \put(1,64){\scriptsize{\makebox(0,0){\rotatebox{90}{New Sun at 14:30}}}}  
    \put(1,41){\scriptsize{\makebox(0,0){\rotatebox{90}{New Sun at 15:00}}}} 
    \put(1,18){\scriptsize{\makebox(0,0){\rotatebox{90}{New Sun at 15:55}}}} 
    \put(60,2.5){\scriptsize \color{black}{21.0}}
    \put(84,2.5){\scriptsize \color{black}{23.0}}   
    \put(67,0){\scriptsize \color{black}{Temperature ($^\circ\text{C}$)}}
  \end{overpic}
  \caption{Estimating indoor heat map at different times. The top row shows the scene rendered with the existing outdoor image with clear sky condition at 13:48. Subsequent rows showcase the scene rendered with the new virtual sun positions and their corresponding heat maps at 14:30 (second row), 15:00 (third row), and 15:55 (bottom row).}
  \label{fig_ht_new_clrsun}
\end{figure*}


Our application can estimate indoor light and heat panoramas based on new outdoor images. In Fig. \ref{fig_ht_new_clrsun}, the existing scene is rendered under real-time outdoor lighting at 13:48. We virtually edited the sun's position to simulate different times and estimated the corresponding panoramic heat map. In Fig. \ref{fig_ht_change_sun}, we present the joint estimation of indoor light and heat properties within the scene. The existing scene is renovated with new furniture objects and then converted into the corresponding light and heat maps. Following the approach by \cite{ji2024virtual}, the outdoor scene is initially cloudy, and direct sunlight is added to the outdoor image and used as a light source to relight the scene at different times in the afternoon (16:45, 17:45, and 18:45). In contrast to the cloudy day scenario, increased direct sunlight enters the indoor space, intensifying illumination on the table and walls while producing strong reflections on the refrigerator. This direct sunlight also raises the temperature levels on the wall and floor surfaces near the window.


\begin{figure*}
  \centering
  \begin{overpic}[width= \textwidth]{fig/ht_change_sun.jpg}
    \put(10,78){\scriptsize \color{black}{Rendered Scene}}
    \put(45,78){\scriptsize \color{black}{Light Map}}
    \put(78,78){\scriptsize \color{black}{Heat Map}}
    \put(-1,70){\scriptsize \color{black}{(a)}}
    \put(-1,52){\scriptsize \color{black}{(b)}}
    \put(-1,34){\scriptsize \color{black}{(c)}}
    \put(-1,16){\scriptsize \color{black}{(d)}}   
    \put(37,3){\scriptsize \color{black}{0}}
    \put(63,3){\scriptsize \color{black}{500}}
    \put(69,3){\scriptsize \color{black}{21.0}}
    \put(96,3){\scriptsize \color{black}{25.0}}   
    \put(45,0){\scriptsize \color{black}{Luminance ($cd/m^2$)}}
    \put(80,0){\scriptsize \color{black}{Temperature ($^\circ\text{C}$)}}
  \end{overpic}
  \caption{Indoor Light and Heat Estimation Under New Outdoor Sun Illuminations: (a). The virtual scene is rendered under the captured outdoor panorama. (b) The virtual scene is rendered with direct sun illumination at 16:45 (b), 17:45 (c) and 18:45 (d), respectively.}
  \label{fig_ht_change_sun}
\end{figure*}


\subsection{Sensitivity Analysis}
The transient heat simulation (Equ. \ref{eq:heateq-v2}) accounts for three types of heat transfer: conduction, radiation, and convection. To evaluate the impact of each component on heat estimation, parametric heat simulations were performed with various combinations of these components, and corresponding heat maps for each condition are visualized, as shown in Fig. \ref{fig_3ht_transf}. When conduction, radiation, and convection are all included, the resulting heat map is considered the baseline for computing the error map. When there is no heat transfer (such as conduction, radiation, and convection), the temperature remains at its highest, as no heat is emitted from the object's surface. Adding different types of heat transfer results in varying reductions in surface temperature. Each heat map is compared with the baseline image. In the error map, the first row shows a matrix with zero values, which indicates no temperature difference. Due to the low material conductivity in this simulation, the third row exhibits minimal temperature differences. Other combinations of heat transfer mechanisms increase the temperature by varying degrees, highlighting their individual and collective contributions to the heat distribution.




\begin{figure*}
  \centering
  \begin{overpic}[width= \textwidth]{fig/3_ht_transfer.jpg}
    \put(3,99){\scriptsize \color{black}{Conduction}}
    \put(13,99){\scriptsize \color{black}{Radiation}}   
    \put(23,99){\scriptsize \color{black}{Convection}}  
    \put(40,99){\scriptsize \color{black}{Heat Map}}    
    \put(62,99){\scriptsize \color{black}{Error Map}}   
    \put(35,2){\scriptsize \color{black}{21.0}}
    \put(51,2){\scriptsize \color{black}{31.0}}
    \put(57,2){\scriptsize \color{black}{-10.0}}
    \put(73,2){\scriptsize \color{black}{10.0}}   
    \put(38,0){\scriptsize \color{black}{Temperature ($^\circ\text{C}$)}}
    \put(60,0){\scriptsize \color{black}{Temperature ($^\circ\text{C}$)}}
  \end{overpic}
  \caption{The Effects of Three Heat Transfer Types in Heat Simulations (Equation \ref{eq:heateq-v2}). Black dots indicate when a heat transfer type is toggled. The first three columns show component combinations. Heat maps display simulation results for each combination, while error maps compare results to the first row (all components active), where the error is zero. Minimal conduction effects, due to low material conductivity (Plaster: 0.5 $W/(m\cdot K)$), result in minor differences in the third-row error map.}
  \label{fig_3ht_transf}
\end{figure*}

\begin{figure}
    \centering
    \begin{subfigure}{0.49\linewidth}
        \centering
        \includegraphics[width=\linewidth]{fig/1250+2F_Small+W_patch.jpg}
    \end{subfigure}
    \hfill
    \begin{subfigure}{0.49\linewidth}
        \centering
        \includegraphics[width=\linewidth]{fig/1250+2F_Small+W_blended_image_patch.jpg}
    \end{subfigure}
    \caption{(Left) An indoor panorama. (Right) The target patches are selected by user mouse clicks, which will be used to compute the average temperature in each patch.}
    \label{fig_heat_indoor_patch}
\end{figure}


Various physical parameters in the heat simulation are analyzed for their impacts on indoor surface temperature. For a single panorama, we developed a graphic user interface (GUI) that allows users to click on the input image and outline circular target areas within indoor scenes. These selected target patches are used to compute the average temperature over their coverage, as shown in Fig.~\ref{fig_heat_indoor_patch}. We selected standard materials and parameters to generate the corresponding indoor heat maps. The default heat simulation time is 600$s$, the surface thickness is 1$mm$, and the indoor ambient temperature is 21.11$^\circ\text{C}$. 


For different surface materials (Fig.~\ref{fig_ht_materials}), the surface temperatures and temperature differences (using the temperatures under plaster dense as baseline values) are visualized. Copper results in the lowest temperature on indoor surfaces, while plaster-dense, polystyrene, PVC (polyvinyl chloride), and simulated sheep wool result in higher temperatures than other materials and display similar temperature values across indoor surfaces. 


\begin{figure*}
  \centering
  \begin{subfigure}[t]{\textwidth}
    \centering
    \includegraphics[width=\textwidth]{fig/materials_result_with_color_legend.png}
  \end{subfigure}
  \begin{subfigure}[t]{\textwidth}
    \centering
    \includegraphics[width=\textwidth]{fig/materials_signed_temperature_difference_with_percentage.png}
  \end{subfigure}
  \caption{(Top) The average temperature on indoor surfaces under different materials types. (Bottom) Using the temperature values under plaster dense as baseline values to compute the temperature difference ($^\circ\text{C}$) and percentage error ($\%$).}
  \label{fig_ht_materials}
\end{figure*}

Each material has its unique density, conductivity, and specific heat capacity. In this step, we set the default material to plaster-dense, adjust a single material property, and analyze its impact on surface temperature. Temperatures under different material densities and temperature differences (using the temperatures under correct density (1300 ${kg}/{mm}^3$) as baseline values) are visualized (Fig.~\ref{fig_ht_density}). We observe that, as material density (${kg}/{mm}^3$) increases, surface temperature decreases in general. While some temperatures rise on ceilings under 3300 and 5300 ${kg}/{mm}^3$, with increments in material density, the temperatures at 1200, 1250, 1300, 1350, 1400, and 1500 ${kg}/{mm}^3$ are identical. When the material density reaches 7300 ${kg}/{mm}^3$, it decreases the surface temperature by approximately between - 0.27 and 0.36 $^\circ\text{C}$, with a corresponding percentage error between -1.00 and -1.60 \%. 

\begin{figure*}
  \centering
  \begin{subfigure}[t]{\textwidth}
    \centering
    \includegraphics[width=\textwidth]{fig/density_result_with_color_legend.png}
  \end{subfigure}
  \begin{subfigure}[t]{\textwidth}
    \centering
    \includegraphics[width=\textwidth]{fig/density_temperature_difference_with_percentage.png}
  \end{subfigure}
  \caption{(Top) The average temperature of indoor surfaces under different material density values (${kg}/{mm}^3$): 1200, 1250, 1300, 1350, 1400, 1500, 3300, 5300, 7300, and 9300. (Bottom) Using the temperature values at the correct density of 1300 as baseline values to compute the temperature difference ($^\circ\text{C}$) and percentage error ($\%$).}
  \label{fig_ht_density}
\end{figure*}


When changing material conductivity and specific heat capacity values, the surface temperature on indoor surfaces did not show differences (Fig.~\ref{fig_ht_condu_spec_ht}). This suggests that, compared to material density, conductivity and heat capacity have minor impacts on surface temperature when using plaster-dense as the material and our default simulation settings. While additional simulations could be conducted to further investigate this pattern, this section primarily focuses on the standard building materials and changes their thermal properties in the transient heat simulation.



\begin{figure*}
  \centering
  \begin{subfigure}[t]{\textwidth}
    \centering
    \includegraphics[width=\textwidth]{fig/conductivity_result_with_color_legend.png}
  \end{subfigure}
  \begin{subfigure}[t]{\textwidth}
    \centering
    \includegraphics[width=\textwidth]{fig/specific_heat_result_with_color_legend.png}
  \end{subfigure}
  \caption{(Top) The average temperature on indoor surfaces under different material conductivity values in $W/(m \cdot K)$: 0.01, 0.10, 0.20, 0.50, and 0.70. (Bottom) The average temperature on indoor surfaces under different specific heat capacity values in $J/(kg \cdot K)$: 100, 500, 1000, 1200, 2500, and 3000.}
  \label{fig_ht_condu_spec_ht}
\end{figure*}



\begin{figure*}[t]
  \centering
  \begin{subfigure}[t]{\textwidth}
    \centering
    \includegraphics[width=\textwidth]{fig/surface_thickness_result_with_color_legend.png}
  \end{subfigure}
  \begin{subfigure}[t]{\textwidth}
    \centering
    \includegraphics[width=\textwidth]{fig/surface_thickness_signed_temperature_difference_with_percentage.png}
  \end{subfigure}
  \caption{(Top) The average temperature of indoor surfaces under different surface thicknesses (${mm}$). (Bottom) Using the temperature values at the surface thickness of 1 (${mm}$) as baseline values to compute the temperature difference ($^\circ\text{C}$) and percentage error ($\%$).}
  \label{fig_ht_surf_thick}
\end{figure*}

Surface thickness is crucial in heat simulation, as thicker materials contain more mass, which alters the heat capacity. Following the default simulation settings, surface thickness is adjusted to examine its impact on surface temperatures. Temperatures under different surface thicknesses and their respective differences (using the temperatures for a 1 $mm$ surface thickness as baseline values) are visualized in Fig.~\ref{fig_ht_surf_thick}. As the surface thickness increases from 1 $mm$ to 150 $mm$, the temperature continuously decreases. For example, for the surface temperature on the ceiling, when the thickness increased from 1 $mm$ to 5 $mm$, the temperature dropped from 22.2$^\circ\text{C}$ to below 21.6$^\circ\text{C}$. However, when the thickness increased from 50 $mm$ to 150 $mm$, the temperature change was minimal. Notably, for Wall 1, there was no temperature difference observed between thicknesses of 100 $mm$ and 150 $mm$. Overall, when the indoor ambient temperature is 21.11$^\circ\text{C}$, using thicker material results in a lower indoor temperature, bringing it closer to the ambient temperature in this setting.

When there is heat transfer between indoor and outdoor surfaces, Equ.  \ref{eq:heateq-v3} is used to estimate indoor heat maps at different outdoor temperatures. Fig. \ref{fig_in_outd_temp} shows the results with and without indoor-outdoor heat transfer at various outdoor temperatures. The image without indoor-outdoor heat transfer serves as the baseline for computing temperature differences. When the indoor ambient temperature is 21.11 $^\circ\text{C}$, an outdoor temperature of 11.85 $^\circ\text{C}$ results in lower indoor surface temperatures. As the outdoor temperature rises above the indoor temperature, it leads to higher indoor surface temperatures, with greater heat transfer occurring from the outdoor environment to the indoor space. While the temperature difference is minor, using a temperature map ranging between -0.2 $^\circ\text{C}$ and 0.2 $^\circ\text{C}$ highlights the importance of considering indoor-outdoor temperature exchange for accurate indoor heat estimation in a real-world scenario.

\begin{figure*}
  \centering
  \begin{overpic}[width= \textwidth]{fig/in_out_temp.jpg}
    \put(20,98){\scriptsize \color{black}{Heat Map}}
    \put(55,98){\scriptsize \color{black}{Temperature Difference}}
    \put(1,87){\scriptsize{\makebox(0,0){\rotatebox{90}{No In-Out Heat Transfer}}}}   
    \put(1,64){\scriptsize{\makebox(0,0){\rotatebox{90}{Outdoor 11.85$^\circ\text{C}$}}}}  
    \put(1,41){\scriptsize{\makebox(0,0){\rotatebox{90}{Outdoor 26.85$^\circ\text{C}$}}}} 
    \put(1,18){\scriptsize{\makebox(0,0){\rotatebox{90}{Outdoor 41.85$^\circ\text{C}$}}}} 
    \put(21,2){\scriptsize \color{black}{21.0}}
    \put(39,2){\scriptsize \color{black}{26.0}}
    \put(65,2){\scriptsize \color{black}{-0.2}}
    \put(83,2){\scriptsize \color{black}{0.2}}   
    \put(27,0){\scriptsize \color{black}{Temperature ($^\circ\text{C}$)}}
    \put(70,0){\scriptsize \color{black}{Temperature ($^\circ\text{C}$)}}
  \end{overpic}
  \caption{Heat estimation when indoor-outdoor heat transfer is included (Equ. \ref{eq:heateq-v3}) and the indoor ambient temperature is 21.11 $^\circ\text{C}$. (Left column) Heat maps under different outdoor temperatures. (Right column) Temperature differences using the heat map without indoor-outdoor heat transfer as the baseline for comparison.}
  \label{fig_in_outd_temp}
\end{figure*}

\subsection{Indoor Thermal Imaging}
To evaluate the results of our heat simulation, we captured the real-world scenes using a Ricoh Theta Z1 camera alongside a thermal camera. The heat simulation enables visualization of indoor heat maps in the equirectangular representation, while the thermal camera provides only a 2D perspective view. Therefore, we cropped the target region from the rendered heat map and converted it into a 2D perspective with the same field of view (FOV) as the thermal camera. We then evaluated the rendered images by comparing them with the thermal images captured by the thermal camera.

\begin{figure*}
  \centering
  \begin{overpic}[width= 0.5\textwidth]{fig/camera_Set-up.jpg}
  \end{overpic}
  \caption{Camera setup for capturing indoor panorama and thermal images}
  \label{fig_ht_camera_setup}
\end{figure*}

As shown in Fig. \ref{fig_ht_camera_setup}, a Ricoh Theta Z1 camera is positioned side by side with the FLIR thermal camera at the same height, with a Macbeth color checker and a gray matte board placed within the field of view. The real-time indoor temperature is recorded on the Govee Hygrometer Thermometer (H5075), and the outdoor temperature is obtained from GPS data in the local region.

We set up the FLIR thermal camera in TLinear mode (Boson, image resolution: 640 by 512 pixels) when capturing the thermal images. However, TLinear assumes the default emissivity, atmosphere temperature, and background temperature for the scene. The thermal image captured by TLinear requires a post-process (\cite{flirpyThermalCameras}) to display the correct thermal image based on the actual emissivity of the material.

The counts ($W(T_{obj})$) from the digital converter (ADC) can be expressed as:
\begin{equation}
\label{eq:WT}
    W(T_{obj}) = \frac{R}{\exp\left(\frac{B}{T_K}\right) - F} + O
\end{equation}

Where $T_K$ is the thermal image captured under TLinear mode, $R$, $B$, $F$, and $O$ are FLIRâ€™s constant calibration coefficients.

The flux ($S$) at the detector can be expressed as: 

\begin{equation}
\label{eq:S_flux}
S = \hat{\epsilon} W(T_{obj}) + (1 - \hat{\epsilon}) W(T_{back})
\end{equation}

Where $\hat{\epsilon}$ represents the default emissivity value, and $W(T_{back})$ is the default background temperature (a constant value).

The actual actual emissivity ($\epsilon$) is used to compute the $W(T_{obj})$:  
\begin{equation}
\label{eq:S_flux_rearranged}
    W(T_{obj}) = (S - (1 - \epsilon) W(T_{back})) / \epsilon 
\end{equation}

The thermal image, displayed with the actual material emissivity, can be computed as:

\begin{equation}
\label{eq:TK}
    T_K = \frac{B}{\ln\left(\frac{R}{W(T_{obj}) - O} + F\right)} 
\end{equation}


\subsection{Validation and Comparison}
Using our proposed heat estimation method, a single indoor panorama is used to generate a panoramic heat map from the same camera position (Fig. \ref{fig_ht_comp}). The average temperature values are calculated on the planar indoor surfaces within the white circles, and the heat estimation results are compared with the thermal images captured by the thermal camera. In Scene 1, the temperature difference at selected areas ranged from 2.00 to 2.50 $^\circ\text{C}$. In Scene 2, the temperature difference was approximately 4.00 to 4.50 $^\circ\text{C}$. In Scene 3, the wall plane in the upper left corner showed a temperature difference of about 1.00 $^\circ\text{C}$, while the wall plane on the right and the floor exhibited larger temperature errors, close to 2.00 $^\circ\text{C}$. It is also important to note that the thermal images from the thermal camera are noisy, which can lower the average temperature in the target region.


\begin{figure*}
  \centering
  \begin{overpic}[width= \textwidth]{fig/heat_comp.jpg}
    \put(15,84){\scriptsize \color{black}{Scene 1}}
    \put(47,84){\scriptsize \color{black}{Scene 2}}
    \put(79,84){\scriptsize \color{black}{Scene 3}}
    \put(1,75){\scriptsize{\makebox(0,0){\rotatebox{90}{Input}}}}  
    \put(1,57){\scriptsize{\makebox(0,0){\rotatebox{90}{Heat Map}}}} 
    \put(1,37){\scriptsize{\makebox(0,0){\rotatebox{90}{2D Perspective}}}} 
    \put(1,13){\scriptsize{\makebox(0,0){\rotatebox{90}{Thermal Camera}}}}  
    
    \put(33,28){\tiny{\makebox(0,0){\rotatebox{90}{20.0}}}}     
    \put(33,46){\tiny{\makebox(0,0){\rotatebox{90}{25.0}}}}  
    \put(66,28){\tiny{\makebox(0,0){\rotatebox{90}{20.0}}}}     
    \put(66,46){\tiny{\makebox(0,0){\rotatebox{90}{25.0}}}}
    \put(99,28){\tiny{\makebox(0,0){\rotatebox{90}{20.0}}}}     
    \put(99,46){\tiny{\makebox(0,0){\rotatebox{90}{25.0}}}} 

    \put(33,4){\tiny{\makebox(0,0){\rotatebox{90}{19.0}}}}     
    \put(33,22){\tiny{\makebox(0,0){\rotatebox{90}{23.0}}}}  
    \put(66,4){\tiny{\makebox(0,0){\rotatebox{90}{17.0}}}}     
    \put(66,22){\tiny{\makebox(0,0){\rotatebox{90}{21.0}}}}
    \put(99,4){\tiny{\makebox(0,0){\rotatebox{90}{19.0}}}}     
    \put(99,22){\tiny{\makebox(0,0){\rotatebox{90}{23.0}}}}   
    
    \put(81,0){\scriptsize \color{black}{Temperature ($^\circ\text{C}$)}}
  \end{overpic}
  \caption{Comparison between the rendered heat map and thermal images captured on-site: Three scenes were captured as inputs, and panoramic indoor heat maps were generated. The target regions were cropped to align with the thermal camera's field of view and pose. Indoor surface temperatures are highlighted in white. The temperature scale of each heat map has been adjusted for visualization.}
  \label{fig_ht_comp}
\end{figure*}

An accurate 3D floor layout is essential for precise heat estimation. We focus on the error analysis of the heat simulation in different floor layouts (Fig. \ref{fig_ht_geo_error}). Layout 1 is considered as the correct floor layout, while Layouts 2 and 3 feature slight shifts in the floor boundaries. The heat maps for Layouts 2 and 3 reveal variations in indoor temperature values due to inaccuracies in the room geometry. In the Error Map, the heat maps of Layouts 2 and 3 are compared with the ground-truth (GT) heat map of Layout 1. Layout 2 shows lower temperature estimates at the upper and lower corners of the wall, while Layout 3 exhibits lower temperatures near the wall adjacent to the left window. Although the temperature differences are minor, an accurate floor layout is crucial to generate reliable indoor heat maps.


\begin{figure*}
  \centering
  \begin{overpic}[width= \textwidth]{fig/geo_error_ht.jpg}
    \put(12,74){\scriptsize \color{black}{Layout 1}}
    \put(45,74){\scriptsize \color{black}{Layout 2}}
    \put(78,74){\scriptsize \color{black}{Layout 3}}
    \put(0,62){\scriptsize{\makebox(0,0){\rotatebox{90}{Floor Boundary}}}}
    \put(0,37){\scriptsize{\makebox(0,0){\rotatebox{90}{Heat Map}}}}
    \put(0,14){\scriptsize{\makebox(0,0){\rotatebox{90}{Error Map}}}}
    \put(69,27){\scriptsize \color{black}{21.0}}
    \put(96,27){\scriptsize \color{black}{26.0}} 
    \put(80,24){\scriptsize \color{black}{Temperature ($^\circ\text{C}$)}}
    \put(69,4){\scriptsize \color{black}{-2.0}}
    \put(96,4){\scriptsize \color{black}{2.0}}     
    \put(80,1){\scriptsize \color{black}{Temperature ($^\circ\text{C}$)}}
  \end{overpic}
  \caption{Error analysis of heat estimation (Temperature ($^\circ\text{C}$)) for different floor layouts: Layout 1 presents the correct floor boundary, while Layouts 2 and Layout 3 edit the existing floor boundary. The Heat Map illustrates the estimated heat panoramas based on the respective floor boundaries. The Error Map uses the estimated heat map to minimize the baseline heat map from Layout 1 and displays the per-pixel temperature differences.}
  \label{fig_ht_geo_error}
\end{figure*}

\section{Conclusion}
In this work, we present an application that uses paired indoor and outdoor RGB panoramas as input to estimate indoor lighting and heat properties. Built on image-based rendering techniques, our inverse rendering pipeline not only provides high-quality indoor renderings in a photorealistic manner but also enables us to estimate light levels for indoor task lighting analysis. Since the panorama provides an omnidirectional view of the scene, the task lighting tool allows users to identify suitable work areas. Besides, heat estimation is integrated with lighting analysis. The heat generated by natural light on indoor surfaces is estimated, whereas transient heat transport enables the analysis of indoor heat distribution over time. Our method provides an efficient solution for indoor lighting and thermal analysis, supporting virtual indoor staging and contributing to high-quality scene design, lighting research, and thermal imaging techniques for real-world scenarios.


\section{Discussion}
\subsection{Limitations}
\label{sec:limit_ht}
This paper presents the methodology for a joint estimation of light and heat for a single panorama. However, several limitations are identified in this work. The heat estimation assumes that all indoor heat originates from natural light (the outdoor RGB panorama) and takes sunlight as the sole heat source. Since mechanical systems, such as air conditioning or heating operations, are unknown in a single panorama, their power and functionality remain unknown. Consequently, the heat estimation reflects only the temperature effects caused by outdoor light. The outdoor scene is captured as a 360$^\circ$ environment map. This map serves as an omnidirectional illumination source from an infinite distance. However, accurately modeling detailed outdoor 3D objects can be challenging when obstructions are present. For example, under clear sky conditions, sunlight can be blocked by trees and leaves, resulting in light leakage as beams pass through the foliage. These subtle lighting effects cannot be recovered effectively, as the scene is flattened onto the environment map. The estimation of irradiance (illuminance) is based on the assumption that all objects have Lambertian surfaces. Materials such as glass or metal have not been included in this work.

\subsection{Future Work}
Future work should consider more complex materials, such as transparent glass and specular metals, to enhance the realism of virtual rendered scenes. Additionally, heat simulations should investigate a broader range of material properties and analyze the impacts of various parameters on heat change. Expanding the scope to include more building cases, such as those in different geographic locations, with diverse indoor materials, and under varying weather conditions, would further enrich the study and its applicability.

\section{Disclosure Statement}
The authors declare no potential conflicts of interest with respect to the research, authorship, and/or publication of this article.


% \section*{Acknowledgement(s)}
% Hidden for anonymous peer review.
% An unnumbered section, e.g.\ \verb"\section*{Acknowledgements}", may be used for thanks, etc.\ if required and included \emph{in the non-anonymous version} before any Notes or References.


% \section*{Disclosure statement}

% An unnumbered section, e.g.\ \verb"\section*{Disclosure statement}", may be used to declare any potential conflict of interest and included \emph{in the non-anonymous version} before any Notes or References, after any Acknowledgements and before any Funding information.


% \section*{Funding}
% Hidden for anonymous peer review.
% An unnumbered section, e.g.\ \verb"\section*{Funding}", may be used for grant details, etc.\ if required and included \emph{in the non-anonymous version} before any Notes or References.


% \section*{Notes on contributor(s)}

% An unnumbered section, e.g.\ \verb"\section*{Notes on contributors}", may be included \emph{in the non-anonymous version} if required. A photograph may be added if requested.


% \section*{Nomenclature}

% An unnumbered section, e.g.\ \verb"\section*{Nomenclature}" (or \verb"\section*{Notation}"), may be included if required, before any Notes or References.


% \section*{Notes}

% An unnumbered `Notes' section may be included before the References (if using the \verb"endnotes" package, use the command \verb"\theendnotes" where the notes are to appear, instead of creating a \verb"\section*").

\bibliographystyle{unsrtnat} % or another style like plainnat, unsrtnat, etc.
\bibliography{interactcsesample}

\end{document}
