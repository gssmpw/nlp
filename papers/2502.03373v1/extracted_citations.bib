@misc{deepseekai2025r1,
      title={DeepSeek-R1: Incentivizing Reasoning Capability in LLMs via Reinforcement Learning}, 
      author={DeepSeek-AI},
      year={2025},
      eprint={2501.12948},
      archivePrefix={arXiv},
      primaryClass={cs.CL},
}

@misc{feng2023alphazerolike,
    title={Alphazero-like Tree-Search can Guide Large Language Model Decoding and Training},
    author={Xidong Feng and Ziyu Wan and Muning Wen and Stephen Marcus McAleer and Ying Wen and Weinan Zhang and Jun Wang},
    year={2023},
    eprint={2309.17179},
    archivePrefix={arXiv},
    primaryClass={cs.LG}
}

@inproceedings{flan,
  abstract  = {We study the design decision of publicly available instruction tuning methods, by reproducing and breaking down the development of Flan 2022 (Chung et al., 2022). Through careful ablation studies on the Flan Collection of tasks and methods, we tease apart the effect of design decisions which enable Flan-T5 to outperform prior work by 3-17% across evaluation settings. We find task balancing and enrichment techniques are overlooked but critical to effective instruction tuning, and in particular, training with mixed prompt settings (zero-shot, few-shot, chain-of-thought) actually yields equivalent or stronger (2%) performance in all settings. In further experiments we show Flan-T5 requires less finetuning to converge higher and faster than T5 on single downstream tasks â€“ motivating instruction-tuned models as more computationally-efficient starting checkpoints for new tasks. Finally, to accelerate research on instruction tuning, we make the Flan 2022 collection of datasets, templates, and methods publicly available.},
  author    = {Longpre, Shayne and Hou, Le and Vu, Tu and Webson, Albert and Chung, Hyung Won and Tay, Yi and Zhou, Denny and Le, Quoc V and Zoph, Barret and Wei, Jason and Roberts, Adam},
  booktitle = {Proceedings of the 40th International Conference on Machine Learning},
  editor    = {Krause, Andreas and Brunskill, Emma and Cho, Kyunghyun and Engelhardt, Barbara and Sabato, Sivan and Scarlett, Jonathan},
  month     = {23--29 Jul},
  pages     = {22631--22648},
  pdf       = {https://proceedings.mlr.press/v202/longpre23a/longpre23a.pdf},
  publisher = {PMLR},
  series    = {Proceedings of Machine Learning Research},
  title     = {The Flan Collection: Designing Data and Methods for Effective Instruction Tuning},
  volume    = {202},
  year      = {2023}
}

@misc{kimi2025k15,
      title={Kimi k1.5: Scaling Reinforcement Learning with LLMs}, 
      author={{Kimi Team}},
      year={2025},
      eprint={2501.12599},
      archivePrefix={arXiv},
      primaryClass={cs.AI},
}

@misc{lambert2024tulu,
    title={Tulu 3: Pushing Frontiers in Open Language Model Post-Training},
    author={Nathan Lambert and Jacob Morrison and Valentina Pyatkin and Shengyi Huang and Hamish Ivison and Faeze Brahman and Lester James V. Miranda and Alisa Liu and Nouha Dziri and Shane Lyu and Yuling Gu and Saumya Malik and Victoria Graf and Jena D. Hwang and Jiangjiang Yang and Ronan Le Bras and Oyvind Tafjord and Chris Wilhelm and Luca Soldaini and Noah A. Smith and Yizhong Wang and Pradeep Dasigi and Hannaneh Hajishirzi},
    year={2024},
    eprint={2411.15124},
    archivePrefix={arXiv},
    primaryClass={cs.CL}
}

@inproceedings{lightman2023verifystep,
  author    = {Hunter Lightman and Vineet Kosaraju and Yuri Burda and Harrison Edwards and Bowen Baker and Teddy Lee and Jan Leike and John Schulman and Ilya Sutskever and Karl Cobbe},
  booktitle = {The Twelfth International Conference on Learning Representations},
  title     = {Let's Verify Step by Step},
  year      = {2024}
}

@misc{openai2024o1,
  author = {OpenAI},
  title  = {Learning to reason with LLMs},
  url    = {https://openai.com/index/learning-to-reason-with-llms/},
  year   = 2024
}

@misc{ouyang2022training,
    title={Training language models to follow instructions with human feedback},
    author={Long Ouyang and Jeff Wu and Xu Jiang and Diogo Almeida and Carroll L. Wainwright and Pamela Mishkin and Chong Zhang and Sandhini Agarwal and Katarina Slama and Alex Ray and John Schulman and Jacob Hilton and Fraser Kelton and Luke Miller and Maddie Simens and Amanda Askell and Peter Welinder and Paul Christiano and Jan Leike and Ryan Lowe},
    year={2022},
    eprint={2203.02155},
    archivePrefix={arXiv},
    primaryClass={cs.CL}
}

@misc{snell2024scaling,
    title={Scaling LLM Test-Time Compute Optimally can be More Effective than Scaling Model Parameters},
    author={Charlie Snell and Jaehoon Lee and Kelvin Xu and Aviral Kumar},
    year={2024},
    eprint={2408.03314},
    archivePrefix={arXiv},
    primaryClass={cs.LG}
}

@misc{wang2024multistep,
    title={Multi-step Problem Solving Through a Verifier: An Empirical Analysis on Model-induced Process Supervision},
    author={Zihan Wang and Yunxuan Li and Yuexin Wu and Liangchen Luo and Le Hou and Hongkun Yu and Jingbo Shang},
    year={2024},
    eprint={2402.02658},
    archivePrefix={arXiv},
    primaryClass={cs.AI}
}

@inproceedings{wei2022cot,
 author = {Wei, Jason and Wang, Xuezhi and Schuurmans, Dale and Bosma, Maarten and ichter, brian and Xia, Fei and Chi, Ed and Le, Quoc V and Zhou, Denny},
 booktitle = {Advances in Neural Information Processing Systems},
 editor = {S. Koyejo and S. Mohamed and A. Agarwal and D. Belgrave and K. Cho and A. Oh},
 pages = {24824--24837},
 publisher = {Curran Associates, Inc.},
 title = {Chain-of-Thought Prompting Elicits Reasoning in Large Language Models},
 volume = {35},
 year = {2022}
}

@inproceedings{yu2024metamath,
  author    = {Longhui Yu and Weisen Jiang and Han Shi and Jincheng YU and Zhengying Liu and Yu Zhang and James Kwok and Zhenguo Li and Adrian Weller and Weiyang Liu},
  booktitle = {The Twelfth International Conference on Learning Representations},
  title     = {MetaMath: Bootstrap Your Own Mathematical Questions for Large Language Models},
  year      = {2024}
}

