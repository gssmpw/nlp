\section{Threat Models and Privacy Definition}
\label{sec::threat_privacy}



\noindent\textbf{Threat Model.} 
We consider a scenario where users interact with large, remote, and untrusted LCAs through APIs. These can be web-based or hosted on cloud-based services or private networks and may be either general-purpose or domain-specific. Users often share personal, financial, or medical information without clear knowledge of how their data is managed, increasing privacy risks due to the lack of transparency around these agents. 


We focus on a threat model where users unintentionally compromise their privacy by oversharing information. Our approach targets out-of-context \emph{self-disclosure} by guiding users to share only contextually necessary information. By identifying unnecessary or sensitive disclosures in real time, we assist users in controlling the information they reveal, thereby reducing the risk of unintentional privacy breaches.
Our approach indirectly mitigates the threat of \emph{malicious users}, who seek to extract sensitive information from the agents by manipulating their interactions, by minimizing the amount of sensitive information exchanged during interactions.






\noindent\textbf{Contextual Privacy in Conversational Agents} 
We define the notion of \textit{contextual privacy} in conversational agents, inspired by the Contextual Integrity (CI) theory. 
CI models privacy as information flow defined by the five parameters sender (who is sharing the data), subject (who the information is about), receiver (who is getting the data), context (what sort of information is being shared), and transmission principle (the conditions under which information flow is conducted) \cite{nissenbaum2004privacy}. CI evaluates whether the information flow adheres to appropriate standards governed by norms, which vary based on the specific circumstances of the interaction. Establishing privacy norms and privacy principles of CI is complex and indeed an open problem in the literature since norms are governed by societal contexts and can evolve in response to societal developments \cite{malkin2023contextual}. 

Instead, we draw inspiration from the CI theory to formalize the notion of contextual privacy, focusing on the user-LCA interaction.
We begin with characterizing the \textit{information flow} between a user and an LCA by drawing on the five essential CI parameters in Table \ref{table:ci_params}. We simplify the transmission principle based on the privacy directive \textit{share information that is essential to get the answer}, similar to \cite{bagdasaryan2024air}.

After we characterize the subject and the \textit{context} (which captures the user’s intent and the key task) from the user’s query along with the prior conversation history, we determine two types of sensitive attributes in the query: (a) details that are essential to answer the query, and (b) sensitive details that are not essential for answering the query. We say that a user query is \textit{contextually private} if it does not contain any nonessential sensitive attributes. An example of essential and non-essential attributes for a query is shown in Figure \ref{fig:framework}.










 






\begin{table*}[t]
  \small
  \renewcommand{\arraystretch}{1.2}
  \centering
  \caption{Entities associated with contextual integrity in conversational agents.}
  \resizebox{0.94\textwidth}{!}{
  \begin{tabular}{ p{2cm}  p{4cm}  p{8cm} }
    \toprule
    \textbf{CI Entity} & \textbf{Definition} & \textbf{Function/Considerations} \\ 
    \toprule
    \textbf{Sender (self)} & The user sending information to the agent to achieve a task. & Ensure the user shares only relevant and necessary information. \\ 
    \midrule
    \textbf{Subject} & The individual(s) about whom information is shared (self, others, or both). & Protect the privacy of the subject by identifying whether the subject is the user or another person. Information shared should respect the subject's privacy. \\ 
    \midrule
    \textbf{Receiver (agent)} & The agent that receives and processes information. & Treat agent as untrusted. Apply strict privacy controls to prevent oversharing. May be domain-specific (e.g., MedicalChat Assistant) or general-purpose (e.g., ChatGPT). \\ 
    \midrule
    \textbf{Context (data type)} & The broader domain or user intent (e.g., medical, finance, work-related) guiding the interaction. & Guides what information is relevant to share. In domain-specific apps, the context is predefined; in general-purpose apps, intent detection is used. Optionally, users may specify sensitive contexts. \\ 
    \midrule
    \textbf{Transmission Principle} & The rule governing the flow of information between sender and receiver. & Share only essential and relevant information for the task, avoiding unnecessary or sensitive information. Respect the privacy expectations defined by context and actors. \\ 
    \bottomrule
  \end{tabular}}
  \label{table:ci_params}
\end{table*}


