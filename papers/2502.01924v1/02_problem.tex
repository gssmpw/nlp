\section{Problem Statement}

Consider an autonomous system with state $\state \in \sset \subseteq \mathbb{R}^n$ that evolves according to dynamics $\dot{\state} = \dyn(\state, \ctrl, \dstb)$, where $\ctrl \in \cset$ and $\dstb \in \dset$ are the control and disturbance of the system, respectively. 
$\dstb$ can represent potential model uncertainties or an actual, adversarial exogenous input to the system.
We assume the dynamics are uniformly continuous in $u$ and $d$, bounded, and Lipschitz continuous in $\state$ for fixed $\ctrl$ and $\dstb$.
Finally, let $\traj_{\state,\tvar}^{\ctrlseq,\mathbf{\dstb}}(\tdummy)$ denote the system state at time $\tdummy$, starting from the state $\state$ at time $\tvar$ under control signal $\ctrlseq(\cdot)$ and disturbance signal $\dstbseq(\cdot)$ while following the dynamics. A control signal $\ctrlseq(\cdot)$ is defined as a measurable function mapping from the time horizon to the set of admissible controls $\cset$, and a disturbance signal is similarly defined. 
We additionally assume that the control and disturbance signals $\ctrlseq(\cdot)$ and $\dstbseq(\cdot)$ are piecewise continuous in $t$. 
This assumption ensures that the system trajectory $\traj_{\state,\tvar}^{\ctrlseq,\mathbf{\dstb}}$
exists and is unique and continuous for all initial states \cite{coddington1955theory, callier2012linear}.

In addition, we are given a failure set $\targetset \subset X$ that the system must avoid at all times (e.g., obstacles for a navigation robot). The safety constraint is encoded via a Lipschitz continuous function $
\targetfunc (\cdot): \targetset= \{\state : \targetfunc(\state)\leq 0\}$.
We aim to design a controller that optimally balances the system's safety constraints and performance objectives. The performance objective is given by minimizing a cost function $S$ over the system trajectory, given by:
%
\begin{equation}    S(\traj)=\phi(\state(\tfinal),\tfinal)+\int_{\tinit}^{\tfinal}{\mathcal{L}}(\state(\tvar),\ctrl(\tvar),\tvar)\mathrm{d}\tvar
\end{equation}
%
where $\phi$ and $\mathcal{L}$ represent the terminal and running cost respectively, and $\tfinal$ the task completion time.
Specifically, we aim to ensure that the control actions $\ctrl$ drive the system towards minimizing $S$ while rigorously maintaining system safety by preventing the state $\state$ from entering $\targetset$ even for the worst case disturbances $\dstb$. This takes the form of the following constrained optimal control problem:
%
\begin{equation}\label{eq:opt_problem}
\begin{aligned}
    \ctrl^{*}(\cdot)&=\argmin_{\ctrl(\cdot)}S(\traj_{\state,\tvar}^{\ctrlseq,\mathbf{\dstb}},\ctrl(\cdot)) \\ 
    \text{subject to:}& \\
    \dot{\state}(t) &= \dyn(\state(t), \ctrl(t), \dstb(t)), \\
    \quad \;\targetfunc(\state(\tvar))& > 0, 
    \;\ctrl(t) \in \cset, 
    \;\dstb(t) \in \dset,
   \forall t \in [\tvar, \tvar_f]
\end{aligned}
\end{equation}
%
\noindent the optimization problem defined in \eqref{eq:opt_problem} in general is non-convex and can be difficult to solve. In this work, we propose a novel MPPI method to solve this problem.