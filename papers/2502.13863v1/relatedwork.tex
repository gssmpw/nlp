\section{Related Works}
\label{sec:related-works}
{
\setlength{\tabcolsep}{3pt}
\begin{table*}
\centering
\renewcommand{\arraystretch}{0.8}
\caption{Related Positioning Datasets. MC: Monocular Camera. SC: Stereo Camera. SS: Solid-state \ac{lidar}. A: Automotive 4D \ac{radar}. N: $360^\circ$ Navtech radar. T: Tactical-grade \ac{imu}. C: Commercial-grade \ac{imu}. GT: Ground truth pose source. RTK (Real-Time Kinematic) uses a \ac{gnss} base station and differential measurements to improve the estimations. RTX uses data from a global network of tracking stations to calculate corrections.}
\label{tab:datasets}
\resizebox{\textwidth}{!}{%
\begin{tabular}{@{}llllllccc@{}}
\toprule
\textbf{Name} &
  \textbf{Camera} &
  \textbf{\ac{lidar}} &
  \textbf{\ac{radar}} &
  \textbf{\ac{imu}} &
  \textbf{GT} &
  \textbf{Indoor} &
  \textbf{Night} &
 \textbf{\ac{ros} Support} \\ \midrule
KITTI (odometry)~\cite{geiger_vision_2013} &
  4$\times$ MC &
  1$\times$ 64 ch &
  \xmark &
  1$\times$ T &
  \ac{gnss}/\ac{imu} + RTK &
  \xmark &
  \xmark &
  \xmark \\
Oxford RobotCar~\cite{maddern_1_2017} &
  1$\times$ SC + 3$\times$ MC &
  1$\times$ 4 ch + 2$\times$ 1 ch &
  \xmark &
  1$\times$ T &
  \ac{gnss}/\ac{imu} &
  \xmark &
  \cmark &
  \xmark \\
Oxford Radar RobotCar~\cite{barnes_oxford_2020} &
  1$\times$ SC + 3$\times$ MC &
  2$\times$ 32 ch + 2$\times$ 1 ch &
  1$\times$ N &
  1$\times$ T &
  \ac{gnss}/\ac{imu} + VO &
  \xmark &
  \xmark &
  \xmark \\
UrbanNav~\cite{hsu_hong_2023} &
  1$\times$ SC &
  1$\times$ 32 ch + 2$\times$ 16 ch &
  \xmark &
  1$\times$ C &
  \ac{gnss}/\ac{imu} + RTK &
  \textcolor{blue}{\textbf{!}} &
  \cmark &
  \cmark \\
Complex Urban~\cite{jeong_complex_2018} &
  \xmark &
  2$\times$ 16 ch + 2$\times$ 1 ch &
  \xmark &
  1$\times$ T + 1$\times$ C &
  \ac{gnss}/\ac{imu} &
  \textcolor{blue}{\textbf{!}} &
  \xmark &
  \cmark \\
MSC-RAD4R~\cite{choi_msc-rad4r_2023} &
  1$\times$ SC &
  1$\times$ 128 ch &
  1$\times$ A &
  1$\times$ C &
  \ac{gnss} + RTK &
  \textcolor{blue}{\textbf{!}} &
  \cmark &
  \cmark \\
MulRan~\cite{kim_mulran_2020} &
  \xmark &
  1$\times$ 64 ch &
  1$\times$ N &
  \xmark &
  SLAM &
  \xmark &
  \xmark &
  \cmark \\
K-Radar~\cite{paek_k-radar_2023} &
  4$\times$ SC &
  1$\times$ 128 ch + 1$\times$ 64 ch &
  1$\times$ A &
  2$\times$ C &
  \ac{gnss} + RTK* &
  \xmark &
  \cmark &
  \xmark \\
Boreas~\cite{burnett_boreas_2023} &
  1$\times$ MC &
  1$\times$ 128 ch &
  1$\times$ N &
  1$\times$ T &
  \ac{gnss}/\ac{imu} + RTX &
  \xmark &
  \cmark &
  \xmark \\
PixSet~\cite{deziel_pixset_2021} &
  4$\times$ MC &
  1$\times$ SS + 1$\times$ 64 ch &
  1$\times$ A &
  1$\times$ T &
  \ac{gnss}/\ac{imu} + RTK &
  \xmark &
  \cmark &
  \xmark \\
\textbf{\ac{navinst}} &
  2$\times$ SC + 1$\times$ MC &
  1$\times$ SS + 1$\times$ 16 ch &
  4$\times$ A + 1$\times$ 1D &
  4$\times$ C + 1$\times$ T &
  \acs{gnss}/\ac{imu} + RTK &
  \cmark &
  \cmark &
  \cmark \\ \bottomrule
  \multicolumn{9}{l}{\scriptsize \textcolor{blue}{\textbf{!}}~tunnels in some of the trajectories. * no GT reference is mentioned in the paper, this may be the most accurate information available.}
\end{tabular}%
}
\end{table*}
}

Several datasets have been published in recent years to enable research in positioning and navigation through the fusion of perception sensors, onboard motion sensors, and \ac{gnss}. \tablename~\ref{tab:datasets} summarizes a collection of these datasets.

One of the earliest contributions to this body of work is the KITTI odometry dataset \cite{geiger_vision_2013}. It consists of data from four monocular cameras, a 64-channel \ac{lidar}, as well as inertial and \ac{gnss} data. Additionally, all data is collected during daylight hours. More recent contributions to open navigation datasets include the Oxford RobotCar \cite{maddern_1_2017} and UrbanNav \cite{hsu_hong_2023} datasets. Both provide camera, \ac{lidar} and inertial measurement data. The Oxford RobotCar explores nighttime (darkened) driving, and UrbanNav provides \ac{ros} support to users. Neither dataset includes \ac{radar} data. The Complex Urban \cite{jeong_complex_2018} dataset provides neither \ac{radar} nor camera data but is interesting in that it provides both tactical and commercial grade \ac{imu} data and offers \ac{ros} support to facilitate its use. 

\ac{radar} technology has improved in the past decade, making it a promising sensor for positioning and navigation applications. As such, only a subset of existing datasets offer \ac{radar} data within their sensor suite. The datasets including \ac{radar} data are divided by the \ac{radar} technology used: mechanically scanning \ac{radar} or electronically scanning \ac{radar}. The Oxford Radar~\cite{barnes_oxford_2020}, MulRan~\cite{kim_mulran_2020}, and Boreas~\cite{burnett_boreas_2023} datasets provide data from a mechanically scanning $360^\circ$ \ac{radar}. The data provided by these \acp{radar} is high resolution, but the sensors are costly and do not provide Doppler velocity information \cite{kung-2021}. Other datasets employ \ac{esr} instead. A 3D \ac{esr} provides range, azimuth, and Doppler velocity measurements for target objects. A 4D \ac{esr} provides an additional elevation angle measurement. MSC-RAD4R~\cite{choi_msc-rad4r_2023} and K-Radar~\cite{paek_k-radar_2023} are interesting datasets, each providing data from a single 4D \ac{radar}. However, 4D \acp{radar} have limited fields of view, and a single \ac{radar} cannot provide a $360^\circ$ view of the vehicle's surroundings. The \ac{navinst} multisensory platform has four 4D \ac{esr}, enabling a $360^\circ$ view of the vehicle's environment and providing Doppler velocity information for all targets.  

The PixSet dataset published by Leddar Tech is among the first to provide data from a proprietary solid-state \ac{lidar} alongside a 64-channel scanning \ac{lidar} \cite{deziel_pixset_2021}. However, a single 3D \ac{radar} mounted at the front bumper of the data collection vehicle provides limited opportunities for \ac{radar}-based positioning research. Inertial data is restricted to a single tactical grade \ac{imu}. The \ac{navinst} dataset also provides a solid-state \ac{lidar} and a 16-channel mechanical \ac{lidar}, with the advantage of four 4D \ac{esr} for comparison and fusion opportunities.