To understand the effectiveness of three selected tasks, we conducted an online study where participants were asked
to play the role of an employee of a fictitious company and had to manage their virtual character's email inbox.
The inbox contained a mix of benign and phishing emails. A participant had to process benign emails and report 
phishing ones. To make the role-play as realistic as possible, we took advantage of participants' prior
knowledge of, and familiarity with, certain technologies. The study featured a familiar-looking email client (Figure~\ref{fig:platform.client}) and 
realistic-seeming emails.
Also, a participant could personalize their experience by selecting their preferred emails, services, and roles.
Details of the experimental setup are described below.

\subsection{Role-play Platform}

\paragraph{Task}
The goal for a participant was to manage their character's mailbox.
They were instructed to manage two types of emails: (1) for an email containing no links, they had to read it and mark 
it as completed, and (2) for an email with a link, a participant had to click that link to indicate that 
their character would visit the website and do what was asked.
If any email/link seemed suspicious, they were instructed to report it through a button in the email client.

Each participant had a time limit of 15 minutes to manage all emails.
For benign emails, the correct action was to either mark them as completed or click on the link, while, 
for phishing emails, the correct action was to report them.
While we are mainly interested in collecting data pertaining to emails with links, we introduced the additional 
task of asking participants to mark emails with no links as completed to make their 
experience more realistic and avoid priming them on the true nature of the study.

\paragraph{Steps}
As a setting for the email management task, we designed and developed a custom online platform.
First, participants gave their informed consent using a checkbox and button on a consent form that 
described the study as a role-play with the goal of testing a new user interface to an email client.
Next, participants filled out a pre-study questionnaire that collected demographic information and their 
familiarity with technology, phishing, and a set of popular online services: from document processing and 
sharing tools (Google Drive and Microsoft Sharepoint) to social media providers, payment platforms, and 
delivery services. These answers customized the role-play setting and 
the emails participants would receive, as discussed in Section~\ref{sec:setup.content}.

After the questionnaire, participants were introduced to their character: their role and responsibilities 
in the company, and basic information that their character would know, e.g., the format of corporate email addresses 
and names and URLs of various services used at the company, e.g., Google Drive or Microsoft Sharepoint.
Subsequently, on our custom browser-based email client mocked up to resemble Microsoft Outlook 
(Figure~\ref{fig:platform.client}), participants could manage the emails received by their character, 
besides reviewing information about the character and their role at the company.
Also, on the side of the screen, participants were always reminded of study instructions and what they had to do.
The email client featured a timer showing the remaining time to complete the task and a button to 
leave the study early if they wished to do so.

After managing the emails, participants were informed about the true nature of the study and received 
more information about phishing as well as the means to protect against it.
Finally, participants were presented with a post-study questionnaire which collected information about 
their study experience and the anti-phishing mechanisms that they encountered.

\subsection{Study Content}
\label{sec:setup.content}

\paragraph{Study emails}
We crafted a set of realistic-looking emails to be ``sent'' to the participants' characters according to their job
responsibilities. 
To enhance the study's realism and tap into participants' existing familiarity, we used real emails 
from well-known services for both legitimate and phishing emails.
By stripping away cues from the email content, we create a more realistic scenario where phishing e
mails are harder to detect, thus enabling a more accurate assessment of the proposed mechanism's effectiveness.
We created a total of 36 emails, as follows:
\begin{compactitem}
    \item 6 \textit{internal group emails}: benign text-only emails that set the context for the role-play and 
    familiarized participants with the names and email addresses of their co-workers.
    \item 9 legitimate and 9 phishing \textit{services emails}: mimicking those participants would receive 
    in their daily work routine from common services (e.g., comments on a Sharepoint document, or a FedEx tracking email).
    \item 6 legitimate and 6 phishing \textit{direct emails}: to test participants on more targeted attacks, such as spearphishing.
\end{compactitem}


\paragraph{Study URLs}
For each service used in the study, we created a set of six URLs: one legitimate URL and five phishing URLs, 
each representing a distinct type of phishing attack categorized in Section~\ref{sec:design.url}.
The legitimate URL was obtained directly from the actual service and, where necessary, included realistic path or 
query parameters, e.g., a Google Drive document URL featuring a path \texttt{/drive/folders/1t8FLJdJzDSOsMFYv} 
which incorporates the document ID.
Phishing URLs were constructed to be as similar as possible to the legitimate URL, the only difference being
the domain or the path component, Also, they were purposely designed to be confusing and hard to detect.
All URLs used in the study are shown in Appendix~\ref{sec:appendix.urls}.


\paragraph{Sampling}
\new{
Each participant received a total of 14 emails to manage: 11 legitimate and 3 phishing.
The exact emails served to each participant were customized according 
to the answers provided in the pre-study questionnaire: all {6 group emails}, 
{4 legitimate services emails} and {2 phishing services emails}, and {1 direct legitimate} and {1 direct phishing email}.}

\new{
Each benign email contained a link to its legitimate URL. For each phishing email, one of its 
five possible phishing patterns was picked at random.
Furthermore, for each URL, we randomly selected one of the three tasks they would be served upon clicking on the link 
(clicking, highlighting, or typing), with one exception: the clicking task was only served for phishing 
URLs that are {\bf not} typosquats, because they did not have any subdomains to generate the list of choices.}

\begin{figure*}[!t]
    \centering
    \begin{subfigure}{0.32\textwidth}
        \centering
        \includegraphics[width=0.9\textwidth]{figures/demographics_age_grouped.pdf}
        \caption{Age.}
        \label{fig:demographics.age}
    \end{subfigure}
    \begin{subfigure}{0.32\textwidth}
        \centering
        \includegraphics[width=0.9\textwidth]{figures/demographics_ethnicities.pdf}
        \caption{(Simplified) Ethnicity.}
        \label{fig:demographics.ethnicity}
    \end{subfigure}
    \begin{subfigure}{0.32\textwidth}
        \centering
        \includegraphics[width=0.9\textwidth]{figures/demographics_tech_use_sum.pdf}
        \caption{Tech Use Summary.}
        \label{fig:demographics.tech_use_summary}
    \end{subfigure}
    \caption{\textbf{Main demographics of the U.S. participants.} For age, we also report the distribution of the population 
    in employment in the U.S. in 2024; for ethnicity, the distribution of the general population from the U.S. 2020 census.}
    \label{fig:demographics}
\end{figure*}

\subsection{Experimental Groups}
We divided participants into 4 experimental groups according to the help and tools they received to manage the mailbox: 
a control group, two baseline approaches to compare against (see Appendix~\ref{sec:appendix.baselines} for details), 
and our tasks.

\noindent\textbf{Control}: participants did not receive any help and had to rely on their own knowledge 
and the email client interface.

\noindent\textbf{Passive} (baseline): after clicking on a link, participants were shown a warning page which 
presented the URL and asked them to confirm that they wish to visit it. This is a common approach used by several online services.

\noindent\textbf{Active} (baseline): participants were given with an activation task of dragging the pieces of the URL 
on which they just clicked to the center line and then confirm that they wish to navigate to that page.
This second baseline helps us decouple benefits of activation from those of intent checking: the task is 
designed to engage the user actively, though it cannot be solved incorrectly since the user has to notice 
whether it is a phishing URL while performing the task.
This latter aspect is only provided by our mechanism; thus, the comparison will help us isolate these two effects.

\noindent\textbf{Inspection tasks}: our novel tasks were served upon clicking a link in an email.

We decided to assign participants to the groups with an imbalance: roughly three times as many participants 
were assigned to our mechanism.
This is because we aim to study three different tasks, and thus wanted comparable group sizes for \textit{each} of them.

\subsection{Study Execution}
%
\paragraph{Participants}
We recruited participants for the main study on Prolific, a well-known and popular crowd-sourcing platform.
Participants has to be at least 18 years old, residing in the U.S., with English as their first language, 
a Prolific approval rate of at least 95\%, and at least 50 previous completed submissions on the platform.
Participants were paid to meet the highest minimum wage in the U.S., i.e., US\$~17.25/hour. 

The study did not employ attention or performance checks since they are not recommended 
and do not seem to improve data quality on the Prolific platform~\cite{tang2022replication,douglas2023data}.
Furthermore, previous work highlighted how attention checks can actively change participants' attention (rather 
than test it) and prime them to be more attentive since they are afraid of being tricked~\cite{hauser2015sa}, 
thus introducing an unacceptable bias. However, we excluded only \numExcluded{} participants due to mismatches 
between their answers in our questionnaires and the data they provided to Prolific or managing less than 
two emails before leaving the study. The median completion time for the study ranged from 9m 37s for the control 
group to 14m 02s for our tasks group; slightly more than 80\% of all participants completed the study within the estimated 20 
minutes. Furthermore, 97\% of participants fully filled out the pre-study questionnaire (18 or 19 answers), 
and 96\% the post-study questionnaire.


\paragraph{Demographics}
Key demographics of the participants can be seen in Figure~\ref{fig:demographics}.
The gender balance was: male -- \numMale, female -- \numFemale, and  other -- \numOther{}.
Figure~\ref{fig:demographics.age} shows that the participants base was skewed towards younger ages, 
in particular, 25-34 and 35-44, deviating slightly from the general population in employment in the U.S. 
and under-representing the 55-64 age group. Participants' ethnicity is shown in Figure~\ref{fig:demographics.ethnicity}: 
we observe a fairly balanced distribution compared to the general U.S. population.
Regarding education, 30\% had a high school diploma, 47\% a bachelors degree, and 17\% a masters degree.

Our initial questionnaire asked participants about the frequency of technology use in their private lives 
(computers, smartphones, instant messaging, and email) and on the job (computers for technical work, 
computers for non-technical work, e.g., data entry, and communication tools) on a scale from 1 to 5, 
where 1 is never, and 5 is all the time. Furthermore, we asked participants about their familiarity with 
email scams, the term ``phishing'', and whether they had received, or fallen for, any phishing emails in 
the past year, either in their personal lives or on the job. 

We report the sum of participants' answers related to the use of technology in their private lives 
(from 4 to 20) and in their jobs (from 3 to 15) in Figure~\ref{fig:demographics.tech_use_summary}. 
The participants are skewed towards being tech-savvy, with frequent use of electronic devices in their personal lives; 
there is a more even distribution in the use of technology on the job.
Participants reported a high perceived familiarity with email scams (75\% of participants 
reported a 4 or 5, mean 3.93) and the term phishing (similar numbers).
Participants frequently receive email scams in their personal mailboxes: 76.6\% received more than one in the last year. 
However, only 3.4\% reported falling for one, and 10.9\% almost falling for one.
There is more diversity related to phishing in the workplace: of the employed participants, 60\% experienced 
one or more phishing emails in the last three months, and 48\% received regular training in email security. 
This was similarly observed in previous studies using Prolific for security-related tasks~\cite{tang2022replication} 
that found greater technology use and more knowledge of technology among participants, as compared to the general population.

