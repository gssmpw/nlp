\subsection{Approach Limitations}
\label{sec:discussion.approach}


\paragraph{\new{Knowledge of URLs}}
\new{Inspecting the URL alone cannot help with opaque URLs (e.g., URL shorteners and redirections~\cite{gupta2014bit}) as well as legitimate services hosting malicious content (e.g., a Google Drive document containing malicious links, or a survey service asking for credentials) where the user needs to leverage knowledge and context.
Indeed, nowadays the user needs to know the correct domain for their desired service on the Internet.
For well-known websites and the ones encountered frequently, this is less of a concern than for lesser-known services: URLs pointing to not-so-well-known domains should trigger higher user scrutiny. 
Note that our approach helped heighten user attention also against cloud-based services, URLs more complicated to parse, and out-of-context URLs (all frequently used by phishers; see Section~\ref{sec:results.more_complex_urls}) and prompted users to (re)think.}

\paragraph{Practical Tradeoffs}
An inherent tradeoff between security and usability is in how our approach checks the solution of the tasks.
The ``brand'' of the service might be in a subdomain (\texttt{drive.google.com})---therefore, it makes sense for the user answer to include the subdomain, which should not be considered an error.
However, this might decrease the security of our approach for services that host user-controlled content in subdomains, e.g., consider a phishing URL leading to \texttt{drive.google.com} where the attacker hosts something impersonating \textit{another} service hosted on the same domain such as \texttt{mail.google.com}.
Requiring only the domain as an answer to the task would not protect users as we intend.
We can mitigate the first issue by allowing also subdomain(s) to be part of the answer; the second issue is more challenging to address, as it would require deciding when to require subdomains (e.g., for Google in our example) and when not to (e.g., for a service that does not host user-generated content).


\subsection{Study Limitations}

\paragraph{Generalization}
The demographics of the U.S. and German studies are skewed toward younger, more tech-savvy participants, which might not be representative of the general population.
The study had a short time restriction and was limited to one single session, therefore, how our approach would fare with repeated use must be further investigated.
In our study, we only tested a limited number of handcrafted URLs. 
We did so to ensure quality of the tested URLs, and to reduce one source of variance in our study; further, we tested all the common structures of phishing URLs in their basic structure: longer or more complex URLs were not tested but are expected to fall into one of our tested categories.

\paragraph{Roleplay setting}
Our study incorporated a roleplay setting, which raises several questions regarding participants' (i) motivations, (ii) familiarity with the role, and (iii) realism of the setting.
Regarding motivation, while we did not tie participants' rewards to their performance, some might have felt pressured to perform ``well''---however, the clear goal of the study was fully revealed only after debriefing.
Further, the incentive of participants to complete the study fast is similar to employees in a company who want to manage their email as fast as possible~\cite{greene2018user}.
Finally, we leveraged participants' previous knowledge and thus offered customized and realistic emails and roles based on their experience, and a familiar UI.

\paragraph{Biases}
Participants in different groups might have been differently biased towards the true nature of the experiment, and thus involuntarily nudged towards paying more attention.
Indeed, non-control participants saw countermeasures upon clicking on links and might have understood that the study was about correctly classifying phishing URLs: \new{this might have increased the false positive rates}.
However, this does not impact the comparisons between the baselines and our approach.
Another potential source of bias is that the legitimate URLs employed in the study were overall slightly simpler than the phishing URLs, which might have directed participants towards suspecting phishing when seeing more complicated URLs.
However, this reflects the reality of phishing URLs being more complex than legitimate ones~\cite{althobaiti2021don}.

\paragraph{Data quality}
Finally, we reflect on the quality of the data collected on the online platforms.
We decided not to employ \textit{attention checks} despite their popularity in online studies because they are not recommended in Prolific, do not seem to increase data quality~\cite{tang2022replication}, and for security-related studies they might bias participants into paying more attention than they would in real life~\cite{hauser2015sa}.
Furthermore, we observed good data quality on this platform~\cite{albert2023comparing,douglas2023data,tang2022replication} with very high completion rates, realistic solving times, and low error rates in our study.
Finally, we checked the agreement of participants' gender and age between our questionnaire and the data they provided to Prolific, and only excluded 4 due to mismatches.