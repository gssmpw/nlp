\documentclass[sigconf]{acmart}

\AtBeginDocument{
  \providecommand\BibTeX{{
    Bib\TeX}}}

\setcopyright{acmlicensed}
\copyrightyear{2025}
\acmYear{2025}
\acmDOI{XXXXXXX.XXXXXXX}

\acmConference[Conference acronym 'XX]{Make sure to enter the correct
  conference title from your rights confirmation email}{June 03--05,
  2025}{Woodstock, NY}

\acmISBN{978-1-4503-XXXX-X/2025/06}

\begin{document}

\title{Enhancing Cross-Domain Recommendations with Memory-Optimized LLM-Based User Agents}

\author{Jiahao Liu}
\authornote{Equal contribution.}
\orcid{0000-0002-5654-5902}
\author{Shengkang Gu}
\authornotemark[1]
\affiliation{
  \institution{Fudan University}
  \city{Shanghai}
  \country{China}}
\email{jiahaoliu23@m.fudan.edu.cn}
\email{gusk24@m.fudan.edu.cn}

\author{Dongsheng Li}
\orcid{0000-0003-3103-8442}
\affiliation{
  \institution{Microsoft Research Asia}
  \city{Shanghai}
  \country{China}}
\email{dongsli@microsoft.com}

\author{Guangping Zhang}
\affiliation{
  \institution{Fudan University}
  \city{Shanghai}
  \country{China}}
\email{gpzhang20@fudan.edu.cn}

\author{Mingzhe Han}
\affiliation{
  \institution{Fudan University}
  \city{Shanghai}
  \country{China}}
\email{	mzhan22@m.fudan.edu.cn}

\author{Hansu Gu}
\orcid{0000-0002-1426-3210}
\affiliation{
  \institution{Independent}
  \city{Seattle}
  \country{United States}}
\email{hansug@acm.org}

\author{Peng Zhang}
\orcid{0000-0002-9109-4625}
\affiliation{
  \institution{Fudan University}
  \city{Shanghai}
  \country{China}}
\email{zhangpeng\_@fudan.edu.cn}

\author{Tun Lu}
\orcid{0000-0002-6633-4826}
\affiliation{
  \institution{Fudan University}
  \city{Shanghai}
  \country{China}}
\email{lutun@fudan.edu.cn}

\author{Li Shang}
\orcid{0000-0003-3944-7531}
\affiliation{
  \institution{Fudan University}
  \city{Shanghai}
  \country{China}}
\email{lishang@fudan.edu.cn}

\author{Ning Gu}
\orcid{0000-0002-2915-974X}
\affiliation{
  \institution{Fudan University}
  \city{Shanghai}
  \country{China}}
\email{ninggu@fudan.edu.cn}

\renewcommand{\shortauthors}{Jiahao Liu et al.}

\begin{abstract}
Large Language Model (LLM)-based user agents have emerged as a powerful tool for improving recommender systems by simulating user interactions. However, existing methods struggle with cross-domain scenarios due to inefficient memory structures, leading to irrelevant information retention and failure to account for social influence factors such as popularity. To address these limitations, we introduce AgentCF++, a novel framework featuring a dual-layer memory architecture and a two-step fusion mechanism to filter domain-specific preferences effectively. Additionally, we propose interest groups with shared memory, allowing the model to capture the impact of popularity trends on users with similar interests. Through extensive experiments on multiple cross-domain datasets, AgentCF++ demonstrates superior performance over baseline models, highlighting its effectiveness in refining user behavior simulation for recommender systems. Our code is available at \url{https://anonymous.4open.science/r/AgentCF-plus}.
\end{abstract}

\begin{CCSXML}
<ccs2012>
   <concept>
       <concept_id>10002951.10003317.10003347.10003350</concept_id>
       <concept_desc>Information systems~Recommender systems</concept_desc>
       <concept_significance>500</concept_significance>
       </concept>
 </ccs2012>
\end{CCSXML}

\ccsdesc[500]{Information systems~Recommender systems}

\keywords{LLM-based agents, user behavior simulation, recommendations}

\maketitle

\section{Introduction}
\begin{figure*}[t]
  \centering
  \includegraphics[width=0.97\linewidth]{method.pdf}
  \caption{(a) The memory propagation process in AgentCF. (b) An example illustrating AgentCF's limitations in modeling user behavior influenced by popularity factors. (c) Illustration of why modeling popularity factors is necessary for accurately simulating user behavior. (d) Overview of the proposed AgentCF++ model, highlighting its improvements over AgentCF.}
  \label{fig:i9cm}
\end{figure*}

Recommender systems play a pivotal role in the dissemination of information today~\cite{ricci2010introduction,xia2022fire,liu2023personalized,liu2023autoseqrec,liu2023recommendation,liu2023triple,liu2024filtering,liu2022parameter}.
However, their development is hindered by challenges in effectively understanding user behavior~\cite{shani2011evaluating}.
One promising approach to overcoming these challenges is the reliable simulation of user interaction behavior in a controlled, privacy-preserving manner, thereby improving recommender systems by offering insights into user preferences and system performance~\cite{zhang2024simulating}.
Recent advancements in large language models (LLMs), renowned for their capabilities in understanding, reasoning, and generating content~\cite{zhao2023survey}, have inspired significant efforts to develop LLM-based agents~\cite{wang2024survey}.
These agents often incorporate memory modules~\cite{zhang2024survey}, utilize external tools~\cite{yuan2024easytool}, and engage in advanced reasoning~\cite{huang2024understanding}, enabling them to exhibit emergent human-like behaviors~\cite{park2023generative}.
In this context, researchers have begun investigating the potential of LLM-based agents to simulate user interaction behavior in the field of recommender systems~\cite{wang2024user,zhang2024generative,zhang2024agentcf,shu2024rah,cai2024flow,zhang2024llm}.

Accurately representing user preferences is crucial for a user agent to realistically simulate user behavior.
While various terms are used across studies, this paper uniformly refers to these preferences as being stored in \textit{memory}.
In real-world scenarios, users' interactions with recommender systems often exhibit cross-domain characteristics~\cite{zang2022survey}.
Additionally, individual behaviors are frequently influenced by those of others~\cite{huang2006herding}.
For instance, popularity-related factors suggest that even in the absence of explicit social networks, such influences can be inferred from interaction graphs and propagated through interaction paths~\cite{zhang2021cope}.
However, the current memory design causes the user agent to exhibit two significant limitations:
\textbf{First}, user preferences from multiple domains are mixed into a single memory.
However, only a portion of the preferences is relevant to decision-making in the target domain, leading the user agent to process a considerable amount of irrelevant information.
\textbf{Second}, memory construction relies exclusively on individual user interactions, neglecting how external factors, such as popularity influences, shape user preferences.

In this paper, we present \textbf{AgentCF++}, an enhanced version of AgentCF~\cite{zhang2024agentcf}.
Our approach introduces a \textit{dual-layer memory architecture} comprising \textit{domain-separated memory} and \textit{domain-fused memory}, designed to prioritize target-domain-relevant information in decision-making for cross-domain scenarios.
To refine this architecture, we propose an attention-inspired \textit{two-step fusion mechanism}.
This mechanism first identifies valuable cross-domain knowledge pertinent to the target domain and then integrates these critical preferences.
Furthermore, we introduce the concept of \textit{interest groups} and propose a \textit{group-shared memory mechanism} to facilitate the transfer of popularity effects within the same interest group.
By utilizing interest groups, we ensure that a userâ€™s behavior impacts only those with similar interests, effectively preventing the spread of popularity effects to unrelated users.
Our experimental results on five cross-domain datasets demonstrate the effectiveness of the proposed modules.
Additionally, several case studies underscore the enhanced capabilities of AgentCF++.

\section{Preliminaries}

\subsection{AgentCF}
Unlike previous studies~\cite{wang2024user,zhang2024generative,shu2024rah,cai2024flow,zhang2024llm} that consider only users as agents, AgentCF~\cite{zhang2024agentcf} treats both users and items as agents.
Each user agent is equipped with a memory to store individual preferences, while each item agent maintains a memory to track the interest levels of users with varying preferences towards it.
At each step, leveraging LLMs for decision-making and reflection, these agents autonomously interact, compare their actions with real-world data, and collaboratively adjust their memories to better align with observed behaviors.
As illustrated in Figure~\ref{fig:i9cm}(a), user and item memories gradually propagate over time through interactions, embodying the principles of collaborative filtering.

\subsection{Limitations of AgentCF}
AgentCF employs a single memory for each user agent and item agent.
In cross-domain scenarios, the propagation process integrates information from multiple domains into the memory of each user and item.
On one hand, the mixing of cross-domain preferences in the user agent may introduce noise, thereby complicating decision-making on target domain.
On the other hand, such intermingling may cause the item agent to lose its original domain characteristics.
We illustrate this with a case study in Section~\ref{sec:9fmd}.

Additionally, while AgentCF employs collaborative filtering to capture the influence of others' interactions, memory updates for user and item agents occur only during direct interactions, limiting its capacity to comprehensively model how popularity factors shape user behavior.
To illustrate this limitation, consider the following example.
Figure \ref{fig:i9cm}(b) visualizes user-item interaction dynamics using a timestamped bipartite graph.
At $t_1$, Alice, Bob, and Carl purchase outdoor activity items; at $t_2$, Bob and Carl buy rain gear; at $t_3$, Carl purchases camping equipment.
Under the AgentCF framework, Alice, who ceases interactions after $t_1$, is still assumed to engage in outdoor activities, despite worsening weather conditions at $t_2$.
Similarly, Bob shows no interest at $t_3$, failing to account for the improved weather conditions.
This indicates that, within the AgentCF framework, users' memories remain static in the absence of additional interactions.
In practice, however, even without further direct participation, Alice might infer the weather changes at $t_2$ and $t_3$ by observing Bob's and Carl's actions.
This underscores the need for user agents to update their memories not only through their own interactions with item agents but also in response to interactions by other user agents.
In essence, a userâ€™s memory should evolve dynamically, even without direct participationâ€”a critical capability currently missing in the AgentCF framework.

\textbf{Clarification.}
As shown in Figure \ref{fig:i9cm}(c), user behavior ($Y$) is influenced by both user preferences ($X$) and popularity factors ($P$).  
Unlike debiasing approaches, which seek to model user preferences by removing the effects of popularity factors~\cite{ge2024survey,chen2023bias}, user behavior simulation aims to model user behavior.  
Therefore, in user behavior simulation, popularity factors are not a nuisance to be mitigated but a critical factor to be explicitly modeled.

\section{AgentCF++}
Similar to AgentCF, AgentCF++ simulates interactions between user agents and item agents from multiple domains and performs reflection during this process to update the memories of both sides, thereby aligning with user behavior.

\subsection{Memory Architecture}
AgentCF++ employs a similar memory architecture to AgentCF for the item agent, using a single memory to record the interest levels of users with various preferences towards it.
Initially, the item's memory is seeded with its side information.
However, AgentCF++ has meticulously designed the memory architecture for the user agent to enhance its functionality.

Firstly, each user agent in AgentCF++ is equipped with a \textbf{dual-layer memory architecture}.
Specifically, each user agent maintains two types of memory for \textbf{each domain}:
(1) \textbf{Domain-separated memory} retains the userâ€™s preferences specific to a single domain.  
(2) \textbf{Domain-fused memory} also stores preferences within a particular domain but integrates domain-separated memories from other domains.
Initially, both memories are empty.

Additionally, each user agent is assigned to several \textbf{interest groups} through the following process:
(1) \textit{Building user-tag relationships}: The user agentâ€™s domain-fused memory is processed by an LLM to derive a set of interest tags representing the userâ€™s preferences.
(2) \textit{Merging synonymous tags}: The LLM transforms all tags into embedding vectors, which are then grouped into clusters based on semantic similarity using a K-means clustering algorithm.
Each cluster corresponds to a specific area of interest, encompassing tags with high semantic similarity.
(3) \textit{Refining interest groups}: The LLM synthesizes the tags in each cluster to generate a consolidated interest group name.
Ultimately, only the largest few interest groups are retained, collectively covering the majority of the user's interests.
AgentCF++ periodically re-segments the interest groups to ensure they reflect any updates in user preferences.

Each interest group is equipped with a \textbf{group-shared memory}, enabling all user agents within the group to collaboratively access shared information.
The shared memory is of fixed size, designed to store the recent interaction history of its associated users.

\begin{table}\footnotesize
  \caption{Cross-domain dataset construction.}
  \label{tab:93md}
    \begin{tabular}{c|c}
    \hline
    Cross-domain Dataset & Source Datasets                 \\ \hline
    Cross-1              & CDs \& Movies \& Games          \\
    Cross-2              & Books \& Movies \& Games        \\
    Cross-3              & Books \& CDs \& Games           \\
    Cross-4              & Books \& CDs \& Movies          \\
    Cross-5              & Books \& CDs \& Movies \& Games \\ \hline
    \end{tabular}
\end{table}

\subsection{Inference Phase}
We assume that the current interaction is $(u, i, d)$, where $u$ represents a user agent, $i$ represents an item agent, and $d$ denotes the domain of $i$.
First, a negative sample $j$ is selected from the domain $d$.
Then, $u$ receives the memories of $i$ and $j$ and is tasked with identifying the positive sample while explaining its reasoning.
To mitigate potential position bias, in which LLMs tend to favor earlier options, $j$ is deliberately placed before $i$.
Note that $u$'s decisions depend simultaneously on both domain-separated memory and domain-fused memory within domain $d$, as well as on the group-shared memories it can access.

\textbf{Discussion.}
The dual-layer memory architecture includes a domain-separated memory and a domain-fused memory corresponding to each domain.  
With this memory enhancement, only information relevant to the target domain is utilized during decision-making, effectively reducing noise in cross-domain scenarios.
On the other hand, the sharing mechanism allows user behavior to influence related users without directly updating their individual memories, incorporating the influence of popularity factors into preferences modeling.
For instance, in the scenario depicted in Figure~\ref{fig:i9cm}(b), Bob and Carl insert the behavior of purchasing rain gear into the memory shared with Alice at $t_2$.
At $t_3$, Carl adds the behavior of purchasing camping gear into the memory shared with both Alice and Carl.
This results in Aliceâ€™s willingness to go outdoors decreasing at $t_2$ and increasing at time $t_3$, reflecting real-world patterns where user behavior is influenced by trends and popularity factors.
Note that we segment users based on their interests rather than the similarity of their interaction history, to more precisely identify populations influenced by popularity factors.

\subsection{Update Phase}
The memories are updated using a reflection mechanism~\cite{shinn2024reflexion,madaan2024self,pan2023automatically}.
Specifically:
(1) According to the results of the inference phase, $u$ updates its domain-separated memory in domain $d$ using the memories of $i$ and $j$.
This step enables $u$ to learn what it like and dislike from the latest interaction.
(2) We propose a \textbf{two-step fusion mechanism} to effectively integrate information from multiple domains.
Firstly, $u$ extracts preferences related to the target domain $d$ from domain-separated memories of other domains.
Then, $u$ updates its domain-fused memory in domain $d$ based on the extracted preferences.
(3) $i$ and $j$ update their item memories using $u$'s domain-fused memory in domain $d$. 
In this step, $i$ learns which user preferences it appeals to, while $j$ learns which user preferences it does not appeal to.

\textbf{Discussion.}
Figure~\ref{fig:i9cm}(d) illustrates the process of update phase.
The two-step fusion mechanism implicitly incorporates the idea of the attention mechanism, ensuring that the domain-fused memory effectively integrates preferences from other domains while retaining only preferences relevant to the corresponding domain.
Specifically, in the first step, only preferences related to the target domain are extracted, akin to the computation of attention scores.  
In the second step, the extracted preferences from different domains are integrated, akin to the weighted aggregation process in the attention mechanism.
Additionally, with the aid of the reflection mechanism, the cyclic updates of item memory, domain-separated memory, and domain-fused memory enable all memories to achieve self-improvement.

\section{Experiments}

\subsection{Settings}

\subsubsection{Datasets}
We experimented with the Amazon review dataset~\cite{hou2024bridging}.
As summarized in Table~\ref{tab:93md}, we constructed cross-domain datasets \textit{Cross-1}---\textit{Cross-5} by combining datasets from the Books, CDs, Movies, and Games domains.
Then, we retained interaction records with ratings $\geq 4$ and timestamps spanning six months, from October 2021 to March 2022.
We further filtered the data to include only records of users who interacted across multiple domains and had $\ge$ 10 total interactions.
Following AgentCF, we randomly sampled 100 users to minimize API call expenses.
Next, we sorted these interaction records chronologically and split them into training, validation, and test sets with an 8:1:1 ratio.

\subsubsection{Evaluation}
For each ground truth item, we randomly sample 9 items from the same domain that the user has not interacted with to construct the candidate set.
The user agent is then tasked with ranking these items, and the ranking performance is measured using NDCG and MRR.
We report the average results over 5 runs.

\subsubsection{Baselines}
We used two traditional recommendation models, BPR-MF~\cite{rendle2012bpr} and SASRec~\cite{kang2018self}, as well as four training-free methods, Pop, LLMSeqSim~\cite{harte2023leveraging}, LLMRank~\cite{hou2024large}, and AgentCF~\cite{zhang2024agentcf}, as baseline methods for comparison.
Specifically, Pop ranks candidates based on item popularity, LLMSeqSim evaluates candidates by measuring their similarity to the user's interaction history, and LLMRank employs an LLM as a zero-shot ranker to prioritize candidate items.

We compared solely with AgentCF, omitting other LLM-based user agent methods.
Our goal is to demonstrate that the proposed module enhances AgentCF.
Performance differences with other methods may stem from differing agent construction paradigms, making it challenging to attribute improvements directly to the proposed module.
On the other hand, they all construct memory directly through the user's interaction history, which can, to some extent, be considered equivalent to LLMRank.

We also designed three ablation variants for AgentCF++:
(1) \textit{AgentCF + dual}: Extends AgentCF with only the dual-layer memory architecture.
(2) \textit{AgentCF + shared}: Extends AgentCF with only interest groups and group-shared memory.
(3) \textit{AgentCF++ w/o group}: Users are grouped based on their full interaction history rather than their interests.
The other components, including treating users as agents, treating items as agents, the automatic interaction process, and the reflection mechanism, have already been validated as effective by AgentCF.
Therefore, these components were not included in the ablation study.

\subsection{Overall Performance}
As shown in Table~\ref{tab:d9jv}, on cross-domain datasets, AgentCF achieves comparable performance to training-free methods such as LLMRank but fails to surpass traditional recommendation models like SASRec.
This suggests that traditional models inherently capture popularity factors and cross-domain collaborative information through their training mechanisms, giving them a clear advantage over LLM-based user agents in predicting user behavior.
Encouragingly, the proposed AgentCF++ consistently outperforms both its ablation variants and all baselines. Moreover, the ablation variants consistently outperform AgentCF, further validating the effectiveness of the proposed modules.
Notably, \textit{AgentCF++ w/o group} performs not only worse than AgentCF++ but also worse than \textit{AgentCF + dual}, further underscoring the importance of dividing users into interest groups.
This indicates that assigning users to groups based on their full interaction history is too coarse, allowing the popularity factor to influence unrelated users, introducing noise, and ultimately reducing accuracy.

\begin{table} \footnotesize
  \caption{Overall performance. Due to space constraints, we only report MRR results. NDCG results, available in the repository, lead to consistent conclusions.}
  \label{tab:d9jv}
\begin{tabular}{c|ccccc}
\hline
Method                       & Cross-1         & Cross-2         & Cross-3         & Cross-4         & Cross-5         \\ \hline
BPR-MF                       & 0.2949          & 0.2959          & 0.3114          & 0.3012          & 0.3127          \\
SASRec                       & 0.3463          & 0.3154          & 0.3828          & 0.3118          & 0.3687          \\ \hline
Pop                          & 0.2589          & 0.2817          & 0.3094          & 0.2954          & 0.3089          \\
LLMSeqSim                    & 0.2646          & 0.2549          & 0.3101          & 0.2959          & 0.3124          \\
LLMRank                      & 0.3268          & 0.2730          & 0.3106          & 0.2970          & 0.3308          \\
AgentCF                      & 0.3284          & 0.2681          & 0.3114          & 0.3032          & 0.3480          \\
\textbf{AgentCF++}           & \textbf{0.3537} & \textbf{0.3176} & \textbf{0.3989} & \textbf{0.3321} & \textbf{0.3837} \\ \hline
\textit{AgentCF + dual}      & 0.3495          & 0.2962          & 0.3581          & 0.3139          & 0.3581          \\
\textit{AgentCF + shared}    & 0.3488          & 0.2777          & 0.3190          & 0.3147          & 0.3689          \\
\textit{AgentCF++ w/o group} & 0.3415          & 0.2724          & 0.3181          & 0.3126          & 0.3549          \\ \hline
\end{tabular}
\end{table}

\subsection{Case Studies}\label{sec:9fmd}

\subsubsection{Memory}
Figure~\ref{fig:93mi} (a) and (c) illustrate the memory of AgentCF++ and AgentCF in the Game \& Book domains, respectively.
It is evident that the user agent in AgentCF intermixes preferences from different domains, with its memory containing both game-related preferences (e.g., role-playing) and book-related preferences (e.g., economics).
As memory propagates, this mixing effect further causes its item agent to gradually lose domain-specific information.

In contrast, AgentCF++ separates preferences by domain and fuse information via a two-step fusion mechanism.
First, as shown in Figure~\ref{fig:93mi} (b), this mechanism extracts target-domain preferences from other domains based on cross-domain mappings (e.g., role-playing and open-world in the game domain correspond to fantasy and adventure in the book domain).
Then, the mechanism fuses the extracted preferences to ensure broad coverage across domains while maintaining domain specificity.
This mechanism ensures that the item agent retains information relevant to its domain.

\subsubsection{Interest Group}
Figure~\ref{fig:93mi} (d) illustrates two interest groups along with their agenda items, each named to represent its focus.

\section{Related Work}
LLM-based agents in recommender systems can be broadly divided into two categories.
The first category focuses on \textbf{recommendation agents} that leverage LLMs to generate or improve recommendations~\cite{shi2024large,zhang2023recommendation,huang2023recommender,wang2023recmind,wang2024multi,zhao2024let,zhang2024prospect}.
% InteRecAgent~\cite{huang2023recommender} uses LLMs to transform traditional recommender systems into interactive systems with natural language interfaces.
% RecMind~\cite{wang2023recmind} improves recommendations by combining planning, external knowledge, user data, and an innovative self-inspiring algorithm.
% MACRec~\cite{wang2024multi} enhances recommender systems through multi-agent collaboration.
% ToolRec~\cite{zhao2024let} leverages LLMs as surrogate users to guide recommendations and integrate external tools, ensuring better alignment with users' preferences.
% Rec4Agentverse~\cite{zhang2024prospect} pioneers a new recommendation paradigm by treating the recommendation agent itself as the item to be recommended.
%
The second category explores \textbf{user agents} that leverage LLMs to simulate user behavior.
While some studies focus on simulating user dialogues in conversational recommendation~\cite{zhu2024llm,zhu2024reliable,kim2024stop,friedman2023leveraging,wang2023rethinking}, our emphasis is on simulating user interaction behavior.
RecAgent~\cite{wang2024user} and Agent4Rec~\cite{zhang2024generative} employ LLM-based agents, incorporating user profiles, memory, and action modules, to simulate interactions with recommender systems.
RAH~\cite{shu2024rah} places LLM-based multi-agents between users and recommender systems, serving both as recommendation agents and as proxies for user interactions.
FLOW~\cite{cai2024flow} facilitates collaboration between recommendation agents and user agents by establishing a feedback loop.
\citet{zhang2024llm} integrate explicit user preferences, LLM-driven sentiment analysis, a human engagement model, and a statistical framework to robustly simulate user interactions.
AgentCF~\cite{zhang2024agentcf} proposes a novel approach, conceptualizing users and items as agents and employing a collaborative learning strategy to optimize them simultaneously.

Several studies have highlighted LLMs' generalization capabilities in \textbf{cross-domain recommendation}~\cite{bao2023tallrec,bai2024aligning,shen2024exploring,vajjala2024cross,petruzzelli2024instructing,tang2023one} and explored \textbf{popularity bias} in LLM-based recommenders~\cite{jiang2024item,lichtenberg2024large,gao2024sprec,ortega2024evaluating,deldjoo2024understanding}.
These works mainly use LLMs as recommenders, not for simulating user behavior.
Importantly, we emphasize the need to explicitly model popularity factors when simulating user behavior, rather than merely reducing their influence.

\begin{figure}[t]
  \centering
  \includegraphics[width=\linewidth]{case.pdf}
  \caption{Case Studies.}
  \label{fig:93mi}
\end{figure}

\section{Conclusions}
We propose AgentCF++, which consists of:
(1) a dual-layer memory architecture and a two-step fusion mechanism that allow the user agent to avoid introducing irrelevant in cross-domain scenarios;
(2) the concept of interest groups and a shared memory mechanism that captures the influence of popularity among users with similar interests.
Comprehensive experiments demonstrate the effectiveness of AgentCF++.
In the future, we aim to adapt these designs to other LLM-based user agent frameworks.

\begin{acks}
\end{acks}

\balance

\bibliographystyle{ACM-Reference-Format}
\bibliography{main}

\appendix

\end{document}
