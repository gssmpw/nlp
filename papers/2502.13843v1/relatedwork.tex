\section{Related Work}
LLM-based agents in recommender systems can be broadly divided into two categories.
The first category focuses on \textbf{recommendation agents} that leverage LLMs to generate or improve recommendations~\cite{shi2024large,zhang2023recommendation,huang2023recommender,wang2023recmind,wang2024multi,zhao2024let,zhang2024prospect}.
% InteRecAgent~\cite{huang2023recommender} uses LLMs to transform traditional recommender systems into interactive systems with natural language interfaces.
% RecMind~\cite{wang2023recmind} improves recommendations by combining planning, external knowledge, user data, and an innovative self-inspiring algorithm.
% MACRec~\cite{wang2024multi} enhances recommender systems through multi-agent collaboration.
% ToolRec~\cite{zhao2024let} leverages LLMs as surrogate users to guide recommendations and integrate external tools, ensuring better alignment with users' preferences.
% Rec4Agentverse~\cite{zhang2024prospect} pioneers a new recommendation paradigm by treating the recommendation agent itself as the item to be recommended.
%
The second category explores \textbf{user agents} that leverage LLMs to simulate user behavior.
While some studies focus on simulating user dialogues in conversational recommendation~\cite{zhu2024llm,zhu2024reliable,kim2024stop,friedman2023leveraging,wang2023rethinking}, our emphasis is on simulating user interaction behavior.
RecAgent~\cite{wang2024user} and Agent4Rec~\cite{zhang2024generative} employ LLM-based agents, incorporating user profiles, memory, and action modules, to simulate interactions with recommender systems.
RAH~\cite{shu2024rah} places LLM-based multi-agents between users and recommender systems, serving both as recommendation agents and as proxies for user interactions.
FLOW~\cite{cai2024flow} facilitates collaboration between recommendation agents and user agents by establishing a feedback loop.
\citet{zhang2024llm} integrate explicit user preferences, LLM-driven sentiment analysis, a human engagement model, and a statistical framework to robustly simulate user interactions.
AgentCF~\cite{zhang2024agentcf} proposes a novel approach, conceptualizing users and items as agents and employing a collaborative learning strategy to optimize them simultaneously.

Several studies have highlighted LLMs' generalization capabilities in \textbf{cross-domain recommendation}~\cite{bao2023tallrec,bai2024aligning,shen2024exploring,vajjala2024cross,petruzzelli2024instructing,tang2023one} and explored \textbf{popularity bias} in LLM-based recommenders~\cite{jiang2024item,lichtenberg2024large,gao2024sprec,ortega2024evaluating,deldjoo2024understanding}.
These works mainly use LLMs as recommenders, not for simulating user behavior.
Importantly, we emphasize the need to explicitly model popularity factors when simulating user behavior, rather than merely reducing their influence.

\begin{figure}[t]
  \centering
  \includegraphics[width=\linewidth]{case.pdf}
  \caption{Case Studies.}
  \label{fig:93mi}
\end{figure}