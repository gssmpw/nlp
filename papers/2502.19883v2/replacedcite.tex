\section{Related Work}
%-----------------------------------------------------
\subsection{Jailbreak Attacks}
Jailbreak attacks, which transform harmful queries like ``How to make a bomb'' into more sophisticated prompts to deceive target models to generate toxic output, can be mainly classified into two categories: white-box methods and black-box methods. 

White-box methods generally rely on access to the internal states of LLMs to design attack strategies. 
These methods generally use gradients and logits of target LLMs as loss functions to optimize adversarial suffixes appended to malicious questions____, or manipulate the output logits to enforce target LLMs to generate affirmative responses____.
However, white-box methods tend to generate irregular prompts that are easily detectable and cannot be optimized directly on black-box models like ChatGPT.

In contrast, black-box methods construct readable prompts in different ways and validate their effectiveness based on the responses of the target LLMs. 
Some studies employ heuristic strategies to rewrite malicious questions in other formats such as ASCII format____, code format____, encrypted format____ and low-resource languages____, exploiting the insufficient safety alignment of target LLMs in these formats to bypass the defense mechanism.
Another line of research is to instruct an advanced LLM like GPT-4 to optimize jailbreak prompts by incorporating iterative refinement____, genetic algorithms____ and psychological expertise____, or fine-tune another LLM with successful jailbreak templates to serve as an attacker to generate jailbreak prompts automatically____.
Compared with white-box methods, black-box methods can be applied to most models. For this reason, black-box methods are widely used in empirical experiments to evaluate the safety of LLMs.

To mitigate threats caused by jailbreak attacks, different defense techniques are proposed to ensure the security of LLMs. One line of work addresses the issue by detecting____ or perturbing____ the jailbreak prompts to reduce the toxicity of the input, while another line of work directly enhances the robustness of LLMs by supervised fine-tuning____ or reinforcement learning from human feedback____. 

\subsection{Small Language Models}
Similar to LLMs, SLMs are typically built upon decoder-only architectures, while they show diversity in implementation details such as the type of attention heads, layer numbers, dimension sizes, activation functions, and so on. 

\begin{figure*}[t]
    \centering
    \includegraphics[width=1.0\linewidth]{figs/Overall.pdf}
    \caption{The family tree of the target SLMs we evaluate in our paper. The solid line represents the model is belonging to a certain family, while the dashed line indicates that the model is derived from that family with certain SLM technology.}
    \label{fig:overall}
\end{figure*}


To achieve competitive performance within the limited scale of SLMs, different model compression techniques are adopted to construct lightweight architectures efficiently. 
For instance, MobilLLaMA____ and MobileLLM____ introduce a parameter-sharing scheme in embedding blocks and attention head blocks to reduce the cost of GPU memory. 
TinyLLaMA____ optimizes memory load with the FlashAttention technique____, which introduces an IO-aware attention algorithm to reduce the budget of high bandwidth memory. 
Quantization techniques, such as GPTQ____ and AWQ____, can also effectively reduce memory loads by compressing the size parameters from 16 bits to 8 bits or even 4 bits.  
In model collections such as Llama 3____, Qwen____, and MiniCPM____, SLMs are generally designed and pre-trained following LLMs in the same family. 
Additionally, during the training phase, knowledge distillation techniques are widely used to derive performance from teacher LLMs to student SLMs, as models in the same family generally share similar tokenizers and architecture.

Recent research has demonstrated that SLMs can achieve comparable performance in some reasoning tasks, and can even outperform LLMs in specific scenarios____. 
Our study fills a gap in evaluating the security of SLMs from another perspective. In the following sections, we will demonstrate the security differences between various SLMs and delve into their underlying causes.

%-----------------------------------------------------