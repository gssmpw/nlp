[
  {
    "index": 0,
    "papers": [
      {
        "key": "ZWKF23",
        "author": "Zou, Andy and Wang, Zifan and Carlini, Nicholas and Nasr, Milad and Kolter, J Zico and Fredrikson, Matt",
        "title": "Universal and transferable adversarial attacks on aligned language models"
      },
      {
        "key": "JDRS23",
        "author": "Jones, Erik and Dragan, Anca and Raghunathan, Aditi and Steinhardt, Jacob",
        "title": "Automatically auditing large language models via discrete optimization"
      },
      {
        "key": "ZZAWBWHNS23",
        "author": "Zhu, Sicheng and Zhang, Ruiyi and An, Bang and Wu, Gang and Barrow, Joe and Wang, Zichao and Huang, Furong and Nenkova, Ani and Sun, Tong",
        "title": "Autodan: Automatic and interpretable adversarial attacks on large language models"
      },
      {
        "key": "andriushchenko2024jailbreaking",
        "author": "Andriushchenko, Maksym and Croce, Francesco and Flammarion, Nicolas",
        "title": "Jailbreaking leading safety-aligned llms with simple adaptive attacks"
      },
      {
        "key": "geisler2024attacking",
        "author": "Geisler, Simon and Wollschl{\\\"a}ger, Tom and Abdalla, MHI and Gasteiger, Johannes and G{\\\"u}nnemann, Stephan",
        "title": "Attacking large language models with projected gradient descent"
      },
      {
        "key": "mangaokar2024prp",
        "author": "Neal Mangaokar and\nAshish Hooda and\nJihye Choi and\nShreyas Chandrashekaran and\nKassem Fawaz and\nSomesh Jha and\nAtul Prakash",
        "title": "{PRP:} Propagating Universal Perturbations to Attack Large Language\nModel Guard-Rails"
      }
    ]
  },
  {
    "index": 1,
    "papers": [
      {
        "key": "HGXLC24",
        "author": "Yangsibo Huang and\nSamyak Gupta and\nMengzhou Xia and\nKai Li and\nDanqi Chen",
        "title": "Catastrophic Jailbreak of Open-source LLMs via Exploiting Generation"
      },
      {
        "key": "zhang2024jailbreak",
        "author": "Zhang, Hangfan and Guo, Zhimeng and Zhu, Huaisheng and Cao, Bochuan and Lin, Lu and Jia, Jinyuan and Chen, Jinghui and Wu, Dinghao",
        "title": "Jailbreak open-sourced large language models via enforced decoding"
      }
    ]
  },
  {
    "index": 2,
    "papers": [
      {
        "key": "jiang2024artprompt",
        "author": "Fengqing Jiang and\nZhangchen Xu and\nLuyao Niu and\nZhen Xiang and\nBhaskar Ramasubramanian and\nBo Li and\nRadha Poovendran",
        "title": "ArtPrompt: {ASCII} Art-based Jailbreak Attacks against Aligned LLMs"
      }
    ]
  },
  {
    "index": 3,
    "papers": [
      {
        "key": "KLSGZH23",
        "author": "Kang, Daniel and Li, Xuechen and Stoica, Ion and Guestrin, Carlos and Zaharia, Matei and Hashimoto, Tatsunori",
        "title": "Exploiting programmatic behavior of llms: Dual-use through standard security attacks"
      },
      {
        "key": "lv2024codechameleon",
        "author": "Lv, Huijie and Wang, Xiao and Zhang, Yuansen and Huang, Caishuang and Dou, Shihan and Ye, Junjie and Gui, Tao and Zhang, Qi and Huang, Xuanjing",
        "title": "Codechameleon: Personalized encryption framework for jailbreaking large language models"
      }
    ]
  },
  {
    "index": 4,
    "papers": [
      {
        "key": "YJWHHST24",
        "author": "Yuan, Youliang and Jiao, Wenxiang and Wang, Wenxuan and Huang, Jen-tse and He, Pinjia and Shi, Shuming and Tu, Zhaopeng",
        "title": "GPT-4 Is Too Smart To Be Safe: Stealthy Chat with LLMs via Cipher"
      },
      {
        "key": "liu2024making",
        "author": "Liu, Tong and Zhang, Yingjie and Zhao, Zhe and Dong, Yinpeng and Meng, Guozhu and Chen, Kai",
        "title": "Making them ask and answer: Jailbreaking large language models in few queries via disguise and reconstruction"
      }
    ]
  },
  {
    "index": 5,
    "papers": [
      {
        "key": "DZPB24",
        "author": "Deng, Yue and Zhang, Wenxuan and Pan, Sinno Jialin and Bing, Lidong",
        "title": "Multilingual Jailbreak Challenges in Large Language Models"
      }
    ]
  },
  {
    "index": 6,
    "papers": [
      {
        "key": "jin2024guard",
        "author": "Jin, Haibo and Chen, Ruoxi and Zhou, Andy and Zhang, Yang and Wang, Haohan",
        "title": "GUARD: Role-playing to Generate Natural-language Jailbreakings to Test Guideline Adherence of Large Language Models"
      }
    ]
  },
  {
    "index": 7,
    "papers": [
      {
        "key": "LXCX23",
        "author": "Liu, Xiaogeng and Xu, Nan and Chen, Muhao and Xiao, Chaowei",
        "title": "AutoDAN: Generating Stealthy Jailbreak Prompts on Aligned Large Language Models"
      }
    ]
  },
  {
    "index": 8,
    "papers": [
      {
        "key": "ZLZYJS24",
        "author": "Yi Zeng and\nHongpeng Lin and\nJingwen Zhang and\nDiyi Yang and\nRuoxi Jia and\nWeiyan Shi",
        "title": "How Johnny Can Persuade LLMs to Jailbreak Them: Rethinking Persuasion to Challenge {AI} Safety by Humanizing LLMs"
      }
    ]
  },
  {
    "index": 9,
    "papers": [
      {
        "key": "deng2024masterkey",
        "author": "Deng, Gelei and Liu, Yi and Li, Yuekang and Wang, Kailong and Zhang, Ying and Li, Zefeng and Wang, Haoyu and Zhang, Tianwei and Liu, Yang",
        "title": "Masterkey: Automated jailbreaking of large language model chatbots"
      },
      {
        "key": "ge2023mart",
        "author": "Suyu Ge and\nChunting Zhou and\nRui Hou and\nMadian Khabsa and\nYi{-}Chia Wang and\nQifan Wang and\nJiawei Han and\nYuning Mao",
        "title": "{MART:} Improving {LLM} Safety with Multi-round Automatic Red-Teaming"
      }
    ]
  },
  {
    "index": 10,
    "papers": [
      {
        "key": "inan2023llama",
        "author": "Inan, Hakan and Upasani, Kartikeya and Chi, Jianfeng and Rungta, Rashi and Iyer, Krithika and Mao, Yuning and Tontchev, Michael and Hu, Qing and Fuller, Brian and Testuggine, Davide and others",
        "title": "Llama guard: Llm-based input-output safeguard for human-ai conversations"
      }
    ]
  },
  {
    "index": 11,
    "papers": [
      {
        "key": "RWHP23",
        "author": "Robey, Alexander and Wong, Eric and Hassani, Hamed and Pappas, George J",
        "title": "Smoothllm: Defending large language models against jailbreaking attacks"
      }
    ]
  },
  {
    "index": 12,
    "papers": [
      {
        "key": "BSARJHZ24",
        "author": "Bianchi, Federico and Suzgun, Mirac and Attanasio, Giuseppe and Rottger, Paul and Jurafsky, Dan and Hashimoto, Tatsunori and Zou, James",
        "title": "Safety-Tuned LLaMAs: Lessons From Improving the Safety of Large Language Models that Follow Instructions"
      }
    ]
  },
  {
    "index": 13,
    "papers": [
      {
        "key": "Ouayng22",
        "author": "Ouyang, Long and Wu, Jeffrey and Jiang, Xu and Almeida, Diogo and Wainwright, Carroll and Mishkin, Pamela and Zhang, Chong and Agarwal, Sandhini and Slama, Katarina and Ray, Alex and others",
        "title": "Training language models to follow instructions with human feedback"
      }
    ]
  },
  {
    "index": 14,
    "papers": [
      {
        "key": "thawakar2024mobillama",
        "author": "Thawakar, Omkar and Vayani, Ashmal and Khan, Salman and Cholakal, Hisham and Anwer, Rao M and Felsberg, Michael and Baldwin, Tim and Xing, Eric P and Khan, Fahad Shahbaz",
        "title": "Mobillama: Towards accurate and lightweight fully transparent gpt"
      }
    ]
  },
  {
    "index": 15,
    "papers": [
      {
        "key": "chu2023mobilevlm",
        "author": "Chu, Xiangxiang and Qiao, Limeng and Lin, Xinyang and Xu, Shuang and Yang, Yang and Hu, Yiming and Wei, Fei and Zhang, Xinyu and Zhang, Bo and Wei, Xiaolin and others",
        "title": "Mobilevlm: A fast, strong and open vision language assistant for mobile devices"
      }
    ]
  },
  {
    "index": 16,
    "papers": [
      {
        "key": "zhang2024tinyllama",
        "author": "Zhang, Peiyuan and Zeng, Guangtao and Wang, Tianduo and Lu, Wei",
        "title": "Tinyllama: An open-source small language model"
      }
    ]
  },
  {
    "index": 17,
    "papers": [
      {
        "key": "dao2022flashattention",
        "author": "Dao, Tri and Fu, Dan and Ermon, Stefano and Rudra, Atri and R{\\'e}, Christopher",
        "title": "Flashattention: Fast and memory-efficient exact attention with io-awareness"
      }
    ]
  },
  {
    "index": 18,
    "papers": [
      {
        "key": "frantar2022gptq",
        "author": "Frantar, Elias and Ashkboos, Saleh and Hoefler, Torsten and Alistarh, Dan",
        "title": "Gptq: Accurate post-training quantization for generative pre-trained transformers"
      }
    ]
  },
  {
    "index": 19,
    "papers": [
      {
        "key": "lin2024awq",
        "author": "Lin, Ji and Tang, Jiaming and Tang, Haotian and Yang, Shang and Chen, Wei-Ming and Wang, Wei-Chen and Xiao, Guangxuan and Dang, Xingyu and Gan, Chuang and Han, Song",
        "title": "AWQ: Activation-aware Weight Quantization for On-Device LLM Compression and Acceleration"
      }
    ]
  },
  {
    "index": 20,
    "papers": [
      {
        "key": "LLAMA23",
        "author": "Touvron, Hugo and Lavril, Thibaut and Izacard, Gautier and Martinet, Xavier and Lachaux, Marie-Anne and Lacroix, Timoth{\\'e}e and Rozi{\\`e}re, Baptiste and Goyal, Naman and Hambro, Eric and Azhar, Faisal and others",
        "title": "Llama: Open and efficient foundation language models"
      }
    ]
  },
  {
    "index": 21,
    "papers": [
      {
        "key": "bai2023qwen",
        "author": "Bai, Jinze and Bai, Shuai and Chu, Yunfei and Cui, Zeyu and Dang, Kai and Deng, Xiaodong and Fan, Yang and Ge, Wenbin and Han, Yu and Huang, Fei and others",
        "title": "Qwen technical report"
      }
    ]
  },
  {
    "index": 22,
    "papers": [
      {
        "key": "hu2024minicpm",
        "author": "Hu, Shengding and Tu, Yuge and Han, Xu and He, Chaoqun and Cui, Ganqu and Long, Xiang and Zheng, Zhi and Fang, Yewei and Huang, Yuxiang and Zhao, Weilin and others",
        "title": "Minicpm: Unveiling the potential of small language models with scalable training strategies"
      }
    ]
  },
  {
    "index": 23,
    "papers": [
      {
        "key": "lu2024small",
        "author": "Lu, Zhenyan and Li, Xiang and Cai, Dongqi and Yi, Rongjie and Liu, Fangming and Zhang, Xiwen and Lane, Nicholas D and Xu, Mengwei",
        "title": "Small language models: Survey, measurements, and insights"
      }
    ]
  }
]