\subsection{Introduction of Bias in Ranked Items via an Unbiased Model}
\label{subsec:introduced_bias}


In this section, we start by analyzing a simple case of one-stage ranking.
Suppose we have $n$ ads candidates with the underlying ground truth Cost Per Mille (CPM) following the distribution of $\vy_i\sim\gN(\vmu, \vsigma^2)$. Let $\vz_i$ be a random variable representing the CPM predictions by some model (here we are simplifying the problem by considering a model outputting the whole eCPM while in reality eCPM was constructed by multiple models). If we assume $\mathbf{M_1}$ to be an unbiased predictor with the prediction error $\ve_1\sim\gN(\vzero, {\vsigma_1}^2)$, we will have $\vz_i\sim\gN(\vmu, \vsigma^2+{\vsigma_1}^2)$. The true value of $\vy_i$ is unknown and only model predictions $\vz_i$ can be observed. Under a typical ranking setup, the model will select the top-k ads based on its own predictions. Let $\sS_1$ be the top-k predicted ads subset selected by $\mathbf{M_1}$ from $n$ available ads, such that  $\sS_1=\{\vz_1, \vz_2, \dots, \vz_k\}$ where $\vz_1>\vz_2>\dots> \vz_k$, . 
We can obtain the expectations of eCPMs following the method described in ~\cite{royston1982expected}:
\begin{align}
    \label{eq:expeCPM}
    \E(\vz_i| \vmu, \vsigma^2,{\vsigma_1}^2,n)=\vmu+
    \sqrt{\vsigma^2+{\vsigma_1}^2}\Phi^{-1}\left(\frac{n-i-\alpha+1}{n-2\alpha+1}  \right)
\end{align}
where $\alpha=3.375$, $\Phi$ is the Gaussian CDF.
With Eq.\ref{eq:expeCPM} in hand, we can now do some analysis on the relationship between eCPMs and CPMs of the selected ads. The goal of this ranking system is to maximize the total return which is the sum of the CPMs of the selected ads. If the model is perfect without any errors, the system reaches its optimal state by finding the top-k CPM ads from the given n ads. The optimal return can be also calculated via Eq.\ref{eq:expeCPM} by setting $\vsigma_1=0$. From Eq.\ref{eq:expeCPM} we can observe that the estimation of the $i^{th}$ ranked item increases as variance of the predictor becomes larger while the total return becomes smaller. In other words, the model predictions are over-calibrated on the set of selected ads. With this toy example, we can see that an unbiased estimator can produce a biased result under a ranking system context. This phenomenon can be understood intuitively by the following argument:
{Although the model's overall prediction is unbiased on the entire candidate set, it is under-calibrated on some parts of the population and over-calibrated on other parts of the population. Therefore, when the model selects the top-k ads based on its prediction, it naturally tends to pick the ones that are over-calibrated. 

\subsection{The inherent Miscalibration in Multi-stage Ranking}
\label{subsec:inherent_miscalibration}
In this section we extend our analysis to a two stage ranking system which better resembles a real world multi-stage ranking system. Suppose we have a first-stage unbiased predictor $\mathbf{M_1}$ with prediction error of $\ve_1\sim\gN(\vzero, {\vsigma_1}^2)$, and a second-stage unbiased predictor $\mathbf{M_2}$ with prediction error of $\ve_2\sim\gN(\vzero, {\vsigma_2}^2)$.
Given the common assumption that early-stage models have higher variance than later stage models, let us further assume that ${\vsigma_1}^2>{\vsigma_2}^2$. Like the discussion in the previous section, we assume we have n ad candidates following the distribution of $\vy_i\sim\gN(\vmu, \vsigma^2)$. The first stage model will select top $k_1$ ads and send them to the second stage, and the second stage model will select top $k_2$ ads and send them to the users. 

The model calibration on the set of ads selected by the first stage ($\sS_1$) is defined as:
\begin{equation}
    \text{cal(i,j)}=\frac{\vmu'_i}{\vmu'_j}
\end{equation}
where ${\vmu'}_i$ and $\vmu'_j$ are average CPM estimation of stages $i$ and $j$ on $\sS_1$, respectively. We use this quantity as an example to illustrate the inherent miscalibration that exist in a multi-stage ranking system. The cross-stage calibration ($\mathbf{M_1}$ w.r.t $\mathbf{M_2}$) is calculated by $cal(1,2)$.
Similarly, we can calculate the calibration of each stage model e.g, $\mathbf{M_j}$ via $cal(j,0)$ where ${\vmu'}_0$ is the average of true CPMs on $\sS_1$.  

In order to analyze the calibration as a function of number of retrieved samples and model characteristics, we run a simulation and show the results in Figure~\ref{fig:two_stage_sim}.
Here, we depict the result of simulation for cross-stage calibration, as well as for each stage's calibration as a function of $k_1$ and different variants of model noise level. 
Regardless of the choice of parameters, we can see that on $\sS_1$ the first stage model is over-calibrated (Figure~\ref{fig:two_stage_sim}-a,b) while the second stage model is well calibrated (Figure~\ref{fig:two_stage_sim}-c). This observation aligns with the intuition discussed in Section ~\ref{subsec:introduced_bias} in that an unbiased model only becomes biased on the set of candidates selected by itself. This simulation result also aligns well with the experimental observation described in Section ~\ref{subsec:semi_consistency_calib}, and at the same time suggests the direction of using the second stage model to correct the bias of the first stage model. 


\begin{figure}[h]
  \centering
   \includegraphics[width=8cm]{figs/cali_simulations.png}
  \caption{Simulation results for model calibrations. a) $\text{cal}(1,2)$. b)  $\text{cal}(1,0)$. c) $\text{cal}(2,0)$. d) all previous plots along side each other.
  Notes: $\mathbf{M_0}$ denotes the ground truth. All calibrations are calculated on the top $k_1$ ads candidates selected by the first stage model ($\sS_1$).
  }
 \label{fig:two_stage_sim}
\end{figure}
