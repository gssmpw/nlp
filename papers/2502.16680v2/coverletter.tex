\documentclass[a4paper]{article}
\usepackage[margin=1.0in]{geometry}
\pagestyle{empty}

\usepackage[colorlinks, linkcolor=blue, anchorcolor=blue,  citecolor=blue, urlcolor=blue]{hyperref}
\usepackage{amsmath, amsthm, amssymb, bm, graphicx, hyperref, mathrsfs}
\usepackage[colorlinks,linkcolor=blue]{hyperref}
\usepackage{adjustbox}
\bibliographystyle{elsarticle-num}

\title{\textbf{Cover Letter for Manuscript Submission}}
\author{Rui Li}
\date{\today}
\linespread{1.5}
\newcounter{problemname}
\newenvironment{problem}{\stepcounter{problemname}\par\noindent\textsc{Problem \arabic{problemname}. }}{\\\par}
\newenvironment{solution}{\par\noindent\textsc{Solution. }}{\\\par}
\newenvironment{note}{\par\noindent\textsc{Note of Problem \arabic{problemname}. }}{\\\par}

\begin{document}

\noindent Dear Prof. Jonathan Li,\\

We are pleased to submit our manuscript entitled \textbf{AeroReformer: Aerial Referring Transformer for UAV-based Referring Image Segmentation} for consideration in the \textit{International Journal of Applied Earth Observation and Geoinformation}. No conflict of interest exists in the submission of this manuscript, and all authors have approved it for publication. On behalf of my co-authors, I confirm that this work is original, has not been published previously, and is not under consideration for publication elsewhere in whole or in part. Please note that an early version of this manuscript is available on arXiv under a non-exclusive license.  

This paper introduces \textbf{AeroReformer}, a novel UAV-specific referring image segmentation framework, addressing the unique challenges posed by UAV imagery, including varying viewpoints, occlusions, and complex background clutter. While referring remote sensing image segmentation (RRSIS) has been explored, existing datasets are limited to nadir-view imagery, making them unsuitable for UAV scenarios where oblique angles and dynamic perspectives significantly affect object appearance. To bridge this gap, we design an automatic dataset generation framework leveraging existing UAV segmentation datasets and a multimodal large language model (MLLM), resulting in the first UAV-referring segmentation datasets: \textbf{UAVid-RIS} and \textbf{VDD-RIS}.  

To effectively align visual and textual modalities in UAV imagery, we design AeroReformer with a \textbf{Vision-Language Cross-Attention Module (VLCAM)} for robust multimodal fusion and a \textbf{Rotation-Aware Multi-Scale Fusion (RAMSF)} decoder to handle scale variations and directional inconsistencies. Experimental results on UAVid-RIS and VDD-RIS demonstrate that AeroReformer achieves state-of-the-art performance, outperforming existing methods in both quantitative and qualitative evaluations.  

We believe that our work will be of interest to the remote sensing and computer vision communities, as it introduces the first UAV-referring segmentation dataset and establishes a strong benchmark for UAV-based vision-language understanding. We sincerely hope that this manuscript is considered suitable for publication in the \textit{International Journal of Applied Earth Observation and Geoinformation}. All codes and datasets will be made publicly available.

Thank you for your time and consideration. We look forward to your feedback. \\

\noindent Yours sincerely, \\

\noindent Rui Li \\  
\noindent Corresponding author: Xiaowei Zhao \\  
\noindent E-mail: xiaowei.zhao@warwick.ac.uk  

\end{document}
