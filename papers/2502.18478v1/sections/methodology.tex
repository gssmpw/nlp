In this section, we delve into the core regularization techniques we have applied to an industrial-scale ads recommendation system. 
We start by discussing our data augmentation strategies which are an important part of Perturbation-Based Regularization, and further detail Self-Consistency regularization methods. 
We then discuss regularization techniques that promote perturbation invariance beyond Self-Consistency Regularization.
Finally, we discuss the integration of these techniques into different phases of industrial-scale models - such as Retrieval, Early and Final Stage Ranking.


\subsection{Data Augmentation} 

Data augmentation has played a role in our perturbation-based regularization algorithms. 
It's essential to underline that recommender systems, as mentioned in \cite{int_ctr} and \cite{augmentation2}, are significantly influenced by both sparse and dense features. 
Therefore, a robust augmentation strategy that caters to both types of features, improving the effectiveness of our regularization methods in various recommendation scenarios.

\textbf{Dropout}  
was initially proposed as a regularization method that enabled deep learning models to generalize, and is known as one of the stepping stones of deep learning~\cite{srivastava2014dropout}.
It further emerged as a vital data augmentation strategy tailored for sparse features, leveraging insights from its prior applications in natural language processing \cite{gao2021simcse} and recommender systems \cite{augmentation2}. In this context, the core concept involves creating a subset of existing sparse features as augmented copies of the original sparse feature set.
For instance, consider a datapoint with embedding features $\ve$ and sparse features $\vs$:
\begin{align*}
    (\evs_1,\evs_2,\evs_3,\evs_4,\evs_5,\evs_6) \rightarrow  (\eve_1, \eve_2, e_3), 
    (\evs_1,\evs_2,0,0,\evs_5, \evs_6) 
\end{align*}

The extent of dropout perturbation varies depending on the problem setting, with the option to employ either a strong or weak dropout. When integrated correctly with Self-Supervised Learning (SSL) techniques, dropout has exhibited substantial performance improvements in large-scale item recommendations \cite{augmentation2}, emphasizing its pivotal role in enhancing recommendation systems.

\textbf{Gaussian Noise Injection} serves as a technique for augmenting dense features within our framework. The concept is elegantly simple, involving the generation of a random vector $\vpsi_i$ from a Gaussian distribution, denoted as $\vpsi_i\sim\mathcal{N}(\vmu, \vsigma)$. 
For instance, in a 3-dimensional float vector, represented as $\vx = (\evx_1, \evx_2, \evx_3)$, augmentation with Gaussian Noise can be described as follows:
\begin{align*}
(\eve_1, \eve_2, \eve_3) \rightarrow (\eve_1 + \psi_1, \eve_2 + \psi_2, \eve_3 + \psi_3)
\end{align*}

This augmentation introduces controlled randomness to the features, contributing to the model's robustness and diversity of the data.


\subsection{Self-Consistency Regularization (SCR)}

Self-Consistency Regularization is an algorithm that enforces small modifications in the data still preserve the similar prediction value.
The algorithm, is especially important when the model is too large, and data-set is not large enough to serve to the model's capacity.
The algorithm introduces an auxiliary loss term, that penalizes the disparity between the outcomes of the perturbed and the original data point, effectively promoting consistency in the latent space representation (see Figure~\ref{fig:consistency}).
\begin{figure}[ht!]
  \centering
  \includegraphics[width=7.5cm, height = 7.8cm]{used_figures/consistency.png}
  \caption{Self Consistency Regularization (SCR)}
\label{fig:consistency}
\end{figure}


The concept underlying SCR is as straightforward as depicted in Figure~\ref{fig:consistency}.
As can be seen, perturbed data along with the original data is fed to the model, and an additional regularization loss is used to minimize the model's output differences between original and perturbed data.
In this approach, we incorporate Mean Squared Error (MSE) loss term as the regularizer alongside the supervised loss term.
\begin{align*}
    \mathcal{L_{\text{consistency}}}(\vy_i,\hat{\vy}_i,\vp_i,\vp'_i)  = \mathcal{L_{\text{supervised}}}(\vy_i,\hat{\vy}_i) + \lambda \mathcal{L_{\text{MSE}}}(\vp_i,\vp'_i)
\end{align*}
where $\mathcal{L_{\text{supervised}}}$ is as defined in Eq.~\ref{eq:bce} and $\mathcal{L_{\text{MSE}}}$ is defined as
\begin{align*}
\mathcal{L_{\text{MSE}}}(\vp_i,\vp'_i)&= \frac{1}{N} \sum_{i=1}^{N}(\vp_i- \vp'_i)^2\\
\end{align*}
and $\vp_i$ represent some hidden representation of the deep neural network for some input $\vx_i$, while ${\vp'}_i$ denotes this representation for the perturbed input ${\vx'}_i$.

  
\subsection{Loss-Balanced Small Perturbation Regularization (LSPR)}
\begin{algorithm}
\caption{Loss-Balanced Small Perturbation Regularization}
\label{alg:lspr}
\begin{algorithmic}
\For{ batch from data}
    \State 1. Sample data
    \State 2. Sample small noise
    \State 3. Create perturbed data by adding noise to data
    \State 4. Calculate $\mathcal{L_{\text{supervised}}}$ on sampled data
    \State 5. Calculate $\mathcal{L_{\text{supervised}}}$ on perturbed sampled data
    \State 6. Balance losses by calculating $\mathcal{L_{\text{LSPR}}}$ from Eq.~\ref{eq:spr}
    \State 7. Update model parameters
\EndFor

\end{algorithmic}
\end{algorithm}
Despite its simplicity and generality, training models with noise has been known to improve  generalization of models~\cite{bishop1995training}.
In this section, we study a variation of Perturbation-Based Regularization, namely, Loss-Balanced Small Perturbation Regularization (LSPR). 
In this approach, perturbed points are treated as original points but with smaller weights in the loss.
Moreover, we expect these datapoints that contain small perturbations to have the same label as the original data points. Therefore, we name this algorithm Loss-Balanced Small Perturbation Regularization (LSPR).
In contrast to data augmentation that treats both augmented (or perturbed) data and original data equal in the loss calculation, LSPR reduces the weights of perturbed data in the calculation of the loss, hence, is less disruptive to learning dynamics.
\newmaterial{
Furthermore, we report a successful deployment of LSPR in a billion-scale industrial ranking system.
To the best of our knowledge, LSPR is the first of its kind, and it is specially designed to address the various scalability challenges. Not only does the system need to cater to billions of users, but also serve various surfaces (e.g, client-facing apps and product platforms), global geological locations, various clients (e.g, web, mobile app), and various conversion events (e.g. clicks, purchases) which means the system consists of hundreds of models up and running at any given time.}


The LSPR algorithm is depicted in Algorithm~\ref{alg:lspr}. 
\newmaterial{As can be seen, LSPR constructs perturbations to create perturbed examples, then uses those perturbation to calculate a regularization loss, which is combined with the main objective and is balanced accordingly.
In constructing the perturbations, LSPR ensures that perturbation and data are both of the same class of distributions. For instance, if data is categorical, the perturbations will also be of a categorical distribution.}

In this paper, we have treated any perturbed data point with a uniform weight. Here, we scale samples uniformly with a scale parameter $\lambda<1$. 
However, exploring perturbation-dependent weights is a worthwhile follow-up.
The formula for LSPR regularization is as follows:
\begin{align}
\label{eq:spr}
    \mathcal{L_{\text{LSPR}}}(\vy_i,\hat{\vy}_i, \hat{\vy}'_i)   = \mathcal{L_{\text{supervised}}}(\vy_i,\hat{\vy}_i) + \lambda \mathcal{L_{\text{supervised}}}(\vy_i,\hat{\vy}'_i) 
\end{align}

where $\hat{\vy}'_i$ is the model's prediction on the perturbed input $\vx'_i$
traditional supervised loss function.
The schematic representation of this regularization technique is outlined below in the Figure~\ref{fig:lspr_diagram}:
\begin{figure}[h]
  \centering
  \includegraphics[width=7.5cm, height = 8.1cm]{used_figures/lspr_diagram.png}
  \caption{Loss-Balanced Small Perturbation Regularization. (LSPR)}
\label{fig:lspr_diagram}
\end{figure}
Unlike Self-Consistency Regularization, Small Perturbation regularization does not prioritize minimizing the distance between original data points and perturbed points. 
Instead, it focuses on correct predictions for perturbed points.
Depending on the defined loss $\mathcal{L}$, this discrepancy can result in significant variance in the resulting parameters.
Hence, the batch size at each stage will be doubled in this case, while some of the points having smaller weights compared to others.

\subsection{LSPR's Hyperparameters}

\newmaterial{
LSPR is designed to be simple yet effective, with only three major hyperparameters, while providing significant values in performance and optimization. Here are its hyperparameters and our approach in hyperparameter tuning:
- dense feature perturb: We enforce perturbation to be of the same distribution as our dense features.
- sparse feature dropout: we apply a relatively small dropout rate to sparse features.
- loss weight: We start our hyperparameter search for the loss weight from a smaller scale relative to main objectives, and then to a more fine grained search
This simplicity allows for easier tuning and deployment in large-scale industrial settings while still delivering significant performance improvements.
We will add these details to the final version of our paper.
}
