\begin{figure*}[ht]
    \centering
    \includegraphics[width=0.33\linewidth]{syndata_nomodification.pdf}
    \includegraphics[width=0.33\linewidth]{syndata_shift5.pdf}
    \includegraphics[width=0.33\linewidth]{syndata_corruption_m3.pdf}
    \caption{Average estimation error for the watermark keys versus sample sizes, in the no-alteration (left), the shifting case (center), and the sample corruption case (right), using synthetic data. The estimation error decreases as more samples $n$ are available, although the text length $m$, the potential shift $k$ and the number of corrupted samples make the estimation problem more challenging. We report the mean and standard deviation over 10 runs (see text for more details).}
    \label{true_binary_fig}
\end{figure*}

\section{Experimental Analysis}
\label{sec:experiment}

The main question raised in the previous section is whether our method of secret key estimation is capable of reliably \textquote{stealing} the watermark used by the distortion-free watermarking algorithm \citep{kuditipudi2024robust} in a real-world LLM. In this section, we empirically evaluate our \textquote{spoofing} attack across three different scenarios mentioned above using both synthetic data and tokens generated from a watermarked LLM (OPT-125M model \citealt{zhang2022opt}). 


\subsection{Evaluate Secret Watermark Key Estimation using Synthetic Data}

We evaluate the estimated watermark keys, denoted as $\hat{\xi}$ , using synthetic data by varying both the text length $m$ and the number of possible shifts in each sample $k$. The synthetic data are generated by randomly sampling both the watermark keys and the probability mass in the set $\mathcal{G}$ from a uniform distribution $\xi^*_i, q^i_j \sim \mathcal{U}[0,1]$ for all $i, j$. Figure~\ref{true_binary_fig} illustrates how the average $L^1$ error in watermark key estimation (i.e., $1/m \sum_j |\hat{\xi}_j - \xi^*_j |$), decreases as the number of samples $n$ increases. As expected, while the estimation problem becomes more challenging with increases in text length $m$, the number of possible shifts $k$ , or the presence of corrupted samples, the error tends to reduce with more samples. We also note that in the sample corruption case, if the number of corrupted samples is larger than the upper bound $T$ for the boolean variable $v$ in the optimization problem (\ref{eq:shiftcorrlower}), the optimization problem is unable to ignore all corrupted samples, and a larger sample size does not necessarily imply a better estimation error. We report the mean and standard deviation of the estimation error over 10 runs (where in each run we change the random seed for the generation of the watermark keys as well as the probability mass in the set $\mathcal{G}$).


\subsection{Breaking the Watermarks in OPT-125M LLM}

For our watermark stealing experiments, we utilize the OPT-125M model \cite{{zhang2022opt}}. To replicate a variation of language modeling scenarios, we generate our binary text using 100 random prompts generated from ChatGPT \cite{radford2019language}. We then follow the methodology outlined by \citep{kuditipudi2024robust} for watermark detection, where the block size is set equal to the length $m$ of each sample text. This process involves comparing blocks of the binary sequence to the secret key using a test statistic which is then used to calculate a $p$-value for determining whether the sequence is watermarked. 

As seen in Figure~\ref{median_pvalue_opt125m} and Figure~\ref{spoof_fig}, we vary the text length $m$ while fixing the watermark key length to 256 and report median $p$-values of our spoofed watermarked text for 100 samples. We also evaluate the robustness of our watermark key estimation to the two other attacks, shifting and corruption, mentioned above. These attacks enable us to adjust the degree of alteration of our watermarked text. For the experiments done in this paper, we set our corruption rate = 5\%, the shifting amount, $k$ = 2, and vary the text length $m$. 
% \begin{figure}[h]
%     % \centering
%     \includegraphics[width=1\linewidth]{true_binary.pdf}
%     \caption{Median $p$-value of watermarked text generated using the true secret key for varying text length $m$. Figure shows the performance of the generated binary text. Across the text length for of OPT-125M model, the median p-values decrease rapidly with increasing text length  $m$ plateauing after 25 text length}
%     \label{true_binary_fig}
% \end{figure}


\begin{figure}[h]
    \centering
    \includegraphics[width=1\linewidth]{true_binary_ND.pdf}
    \caption{Median $p$-value of watermarked text generated using the true secret key for varying text length $m$. Figure shows the performance of the generated binary text. Across the text length for of OPT-125M model, the median p-values decrease rapidly with increasing text length  $m$ plateauing after 25 text length.}
    \label{median_pvalue_opt125m}
\end{figure}


As mentioned in section~\ref{methodology}, we initially generate binary text using the key sequence provided by the LM provider. Since this binary text is generated with the true secret key, it serves as the baseline against which our secret key estimation attacks are compared. With a watermark detection threshold of $p < 0.05$, it requires approximately 20 binary texts $m$  before our generated text can be detected as fully watermarked. For binary texts generated exceeding roughly 25, watermark detection tends to yield $p$-values close to zero. We compare our binary texts generated from the estimated secret key (fig~\ref{spoof_fig}) against the texts generated from using the true secret key (fig~\ref{true_binary_fig}). 

Our watermark key estimations are competitive with that of the true key as the generated texts follow the same pattern of requiring about 20 binary texts generated before the watermark can be detected. The \textquote{spoofing} also shows good results with regard to shifting the elements of the underlying key, as this has little to no effect on the $p$-value with results similar to the key estimation with no alterations. This is not the case when corrupting a percent of the binary texts as this degrades the quality of the watermarked text, requiring more than 45 generated binary texts before the watermark can be detected. 

Overall, our results demonstrate that reliable spoofing of binary texts on the OPT-125M language model \cite{zhang2022opt} is possible using our mixed linear programming attack for watermark key estimation, even with various types of attacks and only a few samples of the watermarked text. Similar to the binary text generated from the true secret key, longer texts have to be generated to achieve stronger watermark detection.

\begin{figure}[h]
    % \centering
    \includegraphics[width=1\linewidth]{vanilla_shift_sub_ND.pdf}
    \caption{Median $p$-value of watermarked text generated using our mixed linear programming framework to accurately estimate the secret watermark key. Figure shows the performance using our watermark key estimation \textquote{spoofing} on the three cases of  attacks -\textit{no alteration}, \textit{corruption}, and \textit{shifting}. Across the text length $m$ for OPT-125M model, the median p-values of decrease  with increasing text length $m$.}
    \label{spoof_fig}
\end{figure}



\section{Conclusion and Future Work}
%This work demonstrates the potential of our mixed linear programming framework to accurately estimate the secret watermark key used by the distortion free watermarking algorithm. We also show that this framework is robust to input after shifting and corrupting the LLM user due to the similar results as that from the distortion free watermark. As a potential next step, we will like to increase our use case from binary generative text to the full vocabulary of an LM. Another potential direction to take is to vary the corruption rate and $k$ parameters to see the rate of change of watermark detection as we increase binary text length generation. Such investigations could provide valuable insights and advancements in the field.

This work highlights the effectiveness of our mixed linear programming framework in accurately estimating the secret watermark key used by the distortion-free watermarking algorithm. We demonstrate that this framework is robust to input shifts and corruption introduced by the LLM user, as evidenced by the results that closely match those of the distortion-free watermarking method. Moving forward, we plan to extend our approach from the binary generative text to cover the full vocabulary of an LLM. Additionally, we aim to explore the impact of varying the corruption rate and the $k$ parameters, examining how these factors affect watermark detection as the length of the generated binary text increases. We also intend to test our framework with different LLMs. These investigations could offer valuable insights and drive further advancements in the field. 

% As a next step, we aim to expand our use case from binary generative text to encompass the full vocabulary of an LLM. Additionally, we plan to explore the impact of  varying the corruption rate and the $k$ parameters, investigating how these factors influence watermark detection as the length of generated binary text increases. We also plan to experiment with different LLMs. Such investigations could provide valuable insights and advancements in the field.

% \subsubsection*{Disclaimer.} This paper was prepared for informational purposes and is contributed by the Artificial Intelligence
% Research group of JPMorgan Chase \& Co and its affiliates (``J.P. Morgan''), and is not a
% product of the Research Department of J.P. Morgan. J.P. Morgan makes no representation
% and warranty whatsoever and disclaims all liability, for the completeness, accuracy or reliability
% of the information contained herein. This document is not intended as investment research or
% investment advice, or a recommendation, offer or solicitation for the purchase or sale of any
% security, financial instrument, financial product or service, or to be used in any way for evaluating
% the merits of participating in any transaction, and shall not constitute a solicitation under any
% jurisdiction or to any person, if such solicitation under such jurisdiction or to such person would
% be unlawful