\documentclass[letterpaper]{article}

% To return to anonymous, go to preamble.tex
% and change the AAAI usepackage as mentioned
% there

% \date{September 2024}
\input{headers/preamble}
\input{headers/macros}
% \usepackage[round]{natbib}
\renewcommand{\bibname}{References}
\renewcommand{\bibsection}{\subsubsection*{\bibname}}
\usepackage{float}
\title{Toward Breaking Watermarks in Distortion-free Large Language Models}
\author {
    % Authors
    Shayleen Reynolds\textsuperscript{\rm 1},
    Saheed Obitayo\textsuperscript{\rm 1},
    Niccol\`o Dalmasso\textsuperscript{\rm 1},
    Dung Daniel T. Ngo\textsuperscript{\rm 1},\\
    Vamsi K. Potluru\textsuperscript{\rm 1},
    Manuela Veloso\textsuperscript{\rm 1}
}
\affiliations {
    % Affiliations
    \textsuperscript{\rm 1}J.P. Morgan AI Research, New York\\
    $\{$shayleen.reynolds, saheed.obitayo, niccolo.dalmasso, tuandung.ngo,  vamsi.k.potluru, manuela.veloso$\}$@jpmchase.com \\
}
\date{}
%
\begin{document}
%
\maketitle
%
\begin{abstract}
In recent years, LLM watermarking has emerged as an attractive safeguard against AI-generated content, with promising applications in many real-world domains. However, there are growing concerns that the current LLM watermarking schemes are vulnerable to expert adversaries wishing to reverse-engineer the watermarking mechanisms. Prior work in \textquote{breaking} or \textquote{stealing} LLM watermarks mainly focuses on the distribution-modifying algorithm of \citet{kirchenbauer2023watermark}, which perturbs the logit vector before sampling. In this work, we focus on reverse-engineering the other prominent LLM watermarking scheme, distortion-free watermarking \citep{kuditipudi2024robust}, which preserves the underlying token distribution by using a hidden watermarking key sequence. We demonstrate that, even under a more sophisticated watermarking scheme, it is possible to \textquote{compromise} the LLM and carry out a \textquote{spoofing} attack. Specifically, we propose a mixed integer linear programming framework that accurately estimates the secret key used for watermarking using only a few samples of the watermarked dataset. Our initial findings challenge the current theoretical claims on the robustness and usability of existing LLM watermarking techniques.
\end{abstract}
%
\input{intro}
%
\input{methodology}
%
% \input{inverse-transform-sampling}
%
% \input{detectability}
% \bibliographystyle{abbrvnat}
\input{experiment}
\input{acknowledgments}
\input{impact_statement}

\begin{thebibliography}{14}
\providecommand{\natexlab}[1]{#1}

\bibitem[{Aaronson(2023)}]{aaronson2023openai}
Aaronson, S. 2023.
\newblock `{R}eform' {AI} {A}lignment with {S}cott {A}aronson.
\newblock AXRP - the AI X-risk Research Podcast.

\bibitem[{Gloaguen et~al.(2024{\natexlab{a}})Gloaguen, Jovanovi{\'c}, Staab,
  and Vechev}]{gloaguen2024black}
Gloaguen, T.; Jovanovi{\'c}, N.; Staab, R.; and Vechev, M. 2024{\natexlab{a}}.
\newblock Black-box detection of language model watermarks.
\newblock \emph{arXiv preprint arXiv:2405.20777}.

\bibitem[{Gloaguen et~al.(2024{\natexlab{b}})Gloaguen, Jovanovi{\'c}, Staab,
  and Vechev}]{gloaguen2024discovering}
Gloaguen, T.; Jovanovi{\'c}, N.; Staab, R.; and Vechev, M. 2024{\natexlab{b}}.
\newblock Discovering Clues of Spoofed LM Watermarks.
\newblock \emph{arXiv preprint arXiv:2410.02693}.

\bibitem[{Jovanović, Staab, and
  Vechev(2024)}]{jovanovic2024watermarkstealinglargelanguage}
Jovanović, N.; Staab, R.; and Vechev, M. 2024.
\newblock Watermark Stealing in Large Language Models.
\newblock arXiv:2402.19361.

\bibitem[{Kirchenbauer et~al.(2023)Kirchenbauer, Geiping, Wen, Katz, Miers, and
  Goldstein}]{kirchenbauer2023watermark}
Kirchenbauer, J.; Geiping, J.; Wen, Y.; Katz, J.; Miers, I.; and Goldstein, T.
  2023.
\newblock A watermark for large language models.
\newblock \emph{arXiv preprint arXiv:2301.10226}.

\bibitem[{Kuditipudi et~al.(2024)Kuditipudi, Thickstun, Hashimoto, and
  Liang}]{kuditipudi2024robust}
Kuditipudi, R.; Thickstun, J.; Hashimoto, T.; and Liang, P. 2024.
\newblock Robust Distortion-free Watermarks for Language Models.
\newblock \emph{Transactions on Machine Learning Research}.

\bibitem[{Ning et~al.(2024)Ning, Chen, Zhong, Zhang, Wang, Li, Zhang, Zhang,
  and Zheng}]{ning2024mcgmark}
Ning, K.; Chen, J.; Zhong, Q.; Zhang, T.; Wang, Y.; Li, W.; Zhang, Y.; Zhang,
  W.; and Zheng, Z. 2024.
\newblock MCGMark: An Encodable and Robust Online Watermark for LLM-Generated
  Malicious Code.
\newblock \emph{arXiv preprint arXiv:2408.01354}.

\bibitem[{Pang et~al.(2024)Pang, Hu, Zheng, and Smith}]{pang2024attacking}
Pang, Q.; Hu, S.; Zheng, W.; and Smith, V. 2024.
\newblock Attacking LLM Watermarks by Exploiting Their Strengths.
\newblock \emph{arXiv preprint arXiv:2402.16187}.

\bibitem[{Piet et~al.(2024)Piet, Sitawarin, Fang, Mu, and
  Wagner}]{piet2024markwordsanalyzingevaluating}
Piet, J.; Sitawarin, C.; Fang, V.; Mu, N.; and Wagner, D. 2024.
\newblock Mark My Words: Analyzing and Evaluating Language Model Watermarks.
\newblock arXiv:2312.00273.

\bibitem[{Radford et~al.(2019)Radford, Wu, Child, Luan, Amodei, and
  Sutskever}]{radford2019language}
Radford, A.; Wu, J.; Child, R.; Luan, D.; Amodei, D.; and Sutskever, I. 2019.
\newblock Language Models are Unsupervised Multitask Learners.

\bibitem[{Wu and Chandrasekaran(2024)}]{wu2024bypassingllmwatermarkscoloraware}
Wu, Q.; and Chandrasekaran, V. 2024.
\newblock Bypassing LLM Watermarks with Color-Aware Substitutions.
\newblock arXiv:2403.14719.

\bibitem[{Zhang et~al.(2024{\natexlab{a}})Zhang, Hussain, Neekhara, and
  Koushanfar}]{zhang2024remark}
Zhang, R.; Hussain, S.~S.; Neekhara, P.; and Koushanfar, F. 2024{\natexlab{a}}.
\newblock $\{$REMARK-LLM$\}$: A robust and efficient watermarking framework for
  generative large language models.
\newblock In \emph{33rd USENIX Security Symposium (USENIX Security 24)},
  1813--1830.

\bibitem[{Zhang et~al.(2022)Zhang, Roller, Goyal, Artetxe, Chen, Chen, Dewan,
  Diab, Li, Lin et~al.}]{zhang2022opt}
Zhang, S.; Roller, S.; Goyal, N.; Artetxe, M.; Chen, M.; Chen, S.; Dewan, C.;
  Diab, M.; Li, X.; Lin, X.~V.; et~al. 2022.
\newblock Opt: Open pre-trained transformer language models.
\newblock \emph{arXiv preprint arXiv:2205.01068}.

\bibitem[{Zhang et~al.(2024{\natexlab{b}})Zhang, Zhang, Zhang, Zhang, Chen, Hu,
  Gill, and Pan}]{zhang2024largelanguagemodelwatermark}
Zhang, Z.; Zhang, X.; Zhang, Y.; Zhang, L.~Y.; Chen, C.; Hu, S.; Gill, A.; and
  Pan, S. 2024{\natexlab{b}}.
\newblock Large Language Model Watermark Stealing With Mixed Integer
  Programming.
\newblock arXiv:2405.19677.

\end{thebibliography}


%
\appendix
% \onecolumn
%
% \input{appendix/appendix-inverse-transform-sampling}]
%
% \clearpage
%\input{appendix/appendix-results}
% \clearpage
%\input{appendix/appendix-vanilla-demonstrations}
% \clearpage
\end{document}
