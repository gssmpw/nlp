\begin{table*}[t]
\centering
% \captionsetup{justification=centering}
\resizebox{\textwidth}{!}{
\begin{tabular}{lcccccc}
\hline
                                 & \multicolumn{2}{c}{\textbf{Easy}}              & \multicolumn{2}{c}{\textbf{Medium}} & \multicolumn{2}{c}{\textbf{Hard}} \\
\multirow{-2}{*}{\textbf{Model}} & Flowchart & Mermaid                            & Flowchart       & Mermaid           & Flowchart      & Mermaid          \\ \hline
\multicolumn{7}{c}{Proprietary Models}                                                                                                                      \\ \hline
GPT-4o                           & 91.1      &  88.9 {\color[HTML]{FE0000}(-2.2)} & 89.3            & 85.3 {\color[HTML]{FE0000}(-4.0)}       & 79.3           & 82.8 {\color[HTML]{009901}(+3.5)}      \\
Claude 3.5 Sonnet                & 84.4      & 82.2 {\color[HTML]{FE0000}(-2.2)}                        & 77.3            & 73.3 {\color[HTML]{FE0000}(-4.0)}       & 48.3           & 44.8 {\color[HTML]{FE0000}(-3.5)}      \\
Claude 3 Sonnet                  & 31.1      & 37.8 {\color[HTML]{009901}(+6.7)} & 14.7            & 20.0 {\color[HTML]{009901}(+5.3)}       & 3.4            & 17.2 {\color[HTML]{009901}(+13.8)}     \\
Claude 3 Haiku                   & 22.2      & 22.2 {\color[HTML]{009901}(+0.0)}                        & 4.0             & 10.7 {\color[HTML]{009901}(+6.7)}       & 0.0            & 6.9 {\color[HTML]{009901}(+6.9)}       \\
Gemini 1.5 Pro                   & 88.9      & 84.4 {\color[HTML]{FE0000}(-4.5)}                        & 72.0            & 73.3 {\color[HTML]{009901}(+1.3)}       & 44.8           & 51.7 {\color[HTML]{009901}(+6.9)}      \\
Gemini 1.5 Flash                 & 40.0      & 44.4 {\color[HTML]{009901}(+4.4)}                        & 32.0            & 44.0 {\color[HTML]{009901}(+12.0)}      & 10.3           & 20.7 {\color[HTML]{009901}(+10.4)}     \\ \hline
\multicolumn{7}{c}{Open-source Models}                                                                                                                      \\ \hline
Llama-3.2-11B-Vision-Instruct    & 8.9       & 28.9 {\color[HTML]{009901}(+20.0)}                       & 1.3             & 6.7 {\color[HTML]{009901}(+5.4)}        & 0.0            & 6.9 {\color[HTML]{009901}(+6.9)}       \\
Llama-3.2-90B-Vision-Instruct    & 17.8      & 28.9 {\color[HTML]{009901}(+11.1)}                       & 8.0             & 13.3 {\color[HTML]{009901}(+5.3)}       & 0.0            & 13.8 {\color[HTML]{009901}(+13.8)}     \\
Phi-3-vision-128k-instruct       & 15.6      & 31.1 {\color[HTML]{009901}(+15.5)}                       & 4.0             & 10.7 {\color[HTML]{009901}(+6.7)}       & 0.0            & 6.9 {\color[HTML]{009901}(+6.9)}       \\
Phi-3.5-vision-instruct          & 8.9       & 22.2 {\color[HTML]{009901}(+13.3)}                       & 0.0             & 9.3 {\color[HTML]{009901}(+9.3)}        & 0.0            & 3.5 {\color[HTML]{009901}(+3.4)}       \\
MiniCPM-V 2.6                    & 22.2      & 33.3 {\color[HTML]{009901}(+11.1)}                       & 9.3             & 18.7 {\color[HTML]{009901}(+9.4)}       & 0.0            & 6.9 {\color[HTML]{009901}(+6.9)}       \\
Qwen-VL-Plus                     & 11.1      & 31.1 {\color[HTML]{009901}(+20.0)}                       & 0.0             & 9.3 {\color[HTML]{009901}(+9.3)}        & 0.0            & 10.3 {\color[HTML]{009901}(+10.3)}     \\ \hline
\end{tabular}
}
\caption{Comparison of MLLMs When Flowchart or Mermaid Are Used as Input. We calculate the performance change ($Flowchart-Mermaid$), with {\color[HTML]{FE0000}red} representing a drop and {\color[HTML]{009901}green} representing a rise. Open-source models show substantial improvements with mermaid inputs. We use Algorithm subset.}
\label{tab: mermaid}
\end{table*}