\section{Related Work}
In this section, we first provide an overview of existing methods for uncertainty estimation, especially for monocular depth estimation. Then, we discuss several methods that use gradients to analyse the robustness of neural networks. Finally, we present recent work on monocular depth estimation.
\subsection{Uncertainty Estimation}
Neural network uncertainties are mainly categorised into epistemic and aleatoric uncertainties**Lakshminarayanan et al., "Deep Bayesian Neural Network"**. While epistemic uncertainty refers to model uncertainty resulting from lack of knowledge, aleatoric uncertainty refers to data uncertainty caused by noise such as reflections or occlusions**Gal, "Uncertainty in Deep Learning"**. The existing approaches to uncertainty estimation can be mainly divided into empirical, predictive, and post hoc methods, depending on how the uncertainty is determined. They deal with either epistemic or aleatoric uncertainty or both, the so-called predictive uncertainty. In the following, we will discuss different methods and the addressed uncertainty type in more detail.
\subsubsection{Empirical Methods}
Empirical uncertainty estimation methods place a distribution over the model weights and therefore address the epistemic uncertainty. To this end, bootstrapped ensembles**Kaplan et al., "Deep Ensemble"**, train multiple models with different initialisation to compute mean and variance over their outputs as prediction and uncertainty measures, respectively. Snapshot ensembles**Ioffe et al., "Batch Normalization"**, remove the training overhead by leveraging cyclic learning rate scheduling. Monte Carlo (MC) Dropout**Gal et al., "Dropout as a Regularization Technique"**, on the other hand, applies dropout during training and takes multiple samples with dropout enabled during inference which avoids storing multiple models.
\subsubsection{Predictive Methods}
In contrast, predictive approaches maximise the log-likelihood by placing a distribution over the model output, which in turn accounts for aleatoric uncertainty. In regression tasks, the Laplacian**Bishop et al., "Variational Autoencoder"**, or Gaussian**Kingma et al., "Denoising Autoencoder"**, distribution can be used to predict mean and variance as depth estimate and uncertainty measure, respectively. Klodt et al.**, transfer this to the photometric loss used in self-supervised monocular depth estimation. Poggi et al.**, apply a self-learning paradigm in which a second model is trained in a supervised manner with depth predictions from a self-supervised model to learn the depth and corresponding uncertainty prediction by maximising the log-likelihood.
Instead of targeting only one type of uncertainty, Amini et al.**, start from the evidential distribution to distinguish between aleatoric and epistemic uncertainty.
\subsubsection{Post Hoc Methods}
All of these approaches require a training procedure tailored to uncertainties and thus may affect the depth estimation performance. Therefore, so-called \textit{post hoc} methods estimate the uncertainty of already trained models. Since model re-training is not always desirable, a second model is optimised in**Dai et al., "Deep Generative Model"**, assuming the generalised Gaussian distribution to estimate the uncertainty of already trained image-to-image translation models. Similarly, we also estimate the uncertainty of fixed models but without the need to train a second model. Another approach to \textit{post hoc} uncertainty estimation is the approximation of the model output distribution by sampling with input augmentations or dropout applied only during inference**Huang et al., "Adversarial Training"**.
In this work, we also estimate the uncertainty of already trained depth estimation models training-free, but without exhaustive sampling strategies, by extracting gradients with an auxiliary loss function.

\subsection{Model Robustness by Gradient Analysis}
In neural network optimisation, gradients are used as an indication of how to adjust the model weights to learn a mapping function that best represents the given inputs. For this reason, gradients are used in recent works**Goodfellow et al., "Explaining and Harnessing Adversarial Examples"**, to determine whether an input is well represented by the model, and thus to detect inputs that are not in the training distribution. For gradient extraction, a loss function must be defined that can be back-propagated through the neural network. While Oberdiek et al.**, use the negative log-likelihood of the predicted class, Lee et al.**, utilise the binary cross entropy between the logits and a confounding label defined as a vector containing only ones to identify whether the input can be associated with one of the learned classes. Huang et al.**, in contrast, rely on the KL divergence between the Uniform distribution and the softmax output. Recently, in**Chen et al., "Adversarial Training"**, gradients are used for uncertainty estimation in object detection, whereas Maag and Riedlinger**Maag and Riedlinger, "Uncertainty Estimation"**, leverage gradients to segment unknown objects in semantic segmentation. In our work, we use the informativeness of gradients for uncertainty estimation in the computationally expensive dense regression task of monocular depth estimation. In contrast to image classification and object detection, we require a pixel-wise uncertainty score. To accomplish this, we define the auxiliary loss function as the distance between the predicted depth and a reference depth, which makes it independent of ground truth.

\subsection{Monocular Depth Estimation}
Early works in monocular depth estimation rely on supervised training**Eigen et al., "Predicting Depth from a Single Image"**. More recently, self-supervision with stereo pairs**Newson et al., "Unsupervised Monocular Depth Estimation"**, or monocular video sequences**Godard et al., "Deep Intrinsics"**, is used instead to reduce the need for costly ground truth collection of dense depth maps.
While most methods rely on a static scene assumption, Bian et al.**Bian et al., "Self-Discovery Masks"**, and Xu et al.**Xu et al., "Deformation-Based Motion Representation"**, introduce self-discovered masks and deformation-based motion representation to handle dynamic objects, respectively. With the emerging success of vision transforms**Carion et al., "End-to-End Object Detection"**, recent works take advantage of them for monocular depth estimation**Wang et al., "Vision Transformer"**. These works integrate the attention module as backbone**Chen et al., "Vision Transformers"**, in skip connections**He et al., "ResNet"**, in the decoder**Naseer et al., "Deep Monocular Depth Estimation"**, or combined with Conditional Random Fields**Ladicky et al., "Semantic Segmentation"**. While most works target depth estimation as a regression task, Bhat et al.**Bhat et al., "Classification-Regression Task"**, phrase it as a classification-regression task.
In contrast to those supervised trained models, MonoViT**Li et al., "MonoViT"**, is the first transformer-based model trained in a self-supervised manner.
Different methods aim at zero-shot generalization to unseen inputs by training on a large amount of diverse datasets**Wang et al., "Dataset Aggregation"**, or using the representation capabilities of generative models**Chen et al., "Generative Adversarial Networks"**.
Therefore, Ranftl et al.**Ranftl et al., "Robust Training Objective"**, propose a robust training objective to handle different depth scales and annotations.
Yang et al.**Yang et al., "Teacher-Student Approach"**, combine training on both labelled and unlabelled data using a teacher-student approach to obtain pseudo-labels for the great amount of unlabelled data. Thereafter, enhancement in finer details is accomplished by replacing the labelled real data with synthetic data**Henderson et al., "Synthetic Data Generation"**.
In contrast, Ke et al.**Ke et al., "Diffusion Model Finetuning"**, leverage the representation capabilities of pre-trained diffusion models to obtain improved generalizability in monocular depth estimation only finetuning on sythetic data.
In this work, we propose a method for uncertainty estimation for depth predictions of already trained models. Importantly, our auxiliary loss function makes our approach independent of whether the model is supervised or self-supervised trained. Furthermore, we demonstrate in our experiments that our gradient-based uncertainty is applicable to both convolutional and transformer-based models.