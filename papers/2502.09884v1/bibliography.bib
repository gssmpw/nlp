@article{konda2004convergence,
  title={Convergence rate of linear two-time-scale stochastic approximation},
  author={Konda, Vijay R and Tsitsiklis, John N},
  year={2004},
journal = {The Annals of Applied Probability},
publisher = {Institute of Mathematical Statistics},
}


@article{polyakJuditsky,
    author = {Polyak, B. T. and Juditsky, A. B.},
    title = {Acceleration of Stochastic Approximation by Averaging},
    journal = {SIAM Journal on Control and Optimization},
    volume = {30},
    number = {4},
    pages = {838-855},
    year = {1992},
}

@misc{thinhFastNonlinear2024,
      title={Fast Nonlinear Two-Time-Scale Stochastic Approximation: Achieving $O(1/k)$ Finite-Sample Complexity}, 
      author={Thinh T. Doan},
      year={2024},
      eprint={2401.12764},
      archivePrefix={arXiv},
      primaryClass={math.OC},
}

@misc{srikant2024CLT,
      title={Rates of Convergence in the Central Limit Theorem for Markov Chains, with an Application to TD Learning}, 
      author={R. Srikant},
      year={2024},
      eprint={2401.15719},
      archivePrefix={arXiv},
      primaryClass={math.PR},
}



@article{lancaster1970explicit,
  title={Explicit solutions of linear matrix equations},
  author={Lancaster, Peter},
  journal={SIAM review},
  volume={12},
  number={4},
  pages={544--566},
  year={1970},
  publisher={SIAM}
}

@inproceedings{kaledin2020finite,
  title={Finite time analysis of linear two-timescale stochastic approximation with Markovian noise},
  author={Kaledin, Maxim and Moulines, Eric and Naumov, Alexey and Tadic, Vladislav and Wai, Hoi-To},
  booktitle={Conference on Learning Theory},
  pages={2144--2203},
  year={2020},
  organization={PMLR}
}

@article{MatrixExponential,
author = {Moler, Cleve and Van Loan, Charles},
title = {Nineteen Dubious Ways to Compute the Exponential of a Matrix, Twenty-Five Years Later},
journal = {SIAM Review},
volume = {45},
number = {1},
pages = {3-49},
year = {2003},
}


@article{DEADMAN2016354,
title = {Taylor's theorem for matrix functions with applications to condition number estimation},
journal = {Linear Algebra and its Applications},
volume = {504},
pages = {354-371},
year = {2016},
issn = {0024-3795},
doi = {https://doi.org/10.1016/j.laa.2016.04.010},
url = {https://www.sciencedirect.com/science/article/pii/S0024379516300957},
author = {Edvin Deadman and Samuel D. Relton},
keywords = {Matrix function, Taylor polynomial, Remainder, Condition number, Pseudospectrum, Fréchet derivative},
abstract = {We derive an explicit formula for the remainder term of a Taylor polynomial of a matrix function. This formula generalizes a known result for the remainder of the Taylor polynomial for an analytic function of a complex scalar. We investigate some consequences of this result, which culminate in new upper bounds for the level-1 and level-2 condition numbers of a matrix function in terms of the pseudospectrum of the matrix. Numerical experiments show that, although the bounds can be pessimistic, they can be computed much faster than the standard methods. This makes the upper bounds ideal for a quick estimation of the condition number whilst a more accurate (and expensive) method can be used if further accuracy is required. They are also easily applicable to more complicated matrix functions for which no specialized condition number estimators are currently available.}
}

@misc{haque2023tightfinitetimebounds,
  title={Tight finite time bounds of two-time-scale linear stochastic approximation with markovian noise},
  author={Haque, Shaan Ul and Khodadadian, Sajad and Maguluri, Siva Theja},
  journal={arXiv preprint arXiv:2401.00364},
  year={2023}
}

@article{mokkadem2006convergence,
  title={Convergence rate and averaging of nonlinear two-time-scale stochastic approximation algorithms},
  author={Mokkadem, Abdelkader and Pelletier, Mariane},
  year={2006},
  journal = {The Annals of Applied Probability},
}



@misc{han2024finitetimedecoupledconvergencenonlinear,
  title={Finite-Time Decoupled Convergence in Nonlinear Two-Time-Scale Stochastic Approximation},
  author={Han, Yuze and Li, Xiang and Zhang, Zhihua},
  journal={arXiv preprint arXiv:2401.03893},
  year={2024}
}

@book{bhatia2009positive,
  title={Positive definite matrices},
  author={Bhatia, Rajendra},
  year={2009},
  publisher={Princeton university press}
}

@article{Theobald_1975, title={An inequality for the trace of the product of two symmetric matrices}, volume={77}, DOI={10.1017/S0305004100051070}, number={2}, journal={Mathematical Proceedings of the Cambridge Philosophical Society}, author={Theobald, C. M.}, year={1975}, pages={265–267}} <div></div>

@article{shebrawi2013trace,
  title={Trace inequalities for matrices},
  author={Shebrawi, Khalid and Albadawi, Hussien},
  journal={Bulletin of the Australian Mathematical Society},
  volume={87},
  number={1},
  pages={139--148},
  year={2013},
  publisher={Cambridge University Press}
}


@article{doan2022nonlinear,
  title={Nonlinear two-time-scale stochastic approximation: Convergence and finite-time performance},
  author={Doan, Thinh T},
  journal={IEEE Transactions on Automatic Control},
  year={2022},
  publisher={IEEE}
}

@inproceedings{zeng2024fast,
  title={Fast two-time-scale stochastic gradient method with applications in reinforcement learning},
  author={Zeng, Sihan and Doan, Thinh},
  booktitle={The Thirty Seventh Annual Conference on Learning Theory},
  pages={5166--5212},
  year={2024},
  organization={PMLR}
}

@inproceedings{dalal2018finite,
  title={Finite sample analysis of two-timescale stochastic approximation with applications to reinforcement learning},
  author={Dalal, Gal and Thoppe, Gugan and Sz{\"o}r{\'e}nyi, Bal{\'a}zs and Mannor, Shie},
  booktitle={Conference On Learning Theory},
  pages={1199--1233},
  year={2018},
  organization={PMLR}
}

@article{heusel2017gans,
  title={Gans trained by a two time-scale update rule converge to a local nash equilibrium},
  author={Heusel, Martin and Ramsauer, Hubert and Unterthiner, Thomas and Nessler, Bernhard and Hochreiter, Sepp},
  journal={Advances in neural information processing systems},
  volume={30},
  year={2017}
}

@article{shen2022single,
  title={A single-timescale analysis for stochastic approximation with multiple coupled sequences},
  author={Shen, Han and Chen, Tianyi},
  journal={Advances in Neural Information Processing Systems},
  volume={35},
  pages={17415--17429},
  year={2022}
}

@article{samsonov2024gaussian,
  title={Gaussian Approximation and Multiplier Bootstrap for Polyak-Ruppert Averaged Linear Stochastic Approximation with Applications to TD Learning},
  author={Samsonov, Sergey and Moulines, Eric and Shao, Qi-Man and Zhang, Zhuo-Song and Naumov, Alexey},
  journal={arXiv preprint arXiv:2405.16644},
  year={2024}
}

@article{durmus2024finite,
  title={Finite-Time High-Probability Bounds for Polyak--Ruppert Averaged Iterates of Linear Stochastic Approximation},
  author={Durmus, Alain and Moulines, Eric and Naumov, Alexey and Samsonov, Sergey},
  journal={Mathematics of Operations Research},
  year={2024},
  publisher={INFORMS}
}

@inproceedings{anastasiou2019normal,
  title={Normal approximation for stochastic gradient descent via non-asymptotic rates of martingale CLT},
  author={Anastasiou, Andreas and Balasubramanian, Krishnakumar and Erdogdu, Murat A},
  booktitle={Conference on Learning Theory},
  pages={115--137},
  year={2019},
  organization={PMLR}
}


@InProceedings{srikant19,
  title = 	 {Finite-Time Error Bounds For Linear Stochastic Approximation andTD Learning},
  author =       {Srikant, R. and Ying, Lei},
  booktitle = 	 {Proceedings of the Thirty-Second Conference on Learning Theory},
  pages = 	 {2803--2830},
  year = 	 {2019},
  volume = 	 {99},
  series = 	 {Proceedings of Machine Learning Research},
  month = 	 {25--28 Jun},
  publisher =    {PMLR},
  pdf = 	 {http://proceedings.mlr.press/v99/srikant19a/srikant19a.pdf},
}

@misc{mou2020linearstochasticapproximationfinegrained,
      title={On Linear Stochastic Approximation: Fine-grained Polyak-Ruppert and Non-Asymptotic Concentration}, 
      author={Wenlong Mou and Chris Junchi Li and Martin J. Wainwright and Peter L. Bartlett and Michael I. Jordan},
      year={2020},
      eprint={2004.04719},
      archivePrefix={arXiv},
      primaryClass={stat.ML},
}

@article{RobbinsMonro,
author = {Herbert Robbins and Sutton Monro},
title = {{A Stochastic Approximation Method}},
volume = {22},
journal = {The Annals of Mathematical Statistics},
number = {3},
publisher = {Institute of Mathematical Statistics},
pages = {400 -- 407},
year = {1951},
}

@article{polyak,
    author = {Boris T. Polyak},
    title = {New Stochastic Approximation Type Procedures},
    journal = {Automat. Remote Control},
    year ={1991}
}

@article{ruppert,
    author = {David Ruppert},
    title = {Efficient estimators from a slowly convergent Robbins-Monro process},
    journal = {Tech Report},
    year ={1988} 
}

@article{gadat2017optimal,
  title={Optimal non-asymptotic bound of the Ruppert-Polyak averaging without strong convexity},
  author={Gadat, S{\'e}bastien and Panloup, Fabien},
  journal={arXiv preprint arXiv:1709.03342},
  year={2017}
}

@book{bhatnagar2012stochastic,
  title={Stochastic Recursive Algorithms for Optimization: Simultaneous Perturbation Methods},
  author={Bhatnagar, S. and Prasad, H.L. and Prashanth, L.A.},
  isbn={9781447142850},
  series={Lecture Notes in Control and Information Sciences},
  year={2012},
  publisher={Springer London}
}

@inproceedings{harsh19,
 author = {Gupta, Harsh and Srikant, R. and Ying, Lei},
 booktitle = {Advances in Neural Information Processing Systems},
 pages = {},
 title = {Finite-Time Performance Bounds and Adaptive Learning Rate Selection for Two Time-Scale Reinforcement Learning},
 volume = {32},
 year = {2019}
}


@article{konda1999actor,
  title={Actor-critic--type learning algorithms for Markov decision processes},
  author={Konda, Vijaymohan R and Borkar, Vivek S},
  journal={SIAM Journal on control and Optimization},
  volume={38},
  number={1},
  pages={94--123},
  year={1999},
  publisher={SIAM}
}


@article{sutton2008convergent,
  title={A convergent $ o (n) $ temporal-difference algorithm for off-policy learning with linear function approximation},
  author={Sutton, Richard S and Maei, Hamid and Szepesv{\'a}ri, Csaba},
  journal={Advances in neural information processing systems},
  volume={21},
  year={2008}
}

@inproceedings{sutton2009fast,
  title={Fast gradient-descent methods for temporal-difference learning with linear function approximation},
  author={Sutton, Richard S and Maei, Hamid Reza and Precup, Doina and Bhatnagar, Shalabh and Silver, David and Szepesv{\'a}ri, Csaba and Wiewiora, Eric},
  booktitle={Proceedings of the 26th annual international conference on machine learning},
  pages={993--1000},
  year={2009}
}

@article{xu2019two,
  title={Two time-scale off-policy TD learning: Non-asymptotic analysis over Markovian samples},
  author={Xu, Tengyu and Zou, Shaofeng and Liang, Yingbin},
  journal={Advances in neural information processing systems},
  volume={32},
  year={2019}
}

@article{wu2020finite,
  title={A finite-time analysis of two time-scale actor-critic methods},
  author={Wu, Yue Frank and Zhang, Weitong and Xu, Pan and Gu, Quanquan},
  journal={Advances in Neural Information Processing Systems},
  volume={33},
  pages={17617--17628},
  year={2020}
}

@book{borkar2008stochastic,
  title={Stochastic approximation: a dynamical systems viewpoint},
  author={Borkar, Vivek S},
  volume={9},
  year={2008},
  publisher={Springer}
}

@article{zeng2024accelerated,
  title={Accelerated Multi-Time-Scale Stochastic Approximation: Optimal Complexity and Applications in Reinforcement Learning and Multi-Agent Games},
  author={Zeng, Sihan and Doan, Thinh T},
  journal={arXiv preprint arXiv:2409.07767},
  year={2024}
}

@inproceedings{tsypkin1974attainable,
  title={Attainable accuracy of adaptation algorithms},
  author={Tsypkin, Yakov Zalmanovich and Polyak, Boris Teodorovich},
  booktitle={Doklady Akademii Nauk},
  volume={218},
  number={3},
  pages={532--535},
  year={1974},
  organization={Russian Academy of Sciences}
}

@article{WeiNewtonEstimation,
author = {C. Z. Wei},
title = {{Multivariate Adaptive Stochastic Approximation}},
volume = {15},
journal = {The Annals of Statistics},
number = {3},
publisher = {Institute of Mathematical Statistics},
pages = {1115 -- 1130},
keywords = {Adaptive stochastic approximation, asymptotically efficient, Robbins-Monro process},
year = {1987},
doi = {10.1214/aos/1176350496},
}


@article{chen2022finite,
  title={Finite-sample analysis of nonlinear stochastic approximation with applications in reinforcement learning},
  author={Chen, Zaiwei and Zhang, Sheng and Doan, Thinh T and Clarke, John-Paul and Maguluri, Siva Theja},
  journal={Automatica},
  volume={146},
  pages={110623},
  year={2022},
  publisher={Elsevier}
}



@book{SBbook2018,
  title={Reinforcement Learning: An Introduction},
  author={Richard S. Sutton and Andrew G. Barto},
  year={2018},
  edition = {2nd},
  publisher = {MIT Press, Cambridge, MA},
}

@BOOK{BTbook1999,
   author = {Dimitri Bertsekas and John Tsitsiklis},
   title = {Neuro-Dynamic Programming},
   edition = {2nd},
   publisher = {Athena Scientific, Belmont, MA},
   year = {1999},
}

@BOOK{LanBook2020,
  title = {
Lectures on Optimization
Methods for Machine Learning},
   publisher = {Springer-Nature},
  author = 	 {Guanghui Lan},
  year={2020}, 
}
@article{zeng2022regularized,
  title={Regularized gradient descent ascent for two-player zero-sum Markov games},
  author={Zeng, Sihan and Doan, Thinh and Romberg, Justin},
  journal={Advances in Neural Information Processing Systems},
  volume={35},
  pages={34546--34558},
  year={2022}
}

@inproceedings{hu2024central,
  title={Central Limit Theorem for Two-Timescale Stochastic Approximation with Markovian Noise: Theory and Applications},
  author={Hu, Jie and Doshi, Vishwaraj and others},
  booktitle={International Conference on Artificial Intelligence and Statistics},
  pages={1477--1485},
  year={2024},
  organization={PMLR}
}