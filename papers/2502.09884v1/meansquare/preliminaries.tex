% \section{Problem Statement and Overview}
\section{Introduction}
% \tdoan{Outline}
% \begin{itemize}
%     \item A paragraph for SA, bringing the idea of P-R averaging.
%     \item A paragraph for two-time-scale SA (TSA) and its applications in optimization and RL
%     \item A few sentences discussing the existing results of TSA
%     \item State the main contributions
% \end{itemize}
Stochastic approximation (SA), introduced by \citep{RobbinsMonro}, is an iterative sample-based approach to find the root (or fixed point)  $x^{\star}$  of some unknown operator $F$. 
% In particular, SA iteratively updates $x$, an estimate of $x^{\star}$, by moving along the direction of the samples $F(x;\xi)$ of $F(x)$ scaled by some step size, where $\xi$ is a random variable representing sampling noise. 
In particular, SA iteratively updates $x$, an estimate of $x^{\star}$, by moving along the direction of the sample $F(x;\xi)$ scaled by some step size, where $\xi$ is a random variable representing sampling noise. 
The simplicity of its implementation has enabled broad applications in many areas including stochastic optimization, machine learning, and reinforcement learning \citep{SBbook2018,LanBook2020}. 
The convergence properties of SA are well-studied, where the error rate achieved by SA with Polyak-Ruppert (PR) averaging is known to decay faster than that of SA without PR averaging \citep{polyakJuditsky}. 




In this paper, we study the finite-time error rates of the linear two-time-scale SA (TSA) algorithm, a generalized variant of SA, for solving a system of two coupled linear equations, i.e., we seek to find a pair $(x^{*},y^{*})$ that solves 
\begin{align}\label{eq:problem}
\left\{\begin{array}{ll}
\mathbb{E}_{W}[A_{ff}x^{*}+A_{fs}y^{*}-W] = 0,\\
\mathbb{E}_{V}[A_{sf}x^{*}+A_{ss}y^{*}-V] = 0,
\end{array}\right.    
\end{align}
where $W, V$ are random vectors with unknown distributions and $A_{ff}, A_{fs}, A_{sf}, A_{ss}$ are the system parameters. 
In this setting, TSA iteratively updates $(x,y)$ as follows:
%
%Linear stochastic approximation is a framework for solving a linear system given access to noisy observations.  Many algorithms in machine learning can be formulated as stochastic approximation methods, where two iterates $x_t$ and $y_t$ are updated as
\begin{equation}
    \begin{split}
        x_{t+1} &= x_t - \alpha_t \left(A_{ff} x_t + A_{fs} y_t - W_t \right) \\ 
        y_{t+1} &= y_t - \gamma_t \left(A_{sf} x_t + A_{ss} y_t - V_t \right), 
    \end{split}
    \label{eq:ttsa_general}
\end{equation}
where $\{(W_t, V_t)\}$ is a martingale difference sequence representing the sampling noise. Here, $\alpha_{t}\gg\gamma_{t}$ are two different step sizes. The variable $x$ is often referred to as the fast-time-scale variable (using larger step sizes) while $y$ is called the slow-time-scale variable (using smaller step sizes).%, explaining for the name of two-time-scale SA. These two-step sizes have to be carefully designed to guarantee the convergence of TSA.       


% The step sizes $\{\alpha_t\}$ and $\{\gamma_t\}$ are to be designed so that the solution $(x^*, y^*)$ to the system $A$ with components $A_{ff}, A_{fs}, A_{sf}, A_{ss}$ is obtained, where $\{(W_t, V_t)\}$ is a martingale difference sequence. 


TSA has received a great amount of interest due to its application in many areas where the classic SA is not applicable. Prominent examples include gradient temporal-difference learning \citep{sutton2008convergent,sutton2009fast,xu2019two}, actor-critic methods in reinforcement learning \citep{konda1999actor,bhatnagar2012stochastic,harsh19,wu2020finite,zeng2024accelerated}, and gradient descent-ascent methods in min-max optimization for zero-sum games \citep{zeng2022regularized}. These methods require one iterate being updated using a smaller step size than the other to guarantee convergence.  




Unlike the literature on SA where convergence properties are well understood, theoretical results for TSA are not complete.
% While the benefit of using PR averaging has been established for SA \citep{polyakJuditsky}, a similar result has been studied for TSA in \citep{mokkadem2006convergence}, where only an asymptotic convergence in distribution to a non-zero limit was established.  
While the benefit of using PR averaging has been established for SA \citep{polyakJuditsky}, its benefit has only been demonstrated with respect to asymptotic convergence in distribution for TSA \citep{mokkadem2006convergence}.
In this paper, we focus on understanding the finite-time error rates at which the PR average of the iterates generated by TSA converge to the desired solution. 
% We use TSA to refer to the variables $(x_t, y_t)$ generated as in Eq. \ref{eq:ttsa_general}, to distinguish from TSA with PR averaging (TSA-PR) that produces $\bar{x}_n = n^{-1} \sum_{t=1}^n x_t$ and $\bar{y}_n = n^{-1} \sum_{t=1}^n y_t$.
We use TSA to refer to the sequence $\{(x_t, y_t)\}$ in Eq. \eqref{eq:ttsa_general} without Polyak-Ruppert averaging, to distinguish from TSA-PR which is used to refer to the averages $(\bar{x}_n, \bar{y}_n)$. 
\textbf{Our contributions} are summarized below. 
\vspace{-0.3cm}
\begin{enumerate}
    \item 
    We establish in Theorem \ref{thm:clt} a finite-time bound on the Wasserstein-1 distance between the scaled deviations $\sqrt{n}(\bar{x}_n - x^*)$ and $\sqrt{n}(\bar{y}_n - y^*)$ generated by TSA-PR and their Gaussian limits. 
    This is the first non-asymptotic central limit theorem (CLT) in the context of two-time-scale algorithms, complementing the asymptotic CLT established in \citep{mokkadem2006convergence}. 
    % {\color{red}Similar to the classical SA setting, we do not require the knowledge of the problem parameters to schedule the step sizes.}
    \vspace{-0.3cm}
 
    \item Our bound on the Wasserstein-1 distance implies that the expected error achieved by TSA-PR decays at rate $n^{-1/2}$ (Corollary \ref{cor:mae}), where error is defined to be the norms $\lVert \bar{x}_n - x^* \rVert$ and $\lVert \bar{y}_n - y^*\rVert$. 
    This rate significantly improves the rate achieved by TSA without PR averaging, as explained in Section \ref{sec:PR_TTSA} and Remark \ref{rem:comparison_with_mse}.\vspace{-0.3cm}

    \item In proving these results, we also establish in Theorem \ref{thm:mse} lower and upper bounds on the expected square error (MSE) achieved by TSA (i.e., without PR averaging). 
    When compared to similar bounds in prior works, our result provides a more convenient representation to establish our main results above while using a much simpler proof technique.      
    % This result may be of independent interest since there are a lot of prior work on TSA, but to the best of our knowledge, prior results specialized to our model provide weaker results.
    \vspace{-0.3cm}
    
    % The result captures both the magnitude of their second moments, as well as the rate at which the second moments converge to their asymptotic covariances. 
\end{enumerate}






\input{RelatedWork}

\section{Model and Preliminaries}\label{sec:preliminaries}
In this paper, we consider two time-scale stochastic approximation algorithms of the form
\begin{equation}
    \begin{split}
        x_{t+1} &= x_t - \alpha_t \left(A_{ff} x_t + A_{fs} y_t - W_t \right),
        \\
        y_{t+1} &= y_t - \gamma_t \left(A_{sf} x_t + A_{ss} y_t - V_t \right).
    \end{split}\label{eq:ttsa}
\end{equation}
While we do not consider the so-called ODE approach here to analyze the system, the assumptions on the system matrices in Eq. \eqref{eq:ttsa} are easy to explain by relating the above to a singularly perturbed differential equation (ODE); see \citep{borkar2008stochastic}:
\begin{equation}
    \dot{x}_t = - (A_{ff} x_t + A_{fs} y_t) , 
    \quad
    \dot{y}_t = - \frac{\gamma}{\alpha} \left(A_{sf} x_t + A_{ss} y_t \right).
\end{equation}
In the limit $\gamma/\alpha \to 0$, $x_t$ evolves much faster than $y_t$.
When the system governing $\dot{x}_t$ is stable, the slow-time-scale $y_t$ is analyzed assuming a stationary solution $x_\infty (y) = -A_{ff}^{-1} A_{fs} y$:
\begin{equation}
    \dot{y}_t = -\left(A_{sf} x_\infty (y_t) + A_{ss} y_t\right) 
    = -(A_{ss} - A_{sf} A_{ff}^{-1} A_{fs}) y_t
    .
\end{equation}
To ensure that both $x_t$ and $y_t$ converge to their respective limits, it is therefore assumed that $-A_{ff}$ and $-\Delta = -(A_{ss} - A_{sf} A_{ff}^{-1} A_{fs})$ are both H\"{u}rwitz stable, i.e., the eigenvalues lie in the left-half of the complex plane. 
The rates at which the discretized system in Eq. \eqref{eq:ttsa} approach their limits are studied under the same setting, which we now state formally. 
% Motivated by this ODE analysis, the same assumption is used for the convergence analysis of the discretized system in Eq. \eqref{eq:ttsa}.
% Next, we state a few standards assumptions used in the TTSA literature \cite{}.
% ***Clearly make the connection to TTSA*** Consider the root $x_\infty (y)$ that solves the fast system $F(x_\infty (y), y) = 0$ for every $y$.
% A closed form solution is given by $x_\infty (y) = - A_{ff}^{-1} A_{fs} y \eqqcolon H y$.
% Our first assumption is that the fast and slow systems are both asymptotically stable, i.e., $x_n \to x_\infty (y)$ whenever $y$ is fixed and $y_n \to y^*$ when $x_n$ is taken to be $x_\infty (y_n)$.
% When the solution $x_\infty (y)$ to the fast system $F(x, y) = 0$ can be solved for any $y$, $y^*$ is a global attractor for the slow system $S$ iff
% \begin{align*}
%     \hat{y} \coloneqq y - y^* = S(x_\infty (y), y) - S(x_{\infty}(y^*), y^*) =
%     (A_{ss} -A_{sf} A_{ff}^{-1} A_{fs}) \hat{y} 
% \end{align*}
% is stable for every $y$.
\begin{assumption}[System Parameters]\label{assumption:structure}\label{assumption:first}
    The matrix $A_{ff}$ and its Schur complement $\Delta = A_{ss} - A_{sf} A_{ff}^{-1} A_{fs}$ are real and satisfy 
    \begin{equation}
        A_{ff} + A_{ff}^T \succ 0, \quad \Delta + \Delta^T \succ 0 .
    \end{equation}
\end{assumption}
% In other words, $-A_{ff}, -\Delta$ are both H\"{u}rwitz stable. 
When a matrix $-A$ is H\"{u}rwitz stable, we use $\mu_A, \nu_A$ to denote the smallest and largest eigenvalues of $A + A^T$, respectively.







\begin{assumption}[Noise]\label{assumption:noise}
    Let $\{N_t\} \coloneqq \{(W_t, V_t)\}_{t=1}^\infty$ be a martingale difference sequence drawn independently of the iterates $x_t$ and $y_t$.
    We assume that for every $t \geq 1$, $\mathbb{E}\lVert N_t \rVert^{2 + \beta} < \infty$ for some $\beta \in (1/2, 1)$ and that
    \begin{align*}
        \mathbb{E} [W_t W_t^T | \historyprev] = \Gamma_{ff}, \mathbb{E} [V_t V_t^T | \historyprev] = \Gamma_{ss}, \mathbb{E} [W_t V_t^T | \historyprev] = \Gamma_{fs} ,
    \end{align*} 
    where  $\history = \{x_1, y_1, W_1, V_1, \cdots, W_t, V_t\}$ and $\Gamma$ is covariance matrix of $(W_t, V_t)$ conditioned on the history.
\end{assumption}
Our last assumption is a guidance on how to choose the step sizes.
\begin{assumption}[Step Size]\label{assumption:steps}\label{assumption:last}
    The step sizes are chosen to be $\alpha_t = \alpha_1 t^{-a}, \gamma_t = \gamma_1 t^{-b}$
    for $1/2 < a < b < 1$ and any $\alpha_1, \gamma_1 > 0$.
\end{assumption}
\begin{remark}
    Both $x_n$ and $y_n$ converge even when $b = 1$. 
    This parameter is crucial when deducing the $n^{-1}$ rate for the second moment of the slow-time-scale iterate. 
    As we will show that the Polyak-Ruppert averaging scheme achieves this fast rate for both fast- and slow-time-scale variables without having to set $b = 1$, we assume $b < 1$ which introduces minor technical conditions on the requirement for $\gamma_1$.
\end{remark}
Here we allow arbitrary $\alpha_1, \gamma_1 > 0$, but clarify a few technical conditions. 
Define $(\mu_{ff}, \nu_{ff})$ and $(\mu_\Delta, \nu_\Delta)$ such that $\mu_{ff} I \preceq A_{ff} + A_{ff}^T \preceq \nu_{ff} I$ and $\mu_\Delta I \preceq \Delta + \Delta^T \preceq \nu_\Delta I$.  
Because $\alpha_t, \gamma_t \to 0$ and $\gamma_t/\alpha_t \to 0$, there exists a time $t_0$ and problem-dependent constants $K_1, K_2, K_3$ such that the following holds for all $t \geq t_0$: 
\begin{align*}
    % \alpha_t &\leq \frac{2}{\mu_{ff}} , 
    \alpha_t &< K_1 \frac{\mu_{ff}}{\nu_{ff}^2} , 
    \quad 
    \gamma_t < K_2 \frac{\mu_{\Delta}}{\nu_\Delta^2} ,
    % \\ 
    \quad
    \frac{\gamma_t}{\alpha_t} = K_3 \min\left\{
        \frac{\mu_{ff}}{\nu_{ff}^2}, \frac{\mu_{\Delta}}{\nu_{\Delta}^2}
    \right\} .
    % \leq \min\left\{
    %     \frac{\mu_{ff}}{2 M_f},
    %     % \frac{M_g}{4 \mu_{ff}},
    %     \frac{\nu_{ff}}{4 M_g} ,
    %     \frac{2\mu_\Delta}{M_h}
    % \right\},  
    \numberthis \label{eq:initial_steps}
\end{align*}
% These conditions must be satisfied to ensure that the error rates do not increase.
% In many applications, it is hard to verify the above conditions because the system parameters are unknown. 
Since this condition will be satisfied at some finite-time $t_0$, the analysis in this paper holds for all $t \geq t_0.$ We set $t_0 = 1$ for simplicity of exposition.
% {\color{red}Include above: $\alpha_t, \gamma_t$ must be defined so that $\{L_t\}$ is well-defined, e.g. see \citep{kaledin2020finite}.
%     Note that their condition that $L_t \leq L_\infty$ (before Eq. 17) is fine but not strong enough; we can work from the recursion and prove when it is finite. 
% }




