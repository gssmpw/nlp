% \section{Mean Square Analysis of TTSA Last Iterates}
\section{Auxiliary Results}
In this section, we first present the derivation for \eqref{eq:recursion_expression}.
This expression will be used to derive the finite-time bounds on the second moments of $\tilde{x}_t$ and $\hat{y}_t$. 
Some useful properties of recurring quantities will be derived, before presenting the proof of Theorems \ref{thm:mse} and \ref{thm:clt}.


\input{proofs/recursion_derivation}



\subsection{Usage of Assumptions \ref{assumption:first}--\ref{assumption:last}}\label{sec:recursion}
Here we state a few elementary properties that will be used to prove Theorems \ref{thm:mse} and \ref{thm:clt}.
% useful in the analysis of mean square analysis.
We will express the difference between finite-time second moments and the asymptotic covariance as a contraction, and so we require that the contraction is well defined for symmetric matrices, rather than for definite matrices.  
The contraction that appears often is as follows. Given any matrix $A$, we denote $\|A\|$ is the matrix norm of $A$. Let $A$ satisfy $\mu I \preceq A + A^T \preceq \nu I$. Given any symmetric matrix $R$, we have
\begin{align*}
    R - \alpha (A R + R A^T)
    &= (I - \alpha A) R (I - \alpha A)^T - \alpha^2 A R A^T,
\end{align*}
which implies 
\begin{align*}
    % R - \alpha (A R + R A^T)
    % &= (I - \alpha A) R (I - \alpha A)^T - \alpha^2 A R A^T
    % \\
    % \Rightarrow 
    \lVert R - \alpha (A R + R A^T) \rVert &\leq \lVert I - \alpha A \rVert^2 \lVert R \rVert + \alpha^2 \lVert A R A^T \rVert.
\end{align*}
In addition, we have $\lVert A \rVert \leq \nu / 2$, which gives
\begin{align*}
    \lVert I - \alpha A \rVert^2 = \sup_{x \neq 0} \left(1 - \alpha \frac{x^T (A + A^T) x}{\lVert x \rVert^2} + \alpha^2 \frac{\lVert A x \rVert^2}{\lVert x \rVert^2}\right) 
    \leq 1 - \alpha \mu + \alpha^2 \lVert A \rVert^2.
\end{align*}
Thus, for $\alpha \leq \mu/\nu^2$ we obtain
\begin{equation}\label{eq:contraction}
    \lVert R - \alpha (A R + R A^T) \rVert 
    \leq 
    \left(1 - \alpha \mu + \alpha^2 \frac{\nu^2}{2}\right) \lVert R \rVert 
    \leq \left(1 - \alpha \frac{\mu}{2}\right)\lVert R \rVert     .
\end{equation}
% For a symmetric matrix $S$ and $\mu I \preceq A + A^T \preceq \nu I$, we have that 
% \begin{align*}
%     S - \alpha (AS + S A^T) = (I/2 - \alpha A) S + S (I/2 - \alpha A)^T ,
% \end{align*}
% and using Weyl's inequality to deduce that $\lambda_{\max} (A) \leq \nu/2$ and $\lVert I/2 - \alpha A\rVert \leq 1 - \alpha $

% When $\nu I \succeq A + A^T \succeq \mu I$ and $X \succeq 0$, we have by Lyapunov stability that 
% \begin{align*}
%     \nu X \succeq A X + X A^T \succeq \mu X .
% \end{align*}
% This can be seen by rearranging $(A + \mu/2 I) X + X (A + \mu/2 I)^T \succ 0$.
% Using this, we have that for a symmetric matrix $S$,
% \begin{align*}
%     \lVert S - (A S + S A^T)\rVert 
% \end{align*}
% {\color{red}Finish this part up and see if I'm using it correctly. }


Next, the choice of step size in Assumption \ref{assumption:steps} implies that
\begin{align*}
    \alpha_t - \alpha_{t+1} \leq \frac{\alpha_{t+1}}{t} ,
\end{align*}
obtained from the elementary inequality $(\frac{t+1}{t})^a \leq (1+\frac{1}{t})$ for every $a \in (0, 1]$. 
Moreover, this implies $\alpha_{t+1}^{-1} - \alpha_t^{-1} \leq (\alpha_{t} t)^{-1}$ and is also true for the sequence $\{\gamma_t\}$, which is tight for the range of values $a, b$ we consider. 

Finally, we derive a recursive bound for the absolute error of the second moments of fast and slow iterates from their asymptotic covariances.
After an induction step, the dominant rates are then obtained using Lemma 14 \citep{kaledin2020finite}, which states that for $\alpha_1 \mu_{ff}/4 \leq 1$ and constants
\begin{align*}
    \xi = 1 + \max \left\{\alpha_1 \frac{\mu_{ff}}{4}, \gamma_1 \frac{\mu_\Delta}{16} \right\},
    \quad 
    \xi' = \frac{8}{\mu_{ff}}\max \left\{\xi, \frac{\mu_{ff}}{4\mu_{\Delta}} \xi, 2 \xi^3
        \right\},
\end{align*}
it holds that
\begin{equation}
    \begin{split}
        \sum_{t=1}^n \gamma_t \prod_{j=t+1}^n \left(1 - \frac{\mu_{ff}}{4} \alpha_j\right) 
        \leq \xi' \frac{\gamma_{n}}{\alpha_n}
        \\
        \sum_{t=1}^n \alpha_t \gamma_t \prod_{j=t+1}^n \left(1 - \frac{\mu_{ff}}{4} \alpha_j\right) 
        \leq \xi' \gamma_{n}
        ,
        \\
        \sum_{t=1}^n \frac{\alpha_t}{t} \prod_{j=t+1}^n \left(1 - \frac{\mu_{ff}}{4} \alpha_j \right) 
        \leq 
        \xi' \frac{1}{n} .
    \end{split} 
    \label{eq:induction_size_equation}
\end{equation}
Variants of the above inequalities can also be deduced to be true, for example when $\gamma_t$ in the first inequality is replaced by $\gamma_t^2$. 

