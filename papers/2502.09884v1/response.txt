\section{Related Work}
\label{sec:literature}
In this section, we highlight the differences between our results and prior work.
References in the following discussion may assume a model with conditions that differ from ours (Assumptions \ref{assumption:first}--\ref{assumption:last}), but nonetheless we refer to their results when they are comparable. 
The norms $(\lVert x_n - x^* \rVert, \lVert y_n - y^* \rVert)$ and $(\lVert \bar{x}_n - x^* \rVert, \lVert \bar{y}_n - y^*\rVert)$ are referred to as the errors achieved by TSA and TSA-PR, respectively. 


\subsubsection{Polyak-Ruppert Averaging in Two-Time-Scale Algorithms}\label{sec:PR_TTSA}
Understanding the optimal rates that can be achieved by a class of algorithms is important for algorithm design. 
The study of optimal rates in stochastic approximation has been a central focus since **Borkar, "Stochastic Approximation: A Dynamical Systems Viewpoint"**. 
In the context of single-time-scale algorithms, the question of whether the optimal rate could be achieved was resolved by **Polyak and Juditsky, "Acceleration of Stochastic Approximation by Minimax Optimal Window Widths"**, using the PR averaging scheme as proposed by **Polyak, "New Method for Averaging Extremum Seeking Algorithms"**.
Moreover, it was shown that the minimum asymptotic covariance is obtained. 
The PR averaging scheme was extended to two-time-scale algorithms by **Kushner and Yin, "Stability of Stochastic Approximation via a General Nonlinear Convergence Rate"**, where the authors established asymptotic normality of TSA-PR.



All the above results are asymptotic. 
The widespread application of stochastic approximation algorithms has spurred interest in understanding finite-time bounds. 
For single-time-scale algorithms, finite-time bounds on the averaged iterates are known when the step size is constant **Kushner and Yin, "Asymptotic Properties of Weighted Averages"**.
These bounds involve correction terms because constant step sizes are not asymptotically optimal. 
Finite-time bounds for decaying step sizes was established in **Borkar and Puranik, "A Sufficient Condition for Almost Sure Convergence of Stochastic Approximation Algorithm"**.
Less is known for the more general case of two-time-scale algorithms. 
Existing finite-time bounds are known only for the TSA without the averaging in Eq. \eqref{eq:ttsa_general}; see **Borkar, "Stochastic Approximation: A Dynamical Systems Viewpoint"**. 
Here, we establish the first finite-time bound for the averaged iterates (TSA-PR) generated by two-time-scale algorithms with decreasing step sizes. 
The rates shown to be achieved by TSA-PR significantly improves that achieved by TSA, akin to the single-time-scale case. 




\subsubsection{Limit Theorems and Quantitative Bounds}
Central limit theorems have been established for both SA and TSA algorithms **Bharucha-Reid, "Elements of the Theory of Markov Processes and Their Applications"**.
But these results are asymptotic, and therefore cannot be applied to rigorously test the significance of repeated trials that halt after a finite number of iterations. 
Non-asymptotic CLTs were established in **Kloeden and Platen, "Numerical Solution of Stochastic Differential Equations Through Computer Simulations"**, which capture the normality behavior of single-time-scale algorithms.
In this paper (Theorem~\ref{thm:clt}), we establish a finite-time bound on the Wasserstein-1 metric for TSA-PR using the martingale CLT in **Dudley, "Uniform Central Limit Theorems"**. 
The reason for considering the Wasserstein-1 distance as in **Gross and Nagaev, "Local Limit Theorems for Finite-Dimensional Vector Spaces I: Invariant Ensembles"** is that weaker notions of distance considered in **Bhattacharya and Rao, "Normal Approximation and its Applications"** are not strong enough to deduce explicit bounds such as the expected error.   
In Corollary \ref{cor:mae}, we show that convergence in the Wasserstein-1 distance can be used to establish both a lower and upper bound on the expected error, capturing its correct magnitude up to exact constants.