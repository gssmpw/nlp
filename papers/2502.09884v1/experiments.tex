\section{Experiments}
In this section, we complement our theoretical results with simulations that demonstrate the numerical observation of the finite-time bounds and CLT behaviors as predicted by our theories.


\begin{figure}[thbp]
    \centering
    \begin{minipage}[th]{\textwidth}
        \centering
        \includegraphics[width=\linewidth]{figures/jan31/MAE_synthetic_scaled.png}
    \end{minipage}
    \vspace{-15pt}
    \caption{
    Errors achieved by TSA and TSA-PR when solving a synthetic system of equations with step sizes $\alpha_n=0.5/(n+1000)^{0.5}$, $\gamma_n=0.5/(n+1000)^{0.6}$. 
    Left: fast-time-scale. Right: slow-time-scale.
    Errors are scaled by $\sqrt{n}$ to compare the rates, where the upward movement of TSA curves indicates that both fast- and slow-time-scales suffer a slower rate of convergence. 
    % illustrates that its rate is slower than $n^{-1/2}$ for both fast- and slow-time-scales. 
    TSA-PR achieves the $n^{-1/2}$ error rate. 
    }
    \label{fig:synthetic}
\end{figure}

\noindent\textbf{Synthetic System of Equations.} 
% In our first set of experiments, we solve \eqref{eq:ttsa_general} in dimension $d=5$ with randomly generated system parameters $A_{ff},A_{fs},A_{sf},A_{ss}\in\mathbb{R}^d$ that satisfy Assumption~\ref{assumption:first}. For the covariance matrices, we take $\Gamma_{fs}=0$ and choose $\Gamma_{ss},\Gamma_{ff}$ according to $A_{ff},A_{fs},A_{sf},A_{ss}$ to make $\bar{\Sigma}_{ss}=I_{d\times d}$. We sample $W_t\sim N(0,\Gamma_{ff}),V_t\sim N(0,\Gamma_{ss})$ independently over time.
Our first set of experiments uses randomly generated system parameters $A_{ff},A_{fs},A_{sf},A_{ss}\in\mathbb{R}^{5\times 5}$ subject to the constraints in Assumption~\ref{assumption:structure}. 
The noise $\{(W_t, V_t)\}$ is sampled i.i.d. from the Gaussian distribution $\mathcal{N}(0, \Gamma)$ with $\Gamma_{fs} = 0$ and $\Gamma_{ff}, \Gamma_{ss}$ chosen to satisfy $\bar{\Sigma}_{ss} = I$ according to Eq. \eqref{eq:optimal_covariance}.


We implement TSA and TSA-PR with the step sizes $\alpha_n=0.5/(n+1000)^{0.5}$, $\gamma_n=0.5/(n+1000)^{0.6}$.
By Corollary \ref{cor:mae}, the errors $\lVert \bar{x}_n - x^*\rVert,\lVert \bar{y}_n - y^*\rVert$ achieved by TSA-PR are expected to decay with rate $1/\sqrt{n}$, whereas Theorem \ref{thm:mse} suggests that the errors $\lVert x_n - x^*\rVert,\lVert y_n - y^*\rVert$ achieved by TSA depend on the choice of step sizes and decay slower than $1/\sqrt{n}$. This is indeed observed in Figure \ref{fig:synthetic}, which plots the empirical errors scaled by $\sqrt{n}$, averaged over 100 trials. 
The TSA-PR curves for fast- and slow-time-scale variables exhibit downward movement, suggesting that $\|\bar{x}_n-x^{\star}\|$ and $\|\bar{y}_n-y^{\star}\|$ both decay with rate $\mathcal{O}(1/\sqrt{n})$. In comparison, the TSA curves move upward over iterations, which indicates that the iterates of TSA do not converge at an $1/\sqrt{n}$ rate.




According to Theorems \ref{thm:mse} and \ref{thm:clt}, the scaled deviation $\sqrt{n} (x_n-x^*, y_n-y^*)$ of TSA exhibits increasing variance as $n$ grows, whereas the scaled deviation $\sqrt{n} (\bar{x}_n-x^*, \bar{y}_n-y^*)$ of TSA-PR converges to a Gaussian distribution.
We visualize the deviations in Figure \ref{fig:clt} using a smoothed kernel density plot at three checkpoints (different values of $n$). 
For simplicity of illustration, we only plot the first coordinates of the slow variables $\sqrt{n}(y_n - y^*)$ and $\sqrt{n}(\bar{y}_n - y^*$). 
% The figure reveals that $\sqrt{n} (\bar{y}_n-y^*)$ indeed converges to a Gaussian distribution centered around the origin with standard deviation $1$, which is the asymptotic covariance predicted by Theorem~\ref{thm:clt}. The distribution of $\sqrt{n} (y_n-y^*)$ exhibits an increasing standard deviation over time, again matching the results in Theorem~\ref{thm:mse}.
The figure reveals that $\sqrt{n} (\bar{y}_n-y^*)$ indeed converges to a Gaussian distribution with standard deviation $1$, which is the asymptotic covariance predicted by Theorem~\ref{thm:clt}. The distribution of $\sqrt{n} (y_n-y^*)$ exhibits an increasing standard deviation over time, again matching the results in Theorem~\ref{thm:mse}.



\begin{figure}[thbp]
    \centering
    \begin{minipage}[t]{\textwidth}
        \centering
        \includegraphics[width=\linewidth]{figures/jan31/CLT1.png}
    \end{minipage}
    \vspace{-22pt}
    \caption{
        Gaussian behavior of slow-time-scale iterate around the solution $y^*$ with the choice of step sizes $\alpha_n=0.5/(n+1000)^{0.5}$, $\gamma_n=0.5/(n+1000)^{0.6}$.         
        As $n$ increases, the variance $\sqrt{n}(y_{n,1} - y_1^*)$ of TSA increases as suggested by Theorem \ref{thm:mse}, whereas that of TSA-PR converges and approaches 1.
        }
    \label{fig:clt}
\end{figure}


\noindent\textbf{Gradient-Based Policy Evaluation.} 
Temporal difference learning with gradient correction (TDC) is a gradient-based policy evaluation algorithm in RL which works stably with function approximation and off-policy sampling \citep{sutton2009fast}. 
% It can be regarded as a TSA method for solving the following system of equations:
% Its update can be expressed in the form Eq. \eqref{eq:problem} as
The algorithm seeks to solve the system of equations
\begin{align}
    \left\{\begin{array}{l}
         \mathbb{E}_{\pi}[\phi(s)\phi(s)^{\top}x - r(s, a)-\gamma \phi(s')^{\top} y \phi(s)+\phi(s)^{\top} y \phi(s)]=0 , \\
         \mathbb{E}_{\pi}[\gamma\phi(s')\phi(s)^{\top}x - r(s, a)-\gamma \phi(s')^{\top} y \phi(s)+\phi(s)^{\top} y \phi(s)]=0.
    \end{array}\right.
\end{align}
Here $x, y\in\mathbb{R}^d$ are the (fast- and slow-time-scale) variables, $s,a,s'$ denote the state, action, and next state, and $\phi(s)\in\mathbb{R}^d$ is the feature vector associated with state $s$. 
% More details on how two-time-scale stochastic approximation abstracts the TDC method can be found in \citep{xu2019two,zeng2024fast}.
% Details on how two-time-scale stochastic approximation abstracts the TDC method can be found in \citep{xu2019two,zeng2024fast}.
Details on how TDC can be expressed in the form Eq. \eqref{eq:ttsa_general} can be found in \citep{xu2019two,zeng2024fast}.


We employ TSA (equivalent to the standard TDC method in this case) and TSA-PR to evaluate the cumulative reward of a random policy under linear function approximation and off-policy samples collected by a uniform behavior policy. The reward function, transition kernel, and feature vectors are all randomly generated, with $d=10$. 
Figure~\ref{fig:TDC} compares the (scaled) errors of TSA and TSA-PR under the step sizes $\alpha_n=0.5/(n+1000)^{0.5}$, $\gamma_n=0.5/(n+1000)^{0.6}$, and again shows that the errors $\lVert \bar{x}_n - x^*\rVert,\lVert \bar{y}_n - y^*\rVert$ of TSA-PR converge with rate $1/\sqrt{n}$ while the errors $\lVert x_n - x^*\rVert,\lVert y_n - y^*\rVert$ of TSA do not converge as fast.

\begin{figure}[htbp]
    \centering
    \begin{minipage}[t]{\textwidth}
        \centering
        \includegraphics[width=\linewidth]{figures/jan31/MAE_TDC_scaled.png}
    \end{minipage}
    \vspace{-20pt}
    \caption{
    Scaled errors of TSA and TSA-PR for policy evaluation with the step sizes $\alpha_n=0.5/(n+1000)^{0.5}$, $\gamma_n=0.5/(n+1000)^{0.6}$. Left: fast-time-scale. Right: slow-time-scale.
    Again, the TSA curves move up over time, suggesting that both fast- and slow-time-scale errors decay at rate slower than $n^{-1/2}$. 
    In comparison, TSA-PR achieves the $n^{-1/2}$ error rate.}
    \label{fig:TDC}
\end{figure}




