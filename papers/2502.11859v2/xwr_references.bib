@misc{aghzalCanLargeLanguage2023,
  title = {Can Large Language Models Be Good Path Planners? {{A}} Benchmark and Investigation on Spatial-Temporal Reasoning},
  shorttitle = {Can Large Language Models Be Good Path Planners?},
  author = {Aghzal, Mohamed and Plaku, Erion and Yao, Ziyu},
  year = {2023},
  month = oct,
  journal = {arXiv.org},
  urldate = {2024-10-08},
  abstract = {Large language models (LLMs) have achieved remarkable success across a wide spectrum of tasks; however, they still face limitations in scenarios that demand long-term planning and spatial reasoning. To facilitate this line of research, in this work, we propose a new benchmark, termed \${\textbackslash}textbf\{P\}\$ath \${\textbackslash}textbf\{P\}\$lanning from \${\textbackslash}textbf\{N\}\$atural \${\textbackslash}textbf\{L\}\$anguage (\${\textbackslash}textbf\{PPNL\}\$). Our benchmark evaluates LLMs' spatial-temporal reasoning by formulating ''path planning'' tasks that require an LLM to navigate to target locations while avoiding obstacles and adhering to constraints. Leveraging this benchmark, we systematically investigate LLMs including GPT-4 via different few-shot prompting methodologies as well as BART and T5 of various sizes via fine-tuning. Our experimental results show the promise of few-shot GPT-4 in spatial reasoning, when it is prompted to reason and act interleavedly, although it still fails to perform long-term temporal reasoning. In contrast, while fine-tuned LLMs achieved impressive results on in-distribution reasoning tasks, they struggled to generalize to larger environments or environments with more obstacles.},
  howpublished = {https://arxiv.org/abs/2310.03249v2},
  langid = {english},
  file = {E:\OneDrive\Zotero Literature\参考文献\【会议论文】大模型空间认知\Aghzal 等 - 2023 - Can large language models be good path planners A benchmark and investigation on spatial-temporal r.pdf}
}

@article{alvarez-vargasSpatialAnxietyMediates2020,
  title = {Spatial Anxiety Mediates the Sex Difference in Adult Mental Rotation Test Performance},
  author = {{Alvarez-Vargas}, Daniela and Abad, Carla and Pruden, Shannon M.},
  year = {2020},
  month = dec,
  journal = {Cognitive Research: Principles and Implications},
  volume = {5},
  number = {1},
  pages = {31},
  issn = {2365-7464},
  doi = {10.1186/s41235-020-00231-8},
  urldate = {2024-11-07},
  abstract = {Abstract                            Mental rotation ability is associated with successful advances in STEM (science, technology, engineering, and mathematics) education and occupations. Meta-analyses have shown consistent sex disparities in mental rotation, where men outperform women on one measure of mental rotation ability, the               Mental Rotations Test               (               MRT               ). Spatial anxiety, or the fear and apprehension felt when completing a task that requires spatial thinking, was proposed as a mechanism explaining the relation between sex and mental rotation test performance. This study modified the               Spatial Anxiety Scale               (               SAS               ) to include questions about how anxious individuals feel when they must mentally rotate items to accomplish a task (e.g., playing Tetris). An exploratory factor analysis was conducted to assess the factorial structure of the modified spatial anxiety scale. Three factor loadings were extracted representing the ability to navigate, mentally rotate objects, and visualize objects. Furthermore, we analyzed the role of spatial anxiety and trait anxiety as potential mediators of the relation between participant sex and mental rotation performance. Spatial anxiety partially mediated the link between the sex of the participants and the MRT performance controlling for trait anxiety. Only navigation and mental rotation anxiety significantly mediated the relation between participant sex and mental rotation performance. We posit spatial anxiety as a barrier to efficient and accurate spatial thinking, and suggest that reducing spatial anxiety has the potential to improve spatial skills and reduce sex differences in mental rotation test performance. To ascertain this, an experimental design can determine whether a reduction in spatial anxiety causes changes in mental rotation test scores.},
  langid = {english},
  file = {E:\OneDrive\Zotero Literature\论文项目参考文献\2024【会议】大模型空间认知\Alvarez-Vargas 等 - 2020 - Spatial anxiety mediates the sex difference in adult mental rotation test performance.pdf}
}

@article{atitSituatingSpaceUsing2020,
  title = {Situating Space: Using a Discipline-Focused Lens to Examine Spatial Thinking Skills},
  shorttitle = {Situating Space},
  author = {Atit, Kinnari and Uttal, David H. and Stieff, Mike},
  year = {2020},
  month = apr,
  journal = {Cognitive Research: Principles and Implications},
  volume = {5},
  number = {1},
  pages = {19},
  issn = {2365-7464},
  doi = {10.1186/s41235-020-00210-z},
  urldate = {2024-11-07},
  abstract = {Spatial skills are an important component of success in science, technology, engineering, and math (STEM) fields. A majority of what we know about spatial skills today is a result of more than 100\,years of research focused on understanding and identifying the kinds of skills that make up this skill set. Over the last two decades, the field has recognized that, unlike the spatial skills measured by psychometric tests developed by psychology researchers, the spatial problems faced by STEM experts vary widely and are multifaceted. Thus, many psychological researchers have embraced an interdisciplinary approach to studying spatial thinking with the aim of understanding the nature of this skill set as it occurs within STEM disciplines. In a parallel effort, discipline-based education researchers specializing in STEM domains have focused much of their research on understanding how to bolster students' skills in completing domain-specific spatial tasks. In this paper, we discuss four lessons learned from these two programs of research to enhance the field's understanding of spatial thinking in STEM domains. We demonstrate each contribution by aligning findings from research on three distinct STEM disciplines: structural geology, surgery, and organic chemistry. Lastly, we discuss the potential implications of these contributions to STEM education.},
  keywords = {Discipline-based education research,Expertise,Interdisciplinary research,Spatial skills,STEM education},
  annotation = {TLDR: Four lessons learned from two programs of research on how to bolster students' skills in completing domain-specific spatial tasks are discussed to enhance the field's understanding of spatial thinking in STEM domains.},
  file = {E\:\\OneDrive\\Zotero Literature\\论文项目参考文献\\2024【会议】大模型空间认知\\Atit 等 - 2020 - Situating space using a discipline-focused lens to examine spatial thinking skills.pdf;C\:\\Users\\wenruixu\\Zotero\\storage\\6B8MRE9T\\s41235-020-00210-z.html}
}

@misc{baiQwenVLFrontierLarge2023,
  title = {Qwen-{{VL}}: A Frontier Large Vision-Language Model with Versatile Abilities},
  shorttitle = {Qwen-{{VL}}},
  author = {Bai, Jinze and Bai, Shuai and Yang, Shusheng and Wang, Shijie and Tan, Sinan and Wang, Peng and Lin, Junyang and Zhou, Chang and Zhou, Jingren},
  year = {2023},
  month = aug,
  number = {arXiv:2308.12966},
  eprint = {2308.12966},
  primaryclass = {cs},
  publisher = {arXiv},
  doi = {10.48550/arXiv.2308.12966},
  urldate = {2024-12-13},
  abstract = {We introduce the Qwen-VL series, a set of large-scale vision-language models designed to perceive and understand both text and images. Comprising Qwen-VL and Qwen-VL-Chat, these models exhibit remarkable performance in tasks like image captioning, question answering, visual localization, and flexible interaction. The evaluation covers a wide range of tasks including zero-shot captioning, visual or document visual question answering, and grounding. We demonstrate the Qwen-VL outperforms existing Large Vision Language Models (LVLMs). We present their architecture, training, capabilities, and performance, highlighting their contributions to advancing multimodal artificial intelligence. Code, demo and models are available at https://github.com/QwenLM/Qwen-VL.},
  archiveprefix = {arXiv},
  langid = {english},
  keywords = {Computer Science - Computation and Language,Computer Science - Computer Vision and Pattern Recognition},
  annotation = {TLDR: The Qwen-VL series is introduced, a set of large-scale vision-language models designed to perceive and understand both text and images that outperforms existing Large Vision Language Models (LVLMs).},
  file = {E\:\\OneDrive\\Zotero Literature\\论文项目参考文献\\2024【会议】大模型空间认知\\Bai 等 - 2023 - Qwen-VL a frontier large vision-language model with versatile abilities.pdf;C\:\\Users\\wenruixu\\Zotero\\storage\\JUP7EE8A\\2308.html}
}

@misc{bangMultitaskMultilingualMultimodal2023,
  title = {A Multitask, Multilingual, Multimodal Evaluation of {{ChatGPT}} on Reasoning, Hallucination, and Interactivity},
  author = {Bang, Yejin and Cahyawijaya, Samuel and Lee, Nayeon and Dai, Wenliang and Su, Dan and Wilie, Bryan and Lovenia, Holy and Ji, Ziwei and Yu, Tiezheng and Chung, Willy and Do, Quyet V. and Xu, Yan and Fung, Pascale},
  year = {2023},
  month = nov,
  number = {arXiv:2302.04023},
  eprint = {2302.04023},
  primaryclass = {cs},
  publisher = {arXiv},
  doi = {10.48550/arXiv.2302.04023},
  urldate = {2024-12-15},
  abstract = {This paper proposes a framework for quantitatively evaluating interactive LLMs such as ChatGPT using publicly available data sets. We carry out an extensive technical evaluation of ChatGPT using 23 data sets covering 8 different common NLP application tasks. We evaluate the multitask, multilingual and multi-modal aspects of ChatGPT based on these data sets and a newly designed multimodal dataset. We find that ChatGPT outperforms LLMs with zero-shot learning on most tasks and even outperforms fine-tuned models on some tasks. We find that it is better at understanding non-Latin script languages than generating them. It is able to generate multimodal content from textual prompts, via an intermediate code generation step. Moreover, we find that ChatGPT is 63.41\% accurate on average in 10 different reasoning categories under logical reasoning, non-textual reasoning, and commonsense reasoning, hence making it an unreliable reasoner. It is, for example, better at deductive than inductive reasoning. ChatGPT suffers from hallucination problems like other LLMs and it generates more extrinsic hallucinations from its parametric memory as it does not have access to an external knowledge base. Finally, the interactive feature of ChatGPT enables human collaboration with the underlying LLM to improve its performance, i.e, 8\% ROUGE-1 on summarization and 2\% ChrF++ on machine translation, in a multi-turn "prompt engineering" fashion. We also release codebase for evaluation set extraction.},
  archiveprefix = {arXiv},
  langid = {english},
  keywords = {Computer Science - Artificial Intelligence,Computer Science - Computation and Language},
  file = {E\:\\OneDrive\\Zotero Literature\\论文项目参考文献\\2024【会议】大模型空间认知\\Bang 等 - 2023 - A multitask, multilingual, multimodal evaluation of ChatGPT on reasoning, hallucination, and interac.pdf;C\:\\Users\\wenruixu\\Zotero\\storage\\BAUTKVDN\\2302.html}
}

@article{bartlettGenderDifferencesSpatial2023,
  title = {Gender Differences in Spatial Ability: A Critical Review},
  shorttitle = {Gender Differences in Spatial Ability},
  author = {Bartlett, Kristin A. and Camba, Jorge D.},
  year = {2023},
  month = jan,
  journal = {Educational Psychology Review},
  volume = {35},
  number = {1},
  pages = {8},
  issn = {1573-336X},
  doi = {10.1007/s10648-023-09728-2},
  urldate = {2024-10-24},
  abstract = {Spatial ability has long been regarded as important in STEM, and mental rotation, a subcategory of spatial ability, is widely accepted as the cognitive ability with the largest gender difference in favor of men. Multiple meta-analyses of various tests of spatial ability have found large gender differences in outcomes of the mental rotation test (MRT). In this paper, we argue that more recent literature suggests that the MRT is not a valid measure of mental rotation ability. More importantly, we argue that the construct of ``spatial ability'' itself has been co-constructed with gender, and thus has not been devised in a neutral way, but in a manner that is influenced by gender beliefs. We discuss that though spatial thinking is also required in feminized fields, past research has cast spatial ability as only necessary in masculinized STEM fields. Due to a prevailing belief that spatial ability was an inherently male ability, researchers ``selectively bred'' some spatial assessment instruments to maximize gender differences, rather than to precisely measure a spatial construct. We argue that such instruments, of which the MRT is one, cannot validly assess between-group differences, and ideas about biological or evolutionary causes of sex differences in spatial ability lack empirical evidence. Instead, the co-construction of gender and spatial ability better explains observed patterns. We also provide recommendations for spatial researchers moving forward.},
  langid = {english},
  keywords = {Gender differences,Mental rotation,Sex differences,Spatial ability,Spatial cognition},
  file = {E:\OneDrive\Zotero Literature\论文项目参考文献\2024【会议】大模型空间认知\Bartlett和Camba - 2023 - Gender differences in spatial ability a critical review.pdf}
}

@article{ben-chaimDevelopmentAnalysisSpatial1986,
  title = {Development and Analysis of a Spatial Visualization Test for Middle School Boys and Girls},
  author = {{Ben-Chaim}, D. and Lappan, G. and Houang, R. T.},
  year = {1986},
  month = oct,
  journal = {Perceptual and Motor Skills},
  volume = {63},
  number = {2 Pt 1},
  pages = {659--669},
  issn = {0031-5125},
  doi = {10.2466/pms.1986.63.2.659},
  abstract = {The development of a paper-and-pencil spatial-visualization test for middle school students is reported. The test consists of 32 multiple-choice items of 10 different types. The basic figures for the stimuli and the responses for the items vary from flat views, to numerical data, to corner views of "buildings" constructed from small cubes. The test was administered to a sample of 674 boys and 676 girls in Grades 5 through 8 from three sites representing a broad range of socioeconomic background. The reliability coefficients for various groups of students ranged from .72 to .86. The test-retest reliability coefficient for 73 students was .79. Site, grade, and sex differences, consistent with many other reports, were found. For additional 582 students in Grades 8 to 12 at two sites scores correlated .61 and .66 with scores of the Differential Aptitude Space Relations Test.},
  langid = {english},
  pmid = {3774472},
  keywords = {Child,Child Development,Concept Formation,Female,Form Perception,Humans,Male,Orientation,Psychological Tests,Space Perception},
  annotation = {TLDR: The development of a paper-and-pencil spatial-visualization test for middle school students is repotted and site, grade, and sex differences, consistent with many other reports, were found.},
  file = {E:\OneDrive\Zotero Literature\论文项目参考文献\2024【会议】大模型空间认知\Ben-Chaim 等 - 1986 - Development and analysis of a spatial visualization test for middle school boys and girls.pdf}
}

@inproceedings{Bennett2012TheDA,
  title = {The Differential Aptitude Test : A Review and Critique},
  author = {Bennett, George K. and Seashore, Harold G. and Wesman, Alexander G.},
  year = {2012},
  langid = {english}
}

@article{berkowitzSpatialAbilitiesArchitecture2021,
  title = {Spatial {{Abilities}} for {{Architecture}}: {{Cross Sectional}} and {{Longitudinal Assessment With Novel}} and {{Existing Spatial Ability Tests}}},
  shorttitle = {Spatial {{Abilities}} for {{Architecture}}},
  author = {Berkowitz, Michal and Gerber, Andri and Thurn, Christian M. and Emo, Beatrix and Hoelscher, Christoph and Stern, Elsbeth},
  year = {2021},
  month = feb,
  journal = {Frontiers in Psychology},
  volume = {11},
  publisher = {Frontiers},
  issn = {1664-1078},
  doi = {10.3389/fpsyg.2020.609363},
  urldate = {2024-11-07},
  abstract = {{$<$}p{$>$}This study examined individual differences in spatial abilities of architecture students. Students at different educational levels were assessed on spatial ability tests that varied in their domain-specificity to architecture, with the hypothesis that larger differences between beginner and advanced students will emerge on more domain-specific tests. We also investigated gender differences in test performance and controlled for general reasoning ability across analyses. In a cross sectional study, master students ({$<$}italic{$>$}N{$<$}/italic{$>$} = 91) outperformed beginners ({$<$}italic{$>$}N{$<$}/italic{$>$} = 502) on two novel tests involving perspective taking and object composition, as well as on a standardized visualization of cross-sections test, but not on a standardized mental rotations test. Longitudinally ({$<$}italic{$>$}N{$<$}/italic{$>$} = 117), spatial performance improved after the first bachelor year on visualization of cross-sections, object composition and mental rotation. Although both genders showed higher spatial test performance with increased experience, male students outperformed females across tests and levels of education. The results overall confirmed improvements in spatial performance during architecture studies, with partial support for the domain-specificity hypothesis. A gender gap among advanced students calls for further examining architecture-specific spatial thinking.{$<$}/p{$>$}},
  langid = {english},
  keywords = {architecture,gender,Higher educaction,spatial abilities,Test performance},
  annotation = {TLDR: Improvements in spatial performance during architecture studies were confirmed, with partial support for the domain-specificity hypothesis, and a gender gap among advanced students calls for further examining architecture-specific spatial thinking.},
  file = {E:\OneDrive\Zotero Literature\论文项目参考文献\2024【会议】大模型空间认知\Berkowitz 等 - 2021 - Spatial Abilities for Architecture Cross Sectional and Longitudinal Assessment With Novel and Exist.pdf}
}

@article{bodnerPurdueVisualizationRotations1997,
  title = {The Purdue Visualization of Rotations Test},
  author = {Bodner, George and Guay, Roland},
  year = {1997},
  month = oct,
  journal = {Chemical Educator},
  volume = {2},
  pages = {1--17},
  doi = {10.1007/s00897970138a},
  abstract = {This paper probes the relationship between the psychometric construct known as spatial ability and students performance in introductory chemistry courses. It examines some of the early literature on the evolution of the concept of spatial ability, reviews the results of research on the relationship between success (or failure) in introductory chemistry courses and students spatial ability, and describes a spatial ability test known as The Purdue Visualization of Rotations (ROT) test that has been shown to be among the spatial ability tests whose results are least likely to be complicated by analytical processing.},
  langid = {english},
  annotation = {TLDR: A spatial ability test known as The Purdue Visualization of Rotations (ROT) test that has been shown to be among the spatial ability tests whose results are least likely to be complicated by analytical processing is described.},
  file = {E:\OneDrive\Zotero Literature\论文项目参考文献\2024【会议】大模型空间认知\Bodner和Guay - 1997 - The purdue visualization of rotations test.pdf}
}

@article{bornsteinFramesMindTheory1986,
  title = {Frames of Mind: The Theory of Multiple Intelligences},
  shorttitle = {Frames of Mind},
  author = {Bornstein, Marc H. and Gardner, Howard},
  year = {1986},
  journal = {Journal of Aesthetic Education},
  volume = {20},
  number = {2},
  eprint = {3332707},
  eprinttype = {jstor},
  pages = {120},
  issn = {00218510},
  doi = {10.2307/3332707},
  urldate = {2024-10-24},
  langid = {english},
  annotation = {TLDR: The Tenth Anniversary Edition of Intelligence explains the development of intelligence in the 21st Century through the applications of language, linguistics, mathematics, and more.},
  file = {E:\OneDrive\Zotero Literature\论文项目参考文献\2024【会议】大模型空间认知\Bornstein和Gardner - 1986 - Frames of mind the theory of multiple intelligences.pdf}
}

@article{caemmererIndividualIntelligenceTests2020,
  title = {Beyond Individual Intelligence Tests: Application of Cattell-Horn-Carroll Theory},
  shorttitle = {Beyond Individual Intelligence Tests},
  author = {Caemmerer, Jacqueline M. and Keith, Timothy Z. and Reynolds, Matthew R.},
  year = {2020},
  month = mar,
  journal = {Intelligence},
  volume = {79},
  pages = {101433},
  issn = {01602896},
  doi = {10.1016/j.intell.2020.101433},
  urldate = {2024-10-24},
  langid = {english},
  file = {E:\OneDrive\Zotero Literature\论文项目参考文献\2024【会议】大模型空间认知\Caemmerer 等 - 2020 - Beyond individual intelligence tests application of cattell-horn-carroll theory.pdf}
}

@misc{caiSpatialBotPreciseSpatial2024,
  title = {{{SpatialBot}}: Precise Spatial Understanding with Vision Language Models},
  shorttitle = {{{SpatialBot}}},
  author = {Cai, Wenxiao and Ponomarenko, Iaroslav and Yuan, Jianhao and Li, Xiaoqi and Yang, Wankou and Dong, Hao and Zhao, Bo},
  year = {2024},
  month = sep,
  number = {arXiv:2406.13642},
  eprint = {2406.13642},
  publisher = {arXiv},
  doi = {10.48550/arXiv.2406.13642},
  urldate = {2024-10-24},
  abstract = {Vision Language Models (VLMs) have achieved impressive performance in 2D image understanding, however they are still struggling with spatial understanding which is the foundation of Embodied AI. In this paper, we propose SpatialBot for better spatial understanding by feeding both RGB and depth images. Additionally, we have constructed the SpatialQA dataset, which involves multi-level depth-related questions to train VLMs for depth understanding. Finally, we present SpatialBench to comprehensively evaluate VLMs' capabilities in spatial understanding at different levels. Extensive experiments on our spatial-understanding benchmark, general VLM benchmarks and Embodied AI tasks, demonstrate the remarkable improvements of SpatialBot trained on SpatialQA. The model, code and data are available at https://github.com/BAAI-DCAI/SpatialBot.},
  archiveprefix = {arXiv},
  langid = {english},
  keywords = {Computer Science - Computer Vision and Pattern Recognition},
  annotation = {TLDR: This paper proposes SpatialBot for better spatial understanding by feeding both RGB and depth images and constructed the SpatialQA dataset, which involves multi-level depth-related questions to train VLMs for depth understanding.},
  file = {E\:\\OneDrive\\Zotero Literature\\论文项目参考文献\\2024【会议】大模型空间认知\\Cai 等 - 2024 - SpatialBot precise spatial understanding with vision language models.pdf;C\:\\Users\\wenruixu\\Zotero\\storage\\5NU5EL84\\2406.html}
}

@book{carrollHumanCognitiveAbilities1993,
  title = {Human {{Cognitive Abilities}}: {{A Survey}} of {{Factor-Analytic Studies}}},
  shorttitle = {Human {{Cognitive Abilities}}},
  author = {Carroll, John B.},
  year = {1993},
  publisher = {Cambridge University Press},
  address = {Cambridge},
  doi = {10.1017/CBO9780511571312},
  urldate = {2024-11-07},
  abstract = {This 1993 work surveys and summarizes the results of more than seventy years of investigation, by factor analysis, of a variety of cognitive abilities, with particular attention to language, thinking, memory, visual and auditory perception, creativity and the production of ideas, and the speed and accuracy of mental processing. The author describes his detailed findings resulting from reanalysis of more than 460 data sets from the factor-analytic literature, followed by a presentation of a hierarchical, three-stratum theory of cognitive ability and its implications for further research. A set of three computer disks (IBM 3-1/2\&quot; 1.4 megabytes, ASCII format) containing the numerical data sets and Dr. Carroll's statistical results is also available. Representing over 4 megabytes of data or roughly 2000 printed pages the disks are major resources for the interested researcher.},
  isbn = {978-0-521-38275-5},
  langid = {english},
  file = {E\:\\OneDrive\\Zotero Literature\\论文项目参考文献\\2024【会议】大模型空间认知\\Carroll - 1993 - Human Cognitive Abilities A Survey of Factor-Analytic Studies.pdf;C\:\\Users\\wenruixu\\Zotero\\storage\\BTVNTE7D\\F83D5EADF14A453F6350FF3DD39631C8.html;C\:\\Users\\wenruixu\\Zotero\\storage\\KJAC8M6R\\F83D5EADF14A453F6350FF3DD39631C8.html}
}

@article{cattellTheoryFluidCrystallized1963,
  title = {Theory of Fluid and Crystallized Intelligence: A Critical Experiment},
  shorttitle = {Theory of Fluid and Crystallized Intelligence},
  author = {Cattell, Raymond B.},
  year = {1963},
  month = feb,
  journal = {Journal of Educational Psychology},
  volume = {54},
  number = {1},
  pages = {1--22},
  issn = {1939-2176, 0022-0663},
  doi = {10.1037/h0046743},
  urldate = {2024-10-24},
  langid = {english},
  file = {E:\OneDrive\Zotero Literature\论文项目参考文献\2024【会议】大模型空间认知\Cattell - 1963 - Theory of fluid and crystallized intelligence a critical experiment.pdf}
}

@misc{changSurveyEvaluationLarge2023,
  title = {A {{Survey}} on {{Evaluation}} of {{Large Language Models}}},
  author = {Chang, Yupeng and Wang, Xu and Wang, Jindong and Wu, Yuan and Yang, Linyi and Zhu, Kaijie and Chen, Hao and Yi, Xiaoyuan and Wang, Cunxiang and Wang, Yidong and Ye, Wei and Zhang, Yue and Chang, Yi and Yu, Philip S. and Yang, Qiang and Xie, Xing},
  year = {2023},
  month = dec,
  number = {arXiv:2307.03109},
  eprint = {2307.03109},
  publisher = {arXiv},
  doi = {10.48550/arXiv.2307.03109},
  urldate = {2024-11-07},
  abstract = {Large language models (LLMs) are gaining increasing popularity in both academia and industry, owing to their unprecedented performance in various applications. As LLMs continue to play a vital role in both research and daily use, their evaluation becomes increasingly critical, not only at the task level, but also at the society level for better understanding of their potential risks. Over the past years, significant efforts have been made to examine LLMs from various perspectives. This paper presents a comprehensive review of these evaluation methods for LLMs, focusing on three key dimensions: what to evaluate, where to evaluate, and how to evaluate. Firstly, we provide an overview from the perspective of evaluation tasks, encompassing general natural language processing tasks, reasoning, medical usage, ethics, educations, natural and social sciences, agent applications, and other areas. Secondly, we answer the `where' and `how' questions by diving into the evaluation methods and benchmarks, which serve as crucial components in assessing performance of LLMs. Then, we summarize the success and failure cases of LLMs in different tasks. Finally, we shed light on several future challenges that lie ahead in LLMs evaluation. Our aim is to offer invaluable insights to researchers in the realm of LLMs evaluation, thereby aiding the development of more proficient LLMs. Our key point is that evaluation should be treated as an essential discipline to better assist the development of LLMs. We consistently maintain the related open-source materials at: https://github.com/MLGroupJLU/LLM-eval-survey.},
  archiveprefix = {arXiv},
  langid = {american},
  keywords = {,Computer Science - Artificial Intelligence,Computer Science - Computation and Language},
  file = {E\:\\OneDrive\\Zotero Literature\\论文项目参考文献\\2024【会议】大模型空间认知\\Chang 等 - 2023 - A Survey on Evaluation of Large Language Models.pdf;C\:\\Users\\wenruixu\\Zotero\\storage\\WCLJ93HZ\\2307.html}
}

@misc{chenHowFarAre2024,
  title = {How Far Are We to {{GPT-4V}}? {{Closing}} the Gap to Commercial Multimodal Models with Open-Source Suites},
  shorttitle = {How Far Are We to {{GPT-4V}}?},
  author = {Chen, Zhe and Wang, Weiyun and Tian, Hao and Ye, Shenglong and Gao, Zhangwei and Cui, Erfei and Tong, Wenwen and Hu, Kongzhi and Luo, Jiapeng and Ma, Zheng and Ma, Ji and Wang, Jiaqi and Dong, Xiaoyi and Yan, Hang and Guo, Hewei and He, Conghui and Shi, Botian and Jin, Zhenjiang and Xu, Chao and Wang, Bin and Wei, Xingjian and Li, Wei and Zhang, Wenjian and Zhang, Bo and Cai, Pinlong and Wen, Licheng and Yan, Xiangchao and Dou, Min and Lu, Lewei and Zhu, Xizhou and Lu, Tong and Lin, Dahua and Qiao, Yu and Dai, Jifeng and Wang, Wenhai},
  year = {2024},
  month = apr,
  number = {arXiv:2404.16821},
  eprint = {2404.16821},
  primaryclass = {cs},
  publisher = {arXiv},
  doi = {10.48550/arXiv.2404.16821},
  urldate = {2024-12-13},
  abstract = {In this report, we introduce InternVL 1.5, an open-source multimodal large language model (MLLM) to bridge the capability gap between open-source and proprietary commercial models in multimodal understanding. We introduce three simple improvements: (1) Strong Vision Encoder: we explored a continuous learning strategy for the large-scale vision foundation model -- InternViT-6B, boosting its visual understanding capabilities, and making it can be transferred and reused in different LLMs. (2) Dynamic High-Resolution: we divide images into tiles ranging from 1 to 40 of 448\${\textbackslash}times\$448 pixels according to the aspect ratio and resolution of the input images, which supports up to 4K resolution input. (3) High-Quality Bilingual Dataset: we carefully collected a high-quality bilingual dataset that covers common scenes, document images, and annotated them with English and Chinese question-answer pairs, significantly enhancing performance in OCR- and Chinese-related tasks. We evaluate InternVL 1.5 through a series of benchmarks and comparative studies. Compared to both open-source and proprietary models, InternVL 1.5 shows competitive performance, achieving state-of-the-art results in 8 of 18 benchmarks. Code has been released at https://github.com/OpenGVLab/InternVL.},
  archiveprefix = {arXiv},
  langid = {english},
  keywords = {Computer Science - Computer Vision and Pattern Recognition},
  annotation = {TLDR: InternVL 1.5, an open-source multimodal large language model (MLLM) to bridge the capability gap between open-source and proprietary commercial models in multimodal understanding, shows competitive performance, achieving state-of-the-art results in 8 of 18 benchmarks.},
  file = {E\:\\OneDrive\\Zotero Literature\\论文项目参考文献\\2024【会议】大模型空间认知\\Chen 等 - 2024 - How far are we to GPT-4V Closing the gap to commercial multimodal models with open-source suites.pdf;C\:\\Users\\wenruixu\\Zotero\\storage\\RKPPAGHN\\2404.html}
}

@inproceedings{chenSpatialVLMEndowingVisionLanguage2024,
  title = {{{SpatialVLM}}: {{Endowing Vision-Language Models}} with {{Spatial Reasoning Capabilities}}},
  shorttitle = {{{SpatialVLM}}},
  booktitle = {Proceedings of the {{IEEE}}/{{CVF Conference}} on {{Computer Vision}} and {{Pattern Recognition}}},
  author = {Chen, Boyuan and Xu, Zhuo and Kirmani, Sean and Ichter, Brain and Sadigh, Dorsa and Guibas, Leonidas and Xia, Fei},
  year = {2024},
  pages = {14455--14465},
  urldate = {2024-11-07},
  langid = {english},
  file = {E:\OneDrive\Zotero Literature\论文项目参考文献\2024【会议】大模型空间认知\Chen 等 - 2024 - SpatialVLM Endowing Vision-Language Models with Spatial Reasoning Capabilities.pdf}
}

@misc{cohnDialecticalLanguageModel2023,
  title = {Dialectical Language Model Evaluation: An Initial Appraisal of the Commonsense Spatial Reasoning Abilities of {{LLMs}}},
  shorttitle = {Dialectical Language Model Evaluation},
  author = {Cohn, Anthony G. and {Hernandez-Orallo}, Jose},
  year = {2023},
  month = apr,
  number = {arXiv:2304.11164},
  eprint = {2304.11164},
  primaryclass = {cs},
  publisher = {arXiv},
  doi = {10.48550/arXiv.2304.11164},
  urldate = {2024-12-15},
  abstract = {Language models have become very popular recently and many claims have been made about their abilities, including for commonsense reasoning. Given the increasingly better results of current language models on previous static benchmarks for commonsense reasoning, we explore an alternative dialectical evaluation. The goal of this kind of evaluation is not to obtain an aggregate performance value but to find failures and map the boundaries of the system. Dialoguing with the system gives the opportunity to check for consistency and get more reassurance of these boundaries beyond anecdotal evidence. In this paper we conduct some qualitative investigations of this kind of evaluation for the particular case of spatial reasoning (which is a fundamental aspect of commonsense reasoning). We conclude with some suggestions for future work both to improve the capabilities of language models and to systematise this kind of dialectical evaluation.},
  archiveprefix = {arXiv},
  langid = {english},
  keywords = {Computer Science - Artificial Intelligence,Computer Science - Computation and Language},
  annotation = {TLDR: This paper conducts some qualitative investigations of this kind of evaluation for the particular case of spatial reasoning (which is a fundamental aspect of commonsense reasoning) and concludes with some suggestions for future work both to improve the capabilities of language models and to systematise this type of dialectical evaluation.},
  file = {E\:\\OneDrive\\Zotero Literature\\论文项目参考文献\\2024【会议】大模型空间认知\\Cohn和Hernandez-Orallo - 2023 - Dialectical language model evaluation an initial appraisal of the commonsense spatial reasoning abi.pdf;C\:\\Users\\wenruixu\\Zotero\\storage\\RNH7HFBI\\2304.html}
}

@misc{cohnEvaluatingAbilityLarge2024,
  title = {Evaluating the {{Ability}} of {{Large Language Models}} to {{Reason}} about {{Cardinal Directions}}},
  author = {Cohn, Anthony G. and Blackwell, Robert E.},
  year = {2024},
  month = jun,
  number = {arXiv:2406.16528},
  eprint = {2406.16528},
  publisher = {arXiv},
  doi = {10.48550/arXiv.2406.16528},
  urldate = {2024-11-07},
  abstract = {We investigate the abilities of a representative set of Large language Models (LLMs) to reason about cardinal directions (CDs). To do so, we create two datasets: the first, co-created with ChatGPT, focuses largely on recall of world knowledge about CDs; the second is generated from a set of templates, comprehensively testing an LLM's ability to determine the correct CD given a particular scenario. The templates allow for a number of degrees of variation such as means of locomotion of the agent involved, and whether set in the first , second or third person. Even with a temperature setting of zero, Our experiments show that although LLMs are able to perform well in the simpler dataset, in the second more complex dataset no LLM is able to reliably determine the correct CD, even with a temperature setting of zero.},
  archiveprefix = {arXiv},
  langid = {american},
  keywords = {Computer Science - Computation and Language},
  file = {E\:\\OneDrive\\Zotero Literature\\论文项目参考文献\\2024【会议】大模型空间认知\\Cohn和Blackwell - 2024 - Evaluating the Ability of Large Language Models to Reason about Cardinal Directions.pdf;C\:\\Users\\wenruixu\\Zotero\\storage\\P5HDT7IZ\\2406.html}
}

@article{desmeIndividualDifferencesEmerging2024,
  title = {Individual Differences in Emerging Adults' Spatial Abilities: {{What}} Role Do Affective Factors Play?},
  shorttitle = {Individual Differences in Emerging Adults' Spatial Abilities},
  author = {Desme, Carlos J. and Dick, Anthony S. and Hayes, Timothy B. and Pruden, Shannon M.},
  year = {2024},
  month = mar,
  journal = {Cognitive Research: Principles and Implications},
  volume = {9},
  number = {1},
  pages = {13},
  issn = {2365-7464},
  doi = {10.1186/s41235-024-00538-w},
  urldate = {2024-11-07},
  abstract = {Spatial ability is defined as a cognitive or intellectual skill used to represent, transform, generate, and recall information of an object or the environment. Individual differences across spatial tasks have been strongly linked to science, technology, engineering, and mathematics (STEM) interest and success. Several variables have been proposed to explain individual differences in spatial ability, including affective factors such as one's confidence and anxiety. However, research is lacking on whether affective variables such as confidence and anxiety relate to individual differences in both a mental rotation task (MRT) and a perspective-taking and spatial orientation task (PTSOT). Using a sample of 100 college students completing introductory STEM courses, the present study investigated the effects of self-reported spatial confidence, spatial anxiety, and general anxiety on MRT and PTSOT. Spatial confidence, after controlling for effects of general anxiety and biological sex, was significantly related to performance on both the MRT and PTSOT. Spatial anxiety, after controlling for effects of general anxiety and biological sex, was not related to either PTSOT or MRT scores. Together these findings suggest some affective factors, but not others, contribute to spatial ability performance to a degree that merits advanced investigation in future studies.},
  langid = {american},
  keywords = {Confidence,Mental rotation,Perspective taking,Spatial ability,Spatial anxiety},
  file = {E\:\\OneDrive\\Zotero Literature\\论文项目参考文献\\2024【会议】大模型空间认知\\Desme 等 - 2024 - Individual differences in emerging adults’ spatial abilities What role do affective factors play.pdf;C\:\\Users\\wenruixu\\Zotero\\storage\\EE59ELN4\\s41235-024-00538-w.html}
}

@article{doliveiraDynamicSpatialAbility2004,
  title = {Dynamic Spatial Ability: An Exploratory Analysis and a Confirmatory Study},
  shorttitle = {Dynamic Spatial Ability},
  author = {D'Oliveira, Teresa C.},
  year = {2004},
  month = feb,
  journal = {International Journal of Aviation Psychology},
  volume = {14},
  number = {1},
  pages = {19--38},
  issn = {1050-8414, 1532-7108},
  doi = {10.1207/s15327108ijap1401_2},
  urldate = {2024-10-24},
  langid = {english},
  annotation = {TLDR: Both empirical studies confirm the existence of dynamic spatial ability as a distinct dimension within the spatial domain.},
  file = {E:\OneDrive\Zotero Literature\论文项目参考文献\2024【会议】大模型空间认知\D'Oliveira - 2004 - Dynamic spatial ability an exploratory analysis and a confirmatory study.pdf}
}

@article{duanSurveyEmbodiedAI2022,
  title = {A Survey of Embodied {{AI}}: From Simulators to Research Tasks},
  shorttitle = {A Survey of Embodied {{AI}}},
  author = {Duan, Jiafei and Yu, Samson and Tan, Hui Li and Zhu, Hongyuan and Tan, Cheston},
  year = {2022},
  month = apr,
  journal = {IEEE Transactions on Emerging Topics in Computational Intelligence},
  volume = {6},
  number = {2},
  pages = {230--244},
  issn = {2471-285X},
  doi = {10.1109/TETCI.2022.3141105},
  urldate = {2024-12-12},
  abstract = {There has been an emerging paradigm shift from the era of ``internet AI'' to ``embodied AI,'' where AI algorithms and agents no longer learn from datasets of images, videos or text curated primarily from the internet. Instead, they learn through interactions with their environments from an egocentric perception similar to humans. Consequently, there has been substantial growth in the demand for embodied AI simulators to support various embodied AI research tasks. This growing interest in embodied AI is beneficial to the greater pursuit of Artificial General Intelligence (AGI), but there has not been a contemporary and comprehensive survey of this field. This paper aims to provide an encyclopedic survey for the field of embodied AI, from its simulators to its research. By evaluating nine current embodied AI simulators with our proposed seven features, this paper aims to understand the simulators in their provision for use in embodied AI research and their limitations. Lastly, this paper surveys the three main research tasks in embodied AI -- visual exploration, visual navigation and embodied question answering (QA), covering the state-of-the-art approaches, evaluation metrics and datasets. Finally, with the new insights revealed through surveying the field, the paper will provide suggestions for simulator-for-task selections and recommendations for the future directions of the field.},
  langid = {english},
  keywords = {3D simulators,Artificial intelligence,computer vision,Embodied AI,Navigation,Physics,Solid modeling,Task analysis,Three-dimensional displays,Visualization},
  annotation = {TLDR: An encyclopedic survey of the three main research tasks in embodied AI -- visual exploration, visual navigation and embodied question answering -- covering the state-of-the-art approaches, evaluation metrics and datasets is surveyed.},
  file = {E\:\\OneDrive\\Zotero Literature\\Duan 等 - 2022 - A survey of embodied AI from simulators to research tasks.pdf;C\:\\Users\\wenruixu\\Zotero\\storage\\45ECVAGC\\9687596.html}
}

@misc{duranteInteractiveAgentFoundation2024,
  title = {An Interactive Agent Foundation Model},
  author = {Durante, Zane and Sarkar, Bidipta and Gong, Ran and Taori, Rohan and Noda, Yusuke and Tang, Paul and Adeli, Ehsan and Lakshmikanth, Shrinidhi Kowshika and Schulman, Kevin and Milstein, Arnold and Terzopoulos, Demetri and Famoti, Ade and Kuno, Noboru and Llorens, Ashley and Vo, Hoi and Ikeuchi, Katsu and {Fei-Fei}, Li and Gao, Jianfeng and Wake, Naoki and Huang, Qiuyuan},
  year = {2024},
  month = jun,
  number = {arXiv:2402.05929},
  eprint = {2402.05929},
  primaryclass = {cs},
  publisher = {arXiv},
  doi = {10.48550/arXiv.2402.05929},
  urldate = {2024-12-12},
  abstract = {The development of artificial intelligence systems is transitioning from creating static, task-specific models to dynamic, agent-based systems capable of performing well in a wide range of applications. We propose an Interactive Agent Foundation Model that uses a novel multi-task agent training paradigm for training AI agents across a wide range of domains, datasets, and tasks. Our training paradigm unifies diverse pre-training strategies, including visual masked auto-encoders, language modeling, and next-action prediction, enabling a versatile and adaptable AI framework. We demonstrate the performance of our framework across three separate domains -- Robotics, Gaming AI, and Healthcare. Our model demonstrates its ability to generate meaningful and contextually relevant outputs in each area. The strength of our approach lies in its generality, leveraging a variety of data sources such as robotics sequences, gameplay data, large-scale video datasets, and textual information for effective multimodal and multi-task learning. Our approach provides a promising avenue for developing generalist, action-taking, multimodal systems.},
  archiveprefix = {arXiv},
  langid = {english},
  keywords = {Computer Science - Artificial Intelligence,Computer Science - Machine Learning,Computer Science - Robotics},
  annotation = {TLDR: This work proposes an Interactive Agent Foundation Model that uses a novel multi-task agent training paradigm for training AI agents across a wide range of domains, datasets, and tasks, enabling a versatile and adaptable AI framework.},
  file = {E\:\\OneDrive\\Zotero Literature\\论文项目参考文献\\2024【会议】大模型空间认知\\Durante 等 - 2024 - An interactive agent foundation model.pdf;C\:\\Users\\wenruixu\\Zotero\\storage\\YSBJTTZG\\2402.html}
}

@article{eganAnalysisSpatialOrientation1981,
  title = {An Analysis of Spatial Orientation Test Performance},
  author = {Egan, Dennis E.},
  year = {1981},
  month = jan,
  journal = {Intelligence},
  volume = {5},
  number = {1},
  pages = {85--100},
  issn = {0160-2896},
  doi = {10.1016/0160-2896(81)90020-9},
  urldate = {2024-11-21},
  abstract = {Spatial Orientation ability correlates with important criteria such as achievement in calculus and physics, but this ability has not been investigated systematically. Performance on individual items adapted from a standard test of Spatial Orientation was studied. Subjects judged whether aerial views would be seen by an observer oriented in various ways. For practiced subjects, the time to answer items was an approximately linear function of the number of abstract spatial dimensions on which the aerial view and the observer's orientation were consistent. Practice led to lower error rates and lower intercepts for the response-time functions. Subject's ability correlated with the linearity of their response-time functions suggesting that lower ability subjects fail to code one or more spatial dimensions. A model specifying serial, self-terminating comparison of abstract spatial dimensions is proposed as an ideal which subjects approach after practice.}
}

@inproceedings{eliotInternationalDirectorySpatial1984,
  title = {An International Directory of Spatial Tests},
  author = {Eliot, J.},
  year = {1984},
  month = mar,
  urldate = {2024-11-21},
  abstract = {Semantic Scholar extracted view of "An International Directory of Spatial Tests" by J. Eliot},
  langid = {english}
}

@book{erkekRelationshipPreserviceTeachers2011,
  title = {The Relationship between Preservice Teachers' Spatial Anxiety and Geometry Self-Efficacy in Terms of Gender and Undergraduate Program},
  author = {Erkek, {\"O}zlem and Isiksal, Mine and Cakiroglu, Erdinc},
  year = {2011},
  month = sep,
  langid = {english},
  file = {E:\OneDrive\Zotero Literature\论文项目参考文献\2024【会议】大模型空间认知\Erkek 等 - 2011 - The relationship between preservice teachers’ spatial anxiety and geometry self-efficacy in terms of.pdf}
}

@article{farzanfarCognitiveMapsSpatial2023,
  title = {From Cognitive Maps to Spatial Schemas},
  author = {Farzanfar, Delaram and Spiers, Hugo J. and Moscovitch, Morris and Rosenbaum, R. Shayna},
  year = {2023},
  month = feb,
  journal = {Nature Reviews Neuroscience},
  volume = {24},
  number = {2},
  pages = {63--79},
  publisher = {Nature Publishing Group},
  issn = {1471-0048},
  doi = {10.1038/s41583-022-00655-9},
  urldate = {2024-09-30},
  abstract = {A schema refers to a structured body of prior knowledge that captures common patterns across related experiences. Schemas have been studied separately in the realms of episodic memory and spatial navigation across different species and have been grounded in theories of memory consolidation, but there has been little attempt to integrate our understanding across domains, particularly in humans. We propose that experiences during navigation with many similarly structured environments give rise to the formation of spatial schemas (for example, the expected layout of modern cities) that share properties with but are distinct from cognitive maps (for example, the memory of a modern city) and event schemas (such as expected events in a modern city) at both cognitive and neural levels. We describe earlier theoretical frameworks and empirical findings relevant to spatial schemas, along with more targeted investigations of spatial schemas in human and non-human animals. Consideration of architecture and urban analytics, including the influence of scale and regionalization, on different properties of spatial schemas may provide a powerful approach to advance our understanding of spatial schemas.},
  copyright = {2022 Springer Nature Limited},
  langid = {english},
  keywords = {,Cognitive neuroscience,Psychology},
  file = {E:\OneDrive\Zotero Literature\Peoples\others\清华-高宸\Farzanfar 等 - 2023 - From cognitive maps to spatial schemas.pdf}
}

@article{fehringerRCubeSRTestNew2023,
  title = {R-{{Cube-SR Test}}: {{A New Test}} for {{Spatial Relations Distinguishable From Visualization}}},
  shorttitle = {R-{{Cube-SR Test}}},
  author = {Fehringer, Benedict C. O. F.},
  year = {2023},
  month = jan,
  journal = {European Journal of Psychological Assessment},
  volume = {39},
  number = {1},
  pages = {37--48},
  issn = {1015-5759, 2151-2426},
  doi = {10.1027/1015-5759/a000682},
  urldate = {2024-11-21},
  abstract = {Visualization and spatial relations (mental rotation) are two important factors of spatial thinking. Visualization refers to complex visual-spatial transformations, whereas spatial relations refer to simple mental rotation of visualized objects. Conventional spatial relations tests, however, have been found to be highly correlated with visualization tests because solving items through mental rotation might involve visualization ability due to the complexity of the visual materials of these tests. In two studies (N = 51, N = 109), a new computer-based test for spatial relations, the R-Cube-SR Test, was developed and validated. The R-Cube-SR Test utilizes simple, single-colored cubes as rotated visual materials. Reliability estimates of the reaction times reach {$\omega$} = .87. Correlations with standard tests of spatial relations (up to r = .55) were significantly higher than with visualization tests, such as the new R-Cube-Vis Test (Fehringer, 2020), which uses the same visual materials. This was supported by CFAs. It is concluded that the new R-Cube-SR Test is a valid measure of spatial relations. Both tests together, the R-Cube-Vis and R-Cube-SR, as specific tests for their respective factor, now, are able to provide a differential diagnosis of a participant's spatial thinking ability using the same visual materials.},
  copyright = {https://creativecommons.org/licenses/by-nc-nd/4.0},
  langid = {english},
  annotation = {TLDR: Both tests together, the R-Cube-Vis and R- Cube-SR, as specific tests for their respective factor are able to provide a differential diagnosis of a participant's spatial thinking ability using the same visual materials.},
  file = {C:\Users\wenruixu\Zotero\storage\QUCZL3YC\Fehringer - 2023 - R-Cube-SR Test A New Test for Spatial Relations Distinguishable From Visualization.pdf}
}

@article{fehringerSupplementaryMaterialsImplementation2021,
  title = {Supplementary Materials for: Implementation of the {{R-cube-vis}} Test in Its Long and Short Version in English as Well as German},
  shorttitle = {Supplementary Materials For},
  author = {Fehringer, Benedict},
  year = {2021},
  month = oct,
  urldate = {2024-12-13},
  langid = {english},
  file = {C:\Users\wenruixu\Zotero\storage\4BSKTIBY\0be5b0ed-89d2-42eb-82e1-5bcf6b5ce118.html}
}

@book{flanaganContemporaryIntellectualAssessment2018,
  title = {Contemporary {{Intellectual Assessment}}: {{Theories}}, {{Tests}}, and {{Issues}}},
  shorttitle = {Contemporary {{Intellectual Assessment}}},
  author = {Flanagan, Dawn P. and McDonough, Erin M.},
  year = {2018},
  month = sep,
  publisher = {Guilford Publications},
  abstract = {This leading practitioner reference and text--now in a revised and expanded fourth edition--provides the knowledge needed to use state-of-the-art cognitive tests with individuals of all ages, from preschoolers to adults. The volume examines major theories and tests of intelligence (in chapters written by the theorists and test developers themselves) and presents research-based approaches to test interpretation. Contributors address critical issues in evaluating culturally and linguistically diverse students, gifted students, and those with intellectual disability, sensory--motor impairments, traumatic brain injuries, and learning difficulties and disabilities. The fourth edition highlights the use of cognitive test results in planning school-based interventions. New to This Edition *Complete coverage of new or updated tests: WPPSI-IV, WISC-V, WISC-V Integrated, WJ IV, ECAD, CAS2, RIAS-2, KABC-II Normative Update, and UNIT2. *Chapters on cutting-edge approaches to identifying specific learning disabilities and reading disorders. *Chapters on brain imaging, neuropsychological intervention in schools, adult intellectual development, and DSM-5 criteria for learning disorders. *Updated chapters on theories of intelligence, their research base, and their clinical utility in guiding cognitive and neuropsychological assessment practice.},
  googlebooks = {JA1mDwAAQBAJ},
  isbn = {978-1-4625-3578-1},
  langid = {english},
  keywords = {Education / Educational Psychology,Education / Testing & Measurement,Medical / Psychiatry / Child & Adolescent,Psychology / Assessment Testing & Measurement,Psychology / Psychotherapy / Child & Adolescent}
}

@article{friedmanComputerizedSpatialOrientation2020,
  title = {A Computerized Spatial Orientation Test},
  author = {Friedman, Alinda and Kohler, Bernd and Gunalp, Peri and Boone, Alexander P. and Hegarty, Mary},
  year = {2020},
  month = apr,
  journal = {Behavior Research Methods},
  volume = {52},
  number = {2},
  pages = {799--812},
  issn = {1554-3528},
  doi = {10.3758/s13428-019-01277-3},
  urldate = {2024-11-21},
  abstract = {In three experiments, we compared performance on a paper-based perspective-taking task (the Spatial Orientation Test [SOT]; Hegarty \& Waller, 2004) with performance on a computer-based version of the task. The computer-based version automates scoring angular errors, allows for different stimulus orders to be given to each participant, and allows for different testing time limits. In Experiment 1, the two media used different objects and mirror-image stimulus arrays in the two versions to mitigate the effects of memory for specific objects or responses. In Experiments 2 and 3, the two media used identical objects (also in a mirrored arrangement), to provide a more equivalent between-media comparison. We also substituted new objects for objects in the original version that had an inherent front/back (e.g., a car) and/or that were animate; directional or animate objects may add variance that is unrelated to perspective-taking ability. Experiment 3 used clarified instructions and a sample size sufficient to examine relatively small differences between the media as well as sex differences. Overall, the computer-based version produced performance that was similar to that of the paper-based version in terms of the rank-order of the participants. The new computer and paper versions of the SOT also had similar correlations with the Money Road Map test and the Santa Barbara Sense of Direction questionnaire, adding support to the claim that the computerized SOT is tapping into the same skill as the paper-based version. We provide a Java version of the new SOT, along with pdf files of instructions and practice stimuli, on the Open Science Framework website.},
  langid = {english},
  keywords = {Individual differences,Perspective taking,Psychometric tests,Spatial ability},
  annotation = {TLDR: The new computer and paper versions of the SOT had similar correlations with the Money Road Map test and the Santa Barbara Sense of Direction questionnaire, adding support to the claim that the computerized SOT is tapping into the same skill as the paper-based version.},
  file = {E:\OneDrive\Zotero Literature\论文项目参考文献\2024【会议】大模型空间认知\Friedman 等 - 2020 - A computerized spatial orientation test.pdf}
}

@misc{fuSceneLLMExtendingLanguage2024,
  title = {Scene-{{LLM}}: {{Extending Language Model}} for {{3D Visual Understanding}} and {{Reasoning}}},
  shorttitle = {Scene-{{LLM}}},
  author = {Fu, Rao and Liu, Jingyu and Chen, Xilun and Nie, Yixin and Xiong, Wenhan},
  year = {2024},
  month = mar,
  number = {arXiv:2403.11401},
  eprint = {2403.11401},
  publisher = {arXiv},
  doi = {10.48550/arXiv.2403.11401},
  urldate = {2024-11-07},
  abstract = {This paper introduces Scene-LLM, a 3D-visual-language model that enhances embodied agents' abilities in interactive 3D indoor environments by integrating the reasoning strengths of Large Language Models (LLMs). Scene-LLM adopts a hybrid 3D visual feature representation, that incorporates dense spatial information and supports scene state updates. The model employs a projection layer to efficiently project these features in the pre-trained textual embedding space, enabling effective interpretation of 3D visual information. Unique to our approach is the integration of both scene-level and ego-centric 3D information. This combination is pivotal for interactive planning, where scene-level data supports global planning and ego-centric data is important for localization. Notably, we use ego-centric 3D frame features for feature alignment, an efficient technique that enhances the model's ability to align features of small objects within the scene. Our experiments with Scene-LLM demonstrate its strong capabilities in dense captioning, question answering, and interactive planning. We believe Scene-LLM advances the field of 3D visual understanding and reasoning, offering new possibilities for sophisticated agent interactions in indoor settings.},
  archiveprefix = {arXiv},
  keywords = {Computer Science - Artificial Intelligence,Computer Science - Computer Vision and Pattern Recognition},
  file = {E\:\\OneDrive\\Zotero Literature\\论文项目参考文献\\2024【会议】大模型空间认知\\Fu 等 - 2024 - Scene-LLM Extending Language Model for 3D Visual Understanding and Reasoning.pdf;C\:\\Users\\wenruixu\\Zotero\\storage\\TZSJXIYP\\2403.html}
}

@article{gaoEmbodiedcityBenchmarkPlatform,
  title = {Embodiedcity: A Benchmark Platform for Em- Bodied Agent in Real-World City Environment},
  author = {Gao, Chen and Zhao, Baining and Zhang, Weichen and Mao, Jinzhu and Zhang, Jun and Zheng, Zhiheng and Man, Fanhang and Fang, Jianjie and Zhou, Zile and Cui, Jinqiang and Chen, Xinlei and Li, Yong},
  abstract = {Embodied artificial intelligence (EmbodiedAI) emphasizes the role of an agent's body in generating human-like behaviors. The recent efforts on EmbodiedAI pay a lot of attention to building up machine learning models to possess perceiving, planning, and acting abilities, thereby enabling real-time interaction with the world. However, most works focus on bounded indoor environments, such as navigation in a room or manipulating a device, with limited exploration of embodying the agents in open-world scenarios. That is, embodied intelligence in the open and outdoor environment is less explored, for which one potential reason is the lack of high-quality simulators, benchmarks, and datasets. To address it, in this paper, we construct a benchmark platform for embodied intelligence evaluation in realworld city environments. Specifically, we first construct a highly realistic 3D simulation environment based on the real buildings, roads, and other elements in a real city. In this environment, we combine historically collected data and simulation algorithms to conduct simulations of pedestrian and vehicle flows with high fidelity. Further, we designed a set of evaluation tasks covering different EmbodiedAI abilities. Moreover, we provide a complete set of input and output interfaces for access, enabling embodied agents to easily take task requirements and current environmental observations as input and then make decisions and obtain performance evaluations. On the one hand, it expands the capability of existing embodied intelligence to higher levels. On the other hand, it has a higher practical value in the real world and can support more potential applications for artificial general intelligence. Based on this platform, we evaluate some popular large language models for embodied intelligence capabilities of different dimensions and difficulties. The executable program of this platform is available for download, and we have also released an easy-to-use Python library and detailed tutorial documents. All of the software, Python library, codes, datasets, tutorials, and real-time online service are available on this website: https://embodied-city.fiblab. net.},
  langid = {english},
  file = {C:\Users\wenruixu\Zotero\storage\GLIZ2DWM\Gao 等 - Embodiedcity a benchmark platform for em- bodied agent in real-world city environment.pdf}
}

@article{gearyInclassAttentionSpatial2021,
  title = {In-Class Attention, Spatial Ability, and Mathematics Anxiety Predict across-Grade Gains in Adolescents' Mathematics Achievement},
  author = {Geary, David C. and Hoard, Mary K. and Nugent, Lara and Scofield, John E.},
  year = {2021},
  month = may,
  journal = {Journal of Educational Psychology},
  volume = {113},
  number = {4},
  pages = {754--769},
  issn = {1939-2176, 0022-0663},
  doi = {10.1037/edu0000487},
  urldate = {2024-10-24},
  copyright = {http://www.apa.org/pubs/journals/resources/open-access.aspx},
  langid = {english},
  annotation = {TLDR: Bayesian regression models revealed that complex spatial abilities and in-class attention were the most plausible predictors of seventh-grade mathematics, but not word reading, achievement, controlling for prior achievement.},
  file = {E:\OneDrive\Zotero Literature\论文项目参考文献\2024【会议】大模型空间认知\Geary 等 - 2021 - In-class attention, spatial ability, and mathematics anxiety predict across-grade gains in adolescen.pdf}
}

@article{gearySpatialAbilityDistinct2022,
  title = {Spatial Ability as a Distinct Domain of Human Cognition: An Evolutionary Perspective},
  shorttitle = {Spatial Ability as a Distinct Domain of Human Cognition},
  author = {Geary, David C.},
  year = {2022},
  month = jan,
  journal = {Intelligence},
  volume = {90},
  pages = {101616},
  issn = {01602896},
  doi = {10.1016/j.intell.2021.101616},
  urldate = {2024-10-24},
  abstract = {Psychometric studies have consistently identified spatial abilities as a broad domain of human cognition. Spatial abilities are in fact found in species in which engagement with the physical world, as in prey capture or mate searches, influences survival or reproductive prospects and much is now known about the brain and cognitive systems that support these activities. Sex differences in spatial abilities are found in species in which one sex or the other engages the physical world in more complex ways, such as having a larger home range. Sex differences provide a unique opportunity to study the influence of evolutionary pressures on cognition, because the study of males and females from the same species controls for many aspects of evolutionary history. When there are differences in past selection pressures on males and females they are typically related to reproductive demands. The approach is illustrated here for spatial abilities and provides a blueprint for linking psychometric and evolutionary approaches to the study of human spatial and other abilities.},
  langid = {english},
  file = {C:\Users\wenruixu\Zotero\storage\VVJ4JT64\Geary - 2022 - Spatial ability as a distinct domain of human cognition an evolutionary perspective.pdf}
}

@misc{geBEHAVIORVisionSuite2024,
  title = {{{BEHAVIOR}} Vision Suite: Customizable Dataset Generation via Simulation},
  shorttitle = {{{BEHAVIOR}} Vision Suite},
  author = {Ge, Yunhao and Tang, Yihe and Xu, Jiashu and Gokmen, Cem and Li, Chengshu and Ai, Wensi and Martinez, Benjamin Jose and Aydin, Arman and Anvari, Mona and Chakravarthy, Ayush K. and Yu, Hong-Xing and Wong, Josiah and Srivastava, Sanjana and Lee, Sharon and Zha, Shengxin and Itti, Laurent and Li, Yunzhu and {Mart{\'i}n-Mart{\'i}n}, Roberto and Liu, Miao and Zhang, Pengchuan and Zhang, Ruohan and {Fei-Fei}, Li and Wu, Jiajun},
  year = {2024},
  month = may,
  number = {arXiv:2405.09546},
  eprint = {2405.09546},
  publisher = {arXiv},
  doi = {10.48550/arXiv.2405.09546},
  urldate = {2024-10-24},
  abstract = {The systematic evaluation and understanding of computer vision models under varying conditions require large amounts of data with comprehensive and customized labels, which real-world vision datasets rarely satisfy. While current synthetic data generators offer a promising alternative, particularly for embodied AI tasks, they often fall short for computer vision tasks due to low asset and rendering quality, limited diversity, and unrealistic physical properties. We introduce the BEHAVIOR Vision Suite (BVS), a set of tools and assets to generate fully customized synthetic data for systematic evaluation of computer vision models, based on the newly developed embodied AI benchmark, BEHAVIOR-1K. BVS supports a large number of adjustable parameters at the scene level (e.g., lighting, object placement), the object level (e.g., joint configuration, attributes such as "filled" and "folded"), and the camera level (e.g., field of view, focal length). Researchers can arbitrarily vary these parameters during data generation to perform controlled experiments. We showcase three example application scenarios: systematically evaluating the robustness of models across different continuous axes of domain shift, evaluating scene understanding models on the same set of images, and training and evaluating simulation-to-real transfer for a novel vision task: unary and binary state prediction. Project website: https://behavior-vision-suite.github.io/},
  archiveprefix = {arXiv},
  langid = {english},
  keywords = {Computer Science - Computer Vision and Pattern Recognition},
  file = {E\:\\OneDrive\\Zotero Literature\\论文项目参考文献\\2024【会议】大模型空间认知\\Ge 等 - 2024 - BEHAVIOR vision suite customizable dataset generation via simulation.pdf;C\:\\Users\\wenruixu\\Zotero\\storage\\LYWGB6XZ\\2405.html}
}

@misc{geminiteamGeminiFamilyHighly2024,
  title = {Gemini: A Family of Highly Capable Multimodal Models},
  author = {{Gemini Team}},
  year = {2024}
}

@misc{hagendorffMachinePsychology2024,
  title = {Machine {{Psychology}}},
  author = {Hagendorff, Thilo and Dasgupta, Ishita and Binz, Marcel and Chan, Stephanie C. Y. and Lampinen, Andrew and Wang, Jane X. and Akata, Zeynep and Schulz, Eric},
  year = {2024},
  month = aug,
  number = {arXiv:2303.13988},
  eprint = {2303.13988},
  publisher = {arXiv},
  doi = {10.48550/arXiv.2303.13988},
  urldate = {2024-11-07},
  abstract = {Large language models (LLMs) show increasingly advanced emergent capabilities and are being incorporated across various societal domains. Understanding their behavior and reasoning abilities therefore holds significant importance. We argue that a fruitful direction for research is engaging LLMs in behavioral experiments inspired by psychology that have traditionally been aimed at understanding human cognition and behavior. In this article, we highlight and summarize theoretical perspectives, experimental paradigms, and computational analysis techniques that this approach brings to the table. It paves the way for a "machine psychology" for generative artificial intelligence (AI) that goes beyond performance benchmarks and focuses instead on computational insights that move us toward a better understanding and discovery of emergent abilities and behavioral patterns in LLMs. We review existing work taking this approach, synthesize best practices, and highlight promising future directions. We also highlight the important caveats of applying methodologies designed for understanding humans to machines. We posit that leveraging tools from experimental psychology to study AI will become increasingly valuable as models evolve to be more powerful, opaque, multi-modal, and integrated into complex real-world settings.},
  archiveprefix = {arXiv},
  keywords = {Computer Science - Artificial Intelligence,Computer Science - Computation and Language},
  file = {E\:\\OneDrive\\Zotero Literature\\论文项目参考文献\\2024【会议】大模型空间认知\\Hagendorff 等 - 2024 - Machine Psychology.pdf;C\:\\Users\\wenruixu\\Zotero\\storage\\DVCUUYA7\\2303.html}
}

@book{halpernSexDifferencesCognitive1992,
  title = {Sex Differences in Cognitive Abilities, 2nd Ed},
  author = {Halpern, Diane F.},
  year = {1992},
  series = {Sex Differences in Cognitive Abilities, 2nd Ed},
  pages = {xii, 308},
  publisher = {Lawrence Erlbaum Associates, Inc},
  address = {Hillsdale, NJ, US},
  abstract = {This book was written with a broad audience in mind---bright undergraduates and graduates and their professors and general readers who are intrigued with the questions and answers about cognitive sex differences. (PsycINFO Database Record (c) 2016 APA, all rights reserved)},
  isbn = {978-0-8058-0844-5 978-0-8058-0845-2},
  langid = {english},
  keywords = {Cognitive Ability,Human Sex Differences,Psychosocial Factors},
  file = {C:\Users\wenruixu\Zotero\storage\GIFM48TQ\1992-97046-000.html}
}

@article{hegartyHowSpatialAbilities2009,
  title = {How Spatial Abilities Enhance, and Are Enhanced by, Dental Education},
  author = {Hegarty, Mary and Keehner, Madeleine and Khooshabeh, Peter and Montello, Daniel R.},
  year = {2009},
  month = jan,
  journal = {Learning and Individual Differences},
  volume = {19},
  number = {1},
  pages = {61--70},
  issn = {1041-6080},
  doi = {10.1016/j.lindif.2008.04.006},
  urldate = {2024-11-21},
  abstract = {In two studies with a total of 324 participants, dentistry students were assessed on psychometric measures of spatial ability, reasoning ability, and on new measures of the ability to infer the appearance of a cross-section of a three-dimensional (3-D) object. We examined how these abilities and skills predict success in dental education programs, and whether dental education enhances an individual's spatial competence. The cross-section tests were correlated with spatial ability measures, even after controlling for reasoning ability, suggesting that they rely specifically on the ability to store and transform spatial representations. Sex differences in these measures indicated a male advantage, as is often found on measures of spatial ability. Spatial ability was somewhat predictive of performance in restorative dentistry practical laboratory classes, but not of learning anatomy in general. Comparisons of the performance of students early and late in their dental education indicated that dentistry students develop spatial mental models of the 3-D structure of teeth, which improves their ability to mentally maintain and manipulate representations of these specific structures, but there is no evidence that dental education improves spatial transformation abilities more generally.},
  langid = {english},
  keywords = {Dental education,Mental representations,Spatial abilities,Spatial transformations},
  annotation = {TLDR: Comparisons of the performance of students early and late in their dental education indicated that dentistry students develop spatial mental models of the 3-D structure of teeth, which improves their ability to mentally maintain and manipulate representations of these specific structures, but there is no evidence that dental education improves spatial transformation abilities more generally.},
  file = {E\:\\OneDrive\\Zotero Literature\\论文项目参考文献\\2024【会议】大模型空间认知\\Hegarty 等 - 2009 - How spatial abilities enhance, and are enhanced by, dental education.pdf;C\:\\Users\\wenruixu\\Zotero\\storage\\GPBGIT2D\\S1041608008000289.html}
}

@article{hegartySpatialAbilitiesDifferent2006,
  title = {Spatial Abilities at Different Scales: {{Individual}} Differences in Aptitude-Test Performance and Spatial-Layout Learning},
  shorttitle = {Spatial Abilities at Different Scales},
  author = {Hegarty, Mary and Montello, Daniel R. and Richardson, Anthony E. and Ishikawa, Toru and Lovelace, Kristin},
  year = {2006},
  month = mar,
  journal = {Intelligence},
  volume = {34},
  number = {2},
  pages = {151--176},
  issn = {0160-2896},
  doi = {10.1016/j.intell.2005.09.005},
  urldate = {2024-11-07},
  abstract = {Most psychometric tests of spatial ability are paper-and-pencil tasks at the ``figural'' scale of space, in that they involve inspecting, imagining or mentally transforming small shapes or manipulable objects. Environmental spatial tasks, such as wayfinding or learning the layout of a building or city, are carried out in larger spaces that surround the body and involve integration of the sequence of views that change with one's movement in the environment. In a correlational study, 221 participants were tested on psychometric measures of spatial abilities, spatial updating, verbal abilities and working memory. They also learned the layout of large environments from direct experience walking through a real environment, and via two different media: a desktop virtual environment (VE) and a videotape of a walk through an environment. In an exploratory factor analysis, measures of environmental learning from direct experience defined a separate factor from measures of learning based on VE and video media. In structural-equation models, small-scale spatial abilities predicted performance on the environmental-learning tasks, but were more predictive of learning from media than from direct experience. The results indicate that spatial abilities at different scales of space are partially but not totally dissociated. They specify the degree of overlap between small-scale and large-scale spatial abilities, inform theories of sex differences in these abilities, and provide new insights about what these abilities have in common and how they differ.},
  copyright = {https://www.elsevier.com/tdm/userlicense/1.0/},
  langid = {english},
  file = {E\:\\OneDrive\\Zotero Literature\\论文项目参考文献\\2024【会议】大模型空间认知\\Hegarty 等 - 2006 - Spatial abilities at different scales individual differences in aptitude-test performance and spati.pdf;C\:\\Users\\wenruixu\\Zotero\\storage\\5IPR84HI\\S0160289605000905.html}
}

@misc{hong3DLLMInjecting3D2023,
  title = {{{3D-LLM}}: {{Injecting}} the {{3D World}} into {{Large Language Models}}},
  shorttitle = {{{3D-LLM}}},
  author = {Hong, Yining and Zhen, Haoyu and Chen, Peihao and Zheng, Shuhong and Du, Yilun and Chen, Zhenfang and Gan, Chuang},
  year = {2023},
  month = jul,
  number = {arXiv:2307.12981},
  eprint = {2307.12981},
  publisher = {arXiv},
  doi = {10.48550/arXiv.2307.12981},
  urldate = {2024-11-07},
  abstract = {Large language models (LLMs) and Vision-Language Models (VLMs) have been proven to excel at multiple tasks, such as commonsense reasoning. Powerful as these models can be, they are not grounded in the 3D physical world, which involves richer concepts such as spatial relationships, affordances, physics, layout, and so on. In this work, we propose to inject the 3D world into large language models and introduce a whole new family of 3D-LLMs. Specifically, 3D-LLMs can take 3D point clouds and their features as input and perform a diverse set of 3D-related tasks, including captioning, dense captioning, 3D question answering, task decomposition, 3D grounding, 3D-assisted dialog, navigation, and so on. Using three types of prompting mechanisms that we design, we are able to collect over 300k 3D-language data covering these tasks. To efficiently train 3D-LLMs, we first utilize a 3D feature extractor that obtains 3D features from rendered multi- view images. Then, we use 2D VLMs as our backbones to train our 3D-LLMs. By introducing a 3D localization mechanism, 3D-LLMs can better capture 3D spatial information. Experiments on ScanQA show that our model outperforms state-of-the-art baselines by a large margin (e.g., the BLEU-1 score surpasses state-of-the-art score by 9\%). Furthermore, experiments on our held-in datasets for 3D captioning, task composition, and 3D-assisted dialogue show that our model outperforms 2D VLMs. Qualitative examples also show that our model could perform more tasks beyond the scope of existing LLMs and VLMs. Project Page: : https://vis-www.cs.umass.edu/3dllm/.},
  archiveprefix = {arXiv},
  keywords = {Computer Science - Artificial Intelligence,Computer Science - Computation and Language,Computer Science - Computer Vision and Pattern Recognition,Computer Science - Machine Learning,Computer Science - Robotics},
  annotation = {TLDR: This work proposes to inject the 3D world into large language models and introduce a whole new family of 3D-LLMs that can take 3D point clouds and their features as input and perform a diverse set of 3D-related tasks, including captioning, dense captioning, 3D question answering, task decomposition, 3D grounding, 3D-assisted dialog, navigation, and so on.},
  file = {E\:\\OneDrive\\Zotero Literature\\论文项目参考文献\\2024【会议】大模型空间认知\\Hong 等 - 2023 - 3D-LLM Injecting the 3D World into Large Language Models.pdf;C\:\\Users\\wenruixu\\Zotero\\storage\\V55IX7ZF\\2307.html}
}

@article{hornOrganizationAbilitiesDevelopment1968,
  title = {Organization of Abilities and the Development of Intelligence},
  author = {Horn, John L.},
  year = {1968},
  journal = {Psychological Review},
  volume = {75},
  number = {3},
  pages = {242--259},
  issn = {1939-1471, 0033-295X},
  doi = {10.1037/h0025662},
  urldate = {2024-10-24},
  langid = {english},
  annotation = {TLDR: Performances which are accepted as indicators of intelligence are interrelated in ways which indicate 2 broad factors, called crystallized intelligence and fluid intelligence, which indicate the extent of acculturation as it determines human abilities.},
  file = {E:\OneDrive\Zotero Literature\论文项目参考文献\2024【会议】大模型空间认知\Horn - 1968 - Organization of abilities and the development of intelligence.pdf}
}

@article{hydeGenderDifferencesMathematics1990,
  title = {Gender Differences in Mathematics Performance: A Meta-Analysis},
  shorttitle = {Gender Differences in Mathematics Performance},
  author = {Hyde, Janet S. and Fennema, Elizabeth and Lamon, Susan J.},
  year = {1990},
  journal = {Psychological Bulletin},
  volume = {107},
  number = {2},
  pages = {139--155},
  issn = {1939-1455, 0033-2909},
  doi = {10.1037/0033-2909.107.2.139},
  urldate = {2024-10-24},
  langid = {english},
  file = {E:\OneDrive\Zotero Literature\论文项目参考文献\2024【会议】大模型空间认知\Hyde 等 - 1990 - Gender differences in mathematics performance a meta-analysis.pdf}
}

@article{ilicEvidenceInterrelatedCognitivelike2024,
  title = {Evidence of Interrelated Cognitive-like Capabilities in Large Language Models: {{Indications}} of Artificial General Intelligence or Achievement?},
  shorttitle = {Evidence of Interrelated Cognitive-like Capabilities in Large Language Models},
  author = {Ili{\'c}, David and Gignac, Gilles E.},
  year = {2024},
  month = sep,
  journal = {Intelligence},
  volume = {106},
  pages = {101858},
  issn = {0160-2896},
  doi = {10.1016/j.intell.2024.101858},
  urldate = {2024-11-07},
  abstract = {Large language models (LLMs) are advanced artificial intelligence (AI) systems that can perform a variety of tasks commonly found in human intelligence tests, such as defining words, performing calculations, and engaging in verbal reasoning. There are also substantial individual differences in LLM capacities. Given the consistent observation of a positive manifold and general intelligence factor in human samples, along with group-level factors (e.g., crystallised intelligence), we hypothesized that LLM test scores may also exhibit positive inter-correlations, which could potentially give rise to an artificial general ability (AGA) factor and one or more group-level factors. Based on a sample of 591 LLMs and scores from 12 tests aligned with fluid reasoning (Gf), domain-specific knowledge (Gkn), reading/writing (Grw), and quantitative knowledge (Gq), we found strong empirical evidence for a positive manifold and a general factor of ability. Additionally, we identified a combined Gkn/Grw group-level factor. Finally, the number of LLM parameters correlated positively with both general factor of ability and Gkn/Grw factor scores, although the effects showed diminishing returns. We interpreted our results to suggest that LLMs, like human cognitive abilities, may share a common underlying efficiency in processing information and solving problems, though whether LLMs manifest primarily achievement/expertise rather than intelligence remains to be determined. Finally, while models with greater numbers of parameters exhibit greater general cognitive-like abilities, akin to the connection between greater neuronal density and human general intelligence, other characteristics must also be involved.},
  keywords = {Artificial general intelligence,Artificial intelligence,Number of parameters},
  file = {E\:\\OneDrive\\Zotero Literature\\论文项目参考文献\\2024【会议】大模型空间认知\\Ilić和Gignac - 2024 - Evidence of interrelated cognitive-like capabilities in large language models Indications of artifi.pdf;C\:\\Users\\wenruixu\\Zotero\\storage\\D9DGWRSV\\S0160289624000527.html}
}

@article{ilicTypologySpatialAbility2017,
  title = {Typology of Spatial Ability Tests and Its Implementation in Architectural Study Entrance Exams},
  author = {Ilic, Maja and Djukic, Aleksandra},
  year = {2017},
  month = jan,
  journal = {Facta universitatis - series: Architecture and Civil Engineering},
  volume = {15},
  pages = {1--14},
  doi = {10.2298/FUACE161113001I},
  abstract = {Specialized spatial skills are necessary for success in various fields of STEM (science, technology, engineering, and mathematics) education. Technical disciplines are an academic field where the largest correlation with spatial skills has been noticed, and therefore spatial skills have been included in the entrance exams of study of architecture at the University of Banja Luka. Given that the scientific community has not reached consensus on what the spatial abilities are, there are various tests and tools used for its assessment, listed by factors that they measure. The paper will present typology of these factors and the variety of tests used for their assessment. This typology of tasks will be compared to the entrance exams held at the University of Banja Luka in the period 2005-2013. Also, the results of entrance exams will be compared with the student?s success in specific groups of subjects during the study period to see if there would be any correlation among them. Results indicate at the emergence of a new factor in assessing the ability of candidates to study architecture - ability of divergent thinking. This correlation of divergent thinking and spatial ability has also been a topic of the latest research in cognitive psychology.},
  langid = {american},
  file = {E:\OneDrive\Zotero Literature\论文项目参考文献\2024【会议】大模型空间认知\Ilic和Djukic - 2017 - Typology of spatial ability tests and its implementation in architectural study entrance exams.pdf}
}

@article{johnsonSexDifferencesMental2007,
  title = {Sex Differences in Mental Abilities: g Masks the Dimensions on Which They Lie},
  shorttitle = {Sex Differences in Mental Abilities},
  author = {Johnson, Wendy and Bouchard, Thomas J.},
  year = {2007},
  month = jan,
  journal = {Intelligence},
  volume = {35},
  number = {1},
  pages = {23--39},
  issn = {01602896},
  doi = {10.1016/j.intell.2006.03.012},
  urldate = {2024-10-24},
  copyright = {https://www.elsevier.com/tdm/userlicense/1.0/},
  langid = {english},
  file = {E:\OneDrive\Zotero Literature\论文项目参考文献\2024【会议】大模型空间认知\Johnson和Bouchard - 2007 - Sex differences in mental abilities g masks the dimensions on which they lie.pdf}
}

@article{johnsonStructureHumanIntelligence2005,
  title = {The Structure of Human Intelligence: It Is Verbal, Perceptual, and Image Rotation ({{VPR}}), Not Fluid and Crystallized},
  shorttitle = {The Structure of Human Intelligence},
  author = {Johnson, W and Bouchardjr, T},
  year = {2005},
  month = jul,
  journal = {Intelligence},
  volume = {33},
  number = {4},
  pages = {393--416},
  issn = {01602896},
  doi = {10.1016/j.intell.2004.12.002},
  urldate = {2024-10-24},
  copyright = {https://www.elsevier.com/tdm/userlicense/1.0/},
  langid = {english},
  file = {E:\OneDrive\Zotero Literature\论文项目参考文献\2024【会议】大模型空间认知\Johnson和Bouchardjr - 2005 - The structure of human intelligence it is verbal, perceptual, and image rotation (VPR), not fluid a.pdf}
}

@article{jonesSpatialAbilityLearning2008,
  title = {Spatial Ability and Learning to Program},
  author = {Jones, Sue and Burnett, Gary},
  year = {2008},
  journal = {Human Technology: An Interdisciplinary Journal on Humans in ICT Environments},
  volume = {4},
  number = {1},
  pages = {47--61},
  publisher = {Agora Center},
  address = {Finland},
  issn = {1795-6889},
  doi = {10.17011/ht/urn.200804151352},
  abstract = {Results in introductory computer programming modules are often disappointing, and various individual differences have been found to be relevant. This paper reviews work in this area, with particular reference to the effect of a student's spatial ability. Data is presented on a cohort of 49 students enrolled on an MSc in Information Technology course at a university in the UK. A measure was taken of their mental rotation ability, and a questionnaire administered that focused on their previous academic experience, and expectations relating to the introductory computer programming module they were studying. The results showed a positive correlation between mental rotation ability and success in the module (r = 0.48). Other factors, such as confidence level, expected success, and programming experience, were also found to be important. These results are discussed in relation to the accessibility of programming to learners with low spatial ability. (PsycInfo Database Record (c) 2023 APA, all rights reserved)},
  keywords = {Computer Programming,Expectations,Human Computer Interaction,Individual Differences,Information and Communication Technology,Mental Rotation,Spatial Ability,Technology},
  annotation = {TLDR: A positive correlation between mental rotation ability and success in the module showed, and other factors, such as confidence level, expected success, and programm ing experience, were also found to be important.},
  file = {E:\OneDrive\Zotero Literature\论文项目参考文献\2024【会议】大模型空间认知\Jones和Burnett - 2008 - Spatial ability and learning to program.pdf}
}

@article{jungParietofrontalIntegrationTheory2007,
  title = {The Parieto-Frontal Integration Theory ({{P-FIT}}) of Intelligence: Converging Neuroimaging Evidence},
  shorttitle = {The Parieto-Frontal Integration Theory ({{P-FIT}}) of Intelligence},
  author = {Jung, Rex E. and Haier, Richard J.},
  year = {2007},
  month = apr,
  journal = {Behavioral and Brain Sciences},
  volume = {30},
  number = {2},
  pages = {135--154},
  issn = {0140-525X, 1469-1825},
  doi = {10.1017/S0140525X07001185},
  urldate = {2024-10-24},
  abstract = {Abstract                            ``Is there a biology of intelligence which is characteristic of the normal human nervous system?'' Here we review 37 modern neuroimaging studies in an attempt to address this question posed by Halstead (1947) as he and other icons of the last century endeavored to understand how brain and behavior are linked through the expression of intelligence and reason. Reviewing studies from functional (i.e., functional magnetic resonance imaging, positron emission tomography) and structural (i.e., magnetic resonance spectroscopy, diffusion tensor imaging, voxel-based morphometry) neuroimaging paradigms, we report a striking consensus suggesting that variations in a distributed network predict individual differences found on intelligence and reasoning tasks. We describe this network as the               Parieto-Frontal Integration Theory               (P-FIT). The P-FIT model includes, by Brodmann areas (BAs): the dorsolateral prefrontal cortex (BAs 6, 9, 10, 45, 46, 47), the inferior (BAs 39, 40) and superior (BA 7) parietal lobule, the anterior cingulate (BA 32), and regions within the temporal (BAs 21, 37) and occipital (BAs 18, 19) lobes. White matter regions (i.e., arcuate fasciculus) are also implicated. The P-FIT is examined in light of findings from human lesion studies, including missile wounds, frontal lobotomy/leukotomy, temporal lobectomy, and lesions resulting in damage to the language network (e.g., aphasia), as well as findings from imaging research identifying brain regions under significant genetic control. Overall, we conclude that modern neuroimaging techniques are beginning to articulate a biology of intelligence. We propose that the P-FIT provides a parsimonious account for many of the empirical observations, to date, which relate individual differences in intelligence test scores to variations in brain structure and function. Moreover, the model provides a framework for testing new hypotheses in future experimental designs.},
  copyright = {https://www.cambridge.org/core/terms},
  langid = {english},
  annotation = {TLDR: It is proposed that the P-FIT provides a parsimonious account for many of the empirical observations, to date, which relate individual differences in intelligence test scores to variations in brain structure and function.},
  file = {E:\OneDrive\Zotero Literature\论文项目参考文献\2024【会议】大模型空间认知\Jung和Haier - 2007 - The parieto-frontal integration theory (P-FIT) of intelligence converging neuroimaging evidence.pdf}
}

@article{juVscVakovaTPSTestDevelopment,
  title = {{{TPS}} Test Development and Application into Research on Spatial Abilities},
  author = {Ju{\textasciicaron}sc{\textasciicaron}akova, Zuzana and Gorska, Renata A},
  abstract = {TPS has been developed to provide a modern tool for measuring spatial skills of engineering students. The genesis and development of the subsequent versions of the test, starting from the TPP, through TPS1 to TPS2, will be described in this publication. The test has been administered on a representative group of students (n {$>$} 1270 subjects) at various types of schools and universities in Slovak and Czech Republics, Poland and Austria. In order to provide a reference measure between the TPS and the other tests used by psychologists as a measure of spatial abilities, standardized psychometric tests such as IST, ISA, OTRS, and MRT have been administered in the researched groups. High correlation coefficients between the listed tests and the TPS have been received. The aim for this part of the research was to validate a new tool for being able to measure spatial ability, namely the TPS, and to provide a comparative study of the test validity.},
  langid = {english},
  file = {E:\OneDrive\Zotero Literature\论文项目参考文献\2024【会议】大模型空间认知\Juˇscˇakova和Gorska - TPS test development and application into research on spatial abilities.pdf}
}

@article{kaneRolePrefrontalCortex2002,
  title = {The Role of Prefrontal Cortex in Working-Memory Capacity, Executive Attention, and General Fluid Intelligence: An Individual-Differences Perspective},
  shorttitle = {The Role of Prefrontal Cortex in Working-Memory Capacity, Executive Attention, and General Fluid Intelligence},
  author = {Kane, Michael J. and Engle, Randall W.},
  year = {2002},
  month = dec,
  journal = {Psychonomic Bulletin \& Review},
  volume = {9},
  number = {4},
  pages = {637--671},
  issn = {1069-9384, 1531-5320},
  doi = {10.3758/BF03196323},
  urldate = {2024-10-24},
  copyright = {http://www.springer.com/tdm},
  langid = {english},
  annotation = {TLDR: Although the dorsolateral PFC is but one critical structure in a network of anterior and posterior ``attention control'' areas, it does have a unique executiveattention role in actively maintaining access to stimulus representations and goals in interference-rich contexts.},
  file = {E:\OneDrive\Zotero Literature\论文项目参考文献\2024【会议】大模型空间认知\Kane和Engle - 2002 - The role of prefrontal cortex in working-memory capacity, executive attention, and general fluid int.pdf}
}

@misc{kaplanScalingLawsNeural2020,
  title = {Scaling Laws for Neural Language Models},
  author = {Kaplan, Jared and McCandlish, Sam and Henighan, Tom and Brown, Tom B. and Chess, Benjamin and Child, Rewon and Gray, Scott and Radford, Alec and Wu, Jeffrey and Amodei, Dario},
  year = {2020},
  month = jan,
  number = {arXiv:2001.08361},
  eprint = {2001.08361},
  primaryclass = {cs},
  publisher = {arXiv},
  doi = {10.48550/arXiv.2001.08361},
  urldate = {2024-12-14},
  abstract = {We study empirical scaling laws for language model performance on the cross-entropy loss. The loss scales as a power-law with model size, dataset size, and the amount of compute used for training, with some trends spanning more than seven orders of magnitude. Other architectural details such as network width or depth have minimal effects within a wide range. Simple equations govern the dependence of overfitting on model/dataset size and the dependence of training speed on model size. These relationships allow us to determine the optimal allocation of a fixed compute budget. Larger models are significantly more sample-efficient, such that optimally compute-efficient training involves training very large models on a relatively modest amount of data and stopping significantly before convergence.},
  archiveprefix = {arXiv},
  langid = {english},
  keywords = {Computer Science - Machine Learning,Statistics - Machine Learning},
  file = {E\:\\OneDrive\\Zotero Literature\\论文项目参考文献\\2024【会议】大模型空间认知\\Kaplan 等 - 2020 - Scaling laws for neural language models.pdf;C\:\\Users\\wenruixu\\Zotero\\storage\\BJ2WNJ9X\\2001.html}
}

@article{katsioloudisComparativeAnalysisSpatial2014,
  title = {A Comparative Analysis of Spatial Visualization Ability and Drafting Models for Industrial and Technology Education Students},
  author = {Katsioloudis, Petros and Jovanovic, Vukica and Jones, Mildred},
  year = {2014},
  month = dec,
  journal = {Journal of Technology Education},
  volume = {26},
  pages = {88--104},
  doi = {10.21061/jte.v26i1.a.6},
  langid = {english}
}

@article{khelouiSexGenderDifferences2023,
  title = {Sex/Gender Differences in Cognitive Abilities},
  author = {Kheloui, Sarah and {Jacmin-Park}, Silke and Larocque, Oph{\'e}lie and Kerr, Philippe and Rossi, Mathias and Cartier, Louis and Juster, Robert-Paul},
  year = {2023},
  month = sep,
  journal = {Neuroscience \& Biobehavioral Reviews},
  volume = {152},
  pages = {105333},
  issn = {0149-7634},
  doi = {10.1016/j.neubiorev.2023.105333},
  urldate = {2024-10-24},
  abstract = {Sex/gender differences in cognitive sciences are riddled by conflicting perspectives. At the center of debates are clinical, social, and political perspectives. Front and center, evolutionary and biological perspectives have often focused on `nature' arguments, while feminist and constructivist views have often focused on `nurture arguments regarding cognitive sex differences. In the current narrative review, we provide a comprehensive overview regarding the origins and historical advancement of these debates while providing a summary of the results in the field of sexually polymorphic cognition. In so doing, we attempt to highlight the importance of using transdisciplinary perspectives which help bridge disciplines together to provide a refined understanding the specific factors that drive sex differences a gender diversity in cognitive abilities. To summarize, biological sex (e.g., birth-assigned sex, sex hormones), socio-cultural gender (gender identity, gender roles), and sexual orientation each uniquely shape the cognitive abilities reviewed. To date, however, few studies integrate these sex and gender factors together to better understand individual differences in cognitive functioning. This has potential benefits if a broader understanding of sex and gender factors are systematically measured when researching and treating numerous conditions where cognition is altered.},
  langid = {english},
  keywords = {Cognition,Evolutionary psychology,Feminist perspectives,Gender diversity,Sex differences,Sexually polymorphic cognition}
}

@article{kozhevnikovDissociationObjectManipulation2001,
  title = {A Dissociation between Object Manipulation Spatial Ability and Spatial Orientation Ability},
  author = {Kozhevnikov, Maria and Hegarty, Mary},
  year = {2001},
  month = jul,
  journal = {Memory \& Cognition},
  volume = {29},
  number = {5},
  pages = {745--756},
  issn = {1532-5946},
  doi = {10.3758/BF03200477},
  urldate = {2024-11-21},
  abstract = {We developed psychometric tests of spatial orientation ability, in which people are shown a two dimensional array of objects, imagine taking a perspective within the array, and indicate the direction to a target object from this perspective. Patterns of errors on these tests were consistent with experimental studies of perspective taking. Characteristic errors and verbal protocols supported the validity of the perspective-taking tests, suggesting that people encoded the objects in the display with respect to a body-centered coordinate system when the imagined perspective was more than 90{$^\circ$} different from the orientation of the display. By comparing alternative models in a confirmatory factor analysis, we found that the ability to mentally rotate and manipulate an imagined object (as measured by tests of spatial visualization and spatial relations) and the ability to reorient the imagined self (as measured by the perspective-taking tests) are separable spatial abilities.},
  langid = {english},
  keywords = {Mental Rotation,Object Manipulation,Perspective Taking,Spatial Ability,Spatial Visualization},
  annotation = {TLDR: It is found that the ability to mentally rotate and manipulate an imagined object and the able to reorient the imagined self are separable spatial abilities.},
  file = {E:\OneDrive\Zotero Literature\论文项目参考文献\2024【会议】大模型空间认知\Kozhevnikov和Hegarty - 2001 - A dissociation between object manipulation spatial ability and spatial orientation ability.pdf}
}

@inproceedings{liangCodePoliciesLanguage2023,
  title = {Code as {{Policies}}: {{Language Model Programs}} for {{Embodied Control}}},
  shorttitle = {Code as {{Policies}}},
  booktitle = {2023 {{IEEE International Conference}} on {{Robotics}} and {{Automation}} ({{ICRA}})},
  author = {Liang, Jacky and Huang, Wenlong and Xia, Fei and Xu, Peng and Hausman, Karol and Ichter, Brian and Florence, Pete and Zeng, Andy},
  year = {2023},
  month = may,
  pages = {9493--9500},
  publisher = {IEEE},
  address = {London, United Kingdom},
  doi = {10.1109/ICRA48891.2023.10160591},
  urldate = {2024-12-15},
  copyright = {https://doi.org/10.15223/policy-029},
  isbn = {979-8-3503-2365-8},
  langid = {american},
  annotation = {TLDR: Code as Policies is presented, a robot-centric formulation of language model generated programs (LMPs) that can represent reactive policies (e.g., impedance controllers), as well as waypoint-based policies (vision-based pick and place, trajectory-based control), demonstrated across multiple real robot platforms.},
  file = {E:\OneDrive\Zotero Literature\论文项目参考文献\2024【会议】大模型空间认知\Liang 等 - 2023 - Code as Policies Language Model Programs for Embodied Control.pdf}
}

@inproceedings{ligaTestingSpatialReasoning2023,
  title = {Testing Spatial Reasoning of {{Large Language Models}}: The Case of Tic-Tac-Toe},
  shorttitle = {Testing Spatial Reasoning of {{Large Language Models}}},
  booktitle = {{$<$}a Href="{{https://ceur-ws.org/Vol-3563/paper\_14.pdf"$>$https://ceur-ws.org/Vol-3563/paper\_14.pdf$<$/a$>$}}},
  author = {Liga, Davide and Pasetto, Luca},
  year = {2023},
  urldate = {2024-11-07},
  abstract = {In recent times, Large Language Models (LLMs) have shown to be successful in solving tasks that previously were believed to be very hard to achieve. While language and reasoning are two interlinked concepts, the reasoning capabilities of LLMs are not considered at this moment to be on par with their linguistic ones. In this work, we test how LLMs can choose moves in the popular tic-tac-toe game in order to assess their reasoning capabilities when the information to reason on is immersed in a spatial context. In order to do this, we run a number of LLMs, task them to play matches of tic-tac-toe against the well-known minimax algorithm, and compare the results. In this context, the performed task is non-trivial, as it involves recognition of combinations of text characters and a capacity that resembles reasoning based on their positions in a bi-dimensional space. Moreover, we ask the LLMs to keep track of the state of the game by listing the sequences they could use to win, in order for us to assess whether this information is used in their choices or not. One of the necessary features of consciousness in an agent is that it is able to build a model of itself and of the external world, and it acts based on these models. While we do not argue that LLMs have consciousness, we believe that it is important to monitor whether features related to consciousness appear in these LLMs, which is the final objective, not yet completed, of this research.},
  langid = {english},
  file = {E:\OneDrive\Zotero Literature\论文项目参考文献\2024【会议】大模型空间认知\Liga和Pasetto - 2023 - Testing spatial reasoning of Large Language Models the case of tic-tac-toe.pdf}
}

@article{linnEmergenceCharacterizationSex1985,
  title = {Emergence and Characterization of Sex Differences in Spatial Ability: A Meta-Analysis},
  shorttitle = {Emergence and Characterization of Sex Differences in Spatial Ability},
  author = {Linn, Marcia C. and Petersen, Anne C.},
  year = {1985},
  journal = {Child Development},
  volume = {56},
  number = {6},
  eprint = {1130467},
  eprinttype = {jstor},
  pages = {1479--1498},
  publisher = {[Wiley, Society for Research in Child Development]},
  issn = {0009-3920},
  doi = {10.2307/1130467},
  urldate = {2024-10-24},
  abstract = {Sex differences in spatial ability are widely acknowledged, yet considerable dispute surrounds the magnitude, nature, and age of first occurrence of these differences. This article focuses on 3 questions about sex differences in spatial ability: (a) What is the magnitude of sex differences in spatial ability? (b) On which aspects of spatial ability are sex differences found? and (c) When, in the life span, are sex differences in spatial ability first detected? Implications for clarifying the linkage between sex differences in spatial ability and other differences between males and females are discussed. We use meta-analysis, a method for synthesizing empirical studies, to investigate these questions. Results of the meta-analysis suggest (a) that sex differences arise on some types of spatial ability but not others, (b) that large sex differences are found only on measures of mental rotation, (c) that smaller sex differences are found on measures of spatial perception, and (d) that, when sex differences are found, they can be detected across the life span.},
  langid = {english},
  annotation = {TLDR: Meta-analysis is used, a method for synthesizing empirical studies, to investigate sex differences in spatial ability and suggests that sex differences arise on some types of spatial ability but not others, and that, when sex differences are found, they can be detected across the life span.},
  file = {E\:\\OneDrive\\Zotero Literature\\论文项目参考文献\\2024【会议】大模型空间认知\\Linn和Petersen - 1985 - Emergence and characterization of sex differences in spatial ability a meta-analysis_1.pdf;E\:\\OneDrive\\Zotero Literature\\论文项目参考文献\\2024【会议】大模型空间认知\\Linn和Petersen - 1985 - Emergence and characterization of sex differences in spatial ability a meta-analysis_2.pdf;E\:\\OneDrive\\Zotero Literature\\论文项目参考文献\\2024【会议】大模型空间认知\\Linn和Petersen - 1985 - Emergence and characterization of sex differences in spatial ability a meta-analysis.pdf}
}

@phdthesis{LiuXiaoXueShengKongJianGuanNianDeFaZhanGuiLuJiTeDianYanJiu2007,
  type = {{博士学位论文}},
  title = {{小学生空间观念的发展规律及特点研究}},
  author = {刘, 晓玫},
  year = {2007},
  address = {长春},
  urldate = {2024-10-24},
  abstract = {一个多世纪以来,中小学几何课程的目标与内容一直是人们争论和关注的焦点。从数学课程的比较中不难看到各国几何课程的内容与要求差距之大,至于几何的教学,差异就更加突出。尽管几何课程面对的问题较为复杂,但是我们仍然需要从课程的角度出发找出它的一般特征,并依此进行宏观的设计和微观的研究,从而搭建合理的几何课程体系。在几何课程中,无论争论如何,空间想象力(空间能力的一部分)被认为是数学诸多能力中的重要部分。作为空间想象力发展基础的空间观念应该成为小学阶段甚至是义务教育阶段几何课程的主要培养目标之一。以往对儿童空间能力的培养和发展水平的研究更多地是从心理学的角度进行的,即或是从数学教育角度出发的研究也多半是一些零散的、局部的,缺少对学生空间观念的发展规律和特点进行系统的、全面的研究,也使几何课程的构建缺少了一定的研究基础。因此,本研究力图从课程的角度出发分析空间观念的基本成分,研究支撑其发展的课程要素,考察学生空间观念发展的规律和特点,划分学生的发展水平和阶段,并提出确定相关几何课程内容的建议。本研究首先采用定性研究的方法,从课程的角度出发来分析空间观念的基本成分并划分了空间观念的三个发展水平,水平1:(完全)直观想象阶段;水平2:直观想象与简单分析抽象阶段;水平3:直观想象与复杂分析阶段。依此设计出考察小学生空间观念的发展规律、特点及水平的测试卷。其次,我们选取了三所小学的500多名二年级至六年级的学生做为研究样本,进行了测试。通过对测试结果的统计分析,我们得出了小学生在空间观念方面的发展规律和特点,总结出小学生空间观念发展的阶段性和所能达到的水平。主要结论有:从年级的角度考察学生空间观念发展的规律,我们发现二、三年级(7-8岁)学生的空间观念发展水平比较一致,四、五、六年级(9-11岁)学生的发展水平差异不大,因此在空间观念的发展过程中,可以将他们看成为两个发展阶段。二年级至六年级在较少涉及概念而只与空间想象有关的问题解决中,年级间的差异不显著,低年级的学生能够达到较好的水平;对于复杂的、需较高要求的想象判断等问题,就出现了年级间的差异,而表现出高年级的优势。适时的教学干预是十分必要的,只要给低年级学生提供适当的教学材料,就可能会在空间观念方面有较好的发展。如果没有适时的教学干预,学生空间观念的发展就会受到抑制甚至会造成无法弥补的欠缺...},
  langid = {chinese},
  school = {东北师范大学},
  file = {E:\OneDrive\Zotero Literature\论文项目参考文献\2024【会议】大模型空间认知\刘 - 2007 - 小学生空间观念的发展规律及特点研究.pdf}
}

@article{LiZhongXueShengKongJianRenZhiNengLiJieGouDeYanJiu2005,
  title = {{中学生空间认知能力结构的研究}},
  author = {李, 洪玉 and 林, 崇德},
  year = {2005},
  journal = {心理科学},
  number = {2},
  pages = {269--271},
  issn = {1671-6981},
  doi = {10.16719/j.cnki.1671-6981.2005.02.003},
  urldate = {2024-10-24},
  abstract = {以51 0名中学生为被试,采用自编的《空间认知能力倾向成套测验》,考察了中学生空间认知能力的结构特点。结果表明:(1 )在中学生被试的空间认知能力结构中,主要包括图形分解/组合能力、数学关系形象化表达能力、心理旋转能力、空间意识能力、空间定向能力、图形特征记忆能力和图形特征抽象/概括能力等成分;(2 )在初中生与高中生的空间认知能力结构中,大部分成分是相同的,但这些成分在各自结构中的重要性程度却不相同。},
  langid = {chinese},
  file = {E:\OneDrive\Zotero Literature\论文项目参考文献\2024【会议】大模型空间认知\李和林 - 2005 - 中学生空间认知能力结构的研究.pdf}
}

@misc{Llama32Revolutionizing,
  title = {Llama 3.2: Revolutionizing Edge {{AI}} and Vision with Open, Customizable Models},
  shorttitle = {Llama 3.2},
  journal = {Meta AI},
  urldate = {2024-12-13},
  abstract = {Today, we're releasing Llama 3.2, which includes small and medium-sized vision LLMs, and lightweight, text-only models that fit onto edge and mobile devices.},
  howpublished = {https://ai.meta.com/blog/llama-3-2-connect-2024-vision-edge-mobile-devices/},
  langid = {english},
  file = {C:\Users\wenruixu\Zotero\storage\LJ3JX7JG\llama-3-2-connect-2024-vision-edge-mobile-devices.html}
}

@misc{llamateamai@metaLlama3Herd2024,
  title = {The Llama 3 Herd of Models},
  author = {{Llama Team, AI @ Meta}},
  year = {2024},
  langid = {american},
  file = {E:\OneDrive\Zotero Literature\论文项目参考文献\2024【会议】大模型空间认知\Llama Team, AI @ Meta - 2024 - The llama 3 herd of models.pdf}
}

@incollection{lohmanSpatialAbility1996,
  title = {Spatial {{Ability}} and g},
  booktitle = {Human {{Abilities}}},
  author = {Lohman, David F.},
  year = {1996},
  publisher = {Psychology Press},
  abstract = {Spatial abilities have long been relegated to a secondary status in accounts of human intelligence. Tests of spatial abilities are often viewed as measures of practical and mechanical abilities that are useful in predicting success in technical occupations, but not as measures of abstract reasoning abilities (Smith, 1964). This conflicts with the important role afforded to spatial imagery in accounts of creative thinking (Shepard, 1978), and with the observed correlations between spatial tests and other measures of intelligence. In fact, Spearman (see Spearman \& Wynn Jones, 1950) considered spatial tests merely as unreliable measures of g. Hierarchical factor analyses generally support Spearman's conclusion, especially for complex spatial tests. Such tests are primarily measures of g, secondarily measures of something task-specific, and thirdly measures of something that covaries uniquely with performance on other spatial tasks (Lohman, 1988). Simpler, speeded spatial tasks show lower g loadings, higher task-specific loadings, and higher spatial factor loadings. In this chapter, I first summarize and then attempt to explain these findings. The relationship between spatial task performance and g may reflect both statistical artifacts and psychological factors. Psychological factors include the attentional demands of maintaining and transforming images in working memory (Kyllonen \& Christal, 1990) and the importance of mental models in reasoning (Johnson-Laird, 1983). Indeed, one can turn Spearman's conclusion around and with equal conviction conclude that measures of g are, by and large, unreliable measures of the ability to generate and coordinate different types of mental models in working memory. Evidence that supports and challenges such a conclusion is reviewed.},
  isbn = {978-0-203-77400-7},
  langid = {american},
  file = {E:\OneDrive\Zotero Literature\论文项目参考文献\2024【会议】大模型空间认知\Lohman - 1996 - Spatial Ability and g.pdf}
}

@article{lutkeColouredCubeTest,
  title = {The Coloured Cube Test and the Coloured Mental Rotation Test. {{Two}} New Measures of Spatial Ability and Mental Rotation},
  author = {L{\"u}tke, Nikolay},
  abstract = {This research introduces two new measures of mental rotation (MR) for 4- to 11-year-old children. Instead of the complex achromatic three-dimensional (3D) cube aggregates used with adults (Shepard \& Metzler, 1971), or the flat two-dimensional animals used with children (Quaiser-Pohl, 2003), the new tests uses 3D colourful cubes, either as a standalone, or as a cube aggregate but with fewer elements. The test format is similar to the Raven's Coloured Progressive Matrices Test (RCPM) which also served as a validation tool. The first new test, the Rotated Colour Cube Test (RCCT), consists of multicoloured single cubes in different orientations. Three age groups of 7- to 10year-old children (N=100) were increasingly successful in identifying cubes, with boys from socio-economic background that did not receive state benefits performing better in the more challenging test sections. While cubes that were different to the target in terms of cube face colour made the test easier, differently oriented cubes increased task difficulty. RCCT and RCPM were correlated, with the RCCT being the easier test. The second new test development, the Coloured Mental Rotation Test (CMRT), investigated differences in set-size, angularity, and axis of rotation of coloured cube aggregates in 4- to 11-year-old children (N=80). Several higher-order interactions all involved set-size and showed that 4-cube aggregates were the most economical and best 3D object for children's MR in all age groups. Interestingly, the linear decrease in performance with increasing angularity of 4-cube aggregates was already observed in 4-to 5-year but also still in 10- to 11-year-old boys, as well as in 6- to 7- and 8- to 9-year-old girls. It was concluded that the magical number 4, a capacity limit in attention and shortterm memory (Cowan, 2001), can also be observed in MR, due to the Good Gestalt of the 4-cube aggregates.},
  langid = {english},
  file = {C:\Users\wenruixu\Zotero\storage\G994479M\Lütke - The coloured cube test and the coloured mental rotation test. Two new measures of spatial ability an.pdf}
}

@article{lutkeKeepingItThree2015,
  title = {Keeping {{It}} in {{Three Dimensions}}: {{Measuring}} the {{Development}} of {{Mental Rotation}} in {{Children}} with the {{Rotated Colour Cube Test}} ({{RCCT}})},
  shorttitle = {Keeping {{It}} in {{Three Dimensions}}},
  author = {Lutke, Nikolay and {Lange-Kuettner}, Chris},
  year = {2015},
  month = jun,
  journal = {International Journal of Developmental Science},
  volume = {2015},
  pages = {95--114},
  doi = {10.3233/DEV-14154},
  abstract = {This study introduces the new Rotated Colour Cube Test (RCCT) as a measure of object identification and mental rotation using single 3D colour cube images in a matching-to-sample procedure. One hundred 7- to 11-year-old children were tested with aligned or rotated cube models, distracters and targets. While different orientations of distracters made the RCCT more difficult, different colours of distracters had the opposite effect and made the RCCT easier because colour facilitated clearer discrimination between target and distracters. Ten-year-olds performed significantly better than 7- to 8-year-olds. The RCCT significantly correlated with children's performance on the Raven's Coloured Progressive Matrices Test (RCPM) presumably due to the shared multiple-choice format, but the RCCT was easier, as it did not require sequencing. Children from families with a high socio-economic status performed best on both tests, with boys outperforming girls on the more difficult RCCT test sections.},
  annotation = {TLDR: The new Rotated Colour Cube Test (RCCT) is introduced as a measure of object identification and mental rotation using single 3D colour cube images in a matching-to-sample procedure and children from families with a high socio-economic status performed best.},
  file = {E:\OneDrive\Zotero Literature\论文项目参考文献\2024【会议】大模型空间认知\Lutke和Lange-Kuettner - 2015 - Keeping It in Three Dimensions Measuring the Development of Mental Rotation in Children with the Ro.pdf}
}

@book{maccobyPsychologySexDifferences1974,
  title = {The Psychology of Sex Differences},
  author = {Maccoby, Eleanor E. and Jacklin, Carol N.},
  year = {1974},
  series = {The Psychology of Sex Differences},
  pages = {xiii, 634},
  publisher = {Stanford University Press},
  abstract = {Discusses the development of sexual behavior on the basis of the theory that psychological sex differentiation occurs through imitation, praise or discouragement, and self-socialization. The validity of some of the most widely held beliefs about sex differences is assessed. (PsycINFO Database Record (c) 2016 APA, all rights reserved)},
  isbn = {978-0-8047-0859-3},
  langid = {english},
  keywords = {Human Sex Differences,Psychosexual Behavior},
  file = {C:\Users\wenruixu\Zotero\storage\RIUWLXTC\1975-09417-000.html}
}

@article{maedaPsychometricPropertiesRevised2013,
  title = {Psychometric Properties of the Revised {{PSVT}}: {{R}} for Measuring First Year Engineering Students' Spatial Ability},
  shorttitle = {Psychometric Properties of the Revised {{PSVT}}},
  author = {Maeda, Yukiko and Yoon, So Yoon and {Kim-Kang}, K. and Imbrie, P.K.},
  year = {2013},
  month = jan,
  journal = {International Journal of Engineering Education},
  volume = {29},
  abstract = {While various spatial tests are available, the Purdue Spatial Visualization Tests: Visualization of Rotations (PSVT:R) has been commonly used to predict students' success in the engineering field. While many studies that used the PSVT:R exist, little attention had been given to its psychometric properties in measuring spatial ability and relationships to other academic indices. The purposes of this study were (a) to characterize the item- and test-level functions of the Revised PSVT:R for the use of incoming First Year Engineering (FYE) students, and (b) to investigate its relationship to academicrelated variables to provide validity evidence. Approximately 2400 FYE students enrolled in the fall of 2010 and 2011 in a large Midwestern public university completed the Revised PSVT:R. Students' academic-related variables were also retrieved from the university archive. A variety of statistical analyses, including exploratory and confirmatory factor analyses as well as item analyses, were conducted on the Revised PSVT:R scores. Pearson's product-moment correlation coefficients between the Revised PSVT:R and other academic variables were also obtained. The Revised PSVT:R measures a unidimensional subcomponent of spatial ability. Cronbach's a was 0.84. Items were relatively easy and the test provides the most precise estimate for students whose ability level is at or below average. Weak to moderate correlations were found between the Revised PSVT:R scores and the aptitude test scores. The Revised PSVT:R is a psychometrically sound instrument. However, items are relatively easy, but it is still appropriate to measure spatial visualization ability of the FYE students.},
  langid = {english},
  file = {E\:\\OneDrive\\Zotero Literature\\论文项目参考文献\\2024【会议】大模型空间认知\\Maeda 等 - 2013 - Psychometric properties of the revised PSVT R for measuring first year engineering students' spatia_1.pdf;E\:\\OneDrive\\Zotero Literature\\论文项目参考文献\\2024【会议】大模型空间认知\\Maeda 等 - 2013 - Psychometric Properties of the Revised PSVT R for Measuring First Year Engineering Students' Spatia.pdf}
}

@inproceedings{maierSpatialGeometrySpatial1996,
  title = {Spatial Geometry and Spatial Ability--{{How}} to Make Solid Geometry Solid},
  booktitle = {Selected Papers from the {{Annual Conference}} of {{Didactics}} of {{Mathematics}}},
  author = {Maier, Peter Herbert},
  year = {1996},
  address = {Osnabrueck, Germany: Gesellschaft f{\"u}r Didaktik der Mathematik (GDM)},
  urldate = {2024-12-12},
  langid = {english},
  file = {E:\OneDrive\Zotero Literature\论文项目参考文献\2024【会议】大模型空间认知\maier.pdf}
}

@article{marunicImprovementAssessmentSpatial2014,
  title = {Improvement and Assessment of Spatial Ability in Engineering Education},
  author = {Maruni{\'c}, G and Glazar, Vladimir},
  year = {2014},
  month = jun,
  journal = {Engineering Review},
  volume = {34},
  pages = {139--150},
  abstract = {The development of three-dimensional Computer Aided Design (3D CAD) technology has additionally spurred research into spatial ability to find the ways for its enhancement through teaching and instruction and to understand the mechanism of its assessment. The techniques involved in multimedia engineering environment of today as well as their inclusion into engineering curricula and courses have to be strongly supported by wider knowledge of spatial ability. This paper is a review of research results applied to engineering graphics education by respecting spatial ability as a recognized predictor of success in engineering. The development of engineering graphics teaching based on research suggestions about spatial ability represents an increasingly complex approach that puts additional stress on engineering graphics educators. Thus classical tests for the assessment of spatial ability are described, the applied strategies for their solving are presented, the selected obtained results are compared, and a distinction is drawn between the strategies employed for more complex spatial tasks that engineering is dealing with.},
  langid = {english},
  file = {E:\OneDrive\Zotero Literature\论文项目参考文献\2024【会议】大模型空间认知\Marunić和Glazar - 2014 - Improvement and assessment of spatial ability in engineering education.pdf}
}

@article{mcgeeHumanSpatialAbilities1979,
  title = {Human Spatial Abilities: Psychometric Studies and Environmental, Genetic, Hormonal, and Neurological Influences},
  shorttitle = {Human Spatial Abilities},
  author = {McGee, Mark G.},
  year = {1979},
  journal = {Psychological Bulletin},
  volume = {86},
  number = {5},
  pages = {889--918},
  publisher = {American Psychological Association},
  address = {US},
  issn = {1939-1455},
  doi = {10.1037/0033-2909.86.5.889},
  abstract = {Reviews the spatial abilities literature. Psychometric consideration encompasses (a) factor analytic studies that conclusively demonstrate the existence of at least 2 spatial factors---Visualization and Orientation, and (b) predictive validity studies that argue for the social relevance of these factors. Sex differences in various aspects of perceptual-cognitive functioning (e.g., mathematics, field independence) are interpreted as a secondary consequence of differences with respect to spatial visualization and spatial orientation abilities. Sources of variation in performance on spatial tests including environmental, genetic, hormonal, and neurological are considered, with special emphasis on age and sex differences. Evidence that variation in spatial test scores is to some degree heritable remains positive; however, the X-linked recessive gene hypothesis that has served as a tentative explanation for sex differences in spatial abilities and for the mode of genetic transmission is not supported strongly in recent studies. Neurological studies showing variations in the lateral organization of the human brain provide experimental evidence for a structural source of the variation in spatial abilities, and this evidence is reviewed as it relates to human handedness and cerebral bilateralization for spatial and linguistic functions. (9 p ref) (PsycINFO Database Record (c) 2016 APA, all rights reserved)},
  langid = {english},
  keywords = {,Cerebral Dominance,Environment,Form and Shape Perception,Genetics,Hormones,Human Sex Differences,Imagery,Literature Review,Practice,Spatial Perception},
  file = {E\:\\OneDrive\\Zotero Literature\\论文项目参考文献\\2024【会议】大模型空间认知\\McGee - 1979 - Human spatial abilities psychometric studies and environmental, genetic, hormonal, and neurological.pdf;C\:\\Users\\wenruixu\\Zotero\\storage\\LU82QY29\\doiLanding.html}
}

@incollection{mcgrewCattellHornCarrollTheoryCognitive2005,
  title = {The {{Cattell-Horn-Carroll Theory}} of {{Cognitive Abilities}}: {{Past}}, {{Present}}, and {{Future}}},
  shorttitle = {The {{Cattell-Horn-Carroll Theory}} of {{Cognitive Abilities}}},
  booktitle = {Contemporary {{Intellectual Assessment}}: {{Theories}}, {{Tests}}, and {{Issues}}},
  author = {McGrew, Kevin S.},
  year = {2005},
  pages = {136--181},
  publisher = {The Guilford Press},
  address = {New York, NY, US},
  abstract = {In this chapter, the author presents a synthesized Carroll and Horn-Cattell (CHC) Gf-Gc framework. The primary goals of this chapter are to (1) describe the evolution of contemporary CHC theory; (2) describe the broad and narrow CHC abilities; and (3) review structural evidence that supports the broad strokes of CHC theory. (PsycInfo Database Record (c) 2024 APA, all rights reserved)},
  isbn = {978-1-59385-125-5},
  keywords = {Cognitive Ability,History of Psychology,Theories},
  file = {C:\Users\wenruixu\Zotero\storage\XUGTYJCX\2005-09732-008.html}
}

@article{mcgrewCHCTheoryHuman2009,
  title = {{{CHC}} Theory and the Human Cognitive Abilities Project: Standing on the Shoulders of the Giants of Psychometric Intelligence Research},
  shorttitle = {{{CHC}} Theory and the Human Cognitive Abilities Project},
  author = {McGrew, Kevin S.},
  year = {2009},
  month = jan,
  journal = {Intelligence},
  volume = {37},
  number = {1},
  pages = {1--10},
  issn = {01602896},
  doi = {10.1016/j.intell.2008.08.004},
  urldate = {2024-10-24},
  copyright = {https://www.elsevier.com/tdm/userlicense/1.0/},
  langid = {english},
  file = {E:\OneDrive\Zotero Literature\论文项目参考文献\2024【会议】大模型空间认知\McGrew - 2009 - CHC theory and the human cognitive abilities project standing on the shoulders of the giants of psy.pdf}
}

@article{michaelDescriptionSpatialvisualizationAbilities1957,
  title = {The Description of Spatial-Visualization Abilities},
  author = {Michael, William B. and Guilford, J.P. and Fruchter, Benjamin and Zimmerman, Wayne S.},
  year = {1957},
  month = jul,
  journal = {Educational and Psychological Measurement},
  volume = {17},
  number = {2},
  pages = {185--199},
  issn = {0013-1644, 1552-3888},
  doi = {10.1177/001316445701700202},
  urldate = {2024-10-24},
  copyright = {https://journals.sagepub.com/page/policies/text-and-data-mining-license},
  langid = {english},
  file = {E:\OneDrive\Zotero Literature\论文项目参考文献\2024【会议】大模型空间认知\Michael 等 - 1957 - The description of spatial-visualization abilities.pdf}
}

@article{millerCanSpatialTraining2013,
  title = {Can Spatial Training Improve Long-Term Outcomes for Gifted {{STEM}} Undergraduates?},
  author = {Miller, David I. and Halpern, Diane F.},
  year = {2013},
  month = aug,
  journal = {Learning and Individual Differences},
  volume = {26},
  pages = {141--152},
  issn = {1041-6080},
  doi = {10.1016/j.lindif.2012.03.012},
  urldate = {2024-11-21},
  abstract = {This one-year longitudinal study investigated the benefits of spatial training among highly gifted science, technology, engineering and mathematics (STEM) undergraduates (28 female, 49 male). Compared to a randomized control condition, 12h of spatial training (1) improved the skills to mentally rotate and visualize cross-sections of 3-D objects shortly after training, (2) narrowed gender differences in spatial skills shortly after training, and (3) improved examination scores in introductory physics (d=.38) but not for other STEM courses. After eight months, however, there were no training differences for spatial skills, STEM course grades, physics self-efficacy, or declared majors. Large gender differences, favoring males, persisted for some spatial skills, physics grades, and physics self-efficacy eight months after training. These results suggest that sustained exposure to spatially enriching activities over several semesters or years may be necessary to address gender gaps in spatial skills among highly gifted STEM undergraduates.},
  langid = {english},
  keywords = {Gender differences,Gifted education,Spatial skills,Spatial training,STEM education},
  file = {E\:\\OneDrive\\Zotero Literature\\论文项目参考文献\\2024【会议】大模型空间认知\\Miller和Halpern - 2013 - Can spatial training improve long-term outcomes for gifted STEM undergraduates.pdf;C\:\\Users\\wenruixu\\Zotero\\storage\\6DA8FQP5\\S1041608012000386.html}
}

@misc{momennejadEvaluatingCognitiveMaps2023,
  title = {Evaluating Cognitive Maps and Planning in Large Language Models with {{CogEval}}},
  author = {Momennejad, Ida and Hasanbeig, Hosein and Vieira, Felipe and Sharma, Hiteshi and Ness, Robert Osazuwa and Jojic, Nebojsa and Palangi, Hamid and Larson, Jonathan},
  year = {2023},
  month = sep,
  journal = {arXiv.org},
  urldate = {2024-10-08},
  abstract = {Recently an influx of studies claim emergent cognitive abilities in large language models (LLMs). Yet, most rely on anecdotes, overlook contamination of training sets, or lack systematic Evaluation involving multiple tasks, control conditions, multiple iterations, and statistical robustness tests. Here we make two major contributions. First, we propose CogEval, a cognitive science-inspired protocol for the systematic evaluation of cognitive capacities in Large Language Models. The CogEval protocol can be followed for the evaluation of various abilities. Second, here we follow CogEval to systematically evaluate cognitive maps and planning ability across eight LLMs (OpenAI GPT-4, GPT-3.5-turbo-175B, davinci-003-175B, Google Bard, Cohere-xlarge-52.4B, Anthropic Claude-1-52B, LLaMA-13B, and Alpaca-7B). We base our task prompts on human experiments, which offer both established construct validity for evaluating planning, and are absent from LLM training sets. We find that, while LLMs show apparent competence in a few planning tasks with simpler structures, systematic evaluation reveals striking failure modes in planning tasks, including hallucinations of invalid trajectories and getting trapped in loops. These findings do not support the idea of emergent out-of-the-box planning ability in LLMs. This could be because LLMs do not understand the latent relational structures underlying planning problems, known as cognitive maps, and fail at unrolling goal-directed trajectories based on the underlying structure. Implications for application and future directions are discussed.},
  howpublished = {https://arxiv.org/abs/2309.15129v1},
  langid = {english},
  file = {E:\OneDrive\Zotero Literature\参考文献\【会议论文】大模型空间认知\Momennejad 等 - 2023 - Evaluating cognitive maps and planning in large language models with CogEval.pdf}
}

@article{mooneyUnderstandingGeospatialSkills2023,
  title = {Towards {{Understanding}} the {{Geospatial Skills}} of {{ChatGPT}}: {{Taking}} a {{Geographic Information Systems}} ({{GIS}}) {{Exam}}},
  shorttitle = {Towards {{Understanding}} the {{Geospatial Skills}} of {{ChatGPT}}},
  author = {Mooney, Peter and Cui, Wencong and Guan, Boyuan and Juh{\'a}sz, Levente},
  year = {2023},
  month = jun,
  publisher = {EarthArXiv},
  urldate = {2024-11-07},
  abstract = {This paper examines the performance of ChatGPT, a large language model (LLM), in a geographic information systems (GIS) exam. As LLMs like ChatGPT become increasingly prevalent in various domains, including education, it is important to understand their capabilities and limitations in specialized subject areas such as GIS. Human learning of spatial concepts significantly differs from LLM training methodologies. Therefore, this study aims to assess ChatGPT's performance and spatial literacy by challenging it with a real GIS exam. By analyzing ChatGPT's responses and evaluating its understanding of GIS principles, we gain insights into the potential applications and challenges of LLMs in spatially-oriented fields. We conduct our evaluation with two models, GPT-3.5 and GPT-4, to understand whether general improvements of an LLM translate to improvements in answering questions related to the spatial domain. We find that both GPT variants can pass a balanced, introductory GIS exam, scoring 63.3{\textbackslash}\% (GPT-3.5) and 88.3{\textbackslash}\% (GPT-4), which correspond to grades D and B+ respectively in standard US letter grading scale. In addition, we also identify specific questions and topics where the LLMs struggle to grasp spatial concepts, highlighting the challenges in teaching such topics to these models. Finally, we assess ChatGPT's performance in specific aspects of GIS, including spatial analysis, basic concepts of mapping, and data management. This granular analysis provides further insights into the strengths and weaknesses of ChatGPT's GIS literacy. This research contributes to the ongoing dialogue on the integration of AI models in education and can provide guidance for educators, researchers, and practitioners seeking to leverage LLMs in GIS. By focusing on specific questions or concepts that pose difficulties for the LLM, this study addresses the nuances of teaching spatial concepts to AI models and offers potential avenues for improvement in spatial literacy within future iterations of LLMs.},
  copyright = {CC BY Attribution 4.0 International},
  langid = {english},
  file = {E:\OneDrive\Zotero Literature\论文项目参考文献\2024【会议】大模型空间认知\Mooney 等 - 2023 - Towards Understanding the Geospatial Skills of ChatGPT Taking a Geographic Information Systems (GIS.pdf}
}

@incollection{nagy-kondorSpatialAbilityMeasurement2017,
  title = {Spatial Ability: Measurement and Development},
  shorttitle = {Spatial Ability},
  booktitle = {Visual-Spatial {{Ability}} in {{STEM Education}}: {{Transforming Research}} into {{Practice}}},
  author = {{Nagy-Kondor}, Rita},
  editor = {Khine, Myint Swe},
  year = {2017},
  pages = {35--58},
  publisher = {Springer International Publishing},
  address = {Cham},
  doi = {10.1007/978-3-319-44385-0_3},
  urldate = {2024-11-21},
  abstract = {Spatial visualization skills are essential for an expert to be successful in several disciplines. Spatial thinking has an important role in the teaching and learning of mathematics process and engineering studies; previous studies proved that this ability has positive correlations with geometry and mathematics education. Spatial visualisation ability is a prerequisite for success in technical education. Studies deal with spatial ability are vital in the field of mathematics, geometry and engineering, but also in chemistry, physics, anatomy and psychology, so measurement and development of spatial ability are very useful. Many studies have shown that there are correlations between various measures of spatial skills and performance in particular Science, Technology, Engineering and Mathematics (STEM) (Uttal DH, Cohen CA, Psychol Learn Motiv 57:147--181, 2012).},
  isbn = {978-3-319-44385-0},
  langid = {english},
  keywords = {Dynamic geometry systems,Object rotations,Spatial visualization ability,STEM,Technical education},
  file = {E:\OneDrive\Zotero Literature\论文项目参考文献\2024【会议】大模型空间认知\Nagy-Kondor - 2017 - Spatial ability measurement and development.pdf}
}

@inproceedings{newcombeThinkingSpatialThinking2015,
  title = {Thinking about Spatial Thinking: New Typology, New Assessments},
  shorttitle = {Thinking about Spatial Thinking},
  booktitle = {Studying {{Visual}} and {{Spatial Reasoning}} for {{Design Creativity}}},
  author = {Newcombe, Nora S. and Shipley, Thomas F.},
  editor = {Gero, John S.},
  year = {2015},
  pages = {179--192},
  publisher = {Springer Netherlands},
  address = {Dordrecht},
  doi = {10.1007/978-94-017-9297-4_10},
  abstract = {Our world is a world that exists in space, and a world without space is literally inconceivable. Given this basic truth, it is clear that living in the world requires spatial functioning of some kind. Being creative in this world, and designing new tools and new habitats, probably requires even higher levels of spatial functioning. And people vary in their levels of spatial ability. What do these facts mean for the field of design? There are certain obvious practical questions. For example, should design schools accept only applicants who test high in spatial ability, following the lead of dental schools, which assess spatial thought on the Dental Admissions Test or with practical exercises in assignments such as tooth modeling? Or should design schools strive to enhance the spatial ability of anyone with the desire to do creative design, following the lead of selection committees for surgical residencies, which do not assess spatial ability in any way? The latter course is arguably supported by evidence (to be discussed later) showing that spatial skill is malleable. As another example of a practical question for design, consider what designers should or could know about the potential users of a product. What kinds and levels of spatial abilities should they assume that users will have? How would they be able to predict when a new tool will be too hard to master for many users, or when a building design will result in an environment in which many people easily get lost?},
  isbn = {978-94-017-9297-4},
  langid = {english},
  keywords = {Mental Rotation,Perspective Taking,Spatial Ability,Spatial Functioning,Spatial Skill},
  annotation = {TLDR: The field of design should strive to enhance the spatial ability of anyone with the desire to do creative design, following the lead of selection committees for surgical residencies, which do not assess spatial ability in any way.},
  file = {E:\OneDrive\Zotero Literature\论文项目参考文献\2024【会议】大模型空间认知\Newcombe和Shipley - 2015 - Thinking about spatial thinking new typology, new assessments.pdf}
}

@article{papantoniouDoesCognitiveInterference2017,
  title = {Does Cognitive Interference Induce Measurement Bias in Cognitive Ability Tests?},
  author = {Papantoniou, Georgia and Moraitou, Despina and Filippidou, Dimitra and Katsadima, Effie and Dinou, Magda},
  year = {2017},
  month = jan,
  journal = {Journal of Behavioral and Brain Science},
  volume = {7},
  number = {1},
  pages = {21--29},
  publisher = {Scientific Research Publishing},
  doi = {10.4236/jbbs.2017.71003},
  urldate = {2024-11-21},
  abstract = {The aim of this paper was to test for measurement bias, due to cognitive interference on cognitive ability tests, using a structural equation modeling technique. The sample consisted of 231 undergraduate students who were examined with three tests addressed to numerical ability, space visualization and inductive ability, respectively. They were also asked to respond to the Cognitive Interference Questionnaire tapping task-oriented worries while working on the aforementioned tests. In comparing two nested models, one hypothesizing measurement bias due to cognitive interference and one not, results show that the test tapping inductive ability displays measurement bias due to cognitive interference.},
  copyright = {http://creativecommons.org/licenses/by/4.0/},
  langid = {english},
  file = {E:\OneDrive\Zotero Literature\论文项目参考文献\2024【会议】大模型空间认知\Papantoniou 等 - 2017 - Does cognitive interference induce measurement bias in cognitive ability tests.pdf}
}

@inproceedings{parkinsonInvestigatingRelationshipSpatial2018,
  title = {Investigating the {{Relationship Between Spatial Skills}} and {{Computer Science}}},
  booktitle = {Proceedings of the 2018 {{ACM Conference}} on {{International Computing Education Research}}},
  author = {Parkinson, Jack and Cutts, Quintin},
  year = {2018},
  month = aug,
  series = {{{ICER}} '18},
  pages = {106--114},
  publisher = {Association for Computing Machinery},
  address = {New York, NY, USA},
  doi = {10.1145/3230977.3230990},
  urldate = {2024-11-21},
  abstract = {The relationship between spatial skills training and computer science learning is unclear. Reported experiments provide tantalising, though not convincing, evidence that training a programming student's spatial skills may accelerate the development of their programming skills. Given the well-documented challenge of learning to program, such acceleration would be welcomed. Despite the experimental results, no attempt has been made to develop a model of how a linkage between spatial skills and computer science ability might operate, hampering the development of a sound research programme to investigate the issue further. This paper surveys the literature on spatial skills and investigates the various underlying cognitive skills involved. It poses a theoretical model for the relationship between computer science ability and spatial skills, exploring ways in which the cognitive processes involved in each overlap, and hence may influence one another. An experiment shows that spatial skills typically increase as the level of academic achievement in computer science increases. Overall, this work provides a substantial foundation for, and encouragement to develop, a major research programme investigating precisely how spatial skills training influences computer science learning, and hence whether computer science education could be significantly improved.},
  isbn = {978-1-4503-5628-2},
  annotation = {TLDR: A theoretical model is posed for the relationship between computer science ability and spatial skills, exploring ways in which the cognitive processes involved in each overlap, and hence may influence one another, and whether computer science education could be significantly improved.},
  file = {E:\OneDrive\Zotero Literature\论文项目参考文献\2024【会议】大模型空间认知\Parkinson和Cutts - 2018 - Investigating the Relationship Between Spatial Skills and Computer Science.pdf}
}

@article{parkinsonPracticeReportSix2021,
  title = {Practice Report: Six Studies of Spatial Skills Training in Introductory Computer Science},
  shorttitle = {Practice Report},
  author = {Parkinson, Jack and Bockmon, Ryan and Cutts, Quintin and Liut, Michael and Petersen, Andrew and Sorby, Sheryl},
  year = {2021},
  month = dec,
  journal = {ACM Inroads},
  volume = {12},
  number = {4},
  pages = {18--29},
  issn = {2153-2184, 2153-2192},
  doi = {10.1145/3494574},
  urldate = {2024-11-21},
  langid = {english},
  annotation = {TLDR: Six distinct case studies of training deliveries of spatial skills training for Computing Science students are described, highlighting the main challenges faced and some important takeaways.},
  file = {E:\OneDrive\Zotero Literature\论文项目参考文献\2024【会议】大模型空间认知\Parkinson 等 - 2021 - Practice report six studies of spatial skills training in introductory computer science.pdf}
}

@article{pawlak-jakubowskaEvaluationSTEMStudents2023,
  title = {Evaluation of {{STEM}} Students' Spatial Abilities Based on a Novel Net Cube Imagination Test},
  author = {{Pawlak-Jakubowska}, Anita and Terczy{\'n}ska, Ewa},
  year = {2023},
  month = oct,
  journal = {Scientific Reports},
  volume = {13},
  number = {1},
  pages = {17296},
  publisher = {Nature Publishing Group},
  issn = {2045-2322},
  doi = {10.1038/s41598-023-44371-5},
  urldate = {2024-11-21},
  abstract = {This study aimed to determine the level of spatial ability among STEM students. A universal multiple-choice test was prepared. The validity of the test and the effectiveness of its application were tested. The test is an extension of those currently in use. It contains tasks on spatial perception, spatial visualization, mental folding, rotation of spatial elements, and representation of spatial elements on a plane. The test consists of 16 tasks showing a cube with lines located on the walls. The student's task was to determine the development of the cube and mentally construct a cube based on the development. The results of the test determined the level of progress of the group (105 participants), and showed that a significant number of students have difficulties in perceiving and working with a three-dimensional object. On average 55\% of the questions were answered correctly. For the group tested, reading a flat drawing and determining axonometry proved easier than other task. Students who attended technical high school or had design experience scored better. During the course, measures to improve teaching were introduced. Spatial model work was strengthened and initial tasks were adjusted according to the level of the group. Emphasis on teamwork and consultation was introduced for those with the lowest scores. The applied modifications in classroom management had a good effect. The average of the final grade was B. The test is a useful tool for academics and students to study spatial ability and improve teaching activities for STEM students.},
  copyright = {2023 The Author(s)},
  langid = {english},
  keywords = {,Civil engineering,Engineering},
  annotation = {TLDR: It is shown that a significant number of students have difficulties in perceiving and working with a three-dimensional object and a universal multiple-choice test is a useful tool for academics and students to study spatial ability and improve teaching activities for STEM students.},
  file = {E:\OneDrive\Zotero Literature\论文项目参考文献\2024【会议】大模型空间认知\Pawlak-Jakubowska和Terczyńska - 2023 - Evaluation of STEM students' spatial abilities based on a novel net cube imagination test.pdf}
}

@misc{PDFManualKit,
  title = {[{{PDF}}] Manual for Kit of Factor-Referenced Cognitive Tests {\textbar} Semantic Scholar},
  urldate = {2024-11-21},
  howpublished = {https://www.semanticscholar.org/paper/Manual-for-kit-of-factor-referenced-cognitive-tests-Ekstrom-French/5791328586959dab9fda8476bf055b31bbfed1ff},
  langid = {english},
  file = {C:\Users\wenruixu\Zotero\storage\L33I2J8T\5791328586959dab9fda8476bf055b31bbfed1ff.html}
}

@article{pellegrinoUnderstandingSpatialAbility1984,
  title = {Understanding Spatial Ability},
  author = {Pellegrino, James W. and Alderton, David L. and Shute, Valerie J.},
  year = {1984},
  month = sep,
  journal = {Educational Psychologist},
  volume = {19},
  number = {4},
  pages = {239--253},
  issn = {0046-1520, 1532-6985},
  doi = {10.1080/00461528409529300},
  urldate = {2024-10-24},
  langid = {english},
  file = {E:\OneDrive\Zotero Literature\论文项目参考文献\2024【会议】大模型空间认知\Pellegrino 等 - 1984 - Understanding spatial ability.pdf}
}

@article{petersRedrawnVandenbergKuse1995,
  title = {A {{Redrawn Vandenberg}} and {{Kuse Mental Rotations Test}} - {{Different Versions}} and {{Factors That Affect Performance}}},
  author = {Peters, M. and Laeng, B. and Latham, K. and Jackson, M. and Zaiyouna, R. and Richardson, C.},
  year = {1995},
  month = jun,
  journal = {Brain and Cognition},
  volume = {28},
  number = {1},
  pages = {39--58},
  issn = {0278-2626},
  doi = {10.1006/brcg.1995.1032},
  urldate = {2024-11-07},
  abstract = {The available versions of the Vendenberg and Kuse (1978) Mental Rotations Test (MRT) have physically deteriorated because only copies of copies are available. We report results from a redrawn version of the MRT and for alternate versions of the test. Males perform better than females, and students drawn from the physical sciences perform better than students drawn from the social sciences and humanities, confirming other reports with the original version of the MRT. Subjects find it very hard to perform the MRT when stimuli require rotation along both the top/bottom axis and the left/right axis. The magnitude of effect sizes for sex (which account, on average, for some 20\% of the variance) does not increase with increasing difficulty of the task. Minimal strategy effects were observed and females did not perform differently during the menstrual period as opposed to the days between the menstrual periods. Practice effects are dramatic, confirming other reports with the original MRT, and can also be shown to be powerful in a transfer for practice paradigm, where test and retest involve different versions of the MRT. Main effects of handedness on MRT performance were not found.},
  langid = {american},
  annotation = {TLDR: Practice effects are dramatic, confirming other reports with the original MRT, and can also be shown to be powerful in a transfer for practice paradigm, where test and retest involve different versions of the MRT.},
  file = {E\:\\OneDrive\\Zotero Literature\\论文项目参考文献\\2024【会议】大模型空间认知\\Peters 等 - 1995 - A Redrawn Vandenberg and Kuse Mental Rotations Test - Different Versions and Factors That Affect Per.pdf;C\:\\Users\\wenruixu\\Zotero\\storage\\73GC2JB6\\S0278262685710329.html;C\:\\Users\\wenruixu\\Zotero\\storage\\JMREBAGI\\S0278262685710329.html}
}

@article{poratSpatialAbilityUnderstanding2023,
  title = {Spatial Ability: Understanding the Past, Looking into the Future},
  shorttitle = {Spatial Ability},
  author = {Porat, Ronen and Ceobanu, Ciprian},
  year = {2023},
  month = may,
  journal = {European Proceedings of Educational Sciences},
  volume = {Education, Reflection, Development - ERD 2022},
  publisher = {European Publisher},
  issn = {2672-815X},
  doi = {10.15405/epes.23056.9},
  urldate = {2024-10-24},
  abstract = {Spatial ability (SA) refers to the ability to generate, retain and manipulate abstract visual images. From 1880 to 1940 SA was gradually understood and defined as an independent, unique ability and justly included as one of Gardner's types of intelligences. Later, Maier improved Gardner's model by distinguishing between five types of spatial abilities and intelligence: Spatial perception, Visualization, Mental rotation, Spatial relations and Spatial orientation. During the 70's and 80's the developmental attributes of the term were addressed. Those studies wished to understand how and when SA develops and naturally were directed mostly at children as subjects. Those studies revealed that SA is an essential ability to the development of mathematical skills. Later developmental studies addressed adult SA development and accordingly found that SA was a predictor of success in STEM fields of academic studies. Furthermore, during those years psychometric studies started to develop standardized tests to measure SA. Starting from the 80's and up to now, a great deal of research is being directed at technology and the way it influences SA development. These studies direct special attention at studying how new technologies such as computer games and VR affect SA measuring and training. The current research wishes to continue the rich tradition of this field of studies and draws attention to first year engineering and architecture students. It seeks to investigate how to best train their SA and the way this training will influence future achievements on both fields.},
  langid = {english},
  file = {E:\OneDrive\Zotero Literature\论文项目参考文献\2024【会议】大模型空间认知\Porat和Ceobanu - 2023 - Spatial ability understanding the past, looking into the future.pdf}
}

@misc{PsychometricPropertiesRevised,
  title = {Psychometric Properties of the {{Revised Purdue Spatial Visualization Tests}}: {{Visualization}} of {{Rotations}} (the {{Revised PSVT}}:{{R}}) - {{ProQuest}}},
  shorttitle = {Psychometric Properties of the {{Revised Purdue Spatial Visualization Tests}}},
  urldate = {2024-11-21},
  abstract = {Explore millions of resources from scholarly journals, books, newspapers, videos and more, on the ProQuest Platform.},
  howpublished = {https://www.proquest.com/docview/904417099?sourcetype=Dissertations\%20\&\%20Theses},
  langid = {english},
  file = {C:\Users\wenruixu\Zotero\storage\K5B5CUB2\904417099.html}
}

@article{quaiser-pohlRelationshipComputergamePreference2006,
  title = {The Relationship between Computer-Game Preference, Gender, and Mental-Rotation Ability},
  author = {{Quaiser-Pohl}, Claudia and Geiser, Christian and Lehmann, Wolfgang},
  year = {2006},
  month = feb,
  journal = {Personality and Individual Differences},
  volume = {40},
  number = {3},
  pages = {609--619},
  issn = {0191-8869},
  doi = {10.1016/j.paid.2005.07.015},
  urldate = {2024-11-21},
  abstract = {This study examined how computer-game preference relates to mental-rotation test (MRT) performance and to gender differences. Subjects were 861 German secondary-school children (mean age=14.67; range 10--20 years). Latent class analysis with the data of a computer-game preference scale revealed three types of players: ``non-players'', ``action-and-simulation game players'' and ``logic-and-skill-training game players''. Large gender differences were found with respect to class assignment. More females than males were found in the ``logic-and-skill-training game player'' class (82.9\%) and in the class of ``non-players'' (81.9\%). Males in contrast were overrepresented (81.7\%) in the class of ``action-and-simulation game players''. As expected, males on average outperformed females in mental-rotation test performance (d=0.63). Furthermore, ANOVA results indicated mean differences in mental-rotation ability between action-and-simulation players and non-players (partial {$\eta$}2=.01) as well as age differences (partial {$\eta$}2=.04). With boys, non-players on average had lower MRT scores than action-and-simulation game players. For females, computer-game preference was unrelated to MRT performance. Results are discussed within a nature--nurture-interactionist framework of gender differences in spatial abilities.},
  langid = {english},
  keywords = {Computer-games,Gender differences,Mental-rotation,Spatial ability},
  file = {C:\Users\wenruixu\Zotero\storage\6EIPVZRY\S0191886905002813.html}
}

@article{safhalterDevelopmentSpatialThinking2022,
  title = {Development of Spatial Thinking Abilities in Engineering {{3D}} Modeling Course Aimed at Lower Secondary Students},
  author = {{\v S}afhalter, Andrej and Glode{\v z}, Sre{\v c}ko and Sorgo, Andrej and Ploj Virti{\v c}, Mateja},
  year = {2022},
  month = mar,
  journal = {International Journal of Technology and Design Education},
  volume = {32},
  doi = {10.1007/s10798-020-09597-8},
  abstract = {Spatial visualization ability is an important factor in a child's cognitive development. Its development is affected by numerous factors such as general intelligence, problem-solving skills, gender, playing building games, experience with engineering drawing and 3D modelling, etc. The study aimed to explore how engineering 3D modelling with SketchUp computer programme affects the development of students' spatial thinking and visualization in consideration of previous experience with 3D modelling and students' grades in Technics and Technology. The study included 166 11--14-year-old students who were assigned to an experimental and a control group. A pre-and post-test were applied for initial and final testing. To test students' spatial visualization abilities, an experimental tool with the following elements was assembled: Picture Rotation Test, Form Board Test, The Punched Holes Test, Differential Aptitude Test: Space Relations, The Surface Development Test, Mental Rotation Test, Purdue Spatial Visualization Test: Rotations. The experimental group was included in 30-h training in 3D modelling with SketchUp. The results have shown an excellent response of students in the experimental group to the training and confirmed the expectations concerning the improvement of spatial visualization abilities of these students irrespective of their previous experience and school grades in Technics and Technology. The study has shown that introducing spatial modelling with SketchUp in early technics and technology education enables more effective development and improvement of children's spatial visualization ability skills.},
  langid = {english},
  file = {E:\OneDrive\Zotero Literature\论文项目参考文献\2024【会议】大模型空间认知\Šafhalter 等 - 2022 - Development of spatial thinking abilities in engineering 3D modeling course aimed at lower secondary.pdf}
}

@misc{sharmaExploringImprovingSpatial2023,
  title = {Exploring and Improving the Spatial Reasoning Abilities of Large Language Models},
  author = {Sharma, Manasi},
  year = {2023},
  month = dec,
  number = {arXiv:2312.01054},
  eprint = {2312.01054},
  publisher = {arXiv},
  doi = {10.48550/arXiv.2312.01054},
  urldate = {2024-11-07},
  abstract = {Large Language Models (LLMs) represent formidable tools for sequence modeling, boasting an innate capacity for general pattern recognition. Nevertheless, their broader spatial reasoning capabilities, especially applied to numerical trajectory data, remain insufficiently explored. In this paper, we investigate the out-of-the-box performance of ChatGPT-3.5, ChatGPT-4 and Llama 2 7B models when confronted with 3D robotic trajectory data from the CALVIN baseline and associated tasks, including 2D directional and shape labeling. Additionally, we introduce a novel prefix-based prompting mechanism, which yields a 33\% improvement on the 3D trajectory data and an increase of up to 10\% on SpartQA tasks over zero-shot prompting (with gains for other prompting types as well). The experimentation with 3D trajectory data offers an intriguing glimpse into the manner in which LLMs engage with numerical and spatial information, thus laying a solid foundation for the identification of target areas for future enhancements.},
  archiveprefix = {arXiv},
  langid = {english},
  keywords = {Computer Science - Artificial Intelligence,Computer Science - Computation and Language,Computer Science - Robotics},
  annotation = {TLDR: This paper investigates the out-of-the-box performance of ChatGPT-3.5, ChatG PT-4 and Llama 2 7B models when confronted with 3D robotic trajectory data from the CALVIN baseline and associated tasks, including 2D directional and shape labeling.},
  file = {E\:\\OneDrive\\Zotero Literature\\Sharma - 2023 - Exploring and improving the spatial reasoning abilities of large language models.pdf;C\:\\Users\\wenruixu\\Zotero\\storage\\RECYEL8J\\2312.html}
}

@misc{SpatialAbilityTest,
  title = {Spatial {{Ability Test}}},
  journal = {Aptitude-test.com},
  urldate = {2024-11-07},
  abstract = {What is a Spatial Ability Test? Find out here and try a free Spatial Ability practice test.},
  langid = {american},
  file = {C:\Users\wenruixu\Zotero\storage\82A3F7YU\spatial-ability.html}
}

@article{spearmanGeneralIntelligenceObjectively1904,
  title = {"general Intelligence," Objectively Determined and Measured},
  author = {Spearman, C.},
  year = {1904},
  month = apr,
  journal = {American Journal of Psychology},
  volume = {15},
  number = {2},
  eprint = {1412107},
  eprinttype = {jstor},
  pages = {201},
  issn = {00029556},
  doi = {10.2307/1412107},
  urldate = {2024-10-24},
  langid = {english},
  file = {E:\OneDrive\Zotero Literature\论文项目参考文献\2024【会议】大模型空间认知\Spearman - 1904 - general intelligence, objectively determined and measured.pdf}
}

@book{tangSparkleMasteringBasic2024,
  title = {Sparkle: Mastering Basic Spatial Capabilities in Vision Language Models Elicits Generalization to Composite Spatial Reasoning},
  shorttitle = {Sparkle},
  author = {Tang, Yihong and Qu, Ao and Wang, Zhaokai and Zhuang, Dingyi and Wu, Zhaofeng and Ma, Wei and Wang, Shenhao and Zheng, Yunhan and Zhao, Zhan and Zhao, Jinhua},
  year = {2024},
  month = oct,
  doi = {10.48550/arXiv.2410.16162},
  abstract = {Vision language models (VLMs) have demonstrated impressive performance across a wide range of downstream tasks. However, their proficiency in spatial reasoning remains limited, despite its crucial role in tasks involving navigation and interaction with physical environments. Specifically, much of the spatial reasoning in these tasks occurs in two-dimensional (2D) environments, and our evaluation reveals that state-of-the-art VLMs frequently generate implausible and incorrect responses to composite spatial reasoning problems, including simple pathfinding tasks that humans can solve effortlessly at a glance. To address this, we explore an effective approach to enhance 2D spatial reasoning within VLMs by training the model on basic spatial capabilities. We begin by disentangling the key components of 2D spatial reasoning: direction comprehension, distance estimation, and localization. Our central hypothesis is that mastering these basic spatial capabilities can significantly enhance a model's performance on composite spatial tasks requiring advanced spatial understanding and combinatorial problem-solving. To investigate this hypothesis, we introduce Sparkle, a framework that fine-tunes VLMs on these three basic spatial capabilities by synthetic data generation and targeted supervision to form an instruction dataset for each capability. Our experiments demonstrate that VLMs fine-tuned with Sparkle achieve significant performance gains, not only in the basic tasks themselves but also in generalizing to composite and out-of-distribution spatial reasoning tasks (e.g., improving from 13.5\% to 40.0\% on the shortest path problem). These findings underscore the effectiveness of mastering basic spatial capabilities in enhancing composite spatial problem-solving, offering insights for improving VLMs' spatial reasoning capabilities.},
  langid = {english},
  file = {E:\OneDrive\Zotero Literature\论文项目参考文献\2024【会议】大模型空间认知\Tang 等 - 2024 - Sparkle mastering basic spatial capabilities in vision language models elicits generalization to co.pdf}
}

@article{thurstonePrimaryAbilitiesVisual1950,
  title = {Some Primary Abilities in Visual Thinking},
  author = {Thurstone, L. L.},
  year = {1950},
  journal = {Proceedings of The American Philosophical Society},
  volume = {94},
  number = {6},
  eprint = {3143593},
  eprinttype = {jstor},
  pages = {517--521},
  publisher = {American Philosophical Society},
  issn = {0003-049X},
  urldate = {2024-10-24},
  langid = {english},
  file = {E:\OneDrive\Zotero Literature\论文项目参考文献\2024【会议】大模型空间认知\Thurstone - 1950 - Some primary abilities in visual thinking.pdf}
}

@article{uttalHowCanWe2024,
  title = {How {{Can We Best Assess Spatial Skills}}? {{Practical}} and {{Conceptual Challenges}}},
  shorttitle = {How {{Can We Best Assess Spatial Skills}}?},
  author = {Uttal, David H. and McKee, Kiley and Simms, Nina and Hegarty, Mary and Newcombe, Nora S.},
  year = {2024},
  month = jan,
  journal = {Journal of Intelligence},
  volume = {12},
  number = {1},
  pages = {8},
  publisher = {Multidisciplinary Digital Publishing Institute},
  issn = {2079-3200},
  doi = {10.3390/jintelligence12010008},
  urldate = {2024-11-07},
  abstract = {Spatial thinking skills are associated with performance, persistence, and achievement in science, technology, engineering, and mathematics (STEM) school subjects. Because STEM knowledge and skills are integral to developing a well-trained workforce within and beyond STEM, spatial skills have become a major focus of cognitive, developmental, and educational research. However, these efforts are greatly hampered by the current lack of access to reliable, valid, and well-normed spatial tests. Although there are hundreds of spatial tests, they are often hard to access and use, and information about their psychometric properties is frequently lacking. Additional problems include (1) substantial disagreement about what different spatial tests measure---even two tests with similar names may measure very different constructs; (2) the inability to measure some STEM-relevant spatial skills by any existing tests; and (3) many tests only being available for specific age groups. The first part of this report delineates these problems, as documented in a series of structured and open-ended interviews and surveys with colleagues. The second part outlines a roadmap for addressing the problems. We present possibilities for developing shared testing systems that would allow researchers to test many participants through the internet. We discuss technological innovations, such as virtual reality, which could facilitate the testing of navigation and other spatial skills. Developing a bank of testing resources will empower researchers and educators to explore and support spatial thinking in their disciplines, as well as drive the development of a comprehensive and coherent theoretical understanding of spatial thinking.},
  copyright = {http://creativecommons.org/licenses/by/3.0/},
  langid = {english},
  keywords = {assessment and measurement,psychometrics,spatial cognition},
  file = {E:\OneDrive\Zotero Literature\论文项目参考文献\2024【会议】大模型空间认知\Uttal 等 - 2024 - How Can We Best Assess Spatial Skills Practical and Conceptual Challenges.pdf}
}

@article{uttalMalleabilitySpatialSkills2013,
  title = {The Malleability of Spatial Skills: A Meta-Analysis of Training Studies},
  shorttitle = {The Malleability of Spatial Skills},
  author = {Uttal, David H. and Meadow, Nathaniel G. and Tipton, Elizabeth and Hand, Linda L. and Alden, Alison R. and Warren, Christopher and Newcombe, Nora S.},
  year = {2013},
  month = mar,
  journal = {Psychological Bulletin},
  volume = {139},
  number = {2},
  pages = {352--402},
  issn = {1939-1455, 0033-2909},
  doi = {10.1037/a0028446},
  urldate = {2024-10-24},
  langid = {english},
  annotation = {TLDR: The results suggest that spatially enriched education could pay substantial dividends in increasing participation in mathematics, science, and engineering.},
  file = {E:\OneDrive\Zotero Literature\论文项目参考文献\2024【会议】大模型空间认知\Uttal 等 - 2013 - The malleability of spatial skills a meta-analysis of training studies.pdf}
}

@misc{VandenbergKuseMental,
  title = {Vandenberg \& {{Kuse Mental Rotation Test}} ({{Redrawn}} Version)},
  journal = {SILC},
  urldate = {2024-11-07},
  abstract = {The original Vandenberg \&amp; Kuse Mental Rotation Test has deteriorated to such an extent (only copies of copies are available) that it is of questionable usefulness. We have redrawn this test and it is available in four versions},
  howpublished = {https://www.spatiallearning.org/tools/vandenberg-kuse-mental-rotation-test-redrawn-version},
  langid = {american},
  file = {C:\Users\wenruixu\Zotero\storage\K8VJVXFQ\vandenberg-kuse-mental-rotation-test-redrawn-version.html}
}

@article{vandenbergMentalRotationsGroup1978,
  title = {Mental {{Rotations}}, a {{Group Test}} of {{Three-Dimensional Spatial Visualization}}},
  author = {Vandenberg, Steven G. and Kuse, Allan R.},
  year = {1978},
  month = dec,
  journal = {Perceptual and Motor Skills},
  volume = {47},
  number = {2},
  pages = {599--604},
  issn = {0031-5125, 1558-688X},
  doi = {10.2466/pms.1978.47.2.599},
  urldate = {2024-11-07},
  abstract = {A new paper-and-pencil test of spatial visualization was constructed from the figures used in the Chronometric study of Shepard and Metzler (1971). In large samples, the new test displayed substantial internal consistency (Kuder-Richardson 20 = .88), a test-retest reliability (.83), and consistent sex differences over the entire range of ages investigated. Correlations with other measures indicated strong association with tests of spatial visualization and virtually no association with tests of verbal ability.},
  copyright = {https://journals.sagepub.com/page/policies/text-and-data-mining-license},
  langid = {english},
  annotation = {TLDR: A new paper-and-pencil test of spatial visualization was constructed from the figures used in the Chronometric study of Shepard and Metzler (1971), and in large samples, the new test displayed substantial internal consistency and a test-retest reliability.},
  file = {E:\OneDrive\Zotero Literature\论文项目参考文献\2024【会议】大模型空间认知\Vandenberg和Kuse - 1978 - Mental Rotations, a Group Test of Three-Dimensional Spatial Visualization.pdf}
}

@article{velascoExpertNavigatorsDeploy,
  title = {Expert {{Navigators Deploy Rational Hierarchical Priorization Over Predictive Maps For Large-Scale Real-World Planning}}},
  author = {Velasco, Pablo Fernandez and Griesbauer, Eva-Maria and Brunec, Iva and Morley, Jeremy and Manley, Ed and McNamee, Daniel C and Spiers, Hugo J},
  abstract = {Efficient planning is a distinctive hallmark of human intelligence. Computational analyses of human behavior during planning provide evidence for hierarchically segmented representations of the state space of options. However, such evidence derives from simplistic tasks with small state-spaces that belie the complexity of real-world planning. Here, we examine the street-by-street route plans of London taxi drivers navigating across more than 26,000 streets in London (UK). Response times were faster for states with higher successor representations, providing evidence for predictive mapping. We also find an effect for the interaction between a state's successor representation and local transition entropy, which indicates hierarchical chunking of transition sequences, and thus provides real-world support to existing theories of hierarchical state-space representations and planning. Finally, we explored how planning unfolded dynamically over different phases of the constructed journey and identify theoretic principles by which expert planners rationally prioritize specific states during the planning process. Overall, our findings provide real-world evidence for predictive maps and rational hierarchical prioritization in expert route planning.},
  langid = {english},
  file = {E:\OneDrive\Zotero Literature\参考文献\【会议论文】大模型空间认知\Velasco 等 - Expert Navigators Deploy Rational Hierarchical Priorization Over Predictive Maps For Large-Scale Rea.pdf}
}

@article{vernonAbilityFactorsEnvironmental1965,
  title = {Ability Factors and Environmental Influences},
  author = {Vernon, Philip E.},
  year = {1965},
  month = sep,
  journal = {American Psychologist},
  volume = {20},
  number = {9},
  pages = {723--733},
  issn = {1935-990X, 0003-066X},
  doi = {10.1037/h0021472},
  urldate = {2024-10-24},
  langid = {english},
  annotation = {TLDR: The following lectureship is established, under the auspices of the American Psychological Association, an annual lectureship to call attention to the importance of the discovery and development of talented persons.},
  file = {E:\OneDrive\Zotero Literature\论文项目参考文献\2024【会议】大模型空间认知\Vernon - 1965 - Ability factors and environmental influences.pdf}
}

@article{vingerhoetsAnalysisMoneyRoadmap1996,
  title = {Analysis of the Money Road-Map Test Performance in Normal and Brain-Damaged Subjects},
  author = {Vingerhoets, Guy and Lannoo, Engelien and Bauwens, Sabien},
  year = {1996},
  month = jan,
  journal = {Archives of Clinical Neuropsychology},
  volume = {11},
  number = {1},
  pages = {1--9},
  issn = {0887-6177},
  doi = {10.1016/0887-6177(95)00055-0},
  urldate = {2024-12-13},
  abstract = {The Money Road-Map Test (MRMT) is a paper and pencil assessment of left-right discrimination. Some of the answers require an egocentric mental rotation in space. In a first experiment with 63 normal adults, we found that the accuracy and speed of the left-right decision process significantly decreased with a increasing degree of mental rotation required. A division of the MRMT turns in three categories with increasing mental rotation was proposed. In a second study (n = 50), patients with predominantly parietal brain lesions performed significantly worse than patients with predominantly frontal lesions. The significant group difference in total error score was especially due to the error scores of turns requiring mental rotation. The turn type analysis did not contribute to the lateralization of the lesions.},
  langid = {english},
  annotation = {TLDR: It was found that the accuracy and speed of the left-right decision process significantly decreased with a increasing degree of mental rotation required, and a division of the MRMT turns in three categories with increasing mental rotation was proposed.},
  file = {E\:\\OneDrive\\Zotero Literature\\论文项目参考文献\\2024【会议】大模型空间认知\\Vingerhoets 等 - 1996 - Analysis of the money road-map test performance in normal and brain-damaged subjects.pdf;C\:\\Users\\wenruixu\\Zotero\\storage\\K3Y4JEHM\\0887617795000550.html}
}

@article{voyerMagnitudeSexDifferences1995,
  title = {Magnitude of Sex Differences in Spatial Abilities: {{A}} Meta-Analysis and Consideration of Critical Variables.},
  shorttitle = {Magnitude of Sex Differences in Spatial Abilities},
  author = {Voyer, Daniel and Voyer, Susan and Bryden, M. Philip},
  year = {1995},
  journal = {Psychological Bulletin},
  volume = {117},
  number = {2},
  pages = {250--270},
  issn = {1939-1455, 0033-2909},
  doi = {10.1037/0033-2909.117.2.250},
  urldate = {2024-11-07},
  langid = {english},
  annotation = {TLDR: Results showed that sex differences are significant in several tests but that some intertest differences exist, and partial support was found for the notion that the magnitude of sex differences has decreased in recent years.},
  file = {E:\OneDrive\Zotero Literature\论文项目参考文献\2024【会议】大模型空间认知\Voyer 等 - 1995 - Magnitude of sex differences in spatial abilities a meta-analysis and consideration of critical var.pdf}
}

@misc{wuMindsEyeLLMs2024,
  title = {Mind's {{Eye}} of {{LLMs}}: {{Visualization-of-Thought Elicits Spatial Reasoning}} in {{Large Language Models}}},
  shorttitle = {Mind's {{Eye}} of {{LLMs}}},
  author = {Wu, Wenshan and Mao, Shaoguang and Zhang, Yadong and Xia, Yan and Dong, Li and Cui, Lei and Wei, Furu},
  year = {2024},
  month = oct,
  number = {arXiv:2404.03622},
  eprint = {2404.03622},
  publisher = {arXiv},
  doi = {10.48550/arXiv.2404.03622},
  urldate = {2024-11-07},
  abstract = {Large language models (LLMs) have exhibited impressive performance in language comprehension and various reasoning tasks. However, their abilities in spatial reasoning, a crucial aspect of human cognition, remain relatively unexplored. Human possess a remarkable ability to create mental images of unseen objects and actions through a process known as the Mind's Eye, enabling the imagination of the unseen world. Inspired by this cognitive capacity, we propose Visualization-of-Thought (VoT) prompting. VoT aims to elicit spatial reasoning of LLMs by visualizing their reasoning traces, thereby guiding subsequent reasoning steps. We employed VoT for multi-hop spatial reasoning tasks, including natural language navigation, visual navigation, and visual tiling in 2D grid worlds. Experimental results demonstrated that VoT significantly enhances the spatial reasoning abilities of LLMs. Notably, VoT outperformed existing multimodal large language models (MLLMs) in these tasks. While VoT works surprisingly well on LLMs, the ability to generate mental images to facilitate spatial reasoning resembles the mind's eye process, suggesting its potential viability in MLLMs. Please find the dataset and codes at https://microsoft.github.io/visualization-of-thought},
  archiveprefix = {arXiv},
  keywords = {Computer Science - Computation and Language},
  file = {E\:\\OneDrive\\Zotero Literature\\论文项目参考文献\\2024【会议】大模型空间认知\\Wu 等 - 2024 - Mind's Eye of LLMs Visualization-of-Thought Elicits Spatial Reasoning in Large Language Models.pdf;C\:\\Users\\wenruixu\\Zotero\\storage\\6KSRSYIP\\2404.html}
}

@article{XuXiaoXueShengKongJianNengLiJiQiFaZhanQingXiangDeXingBieChaiYiYanJiu2000,
  title = {{小学生空间能力及其发展倾向的性别差异研究}},
  author = {许, 燕 and 张, 厚粲},
  year = {2000},
  journal = {心理科学},
  number = {2},
  pages = {160--164, 253},
  issn = {31-1469/C},
  doi = {10.16719/j.cnki.1671-6981.2000.02.007},
  urldate = {2024-10-24},
  abstract = {本研究探讨了二、四、六年级小学生空间能力的性别差异表现特征。结果表明 ,在空间能力的加工方式、加工精确性及加工策略上均存在着性别差异 ,而在加工速度上表现为无差现象。在空间能力的发展趋势和空间组合能力方面 ,女生表现出稳定的优势 ;在空间旋转能力上 ,男生的优势随年龄增长表现为减弱并消失的特征},
  langid = {chinese},
  file = {E:\OneDrive\Zotero Literature\论文项目参考文献\2024【会议】大模型空间认知\许和张 - 2000 - 小学生空间能力及其发展倾向的性别差异研究.pdf}
}

@misc{yamadaEvaluatingSpatialUnderstanding2024,
  title = {Evaluating {{Spatial Understanding}} of {{Large Language Models}}},
  author = {Yamada, Yutaro and Bao, Yihan and Lampinen, Andrew K. and Kasai, Jungo and Yildirim, Ilker},
  year = {2024},
  month = apr,
  number = {arXiv:2310.14540},
  eprint = {2310.14540},
  publisher = {arXiv},
  doi = {10.48550/arXiv.2310.14540},
  urldate = {2024-11-07},
  abstract = {Large language models (LLMs) show remarkable capabilities across a variety of tasks. Despite the models only seeing text in training, several recent studies suggest that LLM representations implicitly capture aspects of the underlying grounded concepts. Here, we explore LLM representations of a particularly salient kind of grounded knowledge -- spatial relationships. We design natural-language navigation tasks and evaluate the ability of LLMs, in particular GPT-3.5-turbo, GPT-4, and Llama2 series models, to represent and reason about spatial structures. These tasks reveal substantial variability in LLM performance across different spatial structures, including square, hexagonal, and triangular grids, rings, and trees. In extensive error analysis, we find that LLMs' mistakes reflect both spatial and non-spatial factors. These findings suggest that LLMs appear to capture certain aspects of spatial structure implicitly, but room for improvement remains.},
  archiveprefix = {arXiv},
  langid = {american},
  keywords = {,Computer Science - Artificial Intelligence,Computer Science - Computation and Language},
  annotation = {TLDR: This work designs natural-language navigation tasks and evaluates the ability of LLMs, in particular GPT-3.5-turbo, GPT-4, and Llama2 series models, to represent and reason about spatial structures, finding that LLMs' mistakes reflect both spatial and non-spatial factors.},
  file = {E\:\\OneDrive\\Zotero Literature\\论文项目参考文献\\2024【会议】大模型空间认知\\Yamada 等 - 2024 - Evaluating Spatial Understanding of Large Language Models.pdf;C\:\\Users\\wenruixu\\Zotero\\storage\\CGBYZWG3\\2310.html}
}

@misc{yangDawnLMMsPreliminary2023,
  title = {The Dawn of {{LMMs}}: Preliminary Explorations with {{GPT-4V}}(Ision)},
  shorttitle = {The Dawn of {{LMMs}}},
  author = {Yang, Zhengyuan and Li, Linjie and Lin, Kevin and Wang, Jianfeng and Lin, Chung-Ching and Liu, Zicheng and Wang, Lijuan},
  year = {2023},
  month = oct,
  number = {arXiv:2309.17421},
  eprint = {2309.17421},
  primaryclass = {cs},
  publisher = {arXiv},
  doi = {10.48550/arXiv.2309.17421},
  urldate = {2024-12-13},
  abstract = {Large multimodal models (LMMs) extend large language models (LLMs) with multi-sensory skills, such as visual understanding, to achieve stronger generic intelligence. In this paper, we analyze the latest model, GPT-4V(ision), to deepen the understanding of LMMs. The analysis focuses on the intriguing tasks that GPT-4V can perform, containing test samples to probe the quality and genericity of GPT-4V's capabilities, its supported inputs and working modes, and the effective ways to prompt the model. In our approach to exploring GPT-4V, we curate and organize a collection of carefully designed qualitative samples spanning a variety of domains and tasks. Observations from these samples demonstrate that GPT-4V's unprecedented ability in processing arbitrarily interleaved multimodal inputs and the genericity of its capabilities together make GPT-4V a powerful multimodal generalist system. Furthermore, GPT-4V's unique capability of understanding visual markers drawn on input images can give rise to new human-computer interaction methods such as visual referring prompting. We conclude the report with in-depth discussions on the emerging application scenarios and the future research directions for GPT-4V-based systems. We hope that this preliminary exploration will inspire future research on the next-generation multimodal task formulation, new ways to exploit and enhance LMMs to solve real-world problems, and gaining better understanding of multimodal foundation models. Finally, we acknowledge that the model under our study is solely the product of OpenAI's innovative work, and they should be fully credited for its development. Please see the GPT-4V contributions paper for the authorship and credit attribution: https://cdn.openai.com/contributions/gpt-4v.pdf},
  archiveprefix = {arXiv},
  langid = {english},
  keywords = {Computer Science - Computation and Language,Computer Science - Computer Vision and Pattern Recognition},
  annotation = {TLDR: This paper analyzes the latest model, GPT-4V(ision), to deepen the understanding of large multimodal models, and curate and organize a collection of carefully designed qualitative samples spanning a variety of domains and tasks to inspire future research on the next-generation multi-sensory task formulation.},
  file = {E\:\\OneDrive\\Zotero Literature\\论文项目参考文献\\2024【会议】大模型空间认知\\Yang 等 - 2023 - The dawn of LMMs preliminary explorations with GPT-4V(ision).pdf;C\:\\Users\\wenruixu\\Zotero\\storage\\BSKYRJR5\\2309.html}
}

@article{YangKongJianRenZhiNengLiDeCeYanYanJiu1990,
  title = {{空间认知能力的测验研究}},
  author = {杨, 孟萍 and 石, 德澄},
  year = {1990},
  journal = {心理发展与教育},
  number = {4},
  pages = {213--217},
  issn = {1001-4918},
  urldate = {2024-10-24},
  abstract = {{$<$}正{$>$} 一、研究目的一般认为智力包括语言因素,数量因素和非语言性因素,其中非语言性因素就是指的空间能力因素。运用空间映象来解决各类课题(包括教学的、生产的、艺术的以及设计技术的等等)的技能是人的智力的重要特点。空间能力的研究在国外开始于本世纪初(1904年),从确定一个独立的空间因素的存在,到探索空间因素的亚类,空间能力的结构、特征、以及用信息加工模型来解决空间问题等,经历了八十多年的时间。其间Thurslore{$\cdot$}Koussf,French,Michace 等人进行了大量深入的研究,做出了突出的贡献。其中一些有关空间认知},
  langid = {chinese},
  file = {E:\OneDrive\Zotero Literature\论文项目参考文献\2024【会议】大模型空间认知\杨和石 - 1990 - 空间认知能力的测验研究.pdf}
}

@article{YouXiaoXueShengShuXueYingYongTiJieTiShuiPingYingXiangYinSuDeYanJiuShiKongJianNengLiRenZhiFangShiJiBiaoZhengFangShiDeYingXiang2006,
  title = {{小学生数学应用题解题水平影响因素的研究------视空间能力、认知方式及表征方式的影响}},
  author = {游, 旭 and 群, 张 and 媛, 刘 and 登, 攀 and 丽, 萍},
  year = {2006},
  journal = {心理科学},
  number = {4},
  pages = {868--873},
  issn = {1671-6981},
  doi = {10.16719/j.cnki.1671-6981.2006.04.024},
  urldate = {2024-10-24},
  abstract = {研究采用3(年级){\texttimes}2(场认知方式){\texttimes}2(视空间能力水平){\texttimes}3(问题表征方式)四因素混合实验设计,探讨了这四种因素对小学生数学应用题解题水平的影响。结果表明:年级、认知方式、空间能力以及问题表征方式均是影响小学生应用题解决水平的关键因素;问题表征方式、认知方式、空间能力以及年级四个因素对小学生解题水平存在交互作用,其中图形提示有利于场依存性学生解题水平的提高,低空间-场依存型的学生更适合图形提示;高空间-场依存型的学生随年级升高解题能力发展较快,而低空间-场依存型的学生解题水平提高较慢;随着年级的升高,图式表征对小学生问题解决的促进作用增强。},
  langid = {chinese},
  file = {E:\OneDrive\Zotero Literature\论文项目参考文献\2024【会议】大模型空间认知\游 等 - 2006 - 小学生数学应用题解题水平影响因素的研究——视空间能力、认知方式及表征方式的影响.pdf}
}

@article{ZhouXianDaiRenZhiXinLiXueGuanYuKongJianNengLiHeXinLiXuanZhuanDeYanJiu1995,
  title = {{现代认知心理学关于空间能力和心理旋转的研究}},
  author = {周, 详 and 曾, 晖},
  year = {1995},
  journal = {心理科学},
  number = {6},
  pages = {363--365},
  issn = {10006648},
  doi = {10.16719/j.cnki.1671-6981.1995.06.011},
  urldate = {2024-10-24},
  abstract = {现代认知心理学关于空间能力和心理旋转的研究周详，曾晖（海南师范大学教育管理系）１有关空间能力的研究空间能力和言语能力都是智能的基本成分。在人类早期智能研究中，人们已发现：言语能力并非唯一的与智力有关的能力，空间能力也是较为独立的智力结构，好的非言语测...},
  langid = {chinese},
  file = {E:\OneDrive\Zotero Literature\论文项目参考文献\2024【会议】大模型空间认知\周和曾 - 1995 - 现代认知心理学关于空间能力和心理旋转的研究.pdf}
}
