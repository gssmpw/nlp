

We use real-world data from scheduling jobs on parallel machines\footnote{https://www.cs.huji.ac.il/labs/parallel/workload/} to test our algorithms. More information on the handling of these datasets can be found in a study by Feitelson et al. \cite{feitelson2014experience}. We focus on two datasets, \texttt{NASA-iPSC} (18,239 jobs) and \texttt{CTC-SP2} (77,222 jobs). As is usually the case, the performance of algorithms is much better than their worst-case bounds. For every algorithm we average its performance over random permutations of the input instance, for multiple error values. The $y$ axis values for proportional weights are expressed in scientific notation. We note that algorithm \texttt{GrNR} refers to a greedy algorithm without revoking, a very natural algorithm to compare our \texttt{Naive} algorithm against. All other algorithms have been mentioned earlier in the paper. Our experimental results are in line with our intuition, with the predictions algorithms outperforming predictionless algorithms for some values of the error, even when they are not $1$-consistent. Especially in the setting of revocable acceptances, even with half of the max possible error, our predictions algorithms perform just as well as their purely online counterparts. In the CTC dataset (figure \ref{fig:ctc_exps}) this is always the case, with the \texttt{Naive} algorithm outperforming \texttt{GrNR} for nearly all values of error.
In the case of proportional weights with revoking in figure \ref{fig:nasa_exps}, it is noteworthy that the variant of \texttt{Revoke-Proportional} with $\lambda = 4$, outperforms the $\lambda = \phi$ variant for some small values of error, but its performance degrades faster. This further validates the notion that the bigger the $\lambda$, the more the algorithm follows the predictions.\\
We also have to address the seemingly abnormal behavior of algorithm \texttt{Revoke-Proportional} in figure \ref{fig:ctc_exps}(d). As the error increases, so does the performance of \texttt{Revoke-Proportional}, which is counterintuitive and dissimilar to the corresponding plot of figure \ref{fig:nasa_exps}. This is because of the underlying structure of the \texttt{CTC-SP2} dataset, on which \textit{greedy} algorithms perform exceptionally well. We showcase this by having included algorithm \texttt{LR$'$} with $\beta = 1$, the algorithm that accepts a new interval if it is at least as big as everything it conflicts with. As the error increases, a larger number of intervals can be accepted through this clearly beneficial, relaxed predictions rule, which helps explain the improved performance. We also contrast this with algorithm \texttt{Rev-Prop-Half}, which uses a modified predictions rule, that can accept supposedly optimal intervals that are half the weight of their conflicts. This makes the algorithm more sensitive to the predictions, and its performance falls in line with what we would expect.\\
In conclusion, algorithms for interval selection can greatly benefit from utilizing imperfect predictions, and remain robust even in the presence of high error.


%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%% NASA %%%%%%%%%%%%%%%%%%%%%%

