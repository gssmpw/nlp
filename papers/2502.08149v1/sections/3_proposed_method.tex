
% In this section, we present our framework comprising two main stages: generalized class discovery and dynamic learning. In the first stage, we propose a novel generalized class discovery model $f_d$ to cluster unlabeled objects in $\calD^u$ discovered by an open-world instance segmentation model $f_o$ pre-trained using $\calD^l$. In the second stage, we utilize both $\calD^l$ and $\calD^u$ with generated pseudo-labels to train a novel instance segmentation network $f_s$. The overall architecture of the proposed framework is shown in~\fref{fig:overview_training}. 


% We first define the GCD problem in instance segmentation, which aims to discover novel classes and learn to segment instances of both known and novel categories, given labeled and unlabeled data. Then, we present our GCD method including instance-wise temperature assignment (ITA) and soft attention modules (SAM). Lastly, we introduce the reliability-based dynamic learning (RDL) method for training an instance segmentation network using pseudo-labels from the GCD model. An overview of the proposed framework during training is illustrated in~\fref{fig:overview_training}.

\section{Proposed Method}
\label{sec:method}
We first define the GCD problem in instance segmentation, which aims to discover novel classes and learn to segment instances of both known and novel categories, given labeled and unlabeled data. We then present our GCD method in~\sref{sec:class_discovery} and the method for training an instance segmentation network in~\sref{sec:dynamic_learning}. An overview of the proposed framework during training is illustrated in~\fref{fig:overview_training}.



% We assume that a labeled dataset $\calD^l$ and one or more unlabeled datasets $\calD^u$ are given where $\calD^l$ contains images $\{\mI^l\}$, instance-wise class labels $\{\vy^l\}$, and instance-wise mask labels $\{\mM^l\}$ for known object classes $\calC^l$, whereas $\calD^u$ comprises only images $\{\mI^u\}$. The images $\{\mI^u\}$ in $\calD^u$ may contain instances of both the known classes $\calC^l$ and novel classes $\calC^u$. The novel classes are disjoint from the known classes (\ie $\calC^l \cap \calC^u=\emptyset$). Given $\calD^l$ and $\calD^u$, we aim to obtain an instance segmentation network capable of segmenting instances of both the known and novel classes $\calC = \calC^l \cup \calC^u$. For example, given an arbitrary image $\mI$, the network is expected to segment instances of known classes (\eg person and car) and novel classes (\eg $\text{unknown}_1$ and $\text{unknown}_2$).

% \subsection{Problem Formulation}
\subsection{Preliminaries}
\label{sec:prelim}
\noindent \textbf{Problem Formulation}.
We are given a labeled dataset $\calD^l$ and an unlabeled dataset $\calD^u$. $\calD^l$ contains images $\{\mI^l\}$ along with instance-wise class and mask labels ($\{\vy^l\}$, $\{\mM^l\}$) for known classes $\calC^k$, while $\calD^u$ comprises only images $\{\mI^u\}$. Given $\calD^l$ and $\calD^u$, GCD in instance segmentation aims to discover novel categories $\calC^n$ (\ie $\calC^k \cap \calC^n = \emptyset$) and to obtain a model capable of segmenting instances of both the known and novel classes $\calC = \calC^k \cup \calC^n$. Hence, during inference, the network is expected to segment instances of known classes (\eg person and car) as well as novel categories (\eg $\text{unknown}_1$ and $\text{unknown}_2$) given an image $\mI$. The images in $\calD^l$ and $\calD^u$ may contain instances of both the known and novel classes.


\vspace{1mm}
\noindent \textbf{Contrastive Learning for GCD}. 
\cite{vaze2022generalized} introduced a contrastive learning (CL) method for GCD in balanced image classification datasets. They first pre-trained a backbone with DINO~\cite{dino2021} on the ImageNet dataset~\cite{imagenet2015} without labels. Subsequently, they fine-tuned the backbone and a projection head using supervised CL on the labeled data and unsupervised CL on both the labeled and unlabeled data. 

% While \cite{vaze2022generalized} explored contrastive learning on a curated and balanced dataset, we focus on GCD in instance segmentation, which is naturally imbalanced (\ie certain objects appear more frequently than others).


Following~\cite{wen2023parametric, vaze2022generalized}, our GCD model $f_d(\cdot)$ consists of a backbone $b(\cdot)$ and a projection head $g(\cdot)$. We utilize an MLP for $g(\cdot)$ and a ResNet-50 backbone~\cite{resnet} for $b(\cdot)$, which is pre-trained on the unlabeled ImageNet dataset~\cite{imagenet2015} using DINO~\cite{dino2021}. Additionally, we employ a momentum encoder $f'_d(\cdot)$ whose parameters are momentum-based moving averages of the parameters of $f_d(\cdot)$ during training, following MoCo~\cite{he2020momentum}. We also use a queue to store the embeddings from $f'_d(\cdot)$ for the samples of both the previous and current mini-batches.


% (\ie $\mI_i \in \calI^u_o \cup \calI^l_o$)

% $f'_d(\cdot)$ is utilized to extract consistent representations between mini-batches while training $f_d(\cdot)$. 
% Additionally, we use a queue $\bar{\calZ}$ to store the representations $\vz'_j = f'_d(\mI_j)$ of the samples from both the previous and current mini-batches, generated by the momentum encoder $\bar{f}_d(\cdot)$.

% where $\calZ'$ denotes the queue containing the representations from the momentum encoder; 


Formally, given an image, we generate two views (random augmentations) $\mI_i$ and $\mI'_i$. We then encode them using $f_d(\cdot)$ and $f'_d(\cdot)$ to obtain $\vz_i = f_d(\mI_i) = g(b(\mI_i))$ and $\vz'_i = f'_d(\mI'_i)$, respectively. We store $\vz'_i$ from the samples in the previous and current mini-batches in the queue $\calZ'$. In~\cite{vaze2022generalized}, the unsupervised contrastive loss $\calL^u_{rep}$ and supervised contrastive loss $\calL^s_{rep}$ are computed as follows:
\begin{equation}
\begin{split}
& \calL^u_{rep}:= -\log \frac{\exp(\vz_i^\mathsf{T} \vz'_i/\tau)}{\sum_{\vz'_j \in \hat{\calZ}_i } \exp(\vz_i^\mathsf{T} \vz'_j/\tau)}, \\
& \calL^s_{rep} := - \frac{1}{|\calZ^p_i|}\sum_{\vz'_k \in \calZ^p_i} \log \frac{\exp(\vz_i^\mathsf{T} \vz'_k/\tau)}{\sum_{\vz'_j \in \hat{\calZ}_i } \exp(\vz_i^\mathsf{T} \vz'_j/\tau)}
\label{eqn:cont_loss_prelim}
\end{split}
\end{equation}
where $\hat{\calZ}_i$ represents the set $\calZ'$ excluding $\vz'_i$ (\ie $\hat{\calZ}_i = \calZ' \setminus \vz'_i$); $\calZ^p_i$ denotes the subset of $\calZ'$ containing the representations that belong to the same class as $\mI_i$; $\tau$ is a temperature hyperparameter; and $|\cdot|$ denotes the number of samples in the set.


% $\calL^s_{rep}$ and $\calL^u_{rep}$ are computed on the labeled data and both the labeled and unlabeled data, respectively. 


% Firstly, a source (labeled) dataset $\calD^l$ is given where $\calD^l$ contains the images $\{\mI^l\}$, instance-wise class labels $\{\vy^l\}$, and instance-wise mask labels $\{\mM^l\}$ for known object classes $\calC^l$. Additionally, one or more target (unlabeled) datasets $\calD^u$ are provided where $\calD^u$ comprises images $\{\mI^u\}$ that may contain instances of both the known classes $\calC^l$ and novel classes $\calC^u$. The two sets of classes are disjoint (\ie, $\calC^l \cap \calC^u=\emptyset$). Given both the labeled $\calD^l$ and unlabeled $\calD^u$ datasets, our aim is to train an instance segmentation network that is capable of segmenting instances of both the known and novel classes $\calC = \calC^l \cup \calC^u$. For example, given an arbitrary image $\mI$, the network is expected to segment instances of known classes (\eg person and car) as well as instances of novel classes (\eg $\text{unknown}_1$ and $\text{unknown}_2$). 

% We assume that the number $|\calC^u|$ of novel classes is larger than the number $|\calC^l|$ of known classes. 

% We further assume that the quantity of novel classes $\calC^u$ is an established prior following~\cite{fomenko2022learning}. 

%==============================================================

% check later 0815
% To predict instance masks and classes for both known and novel categories given labeled and unlabeled datasets, we first employ GGNs~\cite{wang2022open} to obtain class-agnostic instance masks for all instances in the unlabeled dataset. We then apply the proposed class discovery method to generate pseudo-class labels for these instances. Subsequently, we train SOLOv2~\cite{wang2020solov2} using the proposed reliability-based dynamic learning approach on the labeled dataset and the unlabeled images with pseudo-labels.


% check later 0815
% While we also generate pseudo-labels for unlabeled images and train an instance segmentation network using them, similar to~\cite{zhao2022novel, riz2023novel} in semantic segmentation, we take into account the long-tail distribution of classes by proposing instance-wise temperature assignment and class-wise reliability-based dynamic learning. In instance segmentation, similar to~\cite{fomenko2022learning}, our method does not require clustering during inference~\cite{weng2021unsupervised}. Different from~\cite{fomenko2022learning}, we do not depend on the pre-selected prior distribution and use self-computed target distribution for optimization. 


% check later 0815
% While \cite{vaze2022generalized, wen2023parametric} used the same constant values for $\tau_u$ and $\tau_s$ across all the data, we propose to assign varying values to each sample based on its headness or tailness.


% check later 0815
% Following~\cite{fomenko2022learning}, we also utilize an online clustering method to avoid the separate semi-supervised clustering step used in~\cite{vaze2022generalized}. However, while \cite{fomenko2022learning} employed online constrained clustering with an experimentally selected target prior distribution, we investigate contrastive learning for clustering.

\subsection{Generalized Class Discovery}
\label{sec:class_discovery}
Given $\calD^l$ and $\calD^u$, we aim to discover novel categories in $\calD^u$ using the knowledge from $\calD^l$. To achieve this, we first train an instance segmentation network using $\calD^l$ and $\calD^u$ to generate class-agnostic instance masks $\mM^u$ for all objects in $\calD^u$. Subsequently, we crop the unlabeled images using $\mM^u$ and the labeled images using the ground-truth masks $\mM^l$. Then, we train a GCD model using the cropped unlabeled images $\calI^u_o$ and the cropped labeled images $\calI^l_o$ with class labels $\vy^l$ to generate pseudo-class labels $\vy^u$ for $\calI^u_o$.

% In this work , 

% Hence, the class discovery model needs to discover novel classes that are distinct from the known classes given instance images of both known and unseen classes. In this work, we investigate a novel generalized class discovery model for a long-tailed and large-scale dataset considering numerous objects in the real world and their long-tail distribution, .

% We train an open-world instance segmentation network $f_o(\cdot)$ using $\calD^l$ and $\calD^u$. We then apply the trained network $f_o$ to the unlabeled images $\mI^u \in \calD^u$ to generate class-agnostic instance masks for the instances of both known and unseen classes $\calC = \calC^l \cup \calC^u$. Specifically, we employ the Generic Grouping Network (GGN)~\cite{wang2022open} for $f_o(\cdot)$. 
\vspace{1mm}
\noindent \textbf{Class-Agnostic Instance Mask Generation}.
Similar to~\cite{fomenko2022learning}, we first train an instance segmentation network $f_o(\cdot)$ to obtain class-agnostic instance masks for both known and unseen classes $\calC = \calC^k \cup \calC^n$. We train a class-agnostic instance segmentation network, the Generic Grouping Network (GGN) from~\cite{wang2022open}, using both $\calD^l$ and $\calD^u$. We experimentally demonstrate that our GCD method is robust when applied to other class-agnostic instance segmentation methods.

% While \cite{fomenko2022learning} trained Mask R-CNN~\cite{he2017mask} using $\calD^l$, w


% , including Mask R-CNN~\cite{he2017mask}, OLN~\cite{Kim2022Learning}, LDET~\cite{Saito2022Learning}, and UDOS~\cite{kalluri2023open}

Once the training terminates, we apply $f_o(\cdot)$ to the images $\mI^u \in \calD^u$ to obtain instance masks $\mM^u$. We then construct an unlabeled object image set $\calI^u_o$ by cropping the rectangular regions of $\mI^u$ based on $\mM^u$. Similarly, a labeled object image set $\calI^l_o$ is prepared by cropping $\mI^l$ in $\calD^l$ based on the mask labels $\mM^l$.

% Additionally, $\mM^u$ is retained to compute a loss during the training of a discovery model.

% We train an open-world instance segmentation network $f_o(\cdot)$ using the labeled dataset $\calD^l$, which contains images and mask/class labels. 

% The images and masks are padded to square shapes and resized to $224 \times 224$ for further processes.








% Then, we train $f_d(\cdot)$ using images $\mI_i$ in $\calI^u_o$ and $\calI^l_o$ (\ie $\mI_i \in \calI^u_o \cup \calI^l_o$), a momentum encoder, and a novel loss function. The loss function is designed to cluster the unlabeled object images $\calI^u_o$ into classes $\calC = \calC^k \cup \calC^n$.

% , by leveraging the semi-supervised $k$-means clustering method in~\cite{vaze2022generalized}.


% Hence, we propose a novel adaptive temperature assignment method that estimates a temperature value for each sample based on its likelihood of belonging to head or tail classes. 

\vspace{1mm}
\noindent \textbf{Contrastive Learning for GCD in Instance Segmentation}. 
We propose a contrastive learning method for GCD in instance segmentation by modifying the losses in~\eref{eqn:cont_loss_prelim}. While these losses are designed for curated and balanced data, instances in typical instance segmentation datasets are naturally imbalanced (\ie certain objects appear more frequently than others). To address the long-tail distribution of instances for each class, we propose to adjust the temperature parameters in $\calL^u_{rep}$ and $\calL^s_{rep}$ for each instance based on its likelihood of belonging to head classes. 


% check later 0815
% \textcolor{red}{more details}. 

\fref{fig:ITA} visualizes $t$-SNE projections of two semantically similar classes: `book' and `booklet'. Previously, \cite{kukleva2023temperature} showed that a low temperature value tends to uniformly discriminate all instances while a high temperature value leads to group-wise discrimination, as shown in~\fref{fig:ITA} (a) and (b). Based on this, \cite{kukleva2023temperature} introduced a cosine temperature scheduling (TS) method to alternate between instance-wise and group-wise discrimination. In contrast, we propose to estimate the headness of each instance and assign high/low temperature values to instances belonging to head/tail class samples. \fref{fig:ITA} demonstrates the superiority of our instance-wise temperature assignment (ITA) method compared to static assignments and TS~\cite{kukleva2023temperature}.

% Specifically, we assign high-temperature values to instances belonging to head classes to relax instance discrimination and emphasize group-wise discrimination, and vice versa.

% In related work, \cite{kukleva2023temperature} introduced a cosine temperature scheduling method to alternate between instance and group-wise discrimination. However, they assigned the same temperature parameter to all samples in each iteration. We experimentally demonstrate the superiority of our temperature assignment method compared to~\cite{kukleva2023temperature} in~\tref{tab:analysis_temperature}.


% The training of the proposed generalized discovery model is illustrated in~\fref{fig:overgcd}. 

% \input{sections/over_gcd}

\input{sections/fig_ITA}

In detail, we first compute a headness score $\hat{h}_i$ for each instance $\mI_i$ by estimating the density of the neighborhood of $\vz_i$ in the embedding space. A higher score $\hat{h}_i$ indicates a higher probability of $\mI_i$ belonging to a head class. We then apply a momentum update to the headness scores to enhance the robustness of the estimation. Specifically, $\hat{h}_i$ and the momentum-updated headness score $h_i$ at the $t$-th epoch are computed as follows:
\begin{equation}
\begin{split}
& \hat{h}_i^t := \frac{\sum_{\vz'_j \in \hat{\calZ}^{top_K}_i }\exp(\vz_i^\mathsf{T} \vz'_j)}{\sum_{\vz'_j \in \hat{\calZ}_i} \exp(\vz_i^\mathsf{T} \vz'_j)}, \\
& h_i^t := \rho h_i^{t-1}+(1-\rho) \hat{h}_i^t 
\label{eqn:headness}
\end{split}
\end{equation}
where $\hat{\calZ}_i = \calZ' \setminus \vz'_i$; $\hat{\calZ}^{top_K}_i$ denotes the set containing the $K\%$ most similar representations to $\vz_i$ in $\hat{\calZ}$; $\rho$ denotes a momentum hyperparameter with a value between 0 and 1.


Subsequently, we determine a temperature value $\tau_i$ for each instance $\mI_i$ using $h_i^t$. To avoid extreme values, we constrain $h_i^t$ to fall within the lowest 10\% ($h^{low}$) and highest 10\% ($h^{high}$) of the scores. We then apply min-max normalization to adjust the score to fall within the range between $\tau^{min}$ and $\tau^{max}$. Specifically, the temperature value $\tau_i$ for $\mI_i$ is calculated as follows:
\begin{equation}
\begin{split}
\tau_i := \frac{\bar{h}_i^t - \min(\calH^t)}{\max(\calH^t)-\min(\calH^t)}(\tau^{max} - \tau^{min})+\tau^{min} 
\label{eqn:temperature}
\end{split}
\end{equation}
where $\bar{h}_i^t := \min ( \max (h_i^t, h^{low}), h^{high} )$; $\calH^t$ represents the set containing the headness scores for all samples. For efficiency, $\tau_i$ and $h_i^t$ are updated at every epoch.


The two contrastive losses $\calL^u_{rep}$ and $\calL^s_{rep}$ in~\eref{eqn:cont_loss_prelim} are modified using the estimated instance-wise temperature value $\tau_i$ as follows:
\begin{equation}
\begin{split}
& \calL^u_{rep}:= -\log \frac{\exp(\vz_i^\mathsf{T} \vz'_i/\tau_i)}{\sum_{\vz'_j \in \hat{\calZ}_i } \exp(\vz_i^\mathsf{T} \vz'_j/\tau_i)}, \\
& \calL^s_{rep} := - \frac{1}{|\calZ^p_i|}\sum_{\vz'_k \in \calZ^p_i} \log \frac{\exp(\vz_i^\mathsf{T} \vz'_k/\tau_i)}{\sum_{\vz'_j \in \hat{\calZ}_i } \exp(\vz_i^\mathsf{T} \vz'_j/\tau_i)}_.
\label{eqn:loss_unsupervised}
\end{split}
\end{equation}
% where $\calL^u_{rep}$ is computed using both $\calI^u_o$ and $\calI^l_o$, while $\calL^s_{rep}$ is calculated using $\calI^l_o$ and their class labels $\{\vy^l\}$.

% When the anchor $\mI_i$ has a high probability of belonging to head classes, a high temperature parameter $\tau_i$ is assigned to relax instance discrimination and emphasize group-wise discrimination, and vice versa. 





%\textcolor{blue}{
%In addition to $\calL^u_{cls}$, we compute the typical cross-entropy loss $\calL^s_{cls}$ for supervised learning on $\calD^l$, as follows:
%}
%\begin{equation}
%\begin{split}
%\calL^s_{cls} := \sum_{c=1}^C - y_{ic} \log q_{ic}
%\label{eqn:loss_cross_entropy}
%\end{split}
%\end{equation}
%where $\vy_i$ denotes the one-hot encoded label for $\mI_i$.




%\textcolor{blue}{
%In detail, we first compute class scores by measuring the cosine similarities between the embeddings $\vv_i=b(\mI_i)$ from the backbone of $f_d(\cdot)$ and the class-wise prototypes $\hat{\vv}_c$ and by applying a softmax function. Specifically, the probability $q_{ic}$ of $\mI_i$ belonging to class $c$ is computed as follows:
%}
%\begin{equation}
%q_{ic} := \frac{\exp(\vv_i \cdot \hat{\vv}_c/\tau)}{\sum_{c=1}^C \exp(\vv_i \cdot \hat{\vv}_c / \tau)}
%\label{eqn:class_score}
%\end{equation}
%where $C$ is the total number of prototypes, and $\tau$ is a temperature hyperparameter. Similarly, we compute $\bar{q}_{ic}$ using $\bar{\vv}_i$ from the backbone of the momentum encoder $f'_d(\cdot)$ and $\hat{\vv}_c$.
%
%
%\textcolor{blue}{
%Subsequently, we estimate the auxiliary target class probability $\bar{p}_{ic}$, inspired by~\cite{xie2016unsupervised}, as follows:
%}
%\begin{equation}
%\bar{p}_{ic} := \frac{\bar{q}_{ic}^2 / n_c}{\sum_{c=1}^C \bar{q}_{ic}^2 / n_c}
%\label{eqn:target_class_prob}
%\end{equation}
%where $n_c = \sum_{i} \bar{q}_{ic}^2$. Squaring $\bar{q}_{ic}$ increases reliance on highly confident samples while reducing the impact of low-confidence samples. $n_c$ balances classes with varying sample counts using the samples in the queue.




\vspace{1mm}
\noindent \textbf{Soft Attention Module}. 
Since $\calI^u_o$ and $\calI^l_o$ contain target objects along with background or adjacent objects, we investigate a soft attention module (SAM) to encode object-specific features. Although we generate pseudo-masks $\mM^u$ for $\calD^u$ using $f_o(\cdot)$, directly using these pseudo-masks to encode object-specific features is risky due to noisy boundaries. To address this, we train an efficient attention module using the pseudo-masks $\mM^u$ for $\calD^u$ and ground-truth masks $\mM^l$ for $\calD^l$. We integrate this attention module into every stage of the CNN backbone. Additionally, we utilize pooled feature maps and embedding functions with depth reduction to reduce computational complexity.

% (\ie $\mP_i := \eta_i(p^s_i(\mF))$)

Given a feature map $\mF \in \mathbb{R}^{D \times \bar{H} \times \bar{W}}$ at the end of each stage in the backbone, we first reduce its dimensions to decrease subsequent computations. Specifically, we apply spatial average pooling to $\mF$ with varying receptive fields. Then, we use $M$ embedding functions $\eta_i(\cdot)$ to generate $M$ outputs $\mP_i \in \mathbb{R}^{d \times s_i \times s_i}$. Here, $i$ indexes the $M$ outputs, $d$ represents the reduced depth produced by the embedding functions, and $s_i \times s_i$ denotes the resulting spatial dimension after pooling. Subsequently, we reshape $\mP_i$ into $\hat{\mP}_i \in \mathbb{R}^{d \times s_i^2}$ and concatenate them to obtain $\bar{\mP} \in \mathbb{R}^{d \times (s_1^2 + s_2^2 + \cdots + s_M^2)}$.

Then, we compute a pairwise affinity matrix $\mA$ by projecting $\mF$ using an embedding function $\phi(\cdot)$ and multiplying the result by $\bar{\mP}$ (\ie $\mA := \bar{\mP}^T \phi(\mF)$). The matrix $\mA \in \mathbb{R}^{(s_1^2 + s_2^2 + \cdots + s_M^2) \times \bar{H} \times \bar{W}}$ represents the spatial relations between the pooled feature map $\mP$ and $\mF$. Additionally, we project $\mF$ using a function $\psi(\cdot)$ and apply global average pooling along the channel dimension, generating a map $\mG$.


Finally, we concatenate $\mA$ with $\mG$ and apply an embedding function $\nu(\cdot)$ followed by a sigmoid function to obtain an attention map $\mS \in \mathbb{R}^{1 \times \bar{H} \times \bar{W}}$. This map $\mS$ is then element-wise multiplied with each channel of $\mF$ to produce the output $\mO \in \mathbb{R}^{D \times \bar{H} \times \bar{W}}$ of the attention module.
\begin{equation}
\begin{split}
\mO := \mS \odot \mF := \sigma( \nu ( [\mA, \mG] ) ) \odot \mF
\label{eqn:soft_attention}
\end{split}
\end{equation}
where $\odot$ and $\sigma(\cdot)$ denote element-wise multiplication and the sigmoid function, respectively; $[\cdot, \cdot]$ represents concatenation. Each of the embedding functions ($\eta(\cdot)$, $\psi(\cdot)$, $\phi(\cdot)$) consists of a $1 \times 1$ convolution layer, batch normalization, and ReLU activation. In comparison, $\nu(\cdot)$ contains only a $1 \times 1$ convolution layer and batch normalization.


% On the other hand, when $\mI_i$ has a high probability of belonging to tail classes, a low value is assigned to $\tau_i$ to focus on instance discrimination. We experimentally demonstrate the effectiveness of the proposed adaptive temperature assignment method in separating classes with a long-tail distribution. 

To train the soft attention modules, we use object masks $\mM^u$ from $f_o(\cdot)$ for $\calD^u$ and ground-truth masks $\mM^l$ for $\calD^l$. Because the pseudo-masks for $\calD^u$ are noisy, especially near object boundaries~\cite{wang2022noisy}, we utilize a weight map $\mW$ to reduce reliance on these regions. Specifically, the attention loss $\calL_{att}$ is computed as follows:
\begin{equation}
\begin{split}
& \calL_{att} := \frac{1}{HW} \sum_{i=1}^H \sum_{j=1}^W \mW_{ij} \norm{\mS_{ij}-\mM_{ij}}^2_2, \\
\end{split}
\end{equation}
where $\mW_{ij}$ is set to $w$ if $d_{ij} \leq \bar{d}$ and $\mM \in \{\mM^u\}$, and to 1 otherwise. Here, $d_{ij}$ denotes the Euclidean distance from ($i, j$) to the nearest object boundary; $\bar{d}$ is a hyperparameter that defines the boundary regions; and $w$ is a weighting coefficient ($\leq 1$). Since SAM is applied after each stage of the backbone, $\calL_{att}$ is obtained by averaging all the corresponding losses.

%  that varies depending on the stage in the backbone

\input{sections/fig_SAM}


\fref{fig:SAM} visualizes the pairwise affinity between a marked position and other pixels. The results show that our method, which uses pooled feature maps, is more robust than the previous approach~\cite{zhang2020relation}.











\vspace{1mm}
\noindent \textbf{Deep Clustering for GCD}. 
To avoid the separate semi-supervised clustering step in~\cite{vaze2022generalized}, we employ a deep clustering method similar to those in~\cite{fomenko2022learning, wen2023parametric}. However, unlike~\cite{fomenko2022learning}, our method does not rely on an experimentally selected target prior distribution. Additionally, it is designed to handle imbalanced data, in contrast to~\cite{wen2023parametric}. Specifically, we use the method from~\cite{Zhang2021Supporting} for clustering $\calI^u_o$, with a minor modification: replacing L2 distance with cosine similarity.

We compute the KL-divergence-based loss $\calL^u_{cls}$ on $\calI^u_o$ for unsupervised clustering in~\cite{Zhang2021Supporting}, as follows:
\begin{equation}
\begin{split}
\calL^u_{cls} := \sum_{c=1}^C \bar{p}_{ic} \log \frac{\bar{p}_{ic}}{q_{ic}}
\label{eqn:loss_KL_divergence}
\end{split}
\end{equation}
where $q_{ic}$ is the probability of $\mI_i$ belonging to class $c$; $\bar{p}_{ic}$ is the auxiliary target class probability; and $C$ is the total number of clusters/classes. % Additional details are provided in the supplementary material.

Independent from deep clustering, we additionally compute the typical cross-entropy loss $\calL^s_{cls}$ on $\calD^l$ for supervised classification, as follows:
\begin{equation}
\begin{split}
\calL^s_{cls} := \sum_{c=1}^C - y_{ic} \log q_{ic}
\label{eqn:loss_cross_entropy}
\end{split}
\end{equation}
where $\vy_i$ denotes the one-hot encoded label for $\mI_i$. 



\vspace{1mm}
\noindent \textbf{Total Loss for GCD}. 
The total loss $\calL_{gcd}$ for $f_d(\cdot)$ is computed as the weighted sum of the two contrastive losses, the two classification losses, and the attention loss, as follows:
\begin{equation}
\calL_{gcd} := \calL_{att} + (1-\lambda) \calL^u_{rep} + \lambda \calL^s_{rep} + (1-\lambda) \calL^u_{cls} + \lambda \calL^s_{cls}
\label{eqn:gcd_loss}
\end{equation}
where $\lambda$ is a hyperparameter used to balance the losses, following~\cite{wen2023parametric}. 



% \input{sections/qualitative3}
% \input{sections/soft_att}

% During novel class discovery, we generate pseudo-masks $\mM^u$ and pseudo-class labels $\vy^u$ for the target (unlabeled) dataset $\calD^u$. Given the source (labeled) dataset $\calD^l$ containing images $\{\mI^l\}$, ground-truth masks $\{\mM^l\}$, and ground-truth class labels $\{\vy^l\}$ and the target (unlabeled) dataset $\calD^u$ containing images $\{\mI^u\}$, pseudo-masks $\{\mM^u\}$, and pseudo-class labels $\{\vy^u\}$, we train an instance segmentation network that can segment instances of both known and novel classes $\calC = \calC^l \cup \calC^u$. Because the pseudo-labels for the unlabeled dataset may contain inaccurate information, we propose a novel dynamic learning method to rely on accurate pseudo-labels while reducing the dependency on inaccurate pseudo-labels. 


\subsection{Reliability-Based Dynamic Learning}
\label{sec:dynamic_learning}
We generate pseudo-masks $\mM^u$ and pseudo-class labels $\vy^u$ for $\calD^u$ using the method described in~\sref{sec:class_discovery}. Subsequently, we train an instance segmentation network $f_s(\cdot)$ that can segment instances of both known and novel classes using $\calD^l$ and $\calD^u$ with pseudo-labels. To address the issues of inaccurate pseudo-labels and imbalanced instance distributions across classes, we propose a reliability-based dynamic learning (RDL) method. It applies different reliability criteria to each class to avoid excluding all samples from tail classes. Additionally, it adjusts these criteria during training to use diverse data in the early stages while relying only on reliable pseudo-labels in the later stages.


Inspired by~\cite{yang2022st++}, we use holistic stability to measure the reliability of the pseudo-labels. At every fixed number of epochs during training $f_d(\cdot)$, we save the model at that point in time. We then apply these saved models to object images $\mI_i \in \calI^u_o$ to compute the probability $q^{\bar{t}}_{ic}$ of $\mI_i$ belonging to class $c$, where $\bar{t}$ denotes the index of the stored models, ranging from 1 to $\bar{T}$. Subsequently, we compute the stability $s_{i}$ of the probabilities by comparing $q^{\bar{T}}_{ic}$ from the final model with $q^{\bar{t}}_{ic}$ from the intermediate models, as follows:
\begin{equation}
s_{i} = \sum_{\bar{t}=1}^{\bar{T} - 1} \frac{1}{KL(\vq^{\bar{T}}_{i} || \vq^{\bar{t}}_{i})}
\label{eqn:stability}
\end{equation}
where $KL(\cdot||\cdot)$ represents the Kullback-Leibler divergence, and $\vq^{\bar{t}}_{i} \in \mathbb{R}^{|\calC|}$. Since a higher $s_{i}$ indicates greater stability, \cite{yang2022st++} considered pseudo-labels with the lowest $r\%$ scores unreliable.


% $s_{i} = \sum_{\bar{t}=1}^{\bar{T} - 1} \frac{1}{KL(\vq^{\bar{T}}_{i} || \vq^{\bar{t}}_{i})}$


However, applying the same criteria to all data may result in categorizing most samples of a certain class as unreliable. Specifically, for imbalanced data, instances of tail classes tend to have lower $s_{i}$ than those of head classes due to the smaller number of training samples. Additionally, because neural networks tend to first memorize easy samples and then gradually learn harder instances during training~\cite{arpit2017closer}, difficult samples/classes often have lower $s_{i}$ than easier ones. To address these issues, we propose to use class-wise reliability criteria, which consider pseudo-labels with the lowest $r\%$ scores per class as unreliable. 


% and use the rest with the reliability-based adjusting weight $\kappa^t_i$ during training.

% We then assign a discrete value $t_i$ between 0 and $T_d-1$ to each instance $i$ based on 

Additionally, we gradually increase the portion $r\%$ of unreliable samples to initially learn from all data and later optimize using only reliable samples. The idea is that, in the early stages, having a larger number of diverse samples is more important than the accuracy of pseudo-labels, while pseudo-label quality becomes more crucial in later stages. Specifically, we first compute $\bar{t}_i$ for each instance $i$ by finding the rank of $s_i$ among the lowest values within its class. We assign $\gamma$ to $\bar{t}_i$ if its proportional rank falls between $\frac{\gamma}{T_{is}}$ and $\frac{\gamma+1}{T_{is}}$. Then, the reliability-based adjustment weight $\kappa^t_i$ is computed as follows:
\begin{equation}
\kappa^t_i = \sqrt{1-\Big( \max \Big(\frac{ t - \bar{t}_i}{T_{is}}, 0 \Big) \Big)^2} \\
% \kappa^t_i = \sqrt{1-\Big( \max \Big(\frac{\bar{s}^{t}_i - s_i }{T_{is}}, 0 \Big) \Big)^2} \\
\label{eqn:adjusting_weight}
\end{equation}
where $t$ and $T_{is}$ denote the current epoch and the total number of epochs for training $f_s(\cdot)$, respectively.


% When $s_i$ is lower than $\bar{s}^{t}_i$, $\kappa^t_i$ is smaller than 1, reducing reliance on the corresponding instance $i$. 

% $\bar{s}^{t}_i$ denotes the stability threshold for the instance $i$ at the $t$-th epoch;
% 

Finally, we employ SOLOv2~\cite{wang2020solov2} for $f_s(\cdot)$ and use its loss function with modifications for training. First, we replace the focal loss~\cite{lin2017focal} with the equalized focal loss~\cite{li2022equalized}, which performs better on imbalanced data. We use this modified loss $\calL_{s}$ for $\calD^l$ and this loss multiplied by $\kappa^t_i$ for $\calD^u$. Therefore, the total instance segmentation loss $\calL_{is}$ is computed as follows:
\begin{equation}
\begin{split}
% \calL_{is} = & \frac{1}{|\calB^l|} \sum_{i \in \calB^l} \calL_{s}(\mI^l_i,\mM^l_i,\vy^l_i) \\ 
%  & + \frac{1}{|\calB^u|} \sum_{i \in \calB^u} \kappa^t_i \calL_{s}(\mI^u_i,\mM^u_i,\vy^u_i) \\
\calL_{is} = \sum_{i \in \calB^l} \calL_{s}(\mI^l_i,\mM^l_i,\vy^l_i) + \sum_{i \in \calB^u} \kappa^t_i \calL_{s}(\mI^u_i,\mM^u_i,\vy^u_i)
\label{eqn:loss_instance_segmentation}
\end{split}
\end{equation}
where $\calB^l$ and $\calB^u$ denote the sets containing the indices of the data from $\calD^l$ and $\calD^u$, respectively.



% The overall process is described in Algorithm 1. 

% \input{sections/algorithm}



