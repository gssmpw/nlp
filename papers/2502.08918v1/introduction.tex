\section{Introduction}

Graphs are a core data structure in many applications, such as social networks \cite{GraphSAGE,GraphRec,sigir24sun}, citation networks \cite{Planetoid,GCN}, knowledge graphs \cite{TransE,RotatE,www22KGwang}, and bio-chemical graphs \cite{Protein,GTPN}. Graph neural networks (GNNs) have been applied to various graph learning problems, showing powerful results. In the real world, graphs are often formed by different types of nodes and edges, making ordinary GNNs inadequate for modeling such heterogeneous graphs. This leads to a series of studies on heterogeneous graph learning \cite{HetGNN,HAN}.

The ``pre-train, fine-tune'' paradigm is widely adopted to solve the problems of label scarcity and task dependence. Specifically, a graph model is pre-trained using self-supervised pretext tasks \cite{GPTGNN,GraphCL} and then fine-tuned with partial labels from downstream tasks. However, there is a gap between pretext and downstream tasks due to their different training objectives. Inspired by prompt learning in language models, researchers attempt to bridge the gap by employing the ``pre-train, prompt'' paradigm in the graph domain \cite{GPPT,All,www25sun}. These methods aim to use prompts to reformulate downstream tasks in line with the pretext task.

Although graph prompt learning has shown promising results, challenges remain when the technique is applied to heterogeneous graphs: 1) \textit{How to align the pretext task and downstream task through graph modification?} Existing heterogeneous graph prompting methods primarily design feature prompts to modify node features, allowing downstream tasks to focus on task-specific features. However, such prompts struggle to learn the structure information of heterogeneous graphs. 2) \textit{How to capture semantic information with prompts?} Meta-paths, as multi-hop connection patterns, reflect high-order semantics in heterogeneous graphs. Existing graph prompting methods typically leverage the direct neighbor connection to learn prompts, which overlooks the rich semantic information conveyed by meta-paths.

To address these limitations, we propose \ourmethod, a novel heterogeneous graph prompt learning model. Our intuition is that during graph training, nodes of the same label tend to learn embeddings that cluster together. We abstract each cluster as a virtual node that becomes our prompt. We insert the prompts into the original heterogeneous graph by connecting them to the target nodes. As heterogeneous graphs comprise multiple types of nodes and edges, we assign a new node type to the clusters and a new edge type to the connections. As shown in Figure \ref{figure::prompt}, ``Paper'' is the target node to be labeled. We regard each cluster as a prompt token and learn the adjacency matrix between ``Paper'' and ``Prompt''. Following the graph reconstruction above, downstream tasks such as node clustering and node classification can be reformulated as link prediction on the prompt-augmented heterogeneous graphs.

\begin{figure}[t]
    \centering
    \includegraphics[width=0.5\textwidth]{figure/1.pdf}
    \caption{Cluster prompts in heterogeneous graphs. ``Paper'' is the target node and ``Prompt'' represents the cluster.}
    \label{figure::prompt}
    \vspace{-5mm}
\end{figure}

To capture both structural and semantic information, we design novel algorithms for both pre-training and prompt learning. During pre-training, we employ GNNs to learn structural and semantic features separately, and then use a contrastive framework to enhance the learning of both features. During prompt learning, we train prompts based on graph reconstruction and design a meta-path template to guide them in understanding high-order semantics. To bridge the gap between pretext and downstream tasks, we unify the optimization objective of pre-training and prompting. Specifically, we aggregate clustering features of target nodes from prompt tokens, which can be viewed as data augmentation w.r.t. structural or semantic features. Hence, the prompt tokens and the adjacency matrix can be learned using a contrastive loss aligned with pre-training.

The contributions of our work are summarized as follows:

\begin{itemize}
    \item We propose \ourmethod, a novel prompt learning model for heterogeneous graphs. To the best of our knowledge, this is the first attempt to reformulate downstream tasks as heterogeneous graph reconstruction with prompts.
    \item We introduce a contrastive framework to learn structural, semantic, and clustering information in heterogeneous graphs, which unifies the optimization objective of pre-training and prompting.
    \item We design a meta-path template to guide prompts in capturing semantics from meta-paths.
    \item Extensive experiments on downstream tasks demonstrate the superiority of our model against state-of-the-art heterogeneous graph learning models.
\end{itemize}

% Distinguished from the linear sequence of text, graphs are topological structures consisting of complex relationships and connections between nodes. The graph prompt should not only reformulate downstream tasks to look like the pretext task, but also conform to the structure of the heterogeneous graph. 2) Creating prompts by manually combining tokens is not feasible since nodes cannot express semantics explicitly like words. Additionally, it is unlikely to use known tokens for prompting and prediction since each token represents a specific entity in the graph. 3) Heterogeneous graphs contain not only structural information of node connections but also semantic information of meta-paths. It is significant for the prompt token to exploit the graph properties of both, which enables more effective and comprehensive predictions.

% Typical structure-preserved heterogeneous graph embedding methods can be roughly divided into two categories, including link-based methods and path-based methods. Specifically, most of them focus on reconstruction of heterogeneous graph structure to learn node embeddings, i.e., preservation of first-order and high-order proximity, respectively. By utilizing the structural information of heterogeneous graphs for pre-training, node embeddings are highly compatible with structure-specific tasks, such as link prediction and meta-path selection. For other downstream tasks like node classification, fine-tuning strategies are leveraged to transfer the learned source knowledge to the target domain. Nevertheless, there are usually differences in knowledge distribution between the source domain and the target domain, resulting in distorted or missing features after transfer learning. % add more description

% To bridge this gap between pre-training tasks and downstream tasks, prompt learning has attracted growing attention and achieved great success on natural language processing (NLP). For example, given a case ``I am interested in this paper, \underline{it is a} [good] \underline{paper}", the paper can be classified via a prompt token ``\underline{it is a} [MASK] \underline{paper}". The classification task is converted to a slot filling task that naturally conforms to the pre-training objective. In this way, the pre-trained knowledge can be directly used by downstream tasks without fine-tuning, which reduces semantic differences. Inspired by the language prompts, studies \cite{GPPT,All} propose to apply prompt learning on homogeneous graphs, which reformulates downstream tasks into the pattern of pre-training tasks.

% However, there are still difficulties in designing appropriate prompts on heterogeneous graphs. First, the data structure of heterogeneous graphs is different from that of natural language. If we view nodes as tokens, they form a network structure in the graph rather than a sequential structure. Graph structures such as neighbors and meta-paths should be taken into consideration. Second, creating prompts by manually combining tokens is not feasible since nodes cannot express semantics explicitly like words. Additionally, it is unlikely to use known tokens for prompting and prediction since each token represents a specific entity in the graph. Third, heterogeneous graphs contain multiple types of nodes and edges. Different from a single type of tokens in homogeneous graph, we should assign appropriate types to tokens and their connections.
