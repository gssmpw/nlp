% !TEX root = ../main.tex

\subsection{Additional results}
\label{sec:additional_results}
  \cref{fig:pointplot/rcp_vs_base/horizontal} extends the results in \cref{fig:pointplot/rcp_vs_base/wsc} by displaying additionally the marginal coverage and conditional coverage error. As expected, all methods obtain a correct marginal coverage. Furthermore, the methods with the best worst slab coverage (closest to $1 - \alpha$) also obtain a small conditional coverage error, supporting our conclusions in \cref{sec:experiments}.

  \begin{figure}[H]
    \centering
    \includegraphics[width=0.8\linewidth]{fig/pointplot/rcp_vs_base/horizontal.pdf}
    \caption{Marginal coverage and conditional coverage error for three conformal methods and their \RCP\ counterparts, on datasets sorted by total size.}
    \label{fig:pointplot/rcp_vs_base/horizontal}
  \end{figure}


\subsection{Estimation of conditional quantile function}
\label{sec:tau_testimation}
  \cref{fig:pointplot/kernel_0.01/horizontal} compares two ways of estimating $\widehat{\tau}$ (see \cref{subsec:tau_qr}). RCP$_\text{MLP}$ corresponds to quantile regression based on a neural network as in \cref{sec:experiments}, while RCP$_\text{local}$ corresponds to local quantile regression. On most datasets, the more flexible RCP$_\text{MLP}$ is able to obtain better conditional coverage. However, local quantile regression has theoretical guarantee on its conditional coverage (see \cref{sec:theory}).

  \begin{figure}[H]
    \centering
    \includegraphics[width=0.8\linewidth]{fig/pointplot/kernel_0.01/horizontal.pdf}
    \caption{Marginal coverage and conditional coverage error for two types of quantile estimators in combination with different conformal methods, on datasets sorted by total size.}
    \label{fig:pointplot/kernel_0.01/horizontal}
  \end{figure}


\subsection{Choice of adjustment function}
\label{sec:adj_function}
  \Cref{fig:pointplot/adjustment_issue/horizontal} compares \RCP\ with difference ($-$) and linear ($*$) adjustments when combined with the DCP method. Since \RCP\ with any adjustment function adheres to the SCP framework, marginal coverage is guaranteed, as shown in Panel 1.

  The conformity score for DCP is defined as \( V(x, y) = -\log \hat{p}(y \mid x) \), which can take negative values, implying that \( \mathbb{T} = \mathbb{R} \). However, the linear adjustment requires \( \mathbb{T} \subseteq \mathbb{R}_+^* \), violating \cref{ass:tau} and resulting in a failure to approximate conditional coverage accurately. This issue is evident in Panel 2, particularly for datasets \texttt{rf\_1}, \texttt{rf\_2}, \texttt{meps\_21}, \texttt{meps\_19}, and \texttt{meps\_20}. In contrast, the difference adjustment does not impose such a restriction.

  Panel 3 compares PCP and ResCP when used with difference and linear adjustments. Since the conformity scores for these methods are always positive, i.e., \( \mathbb{T} = \mathbb{R}^*_+ \), both adjustment methods satisfy \cref{ass:tau}. In general, we observe no significant differences between the two adjustment methods.

  \begin{figure}[H]
    \centering
    \includegraphics[width=0.66\linewidth]{fig/pointplot/adjustment_issue/horizontal.pdf}
    \includegraphics[width=0.32\linewidth]{fig/pointplot/adjustments/cond_cov_x_error.pdf}
    \caption{Marginal coverage and conditional coverage error obtained for two types of adjustments.}
    \label{fig:pointplot/adjustment_issue/horizontal}
  \end{figure}

\newpage
\subsection{Additional adjustment functions}
\label{sec:additional_adjustment}
  We consider two additional adjustments functions, namely $f_t(v) = \exp{(t + v)}$, denoted $\exp -$, and $f_t(v) = \exp{(t v)}$, denoted $\exp *$. To apply these custom adjustment functions we need to ensure that the conditions \Cref{ass:tau} and \Cref{ass:tau-in-T} are satisfied.
  %\todo[inline]{Does $\exp *$ require scores greater than 1?}
  For the first function we have: $\tilde{f}_{\varphi}^{-1}(v) = (\ln v) - \varphi \in \mathbb{T}$ and $\varphi = 0$. Then $\tilde{f}_{\varphi}^{-1}(v) > 0 \; \Rightarrow \ln v > 0 \; \Rightarrow v > 1$. For the second function we can take $\varphi = 1$ and by similar argument we arrive at the same requirement $v > 1$. In practice, conformity scores are usually
   non-negative as is the case with PCP and residual scores that we consider here, and we can always add a constant $1$ to satisfy this requirement.
  
  \cref{fig:pointplot/adjustments_pcp/horizontal,fig:pointplot/adjustments_res/horizontal} show the marginal coverage and conditional coverage error obtained with these adjustment functions.
  

  \begin{figure}[H]
    \centering
    \includegraphics[width=0.8\linewidth]{fig/pointplot/adjustments_pcp/horizontal.pdf}
    \caption{Marginal coverage and conditional coverage error for two additional types of adjustments combined with the method PCP.}
    \label{fig:pointplot/adjustments_pcp/horizontal}
  \end{figure}

  \begin{figure}[H]
    \centering
    \includegraphics[width=0.8\linewidth]{fig/pointplot/adjustments_res/horizontal.pdf}
    \caption{Marginal coverage and conditional coverage error for two additional types of adjustments combined with the method ResCP.}
    \label{fig:pointplot/adjustments_res/horizontal}
  \end{figure}

\newpage
\subsection{Comparison with simple baselines}
\label{sec:simple_baseline}
  \cref{fig:pointplot/rcp_vs_qr/horizontal} demonstrates improvements of \RCP\ over simpler baseline methods, serving as a small ablation study. 

  The first baseline, denoted CQR, is based on quantile regression estimates for each dimension of the output variable. First, (univariate) conformalized quantile regression scores~\cite{romano2019conformalized} are computed for each dimension. Then, they are aggregated by taking the maximum score over each dimension, similarly to ResCP in the main text. The resulting prediction set in this case is a hyperrectangle. Its size is adaptive to the input, but the conformal correction is isotropic and constant for all input points. 

  For the remaining methods, the model outputs parameters of a multivariate normal distribution. The score in this case is the Mahalanobis distance. The first part of the name before the dash states the type of the base model. ``Const'' is a constant prediction of the empirical mean and covariance matrix on the train set. ``MLP'' corresponds to a small neural network that predicts these parameters based on the input point $x$. The prediction sets for this group of methods are hyperellipsoids (not necessarily aligned with the axes).

  \begin{figure}[H]
    \centering
    \includegraphics[width=0.8\linewidth]{fig/pointplot/rcp_vs_qr/wsc_log_vol_1.pdf}
    \caption{Worst slab coverage and logarithm of prediction set volume (divided by number of dimensions of the response).}
    \label{fig:pointplot/rcp_vs_qr/horizontal}
  \end{figure}

  These graphs provide some important insights:
  \begin{itemize}
    \item Methods based on classic conformal prediction (Const-CP, MLP-CP) often struggle to maintain conditional coverage.
    \item \RCP\ improves conditional coverage: Const-RCP outperforms Const-CP in conditional coverage and set size.
    \item \RCP\ in combination with any of these conformity score either maintains or improves conditional coverage and volume.
  \end{itemize}
