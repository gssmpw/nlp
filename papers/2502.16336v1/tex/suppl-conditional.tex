% !TEX root = ../main.tex

This section is dedicated to the proof of the conditional guarantee provided in \Cref{sec:theory}. Along this section, we denote $\tilde{V}(x,y)=\adj{\hat{\tau}(x)}^{-1}(V(x,y))$ and for any $t\in\R$, we denote
\begin{equation*}
  F_{\tilde{\mathbf{V}}\mid X=x}(t)
  = \prob\prn{\tilde{V}(X,Y)\le t \,\vert\, X=x}
  \qquad\text{ and }\qquad
  F_{\tilde{\mathbf{V}}}(t) = \prob\prn{\tilde{V}(X,Y)\le t}.
\end{equation*}
%
For any $x\in\XC$, we assess the quality of the quantile estimate $\tau(x)$ via
\begin{equation*}
  \epsilon_{\tau}(x)
  = \prob\pr{\adjinv^{-1}(V(x,Y))\le \hat{\tau}(x) \,\vert\, X=x} - 1 + \alpha.
\end{equation*}
%
For all $n\in\N$, note that $\alpha (1-\alpha)^{\tcount+1}\le \frac{\rme}{\tcount+2}$.
If $\alpha\ge 0.1$ and $\tcount\ge 100$, then $\alpha (1-\alpha)^{\tcount+1}\le \frac{1}{4183\tcount}$.
In addition, if $F_{\tilde{V}}(\varphi)\le 1-\alpha$, then $\alpha \mathrm{L} F_{\tilde{V}}(\varphi) \le \frac{\mathrm{L}}{4183\tcount}$.

\begin{theorem}  
  Assume that \Cref{ass:tau}-\Cref{ass:tau-in-T} hold.  Assume in addition that, for any $x \in \XC$, $F_{\tilde{V}}$ is continuous and $F_{\tilde{V}\mid X=x}\circ F_{\tilde{V}}^{-1}$ is $\mathrm{L}$-Lipschitz. Then for $\alpha\in[\{\tcount+1\}^{-1},1)$ it holds
  \begin{multline*}
    1 - \alpha + \epsilon_{\tau}(X_{\tcount+1})
    - \alpha \mathrm{L} \times \brn{F_{\tilde{V}}(\varphi)}^{\tcount+1}
    \le \prob\pr{Y_{\tcount+1}\in \mathcal{C}_{\alpha}(X_{\tcount+1}) \,\vert\, X_{\tcount+1}}
    \\
    \le 1 - \alpha + \epsilon_{\tau}(X_{\tcount+1})
    + \mathrm{L} \prt{1 - \alpha + (\tcount+1)^{-1}} \times \brn{1 - F_{\tilde{V}}(\varphi)}^{\tcount+1}.
  \end{multline*}
\end{theorem}

\begin{proof}
  Let $t\in\R$ be fixed. A first calculation shows that
  \begin{align*}
    \prob\pr{\adj{\tau(X)}^{-1}(V(X,Y))\le t}
    &= \int \prob\pr{\adj{\tau(x)}^{-1}(V(x,Y))\le t \,\vert\, X=x} \textup{P}_{X}(\rmd x)
    \\
    &= \int \prob\pr{\tilde{f}_{t}^{-1}(V(x,Y))\le \tau(x) \,\vert\, X=x} \textup{P}_{X}(\rmd x).
  \end{align*}
  %
  Now, we introduce the notation $\Delta_{t}(x)$, which quantifies the discrepancy between substituting $\varphi$ with $t$:
  \begin{equation*}
    \Delta_{t}(x)
    = \prob\pr{\tilde{f}_{t}^{-1}(V(x,Y))\le \tau(x) \,\vert\, X=x}
    - \prob\pr{\adjinv^{-1}(V(x,Y))\le \tau(x) \,\vert\, X=x}.
  \end{equation*}
  %
  Let's $\textup{P}_Q$ denote the distribution of the empirical quantile $\q{(1-\alpha)(1+\tcount^{-1})} (\frac{1}{\tcount} \sum\nolimits_{k=1}^{\tcount} \delta_{\tilde{V}_k})$.
  We can rewrite the conditional coverage as follows
  \begin{align*}
    \prob\pr{Y_{\tcount+1}\in \mathcal{C}_{\alpha}(X_{\tcount+1}) \,\vert\, X_{\tcount+1}=x}
    &= \int \prob\pr{\adj{\tau(x)}^{-1}(V(x,Y))\le t \,\vert\, X=x} \textup{P}_Q(\rmd t)
    \\
    &= \int \prob\pr{\tilde{f}_{t}^{-1}(V(x,Y))\le \tau(x) \,\vert\, X=x} \textup{P}_Q(\rmd t)
    \\
    &= \prob\pr{\adjinv^{-1}(V(x,Y))\le \tau(x) \,\vert\, X=x} + \int \Delta_{t}(x) \textup{P}_Q(\rmd t)
    \\
    &= 1 - \alpha + \epsilon_{\tau}(x) + \int \Delta_{t}(x) \textup{P}_Q(\rmd t).
  \end{align*}
  %
  Moreover, consider a set of $\tcount$ i.i.d. uniform random variables $\{U_k\}_{1\le k\le \tcount}$, and let $U_{(1)}\le\ldots\le U_{(\tcount)}$ denote their order statistics.
  Since $\tilde{V}_1,\ldots,\tilde{V}_{\tcount}$ are i.i.d., their joint distribution is the same as $(F_{\tilde{V}}^{-1}(U_1),\ldots,F_{\tilde{V}}^{-1}(U_{\tcount}))$.
  Therefore, $\textup{P}_{Q}$ is also the distribution of the $(1+\tcount^{-1})(1-\alpha)$-quantile of $\frac{1}{\tcount} \sum\nolimits_{k=1}^{\tcount} \delta_{F_{\tilde{V}}^{-1}(U_k)}$. Thus, there exists an integer $k_{\alpha}\in\{1,\ldots,\tcount\}$ such that
  \begin{equation*}
    F_{\tilde{V}}^{-1}(U_{(k_{\alpha})}) = \q{(1-\alpha)(1+\tcount^{-1})} \pr{ \frac{1}{\tcount} \sum\nolimits_{k=1}^{\tcount} \delta_{F_{\tilde{V}}^{-1}(U_k)} }.
  \end{equation*}
  %
  Moreover, using that $\{\tilde{V}_k\colon k\in[\tcount]\}$ are almost surely distinct, we deduce the existence of the minimal integer $k_{\alpha}\in[\tcount]$ such that
  \begin{equation*}
    \frac{1}{\tcount} \sum\nolimits_{k=1}^{\tcount} \1_{U_{(k)}\le U_{(k_{\alpha})}} 
    \ge \pr{1+\frac{1}{\tcount}} (1-\alpha).
  \end{equation*}
  %
  Since $\sum\nolimits_{k=1}^{\tcount} \1_{U_{(k)}\le U_{(k_{\alpha})}} = k_{\alpha}$ almost surely, we deduce that $k_{\alpha} = \lceil (\tcount+1) (1-\alpha) \rceil$. 
  We also get that $F_{\tilde{V}}^{-1}(U_{(k_{\alpha})})\sim \textup{P}_{Q}$.
  In the following, we provide a lower bound on $\Delta_{t}(x)$.
  Since $F_{\tilde{V}\mid X=x}$ is increasing, we can write
  \begin{equation}\label{eq:eq:int-delta-PQ}
    \int \Delta_{t}(x) \textup{P}_Q(\rmd t)
    = \E\br{F_{\tilde{V}\mid X=x}\circ F_{\tilde{V}}^{-1}(U_{(k_{\alpha})}) - F_{\tilde{V}\mid X=x}(\varphi)}.
  \end{equation}

\paragraph{Lower bound.}
  First, using~\eqref{eq:eq:int-delta-PQ} implies that
  \begin{equation*}
    \int \Delta_{t}(x) \textup{P}_Q(\rmd t)
    \ge - \E\br{ \1_{\varphi \ge F_{\tilde{V}}^{-1}(U_{(k_\alpha)})} \times \ac{ F_{\tilde{V}\mid X=x}(\varphi) - F_{\tilde{V}\mid X=x}\circ F_{\tilde{V}}^{-1}(U_{(k_{\alpha})}) }_{+} }.
  \end{equation*}
  Moreover, by definition of the cumulative density function and its inverse, we have 
  $
    F_{\tilde{V}\mid X=x}\circ F_{\tilde{V}}^{-1} \circ F_{\tilde{V}}(\varphi)
    \le F_{\tilde{V}\mid X=x}(\varphi)
  $.
  Thus, it follows that
  \begin{multline}\label{eq:bound:expec-Delta}
    \E\br{ \1_{\varphi \ge F_{\tilde{V}}^{-1}(U_{(k_\alpha)})} \times \ac{ F_{\tilde{V}\mid X=x}(\varphi) - F_{\tilde{V}\mid X=x}\circ F_{\tilde{V}}^{-1}(U_{(k_{\alpha})}) }_{+} }
    \\
    \le F_{\tilde{V}\mid X=x}(\varphi) - F_{\tilde{V}\mid X=x}\circ F_{\tilde{V}}^{-1} \circ F_{\tilde{V}}(\varphi)
    \\
    + \E\br{ \1_{\varphi \ge F_{\tilde{V}}^{-1}(U_{(k_\alpha)})} \times \ac{ F_{\tilde{V}\mid X=x}\circ F_{\tilde{V}}^{-1} \circ F_{\tilde{V}}(\varphi) - F_{\tilde{V}\mid X=x}\circ F_{\tilde{V}}^{-1}(U_{(k_{\alpha})}) }_{+} }
        .
  \end{multline}
  %
  If $F_{\tilde{V}}(\varphi)=1$, then $F_{\tilde{V}\mid X=x}(\varphi)=1$ $\textup{P}_{X}$-almost everywhere.
  Let's now suppose that $F_{\tilde{V}}(\varphi)<1$ and let's define $\varphi_\star = \sup\{t\in\R\colon F_{\tilde{V}}(t)=F_{\tilde{V}}(\varphi)\}$.
  For any $\epsilon>0$, note that $F_{\tilde{V}}(\varphi_\star + \epsilon) > F_{\tilde{V}}(\varphi_{\star})$. This leads to
  \begin{equation*}
    F_{\tilde{V}}^{-1} \circ F_{\tilde{V}}(\varphi_\star + \epsilon)
    = \inf\ac{t\in\R\colon F_{\tilde{V}}(t) \ge F_{\tilde{V}}(\varphi_\star + \epsilon)}
    > \varphi_{\star}.
  \end{equation*}
  %
  Furthermore, using the $\mathrm{L}$-Lipschitz assumption on $F_{\tilde{V}\mid X=x}\circ F_{\tilde{V}}^{-1}$ implies that
  \begin{align}
    \nonumber
    0
    &\le F_{\tilde{V}\mid X=x}(\varphi) - F_{\tilde{V}\mid X=x}\circ F_{\tilde{V}}^{-1} \circ F_{\tilde{V}}(\varphi)
    \\
    \nonumber
    &\le \liminf_{\epsilon\to 0_+} \ac{
      F_{\tilde{V}\mid X=x}\circ F_{\tilde{V}}^{-1} \circ F_{\tilde{V}}(\varphi_\star + \epsilon)
      - F_{\tilde{V}\mid X=x}\circ F_{\tilde{V}}^{-1} \circ F_{\tilde{V}}(\varphi)
    }
    \\
    \label{eq:bound:diff-Fvarphi}
    &\le \mathrm{L} \liminf_{\epsilon\to 0_+} \ac{F_{\tilde{V}}(\varphi_\star + \epsilon) - F_{\tilde{V}}(\varphi)}.
  \end{align}
  %
  From the continuity of $F$, we deduce that $F_{\tilde{V}}(\varphi)=F_{\tilde{V}}(\varphi_\star)$. Therefore, we can conclude that $\liminf_{\epsilon\to 0_+} \{F_{\tilde{V}}(\varphi_\star + \epsilon) - F_{\tilde{V}}(\varphi)\} = 0$.
  This computation combined with~\eqref{eq:bound:diff-Fvarphi} shows that $F_{\tilde{V}\mid X=x}(\varphi) = F_{\tilde{V}\mid X=x}\circ F_{\tilde{V}}^{-1} \circ F_{\tilde{V}}(\varphi)$.
  Lastly, it just remains to upper bound the last term of~\eqref{eq:bound:expec-Delta}. Once again, using that $F_{\tilde{V}\mid X=x}\circ F_{\tilde{V}}^{-1}$ is Lipschitz gives
  \begin{equation*}
    \E\br{ \1_{\varphi \ge F_{\tilde{V}}^{-1}(U_{(k_\alpha)})} \times \ac{ F_{\tilde{V}\mid X=x}\circ F_{\tilde{V}}^{-1} \circ F_{\tilde{V}}(\varphi) - F_{\tilde{V}\mid X=x}\circ F_{\tilde{V}}^{-1}(U_{(k_{\alpha})}) }_{+} }
    \le \mathrm{L} \E\br{ \ac{ F_{\tilde{V}}(\varphi) - U_{(k_{\alpha})} }_{+} }.
  \end{equation*}
  %
  Finally, applying \Cref{lem:bound:expec-1alphaU} with $\beta=F_{\tilde{V}}(\varphi)$ and $k=k_{\alpha}$ yields the lower bound.

\paragraph{Upper bound.}
  From~\eqref{eq:eq:int-delta-PQ}, we deduce that
  \begin{equation}
    \int \Delta_{t}(x) \textup{P}_Q(\rmd t)
    \le \E\br{ \1_{\varphi \le F_{\tilde{V}}^{-1}(U_{(k_\alpha)})} \times \ac{ F_{\tilde{V}\mid X=x}\circ F_{\tilde{V}}^{-1}(U_{(k_{\alpha})}) - F_{\tilde{V}\mid X=x}(\varphi) }_{+} }.
  \end{equation}
  %  
  By definition of $F_{\tilde{V}}^{-1}$, we get $\varphi \ge F_{\tilde{V}}^{-1} \circ F_{\tilde{V}}(\varphi)$.
  Since $F_{\tilde{V}\mid X=x}$ is increasing and $F_{\tilde{V}\mid X=x}\circ F_{\tilde{V}}^{-1}$ is $\mathrm{L}$-Lipschitz, it follows that
  \begin{align*}
    \int \Delta_{t}(x) \textup{P}_Q(\rmd t)
    &\le \E\br{ \1_{\varphi \le F_{\tilde{V}}^{-1}(U_{(k_\alpha)})} \times \ac{ F_{\tilde{V}\mid X=x}\circ F_{\tilde{V}}^{-1}(U_{(k_{\alpha})}) - F_{\tilde{V}\mid X=x}(\varphi) }_{+} }
    \\
    &\le \mathrm{L} \E\br{ \ac{ U_{(k_{\alpha})} - F_{\tilde{V}}(\varphi) }_{+} }
    \\
    &= \mathrm{L} \E\br{ \ac{ 1 - F_{\tilde{V}}(\varphi) - (1 - U_{(k_{\alpha})}) }_{+} }.
  \end{align*}
  %
  Since the distribution of $1 - U_{(k_{\alpha})}$ is the same that the distribution of $U_{(\tcount+1-k_{\alpha})}$, applying \Cref{lem:bound:expec-1alphaU} with $\beta=1-F_{\tilde{V}}(\varphi)$ and $k=\tcount+1-k_{\alpha}$ yields the upper bound.
\end{proof}

Let's denote by $U_{(k)}$ the $k$th order statistic of the i.i.d. uniform random variables $U_1,\ldots,U_{\tcount}$.
\begin{lemma}\label{lem:bound:expec-1alphaU}
  For any $\beta\in[0,1]$ and $k\in[\tcount]$, it holds that
  \begin{equation*}
    \E\br{\pr{\beta - U_{(k)}}_{+}}
    = \beta^{\tcount+1} \pr{1 - \frac{k}{\tcount+1}}.
  \end{equation*}
\end{lemma}

\begin{proof}
  Let $\beta\in[0,1]$ be fixed.
  For any $(i,j)\in\N^2$, define 
  \[
    I(i,j)
    = \int_0^{\beta} u^i (1-u)^j \rmd u.
  \]
  %
  By applying integration by parts for $j\ge 1$, we obtain
  \begin{equation*}
    \frac{I(i,j)}{i! j!}
    = \frac{I(i+1,j-1)}{(i+1)! (j-1)!}
    = \cdots
    = \frac{I(i+j,0)}{(i+j)!}
    = \frac{\beta^{i+j+1}}{(i+j+1)!}.
  \end{equation*}
  %
  Since $U_{(k)}$ follows a beta distribution with parameters $(k, \tcount+1-k)$, it follows that
  \begin{equation}\label{eq:eq:expect-beta-Uk}
    \E\br{\pr{\beta - U_{(k)}}_{+}}
    = \int_{0}^{\beta} \frac{\tcount! (\beta - u)}{(k-1)! (\tcount-k)!} u^{k-1} (1-u)^{\tcount-k} \rmd u.
  \end{equation}
  %  
  Furthermore, we have the following derivations:
  \begin{align}
    \nonumber
    &\int_0^{\beta} (\beta-u) u^{k-1} (1-u)^{\tcount-k} \rmd u
    \\
    \nonumber
    &= \beta \int_0^{\beta} u^{k-1} (1-u)^{\tcount-k} \rmd u
    - \int_0^{\beta} (\beta-u) u^{k} (1-u)^{\tcount-k} \rmd u
    \\
    \label{eq:bound:alpha-1-alpha}
    &= \beta I(k-1,\tcount-k) - I(k,\tcount-k).
  \end{align}
  %
  Lastly, combining \eqref{eq:eq:expect-beta-Uk} with \eqref{eq:bound:alpha-1-alpha} yields the next result
  \begin{equation*}
    \E\br{\pr{\beta - U_{(k)}}_{+}}
    = \beta \frac{\tcount! I(k-1,\tcount-k)}{(k-1)! (\tcount-k)!} - \frac{\tcount! I(k,\tcount-k)}{(k-1)! (\tcount-k)!}
    = \beta^{\tcount+1} - \frac{\beta^{\tcount+1} k}{\tcount+1}.
  \end{equation*}
\end{proof}

For any $\beta\in[0,1]$, observe that
\begin{equation*}
  (1-\beta) \beta^{\tcount+1}
  \le \frac{\exp\pr{(\tcount+1) \log(1-(\tcount+2)^{-1})}}{\tcount+2}.
\end{equation*}
%
Noting that $\log(1-(\tcount+2)^{-1}) = \sum_{k\ge 1} k^{-1} (\tcount+2)^{-k}$, we can show that:
\begin{equation*}
  (\tcount+1) \log\pr{1-\frac{1}{\tcount+2}}
  = 1 - \frac{1}{\tcount+2} + \frac{\tcount+1}{(\tcount+2)^2} \sum_{k\ge 0} \frac{(\tcount+2)^{-k}}{k+2}
  \le 1.
\end{equation*}
%
Consequently, this implies that $(1-\beta) \beta^{\tcount+1}\le (\tcount+2)^{-1} \rme$.
