% !TEX root = ../main.tex

If $\tau_\star\in\mathcal{T}$, then the Jensen's inequality implies that
\begin{align*}
  \E\abs{\epsilon_{\tau}(X_{\tcount+1})}
  &\le \E\sqrt{ 2 \mathrm{Lip}(\mathcal{L}_{X_{\tcount+1}}) \times \ac{ \mathcal{L}_{X_{\tcount+1}}(\tau) - \mathcal{L}_{X_{\tcount+1}}(\tau_\star) } }
  \\
  &\le \sqrt{ 2 \act{\sup_{x\in\XC}\mathrm{Lip}(\mathcal{L}_{x})} \times \ac{ \mathcal{L}(\tau) - \mathcal{L}(\tau_\star) } }.
\end{align*}


\paragraph{Probabilistic bound on $\E[\epsilon_{\tau}(X_{\tcount+1}) \mid \mathcal{D}_{\mathrm{train}}]$.}
  In this paragraph, we control the expected approximation error $\E[\epsilon_{\tau}(X_{\tcount+1}) \mid \mathcal{D}_{\mathrm{train}}]$, which is the difference between the confidence level given by the quantile $\tau(x)$ and the target $1-\alpha$. We use a result based on Rademacher complexity; see~\cite[Theorem~6]{takeuchi2006nonparametric}. Let $\tau_{\star}$ denote the minimizer of the loss function $\mathcal{L}$ given by
  \begin{equation*}
    \mathcal{L}\pr{\tau_{\star}}
    = \argmin_{g\in \mathcal{T}}\E\br{\mathcal{L}_{X}\pr{g}}.
  \end{equation*}
  We consider its empirical minimizer $\tau$ as in~\eqref{eq:def:reg-tau}.
  \thmspace

  \begin{theorem}
    Assume that all the functions in $\mathcal{T}$ are uniformly bounded by a constant $\norm{\mathcal{T}}_{\infty}$. 
    Given $\delta\in(0,1)$, with probability at least $(1-\delta)$ it holds that
    \begin{equation*}
      \mathcal{L}\pr{\tau} - \mathcal{L}\pr{\tau_{\star}} 
      \le (4 + \norm{\mathcal{T}}_{\infty}) \sqrt{\frac{\log 2 / \delta}{2 \tcount}}.
      + \frac{4}{|\mathcal{D}_{\mathrm{train}}|} \E\br{\textstyle \sup _{g \in \mathcal{T}}\abs{ \sum_{(X_i,Y_i)\in\mathcal{D}_{\mathrm{train}}} \sigma_i g(X_i) }}
    \end{equation*}
    %
    Additionally, if the true conditional quantile belongs to $\mathcal{T}$, then
    \begin{equation*}
      \E\br{ \abs{\epsilon_{\tau}(X_{\tcount+1})} \,\vert\, \mathcal{D}_{\mathrm{train}} }
      \le \sqrt{ 2 \ac{ \mathcal{L}(\tau) - \mathcal{L}(\tau_\star) } }.
    \end{equation*}
  \end{theorem}

  \vp{The expectations are taken conditionally on the training dataset. Maybe we need to change the notation to avoid confusion. Mettre la d√©finition (9) de {https://arxiv.org/pdf/1203.5422}.}

  \vincent{Asymptotic validity}
