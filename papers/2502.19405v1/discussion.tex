\section{Concluding discussion}

Our work shows that the refereed delegation model, if sufficiently tailored to the ML setting and with our RepOps library to ensure deterministic computation, provides a middle ground between the expense of fully verified ML training and the insecurity of heuristic approaches.
Bringing our work to practice requires solving several additional practical challenges.
First, to ensure a high likelihood of at least one honest \trainer, a robust ecosystem of \trainers is needed, which are unlikely to collude or suffer related faults (e.g. by running the same third party data center).
Second, incentives are needed to compensate \trainers both for running the original computation and for interacting with the referee to detect dishonest behavior.
The recent BoLD protocol~\cite{alvarez2024bold}, designed for optimistic rollups, may provide a template here.
Finally, our work may see application in the context of blockchains, meaning our referee functionality needs to be implemented to run efficiently as a smart contract in an environment like the Ethereum Virtual Machine (EVM).
EVM was not designed with ML operations involved, and in particular offers no native support for floating point operations.
We leave developing our referee functionality to run in this environment to future work.
