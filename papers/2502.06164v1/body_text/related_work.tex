\section{Related Work}
Many existing approaches  augment the tensor with a time mode  to integrate temporal information~\citep{Xiong_Chen_Huang_Schneider_Carbonell_2010, Rogers_Li_Russell_2013, Zhe_Zhang_Wang_Lee_Xu_Qi_Ghahramani_2016,post}.
To leverage continuous timestamps, \citet{bctt} modeled the tensor core while 
\citet{SFTL} modeled the latent factors 
as  time functions with Gaussian processes within the Tucker decomposition.  Similarly, \citet{NONFAT} captured the temporal evolution of latent factors in the frequency domain by employing a Gaussian process prior, with the factor trajectories subsequently generated via inverse Fourier transform.
In contrast,  \citet{thisode} directly applied a neural ODE model to represent tensor entry values as a function of the corresponding latent factors and time. However,  it learns time-invariant latent factors to control the derivatives of the entry dynamics, limiting its expressiveness. 
The most recent work~\citep{wang2024dynamictensor} constructed 
 a multipartite graph to encode interactions across different modes into the evolution of  latent factors. 
 However, the above  methods are unable to model the temporal tensor data with all modes being continuous-indexed. 




Within burgeoning literature on functional tensors, existing methods often rely on deterministic tensor models, such as the Tucker model \cite{luo2023lowrank} or tensor train models \cite{Gor_2015_tt, Big_2016_tt, Ballester-Ripoll_Paredes_Pajarola_2019_tt, chertkov2022optimization_tt, chertkov2023black_tt}, to approximate multivariate functions with low-rank structures. However, these methods are sensitive to  data noise and lack the capability to provide uncertainty quantification.
Alternatively, tensor-based Bayesian models with Gaussian process priors have been proposed to represent continuous-indexed latent factors \cite{Schmidt_2009_cp, fang2023functional}. Despite their advantages, these approaches do not explicitly model temporal dynamics, limiting their effectiveness in capturing complex patterns.


