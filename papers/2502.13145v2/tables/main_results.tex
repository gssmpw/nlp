    
    
\begin{table*}[t!]
    \centering
    \small
    
    \scalebox{0.90}{
    \setlength{\tabcolsep}{1.0pt}
    \begin{tabular}{l c c c r | c c c c c c |c  c c }
    \toprule
    \multirow{1}{*}{Method} & \multirow{1}{*}{Recipe} & \multirow{1}{*}{Complexity} & \multirow{1}{*}{\# P.} & \multirow{1}{*}{\# T.P.}& MME & MMB &POPE & \multicolumn{1}{c} {SEED} & MMMU & MM-Vet& TQA & SQA-I  & \multicolumn{1}{c}{GQA} \\
    \midrule
    \rowcolor{gray!14}
    \multicolumn{14}{l}{\textbf{\textit{Encoder-based VLMs}}} \\ 
    OpenFlamingo~\cite{openflamingo} & \underline{PT, SFT}& Quadratic & 9B& 96.6\%  & - & 4.6 & - & - & - & - & 33.6 & - & - \\
    MiniGPT-4~\cite{minigpt} & \underline{PT, SFT}& Quadratic & 13B& 94.8\%  & 581.7 & 23.0 & - & - & -& 22.1 & - & - & 32.2  \\
    Qwen-VL~\cite{qwenvl} & \underline{PT, SFT}& Quadratic & 7B& 100.0\%  & - & 38.2 & - & 56.3 & - & - & 63.8 & 67.1 & 59.3\\ 
    LLaVA-Phi~\cite{llavaphi}  & \underline{PT, SFT}& Quadratic & 3B& 90.0\%  & 1335.1 & 59.8 & 85.0 & - & - & 28.9& 48.6 & 68.4 & - \\
    MobileVLM-3B~\cite{mobilevlm} & \underline{PT, SFT}& Quadratic & 3B& 90.0\%  & 1288.9 & 59.6 & 84.9 & - & - & - & 47.5 & 61.0 & 59.0  \\
    VisualRWKV~\cite{visualrwkv} & \underline{PT, SFT}&  \textbf{Linear} & 3B& 90.0\%  & 1369.2 & 59.5 & 83.1 & - & - & - & 48.7 & 65.3 & 59.6 \\
    VL-Mamba~\cite{vlmamba} & \underline{PT, SFT}&  \textbf{Linear} & 3B& 90.0\%  & 1369.6 & 57.0 & 84.4 & - & -& 32.6 & 48.9 & 65.4 & 56.2 \\
    Cobra~\cite{cobra} & \underline{PT, SFT}&  \textbf{Linear} & 3.5B& 82.6\%  & - & - & \textbf{88.4} & - & - & - & 58.2 & - & \textbf{62.3}\\
    \midrule
    \rowcolor{gray!14}
    \multicolumn{14}{l}{\textbf{\textit{Decoder-only VLMs}}} \\
    Fuyu-8B (HD)~\cite{fuyu} & \underline{PT, SFT}& Quadratic & 8B& 100.0\%  & 728.6 & 10.7 & 74.1 & - & - & 21.4 & - & - & -\\
    SOLO~\cite{solo} & \underline{PT, SFT}& Quadratic &  7B& 100.0\%   & 1001.3 & - & - & 64.4 & - & - & - & 73.3 & -   \\    
    Chameleon-7B~\cite{chameleon}  & \underline{PT, SFT}& Quadratic &  7B& 100.0\%   & 170 & 31.1 & - & 30.6 & 25.4 & 8.3 & 4.8 & 47.2 & -\\  
    EVE-7B~\cite{eve}  & \underline{PT, SFT}& Quadratic &  7B& 100.0\%  & 1217.3 & 49.5 & 83.6 & 61.3 & \underline{32.3} & 25.6& 51.9 & 63.0 & 60.8 \\
    Emu3~\cite{emu3} & \underline{PT, SFT}& Quadratic & 8B& 100.0\%  & - & 58.5 & 85.2 & \underline{68.2} & 31.6 & \underline{37.2} & \underline{64.7} & \underline{89.2} & 60.3\\
    HoVLE~\cite{hovle} & DT, PT, SFT & Quadratic & \textbf{2.6B}& 100.0\%  & \textbf{1433.5} & \textbf{71.9} & \underline{87.6} & \textbf{70.7} & \textbf{33.7} & \textbf{44.3} & \textbf{66.0} & \textbf{94.8} & \underline{60.9} \\
    \rowcolor{green!15}
    \name{} & \textbf{DT} & \textbf{Linear} & \underline{2.7B}& \underline{14.7\%}  &1303.5 & 57.2 & 85.2 & 62.9& 30.7  & 31.1 &47.7 & 79.2 & 57.4 \\
    \rowcolor{yellow!15}
    \name{} & \textbf{DT} & \underline{Hybrid} & \underline{2.7B}& \textbf{11.2\%}  & \underline{1371.1} & \underline{63.7} & 86.7 & 66.3 & \underline{32.3} & 36.9 & 55.1 & 86.9 & 59.3  \\
    
    \bottomrule
    \end{tabular}
    }
    \vspace{-1em}
    \caption{\textbf{Comparison with existing VLMs on general VLM benchmarks.} ``Recipe'' denotes the adopted training recipe. ``PT'', ``SFT'', and ``DT'' denote the pre-training, supervised fine-tuning, and distillation training, respectively. ``Complexity'' denotes the model computation complexity with respect to the number of tokens. ``\# P.'' denotes the number of total parameters. ``\# T.P.'' denotes the percentage of trainable parameters ($\frac{\text{trainable paramters}}{\text{total parameters}}$). The best performance is highlighted in \textbf{bold} and the second-best result is \underline{underlined}.}
    \label{tab:results_general}
    \end{table*}
