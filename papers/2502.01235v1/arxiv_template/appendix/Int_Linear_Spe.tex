\subsection{Gradient Descent under Spectral Initialization}
\label{app:lrspec}
For notational simplicity, we denote $\widehat{\bm \Sigma} := \frac{1}{N}\widetilde{\bm X}^{\!\top}\widetilde{\bm X}$ in the following content. Recall the negative gradient of Full Fine-tuning at the first step in \cref{eq:G}, we write it here again
\begin{align}
\label{NGG}
  {\bm G}^{\natural} & = -\nabla_{\bm W} \widetilde{L}(\bm W^\natural) = \frac{1}{N}\widetilde{\bm X}^{\!\top}\widetilde{\bm Y}_{\Delta} = \widehat{\bm \Sigma}\Delta = \widetilde{\bm U}_{\bm G^\natural}\widetilde{\bm S}_{\bm G^\natural}\widetilde{\bm V}_{\bm G^\natural}^{\!\top}\,.
\end{align}
In this section, according to \cref{lem:conrg}, the following statement 
\begin{align}
\label{concentration-N}
    \left\|\widehat{\bm \Sigma} - \bm I_d\right\|_{op}=\epsilon \leq \min\left\{\frac{1}{2\kappa}\,,\frac{c}{\kappa^3}\right\} \leq \frac{1}{2} \,, \quad \mbox{for some small constant $c$}\,,
\end{align}
holds with probability at least $1- 2C\exp(-\epsilon^2 N)$ for a universal constant $C>0$. We propose the following initialization scheme \eqref{eq:spectral-init-linear}
\begin{align*}
    \bm A_0 = \left[\widetilde{\bm U}_{\bm G^\natural}\right]_{[:,1:r]}\left[\widetilde{\bm S}_{\bm G^\natural}^{1/2}\right]_{[1:r]}\,,\quad \bm B_0 = \left[\widetilde{\bm S}_{\bm G^\natural}^{1/2}\right]_{[1:r]}\left[\widetilde{\bm V}_{\bm G^\natural}\right]_{[:,1:r]}^{\!\top}\,.
\end{align*}
First, we have the following lemma.
\begin{lemma}
\label{linear-initial-risk}
Under assumptions in \cref{sec:assumptions} for the linear setting, with spectral initialization \eqref{eq:spectral-init-linear}, recall $\kappa := \lambda_1^*(\Delta) / \lambda_{r^*}^*(\Delta)$, then with probability at least with probability $1- 2C\exp(-\epsilon^2 N)$ for a universal constant $C>0$, we have
    \begin{align}
        \left\|\bm A_0 \bm B_0 - \Delta\right\|_{op} & \leq \epsilon \| \Delta \|_{op} \leq \frac{\lambda_{r^*}^*}{2} \label{spectral_linear_risk_initial}\,,
    \end{align}
    and
    \begin{align}
        \lambda_{r^*}\left(\bm A_0\right)\geq \frac{\sqrt{\lambda_{r^*}^*}}{2}\,,\quad \lambda_{r^*}\left(\bm B_0\right)\geq \frac{\sqrt{\lambda_{r^*}^*}}{2}\label{initial-smallest-singular-values-linear}\,.
    \end{align}
\end{lemma}
\begin{proof}
    Due to $\operatorname{rank}\left({\bm G}^{\natural}\right) = r^*$ and $r\geq r^*$, then $\bm A_0 \bm B_0 = {\bm G}^{\natural}$, so we have
    \begin{align*}
        \left\|\bm A_0 \bm B_0 - \Delta\right\|_{op} & \leq \left\|\bm A_0 \bm B_0 - {\bm G}^{\natural}\right\|_{op} + \left\|{\bm G}^{\natural} - \Delta\right\|_{op}\\
        & = \left\|{\bm G}^{\natural} - \Delta\right\|_{op}\\
        & = \left\|\left(\widehat{\bm \Sigma} - \bm I_d\right) \Delta\right\|_{op} \tag*{\color{teal}[using \cref{NGG}]} \\
        & \leq \left\|\widehat{\bm \Sigma} - \bm I_d\right\|_{op} 
        \left\|\Delta\right\|_{op}\,.
    \end{align*}
    Accordingly, by \cref{concentration-N}, with probability at least $1-2\exp(- c \epsilon^2 N )$, we have
    \begin{align*}
        \left\|\bm A_0 \bm B_0 - \Delta\right\|_{op} & \leq \epsilon \| \Delta \|_{op} \\
        & \leq \frac{1}{2\kappa}\left\|\Delta\right\|_{op} \tag*{\color{teal}[using \cref{concentration-N}]} \\
        & = \frac{\lambda_{r^*}^*}{2}\,.
    \end{align*}
    Then, using the above result and Weyl's inequality, we have the upper bound $\lambda_{r^*}\left(\bm A_0 \bm B_0\right) \leq \lambda_{1}\left(\bm A_0\right)\lambda_{r^*}\left(\bm B_0\right)$ and the lower bound
    \begin{align*}
        \lambda_{r^*}\left(\bm A_0 \bm B_0\right) = \lambda_{r^*}\left(\bm G^{\natural} \right) \geq \lambda_{r^*}\left(\Delta\right) - \left\|{\bm G}^{\natural}-\Delta\right\|_{op} = \lambda_{r^*}\left(\Delta\right) - \left\|\bm A_0 \bm B_0 -\Delta\right\|_{op} \geq \frac{\lambda_{r^*}^*}{2}\,.
    \end{align*}
    Now we are ready to give the lower bound of $\lambda_{r^*}\left(\bm B_0\right)$. 
    Because of $\bm A_0 \bm B_0 = \bm G^{\natural}$ under spectral initialization, we have 
    \begin{equation*}
        \lambda_{1}\left(\bm A_0\right) \leq \sqrt{\lambda_1({\bm G}^{\natural})}\leq \sqrt{\left\|\widehat{\bm \Sigma} - \bm I_d\right\|_{op}\lambda_1(\Delta)}\leq \sqrt{\epsilon \lambda_1(\Delta)}\,, \quad \mbox{with high probability at least}~1- 2C\exp(- \epsilon^2 N)\,.
    \end{equation*}
    where we use $\bm G^{\natural} = \widehat{\bm \Sigma}\Delta$ and the concentration results on $\widehat{\bm \Sigma}$. Then combining the above two inequalities, $\lambda_{r^*}\left(\bm B_0\right)$ is lower bounded by
    \begin{equation*}
        \lambda_{r^*}\left(\bm B_0\right) \geq \frac{\lambda_{r^*}\left(\bm A_0 \bm B_0\right)}{\lambda_{1}\left(\bm A_0\right)} \geq \frac{\lambda_{r^*}^*/2}{\lambda_{1}\left(\bm A_0\right)}\geq \frac{\sqrt{\lambda_{r^*}^*}}{2}\,,
    \end{equation*}
by taking $\epsilon \leq \frac{1}{2 \kappa}$.
The lower bound of $\lambda_{r^*}\left(\bm A_0\right)$ can be obtained similarly.
\end{proof}
The following lemma indicates $\bm B_t$'s GD dynamics stay in the low-dimensional target subspace under the spectral initialization.
\begin{lemma}
\label{linear-invariant-B2}
Under assumptions in \cref{sec:assumptions} for the linear setting, with spectral initialization \eqref{eq:spectral-init-linear}, during the iteration, for any $t\in\mathbb{N}^{+}$, we always have $\bm B_t \bm V_\perp = \bm 0_{d\times (d-r^*)}$, where $\bm V_\perp$ comes from the complete SVD of $\Delta$ in \cref{Delta-SVD}.
\end{lemma}
\begin{proof}
We prove it by induction.
First, recall the SVD of $\Delta$ in \cref{Delta-SVD}, we have
    \begin{align*}
        {\bm G}^{\natural} \bm V_\perp = \widetilde{\bm \Sigma}\Delta \bm V_\perp = \bm 0_{d\times (d-r^*)}\,,
    \end{align*}
    and
    \begin{align*}
        \bm B_0 \bm V_\perp & = \left[\widetilde{\bm S}_{\bm G^\natural}^{1/2}\right]_{[1:r]}\left[\widetilde{\bm V}_{\bm G^\natural}^{\!\top}\right]_{[:,1:r]}\bm V_\perp\\
        & = \left[\widetilde{\bm S}_{\bm G^\natural}^{-1/2}\right]_{[1:r]}\left[\widetilde{\bm U}_{\bm G^\natural}^{\!\top}\right]_{[:,1:r]}{\bm G}^{\natural} \bm V_\perp \\
        & = \left[\widetilde{\bm S}_{\bm G^\natural}^{-1/2}\right]_{[1:r]}\left[\widetilde{\bm U}_{\bm G^\natural}^{\!\top}\right]_{[:,1:r]}\widehat{\bm \Sigma}\Delta \bm V_\perp\\
        & = \bm 0_{d\times (d-r^*)}\,.
    \end{align*}
    Next, We prove by induction. Starting from $t = 1$, using the above two equations, we have
    \begin{align*}
        \bm B_1 \bm V_\perp 
        & = \bm B_0 \bm V_\perp -\frac{\eta_2}{N} \bm A^{\!\top}_0 \widetilde{\bm X}^{\!\top} \Bigl(\widetilde{\bm X} (\bm W^\natural+\bm A_0 \bm B_0) - \widetilde{\bm Y}\Bigr)\bm V_\perp\\
        & = \bm B_0 \bm V_\perp - \frac{\eta_2}{N} \bm A^{\!\top}_0 \widetilde{\bm X}^{\!\top} \widetilde{\bm X} \bm A_0 \bm B_0\bm V_\perp + \eta \bm A^{\!\top}_0 {\bm G}^{\natural} \bm V_\perp\\
        & = \bm 0_{d\times (d-r^*)}\,.
    \end{align*}
    Assume $\bm B_t {\bm V_\perp} = \bm 0_{d\times (d-r^*)}$ holds for any  $t= 2,3,\cdots$, then at $t+1$, we have
    \begin{align*}
         \bm B_{t+1} \bm V_\perp
        & = \bm B_t \bm V_\perp - \frac{\eta}{N} \bm A^{\!\top}_t \widetilde{\bm X}^{\!\top} \widetilde{\bm X} \bm A_t \bm B_t\bm V_\perp + \eta_2 \bm A^{\!\top}_t {\bm G}^{\natural} \bm V_\perp\\
        & = \bm 0_{d\times (d-r^*)}\,.
    \end{align*}
    Accordingly we finish the proof.
\end{proof}
Under spectral initialization, we have already demonstrated that $\bm A_0 \bm B_0$ is close to $\Delta$. In the following content, we aim to track how $\left\|\bm A_t \bm B_t - \Delta\right\|_{op}$ behaves (in a local sense), which is a critical ingredient to study both the loss and risk of LoRA training. In this regime, there is no significant difference on setting different step-size $\eta_1$ and $\eta_2$. For ease of description, we set $\eta_1=\eta_2 := \eta$.

Here we can characterize the operator norm of $\left(\bm A_t \bm B_t - \Delta\right)$ as
\begin{align}
    \left\|\bm A_t \bm B_t - \Delta\right\|_{op} & = \left\|\bigg(\bm A_t \bm B_t - \Delta\bigg)\begin{bmatrix}
        \bm V & \bm V_\perp
    \end{bmatrix}\right\|_{op} \quad \tag*{\color{teal}[by unitary invariance of operator norm]}\nonumber\\
    & = \left\|\bm A_t \bm B_t\bm V - \bm U\bm S^*\right\|_{op} \quad \tag*{\color{teal}[by \cref{linear-invariant-B2}]}\nonumber\\
    & = \left\|\bigg(\bm U \bm U^{\!\top}+\bm U_{\perp} \bm U^{\!\top}_\perp\bigg)\bigg(\bm A_t \bm B_t\bm V - \bm U\bm S^*\bigg)\right\|_{op}\nonumber\\
    & = \left\|\bm U \bigg(\bm U^{\!\top}\bm A_t \bm B_t\bm V - \bm S^*\bigg)\right\|_{op}+\left\|\bm U_{\perp} \bm U^{\!\top}_\perp\bm A_t \bm B_t\bm V\right\|_{op}\nonumber\\
    & \leq  \underbrace{\left\|\bm U^{\!\top}\bm A_t \bm B_t\bm V - \bm S^*\right\|_{op}}_{\mbox{signal space}}+ \underbrace{\left\|\bm U^{\!\top}_\perp\bm A_t \bm B_t\bm V\right\|_{op}}_{\mbox{complementary}}\,,\label{deco}
\end{align}
where the first term denotes the loss in the signal space $\left\|\bm U^{\!\top}\bm A \bm B\bm V - \bm S^*\right\|_{op}$ and the second term denotes the complementary space decay $\left\|\bm U^{\!\top}_\perp\bm A \bm B\bm V\right\|_{op}$. Next, we need a new parametrization to track the dynamics of these two terms. Recall the complete SVD of $\Delta$ in \cref{Delta-SVD} as
\begin{align*}
\Delta=\widetilde{\bm U} \widetilde{\bm S}^* \widetilde{\bm V}^{\!\top}=
    \begin{bmatrix}
        \bm U & \bm U_\perp
    \end{bmatrix}\begin{bmatrix}
       \bm S^* & \bm 0_{r^*\times (d-r^*)}\\
        \bm 0_{(d-r^*)\times r^*} & \bm 0_{(d-r^*)\times (d-r^*)}
    \end{bmatrix}\begin{bmatrix}
        \bm V^{\!\top} \\ \bm V_\perp^{\!\top}
    \end{bmatrix}\,.
\end{align*}
For notational simplicity, we denote 
\begin{align*}
    \bm A^{\bm U}_t:=\bm U^{\!\top}\bm A_t\,,\quad \bm A^{\bm U_\perp}_t:=\bm U_\perp^{\!\top}\bm A_t\,,\quad \bm B_t \bm V:=\bm B_t^{\bm V}\,,\quad \bm B_t \bm V_\perp:=\bm B_t^{\bm V_\perp}\,.
\end{align*}
and thus
\begin{align*}
    \bm R_t := (\bm A_t \bm B_t - \Delta) \bm V \,,\quad \bm R_t^*:=\bm A^{\bm U}_t\bm B_t^{\bm V}-\bm S^*\,,\quad \bm R_t^\perp := \bm A^{\bm U_\perp}_t\bm B_t^{\bm V}\,.
\end{align*}
Accordingly, \cref{deco} can be reformulated as $\left\|\bm R_t\right\|_{op}\leq \left\|\bm R_t^*\right\|_{op}+\left\|\bm R_t^\perp\right\|_{op}$. By \cref{linear-invariant-B2}, we have $\bm B^{\bm V_\perp}=\bm 0_{r\times(k-r^*)}$ for $\forall\,t \in \mathbb{N}^+$.
Next, we can track $\bm R^*_t$ and $\bm R^\perp_t$ via the following two lemmas.
\begin{lemma}
    \label{A^U_t-B_t^V}
Under assumptions in \cref{sec:assumptions} for the linear setting, with spectral initialization \eqref{eq:spectral-init-linear}, we have the following reparametrized iterates
    \begin{align}
        \bm A^{\bm U}_{t+1} & = \bm A^{\bm U}_t - \eta \bm R^*_t \left(\bm B_t^{\bm V}\right)^{\!\top} - \eta \bm U^{\!\top}\left(\widehat{\bm \Sigma}
        - \bm I_d\right) \bm R_t \left(\bm B_t^{\bm V}\right)^{\!\top}\,,\label{AtU}\\
        \bm A^{\bm U_\perp}_{t+1} & = \bm A^{\bm U_\perp}_t - \eta \bm R^\perp_t \left(\bm B_t^{\bm V}\right)^{\!\top} - \eta \bm U^{\!\top}_\perp\left(\widehat{\bm \Sigma}
        - \bm I_d\right) \bm R_t \left(\bm B_t^{\bm V}\right)^{\!\top}\,,\label{AUperp}\\
        \bm B_{t+1}^{\bm V} & = \bm B_t^{\bm V} - \eta \left(\bm A^{\bm U}_t\right)^{\!\top}\bm R^*_t - \eta \left(\bm A^{\bm U_\perp}_t\right)^{\!\top}\bm R^\perp_t\nonumber\\
        & - \eta \left(\bm A_t^{\bm U}\right)^{\!\top}\bm U^{\!\top}\left(\widehat{\bm \Sigma}-\bm I_d\right)\bm R_t  - \eta \left(\bm A_t^{\bm U_\perp}\right)^{\!\top}\bm U_\perp^{\!\top}\left(\widehat{\bm \Sigma}-\bm I_d\right)\bm R_t\label{BVt}\,.
    \end{align}
\end{lemma}
\begin{proof}
    Recall the gradient update for $\bm A_{t+1}$, we have
    \begin{align*}
        \bm A_{t+1} & = \bm A_t - \eta \widehat{\bm \Sigma}\left(\bm A_t \bm B_t - \Delta\right)\left(\bm B_t\right)^{\!\top}\\
        & = \bm A_t - \eta \left(\bm A_t \bm B_t - \Delta\right)\left(\bm B_t\right)^{\!\top} - \eta \left(\widehat{\bm \Sigma}-\bm I_d\right)\left(\bm A_t \bm B_t - \Delta\right)\left(\bm B_t\right)^{\!\top}\,.
    \end{align*}
   Recall $\bm R_t := (\bm A_t \bm B_t - \Delta)\bm V$ and $\Delta = \bm U \bm S^* \bm V^{\!\top}$, we have
    \begin{align*}
        \bm U^{\!\top}\bm A_{t+1} & = \bm U^{\!\top}\bm A_t - \eta \bm U^{\!\top}\left(\bm A_t \bm B_t - \Delta\right)\left(\bm V\bm V^{\!\top}+\bm V_\perp \bm V_\perp^{\!\top}\right)\left(\bm B_t\right)^{\!\top}\\
        &- \eta \bm U^{\!\top}\left(\widehat{\bm \Sigma}-\bm I_d\right)\left(\bm A_t \bm B_t - \Delta\right)\left(\bm V\bm V^{\!\top}+\bm V_\perp \bm V_\perp^{\!\top}\right)\left(\bm B_t\right)^{\!\top}\\
        & = \bm U^{\!\top}\bm A_t - \eta \bm U^{\!\top}\left(\bm A_t \bm B_t\bm V - \Delta\bm V\right)\left(\bm B_t\bm V\right)^{\!\top} - \eta \bm U^{\!\top}\left(\widehat{\bm \Sigma}
        - \bm I_d\right)\left(\bm A_t \bm B_t\bm V - \Delta\bm V\right)\left(\bm B_t\bm V\right)^{\!\top}\quad \tag*{\color{teal}[by \cref{linear-invariant-B2}]}\\
        & = \bm U^{\!\top}\bm A_t - \eta \left(\bm U^{\!\top}\bm A_t \bm B_t\bm V - \bm S^*\right)\left(\bm B_t\bm V\right)^{\!\top}
         - \eta \bm U^{\!\top}\left(\widehat{\bm \Sigma}
        - \bm I_d\right)\bm R_t \left(\bm B_t\bm V\right)^{\!\top}\,.
    \end{align*} 
   Accordingly, the recursion for $\bm A^{\bm U}_{t+1}$ is reformulated as
    \begin{align*}
        \bm A^{\bm U}_{t+1} & = \bm A^{\bm U}_t - \eta \bm R^*_t \left(\bm B_t^{\bm V}\right)^{\!\top} - \eta \bm U^{\!\top}\left(\widehat{\bm \Sigma}
        - \bm I_d\right) \bm R_t \left(\bm B_t^{\bm V}\right)^{\!\top}\,.
    \end{align*}
    Similarly, we can obtain
    \begin{align*}
        \bm A^{\bm U_\perp}_{t+1} & = \bm A^{\bm U_\perp}_t - \eta \bm R^\perp_t \left(\bm B_t^{\bm V}\right)^{\!\top} - \eta \bm U^{\!\top}_\perp\left(\widehat{\bm \Sigma}
        - \bm I_d\right) \bm R_t \left(\bm B_t^{\bm V}\right)^{\!\top}\,.
    \end{align*}
    Regarding the recursion for $ \bm B_{t+1}$, we can derive in a similar way
    \begin{align*}
        \bm B_{t+1}\bm V & = \bm B_t\bm V - \eta \left(\bm A_t\right)^{\!\top}\widehat{\bm \Sigma}\left(\bm A_t \bm B_t - \Delta\right)\bm V\\
        & = \bm B_t\bm V - \eta \left(\bm A_t\right)^{\!\top}\left(\bm U \bm U^{\!\top}+\bm U_\perp \bm U_\perp^{\!\top}\right)\left(\bm A_t \bm B_t - \Delta\right)\bm V\\
        & - \eta \left(\bm A_t\right)^{\!\top}\left(\bm U \bm U^{\!\top}+\bm U_\perp \bm U_\perp^{\!\top}\right)\left(\widehat{\bm \Sigma}-\bm I_d\right)\left(\bm A_t \bm B_t - \Delta\right)\bm V\,,
    \end{align*}
    which implies
    \begin{align*}
        \bm B_{t+1}^{\bm V} & = \bm B_t^{\bm V} - \eta \left(\bm A^{\bm U}_t\right)^{\!\top}\bm R^*_t - \eta \left(\bm A^{\bm U_\perp}_t\right)^{\!\top}\bm R^\perp_t  - \eta \left(\bm A_t^{\bm U}\right)^{\!\top}\bm U^{\!\top}\left(\widehat{\bm \Sigma}-\bm I_d\right)\bm R_t  - \eta \left(\bm A_t^{\bm U_\perp}\right)^{\!\top}\bm U_\perp^{\!\top}\left(\widehat{\bm \Sigma}-\bm I_d\right)\bm R_t\,.
    \end{align*}
\end{proof}
In the next, we are able to characterize the upper bound of $  \left\|\bm R^*_{t+1}\right\|_{op}$.
\begin{lemma}
\label{mathcalMt}
    Denote $\mathcal{M}_t:=\max \left\{\left\|\bm R^*_{t}\right\|_{op}\,,\left\|\bm R^\perp_{t}\right\|_{op}\right\}$, 
under assumptions in \cref{sec:assumptions} for the linear setting, with spectral initialization \eqref{eq:spectral-init-linear}, then we choose $\epsilon$ with probability at least $1- 2C\exp(-\epsilon^2 N)$ for a universal constant $C>0$, we have 
    \begin{align*}
        \left\|\bm R^*_{t+1}\right\|_{op} & \leq \bigg(1-\eta\left(\lambda_{r^*}^2\left(\bm A_t^{\bm U}\right)+\lambda_{r^*}^2\left(\bm B_t^{\bm V}\right)\right)\bigg)\mathcal{M}_t\\
        & + 2\eta \epsilon \left\|\bm B^{\bm V}_{t}\right\|_{op}^2 \mathcal{M}_t + \eta^2 \left\|\bm A^{\bm U}_{t}\right\|_{op}\left\|\bm B^{\bm V}_{t}\right\|_{op}\mathcal{M}_t^2 + 2\eta^2 \epsilon \left\|\bm A^{\bm U}_{t}\right\|_{op}\left\|\bm B^{\bm V}_{t}\right\|_{op}\mathcal{M}_t^2\\
        & + \eta \left\|\bm A^{\bm U}_{t}\right\|_{op}\left\|\bm A^{\bm U_\perp}_{t}\right\|_{op}\mathcal{M}_t+\eta^2 \left\|\bm B^{\bm V}_{t}\right\|_{op}\left\|\bm A^{\bm U_\perp}_{t}\right\|_{op}\mathcal{M}_t^2\\
        & +2\eta^2 \epsilon \left\|\bm B^{\bm V}_{t}\right\|_{op}\left\|\bm A^{\bm U_\perp}_{t}\right\|_{op}\mathcal{M}_t^2+2\eta \epsilon \left\|\bm A^{\bm U}_{t}\right\|_{op}^2 \mathcal{M}_t\\
        & + 2 \eta^2 \epsilon \left\|\bm A^{\bm U}_{t}\right\|_{op}\left\|\bm B^{\bm V}_{t}\right\|_{op} \mathcal{M}_t + 4 \eta^2 \epsilon^2 \left\|\bm A^{\bm U}_{t}\right\|_{op}\left\|\bm B^{\bm V}_{t}\right\|_{op} \mathcal{M}_t^2\\
        & + 2 \eta \epsilon \left\|\bm A^{\bm U}_{t}\right\|_{op}\left\|\bm A^{\bm U_\perp}_{t}\right\|_{op}\mathcal{M}_t+2\eta^2 \epsilon \left\|\bm A^{\bm U_\perp}_{t}\right\|_{op}\left\|\bm B^{\bm V}_{t}\right\|_{op}\mathcal{M}_t^2\\
        & + 4 \eta^2 \epsilon^2 \left\|\bm A^{\bm U_\perp}_{t}\right\|_{op}\left\|\bm B^{\bm V}_{t}\right\|_{op} \mathcal{M}_t^2\,,
    \end{align*}
    and
    \begin{align}
        \left\|\bm R^\perp_{t+1}\right\|_{op} & \leq \bigg(1-\eta\left(\lambda_{\min}^2\left(\bm A_t^{\bm U_\perp}\right)+\lambda_{r^*}^2\left(\bm B_t^{\bm V}\right)\right)\bigg)\mathcal{M}_t\label{drop}\\
        & + 2 \eta \epsilon \left\|\bm B^{\bm V}_{t}\right\|_{op}^2 \mathcal{M}_t + \eta^2 \left\|\bm A^{\bm U}_{t}\right\|_{op}\left\|\bm B^{\bm V}_{t}\right\|_{op}\mathcal{M}_t^2 + 2\eta^2 \epsilon \left\|\bm A^{\bm U}_{t}\right\|_{op}\left\|\bm B^{\bm V}_{t}\right\|_{op}\mathcal{M}_t^2\nonumber\\
        & + \eta \left\|\bm A^{\bm U}_{t}\right\|_{op}\left\|\bm A^{\bm U_\perp}_{t}\right\|_{op}\mathcal{M}_t+\eta^2 \left\|\bm B^{\bm V}_{t}\right\|_{op}\left\|\bm A^{\bm U_\perp}_{t}\right\|_{op}\mathcal{M}_t^2\nonumber\\
        & +2\eta^2 \epsilon \left\|\bm B^{\bm V}_{t}\right\|_{op}\left\|\bm A^{\bm U_\perp}_{t}\right\|_{op}\mathcal{M}_t^2+2\eta \epsilon \left\|\bm A^{\bm U}_{t}\right\|_{op}\left\|\bm A^{\bm U_\perp}_{t}\right\|_{op} \mathcal{M}_t\nonumber\\
        & + 2 \eta^2 \epsilon \left\|\bm A^{\bm U}_{t}\right\|_{op}\left\|\bm B^{\bm V}_{t}\right\|_{op} \mathcal{M}_t + 4 \eta^2 \epsilon^2 \left\|\bm A^{\bm U}_{t}\right\|_{op}\left\|\bm B^{\bm V}_{t}\right\|_{op} \mathcal{M}_t^2\nonumber\\
        & + 2 \eta \epsilon \left\|\bm A^{\bm U_\perp}_{t}\right\|_{op}^2\mathcal{M}_t+2\eta^2 \epsilon \left\|\bm A^{\bm U_\perp}_{t}\right\|_{op}\left\|\bm B^{\bm V}_{t}\right\|_{op}\mathcal{M}_t^2\nonumber\\
        & + 4 \eta^2 \epsilon^2 \left\|\bm A^{\bm U_\perp}_{t}\right\|_{op}\left\|\bm B^{\bm V}_{t}\right\|_{op} \mathcal{M}_t^2\,.\nonumber
    \end{align}
\end{lemma}
\begin{proof}
    Here we first track the dynamics of $\bm R^*_t$. We have
    \begin{align*}
        \bm R^*_{t+1} & = \bm A^{\bm U}_{t+1}\bm B_{t+1}^{\bm V} - \bm S^*\\
        & = \bm R^*_t
        - \eta \bm R^*_t \left(\bm B_t^{\bm V}\right)^{\!\top}\bm B_{t}^{\bm V}
        - \eta \bm U^{\!\top}\left(\widehat{\bm \Sigma}
        - \bm I_d\right) \bm R_t \left(\bm B_t^{\bm V}\right)^{\!\top}\bm B_{t}^{\bm V}\\
        & -\eta \bm A^{\bm U}_t\left(\bm A^{\bm U}_t\right)^{\!\top}\bm R^*_t
        + \eta^2 \bm R^*_t \left(\bm B_t^{\bm V}\right)^{\!\top}\left(\bm A^{\bm U}_t\right)^{\!\top}\bm R^*_t
        + \eta^2 \bm U^{\!\top}\left(\widehat{\bm \Sigma}
        - \bm I_d\right) \bm R_t \left(\bm B_t^{\bm V}\right)^{\!\top}\left(\bm A^{\bm U}_t\right)^{\!\top}\bm R^*_t\\
        & - \eta \bm A^{\bm U}_t \left(\bm A^{\bm U_\perp}_t\right)^{\!\top}\bm R^\perp_t
        + \eta^2 \bm R^*_t \left(\bm B_t^{\bm V}\right)^{\!\top}\left(\bm A^{\bm U_\perp}_t\right)^{\!\top}\bm R^\perp_t
        + \eta^2 \bm U^{\!\top}\left(\widehat{\bm \Sigma}
        - \bm I_d\right) \bm R_t \left(\bm B_t^{\bm V}\right)^{\!\top}\left(\bm A^{\bm U_\perp}_t\right)^{\!\top}\bm R^\perp_t\\
        & ------ \\
        & - \eta \bm A^{\bm U}_t \left(\bm A_t^{\bm U}\right)^{\!\top}\bm U^{\!\top}\left(\widehat{\bm \Sigma}-\bm I_d\right)\bm R_t\\
        & + \eta^2 \bm R^*_t \left(\bm B_t^{\bm V}\right)^{\!\top}\left(\bm A_t^{\bm U}\right)^{\!\top}\bm U^{\!\top}\left(\widehat{\bm \Sigma}-\bm I_d\right)\bm R_t\\
        & + \eta^2 \bm U^{\!\top}\left(\widehat{\bm \Sigma}
        - \bm I_d\right) \bm R_t \left(\bm B_t^{\bm V}\right)^{\!\top}\left(\bm A_t^{\bm U}\right)^{\!\top}\bm U^{\!\top}\left(\widehat{\bm \Sigma}-\bm I_d\right)\bm R_t\\
        & ------ \\
        & - \eta \bm A^{\bm U}_t \left(\bm A_t^{\bm U_\perp}\right)^{\!\top}\bm U_\perp^{\!\top}\left(\widehat{\bm \Sigma}-\bm I_d\right)\bm R_t \\
        & + \eta^2 \bm R^*_t \left(\bm B_t^{\bm V}\right)^{\!\top}\left(\bm A_t^{\bm U_\perp}\right)^{\!\top}\bm U_\perp^{\!\top}\left(\widehat{\bm \Sigma}-\bm I_d\right)\bm R_t\\
        & + \eta^2 \bm U^{\!\top}\left(\widehat{\bm \Sigma}
        - \bm I_d\right) \bm R_t \left(\bm B_t^{\bm V}\right)^{\!\top}\left(\bm A_t^{\bm U_\perp}\right)^{\!\top}\bm U_\perp^{\!\top}\left(\widehat{\bm \Sigma}-\bm I_d\right)\bm R_t\,.
    \end{align*}
    Then, we take operator norm over the above equation. Hence, with probability at least $1- 2C\exp(-\epsilon^2 N)$ for a universal constant $C>0$, we have
    \begin{align*}
        \left\|\bm R^*_{t+1}\right\|_{op} & \leq \bigg(1-\eta\left(\lambda_{r^*}^2\left(\bm A_t^{\bm U}\right)+\lambda_{r^*}^2\left(\bm B_t^{\bm V}\right)\right)\bigg)\left\|\bm R^*_{t}\right\|_{op}\\
        & + \eta \epsilon \left\|\bm B^{\bm V}_{t}\right\|_{op}^2 \left\|\bm R_{t}\right\|_{op} + \eta^2 \left\|\bm A^{\bm U}_{t}\right\|_{op}\left\|\bm B^{\bm V}_{t}\right\|_{op}\left\|\bm R^*_{t}\right\|_{op}^2 + \eta^2 \epsilon \left\|\bm A^{\bm U}_{t}\right\|_{op}\left\|\bm B^{\bm V}_{t}\right\|_{op}\left\|\bm R^*_{t}\right\|_{op}\left\|\bm R_{t}\right\|_{op}\\
        & + \eta \left\|\bm A^{\bm U}_{t}\right\|_{op}\left\|\bm A^{\bm U_\perp}_{t}\right\|_{op}\left\|\bm R^\perp_{t}\right\|_{op}+\eta^2 \left\|\bm B^{\bm V}_{t}\right\|_{op}\left\|\bm A^{\bm U_\perp}_{t}\right\|_{op}\left\|\bm R^\perp_{t}\right\|_{op}\left\|\bm R^*{t}\right\|_{op}\\
        & +\eta^2 \epsilon \left\|\bm B^{\bm V}_{t}\right\|_{op}\left\|\bm A^{\bm U_\perp}_{t}\right\|_{op}\left\|\bm R^\perp_{t}\right\|_{op}\left\|\bm R_{t}\right\|_{op}+\eta \epsilon \left\|\bm A^{\bm U}_{t}\right\|_{op}^2 \left\|\bm R_{t}\right\|_{op}\\
        & + \eta^2 \epsilon \left\|\bm A^{\bm U}_{t}\right\|_{op}\left\|\bm B^{\bm V}_{t}\right\|_{op} \left\|\bm R_{t}\right\|_{op} + \eta^2 \epsilon^2 \left\|\bm A^{\bm U}_{t}\right\|_{op}\left\|\bm B^{\bm V}_{t}\right\|_{op} \left\|\bm R_{t}\right\|_{op}^2\\
        & + \eta \epsilon \left\|\bm A^{\bm U}_{t}\right\|_{op}\left\|\bm A^{\bm U_\perp}_{t}\right\|_{op}\left\|\bm R_{t}\right\|_{op}+\eta^2 \epsilon \left\|\bm A^{\bm U_\perp}_{t}\right\|_{op}\left\|\bm B^{\bm V}_{t}\right\|_{op}\left\|\bm R^*_{t}\right\|_{op}\left\|\bm R_{t}\right\|_{op}\\
        & + \eta^2 \epsilon^2 \left\|\bm A^{\bm U_\perp}_{t}\right\|_{op}\left\|\bm B^{\bm V}_{t}\right\|_{op} \left\|\bm R_{t}\right\|_{op}^2\,.
    \end{align*}
    Next, we take maximum over $\left\|\bm R^*_{t}\right\|_{op}$  and $\left\|\bm R^\perp_{t}\right\|_{op}$ on the right hand side above. Recall $\mathcal{M}_t=\max \left\{\left\|\bm R^*_{t}\right\|_{op}\,,\left\|\bm R^\perp_{t}\right\|_{op}\right\}$, using the fact that $\left\|\bm R_{t}\right\|_{op}\leq 2 \mathcal{M}_t$, we have:
    \begin{align*}
        \left\|\bm R^*_{t+1}\right\|_{op} & \leq \bigg(1-\eta\left(\lambda_{r^*}^2\left(\bm A_t^{\bm U}\right)+\lambda_{r^*}^2\left(\bm B_t^{\bm V}\right)\right)\bigg)\mathcal{M}_t\\
        & + 2\eta \epsilon \left\|\bm B^{\bm V}_{t}\right\|_{op}^2 \mathcal{M}_t + \eta^2 \left\|\bm A^{\bm U}_{t}\right\|_{op}\left\|\bm B^{\bm V}_{t}\right\|_{op}\mathcal{M}_t^2 + 2\eta^2 \epsilon \left\|\bm A^{\bm U}_{t}\right\|_{op}\left\|\bm B^{\bm V}_{t}\right\|_{op}\mathcal{M}_t^2\\
        & + \eta \left\|\bm A^{\bm U}_{t}\right\|_{op}\left\|\bm A^{\bm U_\perp}_{t}\right\|_{op}\mathcal{M}_t+\eta^2 \left\|\bm B^{\bm V}_{t}\right\|_{op}\left\|\bm A^{\bm U_\perp}_{t}\right\|_{op}\mathcal{M}_t^2\\
        & +2\eta^2 \epsilon \left\|\bm B^{\bm V}_{t}\right\|_{op}\left\|\bm A^{\bm U_\perp}_{t}\right\|_{op}\mathcal{M}_t^2+2\eta \epsilon \left\|\bm A^{\bm U}_{t}\right\|_{op}^2 \mathcal{M}_t\\
        & + 2 \eta^2 \epsilon \left\|\bm A^{\bm U}_{t}\right\|_{op}\left\|\bm B^{\bm V}_{t}\right\|_{op} \mathcal{M}_t + 4 \eta^2 \epsilon^2 \left\|\bm A^{\bm U}_{t}\right\|_{op}\left\|\bm B^{\bm V}_{t}\right\|_{op} \mathcal{M}_t^2\\
        & + 2 \eta \epsilon \left\|\bm A^{\bm U}_{t}\right\|_{op}\left\|\bm A^{\bm U_\perp}_{t}\right\|_{op}\mathcal{M}_t+2\eta^2 \epsilon \left\|\bm A^{\bm U_\perp}_{t}\right\|_{op}\left\|\bm B^{\bm V}_{t}\right\|_{op}\mathcal{M}_t^2\\
        & + 4 \eta^2 \epsilon^2 \left\|\bm A^{\bm U_\perp}_{t}\right\|_{op}\left\|\bm B^{\bm V}_{t}\right\|_{op} \mathcal{M}_t^2\,.
    \end{align*}
    Next, we track the dynamics of $\bm R^\perp_t$. We have
    \begin{align*}
        \bm R^\perp_{t+1} & = \bm A^{\bm U_\perp}_{t+1}\bm B_{t+1}^{\bm V}\\
        & = \bm R^\perp_t
        - \eta \bm R^\perp_t \left(\bm B_t^{\bm V}\right)^{\!\top}\bm B_{t}^{\bm V}
        - \eta \bm U_\perp^{\!\top}\left(\widehat{\bm \Sigma}
        - \bm I_d\right) \bm R_t \left(\bm B_t^{\bm V}\right)^{\!\top}\bm B_{t}^{\bm V}\\
        & -\eta \bm A^{\bm U_\perp}_t\left(\bm A^{\bm U}_t\right)^{\!\top}\bm R^*_t
        + \eta^2 \bm R^\perp_t \left(\bm B_t^{\bm V}\right)^{\!\top}\left(\bm A^{\bm U}_t\right)^{\!\top}\bm R^*_t
        + \eta^2 \bm U_\perp^{\!\top}\left(\widehat{\bm \Sigma}
        - \bm I_d\right) \bm R_t \left(\bm B_t^{\bm V}\right)^{\!\top}\left(\bm A^{\bm U}_t\right)^{\!\top}\bm R^*_t\\
        & - \eta \bm A^{\bm U_\perp}_t \left(\bm A^{\bm U_\perp}_t\right)^{\!\top}\bm R^\perp_t
        + \eta^2 \bm R^\perp_t \left(\bm B_t^{\bm V}\right)^{\!\top}\left(\bm A^{\bm U_\perp}_t\right)^{\!\top}\bm R^\perp_t
        + \eta^2 \bm U_\perp^{\!\top}\left(\widehat{\bm \Sigma}
        - \bm I_d\right) \bm R_t \left(\bm B_t^{\bm V}\right)^{\!\top}\left(\bm A^{\bm U_\perp}_t\right)^{\!\top}\bm R^\perp_t\\
        & - \eta \bm A^{\bm U_\perp}_t \left(\bm A_t^{\bm U}\right)^{\!\top}\bm U^{\!\top}\left(\widehat{\bm \Sigma}-\bm I_d\right)\bm R_t\\
        & + \eta^2 \bm R^\perp_t \left(\bm B_t^{\bm V}\right)^{\!\top}\left(\bm A_t^{\bm U}\right)^{\!\top}\bm U^{\!\top}\left(\widehat{\bm \Sigma}-\bm I_d\right)\bm R_t\\
        & + \eta^2 \bm U_\perp^{\!\top}\left(\widehat{\bm \Sigma}
        - \bm I_d\right) \bm R_t \left(\bm B_t^{\bm V}\right)^{\!\top}\left(\bm A_t^{\bm U}\right)^{\!\top}\bm U^{\!\top}\left(\widehat{\bm \Sigma}-\bm I_d\right)\bm R_t\\
        & - \eta \bm A^{\bm U_\perp}_t \left(\bm A_t^{\bm U_\perp}\right)^{\!\top}\bm U_\perp^{\!\top}\left(\widehat{\bm \Sigma}-\bm I_d\right)\bm R_t \\
        & + \eta^2 \bm R^\perp_t \left(\bm B_t^{\bm V}\right)^{\!\top}\left(\bm A_t^{\bm U_\perp}\right)^{\!\top}\bm U_\perp^{\!\top}\left(\widehat{\bm \Sigma}-\bm I_d\right)\bm R_t\\
        & + \eta^2 \bm U_\perp^{\!\top}\left(\widehat{\bm \Sigma}
        - \bm I_d\right) \bm R_t \left(\bm B_t^{\bm V}\right)^{\!\top}\left(\bm A_t^{\bm U_\perp}\right)^{\!\top}\bm U_\perp^{\!\top}\left(\widehat{\bm \Sigma}-\bm I_d\right)\bm R_t\,.
    \end{align*}
    Then, we take operator norm over the above equation. With probability at least $1- 2C\exp(-\epsilon^2 N)$ for a universal constant $C>0$, we have
    \begin{align*}
        \left\|\bm R^\perp_{t+1}\right\|_{op} & \leq \bigg(1-\eta\left(\lambda_{\min}^2\left(\bm A_t^{\bm U_\perp}\right)+\lambda_{r^*}^2\left(\bm B_t^{\bm V}\right)\right)\bigg)\left\|\bm R^\perp_{t}\right\|_{op}\\
        & + \eta \epsilon \left\|\bm B^{\bm V}_{t}\right\|_{op}^2 \left\|\bm R_{t}\right\|_{op} + \eta^2 \left\|\bm A^{\bm U}_{t}\right\|_{op}\left\|\bm B^{\bm V}_{t}\right\|_{op}\left\|\bm R^*_{t}\right\|_{op}\left\|\bm R^\perp_{t}\right\|_{op} + \eta^2 \epsilon \left\|\bm A^{\bm U}_{t}\right\|_{op}\left\|\bm B^{\bm V}_{t}\right\|_{op}\left\|\bm R^*_{t}\right\|_{op}\left\|\bm R_{t}\right\|_{op}\\
        & + \eta \left\|\bm A^{\bm U}_{t}\right\|_{op}\left\|\bm A^{\bm U_\perp}_{t}\right\|_{op}\left\|\bm R^*_{t}\right\|_{op}+\eta^2 \left\|\bm B^{\bm V}_{t}\right\|_{op}\left\|\bm A^{\bm U_\perp}_{t}\right\|_{op}\left\|\bm R^\perp_{t}\right\|_{op}^2\\
        & +\eta^2 \epsilon \left\|\bm B^{\bm V}_{t}\right\|_{op}\left\|\bm A^{\bm U_\perp}_{t}\right\|_{op}\left\|\bm R^\perp_{t}\right\|_{op}\left\|\bm R_{t}\right\|_{op}+\eta \epsilon \left\|\bm A^{\bm U}_{t}\right\|_{op}\left\|\bm A^{\bm U_\perp}_{t}\right\|_{op} \left\|\bm R_{t}\right\|_{op}\\
        & + \eta^2 \epsilon \left\|\bm A^{\bm U}_{t}\right\|_{op}\left\|\bm B^{\bm V}_{t}\right\|_{op} \left\|\bm R_{t}\right\|_{op} + \eta^2 \epsilon^2 \left\|\bm A^{\bm U}_{t}\right\|_{op}\left\|\bm B^{\bm V}_{t}\right\|_{op} \left\|\bm R_{t}\right\|_{op}^2\\
        & + \eta \epsilon \left\|\bm A^{\bm U_\perp}_{t}\right\|_{op}^2\left\|\bm R_{t}\right\|_{op}+\eta^2 \epsilon \left\|\bm A^{\bm U_\perp}_{t}\right\|_{op}\left\|\bm B^{\bm V}_{t}\right\|_{op}\left\|\bm R^\perp_{t}\right\|_{op}\left\|\bm R_{t}\right\|_{op}\\
        & + \eta^2 \epsilon^2 \left\|\bm A^{\bm U_\perp}_{t}\right\|_{op}\left\|\bm B^{\bm V}_{t}\right\|_{op} \left\|\bm R_{t}\right\|_{op}^2\,.
    \end{align*}
    Next, we take maximum over $\left\|\bm R^*_{t}\right\|_{op}$  and $\left\|\bm R^\perp_{t}\right\|_{op}$ on the right hand side above. Recall $\mathcal{M}_t=\max \left\{\left\|\bm R^*_{t}\right\|_{op}\,,\left\|\bm R^\perp_{t}\right\|_{op}\right\}$, using the fact that $\left\|\bm R_{t}\right\|_{op}\leq 2 \mathcal{M}_t$, we have:
    \begin{align*}
        \left\|\bm R^\perp_{t+1}\right\|_{op} & \leq \bigg(1-\eta\left(\lambda_{\min}^2\left(\bm A_t^{\bm U_\perp}\right)+\lambda_{r^*}^2\left(\bm B_t^{\bm V}\right)\right)\bigg)\mathcal{M}_t\\
        & + 2 \eta \epsilon \left\|\bm B^{\bm V}_{t}\right\|_{op}^2 \mathcal{M}_t + \eta^2 \left\|\bm A^{\bm U}_{t}\right\|_{op}\left\|\bm B^{\bm V}_{t}\right\|_{op}\mathcal{M}_t^2 + 2\eta^2 \epsilon \left\|\bm A^{\bm U}_{t}\right\|_{op}\left\|\bm B^{\bm V}_{t}\right\|_{op}\mathcal{M}_t^2\\
        & + \eta \left\|\bm A^{\bm U}_{t}\right\|_{op}\left\|\bm A^{\bm U_\perp}_{t}\right\|_{op}\mathcal{M}_t+\eta^2 \left\|\bm B^{\bm V}_{t}\right\|_{op}\left\|\bm A^{\bm U_\perp}_{t}\right\|_{op}\mathcal{M}_t^2\\
        & +2\eta^2 \epsilon \left\|\bm B^{\bm V}_{t}\right\|_{op}\left\|\bm A^{\bm U_\perp}_{t}\right\|_{op}\mathcal{M}_t^2+2\eta \epsilon \left\|\bm A^{\bm U}_{t}\right\|_{op}\left\|\bm A^{\bm U_\perp}_{t}\right\|_{op} \mathcal{M}_t\\
        & + 2 \eta^2 \epsilon \left\|\bm A^{\bm U}_{t}\right\|_{op}\left\|\bm B^{\bm V}_{t}\right\|_{op} \mathcal{M}_t + 4 \eta^2 \epsilon^2 \left\|\bm A^{\bm U}_{t}\right\|_{op}\left\|\bm B^{\bm V}_{t}\right\|_{op} \mathcal{M}_t^2\\
        & + 2 \eta \epsilon \left\|\bm A^{\bm U_\perp}_{t}\right\|_{op}^2\mathcal{M}_t+2\eta^2 \epsilon \left\|\bm A^{\bm U_\perp}_{t}\right\|_{op}\left\|\bm B^{\bm V}_{t}\right\|_{op}\mathcal{M}_t^2\\
        & + 4 \eta^2 \epsilon^2 \left\|\bm A^{\bm U_\perp}_{t}\right\|_{op}\left\|\bm B^{\bm V}_{t}\right\|_{op} \mathcal{M}_t^2\,.
    \end{align*}
    Finally we conclude the proof.
\end{proof}
Before we move to the main proof, we need to establish a strict upper bound on $\bm A_t$ and $\bm B_t$.
\begin{lemma}
\label{mahdi-upper}
    Under assumptions in \cref{sec:assumptions} for the linear setting, suppose $\left\|\bm A_t^{\!\top}\bm A_t - \bm B_t^{\!\top}\bm B_t\right\|_{op} + \epsilon \left\|\bm R_t\right\|_{op} \leq \lambda_1^*$ and $\eta\leq \frac{1}{10\lambda_1^*}$, if $\left\|\bm A_{t}\right\|_{op}\leq 2\sqrt{\lambda_1^*}$ and $\left\|\bm B_{t}\right\|_{op}\leq 2\sqrt{\lambda_1^*}$, we choose $\epsilon$ satisfying \cref{concentration-N}, then with probability $1- 2C\exp(-\epsilon^2 N)$ for a universal constant $C>0$, we have
    \begin{align*}
        \left\|\bm A_{t+1}\right\|_{op}\leq 2\sqrt{\lambda_1^*}\,,\quad\left\|\bm B_{t+1}\right\|_{op}\leq 2\sqrt{\lambda_1^*}\,.
    \end{align*}
\end{lemma}
\begin{proof}
    Inspired by \cite{soltanolkotabi2023implicit}, we recall the stacked iterate $\bm Z_t$ defined in \cref{stack-Z} and construct an anti-iterate
    \begin{align*}
        \underline{\bm Z}_t:=\begin{bmatrix}
            \bm A_t \\ -\bm B_t^{\!\top}
        \end{bmatrix}\,.
    \end{align*}
Additionally, we define a perturbation matrix
    \begin{align*}
        \bm \Xi_t & := \begin{bmatrix}
            \bm 0_{d\times d} & \left(\widetilde{\bm \Sigma}-\bm I_d\right)\bm R_t \\
            \bm R_t^{\!\top}\left(\widetilde{\bm \Sigma}-\bm I_d\right) & \bm 0_{k\times k}
        \end{bmatrix}\,.
    \end{align*}
    Then, we can reformulate the recursion of $\bm Z_{t+1}$ as
    \begin{align*}
        \bm Z_{t+1} & = \bm Z_t - \eta \left(\bm Z_t\bm Z_t^{\!\top}-\underline{\bm Z}_t\underline{\bm Z}_t^{\!\top}-\bm \Gamma\right)\bm Z_t+\eta \bm \Xi_t \bm Z_t\\
        & = \left(\bm I_{2d}-\eta\bm Z_t\bm Z_t^{\!\top}\right)\bm Z_t+\eta\underline{\bm Z}_t\underline{\bm Z}_t^{\!\top}\bm Z_t-\eta \bm \Gamma \bm Z_t+\eta \bm \Xi_t \bm Z_t\,,
    \end{align*}
    where $\bm \Gamma$ is defined as
    \begin{align*}
        \bm \Gamma & := \begin{bmatrix}
            \bm 0_{d\times d} & \Delta \\
            \Delta^{\!\top} & \bm 0_{k\times k}
        \end{bmatrix}\,.
    \end{align*}
    Then, by the triangle inequality, with probability $1- 2C\exp(-\epsilon^2 N)$ for a universal constant $C>0$, we have
    \begin{align*}
        \left\|\bm Z_{t+1}\right\|_{op} & \leq \left\|\left(\bm I_{2d}-\eta\bm Z_t\bm Z_t^{\!\top}\right)\bm Z_t\right\|_{op}+\eta\left\|\underline{\bm Z}_t\underline{\bm Z}_t^{\!\top}\bm Z_t\right\|_{op}+\eta\left\|\bm \Gamma \bm Z_t\right\|_{op}+\eta \left\|\bm \Xi_t \bm Z_t\right\|_{op}\\
        & \leq \left(1-\eta \left\|\bm Z_{t}\right\|_{op}^2\right)\left\|\bm Z_{t}\right\|_{op}\quad\tag*{\color{teal}[by simultaneous diagonalization]}\\
        & +\eta\left\|\underline{\bm Z}_t\underline{\bm Z}_t^{\!\top}\bm Z_t\right\|_{op}+\eta\left\|\bm \Gamma \bm Z_t\right\|_{op}+\eta \left\|\bm \Xi_t \bm Z_t\right\|_{op}\\
        & \leq \left(1-\eta \left\|\bm Z_{t}\right\|_{op}^2\right)\left\|\bm Z_{t}\right\|_{op}
        + \eta \left\|\underline{\bm Z}_t^{\!\top}\bm Z_t\right\|_{op}\left\|\bm Z_{t}\right\|_{op} + \eta \lambda_1^* \left\|\bm Z_{t}\right\|_{op}+\eta \epsilon \left\|\bm R_t\right\|_{op} \left\|\bm Z_{t}\right\|_{op}\,,
    \end{align*}
    where the last inequality follows from the fact that
    \begin{align*}
        \left\|\underline{\bm Z}_t\right\|_{op}&=\left\|\bm Z_t\right\|_{op}\,,\\
        \left\|\bm \Gamma\right\|_{op}&=\lambda_1^*\,,\\
        \left\|\bm \Xi_t\right\|_{op}&=\left\|\left(\widetilde{\bm \Sigma}-\bm I_d\right)\bm R_t\right\|_{op}\leq \epsilon \left\|\bm R_t\right\|_{op}\,, \quad \mbox{w.h.p.}~1 - 2C\exp(-\epsilon^2 N)\,.
    \end{align*}
    Using the assumption
    \begin{align*}
        \left\|\underline{\bm Z}_t^{\!\top}\bm Z_t\right\|_{op}+ \epsilon \left\|\bm R_t\right\|_{op} & = \left\|\bm A_t^{\!\top}\bm A_t - \bm B_t^{\!\top}\bm B_t\right\|_{op} + \epsilon \left\|\bm R_t\right\|_{op} \leq \lambda_1^*\,,
    \end{align*}
    then $ \left\|\bm Z_{t+1}\right\|_{op}$ can be further bounded by
    \begin{align}
        \left\|\bm Z_{t+1}\right\|_{op} & \leq \left(1-\eta \left\|\bm Z_{t}\right\|_{op}^2 + 2 \eta \lambda_1^*\right)\left\|\bm Z_{t}\right\|_{op}\label{third-order-eq}\,.
    \end{align}
    Denote $x=\left\|\bm Z_{t}\right\|_{op}$ and $f(x)=\left(1-\eta x^2 + 2 \eta \lambda_1^*\right)x$, we have $f'(x)=1+2\eta\lambda_1^*-3\eta x^2$ and $f''(x)=-6\eta x$. Then, we know $f'(x^*)=0$ for $x>0$ attained at $x^*=\sqrt{\frac{1+2\eta\lambda_1^*}{3\eta}}=\sqrt{\frac{1}{3\eta}+\frac{2}{3}\lambda_1^*}$. As we pick $\eta \leq \frac{1}{10\lambda_1^*}$, then $x^*\geq 2\sqrt{\lambda_1^*}$, which implies the maximum of $f(x)$ attained at $x^*=2\sqrt{\lambda_1^*}$ over $x\in[0\,,2\lambda_1^*]$ since $\left\|\bm Z_{t}\right\|_{op}\leq 2\sqrt{\lambda_1^*}$ and
    \begin{align*}
        f(2\sqrt{\lambda_1^*})=2(1-4\eta\lambda_1^*+2\eta\lambda_1^*)\sqrt{\lambda_1^*}=2\sqrt{\lambda_1^*}-4\eta\lambda_1^*\leq 2\sqrt{\lambda_1^*}\,,
    \end{align*}
   which directly implies $\left\|\bm Z_{t+1}\right\|_{op}\leq 2\sqrt{\lambda_1^*}$. By consequence, $\left\|\bm A_{t+1}\right\|_{op}\,,\left\|\bm B_{t+1}\right\|_{op}\leq 2\sqrt{\lambda_1^*}$ if $\left\|\bm A_{t}\right\|_{op}\,,\left\|\bm B_{t}\right\|_{op}\leq 2\sqrt{\lambda_1^*}$, since $\bm A_{t+1}$ and $\bm B_{t+1}$ are sub-matrices of $\bm Z_{t+1}$.
\end{proof}

Based on the above results, we are ready to present the following intermediate results.
\begin{lemma}
\label{linear-induction-gd}
    Under assumptions in \cref{sec:assumptions} for the linear setting, with spectral initialization \eqref{eq:spectral-init-linear}, we take $\epsilon$ in data concentration as
    \begin{align*}
        \epsilon \leq \min\left\{\frac{1}{2\kappa}\,,\frac{\lambda^*_{r^*}}{32\kappa(32 \lambda_1^*+128 \kappa^2)}\right\}\,,
    \end{align*}
    and set the step-size as
    \begin{align*}
        \eta \leq \min\left\{\frac{1}{128\kappa\lambda_1^*}\,,\frac{(1-\epsilon/\kappa)}{1152\lambda^*_{1}}\right\}\,,
    \end{align*}
    then with probability at least with probability $1- 2C\exp(-\epsilon^2 N)$ for a universal constant $C>0$, we have that for $\forall\,t\geq 0$
    \begin{align}
        & \mathcal{M}_t \leq \frac{\lambda^*_{r^*}}{2} \label{M}\\
        & \max\left\{\left\|\bm A_{t}\right\|_{op}\,,\left\|\bm B_{t}\right\|_{op}\right\}\leq 2\sqrt{\lambda_1^*}\,, \label{upper}\\
        & \lambda_{r^*}^*\left(\bm A_t\right)\,,\lambda_{r^*}^*\left(\bm B_t\right) \geq \frac{\sqrt{\lambda_{r^*}^*}}{4\sqrt{\kappa}} \,,\label{lower}\\
        & \left\|\bm A^{\bm U_\perp}_{t}\right\|_{op} \leq \frac{32 \kappa \epsilon\sqrt{\lambda_1^*}}{\lambda^*_{r^*}}\,. \label{res-A}
    \end{align}
    Also, we can obtain
    \begin{align}
        \mathcal{M}_{t+1} \leq \bigg(1-\eta \frac{\lambda^*_{r^*}}{64\kappa}\bigg)\mathcal{M}_t \label{ML}\,.
    \end{align}
\end{lemma}
\begin{proof}
Inspired by the matrix sensing technique from \cite{xiong2023over}, we develop an inductive approach to prove the claims on our settings.
    At $t=0$, \cref{M}-\cref{res-A} can be adopted from \cref{linear-initial-risk}. We assume \cref{M}-\cref{res-A} hold at $t\geq 1$, recall \cref{AUperp}, we have
    \begin{align*}
        \left\|\bm A^{\bm U_\perp}_{t+1}\right\|_{op} & \leq \left(1-\eta \lambda_{r^*}^2\left(\bm B_t^{\bm V}\right)\right) \left\|\bm A^{\bm U_\perp}_t\right\|_{op} + \eta \epsilon \left\|\bm R_t\right\|_{op} \left\|\bm B_t^{\bm V}\right\|_{op}\\
        & \leq \left(1-\eta \lambda_{r^*}^2\left(\bm B_t^{\bm V}\right)\right) \left\|\bm A^{\bm U_\perp}_t\right\|_{op} + 4 \eta \epsilon \mathcal{M}_t \sqrt{\lambda_1^*}\\
        & \leq \bigg(1-\eta \frac{(\lambda^*_{r^*})^2}{16\kappa}\bigg)\left\|\bm A^{\bm U_\perp}_t\right\|_{op} + 2 \eta \epsilon \lambda^*_{r^*} \sqrt{\lambda_1^*}\\
        & \leq \frac{32 \kappa \epsilon\sqrt{\lambda_1^*}}{\lambda^*_{r^*}}\,, \tag*{\color{teal}$\left[\text{by }\left\|\bm A^{\bm U_\perp}_t\right\|_{op}\leq \frac{32 \kappa \epsilon\sqrt{\lambda_1^*}}{\lambda^*_{r^*}}\right]$}
    \end{align*}
    which proves the \cref{res-A} at $t+1$. Next, by \cref{mathcalMt}, we have
    \begin{align*}
        \left\|\bm R^*_{t+1}\right\|_{op} & \leq \bigg(1-\eta \frac{\lambda^*_{r^*}}{8\kappa}\bigg)\mathcal{M}_t\\
        & + 8 \eta \epsilon \lambda_1^* \mathcal{M}_t + 2\eta^2 \lambda_1^*\lambda_{r^*}^*\mathcal{M}_t + 4\eta^2 \epsilon \lambda_1^*\lambda_{r^*}^*\mathcal{M}_t
         + 64 \eta \epsilon \kappa^2 \mathcal{M}_t
        +32 \eta^2 \kappa^2 \epsilon\lambda^*_{r^*}\mathcal{M}_t+ 128 \eta^2 \epsilon^3 \kappa^2 \lambda_{r^*}^*\mathcal{M}_t\\
        & +64\eta^2 \epsilon^2  \kappa^2 \lambda_{r^*}^* \mathcal{M}_t+8\eta \epsilon \lambda_1^* \mathcal{M}_t
         + 8 \eta^2 \epsilon \lambda_1^* \mathcal{M}_t + 8 \eta^2 \epsilon^2 \lambda_1^* \lambda_{r^*}^* \mathcal{M}_t
         + 128 \eta \epsilon^2 \kappa^2 \mathcal{M}_t+64\eta^2 \epsilon^2  \kappa^2 \lambda_{r^*}^* \mathcal{M}_t\\
        & = \bigg(1-\eta \frac{\lambda^*_{r^*}}{8\kappa}\bigg)\mathcal{M}_t\\
        & \quad + \eta\Bigg\{16\epsilon \lambda_1^*+64\epsilon \kappa^2+2\eta \lambda_1^*\lambda_{r^*}^*+\eta\epsilon\left(4\lambda_1^*\lambda_{r^*}^*+32\kappa^2\lambda_{r^*}^*+8\lambda_1^*\right)
         + 128 \epsilon^2\kappa^2\\
         & \quad +\eta\left(128\eta\epsilon^2\kappa^2\lambda_{r^*}^*+8\eta\epsilon^2\lambda_1^*\lambda_{r^*}^*\right)+128\eta\epsilon^3\kappa^2\lambda_{r^*}^*\Bigg\}\mathcal{M}_t\\
         & \leq \bigg(1-\eta \frac{\lambda^*_{r^*}}{8\kappa}\bigg)\mathcal{M}_t
        + 2\eta\bigg(16\epsilon \lambda_1^*+64\epsilon \kappa^2+2\eta \lambda_1^*\lambda_{r^*}^*
         \bigg)\mathcal{M}_t \quad \tag*{\color{teal}[due to the order dominance]}\\
         & \leq \bigg(1-\eta \frac{\lambda^*_{r^*}}{16\kappa}\bigg)\mathcal{M}_t
        + 2\eta\bigg(16\epsilon \lambda_1^*+64\epsilon \kappa^2
         \bigg)\mathcal{M}_t\quad \tag*{\color{teal}$\left[\text{by }\eta \leq \frac{1}{64\kappa\lambda_1^*}\right]$}\\
         & \leq \bigg(1-\eta \frac{\lambda^*_{r^*}}{32\kappa}\bigg)\mathcal{M}_t\,,\quad \tag*{\color{teal}$\left[\text{by }\epsilon \leq \frac{\lambda^*_{r^*}}{16\kappa(32 \lambda_1^*+128 \kappa^2)}\right]$}
    \end{align*}
   where the order dominance from the second inequality follows from the fact that $\eta$ and $\epsilon$ are sufficiently small constant such that the terms in $\mathcal{O}(\eta \epsilon)\,,\mathcal{O}(\epsilon^2)\,,\mathcal{O}(\eta^2\epsilon^2)\,,\mathcal{O}(\eta \epsilon^3)$ are significantly smaller the terms in $\mathcal{O}(\eta)$ and $\mathcal{O}(\epsilon)$.
    
    Similarly, we can obtain
    \begin{align*}
        \left\|\bm R^\perp_{t+1}\right\|_{op} & \leq \bigg(1-\eta \frac{\lambda^*_{r^*}}{16\kappa}\bigg)\mathcal{M}_t\quad \tag*{\color{teal}$\left[\text{since }\lambda_{\min}\left(\bm A^{\bm U_\perp}_t\right)\geq 0\right]$}\\
        & + \eta \Bigg\{8\epsilon \lambda_1^*+2\eta \lambda_1^* \lambda_{r^*}^* + 4\eta \epsilon \lambda_1^* \lambda_{r^*}^* + 64 \epsilon \kappa^2 + 32 \eta \epsilon \kappa^2\lambda_{r^*}^*+64\eta \epsilon \kappa^2 \lambda_{r^*}^*+128\epsilon^2\kappa^2\\
        & + 8\eta \epsilon \lambda_1^* + 8\eta \epsilon^2 \lambda_1^* \lambda_{r^*}^* + 2048 \epsilon^3\frac{\kappa^3}{\lambda_{r^*}^*}+64\eta \epsilon^2 \kappa^2 + 128 \eta \epsilon^3\kappa^2
        \Bigg\}\mathcal{M}_t\\
        & \leq \bigg(1-\eta \frac{\lambda^*_{r^*}}{16\kappa}\bigg)\mathcal{M}_t
        + 2\eta \Bigg\{8\epsilon \lambda_1^*+2\eta \lambda_1^* \lambda_{r^*}^* + 64 \epsilon \kappa^2\Bigg\}\mathcal{M}_t\quad \tag*{\color{teal}[due to the order dominance]}\\
        & \leq \bigg(1-\eta \frac{\lambda^*_{r^*}}{32\kappa}\bigg)\mathcal{M}_t
        + 2\eta \Bigg\{8\epsilon \lambda_1^*+ 64 \epsilon \kappa^2\Bigg\}\mathcal{M}_t\quad \tag*{\color{teal}$\left[\text{by }\eta \leq \frac{1}{128\kappa\lambda_1^*}\right]$}\\
        & \leq \bigg(1-\eta \frac{\lambda^*_{r^*}}{64\kappa}\bigg)\mathcal{M}_t\,,\quad \tag*{\color{teal}$\left[\text{by }\epsilon \leq \frac{\lambda^*_{r^*}}{32\kappa(32 \lambda_1^*+128 \kappa^2)}\right]$}
    \end{align*}
    which proves the \cref{M} at $t+1$. 
    
    Therefore, we can conclude that
    \begin{align*}
        \mathcal{M}_{t+1} & \leq \bigg(1-\eta \frac{\lambda^*_{r^*}}{64\kappa}\bigg)\mathcal{M}_t\,.
    \end{align*}
    Next, assume \cref{M}-\cref{res-A} hold at $t\geq 1$, we have
    \begin{align*}
        \left(\bm A_{t+1}^{\!\top}\bm A_{t+1} - \bm B_{t+1}\bm B_{t+1}^{\!\top}\right)-\left(\bm A_{t}^{\!\top}\bm A_{t} - \bm B_{t}\bm B_{t}^{\!\top}\right) & = \eta^2 \bm B_t\left(\bm A_t \bm B_t - \Delta\right)^{\!\top}\widehat{\bm \Sigma}\widehat{\bm \Sigma}\left(\bm A_t \bm B_t - \Delta\right)\bm B_t^{\!\top}\\
        & + \eta^2 \bm A_t^{\!\top}\widehat{\bm \Sigma}\left(\bm A_t \bm B_t - \Delta\right)\left(\bm A_t \bm B_t - \Delta\right)^{\!\top}\widehat{\bm \Sigma}\bm A_t\,.
    \end{align*}
    Accordingly, we can derive
    \begin{align*}
        &\left\|\left(\bm A_{t+1}^{\!\top}\bm A_{t+1} - \bm B_{t+1}\bm B_{t+1}^{\!\top}\right)-\left(\bm A_{0}^{\!\top}\bm A_{0} - \bm B_{0}\bm B_{0}^{\!\top}\right)\right\|_{op}\\
        =&\sum_{i=1}^{t+1}\left\|\left(\bm A_{i}^{\!\top}\bm A_{i} - \bm B_{i}\bm B_{i}^{\!\top}\right)-\left(\bm A_{i-1}^{\!\top}\bm A_{i-1} - \bm B_{i-1}\bm B_{i-1}^{\!\top}\right)\right\|_{op}\\
        =&\sum_{i=1}^{t+1}2\eta^2 \|\widehat{\bm \Sigma}\|_{op}^2 \|\bm R_{i-1}\|_{op}^2 \max\left\{\|\bm A_{i-1}\|_{op}^2\,, \|\bm B_{i-1}\|_{op}^2\right\}\\
        =&\sum_{i=1}^{t+1}72\eta^2 \mathcal{M}_{i-1}^2 \lambda_1^*\quad \tag*{\color{teal}[by \cref{concentration-N}]}\\
        \leq &\sum_{i=1}^{t+1}18\eta^2 \bigg(1-\eta \frac{\lambda^*_{r^*}}{64\kappa}\bigg)^{2(i-1)}(\lambda_{r^*}^*)^2 \lambda_1^*\\
        \leq& 18\eta^2(\lambda_{r^*}^*)^2 \lambda_1^*\sum_{i=0}^{\infty}\bigg(1-\eta \frac{\lambda^*_{r^*}}{64\kappa}\bigg)^{2i}\\
        \leq& 18\eta^2(\lambda_{r^*}^*)^2 \lambda_1^* \frac{64\kappa}{\eta\lambda^*_{r^*}}\\
        =&1152\eta\lambda_1^*\lambda^*_{r^*}\kappa\\
        \leq& (1-\epsilon/\kappa)\lambda_1^*\,. \quad \tag*{\color{teal}$\left[\text{by }\eta\leq\frac{(1-\epsilon/\kappa)}{1152\lambda^*_{1}}\right]$}
    \end{align*}
    Since $\left\|\left(\bm A_{0}^{\!\top}\bm A_{0} - \bm B_{0}\bm B_{0}^{\!\top}\right)\right\|_{op}=0$ due to the spectral initialization \eqref{eq:spectral-init-linear}, by triangle inequality, $\left\|\left(\bm A_{t+1}^{\!\top}\bm A_{t+1} - \bm B_{t+1}\bm B_{t+1}^{\!\top}\right)\right\|_{op}\leq (1-\epsilon/\kappa)\lambda_1^*$. Next, by \cref{mahdi-upper}, we can obtain
    \begin{align*}
        \left\|\bm A_{t+1}\right\|_{op}\leq 2\sqrt{\lambda_1^*}\,,\quad\left\|\bm B_{t+1}\right\|_{op}\leq 2\sqrt{\lambda_1^*}\,,
    \end{align*}
    which proves the \cref{upper} at $t+1$. Lastly, assume \cref{M}-\cref{res-A} hold at $t\geq 1$, by Weyl's inequality, combine with $\mathcal{M}_{t+1}\leq \frac{\lambda_{r^*}^*}{2}$, we have
    \begin{align*}
        \frac{\lambda_{r^*}^*}{2} \geq \left\|\bm A_{t+1}^{\bm U} \bm B_{t+1}^{\bm V} - \bm S^*\right\|_{op} \geq \lambda_{r^*}^* - \lambda_{r^*}(\bm A_{t+1}^{\bm U} \bm B_{t+1}^{\bm V})\Rightarrow \lambda_{r^*}(\bm A_{t+1}^{\bm U} \bm B_{t+1}^{\bm V})\geq \frac{\lambda_{r^*}^*}{2}\,.
    \end{align*}
    Again by Weyl's inequality and the \cref{upper} at time $t+1$ we can get
    \begin{align*}
        2 \sqrt{\lambda_1^*}\cdot\lambda_{r^*}(\bm B_{t+1}^{\bm V})\geq \lambda_1(\bm A_{t+1}^{\bm U})\lambda_{r^*}(\bm B_{t+1}^{\bm V})\geq\lambda_{r^*}(\bm A_{t+1}^{\bm U} \bm B_{t+1}^{\bm V})\geq \frac{\lambda_{r^*}^*}{2}\Rightarrow \lambda_{r^*}(\bm B_{t+1}^{\bm V}) \geq \frac{\sqrt{\lambda_{r^*}^*}}{4 \sqrt{\kappa}}\,.
    \end{align*}
    Besides, $\lambda_{r^*}^*(\bm A_{t+1}^{\bm U})$ follows similar derivation. We prove all the claims.
\end{proof}
\begin{theorem}
\label{risk-conv-linear-vanilla-gd}
    Under assumptions in \cref{sec:assumptions} for the linear setting, with spectral initialization \eqref{eq:spectral-init-linear}, we take $\epsilon$ in data concentration as
    \begin{align*}
        \epsilon \leq \min\left\{\frac{1}{2\kappa}\,,\frac{\lambda^*_{r^*}}{32\kappa(32 \lambda_1^*+128 \kappa^2)}\right\}\,,
    \end{align*}
    and set the step-size as
    \begin{align}\label{lr-linear-gd}
        \eta \leq \min\left\{\frac{1}{128\kappa\lambda_1^*}\,,\frac{(1-\epsilon/\kappa)}{1152\lambda^*_{1}}\right\}\,,
    \end{align}
    then with probability at least with probability $1- 2C\exp(-\epsilon^2 N)$ for a universal constant $C>0$, we have that for $\forall\,t\geq 0$
    \begin{align*}
    \left\|\bm A_t \bm B_t - \Delta\right\|_F
    & \leq \sqrt{2 r^*} \left(1 - \eta \frac{\lambda_{r^*}^*}{64 \kappa}\right)^{t}\cdot\lambda_{r^*}^*\,.
\end{align*}
\end{theorem}
\begin{proof}
By \cref{linear-induction-gd}, with probability at least with probability $1- 2C\exp(-\epsilon^2 N)$ for a universal constant $C>0$, we can obtain the linear convergence of generalization risk
\begin{align*}
    \left\|\bm A_t \bm B_t - \Delta\right\|_F & \leq \sqrt{2 r^*} \left\|\bm A_t \bm B_t - \Delta\right\|_{op}\tag*{\color{teal}$\left[\operatorname{Rank}(\bm A_t \bm B_t)=r^*\text{ by \cref{linear-invariant-B2} and }\operatorname{Rank}(\Delta)=r^*\right]$}\\
    & \leq \sqrt{2 r^*} \left(1 - \eta \frac{\lambda_{r^*}^*}{64 \kappa}\right)^{t}\cdot\lambda_{r^*}^*\,,
\end{align*}
which is independent of the choice of LoRA rank $r$ if $r\geq r^*$.
\end{proof}