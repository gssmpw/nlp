\newpage
\section{Proofs for Linear Model}
\label{lora_linear}


In \cref{app:align_linear}, we deliver the proofs for alignment in \cref{sec:align_linear}.
In \cref{app:lrspec}, we present the proofs for the main results in \cref{sec:linear-spectral} under spectral initialization.
In \cref{app:precgdlr}, we give the proofs for precondition GD in \cref{sec:scaledgd}.

\subsection{Proofs for LoRA under Random Initialization}
\label{app:align_linear}

Let $\widetilde{\bm X}$ be the fine-tuned data with $\widetilde{\bm X} \in \mathbb{R}^{N \times d}$ and the multi-output $\widetilde{\bm Y} \in \mathbb{R}^{N \times k}$.
For simplicity, we define the initial residual error $\widetilde{\bm Y}_{\Delta} := \widetilde{\bm Y} - \widetilde{\bm X}\bm W^\natural = \widetilde{\bm X}\Delta$. Then, denote the negative gradient of Full Fine-tuning after the first step as
\begin{align*}
  {\bm G}^{\natural} & = -\nabla_{\bm W} {L}(\bm W^\natural) = -\frac{1}{N}\widetilde{\bm X}^{\!\top}(\widetilde{\bm X}\bm W^\natural-\widetilde{\bm Y}) = \frac{1}{N}\widetilde{\bm X}^{\!\top}\widetilde{\bm Y}_{\Delta} \in \mathbb{R}^{d \times k}\, .
\end{align*}

Recall the gradient update for LoRA
\begin{equation*}
    \bm A_{t+1} = \bm A_{t}-\frac{\eta_1}{N} \widetilde{\bm X}^{\!\top} \Bigl(\widetilde{\bm X} (\bm W^\natural+\bm A_t \bm B_t) - \widetilde{\bm Y}\Bigr) \bm B^{\!\top}_t\, ,
\end{equation*}
\begin{equation*}
    \bm B_{t+1} = \bm B_t -\frac{\eta_2}{N} \bm A^{\!\top}_t \widetilde{\bm X}^{\!\top} \Bigl(\widetilde{\bm X} (\bm W^\natural+\bm A_t \bm B_t) - \widetilde{\bm Y}\Bigr)\,,
\end{equation*}
we rewrite it in a compact form
\begin{equation}\label{eq:dynamics}
    \begin{split}
    \begin{bmatrix}
        \bm A_{t+1} \\ \bm B_{t+1}^{\!\top}
    \end{bmatrix} & = \begin{bmatrix}
        \bm A_t \\ \bm B_t^{\!\top}
    \end{bmatrix} + \underbrace{\begin{bmatrix}
        \bm 0 & \eta_1 {\bm G}^{\natural}\\
        \eta_2 {{\bm G}^{\natural}}^{\!\top} & \bm 0
    \end{bmatrix}}_{:=\bm H} \begin{bmatrix}
        \bm A_t \\ \bm B_t^{\!\top}
    \end{bmatrix} - \frac{1}{N} \begin{bmatrix}
        \bm 0 & \eta_1 \widetilde{\bm X}^{\!\top}\widetilde{\bm X}\bm A_t \bm B_t\\
        \eta_2 \bm B_t^{\!\top} \bm A_t^{\!\top}\widetilde{\bm X}^{\!\top}\widetilde{\bm X} & \bm 0
    \end{bmatrix}\begin{bmatrix}
        \bm A_t \\ \bm B_t^{\!\top}
    \end{bmatrix}\\
    & = \underbrace{\begin{bmatrix}
        \bm I_d & \eta_1 {\bm G}^{\natural}\\
        \eta_2 {{\bm G}^{\natural}}^{\!\top} & \bm I_k
    \end{bmatrix}}_{:=\bm H} \begin{bmatrix}
        \bm A_t \\ \bm B_t^{\!\top}
    \end{bmatrix} - \underbrace{\frac{1}{N} \begin{bmatrix}
        \bm 0 & \eta_1 \widetilde{\bm X}^{\!\top}\widetilde{\bm X}\bm A_t \bm B_t\\
        \eta_2 \bm B_t^{\!\top} \bm A_t^{\!\top}\widetilde{\bm X}^{\!\top}\widetilde{\bm X} & \bm 0
    \end{bmatrix}\begin{bmatrix}
        \bm A_t \\ \bm B_t^{\!\top}
    \end{bmatrix}}_{:=\widehat{\bm E}_{t+1}}\, .     
    \end{split}
\end{equation}
By defining a stack iterate
\begin{align}
    \bm Z_t & := \begin{bmatrix}
        \bm A_t \\ \bm B_t^{\!\top}
    \end{bmatrix}\, , \quad \mbox{and} \quad \bm Z_0 := \begin{bmatrix}
        \bm A_0 \\ \bm 0
    \end{bmatrix}\in \mathbb{R}^{(d+k)\times r}\, , \label{stack-Z}
\end{align}
we can formulate \cref{eq:dynamics} as a compact form of a nonlinear dynamical system  
\begin{align}\label{eq:nonlineardy}
    \bm Z_{t+1} & = \bm H \bm Z_t - \widehat{\bm E}_{t+1}\,,
\end{align}
where $\bm H$ is a time-independent matrix corresponding to the linear part, and $\widehat{\bm E}_{t+1}$ corresponds to the nonlinear part.

\subsubsection{SVD and Schur Decomposition}
\label{app:svd}

We recall the complete SVD of $\Delta \in \mathbb{R}^{d \times k}$ 
\begin{align*}
\Delta=\widetilde{\bm U} \widetilde{\bm S} \widetilde{\bm V}^{\!\top}=
    \begin{bmatrix}
        \bm U & \bm U_\perp
    \end{bmatrix}\begin{bmatrix}
       \bm S^* & \bm 0_{r^*\times (k-r^*)}\\
        \bm 0_{(d-r^*)\times r^*} & \bm 0_{(d-r^*)\times (k-r^*)}
    \end{bmatrix}\begin{bmatrix}
        \bm V^{\!\top} \\ \bm V_\perp^{\!\top}
    \end{bmatrix},\quad \text{where }\bm S^* = \operatorname{Diag}\left(\lambda_1^*\,, \cdots \,,\lambda_{r^*}^*\right)\,.
\end{align*}

Similarly, we recall the complete SVD of ${\bm G}^{\natural}$ as ${\bm G}^{\natural} =\widetilde{\bm U}_{\bm G^\natural} \widetilde{\bm S}_{\bm G^\natural} \widetilde{\bm V}_{\bm G^\natural}^{\!\top}$. We derive the Schur decomposition of $\bm H$ under the special case $d=k$ in \cref{H-schur} and then extend to $d\neq k$ in \cref{lemma:Hdnk} via zero padding on SVD in \cref{zero-block-svd}.
\begin{lemma}[Schur Decomposition of $\bm H$ under $d=k$]
\label{H-schur}
    Under assumptions in \cref{sec:assumptions} for the linear setting, given ${\bm G}^{\natural}\in\mathbb{R}^{d\times k}$ in \cref{eq:G} and its complete SVD $\widetilde{\bm U}_{\bm G^\natural}\widetilde{\bm S}_{\bm G^\natural}\widetilde{\bm V}_{\bm G^\natural}^{\!\top}$, if $d=k$, then the block matrix $\bm H$ admits the following Schur decomposition
    \begin{align*}
        \bm H = 
        \begin{bmatrix}
            \bm I_d & \eta_1 {\bm G}^{\natural}\\
            \eta_2 \left({\bm G}^{\natural}\right)^{\!\top} & \bm I_d
        \end{bmatrix} = \mathbf{C}\mathbf{T}\mathbf{C}^{\!\top}\,,
    \end{align*}
    where $\bm C$ is an orthogonal matrix and $\bm T$ is a block upper triangular matrix
    \begin{align*}
        \mathbf{C} & = \frac{1}{\sqrt{1+\frac{\eta_2}{\eta_1}}}\begin{bmatrix}
        \widetilde{\bm U}_{\bm G^\natural} & -\sqrt{\frac{\eta_2}{\eta_1}}\widetilde{\bm U}_{\bm G^\natural}\\
        \sqrt{\frac{\eta_2}{\eta_1}}\widetilde{\bm V}_{\bm G^\natural} & \widetilde{\bm V}_{\bm G^\natural}
    \end{bmatrix}\,,
   \quad \mbox{and} \quad
        \mathbf{T} = \begin{bmatrix}
        \bm I_d+\sqrt{\eta_1\eta_2}\widetilde{\bm S}_{\bm G^\natural} & (\eta_1 - \eta_2)\widetilde{\bm S}_{\bm G^\natural} \\
        \bm 0 & \bm I_d-\sqrt{\eta_1\eta_2}\widetilde{\bm S}_{\bm G^\natural}
        \end{bmatrix}\,.
    \end{align*}
\end{lemma}
\begin{proof}
    We prove by verifying the claim. Starting with
    \begin{align*}
        & \begin{bmatrix}
        \widetilde{\bm U}_{\bm G^\natural} & -\sqrt{\frac{\eta_2}{\eta_1}}\widetilde{\bm U}_{\bm G^\natural}\\
        \sqrt{\frac{\eta_2}{\eta_1}}\widetilde{\bm V}_{\bm G^\natural} & \widetilde{\bm V}_{\bm G^\natural}
        \end{bmatrix}\begin{bmatrix}
        \bm I_d+\sqrt{\eta_1\eta_2}\widetilde{\bm S}_{\bm G^\natural} & (\eta_1 - \eta_2)\widetilde{\bm S}_{\bm G^\natural} \\
        \bm 0 & \bm I_d-\sqrt{\eta_1\eta_2}\widetilde{\bm S}_{\bm G^\natural}
        \end{bmatrix}\\
        & =  \begin{bmatrix}
            \widetilde{\bm U}_{\bm G^\natural} + \sqrt{\eta_1\eta_2}\widetilde{\bm U}_{\bm G^\natural}\widetilde{\bm S}_{\bm G^\natural} & \eta_1\widetilde{\bm U}_{\bm G^\natural}\widetilde{\bm S}_{\bm G^\natural} - \sqrt{\frac{\eta_2}{\eta_1}}\widetilde{\bm U}_{\bm G^\natural}\\
            \sqrt{\frac{\eta_2}{\eta_1}}\widetilde{\bm V}_{\bm G^\natural}+\eta_2\widetilde{\bm V}_{\bm G^\natural}\widetilde{\bm S}_{\bm G^\natural} & \sqrt{\frac{\eta_2}{\eta_1}}(\eta_1 - \eta_2)\widetilde{\bm V}_{\bm G^\natural}\widetilde{\bm S}_{\bm G^\natural} + \widetilde{\bm V}_{\bm G^\natural} - \sqrt{\eta_1\eta_2}\widetilde{\bm V}_{\bm G^\natural}\widetilde{\bm S}_{\bm G^\natural}
        \end{bmatrix} =: \bm \Xi \,,
    \end{align*}
    then we can verify that
    \begin{align*}
    & \frac{\eta_1}{\eta_1 + \eta_2}\times \bm \Xi \times\begin{bmatrix}
        \widetilde{\bm U}_{\bm G^\natural}^{\!\top} & \sqrt{\frac{\eta_2}{\eta_1}}\widetilde{\bm V}_{\bm G^\natural}^{\!\top} \\
        -\sqrt{\frac{\eta_2}{\eta_1}}\widetilde{\bm U}_{\bm G^\natural}^{\!\top} & \widetilde{\bm V}_{\bm G^\natural}^{\!\top}
    \end{bmatrix}\\
    = & \frac{\eta_1}{\eta_1 + \eta_2}\times\begin{bmatrix}
        \left(1+\frac{\eta_2}{\eta_1}\right)\bm I_d & (\eta_1 + \eta_2) \widetilde{\bm U}_{\bm G^\natural}\widetilde{\bm S}_{\bm G^\natural}\widetilde{\bm V}_{\bm G^\natural}^{\!\top}\\
        \eta_2 \left(1+\frac{\eta_2}{\eta_1}\right)\widetilde{\bm V}_{\bm G^\natural}\widetilde{\bm S}_{\bm G^\natural}\widetilde{\bm U}_{\bm G^\natural}^{\!\top} & \left(1+\frac{\eta_2}{\eta_1}\right)\bm I_d
    \end{bmatrix}\\
    = & \begin{bmatrix}
        \bm I_d & \eta_1 \widetilde{\bm U}_{\bm G^\natural}\widetilde{\bm S}_{\bm G^\natural}\widetilde{\bm V}_{\bm G^\natural}^{\!\top}\\
        \eta_2 \widetilde{\bm V}_{\bm G^\natural}\widetilde{\bm S}_{\bm G^\natural}\widetilde{\bm U}_{\bm G^\natural}^{\!\top} & \bm I_d
    \end{bmatrix}=\bm H\,.
    \end{align*}
    Accordingly, we conclude the result.
\end{proof}
Next, we consider the case of $d\neq k$.
\paragraph{Case 1 ($d>k$):} by zero padding, ${\bm G}^{\natural}$ and related matrices are given by
\begin{align*}
    \underline{\mathbf{G}}^\natural & = \begin{bmatrix}
        {\bm G}^{\natural} & \bm 0_{d \times (d-k)}
    \end{bmatrix}\,,\quad \underline{\bm H} = \begin{bmatrix}
        \bm I_d & \eta_1 \underline{\mathbf{G}}^\natural\\
        \eta_2 \left(\underline{\mathbf{G}}^\natural\right)^{\!\top} & \bm I_d
    \end{bmatrix}\,,
\end{align*}
and for any $t\geq 0$, we have the following related matrices
\begin{align*}
    \underline{\bm B}_t & = \begin{bmatrix}
        \bm B_t & \bm 0_{r\times (d-k)}
    \end{bmatrix}\,,\quad \underline{\bm Z}_t = \begin{bmatrix}
        \bm A_t \\ \left(\underline{\bm B}_t\right)^{\!\top}
    \end{bmatrix}\,,\quad \underline{\widetilde{\bm Z}}_t = \begin{bmatrix}
        \bm A^{\tt lin}_t \\
        \left(\underline{\bm B^{\tt lin}}_t\right)^{\!\top}
    \end{bmatrix} = \underline{\bm H}^t \underline{\bm Z}_0\,.
\end{align*}
\paragraph{Case 2 ($d<k$):} Similarly, by zero padding, we define
\begin{align*}
    \underline{\mathbf{G}}^\natural & = \begin{bmatrix}
        {\bm G}^{\natural} \\ \bm 0_{(k-d) \times k}
    \end{bmatrix}\,,\quad \underline{\bm H} = \begin{bmatrix}
        \bm I_k & \eta_1 \underline{\mathbf{G}}^\natural\\
        \eta_2 \left(\underline{\mathbf{G}}^\natural\right)^{\!\top} & \bm I_k
    \end{bmatrix}\,,
\end{align*}
and for $\forall\,t\geq 0$, we define
\begin{align*}
    \underline{\bm A}_t & = \begin{bmatrix}
        \bm A_t \\ \bm 0_{(k-d)\times r}
    \end{bmatrix}\,,\quad \underline{\bm Z}_t = \begin{bmatrix}
        \underline{\bm A}_t \\ \left(\bm B_t\right)^{\!\top}
    \end{bmatrix}\,,\quad \underline{\widetilde{\bm Z}}_t = \begin{bmatrix}
        \underline{\bm A^{\tt lin}}_t\\
        \left(\bm B^{\tt lin}_t\right)^{\!\top}
    \end{bmatrix} = \underline{\bm H}^t \underline{\bm Z}_0\,.
\end{align*}
Then we have the following lemma on the SVD of $\underline{\mathbf{G}}^\natural$.
\begin{lemma}
\label{zero-block-svd}
    If $d>k$, then we have the following SVD of $\underline{\mathbf{G}}^\natural$
    \begin{align*}
        \underline{\mathbf{G}}^\natural & = \widetilde{\bm U}_{\bm G^\natural} \underline{\widetilde{\bm S}_{\bm G^\natural}} \underline{\widetilde{\bm V}_{\bm G^\natural}}^{\!\top}\,,
    \end{align*}
    where
    \begin{align*}
        \underline{\widetilde{\bm V}_{\bm G^\natural}} & = \begin{bmatrix}
            \widetilde{\bm V}_{\bm G^\natural} & \bm 0_{k\times (d-k)}\\
            \bm 0_{(d-k) \times k} & \bm I_{(d-k)}
        \end{bmatrix}\,, \quad \text{and} \quad \underline{\widetilde{\bm S}_{\bm G^\natural}} = \begin{bmatrix}
       \widetilde{\bm S}_{\bm G^\natural} & \bm 0_{d\times (d-k)}
       \end{bmatrix}\,.
    \end{align*}
    If $d<k$, then we have the following SVD of $\underline{\mathbf{G}}^\natural$
    \begin{align*}
        \underline{\mathbf{G}}^\natural & = \underline{\widetilde{\bm U}_{\bm G^\natural}} \underline{\widetilde{\bm S}_{\bm G^\natural}} \widetilde{\bm V}_{\bm G^\natural}^{\!\top}\,,
    \end{align*}
    where
    \begin{align*}
        \underline{\widetilde{\bm U}_{\bm G^\natural}} & = \begin{bmatrix}
            \widetilde{\bm U}_{\bm G^\natural} & \bm 0_{k\times (k-d)}\\
            \bm 0_{(k-d) \times k} & \bm I_{(k-d)}
        \end{bmatrix}\,, \quad \text{and} \quad \underline{\widetilde{\bm S}_{\bm G^\natural}} = \begin{bmatrix}
       \widetilde{\bm S}_{\bm G^\natural} \\ \bm 0_{(k-d)\times k}
       \end{bmatrix}\,.
    \end{align*}
\end{lemma}
\begin{proof}
    The block construction does not affect the original part of the SVD. It only appends zeros to the singular values and grows the corresponding orthonormal bases as partial identity matrices appropriately.
\end{proof}
Now we can apply Lemma~\ref{zero-block-svd} for Lemma~\ref{H-schur} to extend to $d\neq k$ via the following lemma.
The proof is direct and we omit it here.
\begin{lemma}[Schur decomposition of $\bm H$ under $d \neq k$]
\label{lemma:Hdnk}
    Given the defined block matrix $\underline{\bm H} \in \mathbb{R}^{2s \times 2s}$ with $s:=\max\{ d,k \}$, we have the following decomposition
    \begin{align*}
        \underline{\bm H} & = \mathbf{C}\mathbf{T}\mathbf{C}^{\!\top}\,,
    \end{align*}
    If $d>k$,
    \begin{align*}
        \mathbf{C} & = \frac{1}{\sqrt{1+\frac{\eta_2}{\eta_1}}}\begin{bmatrix}
        \widetilde{\bm U}_{\bm G^\natural} & -\sqrt{\frac{\eta_2}{\eta_1}}\widetilde{\bm U}_{\bm G^\natural}\\
        \sqrt{\frac{\eta_2}{\eta_1}}\underline{\widetilde{\bm V}_{\bm G^\natural}} & \underline{\widetilde{\bm V}_{\bm G^\natural}}
    \end{bmatrix}\,,\quad
        \mathbf{T} = \begin{bmatrix}
        \bm I_d+\sqrt{\eta_1\eta_2}\underline{\widetilde{\bm S}_{\bm G^\natural}} & (\eta_1 - \eta_2)\underline{\widetilde{\bm S}_{\bm G^\natural}} \\
        \bm 0 & \bm I_d-\sqrt{\eta_1\eta_2}\underline{\widetilde{\bm S}_{\bm G^\natural}}
        \end{bmatrix}\,.
    \end{align*}
    If $d<k$,
    \begin{align*}
        \mathbf{C} & = \frac{1}{\sqrt{1+\frac{\eta_2}{\eta_1}}}\begin{bmatrix}
        \underline{\widetilde{\bm U}_{\bm G^\natural}} & -\sqrt{\frac{\eta_2}{\eta_1}}\underline{\widetilde{\bm U}_{\bm G^\natural}}\\
        \sqrt{\frac{\eta_2}{\eta_1}}{\widetilde{\bm V}_{\bm G^\natural}} & {\widetilde{\bm V}_{\bm G^\natural}}
    \end{bmatrix}\,,\quad
        \mathbf{T} = \begin{bmatrix}
        \bm I_k+\sqrt{\eta_1\eta_2}\underline{\widetilde{\bm S}_{\bm G^\natural}} & (\eta_1 - \eta_2)\underline{\widetilde{\bm S}_{\bm G^\natural}} \\
        \bm 0 & \bm I_k-\sqrt{\eta_1\eta_2}\underline{\widetilde{\bm S}_{\bm G^\natural}}
        \end{bmatrix}\,.
    \end{align*}
\end{lemma}


\subsubsection{Dynamics of Linear Approximation}
The target of our proof is to demonstrate that $\widehat{\bm E}_{t+1}$ does not effect the dynamics too much such that the dynamics of $\bm Z_{t}$ is close to the following pseudo iterate
\begin{align}\label{eq:pseduo_iterate}
    \bm Z^{\tt lin}_t := \bm H^t \bm Z_0 =: \begin{bmatrix}
    \bm A^{\tt lin}_t \\ \left(\bm B^{\tt lin}_t\right)^{\!\top}
\end{bmatrix} \,.
\end{align}
The updates of the pseudo iterate follow the trajectory of Oja's Power Method \citep{oja1982simplified}. Therefore, we aim to prove that the error between the actual iterate $\bm Z_t$ and the pseudo iterate $\bm Z^{\tt lin}_t$ is sufficiently small, which is equivalent to that the actual iterate $\bm Z_t$ performs a power iteration during the early steps. First, 
we obtain the difference between $\bm Z_t$ and $\bm Z^{\tt lin}_t$ by the following lemma.
\begin{lemma}[Formulation of $\bm E_t$]
\label{induc}
Under assumptions in \cref{sec:assumptions} for the linear setting, given the nonlinear dynamical system \eqref{eq:nonlineardy} and its linear part \eqref{eq:pseduo_iterate}, their difference admits
    \begin{align}
      \bm E_t := \bm Z_t - \bm Z^{\tt lin}_t = - \sum_{i=1}^t \bm H^{t-i} \widehat{\bm E}_{i}\label{pseudo-error} \,, \quad \forall t \in \mathbb{N}^+\,,
    \end{align}
where $\widehat{\bm E}_{i}$ corresponds to the nonlinear part in \cref{eq:dynamics}.
\end{lemma}

\begin{proof}[Proof of \cref{induc}]
We prove it by induction.
Recall the formulation of the nonlinear dynamical system
$\bm Z_{t+1} = \bm H \bm Z_t - \widehat{\bm E}_{t+1}$, we start with the base case $t=1$ such that
    \begin{align*}
        \bm Z_1 & = \bm H \bm Z_0 - \widehat{\bm E}_{1} = \widetilde{\bm Z}_1 - \widehat{\bm E}_{1}\, ,
    \end{align*}
    which proves the claim. Next, we assume Eq.~\eqref{pseudo-error} holds for $t\geq 2$, then for $t+1$, we have
    \begin{align*}
        \bm Z_{t+1} & = \bm H \bm Z_t - \widehat{\bm E}_{t+1}\\
        & = \bm H \left(\bm Z^{\tt lin}_t - \sum_{i=1}^t \bm H^{t-i} \widehat{\bm E}_{i}\right)- \widehat{\bm E}_{t+1}\\
        & = \bm Z^{\tt lin}_{t+1} - \sum_{i=1}^{t} \bm H^{t+1-i} \widehat{\bm E}_{i} - \widehat{\bm E}_{t+1}\\
        & = \bm Z^{\tt lin}_{t+1} - \sum_{i=1}^{t+1} \bm H^{t+1-i} \widehat{\bm E}_{i}\, ,
    \end{align*}
    which proves the claim.
\end{proof}

If $\|\bm E_t\|_{op}$ is sufficiently small within a certain period, e.g., $t \leq T$, then we could approximate the early dynamics by
\begin{align*}
 \bm Z_{t+1} :=
    \begin{bmatrix}
       \bm A_{t+1} \\ \bm B_{t+1}^{\!\top}
    \end{bmatrix} & \approx \bm Z^{\tt lin}_t := \begin{bmatrix}
    \bm A^{\tt lin}_{t+1} \\ \left(\bm B^{\tt lin}_{t+1}\right)^{\!\top}
\end{bmatrix}=
\begin{bmatrix}
    \bm A^{\tt lin}_t \\ \left(\bm B^{\tt lin}_{t}\right)^{\!\top}
\end{bmatrix} + 
    \begin{bmatrix}
        \bm 0 & \eta_1{\bm G}^{\natural}\\
        \eta_2{{\bm G}^{\natural}}^{\!\top} & \bm 0
    \end{bmatrix} \begin{bmatrix}
    \bm A^{\tt lin}_t \\ \left(\bm B^{\tt lin}_{t}\right)^{\!\top}
\end{bmatrix}\,,
\end{align*}
via
\begin{align*}
    \left\|\begin{bmatrix}
        \bm A_t \\ \bm B_t^{\!\top}
    \end{bmatrix}-\begin{bmatrix}
        \bm A^{\tt lin}_t \\ \left(\bm B^{\tt lin}_t\right)^{\!\top}
    \end{bmatrix}\right\|_{op} & \leq \|\bm E_t\|_{op}\,.
\end{align*}
In this subsection, we will bound $\|\bm E_t\|_{op}$ to show that it is actually small up to the initialization.
To prove it, we first conduct the dynamical analysis of $\bm Z^{\tt lin}_t$ via the structure of $\bm H$.\\

\noindent
{\bf Part I: Dynamics of $\bm Z^{\tt lin}_t$}\\

With the algebra fact above, we can derive the precise spectral dynamics of $\bm Z^{\tt lin}_t$, i.e., $\bm A^{\tt lin}_t$ and $\bm B^{\tt lin}_t$ separately.
\begin{lemma}\label{psuedo-dynamics}
Under assumptions in \cref{sec:assumptions} for the linear setting, given the pseudo iterate \eqref{eq:pseduo_iterate} on $\bm Z^{\tt lin}_t$, where two components $\bm A^{\tt lin}_t$ and $\bm B^{\tt lin}_t$ admit the following recursion
    \begin{align*}
        \left\{\begin{aligned}
            \bm A^{\tt lin}_t & = \underbrace{\frac{1}{2}\widetilde{\bm U}_{\bm G^\natural}\bigg(\left(\bm I_d + \sqrt{\eta_1 \eta_2}\widetilde{\bm S}_{\bm G^\natural}\right)^t + \left(\bm I_d - \sqrt{\eta_1 \eta_2}\widetilde{\bm S}_{\bm G^\natural}\right)^t\bigg)\widetilde{\bm U}_{\bm G^\natural}^{\!\top}}_{:= \bm P_t^{\bm A}}\bm A_0\,,\\
            \left(\bm B^{\tt lin}_t\right)^{\!\top} & = \underbrace{\frac{1}{2}\sqrt{\frac{\eta_2}{\eta_1}}\widetilde{\bm V}_{\bm G^\natural}\bigg(\left(\bm I_d + \sqrt{\eta_1 \eta_2}\widetilde{\bm S}_{\bm G^\natural}\right)^t - \left(\bm I_d - \sqrt{\eta_1 \eta_2}\widetilde{\bm S}_{\bm G^\natural}\right)^t\bigg)\widetilde{\bm U}_{\bm G^\natural}^{\!\top}}_{:=\bm P_t^{\bm B}}\bm A_0\,.
        \end{aligned}\right.
    \end{align*}
    Furthermore, if $\widetilde{\bm X}^{\!\top}\widetilde{\bm X}$ is non-singular, $ \bm P_t^{\bm A}$ is a full rank matrix and singular values are 1 after the $r^*$-th order. $ \bm P_t^{\bm B}$ is a rank-$r^*$ matrix.
\end{lemma}

\begin{proof}
    We start with the special case $d=k$ and then discuss the case of $d \neq k$.
    For the case of $d = k$, we have
    \begin{align*}
        \bm Z^{\tt lin}_t = \bm H^t \bm Z_0 = (\mathbf{C}\mathbf{T}\mathbf{C}^{\!\top})^t\bm Z_0 = \mathbf{C}\mathbf{T}^t\mathbf{C}^{\!\top}\bm Z_0\,,
    \end{align*}
    where the last equality follows from the fact that $\mathbf{C}$ is an orthogonal matrix. Next, we compute $\mathbf{T}^t$
    \begin{align}
        \mathbf{T}^t & = \begin{bmatrix}
            \left(\bm I_d + \sqrt{\eta_1 \eta_2}\widetilde{\bm S}_{\bm G^\natural}\right)^t & \underbrace{(\eta_1 - \eta_2) \widetilde{\bm S}_{\bm G^\natural}\left(\sum_{j=0}^{t-1} \left(\bm I_d - \sqrt{\eta_1 \eta_2}\widetilde{\bm S}_{\bm G^\natural}\right)^{t-j-1}\left(\bm I_d + \sqrt{\eta_1 \eta_2}\widetilde{\bm S}_{\bm G^\natural}\right)^{j}\right)}_{:= \mathbf{D}^t}\\
            \bm 0_{d\times d} & \left(\bm I_d - \sqrt{\eta_1 \eta_2}\widetilde{\bm S}_{\bm G^\natural}\right)^t
        \end{bmatrix}\label{T^t}\,.
    \end{align}
    We first deal with the upper-right part $\mathbf{D}^t$.
    It is a mix of several diagonal matrices under addition and multiplications, leading to be a diagonal matrix again, i.e., $\mathbf{D}^t_{(i,j)}=0, \forall i \neq j$. 
   Note that the diagonal matrix $\widetilde{\bm S}_{\bm G^\natural}$ is a rank-$r^*$ matrix, we have
   $\mathbf{D}^t_{(i,i)}=0$ for $(r^*+1)\leq i \leq d$. Accordingly, we only need to handle $\mathbf{D}^t_{(i,i)}$ in the $1\leq i \leq r^*$ part
    \begin{align*}
        \mathbf{D}^t_{(i,i)} & = (\eta_1 - \eta_2) \sigma_i^* \left(\sum_{j=0}^{t-1} \left(1 - \sqrt{\eta_1 \eta_2}\,\sigma_i^*\right)^{t-j-1}\left(1 + \sqrt{\eta_1 \eta_2}\,\sigma_i^*\right)^{j}\right)\\
        & = (\eta_1 - \eta_2) \sigma_i^* \frac{\left(1 + \sqrt{\eta_1 \eta_2}\,\sigma_i^*\right)^t - \left(1 - \sqrt{\eta_1 \eta_2}\,\sigma_i^*\right)^t}{ 2\sqrt{\eta_1 \eta_2}\,\sigma_i^*}\\
        & = \frac{\eta_1 - \eta_2}{2\sqrt{\eta_1 \eta_2}}\Bigg(\left(1 + \sqrt{\eta_1 \eta_2}\,\sigma_i^*\right)^t - \left(1 - \sqrt{\eta_1 \eta_2}\,\sigma_i^*\right)^t\Bigg)\,,
    \end{align*}
    where we use $\sum_{j=0}^{t-1}x^{t-j-1}y^j=\frac{x^t-y^t}{x-y}$. Therefore, we can conclude 
    \begin{align*}
        \mathbf{T}^t & = \begin{bmatrix}
            \left(\bm I_d + \sqrt{\eta_1 \eta_2}\widetilde{\bm S}_{\bm G^\natural}\right)^t & \frac{\eta_1 - \eta_2}{2\sqrt{\eta_1 \eta_2}}\Bigg(\left(\bm I_d + \sqrt{\eta_1 \eta_2}\widetilde{\bm S}_{\bm G^\natural}\right)^t - \left(\bm I_d - \sqrt{\eta_1 \eta_2}\widetilde{\bm S}_{\bm G^\natural}\right)^t\Bigg)\\
            \bm 0_{d\times d} & \left(\bm I_d - \sqrt{\eta_1 \eta_2}\widetilde{\bm S}_{\bm G^\natural}\right)^t
        \end{bmatrix}\,.
    \end{align*}
    Finally, we can derive the following recursion
    {\begin{align*}
    & \bm Z^{\tt lin}_t
    =  \bm H^t\bm Z_0\\
    = & \frac{1}{\sqrt{1+\frac{\eta_2}{\eta_1}}}\begin{bmatrix}
        \widetilde{\bm U}_{\bm G^\natural} & -\sqrt{\frac{\eta_2}{\eta_1}}\widetilde{\bm U}_{\bm G^\natural}\\
        \sqrt{\frac{\eta_2}{\eta_1}}\widetilde{\bm V}_{\bm G^\natural} & \widetilde{\bm V}_{\bm G^\natural}
    \end{bmatrix}\\
    & \times \begin{bmatrix}
            \left(\bm I_d + \sqrt{\eta_1 \eta_2}\widetilde{\bm S}_{\bm G^\natural}\right)^t & \frac{\eta_1 - \eta_2}{2\sqrt{\eta_1 \eta_2}}\Bigg(\left(\bm I_d + \sqrt{\eta_1 \eta_2}\widetilde{\bm S}_{\bm G^\natural}\right)^t - \left(\bm I_d - \sqrt{\eta_1 \eta_2}\widetilde{\bm S}_{\bm G^\natural}\right)^t\Bigg)\\
            \bm 0_{d\times d} & \left(\bm I_d - \sqrt{\eta_1 \eta_2}\widetilde{\bm S}_{\bm G^\natural}\right)^t\,.
        \end{bmatrix}\mathbf{C}^{\!\top}\bm Z_0\\
    = & \begin{bmatrix}
            \widetilde{\bm U}_{\bm G^\natural}\left(\bm I_d + \sqrt{\eta_1 \eta_2}\widetilde{\bm S}_{\bm G^\natural}\right)^t & \frac{\eta_1 - \eta_2}{2\sqrt{\eta_1 \eta_2}}\widetilde{\bm U}_{\bm G^\natural}\left(\bm I_d + \sqrt{\eta_1 \eta_2}\widetilde{\bm S}_{\bm G^\natural}\right)^t - \frac{1}{2}\left(\sqrt{\frac{\eta_1}{\eta_2}}+\sqrt{\frac{\eta_2}{\eta_1}}\right)\widetilde{\bm U}_{\bm G^\natural}\left(\bm I_d - \sqrt{\eta_1 \eta_2}\widetilde{\bm S}_{\bm G^\natural}\right)^t\\
            \sqrt{\frac{\eta_2}{\eta_1}}\widetilde{\bm V}_{\bm G^\natural}\left(\bm I_d + \sqrt{\eta_1 \eta_2}\widetilde{\bm S}_{\bm G^\natural}\right)^t & \frac{1}{2}\left(1-\frac{\eta_2}{\eta_1}\right)\widetilde{\bm V}_{\bm G^\natural}\left(\bm I_d + \sqrt{\eta_1 \eta_2}\widetilde{\bm S}_{\bm G^\natural}\right)^t + \frac{1}{2}\left(1+\frac{\eta_2}{\eta_1}\right)\widetilde{\bm V}_{\bm G^\natural}\left(\bm I_d - \sqrt{\eta_1 \eta_2}\widetilde{\bm S}_{\bm G^\natural}\right)^t
        \end{bmatrix}\\
        & \times \frac{\mathbf{C}^{\!\top}\bm Z_0}{\sqrt{1+\frac{\eta_2}{\eta_1}}}\\
        = & \begin{bmatrix}
            \frac{1}{2}\widetilde{\bm U}_{\bm G^\natural}\bigg(\left(\bm I_d + \sqrt{\eta_1 \eta_2}\widetilde{\bm S}_{\bm G^\natural}\right)^t + \left(\bm I_d - \sqrt{\eta_1 \eta_2}\widetilde{\bm S}_{\bm G^\natural}\right)^t\bigg)\widetilde{\bm U}_{\bm G^\natural}^{\!\top} & * \quad\quad\\
            \frac{1}{2}\sqrt{\frac{\eta_2}{\eta_1}}\widetilde{\bm V}_{\bm G^\natural}\bigg(\left(\bm I_d + \sqrt{\eta_1 \eta_2}\widetilde{\bm S}_{\bm G^\natural}\right)^t - \left(\bm I_d - \sqrt{\eta_1 \eta_2}\widetilde{\bm S}_{\bm G^\natural}\right)^t\bigg)\widetilde{\bm U}_{\bm G^\natural}^{\!\top} & * \quad\quad
        \end{bmatrix}\begin{bmatrix}
            \bm A_0 \\ \bm 0
        \end{bmatrix}\\
        = & \begin{bmatrix}
            \frac{1}{2}\widetilde{\bm U}_{\bm G^\natural}\bigg(\left(\bm I_d + \sqrt{\eta_1 \eta_2}\widetilde{\bm S}_{\bm G^\natural}\right)^t + \left(\bm I_d - \sqrt{\eta_1 \eta_2}\widetilde{\bm S}_{\bm G^\natural}\right)^t\bigg)\widetilde{\bm U}_{\bm G^\natural}^{\!\top}\bm A_0\\
            \frac{1}{2}\sqrt{\frac{\eta_2}{\eta_1}}\widetilde{\bm V}_{\bm G^\natural}\bigg(\left(\bm I_d + \sqrt{\eta_1 \eta_2}\widetilde{\bm S}_{\bm G^\natural}\right)^t - \left(\bm I_d - \sqrt{\eta_1 \eta_2}\widetilde{\bm S}_{\bm G^\natural}\right)^t\bigg)\widetilde{\bm U}_{\bm G^\natural}^{\!\top}\bm A_0
        \end{bmatrix}\,.
    \end{align*}}
    Next, we extend the results above to $d\neq k$. Here we take $d>k$,
    \begin{align*}
        \underline{\bm B}^{\tt lin}_t & = \frac{1}{2}\sqrt{\frac{\eta_2}{\eta_1}}\underline{\widetilde{\bm V}_{\bm G^\natural}}\bigg(\left(\bm I_d + \sqrt{\eta_1 \eta_2}\underline{\widetilde{\bm S}_{\bm G^\natural}}\right)^t - \left(\bm I_d - \sqrt{\eta_1 \eta_2}\underline{\widetilde{\bm S}_{\bm G^\natural}}\right)^t\bigg)\widetilde{\bm U}_{\bm G^\natural}^{\!\top}\bm A_0\\
        & = \begin{bmatrix}
            \frac{1}{2}\sqrt{\frac{\eta_2}{\eta_1}}\widetilde{\bm V}_{\bm G^\natural}\bigg(\left(\bm I_d + \sqrt{\eta_1 \eta_2}\widetilde{\bm S}_{\bm G^\natural}\right)^t - \left(\bm I_d - \sqrt{\eta_1 \eta_2}\widetilde{\bm S}_{\bm G^\natural}\right)^t\bigg)\widetilde{\bm U}_{\bm G^\natural}^{\!\top}\bm A_0 & \bm 0_{r \times (d-k)}
        \end{bmatrix}\,,
    \end{align*}
    which proves the claim. Lastly, we take $d<k$,
    \begin{align*}
        \underline{\bm A}^{\tt lin}_t & = \frac{1}{2}\underline{\widetilde{\bm U}_{\bm G^\natural}}\bigg(\left(\bm I_k + \sqrt{\eta_1 \eta_2}\underline{\widetilde{\bm S}_{\bm G^\natural}}\right)^t + \left(\bm I_k - \sqrt{\eta_1 \eta_2}\underline{\widetilde{\bm S}_{\bm G^\natural}}\right)^t\bigg)\underline{\widetilde{\bm U}_{\bm G^\natural}}^{\!\top}\underline{\bm A_0}\\
        & \begin{bmatrix}
            \frac{1}{2}\widetilde{\bm U}_{\bm G^\natural}\bigg(\left(\bm I_d + \sqrt{\eta_1 \eta_2}\widetilde{\bm S}_{\bm G^\natural}\right)^t + \left(\bm I_d - \sqrt{\eta_1 \eta_2}\widetilde{\bm S}_{\bm G^\natural}\right)^t\bigg)\widetilde{\bm U}_{\bm G^\natural}^{\!\top}\bm A_0 \\
            \bm 0_{(k-d) \times r}
        \end{bmatrix}\,,
    \end{align*}
    which completes the proof.

    Besides, we discuss about some properties of $\bm P_t^{\bm A}$ and $\bm P_t^{\bm B}$. Recall $\operatorname{Rank}({\bm G}^{\natural}) = \operatorname{Rank}(\Delta) = r^*$, then we have
    \begin{align*}
        \lambda_{r^*+i}(\bm P_t^{\bm A}) & = \frac{1}{2}\lambda_{r^*+i}\left((\bm I_d+\sqrt{\eta_1 \eta_2}\widetilde{\bm S}_{\bm G^\natural})^t + (\bm I_d-\sqrt{\eta_1 \eta_2}\widetilde{\bm S}_{\bm G^\natural})^t\right)=1\,,\quad \text{for }\forall\,1\leq i \leq (d-r^*)\,.
    \end{align*}
   That means $ \bm P_t^{\bm A} \in \mathbb{R}^{d \times d}$ is a full rank matrix and the  singular values are 1 after the $r^*$-th order. However $ \bm P_t^{\bm B} \in \mathbb{R}^{k \times k} $ is a rank-$r^*$ matrix.\\
\end{proof}

\noindent
{\bf Part II: Control $\|\bm E_t\|_{op}$}\\

Based on the above results, we are ready to prove that $\|\bm E_t\|_{op}$ is small.
\begin{lemma}\label{E_t_A_0}
Under assumptions in \cref{sec:assumptions} for the linear setting, with LoRA initialization \eqref{eq:lorainit}, given $\| \bm A_0\|_{op}$ and $\bm G^{\natural}$ in \cref{eq:G} and its largest singular value $\lambda_1(\bm G^{\natural})$, 
consider the following time period
\begin{equation*}\label{eq:t*}
t \leq t^* : =\frac{\ln\left(\frac{\lambda_1(\bm G^{\natural})}{6\,\zeta(\eta_1\,,\eta_2) \|\bm A_0\|_{op}^2}\right)}{3\ln\left(1+\sqrt{\eta_1 \eta_2}\lambda_1({\bm G}^{\natural})\right)}\,,  
\end{equation*}
where $\zeta(\eta_1\,,\eta_2)$ is a function of $\eta_1\,,\eta_2$ defined as
\begin{equation}\label{eq:funczeta}
\zeta(\eta_1\,,\eta_2) := \max\left\{1,\,\frac{1}{2}\sqrt{\frac{\eta_2}{\eta_1}}\right\} \times \max\left\{\left(\sqrt{\frac{\eta_2}{\eta_1}} + \frac{1}{2}\right),\,\left(\sqrt{\frac{\eta_1}{\eta_2}}+\sqrt{\frac{\eta_2}{\eta_1}}\right)\right\}\,,  
\end{equation}
then the following statement holds with probability at least $1- 2C\exp(-N)$ for a universal constant $C$ over random Gaussian data
\begin{align}
\label{E_t_A0}
    \|\bm E_t\|_{op} \leq \|\bm A_0\|_{op}\,.
\end{align}
\end{lemma}

\noindent
{\bf Remark:} By choosing proper random initialization variance over $\bm A_0$, we can ensure $t^* > 1$ to avoid vacuous upper bound.

\begin{proof}
We will prove by induction. Starting from $t=0$, this is trivially true since $\bm Z_0 = \bm Z^{\tt lin}_0$. Next, we assume \cref{E_t_A0} holds for $t-1$ with $t\geq 1$ and prove $\|\bm E_t\|_{op} \leq \|\bm A_0\|_{op}$.
To deliver the proof, denote $a_0:=\|\bm A_0\|_{op}$, from \cref{psuedo-dynamics}, we know that 
\begin{equation}\label{eq:normABt}
 \|\bm A^{\tt lin}_{t-1}\|_{op} \leq \left(1+\sqrt{\eta_1 \eta_2}\lambda_1({\bm G}^{\natural})\right)^{t-1} a_0\,, \quad   \|\bm B^{\tt lin}_{t-1}\|_{op} \leq \frac{1}{2}\sqrt{\frac{\eta_1}{\eta_2}}\left(1+\sqrt{\eta_1 \eta_2}\lambda_1({\bm G}^{\natural})\right)^{t-1} a_0\,.
\end{equation}

Besides, since $(\bm A_t -\bm A^{\tt lin}_t)$ and $(\bm B_t -\bm B^{\tt lin}_t)$ are the sub-matrices of the error term $\bm E_t$, our condition $\|\bm E_{t-1}\|_{op} \leq \|\bm A_0\|_{op}$ we have 
\begin{align}\label{AB_t_diff}
    \left\|
        \bm A_{t-1} -\bm A^{\tt lin}_{t-1}
    \right\|_{op} \leq \|\bm E_{t-1}\|_{op}\,,\quad
    \left\|
        \bm B_{t-1} -\bm B^{\tt lin}_{t-1}
    \right\|_{op} \leq \|\bm E_{t-1}\|_{op}\, .
\end{align}
It implies that
\begin{equation}\label{A-B-pseudo-upper-bound}
\begin{split}
    & \|\bm A_{t-1}\|_{op} \leq \left(1+\sqrt{\eta_1 \eta_2}\lambda_1({\bm G}^{\natural})\right)^{t-1} a_0 + \|\bm E_{t-1}\|_{op}\,, \\ 
    & \|\bm B_{t-1}\|_{op} \leq \frac{1}{2}\sqrt{\frac{\eta_1}{\eta_2}}\left(1+\sqrt{\eta_1 \eta_2}\lambda_1({\bm G}^{\natural})\right)^{t-1} a_0 + \|\bm E_{t-1}\|_{op}\,.
\end{split}
\end{equation}
Besides, according to covariance matrix estimation in the operator norm in \cref{lem:conrg}, with probability at least $1-2C\exp(-N{\epsilon}^2)$ for a universal constant $C>0$, we have (taking $\epsilon=1$)
\begin{align}\label{eq:concenXX}
    \left\|\frac{1}{N}\widetilde{\bm X}^{\!\top}\widetilde{\bm X} - \bm I_d\right\|_{op} \leq \epsilon = 1\,.
\end{align} 
Accordingly, with probability at least $1-2C\exp(-N)$, $\|\widehat{\bm E}_t\|_{op}$ can be upper bounded by
\begin{align*}
    \|\widehat{\bm E}_t\|_{op} & \leq \eta_1 \left\|\frac{1}{N}\widetilde{\bm X}^{\!\top}\widetilde{\bm X}\bm A_{t-1} \bm B_{t-1} \bm B_{t-1}^{\!\top}\right\|_{op}+ \eta_2 \left\|\bm B_{t-1}^{\!\top}\bm A_{t-1}^{\!\top}\frac{1}{N}\widetilde{\bm X}^{\!\top}\widetilde{\bm X}\bm A_{t-1}\right\|_{op}\\
    & \leq \eta_1 (1+\epsilon) \|\bm A_{t-1}\|_{op} \|\bm B_{t-1}\|_{op}^2 + \eta_2 (1+\epsilon) \|\bm A_{t-1}\|_{op}^2 \|\bm B_{t-1}\|_{op} \quad \tag*{\color{teal}[using~\cref{eq:concenXX}]} \\
    & \leq (1+\epsilon) \left(\|\bm A^{\tt lin}_{t-1}\|_{op}+\|\bm E_{t-1}\|_{op}\right) \left(\|\bm B^{\tt lin}_{t-1}\|_{op}+\|\bm E_{t-1}\|_{op}\right)\times\\
    & \quad \left(\eta_1 \|\bm B^{\tt lin}_{t-1}\|_{op} + \eta_2 \|\bm A^{\tt lin}_{t-1}\|_{op}+\left(\eta_1+\eta_2\right)\|\bm E_{t-1}\|_{op}\right) \quad \tag*{\color{teal}[using~\cref{AB_t_diff}]} \\
    & \leq (1+\epsilon) \sqrt{\eta_1 \eta_2} \left(\left(1+\sqrt{\eta_1 \eta_2}\lambda_1({\bm G}^{\natural})\right)^{t-1} a_0+\|\bm E_{t-1}\|_{op}\right)\tag*{\color{teal}[using~\cref{A-B-pseudo-upper-bound}]}\\
    &\quad \times \left(\frac{1}{2}\sqrt{\frac{\eta_2}{\eta_1}}\left(1+\sqrt{\eta_1 \eta_2}\lambda_1({\bm G}^{\natural})\right)^{t-1} a_0+\|\bm E_{t-1}\|_{op}\right)\\
    & \quad \times \left(\left(\sqrt{\frac{\eta_2}{\eta_1}} + \frac{1}{2}\right)\left(1+\sqrt{\eta_1 \eta_2}\lambda_1({\bm G}^{\natural})\right)^{t-1} a_0 +\left(\sqrt{\frac{\eta_1}{\eta_2}}+\sqrt{\frac{\eta_2}{\eta_1}}\right)\|\bm E_{t-1}\|_{op}\right)\\
    & \leq (1+\epsilon) \underbrace{\max\left\{1,\,\frac{1}{2}\sqrt{\frac{\eta_2}{\eta_1}}\right\} \times \max\left\{\left(\sqrt{\frac{\eta_2}{\eta_1}} + \frac{1}{2}\right),\,\left(\sqrt{\frac{\eta_1}{\eta_2}}+\sqrt{\frac{\eta_2}{\eta_1}}\right)\right\}}_{:=\zeta(\eta_1\,,\eta_2)}\times \\ 
    & \left(\left(1+\sqrt{\eta_1 \eta_2}\lambda_1({\bm G}^{\natural})\right)^{t-1} a_0+\|\bm E_{t-1}\|_{op}\right)^3\\
    & \leq 4 (1+\epsilon) \sqrt{\eta_1 \eta_2} \,\zeta(\eta_1\,,\eta_2) \left(\left(1+\sqrt{\eta_1 \eta_2}\lambda_1({\bm G}^{\natural})\right)^{3t-3} a_0^3+\|\bm E_{t-1}\|_{op}^3\right)\\
    & \leq 12 \sqrt{\eta_1 \eta_2} \,\zeta(\eta_1\,,\eta_2) \left(1+\sqrt{\eta_1 \eta_2}\lambda_1({\bm G}^{\natural})\right)^{3t-3} a_0^3 \,. \quad \tag*{\color{teal}[from our inductive hypothesis]} 
\end{align*}
Then, by Lemma~\ref{induc}, we can conclude that
\begin{align}
    \|\bm E_t\|_{op} & = \left\|\sum_{i=1}^t \bm H^{t-i} \widehat{\bm E}_i \right\|_{op} \leq \sum_{i=1}^t \|\bm H\|_{op}^{t-i} \|\widehat{\bm E}_i\|_{op}\nonumber\\
    & \leq 12 \sqrt{\eta_1 \eta_2} \,\zeta(\eta_1\,,\eta_2) a_0^3 \times \sum_{i=1}^t  \left(1+\sqrt{\eta_1 \eta_2}\lambda_1({\bm G}^{\natural})\right)^{t+2i-3} \quad \tag*{\color{teal}[using~\cref{H-schur}]} \nonumber\\
    & = 12 \sqrt{\eta_1 \eta_2} \,\zeta(\eta_1\,,\eta_2) a_0^3 \times \left(1+\sqrt{\eta_1 \eta_2}\lambda_1({\bm G}^{\natural})\right)^{t-1}\sum_{i=1}^t  \left(1+\sqrt{\eta_1 \eta_2}\lambda_1({\bm G}^{\natural})\right)^{2i-2} \nonumber\\
    & = 12 \sqrt{\eta_1 \eta_2} \,\zeta(\eta_1\,,\eta_2) a_0^3 \times \left(1+\sqrt{\eta_1 \eta_2}\lambda_1({\bm G}^{\natural})\right)^{t-1} \frac{\left(1+\sqrt{\eta_1 \eta_2}\lambda_1({\bm G}^{\natural})\right)^{2t}-1}{\left(1+\sqrt{\eta_1 \eta_2}\lambda_1({\bm G}^{\natural})\right)^2-1} \quad \tag*{\color{teal}[geometric series]} \nonumber\\
    & \leq 12 \sqrt{\eta_1 \eta_2} \,\zeta(\eta_1\,,\eta_2) a_0^3 \times \left(1+\sqrt{\eta_1 \eta_2}\lambda_1({\bm G}^{\natural})\right)^{t-1} \frac{\left(1+\sqrt{\eta_1 \eta_2}\lambda_1({\bm G}^{\natural})\right)^{2t+1}}{2\sqrt{\eta_1 \eta_2}\lambda_1({\bm G}^{\natural})}\nonumber\\
    & \leq 6 \zeta(\eta_1\,,\eta_2) \left(1+\sqrt{\eta_1 \eta_2}\lambda_1({\bm G}^{\natural})\right)^{3t} \frac{a_0^3}{\lambda_1({\bm G}^{\natural})}\label{E_t_induction}\,.
\end{align}
Accordingly, when $t \leq t^* := \frac{\ln\left(\frac{\lambda_1({\bm G}^{\natural})}{6\,\zeta(\eta_1\,,\eta_2) \|\bm A_0\|_{op}^2}\right)}{3\ln\left(1+\sqrt{\eta_1 \eta_2}\lambda_1({\bm G}^{\natural})\right)}$, we have
\begin{align*}
    \|\bm E_t\|_{op} \leq \|\bm A_0\|_{op}\,,
\end{align*}
which proves the claim.
\end{proof}

\subsubsection{Alignment to Negative Gradient of Full Fine-tuning}

Now we can apply \cref{E_t_A_0} to obtain
\[
\left\|\bm A_t -\bm A^{\tt lin}_t\right\|_{op} \leq \|\bm A_0\|_{op}\,.
\]
Recall \cref{psuedo-dynamics}, we can observe that the dynamic of $\bm A^{\tt lin}_t$ also follows an Oja's Power Method \citep{oja1982simplified}, which aligns $\bm A^{\tt lin}_t$'s left singular subspace to the left subspace of the initial negative gradient step ${\bm G}^{\natural}$ of full fine-tuning. We anticipate that $\lambda_{r^*}\left(\bm A_t\right)\gg\lambda_{r^*+1}\left(\bm A_t\right)$ for sufficiently large $t$. Furthermore, if $\|\bm E_t\|_{op}$ remains small, then the top-$r^*$ left singular subspace of $\bm A_t$ can closely align to ${\bm G}^{\natural}$'s. To prove this alignment, we modify \citet[Lemma 8.3]{stoger2021small} to obtain the following results.
\begin{lemma}
\label{Mahdi}
Under assumptions in \cref{sec:assumptions} for the linear setting, recall
\begin{align*}
    \bm P_t^{\bm A}:=\frac{1}{2}\widetilde{\bm U}_{\bm G^\natural}\bigg(\left(\bm I_d + \sqrt{\eta_1 \eta_2}\widetilde{\bm S}_{\bm G^\natural}\right)^t + \left(\bm I_d - \sqrt{\eta_1 \eta_2}\widetilde{\bm S}_{\bm G^\natural}\right)^t\bigg)\widetilde{\bm U}_{\bm G^\natural}^{\!\top}
\end{align*}
as an $\mathbb{R}^{d\times d}$-valued symmetric matrix in \cref{psuedo-dynamics}, we assume that
    \begin{align*}
        \lambda_{r^*+1}(\bm P_t^{\bm A})\|\bm A_0\|_{op}+\|\bm E_t\|_{op} < \lambda_{r^*}(\bm P_t^{\bm A})\lambda_{\min}(\bm U^{\!\top}_{r^*}(\bm P_t^{\bm A}) \bm A_0)\, ,
    \end{align*}
    that can be satisfied under certain conditions (discussed later).
    Then the following three inequalities hold:
    \begin{align}
        \lambda_{r^*}(\bm P_t^{\bm A}\bm A_0+\bm E_t) & \geq \lambda_{r^*}(\bm P_t^{\bm A})\lambda_{\min}(\bm U^{\!\top}_{r^*}(\bm P_t^{\bm A}) \bm A_0)-\|\bm E_t\|_{op}\,, \label{eq:rP} \\
        \lambda_{r^*+1}(\bm P_t^{\bm A}\bm A_0+\bm E_t) & \leq \lambda_{r^*+1}(\bm P_t^{\bm A})\|\bm A_0\|_{op} + \|\bm E_t\|_{op}\,, \label{eq:r1P} \\
        \|\bm U^{\!\top}_{r^*,\perp}(\bm P_t^{\bm A})\bm U_{r^*}(\bm P_t^{\bm A}\bm A_0+\bm E_t)\|_{op} & \leq \frac{\lambda_{r^*+1}(\bm P_t^{\bm A})\|\bm A_0\|_{op} + \|\bm E_t\|_{op}}{\lambda_{r^*}(\bm P_t^{\bm A})\lambda_{\min}(\bm U^{\!\top}_{r^*}(\bm P_t^{\bm A}) \bm A_0) - \lambda_{r^*+1}(\bm P_t^{\bm A})\|\bm A_0\|_{op}-\|\bm E_t\|_{op}}\,, \label{eq:angle}
    \end{align}
    where $\bm U_k(\bm M)$ denotes the left singular subspace spanned by the $k$ largest singular values of the input matrix $\bm M$ and $\bm U_{k,\perp}(\bm M)$ denotes the left singular subspace orthogonal to $\bm U_{k}\left(\bm{M}\right)$.
\end{lemma}
This lemma can help us derive the principle angle of the left singular subspace between $\bm A^{\tt lin}_t$ and $\bm A_t$. Note that the assumption comes from the necessary condition of Wedin's $\sin \theta$ theorem \citep{wedin1972perturbation}. In the next lemma, we aim to derive the time threshold which can fulfill this assumption.
\begin{lemma}\label{lemma:aligntheta}
Under assumptions in \cref{sec:assumptions} for the linear setting, given $\| \bm A_0\|_{op}$, 
    for any $\theta \in (0,1)$, taking
    \[
    t \leq \frac{\ln\left(\frac{8\|\bm A_0\|_{op}}{\theta \lambda_{\min}(\bm U^{\!\top}_{r^*}(\bm P_t^{\bm A}) \bm A_0)}\right)}{\ln\left(1+\sqrt{\eta_1 \eta_2}\lambda_{r^*}\left({\bm G}^{\natural}\right)\right)}\,,
    \]
     then \cref{eq:angle} holds with probability at least $1- 2C\exp(- N)$ for a universal constant $C$ over random Gaussian data, i.e. 
    \begin{align*}
        \|\bm U^{\!\top}_{r^*,\perp}(\bm P_t^{\bm A})\bm U_{r^*}(\bm P_t^{\bm A}\bm A_0+\bm E_t)\|_{op} & \leq \theta\, .
    \end{align*}
\end{lemma}
\noindent {\bf Remark:} To ensure that the $\theta$-alignment phase still falls into the early phase in \cref{E_t_A_0} for $\| \bm E_t \|_{op} \leq \| \bm A_0 \|_{op}$, we need to choose proper initialization for $\bm A_0$.
We will detail this in \cref{thm:alignlinearA} later.
\begin{proof}
    First, $\lambda_{r^*}(\bm P_t^{\bm A})$ in \cref{psuedo-dynamics} can be lower bounded by
    \begin{equation}\label{eq:lambdarpta}
      \begin{split}
            \lambda_{r^*}(\bm P_t^{\bm A}) & = \frac{1}{2}\lambda_{r^*}\left((\bm I_d+\sqrt{\eta_1 \eta_2}\widetilde{\bm S}_{\bm G^\natural})^t + (\bm I_d-\sqrt{\eta_1 \eta_2}\widetilde{\bm S}_{\bm G^\natural})^t\right)\\ 
        & \geq \frac{1}{2}\lambda_{r^*}\left((\bm I_d+\sqrt{\eta_1 \eta_2}\widetilde{\bm S}_{\bm G^\natural})^t\right)\\
        & = \frac{1}{2}\left(1+\sqrt{\eta_1 \eta_2}\lambda_{r^*}\left({\bm G}^{\natural}\right)\right)^t\,.
      \end{split}  
    \end{equation}

    Recall \cref{psuedo-dynamics}, we have $\lambda_{r^*+1}(\bm P_t^{\bm A}) = 1$ and \cref{E_t_A_0} with $\|\bm E_t\|_{op} \leq \|\bm A_0\|_{op}$, we define the following threshold $\gamma$ and upper bound it
    \begin{align}
        \gamma & := \frac{\lambda_{r^*+1}(\bm P_t^{\bm A})\|\bm A_0\|_{op}+\|\bm E_t\|_{op}}{\lambda_{r^*}(\bm P_t^{\bm A})\lambda_{\min}(\bm U^{\!\top}_{r^*}(\bm P_t^{\bm A}) \bm A_0)}\nonumber\\
        & \leq \frac{2\|\bm A_0\|_{op}}{\frac{1}{2}\left(1+\sqrt{\eta_1 \eta_2}\lambda_{r^*}\left({\bm G}^{\natural}\right)\right)^t \lambda_{\min}(\bm U^{\!\top}_{r^*}(\bm P_t^{\bm A}) \bm A_0)} \quad \tag*{\color{teal}[using~\cref{psuedo-dynamics},~\ref{E_t_A_0}]} \nonumber\\
        & = \exp\left(-\ln\left(1+\sqrt{\eta_1 \eta_2}\lambda_{r^*}\left({\bm G}^{\natural}\right)\right)\cdot t\right)\cdot\frac{4\|\bm A_0\|_{op}}{\lambda_{\min}(\bm U^{\!\top}_{r^*}(\bm P_t^{\bm A}) \bm A_0)}\, .\label{gamma-upper-bound}
    \end{align}
    Set $\theta\in(0,1)$, let Eq.(\ref{gamma-upper-bound})$\leq \frac{\theta}{2}$, then we have that
    \begin{align*}
        \|\bm U^{\!\top}_{r^*,\perp}(\bm P_t^{\bm A})\bm U_{r^*}(\bm P_t^{\bm A}\bm A_0+\bm E_t)\|_{op} & \leq \theta\, .
    \end{align*}
    The time $t$ to achieve this angle $\theta$ can be upper bounded by
    \begin{align*}
        \exp\left(-\ln\left(1+\sqrt{\eta_1 \eta_2}\lambda_{r^*}\left({\bm G}^{\natural}\right)\right)\cdot t\right)\cdot\frac{4\|\bm A_0\|_{op}}{\lambda_{\min}(\bm U^{\!\top}_{r^*}(\bm P_t^{\bm A}) \bm A_0)} \leq \frac{\theta}{2}\,,
        \end{align*}
   which implies that     
        \begin{align*}
        t \leq \frac{\ln\left(\frac{8\|\bm A_0\|_{op}}{\theta \lambda_{\min}(\bm U^{\!\top}_{r^*}(\bm P_t^{\bm A}) \bm A_0)}\right)}{\ln\left(1+\sqrt{\eta_1 \eta_2}\lambda_{r^*}\left({\bm G}^{\natural}\right)\right)}\, .
    \end{align*}
    Finally we conclude the proof.
\end{proof}

\begin{theorem}\label{thm:alignlinearA:full}[Full version of \cref{thm:alignlinearA}]
    Under assumptions in \cref{sec:assumptions} for the linear setting, recall ${\bm G}^{\natural}$ defined in \cref{eq:G} with its condition number $\kappa^{\natural}$, we consider random Gaussian initialization $\bm A_0 \in \mathbb{R}^{d \times r}$ with $[\bm A_0]_{ij} \sim \mathcal{N}(0, \alpha^2)$ in \eqref{eq:lorainit}, for any $\theta \in (0,1)$, let $\xi = o(1)$ be chosen such that
\begin{equation*}
    \alpha \leq
\begin{cases} 
\left(\frac{\theta \xi}{24r\sqrt{d}}\right)^{\frac{3\kappa^\natural}{2}}\sqrt{\frac{\lambda_1({\bm G}^{\natural})}{54d\,\zeta(\eta_1, \eta_2)}} & \text{if } r^*\leq r < 2r^*, \\
\left(\frac{\theta}{24\sqrt{d}}\right)^{\frac{3\kappa^\natural}{2}}\sqrt{\frac{\lambda_1({\bm G}^{\natural})}{54d\,\zeta(\eta_1, \eta_2)}} & \text{if } r \geq 2r^*\,,
\end{cases}
\end{equation*}
where $\zeta(\eta_1, \eta_2)$ is defined in \cref{eq:funczeta} and satisfies $\zeta(\eta_1, \eta_2) = \Theta(1)$.
Then if we run gradient descent for $t^*$ steps with
\begin{align*}
    t^* \lesssim 
    \begin{cases}
        \frac{\ln\left(\frac{24r\sqrt{d}}{\theta \xi}\right)}{\ln\left(1+\sqrt{\eta_1 \eta_2}\lambda_{r^*}\left({\bm G}^{\natural}\right)\right)}  & \text{if } r^*\leq r < 2r^*, \\
        \frac{\ln\left(\frac{24\sqrt{d}}{\theta}\right)}{\ln\left(1+\sqrt{\eta_1 \eta_2}\lambda_{r^*}\left({\bm G}^{\natural}\right)\right)}  & \text{if } r \geq 2r^*\,,
    \end{cases}
\end{align*}
we have the following alignment on the left singular subspace between $\bm G^{\natural}$ and $\bm A_{t^*}$
    \begin{align*}
        &\left\|\bm U^{\!\top}_{r^*,\perp}(  \bm G^{\natural} )\bm U_{r^*}\left(\bm A_{t^*}\right)\right\|_{op} \lesssim \theta\,,\\
        &\mbox{with probability at least}~
        \begin{cases} 
1\!-\! C_1\exp(-d) \!-\! (C_2 \xi)^{r-r^*+1} \!-\! C_3\exp(-r) \!-\! C\exp(-N) & \text{if } r^*\leq r < 2r^*, \\
1 \!-\! C_4\exp(- d) -C_5\exp(- r) -C\exp(- N) & \text{if } r \geq 2r^*\,,
\end{cases}
    \end{align*}
for some positive constants $C\,,C_1\,,C_2\,,C_3\,,C_4\,,C_5$.
Here $\bm U_{r^*}(\bm A_{t^*})$ denotes the left singular subspace spanned by the $r^*$ largest singular values of $\bm A_{t^*}$ and $\bm U_{r^*,\perp}(\bm M)$ denotes the left singular subspace orthogonal to $\bm U_{r^*}\left(\bm{M}\right)$. Note that we can select any pair of stepsizes $(\eta_1\,,\eta_2)$ that satisfies the conditions $t^*>1$, $\eta_2 \geq \eta_1$, and $\zeta(\eta_1, \eta_2) = \Theta(1)$.
\end{theorem}
\begin{proof}
For ease of description, we denote $\bm A_0 := \alpha \bm T \in \mathbb{R}^{d \times r}$ where $\bm T$ is a standard random Gaussian matrix with zero-mean and unit variance.
Here we aim to choose a proper $\alpha$ to ensure that $\theta$-alignment phase in \cref{lemma:aligntheta} still falls into the early phase in \cref{E_t_A_0}, i.e.
    \begin{align*}
        & \frac{\ln\left(\frac{8\|\bm A_0\|_{op}}{\theta \lambda_{\min}(\bm U^{\!\top}_{r^*}(\bm P_t^{\bm A}) \bm A_0)}\right)}{\ln\left(1+\sqrt{\eta_1 \eta_2}\lambda_{r^*}\left({\bm G}^{\natural}\right)\right)} = \frac{\ln\left(\frac{\lambda_1({\bm G}^{\natural})}{6\,\zeta(\eta_1\,,\eta_2) \|\bm A_0\|_{op}^2}\right)}{3\ln\left(1+\sqrt{\eta_1 \eta_2}\lambda_1({\bm G}^{\natural})\right)}=t^*\\
        \Leftrightarrow\quad & \ln\left(\frac{8\|\bm A_0\|_{op}}{\theta \lambda_{\min}(\bm U^{\!\top}_{r^*}(\bm P_t^{\bm A}) \bm A_0)}\right) = \frac{\ln\left(1+\sqrt{\eta_1 \eta_2}\lambda_{r^*}\left({\bm G}^{\natural}\right)\right)}{3\ln\left(1+\sqrt{\eta_1 \eta_2}\lambda_1({\bm G}^{\natural})\right)}\ln\left(\frac{\lambda_1({\bm G}^{\natural})}{6\,\zeta(\eta_1\,,\eta_2) \|\bm A_0\|_{op}^2}\right)\\
        \Leftrightarrow\quad & \frac{8\|\bm A_0\|_{op}}{\theta \lambda_{\min}(\bm U^{\!\top}_{r^*}(\bm P_t^{\bm A}) \bm A_0)} = \left(\frac{\lambda_1({\bm G}^{\natural})}{6\,\zeta(\eta_1\,,\eta_2) \|\bm A_0\|_{op}^2}\right)^\frac{\ln\left(1+\sqrt{\eta_1 \eta_2}\lambda_{r^*}\left({\bm G}^{\natural}\right)\right)}{3\ln\left(1+\sqrt{\eta_1 \eta_2}\lambda_1({\bm G}^{\natural})\right)}\\
        \Leftrightarrow\quad & \theta = \frac{8\|\bm A_0\|_{op}}{\lambda_{\min}(\bm U^{\!\top}_{r^*}(\bm P_t^{\bm A}) \bm A_0)} \left(\frac{6\,\zeta(\eta_1\,,\eta_2) \|\bm A_0\|_{op}^2}{\lambda_1({\bm G}^{\natural})}\right)^{\frac{\ln\left(1+\sqrt{\eta_1 \eta_2}\lambda_{r^*}\left({\bm G}^{\natural}\right)\right)}{3\ln\left(1+\sqrt{\eta_1 \eta_2}\lambda_1({\bm G}^{\natural})\right)}}\\
        & = \frac{8\|\bm T\|_{op}}{\lambda_{\min}(\bm U^{\!\top}_{r^*}(\bm P_t^{\bm A}) \bm T)} \left(\frac{6\,\zeta(\eta_1\,,\eta_2) \|\bm T\|_{op}^2}{\lambda_1({\bm G}^{\natural})}\right)^\iota \alpha^{2\iota}\,. \tag*{\color{teal}$\left[\text{by setting }\iota:=\frac{\ln\left(1+\sqrt{\eta_1 \eta_2}\lambda_{r^*}\left({\bm G}^{\natural}\right)\right)}{3\ln\left(1+\sqrt{\eta_1 \eta_2}\lambda_1({\bm G}^{\natural})\right)}\right]$}
    \end{align*}
    In the next, we will discuss how to pick up $\alpha$.
     According to \cref{lem:min-singular-conct}, we need to consider the following two cases on the relationship between $r^*$ and $r$.
    
    {\bf Case 1.} $r^*\leq r < 2r^*$: by \cref{lem:init-op-conct} and \cref{lem:min-singular-conct}, with probability at least $1-C_1 \exp(-d)-(C_2 \xi)^{r-r^*+1}-C_3\exp(-r)$ for some positive constants $C_1\,,C_2\,,C_3$, we have
    \begin{align}\label{eq:r2r}
        \frac{\|\bm T\|_{op}}{3\sqrt{d}} \leq 1\,,\quad \frac{\xi}{r\lambda_{\min}(\bm U^{\!\top}_{r^*}(\bm P_t^{\bm A}) \bm T)} \lesssim 1\,.
    \end{align}
    Here we pick
    \begin{align*}
        \alpha & \leq \left(\frac{\theta \xi}{24r\sqrt{d}}\right)^{\frac{3\kappa^\natural}{2}}\sqrt{\frac{\lambda_1({\bm G}^{\natural})}{54\,\zeta(\eta_1\,,\eta_2)d}}\,,
    \end{align*}
    then recall \cref{lemma:aligntheta} on the alignment, we take $\alpha$ here
    \begin{align*}
        & \left\|\bm U^{\!\top}_{r^*,\perp}\left(-\nabla_{\bm W}\widetilde{L}(\bm W^\natural)\right)\bm U_{r^*}\left(\bm A_{t^*}\right)\right\|_{op}\\
        \leq & \frac{8\|\bm T\|_{op}}{\lambda_{\min}(\bm U^{\!\top}_{r^*}(\bm P_t^{\bm A}) \bm T)} \left(\frac{6\,\zeta(\eta_1\,,\eta_2) \|\bm S\|_{op}^2}{\lambda_1({\bm G}^{\natural})}\right)^\iota \alpha^{2\iota}\\
        = & \frac{8\|\bm T\|_{op}}{\lambda_{\min}(\bm U^{\!\top}_{r^*}(\bm P_t^{\bm A}) \bm T)} \left(\frac{6\,\zeta(\eta_1\,,\eta_2) \|\bm S\|_{op}^2}{\lambda_1({\bm G}^{\natural})}\right)^\iota \left(\frac{\theta \xi}{24r\sqrt{d}}\right)^{3\kappa^\natural\iota}\left(\frac{\lambda_1({\bm G}^{\natural})}{54\,\zeta(\eta_1\,,\eta_2)d}\right)^\iota\\
        = & \frac{8\|\bm T\|_{op}}{\lambda_{\min}(\bm U^{\!\top}_{r^*}(\bm P_t^{\bm A}) \bm T)} \left(\frac{\|\bm T\|_{op}^2}{9d}\right)^\iota \left(\frac{\theta \xi}{24r\sqrt{d}}\right)^{3\kappa^\natural\iota}\\
        \leq & \frac{\|\bm T\|_{op}\theta \xi}{3r\sqrt{d}\lambda_{\min}(\bm U^{\!\top}_{r^*}(\bm P_t^{\bm A}) \bm T)} \left(\frac{\|\bm T\|_{op}^2}{9d}\right)^\iota\,.\quad \tag*{\color{teal}$\left[\text{since }\iota \geq 1/3\kappa^\natural\text{ and }\frac{\theta \xi}{24r\sqrt{d}}\in(0,1)\right]$}\\
    \end{align*}
    Then using \cref{eq:r2r}, with probability at least $1-C_1 \exp(-d)-(C_2 \xi)^{r-r^*+1}-C_3\exp(-r)$ for some positive constants $C_1\,,C_2\,,C_3$, we have
    \begin{align*}
        \left\|\bm U^{\!\top}_{r^*,\perp}\left(-\nabla_{\bm W}\widetilde{L}(\bm W^\natural)\right)\bm U_{r^*}\left(\bm A_{t^*}\right)\right\|_{op} & \lesssim \theta\,.
    \end{align*}
    And we can compute the upper bound of $t^*$ as
    \begin{align*}
        t^* &
        = \frac{\ln\left(\frac{8\|\bm A\|_{op}}{\theta \lambda_{\min}(\bm U^{\!\top}_{r^*}(\bm P_t^{\bm A}) \bm A)}\right)}{\ln\left(1+\sqrt{\eta_1 \eta_2}\lambda_{r^*}\left({\bm G}^{\natural}\right)\right)}
        \lesssim \frac{\ln\left(\frac{24r\sqrt{d}}{\theta \xi}\right)}{\ln\left(1+\sqrt{\eta_1 \eta_2}\lambda_{r^*}\left({\bm G}^{\natural}\right)\right)}\,.
    \end{align*}
   {\bf Case 2.} $r \geq 2r^*$: by \cref{lem:init-op-conct} and \cref{lem:min-singular-conct}, with probability at least $1-C_4 \exp(-d)-C_5 \exp(- r)$ for some positive constants $C_4\,,C_5$, we have
    \begin{align*}
        \frac{\|\bm T \|_{op}}{3\sqrt{d}} \leq 1\,,\quad \frac{1}{\lambda_{\min}(\bm U^{\!\top}_{r^*}(\bm P_t^{\bm A}) \bm T)} \lesssim 1\,.
    \end{align*}
   Here we pick
    \begin{align*}
        \alpha & \leq \left(\frac{\theta}{24\sqrt{d}}\right)^{\frac{3\kappa^\natural}{2}}\sqrt{\frac{\lambda_1({\bm G}^{\natural})}{54d\,\zeta(\eta_1\,,\eta_2)}}\,.
    \end{align*}
    Similarly, we can obtain
    \begin{align*}
        \left\|\bm U^{\!\top}_{r^*,\perp}\left(-\nabla_{\bm W}\widetilde{L}(\bm W^\natural)\right)\bm U_{r^*}\left(\bm A_t\right)\right\|_{op} & \leq \frac{\|\bm T \|_{op}\theta}{3\sqrt{d}\lambda_{\min}(\bm U^{\!\top}_{r^*}(\bm P_t^{\bm A}) \bm S)} \left(\frac{\|\bm S\|_{op}^2}{9d}\right)^\iota \lesssim \theta\,.
    \end{align*}
    And we can compute the upper bound of $t^*$ as
    \begin{align*}
        t^* &
        \leq \frac{\ln\left(\frac{24\sqrt{d}}{\theta}\right)}{\ln\left(1+\sqrt{\eta_1 \eta_2}\lambda_{r^*}\left({\bm G}^{\natural}\right)\right)}\,.
    \end{align*}
\end{proof}


\begin{theorem}
\label{linear-align-Bt}
    Under assumptions in \cref{sec:assumptions} for the linear setting, using the LoRA initialization for $\bm B_0 = \bm 0$, then for any time-step $t \in \mathbb{N}_+$, we have
    \begin{align*}
        \left\|\bm V^{\!\top}_{r^*,\perp}\left(-\nabla_{\bm W}\widetilde{L}(\bm W^\natural)\right)\bm V_{r^*}\left(\bm B_t\right)\right\|_{op} & = 0\,.
    \end{align*}
\end{theorem}
\begin{proof}
    We prove by induction. Recall the complete SVD of $\Delta$ in \cref{Delta-SVD} as
    \begin{align*}
    \Delta=\widetilde{\bm U} \widetilde{\bm S}^* \widetilde{\bm V}^{\!\top}=
    \begin{bmatrix}
        \bm U & \bm U_\perp
    \end{bmatrix}\begin{bmatrix}
       \bm S^* & \bm 0_{r^*\times (d-r^*)}\\
        \bm 0_{(d-r^*)\times r^*} & \bm 0_{(d-r^*)\times (d-r^*)}
    \end{bmatrix}\begin{bmatrix}
        \bm V^{\!\top} \\ \bm V_\perp^{\!\top}
    \end{bmatrix}\,.
\end{align*}
    For $t=1$, recall ${\bm G}^{\natural} = \frac{1}{N}\widetilde{\bm X}^{\!\top} \widetilde{\bm X}\Delta$ in \cref{eq:G}, we have
    \begin{align*}
        \bm B_1\bm V_\perp & = \frac{\eta_2}{N}\bm A_0^{\!\top}{\bm G}^{\natural}\bm V_\perp  = \frac{\eta_2}{N}\bm A_0^{\!\top}\widetilde{\bm X}^{\!\top}\widetilde{\bm X}\Delta\bm V_\perp = \bm 0_{r\times (d-r^*)}\,.
    \end{align*}
    Assume $\bm B_t\bm V_\perp = \bm 0_{r\times (d-r^*)}$ holds for any $t \in \mathbb{N}_+$ and $t \geq 2$, then
    \begin{align*}
        \bm B_{t+1}\bm V_\perp & = \bm B_t\bm V_\perp - \frac{\eta_2}{N}\bm A_t^{\!\top}\widetilde{\bm X}^{\!\top}\widetilde{\bm X}\bm A_t\bm B_t\bm V_\perp+\frac{\eta_2}{N}\bm A_t^{\!\top}{\bm G}^{\natural}\bm V_\perp= \bm 0_{r\times (d-r^*)}\,,
    \end{align*}
    which completes the claim. 
\end{proof}

\input{arxiv_template/appendix/Int_Linear_Spe}
\input{arxiv_template/appendix/scaled_GD}