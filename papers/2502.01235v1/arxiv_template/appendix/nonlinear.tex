\section{Proofs for Nonlinear Model}
\label{lora_nonlinear}

We deliver the proofs for nonlinear models in \cref{sec:nonlinear} here.
The problem setting and results for $\| \bm A_0 \bm B_0 - \Delta \|_{\rm F}$ are presented in \cref{app:problemnon}.
In \cref{app:loraspec}, we present the proofs of \cref{main:LC} as well as proofs for smoothed GD.

\subsection{Problem Settings and Spectral Initialization}
\label{app:problemnon}
Recall the pre-training model from \cref{assum:pre-trained-model}
\begin{align}
    f_\text{pre}\left(\bm x\right) & = \sigma\left(\bm x^{\!\top}\bm W^\natural\right)^{\!\top} \in \mathbb{R}^k \,,\quad \bm W^\natural\in\mathbb{R}^{d\times k}\,,
\end{align}
and the downstream teacher weights from \cref{assum:downstream-delta}
\begin{align*}
    \widetilde{\bm W}^\natural = \bm W^\natural+\Delta \in \mathbb{R}^{d \times k}\,, \quad \mbox{with}~  \widetilde{\bm W}^\natural := \begin{bmatrix}
        \widetilde{\bm w}_1^{\natural}, \widetilde{\bm w}_2^{\natural}, \cdots, \widetilde{\bm w}_k^{\natural}
    \end{bmatrix}\,.
\end{align*}


The empirical loss of LoRA fine-tuning is defined as
\begin{equation*}
    \begin{split}
        \widetilde{L}\left(\bm A_t, \bm B_t\right) & 
    = \frac{1}{2N}\left\|\sigma\left(\widetilde{\bm X}( \bm W^{\natural} + \bm A_t \bm B_t) \right) - \sigma\left(\widetilde{\bm X}\widetilde{\bm W}^\natural\right)\right\|_{\mathrm{F}}^2\,.
    \end{split}
\end{equation*}
Next, we can derive the empirical gradients for $\bm A_t$ and $\bm B_t$ respectively.
\begin{align}
       \nabla_{\bm A}\widetilde{L}\left(\bm A_t\,,\bm B_t\right) & = \frac{1}{N} \widetilde{\bm X}^{\top} \left[ \sigma\left(\widetilde{\bm X}(\bm W^{\natural} + \bm A_t \bm B_t) \right) - \sigma\left(\widetilde{\bm X}\widetilde{\bm W}^\natural\right) \right] \odot \sigma'\left(\widetilde{\bm X}(\bm W^{\natural} + \bm A_t \bm B_t)\right) \bm B_t^{\!\top}\nonumber\\
       & := \frac{1}{N} \widetilde{\bm X}^{\!\top} \left[ \sigma\left(\widetilde{\bm X}(\bm W_t) \right) - \sigma\left(\widetilde{\bm X}\widetilde{\bm W}^\natural\right) \right] \odot \sigma'\left(\widetilde{\bm X}\bm W_t\right) \bm B_t^{\!\top} \quad \tag*{\color{teal}[denote $\bm W_t := \bm W^{\natural} + \bm A_t \bm B_t$]}\nonumber\\
       & = - \left[ \underbrace{\frac{1}{N}\widetilde{\bm X}^{\!\top}\sigma\left(\widetilde{\bm X}\widetilde{\bm W}^\natural\right)\odot \sigma'\left(\widetilde{\bm X}\bm W_t\right)}_{:=\bm \Gamma_{1,t}}
    - \underbrace{\frac{1}{N}\widetilde{\bm X}^{\!\top}\sigma\left(\widetilde{\bm X}\bm W_t\right)\odot \sigma'\left(\widetilde{\bm X}\bm W_t\right)}_{:=\bm \Gamma_{2,t}} \right] \bm B_t^{\!\top}\label{I-def}\\
    & := - \bm J_{\bm W_t} \bm B_t^{\!\top} \tag*{\color{teal}[denote $\bm J_{\bm W_t} := \bm \Gamma_{1,t} - \bm \Gamma_{2,t}$]}\nonumber
\end{align}
where the matrix operator $\bm J_{\bm W}: \mathbb{R}^{d \times k} \rightarrow \mathbb{R}^{d \times k}$ is formally defined as (by denoting $\bm W_t := \bm W^{\natural} + \bm A_t \bm B_t$)
\begin{align}\label{JW}
    \bm J_{\bm W}:\bm W \rightarrow \frac{1}{N} \widetilde{\bm X}^{\!\top} \left[\sigma\left(\widetilde{\bm X}\widetilde{\bm W}^\natural\right)-\sigma\left(\widetilde{\bm X}(\bm W) \right)\right] \odot \sigma'\left(\widetilde{\bm X}\bm W\right)\,.
\end{align}
Similarly, we can compute
\begin{align*}
    \nabla_{\bm B}\widetilde{L}\left(\bm A_t\,,\bm B_t\right) & = \frac{1}{N} \bm A_t^{\!\top} \widetilde{\bm X}^{\!\top} \left[ \sigma\left(\widetilde{\bm X}(\bm W_t) \right) - \sigma\left(\widetilde{\bm X}\widetilde{\bm W}^\natural\right) \right] \odot \sigma'\left(\widetilde{\bm X}\bm W_t\right)\\
    & = - \bm A_t^{\!\top}\bm J_{\bm W_t}\,.
\end{align*}


For full fine-tuning, we consider the following empirical loss function over $\bm K \in \mathbb{R}^{d \times k}$
\begin{equation*}
    \begin{split}
        {L}\left(\bm K \right) & 
    = \frac{1}{2N}\left\|\sigma\left(\widetilde{\bm X}\bm K \right) - \sigma\left(\widetilde{\bm X}\widetilde{\bm W}^\natural\right)\right\|_{\mathrm{F}}^2\,.
    \end{split}
\end{equation*}
The gradient w.r.t. $\bm K$ is
\begin{equation*}
    \nabla L\left(\bm K\right) =  \frac{1}{N} \widetilde{\bm X}^{\!\top} \left[ \sigma\left(\widetilde{\bm X}\bm K \right) - \sigma\left(\widetilde{\bm X}\widetilde{\bm W}^\natural\right) \right] \odot \sigma'\left(\widetilde{\bm X}\bm K\right) 
\end{equation*}
Next, we can define the one-step negative gradient of full fine-tuning in the nonlinear case as
\begin{align*}
        \bm G^{\natural} & :=  - \nabla L\left(\bm W^{\natural}\right) \\
        & = \frac{1}{N} \widetilde{\bm X}^{\!\top} \left[ \sigma\left(\widetilde{\bm X}\widetilde{\bm W}^\natural\right)-\sigma\left(\widetilde{\bm X}\bm W^{\natural} \right)\right] \odot \sigma'\left(\widetilde{\bm X}\bm W^{\natural}\right)  \\
        & = \bm J_{\bm W^{\natural}}\,.\tag*{\color{teal}[by definition of $\bm J_{\bm W}$ in \cref{JW}]}
\end{align*}
Additionally, we define
\begin{equation}
\label{gamma-natural}
    \begin{split}
        \bm \Gamma_1^\natural & = \frac{1}{N} \widetilde{\bm X}^{\!\top} \sigma\left(\widetilde{\bm X}\widetilde{\bm W}^\natural\right)\odot \sigma'\left(\widetilde{\bm X}\bm W^{\natural}\right)\,,\\
        \bm \Gamma_2^\natural & = \frac{1}{N} \widetilde{\bm X}^{\!\top} \sigma\left(\widetilde{\bm X}\bm W^{\natural} \right) \odot \sigma'\left(\widetilde{\bm X}\bm W^{\natural}\right)\,.
    \end{split}
\end{equation}

In this section, we aim to analyze the initial properties of low-rank adapters under \eqref{eq:spectral-init-linear} in a nonlinear context. The high-level proof strategy begins with examining the spectral properties of the one-step full gradient matrix, $\bm{G}^\natural$. Unlike the linear case, the presence of nonlinearity prevents a direct analysis. To address this, we first establish the concentration of the empirical full gradient, leveraging the fact that the empirical gradient approximates its expectation closely when the sample size is sufficiently large.

Subsequently, we utilize tools from Hermite decomposition to derive useful properties of the expected gradients. These properties are then transferred back to the empirical gradients through concentration results. Finally, since low-rank adapters under \eqref{eq:spectral-init-linear} represent the best $r$-rank approximation of $\bm{G}^\natural$, we apply matrix analysis techniques to derive the desired results. Also, the concentration results in this part can serve as an important component for the later convergence analysis.


\subsubsection{Computation of Full Population Gradients}
First, we can simplify $\bm \Gamma_{1,t}$ and $\bm \Gamma_{2,t}$ which defined in \cref{I-def} to be
\begin{align*}
    \bm \Gamma_{1,t} & = \frac{1}{N} \sum_{i=1}^N \widetilde{\bm x}_i {\begin{bmatrix}
        \sigma \left(\widetilde{\bm x}_i^{\!\top}\widetilde{\bm w}_1^\natural\right)\sigma' \left(\widetilde{\bm x}_i^{\!\top}\bm w_{t,1}\right) &
        \hdots &
        \sigma \left(\widetilde{\bm x}_i^{\!\top}\widetilde{\bm w}_k^\natural\right) \sigma' \left(\widetilde{\bm x}_i^{\!\top}\bm w_{t,k}\right)
    \end{bmatrix}}\,,
\end{align*}
and
\begin{align*}
    \bm \Gamma_{2,t} & = \frac{1}{N} \sum_{i=1}^N \widetilde{\bm x}_i {\begin{bmatrix}
        \sigma \left(\widetilde{\bm x}_i^{\!\top}\bm w_{t,1}\right)\sigma' \left(\widetilde{\bm x}_i^{\!\top}\bm w_{t,1}\right)&
        \hdots &
        \sigma \left(\widetilde{\bm x}_i^{\!\top}\bm w_{t,k}\right) \sigma' \left(\widetilde{\bm x}_i^{\!\top}\bm w_{t,k}\right)
    \end{bmatrix}}\,,
\end{align*}
where $\bm w_{t,m}$ is the $m$-th column of $\bm W_t:= \widetilde{\bm W}^\natural + \bm A_t \bm B_t$ and $\widetilde{\bm w}^\natural_m$ is the $m$-th column of $\widetilde{\bm W}^\natural$.

The following two lemmas provide the columnwise expectation of $\bm \Gamma_{1,t}$ and $\bm \Gamma_{2,t}$ respectively.
\begin{lemma}
\label{I-expectation}
Under assumptions in \cref{sec:assumptions} for the nonlinear setting, for $\forall\,1\leq m \leq k$, we have
    \begin{align}\label{sigma-target-model-corr}
    \mathbb{E}_{\widetilde{\bm x}}\left[\widetilde{\bm x} \sigma' \left(\widetilde{\bm x}^{\!\top}\bm w_{t,m}\right) \sigma \left(\widetilde{\bm x}^{\!\top}\widetilde{\bm w}^\natural_m\right)\right]
    & = \sum_{j=0}^{\infty}\frac{c_{j+1}^2\left\langle\widetilde{\bm w}^\natural_m,\bm w_{t,m}\right\rangle^{j}}{(j+1)!(j+1)!}\widetilde{\bm w}^\natural_m + \sum_{j= 0}^{\infty}\frac{c_{j+2}c_{j}\left\langle\widetilde{\bm w}^\natural_m,\bm w_{t,m}\right\rangle^{j}}{j!(j+2)!}\bm w_{t,m}\,,
\end{align}
and
\begin{align}
        \mathbb{E}_{\widetilde{\bm x}}\left[\bm x \sigma' \left(\widetilde{\bm x}^{\!\top}\bm w_{t,m}\right) \sigma \left(\widetilde{\bm x}^{\!\top}\bm w_{t,m}\right)\right]
        & = \sum_{j= 0}^{\infty}\left(\frac{c_{j+1}^2}{(j+1)!(j+1)!}+\frac{c_{j+2}c_{j}}{j!(j+2)!}\right)\left\langle\bm w_{t,m},\bm w_{t,m}\right\rangle^{j}\bm w_{t,m}\,.\label{sigma-target-target}
    \end{align}
\end{lemma}
\begin{proof}
For $\forall\,1\leq m \leq k$, by \cref{Hermite-sigma} and \cref{Hermite-sigma'} on the Hermite expansion of ReLU function, we have
\begin{align*}
    & \mathbb{E}_{\widetilde{\bm x}}\left[\widetilde{\bm x} \sigma' \left(\widetilde{\bm x}^{\!\top}\bm w_{t,m}\right) \sigma \left(\widetilde{\bm x}^{\!\top}\widetilde{\bm w}^\natural_m\right)\right]\\
    = & \mathbb{E}_{\widetilde{\bm x}}\left[\sigma' \left(\widetilde{\bm x}^{\!\top}\bm w_{t,m}\right) \nabla_{\widetilde{\bm x}}\sigma \left(\widetilde{\bm x}^{\!\top}\widetilde{\bm w}^\natural_m\right)\right] + \mathbb{E}_{\widetilde{\bm x}}\left[ \sigma'' \left(\widetilde{\bm x}^{\!\top}\bm w_{t,m}\right) \sigma \left(\widetilde{\bm x}^{\!\top}\widetilde{\bm w}^\natural_m\right)\right]\bm w_{t,m}\quad \tag*{\color{teal}[by Stein's Lemma]}\\
    = & \sum_{j= 0}^{\infty}\frac{c_{j+1}\mathbb{E}_{\widetilde{\bm x}}\left[\nabla_{\widetilde{\bm x}}^{j+1}\sigma \left(\widetilde{\bm x}^{\!\top}\widetilde{\bm w}^\natural_m\right)\right]\left(\bm w_{t,m}\right)^{\otimes j}}{(j+1)!(j+1)!} + \sum_{j= 0}^{\infty} \frac{c_{j+2}\mathbb{E}_{\widetilde{\bm x}}\left[\nabla_{\widetilde{\bm x}}^{j}\sigma \left(\widetilde{\bm x}^{\!\top}\widetilde{\bm w}^\natural_m\right)\right]\left(\bm w_{t,m}\right)^{\otimes j}}{j!(j+2)!}
    \bm w_{t,m}\quad \tag*{\color{teal}[by \cref{Hermite-coef}]}\\
    = & \sum_{j= 0}^{\infty}\frac{c_{j+1}^2\left(\widetilde{\bm w}^\natural_m\right)^{\otimes (j+1)}\left(\bm w_{t,m}\right)^{\otimes j}}{(j+1)!(j+1)!} + \sum_{j=0}^{\infty} \frac{c_{j+2}c_{j}\left(\widetilde{\bm w}^\natural_m\right)^{\otimes j}\left(\bm w_{t,m}\right)^{\otimes j}}{j!(j+2)!}
    \bm w_{t,m}\\
    = & \sum_{j= 0}^{\infty}\frac{c_{j+1}^2\left\langle\widetilde{\bm w}^\natural_m,\bm w_{t,m}\right\rangle^{j}}{(j+1)!(j+1)!}\widetilde{\bm w}^\natural_m + \sum_{j= 0}^{\infty}\frac{c_{j+2}c_{j}\left\langle\widetilde{\bm w}^\natural_m,\bm w_{t,m}\right\rangle^{j}}{j!(j+2)!}\bm w_{t,m}\,,
\end{align*}
which completes the proof for \cref{sigma-target-model-corr}. The proof for \cref{sigma-target-target} is the same as that of \cref{sigma-target-model-corr} and we therefore omit it here.
\end{proof}
Next, we can obtain the expected full gradients via the following lemma.
\begin{lemma}
\label{expec-grad}
    Recall $\bm W_t := \bm W^\natural + \bm A_t \bm B_t$, under assumptions in \cref{sec:assumptions} for the nonlinear setting and \cref{assum:nonlinear-orth}, then it holds that
    \begin{align*}
    \mathbb{E}_{\widetilde{\bm x}}\left[\bm J_{\bm W_t}\right] & = \left(c_1^2+c_0 c_2 / 2\right)\left(\bm A_t \bm B_t - \Delta\right)+\sum_{\substack{n\geq 1,\\n\text{ odd}}}\bm \Psi_t(n)\,,
\end{align*}
where
\begin{align*}
    \bm \Psi_t(n) & = \frac{1}{4\pi} \frac{\operatorname{Diag}\bigg(\left\langle{\bm w}_{t,1},{\bm w}_{t,1}\right\rangle^{n}-\left\langle\widetilde{\bm w}^\natural_1,{\bm w}_{t,1}\right\rangle^{n}\,,...\,,\left\langle{\bm w}_{t,k},{\bm w}_{t,k}\right\rangle^{n}-\left\langle\widetilde{\bm w}^\natural_k,{\bm w}_{t,k}\right\rangle^{n}\bigg)}{2^{n} n^2 n! n!}  \widetilde{\bm W}^\natural\\
    &+\frac{1}{4\pi} \frac{\operatorname{Diag}\bigg(\left\langle{\bm w}_{t,1},{\bm w}_{t,1}\right\rangle^n\,,...\,,\left\langle{\bm w}_{t,k},{\bm w}_{t,k}\right\rangle^n\bigg)}{2^{n} n^2 n! n!}\left(\bm A_t \bm B_t - \Delta\right)\\
    &-\frac{1}{4\pi}\frac{\operatorname{Diag}\bigg(\left\langle{\bm w}_{t,1},{\bm w}_{t,1}\right\rangle^{n+1}-\left\langle\widetilde{\bm w}^\natural_1,{\bm w}_{t,1}\right\rangle^{n+1}\,,...\,,\left\langle{\bm w}_{t,k},{\bm w}_{t,k}\right\rangle^{n+1}-\left\langle\widetilde{\bm w}^\natural_k,{\bm w}_{t,k}\right\rangle^{n+1}\bigg)}{2^{n+1} n(n + 2)(n+1)!(n+3)!}{\bm W}_{t}\,.
\end{align*}
Also, we have
\begin{align*}
  \left\|\bm \Psi_t(n)\right\|_{\rm F}
  & \leq \Bigg(\frac{\|\widetilde{\bm W}^\natural\|_{op}\max\left\{\left(1 + \left\|\bm A_t \bm B_t - \Delta\right\|_{op} + \|\Delta\|_{op}\right)\,,\left\|\widetilde{\bm W}^\natural\right\|_{op}\right\}^{2n-1}}{4\pi 2^{n} n (n!)^2}\\
  & \quad +\frac{\left(\|\widetilde{\bm W}^\natural\|_{op}+\left\|\bm A_{t}\bm B_t - \Delta\right\|_{op}\right)\max\left\{\left(1 + \left\|\bm A_t \bm B_t - \Delta\right\|_{op} + \|\Delta\|_{op}\right)\,,\left\|\widetilde{\bm W}^\natural\right\|_{op}\right\}^{2n+1}}{4\pi2^{n+1} n(n + 2)n!(n+3)!}\\
  & \quad +\frac{\left(1+\left\|\bm A_{t}\bm B_t - \Delta\right\|_{op}+\left\|\Delta\right\|_{op}\right)^{2n}}{4\pi 2^{n} n (n!)^2}\Bigg)\left\|\bm A_t \bm B_t - \Delta\right\|_{\rm F}\,.
\end{align*}
\end{lemma}
\begin{proof}
We first give some notations here. Let $\bm w_{t,m}$ be the $m$-th column of $\bm W_t \in \mathbb{R}^{d \times k}$, $\bm w^\natural_m$ be the $m$-th column of $\widetilde{\bm W}^\natural$, $\Delta_m$ as the $m$-th of the low-rank shift $\Delta$, $[\bm A_t \bm B_t]_m$ as the $m$-th column of $\bm A_t \bm B_t$.

By \cref{I-expectation}, we can derive $m$-th column of $\mathbb{E}_{\widetilde{\bm x}}\left[\bm J_{\bm W_t}\right]$ for any $m=1,2,\cdots,k$ as
\begin{align*}
    & \mathbb{E}_{\widetilde{\bm x}}\left[\frac{1}{N}\sum_{i=1}^N\left(\sigma \left(\widetilde{\bm x}_i^{\!\top}{\bm w}_{t,m}\right)-\sigma \left(\widetilde{\bm x}_i^{\!\top}\widetilde{\bm w}_m^\natural\right)\right)\sigma' \left(\widetilde{\bm x}_i^{\!\top}\bm w_{t,m}\right)\widetilde{\bm x}_i\right]\\
    & = \sum_{j=0}^{\infty}\frac{c_{j+1}^2}{(j+1)!(j+1)!}\left\langle{\bm w}_{t,m},{\bm w}_{t,m}\right\rangle^{j}{\bm w}_{t,m} + \sum_{j= 0}^{\infty}\frac{c_{j+2}c_{j}}{j!(j+2)!}\left\langle{\bm w}_{t,m},{\bm w}_{t,m}\right\rangle^{j}{\bm w}_{t,m}\\
    & \quad -\sum_{j=0}^{\infty}\frac{c_{j+1}^2}{(j+1)!(j+1)!}\left\langle\widetilde{\bm w}^\natural_m,{\bm w}_{t,m}\right\rangle^{j}\widetilde{\bm w}^\natural_m - \sum_{j= 0}^{\infty}\frac{c_{j+2}c_{j}}{j!(j+2)!}\left\langle\widetilde{\bm w}^\natural_m,{\bm w}_{t,m}\right\rangle^{j}{\bm w}_{t,m}\\
    & = \left(c_1^2+c_0 c_2 / 2\right) \left(\bm w_{t,m}-\widetilde{\bm w}^\natural_m\right)\\
    & \quad + \sum_{j=1}^{\infty}\frac{c_{2j}^2}{(2j)!(2j)!}\left\langle{\bm w}_{t,m},{\bm w}_{t,m}\right\rangle^{2j-1}{\bm w}_{t,m} + \sum_{j= 1}^{\infty}\frac{c_{2j+2}c_{2j}}{(2j)!(2j+2)!}\left\langle{\bm w}_{t,m},{\bm w}_{t,m}\right\rangle^{2j}{\bm w}_{t,m}\\
    & \quad -\sum_{j=1}^{\infty}\frac{c_{2j}^2}{(2j)!(2j)!}\left\langle\widetilde{\bm w}^\natural_m,{\bm w}_{t,m}\right\rangle^{2j-1}\widetilde{\bm w}^\natural_m - \sum_{j= 1}^{\infty}\frac{c_{2j+2}c_{2j}}{(2j)!(2j+2)!}\left\langle\widetilde{\bm w}^\natural_m,{\bm w}_{t,m}\right\rangle^{2j}{\bm w}_{t,m}\,.
\end{align*}
By re-arranging the index of infinite sum, we can obtain
\begin{align*}
    & \mathbb{E}_{\widetilde{\bm x}}\left[\frac{1}{N}\sum_{i=1}^N\left(\sigma \left(\widetilde{\bm x}_i^{\!\top}{\bm w}_{t,m}\right)-\sigma \left(\widetilde{\bm x}_i^{\!\top}\widetilde{\bm w}_m^\natural\right)\right)\sigma' \left(\widetilde{\bm x}_i^{\!\top}\bm w_{t,m}\right)\widetilde{\bm x}_i\right]\\
    = &  \left(c_1^2+c_0 c_2 / 2\right) \left(\left[\bm A_t \bm B_t \right]_{m}-\Delta_m\right)\\
    & + \frac{1}{4\pi} \sum_{\substack{n\geq 1, \\ n \text{ odd}}} \frac{\bigg(\left\langle{\bm w}_{t,m},{\bm w}_{t,m}\right\rangle^{n}-\left\langle\widetilde{\bm w}^\natural_m,{\bm w}_{t,m}\right\rangle^{n}\bigg)}{2^{n} n^2 n! n!}  \widetilde{\bm w}^\natural_m\\
    & + \frac{1}{4\pi} \sum_{\substack{n\geq 1, \\ n \text{ odd}}} \frac{\left\langle{\bm w}_{t,m},{\bm w}_{t,m}\right\rangle^n}{2^{n} n^2 n! n!}\left(\left[\bm A_t \bm B_t \right]_{m}-\Delta_m\right)\\
    & -\frac{1}{4\pi}\sum_{\substack{n\geq 1,\\n\text{ odd}}}\frac{\bigg(\left\langle{\bm w}_{t,m},{\bm w}_{t,m}\right\rangle^{n+1}-\left\langle\widetilde{\bm w}^\natural_m,{\bm w}_{t,m}\right\rangle^{n+1}\bigg)}{2^{n+1} n(n + 2)(n+1)!(n+3)!}{\bm w}_{t,m}\,.
\end{align*}
Then, for the last three terms, we define the $m$-th residual vector of order-$n$ of them as
\begin{align*}
    \bm r_m(n)&:=\frac{1}{4\pi} \frac{\bigg(\left\langle{\bm w}_{t,m},{\bm w}_{t,m}\right\rangle^{n}-\left\langle\widetilde{\bm w}^\natural_m,{\bm w}_{t,m}\right\rangle^{n}\bigg)}{2^{n} n^2 n! n!}  \widetilde{\bm w}^\natural_m
     + \frac{1}{4\pi} \frac{\left\langle{\bm w}_{t,m},{\bm w}_{t,m}\right\rangle^n}{2^{n} n^2 n! n!}\left(\left[\bm A_t \bm B_t \right]_{m}-\Delta_m\right)\\
    &-\frac{1}{4\pi}\frac{\bigg(\left\langle{\bm w}_{t,m},{\bm w}_{t,m}\right\rangle^{n+1}-\left\langle\widetilde{\bm w}^\natural_m,{\bm w}_{t,m}\right\rangle^{n+1}\bigg)}{2^{n+1} n(n + 2)(n+1)!(n+3)!}{\bm w}_{t,m}\,.
\end{align*}
Combining the above equations, we can write in matrix form as
\begin{align*}
    \mathbb{E}_{\widetilde{\bm x}}\left[ \bm J_{\bm W_t} \right] & = \left(c_1^2+c_0 c_2 / 2\right)\left(\bm A_t \bm B_t - \Delta\right)+\sum_{\substack{n\geq 1,\\n\text{ odd}}}\underbrace{\begin{bmatrix}
        \bm r_1(n) & \hdots & \bm r_k(n)
    \end{bmatrix}}_{:=\bm \Psi_t(n)}\,,
\end{align*}
where $\bm \Psi_t(n)$ can be formulated as
\begin{align}
    \bm \Psi_t(n) & = \frac{1}{4\pi} \frac{\operatorname{Diag}\bigg(\left\langle{\bm w}_{t,1},{\bm w}_{t,1}\right\rangle^{n}-\left\langle\widetilde{\bm w}^\natural_1,{\bm w}_{t,1}\right\rangle^{n}\,,...\,,\left\langle{\bm w}_{t,k},{\bm w}_{t,k}\right\rangle^{n}-\left\langle\widetilde{\bm w}^\natural_k,{\bm w}_{t,k}\right\rangle^{n}\bigg)}{2^{n} n^2 n! n!}  \widetilde{\bm W}^\natural \label{eq:psin1} \\
    &+\frac{1}{4\pi} \frac{\operatorname{Diag}\bigg(\left\langle{\bm w}_{t,1},{\bm w}_{t,1}\right\rangle^n\,,...\,,\left\langle{\bm w}_{t,k},{\bm w}_{t,k}\right\rangle^n\bigg)}{2^{n} n^2 n! n!}\left(\bm A_t \bm B_t - \Delta\right) \label{eq:psin2} \\
    &-\frac{1}{4\pi}\frac{\operatorname{Diag}\bigg(\left\langle{\bm w}_{t,1},{\bm w}_{t,1}\right\rangle^{n+1}-\left\langle\widetilde{\bm w}^\natural_1,{\bm w}_{t,1}\right\rangle^{n+1}\,,...\,,\left\langle{\bm w}_{t,k},{\bm w}_{t,k}\right\rangle^{n+1}-\left\langle\widetilde{\bm w}^\natural_k,{\bm w}_{t,k}\right\rangle^{n+1}\bigg)}{2^{n+1} n(n + 2)(n+1)!(n+3)!}{\bm W}_{t}\,. \label{eq:psin3}
\end{align}
Now we aim to upper bound the Frobenius norm of $\bm \Psi_t(n)$ for $n\geq 1$. 
We handle these three terms of $\bm \Psi_t(n)$ respectively.
Regarding the first term \eqref{eq:psin1}, we have
\begin{align*}
    &\left\|\frac{1}{4\pi} \frac{\operatorname{Diag}\bigg(\left\langle{\bm w}_{t,1},{\bm w}_{t,1}\right\rangle^{n}-\left\langle\widetilde{\bm w}^\natural_1,{\bm w}_{t,1}\right\rangle^{n}\,,...\,,\left\langle{\bm w}_{t,k},{\bm w}_{t,k}\right\rangle^{n}-\left\langle\widetilde{\bm w}^\natural_k,{\bm w}_{t,k}\right\rangle^{n}\bigg)}{2^{n} n^2 n! n!}  \widetilde{\bm W}^\natural\right\|^2_{\rm F}\\
    \leq & \frac{\left\|\widetilde{\bm W}^\natural\right\|^2_{op}}{16\pi^2 2^{2n} n^4 (n!)^4}\sum_{m=1}^k\bigg(\left\langle{\bm w}_{t,m},{\bm w}_{t,m}\right\rangle^{n}-\left\langle\widetilde{\bm w}^\natural_m,{\bm w}_{t,m}\right\rangle^{n}\bigg)^2\\
    \leq & \frac{\left\|\widetilde{\bm W}^\natural\right\|^2_{op}}{16\pi^2 2^{2n} n^4 (n!)^4}\sum_{m=1}^k\bigg(n\,\max\left\{\left\|{\bm w}_{t,m}\right\|_2\,,\left\|\widetilde{\bm w}^\natural_m\right\|_2\right\}^{2n-1}\left\|\left[\bm A_t \bm B_t\right]_{m}-\Delta_m\right\|_2\bigg)^2\quad \tag*{\color{teal}$\left[\text{by }\left|\langle \bm u\,, \bm u \rangle^j - \langle \bm u\,, \bm v \rangle^j\right| \leq j\,\max\left\{\left\|\bm u\right\|_2\,,\left\|\bm v\right\|_2\right\}^{2j-1} \left\|\bm u - \bm v\right\|_2\text{ in \cref{vec-ineq}}\right]$}\\
    \leq & \frac{\left\|\widetilde{\bm W}^\natural\right\|^2_{op}}{16\pi^2 2^{2n} n^2 (n!)^4}\sum_{m=1}^k\bigg(\,\max\left\{\left(1 + \|\left[\bm A_t \bm B_t\right]_{m}-\Delta_m\|_2 + \|\Delta_m\|_2\right)\,,\left\|\widetilde{\bm w}^\natural_m\right\|_2\right\}^{2n-1}\left\|\left[\bm A_t \bm B_t\right]_{m}-\Delta_m\right\|_2\bigg)^2\tag*{\color{teal}$\left[\text{by \cref{assum:nonlinear-orth} and triangle inequality }\|{\bm w}_{t,m}\|_{2} \leq 1 + \|\left[\bm A_t \bm B_t\right]_{m}-\Delta_m\|_2 + \|\Delta_m\|_2\right]$}\\
    \leq & \frac{\left\|\widetilde{\bm W}^\natural\right\|^2_{op}\max\left\{\left(1 + \left\|\bm A_t \bm B_t - \Delta\right\|_{op} + \|\Delta\|_{op}\right)\,,\left\|\widetilde{\bm W}^\natural\right\|_{op}\right\}^{4n-2}}{16\pi^2 2^{2n} n^2 (n!)^4}\left\|\bm A_t \bm B_t - \Delta\right\|_{\rm F}^2\,,
\end{align*}
where the last inequality holds by $\max_{j} \| \bm a_j \|_2 \leq \|\bm A\|_{op} $ for any matrix $\bm A = [\bm a_1, \bm a_2, \cdots, \bm a_k] \in \mathbb{R}^{d \times k}$.

Accordingly, we have
\begin{align*}
    &\left\|\frac{1}{4\pi} \frac{\operatorname{Diag}\bigg(\left\langle{\bm w}_{t,1},{\bm w}_{t,1}\right\rangle^{n}-\left\langle\widetilde{\bm w}^\natural_1,{\bm w}_{t,1}\right\rangle^{n}\,,...\,,\left\langle{\bm w}_{t,k},{\bm w}_{t,k}\right\rangle^{n}-\left\langle\widetilde{\bm w}^\natural_k,{\bm w}_{t,k}\right\rangle^{n}\bigg)}{2^{n} n^2 n! n!}  \widetilde{\bm W}^\natural\right\|_{\rm F}\\
    &\leq \frac{\left\|\widetilde{\bm W}^\natural\right\|_{op}\max\left\{\left(1 + \left\|\bm A_t \bm B_t - \Delta\right\|_{op} + \|\Delta\|_{op}\right)\,,\left\|\widetilde{\bm W}^\natural\right\|_{op}\right\}^{2n-1}}{4\pi 2^{n} n (n!)^2}\left\|\bm A_t \bm B_t - \Delta\right\|_{\rm F}\,.
\end{align*}
Regarding the second term~\eqref{eq:psin2}, we have
\begin{align*}
    &\left\|\frac{1}{4\pi} \frac{\operatorname{Diag}\bigg(\left\langle{\bm w}_{t,1},{\bm w}_{t,1}\right\rangle^n\,,...\,,\left\langle{\bm w}_{t,k},{\bm w}_{t,k}\right\rangle^n\bigg)}{2^{n} n^2 n! n!}\left(\bm A_t \bm B_t - \Delta\right)\right\|_{\rm F}\\
    \leq & \frac{\left(1+\left\|\bm A_{t}\bm B_t - \Delta\right\|_{op}+\left\|\Delta\right\|_{op}\right)^{2n}}{4\pi2^{n} n (n!)^2}\left\|\bm A_t \bm B_t - \Delta\right\|_{\rm F}\,.
\end{align*}
Regarding the third term~\eqref{eq:psin3}, we can also have
\begin{align*}
    &\left\|\frac{1}{4\pi}\frac{\operatorname{Diag}\bigg(\left\langle{\bm w}_{t,1},{\bm w}_{t,1}\right\rangle^{n+1}-\left\langle\widetilde{\bm w}^\natural_1,{\bm w}_{t,1}\right\rangle^{n+1}\,,...\,,\left\langle{\bm w}_{t,k},{\bm w}_{t,k}\right\rangle^{n+1}-\left\langle\widetilde{\bm w}^\natural_k,{\bm w}_{t,k}\right\rangle^{n+1}\bigg)}{2^{n+1} n(n + 2)(n+1)!(n+3)!}{\bm W}_{t}\right\|^2_{\rm F}\\
    \leq & \left(\frac{\|\bm W_t\|_{op}}{4\pi2^{n+1} n(n + 2)(n+1)!(n+3)!}\right)^2\sum_{m=1}^k\bigg(\left\langle{\bm w}_{t,m},{\bm w}_{t,m}\right\rangle^{n+1}-\left\langle\widetilde{\bm w}^\natural_m,{\bm w}_{t,m}\right\rangle^{n+1}\bigg)^2\\
    \leq & \left(\frac{\|\bm W_t\|_{op}}{4\pi2^{n+1} n(n + 2)(n+1)!(n+3)!}\right)^2\sum_{m=1}^k\bigg((n+1)\,\max\left\{\left\|{\bm w}_{t,m}\right\|_2\,,\left\|\widetilde{\bm w}^\natural_m\right\|_2\right\}^{2n+1}\left\|\left[\bm A_t \bm B_t\right]_{m}-\Delta_m\right\|_2\bigg)^2\tag*{\color{teal}$\left[\text{by }\left|\langle \bm u\,, \bm u \rangle^j - \langle \bm u\,, \bm v \rangle^j\right| \leq j\,\max\left\{\left\|\bm u\right\|_2\,,\left\|\bm v\right\|_2\right\}^{2j-1} \left\|\bm u - \bm v\right\|_2\text{ in \cref{vec-ineq}}\right]$}\\
    \leq & \left(\frac{\left(\|\widetilde{\bm W}^\natural\|_{op}+\left\|\bm A_{t}\bm B_t - \Delta\right\|_{op}\right)\max\left\{\left(1 + \left\|\bm A_t \bm B_t - \Delta\right\|_{op} + \|\Delta\|_{op}\right)\,,\left\|\widetilde{\bm W}^\natural\right\|_{op}\right\}^{2n+1}}{4\pi2^{n+1} n(n + 2)n!(n+3)!}\right)^2\left\|\bm A_t \bm B_t - \Delta\right\|^2_{\rm F}\,.
\end{align*}
Finally, combining the above three terms, we obtain
\begin{align*}
  \left\|\bm \Psi_t(n)\right\|_{\rm F}
  & \leq \Bigg(\frac{\|\widetilde{\bm W}^\natural\|_{op}\max\left\{\left(1 + \left\|\bm A_t \bm B_t - \Delta\right\|_{op} + \|\Delta\|_{op}\right)\,,\left\|\widetilde{\bm W}^\natural\right\|_{op}\right\}^{2n-1}}{4\pi 2^{n} n (n!)^2}\\
  & \quad +\frac{\left(\|\widetilde{\bm W}^\natural\|_{op}+\left\|\bm A_{t}\bm B_t - \Delta\right\|_{op}\right)\max\left\{\left(1 + \left\|\bm A_t \bm B_t - \Delta\right\|_{op} + \|\Delta\|_{op}\right)\,,\left\|\widetilde{\bm W}^\natural\right\|_{op}\right\}^{2n+1}}{4\pi2^{n+1} n(n + 2)n!(n+3)!}\\
  & \quad +\frac{\left(1+\left\|\bm A_{t}\bm B_t - \Delta\right\|_{op}+\left\|\Delta\right\|_{op}\right)^{2n}}{4\pi 2^{n} n (n!)^2}\Bigg)\left\|\bm A_t \bm B_t - \Delta\right\|_{\rm F}\,,
\end{align*}
which completes the proof.
\end{proof}

\subsubsection{Concentration of Empirical Gradients}
In this part, we aim to provide the concentration of empirical gradient $\bm J_{\bm W_t}:= \bm \Gamma_{1,t} - \bm \Gamma_{2,t} \in \mathbb{R}^{d \times k}$ in Frobenius norm. Recall $\bm W_t:=\bm W^\natural+\bm A_t \bm B_t$ and $\bm w_{t,m}$ is the corresponding $m$-th column of $\bm W_t$, denote $\widetilde{x}_{i,j}$ as the $j$-th element of $\widetilde{\bm x}_i$, for notational simplicity, we define each element of $\bm J_{\bm W_t}:= \bm \Gamma_{1,t} - \bm \Gamma_{2,t}$ as
\begin{align*}
    c^j_{t,m}\left(\widetilde{\bm x}_i\right) & := 
        \left(\sigma \left(\widetilde{\bm x}_i^{\!\top}\widetilde{\bm w}_m^\natural\right)-\sigma \left(\widetilde{\bm x}_i^{\!\top}{\bm w}_{t,m}^\natural\right)\right)\sigma' \left(\widetilde{\bm x}_i^{\!\top}\bm w_{t,m}^\natural\right)\widetilde{ x}_{i,j}\in\mathbb{R}\,,\quad \text{for }1\leq m\leq k\,,1\leq i\leq N\,,1\leq j\leq d\,,
\end{align*}
Then, we can write $\bm J_{\bm W_t}$ in an element-wise way
\begin{align*}
    \bm J_{\bm W_t} =\frac{1}{N}\sum_{i=1}^N\begin{bmatrix}
        c^1_{t,1}\left(\widetilde{\bm x}_i\right) & \hdots & c^1_{t,k}\left(\widetilde{\bm x}_i\right)\\
        \vdots & \ddots & \vdots\\
        c^d_{t,1}\left(\widetilde{\bm x}_i\right) & \hdots & c^d_{t,k}\left(\widetilde{\bm x}_i\right)
    \end{bmatrix} \in \mathbb{R}^{d \times k}\,,
\end{align*}
and
\begin{align*}
    \bigg\|\bm J_{\bm W_t} - \mathbb{E}_{\widetilde{\bm x}}\left[\bm J_{\bm W_t} \right]\bigg\|^2_{\rm F} & = \sum_{j=1}^d\sum_{m=1}^k \left(\frac{1}{N}\sum_{i=1}^N c^j_{t,m}\left(\widetilde{\bm x}_i\right)-\mathbb{E}_{\widetilde{\bm x}}\left[ c^j_{t,m}\left(\widetilde{\bm x}\right)\right]\right)^2\,.
\end{align*}
Next, we have the following lemma.
\begin{lemma}
\label{entrywise-concen}
  For $1\leq m \leq k$, $1\leq j \leq d$, under assumptions in \cref{sec:assumptions} for the nonlinear setting, with probability at least $1-2C\operatorname{exp}\left(- N\epsilon^2\right)$ for a universal constant $C>0$ and $\epsilon\in(0,1)$, we have
  \begin{align*}
      \left|\frac{1}{N}\sum_{i=1}^N c^j_{t,m}\left(\widetilde{\bm x}_i\right)-\mathbb{E}_{\widetilde{\bm x}}\left[ c^j_{t,m}\left(\widetilde{\bm x}\right)\right]\right|&\leq C^* K^2 \epsilon \|\widetilde{\bm w}_m^\natural-{\bm w}_{t,m}^\natural\|_2\,,
  \end{align*}
  for some absolute constant $C^*>0$ and $K=\sqrt{8/3}$.
\end{lemma}
\begin{proof}
Since $\widetilde{x}_{i,j}\sim \mathcal{N}(0\,,1)$ for $\forall\,1\leq m \leq k$ and $\forall\,1\leq j \leq d$, then we have that $K:=\|\widetilde{x}_{i,j}\|_{\psi_2}=\sqrt{8/3}$. By the Orlicz-based definition of subgaussian norm, the subgaussian norm of random variable is identical to its absolute value. Then, for any $\lambda\in\mathbb{R}$, we have the following moment generating function
\begin{align*}
&\mathbb{E}\left[\operatorname{exp}\left(\lambda\left|\left(\sigma \left(\widetilde{\bm x}_i^{\!\top}\widetilde{\bm w}_m^\natural\right)-\sigma \left(\widetilde{\bm x}_i^{\!\top}{\bm w}_{t,m}^\natural\right)\right)\sigma' \left(\widetilde{\bm x}_i^{\!\top}\bm w_{t,m}^\natural\right)\right| \right)\right]\\
\leq&\mathbb{E}\left[\operatorname{exp}\left(\lambda\left|\left\langle\widetilde{\bm x}_i\,,\widetilde{\bm w}_m^\natural-{\bm w}_{t,m}^\natural\right\rangle\right|\right)\right]\quad \tag*{\color{teal}[by Lipschitz continuity of $\sigma$ and $\sigma'$]}\\
\leq & \mathbb{E}\left[\operatorname{exp}\left((C^*)^2\lambda^2\left\|\left|\left\langle\widetilde{\bm x}_i\,,\widetilde{\bm w}_m^\natural-{\bm w}_{t,m}^\natural\right\rangle\right|\right\|_{\psi_2}^2\right)\right]\,,\quad \tag*{\color{teal}[by subgaussian property]}
\end{align*}
for some constant $C^*>0$, which implies
\begin{align*}
    \left\|\left(\sigma \left(\widetilde{\bm x}_i^{\!\top}\widetilde{\bm w}_m^\natural\right)-\sigma \left(\widetilde{\bm x}_i^{\!\top}{\bm w}_{t,m}^\natural\right)\right)\sigma' \left(\widetilde{\bm x}_i^{\!\top}\bm w_{t,m}^\natural\right)\right\|_{\psi_2}^2 &\leq (C^*)^2\left\|\left|\left\langle\widetilde{\bm x}_i\,,\widetilde{\bm w}_m^\natural-{\bm w}_{t,m}^\natural\right\rangle\right|\right\|_{\psi_2}^2
    = (C^*K)^2 \|\widetilde{\bm w}_m^\natural-{\bm w}_{t,m}^\natural\|_2^2\,,
\end{align*}
where the last inequality follows from the fact that $\|X\|_{\psi_2}=Ks$ if $X\sim\mathcal{N}(0,s^2)$. Therefore, by \citet[Lemma 2.7.7]{vershynin2018high}, this implies $c^j_{t,m}\left(\widetilde{\bm x}_i\right)$ is sub-exponential with
\begin{align}
    B_{t,m}:=\|c^j_{t,m}\left(\widetilde{\bm x}\right)\|_{\psi_1}\leq \|\widetilde{x}_{i,j}\|_{\psi_2}\left\|\left(\sigma \left(\widetilde{\bm x}_i^{\!\top}\widetilde{\bm w}_m^\natural\right)-\sigma \left(\widetilde{\bm x}_i^{\!\top}{\bm w}_{t,m}^\natural\right)\right)\sigma' \left(\widetilde{\bm x}_i^{\!\top}\bm w_{t,m}^\natural\right)\right\|_{\psi_2}\leq C^* K^2 \|\widetilde{\bm w}_m^\natural-{\bm w}_{t,m}^\natural\|_2\,.\label{est-sg-norm}
\end{align}
Then, let $\epsilon_{t,m}=C^* K^2 \epsilon \|\widetilde{\bm w}_m^\natural-{\bm w}_{t,m}^\natural\|_2$ for $\epsilon\in(0\,,1)$, we can apply Bernstein’s inequality for sub-exponential variables \citet[Corollary 2.8.3]{vershynin2018high}
\begin{align*}
    & \mathbb{P}\left(\left|\frac{1}{N}\sum_{i=1}^N c^j_{t,m}\left(\widetilde{\bm x}_i\right)-\mathbb{E}_{\widetilde{\bm x}}\left[ c^j_{t,m}\left(\widetilde{\bm x}\right)\right]\right|\geq \epsilon_{t,m}\right)\\
    \leq & 2C\operatorname{exp}\left(- N \min \left\{\frac{\epsilon_{t,m}}{B_{t,m}}\,,\frac{\epsilon_{t,m}^2}{B_{t,m}^2}\right\}\right)\quad\tag*{\color{teal}$[\text{ for some constant }C>0]$}\\
    \leq & 2C\operatorname{exp}\left(- N\epsilon^2\right)\quad \tag*{\color{teal}[by \cref{est-sg-norm} and $\epsilon\in(0\,,1)$]}
\end{align*}
\end{proof}
\begin{theorem} \label{emp-concen}
Suppose $\epsilon \in (0,1)$, under assumptions in \cref{sec:assumptions} for the nonlinear setting, then with probability at least $1-2Cdk\operatorname{exp}\left(- N\epsilon^2\right)$ for a universal constant $C>0$, we have
\begin{align*}
    \bigg\|\bm J_{\bm W_t} - \mathbb{E}_{\widetilde{\bm x}}\left[\bm J_{\bm W_t} \right]\bigg\|_{\rm F} & \leq C^* K^2\sqrt{d}\epsilon \|\bm A_t \bm B_t - \Delta\|_{\rm F}\,,
\end{align*}
for some absolute constant $C^*>0$ and $K=\sqrt{8/3}$.
\end{theorem}
\begin{proof}
By a union bound argument and \cref{entrywise-concen}, with probability at least $1-2Cdk\operatorname{exp}\left(-N\epsilon^2\right)$ for a universal constant $C>0$, we have
    \begin{align*}
    \bigg\|\bm J_{\bm W_t} - \mathbb{E}_{\widetilde{\bm x}}\left[\bm J_{\bm W_t}\right]\bigg\|^2_{\rm F} & = \sum_{j=1}^d\sum_{m=1}^k \left(\frac{1}{N}\sum_{i=1}^N c^j_{t,m}\left(\widetilde{\bm x}_i\right)-\mathbb{E}_{\widetilde{\bm x}}\left[ c^j_{t,m}\left(\widetilde{\bm x}\right)\right]\right)^2\\
    & \leq \sum_{j=1}^d\sum_{m=1}^k \epsilon^2_{t,m}\\
    & \leq \sum_{j=1}^d \sum_{m=1}^k (C^* K^2)^2 \epsilon^2 \|\widetilde{\bm w}_m^\natural-{\bm w}_{t,m}^\natural\|^2_2\\
    & = d (C^* K^2)^2 \epsilon^2 \|\bm A_t \bm B_t - \Delta\|^2_{\rm F}\,,
\end{align*}
which implies
\begin{align*}
    \bigg\|\bm J_{\bm W_t} - \mathbb{E}_{\widetilde{\bm x}}\left[\bm J_{\bm W_t}\right]\bigg\|_{\rm F} & \leq C^* K^2\sqrt{d}\epsilon \|\bm A_t \bm B_t - \Delta\|_{\rm F}\,,
\end{align*}
which finishes the proof.
\end{proof}
\begin{lemma}
\label{A0B0-init-risk}
    Recall $\bm G^\natural:=-\nabla L(\bm W^\natural)=\bm J_{\bm W^\natural}$, under assumptions in \cref{sec:assumptions} for the nonlinear setting and \cref{assum:nonlinear-orth}, with \eqref{eq:spectral-init-linear}, suppose $\epsilon \leq \frac{\rho}{3C^*K^2\gamma\sqrt{2d}r^*\kappa}$ for some $\rho>0$ and we set
    \begin{equation}\label{G-concen-err}
       \gamma\in\left[\frac{1}{c_{\rm H}}-\frac{\rho}{3c_{\rm H}\kappa\sqrt{2r^*}}\,,\frac{1}{c_{\rm H}}+\frac{\rho}{3c_{\rm H}\kappa\sqrt{2r^*}}\right], \quad \mbox{with}~ c_{\rm H} :=\frac{1}{4} + \frac{1}{4\pi}\sum_{\substack{n\geq 1, \\ n \text{ odd}}} 2^{-n} n^{-2} (n!)^{-2}\,,
    \end{equation}
    then with probability at least $1-2Cdk\operatorname{exp}(-N\epsilon^2)$ for a universal constant $C>0$, it holds that
    \begin{align*}
        \left\|\bm A_0 \bm B_0 - \Delta\right\|_{\rm F} & \leq \rho\lambda^*_{r^*}\,.
    \end{align*}
\end{lemma}
{\bf Remark} Notice that computing the exact value of $c_{\rm H}$ is difficult. However, because of the super-fast decay of Hermite coefficients of ReLU $\sigma$, we can approximate $c_{\rm H}$ very well by only three higher order terms, i.e. $n\in\{1\,,3\,,5\}$, which is $c_{\rm H}\simeq 0.28982$. The residual terms which the corresponding order bigger than $5$ are negligible. For example, when $n=7$, $\frac{1}{4\pi2^{n} n^{2} (n!)^{2}}\simeq 4.99\times 10^{-13}$.
\begin{proof}
Recall $\bm \Gamma^\natural_{1}$ and $\bm \Gamma^\natural_{2}$ defined in \cref{gamma-natural}, by \cref{I-expectation}, we can obtain
\begin{align*}
    \mathbb{E}_{\widetilde{\bm x}}\left[\bm \Gamma^\natural_{1}\right] & = \sum_{j= 0}^{\infty}\Bigg\{\frac{c_{j+1}^2}{(j+1)!(j+1)!}\operatorname{Diag}\left(\left(\bm W^\natural+\Delta\right)^{\!\top}\bm W^\natural\right)^j \left(\bm W^\natural+\Delta\right)\\
    & \quad +\frac{c_{j+2}c_{j}}{j!(j+2)!}\operatorname{Diag}\left(\left(\bm W^\natural+\Delta\right)^{\!\top}\bm W^\natural\right)^j \bm W^\natural\Bigg\}\\
    & = \sum_{j= 0}^{\infty}\Bigg\{\frac{c_{j+1}^2}{(j+1)!(j+1)!}\operatorname{Diag}\left(\left(\bm W^\natural\right)^{\!\top}\bm W^\natural\right)^j \left(\bm W^\natural+\Delta\right) \\
    &\quad +\frac{c_{j+2}c_{j}}{j!(j+2)!}\operatorname{Diag}\left(\left(\bm W^\natural\right)^{\!\top}\bm W^\natural\right)^j \bm W^\natural\Bigg\}\,, \quad \tag*{\color{teal}[by \cref{assum:nonlinear-orth}]}
\end{align*}
and
\begin{align*}
    \mathbb{E}_{\widetilde{\bm x}}\left[\bm \Gamma^\natural_{2}\right] & = \sum_{j= 0}^{\infty} \left(\frac{c_{j+1}^2}{(j+1)!(j+1)!}\operatorname{Diag}\left(\left(\bm W^\natural\right)^{\!\top}\bm W^\natural\right)^j  +\frac{c_{j+2}c_{j}}{j!(j+2)!}\operatorname{Diag}\left(\left(\bm W^\natural\right)^{\!\top}\bm W^\natural\right)^j \right)\bm W^\natural\,.
\end{align*}

Therefore, taking the Hermite coefficients by \cref{Hermite-coef}, we have
\begin{align}
    \mathbb{E}_{\widetilde{\bm x}}\left[\bm G^\natural\right] & = \sum_{j= 0}^{\infty}\Bigg(\frac{c_{j+1}^2}{(j+1)!(j+1)!}\operatorname{Diag}\left(\left(\bm W^\natural\right)^{\!\top}\bm W^\natural\right)^j \left(\bm W^\natural+\Delta\right)\\
    &\quad -\frac{c_{j+1}^2}{(j+1)!(j+1)!}\operatorname{Diag}\left(\left(\bm W^\natural\right)^{\!\top}\bm W^\natural\right)^j \bm W^\natural\Bigg)\nonumber\\
    & = \sum_{j= 0}^{\infty}\frac{c_{j+1}^2}{(j+1)!(j+1)!}\operatorname{Diag}\left(\left(\bm W^\natural\right)^{\!\top}\bm W^\natural\right)^j \Delta\nonumber\\
    & = \sum_{j= 0}^{\infty}\frac{c_{j+1}^2}{(j+1)!(j+1)!}\Delta\quad \tag*{\color{teal}[by \cref{assum:nonlinear-orth}]}\nonumber\\
    & = \underbrace{\left(c_1^2 + \frac{1}{4\pi}\sum_{\substack{n\geq 1, \\ n \text{ odd}}} \frac{1}{2^{n} n^2 (n!)^2}\right)}_{:=c_{\rm H}}\Delta\,. \label{eq:expectation-G}
\end{align}
Following \cref{emp-concen}, we replace $\bm W_t$ with $\bm W^\natural$ and then obtain the following concentration with the probability at least $1-2Cdk\operatorname{exp}(-N\epsilon^2)$ for a universal constant $C>0$
\begin{align*}
    \left\|\bm G^\natural - \mathbb{E}_{\widetilde{\bm x}}\left[\bm G^\natural\right]\right\|_{\rm F}\leq \frac{\rho\|\Delta\|_{\rm F}}{3\sqrt{2}r^*\gamma\kappa}\leq \frac{\rho\sqrt{r^*}\|\Delta\|_{op}}{3\sqrt{2}r^*\gamma\kappa}=\frac{\rho\lambda^*_{r^*}}{3\sqrt{2r^*}\gamma}\,,
\end{align*}
where $\epsilon \leq \frac{\rho}{2C^*K^2\gamma\sqrt{2d}r^*\kappa}$ for $\rho>0$. Besides, we have
\begin{align*}
    \left|\gamma\lambda_{r^*+1}\left(\bm G^\natural\right)-\lambda_{r^*+1}\left(\gamma\mathbb{E}_{\widetilde{\bm x}}\left[\bm G^\natural\right]\right)\right|&=\left|\gamma\lambda_{r^*+1}\left(\bm G^\natural\right)-\lambda_{r^*+1}\left(\Delta\right)\right|\\
    &=\gamma\lambda_{r^*+1}\left(\bm G^\natural\right) \tag*{\color{teal}[since $\operatorname{Rank}(\Delta)=r^*$]}\\
    &\leq \gamma\left\|\bm G^\natural - \mathbb{E}_{\widetilde{\bm x}}\left[\bm G^\natural\right]\right\|_{op}\quad \tag*{\color{teal}$\left[\text{by Weyl's inequality}\right]$}\\
    &\leq \gamma\left\|\bm G^\natural - \mathbb{E}_{\widetilde{\bm x}}\left[\bm G^\natural\right]\right\|_{\rm F} \\
    &\leq \frac{\rho\lambda^*_{r^*}}{3\sqrt{2r^*}}\,, \quad\tag*{\color{teal}[by \cref{G-concen-err}]}
\end{align*}
which implies
\begin{align}
    \lambda_{r^*+1}\left(\bm G^\natural\right) \leq \frac{\rho\lambda^*_{r^*}}{3\sqrt{2r^*}\gamma}\,,\label{approx-r}
\end{align}
due to $\operatorname{Rank}\left(\mathbb{E}_{\widetilde{\bm x}}\left[\bm G^\natural\right]\right)=\operatorname{Rank}(\Delta)=r^*$ by \cref{eq:expectation-G}. Then, we have
\begin{align}
    \left\|\bm A_0 \bm B_0 - \Delta\right\|_{op} & \leq \left\|\bm A_0 \bm B_0 - \gamma\bm G^\natural\right\|_{op} + \gamma\left\|\bm G^\natural - \mathbb{E}_{\widetilde{\bm x}}\left[\bm G^\natural\right]\right\|_{op} + \left\|\gamma\mathbb{E}_{\widetilde{\bm x}}\left[\bm G^\natural\right]-\Delta\right\|_{op}\nonumber\\
    & \leq \left\|\bm A_0 \bm B_0 - \gamma\bm G^\natural\right\|_{op} + \gamma \left\|\bm G^\natural - \mathbb{E}_{\widetilde{\bm x}}\left[\bm G^\natural\right]\right\|_{\rm F} + \left|\gamma c_{\rm H} - 1\right|\|\Delta\|_{op}\tag*{\color{teal}[by \cref{eq:expectation-G}]}\nonumber\\
    & \leq \left\|\bm A_0 \bm B_0 - \gamma\bm G^\natural\right\|_{op} + \frac{2\rho\lambda^*_{r^*}}{3\sqrt{2r^*}} \quad\tag*{\color{teal}$\left[\text{by \cref{G-concen-err} and }\gamma\in\left[\frac{1}{c_{\rm H}}-\frac{\rho}{3c_{\rm H}\kappa\sqrt{2r^*}}\,,\frac{1}{c_{\rm H}}+\frac{\rho}{3c_{\rm H}\kappa\sqrt{2r^*}}\right]\right]$}\nonumber\\
    & \leq \gamma\lambda_{r^*+1}\left(\bm G^\natural\right) + \frac{2\rho\lambda^*_{r^*}}{3\sqrt{2r^*}}\nonumber\\
    & \leq \frac{\rho\lambda^*_{r^*}}{\sqrt{2r^*}}\,.\quad \tag*{\color{teal}[by \cref{approx-r}]}
\end{align}
Since we work in the exact-rank case $\operatorname{Rank}\left(\bm A_t \bm B_t\right)\leq r=r^*$ with $\operatorname{Rank}(\Delta)=r^*$, then $\operatorname{Rank}(\bm A_0 \bm B_0 - \Delta)\leq 2r^*$, which implies
\begin{align*}
    \left\|\bm A_0 \bm B_0 - \Delta\right\|_{\rm F} & \leq \sqrt{2r^*} \left\|\bm A_0 \bm B_0 - \Delta\right\|_{op} \leq \rho\lambda^*_{r^*}\,.
\end{align*}
\end{proof}

\input{arxiv_template/appendix/prec_nonl}