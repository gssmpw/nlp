\documentclass[11pt]{article}
\usepackage{fullpage,graphicx,psfrag,amsmath,amsfonts,verbatim}
\usepackage{xcolor}
\usepackage{amsthm}
\usepackage[small,bf]{caption}
\usepackage{authblk}
\newcommand{\theHalgorithm}{\arabic{algorithm}}
\usepackage{amsmath}
\usepackage{amssymb}
\usepackage{mathtools}
\usepackage{amsthm}
% \usepackage{natbib}
\usepackage{amsfonts}
\usepackage{algorithm}
\usepackage{algorithmic}

\usepackage{tabularx}
\usepackage{makecell}
\usepackage{multirow}
% \usepackage[table,xcdraw,dvipsnames]{xcolor}

% Recommended, but optional, packages for figures and better typesetting:
\usepackage{microtype}
\usepackage{graphicx}
% \usepackage{subfigure}
\usepackage{booktabs} % for professional tables
\usepackage{hyperref}
\usepackage{subcaption}
\usepackage{enumitem}

%\hypersetup{
%    colorlinks = true,
%    allcolors = {purple},
%    linkbordercolor = {white},
%}

%\input defs.tex
\allowdisplaybreaks

\bibliographystyle{alpha}

\title{Generative Multi-Agent Collaboration in Embodied AI: A Systematic Review}

\author[1]{Di Wu}
\author[3]{Xian Wei}
\author[1]{Guang Chen}
\author[4]{Hao Shen}
\author[3]{Xiangfeng Wang}
\author[1]{\\Wenhao Li\thanks{\texttt{whli@tongji.edu.cn}}}
\author[2,1]{Bo Jin\thanks{\texttt{bjin@tongji.edu.cn}}}

\affil[1]{School of Computer Science and Technology, Tongji University}
\affil[2]{Shanghai Research Institute for Intelligent Autonomous Systems, Tongji University}
\affil[3]{School of Computer Science and Technology, East China Normal University}
\affil[4]{Technical University of Munich}
% \date{}
\begin{document}
\maketitle
\begin{abstract}
% Embodied multi-agent system (EMAS) consists of agents, that cooperate to solve complex tasks, demonstrating autonomy, distribution, and collaboration. 
% Traditionally developed by classical methods or reinforcement learning, recent advancements in large language models (FMs) offer new opportunities for EMAS with enhanced generalization and knowledge capabilities. 
% In multi-agent embodied AI, focusing on enabling systems to interact with physical environments, EMAS play a critical role in task allocation, resource management, collective intelligence, etc. 
% This survey presents a systematic review on MAS in embodied systems, encompassing physical agents and FM-based agents in virtual spaces. 
% It proposes a taxonomy of system architectures, explores collaboration strategies, and highlights methods for enhancing task performance through agent cooperation. 
% While FM-based MAS in embodied AI remain in early stages, this review aims to clarify evolving directions and inspire further works in this emerging field.
Embodied multi-agent systems (EMAS) have attracted growing attention for their potential to address complex, real-world challenges in areas such as logistics and robotics. 
Recent advances in foundation models pave the way for generative agents capable of richer communication and adaptive problem-solving. 
This survey provides a systematic examination of how EMAS can benefit from these generative capabilities. 
We propose a taxonomy that categorizes EMAS by system architectures and embodiment modalities, emphasizing how collaboration spans both physical and virtual contexts. 
Central building blocks, perception, planning, communication, and feedback, are then analyzed to illustrate how generative techniques bolster system robustness and flexibility. 
Through concrete examples, we demonstrate the transformative effects of integrating foundation models into embodied, multi-agent frameworks. 
Finally, we discuss challenges and future directions, underlining the significant promise of EMAS to reshape the landscape of AI-driven collaboration.
\end{abstract}

\section{Introduction}

%Artificial intelligence has propelled significant advancements in embodied AI.
%However, achieving full autonomy in complex, dynamic settings remains challenging for individual agents. 
%To address these limitations.
% Embodied multi-agent system (EMAS) has became a popular research topic, due to its remarkable potential in the fields of smart transportation, smart logistics, smart manufacturing, etc.
% Multi-agent systems (MAS) have emerged as a critical paradigm, which offers a transformative approach allowing agents to collaborate and interact with the infrastructure to handle a wide range of tasks.

Embodied multi-agent systems (EMAS) have garnered growing interest due to their significant potential in domains such as smart transportation, logistics, and manufacturing~\cite{yan2013survey,ismail2018survey}. 
By integrating physical embodiments—ranging from autonomous vehicles to robotic manipulators—with multi-agent systems (MAS)~\cite{dorri2018multi}, EMAS offers a decentralized, collaborative approach that can handle complex tasks with remarkable efficiency. 
Despite these advantages, designing and implementing effective EMAS remains a non-trivial endeavor, often requiring specialized knowledge of cybernetics, extensive training data, and careful reinforcement-learning paradigms~\cite{landauer2008computational,orr2023multi}.

% MAS leverage the principles of autonomy, distribution, and collaboration to enhance the capabilities of embodied systems. 
% Multi-agent collaboration facilitates the execution of complex tasks through shared responsibilities, improved efficiency, and collective intelligence. 
% The design and implementation of MAS traditionally rely on cybernetics or reinforcement learning, involving significant domain expertise and extensive training data. 
% Hence, existing methods often face difficulties in generalizing to new tasks or environments, limiting their applicability in real-world embodied AI scenarios.

In traditional MAS, agents collaborate by dividing responsibilities, sharing state information, and collectively adapting to dynamic environments~\cite{dorri2018multi}. 
While these principles have led to impressive success in certain niches, conventional approaches face critical limitations in generalizing to new tasks~\cite{mahajan2022generalization}, scaling to large agent populations~\cite{cui2022survey}, and coping with unexpected environmental changes~\cite{weinberg2004best}. 
They often rely on narrowly trained models, which can be brittle or constrained to specific domains~\cite{yuan2023robust}. 
These shortfalls underscore the urgency for more flexible and robust solutions that can thrive in open-ended and rapidly changing embodied scenarios.

% Recent advances in large language models (FMs) have brought transformative changes to the field of MAS, particularly through the introduction of generative agents. 
% These agents, powered by FMs, exhibit human-level abilities such as contextual reasoning, natural language communication, and adaptive decision-making. 
% Unlike traditional approaches, FM-based MAS enable dynamic and semantically rich interactions among agents, fostering emergent collective intelligence and innovative problem-solving strategies. 
% This evolution not only addresses the limitations of single-agent systems, but also expands the horizons of embodied AI, by introducing scalable, flexible, and modular architectures for multi-agent collaboration.

Recent breakthroughs in foundation models (FMs, e.g., large language models, FMs, or vision-language models, VLMs)~\cite{zhou2024comprehensive} have opened new avenues for advancing MAS toward more adaptive and generative behaviors. 
By equipping agents with natural language capabilities, contextual reasoning, and the ability to generate novel solutions, FM-based MAS transcend some of the limitations inherent in purely signal-driven or reinforcement-based frameworks~\cite{guo2024large,chen2024survey,lu2024merge} . 
These ``generative agents'' can communicate in semantically rich ways, collaborate with human-level fluency, and rapidly adapt strategies in response to unforeseen challenges. 
As such, FM-powered agents could transform how multi-agent collaboration unfolds—both in physical spaces populated by embodied devices and in virtual spaces where agents share abstract knowledge and tasks.

Against this backdrop, the field of EMAS stands poised to benefit from these recent advances in FMs.
By combining physical embodiments with generative multimodal intelligence, future systems may embrace a broader design space that incorporates complex perception, high-level linguistic and visual reasoning, and adaptive decision-making. 
However, existing literature surveys on embodied AI and multi-agent systems often treat these fields in isolation, leaving critical gaps at their intersection~\cite{ismail2018survey,duan2022survey,guo2024large,ma2024survey,hunt2024survey}.
A systematic view of how FM-based generative agents can best be integrated into EMAS is still emerging.

% In light of these developments, this paper provides a systematic survey of the current state of multi-agent collaboration in embodied systems from the perspective of the generative AI era. 
% We first classify the architectures of existing multi-agent embodied systems by the number of models and embodiments. 
% In contemporary research on Embodied AI, multi-agent collaboration can manifest not only through interactions among different physical embodiments, but also through cooperation among multiple FM-based agents in virtual semantic spaces. 
% Then,  we further explore how to achieve efficient multi-agent embodied collaboration, focusing on the design of key modules such as system perception, planning, communication, and feedback. 
% This paper specifically introduces the applications of multi-agent collaboration in embodied scenarios.
% To sum up, we open the discussion for future research challenges and opportunities.

% \begin{figure*}[htb!]
% \centering
%     \begin{subfigure}[h]{0.64\linewidth}
%         \centering
%         \includegraphics[width=\linewidth]{figure/overall_6.pdf}
%         \caption{}
%         \label{fig:overall_large_pic}
%     \end{subfigure}
%     % \hfill
%     \begin{subfigure}[h]{0.34\linewidth}
%         \centering
%         \includegraphics[width=\linewidth]{figure/architecture_2.pdf}
%         \caption{}
%         \label{fig:architecture}
%     \end{subfigure}
%     \caption{\textbf{(a)} A unified multi-agent framework for generative embodied AI; \textbf{(b)} The embodied multi-agent collaborative architecture.}
%     \label{fig:overviews}
% \end{figure*}

\begin{figure}[htb!]
\centering
    \includegraphics[width=\linewidth]{figure/overall_6.pdf}
    \caption{A unified multi-agent framework for generative embodied AI.}
    \label{fig:overall_large_pic}
\end{figure}

% \begin{figure*}[h]
%     \centering
%     % \vspace{-20pt}
%     % \includegraphics[trim=0.05cm 2.5cm 0.0cm 5cm, clip, width=0.8\linewidth]{figure/overall_2.pdf}
%     \includegraphics[width=0.8\linewidth]{figure/overall_2.pdf}
%     % \vspace{-12pt} 
%     \caption{A unified multi-agent framework for generative embodied AI.}
%     % \vspace{-10pt}
%     \label{fig:overall_large_pic}
% \end{figure*}

This survey aims to provide a comprehensive and structured examination of the current state of generative multi-agent collaboration in Embodied AI, as shown in Figure~\ref{fig:overall_large_pic}. 
First, we introduce a taxonomy that classifies existing EMAS solutions based on the number of models and types of embodiments in Section~\ref{sec:arch}, highlighting how collaboration can arise both among physical agents and in purely virtual semantic environments.
Next, we explore the major building blocks of multi-agent collaboration—system perception, planning, communication, and feedback—and examine how each of these components can be designed to leverage FM-based generative capabilities in Section~\ref{sec:modular}. 
Moving beyond theoretical perspectives, we delve into practical applications in Section~\ref{sec:app}, illustrating how generative multi-agent collaboration enhances functionality across diverse embodied scenarios.

% Embedied multi-agent systems, particularly those using large language models, are still in the stage of development. 
% This survey focuses on the collaboration of multi generative agents in embodied scenarios, aims to provide a comprehensive understanding of this rapidly evolving field and inspire further exploration by researchers in this domain. 
% To the best of our knowledge, this is the first review to simultaneously address both multi-agent systems and Embodied AI in the context of the rise of large models. 

To the best of our knowledge, this is the first survey to systematically address the convergence of MAS, Embodied AI, and foundation models. 
We close by summarizing open research challenges in Section~\ref{sec:future}, delineating crucial future directions, and discussing the potential impact of EMAS on broader AI and robotics landscapes.
Our goal is to inform and inspire researchers, practitioners, and stakeholders by presenting a holistic overview of this rapidly evolving field.

% \begin{figure}[htb!]
%     \centering
%     \includegraphics[width=0.8\linewidth]{figure/architecture.pdf}
%     \caption{The embodied multi-agent collaborative architecture.}
%     \label{fig:architecture}
% \end{figure}
\begin{figure}[htb!]
\centering
    \includegraphics[width=0.7\linewidth]{figure/architecture_2.pdf}
    \caption{The embodied multi-agent collaborative architecture.}
    \label{fig:architecture}
\end{figure}

\section{Collaborative Architectures}\label{sec:arch}

% In traditional control-based or reinforcement learning-based approaches, embodied multi-agent systems often overlap significantly with multi-robot systems, where collaboration among agents is primarily reflected in the interaction between external embodied entities. This collaboration paradigm is referred to as extrinsic collaboration. In an extrinsic collaboration framework, a centralized control strategy is employed when a single overarching model governs multiple embodied entities. In contrast, a decentralized control strategy is adopted when multiple models each independently controll its corresponding embodied entity. Decentralized architectures provide flexibility and robustness, whereas centralized approaches can be effective in certain systems but may face challenges such as complexity, cost, and adaptability.

% With the rise of large language model-based agents, instances of large models equipped with different memory modules, proifle modules, and role-playing instructions can function as autonomous, reactive, and social agents, collectively forming a multi-agent system. Thus, when collaboration among multiple FM-based agents occurs internally within the system and is applied to control a single embodied entity in the external world, we refer to this as intrinsic collaboration. Internal collaboration consolidates the knowledge and contributions of different FM-based agents and maps their actions onto a single physical entity, enabling more effective execution of embodied tasks.

% In traditional approaches based on control or reinforcement learning, embodied multi-agent systems often overlap with multi-robot systems, where collaboration is reflected in the interaction between embodied entities, known as extrinsic collaboration. 
% In this framework, centralized control governs multiple entities, while decentralized control uses independent models for each entity.

Building upon the key challenges and opportunities outlined in the previous section, this section presents an overview of collaborative architectures in EMAS, as shown in Figure~\ref{fig:architecture}.
In particular, we address how generative multi-agent systems leverage either \emph{extrinsic collaboration} across multiple embodied entities or \emph{intrinsic collaboration} among multiple FMs within a single embodied entity. 
We also cover \emph{hybrid} approaches that combine these strategies to meet diverse system requirements. 
The goal is to provide a structured understanding of how multi-agent collaborations can be orchestrated to maximize adaptability, scalability, and task alignment, especially when integrated with FMs.

% With the rise of large language model-based agents, multiple FM-based agents with memory, profile, and role modules can collaborate internally to control a single embodied entity, known as intrinsic collaboration. 
% This internal collaboration consolidates the agents' knowledge and actions for more effective execution of embodied tasks. 


\subsection{Extrinsic Collaboration}

In scenarios where collaboration unfolds among multiple embodied entities, known as \emph{extrinsic collaboration}, agents physically or virtually interact to accomplish shared objectives. 
Drawing from the longstanding multi-robot and conventional MAS literature, extrinsic collaboration can be organized using either a centralized or a decentralized strategy. 
These approaches offer differing trade-offs related to scalability, communication overhead, and global versus local control.

\paragraph{Centralized Architecture}
In a centralized policy framework, a single unified model controls multiple robots or agents, offering centralized task allocation and decision-making. 
The centralized model assigns tasks based on agent capabilities and system objectives, ensuring coordination across agents by providing a global perspective. 
Studies have explored language-based~\cite{liu_coherent_2024,obata_lip-llm_2024,chen_emos_2024} and code-based~\cite{kannan_smart-llm_2024,zhang_lamma-p_2024} task allocation.

The centralized model also plays a key role in decision-making by synthesizing information from all agents to make final decisions, ensuring coherence. 
For example, \cite{yu_co-navgpt_2023} uses a centralized model for navigation target determination, \cite{tan_multi-agent_2020} uses it for interactive question answering with a 3D-CNN-LSTM QA model, and \cite{garg_foundation_2024} employs it for deadlock resolution in multi-robot systems by guiding a leader robot’s actions.

% 总结centralized 架构的优势和不足
The centralized control strategy ensures coordination by using a single model for task allocation and decision-making. 
Its advantages include optimal task distribution and consistent decisions. 
However, it can be limited by system complexity, high computational demands, and scalability issues in large or dynamic environments.


% In a centralized policy framework for multi-agents in embodied AI, there are multiple robots or embodied agents in the environment, but a single unified model is responsible for controlling them all. This centralized control architecture offers two key advantages: centralized task allocation and centralized decision-making.

% First, the centralized model can be responsible for task allocation, where it assigns specific tasks to each agent based on their capabilities and the overall system objectives. This approach ensures a coordinated effort across all agents by providing a global perspective on the task distribution. Centralized task allocation typically involves specifying the precise roles and action plans for each agent, which are tailored to their individual characteristics. Several studies have explored this approach, with models generating language-based (\cite{liu_coherent_2024},\cite{obata_lip-llm_2024},\cite{chen_emos_2024}) or code-based(\cite{kannan_smart-llm_2024},\cite{zhang_lamma-p_2024}) tasks for agents.

% Second, the centralized model also plays a crucial role in decision-making, especially in tasks where final judgments are required, such as determining a navigation target or providing an answer to a query. In such cases, the centralized model collects and synthesizes information from all agents, allowing it to make a final decision based on the gathered data. This approach ensures coherence and consistency in the decision-making process, as it integrates diverse inputs from multiple agents to arrive at a unified and optimal outcome. For instance,\cite{yu_co-navgpt_2023} uses a centralized decision-making LLM to process environmental exploration data and determine the next target position for each robot, enhancing search efficiency. \cite{tan_multi-agent_2020} explores multi-agent interactive question answering, where agents collaboratively build a global 3D status and semantic memory, which is leveraged by a centralized 3D-CNN-LSTM QA model to answer human queries. \cite{garg_foundation_2024} addresses deadlock resolution in multi-robot systems by using an FM-based model to designate a leader robot and guide its actions for conflict resolution, improving coordination.

% \begin{table*}[ht]
% \renewcommand{\arraystretch}{1.7} % 调整行间距以增大表格高度
% \setlength{\tabcolsep}{4pt} % 调整列间距
% \small % 缩小表格字体
% \begin{tabularx}{\linewidth}{c|c|X|X|X|X|X|X|X|X}
% \hline
% \multicolumn{2}{c|}{{\color[HTML]{000000} \textbf{Collaboration Architecture}}} & 
% \multirow{2}{*}{{\color[HTML]{000000} \textbf{Work}}} & 
% \multicolumn{5}{c|}{{\color[HTML]{000000} \textbf{Component}}} & 
% \multicolumn{2}{c}{{\color[HTML]{000000} \textbf{Application}}} \\ \cline{1-2} \cline{4-10}

% \multicolumn{1}{c|}{\multirow{2}{*}{}} & 
% {\color[HTML]{000000} \textbf{\begin{tabular}[c]{@{}c@{}}Control\\ Architecture\end{tabular}}} & 
% & 
% {\color[HTML]{036400} \textbf{Perception}} & 
% {\color[HTML]{F56B00} \textbf{Planning}} & 
% {\color[HTML]{3166FF} \textbf{Comm}} & 
% {\color[HTML]{F400FE} \textbf{Feedback}} & 
% {\color[HTML]{343434} \textbf{Agent Role}} & 
% {\color[HTML]{003366} \textbf{Env}} &
% {\color[HTML]{4d4d4d} \textbf{Task}}

% & \\ \hline
% & & \cite{yu_co-navgpt_2023} & Semantic map & language &  &  &  & Simulator &  \checkmark \\ \cline{3-10}
% & & work2 & 2.1 & 2.2 & 2.3 & 2.4 & 2.5 & 2.6 & 2.7 \\ \cline{3-10}
% & & work3 & 3.1 & 3.2 & 3.3 & 3.4 & 3.5 & 3.6 & 3.7 \\ \cline{3-10}
% & & work4 & 4.1 & 4.2 & 4.3 & 4.4 & 4.5 & 4.6 & 4.7 \\ \cline{3-10}
% & & work5 & -- & -- & -- & -- & -- & -- & -- \\ \cline{3-10}
% & & work6 & -- & -- & -- & -- & -- & -- & -- \\ \cline{3-10}
% & & work7 & -- & -- & -- & -- & -- & -- & -- \\ \cline{3-10}
% & & work8 & -- & -- & -- & -- & -- & -- & -- \\ \cline{3-10}
% & & work9 & -- & -- & -- & -- & -- & -- & -- \\ \cline{3-10}
% & \multirow{-5}{*}{\color[HTML]{000000} Centralized} & work15 & 5.1 & 5.2 & 5.3 & 5.4 & 5.5 & 5.6 & 5.7 \\ \cline{2-10}
% \multirow{-10}{*}{{\color[HTML]{000000} \textbf{\begin{tabular}[c]{@{}c@{}}Extrinsic\\ Collaboration\end{tabular}}}} & 
% \multirow{5}{*}{{\color[HTML]{000000} Decentralized}} & work1 & -- & -- & -- & -- & -- & -- & -- \\ \cline{3-10}
% & & work2 & -- & -- & -- & -- & -- & -- & -- \\ \cline{3-10}
% & & work3 & -- & -- & -- & -- & -- & -- & -- \\ \cline{3-10}
% & & work4 & -- & -- & -- & -- & -- & -- & -- \\ \cline{3-10}
% & & work5 & -- & -- & -- & -- & -- & -- & -- \\ \cline{3-10}
% & & work6 & -- & -- & -- & -- & -- & -- & -- \\ \cline{3-10}
% & & work7 & -- & -- & -- & -- & -- & -- & -- \\ \cline{3-10}
% & & work8 & -- & -- & -- & -- & -- & -- & -- \\ \cline{3-10}
% & & work9 & -- & -- & -- & -- & -- & -- & -- \\ \cline{3-10}
% & & work15 & -- & -- & -- & -- & -- & -- & -- \\ \hline
% \end{tabularx}
% \caption{Extrinsic Collaboration Paper}
% \label{tab:my-table}
% \end{table*}

% \begin{table*}[ht]
% \renewcommand{\arraystretch}{1.25} % 调整行间距
% \setlength{\tabcolsep}{2pt} % 调整列间距
% \tiny
% \begin{tabularx}{\linewidth}{cc|p{2cm}|X|X|X|X|X|X|X} % 自适应宽度
% \hline
% \multicolumn{2}{c|}{\textbf{Collaboration Architecture}} & 
% \textbf{Work} & 
% \multicolumn{5}{c|}{\textbf{Component}} & 
% \multicolumn{2}{c}{\textbf{Application}} \\ \cline{4-10}

%  & & & 
% \textbf{\color[HTML]{036400} Perception} & 
% \textbf{\color[HTML]{F56B00} Planning} & 
% \textbf{\color[HTML]{3166FF} Communication} & 
% \textbf{\color[HTML]{F400FE} Feedback} & 
% \textbf{\color[HTML]{343434} Agent Role} & 
% \textbf{\color[HTML]{003366} Environment} & 
% \textbf{\color[HTML]{4D4D4D} Task} \\ \hline

% \multirow{18}{*}{\textbf{\begin{tabular}[|c|]{@{}c@{}}Extrinsic\\ Collaboration\end{tabular}}} & 
% \multicolumn{1}{|c|}{\multirow{7}{*}{\textbf{Centralized}\\}} & 
% \cite{yu_co-navgpt_2023} & Semantic map & Language & Star & -- & homo-agents  & Simulator & Navigation \\ \cline{3-10}
% & \multicolumn{1}{|c|}{} & \cite{liu_coherent_2024} & Description & Language & Star & Environment & hetero-agents & Simulator, real-world & Household tasks \\ \cline{3-10}
% & \multicolumn{1}{|c|}{} & \cite{chen_emos_2024} & Semantic map & Language & FC,Star & System & hetero-agents & Simulator & Household tasks \\ \cline{3-10}
% % & & \cite{obata_lip-llm_2024} & - & Language & Star & - & homo-robots & Simulator & Manipulation (Put,Stack) \\ \cline{3-10}
% & \multicolumn{1}{|c|}{} & \cite{kannan_smart-llm_2024} & Description  & Code & Star & - & homo-agents & Simulator, real-world & Household tasks \\ \cline{3-10}
% & \multicolumn{1}{|c|}{} & \cite{zhang_lamma-p_2024} & - & Code (PDDL) & Star & System & hetero-robots & Simulator & Household tasks \\ \cline{3-10}
% & \multicolumn{1}{|c|}{} & \cite{tan_multi-agent_2020} & Semantic map & - & Star & - & homo-agents & Simulator & EQA \\ \cline{3-10}
% % & & \cite{liu_embodied_2022} & End2End & MARL & Horizontal & - &  homogeneous robots & Simulator, real-world & EIF \\ \cline{3-10}
% & \multicolumn{1}{|c|}{} & \cite{wang_safe_2024} & Description & Language & Star & Human & homo-agents & Simulator & Household tasks \\ \cline{2-10}

% & \multicolumn{1}{|c|}{\multirow{11}{*}{\textbf{Decentralized}}} & \cite{mandi_roco_2023} &  Visual detect & Language & FC & Environment & homo-agents & Simulator, real-world & Household tasks  \\ \cline{3-10}
% & \multicolumn{1}{|c|}{} & \cite{zhang_building_2024} & Semantic map & Language & FC & - & homo-agents & Simulator & Household tasks \\ \cline{3-10}
% & \multicolumn{1}{|c|}{} & \cite{zhang_combo_2024} & World model & Language & - & System & homo-agents & Simulator & Cooperative, Competitive game\\ \cline{3-10}
% & \multicolumn{1}{|c|}{} & \cite{agashe_llm-coordination_2024} & Descrpition & Language & - & System & homo-agents & Game & Overcooked, hanabi game \\ \cline{3-10}
% & \multicolumn{1}{|c|}{} & \cite{guo_embodied_2024} & - & Language & Hierarchical & Environment &homo-agents, multi-role llm & Simulator & Household tasks \\ \cline{3-10}
% % & & \cite{wu_camon_2024} & Semantic map & Language & Hierarchical & - & homo-robots & - & Navigation \\ \cline{3-10}
% & \multicolumn{1}{|c|}{} & \cite{chen_s-agents_2024} & Description  & Language & Hierarchical & - &homo-agents  & Game & Minecraft creation \\ \cline{3-10}
% & \multicolumn{1}{|c|}{} & \cite{chen_autotamp_2024} & Description & Language & - & System & homo-agents, multi-role llm & Grid & Multi grid tasks \\ \cline{3-10}
% & \multicolumn{1}{|c|}{} & \cite{chen_agentverse_2024} & - & Language & Hierarchical & Environment & homo-agents & Game &  Minecraft creation\\ \cline{3-10}
% & \multicolumn{1}{|c|}{} & \cite{zhang_towards_2024} & - & Language & FC & System & homo-agents & Simulator,game & Household tasks, overcooked game \\ \cline{3-10}
% & \multicolumn{1}{|c|}{} & \cite{tan_knowledge-based_2023} & Semantic map & - & - & - & homo-robots & Simulator & EQA \\ \cline{3-10}
% & \multicolumn{1}{|c|}{} & \cite{wu_hierarchical_2024} & Description & Language & Hierarchical & Environment & homo-agents  & Game  & Minecraft navigation \\ \hline

% \multicolumn{2}{c|}{\multirow{6}{*}{\textbf{Intrinsic Collaboration}}}  & \cite{shi_opex_2024} & Semantic Map & Language & - & - & multi-role llm & Simulator & Household tasks  \\ \cline{3-10}

% && \cite{qin_mp5_2024} & Description & Language & - & Environment & multi-role llm & Game & Minecraft creation, navigation  \\ \cline{3-10} 

% & & \cite{nayak_long-horizon_2024} & Description & Language & - & System, Environment & multi-role llm & Simulator & Household tasks   \\ \cline{3-10} 

% && \cite{zhang_controlling_2024} & Description & - & Hierarchical & System & multi-role llm & Grid & Grid Transportation   \\ \cline{3-10} 

% &&  \cite{fastandslow} & Description & Language & - & System,Human & multi-role llm  & Game & Overcooked game    \\ \cline{3-10} 

% &&\cite{chen_towards_2023} & Visual detect & Language & - & System & multi-role llm & - & EQA   \\ \hline

% \end{tabularx}
% \caption{Taxonomy of representative works. ``-'' denotes that a particular element is not specifically mentioned in this work.}
% \label{tab:large-table}
% \end{table*}

\begin{table*}[htb!]
\renewcommand{\arraystretch}{1.25}
\setlength{\tabcolsep}{3pt}
\tiny
\begin{tabularx}{\linewidth}{c|c|p{2cm}|X|X|X|X|X|X|X}
\hline
\multicolumn{2}{c|}{\textbf{Collaboration Architecture}} & 
\textbf{Work} & 
\multicolumn{5}{c|}{\textbf{Component}} & 
\multicolumn{2}{c}{\textbf{Application}} \\ \cline{4-10}

& & & 
{\color[HTML]{036400} \textbf{Perception}} & 
{\color[HTML]{F56B00} \textbf{Planning}} & 
{\color[HTML]{3166FF} \textbf{Comm.}} & 
{\color[HTML]{F400FE} \textbf{Feedback}} & 
{\color[HTML]{4D4D4D} \textbf{Agent}}    &
{\color[HTML]{003366} \textbf{Env.}} & 
{\color[HTML]{4D4D4D} \textbf{Task}} \\ \hline

\multirow{18}{*}{\makecell{Extrinsic\\Collaboration}} & 
\multirow{7}{*}{Centralized} & 
\cite{yu_co-navgpt_2023} & Semantic map & Language & Star & -- & homo-agents  & Simulator & Navigation \\ \cline{3-10}
& & \cite{liu_coherent_2024} & Description & Language & Star & Environment & hetero-agents & Simulator, real-world & Household tasks \\ \cline{3-10}
& & \cite{chen_emos_2024} & Semantic map & Language & FC,Star & System & hetero-agents & Simulator & Household tasks \\ \cline{3-10}
& & \cite{kannan_smart-llm_2024} & Description  & Code & Star & -- & homo-agents & Simulator, real-world & Household tasks \\ \cline{3-10}
& & \cite{zhang_lamma-p_2024} & -- & Code (PDDL) & Star & System & hetero-robots & Simulator & Household tasks \\ \cline{3-10}
& & \cite{tan_multi-agent_2020} & Semantic map & -- & Star & -- & homo-agents & Simulator & EQA \\ \cline{3-10}
& & \cite{wang_safe_2024} & Description & Language & Star & Human & homo-agents & Simulator & Household tasks \\ \cline{2-10}

& \multirow{11}{*}{Decentralized} & 
\cite{mandi_roco_2023} & Visual detect & Language & FC & Environment & homo-agents & Simulator, real-world & Household tasks \\ \cline{3-10}
& & \cite{zhang_building_2024} & Semantic map & Language & FC & -- & homo-agents & Simulator & Household tasks \\ \cline{3-10}
& & \cite{zhang_combo_2024} & World model & Language & -- & System & homo-agents & Simulator & Cooperative, Competitive game \\ \cline{3-10}
& & \cite{agashe_llm-coordination_2024} & Descrpition & Language & -- & System & homo-agents & Game & Overcooked, hanabi game \\ \cline{3-10}
& & \cite{guo_embodied_2024} & -- & Language & Hierarchical & Environment & homo-agents, multi-role llm & Simulator & Household tasks \\ \cline{3-10}
& & \cite{chen_s-agents_2024} & Description & Language & Hierarchical & -- & homo-agents & Game & Minecraft creation \\ \cline{3-10}
& & \cite{chen_autotamp_2024} & Description & Language & -- & System & homo-agents, multi-role llm & Grid & Multi grid tasks \\ \cline{3-10}
& & \cite{chen_agentverse_2024} & -- & Language & Hierarchical & Environment & homo-agents & Game & Minecraft creation \\ \cline{3-10}
& & \cite{zhang_towards_2024} & -- & Language & FC & System & homo-agents & Simulator,game & Household tasks, overcooked game \\ \cline{3-10}
& & \cite{tan_knowledge-based_2023} & Semantic map & -- & -- & -- & homo-robots & Simulator & EQA \\ \cline{3-10}
& & \cite{wu_hierarchical_2024} & Description & Language & Hierarchical & Environment & homo-agents & Game & Minecraft navigation \\ \hline

\multirow{6}{*}{\makecell{Intrinsic\\Collaboration}} & & 
\cite{shi_opex_2024} & Semantic Map & Language & -- & -- & multi-role llm & Simulator & Household tasks \\ \cline{3-10}
& & \cite{qin_mp5_2024} & Description & Language & -- & Environment & multi-role llm & Game & Minecraft creation, navigation \\ \cline{3-10}
& & \cite{nayak_long-horizon_2024} & Description & Language & -- & System, Environment & multi-role llm & Simulator & Household tasks \\ \cline{3-10}
& & \cite{zhang_controlling_2024} & Description & -- & Hierarchical & System & multi-role llm & Grid & Grid Transportation \\ \cline{3-10}
& & \cite{fastandslow} & Description & Language & -- & System,Human & multi-role llm & Game & Overcooked game \\ \cline{3-10}
& & \cite{chen_towards_2023} & Visual detect & Language & -- & System & multi-role llm & -- & EQA \\ \hline

\end{tabularx}
\caption{Taxonomy of representative works. ``--'' denotes that a particular element is not specifically mentioned in this work.}
% \label{tab:large-table}
\end{table*}

\paragraph{Decentralized Architecture}
% When a system comprises multiple models and multiple embodied entities, this control strategy is referred to as a decentralized strategy. In a decentralized strategy, each model independently controls its corresponding embodied entity, making each individual in the system autonomous. Decisions are made based solely on their own observations and capabilities without relying on centralized control or global information, thereby providing the system with greater flexibility and scalability.  

% \begin{table*}[ht]
% \renewcommand{\arraystretch}{1.7} % 调整行间距以增大表格高度
% \setlength{\tabcolsep}{4pt} % 调整列间距
% \scriptsize
% \begin{center} % 表格居中
% \begin{tabularx}{\linewidth}{x|x|X|X|X|X|X|X|X|X}
% \hline
% {\color[HTML]{000000} } & {\color[HTML]{000000} } & \multicolumn{5}{c|}{{\color[HTML]{000000} \textbf{Component}}} & \multicolumn{2}{c|}{{\color[HTML]{000000} \textbf{Application}}} & {\color[HTML]{000000} } \\ \cline{3-9}  

% \multirow{-2}{*}{{\color[HTML]{000000} \makecell{\textbf{Collaboration}\\ \textbf{Architecture}}}} & \multirow{-2}{*}{{\color[HTML]{000000} \textbf{Work}}} & 

% \multicolumn{1}{l|}{{\color[HTML]{036400} \textbf{Perception}}} & \multicolumn{1}{l|}{{\color[HTML]{F56B00} \textbf{Planning}}} & \multicolumn{1}{l|}{{\color[HTML]{3166FF} \textbf{Comm}}} & \multicolumn{1}{l|}{{\color[HTML]{F400FE} \textbf{Feedback}}} & \multicolumn{1}{c|}{\color[HTML]{800080} \textbf{Agent role}} & \multicolumn{1}{c|}{{\color[HTML]{003366} \textbf{Env}}}  &  \multicolumn{1}{c|}{{\color[HTML]{4d4d4d} \textbf{Task}}} &  \multirow{-2}{*}{{\color[HTML]{000000} \textbf{Code}}}  \\ \hline

%  & \cite{shi_opex_2024} & Semantic Map & Language & - & - & Observer, Planner, Executor & Simulator & EIF & \\ \cline{2-10} 
%  & \cite{qin_mp5_2024} & Description (dynamic) & Language & - & Env & Planner, Partoller, Percipient.etc & Game (Minecraft) & creation, navigation  & \checkmark \\ \cline{2-10} 
%  & \cite{nayak_long-horizon_2024} & Description & Language & - & System, Env & Planner, Actor, Corrector, Verfier & Simulator & EIF \\ \cline{2-10} 
%  & \cite{wang_llm-sap_2024} & Description, given prompt & code & - & System & LLM gen, LLM eval & - & - \\ \cline{2-10} 
%  & \cite{zhang_controlling_2024} & Description & - & Vertical & System & Critic, Assessor & Grid & Grid  Transportation \\ \cline{2-10} 
%  & \cite{chen_towards_2023} & Description (tool use) & Language & - & System & Different  API tool & - & EQA & \checkmark \\ \cline{2-10} 
% \multirow{-9}{*}{\begin{tabular}[c]{@{}c@{}}\textbf{Intrinsic} \\ \textbf{Collaboration}\end{tabular}} & \cite{liu_agentlite_2024} & - & - & Vertical & - & Manager, Individual & - & - & \checkmark  \\ \hline

% \end{tabularx}
% \end{center}
% \caption{Intrinsic Collaboration Paper}
% \label{tab:my-table-2}
% \end{table*}


% While Some early studies employed reinforcement learning methods to achieve decentralized multi-agent control strategies, with the rise of large language models, autonomous agents have significantly advanced, gaining the ability to handle a variety of tasks \cite{chen_s-agents_2024}. Consequently, more recent research leverages FMs to construct each agent within a system, forming decentralized control strategies. 

% The most direct advantage of introducing large language models lies in equipping each agent with the ability to communicate using human natural language. Unlike classical multi-agent communication with carefully structured process and predefined protocols, FMs, however, provide the opportunity to remove these constraints and allow generative models to produce messages in a dialogical manner. Such communication fosters collective intelligence, similar to human teams, where language facilitates collaboration and organization, making it particularly effective for decentralized multi-agent systems.

% In addition to communication, the semantic understanding and reasoning abilities of FMs further facilitate decentralized collaboration. In decentralized strategies, each individual can only access local observations and lacks global information, which necessitates the use of the LLM's reasoning capabilities to aid decision-making. \cite{zhang_combo_2024} utilizes a world model to assist multi-agent planning, where each individual predicts the behavior of other agents through the world model and infers its own plan. Similarly,\cite{agashe_llm-coordination_2024} introduce an auxiliary Theory of Mind Reasoning LLM to interpret the actions and needs of partner agents, thereby supporting individual decision-making.

% Furthermore, with the reasoning and communication capabilities of FMs, FM-based agents exhibit emergent sociality, enabling the introduction of human societal organizational structures into teams of LLM agents,enhancing decentralized collaboration. \cite{chen_multi-agent_2023} revealed that when not explicitly instructed on which strategy to adopt, FM-driven agents primarily follow the average strategy, representing an egalitarian organizational structure among agents. Some studies have preliminarily found that introducing a leadership role into multi-agent teams is often beneficial.\cite{guo_embodied_2024} introduced organizational frameworks for decentralized multi-agent systems, such as assigning a leader role, to reduce communication costs and improve team efficiency. \cite{wu_camon_2024} designed a communication-triggered dynamic leadership organization structure, which achieves faster team consensus with fewer communication instances, enhancing navigation effectiveness and collaborative exploration efficiency.\cite{chen_s-agents_2024} adopted a "Tree of agents" structure, designating one agent as the leadership agent while others act as executors, which demonstrated significant effectiveness.

In a decentralized strategy, each model independently controls its corresponding embodied entity, providing greater flexibility and scalability. 
Early studies used reinforcement learning for decentralized control, but the rise of FMs has enabled agents to handle diverse tasks autonomously~\cite{chen_s-agents_2024}, forming more advanced decentralized systems.

FMs enhance decentralized systems by leveraging the reasoning capabilities to improve individual decision-making based on local partial observations. 
For example, \cite{zhang_combo_2024} utilizes a world model to assist multi-agent planning, where each individual predicts the behavior of other agents through the world model and infers its own plan. 
Similarly, \cite{agashe_llm-coordination_2024} introduces an auxiliary theory-of-mind reasoning FM to interpret the actions and needs of partner agents, thereby supporting individual decision-making.

Furthermore, with the reasoning and communication capabilities of FMs, FM-based agents exhibit emergent sociality. 
\cite{chen_multi-agent_2023} reveals that when not explicitly instructed on which strategy to adopt, FM-driven agents primarily follow the average strategy, representing an egalitarian organizational structure among agents. 
Other research~\cite{guo_embodied_2024,chen_s-agents_2024} highlight the potential benefits of more structured roles within the team. 
This suggests that, similar to human social structures, FM agents can exhibit emergent behaviors that optimize collaboration by adapting to organizational frameworks, enhancing their collective ability to tackle complex tasks.


\subsection{Intrinsic Collaboration}

% While extrinsic collaboration occurs among multiple robots, intrinsic collaboration focuses on cooperation among multiple FMs within a system, also referred to as an LLM workflow. 
% Each LLM in this workflow takes on a specific role to collaboratively complete a task. 
% Research has applied this paradigm to embodied learning systems, such as~\cite{qin_mp5_2024}, which uses modules like Planner, Partoller, and Performer for task-solving in a Minecraft sandbox, and \cite{shi_opex_2024}, which decomposes tasks into Observer, Planner, and Executor roles. 
% LLaMAR~\cite{nayak_long-horizon_2024} also employs a plan-act-correct-verify framework for self-correction without oracles or simulators.

While extrinsic collaboration deals with multiple robots and embodied entities, \emph{intrinsic collaboration} occurs within the internal structure of a single system that may contain multiple FMs. 
This concept resonates with the recent push for collaborative workflows among various FM modules, each specializing in different roles, to jointly handle increasingly complex tasks. 
Such internal orchestration expands traditional notions of multi-agent coordination by focusing on consolidated decision-making within a single embodiment.

Each FM in this workflow assumes a specific function or \emph{role} to collaboratively complete a task. 
Research has applied this paradigm to embodied learning systems, such as~\cite{qin_mp5_2024}, which uses modules like planner, partoller, and performer for task-solving in a Minecraft sandbox, and \cite{shi_opex_2024}, which decomposes tasks into observer, planner, and executor roles. 
LLaMAR~\cite{nayak_long-horizon_2024} also employs a plan-act-correct-verify framework for self-correction without oracles or simulators.

Intrinsic collaboration can improve system functionality by enhancing planning accuracy, safety, and adaptability. 
For example, \cite{fastandslow} uses FM-based fast-mind and slow-mind for collaborative plan generation and evaluation, while LLaMAC~\cite{zhang_controlling_2024} employs multiple critics and an assessor to provide feedback and improve robustness.

% % 对多LLM协作输出自己的见解




% While extrinsic collaboration occurs among multiple robots, in the Generative AI era, intrinsic collaboration emphasizes the cooperation among multiple FMs within a system. This kind of intrinsic collaboration is also referred to as an LLM workflow, where each LLM takes on a specific role and function within the workflow, collaboratively completing the overall process.

% Some research have leveraged this LLM workflow paradigm to construct the whole embodied learning systems. For instance, \cite{qin_mp5_2024} constructs a system framework for solving tasks in the MC sandbox using multiple agent modules such as Planner, Partoller, and Performer. \cite{shi_opex_2024} decomposes the framework for solving embodied tasks into three modules: Observer, Planner, and Executor. Similarly, LLaMAR (\cite{nayak_long-horizon_2024}) employs a plan-act-correct-verify framework, with each part handled by a different LLM agent, allowing for self-correction from action execution feedback without relying on oracles or simulators.

% The intrnsic LLM collaboration can also target specific system functionalities, enhancing planning accuracy, safety, and adaptability through specialized agent roles.  \cite{wang_llm-sap_2024} uses two agents, LLMgen and LLMeval, distributed for plan generation and evaluation, respectively, aiming to collaboratively build a safer and more predictable LLM planning framework. LLaMAC (\cite{zhang_controlling_2024}) utilizes the collaboration of multiple Critics and one Assessor to provide suggestions for the robot's plan, thereby constructing an internal feedback mechanism to enhance the viability and robustness of the initial policy.

% % 对多LLM协作输出自己的见解
% The multi-LLM workflow can be seen as a versatile plugin that enables the workflow of a single LLM to be accomplished through the collaboration of multiple FMs. Although there is no conclusive evidence yet to demonstrate the theoretical advantages of multiple FMs over a single LLM, multi-LLM systems generally leverage intrinsic LLM collaboration to achieve more efficient task resolution, assigning unique functions and roles to each agent. This multi-LLM workflow not only maximizes the language interaction capabilities of FMs but also fully exploits their potential in specialized and adaptive tasks, making the system more flexible and reliable.

\subsection{Hybrid Collaboration Architectures}

In many real-world applications, drawing a strict boundary between extrinsic and intrinsic collaboration is neither practical nor advantageous. 
Instead, hybrid collaborative architectures combine these strategies to exploit the strengths of centralized, decentralized, and internal FM workflows. 
As embodied tasks grow in complexity, the flexibility to mix different levels of collaboration, both among robots and within an agent’s internal structure, becomes increasingly valuable.

% In practical applications, multiple collaboration strategies are often combined to form a Hybrid Control Architecture. 
% Intrinsic collaboration enhances model capabilities through modular FMs and can be applied in both centralized and decentralized embodied systems. 
% For example, CoELA~\cite{zhang_building_2024} uses five modules—Perception, Memory, Communication, Planning, and Execution—while~\cite{yu_mhrc_2024} builds agents with Observation, Memory, and Planning modules for decentralized robot collaboration. 
% Centralized models can also use modular FMs, such as~\cite{wu_hierarchical_2024}, which employs a Task LLM and Action LLM for robot task assignment.

Intrinsic collaboration enhances model capabilities through modular FMs and can be applied in centralized and decentralized systems. 
For example, CoELA~\cite{zhang_building_2024} uses five modules--perception, memory, communication, planning, and execution--while~\cite{yu_mhrc_2024} builds agents with observation, memory, and planning modules for decentralized robot collaboration. 
Centralized models can also use modular FMs, such as~\cite{wu_hierarchical_2024}, which employs a task- and action-FM for task assignment.

% Centralized and decentralized strategies can be combined, with different stages of a task utilizing different approaches. 
% Inspired by the Centralized Training with Decentralized Execution (CTDE) framework, research like~\cite{chen_emos_2024} and \cite{zhao_hierarchical_2024} propose Centralized Planning with Decentralized Execution (CPDE), where global planning guides task execution, maximizing the synergy between global oversight and local autonomy.
% In practical applications of embodied systems, it is not always to use only one collaboration strategy. Instead, multiple collaboration strategies can be combined to form a Hybrid Control Architecture.

Centralized and decentralized strategies can be combined, with different stages of a task utilizing different approaches. 
Inspired by the centralized training with decentralized execution (CTDE) framework in multi-agent reinforcement learning (MARL), \cite{chen_emos_2024} and \cite{zhao_hierarchical_2024} propose centralized planning with decentralized execution, where global planning guides task execution, maximizing the synergy between global oversight and local autonomy.

By showcasing these varying architectures, we illustrate how practitioners can effectively orchestrate multi-agent collaboration in EMAS across different levels of granularity and control. 
The next section builds on this architectural perspective by examining how key system components--perception, planning, communication, and feedback--can be designed to leverage FM-based generative capabilities for more robust and adaptive multi-agent collaboration.

% The essence of intrinsic collaboration lies in enhancing the model's capabilities through multiple modular FMs. Therefore, the paradigm of intrinsic collaboration can theoretically exist in any system involving FMs, naturally extending to both centralized and decentralized embodied collaboration. For example, CoELA (\cite{zhang_building_2024}) constructs each agent using five distinct modules, including Perception, Memory, Communication, Planning, and Execution. This modular design enables embodied agents to exhibit improved collaboration performance. Similarly, \cite{yu_mhrc_2024} builds every agent with Observation, Memory, and Planning modules to achieve closed-loop decentralized multi-heterogeneous robot collaboration. Centralized control models can also be designed using multiple modular LLM agents. For instance,\cite{wu_hierarchical_2024} developed a centralized decision model comprising a Task LLM and an Action LLM, which assigns tracking targets to each robot in a multi-robot team.

% Centralized and decentralized strategies can also be mixed, with different stages of an embodied task utilizing different strategies. Inspired by the Centralized Training with Decentralized Execution (CTDE) framework (Hu et al., 2023; Sunehag et al., 2017; Lowe et al., 2017; Mao et al., 2018) for cooperative multi-agent reinforcement learning (MARL), some research works(\cite{chen_emos_2024},\cite{zhao_hierarchical_2024}) proposed Centralized Planning with Decentralized Execution (CPDE) for cooperative FM-based multi-agent embodied systems. The CPDE architecture utilizes global state information to guide the planning process, while task execution is carried out independently by local agents, maximizing the synergy between global oversight and local autonomy.

% \begin{table*}[ht]
% \renewcommand{\arraystretch}{1.7} % 调整行间距以增大表格高度
% \setlength{\tabcolsep}{4pt} % 调整列间距
% \small % 缩小表格字体
% \begin{tabular}{|cc|l|llll|l|l|}
% \hline
% \multicolumn{2}{|c|}{{\color[HTML]{000000} }} & {\color[HTML]{000000} } & \multicolumn{4}{c|}{{\color[HTML]{000000} \textbf{Component}}} & {\color[HTML]{000000} } & {\color[HTML]{000000} } \\ \cline{4-7}
% \multicolumn{2}{|c|}{\multirow{-2}{*}{{\color[HTML]{000000} \textbf{Collaboration Architecture}}}} & \multirow{-2}{*}{{\color[HTML]{000000} \textbf{Work}}} & \multicolumn{1}{l|}{{\color[HTML]{036400} \textbf{Perception}}} & \multicolumn{1}{l|}{{\color[HTML]{F56B00} \textbf{Planning}}} & \multicolumn{1}{l|}{{\color[HTML]{3166FF} \textbf{Communication}}} & \cellcolor[HTML]{FFFFFF}{\color[HTML]{F400FE} \textbf{Feedback}} & \multirow{-2}{*}{{\color[HTML]{000000} \textbf{\begin{tabular}[c]{@{}l@{}}Experiment\\ environment\end{tabular}}}} & \multirow{-2}{*}{{\color[HTML]{000000} \textbf{Code}}} \\ \hline
% \multicolumn{1}{|c|}{} &  & work1 & \multicolumn{1}{l|}{1.1} & \multicolumn{1}{l|}{1.2} & \multicolumn{1}{l|}{1.3} & 1.4 & 1.6 & 1.7 \\ \cline{3-9} 
% \multicolumn{1}{|c|}{} &  & work2 & \multicolumn{1}{l|}{2.1} & \multicolumn{1}{l|}{2.2} & \multicolumn{1}{l|}{2.3} & 2.4 & 2.6 & 2.7 \\ \cline{3-9} 
% \multicolumn{1}{|c|}{} &  & work3 & \multicolumn{1}{l|}{3.1} & \multicolumn{1}{l|}{3.2} & \multicolumn{1}{l|}{3.3} & 3.4 & 3.6 & 3.7 \\ \cline{3-9} 
% \multicolumn{1}{|c|}{} &  & work4 & \multicolumn{1}{l|}{4.1} & \multicolumn{1}{l|}{4.2} & \multicolumn{1}{l|}{4.3} & 4.4 & 4.6 & 4.7 \\ \cline{3-9} 
% \multicolumn{1}{|c|}{} & \multirow{-5}{*}{Centralized} & work5 & \multicolumn{1}{l|}{5.1} & \multicolumn{1}{l|}{5.2} & \multicolumn{1}{l|}{5.3} & 5.4 & 5.6 & 5.7 \\ \cline{2-9} 
% \multicolumn{1}{|c|}{} &  & work6 & \multicolumn{1}{l|}{} & \multicolumn{1}{l|}{} & \multicolumn{1}{l|}{} &  &  &  \\ \cline{3-9} 
% \multicolumn{1}{|c|}{} &  & work7 & \multicolumn{1}{l|}{} & \multicolumn{1}{l|}{} & \multicolumn{1}{l|}{} &  &  &  \\ \cline{3-9} 
% \multicolumn{1}{|c|}{} &  & work8 & \multicolumn{1}{l|}{} & \multicolumn{1}{l|}{} & \multicolumn{1}{l|}{} &  &  &  \\ \cline{3-9} 
% \multicolumn{1}{|c|}{} &  & work9 & \multicolumn{1}{l|}{} & \multicolumn{1}{l|}{} & \multicolumn{1}{l|}{} &  &  &  \\ \cline{3-9} 
% \multicolumn{1}{|c|}{\multirow{-10}{*}{\begin{tabular}[c]{@{}c@{}}Extrinsic \\ Collaboration\end{tabular}}} & \multirow{-5}{*}{Decentralized} & work10 & \multicolumn{1}{l|}{} & \multicolumn{1}{l|}{} & \multicolumn{1}{l|}{} &  &  &  \\ \hline
% \end{tabular}
% \caption{Extrinsic Collaboration paper}
% \label{tab:my-table}
% \end{table*}


\section{Advancing Collaborative Functionality}\label{sec:modular}
% 在基础架构之上，我们列出了三个关键点，指出如何增强Agent collaboration，使智能体更好的进行规划与任务执行
% Although different collaboration architectures may be adopted, the general process of collaboratively solving embodied tasks is roughly the same. 
% Therefore, this section summarizes several key parts which enhance the embodied collaboration performance, including perception, planning, communication, and feedback module.

Building upon the architectural insights from Section~\ref{sec:arch}, which examined how multi-agent collaboration can be orchestrated at the structural level, we now pivot to the functional building blocks that drive effective teamwork among embodied agents. 
Specifically, we highlight how \emph{perception}, \emph{planning}, \emph{communication}, and \emph{feedback} mechanisms can be designed to harness the generative capabilities of FMs. 
By focusing on these key modules, we illustrate how EMAS solutions can more robustly interpret the physical environment, formulate and adapt plans, exchange information, and iteratively learn from both their own behaviors and the environment itself. 
This approach complements the collaboration architectures introduced previously, offering a finer-grained perspective on enabling dynamic and context-aware cooperation among embodied agents. 

\subsection{Perception}
% One of the most significant differences between Embodied Agents and FMs is that Embodied Agents need to perceive information from the physical world and interact with the environment, which requires a deeper understanding of 3D space and dynamic environments\cite{liu2024aligning}. Therefore, the perception module in embodied systems is indispensable, as it is responsible for conveying detailed descriptions of environmental features to the subsequent models\cite{pan2024recent}.
% One key difference between embodied agents and FMs is that embodied agents must perceive information from the physical world and interact with the environment, which requires a deeper understanding of 3D structures, dynamic conditions and real-time interactions~\cite{liu2024aligning}. 
% Thus, the perception module is essential, as it provides detailed environmental features to subsequent models~\cite{pan2024recent}.

Although a generative model may derive semantic knowledge from text and vision, embodied agents must actively sense and interpret the physical world. 
This entails handling 3D structures, dynamic conditions, and real-time interactions~\cite{liu2024aligning}. 
Consequently, the perception module is paramount, as it conveys detailed environmental features to subsequent models, ensuring that generative capabilities are grounded in tangible contexts~\cite{pan2024recent}. 

\paragraph{Physical Perception for FM}
% The simplest way to enable a LLM to perceive the physical environment is to directly provide a linguistic environment description. 
% Apart from manually writing the description prompt, some studies~\cite{mandi_roco_2023,chen_towards_2023} use visual models as tools to provide the object detection result; 
% Other studies~\cite{brohan2023can,huang2023voxposer} utilize Affordance Learning to perceive the environment by combining the operability and functionality of environment objects with the language model.

% In addition to passively receiving information, there are also studies that allow agents to autonomously decide \emph{when} and \emph{what type} of information to observe, that is, actively perceiving and exploring the environment. 
% For instance, \cite{qin_mp5_2024} enables the LLM to ask necessary questions about the environmental information and then answers these questions using a fine-tuned Vicuna-13B-v1.5 model, thus constructing a description of the scene.

The simplest means of providing physical context to an FM is to supply a verbal description of the environment. 
Although such prompts may be crafted manually, many approaches augment linguistic descriptions with automated tools. 
For instance, some studies~\cite{mandi_roco_2023,chen_towards_2023} use visual models to detect and describe objects, while others~\cite{brohan2023can,huang2023voxposer} employ affordance learning to enrich the FM’s understanding of how objects can be operated upon in a physical setting.
Beyond passively receiving information, recent work enables agents to decide \emph{when} and \emph{what type} of information to observe, facilitating active perception. 
For example, \cite{qin_mp5_2024} allows the FM to query a fine-tuned model about environmental details; the responses inform a progressively constructed scene description.

\paragraph{Collaborative Perception}
% In multi-agent systems, Collaborative Perception is a common approach, which investigates how to aggregate complementary perception semantics across connected agents to improve overall system performance~\cite{yang_spatio-temporal_2023}.

% In fields such as autonomous driving and drones, Collaborative Perception often relies on feature level data sharing between sensors, or information fusion at the output layer of the perception network~\cite{singh2024multi}. 
% In FM-based systems, it can construct a global environmental memory through the exploration of different agents. 
% For example, \cite{yu_co-navgpt_2023} gathers RGBD images observed by each agent and the corresponding Semantic Map derived from those images, then fuses the local Semantic Maps. 
% Meanwhile, \cite{tan_multi-agent_2020} performs 3D reconstruction on the observation images of each agent, thus combining them to create a more detailed Global 3D Status and Semantic Memory.

In multi-agent systems, collaborative perception aims to merge complementary sensory inputs from different agents, enhancing overall performance~\cite{yang_spatio-temporal_2023}. 
Within autonomous driving or drone fleets, this often arises through sensor-level data sharing or output-level fusion~\cite{singh2024multi}. 
In FM-based systems, collaborative agents may collectively build a global memory of the environment by aggregating each agent’s local maps or visual data. 
For instance, \cite{yu_co-navgpt_2023} fuses the semantic maps derived from RGBD inputs of multiple agents, and \cite{tan_multi-agent_2020} employs 3D reconstruction of each agent’s observations to form a holistic 3D status and semantic memory of the shared environment.


% \subsubsection{End-to-End Perception}
% With the rise of Vision-Language Foundation models, some decision-making models have gained the preliminary ability to directly perceive the environment. For example, \cite{zhang_combo_2024} uses a fine-tuned LLaVA model to accept environmental information as input, output suggested actions, and analyze the intentions of other agents. \cite{zhao_we_2024}, on the other hand, uses GPT-4v to directly perceive environmental information and make decisions. Moreover, recent research has attempted to use foundational models to perceive the environment and directly output robotic control actions instead of text, forming what is known as Vision-Language-Action (VLA) models. With the increase in data scale and enhanced model architecture, recent VLA models have demonstrated outstanding performance, offering possibilities for building generalized robot policy. However, there has been limited exploration of using generalized VLA models for collaboration among multiple robots.

% \subsubsection{Convert environmental information}
% Despite advances in foundational models, their handling of environmental details is often not sufficiently refined and they typically rely on large amounts of training data and computational resources. Therefore, converting raw environmental information can effectively simplify the complexity, providing a more abstract and precise representation, which allows subsequent decision-making models to perform task planning and execution more efficiently. For instance, Roco(\cite{mandi_roco_2023}) uses OWL-ViT for object recognition, generating textual descriptions of the scene from RGB images. \cite{qin_mp5_2024} aligns visual features with text embeddings using MineCLIP, and employs the LoRA fine-tuned Vicuna-13B-v1.5 model to answer environment-related questions, building a description of the scene. More research has focused on utilizing \textbf{Semantic Maps} to transform environmental information. \cite{wu_camon_2024}, \cite{shi_opex_2024}, and \cite{chen_emos_2024} construct Semantic Maps from images and extract environment-related linguistic descriptions to obtain more accurate text-based information. \cite{tan_knowledge-based_2023},\cite{liu_heterogeneous_2023}, and \cite{liu_embodied_2022} store the generated Semantic Maps and use them as features for subsequent model reasoning. Specifically, \cite{yu_co-navgpt_2023} and \cite{tan_multi-agent_2020} build global memories through collaborative exploration, constructing a global Semantic Map via multi-agent cooperation.


\subsection{Planning}

% Planning is a core module in multi-agent embodied systems, enabling agents to scheme a sequence of actions based on states, objectives, and individual capabilities.

Planning constitutes a core module of multi-agent embodied systems, enabling agents to strategize based on states, goals, and individual capabilities. 
Effective planning is crucial for task assignment, coordination, and seamlessly integrating the capabilities of generative FMs.

\paragraph{Planning format}
% Depending on the format of the plan, planning methods are typically categorized into \textit{language-based plans} and \textit{code-based plans}. 
% Language-based planning methods primarily use natural language instructions to describe and generate task plans, offering intuitiveness and scalability. 
% With the rise of LLM, this type of planning often relies on such models for generation \cite{mandi_roco_2023,yu_co-navgpt_2023}. 
% Contrastively, code-based planning methods typically depend on formatted languages or programming languages, allowing the system to describe tasks in a more precise and structured manner. 
% \cite{kannan_smart-llm_2024} uses Python code exclusively to build the overall task flow, while \cite{zhang_lamma-p_2024} converts tasks into PDDL problems and assigns corresponding PDDL plans to each robot.
Planning methods often employ either \emph{language-based} or \emph{code-based} formats. 
Language-based planning uses natural language to guide task flows, achieving intuitiveness and ease-of-adaptation, especially with the advent of advanced FMs~\cite{mandi_roco_2023,yu_co-navgpt_2023}. 
By contrast, code-based methods utilize structured programming or domain-specific notations (e.g., PDDL) for higher precision. 
\cite{kannan_smart-llm_2024} uses Python code to frame overall task flow, and \cite{zhang_lamma-p_2024} converts tasks into PDDL problems for allocation to multiple robots.

\paragraph{Planning process}
% In multi-agent collaboration, planning involves not only the decision-making of individual agents but also coordination between multiple agents, conflict resolution, and resource sharing. 
% Centralized control architectures feature a task assignment phase, where a central model allocates tasks. 
% For example, \cite{liu_coherent_2024} creates action lists for robots based on capabilities, while \cite{obata_lip-llm_2024} combines FMs with linear programming to decompose tasks. 
% \cite{chen_emos_2024} uses ``Robot Resumes'' for centralized task allocation via FM-based discussions. 
% In decentralized systems, communication between agents optimizes planning, enabling more efficient collaboration, which will be discussed in detail in the following section.
Beyond individual decision-making, multi-agent collaboration demands consensus-building, conflict resolution, and resource sharing. 
In \emph{centralized} systems, a single model frequently allocates sub-tasks. 
For example, \cite{liu_coherent_2024} generates action lists based on each agent’s capability, \cite{obata_lip-llm_2024} integrates FMs and linear programming to solve task partitions, while \cite{chen_emos_2024} exploits ``robot resumes'' for FM-based discussions around task assignment. 
In \emph{decentralized} systems, agents communicate directly to optimize their collective plans, supported by robust information exchanges that will be explored in the following subsection.

% Depending on the format of the plan, planning methods are typically categorized into \textbf{language-based plans} and \textbf{code-based plans}. Language-based planning methods primarily use natural language instructions to describe and generate task plans, offering intuitiveness and scalability. With the rise of large language models, this type of planning often relies on such models for generation (\cite{}). On the other hand, code-based planning methods typically depend on formatted languages or programming languages, allowing the system to describe tasks in a more precise and structured manner. For example, \cite{kannan_smart-llm_2024} uses Python code exclusively to build the overall task flow, while \cite{zhang_lamma-p_2024} converts tasks into PDDL problems and assigns corresponding PDDL plans to each robot.

% In multi-agent collaboration, planning involves not only the decision-making of individual agents but also coordination between multiple agents, conflict resolution, and resource sharing. Centralized control architectures typically include a task assignment phase, where a central model allocates tasks to each agent, ensuring the overall multi-agent system operates in harmony and avoids potential conflicts. For instance, \cite{liu_coherent_2024} generates an action list for each robot based on its capabilities, such as open container or open door, defining the robot's action space, and a centralized task assigner LLM then selects specific actions from these lists for each robot;\cite{obata_lip-llm_2024} integrates FMs with linear programming and dependency graphs to decompose tasks into sub-tasks and allocate them to robots; \cite{chen_emos_2024} employs a "Robot Resume" to describe the physical capabilities of each robot and uses centralized FM-based group discussions to allocate tasks.

% Decentralized architectures, on the other hand, often rely on communication between agents to exchange information, thereby optimizing individual plans and achieving efficient collaboration. We will discuss the details of communication in the following section.


\subsection{Communication}

% Communication is a unique capability and behavior brought to embodied systems by multi-agent collaboration. 
% It allows agents to share information, make effective task assignments, and collaborate on decision-making. 
% Traditional multi-agent communication often requires careful design of the communication content and information transmission strategies. 
% However, with the rise of generative agents, large language models have provided agents with zero-shot language communication abilities, greatly simplifying the design cost of the communication module.
Communication is central to MAS, enabling agents to share situational updates, coordinate tasks, and reach consensus. 
Unlike traditional approaches that require painstaking communication protocol design, generative agents can exploit the zero-shot language generation abilities of FMs, reducing the complexity of building efficient communication interfaces.

% Referring to the work in~\cite{sheng2022learning}, we divide the communication methods for Multi-Generative Agents in embodied AI scenarios into three categories:
% \noindent\textbf{(1) Star}: A virtual central agent needs to transmit messages to all other agents. The information transmitted is often the plan or action instructions for each robot, generated by the central decision-making process.
% \noindent\textbf{(2) Fully Connected (FC)}: Agents need to communicate with all others, meaning each agent can spontaneously communicate with every other agent without any restrictions. The content of the communication is entirely generated by the LLM. For example, \cite{mandi_roco_2023} equips two robotic arms with individual FMs and uses communication between FMs to collaborate on manipulation tasks. CoELA~\cite{zhang_building_2024} designs a communication module for each agent, providing the LLM with current state information by retrieving relevant memories, thus generating the communication content. 
% \noindent\textbf{(3) Hierarchical}: As the number of agents increases, the efficiency of FC communication often becomes a bottleneck. To enable more effective and efficient communication, some studies introduce the organizational structure to the FC method, forming a hierarchical communication. In this approach, multi-agent teams typically include a leadership role. Other agents prioritize reporting to the leader, who then makes the team's decisions. Many works~\cite{wu_camon_2024,chen_s-agents_2024,liu_agentlite_2024,guo_embodied_2024} find that introducing the leader role in LLM communication can avoid ineffective communication and achieve better results.

Following~\cite{sheng2022learning}, we categorize multi-generative-agents communication patterns in embodied AI to three main structures:
\begin{itemize}[leftmargin=*]
    \item \textbf{Star}: A virtual central agent controls the flow of messages, broadcasting plans or directives to other agents.Much work with centralized architecture has explored this approach~\cite{kannan_smart-llm_2024,yu_co-navgpt_2023}
    \item \textbf{Fully Connected (FC)}: Every agent communicates freely with every other agent, leveraging FM-driven messages. For instance, \cite{mandi_roco_2023} uses inter-FM dialogues between two robotic arms to coordinate manipulation tasks. In CoELA~\cite{zhang_building_2024}, each agent references current state information via memory retrieval, generating communication content through an FM.
    \item \textbf{Hierarchical}: A leadership structure emerges to boost scalability and reduce communication overhead. \cite{chen_s-agents_2024,liu_agentlite_2024,guo_embodied_2024} show how leadership roles channel or filter communications, improving efficiency and outcomes.
\end{itemize}

% In multi-generative agent collaboration, the content of communication is often generated by FMs. For example, \cite{mandi_roco_2023} equips two robotic arms with individual FMs and uses communication between FMs to collaborate on manipulation tasks. CoELA (\cite{zhang_building_2024}) designs a communication module for each agent, providing the LLM with current state information by retrieving relevant memories, thus generating the communication content. Furthermore, \cite{liu_capo_2024} enhances communication by guiding agents to generate more long-horizon strategic plans during their dialogue, rather than simply communicating to decide the next action, which would result in a greedy single-step plan that is often suboptimal. Additionally, \cite{zhang_towards_2024} leverages the advantage function evaluated by a critic as feedback, revising the plan if the advantage value falls below a defined threshold, which significantly reduces the interaction rounds to the environment, thereby improving communication efficiency.

% Furthermore, as the number of agents increases, how to design the communication architecture becomes a key issue. Current research mainly focuses on two typical communication structures: \textbf{horizontal structure} (\cite{}) and \textbf{vertical structure} (\cite{}). The horizontal structure refers to all agents communicating at the same level. In this architecture, all agents have an equal status, and information is typically shared either point-to-point or through group broadcasting. On the other hand, the vertical structure introduces a centralized hierarchical relationship, where communication between agents typically occurs through a central node or higher-level agents. In this setup, there often exists a "leader" role within the multi-agent team. Specifically, \cite{chen_scalable_2024} proposes four more refined communication architectures based on the horizontal and vertical structures, evaluating their effects on different tasks. In addition, \cite{wu_camon_2024}, \cite{chen_s-agents_2024}, \cite{liu_agentlite_2024}, and \cite{guo_embodied_2024} all find that introducing the leader role in LLM communication can avoid ineffective communication and achieve better results.



\subsection{Feedback}

Embodied tasks are complex and uncertain, making feedback mechanisms essential for agent improvement. 
Feedback enables agents to adjust and optimize behavior, allowing continuous learning based on the current state, environmental changes, or external guidance. 

\paragraph{System Feedback}
% It refers to feedback information that originates within the agent and occurs before the agent performs an action. 
% System feedback often requires the model to evaluate and revise the initial plan using prior knowledge, thereby improving the likelihood of successful execution of the plan. 
% For example, some works~\cite{liu_capo_2024,chen_emos_2024,zhang_controlling_2024} add a multi-agent discussion phase after the initial plan is established, using feedback from other agents to optimize their own plans. 
% \cite{chen_autotamp_2024} and \cite{zhang_lamma-p_2024} use FMs as checkers to verify the validity of Code-based Plans, such as checking for syntax errors. 
% Furthermore, \cite{zhang_towards_2024} constructs advantage functions to assess plans and perform closed-loop planning. 
% \cite{wang_llm-sap_2024} uses LLM to deduce the consequences of plan execution, followed by another LLM agent to score it, iterating on the plan in this manner.
System feedback refers to information generated internally before an action is taken. 
This involves agents or a centralized model revisiting their initial plans to identify flaws or potential improvements. 
Several works~\cite{liu_capo_2024,chen_emos_2024,zhang_controlling_2024} implement a multi-agent discussion phase post-plan generation, refining action lists through peer feedback. 
\cite{chen_autotamp_2024} and \cite{zhang_lamma-p_2024} employ FM checkers to validate code-based plans, ensuring syntactic correctness. 
Meanwhile, \cite{zhang_towards_2024} devises advantage functions to evaluate and iteratively refine plans, and \cite{fastandslow} applies an FM to predict plan consequences, followed by another FM that rates plan quality, thus driving iterative enhancements.

\paragraph{Environmental Feedback}
% It comes from the agent's interaction with the external environment. 
% A common approach is to optimize the task planning process using environmental feedback. 
% For instance, \cite{liu_coherent_2024} and \cite{yu_mhrc_2024} store the consequences of each action round in their memory modules, which can be referred to when planning subsequent actions. 
% \cite{qin_mp5_2024} and \cite{nayak_long-horizon_2024} reflect on the causes of action failure and correct the failed plans.

% In addition to optimizing plans, the organizational structure of the multi-agent embodied system can also self-optimize through environmental feedback. 
% \cite{chen_agentverse_2024} dynamically adjusts the roles of each agent in the team based on feedback from each round of actions, ensuring that agents play different roles based on actual needs at different stages.
% \cite{guo_embodied_2024} evaluates agents’ performance using a Critic LLM after each round and adjusts the organizational structure of the team, such as changing the leader of the team.
Environmental feedback surfaces after executing actions in the physical (or simulated) world. 
Many studies log real-world outcomes to guide future decisions. 
For example, \cite{liu_coherent_2024} and \cite{yu_mhrc_2024} store action results in memory for future planning references, whereas \cite{qin_mp5_2024} and \cite{nayak_long-horizon_2024} assess the root cause of failures and adapt their action plans accordingly. 
Additionally, multi-agent organizational structures can be reconfigured mid-task in response to environmental signals. 
\cite{chen_agentverse_2024} dynamically updates the roles, and \cite{guo_embodied_2024} employs a critic FM to evaluate agent performance, even reorganizing leadership.

\paragraph{Human Feedback}
% As an external guidance source, it plays an irreplaceable role in the evolution of multi-agent systems. 
% While agents can autonomously learn and adapt to continuously optimize their behaviors, human guidance and intervention can often provide higher-level decision-making support for the system. 

% Some research attempts to teach robots to seek human help at the appropriate moments.
% For instance, \cite{park2023clara} measures the uncertainty of task instructions from the perspectives of ``Ambiguous'' and ``Infeasible.'', \cite{wang_safe_2024} and \cite{ren2023robots} use conformal prediction to assess task uncertainty. 
% When uncertainty reaches a certain threshold, the robot is programmed to request help. 

% Besides asking for help, \cite{cui2023no} and \cite{shi2024yell} allow humans to provide real-time corrections and fine-tuning of the robot’s actions through human voice during task execution, thereby improving task completion.
External human guidance can offer nuanced interventions and strategic directions unattainable through purely automated systems. 
For instance, \cite{park2023clara} identifies \emph{ambiguous} or \emph{infeasible} task instructions warranting human assistance, while \cite{wang_safe_2024} and \cite{ren2023robots} integrate conformal prediction to measure task uncertainty and trigger human help requests. 
Beyond soliciting assistance, \cite{cui2023no} and \cite{shi2024yell} permit human operators to refine on-the-fly robot actions through spoken instructions, improving task success rates.

In sum, perception, planning, communication, and feedback emerge as foundational pillars for translating high-level collaborative architectures into practical, generative multi-agent solutions. 
Whether agents collaborate extrinsically through distributed configurations or intrinsically via multiple FMs within a single embodied, robust supporting modules ensure adaptability and resilience in real-world settings. 

The next section delves into concrete application domains, illustrating how these functional modules synergize to tackle diverse embodied tasks. 
By bridging architectural principles (Section~\ref{sec:arch}) with modular functionalities and grounding them in real-world scenarios, we aim to offer a comprehensive view of how generative multi-agent collaboration can be effectively realized in EMAS.

% \begin{table*}[ht]
% \renewcommand{\arraystretch}{1.7} % 调整行间距
% \setlength{\tabcolsep}{4pt} % 调整列间距
% % \small
% \tiny
% \begin{tabularx}{\linewidth}{x|x|x|x}
% \cline{1-4} 
% \textbf{} & \textbf{\begin{tabular}[c]{@{}l@{}}Environment \\ and Benchmark\end{tabular}} & \textbf{task description} & \textbf{Related paper} \\ \cline{1-4} 

% \textbf{Grid} & Grid World & multi-agent grid planning problems &\cite{zhang_controlling_2024}, \cite{chen_autotamp_2024},\cite{chen_scalable_2024} \\ \cline{1-4} 
% \multirow{2}{*}{\textbf{Game}} & Minecraft & Minecraft navigation,crafting,creation & \cite{chen_s-agents_2024},\cite{park_mrsteve_2024},\cite{qin_mp5_2024},\cite{zhao_hierarchical_2024},\cite{zhao_we_2024} \\ \cline{2-4} 

%  & Overcooked-AI & collaborate to finish the cook game & \cite{agashe_llm-coordination_2024},\cite{ying_goma_2024},\cite{zhang_towards_2024} \\ \cline{1-4} 
 
% \multirow{8}{*}{\textbf{Simulator}} & ThreeDWorld & transport,watch-and-help,cook tasks in ThreeDworld Env & \cite{zhang_combo_2024},\cite{liu_capo_2024},\cite{zhang_building_2024} \\ \cline{2-4} 

%  & AI-THOR & \makecell{finish user's dynamic instructions in the house \\e.g: Put apple in the fridge and switch off the bedroom light } & \cite{kannan_smart-llm_2024},\cite{wang_safe_2024},\cite{nayak_long-horizon_2024},\cite{zhang_lamma-p_2024},\cite{liu_heterogeneous_2023}  \\ \cline{2-4} 
 
%  & ALFRED & finish user's dynamic instructions in the house & \cite{shi_opex_2024} \\ \cline{2-4} 
%  & Habitat & household navigation and rearrangement task& \cite{chen_emos_2024},\cite{yu_co-navgpt_2023} \\ \cline{2-4} 
%  & VitualHome & household tasks, e.g: Prepare afternoon tea, Set Table& \cite{ying_goma_2024},\cite{guo_embodied_2024}\\ \cline{2-4} 
%  & RocoBench & \makecell{collaboration tasks on the tabletop \\ e.g: Make Sandwich,Sort Cubes,Pack Grocery}& \cite{mandi_roco_2023},\cite{zhang_towards_2024} \\ \cline{2-4} 
%  & Bestman & Pack Objects, Sort solids, Make sandwich(with navigation) & \cite{yu_mhrc_2024} \\ \cline{2-4} 
%  & Behavior-1k & finish user's dynamic instructions in the house & \cite{liu_coherent_2024} \\ \cline{1-4} 
% \end{tabularx}
% \caption{Application Table}
% \label{tab:my-table-3}
% \end{table*}


% \section{Application}

% \subsection{Pre-defined Task Solving}
% Pre-defined Task Solving typically involves specific tasks in a fixed environment with predefined rules and goals. These tasks usually come with clear objectives, constraints, and structured settings, allowing researchers to precisely control and evaluate the performance of agents. Some studies utilize the collaboration of multiple agents to complete pre-defined tasks across grid environments, game environments, simulation environments, and real-world environments. 

% \subsubsection{Grid environment}
% Grid environments are abstracted discrete spaces, typically composed of regularly arranged grids, used to simulate agent movement, path planning, and task execution. These environments simplify physical details while focusing on agent decision-making, collaboration, and path optimization, making them widely applicable for algorithm verification and reinforcement learning research. \cite{chen_autotamp_2024} improves the performance of several grid-world-based tasks using an LLM Translator and Checker framework.\cite{zhang_controlling_2024} enhances the performance of Grid Transportation tasks through feedback mechanisms. \cite{chen_scalable_2024} explores various FM-based multi-robot architectures and evaluates their performance on grid-world tasks.

% \subsubsection{Game scenarios}
% In addition, some studies design game scenarios with clear rules and objectives to test the effectiveness of multi-agent collaboration. The Overcooked Game is a typical example, simulating a multi-agent kitchen collaboration scenario where agents must cooperate within a time limit to complete tasks such as preparing ingredients, cooking, and serving dishes. Studies such as \cite{ying_goma_2024}, \cite{agashe_llm-coordination_2024}, and \cite{zhang_towards_2024} have conducted experiments in this environment. LLM-Coordination(\cite{agashe_llm-coordination_2024}) also extends to other game environments, such as Hanabi and Collab Games.

% Another typical game environment is Minecraft , which is an open-ended sandbox game. Unlike most other games studied in AI, Minecraft does not impose a predefined end goal or a fixed storyline but rather provides a unique playground with endless possibilities \cite{wang_voyager_2023},and it has become a leading testbed, offering a demanding, open-ended environment with rich interaction possibilities \cite{park_mrsteve_2024}. While early research often focused solely on single-agent decision-making, an increasing number of studies aim to achieve multi-agent collaboration in Minecraft. Some studies(\cite{park_mrsteve_2024},\cite{zhao_hierarchical_2024},\cite{qin_mp5_2024} explore collaborative navigation tasks, such as maximizing map coverage, locating specific blocks, or finding particular structures. Others(\cite{chen_s-agents_2024},\cite{chen_agentverse_2024},\cite{zhao_we_2024}) focus on tasks like collaboratively constructing buildings or collecting materials and crafting specific items.

% \subsubsection{Simulator and Real-World}
% In the field of Embodied AI, simulation and real-world environments are more commonly used as experimental settings. These environments contain rich physical information, making them closer to practical applications and posing higher demands on agents’ perception, planning, and execution capabilities. CoELA(\cite{zhang_building_2024}) and CaPo(\cite{liu_capo_2024}) conduct Multi-Agent Transport and Communicative Watch-And-Help tasks in the ThreeDWorld simulation environment. In the ThreeDWorld Multi-Agent Transport task, multiple agents collaborate and use containers to transport as many target objects as possible to designated locations. In the Watch-And-Help task, agents cooperate to complete common household activities, emphasizing agent collaboration and communication. Similarly, in the ThreeDWorld simulation environment, \cite{zhang_combo_2024} constructs TDW Cook and TDW Game tasks, focusing on cooking and board games, respectively.

% Roco(\cite{mandi_roco_2023}) introduces RocoBench, built with the MuJoCo physics engine, which serves as a benchmark for collaborative robot manipulation tasks such as making sandwiches and cleaning tables. Roco uses communication between robots to accomplish Collaborative Manipulation tasks, while Towards Efficient further improves task performance on RocoBench by introducing Reinforced Advantage feedback. Beyond RocoBench, \cite{yu_mhrc_2024} employs the Bestman simulation environment to create Collaborative Manipulation tasks similar to those in RocoBench, while \cite{obata_lip-llm_2024} focuses on multi-robot collaboration for simpler long-horizon manipulation tasks such as stacking blocks.

% Apart from manipulation, another common category of embodied tasks is navigation. \cite{yu_co-navgpt_2023} leverages the Habitat-Matterport 3D dataset to construct scenes, implementing a centralized multi-agent navigation framework that uses FMs to assign exploration areas to each robot;\cite{wu_hierarchical_2024} allocate tracking targets to each agent, while Rebel assigns initial navigation task points to each agent.



% \subsection{Embodied Instruction Following}
% Unlike the predefined tasks discussed in Section 4.1, some studies enable embodied agents to execute actions based on human-provided dynamic instructions, which are collectively referred to as Embodied Instruction Following (EIF) tasks. AI2-THOR is an open-source interactive 3D simulation platform containing over 200 meticulously designed indoor scenes. Several studies (\cite{kannan_smart-llm_2024},\cite{wang_safe_2024},\cite{liu_embodied_2022}) propose related EIF tasks based on AI2-THOR scenarios and leverage multi-agent collaboration to solve them. For instance, SMART-LLM(\cite{kannan_smart-llm_2024}) introduces a benchmark for multi-agent planning that includes instructions like "Turn on the desk and floor lamp and watch TV." Agents must not only reach the correct locations but also execute fundamental action skills and effectively decompose tasks involving multiple actions. Subsequent research has expanded this benchmark, such as MAP-THOR proposed by \cite{nayak_long-horizon_2024} and MAT-THOR introduced by \cite{zhang_lamma-p_2024}.

% In addition to AI2-THOR, other simulation environments have also been used in related research. For example, \cite{shi_opex_2024} utilizes the ALFRED environment, \cite{guo_embodied_2024} uses VirtualHome-Social, \cite{liu_coherent_2024} builds its environment based on BEHAVIOR-1K, and \cite{chen_emos_2024} develops the Habitat-MAS benchmark on top of Habitat. Despite differences in simulation environments, these studies address similar tasks, executing movements and manipulations to fulfill user-provided instructions, such as "Put the apple in the refrigerator" or "Go to the kitchen and get something to eat."

% \subsection{Embodied Question Answering}
% Embodied Question Answering (EQA) is a prominent task in embodied AI, requiring an agent to actively explore a virtual environment to answer questions about it. Unlike manipulation or navigation tasks,EQA does not prioritize physical actions or modifying the environment so much,but emphasizes reasoning abilities, including spatial, temporal, and causal understanding, while integrating exploration as a means to gather necessary information. Multi-agent collaboration can provide advantages in exploration and reasoning for Embodied Question Answering. For example, \cite{tan_knowledge-based_2023} and \cite{tan_multi-agent_2020} utilize collaborative exploration among multiple agents to build global memory, which is then used to answer questions. \cite{chen_towards_2023} leverages agents with different functions to provide their respective information, aiding the final decision-making process. \cite{patel_multi-llm_2024} employs multiple agents to answer the same question and integrates their responses to derive the final answer.

\section{Downstream Tasks: From Simulation to Real-World Deployment}\label{sec:app}

% Although multi-robot collaboration holds significant potential for future development, it is still some distance from widespread implementation. 
% Therefore, research on multi-agent embodied collaboration often relies on simulation environments for development and evaluation. 
% We will introduce the simulators and benchmarks involved in this field in Section 5.1, and summarize the application scenarios of Generative Multi-agent Collaboration in Section 5.2.

Building on the architectures and functional modules, this section examines how generative multi-agent collaboration moves from controlled simulation environments to real-world applications. 
Although many advances are validated through virtual platforms, these simulation insights lay the groundwork for tackling the complexities of intelligent transportation, household robotics, and embodied question answering.

% \subsection{Simulators}

\subsection{Simulation Platforms}\label{sec:simulators}

Earlier sections introduced how multi-agent collaboration can be structured and functionally enabled. 
Simulation environments now enter as a crucial layer for testing these designs, allowing researchers to systematically refine agent interactions without incurring real-world operational costs or risks. 

\paragraph{Grid-World Paradigms}
% Grid environments are abstracted discrete spaces, typically composed of regularly arranged grids, used to simulate agent movement, path planning, and task execution. 
% These environments simplify physical details while focusing on agent decision-making, collaboration, and path optimization, making them widely applicable for algorithm verification and reinforcement learning research. 
% \cite{chen_autotamp_2024} improves the performance of several grid-world-based tasks using an LLM Translator and Checker framework.
% \cite{zhang_controlling_2024} enhances the performance of Grid Transportation tasks through feedback mechanisms. 
% \cite{chen_scalable_2024} explores various FM-based multi-robot architectures and evaluates their performance on grid-world tasks.
Grid worlds feature cell-based structures that focus on decision-making and path planning while abstracting away physical details. 
By adopting an FM-based translator-and-checker framework, \cite{chen_autotamp_2024} improves multi-agent performance on grid tasks, while \cite{zhang_controlling_2024} introduces feedback mechanisms to enhance grid transportation. 
\cite{chen_scalable_2024} further evaluates various FM-driven multi-robot architectures in a grid setup, underscoring how these simplified worlds facilitate quick validation of collaborative designs.

\begin{table}[ht]
\renewcommand{\arraystretch}{1.25} % 调整行间距
\setlength{\tabcolsep}{2pt} % 调整列间距
\small
% \tiny
\begin{tabularx}{\linewidth}{X|X|p{5.4cm}}
\cline{1-3} 
\textbf{Simulator Level} & \textbf{\begin{tabular}[c]{@{}l@{}}Environment \\ and Benchmark\end{tabular}} & \textbf{Related paper} \\ \cline{1-3} 

\textbf{Grid} & Grid World & \cite{zhang_controlling_2024}, \cite{chen_autotamp_2024}, \cite{chen_scalable_2024} \\ \cline{1-3} 
\multirow{2}{*}{\textbf{Game}} & Minecraft & \cite{chen_s-agents_2024}, \cite{park_mrsteve_2024}, \cite{qin_mp5_2024}, \cite{zhao_hierarchical_2024}, \cite{zhao_we_2024} \\ \cline{2-3} 

& Overcooked-AI & \cite{agashe_llm-coordination_2024}, \cite{ying_goma_2024}, \cite{zhang_towards_2024} \\ \cline{1-3} 
 
\multirow{8}{*}{\textbf{Advanced 3D}} & ThreeDWorld & \cite{zhang_combo_2024}, \cite{liu_capo_2024}, \cite{zhang_building_2024} \\ \cline{2-3} 

& AI-THOR & \cite{kannan_smart-llm_2024}, \cite{wang_safe_2024}, \cite{nayak_long-horizon_2024}, \cite{zhang_lamma-p_2024}, \cite{liu_heterogeneous_2023}  \\ \cline{2-3} 
 
& ALFRED & \cite{shi_opex_2024} \\ \cline{2-3} 
& Habitat & \cite{chen_emos_2024}, \cite{yu_co-navgpt_2023} \\ \cline{2-3} 
& VitualHome & \cite{ying_goma_2024}, \cite{guo_embodied_2024} \\ \cline{2-3} 
& RocoBench & \cite{mandi_roco_2023}, \cite{zhang_towards_2024} \\ \cline{2-3} 
& Bestman & \cite{yu_mhrc_2024} \\ \cline{2-3} 
& Behavior-1k & \cite{liu_coherent_2024} \\ \cline{1-3} 
\end{tabularx}
\caption{Simulators and applications.}
\label{tab:my-table-3}
\end{table}

\paragraph{Game-Based Collaboration Scenarios}
% Some studies test multi-agent collaboration through game scenarios with clear rules, such as the Overcooked Game, where agents cooperate under a time limit to complete cook tasks. 
% Experiments in this environment include~\cite{ying_goma_2024}, \cite{agashe_llm-coordination_2024}, and \cite{zhang_towards_2024}, with LLM-Coordination extending to other games like Hanabi and Collab Games.
% Minecraft, an open-ended sandbox game, offers a unique leading testbed with endless possibilities~\cite{wang_voyager_2023,park_mrsteve_2024}. 
% While early research focused on single-agent tasks, recent studies explore multi-agent collaboration.
% Some studies~\cite{park_mrsteve_2024,zhao_hierarchical_2024,qin_mp5_2024} explore collaborative navigation tasks, such as maximizing map coverage or finding particular structures, others~\cite{chen_s-agents_2024,chen_agentverse_2024,zhao_we_2024} focus on tasks like collaboratively constructing buildings or collecting materials and crafting specific items.
Game-based platforms like Overcooked provide clear rules, time constraints, and forced coordination among agents~\cite{ying_goma_2024,agashe_llm-coordination_2024,zhang_towards_2024}. 
FM-coordination extends to other structured games such as Hanabi and Collab Games, showcasing that generative approaches are adaptable to diverse team-based challenges.
For more open-ended tasks, Minecraft~\cite{wang_voyager_2023,park_mrsteve_2024} pushes the envelope with larger environments and indefinite goals. 
Recent work~\cite{park_mrsteve_2024,zhao_hierarchical_2024,qin_mp5_2024} focuses on collaborative exploration, while others~\cite{chen_s-agents_2024,chen_agentverse_2024,zhao_we_2024} tackle resource collection or structure building.

\paragraph{Advanced 3D Environments and Robotic Simulations}
% In the field of embodied intelligence research, a more refined simulator is often indispensable. 
% These simulators are used to recreate real-world scenarios as accurately as possible, making them closer to practical applications and posing higher demands on agents' perception, planning, and execution capabilities.

Realistic simulators aim to mirror real-life complexity more closely. 
AI2-THOR~\cite{Kolve2017AI2THORAn} offers meticulously rendered indoor scenes and is used for multi-agent household tasks~\cite{kannan_smart-llm_2024,wang_safe_2024,liu_embodied_2022,shi_opex_2024}. 
Similarly, VirtualHome-Social~\cite{guo_embodied_2024}, BEHAVIOR-1K~\cite{liu_coherent_2024}, and Habitat-based benchmarks~\cite{chen_emos_2024} enable agents to develop collaborative strategies in object manipulation and navigation. 
Such platforms help bridge the gap between algorithmic development and physical deployment.

% 可以加入一些具身benchmark本身的进展介绍，尽管与多智能体无关，然后下一段再讲和多智能体相关的研究用到的具身benchmark

% AI2-THOR~\cite{Kolve2017AI2THORAn} is an open-source interactive 3D simulation platform containing over 200 meticulously designed indoor scenes. 
% Several studies~\cite{kannan_smart-llm_2024,wang_safe_2024,liu_embodied_2022} propose household tasks based on AI2-THOR scenarios and leverage multi-agent collaboration to solve them, and \cite{shi_opex_2024} utilizes the ALFRED benchmark, which is built upon the AI2-THOR environment.
% In addition to AI2-THOR, other simulation environments have also been used in related research. 
% For example, \cite{guo_embodied_2024} uses VirtualHome-Social benchmark, \cite{liu_coherent_2024} builds its environment based on BEHAVIOR-1K, and \cite{chen_emos_2024} develops the Habitat-MAS benchmark on top of Habitat simulator. 

\subsection{Emerging Applications}\label{sec:emerge-app}

Armed with validated architectures and robust functional modules, researchers have begun to face the ultimate frontier: translating simulator learnings into viable physical deployments. 
From intelligent transportation to household robotics, the following subsections spotlight how generative multi-agent collaboration is being adapted to meet real-world demands, illustrating both the maturity and remaining challenges of these systems.

\paragraph{Intelligent Transportation and Delivery}
% Applications of multi-agent collaboration in intelligent transportation include intelligent control and coordination of UAVs and UGVs, path planning and obstacle avoidance, as well as cargo delivery and computation, often relying on multi-agent reinforcement learning (MARL). 
% Recently, some studies have begun to explore the use of large models for collaboration. 
% For example, \cite{gupte_rebel_2024} utilizes FMs for initial task allocation (ITA) in environmental surveillance tasks, while \cite{wu_hierarchical_2024} uses FMs to assign targets to be tracked by each drone. 
Multi-agent collaboration in intelligent transportation covers UAV/UGV coordination for cargo delivery and environmental monitoring. 
Early approaches mainly leveraged MARL, but FM-driven solutions are now emerging. 
\cite{gupte_rebel_2024} explores FM-based initial task allocation for surveillance missions, and \cite{wu_hierarchical_2024} applies generative models to assign tracking targets, suggesting that language-guided strategies can adapt swiftly to dynamic scenarios.

\paragraph{Household Assistance Robotics}
% A large number of simulation environments are dedicated to simulating indoor environments, providing ample conditions for studying multi-agent collaboration in household tasks. 
% Many researches~\cite{kannan_smart-llm_2024,wang_safe_2024,liu_heterogeneous_2023,mandi_roco_2023,zhang_towards_2024} focus on enabling multi-agent collaboration to assist humans in completing household tasks, such as ``clearing the table'' or following instructions like ``Turn on the desk and floor lamp and watch TV.'' 
% To play the role of a household assistant, agents need to understand human intention, navigate to the correct locations, execute basic action skills, and perform reasonable decomposition of tasks that involve multiple actions.
Many 3D simulation benchmarks, including AI2-THOR and Habitat, were originally crafted to emulate domestic environments. 
Domestic tasks such as ``clearing the table'' or following instructions like ``Turn on the desk and floor lamp and watch TV'' demand robust perception, planning, and communication. 
Studies~\cite{kannan_smart-llm_2024,wang_safe_2024,liu_heterogeneous_2023,mandi_roco_2023,zhang_towards_2024} demonstrate how multiple agents can share roles, interpret commands, and divide complex tasks. 
Generative models further streamline coordination, enabling adaptive task assignment and richer human-robot interactions.

\paragraph{Beyond Exploration: Embodied Question Answering}
% Embodied Question Answering (EQA) is a prominent task in embodied AI, requiring an agent to actively explore the environment to answer questions about it. 
% Unlike other applications, EQA does not prioritize physical actions, but emphasizes reasoning abilities, including spatial, temporal, and causal understanding.
% Multi-agent collaboration can provide advantages in exploration and reasoning for EQA.
% For example, \cite{tan_knowledge-based_2023} and \cite{tan_multi-agent_2020} utilize collaborative exploration among multiple agents to build global memory, which is then used to answer questions. 
% \cite{chen_towards_2023} leverages agents with different functions to provide their respective information, aiding the final decision-making process. 
% \cite{patel_multi-llm_2024} employs multiple agents to answer the same question and integrates their responses to derive the final answer.
Embodied Question Answering (EQA) involves active exploration and reasoning in 3D spaces. 
Unlike tasks that emphasize physical interactions, EQA focuses on gathering and interpreting information, often requiring an advanced understanding of spatial layouts, object relationships, or event histories.
Multi-agent versions often leverage team-based sensing for global memory and consensus~\cite{tan_knowledge-based_2023,tan_multi-agent_2020,patel_multi-llm_2024}. 
\cite{chen_towards_2023} positions agents with specialized functions to contribute key information, showcasing how FM-driven collaboration can integrate observations into coherent answers.

In highlighting these simulation benchmarks and real-world applications, this section underscores a key trajectory in EMAS: leveraging structured testbeds for proof-of-concept, then transitioning solutions to high-stakes domains. 
Having established where and how generative multi-agent collaboration can be deployed, the subsequent sections will address remaining challenges and outline prospective frontiers for EMAS research.

% \subsubsection{Artistic robots}
\section{Open Challenges and Future Trends}\label{sec:future}

As the field of multi-agent collaboration in embodied AI systems is continuing to develop, there remain several open challenges and promising future directions. 
Despite the progress made, numerous real-world obstacles persist, limiting the application of embedied systems. 
This section identifies key challenges and outlines potential areas of exploration and innovation to address these issues.

\paragraph{Benchmarking and Evaluation}
One major challenge is lacking standardized evaluation criteria. 
While significant strides have been made in benchmarking individual agents and single-agent systems, there is a notable gap for the evaluation of embodied multi-agent collaboration. 
Existing benchmarks focus on task-specific metrics, and fail to account for the complexity of interactions, coordination, and emergent behaviors, that arise in multi-agent settings. 
There is an urgent need for unified evaluation standards for the holistic performance, including factors such as scalability, adaptability, robustness, and collective intelligence. 
The development of benchmarks is crucial to ensure consistent across different domains, and enabling meaningful comparisons between various multi-agent frameworks.

\paragraph{Data Collection and Heterogeneity}
Another challenge in multi-agent collaboration is the data scarcity and heterogeneity for embodied systems.
Collecting large-scale, high-quality datas of different systems with diverse physical characteristics and capabilities is an arduous task. 
The variation in hardware, sensor, and environmental interactions leads to inconsistence, making it difficult to generalize across systems and tasks. 
The real-world data available could be limited, hindering training and evaluating effectively. 
Additionally, most works in multi-agent collaboration are conducted in simulated environments, due to practical constraints, and only a few studies employ real-world data. 
Hence, there is a pressing need for standardized data collection, as well as innovative methods to transfer between simulation and real-world applications, to bridge the gap between theory and reality.

\paragraph{Foundation Models for Embodied AI}
The development of foundation models, particularly for embodied agents, is poised to be a transformative breakthrough in the field of multi-agent collaboration. 
Currently, generative agents primarily rely on FMs to perform complex tasks, and naturally the next step is to build specifical foundational models designed for embodied systems. 
These models serve as a core framework for multi-agent collaboration, integrating perception, decision-making, and action. 
Recent works, such as RT-1~\cite{brohan2022rt} and RDT~\cite{liu2024rdt}, %and $\pi0$, 
made significant strides in robot foundation models for adaptable and scalable systems. 
The evolution of foundation models will lay the groundwork for more seamless multi-agent collaboration, enabling agents with comprehensive capabilities and teamworks in dynamic environments. 
However, challenges remain to extend single-agent FMs to multi-agent, requiring novel architectures and methodologies.

\paragraph{Scalability of Agents}
Currently, numbers of agents involved in collaborative multi-agent  systems remains small. 
Scaling up the number of agents will lead to the increased complexity and difficulty of computation, communication, coordination, task allocations, and resource management. 
Moreover, maintaining stability and robustness in large-scale multi-agent systems requires sophisticated orchestration and coordination techniques. 
Researches on scalable architecture, efficient communication protocol, and collaborative tactics 
will be essential to unlocking the full potential of large-scale embedied systems. 
The development to optimize agent workflows and patterns will be crucial for scaling up these systems in a resource-awareness manner.

\paragraph{Human-Centric Collaboration}
The integration of robots into human-centered environments remains a critical topic. 
In many applications, multi-agent systems need to collaborate with not only each other but also  human. 
Ensuring that robots can work seamlessly alongside humans in dynamic and unstructured environments requires the development of human-robot interaction (HRI) protocols that consider human cognitive capabilities, preferences, and limitations. 
Human-robot collaboration introduces additional challenges, such as safety, adaptability, and trustworthy. 
Researches on human-robot teamwork, shared autonomy, and intuitive interfaces will be vital for fostering productive and safe collaboration between humans and robots, particularly for healthcare, industrial automation, and service robots.

\paragraph{Theoretical Foundations and Interpretability}
Current approaches of embodied multi-agent collaborations, particularly those involving FMs, often lack a solid theoretical foundation. 
While substantial progress has been made in developing practical systems, the understanding is very limited about the underlying principles and collective intelligence that emerges to govern agent interactions. 
%In particular, the question of why collaboration between large models is more effective than relying on a single model remains largely unexplored. 
A deeper theoretical exploration of the dynamic cooperation, including the roles of communication, coordination, and consensus, is essential for advancing the field. 
Furthermore, the reliability and interpretability of embedied multi-agent systems and models is critical, especially for safety-critical environments, such as automatic drive and smart railway.
%Research into the interpretability of multi-agent systems, as well as the design of explainable models, will be vital for building trust and ensuring the responsible deployment of these technologies.

%\paragraph{Safety and Ethics}
%As robots become more capable and autonomous, safety and ethical concerns will increasingly come to the forefront. 
%The ability of multi-agent systems to perform complex tasks in the physical world introduces risks, particularly when these systems are deployed in human-centric environments. 
%Ensuring that robots can operate safely, reliably, and ethically is paramount. 
%This includes preventing harm to humans, ensuring fairness and transparency in decision-making, and mitigating the potential for unintended consequences. 
%Developing robust safety protocols, ethical guidelines, and regulatory frameworks will be essential for guiding the deployment of multi-agent systems in real-world applications. 
%Additionally, as these systems become more autonomous, addressing issues of accountability and responsibility will be crucial for ensuring their ethical use.

\section{Related Work}

% Other notable related reviews include the following:  

% \cite{hu2023toward}, \cite{firoozi2023foundation}, \cite{ma2024survey}, \cite{duan2022survey}, \cite{liu2024aligning} systematically present the current state of research in Embodied AI, but none of them specifically focus on the application of multi-agent systems.

% \cite{guo2024large},\cite{chen2024survey},\cite{lu2024merge} focuses on multi-agent systems based on large language models and the multi LLM collaboration, providing a comprehensive overview of their progress, applications, and challenges, but it does not delve deeply into the application of multi-agent systems in the embodied domain.

% \cite{ismail2018survey}, \cite{yan2013survey} firstly discussed Cooperative Multi-Agent Robot Systems, which is closely related to our topic. However, these papers were written before the generative AI era, and with the rapid development of technologies such as FMs in recent years, multi-agent systems have gained new dimensions, making it essential to revisit the latest developments in this area.

% \cite{hunt2024survey} explores the applications and development of language-based robots by examining communication between robots, between humans, and between human and robot. While language communication is a key component of multi-agent collaboration, it does not encompass all forms of collaboration.

% \cite{sun2024llm} introduces FM-based multi-agent reinforcement learning, focusing on its applications in embodied AI. However, it does not entirely focus on the embodied domain but rather emphasizes the perspective of reinforcement learning.

Although numerous surveys have examined embodied AI or MAS individually, few efforts have tackled the critical overlap between these fields, leaving significant knowledge gaps unaddressed.
Early studies on embodied AI~\cite{hu2023toward,firoozi2023foundation,ma2024survey} focus on single-agent perception-action loops. 
They discuss autonomy and sensorimotor learning in depth, yet devote limited attention to collaborative paradigms. 
Similarly, \cite{duan2022survey} and \cite{liu2024aligning} explore how agents interact with environments but still assume solitary agents with limited capacity for distributed teamwork.
% in complex tasks.

In contrast, recent surveys on FM-driven multi-agent systems~\cite{guo2024large,chen2024survey,lu2024merge} showcase promising results in semantic communication and emergent coordination, especially in virtual environments. 
However, these contributions remain detached from physical embodiment, where hardware constraints, sensor noise, and kinematic coordination pose significant challenges. 
Meanwhile, classic robotics surveys~\cite{ismail2018survey,yan2013survey} laid the groundwork for cooperative swarm behaviors but lack generative capabilities that facilitate role adaptation or zero-shot planning.

Several specialized reviews provide partial bridges. 
For instance, \cite{hunt2024survey} advances language-based human-robot interaction, yet overlooks non-linguistic coordination crucial in industrial or warehouse settings. 
Likewise, \cite{sun2024llm} integrates FMs with MARL but treats embodiment mostly as an implementation detail. 
Consequently, none of these views examine physical grounding, collaborative intelligence, and generative models under a unified lens.

Our survey addresses this gap by synthesizing insights from three converging axes: 
(i) embodied AI’s physical imperatives, 
(ii) multi-agent systems’ collaborative intelligence, and 
(iii) generative models’ adaptive reasoning. 
We propose a novel taxonomy that reconciles embodiment multiplicity (physical agents) with model multiplicity (virtual agents). 
Through case studies in cross-modal perception and emergent communication, we show how FMs overcome conventional multi-agent limitations in real-world embodied contexts. 
Finally, we identify underscored challenges, such as Sim2Real transfer for generative collectives, bridging the divide between robotics and FM-based coordination. 
Our work thus establishes conceptual foundations for a new generation of embodied systems, where physical constraints and generative collaboration progress in tandem.

% \section{Background}

% \subsection{Multi agent}
% The concept of Multi agent,including the introduction for MARL and language based multi agent

% \subsection{embodied AI}
% Demonstrate the development of embodied ai,from classic methods to RL,and agent.


\section{Conclusion}\label{sec:conclusion}

This survey investigates a popular and potential research area, i.e. multi-agent collaboration in embodied systems, which focuses on how generative foundation models can be integrated into embodied multi-agent systems.
We emphasize how FM-based generative agents facilitate dynamic collaboration and emergent intelligence, and systematically explore multi-agent collaboration architectures from both intrinsic and extrinsic perspectives, focusing on key technologies such as perception, planning, communication and feedback mechanisms.
Various applications range from grid world exploration to household assistance in embodied scenarios are studied to demonstrate the potential of FM-based EMAS to address complex problems, and discuss the associated challenges and opportunities in this rapidly evolving field.
We hope this survey can serve as a valuable lamp for researchers,  practitioners, and stakeholders, that offers a comprehensive understanding of the current landscape and inspires more advanced and scalable solutions of dynamic seamless collaboration for embodied multi-agent AI. 

%% The file named.bst is a bibliography style file for BibTeX 0.99c
\clearpage
\newpage
% \bibliographystyle{named}
\bibliography{ijcai24}


%\bibliographystyle{alpha}
%\bibliography{ref}


\end{document}


