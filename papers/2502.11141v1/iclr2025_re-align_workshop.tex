
\documentclass{article} % For LaTeX2e
\usepackage{iclr2025_re-align_workshop,times}

% Optional math commands from https://github.com/goodfeli/dlbook_notation.
\input{math_commands.tex}

\usepackage{hyperref}
\usepackage{url}
\usepackage{graphicx}
\usepackage{subcaption} % For subfigures
\usepackage{makecell}
\usepackage{booktabs}
\usepackage{multirow}
\usepackage{hhline}


\title{Cognitive Neural Architecture Search \\ Reveals Hierarchical Entailment}

% Authors must not appear in the submitted version. They should be hidden
% as long as the \iclrfinalcopy macro remains commented out below.
% Non-anonymous submissions will be rejected without review.

\author{Lukas Kuhn$^{*}$, Sari Saba-Sadiya$^{*,\dagger}$, Gemma Roig \\
Department of Informatics\\
Goethe-Universit√§t Frankfurt\\
}

% The \author macro works with any number of authors. There are two commands
% used to separate the names and addresses of multiple authors: \And and \AND.
%
% Using \And between authors leaves it to \LaTeX{} to determine where to break
% the lines. Using \AND forces a linebreak at that point. So, if \LaTeX{}
% puts 3 of 4 authors names on the first line, and the last on the second
% line, try using \AND instead of \And before the third author name.

\newcommand{\fix}{\marginpar{FIX}}
\newcommand{\new}{\marginpar{NEW}}

\iclrfinalcopy % Uncomment for camera-ready version, but NOT for submission.
\begin{document}


\maketitle

\begin{abstract}
%Convolutional neural networks have long been the leading class of models in representational similarity analysis of the human visual cortex. 
Recent research has suggested that the brain is more shallow than previously thought, challenging the traditionally assumed hierarchical structure of the ventral visual pathway. Here, we demonstrate that optimizing convolutional network architectures for brain-alignment via evolutionary neural architecture search results in models with clear representational hierarchies. Despite having random weights, the identified models achieve brain-alignment scores surpassing even those of pretrained classification models - as measured by both regression and representational similarity analysis. Furthermore, through traditional supervised training, architectures optimized for alignment with late ventral regions become competitive classification models. These findings suggest that hierarchical structure is a fundamental mechanism of primate visual processing. Finally, this work demonstrates the potential of neural architecture search as a framework for computational cognitive neuroscience research that could reduce the field's reliance on manually designed convolutional networks.
\end{abstract}

\section{Introduction}

% Moved from Methods since it sounds way too much like an introduction to the methodology

\def\thefootnote{*}\footnotetext{These authors contributed equally to this work}\def\thefootnote{\arabic{footnote}}
\def\thefootnote{$\dagger$}\footnotetext{Corresponding Author: \texttt{sadiya@rz.uni-frankfurt.de}\\}\def\thefootnote{\arabic{footnote}}


Throughout the last decade, Convolutional Neural Networks (CNNs) have emerged as powerful cognitive models capable of providing valuable insight into the neural mechanisms underlying primate visual processing \citep{Yamis2014,StYves2022,Manshan2025}. In their seminal work, \cite{Yamis2014} demonstrated that CNNs trained to perform image classification can be used to predict brain activity. Moreover, their findings suggested a shared representational hierarchy between CNN layers and visual cortex regions, where intermediate and late CNN layers correspond to intermediate and late visual processing regions, respectively. However, recent research that directly explored the emergence of brain-like hierarchy in neural networks trained to directly predict brain activity found evidence against the necessity of entailment hierarchy \citep{StYves2022}. Based on their results, the authors posit the \textit{shallow brain hypothesis}, arguing that low-level representations may not be necessary as preprocessing stages for higher-level representations. Our work expands on this \textit{shallow vs deep-brain} debate by employing Neural Architecture Search (NAS) to explore the emergence of early visual cortex-like representation in network architectures optimized to align with late ventral representation. 

Previous studies have demonstrated that it is possible to identify CNNs with state-of-the-art classification performance by directly optimizing model architectures using methods such as reinforcement learning or genetic algorithms. For instance, \citep{GeneticCNN,liu2018hierarchical} leveraged genetic algorithms to `evolve' architectures that outperform manually designed CNNs on MNIST and CIFAR-10 datasets. More recently, \cite{mundt2021neuralarchitecturesearchdeep} employed NAS to identify network architectures that, even without gradient descent training, compute representations that enable classification performance comparable to fully trained deep networks by simply training a linear probe to predict the image label. Building on this, we evolved CNNs to predict cognitive representations across different regions of the ventral stream. We formulate a simple hypothesis in favor of the \textit{deep-brain} model: optimizing CNNs to predict late visual representations in the inferior temporal (IT) cortex would spontaneously optimize their alignment with representations found in the early (V2) and intermediate (V4) visual cortex regions. Our results demonstrate that NAS can identify CNNs that outperform manually designed image classification models such as AlexNet, VGG16 and CORNet. Furthermore, we found that the optimal CNNs for predicting V2 and V4 representations were sub-networks of those optimized for predicting IT representations, indicating that these earlier representations might be necessary when trying to predict high level visual representations, therefore providing evidence in favor of the \textit{deep-brain} model of the visual cortex. Finally, we also observed that the models optimized to predict brain representations were also excellent backbones for image classification. 

%When researching similar questions regarding the architecture of the visual cortex, researchers often employ a simple recipe: Specific and targeted modification to the Neural Network architecture are introduced while keeping other factors that could influence model-brain alignment (such as the training data) constant. If the model-brain alignment increases, then the results are seen as evidence of a similar element in the brain architecture. For instance, in \citep{Manshan2025} increase in alignment between model activations and the representations found in specific brain regions after feedback and top down mechanisms are introduced is seen as evidence that the processing in these areas relies on top-down signals. However, this popular approach has several drawbacks: Only      

%Similar debates surrounding for instance The debate surrounding hierarchical nature of the brain poses unique challenges for computational modeling approaches.  

%This debate highlights a major challenge in modern computational cognitive neuroscience; the performance of ANN as cognitive models is influenced by many factors, including training data, loss function, and model architecture. Researchers have previously overcome this issue by limiting the cross model variability when using ANNs as cognitive models. For instance, \citep{Kshitij2021,Kshitij2024} utilized a pool of ANNs that share architecture and training data, differing only in the visual task they were trained to solve. This approach of varying the all model parameters other than the loss function enabled the authors to make inferences regarding the cognitive functionality of cognitive representations as they cascade in space \citep{Kshitij2021} and time \cite{Kshitij2024}. Here we utilize an analogous approach where neural architecture search is used to 
the ANNs architecture while the training and   

%\section{Related Work}
%Recent surveys give an overview over the vast amount of current Neural architecture search algorithms that have been widely adopted for algorithmically finding strong performing architectures for image classification \citep{ren2021comprehensivesurveyneuralarchitecture, NASsurvey}. 

%One class of algorithms utilize evolutionary methods, inspired by the process of natural selection, using bio-inspired methods such as selection, mutation and crossover \citep{liu2018hierarchical, real2017largescaleevolution, GeneticCNN}. 


\begin{figure}[t]
    \centering
    {\includegraphics[width=12cm]{ReAlignMethod_v2.png}}
    \caption{The evolutionary neural architecture search framework: Starting with a generation of neural architectures, for each model embeddings of all images in the shared NSD dataset are extracted. A ridge regression is then trained to predict the recorded fMRI activity and the correlation coefficient between the predicted and ground truth fMRI is calculated. The models are evaluated based on the mean correlation for all subjects, and the bottom 50\% are eliminated. Finally genetic operations are used to repopulate the models for the next generation.}
    \label{fig:accuracy}
\end{figure}

\section{Method}
 We follow the standard evolutionary NAS methodology of allowing the genetic algorithm to perform selection, mutation, and crossover of the best networks in each generation to find an optimal CNN architecture \citep{liu2018hierarchical}. In the following section, we present the specifics of this evolutionary architecture search. That is, we discuss the search space, the evaluation strategy, and the genetic operators used to evolve each new generation of CNNs. 

\subsection{Search Space}
Following \cite{GeneticCNN}, we construct an initial generation of random individual networks, where each is a standard hierarchical stack of multiple convolution and max-pooling layers. We empirically found that linear layers are bad predictors of brain-alignment and therefore excluded them from the search space to allow for faster convergence. We also limit the searchable hyper-parameter ranges of the convolution layers kernel size (3 to 11), stride (1 to 4) and number of filters (64 to 512). Furthermore, the max-pooling layers kernel size range was 2 to 3. Finally, to further restrict the search space we also enforce the CNNs to always have a monotonically increasing number of filters across the layers.

%In initial experiments we evaluated each network with three random seeds but found that increasing this number to ten helps with stabilizing the convergence. 

\subsection{Genetic Operators}
After all the models in a generation are evaluated, we remove the bottom 50\% of the CNN population based on fitness. We then create new offspring networks to repopulate the population. This is achieved using standard mutation and crossover genetic operators \citep{GeneticCNN}.

Our mutation strategy employs three operators on each selected parent network: addition, modification, and removal. The addition operation introduces new layers while maintaining architectural validity, with special attention to channel dimensionality progression and layer-type constraints. Modification alternate between layer-type transformations (with probability $P=0.3$) and parameter refinements ($P=0.7$) in which architecture elements such as the kernel size are adjusted. The removal operation preserves network integrity by selectively eliminating layers while maintaining essential architectural elements (minimum depth of one layer and output size larger than one).

Our crossover operator implements a single-point crossover strategy in which architectures exchange structural information at a randomly selected position. The operation creates offspring by preserving the parent's layers up to the crossover point and inheriting the remaining layers from the second parent, maintaining architectural validity through constraint checking.


\subsubsection{Evaluation}
Adapting the approach of \cite{mundt2021neuralarchitecturesearchdeep} we evaluate multiple randomly initialized versions of the same network, guaranteeing that the models are picked based on architecture, rather than a lucky weight initialization (the lottery ticket hypothesis). We evaluate network performance by extracting the last layer image encoding and training a ridge regression to predict fMRI responses to the same image. The fitness of each model was calculated by taking the mean Pearson correlation coefficient over ten consecutive random seeds for each subject. Finally, to speed convergence, in the first two generations we artificially increase the population size by evaluating every layer of each network (not just the last) and use the best performing sub-network in following generations. Following common practice, the random network weights were initialized using a Kaiming uniform distribution with a bias of zero.

\subsection{Dataset}
The regression was trained using data from the NSD Dataset \cite{NSDDataset}, a large-scale fMRI dataset of 8 subjects viewing thousands of natural scenes. Specifically, we used a set of $872$ images shared across all subjects. Following \citep{Manshan2025}, we used a subset of five subjects (subjects 1,2,4,5,7) with a high signal-to-noise ratio (SNR). Moreover, we focused on the brain activity recorded in V2, V4, and the Inferior Temporal cortex (IT) as stand-ins for representations in the early, intermediate, and late ventral stream respectively. Specifically, IT activations were constructed by concatenating activations from the FFA, FBA, EBA and PPA regions. 

\subsection{Baseline Models}
We compare the brain-alignment of our models against well known CNNs such as AlexNet and VGG16 which are often used as cognitive models (see \cite{Yamis2014,Manshan2025}). Moreover, we also use CORNetS which was specifically designed to process information in a more brain-like manner \cite{CORNet}.


\begin{figure}[t]
    \centering
    {\includegraphics[width=10cm]{ReAlign2025_fig1.png}}
    \caption{Left: The optimal \emph{EvoIT} architecture. Right: The average rewards for the architectures optimized to predict V2, V4, and IT brain activations in each generation}
    \label{fig:combined}
\end{figure}

\section{Experiments and Results}
The brain alignment results reported in this section are in terms of percent of variance explained relative to the lower noise ceiling. For representational similarity analysis we followed the standard lower noise ceiling calculation \cite{RSA}. For the regression based alignment score we used the estimation method presented by \cite{LageCastellanos2019}.

\subsection{Evolutionary Search for Cognitive Models}
We ran our evolutionary search three times for each brain region. Each run consisted of $100$ generations with a mutation rate of $0.25$ and a crossover rate of $0.5$. The optimal architectures discovered were virtually identical in all runs optimizing for the alignment with the same brain region, indicating that the identified networks are robust to noise in the evolutionary search process. Moreover, the three optimal architectures EvoV2, EvoV4, and EvoIT had high alignment with their respective brain regions, outperforming most baseline models (Table \ref{tab:model-comparison}). The number of layers for EvoV2, EvoV4, and EvoIT was five, six, and nine respectively. 


\begin{table}[ht]
\centering
\renewcommand{\arraystretch}{1.2}
\begin{tabular}{|m{4em}|c|c|c|c|c|c|c|}
\hhline{~~------}
 \multicolumn{2}{c}{} & \multicolumn{2}{|c|}{V2} & \multicolumn{2}{c|}{V4} & \multicolumn{2}{c|}{IT} \\
 \hhline{~~------}
 \multicolumn{2}{c|}{} & Reg & RSA & Reg & RSA & Reg & RSA \\
\hline
\multirow{2}{=}{\centering AlexNet} & Random & 8 & 5.15 & 5.14 & 3.09 & 1.29 & 0.40 \\
& Trained & 4.6 & 14.51 & 2.59 & 7.54 & 1.12 & 1.16 \\
\hline
\multirow{2}{=}{\centering VGG16} & Random & 1.09 &  3.03 &  5.4 & 1.51  & 0.95  &  0.12 \\
& Trained & \textbf{13.76} & 16.12 & 4.82 & 6.91 & 0.75 & 0.85 \\
\hline
\multirow{2}{=}{\centering CORNet} & Random & 2.38 & 1.52 & 2.33 & 0.91 & 0.65 & 0.33 \\
& Trained & 2.276 & \textbf{17.82} & 1.4 & \textbf{9.99}  & 1.13 & 1.09 \\
\hline
\multirow{2}{=}{\centering EvoV2} & Random & 11.9 & 5.99 & 6.15 & 3.47 & 0.95 & 0.41 \\
& Trained & 3.76 & 6.33 & 1.81 & 3.52  & 0.69 & 0.56 \\
\hline
\multirow{2}{=}{\centering EvoV4} & Random & 11.98 & 3.94 & 6.5 & 2.47 & 1.2 & 0.41 \\
& Trained & 3.544 & 6.32 & 1.9 & 4.00 & 0.55 & 0.60 \\
\hline
\multirow{2}{=}{\centering EvoIT} & Random & 10.64 & 3.90 & \textbf{6.63} & 2.70 & \textbf{1.92} & 0.43 \\
& Trained & 8.82 & 16.33 & 4.06 & 8.27 & 1.04 & \textbf{1.18} \\
\hline
\end{tabular}
\caption{Brain-model similarity as measured by regression and representational similarity analysis across brain regions and model architectures for both trained and random weights. All Trained models use weights optimized on the CIFAR-10 classification (Section \ref{sub:cifar})}
\label{tab:model-comparison}
\end{table}


\subsection{Representational Hierarchy in Evolutionary Cognitive Models}
We formulated the following hypothesis in favor of the existence of hierarchical entailment across brain region representations: optimizing CNNs to predict activations in the IT representations will also spontaneously optimize the networks to learn V2 and V4 representations. To accomplish this we tested the brain-alignment of each brain region with each layer in all CNNs (Table \ref{tab:model-comparison}). Indeed, we find that EvoIT contained sub-networks that are competitive predictors of V2 and V4 (in fact, a subnetwork of EvoIT was the best in class V4 model). Specifically, the EvoIT layer that was most correlated with V4 was the third pooling layer (Figure \ref{fig:combined} left). Moreover, manually inspecting the best performing architectures we observed that the EvoV4 and EvoIT architectures contained subnetworks virtually identical to EvoV2 and EvoV4 respectively. Overall, these results indicate that to compute representations similar to those found in the IT it is indeed beneficial to first compute representations similar to those found in V2 and V4.  

\subsection{Training Evolutionary Cognitive Models for Image Classification} \label{sub:cifar}

CNNs designed to perform image classification are state-of-the-art cognitive models \cite{Yamis2014}. Here we investigate if CNNs with architectures that were specifically optimized for brain-alignment can be trained to perform image classification. To achieve this we used the best architectures identified by the evolutionary search by adding a linear layer with Softmax on top of the CNN backbone and training the models with cross-entropy on the CIFAR-10 dataset for 7 epochs. To establish multiple baselines we also randomized the weights of the baseline CNNs and trained them using a similar procedure.

We observe that the classification performance increased for models optimized to align with later ventral regions, with EvoV2 having the lowest score, followed by EvoV4 and EvoIT. Overall, the performance of EvoIT was close to the performance of several baseline models (Table \ref{tab:cifar10}). 

\begin{table}[ht]
\centering
\begin{tabular}{ccccccc} \toprule
 \rule{0pt}{2ex} & EvoV2 & EvoV4 & EvoIT & VGG16 & AlexNet & CORNet \\
\midrule
 \makecell{Top-1 \\ Accuracy} & 64.1 & 67.7 & 77.2 & 78.5 & 79.5 & 80.85 \\
\bottomrule
\end{tabular}
\caption{Classification performance after training randomly initialized models on CIFAR-10}
\label{tab:cifar10}
\end{table}


\subsection{Regression and Representational Similarity Analysis}

Both regression and representational similarity analysis have been used to measure brain-model similarity. The evolutionary search fit function we used was directly based on the Pearson correlation between ground truth fMRI and the predictions of a trained ridge regression. Therefore, it is to be expected that, while the models identified by this optimization outperform the baselines when the evaluation is done with regression, the RSA results are less consistent. Moreover, training the networks using the CIFAR-10 classification task improved brain-alignment as measured through RSA while hurting the regression score. This might indicate that the representation space of the evolved models lacks some structural elements that can only be learned through gradient descent training. We look forward to exploring this further using experiments that employ other brain-alignment scores such as RSA and CKA.  

%We found that our proposed neural architecture search finds novel architectures that outperform the established AlexNet in regression and representational similarity analysis for all three regions of interest. Similarly the evolved networks outperform VGG-16 in RSA for all three ROIs and for V4 and IT for ridge regression while performing slightly worse in regression for V2 (see Table \ref{tab:model-comparison}).


%\begin{figure}[h]
%   \centering
%   \includegraphics[width=0.8\textwidth]{cifar10accbars.png}
%   \caption{Test set accuracy of all models on Cifar10}
%   \label{fig:accuracy}
%\end{figure}

\section{Discussion and Future Work}

In this paper we used genetic algorithm based neural architecture search to optimize the architecture of the convolutional neural networks directly to be more brain-like. Through this framework we identified network architectures that had high similarity to various brain regions despite the lack of any gradient descent based training. Moreover, we found that the model optimized for similarity with late ventral stream areas contained subnetworks that were virtually identical to those identified as the optimal models for similarity with early and intermediate visual cortex representations. This finding directly contributes to the recent discussion regarding the hierarchy  - or lack thereof - found across visual cortex representation \citep{Yamis2014,StYves2022}.

More broadly, the framework presented here is a potential new useful tool for computational cognitive neuroscience research. Previous research tackling questions regarding the architecture of the brain often followed a specific recipe: CNN architectures are modified in a controlled manner while the training data and function are held constant. Model-brain alignment is then measured to determine if the modification improves brain similarity, which would be taken as evidence that the modification constitutes an abstraction of a mechanism found in the brain (for example see \cite{Manshan2025}). In contrast, the cognitive NAS framework presented here optimizes the model architecture directly, instead of relaying on handcrafted CNNs, which might introduce unwanted bias. 

The initial results presented here highlight the potential utility of Cognitive NAS for the research community. However, the results of our experiments also raise multiple questions. Specifically, while the evolved networks were powerful encoding models, their performance was subpar when measured through representational similarity analysis. Future work should carefully investigate the impact of the brain-similarity measure used during the NAS on the trajectory of the architecture search and the final networks identified as optimal cognitive models.   

\newpage
\bibliography{iclr2025_conference}
\bibliographystyle{iclr2025_conference}

%\appendix
%\section{Appendix}
%You may include other additional sections here.


\end{document}
