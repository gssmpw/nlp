\section{Conclusion}


In this paper, we present CaseGen, the first comprehensive benchmark designed to evaluate LLMs in legal case documents generation task. 
CaseGen fills a critical gap by providing a robust framework for evaluating LLMs in multi-stage legal document generation.
By covering all key stages of legal document creation—from prosecution to judgment—it enables a more nuanced evaluation of LLM performance in tasks that capture the complexities of real-world legal work.
Additionally, CaseGen supports four key tasks: drafting defense statements, writing trial facts, composing legal reasoning, and generating judgment results. It offers both researchers and practitioners a means to identify strengths and weaknesses in current LLMs, laying the foundation for future improvements in automated legal case documents generation.
In the future, we will further refine the automated evaluation framework for legal documents generation to achieve more accurate and comprehensive assessment results.