\section{Motivation}
\label{sec:background}

The current practice in DL application development involves sequentiality, where the data is prepared first followed by model design and training. 
The designed model is tested for 
crash and silent bugs using the data by monitoring and identifying abnormal behavior during training~\cite{schoop2021umlaut,wardat21DeepLocalize,wardat22DeepDiagnosis,BraiekDeepChecker,cao2022deepfd,Zhang21Autotrainer,ghanbari2023deepmufl}.
Bugs can originate from any stage of the DL pipeline, such as data preparation or model design, and often exhibit similar symptoms during training.
For example, exploding gradients, a common issue that can arise from the data preparation stage due to improper training data or from the model design stage due to high learning rate, improper weight or bias initialization, and large batch size~\cite{wardat22DeepDiagnosis}. This overlap in the symptoms makes it challenging to pinpoint the root cause of the bugs~\cite{islam20repairing}, thereby requiring several iterations to identify the stage of origin of the bug correctly
\cite{schoop2021umlaut,wardat21DeepLocalize,wardat22DeepDiagnosis,BraiekDeepChecker,ghanbari2023deepmufl}.
This highlights the need for a systematic approach for testing and debugging each stage in isolation.

In traditional software development, unit testing has proven useful for conducting a lightweight evaluation of each functionality in isolation. It holds the potential to identify areas for improvement before integrating the two functionalities~\cite{runeson2006survey}.
Due to the dependency of the model design stage on the data preparation stage in the DL applications, unit testing cannot be applied directly.
Our insight is that by decoupling these stages and using the concept of mocks, each module can be tested independently before integration.
In the context of DL, \textit{mock data} refers to synthetic data designed to replicate the key characteristics of real data, while a \textit{mock model} is a simplified version of the real model that mimics its behavior without incorporating the complexities of the full model architecture.


To illustrate, consider a DL program shown in \figref{Motivation} designed to predict the selling price of the trucks based on 7 features. 
The code from \texttt{Lines 1-8} represents the preparation of the data, \texttt{Lines 9-13} represents the model design, and finally the model is trained (\texttt{Line 14}) using the data obtained from \texttt{Lines 5 \& 8}.
During model training, the program behaved erratically, resulting in NaN values for both the metrics, \ie, mean\_squared\_error and mean\_absolute\_error.
NaN loss during training can arise from either of the two stages: the data preparation stage, due to NaN values in data, or the model design stage, due to too high learning rate causing model parameters to update too aggressively, divide by zero error during learning or incorrect weight initialization~\cite{wardat21DeepLocalize}. 
For instance, this behavior occurred because of the NaN value in the data for the DL program shown in \figref{Motivation}, as the developer forgot to remove or replace missing values during data preparation.
Even if the issues in the data preparation stage are addressed, silent bugs in the model design stage can still occur.
Isolating the two stages and testing them independently using mocks can help the developer identify and address the issue at the correct stage,
thereby reducing the overall debugging effort required during the training process.
This motivates the development of {\em KUnit}, a novel approach for facilitating unit testing of DL applications using mocks.
The fundamental idea of {\em KUnit} is based on the observation that the behavior of the original data on the mock model and the original model on the mock data remains consistent.
To illustrate, for the example in \figref{Motivation}, the unit testing of the data preparation stage using a mock model resulted in NaN loss
(consistent with the original model behavior). 
{\em KUnit} reported that the issue occurred because of missing values in the data which can be addressed in the data preparation stage.
Similarly, for the model design stage, the oscillating loss on the mock data reported by {\em KUnit} (consistent with the model behavior on original data after replacing the missing values), indicates incorrect hyperparameter selection, which can be refined before combining two stages.
Unit testing these stages and resolving issues at the error-inducing stage enables early resolution of potential problems before initiating the training process.
The rest of this work describes our approach, {\em KUnit}, for enabling mock testing for DL applications.


\begin{figure*}[t!]
    \centering
    \subfloat[\centering Interface of data preparation stage]{{\includegraphics[height=4.5cm]{figures/InterfaceDataStage.pdf} }}%
    \qquad
    \subfloat[\centering Interface of model design stage]{{\includegraphics[height=4.5cm]{figures/InterfaceModelStage.pdf} }}%
    \caption{Interface definition and class description.}%
    \label{fig:InterfaceDefinition}
\vspace{-0.6cm}
\end{figure*}


