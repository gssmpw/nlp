\section{Threats to Validity}
\label{sec:THREATSTOVALIDITY}
A potential threat to the internal validity of our study is the possibility of bugs in {\em KUnit}'s implementation, which could lead to inaccurate results. To mitigate this risk, we conducted a user study involving developers with diverse expertise levels and backgrounds, ensuring diverse perspectives on {\em KUnit}'s functionality. Additionally, we have made {\em KUnit}'s source code publicly available, allowing other researchers to review and validate our work.
In the user study, participants used DeepDiagnosis for debugging. DeepDiagnosis detects bugs and suggests fixes to resolve them. Participants manually addressed each bug identified by DeepDiagnosis and repeated the process until no further issues were reported. To mitigate the risk due to incorrect tool usage, we had our protocol reviewed by the authors of DeepDiagnosis to ensure it aligned with its intended functionality~\cite{commwith}.
Our proposed approach may be affected by external threats, such as imprecise conditions used as assertions and the effectiveness of the actionable fixes provided as solutions. To mitigate the risk, we have adopted guidelines from previous works~\cite{islam20repairing,wardat22DeepDiagnosis,Zhang21Autotrainer,ahmed23dlcontract,Khairunnesa2023,cao2022deepfd,ghanbari2023deepmufl} and Keras documentation~\cite{Keras,kerasexamples}. 
In our empirical evaluation, we assessed 50 DL programs in our benchmark. This process involved manually separating each DL program into two parts: data preparation and model design, which could introduce human error. To mitigate this threat, one of the co-authors thoroughly reviewed each part to 
ensure correctness.




