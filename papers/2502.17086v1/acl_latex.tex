% This must be in the first 5 lines to tell arXiv to use pdfLaTeX, which is strongly recommended.
\pdfoutput=1
% In particular, the hyperref package requires pdfLaTeX in order to break URLs across lines.

\documentclass[11pt]{article}

% Change "review" to "final" to generate the final (sometimes called camera-ready) version.
% Change to "preprint" to generate a non-anonymous version with page numbers.
\usepackage[preprint]{acl}

% Standard package includes
\usepackage{times}
\usepackage{latexsym}

% For proper rendering and hyphenation of words containing Latin characters (including in bib files)
\usepackage[T1]{fontenc}
% For Vietnamese characters
% \usepackage[T5]{fontenc}
% See https://www.latex-project.org/help/documentation/encguide.pdf for other character sets

% This assumes your files are encoded as UTF8
\usepackage[utf8]{inputenc}

% This is not strictly necessary, and may be commented out,
% but it will improve the layout of the manuscript,
% and will typically save some space.
\usepackage{microtype}

% This is also not strictly necessary, and may be commented out.
% However, it will improve the aesthetics of text in
% the typewriter font.
\usepackage{inconsolata}

%Including images in your LaTeX document requires adding
%additional package(s)
\usepackage{graphicx}
\usepackage{amsmath}
\usepackage{amssymb}
\usepackage{multirow}
\usepackage{booktabs} % For better table rules
\usepackage{caption}  % Optional, for caption customization
\usepackage{booktabs}   % For improved table rules
\usepackage{caption}    % For caption customization
\usepackage{makecell}   % For multi-line cells
\usepackage{float}
\usepackage{lipsum}
\usepackage{stfloats} % Add this to your preamble
\usepackage{xcolor}     % For color support




% Define a command for a cell with three lines: F1, Precision, and Recall
\newcommand{\triple}[3]{\makecell{#1\\#2\\#3}}
\newcommand{\dualerow}[3]{%
  \makecell{#1 \\ {\small #2\;/\;#3}}%
}
% Define a command to insert a subtle gray line between rows.
\newcommand{\grayline}{%
  \noalign{\vskip 0.5ex\color{gray}\hrule height 0.1pt\vskip 0.5ex}%
}


% Define a command that displays the overall F1 score on the first line,
% and the F1 scores for strength and weakness on the second line.
\newcommand{\swrow}[3]{%
  \makecell{#1 \\ {\small #2\;/\;#3}}%
}



% \newcommand{\see}[1]{#1}
\newcommand{\see}[1]{\textcolor{red}{#1}}
\newcommand{\notyet}[1]{\textcolor{purple}{TODO: #1}}
\newcommand{\hgshin}[1]{{\color{orange}HG: #1}}
% \newcommand{\strike}[1]{\see{\sout{#1}}}

\newcommand{\placeholder}[1]{{\color{lightgray}\lipsum[#1]}}
\newcommand{\keyword}[1]{``#1''}

\definecolor{citecolor}{HTML}{0071bc}
\definecolor{pinegreen}{rgb}{0.0, 0.47, 0.44}
\definecolor{cornellred}{rgb}{0.7, 0.11, 0.11}
\definecolor{cadmiumgreen}{rgb}{0.0, 0.42, 0.24}
\definecolor{royalblue}{rgb}{0.0, 0.14, 0.4}
\definecolor{spirodiscoball}{rgb}{0.06, 0.75, 0.99}
\definecolor{mylightblue}{rgb}{0.85, 0.90, 0.94}
\definecolor{kaistblue}{RGB}{20,135,200}
\definecolor{auburn}{RGB}{166,38,57}



% If the title and author information does not fit in the area allocated, uncomment the following
%
%\setlength\titlebox{<dim>}
%
% and set <dim> to something 5cm or larger.

\title{Automatically Evaluating the Paper Reviewing Capability of \\ Large Language Models}

% Author information can be set in various styles:
% For several authors from the same institution:
% \author{Author 1 \and ... \and Author n \\
%         Address line \\ ... \\ Address line}
% if the names do not fit well on one line use
%         Author 1 \\ {\bf Author 2} \\ ... \\ {\bf Author n} \\
% For authors from different institutions:
% \author{Author 1 \\ Address line \\  ... \\ Address line
%         \And  ... \And
%         Author n \\ Address line \\ ... \\ Address line}
% To start a separate ``row'' of authors use \AND, as in
% \author{Author 1 \\ Address line \\  ... \\ Address line
%         \AND
%         Author 2 \\ Address line \\ ... \\ Address line \And
%         Author 3 \\ Address line \\ ... \\ Address line}

% \author{
%     Hyungyu Shin \\ KAIST \\ \texttt{hyungyu.sh@kaist.ac.kr} 
%     \And 
%     Jingyu Tang \\ Huazhong University of Science and Technology \\ \texttt{u202215423@hust.edu.cn} 
%     \And 
%     Yoonjoo Lee \\ KAIST \\ \texttt{yoonjoo.lee@kaist.ac.kr} 
%     \AND
%     Nayoung Kim \\ KAIST \\ \texttt{skdud727@kaist.ac.kr} 
%     \And 
%     Hyunseung Lim \\ KAIST \\ \texttt{charlie9807@kaist.ac.kr} 
%     \And 
%     Ji Yong Cho \\ LG AI Research, Cornell University \\ \texttt{jiyong.cho@lgresearch.ai} 
%     \AND
%     Hwajung Hong \\ KAIST \\ \texttt{hwajung@kaist.ac.kr} 
%     \And 
%     Moontae Lee \\ LG AI Research, University of Illinois Chicago \\ \texttt{moontae.lee@lgresearch.ai} 
%     \And 
%     Juho Kim \\ KAIST \\ \texttt{juhokim@kaist.ac.kr} 
% }
\author{
    Hyungyu Shin$^{\dagger}$, Jingyu Tang$^{\ddagger}$, Yoonjoo Lee$^{\dagger}$, Nayoung Kim$^{\dagger}$, Hyunseung Lim$^{\dagger}$, \\
    \textbf{Ji Yong Cho$^{\S}$}, \textbf{Hwajung Hong$^{\dagger}$}, \textbf{Moontae Lee$^{\S,\|}$}, \textbf{Juho Kim$^{\dagger}$} \\\\
    $^{\dagger}$KAIST \quad $^{\ddagger}$Huazhong University of Science and Technology \\
    $^{\S}$LG AI Research \quad $^{\|}$University of Illinois Chicago \\\\
 %    \texttt{\{hyungyu.sh, yoonjoo.lee, skdud727, charlie9807, hwajung, juhokim\}@kaist.ac.kr} \\
 % \texttt{u202215423@hust.edu.cn} \quad 
 % \texttt{\{jiyong.cho, moontae.lee\}@lgresearch.ai}
 % \texttt{jiyong.cho@lgresearch.ai} \quad \texttt{moontae.lee@lgresearch.ai}
 %    % .ai} \quad \texttt{moontae.lee@lgresearch.ai}\\
}


%\author{
%  \textbf{First Author\textsuperscript{1}},
%  \textbf{Second Author\textsuperscript{1,2}},
%  \textbf{Third T. Author\textsuperscript{1}},
%  \textbf{Fourth Author\textsuperscript{1}},
%\\
%  \textbf{Fifth Author\textsuperscript{1,2}},
%  \textbf{Sixth Author\textsuperscript{1}},
%  \textbf{Seventh Author\textsuperscript{1}},
%  \textbf{Eighth Author \textsuperscript{1,2,3,4}},
%\\
%  \textbf{Ninth Author\textsuperscript{1}},
%  \textbf{Tenth Author\textsuperscript{1}},
%  \textbf{Eleventh E. Author\textsuperscript{1,2,3,4,5}},
%  \textbf{Twelfth Author\textsuperscript{1}},
%\\
%  \textbf{Thirteenth Author\textsuperscript{3}},
%  \textbf{Fourteenth F. Author\textsuperscript{2,4}},
%  \textbf{Fifteenth Author\textsuperscript{1}},
%  \textbf{Sixteenth Author\textsuperscript{1}},
%\\
%  \textbf{Seventeenth S. Author\textsuperscript{4,5}},
%  \textbf{Eighteenth Author\textsuperscript{3,4}},
%  \textbf{Nineteenth N. Author\textsuperscript{2,5}},
%  \textbf{Twentieth Author\textsuperscript{1}}
%\\
%\\
%  \textsuperscript{1}Affiliation 1,
%  \textsuperscript{2}Affiliation 2,
%  \textsuperscript{3}Affiliation 3,
%  \textsuperscript{4}Affiliation 4,
%  \textsuperscript{5}Affiliation 5
%\\
%  \small{
%    \textbf{Correspondence:} \href{mailto:email@domain}{email@domain}
%  }
%}

\begin{document}
\maketitle
\begin{abstract}
Peer review is essential for scientific progress, but it faces challenges such as reviewer shortages and growing workloads. Although Large Language Models (LLMs) show potential for providing assistance, research has reported significant limitations in the reviews they generate. While the insights are valuable, conducting the analysis is challenging due to the considerable time and effort required, especially given the rapid pace of LLM developments. To address the challenge, we developed an automatic evaluation pipeline to assess the LLMs' paper review capability by comparing them with expert-generated reviews. By constructing a dataset\footnote{\url{https://figshare.com/s/d5adf26c802527dd0f62}} consisting of 676 OpenReview papers, we examined the agreement between LLMs and experts in their strength and weakness identifications. The results showed that LLMs lack balanced perspectives, significantly overlook novelty assessment when criticizing, and produce poor acceptance decisions. Our automated pipeline enables a scalable evaluation of LLMs' paper review capability over time.







\end{abstract}



\input{sections/1_Introduction}
\input{sections/3_Data_collection}
\input{sections/4_Data_analysis}
\input{sections/5_Result}
% \input{sections/6_Implication}
\input{sections/2_Related_work}
\input{sections/7_Conclusion}


% \section{Introduction}

% These instructions are for authors submitting papers to *ACL conferences using \LaTeX. They are not self-contained. All authors must follow the general instructions for *ACL proceedings,\footnote{\url{http://acl-org.github.io/ACLPUB/formatting.html}} and this document contains additional instructions for the \LaTeX{} style files.

% The templates include the \LaTeX{} source of this document (\texttt{acl\_latex.tex}),
% the \LaTeX{} style file used to format it (\texttt{acl.sty}),
% an ACL bibliography style (\texttt{acl\_natbib.bst}),
% an example bibliography (\texttt{custom.bib}),
% and the bibliography for the ACL Anthology (\texttt{anthology.bib}).

% \section{Engines}

% To produce a PDF file, pdf\LaTeX{} is strongly recommended (over original \LaTeX{} plus dvips+ps2pdf or dvipdf). Xe\LaTeX{} also produces PDF files, and is especially suitable for text in non-Latin scripts.

% \section{Preamble}

% The first line of the file must be
% \begin{quote}
% \begin{verbatim}
% \documentclass[11pt]{article}
% \end{verbatim}
% \end{quote}

% To load the style file in the review version:
% \begin{quote}
% \begin{verbatim}
% \usepackage[review]{acl}
% \end{verbatim}
% \end{quote}
% For the final version, omit the \verb|review| option:
% \begin{quote}
% \begin{verbatim}
% \usepackage{acl}
% \end{verbatim}
% \end{quote}

% To use Times Roman, put the following in the preamble:
% \begin{quote}
% \begin{verbatim}
% \usepackage{times}
% \end{verbatim}
% \end{quote}
% (Alternatives like txfonts or newtx are also acceptable.)

% Please see the \LaTeX{} source of this document for comments on other packages that may be useful.

% Set the title and author using \verb|\title| and \verb|\author|. Within the author list, format multiple authors using \verb|\and| and \verb|\And| and \verb|\AND|; please see the \LaTeX{} source for examples.

% By default, the box containing the title and author names is set to the minimum of 5 cm. If you need more space, include the following in the preamble:
% \begin{quote}
% \begin{verbatim}
% \setlength\titlebox{3cm}
% \end{verbatim}
% \end{quote}
% where \verb|<dim>| is replaced with a length. Do not set this length smaller than 5 cm.

% \section{Document Body}

% \subsection{Footnotes}

% Footnotes are inserted with the \verb|\footnote| command.\footnote{This is a footnote.}

% \subsection{Tables and figures}

% See Table~\ref{tab:accents} for an example of a table and its caption.
% \textbf{Do not override the default caption sizes.}

% \begin{table}
%   \centering
%   \begin{tabular}{lc}
%     \hline
%     \textbf{Command} & \textbf{Output} \\
%     \hline
%     \verb|{\"a}|     & {\"a}           \\
%     \verb|{\^e}|     & {\^e}           \\
%     \verb|{\`i}|     & {\`i}           \\
%     \verb|{\.I}|     & {\.I}           \\
%     \verb|{\o}|      & {\o}            \\
%     \verb|{\'u}|     & {\'u}           \\
%     \verb|{\aa}|     & {\aa}           \\\hline
%   \end{tabular}
%   \begin{tabular}{lc}
%     \hline
%     \textbf{Command} & \textbf{Output} \\
%     \hline
%     \verb|{\c c}|    & {\c c}          \\
%     \verb|{\u g}|    & {\u g}          \\
%     \verb|{\l}|      & {\l}            \\
%     \verb|{\~n}|     & {\~n}           \\
%     \verb|{\H o}|    & {\H o}          \\
%     \verb|{\v r}|    & {\v r}          \\
%     \verb|{\ss}|     & {\ss}           \\
%     \hline
%   \end{tabular}
%   \caption{Example commands for accented characters, to be used in, \emph{e.g.}, Bib\TeX{} entries.}
%   \label{tab:accents}
% \end{table}

% As much as possible, fonts in figures should conform
% to the document fonts. See Figure~\ref{fig:experiments} for an example of a figure and its caption.

% Using the \verb|graphicx| package graphics files can be included within figure
% environment at an appropriate point within the text.
% The \verb|graphicx| package supports various optional arguments to control the
% appearance of the figure.
% You must include it explicitly in the \LaTeX{} preamble (after the
% \verb|\documentclass| declaration and before \verb|\begin{document}|) using
% \verb|\usepackage{graphicx}|.

% \begin{figure}[t]
%   \includegraphics[width=\columnwidth]{example-image-golden}
%   \caption{A figure with a caption that runs for more than one line.
%     Example image is usually available through the \texttt{mwe} package
%     without even mentioning it in the preamble.}
%   \label{fig:experiments}
% \end{figure}

% \begin{figure*}[t]
%   \includegraphics[width=0.48\linewidth]{example-image-a} \hfill
%   \includegraphics[width=0.48\linewidth]{example-image-b}
%   \caption {A minimal working example to demonstrate how to place
%     two images side-by-side.}
% \end{figure*}

% \subsection{Hyperlinks}

% Users of older versions of \LaTeX{} may encounter the following error during compilation:
% \begin{quote}
% \verb|\pdfendlink| ended up in different nesting level than \verb|\pdfstartlink|.
% \end{quote}
% This happens when pdf\LaTeX{} is used and a citation splits across a page boundary. The best way to fix this is to upgrade \LaTeX{} to 2018-12-01 or later.

% \subsection{Citations}

% \begin{table*}
%   \centering
%   \begin{tabular}{lll}
%     \hline
%     \textbf{Output}           & \textbf{natbib command} & \textbf{ACL only command} \\
%     \hline
%     \citep{Gusfield:97}       & \verb|\citep|           &                           \\
%     \citealp{Gusfield:97}     & \verb|\citealp|         &                           \\
%     \citet{Gusfield:97}       & \verb|\citet|           &                           \\
%     \citeyearpar{Gusfield:97} & \verb|\citeyearpar|     &                           \\
%     \citeposs{Gusfield:97}    &                         & \verb|\citeposs|          \\
%     \hline
%   \end{tabular}
%   \caption{\label{citation-guide}
%     Citation commands supported by the style file.
%     The style is based on the natbib package and supports all natbib citation commands.
%     It also supports commands defined in previous ACL style files for compatibility.
%   }
% \end{table*}

% Table~\ref{citation-guide} shows the syntax supported by the style files.
% We encourage you to use the natbib styles.
% You can use the command \verb|\citet| (cite in text) to get ``author (year)'' citations, like this citation to a paper by \citet{Gusfield:97}.
% You can use the command \verb|\citep| (cite in parentheses) to get ``(author, year)'' citations \citep{Gusfield:97}.
% You can use the command \verb|\citealp| (alternative cite without parentheses) to get ``author, year'' citations, which is useful for using citations within parentheses (e.g. \citealp{Gusfield:97}).

% A possessive citation can be made with the command \verb|\citeposs|.
% This is not a standard natbib command, so it is generally not compatible
% with other style files.

% \subsection{References}

% \nocite{Ando2005,andrew2007scalable,rasooli-tetrault-2015}

% The \LaTeX{} and Bib\TeX{} style files provided roughly follow the American Psychological Association format.
% If your own bib file is named \texttt{custom.bib}, then placing the following before any appendices in your \LaTeX{} file will generate the references section for you:
% \begin{quote}
% \begin{verbatim}
% \bibliography{custom}
% \end{verbatim}
% \end{quote}

% You can obtain the complete ACL Anthology as a Bib\TeX{} file from \url{https://aclweb.org/anthology/anthology.bib.gz}.
% To include both the Anthology and your own .bib file, use the following instead of the above.
% \begin{quote}
% \begin{verbatim}
% \bibliography{anthology,custom}
% \end{verbatim}
% \end{quote}

% Please see Section~\ref{sec:bibtex} for information on preparing Bib\TeX{} files.

% \subsection{Equations}

% An example equation is shown below:
% \begin{equation}
%   \label{eq:example}
%   A = \pi r^2
% \end{equation}

% Labels for equation numbers, sections, subsections, figures and tables
% are all defined with the \verb|\label{label}| command and cross references
% to them are made with the \verb|\ref{label}| command.

% This an example cross-reference to Equation~\ref{eq:example}.

% \subsection{Appendices}

% Use \verb|\appendix| before any appendix section to switch the section numbering over to letters. See Appendix~\ref{sec:appendix} for an example.

% \section{Bib\TeX{} Files}
% \label{sec:bibtex}

% Unicode cannot be used in Bib\TeX{} entries, and some ways of typing special characters can disrupt Bib\TeX's alphabetization. The recommended way of typing special characters is shown in Table~\ref{tab:accents}.

% Please ensure that Bib\TeX{} records contain DOIs or URLs when possible, and for all the ACL materials that you reference.
% Use the \verb|doi| field for DOIs and the \verb|url| field for URLs.
% If a Bib\TeX{} entry has a URL or DOI field, the paper title in the references section will appear as a hyperlink to the paper, using the hyperref \LaTeX{} package.

% \section*{Acknowledgments}

% This document has been adapted
% by Steven Bethard, Ryan Cotterell and Rui Yan
% from the instructions for earlier ACL and NAACL proceedings, including those for
% ACL 2019 by Douwe Kiela and Ivan Vuli\'{c},
% NAACL 2019 by Stephanie Lukin and Alla Roskovskaya,
% ACL 2018 by Shay Cohen, Kevin Gimpel, and Wei Lu,
% NAACL 2018 by Margaret Mitchell and Stephanie Lukin,
% Bib\TeX{} suggestions for (NA)ACL 2017/2018 from Jason Eisner,
% ACL 2017 by Dan Gildea and Min-Yen Kan,
% NAACL 2017 by Margaret Mitchell,
% ACL 2012 by Maggie Li and Michael White,
% ACL 2010 by Jing-Shin Chang and Philipp Koehn,
% ACL 2008 by Johanna D. Moore, Simone Teufel, James Allan, and Sadaoki Furui,
% ACL 2005 by Hwee Tou Ng and Kemal Oflazer,
% ACL 2002 by Eugene Charniak and Dekang Lin,
% and earlier ACL and EACL formats written by several people, including
% John Chen, Henry S. Thompson and Donald Walker.
% Additional elements were taken from the formatting instructions of the \emph{International Joint Conference on Artificial Intelligence} and the \emph{Conference on Computer Vision and Pattern Recognition}.

% Bibliography entries for the entire Anthology, followed by custom entries
%\bibliography{anthology,custom}
% Custom bibliography entries only
\bibliography{main}


\clearpage
\appendix
\begin{onecolumn}
\section{Appendix}

\label{sec:appendix}



\subsection{Review Generation}
\subsubsection{Prompts for Expert Review Generation}
\label{appendix:gt-prompt}

In this section, we provide prompts for identifying key strength and weakness from review data. Figure~\ref{fig:metareview-summarization} shows the prompt for extracting weakness and strength from meta-review. Figure~\ref{fig:augmentedReview} shows the prompt for using detailed comments from reviews to augment the extracted elements. Figure~\ref{fig:paraphrasing} shows the prompt for removing some extraneous reference. We used the three prompts in a prompt chain, sequentially running the prompts.

\begin{figure*}[h]
    \centering
    \includegraphics[width=\linewidth]{Prompt-Meta-Review-Summarization.pdf}
    \caption{Prompt for Meta-Review Summarization}
    \label{fig:metareview-summarization}
\end{figure*}

\begin{figure*}[h]
    \centering
    \includegraphics[width=\linewidth]{Prompt-AugmentedReview.pdf}
    \caption{Prompt for Generating  Augmented Review }
    \label{fig:augmentedReview}
\end{figure*}

\begin{figure*}[h]
    \centering
    \includegraphics[width=\linewidth]{Prompt-Paraphrasing-AugmentedReview.pdf}
    \caption{Prompt for Paraphrasing  Augmented Review }
    \label{fig:paraphrasing}
\end{figure*}


\clearpage


% \subsection{Additional Experiments Results}

% In this section, we provide detailed results on the focus of LLM and human reviewers when they are reviewing papers.


% confusion matrix  ggests that the er- rors tend to occur in semantically related categories, indicating that the misclassifications are not arbitrary but rather reflect subtle ambiguities inherent in the data. 


\


\subsubsection{Prompts for LLM Review Generation}

\label{appendix:llm-prompt}
Figure~\ref{fig:llm-review-gen} shows the prompt for using LLM to generate reviews from paper.


\begin{figure*}[h]
    \centering
    \includegraphics[width=1\linewidth]{prompt-generate-review.pdf}
    \caption{Prompt for LLM Review Generation}
    \label{fig:llm-review-gen}
\end{figure*}

\clearpage


\subsection{Details of Building Automatic Annotator }
\subsubsection{AI paper writing guidelines}
\label{appendix:guidelines}
To ensure guidelines are comprehensive, we collected guidelines from 9 sources, comprising a total of 243 items, as shown in Table~\ref{tab:guideline_item_count}. An item refers to a specific requirement mentioned in the guidelines, which serves as a distinct criterion for reviewing or writing a paper.
\begin{table}[h]
\centering
\caption{Guidelines and Item Count Summary}
\label{tab:guideline_item_count}
\begin{tabular}{lr}
\toprule
Guideline & Item Count \\
\midrule
ICML Paper Writing Best Practices\footnotemark[1] & 38 \\
ICML 2023 Paper Guidelines\footnotemark[2] & 30 \\
NIPS 2024 Reviewer Guidelines\footnotemark[3] & 18 \\
ACL Checklist\footnotemark[4] & 49 \\
How to Write a Good Research Paper in the Machine Learning Area\footnotemark[5] & 6 \\
ACL Ethics Review Questions\footnotemark[6] & 21 \\
AAAI Reproducibility Checklist\footnotemark[7] & 29 \\
NeurIPS 2021 Paper Checklist Guidelines\footnotemark[8] & 46 \\
ICLR 2019 Guidelines\footnotemark[9] & 6 \\
\midrule
\textbf{Total Count} & \textbf{243} \\
\bottomrule
\end{tabular}
\end{table}

\footnotetext[1]{\url{https://icml.cc/Conferences/2022/BestPractices}}
\footnotetext[2]{\url{https://icml.cc/Conferences/2023/PaperGuidelines}}
\footnotetext[3]{\url{https://neurips.cc/Conferences/2024/ReviewerGuidelines}}
\footnotetext[4]{\url{https://aclrollingreview.org/responsibleNLPresearch/}}
\footnotetext[5]{\url{https://www.turing.com/kb/how-to-write-research-paper-in-machine-learning-area}}
\footnotetext[6]{\url{https://2023.eacl.org/ethics/review-questions/}}
\footnotetext[7]{\url{https://aaai.org/conference/aaai/aaai-25/aaai-25-reproducibility-checklist/}}
\footnotetext[8]{\url{https://neurips.cc/Conferences/2021/PaperInformation/PaperChecklist}}
\footnotetext[9]{\url{https://iclr.cc/Conferences/2019/Reviewer_Guidelines}}




\subsubsection{Prompts}
\label{appendix:annotate-prompt}

In this section, we provide prompts designed to annotate reviews. We designed 4 prompts where each corresponds to one of the four combinations of target/aspect and strength/weakness. Specifically, we designed Target-Strength (Figure~\ref{fig:target-strength-prompt}), Aspect-Strength, (Figure~\ref{fig:aspect-strength-prompt}), Target-Weakness (Figure~\ref{fig:target-weakness-prompt}) , and Aspect-Weakness (Figure~\ref{fig:aspect-weakness-prompt}) prompts.





% Strengths and weaknesses identification prompt 

\begin{figure*}[t]
    \centering
    \includegraphics[width=\linewidth, height=1\textheight, keepaspectratio]{prompt-target-strength.pdf}
    \caption{Prompt for Automatic Target Annotation for Strength}
    \label{fig:target-strength-prompt}
\end{figure*}


\begin{figure*}[t]
    \centering
    \includegraphics[width=\linewidth, height=1\textheight, keepaspectratio]{prompt-target-weakness.pdf}
    \caption{Prompt for Automatic Target Annotation for Weakness}
    \label{fig:target-weakness-prompt}
\end{figure*}

\begin{figure*}[t]
    \centering
    \includegraphics[width=\linewidth, height=1\textheight, keepaspectratio]{prompt-aspect-strength.pdf}
    \caption{Prompt for Automatic Aspect Annotation for Strength}
    \label{fig:aspect-strength-prompt}
\end{figure*}

\begin{figure*}[t]
    \centering
    \includegraphics[width=\linewidth, height=1\textheight, keepaspectratio]{prompt-aspect-weakness.pdf}
    \caption{Prompt for Automatic Aspect Annotation for Weakness}
    \label{fig:aspect-weakness-prompt}
\end{figure*}

\clearpage

\subsubsection{Annotation Comparison}
\label{appendix:annotate-confusion-matrix}

We present a comparison between LLM and human annotations for both target and aspect. Figures~\ref{fig:error-target-matrix} and Figure~\ref{fig:error-aspect-matrix} illustrate the discrepancies. Areas of alignment between LLM and human annotations are shown in green, while red highlights regions with significant discrepancies.




\begin{figure}[h]
    \centering
    \includegraphics[width=0.5\linewidth]{error-target-matrix.png}
    \caption{LLM vs. human target annotation}
    \label{fig:error-target-matrix}
\end{figure}


\begin{figure}[h]
    \centering
    \includegraphics[width=0.5\linewidth]{aspect-error-matrix.png}
    \caption{LLM vs. human aspect annotation}
    \label{fig:error-aspect-matrix}
\end{figure}


While LLM annotations differ from human annotations in some cases, certain discrepancies remain reasonable. Figure~\ref{fig:target-case} and Figure~\ref{fig:aspect-case}  illustrate examples of such reasonable discrepancies.

\begin{figure}[h]
    \centering
    \includegraphics[width=1\linewidth]{target-case.pdf}
    \caption{Cases of Target Annotation Discrepancy}
    \label{fig:target-case}

\end{figure}

\begin{figure}[h]
    \centering
    \includegraphics[width=1\linewidth]{aspect-case.pdf}
    \caption{Cases of  Aspect Annotation Discrepancy}
    \label{fig:aspect-case}

\end{figure}

\clearpage

\subsubsection{Results}
\label{appendix:result}

The following tables present a comprehensive performance comparison of models across different metrics and evaluation targets, including both strengths and weaknesses (Table~\ref{tab:target-all}), as well as separate analyses focusing on strengths (Table~\ref{tab:target_strength_metrics}) and weaknesses (Table~\ref{tab:target_weakness_metrics}). Additionally, we provide a similar comparison across metrics and broader aspects, including both strengths and weaknesses (Table~\ref{tab:aspect-all}), strengths alone (Table~\ref{fig:aspect-strength}), and weaknesses alone (Table~\ref{fig:aspect-weakness}).


\begin{table}[h]
    \centering
    \caption{Performance Comparison of Models Across Metrics and Targets (Including both Strengths and Weaknesses)}    
    \small
    \begin{tabular}{lccccccc}
        \toprule
        Target & Problem & Prior Research & Method & Theory & Experiment & Conclusion & Paper \\
        \midrule
        F1 (gpt-4o-mini) & 0.268 & 0.076 & 0.737 & 0.427 & 0.680 & 0.103 & 0.227 \\
        F1 (gpt-4o) & 0.292 & 0.052 & 0.741 & 0.448 & 0.673 & 0.089 & 0.247 \\
        F1 (o1-mini) & 0.275 & 0.054 & \textbf{0.764} & 0.472 & \textbf{0.684} & \textbf{0.175} & \textbf{0.253} \\
        F1 (o1) & 0.274 & 0.044 & 0.754 & \textbf{0.489} & 0.673 & 0.133 & 0.091 \\
        F1 (llama-70B) & 0.269 & 0.049 & 0.711 & 0.410 & 0.659 & 0.172 & 0.158 \\
        F1 (llama-405B) & 0.158 & 0.031 & 0.690 & 0.427 & 0.662 & 0.167 & 0.134 \\
        F1 (deepseek-r1) & \textbf{0.297} & \textbf{0.081} & 0.729 & 0.473 & 0.682 & 0.164 & 0.152 \\
        F1 (deepseek-v3) & 0.241 & 0.051 & 0.725 & 0.405 & 0.680 & 0.110 & 0.092 \\
        \midrule
        Prec (gpt-4o-mini) & 0.317 & 0.134 & 0.647 & 0.317 & 0.549 & 0.063 & 0.241 \\
        Prec (gpt-4o) & 0.298 & 0.109 & 0.634 & 0.334 & 0.547 & 0.057 & 0.251 \\
        Prec (o1-mini) & 0.315 & 0.130 & 0.639 & 0.342 & 0.549 & 0.107 & 0.274 \\
        Prec (o1) & 0.279 & 0.064 & \textbf{0.648} & \textbf{0.381} & 0.549 & 0.111 & 0.245 \\
        Prec (llama-70B) & \textbf{0.339} & \textbf{0.143} & 0.653 & 0.295 & 0.548 & 0.105 & 0.289 \\
        Prec (llama-405B) & 0.324 & 0.071 & 0.647 & 0.310 & \textbf{0.558} & 0.115 & 0.233 \\
        Prec (deepseek-r1) & 0.321 & 0.099 & 0.639 & 0.327 & 0.549 & \textbf{0.135} & \textbf{0.301} \\
        Prec (deepseek-v3) & 0.288 & 0.100 & 0.645 & 0.280 & 0.547 & 0.076 & 0.249 \\
        \midrule
        Rec (gpt-4o-mini) & 0.233 & 0.053 & 0.870 & 0.691 & 0.983 & 0.274 & 0.232 \\
        Rec (gpt-4o) & 0.297 & 0.034 & 0.899 & 0.723 & 0.965 & 0.202 & \textbf{0.270} \\
        Rec (o1-mini) & 0.266 & 0.034 & \textbf{0.952} & 0.834 & \textbf{0.994} & \textbf{0.536} & 0.249 \\
        Rec (o1) & \textbf{0.353} & 0.034 & 0.905 & 0.736 & 0.963 & 0.167 & 0.056 \\
        Rec (llama-70B) & 0.246 & 0.030 & 0.803 & 0.720 & 0.919 & 0.476 & 0.146 \\
        Rec (llama-405B) & 0.108 & 0.020 & 0.774 & 0.694 & 0.894 & 0.300 & 0.095 \\
        Rec (deepseek-r1) & 0.299 & \textbf{0.069} & 0.859 & \textbf{0.865} & 0.983 & 0.357 & 0.102 \\
        Rec (deepseek-v3) & 0.210 & 0.035 & 0.844 & 0.755 & 0.981 & 0.238 & 0.058 \\
        \bottomrule
    \end{tabular}

    \label{tab:target-all}
\end{table}


\begin{table}[h]
    \centering
    \small
    \caption{Performance Comparison of Models Across Metrics and Targets (Strengths)}
    
    \begin{tabular}{lccccccc}
        \toprule
        Target & Problem & Prior Research & Method & Theory & Experiment & Conclusion & Paper \\
        \midrule
        F1 (gpt-4o-mini) & 0.283 & 0.000 & \textbf{0.760} & 0.424 & 0.511 & 0.118 & 0.232 \\
        F1 (gpt-4o) & 0.329 & 0.000 & 0.756 & 0.446 & \textbf{0.517} & 0.143 & 0.119 \\
        F1 (o1-mini) & 0.345 & 0.000 & 0.753 & 0.411 & 0.511 & 0.300 & \textbf{0.233} \\
        F1 (o1) & 0.384 & 0.000 & 0.749 & \textbf{0.470} & 0.512 & 0.267 & 0.061 \\
        F1 (llama-70B) & 0.245 & 0.000 & 0.750 & 0.420 & 0.516 & 0.242 & 0.198 \\
        F1 (llama-405B) & 0.160 & 0.000 & 0.755 & 0.455 & 0.516 & \textbf{0.333} & 0.079 \\
        F1 (deepseek-r1) & \textbf{0.396} & 0.000 & 0.749 & 0.436 & 0.513 & 0.174 & 0.135 \\
        F1 (deepseek-v3) & 0.331 & 0.000 & 0.755 & 0.423 & 0.509 & 0.114 & 0.086 \\
        \midrule
        Prec (gpt-4o-mini) & 0.315 & 0.000 & 0.622 & 0.286 & 0.343 & 0.071 & 0.198 \\
        Prec (gpt-4o) & 0.295 & 0.000 & 0.616 & 0.299 & 0.350 & 0.091 & 0.182 \\
        Prec (o1-mini) & 0.314 & 0.000 & 0.611 & 0.264 & 0.343 & 0.176 & 0.203 \\
        Prec (o1) & 0.285 & 0.000 & \textbf{0.624} & \textbf{0.322} & 0.346 & 0.222 & 0.172 \\
        Prec (llama-70B) & 0.404 & 0.000 & 0.620 & 0.275 & 0.352 & 0.148 & 0.178 \\
        Prec (llama-405B) & \textbf{0.419} & 0.000 & 0.620 & 0.319 & \textbf{0.358} & \textbf{0.231} & 0.163 \\
        Prec (deepseek-r1) & 0.355 & 0.000 & 0.617 & 0.289 & 0.347 & 0.103 & \textbf{0.279} \\
        Prec (deepseek-v3) & 0.364 & 0.000 & 0.620 & 0.276 & 0.344 & 0.069 & 0.154 \\
        \midrule
        Rec (gpt-4o-mini) & 0.258 & 0.000 & 0.975 & 0.819 & \textbf{0.996} & 0.333 & \textbf{0.281} \\
        Rec (gpt-4o) & 0.371 & 0.000 & 0.978 & 0.872 & 0.991 & 0.333 & 0.089 \\
        Rec (o1-mini) & 0.382 & 0.000 & \textbf{0.980} & \textbf{0.935} & \textbf{0.996} & \textbf{1.000} & 0.274 \\
        Rec (o1) & \textbf{0.588} & 0.000 & 0.936 & 0.872 & 0.987 & 0.333 & 0.037 \\
        Rec (llama-70B) & 0.176 & 0.000 & 0.948 & 0.894 & 0.969 & 0.667 & 0.224 \\
        Rec (llama-405B) & 0.099 & 0.000 & 0.965 & 0.796 & 0.921 & 0.600 & 0.052 \\
        Rec (deepseek-r1) & 0.447 & 0.000 & 0.953 & 0.883 & 0.983 & 0.571 & 0.089 \\
        Rec (deepseek-v3) & 0.303 & 0.000 & 0.963 & 0.904 & 0.982 & 0.333 & 0.059 \\
        \bottomrule
    \end{tabular}
    \label{tab:target_strength_metrics}
\end{table}



\begin{table}[h]
    \centering
    \small
    \caption{Performance Comparison of Models Across Metrics and Targets (Weaknesses)}
    
    \begin{tabular}{lccccccc}
        \toprule
        Target & Problem & Prior Research & Method & Theory & Experiment & Conclusion & Paper \\
        \midrule
        F1 (gpt-4o-mini) & 0.253 & 0.153 & 0.715 & 0.430 & 0.849 & 0.088 & 0.222 \\
        F1 (gpt-4o) & 0.256 & 0.104 & 0.726 & 0.449 & 0.830 & 0.036 & \textbf{0.375} \\
        F1 (o1-mini) & 0.204 & 0.108 & \textbf{0.774} & 0.534 & \textbf{0.857} & 0.050 & 0.272 \\
        F1 (o1) & 0.164 & 0.089 & 0.760 & 0.508 & 0.835 & 0.000 & 0.120 \\
        F1 (llama-70B) & \textbf{0.294} & 0.098 & 0.672 & 0.400 & 0.802 & 0.103 & 0.118 \\
        F1 (llama-405B) & 0.155 & 0.062 & 0.625 & 0.399 & 0.809 & 0.000 & 0.190 \\
        F1 (deepseek-r1) & 0.198 & \textbf{0.163} & 0.709 & \textbf{0.510} & 0.852 & \textbf{0.154} & 0.169 \\
        F1 (deepseek-v3) & 0.151 & 0.103 & 0.696 & 0.387 & 0.850 & 0.105 & 0.099 \\
        \midrule
        Prec (gpt-4o-mini) & \textbf{0.320} & 0.268 & 0.672 & 0.347 & 0.755 & 0.056 & 0.283 \\
        Prec (gpt-4o) & 0.301 & 0.219 & 0.651 & 0.369 & 0.743 & 0.024 & 0.321 \\
        Prec (o1-mini) & 0.315 & 0.259 & 0.666 & 0.420 & 0.754 & 0.038 & 0.345 \\
        Prec (o1) & 0.273 & 0.127 & 0.672 & \textbf{0.440} & 0.752 & 0.000 & 0.317 \\
        Prec (llama-70B) & 0.274 & \textbf{0.286} & \textbf{0.687} & 0.315 & 0.744 & 0.062 & \textbf{0.400} \\
        Prec (llama-405B) & 0.228 & 0.143 & 0.673 & 0.300 & \textbf{0.758} & 0.000 & 0.304 \\
        Prec (deepseek-r1) & 0.287 & 0.197 & 0.661 & 0.365 & 0.750 & \textbf{0.167} & 0.323 \\
        Prec (deepseek-v3) & 0.212 & 0.200 & 0.669 & 0.284 & 0.750 & 0.083 & 0.345 \\
        \midrule
        Rec (gpt-4o-mini) & 0.209 & 0.107 & 0.764 & 0.563 & 0.970 & \textbf{0.214} & 0.183 \\
        Rec (gpt-4o) & 0.222 & 0.068 & 0.821 & 0.574 & 0.939 & 0.071 & \textbf{0.451} \\
        Rec (o1-mini) & 0.151 & 0.068 & \textbf{0.924} & 0.732 & \textbf{0.992} & 0.071 & 0.224 \\
        Rec (o1) & 0.118 & 0.068 & 0.874 & 0.600 & 0.939 & 0.000 & 0.074 \\
        Rec (llama-70B) & \textbf{0.316} & 0.059 & 0.658 & 0.547 & 0.869 & 0.286 & 0.069 \\
        Rec (llama-405B) & 0.118 & 0.040 & 0.583 & 0.593 & 0.867 & 0.000 & 0.138 \\
        Rec (deepseek-r1) & 0.151 & \textbf{0.139} & 0.764 & \textbf{0.847} & 0.984 & 0.143 & 0.115 \\
        Rec (deepseek-v3) & 0.118 & 0.069 & 0.725 & 0.605 & 0.980 & 0.143 & 0.057 \\
        \bottomrule
    \end{tabular}
    \label{tab:target_weakness_metrics}
\end{table}

\begin{table}[h]
    \centering
    \caption{Performance Comparison of Models Across Metrics and Aspects (Including both Strengths and Weaknesses)}
    \small
    \begin{tabular}{lcccc}
        \toprule
        Aspect & Novelty & Impact & Validity & Clarity \\
        \midrule
        F1 (gpt-4o-mini)   & 0.334 & 0.390 & \textbf{0.775} & 0.396 \\
        F1 (gpt-4o)        & 0.378 & \textbf{0.428} & 0.769 & 0.365 \\
        F1 (o1-mini)       & 0.386 & 0.427 & 0.773 & 0.395 \\
        F1 (o1)            & \textbf{0.404} & 0.399 & 0.772 & \textbf{0.401} \\
        F1 (llama-70B)     & 0.334 & 0.322 & 0.769 & 0.327 \\
        F1 (llama-405B)    & 0.337 & 0.318 & 0.772 & 0.278 \\
        F1 (deepseek-r1)   & 0.387 & 0.414 & \textbf{0.775} & 0.266 \\
        F1 (deepseek-v3)   & 0.346 & 0.422 & 0.768 & 0.187 \\
        \midrule
        Prec (gpt-4o-mini) & 0.367 & 0.291 & \textbf{0.671} & 0.317 \\
        Prec (gpt-4o)      & 0.474 & 0.313 & 0.668 & 0.298 \\
        Prec (o1-mini)     & 0.528 & 0.300 & 0.668 & 0.311 \\
        Prec (o1)          & 0.589 & 0.305 & 0.669 & 0.334 \\
        Prec (llama-70B)   & \textbf{0.665} & \textbf{0.318} & 0.667 & 0.337 \\
        Prec (llama-405B)  & 0.587 & 0.302 & \textbf{0.671} & 0.332 \\
        Prec (deepseek-r1) & 0.535 & 0.308 & 0.670 & \textbf{0.339} \\
        Prec (deepseek-v3) & 0.504 & 0.306 & 0.664 & 0.309 \\
        \midrule
        Rec (gpt-4o-mini)  & 0.460 & 0.600 & \textbf{0.990} & \textbf{0.549} \\
        Rec (gpt-4o)       & 0.506 & 0.689 & 0.975 & 0.485 \\
        Rec (o1-mini)      & \textbf{0.507} & \textbf{0.758} & \textbf{0.990} & 0.548 \\
        Rec (o1)           & 0.435 & 0.579 & 0.981 & 0.511 \\
        Rec (llama-70B)    & 0.450 & 0.371 & 0.981 & 0.346 \\
        Rec (llama-405B)   & 0.478 & 0.352 & 0.978 & 0.241 \\
        Rec (deepseek-r1)  & 0.502 & 0.632 & 0.988 & 0.219 \\
        Rec (deepseek-v3)  & 0.478 & 0.683 & 0.982 & 0.134 \\
        \bottomrule
    \end{tabular}
    \label{tab:aspect-all}
\end{table}



\begin{table}[h]
    \centering
    \caption{Performance Comparison of Models Across Metrics and Aspects (Strengths)}
    \small
    \begin{tabular}{lcccc}
        \toprule
        Aspect & Novelty & Impact & Validity & Clarity \\
        \midrule
        F1 (gpt-4o-mini)   & 0.643 & 0.474 & \textbf{0.599} & 0.309 \\
        F1 (gpt-4o)        & 0.654 & 0.520 & 0.593 & 0.202 \\
        F1 (o1-mini)       & 0.656 & \textbf{0.556} & 0.592 & 0.299 \\
        F1 (o1)            & 0.626 & 0.530 & 0.596 & \textbf{0.342} \\
        F1 (llama-70B)     & 0.636 & 0.411 & 0.593 & 0.292 \\
        F1 (llama-405B)    & \textbf{0.660} & 0.345 & 0.596 & 0.157 \\
        F1 (deepseek-r1)   & 0.655 & 0.536 & 0.598 & 0.170 \\
        F1 (deepseek-v3)   & \textbf{0.660} & 0.547 & 0.585 & 0.122 \\
        \midrule
        Prec (gpt-4o-mini) & 0.498 & 0.368 & \textbf{0.431} & 0.222 \\
        Prec (gpt-4o)      & 0.498 & 0.398 & 0.428 & 0.190 \\
        Prec (o1-mini)     & 0.501 & 0.403 & 0.424 & 0.224 \\
        Prec (o1)          & \textbf{0.530} & 0.412 & 0.430 & \textbf{0.261} \\
        Prec (llama-70B)   & 0.497 & \textbf{0.467} & 0.426 & 0.236 \\
        Prec (llama-405B)  & 0.506 & 0.368 & \textbf{0.431} & 0.215 \\
        Prec (deepseek-r1) & 0.503 & 0.400 & \textbf{0.431} & 0.224 \\
        Prec (deepseek-v3) & 0.509 & 0.403 & 0.419 & 0.207 \\
        \midrule
        Rec (gpt-4o-mini)  & 0.907 & 0.667 & \textbf{0.986} & \textbf{0.511} \\
        Rec (gpt-4o)       & \textbf{0.955} & 0.749 & 0.965 & 0.216 \\
        Rec (o1-mini)      & 0.949 & \textbf{0.897} & 0.979 & 0.449 \\
        Rec (o1)           & 0.763 & 0.744 & 0.969 & 0.496 \\
        Rec (llama-70B)    & 0.883 & 0.366 & 0.976 & 0.384 \\
        Rec (llama-405B)   & 0.949 & 0.324 & 0.969 & 0.123 \\
        Rec (deepseek-r1)  & 0.937 & 0.809 & 0.976 & 0.137 \\
        Rec (deepseek-v3)  & 0.940 & 0.851 & 0.965 & 0.086 \\
        \bottomrule
    \end{tabular}
    \label{fig:aspect-strength}

\end{table}


\begin{table}[h]
    \centering
    \small
    \caption{Performance Comparison of Models Across Metrics and Aspects (Weaknesses)}
    \begin{tabular}{lcccc}
        \toprule
        Aspect & Novelty & Impact & Validity & Clarity \\
        \midrule
        F1 (gpt-4o-mini)   & 0.024 & 0.306 & 0.951 & 0.484 \\
        F1 (gpt-4o)        & 0.103 & \textbf{0.335} & 0.945 & \textbf{0.528} \\
        F1 (o1-mini)       & 0.116 & 0.299 & \textbf{0.954} & 0.492 \\
        F1 (o1)            & \textbf{0.182} & 0.268 & 0.949 & 0.459 \\
        F1 (llama-70B)     & 0.032 & 0.233 & 0.945 & 0.362 \\
        F1 (llama-405B)    & 0.013 & 0.291 & 0.947 & 0.399 \\
        F1 (deepseek-r1)   & 0.120 & 0.292 & 0.952 & 0.362 \\
        F1 (deepseek-v3)   & 0.031 & 0.297 & 0.951 & 0.253 \\
        \midrule
        Prec (gpt-4o-mini) & 0.235 & 0.214 & \textbf{0.912} & 0.411 \\
        Prec (gpt-4o)      & 0.450 & 0.228 & 0.907 & 0.406 \\
        Prec (o1-mini)     & 0.556 & 0.197 & 0.911 & 0.397 \\
        Prec (o1)          & 0.647 & 0.198 & 0.908 & 0.406 \\
        Prec (llama-70B)   & \textbf{0.833} & 0.169 & 0.907 & 0.438 \\
        Prec (llama-405B)  & 0.667 & \textbf{0.236} & 0.911 & 0.450 \\
        Prec (deepseek-r1) & 0.568 & 0.215 & 0.908 & \textbf{0.454} \\
        Prec (deepseek-v3) & 0.500 & 0.209 & 0.908 & 0.410 \\
        \midrule
        Rec (gpt-4o-mini)  & 0.013 & 0.533 & 0.994 & 0.587 \\
        Rec (gpt-4o)       & 0.058 & \textbf{0.630} & 0.985 & \textbf{0.754} \\
        Rec (o1-mini)      & 0.065 & 0.619 & \textbf{1.000} & 0.646 \\
        Rec (o1)           & \textbf{0.106} & 0.415 & 0.994 & 0.527 \\
        Rec (llama-70B)    & 0.016 & 0.376 & 0.987 & 0.308 \\
        Rec (llama-405B)   & 0.006 & 0.381 & 0.987 & 0.359 \\
        Rec (deepseek-r1)  & 0.067 & 0.455 & \textbf{1.000} & 0.302 \\
        Rec (deepseek-v3)  & 0.016 & 0.515 & 0.998 & 0.183 \\
        \bottomrule
    \end{tabular}
    \label{fig:aspect-weakness}
\end{table}


\end{onecolumn}


\end{document}
