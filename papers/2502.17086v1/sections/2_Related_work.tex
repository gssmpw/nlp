% \section{Related Work}

% With the powerful reasoning capability of LLMs, LLMs have the potential to assist in the task of reviewing papers~\citep{latona2024ai, d2024marg}. Research has explored the capability of LLMs in reviewing papers, identifying a set of limitations. While LLM-generated reviews can be helpful~\citep{liang2024can, tyser2024ai}, research has shown that LLMs-generated reviews lack diversity~\citep{du2024llms, liang2024can} and technical details~\citep{zhou2024llm}, tend to provide positive feedback~\citep{zhou2024llm, du2024llms}, and may include irrelevant or even inaccurate comments~\citep{mostafapour2024evaluating}. Furthermore, research also has reported that LLM-generated reviews have a low level of agreement with experts-generated reviews~\citep{saad2024exploring}. 

% To assess the quality of review, research has taken a quantitative approach by analyzing review text. For instance, research has evaluated the quality of review based on human preferences~\citep{tyser2024ai} and similarity to human-generated review~\citep{zhou2024llm, liang2024can}. Another approach is to classify review data based on categories such as section~\citep{ghosal2022peer} and aspect~\citep{yuan2022can, chamoun2024automated} \todo{ and what?}. While quantitative approach provides concrete insights, it is typically conducted as a one-time evaluation, making it challenging to apply the same methodology to newly developed LLMs.
