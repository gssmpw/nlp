\section{Related Works}
\label{sec:2}

\subsection{Medical Image Classification.}
Medical image classification remains a significant challenge, critical in organizing large volumes of data into meaningful categories \cite{azad2024advances}. Over the past decade, CNNs have dominated the field of image classification. They have been widely employed in applications such as cancer detection \cite{ren2023ipsilateral}, skin disease diagnosis \cite{elbatel2023fopro}, thoracic surgery \cite{harirpoush2024architecture}, retinal disease identification \cite{ju2023hierarchical}, and fetal brain volume estimation \cite{pei2023pets}.

More recently, Vision Transformers (ViTs) have emerged as a powerful alternative to conventional CNNs, achieving remarkable success in various image classification tasks \cite{swin, mobilevit_v2, Twins, CSWin}. ViTs offer several advantages, including the ability to model long-range dependencies, adapt to diverse inputs, and generate attention maps that highlight critical regions within an image \cite{gheflati2022vision}. These features have sparked significant interest in leveraging Transformer-based models for medical image classification, where precise classification is increasingly essential to support timely clinical decision-making, particularly for difficult cases.
Early ViT models typically rely on large-scale datasets and relatively simple configurations \cite{ViT}. However, recent advancements have integrated inductive biases related to visual perception into ViT architectures \cite{manzari2023robust, yu2022metaformer, wang2024repvit, yan2023hybrid}. This evolution has made ViTs more adaptable and effective in classification, registration, and segmentation. By treating images as sequences of patches without incorporating 2D inductive biases, ViTs are particularly suitable for multimodal applications \cite{xu2023research}.
In particular, the growth of datasets and innovations in model architectures have driven ViT-based foundation models with unprecedented capabilities, enabling \textit{flexible} applications in medical imaging \cite{manigrasso2025mammography, horst2024cellvit, koleilat2024medclip}. For example, researchers have introduced FastGlioma, a tool for detecting tumor infiltration during surgery \cite{kondepudi2024foundation}, while RETFound learns generalizable representations from unlabelled retinal images, enabling label-efficient model adaptation across various applications \cite{zhou2023foundation}. Additional applications include leveraging tumor registry data and demographic information to predict overall survival rates \cite{jee2024automated}. %With further optimization and domain-specific enhancements, ViTs are well-positioned to play an increasingly transformative role in medical image analysis.


\subsection{Kolmogorovâ€“Arnold Networks}
KANs have inspired numerous studies that demonstrate their effectiveness across various domains, including keyword spotting, complex optimization problems, survival analysis, time series forecasting, quantum computing, and vision tasks~\cite{li2024u,cheon2024demonstrating,ge2024tc}. Furthermore, many advanced KAN models leverage well-established mathematical functions, particularly those adept at handling curves, such as B-splines~\cite{ta2024bsrbf}, which combine B-splines and Radial Basis Functions (RBF) to fit input data during training. FastKAN~\cite{li2024kolmogorov} approximates third-order B-splines in KANs using Gaussian RBF, while DeepOKAN~\cite{abueidda2024deepokan} directly employs Gaussian RBF instead of B-splines. Other approaches, such as FourierKAN-GCF~\cite{xu2024fourierkan}, wavelet-based KANs~\cite{seydi2024unveiling}, and polynomial-function-based KANs~\cite{teymoor2024exploring}, explore the suitability of various basis functions in KAN models for classification and other tasks.

KANs have also demonstrated significant potential in medical image processing, where interpretability and precision are paramount. For instance, BSRBF-KAN~\cite{ta2024bsrbf} has been utilized to improve the segmentation accuracy of complex medical images, such as MRI scans, by leveraging the flexibility of RBF. Similarly, TransUKAN~\cite{wu2024transukan} integrates KANs, transformers, and U-Net architectures to enhance the efficiency and performance of medical image segmentation while significantly reducing parameter counts. Additionally, Bayesian-KAN~\cite{hassan2024bayesian} combines KAN with Bayesian inference to deliver explainable, uncertainty-aware predictions in healthcare settings. These developments showcase how the mathematical foundations of KANs can be adapted to address specific challenges in medical imaging, providing a balance between high interpretability and computational efficiency.
%This growing body of evidence underscores the versatility of KANs and their applicability across diverse fields, including healthcare, establishing them as a powerful tool for advancing AI-driven solutions in critical domains.