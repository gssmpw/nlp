\clearpage
\onecolumn
\setcounter{page}{1}
\appendix
\appendixpage
\counterwithin{figure}{section}
\counterwithin{table}{section}
%-------------------------------------------------
\section{Contents}
\label{sec:SuppleIntro}
As part of the supplementary materials for this paper, we share our Implementation details and show extended qualitative and quantitative results for our proposed approach. The supplementary materials contain: 

\begin{easylist}[itemize]
@ Datasets 
@ Implementation Details and Hyperparameters
@ Quantitative Results
    @@ Standalone StyleZero and ObjectZero adapters
    @@ Varying style and content scaling
    @@ Subject leakage 
    measurement
    @@ Runtime analysis
    @@ Zero-order stochastic optimal control    
@ Qualitative Results
    @@ Face style composition
        @@@ With style helper prompts
        @@@ Without style helper prompts
    @@ Object style composition
@ Limitations and Future Work
\end{easylist}  


\section{Datasets}
\label{subsec:data_app}
\paragraph{Face-Style Composition.} As discussed in Section~\ref{sec:expsetup}, we curate a dataset with 12 faces \textbf{which remain unseen by our foundational models}. We do not use a public dataset, as we observe that celebrity faces and AI generated faces are easy for foundational models to replicate, as these faces might have been seen before. Hence, we collect our own dataset, with faces which are not seen before. The images shared with us are directly by the subjects themselves. Moreover, each subject is invited to participate in our user study in Table~\ref{tab:human}. Of the 12 subjects, 10 participated in the study. For styles, we collect 30 vivid styles from datasets such as SubjectPlop~\cite{ruiz2024magic}, StyleDrop~\cite{sohn2023styledrop} and StyleAligned~\cite{hertz2024style}. All style images are shown in Figure~\ref{fig:all_styles}. For each result in Tables~\ref{tab:face_stylization_main},\ref{table:face_ablation},\ref{table:stylezero_faces},\ref{table:latency}, we perform analysis over 12 subjects, 30 styles and 3 seeds, totaling \textbf{1080 samples}.

\begin{figure}[h]
    \centering
    \includegraphics[width=1.0\linewidth]{figures/subzero_all_styles.jpg}
    \caption{
    % \textbf{Stylized Faces with SubZero}. Stylized Faces with SubZero.
All the style images from our face-style composition dataset
    }%, and suffer from mode collapse. However, our proposed FouRA produces more diverse images.}
    \label{fig:all_styles}

\end{figure}


\paragraph{Face-Style-Action Composition.} As discussed in Section~\ref{sec:facestyleactionRes}, we use a dataset with 12 faces, 10 styles and 10 action prompts over 3 seeds for action generation. This totals inference over \textbf{3600 samples}.  We list the 10 action prompts below.
\begin{python}
1. wearing a jacket
2. walking on the beach
3. laughing
4. playing soccer
5. dancing
6. punching 
7. on a bicycle
8. wearing a hat
9. holding a mike
10. giving a speech to an audience
\end{python}

\paragraph{Subject Leakage.}
To measure the subject leakage problem in further detail, we curate a dataset of 10 styles, each of which contain a salient object. These images are shown in Figure~\ref{fig:leakage_dataset}. To measure leakage along with Style Similarity, we compute the CLIP-ViT-L distance between the generated images and "leakage prompts" which describe the salient subject in the style image. This analysis is further detailed in Section~\ref{subsec:leakage}.

\begin{figure}[h]
    \centering
    \includegraphics[width=0.8\linewidth]{figures/subzero_leakage_dataset.jpg}
    \caption{
    % \textbf{Stylized Faces with SubZero}. Stylized Faces with SubZero.
All the style images from our style leakage dataset, along with leakage prompts
    }%, and suffer from mode collapse. However, our proposed FouRA produces more diverse images.}
    \label{fig:leakage_dataset}

\end{figure}

\paragraph{Object-Style Composition}
We use a set of ten unique subject images from the Dreambooth dataset~\cite{ruiz2023dreambooth}, and visualize them in figure~\ref{fig:content_images}. In addition, we select ten unique style images from the StyleDrop dataset~\cite{sohn2023styledrop}, shown in figure~\ref{fig:style_images}. We run inference over 3 seeds. Hence, object stylization results are over \textbf{300 samples}.

\begingroup
\setlength{\tabcolsep}{2pt} % Default value: 6pt
\renewcommand{\arraystretch}{0.7} % Default value: 1

\begin{figure}
    \centering
    \begin{tabular}{ccccc}
    \includegraphics[width=0.15\linewidth]{figures/object_style_composition/content/backpack_00.jpg} & \includegraphics[width=0.15\linewidth]{figures/object_style_composition/content/bear_plushie_00.jpg} &  \includegraphics[width=0.15\linewidth]{figures/object_style_composition/content/berry_bowl.jpg} &
     \includegraphics[width=0.15\linewidth]{figures/object_style_composition/content/can_00.jpg} &
      \includegraphics[width=0.15\linewidth]{figures/object_style_composition/content/candle_content.jpg} \\
       \includegraphics[width=0.15\linewidth]{figures/object_style_composition/content/cat_00.jpg} & \includegraphics[width=0.15\linewidth]{figures/object_style_composition/content/cat02_00.jpg} & 
       \includegraphics[width=0.15\linewidth]{figures/object_style_composition/content/dog_00.jpg} & 
       \includegraphics[width=0.15\linewidth]{figures/object_style_composition/content/dog2.jpg} & 
       \includegraphics[width=0.15\linewidth]{figures/object_style_composition/content/duck_toy_00.jpg}\\
\end{tabular}
\caption{Content images used for the object-style composition evaluation. }
\label{fig:content_images}
\end{figure}

\begin{figure}[ht]
    \centering
    \begin{tabular}{ccccc}
    \includegraphics[width=0.15\linewidth, height=0.15\linewidth]{figures/object_style_composition/style/image_01_04.jpg} & \includegraphics[width=0.15\linewidth, height=0.15\linewidth]{figures/object_style_composition/style/image_01_08.jpg} &  \includegraphics[width=0.15\linewidth, height=0.15\linewidth]{figures/object_style_composition/style/image_01_21.jpg} &
     \includegraphics[width=0.15\linewidth, height=0.15\linewidth]{figures/object_style_composition/style/image_01_22.jpg} &
      \includegraphics[width=0.15\linewidth, height=0.15\linewidth]{figures/object_style_composition/style/image_01_23.jpg} \\
       \includegraphics[width=0.15\linewidth, height=0.15\linewidth]{figures/object_style_composition/style/image_02_03.jpg} & \includegraphics[width=0.15\linewidth, height=0.15\linewidth]{figures/object_style_composition/style/image_02_04.jpg} & 
      \includegraphics[width=0.15\linewidth, height=0.15\linewidth]{figures/object_style_composition/style/image_02_06.jpg} & 
       \includegraphics[width=0.15\linewidth, height=0.15\linewidth]{figures/object_style_composition/style/image_03_05.jpg} & 
       \includegraphics[width=0.15\linewidth, height=0.15\linewidth]{figures/object_style_composition/style/van_gogh.jpg}\\
\end{tabular}
\caption{Style images used for the object-style composition evaluation.}
\label{fig:style_images}
\end{figure}

\endgroup

\section{Additional Implementation Details}
\subsection{Training StyleZero and ObjectZero}
We implemented our training pipeline for both StyleZero and ObjectZero using the IP-Adapter~\cite{ye2023ip-adapter} repository\footnote{https://github.com/tencent-ailab/IP-Adapter/tree/main}.  We train both of our adapters for $90$K iterations on four Nvidia A100 GPUs with the batch size of four per each GPU. We train StyleZero using image-text pairs from the ContraStyles~\cite{somepalli2024measuring} dataset and ObjectZero on image-text pairs from MS-COCO~\cite{Lin2014MicrosoftCC}. We use the Adam optimizer with the learning rate of $0.0002$ and weight decay of $0.01$. For both adapters, we set $\gamma$ in the loss as $0.3$.
\subsection{W\"{u}rstchen}
To implement our method (and RB-Modulation) on W\"{u}rstchen architecture, we build on the official codebase\footnote{https://github.com/google/RB-Modulation} provided by RB-Modulation~\cite{rout2024rb} authors. For all experiments, we set $M$ (optimization steps) to $5$. We use a single Nvidia Tesla A100 GPU with batch-size=1. Apart from $M$, we keep the default hyperparameters for RB-modulation intact. To implement SubZero, we set $\gamma_{nc}$ to $1$. For Face-Style (and Action) composition, we set $\gamma_{ns}$ to $0$, and for Object-Style composition experiments, we set $\gamma_{ns}$ to $1$. $\mu_{s,0}$ is set to $0.6$, $\zeta$ is set to $0.4$, and the update is capped once $\mu_{s,t}$ reaches $1$.

\subsection{SDXL-Lightning experiments}
For results on SDXL-Lightning, we implemented all components of SubZero over the official PuLID~\cite{guo2024pulid} repository\footnote{https://github.com/ToTheBeginning/PuLID}, open-sourced by their authors. For face-style composition, we apply various projectors (IP-Adapter\footnote{https://github.com/tencent-ailab/IP-Adapter}, StyleCrafter\footnote{https://github.com/GongyeLiu/StyleCrafter-SDXL} and the proposed StyleZero) for stylization, while keeping the Subject projector as PuLID in all experiments. For object-style composition, we use IP-Adapter, StyleZero and ObjectZero as our style and subject projectors. Unless mentioned otherwise, for weighted aggregation of attention weights, we select the style scales and subject scales which produce the best operating point for all experiments. To report scores with RB-Modulation on SDXL-Lightning, We implement the RB-Modulation stochastic controller in the diffusers pipeline. We set $M$ (optimization steps) to 5. To implement SubZero, we set $\gamma_{nc}$ to $1$. For SubZero Face-Style (and Action) composition, we set $\gamma_{ns}$ to $0$, and for SubZero Object-style composition experiments, we set $\gamma_{ns}$ to $1$. $\mu_{s,0}$ is set to $0.6$, $\zeta$ is set to $0.4$, and the update is capped once $\mu_{s,t}$ reaches $1.5$.

\subsection{Baselines}
\paragraph{InstantID.} To reproduce results using InstantID for subject-style composition, we used an open-source adaptation of their ``Visual Prompting" method\footnote{https://github.com/TheDenk/InstantID-Visual-Prompt/tree/main} on SDXL. We replaced the backbone with SDXL-Lightning and used default settings. We use a single Nvidia Tesla A100 GPU with batch-size $1$.

\paragraph{InstantStyle-Plus.}
We replace the InstantStyle-Plus base model \footnote{https://github.com/instantX-research/InstantStyle-Plus} with SDXL-Lightning while modifying the default settings. For action, we modify the settings for ReNoise to ensure we maintain structural integrity of content and faithfullness to the action specified by prompt while aligning with the style. To ensure action is faithfully generated, we update the number of inversion steps to $40$ and number of renoise iterations per timestep to $4$. In addition, we found that reducing controlnet guidance scale to $0.3$ did not undermine the subject reconstruction. The global and local scales for IP adapter were set at $0.3$ and $0.6$ respectively.

\paragraph{StyleAligned.}
For object-style composition baselines, we replace the base model for StyleAligned \footnote{https://github.com/google/style-aligned/} with SDXL-Lightning while modifying the default settings. Since StyleAligned originally does not input a reference image for style and instead generates the style from a reference prompt, we modify the pipeline to input DDIM inverted latents to the model. The model is conditioned on controlnet. We set the controlnet conditioning scale at $0.9$ and guidance scale at $7.5$. 
We generate images across a single image per prompt for an object-style pair. 

\section{Quantitative Results}
\subsection{Performance of standalone StyleZero and ObjectZero projectors}

Figure~\ref{fig:cross_scale_object} shows the individual gain from our disentangled StyleZero and ObjectZero projector pair over IP-Adapter. We perform this experiment on the object stylization task. However, unlike Table~\ref{tab:obj_stylization_main}, the results are on an SDXL baseline. We compare using our projectors against IP-Adapter. We vary style and subject scaling to generate a trade-off curve between subject and style similarity, on the object-style composition task.
As observed, using the StyleZero and ObjectZero pair provides a significantly better operating point on the Object similarity and Style similarity curve, compared to IP-Adapters. This is due to the fact that our adapters are less prone to Subject leakage.

% \begin{table}[ht]
%     %\addtolength{\tabcolsep}{-1.5pt}
%     \centering
%     \vspace{-0.5 em}

%     \fontsize{7.0pt}{5.75pt}\selectfont
%     \begin{tabular}{c|c|cc}
%     \toprule
%     Style Projector & Object Projector & DINO Sim & Style Sim \\ [0.5ex] 
%     \hline
%     % \midrule
%     % IP-Adapter  & - & 0.156 &  0.756\\
%     % \rowcolor{Gray} StyleZero & - & 0.181 & 0.644 \\
%     % \midrule
%     %  - & IP-Adapter~\cite{ye2023ip-adapter}   & 0.546 & 0.161 \\
%     % % Content & IP-Adapter   & 0.546 & - \\
%     % \rowcolor{Gray} - & ObjectZero (Ours)   & \textbf{0.610} &  \textbf{0.167} \\
%     \midrule
%      IP-Adapter~\cite{ye2023ip-adapter} & IP-Adapter~\cite{ye2023ip-adapter}   & 0.351 & 0.438 \\
%     % Content & IP-Adapter   & 0.546 & - \\
%     \rowcolor{Gray} StyleZero & ObjectZero   & \textbf{0.539} & \textbf{0.441} \\
    
%     % \rowcolor{Gray} Content & ObjectZero   & 0.610 &  - \\
%     \bottomrule
% \end{tabular}
% % \fontsize{8.00pt}{8.25pt}\selectfont

% \caption{\textbf{Our trained standalone object/style adapters}}
% \vspace{-1em}
% \label{tab:standalone}
% \end{table}

\begin{figure}[h]
    \centering
    \includegraphics[width=0.4\linewidth]{figures/subzero_cross_scale_object.jpg}
    \caption{
    % \textbf{Stylized Faces with SubZero}. Stylized Faces with SubZero.
Varying the style and content scaling to generate a trade-off curve between Object and Style similarity for standalone ObjectZero and StyleZero adapters on SDXL.
    }%, and suffer from mode collapse. However, our proposed FouRA produces more diverse images.}
    \label{fig:cross_scale_object}

\end{figure}


\subsection{Varying style and content scaling on Face-Style composition}
In Figure~\ref{fig:cross_scale}, we vary style and content scaling to generate a trade-off curve between face and style similarity, on the face style composition task. All results are without style helper prompts on SDXL-Lightning, as an extension of the ones shown in Table~\ref{tab:face_stylization_main}. We compare our StyleZero projector added to PuLID, RB-Modulation (with both these projectors) and our proposed SubZero approach. As observed, SubZero observe a consistent improvement over RB-Modulation and naiive merging of base projectors over a distribution of scales.

\begin{figure}[h]
    \centering
    \includegraphics[width=0.4\linewidth]{figures/subzero_cross_scale.jpg}
    \caption{
    % \textbf{Stylized Faces with SubZero}. Stylized Faces with SubZero.
Varying the style and content scaling to generate a trade-off curve between Face and Style similarity.
    }%, and suffer from mode collapse. However, our proposed FouRA produces more diverse images.}
    \label{fig:cross_scale}

\end{figure}

\subsection{Subject leakage measurement}
To effectively quantify and measure subject leakage, we curate a dataset of 10 style images which are likely susceptible to leakage. This dataset is described in Section~\ref{subsec:data_app}. To measure leakage, we measure a normalized CLIP similarity between generated images and the leakage text prompts. We show quantitative results in Table~\ref{table:subj_leakage}, and qualitative results in Figure~\ref{fig:sub_leakage}. As shown from results, the StyleZero projector significantly reduces leakage while keeping the Style Similarity consistent. Additionally, SubZero the inference algorithm including OTA and Disentangled Latent Optimization further improves subject and style similarity, while reducing leakage. This is also evident in Figure~\ref{fig:sub_leakage}, as subject leakage artifacts, which include cat ears, dog ears and subject shape are fixed by either the StyleZero projector and SubZero inference.

\label{subsec:leakage}
\begin{figure}[h]
    \centering
    \includegraphics[width=0.8\linewidth]{figures/subzero_subject_leakage.jpg}
    \caption{
    % \textbf{Stylized Faces with SubZero}. Stylized Faces with SubZero.
Visualizing subject leakage for various schemes
    }%, and suffer from mode collapse. However, our proposed FouRA produces more diverse images.}
    \label{fig:sub_leakage}

\end{figure}


\begin{table}[h]
    %\addtolength{\tabcolsep}{-1.5pt}

    
    \centering
    \fontsize{7.0pt}{5.75pt}\selectfont
    \begin{tabular}{c|cc|ccc}
    \toprule
    Style projector & Disentangled Control & Ortho. Temporal Aggregation & Face Sim.($\uparrow$) & Style Sim.($\uparrow$) & Subject Leakage($\downarrow$)\\
    \hline
    \midrule
        &  & & 56.2 & 59.1 & 54.6 \\
       \rowcolor{Gray} &  & \checkmark & 58.3  & 58.7 & 41.5 \\
       %\midrule
       %RB-Modulation & & & 54.1 & \textbf{76.5} & 58.3 \\
       \rowcolor{Gray} \multirow{-3}{*}{IP-Adapter} & \checkmark & \checkmark & \textbf{64.8} & \textbf{70.1}  & \textbf{33.4}  \\
    \midrule
       \rowcolor{Gray} &  & & 57.2 & 60.8 & 55.4   \\
       \rowcolor{Gray}  &  & \checkmark & 60.3 & 59.0 & 37.6 \\
       %\midrule
       %RB-Modulation & & & 54.1 & \textbf{76.5} & 58.3 \\
       \rowcolor{Gray} \multirow{-3}{*}{StyleZero} & \checkmark & \checkmark & \textbf{66.4} & \textbf{69.3} & \textbf{28.6} \\

      \hline
    \bottomrule
\end{tabular}
% \fontsize{8.00pt}{8.25pt}\selectfont
\vspace{-0.7 em}
\caption{\textbf{Measuring Subject Leakage:} We report results on SDXL-Lightning with IP-Adapter and PulID. All numbers are without style helper prompts.}\label{table:subj_leakage}
\vspace{-1.0 em}
\end{table}

\subsection{Runtime Analysis}
Table~\ref{table:latency} lists the overall runtime to generate face-style composed images with SDXL-Lightning baseline. All numbers are using style helper prompts. The measurements are on a single Nvidia A100 GPU. As observed, the Orthogonal Temporal Aggregation and Disentangled Stochastic Optimal Control algorithms trade-off performance in terms of Face and Style similarity, with latency. For a gradient-free inference suitable for mobile devices, our StyleZero adapter with Orthogonal Temporal Aggregation of attention features achieves the most promising operating point. This method can also successfully reduce subject leakage, as shown in Table~\ref{table:subj_leakage}.

\begin{table}[h]
    %\addtolength{\tabcolsep}{-1.5pt}

    
    \centering
    \fontsize{7.0pt}{5.75pt}\selectfont
    \begin{tabular}{ccc|ccc|c}
    \toprule
    StyleZero & Ortho Temporal Aggregation & Dis. Control & Face Sim. & Style Sim. & Average & Runtime (sec)\\
    \hline
    \midrule
     \rowcolor{Gray} \checkmark & & & 59.5 & 58.4 & 59.0 & 0.7 \\
      \rowcolor{Gray} \checkmark & \checkmark &  & 60.1 & 61.9 & 61.0 & 0.9 \\
      \rowcolor{Gray} \checkmark & \checkmark & \checkmark & \textbf{66.5} & \textbf{72.4} & \textbf{69.5} & 2.0 \\
    \bottomrule
\end{tabular}
% \fontsize{8.00pt}{8.25pt}\selectfont
\caption{\textbf{Runtime Analysis from SubZero components:} We report total runtime with results on SDXL-Lightning with StyleZero. All numbers are with style helper prompts}\label{table:latency}

\end{table}

\subsection{Zero-Order Stochastic Optimal Control}

As discussed in Section~\ref{subsec:zo}, Zero-Order(ZO) methods approximate the gradient by perturbing the weight parameters by a small amount based on some random noise.
As shown in Table~\ref{tab:zo_control}, we perform preliminary experiments by leveraging the ZO-Adam scheme described in MeZO ~\cite{malladi2024finetuninglanguagemodelsjust} and extend it to update the latent in the optimizer. This experiment is on the W\"{u}rstchen architecture, performing Face-Style composition for 4 subjects and 30 styles over a single seed. We report the Face Similarity metric along with cached memory overhead for backpropagation, $\Delta_{bp}$.  For this experiment, we focus on a single constraint, i.e. the subject descriptor constraint $\mathcal{L}_c$ from Equation~\ref{eq:dsoc}. This is due to the fact that gradient-free methods find it harder to converge with additional criterions. The first row provides performance and $\Delta_{bp}$ measurements on base Wurschten model without stochastic control. The second row shows results with gradient descent(as used in our paper), and the third row shows zero-order optimization. As stated in the table, we observe that while ZO optimization is not at par with gradient descent, it shows that it outperforms the base model with no latent optimization - achieving a competitive personalization distance.
Also, the memory savings resulting from ZO are significant. Thus, we suggest the use of ZO techniques for the latent update in scenarios where one can afford to trade training time for a more favorable memory budget. Our experiments with ZO are preliminary, and moving forward we intend to explore this area in much more detail.

\begin{table}[ht]
    %\addtolength{\tabcolsep}{-1.5pt}
    \centering
    \vspace{-0.5 em}

    \fontsize{7.0pt}{5.75pt}\selectfont
    \begin{tabular}{cc|cc}
    \toprule
    Latent Optimization & Zero Order & Face Sim & $\Delta_{bp}$ (GB) \\ [0.5ex] 
    \hline
    \midrule
     &  & 57.7 & 0 \\
    % Content & IP-Adapter   & 0.546 & - \\
     \rowcolor{Gray} \checkmark & & \textbf{65.4} & 5.6 \\
     \rowcolor{Gray} \checkmark & \checkmark & 58.9 & 0 \\
    
    % \rowcolor{Gray} Content & ObjectZero   & 0.610 &  - \\
    \bottomrule
\end{tabular}
% \fontsize{8.00pt}{8.25pt}\selectfont

\caption{\textbf{Zero-Order Stochastic Controller}}
\label{tab:zo_control}
\end{table}


\section{Qualitative Results}
\subsection{Face-Style Composition}

Figure~\ref{fig:faces_stylized_all} is an extension to our Fig~\ref{fig:faces_stylized}, and shows SubZero results for 9 faces stylized by 9 styles. As observed, SubZero can stylize a wider distribution of faces across a broad range of styles in a zero-shot setting. These images are generated with style descriptor prompts. Additionally, we show SubZero face-style composition results without style helper prompts in Figure~\ref{fig:faces_stylized_nohelpers}. As observed, our trained StyleZero adapter can effectively adapt to a wide variety of styles, without the need for the style descriptor in prompt. This is an elusive goal in the domain of image stylization, as also discussed by the authors of~\cite{rout2024rb} and ~\cite{shah2025ziplora}.

\begin{figure}[h]
    \centering
    \includegraphics[width=1.0\linewidth]{figures/faces_stylized_all.jpg}
    \caption{
    % \textbf{Stylized Faces with SubZero}. Stylized Faces with SubZero.
Various stylized face images generated using our proposed SubZero method. These images are using style helper prompts.
SubZero produces high-quality, diverse stylized images while maintaining facial features.
    }%, and suffer from mode collapse. However, our proposed FouRA produces more diverse images.}
    \label{fig:faces_stylized_all}

\end{figure}


\begin{figure}[h]
    \centering
    \includegraphics[width=1.0\linewidth]{figures/subzero_all_faces_stylized_nohelpers.jpg}
    \caption{
    % \textbf{Stylized Faces with SubZero}. Stylized Faces with SubZero.
Various stylized face images generated using our proposed SubZero method. These images are without style helper prompts. Even without style descriptors in the prompt, SubZero produces images which remain faithful to the input style while maintaining facial features.
    } \label{fig:faces_stylized_nohelpers}

\end{figure}

\clearpage

\subsection{Object-Style Composition}
Figure~\ref{fig:object_style_app} is an extension to our Fig~\ref{fig:object_style_action}, and shows SubZero results for object-style composition compared to IP-Adapter. As clearly visible in the image, IP-Adapter contains subject leakage artifacts, which are clearly fixed when using SubZero.

\begin{figure}[h]
    \centering
    \includegraphics[width=1.0\linewidth]{figures/subzero_object_app.jpg}
    \caption{
    % \textbf{Stylized Faces with SubZero}. Stylized Faces with SubZero.
SubZero object-style composition v/s IP-Adapter. All results are using SDXL lightning backbone. As observed, IP-Adapter contains subject leakage artifacts, which are clearly fixed when using SubZero.
    } \label{fig:object_style_app}

\end{figure}

\section{Limitations and Future Work}

While SubZero manages to produce a significant improvement in performance on Subject, Style and Action composition over current SOTA, we observe that there is still a scope for improvement. In certain cases with detailed action prompts, we observe artifacts such as multiple-object generation and distortion. This is also attributed to the fact that SDXL-Lightning is a 4-step diffusion model, and does not enable corrective negative prompting with guidance conditioning. Hence, we aim to improve the robustness of this method by integrating newer baselines which produce lesser failure cases.

Furthermore, our proposed zero-order optimization for latent optimization is a promising step to incorporate zero-order training within the vision community. While our method can run on a mobile device without latent optimization, we plan to build on our ZO results to enable the capabilities of our proposed disentangled stochastic optimal controller for mobile devices which cannot perform back-propagation.

Overall, assessing the performance of SubZero, we believe that our proposed method will lay a foundation for further research in training-free personalization