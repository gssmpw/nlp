\section{Introduction}

Technology use in the education domain, at both K12 and higher education institutes (HEI), has seen unprecedented growth recently, digitizing every aspect of teaching, learning, research, and administrative tasks~\cite{datafication-HE, constant-expanding-classroom, edtech-ccs2024, chanensonUncoveringPrivacySecurityK12CHI23}. %These tools and services include the ones that were designed for educational purposes, such as x and y, and also repurposing general ones, like x and y, turning educational institutes into giant and complex tech ecosystems. In parallel, there has been an increasing number of reported incidents of security and privacy attacks by external adversaries, as well as data abuse by the service providers~\cite{abc}.
Simultaneously, there has been much effort from the research community to understand \SP risks as perceived by different stakeholders in this setting. For example, researchers investigated the factors affecting decisions to adopt tools by educators and administrators~\cite{chanensonUncoveringPrivacySecurityK12CHI23, balashEducatorsPerspectives2023, shiojiItsBeenLovely}, rising \SP concerns of data subjects due to an increasing number of tools being deployed~\cite{edtechPETS23, studentPrivacySchoolDevices, examining-examiners, yang_discovering_2024, radway_investigation_2024}, how these tools are being audited and maintained to alleviate \SP risks~\cite{edtech-ccs2024, chanensonUncoveringPrivacySecurityK12CHI23}, as well as how institutional policies and other regulatory measures aim to minimize the use of collected data in privacy-invasive ways~\cite{radway_investigation_2024, edtech-ccs2024}. 

Existing literature lacks an understanding of the \SP impacts of tools and services that escape institutional auditing and are nrot bound by institutional policy or contracts that mandate certain levels of data protection and restrict the use and sharing of data. A previous study noted that such use cases may be ubiquitous as there is a plethora of apps and services that can be used by anyone for teaching and learning-related activities, often free of cost~\cite{edtech-ccs2024}. Even paid apps in many cases can be personally acquired, for example using research grants or departmental funds, where they do not go through the institutional procurement and security audit process if the price is lower than a threshold~\cite{edtech-ccs2024}, and thus they do not have a formal contract restricting data collection and use. This lack of a vetting process and contracts may lead to increased risks of leaking private data, as well as legal liabilities for the users or the institutions since many institutional records are protected under laws (such as FERPA~\cite{ferpa}) that do not apply to other domains. Thus, investigating the use of technologies (apps and services) in institutional settings that were not institutionally acquired or sanctioned, and the associated data \SP issues need urgent attention.

% Moreover, the use of personal devices (such as mobile phones and laptops), which are excluded from institutional protective mechanisms, for professional activities has become commonplace in many domains~\cite{boyd2014, BOYD-HEI, orrShadowITHigherEduSurvey2024}; but such uses in the academic context can have legal implications due to additional privacy regulations applicable here, such as FERPA~\cite{ferpa}. In summary, the use of unsanctioned apps and devices for educational purposes raises data privacy and security concerns, as well as may lead to institutional non-compliance with applicable privacy laws. Thus, there is an urgent need to investigate the \SP  impact of the use of unsanctioned apps and devices in the academic context.
%
This paper contributes to shedding light on this matter; specifically, it seeks to answer the following research questions: (1)~RQ1: What unsanctioned technologies do instructors (at K12 or HEIs) use that are not institutionally acquired (i.e., unsanctioned) and why?, (2)~RQ2: How do instructors perceive and experience \SP issues and risks of those apps and how those perceptions impact their use?, and (3)~How the use of unsanctioned technologies impact the \SP posture of education institutes?

To answer these questions, we first conduct an online study (N=432) involving instructors at K12 and HEIs to learn about their use of unsanctioned apps and personal devices, their perception and experience of associated \SP issues, their knowledge and understanding of institutional policy about unsanctioned technology use, as well as their efforts to minimize \SP risks. We identified 452 unique apps they use for various purposes, including research purposes and photography classes. We identify the absence of institution-provided alternatives, habituation, usability, and surprisingly, being `forced' by school admins, among the primary reasons for unsanctioned app use. Major selection criteria they used include the apps' capacity to engage students and AI (Artificial Intelligence) features; \SP were rarely considered as a primary deciding factor. 
% main reasons: no alternative, habit and usability even if alternatives were available. Primary selection criteria: interactive tools to engage students, AI features (in HEI), SP was not a primary selection factor, though 218 of the participants considered SP, 176 considered it never. 
%Typical uses of these apps include (\hlfixme{add two to three uses}) but some uses seem to be invasive and ethically questionable (e.g., an app is used to help student regulate their emotion). Additionally, most apps (\hlfixme{N=XXx}) require students to sign up using personal or institutional credentials, potentially violating FERPA. 
We also find that many participants continued to use apps despite distrusting them and even after observing privacy-invasive behaviors. Less than half of the participants knew the existence of institutional policy, and most of those who knew went against it to use unsanctioned apps. 

%While most people knew PII, they lacked understanding of tracking using PII or existence of brokers who sell PII.

% In the absence of institutional contracts, developers' privacy policies dictate data collection behaviors of unsanctioned apps. Thus, we manually reviewed the policies of the most frequently mentioned \hlfixme{N} apps. Apps specifically created for education purposes, such as Google Classroom, have a separate privacy policy for student data and are generally more conservative in data collection, profiling, and targeted advertising. General purpose apps, however, contain statements indicating the collection, use, and sharing of data (that may include data protected under FERPA) that can pose privacy risks \sazz{Which is not surprising?}.

% Prior research has reported that apps may not comply with their own privacy policy; to investigate if similar issues exists here, we conducted static analysis of \hlfixme{XXx} apps. Besides identifying excessive data collection/trackers in many apps, 'app X' also contained trackers, contradicting their privacy policy. Moreover, to investigate actual behavior, we conducted dynamic analysis of top \hlfixme{XXx} apps with simulated user interactions for three hours per app. We find that ...

We supplement these findings with another study surveying school administrators, IT support staff, and technology policy makers (N=29). The results concur with findings from the first survey, where admins acknowledged that instructors often use unsanctioned apps and request their integration with institutional apps, which are sometimes accommodated. Participants also listed \SP incidents their institution faced because of unsanctioned app and device use; examples include a third-party app scraping institutional data, and increased security vulnerability due to instructors forwarding emails to their private accounts. 

Overall, our studies surface striking \SP issues, which might impact millions of students, arising from using unsanctioned technology. We discuss the privacy, security, and compliance implications of these results, and provide recommendations to improve this situation. 

% Overall, our contributions are:
% \begin{itemize}
%     \item Contribution 1
%     \item Contribution 2
%     \item How many do you want?
% \end{itemize}