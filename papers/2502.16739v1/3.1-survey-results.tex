\subsubsection{Participants}
We collected data from $450$ participants and manually reviewed it to exclude $18$ responses that were either autogenerated or gibberish. This left us with $432$ valid responses: $283$ from K-12 educators and $149$ from HEI educators.
Our participants represented diverse demographics: $313$ identified as female, $137$ as male, and $5$ as non-binary. 
% The age distribution was as follows: $26$ participants were 18–24, 72 were 25–30, 144 were 31–40, 125 were 41–50, 67 were 51–60, and 22 were 61+. 
The age distribution was as follows: $98$ participants were under $30$ (18–29), $269$ were 30–50, and $89$ were over $50$.
Regarding education, $18$ had a high school diploma, $55$ had a Bachelor’s degree, $104$ had a Master’s degree, $23$ had a doctorate, and the rest preferred not to answer.
Discipline-wise, $28$ participants taught STEM subjects, $290$ taught non-STEM subjects, and $135$ did not disclose their discipline.

\subsubsection{Use of unsanctioned apps}
\label{use_unsanctioned_apps}
Participants listed a total of 1,654 apps and services, with 494 being unique. Among these, participants K-12 and HEIs shared 88 applications. K-12 participants 284 unique apps, while HEIs identified 121 unique applications.
% \rakib{need to add all app names with the number of people mentioning them in a table in the appendix}.
The most popular personal use applications were Kahoot! (n=73), ChatGPT (n=69), Google Classroom (n=63), Canva (n=55), and Quizlet (n=50). For K-12 participants alone, top 3 were Google Classroom, Kahoot!, and a tie between ChatGPT and Canva, while HEI participants favored ChatGPT, Kahoot!, and Canva.

A huge majority ($87\%$ of $432$ participants) stated that they use personal devices for teaching-related tasks.
Among these, $114$ participants used personal devices daily, while 139 used them several times a week.
%Breakdown: ('Several times a week', 139), ('Daily', 114), ('A few times a month', 46), ('Rarely', 44), ('Once a week', 36). 
Moreover, $277$ participants downloaded institutional documents (e.g., student data, grade books) onto personal devices.
Of these, $137$ reported that their devices had automatic cloud backups through personal accounts, potentially exposing institutional data to security risks. % meaning that the work they are downloading will be saved onto the educators personal device. 

\subsubsection{Primary factors in app selection}
\label{app_selection_factors}
Gamification was a key factor in app selection, with $30.4\%$ of K-12 apps focused on helping students
% Among the 327 unique applications that K-12 educators shared with us, 30.4\% were programs that gamified education and helped students 
learn basics of reading, mathematics, and other general subjects.
Classroom management tools also played a significant role among K-12 participants, comprising $12.2\%$ of the apps.
Participants emphasized their value, describing them as ``a fun way to track classroom behavior'' (P59) and noting they were ``chosen for their ability to enhance classroom management and communication with both students and parents'' (P83).

HEI educators used a range of tools, with $30.3\%$ of their apps 
% (total 209; including both unique to HEIs and common with K-12 participants)
focused on tasks such as note-taking, sharing materials with students, and conducting research. 
AI-based applications made up $7.4\%$ of their apps, reflecting the growing integration of AI in education. 
Educators stated that the use of AI ``makes students want to learn, and motivates me'' (P211) and ``enhances my teaching of literature'' (P210).
In addition, specialized tools were commonly used, and one participant mentioned the need for apps to ``shoot RAW images with a smartphone'' (P151).

% Among the apps were the ones that continuously monitor the users, such as Class Dojo and GoGuardian, and have been controversial for privacy and ethical reasons~\cite{abc}.  These apps supposedly are used for reasons such as safety and, as one participant stated ``to help students regulate their emotions'', but their ...

% Regarding integrating the unsanctioned apps with other institutionally acquired apps, 259 participants did that for at least one app while 53 did that for all three apps. Additionally, 556 apps \rakib{Easton, need to explain how we have 556 apps instead of 494 mentioned above} of the total 1654 required students to sign in with their own credentials - student email, ID number, etc. Such integration and institutional authentication can have security, privacy, and legal implications (see \S~\ref{sec:discussion}). 


% While 7 participants stated that a factor that mattered to them when choosing an application was that it was ``secure'', most respondents did not think about it. At the end of the survey, we asked participants to define in their own words what the meaning of Online tracking, Personally Identifiable Information (PII), and Data Brokers were to see if educators that are choosing these applications are aware of what their own data is and how it could be tracked. 

% When asked if there was an institutionally approved alternative to use and why they did not use theme, participants said that they were ``unfamiliar'' (P404) or ``didn’t find it easy to use'' (P20). One participant highlighted their issue with their institutionally provided software, stating ``Yes, there was an alternative available within the university's tool profile, such as the university's cloud storage service. However, I chose not to use it because Google Drive offered better accessibility, real-time collaboration features, and a more intuitive user interface, making it a more convenient and efficient option for my needs.'' (P14).

\subsubsection{Reasons behind unsanctioned app use}
\label{reasons_unsanctioned_app_use}
In both K-12 and HEI contexts, the overwhelming majority ($n=387$) mentioned ``ease of use'' or similar phrases as the primary reason to use unsanctioned apps, even when institutional alternatives were available. 
Accessibility ($n=281$), student engagement ($n=279$), and price ($n=212$) followed closely as significant factors. 
%
Almost $70\%$ of the participants who prioritized engagement ($n=279$) were K-12 educators ($n=195$), emphasizing that these apps ``keep students very engaged'' (P30).
Familiarity with certain tools also played a role: $84$ participants resisted school-provided options, noting they were accustomed to other tools due to previous careers, long-term use, and unwillingness to adapt to a new tool.

% Interestingly, 25 participants reported being strongly encouraged or required to use certain apps by administrators.
% K-12 were especially looking for applications that ``Keeps students very engaged'' (P30). Of the 279 participants that put engagement as one of their primary reasons, 195 of them were from K-12 educators. 
% For K-12 educators, being accustomed to using tools also plays a key role: 84 participants mentioned that they did not use school-provided tools because they were used to using another tool (``Previous career'' (P10), ``using it since I was in high school'') and were unwilling to learn a new one. Another surprising reason a fairly large number of K-12  participants (N=25) mentioned was being strongly recommended or even forced to use by administrators. 

Within HEI setting, primary driver was the need for specialized tools unavailable through their institutions (n=61). 
Participants highlighted requirements for tasks such as ``basic image editing'' (P300) or accessing ``reference apps for specific films and developer combinations'' (P151). 
Research-related tools were also important, with educators seeking apps to ``help with research papers'' (P52) and tools for lab-specific needs, such as ``coding observational data'' (P37).
%
%For example, one participant stated how their ``district encouraged us to use AI.'' (P329).
%
Surprisingly, only $7/432$ (i.e., $1.6\%$) participants cited ``security'' as a factor in their unsanctioned application choices, indicating that most respondents did not prioritize it as a primary selection criterion.


\subsubsection{Security and Privacy Perceptions}
\label{sp_perceptions}
As mentioned previously, while \sp were rarely top priorities in app selection, $218$ participants acknowledged considering these issues for at least one unsanctioned app they listed, and $72$ consistently evaluated \sp for all three apps they listed. On the other hand, a significant proportion---more than one-third ($n=176$)---did not consider these aspects at all when choosing their apps. 
This highlights a complex relationship between perceived risks and actual behavior.


% while security and privacy were not among the major selection criteria, $218$ participants stated that they considered \ananta{what does it mean by considering sp issues? need to explain better. We already mentioned that security was only mentioned by 7 participants, now here these big numbers can throw off any reader.} these issues for at least one app, while 72 considered these aspects for all 3 apps. More than one-third of the participants (N=176) did not consider security and privacy when selecting any of the three apps they used. 

Despite limited consideration during selection, concerns about \sp issues emerged post-usage. 
$23$ participants reported experiencing security or privacy breaches with at least one app, while $38$ expressed concerns about apps' data collection practices potentially violating user privacy. 
Alarmingly, $43$ participants believed that at least one app sold user data to advertisers, with one participant extending this belief to all three apps they listed.

Compliance awareness was mixed. 
All participants assumed FERPA~\cite{ferpa} and HIPAA~\cite{hipaa} applied to the apps they used, but their perceptions of compliance varied.
For FERPA, 107 participants believed all three apps were compliant, 7 believed none were, and 237 thought at least one app was compliant. However, 71 participants were unsure of any app's FERPA compliance. For HIPAA, 81 participants believed all three apps were compliant, 10 believed none were, 182 believed at least one app was compliant, and 51 were unsure.

Trust in developers’ ability to safeguard user privacy was similarly divided. Fifty-three participants distrusted at least one app, and one distrusted all apps they used. Forty-six doubted the competence of at least one app’s developers to protect privacy, with one participant holding this belief for all their apps.

% \ananta{discussion point: While there is growing awareness of security and privacy issues, many participants continue to use unsanctioned apps, often prioritizing functionality, ease of use, and engagement over compliance and safety.}

\subsubsection{Institutional policy about unsanctioned app use}
\label{inst_policy_on_unsanction_app_use}
%Even if using other technologies were against their institution’s policy, participants in both K-12 and higher education do not know their institution’s policy. 

Surprisingly, only $30.3\%$ of K-12 participants and $24.8\%$ HEI participants were aware that their institution had a policy regarding the use of unsanctioned education technologies. 
Many of those aware of policies (N=22) admitted to using unsanctioned apps despite policy prohibitions, citing institutional shortcomings.
P10 shared that ``[my institution doesn’t] provide a workable path to utilize new and emerging technologies so [I] have to go against it.'' 
Another noted, ``we are not supposed to use any application that is [not] already approved, but many, like myself, ignore the rule.'' (P68).
% \rakib{need to manually categorize the institutional policies participants were aware of  and report here.}

$107$ participants reported receiving institutional warnings about the risks associated with unsanctioned app use. 
Among them, $33$ mentioned that those warnings led to behavioral changes.
The most common changes included discontinuing unsanctioned app use, switching to alternatives perceived as more secure, adopting 2FA, and exercising greater caution when sharing content with platforms. 

% \ananta{discussion point: firstly 107/432 being aware of any institutional warning is a small portion and among them, only 33 were influenced to make any changes. Can we say that current warnings do not translate into action?
% We can discuss about improving overall policy enforcement through improved educators' education, awareness toward risks, and potentially suggesting educator-friendly actions to balance institutional compliance and educator preferences} 

\subsubsection{Discontinuation and data deletion}
\label{discontinue_data_deletion}
$368$ participants reported that they continue to use the three unsanctioned applications they mentioned in the survey. 
This includes 19 participants who experienced security or privacy issues with the apps, 33 who believed the apps collect data that violates users' privacy, 33 who stated the apps share data with advertisers, 47 who expressed distrust in the apps, and 41 who considered the app providers incompetent at protecting privacy.
%
Eighty-five participants mentioned that they stopped using at least one app.
Only nine of them said that the apps provided an option to delete data, and eight of them requested data deletion, while 60 participants were uncertain about the data deletion feature.

% \ananta{discussion point: since we have already discussed the continued usage of unsanctioned apps in presence of institutional policies and limited awareness of \sp risks, we can discuss that although having an option of downloading unsanctioned apps provides a sense of flexibility to the educators, it is an illusion of control at the same time as an exit from these apps is not well understood and implemented so far. Being unaware of data deletion option is a huge indicator of that. It also showcases that educators are not the best candidate to protect institutional data at this moment. Hence, circling back to education and awareness.}

% Some of the tools that participants stated were still in use were such applications that they used over two decades ago, ``It was assigned as part of an undergraduate class back in 2004'' (P149) meaning that some applications may not have up to date security policies to allow for adequate protection for students. Other applications have lost support from their companies, meaning that they are no longer staying up to date on security threats. One such application was Blackboard for self or managed hosting, Blackboard is still updating its bigger applications but no longer support self hosting which is what the educators we surveyed used. With this, educators would still be able to use the application but there would no longer be support for them, leaving themselves and their students in a precarious situation.



% \subsubsection{Privacy and security knowledge, attitude, and behaviors}

% When asked about Online Tracking, 38 and 14 participants in K-12 and University positions, respectfully, did not know what it was or referred to it is how they are able to track their students with management applications stating that it ``refers to student data. I can track how my students are doing online'' (P29) and ``When a district watches your online movements from a sponsored media device'' (P327).

% Most participants understood the meaning of PII, with 31 participants in K-12 and 6 participants in HEIs that did not know the meaning. Most times confusing it with something close to an IP address ``a unique number used to identify a particular user on the Internet'' (P236) or simply stating ``I don’t know'' (P116).

% As a whole there was less understanding of the definition of a Data Broker, with 110 K-12 participants and 32 HEI participants not knowing what it means. Mostly confusing the term with someone that would protect data or hack to get your data themselves, stating ``Data brokers are [there] to protect privacy.'' (P197) and ``someone [that] hacks into your data'' (P256).

% With the use of these applications and subsequent use of student credentials the authors looked into the top applications that our participants used to compare privacy policies to see if specifically educational technologies used different terms and conditions for the sensitive population. 


% \subsubsection{Personal device use}



% \textbf{Discussion point}: Teachers will go to things that others are using as it would be easier to gain help from it, the more people that use it in their institution means the more people that will have experience similar issues. 



% \subsubsection{Privacy Policies}
% \texttt{Kahoot!} is the most widely used educational application overall, as indicated by our findings (\ananta{refer to the relevant section}). 
% It ranks as the most popular tool among K-12 educators and the second most popular among educators in HEIs. 

% The application has a comprehensive privacy policy tailored for distinct user groups—students and general users (\ananta{provide references/citations for both privacy policies}).
% Designed for the global educational technology market, Kahoot! adheres to key educational privacy regulations, including EU’s General Data Protection Regulation (GDPR), the Family Educational Rights and Privacy Act (FERPA), the Children’s Online Privacy Protection Act (COPPA), the California Student Online Personal Information Protection Act (SOPIPA). 
% Notably, Kahoot! emphasizes its commitment to data privacy, stating: 

% \begin{displayquote}
%     \noindent\textit{We do not sell Personal Information (including Sensitive Personal Information), and we do not ``share'' or otherwise process Personal Information (including Sensitive Personal Information) for purposes of cross-context behavioral or targeted advertising, as defined under applicable law.}
% \end{displayquote}

% In K-12 settings, Kahoot! is predominantly used for review sessions and educational games (\ananta{refer to the section on participant motivations for using Kahoot! in K-12 contexts}). The privacy policy explicitly states: \emph{``We do not collect any Personal Information from a person who merely plays a kahoot.''}
% This is particularly invaluable (\ananta{valuable or invaluable?)} for K-12 users as most interactions involve students participating in games rather than creating accounts or generating content. 

% For students who choose to create accounts, the platform provides additional safeguards. 
% Kahoot!’s policy reflects strict compliance with educational privacy laws, ensuring: 

% \begin{displayquote}
%     \noindent\textit{We do not sell students' personal information. We do not build a profile of a student other than in support of authorized school purposes, such as for purposes of attendance or assessment.}
% \end{displayquote}

% If a school has direct contract with Kahoot! then they are able control what information would be taken from the student to then be given to the school. The policy states:
% \emph{``Kahoot! does not collect, retain, use or share students' personal information, except as necessary for authorized school purposes, at the direction of our school and school district customers and pursuant to our agreements with them.''}

% While \texttt{ChatGPT} is the second most used application overall, it is not specifically designed for educational purposes. This distinction is evident in its privacy policy, which does not explicitly address data usage for students, particularly those in K-12 education. The policy states that \emph{``Our Services are not directed to, or intended for, children under 13.''}

% This implies that if educators use ChatGPT with younger students, any data collected could potentially violate data protection regulations for minors, such as COPPA in the United States. The policy outlines:

% \begin{displayquote}
%     \noindent\textit{We collect Personal Data that you provide in the input to our Services (``Content''), including your prompts and other content you upload, such as files, images, and audio, depending on the features you use.}
% \end{displayquote}


% In a classroom setting, this means that any data students input---intentionally or inadvertently---could be collected, including sensitive information. 
% Moreover, since ChatGPT uses input data to refine and train its models, students could unknowingly contribute to a data set without understanding the implications, raising concerns about \emph{data security and informed consent}\ananta{can we cite this?}.

% Additionally, ChatGPT does not provide a comprehensive list of vendors or service providers with whom it shares personal data. 
% While it states that \emph{``To assist us in meeting business operations needs and to perform certain services and functions, we may disclose Personal Data to vendors and service providers... Pursuant to our instructions, these parties will access, process, or store Personal Data only in the course of performing their duties to us.''}

% However, the policy lists vendors such as ``hosting services, customer service vendors, cloud services, content delivery services, web analytics, and payment processors.'' 
% While this provides some transparency, it still leaves questions about the specific safeguards for student and educator data.


% In contrast, \texttt{Google Classroom}, which ranks as the third most used application among educators overall, is specifically designed with educational contexts in mind. This is reflected in the privacy policy of Google Workspace for Education, which includes provisions to protect students and minors. Unlike the standard Google Suites, which may track user activity for personalized ads, Google Classroom adheres to stricter standards for K-12 students. The privacy policy explicitly states:

% \begin{displayquote}
%     \noindent\textit{Your Google Workspace for Education account in primary and secondary schools (K-12), we don’t show you personalized ads, which means we don’t use information from your account or past activity to target ads. However, we may show ads based on general factors like your search query, the time of day, or the content of a page you’re reading.}
% \end{displayquote}

% This ensures that students in K-12 education are not subjected to personalized advertising based on their activity. 
% Additionally, Google Classroom aligns with educational privacy laws such as COPPA and FERPA, offering more transparency and control to educators and institutions. 
% By separating its educational services from general Google services, Google provides a safer and more privacy-conscious environment for student learning.

