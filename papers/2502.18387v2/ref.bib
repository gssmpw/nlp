@misc{yao2023tree,
      title={{Tree of Thoughts}: Deliberate Problem Solving with Large Language Models}, 
      author={Shunyu Yao and Dian Yu and Jeffrey Zhao and Izhak Shafran and Thomas L. Griffiths and Yuan Cao and Karthik Narasimhan},
      year={2023},
      eprint={2305.10601},
      archivePrefix={arXiv},
      primaryClass={cs.CL}
}

@inproceedings{valmeekam2022large,
  title={Large language models still can't plan (a benchmark for LLMs on planning and reasoning about change)},
  author={Valmeekam, Karthik and Olmo, Alberto and Sreedharan, Sarath and Kambhampati, Subbarao},
  booktitle={NeurIPS 2022 Foundation Models for Decision Making Workshop},
  year={2022}
}

@inproceedings{hao2023reasoning,
  title={Reasoning with Language Model is Planning with World Model},
  author={Hao, Shibo and Gu, Yi and Ma, Haodi and Hong, Joshua and Wang, Zhen and Wang, Daisy and Hu, Zhiting},
  booktitle={Proceedings of the 2023 Conference on Empirical Methods in Natural Language Processing},
  pages={8154--8173},
  year={2023}
}

@article{achiam2023gpt,
  title={Gpt-4 technical report},
  author={Achiam, Josh and Adler, Steven and Agarwal, Sandhini and Ahmad, Lama and Akkaya, Ilge and Aleman, Florencia Leoni and Almeida, Diogo and Altenschmidt, Janko and Altman, Sam and Anadkat, Shyamal and others},
  journal={arXiv preprint arXiv:2303.08774},
  year={2023}
}

@article{cao2024automating,
  title={Automating Thought of Search: A Journey Towards Soundness and Completeness},
  author={Cao, Daniel and Katz, Michael and Kokel, Harsha and Srinivas, Kavitha and Sohrabi, Shirin},
  journal={arXiv preprint arXiv:2408.11326},
  year={2024}
}


@inproceedings{
wang2023selfconsistency,
title={Self-Consistency Improves Chain of Thought Reasoning in Language Models},
author={Xuezhi Wang and Jason Wei and Dale Schuurmans and Quoc V Le and Ed H. Chi and Sharan Narang and Aakanksha Chowdhery and Denny Zhou},
booktitle={The Eleventh International Conference on Learning Representations },
year={2023},
url={https://openreview.net/forum?id=1PL1NIMMrw}
}

@article{snell2024scaling,
  title={Scaling llm test-time compute optimally can be more effective than scaling model parameters},
  author={Snell, Charlie and Lee, Jaehoon and Xu, Kelvin and Kumar, Aviral},
  journal={arXiv preprint arXiv:2408.03314},
  year={2024}
}

@inproceedings{
feng2023alphazerolike,
title={Alphazero-like Tree-Search can Guide Large Language Model Decoding and Training},
author={Xidong Feng and Ziyu Wan and Muning Wen and Ying Wen and Weinan Zhang and Jun Wang},
booktitle={NeurIPS 2023 Foundation Models for Decision Making Workshop},
year={2023},
url={https://openreview.net/forum?id=PJfc4x2jXY}
}

@article{wei2022chain,
  title={Chain-of-thought prompting elicits reasoning in large language models},
  author={Wei, Jason and Wang, Xuezhi and Schuurmans, Dale and Bosma, Maarten and Xia, Fei and Chi, Ed and Le, Quoc V and Zhou, Denny and others},
  journal={Advances in neural information processing systems},
  volume={35},
  pages={24824--24837},
  year={2022}
}

@misc{Sutton2019BitterLesson,
  author       = {Sutton, Richard},
  title        = {The Bitter Lesson},
  year         = {2019},
  howpublished = {Blog post},
  url          = {http://www.incompleteideas.net/IncIdeas/BitterLesson.html},
  note         = {Accessed: Augsust 2024},
}

@article{wang2024litesearch,
  title={Litesearch: Efficacious tree search for llm},
  author={Wang, Ante and Song, Linfeng and Tian, Ye and Peng, Baolin and Yu, Dian and Mi, Haitao and Su, Jinsong and Yu, Dong},
  journal={arXiv preprint arXiv:2407.00320},
  year={2024}
}


@article{besta2024got,
  title = {{Graph of Thoughts: Solving Elaborate Problems with Large Language Models}},
  author = {Besta, Maciej and Blach, Nils and Kubicek, Ales and Gerstenberger, Robert and Gianinazzi, Lukas and Gajda, Joanna and Lehmann, Tomasz and Podstawski, Micha{\l} and Niewiadomski, Hubert and Nyczyk, Piotr and Hoefler, Torsten},
  year = 2024,
  month = {Mar},
  journal = {Proceedings of the AAAI Conference on Artificial Intelligence},
  volume = 38,
  number = 16,
  pages = {17682-17690},
  publisher = {AAAI Press},
  doi = {10.1609/aaai.v38i16.29720},
  url = {https://ojs.aaai.org/index.php/AAAI/article/view/29720}
}

@article{katz2024planning,
  title={Planning with Language Models Through The Lens of Efficiency},
  author={Katz, Michael and Kokel, Harsha and Srinivas, Kavitha and Sohrabi, Shirin},
  journal={NeurIPS},
  year={2024}
}

@article{du2024advancing,
  title={Advancing Real-time Pandemic Forecasting Using Large Language Models: A COVID-19 Case Study},
  author={Du, Hongru and Zhao, Jianan and Zhao, Yang and Xu, Shaochong and Lin, Xihong and Chen, Yiran and Gardner, Lauren M and Yang, Hao Frank},
  journal={arXiv preprint arXiv:2404.06962},
  year={2024}
}

@article{mao2023gpt,
  title={Gpt-driver: Learning to drive with gpt},
  author={Mao, Jiageng and Qian, Yuxi and Ye, Junjie and Zhao, Hang and Wang, Yue},
  journal={arXiv preprint arXiv:2310.01415},
  year={2023}
}


@article{gpt4ocard,
  title={Gpt-4o system card},
  author={Hurst, Aaron and Lerer, Adam and Goucher, Adam P and Perelman, Adam and Ramesh, Aditya and Clark, Aidan and Ostrow, AJ and Welihinda, Akila and Hayes, Alan and Radford, Alec and others},
  journal={arXiv preprint arXiv:2410.21276},
  year={2024}
}

@misc{qwen2.5,
  title={Qwen2.5: A Party of Foundation Models},
  url={https://qwenlm.github.io/blog/qwen2.5/},
  author={Qwen},
  month={September},
  year={2024}
}

@misc{qwq-32b-preview,
  title = {QwQ: Reflect Deeply on the Boundaries of the Unknown},
  url = {https://qwenlm.github.io/blog/qwq-32b-preview/},
  author = {Qwen},
  month = {November},
  year = {2024}
}

@misc{openaio1card,
  title = {OpenAI o1 System Card},
  author = {OpenAI},
  year = {2024},
  url = {https://cdn.openai.com/o1-system-card.pdf}
}


@misc{sky_t1_2025,
  author       = {NovaSky},
  title        = {Sky-T1: Fully open-source reasoning model with o1-preview performance in \$450 budget},
  url = {https://novasky-ai.github.io/posts/sky-t1},
  year         = {2025}
}

@article{cobbe2021training,
  title={Training verifiers to solve math word problems},
  author={Cobbe, Karl and Kosaraju, Vineet and Bavarian, Mohammad and Chen, Mark and Jun, Heewoo and Kaiser, Lukasz and Plappert, Matthias and Tworek, Jerry and Hilton, Jacob and Nakano, Reiichiro and others},
  journal={arXiv preprint arXiv:2110.14168},
  year={2021}
}

@article{lightman2023let,
  title={Let's verify step by step},
  author={Lightman, Hunter and Kosaraju, Vineet and Burda, Yura and Edwards, Harri and Baker, Bowen and Lee, Teddy and Leike, Jan and Schulman, John and Sutskever, Ilya and Cobbe, Karl},
  journal={arXiv preprint arXiv:2305.20050},
  year={2023}
}

@article{zhao2024large,
  title={Large language models as commonsense knowledge for large-scale task planning},
  author={Zhao, Zirui and Lee, Wee Sun and Hsu, David},
  journal={Advances in Neural Information Processing Systems},
  volume={36},
  year={2024}
}

@article{xiao2023llm,
  title={Llm a*: Human in the loop large language models enabled a* search for robotics},
  author={Xiao, Hengjia and Wang, Peng},
  journal={arXiv preprint arXiv:2312.01797},
  year={2023}
}

@article{liu2023llm+,
  title={Llm+ p: Empowering large language models with optimal planning proficiency},
  author={Liu, Bo and Jiang, Yuqian and Zhang, Xiaohan and Liu, Qiang and Zhang, Shiqi and Biswas, Joydeep and Stone, Peter},
  journal={arXiv preprint arXiv:2304.11477},
  year={2023}
}

@inproceedings{yao2023react,
  title={ReAct: Synergizing Reasoning and Acting in Language Models},
  author={Yao, Shunyu and Zhao, Jeffrey and Yu, Dian and Du, Nan and Shafran, Izhak and Narasimhan, Karthik R and Cao, Yuan},
  booktitle={ICLR},
  year={2023}
}

@article{valmeekam2023planning,
  title={On the planning abilities of large language models-a critical investigation},
  author={Valmeekam, Karthik and Marquez, Matthew and Sreedharan, Sarath and Kambhampati, Subbarao},
  journal={Advances in Neural Information Processing Systems},
  volume={36},
  pages={75993--76005},
  year={2023}
}

@article{jojic2023gpt,
  title={Gpt is becoming a turing machine: Here are some ways to program it},
  author={Jojic, Ana and Wang, Zhen and Jojic, Nebojsa},
  journal={arXiv preprint arXiv:2303.14310},
  year={2023}
}

@inproceedings{lyu2023faithful,
  title={Faithful Chain-of-Thought Reasoning},
  author={Lyu, Qing and Havaldar, Shreya and Stein, Adam and Zhang, Li and Rao, Delip and Wong, Eric and Apidianaki, Marianna and Callison-Burch, Chris},
  booktitle={IJCNLP-AACL},
  pages={305--329},
  year={2023}
}

@inproceedings{
zhou2023leasttomost,
title={Least-to-Most Prompting Enables Complex Reasoning in Large Language Models},
author={Denny Zhou and Nathanael Sch{\"a}rli and Le Hou and Jason Wei and Nathan Scales and Xuezhi Wang and Dale Schuurmans and Claire Cui and Olivier Bousquet and Quoc V Le and Ed H. Chi},
booktitle={The Eleventh International Conference on Learning Representations },
year={2023},
}

@inproceedings{
welleck2023generating,
title={Generating Sequences by Learning to Self-Correct},
author={Sean Welleck and Ximing Lu and Peter West and Faeze Brahman and Tianxiao Shen and Daniel Khashabi and Yejin Choi},
booktitle={The Eleventh International Conference on Learning Representations },
year={2023}
}

@article{shinn2024reflexion,
  title={Reflexion: Language agents with verbal reinforcement learning},
  author={Shinn, Noah and Cassano, Federico and Gopinath, Ashwin and Narasimhan, Karthik and Yao, Shunyu},
  journal={Advances in Neural Information Processing Systems},
  volume={36},
  year={2024}
}

@inproceedings{paul2023refiner,
  title={REFINER: Reasoning Feedback on Intermediate Representations},
  author={Paul, Debjit and Ismayilzada, Mete and Peyrard, Maxime and Borges, Beatriz and Bosselut, Antoine and West, Robert and Faltings, Boi},
  booktitle={EACL 2024, Malta},
  year={2023}
}

@inproceedings{gao2023pal,
  title={Pal: Program-aided language models},
  author={Gao, Luyu and Madaan, Aman and Zhou, Shuyan and Alon, Uri and Liu, Pengfei and Yang, Yiming and Callan, Jamie and Neubig, Graham},
  booktitle={International Conference on Machine Learning},
  pages={10764--10799},
  year={2023},
  organization={PMLR}
}

@article{crama2005local,
  title={Local search in combinatorial optimization},
  author={Crama, Yves and Kolen, Antoon WJ and Pesch, EJ},
  journal={Artificial Neural Networks: An Introduction to ANN Theory and Practice},
  pages={157--174},
  year={2005},
  publisher={Springer}
}

@article{hart1968formal,
  title={A formal basis for the heuristic determination of minimum cost paths},
  author={Hart, Peter E and Nilsson, Nils J and Raphael, Bertram},
  journal={IEEE transactions on Systems Science and Cybernetics},
  volume={4},
  number={2},
  pages={100--107},
  year={1968},
  publisher={IEEE}
}

@article{deepseekai2025deepseekr1,
  title={DeepSeek-R1: Incentivizing Reasoning Capability in LLMs via Reinforcement Learning},
  author={Guo, Daya and Yang, Dejian and Zhang, Haowei and Song, Junxiao and Zhang, Ruoyu and Xu, Runxin and Zhu, Qihao and Ma, Shirong and Wang, Peiyi and Bi, Xiao and others},
  journal={arXiv preprint arXiv:2501.12948},
  year={2025}
}


@article{abacha2024medec,
  title={Medec: A benchmark for medical error detection and correction in clinical notes},
  author={Abacha, Asma Ben and Yim, Wen-wai and Fu, Yujuan and Sun, Zhaoyi and Yetisgen, Meliha and Xia, Fei and Lin, Thomas},
  journal={arXiv preprint arXiv:2412.19260},
  year={2024}
}

@article{wang2024q,
  title={Q*: Improving multi-step reasoning for llms with deliberative planning},
  author={Wang, Chaojie and Deng, Yanchen and Lyu, Zhiyi and Zeng, Liang and He, Jujie and Yan, Shuicheng and An, Bo},
  journal={arXiv preprint arXiv:2406.14283},
  year={2024}
}

@article{wang2024multi,
  title={Multi-step problem solving through a verifier: An empirical analysis on model-induced process supervision},
  author={Wang, Zihan and Li, Yunxuan and Wu, Yuexin and Luo, Liangchen and Hou, Le and Yu, Hongkun and Shang, Jingbo},
  journal={arXiv preprint arXiv:2402.02658},
  year={2024}
}

@article{uesato2022solving,
  title={Solving math word problems with process-and outcome-based feedback},
  author={Uesato, Jonathan and Kushman, Nate and Kumar, Ramana and Song, Francis and Siegel, Noah and Wang, Lisa and Creswell, Antonia and Irving, Geoffrey and Higgins, Irina},
  journal={arXiv preprint arXiv:2211.14275},
  year={2022}
}

@inproceedings{silver2024generalized,
  title={Generalized planning in pddl domains with pretrained large language models},
  author={Silver, Tom and Dan, Soham and Srinivas, Kavitha and Tenenbaum, Joshua B and Kaelbling, Leslie and Katz, Michael},
  booktitle={Proceedings of the AAAI Conference on Artificial Intelligence},
  volume={38},
  number={18},
  pages={20256--20264},
  year={2024}
}

@inproceedings{howey2003automatic,
  title={The Automatic Validation Tool for PDDL2.},
  author={Howey, Richard and Long, Derek},
  year={2003}
}

@article{wang2024comprehensive,
  title={A comprehensive survey of small language models in the era of large language models: Techniques, enhancements, applications, collaboration with llms, and trustworthiness},
  author={Wang, Fali and Zhang, Zhiwei and Zhang, Xianren and Wu, Zongyu and Mo, Tzuhao and Lu, Qiuhao and Wang, Wanjing and Li, Rui and Xu, Junjie and Tang, Xianfeng and others},
  journal={arXiv preprint arXiv:2411.03350},
  year={2024}
}

@article{lin2024decoding,
  title={Decoding Time Series with LLMs: A Multi-Agent Framework for Cross-Domain Annotation},
  author={Lin, Minhua and Chen, Zhengzhang and Liu, Yanchi and Zhao, Xujiang and Wu, Zongyu and Wang, Junxiang and Zhang, Xiang and Wang, Suhang and Chen, Haifeng},
  journal={arXiv preprint arXiv:2410.17462},
  year={2024}
}

@article{zhang2024does,
  title={Does your LLM truly unlearn? An embarrassingly simple approach to recover unlearned knowledge},
  author={Zhang, Zhiwei and Wang, Fali and Li, Xiaomin and Wu, Zongyu and Tang, Xianfeng and Liu, Hui and He, Qi and Yin, Wenpeng and Wang, Suhang},
  journal={arXiv e-prints},
  pages={arXiv--2410},
  year={2024}
}

@article{wu2025lanp,
  title={LanP: Rethinking the Impact of Language Priors in Large Vision-Language Models},
  author={Wu, Zongyu and Niu, Yuwei and Gao, Hongcheng and Lin, Minhua and Zhang, Zhiwei and Zhang, Zhifang and Shi, Qi and Wang, Yilong and Fu, Sike and Xu, Junjie and others},
  journal={arXiv preprint arXiv:2502.12359},
  year={2025}
}

@article{zhang2024divide,
  title={Divide-Verify-Refine: Aligning LLM Responses with Complex Instructions},
  author={Zhang, Xianren and Tang, Xianfeng and Liu, Hui and Wu, Zongyu and He, Qi and Lee, Dongwon and Wang, Suhang},
  journal={arXiv preprint arXiv:2410.12207},
  year={2024}
}

@article{xu2024llm,
  title={Llm and gnn are complementary: Distilling llm for multimodal graph learning},
  author={Xu, Junjie and Wu, Zongyu and Lin, Minhua and Zhang, Xiang and Wang, Suhang},
  journal={arXiv preprint arXiv:2406.01032},
  year={2024}
}