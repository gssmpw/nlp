\section{Toward Complete Search via Learning}
{While \method effectively balances efficiency and effectiveness, our observation indicates potential compromises in solution accuracy. In high-stakes domains such as autonomous driving~\cite{mao2023gpt} and pandemic response planning~\cite{du2024advancing}, ensuring completeness is fundamental to search algorithms, as overlooking any viable solution can have severe consequences. This motivates us to develop a search framework that rigorously ensures completeness. Next, we formalize search completeness and introduce \cmethod, an enhanced variant of \method{} that integrates efficient learning-guided exploration with formal guarantees of completeness.}

% \vspace{-1em}
\subsection{Formalizing Search Completeness}
\label{subsec:theoretical_foundations}
We begin by formalizing search completeness--the guarantee of finding a solution when one exists:
\begin{definition}[Search Completeness]
A search algorithm is complete if and only if for any initial state $s^{init} \in \mathcal{S}$ and goal state $s^{goal}$, whenever there exists a valid solution path $P = (s^0, ..., s^n)$ where $s^n \in s^{goal}$, the algorithm is guaranteed to find it.
\end{definition}


\subsection{\cmethod: Achieving Search Completeness}
\label{subsec:method_cs}
Building on this definition, we first analyze potential completeness compromises in \method, then present \cmethod's mechanisms for ensuring rigorous completeness. The full algorithm of \cmethod is shown in Alg.~\ref{alg:Framwork_completeness}.

\noindent \textbf{How Can Completeness Be Compromised}?
According to Sec.\ref{sec:seal_method}, \method uses LLMs for state decomposition and validity checking, inspired by Obs. 2 and 3. However, our analysis in Sec.\ref{sec:preliminary_results_analysis} reveals that they may inadvertently ignore valid states during decomposition or prematurely terminate exploration of valid paths, compromising completeness.

\noindent \textbf{Learning-Guided Complete State Decomposition}. To ensure completeness while maintaining efficiency, \cmethod employs a learning-guided complete state decomposition strategy by combining learning-based prioritization with a fallback mechanism for exhaustive state expansion:
\begin{equation}
% \begin{aligned}
\small
{S}^{next} = M\big(p_d(s^{cur})\big) || \big(D(s^{cur})\setminus M(p_d(s^{cur}))\big)
% \end{aligned}
\end{equation}
where $||$ denotes ordered concatenation, ensuring LLM-generated states $M(p_{{d}}(s))$ are explored first. $D(s)$ is the complete state decomposition function from Eq.~(\ref{eq:state_decomposition}). 
% $\setminus$ is the set difference, retaining the rest states in $D(s)$ not proposed by LLMs. 
This approach prioritizes exploration of likely valid states while ensuring no potential solution is overlooked, guaranteeing completeness while benefiting from learning-guided efficiency.

\noindent \textbf{Two-phase Ranking}. 
To further improve efficiency, \cmethod{} introduces a two-phase ranking strategy for $S^{next}$. Instead of ranking all states at once, it first ranks and explores the LLM-generated states $M(p_d(s^{cur}))$, which are more likely to reach $s^{goal}$. Only when no solution is found does the algorithm proceed to rank and explore the remaining states from $D(s^{cur})$, which significantly reduces the search space by avoiding unnecessary ranking of supplementary states.

