\section{Related Work}
%Due to space constraints, we have not discussed many other interesting training phenomena that may also be related to symmetry. In fact, parameter symmetries have been extensively studied by previous literature. Permutation symmetries are found to induce connected critical points for overparameterized networks ____ and lead to linear model connectivity ____. Rescaling symmetries can be used to explain the generalization of ReLU networks ____. Rotational symmetries can cause the dimensional collapse in self-supervised learning ____ and the low-rankness of attention layers ____.

%Symmetries also motivate the design of optimization methods. One line of research utilizes parameter symmetries to accelerate optimization ____, and other work discusses how to remove symmetries to improve the model ____.

%For examples, Ref.____ showed that both progressive sharpening ____ and flattening (which is required for warmup ____) may be due to symmetry.