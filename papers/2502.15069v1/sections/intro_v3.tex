

Rare diseases, often overlooked in the medical landscape, impact approximately 5.9\%  of the global population. For those affected, the journey to diagnosis is fraught with challenges, with an average wait of four to five years. Patients typically endure three misdiagnoses and consultations with at least five doctors during this process. This prolonged diagnostic odyssey is often due to limited provider knowledge, implicit biases, or symptom overlap with common conditions \cite{Kliegman17, Gao2021}. Only in a few instances does the absence of specific tests or the extreme rarity of the disease present the challenge.

Clinical decision support systems focusing on rare disease diagnoses emerged in the 1980s as a tool to address this challenge \citet{miller_internist-1_1982, mycin, barnett_dxplain:_1987, ExpertSystemsProbabilities, JacksonExpertSystems}. Practical use of these systems, however, has been constrained by several factors \cite{Miller94}, including lack of integration with physician workflows. Additionally, they are often custom-built explicitly for rare diseases and exclude common conditions.

Recent advances in large language models (LLMs; \citet{openai2024gpt4ocard, TheC3,grattafiori2024llama3herdmodels,jiang2023mistral}) achieve state-of-the-art performance on a variety of tasks \cite{zheng2023MT,wang2019super,hendrycksmeasuring}, including in high-stakes healthcare applications \cite{chen2023meditron70bscalingmedicalpretraining,thawakar-etal-2024-xraygpt,nair-etal-2024-dera}.  
Studies on rare disease diagnosis using LLMs show similar promise but have been on smaller, curated datasets of clinical vignettes that often include laboratory and imaging information to diagnose \cite{hu2023can,shyr2024identifying,sandmann2024systematic,chen2024rarebench,yang2024rdmaster,yang2024rdguru,mehnen2023chatgpt,shyr2024identifying,Olmo2024AssessingDD}.


Furthermore, the challenge with these studies is that 
the first point of contact for the patient is the primary care physician. For an untrained physician in rare diseases, the overlap of symptoms (\textit{e.g.}, \textit{pulmonary legionellosis} usually manifests with symptoms similar to flu or pneumonia)  makes it easy to overlook without specialized knowledge. While rare diagnoses often require additional information beyond the initial symptom presentation, they cannot be diagnosed if not considered in the first place.   This illustrates the criticality of including relevant rare diseases in the differential diagnosis, even before any lab work, directly based on patient-provider history-taking conversations. We found that applying black-box LLMs to the task of rare disease diagnosis shows only moderate performance (\textit{e.g.} 56.8\% Top-5 accuracy using gpt-4o).  This indicates that while LLMs have some knowledge of rare diseases, they also may struggle in certain cases.


In this paper, we improve the diagnostic capability of LLMs in identifying rare diseases based on two key insights. First, \textbf{given LLMs have some knowledge of rare diseases, can we more explicitly target this knowledge?}  Second, \textbf{can knowledge from rare expert systems be used to better evaluate and inform LLMs?}

We propose \methodname, which is designed to improve differential diagnoses of rare diseases directly from history-taking dialogues.  Figure \ref{fig:overview} provides an overview of our approach. 

We utilize a rare disease expert system and a medical case simulator to generate a broad set of structured clinical cases with closed-world assumptions within the expert system. These cases consist of structured findings, that a patient with the given rare disease may exhibit. These cases are then used as inputs to the history-taking conversation simulator that generates free-form provider questions and patient answers that conform to those cases. This approach covers 575 rare diseases, beginning with Abdominal Actinomycosis and ending with Wilson's Disease. 

Given that the expert system excludes common diseases, we develop a rare disease candidate generation model instead of a full diagnosis system. For each case, we generate a list of candidate rare diseases to prompt a larger, black-box LLM, which combines its general diagnostic capabilities with the specialized knowledge of the smaller model.

Our results show statistically significant performance improvements compared to relying solely on LLMs like GPT-4o.  For example, we find that the Top-5 accuracy improves from 56.7\% to 74.1\% on gpt-4o generated chats.  We believe this illustrates the potential of integrating curated expert knowledge sources and the power of LLMs.
