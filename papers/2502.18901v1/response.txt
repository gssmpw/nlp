\section{Related Work}
\label{sec:Related Work}
\subsection{Reinforcement Learning for Legged Locomotion}
Reinforcement learning has been extensively studied in robotic 
locomotion **Siekmann, A. P., "Sim-to-Real Transfer"**
For instance, **Loiacono, D., "RL-GUI: Rapid Generation of Policies for Robotic Tasks"** describes a setup that rapidly generates policies for robotic tasks using parallelism on a single GPU. Additionally, **Mnih, V., "Human-level control through deep reinforcement learning"** proposes an estimator that encodes environmental parameters through proprioceptive state histories.

While quadruped locomotion excels in navigating complex terrains, 
humanoid locomotion faces unique challenges due to 
higher degrees of freedom and the need for dynamic balance **Bengio, Y., "Guiding the Search for a Robust Controller for Walking"**
**Huang, Z., "Robust Controller Learning for Humanoid Robots via Multi-Task Optimization"** developed an RL-based humanoid 
locomotion framework using the Legged Gym platform.
 **Gu, S., "Robust and Agile Locomotion in Quadrupedal and Humanoid Robots"** created a framework 
for training robust controllers for walking, 
running, and jumping skills. 

\begin{figure}[t]
        \centering
        \includegraphics[width=0.48\textwidth]{figs/retargeting.pdf}
        \caption{ \small 
        Illustration of motion re-targeting from expert data (Left) to 
        our humanoid robot ``Noetix N1''(Right). 
        N1 weights 23 kg and is of height ass 0.95 m, with 18 DoFs in total (four on each arm and five on each leg).
        }
    % DoFs of a single arm & 4 \\
    % DoFs of a single leg & 5 \\%Remapping of Key Points between Human Motion Data and Real Robots.
        \label{fig:retarget}
        \vspace{-6mm}
\end{figure}

\subsection{Motion Imitation}
\tonghe{ 
% In robotic locomotion, adapting complex motion patterns enhances 
% robotic capabilities. 
}
Imitation Learning (IL) effectively tracks joint trajectories and extracts gait features but can struggle with discontinuities between locomotion patterns.
Generative Adversarial Imitation Learning (GAIL)**Tzeng, E., "Adversarial Generative Imitation Learning"** addresses these continuity challenges. 
Innovations like Adversarial Motion Priors (AMP) enhance the generation of realistic motions from unstructured datasets, 
avoiding manual motion design constraints. 
These advancements support agile movements in quadrupedal and humanoid robots using refined 
IL techniques **Liu, J., "Motion Prior-Aided Generative Adversarial Imitation Learning"**.

Building on these methodologies, our research proposes a framework that enhances robotic adaptability and performance in real-world environments.