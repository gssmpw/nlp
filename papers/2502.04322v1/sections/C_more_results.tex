\newpage
\section{Supplementary Results}
\label{app:supp_experiments}

In this section, we provide additional results on the performance of \speakeasy. 
Table~\ref{tab:quant_eval} presents the full evaluation results, which we use to create Figure~\ref{fig:quant_eval}. 

 \begin{table*}[h!]
    \centering
    \resizebox{\textwidth}{!}
    {
    \begin{tabular}{ll|cc|cc|cc|cc|cc}
    \toprule
        \textbf{Target} & \textbf{Jailbreak} & \multicolumn{2}{c|}{\textbf{\harmbench}} & \multicolumn{2}{c|}{\textbf{\advbench}} & \multicolumn{2}{c|}{\textbf{\sorrybench}} & \multicolumn{2}{c|}{\textbf{\medsafety}} & \multicolumn{2}{c}{\textbf{Average}}\\
         \textbf{LLM} & \textbf{Method} & \textbf{\asr} & \textbf{\harmscore} & \textbf{\asr} & \textbf{\harmscore} & \textbf{\asr} & \textbf{\harmscore} & \textbf{\asr} & \textbf{\harmscore} & \textbf{\asr} & \textbf{\harmscore} \\
    \midrule
    \midrule
        \multirow{6}{*}{\gptfouro} & \dr & 0.125 & 0.099 & 0.010 & 0.010 & 0.158 & 0.236 & 0.073 & 0.376 & 0.092 & 0.180 \\
        & $+$ \speakeasy & \textbf{0.560} & \textbf{0.779} & \textbf{0.682} & \textbf{0.724} & \textbf{0.604} & \textbf{0.793} & \textbf{0.373} & \textbf{0.740} & \textbf{0.555} & \textbf{0.759}\\
    \cmidrule{2-12}
        & \gcg & 0.095 & 0.105 & 0.010 & 0.017 & 0.178 & 0.198 & 0.058 & 0.301 & 0.085 & 0.155 \\
        & $+$ \speakeasy & \textbf{0.586} & \textbf{0.816} & \textbf{0.694} & \textbf{0.660} & \textbf{0.587} & \textbf{0.807} & \textbf{0.393} & \textbf{0.882} & \textbf{0.565} & \textbf{0.791} \\
    \cmidrule{2-12}
        & \tap & 0.575 & 0.402 & 0.946 & 0.558 & 0.678 & 0.509 & 0.529 & 0.608 & 0.682 & 0.519 \\
        & $+$ \speakeasy & \textbf{0.985} & \textbf{0.912} & \textbf{0.994} & \textbf{0.930} & \textbf{0.933} & \textbf{0.919} & \textbf{0.950} & \textbf{0.887} & \textbf{0.966} & \textbf{0.912}\\
    \midrule
        \multirow{6}{*}{\qwenabbr} & \dr & 0.005 & 0.002 & 0.006 & 0.008 & 0.138 & 0.185 & 0.058 & 0.321 & 0.052 & 0.129 \\
        & $+$ \speakeasy & \textbf{0.426} & \textbf{0.613} & \textbf{0.356} & \textbf{0.523} & \textbf{0.393} & \textbf{0.714} & \textbf{0.249} & \textbf{0.806} & \textbf{0.356} & \textbf{0.664}\\
    \cmidrule{2-12}
        & \gcg & 0.020 & 0.015 & 0.010 & 0.100 & 0.144 & 0.222 & 0.058 & 0.354 & 0.058 & 0.173\\
        & $+$ \speakeasy & \textbf{0.400} & \textbf{0.637} & \textbf{0.390} & \textbf{0.524} & \textbf{0.391} & \textbf{0.707} & \textbf{0.244} & \textbf{0.779} & \textbf{0.356} & \textbf{0.662}\\
    \cmidrule{2-12}
        & \tap & 0.435 & 0.343 & 0.627 & 0.573 & 0.536 & 0.457 & \textbf{0.778} & 0.520 & 0.594 & 0.473 \\
        & $+$ \speakeasy & \textbf{0.864} & \textbf{0.842} & \textbf{0.896} & \textbf{0.844} & \textbf{0.842} & \textbf{0.863} & 0.713 & \textbf{0.823} & \textbf{0.829} & \textbf{0.843} \\
    \midrule
        \multirow{6}{*}{\llamaseventyabbr} & \dr & 0.090 & 0.174 & 0.031 & 0.155 & 0.260 & 0.367 & 0.164 & 0.416 & 0.136 & 0.278 \\
        & $+$ \speakeasy & \textbf{0.365} & \textbf{0.559} & \textbf{0.465} & \textbf{0.454} & \textbf{0.413} & \textbf{0.654} & \textbf{0.204} & \textbf{0.751} & \textbf{0.362} & \textbf{0.605} \\
    \cmidrule{2-12}
        & \gcg & 0.100 & 0.280 & 0.110 & 0.386 & 0.264 & 0.370 & 0.144 & 0.346 & 0.155 & 0.346 \\
        & $+$ \speakeasy & \textbf{0.395} & \textbf{0.511} & \textbf{0.544} & \textbf{0.416} & \textbf{0.438} & \textbf{0.656} & \textbf{0.218} & \textbf{0.615} &\textbf{0.399} & \textbf{0.550} \\
    \cmidrule{2-12}
        & \tap & 0.580 & 0.403 & 0.806 & 0.549 & 0.502 & 0.289 & 0.549 & 0.392 & 0.609 & 0.408 \\
        & $+$ \speakeasy & \textbf{0.980} & \textbf{0.753} & \textbf{0.981} & \textbf{0.649} & \textbf{0.915} & \textbf{0.766} & \textbf{0.904} & \textbf{0.661} & \textbf{0.945} & \textbf{0.707} \\
    \bottomrule
    \end{tabular}}
    % \vspace{-3mm}
    \caption{Jailbreak performance measured by \asr and \harmscore before and after integrating \speakeasy into the baselines, with the higher scores in bold. \speakeasy significantly increases both \asr and \harmscore across almost all methods.} 
    \label{tab:quant_eval}
 \end{table*}

Table~\ref{tab:ablation_detail} presents detailed results from the ablation studies in \S\ref{sec:ablation_studies}, where we vary the number of query decomposition steps, number of languages, and response selection methods in \speakeasy. Here, we provide a breakdown of \harmscore into actionability and informativeness scores. Response Rate ($[0,1]$) measures the proportion of queries for which the model provides a non-refusal response. For the Fixed-Language selection method, which always selects responses from the same language, we report scores for all six languages.

\begin{table*}[h!]
    \centering
    \small
    \begin{tabular}{c|c|cc|c}
    \toprule
    \textbf{Ablation} & \textbf{Setting} & \textbf{Actionability} & \textbf{Informativeness} & \textbf{Response Rate} \\
    \midrule
    \midrule
    \multirow{3}{*}{\shortstack{Number of\\Steps}} & $1$ & $0.160$ & $0.156$ & $0.190$ \\
                              & $\textbf{3}$ & $0.736$ & $0.889$ & $0.985$ \\
                              & $5$ & $0.700$ & $0.810$ & $0.890$ \\
    \midrule
    \multirow{4}{*}{\shortstack{Number of\\Languages}} & $1$ & $0.466$ & $0.548$ & $0.610$ \\
                               & $3$ & $0.653$ & $0.777$ & $0.835$ \\
                               & $\textbf{6}$ & $0.736$ & $0.889$ & $0.985$ \\
                               & $9$ & $0.755$ & $0.840$ & $0.910$ \\
    \midrule    
    \multirow{4}{*}{\shortstack{Response\\Selection}} & Random & $0.667$ & $0.872$ & $0.985$ \\
                                 & Fixed-Comb.    & $0.676$ & $0.866$ & $0.975$ \\
                                 & Oracle        & $0.894$ & $0.979$ & $1.000$ \\
                                 & \textbf{Ours}& $0.736$ & $0.889$ & $0.985$ \\ 
                                 \midrule    
    \multirow{6}{*}{\shortstack{Response\\Selection\\(Fixed-Language)}} & English & $0.440$ & $0.569$ & $0.820$ \\
                                 & Chinese  & $0.425$ & $0.552$ & $0.820$ \\
                                 & Turkish   & $0.406$ & $0.588$ & $0.860$ \\
                                 & Ukrainian & $0.324$ & $0.516$ & $0.845$ \\ 
                                 & Thai  & $0.404$ & $0.567$ & $0.830$ \\ 
                                 & Zulu & $0.331$ & $0.492$ & $0.885$ \\ 
    \bottomrule
    \end{tabular}
    \caption{Jailbreak performance of ablated \speakeasy settings. 
    The default setting uses 3 steps, 6 languages, and our fine-tuned response selection models (bolded). 
    In general, \asr and \harmscore increase with decomposition steps and languages, with the number of steps having a greater impact. 
    The fixed-best response selection method underperforms, highlighting the need for flexibility, while the oracleâ€™s high scores suggest areas for improvement.
    }
    \label{tab:ablation_detail}
\end{table*}


In Figure~\ref{fig:lang_select}, we show language selection rates for settings where responses are chosen from $n=3$ and $n=9$ languages.
We observe that English is consistently the most selected language across all settings, and higher-resource languages tend to be chosen more frequently than lower-resource ones.
We hypothesize that this is due to higher response quality in high-resource languages, leading the response selection model to favor them.

\begin{figure}[h!]
    \centering
    \includegraphics[width=\columnwidth]{images/sel_rates_ablation.pdf}
    \caption{Language selection rates for $n=3$ and $n=9$.
    Each color theme represents a language resource level.
    We observe that selection rates correlate with language resource levels, with high-resource languages being chosen more frequently than lower-resource ones across all settings.}
    \label{fig:lang_select}
\end{figure}