\begin{figure}[t]
    \centering  
    \includegraphics[width=0.48\textwidth]{images/human_eval_process.pdf}
    \vspace{-18pt}
    \caption{Process flow of human evaluation to identify attributes contributing to jailbreak harmfulness. We collect and curate $10$ harmful base examples that meet all four attributes and augment each response into $16$ variants with different attribute combinations using \gptfour. Human annotators then assess each variant for the four attributes and the overall harm level.}
    \label{fig:human_eval_process}
    \vspace{-3mm}
\end{figure}

\vspace{-2mm}
\section{What Constitutes a Harmful Jailbreak?} \label{sec:human_eval}
\vspace{-1mm}

Existing evaluation metrics predominantly score jailbreak responses with explicit measures of success, such as \asr \citep{mazeikaharmbench, jailbroken}.
However, relying solely on success rates may lead to misalignments with human judgment \citep{souly2024strongreject}.
This gap raises the need for more precise measurements that better align with human perceptions, particularly in terms of how useful the jailbroken responses are for malicious actors.
We first identify four attributes that relate to characterizing the harmfulness of a jailbreak response by drawing from red-teaming and computational linguistics literature:
\begin{itemize}[itemsep=0pt, topsep=0pt, partopsep=0pt]
    \item \textbf{Actionability} measures if a response has clear steps, specific action verbs, and objects that assist a user in carrying out harmful actions \citep{ganguli2022red}. 
    \item \textbf{Coherence} measures if a response is logically connected \citep{cho2019towards} and contains consistent information \citep{malkin2022coherence} such that a malicious user can easily understand the response.
    \item \textbf{Conciseness} measures how effectively information is communicated maximally in terms of response length \citep{renze2024benefits}.
    \item \textbf{Informativeness} measures if the response provides relevant, meaningful details, such as explaining specific terms and clarifying the impact of an action \citep{xing2017topic, ke2018generating}.\footnote{Following \citet{mazeikaharmbench}, we prioritize the relevance of the provided information over the correctness of the content.}
\end{itemize}
We include examples for each of the four attributes in \S\ref{app:definitions}.
To identify the relationship between the four attributes and the harmfulness of a jailbreak response, we conduct human evaluation using a synthetic test set.
We describe the procedure in \S\ref{sec:human_evaluation_jailbreak_attributes} below.

\vspace{-1mm}
\subsection{Human Evaluation on Jailbreak Attributes}
\label{sec:human_evaluation_jailbreak_attributes}
\vspace{-0.5mm}
To construct the synthetic test set, we first curate 10 high-quality jailbreak query-response pairs from the \harmbench validation set. 
As each of the four attributes can either be present or absent, we collect $16$ unique combinations for a given query-response pair. 
We augment the original response to incorporate specific combinations of attribute settings by prompting \gptfour and generate a total of $160$ pairs.
Given the augmented pairs, we recruit $20$ annotators to evaluate two factors: (1) the efficacy of \gptfour's augmentations by whether annotators can identify the applied attribute combinations, and (2) the harmfulness of the augmented responses.
We illustrate the evaluation process in Figure~\ref{fig:human_eval_process} with additional details in \S\ref{app:augmentation}.

We include our results in Table~\ref{tab:attributes_human}.
First, we conduct a $\chi^2$ test to demonstrate that the augmented responses exhibit statistically significant correlations with human judgements for all four attributes, confirming the efficacy of the augmentations by \gptfour.
We also observe Fleiss' $\kappa > 0$ for all four attributes, indicating strong inter-annotator agreement. 
Then, we use Lasso regression to investigate which attributes most influence the harmfulness of jailbreak responses.
The learned coefficients demonstrate that informativeness exhibits the greatest impact on harmfulness followed by actionability, while coherence and conciseness show less influence. 
Hence, we focus on measuring actionability and informativeness by proposing a new metric, which we cover in \S\ref{sec:jailbreak_evaluation_harmscore} below.

\begin{table}[t]
    \centering
    \small
    \begin{tabular}{l|ccc}
        \toprule
        \textbf{Attribute} & $\boldsymbol{\chi^2}$ \textbf{Test} & \textbf{Fleiss'} $\boldsymbol{\kappa}$ & \textbf{Lasso Coef.} \\
        \midrule
        \midrule
        Actionability & $38.63^*$ & $0.56$ & $0.11$ \\
        Informativeness & $41.79^*$ & $0.48$ & $0.45$ \\
        Coherence & $38.41^*$ & $0.41$ & $0.01$ \\  
        Conciseness & $25.70^*$ & $0.21$ & $0.00$ \\
        \bottomrule
    \end{tabular}
    \vspace{-3pt}
    \caption{Human evaluation of the relationship between jailbreak harmfulness and four identified attributes.
    The $^*$ symbol indicates $p\text{-value} < 0.001$ from the $\chi^2$ test, confirming \gptfour's adherence to augmentation instructions. 
    Fleiss' $\kappa > 0$ shows strong inter-annotator agreement, and Lasso regression highlights actionability and informativeness as key factors in jailbreak harmfulness.}
    \label{tab:attributes_human}
    \vspace{-7pt}
\end{table}


\vspace{-1mm}
\subsection{Jailbreak Evaluation with \harmscore} \label{sec:jailbreak_evaluation_harmscore}
\vspace{-0.5mm}
Now, we consider measuring harmfulness through the lens of actionability and informativeness through our metric termed \harmscore. 
First, note that a harmful response should be both actionable and informative: An actionable response with poor informativeness may include irrelevant instructions, while an informative but unactionable response may only provide information without guiding actions.
We can realize this notion via the geometric mean of a jailbreak response's actionability and informativeness scores.

Concretely, given a malicious query $Q$, a jailbreak response $R$, and metrics $f_A(Q,R)\in[0,1]$ and $f_I(Q,R)\in[0,1]$ which respectively score the actionability and informativeness of $R$ in response to $Q$, we define \harmscore as:
\begin{equation*}
    \resizebox{\hsize}{!}{$
    \textsc{HarmScore}(Q,R) = \mathbbm{1}[R \cap \mathcal{S} \neq \emptyset] \cdot \sqrt{f_A(Q,R) \cdot f_I(Q,R)},
    $}
\end{equation*}
where the indicator function determines whether $R$ contains any predefined refusal strings $\mathcal{S}$ \citep{tap, zou2023universal, mazeikaharmbench}.
In words, if the response $R$ does not refuse to engage with the malicious query $Q$, we assess the harmfulness of $R$ by computing the geometric mean of its actionability and informativeness scores.

