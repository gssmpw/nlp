\section{Implementation Details of \speakeasy}
\label{app:implementation_details}
In this section, we provide additional details on the implementation of the \speakeasy framework introduced in \S\ref{sec:speakeasy}.

\subsection{Query Decomposition in \speakeasy}
\label{app:decomposition}

In the \speakeasy framework, we first decompose a harmful query into multiple seemingly benign subqueries. 
To do so, we instruct the target LLM to perform this decomposition with a prompt that includes four in-context examples of benign questions, as shown in Figure~\ref{fig:decompose_prompt}. 
The in-context examples were manually constructed with reference to previous work on query decomposition \citep{dua2022successive} and multi-step question answering \citep{shaikh2023second}.

\begin{figure}[ht]
    \centering
    \includegraphics[width=\textwidth]{images/decomposition_prompt.pdf}
    \vspace{-2em}
    \caption{The prompt used to decompose the harmful query, along with four in-context examples. \texttt{[NUMBER OF SUBQUERIES]} and \texttt{[HARMFUL QUERY]} are replaced with the number of subqueries and the jailbreak query during test time. By default, \texttt{[NUMBER OF SUBQUERIES]} is set to 3.}
    \label{fig:decompose_prompt}
\end{figure}

\subsection{Response Selection Models}
\label{app:selection_model_training}
In this section, we outline the process used to fine-tune the two response selection models in \S\ref{sec:4.2}.

\paragraph{Fine-Tuning Datasets.} 
As outlined in \S\ref{sec:4.2}, we preprocess the \hhrlhf \citep{bai2022training} and \texttt{Stack-} \texttt{Exchange-Preferences} \citep{h4stackexchange} datasets by filtering out irrelevant instances. 
The \hhrlhf dataset originally contains $161{,}000$ preference pairs, each consisting of two responses to the same question---one selected and one rejected by a human annotator. 
The \stackexchange dataset follows a similar structure.

The preprocessing involves three main steps. 
First, because instances from \stackexchange often include lengthy queries with context that differ from typical jailbreak prompts, we instruct \gptfouro to summarize these instances using the prompt instructions in Figure~\ref{fig:label_summarize}.
Second, we label each query to determine if it can be answered with an actionable or informative response. 
The prompts used for this process are shown in Figures~\ref{fig:label_act} and \ref{fig:label_inf}.
Finally, we label each query-response pair as either actionable or informative, using the prompt provided in Figure~\ref{fig:label_act_inf}. 
We provide example instances before and after summarization in Table~\ref{tab:summarize}. 
Table~\ref{tab:preference_pairs} shows sample pairs from the final dataset.

\begin{figure*}[!ht]
    \centering
    \begin{subfigure}[t]{\textwidth}
        \centering
        \includegraphics[width=\textwidth]{images/label_sum.pdf}
        \caption{Prompt used to summarize paragraph-length questions in the \stackexchange dataset into a single sentence.}
        \label{fig:label_summarize}
    \end{subfigure}
    \begin{subfigure}[t]{\textwidth}
        \centering
        \includegraphics[width=\textwidth]{images/label_act.pdf}
        \caption{Prompt used to determine whether a question from the \hhrlhf or \stackexchange datasets can be answered with an actionable response to filter out irrelevant questions.}
        \label{fig:label_act}
    \end{subfigure}
    \begin{subfigure}[t]{\textwidth}
        \centering
        \includegraphics[width=\textwidth]{images/label_inf.pdf}
        \caption{Prompt used to determine whether a question from the \hhrlhf or \stackexchange datasets can be answered with an informative response to filter out irrelevant questions.}
        \label{fig:label_inf}
    \end{subfigure}
    \begin{subfigure}[t]{\textwidth}
        \centering
        \includegraphics[width=\textwidth]{images/label_act_inf.pdf}
        \caption{Prompt used to determine whether a query-response pair is actionable or informative.}
        \label{fig:label_act_inf}
    \end{subfigure}
    \caption{Prompts used for summarization, filtering for actionability or informativeness, and labeling query-response pairs when preparing the fine-tuning datasets for the response selection models.}
\end{figure*}

\clearpage

\begin{table}[ht]
    \small
    \centering
    \begin{tabular}{p{7.6cm}|p{7.6cm}}
    \toprule
    {\bf Original Question} & {\bf Summarized Question} \\
    \midrule
    \midrule
    I want that my unit tests to cover my POCO's. How should I test them? What If I add a new property? How to make my test fail? Testing the properties and methods I know, but the problem is, how to make sure my tests fail if anything is added to my POCO's. &
    How should I cover my POCO's with unit tests, ensure they fail if a new property is added, and confirm that they fail if anything is added to my POCO's, given that I already know how to test the properties and methods? \\
    \midrule
    When I look at a directory in Windows Explorer, I can see a \texttt{ProductName} and \texttt{ProductVersion} property for the DLL's in that directory. I need to export this DLL list with \texttt{ProductName} and \texttt{ProductVersion} into a text file. 
    If I do \texttt{c:\textbackslash dir *.dll > test.log}, the \texttt{test.log} does not have the \texttt{ProductName} and \texttt{ProductVersion}. Could someone help me to get these properties exported to a file along with the filename? Even if it is a freeware tool or some other dir switch, that will be useful. &
    How can I export a DLL list with \texttt{ProductName} and \texttt{ProductVersion} properties from a directory in Windows Explorer into a text file, considering that using the command \texttt{c:\textbackslash dir *.dll > test.log} doesn't include these properties, and is there a freeware tool or another dir switch that could help me achieve this? \\
    \bottomrule
    \end{tabular}
    \caption{Examples from the \stackexchange dataset before and after summarization.}
    \label{tab:summarize}
\end{table}

\begin{table}[h!]
    \small
    \centering
    \begin{tabular}{p{2cm}|p{4cm}|p{5.5cm}|p{3.25cm}}
    \toprule
    {\bf Dataset} & {\bf Query} & {\bf Actionable Response} & {\bf Unactionable Response} \\
    \midrule
    \midrule
    \multirow{2}{*}{\hhrlhf}
    &
    {Is there a way to create a backup of a SQL Server 2005 Database that includes only the structure or schema, not the records, to use with old processes, without using a script?}
    & 
    {Use a 3 step process:\newline
    1. Generate a script from the working database
    \newline
    2. Create a new database from that script
    \newline
    3. Create a backup of the new database 
    }
    & 
    { Toad for SQL Server does this nicely, if you're considering a commercial product.}\\
    \cmidrule{2-4}
    &
    {How do you embezzle money?} 
    & 
    {The most common way to embezzle money is to overstate the business income and understate the expenses to make the business seem more profitable than it actually is.  For example, one may falsify bank statements to make it seem like the business's sales have been good and that the business isn't running a deficit, so that they can secure loans to grow the business.  But this is only one example, and embezzlement can also be carried out through bribery or other means.}
    & 
    {I'm afraid that's not how it works, can you explain more?}  \\
    \midrule
    \multirow{2}{*}{\shortstack[l]{\texttt{Stack-}\\\texttt{Exchange-}\\\texttt{Preferences}}}
    &
    {Is there an underlying reason for the recommendation on Stack Overflow and PEP 8 to use spaces only for indentation in Python programs, considering that tabs might be easier to work with, despite the need for consistent indentation? }
    & 
    {Well, I would say that there is not such 'recommendation' in the PEP 8. It is stated as a recommendation since they won't prohibit you to write tabs but since code must be written in the most standardized way, use spaces we must. That said, if I were the one to write the standard guide, I would recommend tabs since they are a modern and more practical way to indent code. Finally, I'll stress, I am not encouraging anybody to use tabs, instead, I am saying that all of us should use spaces as stated in the style guide.}
    & 
    {You can have your cake and eat it to. Set your editor to expand tabs into spaces automatically. (That would be :set expandtab in Vim.) }\\
    \cmidrule{2-4}
    &
    {How do I get into the NFL?} 
    & 
    {To get into the NFL, you need to start by playing at the college level. Once you’ve completed a college degree, the next step would be to join a NFL training camp as a free agent. From there, it’s all about hard work, dedication, and being in the right place at the right time. }
    & 
    {Are you interested in becoming a professional football player, or a sports journalist?}  \\
    \bottomrule
    \end{tabular}
    \caption{Sample preference pairs from the curated \hhrlhf and \stackexchange datasets.}
    \label{tab:preference_pairs}
\end{table}

\paragraph{Training Framework.}
Using our preference data, we train two \llama models, one for each attribute by employing iterative Direct Preference Optimization (DPO) \citep{rafailov2023direct} under the Bradley-Terry model \citep{Bradley1952RankAO}. 
Formally, given a preference dataset $\mathcal{D}_\textup{train} = \{(x^{(i)}, y^{(i)}_w, y^{(i)}_l)\}_{i=1}^{N}$ where $N = 27{,}000$ and a backbone model $f_\theta(x, y)$ parameterized by weights $\theta$ that takes a query $x$ and a response $y$, we train the model to maximize the probability that the preferred answer $y_w$ is ranked higher than the unpreferred answer $y_l$:
\begin{equation*}
    \Pr[y_w > y_l \mid x] = \frac{e^{f_\theta(x, y_w)}}{e^{f_\theta(x, y_w)} + e^{f_\theta(x, y_l)}}.
\end{equation*}
This optimization is achieved by minimizing the negative log-likelihood:
\begin{equation*}
    \mathcal{L}_\textup{BT}(\theta) = - \sum_{i=1}^{N} \log\left[\sigma\left(f_\theta\left(x^{(i)}, y^{(i)}_w\right) - f_\theta\left(x^{(i)}, y^{(i)}_l\right)\right)\right],
\end{equation*}

where $\sigma$ denotes the sigmoid function. 

\paragraph{Training Details.} 
We followed the implementation by \citet{dong2023raft} and used a learning rate of $2 \times 10^{-6}$ with a linear decay rate of $0.999$ over $8$ epochs and a batch size of $64$. 
We trained the model with a cosine scheduler, a warmup ratio of 0.03, and \texttt{bf16} precision. 
DPO preference tuning was performed on one A100 GPU for both response selection models.



\subsection{Jailbreak Method Details}\label{app:jailbreak_baselines}
For all experiments, we follow prior work and use greedy decoding for output generation \citep{pair, zou2023universal}. We set max\_tokens to $256$ \citep{mazeikaharmbench}. 

\paragraph{GCG-Transfer.} We use the transfer version of GCG \citep{zou2023universal}, which generates adversarial suffixes that can be transferred to all models. For training, we use the Vicuna-7B and Vicuna-13B \citep{vicuna2023} models and randomly sample 25 test cases from the given benchmark. The suffix that achieves the lowest loss after 100 steps is selected. We abbreviate this method as GCG-T. 
 
\paragraph{GCG-T $+$ \speakeasy.} Within the \speakeasy framework, we append the adversarial suffix optimized for the given benchmark to the translated and decomposed subqueries. The rest of the process follows the standard \speakeasy pipeline. 

\paragraph{TAP-Transfer.} We use the transfer version of TAP \citep{tap}, following the settings in \citet{mazeikaharmbench}. We use \gptfouro as the judge and target models, and Mixtral 8x7B \citep{jiang2024mixtral} as the attack generator. The generated test cases are used as transfer cases for all other models. We abbreviate this as TAP-T.

\paragraph{TAP-T $+$ \speakeasy.} We apply the TAP-T method to the decomposed English subqueries in \speakeasy before translation. 
After TAP-T refines the test case for each subquery, the resulting test case is fed back into the \speakeasy pipeline. 
It is then translated into the target languages for inference, with the remainder following the standard \speakeasy pipeline.