@article{An2024,
	author = {An, Qiang and Yeh, Chunmao and Lu, Yaobing and He, Yaomin and Yang, Jian},
	doi = {10.1109/TAES.2024.3379315},
	journal = {IEEE Transactions on Aerospace and Electronic Systems},
	keywords = {Scattering;Radar;Wideband;Direction-of-arrival estimation;Signal to noise ratio;Mathematical models;Aerospace and electronic systems;Sum-and-difference beams;monopulse radar;long-time coherent integration;angle migration;time-varying angle estimation},
	pages = {1-19},
	title = {{Time-Varying Angle Estimation of Multiple Unresolved Extended Targets via Monopulse Radar}},
	year = {2024},
	bdsk-url-1 = {https://doi.org/10.1109/TAES.2024.3379315}}

@inproceedings{Danelljan2016,
	author = {Danelljan, Martin and Robinson, Andreas and Shahbaz Khan, Fahad and Felsberg, Michael},
	booktitle = {Computer Vision--ECCV 2016: 14th European Conference, Amsterdam, The Netherlands, October 11-14, 2016, Proceedings, Part V 14},
	organization = {Springer},
	pages = {472--488},
	title = {{Beyond correlation filters: Learning continuous convolution operators for visual tracking}},
	year = {2016}}

@Misc{FAA2023,
  author       = {{Federal Aviation Administration}},
  howpublished = {Federal Aviation Administration (FAA)},
  note         = {Available online: \url{https://www.faa.gov/uas/getting_started/remote_id}},
  title        = {Remote Identification of Drones},
  year         = {2023},
}

@inproceedings{He2023,
	author = {He, Min and Fang, Xin and Huang, Darong and Zhang, Zhenyuan},
	booktitle = {2023 38th Youth Academic Annual Conference of Chinese Association of Automation (YAC)},
	doi = {10.1109/YAC59482.2023.10401638},
	keywords = {Target tracking;Radar cross-sections;Trajectory tracking;MIMO radar;Simulation;Radar tracking;Signal to noise ratio;2D MIMO radar;low-observable target;micro-UAV tracking;keystone transform;track-before-detect},
	pages = {809-813},
	title = {{A Hybrid Integration Method for Low-Observable Micro-UAV Trajectory Tracking by 2D MIMO Radar}},
	year = {2023},
	bdsk-url-1 = {https://doi.org/10.1109/YAC59482.2023.10401638}}

@article{Jin2024,
	author = {Jin, Woo-Cheol and Kim, Kyungtae and Choi, Ji-Woong},
	doi = {10.1109/TVT.2023.3320176},
	journal = {IEEE Transactions on Vehicular Technology},
	keywords = {Jamming;Autonomous aerial vehicles;Radar;Radar antennas;Radar detection;Spaceborne radar;Array signal processing;Anti-UAV system;jamming;radar;beamforming;beam misalignment},
	number = {2},
	pages = {2320-2331},
	title = {{Adaptive Beam Control Considering Location Inaccuracy for Anti-UAV Systems}},
	volume = {73},
	year = {2024},
	bdsk-url-1 = {https://doi.org/10.1109/TVT.2023.3320176}}

@inproceedings{Jurn2021,
	author = {Jurn, Yaseen N. and Mahmood, Sawsen A. and Aldhaibani, Jaafar A.},
	booktitle = {2021 11th IEEE International Conference on Control System, Computing and Engineering (ICCSCE)},
	doi = {10.1109/ICCSCE52189.2021.9530992},
	keywords = {Location awareness;System performance;Radar detection;Radar;Radar tracking;Sensor systems;Robustness;anti-drone system;anti-drone techniques;drone detection;drone identification;UAV tracking. radar system;non-radar system},
	pages = {114-119},
	title = {{Anti-Drone System Based Different Technologies: Architecture, Threats and Challenges}},
	year = {2021},
	bdsk-url-1 = {https://doi.org/10.1109/ICCSCE52189.2021.9530992}}

@inproceedings{KianiGaloogahi2017,
	author = {Kiani Galoogahi, Hamed and Fagg, Ashton and Lucey, Simon},
	booktitle = {Proceedings of the IEEE international conference on computer vision},
	pages = {1135--1143},
	title = {{Learning background-aware correlation filters for visual tracking}},
	year = {2017}}

@article{Lee2023,
	author = {Lee, Hunje and Han, Sujeong and Byeon, Jeong-Il and Han, Seoulgyu and Myung, Rangun and Joung, Jingon and Choi, Jihoon},
	doi = {10.1109/ACCESS.2023.3293124},
	journal = {IEEE Access},
	keywords = {Drones;Radar;Laser radar;Sensor fusion;Radar detection;Airborne radar;Radar cross-sections;UAV detection;UAV classification;sensor fusion;convolutional neural network (CNN);multinomial logistic regression},
	pages = {68791-68808},
	title = {{CNN-Based UAV Detection and Classification Using Sensor Fusion}},
	volume = {11},
	year = {2023},
	bdsk-url-1 = {https://doi.org/10.1109/ACCESS.2023.3293124}}

@article{Li2022,
	abstract = {Unmanned Aerial Vehicle (UAV) technology is being increasingly used in a wide variety of applications ranging from remote sensing, to delivery and security. As the number of UAVs increases, there is a growing need for UAV to UAV detection and tracking systems for both collision avoidance and coordination. Among possible solutions, autonomous ``see-and-avoid'' systems based on low-cost high-resolution video cameras offer important advantages in terms of light weight and low power consumption. However, in order to be effective, camera based ``see-and-avoid'' systems require sensitive, robust, and computationally efficient algorithms for autonomous detection and tracking of UAVs from a moving camera. In this article, we propose a general architecture for a highly accurate and computationally efficient UAV to UAV detection and tracking (U2U-D&T) algorithm from a camera mounted on a moving UAV platform. The system is based on a computationally efficient pipeline consisting of a moving target detector, followed by a target tracker. The algorithm is validated using video data collected from multiple fixed-wing UAVs that is manually ground-truthed and is publicly available. Results indicate that the proposed algorithm can be implemented on commodity hardware and robustly achieves highly accurate detection and tracking of even distant and faint UAVs. Open source code for the U2U-D&T algorithm is available at: https://github.com/jingliinpurdue/Fast-and-Robust-UAV-to-UAV-Detection-and-Tracking.git.},
	author = {Li, Jing and Ye, Dong Hye and Kolsch, Mathias and Wachs, Juan P. and Bouman, Charles A.},
	doi = {10.1109/TETC.2021.3104555},
	journal = {IEEE Transactions on Emerging Topics in Computing},
	keywords = {Target tracking;Cameras;Detectors;Unmanned aerial vehicles;Optical imaging;Radar tracking;Optical detectors;UAV tracking;sense-and-avoid;temporal detection;collision avoidance},
	number = {3},
	pages = {1519-1531},
	title = {{Fast and Robust UAV to UAV Detection and Tracking From Video}},
	volume = {10},
	year = {2022},
	bdsk-url-1 = {https://doi.org/10.1109/TETC.2021.3104555}}

@article{Li2023,
	author = {Li, Jiachun and Zhang, Weijiong and Meng, Yan and Li, Shaofeng and Ma, Lichuan and Liu, Zhen and Zhu, Haojin},
	doi = {10.1109/TVT.2023.3253894},
	journal = {IEEE Transactions on Vehicular Technology},
	keywords = {Autonomous aerial vehicles;Space-air-ground integrated networks;Security;Routing;Quality of service;Satellites;Probabilistic logic;Space-air-ground integrated network;message spoofing;misbehavior attack;UAV tracking},
	number = {8},
	pages = {10682-10695},
	title = {{Secure and Efficient UAV Tracking in Space-Air-Ground Integrated Network}},
	volume = {72},
	year = {2023},
	bdsk-url-1 = {https://doi.org/10.1109/TVT.2023.3253894}}

@article{Li2023a,
	abstract = {With the high computation efficiency and tracking accuracy, discriminative correlation filters (DCFs) have been applied to unmanned aerial vehicle (UAV) tracking. However, in the scenarios (i.e., complex background and temporary occlusion), DCF-based trackers usually generate low credibility response under the influence of background distractors, which contains multiple side peaks and declines the tracking performance. Motivated by the response consistency in adjacent frames and background information penalization, we propose learning a response interference suppression (RIS) CF to tackle this problem. Specifically, we introduce an RIS regularization into the DCF-based framework, which aims to keep the target area response consistent in adjacent frames and repress distractors' response in the background. Besides, we adopt a response auxiliary strategy (RAS) to smooth the target response, which intends to obtain the precise location and avoid target drift. Furthermore, extensive experiments on three UAV benchmarks demonstrate the excellent performance of the proposed method against other 19 state-of-the-art trackers. Moreover, the tracking speed of the proposed method can reach âˆ¼ 42 frames/s (FPS) on a single CPU.},
	author = {Li, Yan and Zhang, Hong and Yang, Yifan and Liu, Hanyang and Yuan, Ding},
	doi = {10.1109/LGRS.2023.3273906},
	journal = {IEEE Geoscience and Remote Sensing Letters},
	keywords = {Target tracking;Correlation;Interference suppression;Feature extraction;Autonomous aerial vehicles;Benchmark testing;Training;Discriminative correlation filter (DCF);object tracking;response interference suppression (RIS);unmanned aerial vehicle (UAV)},
	pages = {1-5},
	title = {{RISTrack: Learning Response Interference Suppression Correlation Filters for UAV Tracking}},
	volume = {20},
	year = {2023},
	bdsk-url-1 = {https://doi.org/10.1109/LGRS.2023.3273906}}

@article{Park2021,
	author = {Park, Seongjoon and Kim, Hyeong Tae and Lee, Sangmin and Joo, Hyeontae and Kim, Hwangnam},
	doi = {10.1109/ACCESS.2021.3065926},
	journal = {IEEE Access},
	keywords = {Drones;Terrorism;Jamming;Airports;Safety;Radar;Military aircraft;Anti-drone;counter-drone;drone detection;drone identification;drone neutralization},
	pages = {42635-42659},
	title = {{Survey on Anti-Drone Systems: Components, Designs, and Challenges}},
	volume = {9},
	year = {2021},
	bdsk-url-1 = {https://doi.org/10.1109/ACCESS.2021.3065926}}

@inproceedings{Sadovskis2022,
	author = {Sadovskis, Jurijs and Aboltins, Arturs},
	booktitle = {2022 IEEE 63th International Scientific Conference on Power and Electrical Engineering of Riga Technical University (RTUCON)},
	doi = {10.1109/RTUCON56726.2022.9978860},
	keywords = {Location awareness;Electrical engineering;Visualization;Radar detection;Autonomous aerial vehicles;Radar tracking;Airports;drones;aircraft;reconnaissance;surveillance;monitoring;protection;object detection;computer vision;sensor arrays;rf signals;radar detection},
	pages = {1-7},
	title = {Modern methods for {UAV} detection, classification, and tracking},
	year = {2022},
	bdsk-url-1 = {https://doi.org/10.1109/RTUCON56726.2022.9978860}}

@article{Tedeschi2024,
	author = {Tedeschi, Pietro and Al Nuaimi, Fatima Ali and Awad, Ali Ismail and Natalizio, Enrico},
	doi = {10.1109/TII.2023.3280325},
	journal = {IEEE Transactions on Industrial Informatics},
	keywords = {Autonomous aerial vehicles;Privacy;Drones;Standards;Wireless fidelity;Regulation;Security;Anonymity;privacy;remote ID;security;unmanned aerial vehicles (UAVs)},
	number = {2},
	pages = {1069-1080},
	title = {{Privacy-Aware Remote Identification for Unmanned Aerial Vehicles: Current Solutions, Potential Threats, and Future Directions}},
	volume = {20},
	year = {2024},
	bdsk-url-1 = {https://doi.org/10.1109/TII.2023.3280325}}

@article{You2023,
	author = {You, Jiang and Ye, Zixun and Gu, Jingliang and Pu, Juntao},
	doi = {10.1109/ACCESS.2023.3333394},
	journal = {IEEE Access},
	keywords = {Target tracking;Drones;Radar tracking;Feature extraction;Autonomous aerial vehicles;Convolutional neural networks;Task analysis;Real-time systems;Autonomous aerial vehicles;UAV pose detection;real-time tracking;maneuvering target;UAV countermeasures},
	pages = {129144-129155},
	title = {{UAV-Pose: A Dual Capture Network Algorithm for Low Altitude UAV Attitude Detection and Tracking}},
	volume = {11},
	year = {2023},
	bdsk-url-1 = {https://doi.org/10.1109/ACCESS.2023.3333394}}

@article{Zhang2023,
	author = {Zhang, Yunzuo and Wu, Cunyu and Zhang, Tian and Liu, Yameng and Zheng, Yuxin},
	doi = {10.1109/LGRS.2023.3265995},
	journal = {IEEE Geoscience and Remote Sensing Letters},
	keywords = {Feature extraction;Object detection;Convolution;Autonomous aerial vehicles;Head;Geoscience and remote sensing;Training;Multiscale feature fusion;object detection;self-attention;unmanned aerial vehicle (UAV) image},
	pages = {1-5},
	title = {{Self-Attention Guidance and Multiscale Feature Fusion-Based UAV Image Object Detection}},
	volume = {20},
	year = {2023},
	bdsk-url-1 = {https://doi.org/10.1109/LGRS.2023.3265995}}

