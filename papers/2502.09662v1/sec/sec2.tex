\subsection*{Large-scale multi-center cervical data collection and annotation}\label{subsec2-1}

\begin{figure*}[htbp]
    \centering
    \includegraphics[width=\linewidth]{fig/F2_v8.pdf}%
    \caption{\textbf{Overview of CCS-127K data and annotations in this study.} \textbf{a}. Class-wise distribution of 127,471 WSIs collected from 48 medical centers, including 124118 samples from 45 retrospective centers and 3,353 samples from 3 prospective centers. Note: RCM represents the centers merged due to limited sample size for each center. \textbf{b}. Abnormal cell annotation statistics: 104,979 abnormal lesion cells were annotated into 6 categories, ASC-US, LSIL, ASC-H, HSIL, SCC, and AGC, termed as CCS-Cell dataset. \textbf{c}. Designed flowchart of the study for the development and validation of the proposed Smart-CCS system. The orange flow represents retrospective studies, while the blue flow represents prospective studies.}
    \label{F2_data}
\end{figure*}
% \clearpage
To develop and validate the Smart-CCS system for generalizable cancer screening, we curated the large-scale and multi-center dataset, named CCS-127K. As illustrated in Fig. \ref{F2_data}(a), we collected a total of 127,471 cytology WSIs from 48 centers. These WSIs were obtained from 128,423 specimens after slide preparation, scanning, and quality control. Details of these processes are elaborated in the Methods section. According to the TBS guidelines \cite{nayar2015bethesda}, cytologists provided slide-level and cell-level annotations. The slide-level labels contained seven major cytology grades including negative for intraepithelial lesion or malignancy (NILM), atypical squamous cells of undetermined significance (ASC-US), low–grade squamous intraepithelial lesion (LSIL), atypical squamous cells cannot exclude an HSIL (ASC-H), high–grade squamous intraepithelial lesions (HSIL), squamous cell carcinoma (SCC), and atypical glandular cells (AGC). In total, cytologists annotated 69,940 retrospective WSIs from 45 centers and 3,353 prospective WSIs from 3 centers.
For cell-level annotations, cytologists delineated regions of interest (RoIs) and annotated abnormal cells using bounding boxes. As shown in Fig. \ref{F2_data}(b), they identified a total of 104,979 abnormal cells from 13 retrospective centers, spanning six abnormal cell types: ASC-US, LSIL, ASC-H, HSIL, SCC, and AGC, named as CCS-Cell dataset. More abbreviations are detailed in Extended Data Table \ref{ST_abb}.

Building on this large and diverse dataset, we designed a structured workflow, illustrated in Fig. \ref{F2_data}(c), that incorporates both retrospective and prospective cohorts. The retrospective cohort was used for model development and evaluation, and it was further divided into three subsets: pretraining, finetuning, and testing. The pretraining cohort, consisting of 112,062 slides from 39 centers, was used for self-supervised learning to initialize the CCS model. This was followed by the finetuning cohort, which included 49,063 labeled slides from 27 centers, to train the model for WSI classification task. For testing, the model was evaluated on a testing cohort divided into two datasets: an internal test dataset with 11,722 slides from 11 centers and an external test dataset with 9,155 samples from 6 independent centers.  Additionally, a prospective cohort of 3,353 slides from three centers was used to evaluate the clinical effectiveness in real-world scenarios. Finally, we collected the 738 corresponding histology diagnoses, which serve as the ground truth to evaluate the cancer diagnosis capability of the Smart-CCS system.

\subsection*{Overview of proposed Smart-CCS system}\label{subsec2-2}
As shown in Extended Data Fig. \ref{SF_method}, we developed a thorough AI-assisted CCS paradigm called Smart-CCS, consisting of three sequential stages: 1) large-scale self-supervised pretraining, 2) CCS model finetuning, and 3) test-time adaptation.

The framework of Smart-CCS is illustrated in Fig. \ref{F3_method}. In the pretraining stage, the curated cytology dataset CCS-127K was fully leveraged and exploited in a self-supervised learning manner \cite{oquabdinov2}. Thus, our Smart-CCS could effectively capture and represent inherent and generalizable cytological knowledge such as cellular instance features (cytoplasm, nucleus), semantic features (morphology), and global information (distribution).
In the finetuning stage, the pretrained models were further specialized to CCS tasks under both slide-level and cell-level supervision. Specifically, we followed the two-step CCS scheme involving two models: an abnormal cell detector and a WSI classifier. The detector identified suspicious cells across the entire slide, while the classifier aggregated these cell candidates to generate the final slide classification results. During the adaptation stage, the WSI classification model was optimized to handle unseen samples before making predictions. This approach could enhance the adaptability and generalizability of the Smart-CCS system, enabling it to perform effectively under diverse and complex screening conditions.

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\begin{figure*}[t]
    \centering
    \includegraphics[width=1.0\linewidth]{fig/F3_v8.pdf}
    \caption{\textbf{Overview of the Smart-CCS Paradigm.} The Smart-CCS paradigm consists of three sequential stages. \textbf{a.} the \textbf{pretraining stage}, which involves large-scale self-supervised pretraining on diverse cytology images from various centers to build a generalizable feature extraction model. \textbf{b.} the \textbf{finetuning stage}, which specializes the pretrained model for cancer screening tasks, including two components: an abnormal cell detector for identifying abnormal cells and a WSI classifier for slide-level  predictions. \textbf{c.} the \textbf{adaptation stage}, which further optimizes trained model for diverse clinical settings via adapting and refining predictions.
    }
    \label{F3_method}
\end{figure*}

\subsection*{Self-supervised pretraining for cervical cancer screening}\label{subsec2-3}
Large-scale self-supervised pretraining empowers the model with strong generalization capability by yielding robust and off-the-shelf representation in computational cytology. 
In this study, we first investigated the effectiveness of self-supervised pretraining for two crucial tasks in CCS, namely cell-level and WSI-level classification. 

In cell-level tasks, we utilized two public datasets, HErlev \cite{jantzen2005pap} and SIPaKMeD \cite{plissiti2018sipakmed}, along with our collected CCS-Cell dataset to evaluate cell classification performance. We first evaluated scaling law of self-supervised pretraining, the results are illustrated in Fig. \ref{FE1}(a). Overall, the reported cell classification results indicate that pretraining can benefit downstream tasks across all three datasets. Specifically, pretraining using 1 million (M) cytology images yielded top-1 accuracy gains of 4.5\% on HErlev, 1\% on SIPaKMeD, and 3.5\% on CCS-Cell. As scaling pretraining data, classification performance improved steadily and continuously, with increases of 7.2\%, 3.4\%, and 5.6\%, respectively. Ultimately, three datasets reached top-1 accuracies of 0.914 (95\% CI: 0.873–0.955), 0.960 (95\% CI: 0.946–0.974), and 0.883 (95\% CI: 0.868–0.898) when pretrained using 100M cytology patches. 
 To further illustrate the effectiveness, we used t-SNE to visualize cell features with and without pretraining in Extended Data Fig. \ref{SF_tsne}. These visualizations reveal the enhanced feature aggregation capability after pretraining, where cell features are tightly clustered within each category and well-separated from neighboring categories. This aggregation capability potentially addresses category ambiguity issues in classifying cytology grades \cite{jiang2024holistic}.

In WSI-level tasks, we included three retrospective centers consisting of 25,571 WSIs from CCS-127K to investigate the impact of pretraining and investigate the scaling law. We gradually scaled up the pretraining data from 0 to 100M. Shown in Fig. \ref{FE1}(b), the results demonstrated the significant efficacy of pretraining, evidenced by its application in cancer screening through the detection of epithelial cell abnormalities (denoted as ECA), as well as in fine-grained cytology WSI classification tasks (denoted as ALL). As the pretraining data increased, the experimental results steadily improved, showing an overall accuracy increase of 10.34\% in cancer screening and 8.61\% in fine-grained cytology classification, reaching up to 100M data. Ultimately, the three centers achieved 0.950 (95\%CI: 0.942 - 0.959), 0.915 (95\%CI: 0.902-0.929) and 0.958 (95\%CI: 0.946-0.970) accuracies for cancer screening. Details regarding cell and WSI classification are provided in Extended Data Tables. \ref{ST_pretrain_cell}-\ref{ST_pretrain_wsi}.

 Additionally, ablation experiments were conducted on pretraining backbones (ViT-Large, ViT-Gaint) and algorithms (DINOv2 \cite{oquabdinov2}, MoCov3 \cite{chen2021empirical}). Based on the results, we employed the ViT-Large architecture pretrained with DINOv2 using 100 million pretraining data in the following experiments. More experimental results are provided in Extended Data Table. \ref{ST_pretrain_ablation}. 

\subsection*{Retrospective evaluation of abnormal cell detection}\label{subsec2-4}
\begin{figure*}[htbp]
    \centering
    \includegraphics[width=\linewidth]{fig/FE1_v4.pdf}
    \caption{\textbf{Performance of Smart-CCS in retrospective study.} \textbf{a.} Evaluation of cell-level cytology task using cell classification datasets,  SIPaKMeD ($N$ = 4,049), HErlev ($N$ = 918), and CCS-Cell ($N$ = 9,008). \textbf{b.} Evaluation of the WSI-level cytology task using retrospective cervical cytology datasets ($N$ = 5,189, 11,986, 8,396) to assess cancer screening (ECA) and fine-grained classification (ALL) performances. \textbf{c.} Comparison of abnormal cell detection performance among DDETR, DETR, RetinaNet, Faster R-CNN and YOLOv3 on CCS-Cell dataset. \textbf{d.} The external testing performances are evaluated by metric AUC with different settings, Base denotes the typical two-step CCS model, w/ P is introducing pretraining, w/ P\&A refers to our proposed Smart-CCS with pretraining and adaptation. \textbf{e.} Internal and external data distribution, along with the results of cervical cancer screening evaluations.}
    \label{FE1}
\end{figure*}
Abnormal cell detection typically serves as the prerequisite for AI-assisted CCS, where abnormal cells with high confidence scores are identified from the whole slide as candidates and then aggregated for slide-level classification. Thus, we aim to build a strong cell detector to screen out all abnormal and suspicious cells within each WSI. 
As shown in Fig. \ref{FE1}(c), we compared several state-of-the-art (SOTA) detectors used in previous CCS studies, including Faster R-CNN \cite{ren2015faster}, YOLOv3 \cite{zhu2021hybrid,wei2021efficient}, RetinaNet \cite{wang2024artificial}, transformer-based detector DETR \cite{carion2020end}, and its deformable variant DDETR \cite{zhu2020deformable}. 
The experimental results showed that DDETR achieved the best performance and was selected as the detector in Smart-CCS. DDETR surpassed YOLOv3, Faster R-CNN, and RetinaNet by 14.3\%, 5.9\%, and 7.3\% in AP50 (Average Precision with an IoU threshold of 0.50), respectively, benefiting from the powerful visual representation capability of the transformer and the adaptability of deformable attention to multi-resolution \cite{zhu2020deformable}.
The per-class detection results showed that DDETR not only addressed the issue of missed detections for tiny objects, such as SCC (naked nuclei and small nucleoli), achieving a 10.3\% AP50 increase compared to YOLOv3, but also enhanced the detection of morphologically diverse atypical cells. Specifically, it achieved a +13.1\% AP50 improvement in ASC-US and a +8.5\% AP50 improvement in ASC-H (Extended Data Table \ref{ST_det}-\ref{ST_det_p2}). Subsequently, the cell classification performance was evaluated using a confusion matrix, shown in Extended Data Fig. \ref{SF_det}. From this matrix, we observed a clear distinction in the model's ability to identify glandular cells (class AGC) compared to other squamous cell abnormalities. This is attributed to the distinct morphological abnormalities and unique arrangement characteristics of glandular cells. We also found a strong correlation between ASC-US and LSIL, as well as between ASC-H and HSIL, which aligns with clinical practice \cite{nayar2015bethesda,vandenbussche2022cytologic}. Overall, our detector outperforms previous work in differentiating fine-grained cell categories, which serves as the first step in WSI classification model for cancer screening.

\subsection*{Internal testing for multi-center evaluation}\label{subsec2-5}
In the retrospective study, a total of 112,062 cervical cytology samples from pretraining and finetuning cohorts were included for the Smart-CCS system development. Then, internal testing included 11,722 samples from 11 centers for multi-center evaluation of the developed Smart-CCS (Fig. \ref{FE1}(e)). The positive rates among these centers range from 5.48\% 
 to 49.26\% with different grades of epithelial abnormalities.

The quantitative performances in testing centers are presented in Fig. \ref{FE1}(e). 
Overall, Smart-CCS achieved an overall of 0.965 (95\% CI: 0.961–0.969) AUC, 0.965 (95\% CI: 0.961–0.969) accuracy, 0.913 (95\% CI: 0.907–0.919) sensitivity, and  0.896 (95\% CI: 0.889–0.902) specificity on internal testing centers. Specifically, 9 centers achieved AUC metrics greater than  95\% among the 11 internal testing centers, such as 0.971 (95\% CI 0.965–0.978) in RC2, 0.990 (95\% CI: 0.985–0.995) in RC3, 0.985 (95\% CI: 0.977–0.992) in RC5, and 0.971 (95\% CI: 0.960–0.982) in RC7. We also found that centers with a low positive rate, such as RC1, often showed lower classification accuracies. Besides, the system screening capabilities are highly determined by accurately detecting early-stage intraepithelial abnormalities from a large number of samples, as indicated by the metric, sensitivity. Smart-CCS achieved a high overall sensitivity of 0.913 (95\% CI: 0.907–0.919), with 9 internal centers demonstrating sensitivities greater than 85\%, indicating strong screening capabilities.

In terms of different cytology grades, ASC-US+, considered as the squamous cell abnormality, Smart-CCS exhibited high classification capability with an overall AUC of 0.961 (95\% CI: 0.957–0.965) and a sensitivity of 0.910 (95\% CI: 0.904–0.916). Then, the critical cytology group LSIL+, to be considered for further colposcopy, maintained advanced screening performance of 0.958 (95\% CI: 0.953–0.962) AUC with 0.910 (95\% CI: 0.903–0.916) sensitivity. Especially in RC1, the challenging center with a quite low positive rate (5.48\%), Smart-CCS increased from 0.767 (95\% CI: 0.750–0.784) in ECA to 0.902 (95\% CI: 0.890–0.914) in LSIL+, demonstrating the effect of ASC-US, the ambiguous category \cite{jiang2024holistic, nayar2015bethesda}. The HSIL+ group typically refers to malignant neoplasia, with superior classification results ranging from 0.918 (95\% CI: 0.904–0.931) to 0.994 (95\% CI: 0.987–1.001) in AUC within internal testing centers. Furthermore, we also reported the F1 score metric to assess the model stability under class imbalance. Smart-CCS achieved favorable F1 scores of 0.903 (95\% CI: 0.896–0.909), 0.897 (95\% CI: 0.890–0.903), 0.891 (95\% CI: 0.884–0.897), and 0.950 (95\% CI: 0.945–0.955) in subgroups ECA, ASC-US+, LSIL+, and HSIL+. More result details are appended in Extended Data Tables. \ref{ST_wsi}-\ref{ST_wsi_3}.

\subsection*{External testing for generalizability evaluation}\label{subsec2-5}
The cytology samples collected from different centers present diverse and large variations, which brings challenges for system generalizability. Under the proposed Smart-CCS paradigm, the pretrained model could extract general and strong cytology features that are domain-invariant across diverse clinical centers.  To evaluate the effectiveness and generalizability of developed Smart-CCS, we retrospectively included 9,155 cytology WSIs from six independent centers (RC8-RC13).

In the external testing, the positive rates among six centers ranged from 8.81\% (RC8) to 52.65\% (RC12), resulting in an overall rate of 23.89\%. The results are shown in Fig. \ref{FE1}(e), where we obtained an overall screening performance of 0.912 (95\% CI: 0.906–0.918) accuracy, 0.950 (95\% CI: 0.945–0.954) AUC, and 0.854 (95\% CI: 0.847–0.861) sensitivity. Specifically, Smart-CCS achieved consistent and favorable classification results ranging from 0.880 (95\% CI: 0.859–0.901) to 0.963 (95\% CI: 0.954–0.972) AUC across six external centers.
The external testing performance reveals the strong generalization capabilities of Smart-CCS.

To further investigate the efficacy of the proposed pretraining and adaptation strategies in Smart-CCS, we conducted ablation studies comparing three experimental groups: a two-step CCS model (denoted as Base), CCS with pretraining (denoted as w/ P), and our Smart-CCS with both pretraining and adaptation (denoted as w/ P\&A). As illustrated in Fig. \ref{FE1}(d), we report the area under the receiver operating characteristic curve (AUC) for cancer screening across different centers, as well as the overall performance. Compared to the CCS baseline model, pretraining consistently increased the AUC, from 0.897 (95\% CI: 0.877–0.918) to 0.930 (95\% CI: 0.913–0.948) in RC9, and from 0.830 (95\% CI: 0.805–0.855) to 0.911 (95\% CI: 0.892–0.930) in RC10, among others. Furthermore, when both pretraining and adaptation were applied, Smart-CCS achieved a 6.3\% AUC improvement against the CCS baseline model. The demonstrated effectiveness of the Smart-CCS paradigm in external testing underscores its potential clinical applicability in complex scenarios. Additional details regarding the ablation studies can be found in Extended Data Table \ref{ST_ext}. Moreover, we compared classifiers, including MeanMIL, MaxMIL, ABMIL \cite{ilse2018attention}, DSMIL \cite{li2021dual}, CLAM \cite{shao2021transmil}, TransMIL \cite{lu2021data}, and S4MIL \cite{fillioux2023structured}, in terms of internal and external testing performance, as shown in Extended Data Table \ref{ST_clas}.

\subsection*{Prospective study for clinical validation}\label{subsec2-6}
Between January 1 2024 and July 31, 2024, we recruited a total of 3,353 participants from three prospective centers, PC1, PC2 and PC3 to form the prospective cohort. 
As shown in Fig. \ref{FE2}(a), three prospective centers individually contributed 998, 1,311, and 1,044 samples, with positive rates of 43.24\%, 26.32\%, and 28.35\%. Besides, we also obtained 185, 258, and 295 corresponding histological diagnosis results as the gold standard for further system evaluation.

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\begin{figure*}[htbp]
    \centering
    \includegraphics[width=1.0\linewidth]{fig/FE2_v5.pdf}
    \caption{\textbf{Performance of Smart-CCS in the prospective study.} \textbf{a}. Grade distribution among three prospective centers (PC1, PC2 and PC3) and reported evaluation results from our Smart-CCS system. \textbf{b}. The diagnostic performance of Smart-CCS in cancer detection using histological results as the gold standard. \textbf{c}. Visualizations from cervical cancer screenings, which include interpretable results at both the cell-level and slide-level, derived from three sample tests.}
    \label{FE2}
\end{figure*}

Overall, the evaluation results of Smart-CCS for cancer screening demonstrated consistent generalization capabilities in prospective centers, as shown in Fig. \ref{FE2}(a) and Extended Data Table. \ref{ST_pros}. Specifically, Smart-CCS achieved accuracies of  0.877 (95\% CI: 0.856–0.897), 0.862 (95\% CI: 0.843–0.881), and 0.950 (95\% CI: 0.937–0.963) across three prospective centers, with high sensitivities of 0.893 (95\% CI: 0.874–0.912), 0.881 (95\% CI: 0.864–0.899), and 0.946 (95\% CI: 0.932–0.960). The high AUC scores ranging from 0.924 (95\% CI: 0.910–0.938) to 0.986 (95\% CI: 0.979–0.993) also reveal the robust and strong cancer screening capability of Smart-CCS system in clinical scenarios.

To further validate Smart-CCS for cervical cancer diagnosis, we utilized histological biopsy results as the gold standard \cite{ouh2021discrepancy}. Histology provides a more confirmative diagnosis through direct tissue examination compared to the individual cell analysis of cytology, making it a reliable benchmark for assessing the accuracy of the cytology-based Smart-CCS. The overall and different grades (i.e., CIN1, CIN2, CIN3) results are presented in Fig. \ref{FE2}(b). Overall, Smart-CCS obtained a sensitivity of 0.943 (95\% CI 0.927-0.960) and an AUC of 0.902 (95\% CI 0.880-0.923) in cervical cancer diagnosis. Specifically, the three prospective centers reported sensitivities of 0.967 (95\% CI: 0.942–0.993), 0.992 (95\% CI: 0.981–1.000), 0.949 (95\% CI: 0.924–0.974), with corresponding AUCs of 0.984 (95\% CI: 0.965–1.000), 0.921(95\% CI: 0.888–0.954), and N/A due to the lack of negative samples in PC3. For histology-positive samples, Smart-CCS achieved an overall of 0.957 (95\% CI: 0.942–0.973) sensitivity in three centers. The high sensitivities can be observed across all groups, ranging from 0.935 (95\% CI: 0.902–0.968) to 1.000 (95\% CI: 1.000–1.000). We also provided the results of different histology grades, CIN1, CIN2, and CIN3. We found there were no missed samples in CIN1 and CIN3 in two centers (PC1, PC3). The CIN2 group achieved 0.971 (95\% CI: 0.943–0.999), 0.937 (95\% CI: 0.894–0.979) and 0.935 (95\% CI: 0.902–0.968) sensitivities.
Notably, Smart-CCS yielded sensitivities close to 1.00 for HSIL+ across all three prospective centers, demonstrating a high consistency between cancer screening and diagnosis on higher cytology grades. 
Therefore, generalizable cancer screening could potentially avoid unnecessary biopsies and colposcopies for patients at risk of cervical cancer. 

\subsection*{Interpretability analysis}
To support clinical practice, we illustrate the decision-making process of Smart-CCS in Fig. \ref{FE2}(c), providing interpretable insights from diverse perspectives.
 At the slide-level, Smart-CCS predicts positive scores for precancerous abnormalities based on cervical cytology specimens. It provides detailed prediction categories and scores for malignancy grade evaluation, which inform subsequent colposcopy and biopsy procedures. For instance, in Fig. \ref{FE2}(c), the left WSI sample achieves a confidence score of 0.9999 for the NILM category, while the middle sample yields a positive score of 0.9999, with a high-grade HSIL confidence of 0.9915. This indicates a high probability of cervical neoplasia and malignancy.

In the context of cell-level screening, suspicious cells are highlighted using distinct markers in each WSI. The visualization illustrates that these suspicious cells are randomly distributed across the WSIs due to the uniform mixing and centrifugation during specimen preparation \cite{jiang2023deep}. Furthermore, detected suspicious cells, along with confidence score statistics and characteristic morphologies, provide reliable clues for the final diagnosis. In the middle sample illustrated in Fig. \ref{FE2}(c), Smart-CCS detected a few  LSIL cells (i.e., koilocytotic cells with typical perinuclear halos) alongside a significant number of HSIL cells, which demonstrated markedly enlarged nuclei, reduced cytoplasmic areas, and hyperchromatic clustering. This predicted information aligns well with the ground truth for this sample, which is HSIL. Similarly, the AGC sample reveals a substantial presence of AGC cells arranged in a fence-like pattern, alongside other atypical cells, as shown in Fig. \ref{FE2}(c)(right). In the case of NILM, despite a slide-level prediction score of nearly 1.00, some cells exhibit deepening and enlargement of nuclei, presenting as non-neoplastic cellular variations or hard mimics \cite{nayar2015bethesda}. By integrating these insights within an interactive interface, we have developed Smart-CCS into a comprehensive system, as depicted in Extended Data Fig. \ref{SF_integrate}. This system aims to provide cytologists with interpretable AI-assisted results, ensuring reliable screening outcomes and guiding subsequent final diagnoses, thereby enhancing the overall diagnostic workflow.
