@article{frantar2022optimal,
  title={Optimal brain compression: A framework for accurate post-training quantization and pruning},
  author={Frantar, Elias and Alistarh, Dan},
  journal={Advances in Neural Information Processing Systems},
  volume={35},
  pages={4475--4488},
  year={2022}
}

@article{any_precision_dnn,
  title={Any-Precision Deep Neural Networks},
  author={Haichao Yu and Haoxiang Li and Humphrey Shi and Thomas S. Huang and Gang Hua},
  journal={ArXiv},
  year={2019},
  volume={abs/1911.07346},
  url={https://api.semanticscholar.org/CorpusID:208138922}
}

@inproceedings{wanda,
  author       = {Mingjie Sun and
                  Zhuang Liu and
                  Anna Bair and
                  J. Zico Kolter},
  title        = {A Simple and Effective Pruning Approach for Large Language Models},
  booktitle    = {The Twelfth International Conference on Learning Representations,
                  {ICLR} 2024, Vienna, Austria, May 7-11, 2024},
  publisher    = {OpenReview.net},
  year         = {2024},
  url          = {https://openreview.net/forum?id=PxoFut3dWW},
  timestamp    = {Wed, 07 Aug 2024 17:11:53 +0200},
  biburl       = {https://dblp.org/rec/conf/iclr/Sun0BK24.bib},
  bibsource    = {dblp computer science bibliography, https://dblp.org}
}

@article{frantar2022gptq,
  title={Gptq: Accurate post-training quantization for generative pre-trained transformers},
  author={Frantar, Elias and Ashkboos, Saleh and Hoefler, Torsten and Alistarh, Dan},
  journal={arXiv preprint arXiv:2210.17323},
  year={2022}
}

@article{dettmers2023spqr,
  title={Spqr: A sparse-quantized representation for near-lossless llm weight compression},
  author={Dettmers, Tim and Svirschevski, Ruslan and Egiazarian, Vage and Kuznedelev, Denis and Frantar, Elias and Ashkboos, Saleh and Borzunov, Alexander and Hoefler, Torsten and Alistarh, Dan},
  journal={arXiv preprint arXiv:2306.03078},
  year={2023}
}

@article{lee2023owq,
  title={Owq: Lessons learned from activation outliers for weight quantization in large language models},
  author={Lee, Changhun and Jin, Jungyu and Kim, Taesu and Kim, Hyungjun and Park, Eunhyeok},
  journal={arXiv preprint arXiv:2306.02272},
  year={2023}
}


@inproceedings{saliency,
  author       = {Jinyang Guo and
                  Jianyu Wu and
                  Zining Wang and
                  Jiaheng Liu and
                  Ge Yang and
                  Yifu Ding and
                  Ruihao Gong and
                  Haotong Qin and
                  Xianglong Liu},
  title        = {Compressing Large Language Models by Joint Sparsification and Quantization},
  booktitle    = {Forty-first International Conference on Machine Learning, {ICML} 2024,
                  Vienna, Austria, July 21-27, 2024},
  publisher    = {OpenReview.net},
  year         = {2024},
  url          = {https://openreview.net/forum?id=sCGRhnuMUJ},
  timestamp    = {Mon, 02 Sep 2024 16:55:27 +0200},
}


@inproceedings{squeezellm,
  author       = {Sehoon Kim and
                  Coleman Hooper and
                  Amir Gholami and
                  Zhen Dong and
                  Xiuyu Li and
                  Sheng Shen and
                  Michael W. Mahoney and
                  Kurt Keutzer},
  title        = {SqueezeLLM: Dense-and-Sparse Quantization},
  booktitle    = {Forty-first International Conference on Machine Learning, {ICML} 2024,
                  Vienna, Austria, July 21-27, 2024},
  publisher    = {OpenReview.net},
  year         = {2024},
  url          = {https://openreview.net/forum?id=0jpbpFia8m},
  timestamp    = {Mon, 02 Sep 2024 16:55:26 +0200},
  biburl       = {https://dblp.org/rec/conf/icml/KimHGDLSMK24.bib},
  bibsource    = {dblp computer science bibliography, https://dblp.org}
}

@article{DBLP:cdquant,
  author       = {Pranav Ajit Nair and
                  Arun Sai Suggala},
  title        = {CDQuant: Accurate Post-training Weight Quantization of Large Pre-trained
                  Models using Greedy Coordinate Descent},
  journal      = {CoRR},
  volume       = {abs/2406.17542},
  year         = {2024},
  url          = {https://doi.org/10.48550/arXiv.2406.17542},
  doi          = {10.48550/ARXIV.2406.17542},
  eprinttype    = {arXiv},
  eprint       = {2406.17542},
  timestamp    = {Mon, 22 Jul 2024 14:28:28 +0200},
  biburl       = {https://dblp.org/rec/journals/corr/abs-2406-17542.bib},
  bibsource    = {dblp computer science bibliography, https://dblp.org}
}


@inproceedings{apllm,
  author       = {Yeonhong Park and
                  Jake Hyun and
                  SangLyul Cho and
                  Bonggeun Sim and
                  Jae W. Lee},
  title        = {Any-Precision {LLM:} Low-Cost Deployment of Multiple, Different-Sized
                  LLMs},
  booktitle    = {Forty-first International Conference on Machine Learning, {ICML} 2024,
                  Vienna, Austria, July 21-27, 2024},
  publisher    = {OpenReview.net},
  year         = {2024},
  url          = {https://openreview.net/forum?id=u09gadH3BU},
  timestamp    = {Mon, 02 Sep 2024 16:55:25 +0200},
  biburl       = {https://dblp.org/rec/conf/icml/ParkHCSL24.bib},
  bibsource    = {dblp computer science bibliography, https://dblp.org}
}


@article{adepu2024framequant,
  title={FrameQuant: Flexible Low-Bit Quantization for Transformers},
  author={Adepu, Harshavardhan and Zeng, Zhanpeng and Zhang, Li and Singh, Vikas},
  journal={arXiv preprint arXiv:2403.06082},
  year={2024}
}

@article{chee2024quip,
  title={Quip: 2-bit quantization of large language models with guarantees},
  author={Chee, Jerry and Cai, Yaohui and Kuleshov, Volodymyr and De Sa, Christopher M},
  journal={Advances in Neural Information Processing Systems},
  volume={36},
  year={2024}
}


@article{ma2024affinequant,
  title={AffineQuant: Affine Transformation Quantization for Large Language Models},
  author={Ma, Yuexiao and Li, Huixia and Zheng, Xiawu and Ling, Feng and Xiao, Xuefeng and Wang, Rui and Wen, Shilei and Chao, Fei and Ji, Rongrong},
  journal={arXiv preprint arXiv:2403.12544},
  year={2024}
}


@article{spinquant,
  author       = {Zechun Liu and
                  Changsheng Zhao and
                  Igor Fedorov and
                  Bilge Soran and
                  Dhruv Choudhary and
                  Raghuraman Krishnamoorthi and
                  Vikas Chandra and
                  Yuandong Tian and
                  Tijmen Blankevoort},
  title        = {SpinQuant: {LLM} quantization with learned rotations},
  journal      = {CoRR},
  volume       = {abs/2405.16406},
  year         = {2024},
  url          = {https://doi.org/10.48550/arXiv.2405.16406},
  doi          = {10.48550/ARXIV.2405.16406},
  eprinttype    = {arXiv},
  eprint       = {2405.16406},
  timestamp    = {Tue, 18 Jun 2024 16:10:22 +0200},
  biburl       = {https://dblp.org/rec/journals/corr/abs-2405-16406.bib},
  bibsource    = {dblp computer science bibliography, https://dblp.org}
}

@article{quarot,
  author       = {Saleh Ashkboos and
                  Amirkeivan Mohtashami and
                  Maximilian L. Croci and
                  Bo Li and
                  Martin Jaggi and
                  Dan Alistarh and
                  Torsten Hoefler and
                  James Hensman},
  title        = {QuaRot: Outlier-Free 4-Bit Inference in Rotated LLMs},
  journal      = {CoRR},
  volume       = {abs/2404.00456},
  year         = {2024},
  url          = {https://doi.org/10.48550/arXiv.2404.00456},
  doi          = {10.48550/ARXIV.2404.00456},
  eprinttype    = {arXiv},
  eprint       = {2404.00456},
  timestamp    = {Wed, 08 May 2024 17:22:41 +0200},
  biburl       = {https://dblp.org/rec/journals/corr/abs-2404-00456.bib},
  bibsource    = {dblp computer science bibliography, https://dblp.org}
}


@article{lin2023awq,
  title={Awq: Activation-aware weight quantization for llm compression and acceleration},
  author={Lin, Ji and Tang, Jiaming and Tang, Haotian and Yang, Shang and Dang, Xingyu and Han, Song},
  journal={arXiv preprint arXiv:2306.00978},
  year={2023}
}


@article{behdin2023quantease,
  title={QuantEase: Optimization-based Quantization for Language Models},
  author={Behdin, Kayhan and Acharya, Ayan and Gupta, Aman and Song, Qingquan and Zhu, Siyu and Keerthi, Sathiya and Mazumder, Rahul},
  journal={arXiv preprint arXiv:2309.01885},
  year={2023}
}



@inproceedings{aqlm,
  author       = {Vage Egiazarian and
                  Andrei Panferov and
                  Denis Kuznedelev and
                  Elias Frantar and
                  Artem Babenko and
                  Dan Alistarh},
  title        = {Extreme Compression of Large Language Models via Additive Quantization},
  booktitle    = {Forty-first International Conference on Machine Learning, {ICML} 2024,
                  Vienna, Austria, July 21-27, 2024},
  publisher    = {OpenReview.net},
  year         = {2024},
  url          = {https://openreview.net/forum?id=5mCaITRTmO},
  timestamp    = {Mon, 02 Sep 2024 16:55:26 +0200},
  biburl       = {https://dblp.org/rec/conf/icml/EgiazarianPKFBA24.bib},
  bibsource    = {dblp computer science bibliography, https://dblp.org}
}

@inproceedings{quip_sharp,
  author       = {Albert Tseng and
                  Jerry Chee and
                  Qingyao Sun and
                  Volodymyr Kuleshov and
                  Christopher De Sa},
  title        = {QuIP{\#}: Even Better {LLM} Quantization with Hadamard Incoherence
                  and Lattice Codebooks},
  booktitle    = {Forty-first International Conference on Machine Learning, {ICML} 2024,
                  Vienna, Austria, July 21-27, 2024},
  publisher    = {OpenReview.net},
  year         = {2024},
  url          = {https://openreview.net/forum?id=9BrydUVcoe},
  timestamp    = {Mon, 02 Sep 2024 16:55:26 +0200},
  biburl       = {https://dblp.org/rec/conf/icml/TsengCSKS24.bib},
  bibsource    = {dblp computer science bibliography, https://dblp.org}
}


@inproceedings{xiao2023smoothquant,
  title={Smoothquant: Accurate and efficient post-training quantization for large language models},
  author={Xiao, Guangxuan and Lin, Ji and Seznec, Mickael and Wu, Hao and Demouth, Julien and Han, Song},
  booktitle={International Conference on Machine Learning},
  pages={38087--38099},
  year={2023},
  organization={PMLR}
}


@article{wei2022outlier,
  title={Outlier suppression: Pushing the limit of low-bit transformer language models},
  author={Wei, Xiuying and Zhang, Yunchen and Zhang, Xiangguo and Gong, Ruihao and Zhang, Shanghang and Zhang, Qi and Yu, Fengwei and Liu, Xianglong},
  journal={Advances in Neural Information Processing Systems},
  volume={35},
  pages={17402--17414},
  year={2022}
}

@article{wei2023outlier,
  title={Outlier suppression+: Accurate quantization of large language models by equivalent and optimal shifting and scaling},
  author={Wei, Xiuying and Zhang, Yunchen and Li, Yuhang and Zhang, Xiangguo and Gong, Ruihao and Guo, Jinyang and Liu, Xianglong},
  journal={arXiv preprint arXiv:2304.09145},
  year={2023}
}


@article{liu2023qllm,
  title={QLLM: Accurate and Efficient Low-Bitwidth Quantization for Large Language Models},
  author={Liu, Jing and Gong, Ruihao and Wei, Xiuying and Dong, Zhiwei and Cai, Jianfei and Zhuang, Bohan},
  journal={arXiv preprint arXiv:2310.08041},
  year={2023}
}

@article{kusupati2022matryoshka,
  title={Matryoshka representation learning},
  author={Kusupati, Aditya and Bhatt, Gantavya and Rege, Aniket and Wallingford, Matthew and Sinha, Aditya and Ramanujan, Vivek and Howard-Snyder, William and Chen, Kaifeng and Kakade, Sham and Jain, Prateek and others},
  journal={Advances in Neural Information Processing Systems},
  volume={35},
  pages={30233--30249},
  year={2022}
}

@inproceedings{rippel2014learning,
  title={Learning ordered representations with nested dropout},
  author={Rippel, Oren and Gelbart, Michael and Adams, Ryan},
  booktitle={International Conference on Machine Learning},
  pages={1746--1754},
  year={2014},
  organization={PMLR}
}

@article{yu2018slimmable,
  title={Slimmable neural networks},
  author={Yu, Jiahui and Yang, Linjie and Xu, Ning and Yang, Jianchao and Huang, Thomas},
  journal={arXiv preprint arXiv:1812.08928},
  year={2018}
}

@article{denton2015deep,
  title={Deep generative image models using a laplacian pyramid of adversarial networks},
  author={Denton, Emily L and Chintala, Soumith and Fergus, Rob and others},
  journal={Advances in neural information processing systems},
  volume={28},
  year={2015}
}

@article{devvrit2023matformer,
  title={Matformer: Nested transformer for elastic inference},
  author={Devvrit, F and Kudugunta, Sneha and Kusupati, Aditya and Dettmers, Tim and Chen, Kaifeng and Dhillon, Inderjit and Tsvetkov, Yulia and Hajishirzi, Hannaneh and Kakade, Sham and Farhadi, Ali and Jain, Prateek and others},
  journal={arXiv preprint arXiv:2310.07707},
  year={2023}
}

@article{dettmers2022gpt3,
  title={Gpt3. int8 (): 8-bit matrix multiplication for transformers at scale},
  author={Dettmers, Tim and Lewis, Mike and Belkada, Younes and Zettlemoyer, Luke},
  journal={Advances in Neural Information Processing Systems},
  volume={35},
  pages={30318--30332},
  year={2022}
}

@inproceedings{lin2017feature,
  title={Feature pyramid networks for object detection},
  author={Lin, Tsung-Yi and Doll{\'a}r, Piotr and Girshick, Ross and He, Kaiming and Hariharan, Bharath and Belongie, Serge},
  booktitle={Proceedings of the IEEE conference on computer vision and pattern recognition},
  pages={2117--2125},
  year={2017}
}

@article{adelson1984pyramid,
  title={Pyramid methods in image processing},
  author={Adelson, Edward H and Anderson, Charles H and Bergen, James R and Burt, Peter J and Ogden, Joan M},
  journal={RCA engineer},
  volume={29},
  number={6},
  pages={33--41},
  year={1984}
}

@inproceedings{abdolrashidi2021pareto,
  title={Pareto-optimal quantized resnet is mostly 4-bit},
  author={Abdolrashidi, AmirAli and Wang, Lisa and Agrawal, Shivani and Malmaud, Jonathan and Rybakov, Oleg and Leichner, Chas and Lew, Lukasz},
  booktitle={Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition},
  pages={3091--3099},
  year={2021}
}

@inproceedings{jacob2018quantization,
  title={Quantization and training of neural networks for efficient integer-arithmetic-only inference},
  author={Jacob, Benoit and Kligys, Skirmantas and Chen, Bo and Zhu, Menglong and Tang, Matthew and Howard, Andrew and Adam, Hartwig and Kalenichenko, Dmitry},
  booktitle={Proceedings of the IEEE conference on computer vision and pattern recognition},
  pages={2704--2713},
  year={2018}
}


@inproceedings{lqer,
  author       = {Cheng Zhang and
                  Jianyi Cheng and
                  George Anthony Constantinides and
                  Yiren Zhao},
  title        = {{LQER:} Low-Rank Quantization Error Reconstruction for LLMs},
  booktitle    = {Forty-first International Conference on Machine Learning, {ICML} 2024,
                  Vienna, Austria, July 21-27, 2024},
  publisher    = {OpenReview.net},
  year         = {2024},
  url          = {https://openreview.net/forum?id=dh8k41g775},
  timestamp    = {Mon, 02 Sep 2024 16:55:26 +0200},
  biburl       = {https://dblp.org/rec/conf/icml/ZhangCCZ24.bib},
  bibsource    = {dblp computer science bibliography, https://dblp.org}
}

  title={Qlora: Efficient finetuning of quantized llms},
  author={Dettmers, Tim and Pagnoni, Artidoro and Holtzman, Ari and Zettlemoyer, Luke},
  journal={Advances in Neural Information Processing Systems},
  volume={36},
  year={2024}
}



@article{chai2023int2,
  title={Int2. 1: Towards fine-tunable quantized large language models with error correction through low-rank adaptation},
  author={Chai, Yuji and Gkountouras, John and Ko, Glenn G and Brooks, David and Wei, Gu-Yeon},
  journal={arXiv preprint arXiv:2306.08162},
  year={2023}
}


@inproceedings{DBLP:llmqat,
  author       = {Zechun Liu and
                  Barlas Oguz and
                  Changsheng Zhao and
                  Ernie Chang and
                  Pierre Stock and
                  Yashar Mehdad and
                  Yangyang Shi and
                  Raghuraman Krishnamoorthi and
                  Vikas Chandra},
  editor       = {Lun{-}Wei Ku and
                  Andre Martins and
                  Vivek Srikumar},
  title        = {{LLM-QAT:} Data-Free Quantization Aware Training for Large Language
                  Models},
  booktitle    = {Findings of the Association for Computational Linguistics, {ACL} 2024,
                  Bangkok, Thailand and virtual meeting, August 11-16, 2024},
  pages        = {467--484},
  publisher    = {Association for Computational Linguistics},
  year         = {2024},
  url          = {https://doi.org/10.18653/v1/2024.findings-acl.26},
  doi          = {10.18653/V1/2024.FINDINGS-ACL.26},
  timestamp    = {Tue, 24 Sep 2024 10:55:38 +0200},
  biburl       = {https://dblp.org/rec/conf/acl/LiuO0CSMSKC24.bib},
  bibsource    = {dblp computer science bibliography, https://dblp.org}
}

@article{DBLP:efficientqat,
  author       = {Mengzhao Chen and
                  Wenqi Shao and
                  Peng Xu and
                  Jiahao Wang and
                  Peng Gao and
                  Kaipeng Zhang and
                  Yu Qiao and
                  Ping Luo},
  title        = {EfficientQAT: Efficient Quantization-Aware Training for Large Language
                  Models},
  journal      = {CoRR},
  volume       = {abs/2407.11062},
  year         = {2024},
  url          = {https://doi.org/10.48550/arXiv.2407.11062},
  doi          = {10.48550/ARXIV.2407.11062},
  eprinttype    = {arXiv},
  eprint       = {2407.11062},
  timestamp    = {Mon, 26 Aug 2024 07:38:53 +0200},
  biburl       = {https://dblp.org/rec/journals/corr/abs-2407-11062.bib},
  bibsource    = {dblp computer science bibliography, https://dblp.org}
}

@article{DBLP:158bit,
  author       = {Shuming Ma and
                  Hongyu Wang and
                  Lingxiao Ma and
                  Lei Wang and
                  Wenhui Wang and
                  Shaohan Huang and
                  Li Dong and
                  Ruiping Wang and
                  Jilong Xue and
                  Furu Wei},
  title        = {The Era of 1-bit LLMs: All Large Language Models are in 1.58 Bits},
  journal      = {CoRR},
  volume       = {abs/2402.17764},
  year         = {2024},
  url          = {https://doi.org/10.48550/arXiv.2402.17764},
  doi          = {10.48550/ARXIV.2402.17764},
  eprinttype    = {arXiv},
  eprint       = {2402.17764},
  timestamp    = {Fri, 19 Jul 2024 08:34:48 +0200},
  biburl       = {https://dblp.org/rec/journals/corr/abs-2402-17764.bib},
  bibsource    = {dblp computer science bibliography, https://dblp.org}
}

@article{DBLP:onebit,
  author       = {Yuzhuang Xu and
                  Xu Han and
                  Zonghan Yang and
                  Shuo Wang and
                  Qingfu Zhu and
                  Zhiyuan Liu and
                  Weidong Liu and
                  Wanxiang Che},
  title        = {OneBit: Towards Extremely Low-bit Large Language Models},
  journal      = {CoRR},
  volume       = {abs/2402.11295},
  year         = {2024},
  url          = {https://doi.org/10.48550/arXiv.2402.11295},
  doi          = {10.48550/ARXIV.2402.11295},
  eprinttype    = {arXiv},
  eprint       = {2402.11295},
  timestamp    = {Tue, 13 Aug 2024 07:52:12 +0200},
  biburl       = {https://dblp.org/rec/journals/corr/abs-2402-11295.bib},
  bibsource    = {dblp computer science bibliography, https://dblp.org}
}

@inproceedings{DBLP:BitDistiller,
  author       = {Dayou Du and
                  Yijia Zhang and
                  Shijie Cao and
                  Jiaqi Guo and
                  Ting Cao and
                  Xiaowen Chu and
                  Ningyi Xu},
  editor       = {Lun{-}Wei Ku and
                  Andre Martins and
                  Vivek Srikumar},
  title        = {BitDistiller: Unleashing the Potential of Sub-4-Bit LLMs via Self-Distillation},
  booktitle    = {Proceedings of the 62nd Annual Meeting of the Association for Computational
                  Linguistics (Volume 1: Long Papers), {ACL} 2024, Bangkok, Thailand,
                  August 11-16, 2024},
  pages        = {102--116},
  publisher    = {Association for Computational Linguistics},
  year         = {2024},
  url          = {https://doi.org/10.18653/v1/2024.acl-long.7},
  doi          = {10.18653/V1/2024.ACL-LONG.7},
  timestamp    = {Mon, 13 Jan 2025 16:16:40 +0100},
  biburl       = {https://dblp.org/rec/conf/acl/DuZCGCCX24.bib},
  bibsource    = {dblp computer science bibliography, https://dblp.org}
}


@article{Riviere2024Gemma2I,
  title={Gemma 2: Improving Open Language Models at a Practical Size},
  author={Gemma-Team},
  journal={ArXiv},
  year={2024},
  volume={abs/2408.00118},
  url={https://api.semanticscholar.org/CorpusID:270843326}
}

@article{DBLP:mistral,
  author       = {Albert Q. Jiang and
                  Alexandre Sablayrolles and
                  Arthur Mensch and
                  Chris Bamford and
                  Devendra Singh Chaplot and
                  Diego de Las Casas and
                  Florian Bressand and
                  Gianna Lengyel and
                  Guillaume Lample and
                  Lucile Saulnier and
                  L{\'{e}}lio Renard Lavaud and
                  Marie{-}Anne Lachaux and
                  Pierre Stock and
                  Teven Le Scao and
                  Thibaut Lavril and
                  Thomas Wang and
                  Timoth{\'{e}}e Lacroix and
                  William El Sayed},
  title        = {Mistral 7B},
  journal      = {CoRR},
  volume       = {abs/2310.06825},
  year         = {2023},
  url          = {https://doi.org/10.48550/arXiv.2310.06825},
  doi          = {10.48550/ARXIV.2310.06825},
  eprinttype    = {arXiv},
  eprint       = {2310.06825},
  timestamp    = {Thu, 26 Oct 2023 16:46:26 +0200},
  biburl       = {https://dblp.org/rec/journals/corr/abs-2310-06825.bib},
  bibsource    = {dblp computer science bibliography, https://dblp.org}
}

@inproceedings{DBLP:hellaswag,
  author       = {Rowan Zellers and
                  Ari Holtzman and
                  Yonatan Bisk and
                  Ali Farhadi and
                  Yejin Choi},
  editor       = {Anna Korhonen and
                  David R. Traum and
                  Llu{\'{\i}}s M{\`{a}}rquez},
  title        = {HellaSwag: Can a Machine Really Finish Your Sentence?},
  booktitle    = {Proceedings of the 57th Conference of the Association for Computational
                  Linguistics, {ACL} 2019, Florence, Italy, July 28- August 2, 2019,
                  Volume 1: Long Papers},
  pages        = {4791--4800},
  publisher    = {Association for Computational Linguistics},
  year         = {2019},
  url          = {https://doi.org/10.18653/v1/p19-1472},
  doi          = {10.18653/V1/P19-1472},
  timestamp    = {Sat, 29 Apr 2023 10:09:26 +0200},
  biburl       = {https://dblp.org/rec/conf/acl/ZellersHBFC19.bib},
  bibsource    = {dblp computer science bibliography, https://dblp.org}
}

@article{DBLP:arc,
  author       = {Peter Clark and
                  Isaac Cowhey and
                  Oren Etzioni and
                  Tushar Khot and
                  Ashish Sabharwal and
                  Carissa Schoenick and
                  Oyvind Tafjord},
  title        = {Think you have Solved Question Answering? Try ARC, the {AI2} Reasoning
                  Challenge},
  journal      = {CoRR},
  volume       = {abs/1803.05457},
  year         = {2018},
  url          = {http://arxiv.org/abs/1803.05457},
  eprinttype    = {arXiv},
  eprint       = {1803.05457},
  timestamp    = {Mon, 13 Aug 2018 16:48:43 +0200},
  biburl       = {https://dblp.org/rec/journals/corr/abs-1803-05457.bib},
  bibsource    = {dblp computer science bibliography, https://dblp.org}
}

@inproceedings{DBLP:piqa,
  author       = {Yonatan Bisk and
                  Rowan Zellers and
                  Ronan Le Bras and
                  Jianfeng Gao and
                  Yejin Choi},
  title        = {{PIQA:} Reasoning about Physical Commonsense in Natural Language},
  booktitle    = {The Thirty-Fourth {AAAI} Conference on Artificial Intelligence, {AAAI}
                  2020, The Thirty-Second Innovative Applications of Artificial Intelligence
                  Conference, {IAAI} 2020, The Tenth {AAAI} Symposium on Educational
                  Advances in Artificial Intelligence, {EAAI} 2020, New York, NY, USA,
                  February 7-12, 2020},
  pages        = {7432--7439},
  publisher    = {{AAAI} Press},
  year         = {2020},
  url          = {https://doi.org/10.1609/aaai.v34i05.6239},
  doi          = {10.1609/AAAI.V34I05.6239},
  timestamp    = {Thu, 11 Apr 2024 13:33:56 +0200},
  biburl       = {https://dblp.org/rec/conf/aaai/BiskZLGC20.bib},
  bibsource    = {dblp computer science bibliography, https://dblp.org}
}


@inproceedings{DBLP:winogrande,
  author       = {Keisuke Sakaguchi and
                  Ronan Le Bras and
                  Chandra Bhagavatula and
                  Yejin Choi},
  title        = {WinoGrande: An Adversarial Winograd Schema Challenge at Scale},
  booktitle    = {The Thirty-Fourth {AAAI} Conference on Artificial Intelligence, {AAAI}
                  2020, The Thirty-Second Innovative Applications of Artificial Intelligence
                  Conference, {IAAI} 2020, The Tenth {AAAI} Symposium on Educational
                  Advances in Artificial Intelligence, {EAAI} 2020, New York, NY, USA,
                  February 7-12, 2020},
  pages        = {8732--8740},
  publisher    = {{AAAI} Press},
  year         = {2020},
  url          = {https://doi.org/10.1609/aaai.v34i05.6399},
  doi          = {10.1609/AAAI.V34I05.6399},
  timestamp    = {Mon, 04 Sep 2023 16:50:27 +0200},
  biburl       = {https://dblp.org/rec/conf/aaai/SakaguchiBBC20.bib},
  bibsource    = {dblp computer science bibliography, https://dblp.org}
}


@inproceedings{DBLP:boolqa,
  author       = {Christopher Clark and
                  Kenton Lee and
                  Ming{-}Wei Chang and
                  Tom Kwiatkowski and
                  Michael Collins and
                  Kristina Toutanova},
  editor       = {Jill Burstein and
                  Christy Doran and
                  Thamar Solorio},
  title        = {BoolQ: Exploring the Surprising Difficulty of Natural Yes/No Questions},
  booktitle    = {Proceedings of the 2019 Conference of the North American Chapter of
                  the Association for Computational Linguistics: Human Language Technologies,
                  {NAACL-HLT} 2019, Minneapolis, MN, USA, June 2-7, 2019, Volume 1 (Long
                  and Short Papers)},
  pages        = {2924--2936},
  publisher    = {Association for Computational Linguistics},
  year         = {2019},
  url          = {https://doi.org/10.18653/v1/n19-1300},
  doi          = {10.18653/V1/N19-1300},
  timestamp    = {Tue, 16 Aug 2022 23:04:27 +0200},
  biburl       = {https://dblp.org/rec/conf/naacl/ClarkLCK0T19.bib},
  bibsource    = {dblp computer science bibliography, https://dblp.org}
}

@inproceedings{dettmers2023case,
  title={The case for 4-bit precision: k-bit inference scaling laws},
  author={Dettmers, Tim and Zettlemoyer, Luke},
  booktitle={International Conference on Machine Learning},
  pages={7750--7774},
  year={2023},
  organization={PMLR}
}

@article{raffel2020exploring,
  title={Exploring the limits of transfer learning with a unified text-to-text transformer},
  author={Raffel, Colin and Shazeer, Noam and Roberts, Adam and Lee, Katherine and Narang, Sharan and Matena, Michael and Zhou, Yanqi and Li, Wei and Liu, Peter J},
  journal={Journal of machine learning research},
  volume={21},
  number={140},
  pages={1--67},
  year={2020}
}

@article{shao2023omniquant,
  title={Omniquant: Omnidirectionally calibrated quantization for large language models},
  author={Shao, Wenqi and Chen, Mengzhao and Zhang, Zhaoyang and Xu, Peng and Zhao, Lirui and Li, Zhiqian and Zhang, Kaipeng and Gao, Peng and Qiao, Yu and Luo, Ping},
  journal={arXiv preprint arXiv:2308.13137},
  year={2023}
}

@inproceedings{vaswani2017attention,
  title={Attention is All you Need},
  author={Ashish Vaswani and Noam M. Shazeer and Niki Parmar and Jakob Uszkoreit and Llion Jones and Aidan N. Gomez and Lukasz Kaiser and Illia Polosukhin},
  booktitle={Neural Information Processing Systems},
  year={2017},
  url={https://api.semanticscholar.org/CorpusID:13756489}
}


@article{team2024gemini,
  title={Gemini 1.5: Unlocking multimodal understanding across millions of tokens of context},
  author={G Team, Gemini and Georgiev, Petko and Lei, Ving Ian and Burnell, Ryan and Bai, Libin and Gulati, Anmol and Tanzer, Garrett and Vincent, Damien and Pan, Zhufeng and Wang, Shibo and others},
  journal={arXiv preprint arXiv:2403.05530},
  year={2024}
}

@article{achiam2023gpt,
  title={Gpt-4 technical report},
  author={Achiam, Josh and Adler, Steven and Agarwal, Sandhini and Ahmad, Lama and Akkaya, Ilge and Aleman, Florencia Leoni and Almeida, Diogo and Altenschmidt, Janko and Altman, Sam and Anadkat, Shyamal and others},
  journal={arXiv preprint arXiv:2303.08774},
  year={2023}
}

@article{bengio2013estimating,
  title={Estimating or propagating gradients through stochastic neurons for conditional computation},
  author={Bengio, Yoshua and L{\'e}onard, Nicholas and Courville, Aaron},
  journal={arXiv preprint arXiv:1308.3432},
  year={2013}
}

@article{dubey2024llama,
  title={The llama 3 herd of models},
  author={Dubey, Abhimanyu and Jauhri, Abhinav and Pandey, Abhinav and Kadian, Abhishek and Al-Dahle, Ahmad and Letman, Aiesha and Mathur, Akhil and Schelten, Alan and Yang, Amy and Fan, Angela and others},
  journal={arXiv preprint arXiv:2407.21783},
  year={2024}
}

