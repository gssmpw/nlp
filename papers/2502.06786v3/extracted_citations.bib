@inproceedings{DBLP:BitDistiller,
  author       = {Dayou Du and
                  Yijia Zhang and
                  Shijie Cao and
                  Jiaqi Guo and
                  Ting Cao and
                  Xiaowen Chu and
                  Ningyi Xu},
  editor       = {Lun{-}Wei Ku and
                  Andre Martins and
                  Vivek Srikumar},
  title        = {BitDistiller: Unleashing the Potential of Sub-4-Bit LLMs via Self-Distillation},
  booktitle    = {Proceedings of the 62nd Annual Meeting of the Association for Computational
                  Linguistics (Volume 1: Long Papers), {ACL} 2024, Bangkok, Thailand,
                  August 11-16, 2024},
  pages        = {102--116},
  publisher    = {Association for Computational Linguistics},
  year         = {2024},
  url          = {https://doi.org/10.18653/v1/2024.acl-long.7},
  doi          = {10.18653/V1/2024.ACL-LONG.7},
  timestamp    = {Mon, 13 Jan 2025 16:16:40 +0100},
  biburl       = {https://dblp.org/rec/conf/acl/DuZCGCCX24.bib},
  bibsource    = {dblp computer science bibliography, https://dblp.org}
}

@article{DBLP:cdquant,
  author       = {Pranav Ajit Nair and
                  Arun Sai Suggala},
  title        = {CDQuant: Accurate Post-training Weight Quantization of Large Pre-trained
                  Models using Greedy Coordinate Descent},
  journal      = {CoRR},
  volume       = {abs/2406.17542},
  year         = {2024},
  url          = {https://doi.org/10.48550/arXiv.2406.17542},
  doi          = {10.48550/ARXIV.2406.17542},
  eprinttype    = {arXiv},
  eprint       = {2406.17542},
  timestamp    = {Mon, 22 Jul 2024 14:28:28 +0200},
  biburl       = {https://dblp.org/rec/journals/corr/abs-2406-17542.bib},
  bibsource    = {dblp computer science bibliography, https://dblp.org}
}

@article{DBLP:efficientqat,
  author       = {Mengzhao Chen and
                  Wenqi Shao and
                  Peng Xu and
                  Jiahao Wang and
                  Peng Gao and
                  Kaipeng Zhang and
                  Yu Qiao and
                  Ping Luo},
  title        = {EfficientQAT: Efficient Quantization-Aware Training for Large Language
                  Models},
  journal      = {CoRR},
  volume       = {abs/2407.11062},
  year         = {2024},
  url          = {https://doi.org/10.48550/arXiv.2407.11062},
  doi          = {10.48550/ARXIV.2407.11062},
  eprinttype    = {arXiv},
  eprint       = {2407.11062},
  timestamp    = {Mon, 26 Aug 2024 07:38:53 +0200},
  biburl       = {https://dblp.org/rec/journals/corr/abs-2407-11062.bib},
  bibsource    = {dblp computer science bibliography, https://dblp.org}
}

@inproceedings{DBLP:llmqat,
  author       = {Zechun Liu and
                  Barlas Oguz and
                  Changsheng Zhao and
                  Ernie Chang and
                  Pierre Stock and
                  Yashar Mehdad and
                  Yangyang Shi and
                  Raghuraman Krishnamoorthi and
                  Vikas Chandra},
  editor       = {Lun{-}Wei Ku and
                  Andre Martins and
                  Vivek Srikumar},
  title        = {{LLM-QAT:} Data-Free Quantization Aware Training for Large Language
                  Models},
  booktitle    = {Findings of the Association for Computational Linguistics, {ACL} 2024,
                  Bangkok, Thailand and virtual meeting, August 11-16, 2024},
  pages        = {467--484},
  publisher    = {Association for Computational Linguistics},
  year         = {2024},
  url          = {https://doi.org/10.18653/v1/2024.findings-acl.26},
  doi          = {10.18653/V1/2024.FINDINGS-ACL.26},
  timestamp    = {Tue, 24 Sep 2024 10:55:38 +0200},
  biburl       = {https://dblp.org/rec/conf/acl/LiuO0CSMSKC24.bib},
  bibsource    = {dblp computer science bibliography, https://dblp.org}
}

@inproceedings{abdolrashidi2021pareto,
  title={Pareto-optimal quantized resnet is mostly 4-bit},
  author={Abdolrashidi, AmirAli and Wang, Lisa and Agrawal, Shivani and Malmaud, Jonathan and Rybakov, Oleg and Leichner, Chas and Lew, Lukasz},
  booktitle={Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition},
  pages={3091--3099},
  year={2021}
}

@article{adelson1984pyramid,
  title={Pyramid methods in image processing},
  author={Adelson, Edward H and Anderson, Charles H and Bergen, James R and Burt, Peter J and Ogden, Joan M},
  journal={RCA engineer},
  volume={29},
  number={6},
  pages={33--41},
  year={1984}
}

@article{adepu2024framequant,
  title={FrameQuant: Flexible Low-Bit Quantization for Transformers},
  author={Adepu, Harshavardhan and Zeng, Zhanpeng and Zhang, Li and Singh, Vikas},
  journal={arXiv preprint arXiv:2403.06082},
  year={2024}
}

@article{any_precision_dnn,
  title={Any-Precision Deep Neural Networks},
  author={Haichao Yu and Haoxiang Li and Humphrey Shi and Thomas S. Huang and Gang Hua},
  journal={ArXiv},
  year={2019},
  volume={abs/1911.07346},
  url={https://api.semanticscholar.org/CorpusID:208138922}
}

@article{chee2024quip,
  title={Quip: 2-bit quantization of large language models with guarantees},
  author={Chee, Jerry and Cai, Yaohui and Kuleshov, Volodymyr and De Sa, Christopher M},
  journal={Advances in Neural Information Processing Systems},
  volume={36},
  year={2024}
}

@article{denton2015deep,
  title={Deep generative image models using a laplacian pyramid of adversarial networks},
  author={Denton, Emily L and Chintala, Soumith and Fergus, Rob and others},
  journal={Advances in neural information processing systems},
  volume={28},
  year={2015}
}

@article{dettmers2022gpt3,
  title={Gpt3. int8 (): 8-bit matrix multiplication for transformers at scale},
  author={Dettmers, Tim and Lewis, Mike and Belkada, Younes and Zettlemoyer, Luke},
  journal={Advances in Neural Information Processing Systems},
  volume={35},
  pages={30318--30332},
  year={2022}
}

@inproceedings{dettmers2023case,
  title={The case for 4-bit precision: k-bit inference scaling laws},
  author={Dettmers, Tim and Zettlemoyer, Luke},
  booktitle={International Conference on Machine Learning},
  pages={7750--7774},
  year={2023},
  organization={PMLR}
}

@article{devvrit2023matformer,
  title={Matformer: Nested transformer for elastic inference},
  author={Devvrit, F and Kudugunta, Sneha and Kusupati, Aditya and Dettmers, Tim and Chen, Kaifeng and Dhillon, Inderjit and Tsvetkov, Yulia and Hajishirzi, Hannaneh and Kakade, Sham and Farhadi, Ali and Jain, Prateek and others},
  journal={arXiv preprint arXiv:2310.07707},
  year={2023}
}

@article{frantar2022gptq,
  title={Gptq: Accurate post-training quantization for generative pre-trained transformers},
  author={Frantar, Elias and Ashkboos, Saleh and Hoefler, Torsten and Alistarh, Dan},
  journal={arXiv preprint arXiv:2210.17323},
  year={2022}
}

@inproceedings{jacob2018quantization,
  title={Quantization and training of neural networks for efficient integer-arithmetic-only inference},
  author={Jacob, Benoit and Kligys, Skirmantas and Chen, Bo and Zhu, Menglong and Tang, Matthew and Howard, Andrew and Adam, Hartwig and Kalenichenko, Dmitry},
  booktitle={Proceedings of the IEEE conference on computer vision and pattern recognition},
  pages={2704--2713},
  year={2018}
}

@article{kusupati2022matryoshka,
  title={Matryoshka representation learning},
  author={Kusupati, Aditya and Bhatt, Gantavya and Rege, Aniket and Wallingford, Matthew and Sinha, Aditya and Ramanujan, Vivek and Howard-Snyder, William and Chen, Kaifeng and Kakade, Sham and Jain, Prateek and others},
  journal={Advances in Neural Information Processing Systems},
  volume={35},
  pages={30233--30249},
  year={2022}
}

@inproceedings{lin2017feature,
  title={Feature pyramid networks for object detection},
  author={Lin, Tsung-Yi and Doll{\'a}r, Piotr and Girshick, Ross and He, Kaiming and Hariharan, Bharath and Belongie, Serge},
  booktitle={Proceedings of the IEEE conference on computer vision and pattern recognition},
  pages={2117--2125},
  year={2017}
}

@article{lin2023awq,
  title={Awq: Activation-aware weight quantization for llm compression and acceleration},
  author={Lin, Ji and Tang, Jiaming and Tang, Haotian and Yang, Shang and Dang, Xingyu and Han, Song},
  journal={arXiv preprint arXiv:2306.00978},
  year={2023}
}

@article{ma2024affinequant,
  title={AffineQuant: Affine Transformation Quantization for Large Language Models},
  author={Ma, Yuexiao and Li, Huixia and Zheng, Xiawu and Ling, Feng and Xiao, Xuefeng and Wang, Rui and Wen, Shilei and Chao, Fei and Ji, Rongrong},
  journal={arXiv preprint arXiv:2403.12544},
  year={2024}
}

@article{quarot,
  author       = {Saleh Ashkboos and
                  Amirkeivan Mohtashami and
                  Maximilian L. Croci and
                  Bo Li and
                  Martin Jaggi and
                  Dan Alistarh and
                  Torsten Hoefler and
                  James Hensman},
  title        = {QuaRot: Outlier-Free 4-Bit Inference in Rotated LLMs},
  journal      = {CoRR},
  volume       = {abs/2404.00456},
  year         = {2024},
  url          = {https://doi.org/10.48550/arXiv.2404.00456},
  doi          = {10.48550/ARXIV.2404.00456},
  eprinttype    = {arXiv},
  eprint       = {2404.00456},
  timestamp    = {Wed, 08 May 2024 17:22:41 +0200},
  biburl       = {https://dblp.org/rec/journals/corr/abs-2404-00456.bib},
  bibsource    = {dblp computer science bibliography, https://dblp.org}
}

@inproceedings{rippel2014learning,
  title={Learning ordered representations with nested dropout},
  author={Rippel, Oren and Gelbart, Michael and Adams, Ryan},
  booktitle={International Conference on Machine Learning},
  pages={1746--1754},
  year={2014},
  organization={PMLR}
}

@article{shao2023omniquant,
  title={Omniquant: Omnidirectionally calibrated quantization for large language models},
  author={Shao, Wenqi and Chen, Mengzhao and Zhang, Zhaoyang and Xu, Peng and Zhao, Lirui and Li, Zhiqian and Zhang, Kaipeng and Gao, Peng and Qiao, Yu and Luo, Ping},
  journal={arXiv preprint arXiv:2308.13137},
  year={2023}
}

@article{spinquant,
  author       = {Zechun Liu and
                  Changsheng Zhao and
                  Igor Fedorov and
                  Bilge Soran and
                  Dhruv Choudhary and
                  Raghuraman Krishnamoorthi and
                  Vikas Chandra and
                  Yuandong Tian and
                  Tijmen Blankevoort},
  title        = {SpinQuant: {LLM} quantization with learned rotations},
  journal      = {CoRR},
  volume       = {abs/2405.16406},
  year         = {2024},
  url          = {https://doi.org/10.48550/arXiv.2405.16406},
  doi          = {10.48550/ARXIV.2405.16406},
  eprinttype    = {arXiv},
  eprint       = {2405.16406},
  timestamp    = {Tue, 18 Jun 2024 16:10:22 +0200},
  biburl       = {https://dblp.org/rec/journals/corr/abs-2405-16406.bib},
  bibsource    = {dblp computer science bibliography, https://dblp.org}
}

@inproceedings{squeezellm,
  author       = {Sehoon Kim and
                  Coleman Hooper and
                  Amir Gholami and
                  Zhen Dong and
                  Xiuyu Li and
                  Sheng Shen and
                  Michael W. Mahoney and
                  Kurt Keutzer},
  title        = {SqueezeLLM: Dense-and-Sparse Quantization},
  booktitle    = {Forty-first International Conference on Machine Learning, {ICML} 2024,
                  Vienna, Austria, July 21-27, 2024},
  publisher    = {OpenReview.net},
  year         = {2024},
  url          = {https://openreview.net/forum?id=0jpbpFia8m},
  timestamp    = {Mon, 02 Sep 2024 16:55:26 +0200},
  biburl       = {https://dblp.org/rec/conf/icml/KimHGDLSMK24.bib},
  bibsource    = {dblp computer science bibliography, https://dblp.org}
}

@inproceedings{xiao2023smoothquant,
  title={Smoothquant: Accurate and efficient post-training quantization for large language models},
  author={Xiao, Guangxuan and Lin, Ji and Seznec, Mickael and Wu, Hao and Demouth, Julien and Han, Song},
  booktitle={International Conference on Machine Learning},
  pages={38087--38099},
  year={2023},
  organization={PMLR}
}

@article{yu2018slimmable,
  title={Slimmable neural networks},
  author={Yu, Jiahui and Yang, Linjie and Xu, Ning and Yang, Jianchao and Huang, Thomas},
  journal={arXiv preprint arXiv:1812.08928},
  year={2018}
}

