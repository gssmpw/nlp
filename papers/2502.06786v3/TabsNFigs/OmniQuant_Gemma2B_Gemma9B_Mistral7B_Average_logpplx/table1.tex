% Please add the following required packages to your document preamble:
% \usepackage{booktabs}
% \usepackage{multirow}
\begin{table*}[!ht]
\centering
\vspace{-3mm}
\caption{\alg with OmniQuant across Gemma-2 2B, 9B and Mistral 7B models. \alg performs on par with the baseline for int4 and int8 while significantly outperforming it for int2. Even the int3, int6 models obtained for free through interpolation from \alg perform comparably to the explicitly trained baselines. Task Avg. is average accuracy on the evaluation tasks ($\uparrow$) while log pplx (perplexity) is computed on C4 validation set ($\downarrow$).} 
\resizebox{1.5\columnwidth}{!}{ 
\begin{tabular}{@{}cccccccc@{}}
\toprule
Data type              & Method               & \multicolumn{2}{c}{Gemma-2 2B} & \multicolumn{2}{c}{Gemma-2 9B} & \multicolumn{2}{c}{Mistral 7B} \\\midrule
\multicolumn{1}{l}{}   & \multicolumn{1}{c}{OmniQuant} & Task Avg.       & log pplx.      & Task Avg.       & log pplx.      & Task Avg.       & log pplx.      \\\midrule
bfloat16               & \multicolumn{1}{l}{} & $68.21$       & $2.551$        & $74.38$       & $2.418$        & $73.99$       & $2.110$         \\\midrule
\multirow{2}{*}{int8} & Baseline            & $68.25$       & $2.552$        & $74.59$       & $2.418$        & $73.77$       & $2.110$         \\
                       & \alg            & $68.02$       & $2.570$         & $74.05$       & $2.438$        & $73.65$       & $2.125$        \\\midrule
\multirow{3}{*}{int4} 
                       & Sliced int8   & $62.87$       & $2.730$        & $72.26$       & $2.480$        & $38.51$       & $4.681$        \\
                       & Baseline            & $67.03$       & $2.598$        & $74.33$       & $2.451$        & $73.62$       & $2.136$        \\
                       & \alg             & $66.58$       & $2.618$        & $73.83$       & $2.491$         & $73.06$       & $2.153$        \\\midrule
\multirow{3}{*}{int2} 
                       & Sliced int8  & $39.78$       & $17.030$       & $38.11$       & $15.226$       & $37.29$       & $11.579$       \\
                       & Baseline            & $51.33$       & $3.835$        & $60.24$       & $3.292$        & $59.74$       & $3.931$        \\
                       & \alg             & $\bf52.37$         & $\bf3.800$        & $\bf63.35$       & $\bf3.187$        & $\bf62.75$       & $\bf3.153$       \\\midrule\midrule
\multirow{3}{*}{int6} 
                       & Sliced int8  & $67.72$       & $2.497$        & $74.64$       & $2.353$        & $73.00$        & $2.071$        \\
                       & Baseline            & $68.06$       & $2.554$        & $74.23$       & $2.420$         & $74.10$        & $2.112$        \\
                       & \alg             & $67.52$       & $2.574$        & $73.92$        & $2.440$        & $73.63$       & $2.127$       \\\midrule
\multirow{3}{*}{int3} 
                       & Sliced int8  & $41.35$          & $6.024$        & $54.18$       & $3.977$         & $39.21$        & $10.792$        \\
                       & Baseline            & $64.37$       & $2.727$        & $73.23$       &    $2.549$        & $71.68$       & $2.211$        \\
                       & \alg             & $64.47$       & $2.618$        & $72.87$       & $2.607$        & $71.16$       & $2.238$        \\
 \bottomrule
\end{tabular}
\label{tab:omniquant-ffn}
}
\vspace{-4mm}
\end{table*}