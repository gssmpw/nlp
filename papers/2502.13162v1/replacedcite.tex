\section{Related Work}
\label{Related Work}
\subsection{Jailbreak Attack on LLMs}
Previous studies show LLMs can be manipulated to generate harmful content via prompts____, often through manual design or model-generated adversarial prompts
For example, DAN____ proposed thousands of manually designed jailbreak templates. DeepInception____ leverages LLM personification abilities and a virtual nested scene to achieve adaptive jailbreaks with high harmfulness. PAIR____ uses an attacker LLM to iteratively refine jailbreaking prompts, achieving high success rates with minimal queries.
Optimization-based methods also represent a significant approach in jailbreak attacks. 
The GCG method____ generates adversarial suffixes via gradient-based search, AutoDan____ uses a hierarchical genetic algorithm, and ASETF____ optimizes them with an embedding translation model.
SAA____ extended GCG with adaptive adversarial templates. 
% DiffusionAttacker____ uses a seq2seq text diffusion model and guides the denoising process using attack loss. 

\subsection{Jailbreak Defense on LLMs}
Jailbreak defense can be applied through either response-defense or prompt-defense methods.
Response-defense methods evaluate and modify model outputs to mitigate harmful responses, including fine-tuned classifiers ____ for detecting unsafe generations and inference-time techniques like self-examination and response filtering ____.
However, these approaches require additional inference steps, increasing latency and computational cost.
Prompt-defense defenses offer a more efficient alternative by analyzing and modifying prompts before LLM inference, reducing the risk of generating unsafe outputs while saving computational resources. 
Existing parameter-free methods rely on ad hoc reasoning, such as perplexity-based filtering ____, paraphrasing ____, self-reminders ____, in-context demonstrations ____, and intent-based two-stage filtering ____. Although G4D ____ enhances defense with multi-agent guidance and external knowledge (Wikipedia), it remains computationally expensive and lacks a structured approach to capturing intrinsic attack characteristics. In contrast, our ShieldLearner directly learns attack patterns and defense principles from jailbreak prompt data, enabling a more systematic and generalizable defense.