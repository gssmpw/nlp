@article{blanchard2017krum,
  title={Machine learning with adversaries: Byzantine tolerant gradient descent},
  author={Blanchard, Peva and El Mhamdi, El Mahdi and Guerraoui, Rachid and Stainer, Julien},
  journal={Advances in Neural Information Processing Systems},
  volume={30},
  year={2017}
}

@article{li2019convergence,
  title={On the convergence of fedavg on non-iid data},
  author={Li, Xiang and Huang, Kaixuan and Yang, Wenhao and Wang, Shusen and Zhang, Zhihua},
  journal={arXiv preprint arXiv:1907.02189},
  year={2019}
}

@article{peng2024fedcal,
  title={FedCal: Achieving Local and Global Calibration in Federated Learning via Aggregated Parameterized Scaler},
  author={Peng, Hongyi and Yu, Han and Tang, Xiaoli and Li, Xiaoxiao},
  journal={arXiv preprint arXiv:2405.15458},
  year={2024}
}

@article{woodworth2020minibatch,
  title={Minibatch vs local sgd for heterogeneous distributed learning},
  author={Woodworth, Blake E and Patel, Kumar Kshitij and Srebro, Nati},
  journal={Advances in Neural Information Processing Systems},
  volume={33},
  pages={6281--6292},
  year={2020}
}

@inproceedings{yin2018mediantrmean,
  title={Byzantine-robust distributed learning: Towards optimal statistical rates},
  author={Yin, Dong and Chen, Yudong and Kannan, Ramchandran and Bartlett, Peter},
  booktitle={International Conference on Machine Learning},
  pages={5650--5659},
  year={2018},
  organization={PMLR}
}

