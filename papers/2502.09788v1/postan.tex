
For the daily blocklist generation, we set the FPR to 0.1\% and apply additional filtering to exclude potentially impactful benign domains, in line with common cybersecurity practices that combine rule-based methods with ML models~\cite{mink:SP:2023}. Our manual spot-checking of random samples (Section~\ref{subsec:analysisofdetectedmalicious}), confirms the validity of this measurement and underscores the representativeness of our ground truth.
Fig.~\ref{fig:dailyblocklistcount} shows the seed domain count and the number of newly predicted malicious domains at an FPR of 0.1\%. On average, \system detects over 5 new malicious domains for each seed malicious domain.  


\subsection{GNN Explanations}
\label{sec5:feature_importance}
\spfinal{To enhance transparency and interpretability, we evaluated the importance of features and connections using two GNN explainers: a perturbation-based approach~\cite{ying2019gnnexplainer} and a gradient-based method~\cite{kokhlikyan:captum:2020}.
We categorized features into groups such as domain hosting, IP hosting, lexical, linguistic, and statistical, and assessed their significance across various prediction outcomes. Our analysis highlights the importance of hosting features (domain and IP) and certain lexical attributes, such as suspicious brands in domain names and matching nameservers, and the unimportance of features like length and the number of minuses. While the latter features can be easily circumvented by attackers, former ones, like longer durations with high query counts, would be hard for attackers to manipulate, thus increasing our robustness. We pay special attention to misclassifications and, as shown in Fig.~\ref{fig:exp_explain_gnnexp_main}, longer hosting durations and statistical lexical features contribute to false negatives, whereas lexical features have the greatest impact on false positives. Incorporating traffic pattern related hosting features and/or domain registration features likely to reduce such false positives.
Additionally, our analysis of the important connections within the expanded graph sheds light on potential malicious campaigns like the ones presented in Section~\ref{ss:campaigns}.
}

\begin{figure}
\centering
\includegraphics[width=0.99\columnwidth]{images/gnexp_fp_fn.png}
  \caption{Feature importance for (a) false-positive and (b) false-negative predictions using perturbation-based method.}
  \label{fig:exp_explain_gnnexp_main}
\end{figure}


\begin{figure}[t]
\centering
\includegraphics[width=0.85\columnwidth]{images/6.dailybfcount.png}
\caption{Number of newly detected malicious domains.\eat{\fatih{For this figure count ratio MANTIS/VT=5.20.}}}
\vspace{-3mm}
\label{fig:dailyblocklistcount}
\end{figure}

\subsection{Analysis of Detected Malicious Domains}
\label{subsec:analysisofdetectedmalicious}

We analyzed and validated a sample of malicious domains predicted (i.e., not part of the ground truth) by \system.
This post-analysis process includes rule-based daily status checking of a random set of daily malicious predictions for a predefined period. The pipeline is completed with a domain expert's manual verification of the remaining suspicious domains. In this way, we not only rely on the output of the machine learning models but also have the chance to observe new attack behaviors and update our approach.
For each day, we report VT malicious counts\revision{, GSB status} of the selected domains and active DNS (ADNS) resolutions \fatih{that represent non-NX and non-sinkhole domain counts}. 
Although \system is content-agnostic, we collect and check website contents to investigate additional signs of suspicion.
Our manual verification process is outlined in Appendix~\ref{app:sanity_table}.

For randomly selected 1000 malicious predictions by \system on September 8, 2022, Fig.~\ref{fig:sanity1} shows the cumulative distribution of the detected domains by VT, \revision{GSB}, and ADNS resolution counts over time. \fatih{Upon the initial scan, the first-seen times within the collected reports reveal that 621 of these domains were originally submitted to VT by \system. This demonstrates the proactiveness of our discovery of malicious domains through passive DNS expansion. Among these 621 \system-submitted domains, $28.9\%$ and, for the cumulative one-thousand domains, $47.7\%$ of domains were initially classified as malicious by at least five engines. After two months, these figures increased to $64.6\%$ and $70.3\%$ for the \system-submitted domains and the overall. }

{\bf Active DNS Analysis:}
\fatih{ADNS resolutions provide valuable information for assessing the operational status of domains, offering insights into potential malicious activities. Upon classification, we note that 77.9\% of the selected domains immediately resolve to an IP address. Remarkably, within a span of just four days, this ratio increases to $91.5\%$, indicating a rapid deployment and activation of the identified domains.
After two months, this ratio decreases to $36.2\%$. This substantial decrease suggests a dynamic landscape of malicious activities.
These findings highlight the effectiveness of our GNN-based classifier in detecting malicious domains at an early stage, even before the web page contents are fully up and running. By leveraging passive DNS resolutions, \system demonstrates its capability to identify and flag potentially malicious domains during the early stages of their deployment.}

\begin{figure}[t]
\centering
\includegraphics[width=0.85\columnwidth]{images/7.sanity1.png}
\caption{Sanity checking for 60 consec. days. \eat{\nabeel{Let's add GSB results as well.}}}
\label{fig:sanity1}
\end{figure}

{\bf VT Status \& Content Analysis:}
After actively scanning the status of these domains for 60 days, we observe that $82.3\%$ of the domains are marked as malicious by at least one of the VT engines. Notably, none of the VT engines report $17.7\%$ of the domains as malicious, which is consistent with the findings of prior studies that report a range of $14.1\%$ to $18.2\%$ of undetected malicious domains~\cite{vissers:euric:2019, vissers:30day:2017}. It is concerning to note that existing approaches have a blind spot for these malicious domains. We attribute this to various reasons: not reported by a user, unavailability or insufficiency of the content when the scanning is performed, and domain cloaking. 
For the domains that do not have IOCs, after 60 days, we observe attributes akin to malicious domains: $54.8\%$ do not resolve to an IP, $48.6\%$ do not have any PDNS trace, $92.7\%$ have had less than 100 queries during the whole second month of the verification process, and none of them are present in the Internet Wayback Machine.
Regarding the ones that resolve to an IP, we observe that $6.3\%$ are parked, and $58.8\%$ either do not provide any HTML response, show empty content or various error messages such as invalid common name within the certificate, registration confirmation errors, or hosting provider-related warnings rather than legitimate content. 
Considering the attacker's hit and run strategy, in which malicious domains remain operational for a short duration, often just a single day in $60\%$ of cases~\cite{hao:30day:2013, oest:sunrise:usenix:2020}, our post analysis results comply with the expected attacker behavior.
\spupdate{Still, these are not concluding evidences for the maliciousness of domains. Many expired benign domains are also parked, and not all benign domains appear in the Wayback Machine. Nonetheless, these factors do raise suspicion regarding these domains.}
Table~\ref{tab:sanity_60days} in Appendix~\ref{app:sanity_table} further details the inspection results for different VT scores.

{\bf Precision and FPR:}
\fatih{Domains that resolve to an IP address, have HTTP content, are not marked as malicious by at least five VT engines or GSB are verified by a domain expert following the steps outlined in Appendix~\ref{app:sanity_table}. 
Through this rigorous process, we discover that 12 domains previously labeled as potentially malicious are, in fact, false positives. These domains and their details can be found in Table~\ref{tab:falsepositives} in Appendix~\ref{app:sanity_table}, demonstrating the precision of our sanity checking at an impressive 0.988.}
\fatihh{Despite our graph's relatively higher toxicity, benign predictions still dominate with a benign-to-malicious ratio of $\geq 10$. Consequently, the FPR ($\frac{FP}{FP + TN}$), remains impressively low ($\frac{12}{10,000}\approx0.1$\%), underscoring the exceptional efficacy of \system and aligning with the measured FPR using the ground truth we have collected.}



{\bf Comparison with GSB:}
\revision{We further compare \system with GSB. Specifically, we randomly pick 1000 predicted domains by \system and check how many are also marked as malicious by GSB. For those not marked by GSB, we followed the manual process described above conducted by a domain expert to check their status daily. We run this experiment over 6 different days. On average, around 18\% of those predicted by \system are marked by GSB on the first day. For the remaining domains predicted by \system, within the following two months, only an additional 12\% are marked by GSB as malicious within two months. This experiment shows \system's proactiveness, which can predict malicious domains much earlier than GSB, and \system's capability of detecting malicious domains missed by GSB. }


\spfinal{

\subsection{ Registration, Resolution \& Detection Times}~\label{ss:registrationdetection_analysis}


We also analyze the registration and PDNS first appearance times of the blocklisted domains to demonstrate the proactiveness of \system. Similar to prior work~\cite{hao:30day:2013, vissers:30day:2017}, we observe that the vast majority of malicious behavior of malicious domains occurs within 30 days after their registration. Specifically, $75.8\%$ of the predicted malicious domains are registered within the past month, and $96.1\%$ of the registrations occurred within the past year before detection. 
Our analysis further shows that benign domains take an average of 10 days from registration to their first PDNS appearance, while malicious domains appear in just 2 days. For newly discovered malicious domains registered in the past month, our system detects them on average within 3 days and 17 hours after their first PDNS appearance, compared to over 8 days for VT. This delay from VT is likely due to the reliance on submissions and the unavailability of domain contents. These statistics highlight the potential of our framework for earlier detection compared to traditional methods, which is quite valuable to registrars and hosting providers to detect abuses of their services early and take corrective actions.




\subsection{False Positive/Negative Analysis}~\label{ss:fpfn_analysis}


From the daily detection, we take random samples of 100 domains to perform error analysis periodically. We observed that the false positive rate is within the desired set threshold and the false positives are influenced by linguistic and statistical features. Specifically, domains containing consecutive numbers and minus characters were more likely to be flagged as malicious. As shown in Figure~\ref{sec5:feature_importance}, domains with no subdomains (just a landing page) or very long subdomains  also contributed to false positive predictions. Sample of such domains and their details can be found in Table~\ref{tab:falsepositives} in Appendix~\ref{app:sanity_table}. One may avoid such false positives by incorporating additional features such as WHOIS registration and TLS certificate features. In contrast, false negatives are associated with longer duration, high query counts, absence of suspicious brands in the domain name, presence of a matching name-server domain name, and low digit and consecutive consonant ratiosâ€”traits more commonly associated with benign domains. Content based features such presence of forms, brand logos, and injected scripts may assist in reducing such false negatives. 
}

\subsection{Example Campaigns Detected}~\label{ss:campaigns}
In this section, we investigate a couple of example campaigns detected by \system. 
Fig.~\ref{fig:campaignweb3} shows a campaign where web3 domains such as \url{opensea.com}, \url{ens.domains}, and \url{rarible.com} are abused. The threat actor predominantly uses homographs to trick users. 
An interesting observation is that the campaign hosts incrementally more domains each day. However, all of them are hosted within one day of registration. Fig.~\ref{fig:campaignicloud} shows another campaign that abuses Apple and/or iCloud. \system starts to detect the first of the malicious domains and continues to crawl the same infrastructure to proactively discover additional malicious domains as and when they are hosted. Unlike the web3 campaign, we observe that the threat actor not only hosts domains over a long period of time but also strategically waits after domain registration, possibly to avoid detection by domain reputation systems. For example, \url{map-findmy.app} was created on 2022-10-02, but used to launch an attack on 2022-11-13.


\begin{figure}
\centering
\begin{subfigure}[t]{0.85\linewidth}
    \includegraphics[width=\linewidth]{images/campaign_web3_2.png}
    \caption{}
    \label{fig:campaignweb3}
  \end{subfigure}  \hfill
  \begin{subfigure}[t]{0.85\linewidth}
    \includegraphics[width=\linewidth]{images/campaign_web3f_2.png}
    \caption{}
    \label{fig:campaignicloud}
  \end{subfigure}\hfill
  \caption{Campaigns abusing (a) web3 domains (b) Apple/iCloud, along with resolved IPs and first detection dates.}
  \label{fig:campaigns}
\end{figure}

