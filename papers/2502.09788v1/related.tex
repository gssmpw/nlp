{\bf Early Detection.} PhishNet~\cite{phishnet:2010} proposes five
heuristics to enumerate simple combinations of known phishing sites to discover new phishing URLs. Felegyhazi et al.~\cite{predictive:leet:2010} identify new malicious domains leveraging DNS zone files and WHOIS records. They observe that malicious domains are registered in bulk and are utilizing either fresh or self-resolving name servers. Based on these observations, they cluster domains and identify domains not discovered by existing blocklists. EvilSeed~\cite{evilseed:sp:2012} proposes an approach to identify likely malicious webpages based on the links in seed malicious pages.  Predator~\cite{Predator_Hao2016} attempts to identify malicious domains at the time of registration. Their intuition is that spam domains are registered in bursts and often at similar stages in the domain life cycle. They rely on the WHOIS records at the domain registration, historical WHOIS records for domains, and the WHOIS records of domains registered at the same registrar. While these approaches detect malicious domains that are lexically similar or registered in bursts, we remark that the detected set is only a small subset of all malicious domains out there as many malicious domains do not exhibit lexical similarity nor time-based correlation. 


{\bf Feature Based Classification.}
Many approaches~\cite{maldom:kdd:2009,Fukuda:2015:DNSBackScatter,Segugio_Rahbarinia2015,DeepDGA_Anderson2016,MethodForDetectingDgaBotnet_Tong2016}, including Notos~\cite{Notos_Antonakakis2010} and EXPOSURE~\cite{bilge:2014:Exposure}, identify malicious domains by building a classifier using the local features extracted from passive DNS data along with other network information such as WHOIS records~\cite{Liu:2015:CLP}. Such approaches are effective as long as the local features used in the classification are not manipulated. However, it has been shown~\cite{TowardsSystematicEvaluationOfTheEvadabilityOfBotnetDetectionMethods_Stinson2008} that many local features such as TTL-based features and patterns in domain names, are easy to manipulate and thus rendering such techniques less effective. These approaches perform best when one has access to sensitive individual DNS queries which are difficult to gain access to. On the other hand, graph-based approaches like ours can detect malicious domains with high accuracy using only aggregate DNS data which is relatively easier to gain access to. 
{\bf Graph Based Detection.}
Nabeel et. al.~\cite{bp_mal2:2020} utilize the passive DNS data and graph inference algorithms such as belief propagation and path-based algorithms for malicious domain defections. 
A recent study by Kim et. al.~\cite{BPPhishingCCS:2022} uses loopy belief propagation with adaptive edge potentials on a heterogeneous network consisting of URLs, domains, IPs, and word segments. \revision{Simeonovski et al.~\cite{internetgraph2017} propose a taint-style propagation technique based on a set of rules that focuses on a graph structure around the top 100K Alexa domains.} 
MalRank~\cite{malrank:acsac:2019} implements a large-scale graph inference algorithm to detect malicious domains in SIEM environments. 
HinDom~\cite{hindom:raid:2019} implements a malicious domain detection system by representing DNS in a heterogeneous information network (HIN) and a meta-path based path-similarity classifier.  Meanwhile, HGDom~\cite{hgdom:NOMS:2020} utilizes a heterogeneous variant of GCN called MAGCN for domain classification. Ringer~\cite{ringer:ICCS:2020} proposes a scalable method to detect malicious domains by a dynamic graph neural network. DeepDom~\cite{deepdom:cns:2020} uses SHetGCN to classify malicious domains, a heterogeneous variant of GCN. The graph contains clients, domains, IP addresses, accounts, and relationships in between. GAMD~\cite{ahgnn}, Blocklist-Forecast~\cite{blocklist_raid2024} and HANDom~\cite{handom:wang:2023} utilize variations of heterogeneous graph neural networks for malicious domain prediction. The DNS graph contains clients, domains, IPs, and relationships among them. 
\eat{80\% of their dataset is based on a dataset from 2017 that may not reflect current attack behaviors. Their precision values are also quite low compared to our approach (0.832), which can restrict their usage in real-life.}

Though the above models show promising results, they have limitations when predicting at a global scale:(1) belief propagation based approaches fail to take advantage of features associated with domains whereas our approach leverages both node features and network topology; (2) existing approaches require user-level DNS query, which is often limited, to build the network graph whereas our approach utilizes publicly available aggregated DNS resolution information; (3) They are not able to predict on unseen domains without retraining from the scratch, whereas our approach supports inductive learning without retraining; and (4) They use static graphs and do not show if they generalize to unseen data, whereas our approach is generalizable over time. 
