\subsection{Ground Truth Collection}~\label{sec:gt}\textbf{Seed Extraction:}
We collect two sets of malicious domains through VT. The first is a set of seed malicious domains, which are used to construct a network graph. The other is the malicious domain ground truth for model training. 
For the daily seed domains, we first select those URLs seen for the first time in the VT feed within the past 24 hours and marked as malicious by at least 5 scanners and an active VT scan of the corresponding domains with at least 3 VT scanners following prior research~\cite{comp_or_at:2021:usenix}. 
\fatihh{We extract only those malicious domains that are highly likely to be created by attackers and filter out potentially compromised domains (whose apex domains appear in the top lists utilized in this work) as well as domains belonging to web hosting services (e.g., weebly.com). We employ a rule-based approach to differentiate between public domains (such as web hosting and CDN domains) and attacker-created domains~\footnote{We use the whitelists from Mozilla’s widely accepted Public Suffix List~\cite{publicsuffix:mozilla} and the data from~\cite{comp_or_at:2021:usenix} available at \url{https://bit.ly/3Yw8Sip}.}, which is widely used in the industry to flag malicious domains~\cite{paloalto:2014}.} \eat{Further, we exclude sinkhole domains as their hosting infrastructure differs from attack infrastructure.
We further use an LSTM-based model to filter out DGA domains as they are not the focus of our detection and there exist highly effective techniques to detect DGA domains.} 
From the remaining domains, we identify those with popular brand keywords~\cite{phicious:raid:2022} and include them within the seed domains. At the end of this process, we identify \revision{close} to 3000 likely attack seed domains per day seen for the first time from June 1st, 2022 until June 1st, 2023.

\eat{
We follow the below steps to generate the daily seed malicious domains.

\begin{itemize}[leftmargin=*]
\itemsep0em 
    \item VT feed contains all the URLs queried by users worldwide. Since our goal is to identify the latest malicious domains, we first select the URLs seen for the first time in the VT feed within the past 24 hours. 
    \item From the first seen URLs, we select those URLs marked as malicious by at least 5 scanners~\cite{mulvt2, mulvt3}.
    \item We then extract the apex domains from these malicious URLs.
    \item Even though a URL is malicious, its apex domain is not necessarily malicious. This is the case with compromised domains. Based on the webhosting list identified in~\cite{comp_or_at:2021:usenix}, we exclude likely compromised domains by removing those present in the top lists. We also exclude apexes belonging to web hosting services such as 000webhostapp.com, github.io, and godaddysites.com, as these hosting services exhibit benign behavior~\footnote{Due to the benign indicators, malicious websites created on hosting sites are likely indistinguishable from the benign websites on the same site purely based on the hosting infrastructure. One would require a different mechanism to detect such malicious websites, which is beyond the scope of this work. }.     \item We use an LSTM-based model~\cite{DgaIntel} to identify DGA (Domain Generation Algorithm) domains and filter them out. Usually, DGA domains are created in thousands and hosted on a limited set of IP addresses. We observe that such malicious domains are quite different from other attack domains and having such domains reduces the detection efficacy of non-DGA malicious domains. Hence, to detect attack domains with a high efficacy, we exclude DGA domains~\footnote{There are excellent mechanisms to identify DGAs~\cite{dgarnn:2021} and we recommend utilizing such mechanisms along with our approach to detect different types of malicious domains with a high efficacy}.     \item Prior research shows that newly observed domains with popular brand impersonating keywords~\cite{phicious:raid:2022}  are more likely to be malicious. Based on this observation, we identify a seed malicious domain list with any popular brand keywords used in prior research~\cite{phicious:raid:2022}.
    \item For those likely attack domains that do not have popular brand keywords, we perform additional filtering. Our intuition is that recently registered and short-lived domains are more likely to be attack domains. To this end, we extract those domains that are registered within one year of the day the pipeline is executed. If the WHOIS record is not available, we check the PDNS records to obtain its footprint. If the PDNS record is available and the footprint duration is less than one year, we add the domain to our daily seed domains.     
\end{itemize}
At the end of this pipeline, we identify likely attack seed domains that are seen for the first time since June 1st, 2022 until Nov 25th, 2022.
On average, our pipeline identifies \revision{close} to $\sim$3000 seed domains per day.}

\fatihh{\textbf{Malicious GT:} We utilize a subset of seed domains ($VT \ge 5 $) in our ground truth. Also, after constructing the network graph from these seeds, we identify previously marked malicious domains using the same threshold within the expanded graph and incorporate them into our malicious ground truth.}

\eat{MOVED TO APPENDIX: Once we construct the network graph from the seed domains, we randomly select a set of domains from the graph and follow the below mentioned manual process to identify those malicious ones as our malicious domain ground truth. 
\fatih{During manual ground truth collection, we investigate the presence of phishing and fraudulent activities, distribution of malware, malicious or harmful content, and involvement in different types of brand squatting attacks. In addition to investigating the website content, we assess auxiliary information such as registration information, hosting information, Internet Wayback Machine snapshots, and historical WHOIS records. We also assess the detailed reports from two threat intelligence platforms, Microsoft Defender
Threat Intelligence (ti.defender.microsoft.com) and AlienVault (otx.alienvault.com).}}


\textbf{Benign GT:}
\spfinal{
Benign domains are randomly collected from the domains in the expanded PDNS graph, and VT is used to further ascertain their benignness. We leverage diverse sources, including top lists, existing benign sources, and reputable TLDs. To reduce bias, we focus on newly seen domains in the VT feed and unpopular domains, as Tranco and other domain ranking lists tend to skew toward popular, long-established domains. Specifically, we randomly sample 10,000 domains from the expanded graph that do not exist in our local VT domain database or exist in the local unpopular domain dataset, such as those collected from sources like Yellow Pages~\cite{YellowPages}.
We perform additional heuristic-based filtering to remove suspicious domains, including those resolved to sinkhole IPs, those with invalid or expired certificates, or lacking valid content.
We also exclude DGA domains, domains impersonating popular brand names, and those from TLDs managed by Freenom\footnote{Freenom was discontinued in 2023, and therefore this filtering step no longer removes a significant number of domains.}—such as .gq, .ml, .cf, and .tk—as they generally have very low reputations. We then submit the remaining domains to VT to check their status, and extract those marked as benign by all scanners. While these heuristics do not offer a precise or comprehensive method for detecting malicious domains with high confidence, they help build a high-quality benign ground truth to ensure robustness in classification.
In addition to domains identified through active lookup, we passively collect .edu and .gov domains, as well as top lists from sources like Alexa, Umbrella, CrUX, and Tranco. Since relying solely on top lists leads to poor generalization and a higher false positive rate, we integrate newly observed domains, domains from reputed TLDs, and other top lists into the benign ground truth to create a more representative dataset, enabling us to train a generalizable classifier with a lower false positive rate. When we examine the distribution of our benign ground truth across different categories, we observe that approximately 54\% of the benign ground truth comes from popularity-based domains, 41\% from heuristics-based domains, and 5\% from educational and governmental websites.
Further details related to the quality checks on the ground truth are provided in Appendix~\ref{app:sanity_table}. 
}
