\subsection{Graph Neural Networks (GNNs)} \label{ss:GNNs}

GNNs are a class of deep learning models for learning from data represented as graphs. GNNs learn representations of either nodes, edges, or whole graphs. In this work, as our objective is to detect malicious domains, we focus on node representation learning. 
\fatih{GNNs combine node features with the graph
structure by recursively passing neural messages along the
edges of the input graph using three key functions, namely \texttt{MSG}, \texttt{AGG}, and \texttt{UPDATE}. These functions work together for exchanging messages between a node $v_i$ and its immediate neighboring nodes $\mathcal{N}_{v_i}$. 
In layer $l$, a message between two nodes $(v_i, v_j)$ depends on the previous layer's hidden representations $h_i^{l-1}$ and $h_j^{l-1}$, i.e, $m_{ij}^l = \texttt{MSG}(h_i^{l-1}, h_j^{l-1})$. 
\texttt{AGG} combines the messages from $\mathcal{N}_{v_i}$ with $h_i^{l-1}$ to produce $v_i$'s representation for layer $l$ in  \texttt{UPDATE}. 
Various adaptations of this core message passing framework with different \texttt{MSG}, \texttt{AGG}, and \texttt{UPDATE} implementations have been proposed~\cite{graphsage:nips:2017, hgt:web:2020, gcn:iclr:2017, rgcn:www:2018, gat:velickovic2018graph}. These can be categorized into two groups: those that work on homogeneous graphs~\cite{graphsage:nips:2017, gcn:iclr:2017, gat:velickovic2018graph} with one type of nodes and edges and those on heterogeneous graphs~\cite{hgt:web:2020, rgcn:www:2018} with different node and/or edge types. To harness the comprehensive representation, we employ a heterogeneous GNN that considers both node and edge types.}


\subsection{Data Sources}
\eat{In this section, we provide a brief description of the data and intelligence sources we use in this work.} We utilize the following data sources:

\textbf{Passive DNS:}  
\revision{We use Farsight PDNS data~\cite{DNSDB} that is collected from sensors placed near DNS resolvers and provides a summary of domain resolutions and publicly accessible updates to zone files. Farsight streams records at various time granularity, ranging from every minute to daily to monthly. For training purposes, we use the daily feed, but for on-demand detection, we advise using the feed published every minute.} \fatih{We use PDNS to extract domains related to seed domains (expansion) and collect domain/IP features.} \eat{In our research, we use Farsight data as our PDNS feed. One advantage of PDNS is that it preserves the privacy of individual Internet users as it contains only aggregated information. However, such data is not as rich in information as proxy/HTTP DNS logs, which not only contain individual DNS queries and responses but also timing information. Despite its limited information, we are able to extract domains related to seed malicious domains as well as domain/IP features from the PDNS repository as described in Section~\ref{sec:approach}.} \eat{Previous research utilizes this data feed to uncover the behavior of domains in the wild and also detect malicious domains~\cite{Kintis:2017:Combosquatting, Khalil:2018:Inference}.} \eat{In this work, we use the following three record types from PDNS:
\begin{itemize}
    \item SOA records: they contain the MNAME (the primary name server for the domain) and RNAME (email of the domain name administrator). 
    \item A records: these records map the domain names to their IPs. 
    \item MX (mail exchange server) and NS (name server) records: these records specify where inbound mails for a domain should get directed and authoritative name servers respectively.
\end{itemize}

All of the above records contain aggregated timing information (such as the first and last seen timestamps for each record), and the count of DNS lookup requests. Such timing information is crucial to identify recent records to build our graphs and perform classification.}


\textbf{VirusTotal URL Feed (VT):} ~\cite{VirusTotal}
\eat{URL feeds have become essential in the evolving security technology landscape. Organizations integrate their Security Orchestration, Automation, and Response (SOAR) products with threat intelligence platforms like VirusTotal to gather insights about encountered URLs. This integration leverages contributions from a vast network of global sensors connected to email and internet gateways, enabling real-time visibility into potential and emerging threats.}
VT feed contains all the URLs queried by users worldwide and VT provides an API to monitor the status of specific URLs and generates an hourly feed of JSON-encoded reports. Using our organization's subscription, we observe a daily volume of approximately 2-5 million URLs within VT's feed in Sep 2023, monitoring them regardless of their maliciousness.
This feed comprises URLs and aggregated intelligence collected from over 90 third-party scanners, including notable sources such as Google Safe Browsing (GSB)\footnote{GSB is available for enterprises through cloud-based Google WebRisk}~\cite{GoogleSafeBrowsing}, Phishtank~\cite{phishtank}, among others. 
We continuously profile newly observed domains in this feed and utilize them in two primary ways: (1) to generate a daily collection of potentially malicious seed domains, and (2) to construct our malicious ground truth. Following the prior studies~\cite{phicious:raid:2022,comp_or_at:2021:usenix}, we set a threshold of five scanners to identify malicious domains, which allows us to aggregate intelligence from diverse scanners, enhancing the generalizability of our dataset. \eat{If a domain is reported as malicious by five or more scanners and determined to be an attack domain, it is included in our ground truth. This approach allows us to aggregate intelligence from diverse scanners, enhancing the generalizability of our dataset.}


\revision{\textbf{Alexa, Tranco, Cisco Umbrella, and Googleâ€™s Chrome User Experience Report (CrUX) Top Lists:}   \fatih{To ensure a comprehensive and unbiased benign ground truth, we employ a robust approach that integrates multiple reputable top lists along with randomly selected benign domains from passive DNS based on predefined rules. By leveraging diverse sources like Alexa~\cite{Alexa}, Umbrella~\cite{Umbrella}, Tranco~\cite{trancolist}, CrUX~\cite{Crux}, and passive DNS, we aim to minimize any inherent bias and provide a more accurate representation of benign domains.}
Alexa lists the most popular 1 million domains each day. 
Umbrella aggregates DNS queries to the OpenDNS resolvers to create the most frequently queried names.
Tranco~\footnote{Available at https://tranco-list.eu/list/Y52LG.} aggregates rankings from the Alexa, Umbrella, and Majestic~\cite{Majestic} lists, and CrUX computes rankings directly based on browsing data from Chrome users and provides ranking buckets (e.g., top 1K, 5K, 10K, etc.). 
\eat{It is aggregated monthly, and as suggested by~\cite{toppling2022}, it captures the unordered set of most popular websites more accurately than other top lists.} }
Indeed, a popular domain does not always mean it is benign~\cite{toppling2022}.
However, domains consistently appearing in the top lists over a period are highly likely to be benign, as attackers tend to use a domain for a short time period, their domain popularity is likely to last only a few days~\cite{bilge:2014:Exposure, toplistsanalyze:2019}.
Based on these observations, following prior studies, for the daily top lists from Alexa and Umbrella, we compile the top 30-day list, which includes the domains consistently appearing in the list for 30-days and also exclude those marked as malicious by VT. They are combined with the monthly lists from Tranco and CrUX to form part of our benign ground truth.




