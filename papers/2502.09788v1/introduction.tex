Attackers increasingly utilize short-lived domains as a primary vector to launch cyber attacks, often stockpiling these domains~\cite{stockpiled} to maximize their returns. 
IBM's Data Breach Report shows that the average cost of a data breach, frequently originating from malicious domains, reached USD 4.45M in 2023~\cite{ibmcost:2022} despite numerous defense-in-depth solutions deployed to detect such malicious domains. 
Attackers keep evolving and finding more sophisticated and evasive ways to circumvent the security controls in place and lure users to access malicious websites. 
Though a plethora of detection solutions have been proposed and deployed in practice, many malicious domains either go undetected or get detected only after users are compromised. 
Thus, adapting security solutions to defend against evolving attacks is important. In this work, we leverage the fact that even though there are many possible ways to create malicious domains, the deployment options for domains are limited. 

\begin{figure}[t]
\centering
\includegraphics[width=0.95\columnwidth]{images/early_detection.png}
\caption{\system vs. Existing Approaches: \system detects malicious domains much early at the hosting time compared to many of the existing techniques which often detect domains only after the web content is available.}
\label{fig:earlydet}
\end{figure}

\ccsupdate{As shown in Fig.~\ref{fig:earlydet}, the goal of our system, \system, is to detect malicious domains much early at their hosting time.
Registration time approaches result in a higher likelihood of false positives due to insufficient evidence~\cite{premadoma:euroic:2019, dga2019, vissers:euric:2019}, and most existing security scanners rely on webpage contents or network logs to detect malicious domains after they reach a security enforcement point (e.g. Firewall, browser)~\cite{contentbasedphish2021, wardman2011:contentbased,jain2020phishskape::contentbased}.
While content/network log based techniques are important, they have several limitations: (1) they have a blind spot for cloaked webpages, which is a technique attackers increasingly utilize~\cite{crawlphish:2021}; (2) they require huge amounts of computational resources to analyze billions of webpage contents; (3) there is limited visibility to malicious domains in the wild and (4) by the time malicious webpage contents or network traces are available, it is difficult, if not impossible, to prevent the attack from happening. Note that \system~\footnote{The source code and the daily generated blocklists are available at https://github.com/fatihdeniz/mantis.} is designed to augment, not replace, content-based detection methods. In some instances, like detecting compromised domains, content-based detection may be the most viable approach. 
A challenge is that we need to differentiate malicious domains from benign ones with much less available information than content-based approaches. }



We observe that while the toxicity~\revision{\cite{toxicity2013}}, i.e. the ratio of malicious domains to all domains, of hosting infrastructures on the Internet, in general, is very low, the same measure in the neighborhoods that previously hosted malicious domains is relatively high, i.e., they tend to host malicious domains again in the near future. For example, the toxicity of a sample of domains observed from passive DNS is 0.002, whereas the toxicity of a sample of domains around the IPs previously hosting malicious domains on the same day is 0.063 (31.5 times higher, detailed in Appendix~\ref{app:graphtoxicity}). 
\fatihh{Further, to evade detection, attackers deploy malicious domains with dynamic behavior by frequently rotating their IP resolutions or creating new domains. While doing so, attackers tend to reuse infrastructure resources and increasingly employ automation to host malicious domains within a similar pool of IPs (E.g. Postal campaign~\cite{campaign1:postal} and ApateWeb Campaign~\cite{campaign2:apateweb}). As shown in Fig.~\ref{fig:overlapping_ip_july}, over 80\% of IP addresses used to host malicious domains on a given day were found to be reused from the previous 7 days.}
By monitoring new domains hosted on the IPs that recently hosted malicious domains, it seems intuitive that one can identify new malicious domains easily. However, due to the increasing utilization of shared hosting, we observe that not all new domains hosted in a toxic infrastructure are malicious. In other words, being hosted on a malicious infrastructure is not conclusive evidence of the maliciousness of a domain. Therefore, additional innovative mechanisms are required to distinguish true malicious domains from false positives sharing the same hosting infrastructures.



A set of solutions extract representative features of domains and train a binary classifier to distinguish malicious and benign domains~\cite{Notos_Antonakakis2010, bilge:2014:Exposure,  lexical2015, page:2019:mal, schuppen:fanci:usenix:2018}. Yet such approaches are sub-optimal as they fail to leverage the network topology of the hosting infrastructure. Another line of solutions model domains as a graph (e.g. domain-IP graph) and exploit the label similarity of domains in the proximity of the hosting infrastructure by utilizing techniques such as belief propagation or label propagation~\cite{polonium:SIAM:2011, nazca:NDSS:2014, bp_mal2:2020, marmite:CCS:2017}. While such approaches consider network topology, they fail to capture domain features. A similar drawback exists with shallow node encoding (e.g. Node2Vec~\cite{node2vec:sigkdd:2016}) followed by a supervised classifier. 
\spupdate{It is tempting to create an ensemble classifier that combines a feature classifier with a network topology-based classifier~\cite{practicalattacks:SP:2024}. Yet, it still remains sub-optimal as it does not effectively learn the correlation between the network topology and node features.}
Graph Neural Networks (GNNs) address these issues by learning a model simultaneously considering both aspects. 
\begin{figure}[t]
\centering
\includegraphics[width=0.8\columnwidth]{images/overlapping_ip_july.png}
\caption{\fatih{Reuse of Hosting Infrastructure. Over 80\% of IP addresses used to host malicious domains on a given day were found to be reused from the previous 7 days.}}
\label{fig:overlapping_ip_july}
\vspace{-2mm}
\end{figure}
It presents a significant challenge to construct a network graph that consistently achieves high precision and recall in GNN-based malicious domain classification tasks across different time frames. Recent research suggests that belief propagation on a similar network graph outperforms GNNs~\cite{BPPhishingCCS:2022}. However, we attribute the contradictory lower performance to the deficiencies in the constructed graph, specifically the lack of preservation of the homophily property. 

A malicious domain could be compromised (i.e. benign domains exploited by attackers) or attacker-created (i.e. the domain registered by attackers). Through an analysis of daily blocklists, we found that around $82\%$ of the domains were maliciously registered, with the remaining $18\%$ identified as compromised. Since compromised domains are originally benign, they tend to be hosted on infrastructures where many other benign domains are hosted. Prior works do not distinguish between these two types of malicious domains, leading to suboptimal classification results~\cite{BPPhishingCCS:2022, ringer:ICCS:2020,hgdom:NOMS:2020}. 
Instead of building one model to detect different types of malicious domains, it is more effective to employ orthogonal detectors to identify malicious web hosting and compromised domains, such as those proposed in \cite{comp_or_at:2021:usenix}. In this study, our main objective is to detect attacker-created domains as soon as they are being hosted, meaning a DNS server resolves each domain to an IP address(es), even before it serves any content or is weaponized.

We observe that many research efforts utilizing graph models to classify malicious domains suffer from the following limitations: (1) they use biased ground truth, especially benign ground truth, where often only popular domains are utilized~\cite{Bahnsen:2017:PhishingURLsNN, practicalattacks:SP:2024}, leading to overfitted classifiers; (2) they use fully labeled graphs and are not shown to work on unlabeled domains under a semi-supervised learning setting; 
and (3) they are unable to perform on-demand predictions on domains that are not part of the training graph~\cite{BPPhishingCCS:2022, bp_mal2:2020}. 
We address these issues and build a practical system named \system
that support two key use cases: (1) daily blocklist generation (batch mode); and (2) on-demand prediction. On a daily basis, \system first compiles a list of seed malicious domains first seen on a given day and identifies other recent domains hosted on the same infrastructure as the seed domains.
Based on these resolutions, \system builds a graph and then collects lexical and hosting features and ground truth domains to train a model. 
An ensemble of daily trained models is utilized to predict malicious domains not present in the training graph to further reduce false positives. \ccsupdate{To the best of our knowledge, we are the first to construct a graph around \emph{attacker-owned} domains that yields consistent results over different and temporarily separate datasets.}

\ccsupdate{
In summary, we make the following contributions.
We devise a method to automate the construction of a graph around attack domains, enabling the identification of new ones. The guided graph expansion facilitates the creation of high-toxicity graphs in the ever-increasing utilization of shared hosting and reduces graph size significantly (around $5\%$ of the all-active-resolutions graph). \spupdate{With this targeted perspective, we detect malicious domains with a low FPR days to weeks ahead of popular detectors.} We construct representative benign and malicious ground truth, leading to accurately predicting the maliciousness of domains not seen in the input graph, which is often overlooked in domain classification. We apply inductive training that 
enables on-demand predictions, even when no labeled domain exists within the computation graph.
To enhance transparency and interoperability, we provide feature importance, shedding light on the significance of different feature categories and analyze our robustness. We build a sanity checking system to monitor the predicted malicious domains and show that \system serves as an early detection system. 
As a testament to its practicality and effectiveness, \system has been operational for over a year and detects $\sim$19K malicious domains (5 times more than VirusTotal malicious domains) daily at a low FPR of 0.1\%. 
}

\eat{
Our contributions are as follows:
\begin{itemize}[leftmargin=*]
\itemsep0em
    \item We design a graph-based malicious domain detection system that consistently demonstrates high average precision of 99\% and a low average FPR of 0.5\%.
    \item We construct representative benign and malicious ground truth for the model leading to accurately predicting the maliciousness of domains not seen in the input graph which is often overlooked in graph classification.    \item We build a practical system that has been operational since June 1st, 2022. \system detects $\sim$19K malicious domains at a low FPR of 0.1\% (5 times more than VirusTotal malicious domains) on a daily basis.
    \item We build a sanity-checking system to monitor the predicted malicious domains and show that \system predicts days to weeks ahead of popular detectors.
    \item We perform an in-depth analysis of the graph-based classifier and provide insights into its outcomes to better understand its design choices.\end{itemize}
}

\eat{
The rest of the paper is organized as follows. Section~\ref{sec:background} provides background information on GNNs, and data/intelligence sources utilized in this work. Section~\ref{sec:overview} provides an overview of our system, \system. \eat{We describe the process of compiling a representative ground truth dataset in Section~\ref{sec:gt}.} We describe our approach in detail in Section~\ref{sec:approach}. In Section~\ref{sec:classifier}, we perform an in-depth analysis of the classifier design choices. \eat{Further, we compare the chosen GNN model against the baseline models.} \eat{We describe our practical system \system in Section~\ref{sec:system}.} We perform an in-depth sanity check on the detected domains in Section~\ref{sec:post}. Section~\ref{sec:related} critically evaluates the works related to ours. We discuss the limitations of this work and possible remediation actions in Section~\ref{sec:limiations}. Finally, we conclude the paper in Section~\ref{sec:conclusion} summarizing the key findings and possible future directions.
}