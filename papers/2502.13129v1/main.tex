
\documentclass{article}

\usepackage[page,toc,titletoc,title]{appendix}

\newcommand{\theHalgorithm}{\arabic{algorithm}}

\usepackage[accepted]{icml2025}

\input{cmd.tex}
\usepackage[capitalize]{cleveref}
\crefname{ourcustomizedthrm}{Theorem}{Theorems}
\crefname{approximation}{Statement}{Statements}
\crefname{statement}{Statement}{Statements}
\crefname{goodthrm}{Theorem}{Theorems}
\usepackage{tcolorbox}

\usepackage[textsize=tiny]{todonotes}

\usepackage{microtype}
\usepackage{graphicx}
\usepackage{booktabs} 
\usepackage{hyperref}
\usepackage{amsmath}
\usepackage{amssymb}
\usepackage{mathtools}
\usepackage{amsthm}
\usepackage{svg}
\usepackage{overpic}


\newcommand{\tablestyle}[2]{\setlength{\tabcolsep}{#1}\renewcommand{\arraystretch}{#2}\centering\footnotesize}

\theoremstyle{plain}

\begin{document}

\twocolumn[
\icmltitle{Is Noise Conditioning Necessary for Denoising Generative Models?}

\icmlsetsymbol{equal}{*}

\begin{icmlauthorlist}
\icmlauthor{Qiao Sun}{equal,yyy}
\icmlauthor{Zhicheng Jiang}{equal,yyy}
\icmlauthor{Hanhong Zhao}{equal,yyy}
\icmlauthor{Kaiming He}{yyy}
\end{icmlauthorlist}

\icmlaffiliation{yyy}{MIT}

\icmlcorrespondingauthor{Qiao Sun}{sqa24@mit.edu}
\icmlcorrespondingauthor{Zhicheng Jiang}{jzc\_2007@mit.edu}
\icmlcorrespondingauthor{Hanhong Zhao}{zhh24@mit.edu}
\icmlcorrespondingauthor{Kaiming He}{kaiming@mit.edu}
\icmlkeywords{generative models, diffusion, flow matching, noise conditioning}

\vskip 0.2in
]

\printAffiliationsAndNotice{\icmlEqualContribution}


\begin{abstract}

It is widely believed that noise conditioning is indispensable for denoising diffusion models to work successfully. This work challenges this belief. Motivated by research on blind image denoising, we investigate a variety of denoising-based generative models in the absence of noise conditioning. To our surprise, most models exhibit graceful degradation, and in some cases, they even perform better without noise conditioning. We provide a theoretical analysis of the error caused by removing noise conditioning and demonstrate that our analysis aligns with empirical observations. We further introduce a noise-\textit{unconditional} model that achieves a competitive FID of 2.23 on CIFAR-10, significantly narrowing the gap to leading noise-conditional models. We hope our findings will inspire the community to revisit the foundations and formulations of denoising generative models.


\end{abstract}

\input{intro.tex}
\input{related.tex}
\input{formulation.tex}
\input{remove.tex}

\input{method.tex}
\input{conclusion.tex}

\bibliography{bibliography}
\bibliographystyle{icml2025}


\newpage
\appendix
\onecolumn
\input{appendix.tex}

\end{document}
\typeout{get arXiv to do 4 passes: Label(s) may have changed. Rerun}
