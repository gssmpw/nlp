\section{Preliminary}
\label{sec:3}
% 在本节，我们将分别定义实现高效CBE的三个要素：accuracy，convergence, scalability，并分析影响它们的要素。
In this section, we start by symbolically introducing the working process of CBE. Afterwards, we introduce the key objectives for achieving efficient CBE: accuracy, convergence, and scalability, and analyze the factors that influence them.
We mainly discuss the pair-wise evaluation scenario (where the judge provides preference between two models per time) for its wide applications \citep{paireval,allpair}. Actually, list-wise preferences can be easily converted into pair-wise ones, as demonstrated in \S\ref{sec:5.4-2}, so the discussions below are general for CBE.
% 考虑到pair-wise comparison（Judge每次给出对两个models的preference）是CBE的最典型场景，我们在本节围绕pair-wsie evaluation展开讨论。事实上，list-wise preference results可以轻松地转化成pair-wise，正如第三届所示的那样。
\subsection{Process of CBE}
%一个CBE method 可以被划分为三部分：preference allocation strategy, sampling strategy以及model score estimation strategy。
Generally, a CBE method $f$ can be divided into three parts: budget allocation strategy $f^{ba}$, tuple sampling strategy $f^{ts}$, and preference aggregation strategy $f^{pa}$.
Given benchmark $\mathcal{D}:s_{1:N}$ and models under evaluation $\mathcal{M}:m_{1:M}$, we iterate the following steps: 
\textit{step 1.} applying $f^{ba}$ to attain sampling matrix $P^l$ at iteration $l$, where $P_{i,j,k}^l$ denotes the probability to select tuple $(m_i,m_j,s_k)$ for judging; 
\textit{step 2.} applying $f^{ts}$ to sample certain tuple $(m^{l1},m^{l2},s^l)$ based on $P^l$; 
\textit{step 3.} attaining preference result $r^l$ from the judge, where $r^l \in [0,1]$ denotes the degree $m^{l1}$ wins over $m^{l2}$ (0.5 means tie). 
We stop this iterative process when the preset preference budget $T$ is achieved and then apply $f^{pa}$ on preference results $\{(m^{l1},m^{l2},s^l,r^l)\}_{l=1}^T$ to attain estimated model scores $u_{1:M}$.

\subsection{Accuracy}
\label{sec:3.2}
Theoretically, if we have a budget of $\hat{T}=\frac{NM(M-1)}{2}$, we can explore all tuples to obtain the ground truth estimation for the model scores $\hat{u}_{1:M}$. 
However, typically $T$ is much smaller than $\hat{T}$ in reality considering the preciousness of preference signals. 
% 然而，在现实中考虑到preference的珍贵性T通常远小于Y. 
Previous studies \citep{samplebias1,samplebias2} have discussed the risks of introducing sampling bias in incomplete sampling scenarios, which we believe could similarly lead to potential risks in CBE. % due to inappropriate $f^{ba}$. 
% 考虑到每次采样的内容是(ml-1, ml-2, sl)，我们认为sample bias存在两方面.
Considering that the content of each sample is $(m^{l1},m^{l2},s^l)$, we think the sample bias exists across both samples and models. 
% 首先，由于不同的模型可能擅长回答不同类型的问题，因此模型的能力值会随采样的sample而发生变化：

\begin{figure}[ht]
    \centering
    \subfigure[Sampling bias with different preference aggregation strategies across samples and models.]{
    \label{fig:bias1}
        \includegraphics[width=0.47\textwidth]{figs/score_bias2.pdf}
    }
    \hfill
    \subfigure[Interval distribution of bias across samples with $f^{pa}_{BT}$ as preference aggregation strategy.]{
    \label{fig:bias2}
        \includegraphics[width=0.48\textwidth]{figs/score_bias1.pdf}
    } \\
    \vspace{-0.2cm}
    \subfigure[Bias across models with $f^{pa}_{BT}$ as preference aggregation strategy.]{
    \label{fig:bias3}
        \includegraphics[width=0.95\textwidth]{figs/score_bias3.pdf}
    }
    \vspace{-0.2cm}
    \caption{Analyses of potential sampling bias risks in CBE.}
    \vspace{-0.4cm}
    \label{fig:samplebias}
\end{figure}


\paragraph{Bias across Samples.} Since different models may excel at answering different types of queries, the model scores can vary depending on the sampled data:
\begin{equation}
    \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ u_t=f^{pa}(\{(m_i,m_j,s_k,r_{i,j,k})\}_{i\in 1:M,j\in i+1:M})_t = \hat{u}_t + \eta_{m_t,\text{-},s_k} \ \ \ \ \ \ \ \ \ \ \ \ \text{for} \ \ \ \forall \  t,k
    \label{eq:1}
\end{equation}
% 为了验证this，我们在alpacaeval benchmark上以GPT-4o为judge，随机选择了20个模型进行了如下实验：
% 我们首先在每个sample上遍历所有的model pair得到对应的N组preference results。然后应用f计算相应的u，并计算u与s之间差值的绝对值，也即k，并取均值。
% s中提到的三种Preference Aggregation方法计算对应的
where $\eta_{m_t,\text{-},s_k}$ represents the bias between the observed model score $u_t$ of $m_t$ and the ground truth $\hat{u}_t$ when sorely assessing on sample $s_k$.
To verify this, we conduct experiments on the AlpacaEval benchmark \citep{alpacaeval} using GPT-4o \citep{4o} as the judge across randomly selected 20 LLMs (listed in Figure~\ref{fig:bias3}). We first traversed all model pairs for samples $s_{1:N}$ to obtain corresponding $N$ sets of preference results and then calculate the respective $|\eta_{m_i,\text{-},s_k}|$ for $\ i\in 1:M$ and $\ k\in 1:N$ according to~\eqref{eq:1} (model scores are normalized to an average of 1). We calculate the average value of $|\eta_{m_i,\text{-},s_k}|$ across models and samples using different preference aggregation strategies $f^{pa}$ discussed in \S\ref{sec:2-pa}. As shown in Figure~\ref{fig:bias1}, with all kinds of $f^{pa}$, the average difference between the model scores estimated on single sample and the ground truth values exceeds 0.25, indicating a significant bias across samples. We further analyze the proportion of samples with different biases using $f^{pa}_{BT}$ in Figure~\ref{fig:bias2} and find that they overall follow a Gaussian distribution, showing the wide existence of sample bias in CBE.
\paragraph{Bias across Models.} Just as humans may perform differently when facing different opponents, models may also have varying scores when competing against different models:
\begin{equation}
    \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ u_i=f^{pa}(\{(m_i,m_j,s_k,r_{i,j,k})\}_{k\in 1:N})_i = \hat{u}_i + \eta_{m_i,m_j,\text{-}} \ \ \ \ \ \ \ \ \ \ \ \ \text{for} \ \ \ \forall \  i,j
    \label{eq:2}
\end{equation}
We validate this from two perspectives:  
(1) We calculate the average $|\eta_{m_i,m_j,\text{-}}|$ according to~\eqref{eq:2} like the process above and show the results in Figure~\ref{fig:bias1}. Overall, although the bias across models is significantly lower than the bias across samples, it still exists at a scale around 0.05. We further visualize the pair-wise model score bias in Figure~\ref{fig:bias3} to validate its wide existence. 
(2) We obtain over 1.7 million pairwise preference results across 129 LLMs collected by Chatbot Arena \footnote{\url{https://storage.googleapis.com/arena_external_data/public/clean_battle_20240814_public.json}}. After excluding pairs with fewer than 50 comparisons, we calculate the pairwise win rates and find non-transitivity in 81 model triplets (win rate: $A > B$, $B > C$, $C > A$), which also verifies the existence of bias across models.

% 在



\paragraph{Uniform Allocation Brings the Least Bias.} 
Based on the discussions above, we analyze the budget allocation strategy that can introduce the least bias. 
Considering the presence of sampling bias, the estimation error of $u_i$ with $T$ evaluation budget can be expressed as follows:
%考虑到采样偏差的存在，在T次采样时，我们有以下equation：
\begin{equation}
    u_i-\hat{u}_i = \sum_{l=1}^T \1_{m^{l1}=m_i} \times \eta_{m^{l1},m^{l2},s^l}
    \label{eq:3}
\end{equation}

Considering that $u=\hat{u}$ when all the tuples are traversed, we have the following equation:
\begin{equation}
    \ \ \ \ \ \ \ \ \ \ 0 = u_i-\hat{u}_i = \sum_{j=1}^M\sum_{k=1}^N \eta_{i,j,k} \ \ \ \ \ \ \ \ \ \ \ \ \text{for} \ \ \ \forall \  i
    \label{eq:4}
\end{equation}
%此时获得最小的estimation error of $u_i$ 的目标转化为了从U个和为0的数中采样V个数，使这V个数的和的绝对值最小。
The goal of obtaining the minimum estimation error for $u_i$ is transformed into sampling \( T \) numbers (~\eqref{eq:3}) from \( MN \) numbers that sum to zero (~\eqref{eq:4}), such that the absolute value of the sum of these \( T \) numbers is minimized. We have provided a detailed proof in Appendix~\ref{app:proof} that the best strategy is completely uniform sampling. \textit{\textbf{This denotes that the score estimation error can be minimized when the preference budgets are uniformly distributed across models and samples to bring the least sampling bias.}}

% Given that $\sum_{i=1}^U X_i = 0$, we want to attain sampling set $\mathcal{S}$ that satisfies $|\mathcal{S}|=V$ and:
% \begin{equation}
%     \mathcal{S} = argmin_{\mathcal{S}} | \sum\limits_{i \in \mathcal{S}} X_i |
%     \label{eq-ap:1}
% \end{equation}
% It is easy to know that for any sampling set $\mathcal{S}$:
% \begin{equation}
%     \mathbb{E}[ \sum\limits_{i \in \mathcal{S}} X_i ]=0
%     \label{eq-ap:2}
% \end{equation}
% Thus, 
% \begin{equation}
%     \mathbb{E}[|\sum\limits_{i \in \mathcal{S}} X_i|] = \mathbb{E}[\mathrm{StdVar}[ \sum\limits_{i \in \mathcal{S}} X_i ]] =\mathbb{E}[  \sqrt{\mathrm{Var}[ \sum\limits_{i \in \mathcal{S}} X_i ]} ]
%     \label{eq-ap:3}
% \end{equation}
% Considering that:
% \begin{equation}
%     \mathrm{Var}[ \sum\limits_{i \in \mathcal{S}} X_i ] =  \sum\limits_{i \in \mathrm{set}(\mathcal{S})} c_i^2\mathrm{Var}(X_i)
%     \label{eq-ap:4}
% \end{equation}
% where $c_i$ denotes the number of $X_i$ in $\mathcal{S}$. On this basis, we derive that:
% \begin{equation}
% \begin{aligned}
%     \mathbb{E}[|\sum\limits_{i \in \mathcal{S}} X_i|] &= \sqrt{\mathbb{E}[\mathrm{Var}(X)]\sum\limits_{i \in \mathrm{set}(\mathcal{S})} c_i^2}\\
% &=\sqrt{\mathbb{E}[\mathrm{Var}(X)]}\sqrt{\sum\limits_{i \in \mathrm{set}(\mathcal{S})} c_i^2}\\
% &\geq \sqrt{\mathbb{E}[\mathrm{Var}(X)]}\sqrt{(\sum\limits_{i \in \mathrm{set}(\mathcal{S})} c_i)^2/|\mathrm{set}(\mathcal{S})|}\\
% &=V\sqrt{\mathbb{E}[\mathrm{Var}(X)]}\sqrt{ |\mathrm{set}(\mathcal{S})|^{-1} } \\
% &\geq V\sqrt{\mathbb{E}[\mathrm{Var}(X)]}\sqrt{\mathrm{min}(U,V)^{-1}}
% \end{aligned}
% \label{eq-ap:5}
% \end{equation}
% The equality condition of the first inequality is: the number of samples taken from each category is equal. The equality condition of the second inequality is: the number of sampled categories equals to $\mathrm{min}(U,V)$. These two conditions imply that a completely uniform sampling strategy is optimal.

% using $f^{pa}$ and compute the absolute difference between them and $\hat$, denoted as k, and took the average.
% 当T<T时，
% 
% 
\subsection{Convergence}
\label{sec:3.3}
% 在评测进行的过程中，随着新的preference results被观测到，模型间的胜负关系和对模型score的预估值都在发生变化。
During the evaluation process, as new preference results are continuously observed, the estimated values of the models win rate matrix and model scores also change constantly. 
To accelerate the convergence process, we analyze the uncertainty of the win rate matrix as follows.
Defining that:
\begin{equation}
    X^l_{i,j} = \frac{1}{P^l_{i,j}}r^l\1_{m^{l1}=m_i \And m^{l2}=m_j} + \frac{1}{P^l_{j,i}}(1-r^l)\1_{m^{l1}=m_j \And m^{l2}=m_i}
    \label{eq:6}
\end{equation}
The unbiased estimated win rate matrix $\Phi$ at iteration $L$ can be calculated as follows:
\begin{equation}
    \Phi^L = \frac{1}{L}\sum_{l=1}^L X^l
    \label{eq:7}
\end{equation}
We further estimate the variance matrix $\Theta$ as:
\begin{equation}
    \Theta^L = \frac{1}{L}\sum_{l=1}^L(X^l-\Phi^L)\circ (X^l-\Phi^L)
    \label{eq:8}
\end{equation}
Denoting if the model pair $(m_i,m_j)$ has been compared on sample $s_k$ after $l$ iterations as $C^l_{i,j,k}$, the uncertainty (standard deviation) of each element in the win rate matrix is as follows:
\begin{equation}
    \epsilon^l_{i,j} = \sqrt{\frac{\Theta^l_{i,j}}{\sum_{k=1}^{N} C^l_{i,j,k}}}
    \label{eq:9}
\end{equation}
Allocating the next preference budget on $(m_i,m_j)$ can reduce the uncertainty of their win rate by:
\begin{equation}
    \sqrt{\frac{\Theta^l_{i,j}}{\sum_{k=1}^{N} C^l_{i,j,k}}} - \sqrt{\frac{\Theta^l_{i,j}}{\sum_{k=1}^{N} C^l_{i,j,k}+1}}
    \label{eq:10}
\end{equation}
%在此基础上，考虑到我们的核心目标是对于所有的模型都进行准确的能力评估，因此我们需要globally平衡胜率矩阵不确定度的descent process以避免。
Considering that our core objective is to conduct accurate capability assessments for all models and estimate their ranking relationship, \textit{\textbf{we should globally ensure the uniformity of the win rate uncertainty matrix during its descending process to achieve smooth evaluation convergence}}.


\subsection{Scalability}
\label{sec:3.4}
Due to the continuous emergence of new LLMs, the demand for scalability in evaluation method is becoming increasingly prominent \citep{scalable}. 
Considering that we have evaluated $m_{1:M}$ with $T$ budgets, when model $m_{M+1}$ is introduced for assessment, a well-scalable CBE method should be able to quickly calibrate the capability estimates of $m_{1:M+1}$ with minimal additional preference budget. 
In this scenario, at the beginning stage when \( m_{M+1} \) is introduced, $\mathrm{avg}(C_{M+1,\text{-},\text{-}})$ is much smaller than $\mathrm{avg}(C_{\neq M+1,\text{-},\text{-}})$. 
According to~\eqref{eq:9}, the uncertainty at this point mainly arises from $\epsilon_{M+1}$, which is also intuitively easy to understand.
\textit{\textbf{Therefore, the key to improving scalability lies in allocating sufficient evaluation budgets to the newly added models to ensure
the uniform allocation among models, reducing the updating uncertainty.}}
%依据公式7可知此时评测的不确定性主要来自于对$m_{1:M+1}$，这也是直观上容易理解的。
%因此，提升可扩展性的关键在于sufficient evaluation budgets being allocated to new added models 从而快速减少更新带来的不确定性
% 


% 定义accuracy，convergence, scalability 
% 明确他们分别与sampling bias, observation variance, updating bias的关系
% 推导降低这三者的方法分别在于XXX