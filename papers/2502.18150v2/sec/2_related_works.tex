\section{Related works}
\label{sec:related}
\noindent{\textbf{3D human and object reconstruction:}
To reconstruct 3D human and object jointly, previous methods use parametric models to fit human and object meshes satisfying various constraints. PHOSA~\cite{zhang2020perceiving} and D3D-HOI~\cite{xu2021d3d} each proposed an optimization based framework with physical constraints on scale and predefined contact priors. 
Wang \emph{et al.}~\cite{wang2022reconstructing} modeled 3D human-object shapes from an image using commonsense knowledge from large language models. Holistic++~\cite{chen2019holistic++} modeled fine-grained human-object relations in a scene using Markov chain Monte Carlo method.  CHORE proposed to fit a parametric model to a learned neural-implicit functions. Vistracker~\cite{xie2023vistracker}, InterTrack~\cite{xie2024intertrack} reconstruct human-object from a single video, by specifically modeling the temporal context.
Recently, CONTHO~\cite{nam2024contho} proposed a method to refine human-object reconstruction from an image by 3D guided contact estimation.
ProciGen~\cite{xie2023template_free} proposed a Hierarchical Diffusion Model to reconstruct human and object. None of the current approaches for single-view human-object reconstruction can recover realistic clothed humans at the same fidelity as \name. Alternate methods~\cite{sun2021neural, jiang2022neuralhofusion, jiang2023instant, zhang2023neuraldome} that can reconstruct clothed human-object, either use sparse, multi-views or monocular RGBD image as inputs, thereby relaxing their constraints and are thus not comparable to our work.}
%We address the problem of jointly reconstructing realistic non-parametric clothed humans and objects from single images. 
%

\noindent{\textbf{Neural implicit model for single-view 3D reconstruction:}
Early reconstruction methods cannot produce realistic 3D shapes due to the discretized nature of traditional representations like voxels, meshes or point clouds. The introduction of the implicit representation for 3D reconstruction~\cite{mescheder2019occupancy, chen2019learning,park2019deepsdf} has led deep learning approaches to adopt this continuous representation because it can represent fine details on the reconstructed shapes. These works estimate the implicit representation with neural implicit models.
%
Several works have since used neural implicit models for object reconstruction from single images. Early models estimate occupancy~\cite{chen2019learning, mescheder2019occupancy} or signed distance fields~\cite{park2019deepsdf,xu2019disn,zhang2021generalized} using multi-layer perceptrons conditioned on input features. Recent works improve the object reconstruction by incorporating prior knowledge into implicit functions ~\cite{liu2019learning, chen2023g2ifu};
using monocular geometric cues ~\cite{yu2022monosdf}; combining explicit templates with implicit representations~\cite{fahim2022enhancing, wang2023ifkd} or leveraging input global and local features ~\cite{li2021d2im,arshad2023list}.
%
Other implicit models focus on reconstructing high-quality 3D human shapes from single images.  PIFu~\cite{pifu} introduced the pixel-aligned implicit function to retrieve detailed human shapes. Building on this, several works improved quality using normal maps~\cite{pifuhd, icon} or super-resolution shapes~\cite{surs}; addressed depth ambiguity using parametric models~\cite{pamir, geopifu}; achieved complete reconstructions with diffusion models~\cite{google1, google2, ho2024sith} or incorporating additional data as depth maps~\cite{econ, anim} or unconstrained images~\cite{cosmu}.
%to capture high-quality details in occluded regions of the body.
These works cannot jointly reconstruct human-object shapes since they are category-specific, with human-focused methods unable to reconstruct objects and vice-versa. \name jointly reconstructs realistic clothed humans and objects from a single image. }

