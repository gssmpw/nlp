% \begin{table*}[t]
% {\resizebox{1.0\textwidth}{!}{
% \begin{tabular}{lcccccccccccccccc}
% \toprule
% \multicolumn{1}{c}{\multirow{2}{*}{\textbf{Model}}} & \multirow{2}{*}{\begin{tabular}[c]{@{}c@{}}\textbf{Parameter}\\ \textbf{Scale}\end{tabular}}  & \multicolumn{5}{c}{\textbf{Multifacet}} & \multicolumn{9}{c}{\textbf{Unseen Benchmarks}} & \multirow{2}{*}{\textbf{Average}} \\ \cmidrule{3-7} \cmidrule{8-16} 
% \multicolumn{1}{c}{} &  & \multicolumn{1}{l}{\textbf{AE}} & \multicolumn{1}{l}{\textbf{FLASK}} & \multicolumn{1}{l}{\textbf{Ka}} & \multicolumn{1}{l}{\textbf{MB}} & \multicolumn{1}{l}{\textbf{SI}} & \multicolumn{1}{l}{\textbf{MMLU}} & \multicolumn{1}{l}{\textbf{MMLU-Pro}} & \multicolumn{1}{l}{\textbf{ARC-c}} & \multicolumn{1}{l}{\textbf{GPQA}} & \multicolumn{1}{l}{\textbf{HellaSwag}} & \multicolumn{1}{l}{\textbf{IFEVAL}} & \multicolumn{1}{l}{\textbf{MT-Bench}} & \textbf{MATH} & \textbf{BBH} & \\ \midrule
% Proprietary Models \\ \midrule
% GPT-3.5-Turbo-0125 & \xmark &  & & & &  &   & & & & & & &  &  &  \\ 
% GPT-4-0613 & \xmark &  & & & &  &   & & & & & & &  &  &  \\ 
% GPT-4-Turbo-0125 & \xmark &  & & & &  &   & & & & & & &  &  &  \\ \midrule
% Open-Source Models \\ \midrule
% LLaMA-3.1-8B-instruct & 8B & 4.26 & 3.82 & 4.29 & 4.15 & 4.06 &   & & & & & & &  &  &  \\ 
% Gemma-2-9B-instruct & 9B & 4.10 & 3.80 & 4.26 & 4.15 & 3.92 &   & & & & & & &  &  &  \\ 
% Mixtral-8x22B-instruct & 8x22B & 4.24 & 3.90 & 4.16 & 3.94 & 4.08 &   & & & & & & &  &  &  \\ 
% Solar-10.7b-instruct & 10.7B &  & & & &  &   & & & & & & &  &  &  \\ 
% Qwen2.5-14b-instruct & 14B & 4.37 & 4.07 & 4.37 & 4.27 & 4.21 &   & & & & & & &  &  &  \\  
% Phi-4 & 14B & 4.53 & 4.24 & 4.51 & 4.39 & 4.40 &   & & & & & & &  &  &  \\ \midrule
% Open-Source Models (with \textbf{\textsc{SysGen}}) \\ \midrule 
% LLaMA-3.1-8B-instruct & 8B &  & & & &  &   & & & & & & &  &  &  \\ 
% Gemma-2-9B-instruct & 9B &  & & & &  &   & & & & & & &  &  &  \\ 
% Mixtral-8x22B-instruct & 8x22B &  &  &  &  &  &   & & & & & & &  &  &  \\ 
% Solar-10.7b-instruct & 10.7B &  & & & &  &   & & & & & & &  &  &  \\ 
% Qwen2.5-14b-instruct & 14B &  & & & &  &   & & & & & & &  &  &  \\  
% Phi-4 & 14B &  & & & &  &   & & & & & & &  &  &  \\ 
% \bottomrule
% \end{tabular}}}
% \caption{Main Experiment Table. Multifacet}
% \label{tab:main_experiments}
% \end{table*}

% \begin{table*}[t]
% \centering
% {\resizebox{0.95\textwidth}{!}{
% \begin{tabular}{lccccccc}
% \toprule
% \multicolumn{1}{c}{\multirow{2}{*}{\textbf{Model}}} & \multirow{2}{*}{\begin{tabular}[c]{@{}c@{}}\textbf{Parameter}\\ \textbf{Scale}\end{tabular}}  & \multicolumn{5}{c}{\textbf{Multifacet}} & \multirow{2}{*}{\textbf{Average}} \\ \cmidrule{3-7}  
% \multicolumn{1}{c}{} &  & \multicolumn{1}{l}{\textbf{AlpacaEval}} & \multicolumn{1}{l}{\textbf{FLASK}} & \multicolumn{1}{l}{\textbf{Koala}} & \multicolumn{1}{l}{\textbf{MT-Bench}} & \multicolumn{1}{l}{\textbf{Self-Instruct}} & \\ \midrule
% \textit{Proprietary Models} \\ \midrule
% GPT-3.5-Turbo-0125$\dagger$ & \xmark & 4.05 & 3.86 & 4.15 & 3.87 & 3.85 & 3.91  \\ 
% GPT-4-0613$\dagger$ & \xmark & 4.25 & 4.00 & 4.18 & 4.16 & 4.13  & 4.10  \\ 
% GPT-4-Turbo-0125$\dagger$ & \xmark & 4.45 & 4.27 & 4.61 & 4.45 & 4.27 & 4.35  \\  \midrule
% \textit{Open-Source Models} \\ \midrule
% Solar-10.7B-instruct & 10.7B & 3.30 & 3.31 & 3.09 & 3.19 & 3.08 & 3.19  \\  
% Gemma-2-9B-instruct & 9B & 4.10 & 3.80 & 4.26 & 4.15 & 3.92 & 4.05  \\ 
% LLaMA-3.1-8B-instruct & 8B & 4.26 & 3.82 & 4.29 & 4.15 & 4.06 & 4.12 \\ 
% % Mixtral-8x22B-instruct & 8x22B & 4.24 & 3.90 & 4.16 & 3.94 & 4.08 & 4.06 \\ 
% Qwen2.5-14B-instruct & 14B & 4.37 & 4.07 & 4.37 & 4.27 & 4.21 & 4.26 \\  
% Phi-4 & 14B & 4.53 & 4.24 & 4.51 & 4.39 & 4.40 & 4.41  \\
% \midrule
% \multicolumn{8}{l}{\textit{Open-Source Models (with \textbf{\textsc{SysGen}})}} \\
% \midrule 
% LLaMA-3.1-8B-instruct & 8B & 4.38 & 3.95 & 4.41 & 4.22 & 4.11 & 4.21 (+0.09) \\ 
% % Gemma-2-9B-instruct & 9B &  & & & &  &   \\ 
% % Mixtral-8x22B-instruct & 8x22B &  & & & &  &   \\ 
% % Solar-10.7B-instruct & 10.7B &  & & & &  &   \\ 
% Qwen2.5-14B-instruct & 14B & 4.40 & 4.11 & 4.42 & 4.22 & 4.25 & 4.28 (+0.02) \\ 
% Phi-4 & 14B & 4.62 & 4.63 & 4.52 & 4.44 & 4.49 & 4.54 (+0.13) \\ \midrule
% \multicolumn{8}{l}{\textit{Open-source Models} $+$ \textit{Knowledge Distillation (with \textbf{\textsc{SysGen}})}} \\
% \midrule 
% Gemma-2-9B-instruct & 9B & 4.40 & 4.04 & 4.30 & 4.23 & 4.18 & 4.23 (+0.18) \\ 
% Solar-10.7B-instruct & 10.7B & 3.97 & 3.73 & 3.64 & 3.98 & 3.52 & 3.76 (+0.57) \\ 
% \bottomrule
% \end{tabular}}}
% \caption{Multifacet benchmark evaluates how well a model aligns with both the system message and user instruction when generating responses. We provide baseline models (proprietary and open-source), models that trained on data generated using \textsc{SysGen}, and models trained via knowledge distillation using Phi-4 generated data. A higher score is better and the maximum score is up to 5.}
% \label{tab:main_experiments}
% \end{table*}

\begin{table*}[t]
\centering
{\resizebox{0.95\textwidth}{!}{
\begin{tabular}{lccccccc}
\toprule
\multicolumn{1}{c}{\multirow{2}{*}{\textbf{Model}}} & \multirow{2}{*}{\begin{tabular}[c]{@{}c@{}}\textbf{Parameter}\\ \textbf{Scale}\end{tabular}}  & \multicolumn{5}{c}{\textbf{Multifacet}} & \multirow{2}{*}{\textbf{Average}} \\ \cmidrule{3-7}  
\multicolumn{1}{c}{} &  & \multicolumn{1}{l}{\textbf{AlpacaEval}} & \multicolumn{1}{l}{\textbf{FLASK}} & \multicolumn{1}{l}{\textbf{Koala}} & \multicolumn{1}{l}{\textbf{MT-Bench}} & \multicolumn{1}{l}{\textbf{Self-Instruct}} & \\ \midrule
\textit{Proprietary Models} \\ \midrule
GPT-3.5-Turbo-0125$\dagger$ & \xmark & 4.05 & 3.86 & 4.15 & 3.87 & 3.85 & 3.91  \\ 
GPT-4-0613$\dagger$ & \xmark & 4.25 & 4.00 & 4.18 & 4.16 & 4.13  & 4.10  \\ 
GPT-4-Turbo-0125$\dagger$ & \xmark & 4.45 & 4.27 & 4.61 & 4.45 & 4.27 & 4.35  \\  \midrule
\textit{Open-Source Models} \\ \midrule
% Solar-10.7B-instruct & 10.7B & 3.30 & 3.31 & 3.09 & 3.19 & 3.08 & 3.19  \\  
% Gemma-2-9B-instruct & 9B & 4.10 & 3.80 & 4.26 & 4.15 & 3.92 & 4.05  \\ 
LLaMA-3.1-8B-instruct & 8B & 4.26 & 3.82 & 4.29 & 4.15 & 4.06 & 4.12 \\ 
% Mixtral-8x22B-instruct & 8x22B & 4.24 & 3.90 & 4.16 & 3.94 & 4.08 & 4.06 \\ 
Qwen2.5-14B-instruct & 14B & 4.37 & 4.07 & 4.37 & 4.27 & 4.21 & 4.26 \\  
Phi-4 & 14B & 4.53 & 4.24 & 4.51 & 4.39 & 4.40 & 4.41  \\
\midrule
\multicolumn{8}{l}{\textit{Open-Source Models (Fine-tuning on \textbf{\textsc{SysGen}} dataset)}} \\
\midrule 
LLaMA-3.1-8B-instruct & 8B & 4.38 & 3.95 & 4.41 & 4.22 & 4.11 & 4.21\\ 
% Gemma-2-9B-instruct & 9B &  & & & &  &   \\ 
% Mixtral-8x22B-instruct & 8x22B &  & & & &  &   \\ 
% Solar-10.7B-instruct & 10.7B &  & & & &  &   \\ 
Qwen2.5-14B-instruct & 14B & 4.40 & 4.11 & 4.42 & 4.22 & 4.25 & 4.28\\ 
Phi-4 & 14B & 4.62 & 4.63 & 4.52 & 4.44 & 4.49 & 4.54 \\ 
% \midrule
% \multicolumn{8}{l}{\textit{Open-source Models} $+$ \textit{Knowledge Distillation (with \textbf{\textsc{SysGen}})}} \\
% \midrule 
% Gemma-2-9B-instruct & 9B & 4.40 & 4.04 & 4.30 & 4.23 & 4.18 & 4.23 (+0.18) \\ 
% Solar-10.7B-instruct & 10.7B & 3.97 & 3.73 & 3.64 & 3.98 & 3.52 & 3.76 (+0.57) \\ 
\bottomrule
\end{tabular}}}
\caption{Multifacet benchmark evaluates how well a model aligns with both the system message and user instruction when generating responses. We provide baseline models (proprietary and open-source), models that trained on data generated using \textsc{SysGen}. A higher score is better and the maximum score is up to 5. $\dagger$ signifies the results were taken from the Multifacet~\citep{lee2024aligning} paper.}
\label{tab:main_experiments}
% \vspace{-0.5cm}
\end{table*}