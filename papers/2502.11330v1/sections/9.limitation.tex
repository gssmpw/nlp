\section*{Limitations}
While our \textsc{SysGen} pipeline demonstrates promising results in system messages alignment to the user instructions through Multifacet dataset.
However, our data construction pipeline only considers the single-turn conversation without handling multi-turn conversations~\citep{qin2024sysbench}.
We acknowledge that it is important for system messages to remain effective throughout multi-turn conversations, but our study focuses on evaluation and simple level of inference usage.

Additionally, our experimental results reveal that training with \textsc{SysGen} data shows minimal performance degradation on unseen benchmark, Open LLM Leaderboard 2 dataset.
However, we suspect that the observed performance drop may be due to the format of natural text that the SFT datasets we selected, rather than formats similar to multiple-choice questions commonly found in the unseen benchmark. 
Therefore, we are curious about how well the system messages could be generated in various formats such as True/False questions or Multiple Choice questions and prove its effectiveness.

Finally, in Table~\ref{app:tag_statistics}, we identify the special tokens of tags which are annotated to the publicly avaiable data.
The <<Tool>> tag has been absolutely shown small portion compared to other tags.
Our initial intention was to utilize the tag for generating data through search functionality or function calls. 
However, the selected public data deviated from this purpose, resulting in a very low proportion of the tag being generated.
Therefore, it would be beneficial to gather and generate data appropriately for each tag's intended use.