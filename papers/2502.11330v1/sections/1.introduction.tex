\section{Introduction}
% Post-training techniques enable large language models (LLMs) to align more closely with human preferences~\citep{askell2021general, bai2022training, bai2022constitutional}.
% These techniques involve augmenting and constructing training data to improve understanding of the target task through supervised fine-tuning (SFT), as well as performing alignment tuning to meet task-specific intentions~\citep{wang2022self, chung2024scaling, rafailov2024direct}.
% However, the development processes make LLMs face several challenges.
% These include insufficient data for target tasks and the need for effective training methods to ensure that the model accurately follows user instructions~\citep{xie2020unsupervised, ouyang2022training, zhou2023instruction, cui2023ultrafeedback, xu2023parameter, pareja2024unveiling}.

\input{figure/motivation_figure}

% 정의, 언제 사용해야하는가, 왜 사용해야하는가
% To address the limitations, we focus on using a system message.
System message, also known as initial prompt, serves as an initial input to start a conversation with LLMs~\citep{openai2024function, cohere2024,  prompthub2025}.
% system message가 user intention에 부합하게 사용되는 점, initial input으로 활용되는 예시, system message가 있을 때의 지켜져야 할 safety and harmlessness responses
They have been shown to greatly affect model's assistant responses by providing contexts, guidances, and directions to LLMs~\citep{qin2024sysbench, lee2024aligning}.
% The system messages can provide contexts, guidances, and directions to LLMs, greatly affecting assistant responses~\citep{qin2024sysbench, lee2024aligning}.
For example, given a system message, we can steer the LLM's behavior to set roles, provide the additional background information, maintain consistency of generated responses, customize a format, align to user preferences, and ensure safety and ethical considerations~\cite{alkhamissi2024investigating, yang2024qwen2, dubey2024llama}.
System messages have proven capable of setting constraints such as knowledge cut-off and current  date or when different model behaviors need to be tailored for optimal overall performance~\citep{lin2024baichuan, abdin2024phi}.


While LLMs' capabilities of utilizing the system messages is widely investigated, how to acquire these system messages is underexplored.
Our preliminary analysis has shown the following limitations about system messages in datasets.
Most publicly available datasets have license constraints when used in the industry field, limiting their use in post-training techniques for target tasks~\citep{xie2020unsupervised, ouyang2022training, zhou2023instruction, cui2023ultrafeedback}. 
Additionally, most datasets either lack system messages or contain the common system messages such as ``You are a helpful AI assistant.''~\citep{xu2023parameter, pareja2024unveiling}.
Lastly, labeling system messages to fit various user instruction scenarios requires substantial resources~\citep{abdin2024phi, qin2024sysbench, lee2024aligning}.


% system message를 license-free 상황에서 사용하기 위한 방법
In this study, we propose \textbf{\textsc{SysGen}}, a data construction pipeline that generates system messages using open-source models with well-aligned assistant responses from existing SFT datasets without system messages.
Our \textsc{SysGen} pipeline addresses the above limitations by automatically generating diverse system messages with open-source models that are not only well-aligned with user instructions but also avoid infringement of license constraints.
Specifically, our \textsc{SysGen} pipeline provides the phrase level of system messages according to each key functionality, tailored to various user instructions~\citep{alkhamissi2024investigating, jiang2024evaluating, qian2024tell, lee2024aligning}.
Figure~\ref{fig:motivation_figure} illustrates the key concept of our \textsc{SysGen} pipeline.
% We manually divide eight key functionalities to annotate phrases in system message: tasks, tools, style, format, action, content, background, and role~\citep{alkhamissi2024investigating, jiang2024evaluating, qian2024tell, lee2024aligning}.

We generate system messages by annotating these key functionalities at the phrase level, making it easy to track which features are lacking and working effectively (Sec~\ref{sysgen:system_generation}).
% We then filter out the incorrect special tokens generated through open-source LLMs and reorganize the generated system message (Sec~\ref{sysgen:filtering}).
Erroneous special tokens are then filtered out before reorganizing the generated system message into a consistent order (Sec~\ref{sysgen:filtering}).
%We then filter out the incorrect special tokens and reorganize the generated system message (Sec~\ref{sysgen:filtering}).
% By verifying through self LLM-as-a-judge~\citep{zheng2023judging} that which functionality phrase and tag are generated well, we softly remove abnormal phrases of functionalities (Sec~\ref{sysgen:verification}).
By verifying each functionality of the system messages with LLM-as-a-judge approach~\citep{zheng2023judging} as a self-model feedback, we softly remove abnormal phrases of functionalities (Sec~\ref{sysgen:verification}).
We generate new assistant responses which are better aligned with a refined system message and user instruction.
Our new responses also exhibit higher lexical overlap, semantic similarities, and verbosity than the original assistant responses (Sec~\ref{sysgen:answer_generation}).

% To address augmenting data containing system role without making major changes, we add system messages to widely-used SFT dataset that lacks of system message.
% We use open-source models to generate a system message and a better aligned assistant response and observe that newly-generated responses exhibit higher lexical overlap, semantic similarities, and verbosity compared to original assistant repsonses.

% We use Multifacet~\citep{lee2024aligning} dataset to measure how well assitant responses align with system messages and user instructions.
After training various open-source models on \textsc{SysGen} data, we evaluated the models on the Multifacet~\citep{lee2024aligning} dataset to measure how well the assistant responses align with system messages and user instructions.
Our experiments have shown consistent improvement across various models, notably LLaMA-3.1-8B-instruct~\citep{meta2024introducing} and Phi-4~\citep{abdin2024phi} models achieving +0.9, +0.13 absolute improvements, respectively.
% For models that do not support system roles, such as Gemma-2-9b-it~\citep{team2024gemma}, or models like Solar-10.7B-instruct~\citep{kim-etal-2024-solar} that have not been trained on system roles, knowledge distillation~\citep{hinton2015distilling} using data generated by the Phi-4 model through our \textsc{Sysgen} pipeline resulted in absolute improvements of +0.18 and +0.57, respectively.
For models that do not support system roles, such as Gemma-2-9b-it~\citep{team2024gemma}, or have not been trained on system roles, such as Solar-10.7B-instruct~\citep{kim-etal-2024-solar}, knowledge distillation~\citep{hinton2015distilling} using \textsc{SysGen} data generated by the Phi-4 model resulted in absolute improvements of +0.18 and +0.57, respectively.
In addition, our experiments reveal that training on \textsc{SysGen} data can effectively reduce performance degradation on unseen benchmarks, Open LLM Leaderboard 2~\citep{myrzakhan2024open}.

Our analysis highlights that training open-source models with system messages tailored to diverse contexts is significantly more beneficial to align user instructions than using a common system message (e.g., "You are a helpful AI assistant") or not providing a system message.
We also demonstrate that distinguishing the system and user roles in the chat template is crucial for assistant responses to align user instructions.
We further provide LLM-as-a-judge result to verify that new assistant responses are truly aligned to the generated system messages.

% The main goal of \textsc{SysGen} is to add system messages to the SFT dataset consisting solely of pairs of questions and assistant responses.
% After generating system message given the question and response pair, we then generates additional assistant response based on the created system message, followed by filtering and validation process.
% The main contribution of the \textsc{SysGen} pipeline is that it does not degrade performance based on the metrics used to evaluate the existing question-response pairs, while still leveraging the benefits of system messages.


% We use two system-related benchmarks to analyze system message following abilities: SysBench~\citep{} and Multifacet~\citep{}.
% We observe that the \textsc{SysGen} truly generates the diverse situation of system message and its corresponding assistant response which enhances up to x.xx\% (SysBench) and x.xx\% (Multifacet) on average.
% Additionally, we use the Open LLM Leaderboard 2 benchmark~\citep{} to verify that there is no performance degradation when system messages are added to the existing SFT data in unseen evaluation scenarios.
% Furthermore, when synthesizing a new assistant response with the added system message, the new response shows more fluent and diverse while preserving semantically and synthetically similar to the current response.
% % ablation study 진행하고 결과 작성
% Our ablation studies demonstrate that each key feature highly affects the LLM's behavior in overall response quality.
 
