\section{\textsc{SysGen}: Pipeline of System and Assistant Response Generation}
Our \textbf{\textsc{SysGen}} pipeline consists of four phases: (1) generating system messages with eight key functionalities (Sec~\ref{sysgen:system_generation}), (2) filtering mis-specified system tags and reorganizing them (Sec~\ref{sysgen:filtering}), (3) verifying the key functionalities on a phrase level (Sec~\ref{sysgen:verification}), (4) generating the new assistant responses using the refined system messages and original user instructions (Sec~\ref{sysgen:answer_generation}).
Figure~\ref{fig:data_construction} depicts the overall architecture of the \textsc{SysGen} pipeline. 

\subsection{Phase 1: System Message Generation}
\label{sysgen:system_generation}
% The primary goal of our \textbf{\textsc{SysGen}} pipeline is to generate the system messages that are not included in the original SFT dataset.
The primary goal of our \textbf{\textsc{SysGen}} pipeline is to enhance existing SFT datasets by adding system messages that were not originally included.
% During the process of developing and releasing LLMs, license constraints inevitably arise, making it difficult to utilize most publicly available data.
As the system messages can steer the LLM's behaviors, we focus on these messages during the development and release of the models.
%The system messages can steer the LLM's behaviors, so we focus on these messages during the development and release of the models.
However, license constraints and substantial resource requirements of manually labeling the system messages inevitably arise, making it difficult to utilize most publicly available datasets.
Thus, we aim to generate system messages by leveraging open-source models and data without any license issues.
% We focus on system messages because they can control the LLM's behavior, set roles, provide additional background contexts, and maintain consistent responses.

\paragraph{Phrase level Annotation to System Messages}
% eight key features 나열, 하는 역할 제공 및 어떻게 annotate하고 이를 verify하는지
We manually classify eight functionalities that are widely used in the system messages referring to previous works~\citep{openai2024function, cohere2024, alkhamissi2024investigating,lee2024aligning}: 
(1) Specifies the role, profession, or identity that needs to be played (Role);
(2) Specifies the content that needs to be included in the response such as an identity of the company (Content);
(3) Identifies what to perform (Task);
(4) Specifies the behavior to perform (Action);
(5) Prefers the style of communication for responses (Style);
(6) Provides additional information to be served as an assistant (Background);
(7) Provides built-in methods to use (Tool); 
(8) Preference of what output should look like (Format).


As shown in Figure~\ref{fig:data_construction} (top left), all functionalities are annotated at a phrase level with pre-/post-fix tags. 
Given a pair of user instructions $\mathcal{Q}$ and assistant responses $\mathcal{A}$, we generate a system message $\mathcal{S}$ using the open-source LLMs $\mathcal{M}$ with a prompt $\mathcal{P}$ that includes few-shot demonstrations:
\begin{equation}
    \mathcal{M}(\mathcal{S}|\mathcal{P},\mathcal{Q},\mathcal{A})
\end{equation}
We provide details about the few-shot demonstrations in the Appendix~\ref{app:prompt}.


\subsection{Phase 2: Filtering Process}
\label{sysgen:filtering}
After generating the system messages, we filter out the abnormal system messages for consistent text format.
In Figure~\ref{fig:data_construction} (top right), we first identify and remove mis-tagged phrases.
% For example, if the start token is set as <<Task>> but the end token is set as <<Format>>, then we cannot guarantee the phrase between these tokens corresponds to <<Task>> or <<Format>>.
For example, we can guarantee the correctness of the phrases between these tokens only if the start and end tokens are the same (e.g., <<Task>>).
% For example, if the start and end tokens are the same (e.g., <<Task>>), then we can guarantee the correctness of the phrases between these tokens.
In addition, we remove invalid tags such as <<Example>> or <<System>>, which may be generated in phase 1.
To ensure a consistent structure of system messages, we reorder the tags and phrases in manually defined order.

\input{table/answer_quality}

\subsection{Phase 3: Verification of Eight Key Functionalities}
\label{sysgen:verification}
In this phase, we verify whether each generated phrase is appropriate for its assigned tag. 
Using the LLM-as-a-judge~\citep{zheng2023judging} approach with self-model feedback, we assign one of three labels for each tag: \textit{Good} if the tagging is appropriate, \textit{Bad} if the tagging is inappropriate, and \textit{None} if the tag or phrases are missing.
Phrases labeled as \textit{Bad} or \textit{None} are then removed from the system message to ensure accuracy and consistency.
We observe that most of the data instances (up to 99\%) are preserved after applying phase 3.
% In Figure~\ref{}, we provide the filtered statistics of the phase 2 \& 3.


\subsection{Phase 4: Assistant Response Generation}
\label{sysgen:answer_generation}
% remove annotated tags for naturality
After filtering and verifying the generated system messages, they can be used alongside existing QA pairs.
However, we hypothesize that if there is any potential misalignment between the human curated QA and model-generated system messages, a follow-up data alignment phase is necessary.
% However, our experimental results reveal that training LLMs on existing QA pairs with generated system messages leads to little to no improvement in benchmarks evaluating system message alignment such as Multifacet~\citep{lee2024aligning}.
% The performance degradation has also been observed in unseen benchmarks such as Open LLM Leaderboard 2~\citep{myrzakhan2024open}.
% Therefore, we hypothesize that we have to generate new assistant responses $\mathcal{A'}$ based on a refined system messages $\mathcal{S}$ and the user instructions $\mathcal{Q}$, ensuring better alignment with the given instructions.
Therefore, we generate new assistant responses $\mathcal{A'}$ based on a refined system messages $\mathcal{S}$ and the user instructions $\mathcal{Q}$, ensuring better alignment with the given instructions.
%Therefore, it is necessary to generate new assistant responses $\mathcal{A'}$ based on a refined system message $\mathcal{S}$ and the user's original instruction $\mathcal{Q}$.

% answer generation with system message and original query
To achieve this, we first remove the annotated tags from the system messages to guarantee that the refined messages seem natural.
We provide a detailed example in Figure~\ref{fig:data_construction} (bottom right).
Then, we use the open-source LLMs $\mathcal{M}$ employed in phase 1 to generate new responses $\mathcal{A'}$.
\begin{equation}
    \mathcal{M}(\mathcal{A'}|\mathcal{S},\mathcal{Q})
\end{equation}
% how answer could be diversified and preserved compared to original answer
In Table~\ref{tab:statistics_generated_answer}, the new responses preserve similar content with high n-gram matching compared to the original responses, but have shown diversified formats with high semanticity and verbosity.
We provide the cases in Appendix~\ref{app:qualitative_analysis}.

\input{figure/answer_comparison}

% LLM-as-a-judge to verify new answer is preferred
We also use LLM-as-a-judge with GPT-4o to analyze that the new responses $\mathcal{A'}$ are better aligned to the user instructions than the original responses $\mathcal{A}$.
Figure~\ref{fig:answer_comparison} illustrates the proportion of cases where the new responses are judged to be better aligned than the original responses when given the user instructions.
For simpler evaluation, we evaluated 1K randomly sampled instances from the generated datasets.
Overall, our findings suggest that generating responses based on the system messages lead to better alignment with user instructions.
% Additionally, our experiments show that models trained with both the system messages and the new responses achieve quantifiable performance improvements, highlighting the importance of generating new responses.