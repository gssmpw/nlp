\section{Conclusions}
In this paper, we propose AproMFL, a client-adaptive prototype-based MFL framework for mixed modalities and heterogeneous tasks. The framework aligns local modality knowledge with global modality knowledge through global prototypes and global models, improving the performance and generalization ability of client models.
In AproMFL, clients select the appropriate prototype construction method according to the task, without requiring unified label information. To aggregate the mixed-modality prototypes from different clients, the server unifies unimodality prototypes into multimodal prototypes through semantic completion, and then derives global prototype pairs via multimodal clustering. To reduce performance degradation from model aggregation in heterogeneous task scenarios, we propose relationship graph-based model aggregation method. 
The aggregated prototypes and models regularize local model updates. During training, the model is divided into modules, with clients sending only the mapping module to the server, reducing communication and computation overhead. Experimental results demonstrate that AproMFL effectively facilitates collaborative training of clients with mixed modalities and task heterogeneity, achieving superior performance with smaller models.