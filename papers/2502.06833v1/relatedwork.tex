\section{Related Work}
\subsection{Uncertainty Estimation in Language Models}
Uncertainty estimation in neural language models has been extensively studied through various lens, with entropy in logit distributions emerging as a key metric. Early work by \cite{shannon_prediction_1951} established the connection between entropy and predictability in natural language, while more recent studies have applied these insights to neural models. The use of entropy as an uncertainty metric has found applications beyond pure measurement. \cite{holtzman_curious_2020} showed that locally dynamic temperature sampling based on entropy can improve generation quality. \cite{meister_locally_2023} used entropy in beam search to better balance exploration and exploitation during decoding. These works establish entropy as a reliable proxy for generation difficulty, though they primarily focus on improving quality rather than computational efficiency.
\subsection{Speculative Decoding}
Speculative decoding has emerged as a promising approach for accelerating language model inference. The technique was first introduced by \cite{leviathan_fast_2023}. Their key insight was that smaller helper models could predict multiple tokens in parallel, with verification against a larger target model ensuring output quality. The Medusa architecture \citep{cai_medusa_2024} attached specialized prediction heads to existing models rather than using separate helper models. These approaches all maintain perfect output equivalence with the target model through verification mechanisms, prioritizing quality over potential computational savings.
\subsection{Adaptive Computation in Language Models}
The concept of dynamically adjusting computational resources has precedent in language model research. \cite{chen_ee-llm_2024} proposed early-exit transformers that could terminate computation at different layers based on confidence thresholds. These approaches typically focus on layer-wise adaptivity within a single model rather than switching between models of different sizes. There has also been work on switching between different smaller models that are tuned to specific tasks to save compute \cite{simonds_modem_2024}'s. Our work bridges these research areas by using entropy-based uncertainty estimation to guide adaptive model switching during generation. Unlike previous approaches that maintain perfect output equivalence or adapt computation within a single model, we explore the novel direction of allowing controlled output divergence in exchange for computational benefits.