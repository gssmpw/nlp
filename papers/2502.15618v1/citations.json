[
  {
    "index": 0,
    "papers": [
      {
        "key": "yuan2021mest",
        "author": "Yuan, Geng and Ma, Xiaolong and Niu, Wei and Li, Zhengang and Kong, Zhenglun and Liu, Ning and Gong, Yifan and Zhan, Zheng and He, Chaoyang and Jin, Qing and others",
        "title": "Mest: Accurate and fast memory-economic sparse training framework on the edge"
      }
    ]
  },
  {
    "index": 1,
    "papers": [
      {
        "key": "lecun1989optimal",
        "author": "LeCun, Yann and Denker, John and Solla, Sara",
        "title": "Optimal brain damage"
      },
      {
        "key": "hassibi1993optimal",
        "author": "Hassibi, Babak and Stork, David G and Wolff, Gregory J",
        "title": "Optimal brain surgeon and general network pruning"
      },
      {
        "key": "han2015learning",
        "author": "Han, Song and Pool, Jeff and Tran, John and Dally, William",
        "title": "Learning both weights and connections for efficient neural network"
      },
      {
        "key": "mushtaq2021spider",
        "author": "Mushtaq, Erum and He, Chaoyang and Ding, Jie and Avestimehr, Salman",
        "title": "Spider: Searching personalized neural architecture for federated learning"
      },
      {
        "key": "li2021ell",
        "author": "Li, Gen and Gu, Yuantao and Ding, Jie",
        "title": "L1 Regularization in Two-Layer Neural Networks"
      },
      {
        "key": "soltani2021information",
        "author": "Soltani, Mohammadreza and Wu, Suya and Ding, Jie and Ravier, Robert and Tarokh, Vahid",
        "title": "On the information of feature maps and pruning of deep neural networks"
      },
      {
        "key": "yang2022theoretical",
        "author": "Yang, Wenjing and Wang, Ganghua and Ding, Jie and Yang, Yuhong",
        "title": "A theoretical understanding of neural network compression from sparse linear approximation"
      },
      {
        "key": "diao2023pruning",
        "author": "Diao, Enmao and Wang, Ganghua and Zhan, Jiawei and Yang, Yuhong and Ding, Jie and Tarokh, Vahid",
        "title": "Pruning deep neural networks from a sparsity perspective"
      },
      {
        "key": "liu2023sparsity",
        "author": "Liu, Shiwei and Chen, Tianlong and Zhang, Zhenyu and Chen, Xuxi and Huang, Tianjin and Jaiswal, Ajay and Wang, Zhangyang",
        "title": "Sparsity May Cry: Let Us Fail (Current) Sparse Neural Networks Together!"
      },
      {
        "key": "li2024adaptive",
        "author": "Li, Wei and Li, Lujun and Lee, Mark and Sun, Shengjie",
        "title": "Als: Adaptive layer sparsity for large language models via activation correlation assessment"
      },
      {
        "key": "li2024discovering",
        "author": "Li, Lujun and Dong, Peijie and Tang, Zhenheng and Liu, Xiang and Wang, Qiang and Luo, Wenhan and Xue, Wei and Liu, Qifeng and Chu, Xiaowen and Guo, Yike",
        "title": "Discovering Sparsity Allocation for Layer-wise Pruning of Large Language Models"
      },
      {
        "key": "dong2024pruner",
        "author": "Dong, Peijie and Li, Lujun and Tang, Zhenheng and Liu, Xiang and Pan, Xinglin and Wang, Qiang and Chu, Xiaowen",
        "title": "Pruner-Zero: Evolving Symbolic Pruning Metric from Scratch for Large Language Models"
      }
    ]
  },
  {
    "index": 2,
    "papers": [
      {
        "key": "li2016pruning",
        "author": "Li, Hao and Kadav, Asim and Durdanovic, Igor and Samet, Hanan and Graf, Hans Peter",
        "title": "Pruning filters for efficient convnets"
      },
      {
        "key": "liu2017learning",
        "author": "Liu, Zhuang and Li, Jianguo and Shen, Zhiqiang and Huang, Gao and Yan, Shoumeng and Zhang, Changshui",
        "title": "Learning efficient convolutional networks through network slimming"
      },
      {
        "key": "he2019filter",
        "author": "He, Yang and Liu, Ping and Wang, Ziwei and Hu, Zhilan and Yang, Yi",
        "title": "Filter pruning via geometric median for deep convolutional neural networks acceleration"
      },
      {
        "key": "diao2020drasic",
        "author": "Diao, Enmao and Ding, Jie and Tarokh, Vahid",
        "title": "Drasic: Distributed recurrent autoencoder for scalable image compression"
      },
      {
        "key": "fang2023depgraph",
        "author": "Fang, Gongfan and Ma, Xinyin and Song, Mingli and Mi, Michael Bi and Wang, Xinchao",
        "title": "Depgraph: Towards any structural pruning"
      }
    ]
  },
  {
    "index": 3,
    "papers": [
      {
        "key": "frantar2023sparsegpt",
        "author": "Frantar, Elias and Alistarh, Dan",
        "title": "Sparsegpt: Massive language models can be accurately pruned in one-shot"
      }
    ]
  },
  {
    "index": 4,
    "papers": [
      {
        "key": "sun2023simple",
        "author": "Sun, Mingjie and Liu, Zhuang and Bair, Anna and Kolter, J Zico",
        "title": "A Simple and Effective Pruning Approach for Large Language Models"
      }
    ]
  },
  {
    "index": 5,
    "papers": [
      {
        "key": "an2023fluctuation",
        "author": "An, Yongqi and Zhao, Xu and Yu, Tao and Tang, Ming and Wang, Jinqiao",
        "title": "Fluctuation-based Adaptive Structured Pruning for Large Language Models"
      }
    ]
  },
  {
    "index": 6,
    "papers": [
      {
        "key": "ma2023llm",
        "author": "Ma, Xinyin and Fang, Gongfan and Wang, Xinchao",
        "title": "Llm-pruner: On the structural pruning of large language models"
      }
    ]
  },
  {
    "index": 7,
    "papers": [
      {
        "key": "zhang2023pruning",
        "author": "Zhang, Mingyang and Shen, Chunhua and Yang, Zhen and Ou, Linlin and Yu, Xinyi and Zhuang, Bohan and others",
        "title": "Pruning meets low-rank parameter-efficient fine-tuning"
      }
    ]
  },
  {
    "index": 8,
    "papers": [
      {
        "key": "hu2021lora",
        "author": "Hu, Edward J and Shen, Yelong and Wallis, Phillip and Allen-Zhu, Zeyuan and Li, Yuanzhi and Wang, Shean and Wang, Lu and Chen, Weizhu",
        "title": "Lora: Low-rank adaptation of large language models"
      }
    ]
  },
  {
    "index": 9,
    "papers": [
      {
        "key": "hoffmann2022training",
        "author": "Hoffmann, Jordan and Borgeaud, Sebastian and Mensch, Arthur and Buchatskaya, Elena and Cai, Trevor and Rutherford, Eliza and Casas, Diego de Las and Hendricks, Lisa Anne and Welbl, Johannes and Clark, Aidan and others",
        "title": "Training compute-optimal large language models"
      }
    ]
  },
  {
    "index": 10,
    "papers": [
      {
        "key": "kovaleva2021bert",
        "author": "Kovaleva, Olga and Kulshreshtha, Saurabh and Rogers, Anna and Rumshisky, Anna",
        "title": "BERT busters: Outlier dimensions that disrupt transformers"
      },
      {
        "key": "dettmers2022gpt3",
        "author": "Dettmers, Tim and Lewis, Mike and Belkada, Younes and Zettlemoyer, Luke",
        "title": "Gpt3. int8 (): 8-bit matrix multiplication for transformers at scale"
      },
      {
        "key": "dettmers2023spqr",
        "author": "Dettmers, Tim and Svirschevski, Ruslan and Egiazarian, Vage and Kuznedelev, Denis and Frantar, Elias and Ashkboos, Saleh and Borzunov, Alexander and Hoefler, Torsten and Alistarh, Dan",
        "title": "Spqr: A sparse-quantized representation for near-lossless llm weight compression"
      },
      {
        "key": "schaeffer2024emergent",
        "author": "Schaeffer, Rylan and Miranda, Brando and Koyejo, Sanmi",
        "title": "Are emergent abilities of large language models a mirage?"
      },
      {
        "key": "sun2024massive",
        "author": "Sun, Mingjie and Chen, Xinlei and Kolter, J Zico and Liu, Zhuang",
        "title": "Massive Activations in Large Language Models"
      }
    ]
  },
  {
    "index": 11,
    "papers": [
      {
        "key": "dettmers2022gpt3",
        "author": "Dettmers, Tim and Lewis, Mike and Belkada, Younes and Zettlemoyer, Luke",
        "title": "Gpt3. int8 (): 8-bit matrix multiplication for transformers at scale"
      }
    ]
  },
  {
    "index": 12,
    "papers": [
      {
        "key": "sun2024massive",
        "author": "Sun, Mingjie and Chen, Xinlei and Kolter, J Zico and Liu, Zhuang",
        "title": "Massive Activations in Large Language Models"
      },
      {
        "key": "liu2024intactkv",
        "author": "Liu, Ruikang and Bai, Haoli and Lin, Haokun and Li, Yuening and Gao, Han and Xu, Zhengzhuo and Hou, Lu and Yao, Jun and Yuan, Chun",
        "title": "IntactKV: Improving Large Language Model Quantization by Keeping Pivot Tokens Intact"
      }
    ]
  }
]