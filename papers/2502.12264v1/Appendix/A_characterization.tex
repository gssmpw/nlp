\subsection{Preparation: characterization of Agent's Response}\label{sec: characterization BR}


In this subsection, we characterize the agent's best response in any random-order mechanism without disclosure.
% This characterization is mainly used to prove  \cref{lem:feasible-uninformed-rand-distance cost}.
% Readers who are not particularly interested in the proof of \cref{lem:feasible-uninformed-rand-distance cost} are safe to skip this section.
% , i.e.,  when the each of the two tests $\tilde \classifier_i$ used in the uninformed random order mechanism is parallel to the principal's true requirement $\classifier_i$ for $i\in \{A,B\}$.

Consider a random-order mechanism without disclosure $(\tilde \classifier_A, \tilde \classifier_B, q, \varnothing)$. 
We use $\manipulation_{\probprincipal}(\tilde\classifier_A,\tilde\classifier_B)$ to denote the set of attributes that the agent does not initially pass the sequence of tests but could profitably manipulate his attribute so as to pass the selection procedure. 
To prove the main theorem, we show the following coverage property of the manipulation sets for random-order mechanisms without disclosure with different probability $q$. 
\begin{proposition}\label{prop: coverage of Mq}
     For any fixed classifiers $\tilde\classifier_A$ and $\tilde\classifier_B$, the manipulation sets for random-order mechanisms without disclosure $(\tilde\classifier_A,\tilde\classifier_B,q,\nullset)$ satisfy:
    \begin{enumerate}
        \item $\manipulation_{\probprincipal}(\tilde \classifier_A, \tilde \classifier_B) \subset \manipulation_{0} (\tilde \classifier_A, \tilde \classifier_B)$ for any $0\leq \probprincipal \leq 1/2$;
        \item $\manipulation_{\probprincipal} (\tilde \classifier_A, \tilde \classifier_B) \subset \manipulation_{1} (\tilde \classifier_A, \tilde \classifier_B)$ for any $1/2 \leq \probprincipal \leq  1$;
    \end{enumerate}  
\end{proposition}



% \begin{lemma}[zig-zag strategy]\label{lem:zig-zag}
%     Suppose  $\probprincipal=1$. 
%     For any $\features\in R_4\cap \classifier_1^C$, let $\symmetric_{\classifier_1}\features$ be the point that is symmetric of $\features$ over $\classifier_1$.
%     Let $\Pi_{\classifier_2}(\symmetric_{\classifier_1}\features)$ be the projection of $\symmetric_{\classifier_1}\features$ on $\classifier_2$, i.e., the line connecting $\symmetric_{\classifier_1}\features$ and $\Pi_{\classifier_2}(\symmetric_{\classifier_1}\features)$ is perpendicular to  $\classifier_2$.
%     Let $\features'$ be the point that is on the boundary of $\classifier_1$ and intersects the line connecting $\symmetric_{\classifier_1}\features$ and $\Pi_{\classifier_2}(\symmetric_{\classifier_1}\features)$.
%     Then the best zig-zag strategy is to first move to $\features'$  and then to  $\Pi_{\classifier_2}(\symmetric_{\classifier_1}\features)$; moreover the cost of the best zig-zag strategy is $\onecost(\symmetric_{\classifier_1}\features,\Pi_{\classifier_2}(\symmetric_{\classifier_1}\features))$.
%     For any $\features\in R_4\cap \classifier_1$, let $\Pi_{\classifier_2}\features$ be the projection of $\features$ on $\classifier_2$, and let $\features'$ be the point that is on the boundary of $\classifier_1$ and intersects the line connecting $\features$ and $\Pi_{\classifier_2}\features$.
%     Then the best zig-zag strategy is to first move to $\features'$  and then to  $\Pi_{\classifier_2}\features$; moreover the cost of the best zig-zag strategy is $\onecost(\features,\Pi_{\classifier_2}\features)$.
% \end{lemma}
We first formally characterize the zig-zag strategy of agents in the sequential mechanism. For any attributes $\features$ and any classifier $\tilde \classifier_A$, we use $\symmetric_{\tilde\classifier_A} \features$ to denote its symmetric point with respect to the boundary of $\tilde\classifier_A$. We use $\Pi_{\tilde\classifier_A}\features$ to denote its projection onto $\tilde\classifier_A$, which is the closest point to $\features$ in $\tilde \classifier_A$. We call a two-step strategy $(\features,\features_1,\features_2)$ a zig-zag strategy if three attributes $\features$, $\features_1$, and $\features_2$ are not on a line. 

\begin{lemma}[zig-zag strategy]\label{lem:zig-zag}
    %Consider any sequential mechanism with two tests $\tilde \classifier_A$ and $\tilde \classifier_B$ such that the angle between two tests is in $(0,90^{\circ})$.
    Consider any attributes $\features \in \tilde \classifier_A^\compl \cup \tilde \classifier_B^\compl$.  
    If  $\Pi_{\classifier_B}(\symmetric_{\classifier_A}\features)$ does not satisfy $\tilde\classifier_A$, then the best strategy to first satisfy $\tilde\classifier_A$ is a zig-zag strategy $(\features,\features_1, \features_2)$, where $\features_2 = \Pi_{\classifier_B}(\symmetric_{\classifier_A}\features)$and $\features_1$ is the intersection point of $(\symmetric_{\classifier_A}\features)\features_2$ and the boundary of $\tilde\classifier_A$.
\end{lemma}

\begin{proof}[Proof of \cref{lem:zig-zag}]
    %Since the angle between two classifiers $\tilde\classifier_A$ and $\tilde\classifier_B$ is in $(0,90^{\circ})$, the line segment $(\symmetric_{\classifier_A}\features)\features_2$ intersects with the boundary of $\tilde\classifier_A$. 
    We first show that this zig-zag strategy is well-defined. Since $\features \in \tilde \classifier_A^C \cup \tilde \classifier_B^C$, we have $\symmetric_{\classifier_A}\features \in \tilde\classifier_A$. 
    If $\features_2 = \Pi_{\classifier_B}(\symmetric_{\classifier_A}\features)$ does not satisfy $\tilde\classifier_A$, then the line segment $(\symmetric_{\classifier_A}\features)\features_2$ intersects with $\tilde\classifier_A$. 
    Thus, this zig-zag strategy $(\features,\features_1,\features_2)$ is well-defined.
    
    For the zig-zag strategy $(\features,\features_1,\features_2)$, the cost of this strategy is $\cost(\features,\features_1,\features_2) = \onecost(\features,\features_1) + \onecost(\features_1,\features_2)$. Since $\features_1$ is on the boundary of $\tilde\classifier_A$, by symmetry, we have $\onecost(\symmetric_{\tilde\classifier_A}\features,\features_1) = \onecost(\features,\features_1)$. Since $\features_1$ is on the line $(\symmetric_{\tilde\classifier_A}\features)\features_2$, we have
    $$    \cost(\features,\features_1,\features_2) = \onecost(\symmetric_{\tilde\classifier_A}\features,\features_1) + \onecost(\features_1,\features_2) = \onecost(\symmetric_{\tilde\classifier_A}\features, \features_2).
    $$
    
    Consider any zig-zag strategy $(\features, \features',\features'')$ that first satisfies $\tilde\classifier_A$ and then $\tilde\classifier_B$.
    Since the attributes $\features$ do not satisfy $\tilde\classifier_1$, its symmetric point $\symmetric_{\tilde\classifier_A} \features$ satisfy $\tilde\classifier_A$.
    Since $\features'$ satisfies $\tilde \classifier_A$, by symmetry, we have $\onecost(\symmetric_{\tilde\classifier_A}\features, \features') \leq \onecost(\features, \features')$, which implies $\onecost(\symmetric_{\tilde\classifier_A}\features, \features') \leq \onecost(\features, \features')$. 
    By the triangle inequality of the Euclidean distance, the cost of this strategy is at least
    $$
    \cost(\features,\features',\features'') \geq \onecost(\symmetric_{\tilde\classifier_A}\features, \features') + \onecost(\features',\features'') \geq \onecost(\symmetric_{\tilde\classifier_A}\features, \features'').
    $$
    Since $\features_2$ is the projection of $\symmetric_{\tilde\classifier_A} \features$ onto the boundary of $\tilde\classifier_B$, we have $$\cost(\features,\features',\features'') \geq \onecost(\symmetric_{\tilde\classifier_A}\features, \features'') \geq \onecost(\symmetric_{\tilde\classifier_A}\features, \features_2) = \cost(\features,\features_1,\features_2),$$
    which completes the proof.
\end{proof}

\begin{remark}
    Consider any sequential mechanism with two tests $\tilde \classifier_A$ and $\tilde \classifier_B$ such that the angle between two tests is in $[90^{\circ}, 180^{\circ})$.
    For any attributes $\features \in \tilde \classifier_A^\compl \cup \tilde \classifier_B^\compl$, we have  $\Pi_{\classifier_B}(\symmetric_{\classifier_A}\features)$ satisfies $\tilde\classifier_A$. Thus, for such an agent, the best strategy to first satisfy $\tilde\classifier_A$ is not a zig-zag strategy. In this case, it is easy to show that the best strategy is a one-step strategy. An alternative algebraic proof is provided by Theorem 3.7 in \citet{zigzag}.
\end{remark}

In the following analysis, we only consider the sequential mechanism with two tests $\tilde \classifier_A$ and $\tilde \classifier_B$ such that the angle between two tests is in $(0,90^{\circ})$.
We now characterize the manipulation set $\manipulation_{\probprincipal}(\tilde\classifier_A,\tilde\classifier_B)$ for random-order mechanism without disclosure $(\tilde\classifier_A, \tilde\classifier_B,q,\varnothing)$.
Let $L_A$ and $L_B$ be the boundary lines of classifiers $\tilde \classifier_A$ and $\tilde \classifier_B$ respectively. 
Let $O$ be the intersection point of $L_A$ and $L_B$.
Let $\Line_A^+=\Line_A\cap \classifier_B$  and $\Line_B^+=\Line_B\cap \classifier_A$ be the part of $L_A$ and $L_B$ in the qualified region, respectively.
Let $\setperp_A(\tilde \classifier_A, \tilde \classifier_B)=\{\orifeatures\notin \tilde\classifier_A\cap \tilde\classifier_B: \min_{\genericfeatures\in\Line_A^+}\onecost(\orifeatures,\genericfeatures)\leq 1 \}$ be the set of candidates whose true attributes are not qualified but have cost less than one to adopt attributes on $\Line_A^+$.
Similarly, let $\setperp_B(\tilde \classifier_A, \tilde \classifier_B)=\{\orifeatures\notin \tilde \classifier_A\cap \tilde \classifier_B: \min_{\genericfeatures\in\Line_B^+}\onecost(\orifeatures,\genericfeatures)\leq 1 \}$ be the set of candidates whose true attributes are not qualified but have cost less than one to adopt attributes on $\Line_B^+$.

Let $\Omega(\tilde\classifier_A,\tilde\classifier_B) = \bbR^2 \setminus ((\tilde\classifier_A\cap\tilde\classifier_B)\cup \setperp_A(\tilde \classifier_A, \tilde \classifier_B)\cup \setperp_B(\tilde \classifier_A, \tilde \classifier_B))$.
Without loss of generality, we assume the unit normal vector of $\tilde\classifier_A$ is $\weights_A = (1,0)$.
Let $\util_{AB}$ be the agent's best utility among strategies that first pass only $\tilde \classifier_A$ but not $\tilde \classifier_B$ and then pass $\tilde \classifier_B$. 
We define the set $\setonetwo_{\probprincipal}(\tilde\classifier_A,\tilde\classifier_B)=\{\features\in\Omega(\tilde\classifier_A,\tilde\classifier_B): \util_{AB}\geq 0\}$.
Similarly, let $\util_{BA}$ be the agent's best utility among all strategies that first pass only $\tilde\classifier_B$ and then pass $\tilde\classifier_A$. 
Define the set $\settwoone_{\probprincipal}(\tilde\classifier_A,\tilde\classifier_B)=\{\features\in\Omega(\tilde\classifier_A,\tilde\classifier_B): \util_{BA}\geq 0\}$.
Let the agent's utility of directly moving to point $O$ be $\util_{0}$.
We define the set $\setO_{\probprincipal}(\tilde\classifier_A,\tilde\classifier_B)=\{\features\in\Omega(\tilde\classifier_A,\tilde\classifier_B): \util_{0}\geq 0 \}$.
% We use $\manipulation_{\probprincipal}(\tilde\classifier_A,\tilde\classifier_B)$ to denote the set of attributes in $\Omega(\tilde\classifier_A,\tilde\classifier_2)$ that the agent does not initially pass the sequence of tests but could profitably manipulate his attribute so as to pass the selection procedure.
When there is no ambiguity about the two classifiers $\tilde \classifier_A$ and $\tilde \classifier_B$ used in the mechanism, we use $\setO$, $\setonetwo$, and $\settwoone$ to denote these sets. 
Then, we have the manipulation set $\manipulation_{\probprincipal}(\tilde \classifier_A,\tilde\classifier_B)=\setperp_A \cup \setperp_B \cup \setonetwo_{\probprincipal}\cup \settwoone_{\probprincipal}\cup \setO_{\probprincipal}$.
% By \cref{prop: q=1}, we know that under fixed order and announcing the true selection criteria, $\manipulation_{1}= R_3\cup R_4$.
% Notice that the set of attributes where the agent does not initially pass the sequence of tests but could profitably manipulate his attribute so as to pass the selection procedure is $\allmanipulation_{\probprincipal}(\tilde\classifier_1,\tilde\classifier_2)=\manipulation_{\probprincipal}(\tilde\classifier_1,\tilde\classifier_2) \cup R_1(\tilde\classifier_1) \cup R_2(\tilde\classifier_2) $.

% Denote the set of attributes where the agent passes the sequence of tests without manipulating his attribute by $\qualified(\tilde\classifier_1,\tilde\classifier_2) = \tilde\classifier_1\cap\tilde\classifier_2$.
% Then the set of attributes that would eventually be selected is $\selected_{\probprincipal}(\tilde\classifier_1,\tilde\classifier_2)=\allmanipulation_{\probprincipal}(\tilde\classifier_1,\tilde\classifier_2)\cup \qualified(\tilde\classifier_1,\tilde\classifier_2)$.

First, it is easy to see that the set $\setO_{\probprincipal}$ is invariant with the probability $q$.

\begin{lemma}\label{lmm: Bq invariant with q}
    $ \setO_{\probprincipal} = \setO =\arc{OAB}$ for any $\probprincipal\in [0,1]$.
\end{lemma}

\begin{proof}
    The ball $B(O,1/\eta)$ contains all attributes $\features$ such that the cost $\onecost(\features,O) \leq 1$. We have $\setO_{\probprincipal} = B(O, 1/\eta) \cap \Omega(\tilde\classifier_A,\tilde\classifier_B) = \arc{OAB}$.
\end{proof}

Next, we characterize the sets $\setonetwo_{\probprincipal}$ and $\settwoone_{\probprincipal}$. Let the point $\pointonetwo_{\probprincipal}$ be the point whose distance to point $O$ is $\probprincipal/\eta$ and whose projection on $\tilde\classifier_B$ is point $O$. Then $\pointonetwo_{\probprincipal} = -\frac{\probprincipal}{\mc}\cdot \weights_B$, where $\weights_B$ is the unit normal vector of $\tilde\classifier_B$.
Note that for the agent with attributes $\pointonetwo_{\probprincipal}$, the cost for first passing $\tilde\classifier_A$ but not $\tilde \classifier_B$ and then passing $\tilde\classifier_B$ is $\probprincipal$.
Let its symmetric point with respect to the boundary of $\tilde\classifier_A$ be $\pointonetwo_{\probprincipal}' = \symmetric_{\tilde\classifier_A} \pointonetwo_{\probprincipal}$.
Let the point $\tilde \pointonetwo_{\probprincipal}  = (0,-\frac{\probprincipal}{\mc\sin{\theta}})$ be the point that falls on the boundary of $\tilde\classifier_A$ with distance $\probprincipal/\eta$ to $\tilde\classifier_B$.

\begin{lemma}\label{lem: Cq}
    $\setonetwo_{\probprincipal} = O \pointonetwo_{\probprincipal} \tilde \pointonetwo_{\probprincipal} \pointonetwo_{\probprincipal}'$.
\end{lemma}

\begin{proof}
    We first consider the agent with attributes $\features$ in the triangle region $O\pointonetwo_{\probprincipal} \tilde \pointonetwo_{\probprincipal}$. These attributes already satisfy the classifier $\tilde\classifier_A$. Since both $\pointonetwo_{\probprincipal}$ and $\tilde \pointonetwo_{\probprincipal}$ have distance $\probprincipal/\eta$ to $\tilde\classifier_B$, we have the line $\pointonetwo_{\probprincipal}\tilde \pointonetwo_{\probprincipal}$ is parallel to the boundary of $\tilde\classifier_B$. Thus, all attributes in $O\pointonetwo_{\probprincipal} \tilde \pointonetwo_{\probprincipal}$ have distance at most $\probprincipal/\eta$ to $\tilde\classifier_B$. For the agent with these attributes, the utility for providing $\features$ in the first test and then moving to pass $\tilde \classifier_B$ is non-negative. 

    Then, we consider the triangle region $O\pointonetwo_{\probprincipal}' \tilde \pointonetwo_{\probprincipal}$. Note that for each attributes $\features$ in $O\pointonetwo_{\probprincipal}' \tilde \pointonetwo_{\probprincipal}$, its symmetric point with respect to the boundary of $\tilde\classifier_A$ is in $O\pointonetwo_{\probprincipal} \tilde \pointonetwo_{\probprincipal}$. Thus, by Lemma~\ref{lem:zig-zag}, the agent with attributes in $O\pointonetwo_{\probprincipal}' \tilde \pointonetwo_{\probprincipal}$ also has the utility $u_{AB} \geq 0$.
\end{proof}

Similarly, let $\pointtwoone_{1-\probprincipal} = -\frac{1-\probprincipal}{\mc}\cdot \weights_A$ be the point whose distance to point $O$ is $1-\probprincipal$ and whose projection on $\tilde\classifier_A$ is point $O$. 
Let its symmetric point over the boundary of $\tilde\classifier_B$ be $\pointtwoone_{1-\probprincipal}' = \symmetric_{\tilde\classifier_B} \pointtwoone_{1-\probprincipal}$.
Let point $\tilde \pointtwoone_{1-\probprincipal}  = (-\frac{ 1-\probprincipal}{\mc},-\frac{1-\probprincipal}{\mc\tan{\theta}})$ be the point that falls on the boundary of $\tilde\classifier_B$ with distance $\frac{1-\probprincipal}{\eta}$ to $\tilde\classifier_A$. With a similar analysis as in Lemma~\ref{lem: Cq}, we characterize $\settwoone_{\probprincipal}$ as follows.

\begin{lemma}\label{lem: Dq}
    $\settwoone_{\probprincipal} = O \pointtwoone_{1-\probprincipal} \tilde \pointtwoone_{1-\probprincipal} \pointtwoone_{1-\probprincipal}'$.
\end{lemma}

% \begin{proof}
    
% \end{proof}

\begin{lemma}\label{lmm:Cq < Dq+Bq when q is small}
   $\setonetwo_{\probprincipal}\subset \settwoone_{0}\cup \setO$ if $\probprincipal\leq \frac{1}{2\cos{\theta}}$.
   %:=f(\theta)$.
   %This implies that $\manipulation_{\probprincipal}=\settwoone_{\probprincipal}\cup \setO$ if and only if $\probprincipal\leq f(\theta)$.
\end{lemma}

\begin{proof}%[Proof of \cref{lmm:Cq < Dq+Bq when q is small}]
    % Given $\probprincipal, \tilde\classifier_1,\tilde\classifier_2$, $\util_{12}(\orifeatures)\geq 0\Leftrightarrow \cost_{12}(\orifeatures)\leq \probprincipal$, where $\cost_{12}(\orifeatures)$ is the smallest cost of an agent with initial attributes $\orifeatures$ to first move to pass $\tilde\classifier_1$ and then move to pass $\tilde\classifier_2$.

Let $G = (0, -\frac{1}{\mc\sin{2\theta}})$ be the point where $\tilde \pointtwoone_{1} \pointtwoone_{1}'$ intersects with the boundary of $\tilde\classifier_A$.
% Let  $G' = (0, -\frac{1}{\mc})$ be the point where $\setO$ intersects with the boundary of $\tilde\classifier_1$.
When  $\probprincipal\leq \sin{\theta}$, we have $\frac{\probprincipal}{\mc\sin{\theta}}\leq \frac{1}{\mc\sin{2\theta}}$.
Since the point $\tilde \pointonetwo_{\probprincipal} = (0, - \frac{\probprincipal}{\mc\sin{\theta}})$, we have $O\tilde \pointonetwo_{\probprincipal}\subset OG$.

It is easy to see that $O\pointonetwo_{\probprincipal}\subset \setO$ for any $\probprincipal\leq 1$. Since $\pointonetwo_{\probprincipal}'$ is the symmetric point of $\pointonetwo_{\probprincipal}$ with respect to $\tilde\classifier_1$, we have $O\pointonetwo_{\probprincipal}'\subset \setO$ for any $\probprincipal\leq 1$. 

Note that $\settwoone_{0}\cup \setO$ is a convex set. Since four points $O$, $\pointonetwo_{\probprincipal}$, $\pointonetwo_{\probprincipal}'$, and $\tilde \pointonetwo_{\probprincipal}$ are contained in $\settwoone_{0}\cup \setO$, By Lemma~\ref{lem: Cq}, we have that $\setonetwo_{\probprincipal}\subset \settwoone_{\probprincipal}\cup \setO$.
\end{proof}

Similarly, we can show the following coverage property for $\settwoone_{\probprincipal}$.

\begin{lemma}\label{lmm:Dq < Cq+Bq when q is large}
   $\settwoone_{\probprincipal}\subset \setonetwo_{1}\cup \setO$ if and only if $\probprincipal\geq 1 - \frac{1}{2\cos{\theta}}$.
   %=1-h(\theta)$.
   %This implies that $\manipulation_{\probprincipal}=\setonetwo_{\probprincipal}\cup \setO$ if and only if $\probprincipal\geq 1-h(\theta)$.
\end{lemma}

\begin{proof}
    Let $E = (-\frac{1}{2\eta\cos\theta}, -\frac{1}{2\eta\sin{\theta}})$ be the point where $\tilde \pointonetwo_{1} \pointonetwo_{1}'$ intersects with the boundary of $\tilde\classifier_B$. Note that the point $\tilde \pointtwoone_{1-q} = (-\frac{1-q}{\eta},-\frac{1-q}{\eta\tan\theta}) = 2\cos \theta (1-q) E$. When $q \geq 1-\frac{1}{2\cos \theta}$, we have $2\cos \theta (1-q) \leq 1$ , which implies $O\tilde \pointtwoone_{1-q} \subset OE$.
    Since $\pointtwoone_{1-q}$ and $\pointtwoone_{1-q}'$ is in $\setO$ and $\setonetwo_{1}\cup \setO$ is convex, we have $\settwoone_{\probprincipal}\subset \setonetwo_{1}\cup \setO$.
\end{proof} 

% \paragraph{Set order under fixed $\tilde\classifier_1,\tilde\classifier_2$.} The following results concern the order of the manipulation set when the announced criteria are fixed.

Now, we prove the coverage proposition of the manipulation sets for sequential mechanisms.

\begin{proof}[Proof of \cref{prop: coverage of Mq}]
    We first consider the case where $q \leq 1/2$. 
    By \cref{lmm:Cq < Dq+Bq when q is small}, we know that $\manipulation_{\probprincipal}=\setperp_A \cup \setperp_B \cup \setonetwo_q \cup \settwoone_{\probprincipal}\cup \setO \subset \setperp_A \cup \setperp_B \cup\settwoone_0 \cup \setO \subset \manipulation_0$.
    % It suffices to show that $\settwoone_{\probprincipal} \subset \settwoone_{\probprincipal'}$ for any $0\leq \probprincipal'\leq \probprincipal\leq h(\theta)$.
    % This is true because for every edge of $\settwoone_{\probprincipal}$, for instance $O \pointtwoone_{1-\probprincipal}  \subset O \pointtwoone_{1-\probprincipal'} $ for any $0\leq \probprincipal'\leq \probprincipal\leq h(\theta)$.

    We then consider the case where $q \geq 1/2$. 
    By \cref{lmm:Dq < Cq+Bq when q is large}, we know that $\manipulation_{\probprincipal}=\setperp_A \cup \setperp_B \cup\setonetwo_{\probprincipal}\cup \settwoone_{\probprincipal} \cup \setO \subset \setperp_A \cup \setperp_B \cup\setonetwo_1 \cup \setO \subset \manipulation_1$.
    %for any $ \probprincipal\geq 1-h(\theta)$.
    % It suffices to show that $\setonetwo_{\probprincipal} \subset \setonetwo_{\probprincipal'}$ for any $ \probprincipal'\geq \probprincipal\geq 1- h(\theta)$.
    %  This is true because for every edge of $\setonetwo_{\probprincipal}$, for instance $O \pointonetwo_{\probprincipal}  \subset O \pointonetwo_{\probprincipal'} $ for any $ \probprincipal'\geq \probprincipal\geq 1- h(\theta)$.
\end{proof}



\begin{figure}[t]
\centering
% \begin{subfigure}[b]{0.3\linewidth}
% \begin{tikzpicture}[xscale=3.5,yscale=3.5,
%     pics/legend entry/.style={code={%   
%         \draw[pic actions] 
%         (-0.25,0.25) -- (0.25,0.25);}}]]
\begin{tikzpicture}[xscale=6,yscale=6,
    pics/legend entry/.style={code={%   
        \draw[pic actions] 
        (-0.25,0.25) -- (0.25,0.25);}}]]

\draw [domain=0.8:1.16, thick] plot (\x, {tan(deg(0.4*pi))*(\x-1)+1});%less than pi/9
\node [above] at (1.16, 1.5 ) {$\tilde\classifier_2$};
\draw [thick] (1,0.15) -- (1,1.5);
\node [above] at (1, 1.5 ) {$\tilde\classifier_1$};%: \feature_1 \geq 1


\draw [domain={1+0.25*cos(deg(0.1*pi))}:1.4, densely dotted] plot (\x, {tan(deg(0.4*pi))*(\x-1)+1-0.809}); % 1/c = 1/4
%\node [above] at (1.4, 1.5 ) {$\classifier_2^-$};
\draw [densely dotted] (1-0.25,1) -- (1-0.25,1.5);
%\node [above] at (1-0.25, 1.5) {$\classifier_1^-$};
\draw[red] (1-0.25,1) arc (180:240:0.25);
\draw[red] (1,1) -- ++(180:0.25);
\draw[red] (1,1) -- ++(240:0.25) ;

\draw[red] ({1+0.25*cos(deg(0.1*pi))},{1-0.25*sin(deg(0.1*pi))}) arc (360-18:360-78:0.25);
\draw[red] (1,1) -- ++(360-18:0.25);
\draw[red] (1,1) -- ++(360-78:0.25) ;

\draw [red] (1-0.125,{1-0.125*sqrt(3)}) -- (1-0.125,0.61625);
\draw [domain=0.875:0.957, red]  plot(\x,{tan(deg(0.3*pi))*(\x-0.875)+0.61625});

\draw [domain=0.956:1,red]  plot(\x,{-tan(deg(0.4*pi))*(\x-1)+1-0.125/sin(deg(0.1*pi))});
\draw [domain=1:1.053,red]  plot(\x,{tan(deg(0.4*pi))*(\x-1)+1-0.125/sin(deg(0.1*pi))});


\draw[blue] (1,1) -- ++(192:0.25) ;
\draw [domain=1:{1+0.25*cos(deg(0.1*pi))}, blue] plot (\x, {tan(deg(0.4*pi))*(\x-1)+1-0.809});
\draw [domain=1-0.246:1,blue]  plot(\x,{-tan(deg(0.4*pi))*(\x-1)+1-0.809});

\draw [domain=1:{1+0.25*0.8*cos(deg(0.1*pi))}, teal] plot (\x, {tan(deg(0.4*pi))*(\x-1)+1-0.8*0.25/sin(deg(0.1*pi))});
\draw [domain=1-0.196:1,teal]  plot(\x,{-tan(deg(0.4*pi))*(\x-1)+1-0.8*0.25/sin(deg(0.1*pi))});


\node [above] at (1.06, 1.01 ) {\footnotesize$O$};

\matrix [draw, above right] at (1.6,1) {
 \pic[blue]{legend entry}; &  \node[blue,font=\tiny] {$\probprincipal=1$}; \\
 \pic[red]{legend entry}; &  \node[red,font=\tiny] {$\probprincipal=\frac12$}; \\
 \pic[teal]{legend entry}; &  \node[teal,font=\tiny] {$\probprincipal=0.8$}; \\
};

\end{tikzpicture}
\caption{ random-order mechanisms without disclosure vs fixed-order mechanism}
% \rule{0in}{1.2em}$^\dag$\scriptsize 
% In this graph, $\theta=\frac{\pi}{10}$. Notice that $\manipulation_{\frac12}\subset M_1$ and $M_{0.8}\subset M_1$. However, we cannot rank the set $M_{0.8}$ and $\manipulation_{\frac12}$.\\
\end{figure}


% %--------------------------------------
\begin{figure}[t]
\centering
\begin{subfigure}[b]{0.4\linewidth}
\begin{tikzpicture}[xscale=3.5,yscale=3.5,
    pics/legend entry/.style={code={%   
        \draw[pic actions] 
        (-0.25,0.25) -- (0.25,0.25);}}]]
% \begin{tikzpicture}[xscale=6,yscale=6,
%     pics/legend entry/.style={code={%   
%         \draw[pic actions] 
%         (-0.25,0.25) -- (0.25,0.25);}}]]

% \draw [<->] (0,2.1) -- (0,0) -- (2.1,0);
% \node [right] at (2.15, 0 ) {$\feature_1$};
% \node [left] at (0,2.15) {$\feature_2$};


\draw [domain=0.8:1.16, thick] plot (\x, {tan(deg(0.4*pi))*(\x-1)+1});%less than pi/9
\node [above] at (1.16, 1.5 ) {$\classifier_2$};
\draw [thick] (1,0.15) -- (1,1.5);
\node [above] at (1, 1.5 ) {$\classifier_1$};%: \feature_1 \geq 1


\draw [domain={1+0.25*cos(deg(0.1*pi))}:1.4, densely dotted] plot (\x, {tan(deg(0.4*pi))*(\x-1)+1-0.809}); % 1/c = 1/4
\node [above] at (1.4, 1.5 ) {$\classifier_2^-$};
\draw [densely dotted] (1-0.25,1) -- (1-0.25,1.5);
\node [above] at (1-0.25, 1.5) {$\classifier_1^-$};
\draw[blue] (1-0.25,1) arc (180:198:0.25);
\draw[blue] (1,1) -- ++(180:0.25);

\draw[teal] ({1-0.25*cos(deg(0.1*pi))},{1-0.25*sin(deg(0.1*pi))}) arc (198:198+36:0.25);
\draw[teal] (1,1) -- ++(198+36:0.25) ;


\draw[teal] ({1+0.25*cos(deg(0.1*pi))},{1-0.25*sin(deg(0.1*pi))}) arc (360-18:360-54:0.25);
\draw[teal] (1,1) -- ++(360-18:0.25);
\draw[teal] (1,1) -- ++(360-54:0.25) ;




\draw[blue] (1,1) -- ++(192:0.25) ;
\draw [domain=1:{1+0.25*cos(deg(0.1*pi))}, blue] plot (\x, {tan(deg(0.4*pi))*(\x-1)+1-0.809});
\draw [domain=1-0.246:1,blue]  plot(\x,{-tan(deg(0.4*pi))*(\x-1)+1-0.809});

\draw [domain=1:{1+0.25*0.8*sin(47)}, teal] plot (\x, {tan(deg(0.4*pi))*(\x-1)+1-0.8*0.25/sin(deg(0.1*pi))});
\draw [domain={1-0.25*0.8*cos(43)}:1,teal]  plot(\x,{-tan(deg(0.4*pi))*(\x-1)+1-0.8*0.25/sin(deg(0.1*pi))});


\node [above,font=\tiny] at (1.06, 1.01 ) {$O$};

\node [right,font=\tiny] at ({1+0.25*cos(deg(0.1*pi))},{1-0.25*sin(deg(0.1*pi))} ) {$\pointonetwo_{\probprincipal=1}$};
\node [left,font=\tiny] at ({1-0.25*cos(deg(0.1*pi))},{1-0.25*sin(deg(0.1*pi))}) {$\pointonetwo_{\probprincipal=1}'$};
\node [below,font=\tiny] at (1, {1-0.25/sin(deg(0.1*pi))} ) {$\tilde \pointonetwo_{\probprincipal=1}$};


\matrix [draw, above right] at (1.5,0.2) {
 \pic[blue]{legend entry}; &  \node[blue,font=\tiny] {$\probprincipal=1$}; \\
 \pic[teal]{legend entry}; &  \node[teal,font=\tiny] {$\probprincipal=0.8$}; \\
};

\end{tikzpicture}
\caption{Random order $\probprincipal=0.8$} \label{fig:q>1-h(theta)}  
\end{subfigure}
\begin{subfigure}[b]{0.4\linewidth}
\begin{tikzpicture}[xscale=3.5,yscale=3.5,
    pics/legend entry/.style={code={%   
        \draw[pic actions] 
        (-0.25,0.25) -- (0.25,0.25);}}]]

\draw [domain=0.74:1.16, thick] plot (\x, {tan(deg(0.4*pi))*(\x-1)+1});%less than pi/9
\node [above] at (1.16, 1.5 ) {$\classifier_2$};
\draw [thick] (1,0.15) -- (1,1.5);
\node [above] at (1, 1.5 ) {$\classifier_1$};%: \feature_1 \geq 1


\draw [domain={1+0.25*cos(deg(0.1*pi))}:1.4, densely dotted] plot (\x, {tan(deg(0.4*pi))*(\x-1)+1-0.809}); % 1/c = 1/4
\node [above] at (1.4, 1.5 ) {$\classifier_2^-$};
\draw [densely dotted] (1-0.25,1) -- (1-0.25,1.5);
\node [above] at (1-0.25, 1.5) {$\classifier_1^-$};
\draw[teal] (1-0.25,1) arc (180:180+37:0.25);
\draw[teal] (1,1) -- ++(180:0.25);
\draw[teal] (1,1) -- ++(180+37:0.25) ;

\draw[red] ({1+0.25*cos(deg(0.1*pi))},{1-0.25*sin(deg(0.1*pi))}) arc (360-18:360-36:0.25);
\draw[red] (1,1) -- ++(360-18:0.25);
\draw[teal] ({1+0.25*cos(deg(0.2*pi))},{1-0.25*sin(deg(0.2*pi))}) arc (360-36:360-73:0.25);
\draw[teal] (1,1) -- ++(360-73:0.25);
% \draw[red] (1,1) -- ++(360-78:0.25) ;

\draw [teal] (1-0.25*0.8,{1-0.25*0.8*cos(44)}) -- (1-0.25*0.8,{1-0.25*0.8*tan(deg(0.4*pi))});
\draw [domain=1-0.25*0.8:{1+0.25*0.29}, teal]  plot(\x,{tan(deg(0.3*pi))*(\x-1+0.25*0.8)+1-0.25*0.8*tan(deg(0.4*pi))});


\draw[red] (1,1) -- ++(360-36:0.25) ;
\draw[red] (1-0.25,1) -- (1-0.25, {1- 0.25*tan(deg(0.4*pi))}) ;
\draw [domain=1-0.25:{1+0.25*cos(36)}, red] plot (\x, {tan(deg(0.3*pi))*(\x-1+0.25)+1-0.25*tan(deg(0.4*pi))});




\node [above,font=\tiny] at (1.06, 1.01 ) {$O$};

\node [left,font=\tiny] at ({1-0.25},1) {$\pointtwoone_{1-\probprincipal=1}$};
\node [right,font=\tiny] at ({1+0.25*cos(deg(0.2*pi))},{1-0.25*sin(deg(0.2*pi))}) {$\pointtwoone_{1-\probprincipal=1}'$};
\node [below,font=\tiny] at (1-0.25, {1-0.25*tan(deg(0.4*pi))} ) {$\tilde \pointtwoone_{1-\probprincipal=1}$};

\matrix [draw, above right] at (1.5,0) {
 \pic[red]{legend entry}; &  \node[red,font=\tiny] {$\probprincipal=0$}; \\
 \pic[teal]{legend entry}; &  \node[teal,font=\tiny] {$\probprincipal=0.2$}; \\
};

\end{tikzpicture}
\caption{Random order $\probprincipal=0.2$} \label{fig:q<h(theta)}  
\end{subfigure}

% \rule{0in}{1.2em}$^\dag$\scriptsize 
% In this graph, $\theta=\frac{\pi}{10}$. Notice that $\manipulation_{\frac12}\subset M_1$ and $M_{0.8}\subset M_1$. However, we cannot rank the set $M_{0.8}$ and $\manipulation_{\frac12}$.\\
\end{figure}

% %-----------------------------------------------
% \paragraph{Set order with varying $\tilde\classifier_1,\tilde\classifier_2$.}
% The following result shows that given a set of selected attributes from any mechanism with random order, there exists another mechanism with fixed order whose corresponding set of selected attributes is nested in the former set.

% \begin{proposition}[Nested structure of $\selected_{\probprincipal}$ with varying $\tilde\classifier_1,\tilde\classifier_2$]\label{prop: nested structure}
% Suppose $0< \theta<\pi$. Then for any $\probprincipal\in (0,1)$ and $\tilde\classifier_1,\tilde\classifier_2$, there exists $\hat{\probprincipal}\in \{0,1\}$ and $\hat\classifier_1,\hat\classifier_2$ such that
% \begin{equation}
%     \selected_{\hat{\probprincipal}}(\hat\classifier_1,\hat\classifier_2)\subset \selected_{\probprincipal}(\tilde\classifier_1,\tilde\classifier_2).
% \end{equation}
% Moreover, given $\classifier_i,i\in \{1,2\}$ whose boundary is parallel to that of $\tilde\classifier_i,i\in \{1,2\}$, suppose $\qualified(\classifier_1,\classifier_2)\subset \selected_{\probprincipal}(\tilde\classifier_1,\tilde\classifier_2)$ for some $\probprincipal\in (0,1)$, then there exists $\hat{\probprincipal}\in \{0,1\}$ and $\hat\classifier_1,\hat\classifier_2$ such that
% \begin{equation}
% \qualified(\classifier_1,\classifier_2)\subset\selected_{\hat{\probprincipal}}(\hat\classifier_1,\hat\classifier_2)\subset \selected_{\probprincipal}(\tilde\classifier_1,\tilde\classifier_2).
% \end{equation}
% \end{proposition}


% \begin{proof}[Proof of \cref{prop: nested structure}]
%     The proof is constructive. Suppose $\tilde\classifier_1: \tilde\weights_1^T\features\geq 0$ and $\tilde\classifier_2: \tilde\weights_2^T\features\geq 0$.
    
%     \textbf{Part 1.} Consider the following cases:
%     \begin{itemize}
%         \item \textbf{Case 1: $\probprincipal\leq \frac12$.} Let $\hat{\probprincipal}=0$, $\hat\classifier_1:\tilde\weights_1^T(\features+\frac{\probprincipal}{\mc}\cdot v_1)\geq 0$ and
%         $\hat\classifier_2:\tilde\classifier_2$.
%         \item \textbf{Case 2: $\probprincipal> \frac12$.} Let $\hat{\probprincipal}=1$, $\hat\classifier_2:\tilde\weights_2^T(\features+\frac{1-\probprincipal}{\mc}\cdot v_1)\geq 0$ and
%         $\hat\classifier_1=\tilde\classifier_1$.
%     \end{itemize}
%     Next we want to show that under each case, $\selected_{\hat{\probprincipal}}(\hat\classifier_1,\hat\classifier_2)\subset \selected_{\probprincipal}(\tilde\classifier_1,\tilde\classifier_2).$ To show this, we just need to show that every edge of $\selected_{\hat{\probprincipal}}(\hat\classifier_1,\hat\classifier_2)$ is contained in the set $\selected_{\probprincipal}(\tilde\classifier_1,\tilde\classifier_2)$.

%     \textbf{Case 1: $\probprincipal\leq \frac12$.}
%     ...

%      \textbf{Part 2.} Call the intersecting point of the boundaries of $\classifier_i,i\in \{1,2\}$ point $O$. 
%      \emph{First we consider the scenario where point $O$ is at the boundary of set $\selected_{\probprincipal}(\tilde\classifier_1,\tilde\classifier_2)$.}
%      Recall that $\selected_{\probprincipal}(\tilde\classifier_1,\tilde\classifier_2) = \qualified_{\probprincipal}(\tilde\classifier_1,\tilde\classifier_2)\cup R_1(\tilde\classifier_1) \cup R_2(\tilde\classifier_2) \cup \manipulation_{\probprincipal}(\tilde\classifier_1,\tilde\classifier_2)$, where $\manipulation_{\probprincipal}(\tilde\classifier_1,\tilde\classifier_2)=\setonetwo_{\probprincipal}(\tilde\classifier_1,\tilde\classifier_2)\cup\settwoone_{\probprincipal}(\tilde\classifier_1,\tilde\classifier_2)\cup\setO(\tilde\classifier_1,\tilde\classifier_2)$.
     
%      \textbf{Case 1: $\probprincipal\leq h(\theta)$.} From \cref{lmm:Cq < Dq+Bq when q is small}, we know that $\selected_{\probprincipal}(\tilde\classifier_1,\tilde\classifier_2) = \qualified_{\probprincipal}(\tilde\classifier_1,\tilde\classifier_2)\cup R_1(\tilde\classifier_1) \cup R_2(\tilde\classifier_2)\cup\settwoone_{\probprincipal}(\tilde\classifier_1,\tilde\classifier_2)\cup\setO(\tilde\classifier_1,\tilde\classifier_2)$.
%      Let $\hat{\probprincipal}=0$, $\hat\classifier_1:\weights_1^T(\features-\frac{1}{\mc}\cdot v_1)\geq 0$, i.e.,  $\classifier_1$ shifting inward by a distance of $\frac{1}{\mc}$, and
%         $\hat\classifier_2:\weights_2^T(\features-\frac{1}{\mc}\cdot v_2)\geq 0$, i.e., $\classifier_2$ shifting inward by a distance of $\frac{1}{\mc}$.
%      To argue that $\qualified(\classifier_1,\classifier_2)\subset\selected_{\hat{\probprincipal}}(\hat\classifier_1,\hat\classifier_2)\subset \selected_{\probprincipal}(\tilde\classifier_1,\tilde\classifier_2)$, we further distinguish the following cases:
   
%    \textbf{Case 1.a.:} point $O$ is at the boundary of $R_1(\tilde\classifier_1)$. 
%         This is only possible if and only if the boundary of $R_1(\tilde\classifier_1)$ and $\classifier_1$ coincide.

%         ...

%     \textbf{Case 1.b.:} point $O$ is at the boundary of $\settwoone_{\probprincipal}(\tilde\classifier_1,\tilde\classifier_2)$.
%     The construction and argument is the same as the above case.

%     ...



%     \textbf{Case 1.c.:} point $O$ is at the boundary of $\setO(\tilde\classifier_1,\tilde\classifier_2)$.
    

    
%     \textbf{Case 1.d.:} point $O$ is at the boundary of $R_2(\tilde\classifier_2)$.
        
%     ...

%     \textbf{Case 2: $\probprincipal> 1-h(\theta)$.} Let $\hat{\probprincipal}=1$, $\hat\classifier_1:\weights_1^T(\features-\frac{1}{\mc}\cdot v_1)\geq 0$, i.e.,  $\classifier_1$ shifting inward by a distance of $\frac{1}{\mc}$, and
%         $\hat\classifier_2:\weights_2^T(\features-\frac{1}{\mc}\cdot v_2)\geq 0$, i.e., $\classifier_2$ shifting inward by a distance of $\frac{1}{\mc}$. Then we can argue in a similar way...

%         \textbf{Case 3: $h(\theta) \leq \probprincipal\leq 1-h(\theta)$.} 
%         ...most complicated case...


%         \emph{Lastly when point $O$ is not at the boundary of set $\selected_{\probprincipal}(\tilde\classifier_1,\tilde\classifier_2)$,} the same construction we have discussed would go through. 
% \end{proof}