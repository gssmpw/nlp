\section{Omitted proof in \cref{sec:Pii}}\label{appendix: alternative objective}

We first state the two lemmas required for the proof and then we prove the two lemmas.
\begin{lemma}\label{lem:opt_sim Pii}
Consider manipulation setting and program \ref{min unqualified}.
     Suppose $\nabla \density \cdot \weights_A \leq 0$, and $\nabla \density \cdot \weights_B \geq 0$.
     % , where $\weights_A^{\perp}$ is the vector that is orthogonal to $\weights_A$ and satisfies $\weights_A^{\perp} \cdot \weights_B<0$.
    Then the optimal simultaneous mechanism $(\classifier_A^S,\classifier_B^S)$ satisfies  $\classifier_A^S\subset\classifier_A$ and $\classifier_B\subset\classifier_B^S$.
\end{lemma}


\begin{lemma}\label{lem:fix>sim Pii}

    Suppose $(\classifier_A^S,\classifier_B^S)$ is a feasible simultaneous mechanism that satisfies $\classifier_i^S\subset\classifier_i$ and $\classifier_j\subset\classifier_j^S$ for $i,j\in \{A,B\}$ and $i\neq j$.
    Then there exists a feasible fixed-order mechanism such that it is weakly better than the simultaneous mechanism $(\classifier_A^S,\classifier_B^S)$ .
\end{lemma}



\begin{proof}[Proof of \cref{prop:Pii manipulation}]
    By \cref{{lem:opt_sim Pii}}, we know that the optimal simultaneous mechanism $(\classifier_A^S,\classifier_B^S)$ satisfies  $\classifier_A^S\subset\classifier_A$ and $\classifier_B\subset\classifier_B^S$.
    By \cref{lem:fix>sim Pii}, there exists a feasible fixed order mechanism that is no worse than the optimal simultaneous mechanism. 
\end{proof}

%-------------------------------
\begin{proof}[Proof of \cref{lem:opt_sim Pii}]

    It suffices to show that given any feasible simultaneous mechanism $(\tilde\classifier_A,\tilde\classifier_B)$ that violates `$\classifier_A^S\subset\classifier_A$ and $\classifier_B\subset\classifier_B^S$', there exits another feasible simultaneous mechanism  $(\classifier_A^S,\classifier_B^S)$ that (1) satisfies  $\classifier_A^S\subset\classifier_A$ and $\classifier_B\subset\classifier_B^S$; (2) is better than $(\tilde\classifier_A,\tilde\classifier_B)$.

    Suppose the simultaneous mechanism $(\tilde\classifier_A,\tilde\classifier_B)$ is feasible and  it violates `$\tilde\classifier_A\subset\classifier_A$ and $\classifier_B\subset\tilde\classifier_B$'.
    There are three possibilities: (1) $\tilde\classifier_A$ is not a subset of $\classifier_A$ and $\classifier_B$ is a subset of $\tilde\classifier_B$ (Case 1); (2) $\tilde\classifier_A$ is not a subset of $\classifier_A$ and $\classifier_B$ is not a subset of $\tilde\classifier_B$ (Case 2);
    (3) $\classifier_B$ is not a subset of $\tilde\classifier_B$ and and $\tilde\classifier_A$ is a subset of $\classifier_A$ (Case 3).

    \paragraph{Case 1:} Suppose $\tilde\classifier_A$ is not a subset of $\classifier_A$.
    % and $\classifier_B$ is a subset of $\tilde\classifier_B$.

    We first show that the boundary of $\tilde\classifier_A$, denoted by $\tilde\Line_A$, must be in parallel with the boundary of $\classifier_A$, denoted by $\Line_A$. 
    This is true because of \cref{claim:Pii optimal sim not parallel case 1 a} and \cref{claim:Pii optimal sim not parallel case 1 b}.
    Hence $\classifier_A$ is a subset of $\tilde\classifier_A$.
    % Denote the normal vector of $\tilde\classifier_A$ by $\tilde\weights_1 $, and the normal vector of $\classifier_A$ by $\weights_1$.
    Similarly, we can show that the boundary of $\tilde\classifier_B$ must be in parallel with the boundary of $\classifier_B$.

    \begin{claim}\label{claim:Pii optimal sim not parallel case 1 a}
        Suppose $\tilde\Line_A$ intersects with $\classifier_A$ at $\classifier_A\cap\classifier_B$. Then the simultaneous mechanism $(\tilde\classifier_A,\tilde\classifier_B)$ is not feasible.
    \end{claim}

    \begin{claim}\label{claim:Pii optimal sim not parallel case 1 b}
        Suppose $\tilde\Line_A$ intersects with $\classifier_A$ at $(\classifier_A\cap\classifier_B)^\compl$. Then the simultaneous mechanism $(\tilde\classifier_A,\tilde\classifier_B)$ is not optimal.
    \end{claim}
    

    % \textbf{Step 1: constructing $\tilde\classifier_A^-$.}
    % Define  $\tilde\classifier_A^-$....


    % Denote the boundary line of  $\tilde\classifier_A^-$ by  $\tilde\Line_1^-$. 

    
    % Denote the boundary line of $\tilde\classifier_i$ by $\tilde\Line_i$, $i\in \{A,B\}$.
Denote the intersection of the boundary lines of $\tilde\classifier_i$, $i\in \{A,B\}$ by point $\tilde O$.
% $\tilde\Line_A$ and line $\tilde\Line_B$ by point $\tilde O$.
Let $r=\min \metric(\tilde O,\classifier_A)$.
Define point $O^S$ as the point that lies on the boundary line of $\classifier_A$ and is obtained by shifting $\tilde O$ along $\weights_A$ as $O^S= \tilde O+r\cdot \frac{\weights_A}{\lVert \weights_A \rVert }$.
Then the vector $v^S = O^S- \tilde O$ is parallel to $\weights_A$.
    
    Next, consider the following simultaneous mechanism: 
    let $\classifier_A^S$ be the stringent test $\classifier_A^S=\classifier_A$, and let another test $\classifier_B^S =\tilde\classifier_B+v^S$.
    See \cref{fig: Pii case 1} for illustrations.
    Then the intersecting point of the boundary lines of $\classifier_i^S$ is $O^S$.
    Moreover, by construction, $\classifier_A^S\subset \classifier_A$ and $\classifier_B\subset\classifier_B^S$.
    Thus, $\classifier_A\cap\classifier_B\subset \classifier_A^S\cap\classifier_B^S$, i.e., the simultaneous mechanism $(\classifier_A^S,\classifier_B^S)$ is feasible. 


    It remains to show that the simultaneous mechanism $(\classifier_A^S,\classifier_B^S)$ is better than the simultaneous mechanism $(\tilde\classifier_A,\tilde\classifier_B)$.
    Since feasibility requires that $\classifier_A\cap\classifier_B\subset \classifier_A^S\cap\classifier_B^S$ and $\classifier_A\cap\classifier_B\subset \tilde\classifier_A\cap\tilde\classifier_B$, to compare the probability of selecting an unqualified agent under the two mechanisms, it suffices to compare the probability of selecting an agent under the two mechanisms.
   

   We first argue that there is a one-to-one mapping between the set of agent selected under simultaneous mechanism $(\classifier_A^S,\classifier_B^S)$ and the set of agent selected under simultaneous mechanism $(\tilde\classifier_A,\tilde\classifier_B)$.
    This is because by construction and translation invariance of the cost function, for any attributes $\features$ selected under the original simultaneous mechanism $(\tilde\classifier_A,\tilde\classifier_B)$, the attributes $\features+v^S$ are also selected under the newly constructed simultaneous mechanism $(\classifier_A^S,\classifier_B^S)$.

    Since the density function $\density$ is weakly decreasing along $v^S$ (or $\weights_A$), the density of each point in the set of agent selected under simultaneous mechanism $(\classifier_A^S,\classifier_B^S)$ is weakly smaller than the corresponding point in the set of agent selected under simultaneous mechanism $(\tilde\classifier_A,\tilde\classifier_B)$.
    Hence the probability of selecting an agent under  $(\classifier_A^S,\classifier_B^S)$ is smaller.

% \paragraph{Case 2:} Suppose $\tilde\classifier_A$ is not a subset of $\classifier_A$ and $\classifier_B$ is not a subset of $\tilde\classifier_B$.

% Using similar arguments as in \cref{claim:Pii optimal sim not parallel case 1 a} and \cref{claim:Pii optimal sim not parallel case 1 b}, we can show that  the boundary of $\tilde\classifier_i$ must be in parallel with the boundary of $\classifier_i$ for $i\in \{A,B\}$. 

\begin{figure}[t]
\centering
\begin{tikzpicture}[xscale=6,yscale=6]

\draw [domain=0.76:1.36, thick] plot (\x, {3/4*\x+1/4});
\node [left] at (1.32, 1.25 ) {$\classifier_B$};
\draw [thick] (1,0.76) -- (1,1.25);
\node [right] at (1, 1.25 ) {$\classifier_A $};%: \feature_1 \geq 1$
% \node [above] at (0.76, 0.83 ) {$+$};
\node [left] at (1.27,1.2) {$+$};
 \node [right] at (1, 1.18) {$+$};


\draw [thick, blue] (0.8,0.74) -- (0.8,1.38);
\node [right, blue] at (0.8, 1.36 ) {$\tilde\classifier_A$};
\node [right, blue] at (1.2, 1.08 ) {$\tilde\classifier_B$};
\draw [domain=0.76:1.2, thick, blue] plot (\x, {3/4*(\x-0.8)+0.78});
\node [left, blue] at (0.8, 0.78 ) {\footnotesize$\tilde O$};

\node [right, red] at (1, 0.78 ) {\footnotesize$O^S$};
\draw [thick, red] (1,0.7) -- (1,1.38);
\node [above, red] at (1, 1.38 ) {$\classifier_A^S$};

\node [ red, right] at (1.36, 1.05 ) {$\classifier_B^S$};
\draw [domain=0.86:1.36, thick, red] plot (\x, {3/4*(\x-1)+0.78});

\draw [->, thick]  (0.8, 0.78 ) --(1, 0.78 ) ;
\node [below] at (0.9, 0.79 ) {\footnotesize$v^S$};


% \node [above] at (1.016, 1 ) {\footnotesize$O$};
\end{tikzpicture}
\caption{Case 1 in \cref{lem:opt_sim Pii}}
\label{fig: Pii case 1}
\rule{0in}{1.2em}$^\dag$\scriptsize In this graph, the gray line represents the boundary line of $\tilde\classifier_B+v^S$, which does not cover
$\classifier_B$. Hence we pick $\classifier_B^S=\classifier_B$ so that  the simultaneous mechanism $(\classifier_A^S,\classifier_B^S)$ is feasible and improves upon the simultaneous mechanism $(\tilde\classifier_A,\tilde\classifier_B)$.
\end{figure}



\paragraph{Case 2:}  Suppose $\tilde\classifier_A$ is not a subset of $\classifier_A$.
    and $\classifier_B$ is not a subset of $\tilde\classifier_B$.
    
    The analysis is similar to case 1.
    Denote the intersection of the boundary lines of $\tilde\classifier_i$, $i\in \{A,B\}$ by point $\tilde O$.
% $\tilde\Line_A$ and line $\tilde\Line_B$ by point $\tilde O$.
Let $r=\min \metric(\tilde O,\classifier_A)$.
Define point $O^S$ as the point that lies on the boundary line of $\classifier_A$ and is obtained by shifting $\tilde O$ along $\weights_A$ as $O^S= \tilde O+r\cdot \frac{\weights_A}{\lVert \weights_A \rVert }$.
Then the vector $v^S = O^S- \tilde O$ is parallel to $\weights_A$.

If $\tilde\classifier_B+v^S$ covers $\classifier_B$, 
consider the following simultaneous mechanism: 
    let $\classifier_A^S$ be the stringent test $\classifier_A^S=\classifier_A$, and let another test $\classifier_B^S =\tilde\classifier_B+v^S$.
    We can use the same argument as in case 1 to show that  the simultaneous mechanism $(\classifier_A^S,\classifier_B^S)$ is feasible and improves upon the simultaneous mechanism $(\tilde\classifier_A,\tilde\classifier_B)$.
    See \cref{fig: Pii case 2} for illustrations.
    
If $\tilde\classifier_B+v^S$ does not cover $\classifier_B$, 
    we consider the following simultaneous mechanism instead: 
    let $\classifier_A^S$ be the stringent test $\classifier_A^S=\classifier_A$, and let another test $\classifier_B^S =\tilde\classifier_B$.

    The simultaneous mechanism $(\classifier_A^S,\classifier_B^S)$ is feasible. This is because $\classifier_A^S\cap\classifier_B^S$  covers $\classifier_A\cap\classifier_B$.

 Consider the vector $v^S =O- \tilde O$.
    Then there is a one-to-one mapping between the set of agent selected under simultaneous mechanism $(\classifier_A^S,\classifier_B^S)$ and the set of agent selected under the simultaneous mechanism $(\tilde\classifier_A,\tilde\classifier_B)$.
    For any attributes $\features$ selected under the original simultaneous mechanism $(\tilde\classifier_A,\tilde\classifier_B)$, the attributes $\features+v^S$ are also selected under the newly constructed simultaneous mechanism $(\classifier_A^S,\classifier_B^S)$.
    
Since the density function $\density$ is weakly decreasing along  $\weights_A$ and $-\weights_B$, 
the density function $\density$ is also weakly decreasing along the vector $v^S$. 
Hence, 
the density of each point in the set of agent selected under simultaneous mechanism $(\classifier_A^S,\classifier_B^S)$ is weakly smaller than the corresponding point in the set of agent selected under simultaneous mechanism $(\tilde\classifier_A,\tilde\classifier_B)$.
    Hence the probability of selecting an agent under  $(\classifier_A^S,\classifier_B^S)$ is smaller, implying that  $(\classifier_A^S,\classifier_B^S)$ improves upon the simultaneous mechanism $(\tilde\classifier_A,\tilde\classifier_B)$.

\begin{figure}[t]
\centering
\begin{tikzpicture}[xscale=6,yscale=6]

\draw [domain=0.76:1.36, thick] plot (\x, {3/4*\x+1/4});
\node [above] at (1.36, 1.24 ) {$\classifier_B$};
\draw [thick] (1,0.78) -- (1,1.25);
\node [right] at (1, 0.8 ) {$\classifier_A \text{ }+$};%: \feature_1 \geq 1$
% \node [above] at (0.76, 0.83 ) {$+$};
\node [left] at (1.27,1.2) {$+$};
% \node [right] at (1, 0.8) {$+$};


\draw [thick, blue] (0.8,0.78) -- (0.8,1.38);
\node [right, blue] at (0.8, 1.36 ) {$\tilde\classifier_A$};
\node [left, blue] at (1.16, 1.36 ) {$\tilde\classifier_B$};
\draw [domain=0.76:1.2, thick, blue] plot (\x, {3/4*(\x-0.8)+1.08});
\node [left, blue] at (0.8, 1.08 ) {\footnotesize$\tilde O$};

\node [right, gray] at (1, 1.08 ) {\footnotesize$O^S$};
\draw [thick, red] (1,1) -- (1,1.38);
\node [above, red] at (1, 1.38 ) {$\classifier_A^S$};

\node [ gray] at (1.35, 1.35 ) {$\tilde\classifier_B+v^S$};
\draw [domain=0.86:1.36, thick, gray] plot (\x, {3/4*(\x-1)+1.08});

% \draw [->, thick]  (0.8, 1.08 ) --(1, 1.08 ) ;
% \node [below] at (0.9, 1.08 ) {\footnotesize$v^S$};


% \node [above] at (1.016, 1 ) {\footnotesize$O$};
\end{tikzpicture}
\caption{Case 2 in \cref{lem:opt_sim Pii}}
\label{fig: Pii case 2}
\rule{0in}{1.2em}$^\dag$\scriptsize In this graph, the gray line represents the boundary line of $\tilde\classifier_B+v^S$, which does not cover
$\classifier_B$. Hence we pick $\classifier_B^S=\classifier_B$ so that  the simultaneous mechanism $(\classifier_A^S,\classifier_B^S)$ is feasible and improves upon the simultaneous mechanism $(\tilde\classifier_A,\tilde\classifier_B)$.
\end{figure}

\paragraph{Case 3:} Suppose $\classifier_B$ is not a subset of $\tilde\classifier_B$
 and  $\tilde\classifier_A$ is a subset of $\classifier_A$.


    Using similar arguments in  \cref{claim:Pii optimal sim not parallel case 1 a} and \cref{claim:Pii optimal sim not parallel case 1 b}, we can show that the boundary of $\tilde\classifier_B$ must be in parallel with the boundary of $\classifier_B$. 

   Let $\weights_A^{\perp}$ be the vector that is orthogonal to $\weights_A$ and satisfies $\weights_A^{\perp} \cdot \weights_B<0$.
   Since $\nabla \density \cdot \weights_A \leq 0$, and $\nabla \density \cdot \weights_B \geq 0$, we must have $\nabla \density \cdot \weights_A^{\perp} \leq 0$, i.e., the density function is weakly decreasing along the direction of $\weights_A^{\perp}$.
  Denote the intersection of the boundary lines of $\tilde\classifier_i$, $i\in \{A,B\}$ by point $\tilde O$.
% $\tilde\Line_A$ and line $\tilde\Line_B$ by point $\tilde O$.
Let $r=\min \metric(\tilde O,\classifier_B)$.
Define point $O^S$ as the point that lies on the boundary line of $\classifier_B$ and is obtained by shifting $\tilde O$ along $-\weights_B$ as $O^S= \tilde O-r\cdot \frac{\weights_B}{\lVert \weights_B \rVert }$.
Then the vector $v^S = O^S- \tilde O$ is parallel to $-\weights_B$.
    
    Next, consider the following simultaneous mechanism: 
    let $\classifier_A^S$ be the stringent test $\classifier_A^S=\tilde\classifier_A+v^S$, and let another test $\classifier_B^S =\classifier_B$.
    Then the intersecting point of the boundary lines of $\classifier_i^S$ is $O^S$.
    Moreover, by construction, $\classifier_B\subset \classifier_B^S$ and $\classifier_A^S\subset\classifier_A$.
    
    We show that  the simultaneous mechanism $(\classifier_A^S,\classifier_B^S)$ is feasible.
    Using the characterization of the agent's best response in a simultaneous mechanism, it suffices to show that attributes $O$ is accepted by  the simultaneous mechanism $(\classifier_A^S,\classifier_B^S)$.
    Since $(\tilde\classifier_A,\tilde\classifier_B)$ is feasible, then the cost for attributes $O$ to move to some $\features\in \tilde\classifier_A\cap\tilde\classifier_B$ must be less than one, i.e., $\onecost(O,\features)\leq 1$.
    Under the cost function, we know that such attributes $\features=\tilde O$.
    By triangle inequality, $\onecost(O,O^S)\leq \onecost(O,\tilde O) - \onecost(O^S,\tilde O)< 1$.
    Hence attributes $O$ is accepted by  the simultaneous mechanism $(\classifier_A^S,\classifier_B^S)$.
    This implies that the distance between the boundary line of $\classifier_A$ and $\classifier_A^S$ is less than $1/\eta$.
    Hence the simultaneous mechanism $(\classifier_A^S,\classifier_B^S)$ is feasible.

Similarly, there is a one-to-one mapping between the set of agent selected under simultaneous mechanism $(\classifier_A^S,\classifier_B^S)$ and the set of agent selected under the simultaneous mechanism $(\tilde\classifier_A,\tilde\classifier_B)$.
Since the density function $\density$ is weakly decreasing along $v^S$ (or $-\weights_B$), the density of each point in the set of agent selected under simultaneous mechanism $(\classifier_A^S,\classifier_B^S)$ is weakly smaller than the corresponding point in the set of agent selected under simultaneous mechanism $(\tilde\classifier_A,\tilde\classifier_B)$.
    Hence the probability of selecting an agent under  $(\classifier_A^S,\classifier_B^S)$ is smaller, implying that  $(\classifier_A^S,\classifier_B^S)$ improves upon the simultaneous mechanism $(\tilde\classifier_A,\tilde\classifier_B)$.
    
\end{proof}


%--------------------------------
\begin{proof}[Proof of \cref{lem:fix>sim Pii}]

    Without loss of generality, consider the case $\classifier_B^S\subset\classifier_B$ and $\classifier_A\subset\classifier_A^S$.


    \paragraph{Step 1: constructing stringent test $\classifier_i^{+}, i\in \{A,B\}$.}
    Let $\classifier_i^{+}$ to be the half plane obtained from shifting $\classifier_i$ along the direction of $\weights_i$ by a distance of $1/\eta$.
%     We use $i=A$ as an example since the construction for $i=B$ is analogous.
%     By continuity and boundedness, there exists some $\firstfeatures\in \classifier_A^C$ such that $\min_{\genericfeatures\in \classifier_A}\onecost(\firstfeatures,\genericfeatures)=1$.

% We show that there exists some $\tilde\genericfeatures\in \Line_1$ such that $\onecost(\firstfeatures,\tilde\genericfeatures)=1$. Suppose not. Then for any $\genericfeatures\in \Line_1$, $\onecost(\firstfeatures,\genericfeatures)>1$.
% Moreover, since $\min_{\genericfeatures\in \classifier_A}\onecost(\firstfeatures,\genericfeatures)=1$, there exists $\hat \genericfeatures \in \classifier_A\setminus\Line_1$, such that $\onecost(\firstfeatures,\hat\genericfeatures)=1$.
% Let $\genericfeatures^\dag$ be the point where $\firstfeatures\hat\genericfeatures$ intersect with line $\Line_1$.
% Then $\onecost(\firstfeatures,\genericfeatures^\dagger)>\onecost(\firstfeatures,\hat\genericfeatures)$, while $\genericfeatures^\dagger$ is a convex combination of $\firstfeatures$ and $\hat\genericfeatures$. A contradiction to the cost function being directional monotone.
   
%     Let $\genericfeatures^\ddag$ be any non-zero vector such that $\genericfeatures^\ddag\cdot \weights_1=0$, i.e., $\genericfeatures^\ddag$ is parallel to line $\Line_1: \weights_1\cdot \features =0$.
%     Since the cost function is translation invariant, we must have $\onecost(\firstfeatures+\genericfeatures^\ddag,\tilde\genericfeatures+\genericfeatures^\ddag)=1$.
%     Moreover, we know that $\tilde\genericfeatures+\genericfeatures^\ddag\in \Line_1$. 

%     Next we show that $\min_{\genericfeatures\in \classifier_A}\onecost(\firstfeatures+\genericfeatures,\genericfeatures)=1$.
%     Suppose this is not true, i.e., $\min_{\genericfeatures\in \classifier_A}\onecost(\firstfeatures+\genericfeatures,\genericfeatures)<1$. 
%     Then we can find some $\genericfeatures\in \classifier_A$, such that $\onecost(\firstfeatures+\genericfeatures,\genericfeatures)<1$.
%     By translation invariance, we must also have $\min_{\genericfeatures\in \classifier_A}\onecost(\firstfeatures,\genericfeatures)<1$. A contradiction.
    
    
%     Let $\boldsymbol{y}=\tilde\genericfeatures-\features$.
%     Let $\classifier_A^+: \genericfeatures+\boldsymbol{y}$, for any $\genericfeatures\in \classifier_A$.

%     % Similarly, there exists some $\secondfeatures\in \classifier_B^C$ such that $\min_{\genericfeatures\in \classifier_B}\onecost(\secondfeatures,\genericfeatures)=1$. 
%     % Moreover, there exists some $\tilde\genericfeatures'\in \Line_2$ such that $\onecost(\secondfeatures,\tilde\genericfeatures')=1$.
%     % Let $\boldsymbol{y}'=\tilde\genericfeatures'-\secondfeatures$.
%     % We can define $\classifier_B^+: \genericfeatures+\boldsymbol{y}'$, for any $\genericfeatures\in \classifier_B$.
% We point out one useful property of the simultaneous mechanism that would be useful in the proof later.
% Since the simultaneous mechanism is feasible, we must have $\classifier_i^+\subset\classifier_i^S$.

\paragraph{Step 2: constructing the feasible fixed order mechanism.} Consider the fixed order mechanism that uses  $\classifier_A$  as the first test and $\classifier_B^+$ as the second test.
For any qualified attributes $\features\in \classifier_A\cap\classifier_B$, if they are also in $\features\in \classifier_A\cap\classifier_B^+$, then they are selected in the fixed order mechanism.
If they are not in $\features\in \classifier_A\cap\classifier_B^+$, then it must fall in $\classifier_B^+\cap\classifier_B$.
Since such qualified attributes satisfy $\classifier_A$, they can pass the first test under the fixed order mechanism by not making any changes.
Moreover, by the construction of $\classifier_B^+$, such attributes can change to some attributes that pass $\classifier_B^+$ with cost less than one.
Therefore, this fixed order mechanism selects all qualified attributes.



\paragraph{Step 3: fixed order mechanism $(\classifier_A,\classifier_B^+,1)$ is no worse than the simultaneous mechanism.} 
To show this, we want to show that any unqualified attributes that are not selected by the simultaneous mechanism are not selected by the fixed order mechanism.

\textbf{Case 1.} Consider some  attributes $\features$  that do not satisfy $\classifier_B$. By the construction of $\classifier_B^+$, such attributes do not have a profitable one-step strategy to pass $\classifier_B^+$. We want to show that there does not exist any profitable two-step strategy for such attributes to get selected either. Suppose not and now such attributes find it profitable to first change to some attributes $\firstfeatures$ that satisfy $\classifier_A$ and then other attributes $\secondfeatures$ that satisfy $\classifier_B^+$.
Since such a strategy is profitable we must have $\onecost(\features,\firstfeatures)+\onecost(\firstfeatures,\secondfeatures)\leq1$.
By triangle inequality, we have $\onecost(\features,\secondfeatures)\leq1$, which implies the existence of a profitable one-step strategy for such attributes. A contradiction. Hence attributes that do not satisfy $\classifier_B$ can never be selected by the fixed mechanism.

\textbf{Case 2.} Consider some  attributes $\features$  that do not satisfy $\classifier_A$. Suppose such  attributes $\features$  are not selected by the simultaneous mechanism. This implies that such attributes can only get selected by the fixed order mechanism through some two-step strategy. Suppose such attributes find it profitable to first change to some attributes $\firstfeatures$ that satisfy $\classifier_A$ and then other attributes $\secondfeatures$ that satisfy $\classifier_B^+$. Since it is a profitable strategy, we must have $\onecost(\firstfeatures,\secondfeatures)\leq1$ and hence $\firstfeatures\in \classifier_B$.
Therefore, $\firstfeatures\in \classifier_A\cap \classifier_B$, i.e., $\firstfeatures$ are qualified and selected by the simultaneous mechanism.
Since $\features$  are not selected by the simultaneous mechanism, $\firstfeatures$ must not satisfy the two tests $\classifier_i^S,i\in \{1,2\}$ of the simultaneous mechanism at the same time, i.e., $\firstfeatures\not\in\classifier_A^S\cap \classifier_B^S$. We know that $\firstfeatures$ satisfies $\classifier_A$ and therefore must satisfy $\classifier_A^S$. This implies that $\firstfeatures$ do not satisfy $\classifier_B^S$.
However, since the simultaneous mechanism is feasible, $\firstfeatures$ are selected under the simultaneous mechanism.
This implies that there exists at least one profitable one-step strategy for $\firstfeatures$ to satisfy $\classifier_B^S$, i.e., $\min_{\genericfeatures\in \classifier_B^S}\onecost(\firstfeatures,\genericfeatures)<1$.
Since $\classifier_B^+\subset\classifier_B^S$, we can find the attributes $\features'$ that are the intersection of the line connecting $\features$ and $\secondfeatures$ and the boundary of $\classifier_B^S$.
We then have  $\onecost(\firstfeatures,\features')\leq \min_{\genericfeatures\in \classifier_B^S}\onecost(\firstfeatures,\genericfeatures)<1$.
Since $\classifier_B^+\subset\classifier_B^S$, we have $\onecost(\firstfeatures,\features')< \onecost(\firstfeatures,\secondfeatures)=\min_{\genericfeatures\in \classifier_B^+}\onecost(\firstfeatures,\genericfeatures)$.
By triangle inequality, we have $\onecost(\features,\features')\leq \onecost(\features,\firstfeatures)+\onecost(\firstfeatures,\features')\leq \onecost(\features,\firstfeatures)+\onecost(\firstfeatures,\secondfeatures)\leq1$.
Since $\features'$ satisfy the two tests $\classifier_i^S,i\in\{1,2\}$ under the simultaneous mechanism, this implies that $\features$ are also selected under the simultaneous mechanism. A contradiction.

We conclude that any unqualified attributes that are not selected by the simultaneous mechanism are not selected by the fixed order mechanism. Hence the fixed order mechanism is no worse than the simultaneous mechanism. 



\end{proof}


