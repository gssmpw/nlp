\subsection{Robustness to cost functions}\label{subsec: seq general cost}

In this subsection, we consider a larger class of cost functions. 

\begin{assumption}[translation invariance]\label{def: translation invariant}
    The cost function $c : \bbR^6 \to \bbR$ is \emph{translation invariant} if for any attributes $\orifeatures, \firstfeatures,\secondfeatures$ and any shift vector $\genericfeatures\in \bbR^2$, $c(\orifeatures, \firstfeatures,\secondfeatures) = c(\orifeatures+\genericfeatures, \firstfeatures+\genericfeatures,\secondfeatures+\genericfeatures)$.
\end{assumption}

\begin{assumption}[absolute homogeneity]\label{def: absolute homogenous c}
    The cost function $c : \bbR^6 \to \bbR$ is \emph{absolute homogeneous} if for any attributes $\orifeatures, \firstfeatures,\secondfeatures$, and any $\alpha\in \bbR$, $c(\alpha\orifeatures, \alpha\firstfeatures,\alpha\secondfeatures) = |\alpha|c(\orifeatures, \firstfeatures,\secondfeatures)$.
\end{assumption}
This assumption can also be easily extended to homogeneity of any degree $m$ for $m\in \bbR_+$, i.e., $c(\alpha\orifeatures, \alpha\firstfeatures,\alpha\secondfeatures) = |\alpha|^m c(\orifeatures, \firstfeatures,\secondfeatures)$.

\begin{assumption}[triangle inequality]\label{def: trainagle inequality}
    The cost function $c : \bbR^6 \to \bbR$ satisfies triangle inequality if for any attributes $\features,  \boldsymbol{y}, \genericfeatures$, 
    $$\cost(\features, \boldsymbol{y}, \genericfeatures)\geq \onecost(\features,  \genericfeatures).$$ 
\end{assumption}

\begin{assumption}[monotonicity]\label{def: monotone}
    The cost function $c : \bbR^6 \to \bbR$ is monotone if for any attributes $\features, \boldsymbol{y}, \genericfeatures$, 
    $$\cost(\features, \boldsymbol{y}, \genericfeatures)\geq \onecost(\features,  \boldsymbol{y}).$$ 
\end{assumption}


\begin{assumption}[regular]\label{def: existence of minimum cost}
    The cost function $\onecost: \bbR^4 \to \bbR$ is regular if for any attributes $\features$ and any half plane $\classifier$, there exists some $\boldsymbol{y}\in \classifier$ such that 
    $$\onecost(\features, \boldsymbol{y})=\inf_{\genericfeatures\in \classifier}\onecost(\features,\genericfeatures).$$    
\end{assumption}





If the cost function only depends on the differences between the $i$-th attributes and $(i-1)$-th attributes, for $i\in \{1,2\}$, i.e., 
$\cost(\orifeatures,\firstfeatures,\secondfeatures)=c(\firstfeatures-\orifeatures,\secondfeatures -\orifeatures, \secondfeatures-\firstfeatures)$, then the cost function is translation invariant. 


Triangle inequality is reminiscent of the upward triangle inequality in \citet{perez2022test}.
The main difference is that in \citet{perez2022test}, the three attributes lie on the same line, while here, the three attributes lie on the same plane.
It means that the cost of changing from any initial attributes $\orifeatures$ to any $\secondfeatures$ would increase if the agent takes an extra middle step.
This is consistent with our applications where changing attributes require either physical effort or forgone profitability.

Monotonicity rules out transient cost or negative cost. 
Consider a scenario where the agent has to purchase extra equipment to pass the first test but afterwards he is free to sell the equipment.
This would result in $\cost(\orifeatures, \firstfeatures,\secondfeatures)<\onecost(\orifeatures, \firstfeatures)$, which violates monotonicity.
This is a reasonable condition in the manipulation setting. 
In the hiring example, $\firstfeatures$ and $\secondfeatures$ represent how the profile of a candidate appears to be in a job interview.
The cost of changing the candidate's profile represents the cost of actual effort.
Once the effort is exerted, it is sunk.
In the bank regulation example, $\firstfeatures$ and $\secondfeatures$ represent the balance sheet positions of a bank.
Adjusting the balance sheet usually incurs transaction costs.



We cover the extreme case where the cost of modifying attributes is infinity, i.e., the hard evidence environment. In this extreme case, no agent is able to change their attributes. Our results show that the fixed-order mechanism with the original two tests $\classifier_A$ and $\classifier_B$ is still optimal. Moreover, it accepts all qualified agents and no unqualified agent. 



Here are two classes of additive cost functions that satisfy \cref{def: translation invariant}-\ref{def: existence of minimum cost}.
\begin{itemize}
    \item  $
c(\orifeatures,\firstfeatures,\secondfeatures)= \onecost(\orifeatures,\firstfeatures) + \onecost(\firstfeatures,\secondfeatures) 
$, where $\onecost(\cdot,\cdot)$ is a metric.
% \item $
% c(s)= \eta \cdot (d((\firstfeatures-\orifeatures)^+,\boldsymbol{0}) + d((\secondfeatures-\firstfeatures)^+,\boldsymbol{0}) ),
% $ for $\mc>0$, where $(\genericfeatures-\features)^+=((\genericfeature_A-\feature_A)^+,(\genericfeature_B-\feature_B)^+)$.
    \item $
\cost(\orifeatures,\firstfeatures,\secondfeatures) =\onecost(\orifeatures,\firstfeatures) + \onecost(\orifeatures,\secondfeatures),
 $ where  $\onecost(\cdot,\cdot)$ is a metric.
\end{itemize}



\subsubsection{Manipulation}\label{subsubsec: general cost manipulation}


\begin{proposition}\label{thm:opt_manipulation}
    Suppose the cost function $c$ satisfies \cref{assump: cost function one step}-\ref{def: existence of minimum cost}.
    Consider manipulation setting.
    For any distribution $\dist$, there exists a fixed-order sequential mechanism that outperforms the optimal simultaneous mechanism. Moreover, this fixed-order sequential mechanism 
    uses two stringent tests $\widetilde\classifier_A, \widetilde\classifier_B$, i.e., $\widetilde\classifier_A\cap \widetilde\classifier_B \subsetneq \classifier_A\cap \classifier_B$
\end{proposition}


To prove this theorem, we first pin down the optimal tests under that the optimal simultaneous mechanism in \cref{prop:optimal simultaneous manipulation general cost}.
Second, we show that the fixed-order mechanisms that use the same tests as in the optimal simultaneous mechanism are also feasible 
 and select more potential qualified agents than the optimal simultaneous mechanism (\cref{lem:fix-simul}).
These two together imply that the optimal mechanism must be sequential.
Third, we show that any feasible mechanism must use stringent tests (\cref{lem:stringent tests}).
Hence we conclude that the optimal mechanism has the described properties.
All omitted proofs in this subsection can be found in \cref{appendix:general costs}.



 \begin{proposition}\label{prop:optimal simultaneous manipulation general cost}
 Consider the manipulation setting.
    Suppose the one-step cost function $\onecost : \bbR^4 \to \bbR$  satisfies \cref{def: translation invariant} ( translation invariant),\cref{def: absolute homogenous c} (absolute homogeneous) and \cref{def: existence of minimum cost}.
    For any distribution $\dist$, the optimal simultaneous mechanism uses two stringent tests $\classifier_A^{+},\classifier_B^{+}$ where $\classifier_i^{+}\subset \classifier_i$ for $i\in \{A,B\}$.
    \end{proposition}

% To understand this proposition, suppose for a moment that $\onecost(\cdot,\cdot)$ is the Euclidean distance and the test $h_{A}\cap h_{B}$ is used in the simultaneous mechanism. Recall that $%
% h_{A}\cap h_{B}$ is the region of qualified attributes.
% This implies that any agent with true attributes $\orifeatures\in h_{A}\cap h_{B}$
% will not manipulate and will be selected. In addition, agents with true
% attributes $\orifeatures\notin h_{A}\cap h_{B}$ will be selected only if they pay a
%  cost to adopt attributes that are in the qualified region. Since
% the benefit of doing so (i.e., getting selected) is 1, only those with cost
% no greater than 1 will be willing to do so. The set of candidates who are
% willing to do such preparation is 
% \[
% \manipulation=\left\{ \orifeatures\notin h_{A}\cap h_{B}:\min_{\features\in h_{A}\cap
% h_{B}}\onecost(\orifeatures,\features)\leq 1\right\} \text{.}
% \]%
% This set $\manipulation$ comprises all points whose distance to either the two edges of
% the qualified region $h_{A}\cap h_{B}$ is no greater than 1.

% The simultaneous mechanism that passes agents in the qualified region $%
% h_{A}\cap h_{B}$ selects some unqualified agents, so does not satisfy
% the principal's objective. In order not to select any unqualified agents,
% the principal must choose a more stringent test. For example, under Euclidean distance cost, such a more
% stringent test would be $h_{A}^{+}\cap h_{B}^{+}$, where $h_{i}^{+}$ is
% obtained by a parallel shift of $h_{i}$ by a distance of 1. It turns out $h_{A}^{+}\cap
% h_{B}^{+}$ is the optimal simultaneous mechanism.
% As alluded before, this is because shifted non-parallel tests are either not feasible or not optimal (See \cref{fig:non-parallel tests not optimal}).
%  It also turns out that although the exact optimal stringent tests depend on the cost function, this reasoning is not confined to Euclidean cost function and can be extended to cost functions that are translation invariant, absolute homogeneous, and regular.

Next, we compare the optimal simultaneous mechanisms and the fixed-order mechanisms that use the same tests. 
\begin{lemma}\label{lem:fix-simul}
    Given the optimal simultaneous mechanism  $(\classifier_A^{+},\classifier_B^{+})$, the two  fixed-order mechanisms $(\classifier_A^{+},\classifier_B^{+},1)$ and $(\classifier_A^{+},\classifier_B^{+},0)$ are also \emph{feasible} and  are weakly better than the simultaneous mechanism. 
\end{lemma}



% To understand this lemma, suppose now the principal uses a sequential mechanism that offers test $h_{A}$ at the first stage, and (2) among those
% selected in (1), those whose attributes belong to $h_{B}$ will be eventually
% selected. Using the same intuition we discussed before, we can characterize the set of attributes that get selected under such a fixed-order mechanism (see for instance \cref{fig: zig zag} and discussions in \cref{sec: distance cost}).

% In order not to select any unqualified agent, the principal needs to choose
% more stringent tests instead of $h_{A}$ and $h_{B}$. One obvious candidate is the same stringent tests  in the optimal simultaneous mechanism: $%
% h_{A}^{+}$ and $h_{B}^{+}$.
% It remains to check that all agents selected by the fixed-order sequential mechanism are qualified under tests $%
% h_{A}^{+}$ and $h_{B}^{+}$.
% It turns out that this is indeed the case here.
% However, in general, even under additive Euclidean cost function, there are tests that are feasible under simultaneous mechanisms but are not feasible under fixed-order sequential mechanisms.

% Which mechanism: the optimal simultaneous mechanism  $h_{A}^{+}\cap h_{B}^{+}$ or fixed-order sequential $%
% h_{A}^{+}$ and $h_{B}^{+}$ is preferred by the principal? This
% problem has been posed by \citet{zigzag} under additive Euclidean cost; however, there is an error in the proof of their main result (Theorem 4.4), which we correct here. 
% Observe that by using the fixed-order sequential mechanism $%
% h_{A}^{+}$ and $h_{B}^{+}$, the principal selects more agents than
% by using the simultaneous mechanism $h_{A}^{+}\cap h_{B}^{+}$ under the additive Euclidean distance cost. This is
% because the fixed-order sequential mechanism enables agents to use two-step
% strategies, which are cheaper (sometimes strictly) than the best one-step
% strategy. It turns out that this reasoning is quite general and not confined to the additive Euclidean distance cost.



\begin{lemma}\label{lem:stringent tests}
    Any feasible mechanism uses stringent tests, i.e., the two tests the mechanism announces $\tilde\classifier_A$ and $\tilde\classifier_B$  satisfies $\tilde\classifier_A\cap\tilde\classifier_B\subsetneq \classifier_A\cap\classifier_B$.
\end{lemma}








\subsubsection{Investment}\label{subsubsec:investment}
We have shown that in the investment setting, the simultaneous mechanism using the true criteria as the tests achieves the first best (\cref{thm:optimal investment}). 
This is true for any cost function.
% However, sometimes it is not possible to merge two agencies into a single one.
Despite its power, we continue to study the optimal sequential mechanism under investment for two reasons.
First, practically speaking, it is sometimes hard to implement simultaneous mechanisms because of physical constraints.
Second, it helps us to understand better how the two classes of mechanisms work under investment.
In these scenarios, it is useful to know what the optimal sequential mechanism is like.


% \begin{proposition}\label{thm:optimal investment}
%     Consider  the investment setting.  
%     For any distribution $\dist$ and any cost function $\cost$, the optimal simultaneous  mechanism uses two tests that coincide with the true requirement: $\classifier_A$ and $\classifier_B$. Moreover, it achieves the first best (upper bound of the objective value).
%     % Moreover, such a mechanism achieves the first best (upper bound of the objective value) under objective \ref{max qualified}. 
% \end{proposition}

% \begin{proof}[Proof of \cref{thm:optimal investment}]
%     We show that the described simultaneous mechanism achieves the upper bound of the value of program \ref{max qualified}. 
%     First notice that any qualified agent gets selected with zero cost under the described mechanism.
%     Second, we show that the described mechanism accepts every unqualified agent who can improve to another qualified attributes with cost less than one.
%     Consider an unqualified agent with attributes $\features\not\in\classifier_A \cap \classifier_B$. 
%     Suppose there exists attributes $\features'$ such that (1)  $\features'$ satisfy both tests $\classifier_A$ and $\classifier_B$; and (2)  such an agent can move to $\features'$ with cost $c(\features, \features', \features') \leq 1$.
%     Then this unqualified agent has an incentive  to improve his attributes to $\features'$ and get accepted.  
%     However, if instead such attributes $\features'$ do not exist and for any attributes $\features''$ in $\classifier_A \cap \classifier_B$, the cost for this agent with attributes $\features$ to improve to $\features''$ is strictly larger than one, then this unqualified agent has no incentive to move to the qualified region $\classifier_A \cap \classifier_B$ in any mechanism.
%     % While any unqualified agent with attributes in $\{\features : d(\features, \classifier_1\cap \classifier_2) > 1/\eta\}$ needs to pay a cost strictly greater than $1$ to reach qualified region $\classifier_1 \cap \classifier_2$.   
%     Thus, the simultaneous mechanism that uses tests $\classifier_A$ and $\classifier_B$ accepts every agent who is either qualified or can improve their attributes to the qualified region with a cost less than one. 
%     This is the upper bound of the value of program \ref{max qualified}.
%     Hence the described simultaneous mechanism is optimal.
% \end{proof}

% The proof shows that the optimal simultaneous mechanism achieves the upper bound of the value under \ref{max qualified}, i.e., the first best scenario.
% Intuitively, this is because by offering two tests simultaneously, a simultaneous mechanism essentially offers a stricter test that coincides with the qualified region. 
% Not only it selects every qualified agent, but it also induces the initially unqualified agent to invest and become qualified.
% Moreover, the strictness notion here is different from the notion of  stringent tests we used in the previous section.
% Here, strictness refers to the definition of the test, while before, a stringent test refers to the standard of a linear test.
% Setting higher standard for any linear test does not help in the investment setting, but using two linear tests simultaneously encourages most investment.

Therefore, in this subsection, we generalize the result on optimal sequential mechanism in the investment setting (\cref{thm: true effort sequential}) to a broader class of cost functions. 
All proofs are omitted in this subsection and will be provided in \cref{appendix: seq general cost}.

In general, analyzing sequential mechanism under investment is more challenging than under manipulation setting.
As in the manipulation setting, we first need to characterize the agent's best response under a given mechanism.
Moreover, under investment, we also need to keep track of the eventual attributes the agent adopts, in order to decide whether the agent becomes qualified.
The second step can easily get very complicated even when there are nice topological properties coming from the cost function.

Nonetheless, in this subsection, we first provide a condition (\cref{condition:one-step}) under which the agent behaves in the same way under random-order mechanism and under simultaneous mechanism, implying that any simultaneous mechanism can be implemented by some random-order mechanism.

The following condition characterizes any agent's behavior, i.e., best response, in a mechanism.
\begin{conditionp}{O}\label{condition:one-step}
     Every agent prefers some one-step strategy to any two-step strategy.
\end{conditionp}

This condition holds trivially in any simultaneous mechanism.
However, it is not trivial to check when this condition holds in a sequential mechanism.
In general, whether this condition holds in a sequential mechanism is linked to  the cost function and properties of the mechanism.
We will provide examples later to illustrate such a connection.
Equivalently, this condition can be rephrased as the following.

\begin{conditionp}{O'}\label{condition:one-step'}
     No agent prefers using any two-step strategy.
\end{conditionp}

\begin{proposition}\label{lem: optimal max qualified improving effort}
    Consider  the investment setting and program \ref{max qualified}.
    Suppose the cost function satisfies \cref{assump: cost function one step} and \ref{def: translation invariant} (translation invariant).   
    For any distribution $\dist$, if there exists a feasible  random-order mechanism without disclosure $(\tilde \classifier_A, \tilde \classifier_B,q,\nullset)$ in which \cref{condition:one-step} holds, then the optimal sequential mechanism is an  random-order mechanism without disclosure using two tests $\classifier_A,\classifier_B$ and the same randomization probability, i.e., $( \classifier_A,  \classifier_B,q,\nullset)$. 
    
    Moreover, it achives the first best.
\end{proposition}


Although this condition holds for a relatively large class of cost functions, it is not easy to interpret using primitives unless we are equipped with a concrete cost function.
The existence of a feasible  random-order mechanism without disclosure in which \cref{condition:one-step} holds usually depends on: (1) the cost function,  the mechanism, including (2) the angle between the two tests (usually linked to the angle of the qualified region), and (3) the randomization probability and the disclosure decision.
However, to characterize the condition on cost function and the properties of the mechanism that guarantees \cref{condition:one-step} holds is very challenging.
This is because we usually need to completely characterize agent's best response, which requires finding and comparing the best one-step and two-step strategy.
This becomes very difficult when there are not enough topological properties being imposed on the cost function.
Hence, we only provide examples under the additive Euclidean cost function to illustrate the connection between the primitives and \cref{condition:one-step}.

 Under this cost function, there always exists a feasible uninformed random order mechanism in which \cref{condition:one-step} holds if and only if $\theta\geq 30^{\circ}$.
From the previous analysis, we can see that any two-step strategy requires the agent to first adopt attributes that satisfy one test but failing another and later adopt different attributes that satisfy the second test but failing the first.
Holding other primitives fixed, such two-step strategies become less appealing when the randomization probability over the order of the tests is closer to $0.5$ because the randomization creates strategic uncertainty, i.e., it is harder for the agent to predict which test is more likely to be the first one.
Moreover, the no disclosure decision also makes two-step strategies less appealing.
In any sequential mechanism with randomization probability $0.5$ and no disclosure, such strategic uncertainty is maximized.

Holding the randomization probability and disclosure decision fixed, when the two tests are far away from each other, two-step strategy becomes costly and could be less appealing than some one-step strategy by adopting some attributes that satisfy both tests at the same time.
Intuitively, the two tests being far away from each other is measured by both the angle between the two tests and the cost function, which is being held fixed here.
 Recall that $\theta$ is the angle of the qualified region.
$\theta\geq30^{\circ}$ can therefore be understood as the two requirements $\classifier_A$ and $\classifier_B$ are far away from each other. 
% When $ \theta\leq \frac{\pi}{2}$, for any attributes that fail both requirements, i.e., $\orifeatures\in (\classifier_A\cap\classifier_B)^{\compl}$, any two-step strategy that enables the agent to be selected requires moving back and forth between the two requirements.
% As $\theta$ increases, such two-step strategies become more and more costly because the two requirements are further away from each other.
When $ \theta\geq 30^{\circ}$, we can easily compute that under the random order mechanism with randomization probability $\probprincipal=0.5$ and no disclosure, no agent prefers two-step strategies.
However, when $\theta< 30^{\circ}$, some agent prefers using some two-step strategy even under the uninformed random order mechanism with randomization probability $\probprincipal=0.5$.



In the remaining section, we impose stronger properties on the cost function to derive similar sharper characterization of the optimal sequential mechanism as in the Euclidean distance cost. We assume that the cost function is additive.

\begin{assumption}[additive]\label{def: additive}
A cost function $c(\cdot,\cdot,\cdot)$ is additive if 
    for any initial attributes $\orifeatures$ and any two-step strategy $\strategies=(\firstfeatures, \secondfeatures)$,
$$
c(\orifeatures,\firstfeatures, \secondfeatures) = \onecost(\orifeatures,\firstfeatures) + \onecost(\firstfeatures, \secondfeatures).
$$
\end{assumption}

% Here we abuse notations and use the same $c$ to denote the total cost of changing attributes twice and the cost of changing attributes once.

% Moreover, we consider the case where the cost of changing attributes once is induced by a metric $d$ of a normed vector space.
% \begin{definition}
%     We say the cost of changing attributes once is induced by a metric $d$ of a normed vector space if for any two attributes $\features, \features'$, the cost from $\features$ to $\features'$ is proportional to the distance $d$ between these two attributes, i.e., $c(\features,\features') = \eta \cdot d(\features,\features')$. 

%     Moreover, the distance function $d$ is induced by a normed vector space, i.e.,  it satisfies the following two properties:
% \begin{enumerate}
%     \item translation invariant: $d(\features,\features') = d(\features+\genericfeatures,\features'+\genericfeatures)$ for every $\features, \features', \genericfeatures$.
%     \item absolute homogeneous: $d(\alpha \features, \alpha \features') = |\alpha| \cdot d(\features,\features')$ for every attributes $\features, \features'$ and $\alpha \in \bbR$.
% \end{enumerate}
% \end{definition}

\begin{theorem}\label{thm:optimal sequential metric investement}
     Consider  the investment setting and program \ref{max qualified}.
     Suppose the cost function satisfies \cref{assump: cost function one step}-\ref{def: additive}.  
     For any given $\classifier_A$, there exists an angle $\theta^*(\classifier_A) \in (0, 180^{\circ})$ such that when the angle between the two half planes $\classifier_A$ and $\classifier_B$ is greater than $\theta^*(\classifier_A)$, for 
     any distribution $\dist$,    
    the optimal sequential mechanism is an random-order mechanism without disclosure with two tests $\classifier_A$ and $\classifier_B$. 
    
    Moreover, it achieves the first best.
    %no agent prefers a two-step strategy in an uninformed random order mechanism with two tests $\classifier_1$ and $\classifier_2$. 
\end{theorem}


The next result shows that in the investment setting, random-order mechanisms with disclosure is never optimal. The proof uses the same mixed mechanism argument as before.

\begin{proposition}\label{prop:investment fixed order better than informed}
    Consider  the investment setting and program \ref{max qualified}.
     Suppose the cost function satisfies \cref{assump: cost function one step}-\ref{def: additive}.
    For any distribution $\dist$, the optimal fixed-order mechanism is weakly better than the optimal random-order mechanism with disclosure.
\end{proposition}






