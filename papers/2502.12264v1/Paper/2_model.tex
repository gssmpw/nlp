\section{Model}
A principal (hereafter she) is going to test whether an agent (hereafter he)
has desired attributes. Initially, the agent's attributes (or type) are $\orifeatures=(\orifeature_{A},\orifeature_{B})\in \Featurespace = 
%TCIMACRO{\U{211d} }%
%BeginExpansion
\mathbb{R}
%EndExpansion
^{2}$. The attributes are privately known by the agent. The principal only
knows their distribution: $\orifeatures\sim \dists$. The agent can change his attributes to $\features=(\feature_{A},\feature_{B})$
at a cost $\onecost(\orifeatures,\features)$. In large parts of the paper, we will assume this cost
is the Euclidean distance between $\orifeatures$ and $\features$. We model such a change in two ways: In the \textit{investment}
setting,  $\features$
become the agent's new \textit{true} attributes.  In the \textit{manipulation}
setting,  the agent's true attributes stay unaltered at $\orifeatures$ and $\features$ are fake attributes, acquired only for the purpose of testing. 

The principal is interested in learning  the agent's true attributes belong to
a set $\qualregion\subset 
%TCIMACRO{\U{211d} }%
%BeginExpansion
\mathbb{R}
%EndExpansion
^{2}$. If they do, we will say that the agent is \textit{qualified}. For
most of the analysis,  we assume that the principal has two criteria $\classifier_A$ and $\classifier_B$.
Each $\classifier_i$ is a linear constraint on the agent's attributes, which can be represented by a half plane.
Hence, the qualified region is $\qualregion=\classifier_{A}\cap \classifier_{B}$. 
The half planes are marked in red and blue in \cref{fig: hiring}. 
% Each half plane $\classifier_i$ is a linear constraint on the agent's attributes, which reflects one of the principal's criteria. 
Let $\theta $ stand for the angle between the lines that
bound the two half planes. 

% We consider two classes of tests: perfect tests and linear tests. 
% A perfect test $\widetilde{h}\in\perfecttest$ outputs a point that coincides with the input of the test.
% A linear test $\widetilde{h}\in\lineartest$ is a half plane.
We will assume that the principal can choose two tests $\widetilde{h}_{A}$ and $\widetilde{h}_{B}$. 
Each test $\widetilde{h}_{i}$ is a linear constraint (half plane) that specifies which attributes pass the test. 
Define $\widetilde{\qualregion}=\widetilde{h}_{A}\cap \widetilde{h}_{B}$%
, and we will study two kinds of testing mechanisms:

\paragraph{Simultaneous mechanisms} determine whether $\features\in \widetilde{H}$.
 Recall that this $\features$ are true attributes in the investment  setting; in the manipulation setting, $\features$ are fake attributes.
 % acquired only for the purpose of testing. 
% The cost of changing his attributes from $\orifeatures$
% to $\features$ is denoted by $\onecost(\orifeatures,\features)$. In large parts of the paper, we will assume this cost
% is the Euclidean distance between $\orifeatures$ and $\features$.

\paragraph{Sequential mechanisms} are somewhat richer and more involved. Let $(M,s)$ denote a sequential mechanism, where $M$ is a set (of messages) and $s: M\rightarrow\sequential$ is the set of all possible sequential testing procedures. 
Suppose first $M=\nullset$, meaning no upfront communication is allowed.
In
each such a mechanism, the principal selects whether test $\widetilde{h}_{A}$
or test $\widetilde{h}_{B}$ will be performed first. This choice can be
random. Let the triple $(\widetilde{h}_{A},\widetilde{h}_{B},q)$ denote the
mechanism that applies test $\widetilde{h}_{A}$ as first with probability $q$%
, and test $\widetilde{h}_{B}$ as first with the complementary probability.\footnote{Note that $(\widetilde{h}_{A},\widetilde{h}_{B},q)=(\widetilde{h}_{B},%
\widetilde{h}_{A},1-q)$.}
 Test $\widetilde{h}_{i}$, $i=A,B$, determines
whether the agent's attributes at the moment of taking the test belong to the
half plane $\widetilde{h}_{i}$. 
If $q\neq 0,1$, the agent does not know which test will be applied first.
After the first test takes place, the principal can decide whether to disclose this information.
Let $\widetilde{h}_{1}$ denote the first realized test.
Let $s= (\widetilde{h}_{A},\widetilde{h}_{B},q,\disclose)$ denote the sequential mechanism with disclosure decision after the first test $\disclose\in \{\widetilde{h}_{1},\nullset\}$, where
 $\disclose=\widetilde{h}_{1}$ ($\disclose=\nullset$) means the mechanism does (not) disclose the first test after it takes place. 

We allow the agent to change her attributes twice: (1) from $\orifeatures$ to $\firstfeatures$
before taking the first test, and (2) from $\firstfeatures$ to $\secondfeatures$ before taking
the second test. Again, $\firstfeatures$ and $\secondfeatures$ are true attributes in the
investment setting, but are only fake attributes in the manipulation setting.
If $q\neq 0,1$, the agent  chooses $\firstfeatures$ when he knows that the first test will be $\widetilde{h}_{A}$
with probability $q$. 
In the case of disclosure $\disclose=\widetilde{h}_{1}$, he knows which test will be applied
second when he chooses $\secondfeatures$. 
In the case of no disclosure $\disclose=\nullset$, he only knows  test  $\widetilde{h}_{B}$ will be applied
second with probability $q$ when he chooses $\secondfeatures$.
The cost of changing her attributes from $\orifeatures
$ to $\firstfeatures$ and then from $\firstfeatures$ to $\secondfeatures$ is denoted by $%
\cost(\orifeatures,\firstfeatures,\secondfeatures)$. In large parts of the paper, this cost will be
assumed to be additive $\cost(\orifeatures,\firstfeatures,\secondfeatures)= \onecost(\orifeatures,\firstfeatures)+\onecost(\firstfeatures,\secondfeatures)$.
% $\eta\cdot\metric(\orifeatures,\firstfeatures)$ between $%
% \orifeatures$ and $\firstfeatures$ and the Euclidean distance $\eta\cdot\metric(\firstfeatures,\secondfeatures)$ between $\firstfeatures
% $ and $\secondfeatures$, for some $\eta>0$.

The agent just wants to pass the tests.
His utility is 
\[
\indicate{\features\in \widetilde{\qualregion}}-\onecost(\orifeatures,\features)
\]%
for simultaneous mechanisms, and 
        \[
\E\left\{\indicate{\firstfeatures\in \widetilde h_{1}\cap \secondfeatures\in \widetilde  h_{2}}\right\}
-\cost(\orifeatures,\firstfeatures,\secondfeatures)
\]%
for sequential mechanisms. Here, $\indicate{\cdot}$ denotes the
indicator function of the set $[ \cdot ]$, $ \widetilde h_{1}$ and $ \widetilde h_{2}$ denote the
tests that are applied first and second, respectively, and the expectation
refers to the randomness in choosing $ \widetilde h_{1}$ and $ \widetilde h_{2}$.

Suppose $M\neq\nullset$, meaning there is a cheap-talk communication before the principal chooses the sequential procedure. A direct mechanism is one where $M=\Featurespace$ and a menu of sequential procedures $s=<\widetilde{h}_{A}(m),\widetilde{h}_{B}(m),q(m),\disclose(m); m\in M>$. 
 % For a direct mechanism $(M,s)$, we say that 

 For every menu of sequential procedures $s=<\widetilde{h}_{A}(m),\widetilde{h}_{B}(m),q(m),\disclose(m); m\in M>$ and every message $\features$, define $s(\features)$ to be the sequential procedure (mechanism) chosen by the principal after seeing message $\features$.
 We assume that given a mechanism $(M,s)$, an agent of type $\features$ will choose a message such that  his utility under mechanism $s(\features)$ is maximized for all $\features\in M$.
 Moreover, once the mechanism $s(\features)$ is announced, the agent chooses a strategy to change his attributes to maximize his utility under the mechanism $s(\features)$.
 
We will explore various objectives of the principal. However, the most
interesting results will be obtained when the principal's utility is the
probability that a qualified agent (the one whose true attributes are in $\qualregion$)
passes the tests subject to the constraint that unqualified agent never
passes the tests, i.e.,
\begin{equation}\tag{$\mathcal{P}_{I}$}\label{max qualified}
    \begin{aligned}
        \max & \quad \pr[\text{selecting qualified agent}] \\
        s.t. & \quad \text{ no unqualified agent is selected};\\
        % \Leftrightarrow \quad \min & \quad \text{Type II error} \\
        % s.t. & \quad \text{ zero Type I error}.
    \end{aligned}
\end{equation}
This case will be studied in most  sections. The objective represents lexicographic preferences:  avoiding any unqualified agent is a primary objective, since the error of commission is much more costly than the error of omission in many economic settings, including regulation and hiring.

We will now recap the timeline of the game induced by any mechanism:

1. The agent sends a message $m\in M$ to the principal when $M\neq\nullset$.

2. Principal announces and commits to a mechanism (simultaneous or
sequential).

3. In a simultaneous mechanism, the agent chooses $\features$; A passes the test if $\features\in \widetilde{\qualregion}=\widetilde{h}_{A}\cap \widetilde{h}_{B}$, and the game ends.

4. In a sequential mechanism, 

(a) the agent chooses $\firstfeatures$;

(b) a random device chooses the order of the tests, and test $\widetilde h_{1}$ is
applied; 

(c) if $\disclose=\widetilde{h}_{1}$, the first test is announced to the agent;

(d) the agent chooses $\secondfeatures$, and test $\widetilde h_{2}$ is applied.

Finally, A passes the tests if $\firstfeatures\in \widetilde h_{1}$ and $\secondfeatures\in \widetilde h_{2}$, and the game ends.\footnote{%
Of course, if $\firstfeatures\notin \widetilde h_{1}$ and the mechanism discloses the first test, the agent fails the first test, and the
game could end at this point.}

\begin{remark}
    In any simultaneous mechanism, the agent can change his attributes once.
We call this a  \emph{one-step strategy}.
% Conceptually, it is without loss of generality to assume that the agent is only allowed to use \emph{one-step strategies} in simultaneous mechanisms.
% Therefore the agent's strategy in a simultaneous mechanism is a mapping $\strategies:\Featurespace\rightarrow \Featurespace$, where $\strategies(\orifeatures)=\firstfeatures$.
% The agent's cost of such any one-step strategy $\strategies(\orifeatures)=\firstfeatures$ is $\onecost(\orifeatures,\firstfeatures)$.
To ease notations, we assume that there is no cost of maintaining any attributes.

\begin{assumption}\label{assump: cost function one step}
	For any $\orifeatures,\firstfeatures$, $\onecost(\orifeatures,\firstfeatures)=\cost(\orifeatures,\firstfeatures,\firstfeatures)=\cost(\orifeatures,\orifeatures,\firstfeatures).$
 % \begin{equation}
 %     \begin{aligned}
 %         \onecost(\orifeatures,\firstfeatures)&=\cost(\orifeatures,\firstfeatures,\firstfeatures), \\
 %         \onecost(\orifeatures,\firstfeatures)&=\cost(\orifeatures,\orifeatures,\firstfeatures).
 %     \end{aligned}
 % \end{equation}
 
\end{assumption}

% This assumption makes sure that once the agent chooses some attributes, there is no cost of maintaining it. 
% Therefore, we can safely write any \emph{one-step strategy} $\strategies=\features^1$  as $\strategies=(\features^1,\features^1)$ and the cost it incurs as $\cost(\orifeatures,\firstfeatures,\firstfeatures)$.
\end{remark}

% \subsection{Discussions}\label{subsec:discussions}
% In the remaining section, we will discuss more subtleties on the modeling choice. Readers who are not interested in such details in their first read can move on to the next section.




