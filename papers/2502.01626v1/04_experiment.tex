\section{Experiments}
\label{sec:experiment}

\subsection{Experimental Setup}\label{sec:exp_set}
\noindent \textbf{Implementation Details.} 
Our proposed model is fine-tuned on VITON-HD~\cite{choi2021viton}. As with other works~\cite{xu2024ootdiffusion,choi2024improving,velioglu2024tryoffdiff}, we divide it into a training dataset and a testing dataset. Then, we use IDM~\cite{choi2024improving} to prepare the custom datasets for person-to-person task and manually filter out a subset for training. We adopt the FLUX-Fill-dev~\cite{flux} as our foundation model and fine-tuning it on both garment-to-person and person-to-person datasets. In inference stage, the model samples 30 steps to get the final fitting outputs.

\subsection{Qualitative and Quantitative Comparison}\label{sec:exp_comp}
We compare our model with garment-to-person methods OOTD~\cite{xu2024ootdiffusion}, IDM~\cite{choi2024improving}, and CatVTON-FLUX~\cite{catvton-flux}. To adapt these methods for person-to-person tasks, we employ segmentation~\cite{ravi2024sam} and try-off~\cite{velioglu2024tryoffdiff} to extract garment from the reference person. We initially utilize unpaired testing datasets and assess the fidelity of the generated fitting image distributions with three key metrics: FID~\cite{heusel2017gans}, CLIP-FID~\cite{kynkaanniemi2022role} and KID~\cite{binkowski2018demystifying} metrics. In order to more fully evaluate our model, we process the testing dataset using the data preparation method outlined in~\cref{sec:data_preparation} and extract paired datasets such as $\left(P_{mn}, P_{nm}, P_{mm}\right)$ and $\left(P_{nm}, P_{mn}, P_{nn}\right)$. On this dataset, we evaluate the aforementioned metrics and additionally compute SSIM~\cite{wang2004image}, LPIPS~\cite{zhang2018unreasonable} and DISTS~\cite{ding2020image} to evaluate the reconstruction quality between the generated fitting image and corresponding ground truth.

\input{figs/figure4}
\noindent \textbf{Qualitative Comparison.}
As illustrated in~\cref{fig:fig4_method}, our method achieves superior fidelity in person-to-person task. While other methods can adapt to person-to-person task using segmentation or try-off techniques, they often introduce significant artifacts. Despite not requiring a separate input of the person pose, our method effectively preserves the original pose with high accuracy.

\input{tables/quantitative_person}
\input{tables/quantitative_garment}
\noindent \textbf{Quantitative Comparison.}
Quantitative results demonstrate that our method excels in both person-to-person task, as evidenced in~\cref{tab:quantitative_person}, and garment-to-person task, as shown in~\cref{tab:quantitative_garment}, outperforming existing methods across multiple metrics. Additionally, quantitative results indicate that the try-off method is more effective than the segmentation method in facilitating the realization of person-to-person tasks.