We have implemented \approach in a prototype tool and carried out experiments in order to assess its suitability for testing 3D games with respect to a single agent \rlacronym implementation. In this section, we present the setup of the experiment, the metrics used, the various artefacts, and the objects of the experiment. Subsequently, in Section~\ref{sec:results}, we discuss the results obtained and answer the research questions.

\subsection{Prototype} \label{sec:prototype}
\approach is implemented in a prototype tool called \tool. The implementation of \tool is built on top of the iv4XR framework for automated testing of extended reality (XR) based systems~\cite{DBLP:conf/icst/PradaPKDVLDKDF20}. \tool provides an implementation of \approach as described in Section~\ref{sec:approach} as well as an implementation of the single agent variant~\cite{DBLP:conf/kbse/FerdousKPS22}, which we use as a baseline. \tool is developed in Java and uses the BURLAP\footnote{\url{http://burlap.cs.brown.edu/}} library for \rlacronym algorithms. It is fully open source and publicly available on GitHub\footnote{
\url{https://github.com/iv4xr-project/iv4xr-rlbt}}.

% \subsection{Experiment setup} \label{sec:experimentdesign}
%% system under test and levels used
\subsection{Game levels}
\label{sec:levels}
For the experiment, we selected three configurations of \sut, each representing a different scenario with increasing size and complexity:
%representing different scenarios of the environment exhibiting increasing levels of size and difficulty: 
\med, \lrg, and \ext. For each configuration, we prepared five different levels to have different levels of comparable difficulty but different layouts of the game world and entities. The difficulty faced by the testing approach results from the physical dimension of the level, the number of entities in it, and the connections among the entities which make navigation increasingly difficult.


%% metrics for answering RQs
\subsection{Metrics} \label{sec:metrics}
To answer our research questions, we measure coverage achieved by the testing approaches and the corresponding time spent. With respect to \emph{effectiveness} (\rqa), we consider three different notions of coverage related to gameplay~\cite{10.1145/3643658.3643920} for measuring the suitability of the proposed approach in exploring the game under test: \emph{entity coverage}, \emph{entity connection coverage}, and \emph{spatial coverage}.

\textbf{Entity coverage} represents the percentage of observed/interacted entities (with all possible property values) in a given level of \sut. In our running example, the \buttonsdoors level (shown in Figure~\ref{fig:runningexample}) contains seven entities, i.e., three doors and four buttons. A door can be in two states, i.e., \emph{open} or \emph{closed}, and similarly, a button could be in two states, i.e., \emph{pressed} or \emph{not-pressed}. Hence the total space of entities to be covered in a level consists of all these possible combinations. Table~\ref{tab:entitycoverage} lists all the possible entity states for the \buttonsdoors level shown in Figure~\ref{fig:runningexample}.

{
\begin{table}[!htb]
    \centering
    \begin{tabular}{c|c}
        \textbf{Entity} & \textbf{Properties}  \\ \hline
        \texttt{bttn1} & \it{pressed}, \it{not-pressed}\\
        \texttt{bttn2} & \it{pressed},  \it{not-pressed}\\
        \texttt{bttn3} & \it{pressed},  \it{not-pressed}\\
        \texttt{bttn4} & \it{pressed},  \it{not-pressed}\\
        \texttt{door1} & \it{open},  \it{closed}\\
        \texttt{door2} & \it{open},  \it{closed}\\
        \texttt{door3} & \it{open},  \it{closed}\\
        \hline
        \end{tabular}
    \caption{Coverable entities for the running example (see Figure~\ref{fig:runningexample})}
    \label{tab:entitycoverage}
\end{table}
}

\textbf{Entity connection coverage} represents the percentage of the connections exercised among the various entities in a level. In \sut, doors are connected to buttons in such a way that when a button is toggled it opens/closes the door(s) it is connected to. The entity connection coverage metric measures what percentage of such connections is exercised during testing. For our running example, there are five connections to be covered: \texttt{bttn2} is connected to \texttt{door1}, \texttt{bttn3} is connected to \texttt{door1, door2, door3}, and \texttt{bttn4} is connected to \texttt{door1}. Button \texttt{bttn1} is not connected to any doors, as shown in Table~\ref{tab:connectioncoverage}.

 \begin{table}[!h]
     \centering
     \begin{tabular}{c|c}
         \textbf{Buttons} & \textbf{Connecting Doors}  \\ \hline
         \texttt{bttn1} & \it{not connected}\\
         \texttt{bttn2} & \it{door1}\\
         \texttt{bttn3} & \it{door1}, \it{door2}, \it{door3}\\
         \texttt{bttn4} & \it{door1}\\
         \hline
         \end{tabular}
     \caption{Entity connections (see Figure~\ref{fig:runningexample})}
     \label{tab:connectioncoverage}
 \end{table}

\textbf{Spatial coverage} represents a visual representation of the exploration achieved by the agent (player) on a 2D plane using a heat map. 

With respect to \emph{efficiency} (\rqb), we measure the time spent by the approach to perform the testing. A testing run terminates either when all coverable goals have been covered (i.e., 100\% coverage is reached), when the allocated budget runs out (i.e., the number of episodes), or when the game play terminates (e.g., the player dies\footnote{In the case of \sut a player dies when the health point reaches~0 due to repeated travel through fires.}). Specifically, we calculate the \emph{average time per episode} as well as the \emph{average time per action} in a given episode (episode time divided by the number of actions performed in the episode).

\subsection{Experiment protocol} \label{sec:experimentexecution}
%% how many experiments, setup on cluster, ...
We run both \approach and the baseline (i.e., single-agent variant) in a similar environment and implementation to minimize any differences between the two approaches other than the \rl strategy. We run both variants on each level of \lr selected for the experiment (Section~\ref{sec:levels}). Each run was repeated 10 times to account for the inherent randomness in the approaches, and eventually, the metrics were computed as average over the 10 runs. We use the Wilcoxon test in order to determine statistical significance when comparing the performances of the two variants. 

\tool has several parameters that control different aspects of the testing process. Some of the parameters are specific to the game under test while others are specific to \rl aspects. After some preliminary experimentation, we have chosen reasonable values for the parameters to be used in our experiment. Table~\ref{tab:parameters} lists some of the important parameters and their corresponding values. Since the game levels used in our experiments are of different sizes, some of the parameter values are different among the levels, for instance, the number of \emph{cycles per action}, as can be seen in Table~\ref{tab:parameters}. This parameter represents the maximum number of cycles that the agent could execute to complete a given action. The parameter refers to the underlying execution environment which is based on BDI (belief-desire-intention) agents that execute in update cycles~\cite{DBLP:conf/icst/PradaPKDVLDKDF20}. To execute an action selected by the \rlacronym agent in the game (say to move from the current position to a given door), the underlying environment needs to execute for several update cycles in which the test agent repeatedly observes the world and moves towards the destination. If the game world is large, the agent might need more time to perform an action as compared to a smaller game world. Accordingly, we used different values for each level size in our experiment, i.e., 70, 100, and 120 cycles per action for \med, \lrg, and \ext respectively.


\begin{table}[!htb]
\centering
\begin{tabular}{l|l|l|l}
% \begin{tabular}{p{2.8cm}| p{1.2cm}|p{1.0cm}|p{1.0cm}}
\hline \textbf{Parameter}  & \begin{tabular}[c]{@{}l@{}}\textbf{\med}\\\textbf{Levels}\end{tabular} & \begin{tabular}[c]{@{}l@{}}\textbf{\lrg}\\\textbf{Levels}\end{tabular}  & \begin{tabular}[c]{@{}l@{}}\textbf{\ext}\\\textbf{Levels}\end{tabular}\\ \hline
    num. agent & 2 & 2  & 2  \\
    num. episodes & 50 & 50  & 50  \\
    actions per episode & 80 & 150 & 200\\
    cycles per action & 70 & 100 & 120 \\
    initial $\epsilon$-value & 0.5 & 0.5 & 0.5 \\
    learning rate ($\alpha$) & 0.25 & 0.25 & 0.25\\
    discount rate ($\gamma$) & 0.6 & 0.6 & 0.6\\
   % stopping condition & - & 50 & - & 50& 100 \\ 
    %agent's memory clear interval & - & 50\todonote{update} & - & 50 \\  
    \hline
    \end{tabular}
    \caption{Parameter values}
    \label{tab:parameters}
\end{table}
