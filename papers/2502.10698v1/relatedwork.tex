\section{Related Work}
\subsection{Model Merging of Fine-tuned Models}
Model merging is a technique that combines multiple models into a single model to enhance performance or enable the model to perform multiple tasks. 
Previous studies have shown that averaging the weights of multiple models fine-tuned from the same pre-trained initialization is a promising approach for model merging. 
Fisher Merging~\citep{matena2022merging} advances beyond simple averaging by utilizing the Fisher information matrix to assess the importance of individual parameters, which are then weighted accordingly during the merging process. Similarly, RegMean~\citep{jin2022dataless} forms a linear regression problem with extra data for each layer and offers a closed-form solution for the merged model's parameters by solving the regression problem.


Beyond parameter averaging, Task Arithmetic~\citep{ilharco2022editing} introduces task vectors and adding the task vectors of individual tasks to merge model, demonstrating their effectiveness and lightweight nature in facilitating cross-task generalization. Building on this concept, PEM Composition~\citep{zhang2023composing} extends the task arithmetic framework to merge LoRA~\citep{hu2021lora}, while Ties-Merging~\citep{yadav2024ties} addresses task conflicts by resetting redundant parameters and resolving sign conflicts. These methods, however, use a single merging coefficient across all task vectors, which limits their flexibility. In contrast, Lorahub~\citep{huang2023lorahub} and AdaMerging~\citep{yang2023adamerging} use different coefficients for enhanced adaptability. Lorahub's performance is limited as it only searches for coefficients at the task level, while AdaMerging requires complex training and unlabeled test datasets, making it applicable solely to classification problems. DARE~\citep{yu2024language} proposes drop and rescale as preprocessing steps when merging fine-tuned LLMs. PCB-Merging~\citep{du2024parameter} is a lightweight, training-free technique for model merging that balances parameter competition by intra-balancing parameter significance within tasks and inter-balancing parameter similarities across tasks, effectively enhancing performance across various scenarios and domains.


\subsection{Linear Representation Hypothesis}
The linear representation hypothesis states that neural networks encode information by summing up "feature vectors"~\citep{mikolov2013linguistic,arora2016latent,olah2020zoom}, i.e., a layer of a network represents a set of features as a weighted sum of 
task-associated vectors.
This hypothesis has been observed in various models, including word embeddings~\citep{mikolov2013linguistic,conneau2017word}, sentence embeddings~\citep{bowman2015generating}, Transformer language models~\citep{meng2022locating,hendel2023context}, and vision-language models~\citep{trager2023linear,perera2023prompt}.
The hypothesis has been explioted in various fields, especially in probing~\citep{alain2018understanding, belinkov2022probing} and interpretability~\citep{nostalgebraist2020logitlens,elhage2022toy,bricken2023monosemanticity,gao2024scaling}.

Especially, the linear representation hypothesis is prominently featured in recent works on mechanistic interpretablity of language models~\citep{olsson2022context,elhage2022toy,bricken2023monosemanticity,templeton2024scaling}. In mechanistic interpretability, models are understood by decomposing them into interpretable components and understanding how these components interact. The linear representation hypothesis suggests that important features in neural networks are often represented through linear combinations of neuron activations, rather than complex nonlinear transformations.
This hypothesis has gained significant empirical support through studies of language models. For instance, \citep{elhage2022toy} demonstrated a toy model that learned to resconstruct its input through linear combinations of its neurons. Furthermore, \citet{bricken2023monosemanticity} showed that individual neurons in a language model can encode semantically meaningful features in a largely linear fashion, which is later sclaed to large language models~\citep{templeton2024scaling}.