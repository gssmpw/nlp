
\section{\system: System Design}
Informed by the design requirements, we develop \system\footnote{\url{https://github.com/SamLee-dedeboy/GreenMine}}, which implements a three-step prompting pipeline for the mining of DPSIR, and an interface with visualizations to support the interactive mining. The interface has two main views: \textit{Prompt View}, which supports interactive prompt refinement and execution, featuring an uncertainty chart for prompt evaluation; and \textit{DPSIR View}, which visualizes the mining results for collaborative discussions. \sam{
\marginnote{$\triangle$\_5\_1}All the LLM-related computation uses the ``gpt-4o-mini'' model from OpenAI, accessed through official API requests. 
}
% \sam{TODO: add open-source repo (anonymized)}

\paragraph{Dataset and Segmentation}
The system supports datasets of interview transcripts.
Our targeting dataset consists of 19 transcripts of interviews that the collaborating experts have conducted with the residents of Lyudao. 
\sam{
\marginnote{$\triangle$\_5\_2}
To avoid reaching the context length limits, we first segment each transcript into ``snippets'', i.e., consecutive conversations about a specific topic.} 
To account for the variety of topics in the transcripts, the segmentation method is based on a prompt template, where the semi-structured interview questions are inserted, and the model is instructed to identify topics for segmentation. To avoid hallucinations (e.g., generating sentences not in the transcripts), the model outputs conversation indices, which are then used to segment the transcripts programmatically. Sanity checks are conducted to validate the result. This results in 598 snippets, with on average 6 conversations and 379 words (Chinese characters). 

\subsection{Prompting Pipeline}
Mining insights with the DPSIR framework is complex and requires expert validation, and it is unreliable to mine insights with a single prompt.
In response, we develop a prompting pipeline in three steps: \textit{Indicator Identification}, \textit{Variable Identification}, and \textit{Link Identification}, as shown in~\autoref{fig: pipeline}.
Conceptually, the prompts convert each mining task into a multi-label classification task, in which the model is instructed to choose all applicable labels from a candidate list (\textbf{R3}). 
Environmental experts can refine the candidate list (i.e., the indicators, variables, and their definitions) to fit the research goal and dataset context (\textbf{R1}). 

\paragraph{Indicator Identification} 
In this step, the prompt instructs the model to identify occurrences of indicators in each snippet. The prompt template takes the indicator definitions and snippet content as input and outputs a list of occurred indicators, as well as the evidence sentences and a textual explanation. Note that we use ``concept'' instead of ``indicator'' in the prompt, since ``indicator'' can mean differently in the model's training corpus.  

\paragraph{Variable Identification} Based on the assigned indicators, a second prompt template identifies the variables for each indicator in each snippet. Experts can edit the variable list, or refine the definition of each variable. 
The template takes three inputs:
(1) the indicator and the variable list (and definitions),
(2) the snippet content, and
(3) the textual explanation generated in the first step.
 The model outputs a list of occurred variables, as well as the evidence and explanation. Similarly, we use ``tag'' instead of ``variable'' in the prompt. 

\paragraph{Link Identification} Based on the identified variables, the relationships between all pairs of variables (if exist) are mined. We formulate it as a binary classification task on each pair of variables, where the model outputs (relationships) ``exist'' or `not exist''  given a pair of variables. This formulation increases the computation cost, but the results are more reliable due to shorter prompts and easier instructions. The template takes a pair of variables (and definitions) and the snippet content as input, and outputs the source, target, relationship, evidence, and explanation, or ``None'' if no relationship exists. To maintain the creativity of the model, we do not specify a list of predefined relationships in the prompt. During experiments, we observe some frequent relationships, such as ``positive/negative correlation'', ``causality'', ``interconnected'', or ``health-affecting'', showing that the model can identify and distinguish various kinds of relationships without human intervention.

\subsection{Uncertainty Estimation}
Unlike conventional text mining, there is often no labeled dataset available in prompt engineering. While some researchers have proposed to use pseudo-labels~\cite{malik2024pseudolabel}, it is still not feasible in DPSIR mining because the labels are incrementally enriched and contextualized as experts investigate the corpus. 

Given these unique characteristics, we draw inspiration from a recent work that estimates the uncertainty of LLM outputs by sampling multiple outputs for the same input~\cite{chen2024quantifyinguncertaitny}. 
\sam{
\marginnote{$\triangle$\_5\_3}Conceptually, we execute every prompt $k$ times and measure the consistency between outputs. 
Specifically for our prompting pipeline, since each step is formulated as a multi-label classification task (e.g., the response of \textit{Indicator Identification} can be any power set of $\{D, P, S, I, R\}$), we use set similarity metrics such as Jaccard Distance~\cite{jaccard1912jaccardsimilarity} to measure the consistency between $k$ response.
More generally, we recommend using information entropy~\cite{shannon1948informationentropy} for single-label classification tasks or semantic uncertainty~\cite{cheng2024relic} for unstructured outputs.
}

Using \textit{Indicator Identification} as an example, $A_{ij}$ denotes the identifed indicators for snippet $s_i$ in iteration $j \in (1, 2,...k)$, and $\forall a \in A_{ij}, a \in \{D, P, S, I, R\}$. Then we use average pairwise Jaccard Distance to compute the uncertainty $D_i$ for snippet $s_i$:
\vspace*{-0.1cm}
\begin{equation}
\begin{split}
    D_i = \displaystyle \sum_{1 \leq j_1 < j_2 \leq k}\frac{J(A_{ij_1}, A_{ij_2})}{k(k-1)/2}, \\
    where \ J(A, B) = \frac{|A \cup B| - |A\cap B|}{|A \cup B|}
\end{split}
\end{equation}
For variables, $a \in A_{ij}$ are the variables specified by the environmental experts in the form of strings. For links, we consider $a_1=a_2 \Leftrightarrow (src_1, dst_1)= (src_2, dst_2)$, where $(src, dst)$ are the variables, i.e., we do not consider the relationship when matching two links. 
% This is because to allow the model to be creative in assigning relationships, we did not specify a predefined list of relationships, and the model might output semantically the same answers in different forms, such as ``interconnected'' and ``interdependent''. 
Using this uncertainty estimation, we are able to support the evaluation of prompting performances on all subtasks (\textbf{R2}).

\sam{\marginnote{$\triangle$\_5\_4}Note that in \system, we set the GPT model's temperature to $0$ for maximal determinism. Still, uncertainty scores can reach $0.8$ in some cases, revealing significant response inconsistency and showing the necessity of consistency estimation. 
Although calculating uncertainty theoretically introduces up to $k$ times overhead by repeating each prompt $k$ times, we leverage OpenAI's extensive cloud resources to reduce the overhead, by sending all the API requests for one execution concurrently. Since OpenAI's computing clusters likely have the resources to handle all API requests simultaneously, the bottleneck of the system is simply Network I/O. 
In practice, uncertainty calculation adds only a $1.5x$ overhead when $k=5$.
}

\begin{figure*}[t]
     \centering
    \includegraphics[width=\textwidth]{uncertainty_chart_improvements}
    \caption{The process of generating the uncertainty chart. The dots are positioned using polar coordinates. The angles encode semantic similarity, and the radius encodes uncertainty. For angles, we start by generating embeddings from the snippets and calculate a semantic distance matrix using cosine distance. For different steps in the pipeline, we use the corresponding evidence sentences in each snippet to generate the embeddings. The distance matrix is optimized with the objective function defined in~\autoref{eq: dr}, resulting in angles for each snippet. The snippet embeddings are then clustered using agglomerative clustering and aggregated. The radial space is then divided proportionally by the cluster sizes. Then we employ a force-directed layout, with a collision force to avoid node overlapping, and a radial force that attracts nodes to their radius in the polar coordinate. The design considers the visual clarity of the layout while encoding uncertainty and semantics in one chart.}
    \label{fig: uncertainty_chart_improvements}
  \vspace*{-0.5cm}
\end{figure*}

\subsection{Uncertainty Chart}
\sam{
\marginnote{$\triangle$\_5\_5}Since the mining results can be overwhelming to make sense of and evaluate, we design an uncertainty chart (\autoref{fig: uncertainty_chart_improvements}) to organize the mining results with topics and uncertainties (\textbf{R2}).
}
 Each circle on the chart represents a snippet. The position $(\theta, r)$ is calculated in polar coordinates, where the angle $\theta$ encodes the semantics of the snippet's content and the radius $r$ encodes the uncertainty score. As a result, semantically similar snippets are placed together to form clusters, and the uncertain snippets are placed at the peripherals. 

Incorporating semantics into the visualization is a design choice motivated by the progressive characteristic of DPSIR text mining. 
In the beginning, users have a limited understanding of the corpus topics, and they would refine the DPSIR taxonomy as they explore. 
Once the taxonomy is refined, they would re-execute the prompt, evaluate its performance, and then learn more about the corpus.
The uncertainty chart design supports this interleaved sensemaking and evaluation (\textbf{R2}).
The chart supports two kinds of visual exploration. To find missing definitions for the current DPSIR taxonomy, users can investigate uncertain snippets, which are outliers in the peripheral region. To verify that the model's understanding is aligned with the expert's intent, users can investigate certain snippets, which are grouped in the center region.
Next, we introduce the semantic angle calculation and how the visual clarity of the chart is improved.

\subsubsection{Semantic Angle Calculation} 
\sam{
\marginnote{$\triangle$\_5\_6}
The semantic angle calculation combines document embedding models, dimensionality reduction, clustering, and force-directed layout (\autoref{fig: uncertainty_chart_improvements}). The goal is to find angles that maximally preserve the semantic similarities between snippets while reducing overlaps.
}
\paragraph{Capturing semantics}
We use document embeddings to capture the semantic meanings of each snippet. Instead of using the snippet conversations, we use the evidence sentences and explanations generated by LLMs as the embedded content. This way, the embeddings capture only the semantics relevant to the prompting instructions, e.g., sentences and explanations that suggest the occurrence of a \textit{Driver} when conducting indicator identification. We use OpenAI's ``text-embedding-3-small'' model with 1536 dimensions for this step.

\paragraph{Dimensionality reduction into radial space}
Core to the semantic angle calculation is preserving the high-dimensional distances in a single dimension. Different from a 1D t-SNE~\cite{van2008tsne} or MDS~\cite{cox2000mds}, the distances in the reduced dimension should be \textit{circular}, i.e., in the range of $[0, 2\pi)$, points at $\theta+\epsilon$ and $2\pi-\theta-\epsilon$ are of equal distance with points at $\theta$.
To achieve this, we formulate the reduction similar to MDS, but instead of mapping points into 2D or 3D space, we map them into a 1D circular space.
Given a distance matrix $D$, where $D_{ij}$ is the cosine distance between the embeddings of snippet $i$ and snippet $j$, the objective is formulated as:
\begin{equation}\label{eq: dr}
    \begin{split}
    \min_{\theta_1,\theta_2,\theta_3,...\theta_n}\displaystyle \sum_{i=1}^{n}\sum_{j=i+1}^{n}(d_{ij} - D_{ij})^2, \\
    d_{ij}=1 - cos(min(|\theta_i - \theta_j|, 2\pi - |\theta_i - \theta_j|)), \\
    \theta_i \in [0, 2\pi], \quad i = 1,2,3,\dots, n
    \end{split}
\end{equation}
We optimize for $\theta_i$, such that the squared difference between $d_{ij}$ and $D_{ij}$ is minimized. 
The calculation of $d_{ij}$ guarantees the circular characteristic and rescales to match $D_{ij}$. The objective is optimized with Limited-memory BFGS (L-BFGS)~\cite{liu1989limited}.
Next, we introduce how cluttering is reduced with clustering and force-directed layout.

\paragraph{Clustering}
We first apply Agglomerative Clustering~\cite{steinbach2000doccluster} on the embeddings using cosine similarity with a threshold of 0.5, which assigns a cluster to each snippet. With the clusters and angles from DR, we calculate the mean angle for each cluster and use the mean to sort the clusters, and then distribute the space in $[0, 2\pi]$ proportional to the cluster sizes. This maintains the proximity of semantically similar clusters. Since each cluster represents a topic, we want to support users to make sense of the topics at a glance. We use a prompt to assign topic labels to clusters using the snippet contents, which are attached to respective cluster regions in the chart.

% : \textit{``You are a topic assignment system. The user will provide you with a list of texts. You need to assign one topic to summarize all of them. The topic should be a simple noun phrase.''}. 
% The labels are later attached to respective cluster regions.

\begin{figure*}[t]
    \centering
    \includegraphics[width=\textwidth]{case_study}
    \caption{The prompting interface consists of three panels: (a) The Entry Panel, where users can adjust DPSIR taxonomy definitions and prompting templates. (b) The Result Panel, where users can choose to show the results in a list view or an uncertainty chart. (c) The Comparison Panel can be used to compare two prompts side-by-side. (d) The Document Panel shows the corpus contents. Using this interface, \textbf{E1} adds ``improving living conditions'' in the definition of response in (e), and adds ``culture security'' and ``garbage'' in the Driver variables in (f). (g) Users can also navigate to the evidence snippets, which are annotated with explanations generated by LLMs. }
    \label{fig: case_study}
    \vspace*{-0.6cm}
\end{figure*}

\paragraph{Force-Directed Layout}
Finally, we use a force-directed layout~\cite{fruchterman1991forcelayout} to reduce node overlapping.
At rendering time, all circles are initialized with their coordinates $(\theta_i, r_i)$. 
We apply two forces on the nodes: (1) a collision detection force that repels overlapping nodes, (2) a radial position force that attracts each node to its radius. We also implement clipping to limit the nodes in their allocated cluster spaces. 
\sam{\marginnote{$\triangle$\_5\_7}Although force-directed layout might trade accuracy for visual clarity, it is worth noting that the chart construction process provides relatively large flexibility in node placement: First, the uncertainty score (main encoding of the chart) is encoded by the radius of the polar coordinate, so nodes can be placed at varying angles without changing the uncertainty score encoding. By incorporating the radial position force, the layout prioritizes reducing overlaps with angles rather than radius. Second, semantics of the snippets (encoded by angles) is inherently vague, and it is less likely to cause confusion when the angles are adjusted.} Together, node overlapping is reduced with minimum adjustments to coordinates. 

\vspace*{-0.1cm}
\subsection{Prompting Interface}
The prompting interface consists of three panels: an \textit{Entry Panel} for users to edit DPSIR taxonomy and prompts; a \textit{Result Panel} where users can inspect the prompting results using the uncertainty chart or a list view; and a \textit{Comparison Panel} where users can select a previous version of prompting result side-by-side.
\sam{
\marginnote{$\triangle$\_5\_8}All three steps in the pipeline have an Entry Panel, a Result Panel, and a Comparison Panel. On top of that, some UI adjustments are made to better support each step, e.g., the list view for \textit{Link Identification} provides the Link Graph. 
% The uncertainty chart also supports various filters: users can filter by indicators (\autoref{fig: uncertainty_chart}), variables, or links at each step of the pipeline.
}
Next, we introduce each panel and its interactions. 


\begin{figure*}[t]
    \centering
    \includegraphics[width=\textwidth]{simple_vis}
    \caption{\textbf{Left}: Keyword cloud designed to support the exploration of ``miscellaneous'' variables. The keyword cloud combines embeddings and dimensionality reduction to position semantically similar keywords closer. It shows that ``garbage'' and ``environment'' are two significant keywords in the miscellaneous variables for Drivers. \textbf{Right}: The link graph design helps users make sense of complex links in a snippet. The graph shows that ``Activities of Physical Destructions'' is correlated with ``Changes in Natural Habitats'', ``Coral Bleaching'', and other variables.}
    \label{fig: simple_vis}
    \vspace*{-0.5cm}
\end{figure*}

\vspace*{-0.15cm}
\subsubsection{Entry Panel}
The Entry Panel supports four functionalities: version control, DPSIR taxonomy input, prompt input, and rule input (\autoref{fig: case_study}-a). The panel supports managing different versions of inputs for each step. Each version has a set of DPSIR definitions, prompts, and the last execution result. 
The versions are also necessary when specifying data dependency between steps in the pipeline.
% When executing a later step, users must choose a version from the previous step as the basis.
\vspace*{-0.1cm}
\paragraph{Taxonomy and Prompt Input}
In the first two prompting steps, \textit{Indicator Identification} and \textit{Variable Identification}, users can edit the indicator or variable definitions in natural language, add or remove variables, or specify the variable type (societal or environmental). 
Each prompting step has a unique template, in which the dataset and application context can be specified. Each template is divided into three sections: \textit{Persona}, \textit{Context}, and \textit{User}. This section division follows the state-of-the-art prompting methodologies~\cite{promptengineeringuide} and helps users make sense of the template. 
Users can use a special ``\$\{\}'' tag to specify a variable insertion into the template. 
These specifications are inserted into the prompt templates automatically.

\vspace*{-0.1cm}
\paragraph{Rule Entry} The rules enable users to manually modify prompting results and automatically apply them to all versions of results. Each rule should specify a target snippet, a condition (``must'' or ``must not'' have), and a value, which can be indicators, variables, or links. Note that the rules are not used in the prompts or as few-shot examples. We implement this feature for users to cover corner cases where the model fails to capture some nuances.

\vspace*{-0.15cm}
\subsubsection{Result Panel and Comparison Panel}
Result and Comparison Panel (\autoref{fig: case_study}-b, c) support the evaluation of prompt performances (\textbf{R2}) by showing the results using the uncertainty chart or a list view.
The Result Panel always displays the current version, while the Comparison Panel allows selecting any version. We also designed two visualizations—Keyword Cloud and Link Graph—to aid sensemaking in variable and link identification.

\vspace*{-0.1cm}
\paragraph{List View}
The list view shows all results sorted by uncertainty (high to low). By clicking on a result, user can quickly navigate to the evidence and explanations in the Document Panel (\autoref{fig: case_study}-g). 

\vspace*{-0.1cm}
\paragraph{Keyword Cloud}
During variable identification, we reserve a label for ``miscellaneous'' to cover everything that the experts have not considered. Adding new variables by iteratively investigating the ``miscellaneous'' variables is the core of refining the DPSIR variable lists. To support this, we aggregate the keywords from the evidence sentences for results containing ``miscellaneous'', and implement a semantic word cloud~\cite{xu2016semanticwordcloud} using embeddings and Kernel PCA~\cite{scholkopf1997kernel}, as shown in~\autoref{fig: simple_vis} (left).
\sam{
\marginnote{$\triangle$\_5\_9}Users can switch to show the keyword clouds by clicking the button located at the top right of the result panel for \textit{Variable Identification}.
}
We use color and size to double-encode the word frequencies, and use proximity to encode semantic with cosine similarity.
The design also considers maintaining the visual continuity between multiple rounds of iteration.
Specifically, we want the semantic landscape to remain consistent.
Thus, we need a \textit{parametric} dimensionality reduction method, where an explicit mapping function (i.e., projection to low-dimensional space) can be reused, excluding popular non-parametric methods like t-SNE~\cite{van2008tsne} or MDS~\cite{cox2000mds}.
Kernel PCA not only satisfies this constraint, but also captures the non-linear semantic relationships. Similar to the uncertainty chart, we use a collision force with rectangular overlap detection to prevent keyword overlapping.

\vspace*{-0.1cm}
\paragraph{Link Graph}
During link identification, the system supports the visualization of the result for a snippet in a node-link diagram (\autoref{fig: simple_vis}-right), which makes it easier to understand the result and identify graph-related patterns than in a list. Each node is a variable colored by their indicator types. Node radius encodes degree (frequency), and link opacity encodes uncertainty. The links are annotated with the relationship label extracted by the model, and users can click on the links to navigate to the evidence in the Document Panel. Since the graph size is typically small, we use a force-directed layout and implement node dragging in case the labels are occluded. 


\subsection{Visualizing links in DPSIR Graph}
During the mining tasks, the system prioritizes to visualize only a selective subset of results. After the mining, the system can visualize all mined links in the DPSIR Graph, where each node is a variable. 
As shown in~\autoref{fig: DPSIR}, the DPSIR Graph is designed specifically for the DPSIR framework, extending common visualizations created in the environmental science community~\cite{atkins2011dpsir}, featuring a radial layout and progressive disclosure support. It is designed for quick validations and sensemaking during a collaborative discussion (\textbf{R4}). 

\vspace*{-0.1cm}
\paragraph{Responsive Radial Layout} 
Using the cyclic characteristic of the DPSIR framework, the graph is organized in a radial layout. The design follows existing diagrams in environmental studies~\cite{atkins2011dpsir} and emphasizes simplicity and interactivity to better support collaborative discussion.
Each indicator is assigned a unique color consistent with the rest of the system. To lay out each block of indicator, we divide $[0, 2\pi]$ proportionally to the total degree of variables in each indicator (D, P, S, I, R), and put the block at the center of the allocated space. In this formulation, the system can support users to exclude irrelevant indicators during discussion sessions. 
For example, users can hide \textit{States} and \textit{Imapcts} if the discussion is not focusing on these indicators (\autoref{fig: DPSIR}-right), and the layout will automatically redistribute the space to place each block evenly.

\vspace*{-0.1cm}
\paragraph{Progressie Disclosure} 
 Each block of indicators can be interactively ``opened'' to reveal the variables (\autoref{fig: DPSIR}-right), organized in a squared layout to save the central space for internal links. The color saturation of each variable encodes degree (frequency of occurrence). To prevent external links from concentrating in a small space, we put the four highest-degree variables at the four corners of each block. This also helps users locate the most significant variables. The link width and opacity between each variable double-encode the intensity (frequency of the link). Link color is determined by the source indicator type.
  Users can click on any variables or links to highlight them, and navigate to the evidence in the Document Panel.
 The interaction design allows users to focus on relevant subsets of the DPSIR graph during discussions, 
 and seamlessly navigate to supporting evidence in the documents for detailed understanding. 
