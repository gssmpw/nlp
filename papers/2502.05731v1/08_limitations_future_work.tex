\section{Limitations}
While \system \ has proven effective for our collaborating experts, we discuss limitations that could constrain its applicability.
\sam{
\paragraph{Incorporating multiple sources of data}
\marginnote{$\triangle$\_8\_1}The system currently supports only a specific data format for interview transcripts, which is quite limited given LLMs' ability to handle various formats. Extending support for other formats require updates to several system modules, such as the segmentation module and Document Panel.
}
\paragraph{Computation Scalability}
The system is limited in computational scalability. 
The dataset on Lyudao is segmented into 598 snippets with an average length of 379 Chinese characters, which is not a large dataset. During the mining, we observed an average runtime of 150 seconds for indicator and variable identification respectively, 
\sam{\marginnote{$\triangle$\_8\_2}}and 600 seconds for link identification. \sam{Note that in our implementation, the LLM is accessed through network APIs and optimized with multithreading to reduce uncertainty calculation overheads. For local LLM inferences, the overheads could not be reduced and the runtime would drastically increase. 
}
\paragraph{Visual scalability}
The uncertainty chart and DPSIR graph face visual scalability issues. \sam{
\marginnote{$\triangle$\_8\_3}
With nodes clustering in narrow ranges or with excessive topics, the force directed layout might push nodes too far away from their original positions, affecting the accuracy of the uncertainty encoding. 
The DPSIR graph relies on interactions for clarity as the number of nodes increases. 
While suitable for collaborative discussions, it may not work well for static displays like posters, limiting its applicability to larger datasets or more display environments.
}
\sam{
\paragraph{Limitations in evaluation}
\marginnote{$\triangle$\_8\_4}The system's evaluation is based solely on feedback from a small group of collaborating experts, which may not be comprehensive. While feedback has been positive, the experts received a detailed tutorial from the authors. Without the tutorial, users unfamiliar with LLMs or advanced visualization—likely common in the environmental science community—may find the system challenging to use. Additionally, the system has not been tested with other LLMs, making it unclear if model choices would impact the outcome and overall performance.

\paragraph{Ethical considerations}
\marginnote{$\triangle$\_8\_5}Finally, potential ethical concerns~\cite{weidinger2022llmrisk}, such as privacy and biases, remain unaddressed. During \system's development, our collaborating experts raised data privacy concerns, prompting us to de-identify interview transcripts. While this is standard for transcripts, similar standards may not exist for other formats like field reports, leaving privacy a concern. Additionally, LLMs may exhibit biases from their training corpus, potentially undermining their ability to fairly extract insights from large datasets.
}
\sam{
\section{Implications beyond Environmental Study}
}
During the development of \system, we addressed several technical challenges that may also exist in other application scenarios. In this section, we discuss the lessons learned that inform visual analytics system developers beyond environmental study. 

\paragraph{Uncertainty evaluation for knowledge-intensive tasks}
Our human-in-the-loop evaluation using uncertainty has proven effective for DPSIR mining tasks. While LLMs perform well on general tasks, their capabilities on knowledge-intensive tasks remain limited due to insufficient training data and the complexity of eliciting knowledge as prompts~\cite{harvel2024llmknowledge}. By leveraging uncertainty estimation, knowledgeable users can iteratively refine prompts until uncertainty is minimized. 
% Although not all knowledge can be externalized, our approach demonstrates feasibility when it is possible. 
Integrating evaluation with exploration aids this process, providing actionable insights for prompt refinement. Thus, the uncertainty chart also suits other knowledge-intensive applications.
% In our work, the human-in-the-loop evaluation based on uncertainty has shown its effectiveness for DPSIR mining tasks. In broader application scenarios, despite strong performance in many general-purpose tasks, LLM's performance on knowledge-intensive tasks remains questionable~\cite{harvel2024llmknowledge}. The challenge is that most knowledge-intensive tasks lack sufficient training material, and the knowledge is too complex to be elicited as prompts. Using uncertainty estimation and human-in-the-loop evaluation, knowledgable users can iteratively externalize their knowledge in prompts until the uncertainty is low. While it may still be challenging to externalize all knowledge, our work shows that such an approach is feasible when the knowledge can be properly externalized. In particular, our design decision on integrating evaluation and exploration facilitates such a process and ensures that users can get actionable insights on how the knowledge could be better externalized. As a result, we believe that the uncertainty chart is applicable to other application scenarios with knowledge-intensive tasks.

\paragraph{Progressive taxonomy construction in thematic analysis}
The data mining in the DPSIR framework resembles that of thematic analysis, facing similar technical challenges. In thematic analysis, analysts begin with an initial codebook and progressively refine it~\cite{fereday2006thematic}. Some researchers have used LLMs to aid this process~\cite{dai2023llmintheloop, yan2024chatgptthematic}, but they encounter reliability and consistency issues due to inadequate feedback loops. Our approach addresses this by combining uncertainty evaluation and topic exploration in the feedback loop, offering validation and actionable feedback. The insights from our work can improve LLM-facilitated thematic analysis, particularly in enhancing reliability and consistency.

\sam{
\paragraph{Incorporating semantic uncertainty}
For broader applicability, we can use semantic uncertainty to incorporate free-form mining results.
\marginnote{$\triangle$\_9\_1}
In our work, we have demonstrated the benefit of using uncertainty metrics to support users evaluate LLM responses.
To adapt to scenarios beyond classifications, e.g., in extracting facts from a corpus, 
}the uncertainty chart can be extended with semantic uncertainty~\cite{kuhn2023semanticuncertainty, cheng2024relic}, which uses linguistic variances to measure the uncertainty of textual responses. 
With this, the uncertainty chart can be extended to more mining scenarios, providing robust uncertainty evaluation support for both structured and unstructured responses.


\section{Conclusion}
In this paper, we present \system, a system designed to facilitate progressive taxonomy construction based on the DPSIR framework for environmental studies. The system supports the interactive execution of a three-step prompting pipeline, where domain specifications can be inserted in prompts by experts. To support the evaluation of the prompts, we introduce an uncertainty chart that visualizes corpus topics and prompt output consistency. The uncertainty chart, along with other visualizations, supports interleaved evaluation and exploration to provide actionable feedback. Our proposed solution and the lessons learned offer valuable insight into supporting human-in-the-loop text mining beyond environmental studies.
