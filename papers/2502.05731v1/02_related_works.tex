
\vspace*{-0.2cm}
\section{Related Works}
Our work enhances existing visual interfaces for text mining and incorporates prompt engineering to support mining with the DPSIR framework.
We review interfaces for conventional and prompt-based text mining, and design studies for interactive prompt engineering.

\vspace*{-0.15cm}
\subsection{Visual Interfaces for Concept and Relation Mining}
Supporting and visualizing text mining have been extensively studied, incorporating various text mining and visualization techniques~\cite{liu2019bridging}. 
In the context of mining DPSIR indicators, approaches that extract and visualize concepts and relations are most relevant.
Earlier works use statistical models on word frequencies to mine valuable information.
For example, VOSViewer~\cite{wong2018vosviewer} supports the automatic extraction of important terms and co-occurrence relations from a corpus using statistical models. 
Later, techniques related to disambiguated entities or concepts become predominant.
FacetAtlas~\cite{cao2010facetatlas} extracts entities and relations using named entity recognition models~\cite{finkel2005ner}, with a focus on internal and external relations between entity classes. 
ConceptEVA~\cite{zhang2023concepteva} extracts concepts and their co-occurrence relations using domain-specific knowledge graphs~\cite{mendes2011dbpediaspotlight} to support customized generation of document summaries.
Both organize the mining result as a node-link diagram.
ConceptScope~\cite{zhang2021conceptscope} uses domain ontologies to extract concepts and their relations for analyzing documents and visualizes the result in a bubble treemap.

A common limitation of these approaches is that the label taxonomy is static, e.g., the domain ontologies or knowledge graphs.
An exception is ConceptVector~\cite{park2018conceptvector}, which supports user-controlled concept building with clusters of keywords before using them to analyze documents.
However, in the mining of DPSIR indicators, such techniques provide limited support for contextualizing the indicators. 
For example, depending on the research and dataset context, the keyword ``pollution'' can be a ``Driver'' that influences human activities, or a ``Pressure'' that influences environmental phenomena. 
In our work, we combine text mining with topic exploration to support the sensemaking of corpus and contextualization of DPSIR taxonomy.

\vspace*{-0.15cm}
\subsection{Prompt-based Text Mining and Evaluation}
Prompt Engineering is an emerging field that studies effective methods to control LLMs with natural language (i.e., prompts)~\cite{liu2023promptsurvey}, and has achieved state-of-the-art performance on text mining and information extraction tasks~\cite{dagdelen2024structured, xu2024llmforie}.
Moreover, studies have shown that integrating domain knowledge in prompts significantly improves the performance over general prompting methodologies~\cite{liu2025chemitryprompt}. 

Still, inexperienced practitioners can be over-reliant on LLMs, unaware of their limitations and risks~\cite{weidinger2022llmrisk}, such as producing misinformation. To mitigate this issue, NLP researchers have proposed techniques to evaluate LLM responses~\cite{chang2024surveyllm} from various perspectives, such as understanding, reasoning, or factuality. The most relevant to our work is on uncertainty (or confidence) estimation~\cite{chen2024quantifyinguncertaitny, Xiao2019quantify, kuhn2023semanticuncertainty}.
Xiao et al.~\cite{Xiao2019quantify} propose model and data uncertainties based on total variance. Kuhn et.al~\cite{kuhn2023semanticuncertainty} propose semantic uncertainty, which incorporates linguistic variances with off-the-shelf language models. More recently, Chen et al.~\cite{chen2024quantifyinguncertaitny} estimate model uncertainty by sampling multiple responses and their consistency.
In our work, we follow the consistency-based uncertainty estimation approaches and use Jaccard similarity to measure uncertainty. 
Then, we develop an uncertainty chart to combine uncertainty evaluation with topic exploration for progressive taxonomy construction.

\subsection{Design Studies for Prompt Engineering}
Despite the success in NLP, design studies for interactive prompt engineering have shown that writing prompts can be challenging for people without prompting experience or technical background~\cite{zamfirescu2023johnny, kim2024evallm}.
Zamifirescu et al.~\cite{zamfirescu2023johnny} found that non-technical people often overestimate the capability of LLMs because prompting imitates conversation with a human.
Moreover, the fast and constant progress in prompting methodologies~\cite{promptengineeringuide} makes it hard for them to utilize state-of-the-art prompting strategies.
Since some fundamental techniques such as chain-of-thought (CoT)~\cite{wei2023chainofthought} or retrieval-augmented-generation (RAG)~\cite{lewis2021rag}, researchers have proposed more advanced techniques like tree-of-thought (ToT)~\cite{yao2023treeofthought} and Hypothetical Document Embeddings (HyDe)~\cite{gao2022hyde}. 
In this work,  we address this challenge by exposing only the components that require domain knowledge integration to the users and integrating it into a prompting template under the hood.

Another challenge in prompt evaluation that Kim et al.~\cite{kim2024evallm} found in their user study is that evaluation is dynamic, i.e., people add additional evaluation criteria as they examine the outputs, making it hard to get actionable insights. Such a dynamic evaluation is inherent in DPSIR taxonomy mining, in that the environmental experts need to dynamically update the taxonomy as they gain a progressively deeper understanding of the corpus.
Our mining pipeline and uncertainty chart are designed to support such a dynamic evaluation.

