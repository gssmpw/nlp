
\documentclass{article} % For LaTeX2e
\usepackage{iclr2025_conference,times}

% Optional math commands from https://github.com/goodfeli/dlbook_notation.
\input{math_commands.tex}

\usepackage{hyperref}
\usepackage{url}



\usepackage[linesnumbered,ruled,vlined]{algorithm2e}

\SetKwInput{KwInput}{Input}                % Set the Input
\SetKwInput{KwOutput}{Output}              % set the Output

%  Paper 2 Imports

\usepackage{multirow}
 
\usepackage[noend]{algorithmic} 
\usepackage{graphicx}
% \usepackage{textcomp}

\usepackage{xcolor}
\usepackage{vcell}
\usepackage{arydshln}

% \title{confidence elicitation attacks on Large Language Models (LLMs)}
\title{Confidence Elicitation: A New Attack Vector for Large Language Models}

% Authors must not appear in the submitted version. They should be hidden
% as long as the \iclrfinalcopy macro remains commented out below.
% Non-anonymous submissions will be rejected without review.

% \author{Brian Formento \\
% Institute of Data Science, National University of Singapore \\
% Institute for Infocomm Research (I$^2$R), A*STAR \\
% \texttt{brian.formento@u.nus.edu} \\
% \And
% Chuan Sheng Foo \\
% Institute for Infocomm Research (I$^2$R), A*STAR \\
% Center for Frontier AI Research (CFAR), A*STAR \\
% \texttt{foo\_chuan\_sheng@i2r.a-star.edu.sg} \\
% \And
% See-Kiong Ng \\
% Institute of Data Science, National University of Singapore \\
% \texttt{seekiong@nus.edu.sg} 
% }

\author{Brian Formento$^{1,2}$, Chuan Sheng Foo$^{2,3}$, See-Kiong Ng$^{1}$ \\ 
$^1$Institute of Data Science, National University of Singapore \\
$^2$Institute for Infocomm Research, A*STAR \\
$^3$Centre for Frontier AI Research, A*STAR \\
\texttt{brian.formento@u.nus.edu}\\ \texttt{foo\_chuan\_sheng@i2r.a-star.edu.sg} \\ \texttt{seekiong@nus.edu.sg} \\
} 


% The \author macro works with any number of authors. There are two commands
% used to separate the names and addresses of multiple authors: \And and \AND.
%
% Using \And between authors leaves it to \LaTeX{} to determine where to break
% the lines. Using \AND forces a linebreak at that point. So, if \LaTeX{}
% puts 3 of 4 authors names on the first line, and the last on the second
% line, try using \AND instead of \And before the third author name.

\newcommand{\fix}{\marginpar{FIX}}
\newcommand{\new}{\marginpar{NEW}}

\iclrfinalcopy % Uncomment for camera-ready version, but NOT for submission.
\begin{document}


\maketitle
\vspace{-0em} % Adjust this value as needed
\begin{abstract}
\vspace{-0em}
A fundamental issue in deep learning has been adversarial robustness. As these systems have scaled, such issues have persisted. Currently, large language models (LLMs) with billions of parameters suffer from adversarial attacks just like their earlier, smaller counterparts. However, the threat models have changed. Previously, having gray-box access, where input embeddings or output logits/probabilities were visible to the user, might have been reasonable. However, with the introduction of closed-source models, no information about the model is available apart from the generated output. This means that current black-box attacks can only utilize the final prediction to detect if an attack is successful. In this work, we investigate and demonstrate the potential of attack guidance, akin to using output probabilities, while having only black-box access in a classification setting. This is achieved through the ability to elicit confidence from the model. We empirically show that the elicited confidence is calibrated and not hallucinated for current LLMs. By minimizing the elicited confidence, we can therefore increase the likelihood of misclassification. Our new proposed paradigm demonstrates promising state-of-the-art results on three datasets across two models  (LLaMA-3-8B-Instruct and Mistral-7B-Instruct-V0.3) when comparing our technique to existing hard-label black-box attack methods that introduce word-level substitutions. The code is publicly available at \href{https://github.com/Aniloid2/Confidence_Elicitation_Attacks}{GitHub: Confidence\_Elicitation\_Attacks}.
\end{abstract}

\section{Introduction}
\vspace{-0em} % Adjust this value as needed
% Deep learning has demonstrated remarkable performance across a variety of tasks and fields, including computer vision, NLP, speech recognition, and graph representation learning. These technologies are employed for tasks such as classification, question answering, and more. However, deep learning models are known to be vulnerable to adversarial attacks \citep{Adversarial_examples}. This vulnerability persists even as models have scaled up to include billions of parameters, especially in the form of LLMs.

% Due to these weaknesses, adversarial attacks have been applied in practice to create jailbreaks \citep{Jailbreak_1, AutoDan_Genetic_Algo} and adversarial misalignment \citep{Adversarially_Aligned}. 

Deep learning has demonstrated remarkable performance across a variety of tasks and fields, including computer vision, NLP, speech recognition, and graph representation learning. These technologies are employed for tasks such as classification, question answering, and more. However, deep learning models are known to be vulnerable to adversarial attacks \citep{Adversarial_examples}. This vulnerability persists even as models have scaled up to include billions of parameters, especially in the form of LLMs.

% Given these weaknesses, adversarial attacks have been applied in practice to create jailbreaks \citep{Jailbreak_1, AutoDan_Genetic_Algo} and adversarial misalignment \citep{Adversarially_Aligned}.

% Such vulnerabilities are particularly concerning in critical applications that require robust uncertainty assessment, such as healthcare \citep{Medical_Confidence_Estimation}, socio-technical systems and human-machine collaboration \citep{Second_Order_Uncertainty}. Providing confidence estimates is crucial in these domains to ascertain the reliability of a model’s responses, aiding in risk assessment, error mitigation, selective generation, and reducing the effects of hallucinations.

% For example, in healthcare, where a medical system provides uncertainty measurements for a diagnosis, an attacker might introduce input perturbations to reduce confidence, aiming to achieve a misclassification. In clinical support systems, such misclassifications can have lethal consequences \citep{Adversarial_In_Pathology}.

 Such vulnerabilities are particularly concerning in critical applications, such as healthcare \citep{Medical_Confidence_Estimation}, socio-technical systems and human-machine collaboration \citep{Second_Order_Uncertainty}. For example, in healthcare, where a medical system provides a diagnosis, an attacker might introduce input perturbations, aiming to achieve a misclassification. In clinical support systems, such misclassifications can have lethal consequences \citep{Adversarial_In_Pathology}.

Providing confidence estimates through confidence elicitation, whether in a template or a free-form generation, has been shown to enhance the performance and utility of these systems. This is particularly important in domains where assessing the reliability of a model's responses is crucial for effective risk assessment, error mitigation, selective generation, and minimizing the effects of hallucinations. As a result, we can anticipate these techniques to become more widespread. Consequently, exploring whether we can strengthen adversarial perturbations using confidence estimates is an important area of research, with the aim of designing more robust systems.

Adversarial attacks can be classified primarily into three categories: \textbf{white-box} attacks, where every part of the model, including the gradients, is known at the time of the attack; \textbf{grey-box} attacks, where some information, such as input embeddings, output logits or probabilities are available, and \textbf{black-box} attacks, where no information except for the output prediction is known. Based on this classification, common types of adversarial attacks include gradient-based methods \citep{Hotflip,AutoPrompt}, \textbf{soft-label} attacks a form of grey-box scenario where only output probabilities are available \citep{Textfooler, PWWS, BERTAttack}, and black-box \textbf{hard-label} scenarios, where only output predictions are accessible \citep{hard_label, TextHoaxer, TextHacker, sspattack}. 

Despite previous work in this area, the soft-label scenario has been regarded as unrealistic because LLMs (In particular, commercially available models) are now accessed via an API that returns only the generated output, without providing the probability distributions or logits across the categories/vocabulary \citep{TextHoaxer}, while current hard-label approaches often require a significant number of model queries, as they follow a top-down optimization method as illustrated in Figure \ref{fig:confidence_elicitation_attacks_boundary}. This method involves initially over-perturbing a sample and then gradually modifying it to maintain its semantic properties. Throughout this process, the model must be queried continuously to verify whether the changes result in the new sample remaining adversarial, which can be a problem if the API is rate-limited. Furthermore, it can be argued that expecting only basic outputs is beyond the scope for modern LLMs that perform free-form generation. In fact, most previous hard-label works focused on BERT-based models rather than the new LLMs capable of performing classification in multiple ways.

We therefore investigate the realistic scenario of hard-label attacks on LLMs and examine whether some of their emergent abilities under a free-form generation setting can be leveraged to perform these attacks.

In this paper, we demonstrate that it is possible to approximate soft labels, essentially allowing for a hard-label attack with more information. This is achieved through the technique of confidence elicitation \citep{Confidence_Elicitation}, where we simply ask the model for its own uncertainty.
% , receive a generated output and use such output to develop a Dirichlet distribution to sample our approximated probabilities.

% Providing confidence estimates is crucial for critical applications that require uncertainty estimation, such as human-machine collaboration, healthcare, and socio-technical systems. 

% Providing confidence estimates is crucial for critical applications that require uncertainty assessment, such as human-machine collaboration, healthcare, and socio-technical systems. These confidence estimates can offer insights into the reliability of a model’s responses, aiding in risk assessment, error mitigation, selective generation, and reducing the effects of hallucinations \citep{Confidence_Elicitation, Second_Order_Uncertainty, Medical_Confidence_Estimation}. Throughout our investigation, we assume the model is a simple pretrained LLM, potentially instruction-fine-tuned, such as LLaMA-Instruct, used off the shelf without further modifications. We employ this model by adding a prompt to solve its task in a zero-shot setting, a technique that has become popular for performing inference \citep{Zero_Shot_Reasoners}. We also assume that the generated output is accessible as a string format and that either the system is setup to perform confidence elicitation, and therefore can only perturb the input example $x$ or that we have access to the prompt under a free form generation setting, so that we can prompt the model for the predictions and confidence, we then only perturb $x$ during our attacks. We believe this approach is both realistic and suitable for the majority of backend operations that are accessible trough an API, including chatbots, QA, and classification, since it requires no additional compute resources, does not need extra data, and the model does not have to be modified to include an additional task head. Under this scenario, \textbf{we believe that the task of confidence elicitation may be at odds with robustness}.

Our main contributions are as follows: \textbf{Novel Attack Vector}: We are the first to investigate whether confidence elicitation can be used as a potential attack vector on LLMs, while providing strong motivations for why anyone would want to take this approach. \textbf{Effective Black-Box Optimization}: We demonstrate that confidence elicitation can be used effectively as feedback in black-box optimization to generate adversarial examples. Our evaluation across three datasets and two models illustrates that black-box optimization is achievable even with imperfectly calibrated models. \textbf{State-of-the-Art Hard-Label Attack on LLMs}: Our methodology achieves state-of-the-art performance in hard-label, black-box, word-substitution-based attacks on LLMs. Compared to the current state-of-the-art hard-label optimization technique (SSPAttack), our method results in better Attack Success Rates (ASR) with fewer queries and higher semantic similarity. We also release our code\footnote{We release our code in a GitHub Repository (\href{https://github.com/Aniloid2/Confidence_Elicitation_Attacks}{Confidence\_Elicitation\_Attacks})}.


% \begin{itemize}
%     \item \textbf{Novel Attack Vector}: We are the first to investigate whether confidence elicitation can be used as a potential attack vector on LLMs, while providing strong motivations for why anyone would want to take this approach.
%     \item \textbf{Effective Black-Box Optimization}: We demonstrate that confidence elicitation can be used effectively as feedback in black-box optimization to generate adversarial examples. Our evaluation across three datasets and two models illustrates that black-box optimization is achievable even with imperfectly calibrated models.
%     \item \textbf{State-of-the-Art Hard-Label Attack}: Our methodology achieves state-of-the-art performance in hard-label, black-box, word-substitution-based attacks on LLMs. Compared to the current state-of-the-art hard-label optimization technique (SSPAttack), our method results in better Attack Success Rates (ASR) with fewer queries and higher semantic similarity. We also release our code\footnote{We release our code in a Zip folder}.
%     % \item \textbf{Methodological Innovation}: We introduce a Dirichlet distribution aggregation strategy on top of a two-step, top-k verbalized confidence elicitation technique to approximate the model’s confidence. This distribution approximation allows us to minimize the elicited confidence for correct predictions and, if desired, maximize the elicited confidence for misclassifications.
% \end{itemize}
 


\begin{figure}[t]
\centering
  \includegraphics[width=.95\linewidth]{Pictures/confidence_elicitation_attacks-Page-2.drawio.pdf}
  \caption{Confidence elicitation attack on an LLM, assuming a classification task (Start), $x$ has a ground truth $y = false$, we first perform inference and extract the model's prediction $\hat{y}$ and original elicited confidence $\mathbf{p}_{\mathcal{C}}$ (green, Step 1), we use the confidence as feedback (Step 2) to determine whether a perturbation $\delta$, modelled after a word substitution ``\textbf{use}" $\rightarrow$ ``\textbf{utilize}" (Step 3) added to the input leads to lower confidence (yellow, Step 4), we carry on adding $\delta$s to the input $x \rightarrow x_{adv}$ until we achieve a misclassification (red, End).}
  \label{fig:confidence_elicitation_attacks}
\end{figure}


\section{Related Work}
\vspace{-0em} % Adjust this value as needed
\subsection{Attacks on LLMs}
\vspace{-0em}
The traditional adversarial attack formulation involves adding a subtle perturbation $\delta$ to the original $x$ so that $ x_{\text{adv}} = x + \delta$ \citep{Adversarial_examples}. There are many ways to calculate $\delta$; the overarching idea is that we want to add a perturbation $\delta$ to $x$ to identify regions of high risk in the input space \citep{FreeLB}. This, in turn, is expected to increase the output loss for a given task $t_a$.

One of the most effective ways to find regions of high input risk remains the fast gradient sign method (FGSM) \citep{AT}, the basic iterative method (BIM) \citep{BIM}, and projected gradient descent (PGD) \citep{PGD}. These methods utilize gradient information to find an optimal $\delta$ given a bound $\epsilon$ with either one or multiple iterations.

These first-order techniques model a tractable maximization operation over a non-convex loss landscape as follows:

\vspace{-0em} % Adjust this value as needed
\begin{equation}
\rho(\theta) = E_{(x,y) \sim D} \left[ \max_{\delta \in \Delta} L(\theta, x + \delta, y) \right]
\end{equation}
\vspace{-0em} % Adjust this value as needed

Where $\rho(\theta)$ represents the worst possible perturbation for $x$ on model $f_{\theta}$ with parameters $\theta$. When we maximize $ L(\theta, x + \delta, y)$, we do so by using multiple $\delta$ from a set $\Delta$ of all possible perturbations given a bound $\epsilon$. This bound is often set to the $L_2$-Norm: $[ |\delta|_2 \leq \epsilon ]$ or $L_{\infty}$-Norm: $[ |\delta|_\infty \leq \epsilon ]$.

These techniques and their variants have found moderate success when applied to the input embedding (continuous) space as white-box attacks \citep{ASCC, FreeLB, Convexhull}. However, most language applications interact with LLMs through the token space. Although previous work has attempted to use gradient information to perform attacks in the token space \citep{Hotflip, LLM_Attack_1, FGPM}, the projection from a continuous to a discrete space results in high perplexity and low semantics \citep{AutoDAN_Add_New_Tokens_Algo, AutoDan_Genetic_Algo}.

Given the unrealistic threat model of having access to gradients and input embedding spaces, some efforts have explored adversarial attacks in the token space by perturbing at the character \citep{TextBugger, Viper, SSTA,Empirical_Punctuation}, word \citep{Textfooler, PWWS, BERTAttack, morphin}, or sentence level \citep{Sentance_Level_Attack, Paraphrase_Attack, Paraphrase_Attack_2,Multi-Hop-Attacks}. These attacks often use output probabilities as feedback while employing heuristic search techniques, such as beam search, greedy search, or particle swarm optimization \citep{Sememe_PSO}. These methods have been exceptionally effective on BERT \citep{BERT}-based encoding models. However, widely used commercial LLMs (e.g. ChatGPT) are closed-source and logits or probabilities are not available; attacks have to operate  in a purely black-box setting with only hard-predictions available as feedback \citep{sspattack}. Recent works have explored using LLMs to red team (perform multiple black-box hard label attacks \citep{HardLabel}) on other LLMs with moderate success \citep{PAIR, LLM_Fool_Itself}. We believe the lack of feedback in the perturbation ($\delta$) optimization process is holding these attacks back.

In this paper, we propose a novel attack technique we call confidence elicitation attacks, which aim to attack models in a completely black-box setting while still utilizing feedback from the model in the form of elicitation. Our work shows promising state-of-the-art results on word substitution attacks on LLMs.


\subsection{Confidence Elicitation}
\vspace{-0em}
% Previeous work explored how well LLMs can express their confidence levels accurately. Previes work notices some basic prompting techniques do not express their confidence accurately \citep{Confidence_Elicitation}, but did have some success on more sophisitcated strategies such as elicting k guesses \citep{Just_Ask_For_Calibration}. 

% LLMs often do not express their confidence levels accurately \citep{Confidence_Elicitation}, which implies they are poorly calibrated. A common method, which has been thoroughly explored in previous work \citep{Calibration_Logits,Calibration_Logits_LLMs} involves using output logits as a proxy for confidence. This could be implemented by focusing on the first generated vector for a specific token or by adding a binary classification prediction head that utilizes the last generated token \citep{Language_Models_Mostly_Know}. While these approaches could be effective, several challenges arise. Firstly output logits may not be accessible, particularly with proprietary models. Secondly the likelihood of the next token primarily signifies lexical confidence and not epistemic uncertainty \citep{Epistetic_Uncertenty}. In fact, the confidence measure often depends on the application. For instance, when a model answers the query, "What is the capital of Italy?" the initial token could be highly uncertain among "Rome", "The" and "Italy" due to multiple valid response structures such as "Rome is the capital," "The capital is Rome," or "Italy's capital is Rome." This uncertainty underscores the model's difficulty in precisely determining a single method of response, reflecting a broader uncertainty pertinent to \textit{the same question} \citep{Semantic_Uncertainty}. Thirdly Although confidence can be reasonably approximated for classification tasks, it is more nuanced in generative tasks, where no single token's logit might reflect the overall response's confidence.



% LLMs often do not express their confidence levels accurately \citep{Confidence_Elicitation}, which implies they are poorly calibrated. 

Multiple studies have explored calibration in language models. A common method, which has been thoroughly explored in previous work \citep{Calibration_Logits,Calibration_Logits_LLMs} involves using output probabilities as a proxy for confidence. This could be implemented by focusing on the first generated vector for a specific token, by adding a binary classification prediction head that utilizes the last generated token \citep{Language_Models_Mostly_Know}, focusing on the answer specific token or take the average of the probabilities across the whole sequence, these techniques have been classified as white-box confidence estimation. While these approaches could be effective, several challenges arise. Firstly output logits or probabilities may not be accessible, particularly with proprietary models. Secondly the likelihood of the next token primarily signifies lexical confidence and not epistemic uncertainty \citep{Epistetic_Uncertenty}, and therefore, struggles to capture the semantic uncertainty in the entire text \citep{Confidence_Elicitation}. 
% Thirdly although confidence can be reasonably approximated for classification tasks, it is more nuanced in generative tasks, where no single token's logit might reflect the overall response's confidence.   

% Consequently, there remains a need for models capable of expressing uncertainty in natural language more directly.

As a result, previous work highlighted the need for models capable of directly expressing uncertainty in natural language in a black-box setting. Some research has explored enhancing calibration by empirically deriving confidence through repetitive model querying \citep{Strenght_In_Numbers_Elicitation}. Alternatively, models can be prompted to express their confidence verbally, either through verbalized numerical confidence elicitation \citep{Confidence_Elicitation} or verbal confidence elicitation \citep{Epistetic_Uncertenty}. It has been found that some prompts can achieve reasonable uncertainty quantification, especially by querying the model twice, first for the prediction, and the second time for the uncertainty estimates \citep{Just_Ask_For_Calibration} (Example of a prompt for confidence elicitation is in Table \ref{appendix:tab:2Sprompt} in the Appendix).

 

% Models might also be instruction-finetuned to improve calibration \citep{Elicitation_Instruction_Finetuning}. However, these strategies pose drawbacks including the additional computational costs and resources required for further training, which may not be feasible for all users or the requirement of task specific labels. There are also out-of-the-box solutions that do not necessitate further modifications, like semantic entropy. This technique employs an entailment model to cluster sequences generated by the model before estimating the generated uncertainty \citep{Semantic_Uncertainty}, other than an entailment model, a similar approach could be using semantic similarity encoders, which could give more fine grained similarity/meaning information for generated samples \citep{Universalsentenceencoder}\citep{Bertsentence}.

\section{Methodology}
\vspace{-0em} % Adjust this value as needed
In this work, we assume a classification setting similar to previous work \citep{LLM_Fool_Itself}. Here, a model \( f_{\theta} \) maps \( f_{\theta}: \mathcal{X} \mapsto \mathcal{Y} \) and is used to classify a sample \( x \) with ground truth label \( y \). This is done by first obtaining token IDs \(\mathbf{Z} \leftarrow t(x)\), where \( t \) is a tokenizer, and then using such IDs to look up the corresponding embedding vectors from embedding matrix $\mathbf{E}$ so that $\mathbf{X} \leftarrow\ \mathbf{E}(\mathbf{Z})$. The model will then make a prediction \(\hat{y} = f_{\theta}(\mathbf{X} )\). The goal of an adversarial attack is to modify \( x \) through an adversarial sample generator \( g \) (which is an attack algorithm) and a perturbation \( \delta \) (such as word substitutions or character insertions) to produce \( x_{\text{adv}} \), such that \( y \neq \hat{y} \). The adversarial sample \( x_{\text{adv}} \) can be evaluated for linguistic qualitative or quantitative properties using an evaluation algorithm \( d_{\epsilon} \).
\vspace{-0em} % Adjust this value as needed
\begin{equation}\label{minimize_confidence_equation}
     \rho(\theta) = - E_{(x,y) \sim D} \left[ \max_{\delta \in \Delta} C(\theta, x + \delta, y) \right] 
\end{equation}
\vspace{-0em} % Adjust this value as needed
In an adversarial settings, minimizing the confidence $C$ in the correct class \( y \) can be linked to maximizing the probability of misclassification.

% In an adversarial settings, minimizing the confidence $C$ in the correct class \( y \) can be linked to maximizing the probability of misclassification. Let \( p(c \mid x) \) denote the model's confidence for class \( c \) given input \( x \). The misclassification probability \( P_{\text{mis}}(x) \) is defined as $P_{\text{mis}}(x) = 1 - p(y \mid x)$. 


% To maximize the likelihood of misclassification, we aim to find a perturbation \( \delta \) that minimizes the confidence in the correct class \( y \), thereby increasing the misclassification probability:

% \begin{equation} 
% \rho(\theta) = - E_{(x,y) \sim D} \left[ \max_{\delta \in \Delta} p(y \mid x + \delta) \right]
% \end{equation} 

% Given the relationship:
% \begin{equation} 
% \max_{\delta \in \Delta} P_{\text{mis}}(x + \delta) = \max_{\delta \in \Delta} \left[ 1 - p(y \mid x + \delta) \right]
% \end{equation} 

% We see that as \( p(y \mid x + \delta) \) decreases, \( P_{\text{mis}}(x + \delta) \) increases. Thus, minimizing the confidence \( p(y \mid x + \delta) \) effectively maximizes the likelihood of a wrong classification. By incorporating elicited confidence from LLMs to guide perturbations, we can strategically minimize \( p(y \mid x + \delta) \) and thereby heighten the probability of misclassification. 

The approach is Equation \ref{minimize_confidence_equation} is illustrated in the dashed red box of Figure \ref{fig:confidence_elicitation_attacks}. As \(\delta\) substitutions are added to the input sample (green), \(\mathbf{p}{\mathcal{C}}\) decreases (yellow) until a misclassification occurs \textbf{False} $\rightarrow$ \textbf{True} (red), at which point the confidence can be maximized.



\begin{figure*}[t]
\centering 
  \includegraphics[width=.30\linewidth]{Pictures/sspattack_intuition.png}\hspace{.133\linewidth} 
  \includegraphics[width=.30\linewidth]{Pictures/ceattack_intuition.png} 
  \caption{Confidence Elicitation Attack on an LLM: Left) SSPAttack and other previous hard-label attacks first (A) perform multiple $\delta$ word substitutions, so that a heavily perturbed sample is misclassified. Then they (B)/(C) perform further optimization to improve the adversarial sample's quality. Right) In contrast, CEAttacks take a bottom-up approach by progressively perturbing the original sample with $\delta$ word substitutions until a misclassification is achieved, using model guidance through probability approximations. The adversarial perturbation is bounded by $\epsilon$ to preserve its quality. }
  \label{fig:confidence_elicitation_attacks_boundary}
\end{figure*}




% \subsectino{Uncertainty estimation in LLMs}
% When increasing, decreasing the temperature we are influencing the Aleatoric uncertenty, while when performing K guesses we are extracting the models Epistemic uncertenty. Naturaly, due to the random nature of our model, we want to consider both. To do this, we introduce dirichlet sampling to approximate the epistemic uncertenty of the model in the inner inference steps.


\subsection{Confidence Elicitation Attacks}
\vspace{-0em}
In this section, we outline a method to attack a model by leveraging its confidence levels. Assuming an ideal scenario, where the model is black-box, calibrated and always outputs a response with it's prediction and confidence values \citep{Generation_Only_Calibration}, the process involves querying the model using a prompt that includes an output request for its answer's confidence. The response, a confidence value as a percentage between 0 and 100 or verbalised, is then subjected to string analysis. The procedure can be formulated in a generalized confidence elicitation attack, detailed in Algorithm \ref{algo:generalized_algo}.

The algorithm initiates by querying the model with an input $x$ to obtain both a prediction $\hat{y}$ and the model's $f_{\theta}$ confidence in that prediction, denoted as $p_{\hat{y}}$. Subsequently, a generator $g_{\delta}$, designed to perturb the input by a factor of $\delta$, is employed to produce an adversarial example $x_{adv}$. This adversarial input is then verified by a discriminator $d_{\epsilon}$ with bound $\epsilon$, which checks for adherence to specified linguistic constraints. Should the constraints not be met, $g_{\delta}$ is requested to generate a revised $x_{adv}$.

Once an acceptable adversarial sample is obtained, it is processed by $f_{\theta}$ to determine the confidence level of the adversarial example, denoted as $\mathbf{p}_{\mathcal{C}}$. This new confidence is then compared with the original $p_{\hat{y}}$ to decide whether to accept or reject the perturbations introduced in $x_{adv}$. 


\begin{algorithm}[t!]
\DontPrintSemicolon  % Disable semicolons at the end of each line in the algorithm

\KwInput{Initial input $x$, Prompt for perturbation, Vocabulary $\mathcal{V} = \{\tau_1, \tau_2, \ldots, \tau_V\}$, original sample confidence $p_y$}
\KwOutput{Predicted class $\hat{y}$, adversarial sample $x_{adv}$ if conditions are met}

Initialize generator function $g_{\delta}$ and input $x$.\;
\While{not exceeded number of queries}{
    \Repeat{\( d_{\epsilon
    }(x_{adv}) \) is true}{
        $ x_{adv} \gets $ Output from $g_{\delta} $\;
    }
    Compute prediction and confidence: $\hat{y}, \mathbf{p}_{\mathcal{C}} \gets f_{\theta}(x_{\text{adv}})$ \tcp*{Assumes $f_{\theta}$ returns prediction and calibrated confidence}
    \If{$\mathbf{p}_{\mathcal{C}} < p_y$}{
        Substitute $x$ with $x_{adv}$\;
        $p_y \gets \mathbf{p}_{\mathcal{C}}$ \tcp*{Update previous confidence to current}
    }
    \ElseIf{$\mathbf{p}_{\mathcal{C}} \geq p_y$}{
        Perform an alternative perturbation or adjustment.\;
        $x \gets$ Some function of $x_{adv}$ that modifies or reverts changes\;
        $p_y \gets \mathbf{p}_{\mathcal{C}}$ \tcp*{Optionally update the reference confidence}
    }
}
\caption{Confidence elicitation attack}
\label{algo:generalized_algo}
\end{algorithm}


\section{Experimental setup}
\vspace{-0em} % Adjust this value as needed

We conducted our confidence elicitation attacks on Meta-Llama-3-8B-Instruct \citep{LLama} and Mistral-7B-Instruct-v0.2 \citep{Mistral} while performing classification on two common datasets to evaluate adversarial robustness: \textit{SST-2}, \textit{AG-News} and one modern dataset: \textit{StrategyQA} \citep{StrategyQA}. We utilize the evaluation framework previously proposed in \citep{TextAttack}, where an evaluation set is perturbed, and we record the following data metrics: \textit{Clean accuracy} (CA),  \textit{Accuracy under attack} (AUA), the \textit{Attack success rate} (ASR), \textit{Semantic similarity} (SemSim) based on the Universal Sentence Encoder \citep{Universalsentenceencoder}. We compare the original perplexity with the new perturbed sample's perplexity. \textit{Queries} where we subdivide this metric into two categories: \textit{All Att Queries Avg} and \textit{Succ Att Queries Avg}. Additionally, we track \textit{Total Attack Time}. We compare our guided word substitution attacks, CEAttack to ``Self-Fool Word Sub" from \citep{LLM_Fool_Itself}, TextHoaxer \citep{TextHoaxer} and SSPAttack from \citep{sspattack}. We discuss every metric and baseline in more detail in Appendix \ref{appendix:experimental_setup_details}.

 

\subsection{Implementation}
\vspace{-0em}

\paragraph{Prompting}
From Figure \ref{fig:confidence_elicitation_attacks}, we first initialize the model using a two-step prompting strategy. This strategy consists of an initial $k$ guess query to the model, yielding $k_{pred}$ guesses, followed by a second query to the model to obtain verbalized confidence levels for these $ k $ guesses $k_{conf}$. The confidence levels used are 'Highest', 'High', 'Medium', 'Low', and 'Lowest'. This technique has been demonstrated to be effective in previous work \citep{Just_Ask_For_Calibration, Epistetic_Uncertenty}. In our experiments we set $k$ to 20 for \textit{SST2} and \textit{AG-News} and $k$ to 6 for \textit{StrategyQA}.

\paragraph{Model}
Model-wise, previous confidence elicitation works \citep{Confidence_Elicitation} use model settings commonly found in generative tasks where the model samples from the top-$k$ (top-$k=40$) most probable next tokens, applies top-$p$ ($p=0.92$) nucleus sampling, which only considers next tokens with high probability, and uses a temperature setting of $\tau = 0.7$. This setup naturally introduces some randomness to the model, whose behavior is still not fully understood in an adversarial setting, as highlighted in previous work \citep{Catastrophic_Jailbreak,Weak_to_Strong,Crescendo_Jailbreak}. We keep all the settings consistent with previous work, but set $\tau \approx 0$, which follows previous work related to adversarial evaluation \citep{LLM_Fool_Itself}.


\paragraph{Dirichlet aggregation}

The differences among each of the $k_{pred}$ and $k_{conf}$ can be viewed as a form of epistemic uncertainty. To model our confidence thresholds using these $k_{pred}$ and $k_{conf}$, we employ a Dirichlet distribution. First, we construct an $\alpha $ vector where each prediction in  $ k_{pred}$   is assigned a value of 1. For each class, we then add the following foundational values from  $ k_{conf}$ : 'Highest' = 5, 'High' = 4, 'Medium' = 3, 'Low' = 2, and 'Lowest' = 1. Additionally, an $\alpha_0 $ with a value of 1 is included. With this \(\alpha\)-vector, \(\alpha = [\alpha_1, \alpha_2, \ldots, \alpha_C] \), where \( C \) is the number of expected classes. The mean (expectation) of the Dirichlet distribution is given by $ \mu_c = \frac{\alpha_c}{\sum_j \alpha_j}$. The mean is taken as the probability of the classifier, where the classifier uses the \(\text{argmax}\) of these probabilities for classification.

\paragraph{Adversarial setup}
 


Given a sample \( x \), we first extract an ordered subset of words \( W \subset x \) to perturb randomly, with the size of \( W \) capped at \( |W|=5 \). For each word \( w \in W \), we obtain a set \( S \) of synonyms sourced from Counter-fitted embeddings \citep{Counter_Fitted_Embeddings}. We introduce a perturbation \( \delta \) in \( x \) by performing a word substitution, replacing \( w \) with a synonym \( s \) from \( S \). For each synonym replacement, we generate a transformation. The list of all such transformations is denoted as \( T_{x_{w \leftarrow S}} \), where \( x_{w \leftarrow S} \) represents the original sample \( x \) with the word \( w \) systematically replaced by all possible synonyms in \( S \). Formally, for each \( w \in W \) we first identify the set \( S = \{s_1, s_2, \ldots, s_n\} \), where \( S \) is the set of synonyms for \( w \) obtained from counter-fitted word embeddings and then perform substitutions to create transformed samples \( \{x_{w \leftarrow s_1}, x_{w \leftarrow s_2}, \ldots, x_{w \leftarrow s_n}\} \). This yields a set of transformed samples $T_{x_{w \leftarrow S}} = \{x_{w \leftarrow s} \mid s \in S\}$ where we evaluate each \( x_{adv} \in T_{x_{w \leftarrow S}} \) to determine if it successfully achieves a drop in confidence in the prediction. Querying the model with \(  x_{adv} \) produces new \( k'_{pred} \) and \( k'_{conf} \), resulting in a new \(\alpha'\)-vector. With the new \(\alpha'\)-vector derived from \(  x_{adv} \), the new mean \(\mu'\) will be $\mu'_c = \frac{\alpha'_c}{\sum_j \alpha'_j} $.

We aim to induce misclassification by minimizing the probability of the current class:
\begin{equation} \label{mean_minimization}
\mathbb{E}_{(x,y) \sim D} \left[ \max_{\delta \in \Delta, d_\epsilon(x, x + \delta) \leq \epsilon} -(\mu'_y) \right]
\end{equation} 

Where \(\delta \in \Delta\) represents the set of perturbations given \( |W| \) and \( |S| \). For our problem, we aim to minimize the current class probability based on the Dirichlet mean, \(\mu\). If a transformation \( x_{adv} \) succeeds in lowering the confidence level of the model's output, we retain that word substitution. Otherwise, we proceed to the next word in \( W \). This iterative process is similar to a hill-climbing greedy algorithm, where we aim to perturb the sample $x$ iteratively to achieve the desired reduction in model confidence. 

% \paragraph{Adversarial setup}

% % Since our work barely introduces the concept of confidence elicitation attacks, we follow previous adversarial attack work and set the temperature $\tau$ to approximately 0. This approach maintains the general purposefulness of the model while allowing deterministic behavior across multiple model calls with the same input  $M$  in Figure \ref{fig:confidence_elicitation_attacks}. Setting  $\tau \approx 0$  also has the added benefit of reducing computation costs for our analysis since we won't have to perform multiple calls to the model after each perturbation. Nonetheless, we provide an ablation study with $\tau = 0.7$ in Appendix \ref{appendix:temperature_ablation}. 


% Given a sample \( x \), we first extract an ordered subset of words \( W \subset x \) to perturb randomly, with the size of \( W \) capped at \( |W|=10 \). For each word \( w \in W \), we obtain a set \( S \) of synonyms sourced from Counter-fitted embeddings \citep{Counter_Fitted_Embeddings}. We introduce a perturbation \( \delta \) in \( x \) by performing a word substitution, replacing \( w \) with a synonym \( s \) from \( S \).

% For each synonym replacement, we generate a transformation. The list of all such transformations is denoted as \( T_{x_{w \leftarrow S}} \), where \( x_{w \leftarrow S} \) represents the original sample \( x \) with the word \( w \) systematically replaced by all possible synonyms in \( S \).

% Formally, for each \( w \in W \):

% \begin{enumerate}
%     \item Identify the set \( S = \{s_1, s_2, \ldots, s_n\} \), where \( S \) is the set of synonyms for \( w \) obtained from counter-fitted word embeddings.
%     \item Perform substitutions to create transformed samples \( \{x_{w \leftarrow s_1}, x_{w \leftarrow s_2}, \ldots, x_{w \leftarrow s_n}\} \).
% \end{enumerate}

% This yields a set of transformed samples:
% \begin{equation} 
% T_{x_{w \leftarrow S}} = \{x_{w \leftarrow s} \mid s \in S\}.
% \end{equation} 

% Next, we evaluate each \( x_{adv} \in T_{x_{w \leftarrow S}} \) to determine if it successfully achieves a drop in confidence in the prediction. 

% Querying the model with \(  x_{adv} \) produces new \( k'_{pred} \) and \( k'_{conf} \), resulting in a new \(\alpha'\)-vector.

% With the new \(\alpha'\)-vector derived from \(  x_{adv}) \), the new mean \(\mu'\) will be:
% \begin{equation} 
% \mu'_c = \frac{\alpha'_c}{\sum_j \alpha'_j} 
% \end{equation} 

% We aim to induce misclassification by minimizing the logit of the current class:
% \begin{equation} 
% \mathbb{E}_{(x,y) \sim D} \left[ \max_{\delta \in \Delta, d_\epsilon(x, x + \delta) \leq \epsilon} -(\mu'_y) \right]
% \end{equation} 

% where \(\delta \in \Delta\) represents the set of perturbations given \( |W| \) and \( |S| \).

% For our problem, we aim to minimize the current class logit based on the Dirichlet mean, \(\mu\). If a transformation \( x_{adv} \) succeeds in lowering the confidence level of the model's output, we retain that word substitution. Otherwise, we proceed to the next word in \( W \).

% This iterative process is similar to a hill-climbing greedy algorithm, where we aim to perturb the sample $x$ iteratively to achieve the desired reduction in model confidence. 
% In practice, any black-box search algorithm can be used, such as particle swarm optimization, genetic algorithms, or beam search. We choose greedy search due to its simplicity and quick optimization process. Additionally, it serves as an easy-to-understand method for explaining the concept of confidence elicitation attacks. We leave the exploration of more powerful search algorithms for future work.




% \subsection{Evaluation metrics}
% We utilize the evaluation framework previously proposed in \citep{TextAttack}, where an evaluation set is perturbed, and we record the following data from the Total Attacked Samples ($TAS$) set: Number of Successful Attacks ($N_{succ-atk}$), Number of Failed Attacks ($N_{fail-atk}$), and Number of Skipped Attacks ($N_{skp-atk}$). We utilize these values to record the following metrics. \textit{Clean accuracy/Base accuracy/Original accuracy}, which offers a measure of the model's performance during normal inference. \textit{After attack accuracy/Accuracy under attack} ($A_{aft-atk}=\frac{N_{fail-atk}}{TAS}$) or (AUA), is critical, representing how effectively the attacker deceives the model across the dataset. Similarly, the \textit{After success rate} ($A_{succ-rte}=\frac{N_{succ-atk}}{TAS-N_{skp-atk}}$) or (ASR) excludes previously misclassified samples. The paper also considers the \textit{Semantic similarity/SemSim}, an automatic similarity index, as modeled by $d_\epsilon$ \citep{Universalsentenceencoder}. We compare the original perplexity with the new perturbed sample's perplexity, calculated using a GPT-2 model. A higher perplexity indicates that the example is less natural and fluent to the language model. \textit{Queries} denotes the number of model calls for inference. We subdivide this metric into two categories: \textit{All Att Queries Avg} and \textit{Succ Att Queries Avg}. The latter records the queries for successful attacks only, while the former includes all queries. Additionally, we track the duration of the attack process to perturb all the samples under \textit{Total Attack Time}.


% \subsection{Evaluation baselines}
% We compare our guided word substitution attacks, ``CEAttack" to "Self-Fool Word Sub" from \citep{LLM_Fool_Itself} and``SSPAttack" from \citep{sspattack}. The "Self-Fool Word Sub" method operates by instructing the LLM model to substitute words with synonyms while maintaining semantic integrity. We execute a query to generate $x_{adv}$, extract $x_{adv}$ from the generated string, and perform another call to the model to achieve the misclassification, if no misclassification is found, we repeat the process twenty times. On the other hand, the ``SSPAttack" algorithm initially heavily perturbs the original sample with multiple synonym word substitutions to induce misclassification. Subsequently, they optimize the sample for quality by first reverting as many perturbed words to their original form as possible, and then by substituting words with synonyms that enhance semantic similarity. This optimization process is conducted using the hard-label as feedback.

\section{Results}
\vspace{-0em} % Adjust this value as needed
\subsection{Model Calibration}
\vspace{-0em}
% Using techniques from previous work

By calculating the Expected Calibration Error (ECE) \citep{Expected_Calibration_Error}, the Area Under the Receiver Operating Characteristic Curve (AUROC), and plotting reliability diagrams \citep{Confidence_Elicitation}, we can evaluate how well a model is calibrated for confidence elicitation. ECE is a metric used to assess how well a model's confidence estimates align with the actual probabilities of outcomes being correct. For example, it helps evaluate how accurately a model's predicted confidence (e.g., 'I'm 80\% sure this is correct') matches reality. This assessment is averaged across 500 examples. A thorough explanation of ECE is provided in Appendix \ref{appendix:ece}.


We first demonstrate that LLama3 is well-calibrated for the SST2, AG-News, and StrategyQA tasks, as illustrated in Table \ref{tab:calibration_table} and Figure \ref{fig:calibration_llm_llama3_sst2_plots}. In contrast, Mistral-V0.3 is reasonably well-calibrated for these same tasks, as shown in Table \ref{tab:calibration_table} and Figure \ref{appendix:fig:calibration_llm_mistral} in Appendix \ref{appendix:futher_calibration_plots}. The Expected Calibration Error (ECE) is low across all our tests. Additionally, all tests exhibit a high AUROC. Furthermore, for SST2 and StrategyQA with LLama3, the reliability plots are close to the expected diagonal, indicating that the model performs as expected on these tasks and demonstrates some awareness of its own uncertainty in the answers. Consequently, by minimizing confidence, we anticipate an increased likelihood of misclassification. These tests primarily highlight that well-calibrated models, such as LLama3 for SST2 and StrategyQA, already exist. This capability is likely to improve further in the future, as models have been shown to develop emergent abilities with increased scale, thereby making confidence elicitation attacks more powerful.



\begin{table}[ht]
\centering
\scalebox{0.8}{
\begin{tabular}{llcccccccccccc}
\hline
\multicolumn{14}{c}{\textbf{Calibration of verbal confidence elicitation}} \\ \hline
\textbf{Model} & \textbf{Dataset} & \multicolumn{4}{c}{\textbf{Avg ECE ↓}} & \multicolumn{2}{c}{\textbf{AUROC ↑}} & \multicolumn{2}{c}{\textbf{\begin{tabular}[c]{@{}c@{}}AUPRC\\ Positive ↑\end{tabular}}} & \multicolumn{4}{c}{\textbf{\begin{tabular}[c]{@{}c@{}}AUPRC\\ Negative ↑\end{tabular}}} \\ \hline
 & SST2 & \multicolumn{4}{c}{0.1264} & \multicolumn{2}{c}{0.9696} & \multicolumn{2}{c}{0.9730} & \multicolumn{4}{c}{0.9678} \\
 & AG-News & \multicolumn{4}{c}{0.1376} & \multicolumn{2}{c}{0.9293} & \multicolumn{2}{c}{-} & \multicolumn{4}{c}{-} \\
\multirow{-3}{*}{\begin{tabular}[c]{@{}l@{}}LLaMa-3-8B\\ Instruct\end{tabular}} & StrategyQA & \multicolumn{4}{c}{0.0492} & \multicolumn{2}{c}{0.6607} & \multicolumn{2}{c}{0.6212} & \multicolumn{4}{c}{0.6863} \\ \hline
 & SST2 & \multicolumn{4}{c}{0.1542} & \multicolumn{2}{c}{0.9537} & \multicolumn{2}{c}{0.9616} & \multicolumn{4}{c}{0.9343} \\
 & AG-News & \multicolumn{4}{c}{0.1216} & \multicolumn{2}{c}{0.8826} & \multicolumn{2}{c}{-} & \multicolumn{4}{c}{-} \\
\multirow{-3}{*}{\begin{tabular}[c]{@{}l@{}}Mistral-7B\\ Instruct-v0.3\end{tabular}} & StrategyQA & \multicolumn{4}{c}{0.1295} & \multicolumn{2}{c}{0.6358} & \multicolumn{2}{c}{0.6421} & \multicolumn{4}{c}{0.6185} \\ \hline

\end{tabular}
}
\caption{Expected Calibration Error (ECE) and the Area Under Receiver Operating Characteristic (AUROC) of models performing zero shot classification on SST2, AG-News and StrategyQA.}
% \caption{Expected Calibration Error (ECE) and the Area Under Receiver Operating Characteristic (AUROC) of models performing zero shot classification on SST2, AG-News and StrategyQA. For AG-News we do an one-vs-all average for the AUROC.}
  \label{tab:calibration_table}
\end{table}


\begin{figure}[t]
\centering
  \includegraphics[width=0.30\linewidth]{Pictures/calibration_pictures_llama3/sst_cali_llama3.pdf}
  \includegraphics[width=0.30\linewidth]{Pictures/calibration_pictures_llama3/ag_news_cali_llama3.pdf}
   \includegraphics[width=0.30\linewidth]{Pictures/calibration_pictures_llama3/strategyQA_cali_llama3.pdf}
  \includegraphics[width=0.30\linewidth]{Pictures/calibration_pictures_llama3/sst_roc_llama3.pdf} 
  \includegraphics[width=0.30\linewidth]{Pictures/calibration_pictures_llama3/ag_news_roc_llama3.pdf} 
  \includegraphics[width=0.30\linewidth]{Pictures/calibration_pictures_llama3/strategyQA_roc_llama3.pdf}
  \caption{Reliability plots. Top) We show the SST2, AG-News and StrategyQA on LLama 3 8B Instruct calibration plots. Bottom) The ROC curves. The diagonal line is the optimal calibration.}
  \label{fig:calibration_llm_llama3_sst2_plots}
\end{figure}

\subsection{Confidence elicitation attack results}\label{sec:elicitation_attacks}
\vspace{-0em}
When feedback from the model is provided through confidence elicitation, an attack algorithm can identify approximated input perturbations that minimize the elicited confidence, thereby increasing the likelihood of misclassification. Table \ref{tab:elicitation_attacks_table_attack} demonstrates that our Confidence Elicitation Attack (CEAttack) achieves a higher attack success rate ``ASR" for both LLama3 and Mistral across all datasets compared to ``Self-Fool Word Sub" which performs no optimization, and SSPAttack/TextHoaxer which perform optimization on hard labels.

% \begin{table}[ht]
% \centering
% \scalebox{0.63}{
% \begin{tabular}{llcccccccccl}
% \hline
% \multicolumn{2}{l}{\multirow{2}{*}{}} & \multicolumn{10}{c}{\textbf{Attack Performance Tests}} \\ \cline{3-12} 
% \multicolumn{2}{l}{} & \multicolumn{3}{c|}{\textbf{CA {[}\%{]} ↑}} & \multicolumn{3}{c|}{\textbf{AUA {[}\%{]} ↓}} & \multicolumn{4}{c}{\textbf{ASR {[}\%{]} ↑}} \\ \hline
% Model & Dataset & \textbf{\begin{tabular}[c]{@{}c@{}}Self-Fool \\ Word Sub\end{tabular}} & \textbf{SSPAttack} & \multicolumn{1}{c|}{\textbf{CEAttack}} & \textbf{\begin{tabular}[c]{@{}c@{}}Self-Fool \\ Word Sub\end{tabular}} & \textbf{SSPAttack} & \multicolumn{1}{c|}{\textbf{CEAttack}} & \textbf{\begin{tabular}[c]{@{}c@{}}Self-Fool \\ Word Sub\end{tabular}} & \textbf{SSPAttack} & \multicolumn{2}{c}{\textbf{CEAttack}} \\ \hline
% \multirow{3}{*}{\begin{tabular}[c]{@{}l@{}}LLaMa-3-8B\\ Instruct\end{tabular}} & SST2 & 90.36 & 90.76 & \multicolumn{1}{c|}{90.56} & 88.35 & 81.93 & \multicolumn{1}{c|}{\textbf{72.69}} & 2.22 & 9.73 & \multicolumn{2}{c}{\textbf{19.73}} \\
%  & AG-News & 61.37 & 61.77 & \multicolumn{1}{c|}{62.17} & 61.17 & 45.27 & \multicolumn{1}{c|}{\textbf{43.06}} & 0.33 & 26.71 & \multicolumn{2}{c}{\textbf{30.74}} \\
%  & StrategyQA & 60.52 & 60.12 & \multicolumn{1}{c|}{60.12} & 59.52 & 42.28 & \multicolumn{1}{c|}{\textbf{32.67}} & 1.66 & 29.67 & \multicolumn{2}{c}{\textbf{45.67}} \\ \hline
% \multirow{3}{*}{\begin{tabular}[c]{@{}l@{}}Mistral-7B\\ Instruct-v0.3\end{tabular}} & SST2 & 87.87 & 87.66 & \multicolumn{1}{c|}{87.45} & 84.73 & 75.31 & \multicolumn{1}{c|}{\textbf{71.76}} & 3.57 & 14.08 & \multicolumn{2}{c}{\textbf{17.94}} \\
%  & AG-News & - & 65.6 & \multicolumn{1}{c|}{66.18} & - & 52.48 & \multicolumn{1}{c|}{\textbf{40.82}} & - & 20.0 & \multicolumn{2}{c}{\textbf{38.33}} \\
%  & StrategyQA & 60.34 & 59.61 & \multicolumn{1}{c|}{59.61} & 59.61 & 41.13 & \multicolumn{1}{c|}{\textbf{36.21}} & 1.22 & 30.99 & \multicolumn{2}{c}{\textbf{39.26}} \\ \hline
% \end{tabular}
% }
% \caption{Results of performing Confidence Elicitation Attacks. Numbers in \textbf{bold} are the best results}
%   \label{tab:elicitation_attacks_table_attack}
% \end{table}


\begin{table}[ht]
\centering
\scalebox{0.59}{ 
\begin{tabular}{llcccccccccccc}
\hline
\multicolumn{2}{l}{} & \multicolumn{12}{c}{\textbf{Attack Performance Tests}} \\ \cline{3-14} 
\multicolumn{2}{l}{\multirow{-2}{*}{}} & \multicolumn{4}{c|}{\textbf{CA {[}\%{]} ↑}} & \multicolumn{4}{c|}{\textbf{AUA {[}\%{]} ↓}} & \multicolumn{4}{c}{\textbf{ASR {[}\%{]} ↑}} \\ \hline
Model & Dataset & \multicolumn{4}{c|}{\textbf{Vanilla}} & \textbf{\begin{tabular}[c]{@{}c@{}}Self-Fool \\ Word Sub\end{tabular}} & \textbf{\begin{tabular}[c]{@{}c@{}}Text\\ Hoaxer\end{tabular}} & \textbf{\begin{tabular}[c]{@{}c@{}}SSP\\ Attack\end{tabular}} & \multicolumn{1}{c|}{\textbf{\begin{tabular}[c]{@{}c@{}}CE\\ Attack\end{tabular}}} & \textbf{\begin{tabular}[c]{@{}c@{}}Self-Fool \\ Word Sub\end{tabular}} & \multicolumn{1}{c}{\textbf{\begin{tabular}[c]{@{}c@{}}Text\\ Hoaxer\end{tabular}}} & \multicolumn{1}{c}{\textbf{\begin{tabular}[c]{@{}c@{}}SSP\\ Attack\end{tabular}}} & \multicolumn{1}{c}{\textbf{\begin{tabular}[c]{@{}c@{}}CE\\ Attack\end{tabular}}} \\ \hline
 & SST2 & \multicolumn{4}{c|}{90.56±0.14} & 88.35 & 82.93 & 81.93 & \multicolumn{1}{c|}{\textbf{72.69}} & 2.22 & \multicolumn{1}{c}{8.43} & \multicolumn{1}{c}{9.73} & \multicolumn{1}{c}{\textbf{19.73}} \\
 & AG-News & \multicolumn{4}{c|}{61.62±0.38} & 61.17 & 49.3 & 45.27 & \multicolumn{1}{c|}{\textbf{43.06}} & 0.33 & \multicolumn{1}{c}{19.41} & \multicolumn{1}{c}{26.71} & \multicolumn{1}{c}{\textbf{30.74}} \\
\multirow{-3}{*}{\begin{tabular}[c]{@{}l@{}}LLaMa-3-8B\\ Instruct\end{tabular}} & StrategyQA & \multicolumn{4}{c|}{60.22±0.17} & 59.52 & 45.29 & 42.28 & \multicolumn{1}{c|}{\textbf{32.67}} & 1.66 & \multicolumn{1}{c}{24.67} & \multicolumn{1}{c}{29.67} & \multicolumn{1}{c}{\textbf{45.67}} \\ \hline
 & SST2 & \multicolumn{4}{c|}{87.87±0.39} & 84.73 & 74.27 & 75.31 & \multicolumn{1}{c|}{\textbf{71.76}} & 3.57 & \multicolumn{1}{c}{16.08} & \multicolumn{1}{c}{14.08} & \multicolumn{1}{c}{\textbf{17.94}} \\
 & AG-News & \multicolumn{4}{c|}{65.99±0.27} & - & 48.69 & 52.48 & \multicolumn{1}{c|}{\textbf{40.82}} & - & \multicolumn{1}{c}{26.43} & \multicolumn{1}{c}{20.0} & \multicolumn{1}{c}{\textbf{38.33}} \\
\multirow{-3}{*}{\begin{tabular}[c]{@{}l@{}}Mistral-7B\\ Instruct-v0.3\end{tabular}} & StrategyQA & \multicolumn{4}{c|}{59.92±0.32} & 59.61 & 44.33 & 41.13 & \multicolumn{1}{c|}{\textbf{36.21}} & 1.22 & \multicolumn{1}{c}{26.23} & \multicolumn{1}{c}{30.99} & \multicolumn{1}{c}{\textbf{39.26}} \\ \hline 
\end{tabular}
}
\caption{Results of performing Confidence Elicitation Attacks. Numbers in \textbf{bold} are the best results}
  \label{tab:elicitation_attacks_table_attack}
\end{table}


Having a high threshold $\epsilon$ allows only high-quality, label-preserving perturbations to be kept. The successful perturbations in our study all have an angular semantic similarity of at least $\epsilon = 0.84$, which is a common threshold used in previous works \citep{Textfooler}. In practice, any successful perturbation that changes the prediction while being above this threshold is deemed a successful attack. However, we find that our technique is also at times better at preserving quality when compared to the alternatives, as shown by the high ``SemSim" in Table \ref{tab:elicitation_attacks_table_quality}. This is likely due to the algorithm not having to change more words than absolutely necessary to achieve a successful perturbation. We present a detailed analysis of one qualitative example in Table \ref{tab:example_analysis}. Additionally, a further discussion on sample quality, along with multiple qualitative examples, can be found in Appendix \ref{qualitative_examples} and Appendix \ref{appendix:more_qualitative_examples}.


% Word substitutions using Counter-fitted embeddings are already constrained in terms of semantics due to the pre-built nature of the dictionary. This ensures that each word can only be replaced with a previously vetted synonym. Compared to ``Self-Fool Word Sub" and SSPAttack our method more effectively preserves the original meaning of the text, as evidenced by the high ``SemSim" in Table \ref{tab:elicitation_attacks_table_quality}. Table \ref{tab:qualitative_samples} provides multiple examples from SST2 that have been perturbed by our proposed technique, CEAttack demonstrating conversions of examples from Positive to Negative and from Negative to Positive sentiment. Additional examples for AG-News and StrategyQA can be found in Table \ref{appendix:tab:qualitative_samples_ag_news} and Table \ref{appendix:tab:qualitative_samples_strategyQA} in Appendix \ref{appendix:more_qualitative_examples}.

% \begin{table}[h]
% \centering
% \scalebox{0.6}{
% \begin{tabular}{llcccccccccl}
% \hline
% \multicolumn{2}{l}{\multirow{2}{*}{}} & \multicolumn{10}{c}{\textbf{Quality Tests}} \\ \cline{3-12} 
% \multicolumn{2}{l}{} & \multicolumn{3}{c|}{\textbf{SemSim ↑}} & \multicolumn{3}{c|}{\textbf{\begin{tabular}[c]{@{}c@{}}Original \\ Perplexity ↓\end{tabular}}} & \multicolumn{4}{c}{\textbf{\begin{tabular}[c]{@{}c@{}}After-Attack\\ Perplexity ↓\end{tabular}}} \\ \hline
% Model & Dataset & \textbf{\begin{tabular}[c]{@{}c@{}}Self-Fool \\ Word Sub\end{tabular}} & \textbf{SSPAttack} & \multicolumn{1}{c|}{\textbf{CEAttack}} & \textbf{\begin{tabular}[c]{@{}c@{}}Self-Fool \\ Word Sub\end{tabular}} & \textbf{SSPAttack} & \multicolumn{1}{c|}{\textbf{CEAttack}} & \textbf{\begin{tabular}[c]{@{}c@{}}Self-Fool \\ Word Sub\end{tabular}} & \textbf{SSPAttack} & \multicolumn{2}{c}{\textbf{CEAttack}} \\ \hline
% \multirow{3}{*}{\begin{tabular}[c]{@{}l@{}}LLaMa-3-8B\\ Instruct\end{tabular}} & SST2 & 0.87 & 0.87 & \multicolumn{1}{c|}{\textbf{0.88}} & 73.75 & 69.04 & \multicolumn{1}{c|}{69.81} & 82.95 & 143.81 & \multicolumn{2}{c}{111.16} \\
%  & AG-News & 0.86 & 0.88 & \multicolumn{1}{c|}{\textbf{0.93}} & 354.12 & 66.31 & \multicolumn{1}{c|}{72.01} & 320.06 & 193.16 & \multicolumn{2}{c}{98.9} \\
%  & StrategyQA & 0.87 & 0.89 & \multicolumn{1}{c|}{\textbf{0.89}} & 281.38 & 115.63 & \multicolumn{1}{c|}{105.42} & 220.73 & 232.31 & \multicolumn{2}{c}{206.23} \\ \hline
% \multirow{3}{*}{\begin{tabular}[c]{@{}l@{}}Mistral-7B\\ Instruct-v0.3\end{tabular}} & SST2 & 0.87 & 0.87 & \multicolumn{1}{c|}{\textbf{0.88}} & 79.06 & 63.44 & \multicolumn{1}{c|}{61.68} & 91.85 & 118.67 & \multicolumn{2}{c}{95.85} \\
%  & AG-News & - & 0.88 & \multicolumn{1}{c|}{\textbf{0.93}} & - & 74.76 & \multicolumn{1}{c|}{73.2} & - & 188.83 & \multicolumn{2}{c}{97.19} \\
%  & StrategyQA & 0.89 & 0.89 & \multicolumn{1}{c|}{\textbf{0.9}} & 74.04 & 95.43 & \multicolumn{1}{c|}{97.3} & 93.57 & 195.33 & \multicolumn{2}{c}{177.94} \\ \hline
% \end{tabular}
% }
% \caption{Quality results of performing Confidence Elicitation Attacks. Numbers in \textbf{bold} represent the best results for semantic similarity, only successful perturbations are considered.}
%   \label{tab:elicitation_attacks_table_quality}
% \end{table}

% Because CEAttack's optimization path is more direct compared to ``SSPAttack" as illustrated in Figure \ref{fig:confidence_elicitation_attacks_boundary}, the algorithm doesn't need to explore a large section of the manifold. Instead, by approximating the probabilities, it finds regions of high risk closest to the original input, drastically cutting the number of required queries and optimization time. This efficiency is demonstrated in the columns ``Succ Att Queries Avg" which only records the number of queries for the successful attacks, and ``Total Attack Time" in Table \ref{tab:elicitation_attacks_table_efficency}.

\begin{table}[h]
\centering
\scalebox{0.58}{ 
\begin{tabular}{llcccccccccccc} 
\hline
\multicolumn{2}{l}{} & \multicolumn{12}{c}{\textbf{Quality Tests}} \\ \cline{3-14} 
\multicolumn{2}{l}{\multirow{-2}{*}{}} & \multicolumn{4}{c|}{\textbf{SemSim ↑}} & \multicolumn{4}{c|}{\textbf{\begin{tabular}[c]{@{}c@{}}Original \\ Perplexity ↓\end{tabular}}} & \multicolumn{4}{c}{\textbf{\begin{tabular}[c]{@{}c@{}}After-Attack\\ Perplexity ↓\end{tabular}}} \\ \hline
Model & Dataset & \multicolumn{1}{c}{\textbf{\begin{tabular}[c]{@{}c@{}}Self-Fool \\ Word Sub\end{tabular}}} & \textbf{\begin{tabular}[c]{@{}c@{}}Text\\ Hoaxer\end{tabular}} & \textbf{\begin{tabular}[c]{@{}c@{}}SSP\\ Attack\end{tabular}} & \multicolumn{1}{c|}{\textbf{\begin{tabular}[c]{@{}c@{}}CE\\ Attack\end{tabular}}} & \textbf{\begin{tabular}[c]{@{}c@{}}Self-Fool \\ Word Sub\end{tabular}} & \textbf{\begin{tabular}[c]{@{}c@{}}Text\\ Hoaxer\end{tabular}} & \textbf{\begin{tabular}[c]{@{}c@{}}SSP\\ Attack\end{tabular}} & \multicolumn{1}{c|}{\textbf{\begin{tabular}[c]{@{}c@{}}CE\\ Attack\end{tabular}}} & \textbf{\begin{tabular}[c]{@{}c@{}}Self-Fool \\ Word Sub\end{tabular}} & \multicolumn{1}{c}{\textbf{\begin{tabular}[c]{@{}c@{}}Text\\ Hoaxer\end{tabular}}} & \multicolumn{1}{c}{\textbf{\begin{tabular}[c]{@{}c@{}}SSP\\ Attack\end{tabular}}} & \textbf{\begin{tabular}[c]{@{}c@{}}CE\\ Attack\end{tabular}} \\ \hline
 & SST2 & \multicolumn{1}{c}{0.87} & 0.89 & 0.87 & \multicolumn{1}{c|}{0.88} & 73.75 & 76.51 & 69.04 & \multicolumn{1}{c|}{69.81} & 82.95 & \multicolumn{1}{c}{113.0} & \multicolumn{1}{c}{143.81} & 111.16 \\
 & AG-News & \multicolumn{1}{c}{0.86} & 0.94 & 0.88 & \multicolumn{1}{c|}{0.93} & 354.12 & 78.62 & 66.31 & \multicolumn{1}{c|}{72.01} & 320.06 & \multicolumn{1}{c}{99.02} & \multicolumn{1}{c}{193.16} & 98.9 \\
\multirow{-3}{*}{\begin{tabular}[c]{@{}l@{}}LLaMa-3-8B\\ Instruct\end{tabular}} & StrategyQA & \multicolumn{1}{c}{0.87} & 0.89 & 0.89 & \multicolumn{1}{c|}{0.89} & 281.38 & 104.83 & 115.63 & \multicolumn{1}{c|}{105.42} & 220.73 & \multicolumn{1}{c}{182.15} & \multicolumn{1}{c}{232.31} & 206.23 \\ \hline
 & SST2 & \multicolumn{1}{c}{0.87} & 0.9 & 0.87 & \multicolumn{1}{c|}{0.88} & 79.06 & 63.03 & 63.44 & \multicolumn{1}{c|}{61.68} & 91.85 & \multicolumn{1}{c}{85.27} & \multicolumn{1}{c}{118.67} & 95.85 \\
 & AG-News & \multicolumn{1}{c}{-} & 0.94 & 0.88 & \multicolumn{1}{c|}{0.93} & - & 86.47 & 74.76 & \multicolumn{1}{c|}{73.2} & - & \multicolumn{1}{c}{103.25} & \multicolumn{1}{c}{188.83} & 97.19 \\
\multirow{-3}{*}{\begin{tabular}[c]{@{}l@{}}Mistral-7B\\ Instruct-v0.3\end{tabular}} & StrategyQA & \multicolumn{1}{c}{0.89} & 0.9 & 0.89 & \multicolumn{1}{c|}{0.9} & 74.04 & 85.2 & 95.43 & \multicolumn{1}{c|}{97.3} & 93.57 & \multicolumn{1}{c}{140.08} & \multicolumn{1}{c}{195.33} & 177.94 \\ \hline


\end{tabular}
}
\caption{Quality results of performing Confidence Elicitation Attacks. Only successful perturbations are considered.}
  \label{tab:elicitation_attacks_table_quality}
\end{table}

% \vspace{-0em} % Adjust this value as needed

% \begin{table}[h]
% \centering
% \scalebox{0.58}{
% \color{blue} 
% \begin{tabular}{llcccccccccccc} 
% \hline
% \multicolumn{2}{l}{\multirow{2}{*}{}} & \multicolumn{12}{c}{\textbf{Quality Tests}} \\ \cline{3-14} 
% \multicolumn{2}{l}{} & \multicolumn{4}{c|}{\textbf{SemSim ↑}} & \multicolumn{4}{c|}{\textbf{\begin{tabular}[c]{@{}c@{}}Original \\ Perplexity ↓\end{tabular}}} & \multicolumn{4}{c}{\textbf{\begin{tabular}[c]{@{}c@{}}After-Attack\\ Perplexity ↓\end{tabular}}} \\ \hline
% Model & Dataset & \multicolumn{1}{c}{\textbf{\begin{tabular}[c]{@{}c@{}}Self-Fool \\ Word Sub\end{tabular}}} & \textbf{\begin{tabular}[c]{@{}c@{}}Text\\ Hoaxer\end{tabular}} & \textbf{\begin{tabular}[c]{@{}c@{}}SSP\\ Attack\end{tabular}} & \multicolumn{1}{c|}{\textbf{\begin{tabular}[c]{@{}c@{}}CE\\ Attack\end{tabular}}} & \textbf{\begin{tabular}[c]{@{}c@{}}Self-Fool \\ Word Sub\end{tabular}} & \textbf{\begin{tabular}[c]{@{}c@{}}Text\\ Hoaxer\end{tabular}} & \textbf{\begin{tabular}[c]{@{}c@{}}SSP\\ Attack\end{tabular}} & \multicolumn{1}{c|}{\textbf{\begin{tabular}[c]{@{}c@{}}CE\\ Attack\end{tabular}}} & \textbf{\begin{tabular}[c]{@{}c@{}}Self-Fool \\ Word Sub\end{tabular}} & \multicolumn{1}{c}{\textbf{\begin{tabular}[c]{@{}c@{}}Text\\ Hoaxer\end{tabular}}} & \multicolumn{1}{c}{\textbf{\begin{tabular}[c]{@{}c@{}}SSP\\ Attack\end{tabular}}} & \textbf{\begin{tabular}[c]{@{}c@{}}CE\\ Attack\end{tabular}} \\ \hline
% \multirow{3}{*}{\begin{tabular}[c]{@{}l@{}}LLaMa-3-8B\\ Instruct\end{tabular}} & SST2 & \multicolumn{1}{c}{0.87} & 0.89 & 0.87 & \multicolumn{1}{c|}{0.88} & 73.75 & 76.51 & 69.04 & \multicolumn{1}{c|}{69.81} & 82.95 & \multicolumn{1}{c}{113.0} & \multicolumn{1}{c}{143.81} & 111.16 \\
%  & AG-News & \multicolumn{1}{c}{0.86} & 0.94 & 0.88 & \multicolumn{1}{c|}{0.93} & 354.12 & 78.62 & 66.31 & \multicolumn{1}{c|}{72.01} & 320.06 & \multicolumn{1}{c}{99.02} & \multicolumn{1}{c}{193.16} & 98.9 \\
%  & StrategyQA & \multicolumn{1}{c}{0.87} & 0.89 & 0.89 & \multicolumn{1}{c|}{0.89} & 281.38 & 104.83 & 115.63 & \multicolumn{1}{c|}{105.42} & 220.73 & \multicolumn{1}{c}{182.15} & \multicolumn{1}{c}{232.31} & 206.23 \\ \hline
% \multirow{3}{*}{\begin{tabular}[c]{@{}l@{}}Mistral-7B\\ Instruct-v0.3\end{tabular}} & SST2 & \multicolumn{1}{c}{0.87} & 0.9 & 0.87 & \multicolumn{1}{c|}{0.88} & 79.06 & 63.03 & 63.44 & \multicolumn{1}{c|}{61.68} & 91.85 & \multicolumn{1}{c}{85.27} & \multicolumn{1}{c}{118.67} & 95.85 \\
%  & AG-News & \multicolumn{1}{c}{-} & 0.94 & 0.88 & \multicolumn{1}{c|}{0.93} & - & 86.47 & 74.76 & \multicolumn{1}{c|}{73.2} & - & \multicolumn{1}{c}{103.25} & \multicolumn{1}{c}{188.83} & 97.19 \\
%  & StrategyQA & \multicolumn{1}{c}{0.89} & 0.9 & 0.89 & \multicolumn{1}{c|}{0.9} & 74.04 & 85.2 & 95.43 & \multicolumn{1}{c|}{97.3} & 93.57 & \multicolumn{1}{c}{140.08} & \multicolumn{1}{c}{195.33} & 177.94 \\ \hline
% \end{tabular}
% }
% \caption{Quality results of performing Confidence Elicitation Attacks. Only successful perturbations are considered.}
%   \label{tab:elicitation_attacks_table_quality}
% \end{table}

Because CEAttack's optimization path is more direct compared to SSPAttack as illustrated in Figure \ref{fig:confidence_elicitation_attacks_boundary}, the algorithm doesn't need to explore a large section of the manifold. Instead, by approximating the probabilities, it finds regions of high risk closest to the original input, drastically cutting the number of required queries and optimization time. This efficiency is demonstrated in the columns ``Succ Att Queries Avg" which only records the number of queries for the successful attacks, and ``Total Attack Time" in Table \ref{tab:elicitation_attacks_table_efficency}.


% \begin{table}[h]
% \centering
% \scalebox{0.6}{
% \begin{tabular}{llcccccccccl}
% \hline
% \multicolumn{2}{l}{\multirow{2}{*}{}} & \multicolumn{10}{c}{\textbf{Efficiency Test}} \\ \cline{3-12} 
% \multicolumn{2}{l}{} & \multicolumn{3}{c|}{\textbf{\begin{tabular}[c]{@{}c@{}}All Att \\ Queries \\ Avg ↓\end{tabular}}} & \multicolumn{3}{c|}{\textbf{\begin{tabular}[c]{@{}c@{}}Succ Att\\ Queries \\ Avg ↓\end{tabular}}} & \multicolumn{4}{c}{\textbf{\begin{tabular}[c]{@{}c@{}}Total Attack Time \\ {[}HHH:MM:SS{]} ↓\end{tabular}}} \\ \hline
% Model & Dataset & \textbf{\begin{tabular}[c]{@{}c@{}}Self-Fool \\ Word Sub\end{tabular}} & \textbf{SSPAttack} & \multicolumn{1}{c|}{\textbf{CEAttack}} & \textbf{\begin{tabular}[c]{@{}c@{}}Self-Fool \\ Word Sub\end{tabular}} & \textbf{SSPAttack} & \multicolumn{1}{c|}{\textbf{CEAttack}} & \textbf{\begin{tabular}[c]{@{}c@{}}Self-Fool \\ Word Sub\end{tabular}} & \textbf{SSPAttack} & \multicolumn{2}{c}{\textbf{CEAttack}} \\ \hline
% \multirow{3}{*}{\begin{tabular}[c]{@{}l@{}}LLaMa-3-8B\\ Instruct\end{tabular}} & SST2 & 20.96 & 11.11 & \multicolumn{1}{c|}{21.81} & na & 82.95 & \multicolumn{1}{c|}{25.60} & 001:45:58 & 023:12:58 & \multicolumn{2}{c}{017:30:57} \\
%  & AG-News & 21.66 & 43.46 & \multicolumn{1}{c|}{42.88} & na & 152.85 & \multicolumn{1}{c|}{42.36} & 001:42:01 & 059:46:06 & \multicolumn{2}{c}{024:31:58} \\
%  & StrategyQA & 22.23 & 8.03 & \multicolumn{1}{c|}{8.5} & na & 19.76 & \multicolumn{1}{c|}{10.95} & 000:44:37 & 001:22:34 & \multicolumn{2}{c}{001:25:34} \\ \hline
% \multirow{3}{*}{\begin{tabular}[c]{@{}l@{}}Mistral-7B\\ Instruct-v0.3\end{tabular}} & SST2 & 20.5 & 13.28 & \multicolumn{1}{c|}{23.29} & na & 73.49 & \multicolumn{1}{c|}{24.54} & 001:22:23 & 023:52:30 & \multicolumn{2}{c}{017:13:44} \\
%  & AG-News & - & 34.76 & \multicolumn{1}{c|}{42.84} & - & 158.66 & \multicolumn{1}{c|}{42.66} & - & 045:50:13 & \multicolumn{2}{c}{017:16:52} \\
%  & StrategyQA & 20.86 & 8.74 & \multicolumn{1}{c|}{8.71} & na & 21.32 & \multicolumn{1}{c|}{11.37} & 000:34:41 & 001:38:57 & \multicolumn{2}{c}{001:43:48} \\ \hline
% \end{tabular}
% }
% \caption{Efficiency results of performing Confidence Elicitation Attacks.}
%   \label{tab:elicitation_attacks_table_efficency}
% \end{table}


\begin{table}[h]
\centering
\scalebox{0.55}{ 
\begin{tabular}{llcccccccccccc} 
\hline
\multicolumn{2}{l}{} & \multicolumn{12}{c}{\textbf{Efficiency Test}} \\ \cline{3-14} 
\multicolumn{2}{l}{\multirow{-2}{*}{}} & \multicolumn{4}{c|}{\textbf{\begin{tabular}[c]{@{}c@{}}All Att \\ Queries \\ Avg ↓\end{tabular}}} & \multicolumn{4}{c|}{\textbf{\begin{tabular}[c]{@{}c@{}}Succ Att\\ Queries \\ Avg ↓\end{tabular}}} & \multicolumn{4}{c}{\textbf{\begin{tabular}[c]{@{}c@{}}Total Attack Time \\ {[}HHH:MM:SS{]} ↓\end{tabular}}} \\ \hline
Model & Dataset & \multicolumn{1}{c}{\textbf{\begin{tabular}[c]{@{}c@{}}Self-Fool \\ Word Sub\end{tabular}}} & \textbf{\begin{tabular}[c]{@{}c@{}}Text\\ Hoaxer\end{tabular}} & \textbf{\begin{tabular}[c]{@{}c@{}}SSP\\ Attack\end{tabular}} & \multicolumn{1}{c|}{\textbf{\begin{tabular}[c]{@{}c@{}}CE\\ Attack\end{tabular}}} & \textbf{\begin{tabular}[c]{@{}c@{}}Self-Fool \\ Word Sub\end{tabular}} & \textbf{\begin{tabular}[c]{@{}c@{}}Text\\ Hoaxer\end{tabular}} & \textbf{\begin{tabular}[c]{@{}c@{}}SSP\\ Attack\end{tabular}} & \multicolumn{1}{c|}{\textbf{\begin{tabular}[c]{@{}c@{}}CE\\ Attack\end{tabular}}} & \textbf{\begin{tabular}[c]{@{}c@{}}Self-Fool \\ Word Sub\end{tabular}} & \multicolumn{1}{c}{\textbf{\begin{tabular}[c]{@{}c@{}}Text\\ Hoaxer\end{tabular}}} & \multicolumn{1}{c}{\textbf{\begin{tabular}[c]{@{}c@{}}SSP\\ Attack\end{tabular}}} & \textbf{\begin{tabular}[c]{@{}c@{}}CE\\ Attack\end{tabular}} \\ \hline
 & SST2 & \multicolumn{1}{c}{20.96} & 24.97 & 11.11 & \multicolumn{1}{c|}{21.81} & na & 171.31 & 82.95 & \multicolumn{1}{c|}{\textbf{25.60}} & 001:45:58 & \multicolumn{1}{c}{006:28:54} & \multicolumn{1}{c}{023:12:58} & 017:30:57 \\
 & AG-News & \multicolumn{1}{c}{21.66} & 24.18 & 43.46 & \multicolumn{1}{c|}{42.88} & na & 100.49 & 152.85 & \multicolumn{1}{c|}{\textbf{42.36}} & 001:42:01 & \multicolumn{1}{c}{004:33:43} & \multicolumn{1}{c}{059:46:06} & 024:31:58 \\
\multirow{-3}{*}{\begin{tabular}[c]{@{}l@{}}LLaMa-3-8B\\ Instruct\end{tabular}} & StrategyQA & \multicolumn{1}{c}{22.23} & 19.24 & 8.03 & \multicolumn{1}{c|}{8.5} & na & 51.71 & 19.76 & \multicolumn{1}{c|}{\textbf{10.95}} & 000:44:37 & \multicolumn{1}{c}{000:49:09} & \multicolumn{1}{c}{001:22:34} & 001:25:34 \\ \hline
 & SST2 & \multicolumn{1}{c}{20.5} & 38.88 & 13.28 & \multicolumn{1}{c|}{23.29} & na & 183.6 & 73.49 & \multicolumn{1}{c|}{\textbf{24.54}} & 001:22:23 & \multicolumn{1}{c}{007:03:41} & \multicolumn{1}{c}{023:52:30} & 017:13:44 \\
 & AG-News & \multicolumn{1}{c}{-} & 23.96 & 34.76 & \multicolumn{1}{c|}{42.84} & - & 76.71 & 158.66 & \multicolumn{1}{c|}{\textbf{42.66}} & \textbf{-} & \multicolumn{1}{c}{003:43:41} & \multicolumn{1}{c}{045:50:13} & 017:16:52 \\
\multirow{-3}{*}{\begin{tabular}[c]{@{}l@{}}Mistral-7B\\ Instruct-v0.3\end{tabular}} & StrategyQA & \multicolumn{1}{c}{20.86} & 16.66 & 8.74 & \multicolumn{1}{c|}{8.71} & na & 45.71 & 21.32 & \multicolumn{1}{c|}{\textbf{11.37}} & 000:34:41 & \multicolumn{1}{c}{000:55:14} & \multicolumn{1}{c}{001:38:57} & 001:43:48 \\ \hline


\end{tabular}
}
\caption{Efficiency results of performing Confidence Elicitation Attacks.}
  \label{tab:elicitation_attacks_table_efficency}
\end{table}


% \begin{table}[h]
% \centering
% \scalebox{0.55}{
% \color{blue} 
% \begin{tabular}{llcccccccccccc} 
% \hline
% \multicolumn{2}{l}{\multirow{2}{*}{}} & \multicolumn{12}{c}{\textbf{Efficiency Test}} \\ \cline{3-14} 
% \multicolumn{2}{l}{} & \multicolumn{4}{c|}{\textbf{\begin{tabular}[c]{@{}c@{}}All Att \\ Queries \\ Avg ↓\end{tabular}}} & \multicolumn{4}{c|}{\textbf{\begin{tabular}[c]{@{}c@{}}Succ Att\\ Queries \\ Avg ↓\end{tabular}}} & \multicolumn{4}{c}{\textbf{\begin{tabular}[c]{@{}c@{}}Total Attack Time \\ {[}HHH:MM:SS{]} ↓\end{tabular}}} \\ \hline
% Model & Dataset & \multicolumn{1}{c}{\textbf{\begin{tabular}[c]{@{}c@{}}Self-Fool \\ Word Sub\end{tabular}}} & \textbf{\begin{tabular}[c]{@{}c@{}}Text\\ Hoaxer\end{tabular}} & \textbf{\begin{tabular}[c]{@{}c@{}}SSP\\ Attack\end{tabular}} & \multicolumn{1}{c|}{\textbf{\begin{tabular}[c]{@{}c@{}}CE\\ Attack\end{tabular}}} & \textbf{\begin{tabular}[c]{@{}c@{}}Self-Fool \\ Word Sub\end{tabular}} & \textbf{\begin{tabular}[c]{@{}c@{}}Text\\ Hoaxer\end{tabular}} & \textbf{\begin{tabular}[c]{@{}c@{}}SSP\\ Attack\end{tabular}} & \multicolumn{1}{c|}{\textbf{\begin{tabular}[c]{@{}c@{}}CE\\ Attack\end{tabular}}} & \textbf{\begin{tabular}[c]{@{}c@{}}Self-Fool \\ Word Sub\end{tabular}} & \multicolumn{1}{c}{\textbf{\begin{tabular}[c]{@{}c@{}}Text\\ Hoaxer\end{tabular}}} & \multicolumn{1}{c}{\textbf{\begin{tabular}[c]{@{}c@{}}SSP\\ Attack\end{tabular}}} & \textbf{\begin{tabular}[c]{@{}c@{}}CE\\ Attack\end{tabular}} \\ \hline
% \multirow{3}{*}{\begin{tabular}[c]{@{}l@{}}LLaMa-3-8B\\ Instruct\end{tabular}} & SST2 & \multicolumn{1}{c}{20.96} & 24.97 & 11.11 & \multicolumn{1}{c|}{21.81} & na & 171.31 & 82.95 & \multicolumn{1}{c|}{25.60} & 001:45:58 & \multicolumn{1}{c}{006:28:54} & \multicolumn{1}{c}{023:12:58} & 017:30:57 \\
%  & AG-News & \multicolumn{1}{c}{21.66} & 24.18 & 43.46 & \multicolumn{1}{c|}{42.88} & na & 100.49 & 152.85 & \multicolumn{1}{c|}{42.36} & 001:42:01 & \multicolumn{1}{c}{004:33:43} & \multicolumn{1}{c}{059:46:06} & 024:31:58 \\
%  & StrategyQA & \multicolumn{1}{c}{22.23} & 19.24 & 8.03 & \multicolumn{1}{c|}{8.5} & na & 51.71 & 19.76 & \multicolumn{1}{c|}{10.95} & 000:44:37 & \multicolumn{1}{c}{000:49:09} & \multicolumn{1}{c}{001:22:34} & 001:25:34 \\ \hline
% \multirow{3}{*}{\begin{tabular}[c]{@{}l@{}}Mistral-7B\\ Instruct-v0.3\end{tabular}} & SST2 & \multicolumn{1}{c}{20.5} & 38.88 & 13.28 & \multicolumn{1}{c|}{23.29} & na & 183.6 & 73.49 & \multicolumn{1}{c|}{24.54} & 001:22:23 & \multicolumn{1}{c}{007:03:41} & \multicolumn{1}{c}{023:52:30} & 017:13:44 \\
%  & AG-News & \multicolumn{1}{c}{-} & 23.96 & 34.76 & \multicolumn{1}{c|}{42.84} & - & 76.71 & 158.66 & \multicolumn{1}{c|}{42.66} & - & \multicolumn{1}{c}{003:43:41} & \multicolumn{1}{c}{045:50:13} & 017:16:52 \\
%  & StrategyQA & \multicolumn{1}{c}{20.86} & 16.66 & 8.74 & \multicolumn{1}{c|}{8.71} & na & 45.71 & 21.32 & \multicolumn{1}{c|}{11.37} & 000:34:41 & \multicolumn{1}{c}{000:55:14} & \multicolumn{1}{c}{001:38:57} & 001:43:48 \\ \hline
% \end{tabular}
% }
% \caption{Efficiency results of performing Confidence Elicitation Attacks.}
%   \label{tab:elicitation_attacks_table_efficency}
% \end{table}

All figures in \ref{fig:ablation_on_w_and_s} present ablations for the maximum number of possible word substitutions per sample $|W|$ and the number of possible synonym embeddings per word $|S|$. The results indicate that as both parameters increase, the attack success rate also increases, provided there are enough words to perturb. The trend varies across datasets due to differences in the average number of words per example. In our evaluation, AG-News has the longest examples, resulting in the scaling of $|W|$ and $|S|$ having the most significant impact.

\begin{figure}[t]
\centering
\includegraphics[width=0.24\linewidth]{Pictures/ablation_plots/ablation_ceattack_plot_w_asr.pdf}
\includegraphics[width=0.24\linewidth]{Pictures/ablation_plots/ablation_ceattack_plot_w_aua.pdf}
  \includegraphics[width=0.24\linewidth]{Pictures/ablation_plots/ablation_ceattack_plot_w_succ_att_queries_avg.pdf}
  \includegraphics[width=0.24\linewidth]{Pictures/ablation_plots/ablation_ceattack_plot_w_total_attack_time.pdf}
   \includegraphics[width=0.24\linewidth]{Pictures/ablation_plots/ablation_ceattack_plot_s_asr.pdf}
  \includegraphics[width=0.24\linewidth]{Pictures/ablation_plots/ablation_ceattack_plot_s_aua.pdf} 
  \includegraphics[width=0.24\linewidth]{Pictures/ablation_plots/ablation_ceattack_plot_s_succ_att_queries_avg.pdf} 
  \includegraphics[width=0.24\linewidth]{Pictures/ablation_plots/ablation_ceattack_plot_s_total_attack_time.pdf}
  \caption{Ablation study on $|W|$ and $|S|$}
  % \caption{Ablation study on maximum number of possible word substitutions $|W|$ and number of potential word synonym substitutions per word $|S|$}
  \label{fig:ablation_on_w_and_s}
\end{figure}

 


 

% \subsection{Qualitative examples}
 

% Word substitutions using Counter-fitted embeddings are already constrained in terms of semantics due to the pre-built nature of the dictionary. This ensures that each word can only be replaced with a previously vetted synonym. Compared to ``Self-Fool Word Sub" and SSPAttack our method more effectively preserves the original meaning of the text, as evidenced by the high ``SemSim" in Table \ref{tab:elicitation_attacks_table_quality}. Table \ref{tab:qualitative_samples} provides multiple examples from SST2 that have been perturbed by our proposed technique, CEAttack demonstrating conversions of examples from Positive to Negative and from Negative to Positive sentiment. Additional examples for AG-News and StrategyQA can be found in Table \ref{appendix:tab:qualitative_samples_ag_news} and Table \ref{appendix:tab:qualitative_samples_strategyQA} in Appendix \ref{appendix:more_qualitative_examples}.


% \begin{table}[ht]
% \centering
% \scalebox{0.50}{
% \begin{tabular}{llcccccccccccccl}

% \hline
% \multicolumn{12}{l}{\textbf{\begin{tabular}[c]{@{}l@{}}Qualitative Example\\ SST2 (Sentiment Classification)\end{tabular}}} \\ \hline
% \textbf{Technique} & \multicolumn{5}{l}{\textbf{Sample}} & \textbf{SemSim} & \textbf{Perplexity} & \textbf{\begin{tabular}[c]{@{}c@{}}Perturbed \\ Words\end{tabular}} & \textbf{\begin{tabular}[c]{@{}c@{}}Ground \\ Truth\end{tabular}} & \textbf{Prediction} & \multicolumn{1}{c}{\textbf{\begin{tabular}[c]{@{}c@{}}Empirical\\ Mean (Score)\end{tabular}}} \\ \hline
% Original & \multicolumn{5}{l}{\begin{tabular}[c]{@{}l@{}}there is nothing outstanding about this film, but it is good \\ enough and will likely be appreciated most by sailors and \\ folks who know their way around a submarine.\end{tabular}} & - & 48.59 & - & Positive & Positive & \multicolumn{1}{c}{0.48} \\
% \begin{tabular}[c]{@{}l@{}}CEAttack\\ (Ours)\end{tabular} & \multicolumn{5}{l}{\begin{tabular}[c]{@{}l@{}}there is nothing outstanding about this film, but it is \\ \textbf{appropriate} enough and will likely be appreciated most by\\  sailors and \textbf{males} who know their \textbf{routes} around a submarine.\end{tabular}} & 0.85 & 114.7 & 3 & Positive & Negative & \multicolumn{1}{c}{0.90} \\ \hline
% Original & \multicolumn{5}{l}{\begin{tabular}[c]{@{}l@{}}the movie achieves as great an impact by keeping these \\ thoughts hidden as ... (quills) did by showing them.\end{tabular}} & - & 407.19 & - & Positive & Positive & \multicolumn{1}{c}{0.40} \\
% \begin{tabular}[c]{@{}l@{}}CEAttack\\ (Ours)\end{tabular} & \multicolumn{5}{l}{\begin{tabular}[c]{@{}l@{}}the \textbf{filmmakers} \textbf{obtains} as \textbf{formidable} an impact by keeping \\ these thoughts hidden as ... (\textbf{plume}) did by showing them.\end{tabular}} & 0.84 & 616.55 & 4 & Positive & Negative & \multicolumn{1}{c}{0.50} \\ \hline
% Original & \multicolumn{5}{l}{\begin{tabular}[c]{@{}l@{}}combining quick-cut editing and a blaring heavy metal much\\ of the time, beck seems to be under the illusion that he's \\ shooting the latest system of a down video.\end{tabular}} & - & 328.26 & - & Negative & Negative & \multicolumn{1}{c}{0.26} \\
% \begin{tabular}[c]{@{}l@{}}CEAttack\\ (Ours)\end{tabular} & \multicolumn{5}{l}{\begin{tabular}[c]{@{}l@{}}\textbf{mixing} quick-cut editing and a \textbf{thundering} heavy metal much \\ of the \textbf{periods}, beck \textbf{appear} to \textbf{get} under the \textbf{trickery} that he's\\  shooting the latest system of a down video.\end{tabular}} & 0.84 & 571.93 & 6 & Negative & Positive & \multicolumn{1}{c}{0.75} \\ \hline
% Original & \multicolumn{5}{l}{\begin{tabular}[c]{@{}l@{}}schaeffer has to find some hook on which to hang his \\ persistently useless movies, and it might as well be the \\ resuscitation of the middle-aged character.\end{tabular}} & - & 95.63 & - & Negative & Negative & \multicolumn{1}{c}{0.39} \\
% \begin{tabular}[c]{@{}l@{}}CEAttack\\ (Ours)\end{tabular} & \multicolumn{5}{l}{\begin{tabular}[c]{@{}l@{}}\textbf{colson} has to find some hook on which to hang his persistently \\ \textbf{incongruous film}, and it \textbf{may} as \textbf{alright} \textbf{get} the resuscitation of \\ the middle-aged character.\end{tabular}} & 0.84 & 157.87 & 6 & Negative & Positive & \multicolumn{1}{c}{0.65} \\ \hline

% \end{tabular}
% }
% \caption{Confidence elicitation attacks and their confidence levels. Perturbed words are in \textbf{bold}.}
% \label{tab:qualitative_samples}
% \end{table}
 
\section{Analysing attack pathing}
\vspace{-0em} % Adjust this value as needed

Our attack framework, when compared to previous work on adversarial attacks on LLMs, allows us to track how perturbations affect the model's output state. Despite being approximate, it provides valuable insights. In the experiment illustrated in Table \ref{tab:example_analysis} and Figure \ref{fig:dirichlet_distribution_example}, we allow the search algorithm to perturb a sample beyond the boundary. Table \ref{tab:example_analysis} highlights an example where the prediction sentiment shifts from positive to negative after just two word substitutions. As the sample undergoes word substitutions, the probability of the wrong class increases, yet it retains its positive label over five different substitutions. As words are substituted, the empirical mean from the Dirichlet distribution moves from the positive region (top-left plot) to the most negative region (bottom-right plot) in Figure \ref{fig:dirichlet_distribution_example}. The final sample is approximately 97\% correlated with being negative. This approximate information would not be available in a hard label attack scenario, making it difficult to detect the confidence level of the new adversarial example. We observe this behavior across multiple examples.



% Our attack framework, when compared to previous work on adversarial attacks on LLMs, allows us to track how perturbations affect the model's output state. Despite being approximate, it provides valuable insights. In the experiment illustrated in Figure \ref{tab:example_analysis} and Figure \ref{fig:dirichlet_distribution_example}, we allow the search algorithm to perturb a sample beyond the boundary. Figure \ref{tab:example_analysis} highlights an example where the prediction sentiment shifts from positive to negative after just two word substitutions. As the sample undergoes word substitutions, the probability of the wrong class increases, yet it retains its positive label over five different substitutions. As words are substituted, the empirical mean from the Dirichlet distribution moves from the positive region (top-left plot) to the most negative region (bottom-right plot) in Figure \ref{fig:dirichlet_distribution_example}. The final sample is approximately 97\% correlated with being negative. This approximate information would not be available in a hard label attack scenario, making it difficult to detect the confidence level of the new adversarial example. We observe this behavior across multiple examples.

 
 

\begin{table}[ht]
\centering
\scalebox{0.60}{
\begin{tabular}{llcccccccccccccl}
\hline
\multicolumn{12}{l}{\textbf{\begin{tabular}[c]{@{}l@{}}Example Analysis\\ SST2 (Sentiment Classification) LLaMa-3-8B-Instruct\end{tabular}}} \\ \hline
\textbf{Technique} & \multicolumn{8}{l}{\textbf{Sample}} & \textbf{\begin{tabular}[c]{@{}c@{}}Perturbed \\ Words\end{tabular}} & \textbf{Prediction} & \multicolumn{1}{c}{\textbf{\begin{tabular}[c]{@{}c@{}}Empirical\\ Mean (Score)\end{tabular}}} \\ \hline
Original & \multicolumn{8}{l}{\begin{tabular}[c]{@{}l@{}}although laced with humor and a few fanciful touches,\\ the film is a refreshingly serious look at young women.\end{tabular}} & 0 & Positive & \multicolumn{1}{c}{0.13} \\ \hline
\multirow{5}{*}{\begin{tabular}[c]{@{}l@{}}CEAttack\\ (Ours)\end{tabular}} & \multicolumn{8}{l}{\begin{tabular}[c]{@{}l@{}}although laced with humor and a few fanciful touches, \\ the film is a \textbf{blithely} serious look at young women.\end{tabular}} & 1 & Positive & \multicolumn{1}{c}{0.33} \\ \cdashline{2-16}[1pt/1pt]
 & \multicolumn{8}{l}{\begin{tabular}[c]{@{}l@{}}although laced with humor and a few fanciful touches, \\ the film is a \textbf{blithely} serious \textbf{heed} at young women.\end{tabular}} & 2 & Negative & \multicolumn{1}{c}{0.78} \\ \cdashline{2-16}[1pt/1pt]
 & \multicolumn{8}{l}{\begin{tabular}[c]{@{}l@{}}although laced with humor and a few \textbf{awesome} touches, \\ the film is a \textbf{blithely} serious \textbf{heed} at young women.\end{tabular}} & 3 & Negative & \multicolumn{1}{c}{0.94} \\ \cdashline{2-16}[1pt/1pt]
 & \multicolumn{8}{l}{\begin{tabular}[c]{@{}l@{}}although laced with \textbf{fun} and a few \textbf{awesome} touches, \\ the film is a \textbf{blithely} serious \textbf{heed} at young women.\end{tabular}} & 4 & Negative & \multicolumn{1}{c}{0.97} \\ \cdashline{2-16}[1pt/1pt]
 & \multicolumn{8}{l}{\begin{tabular}[c]{@{}l@{}}although laced with \textbf{fun} and a few \textbf{awesome} touches, \\ the film is a \textbf{blithely} \textbf{deeply} \textbf{heed} at young women.\end{tabular}} & 5 & Negative & \multicolumn{1}{c}{0.97} \\ \hline

\end{tabular}
}
\caption{Example of a sample being progressively perturbed, the Dirichlet distributions of this process in Figure \ref{fig:dirichlet_distribution_example}. Perturbed words are in \textbf{bold}.}
% \caption{Example of a sample that is perturbed with word perturbations progressively changing it's sentiment from Positive to Negative while preserving most of the positive sentiment meaning. We also show the Dirichlet distributions of this process in Figure \ref{fig:dirichlet_distribution_example}. Perturbed words are in \textbf{bold}.}
  \label{tab:example_analysis}
\end{table}

\begin{figure}[t]
\centering
  \includegraphics[width=0.25\linewidth]{Pictures/dirichlet_distribution/dirichlet_cs4_is1_a__9.0,65.0,1.0___n1000.pdf}
  \includegraphics[width=0.25\linewidth]{Pictures/dirichlet_distribution/dirichlet_cs4_is17_a__15.0,40.0,5.0___n1000.pdf}
  \includegraphics[width=0.25\linewidth]{Pictures/dirichlet_distribution/dirichlet_cs4_is99_a__61.0,17.0,1.0___n1000.pdf}
   \includegraphics[width=0.25\linewidth]{Pictures/dirichlet_distribution/dirichlet_cs4_is178_a__96.0,6.0,1.0___n1000.pdf}  
  \includegraphics[width=0.25\linewidth]{Pictures/dirichlet_distribution/dirichlet_cs4_is224_a__77.0,2.0,1.0___n1000.pdf} 
  \includegraphics[width=0.25\linewidth]{Pictures/dirichlet_distribution/dirichlet_cs4_is225_a__77.0,2.0,1.0___n1000.pdf}
  % \caption{Ternary plots highlighting the attack path over the Dirichlet distribution for the example in Table \ref{tab:example_analysis}.}
  \caption{Ternary plots highlighting the attack path for the example in Table \ref{tab:example_analysis}. As the algorithm adds adversarial word substitutions the model's predictions and associated confidences to such predictions change leading to a different Dirichlet distribution profile}
  \label{fig:dirichlet_distribution_example}
\end{figure}



% \section{Conclusion}
% We demonstrate that elicited confidence can serve as a feedback mechanism for identifying input perturbations. This feedback enables us to craft stronger adversarial samples. We believe this mechanism is agnostic to the type of input perturbation, the search algorithm, and the quantitative or qualitative $\epsilon$ bounds. Our word substitution attack can be tracked across substitution steps to observe how confidence diminishes and eventually alters the prediction. We achieve all of this within a fully black-box threat model while point out for the first time that confidence elicitiation may be at odds with robustness. We hope that our attack, attack evaluation, and open-source code can assist researchers in identifying sample perturbations, exploring their model's confidence elicitation behavior, and, more broadly, advancing adversarial robustness research.
\section{Conclusion}
\vspace{-0em} % Adjust this value as needed
In this work, we demonstrated that elicited confidence can serve as a feedback mechanism for identifying input perturbations. This feedback enables us to craft stronger adversarial samples. We believe this mechanism is agnostic to the type of input perturbation, the search algorithm, and the quantitative or qualitative bounds of $\epsilon$. Our word substitution attack can be tracked through substitution steps to observe how confidence diminishes and eventually alters the prediction. We achieve all of this within a fully black-box threat model, and for the first time, point out that confidence elicitation may be at odds with robustness. Our results suggest the potential for confidence elicitation to enhance jailbreaks. For example, it may enable current multi-turn dialog jailbreaks \citep{PAIR,TAP} to query the probability of the model's answers and use this information as feedback. Another promising direction is to investigate the susceptibility of token-wise confidence elicitation to input perturbations, and whether it is possible to control or influence the model's token selection process. Additionally, it is worth exploring how effective confidence elicitation attacks are on generative tasks such as free-form question answering \citep{TriviaQA}, and reasoning \citep{Reasoning_Robustness,LLM_Code_Reasoning, Multi-Hop-Attacks, StopReasoning} given that confidence elicitation has also proven to be a reliable and calibrated measure of uncertainty in generative tasks \citep{Generative_Confidence_Elicitation,Generative_Confidence_Elicitation_Gemma}. We hope that our attack, evaluation, insights, and open-source code can assist researchers in identifying sample perturbations, exploring their model's confidence elicitation behavior, and, more broadly, advancing adversarial robustness research.

\clearpage




% \section{Limitations}
% - only focus on word substitutions
% - only focus on a simple greedy seach
% -only focus on vanilla zero shot inference
% -no trasferibility
% -alternative bounds
% \section{Future Work}
% Question1) as we scale the number of datasets/tasks and models can we identify trends between attack success rate and expected calibration error, essentially, as a model becomes more calibrated, perhaps due to emergent abilities through scale, does it become easyer to attack in a fully black box threat model? if so, what implication does this have in theoretical ai safety.
% insight2) pointing out that with temperature 0.7 the performance is better, however, upon closer investgation this may be due to the inherit randomness of the model, making the greedy search attack algorithm belive a sample is adversarial when naturally it is not, since at times doing inference multiple times with the same sample leads to different classifications. In the future, it will be necessary to account of epistemic and aleatoric uncertenty during the attack and peraphs using a margin to decide whether the attack is successful or not so that the randomness of the model is taken into account
% inishgt2.2) this can be seen in figure2 with the last word substitution, we accept this substitution but don't need it since the score dosn't change by much, however, its accepted because the score is higher non the less.

% \subsubsection*{Acknowledgments}
% Use unnumbered third level headings for the acknowledgments. All
% acknowledgments, including those to funding agencies, go at the end of the paper.


\bibliography{iclr2025_conference}
\bibliographystyle{iclr2025_conference}

\appendix
% \section{Appendix}

\section{Ethics Statement}
This research was conducted in accordance with the ACM Code of Ethics. Although our technique may be used to bypass refusal mechanisms, we propose in the discussion section various ways to defend against this.


\section{Future work}
\subsection{Defense Discussion}

The main challenge with defending against this issue arises from an active push within the community to make confidence elicitation an integral part of LLMs' behavior. We believe this is an interesting emergent behavior and do not think the community should halt these efforts. Therefore, simply blocking models from performing confidence elicitation or impairing their ability by adding noise or deliberately making them uncalibrated may not be a viable option \citep{Extreme_Miscalibration}. Ultimately, we concluded that confidence elicitation may be at odds with robustness. However, we have identified two potential directions that the community may find worth exploring:

\subsubsection{Adversarial Training / Adversarial Data Augmentation}

Can the generated adversarial inputs be reintroduced into the training process? This opens up opportunities for confidence elicitation adversarial training, aiming to both enhance robustness against input perturbation and potentially improve calibration. This would adhere to the traditional adversarial training min-max formulation \citep{Robust_Feature_AdvTraining,Efficiant_LLM_AdvTraining,AdvLoRA,SemRoDe}. 

As we incorporate perturbations into the input that alter predictions during instruction fine-tuning, we can loop these samples back into the training process, following a black-box adversarial setup. Adversarial training could potentially be done in a white-box setting by perturbing the input embeddings then checking how the confidence elicitation behavior changes.

Alternatively, a simpler solution involves generating the data first and then using it for further fine-tuning (adversarial augmentation).

\subsubsection{Defense by Intent}

In this case, we aim to protect the system by analyzing the use cases of confidence elicitation with a rule-based defense approach.
\begin{itemize}
    \item Is the user performing the same query multiple times with small semantic similarities between queries, likely adding minor input perturbations?
    \item Is the user explicitly asking for confidence elicitation? This could be implemented as a classifier; if yes, it indicates a desire for confidence elicitation.
    \item Are confidence elicitation values on some tokens decreasing over time? This could suggest some form of optimization in progress.
\end{itemize}


\subsection{Applications of confidence elicitation attacks}
% - adversarial attacks in a classification setting
As briefly introduced in the paper, we target classification settings where either confidence is provided as a main component of the system as feedback or where the attacker can perform confidence elicitation in a free-form generation setting. Exploring this approach using actual medical datasets would be an interesting direction.

Although chatbot jailbreaks can fundamentally differ from adversarial attacks, there are precedents where adversarial techniques have been employed to craft jailbreaks. For example, variants of the HotFlip \citep{Hotflip} adversarial attack and AutoPrompt \citep{AutoPrompt} were utilized to develop the first automatic jailbreak \citep{LLM_Attack_1}. This was achieved by projecting gradients over a vocabulary to select optimal token substitutions for a suffix or by simply adding left-side noise to the prompt \citep{FlipAttack}. Similarly, confidence elicitation could be an interesting concept to enhance chatbot jailbreaks. For instance, it might enable prompt-level multi-turn dialog attacks, such as PAIR \citep{PAIR} and Tree of Attacks \citep{TAP}, to query the probability of the model's answers during a multi-turn dialog and use this information as feedback. A similar approach could be explored for adversarial misalignment \citep{Adversarially_Aligned}.




% - white box for model interprebility, 
% - jailbreaks
% - adversarial alignment


\section{Prompts}\label{appendix:prompt}
Table \ref{appendix:tab:2Sprompt} shows the prompt we use to first perform a prediction on $x$=`text' and then elicit confidence. This prompt is a combination of methods from \citep{Epistetic_Uncertenty}, where verbal confidence is utilized, and \citep{Just_Ask_For_Calibration}, where a two-shot approach is used for confidence elicitation.

 \begin{table}[]
 \centering
\scalebox{0.68}{
\begin{tabular}{llcccccccccccccc}
\hline
\multicolumn{12}{l}{\textbf{Verbal Elicitation Verb. 2S k guesses prompt example}} \\ \hline
\textbf{Prediction Prompt} & \multicolumn{11}{l}{\begin{tabular}[c]{@{}l@{}}f"""\{self.start\_prompt\_header\}\\ Provide your k best guess for the following text (positive, negative). \\ Give ONLY the guesses, no other words or explanation. \\ For example: \\ Guesses: (most likely guesses, either positive or negative; not a complete sentence, just the guesses!\\ Separated by a comma, for example {[}Negative, Positive, Positive, Negative ... xk{]}) \\ The text is:\$\{text\} \\ Guesses:\\ \{self.end\_prompt\_footer\}"""\end{tabular}} \\ \hline
\textbf{\begin{tabular}[c]{@{}l@{}}Confidence Elicitation \\ Prompt\end{tabular}} & \multicolumn{11}{l}{\begin{tabular}[c]{@{}l@{}}f"""\{self.start\_prompt\_header\}\\ You're a model that needs to give the confidence of answers being correct. \\ The previous prompt was: \\ Provide your k best guesses for the following text (positive, negative). \\ Give ONLY the guesses, no other words or explanation.\\ For example: \\ Guesses: (most likely guess, either positive or negative; not a complete sentence, just the guesses!) \\ The text is:\{text\} the guesses were: \{guesses\_output\}, \\ given these guesses provide the verbal confidences that your guesses are correct. \\ Give ONLY the verbal confidences, no other words or explanation. \\ For example: \\ Confidences: (the confidences, from either (Highest, High, Medium, Low, Lowest) that your guesses are correct, \\ without any extra commentary whatsoever, for example {[}Highest, High, Medium, Low, Lowest ...{]}; \\ just the confidence! Separated by a coma \\ Confidences:\\ \{self.end\_prompt\_footer\}"""\end{tabular}} \\ \hline
 



\end{tabular}
}
\caption{An example of the Verb. 2S top-1 prompting technique is as follows: The first prompt generates an answer, $\hat{y}$, through the model $f_{\theta}$. This answer is then passed to the Confidence Elicitation Prompt as the variable `guess\_result'. Next, the second prompt is passed through $f_{\theta}$ to generate the verbal confidence, $\mathbf{p}_{\mathcal{C}}$. The variable `text' is the sample under analysis, while the `start\_prompt\_header' and `end\_prompt\_footer' are model's formatting tokens }
  \label{appendix:tab:2Sprompt}
\end{table}

\section{Further Implementation Details}
 
We use 12 Nvidia A40 GPUs for our testing, every test can be conducted on only 1 A40GPU. For our tests we perturb 500 samples on 1 A40 GPU with 46GB of memory. %All our artifacts are released under a open source MIT license 

\section{Experimental Setup Details}\label{appendix:experimental_setup_details}

\subsection{Datasets, tasks and models}
We conducted our confidence elicitation attacks on Meta-Llama-3-8B-Instruct \citep{LLama} and Mistral-7B-Instruct-v0.2 \citep{Mistral} while performing classification on two common datasets to evaluate adversarial robustness: \textit{SST-2}, \textit{AG-News} and one modern dataset: \textit{StrategyQA} \citep{StrategyQA}.

\subsection{Evaluation metrics}
We utilize the evaluation framework previously proposed in \citep{TextAttack}, where an evaluation set is perturbed, and we record the following data from the Total Attacked Samples ($TAS$) set: Number of Successful Attacks ($N_{succ-atk}$), Number of Failed Attacks ($N_{fail-atk}$), and Number of Skipped Attacks ($N_{skp-atk}$). We utilize these values to record the following metrics. \textit{Clean accuracy/Base accuracy/Original accuracy}, which offers a measure of the model's performance during normal inference. \textit{After attack accuracy/Accuracy under attack} ($A_{aft-atk}=\frac{N_{fail-atk}}{TAS}$) or (AUA), is critical, representing how effectively the attacker deceives the model across the dataset. Similarly, the \textit{After success rate} ($A_{succ-rte}=\frac{N_{succ-atk}}{TAS-N_{skp-atk}}$) or (ASR) excludes previously misclassified samples. The paper also considers the \textit{Semantic similarity/SemSim}, an automatic similarity index, as modeled by $d_\epsilon$ \citep{Universalsentenceencoder}. We compare the original perplexity with the new perturbed sample's perplexity, calculated using a GPT-2 model. A higher perplexity indicates that the example is less natural and fluent to the language model. \textit{Queries} denotes the number of model calls for inference. We subdivide this metric into two categories: \textit{All Att Queries Avg} and \textit{Succ Att Queries Avg}. The latter records the queries for successful attacks only, while the former includes all queries. Additionally, we track the duration of the attack process to perturb all the samples under \textit{Total Attack Time}.


\subsection{Evaluation baselines}
We compare our guided word substitution attacks, CEAttack to ``Self-Fool Word Sub" from \citep{LLM_Fool_Itself}, SSPAttack from \citep{sspattack} and TextHoaxer from \citep{TextHoaxer}. The``Self-Fool Word Sub" method operates by instructing the LLM model to substitute words with synonyms while maintaining semantic integrity. We execute a query to generate $x_{adv}$, extract $x_{adv}$ from the generated string, and perform another call to the model to achieve the misclassification, if no misclassification is found, we repeat the process twenty times. On the other hand, the SSPAttack algorithm initially heavily perturbs the original sample with multiple synonym word substitutions to induce misclassification. Subsequently, they optimize the sample for quality by first reverting as many perturbed words to their original form as possible, and then by substituting words with synonyms that enhance semantic similarity. This optimization process is conducted using the hard-label as feedback. In a manner similar to SSPAttack, TextHoaxer initially introduces significant perturbations to the input $x$ to formulate an adversarial candidate. It then utilizes resources like Counter-Fitted word embeddings \citep{Counter_Fitted_Embeddings} to extract the word embeddings of both the original $x$ and the adversarial version $x_{adv}$. From these embeddings, a perturbation matrix is constructed. TextHoaxer constructs a loss function that is optimized over this perturbation matrix. The optimization aims to enhance semantic similarity while adhering to two constraints: a pairwise perturbation constraint to maintain semantic closeness of word substitutions, and a sparsity constraint to control the extent of word replacements, ensuring minimal yet effective perturbations.

\subsection{Expected Calibration Error (ECE)}\label{appendix:ece}

% Expected Calibration Error is a metric used to evaluate how well a model's confidence estimates align with the actual probabilities of outcomes being correct. For example, it assesses how accurately a model's predicted confidence (e.g., 'I'm 80\% sure this is correct') reflects reality. This evaluation is averaged across 500 examples. 
%A thorough explanation is now provided in Appendix \ref{appendix:ece}.

The ECE is calculated using the formula:

\begin{align*}
\text{ECE} = \sum_{m=1}^{M} \frac{|B_m|}{n} \cdot \left| \text{acc}(B_m) - \text{conf}(B_m) \right|
\end{align*}

In this formula, \( n \) represents the total number of samples, and \( M \) is the total number of bins used to partition the predicted confidence scores. The term \( B_m \) denotes the set of indices of samples whose predicted confidence falls into the \( m \)-th bin, and \( |B_m| \) is the number of samples in this bin. The accuracy within each bin, \( \text{acc}(B_m) \), is calculated as the proportion of correctly predicted samples, given by the equation \( \text{acc}(B_m) = \frac{1}{|B_m|} \sum_{i \in B_m} \mathbf{1}(\hat{y}_i = y_i) \), where \( \hat{y}_i \) is the predicted class label and \( y_i \) is the true class label for sample \( i \). The confidence of the predictions in the \( m \)-th bin, \( \text{conf}(B_m) \), is the average of the predicted confidence scores for the samples in the bin, calculated as \( \text{conf}(B_m) = \frac{1}{|B_m|} \sum_{i \in B_m} \hat{p}_i \), where \( \hat{p}_i \) is the predicted probability for the predicted class of sample \( i \). The ECE thus captures the weighted average of the absolute differences between accuracy and confidence across all bins, providing a summary measure of model calibration.

We use 10 bins to generate our plots in Figure \ref{fig:calibration_llm_llama3_sst2_plots}

\section{Further Calibration Studies}

\subsection{Confidence elicitation generalization}
We investigate whether confidence elicitation serves as a reliable measurement of uncertainty across various models (Table \ref{appendix:fig:calibration_more_models}) and datasets (Table \ref{appendix:fig:calibration_more_datasets}). Our findings suggest that confidence elicitation is indeed a dependable tool for approximating confidence across different models.

\begin{table}[h]
\centering
\scalebox{0.8}{
\begin{tabular}{lllccccccccccc}
\hline
\multicolumn{14}{c}{\textbf{Calibration of verbal confidence elicitation on more models}} \\ \hline
\textbf{Model} & \textbf{Dataset} & \multicolumn{4}{c}{\textbf{Avg ECE ↓}} & \multicolumn{2}{c}{\textbf{AUROC ↑}} & \multicolumn{2}{c}{\textbf{\begin{tabular}[c]{@{}c@{}}AUPRC\\ Positive ↑\end{tabular}}} & \multicolumn{4}{c}{\textbf{\begin{tabular}[c]{@{}c@{}}AUPRC\\ Negative ↑\end{tabular}}} \\ \hline
\multirow{3}{*}{\begin{tabular}[c]{@{}l@{}}Gemma2\\ 9B-Instruct\end{tabular}} & SST2 & \multicolumn{4}{c}{0.0591} & \multicolumn{2}{c}{0.9486} & \multicolumn{2}{c}{0.9547} & \multicolumn{4}{c}{0.9357} \\
 & AG-News & \multicolumn{4}{c}{0.1666} & \multicolumn{2}{c}{0.8342} & \multicolumn{2}{c}{-} & \multicolumn{4}{c}{-} \\
 & StrategyQA & \multicolumn{4}{c}{0.2295} & \multicolumn{2}{c}{0.6631} & \multicolumn{2}{c}{0.5899} & \multicolumn{4}{c}{0.7563} \\ \hline
\multirow{3}{*}{\begin{tabular}[c]{@{}l@{}}Mistral-Nemo\\ 12B-Instruct-2407\end{tabular}} & SST2 & \multicolumn{4}{c}{0.0645} & \multicolumn{2}{c}{0.9958} & \multicolumn{2}{c}{0.9944} & \multicolumn{4}{c}{0.9970} \\
 & AG-News & \multicolumn{4}{c}{0.0673} & \multicolumn{2}{c}{0.9194} & \multicolumn{2}{c}{-} & \multicolumn{4}{c}{-} \\
 & StrategyQA & \multicolumn{4}{c}{0.2748} & \multicolumn{2}{c}{0.6214} & \multicolumn{2}{c}{0.6425} & \multicolumn{4}{c}{0.5863} \\ \hline
\multirow{3}{*}{\begin{tabular}[c]{@{}l@{}}Qwen2.5\\ 7B-Instruct\end{tabular}} & SST2 & \multicolumn{4}{c}{0.0382} & \multicolumn{2}{c}{0.9534} & \multicolumn{2}{c}{0.9399} & \multicolumn{4}{c}{0.9480} \\
 & AG-News & \multicolumn{4}{c}{0.0753} & \multicolumn{2}{c}{0.8722} & \multicolumn{2}{c}{-} & \multicolumn{4}{c}{-} \\
 & StrategyQA & \multicolumn{4}{c}{0.2332} & \multicolumn{2}{c}{0.6247} & \multicolumn{2}{c}{0.6649} & \multicolumn{4}{c}{0.5624} \\ \hline
\multirow{3}{*}{\begin{tabular}[c]{@{}l@{}}LLaMa-3.2-11B\\ Vision-Instruct\end{tabular}} & SST2 & \multicolumn{4}{c}{0.0581} & \multicolumn{2}{c}{0.9535} & \multicolumn{2}{c}{0.9645} & \multicolumn{4}{c}{0.9270} \\
 & AG-News & \multicolumn{4}{c}{0.1090} & \multicolumn{2}{c}{0.8954} & \multicolumn{2}{c}{-} & \multicolumn{4}{c}{-} \\
 & StrategyQA & \multicolumn{4}{c}{0.2720} & \multicolumn{2}{c}{0.6366} & \multicolumn{2}{c}{0.6532} & \multicolumn{4}{c}{0.5928} \\ \hline
  \end{tabular}
}
\caption{Calibration of other models on core datasets SST2, AG-News and StrategyQA}\label{appendix:fig:calibration_more_models}
\end{table}


\begin{table}[h]
\centering
\scalebox{0.8}{ 
\begin{tabular}{lllccccccccccc}
\hline
\multicolumn{14}{c}{\textbf{Calibration of verbal confidence elicitation on more datasets}} \\ \hline
\textbf{Model} & \textbf{Dataset} & \multicolumn{4}{c}{\textbf{Avg ECE ↓}} & \multicolumn{2}{c}{\textbf{AUROC ↑}} & \multicolumn{2}{c}{\textbf{\begin{tabular}[c]{@{}c@{}}AUPRC\\ Positive ↑\end{tabular}}} & \multicolumn{4}{c}{\textbf{\begin{tabular}[c]{@{}c@{}}AUPRC\\ Negative ↑\end{tabular}}} \\ \hline
\multirow{2}{*}{\begin{tabular}[c]{@{}l@{}}LLaMa-3-8B\\ Instruct\end{tabular}} & RTE & \multicolumn{4}{c}{0.2598} & \multicolumn{2}{c}{0.8230} & \multicolumn{2}{c}{0.7972} & \multicolumn{4}{c}{0.8418} \\
 & QNLI & \multicolumn{4}{c}{0.1352} & \multicolumn{2}{c}{0.8413} & \multicolumn{2}{c}{0.8561} & \multicolumn{4}{c}{0.8182} \\ \hline
\multirow{2}{*}{\begin{tabular}[c]{@{}l@{}}Mistral-7B\\ Instruct-v0.3\end{tabular}} & RTE & \multicolumn{4}{c}{0.3047} & \multicolumn{2}{c}{0.6507} & \multicolumn{2}{c}{0.6032} & \multicolumn{4}{c}{0.6927} \\
 & QNLI & \multicolumn{4}{c}{0.2764} & \multicolumn{2}{c}{0.6951} & \multicolumn{2}{c}{0.6444} & \multicolumn{4}{c}{0.7345} \\ \hline
  \end{tabular}
}
\caption{Calibration of other datasets on core models Mistral and LLaMa3}\label{appendix:fig:calibration_more_datasets}
\end{table}

\subsection{Self-Consistency calibration}
It is possible to use empirical self-consistency \citep{Self-Consistency}, with the parameters set to $k=1$, $M=20$, and $\tau=1$, instead of employing confidence elicitation for our attacks. This approach generates multiple predictions from the model, which we can then leverage to obtain empirical uncertainty estimates. We find that the results are similar to those achieved using confidence elicitation, as shown in Table \ref{appendix:self-consistency-calibration}. However, approximating uncertainty using this technique renders the attacks impractical, since each input perturbation would require $M$ calls to the model to estimate confidence, whereas confidence elicitation requires only a single call. We find results similar to previous work, where the outcomes are mixed. Specifically, in line with the findings of \citep{Confidence_Elicitation}, we observe that the confidence elicitation technique outperforms self-consistency on StrategyQA for uncertainty estimation.

\begin{table}[h]
\centering
\scalebox{0.8}{ 
\begin{tabular}{lllccccccccccc}
\hline
\multicolumn{14}{c}{\textbf{Calibration of empirical self-consistency}} \\ \hline
\textbf{Model} & \textbf{Dataset} & \textbf{\begin{tabular}[c]{@{}l@{}}Uncertainty \\ Estimation\\ Technique\end{tabular}} & \multicolumn{3}{c}{\textbf{Avg ECE ↓}} & \multicolumn{2}{c}{\textbf{AUROC ↑}} & \multicolumn{2}{c}{\textbf{\begin{tabular}[c]{@{}c@{}}AUPRC\\ Positive ↑\end{tabular}}} & \multicolumn{4}{c}{\textbf{\begin{tabular}[c]{@{}c@{}}AUPRC\\ Negative ↑\end{tabular}}} \\ \hline
 &  & Self-Consistency & \multicolumn{3}{c}{0.0515} & \multicolumn{2}{c}{0.9631} & \multicolumn{2}{c}{0.9730} & \multicolumn{4}{c}{0.9433} \\
 & \multirow{-2}{*}{SST2} & Confidence Elicitation & \multicolumn{3}{c}{0.1264} & \multicolumn{2}{c}{0.9696} & \multicolumn{2}{c}{0.9730} & \multicolumn{4}{c}{0.9678} \\ \cline{2-14} 
 &  & Self-Consistency & \multicolumn{3}{c}{0.0774} & \multicolumn{2}{c}{0.9147} & \multicolumn{2}{c}{-} & \multicolumn{4}{c}{-} \\
 & \multirow{-2}{*}{AG-News} & Confidence Elicitation & \multicolumn{3}{c}{0.1376} & \multicolumn{2}{c}{0.9293} & \multicolumn{2}{c}{-} & \multicolumn{4}{c}{-} \\ \cline{2-14} 
 &  & Self-Consistency & \multicolumn{3}{c}{0.2113} & \multicolumn{2}{c}{0.6975} & \multicolumn{2}{c}{0.6639} & \multicolumn{4}{c}{0.7124} \\
\multirow{-6}{*}{\begin{tabular}[c]{@{}l@{}}LLaMa-3-8B\\ Instruct\end{tabular}} & \multirow{-2}{*}{StrategyQA} & Confidence Elicitation & \multicolumn{3}{c}{0.0492} & \multicolumn{2}{c}{0.6607} & \multicolumn{2}{c}{0.6212} & \multicolumn{4}{c}{0.6863} \\ \hline
 &  & Self-Consistency & \multicolumn{3}{c}{0.0675} & \multicolumn{2}{c}{0.9466} & \multicolumn{2}{c}{0.9418} & \multicolumn{4}{c}{0.9255} \\
 & \multirow{-2}{*}{SST2} & Confidence Elicitation & \multicolumn{3}{c}{0.1542} & \multicolumn{2}{c}{0.9537} & \multicolumn{2}{c}{0.9616} & \multicolumn{4}{c}{0.9343} \\ \cline{2-14} 
 &  & Self-Consistency & \multicolumn{3}{c}{0.0837} & \multicolumn{2}{c}{0.9240} & \multicolumn{2}{c}{-} & \multicolumn{4}{c}{-} \\
 & \multirow{-2}{*}{AG-News} & Confidence Elicitation & \multicolumn{3}{c}{0.1216} & \multicolumn{2}{c}{0.8826} & \multicolumn{2}{c}{-} & \multicolumn{4}{c}{-} \\ \cline{2-14} 
 &  & Self-Consistency & \multicolumn{3}{c}{0.3671} & \multicolumn{2}{c}{0.6182} & \multicolumn{2}{c}{0.6416} & \multicolumn{4}{c}{0.5861} \\
\multirow{-6}{*}{\begin{tabular}[c]{@{}l@{}}Mistral-7B\\ Instruct-v0.3\end{tabular}} & \multirow{-2}{*}{StrategyQA} & Confidence Elicitation & \multicolumn{3}{c}{0.1295} & \multicolumn{2}{c}{0.6358} & \multicolumn{2}{c}{0.6421} & \multicolumn{4}{c}{0.6185} \\ \hline

  \end{tabular}
}
\caption{Calibration of empirical self-consistency}\label{appendix:self-consistency-calibration}
\end{table}




\subsection{More Calibration Plots}\label{appendix:futher_calibration_plots}
We show the reliability plots for mistral in Figure \ref{appendix:fig:calibration_llm_mistral}

\begin{figure}[t]
\centering
  \includegraphics[width=0.25\linewidth]{Pictures/calibration_pictures_mistralv03/sst_cali_mistralv03.pdf}
  \includegraphics[width=0.25\linewidth]{Pictures/calibration_pictures_mistralv03/ag_news_cali_mistralv03.pdf}
   \includegraphics[width=0.25\linewidth]{Pictures/calibration_pictures_mistralv03/strategyQA_cali_mistralv03.pdf}
  \includegraphics[width=0.25\linewidth]{Pictures/calibration_pictures_mistralv03/sst_roc_mistralv03.pdf}
  % \includegraphics[width=0.25\linewidth]{Pictures/calibration_pictures/ag_news_cali_llama3.pdf}
  \includegraphics[width=0.25\linewidth]{Pictures/calibration_pictures_mistralv03/ag_news_roc_mistralv03.pdf}
  % \includegraphics[width=0.25\linewidth]{Pictures/calibration_pictures/strategyQA_cali_llama3.pdf}
  \includegraphics[width=0.25\linewidth]{Pictures/calibration_pictures_mistralv03/strategyQA_roc_mistralv03.pdf}
  \caption{Reliability plots. On the top, we show the SST2, AG-News and StrategyQA on Mistralv0.3 7B Instruct calibration plots. On the bottom, the ROC curves. The optimal calibration corresponds to a diagonal line.}
  \label{appendix:fig:calibration_llm_mistral}
\end{figure}

\section{Evaluation on a close-source API model}
We conducted tests on GPT-4o using the OpenAI API. We found this model to be more robust against word substitutions (Table \ref{appendix:gpt-4o-attack}) and better at eliciting confidence (Table \ref{appendix:gpt-4o-calibration}).
% which opens up the possibility to research how stronger $\delta$ perturbations can affect these models using confidence elicitation as feedback.

\begin{table}[h]
\centering
\scalebox{0.8}{ 
\begin{tabular}{lllccccccccccc}
\hline
\multicolumn{14}{c}{\textbf{Calibration of verbal confidence elicitation on an API model}} \\ \hline
\textbf{Model} & \textbf{Dataset} & \multicolumn{4}{l}{\textbf{Avg ECE ↓}} & \multicolumn{2}{l}{\textbf{AUROC ↑}} & \multicolumn{2}{l}{\textbf{\begin{tabular}[c]{@{}l@{}}AUPRC\\ Positive ↑\end{tabular}}} & \multicolumn{4}{l}{\textbf{\begin{tabular}[c]{@{}l@{}}AUPRC\\ Negative ↑\end{tabular}}} \\ \hline

\multirow{3}{*}{\begin{tabular}[c]{@{}l@{}}GPT-4o\\ 2024-08-06\end{tabular}} & SST2 & \multicolumn{4}{c}{0.0286} & \multicolumn{2}{c}{0.9713} & \multicolumn{2}{c}{0.0297} & \multicolumn{4}{c}{0.0274} \\
 & AG-News & \multicolumn{4}{c}{0.0641} & \multicolumn{2}{c}{0.9306} & \multicolumn{2}{c}{-} & \multicolumn{4}{c}{-} \\
 & StrategyQA & \multicolumn{4}{c}{0.2300} & \multicolumn{2}{c}{0.7410} & \multicolumn{2}{c}{0.2373} & \multicolumn{4}{c}{0.2227} \\ \hline
  \end{tabular}
}
\caption{Calibration of GPT-4o}\label{appendix:gpt-4o-calibration}
\end{table}

\begin{table}[h]
\centering
\scalebox{0.7}{ 
\begin{tabular}{lllccccccccccc}
\hline
\multicolumn{3}{l}{\multirow{2}{*}{}} & \multicolumn{11}{c}{\multirow{2}{*}{\textbf{Attack performance on an API model}}} \\ \\ \hline
Model & Dataset & Technique & \multicolumn{2}{c}{\textbf{CA {[}\%{]} ↑}} & \multicolumn{2}{c}{\textbf{AUA {[}\%{]} ↓}} & \multicolumn{2}{c}{\textbf{ASR {[}\%{]} ↑}} & \multicolumn{2}{c}{\textbf{SemSim ↑}} & \multicolumn{2}{c}{\textbf{\begin{tabular}[c]{@{}c@{}}Succ Att\\ Queries \\ Avg ↓\end{tabular}}} & \textbf{\begin{tabular}[c]{@{}c@{}}Total Attack Time \\ {[}HHH:MM:SS{]} ↓\end{tabular}} \\ \hline
 &  & SSPAttack & \multicolumn{2}{c}{94.0} & \multicolumn{2}{c}{89.0} & \multicolumn{2}{c}{5.32} & \multicolumn{2}{c}{0.86} & \multicolumn{2}{c}{60.8} & 001:58:12 \\
 &  & CEAttack & \multicolumn{2}{c}{96.0} & \multicolumn{2}{c}{82.0} & \multicolumn{2}{c}{14.58} & \multicolumn{2}{c}{0.88} & \multicolumn{2}{c}{41.92} & 002:54:00 \\
 & \multirow{-3}{*}{SST2} & CEAttack++ & \multicolumn{2}{c}{95.0} & \multicolumn{2}{c}{68.0} & \multicolumn{2}{c}{28.42} & \multicolumn{2}{c}{0.87} & \multicolumn{2}{c}{108.33} & 005:34:25 \\ \cline{2-14} 
 &  & SSPAttack & \multicolumn{2}{c}{88.0} & \multicolumn{2}{c}{87.0} & \multicolumn{2}{c}{1.14} & \multicolumn{2}{c}{0.87} & \multicolumn{2}{c}{144.0} & 002:37:35 \\
 &  & CEAttack & \multicolumn{2}{c}{87.0} & \multicolumn{2}{c}{79.0} & \multicolumn{2}{c}{9.2} & \multicolumn{2}{c}{0.92} & \multicolumn{2}{c}{82.0} & 005:33:36 \\
 & \multirow{-3}{*}{AG-News} & CEAttack++ & \multicolumn{2}{c}{88.0} & \multicolumn{2}{c}{75.0} & \multicolumn{2}{c}{14.77} & \multicolumn{2}{c}{0.91} & \multicolumn{2}{c}{412.23} & 025:56:00 \\ \cline{2-14} 
 &  & SSPAttack & \multicolumn{2}{c}{65.0} & \multicolumn{2}{c}{52.0} & \multicolumn{2}{c}{20.0} & \multicolumn{2}{c}{0.9} & \multicolumn{2}{c}{19.07} & 000:13:22 \\
 &  & CEAttack & \multicolumn{2}{c}{64.0} & \multicolumn{2}{c}{45.0} & \multicolumn{2}{c}{29.69} & \multicolumn{2}{c}{0.89} & \multicolumn{2}{c}{21.15} & 000:31:01 \\
\multirow{-9}{*}{\begin{tabular}[c]{@{}l@{}}GPT-4o\\ 2024-08-06\end{tabular}} & \multirow{-3}{*}{StrategyQA} & CEAttack++ & \multicolumn{2}{c}{68.0} & \multicolumn{2}{c}{43.0} & \multicolumn{2}{c}{36.76} & \multicolumn{2}{c}{0.88} & \multicolumn{2}{c}{39.52} & 001:20:35 \\ \hline

 \end{tabular}
}
\caption{Confidence elicitation attacks can also target closed-source API models. Naturally, their larger scale makes them more robust to semantic perturbations. Therefore, we set $\vert$S$\vert$ to 20 for SSPAttack and CEAttack. For CEAttack++, we set $\vert$S$\vert$ to 50 across all datasets, employ a delete-word ranking scheme, and specify $\vert$W$\vert$ as 5 for StrategyQA, 10 for SST2, and 20 for AG-News. These configurations represent the best set of hyperparameters identified through our ablation studies.}\label{appendix:gpt-4o-attack}
\end{table}



\section{Ablation}\label{appendix:ablation}
Since our work introduces the concept of confidence elicitation attacks, we follow previous adversarial attack work and set the temperature $\tau$ to approximately 0. This approach maintains the general purposefulness of the model while allowing deterministic behavior across multiple model calls with the same input  $M$  in Figure \ref{fig:confidence_elicitation_attacks}. Setting  $\tau \approx 0$  also has the added benefit of reducing computation costs for our analysis since we won't have to perform multiple calls to the model after each perturbation. Nonetheless, we provide an ablation study with $\tau = 0.7$ in Appendix \ref{appendix:temperature_ablation}. 

\subsection{Ablation on number of embedding $|S|$}\label{appendix:ablation_on_w}
The following table \ref{tab:ablation_on_s} holds the values in figure \ref{fig:ablation_on_w_and_s} for the ablation on $|S|$ plots.

\begin{table*}[ht]
\centering
\scalebox{0.57}{
\begin{tabular}{llcccccccccc}
\hline
\multicolumn{3}{l}{\multirow{2}{*}{}} & \multicolumn{9}{c}{\textbf{Ablation on} $\vert$ \textbf{S} $\vert$ } \\
\multicolumn{3}{l}{} & \multicolumn{9}{c}{\textbf{CEAttack}} \\ \hline
Model & Dataset & $\vert$ \textbf{S} $\vert$ & \textbf{CA {[}\%{]} ↑} & \textbf{AUA {[}\%{]} ↓} & \textbf{ASR {[}\%{]} ↑} & \textbf{SemSim ↑} & \textbf{\begin{tabular}[c]{@{}c@{}}Original \\ Perplexity ↓\end{tabular}} & \textbf{\begin{tabular}[c]{@{}c@{}}After-Attack\\ Perplexity ↓\end{tabular}} & \textbf{\begin{tabular}[c]{@{}c@{}}All Att \\ Queries \\ Avg ↓\end{tabular}} & \textbf{\begin{tabular}[c]{@{}c@{}}Succ Att\\ Queries \\ Avg ↓\end{tabular}} & \textbf{\begin{tabular}[c]{@{}c@{}}Total Attack Time \\ {[}HHH:MM:SS{]} ↓\end{tabular}} \\ \hline
\multirow{15}{*}{\begin{tabular}[c]{@{}l@{}}LLaMa-3-8B\\ Instruct\end{tabular}} & \multirow{5}{*}{SST2} & 1 & 85.86 & 78.79 & 8.24 & 0.9 & 61.74 & 105.6 & 4.53 & 4.71 & 000:44:32 \\
 &  & 5 & 87.88 & 69.7 & 20.69 & 0.89 & 81.73 & 131.95 & 13.45 & 16.11 & 002:11:18 \\
 &  & 10 & 85.86 & 68.69 & 20.0 & 0.89 & 75.06 & 105.2 & 21.81 & 28.52 & 003:22:45 \\
 &  & 20 & 85.86 & 63.64 & 25.88 & 0.89 & 72.24 & 106.77 & 34.56 & 49.36 & 005:19:58 \\
 &  & 50 & 86.87 & 58.59 & 32.56 & 0.88 & 74.28 & 112.37 & 61.95 & 78.85 & 009:30:16 \\ \cline{2-12} 
 & \multirow{5}{*}{AG-News} & 1 & 69.0 & 62.0 & 10.14 & 0.92 & 132.98 & 143.96 & 5.71 & 5.71 & 000:48:54 \\
 &  & 5 & 68.0 & 57.0 & 16.18 & 0.93 & 73.76 & 92.56 & 23.85 & 23.45 & 003:02:26 \\
 &  & 10 & 69.0 & 57.0 & 17.39 & 0.91 & 93.73 & 122.97 & 43.61 & 38.5 & 005:47:23 \\
 &  & 20 & 69.0 & 52.0 & 24.64 & 0.92 & 67.26 & 88.92 & 75.32 & 75.35 & 009:41:50 \\
 &  & 50 & 68.0 & 47.0 & 30.88 & 0.91 & 63.93 & 95.39 & 132.49 & 130.19 & 016:30:55 \\ \cline{2-12} 
 & \multirow{5}{*}{StrategyQA} & 1 & 63.0 & 55.0 & 12.7 & 0.9 & 123.55 & 201.62 & 1.95 & 2.75 & 000:05:25 \\
 &  & 5 & 64.0 & 39.0 & 39.06 & 0.9 & 109.45 & 185.19 & 5.38 & 6.68 & 000:12:03 \\
 &  & 10 & 65.0 & 31.0 & 52.31 & 0.89 & 109.8 & 216.1 & 9.14 & 11.35 & 000:20:29 \\
 &  & 20 & 65.0 & 26.0 & 60.0 & 0.89 & 99.77 & 184.98 & 14.98 & 18.66 & 000:32:50 \\
 &  & 50 & 63.0 & 24.0 & 61.9 & 0.89 & 113.4 & 202.82 & 28.24 & 35.74 & 000:58:51 \\ \hline
\end{tabular}
}
\caption{How the greedy search process is affected if we increase the number of potential synonyms per word $|S|$.}
  \label{tab:ablation_on_s}
\end{table*}


 
\subsection{Ablation on maximum number of word substitutions $|W|$}\label{appendix:ablation_on_|W|}
The following table \ref{tab:ablation_on_w} holds the values in figure \ref{fig:ablation_on_w_and_s} for the ablation on $|W|$ plots.
 
\begin{table*}[ht]
\centering
\scalebox{0.57}{
\begin{tabular}{llcccccccccc}
\hline
 
\multicolumn{3}{l}{\multirow{2}{*}{}} & \multicolumn{9}{c}{\textbf{Ablation on} $\vert$ \textbf{W} $\vert$ } \\
\multicolumn{3}{l}{} & \multicolumn{9}{c}{\textbf{CEAttack}} \\ \hline
Model & Dataset & $\vert$ \textbf{W} $\vert$ & \textbf{CA {[}\%{]} ↑} & \textbf{AUA {[}\%{]} ↓} & \textbf{ASR {[}\%{]} ↑} & \textbf{SemSim ↑} & \textbf{\begin{tabular}[c]{@{}c@{}}Original \\ Perplexity ↓\end{tabular}} & \textbf{\begin{tabular}[c]{@{}c@{}}After-Attack\\ Perplexity ↓\end{tabular}} & \textbf{\begin{tabular}[c]{@{}c@{}}All Att \\ Queries \\ Avg ↓\end{tabular}} & \textbf{\begin{tabular}[c]{@{}c@{}}Succ Att\\ Queries \\ Avg ↓\end{tabular}} & \textbf{\begin{tabular}[c]{@{}c@{}}Total Attack Time \\ {[}HHH:MM:SS{]} ↓\end{tabular}} \\ \hline
\multirow{15}{*}{\begin{tabular}[c]{@{}l@{}}LLaMa-3-8B\\ Instruct\end{tabular}} & \multirow{5}{*}{SST2} & 1 & 85.86 & 75.76 & 11.76 & 0.89 & 84.46 & 115.06 & 11.46 & 12.4 & 001:49:00 \\
 &  & 5 & 85.86 & 68.69 & 20.0 & 0.89 & 75.06 & 105.2 & 21.81 & 28.52 & 003:23:17 \\
 &  & 10 & 87.88 & 63.64 & 27.59 & 0.87 & 68.2 & 111.02 & 26.33 & 31.70 & 004:14:46 \\
 &  & 15 & 85.86 & 65.66 & 23.53 & 0.89 & 72.11 & 108.58 & 28.39 & 37.55 & 004:22:39 \\
 &  & 20 & 85.86 & 66.67 & 22.35 & 0.87 & 62.32 & 101.31 & 27.85 & 36.73 & 004:12:58 \\ \cline{2-12} 
 & \multirow{5}{*}{AG-News} & 1 & 67.0 & 61.0 & 8.96 & 0.93 & 113.8 & 132.98 & 15.57 & 20.0 & 001:59:58 \\
 &  & 5 & 69.0 & 57.0 & 17.39 & 0.91 & 93.73 & 122.97 & 43.61 & 38.5 & 005:47:23 \\
 &  & 10 & 69.0 & 50.0 & 27.54 & 0.91 & 78.46 & 115.21 & 78.35 & 72.73 & 010:15:10 \\
 &  & 15 & 69.0 & 49.0 & 28.99 & 0.91 & 68.93 & 114.29 & 106.51 & 99.5 & 014:17:19 \\
 &  & 20 & 71.0 & 47.0 & 33.8 & 0.91 & 67.15 & 116.75 & 133.87 & 113.58 & 018:35:28 \\ \cline{2-12} 
 & \multirow{5}{*}{StrategyQA} & 1 & 63.0 & 48.0 & 23.81 & 0.89 & 107.11 & 226.42 & 4.08 & 8.53 & 000:09:21 \\
 &  & 5 & 65.0 & 31.0 & 52.31 & 0.89 & 109.8 & 216.1 & 9.14 & 11.35 & 000:20:29 \\
 &  & 10 & 64.0 & 32.0 & 50.0 & 0.89 & 105.48 & 209.16 & 9.42 & 11.78 & 000:20:49 \\
 &  & 15 & 64.0 & 32.0 & 50.0 & 0.89 & 105.48 & 209.16 & 9.42 & 11.78 & 000:20:49 \\
 &  & 20 & 64.0 & 32.0 & 50.0 & 0.89 & 105.48 & 209.16 & 9.42 & 11.78 & 000:20:49 \\ \hline
\end{tabular}
}
\caption{How the greedy search process is affected if we increase the maximum number of potential word substitutions in the sentence $|W|$.}
  \label{tab:ablation_on_w}
\end{table*} 



\subsection{Temperature Ablation}\label{appendix:temperature_ablation}
We conduct the same experiments in Section \ref{sec:elicitation_attacks} with a temperature of 0.7, the findings are shown in Tables \ref{appendix:tab:elicitation_attacks_table_attack_temp0_7}, \ref{appendix:tab:elicitation_attacks_table_quality_temp0_7}, \ref{appendix:tab:elicitation_attacks_table_efficency_temp0_7}.


\begin{table*}[ht]
\centering
\scalebox{0.63}{
\begin{tabular}{llcccccccccl}
\hline
\multicolumn{2}{l}{\multirow{2}{*}{}} & \multicolumn{10}{c}{\textbf{Attack Performance Tests}} \\ \cline{3-12} 
\multicolumn{2}{l}{} & \multicolumn{3}{c}{\begin{tabular}[c]{@{}c@{}}Self-Fool \\ Word Sub\end{tabular}} & \multicolumn{3}{c}{SSPAttack} & \multicolumn{4}{c}{CEAttack} \\ \hline
Model & Dataset & CA {[}\%{]} ↑ & AUA {[}\%{]} ↓ & ASR {[}\%{]} ↑ & CA {[}\%{]} ↑ & AUA {[}\%{]} ↓ & ASR {[}\%{]} ↑ & CA {[}\%{]} ↑ & AUA {[}\%{]} ↓ & \multicolumn{2}{c}{ASR {[}\%{]} ↑} \\ \hline
\multirow{3}{*}{\begin{tabular}[c]{@{}l@{}}LLaMa-3-8B\\ Instruct\end{tabular}} & SST2 & 89.9 & 87.47 & 2.7 & 89.31 & 84.48 & 5.42 & 90.12 & \textbf{57.86} & \multicolumn{2}{c}{\textbf{35.79}} \\
 & AG-News & - & \textbf{-} & \textbf{-} & 61.96 & 50.1 & 19.14 & 59.8 & \textbf{35.96} & \multicolumn{2}{c}{\textbf{39.86}} \\
 & StrategyQA & 61.12 & 59.32 & 2.95 & 63.53 & 37.27 & 41.32 & 62.12 & \textbf{23.05} & \multicolumn{2}{c}{\textbf{62.9}} \\ \hline
\multirow{3}{*}{\begin{tabular}[c]{@{}l@{}}Mistral-7B\\ Instruct-v0.3\end{tabular}} & SST2 & 89.77 & 86.01 & 4.19 & 89.6 & 80.67 & 9.98 & 89.38 & \textbf{66.46} & \multicolumn{2}{c}{\textbf{25.64}} \\
 & AG-News & 63.82 & 62.65 & 1.84 & 65.14 & 58.1 & 10.8 & 65.86 & \textbf{14.2} & \multicolumn{2}{c}{\textbf{78.44}} \\
 & StrategyQA & 58.68 & 58.44 & 0.42 & 54.9 & 34.31 & 37.5 & 55.88 & \textbf{23.26} & \multicolumn{2}{c}{\textbf{58.37}} \\ \hline
\end{tabular}
}
\caption{Results of performing Confidence Elicitation Attacks when the model has a temperature of 0.7. Numbers in \textbf{bold} represent the best results}
  \label{appendix:tab:elicitation_attacks_table_attack_temp0_7}
\end{table*}


\begin{table*}[ht]
\centering
\scalebox{0.6}{
\begin{tabular}{llcccccccccl}
\hline
\multicolumn{2}{l}{\multirow{2}{*}{}} & \multicolumn{10}{c}{\textbf{Quality Tests}} \\ \cline{3-12} 
\multicolumn{2}{l}{} & \multicolumn{3}{c}{\textbf{\begin{tabular}[c]{@{}c@{}}Self-Fool \\ Word Sub\end{tabular}}} & \multicolumn{3}{c}{\textbf{SSPAttack}} & \multicolumn{4}{c}{\textbf{CEAttack}} \\ \hline
Model & Dataset & SemSim ↑ & \begin{tabular}[c]{@{}c@{}}Original \\ Perplexity ↓\end{tabular} & \begin{tabular}[c]{@{}c@{}}After-Attack\\ Perplexity ↓\end{tabular} & SemSim ↑ & \begin{tabular}[c]{@{}c@{}}Original \\ Perplexity ↓\end{tabular} & \begin{tabular}[c]{@{}c@{}}After-Attack\\ Perplexity ↓\end{tabular} & SemSim ↑ & \begin{tabular}[c]{@{}c@{}}Original \\ Perplexity ↓\end{tabular} & \multicolumn{2}{c}{\begin{tabular}[c]{@{}c@{}}After-Attack\\ Perplexity ↓\end{tabular}} \\ \hline
\multirow{3}{*}{\begin{tabular}[c]{@{}l@{}}LLaMa-3-8B\\ Instruct\end{tabular}} & SST2 & 0.87 & 80.94 & 99.46 & 0.89 & 76.8 & 148.38 & \textbf{0.88} & 66.49 & \multicolumn{2}{c}{105.88} \\
 & AG-News & - & - & - & 0.88 & 74.61 & 208.4 & \textbf{0.93} & 66.82 & \multicolumn{2}{c}{84.68} \\
 & StrategyQA & 0.88 & 112.97 & 131.68 & 0.91 & 110.59 & 210.26 & \textbf{0.89} & 99.98 & \multicolumn{2}{c}{178.08} \\ \hline
\multirow{3}{*}{\begin{tabular}[c]{@{}l@{}}Mistral-7B\\ Instruct-v0.3\end{tabular}} & SST2 & 0.87 & 71.05 & 82.83 & 0.89 & 64.51 & 113.8 & \textbf{0.88} & 66.14 & \multicolumn{2}{c}{96.25} \\
 & AG-News & 0.86 & 73.73 & 71.49 & 0.87 & 71.43 & 171.11 & \textbf{0.94} & 59.48 & \multicolumn{2}{c}{72.65} \\
 & StrategyQA & \textbf{0.93} & 120.92 & 169.04 & 0.92 & 90.23 & 190.47 & 0.9 & 98.48 & \multicolumn{2}{c}{180.53} \\ \hline
\end{tabular}
}
\caption{Quality results of performing Confidence Elicitation Attacks when the model has a temperature of 0.7. Numbers in \textbf{bold} represent the best results for semantic similarity, only successful perturbations are considered.}
  \label{appendix:tab:elicitation_attacks_table_quality_temp0_7}
\end{table*}


\begin{table*}[ht]
\centering
\scalebox{0.6}{
\begin{tabular}{llcccccccccl}
\hline
\multicolumn{2}{l}{\multirow{2}{*}{}} & \multicolumn{10}{c}{\textbf{Efficiency Test}} \\ \cline{3-12} 
\multicolumn{2}{l}{} & \multicolumn{3}{c}{\textbf{\begin{tabular}[c]{@{}c@{}}Self-Fool \\ Word Sub\end{tabular}}} & \multicolumn{3}{c}{\textbf{SSPAttack}} & \multicolumn{4}{c}{\textbf{CEAttack}} \\ \hline
Model & Dataset & \begin{tabular}[c]{@{}c@{}}All Att \\ Queries \\ Avg ↓\end{tabular} & \begin{tabular}[c]{@{}c@{}}Succ Att\\ Queries \\ Avg ↓\end{tabular} & \begin{tabular}[c]{@{}c@{}}Total Attack Time \\ {[}HHH:MM:SS{]} ↓\end{tabular} & \begin{tabular}[c]{@{}c@{}}All Att \\ Queries \\ Avg ↓\end{tabular} & \begin{tabular}[c]{@{}c@{}}Succ Att\\ Queries \\ Avg ↓\end{tabular} & \begin{tabular}[c]{@{}c@{}}Total Attack Time \\ {[}HHH:MM:SS{]} ↓\end{tabular} & \begin{tabular}[c]{@{}c@{}}All Att \\ Queries \\ Avg ↓\end{tabular} & \begin{tabular}[c]{@{}c@{}}Succ Att\\ Queries \\ Avg ↓\end{tabular} & \multicolumn{2}{c}{\begin{tabular}[c]{@{}c@{}}Total Attack Time \\ {[}HHH:MM:SS{]} ↓\end{tabular}} \\ \hline
\multirow{3}{*}{\begin{tabular}[c]{@{}l@{}}LLaMa-3-8B\\ Instruct\end{tabular}} & SST2 & 20.92 & 3.0 & 001:45:13 & 7.24 & 70.04 & 043:17:07 & 23.48 & 27.28 & \multicolumn{2}{c}{020:35:45} \\
 & AG-News & - & - & - & 34.66 & 165.36 & 073:29:13 & 43.17 & 42.30 & \multicolumn{2}{c}{028:16:30} \\
 & StrategyQA & 21.78 & 3.0 & 000:41:37 & 10.79 & 21.47 & 002:16:44 & 8.45 & 10.54 & \multicolumn{2}{c}{001:27:07} \\ \hline
\multirow{3}{*}{\begin{tabular}[c]{@{}l@{}}Mistral-7B\\ Instruct-v0.3\end{tabular}} & SST2 & 20.43 & 3.0 & 001:18:53 & 10.4 & 72.04 & 038:18:17 & 23.74 & 25.06 & \multicolumn{2}{c}{018:02:37} \\
 & AG-News & 20.85 & 3.0 & 001:20:40 & 20.59 & 157.26 & 062:05:10 & 43.86 & 44.68 & \multicolumn{2}{c}{018:02:17} \\
 & StrategyQA & 21.01 & 3.0 & 000:34:38 & 9.18 & 19.33 & 001:35:31 & 8.71 & 10.90 & \multicolumn{2}{c}{001:40:31} \\ \hline
\end{tabular}
}
\caption{Efficiency results of performing Confidence Elicitation Attacks when the model has a temperature of 0.7.}
  \label{appendix:tab:elicitation_attacks_table_efficency_temp0_7}
\end{table*}

\subsection{Delete Word Ranking Schema Ablation}\label{appendix:delete_word_ranking_schema}
It is possible to enhance the efficacy of the attack by initially ranking the input words based on their importance using a word deletion ranking schema (Table \ref{appendix:tab:delete_word_ranking_schema_ablation}). This involves removing each word from the input example, one at a time, and observing the change in confidence elicited in the output. Words that cause the largest change in confidence are ranked higher, while those causing minimal change are ranked lower. Once the words are ranked, we proceed to perform CEAttacks as previously done. A word deletion ranking schema is appropriate for our technique because it adheres to the black box constraints of the attack. Alternative ranking methods, such as using attention scores or word saliency, would require some knowledge of the model's inner workings.

\begin{table*}[ht]
\centering
\scalebox{0.55}{ 
\begin{tabular}{lllccccccccccc}
\hline
\multicolumn{2}{l}{\multirow{2}{*}{}} & \multicolumn{12}{c}{\textbf{Attack Performance with a delete word ranking schema for CEAttacks}} \\ \cline{3-14} 
\multicolumn{2}{l}{} & \multicolumn{2}{c|}{\textbf{CA {[}\%{]} ↑}} & \multicolumn{2}{c|}{\textbf{AUA {[}\%{]} ↓}} & \multicolumn{2}{c|}{\textbf{ASR {[}\%{]} ↑}} & \multicolumn{2}{c|}{\textbf{SemSim ↑}} & \multicolumn{2}{c|}{\textbf{\begin{tabular}[c]{@{}c@{}}Succ Att\\ Queries \\ Avg ↓\end{tabular}}} & \multicolumn{2}{c}{\textbf{\begin{tabular}[c]{@{}c@{}}Total Attack Time \\ {[}HHH:MM:SS{]} ↓\end{tabular}}} \\ \hline
Model & Dataset & \multicolumn{1}{c}{\textbf{\begin{tabular}[c]{@{}c@{}}Random\\ Ranking\end{tabular}}} & \multicolumn{1}{c|}{\textbf{\begin{tabular}[c]{@{}c@{}}Delete \\ Ranking\end{tabular}}} & \textbf{\begin{tabular}[c]{@{}c@{}}Random\\ Ranking\end{tabular}} & \multicolumn{1}{c|}{\textbf{\begin{tabular}[c]{@{}c@{}}Delete \\ Ranking\end{tabular}}} & \textbf{\begin{tabular}[c]{@{}c@{}}Random\\ Ranking\end{tabular}} & \multicolumn{1}{c|}{\textbf{\begin{tabular}[c]{@{}c@{}}Delete \\ Ranking\end{tabular}}} & \textbf{\begin{tabular}[c]{@{}c@{}}Random\\ Ranking\end{tabular}} & \multicolumn{1}{c|}{\textbf{\begin{tabular}[c]{@{}c@{}}Delete \\ Ranking\end{tabular}}} & \textbf{\begin{tabular}[c]{@{}c@{}}Random\\ Ranking\end{tabular}} & \multicolumn{1}{c|}{\textbf{\begin{tabular}[c]{@{}c@{}}Delete \\ Ranking\end{tabular}}} & \multicolumn{1}{c}{\textbf{\begin{tabular}[c]{@{}c@{}}Random\\ Ranking\end{tabular}}} & \textbf{\begin{tabular}[c]{@{}c@{}}Delete \\ Ranking\end{tabular}} \\ \hline
\multirow{3}{*}{\begin{tabular}[c]{@{}l@{}}LLaMa-3-8B\\ Instruct\end{tabular}} & SST2 & \multicolumn{1}{c}{90.56} & \multicolumn{1}{c|}{90.76} & 72.69 & \multicolumn{1}{c|}{65.06} & 19.73 & \multicolumn{1}{c|}{28.32} & 0.88 & \multicolumn{1}{c|}{0.88} & 25.60 & \multicolumn{1}{c|}{35.67} & \multicolumn{1}{c}{017:30:57} & 025:33:37 \\
 & AG-News & \multicolumn{1}{c}{62.17} & \multicolumn{1}{c|}{61.97} & 43.06 & \multicolumn{1}{c|}{40.85} & 30.74 & \multicolumn{1}{c|}{34.09} & 0.93 & \multicolumn{1}{c|}{0.93} & 42.36 & \multicolumn{1}{c|}{68.13} & \multicolumn{1}{c}{024:31:58} & 039:22:19 \\
 & StrategyQA & \multicolumn{1}{c}{60.12} & \multicolumn{1}{c|}{59.92} & 32.67 & \multicolumn{1}{c|}{33.07} & 45.67 & \multicolumn{1}{c|}{44.82} & 0.89 & \multicolumn{1}{c|}{0.89} & 10.95 & \multicolumn{1}{c|}{17.10} & \multicolumn{1}{c}{001:25:34} & 002:19:30 \\ \hline
\multirow{3}{*}{\begin{tabular}[c]{@{}l@{}}Mistral-7B\\ Instruct-v0.3\end{tabular}} & SST2 & \multicolumn{1}{c}{87.45} & \multicolumn{1}{c|}{88.08} & 71.76 & \multicolumn{1}{c|}{67.78} & 17.94 & \multicolumn{1}{c|}{23.04} & 0.88 & \multicolumn{1}{c|}{0.88} & 24.54 & \multicolumn{1}{c|}{33.18} & \multicolumn{1}{c}{017:13:44} & 024:05:07 \\
 & AG-News & \multicolumn{1}{c}{66.18} & \multicolumn{1}{c|}{65.89} & 40.82 & \multicolumn{1}{c|}{33.24} & 38.33 & \multicolumn{1}{c|}{49.56} & 0.93 & \multicolumn{1}{c|}{0.92} & 42.66 & \multicolumn{1}{c|}{68.95} & \multicolumn{1}{c}{017:16:52} & 027:49:15 \\
 & StrategyQA & \multicolumn{1}{c}{59.61} & \multicolumn{1}{c|}{58.87} & 36.21 & \multicolumn{1}{c|}{33.0} & 39.26 & \multicolumn{1}{c|}{43.93} & 0.9 & \multicolumn{1}{c|}{0.89} & 11.37 & \multicolumn{1}{c|}{18.01} & \multicolumn{1}{c}{001:43:48} & 002:43:34 \\ \hline
 


\end{tabular}
}
\caption{Confidence elicitation can also serve as a proxy for ranking the importance of words in the input.}
  \label{appendix:tab:delete_word_ranking_schema_ablation}
\end{table*}


\subsection{Simple confidence elicitation attacks}
We can replace the Dirichlet aggregator by setting \( k = 1 \), and instead of using verbal confidence (VC), we employ numerical verbal confidence (NVC). In this approach, we ask the model to provide its confidence numerically as a value between 0 and 1 for a prediction. We find that the performance of the attack is lower (Table \ref{appendix:simple-confidence-elicitation}), likely due to having a weaker feedback signal with less fine-grained thresholds. 
% Furthermore, we observe a similar finding from previous work \citep{Confidence_Elicitation} where models tend to be overconfident about their answers. We experience this issue less with verbalized confidence, as the model often outputs responses like 'Low' or 'Lowest' as its confidence level.


% \begin{table}[h]
% \centering
% \scalebox{0.55}{
% \begin{tabular}{lllccccccccccc}
% \hline
% \multicolumn{14}{c}{\textbf{Confidence Elicitation Attack with a simple confidence elicitation technique}} \\ \hline
% \textbf{Model} & \textbf{Dataset} & \multicolumn{1}{c}{\textbf{CA {[}\%{]} ↑}} & \textbf{AUA {[}\%{]} ↓} & \textbf{ASR {[}\%{]} ↑} & \textbf{SemSim ↑} & \textbf{\begin{tabular}[c]{@{}c@{}}Original \\ Perplexity ↓\end{tabular}} & \textbf{\begin{tabular}[c]{@{}c@{}}After-Attack\\ Perplexity ↓\end{tabular}} & \textbf{\begin{tabular}[c]{@{}c@{}}All Att \\ Queries \\ Avg ↓\end{tabular}} & \textbf{\begin{tabular}[c]{@{}c@{}}Succ Att\\ Queries \\ Avg ↓\end{tabular}} & \multicolumn{4}{c}{\textbf{\begin{tabular}[c]{@{}c@{}}Total Attack Time \\ {[}HHH:MM:SS{]} ↓\end{tabular}}} \\ \hline
% \multirow{2}{*}{\begin{tabular}[c]{@{}l@{}}LLaMa-3-8B\\ Instruct\end{tabular}} & SST2 & 91.2 & \multicolumn{1}{l}{76.0} & \multicolumn{1}{l}{16.67} & \multicolumn{1}{l}{0.89} & \multicolumn{1}{l}{64.53} & \multicolumn{1}{l}{86.69} & \multicolumn{1}{l}{34.67} & \multicolumn{1}{l}{29.5} & \multicolumn{4}{c}{005:11:15} \\
%  & StrategyQA & 65.0 & \multicolumn{1}{l}{48.2} & \multicolumn{1}{l}{25.85} & \multicolumn{1}{l}{0.89} & \multicolumn{1}{l}{114.5} & \multicolumn{1}{l}{196.14} & \multicolumn{1}{l}{9.46} & \multicolumn{1}{l}{12.22} & \multicolumn{4}{c}{000:52:20} \\ \hline
%   \end{tabular}
% }
% \caption{Confidence Elicitation Attack with a simple confidence elicitation technique}\label{appendix:simple-confidence-elicitation}
% \end{table}

\begin{table}[h]
\centering
\scalebox{0.65}{ 
\begin{tabular}{lllccccccccccc}
\hline
\multicolumn{14}{c}{\textbf{Confidence Elicitation Attack with a simple confidence elicitation technique}} \\ \hline
\textbf{Model} & \textbf{Dataset} & \multicolumn{2}{c}{\textbf{CA {[}\%{]} ↑}} & \textbf{AUA {[}\%{]} ↓} & \textbf{ASR {[}\%{]} ↑} & \textbf{SemSim ↑} & \multicolumn{3}{c}{\textbf{\begin{tabular}[c]{@{}c@{}}Succ Att\\ Queries \\ Avg ↓\end{tabular}}} & \multicolumn{4}{c}{\textbf{\begin{tabular}[c]{@{}c@{}}Total Attack Time \\ {[}HHH:MM:SS{]} ↓\end{tabular}}} \\ \hline
\multirow{4}{*}{\begin{tabular}[c]{@{}l@{}}LLaMa-3-8B\\ Instruct\end{tabular}} & \multirow{2}{*}{SST2} & NVC & \multicolumn{1}{l}{91.2} & \multicolumn{1}{l}{76.0} & \multicolumn{1}{l}{16.67} & \multicolumn{1}{l}{0.89} & \multicolumn{3}{l}{29.5} & \multicolumn{4}{c}{005:11:15} \\
 &  & Dirichlet+VC & \multicolumn{1}{l}{90.56} & \multicolumn{1}{l}{72.69} & \multicolumn{1}{l}{19.73} & \multicolumn{1}{l}{0.88} & \multicolumn{3}{l}{25.60} & \multicolumn{4}{c}{017:30:57} \\ \cline{2-14} 
 & \multirow{2}{*}{StrategyQA} & NVC & \multicolumn{1}{l}{65.0} & \multicolumn{1}{l}{48.2} & \multicolumn{1}{l}{25.85} & \multicolumn{1}{l}{0.89} & \multicolumn{3}{l}{12.22} & \multicolumn{4}{c}{000:52:20} \\
 &  & Dirichlet+VC & \multicolumn{1}{l}{60.12} & \multicolumn{1}{l}{32.67} & \multicolumn{1}{l}{45.67} & \multicolumn{1}{l}{0.89} & \multicolumn{3}{l}{10.95} & \multicolumn{4}{c}{001:25:34} \\ \hline
  \end{tabular}
}
\caption{Confidence Elicitation Attack with a simple confidence elicitation technique}\label{appendix:simple-confidence-elicitation}
\end{table}


\section{Qualitative examples}\label{qualitative_examples}
 

Word substitutions using Counter-fitted embeddings are already constrained in terms of semantics due to the pre-built nature of the dictionary. This ensures that each word can only be replaced with a previously vetted synonym. Compared to ``Self-Fool Word Sub" and SSPAttack our method more effectively preserves the original meaning of the text, as evidenced by the high ``SemSim" in Table \ref{tab:elicitation_attacks_table_quality}. Table \ref{tab:qualitative_samples} provides multiple examples from SST2 that have been perturbed by our proposed technique, CEAttack demonstrating conversions of examples from Positive to Negative and from Negative to Positive sentiment. Additional examples for AG-News and StrategyQA can be found in Table \ref{appendix:tab:qualitative_samples_ag_news} and Table \ref{appendix:tab:qualitative_samples_strategyQA} in the `More qualitative examples' Section \ref{appendix:more_qualitative_examples}.


\begin{table}[ht]
\centering
\scalebox{0.50}{
\begin{tabular}{llcccccccccccccl}

\hline
\multicolumn{12}{l}{\textbf{\begin{tabular}[c]{@{}l@{}}Qualitative Example\\ SST2 (Sentiment Classification)\end{tabular}}} \\ \hline
\textbf{Technique} & \multicolumn{5}{l}{\textbf{Sample}} & \textbf{SemSim} & \textbf{Perplexity} & \textbf{\begin{tabular}[c]{@{}c@{}}Perturbed \\ Words\end{tabular}} & \textbf{\begin{tabular}[c]{@{}c@{}}Ground \\ Truth\end{tabular}} & \textbf{Prediction} & \multicolumn{1}{c}{\textbf{\begin{tabular}[c]{@{}c@{}}Empirical\\ Mean (Score)\end{tabular}}} \\ \hline
Original & \multicolumn{5}{l}{\begin{tabular}[c]{@{}l@{}}there is nothing outstanding about this film, but it is good \\ enough and will likely be appreciated most by sailors and \\ folks who know their way around a submarine.\end{tabular}} & - & 48.59 & - & Positive & Positive & \multicolumn{1}{c}{0.48} \\
\begin{tabular}[c]{@{}l@{}}CEAttack\\ (Ours)\end{tabular} & \multicolumn{5}{l}{\begin{tabular}[c]{@{}l@{}}there is nothing outstanding about this film, but it is \\ \textbf{appropriate} enough and will likely be appreciated most by\\  sailors and \textbf{males} who know their \textbf{routes} around a submarine.\end{tabular}} & 0.85 & 114.7 & 3 & Positive & Negative & \multicolumn{1}{c}{0.90} \\ \hline
Original & \multicolumn{5}{l}{\begin{tabular}[c]{@{}l@{}}the movie achieves as great an impact by keeping these \\ thoughts hidden as ... (quills) did by showing them.\end{tabular}} & - & 407.19 & - & Positive & Positive & \multicolumn{1}{c}{0.40} \\
\begin{tabular}[c]{@{}l@{}}CEAttack\\ (Ours)\end{tabular} & \multicolumn{5}{l}{\begin{tabular}[c]{@{}l@{}}the \textbf{filmmakers} \textbf{obtains} as \textbf{formidable} an impact by keeping \\ these thoughts hidden as ... (\textbf{plume}) did by showing them.\end{tabular}} & 0.84 & 616.55 & 4 & Positive & Negative & \multicolumn{1}{c}{0.50} \\ \hline
Original & \multicolumn{5}{l}{\begin{tabular}[c]{@{}l@{}}combining quick-cut editing and a blaring heavy metal much\\ of the time, beck seems to be under the illusion that he's \\ shooting the latest system of a down video.\end{tabular}} & - & 328.26 & - & Negative & Negative & \multicolumn{1}{c}{0.26} \\
\begin{tabular}[c]{@{}l@{}}CEAttack\\ (Ours)\end{tabular} & \multicolumn{5}{l}{\begin{tabular}[c]{@{}l@{}}\textbf{mixing} quick-cut editing and a \textbf{thundering} heavy metal much \\ of the \textbf{periods}, beck \textbf{appear} to \textbf{get} under the \textbf{trickery} that he's\\  shooting the latest system of a down video.\end{tabular}} & 0.84 & 571.93 & 6 & Negative & Positive & \multicolumn{1}{c}{0.75} \\ \hline
Original & \multicolumn{5}{l}{\begin{tabular}[c]{@{}l@{}}schaeffer has to find some hook on which to hang his \\ persistently useless movies, and it might as well be the \\ resuscitation of the middle-aged character.\end{tabular}} & - & 95.63 & - & Negative & Negative & \multicolumn{1}{c}{0.39} \\
\begin{tabular}[c]{@{}l@{}}CEAttack\\ (Ours)\end{tabular} & \multicolumn{5}{l}{\begin{tabular}[c]{@{}l@{}}\textbf{colson} has to find some hook on which to hang his persistently \\ \textbf{incongruous film}, and it \textbf{may} as \textbf{alright} \textbf{get} the resuscitation of \\ the middle-aged character.\end{tabular}} & 0.84 & 157.87 & 6 & Negative & Positive & \multicolumn{1}{c}{0.65} \\ \hline

\end{tabular}
}
\caption{Confidence elicitation attacks and their confidence levels. Perturbed words are in \textbf{bold}.}
\label{tab:qualitative_samples}
\end{table}


\section{More Qualitative examples}\label{appendix:more_qualitative_examples}

\subsection{Ag News}

% \begin{table*}[ht]
% \centering
% \scalebox{0.60}{
% \begin{tabular}{llcccccccccccccl}

% \hline
% \multicolumn{12}{l}{\textbf{\begin{tabular}[c]{@{}l@{}}Qualitative Example\\ AG-News (News Classification) LLaMa-3-8B-Instruct\end{tabular}}} \\ \hline
% \textbf{Technique} & \multicolumn{5}{l}{\textbf{Sample}} & \textbf{SemSim} & \textbf{Perplexity} & \textbf{\begin{tabular}[c]{@{}c@{}}Perturbed \\ Words\end{tabular}} & \textbf{\begin{tabular}[c]{@{}c@{}}Ground \\ Truth\end{tabular}} & \textbf{Prediction} & \multicolumn{1}{c}{\textbf{\begin{tabular}[c]{@{}c@{}}Empirical\\ Mean (Score)\end{tabular}}} \\ \hline
% Original & \multicolumn{5}{l}{\begin{tabular}[c]{@{}l@{}}Producer sues for Rings profits Hollywood producer Saul \\ Zaentz sues the producers of The Lord of the Rings for \$20m \\ in royalties.,\end{tabular}} & \multicolumn{1}{l}{-} & \multicolumn{1}{l}{257.14} & \multicolumn{1}{l}{-} & \multicolumn{1}{l}{World} & \multicolumn{1}{l}{World} & 0.50 \\
% \begin{tabular}[c]{@{}l@{}}CEAttack\\ (Ours)\end{tabular} & \multicolumn{5}{l}{\begin{tabular}[c]{@{}l@{}}Producing sues for Rings profits Hollywood producer Saul \\ Zaentz sues the producers of The Lord of the Rings for \$20m \\ in royalties.\end{tabular}} & \multicolumn{1}{l}{0.94} & \multicolumn{1}{l}{325.36} & \multicolumn{1}{l}{1} & \multicolumn{1}{l}{World} & \multicolumn{1}{l}{Business} & 0.66 \\ \hline
% Original & \multicolumn{5}{l}{\begin{tabular}[c]{@{}l@{}}Injured Heskey to miss England friendly NEWCASTLE, \\ England (AP) - Striker Emile Heskey has pulled out of the \\ England squad ahead of Wednesday \#39;s friendly against \\ Ukraine because of a tight hamstring, the Football \\ Association said Tuesday.\end{tabular}} & \multicolumn{1}{l}{-} & \multicolumn{1}{l}{213.64} & \multicolumn{1}{l}{-} & \multicolumn{1}{l}{Sport} & \multicolumn{1}{l}{Sport} & 0.46 \\
% \begin{tabular}[c]{@{}l@{}}CEAttack\\ (Ours)\end{tabular} & \multicolumn{5}{l}{\begin{tabular}[c]{@{}l@{}}Wound Heskey to senorita England friendly NEWCASTLE,\\  English (AP) - Striker Emile Heskey has pulled out of the \\ Britannica squad ahead of Wednesday \#39;s friendly against \\ Ukraine because of a intensive hamstring, the Football \\ Association said Tuesday.\end{tabular}} & \multicolumn{1}{l}{0.87} & \multicolumn{1}{l}{354.76} & \multicolumn{1}{l}{5} & \multicolumn{1}{l}{Sport} & \multicolumn{1}{l}{World} & 0.57 \\ \hline
% Original & \multicolumn{5}{l}{\begin{tabular}[c]{@{}l@{}}SEC may put end to quid pro quo (USATODAY.com) \\ USATODAY.com - The Securities and Exchange Commission \\ is expected to vote Wednesday to prohibit mutual fund \\ companies from funneling stock trades to brokerage firms that\\ agree to promote their funds to investors.\end{tabular}} & \multicolumn{1}{l}{-} & \multicolumn{1}{l}{56.46} & \multicolumn{1}{l}{-} & \multicolumn{1}{l}{Business} & \multicolumn{1}{l}{Business} & 0.47 \\
% \begin{tabular}[c]{@{}l@{}}CEAttack\\ (Ours)\end{tabular} & \multicolumn{5}{l}{\begin{tabular}[c]{@{}l@{}}SEC may put ends to quid pro quo (USATODAY.com) \\ USATODAY.com - The Securities and Exchange Commission \\ is expected to voices Wednesday to prohibit reciprocated fund \\ companies from funneling stock trades to brokerage firms that \\ ok to promote their funds to investors.\end{tabular}} & \multicolumn{1}{l}{0.87} & \multicolumn{1}{l}{140.03} & \multicolumn{1}{l}{4} & \multicolumn{1}{l}{Business} & \multicolumn{1}{l}{World} & 0.6 \\ \hline
% Original & \multicolumn{5}{l}{\begin{tabular}[c]{@{}l@{}}IBM Seeks To Have SCO Claims Dismissed (NewsFactor) \\ NewsFactor - IBM (NYSE: IBM) has -- again -- sought to have \\ the pending legal claims by The SCO Group dismissed. According \\ to a motion it filed in a U.S. district court, IBM argues that SCO \\ has no evidence to support its claims that it appropriated \\ confidential source code from Unix System V and placed it in \\ Linux.\end{tabular}} & \multicolumn{1}{l}{-} & \multicolumn{1}{l}{95.57} & \multicolumn{1}{l}{-} & \multicolumn{1}{l}{Sci/Tech} & \multicolumn{1}{l}{Sci/Tech} & 0.61 \\
% \begin{tabular}[c]{@{}l@{}}CEAttack\\ (Ours)\end{tabular} & \multicolumn{5}{l}{\begin{tabular}[c]{@{}l@{}}IBM Seeks To Have SCO Claims Dismissed (NewsFactor) \\ NewsFactor - IBM (NYSE: IBM) has -- again -- sought to have \\ the pending legal claims by The SCO Clusters dismissed. According \\ to a motion it filed in a U.S. district court, IBM argues that SCO has \\ no evidence to support its claims that it appropriated confidential \\ source code from Unix System volts and placed it in Linux.\end{tabular}} & \multicolumn{1}{l}{0.94} & \multicolumn{1}{l}{111.51} & \multicolumn{1}{l}{2} & \multicolumn{1}{l}{Sci/Tech} & \multicolumn{1}{l}{Business} & 0.63 \\ \hline


% \end{tabular}
% }
% \caption{Examples of confidence elicitation attacks and their respective confidence levels: Top) A positive example perturbed to negative, Bottom) A negative example perturbed to positive. Perturbed words are in \textbf{bold}.}
%   \label{appendix:tab:qualitative_samples_ag_news}
% \end{table*}

\begin{table*}[ht]
\centering
\scalebox{0.60}{
\begin{tabular}{llcccccccccccccl}

\hline
\multicolumn{12}{l}{\textbf{\begin{tabular}[c]{@{}l@{}}Qualitative Example\\ AG-News (News Classification) LLaMa-3-8B-Instruct\end{tabular}}} \\ \hline
\textbf{Technique} & \multicolumn{5}{l}{\textbf{Sample}} & \textbf{SemSim} & \textbf{Perplexity} & \textbf{\begin{tabular}[c]{@{}c@{}}Perturbed \\ Words\end{tabular}} & \textbf{\begin{tabular}[c]{@{}c@{}}Ground \\ Truth\end{tabular}} & \textbf{Prediction} & \multicolumn{1}{c}{\textbf{\begin{tabular}[c]{@{}c@{}}Empirical\\ Mean (Score)\end{tabular}}} \\ \hline
Original & \multicolumn{5}{l}{\begin{tabular}[c]{@{}l@{}}Producer sues for Rings profits Hollywood producer Saul \\ Zaentz sues the producers of The Lord of the Rings for \$20m \\ in royalties.,\end{tabular}} & \multicolumn{1}{l}{-} & \multicolumn{1}{l}{257.14} & \multicolumn{1}{l}{-} & \multicolumn{1}{l}{World} & \multicolumn{1}{l}{World} & 0.50 \\
\begin{tabular}[c]{@{}l@{}}CEAttack\\ (Ours)\end{tabular} & \multicolumn{5}{l}{\begin{tabular}[c]{@{}l@{}}\textbf{Producing} sues for Rings profits Hollywood producer Saul \\ Zaentz sues the producers of The Lord of the Rings for \$20m \\ in royalties.\end{tabular}} & \multicolumn{1}{l}{0.94} & \multicolumn{1}{l}{325.36} & \multicolumn{1}{l}{1} & \multicolumn{1}{l}{World} & \multicolumn{1}{l}{Business} & 0.66 \\ \hline
Original & \multicolumn{5}{l}{\begin{tabular}[c]{@{}l@{}}Injured Heskey to miss England friendly NEWCASTLE, \\ England (AP) - Striker Emile Heskey has pulled out of the \\ England squad ahead of Wednesday \#39;s friendly against \\ Ukraine because of a tight hamstring, the Football \\ Association said Tuesday.\end{tabular}} & \multicolumn{1}{l}{-} & \multicolumn{1}{l}{213.64} & \multicolumn{1}{l}{-} & \multicolumn{1}{l}{Sport} & \multicolumn{1}{l}{Sport} & 0.46 \\
\begin{tabular}[c]{@{}l@{}}CEAttack\\ (Ours)\end{tabular} & \multicolumn{5}{l}{\begin{tabular}[c]{@{}l@{}}\textbf{Wound} Heskey to \textbf{senorita} England friendly NEWCASTLE,\\  \textbf{English} (AP) - Striker Emile Heskey has pulled out of the \\ \textbf{Britannica} squad ahead of Wednesday \#39;s friendly against \\ Ukraine because of a \textbf{intensive} hamstring, the Football \\ Association said Tuesday.\end{tabular}} & \multicolumn{1}{l}{0.87} & \multicolumn{1}{l}{354.76} & \multicolumn{1}{l}{5} & \multicolumn{1}{l}{Sport} & \multicolumn{1}{l}{World} & 0.57 \\ \hline
Original & \multicolumn{5}{l}{\begin{tabular}[c]{@{}l@{}}SEC may put end to quid pro quo (USATODAY.com) \\ USATODAY.com - The Securities and Exchange Commission \\ is expected to vote Wednesday to prohibit mutual fund \\ companies from funneling stock trades to brokerage firms that\\ agree to promote their funds to investors.\end{tabular}} & \multicolumn{1}{l}{-} & \multicolumn{1}{l}{56.46} & \multicolumn{1}{l}{-} & \multicolumn{1}{l}{Business} & \multicolumn{1}{l}{Business} & 0.47 \\
\begin{tabular}[c]{@{}l@{}}CEAttack\\ (Ours)\end{tabular} & \multicolumn{5}{l}{\begin{tabular}[c]{@{}l@{}}SEC may put \textbf{ends} to quid pro quo (USATODAY.com) \\ USATODAY.com - The Securities and Exchange Commission \\ is expected to \textbf{voices} Wednesday to prohibit \textbf{reciprocated} fund \\ companies from funneling stock trades to brokerage firms that \\ \textbf{ok} to promote their funds to investors.\end{tabular}} & \multicolumn{1}{l}{0.87} & \multicolumn{1}{l}{140.03} & \multicolumn{1}{l}{4} & \multicolumn{1}{l}{Business} & \multicolumn{1}{l}{World} & 0.6 \\ \hline
Original & \multicolumn{5}{l}{\begin{tabular}[c]{@{}l@{}}IBM Seeks To Have SCO Claims Dismissed (NewsFactor) \\ NewsFactor - IBM (NYSE: IBM) has -- again -- sought to have \\ the pending legal claims by The SCO Group dismissed. According \\ to a motion it filed in a U.S. district court, IBM argues that SCO \\ has no evidence to support its claims that it appropriated \\ confidential source code from Unix System V and placed it in \\ Linux.\end{tabular}} & \multicolumn{1}{l}{-} & \multicolumn{1}{l}{95.57} & \multicolumn{1}{l}{-} & \multicolumn{1}{l}{Sci/Tech} & \multicolumn{1}{l}{Sci/Tech} & 0.61 \\
\begin{tabular}[c]{@{}l@{}}CEAttack\\ (Ours)\end{tabular} & \multicolumn{5}{l}{\begin{tabular}[c]{@{}l@{}}IBM Seeks To Have SCO Claims Dismissed (NewsFactor) \\ NewsFactor - IBM (NYSE: IBM) has -- again -- sought to have \\ the pending legal claims by The SCO \textbf{Clusters} dismissed. According \\ to a motion it filed in a U.S. district court, IBM argues that SCO has \\ no evidence to support its claims that it appropriated confidential \\ source code from Unix System \textbf{volts} and placed it in Linux.\end{tabular}} & \multicolumn{1}{l}{0.94} & \multicolumn{1}{l}{111.51} & \multicolumn{1}{l}{2} & \multicolumn{1}{l}{Sci/Tech} & \multicolumn{1}{l}{Business} & 0.63 \\ \hline

\end{tabular}
}
\caption{Examples of confidence elicitation attacks and their respective confidence levels: Top) A positive example perturbed to negative, Bottom) A negative example perturbed to positive. Perturbed words are in \textbf{bold}.}
  \label{appendix:tab:qualitative_samples_ag_news}
\end{table*}
\subsection{Strategy QA}
\begin{table*}[ht]
\centering
\scalebox{0.60}{
\begin{tabular}{llcccccccccccccl}

\hline
\multicolumn{12}{l}{\textbf{\begin{tabular}[c]{@{}l@{}}Qualitative Example\\ StrategyQA (Reasoning Classification) LLaMa-3-8B-Instruct\end{tabular}}} \\ \hline
\textbf{Technique} & \multicolumn{5}{l}{\textbf{Sample}} & \textbf{SemSim} & \textbf{Perplexity} & \textbf{\begin{tabular}[c]{@{}c@{}}Perturbed \\ Words\end{tabular}} & \textbf{\begin{tabular}[c]{@{}c@{}}Ground \\ Truth\end{tabular}} & \textbf{Prediction} & \multicolumn{1}{c}{\textbf{\begin{tabular}[c]{@{}c@{}}Empirical\\ Mean (Score)\end{tabular}}} \\ \hline
Original & \multicolumn{5}{l}{\begin{tabular}[c]{@{}l@{}}Did the Wehrmacht affect the outcome of the War to End All \\ Wars?\end{tabular}} & \multicolumn{1}{l}{-} & \multicolumn{1}{l}{33.2} & \multicolumn{1}{l}{-} & \multicolumn{1}{l}{False} & \multicolumn{1}{l}{False} & 0.49 \\
\begin{tabular}[c]{@{}l@{}}CEAttack\\ (Ours)\end{tabular} & \multicolumn{5}{l}{\begin{tabular}[c]{@{}l@{}}Did the Wehrmacht \textbf{impacting} the outcome of the War to \\ \textbf{Conclude} All Wars?\end{tabular}} & \multicolumn{1}{l}{0.89} & \multicolumn{1}{l}{112.07} & \multicolumn{1}{l}{2} & \multicolumn{1}{l}{False} & \multicolumn{1}{l}{True} & 0.62 \\
Explanation & \multicolumn{11}{l}{\begin{tabular}[c]{@{}l@{}}The Wehrmacht was the unified military of Germany from \\ 1935 to 1945 The War to End All Wars is a nickname for \\ World War I World War I ended in 1918\end{tabular}} \\ \hline
Original & \multicolumn{5}{l}{Does Mercury make for good Slip N Slide material?} & \multicolumn{1}{l}{-} & \multicolumn{1}{l}{1224.48} & \multicolumn{1}{l}{-} & \multicolumn{1}{l}{False} & \multicolumn{1}{l}{False} & 0.13 \\
\begin{tabular}[c]{@{}l@{}}CEAttack\\ (Ours)\end{tabular} & \multicolumn{5}{l}{Does Mercury \textbf{deliver} for \textbf{best} Slip N Slide material?} & \multicolumn{1}{l}{0.86} & \multicolumn{1}{l}{5038.86} & \multicolumn{1}{l}{2} & \multicolumn{1}{l}{False} & \multicolumn{1}{l}{True} & 0.62 \\
Explanation & \multicolumn{11}{l}{\begin{tabular}[c]{@{}l@{}}The Slip N Slide was an outdoor water slide toy. Mercury \\ is a thick liquid at room temperature. Mercury is \\ poisonous and used to kill hatters that lined their hats with \\ the substance.\end{tabular}} \\ \hline
Original & \multicolumn{5}{l}{Would human race go extinct without chlorophyll?} & \multicolumn{1}{l}{-} & \multicolumn{1}{l}{91.15} & \multicolumn{1}{l}{-} & \multicolumn{1}{l}{True} & \multicolumn{1}{l}{True} & 0.43 \\
\begin{tabular}[c]{@{}l@{}}CEAttack\\ (Ours)\end{tabular} & \multicolumn{5}{l}{Would \textbf{humanistic} race \textbf{will extinct} without chlorophyll?} & \multicolumn{1}{l}{0.85} & \multicolumn{1}{l}{433.3} & \multicolumn{1}{l}{3} & \multicolumn{1}{l}{True} & \multicolumn{1}{l}{False} & 0.69 \\
Explanation & \multicolumn{11}{l}{\begin{tabular}[c]{@{}l@{}}Chlorophyll is a pigment in plants responsible for \\ photosynthesis. Photosynthesis is the process by which \\ plants release oxygen into the atmosphere. Humans need \\ oxygen to live.\end{tabular}} \\ \hline
Original & \multicolumn{5}{l}{\begin{tabular}[c]{@{}l@{}}Are more people today related to Genghis Khan than Julius \\ Caesar?\end{tabular}} & \multicolumn{1}{l}{-} & \multicolumn{1}{l}{294.74} & \multicolumn{1}{l}{-} & \multicolumn{1}{l}{True} & \multicolumn{1}{l}{True} & 0.34 \\
\begin{tabular}[c]{@{}l@{}}CEAttack\\ (Ours)\end{tabular} & \multicolumn{5}{l}{\begin{tabular}[c]{@{}l@{}}Are more people today \textbf{connected} to Genghis Khan than Julius \\ Caesar?\end{tabular}} & \multicolumn{1}{l}{0.94} & \multicolumn{1}{l}{289.71} & \multicolumn{1}{l}{1} & \multicolumn{1}{l}{True} & \multicolumn{1}{l}{False} & 0.54 \\
Explanation & \multicolumn{11}{l}{\begin{tabular}[c]{@{}l@{}}Julius Caesar had three children. Genghis Khan had sixteen \\ children. Modern geneticists have determined that out of every \\ 200 men today has DNA that can be traced to Genghis Khan.\end{tabular}} \\ \hline

\end{tabular}
}
\caption{Examples of confidence elicitation attacks and their respective confidence levels: Top) A positive example perturbed to negative, Bottom) A negative example perturbed to positive. Perturbed words are in \textbf{bold}.}
  \label{appendix:tab:qualitative_samples_strategyQA}
\end{table*}
% \begin{table*}[ht]
% \centering
% \scalebox{0.60}{
% \begin{tabular}{llcccccccccccccl}

% \hline
% \multicolumn{12}{l}{\textbf{\begin{tabular}[c]{@{}l@{}}Qualitative Example\\ StrategyQA (Reasoning Classification) LLaMa-3-8B-Instruct\end{tabular}}} \\ \hline
% \textbf{Technique} & \multicolumn{5}{l}{\textbf{Sample}} & \textbf{SemSim} & \textbf{Perplexity} & \textbf{\begin{tabular}[c]{@{}c@{}}Perturbed \\ Words\end{tabular}} & \textbf{\begin{tabular}[c]{@{}c@{}}Ground \\ Truth\end{tabular}} & \textbf{Prediction} & \multicolumn{1}{c}{\textbf{\begin{tabular}[c]{@{}c@{}}Empirical\\ Mean (Score)\end{tabular}}} \\ \hline
% Original & \multicolumn{5}{l}{\begin{tabular}[c]{@{}l@{}}Did the Wehrmacht affect the outcome of the War to End All \\ Wars?\end{tabular}} & \multicolumn{1}{l}{-} & \multicolumn{1}{l}{33.2} & \multicolumn{1}{l}{-} & \multicolumn{1}{l}{False} & \multicolumn{1}{l}{False} & 0.49 \\
% \begin{tabular}[c]{@{}l@{}}CEAttack\\ (Ours)\end{tabular} & \multicolumn{5}{l}{\begin{tabular}[c]{@{}l@{}}Did the Wehrmacht impacting the outcome of the War to \\ Conclude All Wars?\end{tabular}} & \multicolumn{1}{l}{0.89} & \multicolumn{1}{l}{112.07} & \multicolumn{1}{l}{2} & \multicolumn{1}{l}{False} & \multicolumn{1}{l}{True} & 0.62 \\
% Explenation & \multicolumn{11}{l}{\begin{tabular}[c]{@{}l@{}}The Wehrmacht was the unified military of Germany from \\ 1935 to 1945 The War to End All Wars is a nickname for \\ World War I World War I ended in 1918\end{tabular}} \\ \hline
% Original & \multicolumn{5}{l}{Does Mercury make for good Slip N Slide material?} & \multicolumn{1}{l}{-} & \multicolumn{1}{l}{1224.48} & \multicolumn{1}{l}{-} & \multicolumn{1}{l}{False} & \multicolumn{1}{l}{False} & 0.13 \\
% \begin{tabular}[c]{@{}l@{}}CEAttack\\ (Ours)\end{tabular} & \multicolumn{5}{l}{Does Mercury deliver for best Slip N Slide material?} & \multicolumn{1}{l}{0.86} & \multicolumn{1}{l}{5038.86} & \multicolumn{1}{l}{2} & \multicolumn{1}{l}{False} & \multicolumn{1}{l}{True} & 0.62 \\
% Explenation & \multicolumn{11}{l}{\begin{tabular}[c]{@{}l@{}}The Slip N Slide was an outdoor water slide toy. Mercury \\ is a thick liquid at room temperature. Mercury is \\ poisonous and used to kill hatters that lined their hats with \\ the substance.\end{tabular}} \\ \hline
% Original & \multicolumn{5}{l}{Would human race go extinct without chlorophyll?} & \multicolumn{1}{l}{-} & \multicolumn{1}{l}{91.15} & \multicolumn{1}{l}{-} & \multicolumn{1}{l}{True} & \multicolumn{1}{l}{True} & 0.43 \\
% \begin{tabular}[c]{@{}l@{}}CEAttack\\ (Ours)\end{tabular} & \multicolumn{5}{l}{Would humanistic race will extinct without chlorophyll?} & \multicolumn{1}{l}{0.85} & \multicolumn{1}{l}{433.3} & \multicolumn{1}{l}{2} & \multicolumn{1}{l}{True} & \multicolumn{1}{l}{False} & 0.69 \\
% Explenation & \multicolumn{11}{l}{\begin{tabular}[c]{@{}l@{}}Chlorophyll is a pigment in plants responsible for \\ photosynthesis. Photosynthesis is the process by which \\ plants release oxygen into the atmosphere. Humans need \\ oxygen to live.\end{tabular}} \\ \hline
% Original & \multicolumn{5}{l}{\begin{tabular}[c]{@{}l@{}}Are more people today related to Genghis Khan than Julius \\ Caesar?\end{tabular}} & \multicolumn{1}{l}{-} & \multicolumn{1}{l}{294.74} & \multicolumn{1}{l}{-} & \multicolumn{1}{l}{True} & \multicolumn{1}{l}{True} & 0.34 \\
% \begin{tabular}[c]{@{}l@{}}CEAttack\\ (Ours)\end{tabular} & \multicolumn{5}{l}{\begin{tabular}[c]{@{}l@{}}Are more people today connected to Genghis Khan than Julius \\ Caesar?\end{tabular}} & \multicolumn{1}{l}{0.94} & \multicolumn{1}{l}{289.71} & \multicolumn{1}{l}{1} & \multicolumn{1}{l}{True} & \multicolumn{1}{l}{False} & 0.54 \\
% Explenation & \multicolumn{11}{l}{\begin{tabular}[c]{@{}l@{}}Julius Caesar had three children. Genghis Khan had sixteen \\ children. Modern geneticists have determined that out of every \\ 200 men today has DNA that can be traced to Genghis Khan.\end{tabular}} \\ \hline


% \end{tabular}
% }
% \caption{Examples of confidence elicitation attacks and their respective confidence levels: Top) A positive example perturbed to negative, Bottom) A negative example perturbed to positive. Perturbed words are in \textbf{bold}.}
%   \label{appendix:tab:qualitative_samples_strategyQA}
% \end{table*}

\end{document}
