@article{Elman1990structure,
  author    = {Elman, J. L.},
  title     = {Finding structure in time},
  journal   = {Cognitive Science},
  volume    = {14},
  number    = {2},
  pages     = {179--211},
  year      = {1990},
  doi       = {10.1207/s15516709cog1402_1},
}

@book{Hopcroft1979introduction,
  author    = {Hopcroft, J. E. and Ullman, J. D.},
  title     = {Introduction to Automata Theory, Languages, and Computation},
  year      = {1979},
  publisher = {Addison-Wesley},
  address   = {Reading, MA},
}

@article{Jurafsky2000speech,
  author    = {Jurafsky, D. and Martin, J. H.},
  title     = {Speech and Language Processing: An Introduction to Natural Language Processing, Computational Linguistics, and Speech Recognition},
  year      = {2000},
  publisher = {Prentice-Hall},
  address   = {Upper Saddle River, NJ},
}

@article{Siegelmann1995computational,
  author    = {Siegelmann, H. T. and Sontag, E. D.},
  title     = {On the computational power of neural networks},
  journal   = {Journal of Computer and System Sciences},
  volume    = {50},
  number    = {1},
  pages     = {132--150},
  year      = {1995},
  doi       = {10.1006/jcss.1995.1007},
}

@misc{cooney2023circuitsvis,
    title = {CircuitsVis},
    author = {Alan Cooney and Neel Nanda},
    year = {2023},
    howpublished = {\url{https://github.com/TransformerLensOrg/CircuitsVis}},
}

@misc{cunningham2023sparseautoencodershighlyinterpretable,
      title={Sparse Autoencoders Find Highly Interpretable Features in Language Models}, 
      author={Hoagy Cunningham and Aidan Ewart and Logan Riggs and Robert Huben and Lee Sharkey},
      year={2023},
      eprint={2309.08600},
      archivePrefix={arXiv},
      primaryClass={cs.LG},
      url={https://arxiv.org/abs/2309.08600}, 
}

@misc{ferrando2024primerinnerworkingstransformerbased,
      title={A Primer on the Inner Workings of Transformer-based Language Models}, 
      author={Javier Ferrando and Gabriele Sarti and Arianna Bisazza and Marta R. Costa-jussà},
      year={2024},
      eprint={2405.00208},
      archivePrefix={arXiv},
      primaryClass={cs.CL},
      url={https://arxiv.org/abs/2405.00208}, 
}

@misc{geva2021transformerfeedforwardlayerskeyvalue,
      title={Transformer Feed-Forward Layers Are Key-Value Memories}, 
      author={Mor Geva and Roei Schuster and Jonathan Berant and Omer Levy},
      year={2021},
      eprint={2012.14913},
      archivePrefix={arXiv},
      primaryClass={cs.CL},
      url={https://arxiv.org/abs/2012.14913}, 
}

@misc{grazzi2024unlockingstatetrackinglinearrnns,
      title={Unlocking State-Tracking in Linear RNNs Through Negative Eigenvalues}, 
      author={Riccardo Grazzi and Julien Siems and Jörg K. H. Franke and Arber Zela and Frank Hutter and Massimiliano Pontil},
      year={2024},
      eprint={2411.12537},
      archivePrefix={arXiv},
      primaryClass={cs.LG},
      url={https://arxiv.org/abs/2411.12537}, 
}

@misc{gurnee2023findingneuronshaystackcase,
      title={Finding Neurons in a Haystack: Case Studies with Sparse Probing}, 
      author={Wes Gurnee and Neel Nanda and Matthew Pauly and Katherine Harvey and Dmitrii Troitskii and Dimitris Bertsimas},
      year={2023},
      eprint={2305.01610},
      archivePrefix={arXiv},
      primaryClass={cs.LG},
      url={https://arxiv.org/abs/2305.01610}, 
}

@misc{merrill2024illusionstatestatespacemodels,
      title={The Illusion of State in State-Space Models}, 
      author={William Merrill and Jackson Petty and Ashish Sabharwal},
      year={2024},
      eprint={2404.08819},
      archivePrefix={arXiv},
      primaryClass={cs.LG},
      url={https://arxiv.org/abs/2404.08819}, 
}

@misc{nikankin2024arithmeticalgorithmslanguagemodels,
      title={Arithmetic Without Algorithms: Language Models Solve Math With a Bag of Heuristics}, 
      author={Yaniv Nikankin and Anja Reusch and Aaron Mueller and Yonatan Belinkov},
      year={2024},
      eprint={2410.21272},
      archivePrefix={arXiv},
      primaryClass={cs.CL},
      url={https://arxiv.org/abs/2410.21272}, 
}

@misc{rai2024practicalreviewmechanisticinterpretability,
      title={A Practical Review of Mechanistic Interpretability for Transformer-Based Language Models}, 
      author={Daking Rai and Yilun Zhou and Shi Feng and Abulhair Saparov and Ziyu Yao},
      year={2024},
      eprint={2407.02646},
      archivePrefix={arXiv},
      primaryClass={cs.AI},
      url={https://arxiv.org/abs/2407.02646}, 
}

@misc{saparov2024transformersstrugglelearnsearch,
      title={Transformers Struggle to Learn to Search}, 
      author={Abulhair Saparov and Srushti Pawar and Shreyas Pimpalgaonkar and Nitish Joshi and Richard Yuanzhe Pang and Vishakh Padmakumar and Seyed Mehran Kazemi and Najoung Kim and He He},
      year={2024},
      eprint={2412.04703},
      archivePrefix={arXiv},
      primaryClass={cs.CL},
      url={https://arxiv.org/abs/2412.04703}, 
}

@misc{wang2022interpretabilitywildcircuitindirect,
      title={Interpretability in the Wild: a Circuit for Indirect Object Identification in GPT-2 small}, 
      author={Kevin Wang and Alexandre Variengien and Arthur Conmy and Buck Shlegeris and Jacob Steinhardt},
      year={2022},
      eprint={2211.00593},
      archivePrefix={arXiv},
      primaryClass={cs.LG},
      url={https://arxiv.org/abs/2211.00593}, 
}

