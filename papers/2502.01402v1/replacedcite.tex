\section{Related Work}
The growing popularity of podcasts has driven research into automated transcription, claim detection, and fact-checking. Early contributions, such as the Spotify Podcast Dataset____, provided valuable large-scale spoken document corpora for natural language processing (NLP). Similarly, datasets for podcast summarization, like those proposed by Manakul et al.____, have advanced understanding in this domain. However, access to these datasets has become increasingly restricted, creating significant gaps in resources for developing robust podcast fact-checking tools.

While datasets for detecting check-worthy claims in political debates exist____, they lack fine-grained annotations for claim types, motivations for fact-checking, and associated claim verification data, limiting their utility in fact-checking scenarios.

General purpose NLP annotation tools like Prodigy\footnote{\url{https://prodi.gy}} exist. There are also text editors for fact-checking____, and systems for live fact-checking of audio streams____ address various aspects of fact-checking. However, these tools are not designed for data annotation. Currently there are no tools specifically designed for podcast annotation that support simultaneous audio playback and transcription annotation. Additionally, there is a lack of fine-grained analysis of claim types and their motivations for fact-checking. Also, an end-to-end dataset for fact-checking podcasts is currently unavailable.