Consider a nonlinear dynamical system characterized by the state $x \in \mathcal{X} \subseteq \mathbb{R}^n$ and control input $u \in \mathcal{U} \subseteq \mathbb{R}^m$, governed by the dynamics $\dot{x}(t) = f(x(t), u(t))$, where the function $f: \mathbb{R}^n \times \mathbb{R}^m \to \mathbb{R}^n$ is locally Lipschitz continuous.
In this work, we assume that the dynamics model $f$ is known; however, it can also be learned from data if unavailable.

We are given a failure set $\mathcal{F} \subseteq \mathcal{X}$ that represents the set of unsafe states for the system (e.g., obstacles for an autonomous ground robot). The system's performance is quantified by the cost function $C(t, x, \ctrlseq)$, given by: 
\begin{equation}
    C(t,x(t), \ctrlseq) = \int_{s=t}^{T} l(x(s)) \, ds + \phi(x(T)),
\end{equation}
where $l: \mathcal{X} \to \mathbb{R}_{\geq 0}$ and $\phi: \mathcal{X} \to \mathbb{R}_{\geq 0}$ are Lipschitz continuous and non-negative functions, representing the running cost over the time horizon $[t, T)$ and the terminal cost at time $T$, respectively. 
$\ctrlseq:[t,T)\rightarrow \mathcal{U}$ is the control signal applied to the system.
Using this premise, we define the main objective of this paper: 

\begin{objective}
\label{obj: Main_obj}
   We aim to synthesize an optimal policy $\pi^*: [t, T) \times \mathcal{X} \to \mathcal{U}$ that minimizes the cost function $C$ while ensuring that the system remains outside the failure set $\mathcal{F}$ at all times. 
\end{objective}


\subsection{State-Constrained Optimal Control Problem}
To achieve the stated objective, the first step is to encode the safety constraint via a function $g: \mathbb{R}^n \to \mathbb{R}$ such that, $\mathcal{F}:= \{x \in \mathcal{X} \mid g(x) > 0\}$. Using these notations, the objective can be formulated as the following State-Constrained Optimal Control Problem (SC-OCP) to compute the value function $V$:
\begin{equation}\label{eq: SC-OCP}
    \begin{aligned}
    V(t, x(t)) = \min_{\ctrlseq}\int_t^{T}&l(x(s)) ds + \phi(x(T))\\
    \text{s.t.} & \; \dot{x} = f(x, u), \\
    & g(x(s)) \leq 0 \quad \forall s \in [t, T]
\end{aligned}
\end{equation}
This SC-OCP enhances the system's performance by minimizing the cost, while maintaining system safety through the state constraint, $g(x) \leq 0$, ensuring that the system avoids the failure set, $\mathcal{F}$. Thus, the policy, $\pi^*$, derived from the solution of this SC-OCP co-optimizes safety and performance. 

\subsection{Epigraph Reformulation}\label{subsec: epigraph}
Directly solving the SC-OCP in \eqref{eq: SC-OCP} presents significant challenges due to the presence of (hard) state constraints. To address this issue, we reformulate the problem in its epigraph form \cite{boyd2004convex}, which transforms the constrained optimization into a more tractable two-stage optimization problem. This reformulation allows us to efficiently obtain a solution to the SC-OCP in \eqref{eq: SC-OCP}. The resulting formulation is given by:
\begin{equation}\label{eq: aux_value_func}
    \begin{aligned}
    V(t, x(t)) = \min_{z \in \mathbb{R^+}} & \; z  \\
    \text{s.t.} & \; \hat{V}(t, x, z) \leq 0,
\end{aligned}
\end{equation}
where $z$ is a non-negative auxiliary optimization variable, and $\hat{V}$ represents the auxiliary value function. Here, $\hat{V}$ is defined as \cite{altarovici2013general}:
% 
\begin{equation}\label{eq: aux_vfunc_def}
\begin{aligned}
    \hat{V}(t, x(t), z) = \min_{\ctrlseq} \max \{C(t, x(t), \ctrlseq) -z, \max_{s \in [t, T]}g(x(s)) \}.
\end{aligned}
\end{equation}
% 
Note that if $\hat{V}(t, x, z) < 0$, it implies that $g(x(s)) < 0$ for all $s \in [t, T]$ . In other words, the system must be outside the failure set at all times; therefore, the system is guaranteed to be safe whenever $\hat{V}(t, x, z) < 0$.

In this reformulated problem, state constraints are effectively eliminated, enabling the use of dynamic programming to characterize the value function, as we explain later in this section. Intuitively, optimal $z$ ($z^*$) can be thought of as the \textit{minimum permissible cost} the policy can incur without compromising on safety. From Equation~\ref{eq: aux_value_func}, it can be inferred that if $z > z^*$, the safety constraint dominates in the max term, resulting in a conservative policy. Conversely, if $z < z^*$, the performance objective takes precedence, leading to a potentially aggressive policy that might compromise safety.

Furthermore, to facilitate solving the epigraph reformulation, $z$ can be treated as a state variable, with its dynamics given by $\dot{z}(t) = -l(x(t))$. This implies that as the trajectory progresses over time, the minimum permissible cost, $z$, decreases by the step cost $l(x)$ at each time step. This allows us to define an augmented system that evolves according to the following dynamics:
\begin{equation}
    \dot{\hat{x}} = \hat{f}(t, \hat{x}, u) := 
    \begin{bmatrix}
        f(t, x, u) \\
        -l(x)
    \end{bmatrix}, \\ 
\end{equation}
% \qquad \qquad \qquad ~~$\forall t \in [0, T),  \ (x, z) \in \mathcal{X} \times \mathbb{R^+},$
where $\hat{x} := [x, z]^T$ represents the augmented state.
With the augmented state representation, it has been shown that the auxiliary value function $\hat{V}(t, x(t), z(t))$ is characterized as the unique continuous viscosity solution of the following Hamilton-Jacobi-Bellman (HJB) partial differential equation (PDE) \cite{altarovici2013general}:
\begin{equation}\label{eq: coopt_pde}
\min\Bigl(-\partial_t \hat{V} - \min_{\ctrlseq} \langle \nabla_{\hat{x}}\hat{V}(t, \hat{x}), \hat{f}(\hat{x}, u)\rangle ,\hat{V} - g(x)\Bigr) = 0,
\end{equation}
$\forall t \in [0,T)$ and $\hat{x} \in \mathcal{X} \times \mathbb{R}$, where $\langle \cdot, \cdot \rangle$ denotes the dot product of vectors. The boundary condition for the PDE is given by:
\begin{equation}\label{eq: terminal_condition}
\hat{V}(T,\hat{x}) = \max\left(\phi(x) - z, g(x)\right), \quad \hat{x} \in \mathcal{X} \times \mathbb{R}.
\end{equation}
Note that by a slight abuse of notations, we have replaced the arguments $x,z$ for $\hat{V}$ with the augmented state $\hat{x}$.
% Building upon this formulation, we state the following theorem to obtain the auxiliary value function $\hat{V}$:
% \begin{theorem}[]\label{thm: aux_hjb_pde}
% For a given state $x \in \mathcal{X} \subseteq \mathbb{R}^n$, $z \in \mathbb{R}^+$ defined over the time horizon $T >0$, the auxiliary value function $\hat{V}$ so obtained from the epigraph form, is characterized as the unique continuous viscosity solution of the following Hamilton-Jacobi-Bellman (HJB) Partial Differential Equation (PDE):
% \begin{equation}\label{eq: coopt_pde}
% \min\Bigl(-\partial_t \hat{V} - \min_{u\in \mathcal{U}}\nabla_{\hat{x}} \hat{V} \cdot \hat{f}(t,\hat{x},u),\hat{V} - g(x)\Bigr) = 0,
% \end{equation}
% for all $t \in [0,T)$ and $(x,z) \in \mathcal{X} \times \mathbb{R}$, with the boundary condition:
% \begin{equation}\label{eq: terminal_condition}
% \hat{V}(T,x,z) = \max\left((\phi(x) - z), g(x)\right), \quad (x,z) \in \mathbb{R}^d \times \mathbb{R}.
% \end{equation}
% \end{theorem}



