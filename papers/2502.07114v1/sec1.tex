
\section{Introduction}\label{sec:1}

We consider the following stochastic optimization problem:
\begin{equation}\label{prob}
\min_{\bx\in\mathbb{R}^d} F(\bx)=\mE_{\P}[f(\bx;\xi)],
\end{equation}
where $F: \mathbb{R}^d \rightarrow \mathbb{R}$ is a stochastic, strongly convex objective function, $f(\cdot;\xi)$ is its noisy observation, and $\xi \sim \P$ is a random variable.
Problems of form \eqref{prob} appear in various decision-making applications in statistics and data science, including online recommendation \citep{Li2010contextual}, precision medicine \citep{Kosorok2019Precision}, energy control \citep{Wallace2005Applications}, portfolio allocation \citep{Fan2012Vast}, and e-commerce  \citep{Chen2022Statistical}.
In these applications, \eqref{prob} is often interpreted as a model parameter estimation problem, where $\bx$ denotes the model parameter and $\xi$ denotes~a~random data sample.~The true model parameter $\bx^{\star} = \argmin_{\bx\in\mathbb{R}^d} F(\bx)$ is the minimizer of the expected~population loss $F$.



The classic offline approach to solving \eqref{prob} is \textit{sample average approximation} or $M$-estimation,~which generates $t$ i.i.d. samples $\xi_1,\dots,\xi_t\sim\mathcal{P}$ and approximates the population loss $F$ by the empirical~loss:
\begin{equation}\label{nequ:1}
\hat{\bx}_t = \argmin_{\bx\in \mR^d} \cbr{\hat{F}_t(\bx) \coloneqq \frac{1}{t}\sum_{i=1}^{t} f(\bx; \xi_i) }.
\end{equation} 
The statistical properties, e.g., $\sqrt{t}$-consistency and asymptotic normality, of $M$-estimators $\hat{\bx}_t$ are well-known in the literature \citep{Vaart1998Asymptotic, Hastie2009Elements}, and numerous deterministic optimization methods can be applied to solve Problem \eqref{nequ:1}, such as gradient descent and Newton's method \citep{Boyd2004Convex}.~However, deterministic methods are not appealing~for~large~datasets~due~to their significant computation and memory costs. In contrast, online methods via \textit{stochastic approximation} have recently attracted much attention. 
These methods efficiently process each sample~once received and then discard, making them well-suited for modern streaming data.~Thus, it is \mbox{particularly} critical to quantify the uncertainty of online methods and leverage the methods to perform \textit{online statistical inference} for model parameters.


One of the most fundamental online methods is stochastic gradient descent (SGD) \citep{Robbins1951Stochastic, Kiefer1952Stochastic}, which takes the form
\begin{equation*}
\bx_{t+1} = \bx_t - \alpha_t \nabla f(\bx_t; \xi_t),\quad t\geq 1.
\end{equation*}
There exists a long sequence of literature that quantifies the uncertainty of SGD and its many~variants. Early works established almost sure convergence and asymptotic normality results of SGD~in restricted settings \citep{Sacks1958Asymptotic, Fabian1968Asymptotic, Robbins1971convergence, Fabian1973Asymptotically, Ljung1977Analysis, Ermoliev1983Stochastic, Lai2003Stochastic}. Later on, \cite{Ruppert1988Efficient, Polyak1992Acceleration} proposed averaging SGD iterates as $\bar{\bx}_t =\sum_{i=1}^{t}\bx_i/t$ and established generic asymptotic normality~results~for~$\bar{\bx}_t$.~This~seminal asymptotic study has then been generalized to other gradient-based methods, including implicit SGD \citep{Toulis2014Statistical, Toulis2017Asymptotic}, constant-stepsize SGD \citep{Li2018Statistical, Mou2020Linear}, moment-adjusted SGD \citep{Liang2019Statistical}, momentum-accelerated SGD \citep{Tang2023Acceleration}, and projected SGD \citep{Duchi2021Asymptotic, Davis2024Asymptotic}. Additionally, studies~under~non-i.i.d. settings have also been reported \citep{Chen2020Statisticala, Liu2023Online, Li2023statistical}. 


With the asymptotic normality result for the averaged iterate $\bar{\bx}_t$ (see \eqref{exp:Omegastar} for the definition~of~$\tOmega$):
\begin{equation}\label{nequ:2}
\sqrt{t}(\barx_t - \tx) \stackrel{d}{\longrightarrow} \mN(0, \tOmega),
\end{equation}
estimating the limiting covariance matrix $\tOmega$ is the crucial next step to perform online statistical inference. While some inferential procedures may bypass the need for this estimation, such as bootstrapping \citep{Fang2018Online, Liu2023Statistical, Zhong2023Online, Lam2023Resampling} and random scaling \citep{Li2021Statistical, Lee2022Fast}, many works have focused on \eqref{nequ:2} and proposed different online covariance matrix estimators for their simplicity and directness. 
In particular, \cite{Chen2020Statistical} proposed two estimators: a plug-in estimator and a batch-means estimator. \mbox{Compared}~to~the plug-in estimator, which averages the estimated objective Hessians and then computes its inverse --- resulting in significant computational costs --- the batch-means estimator is obtained simply through the SGD iterates. \cite{Chen2020Statistical} investigated the~choice~of~batch~sizes~given a~fixed~\mbox{total}~\mbox{sample}~size, while \cite{Zhu2021Online} refined that estimator by not requiring the total sample size being fixed in advance. The two aforementioned works~utilized~increasing~batch~sizes,~which~has been \mbox{relaxed} to~equal~batch~sizes recently by \cite{Zhu2021Constructing} and \cite{Singh2023Utility}.~Combining~the~asymptotic normality~with covariance estimation, we can then construct online confidence intervals~for~model~parameters~$\tx$~based on SGD iterates.


Along with SGD, stochastic Newton methods multiply the gradient direction by a Hessian inverse to incorporate the objective's curvature information, leading to improved and more robust~performance, particularly when dealing with Hessian matrices that have eigenvalues on significantly different scales \citep{Byrd2016Stochastic, Kovalev2019Stochastic, Bercu2020Efficient}. The online \mbox{updating}~scheme~takes the form:
\begin{equation}\label{nequ:3}
\bx_{t+1} = \bx_t + \alpha_t \Delta\bx_t \quad\quad \text{ with }\quad\quad B_t\Delta\bx_t = - \nabla f(\bx_t; \xi_t),
\end{equation}
where $B_t\approx \nabla^2 F(\bx_t)$ is an estimate of the objective Hessian. 
A growing body of literature focuses~on performing (online) statistical inference based on \eqref{nequ:3}. \cite{Leluc2023Asymptotic} considered $B_t$ as a general preconditioning matrix and established the asymptotic normality for the \textit{last} iterate $\bx_t$ assuming the convergence of $B_t$. The authors showed that $\bx_t$ achieves asymptotic efficiency (i.e., minimal covariance) when $B_t \rightarrow \nabla^2 F(\tx)$, corresponding to online Newton methods.
\cite{Bercu2020Efficient} developed an online Newton method for logistic regression and established similar asymptotic normality for $\bx_t$. 
\cite{Cenac2020efficient} and \cite{Boyer2022asymptotic} expanded that approach to more general regression problems and investigated statistical inference on weighted Newton iterates $\bar{\bx}_t = \sum_{i=1}^{t} \bx_i/t$. The above studies revolved around regression~\mbox{problems}~where~the~\mbox{estimated}~Hessian $B_t$ can be expressed as an average of rank-one matrices, allowing its inverse $B_t^{-1}$ to be updated~online by the Sherman-Morrison formula \citep{Sherman1950Adjustment}. However, computing the inverse~of a general estimated Hessian can be computationally demanding, with an $O(d^3)$ time complexity.\quad\quad\quad


To address the above computational bottleneck, \cite{Na2022Statistical} introduced an \textit{online sketched Newton method} that leverages a randomized sketching technique to approximately solve the Newton system \eqref{nequ:3}, without requiring the approximation error to vanish. Specifically,~the~time~complexity can be reduced to $O(\texttt{nnz(S)}d)$, where $S\in\mR^{d\times q}$ is the sketching matrix with $q\ll d$. For instance, when $S$ is a sparse sketching vector, the time complexity is $O(d)$. \cite{Na2022Statistical} quantified the uncertainty of both sampling and sketching and established the asymptotic normality for the last iterate $\bx_t$ of the sketched Newton method (see \eqref{equ:lyap} for the definition of $\tXi$):
\begin{equation}\label{nequ:4}
1/\sqrt{\alpha_t}\cdot(\bx_t-\tx)\stackrel{d}{\longrightarrow}\mN(0, \tXi),
\end{equation}
where the limiting covariance $\tXi\neq \tOmega$ depends on the underlying sketching distribution in a complex manner. Due to the challenges of estimating the sketching components in $\tXi$, the authors~proposed~a plug-in estimator for $\tOmega$ instead. That estimator raises two major concerns.~First,~the~\mbox{plug-in}~estimator is generally not asymptotically consistent, although the bias is controlled by the \mbox{approximation}~error. It is only consistent when solving the Newton system exactly (so that the approximation~error~is zero). The bias significantly compromises the performance of statistical inference.~Second, the~plug-in estimator involves the inversion of the estimated Hessian, leading to an $O(d^3)$ time complexity that contradicts the spirit of using sketching solvers.


Motivated by the limitations of plug-in estimators and the success of batch-means estimators in first-order methods, we propose a novel \textit{weighted sample covariance} estimator for $\tXi$.
Our estimator is constructed entirely from the sketched Newton iterates with varying weights,~and~does~not~\mbox{involve}~any matrix inversion, making it computationally efficient. Additionally, our estimator has a simple~recursive form, aligning well with the online nature of the method. Unlike batch-means estimators~in first-order methods, our estimator is \textit{batch-free}.
We establish the consistency and convergence~rate~of our estimator, and coupled with the asymptotic normality in \eqref{nequ:4}, we can then construct asymptotically valid confidence intervals for the true model parameters $\bx^{\star}$ based on the Newton iterates~$\{\bx_t\}$.
The challenge in our analysis lies in quantifying multiple sources of randomness (sampling, sketching, and adaptive stepsize introduced later); all of them affect the asymptotic behavior of online Newton methods. 
We emphasize that our analysis naturally holds for degenerate designs where the Newton systems are exactly solved and/or the stepsizes are deterministic. To our knowledge, the proposed estimator is the first online construction of a consistent limiting covariance~\mbox{matrix}~estimator for~online second-order methods.~We demonstrate its superior empirical performance through~extensive~experiments on regression problems and benchmark problems from the CUTEst test set.


\vskip0.3cm

\noindent \textbf{Structure of the paper:} 
We introduce the online sketched Newton method in Section \ref{sec:2}, and present assumptions and some preliminary theoretical results in Section \ref{sec:3}. In Section \ref{sec:4}, we~introduce the weighted sample covariance matrix estimator and present its theoretical guarantees. The numerical experiments are provided in Section \ref{sec:5}, followed by conclusions and future work in Section \ref{sec:6}.


\vskip0.3cm

\noindent \textbf{Notation:} 
Throughout the paper, we use $\|\cdot\|$ to denote the $\ell_2$ norm for vectors and the spectral norm for matrices, $\|\cdot\|_F$ to denote the Frobenius norm for matrices, and $\text{Tr}(\cdot)$ to denote the trace of a matrix. We use $O(\cdot)$ and $o(\cdot)$ to denote the big and small $O$ notation in the usual sense. In particular, for two positive sequences $\{a_t, b_t\}$, $a_t=O(b_t)$ (also denoted as $a_t\lesssim b_t$) if $a_t\leq cb_t$ for a positive constant $c$~and all large enough $t$. Analogously, $a_t=o(b_t)$ if $a_t/b_t\rightarrow 0$ as $t\rightarrow\infty$. For two scalars $a$ and $b$, $a\wedge b=\min(a, b)$ and $a\vee b = \max(a,b)$. We let $I$ denote the identity matrix, $\boldsymbol{0}$ denote zero vector~or~matrix, $\boldsymbol{e}_i$ denote the vector with $i$-th entry being 1 and 0 otherwise, and $\boldsymbol{1}$ denote all-ones vector; their dimensions are clear from the context. For a sequence of compatible matrices $\{A_i\}$, $\prod_{k=i}^jA_k = A_j A_{j-1}\cdots A_i$ if $j\geq i$ and $I$ if $j<i$.~For~a~matrix~$A$,~$\lambda_{\min}(A)$~($\lambda_{\max}(A)$)~denotes~the~smallest~(largest) eigenvalue of $A$. We also let~$F_t = F(\bx_t)$ and $F^\star = F(\bx^\star)$ (similar for $\nabla F_t, \nabla^2F_t$, etc.), and let $\mathbf{1}_{\{\cdot\}}$ denote the indicator~function. 
