
\section{Numerical Experiment}\label{sec:5}

In this section, we demonstrate the empirical performance of the weighted sample covariance~\mbox{matrix} $\hat{\Xi}_t$ on both regression problems and benchmark CUTEst problems \citep{Gould2014CUTEst}.~We~\mbox{compare}~$\hat{\Xi}_t$ with two other online covariance estimators: the plug-in estimator $\tilde{\Xi}_t$ in \eqref{exp:PI} 
(based on sketched~Newton) and~the~batch-means~estimator $\bar{\Xi}_t$ (based on SGD) \cite[Algorithm 2]{Zhu2021Online}.~We~evaluate the~performance of each estimator by both the (relative) covariance estimation error and the coverage rate of constructed confidence intervals.~We defer some experimental~results~to~Appendix \ref{appen:exp} due~to~the space limit. {The code is available at \url{https://github.com/weikuang97/SketchedNT-Inf}}.


\subsection{Linear regression}\label{sec5:linear}

We consider the linear regression model $\xi_{b} = \bxi_{a}^T\bx^{\star} + \varepsilon$, where $\xi = (\bxi_a, \xi_b)\in\mR^d\times \mR$ is the feature-response vector and $\varepsilon\sim\mN(0, \sigma^2)$ is the Gaussian noise.~For this model, we use the~squared~loss~defined as $f(\bx; \xi) = \frac{1}{2}(\xi_{b}-\bxi_{a}^T\bx)^2$.~Similar to existing studies \citep{Chen2020Statistical, Zhu2021Online, Na2022Statistical}, we apply Gaussian features $\bxi_a\hskip-1.5pt \sim\hskip-1.5pt \mN(0, \Sigma_a)$ with different dimensions and~covariance matrices $\Sigma_a$. In particular, we vary $d\in\{20, 40, 60, 100\}$, and for each $d$, we consider three~types~of covariance matrices. (i) Identity: $\Sigma_a = I$. (ii) Toeplitz:~$[\Sigma_a]_{i,j} = r^{|i-j|}$~with~\mbox{$r\in\{0.4, 0.5, 0.6\}$}.~(iii)~Equi-correlation: $[\Sigma_a]_{i,i}=1$ and $[\Sigma_a]_{i,j} = r$ for $i\neq j$, with $r\in\{0.1,0.2,0.3\}$. The true model parameter~is set as $\bx^\star = (1/d,\dots,1/d)\in\mR^d$.



For the batch-means estimator $\bar{\Xi}_t$, we adopt the setup in \cite{Zhu2021Online} by setting the~stepsize of SGD as $\beta_t = 0.5t ^{-\beta}$ and the batch size as $a_m \hskip-1pt =\hskip-1pt  \lfloor m^{2/(1-\beta)}\rfloor$ (in their notation) with~\mbox{$\beta = 0.505$}.~For~both plug-in estimator $\tilde{\Xi}_t$ and our sample covariance estimator $\hat{\Xi}_t$, we implement sketched Newton~methods with varying sketching steps $\tau\in\{10,20,40,\infty\}$. When $\tau=\infty$, the scheme reduces to~the~\mbox{standard} Newton method. We apply the Kaczmarz method, where the sketching distribution in \eqref{sec2:equ2}~is~$S\sim \text{Unif}(\{\be_i\}_{i=1}^d)$ (cf. Section \ref{sec:3.1}). We set $\beta_t=t^{-\beta}$ and $\baralpha_t\sim\text{Unif}[\beta_t,\beta_t+\beta_t^2]$. For all estimators,~we initialize the method at $\bx_0=\boldsymbol{0}$, run $3\times 10^5$ iterations, and aim to construct 95\% confidence intervals~for~the averaged parameters $\sum_{i=1}^d\bx^{\star}_i/d$. All the results are averaged over 200 independent~runs.\;


We present the averaged trajectories of relative covariance estimation error and the empirical coverage rate of confidence intervals using three covariance estimators in Figure \ref{fig:1}.
From Figures~\ref{A12} and \ref{A13}, we observe that $\hat{\Xi}_t$ is a consistent estimator for both exact and sketched Newton methods. Additionally, the tails of the green lines (corresponding to $\hat{\Xi}_t$) in both figures form nearly straight lines, with absolute slope values greater than $(1-0.505)/2$. This behavior aligns with the theoretical upper bound established in Theorem \ref{sec4:thm1}. 
Although $\tilde{\Xi}_t$ converges faster than $\hat{\Xi}_t$, it is consistent~only for exact Newton methods. For sketched Newton method, the estimation error of $\tilde{\Xi}_t$ quickly~stabilizes at a positive constant due to the bias introduced by ignoring the sketching effect (cf. \eqref{equ:1}). 
From~Figure \ref{A11}, we see that $\bar{\Xi}_t$ converges more slowly than $\hat{\Xi}_t$, which is also consistent with~the~theoretical~results in \cite{Zhu2021Online}. The estimation error of $\bar{\Xi}_t$ exhibits oscillations along with the batching process. This occurs because the limited sample size in each newly created batch introduces additional errors. This phenomenon is undesirable, as increasing the sample size does not always lead to a reduction in estimation error. Our batch-free estimator effectively resolves this issue.



\begin{figure}[!htp]
\centering     %%% not \center
\subfigure[SGD]{\label{A11}\includegraphics[width=0.32\textwidth]{Figures/Linear/Err_p1.png}}
\subfigure[exact Newton ($\tau=\infty$)]{\label{A12}\includegraphics[width=0.32\textwidth]{Figures/Linear/Err_p2.png}}
\subfigure[sketched Newton ($\tau=2$)]{\label{A13}\includegraphics[width=0.32\textwidth]{Figures/Linear/Err_p3.png}}
\vskip5pt
\centering{Relative covariance estimation error}
	
\subfigure[SGD]{\label{A21}\includegraphics[width=0.32\textwidth]{Figures/Linear/Cov_p1.png}}
\subfigure[exact Newton ($\tau=\infty$)]{\label{A22}\includegraphics[width=0.32\textwidth]{Figures/Linear/Cov_p2.png}}
\subfigure[sketched Newton ($\tau=2$)]{\label{A23}\includegraphics[width=0.32\textwidth]{Figures/Linear/Cov_p3.png}}
\vskip5pt
\centering{Empirical coverage rate of 95\% confidence intervals}	
	
\subfigure[SGD]{\label{A31}\includegraphics[width=0.32\textwidth]{Figures/Linear/Orc_p1.png}}
\subfigure[exact Newton ($\tau=\infty$)]{\label{A32}\includegraphics[width=0.32\textwidth]{Figures/Linear/Orc_p2.png}}
\subfigure[sketched Newton ($\tau=2$)]{\label{A33}\includegraphics[width=0.32\textwidth]{Figures/Linear/Orc_p3.png}}
\vskip5pt
\centering{Empirical coverage rate of 95\% oracle confidence intervals}	
\vskip5pt
\includegraphics[width=0.95\textwidth]{Figures/Linear/legend_plot.png}
\caption{\textit{
The averaged trajectories for linear regression problems with $d=5$ and Equi-correlation $\Sigma_a \;(r=0.3)$. From left to right, the columns correspond to SGD, exact Newton method, and sketched Newton method $(\tau = 2)$. For averaged SGD, the limiting covariance $\Xi^\star$ is estimated~using~the~batch-means estimator $\bar{\Xi}_t$. For exact and sketched Newton methods, $\Xi^\star$ is estimated using both the plug-in estimator $\tilde{\Xi}_t$ and the proposed sample covariance $\hat{\Xi}_t$. 
The first row shows the~log~\mbox{relative}~\mbox{covariance}~estimation error $(\textit{e.g.,}\; \log(\|\hat{\Xi}_t-\Xi^\star\|/\|\Xi^\star\|))$ v.s $\log t$. The second row shows the coverage rate of the 95\% confidence intervals for $\sum_{i=1}^d\bx^{\star}_i/d$ constructed using corresponding estimators of $\Xi^\star$. The third row shows the coverage rate of the oracle 95\% confidence intervals, where the oracle confidence~intervals are constructed using the true covariance $\Xi^\star$. The~figures~demonstrate the consistency of $\hat{\Xi}_t$ and its superior performance in statistical inference.}}\label{fig:1}
\end{figure}



In terms of statistical inference, Figures \ref{A31} - \ref{A33} show that the coverage rates of all oracle confidence intervals -- constructed using the true limiting covariance $\Xi^\star$ under different iterative algorithms -- remain close to the target confidence level of 95\%. This reconfirms the established~asymptotic normality of these algorithms and highlights the importance of accurately estimating $\Xi^\star$ for constructing valid confidence intervals. 
From Figure \ref{A23}, confidence intervals based on $\hat{\Xi}_t$ achieve~a~coverage rate close to 95\%, while those based on $\tilde{\Xi}_t$ exhibit undercoverage due to bias. In Figure \ref{A22},~the~coverage rate trajectories of $\hat{\Xi}_t$ and $\tilde{\Xi}_t$ nearly overlap, indicating that although $\hat{\Xi}_t$ converges slower than $\tilde{\Xi}_t$ in exact Newton method, its accuracy is sufficient for constructing reliable confidence intervals. However, updating $\tilde{\Xi}_t$ is significantly more computationally expensive due to the inverse~of~$B_t$.~Regarding $\bar{\Xi}_t$, Figure \ref{A21} shows that its confidence intervals exhibit undercoverage due to slow convergence. 
Overall, across all figures, we observe that the consistency and fast convergence of $\hat{\Xi}_t$ make it a reliable and computationally efficient choice for constructing confidence intervals.



To comprehensively evaluate the performance of the three estimators in statistical inference,~we present part of results under various settings in Table \ref{table:1}, while a complete table is provided~in~Appendix \ref{appen:exp}. The table reports the empirical coverage rate of the confidence intervals and the averaged relative estimation error in the variance of $\b1^T\tx/d = \sum_{i=1}^d \bx^\star_i/d$, expressed as $\b1^T(\hat{\Xi}_t - \tXi)\b1/\b1^T\Xi^\star\b1$, at the last iteration.
From the table, we observe that, overall, the coverage rate of the confidence intervals based on $\hat{\Xi}_t$ remains around 95\% in most cases. In contrast, the coverage rates for $\tilde{\Xi}_t$ in sketched Newton methods and $\bar{\Xi}_t$ in SGD tend to exhibit undercoverage, as previously explained for Figure \ref{fig:1}. 
It is important to note that the sketching distribution used in our experiments does~not introduce bias when $\Sigma_a = I$. When $\tilde{\Xi}_t$ is a consistent estimator (i.e., when $\Sigma_a = I$ or $\tau = \infty$), $\hat{\Xi}_t$ performs competitively compared to $\tilde{\Xi}_t$. However, in other cases, the relative variance estimation error of $\tilde{\Xi}_t$ is significantly larger than that of $\hat{\Xi}_t$ due to bias, leading to differences~in~statistical~inference performance.
The influence of the dimension $d$ and the sketching iteration number $\tau$ is more pronounced for the Equi-correlation $\Sigma_a$. 
For instance, when $\tau = 10$, we observe that the coverage rate of $\tilde{\Xi}_t$ decreases as $d$ increases, indicating that higher dimensionality makes the problem more challenging. Conversely, when fixing $d = 100$, the coverage rate for $\tilde{\Xi}_t$ gradually~increases~as~$\tau$~increases from $10$ to $40$. This occurs because increasing $\tau$ reduces the approximation error of the Newton direction, thereby reducing the bias introduced by sketching techniques. 
The results in Table \ref{table:1} further demonstrate the superior performance of our proposed estimator $\hat{\Xi}_t$.



\begin{table}[!t]
\centering
\resizebox{\linewidth}{!}{
\begin{tabular}{|c|c|c|c|cccccccc|}
\hline
\multirow{3}{*}{$\Sigma_a$} & \multirow{3}{*}{d} & \multirow{3}{*}{Criterion} & \multirow{2}{*}{SGD} & \multicolumn{8}{c|}{Sketched Newton Method} \\ \cline{5-12} & & & &
\multicolumn{2}{c|}{$\tau=\infty$} & \multicolumn{2}{c|}{$\tau=10$} & \multicolumn{2}{c|}{$\tau=20$} & \multicolumn{2}{c|}{$\tau=40$} \\ \cline{4-12} & & &
{\footnotesize$\bar{\Xi}_t$} & {\footnotesize$\tilde{\Xi}_t$} & \multicolumn{1}{c|}{{\footnotesize$\hat{\Xi}_t$}} & {\footnotesize$\tilde{\Xi}_t$} & \multicolumn{1}{c|}{{\footnotesize$\hat{\Xi}_t$}} & {\footnotesize$\tilde{\Xi}_t$} & \multicolumn{1}{c|}{{\footnotesize$\hat{\Xi}_t$}} & {\footnotesize$\tilde{\Xi}_t$} & {\footnotesize$\hat{\Xi}_t$} \\ \hline
\multirow{8}{*}{Identity} & \multirow{2}{*}{20} & Cov (\%) &
89.50 & 94.00 & \multicolumn{1}{c|}{94.00} & 93.00 &
\multicolumn{1}{c|}{93.00} & 95.00 & \multicolumn{1}{c|}{95.50} & 97.00 & 96.00 \\
& & Var Err & -0.178 & 0.024 & \multicolumn{1}{c|}{0.008} & 0.025 & \multicolumn{1}{c|}{0.026} & 0.025 & \multicolumn{1}{c|}{0.028} & 0.025 & 0.021 \\ \cline{2-12} 
& \multirow{2}{*}{40} & Cov (\%) & 88.00 &  94.00 &
\multicolumn{1}{c|}{93.50} &  96.00 &  \multicolumn{1}{c|}{97.50} &  96.00 &  \multicolumn{1}{c|}{96.00} &  95.00 &  95.00 \\
& &  Var Err &  -0.145 &  0.049 &  \multicolumn{1}{c|}{0.048} &  0.048 &  \multicolumn{1}{c|}{0.035} &  0.049 &  \multicolumn{1}{c|}{0.036} &  0.049 &  0.044 \\ \cline{2-12} 
&  \multirow{2}{*}{60} &  Cov (\%) &  \textbf{85.50} &  91.50 &  \multicolumn{1}{c|}{91.00} &  \textbf{94.50} &  \multicolumn{1}{c|}{\textbf{94.00}} &  94.00 &  \multicolumn{1}{c|}{94.50} &  94.50 &  94.00 \\
&   &  Var Err &  \textbf{-0.174} &  0.072 &  \multicolumn{1}{c|}{0.070} &  \textbf{0.074} &  \multicolumn{1}{c|}{\textbf{0.035}} &  0.073 &  \multicolumn{1}{c|}{0.044} &  0.073 &  0.058 \\ \cline{2-12} 
&  \multirow{2}{*}{100} &  Cov (\%) &  88.00 &  100.0 &  \multicolumn{1}{c|}{100.0} &  95.50 &  \multicolumn{1}{c|}{95.50} &  94.00 &  \multicolumn{1}{c|}{93.00} &  95.00 &  95.50 \\
&   &  Var Err &  -0.185 &  $\infty$ &  \multicolumn{1}{c|}{$\infty$} &  0.129 &  \multicolumn{1}{c|}{0.096} &  0.128 &  \multicolumn{1}{c|}{0.076} &  0.126 &  0.109 \\ \hline
\multirow{8}{*}{\shortstack{Toeplitz\\$r=0.5$}} &  \multirow{2}{*}{20} &  Cov (\%) &  \textbf{87.00} &  94.50 &  \multicolumn{1}{c|}{94.50} &  \textbf{89.00} &  \multicolumn{1}{c|}{\textbf{96.50}} &  89.00 &  \multicolumn{1}{c|}{94.00} &  90.00 &  93.00 \\
&   &  Var Err &  \textbf{-0.104} &  0.025 &  \multicolumn{1}{c|}{0.026} &  \textbf{-0.339} &  \multicolumn{1}{c|}{\textbf{0.003}} &  -0.283 &  \multicolumn{1}{c|}{0.009} &  -0.208 &  0.018 \\ \cline{2-12} 
&  \multirow{2}{*}{40} &  Cov (\%) &  91.00 &  96.50 &  \multicolumn{1}{c|}{96.50} &  89.50 &  \multicolumn{1}{c|}{94.00} &  85.50 &  \multicolumn{1}{c|}{95.50} &  89.00 &  94.50 \\
&   &  Var Err &  -0.074 &  0.048 &  \multicolumn{1}{c|}{0.040} &  -0.376 &  \multicolumn{1}{c|}{0.016} &  -0.343 &  \multicolumn{1}{c|}{0.022} &  -0.285 &  0.029 \\ \cline{2-12} 
&  \multirow{2}{*}{60} &  Cov (\%) &  86.50 &  94.00 &  \multicolumn{1}{c|}{94.50} &  83.50 &  \multicolumn{1}{c|}{92.50} &  85.50 &  \multicolumn{1}{c|}{93.00} &  84.50 &  94.00 \\
&   &  Var Err &  -0.061 &  0.072 &  \multicolumn{1}{c|}{0.074} &  -0.383 &  \multicolumn{1}{c|}{0.044} &  -0.361 &  \multicolumn{1}{c|}{0.029} &  -0.317 &  0.046 \\ \cline{2-12} 
&  \multirow{2}{*}{100} &  Cov (\%) &  93.50 &  100.0 &  \multicolumn{1}{c|}{100.0} &  90.00 &  \multicolumn{1}{c|}{96.00} &  89.00 &  \multicolumn{1}{c|}{95.00} &  89.50 &  97.00 \\
&   &  Var Err &  -0.083 &  $\infty$ &  \multicolumn{1}{c|}{$\infty$} &  1.156 &  \multicolumn{1}{c|}{2.659} &  -0.069 &  \multicolumn{1}{c|}{0.582} &  -0.335 &  0.067 \\ \hline
\multirow{8}{*}{\shortstack{Equi-corr\\$r=0.2$}} &  \multirow{2}{*}{20} &  Cov (\%) &  92.00 &  93.00 &  \multicolumn{1}{c|}{92.50} &  \textbf{79.00} &  \multicolumn{1}{c|}{\textbf{94.00}} &  83.00 &  \multicolumn{1}{c|}{94.00} &  91.50 &  95.50 \\
&   &  Var Err &  -0.063 &  0.024 &  \multicolumn{1}{c|}{0.023} &  \textbf{-0.538} &  \multicolumn{1}{c|}{\textbf{0.013}} &  -0.468 &  \multicolumn{1}{c|}{0.016} &  -0.334 &  0.012 \\ \cline{2-12} 
&  \multirow{2}{*}{40} &  Cov (\%) &  \textbf{90.50} &  95.50 &  \multicolumn{1}{c|}{94.50} &  \textbf{75.00} &  \multicolumn{1}{c|}{\textbf{96.50}} &  82.50 &  \multicolumn{1}{c|}{96.50} &  80.50 &  94.50 \\
&   &  Var Err &  \textbf{-0.139} &  0.048 &  \multicolumn{1}{c|}{0.040} & \textbf{ -0.654} &  \multicolumn{1}{c|}{\textbf{0.022}} &  -0.630 &  \multicolumn{1}{c|}{0.018} &  -0.580 &  0.024 \\ \cline{2-12} 
&  \multirow{2}{*}{60} &  Cov (\%) &  91.00 &  95.50 &  \multicolumn{1}{c|}{95.50} &  \textbf{72.00} &  \multicolumn{1}{c|}{\textbf{91.50}} &  68.00 &  \multicolumn{1}{c|}{94.50} &  81.50 &  96.50 \\
&   &  Var Err &  -0.015 &  0.072 &  \multicolumn{1}{c|}{0.067} &  \textbf{-0.697} &  \multicolumn{1}{c|}{\textbf{0.019}} &  -0.685 &  \multicolumn{1}{c|}{0.027} &  -0.660 &  0.029 \\ \cline{2-12} 
&  \multirow{2}{*}{100} &  Cov (\%) &  93.50 &  100.0 &  \multicolumn{1}{c|}{100.0} &  \textbf{69.50} &  \multicolumn{1}{c|}{\textbf{96.50}} &  \textbf{68.00} &  \multicolumn{1}{c|}{\textbf{97.50}} &  \textbf{73.00} &  \textbf{97.50} \\
&   &  Var Err &  -0.022 &  $\infty$ &  \multicolumn{1}{c|}{$\infty$} &  \textbf{-0.732} &  \multicolumn{1}{c|}{\textbf{0.030}} &  \textbf{-0.727} &  \multicolumn{1}{c|}{\textbf{0.028}} &  \textbf{-0.718} &
\textbf{0.035} \\ \hline
\end{tabular}}
\caption{\textit{Linear regression: the empirical coverage rate of 95\% confidence intervals $(\textit{Cov})$ and the averaged relative estimation error of the variance $(\textit{Var Err})$~of~$\b1^T\bx_t/d$, given by~\mbox{$\b1^T(\hat{\Xi}_t-\Xi^\star)\b1/\b1^T\Xi^\star\b1$}.
We bold entries to highlight scenarios where~$\hat{\Xi}_t$~\mbox{performs}~\mbox{significantly}~\mbox{better}~than~others.}}
\label{table:1}
\end{table}


\subsection{Logistic regression}\label{sec5:logistic}

Next we consider the logistic regression model $P(\xi_{b}\mid\bxi_{a})\propto \exp(0.5\xi_{b}\cdot\bxi_{a}^T\bx^{\star})$ with $\xi_{b}\in\{-1,1\}$.~For~this model, we use the log loss defined as $f(\bx; \xi)=\log\big(1+\exp(-\xi_{b}\cdot\bxi_{a}^T\bx)\big)$. 
We follow the~same experimental setup as in the linear regression model in Section \ref{sec5:linear}. Following Section \ref{sec5:linear}, we summarize part of results for logistic regression in Figure \ref{fig:2} and Table \ref{table:2}; a complete result is provided in~Appendix~\ref{appen:exp}.


The findings largely align with those observed for linear regression. The only noticeable difference is that $\bar{\Xi}_t$ for the SGD method exhibits worse performance in terms of coverage rate~compared~to~linear regression problems. In contrast, second-order (sketched) Newton methods perform consistently well, with the sample covariance $\hat{\Xi}_t$ excelling in the majority of cases. These results~\mbox{further}~\mbox{reconfirm}~the consistency of $\hat{\Xi}_t$ and illustrate that the confidence intervals constructed using $\hat{\Xi}_t$ are asymptotically valid.


	
\begin{figure}[!t]
\centering   
\subfigure[SGD]{\label{B11}\includegraphics[width=0.32\textwidth]{Figures/Logistic/Err_p1.png}}
\subfigure[exact Newton ($\tau=\infty$)]{\label{B12}\includegraphics[width=0.32\textwidth]{Figures/Logistic/Err_p2.png}}
\subfigure[sketched Newton ($\tau=2$)]{\label{B13}\includegraphics[width=0.32\textwidth]{Figures/Logistic/Err_p3.png}}
\vskip5pt
\centering{Relative covariance estimation error}
	
\subfigure[SGD]{\label{B21}\includegraphics[width=0.32\textwidth]{Figures/Logistic/Cov_p1.png}}
\subfigure[exact Newton ($\tau=\infty$)]{\label{B22}\includegraphics[width=0.32\textwidth]{Figures/Logistic/Cov_p2.png}}
\subfigure[sketched Newton ($\tau=2$)]{\label{B23}\includegraphics[width=0.32\textwidth]{Figures/Logistic/Cov_p3.png}}
\vskip5pt
\centering{Empirical coverage rate of 95\% confidence intervals}

\subfigure[SGD]{\label{B31}\includegraphics[width=0.32\textwidth]{Figures/Logistic/Orc_p1.png}}
\subfigure[exact Newton ($\tau=\infty$)]{\label{B32}\includegraphics[width=0.32\textwidth]{Figures/Logistic/Orc_p2.png}}
\subfigure[sketched Newton ($\tau=2$)]{\label{B33}\includegraphics[width=0.32\textwidth]{Figures/Logistic/Orc_p3.png}}
\vskip5pt
\centering{Empirical coverage rate of 95\% oracle confidence intervals}
\vskip5pt
\includegraphics[width=0.95\textwidth]{Figures/Logistic/legend_plot.png}
\caption{\textit{The averaged trajectories for logistic regression problems with $d=5$ and Toeplitz $\Sigma_a$ $(r=0.6)$. See Figure \ref{fig:1} for interpretation.}}\label{fig:2}
\end{figure}



\begin{table}[!t]
\centering
\resizebox{\linewidth}{!}{
\begin{tabular}{|c|c|c|c|cccccccc|}
\hline
\multirow{3}{*}{$\Sigma_a$} &  \multirow{3}{*}{d} &  \multirow{3}{*}{Criterion} &  \multirow{2}{*}{SGD} &  \multicolumn{8}{c|}{Sketched Newton Method} \\ \cline{5-12} 
&   &   &   &  \multicolumn{2}{c|}{$\tau=\infty$} &  \multicolumn{2}{c|}{$\tau=10$} &  \multicolumn{2}{c|}{$\tau=20$} &  \multicolumn{2}{c|}{$\tau=40$} \\ \cline{4-12} 
&   &   &  {\footnotesize$\bar{\Xi}_t$} &  {\footnotesize$\tilde{\Xi}_t$} &  \multicolumn{1}{c|}{{\footnotesize$\hat{\Xi}_t$}} &  {\footnotesize$\tilde{\Xi}_t$} &  \multicolumn{1}{c|}{{\footnotesize$\hat{\Xi}_t$}} &  {\footnotesize$\tilde{\Xi}_t$} &  \multicolumn{1}{c|}{{\footnotesize$\hat{\Xi}_t$}} &  {\footnotesize$\tilde{\Xi}_t$} &  {\footnotesize$\hat{\Xi}_t$} \\ \hline
\multirow{8}{*}{Identity} &  \multirow{2}{*}{20} &  Cov (\%) &  88.00 &  95.00 &  \multicolumn{1}{c|}{95.50} &  93.50 &  \multicolumn{1}{c|}{94.50} &  94.00 &  \multicolumn{1}{c|}{94.00} &  94.00 &  94.00 \\
&   &  Var Err &  -0.262 &  0.040 &  \multicolumn{1}{c|}{0.038} &  0.052 &  \multicolumn{1}{c|}{0.021} &  0.052 &  \multicolumn{1}{c|}{0.036} &  0.048 &  0.031 \\ \cline{2-12} 
&  \multirow{2}{*}{40} &  Cov (\%) &  \textbf{84.50} &  93.00 &  \multicolumn{1}{c|}{93.50} &  \textbf{95.00} &  \multicolumn{1}{c|}{\textbf{94.00}} &  95.50 & \multicolumn{1}{c|}{95.50} &  97.00 &  97.50 \\
&   &  Var Err &  \textbf{-0.307} &  0.084 &  \multicolumn{1}{c|}{0.070} &  \textbf{0.090} &  \multicolumn{1}{c|}{\textbf{0.052}} &  0.090 & \multicolumn{1}{c|}{0.073} &  0.089 &  0.083 \\ \cline{2-12} 
&  \multirow{2}{*}{60} &  Cov (\%) &  89.00 &  92.00 &  \multicolumn{1}{c|}{92.50} &  94.00 &  \multicolumn{1}{c|}{93.50} &  95.00 &  \multicolumn{1}{c|}{95.00} &  92.50 &  92.50 \\
&   &  Var Err &  -0.240 &  0.129 &  \multicolumn{1}{c|}{0.123} &  0.134 &  \multicolumn{1}{c|}{0.102} &  0.134 &  \multicolumn{1}{c|}{0.115} &  0.132 &  0.110 \\ \cline{2-12} 
&  \multirow{2}{*}{100} &  Cov (\%) &  86.50 &  95.50 &  \multicolumn{1}{c|}{96.00} &  97.00 &  \multicolumn{1}{c|}{96.50} &  95.50 &  \multicolumn{1}{c|}{96.00} &  93.50 &  93.00 \\
&   &  Var Err &  -0.220 &  0.229 &  \multicolumn{1}{c|}{0.219} &  0.236 &  \multicolumn{1}{c|}{0.195} &  0.233 &  \multicolumn{1}{c|}{0.200} &  0.231 &  0.221 \\ \hline
\multirow{8}{*}{\shortstack{Toeplitz\\$r=0.5$}} &  \multirow{2}{*}{20} &  Cov (\%) &  88.00 &  98.50 &  \multicolumn{1}{c|}{98.00} &  93.50 &  \multicolumn{1}{c|}{96.00} &  94.00 &  \multicolumn{1}{c|}{95.50} &  93.50 &  94.50 \\
&   &  Var Err &  -0.199 &  0.038 &  \multicolumn{1}{c|}{0.032} &  -0.226 &  \multicolumn{1}{c|}{0.028} &  -0.179 &  \multicolumn{1}{c|}{0.028} &  -0.097 &  0.020 \\ \cline{2-12} 
&  \multirow{2}{*}{40} &  Cov (\%) &  \textbf{85.50} &  96.00 &  \multicolumn{1}{c|}{96.50} &  \textbf{91.50} &  \multicolumn{1}{c|}{\textbf{95.00}} &  90.00 &  \multicolumn{1}{c|}{93.50} &  95.00 &  97.50 \\
&   &  Var Err &  \textbf{-0.190} &  0.079 &  \multicolumn{1}{c|}{0.077} &  \textbf{-0.233} &  \multicolumn{1}{c|}{\textbf{0.063}} &  -0.217 &  \multicolumn{1}{c|}{0.066} &  -0.160 &  0.064 \\ \cline{2-12} 
&  \multirow{2}{*}{60} &  Cov (\%) &  92.00 &  95.50 &  \multicolumn{1}{c|}{94.50} &  92.00 &  \multicolumn{1}{c|}{94.50} &  89.50 &  \multicolumn{1}{c|}{94.00} &  92.50 &  97.00 \\
&   &  Var Err &  -0.170 &  0.122 &  \multicolumn{1}{c|}{0.115} &  -0.215 &  \multicolumn{1}{c|}{0.081} &  -0.208 &  \multicolumn{1}{c|}{0.100} &  -0.174 &  0.094 \\ \cline{2-12} 
&  \multirow{2}{*}{100} &  Cov (\%) &  87.50 &  97.00 &  \multicolumn{1}{c|}{96.00} &  90.50 &  \multicolumn{1}{c|}{93.50} &  92.00 &  \multicolumn{1}{c|}{96.50} &  90.00 &  93.50 \\
&   &  Var Err &  -0.159 &  0.221 &  \multicolumn{1}{c|}{0.215} &  -0.158 &  \multicolumn{1}{c|}{0.163} &  -0.161 &  \multicolumn{1}{c|}{0.166} &  -0.146 &  0.164 \\ \hline
\multirow{8}{*}{\shortstack{Equi-corr\\$r=0.2$}} &  \multirow{2}{*}{20} &  Cov (\%) &  90.00 &  96.00 &  \multicolumn{1}{c|}{96.00} &  88.50 &  \multicolumn{1}{c|}{96.50} &  \textbf{89.00} &  \multicolumn{1}{c|}{\textbf{96.50}} &  92.50 &  96.00 \\
&   &  Var Err &  -0.172 &  0.041 &  \multicolumn{1}{c|}{0.037} &  -0.394 &  \multicolumn{1}{c|}{0.028} &  \textbf{-0.302} &  \multicolumn{1}{c|}{\textbf{0.037}} &  -0.153 &  0.039 \\ \cline{2-12}  
&  \multirow{2}{*}{40} &  Cov (\%) &  \textbf{86.00} &  95.00 &  \multicolumn{1}{c|}{95.00} &  \textbf{78.00} &  \multicolumn{1}{c|}{\textbf{95.00}} &  \textbf{81.00} &  \multicolumn{1}{c|}{\textbf{94.50}} &  \textbf{88.00} &  \textbf{96.50} \\
&   &  Var Err &  \textbf{-0.111} &  0.083 &  \multicolumn{1}{c|}{0.084} &  \textbf{-0.530} &  \multicolumn{1}{c|}{\textbf{0.062}} &  \textbf{-0.490} &  \multicolumn{1}{c|}{\textbf{0.046}} &  \textbf{-0.402} &  \textbf{0.050} \\ \cline{2-12} 
&  \multirow{2}{*}{60} &  Cov (\%) &  80.00 &  94.00 &  \multicolumn{1}{c|}{93.50} &  78.50 &  \multicolumn{1}{c|}{94.00} &  \textbf{80.00} &  \multicolumn{1}{c|}{\textbf{97.00}} &  82.50 &  96.00 \\
&   &  Var Err &  -0.144 &  0.130 &  \multicolumn{1}{c|}{0.110} &  -0.592 &  \multicolumn{1}{c|}{0.076} &  \textbf{-0.569} &  \multicolumn{1}{c|}{\textbf{0.068}} &  -0.518 &  0.072 \\ \cline{2-12} 
&  \multirow{2}{*}{100} &  Cov (\%) &  66.50 &  97.50 &  \multicolumn{1}{c|}{96.00} &  73.50 &  \multicolumn{1}{c|}{96.00} &  \textbf{73.00} &  \multicolumn{1}{c|}{\textbf{96.00}} &  80.00 &  97.00 \\
&   &  Var Err &  -0.108 &  0.234 &  \multicolumn{1}{c|}{0.227} &  -0.647 &  \multicolumn{1}{c|}{0.116} &  \textbf{-0.636} &  \multicolumn{1}{c|}{\textbf{0.115}} &  -0.615 &  0.109 \\ \hline
\end{tabular}}
\caption{\textit{Logistic regression: the empirical coverage rate of 95\% confidence intervals $(\textit{Cov})$ and the averaged relative estimation error of the variance $(\textit{Var Err})$~of~$\b1^T\bx_t/d$, given by~\mbox{$\b1^T(\hat{\Xi}_t-\Xi^\star)\b1/\b1^T\Xi^\star\b1$}.
We bold entries to highlight scenarios where~$\hat{\Xi}_t$~\mbox{performs}~\mbox{significantly}~\mbox{better}~than~others.}}
\label{table:2}
\end{table}




\subsection{CUTEst benchmark problems}\label{sec5:subsec2}

In this section, we explore the empirical performance of $\hat{\Xi}_t$ in constrained optimization, as discussed in Section \ref{sec:4.3}. We perform four equality-constrained problems from the CUTEst test set: \texttt{MARATOS}, \texttt{HS7}, \texttt{BT9}, \texttt{HS39} \citep{Gould2014CUTEst}. 
For each problem and at each iteration, the CUTEst~\mbox{package}~\mbox{provides} true evaluations of the objective gradients and Hessians.~With those quantities, we generate~our {estimates}~by letting  $\bar{g}_t\sim \mathcal{N}(\nabla F_t, \sigma^2(I+\boldsymbol{1}\boldsymbol{1}^T))$ and $[\bar{H}_t]_{i,j} =[\bar{H}_t]_{j,i} \sim \mathcal{N}([\nabla^2 F_t]_{i,j}, \sigma^2)$. We~vary~the~sampling variance $\sigma^2$ from $\sigma^2\in\{10^{-4}, 10^{-2}, 10^{-1}, 1\}$ and set $\tau = 40$. The other parameters are set as in Section \ref{sec5:linear}, while the problem initialization is provided by the CUTEst package. The~true~solution~$\tx$ is computed using the IPOPT solver \citep{Waechter2005implementation}. We construct 95\%~confidence~intervals for the averaged \textit{inactive} parameters $\sum_{i\in\I}\tx_i/|\I|$, where $\I\subseteq\{1,\ldots,d\}$ contains all the~indices for which $\tx_i$ is not specified by the constraint (otherwise, $\tx_i$ has no randomness).



We evaluate the performance of $\hat{\Xi}_t$ on four CUTEst problems and summarize the results in~Table \ref{table:3}. The table records the empirical coverage rate of the confidence intervals based on $\hat{\Xi}_t$ and the averaged relative estimation error of the variance of $\sum_{i\in\I}\tx_i/|\I|$.
From Table \ref{table:3}, we observe that variance estimation errors remain small across all settings. For \texttt{BT9} and \texttt{HS39}, the relative error in variance increases as the sampling variance $\sigma^2$ grows. This is expected since higher noise levels~make the problem more challenging. In contrast, for \texttt{MARATOS} and \texttt{HS7}, the relative error in variance~remains at the same magnitude across different values of $\sigma^2$, indicating that these problems are~less sensitive to noise. Regarding statistical inference, we note that the~coverage~rates~consistently~center around~the target 95\% confidence level. These results~demonstrate the effectiveness~of~$\hat{\Xi}_t$~in~constrained~optimization and its robustness to varying noise levels.



\begin{table}[!t]
\centering
\resizebox{\linewidth}{!}{
\begin{tabular}{|c|cc|cc|cc|cc|}
\hline
\multirow{2}{*}{\diagbox{Prob}{$\sigma^2$}} &  \multicolumn{2}{c|}{$\sigma^2=10^{-4}$} &  \multicolumn{2}{c|}{$\sigma^2 = 10^{-2}$} &  \multicolumn{2}{c|}{$\sigma^2 = 10^{-1}$} &  \multicolumn{2}{c|}{$\sigma=1$} \\ %\cline{2-9} 
& Cov (\%) & Var Err & Cov (\%) & Var Err & Cov (\%) & Var Err & Cov (\%) & Var Err \\ \hline
\texttt{MARATOS} & 97.50    & -0.0025  & 93.00    & -0.0079  & 92.50    & 0.0057   & 95.50    & 0.0124   \\ \hline
\texttt{HS7}     & 96.50    & -0.0053  & 96.50    & -0.0042  & 96.00    & -0.0021  & 94.50    & -0.0020  \\ \hline
\texttt{BT9}     & 94.50    & 0.0007   & 96.00    & 0.0067   & 94.00    & 0.0104   & 95.50    & 0.1668   \\ \hline
\texttt{HS39}    & 95.50    & -0.0030  & 94.50    & 0.0083   & 94.00    & 0.0192   & 96.50    & 0.1770   \\ \hline
\end{tabular}}
\caption{\textit{The empirical coverage rate of 95\% confidence intervals $(\textit{Cov})$ for four CUTEst problems under different sampling variance $\sigma^2\in \{10^{-4}, 10^{-2}, 10^{-1}, 1\}$; as well as the averaged relative~estimation error of the variance $(\textit{Var Err})$ of $\sum_{i\in\I}\tx_i/|\I|$, given by~$\sum_{i,j\in\I}([\hat{\Xi}_t]_{i,j}-[\Xi^\star]_{i,j})/\sum_{i,j\in\I}[\Xi^\star]_{i,j}$.}}
\label{table:3}
\end{table}



