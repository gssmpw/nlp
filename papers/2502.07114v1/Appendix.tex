
\section{Online Update of $\hat{\Xi}_t^{-1}$}\label{appendix:1}

We introduce how to online update $\hat{\Xi}_t^{-1}$ for constructing the confidence region in Corollary \ref{sec4:cor1}.~By~the definition of $\hat{\Xi}_t$ in \eqref{exp:Xihat}, we have
\begin{align*}
\hat{\Xi}_{t+1} & \stackrel{\mathclap{\eqref{exp:Xihat}}}{=} \frac{1}{t+1}\sum_{i=1}^{t+1}\frac{1}{\varphi_{i-1}}(\bx_i-\bar{\bx}_{t+1})(\bx_i-\bar{\bx}_{t+1})^T\\
& = \frac{1}{t+1}\sum_{i=1}^{t}\frac{1}{\varphi_{i-1}}(\bx_i-\bar{\bx}_{t+1})(\bx_i-\bar{\bx}_{t+1})^T + \frac{1/\varphi_t}{t+1}(\bx_{t+1}-\barx_{t+1})(\bx_{t+1}-\barx_{t+1})^T\\
& = \frac{t}{t+1}\bigg(\frac{1}{t}\sum_{i=1}^{t}\frac{1}{\varphi_{i-1}}(\bx_i-\bar{\bx}_{t})(\bx_i-\bar{\bx}_{t})^T + \frac{1}{t}\sum_{i=1}^{t}\frac{1}{\varphi_{i-1}}(\bx_i - \barx_{t})(\barx_{t} - \barx_{t+1})^T \\
&\quad\quad + \frac{1}{t}\sum_{i=1}^{t}\frac{1}{\varphi_{i-1}}(\barx_{t} - \barx_{t+1})(\bx_i - \barx_{t})^T + \frac{1}{t}\sum_{i=1}^{t}\frac{1}{\varphi_{i-1}}(\barx_{t} - \barx_{t+1})(\barx_{t} - \barx_{t+1})^T \bigg)\\
& \quad\quad + \frac{1/\varphi_{t}}{t+1}(\bx_{t+1}-\barx_{t+1})(\bx_{t+1}-\barx_{t+1})^T\\
& \stackrel{\mathclap{\eqref{nequ:9}}}{=} \frac{t}{t+1}\bigg(\hat{\Xi}_{t} + (\bv_{t} - a_{t}\barx_{t})(\barx_{t} - \barx_{t+1})^T + (\barx_{t} - \barx_{t+1})(\bv_{t} - a_{t}\barx_{t})^T + a_{t}(\barx_{t} - \barx_{t+1})(\barx_{t} - \barx_{t+1})^T\bigg) \\
&\quad\quad + \frac{1/\varphi_{t}}{t+1}(\bx_{t+1}-\barx_{t+1})(\bx_{t+1}-\barx_{t+1})^T.
\end{align*}
Let us define two matrices $R_t\in \mR^{d\times 3}$ and $\Lambda_t\in \mR^{3\times 3}$ as
\begin{equation*}
R_t = \rbr{\bv_t - a_t\barx_t; \barx_t - \barx_{t+1}; \bx_{t+1} - \barx_{t+1}}, \quad\quad\quad\quad \Lambda_t = \begin{pmatrix}
0 & 1 & 0\\
1 & a_t & 0\\
0 & 0 & 1/(t\varphi_{t})
\end{pmatrix}.
\end{equation*}
Then, we have
\begin{equation*}
\hat{\Xi}_{t+1} = \frac{t}{t+1}\rbr{\hat{\Xi}_{t} + R_t\Lambda_t R_t^T}. 
\end{equation*}
Thus, by Sherman–Morrison–Woodbury formula, we obtain
\begin{equation*}
\hat{\Xi}_{t+1}^{-1} = \frac{t+1}{t}\hat{\Xi}_{t}^{-1} - \frac{t+1}{t}\hat{\Xi}_{t}^{-1} R_t\rbr{\Lambda_t^{-1} + R_t^T\hat{\Xi}_{t}^{-1}R_t}^{-1} R_t^T\hat{\Xi}_{t}^{-1}.
\end{equation*}



\section{Preparation Lemmas}\label{appen:A1}

We introduce some preparation lemmas regarding the stepsize sequences and the update direction.

\begin{lemma}[\cite{Na2022Statistical}, Lemma B.1]\label{aux:lem3}
 Suppose $\{\varphi_i\}_i$ is a positive sequence that~satisfies $\lim\limits_{i\rightarrow\infty}i(1 - \varphi_{i-1}/\varphi_i) = \varphi$. Then, for any $p \geq 0$, we have $\lim\limits_{i\rightarrow\infty}i\rbr{1 - \varphi_{i-1}^p/\varphi_i^p} = p\cdot \varphi$.
\end{lemma}

\begin{lemma}[\cite{Na2022Statistical}, Lemma B.3(a)]\label{aux:lem1}
Let $\{\phi_i\}_i,\{\varphi_i\}_i,\{\sigma_i\}_i$ be three positive sequences. Suppose\footnote{In fact, $\phi<0$ is only required by Lemma B.3(b) in \cite{Na2022Statistical}, and the statements in Lemma B.3(a) hold for any constant $\phi$.}
\begin{equation}\label{appen:A1:cond1}
\lim\limits_{i\rightarrow \infty} i\rbr{1 - \phi_{i-1}/\phi_i} = \phi<0,\quad \quad\quad\lim\limits_{i\rightarrow\infty}\varphi_i = 0, \quad\quad\quad \lim\limits_{i\rightarrow \infty} i\varphi_i = \tvarphi
\end{equation}
for a constant $\phi$ and a (possibly infinite) constant $\tvarphi \in(0, \infty]$. For any $l\geq 1$, if we further have 
\begin{equation}\label{appen:A1:cond2}
\sum_{k=1}^{l}\sigma_k + \phi/\tvarphi>0,
\end{equation}
then the following results hold as $t\rightarrow \infty$:
\begin{align}
& \frac{1}{\phi_t}\sum_{i=0}^{t}\prod_{j = i+1}^t\prod_{k=1}^{l}(1-\varphi_j\sigma_k)\varphi_i\phi_i \longrightarrow \frac{1}{\sum_{k=1}^{l}\sigma_k + \phi/\tvarphi},\label{appen:A1:equ1a}\\
& \frac{1}{\phi_t}\bigg\{\sum_{i=0}^{t}\prod_{j = i+1}^t\prod_{k=1}^{l}(1-\varphi_j\sigma_k)\varphi_i\phi_i a_i + b\cdot \prod_{j = 0}^t\prod_{k=1}^{l}(1-\varphi_j\sigma_k) \bigg\}  \longrightarrow 0,\label{appen:A1:equ1b}
\end{align}
where the second result holds for any constant $b$ and any sequence $\{a_t\}_t$ such that $a_t\rightarrow 0$.
\end{lemma}


\begin{lemma}\label{aux:lem2}
Suppose $\{\phi_i\}_i$ and $\{\sigma_i\}_i$ are two positive sequences, and $\{\phi_i\}_{i}$ satisfies $\lim_{i\rightarrow \infty} i(1 - \phi_{i-1}/\phi_i) = \phi<0$ for a constant $\phi$. Let $\varphi_i = c_{\varphi}/(i+1)^\varphi + o(1/(i+1)^{\varphi})$ for constants $c_{\varphi}>0$~and~$\varphi\in (0,1)$. For any $l \geq 1$, we have
\begin{equation*}
\Big|\frac{1}{\phi_t}\sum_{i=0}^{t}\prod_{j = i+1}^t\prod_{k=1}^{l}(1-\varphi_j\sigma_k)\varphi_i\phi_i - \frac{1}{\sum_{k=1}^{l}\sigma_k}\Big| \lesssim 
\begin{dcases}
\varphi_t,  & \varphi \in(0,0.5),\\[2pt]
\rbr{0.5-\frac{\phi/c_{\varphi}^2}{(\sum_{k=1}^l\sigma_k)^2}}\varphi_t, & \varphi =0.5,\\[2pt]
-\frac{\phi}{(\sum_{k=1}^l\sigma_k)^2} \cdot \frac{1}{t\varphi_t},  & \varphi \in(0.5,1).
\end{dcases}
\end{equation*}
\end{lemma}

\begin{lemma}\label{aux:lem5}
Suppose $\{\phi_i\}_i,\{\varphi_i\}_i,\{\sigma_i\}_i$ be three positive sequences that satisfy the assumptions~in Lemma \ref{aux:lem1}.~Let $\{\eta_i\}_i$ be a positive sequence such that $\lim_{i\rightarrow\infty}\eta_i/\varphi_i =1$. For any~\mbox{$l\geq 1$},~if~$\sum_{k=1}^l\sigma_k/2 + \phi/\tilde{\varphi}>0$, then we have
\begin{equation*}
\prod_{i=0}^t \prod_{k=1}^l |1-\eta_i\sigma_k|  + \sum_{i=0}^t \prod_{j=i+1}^t \prod_{k=1}^l |1-\eta_j \sigma_k| \varphi_i \phi_i \lesssim \frac{1}{\sum_{k=1}^l\sigma_k/2 + \phi/\tilde{\varphi}}\cdot \phi_t.
\end{equation*}
\end{lemma}


\begin{lemma}\label{aux:lem4}
For the $t$-th iteration, let us define two sketching matrices
\begin{equation}\label{appen:A1:equ6}
\tilde{C}_{t,j} = I-\big(B_tS_{t,j}(S_{t,j}^TB_t^2S_{t,j})^{\dagger}S_{t,j}^TB_t\big)\quad\quad \text{ and }\quad\quad \tilde{C}_t = \prod_{j=1}^\tau \tilde{C}_{t,j},
\end{equation}
and we also let $C_t =\mE[\tilde{C}_t\mid \mF_{t-1}]$. Then, under Assumptions \ref{ass:2} and \ref{ass:4}, the following \mbox{results}~hold~(recall that $C^\star$ is defined in~\eqref{exp:Cstar}):
\begin{enumerate}[label=(\alph*)]
\item We have $\bar{\Delta}\bx_t=(I-\tilde{C}_t)\Delta\bx_t=-(I-\tilde{C}_t)B_t^{-1}\bar{g}_t$ for any $ t\geq 0$.
\item We have $\mE[\bar{\Delta}\bx_t\mid\mF_{t-1}]=-(I-C_t)B_t^{-1}\nabla F_t$ for any $t\geq 0$.
\item We have $\|C_t\|\leq \rho^\tau$ for any $t\geq 0$ with $\rho=1-\gamma_S$. When $\bx_t\rightarrow\tx$, we also have $\|C^\star\|\leq\rho^\tau$.
\item When $\bx_t\rightarrow\tx$, we have $(1-\rho^\tau)I\preceq I-C^\star \preceq I$.
\end{enumerate}
	
\end{lemma}


\section{Proofs of Preparation Lemmas}

\subsection{Proof of Lemma \ref{aux:lem2}}

We note that \eqref{appen:A1:cond1} is satisfied with $\tilde{\varphi}=\infty$ and \eqref{appen:A1:cond2} holds as \mbox{$\sum_{k=1}^l\sigma_k+\phi/\tilde{\varphi}=\sum_{k=1}^l\sigma_k>0$}.~Thus, Lemma \ref{aux:lem1} holds and its proof \cite[(C.1)]{Na2022Statistical} suggests the following decomposition 
\begin{multline}\label{appen:A1:equ2}
\frac{1}{\phi_t} \sum_{i=0}^t \prod_{j=i+1}^t \prod_{k=1}^l\left(1-\varphi_j \sigma_k\right) \varphi_i \phi_i-\frac{1}{\sum_{k=1}^l\sigma_k}=\frac{1}{\phi_t} \prod_{j=1}^t \prod_{k=1}^l (1-\varphi_j\sigma_k)\cdot \phi_0\bigg(\varphi_0-\frac{1}{\sum_{k=1}^{l}\sigma_k}\bigg)\\
+\frac{1}{\phi_t} \sum_{i=1}^t\prod_{j=i+1}^t \prod_{k=1}^l (1-\varphi_j\sigma_k)\phi_i  \bigg\{ \varphi_i-\frac{1}{\sum_{k=1}^{l}\sigma_k}\Big(1-\frac{\phi_{i-1}}{\phi_i}\prod_{k=1}^l(1-\varphi_i\sigma_k)\Big)\bigg\}=: \uppercase\expandafter{\romannumeral1} + \uppercase\expandafter{\romannumeral2}.
\end{multline}
We first calculate the rate of the term in the curly bracket in $\uppercase\expandafter{\romannumeral2}$. We note~that
\begin{align*}
\prod_{k=1}^l(1-\varphi_i\sigma_k) & = 1-\sum_{k=1}^l\sigma_k\varphi_i + 0.5\Big\{\big(\sum_{k=1}^l \sigma_k\big)^2-\big(\sum_{k=1}^l \sigma_k^2\big)\Big\}\varphi_i^2 + o(\varphi_i^2),\\
\frac{\phi_{i-1}}{\phi_i} & = 1-\phi\cdot\frac{1}{i+1}+o\Big(\frac{1}{i+1}\Big).
\end{align*}
Thus, the rate of the multiplication of these two terms is
\begin{equation}\label{pequ:1}
{\footnotesize\frac{\phi_{i-1}}{\phi_i}\prod_{k=1}^l(1-\varphi_i\sigma_k)= 
\begin{dcases}
1 - \sum_{k=1}^l \sigma_k\varphi_i + 0.5\Big\{\big(\sum_{k=1}^l \sigma_k\big)^2-\big(\sum_{k=1}^l \sigma_k^2\big)\Big\}\varphi_i^2 + o(\varphi_i^2), &\varphi\in (0,0.5),\\
1 - \sum_{k=1}^l \sigma_k\varphi_i + \Big\{0.5\{\big(\sum_{k=1}^l \sigma_k\big)^2-\big(\sum_{k=1}^l \sigma_k^2\big)\}-\frac{\phi}{c_{\varphi}^2}\Big\}\varphi_i^2 + o(\varphi_i^2), &\varphi = 0.5,\\
1 -  \sum_{k=1}^l \sigma_k\varphi_i - \frac{\phi}{i+1} + o\Big(\frac{1}{i+1}\Big), &\varphi\in(0.5,1).
\end{dcases}}
\end{equation}
Let us first consider the case $\varphi\in(0.5,1)$. We plug the above display above into $\uppercase\expandafter{\romannumeral2}$ in \eqref{appen:A1:equ2} and get\;\;
\begin{equation*}
\uppercase\expandafter{\romannumeral2} 
=-\frac{\phi}{\sum_{k=1}^{l}\sigma_k}\cdot \frac{1}{\phi_t} \sum_{i=1}^t\prod_{j=i+1}^t \prod_{k=1}^l (1-\varphi_j\sigma_k)\varphi_i\cdot\cbr{\frac{\phi_i}{(i+1)\varphi_i} + o\Big(\frac{\phi_i}{(i+1)\varphi_i}\Big)}.
\end{equation*}
We note that
\begin{equation*}
\lim\limits_{i\rightarrow \infty}i\bigg(1-\frac{\phi_{i-1}/\big(i\varphi_{i-1}\big)}{\phi_{i}/\big((i+1)\varphi_{i}\big)}\bigg) = \lim\limits_{i\rightarrow \infty}i\bigg(1-\frac{\phi_{i-1}}{\phi_{i}}+\frac{\phi_{i-1}}{\phi_{i}}\Big(1-\frac{1/\big(i\varphi_{i-1}\big)}{1/\big((i+1)\varphi_{i}\big)}\Big)\bigg) = \phi+\varphi-1<0,
\end{equation*}
so we can apply Lemma \ref{aux:lem1} and derive 
\begin{align*}
&\lim_{t\rightarrow \infty}\frac{1}{\phi_{t}/\big((t+1)\varphi_{t}\big)} \sum_{i=1}^t\prod_{j=i+1}^t \prod_{k=1}^l (1-\varphi_j\sigma_k)\varphi_i \cdot\frac{\phi_i}{(i+1)\varphi_i}\stackrel{\eqref{appen:A1:equ1a}}{=} \frac{1}{\sum_{k=1}^l \sigma_k},\\
&\lim_{t\rightarrow \infty}\frac{1}{\phi_{t}/\big((t+1)\varphi_{t}\big)} \sum_{i=1}^t\prod_{j=i+1}^t \prod_{k=1}^l (1-\varphi_j\sigma_k)\varphi_i \cdot o\Big(\frac{\phi_i}{(i+1)\varphi_i}\Big)\stackrel{\eqref{appen:A1:equ1b}}{=} 0.
\end{align*}
Combining the two displays, we have $|\uppercase\expandafter{\romannumeral2}| \lesssim -\frac{\phi}{(\sum_{k=1}^l \sigma_k)^2}\cdot\frac{1}{(t+1)\varphi_t}$. For the term $\uppercase\expandafter{\romannumeral1}$ in \eqref{appen:A1:equ2}, we have
\begin{equation*}
\lim_{t\rightarrow\infty}\frac{1}{\phi_{t}/\big((t+1)\varphi_{t}\big)} \prod_{j=1}^t \prod_{k=1}^l (1-\varphi_j\sigma_k)\cdot \phi_0\bigg(\varphi_0-\frac{1}{\sum_{k=1}^{l}\sigma_k}\bigg)\stackrel{\eqref{appen:A1:equ1b}}{=} 0.
\end{equation*}
This indicates $|\uppercase\expandafter{\romannumeral1}|=o(1/(t+1)\varphi_t)$. Combining the rates of $|\uppercase\expandafter{\romannumeral1}|$ and $|\uppercase\expandafter{\romannumeral2}|$ with \eqref{appen:A1:equ2}, we complete the proof for the case $\varphi\in(0.5,1)$. For the case $\varphi = 0.5$, we know from \eqref{pequ:1} and \eqref{appen:A1:equ2} that
\begin{equation*}
\uppercase\expandafter{\romannumeral2} = \frac{0.5\{\big(\sum_{k=1}^l \sigma_k\big)^2-\big(\sum_{k=1}^l \sigma_k^2\big)\}-\phi/c_{\varphi}^2}{\sum_{k=1}^{l}\sigma_k}\frac{1}{\phi_t} \sum_{i=1}^t\prod_{j=i+1}^t \prod_{k=1}^l (1-\varphi_j\sigma_k)\varphi_i\phi_i\cdot\cbr{\varphi_i+o(\varphi_i)}.
\end{equation*}
Following the same analysis as above and applying Lemma \ref{aux:lem1}, we obtain
\begin{equation*}
|\uppercase\expandafter{\romannumeral2}| \lesssim \frac{0.5\{\big(\sum_{k=1}^l \sigma_k\big)^2-\big(\sum_{k=1}^l \sigma_k^2\big)\}-\phi/c_{\varphi}^2}{(\sum_{k=1}^{l}\sigma_k)^2} \varphi_t\leq \rbr{0.5 - \frac{\phi/c_{\varphi}^2}{(\sum_{k=1}^l\sigma_k)^2}} \varphi_t.
\end{equation*}
We also have $|\uppercase\expandafter{\romannumeral1}| = o(\varphi_t)$ and, hence, complete the proof for the case $\varphi=0.5$. The proof for the case $\varphi\in(0,0.5)$ can be done similarly by noting that
\begin{equation*}
\uppercase\expandafter{\romannumeral2} = \frac{0.5\{\big(\sum_{k=1}^l \sigma_k\big)^2-\big(\sum_{k=1}^l \sigma_k^2\big)\}}{\sum_{k=1}^{l}\sigma_k}\frac{1}{\phi_t} \sum_{i=1}^t\prod_{j=i+1}^t \prod_{k=1}^l (1-\varphi_j\sigma_k)\varphi_i\phi_i\cdot\cbr{\varphi_i+o(\varphi_i)}.
\end{equation*}
We complete the proof.


\subsection{Proof of Lemma \ref{aux:lem5}}

Since $\lim_{t \rightarrow \infty}\eta_t/\varphi_t = 1$ and $\lim_{t \rightarrow \infty}\varphi_t = 0$, there exists a fixed integer $\tilde{t}$ such that for any $t\geq \tilde{t}$~and $1\leq k\leq l$, we have $\eta_t \geq \varphi_t/2$ and $0<1-\eta_t\sigma_k\leq 1-\varphi_t\sigma_k/2$.~Define a sequence $\{\tilde{\phi}_t\}_{t=\tilde{t}-1}^{\infty}$ as follows:
\begin{equation*}
\tilde{\phi}_t = \begin{dcases}
\phi_{t} + \sum_{i=0}^{\tilde{t}-2}\prod_{j=i+1}^{\tilde{t}-1}\prod_{k=1}^l |1-\eta_j\sigma_k|\varphi_i \phi_i, &t = \tilde{t}-1,\\
\phi_t, &t\geq \tilde{t}.
\end{dcases}
\end{equation*}
With the above sequence, we use the techniques in \citep[(E.19)]{Na2022Statistical} and rewrite the following series as
\begin{align*}
&\sum_{i=0}^t \prod_{j=i+1}^t \prod_{k=1}^l |1-\eta_j \sigma_k| \varphi_i \phi_i
= \sum_{i = \tilde{t}-1}^t \prod_{j=i+1}^t \prod_{k=1}^l |1-\eta_j \sigma_k| \varphi_i \phi_i + \sum_{i = 0}^{\tilde{t}-2} \prod_{j=i+1}^t \prod_{k=1}^l |1-\eta_j \sigma_k| \varphi_i \phi_i\\
&=\sum_{i = \tilde{t}-1}^t \prod_{j=i+1}^t \prod_{k=1}^l |1-\eta_j \sigma_k| \varphi_i \phi_i + \prod_{j=\tilde{t}}^t \prod_{k=1}^l |1-\eta_j \sigma_k|\cdot \sum_{i = 0}^{\tilde{t}-2} \prod_{j=i+1}^{\tilde{t}-1} \prod_{k=1}^l |1-\eta_j \sigma_k| \varphi_i \phi_i\\
& = \sum_{i = \tilde{t}-1}^t \prod_{j=i+1}^t \prod_{k=1}^l |1-\eta_j \sigma_k| \varphi_i \tilde{\phi_i} \leq \sum_{i = \tilde{t}-1}^t \prod_{j=i+1}^t \prod_{k=1}^l (1-\varphi_j\sigma_k/2) \varphi_i \tilde{\phi_i}\\ 
&\stackrel{\mathclap{\eqref{appen:A1:equ1a}}}{\lesssim} \frac{1}{\sum_{k=1}^l\sigma_k/2 + \phi/\tilde{\varphi}}\cdot \phi_t.
\end{align*}
Additionally, we know
\begin{multline*}
\prod_{i=0}^t \prod_{k=1}^l |1-\eta_i\sigma_k| = \prod_{i=\tilde{t}}^t \prod_{k=1}^l |1-\eta_i\sigma_k| \cdot \prod_{i = 0}^{\tilde{t}-1}\prod_{k=1}^l |1-\eta_i\sigma_k|\\
\leq \prod_{i=\tilde{t}}^t \prod_{k=1}^l (1-\varphi_i\sigma_k/2) \cdot \prod_{i = 0}^{\tilde{t}-1}\prod_{k=1}^l |1-\eta_i\sigma_k| \stackrel{\eqref{appen:A1:equ1b}}{=} o(\phi_t).
\end{multline*}
We complete the proof.


\subsection{Proof of Lemma \ref{aux:lem4}}

Recalling $B_t\Delta\bx_t = -\bar{g}_t$, we subtract $\Delta\bx_t$ from both sides of \eqref{sec2:equ2} and obtain
\begin{equation*}
\Delta\bx_{t,j+1}-\Delta\bx_t =\big(I-B_tS_{t,j}(S_{t,j}^TB_t^2S_{t,j})^{\dagger}S_{t,j}^TB_t\big)(\Delta\bx_{t,j}-\Delta\bx_t) = \tilde{C}_{t,j}(\Delta\bx_{t,j}-\Delta\bx_t).
\end{equation*}
Since $\Delta\bx_{t,0}=\boldsymbol{0}$, we complete the proof of (a). By the independence between sketching and sampling and the unbiasedness of $\barg_t$ in Assumption \ref{ass:2}, we complete the proof of (b). (c) can be found~in Lemma 4.4 and Corollary 5.4 in \cite{Na2022Statistical}. (d) is an immediate result from (c) by observing that $C^\star\succeq \boldsymbol{0}$.


\section{Proofs of Section \ref{sec3:subsec2}}\label{pf:sec3:subsec2}

To ease the presentation, we assume throughout the proof and without loss of generality that~all~upper bound constants in the assumptions $\Upsilon_L,\Upsilon_{S}, \Upsilon_H, C_{g,1}, C_{g,2}, C_{H,1}, C_{H,2} \geq 1$, and the lower bound~constant $0<\gamma_H\leq 1$. The range of these constants is not crucial to the~analysis; all results still hold by replacing $\gamma_H$ by $\gamma_H\wedge 1$ (similar for other constants).



\subsection{Proof of Theorem \ref{sec3:thm1}}\label{pf:sec3:thm1}

By Assumption \ref{ass:3}, $\|\nabla^2 F(\bx)\|\leq \Upsilon_H$. Applying Taylor's expansion, we have
\begin{align}\label{appen:A2:equ8}
&\hskip-0.5cm  F_{t+1}-F^\star \nonumber\\
&\hskip-0.5cm \leq F_t-F^\star + \bar{\alpha}_t \nabla F_t^T\bar{\Delta} \bx_t + \frac{\Upsilon_{H}}{2}\bar{\alpha}_t^2\|\bar{\Delta}\bx_t\|^2 \nonumber\\
&\hskip-0.5cm = F_t-F^{\star}+\bar{\alpha}_t\mE[\nabla F_t^T\bar{\Delta} \bx_t\mid\mF_{t-1}]+\bar{\alpha}_t\Big(\nabla F_t^T\bar{\Delta}\bx_t-\mE[\nabla F_t^T\bar{\Delta} \bx_t\mid\mF_{t-1}]\Big)+\frac{\Upsilon_H}{2}\bar{\alpha}_t^2\|\bar{\Delta}\bx_t\|^2.
\end{align}
Then, we take expectation on both sides conditioning on $\mF_{t-1}$ and obtain
\begin{multline}\label{appen:A2:equ7}
\mE[F_{t+1}-F^\star\mid\mF_{t-1}] \leq F_t-F^\star
+ \mE\Big[\bar{\alpha}_t\mE[\nabla F_t^T\bar{\Delta} \bx_t\mid\mF_{t-1}]\mid \mF_{t-1}\Big]\\
+\mE\Big[\bar{\alpha}_t\Big\{\nabla F_t^T\bar{\Delta}\bx_t-\mE[\nabla F_t^T\bar{\Delta} \bx_t\mid\mF_{t-1}]\Big\}\mid\mF_{t-1}\Big]+\frac{\Upsilon_H}{2}\mE\big[\bar{\alpha}_t^2\|\bar{\Delta}\bx_t\|^2\mid\mF_{t-1}\big].
\end{multline}
For the second term on the right hand side, we apply Assumption \ref{ass:3}, Lemma \ref{aux:lem4}(b, c), and have
\begin{align}\label{appen:A2:equ4}
\mE\Big[\bar{\alpha}_t\mE[\nabla F_t^T\bar{\Delta} \bx_t\mid\mF_{t-1}]\mid \mF_{t-1}\Big]\; &=\; -\nabla F_t^T(I-C_t)B_t^{-1}\nabla F_t \cdot \mE\Big[\bar{\alpha}_t\mid \mF_{t-1}\Big]\nonumber\\
&\leq\Big(- \frac{1}{\Upsilon_H}\|\nabla F_t\|^2 + \frac{\rho^{\tau}}{\gamma_H}\|\nabla F_t\|^2\Big)\cdot \mE\Big[\bar{\alpha}_t\mid \mF_{t-1}\Big]\nonumber\\
&\leq -\frac{3}{4\Upsilon_H}\beta_t\|\nabla F_t\|^2\quad(\text{by }\rho^\tau\leq \gamma_H/4\Upsilon_H\text{ and }\beta_t\leq \bar{\alpha}_t).
\end{align}
For the third term in \eqref{appen:A2:equ7}, we note $\mE\big[\nabla F_t^T\bar{\Delta}\bx_t - \mE[\nabla F_t^T\bar{\Delta}\bx_t\mid\mF_{t-1}]\mid\mF_{t-1}\big]=0$.~Thus,~we~have (recall $\varphi_t=\beta_t+\chi_t/2$)
\begin{multline}\label{appen:A2:equ1}
\mE\Big[\bar{\alpha}_t\Big\{\nabla F_t^T\bar{\Delta}\bx_t-\mE[\nabla F_t^T\bar{\Delta} \bx_t\mid\mF_{t-1}]\Big\}\mid\mF_{t-1}\Big]= \mE\big[(\bar{\alpha}_t-\varphi_t)\nabla F_t^T\big(\bar{\Delta}\bx_t-\mE[\bar{\Delta} \bx_t\mid\mF_{t-1}]\big)\mid\mF_{t-1}\big]\\
\leq \frac{\chi_t}{2}\|\nabla F_t\|\mE\Big[\big\|\bar{\Delta}\bx_t - \mE[\bar{\Delta}\bx_t\mid\mF_{t-1}]\big\|\mid\mF_{t-1}\Big]\quad (\text{by } |\bar{\alpha}_t-\varphi_t|\leq \chi_t/2).
\end{multline}
By Lemma \ref{aux:lem4}(a, b, c), we obtain
\begin{multline*}
\big\|\bar{\Delta}\bx_t - \mE[\bar{\Delta}\bx_t\mid\mF_{t-1}]\big\| = \big\|(I-\tilde{C}_t)B_t^{-1}\bar{g}_t - (I-C_t)B_t^{-1}\nabla F_t\big\|\\
\leq \|C_t-\tilde{C}_t\|\|B_t^{-1}\|\|\nabla F_t\|+\|I-\tilde{C}_t\|\|B_t^{-1}\|\|\bar{g}_t-\nabla F_t\|\stackrel{\eqref{ass:3:c2}}{\leq} \frac{2}{\gamma_H}\|\nabla F_t\|+\frac{2}{\gamma_H}\|\bar{g}_t-\nabla F_t\|.
\end{multline*}
Thus, applying Assumption \ref{ass:2}, we obtain
\begin{align}\label{appen:A2:equ2}
\mE\Big[\big\|\bar{\Delta}\bx_t - \mE[\bar{\Delta}\bx_t\mid\mF_{t-1}]\big\|\mid\mF_{t-1}\Big] &\leq \frac{2}{\gamma_H}\|\nabla F_t\| + \frac{2C_{g,1}^{1/4}}{\gamma_H}\|\bx_t-\bx^\star\|+\frac{2C_{g,2}^{1/4}}{\gamma_H}\nonumber\\
&\leq \frac{4C_{g,1}^{1/4}}{\gamma_H^2}\|\nabla F_t\| +\frac{2C_{g,2}^{1/4}}{\gamma_H} \quad (\text{by } C_{g,1}\geq 1),
\end{align}
where the last inequality also uses the property of strong convexity of $F(\bx)$ \citep{Nesterov2018Lectures} 
\begin{equation}\label{appen:A2:equ3}
\frac{\gamma_H}{2}\left\|\bx_t-\bx^{\star}\right\|^2 \leq F_t-F^{\star} \leq \frac{1}{2 \gamma_H}\left\|\nabla F_t\right\|^2.
\end{equation}
Combining \eqref{appen:A2:equ1} and \eqref{appen:A2:equ2}, we get
\begin{align}\label{appen:A2:equ5}
&\mE\Big[\bar{\alpha}_t\Big\{\nabla F_t^T\bar{\Delta}\bx_t-\mE[\nabla F_t^T\bar{\Delta} \bx_t\mid\mF_{t-1}]\Big\}\mid\mF_{t-1}\Big] \leq \frac{2C_{g,1}^{1/4}}{\gamma_H^2}\chi_t\|\nabla F_t\|^2 + \frac{C_{g,2}^{1/4}}{\gamma_H}\chi_t\|\nabla F_t\|\nonumber\\
&\leq \frac{2C_{g,1}^{1/4}}{\gamma_H^2}\chi_t\|\nabla F_t\|^2 +\frac{1}{4\Upsilon_H}\beta_t\|\nabla F_t\|^2 + \frac{\Upsilon_H C_{g,2}^{1/2}}{\gamma_H^2}\cdot \frac{\chi_t^2}{\beta_t}\quad   \text{(by Young's inequality)}.
\end{align}
Let $\eta_t=\beta_t+\chi_t$. We apply Lemma \ref{aux:lem4}(a) and bound the last term in \eqref{appen:A2:equ7} by
 \begin{align}\label{appen:A2:equ6}
\mE\big[\bar{\alpha}_t^2\|\bar{\Delta} \bx_t\|^2\mid \mF_{t-1}\big]&\leq \mE\big[\bar{\alpha}_t^2\|(I+\tC_t)\|^2\|B_t^{-1}\|^2\|\bar{g}_t\|^2\mid \mathcal{F}_{t-1}\big]\nonumber\\
&\leq \frac{8}{\gamma_H^2}\eta_t^2\Big(\|\nabla F_t\|^2 + \mE\big[\|\bar{g}_t-\nabla F_t\|^2\mid \mathcal{F}_{t-1}\big]\Big)\nonumber\\ 
&\leq \frac{16C_{g,1}^{1/2}}{\gamma_H^4}\eta_t^2\|\nabla F_t\|^2 + \frac{8C_{g,2}^{1/2}}{\gamma_H^2}\eta_t^2\quad \text{(by Assumption \ref{ass:2})}.
\end{align}
We plug \eqref{appen:A2:equ4}, \eqref{appen:A2:equ5}, and \eqref{appen:A2:equ6} into \eqref{appen:A2:equ7}, and obtain
\begin{multline*}
\mE[F_{t+1}-F^\star\mid\mF_{t-1}] \\ 
\leq F_t-F^\star - \Big(\frac{1}{2\Upsilon_H}\beta_t - \frac{2C_{g,1}^{1/4}}{\gamma_H^2}\chi_t-\frac{8\Upsilon_H C_{g,1}^{1/2}}{\gamma_H^4}\eta_t^2\Big)\|\nabla F_t\|^2 + \frac{4\Upsilon_H C_{g, 2}^{1/2}}{\gamma_H^2}\rbr{\frac{\chi_t^2}{\beta_t}+\eta_t^2}.
\end{multline*}
Since $\beta_t = c_{\beta}/(t+1)^{\beta}$ with $\beta\in(0.5, 1]$ and $\chi_t = c_{\chi}/(t+1)^{\chi}$ with $\chi>0.5(\beta+1)\geq \beta$, there exists a fixed integer $t_0$ such that $\frac{2C_{g,1}^{1/4}}{\gamma_H^2}\chi_t+\frac{8\Upsilon_H C_{g,1}^{1/2}}{\gamma_H^4}\eta_t^2\leq\frac{1}{4\Upsilon_H}\beta_t$ for all $t\geq t_0$. Thus, for $t\geq t_0$, we have
\begin{equation*}
\mE[F_{t+1}-F^\star\mid\mF_{t-1}]\leq 
F_t-F^\star - \frac{1}{4\Upsilon_H}\beta_t\|\nabla F_t\|^2 + \frac{4\Upsilon_H C_{g, 2}^{1/2}}{\gamma_H^2}\rbr{\frac{\chi_t^2}{\beta_t}+\eta_t^2}.
\end{equation*}
Note that $\sum_{t=t_0}^\infty \chi_t^2/\beta_t<\infty$ and $\sum_{t=t_0}^\infty \eta_t^2\lesssim \sum_{t=t_0}^\infty \beta_t^2 + \sum_{t=t_0}^\infty \chi_t^2<\infty$.~Thus, we~\mbox{apply}~the~Robbins-Siegmund Theorem \cite[Theorem 1.3.12]{Duflo2013Random} and conclude that $F_t-F^\star$ converges~to~a finite random variable, and $\sum_{t=t_0}^{\infty}\beta_t\left\|\nabla F_t\right\|^2 < \infty$ almost surely. Furthermore, we have $\liminf_{t\rightarrow\infty}\|\nabla F_t\|=0$ due to $\sum_{t=t_0}^\infty\beta_t = \infty$, which leads to $\liminf_{t\rightarrow\infty}(F_t-F^\star) =0$ according to \eqref{appen:A2:equ3}. Since $F_t-F^\star$~converges almost surely, the conclusion can be strengthened to $\lim_{t\rightarrow\infty}F_t-F^\star =0$. Again, we~apply~\eqref{appen:A2:equ3} and obtain $\lim_{t\rightarrow\infty}\bx_t = \bx^\star$ almost surely. This completes the proof.



\subsection{Proof of Theorem \ref{sec3:thm2}}\label{pf:sec3:thm2}

The proof of asymptotic normality is almost identical to the proof of Theorem 5.6 in \cite{Na2022Statistical}. Since $\chi>1.5\beta\Rightarrow \chi>0.5(\beta+1)$, we have $\bx_t\rightarrow \bx^\star$ almost surely, as proved~in~Theorem \ref{sec3:thm1}. Therefore, we only have to note that our growth conditions in Assumptions \ref{ass:2} and \ref{ass:3} on gradients and Hessians do not affect the proof of normality (though they affect the proof of convergence),~since the term $\|\bx_t-\bx^\star\|$ in the growth conditions converges to $0$ almost surely.


\section{Proofs of Section \ref{sec4:subsec1}}

To clear up tedious constants, we assume $\eta_t=\beta_t+\chi_t\leq 1$, $\forall t\geq 0$, without loss of generality for the remainder of this paper.~Note that this condition is non-essential, since $\eta_t \rightarrow 0$~and~the~\mbox{condition}~will~always hold for sufficiently large, fixed $t$.


\subsection{Proof of Lemma \ref{sec4:lem1}}\label{pf:xtbound}

We separate the proof into two parts. 
\vskip4pt
\noindent \textbf{Part 1: Bound of $\mE[\|\bx_t-\bx^\star\|^4]$.} We take square on both sides of \eqref{appen:A2:equ8} and take expectation~conditioning on $\mathcal{F}_{t-1}$, then we get
\begin{align}\label{appen:A3:equ1}
& \mE\big[(F_{t+1}-F^\star)^2\mid \mathcal{F}_{t-1}\big] \leq (F_t-F^\star)^2+\mE\big[2 \bar{\alpha}_t(F_t-F^\star) \nabla F_t^T \bar{\Delta} \bx_t\mid \mathcal{F}_{t-1}\big] + \mE\big[\bar{\alpha}_t^2 \Upsilon_{H}(F_t-F^\star)\|\bar{\Delta} \bx_t\|^2\mid \mathcal{F}_{t-1}\big] \nonumber \\
& +\mE\big[\bar{\alpha}_t^2(\nabla F_t^{T} \bar{\Delta} \bx_t)^2\mid \mathcal{F}_{t-1}\big] + \mE\big[\bar{\alpha}_t^3 \Upsilon_{H} \nabla F_t^{T} \bar{\Delta}\bx_t\|\bar{\Delta} \bx_t\|^2\mid \mathcal{F}_{t-1}\big] +\frac{1}{4}\mE\big[\bar{\alpha}_t^4 \Upsilon_{H}^2\|\bar{\Delta} \bx_t\|^4\mid \mathcal{F}_{t-1}\big].
\end{align}
We rearrange these terms by the order of $\bar{\alpha}_t$ and analyze them one by one.
\vskip4pt
\noindent $\bullet$ \textbf{Term 1:} $\mE[2 \bar{\alpha}_t(F_t-F^\star) \nabla F_t^T \bar{\Delta} \bx_t\mid \mF_{t-1}]$.

\noindent This term can be decomposed as
\begin{align*}
\mE[2 \bar{\alpha}_t(F_t-F^\star) \nabla F_t^T \bar{\Delta} \bx_t\mid \mF_{t-1}] & = 2(F_t-F^\star)\mE\Big[\bar{\alpha}_t\mE[\nabla F_t^T\bar{\Delta} \bx_t\mid\mF_{t-1}]\mid \mF_{t-1}\Big]\\
& \quad +2(F_t-F^\star)\mE\Big[\bar{\alpha}_t\Big\{\nabla F_t^T\bar{\Delta}\bx_t-\mE[\nabla F_t^T\bar{\Delta} \bx_t\mid\mF_{t-1}]\Big\}\mid\mF_{t-1}\Big].
\end{align*}
For the first term on the right hand side, by \eqref{appen:A2:equ4} and \eqref{appen:A2:equ3}, we have
\begin{equation}\label{appen:A3:equ3}
2(F_t-F^\star)\mE\Big[\bar{\alpha}_t\mE[\nabla F_t^T\bar{\Delta} \bx_t\mid\mF_{t-1}]\mid \mF_{t-1}\Big]\leq -\frac{3}{2\Upsilon_H}\beta_t(F_t-F^\star)\|\nabla F_t\|^2\leq -\frac{3\gamma_H}{\Upsilon_H}\beta_t(F_t-F^{\star})^2.
 \end{equation}
For the second term on the right hand side, \eqref{appen:A2:equ1} and \eqref{appen:A2:equ2} give us
\begin{align}\label{appen:A3:equ4}
& \hskip-0.6cm  2(F_t-F^\star)\mE\Big[\bar{\alpha}_t\Big\{\nabla F_t^T\bar{\Delta}\bx_t-\mE[\nabla F_t^T\bar{\Delta} \bx_t\mid\mF_{t-1}]\Big\}\mid\mF_{t-1}\Big] \nonumber\\
&\hskip-0.6cm \leq \chi_t(F_t-F^\star) \|\nabla F_t\|\Big(\frac{2}{\gamma_H}\|\nabla F_t\| +\frac{2C_{g,1}^{1/4}}{\gamma_H}\|\bx_t-\bx^\star\| + \frac{2C_{g,2}^{1/4}}{\gamma_H}\Big) \nonumber\\
&\hskip-0.6cm \leq \frac{4\Upsilon_H^{1/2}}{\gamma_H}\Big(\Upsilon_H^{1/2}+ \frac{C_{g,1}^{1/4}}{\gamma_H^{1/2}}\Big)\chi_t(F_t-F^\star)^2 + \frac{2\sqrt{2}\Upsilon_H^{1/2}C_{g,2}^{1/4}}{\gamma_H}\chi_t(F_t-F^\star)^{3/2} \nonumber\\
&\hskip-0.6cm \leq \rbr{\frac{4\Upsilon_H^{1/2}}{\gamma_H}\Big(\Upsilon_H^{1/2}+ \frac{C_{g,1}^{1/4}}{\gamma_H^{1/2}}\Big)\chi_t+ \frac{\gamma_H}{2\Upsilon_H}\beta_t}(F_t-F^\star)^2 + \frac{3^4\Upsilon_H^5C_{g,2}}{\gamma_H^7}\cdot\frac{\chi_t^4}{\beta_t^3}\quad \text{(Young's inequality)}.
\end{align}
Here, the second inequality is due to \eqref{appen:A2:equ3} and the following $\Upsilon_H$-Lipschitz continuity property of $\nabla F(\bx)$ \citep{Nesterov2018Lectures}:
\begin{equation}\label{appen:A3:equ2}
\frac{1}{2\Upsilon_{H}}\|\nabla F_t\|^2\leq F_t-F^{\star}\leq \frac{\Upsilon_{H}}{2}\|\bx_t-\bx^\star\|^2.
\end{equation}
\noindent$\bullet$ \textbf{Term 2:} $\mE[\bar{\alpha}_t^2 \Upsilon_{H}(F_t-F^\star)\|\bar{\Delta} \bx_t\|^2+\bar{\alpha}_t^2(\nabla F_t^{T} \bar{\Delta} \bx_t)^2\mid \mF_{t-1}]$.


\noindent Since $\bar{\alpha}_t\leq \eta_t$, we bound this term by
\begin{align}\label{appen:A3:equ5}
&\mE[\;\bar{\alpha}_t^2 \Upsilon_{H}(F_t - F^\star)\|\bar{\Delta} \bx_t\|^2 +\bar{\alpha}_t^2(\nabla F_t^{T} \bar{\Delta} \bx_t)^2\mid \mF_{t-1}] \leq \eta_t^2 \mE\big[\big(\Upsilon_{H}(F_t-F^\star) + \|\nabla F_t\|^2\big)\|\bar{\Delta} \bx_t\|^2\mid \mF_{t-1}\big]\nonumber\\
&\stackrel{\mathclap{\eqref{appen:A3:equ2}}}{\leq}\;\;3\Upsilon_{H}\eta_t^2\mE\big[(F_t-F^\star)\|\bar{\Delta} \bx_t\|^2\mid \mF_{t-1}\big] \leq \frac{\gamma_H}{2\Upsilon_H}(\beta_t+\chi_t) (F_t-F^\star)^2+\frac{9\Upsilon_H^3}{2\gamma_H}\eta_t^3 \mE\big[\|\bar{\Delta} \bx_t\|^4\mid \mF_{t-1}\big],
\end{align}
where the last inequality is by Young's inequality.

\vskip4pt
\noindent$\bullet$ \textbf{Term 3:} $\mE[\;\bar{\alpha}_t^3 \Upsilon_H \nabla F_t^{T} \bar{\Delta}\bx_t\|\bar{\Delta} \bx_t\|^2\mid \mF_{t-1}]$.

\noindent Similarly, we use Young's inequality, apply \eqref{appen:A3:equ2}, and have
\begin{align}\label{appen:A3:equ6}
&\hskip-0.7cm \mE[\;\bar{\alpha}_t^3 \Upsilon_{H} \nabla F_t^{T} \bar{\Delta}\bx_t\|\bar{\Delta} \bx_t\|^2\mid \mF_{t-1}]  \leq \eta_t^3\Upsilon_{H}\mE[\|\nabla F_t\| \|\bar{\Delta}\bx_t\|^3\mid \mF_{t-1}] \nonumber\\
&\hskip-0.7cm \leq \frac{1}{4}\eta_t^3\|\nabla F_t\|^4+\frac{3\Upsilon_{H}^{4/3}}{4}\eta_t^3\mE\big[\|\bar{\Delta}\bx_t\|^4\mid\mF_{t-1}\big]  \stackrel{\mathclap{\eqref{appen:A3:equ2}}}{\leq}\; \Upsilon_{H}^2\eta_t^3(F_t-F^\star)^2+\frac{3\Upsilon_{H}^{4/3}}{4}\eta_t^3\mE\big[\|\bar{\Delta}\bx_t\|^4\mid\mF_{t-1}\big].
\end{align}
Substituting \eqref{appen:A3:equ3}, \eqref{appen:A3:equ4}, \eqref{appen:A3:equ5}, and \eqref{appen:A3:equ6} into \eqref{appen:A3:equ1}, we obtain
\begin{multline*}
\mE[(F_{t+1}-F^\star)^2\mid\mF_{t-1}]\leq \Big(1-
\frac{2\gamma_H}{\Upsilon_H}\beta_t+\frac{\gamma_H}{2\Upsilon_H}\chi_t+\frac{4\Upsilon_H^{1/2}}{\gamma_H}\Big(\Upsilon_H^{1/2}+ \frac{C_{g,1}^{1/4}}{\gamma_H^{1/2}}\Big)\chi_t+\Upsilon_{H}^2\eta_t^3\Big)(F_t-F^\star)^2\\
+\frac{3^4\Upsilon_H^5C_{g,2}}{\gamma_H^7}\cdot\frac{\chi_t^4}{\beta_t^3} +\frac{6\Upsilon_H^3}{\gamma_H} \eta_t^3\mE\big[\|\bar{\Delta} \bx_t\|^4\mid \mF_{t-1}\big]\quad(\text{by }\eta_t\leq 1).
\end{multline*}
Following the analysis in \eqref{appen:A2:equ6}, we apply Assumption \ref{ass:2} and have
\begin{align*}
\mE\big[\|\bar{\Delta} \bx_t\|^4\mid \mF_{t-1}\big] & \leq \frac{2^4}{\gamma_H^4}\mE[\|\barg_t\|^4 \mid \mF_{t-1}] \leq \frac{2^7}{\gamma_H^4}\rbr{\mE[\|\barg_t - \nabla F_t\|^4 \mid \mF_{t-1}] + \|\nabla F_t\|^4}\\
& \stackrel{\mathclap{\eqref{appen:A3:equ2}}}{\leq}\; \frac{2^9\Upsilon_{H}^2}{\gamma_H^4}(F_t-F^\star)^2 + \frac{2^7C_{g,1}}{\gamma_H^4}\|\bx_t-\tx\|^4 + \frac{2^7C_{g,2}}{\gamma_H^4}\\
& \stackrel{\mathclap{\eqref{appen:A2:equ3}}}{\leq}\; \frac{2^9\Upsilon_{H}^2}{\gamma_H^4}(F_t-F^\star)^2 + \frac{2^9C_{g,1}}{\gamma_H^6}(F_t-F^\star)^2 + \frac{2^7C_{g,2}}{\gamma_H^4} \\
& = \frac{2^{9}(\Upsilon_H^2 + C_{g,1}/\gamma_H^2)}{\gamma_H^4}(F_t-F^\star)^2 + \frac{2^7C_{g,2}}{\gamma_H^4}.
\end{align*}
Combining the above two displays and taking full expectation, we obtain the recursion:
\begin{align*}
&\mE[(F_{t+1}-F^\star)^2] \\
& \leq \rbr{1-
\frac{2\gamma_H}{\Upsilon_H}\beta_t+\frac{\gamma_H}{2\Upsilon_H}\chi_t+ \frac{4\Upsilon_H^{1/2}}{\gamma_H}\Big(\Upsilon_H^{1/2}+ \frac{C_{g,1}^{1/4}}{\gamma_H^{1/2}}\Big)\chi_t + \frac{2^{12}\Upsilon_{H}^3(\Upsilon_{H}^2+C_{g,1}/\gamma_H^2)}{\gamma_H^5}\eta_t^3}\mE[(F_{t}-F^\star)^2]\\
& \quad +\frac{3^4\Upsilon_H^5C_{g,2}}{\gamma_H^7}\frac{\chi_t^4}{\beta_t^3}  + \frac{2^{10}\Upsilon_H^3C_{g,2}}{\gamma_H^5} \eta_t^3.
\end{align*}
We apply the above inequality recursively until $(F_0 - F^\star)^2$ and then apply Lemma \ref{aux:lem5} to compute~the rate of $\mE[(F_t-F^\star)^2]$. We first verify the assumptions. Since $\chi_t = o(\beta_t)$ by $\chi>\beta$, we know
\begin{equation*}
\lim_{i\rightarrow\infty}\frac{\beta_i - \frac{\Upsilon_H}{2\gamma_H}\rbr{\frac{\gamma_H}{2\Upsilon_H}\chi_i+\frac{4\Upsilon_H^{1/2}}{\gamma_H}\Big(\Upsilon_H^{1/2}+ \frac{C_{g,1}^{1/4}}{\gamma_H^{1/2}}\Big)\chi_i+ \frac{2^{12}\Upsilon_{H}^3(\Upsilon_{H}^2+C_{g,1}/\gamma_H^2)}{\gamma_H^5}\eta_i^3}}{\beta_i} = 1.
\end{equation*}
Since $\beta\in(0,1)$, we have $\lim_{i\rightarrow\infty}i\beta_i=\infty$ and \eqref{appen:A1:cond2} holds naturally. Furthermore, since $\lim_{i\rightarrow\infty}i(1-\beta_{i-1}/\beta_i)=-\beta$ and $\lim_{i\rightarrow\infty}i(1-\chi_{i-1}/\chi_i)=-\chi$, we obtain from Lemma \ref{aux:lem3} that $\lim_{i\rightarrow\infty}i(1-\beta_{i-1}^4/\beta_i^4)=-4\beta$ and $\lim_{i\rightarrow\infty}i(1-\chi_{i-1}^4/\chi_i^4)=-4\chi$. Thus, we have
\begin{equation*}
\begin{aligned}
&\lim_{i \rightarrow\infty} i\rbr{1-\frac{\chi_{i-1}^4/\beta_{i-1}^4}{\chi_i^4/\beta_i^4}}  = \lim_{i \rightarrow\infty} i\rbr{1-\frac{\chi_{i-1}^4}{\chi_{i}^4} + \frac{\chi_{i-1}^4}{\chi_{i}^4}\cbr{1-\frac{1/\beta_{i-1}^4}{1/\beta_i^4}}} = 4(\beta-\chi)<0, \\
&\lim_{i \rightarrow\infty} i\rbr{1-\frac{\eta_{i-1}^3/\beta_{i-1}}{\eta_i^3/\beta_i}}  = \lim_{i \rightarrow\infty} i\rbr{1-\frac{\eta_{i-1}^3}{\eta_{i}^3} + \frac{\eta_{i-1}^3}{\eta_{i}^3}\cbr{1-\frac{1/\beta_{i-1}}{1/\beta_i}}} = -2\beta<0.
\end{aligned}	
\end{equation*}
This suggests that \eqref{appen:A1:cond1} also holds. Now, we apply Lemma \ref{aux:lem5} and obtain
\begin{align}\label{xtrate}
\mE\big[\|\bx_t-\bx^\star\|^4\big]&\stackrel{\mathclap{\eqref{appen:A2:equ3}}}{\lesssim}\;\; \frac{1}{\gamma_H^2}\mE\big[(F_t-F^\star)^2\big]
\lesssim \frac{1}{\gamma_H^2}\cdot \frac{\Upsilon_{H}}{\gamma_H}  \rbr{\frac{\Upsilon_H^5C_{g,2}}{\gamma_H^7}\cdot\frac{\chi_t^4}{\beta_t^4}  + \frac{\Upsilon_H^3C_{g,2}}{\gamma_H^5}\cdot\frac{\eta_t^3}{\beta_t}}\\
&\lesssim \frac{\Upsilon_H^4C_{g,2}}{\gamma_H^8} \beta_t^2 + \frac{\Upsilon_H^6C_{g,2}}{\gamma_H^{10}} \cdot\frac{\chi_t^4}{\beta_t^4}= O\rbr{\beta_t^2 + \frac{\chi_t^4}{\beta_t^4}}.
\end{align}
\noindent \textbf{Part 2: Bound of $\mE[\|B_t-B^\star\|^4]$.} By the construction of $B_t$ in \eqref{nequ:5}, we have
\begin{equation}\label{appen:A3:equ12}
\mE\big[\|B_t-B^\star\|^4\big] \lesssim\mE\bigg[\Big\|\frac{1}{t} \sum_{i=0}^{t-1}(\bar{H}_i-\nabla^2 F_i)\Big\|^4\bigg]
+\mE\bigg[\Big\|\frac{1}{t} \sum_{i=0}^{t-1}(\nabla^2 F_i-\nabla^2 F^\star)\Big\|^4\bigg].
\end{equation}
For the first term, we note that $\bar{H}_i-\nabla^2 F_i$ is a martingale difference sequence and \eqref{ass:3:4th} implies
\begin{equation*}
\mE\big[\left\|\bar{H}_i-\nabla^2 F_i\right\|_F^4\big] \lesssim \mE\big[\left\|\bar{H}_i-\nabla^2 F_i\right\|^4\big] \stackrel{\eqref{ass:3:4th}}{\lesssim} C_{H,1}\mE\big[\|\bx_t-\bx^\star\|^4\big] + C_{H,2}.
\end{equation*}
Therefore, same as in \cite[(63)]{Chen2020Statistical}, we apply \cite[Theorem 2.1]{Rio2008Moment} and obtain
\begin{align*}
\mE\bigg[\Big\|\frac{1}{t} \sum_{i=0}^{t-1}(\bar{H}_i-\nabla^2 F_i)\Big\|^4\bigg]&\leq  \mE\bigg[\Big\|\frac{1}{t} \sum_{i=0}^{t-1}(\bar{H}_i-\nabla^2 F_i)\Big\|_F^4\bigg]\lesssim \frac{1}{t^4}\bigg[\sum_{i=0}^{t-1}\Big(\mE\big[\|\bar{H}_i-\nabla^2 F_i\|_F^4\big]\Big)^{1 / 2}\bigg]^2\nonumber\\
&\lesssim \frac{1}{t^4}\Big(\sum_{i=0}^{t-1} C_{H,1}^{1/2}(\mE\big[\|\bx_t-\bx^\star\|^4\big])^{1/2}\Big)^2 + \frac{1}{t^4}\Big(\sum_{i=0}^{t-1} C_{H,2}^{1/2}\Big)^2\nonumber\\ 
&\stackrel{\mathclap{\eqref{xtrate}}}{\lesssim}\;\; \frac{1}{t^2}\bigg(\frac{\Upsilon_H^4 C_{g,2} C_{H,1}}{\gamma_H^8} \Big(\frac{1}{t}\sum_{i=0}^{t-1} \beta_i\Big)^2 + \frac{\Upsilon_H^6 C_{g,2} C_{H,1}}{\gamma_H^{10}}\Big(\frac{1}{t} \sum_{i=0}^{t-1} \frac{\chi_i^2}{\beta_i^2}\Big)^2 \bigg) + \frac{C_{H,2}}{t^2}.
\end{align*}
We only consider the case where $\chi\leq 1.5\beta$, otherwise $\chi_t^2/\beta_t^2 = o(\beta_t)$ and all $\chi_t^2/\beta_t^2$ terms in~the~following can be absorbed into $\beta_t$. We note that
\begin{equation}\label{appen:A3:equ11}
\frac{1}{t}\sum_{i=0}^{t-1}\beta_i = \frac{1}{t}\beta_0 + \sum_{i=1}^{t-1}\prod_{j=i+1}^{t-1}\Big(1-\frac{1}{j}\Big)\frac{1}{i}\beta_i\stackrel{\eqref{appen:A1:equ1a}}{\lesssim} \frac{1}{1-\beta}\beta_t\quad\text{and}\quad \frac{1}{t}\sum_{i=0}^{t-1}\frac{\chi_i^2}{\beta_i^2} \stackrel{\eqref{appen:A1:equ1a}}{\lesssim} \frac{1}{1-2(\chi-\beta)}\cdot\frac{\chi_t^2}{\beta_t^2},
\end{equation}
where we are able to apply Lemma \ref{aux:lem1} since the condition \eqref{appen:A1:cond2} is satisfied by $\beta<1$ and~$\chi\leq 1.5\beta\Rightarrow 2\chi-2\beta<1$. Thus, we combine the above two displays and have
\begin{equation}\label{appen:A3:equ13}
\footnotesize \frac{1}{t^2}\bigg(\frac{\Upsilon_H^4 C_{g,2} C_{H,1}}{\gamma_H^8} \Big(\frac{1}{t}\sum_{i=0}^{t-1} \beta_i\Big)^2 + \frac{\Upsilon_H^6 C_{g,2} C_{H,1}}{\gamma_H^{10}}\Big(\frac{1}{t} \sum_{i=0}^{t-1} \frac{\chi_i^2}{\beta_i^2}\Big)^2 \bigg) = o\rbr{\frac{1}{t^2}} \quad \text{and} \quad \mE\bigg[\Big\|\frac{1}{t} \sum_{i=0}^{t-1}(\bar{H}_i-\nabla^2 F_i)\Big\|^4\bigg]\lesssim \frac{C_{H,2}}{t^2}.
\end{equation}
For the second term on the right hand side in \eqref{appen:A3:equ12}, the $\Upsilon_L$-Lipschitz continuity of $\nabla^2 F(\bx)$ leads to
\begin{align}\label{appen:A3:equ14}
&\mE\bigg[\Big\|\frac{1}{t} \sum_{i=0}^{t-1}(\nabla^2 F_i-\nabla^2 F^\star)\Big\|^4\bigg] \leq  \mE\bigg[\Big(\frac{1}{t} \sum_{i=0}^{t-1}\|\nabla^2 F_i-\nabla^2 F^\star\|\Big)^4\bigg]
\leq\frac{\Upsilon_{L}^4}{t^4} \mE\bigg[\Big(\sum_{i=0}^{t-1}\|\bx_i-\bx^\star\|\Big)^4\bigg]\nonumber\\
&\leq \frac{\Upsilon_{L}^4}{t^4} \Big(\sum_{i=0}^{t-1}\big(\mE[\|\bx_i-\bx^\star\|^4]\big)^{1/4}\Big)^4 \quad (\text{by H\"older's inequality})\nonumber\\
&\stackrel{\mathclap{\eqref{xtrate}}}{\lesssim}\;\; \frac{\Upsilon_{L}^4\Upsilon_H^4C_{g,2}}{\gamma_H^8} \rbr{\frac{1}{t}\sum_{i=0}^{t-1}\beta_i^{1/2}}^4 + \frac{\Upsilon_{L}^4\Upsilon_H^6C_{g,2}}{\gamma_H^{10}}\rbr{\frac{1}{t}\sum_{i=0}^{t-1}\frac{\chi_i}{\beta_t}}^4\nonumber\\
&\stackrel{\mathclap{\eqref{appen:A3:equ11}}}{\lesssim}\;\; \frac{\Upsilon_{L}^4\Upsilon_H^4C_{g,2}}{\gamma_H^8} \beta_t^2 + \frac{\Upsilon_{L}^4\Upsilon_H^6C_{g,2}}{\gamma_H^{10}}\cdot \frac{\chi_t^4}{\beta_t^4}\quad (\text{by }1-\beta/2>1/2\quad\text{and}\quad 1-(\chi-\beta)>1/2).
\end{align}
Plugging \eqref{appen:A3:equ13} and \eqref{appen:A3:equ14} into \eqref{appen:A3:equ12}, we have
\begin{equation}\label{appen:A3:equ15}
\mE\big[\|B_t-B^\star\|^4\big] \lesssim \frac{\Upsilon_{L}^4\Upsilon_H^4C_{g,2}}{\gamma_H^8} \beta_t^2 + \frac{\Upsilon_{L}^4\Upsilon_H^6C_{g,2}}{\gamma_H^{10}}\cdot \frac{\chi_t^4}{\beta_t^4} = O\rbr{\beta_t^2 + \frac{\chi_t^4}{\beta_t^4}}.
\end{equation}
This completes the proof.


\subsection{Analysis of a dominant term in $\hat{\Xi}_t$}\label{appen:A4}

In this section, we focus on a dominant term of $\hat{\Xi}_t$ and show that the dominate term converges~to~the limiting~covariance matrix $\Xi^\star$. We first introduce a decomposition of the iterate $\bx_t$.

\begin{lemma}\label{appen:A4:lem1}\cite[Lemma 5.1]{Na2022Statistical}
The iterate sequence \eqref{nequ:7} can be decomposed as
\begin{equation}\label{appen:A4:equ1}
\bx_{t+1}-\bx^\star = \I_{1,t} + \I_{2,t} + \I_{3,t},
\end{equation}
where
\begin{align}
\I_{1,t} & = \sum_{i=0}^t\prod_{j=i+1}^{t}\cbr{I - \varphi_j(I-C^\star)}\varphi_i \btheta^i, \label{rec:a}\\
\I_{2,t} & = \sum_{i=0}^t\prod_{j=i+1}^{t} \cbr{I - \varphi_j(I-C^\star)}\rbr{\baralpha_i - \varphi_i}\bar{\Delta}\bx_i, \label{rec:b}\\
\I_{3,t} & = \prod_{i=0}^{t}\cbr{I - \varphi_i(I-C^\star)}(\bx_0 - \bx^\star) + \sum_{i=0}^t\prod_{j=i+1}^{t}\cbr{I - \varphi_j(I-C^\star)}\varphi_i\bdelta^i, 
\label{rec:c}
\end{align}
and
\begin{align}
C^\star &= (I - \mE[B^\star S(S^T(B^\star)^2S)^\dagger S^TB^\star])^\tau, \label{rec:def:a}\\ 
\btheta^i &= \bar{\Delta}\bx_i-\mE[\bar{\Delta}\bx_i\mid \mF_{i-1}] = -(I-\tilde{C}_i)B_i^{-1}\bar{g}_i + (I-C_i)B_i^{-1}\nabla F_i, \label{rec:def:b}\\ 
\bdelta^i &= -(I-C_i)\big\{(B^{\star})^{-1}\bpsi^i + \{B_i^{-1} - (B^\star)^{-1}\}\nabla F_i\big\}
+ \big(C_i-C^\star\big)(\bx_i - \bx^\star),\label{rec:def:c}\\ 
\bpsi^i &= \nabla F_i - B^\star(\bx_i-\bx^\star). \label{rec:def:d} 
\end{align}
\end{lemma}

Here, $\I_{1,t}$ includes the summation of martingale difference sequence; $\I_{2,t}$ characterizes the~influence of the adaptive stepsize; and $\I_{3,t}$ encompasses all remaining errors.~Based on \eqref{appen:A4:equ1},~we~decompose the following matrix as
\begin{equation}\label{appen:A4:equ20}
\frac{1}{t}\sum_{i=1}^t \frac{1}{\varphi_{i-1}}(\bx_i-\bx^\star)(\bx_i-\bx^\star)^T = \sum_{k=1}^3\sum_{l=1}^3\frac{1}{t}\sum_{i=0}^{t -1}\frac{1}{\varphi_i}\I_{k,i}\I_{l,i}.
\end{equation}
We study the dominant term $\frac{1}{t}\sum_{i=0}^{t-1}\frac{1}{\varphi_i}\I_{1,i}\I_{1,i}^T$ in this section and defer the analysis on the remaining terms to Appendix \ref{appen:A5}. The next lemma shows consistency of the dominant term and establishes~the convergence rate, with proof provided in Appendix \ref{pf:I1}.

\begin{lemma}\label{appen:A4:lem2}
Suppose Assumptions \ref{ass:1} -- \ref{ass:4} hold, the \mbox{number}~of~sketches satisfies $\tau\geq \log(\gamma_H/4\Upsilon_H)/\log \rho$ with $\rho = 1-\gamma_S$, and the stepsize parameters satisfy $\beta\in(0,1)$,~$\chi> \beta$, and $c_{\beta}, c_{\chi}>0$. Then, we~have
\begin{equation*}
\mE\bigg[\Big\|\frac{1}{t}\sum_{i=0}^{t-1}\frac{1}{\varphi_i}\I_{1,i}\I_{1,i}^T-\Xi^\star\Big\|\bigg]\lesssim \begin{dcases}
\sqrt{\beta_t} + \chi_t/\beta_t, &\beta\in(0,0.5],\\
1/\sqrt{t\beta_t} + \chi_t/\beta_t, &\beta\in (0.5,1).        
\end{dcases}
\end{equation*} 
\end{lemma}


\subsubsection{Proof of Lemma \ref{appen:A4:lem2}}\label{pf:I1}

We define
\begin{equation}\label{Ctildestar}
\tilde{C}^\star_{k,j}=I-\big(B^\star S_{k,j}(S_{k,j}^T(B^\star)^2S_{k,j})^{\dagger}S_{k,j}^TB^\star\big)\quad \text{ and }\quad \tilde{C}^\star_k = \prod_{j=1}^\tau \tilde{C}^\star_{k,j},
\end{equation}
where $S_{k,j}$ is the same sketching matrix in $\tilde{C}_{k,j}$ at \eqref{appen:A1:equ6}. It is easy to verify $\mE\tilde{C}_k^\star = C^\star$ with~$C^\star$~defined in \eqref{rec:def:a}. We also define 
\begin{equation}\label{appen:A4:equ3}
\tilde{\btheta}^k = -(I-\tilde{C}^\star_k)(B^{\star})^{-1}\nabla f(\bx^\star;\xi_k)\quad \text{ and }\quad \hat{\btheta}^k = \btheta^k-\tilde{\btheta}^k.
\end{equation}
Basically, $\tilde{\btheta}^k$ and $\btheta^k$ share the same randomness but $\tilde{\btheta}^k$ is constructed at $\bx^\star$ instead of $\bx_k$, which means we use the $iid$ copies $\{\tilde{\btheta}^k\}_k$ to approximate the martingale difference sequence~$\{\btheta^k\}_k$.~We~decompose $\I_{1,i}$ as
\begin{equation}\label{appen:A4:equ2}
\I_{1,i} = \sum_{k=0}^i\prod_{l=k+1}^i\{I-\varphi_l(I-C^\star)\}\varphi_k \tilde{\btheta}^k + \sum_{k=0}^i\prod_{l=k+1}^i\{I-\varphi_l(I-C^\star)\}\varphi_k \hat{\btheta}^k =:  \tilde{\I}_{1,i} +\hat{\I}_{1,i}.
\end{equation}
Intuitively, as $\bx_i$ converges to $\bx^\star$, $\tilde{\I}_{1,i}$ should be a good approximation to $\I_{1,i}$ and $\hat{\I}_{1,i}$ should be~negligible. The next two lemma provide bounds for $\tilde{\I}_{1,i}$ and $\hat{\I}_{1,i}$, respectively. The proofs~are~provided~in Appendices \ref{pf:tildeI1} and \ref{pf:hatI1}.


\begin{lemma}\label{appen:A4:lem3}
Under the assumptions of Lemma \ref{appen:A4:lem2}, we have
\begin{equation*}
\mE\bigg[\Big\|\frac{1}{t}\sum_{i=0}^{t-1}\frac{1}{\varphi_i}\tilde{\I}_{1,i}\tilde{\I}_{1,i}^T-\Xi^\star\Big\|\bigg] \lesssim \left\{\begin{aligned}
&\beta_t, &\beta\in(0,1/3],\\
&1/\sqrt{t\beta_t}, &\beta\in(1/3,1).  
\end{aligned}\right.
\end{equation*}
\end{lemma}

\begin{lemma}\label{appen:A4:lem4}
Under the assumptions of Lemma \ref{appen:A4:lem2}, we have
\begin{equation*}
\mE\bigg[\Big\|\frac{1}{t}\sum_{i=0}^{t-1}\frac{1}{\varphi_i}\hat{\I}_{1,i}\hat{\I}_{1,i}^T\Big\|\bigg]\leq\frac{1}{t}\sum_{i=0}^{t-1} \frac{1}{\varphi_i} \mE\big[\|\hat{\I}_{1,i}\|^2\big] \lesssim \beta_t + \frac{\chi_t^2}{\beta_t^2}.
\end{equation*}
\end{lemma}


By the decomposition \eqref{appen:A4:equ2}, we have
\begin{multline}\label{appen:A4:equ23}
\mE\bigg[\Big\|\frac{1}{t}\sum_{i=0}^{t-1}\frac{1}{\varphi_i}\I_{1,i}\I_{1,i}^T-\Xi^\star\Big\|\bigg] \leq \mE\bigg[\Big\|\frac{1}{t}\sum_{i=0}^{t-1}\frac{1}{\varphi_i}\tilde{\I}_{1,i}\tilde{\I}_{1,i}^T-\Xi^\star\Big\|\bigg]\\
+\mE\bigg[\Big\|\frac{1}{t}\sum_{i=0}^{t-1}\frac{1}{\varphi_i}\hat{\I}_{1,i}\hat{\I}_{1,i}^T\Big\|\bigg] + 2\mE\bigg[\Big\|\frac{1}{t}\sum_{i=0}^{t-1}\frac{1}{\varphi_i}\tilde{\I}_{1,i}\hat{\I}_{1,i}^T\Big\|\bigg].
\end{multline}
We apply H\"older's inequality twice to the last term and obtain
\begin{multline}\label{appen:A4:equ19}
\mE\bigg[\Big\|\frac{1}{t}\sum_{i=0}^{t-1}\frac{1}{\varphi_i}\tilde{\I}_{1,i}\hat{\I}_{1,i}^T\Big\|\bigg]
\leq \mE\bigg[\frac{1}{t}\sum_{i=0}^{t-1}\frac{1}{\varphi_i}\|\tilde{\I}_{1,i}\|\|\hat{\I}_{1,i}\|\bigg]\\
\leq \mE\Bigg[\sqrt{\frac{1}{t}\sum_{i=0}^{t-1}\frac{1}{\varphi_i}\|\tilde{\I}_{1,i}\|^2}\sqrt{\frac{1}{t}\sum_{i=0}^{t-1}\frac{1}{\varphi_i}\|\hat{\I}_{1,i}\|^2}\Bigg]\leq\sqrt{\frac{1}{t}\sum_{i=0}^{t-1}\frac{1}{\varphi_i}\mE\|\tilde{\I}_{1,i}\|^2} \sqrt{\frac{1}{t}\sum_{i=0}^{t-1}\frac{1}{\varphi_i}\mE\|\hat{\I}_{1,i}\|^2}.
\end{multline}
Given Lemmas \ref{appen:A4:lem3} and \ref{appen:A4:lem4}, it suffices to bound $\frac{1}{t}\sum_{i=0}^{t-1}\frac{1}{\varphi_i}\mE\|\tilde{\I}_{1,i}\|^2$. We have
\begin{align}\label{appen:A4:equ4}
&\mE\big[\|\tilde{\I}_{1,i}\|^2\big]\;\; \stackrel{\mathclap{\eqref{appen:A4:equ2}}}{=}\;\; \sum_{k_1,k_2=0}^i\varphi_{k_1}\varphi_{k_2}\mE\Big[(\tilde{\btheta}^{k_1})^T\Big(\prod_{l_1=k_1+1}^i\big\{I-\varphi_{l_1}(I-C^\star)\big\}\Big)^T \Big(\prod_{l_2=k_2+1}^i\big\{I-\varphi_{l_2}(I-C^\star)\big\}\Big) \tilde{\btheta}^{k_2}\Big]\nonumber\\
& = \sum_{k=0}^i\varphi_k^2 \mE\bigg[\Big\|\prod_{l=k+1}^i\big\{I-\varphi_{l}(I-C^\star)\big\}\tilde{\btheta}^k\Big\|^2\bigg] \leq \sum_{k=0}^i\varphi_k^2 \prod_{l=k+1}^i\big\|I-\varphi_{l}(I-C^\star)\big\|^2\mE\big[\|\tilde{\btheta}^k\|^2\big]\nonumber\\
&\leq \sum_{k=0}^i \prod_{l=k+1}^i\big(1-(1-\rho)^\tau\varphi_l\big)^2 \varphi_k^2 \mE\big[\|\tilde{\btheta}^k\|^2\big],
\end{align}
where the second equality uses the fact that $\{\tilde{\btheta}^k\}_k$ are mean zero and  independent, and the~last~inequality uses the fact $\varphi_t\leq \eta_t\leq 1$ (cf.~Appendix \ref{sec4:subsec1}) and Lemma \ref{aux:lem4}(d). Note that $\varphi_t\leq 1$~is~not~essential; given $\varphi_t\rightarrow 0$, we can apply Lemma \ref{aux:lem5} to derive the same results without this condition.~Next, we bound the moment of $\|\tilde{\btheta}^k\|$. We note for $m=2,4$ and~any~$k\geq 0$,
\begin{align}\label{appen:A4:equ22}
&\mE\big[\|\nabla f(\bx^\star; \xi_k)\|^m\big] \lesssim \mE\big[\|\nabla f(\bx^\star;\xi_k)-\nabla f(\bx_k;\xi_k)\|^m\big] + \mE\big[\|\nabla f(\bx_k;\xi_k)-\nabla F_k\|^m\big] + \mE\big[\|\nabla F_k - \nabla F^\star\|^m\big]\nonumber\\
&\lesssim \Upsilon_H^m\mE\big[\|\bx_k-\bx^\star\|^m\big] + C_{g,1}^{m/4}\mE\big[\|\bx_k-\bx^\star\|^m\big] + C_{g,2}^{m/4} + \Upsilon_H^m\mE\big[\|\bx_k-\bx^\star\|^m\big]\;\;(\text{Assumptions \ref{ass:2}, \ref{ass:3}})\nonumber\\
&\lesssim C_{g,2}^{m/4}\quad\quad (\mE\big[\|\bx_k-\bx^\star\|^m\big]=o(1) \text{ by Lemma \ref{sec4:lem1}}).
\end{align}
Then, by \eqref{ass:3:c2} and Lemma \ref{aux:lem4}(c), we have for $m=2,4$
\begin{equation}\label{appen:A4:equ5}
\hskip-0.1cm \mE\big[\|\tilde{\btheta}^k\|^m\big] \stackrel{\eqref{appen:A4:equ3}}{\leq} \mE\big[\|I- \tilde{C}_k^\star\|^m\|(B^{\star})^{-1}\|^m\|\nabla f(\bx^\star;\xi_k)\|^m\big] \leq\frac{2^m}{\gamma_H^m}\mE\big[\|\nabla f(\bx^\star;\xi_k)\|^m\big] \stackrel{\eqref{appen:A4:equ22}}{\lesssim} \frac{C_{g,2}^{m/4}}{\gamma_H^m}.
\end{equation}
Plugging \eqref{appen:A4:equ5}  into \eqref{appen:A4:equ4}, we get
\begin{multline}\label{appen:A4:equ17}
\frac{1}{t}\sum_{i=0}^{t-1} \frac{1}{\varphi_i} \mE\big[\|\tilde{\I}_{1,i}\|^2\big] \leq \frac{1}{t}\sum_{i=0}^{t-1} \frac{1}{\varphi_i}\sum_{k=0}^i \prod_{l=k+1}^i (1-(1-\rho^{\tau}) \varphi_l)^2\varphi_k^2 \mE\big[\|\tilde{\btheta}^k\|^2\big]\\
\lesssim \frac{C_{g,2}^{1/2}}{\gamma_H^2}\cdot\frac{1}{t}\sum_{i=0}^{t-1}\underbrace{\frac{1}{\varphi_i}\sum_{k=0}^{i}\prod_{l=k+1}^i(1-(1-\rho^{\tau})\varphi_l)^2 \varphi_k^2}_{\longrightarrow 0.5/(1-\rho^\tau)\quad\text{by Lemma \ref{aux:lem1}}}\lesssim \frac{C_{g,2}^{1/2}}{\gamma_H^2(1-\rho^\tau)},
\end{multline}
where the last inequality uses the fact that $\lim_{t\rightarrow\infty}\sum_{i=0}^{t-1} a_i/t = a \text{ if } \lim_{t\rightarrow\infty}a_t=a$.~\mbox{Combining}~\eqref{appen:A4:equ19}, \eqref{appen:A4:equ17}, and Lemma \ref{appen:A4:lem4} (particularly \eqref{appen:A4:equ21} in the proof), we derive
\begin{equation}\label{appen:A4:equ25}
\mE\bigg[\Big\|\frac{1}{t}\sum_{i=0}^{t-1}\frac{1}{\varphi_i}\tilde{\I}_{1,i}\hat{\I}_{1,i}^T\Big\|\bigg] \lesssim \frac{C_{g,2}^{1/4}C_{\hat{\btheta}}^{1/2}}{\gamma_H(1-\rho^\tau)} \rbr{\frac{1}{(1-\beta)^{1/2}}\sqrt{\beta_t} + \frac{\Upsilon_H^{1/2}\mathbf{1}_{\{\chi\leq 1.5\beta\}}}{\gamma_H^{1/2}(1-2(\chi-\beta))^{1/2}}\cdot\frac{\chi_t}{\beta_t}}
\end{equation}
with a constant $C_{\hat{\btheta}}>0$ defined later in \eqref{appen:A4:equ18}. Finally, combining Lemma \ref{appen:A4:lem3} (\eqref{appen:A4:equ24} in the proof), Lemma \ref{appen:A4:lem4} (\eqref{appen:A4:equ21} in the proof), and \eqref{appen:A4:equ23}, we have
\begin{footnotesize}
\begin{multline}\label{appen:A4:equ27}
\mE\bigg[\Big\|\frac{1}{t}\sum_{i=0}^{t-1}\frac{1}{\varphi_i}\I_{1,i}\I_{1,i}^T-\Xi^\star\Big\|\bigg]\\
\lesssim \begin{dcases}
\frac{C_{g,2}^{1/4}C_{\hat{\btheta}}^{1/2}}{\gamma_H(1-\rho^\tau)}\sqrt{\beta_t} + \frac{\Upsilon_H^{1/2}C_{g,2}^{1/4} C_{\hat{\btheta}}^{1/2} \mathbf{1}_{\{\chi\leq 1.5\beta\}}}{\gamma_H^{3/2}(1-\rho^\tau)}\cdot\frac{\chi_t}{\beta_t}= O\rbr{\sqrt{\beta_t}+ \frac{\chi_t}{\beta_t}}, &\beta\in(0,0.5),\\
\max\bigg(\frac{C_{g,2}^{1/4}C_{\hat{\btheta}}^{1/2}}{\gamma_H(1-\rho^\tau)}, \frac{\max(\|\Lambda\|_F, C_{g,2}^{1/2}/\gamma_H^2)}{c_{\beta}(1-\rho^\tau)^{3/2}}\bigg)\sqrt{\beta_t} + \frac{\Upsilon_H^{1/2}C_{g,2}^{1/4} C_{\hat{\btheta}}^{1/2} \mathbf{1}_{\{\chi\leq 1.5\beta\}}}{\gamma_H^{3/2}(1-\rho^\tau)}\cdot\frac{\chi_t}{\beta_t}=O\rbr{\sqrt{\beta_t}+ \frac{\chi_t}{\beta_t}} , &\beta=0.5,\\
\frac{\max(\|\Lambda\|_F, C_{g,2}^{1/2}/\gamma_H^2)}{(1-\rho^\tau)^{3/2}}\cdot \frac{1}{\sqrt{t\beta_t}} + \frac{\Upsilon_H^{1/2}C_{g,2}^{1/4} C_{\hat{\btheta}}^{1/2} \mathbf{1}_{\{\chi\leq 1.5\beta\}}}{\gamma_H^{3/2}(1-\rho^\tau)(1-2(\chi-\beta))^{1/2}}\cdot\frac{\chi_t}{\beta_t} =O\rbr{\frac{1}{\sqrt{t\beta_t}}+ \frac{\chi_t}{\beta_t}}, &\beta\in(0.5,1),
\end{dcases}
\end{multline}
\end{footnotesize}
\hskip -3.5pt where $\Lambda = \mE[(I- \tilde{C}^\star)\Omega^\star(I-\tilde{C}^\star)^T]$. This completes the proof.


\subsubsection{Proof of Lemma \ref{appen:A4:lem3}}\label{pf:tildeI1}

By the eigenvalue decomposition $I-C^\star = U\Sigma U^T$ with $\Sigma=\text{diag}(\sigma_1,\dots,\sigma_d)$ in \eqref{eigendecomp}, we have
\begin{equation}\label{appen:A4:equ6}
\tilde{\I}_{1,i} = \sum_{k=0}^i\prod_{l=k+1}^i\{I-\varphi_l(I-C^\star)\}\varphi_k \tilde{\btheta}^k =U\sum_{k=0}^i\prod_{l=k+1}^i\{I-\varphi_l\Sigma\}\varphi_k U^T\tilde{\btheta}^k.
\end{equation}   
Let $\tilde{\Q}_i = U^T\tilde{\I}_{1,i}$ and $\Gamma = U^T\Lambda U$ with $\Lambda = \mE[(I- \tilde{C}^\star)\Omega^\star(I- \tilde{C}^\star)^T]$. Recalling the expression of~$\Xi^\star$~in \eqref{exp:Xistar}, we get
\begin{multline*}
\mE\bigg[\Big\|\frac{1}{t}\sum_{i=0}^{t-1}\frac{1}{\varphi_i}\tilde{\I}_{1,i}\tilde{\I}_{1,i}^T-\Xi^\star\Big\|\bigg] = 
\mE\bigg[\Big\|\frac{1}{t}\sum_{i=0}^{t-1}\frac{1}{\varphi_i}\tilde{\Q}_i\tilde{\Q}_i^T-\Theta\circ\Gamma\Big\|\bigg] \leq \mE\bigg[\Big\|\frac{1}{t}\sum_{i=0}^{t-1}\frac{1}{\varphi_i}\tilde{\Q}_i\tilde{\Q}_i^T-\Theta\circ\Gamma\Big\|_F\bigg]\\
\leq \sqrt{\mE\bigg[\Big\|\frac{1}{t}\sum_{i=0}^{t-1}\frac{1}{\varphi_i}\tilde{\Q}_i\tilde{\Q}_i^T-\Theta\circ\Gamma\Big\|_F^2\bigg]} \quad\text{(by H\"older's inequality)}.
\end{multline*}
We perform bias-variance decomposition on this term:
\begin{equation}\label{appen:A4:equ12}
\mE\bigg[\Big\|\frac{1}{t}\sum_{i=0}^{t-1}\frac{1}{\varphi_i}\tilde{\Q}_i\tilde{\Q}_i^T-\Theta\circ\Gamma\Big\|_F^2\bigg] = \sum_{p,q=1}^d \mE\bigg[\Big(\frac{1}{t} \sum_{i=0}^{t-1} \frac{1}{\varphi_i} \tilde{\Q}_{i, p} \tilde{\Q}_{i, q}-\Theta_{p,q}\Gamma_{p,q}\Big)^2\bigg] =: \uppercase\expandafter{\romannumeral1} + \uppercase\expandafter{\romannumeral2},
\end{equation}
with
\begin{align*}
\uppercase\expandafter{\romannumeral1} &= \sum_{p,q=1}^d\bigg\{\mE\bigg[\Big(\frac{1}{t} \sum_{i=0}^{t-1} \frac{1}{\varphi_i} \tilde{\Q}_{i, p} \tilde{\Q}_{i, q}\Big)^2\bigg]-\bigg(\mE\Big[\frac{1}{t} \sum_{i=0}^{t-1} \frac{1}{\varphi_i} \tilde{\Q}_{i, p} \tilde{\Q}_{i, q}\Big]\bigg)^2\bigg\} \quad (\text{variance}),\nonumber  \\
\uppercase\expandafter{\romannumeral2} &= \sum_{p,q=1}^d\bigg(\mE\Big[\frac{1}{t} \sum_{i=0}^{t-1} \frac{1}{\varphi_i} \tilde{\Q}_{i, p}\tilde{\Q}_{i, q}\Big]-\Theta_{p,q} \Gamma_{p,q}\bigg)^2\quad (\text{bias}^2),
\end{align*}
and $\tilde{\Q}_{i, p}$ and $\tilde{\Q}_{i, q}$ represent the $p$-th and $q$-th elements in $\tilde{\Q}_i$. We first look at $\uppercase\expandafter{\romannumeral2}$. By \eqref{appen:A4:equ6}, we get
\begin{multline*}
\mE\Big[\frac{1}{t} \sum_{i=0}^{t-1} \frac{1}{\varphi_i} \tilde{\Q}_{i, p}\tilde{\Q}_{i, q}\Big]= \frac{1}{t} \sum_{i=0}^{t-1} \frac{1}{\varphi_i} \sum_{k_1=0}^i \sum_{k_2=0}^i\prod_{l_1=k_1+1}^i(1-\sigma_p\varphi_{l_1}) \cdot\\
\prod_{l_2=k_2+1}^i(1-\sigma_q\varphi_{l_2}) \varphi_{k_1}\varphi_{k_2} \mE\Big[\big(U^T \tilde{\btheta}^{k_1}\tilde{\btheta}^{k_2^T} U\big)_{p,q}\Big].
\end{multline*}
Given the definition of $\tilde{\btheta}^k$ in \eqref{appen:A4:equ3} and the independence among $\{\tilde{\btheta}^k\}_k$, it is observed that
\begin{equation*}
\mE[U^T\tilde{\btheta}^{k_1} \tilde{\btheta}^{k_2^T}U] = 0\text{ for }k_1\neq k_2 \quad\quad \text{ and } \quad\quad \mE[U^T\tilde{\btheta}^{k}\tilde{\btheta}^{kT}U] = \Gamma.
\end{equation*}
Thus, combining the above two displays leads to 
\begin{equation*}
\mE\Big[\frac{1}{t} \sum_{i=0}^{t-1} \frac{1}{\varphi_i} \tilde{\Q}_{i, p}\tilde{\Q}_{i, q}\Big]= \frac{1}{t} \sum_{i=0}^{t-1}\frac{1}{\varphi_i}\sum_{k=0}^i\prod_{l=k+1}^i (1-\sigma_p\varphi_l)(1-\sigma_q\varphi_l)\varphi_k^2\Gamma_{p,q}.
\end{equation*}
We plug the above display into the term $\uppercase\expandafter{\romannumeral2}$ and apply Lemma \ref{aux:lem2} to bound it. For \mbox{$\beta\in(0.5,1)$},~we~have
\begin{align}\label{appen:A4:equ8}
|\uppercase\expandafter{\romannumeral2}| &\leq  \sum_{p,q=1}^d\bigg(\frac{1}{t} \sum_{i=0}^{t-1} \Big|\frac{1}{\varphi_i} \sum_{k=0}^i \prod_{l=k+1 }^i\left(1-\sigma_p\varphi_l\right)\left(1-\sigma_q\varphi_l\right) \varphi_k^2-\Theta_{p, q}\Big|\bigg)^2\Gamma_{p,q}^2\nonumber\\
&\lesssim \sum_{p,q=1}^d\Big(\frac{\beta}{(\sigma_p+\sigma_q)^2}\cdot \frac{1}{t}\sum_{i=0}^{t-1}\frac{1}{i\varphi_i}\Big)^2\Gamma_{p,q}^2 \stackrel{\eqref{appen:A3:equ11}}{\lesssim} \sum_{p,q=1}^d\Big(\frac{\beta}{(\sigma_p+\sigma_q)^2}\cdot \frac{1}{1-(1-\beta)}\cdot \frac{1}{t\varphi_t}\Big)^2\Gamma_{p,q}^2\nonumber\\
&\lesssim \frac{\|\Gamma\|_F^2}{(1-\rho^\tau)^4} \cdot\frac{1}{t^2\varphi_t^2}\lesssim \frac{\|\Lambda\|_F^2}{(1-\rho^\tau)^4} \cdot\frac{1}{t^2\beta_t^2}\quad (\text{by Lemma \ref{aux:lem4}(d) and }\chi_t=o(\beta_t)).
\end{align}
Applying Lemma \ref{aux:lem2} for $\beta\in(0,0.5)$ and $\beta=0.5$, we similarly obtain
\begin{equation}\label{appen:A4:equ8a}
|\uppercase\expandafter{\romannumeral2}|\lesssim \|\Lambda\|_F^2\beta_t^2 \text{ for } \beta\in(0,0.5)\quad\quad \text{and}\quad\quad|\uppercase\expandafter{\romannumeral2}|\lesssim \Big(1+\frac{\beta/c_{\beta}^2}{2(1-\rho^\tau)^2}\Big)^2 \|\Lambda\|_F^2\beta_t^2 \text{ for }\beta = 0.5.
\end{equation}
Now we deal with the term $\uppercase\expandafter{\romannumeral1}$. By \eqref{appen:A4:equ6}, we expand $\uppercase\expandafter{\romannumeral1}$ as
\begin{multline*}
\uppercase\expandafter{\romannumeral1}= \sum_{p,q=1}^d\frac{1}{t^2} \sum_{i_1, i_2=0}^{t-1} \frac{1}{\varphi_{i_1}} \frac{1}{\varphi_{i_2}} \sum_{k_1,k_1^{\prime}=0}^{i_1} \sum_{k_2,k_2^{\prime}=0}^{i_2} \prod_{l_1=k_1+1}^{i_1}(1- \sigma_p\varphi_{l_1}) \prod_{l_1^{\prime}=k_1^{\prime}+1}^{i_1} (1-\sigma_q\varphi_{l_1^{\prime}}) \prod_{l_2=k_2+1}^{i_2}(1-\sigma_p\varphi_{l_2} ) \prod_{l_2^{\prime}=k_2^{\prime}+1}^{i_2}(1- \sigma_q\varphi_{l_2^{\prime}})\\
\varphi_{k_1}\varphi_{k_1^{\prime}}
\varphi_{k_2}\varphi_{k_2^{\prime}} \bigg\{\mE\Big[\big(U^T \tilde{\btheta}^{k_1}\tilde{\btheta}^{k_1^{\prime T}}U\big)_{p,q}\big(U^T \tilde{\btheta}^{k_2}\tilde{\btheta}^{k_2^{\prime T}}U\big)_{p,q}\Big]-\mE\Big[\big(U^T \tilde{\btheta}^{k_1}\tilde{\btheta}^{k_1^{\prime T}}U\big)_{p,q}\Big]\mE\Big[\big(U^T \tilde{\btheta}^{k_2}\tilde{\btheta}^{k_2^{\prime T}}U\big)_{p,q}\Big]\bigg\}.
\end{multline*}
It is noteworthy that the term in the curly braces is nonzero only when the indices $k_1,k_1^\prime,k_2,k_2^\prime$~are~pairwise identical. Thus, we decompose $\uppercase\expandafter{\romannumeral1}$ into four terms $\uppercase\expandafter{\romannumeral1}_1, \uppercase\expandafter{\romannumeral1}_2, \uppercase\expandafter{\romannumeral1}_3, \uppercase\expandafter{\romannumeral1}_4$ by classifying the indices.

\vskip0.3cm
\noindent$\bullet$ \textbf{Term 1:} $k_1=k_1^{\prime}=k_2=k_2^{\prime}$.

\noindent Summing over all the indices under this case, we get
\begin{align*}
|\uppercase\expandafter{\romannumeral1}_1| = \sum_{p,q}\frac{1}{t^2} \sum_{i_1=0}^{t-1} \sum_{i_2=0}^{t-1} &\frac{1}{\varphi_{i_1}} \frac{1}{\varphi_{i_2}} \sum_{k=0}^{i_1 \wedge i_2} \prod_{l_1=k+1}^{i_1}(1-\sigma_p\varphi_{l_1})(1- \sigma_q\varphi_{l_1})\cdot\\
&\prod_{l_2=k+1}^{i_2}(1- \sigma_p\varphi_{l_2})(1-\sigma_q\varphi_{l_2}) \varphi_k^4 \bigg\{\mE\Big[\big(U^T \tilde{\btheta}^{k}\tilde{\btheta}^{k^ T}U\big)_{p,q}^2\Big]-\bigg(\mE\Big[\big(U^T \tilde{\btheta}^{k}\tilde{\btheta}^{k^ T}U\big)_{p,q}\Big]\bigg)^2\bigg\}\\
\leq \frac{1}{t^2} \sum_{i_1=0}^{t-1} \sum_{i_2=0}^{t-1} \frac{1}{\varphi_{i_1}} &\frac{1}{\varphi_{i_2}} \sum_{k=0}^{i_1 \wedge i_2} \prod_{l_1=k+1}^{i_1}(1-(1-\rho^{\tau})\varphi_{l_1})^2\prod_{l_2=k+1}^{i_2}(1-(1-\rho^{\tau})\varphi_{l_2})^2 \varphi_k^4\mE\Big[\sum_{p,q}\big(U^T \tilde{\btheta}^{k}\tilde{\btheta}^{k^T}U\big)_{p,q}^2\Big].
\end{align*}
Here, the equality holds because $1-\sigma_k\varphi_t>0$ for any $1\leq k\leq d$ and $t\geq 0$ following the~same~discussion as in \eqref{appen:A4:equ4}. By \eqref{appen:A4:equ5}, we know
\begin{equation*}
\mE\Big[\sum_{p,q}\big(U^T \tilde{\btheta}^{k}\tilde{\btheta}^{k^T}U\big)_{p,q}^2\Big] = \mE\big[\|\tilde{\btheta}^k\|^4\big] \lesssim\frac{C_{g,2}}{\gamma_H^4}.
\end{equation*}
Due to the symmetry between the indices $i_1$ and $i_2$, $|\uppercase\expandafter{\romannumeral1}_1|$ can be further bounded by
\begin{multline*}       
|\uppercase\expandafter{\romannumeral1}_1| \leq \frac{2}{t^2} \sum_{i_1=0}^{t-1} \frac{1}{\varphi_{i_1}} \sum_{i_2=0}^{i_1} \frac{1}{\varphi_{i_2}} \prod_{l_2=i_2+1}^{i_1}(1-(1-\rho^{\tau})\varphi_{l_2})^2\underbrace{\sum_{k=0}^{i_2} \prod_{l_1=k+1}^{i_2} (1-(1-\rho^{\tau})\varphi_{l_1})^4 \varphi_k^4}_{\lesssim \varphi_{i_2}^3/(1-\rho^\tau) \quad\text{by Lemma \ref{aux:lem1}}}\mE\big[\|\tilde{\btheta}^k\|^4\big]\\
\lesssim \frac{C_{g,2}}{\gamma_H^4(1-\rho^\tau)}\cdot\frac{1}{t^2} \sum_{i_1=0}^{t-1} \underbrace{\frac{1}{\varphi_{i_1}} \sum_{i_2=0}^{i_1} \prod_{l_2=i_2+1}^{i_1}(1-(1-\rho^{\tau}))\varphi_{l_2})^2 \varphi_{i_2}^2}_{\longrightarrow 0.5/(1-\rho^{\tau})\quad\text{by Lemma \ref{aux:lem1}}}\lesssim \frac{C_{g,2}}{\gamma_H^4(1-\rho^\tau)^2}\cdot\frac{1}{t}.
\end{multline*}
\noindent$\bullet$ \textbf{Term 2:} $k_1=k_1^{\prime}, k_2=k_2^{\prime}, k_1 \neq k_2$.

\noindent We note that
\begin{equation*}
\mE\Big[\big(U^T \tilde{\btheta}^{k_1}\tilde{\btheta}^{k_1^{T}}U\big)_{p,q}\big(U^T \tilde{\btheta}^{k_2}\tilde{\btheta}^{k_2^{T}}U\big)_{p,q}\Big]=\mE\Big[\big(U^T \tilde{\btheta}^{k_1}\tilde{\btheta}^{k_1^{T}}U\big)_{p,q}\Big]\mE\Big[\big(U^T \tilde{\btheta}^{k_2}\tilde{\btheta}^{k_2^{T}}U\big)_{p,q}\Big]\;\;\text{for }k_1\neq k_2.
\end{equation*}
This indicates that $\uppercase\expandafter{\romannumeral1}_2 = 0$.
\vskip0.3cm
\noindent$\bullet$ \textbf{Term 3:} $k_1=k_2,  k_1^{\prime}=k_2^{\prime},  k_1 \neq k_1^{\prime}$.

\noindent In this case, it is observed that
\begin{equation*}
\mE\Big[\big(U^T \tilde{\btheta}^{k_1}\tilde{\btheta}^{k_1^{\prime T}}U\big)_{p,q}\Big]\mE\Big[\big(U^T \tilde{\btheta}^{k_1}\tilde{\btheta}^{k_1^{\prime T}}U\big)_{p,q}\Big] = 0.
\end{equation*}
Thus, we have
\begin{multline*}
|\uppercase\expandafter{\romannumeral1}_3|\leq \frac{1}{t^2} \sum_{i_1=0}^{t-1} \sum_{i_2=0}^{t-1} \frac{1}{\varphi_{i_1}}\frac{1}{\varphi_{i_2}} \sum_{k_1=0}^{i_1 \wedge i_2} \prod_{l_1=k_1+1}^{i_1}(1- (1-\rho^\tau)\varphi_{l_1}) \prod_{l_2=k_1+1}^{i_2}(1- (1-\rho^\tau)\varphi_{l_2}) \varphi_{k_1}^2\cdot\\
\sum_{k_1^{\prime}=0, k_1\neq k_1^{\prime}}^{i_1 \wedge i_2} \prod_{l_1^{\prime}=k_1^{\prime}+1}^{i_1}(1- (1-\rho^\tau)\varphi_{l_1^{\prime}}) \prod_{l_2^{\prime}=k_1^{\prime}+1}^{i_2}(1- (1-\rho^\tau)\varphi_{l_2^{\prime}}) \varphi_{k_1^{\prime}}^2\mE\Big[\sum_{p, q}\big(U^T \tilde{\btheta}^{k_1}\big)_p^2\big(U^T \tilde{\btheta}^{k_1^{\prime}}\big)_q^2\Big].
\end{multline*}
Since $k_1\neq k_1^{\prime}$, we have
\begin{equation*}
\mE\Big[\sum_{p, q}\big(U^T \tilde{\btheta}^{k_1}\big)_p^2\big(U^T \tilde{\btheta}^{k_1^{\prime}}\big)_q^2\Big]= \mE\big[\|\tilde{\btheta}^{k_1}\|^2\big] \mE\big[\|\tilde{\btheta}^{k_1^\prime}\|^2\big] \stackrel{\eqref{appen:A4:equ5}}{\lesssim}\frac{C_{g,2}}{\gamma_H^4}.
\end{equation*}
By the symmetry of the indices $i_1$ and $i_2$, we can further bound $|\uppercase\expandafter{\romannumeral1}_3|$ by
\begin{align}\label{appen:A4:equ26}
|\uppercase\expandafter{\romannumeral1}_3|
&\lesssim \frac{1}{t^2} \sum_{i_1=0}^{t-1} \frac{1}{\varphi_{i_1}} \sum_{i_2=0}^{i_1} \frac{1}{\varphi_{i_2}} \prod_{l=i_2+1}^{i_1}(1- (1-\rho^\tau)\varphi_l)^2\Big\{\underbrace{\sum_{k_1=0}^{i_2} \prod_{l_1=k_1+1}^{i_2}(1- (1-\rho^\tau)\varphi_{l_1})^2 \varphi_{k_1}^2}_{\lesssim \varphi_{i_2}/(1-\rho^\tau)\quad\text{by Lemma \ref{aux:lem1}}}\Big\}^2\cdot\frac{C_{g,2}}{\gamma_H^4}\nonumber\\
&\lesssim \frac{C_{g,2}}{\gamma_H^4(1-\rho^\tau)^2}\cdot\frac{1}{t^2} \sum_{i_1=0}^{t-1}\frac{1}{\varphi_{i_1}}  \underbrace{\sum_{i_2=0}^{i_1} \prod_{l=i_2+1}^{i_1}(1-(1-\rho^\tau)\varphi_l)^2\varphi_{i_2}}_{\longrightarrow 0.5/(1-\rho^{\tau})\quad\text{by Lemma \ref{aux:lem1}}}\nonumber\\
&\lesssim \frac{C_{g,2}}{\gamma_H^4(1-\rho^\tau)^3}\cdot\frac{1}{t^2} \sum_{i_1=0}^{t-1}\frac{1}{\varphi_{i_1}}\lesssim \frac{C_{g,2}}{c_{\beta}\gamma_H^4(1-\rho^\tau)^3}\cdot\frac{1}{t^2} \sum_{i_1=0}^{t-1}(i_1+1)^\beta\lesssim \frac{C_{g,2}}{\gamma_H^4(1-\rho^\tau)^3}\cdot\frac{1}{t\beta_t}.
\end{align}
\noindent$\bullet$ \textbf{Term 4:} $k_1=k_2^{\prime}, k_2=k_1^{\prime},  k_1 \neq k_2$.

\noindent In this case, we have
\begin{equation*}
\mE\Big[\big(U^T \tilde{\btheta}^{k_1}\tilde{\btheta}^{k_1^{\prime T}}U\big)_{p,q}\Big]\mE\Big[\big(U^T \tilde{\btheta}^{k_1^{\prime}}\tilde{\btheta}^{k_1^T}U\big)_{p,q}\Big] = 0.
\end{equation*}
The analysis of $\uppercase\expandafter{\romannumeral1}_4$ is almost identical to $\uppercase\expandafter{\romannumeral1}_3$, only with the expectation term being replaced by
\begin{equation*}
\sum_{p,q}\mE\Big[\big(U^T \tilde{\btheta}^{k_1} \tilde{\btheta}^{k_1^T} U\big)_{p,q}\big(U^T \tilde{\btheta}^{k_2} \tilde{\btheta}^{k_2^T }U\big)_{p,q}\Big] = \sum_{p,q} \Gamma_{p,q}^2 = \|\Gamma\|_F^2=\|\Lambda\|_F^2 \;\;\text{when } k_1\neq k_2.
\end{equation*}
Therefore, we conclude that 
\begin{equation*}\label{appen:A4:equ11}            
|\uppercase\expandafter{\romannumeral1}_4| \lesssim \frac{\|\Lambda\|_F^2}{(1-\rho^\tau)^3}\cdot\frac{1}{t\beta_t}.
\end{equation*}
Combining the analyses of four terms, we obtain
\begin{equation}\label{appen:A4:equ8b}
|\uppercase\expandafter{\romannumeral1}| \leq \sum_{i=1}^4 |\uppercase\expandafter{\romannumeral1}_i|\lesssim \frac{\max(\|\Lambda\|_F^2, C_{g,2}/\gamma_H^4)}{(1-\rho^\tau)^3}\cdot\frac{1}{t\beta_t}.
\end{equation}
Plugging \eqref{appen:A4:equ8}, \eqref{appen:A4:equ8a}, and \eqref{appen:A4:equ8b} into to \eqref{appen:A4:equ12}, we have
\begin{equation}\label{appen:A4:equ24}
\small\mE\bigg[\Big\|\frac{1}{t}\sum_{i=0}^{t-1}\frac{1}{\varphi_i}\tilde{\I}_{1,i}\tilde{\I}_{1,i}^T-\Xi^\star\Big\|\bigg] \lesssim \begin{dcases}
\|\Lambda\|_F\beta_t= O(\beta_t), &\beta\in(0,1/3),\\
\max\bigg(\|\Lambda\|_F, \frac{\max(\|\Lambda\|_F, C_{g,2}^{1/2}/\gamma_H^2)}{c_{\beta}^{3/2}(1-\rho^\tau)^{3/2}}\bigg) \beta_t = O(\beta_t), &\beta = 1/3,\\
\frac{\max(\|\Lambda\|_F, C_{g,2}^{1/2}/\gamma_H^2)}{(1-\rho^\tau)^{3/2}}\cdot \frac{1}{\sqrt{t\beta_t}}=O(1/\sqrt{t\beta_t}), &\beta\in(1/3,1).   
\end{dcases}
\end{equation}
We complete the proof.


\subsubsection{Proof of Lemma \ref{appen:A4:lem4}}\label{pf:hatI1}

We present the following lemma to bound $\hat{\btheta}^k$ defined in \eqref{appen:A4:equ3}, with proof deferred to Appendix~\ref{pf:hattheta}. 

\begin{lemma}\label{appen:A4:lem5}
Under the assumptions of Lemma \ref{appen:A4:lem2}, we have
\begin{equation*}       
\mE\big[\|\hat{\btheta}^k\|^2\big] \lesssim \frac{\Upsilon_H^2}{\gamma_H^2} \mE\big[\|\bx_k-\bx^\star\|^2\big] + \frac{\tau^2\Upsilon_{S}C_{g,2}^{1/2}}{\gamma_H^4}\mE\big[\|B_k-B^\star\|^2\big].
\end{equation*}
\end{lemma}


This lemma indicates that the difference between the martingale difference $\btheta^k$ and its approximation $\tilde{\btheta}^k$ vanishes. Combining Lemma \ref{appen:A4:lem5} with \eqref{xtrate} and \eqref{appen:A3:equ15} in the proof of Lemma~\ref{sec4:lem1},~we~get 
\begin{equation}\label{appen:A4:equ18}
\mE\big[\|\hat{\btheta}^k\|^2\big]\lesssim C_{\hat{\btheta}}\rbr{ \beta_k + \frac{\Upsilon_H}{\gamma_H}\cdot \frac{\chi_k^2}{\beta_k^2}} \;\;\;\;\text{with}\;\;\;\; C_{\hat{\btheta}} = \frac{\Upsilon_H^2 C_{g,2}^{1/2}}{\gamma_H^6}\max\Big(\Upsilon_H^2, \frac{\tau^2\Upsilon_S\Upsilon_L^2C_{g,2}^{1/2}}{\gamma_H^2}\Big).
\end{equation}
Recall the expression of $\hat{\I}_{1,i}$ in \eqref{appen:A4:equ2}. Since $\{\hat{\btheta}^k\}_k$ is a martingale difference sequence, we follow~the analysis in \eqref{appen:A4:equ4} and \eqref{appen:A4:equ17}, and obtain
\begin{align}\label{appen:A4:equ21}
&\frac{1}{t}\sum_{i=0}^{t-1} \frac{1}{\varphi_i} \mE\big[\|\hat{\I}_{1,i}\|^2\big] \leq \frac{1}{t}\sum_{i=0}^{t-1} \frac{1}{\varphi_i}\sum_{k=0}^i \prod_{l=k+1}^i (1-(1-\rho^{\tau}) \varphi_l)^2\varphi_k^2 \mE\big[\|\hat{\btheta}^k\|^2\big]\nonumber\\
&\lesssim C_{\hat{\btheta}}\cdot \frac{1}{t}\sum_{i=0}^{t-1}\underbrace{\frac{1}{\varphi_i}\sum_{k=0}^i\prod_{l=k+1}^i(1-(1-\rho^{\tau})\varphi_l)^2 \varphi_k^2\beta_k}_{\lesssim \beta_i/(1-\rho^\tau)\quad\text{by Lemma \ref{aux:lem1}}} + \frac{\Upsilon_H C_{\hat{\btheta}}}{\gamma_H}\cdot \frac{1}{t}\sum_{i=0}^{t-1}\underbrace{\frac{1}{\varphi_i}\sum_{k=0}^i\prod_{l=k+1}^i(1-(1-\rho^{\tau})\varphi_l)^2 \frac{\varphi_k^2\chi_k^2}{\beta_k^2}}_{\lesssim (\chi_i^2/\beta_i^2)/(1-\rho^\tau)\quad\text{by Lemma \ref{aux:lem1}}}\nonumber\\
&\stackrel{\mathclap{\eqref{appen:A3:equ11}}}{\lesssim}\;\; \frac{C_{\hat{\btheta}}}{(1-\rho^\tau)(1-\beta)}\beta_t + \frac{\Upsilon_H C_{\hat{\btheta}}\mathbf{1}_{\{\chi\leq 1.5\beta\}}}{\gamma_H(1-\rho^\tau)(1-2(\chi-\beta))}\cdot\frac{\chi_t^2}{\beta_t^2} = O\rbr{\beta_t + \frac{\chi_t^2}{\beta_t^2}}.
\end{align}    
We complete the proof.




\subsubsection{Proof of Lemma \ref{appen:A4:lem5}}\label{pf:hattheta}

We expand $\hat{\btheta}^k$ based on its definition in \eqref{appen:A4:equ3} as
\begin{equation*}
\hat{\btheta}^k = \btheta^k - \tilde{\btheta}^k = (I-C_k) B_k^{-1} \nabla F_k -(I-\tilde{C}_k) B_k^{-1} \nabla f(\bx_k; \xi_k) + (I-\tilde{C}_k^\star) (B^{\star})^{-1} \nabla f(\bx^\star; \xi_k).
\end{equation*}
Then, we can bound $\|\hat{\btheta}^k\|^2$ as
\begin{multline*}
\|\hat{\btheta}^k\|^2\lesssim \|I-C_k\|^2 \|B_k^{-1}\|^2 \|\nabla F_k\|^2+\|I-\tilde{C}_k\|^2 \|B_k^{-1}\|^2\|\nabla f(\bx_k; \xi_k)-\nabla f(\bx^\star; \xi_k)\|^2\\
+\|(I-\tilde{C}_k) B_k^{-1}-(1-\tilde{C}_k^\star) (B^{\star})^{-1}\|^2\|\nabla f(\bx^\star; \xi_k)\|^2    =:\uppercase\expandafter{\romannumeral1} + \uppercase\expandafter{\romannumeral2} +  \uppercase\expandafter{\romannumeral3}.
\end{multline*}
For the first two terms, by Assumption \ref{ass:3} and Lemma \ref{aux:lem4}(c), we get
\begin{equation}\label{appen:A4:equ14}
\mE[\uppercase\expandafter{\romannumeral1}] \lesssim \frac{\Upsilon_H^2}{\gamma_H^2}\mE\big[\|\bx_k-\bx^\star\|^2\big]\quad\quad\text{and}\quad\quad\mE[\uppercase\expandafter{\romannumeral2}]  \lesssim \frac{\Upsilon_H^2}{\gamma_H^2}\mE\big[\|\bx_k-\bx^\star\|^2\big].
\end{equation}
Regarding the term $\uppercase\expandafter{\romannumeral3}$, we have
\begin{multline*}
\|(I-\tilde{C}_k) B_k^{-1}-(1-\tilde{C}_k^\star) (B^{\star})^{-1}\|^2\leq\|I-\tilde{C}_k\|^2 \|B_k^{-1}\|^2\|(B^{\star})^{-1}\|^2\|B_k-B^\star\|^2\\
+\|(B^{\star})^{-1}\|^2 \|\tilde{C}_k-\tilde{C}_k^\star\|^2 \lesssim \frac{1}{\gamma_H^4}\|B_k-B^\star\|^2+ \frac{1}{\gamma_H^2}\|\tilde{C}_k-\tilde{C}_k^\star\|^2.
\end{multline*}
Then, we apply the tower property of conditional expectation to bound $\mE[\uppercase\expandafter{\romannumeral3}]$ by first conditioning on $\mF_{k-1}$, and have
\begin{align}\label{appen:A4:equ13}
& \mE[\uppercase\expandafter{\romannumeral3}]
\lesssim \mE\bigg[ \mE\Big[\Big(\frac{1}{\gamma_H^4}\|B_k-B^\star\|^2+ \frac{1}{\gamma_H^2}\|\tilde{C}_k-\tilde{C}_k^\star\|^2\Big)\|\nabla f(\bx^\star;\xi_k)\|^2\mid\mF_{k-1}\Big] \bigg]\nonumber\\
&=\frac{1}{\gamma_H^4}\mE\Big[\|B_k-B^\star\|^2\mE\big[\|\nabla f(\bx^\star;\xi_k)\|^2\mid\mF_{k-1}\big]\Big] + \frac{1}{\gamma_H^2}\mE\Big[\mE\big[\|\tilde{C}_k-\tilde{C}_k^\star\|^2\mid \mF_{k-1}\big] \mE\big[\|\nabla f(\bx^\star;\xi_k)\|^2\mid\mF_{k-1}\big]\Big]\nonumber\\
&\stackrel{\mathclap{\eqref{appen:A4:equ22}}}{\lesssim}\;\;\frac{C_{g,2}^{1/2}}{\gamma_H^4}\mE\big[\|B_k-B^\star\|^2\big]+\frac{C_{g,2}^{1/2}}{\gamma_H^2}\mE\big[\|\tilde{C}_k-\tilde{C}_k^\star\|^2\big].
\end{align}
Here, the second equality is due to $\sigma(\|B_k-B^\star\|)\in\mF_{k-1}$ and the independence between $\xi_k$ and the sketching matrices $\{S_{k,j}\}_{j=0}^\tau$. Plugging in the definition of $\tilde{C}_k$ \eqref{appen:A1:equ6} and $\tilde{C}_k^\star$ \eqref{Ctildestar}, we have
\begin{align*}
\|\tilde{C}_k-\tilde{C}_k^\star\| &=\Big\|\prod_{j=0}^{\tau-1} \tilde{C}_{k, j}-\prod_{j=0}^{\tau-1} \tilde{C}_{k, j}^\star\Big\|
\leq \Big\|\prod_{j=0}^{\tau-2} \tilde{C}_{k, j}-\prod_{j=0}^{\tau-2} \tilde{C}_{k, j}^\star\Big\|\cdot \|C_{k, \tau-1}^\star\|
+\Big\|\prod_{j=0}^{\tau-2} \tilde{C}_{k, j}\Big\|\cdot \|\tilde{C}_{k, \tau-1}-\tilde{C}_{k, \tau-1}^\star\|\\
&\leq\dots\leq \sum_{j=0}^{\tau-1}\left\|\tilde{C}_{k, j}-\tilde{C}_{k, j}^\star\right\|\quad(\text{by }\|C_{k, \tau-1}^\star\|\leq 1\text{ and }\|\tilde{C}_{k,j}\|\leq 1).
\end{align*}
Applying \cite[Lemma 5.2]{Na2022Statistical} and Assumption \ref{ass:4}, we obtain
\begin{equation*}
\mE\big[\|\tilde{C}_k-\tilde{C}_k^\star\|^2\mid\mF_{k-1}\big]\leq
\frac{4\|B_k-B^\star\|^2}{\gamma_H^2}\mE[(\sum_{j=0}^{\tau-1}\|S_{k, j}\|\|S_{k,j}^\dagger\|)^2]\lesssim \frac{\tau^2\Upsilon_{S}}{\gamma_H^2}\|B_k-B^\star\|^2.
\end{equation*}
Combining the above display to \eqref{appen:A4:equ13}, we get
\begin{equation}\label{appen:A4:equ16}
\mE[\uppercase\expandafter{\romannumeral3}]\lesssim \frac{\tau^2\Upsilon_{S}C_{g,2}^{1/2}}{\gamma_H^4}\mE\big[\|B_k-B^\star\|^2\big].
\end{equation}
Combining \eqref{appen:A4:equ14} and \eqref{appen:A4:equ16} completes the proof.


\subsection{Proof of Theorem \ref{sec4:thm1}}\label{appen:A5}

The weighted sample covariance matrix $\hat{\Xi}_t$ can be decomposed as
\begin{multline}\label{appen:A5:equ1}
\widehat{\Xi}_t = \frac{1}{t}\sum_{i=1}^t\frac{1}{\varphi_{i-1}}(\bx_i-\bx^\star)(\bx_i-\bx^\star)^T + \frac{1}{t}\sum_{i=1}^t\frac{1}{\varphi_{i-1}}(\bar{\bx}_t-\bx^\star)(\bar{\bx}_t-\bx^\star)^T \\
- \frac{1}{t}\sum_{i=1}^t\frac{1}{\varphi_{i-1}}(\bx_i-\bx^\star)(\bar{\bx}_t-\bx^\star)^T - \frac{1}{t}\sum_{i=1}^t\frac{1}{\varphi_{i-1}}(\bar{\bx}_t-\bx^\star)(\bx_i-\bx^\star)^T.
\end{multline}
The next two lemmas show that $\frac{1}{t}\sum_{i=1}^t\frac{1}{\varphi_{i-1}}(\bx_i-\bx^\star)(\bx_i-\bx^\star)^T$ converges to $\Xi^{\star}$, and the remaining terms are negligible as $\bar{\bx}_t$ converges to $\bx^\star$ fast. The proofs are in Appendices \ref{pf:samplecov} and \ref{pf:barx}.


\begin{lemma}\label{appen:A5:lem1}

Suppose Assumptions \ref{ass:1} -- \ref{ass:4} hold, the \mbox{number}~of~sketches satisfies $\tau\geq \log(\gamma_H/4\Upsilon_H)/\log \rho$ with $\rho = 1-\gamma_S$, and the stepsize parameters satisfy $\beta\in(0,1)$, $\chi>1.5\beta$, and $c_{\beta}, c_{\chi}>0$. Then, we have
\begin{equation}\label{appen:A5:equ10}
\mE\bigg[\Big\|\frac{1}{t}\sum_{i=1}^t\frac{1}{\varphi_{i-1}}(\bx_i-\bx^\star)(\bx_i-\bx^\star)^T-\Xi^\star\Big\|\bigg] \lesssim \begin{dcases}
\sqrt{\beta_t} + \chi_t/\beta_t^{1.5}, &\beta\in(0,0.5],\\
1/\sqrt{t\beta_t} + \chi_t/\beta_t^{1.5}, &\beta\in(0.5,1),
\end{dcases}
\end{equation}
and
\begin{equation}\label{appen:A5:equ19}
\frac{1}{t}\sum_{i=0}^{t-1}\frac{1}{\varphi_{i-1}}\mE\big[\|\bx_i-\bx^\star\|^2\big] = O(1).
\end{equation}
\end{lemma}

\begin{lemma}\label{appen:A5:lem2}

Suppose Assumptions \ref{ass:1} -- \ref{ass:4} hold, the \mbox{number}~of~sketches satisfies $\tau\geq \log(\gamma_H/4\Upsilon_H)/\log \rho$ with $\rho = 1-\gamma_S$, and the stepsize parameters satisfy $\beta\in(0,1)$, $\chi>1.5\beta$, and $c_{\beta}, c_{\chi}>0$. Then, we have
\begin{equation*}
\mE\bigg[\Big\|\frac{1}{t}\sum_{i=1}^t\frac{1}{\varphi_{i-1}}(\bar{\bx}_t-\bx^\star)(\bar{\bx}_t-\bx^\star)^T\Big\|\bigg]\leq\frac{1}{t}\sum_{i=0}^{t-1}\frac{1}{\varphi_{i-1}}\mE\big[\|\bar{\bx}_t-\bx^\star\|^2\big]
\lesssim \begin{dcases}
\beta_t + \chi_t^2/\beta_t^3, &\beta\in(0,0.5],\\
1/t\beta_t + \chi_t^2/\beta_t^3, &\beta\in(0.5,1).
\end{dcases}
\end{equation*}
\end{lemma}


By the decomposition \eqref{appen:A5:equ1}, we follow the derivations in \eqref{appen:A4:equ23} and \eqref{appen:A4:equ19} and obtain
\begin{align*}
\mE\big[\|\widehat{\Xi}_t-\Xi^\star\|\big]&\leq
\mE\bigg[\Big\|\frac{1}{t}\sum_{i=1}^t\frac{1}{\varphi_{i-1}}(\bx_i-\bx^\star)(\bx_i-\bx^\star)^T-\Xi^\star\Big\|\bigg]+\mE\bigg[\Big\|\frac{1}{t}\sum_{i=1}^t\frac{1}{\varphi_{i-1}}(\bar{\bx}_t-\bx^\star)(\bar{\bx}_t-\bx^\star)^T\Big\|\bigg]\\
&\quad +2\sqrt{\frac{1}{t}\sum_{i=1}^t\frac{1}{\varphi_{i-1}}\mE\big[\|\bx_i-\bx^\star\|^2\big]}\sqrt{\frac{1}{t}\sum_{i=1}^t\frac{1}{\varphi_{i-1}}\mE\big[\|\bar{\bx}_t-\bx^\star\|^2\big]}.
\end{align*}
Plugging \eqref{appen:A5:equ16} and \eqref{appen:A5:equ21} in the proof of Lemma \ref{appen:A5:lem1} and \eqref{appen:A5:equ22} in the proof of Lemma \ref{appen:A5:lem2} into the above display, we obtain
\begin{scriptsize}
\begin{align*}
& \mE\big[\|\widehat{\Xi}_t-\Xi^\star\|\big]\\
&\lesssim \begin{dcases}
\frac{C_{g,2}^{1/4}}{\gamma_H(1-\rho^\tau)}\max \rbr{C_{\hat{\btheta}}^{1/2}, \frac{C_{\bdelta}^{1/2}}{(1-\rho^\tau)^{1/2}}}\sqrt{\beta_t} + \frac{C_{g,2}^{1/2}\mathbf{1}_{\{\chi\leq 2\beta\}}}{\gamma_H^2(1-\rho^\tau)^{3/2}}\sqrt{\frac{\chi_t^2}{\beta_t^{3}}} = O\rbr{\sqrt{\beta_t} + \frac{\chi_t}{\beta_t^{1.5}}}, &\beta\in(0,0.5),\\
\max\rbr{\frac{C_{g,2}^{1/4}}{\gamma_H(1-\rho^\tau)}\max\rbr{C_{\hat{\btheta}}^{1/2}, \frac{C_{\bdelta}^{1/2}}{(1-\rho^\tau)^{1/2}}}, \frac{\max(\|\Lambda\|_F, C_{g,2}^{1/2}/\gamma_H^2)}{c_{\beta}(1-\rho^\tau)^{3/2}}}\sqrt{\beta_t} + \frac{C_{g,2}^{1/2}\mathbf{1}_{\{\chi\leq 2\beta\}}}{\gamma_H^2(1-\rho^\tau)^{3/2}}\sqrt{\frac{\chi_t^2}{\beta_t^{3}}} = O\rbr{\sqrt{\beta_t} + \frac{\chi_t}{\beta_t^{1.5}}}, &\beta = 0.5,\\
\frac{\max(\|\Lambda\|_F, C_{g,2}^{1/2}/\gamma_H^2)}{(1-\rho^\tau)^{3/2}}\cdot\frac{1}{\sqrt{t\beta_t}} + \frac{C_{g,2}^{1/2}\mathbf{1}_{\{\chi\leq\beta+0.5\}}}{\gamma_H^2(1-\rho^\tau)^{3/2} }\sqrt{\frac{\chi_t^2}{\beta_t^{3}}}= O\rbr{\frac{1}{\sqrt{t\beta_t}} + \frac{\chi_t}{\beta_t^{1.5}}}, &\beta\in(0.5,1),
\end{dcases}
\end{align*}
\end{scriptsize}
\hskip-3.5pt with constants $C_{\hat{\btheta}}>0$ defined in \eqref{appen:A4:equ18} and $C_{\bdelta}>0$ later defined in \eqref{appen:A5:equ6}. This~completes~the~proof.


\subsubsection{Proof of Lemma \ref{appen:A5:lem1}}\label{pf:samplecov}

Recalling the decomposition \eqref{appen:A4:equ20}, we have proved the consistency of the dominant term $\frac{1}{t}\sum_{i=0}^{t-1}\frac{1}{\varphi_i}\I_{1,i}\I_{1,i}^T$ in Appendix \ref{appen:A4}. The next two lemmas suggest that the terms involving $\{\I_{2,i}\}_i$ and $\{\I_{3,i}\}_i$ are~higher order errors, the proofs of which are deferred to Appendices \ref{pf:I2} and \ref{pf:I3}.

\begin{lemma}\label{appen:A5:lem3}

Suppose the assumptions in Lemma \ref{appen:A5:lem1} hold, we have
\begin{equation*}
\mE\bigg[\Big\|\frac{1}{t}\sum_{i=0}^{t-1}\frac{1}{\varphi_i}\I_{2,i}\I_{2,i}^T\Big\|\bigg]\leq\frac{1}{t}\sum_{i=0}^{t-1}\frac{1}{\varphi_i}\mE\big[\|\I_{2,i}\|^2\big] =O(\chi_t^2/\beta_t^3)\cdot \mathbf{1}_{\{\chi<1.5\beta+0.5\}} + o(\beta_t)\cdot \mathbf{1}_{\{\chi\geq 1.5\beta+0.5\}}.
\end{equation*}
\end{lemma}

\begin{lemma}\label{appen:A5:lem4}

Suppose the assumptions in Lemma \ref{appen:A5:lem1} hold, we have
\begin{equation*}
\mE\bigg[\Big\|\frac{1}{t}\sum_{i=0}^{t-1}\frac{1}{\varphi_i}\I_{3,i}\I_{3,i}^T\Big\|\bigg]\leq\frac{1}{t} \sum_{i=0}^{t-1} \frac{1}{\varphi_i} \mE\big[\|\I_{3, i}\|^2\big] \lesssim \beta_t.
\end{equation*}
\end{lemma}

With the above two lemmas, we separate the proof Lemma \ref{appen:A5:lem1} by two parts.

\vskip 0.3cm
\noindent \textbf{Part 1: Proof of \eqref{appen:A5:equ10}.} By the decomposition \eqref{appen:A4:equ20}, we follow \eqref{appen:A4:equ23} and \eqref{appen:A4:equ19} and have
\begin{align}\label{appen:A5:equ9}
&\mE\bigg[\Big\|\frac{1}{t}\sum_{i=1}^t\frac{1}{\varphi_{i-1}}(\bx_i-\bx^\star)(\bx_i-\bx^\star)^T-\Xi^\star\Big\|\bigg]\nonumber\\
&\leq \mE\bigg[\Big\|\frac{1}{t}\sum_{i=0}^{t-1}\frac{1}{\varphi_i}\I_{1,i}\I_{1,i}^T-\Xi^\star\Big\|\bigg]
+\mE\bigg[\Big\|\frac{1}{t}\sum_{i=0}^{t-1}\frac{1}{\varphi_i}\I_{2,i}\I_{2,i}^T\Big\|\bigg]+\mE\bigg[\Big\|\frac{1}{t}\sum_{i=0}^{t-1}\frac{1}{\varphi_i}\I_{3,i}\I_{3,i}^T\Big\|\bigg]\nonumber\\
&+2\sum_{1\leq r<s\leq 3}\sqrt{\frac{1}{t}\sum_{i=0}^{t-1}\frac{1}{\varphi_i}\mE\big[\|\I_{r,i}\|^2\big]}  \sqrt{\frac{1}{t}\sum_{i=0}^{t-1}\frac{1}{\varphi_i}\mE\big[\|\I_{s,i}\|^2\big]}.
\end{align}
Given Lemmas \ref{appen:A4:lem2}, \ref{appen:A5:lem3}, and \ref{appen:A5:lem4}, it is sufficient to establish the bound for $\frac{1}{t}\sum_{i=0}^{t-1} \frac{1}{\varphi_i} \mE\big[\|\I_{1,i}\|^2\big]$. We first bound the moment for $\|\btheta^k\|$. Based on its definition \eqref{rec:def:b}, we have
\begin{equation*}
\btheta^k = -(I-\tilde{C}_k)B_k^{-1}(\bar{g}_k-\nabla F_k) + (\tilde{C}_k-C_k)B_k^{-1}\nabla F_k.
\end{equation*}
Furthermore, by $\|\tilde{C}_k\|\leq 1$, $\|C_k\|\leq 1$, and \eqref{ass:3:c2}, we get
\begin{align}\label{appen:A5:equ2}
\mE\big[\|\btheta^k\|^2\big]&\lesssim \frac{1}{\gamma_H^2}\mE\big[\|\bar{g}_k-\nabla F_k\|^2\big] + \frac{1}{\gamma_H^2}\mE\big[\|\nabla F_k\|^2\big]\nonumber\\
&\leq \frac{C_{g,1}^{1/2}}{\gamma_H^2}\mE\big[\|\bx_k-\bx^\star\|^2\big] + \frac{C_{g,2}^{1/2}}{\gamma_H^2} + \frac{\Upsilon_H^2}{\gamma_H^2}\mE\big[\|\bx_k-\bx^\star\|^2\big]\quad(\text{by Assumptions \ref{ass:2} and \ref{ass:3}})\nonumber\\
&\lesssim \frac{C_{g,2}^{1/2}}{\gamma_H^2}\quad (\mE\big[\|\bx_k-\bx^\star\|^2\big]=o(1) \text{ by Lemma \ref{sec4:lem1}}).
\end{align}
Since $\btheta^k$ is a martingale difference sequence, we follow \eqref{appen:A4:equ21} and get
\begin{multline}\label{appen:A5:equ20}
\frac{1}{t}\sum_{i=0}^{t-1} \frac{1}{\varphi_i} \mE\big[\|\I_{1,i}\|^2\big] \leq \frac{1}{t}\sum_{i=0}^{t-1} \frac{1}{\varphi_i}\sum_{k=0}^i \prod_{l=k+1}^i (1-(1-\rho^{\tau}) \varphi_l)^2\varphi_k^2 \mE\big[\|\btheta^k\|^2\big]\\
\lesssim \frac{C_{g,2}^{1/2}}{\gamma_H^2}\frac{1}{t}\sum_{i=0}^{t-1}\underbrace{\frac{1}{\varphi_i}\sum_{k=0}^{i}\prod_{l=k+1}^i(1-(1-\rho^{\tau})\varphi_l)^2 \varphi_k^2}_{\rightarrow 0.5/(1-\rho^\tau)\quad\text{by Lemma \ref{aux:lem1}}}\lesssim \frac{C_{g,2}^{1/2}}{\gamma_H^2(1-\rho^\tau)}.
\end{multline}
Combining the above display, Lemma \ref{appen:A4:lem2} (\eqref{appen:A4:equ27} in the proof), Lemma \ref{appen:A5:lem3} (\eqref{appen:A5:equ14} in the proof), and Lemma \ref{appen:A5:lem4} (\eqref{appen:A5:equ15} in the proof), and plugging them into \eqref{appen:A5:equ9}, we get
\begin{scriptsize}
\begin{multline}\label{appen:A5:equ16}
\mE\bigg[\Big\|\frac{1}{t}\sum_{i=1}^t\frac{1}{\varphi_{i-1}}(\bx_i-\bx^\star)(\bx_i-\bx^\star)^T-\Xi^\star\Big\|\bigg]\\
\lesssim \begin{dcases}
\frac{C_{g,2}^{1/4}}{\gamma_H(1-\rho^\tau)}\max \rbr{C_{\hat{\btheta}}^{1/2}, \frac{C_{\bdelta}^{1/2}}{(1-\rho^\tau)^{1/2}}}\sqrt{\beta_t} + \frac{C_{g,2}^{1/2}\mathbf{1}_{\{\chi\leq 2\beta\}}}{\gamma_H^2(1-\rho^\tau)^{3/2}}\sqrt{\frac{\chi_t^2}{\beta_t^{3}}} = O\rbr{\sqrt{\beta_t} + \frac{\chi_t}{\beta_t^{1.5}}}, &\beta\in(0,0.5),\\
\max\rbr{\frac{C_{g,2}^{1/4}}{\gamma_H(1-\rho^\tau)}\max\rbr{C_{\hat{\btheta}}^{1/2}, \frac{C_{\bdelta}^{1/2}}{(1-\rho^\tau)^{1/2}}}, \frac{\max(\|\Lambda\|_F, C_{g,2}^{1/2}/\gamma_H^2)}{c_{\beta}(1-\rho^\tau)^{3/2}}}\sqrt{\beta_t} + \frac{C_{g,2}^{1/2}\mathbf{1}_{\{\chi\leq 2\beta\}}}{\gamma_H^2(1-\rho^\tau)^{3/2}}\sqrt{\frac{\chi_t^2}{\beta_t^{3}}} = O\rbr{\sqrt{\beta_t} + \frac{\chi_t}{\beta_t^{1.5}}}, &\beta = 0.5,\\
\frac{\max(\|\Lambda\|_F, C_{g,2}^{1/2}/\gamma_H^2)}{(1-\rho^\tau)^{3/2}}\cdot\frac{1}{\sqrt{t\beta_t}} + \frac{C_{g,2}^{1/2}\mathbf{1}_{\{\chi\leq\beta+0.5\}}}{\gamma_H^2(1-\rho^\tau)^{3/2}}\sqrt{\frac{\chi_t^2}{\beta_t^{3}}}= O\rbr{\frac{1}{\sqrt{t\beta_t}} + \frac{\chi_t}{\beta_t^{1.5}}}, &\beta\in(0.5,1),
\end{dcases}
\end{multline}
\end{scriptsize}
\hskip-3.5pt where constants $C_{\hat{\btheta}}>0$ is defined in \eqref{appen:A4:equ18} and $C_{\bdelta}>0$ will be later defined in \eqref{appen:A5:equ6}. Here, we~also use the observation that $\chi_t^2/\beta_t^3 = o(\beta_t)$ when $\chi>2\beta$ and $\beta\in(0,0.5]$, and $\chi_t^2/\beta_t^3=o(1/t\beta_t)$ when $\chi>\beta+0.5$ and $\beta\in(0.5,1)$.

\vskip 0.3cm
\noindent \textbf{Part 2: Proof of \eqref{appen:A5:equ19}.} By the decomposition \eqref{appen:A4:equ20}, we have
\begin{equation}\label{appen:A5:equ21}
\frac{1}{t}\sum_{i=0}^{t-1}\frac{1}{\varphi_{i-1}}\mE\big[\|\bx_i-\bx^\star\|^2\big] \lesssim \sum_{k=1}^3 \frac{1}{t}\sum_{i=0}^{t-1} \frac{1}{\varphi_i} \mE\big[\|\I_{k,i}\|^2\big] \lesssim \frac{C_{g,2}^{1/2}}{\gamma_H^2(1-\rho^\tau)},
\end{equation}
where the last inequality follows from \eqref{appen:A5:equ20}, and Lemmas \ref{appen:A5:lem3} and \ref{appen:A5:lem4}. We complete the proof.


\subsubsection{Proof of Lemma \ref{appen:A5:lem2}}\label{pf:barx}

By \eqref{appen:A4:equ1}, we decompose $\bar{\bx}_t-\bx^\star$ as
\begin{equation}\label{appen:A5:equ4}
\bar{\bx}_t-\bx^\star = \frac{1}{t}\sum_{i=0}^{t-1}\I_{1,i} + \frac{1}{t}\sum_{i=0}^{t-1}\I_{2,i}
+\frac{1}{t}\sum_{i=0}^{t-1}\I_{3,i}=: \bar{\I}_{1,t}
+\bar{\I}_{2,t}+\bar{\I}_{3,t}.
\end{equation}
We expand $\bar{\I}_{1,t}$ by plugging in \eqref{rec:a} and exchange the indices. Then, we obtain
\begin{equation*}
\bar{\I}_{1, t}=\frac{1}{t} \sum_{i=0}^{t-1} \sum_{k=0}^i \prod_{l=k+1}^i \{I-\varphi_l (I-C^\star)\} \varphi_k \btheta^k =\frac{1}{t} \sum_{k=0}^{t-1}\sum_{i=k}^{t-1} \prod_{l=k+1}^i \{I-\varphi_l (I-C^\star)\} \varphi_k \btheta^k.    
\end{equation*}
Since $\btheta^k$ is a martingale difference sequence, the interaction terms in $\mE\big[\|\bar{\I}_{1,t}\|^2\big]$ are vanished. Thus, we have
\begin{multline*}
\mE\big[\|\bar{\I}_{1,t}\|^2\big] 
= \frac{1}{t^2} \sum_{k=0}^{t-1}\varphi_k^2
\mE\bigg[\Big\|\sum_{i=k}^{t-1} \prod_{l=k+1}^i \{I-\varphi_l (I-C^\star)\} \btheta^k\Big\|^2\bigg]\\
\leq \frac{1}{t^2} \sum_{k=0}^{t-1}
\Big(\sum_{i=k}^{t-1} \prod_{l=k+1}^i (1- (1-\rho^\tau)\varphi_l)\Big)^2 \varphi_k^2 \mE\big[\|\btheta^k\|^2\big]=:(\#)\quad\text{(by Lemma \ref{aux:lem4}(d))}.
\end{multline*}
We rewrite the above display by exchanging the indices, and obtain
\begin{align*}
(\#) &= \frac{1}{t^2} \sum_{k=0}^{t-1}
\sum_{i_1=k}^{t-1}\sum_{i_2=k}^{t-1} \prod_{l_1=k_1+1}^{i_1} (1- (1-\rho^\tau)\varphi_{l_1}) \prod_{l_2=k_2+1}^{i_2} (1- (1-\rho^\tau)\varphi_{l_2})\varphi_k^2 \mE\big[\|\btheta^k\|^2\big]\\
&=\frac{1}{t^2} \sum_{i_1=0}^{t-1} \sum_{i_2=0}^{t-1} \sum_{k=0}^{i_1\wedge i_2} \prod_{l_1=k+1}^{i_1}(1- (1-\rho^\tau)\varphi_{l_1}) \prod_{l_2=k+1}^{i_2}(1- (1-\rho^\tau)\varphi_{l_2}) \varphi_k^2 \mE\big[\|\btheta^k\|^2\big]\\
&\leq \frac{2}{t^2}\sum_{i_1=0}^{t-1} \sum_{i_2=0}^{i_1}\prod_{l_1=i_2+1}^{i_1}(1- (1-\rho^\tau)\varphi_{l_1}) \sum_{k=0}^{i_2} \prod_{l_2=k+1}^{i_2}(1- (1-\rho^\tau)\varphi_{l_2})^2 \varphi_k^2 \mE\big[\|\btheta^k\|^2\big],
\end{align*}
where the last inequality comes from the symmetry between the indices $i_1$ and $i_2$. We plug in \eqref{appen:A5:equ2} and get
\begin{align}\label{appen:A5:equ12}
\mE\big[\|\bar{\I}_{1,t}\|^2\big] & \lesssim \frac{C_{g,2}^{1/2}}{\gamma_H^2} \cdot \frac{1}{t^2}\sum_{i_1=0}^{t-1} \sum_{i_2=0}^{i_1}\prod_{l_1=i_2+1}^{i_1}(1- (1-\rho^\tau)\varphi_{l_1}) \underbrace{\sum_{k=0}^{i_2} \prod_{l_2=k+1}^{i_2}(1- (1-\rho^\tau)\varphi_{l_2})^2 \varphi_k^2}_{\lesssim \varphi_{i_2}/(1-\rho^\tau)\quad\text{ by Lemma \ref{aux:lem1}}} \nonumber\\
& \lesssim \frac{C_{g,2}^{1/2}}{\gamma_H^2(1-\rho^\tau)} \cdot \frac{1}{t^2}\sum_{i_1=0}^{t-1} \underbrace{\sum_{i_2=0}^{i_1}\prod_{l_1=i_2+1}^{i_1}(1- (1-\rho^\tau)\varphi_{l_1})\varphi_{i_2}}_{\longrightarrow 1/(1-\rho^{\tau})\quad\text{ by Lemma \ref{aux:lem1}}}\lesssim  \frac{C_{g,2}^{1/2}}{\gamma_H^2(1-\rho^\tau)^2} \cdot \frac{1}{t}.
\end{align}
For the term $\bar{\I}_{2,t}$, we plug in \eqref{rec:b} and get
\begin{equation*}
\bar{\I}_{2, t}=\frac{1}{t} \sum_{i=0}^{t-1} \sum_{k=0}^i \prod_{l=k+1}^i \{I-\varphi_l (I-C^\star)\}(\bar{\alpha}_k- \varphi_k) \bar{\Delta}\bx_k.
\end{equation*}
Furthermore, by Lemma \ref{aux:lem4}(d) and the fact that $|\bar{\alpha}_k-\varphi_k|\leq \chi_k/2$, we know
\begin{multline}\label{appen:A5:equ8}
\mE\big[\|\bar{\I}_{2, t}\|^2\big] \lesssim 
\mE\bigg[\Big(\frac{1}{t}\sum_{i=0}^{t-1} \sum_{k=0}^i \prod_{l=k+1}^i (1-(1-\rho^\tau)\varphi_l)\chi_k \|\bar{\Delta}\bx_k\|\Big)^2\bigg]\\
\leq \Big(\frac{1}{t}\sum_{i=0}^{t-1} \sum_{k=0}^i \prod_{l=k+1}^i (1-(1-\rho^\tau)\varphi_l) \chi_k\sqrt{\mathbb{E}\big[\|\bar{\Delta}\bx_k\|^2\big]}\Big)^2\quad \text{(by H\"older's inequality)}.
\end{multline}
Using $\|\tilde{C}_k\|\leq 1$ and \eqref{ass:3:c2}, we bound $\mathbb{E}\big[\|\bar{\Delta}\bx_k\|^2\big]$ as
\begin{equation}\label{appen:A5:equ5}
\mathbb{E}\big[\|\bar{\Delta}\bx_k\|^2\big]\leq \mE\big[\|I-\tilde{C}_k\|^2\|B_k^{-1}\|^2\|\bar{g}_k\|^2\big] \lesssim \frac{1}{\gamma_H^2}\big(\mE\big[\|\bar{g}_k-\nabla F_k\|^2\big]+\mE\big[\|\nabla F_k\|^2\big]\big)
\stackrel{\eqref{appen:A5:equ2}}{\lesssim} \frac{C_{g,2}^{1/2}}{\gamma_H^2}.
\end{equation}
Consequently, we obtain
\begin{align}\label{appen:A5:equ13}
\mE\big[\|\bar{\I}_{2, t}\|^2\big]\cdot\mathbf{1}_{\{\chi<\beta+1\}} &\lesssim  \frac{C_{g,2}^{1/2}\mathbf{1}_{\{\chi<\beta+1\}}}{\gamma_H^2}\Big(\frac{1}{t}\sum_{i=0}^{t-1} \underbrace{\sum_{k=0}^{i} \prod_{l=k+1}^i\left(1-\left(1-\rho^\tau\right) \varphi_l\right)\varphi_k\cdot \frac{\chi_k}{\varphi_k}}_{\lesssim (\chi_{i}/\beta_i)/(1-\rho^\tau)\quad\text{by Lemma \ref{aux:lem1}}}\Big)^2\nonumber\\
&\lesssim \frac{C_{g,2}^{1/2} \mathbf{1}_{\{\chi<\beta+1\}}}{\gamma_H^2(1-\rho^\tau)^2}\Big(\frac{1}{t}\sum_{i=0}^{t-1}\frac{\chi_i}{\beta_i}\Big)^2    \stackrel{\eqref{appen:A3:equ11}}{\lesssim} \frac{C_{g,2}^{1/2}\mathbf{1}_{\{\chi<\beta+1\}}}{\gamma_H^2(1-\rho^\tau)^2(1-(\chi-\beta))^2}\cdot \frac{\chi_t^2}{\beta_t^2},\\
\mE\big[\|\bar{\I}_{2, t}\|^2\big]\cdot\mathbf{1}_{\{\chi\geq \beta+ 1\}} &= \Big(\frac{1}{t}\sum_{i=0}^{t-1} o(\beta_i)\Big)^2\cdot \mathbf{1}_{\{\chi\geq \beta+ 1\}} \stackrel{\eqref{appen:A3:equ11}}{=} o(\beta_t^2)\cdot \mathbf{1}_{\{\chi\geq \beta+ 1\}}. \nonumber
\end{align}
Here, we use the fact that $\chi\geq \beta+1 > 2\beta \Rightarrow \chi_t/\beta_t = o(\beta_t)$. For~the~term~$\bar{\I}_{3,t}$,~\eqref{rec:c} gives~us~the~following expansion
\begin{equation*}
\bar{\I}_{3, t}=\frac{1}{t} \sum_{i=0}^{t-1} \prod_{k=0}^i \{I-\varphi_k (I-C^\star)\} (\bx_0-\bx^\star) +\frac{1}{t} \sum_{i=0}^{t-1} \sum_{k=0}^i \sum_{ l=k+1}^i \{I-\varphi_l (I-C^\star)\} \varphi_k \bdelta^k.
\end{equation*}
Similar to \eqref{appen:A5:equ8}, by H\"older's inequality, we have
\begin{multline}\label{appen:A5:equ11}
\mE\big[\|\bar{\I}_{3,t}\|^2\big]\lesssim \Big(\frac{1}{t}\sum_{i=0}^{t-1}\prod_{k=0}^i(1-(1-\rho^\tau)\varphi_k)\Big)^2\|\bx_0-\bx^\star\|^2\\
+ \Big(\frac{1}{t}\sum_{i=0}^{t-1}\sum_{k=0}^i\prod_{l=k+1}^i(1-(1-\rho^\tau)\varphi_l)\varphi_k\sqrt{\mE\big[\|\bdelta^k\|^2\big]}\Big)^2.
\end{multline}
Next, we bound the rate of  $\mE\big[\|\bdelta^k\|^2\big]$. By the definition of $\bdelta^k$ in \eqref{rec:def:c} and $\bpsi^k$  in \eqref{rec:def:d}, we have
\begin{align*}
\|\bdelta^k\|^2 &\lesssim \|C_k-C^\star\|^2\|\bx_k-\bx^\star\|^2+\|(B^{\star})^{-1}\|^2\|\bpsi^k\|^2 + \|B_k^{-1}\|^2\|(B^{\star})^{-1}\|^2\|B_k-B^\star\|^2\|\nabla F_k\|^2\\
&\leq \frac{\tau^2\Upsilon_S}{\gamma_H^2}\|B_k-B^\star\|^2 \|\bx_k-\bx^\star\|^2 + \frac{1}{\gamma_H^2}\cdot \frac{\Upsilon_L^2}{4}\|\bx_k-\bx^\star\|^4 + \frac{\Upsilon_H^2}{\gamma_H^4}\|B_k-B^\star\|^2 \|\bx_k-\bx^\star\|^2.
\end{align*}
The second inequality is due to $\|C_k-C^\star\|\leq \tau\Upsilon_{S}^{1/2}\|B_k-B^\star\|/\gamma_H$ \cite[Lemma 5.2]{Na2022Statistical}, the $\Upsilon_L$-Lipschitz continuity of $\nabla^2 F(\bx)$, and \eqref{ass:3:c2}. Thus, we take~expectation~and~obtain
\begin{align}\label{appen:A5:equ6}
\mE\big[\|\bdelta^k\|^2\big] &\lesssim \Big(\frac{\tau^2\Upsilon_{S}}{\gamma_H^2} +\frac{\Upsilon_H^2}{\gamma_H^4}\Big) \mE\big[\|B_k-B^\star\|^2\|\bx_k-\bx^\star\|^2\big] + \frac{\Upsilon_L^2}{\gamma_H^2}\mE\big[\|\bx_k-\bx^\star\|^4\big]\nonumber\\
&\lesssim \Big(\frac{\tau^2\Upsilon_{S}}{\gamma_H^2}+\frac{\Upsilon_H^2}{\gamma_H^4}\Big)\sqrt{\mE\big[\|B_k-B^\star\|^4\big]}\sqrt{\mE\big[\|\bx_k-\bx^\star\|^4\big]} +\frac{\Upsilon_L^2}{\gamma_H^2} 
\mE\big[\|\bx_k-\bx^\star\|^4\big]\nonumber\\
&\lesssim \Big(\frac{\tau^2\Upsilon_S}{\gamma_H^2}+\frac{\Upsilon_H^2}{\gamma_H^4}\Big)\cdot \frac{\Upsilon_L^2\Upsilon_H^4C_{g,2}}{\gamma_H^8}\beta_t^2 \eqqcolon C_{\bdelta}\beta_t^2,
\end{align}
where the last inequality follows from Lemma \ref{sec4:lem1} (particularly \eqref{xtrate} and \eqref{appen:A3:equ15} in the proof) and the observation $\chi>1.5\beta \Rightarrow \chi_t^4/\beta_t^4 = o(\beta_t^2)$. We plug \eqref{appen:A5:equ6} into \eqref{appen:A5:equ11}, apply Lemma \ref{aux:lem1}, and get
\begin{align}\label{appen:A5:equ18}
\mE\big[\|\bar{\I}_{3,t}\|^2\big]&\lesssim \Big(\frac{1}{t}\sum_{i=0}^{t-1}\underbrace{\prod_{k=0}^i(1-(1-\rho^\tau)\varphi_k)}_{=o(\chi_t^2/\beta_t^2+\beta_t)\quad\text{by \eqref{appen:A1:equ1b}}}\Big)^2\|\bx_0-\bx^\star\|^2 + C_{\bdelta}\Big(\frac{1}{t}\sum_{i=0}^{t-1}\underbrace{\sum_{k=0}^i\prod_{l=k+1}^i(1-(1-\rho^\tau)\varphi_l)\varphi_k\cdot \beta_k}_{\lesssim \beta_i/(1-\rho^\tau)\quad\text{by \eqref{appen:A1:equ1a}}}\Big)^2\nonumber\\
&\stackrel{\mathclap{\eqref{appen:A3:equ11}}}{\lesssim}\;\; \frac{C_{\bdelta}}{(1-\rho^\tau)^2(1-\beta)^2}\beta_t^2.
\end{align}
We recall the fact that $\frac{1}{t}\sum_{i=0}^{t-1}\frac{1}{\varphi_i}\lesssim 1/\beta_t$ in \eqref{appen:A4:equ26},  combine \eqref{appen:A5:equ4},  \eqref{appen:A5:equ12}, \eqref{appen:A5:equ13}, and \eqref{appen:A5:equ18}~together, and obtain
\begin{footnotesize}
\begin{equation}\label{appen:A5:equ22}
\frac{1}{t}\sum_{i=0}^{t-1}\frac{1}{\varphi_i}\mE\big[\|\bar{\bx}_t-\bx^\star\|^2\big]
\lesssim \begin{dcases}
\frac{C_{\bdelta}}{(1-\rho^\tau)^2}\beta_t + \frac{C_{g,2}^{1/2}\mathbf{1}_{\{\chi\leq 2\beta\}}}{\gamma_H^2(1-\rho^\tau)^2 }\cdot \frac{\chi_t^2}{\beta_t^3} = O\rbr{\beta_t + \frac{\chi_t^2}{\beta_t^3}}, &\beta\in(0,0.5),\\
\max\rbr{\frac{C_{g,2}^{1/2}}{c_{\beta}^2 \gamma_H^2(1-\rho^\tau)^2}, \frac{ C_{\bdelta}}{(1-\rho^\tau)^2}}\beta_t + \frac{C_{g,2}^{1/2}\mathbf{1}_{\{\chi\leq 2\beta\}}}{\gamma_H^2(1-\rho^\tau)^2 }\cdot \frac{\chi_t^2}{\beta_t^3} = O\rbr{\beta_t + \frac{\chi_t^2}{\beta_t^3}} &\beta=0.5,\\
\frac{C_{g,2}^{1/2}}{\gamma_H^2(1-\rho^\tau)^2}\cdot\frac{1}{t\beta_t} + \frac{C_{g,2}^{1/2}\mathbf{1}_{\{\chi\leq \beta+0.5\}}}{\gamma_H^2(1-\rho^\tau)^2}\cdot \frac{\chi_t^2}{\beta_t^3} = O\rbr{\frac{1}{t\beta_t} + \frac{\chi_t^2}{\beta_t^3}}, &\beta\in(0.5,1).
\end{dcases}
\end{equation}
\end{footnotesize}
\hskip-3.5pt Here follows the same discussion as in \eqref{appen:A5:equ16}. This completes the proof.


\subsubsection{Proof of Lemma \ref{appen:A5:lem3}}\label{pf:I2}

Based on the definition of $\I_{2,i}$ in \eqref{rec:b}, we apply Lemma \ref{aux:lem4}(d) and the fact that $|\bar{\alpha}_k-\varphi_k|\leq \chi_k/2$, then we have
\begin{equation*}
\begin{aligned}
\mE\|\I_{2,i}\|^2 &\leq \mE\sbr{\rbr{\sum_{k=0}^i \prod_{l=k+1}^i(1-(1-\rho^\tau)\varphi_l) \frac{\chi_k}{2}\|\bar{\Delta} \bx_k\|}^2}\\
& \lesssim \Big(\sum_{k=0}^i \prod_{l=k+1}^i(1-(1-\rho^\tau)\varphi_l) \chi_k\sqrt{\mE\big[\|\bar{\Delta} \bx_k\|^2\big]}\Big)^2\quad(\text{by H\"older's inequality})\\
&\stackrel{\mathclap{\eqref{appen:A5:equ5}}}{\lesssim}\;\; \frac{C_{g,2}^{1/2}}{\gamma_H^2}\Big(\sum_{k=0}^i \prod_{l=k+1}^i(1-(1-\rho^\tau)\varphi_l)\varphi_k\cdot\frac{\chi_k}{\varphi_k}\Big)^2 \lesssim \frac{C_{g,2}^{1/2}}{\gamma_H^2(1-\rho^\tau)^2}\cdot \frac{\chi_i^2}{\varphi_i^2}\quad(\text{by Lemma \ref{aux:lem1}}).    
\end{aligned}
\end{equation*}
With the above display, we obtain
\begin{align}\label{appen:A5:equ14}
&\frac{1}{t}\sum_{i=0}^{t-1}\frac{1}{\varphi_i}\mE\big[\|\I_{2,i}\|^2\big]\cdot \mathbf{1}_{\{\chi< 1.5\beta+0.5\}} \lesssim \frac{C_{g,2}^{1/2}\mathbf{1}_{\{\chi< 1.5\beta+0.5\}}}{\gamma_H^2(1-\rho^\tau)^2}\cdot \frac{1}{t}\sum_{i=0}^{t-1}\frac{\chi_i^2}{\varphi_i^3}\nonumber\\
&\quad\quad \stackrel{\mathclap{\eqref{appen:A3:equ11}}}{\lesssim}\;\; \frac{C_{g,2}^{1/2}\mathbf{1}_{\{\chi< 1.5\beta+0.5\}}}{\gamma_H^2(1-\rho^\tau)^2(1-(2\chi-3\beta))}\cdot\frac{\chi_t^2}{\beta_t^3} = O\rbr{\frac{\chi_t^2}{\beta_t^3}}\cdot \mathbf{1}_{\{\chi< 1.5\beta+0.5\}},\\
&\frac{1}{t}\sum_{i=0}^{t-1}\frac{1}{\varphi_i}\mE\big[\|\I_{2,i}\|^2\big]\cdot \mathbf{1}_{\{\chi\geq 1.5\beta+0.5\}} = \frac{1}{t}\sum_{i=0}^{t-1} o(\beta_t)\cdot \mathbf{1}_{\{\chi\geq 1.5\beta+0.5\}} \stackrel{\eqref{appen:A3:equ11}}{=} o(\beta_t)\cdot \mathbf{1}_{\{\chi\geq 1.5\beta+0.5\}}.    \nonumber
\end{align}
This completes the proof.


\subsubsection{Proof of Lemma \ref{appen:A5:lem4}}\label{pf:I3}

Given the expression of $\I_{3,i}$ in \eqref{rec:c}, we apply Lemma \ref{aux:lem4}(d) and have
\begin{align*}
\mE\big[\|\I_{3, i}\|^2\big] &\lesssim \prod_{k=0}^i(1-(1-\rho^{\tau})\varphi_k)^2\|\bx_0-\bx^\star\|^2 + \Big(\sum_{k=0}^i\prod_{l=k+1}^i(1-(1-\rho)^\tau)\varphi_l) \varphi_k\|\bdelta^k\|\Big)^2\\
&\leq \prod_{k=0}^i(1-(1-\rho^{\tau})\varphi_k)^2\|\bx_0-\bx^\star\|^2 + \Big(\sum_{k=0}^i\prod_{l=k+1}^i(1-(1-\rho^\tau)\varphi_l) \varphi_k \sqrt{\mE\big[\|\bdelta^k\|^2\big]}\Big)^2,
\end{align*}
where the last inequality is due to H\"older's inequality. We plugging in \eqref{appen:A5:equ6}, apply Lemma \ref{aux:lem1}, and get
\begin{align}\label{appen:A5:equ15}
\frac{1}{t} \sum_{i=0}^{t-1} \frac{1}{\varphi_i} \mE\big[\|\I_{3, i}\|^2\big] &\lesssim  \frac{1}{t} \sum_{i=0}^{t-1} \frac{1}{\varphi_i} \Big(\underbrace{\prod_{k=0}^i(1-(1-\rho^{\tau})\varphi_k)}_{=o(\beta_i)\quad\text{by \eqref{appen:A1:equ1a}}}\Big)^2\cdot \|\bx_0-\bx^\star\|^2\nonumber\\
&\quad\quad + \frac{C_{\bdelta}}{t} \sum_{i=0}^{t-1} \frac{1}{\varphi_i}\bigg(\underbrace{\sum_{k=0}^i \prod_{l=k+1}^i (1-(1-\rho^\tau)\varphi_l) \varphi_k \cdot\beta_k}_{\lesssim \beta_i/(1-\rho^\tau)\quad\text{by \eqref{appen:A1:equ1b}}} \bigg)^2\nonumber\\
&\lesssim \frac{C_{\bdelta}}{(1-\rho^\tau)^2}\cdot \frac{1}{t}\sum_{i=0}^{t-1}\beta_i \stackrel{\eqref{appen:A3:equ11}}{\lesssim} \frac{C_{\bdelta}}{(1-\rho^\tau)^2(1-\beta)}\beta_t = O\rbr{\beta_t}.
\end{align}
This completes the proof.


\section{Additional Experiment Results}\label{appen:exp}

In this section, we complement Section \ref{sec:5} by presenting additional experimental results on regression problems. Specifically, we evaluate the performance of three online covariance estimators ($\bar{\Xi}_t, \tilde{\Xi}_t$,~and $\hat{\Xi}_t$) across different design covariance matrices $\Sigma_a$. Following the experimental setup in Sections~\ref{sec5:linear} and \ref{sec5:logistic}, we construct 95\% confidence intervals for $\sum_{i=1}^d \bx^\star_i / d$. To assess performance, we vary $r \in \{0.4, 0.5, 0.6\}$ for Toeplitz $\Sigma_a$ and $r \in \{0.1, 0.2, 0.3\}$ for Equi-correlation $\Sigma_a$. Tables \ref{appen:table:1}--\ref{appen:table:4}~summarize the empirical coverage rates of the confidence intervals and the averaged relative variance estimation error for $\sum_{i=1}^d (\bx_t)_i / d$ at the final iteration.



Overall, the results align with the analyses in Sections \ref{sec5:linear} and \ref{sec5:logistic}. These results further~demonstrate the superior performance of $\hat{\Xi}_t$ in statistical inference compared to $\bar{\Xi}_t$ and $\tilde{\Xi}_t$. Regarding~the influence of $r$, a general trend is that increasing $r$ makes the problem more challenging. This~is~because a larger $r$ increases the condition number of $\Sigma_a$, which leads to harder problems. This can be observed in several ways. 
First, for Toeplitz $\Sigma_a$, $\hat{\Xi}_t$ performs well when $r = 0.4$ and $0.5$. However,~for $r = 0.6$ and $d = 100$, both $\tilde{\Xi}_t$ and $\bar{\Xi}_t$ fail to converge. Although their performance improves when $\tau$ increases from 10 to 40, neither achieves convergence for $r = 0.6$. This suggests that the iterate $\bx_t$ does not converge well, and $\tau = 40$ is insufficient to achieve desirable accuracy in approximating~the Newton direction. 
Second, in Table \ref{appen:table:4}, we observe that the coverage rate~corresponding~to~$\bar{\Xi}_t$~decreases as $r$ increases from $0.1$ to $0.3$. Similarly, in Tables \ref{appen:table:3} and \ref{appen:table:4}, for the bold settings, the coverage rate corresponding to $\tilde{\Xi}_t$ decreases as $r$ increases. These results reinforce the impact of $r$ on problem difficulty and highlight the robustness of $\hat{\Xi}_t$ across different scenarios.



\begin{table}[!t]
\centering
\resizebox{\linewidth}{!}{
\begin{tabular}{|c|c|c|c|cccccccc|}
\hline
\multirow{3}{*}{Toeplitz $\Sigma_a$} &
\multirow{3}{*}{d} &
\multirow{3}{*}{Criterion} &
\multirow{2}{*}{SGD} &
\multicolumn{8}{c|}{Sketched Newton Method} \\ \cline{5-12} 
&
&
&
&
\multicolumn{2}{c|}{$\tau=\infty$} &
\multicolumn{2}{c|}{$\tau=10$} &
\multicolumn{2}{c|}{$\tau=20$} &
\multicolumn{2}{c|}{$\tau=40$} \\ \cline{4-12} 
&
&
&
{\footnotesize$\bar{\Xi}_t$} &
{\footnotesize$\tilde{\Xi}_t$} &
\multicolumn{1}{c|}{{\footnotesize$\hat{\Xi}_t$}} &
{\footnotesize$\tilde{\Xi}_t$} &
\multicolumn{1}{c|}{{\footnotesize$\hat{\Xi}_t$}} &
{\footnotesize$\tilde{\Xi}_t$} &
\multicolumn{1}{c|}{{\footnotesize$\hat{\Xi}_t$}} &
{\footnotesize$\tilde{\Xi}_t$} &
{\footnotesize$\hat{\Xi}_t$} \\ \hline
\multirow{8}{*}{r=0.4} &
\multirow{2}{*}{20} &
Cov (\%) &
92.00 &
93.50 &
\multicolumn{1}{c|}{93.50} &
92.00 &
\multicolumn{1}{c|}{97.00} &
94.50 &
\multicolumn{1}{c|}{97.00} &
91.00 &
93.00 \\
&
&
Var Err &
-0.166 &
0.025 &
\multicolumn{1}{c|}{0.017} &
-0.321 &
\multicolumn{1}{c|}{0.014} &
-0.266 &
\multicolumn{1}{c|}{0.015} &
-0.177 &
0.014 \\ \cline{2-12} 
&
\multirow{2}{*}{40} &
Cov (\%) &
92.50 &
92.50 &
\multicolumn{1}{c|}{92.00} &
87.50 &
\multicolumn{1}{c|}{96.50} &
84.50 &
\multicolumn{1}{c|}{93.00} &
90.50 &
97.50 \\
&
&
Var Err &
-0.095 &
0.049 &
\multicolumn{1}{c|}{0.051} &
-0.350 &
\multicolumn{1}{c|}{0.030} &
-0.319 &
\multicolumn{1}{c|}{0.029} &
-0.263 &
0.031 \\ \cline{2-12} 
&
\multirow{2}{*}{60} &
Cov (\%) &
90.50 &
95.00 &
\multicolumn{1}{c|}{95.00} &
91.00 &
\multicolumn{1}{c|}{97.50} &
84.00 &
\multicolumn{1}{c|}{93.50} &
89.00 &
95.00 \\
&
&
Var Err &
-0.112 &
0.072 &
\multicolumn{1}{c|}{0.066} &
-0.350 &
\multicolumn{1}{c|}{0.048} &
-0.332 &
\multicolumn{1}{c|}{0.041} &
-0.292 &
0.060 \\ \cline{2-12} 
&
\multirow{2}{*}{100} &
Cov (\%) &
90.50 &
100.0 &
\multicolumn{1}{c|}{100.0} &
87.50 &
\multicolumn{1}{c|}{95.50} &
92.00 &
\multicolumn{1}{c|}{98.00} &
90.00 &
97.00 \\
&
&
Var Err &
-0.100 &
$\infty$ &
\multicolumn{1}{c|}{$\infty$} &
-0.313 &
\multicolumn{1}{c|}{0.128} &
-0.327 &
\multicolumn{1}{c|}{0.088} &
-0.303 &
0.085 \\ \hline
\multirow{8}{*}{r=0.5} &
\multirow{2}{*}{20} &
Cov (\%) &
\textbf{87.00} &
94.50 &
\multicolumn{1}{c|}{94.50} &
\textbf{89.00} &
\multicolumn{1}{c|}{\textbf{94.00}} &
89.00 &
\multicolumn{1}{c|}{94.00} &
90.00 &
93.00 \\
&
&
Var Err &
\textbf{-0.104} &
0.025 &
\multicolumn{1}{c|}{0.026} &
\textbf{-0.339} &
\multicolumn{1}{c|}{\textbf{0.003}} &
-0.283 &
\multicolumn{1}{c|}{0.009} &
-0.208 &
0.018 \\ \cline{2-12} 
&
\multirow{2}{*}{40} &
Cov (\%) &
91.00 &
96.50 &
\multicolumn{1}{c|}{96.50} &
89.50 &
\multicolumn{1}{c|}{94.00} &
85.50 &
\multicolumn{1}{c|}{95.50} &
89.00 &
94.50 \\
&
&
Var Err &
-0.074 &
0.048 &
\multicolumn{1}{c|}{0.040} &
-0.376 &
\multicolumn{1}{c|}{0.016} &
-0.343 &
\multicolumn{1}{c|}{0.022} &
-0.285 &
0.029 \\ \cline{2-12} 
&
\multirow{2}{*}{60} &
Cov (\%) &
86.50 &
94.00 &
\multicolumn{1}{c|}{94.50} &
83.50 &
\multicolumn{1}{c|}{92.50} &
85.50 &
\multicolumn{1}{c|}{93.00} &
84.50 &
94.00 \\
&
&
Var Err &
-0.061 &
0.072 &
\multicolumn{1}{c|}{0.074} &
-0.383 &
\multicolumn{1}{c|}{0.044} &
-0.361 &
\multicolumn{1}{c|}{0.029} &
-0.317 &
0.046 \\ \cline{2-12} 
&
\multirow{2}{*}{100} &
Cov (\%) &
93.50 &
100.0 &
\multicolumn{1}{c|}{100.0} &
90.00 &
\multicolumn{1}{c|}{96.00} &
89.00 &
\multicolumn{1}{c|}{95.00} &
89.50 &
97.00 \\
&
&
Var Err &
-0.083 &
$\infty$ &
\multicolumn{1}{c|}{$\infty$} &
1.156 &
\multicolumn{1}{c|}{2.659} &
-0.069 &
\multicolumn{1}{c|}{0.582} &
-0.335 &
0.067 \\ \hline
\multirow{8}{*}{r=0.6} &
\multirow{2}{*}{20} &
Cov (\%) &
92.00 &
95.00 &
\multicolumn{1}{c|}{95.50} &
88.00 &
\multicolumn{1}{c|}{93.50} &
87.50 &
\multicolumn{1}{c|}{94.00} &
91.50 &
95.00 \\
&
&
Var Err &
-0.110 &
0.024 &
\multicolumn{1}{c|}{0.031} &
-0.338 &
\multicolumn{1}{c|}{0.003} &
-0.285 &
\multicolumn{1}{c|}{0.004} &
-0.225 &
0.004 \\ \cline{2-12} 
&
\multirow{2}{*}{40} &
Cov (\%) &
89.50 &
95.00 &
\multicolumn{1}{c|}{95.00} &
88.50 &
\multicolumn{1}{c|}{94.50} &
91.50 &
\multicolumn{1}{c|}{96.00} &
92.00 &
96.50 \\
&
&
Var Err &
-0.115 &
0.048 &
\multicolumn{1}{c|}{0.043} &
-0.381 &
\multicolumn{1}{c|}{0.023} &
-0.349 &
\multicolumn{1}{c|}{0.015} &
-0.294 &
0.017 \\ \cline{2-12} 
&
\multirow{2}{*}{60} &
Cov (\%) &
\textbf{89.50} &
97.00 &
\multicolumn{1}{c|}{98.00} &
86.50 &
\multicolumn{1}{c|}{98.00} &
84.00 &
\multicolumn{1}{c|}{94.50} &
\textbf{87.50} &
\textbf{95.50} \\
&
&
Var Err &
\textbf{-0.079} &
0.073 &
\multicolumn{1}{c|}{0.062} &
-0.290 &
\multicolumn{1}{c|}{0.232} &
-0.359 &
\multicolumn{1}{c|}{0.058} &
\textbf{-0.327} &
\textbf{0.037} \\ \cline{2-12} 
&
\multirow{2}{*}{100} &
Cov (\%) &
92.50 &
100.0 &
\multicolumn{1}{c|}{100.0} &
96.50 &
\multicolumn{1}{c|}{99.00} &
97.50 &
\multicolumn{1}{c|}{98.50} &
95.00 &
99.00 \\
&
&
Var Err &
-0.036 &
$\infty$ &
\multicolumn{1}{c|}{$\infty$} &
119.0 &
\multicolumn{1}{c|}{203.4} &
127.3 &
\multicolumn{1}{c|}{232.9} &
29.02 &
49.50 \\ \hline		
\end{tabular}}
\caption{\textit{Linear regression with Toeplitz $\Sigma_a$ across $r\in\{0.4, 0.5, 0.6\}$: the empirical coverage rate of 95\% confidence intervals $(\textit{Cov})$ and the averaged relative estimation error of the variance $(\textit{Var Err})$ of $\b1^T\bx_t/d$, given by~\mbox{$\b1^T(\hat{\Xi}_t-\Xi^\star)\b1/\b1^T\Xi^\star\b1$}. We bold entries to highlight scenarios where $\hat{\Xi}_t$ performs significantly better than others.}}
\label{appen:table:1}
\end{table}


\begin{table}[!h]
\centering
\resizebox{\linewidth}{!}{
\begin{tabular}{|c|c|c|c|cccccccc|}
\hline
\multirow{3}{*}{Equi-corr $\Sigma_a$} &
\multirow{3}{*}{d} &
\multirow{3}{*}{Criterion} &
\multirow{2}{*}{SGD} &
\multicolumn{8}{c|}{Sketched Newton Method} \\ \cline{5-12} 
&
&
&
&
\multicolumn{2}{c|}{$\tau=\infty$} &
\multicolumn{2}{c|}{$\tau=10$} &
\multicolumn{2}{c|}{$\tau=20$} &
\multicolumn{2}{c|}{$\tau=40$} \\ \cline{4-12} 
&
&
&
{\footnotesize$\bar{\Xi}_t$} &
{\footnotesize$\tilde{\Xi}_t$} &
\multicolumn{1}{c|}{{\footnotesize$\hat{\Xi}_t$}} &
{\footnotesize$\tilde{\Xi}_t$} &
\multicolumn{1}{c|}{{\footnotesize$\hat{\Xi}_t$}} &
{\footnotesize$\tilde{\Xi}_t$} &
\multicolumn{1}{c|}{{\footnotesize$\hat{\Xi}_t$}} &
{\footnotesize$\tilde{\Xi}_t$} &
{\footnotesize$\hat{\Xi}_t$} \\ \hline
\multirow{8}{*}{r=0.1} &
\multirow{2}{*}{20} &
Cov (\%) &
90.50 &
92.50 &
\multicolumn{1}{c|}{93.00} &
85.50 &
\multicolumn{1}{c|}{97.00} &
87.00 &
\multicolumn{1}{c|}{93.00} &
91.50 &
94.50 \\
&
&
Var Err &
-0.101 &
0.025 &
\multicolumn{1}{c|}{0.024} &
-0.459 &
\multicolumn{1}{c|}{0.017} &
-0.355 &
\multicolumn{1}{c|}{0.017} &
-0.183 &
0.017 \\ \cline{2-12} 
&
\multirow{2}{*}{40} &
Cov (\%) &
\textbf{91.50} &
93.00 &
\multicolumn{1}{c|}{93.00} &
\textbf{80.00} &
\multicolumn{1}{c|}{\textbf{94.50}} &
85.00 &
\multicolumn{1}{c|}{97.00} &
82.00 &
94.50 \\
&
&
Var Err &
\textbf{-0.118} &
0.048 &
\multicolumn{1}{c|}{0.046} &
\textbf{-0.612} &
\multicolumn{1}{c|}{\textbf{0.027}} &
-0.565 &
\multicolumn{1}{c|}{0.034} &
-0.467 &
0.037 \\ \cline{2-12} 
&
\multirow{2}{*}{60} &
Cov (\%) &
93.50 &
94.50 &
\multicolumn{1}{c|}{92.50} &
71.00 &
\multicolumn{1}{c|}{94.00} &
75.00 &
\multicolumn{1}{c|}{95.50} &
77.00 &
93.00 \\
&
&
Var Err &
-0.059 &
0.072 &
\multicolumn{1}{c|}{0.070} &
-0.681 &
\multicolumn{1}{c|}{0.048} &
-0.655 &
\multicolumn{1}{c|}{0.046} &
-0.600 &
0.047 \\ \cline{2-12} 
&
\multirow{2}{*}{100} &
Cov (\%) &
92.50 &
100.0 &
\multicolumn{1}{c|}{100.0} &
68.00 &
\multicolumn{1}{c|}{96.50} &
64.50 &
\multicolumn{1}{c|}{93.50} &
70.50 &
98.00 \\
&
&
Var Err &
-0.062 &
$\infty$ &
\multicolumn{1}{c|}{$\infty$} &
-0.748 &
\multicolumn{1}{c|}{0.072} &
-0.737 &
\multicolumn{1}{c|}{0.070} &
-0.712 &
0.075 \\ \hline
\multirow{8}{*}{r=0.2} &
\multirow{2}{*}{20} &
Cov (\%) &
92.00 &
93.00 &
\multicolumn{1}{c|}{92.50} &
79.00 &
\multicolumn{1}{c|}{94.00} &
83.00 &
\multicolumn{1}{c|}{94.00} &
91.50 &
95.50 \\
&
&
Var Err &
-0.063 &
0.024 &
\multicolumn{1}{c|}{0.023} &
-0.538 &
\multicolumn{1}{c|}{0.013} &
-0.468 &
\multicolumn{1}{c|}{0.016} &
-0.334 &
0.012 \\ \cline{2-12} 
&
\multirow{2}{*}{40} &
Cov (\%) &
90.50 &
95.50 &
\multicolumn{1}{c|}{94.50} &
75.00 &
\multicolumn{1}{c|}{96.50} &
82.50 &
\multicolumn{1}{c|}{96.50} &
80.50 &
94.50 \\
&
&
Var Err &
-0.139 &
0.048 &
\multicolumn{1}{c|}{0.040} &
-0.654 &
\multicolumn{1}{c|}{0.022} &
-0.630 &
\multicolumn{1}{c|}{0.018} &
-0.580 &
0.024 \\ \cline{2-12} 
&
\multirow{2}{*}{60} &
Cov (\%) &
91.00 &
95.50 &
\multicolumn{1}{c|}{95.50} &
72.00 &
\multicolumn{1}{c|}{91.50} &
68.00 &
\multicolumn{1}{c|}{94.50} &
81.50 &
96.50 \\
&
&
Var Err &
-0.015 &
0.072 &
\multicolumn{1}{c|}{0.067} &
-0.697 &
\multicolumn{1}{c|}{0.019} &
-0.685 &
\multicolumn{1}{c|}{0.027} &
-0.660 &
0.029 \\ \cline{2-12} 
&
\multirow{2}{*}{100} &
Cov (\%) &
93.50 &
100.0 &
\multicolumn{1}{c|}{100.0} &
69.50 &
\multicolumn{1}{c|}{96.50} &
68.00 &
\multicolumn{1}{c|}{97.50} &
73.00 &
97.50 \\
&
&
Var Err &
-0.022 &
$\infty$ &
\multicolumn{1}{c|}{$\infty$} &
-0.732 &
\multicolumn{1}{c|}{0.030} &
-0.727 &
\multicolumn{1}{c|}{0.028} &
-0.718 &
0.035 \\ \hline
\multirow{8}{*}{r=0.3} &
\multirow{2}{*}{20} &
Cov (\%) &
94.00 &
95.00 &
\multicolumn{1}{c|}{96.50} &
83.50 &
\multicolumn{1}{c|}{98.50} &
85.50 &
\multicolumn{1}{c|}{93.50} &
89.50 &
94.00 \\
&
&
Var Err &
-0.057 &
0.025 &
\multicolumn{1}{c|}{0.026} &
-0.543 &
\multicolumn{1}{c|}{0.010} &
-0.504 &
\multicolumn{1}{c|}{0.010} &
-0.424 &
0.008 \\ \cline{2-12} 
&
\multirow{2}{*}{40} &
Cov (\%) &
\textbf{90.50} &
97.50 &
\multicolumn{1}{c|}{97.50} &
\textbf{73.00} &
\multicolumn{1}{c|}{\textbf{94.50}} &
76.00 &
\multicolumn{1}{c|}{96.50} &
85.50 &
95.50 \\
&
&
Var Err &
\textbf{-0.106} &
0.048 &
\multicolumn{1}{c|}{0.048} &
\textbf{-0.617} &
\multicolumn{1}{c|}{\textbf{0.014}} &
-0.605 &
\multicolumn{1}{c|}{0.017} &
-0.581 &
0.007 \\ \cline{2-12} 
&
\multirow{2}{*}{60} &
Cov (\%) &
92.50 &
96.00 &
\multicolumn{1}{c|}{95.50} &
73.00 &
\multicolumn{1}{c|}{93.00} &
72.00 &
\multicolumn{1}{c|}{94.00} &
72.50 &
94.00 \\
&
&
Var Err &
-0.035 &
0.073 &
\multicolumn{1}{c|}{0.065} &
-0.643 &
\multicolumn{1}{c|}{0.010} &
-0.637 &
\multicolumn{1}{c|}{0.013} &
-0.625 &
0.005 \\ \cline{2-12} 
&
\multirow{2}{*}{100} &
Cov (\%) &
91.00 &
100.0 &
\multicolumn{1}{c|}{100.0} &
78.00 &
\multicolumn{1}{c|}{97.00} &
72.50 &
\multicolumn{1}{c|}{95.00} &
73.50 &
94.50 \\
&
&
Var Err &
0.002 &
$\infty$ &
\multicolumn{1}{c|}{$\infty$} &
-0.416 &
\multicolumn{1}{c|}{0.805} &
-0.658 &
\multicolumn{1}{c|}{0.018} &
-0.656 &
0.014 \\ \hline		
\end{tabular}}
\caption{\textit{Linear regression with Equi-correlation $\Sigma_a$ across $r\in\{0.1, 0.2, 0.3\}$. See Table \ref{appen:table:1} for interpretation.}}
\label{appen:table:2}
\end{table}


\begin{table}[!h]
\centering
\resizebox{\linewidth}{!}{
\begin{tabular}{|c|c|c|c|cccccccc|}
\hline
\multirow{3}{*}{Toeplitz $\Sigma_a$} &
\multirow{3}{*}{d} &
\multirow{3}{*}{Criterion} &
\multirow{2}{*}{SGD} &
\multicolumn{8}{c|}{Sketched Newton Method} \\ \cline{5-12} 
&
&
&
&
\multicolumn{2}{c|}{$\tau=\infty$} &
\multicolumn{2}{c|}{$\tau=10$} &
\multicolumn{2}{c|}{$\tau=20$} &
\multicolumn{2}{c|}{$\tau=40$} \\ \cline{4-12} 
&
&
&
{\footnotesize$\bar{\Xi}_t$} &
{\footnotesize$\tilde{\Xi}_t$} &
\multicolumn{1}{c|}{{\footnotesize$\hat{\Xi}_t$}} &
{\footnotesize$\tilde{\Xi}_t$} &
\multicolumn{1}{c|}{{\footnotesize$\hat{\Xi}_t$}} &
{\footnotesize$\tilde{\Xi}_t$} &
\multicolumn{1}{c|}{{\footnotesize$\hat{\Xi}_t$}} &
{\footnotesize$\tilde{\Xi}_t$} &
{\footnotesize$\hat{\Xi}_t$} \\ \hline
\multirow{8}{*}{r=0.4} &
\multirow{2}{*}{20} &
Cov (\%) &
87.50 &
94.50 &
\multicolumn{1}{c|}{94.50} &
93.50 &
\multicolumn{1}{c|}{97.50} &
92.00 &
\multicolumn{1}{c|}{96.00} &
92.50 &
95.00 \\
&
&
Var Err &
-0.226 &
0.040 &
\multicolumn{1}{c|}{0.035} &
-0.197 &
\multicolumn{1}{c|}{0.026} &
-0.159 &
\multicolumn{1}{c|}{0.032} &
-0.079 &
0.033 \\ \cline{2-12} 
&
\multirow{2}{*}{40} &
Cov (\%) &
85.00 &
96.00 &
\multicolumn{1}{c|}{96.00} &
94.50 &
\multicolumn{1}{c|}{96.00} &
88.00 &
\multicolumn{1}{c|}{93.00} &
91.50 &
94.50 \\
&
&
Var Err &
-0.227 &
0.085 &
\multicolumn{1}{c|}{0.074} &
-0.190 &
\multicolumn{1}{c|}{0.077} &
-0.180 &
\multicolumn{1}{c|}{0.079} &
-0.141 &
0.073 \\ \cline{2-12} 
&
\multirow{2}{*}{60} &
Cov (\%) &
\textbf{86.00} &
93.50 &
\multicolumn{1}{c|}{93.00} &
\textbf{93.00} &
\multicolumn{1}{c|}{\textbf{96.50}} &
93.00 &
\multicolumn{1}{c|}{96.50} &
93.00 &
96.00 \\
&
&
Var Err &
\textbf{-0.249} &
0.130 &
\multicolumn{1}{c|}{0.122} &
\textbf{-0.164} &
\multicolumn{1}{c|}{\textbf{0.102}} &
-0.163 &
\multicolumn{1}{c|}{0.100} &
-0.140 &
0.113 \\ \cline{2-12} 
&
\multirow{2}{*}{100} &
Cov (\%) &
87.50 &
94.50 &
\multicolumn{1}{c|}{94.50} &
87.50 &
\multicolumn{1}{c|}{92.00} &
92.50 &
\multicolumn{1}{c|}{95.00} &
95.50 &
98.00 \\
&
&
Var Err &
-0.138 &
0.232 &
\multicolumn{1}{c|}{0.220} &
-0.093 &
\multicolumn{1}{c|}{0.184} &
-0.098 &
\multicolumn{1}{c|}{0.192} &
-0.093 &
0.190 \\ \hline
\multirow{8}{*}{r=0.5} &
\multirow{2}{*}{20} &
Cov (\%) &
88.00 &
98.50 &
\multicolumn{1}{c|}{98.00} &
93.50 &
\multicolumn{1}{c|}{96.00} &
94.00 &
\multicolumn{1}{c|}{95.50} &
93.50 &
94.50 \\
&
&
Var Err &
-0.199 &
0.038 &
\multicolumn{1}{c|}{0.032} &
-0.226 &
\multicolumn{1}{c|}{0.028} &
-0.179 &
\multicolumn{1}{c|}{0.028} &
-0.097 &
0.020 \\ \cline{2-12} 
&
\multirow{2}{*}{40} &
Cov (\%) &
85.50 &
96.00 &
\multicolumn{1}{c|}{96.50} &
91.50 &
\multicolumn{1}{c|}{95.00} &
90.00 &
\multicolumn{1}{c|}{93.50} &
95.00 &
97.50 \\
&
&
Var Err &
-0.190 &
0.079 &
\multicolumn{1}{c|}{0.077} &
-0.233 &
\multicolumn{1}{c|}{0.063} &
-0.217 &
\multicolumn{1}{c|}{0.066} &
-0.160 &
0.064 \\ \cline{2-12} 
&
\multirow{2}{*}{60} &
Cov (\%) &
92.00 &
95.50 &
\multicolumn{1}{c|}{94.50} &
\textbf{92.00} &
\multicolumn{1}{c|}{\textbf{94.50}} &
89.50 &
\multicolumn{1}{c|}{94.00} &
92.50 &
97.00 \\
&
&
Var Err &
-0.170 &
0.122 &
\multicolumn{1}{c|}{0.115} &
\textbf{-0.215} &
\multicolumn{1}{c|}{\textbf{0.081}} &
-0.208 &
\multicolumn{1}{c|}{0.100} &
-0.174 &
0.094 \\ \cline{2-12} 
&
\multirow{2}{*}{100} &
Cov (\%) &
87.50 &
97.00 &
\multicolumn{1}{c|}{96.00} &
90.50 &
\multicolumn{1}{c|}{93.50} &
92.00 &
\multicolumn{1}{c|}{96.50} &
90.00 &
93.50 \\
&
&
Var Err &
-0.159 &
0.221 &
\multicolumn{1}{c|}{0.215} &
-0.158 &
\multicolumn{1}{c|}{0.163} &
-0.161 &
\multicolumn{1}{c|}{0.166} &
-0.146 &
0.164 \\ \hline
\multirow{8}{*}{r=0.6} &
\multirow{2}{*}{20} &
Cov (\%) &
86.00 &
91.00 &
\multicolumn{1}{c|}{90.50} &
91.00 &
\multicolumn{1}{c|}{94.50} &
93.00 &
\multicolumn{1}{c|}{94.50} &
92.50 &
94.00 \\
&
&
Var Err &
-0.188 &
0.036 &
\multicolumn{1}{c|}{0.023} &
-0.241 &
\multicolumn{1}{c|}{0.032} &
-0.185 &
\multicolumn{1}{c|}{0.031} &
-0.113 &
0.028 \\ \cline{2-12} 
&
\multirow{2}{*}{40} &
Cov (\%) &
84.50 &
95.50 &
\multicolumn{1}{c|}{95.00} &
88.00 &
\multicolumn{1}{c|}{94.50} &
87.50 &
\multicolumn{1}{c|}{96.00} &
91.00 &
94.50 \\
&
&
Var Err &
-0.203 &
0.069 &
\multicolumn{1}{c|}{0.062} &
-0.266 &
\multicolumn{1}{c|}{0.065} &
-0.236 &
\multicolumn{1}{c|}{0.064} &
-0.176 &
0.051 \\ \cline{2-12} 
&
\multirow{2}{*}{60} &
Cov (\%) &
86.00 &
94.50 &
\multicolumn{1}{c|}{95.00} &
\textbf{90.50} &
\multicolumn{1}{c|}{\textbf{94.50}} &
91.00 &
\multicolumn{1}{c|}{93.50} &
93.00 &
98.00 \\
&
&
Var Err &
-0.108 &
0.115 &
\multicolumn{1}{c|}{0.104} &
\textbf{-0.257} &
\multicolumn{1}{c|}{\textbf{0.088}} &
-0.242 &
\multicolumn{1}{c|}{0.083} &
-0.200 &
0.091 \\ \cline{2-12} 
&
\multirow{2}{*}{100} &
Cov (\%) &
86.50 &
95.00 &
\multicolumn{1}{c|}{94.50} &
90.00 &
\multicolumn{1}{c|}{96.00} &
89.00 &
\multicolumn{1}{c|}{94.00} &
92.00 &
95.00 \\
&
&
Var Err &
-0.119 &
0.202 &
\multicolumn{1}{c|}{0.184} &
-0.219 &
\multicolumn{1}{c|}{0.163} &
-0.213 &
\multicolumn{1}{c|}{0.149} &
-0.189 &
0.153 \\ \hline		
\end{tabular}}
\caption{\textit{Logistic regression with Toeplitz $\Sigma_a$ across $r\in\{0.4, 0.5, 0.6\}$. See Table \ref{appen:table:1} for interpretation.}}
\label{appen:table:3}
\end{table}




\begin{table}[!h]
\centering
\resizebox{\linewidth}{!}{
\begin{tabular}{|c|c|c|c|cccccccc|}
\hline
\multirow{3}{*}{Equi-corr $\Sigma_a$} &
\multirow{3}{*}{d} &
\multirow{3}{*}{Criterion} &
\multirow{2}{*}{SGD} &
\multicolumn{8}{c|}{Sketched Newton Method} \\ \cline{5-12} 
&
&
&
&
\multicolumn{2}{c|}{$\tau=\infty$} &
\multicolumn{2}{c|}{$\tau=10$} &
\multicolumn{2}{c|}{$\tau=20$} &
\multicolumn{2}{c|}{$\tau=40$} \\ \cline{4-12} 
&
&
&
{\footnotesize$\bar{\Xi}_t$} &
{\footnotesize$\tilde{\Xi}_t$} &
\multicolumn{1}{c|}{{\footnotesize$\hat{\Xi}_t$}} &
{\footnotesize$\tilde{\Xi}_t$} &
\multicolumn{1}{c|}{{\footnotesize$\hat{\Xi}_t$}} &
{\footnotesize$\tilde{\Xi}_t$} &
\multicolumn{1}{c|}{{\footnotesize$\hat{\Xi}_t$}} &
{\footnotesize$\tilde{\Xi}_t$} &
{\footnotesize$\hat{\Xi}_t$} \\ \hline
\multirow{8}{*}{r=0.1} &
\multirow{2}{*}{20} &
Cov (\%) &
89.50 &
94.50 &
\multicolumn{1}{c|}{95.00} &
91.50 &
\multicolumn{1}{c|}{96.00} &
89.00 &
\multicolumn{1}{c|}{93.00} &
94.50 &
96.00 \\
&
&
Var Err &
-0.185 &
0.043 &
\multicolumn{1}{c|}{0.045} &
-0.324 &
\multicolumn{1}{c|}{0.041} &
-0.230 &
\multicolumn{1}{c|}{0.039} &
-0.088 &
0.032 \\ \cline{2-12} 
&
\multirow{2}{*}{40} &
Cov (\%) &
90.00 &
96.50 &
\multicolumn{1}{c|}{95.50} &
82.50 &
\multicolumn{1}{c|}{96.00} &
87.50 &
\multicolumn{1}{c|}{94.50} &
88.00 &
94.00 \\
&
&
Var Err &
-0.171 &
0.094 &
\multicolumn{1}{c|}{0.086} &
-0.458 &
\multicolumn{1}{c|}{0.073} &
-0.399 &
\multicolumn{1}{c|}{0.065} &
-0.288 &
0.069 \\ \cline{2-12} 
&
\multirow{2}{*}{60} &
Cov (\%) &
89.00 &
97.00 &
\multicolumn{1}{c|}{97.00} &
72.00 &
\multicolumn{1}{c|}{92.50} &
83.00 &
\multicolumn{1}{c|}{94.50} &
88.50 &
95.50 \\
&
&
Var Err &
-0.115 &
0.152 &
\multicolumn{1}{c|}{0.146} &
-0.527 &
\multicolumn{1}{c|}{0.106} &
-0.485 &
\multicolumn{1}{c|}{0.107} &
-0.411 &
0.108 \\ \cline{2-12} 
&
\multirow{2}{*}{100} &
Cov (\%) &
\textbf{79.00} &
98.00 &
\multicolumn{1}{c|}{98.00} &
78.00 &
\multicolumn{1}{c|}{92.50} &
\textbf{77.00} &
\multicolumn{1}{c|}{\textbf{96.00}} &
\textbf{82.00} &
\textbf{96.00} \\
&
&
Var Err &
\textbf{-0.161} &
0.262 &
\multicolumn{1}{c|}{0.251} &
-0.595 &
\multicolumn{1}{c|}{0.182} &
\textbf{-0.575} &
\multicolumn{1}{c|}{\textbf{0.177}} &
\textbf{-0.533} &
\textbf{0.177} \\ \hline
\multirow{8}{*}{r=0.2} &
\multirow{2}{*}{20} &
Cov (\%) &
90.00 &
96.00 &
\multicolumn{1}{c|}{96.00} &
88.50 &
\multicolumn{1}{c|}{96.50} &
89.00 &
\multicolumn{1}{c|}{96.50} &
92.50 &
96.00 \\
&
&
Var Err &
-0.172 &
0.041 &
\multicolumn{1}{c|}{0.037} &
-0.394 &
\multicolumn{1}{c|}{0.028} &
-0.302 &
\multicolumn{1}{c|}{0.037} &
-0.153 &
0.039 \\ \cline{2-12} 
&
\multirow{2}{*}{40} &
Cov (\%) &
86.00 &
95.00 &
\multicolumn{1}{c|}{95.00} &
78.00 &
\multicolumn{1}{c|}{95.00} &
81.00 &
\multicolumn{1}{c|}{94.50} &
88.00 &
96.50 \\
&
&
Var Err &
-0.111 &
0.083 &
\multicolumn{1}{c|}{0.084} &
-0.530 &
\multicolumn{1}{c|}{0.062} &
-0.490 &
\multicolumn{1}{c|}{0.046} &
-0.402 &
0.050 \\ \cline{2-12} 
&
\multirow{2}{*}{60} &
Cov (\%) &
80.00 &
94.00 &
\multicolumn{1}{c|}{93.50} &
78.50 &
\multicolumn{1}{c|}{94.00} &
80.00 &
\multicolumn{1}{c|}{97.00} &
82.50 &
96.00 \\
&
&
Var Err &
-0.144 &
0.130 &
\multicolumn{1}{c|}{0.110} &
-0.592 &
\multicolumn{1}{c|}{0.076} &
-0.569 &
\multicolumn{1}{c|}{0.068} &
-0.518 &
0.072 \\ \cline{2-12} 
&
\multirow{2}{*}{100} &
Cov (\%) &
\textbf{66.50} &
97.50 &
\multicolumn{1}{c|}{96.00} &
73.50 &
\multicolumn{1}{c|}{96.00} &
\textbf{73.00} &
\multicolumn{1}{c|}{\textbf{96.00}} &
\textbf{80.00} &
\textbf{97.00} \\
&
&
Var Err &
\textbf{-0.108} &
0.234 &
\multicolumn{1}{c|}{0.227} &
-0.647 &
\multicolumn{1}{c|}{0.116} &
\textbf{-0.636} &
\multicolumn{1}{c|}{\textbf{0.115}} &
\textbf{-0.615} &
\textbf{0.109} \\ \hline
\multirow{8}{*}{r=0.3} &
\multirow{2}{*}{20} &
Cov (\%) &
86.00 &
93.50 &
\multicolumn{1}{c|}{93.50} &
83.00 &
\multicolumn{1}{c|}{94.00} &
85.50 &
\multicolumn{1}{c|}{92.00} &
89.50 &
95.50 \\
&
&
Var Err &
-0.139 &
0.038 &
\multicolumn{1}{c|}{0.024} &
-0.422 &
\multicolumn{1}{c|}{0.027} &
-0.347 &
\multicolumn{1}{c|}{0.011} &
-0.220 &
0.028 \\ \cline{2-12} 
&
\multirow{2}{*}{40} &
Cov (\%) &
81.00 &
93.50 &
\multicolumn{1}{c|}{93.50} &
80.50 &
\multicolumn{1}{c|}{96.50} &
85.50 &
\multicolumn{1}{c|}{95.00} &
79.50 &
95.50 \\
&
&
Var Err &
-0.124 &
0.078 &
\multicolumn{1}{c|}{0.071} &
-0.536 &
\multicolumn{1}{c|}{0.045} &
-0.510 &
\multicolumn{1}{c|}{0.026} &
-0.450 &
0.044 \\ \cline{2-12} 
&
\multirow{2}{*}{60} &
Cov (\%) &
74.00 &
92.00 &
\multicolumn{1}{c|}{91.50} &
82.00 &
\multicolumn{1}{c|}{94.50} &
76.00 &
\multicolumn{1}{c|}{93.50} &
82.50 &
95.00 \\
&
&
Var Err &
-0.137 &
0.111 &
\multicolumn{1}{c|}{0.096} &
-0.584 &
\multicolumn{1}{c|}{0.051} &
-0.567 &
\multicolumn{1}{c|}{0.055} &
-0.539 &
0.046 \\ \cline{2-12} 
&
\multirow{2}{*}{100} &
Cov (\%) &
\textbf{54.00} &
97.00 &
\multicolumn{1}{c|}{96.50} &
78.50 &
\multicolumn{1}{c|}{96.00} &
\textbf{68.50} &
\multicolumn{1}{c|}{\textbf{94.00}} &
\textbf{76.50} &
\textbf{94.50} \\
&
&
Var Err &
\textbf{-0.115} &
0.203 &
\multicolumn{1}{c|}{0.185} &
-0.621 &
\multicolumn{1}{c|}{0.067} &
\textbf{-0.619} &
\multicolumn{1}{c|}{\textbf{0.064}} &
\textbf{-0.604} &
\textbf{0.069} \\ \hline		
\end{tabular}}
\caption{\textit{Logistic regression with Equi-correlation $\Sigma_a$ across $r\in\{0.1, 0.2, 0.3\}$. See Table \ref{appen:table:1} for interpretation.}}
\label{appen:table:4}
\end{table}



