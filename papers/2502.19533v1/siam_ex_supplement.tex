% SIAM Supplemental File Template
\documentclass[final,supplement,hidelinks,onefignum,onetabnum]{siamart250211}

\input{siam_ex_shared}

\externaldocument{siam_ex_article}

% Optional PDF information
%\ifpdf
%\hypersetup{pdftitle={Supplementary Materials: An Example Article},pdfauthor={D. Doe, P. T. Frank, and J. E. Smith}}
%\fi

\begin{document}

\maketitle

\section{Proof of Proposition~2.2}\label{appen-proof2.2}
\begin{proof}
We will use the following ansatz of former expansion: $g_\eps :=g_0 + \eps g_1 + \eps^2 g_2 + ...$ into~(2.15) and equate the terms with like orders in $\varepsilon$, we have 
\begin{align*}
O(\eps^{-2}):\quad \mathcal{L}_0[g_0]  =\dfrac{\l g_0/\tau\r_{\mu,\omega}}{\l g^*/\tau\r_{\mu, \omega}} g^*(\omega) - g_0 = 0\,.
\end{align*}
This suggests that $g_0$ has no $\mu$-dependence, and behaves as equilibrium on $\omega$, i.e. 
\begin{equation}\label{eqn: g0-u}
g_0(t,x,\mu, \omega) = g^*(\omega)u(t,x)\,,
\end{equation}
where $u(t,x)$ is some function of $t, x$ to be specified later. 
\begin{align*}
O(\eps^{-1}): \quad \mu v(\omega) \p_x g_0 = \dfrac{1}{\tau(\omega)} \mathcal{L}_0[g_1]\,.
\end{align*}
Similar to property (5) of $\mathcal L$ in Proposition~2.2, we can find a unique inverse of $\mathcal{L}_0^{-1}$ in the space of $\left(\text{Ker}\mathcal{L}_0\right)^\perp$, making:
\begin{equation}\label{eqn: g1-u}
g_1(t,x,\mu,\omega) = -\mu v(\omega) \tau(\omega) \p_x g_0 =  -\mu v(\omega) \tau(\omega) g^*(\omega) \p_x u \,.
\end{equation}
At last, 
\begin{align*}
O(\eps^{0}): \quad \partial_t g_0 + \mu v(\omega) \p_x g_1 = \dfrac{1}{\tau(\omega)} \mathcal{L}_0 [g_2]\,.
\end{align*}
Using the conservation of $\mathcal L$ (see property (2) in Proposition~2.2), we have:
\begin{equation*}
\average{ \partial_t g_0 + \mu v(\omega) \p_x g_1 }_{\mu,\omega} = \average{ \dfrac{1}{\tau(\omega)}\mathcal{L}_0 [g_2]}_{\mu,\omega} = 0\,.
\end{equation*}
Substituting $g_0$ and $g_1$  expressed in $u(t,x)$ \eqref{eqn: g0-u} \eqref{eqn: g1-u} into the above equation, it becomes
\begin{equation*}
\begin{aligned}
\l \partial_t g_0 + \mu v(\omega) \p_x g_1 \r_{\mu,\omega} & = 
\average{ (\partial_t u) g^* - \mu^2 v^2 \tau g^*\p_x (\p_x u) }_{\mu,\omega}\,, \\
& = \partial_t u \l g^* \r_{\mu,\omega} - \int_\mu \mu^2 d\mu \int_0^\infty \tau v^2 g^* (\p_x^2 u) d\omega\,, \\
& = \l g^* \r_{\mu, \omega} \partial_t u - \frac{1}{3}\l \tau v^2 g^* \r_{\mu,\omega} (\p_x^2 u) = 0\,.
\end{aligned}
\end{equation*}
recovering~(2.16).

To show~(2.17), we note that 
\[
g_\varepsilon \approx g_0 + \varepsilon g_1 = g^*(\omega) u(t,x) - \eps \mu v(\omega) \tau(\omega) g^*(\omega) \p_x u\,,
\]
and thus by the definition of heat flux~(2.7) and temperature~(2.8), we have 
\begin{align*}
q_\eps(t,x) &:= \frac{1}{\eps} \average{\mu v(\omega)g_\eps}_{\mu,\omega} = - \frac{1}{3}\average{v^2 \tau g^*}_\omega \p_x u + O(\eps)\,,\\
T_\eps(t,x) &:= \frac{\average{g_\eps/\tau}_{\mu,\omega}}{\average{g^*/\tau}_{\mu,\omega}} = u(t,x)+ O(\eps)\,.
\end{align*}
Passing the limit $\eps\to 0$ formally, by definition of conductivity~(2.9), we recover:
\begin{align}\label{eqn: heat-con2}
\lim_{\eps\to0}\kappa_\eps := - \lim_{\eps\to0}\frac{q_\eps}{\p_x T_\eps} = \frac{1}{3}\average{v^2 \tau g^*}_\omega \,,
\end{align}
finishing the proof of~(2.7).
% Here, the limit is a constant, which represents the bulk heat conductivity in the diffusive regime~\eqref{eqn: heat-con}.
% Therefore, $u(t,x)$ solves
% \begin{equation*}
% \partial_t u - \frac{\kappa}{\average{g^*}_{\omega}} \p^2_x u = 0\,,
% \end{equation*}
% where $\kappa$ is defined in~\eqref{heat}
\end{proof}

\section{Convergence of SGD}\label{sec: SGD convergence}
In this subsection we expand our discussion about the convergence of SGD algorithms (Theorem~4.1). Recall that our loss function is in the form of:
\[F[\tau] = \sum_{i=1}^N f_i[\tau]\,,\]
where each $f_i$ is corresponding to different source-test function pair: $\{\phi_i, \psi_i\}.$
And at each step, only one gradient is computed: $\nabla f_{\xi_k}[\tau^k]$, with $\xi_k \sim \text{Unif}\{1,...,N\}$.
\begin{theorem}
(Adpated from~\cite{JZZ-SGD-2020}) Under the following two assumptions:
\begin{itemize}
\item Lipschitz objective gradients. There exists some $L>0$ such that for any $\tau, \hat{\tau}$ that are bounded from above and below:
\begin{align}
\|\nabla F[\tau] - \nabla F[\hat{\tau}]\|_2 \leq L\|\tau - \hat{\tau}\|_2\,.
\end{align}
\item First and second moment limits. There exist $\mu_G \geq \mu>0, M\geq 0$ and $M_V \geq 0$ such that for all $k\in \mathbb{N}$,
\begin{align}
\nabla F[\tau^k]^T \mathbb{E}_{\xi_k}[\nabla F[\tau^k]] \geq \mu \|\nabla F[\tau^k]\|_2^2\,, \label{eqn: SGD-cond-1}\\
\mathbb{E}_{\xi_k}[\nabla F[\tau^k]] \leq \mu_G \|\nabla F[\tau^k]\|_2\,,\label{eqn: SGD-cond-2}\\
\mathbb{V}_{\xi_k}[\nabla f_{\xi_k}[\tau^k]] \leq M + M_V \|\nabla F[\tau^k]\|_2^2\,.\label{eqn: SGD-cond-3}
\end{align}
\end{itemize}
Then with a properly tuned sequence of step-size, SGD algorithm converges, i.e.
\[ \liminf_k \,\mathbb{E}[\|\nabla F[\tau]\|_2^2] = 0 \,. \]
\end{theorem}

To verify assumption~\eqref{eqn: SGD-cond-1}, we only need to prove for any $i: \{\phi_i, \psi_i\}$, $\nabla f_i[\tau]$ is Lipschitz continuous. Below the sub-index $i$ is dropped for simplicity.
\begin{lemma} Under some boundedness assumptions, at fixed $\tau$ and for small perturbation $\tilde \tau$, the Fr\'echet derivative $\nabla f[\tau]$ (or equivalently, $\frac{\delta L}{\delta\tau}$ in~(4.12)) is Lipschitz, i.e. there exists some $C>0$ such that 
\begin{equation}\label{eqn: df-Lipschitz}\|\nabla f[\tau + \tilde \tau] - \nabla f[\tau]\|_2 \leq C\|\tilde \tau\|_2\,.\end{equation}
\end{lemma}
\begin{proof}
Suppose both $\tau$ and $g^*$ are both lower and upper bounded in the domain of $\omega$ of our concern: 
\[0<c_1<\tau<c_2\,, 0< c_3< g^*<c_4\,,\]
We will prove that the perturbation of gradient $\nabla f[\tau]$ induced by $\tilde \tau$ is bounded. Recall the gradient formula~(4.12):
\begin{align*}
\nabla f[\tau] = & \dfrac{l}{\average{h^*}_\omega^2} \dfrac{h^*}{\tau} \langle h \psi\rangle_{t,x=0, \mu,\omega} + \dfrac{1}{\tau} \average{p \dfrac{\langle h \rangle_{\mu,\omega}}{\langle h^* \rangle_{\omega}}}_{t, x, \mu} - \dfrac{h^*}{\tau} \dfrac{1}{\langle h^* \rangle_{\omega}^2} \langle \langle h \rangle_{\mu,\omega}\langle p \rangle_{\mu,\omega}\rangle_{t, x}\\
& + \frac{1}{g^*}\langle \mathcal{L}[h]p\rangle_{t,x,\mu}
+ \frac{1}{g^*}\langle \phi \mu v p\rangle_{t,x=0,\mu>0} - \frac{1}{\tau^2\langle h^*\rangle_\omega}\langle \phi \psi\rangle_{t,\mu>0}\,,
\end{align*}
from which we can write out the expression of $\nabla f[\tau+\tilde{\tau}] - \nabla f[\tau]$.
Upon linear approximation, the perturbation can be written into
\begin{align*}
\nabla f[\tau+\tilde{\tau}] - \nabla f[\tau] & = L_1[\tilde{\tau}] + L_2[\tilde{h}] + L_3[\tilde{p}]\,,
\end{align*}
where $L_1$ is a linear function of $\tilde{\tau}$ and involves the unperturbed $\{h, p, h^*, \tau, \phi, \psi\}$, similarly for $L_2$ and $L_3$. Here $\tilde{h}$ is the perturbation to the forward solution and solves~(4.13). We will denote the source term in~(4.13) as 
\begin{equation}\label{eqn: source-Sh}
S_h[\tilde \tau](t,x,\mu,\omega):= - \dfrac{\tilde \tau}{\tau}\mathcal{L}[h] +\dfrac{\average{h}_{\mu,\omega}}{\average{h^*}_{\omega}} \left(-\dfrac{\tilde \tau}{\tau} h^* + \dfrac{\average{h^* \tilde{\tau}/\tau}_\omega}{\average{h^*}_\omega}h^*\right)\,,\end{equation}
then $\tilde h$ solves:
\begin{equation}\label{eqn: perturb-2}
\partial_t \tilde{h} + \mu v \partial_x \tilde{h} = \dfrac{1}{\tau}\mathcal{L}[\tilde{h}] +  \dfrac{1}{\tau} S_h[\tilde \tau]\,.
\end{equation}
Likewise, $\tilde{p}$ is the perturbation to the adjoint solution~(4.11) and solves the following system:
\begin{align}\label{eqn: adjoint-perturb}\left\{\begin{array}{ll}
\partial_t \tilde{p} + \mu v \partial_x \tilde{p} = - \dfrac{1}{\tau} \mathcal{L}[\tilde{p}] - \dfrac{1}{\tau} S_p[\tilde \tau]\,, & 0<x<1\\[3mm]
\tilde{p}(t=T,x,\mu,\omega) = 0\,, & \mu<0\\[3mm]
\tilde{p}(t,x=0,\mu,\omega) = \dfrac{\psi}{\mu v}\left(\tilde l\dfrac{h^*}{\average{h^*}_\omega} - \dfrac{\tilde{\tau}}{\tau}h^* l + \dfrac{(h^*)^2 \tilde{\tau}}{\average{h^*}_\omega^2 \tau}l\right) \,, & \mu<0\\[3mm]
\tilde{p}(t,x=1,-\mu,\omega) = \tilde{p}(t,x=1,\mu,\omega)\,, & \mu<0
\end{array}\right.\end{align}

Using the maximal principle proved in~\cite{GambaLiNair} that
\[\|h\|_\infty \leq C\|\phi\|_\infty\,, \|p\|_\infty \leq C \|\psi\|_\infty\,,\]
it is easy to check that $L_1$ is Lipschitz continuous with respect to $\tilde \tau$:
\[\|L_1[\tilde{\tau}]\|_2 \leq C \|\tilde{\tau}\|_2\,.\]
And the constant $C = C(\|\phi\|_{\infty}, \|\psi\|_{\infty}, c_1, c_2, c_3, c_4)$.

Then we will prove Lipschitz continuity of $\tilde h$ with respect to $\tilde \tau$. As $L_2$ is linearly dependent in $\tilde h$, it is then Lipschitz contibuous in $\tilde \tau$. Firstly we note that $S_h$~\eqref{eqn: source-Sh} is Lipschitz with respect to $\tilde \tau$ by Cauchy-Schwatz inequality:
\[\|S_h[\tilde \tau]\|_2 \leq C\|\tilde \tau\|_2 \,,\]
where the constant $C = C(\|\phi\|_\infty, c_1, c_2, c_3, c_4).$ 

In addition, we multiply $L[\tilde h]$ by $\frac{\tilde{h}}{h^*}$ to attain the following inequality: 
\begin{align*}
\average{\mathcal{L}[\tilde h] \frac{\tilde{h}}{h^*}}_{x,\mu,\omega}
& = \frac{1}{\average{h^*}_\omega}\average{\average{\tilde h}_{\mu,\omega}^2}_{x} - \average{\frac{\tilde{h}^2}{h^*}}_{x,\mu,\omega}\,,\\
& \leq \frac{1}{\average{h^*}_\omega} \average{\frac{\tilde{h}^2}{h^*}}_{x,\mu,\omega} \average{h^*}_{x,\mu,\omega} - \average{\frac{\tilde{h}^2}{h^*}}_{x,\mu,\omega} \leq 0\,,
\end{align*}
the last line is because of Cauchy-Schwatz inequality and 
\[\langle 1\rangle_{x,\mu} = \int_0^1 \int_{-1}^1 1 \,dxd\mu = 1\,.\]

Then equation~\eqref{eqn: perturb-2} is multiplied by $\frac{\tau \tilde h}{h^*}$ and taken the average of $\average{\cdot}_{x,\mu,\omega}$ on both sides, by the above inequality we have:
\begin{align*}
\average{\frac{\tau}{h^*} \frac{1}{2} \partial_t \tilde{h}^2}_{x,\mu,\omega} + \average{\frac{\mu v \tau}{h^*} \frac{1}{2} \partial_x \tilde{h}^2}_{x,\mu,\omega} & = \average{\mathcal{L}[\tilde h] \frac{\tilde{h}}{h^*}}_{x,\mu,\omega} + \average{S_h[\tilde \tau] \frac{\tilde{h}}{h^*} }_{x,\mu,\omega}\,,\\
C\partial_t \average{\tilde{h}^2}_{x,\mu,\omega} + \average{\frac{\mu v \tau}{h^*} \partial_x \tilde{h}^2}_{x,\mu,\omega} & \leq 2\average{S_h[\tilde \tau] \frac{\tilde{h}}{h^*}}_{x,\mu,\omega} \,,
\end{align*}
here $C = C(c_1, c_4)>0.$ By integrating in $x$, the second term at LHS can be written out,
\begin{align*}
\average{\frac{\mu v \tau}{h^*} \partial_x \tilde{h}^2}_{x,\mu,\omega} & = \average{\frac{\mu v \tau}{h^*} \tilde{h}^2}_{x=1,\mu,\omega} - \average{\frac{\mu v}{h^*} \frac{\phi^2 }{\tau^3} \tilde{\tau}^2 }_{\mu^+,\omega} - \average{\frac{\mu v \tau}{h^*} \tilde{h}^2 }_{\mu^-,\omega}\,.
\end{align*}
At $x=1$ we incorporate the reflective boundary condition in~(4.13) to get,
\begin{align*}
\average{\frac{\mu v \tau}{h^*} \tilde{h}^2}_{x=1,\mu,\omega} = 0\,,
\end{align*}
and simply realizing that the third term is non-negative, we have
\[\average{\frac{\mu v \tau}{h^*} \partial_x \tilde{h}^2}_{x,\mu,\omega} \geq - \average{\frac{\mu v}{h^*} \frac{\phi^2 }{\tau^3} \tilde{\tau}^2 }_{\mu^+,\omega}\,.\]
Therefore,
\begin{align*}
C \frac{d}{dt} \average{\tilde{h}^2}_{x,\mu,\omega} & \leq \average{\frac{\mu v}{h^*} \frac{\phi^2}{\tau^3} \tilde{\tau}^2}_{\mu^+,\omega} + 2\average{S_h[\tilde \tau] \frac{\tilde{h}}{h^*}}_{x,\mu,\omega}\,,\\
\frac{d}{dt} \|\tilde{h}\|_2^2 & \leq C_1 \|\tilde \tau \|_2^2 + C_2 \|\tilde \tau\|_2 \|\tilde h \|_2\,, \\
\frac{d}{dt} \|\tilde{h}\|_2^2 & \leq C_1 \|\tilde \tau \|_2^2 + C_2 \|\tilde h \|^2_2\,,
\end{align*}
the second inequality is by Cauchy-Schwarz inequality and the third is by Young's inequality. We define 
\[\|f\|_2(t) := \left(\int f^2 \, dxd\mu d\omega\right)^{1/2}\,,\]
in particular, 
\[\|\tilde \tau\|_2 = \left(\int \tilde \tau^2 \,d\omega\right)^{1/2}\,.\]
We are now ready to apply Gronwall's inequality to the ODE above and obtain,
\begin{align*}
\|\tilde h \|_2^2(t) &\leq \|\tilde h \|_2^2(0)e^{\frac{C}{2}t} + C\|\tilde \tau\|_2^2 \left(e^{\frac{C}{2}t} -1 \right)\,,\\
& \leq C \|\tilde \tau\|_2^2\,, & C = C(T) \text{ for all } 0\leq t \leq T\,.
\end{align*}
hence 
\[\|L_2[\tilde h]\|_2 \leq C \|\tilde \tau\|_2\,.\]

Similar argument can be applied to $\tilde p$ and attain: 
\[
\|\tilde p\|_2 \leq C \|\tilde \tau\|_2\,.
\]

Hence we have proved $L_1, L_2, L_3$ are all Lipschitz with respect to $\tilde \tau$, so there exists some constant $C$ depending on the source function $\phi$, test function $\psi$, domain of $\tau$ and final time $T$, such that~\eqref{eqn: df-Lipschitz} holds.

\end{proof}

With regard to first and second moment limits, it is obvious to check that our method satisfies~\eqref{eqn: SGD-cond-1}, \eqref{eqn: SGD-cond-2} with $\mu = \mu_G = 1$. For~\eqref{eqn: SGD-cond-3}, it can be further transferred to two conditions on the angles between $\nabla f_i$ and their amplitudes. 
\begin{lemma} Under the following two conditions, the second moment limit assumption~\eqref{eqn: SGD-cond-3} can be fulfilled:
\begin{itemize}
\item Angle is small: there exists some constant $c_1$ (uniform in $i$), such that for any $i,j$:
\begin{align}\label{eqn: angle cond}
\frac{\langle \nabla f_i, \nabla f_j\rangle_\omega}{\|\nabla f_i\|_2 \,\|\nabla f_j\|_2} \geq c_1\,,     
\end{align}
and the inner product is in $L^2$:
\begin{align*}
\langle \nabla f_i, \nabla f_j\rangle_\omega := \int \nabla f_i \, \nabla f_j\, d\omega\,.
\end{align*}
\item Amplitudes among all gradients are comparable. There exist some constants $\alpha, \beta >0$ (uniform in $i, j$), such that:
\begin{align}\label{eqn: amp cond}
\alpha \|\nabla f_j\|_2 \leq \|\nabla f_i\|_2 \leq \beta \|\nabla f_j\|_2\,.
\end{align}
\end{itemize}
\end{lemma}
\begin{proof}
We first rewrite condition~\eqref{eqn: SGD-cond-3} by definition.
\begin{align*}
\mathbb{V}_{\xi_k}[\nabla f_{\xi_k}] = \mathbb{E}_{\xi_k}[\|\nabla f_{\xi_k}\|_2^2] - \|\mathbb{E}_{\xi_k}(\nabla f_{\xi_k})\|_2^2 = \frac{1}{N}\sum_{i=1}^N \|\nabla f_{i}\|_2^2 - \|\nabla F\|_2^2\,.
\end{align*}
Thus condition~\eqref{eqn: SGD-cond-3} is equivalent to: $\exists M, M_V\geq 0$, such that
\[\frac{1}{N}\sum_{i=1}^N \|\nabla f_i\|_2^2  \leq M + \frac{M_v+1}{N^2}(\sum_{i=1}^N\, \|\nabla f_i\|_2^2 + \sum_{i\not=j} \langle\nabla f_i, \nabla f_j\rangle_\omega)\,.\]
Assuming \eqref{eqn: angle cond} and \eqref{eqn: amp cond},
\begin{align*}
\sum_{i\not=j} \langle \nabla f_i, \nabla f_j\rangle_\omega &\geq c_1 \sum_{i\not=j} \|\nabla f_i\|_2 \|\nabla f_j\|_2\,,\\
& \geq c_1 \sum_{i\not=j} \|\nabla f_i\|_2 \frac{1}{\beta} \|\nabla f_i\|_2 = \frac{c_1}{\beta} (N-1)\sum_i \|\nabla f_i\|_2^2\,.
\end{align*}
Then we consider and denote $c_2 = \min\{1, \frac{c_1}{\beta}\}$,
\begin{align*}
\frac{1}{N^2}(\sum_{i=1}^N \|\nabla l_i\|_2^2 + \sum_{i\not=j} \langle \nabla f_i, \nabla f_j\rangle_\omega) & \geq \frac{1}{N^2} (\sum_{i=1}^N \|\nabla f_i\|_2^2 + \frac{c_1}{\beta} (N-1)\sum_i \|\nabla f_i\|_2^2)\,,\\
& \geq \frac{c_2}{N^2}N(\sum_i \|\nabla f_i\|_2^2)\,,\\
& \, = \frac{c_2}{N} \sum_i \|\nabla f_i\|_2^2\,.
\end{align*}
Let $M=0$ and $M_V + 1 = \frac{1}{c_2}$ then the second moment limit is proved.
\end{proof}
Due to the complicated expression of gradient in our problem, the geometric meaning of angle between two gradient is rather unclear, we leave the detailed discussion of these two conditions for future study but show some numerical demonstration. Intuitively speaking, suppose among all vectors of $\nabla f_i$, the angle between any two vectors are small, which means they are pointing almost to the same direction, the variance should be controlled.

Despite our observation of gradients (Figure~8) that they concentrate in different $\omega$, since non-trivial linear combination will span the same space as the original basis, we can consider some linear combination of the set $\{\nabla f_i\}$ such that they satisfy these two conditions.

We will show an example of finding a linear combination of gradients at a fix $\tau$. For simplicity, we take $\tau$ to be at the initial guess, 
\[\tau^0(\omega) = -0.15 (\omega - 4) + 1.4\,.\]
and at this specific $\tau^0(\omega)$, we can gather the gradients with respect to each $f_i$ (note that it is corresponding to different pair of $\{\phi_i, \psi_i\}$) into a matrix:
\begin{align*}
\nabla F[\tau^0] = \left[\begin{array}{ll}
\nabla f_1[\tau^0]\,, ...\,, \nabla f_{10}[\tau^0] \end{array}
\right]\,.\end{align*}
Our goal is to find a linear combination of $\{\nabla f_i[\tau]\}$ such that the angle between any two vectors is not $0$ (or not too small).

%For each $\nabla f_i$ has specifically picked one point to 'emphasize' as shown below in Figure~8.

Numerical norm is computed for each individual gradient where the ratio of norms is between $\frac{1}{2}$ and $2$, the norm of this finite set of gradient vectors is obviously comparable.
\begin{figure}[htbp]
    \centering
    \includegraphics[scale =0.16]{manuscript_fig/gradients/df_k_tau0_norm.png}
    \caption{$\|\nabla L_i\|_2\,$ corresponding to Figure~8.}
    \label{fig: show gradient norms}
\end{figure}


And we also compute the angle matrix, whose entry represents the cosine value between any two gradient vectors from $\{\nabla f_i\}$. It is noticeable that the angle between $\nabla f_1, \nabla f_3$ is almost orthogonal that
\[\frac{\average{\nabla f_1, \nabla f_3}}{\|\nabla f_1\|\|\nabla f_3\|} = -0.01\,,\]
and other cosine values are mostly between $0.1$ and less than $0.7$.

Let $A$ be a uniform random matrix, i.e. 
\[A = (a_{ij})\,, a_{ij}\sim \text{Unif}(0,1)\,,\]
and right multiply it to gradient matrix: $\tilde{G} = GA\,,$ we obtain a new set of vectors, as shown in Figure~\ref{fig: show new gradients}. Intuitively, this kind of recombination averages out the update on each specific point $\omega$ and would give a smaller range of angles between each pair of $\nabla f_i$.

\begin{figure}[htbp]
    \centering
    \begin{subfigure}[b]{0.45\textwidth}
         \centering
         \includegraphics[width=\textwidth]{manuscript_fig/gradients/uni_df_k_tau0.png}
         \caption{uniform linear combination}
    \end{subfigure}
    \hfill
    \begin{subfigure}[b]{0.45\textwidth}
         \centering
         \includegraphics[width=\textwidth]{manuscript_fig/gradients/uni_df_k_tau0_norm.png}
         \caption{norm}
    \end{subfigure}
    \caption{Recombination.}
    \label{fig: show new gradients}
\end{figure}

We note that the ratio of norms between these $\{\nabla \tilde{f}_i\}$ roughly stays between $0.5$ and $1$, while the angle between any two vectors are now small in the sense that their cosine values are mostly between $0.92$ and $1$.







\bibliographystyle{siamplain}
%\bibliography{references}
\begin{thebibliography}{99}
\bibitem{JZZ-SGD-2020} B. Jin, Z. Zhou, and J. Zou, {\em On the convergence of stochastic gradient descent for nonlinear ill-posed problems}, SIAM J. Optim., 30 (2020), pp. 1421--1450.
\bibitem{GambaLiNair} I. M. Gamba, Q. Li and A. Nair, {\em Reconstructing the Thermal Phonon Transmission Coefficient at Solid Interfaces in the Phonon Transport Equation}, SIAM J. Appl. Math., 82 (2022), pp. 194--220.
\end{thebibliography}

\end{document}
