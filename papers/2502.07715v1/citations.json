[
  {
    "index": 0,
    "papers": [
      {
        "key": "qiu2021reward",
        "author": "Qiu, Shuang and Ye, Jieping and Wang, Zhaoran and Yang, Zhuoran",
        "title": "On reward-free rl with kernel and neural function approximations: Single-agent {MDP} and {M}arkov {G}ame"
      }
    ]
  },
  {
    "index": 1,
    "papers": [
      {
        "key": "vakilireward",
        "author": "Vakili, Sattar and Nabiei, Farhang and Shiu, Da-shan and Bernacchia, Alberto",
        "title": "Reward-Free Kernel-Based Reinforcement Learning"
      }
    ]
  },
  {
    "index": 2,
    "papers": [
      {
        "key": "qiu2021reward",
        "author": "Qiu, Shuang and Ye, Jieping and Wang, Zhaoran and Yang, Zhuoran",
        "title": "On reward-free rl with kernel and neural function approximations: Single-agent {MDP} and {M}arkov {G}ame"
      }
    ]
  },
  {
    "index": 3,
    "papers": [
      {
        "key": "vakilireward",
        "author": "Vakili, Sattar and Nabiei, Farhang and Shiu, Da-shan and Bernacchia, Alberto",
        "title": "Reward-Free Kernel-Based Reinforcement Learning"
      }
    ]
  },
  {
    "index": 4,
    "papers": [
      {
        "key": "qiu2021reward",
        "author": "Qiu, Shuang and Ye, Jieping and Wang, Zhaoran and Yang, Zhuoran",
        "title": "On reward-free rl with kernel and neural function approximations: Single-agent {MDP} and {M}arkov {G}ame"
      }
    ]
  },
  {
    "index": 5,
    "papers": [
      {
        "key": "qiu2021reward",
        "author": "Qiu, Shuang and Ye, Jieping and Wang, Zhaoran and Yang, Zhuoran",
        "title": "On reward-free rl with kernel and neural function approximations: Single-agent {MDP} and {M}arkov {G}ame"
      }
    ]
  },
  {
    "index": 6,
    "papers": [
      {
        "key": "abbasi2013online",
        "author": "Abbasi-Yadkori, Yasin",
        "title": "Online learning for linearly parametrized control problems"
      }
    ]
  },
  {
    "index": 7,
    "papers": [
      {
        "key": "vakili2024open",
        "author": "Vakili, Sattar",
        "title": "Open Problem: Order Optimal Regret Bounds for Kernel-Based Reinforcement Learning"
      }
    ]
  },
  {
    "index": 8,
    "papers": [
      {
        "key": "lattimore2023lower",
        "author": "Lattimore, Tor",
        "title": "A lower bound for linear and kernel regression with adaptive covariates"
      }
    ]
  },
  {
    "index": 9,
    "papers": [
      {
        "key": "vakilireward",
        "author": "Vakili, Sattar and Nabiei, Farhang and Shiu, Da-shan and Bernacchia, Alberto",
        "title": "Reward-Free Kernel-Based Reinforcement Learning"
      }
    ]
  },
  {
    "index": 10,
    "papers": [
      {
        "key": "jin2020reward",
        "author": "Jin, Chi and Krishnamurthy, Akshay and Simchowitz, Max and Yu, Tiancheng",
        "title": "Reward-free exploration for reinforcement learning"
      }
    ]
  },
  {
    "index": 11,
    "papers": [
      {
        "key": "wang2020reward",
        "author": "Wang, Ruosong and Du, Simon S and Yang, Lin and Salakhutdinov, Russ R",
        "title": "On reward-free reinforcement learning with linear function approximation"
      }
    ]
  },
  {
    "index": 12,
    "papers": [
      {
        "key": "qiu2021reward",
        "author": "Qiu, Shuang and Ye, Jieping and Wang, Zhaoran and Yang, Zhuoran",
        "title": "On reward-free rl with kernel and neural function approximations: Single-agent {MDP} and {M}arkov {G}ame"
      }
    ]
  },
  {
    "index": 13,
    "papers": [
      {
        "key": "vakilireward",
        "author": "Vakili, Sattar and Nabiei, Farhang and Shiu, Da-shan and Bernacchia, Alberto",
        "title": "Reward-Free Kernel-Based Reinforcement Learning"
      }
    ]
  },
  {
    "index": 14,
    "papers": [
      {
        "key": "kearns1998finite",
        "author": "Kearns, Michael and Singh, Satinder",
        "title": "Finite-sample convergence rates for {Q}-learning and indirect algorithms"
      },
      {
        "key": "gheshlaghi2013minimax",
        "author": "Gheshlaghi Azar, Mohammad and Munos, R{\\'e}mi and Kappen, Hilbert J",
        "title": "Minimax PAC bounds on the sample complexity of reinforcement learning with a generative model"
      },
      {
        "key": "agarwal2020model",
        "author": "Agarwal, Alekh and Kakade, Sham and Yang, Lin F",
        "title": "Model-based reinforcement learning with a generative model is minimax optimal"
      }
    ]
  },
  {
    "index": 15,
    "papers": [
      {
        "key": "jin2018q",
        "author": "Jin, Chi and Allen-Zhu, Zeyuan and Bubeck, Sebastien and Jordan, Michael I",
        "title": "Is {Q}-learning provably efficient?"
      },
      {
        "key": "auer2008near",
        "author": "Auer, Peter and Jaksch, Thomas and Ortner, Ronald",
        "title": "Near-optimal regret bounds for reinforcement learning"
      },
      {
        "key": "bartlett2012regal",
        "author": "Bartlett, Peter L and Tewari, Ambuj",
        "title": "REGAL: A regularization based algorithm for reinforcement learning in weakly communicating {MDPs}"
      }
    ]
  },
  {
    "index": 16,
    "papers": [
      {
        "key": "jin2020provably",
        "author": "Jin, Chi and Yang, Zhuoran and Wang, Zhaoran and Jordan, Michael I",
        "title": "Provably efficient reinforcement learning with linear function approximation"
      },
      {
        "key": "yao2014pseudo",
        "author": "Yao, Hengshuai and Szepesv{\\'a}ri, Csaba and Pires, Bernardo Avila and Zhang, Xinhua",
        "title": "Pseudo-{MDPs} and factored linear action models"
      },
      {
        "key": "russo2019worst",
        "author": "Russo, Daniel",
        "title": "Worst-case regret bounds for exploration via randomized value functions"
      },
      {
        "key": "zanette2020frequentist",
        "author": "Zanette, Andrea and Brandfonbrener, David and Brunskill, Emma and Pirotta, Matteo and Lazaric, Alessandro",
        "title": "Frequentist regret bounds for randomized least-squares value iteration"
      },
      {
        "key": "neu2020unifying",
        "author": "Neu, Gergely and Pike-Burke, Ciara",
        "title": "A unifying view of optimism in episodic reinforcement learning"
      }
    ]
  },
  {
    "index": 17,
    "papers": [
      {
        "key": "yang2020provably",
        "author": "Yang, Zhuoran and Jin, Chi and Wang, Zhaoran and Wang, Mengdi and Jordan, Michael",
        "title": "Provably efficient reinforcement learning with kernel and neural function approximations"
      },
      {
        "key": "yang2020reinforcement",
        "author": "Yang, Lin and Wang, Mengdi",
        "title": "Reinforcement learning in feature space: Matrix bandit, kernels, and regret bound"
      },
      {
        "key": "chowdhury2019online",
        "author": "Chowdhury, Sayak Ray and Gopalan, Aditya",
        "title": "Online learning in kernelized {M}arkov decision processes"
      },
      {
        "key": "domingues2021kernel",
        "author": "Domingues, Omar Darwiche and M{\\'e}nard, Pierre and Pirotta, Matteo and Kaufmann, Emilie and Valko, Michal",
        "title": "Kernel-based reinforcement learning: A finite-time analysis"
      },
      {
        "key": "vakili2024kernelized",
        "author": "Vakili, Sattar and Olkhovskaya, Julia",
        "title": "Kernelized Reinforcement Learning with Order Optimal Regret Bounds"
      }
    ]
  },
  {
    "index": 18,
    "papers": [
      {
        "key": "bellemare2016unifying",
        "author": "Bellemare, Marc and Srinivasan, Sriram and Ostrovski, Georg and Schaul, Tom and Saxton, David and Munos, Remi",
        "title": "Unifying count-based exploration and intrinsic motivation"
      },
      {
        "key": "pathak2017curiosity",
        "author": "Pathak, Deepak and Agrawal, Pulkit and Efros, Alexei A and Darrell, Trevor",
        "title": "Curiosity-driven exploration by self-supervised prediction"
      },
      {
        "key": "hazan2019provably",
        "author": "Hazan, Elad and Kakade, Sham and Singh, Karan and Van Soest, Abby",
        "title": "Provably efficient maximum entropy exploration"
      }
    ]
  },
  {
    "index": 19,
    "papers": [
      {
        "key": "jin2020reward",
        "author": "Jin, Chi and Krishnamurthy, Akshay and Simchowitz, Max and Yu, Tiancheng",
        "title": "Reward-free exploration for reinforcement learning"
      },
      {
        "key": "wang2020reward",
        "author": "Wang, Ruosong and Du, Simon S and Yang, Lin and Salakhutdinov, Russ R",
        "title": "On reward-free reinforcement learning with linear function approximation"
      },
      {
        "key": "qiu2021reward",
        "author": "Qiu, Shuang and Ye, Jieping and Wang, Zhaoran and Yang, Zhuoran",
        "title": "On reward-free rl with kernel and neural function approximations: Single-agent {MDP} and {M}arkov {G}ame"
      }
    ]
  },
  {
    "index": 20,
    "papers": [
      {
        "key": "jin2020reward",
        "author": "Jin, Chi and Krishnamurthy, Akshay and Simchowitz, Max and Yu, Tiancheng",
        "title": "Reward-free exploration for reinforcement learning"
      }
    ]
  },
  {
    "index": 21,
    "papers": [
      {
        "key": "wang2020reward",
        "author": "Wang, Ruosong and Du, Simon S and Yang, Lin and Salakhutdinov, Russ R",
        "title": "On reward-free reinforcement learning with linear function approximation"
      }
    ]
  },
  {
    "index": 22,
    "papers": [
      {
        "key": "qiu2021reward",
        "author": "Qiu, Shuang and Ye, Jieping and Wang, Zhaoran and Yang, Zhuoran",
        "title": "On reward-free rl with kernel and neural function approximations: Single-agent {MDP} and {M}arkov {G}ame"
      }
    ]
  },
  {
    "index": 23,
    "papers": [
      {
        "key": "vakilireward",
        "author": "Vakili, Sattar and Nabiei, Farhang and Shiu, Da-shan and Bernacchia, Alberto",
        "title": "Reward-Free Kernel-Based Reinforcement Learning"
      }
    ]
  },
  {
    "index": 24,
    "papers": [
      {
        "key": "vakili2024kernelized",
        "author": "Vakili, Sattar and Olkhovskaya, Julia",
        "title": "Kernelized Reinforcement Learning with Order Optimal Regret Bounds"
      }
    ]
  },
  {
    "index": 25,
    "papers": [
      {
        "key": "levine2020offline",
        "author": "Levine, Sergey and Kumar, Aviral and Tucker, George and Fu, Justin",
        "title": "Offline reinforcement learning: Tutorial, review, and perspectives on open problems"
      }
    ]
  },
  {
    "index": 26,
    "papers": [
      {
        "key": "precup2000eligibility",
        "author": "Precup, Doina",
        "title": "Eligibility traces for off-policy policy evaluation"
      },
      {
        "key": "antos2008learning",
        "author": "Antos, Andr{\\'a}s and Szepesv{\\'a}ri, Csaba and Munos, R{\\'e}mi",
        "title": "Learning near-optimal policies with Bellman-residual minimization based fitted policy iteration and a single sample path"
      },
      {
        "key": "chen2019information",
        "author": "Chen, Jinglin and Jiang, Nan",
        "title": "Information-theoretic considerations in batch reinforcement learning"
      },
      {
        "key": "munos2008finite",
        "author": "Munos, R{\\'e}mi and Szepesv{\\'a}ri, Csaba",
        "title": "Finite-Time Bounds for Fitted Value Iteration."
      }
    ]
  }
]