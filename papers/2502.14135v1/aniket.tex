\documentclass[12pt]{article}

\input preamble.tex

\title{Cluster Analysis and Concept Drift Detection in Malware}

\author{Aniket Mishra\footnotemark[1]\ \ \ 
Mark Stamp\footnotemark[1]\,\,\footnotemark[2]}

\begin{document}

\symbolfootnotetext[1]{Department of Computer Science, San Jose State University}
\symbolfootnotetext[2]{mark.stamp$@$sjsu.edu}

\maketitle

\abstract
Concept drift refers to gradual or sudden 
changes in the properties of data that affect the accuracy of machine learning models. 
In this paper, we address the problem of concept drift detection in the malware domain.
Specifically, we propose and analyze a clustering-based approach to detecting
concept drift. Using a subset of the KronoDroid dataset, malware samples are partitioned 
into temporal batches and analyzed using MiniBatch $K$-Means clustering. 
The silhouette coefficient is used 
as a metric to identify points in time where concept drift has likely occurred. To verify our
drift detection results, we train learning models under three realistic scenarios, 
which we refer to as static training, periodic retraining, and drift-aware retraining. 
In each scenario, we consider four supervised classifiers, namely, Multilayer Perceptron (MLP), 
Support Vector Machine (SVM), Random Forest, and XGBoost. 
Experimental results demonstrate that drift-aware retraining guided by 
silhouette coefficient thresholding 
achieves classification accuracy far superior to static models, and generally
within~1\%\ of periodic retraining, 
while also being far more efficient than periodic retraining. 
These results provide strong evidence that our clustering-based 
approach is effective at detecting concept drift, while also illustrating a 
highly practical and efficient fully automated approach to improved malware 
classification via concept drift detection.

\section{Introduction}\label{chap:intro}

In many applications of machine learning models, the underlying data is not static, 
and hence the features that a model was trained on might change over time. 
Such a change in features is generically referred to  
as concept drift. It is well known that malware writers modify existing malware for use 
in new attacks and to obfuscate malware in an attempt to evade various detection methods~\cite{Lout2024,luomaaho2023analysis}. 
This process of malware evolution can result in gradual or sudden changes in the 
features that machine learning models rely on to detect malware, thereby reducing 
the effectiveness of such models. Hence, concept drift detection is vitally important
in the malware domain, yet this topic appears to have received limited attention 
in the malware research literature. 

Traditionally, malware detection relied primarily on signature-based techniques.
Due to their inherently static nature, signatures
tend to fail under even relatively minor cases of concept drift~\cite{Alejandro}.
On the other hand,
machine learning based techniques, such as Hidden Markov Models (HMM), 
Support Vector Machines (SVM), 
Convolutional Neural Networks (CNN), and Random Forest classifiers, are generally
more robust~\cite{Anupama2022}. 
Consequently, machine learning techniques
have become the focus of malware detection research~\cite{Gibert}. 
However, these methods will also eventually fail 
once malware features sufficiently evolve beyond the training data.

It is well known that there are many obfuscation techniques
available that easily defeat signature scanning~\cite{bm},
and it is not difficult to adapt such techniques to 
defeat machine learning based techniques~\cite{Lin}.
Due to the widespread use of machine learning for malware detection,
and the ease with which malware can be modified---either for
the purpose of obfuscation or due to the 
inherent evolutionary nature of malware---concept drift is a
vitally important topic in the malware field. 

An obvious approach to concept drift detection is to statistically monitor features over time. 
However, it is important to automate the process of concept drift detection, and hence the use
of learning models to monitor features is a reasonable approach. Such an
approach has been previously considered, with HMM and SVM models used for concept 
drift detection in malware classification models~\cite{Sunhera,Lolitha,Mayuri}.

In this paper, we use a clustering based approach to detect concept drift.  
Specifically, we partition the sample of a malware family into
temporal subsets. We then analyze consecutive pairs of subsets using 
MiniBatch $K$-Means clustering~\cite{scikit-learn_mini_batch_kmeans}. 
The silhouette coefficient is used to quantify changes between consecutive clusterings, 
which enables us to detect points in time where significant concept drift has likely occurred.
We then verify that concept drift is being detected by considering various 
model retraining scenarios, which we now introduce.

We train various machine learning models, and use these models to 
classify the samples of a given family. To determine the effectiveness of our 
clustering-based concept drift detection strategy, we consider
the following three scenarios.
\begin{description}
\item[Static training]--- A model is trained on the initial subset of samples, 
and this model is used to classify all remaining
samples, without any retraining.
\item[Periodic retraining]--- A model is trained on the initial subset of samples, and the
model is retrained at regular periodic intervals. A trained model is
used for classification only until the next model is trained.
\item[Drift-aware retraining]--- This is similar to the periodic retraining scenario, 
except that retraining is 
triggered by concept drift detection, rather than regular time intervals.
\end{description}

For each of the three scenarios described above, we experiment with four classifiers. 
Specifically, under each scenario we train  
a Multilayer Perceptron (MLP) neural networks~\cite{scikit-learn_mlp_classifier}, 
Support Vector Machines (SVM)~\cite{scikit-learn_linear_svc}, 
Random Forests~\cite{scikit-learn_random_forest_classifier}, 
and XGBoost models~\cite{xgboost_sklearn_estimator}. We determine the 
accuracy of each of these models under each of the three retraining scenarios.
If we are accurately detecting concept drift, we expect that drift-aware 
retraining will yield strong results, while also being more efficient than
the periodic retraining scenario, in the sense of requiring significantly 
fewer models to be trained.

While many malware datasets are available, few have reliable timestamps associated with 
samples. Without such timestamps, any malware classification results are questionable, due to the
fact that future samples are almost certainly used to train models that are then used
to classify earlier samples, which is
generally not realistic. In any case, accurate timestamps are absolutely essential
for concept drift research. In this paper, we use the KronoDroid dataset~\cite{Krono}, 
since each sample in this dataset includes a timestamp,
and these timestamps appear to be accurate.

The remainder of this paper is organized as follows. In Section~\ref{chap:bg}, 
we discuss relevant background topics, including 
MiniBatch $K$-Means and silhouette coefficients, 
and we introduce each of the
four models that we use for classification.
Section~\ref{sect:rw} contains an overview of 
previous research into concept drift detection within the malware realm. 
Section~\ref{chap:imp} provides implementation details for our experiments. 
Section~\ref{chap:ER} presents our experimental results for 
each model across each of our three retraining scenarios. 
Finally, Section~\ref{chap:con} summarizes 
our findings and highlights potential directions for future research.


\section{Background}\label{chap:bg}

In this section, we discuss relevant background topics. First, we
introduce the topics of supervised and unsupervised learning. Then we 
discuss MiniBatch $K$-Means clustering in some detail, followed by
a brief introduction to each of the four learning techniques used in our experiments.
Finally, we discuss the silhouette coefficient in some detail, as it is 
fundamental to our concept drift detection strategy.

\subsection{Supervised and Unsupervised Learning}

Supervised learning refers to models that are trained on labeled datasets. 
Most popular classifiers are supervised techniques. 
Such methods have proven effective at detecting malware but, 
of course, all are adversely affected by concept drift. 
In this paper, we train various models as a way to test the effectiveness
of our proposed concept drift detection strategy. Specifically, the 
classification models that we consider
are MLP, SVM, Random Forest, and XGBoost, 
each of which is introduced below.

Unsupervised learning is based on unlabeled data. Techniques such as $K$-Means
and Expectation Maximization (EM) clustering are classic 
examples of unsupervised learning. Clustering is typically used
in a data exploration mode, where we are trying to analyze and understand data that
we know little about. This makes clustering a potentially useful approach 
for concept drift detection. In this paper, we experiment with MiniBatch $K$-Means 
as a tool for automatically detecting concept drift. Below, we introduce the 
MiniBatch $K$-Means algorithm, which is a version of $K$-Means that is more efficient
for large datasets.

\subsection{MiniBatch $K$-Means}

In this section, we first discuss the $K$-means algorithm. Then 
we consider the modification known as MiniBatch $K$-Means.

Suppose that we are given the~$n$ feature vectors~$X_1, X_2, \ldots, X_n$,
where each of the~$X_i$ is typically a vector of, say, $m$ real numbers. 
We assume that we want to partition these~$n$ feature vectors
into~$K$ clusters, where~$K$ is specified. 
We also assume that we have a distance function~$d(X_i,X_j)$
that is defined for all pairs of vectors.
Furthermore, we require that each vector~$X_i$ belongs to exactly one cluster.

We associate a centroid
with each cluster, where the centroid can be viewed as representative 
of its cluster---intuitively, a centroid is the center of mass of its cluster.
We denote the clusters as~$C_j$ with the 
corresponding centroid denoted as~$c_j$, for~$j=1,2,\ldots,K$.
Note that in $K$-means, the centroids need not belong to the set
of feature vectors.

Suppose that we have clustered our~$n$ vectors. 
Then we have a set of~$K$ centroids
$$
  c_1, c_2, c_3, \ldots, c_K , 
$$
where each vector in our dataset is associated with one centroid.
Let~$\centroid{X_i}$ denote the (unique) centroid of the cluster
to which~$X_i$ belongs. 
Then the centroids determine the clusters, in the sense that 
$$
  c_j = \centroid{X_i} 
$$
implies~$X_i$ belongs to cluster~$C_j$. 

Before we can cluster data based on the outline above, 
we need to answer the following two basic questions.
\begin{enumerate}
\item How do we determine the centroids~$c_j$?
\item How do we determine the clusters? That is,
we need to specify the function~$\centroid{X_i}$
that assigns data points to centroids.
\end{enumerate}
At the very least, we need a method to compare clusterings, that is,
we must have a way to determine whether one clustering is better than another.
The $K$-Means algorithm uses a simple method for
quantifying cluster quality. 

Intuitively, the more compact a cluster, the better. Of course, this will
depend on the vectors~$X_i$ and the number of clusters~$K$. Since the data is given,
and we assume that~$K$ has been specified, 
we have no control over the~$X_i$ or~$K$.  But, we do have
control over the centroids~$c_j$ and the assignment of points to centroids via the
function~$\centroid{X_i}$. The choice of centroids and the assignment of
points to centroids will clearly influence the compactness
(or ``shape'') of the resulting clusters. 

We define
\begin{equation}\label{eq:cluster_distortion}
  \distortion{} = \sum_{i=1}^n d\bigl(X_i,\centroid{X_i}\bigr) .
\end{equation}
The smaller the~$\distortion{}$, the better, since a smaller~$\distortion{}$
implies that individual clusters are more compact.

For example, consider the data in Figure~\ref{fig:clustDistortion}, where the same
data points are clustered in two different ways. It is clear that the clustering on 
the left-hand side in Figure~\ref{fig:clustDistortion} has a smaller $\distortion{}$ than 
that on the right-hand side. Therefore, we would say that the left-hand clustering is superior,
at least with respect to the measure of~$\distortion{}$.

\begin{figure}[!htb]
\centering
    \input figures/means.tex
\caption{Less distortion and more distortion}\label{fig:clustDistortion}
\end{figure}

Suppose that we want to minimize the $\distortion{}$. 
First, we note that the $\distortion{}$ depends on~$K$, 
since more clusters means more centroids and, all else being equal, 
the larger the value of~$K$, the closer each point will tend to
be to its centroid. Hence, we write $\distortion{K}$ to emphasize the 
dependence on the hyperparameter~$K$. As mentioned above, 
we assume that~$K$ is specified in advance.

The problem we want to solve can be stated precisely as follows.
\begin{equation}\label{eq:clustProb}
\begin{split}
  & \mbox{Given: } K \mbox{ and data points } X_1,X_2,\ldots, X_n\\[-0.75ex]
  & \mbox{Minimize: } \distortion{K} =  \sum_{i=1}^n d\bigl(X_i,\centroid{X_i}\bigr) .
\end{split}
\end{equation}
Finding an exact solution to this problem is computationally infeasible,
but we can derive a very simple, iterative approximation.

We claim that a solution to~\eref{eq:clustProb} must satisfy the following two conditions.
\begin{description}
\item[Condition~1]--- Each~$X_i$ is clustered according to its nearest centroid,
i.e., if~$X_i$ belongs to cluster~$C_j$, 
then~$d(X_i,c_j) \leq d(X_i,c_{\ell})$ for all~$\ell\in\{1,2,\ldots,K\}$,
where the~$c_{\ell}$ are the centroids.
\item[Condition~2]--- Each centroid is located at the center of its cluster.
\end{description}

To verify the necessity of Condition~1,
suppose that~$X_i$ is in cluster~$C_j$ and that~$d(X_i,c_{\ell}) < d(X_i,c_{j})$ 
for some~$\ell$. Then by simply reassigning~$X_i$ to cluster~$\ell$, we 
will reduce~$\distortion{K}$.
Condition~2  is only slightly challenging to prove.
In any case, these two conditions suggest an approximation 
algorithm.

From Condition~1, we see that given any clustering for which there are 
points that are not clustered based on
their nearest centroid, we can improve the clustering by simply reassigning
such data points to their nearest centroid. By Condition~2,
we always want the centroids to be at the center of the clusters. So, given any
clustering, we may improve it---and it cannot get worse---by performing 
either of the following two steps.

\begin{description}
\item[Step~1]--- Assign each data point to its nearest centroid.
\item[Step~2]--- Recompute the centroids so that each lies at the center of
its respective cluster.
\end{description}

It is clear that no improvement will result from applying 
Step~1 more than once in succession, and the same holds true for Step~2.
However, by alternating between these two steps, we obtain an iterative process that
yields a series of solutions that will generally tend to improve, and even in the worst
case, the solution cannot get worse. This is the $K$-means algorithm.

The $K$-Means algorithm is a hill climb, and hence we
are only assured of finding local maximum and, as with any hill climb,
the maximum we obtain will depend on our choice for the initial conditions. 
For $K$-means, the initial conditions correspond to the initial selection of centroids.
Therefore, it can be beneficial to repeat the algorithm multiple times with
different initializations of the centroids.

In the MiniBatch $K$-Means algorithm, instead of using the entire dataset to update the centroids, only
a small subset of the vectors are considered at each iteration. The algorithm 
can be stated as follows~\cite{minibatch_k_means}.
\begin{enumerate}
\item Centroids are initialized at random
\item As in standard $K$-Means, each data point is assigned to its nearest centroid
\item A minibatch of data is randomly selected from the dataset
\item The centroids are recomputed using only the points from the minibatch
\item If there is sufficient change in the centroids, goto~2
\end{enumerate}
MiniBatch $K$-Means is claimed to be more efficient---both in the sense of faster convergence
and requiring less memory---as compared to standard $K$-Means.
For the experiments discussed in this paper, we use the MiniBatch $K$-Means implementation 
at~\cite{scikit-learn_mini_batch_kmeans}.

\subsection{Classification Models}

For all of our classification results, we experiment with four distinct learning algorithms. As mentioned above, these 
four classification algorithms are MLP, SVM, Random Forest, and XGBoost. In this section,
we briefly introduce each of these algorithms.

\subsubsection{MLP}

Multilayer Perceptrons (MLP) are a fundamental class of feedforward artificial neural networks. 
MLPs are capable of learning complex, nonlinear relationships between the input and output spaces. 
For our MLP experiments, we use the implementation at~\cite{scikit-learn_mlp_classifier}.
In all of our MLP models, we use the popular ReLU activation functions, and
we also use the Adam optimizer to adjust the learning rate during training. 
The hyperparameters of an MLP include the number of neurons, the number of layers, 
and the type of regularization. 

As mentioned, one of the advantages of MLPs is their ability to model complex relationships. 
However, the tradeoff is that larger amounts of data and extended training times may be required. 
Batch normalization (BatchNorm) can be used to speed convergence and stabilize the training process. 
Regularization techniques are important for optimizing performance and to mitigate 
issues such as vanishing and exploding gradients~\cite{towardsdatascience_mlp}.

\subsubsection{SVM}

Support Vector Machine (SVM) is a classifier that attempts to find a separating hyperplane, where
the hyperplane maximize the margin (i.e., separation) between the two classes in the feature space. 
For all of our SVM models, we use the Support Vector Classifier implementation
at~\cite{scikit-learn_linear_svc}.

A key hyperparameter of an SVM is
the regularization parameter~$C$. This parameter balances the margin and classification accuracy.
A higher value for~$C$ results in a tighter margin, but can result in overfitting,
whereas a smaller~$C$ value increases the margin of separation, but can lead to 
underfitting~\cite{ibm_svm}.

\subsubsection{Random Forest}

Random Forest is an ensemble learning algorithm that consists of multiple decision trees. 
A random subset of data and features are used to build each tree using a process known as bagging. 
This approach helps reduce the likelihood of overfitting and also reduces the variance. During the classification 
stage, a majority vote among the component decision trees is used.
Random Forest models are considered to be particularly strong in cases with noisy data,
and the can handle both numerical and categorical variables. Another advantage is 
that a Random Forest provides details on feature importance~\cite{ibm_random_forest}.

Random Forest hyperparameters include the number of trees and the maximum depth of each tree. 
As the number of trees are increased, the stability increases and the variance is reduced. 
However, more trees generally leads to longer training times. Random Forests generally perform
well, but the technique may struggle on data with highly correlated features, as this tends to
result in redundant trees. To address this issue, dimensionality reduction techniques can be 
applied to the data before training a Random Forest model.

\subsubsection{XGBoost}

XGBoost (eXtreme Gradient Boosting) is a very efficient version of gradient boosting. 
As with Random Forests, XGBoost models are based on decisions trees.
However, unlike a Random Forest, an XGBoost model is determined sequentially,
in the sense that each tree focuses on reducing the residual errors of the previous tree. 
Overfitting is reduced by minimizing a differentiable loss function, and the technique 
also employs various regularization strategies. In XGBoost, regularization serves to control model 
complexity which, in turn, helps reduce overfitting.  XGBoost is also noted for its
ability to effectively deal with high dimensional data. 

Since XGBoost is based on decision trees many of the hyperparameters are similar to those
of a Random Forest. Some of the important hyperparameters in XGBoost include 
the learning rate, the maximum tree depth, and the number of estimators~\cite{ibm_xgboost}. 

\subsection{Silhouette Coefficient}

When clustering data, intuitively,
we want each cluster to be cohesive,
in the sense that the points within a cluster are close together. 
In addition, we would like the points in different 
clusters to be well separated.
That is, the more cohesive the individual clusters and
the more separation between the clusters, the better. 
In this section, we first provide formulae for
explicitly computing cohesion and separation, relative to a given data point. 
Then we combine these quantities into a single number to obtain the so-called 
silhouette coefficient, relative to the given data point. 
Finally, we argue that the average silhouette coefficient
over all data points provides a sensible measure of cluster quality.

Suppose that we have a set of~$n$ feature vectors~$X_1,X_2,\ldots,X_n$
partitioned into~$K$ clusters, $C_1,C_2,\ldots,C_K$. Let~$n_i$ be the
number of elements in cluster~$C_i$. Note that~$n_1+n_2+\cdots+n_K = n$.

Select a feature vector~$X_i$. Then~$X_i\in C_j$ for some~$j\in\{1,2,\ldots,K\}$.
Let~$a$ be the average distance from~$X_i$ to all other points in 
its cluster~$C_j$. That is, 
\begin{equation}\label{eq:clusterAAA}
  a =  \frac{1}{n_j - 1}\sum_{\substack{Y\in C_j\\ Y\neq X_i}} d(X_i,Y) .
\end{equation}
In the degenerate case where~$n_j = 1$, let~$a=0$.
Also, for each cluster~$C_{\ell}$, such that~$\ell\neq j$,  
let~$b_{\ell}$ be the average distance from~$X_i$
to the other vectors in cluster~$C_{\ell}$, that is,
$$
  b_{\ell} = \frac{1}{n_{\ell}}\sum_{Y\in C_{\ell}} d(X_i,Y) .
$$
Finally, we define~$b$ to be the smallest of the~$b_{\ell}$, that is,
\begin{equation}\label{eq:clusterBBB}
  b = \!\!\!\!\min_{\substack{\ell\in\{1,2,\ldots,K\}\\ \ell\neq j}}\!\!\!\! b_{\ell} .
\end{equation}
The value~$a$ in~\eref{eq:clusterAAA} is a measure of the cohesion of cluster~$C_j$,
relative to the point~$X_i$, while~$b$ in~\eref{eq:clusterBBB} provides 
a measure of separation relative to the vector~$X_i$.

We define the  silhouette coefficient of feature vector~$X_i$ as 
$$
  S(X_i) = \frac{b-a}{\max(a,b)} .
$$
For any reasonable clustering, we expect that~$b > a$, in which case
$$
  S(X_i) = 1 - \frac{a}{b} .
$$

For example, consider the clusters in Figure~\ref{fig:clustSilEx}. 
In this case, $a$ is the average length of the lines connecting~$X_i$
to the other vectors (i.e., the squares) in its cluster, $C_1$. Also, $b_2$ is the average 
length of the lines from~$X_i$ to the vectors (i.e., ovals) in~$C_2$,
and~$b_3$ is the average length of the lines 
from~$X_i$ to the vectors (i.e., circles) in~$C_3$.
Letting~$b=\min\{b_2,b_3\}$, the silhouette coefficient 
for~$x_i$ is given by~$S(x_i)=1-a/b$.

\begin{figure}[!htb]
\centering
    \input figures/silhouette.tex
\caption{Silhouette coefficient example}\label{fig:clustSilEx}
\end{figure}

If~$X_i$ is much closer to the vectors in its own cluster, as compared to
its distance to any other cluster, then~$a$ is much less than~$b$, 
and~$S(X_i)\approx 1$.
On the other hand, if~$X_i$ is relatively far from vectors in its own cluster and
close to vectors in at least one other cluster, then~$S(X_i)$ will be close to~0.
Therefore, the larger the silhouette coefficient~$S(X_i)$, the better. 
The average silhouette coefficient 
$$
  s = \frac{1}{n} \sum_{i=1}^n S(X_i)
$$
provides an intrinsic measure of the overall quality of a given clustering.
The bottom line is that the average silhouette coefficient combines 
cohesion and separation into a single number that provides
a useful intrinsic measure of cluster quality. 

\subsection {Silhouette Coefficient and Concept Drift}

For our purposes, 
we expect that if no concept drift has occurred, a consecutive pair of
temporal subsets will cluster similarly to the previous pair, yielding a small
difference in the average silhouette coefficient. In contrast, when concept
drift has occurred between consecutive temporal subsets,
we will see a more substantial difference in the average
silhouette coefficient, as compared to the clustering of the previous pair. 
Thus, we propose to use the 
average silhouette coefficient as a way to detect changes 
in feature vectors, which implies concept drift.

Recall from Section~\ref{chap:intro} that we consider three different scenarios, 
which we denote as static training, periodic retraining, and drift-aware retraining.
In the static training scenario, a model is trained on the initial temporal subset
and no retraining occurs; in the periodic retraining scenario, 
 a model is retrained at regular intervals without regard to concept drift detection;
while in the drift-aware retraining scenario, 
the model is retrained only when significant concept drift is 
detected via changes in silhouette coefficient. Note that only in the 
drift-aware scenario are we using the silhouette coefficient results.

\section{Related Work}\label{sect:rw}

In this section, our focus is to provide a selective survey of previous work in concept drift detection 
within the malware domain. While the topic of concept drift in malware has been considered in the 
literature, given its importance, it is surprising that more research has not been conducted.

Concept drift is relevant in many areas of cybersecurity~\cite{9027485}, but none more so than 
malware, where detection systems must adapt to ongoing changes. In the malware context,
concept drift can occur any time that new malware samples are created from existing families. 
Modifications are made to existing malware to implement new attacks, or for the 
purpose of obfuscation~\cite{10.1145/2381896.2381910}. Regardless of the reason for modifications,
concept drift will likely occur whenever samples of a malware family are 
modified to any significant degree. 

In recent years, the importance of detecting concept drift has been recognized. In the cybersecurity field, 
concept drift has been studied in areas as diverse as spam filtering and credit card fraud detection~\cite{Jog}. 
However, malware detection poses unique challenges, due to strategies that can be used to actively 
evade detection. Techniques such as polymorphism and metamorphism enable malware developers
to easily modify the features of existing malware families~\cite{Sharma_2014}. Such 
readily available obfuscation techniques further emphasize the need for a robust and automated 
concept drift detection process. It is also important to note that model training is generally
costly, and hence we want to minimize the frequency with which models are retrained.
Thus, detecting concept drift and retraining only when necessary is desirable.

In the interesting paper~\cite{Molina}, the authors detect concept drift in Android 
malware by monitoring the performance of a trained model, using techniques pioneered 
in~\cite{Page} and~\cite{Hinckley}. By retraining only when drift is detected,
they obtain detection results that are essentially equivalent to periodic retraining,
but the process is far more efficient, since fewer models need to be trained.

The research in~\cite{Alejandro} is primarily focused on the validity of timestamps in
the context of concept drift detection for Android malware. The authors develop 
an ``internal'' timestamp that appears to be more accurate than 
typical timestamps.

The paper~\cite{Karbab} relies on Natural Language Processing (NLP)
and machine learning techniques to adapt to changes in malware families. 
The goal is to cluster samples into their respective families.

In~\cite{Xu}, the authors develop DroidEvolver which includes a method 
for automatically updating an Android malware
detection model without retraining. The approach is highly efficient 
and the authors claim that it only reduces the performance
slightly over an extended period of time, as compared to state-of-the-art methods.

The research in~\cite{Kan} is focused on perceived flaws in DroidEvolver, which cause models
to perform much worse than claimed in~\cite{Xu}. The authors of~\cite{Kan} develop and test
DroidEvolver\texttt{++}, which they claim addresses the issues discovered in DroidEvolver.

The research in~\cite{Chen} focuses on a supposed distinction between 
feature-space drift (defined as new features introduced by new 
samples) and data-space drift (defined as data distribution 
shift over existing features) in the malware context. The authors 
claim that data-space drift consistently dominates, and they consider
this to be surprising.

The authors of~\cite{Yizheng} employ a hierarchical contrastive learning approach to update 
malware detection models. Their results show significant improvement over more costly 
retraining techniques.

The work presented in the remainder of this paper
is---in terms of the structure of our experiments---most similar to that in the paper~\cite{Molina}.
However, the actual techniques that we employ for concept drift detection are 
most closely related to those in the series of papers~\cite{Sunhera,Lolitha,Mayuri}
and, in fact, this paper can be viewed as a continuation and extension this series of papers.

\section{Implementation}\label{chap:imp}

This section includes a discussion of the dataset, the features, and preprocessing of the data.
We then discuss the three training scenarios in greater precision, and other relevant implementation 
details are given.

\subsection{Dataset}

This research utilizes the KronoDroid dataset, which contains~41,382 Android malware samples
that are categorized into~240 distinct families~\cite{Krono}. The dataset includes metadata that enables 
us to segment each family into temporal batches. This information is essential for the study 
of malware evolution and concept drift. Each sample in the KronoDroid dataset includes a variety
of extracted features, including permissions, API calls, manifest data, and various behavioral signatures.
In short, the KronoDroid dataset is well-suited for the clustering and classification tasks considered in
this research. Specifically, there are~289 dynamic features (i.e., system calls),
200 static features (i.e., permissions, intent filters, metadata),
and we dropped~19 non-numeric features, giving us a total of~470 features.
There are~4 distinct timestamps per data sample~\cite{github};
in our experiments, we use the ``last modified'' timestamp for each sample.

Most of the families in the KronoDroid dataset have only a small number of samples, which makes them
unusable for concept drift experiments. Therefore, we restrict our attention to the following
five malware families, each of which includes a substantial number of samples.
\begin{description}
\item[Airpush/StopSMS] is a Trojan that aggressively pushes ads to the device notification bar~\cite{AirPush}.
For the remainder of this paper, we shorten the name of this family to Airpush.
\item[SMSreg] is ``riskware'' that claims to improve battery life~\cite{SMSReg}.
\item[Malap] is a generic family that includes malicious apps that steal data or install additional malware~\cite{Alejandro}.
\item[Boxer] is a Trojan that sends SMS messages without the user's authorization~\cite{Boxer}.
\item[Agent] is a family of programs that download and install malware~\cite{Agent}.
\end{description}

The number of samples in each family, along with
other relevant details, are provided in Table~\ref{tab:malware_families_intervals}.
In all cases, we use a batch size of~50 in our experiments. 
This approach ensures that we have a sufficient number of 
samples for training and provides a fair comparison 
across different families and models. 

\begin{table}[!htb]
\def\zz{\phantom{0}}
\newsavebox{\mybox}
\sbox{\mybox}{September~13}
\centering
\caption{Malware dataset}\label{tab:malware_families_intervals}
\adjustbox{scale=0.85}{
\begin{tabular}{c|ccll}
\toprule
\multirow{2}{*}{\textbf{Family}} 
	& \multirow{2}{*}{\textbf{Samples}} 
	& \multirow{2}{*}{\textbf{Intervals}}
	& \multicolumn{2}{c}{\textbf{Date range}} \\ \cline{4-5} \\[-2.6ex]
  & & & \multicolumn{1}{c}{\textbf{Begin}} & \multicolumn{1}{c}{\textbf{End}} \\ \midrule
Airpush & \zz7,775 & 154 & February~29, 2008 & \makebox[\wd\mybox][r]{June~23}, 2016 \\ 
SMSreg & \zz5,019 & \zz84 & February~29, 2008 & \makebox[\wd\mybox][r]{November~9}, 2020 \\ 
Malap & \zz4,055 & \zz70 & February~29, 2008 & \makebox[\wd\mybox][r]{November~11}, 2020 \\ 
Boxer & \zz3,597 & \zz69 & February~29, 2008 & \makebox[\wd\mybox][r]{September~13}, 2017 \\ 
Agent & \zz2,934 & \zz46 & February~29, 2008 & \makebox[\wd\mybox][r]{May~6}, 2020 \\ \midrule
Total & 23,380 & 423 & February~29, 2008 & \makebox[\wd\mybox][r]{November~11}, 2020 \\ \bottomrule
\end{tabular}
}
\end{table}

\subsection{Data Preprocessing}

As mentioned above, the KronoDroid dataset includes temporal metadata. 
We segment each family into fixed size batches,
which allows us to study evolution and concept drift within each 
malware family under consideration.

As mentioned, we partition the samples into temporal batches, with~50 samples per batch. 
In addition, we normalize all feature values, which is standard practice when 
training machine learning models.

\subsection{Model Retraining Scenarios}\label{sect:scenarios}

%As mentioned above, we consider three retraining scenarios. Here, we describe
%these scenarios in detail, but first we require some notation.

Consider an experiment that we denote as ``Family~$X$ vs Family~$Y$.''
Here, Family~$X$ is the family for which we are trying to detect concept drift, 
while Family~$Y$ simply serves to provide samples for the ``other'' class
in our binary classification experiments. 

The samples of family~$X$ are segmented into temporal batches of~50 samples each.
We denote these batches of~$X$ as~$B_1,B_2,\ldots,B_n$. 
Let~${\cal B}_i = \{B_i,B_{i+1}\}$, for~$i=1,2,\ldots,n-1$.
MiniBatch $K$-Means clustering is applied to each~${\cal B}_i$, and the 
average silhouette coefficient corresponding to~${\cal B}_i$ is denote as~$s_i$. 

The subset of~$B_i$ consisting of its first~25 samples is denoted~$B_i^{t}$ 
while the last~25 samples is denoted~$B_i^{T}$. Randomly select two disjoint
subsets of~25 samples each from Family~$Y$, and denote these samples 
as~$Y_{t}$ and~$Y_{T}$. 
We now describe the three model retraining scenarios.

\subsubsection{Static Training}

Train a model~$M$, which is a binary classifier, to distinguish
between the samples from Family~$X$ in~$B^t_1$ and the Family~$Y$
samples in~$Y_t$.
Test the model~$M$ on each of~$(B^T_i,Y_T)$, for~$i=1,2,\ldots,n$. 
We want to determine the overall accuracy, 
and we will graph the accuracy for each batch. 
If concept drift is occurring in Family~$X$,
we expect the accuracy to decrease when drift occurs.

\subsubsection{Periodic Retraining}

For~$i=1,2,\ldots,n$, train model~$M_i$  
on the labeled samples~$(B^t_i,Y_i)$. 
Then test model~$M_i$ on~$(B^T_i,Y_T)$, for~$i=1,2,\ldots,n$. 
Note that model~$M_1$ in this scenario is the same as model~$M$ in the
static scenario.

As in the static scenario,
we want to determine the overall accuracy, and we will graph the accuracy for each batch.
We expect the accuracy to be higher than the static training scenario,
and the accuracy is likely to be reasonably consistent over the batches.

\subsubsection{Drift-Aware Retraining}
 
In this scenario, a model is retrained only when 
concept drift is detected, and this model is then used to score samples until drift is 
once again detected.
For example, suppose that concept drift is first detected at~${\cal B}_i$ and 
the next drift detection occurs at~${\cal B}_j$, and drift is detected for the final time
at~${\cal B}_k$, where
$$
  1 < i < j < k < n
$$ 
Then model~$M'_1$ is trained on~$(B^t_1,Y_t)$,
model~$M'_2$ is trained on~$(B^t_{i+1},Y_t)$,
model~$M'_3$ is trained on~$(B^t_{j+1},Y_t)$, and
model~$M'_4$ is trained on~$(B^t_{k+1},Y_t)$.
Finally, model~$M'_1$ is used to classify test samples
$$
    (B^T_1,Y_T),\ (B^T_2,Y_T),\ \ldots,\ (B^T_i,Y_T)
$$
model~$M'_2$ is used to classify test samples
$$
    (B^T_{i+1},Y_T),\ (B^T_{i+2},Y_T),\ \ldots,\ (B^T_j,Y_T)
$$
model~$M'_3$ is used to classify test samples
$$
    (B^T_{j+1},Y_T),\ (B^T_{j+2},Y_T),\ \ldots,\ (B^T_k,Y_T)
$$
and model~$M'_4$ is used to classify test samples
$$
    (B^T_{k+1},Y_T),\ (B^T_{k+2},Y_T),\ \ldots,\ (B^T_n,Y_T)
$$
Note that~$M'_1$ in this scenario is the same as~$M_1$ in the periodic retraining scenario,
$M'_2$ is the same as~$M_{i+1}$ in the periodic retraining scenario,
$M'_3$ is the same as~$M_{j+1}$ in the periodic retraining scenario, and
$M'_4$ is the same as~$M_{k+1}$ in the periodic retraining scenario.

As in the previous scenarios, 
we want to determine the overall accuracy, and we will graph the accuracy for each batch.
If we are accurately detecting concept drift, we expect that the results for
this scenario will be similar to that for the periodic retraining scenario.
This approach will also generally be more efficient than the periodic
retraining scenario, since we will train fewer models.

\subsection{Development Environment}

For our development environment we use libraries from Python to 
implement and evaluate our models. Table~\ref{tab:development_environment} 
lists these libraries and how they are used in our experiments.

\begin{table}[!htb]
\centering
\caption{Development environment and libraries}
\label{tab:development_environment}
\adjustbox{scale=0.85}{
\begin{tabular}{c|c}
\toprule
\textbf{Library/Tool} & \textbf{Purpose} \\ \midrule
\multirow{4}{*}{Scikit-learn} & MiniBatch $K$-Means clustering  \\
& Models (MLP, SVM, Random Forest,) \\
& Feature selection (RFE), evaluation metrics \\
& Silhouette score calculation \\ \midrule
\multirow{3}{*}{NumPy} & Computation on large arrays and matrices \\
& Handling malware feature vectors\\
& Calculate distance between samples \\ \midrule
\multirow{2}{*}{Matplotlib} & Visualizations of clustering results \\
& Graph silhouette coefficients \\ \midrule
\multirow{2}{*}{Pandas} & Data manipulation using DataFrames \\
& Preprocessing (filtering, aggregation, missing values) \\ \midrule
\multirow{2}{*}{SciPy (spatial module)} & Compute pairwise distances \\
& $K$-Means and silhouette calculations \\ \midrule
XGBoost & XGBoost classifier \\ \bottomrule
\end{tabular}
}
\end{table}

\subsection{Workflow}

The workflow is divided into four stages. 
The first stage is data collection and preprocessing, which involves downloading the KronoDroid dataset, 
normalizing the features, generating temporal batches for each family.
The second stage is clustering and analysis, where for each malware family, 
we apply MiniBatch $K$-Means to consecutive batches and calculate silhouette coefficients.
In the third stage, we analyze the silhouette coefficients for concept drift detection,
which will be used in the drift-aware retraining scenario. Finally, at model training and evaluation stage, 
we train supervised classification models (MLP, SVM, Random Forest, and XGBoost) 
under each of the three retraining scenarios---static training, periodic retraining, and drift-aware retraining. 
We evaluate the performance of each model under each retraining scenario, where
accuracy is our criteria.


\section{Experiments and Results}\label{chap:ER}

In this section, we present our experimental results. 
We compare how well each retraining scenario performs,
in terms of classification accuracy and discuss the significance of 
our results, with the emphasis on concept drift. 

\subsection{Experimental Setup}\label{sect:setup}

Our four classification models (MLP, SVM, Random Forest, and XGBoost)
are evaluated under each of the three retraining scenarios discussed in
Section~\ref{sect:scenarios}. Recall that these three scenarios are denoted
as static training, periodic retraining, and drift-aware retraining.

For the drift-aware retraining scenario, we need to set a threshold that specifies 
when concept drift has been detected. Let~$d_i = |s_i - s_{i-1}|$,
where~$s_i$ is the average silhouette coefficient for the
clustering of the~$i^{\thth}$ temporal subset.\footnote{Recall that
in the notation of Section~\ref{sect:scenarios}, we split the 
family into temporal batches~$B_i$ of~50 samples each,
and then cluster two consecutive of these batches, which we
denote as~${\cal B}_i = \{B_i,B_{i+1}\}$.}
Based on preliminary experiments,
we use a threshold of~$d_i > 0.05$,
to trigger retraining in the drift-aware scenario.

Analysis of silhouette coefficients indicate that some families
exhibit relatively stable results, and other families yield more dynamic results. 
For example, the values of~$d_i$ for SMSreg are given in the form of
a line graph in Figure~\ref{fig:SMS_sil}. In this case, 
we observe that~$d_i$ ranges from essentially~0 to~0.4,
with relatively stable values from interval~10 to interval~73.

%\begin{figure}[!htb]
%    \centering
%    \includegraphics[scale=0.5]{images/sms_sil.png}
%    \caption{Silhouette scores for SMSreg}
%    \label{fig:SMS_sil}
%\end{figure}

\begin{figure}[!htb]
    \centering
    \input figures/silGraphSMSreg.tex
    \caption{Silhouette score differences for SMSreg}\label{fig:SMS_sil}
\end{figure}

As another example, the values of~$d_i$ for Malap are given in Figure~\ref{fig:malap_sil}. 
For this family, we observe that the absolute differences between consecutive
pairs of average silhouette coefficients (i.e., $d_i$) vary over a smaller range than
for SMSreg, but with a more consistent variation throughout all intervals.

%\begin{figure}[!htb]
%    \centering
%    \includegraphics[scale=0.5]{images/malap_sil.png}
%    \caption{Silhouette scores for Malap}
%    \label{fig:malap_sil}
%\end{figure}

\begin{figure}[!htb]
    \centering
    \input figures/silGraphMalap.tex
    \caption{Silhouette score differences for Malap}\label{fig:malap_sil}
\end{figure}

Analogous graphs to those in Figures~\ref{fig:SMS_sil} and~\ref{fig:malap_sil}
for the Agent, Airpush, and Boxer families are
given in the Appendix in Figures~\ref{fig:agent_sil}, 
\ref{fig:airpush_sil}, and~\ref{fig:boxer_sil}, respectively. 
We note that among the five families considered,
Malap exceeds the threshold of~$d_i > 0.05$
with the highest relative frequency, while
Boxer exceeds the threshold with the lowest
relative frequency. We provide more details
in Section~\ref{sect:disc}, below.

\subsection{Hyperparameter Tuning}

Table~\ref{tab:parameters} lists the hyperparameters tested for each model.
The hyperparameters selected for MinBatch $K$-Means are highlighted in boldface. 
For the classification models, a separate grid search was performed over the listed 
hyperparameters for each family.

\begin{table}[!htb]
\centering
\caption{Hyperparameters for clustering and classification models}
\label{tab:parameters}
\adjustbox{scale=0.85}{
\begin{tabular}{c|cc}
\toprule
\textbf{Model} & \textbf{Hyperparameters} & \textbf{Tested values} \\ \midrule
\multirow{3}{*}{MiniBatch $K$-Means} & Batch sizes & \textbf{50}, 100, 150 \\ 
 & MiniBatch sizes & 15, \textbf{20}, 25  \\ 
 & Drift detection threshold & 0.01, 0.03, \textbf{0.05} 0.10 \\ \midrule
\multirow{4}{*}{MLP} & \texttt{hidden\_layer\_sizes} & (50,), (100,), (100,75,75) \\ 
 & \texttt{max\_iter} & 200, 300, 500 \\ 
 & \texttt{activation} & relu, tanh \\ 
 & \texttt{solver} & adam, sgd \\ \midrule
\multirow{4}{*}{SVM} & \texttt{kernel} & linear \\ 
& \texttt{penalty} & L1, L2 \\ 
 & \texttt{C} & 0.01, 0.1, 1.0 \\ 
 & \texttt{tol} & 0.001, 0.0001 \\ \midrule
\multirow{4}{*}{Random Forest} & \texttt{n\_estimators} & 10, 50, 200 \\ 
 & \texttt{max\_depth} & 10, 20, 30 \\ 
 & \texttt{min\_samples\_split} & 2, 5, 10 \\ 
 & \texttt{min\_samples\_leaf} & 1, 5, 10 \\ \midrule
\multirow{3}{*}{XGBoost} & \texttt{n\_estimators} & 50, 100, 200 \\ 
 & \texttt{max\_depth} & 3, 4, 5 \\ 
 & \texttt{learning\_rate} & 0.01, 0.1, 0.2 \\ \bottomrule
\end{tabular}
}
\end{table}

\subsection{Retraining Scenario Results}

This section contains detailed results on the performance of each of the four learning models 
under each of the three retraining scenarios. Note that every learning model is trained and tested
on a binary classification
problem, where ``Family~$X$ vs Family~$Y$'' indicates that Family~$X$ is segmented
into temporal subsets, with models trained, retrained, and tested 
based on these temporal subsets, with
Family~$Y$ simply serving as (fixed) ``not Family~$X$'' data for each trained model.
For each of our five malware families serves as Family~$X$ 
with selected choices for Family~$Y$, 
as some families are inherently easy to distinguish from each other, 
and the easiest cases would tend to mask the effect of concept drift.

\subsubsection{Static Training Results}

Recall that in the static training scenario, models are trained on the initial temporal subset,
and this model is then used to classify all remaining test samples.
This scenario represents a situation where concept drift is ignored, and it
serves as a baseline. The results of all of our static training experiments are 
summarized in the form of a bar graph in Figure~\ref{fig:caseA_All}. 

\begin{figure}[!htb]
    \centering
    \input figures/bar_A_all.tex
    \caption{Accuracies across all models for static training scenario}\label{fig:caseA_All}
\end{figure}

From Figure~\ref{fig:caseA_All},
we observe that Random Forest and XGBoost 
generally perform best, with MLP clearly the worst.
The poor results for MLP are likely due to a lack of training data,
since we only have~50 samples per batch.
We note that some families are much easier to distinguish
than others; for example the results for SMSreg vs Boxer are
among the best, while SMSreg vs Agent is among the worst-performing.

\subsubsection{Periodic Retraining Results}

In periodic retraining, models are updated at each interval, 
regardless of whether drift is detected. The results for these experiments
are given in Figure~\ref{fig:caseB_All}.

\begin{figure}[!htb]
    \centering
    \input figures/bar_B_all.tex
    \caption{Accuracies across all models for periodic retraining scenario}\label{fig:caseB_All}
\end{figure}

Comparing Figures~\ref{fig:caseA_All} and~\ref{fig:caseB_All}, 
we observe that the results for the periodic retraining scenario
are, on average, much better than those for the static training scenario.
This is not surprising, as any cases where significant concept drift occurs
will benefit from periodic retraining.

\subsubsection{Drift-Aware Retraining Results}

Under the drift-aware retraining scenario, 
models are only updated when concept drift is detected,
as determined by the changes in the average silhouette coefficient
when MiniBatch $K$-Means is applied to consecutive temporal batches,
as discussed in Section~\ref{sect:scenarios}.
The results for this scenario are given in Figure~\ref{fig:caseC_All}.

\begin{figure}[!htb]
    \centering
    \input figures/bar_C_all.tex
    \caption{Accuracies across all models for drift-aware scenario}\label{fig:caseC_All}
\end{figure}

Comparing Figures~\ref{fig:caseB_All} and~\ref{fig:caseC_All}, we observe
that the results for the drift-aware scenario appear to be comparable to those
obtained in the periodic retraining scenario. This indicates that we 
are detecting concept drift.

\subsection{Discussion}\label{sect:disc}

A summary of the average accuracies per scenario for each model is provided in Figure~\ref{fig:final_res_model}. As expected, all of
the models perform relatively poorly in the static scenario,
and much better under the periodic retraining scenario.
For the drift-aware scenario, the accuracy only declines 
slightly---less than~1\%, on average---as compared to periodic retraining, 
which indicates that we are indeed detecting concept drift. 
Given our experimental design, we would not expect that any concept drift 
detection approach would outperform periodic retraining. Furthermore,
given that our batch size is~50 samples, and that we cluster two consecutive
batches, it is clear that we will not always detect concept drift at the precise 
point at which it occurs. From this perspective, the results in 
Figure~\ref{fig:final_res_model} appear to be extremely positive.

\begin{figure}[!htb]
    \centering
    \input figures/bar_avg.tex
    \caption{Average results per model under each retraining scenario}
    \label{fig:final_res_model}
\end{figure}

In Figure~\ref{fig:final_res_model_per_family} in the Appendix, we further
break down the results in Figure~\ref{fig:final_res_model} per family.
Comparing the static scenario to the other two scenarios in these graphs,
it appears that Malap and SMSreg are the most affected by
concept drift, while Airpush, Agent, and Boxer are less affected.

In Figures~\ref{fig:per_period_A}, \ref{fig:per_period_B}, and~\ref{fig:per_period_C}
in the Appendix, we graph the per-interval accuracy for selected families and models
under the static training, periodic retraining, and drift-aware retraining scenarios, respectively.
We observe that Random Forest and SVM models consistently yield similar results
in each scenario, with XGBoost differing only slightly. The poor performance of  
MLP models is readily apparent in these graphs.

Interestingly, we observe from Figures~\ref{fig:per_period_A}(c) and~(d)
that even in the presence of substantial concept drift, the accuracy
under the static scenario
can improve at some points. While this may initially seem counterintuitive, 
a likely explanation is that some older variants have been recycled,
either with no modification, or with modifications that
do not affect the original model's accuracy. We also note that the
similarities between the two SMSreg graphs 
in each scenario---see the~(c) and~(d) graphs in 
Figures~\ref{fig:per_period_A}, \ref{fig:per_period_B}, 
and~\ref{fig:per_period_C}---serve to further emphasize
the accuracy and consistency of our concept drift detection strategy.

Finally, we consider the savings---in terms of the number of models 
that need to be trained---under the drift-aware scenario, 
as compared to the periodic retraining scenario.
Figure~\ref{fig:retraining_intervals} compares the number of models in the 
periodic retraining and drift-aware retraining scenarios for the Boxer family.
For this family, there are~69 temporal subsets, and hence there 
are~69 models trained in the periodic retraining scenario. 
For the Boxer family, we detect concept drift at~34
time intervals, which implies that for the drift-aware scenario, 
only~35 models are trained, which is a reduction of almost~50\%.
From Figure~\ref{fig:final_res_model_per_family}(d) in the Appendix, 
we see that, on average, this savings in training time
result in only a minimal loss of accuracy---ignoring the 
consistently poor-performing
MLP model, the loss of accuracy is less that~0.5\%, on average.

%%%%% This is incorrect
\begin{figure}[!htb]
    \centering
    \input figures/intervals.tex
    \caption{Retraining intervals for Boxer family}
    \label{fig:retraining_intervals}
\end{figure}

In Table~\ref{tab:retrain_intervals} we summarize the drift-aware training 
savings for each family. The savings
range from a low of less than~32\%\ for the Malap family, to a high of more 
than~49\%\ for Boxer, while the work reduction 
over all of the families considered is~39.48\%,
with a per-family average reduction of~40.03\%. Thus, our 
concept drift detection technique can be expected to reduce the number of models
that need to be trained by about~40\%, as compared to simply retraining at each
time interval. Furthermore, according to Figure~\ref{fig:final_res_model}, the loss in
accuracy is negligible under this efficient drift-aware scenario, as compared
to periodic retraining.

\begin{table}[!htb]
\def\zz{\phantom{0}}
\centering
\caption{Number of training intervals}\label{tab:retrain_intervals}
\adjustbox{scale=0.85}{
\begin{tabular}{c|ccc}
\toprule
\multirow{2}{*}{\textbf{Family}} & \multicolumn{2}{c}{\textbf{Retraining}} 
		& \multirow{2}{*}{\textbf{Savings}} \\ \cline{2-3} \\[-2.6ex]
	& \textbf{Periodic} & \textbf{Drift-aware}  \\ \midrule
Airpush & 154 & \zz96 & 37.66\% \\ 
SMSreg & \zz84 & \zz50 & 40.48\% \\ 
Malap & \zz70 & \zz48 & 31.43\% \\ 
Boxer & \zz69 & \zz35 & 49.28\% \\ 
Agent & \zz46 & \zz27 & 41.30\% \\ \midrule
Total & 423 & 256 & 39.48\% \\ \bottomrule
\end{tabular}
}
\end{table}


\section{Conclusion}\label{chap:con}

In this paper, we considered the utility of clustering as a means of detecting  
concept drift in the malware domain. We analyzed three different scenarios---static training,
periodic retraining, and drift-aware retraining---and for each of these scenarios,
we trained four different classification models: MLP, SVM, Random Forest, and XGBoost.
In the static training scenario, each learning model was trained on an initial temporal
batch of samples, after which no retraining occurred. This scenario
served as a baseline, and the relatively poor classification results showed 
that at least some degree of concept drift occurs in each of
the malware families tested, although the extent of the drift varied significantly
for different families.

In the periodic retraining scenario, we retrained each model whenever a new 
temporal batch of samples had been accumulated since the previous retraining.
Our results for this scenario demonstrate that we can greatly improve on the 
accuracy of the static training scenario by frequently retraining learning models. 
However, this periodic retraining approach is computationally costly, as models 
need to be constantly retrained. 

Under the drift-aware retraining scenario we only retrained models when
concept drift was detected. To detect concept drift, we employed MiniBatch $K$-Means
clustering and computed the average silhouette coefficient, with an empirically-determined
threshold serving to trigger model retraining. We found that this drift-aware retraining
approach yielded results that were only marginally worse than the periodic retraining scenario, while
being far more computationally efficient, due to less frequent retraining.
These results serve to verify that our clustering-based concept drift detection technique 
provides a practical and efficient method for 
improving the accuracy of malware classification models.

There are several potentially fruitful paths for future research. For example,
the analysis of the three retraining scenarios  
considered in this paper could be expanded to include additional malware families and 
learning techniques. In addition, our clustering-based detection strategy 
could be directly compared to---and possibly combined with---the machine 
learning based techniques in the related series of papers~\cite{Sunhera,Lolitha,Mayuri}.

As another avenue of future work, our clustering-based drift detection approach
could likely be improved by applying a more 
sophisticated analysis to the silhouette coefficients. In a similar vein, additional
thresholding work would likely improve on the results presented in this paper. It would also
be interesting to determine whether other clustering techniques---such as 
EM clustering and density-based clustering---could 
improve on the results presented in this paper.


\bibliographystyle{plain}
\bibliography{references}


\section*{Appendix}\label{app:a}

\titleformat{\section}{\normalfont\large\bfseries}{}{0em}{#1\ \thesection}
\setcounter{section}{0}
\renewcommand{\thesection}{\Alph{section}}
\renewcommand{\thesubsection}{A.\arabic{subsection}}
\setcounter{table}{0}
\renewcommand{\thetable}{A.\arabic{table}}
\setcounter{figure}{0}
\renewcommand{\thefigure}{A.\arabic{figure}}
%\section{Appendix}\label{app:a}

\subsection{Additional Silhouette Coefficient Graphs}

In this section, we provide silhouette coefficient graphs for the Agent, Airpush, and Boxer families
in Figures~\ref{fig:agent_sil}, \ref{fig:airpush_sil}, and~\ref{fig:boxer_sil}, respectively.
The silhouette coefficient graphs for the other two families, SMSreg and Malap,
appear in Section~\ref{sect:setup} is Figures~\ref{fig:SMS_sil} and~\ref{fig:malap_sil}, respectively.

%\begin{figure}[!htb]
%    \centering
%    \includegraphics[scale=0.5]{images/agent_sil.png}
%    \caption{Silhouette scores for Agent}\label{fig:agent_sil}
%\end{figure}
%
%\begin{figure}[!htb]
%    \centering
%    \includegraphics[scale=0.35]{images/airpush_sil.png}
%    \caption{Silhouette scores for Airpush}\label{fig:airpush_sil}
%\end{figure}
%
%\begin{figure}[!htb]
%    \centering
%    \includegraphics[scale=0.5]{images/boxer_sil.png}
%    \caption{Silhouette scores for Boxer}\label{fig:boxer_sil}
%\end{figure}

%%%%%%%%%%%%%%%%%%%%%%%

\begin{figure}[!htb]
    \centering
    \input figures/silGraphAgent.tex
    \caption{Silhouette score differences for Agent}\label{fig:agent_sil}
\end{figure}

\begin{figure}[!htb]
    \centering
    \input figures/silGraphAirpush.tex
    \caption{Silhouette score differences for Airpush}\label{fig:airpush_sil}
\end{figure}

\begin{figure}[!htb]
    \centering
    \input figures/silGraphBoxer.tex
    \caption{Silhouette score differences for Boxer}\label{fig:boxer_sil}
\end{figure}

\clearpage

\subsection{Drift Results per Family}

Here, we break down the results in Figure~\ref{fig:final_res_model} per family.
These graphs are discuss in Section~\ref{sect:disc}.

\begin{figure}[!htb]
    \centering
    \begin{tabular}{ccc}
    \input figures/bar_avg_Airpush.tex
    &
    \input figures/bar_avg_SMSreg.tex
    \\
    \adjustbox{scale=0.85}{(a) Airpush}
    &
    \adjustbox{scale=0.85}{(b) SMSreg}
    \\ \\[-1.25ex]
    \input figures/bar_avg_Malap.tex
    &
    \input figures/bar_avg_Boxer.tex
    \\
    \adjustbox{scale=0.85}{(c) Malap}
    &
    \adjustbox{scale=0.85}{(d) Boxer}
    \\ \\[-1.25ex]
    \multicolumn{2}{c}{\input figures/bar_avg_Agent.tex}
    \\
    \multicolumn{2}{c}{\adjustbox{scale=0.85}{(e) Agent}}
    \end{tabular}
    \caption{Average results per family}\label{fig:final_res_model_per_family}
\end{figure}

\subsection{Accuracy per Training Period}

In this section, we provide graphs of model accuracy per training period 
for selected families %(one-vs-one cases) 
and models. In Figure~\ref{fig:per_period_A} we give such results
for the static training scenario, while 
Figures~\ref{fig:per_period_B} and~\ref{fig:per_period_C} are
the corresponding results for the periodic retraining and drift-aware retraining scenarios,
respectively. These results are discuss in Section~\ref{sect:disc}.

\begin{figure}[!htb]
    \centering
    \begin{tabular}{cc}
    \adjustbox{scale=0.7}{%
    \includegraphics[scale=0.175]{images/airvsmal_XG_casea.png}
    }
    &
    \adjustbox{scale=0.7}{%
    \includegraphics[scale=0.175]{images/airvssms_mlp_casea.png}
    }
    \\
    \adjustbox{scale=0.85}{(a) Airpush vs Malap (XGBoost)}
    &
    \adjustbox{scale=0.85}{(b) Airpush vs SMSreg (MLP)}
    \\ \\[-0.5ex]
    \adjustbox{scale=0.7}{%
    \includegraphics[scale=0.175]{images/smsvsagent_RF_casea.png}
    }
    &
    \adjustbox{scale=0.7}{%
    \includegraphics[scale=0.175]{images/smsvsagent_SVM_casea.png}
    }
    \\
    \adjustbox{scale=0.85}{(c) SMSreg vs Agent (Random Forest)}
    &
    \adjustbox{scale=0.85}{(d) SMSreg vs Agent (SVM)}
    \end{tabular}
    \caption{Static training accuracy per interval (selected cases)}
    \label{fig:per_period_A}
\end{figure}

\begin{figure}[!htb]
    \centering
    \begin{tabular}{cc}
    \adjustbox{scale=0.7}{%
    \includegraphics[scale=0.175]{images/airvsmal_XG_caseb.png}
    }
    &
    \adjustbox{scale=0.7}{%
    \includegraphics[scale=0.175]{images/airvssms_mlp_caseb.png}
    }
    \\
    \adjustbox{scale=0.85}{(a) Airpush vs Malap (XGBoost)}
    &
    \adjustbox{scale=0.85}{(b) Airpush vs SMSreg (MLP)}
    \\ \\[-0.5ex]
    \adjustbox{scale=0.7}{%
    \includegraphics[scale=0.175]{images/smsvsagent_RF_caseb.png}
    }
    &
    \adjustbox{scale=0.7}{%
    \includegraphics[scale=0.175]{images/smsvsagent_SVM_caseb.png}
    }
    \\
    \adjustbox{scale=0.85}{(c) SMSreg vs Agent (Random Forest)}
    &
    \adjustbox{scale=0.85}{(d) SMSreg vs Agent (SVM)}
    \end{tabular}
    \caption{Periodic retraining accuracy per interval (selected cases)}
    \label{fig:per_period_B}
\end{figure}

\begin{figure}[!htb]
    \centering
    \begin{tabular}{cc}
    \adjustbox{scale=0.7}{%
    \includegraphics[scale=0.175]{images/airvsmal_XG_casec.png}
    }
    &
    \adjustbox{scale=0.7}{%
    \includegraphics[scale=0.175]{images/airvssms_mlp_casec.png}
    }
    \\
    \adjustbox{scale=0.85}{(a) Airpush vs Malap (XGBoost)}
    &
    \adjustbox{scale=0.85}{(b) Airpush vs SMSreg (MLP)}
    \\ \\[-0.5ex]
    \adjustbox{scale=0.7}{%
    \includegraphics[scale=0.175]{images/smsvsagent_RF_casec.png}
    }
    &
    \adjustbox{scale=0.7}{%
    \includegraphics[scale=0.175]{images/smsvsagent_SVM_casec.png}
    }
    \\
    \adjustbox{scale=0.85}{(c) SMSreg vs Agent (Random Forest)}
    &
    \adjustbox{scale=0.85}{(d) SMSreg vs Agent (SVM)}
    \end{tabular}
    \caption{Drift-aware retraining accuracy per interval (selected cases)}
    \label{fig:per_period_C}
\end{figure}

\clearpage

\end{document}
