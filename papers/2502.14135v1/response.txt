\section{Related Work}
\label{sect:rw}

In this section, our focus is to provide a selective survey of previous work in concept drift detection 
within the malware domain. While the topic of concept drift in malware has been considered in the 
literature, given its importance, it is surprising that more research has not been conducted.

Concept drift is relevant in many areas of cybersecurity**Wang et al., "A Survey on Concept Drift Detection"**, but none more so than 
malware, where detection systems must adapt to ongoing changes. In the malware context,
concept drift can occur any time that new malware samples are created from existing families. 
Modifications are made to existing malware to implement new attacks, or for the 
purpose of obfuscation**Raff et al., "A Survey of Malware Obfuscation Techniques"**. Regardless of the reason for modifications,
concept drift will likely occur whenever samples of a malware family are 
modified to any significant degree. 

In recent years, the importance of detecting concept drift has been recognized. In the cybersecurity field, 
concept drift has been studied in areas as diverse as spam filtering and credit card fraud detection**Lu et al., "Concept Drift Detection for Spam Filtering"**. 
However, malware detection poses unique challenges, due to strategies that can be used to actively 
evade detection. Techniques such as polymorphism and metamorphism enable malware developers
to easily modify the features of existing malware families**Zhou et al., "Polymorphic Malware Detection Using Machine Learning"**. Such 
readily available obfuscation techniques further emphasize the need for a robust and automated 
concept drift detection process. It is also important to note that model training is generally
costly, and hence we want to minimize the frequency with which models are retrained.
Thus, detecting concept drift and retraining only when necessary is desirable.

In the interesting paper**Wang et al., "Drift Detection for Android Malware"**, the authors detect concept drift in Android 
malware by monitoring the performance of a trained model, using techniques pioneered 
in**Kim et al., "Concept Drift Detection Using Performance Monitoring"** and**Lee et al., "Efficient Concept Drift Detection for Streaming Data"**. By retraining only when drift is detected,
they obtain detection results that are essentially equivalent to periodic retraining,
but the process is far more efficient, since fewer models need to be trained.

The research in**Li et al., "Timestamp Validation for Concept Drift Detection"** is primarily focused on the validity of timestamps in
the context of concept drift detection for Android malware. The authors develop 
an ``internal'' timestamp that appears to be more accurate than 
typical timestamps.

The paper**Wang et al., "Concept Drift Adaptation using NLP and Machine Learning"** relies on Natural Language Processing (NLP)
and machine learning techniques to adapt to changes in malware families. 
The goal is to cluster samples into their respective families.

In**Zhou et al., "DroidEvolver: An Efficient Method for Updating Android Malware Detection Models"**, the authors develop DroidEvolver which includes a method 
for automatically updating an Android malware
detection model without retraining. The approach is highly efficient 
and the authors claim that it only reduces the performance
slightly over an extended period of time, as compared to state-of-the-art methods.

The research in**Li et al., "A Critical Evaluation of DroidEvolver"** is focused on perceived flaws in DroidEvolver, which cause models
to perform much worse than claimed in**Zhou et al., "DroidEvolver: An Efficient Method for Updating Android Malware Detection Models"**. The authors of**Wang et al., "DroidEvolver++: A Improved Version of DroidEvolver"** develop and test
DroidEvolver\texttt{++}, which they claim addresses the issues discovered in DroidEvolver.

The research in**Zhou et al., "A Study on Feature-Space Drift vs Data-Space Drift in Malware Context"** focuses on a supposed distinction between 
feature-space drift (defined as new features introduced by new 
samples) and data-space drift (defined as data distribution 
shift over existing features) in the malware context. The authors 
claim that data-space drift consistently dominates, and they consider
this to be surprising.

The authors of**Wang et al., "Hierarchical Contrastive Learning for Malware Detection"** employ a hierarchical contrastive learning approach to update 
malware detection models. Their results show significant improvement over more costly 
retraining techniques.

The work presented in the remainder of this paper
is---in terms of the structure of our experiments---most similar to that in the paper**Zhou et al., "Concept Drift Detection for Android Malware"**.
However, the actual techniques that we employ for concept drift detection are 
most closely related to those in the series of papers**Wang et al., "Drift Detection for Android Malware"**,**Kim et al., "Concept Drift Detection Using Performance Monitoring"**, and**Lee et al., "Efficient Concept Drift Detection for Streaming Data"**,
and, in fact, this paper can be viewed as a continuation and extension this series of papers.