\section{Backgrounds}
\label{sec:rel}
% 在本节，我们介绍当前仿真数据合成的进展，以及\textsc{CustomGen}潜在能解决的应用需求。
In this section, we first review the latest developments in data synthesis \S\ref{sec:syndata} and then discuss the potential values of developing a generic benchmark generator \S\ref{sec:app}.
\subsection{Synthetic Data Generation}
\label{sec:syndata}
% 要把训练、测试数据的区别做强调
% 要把当前合成测试数据的痛点做强调

% 得益于语言模型能力的增长，LLM as dataset generator开始被广泛研究并展现了比传统数据合成方法显著更佳的潜力。其中，LLM-driven 训练数据合成领域
% 围绕数据飞轮的构建，训练数据合成收获了最多的关注。通过在特定领域合成数据进行训练，如数学，科学，代码，LLM能够取得显著的性能突破。
The growth of language model abilities has led to widespread research on LLM-driven data synthesis, which demonstrates much better quality and controllability over traditional approaches \citep{datasurvey1,datasurvey2}. 
Centering around the construction of data flywheel (LLM-driven evolution) \citep{flywheel1,flywheel2}, training data synthesis has garnered much attention in fields like mathematics \citep{datamath}, science \citep{datasci}, and code \citep{datacode}, continuously pushing LLMs' capability boundaries.
% 与训练集合成以优化模型性能为最终目标不同，benchmark合成的最终优化目标是准确评估模型性能，这在衡量和实现上都有着更大的挑战。
Unlike the training data synthesis aimed at optimizing model performance, the goal of benchmark synthesis is to accurately evaluate models on specific task, presenting greater challenges in both measurement and implementation \citep{evalsurvey}. 
% 在measurement方面，当前的研究往往关注特定的criteria，未能建立一个全面的benchmark generator评价体系。
% 在implementation方面，当前的benchmark generator难以摆脱对已有benchmark或者是任务的依赖，无法实现CUSTOMGEN的愿景。
In terms of measurement, recent studies \citep{dyval,databench,perteval} generally focus on specific criteria, without establishing a comprehensive evaluation system for benchmark generators.
In terms of implementation, current benchmark generators \citep{modelwritten,unigen,dyval2,s3eval} are constrained by their dependence on existing benchmarks and task specific designs, preventing them from being generic. We construct a comprehensive  evaluation framework and develop generic and reliable \textsc{BenchMaker} method to fill this gap. 


\subsection{Potential Applicable Scenarios of \textsc{BenchMaker}}
\label{sec:app}
% 给定任意assessment demands, \textsc{CustomGen}被期待输出一个高质量的、符合需求的benchmark。
% 我们如下总结\textsc{CustomGen}能够解决的问题与适用的场景：
%  (1) 作为当前benchmark无法满足的assessment demands的补充
% （2）作为动态benchmark生成器，缓解数据污染的问题
% （3）通过对于benchmark难度的调控，缓解LLM能力快速增长导致的benchmark饱和的问题。
% （4）或许可以扮演训练集生成器
% 因此，打造\textsc{BenchMaker}对于自然语言社区的科学研究和实际应用都具有重要意义。
Given arbitrary assessment demands $X$ as the sole input, a generic benchmark generator (\textsc{BenchMaker}) $\mathcal{G}$ is expected to generate a well-aligned high-quality benchmark $\mathcal{D}$.
On this basis, we summarize its applicable scenarios as follows: (1) Complementing existing benchmarks for tailored assessment demands; (2) Acting as a dynamic benchmark generator to alleviate data contamination issues \citep{datacontamination}; (3) Serving as a difficulty controllable benchmark generator to mitigate the benchmark saturation problem \citep{saturation}; (4) Functioning as a versatile training data generator. 
Therefore, building \textsc{BenchMaker} holds significant importance for both scientific research and practical applications within the NLP community. 