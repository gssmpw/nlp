

In this section, we present offline evaluations of GiGL on both public benchmarks as well as production graphs in different sizes to showcase time and resource efficiency of GiGL. We experiment with an internal homogeneous graph that is used for friend recommendation, which has $\sim${900M} nodes, $\sim${16.8B} edges, 249 node features, and 19 edge features. Due to space limit, we leave the comprehensive dataset details in \cref{appx:dataset}.

\cref{tab:scale} showcases the component-level runtime comparison of GiGL running on the internal graph and one public benchmark, MAG240M\footnote{We also offer example codes for running MAG240M end-to-end with GiGL at: \url{https://github.com/snap-research/GiGL/tree/main/examples/MAG240M}}~\citep{hu2021ogblsc}. We can observe that GiGL is able to finish end-to-end on the full industry-scale graph within 12 hours, making it feasible for product use-cases. Additionally, from the time comparison of the different versions, we can observe that the number of edges generally has a bigger impact on the runtime, aligning with GNNs' time complexity which is linear with the number of edges~\citep{wu2020comprehensive}. Beyond these graph scaling experiments, we also conducted additional offline experiments of GiGL with varying resources and setups, which are included in \cref{tab:scale-het,tab:resource} in \cref{appx:experiments}. 
