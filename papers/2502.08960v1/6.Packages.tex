\section{Resources}
\label{sec:packages}
\input{table}
With the growing attention on imbalanced data, as shown in Table 1, researchers have developed an expanding array of tools to address the challenges it presents. Santos \cite{santos_imbalance_overlap} spearheaded a project summarizing many open-source contributions in this domain, including benchmark datasets, data generation and visualization tools, class overlap-based methods, data complexity measures, and software designed for learning from imbalanced data. However, some tools remain either insufficiently detailed or absent from the summary. For benchmarks, Qin et al. \cite{qin2024iglbench} introduced IGL-Bench, the first comprehensive benchmark dedicated to imbalanced graph learning. IGL-Bench integrates 16 diverse datasets, such as Cora and PubMed, along with 24 state-of-the-art algorithms, addressing both class and topological imbalances in node-level and graph-level tasks. It ensures fair comparisons by employing unified data segmentation rules, standardized imbalance ratio definitions, and fixed splits for training, validation, and testing. Furthermore, it incorporates multi-dimensional evaluation metrics, such as accuracy, balanced accuracy, macro F1, and AUC, providing a rigorous framework for assessing algorithm performance.In terms of software, several notable tools were not included in Santosâ€™ project. One example is \textit{imbalanced-ensemble}, developed by Liu et al. \cite{liu2021imbens}. This open-source Python toolbox employs undersampling techniques in algorithms like BalancedRandomForest and UnderBagging, which randomly sample subsets from the majority class to train individual base classifiers. It also leverages SMOTE in methods such as SmoteBoost and SmoteBagging to synthesize minority class samples. Additionally, the toolbox uses cost-sensitive approaches to adjust learning objectives, prioritizing minority class performance. The package includes visualization tools, such as Confusion Matrix Heatmaps, to facilitate intuitive performance analysis.Another noteworthy contribution is \textit{Balance}, developed by Sarig et al. \cite{sarig2023balance}. This Python toolkit adjusts and evaluates biased sample data using weighted approaches to align distributions with the target population. Its workflow includes diagnosing initial biases, generating weights via methods like propensity scores, and evaluating the impact of these weights on bias reduction and variance inflation. Balance also supports interactive visualization and diagnostic metrics, such as ASMD, offering researchers a streamlined and flexible API for bias adjustment and analysis.
