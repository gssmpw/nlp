\section{Introduction}
\label{sec:intro}
Diagrams, which visually organize and present information, are one of the most powerful methods for combining text and visual representation in documents. For instance, diagrams are widely utilized in business documentation as effective tools for information communication, such as explicitly illustrating relationships between elements in system architecture blueprints or clarifying complex procedures and processes step by step using flowcharts. 
Recently, with the rapid development of large language models (LLMs)\citep{openai_gpt-4_2024, anil_palm_2023}, methods for processing textual information have become increasingly sophisticated. Applications such as QA systems combined with knowledge bases derived from documents \citep{krishna_fact_2024, fleischer_rag_2024}, efficient document creation and information sharing through automated summarization and report generation \citep{thoppilan_lamda_2022, liu_mmbench_2025}, and automation of compliance verification tasks \citep{cava_safeguarding_2024, kande_security_2024, sollenberger_llm4vv_2024} have made it possible to automate complex tasks traditionally performed manually. This has significantly accelerated the efficiency and standardization of business processes.

\begin{figure}[tbp]
    \vspace{-5pt}
    \centering
    \includegraphics[width=0.85\textwidth]{figures/concept.pdf}
    \caption{\small
    Our approach does not rely on the visual recognition of the VLM, but rather inputs and analyzes the LLM as text, with the underlying graphic information stored in the source files referenced to render the Diagram image.
    }
    \label{fig:concept}
    \vspace{-10pt}
\end{figure}

Moreover, with the advent of Vision-Language Models (VLMs) capable of understanding images \citep{openai_gpt-4o_2024, noauthor_gpt-4vision_2023, fu_vita-15_2025, noauthor_introducing_2024}, there is increasing potential to enhance workflow efficiency by processing not only textual information but also diagrams as images.
VLMs, particularly proprietary models, have achieved remarkable results in diverse tasks such as generating captions for general images like photographs and illustrations, and visual question answering (VQA) \citep{openai_gpt-4o_2024, noauthor_introducing_2024}
Additionally, significant progress has been made in visual reasoning tasks that analyze more symbolic visual information, such as diagrams, fostering growing expectations for automated systems that integratively analyze text and diagrams\citep{lu_mathvista_2024, zhang_mathverse_2024, chen_how_2024}

While these new possibilities are expanding, it is not easy to accurately grasp and extract the structure and interrelationships among the elements shown in a diagram, and many challenges still remain to be overcome before they can be implemented in actual work. 
For example, VLM has been shown to be limited in geometric recognition of images composed of shapes \citep{kamoi_visonlyqa_2024, zhang_mathverse_2024, yue_mmmu_2024}, and the stage of correctly textualizing geometric structures is reported to be a bottleneck in question-answering (QA) and inference tasks using diagrams \citep{ye_beyond_2024}.
In tasks such as question answering (QA) or reasoning about diagrams, the stage of correctly textualizing geometric structures has been reported as a bottleneck \citep{ye_beyond_2024}.
In addition, images containing complex geometric primitives, such as decorative representations of overlapping adjacent lines and shapes, are prone to misidentification by VLMs \citep{rahmanzadehgervi_vision_2024}, and existing VLMs are not robust enough for the variety of color schemes and drawing formats found in real documents \citep{ye_beyond_2024, singh_flowvqa_2024, tannert_flowchartqa_2023}.
Furthermore, while VLMs are relatively good at recognizing entities (graphics) such as system blueprints and flowcharts, it is still difficult to accurately grasp the relationships between elements represented by lines\citep{giledereli_vision-language_2024}, and they tend to halucinate when their previously learned knowledge is inconsistent with the input visual information\citep{mukhopadhyay_unraveling_2024, giledereli_vision-language_2024}.
Considering these limitations, it is essential to develop methods that mitigate the visual capability constraints of VLMs to effectively utilize language models in business scenarios and other contexts involving visually enriched documents.

In this study, we propose a novel approach that does not process diagrams as images but instead extracts and transforms the shape information stored within source files, enabling analysis of this information as text data using 'LLMs'. In business scenarios, documents often exist in editable source file formats such as docx, xlsx, and pptx before being converted into PDF format \citep{noauthor_isoiec_nodate}.  The entity of this source file is XML, which can be parsed to directly extract information on shapes, lines, annotations, and other elements that make up the diagram, and this information can be provided to LLM as text input to bypass visual recognition bottlenecks and enable comprehensive understanding and analysis of diagrams. In this study, system design documents from requirements definitions created in Excel, commonly used in Japanese system development workflows, were prepared. Using these documents, we conducted evaluations by posing several business-relevant questions to compare the proposed method with a VLM-based approach. The results confirmed that while VLMs were unable to answer certain questions accurately, the proposed method provided accurate answers. This study demonstrates the potential of analysis through source file, such as XML, processing to overcome the challenges of diagram comprehension in VLMs. It highlights the possibility of improving workflows and achieving greater efficiency in information utilization systems leveraging LLMs in business contexts.

