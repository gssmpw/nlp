\section{Related Works}
\subsection{Visual Recognition Limitation of VLM in Diagram Understanding}
As various verification studies have been reported in the development of VLM, challenges in its visual recognition performance have come to light.
For example, VLM has been shown to be limited in geometric recognition of images composed of shapes \cite{kamoi_visonlyqa_2024, zhang_mathverse_2024, yue_mmmu_2024}, and the stage of correctly textualizing geometric structures is reported to be a bottleneck in question-answering (QA) and inference tasks using diagrams \cite{ye_beyond_2024}.
In tasks such as question answering (QA) or reasoning about diagrams, the stage of correctly textualizing geometric structures has been reported as a bottleneck \cite{ye_beyond_2024}.
In addition, images containing complex geometric primitives, such as decorative representations of overlapping adjacent lines and shapes, are prone to misidentification by VLMs \cite{rahmanzadehgervi_vision_2024}, and existing VLMs are not robust enough for the variety of color schemes and drawing formats found in real documents \cite{ye_beyond_2024, singh_flowvqa_2024, tannert_flowchartqa_2023}.
Furthermore, while VLMs are relatively good at recognizing entities (graphics) such as system blueprints and flowcharts, it is still difficult to accurately grasp the relationships between elements represented by lines\cite{giledereli_vision-language_2024}, and they tend to halucinate when their previously learned knowledge is inconsistent with the input visual information\cite{mukhopadhyay_unraveling_2024, giledereli_vision-language_2024}.
Considering these limitations, it is essential to develop methods that mitigate the visual capability constraints of VLMs, such as the method presented in this study, to effectively utilize language models in business scenarios and other contexts involving visually enriched documents.

\subsection{The Role of Source File Information in Improving Visual Recognition and Understanding by VLMs and LLMs}
When enabling VLMs and LLMs to understand rendered formats of source files that humans typically view, there are several examples of using source file information as input to facilitate their understanding. 
In the field of VLM-based GUI understanding, while screenshots of screens are input as images, the performance of recognition is enhanced by simultaneously providing layout and positional information of widgets and buttons, along with textual descriptions, as text input \cite{you_ferret-ui_2024, li2024ferret}. Moreover, methods that directly input sources containing metadata such as text information and document structure, like HTML or docx, into models have been reported to improve the accuracy of document comprehension and analysis tasks in VLMs \cite{xu2020layoutlmv2, huang2022layoutlmv3, tan2024htmlrag}.
In the context of diagram comprehension, while there are no studies explicitly demonstrating the advantages of using metadata information from source files, many results suggest its potential. For example, a study analyzing the task of flowchart comprehension, which separates the phase of generating Mermaid notation from flowchart images through visual recognition and the phase of answering questions about the flowchart using the Mermaid text representation, demonstrated that the bottleneck lies in the image-to-Mermaid conversion\cite{ye_beyond_2024, pan_flowlearn_2024}. It also showed that once the correct topology is understood, answering questions about the flowchart is not challenging. These findings, combined with the multiple reports of the visual recognition limitations of VLMs highlighted in the previous section, support the effectiveness of utilizing source file information in diagram comprehension within documents and align with the results of this study.
