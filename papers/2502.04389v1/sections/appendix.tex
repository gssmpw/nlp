\newpage


\appendix
\section*{Appendix}
\renewcommand{\thesubsection}{A.\arabic{subsection}}

\subsection{Limitations}
\begin{itemize}
\item \textbf{Potential XML parsing issues due to Excel version differences:} Depending on the Excel version or individual settings, the underlying XML structure and attributes can vary, possibly leading to parsing inconsistencies or errors.
\item \textbf{Limited support for diverse objects within Office files:} Our approach currently targets standard shapes and connectors. Grouped or composite shapes, SmartArt, and specialized WordArt objects may not be fully supported.
\item \textbf{JSON input format constraint:} While we use JSON to provide shape and connector information to the LLM, alternative structured formats or more natural-language-like representations could be explored for improved flexibility or readability.
\item \textbf{Insufficient quantitative evaluation:} The effectiveness of the proposed approach has been illustrated primarily through case-based examples. Objective metrics such as accuracy or F1-scores would better validate performance.
\end{itemize}

\subsection{Future Work}
\begin{itemize}
\item \textbf{Applying the method to other Office file formats:} Extending this approach to PowerPoint (.pptx), Word (.docx), or Visio (.vsdx) opens up broader use cases and ensures generalizability.
\item \textbf{Handling more complex, real-world requirement documents:} Business documents often contain intricate layouts and multiple layers of grouping. Verifying how well our method can cope with these complexities is crucial for industrial adoption.
\item \textbf{Establishing XML-oriented design guidelines:} A potential methodology is to standardize document creation rules—avoiding excessive grouping or overly complex objects—to streamline both human readability and machine parsing in real business processes.
\item \textbf{Exploring RAG (Retrieval-Augmented Generation) approaches:} When using Excel or other Office files as data sources, it is important to investigate how to integrate RAG efficiently and manage data for effective retrieval.
\item \textbf{Hybridizing text- and vision-based methods:} In certain scenarios, combining VLM-based visual recognition (e.g., for icons) with XML-based extraction of connectors and shapes may offer a robust, hybrid solution that leverages the strengths of both approaches.
\end{itemize}



\begin{figure}[tbp]
    \vspace{-5pt}
    \centering
    \includegraphics[width=0.85\textwidth]{figures/appendix_prompt_wo_img.pdf}
    \caption{\small
    Prompts used in text-driven diagram comprehension. The prompts were used where the blue text was replaced with the corresponding information.}
    \label{fig:prompt1}
\end{figure}


\begin{figure}[tbp]
    \vspace{-5pt}
    \centering
    \includegraphics[width=0.85\textwidth]{figures/appendix_prompt_w_img.pdf}
    \caption{\small Prompts used in diagram comprehension with image input}
    \label{fig:prompt2}
    \vspace{-10pt}
\end{figure}

\subsection{Prompts Used in the Experiment}

All experiments in this study were conducted on GPT4o \citep{openai_gpt-4o_2024} (gpt-4o-2024-08-06).
The prompts used in result \ref{sec:result1} are shown in Figure \ref{fig:prompt1} and the prompts used during result \ref{sec:result2} are shown in Figure \ref{fig:prompt2}. For understanding entities on the conventions, the diagram information in JSON format shown in Figure \ref{fig:data_trans} was included in the prompts, and the information for each attribute in the JSON was given an explanation as shown in Figure \ref{sec:result1}. In addition to the JSON diagram information and information on each attribute, information on entities obtained through entity understanding was also added to the prompts to infer the relationships on the diagrams. For the image input, we used prompts that were not changed from those of the proposed method as much as possible, but only the descriptions added to give information in text were excluded.
