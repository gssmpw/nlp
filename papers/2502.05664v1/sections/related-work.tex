\begin{figure*}[h]
    \centering
    \includegraphics[width=0.99\textwidth]{figures/qualitative-example.pdf}
    \caption{Example of Plan Validation using Simulation (left) and Debugging using Simulation (right) on two different problems using \toolnospace.}
    \label{fig:qualitative-example}
\end{figure*}  

\section{Related Work}
\label{sec:related-works}
\textbf{Code Generation:}
Program synthesis has been a fundamental challenge in AI for decades \cite{Zohar71}. Early attempts with smaller language models centered on code generation by fine-tuning neural networks \cite{wang2021codet5, ahmad2021unified, feng2020codebert, parvez-etal-2018-building, deep_net_for_source_code, code_gen_parsing, cmu_code_gen, naturalnessofsoft}, while others explored leveraging data flow information or conversational intents to guide the process \cite{andreas-etal-2020-task, yu-etal-2019-cosql}. Various prior approaches have also addressed code generation tasks using techniques such as data flow analysis and search-based methods \cite{li2022competition, parisotto2017neural, polozov2015flashmeta, gulwani2011automating}.
\smallskip \\
\noindent{\bf LLMs for Code:}
Various LLMs have been developed for code synthesis~\citep{austin2021program, chen2021evaluating, nijkamp2022codegen, fried2022incoder, allal2023santacoder, alphacode}. Recent open-source LLMs include the Llama family (Llama-2, CodeLlama, Llama3.1, etc.) \citep{roziere2023code, touvron2023llama}, the Mistral family (Mistral, Mixtral, Codestral) \citep{jiang2023mistral}, the Deepseek family (Deepseek Coder, Deepseek-V2, etc.) \cite{guo2024deepseek}, MoTCoder \cite{li2023motcoder}, and the Qwen family (Qwen 1.5, 2.5, 2.5-coder, etc.) \cite{hui2024qwen2}, all of which are capable of solving many basic problems.
\smallskip \\
\noindent{\bf Prompting LLMs and Multi-Agent Code Generation:}
LLM prompting can be summarized into three categories: retrieval \cite{yasunaga2023large, parvez2021retrieval, parvez-etal-2023-retrieval}, planning \citep{jiang2023self, wei2022chain}, and debugging \citep{le2022coderl, chen2022codet, chen2023teaching, ridnik2024code}, in addition to direct code generation approaches. In contrast, our work combines all these paradigms and bridges their gaps (See Table \ref{tab:feature-compare-table}). Recently, numerous works have explored multi-agent code generation and problem-solving, including \cite{kulesza2004generative, jin2024mare, phan2024hyperagent}, as well as approaches highlighted in Section \ref{sec:intro}. However, \tool uniquely features simulation-driven planning and LLM-based debugging. More recently, external debugging has emerged to further boost performance, such as LDB \cite{zhong-etal-2024-debug}, ChatDebug \cite{levin2024chatdbg}, and MGDebugger \cite{shi2024code-mgdebug}, which serve as a \emph{second pass} after our generation.

\input{tables/feature-comparison}


