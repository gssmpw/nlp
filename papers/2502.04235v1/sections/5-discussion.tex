\section{Ablations and Discussions}
\label{sec:ablations}

\subsection{How important is to construct a proper prompt engineering target?}
\label{sec:ablation_pe}
\vspace{-0.5em}
In this section, we provide a further explanation of \textbf{``Limited Consistency''} introduced in Section~\ref{sec:implementation_details}.
The concept centers on balancing ``variance and invariance'' in the reformulation process.
To quantitatively understand this trade-off, we investigate two prompt engineering strategies through controlled experiments.

\vspace{-0.5em}
\subsubsection{Information Preservation Trade-off}

As shown in~\autoref{fig:ablation_pes}, we design two prompt variants:
(1) a strict version that enforces high fidelity to source information,
and (2) a relaxed version that allows substantial deviations while maintaining basic topical relevance.
Using these prompts, we collect training data from the same samples to train two SLM models,
denoted as SLM-Strict and SLM-Relaxed respectively.
The SLM performance comparison is presented in~\autoref{table:ablation_pe_scores}.

\begin{table*}[h]
    \vspace{-1em}
    \centering
    \caption{Performance comparison of different SLM variants on reformulation quality metrics.}
    \begin{adjustbox}{max width=0.9\textwidth}
    \setlength{\tabcolsep}{1mm}{
    \begin{tabular}{lcrrcrrccc}
        \toprule
        Models & Total & \multicolumn{1}{c}{5} & \multicolumn{1}{c}{4} & 3 & \multicolumn{1}{c}{2} & \multicolumn{1}{c}{1} & Rate($\leq 2$) & Rate($\geq 4$) & Rate($= 5$) \\
        \midrule
        SLM-Base   & 15,355 & 3,788 & 7,124 & 3,224 &   736 &   285 & 6.65\% & 71.06\% & 24.67\% \\
        SLM-Strict & 15,355 & 6,814 & 5,220 & 2,384 &   520 &   227 & - & \textbf{78.37\%} & \textbf{44.38\%} \\
        SLM-Relaxed& 15,355 &   408 & 1,685 & 3,889 & 4,156 & 5,086 & \textbf{60.19\%} & - & - \\
        \bottomrule
    \end{tabular}
    }
    \end{adjustbox}

\label{table:ablation_pe_scores}
\end{table*}

For this ablation study, we sample an additional 20B tokens from real data
and generate three synthetic datasets: 80B tokens using SLM-Base, 80B tokens using SLM-Strict, and 40B tokens using SLM-Relaxed.
Following the experimental setup in Section~\ref{sec:main_exp},
we compare MAGA-Mix and MAGA-Only data recipe against a baseline created by replicating the original 20B tokens 10 times.
\vspace{-0.5em}
\subsubsection{Impact on Model Training}
\vspace{-0.5em}
As shown in~\autoref{fig:ablation_pe_training}, our MAGA-Mix setting experiments reveal distinct patterns across training configurations.
Both SLM-Base and SLM-Strict demonstrate performance improvements, while the SLM-Relaxed configuration leads to significant collapse.
A more pronounced performance gap is observed in the MAGA-Only setting presented in Appendix~\ref{sec:appd_abaltion_details}.

\begin{figure}[h]
    \centering
    \includegraphics[width=\linewidth]{figures/ablation-pe-maga-mix.pdf}
    \vspace{-2em}
    \caption{Benchmark results and validation losses in the MAGA-Mix setting. The sensitivity to data repetition varies across capability domains, with knowledge dimension showing greater resilience.}
    \label{fig:ablation_pe_training}
\end{figure}
\vspace{-0.5em}
Despite the apparent effectiveness of strict information preservation,
can it fundamentally address the challenges posed by data repetition?
Our examination of validation loss trajectories reveals a critical distinction:
SLM-Base maintains healthy optimization characteristics throughout training,
whereas SLM-Strict exhibits degraded scaling behavior at higher iteration steps,
reminiscent of the limitations observed with data repetition.


\begin{figure*}[h]
    \centering
    \vspace{-1em}
    \includegraphics[width=\linewidth]{figures/ablation-pe-tsne.png}
    \vspace{-2.5em}
    \caption{t-SNE visualization results. Base (left) maintains a distribution that overlaps with but extends beyond the original data.
    Strict (middle) clusters also extend original data, but indicating limited diversity compared to left. Relaxed (right) shows significant distributional shift, explaining its poor performance.}
    \label{fig:ablation_pe_tsne}
\end{figure*}
To provide deeper insights into these behaviors, we analyze the embedding space distributions through t-SNE visualization (\autoref{fig:ablation_pe_tsne}).
SLM-Strict achieves moderate distribution expansion beyond the source domain,
yet more constrained compared to SLM-Base's balanced extension.
Meanwhile, SLM-Relaxed's excessive drift demonstrates the importance of maintaining appropriate distributional constraints.


These findings highlight the critical importance of proper prompt design in synthetic data generation.
Too strict preservation may limit the benefits of data synthesis,
while too loose constraints can lead to model collapse.
Our Base strategy achieves an effective balance, enabling both quality preservation and beneficial variations
that contribute to improved model performance.

\subsection{Is there a ``model collapse'' phenomenon training with MAGA?}
\label{sec:disscuss_model_collapse}
In Section~\ref{sec:scaling_exp} and \ref{sec:ablation_pe}, we both observe that the validation loss of MAGA group is significantly higher than that of the real data group.
This raises an important question: does this loss degradation indicate a potential ``model collapse'',
as suggested by recent work using loss as measurement~\citep{dohmatob2024talecollapse,dohmatob2024strongcollapse,zhu2024synthesize}.
Our investigation reveals a more nuanced picture.

\subsubsection{Multi-perspective Validation Analysis}
Our analyses across different validation sets reveal varying patterns in model behavior (\autoref{fig:val_loss}).
As expected, MAGA groups' substitution of fineweb-edu data results in adverse effects on corresponding loss, with similar deterioration observed in open-web-math.
Interestingly, the synthetic dataset Cosmopedia-V2 demonstrates improved loss metrics.
A notable contrast emerges in python-edu performance: while MAGA groups exhibit negative impact at the 134M and 377M parameter, this trend reverses at 1.7B, suggesting scale-dependent effects on model behavior.

\begin{figure*}[h]
\centering
\includegraphics[width=\linewidth]{figures/ablation-sec2-losses.pdf}
\vspace{-2em}
\caption{validation losses of experiments in Section~\ref{sec:main_exp}.}
\label{fig:val_loss}
\end{figure*}
\vspace{-1em}

\subsubsection{Fine-grained Pattern Analysis}
To better understand whether the increased validation loss truly indicates model collapse,
we conduct a fine-grained analysis of loss patterns.
Specifically, we compare token-level losses between models trained on real data and MAGA-Mix data (800B checkpoint), using samples from both Fineweb-Edu and MAGACorpus.
As illustrated in subfigures 1 and 3 of \autoref{fig:doc_loss},
each point represents a sample's average token loss,
consistent with the overall loss discrepancy shown in \autoref{fig:val_loss}.

\begin{figure*}[h]
    \vspace{-1em}
    \centering
    \includegraphics[width=\linewidth]{figures/ablation2_losses.png}
    \vspace{-2em}
\caption{Losses pattern analysis. Subfigures 1 and 3 shows comparison between models trained on different data settings, with $loss_{\text{real}}$ on y-axis and $loss_{\text{synt}}$ on x-axis.
Subfigures 2 and 4 track the position where $loss^i_{\text{synt}}-loss^i_{\text{real}}$ ($loss^i_{\text{diff}}$) first becomes significantly higher than the sequence's average difference (detailed definition in Appendix~\ref{sec:appd_abaltion_details}).}
\label{fig:doc_loss}
\end{figure*}

The distribution of first anomaly positions (subfigures 2 and 4) reveals a crucial insight:
when processing real data, models trained on synthetic data show performance degradation (measured by $loss_{\text{diff}}$) that predominantly manifests in later sequence positions,
which intensifies as $loss_{\text{diff}}$ increases.
However, this positional bias disappears when evaluating on synthetic data.

The systematic pattern suggests that rather than experiencing model collapse,
the synthetic-trained model may have developed a different learning strategy (examples shown in \autoref{fig:token_diff_examples} and \autoref{fig:cases_fineweb}).
While it shows higher validation losses on certain real-world datasets,
its strong performance in our main experiments indicates a potential trade-off:
the model may prioritize learning generalizable patterns from context over memorizing specific sequence dependencies.
This shift in learning process could explain both the improved performance on benchmark tasks
and the increased losses on validation sets that potentially require more memorization-based processing.


\subsubsection{Analysis and Implications}
Our findings suggest two key insights into model learning with synthetic data:

\textbf{Limitations of Loss Metrics.}
Validation loss alone may not fully capture the complex dynamics of model learning.
Different validation sets, whether synthetic or real,  represent distinct sampling approaches to human knowledge and skills,
making it challenging to establish truly unbiased evaluation metrics for model performance.
The strong performance of MAGA-trained models on downstream tasks,
despite higher validation loss on certain datasets,
suggests that the relationship between validation loss and model capabilities is more complex than previously assumed.

\textbf{Synthetic Learning Hypothesis.}
Similar to \citet{abdin2024phi}, synthetic data, generated through next-token prediction,
provides more efficient learning pathways by compelling models to focus on core reasoning and contextual understanding.
In contrast, real data contains patterns from non-linear human editing processes, which might require additional model capacity to capture but may not directly contribute to core reasoning capabilities.
Therefore, the relative advantages of synthetic data in certain aspects may stem from the resource competition between capability acquisition and memory storage in models.

While our investigation provides initial insights, we believe this phenomenon merits deeper examination in future research to fully understand the interplay between synthetic and real training data.


