\clearpage
\appendix
\section{Limitations and Opportunities}
While our experimental results demonstrate the effectiveness of MAGA in both quality validation and scaling scenarios, several important aspects warrant further investigation. We identify three key areas for future research:
\begin{itemize}[leftmargin=1.5em]
    \item The tool model (SLM) employed in this work relies on an early internal version with relatively moderate capabilities. While \citet{pieler2024rephrasing} suggests that model size may not be the determining factor for rephrasing tasks, the influence within MAGA framework remains unexplored. Understanding the relationship between SLM capacity and corpus quality is crucial for optimizing the effectiveness-efficiency trade-off.
    
    \item Our current experiments demonstrate effectiveness up to 13B parameters and 1,000B tokens of training budget. Extending this approach to long-horizon training and larger-scale models requires additional validations, particularly for next-generation models which require hundreds of trillions of training tokens.
    
    \item Regarding data repetition strategies, we present preliminary explorations under computational resource constraints. The underlying patterns and their sensitivity to various factors—repetition ratio, data distribution, and data quality—require systematic investigation. Future research should examine how these factors collectively determine optimal data strategies across different training scenarios.
\end{itemize}


\section{Tool Model Implementation}
\label{sec:appd_implementation_details}
Our implementation pipeline consists of three key components:
(1) A large language model serving as both LLM labeler and judger;
(2) Task specific tool models applying W8A8 quantized~\citep{xiao2023smoothquant} for efficient inference;
(3) A comprehensive evaluation framework.


\paragraph{High Quality Corpus}
To ensure reproducibility, we conduct our reformulated corpus based on SmolLM-Corpus\footnote{\url{https://github.com/huggingface/smollm/tree/main/text/pretraining}}~\citep{benallal2024smollmcorpus}, expanding fineweb-edu-dedup source from 195B tokens to 770B tokens.
Then we setup additionally experiments on FineWeb and FineWeb-Edu~\citep{penedo2024finewebdatasets},
which constitute a solid foundation for research on data scaling approaches.
Prior to these experiments, we have validated our approach on our in-house datasets.
The results demonstrate consistent performance across both datasets, suggesting broad applicability of our method.


% \begin{table*}[!hbt]
%     \label{prompt:reformulation_snippet}
% \begin{prompt}{Reformulation prompt snippet.}
% Please use your analytical and writing abilities to reformulate the original text based on the given `genre' and `target audience'. Before beginning the reformulation, you will think through the following requirements:

% 1. First read through the original text carefully, identify its informational content and value, and consider how to maintain these information points and value
% 2. Based on the content of the original text, rewrite it according to the given `genre' requirements, following the descriptions, content modules, language requirements and other stylistic elements specified in the `genre', to create an initial draft
% 3. Polish the initial draft considering the given `audience' requirements, and generate final text in English
% 4. Refine the text to match native English speakers' reading habits and expressions
% \end{prompt}

% \end{table*}

\paragraph{Tool Models Training}
Initialized from a pretrained SLM (an in-house 3.3B MoE model), we collect 50,000 training samples through iterative filtering and training, where 15,000 of raw text to genre-audience pairs, 35,000 of raw text to reformulated output.
Each model's validation responses are scored by capable LLM judger, that ensures the SLMs achieve comparable synthesis quality to the original LLM as shown in~\autoref{table:tool_model_scores}.
The sequence length is 8192 with maximum prompt/response length 4,096 tokens, each model is trained 3 epochs on the samples with a cosine lr scheduler.

\paragraph{Resource Analysis}
To generate 770B synthetic tokens, it takes 256×64 and 1024×130 NVIDIA H100 GPU hours to process two stages, or 4× more hours when using Huawei Ascend910B2. 
In our practice, we use Huawei Ascend910B2 synthesis most tokens of MAGACorpus, which significantly reduce the cost of synthesis.

\section{Pretraining Details}
\label{sec:appd_training}

\paragraph{Evaluation}
The LightEval results provided in Section~\ref{sec:main_exp} follow SmolLM setting, that with GSM8K 5-shot and all the others 0-shot.
The benchmarks presented in \autoref{fig:appd_benchs1} and \autoref{fig:appd_benchs2} follow few-shot evaluation settings, specifically ARC(8-shots), TriviaQA(5-shots), Winogrande(5-shots) 
and similar configurations for other tasks.


\begin{figure*}[htb!]
    \centering    
    \includegraphics[width=\linewidth]{figures/appendix-main-exp.pdf}
    \vspace{-2em}
    \caption{Detail evaluation results of EntireSet described in~\autoref{table:scaling_weight}. MAGACorpus group demonstrats advantages over other groups across most evaluation sets, consistently across models of sizes. }
    \label{fig:appd_benchs1}
\end{figure*}


\begin{figure*}[htb!]
    \centering
    \vspace{-1em}
    \includegraphics[width=\linewidth]{figures/appendix-scaling-exp.pdf}
    \vspace{-2em}
    \caption{Detail evaluation results of Subset described in~\autoref{table:scaling_weight}. As the model size increases, the performance gap between the upsampling group and MAGACorpus gradually widens in ARC, DROP, GSM8K, RACE, but with some variations observed in TriviaQA and WinoGrande.}
    \label{fig:appd_benchs2}
\end{figure*}



\paragraph{Datasets and Models}
We sample 100 million tokens from SmolLM-Corpus as the validation dataset. 
The hyperparams are presented in \autoref{tab:model_hyperparams}, tokenzier used for training and computing token counts is same as 
SmolLM1\footnote{\url{https://huggingface.co/HuggingFaceTB/cosmo2-tokenizer}} with a vocab size of 49,152. 

\begin{table*}[h]
    \centering
    \setlength{\tabcolsep}{4pt}
    \caption{Hyperparams of different model size.}
    \begin{tabular}{*{11}{c}}
        \toprule
        model & batch & learning & hidden & ffn & num & num & shared & seq & tie & total \\
        size & size & rate & size & inner & heads & layers & q\_head & len & emb & params \\
        \midrule
        \textbf{134M} & 128  & 3e-3   & 1,204 &  4,096 &  8 &  8 & 1 & 8,192 & false & 134M \\
        \textbf{377M} & 320  & 1.5e-3 & 1,536 &  6,144 & 12 & 10 & 1 & 8,192 & false & 377M \\
        \textbf{1.7B} & 512  & 5e-4   & 2,560 & 10,240 & 20 & 16 & 1 & 8,192 & false & 1.68B \\
        \textbf{7B}  & 1,024 & 4e-4   & 4,096 &  8,192 & 32 & 32 & 4 & 8,192 & false & 6.98B \\
        \textbf{13B} & 1,024 & 4e-4   & 4,096 & 12,288 & 32 & 48 & 4 & 8,192 & false & 12.9B \\
        \bottomrule
    
    \end{tabular}
   
    \label{tab:model_hyperparams}
\end{table*}

\section{Further Analysis of Experiments}
\label{sec:appd_experiments}
\subsection{Benchmark Improvement}
In our experimental observations (\autoref{tab:appd_bench_analysis}), notable performance improvements are demonstrated in both TriviaQA and GSM8k benchmarks,
 warranting a detailed examination of these score variations. 

\begin{table*}[h]
    \center
    \vspace{-1em}
    \setlength{\fboxsep}{1pt}
    \caption{Benchmark results. A copy of SmolLM1/SmolLM1-Ours/MAGA-Mix in \autoref{tab:main_exp}.
    }
    \renewcommand{\arraystretch}{1.15}
    \begin{adjustbox}{max width=\textwidth}
  
    \setlength{\tabcolsep}{1mm}{
    \setlength{\fboxsep}{1.5pt}
    \begin{tabular}{@{\extracolsep{\fill}}lcccccccccccccccc}
    \toprule
      
      Model & \#Params. & \#Tokens & ARC(C+E) & Wino. & Hella. & MMLU & MMLU-PRO & CSQA & OpenBookQA & PIQA & TriviaQA & GSM8K & Avg. \\
      \midrule
      SmolLM-1.7B & 1.7B & 1T & 59.95 & 54.7 & 62.83 & 39.35 & 10.92 & 38 & 42.6 & 75.9 & 13.14 & 4.62 & 40.20 \\
      Baseline & 1.7B & 1T & 59.63 & 57.38 & 65.19 & 39.4 & 12.11 & \underline{42.59} & \textbf{45.6} & 76.88 & 4.95 & 7.81 & 41.15 \\
      MAGA-Mix & 1.7B & 1T & \colorbox{green!15}{\underline{60.36}} & \colorbox{green!15}{57.46} & \colorbox{green!15}{65.52} & \colorbox{green!15}{\underline{40.79}} & \colorbox{green!15}{\underline{14.1}} & 41.11 & \underline{42.8} & \colorbox{green!15}{77.53} & \colorbox{green!15}{20.42} & \colorbox{green!15}{13.87} & \colorbox{green!15}{43.4} \\
    \bottomrule
    \end{tabular}
    }
    \end{adjustbox}
    \label{tab:appd_bench_analysis}

\end{table*}
The enhanced TriviaQA performance exhibited by SmolLM1-1.7B relative to our baseline 
can be attributed to the larger proportion of Cosmopedia in its training configuration.
Both MAGACorpus and Cosmopedia employ synthetic methodologies, which contribute to improved model learning efficiency. 

The observed gains in GSM8K performance can be traced to the target genres, including teaching schemas and problem-solving exemplars,
embedded within the Reformulation component. 
This early exposure to structured problem-solving approaches facilitates more effective performance on analogous mathematical reasoning tasks.

% \subsection{Visualization}

% \begin{figure*}[htb!]
%     \centering
   
%     \includegraphics[width=0.6\linewidth]{figures/tsne-visualization-maga.png}
%     \vspace{-1em}
%     \caption{t-SNE visualization of SLM-Base, lines show how document representation changes in embedding space.}
    
% \end{figure*}

\subsection{What if use MAGACorpus alone?}
While our method primarily aims to expand existing datasets, 
aligning with recent trends in combining synthetic and real data, 
we explore the effects of training exclusively with MAGACorpus. 
As shown in~\autoref{tab:main_exp2}, the absence of real data leads to performance degradation across most tasks (average -0.95), 
particularly in two tasks, Hellaswag(-1.23/-1.69/-2.85) and CommonsenseQA(-3.11/-4.83/-4.50). 
This decline can be attributed to our design choice, 
which focuses on diversity and overall quality rather than requiring the preservation of all information from each raw documents.

\begin{table*}[h]
  \center
 
  \caption{Comparison between MAGA-Mix and MAGA-Only}
  \vspace{-0.5em}
  \begin{adjustbox}{max width=\textwidth}
  \setlength{\tabcolsep}{1mm}{
  \setlength{\fboxsep}{0pt}
  \begin{tabular}{@{\extracolsep{\fill}}lcccccccccccccccc}
  \toprule
    
    Model & \#Params. & \#Tokens & ARC(C+E) & Wino. & Hella. & MMLU & MMLU-PRO & CSQA & OpenBookQA & PIQA & TriviaQA & GSM8K & Avg. \\
    \midrule
    MAGA-Mix & 134M & 600B & \textbf{43.01} & \textbf{51.7} & \textbf{41.25} & \textbf{30.1} & \textbf{11.76} & \textbf{32.68} & \textbf{36.4} & 67.3 & 2.05 & \textbf{1.44} & \textbf{31.77}\\
    MAGA-Only & 134M & 600B & 41.98 & 51.38 & 40.02 & 29.87 & 11.5 & 29.57 & 33 & \textbf{68.01} & \textbf{2.26} & 1.06 & 30.87\\
    &  &  & \colorbox{red!15}{$\downarrow$-1.03} & \colorbox{red!15}{$\downarrow$-0.32} & \colorbox{red!15}{$\downarrow$-1.23} & \colorbox{red!15}{$\downarrow$-0.23} & \colorbox{red!15}{$\downarrow$-0.26} & \colorbox{red!15}{$\downarrow$-3.11} & \colorbox{red!15}{$\downarrow$-3.40} & \colorbox{green!15}{$\uparrow$0.71} & \colorbox{green!15}{$\uparrow$0.21} & \colorbox{red!15}{$\downarrow$-0.38} & \colorbox{red!15}{$\downarrow$-0.90}\\
    \midrule
    MAGA-Mix & 377M & 600B & \textbf{49.39} & 52.64 & \textbf{51.34} & \textbf{34.09} & 11.35 & \textbf{37.1} & \textbf{38} & \textbf{72.31} & \textbf{7.28} & \textbf{1.74} & \textbf{35.52}\\
    MAGA-Only & 377M & 600B & 47.95 & \textbf{53.35} & 49.65 & 33.31 & \textbf{11.38} & 32.27 & 38 & 70.95 & 6.83 & 1.59 & 34.53\\
    &  &  & \colorbox{red!15}{$\downarrow$-1.44} & \colorbox{green!15}{$\uparrow$0.71} & \colorbox{red!15}{$\downarrow$-1.69} & \colorbox{red!15}{$\downarrow$-0.78} & \colorbox{green!15}{$\uparrow$0.03} & \colorbox{red!15}{$\downarrow$-4.83} &  -  & \colorbox{red!15}{$\downarrow$-1.36} & \colorbox{red!15}{$\downarrow$-0.45} & \colorbox{red!15}{$\downarrow$-0.15} & \colorbox{red!15}{$\downarrow$-0.99}\\
    \midrule
    MAGA-Mix & 1.7B & 1T & \textbf{60.36} & \textbf{57.46} & \textbf{65.52} & \textbf{40.79} & \textbf{14.1} & \textbf{41.11} & 42.8 & \textbf{77.53} & \textbf{20.42} & \textbf{13.87} & \textbf{43.40}\\
    MAGA-Only & 1.7B & 1T & 59.02 & 57.06 & 62.67 & 40.34 & 13.51 & 36.61 & \textbf{45.2} & 76.71 & 19.78 & 13.57 & 42.45\\
    &  &  & \colorbox{red!15}{$\downarrow$-1.34} & \colorbox{red!15}{$\downarrow$-0.40} & \colorbox{red!15}{$\downarrow$-2.85} & \colorbox{red!15}{$\downarrow$-0.45} & \colorbox{red!15}{$\downarrow$-0.59} & \colorbox{red!15}{$\downarrow$-4.50} & \colorbox{green!15}{$\uparrow$2.40} & \colorbox{red!15}{$\downarrow$-0.82} & \colorbox{red!15}{$\downarrow$-0.64} & \colorbox{red!15}{$\downarrow$-0.30} & \colorbox{red!15}{$\downarrow$-0.95}\\
    \bottomrule
  \end{tabular}
  }
  \end{adjustbox}
  \label{tab:main_exp2}
  \vspace{-1em}
\end{table*}


\subsection{Ablation Details}
\label{sec:appd_abaltion_details}
\paragraph{MAGA-Only Setting of PE Ablation}
Upon relaxing the information preservation requirements for PE objectives in the MAGA-Only setting, 
we observe a complete collapse in knowledge-based dimensions while 
maintaining modest improvements in reasoning and mathematical capabilities. 
This divergence suggests that different cognitive capabilities have distinct requirements 
for the richness and nature of training data content.
\begin{figure*}[htb!]
    \centering
 
    \includegraphics[width=\linewidth]{figures/ablation-pe-maga-only.pdf}
    \vspace{-2em}
    \caption{Corresponding benchmark results described in Section~\ref{sec:ablation_pe}.}
\end{figure*}

\paragraph{Further Discussion of Section~\ref{sec:disscuss_model_collapse}}
For our analysis method in \autoref{fig:doc_loss}, we define the token loss difference as $loss^i_{\text{diff}}=loss^i_{\text{synt}}-loss^i_{\text{real}}$, where i is the token index, synt/real is dataset used for model training.
Note that we consistently use synthetic minus real, where a positive value indicates poorer prediction performance by the synthetic model on a given sample.

Since next token prediction is computed based on preceding context, we define the first anomaly position to identify where a model's prediction for tokens within the window begins to significantly deteriorate. 
The definition is as follows:
\begin{align*}
\text{first\_anomaly\_position} = \min\{p ~|~ \left| \frac{1}{w}\sum_{i=p}^{p+w-1} loss^i_{\text{diff}}\right| > |\mu| + k\sigma\},
\end{align*}

where $w = \max(0.05 \times \text{seq\_length}, 1),~\mu = \text{mean}(loss^i_{\text{diff}}),~\sigma = std({loss^i_{\text{diff}}})$.
Here, we employ the absolute value of the windowed average loss to identify significant performance degradation in either model. 
This approach enables the detection of notable prediction quality drops regardless of which model (synthetic or real) experiences the deterioration.

Finally, we define the normalized position, enabling fair comparisons across various sequence lengths:
\begin{align*}
    \text{normalized\_position} = 
    \begin{cases} 
        \frac{\text{first\_anomaly\_position}}{\text{seq\_length}} \times 100\% & \text{if anomaly found} \\ 
        -1 & \text{otherwise} 
    \end{cases}
\end{align*}

Below are example cases from English and Chinese documents.
\autoref{fig:token_diff_examples} presents the token loss difference on each position.
Example 2 and Example 3 show similar anomaly pattern, we can get the reason in \autoref{fig:cases_fineweb},
that they are from the same website source contain identical boilerplate text about region selection and website localization at the end of their content.

\begin{figure*}[htb!]
    \centering
    \includegraphics[width=\linewidth]{figures/token-diff-examples.png}
    \vspace{-2em}
    \caption{Random examples sampling from where $\text{mean}(loss^i_{\text{diff}})>0.5$, the synthetic-trained model fail to predict the tokens in later sequence positions.}
    \label{fig:token_diff_examples}
\end{figure*}

This suggests potential noise in the data preprocessing pipeline, 
specifically in handling website navigation elements and localization prompts 
that should have been removed during content extraction.

While these examples demonstrate clear patterns of model behavior differences in handling noisy web data, we acknowledge that this analysis is limited to selected cases with apparent preprocessing artifacts. A more comprehensive evaluation across diverse data sources and quality levels would be necessary to fully understand the impact of synthetic training data on model performance.

\begin{figure*}[htb!]
    \centering
    \includegraphics[width=\linewidth]{figures/Cases-Fineweb.pdf}
    \vspace{-2em}
    \caption{Corresponding cases sampled from Fineweb-Edu, which align with the loss patterns shown in Figure~\ref{fig:token_diff_examples}, with higher loss by synthetic-trained model highlighted in \colorbox{red!15}{red}.}
    \label{fig:cases_fineweb}
\end{figure*}

\begin{figure*}[htb!]
    \centering
    \includegraphics[width=\linewidth]{figures/Cases-Chinese.pdf}
    \vspace{-2em}
    \caption{Chinese corpus samples with higher loss by synthetic-trained model in \colorbox{red!15}{red}.}
    \label{fig:cases_chinese}
\end{figure*}

\clearpage
\section{Prompts and Cases}
\label{sec:appd_prompt}

\subsection{Cases}
\begin{table*}[h]
    \centering
    \caption{Example outputs of SLM variants.}
    % \vspace{-1em}
    \includegraphics[width=\linewidth]{figures/reformulate-cases.pdf}
\end{table*}

\clearpage
\subsection{Prompts}
Although the term ``rewrite'' is used in some prompt templates as the editing instruction, it serves the same function as ``reformulate'' discussed in sections above, which aims to maintain the core meaning of the documents while only optimizing its expression.


\begin{figure*}[h]
    \centering
    \begin{minipage}[t]{0.48\textwidth}
        \centering
        \begin{prompt}{}
 # strict version            
 You are a text polishing expert. You will polish text based on the given [Genre] and [Audience]. 
 
 When polishing, you must follow these 4 rules:
 1. Read through the entire text and polish it according to the requirements of the given [Genre] and [Audience]
 2. The degree of polishing should not be too heavy - just aim to satisfy the requirements of [Genre] and [Audience] as much as possible
 3. Double-check that the polished text is suitable for the audience described in [Audience]!
 4. Pay attention to the frequency of modal particles - the text should not contain too many modal particles
        \end{prompt}
    \end{minipage}
    \hfill 
    \begin{minipage}[t]{0.48\textwidth}
        \centering
        \begin{prompt}{}
 # relaxed version            
 You are a creative expert skilled at transforming materials into creative inspiration and building independent, complete, and highly original texts. 
 
 Requirements:
 1. Read through the original text thoroughly, extract several key themes/keywords, transform to abstract or universal concept inspiration, then generate entirely new text constructions.
 2. Extract content from [audience] and [genre] sections, but don't be constrained by them directly, just use them as creative inspiration. 
 3. Create and reformulated text around points 1/2, and build new meaning from details to the whole structure.
            \end{prompt}
    \end{minipage}
    \caption{two different prompt templates, we keep the input aligned with MAGA strategy, using raw text, genre, audience to fill the template.}
    \label{fig:ablation_pes}
\end{figure*}


\begin{table*}[h]
\begin{prompt}{reformulation prompt template.}
############# 
#Identity and Capabilities#
You are a content creation expert, specializing in text analysis and rewriting, capable of adapting content based on varying ``genres'' and ``audiences'' to produce ``diverse'' and ``high-quality'' texts. Your English writing is at native editor level, and you will output your rewritten texts in English. International audiences particularly enjoy your work, which receives widespread readership and circulation, earning unanimous acclaim from the industry for your capabilities!

############# 
#Workflow#
Please utilize your analytical and writing abilities to rewrite the text based on the original content and given ``genre'' and ``audience''. Before beginning the rewrite, you will consider the following requirements:

1. First, read through the original text thoroughly, identify its information content and value, and consider how to prevent any loss of information points and value in the rewritten text
2. Focus on the original content, combine it with the given ``genre'' requirements, and rewrite the text following the descriptions, content modules, language requirements, and other stylistic elements specified in the ``genre'', to form an initial draft
3. Polish the initial draft according to the given ``audience'' requirements, and generate the final rewritten text in English
4. Refine the rewritten text to match native English speakers' reading habits and expression patterns

############# 
#Detailed Requirements#
Please ensure you follow the three workflow requirements above, then generate the final English rewritten text according to these detailed requirements.
The given ``audience'' is <<<{audience}>>>.
The given ``genre'' is <<<{genre}>>>.

############# 
#Raw Text#
{raw_text}
\end{prompt}
\label{tab:appd_reformulation_prompt}
\end{table*}


\begin{table*}[t]
\begin{prompt}{genre-audience pairs prompt template.}
############# 
#Identity and Capabilities# 
You are a content creation expert, specializing in text analysis and rewriting, skilled at adapting content based on varying [genres] and [audiences] to produce ``diverse'' and ``high-quality'' texts. Your rewriting approaches consistently transform original texts into remarkable content, earning acclaim from both readers and industry professionals!

############# 
#Workflow#
Please utilize your imagination and creativity to generate 5 pairs of [genre] and [audience] combinations suitable for the original text. Your analysis should follow these requirements:

1. First, analyze the characteristics of the source text, including writing style, information content, and value
2. Then, consider how to preserve the primary content and information while exploring possibilities for ``broader audience engagement'' and ``alternative genres''

############# 
#Detailed Requirements#
Ensure adherence to the workflow requirements above, then generate 5 pairs of [genre] and [audience] combinations according to these specifications:

Your provided [genres] should meet the following requirements:
1. Clear Genre Definition: Demonstrate strong diversity; include genres you've encountered, read, or can envision
2. Detailed Genre Description: Provide 2-3 sentences describing each genre, considering but not limited to type, style, emotional tone, form, conflict, rhythm, and atmosphere. Emphasize diversity to guide knowledge adaptation for specific audiences, facilitating comprehension across different backgrounds. Note: Exclude visual formats (picture books, comics, videos); use text-only genres.

Your provided [audiences] should meet the following requirements:
1. Clear Audience Definition: Demonstrate strong diversity; include both interested and uninterested parties, those who like and dislike the content, overcoming bias toward positive audiences only
2. Detailed Audience Description: Provide 2 sentences describing each audience, including but not limited to age, occupation, gender, personality, appearance, educational background, life stage, motivations and goals, interests, and cognitive level

############# 
#Response#
{
    ``audience_1'': audience1,
    ``genre_1'': genre1,
    ``audience_2'': audience2,
    ``genre_2'': genre2,
    ``audience_3'': audience3,
    ``genre_3'': genre3,
    ``audience_4'': audience4,
    ``genre_4'': genre4,
    ``audience_5'': audience5,
    ``genre_5'': genre5
}

#############
#Input#
{raw_text}

\end{prompt}
\end{table*}


\begin{table*}[t]
\begin{prompt}{Full LLM judger prompt.}
#############
#Identity and Capabilities#
You are a Content Reviewer, skilled at analyzing texts and keenly identifying and analyzing the relationships, similarities, and differences between two texts. Your thorough analysis of each pair of texts, with attention to every detail, provides great convenience for subsequent review work!

#############
#Thinking Process#
Please fully utilize your analytical abilities, review capabilities, and deep thinking skills to analyze the ``Rewritten Text'' against the ``Original Text'' as a benchmark, ultimately providing analysis and scoring for [A]. You will follow these steps for detailed consideration:

1. First, you will read through the original text thoroughly, identifying the information points in the ``Original Text''
2. You will also read through the rewritten text thoroughly, identifying the information points in the ``Rewritten Text''
3. Compare the information in both texts' content. The ``Rewritten Text'' is allowed to have new information points, different writing styles, expression styles, order, and focus from the ``Original Text''. As long as it is created based on some information points from the ``Original Text'', it is considered good for [A]
4. After careful analysis and review, please clearly list the connections and differences between the two texts, and based on this, provide final analysis and scoring for [A]

#############
#Detailed Requirements#
The scoring judgment for [A] must follow these standards:
1. The ``scoring range'' is 1-5 points. You need to analyze and grasp each aspect mentioned in #Thinking Process#, and differentiate scores accordingly. Be strict, don't be too lenient with scoring!
2. The ``Rewritten Text'' is allowed to differ from the ``Original Text'' in writing style, expression style, and focus! This cannot be a basis for deducting points!
3. The ``Rewritten Text'' is allowed to omit some information from the ``Original Text''! It is not required that all information from the ``Original Text'' appears in the ``Rewritten Text''! This also cannot be a basis for deducting points! If this is the only issue, please give a full score of 5 points.

In scoring [A], the following situations will **NOT reduce** the score for [A]:
1. The ``Rewritten Text'' can include information points not present in the ``Original Text''
2. The added content in the ``Rewritten Text'' significantly deviates from the core information of the ``Original Text''
3. The expression style, order, and focus of the ``Rewritten Text'' differ from the ``Original Text''

In scoring [A], the following situations **WILL reduce** the score for [A]:
1. The information points in the ``Rewritten Text'' differ so greatly from the ``Original Text'' that it's not recognizable as being rewritten from the ``Original Text''
2. The ``Rewritten Text'' contains none of the information points from the ``Original Text''

#############
#Original Text#
{raw_text}

#Rewritten Text#
{rewritten_text}

#############
#Response Format#
{
    ``A'':{
        ``analysis'': ``xxx'', provide reasons for point deductions
        ``score'': 1, 2, 3, 4, or 5
    },
}
#############
\end{prompt}
\end{table*}

