\section{Massive Genre-Audience Reformulation}
\label{sec:syntheses_pipeline}
\label{sec:implementation_details}

\begin{figure}[t]
    \centering
    \vspace{-4em}
    \includegraphics[width=\columnwidth]{figures/implement-details.pdf}
    \vspace{-3em}
    \caption[width=0.8\columnwidth]{Implementation details. From a high-quality corpus, we sample a subset to serve as input for the LLM labeler and judger. 
    Through iterative filtering, we train and quantize SLM tool models for each stage to improve inference efficiency,
    which are used to generate the reformulated corpus.}
    \label{fig:synthesis-pipeline}
\end{figure}

Preserving core knowledge while adapting content presentation for diverse audiences is the key motivation behind {\ours} reformulation. 
As shown in \autoref{fig:synthesis-pipeline}, the framework expands original corpus through a two-stage synthesis process followed by an extra heuristic cleaning stage.
Our implementation consists of three key components\footnote{Tool model details presented in Appendix~\ref{sec:appd_implementation_details}. Prompts and case studies in Appendix~\ref{sec:appd_prompt}.}:
(1) A large language model serving as both LLM labeler and judger;
(2) Task specific tool models applying W8A8 quantized~\citep{xiao2023smoothquant} for efficiency;
(3) A balanced quality assessment mechanism defined as Limited Consistency.

\paragraph{Genre-Audience Pairs}
For pretraining corpus, there is a consensus among researchers to ensure diversity and quality.
Inspired by~\cite{maini2024rephrasing};\cite{ge2024scalingpersonas}, we expand the simple rephrasing method from only few styles to massive genre-audience pairs. 

\begin{itemize}[leftmargin=1.5em]
\item \textbf{Genre} defines the knowledge expression framework through multiple dimensions: communication purpose (e.g., education, analysis), content structure (e.g., step-by-step tutorials, analytical reports), language style, and knowledge depth control. This framework guides how information should be reconstructed while preserving core concepts.
\item \textbf{Audience} profiles combine demographic factors (age, education, profession) with knowledge background and motivational characteristics. For example, a beginner-level first-aid guide would be reformulated differently for medical students versus office workers, while maintaining essential medical accuracy.
\end{itemize}

% \vspace{-1.5em}
Our framework supports N genres and M audience types, theoretically enabling NÃ—M unique reformulation patterns.
To balance diversity and computational efficiency, we generate 5 genre-audience pairs per inference pass.
And as each run is conditioned by a different document, we can maximize the coverage of different genre-audience combinations.

\paragraph{Reformulation}
Once the genre-audience pairs are determined, the reformulation process follows a straightforward approach,
as prompt presented in Appendix~\ref{tab:appd_reformulation_prompt}.
The key factor of reformulation is how to evaluate the output text,
so we introduce the concept of \textbf{``Limited Consistency''} as criterion for quality controlling. 
This framework seeks to establish an optimal balance between textual variation and information preservation as shown in Prompt~1. 


\begin{table*}[!hbt]
\begin{prompt}{LLM judger prompt snippet.}
# Detailed Requirements
For scoring judgment, the following standards must be followed:
1. The `scoring range' is 1-5 points. You need to analyze and grasp each point mentioned in #Thought Process#, and give scores with distinction. Be strict, don't be too lenient with scoring!
2. The `Reformulated Text' is allowed to differ from the `Original Text' in writing style, expression style, and focus points! This cannot be a basis for deducting points!
3. The `Reformulated Text' is allowed to omit some information from the `Original Text'! Not all information from the `Original Text' needs to be reflected in the `Reformulated Text'!

The following situations will [NOT REDUCE] the score:
1. The `Reformulated Text' can include information points not present in the `Original Text'
2. The additional content in the `Reformulated Text' deviates significantly from the core information of the `Original Text'
3. The expression style, order, and focus points of the `Reformulated Text' differ from the `Original Text'

The following situations will [REDUCE] the score:
1. The information points in the `Reformulated Text' differ so greatly from the `Original Text' that it's not apparent it was Reformulated from the `Original Text'
2. The `Reformulated Text' lacks every information points present in the `Original Text'
\end{prompt}
\vspace{-0.5em}
\end{table*}

In practice, we use the proportion of samples (score $\ge$ 3) as our primary metric during both labeler LLM prompt engineering and tool model development. 
As shown in \autoref{table:tool_model_scores}, both our LLM and SLM achieve over 92\% with only a minor performance gap (-1.05\%).

\begin{table*}[h]
    \vspace{-1em}
    \centering
    \caption{Performance comparison between SLM and LLM on reformulation quality evaluation.}
    \begin{adjustbox}{max width=\textwidth}
    \setlength{\tabcolsep}{1mm}{
    \begin{tabular}{lcccccccc}
        \toprule
        Models & Total & 5 & 4 & 3 & 2 & 1 & Rate($\ge$ 3) & Diff \\
        \midrule
        Labeler LLM & 15,355 & 4,120 & 7,143 & 3,034 & 661 & 214 & 93.11\% & - \\
        Tool SLM & 15,355 & 3,788 & 7,124 & 3,224 & 736 & 285 & 92.06\% & -1.05\% \\
        \bottomrule
    \end{tabular}
    }
    \end{adjustbox}
% \vspace{-0.5em}
\label{table:tool_model_scores}
\end{table*}

This trade-off between flexibility and fidelity is critical for maintaining reformulation quality while ensuring meaningful content adaptation. The empirical effects of different consistency levels are further explored in our ablation studies (Section~\ref{sec:ablation_pe}), where we demonstrate how models perform when deviating from this balanced approach.
% \vspace{-1.5em}
\paragraph{Cleaning Stage}
Similar to previous synthesis work~\citep{maini2024rephrasing,su2024nemotron}, we involve a final cleaning stage to filter out the high frequency patterns, for example,
`\textit{Notes: ...}', `\textit{Please note that ...}', `\textit{The above is as required ...}', `\textit{The following is...}', etc.
And remove the documents which have an extremely low keyword coverage to raw documents.
