\section{Tempered Likelihood Ratios}\label{sec:tempered}

The Bayesian update rule can be generalized by introducing a \emph{temperature} parameter $\beta > 0$,
\begin{align*}
    \mu_t(\theta) \propto \prod_{s=1}^t p_s(y_s|\theta)^\beta \mu_0(\theta) \,.
\end{align*}
The generalized update rule has been studied under various names, e.g. as \emph{fractional posteriors} \citep{bhattacharya2019bayesian}, \emph{powered likelihoods} \citet{holmes2017assigning} and \emph{tempered posteriors} \citep{alquier2020concentration}, often in the context of adding robustness to misspecification in the Bayesian model \citep{grunwald2012safe}. The result presented below are similar in spirit to the work by \citet{zhang2006varepsilon}, who studies complexity bounds for density estimation in the classical i.i.d.~setting.

\paragraph{Divergences} A few more definitions will be useful, we follow the exposition of \citet{van2014renyi}. Let $p,q \in \sP(\cY)$ be two distributions over the observation space $\cY$. We assume that $p,q$ admit densities w.r.t. a common base measure. We define the Rényi divergence for  $p,q$ and parameter $0 \leq \zeta \leq 1$,
\begin{align*}
    D_\zeta(p\|q) = \frac{1}{\zeta - 1} \log \int p(x)^{\zeta} q(x)^{1- \zeta} dx \,.
\end{align*}
For $0< \zeta < 1$, it holds that
\begin{align*}
   (1-\zeta)  D_\zeta(p\|q) = \zeta D_{1-\zeta}(q\|p)\,.
\end{align*}
Moreover, the Hellinger distance is given by 
\begin{align*}
    H^2(p\|q) = \int \big(\sqrt{p(x)} - \sqrt{q(x)}\big)^2 dx\,.
\end{align*}
Hellinger and Rényi divergences satisfy the following relation:
\begin{align*}
    \frac{1}{2} H^2(p\|q) \leq D_{1/2}(p\|q)\,.
\end{align*}
For notational convenience, we define
\begin{align*}
    D_{\zeta,t}(\theta\|\nu) &:= D_\zeta(p_t(\cdot|\theta)\|p_t(\cdot|\nu)) \,,\\
    H^2_t(\theta\|\nu) &:= H^2(p_t(\cdot|\theta)\|p_t(\cdot|\nu)) \,.\\
\end{align*}

\subsection{Tempered Confidence Sequences}
Let $\hat \theta_0, \hat \theta_1, \dots$ be an $\cF_t$-adapted sequence of estimators.
Define the \emph{tempered} log-ratio, 
\begin{align}
    A_t^\beta(\theta) = - \beta \log \frac{p_t(y_t|\hat \theta_{t-1})}{p_t(y_t|\theta)} \,.
\end{align}
In particular, by applying the exponential function, we get the \emph{tempered likelihood ratio},
\begin{align*}
\exp(-A_t^\beta(\theta)) = \left(\frac{p_t(y_t|\hat \theta_{t-1})}{p_t(y_t|\theta)}\right)^\beta
\end{align*}
As a side remark, Jensen's inequality implies that 
% \begin{align*}
$\bE[\exp(-A_t^\beta(\theta^*))] \leq  \bE\big[\frac{p_t(y_t|\hat \theta_{t-1})}{p_t(y_t|\theta^*)}\big]^\beta = 1$.
% \end{align*}
Hence $\prod_{s=1}^t A_t^\beta(\theta^*)$ is a super-martingale, and all results presented in the main paper continue to hold for the tempered ratio. However, we can strengthen the construction by enforcing the martingale property. Define
\begin{align*}
% M_t(\theta) = \frac{\exp(- \sum_{s=1}^t A_t^\beta(\theta))}{\textstyle \prod_{s=1}^t \bE_\theta[\exp(- A_t^\beta(\theta))|\cF_t]}
M_t(\theta) = \frac{\exp(- \sum_{s=1}^t A_t^\beta(\theta))}{\textstyle \prod_{s=1}^t \int \exp(- A_t^\beta(\theta)) p_t(y|\theta) dy} \,.
\end{align*}
By definition, $M_t(\theta^*)$ is a non-negative martingale. 
Hence, Ville's inequality implies that
\begin{align*}
   \bP\left[- \sum_{s=1}^t \log \int \exp(- A_s^\beta(\theta^*)) p_s(y|\theta^*) dy - \sum_{s=1}^t A_s(\theta^*) \geq \log \frac{1}{\delta}\right] \leq \delta \,.
\end{align*}
Finally, we note that 
\begin{align*}
   - \log \int \exp(- A_t^\beta(\theta)) p_t(y|\theta) dy = (1 - \beta) D_{\beta,t}(\hat \theta_{t-1} \| \theta)= \beta D_{1-\beta,t}(\theta\|\hat \theta_{t-1}) \,.
\end{align*}

\begin{theorem}[Tempered Confidence Set]\label{result:tempered} Let $\hat \theta_0, \hat \theta_1, \dots$ be an $\cF_t$-adapted sequence of estimators. Define the log regret $\Lambda_t(\theta) = - \sum_{s=1}^t \log p_s(y_s|\hat \theta_{s-1}) - L_t(\theta)$ for $\theta \in \Theta$, and
    \begin{align*}
        C_t^\beta = \left\{ \theta \in \Theta : \sum_{s=1}^t D_{1-\beta,s}(\theta\|\hat \theta_{s-1}) - \Lambda_t(\theta)\leq \frac{1}{\beta} \log \frac{1}{\delta}\right\} \,.
    \end{align*}
    Then $C_t^\beta$ defines a $(1-\delta)$-confidence sequence. Moreover, define
    \begin{align*}
        C_t^H = \left\{ \theta \in \Theta :\sum_{s=1}^t  H_s^2(\theta\|\hat \theta_{s-1}) - \Lambda_t(\theta)\leq 2 \log \frac{1}{\delta}\right\} \,.
    \end{align*}
    Then $C_t^H$ defines a $(1-\delta)$-confidence sequence.
\end{theorem}
As a consequence of the result, assume that the estimation sequence is constructed to achieve bounded regret, $\Lambda_t(\theta) \leq B_t$ for a predictable sequence $B_t \geq 0$, typically related to the complexity of the model class (c.f.,~\cref{sec:oco} and \cref{result:regret}), see also \citet{zhang2006varepsilon}. Then \cref{result:tempered} provides confidence sequences that only depend on the Hellinger or Renyi divergences. The advantage is, that unlike the likelihood ratios, the divergence is predictable quantity under the filtration $\cF_t$, hence can be used in sequential decision making setting to control the state $x_t$. This is one of the reasons why similar bounds have recently gained interest in the sequential decision-making literature \citep[e.g.,][]{chen2022unified,foster2021statistical,foster2023tight,wagenmaker2023instance}. In the next section, we provide another application to sparse estimation.

% \todoj{is there any advantage of keeping both the expectation and realized terms?}
% Note that $\sum_{s=1}^t A_t(\theta^*)$ is the log-loss regret and is controlled with probability 1. 
% Moreover, for $\beta=1/2$
% \begin{align*}
%     -\log \EE_t[ \exp(-A_t(\theta^*))] \geq 1 - \EE_t[ \exp(-A_t(\theta^*))] = \frac{1}{2} H^2(p_{\theta^*}, p_{\theta_t})
% \end{align*}
% Therefore
% \begin{align*}
%     \sum_{s=1}^t \frac{1}{2} H^2(p_{\theta^*}, p_{\theta_t}) \leq \log \frac{1}{\alpha} + \sum_{s=1}^t A_t(\theta^*) 
% \end{align*}
% The important difference is that the left-hand side does not depend on the last observation $y_t$, hence the confidence set is ``predictable'', unlike the likelihood ratio.

% Another way to proceed is

% note on introducing mixing distributions
% For $\beta \leq 1$,\todoj{mixing the tempered posterior vs tempering the mixed ratio}
% \begin{align}
%     \EE_{\theta \sim \mu_t}[ \left(\frac{p_{\theta}(y_t)}{p_{\theta^*}(y_t)} \right)^\beta] \leq  \left(\frac{\ip{\mu_t, p_t}}{p_{\theta^*}(y_t)} \right)^\beta 
% \end{align}


\subsection{Online Linear Prediction}\label{sec:sparse}
Recall the sequential linear regression setting from \cref{sec:bayes}. Specifically, assume that $\Theta \subset \bR^d$, and Gaussian likelihood $p_t(y|\theta) \sim \cN(\ip{\theta, x_t}, 1)$ for $\theta \in \Theta$ and covariates $x_t \in \bR^d$. Everything in this section generalizes to $\sigma$-sub-Gaussian noise distribution using the same arguments as in \cref{sec:subgaussian}. In a slight generalization to earlier results, assume that an online learning algorithm produces predictions $\hat y_t \in \cY$ (opposed to $\hat \theta_t \in \Theta$), in way such that the regret satisfies the following bound for any $\theta \in \Theta$,
\begin{align*}
    \Lambda_t(\theta) = \sum_{s=1}^t \frac{1}{2}(\hat y_{s-1} - y_s)^2 - \frac{1}{2}(\ip{\theta, x_s} - y_s)^2 \leq B_t(\theta) \,.
\end{align*}
For a concrete instantiation in the linear setting, we refer to the famous Vovk-Azoury-Warmuth forecaster \citep{vovk1997competitive,azoury2001relative}. We remark that the bound has been further generalized to non-parametric settings by \citet{rakhlin2014online}. We are now in place to generalize the online-to-confidence set conversion by \citet{abbasi2012online}.

\begin{lemma}[Online-To-Confidence Convertion] Assume the sequential linear regression setup defined above with a known bound $\Lambda_t(\theta^*) \leq B_t$. For any $\cF_t$-adapted sequence $\hat y_0, \hat y_1, \hat y_2, \dots,$ and  $0 < \beta < 1$, let
    \begin{align*}
        C_t = \left\{ \theta \in \Theta : \sum_{s=1}^t \frac{1}{2} \big(\hat y_{s-1} - \ip{\theta, x_s}\big)^2 \leq \frac{1}{\beta - \beta^2 } \log \frac{1}{\delta} + \frac{\beta}{\beta - \beta^2} B_t \right\}
    \end{align*}
    Then $C_t$ defines a $(1-\delta)$-confidence sequence.
\end{lemma}
\begin{proof}
The plan is to compute  $- \log \int \exp(- A_t^\beta(\theta)) p_t(y|\theta) dy$ for the Gaussian distribution, and then invoke \cref{result:tempered}. It is useful to note that for Gaussian distributed variable $\epsilon \sim \cN(0, \sigma^2)$ the moment generating function is $\bE[\exp(t \epsilon)] = \exp(\frac{1}{2}\sigma^2 t^2)$.
A short calculation reveals that 
\begin{align*}
    & \int \exp\big(- A_t^\beta(\theta)\big) p_t(y|\theta) dy\\
    &= \int \exp\Big(-  \frac{\beta}{2} \big(\hat y_{s-1} - y\big)^2 + \frac{\beta}{2} \big(\ip{\theta,x_t} - y\big)^2 \Big)  p_t(y|\theta) dy\\
    &= \int \exp\Big(-  \frac{\beta}{2} \big(\hat y_{s-1} - {\theta,x_t}\big)^2 + \beta \epsilon_t \big(\ip{\theta,x_t} - \ip{\theta,x_t}\big) \Big)  p_t(y|\theta) dy\\
    &= \exp\Big(-  \frac{\beta - \beta^2}{2} \big(\hat y_{s-1} - \ip{\theta,x_t}\big)^2 \Big) \,.
\end{align*}
Hence,
\begin{align*}
    & - \log \int \exp\big(- A_t^\beta(\theta)\big) p_t(y|\theta) dy =  \frac{\beta - \beta^2}{2} \big(\hat Y_{s-1} - \ip{\theta,x_t}\big)^2 \,.
\end{align*}
Lastly, we make use of the assumption that $\Lambda_t(\theta^*) \leq B_t$. The result follows by intersecting the confidence set $C_t^\beta$ from \cref{result:tempered} with  $\{\theta \in \Theta : \Lambda_t(\theta) \leq B_t\}$.
\end{proof}

\paragraph{Sparse Linear Regression} We make the additional assumption that the true parameter $\theta^* \in \Theta$ is $k$-sparse, i.e. $\|\theta^*\|_0 \leq k$. The key insight is that \citet{gerchinovitz2011sparsity} provides an online algorithm, producing the sequence $\hat y_0, \hat y_1, \dots$, for which $B_t(\theta^*) \leq  \cO( k \log(t))$. We compare to the result by \citet{abbasi2012online} in the same setting. For $\beta = \frac{1}{2}$, our result reads
\begin{align*}
   C_t = \left\{ \theta \in \Theta : \sum_{s=1}^t \frac{1}{2} (\hat y_{s-1} - \ip{\theta, x_s})^2 \leq 4\log \frac{1}{\delta} + 2 B_t(\theta^*) \right\} \,.
\end{align*}
In comparison, the result by \citet[Theorem 1]{abbasi2012online} reads, in our notation,
\begin{align*}
C_t = \left\{ \theta \in \mathbb{R}^d : \sum_{s=1}^{t}  \frac{1}{2}(\hat y_{s-1} - \langle \theta, x_t \rangle)^2 \leq 16 \log \frac{1}{\delta} + \frac{1}{2} + 2B_t(\theta^*) + 16\log (\sqrt{8} + \sqrt{1 + 2 B_t(\theta^*)}) \right\}
\end{align*}
The additional terms stem from using recursive inequality on the square-error, which we avoid using the more direct argument via the tempered likelihood ratio. This demonstrates the benefit of the sequential likelihood framework for deriving confidence sets via the online-to-confidence set conversion.
% Assume a sparse linear model $y_t = \ip{x_t, \theta^*} + \epsilon_t$ with $\sigma$-sub-Gaussian noise, i.e. satisfying $\bE[\exp(t \cdot \epsilon_t)] \leq \exp(\frac{\sigma^2 t^2}{2})$. The true parameter satisfies $\|\theta\|_0 \leq m$.
% Let $\hat Y_t \in \bR$ be a sequence of predictions from an online learning algorithm with regret bound
% \begin{align*}
%     \rho_n(\theta^*) = \sum_{t=1}^n (\hat Y_t - y_t)^2 - (\ip{\theta^*, x_t} - y_t)^2 = \sum_{t=1}^n r_t(\theta^*) \leq B_n
% \end{align*}
% where we defined $r_t(\theta^*) = (\hat Y_t - y_t)^2 - (\ip{\theta^*, x_t} - y_t)^2$. Note that
% \begin{align}
%     q_t := (\hat Y_t - \ip{\theta^*, x_t})^2 = r_t(\theta^*) + 2 \epsilon_t (\hat Y_t - \ip{\theta^*, x_t}) \label{eq:q_t-to-r_t}
% \end{align}
% Further define 
% \begin{align*}
% Q_n = \sum_{t=1}^n q_t = \sum_{t=1}^n (\hat Y_t - \ip{\theta^*, x_t})^2 
% \end{align*}
% Our goal is to find a high-probability upper bound for $Q_n$ and turn the bound into a confidence set for $\theta^*$.
% We define the following process for parameters $a,b \geq 0$:
% \begin{align}
%     M_t^{a,b} = \exp\left(\tfrac{b}{2} Q_t - \tfrac{b + a}{2} \rho_t(\theta^*)\right)
% \end{align}
% The choice that we make shortly is $a = b = \frac{1}{4 \sigma^2}$. Note that
% \begin{align*}
%     \EE[M_t^{a,b}|\cF_{t-1}] &= \EE[\exp\left(\tfrac{b}{2} Q_t - \tfrac{b + a}{2} \rho_t(\theta^*)\right) | \cF_t]\\
%     &= M_{t-1}^{a,b} \,\EE[\exp\left(\tfrac{b}{2} q_t - \tfrac{b + a}{2} r_t(\theta^*)\right) | \cF_t]\\
%     &= M_{t-1}^{a,b} \,\EE[\exp\left(- \tfrac{a}{2} q_t  +\tfrac{b + a}{2} q_t - \tfrac{b + a}{2} r_t(\theta^*)\right) | \cF_t]\\
%     &\stackrel{(1)}{=} M_{t-1}^{a,b} \,\EE[\exp\left(- \tfrac{a}{2} q_t  + (a+b) (\hat Y_t - \ip{\theta^*, x_t}) \epsilon_t \right) | \cF_t]\\
%     &\stackrel{(2)}{\leq} M_{t-1}^{a,b} \,\EE[\exp\left(- \tfrac{a}{2} q_t  + \sigma^2 \tfrac{(a+b)^2}{2} (\hat Y_t - \ip{\theta^*, x_t})^2 \right) | \cF_t]\\
%     &= M_{t-1}^{a,b}\, \EE[\exp\left(- \tfrac{a}{2} q_t  + \sigma^2 \tfrac{(a+b)^2}{2} q_t \right) | \cF_t]
% \end{align*}
% Equation $(1)$ follows from \ref{eq:q_t-to-r_t}; the $\frac{a+b}{2}$-factor was introduced to precisely cancel $r_t(\theta^*)$. The inequality $(2)$ follows by assumption that the noise is $\sigma$-sub-Gaussian. We now choose $a$ and $b$ to cancel the remaining terms out, i.e.

% \begin{align*}
% a = \sigma^2 (a+b)^2
% \end{align*}
% We can obtain the values of $a$ and $b$ by solving a quadratic, which gives as a general formula $a = \frac{1}{\sigma^2} - b \pm \frac{1}{2\sigma}\sqrt{\frac{1}{\sigma^2} - 4b}$ . An easy choice is $a=b=\frac{1}{4 \sigma^2}$. This is probably close to optimal (after writing out Ville's inequality it becomes intuitively clear  that we want large $b$ and small $a$), and $b=\frac{1}{4 \sigma^2}$ is also the largest feasible value for $b$. Applying Ville's inequality leads to the following bound:
% \begin{align}
% \bP[ M_t^{a,b} \geq \tfrac{1}{\alpha}] \leq \alpha
% \end{align}
% In other words, with probability at least $1-\delta$,
% \begin{align}
% \frac{1}{2} \sum_{t=1}^n (\hat Y_t - \ip{\theta^*, x_t})^2 \leq  4\sigma^2 \log \frac{1}{\alpha} + \rho_n(\theta^*) \leq  4\sigma^2  \log \frac{1}{\alpha} + B_n
% \end{align}


% For $a=b=\frac{1}{4 \sigma^2}$ we have
% \begin{align}
%     C_t^{\frac{1}{4},\frac{1}{4}} &= \left\{\theta : \frac{1}{2} \sum_{t=1}^n (\hat Y_t - \ip{\theta, x_t})^2 \leq  4 \sigma^2 \log \frac{1}{\alpha} + \rho_n(\theta^*)\right\} \\
%     &\subset \left\{\theta : \frac{1}{2} \sum_{t=1}^n (\hat Y_t - \ip{\theta, x_t})^2 \leq  4 \sigma^2 \log \frac{1}{\alpha} + B_n \right\} 
% \end{align}
% On the other hand, $a = 1$ and $b=0$ also leads to a valid confidence set, since $\exp(-\frac{1}{2}\rho_t(\theta^*))$ is the usual likelihood ratio for (sub-)Gaussian likelihood. Writing explicitly,
% \begin{align}
%     C_t = C_t^{0,1} &= \left\{\theta : \frac{1}{2}\rho(\theta) \leq  \log \frac{1}{\alpha} \right\} \\
%     &= \left\{\theta : \frac{1}{2} \sum_{t=1}^n (\hat Y_t - \ip{\theta, x_t})^2 \leq \log \frac{1}{\alpha} + \frac{1}{2} \sum_{t=1}^n (\hat Y_t - y_t)^2\right\} 
% \end{align}