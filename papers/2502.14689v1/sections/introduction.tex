\section{Introduction}
Estimating model uncertainty is a fundamental challenge in machine learning and data science. Uncertainty quantification is essential for assessing model accuracy and robustness, particularly in safety-critical domains such as medical diagnosis, drug discovery, and autonomous driving. Uncertainty quantification also plays a key role in guiding exploration in sequential decision-making algorithms, including active learning, adaptive experimental design and reinforcement learning. 

Significant efforts have been devoted to developing scalable uncertainty estimation techniques for modern machine learning applications. However, most existing work on uncertainty quantification focuses on narrow function classes and specific noise distributions, or relies on asymptotic expansions or adhoc approximations. Moreover, AI systems are often deployed in interactive settings, where data is generated sequentially, introducing complex data dependencies that render any i.i.d.~assumption invalid. Constructing practical, non-asymptotic, any-time valid confidence sets under universal assumptions on the stochastic model class remains a major challenge.

Classical uncertainty quantification methods originate in the field of statistics and are typically classified into Bayesian and frequentist approaches. In frequentist uncertainty estimation, only the data is random, imposing a distribution on the estimator constructed from the data. Confidence sets are derived by modeling the randomness of the data generating process, most commonly by specifying tail bounds on the error distribution. This approach relies on propagating the noise distribution through the estimator, often (though not always) leveraging central limit arguments, i.i.d. assumptions, and strong regularity conditions on the model class to ensure tractability. Moreover, this approach is invariably dependent on the estimator that one chooses. 

Bayesian statistics, on the other hand, introduces a prior distribution over the unknown parameter and updates the posterior using Bayes' rule and the likelihood. The posterior distribution over the model parameters can be interpreted as a measure of uncertainty. Notably, Bayesian inference is a `universal recipe', in the sense that it does not require i.i.d.~data or specific assumptions on the likelihood. Obtaining the Bayesian posterior is therefore a purely computational problem, and much work has been done to develop computationally efficient methods and approximations. 

Despite its popularity, the Bayesian approach is often referred to as \emph{subjective}, as it depends on the choice of the prior. In fact, it is well understood that Bayesian credible sets do not attain frequentist coverage in general, and arguably, the Bayesian view-point is only viable assuming that the true parameter is randomly sampled from the prior distribution. It therefore seems to be a common misconception that Bayesian inference cannot easily lead to confidence sets when frequentist coverage is required. As we will see soon, the opposite is true: 
\begin{quotation}
    \emph{Any Bayesian inference model can be turned into a frequentist confidence set, and a frequentist confidence set can be constructed using Bayesian inference, preserving provable coverage even if approximate inference is used or the model is misspecified.} 
\end{quotation}
In this work, we revisit classical ideas from sequential analysis \citep{wald1947sequential2} for constructing confidence sets using likelihood ratio martingales and Ville's inequality \citep{ville1939etude}, tracing back to early works by \citet{darling1968some,robbins1970statistical}. In its simplest form, the confidence sets are level sets of the negative log-likelihood function $L_t(\theta) = L_t(\theta|x_1,y_1,\dots, x_t, y_t)$,
\begin{align}
    C_t = \big\{\theta \in \Theta : L_t(\theta) \leq \beta_t(\delta)\big\} \,, \label{eq:level-set}
\end{align}
with a confidence coefficient $\beta_t(\delta)$ that scales with the failure probability $\delta \in (0,1)$, and the complexity of the model class. To build intuition, a typical confidence coefficient will take the following approximate form, 
$$\beta_t(\delta) \approx \log \frac{1}{\delta} + L_t(\hat \theta_t^{\MLE}) + B_t\,,$$ where $\hat \theta_t^{\MLE}$ is the maximum likelihood estimator, and $B_t \geq 0$ is a complexity term that depends on the model class. Written like this, the confidence coefficient defines a \emph{relative likelihood} that allows us to interpret the confidence level of a candidate model $\theta \in \Theta$ by comparing $L_t(\theta)$ to $L_t(\hat \theta_t^\MLE)$. In practice, however, a worst-case bound on the model complexity might lead to overly conservative confidence sets, or tight bounds may not be easily available for complex function classes. Therefore, it is beneficial to define the confidence coefficient $\beta_t(\delta)$ in a data-dependent way. Importantly, a smaller $\beta_t(\delta)$ directly translates into a tighter confidence set. 

A key insight is the use of sequential mixing distributions over the likelihood ratio martingale (formally introduced in \cref{sec:mixing}), which allows to define a data-dependent confidence coefficient applicable to general model classes. Moreover, sequential mixing establishes a fundamental connection between Bayesian inference and frequentist confidence estimation. The estimation framework is not limited to Bayesian inference, and integrates with established approximate inference techniques such as variational inference and sampling based techniques, while maintaining provable coverage. The framework is universal in the sense that it does not require i.i.d.~data, any assumptions on the family of likelihood functions, and applies to any sequence of estimators. Further, using standard regret inequalities from online density estimation, the construction establishes a strong connection to classical maximum likelihood estimation.

\paragraph{Related Work} The core constructions in this paper go back to classical works, e.g.,~by \cite{wald1945sequential,darling1968some,robbins1970statistical}, and has seen revived interest in more recent literature \citep[e.g.,][]{wasserman2020universal,Emm23,flynn2024improved,lee2024unified}. More broadly, sequential mixing appears in online convex optimization, e.g., online aggregation, F-weighted portfolios \citep[c.f.,][]{orabona2019modern}, and prediction with expert advice \citep{cesa2006prediction}. Closely related is also the emerging literature on sequential testing using e-values \citep[see, e.g.,][]{grunwald2020safe} and PAC-Bayes bounds \citep[e.g.,][]{lugosi2023online,chugg2023unified}. Different to these works, here we focus on constructing confidence set for model parameters, with typical applications including inverse problems and compressed sensing.  We will refer to further related works in the relevant context, and defer a more complete historic account to \cref{sec:literature}.

\paragraph{Contributions} Our first contribution is to review classical and more recent results, establishing tight connections between seemingly disconnected works, and offering a unified framework for constructing confidence sequences using likelihood ratio martingales. The specific application of sequential mixing distributions to likelihood ratios, along with subsequent equivalence results and connections to Bayesian (approximate) inference, appears novel in this generality, to the best of our knowledge. We demonstrate the strength of the formulation by deriving improved confidence sets for sequential linear regression and for sparse estimation, with simplified proofs.


