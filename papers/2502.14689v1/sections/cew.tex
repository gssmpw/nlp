 
\section{Continuous Exponential Weights}\label{sec:cew}

Continuous exponential weights (\cref{alg:cew}) is a direct generalization of the classical exponential weights algorithm (also known as Hedge) by \cite{freund1997decision,littlestone1994weighted}. For a standard reference, see the book by \cite{cesa2006prediction}. Recall the definition of the log-loss, defined for distributions $\mu \in \sP(\Theta)$,
\begin{align*}
 l_t(\mu) = - \log \left(\int_{\Theta} p_t(y_t|\theta)d\mu(\theta)\right)
\end{align*}
Note that $l_t(\mu)$ is $\eta$-exp-concave for $\eta \leq 1$, since $\exp(-\eta l_t(\mu))$ is concave in $\mu : \sP(\Theta) \rightarrow \bR$. The (continuous) exponential weights algorithm satisfies the following regret bound, that holds for any sequence of $\eta$-exp-concave loss functions.
\begin{theorem}[Regret of Continuous Exponential Weights]\label{thm:cew}
    For any distribution $\rho \in \sP(\Theta)$, and any sequence of $\eta$-exp-concave loss functions $l_1, \dots, l_t$, the regret of the exponential weights algorithms with prior $\mu_0 \in \sP(\Theta)$ and learning rate $\eta$ satisfies
    \begin{align*}
        \sum_{s=1}^t l_s(\mu_{s-1}) - \int L_t(\theta) d\rho \leq \frac{1}{\eta}\KL(\rho, \mu_0)
    \end{align*}
    % So in particular, for any $\theta \in \Theta$ and assuming that $\delta_\theta \ll \mu_0$,
    % \begin{align}
    %     \sum_{t=1}^n \tilde l_t(\mu_t) - \sum_{t=1}^n l_t(\theta) \leq \log\left(\frac{1}{\mu_0(\theta)}\right)
    % \end{align}
    Moreover, for finite $\Theta$ and any $\nu \in \Theta$,
    \begin{align*}
        \sum_{s=1}^t  l_s(\mu_{s-1}) -  L_t(\nu) \leq \frac{1}{\eta}\log \frac{1}{\rho(\nu)}
    \end{align*}
\end{theorem}


% \begin{remark}
%     Note that $\tilde l_t(\mu_t)$ is the `posterior' log likelihood of $p(y|x,\theta)\mu_t(\theta)$.
% \end{remark}
\begin{proof} Denote by $\delta_{\theta} \in \sP(\Theta)$ the Dirac measure on $\theta \in \Theta$. Define the unnormalized measure 
    \begin{align*}
    %    \tilde \mu_t(d\theta) = \exp(-\eta L_{t}(\theta)) \mu_0(d\theta) = \prod_{s=1}^{t} \exp(-\eta l_s(\delta_\theta)) \mu_0(d\theta)
       \tilde \mu_t(d\theta) = \prod_{s=1}^{t} \exp(-\eta l_s(\delta_\theta)) \mu_0(d\theta)
    \end{align*}
    Note that $\mu_t(d\theta) = \frac{\tilde \mu_t(d\theta)}{\tilde \mu_t(\Theta)}$.
To prove the regret bound note that by $\eta$-exp-concavity of $l_t$,
\begin{align*}
    \frac{\tilde \mu_t(\Theta)}{\tilde \mu_{t-1}(\Theta)} &= \int \exp(-\eta l_t(\delta_\theta)) d\mu_{t-1}(\theta) \leq \exp (- \eta  l_t(\mu_{t-1}) )
\end{align*}
Further, for any $\rho \in \sP(\Theta)$, the variational inequality (\cref{lemma:variational-kl}) implies
\begin{align*}
\tilde \mu_t(\Theta) \geq \exp \Big( - \eta \ip{L_n, \rho} - \KL(\rho, \mu_0)\Big)
\end{align*}
Combining the last two inequalities and telescoping, we get
\begin{align*}
    \sum_{s=1}^t  l_s(\mu_{s-1}) -  \int L_s(\theta) d\rho(\theta) \leq \frac{1}{\eta}\KL(\rho, \mu_0)
\end{align*}
This completes the first part of the proof. The second part follows by setting $\rho=\delta_{\nu}$.
\end{proof}


\LinesNumbered
\RestyleAlgo{ruled}
\begin{algorithm2e}[t]
	\DontPrintSemicolon
	\SetAlgoVlined
	\SetAlgoNoLine
	\SetAlgoNoEnd
	\caption{Continuous Exponential Weights} \label{alg:cew}
    \SetKwInput{KwInput}{Input}
    
    \KwInput{Prior $\mu_0 \in \sP(\Theta)$, learning rate $\eta > 0$}

    \For{$t \gets 1, 2. \dots$} {
        \textbf{Predict:} $\mu_{t-1}$\;
        \textbf{Observe:} $x_t, y_t$\;
        \textbf{Receive (log) loss:}$$l_t(\mu_{t-1}) = - \log \left(\int p_t(y_t|\theta)d\mu_{t-1}(\theta)\right)$$\;
        \textbf{Update} $\mu_t(d\theta) \propto \exp\big(-\eta \sum_{s=1}^t l_s(d\theta)\big) \mu_0(d\theta)$ \textbf{:}
        $$\mu_t(d\theta)  = \frac{\exp\big(\eta \log p_t(y_t|\theta)\big) \mu_{t-1}(d\theta)}{\int \exp\big(\eta \log p_t(y_t|\nu)\big) d\mu_{t-1}(\nu)}$$
    }
\end{algorithm2e}

\paragraph{Confidence Sequences using Continuous Exponential Weights} 
Substituting the regret bound from \cref{thm:cew} into \cref{result:posterior_mixing} yields the following $(1-\delta)$-confidence sequence, which holds for any $\cF_t$-adapted sequence $\mu_1,\mu_2, \dots \in \sP(\Theta)$:
\begin{align*}
    C_t  = \left\{ \theta \in \Theta: L_t(\theta) \leq  \log \frac{1}{\delta} + \int L_t(\theta) d\mu_t(\theta) + \KL(\mu_t \| \mu_0)\right\} \,.
\end{align*}
Note that we have recovered the ELBO-confidence set from \cref{result:elbo_confidence_set}. In other words, the regret bound of continuous exponential weights is the sequential analog of the variational inequality \cref{lemma:variational-kl}, and because of the mixing equivalence (\cref{result:mixing-equivalence}), the resulting confidence sets are the same. Unfortunately, for continuous $\Theta$, the bound becomes vacuous when $\rho$ is set to a Dirac measure. This prevents us from using $\mu_t = \delta_{\hat \theta_t^\MLE}$ to derive a confidence set that directly compares to the maximum likelihood estimate. A more careful analysis using additional smoothness assumptions is a possible way forward \citep[c.f.,][]{lee2024unified}.



