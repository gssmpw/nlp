\section{Confidence Estimation via Sequential Likelihood Mixing}

% semi-formal problem definition
We study the sequential confidence estimation problem in which the learner is given a set of model parameters $\Theta$, and a family of conditional densities $\cM = \{p_\theta(y|x): \theta \in \Theta\}$. 
The learner observes a data stream $x_1, y_1, x_2, y_2, \dots, x_t, y_t, \dots$, where $x_t$ is a covariate and $y_t \sim p_{\theta^*}(\cdot|x_t)$ is an observation sampled from a distribution with a ground-truth parameter $\theta^* \in \Theta$. We make no assumptions on how the covariates a generated, in particular, allow for an arbitrary dependence between $x_t$ and all prior data. The role of $x_t$ is secondary and is mostly introduced to match standard machine learning settings. For simplicity, we suppress the dependence on $x_t$ and denote $p_t(y|\theta) = p_{\theta}(y|x_t)$.
Our objective is to construct an anytime \emph{$(1-\delta)$-confidence sequence}: In each round $t \geq 1$, the learner outputs a set $C_t \subset \Theta$, such that $\theta^* \in C_t$ for all $t \geq 1$ holds with probability at least $1-\delta$.

% formal problem definition
\paragraph{Setting} Formally, we let $\cY$ be a measurable observation space and $\cX$ be a measurable covariate space. Let $\bP$ be the true data generating distribution over $(\cX \times \cY)^\infty$, with the data stream $({x_t, y_t})_{t=1}^\infty \sim \bP$. Unless stated otherwise, all probabilistic statements are with respect to this measure. The filtration corresponding to the observation sequence is $\cF_t = \{x_1,y_1, \dots ,x_{t-1},y_{t-1}, x_t\}$. We abbreviate the marginal distribution over the outcome $y_t$, conditioned on past data, with $\bP_t = \bP_{y_t}(\cdot | \cF_t)$. We assume that $\bP_t$ is dominated by a base measure $\xi$ over $\cY$ for all $t \geq 1$. 

We require that $\Theta$ is a measurable space and the density $p_t(y|\theta)$ defines a probability kernel $p_t(y|\theta) d \xi(y)$ from $\Theta$ to $\cY$. We consider both, finite and continuous $\Theta$, and let $\omega$ be a base measure over $\Theta$ (typically the counting measure for finite $\Theta$, or the Lebesgue measure for $\Theta \subset \bR^d$). The space of probability distributions over $\Theta$ is $\sP(\Theta)$. The Kullback-Leibner (KL) divergence between two distributions $\rho, \mu \in \sP(\Theta)$ with $\rho, \mu \ll \omega$ is $\KL(\rho\|\mu) = \int \rho(\theta) \log \frac{\rho(\theta)}{\mu(\theta)} d\omega(\theta)$. We make the following realizability assumption (which we will relax in \cref{sec:misspecified}),
\begin{assumption}[Realizability]\label{a:realizability}
There exists a $\theta^* \in \Theta$ such that $p_t(\cdot|\theta^*) = \frac{d\bP_t}{d\xi}$\,.
\end{assumption}
We remark that realizability and our definition of the model class imply that the distribution $y_t$ conditioned on $x_t$ is stationary and independent of past data, $\bP_t(\cdot|\cF_t) = \bP_t(\cdot|x_t) = p_{\theta^*}(\cdot|x_t)d\xi$. This requirement can be relaxed by defining a model class that is conditioned on the full history.

\paragraph{Confidence Sequences} Let $\delta \in (0,1)$ be a failure probability. Our a goal is to construct a $\cF_t$-adapted sequence of confidence sets $C_1, C_2, \dots \subset \Theta$, such that
\begin{align*}
\bP[\exists t \geq 1 \text{ s.t. }\theta^* \notin C_t] \leq \delta\,.
\end{align*}
In other words, the Type-I error over all time steps is at most $\delta$. We briefly remark that coverage can be achieved trivially, e.g., $C_t = \Theta$ for all $t \geq 1$ is a $(1-\delta)$-confidence sequence, and so is a randomly choosing $(1-\delta)$-fraction of $\Theta$, such that the probability $\{\theta \in C_t\}$ is $1-\delta$ for \emph{any} $\theta \in \Theta$. While these maintain coverage, they are not useful in practice because they do not control the Type-II error, or equivalently, the size of the confidence set, in a meaningful way. Hence, we aim to construct a $(1-\delta)$-confidence sequence and make $C_t$ as small as possible at the same time.

\subsection{Ville's Inequality and Sequential Likelihood Ratios}

We start by reviewing confidence sets based on sequential likelihood ratios \citep{robbins1970statistical,lai1985asymptotically}. Assume that in each round $t \geq 1$, after observing the data $\{x_1, y_1, \dots x_t, y_t\}$, we have a way to construct an estimator $\hat \theta_t \in \Theta$. Formally, the \emph{estimation sequence} $\hat \theta_1, \hat \theta_2, \dots$ is an $\cF_t$-adapted process in $\Theta$. In addition, we include a prior estimate $\hat \theta_0 \in \Theta$ that is chosen before any data is observed. Define the sequential likelihood ratio process for $\theta \in \Theta$,
\begin{align}
    R_t(\theta) = \prod_{s=1}^t \frac{p_s(y_s|\hat \theta_{s-1})}{p_s(y_s|\theta)} \,.
\end{align}
It is important to note that the likelihood of $y_s$ is evaluated under the estimate $\hat \theta_{s-1}$, making the predicted density $p_s(\cdot|\hat \theta_{s-1})$ independent of the observation $y_s$. It is straightforward to verify that $R_t(\theta^*)$ is a non-negative martingale with respect to the filtration $\cF_t$, i.e. 
\begin{align}
    \EE[R_t(\theta^*)|\cF_{t}] &= R_{t-1}(\theta^*) \int \frac{p_t(y|\hat \theta_{s-1})}{p_t(y|\theta)} d\bP_t(y)\nonumber \\
    & \stackrel{(*)}{=} R_{t-1}(\theta^*) \int \frac{p_t(y|\hat \theta_{s-1})}{p_t(y|\theta)} p_t(y|\theta) d\xi(y)  = R_{t-1}(\theta^*) \,.
\end{align}
The second equality $(*)$ uses realizability (\cref{a:realizability}).
% \begin{align*}
% \EE[R_t(\theta^*)|\cF_{t}] = R_{t-1}(\theta^*)
% \end{align*}
The tail event that $R_t(\theta^*)$ growths large is bounded using Ville's inequality \citep{ville1939etude}, which generalizes Markov's inequality to non-negative supermartingales.
\begin{lemma}[Ville's Inequality \citep{ville1939etude}]
    Let \((M_t)_{t \geq 1}\) be a non-negative supermartingale. For any \(\alpha > 0\),
    \begin{align}
        \mathbb{P}\left[\sup_{t \geq 1} M_t \geq \alpha \right] \leq \frac{\mathbb{E}[M_1]}{\alpha} \,.
    \end{align}
\end{lemma}
Applying Ville's inequality to $R_t(\theta^*)$, noting that $R_t(\theta^*) \geq 0$ and $\EE[R_1] =1$, we get that
\begin{align*}
    \bP\left[\sup_{t \geq 1} R_t(\theta^*) \geq \frac{1}{\delta}\right] \leq \delta \,.
\end{align*}
By inverting the inequality, we obtain a $(1-\delta)$-confidence sequence $C_t = \{ \theta \in \Theta : R_t(\theta) \leq \frac{1}{\delta}\}$. As a last step, we re-write the inequality using the negative log-likelihood,
\begin{align*}
L_t(\theta) = L(\theta|x_1,y_1, \dots, x_t, y_t) = - \sum_{s=1}^t \log p_t(y_t|\theta) \,.
\end{align*}
We summarize the construction in the next theorem. Similar constructions have gained renewed interest more recently \citep[e.g.,][]{wasserman2020universal,Emm23}.
\begin{theorem}[Sequential Likelihood-Ratio \citep{robbins1970statistical}] \label{result:likelihood_ratio_confidence_set}
   Let $\hat \theta_0, \hat \theta_1, \hat \theta_2, \dots$ be an estimation sequence adapted to the filtration $\cF_t$. Define
    \begin{align*}
        C_t = \left\{ \theta \in \Theta : L_t(\theta) \leq \log \frac{1}{\delta} - \sum_{s=1}^t \log p_s(y_s|\hat \theta_{s-1}) \right\} \,.
    \end{align*}
    Then $C_t$ is a $(1-\delta)$-confidence sequence for $\theta^*$, i.e.~$\bP[ \forall t \geq 1, \theta^* \in C_t ] \geq 1-\delta$.
\end{theorem}
% The geometric shape of the confidence set is a level set of the log-likelihood function (\cref{eq:level-set}), 
% \begin{align}
%     C_t = \{\theta \in \Theta : L_t(\theta) \leq \beta_t(\delta)\} \label{eq:level-set}
% \end{align}
% with a confidence coefficient $\beta_t(\delta)$ that depends on the data, the estimation sequence and the failure probability $\delta$. 
% Confidence sets that take the form of a level set of the log-likelihood function will be a re-occurring theme in this document, and we may compare the size of such confidence sets by comparing the coefficient $\beta_t(\delta)$. 
The confidence set defined in \cref{result:likelihood_ratio_confidence_set} does not require any assumptions on the family of likelihood functions other than realizability, and makes no assumptions on how the covariates $x_1, x_2, \dots$ are generated, or how the estimation sequence $\hat \theta_0, \hat \theta_1, \dots, \hat \theta_t$ is chosen. The size of the confidence set depends on the ability of the learner to produce an estimation sequence that maximizes the log-likelihood $\sum_{s=1}^t \log p_s(y_s|\hat \theta_{s-1})$. Since the estimated density $p_t(\cdot |\hat \theta_{s-1})$ is evaluated under the next observation $y_s$, it measures the accuracy of the learner to predict the next outcome.


% The construction has two immediate drawbacks: First, the construction requires the parameter estimate $\hat \theta_{t-1}$ used to define the log-likelhood $p_t(y_t|\hat \theta_{t-1})$ at time $t$ to be predictable, and classical estimators such as the maximum likelihood estimator cannot be directly plugged into the construction. Second, the construction heavily depends on the parametrization of the conditional likelihood, which introduces an arbitrary dependence that makes it difficult to directly analyze the confidence set without further assumptions.

\subsubsection{Maximum Likelihood Estimation} \label{sec:mle}
Maximum likelihood estimation is a cornerstone of classical frequentist statistics and closely related to sequential likelihood ratios. Formally, we define the maximum likelihood estimate (MLE)  as a minimizer of the negative log-likelihood,
\begin{align*}
    \hat \theta_t^{\MLE} = \argmin_{\theta \in \Theta} L_t(\theta) \,.
\end{align*}
Further, define the likehood ratio for $\nu, \theta \in \Theta$,
\begin{align} 
    R_t(\nu, \theta) = \prod_{s=1}^t \frac{p_s(y_s|\nu)}{p_s(y_s|\theta)}  \,.\label{eq:two-parameter-ratio}
\end{align}
It is tempting to use the maximum likelihood estimator in the construction of \cref{result:likelihood_ratio_confidence_set}. However, this fails because $R_t(\hat \theta_t^{\MLE}; \theta^*) = \max_{\nu \in \Theta} R_t(\nu; \theta^*)$ is not a super-martingale.

Fortunately, there are several ways to proceed, and we will come back to this in later sections. To set expectations, note that $R_t(\nu;\theta^*)$ is a martingale for any \emph{fixed} $\nu \in \Theta$. Ville's inequality implies that $\bP[\sup_{t \geq 1} R_t(\nu;\theta^*) \geq \frac{1}{\delta}] < \delta$. For finite $\Theta$, a union bound over $\Theta$ suffices to obtain a bound for all $\nu \in \Theta$ simultaneously, and, in particular, for any estimator $\hat \theta_t$. The resulting $(1-\delta)$-confidence sequence is
\begin{align}
C_t = \{ \theta : L_t(\theta) \leq \log \frac{1}{\delta} +  L_t(\hat \theta_t) + \log(|\Theta|) \} \,.
\end{align}
 Note that $C_t$ is a log-likelihood level set as in \cref{eq:level-set} with coefficient $\beta_t(\delta) = \log \frac{|\Theta|}{\delta} +  L_t(\hat \theta_t)$. The difference to \cref{result:likelihood_ratio_confidence_set} is that the union bound allows to compare directly to the log-likelihood $L_t(\hat \theta_t)$ for any estimator $\hat \theta_t$ computed in hindsight, using all observed data. The coefficient is minimized (resulting in the smallest confidence set) by the maximum likelihood estimator $\hat \theta_t^\MLE$. For continuous parameter sets, the argument extends using a suitable covering for $\Theta$. 


\subsection{Prior Likelihood Mixing}

We now introduce a second approach to construct an anytime confidence sequence using the idea of `mixing'. Again, we make use of a martingale process, defined by integrating the likelihood ratio over a given prior distribution. An early reference to this idea is by \cite{robbins1970boundary}, who use mixture martingales to prove law-of-the-iterated-logarithm type bounds. Mixture martingales were popularized in the context of self-normalized bounds by \cite{pena2009self} as the `method of mixtures', with repeated interest in the machine learning community \citep[e.g.,][]{abbasi2011improved}.

Formally, let $\mu_0 \in \sP(\Theta)$ be a data-independent prior distribution. Recall the definition of $R_t(\nu;\theta)$ from \cref{eq:two-parameter-ratio}, and define the \emph{marginal likelihood ratio},
\begin{align*}
    Q_t(\theta) = \int R_t(\nu; \theta) d\mu_0(\nu) =  \frac{ \int \prod_{s=1}^t p_s(y_s|\nu)  d\mu_0(\nu)}{\prod_{s=1}^t p_s(y_s|\theta)} \,.
\end{align*}
Using Fubini's theorem, it follows that $Q_t(\theta^*)$ is a non-negative martingale with $\bE[Q_1(\theta^*)]=1$. Once again, we use Ville's inequality to bound the deviation,
\begin{align*}
    \bP\left[\sup_{t \geq 0} Q_t(\theta^*) \geq \frac{1}{\delta}\right] \leq \delta \,.
\end{align*}
The next theorem summarizes this result.
\begin{theorem}[Prior Likelihood Mixing]\label{result:prior_mixing}
    For any data-independent prior $\mu_0 \in \cP(\Theta)$, define
    \begin{align*}
        C_t &= \left\{ \theta \in \Theta: L_t(\theta) \leq  \log \frac{1}{\delta} - \log \int \prod_{s=1}^t p_s(y_s|\nu) d\mu_0(\nu) \right\} \,.
    \end{align*}
Then $C_t$ is a $(1-\delta)$-confidence sequence.
% where $L_t(\theta) := - \sum_{s=1}^{t} \log p_\theta(y_s|x_s)$ and $M_t = \int \prod_{s=1}^t p_{\nu}(y_s|x_s) d\mu_0(\nu)$
\end{theorem}
Note that the size of the confidence set is determined by the logarithm of the \emph{marginal likelihood} under the prior $\mu_0$, also referred to as Bayesian \emph{evidence}. To understand intuitively why the marginal likelihood offers a reasonable confidence threshold, assume that $\Theta \subset \bR^d$. A second-order Taylor expansion of $L_t(\theta)$ around the maximum likelihood estimate $\hat \theta_t^\MLE$ allows to compute the marginal likelihood in closed-form as a Gaussian integral. This is known as Laplace's method \citep{laplace1774memoire}. Under suitable technical regularity assumptions \citep[e.g.,][]{shun1995laplace}, the following asymptotic expansion holds,  
where $I_t(\theta) = \frac{\partial^2}{\partial \theta^2} L_t(\theta) \in \bR^{d\times d}$ is the empirical Fisher information matrix:
\begin{align*}
    - \log \int \exp(-L_t(\nu))  h(\nu) d\theta
    &\approx L_t(\hat \theta_t^{\MLE})  + \frac{1}{2}\log \det I_t(\hat \theta_t^\MLE) - \frac{d}{2} \log(2\pi) - \log \mu_0(\hat \theta_t^\MLE)  \,.
\end{align*}
This should be compared to the discussion in \cref{sec:mle}. Although $\max_{\nu} R_t(\nu,\theta^*)$ is not a martingale, the marginal likelihood ratio offers an approximation while preserving the martingale property. Further details are in \cref{sec:laplace}, and for an elementary introduction to Laplace's method and its relation to the method of mixtures, we refer to \citet[Chapter 20]{lattimore2020bandit}.


% The idea of u
% \begin{itemize}
%     \item Laplace method and MLE, online density estimation
%     \item Bayesian Posterior However, the Bayesian-minded reader may already have spotted that the construction is equivalent to predicting with the Bayesian posterior $\mu_t$, which we will elaborate below. , also referred to as the Bayesian `evidence'. Simply put, larger evidence leads to a smaller confidence set.

% \end{itemize}
% Computationally, ELBO


% % Assume that the prior $\mu_0$ is absolutelly continuous with respect to the Lebegues meausre and admits a density. 
% Let 
% \begin{align*}
% \hat \theta_t^{MAP} = \argmax_{\theta \in \Theta} L_t(\theta) + \mu_0(\theta)
% \end{align*} \todoj{compact space ?}
% In the case where the prior is uniform, the MAP estimate is equivalent to the maximum likelihood estiamte.
% Laplace method approximates the integral by 
% \begin{align*}
% L_t(\theta) + \mu_0(\theta) \approx L_t(\theta) + \nabla + Hessian
% \end{align*

% Fisher Information $\cI(\theta) = \EE[I_t(\hat \theta_t^{MAP})]$

% \todoj{frequentist asymptotics}


\subsection{Sequential Likelihood Mixing}\label{sec:mixing}
% 
% The effectiveness of the sequential likelihood-ratio confidence set in \cref{result:likelihood_ratio_confidence_set} relies on prediciting a sequence of estimators that effectively maximize the log-likelihood $\sum_{s=1}^t \log p_s(y_s|\hat{\theta}_{s-1})$. However, with limited data, any estimator statistically deviates from the true parameter \(\theta^*\), effectively resulting in a small estimated likelihood, and hence a larger confidence set. A natural idea is to hedge  extend the idea of mixing to the sequential setting.
% 
We now generalize the idea of mixing to the sequential setting.
Formally, let $\mu_1, \mu_2, \dots$ be an $\cF_t$-adapted sequence of \emph{mixing distributions} in $\sP(\Theta)$, and $\mu_0 \in \sP(\Theta)$ a `prior' mixing distribution that is chosen before any data is observed. We define the \emph{sequential marginal likelihood ratio}, 
\begin{align*}
    S_t(\theta)= \prod_{s=1}^t  \frac{\int p_s(y_s|\nu) d\mu_{s-1}(\nu)}{p_s(y_s|\theta)} \,.
\end{align*}
One can think of the mixing distribution $\mu_{s-1}$ as a weighted prediction, aggregation over parameters in $\Theta$. As before, Fubini's theorem is used to show that $S_t(\theta^*)$ is a non-negative martingale under $\cF_t$ with $\EE[S_0(\theta^*)] = 1$, and therefore Ville's inequality implies that
\begin{align*}
     \bP\left[\sup_{t \geq 0} S_t(\theta^*) \geq \frac{1}{\delta}\right] \leq \delta \,.
\end{align*}
Rewriting the concentration inequality using the negative log-likelihood yields the following result.
\begin{theorem}[Sequential Likelihood Mixing]\label{result:posterior_mixing} Let $\mu_0, \mu_1, \mu_2,\dots$ be a sequence of $\cF_t$-adapted mixing distributions in over $\Theta$. Define for $t \geq 1$,
    \begin{align*}
        C_t  = \left\{ \theta \in \Theta: L_t(\theta) \leq  \log \frac{1}{\delta} - \sum_{s=1}^t \log \int p_s(y_s|\nu) d\mu_{s-1}(\nu)\right\} \,.
    \end{align*}
    Then $C_t$ is a $(1-\delta)$-confidence sequence.
\end{theorem}
 \Cref{result:posterior_mixing} can be understood as a sequential analog of the method of mixtures (\cref{result:prior_mixing}), and recovers the sequential likelihood ratio confidence set (\cref{result:likelihood_ratio_confidence_set}) as a special case by setting $\mu_t$ to a Dirac measure on $\hat \theta_t$. The use of sequential mixing distributions has appeared in the literature before \cite[e.g.,][]{kirschner2018information,Emm23,flynn2024tighter}, but we are not aware of a reference that applies mixing directly to the sequential likelihood ratio.



% The remainder of the work is spent on discussing the above choices, with the goal to establish precise relations and a unifying perspective. %However, before moving on, we introduce a second approach to create a mixing martingale.



\section{Applications, Connections and New Perspectives}

Sequential mixing provides a versatile framework for constructing confidence sequences for general parametric model classes via \cref{result:posterior_mixing}. A natural candidate for the mixing distribution is the Bayesian posterior, which we analyze in subsequent subsections. However, the range of possible mixing distributions extends far beyond Bayesian inference, often offering computational and statistical trade-offs. While there is no universally optimal choice, a key consideration is that the resulting confidence set is typically tighter when the mixing distribution $\mu_t$ is concentrated around the true parameter $\theta^*$. For completeness, we list several possible choices below, noting that all of these, including point estimates and sampling-based approximations (e.g., Monte Carlo methods), yield valid $(1-\delta)$-confidence sequences.

% \begin{itemize}
% \item \textbf{Bayesian Inference:} As already alluded to, although the confidence set construction is purely frequentist, a natural approach is to update the mixing distributions using Bayes' rule: $\mu_t(\theta) \propto \prod_{s=1}^t p_t(y_t|\theta) \mu_0(\theta)$. This view point is discussed in detail in \cref{sec:bayes} below.
% \item \textbf{Variational Inference:} 
% Computing the marginal likelihood (or the Bayesian posterior) is intractable in general, but approximate inference methods are available in many cases. In \cref{sec:elbo}, we explore a connection to variational inference and show how the evidence lower bound (ELBO) naturally replaces the marginal likelihood, maintaining provable coverage. %\todoj{better itegrate this list}
% \item \textbf{Sampling:}
% Sampling-based approximation to posterior inference is another viable candidate. If the posterior distributions are log-concave it is known that Langevin dynamics provides an efficient way to sample from the posterior \cite{dwivedi2019log}. As such $\mu_t(\theta) = \frac{1}{N}\sum_{i=1}^N \delta_{\tilde{\theta}_t^i}$, where we sum the delta functions and $\tilde{\theta}_t^i$ are the $N$ samples from the posterior at the time point $t$.
% \item \textbf{Running MLE:}
% Similarly to Robbins' original idea, $\mu_t = \delta_{\hat{\theta}_t^{\text{MLE}}}$ can be a running sequence of MLEs. This variant is explored by \cite{Emm23}, and by \cite{lee2024unified} when convoluted with a uniform distribution. 
% \item \textbf{Online Density Estimation:} The choice of the right mixing distribution $\mu_t$ can be viewed also through lenses of online convex optimization (or online learning), which studies sequential prediction through the lenses of optimization. The task of sequentially minimizing the log-loss $l_t(\mu) = - \log \int p_t(y_t|\theta) d\mu(\theta)$ is also known as \emph{online density estimation}. In \cref{sec:oco} we explore this perspective further, and establish a connection between sequential mixing, maximum likelihood estimation and regret inequalities.
% \end{itemize}

\begin{itemize}
    \item \textbf{Bayesian Inference:} A natural approach is updating the mixing distributions via Bayes' rule: $\mu_t(\theta) \propto \prod_{s=1}^t p_t(y_t|\theta) \mu_0(\theta)$. This is discussed in detail in \cref{sec:bayes}.
    \item \textbf{Variational Inference:} When the marginal likelihood is intractable, variational inference methods provide computational lower bounds on the evidence, see \cref{sec:elbo} below.
    \item \textbf{Posterior Sampling:} Using sampling-based approximations, such as Langevin dynamics \citep{dwivedi2019log}, we can set $\mu_t(\theta) = \frac{1}{N} \sum_{i=1}^N \delta_{\tilde{\theta}_t^i}$ for $N$ samples $\tilde \theta_t^1, \dots, \tilde \theta_t^N \in \Theta$.
    \item \textbf{Online Estimation:} Complexity bounds from online density estimation allow to relate the sequential mixing confidence set to classical supervised estimation, see \cref{sec:oco}.
    % \item \textbf{Point Estimates:} Point estimates, such as the sequential maximum likelihood estimator $\mu_t = \delta_{\hat{\theta}_t^{\text{MLE}}}$, see \citep{robbins1970statistical,Emm23}.
\end{itemize}


