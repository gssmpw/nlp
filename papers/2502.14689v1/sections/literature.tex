% \todoj{conformal prediction, empirical Bayes, Bayes factor, Bayesia experimental design, vovk's online aggregation, Bayesian tools used in frequentist lower bounds, confidence distributions}
\section{Related Literature}\label{sec:literature}
The likelihood principle is at the core of modern statistics. It is only natural that it features in tasks associated with modern statistical decision theory such as the likelihood ratio test. Its history dates back to \cite{wald1945sequential} who considered sequential likelihood ratios for hypothesis testing rather than constructing confidence sequences. One of the earliest references that explicitly considers confidence sets constructed from likelihood ratios is by \citet{darling1968some,robbins1970statistical}. The difference in treatment persists in literature till today. However, the difference is mostly superficial. There is a tight link between confidence sets (or sequences thereof) and statistical tests (and sequential execution of those). Given any of a confidence set, we can directly construct a test, and any family of point-wise tests can be turned into a confidence set. The literature is split between analyzing sequential confidence sets and sequential testing. Yet, more splits occurs when we look at different fields.  A large portion of contributions are made within the field of mathematical statistics, which does not always overlap with modern machine learning theory and sequential decision making. Below we will try to provide links to works from both branches in the literature, and explain differences and similarities, giving the hint of historical, but not yet exhaustive, timeline. 

% The analysis of sequential probabilities is in-depth connected to the theory of martingales, betting, and the game-theoretic interpretation of probability \cite{shafer2019game}. Hence, the main tools for analyzing these concepts come from martingale theory as well. 

\paragraph{Sequential Likelihood Ratios: Origins}
While ideas of sequential likelihood ratios were explored earlier, the work by \citet{robbins1970statistical} is the foundational pillar of later works. This work already contains the ideas of combining Ville's inequality and likelihood ratios to obtain anytime-valid confidence sequences. Mixing with a prior distribution is also presented, which stems from \citet{robbins1970boundary}, with example calculations for example densities, including Gaussian, along with the derivation of the law-of-iterated-logarithm. The work lacks explicit extensions to multi-parameter probability distributions, (un-controlled) covariates. \citet{robbins1970statistical} does not discuss relation to marginal likelihood and Bayesian inference. Later, \cite{Robbins1972} shows how to construct testing scheme with increasing thresholds using these martingale techniques, and proves asymptotic power of these tests. \citet{lai1976confidence} builds upon these works and considers the likelihood ratio for exponential families explicitly. This is later used in order to derive asymptotically optimal bandit algorithm in \cite{lai1985asymptotically}. This is by no mean exhaustive list, however to the best our knowledge this line of work always concerns itself with single parameter families with the notable exception \cite{lai1994modification}. The reviews of \cite{lai2001sequential, lai2009martingales} summarizes the above results from the past decades. Basic martingale tools such such as method of mixtures are extensively used. Closely related to the current work is also the work by \cite{wasserman2020universal} on \emph{universal inference}, which uses the sequential likelihood ratio tests to construct confidence sets, building on the ideas of \cite{robbins1970statistical}. The work heavily focuses on the i.i.d.~setting and the split likelihood ratio test, but refers also a sequential treatment in later sections. 

\paragraph{Mathematical Statistics: Sequential Testing, Mixing and E-Values}
That the likelihood ratio is a martingale under the true distribution as has been clearly demonstrated in the above works. However, other random processes can act as testing martingales, and are referred to in this context as \emph{e-values}. For example, testing sequences can be constructed for classes of likelihood functions (e.g., sub-Gaussian, symmetric, etc). In this context, the method of mixtures and self-normalized processes are extensively used in the seminal work by \citet{pena2009self}. These ideas were further generalized by \cite{Howard2018,Howard2020,chowdhury2023bregman} for many other sub-families, different spaces of random variables beyond Hilbert spaces. The modern treatment of safe anytime inference and game-theoretic interpretation using e-values was initiated in a sequence of works by \citet{vovk2014game,grunwald2020safe,wang2022false,shafer2019game}. The very recent book by \citet{ramdas2024hypothesis} provides an excellent overview, and includes more complete historic account and recent developments. 


\paragraph{Online Estimation, Regret Bounds and Universal Portfolios} There is a rich history on works that study the problem of minimizing the log loss. Regret bounds for online aggregation and online density estimation were pioneered in early works by \citet{vovk1990aggregating,littlestone1994weighted}. A standard reference is the book by \citet{cesa2006prediction}.  In mathematical finance, minimizing the log-loss is equivalently interpreted as maximizing the log return of an allocation strategy, and mixing algorithms are already used by \citet{cover1984algorithm}, most famously for the \emph{universal portfolio}  algorithm \citep{cover1991universal}. The use of regret bounds for constructing concentration inequalities however seems to appear much later in works by \citet{rakhlin2017equivalence,orabona2023tight,ryu2024confidence}. For an introductory text, we refer to \citet{orabona2019modern}. A notable result by  \citet{rakhlin2017equivalence} establishes an equivalence between regret bounds and martingale concentration inequalities.

The idea of using regret bounds for constructing confidence sequences for parametric inverse problems, similar to \cref{result:regret}, is by \citet{abbasi2012online}, who use regret bounds for deriving confidence sets sparse linear regression in the context of linear bandits. We re-derive their result in the mixing framework, with improved constants (see \cref{sec:sparse}). These ideas were further extended to generalized linear models, albeit without the use of mixing in by \cite{Jun2017,lee2024improved}. Lastly, \cite{Emm23} builds on this with likelihood ratios, and interpret the sequential likelihood ratio in \cref{result:likelihood_ratio_confidence_set} as an online prediction game, and analyze the regret of follow-the-regularized leader algorithm which coincides with the running MLE. Different to this work, they analyze it in terms of the parameters of the distribution instead of using mixing distributions, as done in this work. %The online-learning scheme and theoretical results are not general and instead focus only on special case of generalized linear models and follow-the-regularized leader. 



% The literature around e-values has mostly focused on limits and understanding the problem in general context. For example, to look for the best possible super-martingale, i.e. they studied the admissibility of the procedure \cite{Ramdas2020}. A very good summary of works in this direction is presented in \cite{Ramdas2023-game-theoretic} in term of game-theoretic interpretation, while \cite{ramdas2024hypothesistestingevalues} goes more in the hypothesis testing aspect. The likelihood ratio is only a very specific choice of an e-process in this context. 


\paragraph{Sequential Decision Making} Anytime confidence sets play a central role in sequential decision making, including bandit algorithms \citep{lattimore2020bandit} and reinforcement learning theory \citep{agarwal2019reinforcement,foster2023foundations}. There is a large variety of settings and assumptions, but shared is that the learning algorithms controls, to varying degree, the evolution of covariates (e.g., evolving a state by choosing actions). The consequence is that the observation at step $t$, in general, depends on the previous observation history. The data becomes inherently non-i.d.d., and tools such as those described in this work, are essential. Uncertainty estimates or often explicitly used to balance exploration and a goal-driven objective, or to account for safety constraints. Confidence intervals are famously used in the family of upper confidence bound algorithms for action selection \citep{lai1985asymptotically,lai1987adaptive,auer2002finite}. In this context, \citet{abbasi2011improved} uses the method of mixtures to construct improved bounds for the linear bandit. There is a large body of subsequent works, and we can only list a few examples \citep[e.g.,][]{chowdhury2017kernelized,kirschner2018information,Faury2020,Mutny2021a,flynn2024improved,flynn2024tighter}. \citet{lee2024unified} uses the variational inequality as in \cref{lemma:variational-kl} to derive confidence sets for logistic regression. By using the regularity of the likelihood, namely smoothness, and boundedness of the parameter set, they derive tight bounds on the log-likelihood relative to the maximum likelihood estimate. Closely related is the work by \citet{Emm23}, who study the sequential likelihood ratio test of \citet{robbins1970statistical} with an explicit application to sequential decision making.
% try to describe the geometry of these set. They choose a sequence of point estimates using the running MLE estimates, and prove the worst-case size of these confidence sets. The motivation is the use of these confidence sets in sequential decision making. They establish an analysis based on online-convex optimization, where the losses are defined by log likelihoods. 
 

% Another closely related work is by \citet{neiswanger2021uncertainty}, which who frequentist confidence sequences for the Bayesian regression (in the context of Bayesian optimization). They use the likelihood ratio method with prior mixing equivalent to ours. Their motivation is to achieve frequentist coverage of Bayesian credible intervals, for any choice of prior. Other choices than Gaussian likelihood and Gaussian prior are not discussed. 

% Similarly, \cite{chowdhury2023bregman}, also consider likelihood ratio confidence sets. Their goal, however is to report a centered confidence set around a regularized maximum likelihood estimator, and present them in concise analytical form clearly showcasing a distance function, in this case a Bregman divergence. They use mixing in their derivation of the confidence set. In order to derive the threshold parameters, the authors utilize worst-case perspective on the regret that feature in Theorem \ref{result:regret}, and hence their confidence sets have partially worst-case perspective, while at the same time maintain dependence on the data via the regularized MLE estimate. 

\paragraph{Bayesian Inference and Frequentist Statistics} Links between Bayesian inference and (frequentist) worst-case bounds are well-known and appear, more or less explicitly \citep[e.g.,][]{zhang2006varepsilon}, although, we believe, not in the generality for constructing confidence sequences as presented here. Arguably, the tight relationship is not as well-known as perhaps it should be, and it provides a powerful tool to derive anytime-valid confidence sequences in general parametric settings. The prior-posterior ratio confidence set is by \citet{waudby2020confidence}. Surprisingly, we could not find earlier references, and the connection was clearly not apparent in earlier works \citep[e.g.,][]{abbasi2011improved}. The prior-posterior confidence set is applied to Gaussian process regression by \citet{neiswanger2021uncertainty}, however, the work does again not mention the (near-)equivalence to earlier results (including, for example, closed-form expressions for confidence intervals in the kernelized setting).

% \paragraph{Connection to Online Prediction}

\paragraph{Generalization Bounds: PAC-Bayes and Conformal Prediction}
Generalization and shrinking confidence sets are tightly related. Given a confidence set, the image of the confidence set under a forward operator yields bounds on the generalization error. However, this construction is not always practical, and can lead to suboptimal bounds that scale with the model class complexity. A more direct analysis of the generalization error, possibly with additional assumptions, often leads to tighter bounds. Generalization bounds are the main objective in the field of PAC-Bayes learning \citep[e.g.,][]{alquier2024user}. Not surprisingly, PAC-Bayes bounds, regret inequalities and variational bounds are tightly connected as well \citep{lugosi2022generalization,haddouche2022online,chugg2023unified}. Notably, \citet{lugosi2023online} derive generalization bounds that rely purely on the \emph{existence} of a regret inequality, similar to \cref{result:regret}. The emphasize that the main difference between this line of work and the current work is to goal of obtaining generalization bounds, opposed to confidence sets on the model parameters. The difference manifests in the loss function used (in particular, we use the log-loss which is exp-concave and allows for fast rates). Yet another line of work is on \emph{conformal prediction} \citep{angelopoulos2021gentle,angelopoulos2024theoretical}, which again targets the generalization error in a distribution free setting.



% \subsection{PAC-Bayes}

% \textbf{PAC-Bayes aims to bound the generalization error.}

% \paragraph{\cite{lugosi2022generalization}} Generalization bounds via convex analysis, generalizes Mutual-Information bounds of \todoj[]{Russo}

% \subsection{Conformal Prediction}

% Calibrate confidence bands to have true coverage.

% Conformal e-prediction vs Conformal (p-)prediction

% \section{Computational Considerations} To implement confidence sets in practice, there are several challenges. Depending on the formulation, the first challenge is to compute the evidence (marginal likelihood) or equivalently (Thm. \ref{thm:posterior-prior}) the posterior distribution. As we know from Bayesian inference, this task is computationally challenging in general. On the upside, approximations of these quantities are well studied, and additional assumptions allow for efficient computation of the required quantities. Once the marginal likelihood and, respectively, the posterior likelihood have been computed, a membership oracle for the confidence set is readily available; note that the cost for computing the confidence threshold need not be paid only once; given the threshold, we can test containment of any number of parameters by evaluating the data-likelihood. 

% The shape of the confidence set in general depends on the parameterization of the likelihood function and, as such, might not omit an efficient description. 

% Note that variational inference as well as well as approximate inference might be tractable for vast-class of problems such as distributions with log-concave potentials. For such problem efficiently constructing ELBO or point likelihood ratio mixtures is known to be computationally efficient. 


