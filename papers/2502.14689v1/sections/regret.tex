

\subsection{Oracle Complexity Bounds via Online Estimation}\label{sec:oco}

The size of the sequential mixing confidence set in \cref{result:posterior_mixing} depends on the ability of the learner to produce a sequence of mixing distributions that minimize the cumulative log loss,
\begin{align*}
   \sum_{s-1}^t l_s(\mu_{s-1}) =  - \sum_{s=1}^t \log \int p_s(y_s|\nu) d\mu_{s-1}(\nu) \,.
\end{align*}
The field of \emph{online density estimation} studies algorithms for minimizing the cumulative log loss, and offers a rich literature on complexity bounds for the regret \citep[e.g.,][]{vovk1990aggregating,vovk1997competitive,zhang2006varepsilon,rakhlin2014online}. Here, regret is defined as the difference between the cumulative log loss, and the best prediction in hindsight, which, in the simplest case, coincides with the maximum likelihood estimate. Specifically, we assume that the mixing distributions $\mu_1, \mu_2, \dots$ are chosen by an \emph{online estimation} algorithm, in a way that ensures a bound $B_t \geq 0$ on the log-regret,
\begin{align*}
    \Lambda_t = \sum_{s=1}^t l_s(\mu_{s-1}) - \min_{\theta} L_t(\theta) \leq B_t \,.
\end{align*}
For a complete introduction, we refer the reader to the standard literature \citep[e.g.,][]{cesa2006prediction,orabona2019modern,shalev2012online}. 
% More generally, the field of online convex optimization (OCO) studies algorithms for minimizing the regret, with minimal assumptions on  the sequence of loss functions. The OCO setting is typically formulated as a game between an \emph{adversary}, choosing the loss $l_t$, and an \emph{online learning} algorithm choosing a prediction (in our case, $\mu_{t-1})$. At the end of each round, the learner occurs the loss $l_t(\mu_{t-1})$, and the loss function is revealed to the learner, allowing to update the prediction. Our main result is the following.

The next result demonstrates how the sequential likelihood mixing framework relates to maximum likelihood estimation, using regret inequalities from online estimation. 
\begin{theorem}[Regret-To-Confidence]\label{result:regret}
    Assume there exists an online estimation algorithm such that the log-regret is bounded almost-surely, $\Lambda_t \leq B_t$, for a predictable sequence $B_t \geq 0$. Define 
    \begin{align*}
    C_t = \left\{ \theta \in \Theta: L_t(\theta) \leq  \log \frac{1}{\delta} + L_t(\hat \theta_t^\MLE) + B_t \right\} \,.
    \end{align*}
    Then $C_t$ defines a $(1-\delta)$-confidence sequence.
\end{theorem}
\begin{proof}
The result follows directly from \cref{result:posterior_mixing}, by introducing $L_t(\hat \theta_t^\MLE)$ and using the definition of the regret.
\end{proof}
The importance of the result is that the \emph{existence} of an online estimation algorithm with a \emph{known} regret bound, allows to define a valid $(1-\delta)$-confidence sequence, relative to the log-likelihood of the MLE and the complexity bound for online estimation. In particular, the construction does \emph{not} require access to the predictions of the online learning algorithm.  Moreover, the confidence coefficient can be computed using standard supervised learning algorithms, eliminating the need for computing the marginal likelihood. Lastly, the complexity term offers a more interpretable bound on the confidence coefficient. We will come back to several concrete examples below.


The use of regret inequalities to derive concentration inequalities goes back to at least \cite{dekel2010robust,abbasi2012online}. The ``Online-to-Confidence-Set'' conversion by \citet{abbasi2012online} is, however, different in a subtle way, and requires access to the predictions of the online learning algorithm. We recover (and improve upon) their result using a generalization of \cref{result:regret} in \cref{sec:sparse}. Later works extend this idea, for example, to (multinomial) logistic bandits \citep{lee2024improved}. A similarly flavoured result is by \cite{abeles2024generalization} in the context of PAC-Bayes generalization bounds. Worth mentioning is also the work by \cite{rakhlin2017equivalence}, who prove an equivalence between regret bounds and tail inequalities.

\paragraph{Logistic Regression} We illustrate \cref{result:regret} in the sequential logistic regression setting. Let $\Theta = \{\theta \in \bR^d : \|\theta\|_2 \leq S\}$ for a norm bound $S > 0$. The likelihood is a Bernoulli distribution, $p_t(y|\theta) = \Ber(\phi(\ip{\theta, x_t}))$ with the logistic link function $\phi(z) = (1 + e^{-z})^{-1}$  and the covariates $x_t \in \bR^d$. Following along the lines of \citet{lee2024improved}, we invoke a regret bound for logistic regression by \cite{foster2018logistic}, who prove an online learning algorithm that achieves $\Lambda_t \leq 10d \log \left( e + \frac{St}{2d} \right)$. \cref{result:regret} immediately implies the following $(1-\delta)$-confidence sequence:
\begin{align*}
    C_t = \left\{ \theta \in \Theta: L_t(\theta) \leq  \log \frac{1}{\delta} + L_t(\hat \theta_t^\MLE) + 10d \log \left( e + \frac{St}{2d}  \right)\right\} \,.
\end{align*}
We remark that the confidence coefficient above improves upon the result of \citet[Theorem 1]{lee2024improved}, as a consequence of directly applying Ville's inequality to the likelihood ratio.


\paragraph{Compressed Sensing} We come back to the sequential linear regression setting described below \cref{lem:posterior_ratio_confidence_set}, with the additional assumption that the true parameter $\theta^*$ is $k$-sparse, i.e.~$\|\theta^*\|_0 \leq k$. One way to account for the sparsity assumption is to set $\Theta_k = \{\theta \in \bR^d : \|\theta\|_0 < k, \|\theta\|_2 \leq S\}$. For sparse linear regression, \citep{gerchinovitz2011sparsity} proposes online learning algorithm  that achieves $\Lambda_t \leq C_0 k \log(t)$ for a constant $C_0 > 0$. \cref{result:regret} implies the following a confidence sequence,
\begin{align*}
    C_t = \left\{ \theta \in \Theta: L_t(\theta) \leq  \log \frac{1}{\delta} + L_t(\hat \theta_t^\MLE) + C_0 k \log(t)\right\} \,.
\end{align*}
Note that here MLE is defined over the sparse set $\Theta_k$, which poses computational challenges. On the other hand, the confidence set by \citet{abbasi2012online} requires access to the predictions of the online learning algorithm. The construction therefore suffers a similar fate, as finding a computationally efficient algorithm for sparse linear prediction is still an open problem.

% Specialized regret bounds, such as for sparse linear bandits or logistic regression are useful as the reveal concrete dependencies on problem parameters. Perhaps surprisingly, it is possible to obtain regret bounds without any assumptions on the model class.



\paragraph{Finite Model Identification} Assume that the parameter set $\Theta$ is finite, i.e.~$|\Theta|< \infty$. The key insight is to note that the log-loss is $\eta$-exp-concave for $\eta \leq 1$, i.e.~$\exp(-\eta l_t(\mu))$ is concave in $\mu \in \sP(\Theta)$ for all $\eta \leq 1$ (in fact, it is linear for $\eta=1$). This highlights the importance of using mixing distributions, as, in general, $-\log p_t(y_t|\theta)$ is \emph{not} exp-concave as a function of $\theta$.

The standard approach for online learning with exp-concave functions is the \emph{exponential weights algorithm} \citep[EWA, ][]{littlestone1994weighted,freund1997decision}, see also the book by \citet{cesa2006prediction}. For $\eta=1$, EWA is equivalent to Bayesian inference and the prediction $\mu_t$ is equal to the Bayesian posterior (see \cref{alg:cew}). With a uniform prior, the regret of EWA satisfies $\Lambda_t \leq \log(|\Theta|)$, uniformly over all data sequences. The proof is provided for completeness in \cref{sec:cew}. Using \cref{result:regret}, we obtain the following $(1-\delta)$-confidence sequence\looseness=-1
\begin{align*}
    C_t = \{\theta \in \Theta : L_t(\theta) \leq \log \frac{1}{\delta} + L_t(\hat \theta_t^\MLE) + \log |\Theta| \} \,.
\end{align*}
The result should be compared to the standard union bound argument (\cref{sec:mle}). While the bound is the same, note that we obtained \cref{result:regret} as a \emph{relaxation} of \cref{result:posterior_mixing}. Hence, the sequential mixing confidence set (with the Bayesian posterior as mixing distributions) is never worse, and possibly tighter for benign data and structured model classes \citep[e.g.,][]{auer2002adaptive,cesa2007improved,de2014follow}. The confidence set can also be written for the maximum a-posteriori estimate (MAP), in which case the role of the prior distribution becomes more apparent:
\begin{align*}
    C_t = \left\{\theta \in \Theta : L_t(\theta) \leq \log \frac{1}{\delta} + \min_{\nu \in \Theta} \big( L_t(\nu) - \log \mu_0(\nu) \big)\right\} \,.
\end{align*}
Lastly, we remark that the exponential weights algorithm can be generalized to the continuous setting. The confidence sequence derived from the regret bound of continuous exponential weights is equivalent to the ELBO confidence set in \cref{result:elbo_confidence_set}. This is another consequence of the mixing equivalence. We refer to \cref{sec:cew} for further details.
