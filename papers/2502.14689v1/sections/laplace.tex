\section{Laplace's method}\label{sec:laplace}
Recall from section \cref{sec:mle} that $\max_{\nu} R_t(\nu;\theta^*)$ is not a martingale, which prevents a direct application of Ville's inequality. Laplace's method uses the observation that, under suitable regularity assumptions on a sequence functions $f_n : \bR^d \rightarrow \bR$ with unique maximizer $x_n^*$ and positive definite Hessian $H_n(x) = \frac{\partial^2}{\partial x^2} f_n(x) \in \bR^{d \times d}$, the following asymptotic expansion provides an approximation of the maximizer $f_n(x_n^*)$, 
\begin{align*}
    \int_\Theta h(x) e^{- f_n(x)} dx \sim  \frac{(2\pi)^{d/2} h(x^*_n)}{\sqrt{\det H_n(x_n^*)}} e^{- f_n(x^*_n)}
    % \max_{\theta} f_n(\theta) = \log \lim_{n \rightarrow \infty} \int \exp( n f_n(\theta)) d\mu_0(\theta)
\end{align*}
To apply this idea to the marginal likelihood that appears in the confidence coefficient in \cref{result:prior_mixing}, assume that $\Theta \subset \bR^d$ and $\mu_0$ admits a density $h(\theta)$ w.r.t. to the Lebesgue measure. Let $\hat \theta_n^\MLE$ be the maximum likelihood estimate, and $I_t(\theta) = \frac{\partial^2}{\partial \theta^2} L_t(\theta)$ the empirical Fischer information matrix. Laplace's methods gives the following approximation
\begin{align*}
\beta_t(\delta) &= \log \frac{1}{\delta} - \log \int \exp(-L_t(\nu))  h(\nu) d\theta\\
&\approx\log \frac{1}{\delta} + L_t(\hat \theta_t^{\MLE})  + \frac{1}{2}\log \det I_t(\hat \theta_n^\MLE) - \frac{d}{2} \log(2\pi) - \log \mu_0(\hat \theta_n^\MLE)  
\end{align*}
Note that the confidence coefficient is smaller (resulting in a smaller confidence set) the more mass $h(\hat \theta^*_n)$ places on the maximizer.
An similar (and perhaps more natural) argument can be made for the maximum a-posteriori estimate.
Unfortunately, making these approximation rigorous is challenging without placing further assumptions on the data generating distribution and function class \citep[e.g.,][]{shun1995laplace}. We will not pursue this any further here, however point out that regret inequalities (\cref{sec:oco}) provide an alternative way to control the error w.r.t.~the MLE, including in finite time.