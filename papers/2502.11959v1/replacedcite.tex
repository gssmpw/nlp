\section{Related Works}
\subsection{Claim Verification}

Early approaches to claim verification focused on fine-tuning pre-trained models, either by concatenating evidence and claims into a single input____ or processing evidence separately and aggregating the results____. Graph Neural Networks have also been applied to capture relationships between evidence pieces____. With the impressive generative capabilities demonstrated by large language models (LLMs), many studies have turned to LLMs for claim verification____. FACT-GPT____ and FactLlama____ fine-tune LLMs to directly predict the truthfulness of claims. Factscore____ employs systematic decomposition to assess the factuality of individual claim segments, while ProgramFC____ frames claim verification as step-wise program execution. Other works, such as ____, ____, and ____, transform the verification task into a series of sub-questions to be answered.


\subsection{Chain of Thought Reasoning (CoT)}
Chain of Thought (CoT) reasoning____ was proposed to help LLMs solve complex problems by breaking them down into intermediate step-by-step reasoning. ____ demonstrated that adding a prompt such as ``Let's think step by step'' significantly boosts LLM performance. CoT reasoning has been applied to a variety of tasks, including claim verification. Studies like ____ and ____ evaluate CoT methods in different contexts. FOLK____ leverages LLMs to transform claims into first-order logic as intermediate steps for explainable verification.

\subsection{Self-Improvement Methods}
Self-improvement methods for LLMs have garnered attention in recent years, where models are fine-tuned on their self-generated solutions, optionally iterating this process____. $\text{ReST}^{EM}$____ generates reasoning chains for solving math problems and selects those leading to correct answers for retraining. RFT____ enhances reasoning chain diversity by sampling multiple chains before selection. STaR____ introduces hints during reasoning generation for chains that lead to incorrect results. V-STaR____ incorporates Direct Preference Optimization____ into the self-improvement process. Our method shares similarities with STaR. We are the first to apply self-improvement to claim verification. We also highlight the unique challenges of claim verification, distinguishing it from tasks like math problem-solving, and address these challenges through the integration of structured reasoning design.