\section{Conclusion}
We presented \themodel: Structured Reasoning for Self-Improved Verification, a method that integrates structured reasoning and self-improvement training for claim verification. By incorporating Claim Decomposition, Entity Analysis, and Evidence Grounding Verification, \themodel improves the quality of reasoning chains and enables more effective self-improvement. Our experiments demonstrate that \themodel significantly outperforms baseline approaches, highlighting the effectiveness of structured reasoning for self-improvement in claim verification. 
%This work paves the way for future advancements in leveraging structured methods for complex reasoning tasks.


\section{Limitations}
Our approach relies on a structured warm-up phase that requires a small amount of annotated data. In our experiments, we selected 10 moderately difficult claims for reasoning chain labeling without further extensive sample filtering. While this approach has yielded positive results, we recognize that the choice of these samples may influence the subsequent model training. We believe that more carefully selected or diverse samples could further enhance the model's performance and provide additional insights into how sample selection impacts self-improvement. Additionally, our approach improves the claim verification capabilities of LLM in a resource-efficient manner. Both the quantity of annotations and the training strategies were designed for resource efficiency. This low-cost approach has proven effective for performance enhancement, but it also presents opportunities for future research, particularly in terms of scalability. Expanding to larger datasets and more complex models could offer valuable insights, though it remains to be explored in future works.