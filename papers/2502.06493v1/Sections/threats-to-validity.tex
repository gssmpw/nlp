\section{Threats to Validity}

Threats to \textit{external validity} concerns the generalizability of our findings. While our study is prototyped on Qualcomm QIDK platform and tested on a single mobile device as discussed in the experimental setup section, and a specific set of models, the techniques used in our EdgeMLBalancer approach can be extended to other ML tasks and resource-constrained environments with similar challenges, such as energy efficiency, performance, and adaptability. It can also can be extended to other android devices, but non-android devices is beyond the scope of this work.

Threats to \textit{construct validity} concern whether the metrics used accurately represent the phenomena being studied. In our case, potential threats arise from the accuracy of switching time measurements and the model usage fairness calculations. While switching times are measured based on timestamps, minor discrepancies due to system-level latencies might exist. On the other end, the fairness analysis is based on the model usage distribution, which assumes equal utility for all models. This assumption may not hold in scenarios where certain models are inherently more suitable for specific workloads. To address this, the same experimental setup and data sources were used across all approaches to ensure consistent measurement conditions. Additionally, model selection decisions are based on real-time metrics like CPU usage and accuracy, ensuring that the evaluation reflects practical system behavior. 
% While memory usage is a component of computational overhead, this study specifically focuses on CPU usage as the primary metric for evaluating the proposed technique, as it is most critical to the real-time performance of model switching in our setup. Memory usage analysis is outside the scope of this work. Additionally, epsilon-greedy may struggle under highly variable workloads, as it lacks the ability to adapt swiftly to abrupt changes, leading to inefficient exploration of suboptimal models. 

One potential threat to \textit{internal validity} can be the impact of varying hardware conditions, such as residual background tasks, temperature fluctuations, or battery states, which might affect CPU performance. To mitigate these factors, we took the following precautions: The mobile device was completely reset before testing each approach to eliminate residual processes that could interfere with the experiment. The device was fully charged before starting each approach to ensure uniform initial battery conditions. A warm-up phase was performed before each test to stabilize the hardware state, ensuring consistency throughout the experiments. 

\textit{Conclusion validity} concerns the robustness and reliability of the results. A potential threat is the statistical power of our findings, given the limited duration of experiments (30 minutes per approach). While this duration allowed for meaningful comparisons, it may not fully capture the long-term trends such as battery degradation or model stability under sustained usage, as our decision was to focus only on evaluating the short-term performance and adaptability. To mitigate this, multiple runs were performed to ensure repeatability and comparisons were made using consistent metrics such as CPU usage, accuracy, and switching time. 