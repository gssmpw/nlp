\section{Introduction}

Artificial Intelligence (AI) is increasingly integrated into everyday technologies, with smartphones serving as prominent edge devices where many machine learning (ML) functionalities are embedded \cite{b1}.  These devices now support real-time ML applications, leveraging proximity to data sources for improved privacy and reduced latency. However, deploying the computationally intensive ML models on resource-constrained devices introduces critical challenges, including limited memory, energy storage, and processing power \cite{b2}.  

While lightweight and quantized models offer solutions to reduce resource demands, they often compromise on accuracy \cite{b14}\cite{b15}, which is critical for applications such as autonomous vehicles and augmented reality, these optimized models cannot fully adapt to varying workloads or operational contexts, where real-time responsiveness and precision are simultaneously required \cite{b16}\cite{b17}\cite{b18}. The challenge lies not just in model selection but in dynamically balancing trade-offs between computational efficiency and accuracy based on situational demands \cite{b3}. Unlike cloud systems, where scalability and abundant resources mitigate such constraints, edge devices must operate within finite computational capacities. This limitation underscores the critical need for efficient and adaptive resource management techniques that balance precision and performance, particularly for real-time applications \cite{b4}. Significant advances have been made to address these issues. Techniques such as dynamic model switching, TinyML, and neural network compression optimize resource utilization while maintaining system precision \cite{b5}\cite{b6}. Frameworks such as EcoMLS, Ada-HAR have demonstrated energy-efficient solutions for managing workloads~\cite{b7}\cite{b8}.
%and Ada-HAR has been applied for real-time monitoring and unsupervised learning in dynamic environments \cite{b7}\cite{b8}. 

However, the majority of existing approaches focus on cloud-based or Mobile Edge Computing (MEC) systems \cite{b19}\cite{b20}\cite{b21}, where resource constraints are mitigated through offloading computations to cloud servers or nearby edge infrastructures. These methods excel in leveraging shared resources but are not directly applicable to scenarios involving standalone edge devices, such as smartphones, which operate independently without external computational support. Additionally, many approaches emphasize static optimization strategies or cater to specific applications, leaving room for dynamic, adaptable frameworks that can address the diverse and evolving requirements of real-world edge applications. 

Self-adaptive systems have emerged as a promising solution to handle run-time uncertainities, making them particularly valuable in resource-constrained settings where resources are limited and conditions are uncertain. These systems leverage feedback loops to continuously monitor, analyze, and adjust their behavior to meet predefined goals \cite{b35}. For instance, probabilistic modeling frameworks evaluated the cost-benefit trade-offs of adaptation actions, ensuring that system utility is optimized without compromising performance \cite{b23}. Although adaptive techniques such as QoS-aware model switching and modular software designs \cite{b3}\cite{b15} have shown promise, they are often tailored to specific applications and primarily focus on cloud-based systems. These approaches address trade-offs between computational efficiency and accuracy but are not directly applicable to scenarios involving real-time constraints on resource-limited devices such as smartphones. 

To address these challenges, this study introduces a dynamic model-switching approach, EdgeMLBalancer for object detection on edge devices. Building on the principles of self-adaptation, the concept of ML Balancer is introduced in this study. The ML Balancer is designed to dynamically evaluate and select between ML models based on accuracy and resource demands. The approach is based on an epsilon-greedy strategy to promote fairness and to prevent model starvation. Given a real-time traffic monitoring scenario, our approach (i) continuously monitors CPU usage and accuracy, (ii) selects the most suitable model adaptively, balancing computational efficiency and accuracy, (iii) dynamically switches between models based on epsilon-greedy decision-making strategy to facilitate fairness and responsiveness, and (iv) prevents overutilization of specific models by distributing workloads across available options. The EdgeMLBalancer approach is prototyped on \textit{Qualcomm QIDK platform}\footnote{\url{https://www.qualcomm.com/products/mobile/snapdragon/smartphones/snapdragon-8-series-mobile-platforms/snapdragon-8-gen-2-mobile-platform}}, to simulate different scenarios, and is further evaluated on real-time traffic data using the edge-device (smartphone). The evaluation demonstrates significant improvements in balancing computational efficiency and accuracy, facilitating fairness of model usage compared to other approaches, validating effectiveness of the proposed EdgeMLBalancer approach in achieving optimzal performance under varying runtime conditions.

The remainder of the paper is structured as follows: Section II provides a running example. Section III introduces the our approach. Experimentation and results from its application are in Section IV. Threats to validity and Related work are discussed in Section V and VI respectively. Section VII concludes and discusses future work.

 