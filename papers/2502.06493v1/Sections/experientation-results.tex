\section{Experimentation and Results}

\begin{table*}[ht]
    \centering
    \resizebox{\textwidth}{!}{%
    \begin{tabular}{@{}|l|c|c|c|c|c|c|@{}}
        \toprule
        \textbf{Approach} & \textbf{Frames Processed} & \textbf{Average CPU Usage (\%)} & \textbf{Average Accuracy (\%)} & \textbf{Average Switching Time (s)} & \textbf{Battery Consumption (mAh)} \\ 
        \midrule
        Epsilon-Greedy & 1952 & 19.90 & 17.36 & 0.85 & 2.10 \\ 
        Naive & 2482 & 20.63 & 2.94 & 0.50 & 5.25 \\ 
        Round Robin With Boosting & 2458 & 19.08 & 10.85 & 1.40 & 3.10 \\ 
        \bottomrule
    \end{tabular}%
    }
    \caption{Performance metrics comparison of different approaches.}
    \label{tab:table}
\end{table*}

\begin{figure}
    \centering
\includegraphics[width=\linewidth]{Images/scatter-plot.png}
    \caption{Scatter-plot depicting CPU Usage vs Confidence Score}
    \label{fig:scatter-plot}
\end{figure}

\begin{figure*}[ht]
    \centering
    \includegraphics[width=1\linewidth]{Images/box-plot.png}
    \caption{Comparison of All Parameters Using Box-plot}
    \label{fig:box-plot}
\end{figure*}

\begin{figure}
    \centering
    \includegraphics[width=1\linewidth]{Images/fairness.png}
    \caption{Model Usage for Different Approaches}
    \label{fig:model-usage}
\end{figure}


\begin{figure}
    \centering
    \includegraphics[width=1\linewidth]{Images/bar-plot.png}
    \caption{Comparison of Average Values for All Parameters (Including Switch Time)}
    \label{fig:all-parameters-comparision}
\end{figure}

% \begin{figure}
%     \centering
%     \includegraphics[width=1\linewidth]{Images/cummulative-graphs.png}
%     \caption{Cumulative Graphs for each of the approaches}
%     \label{fig:cummulative-graphs}
% \end{figure}

The objective of our EdgeMLBalancer evaluation is to assess the effectiveness, fairness, and efficiency of the approach by answering:

\begin{enumerate}[label=\textbf{RQ\arabic*.}]
    \item How effective is our EdgeMLBalancer approach compared to other approaches in balancing trade-offs between computational efficiency, and detection accuracy within ML-Enabled System?
    \item Which model selection approach ensures the fair allocation of resources between models, effectively balancing detection accuracy and resource utilization, while avoiding model starvation and maintaining robust system performance?
    \item How does the time taken for model switching in our EdgeMLBalancer approach compare to other approaches in terms of its impact on responsiveness and overall system efficiency during real-time operations?
\end{enumerate}


In the remainder of this section, we first discuss our experimental setup, as well as the data used for the evaluation of the approach, following with a discussion of the results for the research questions. 

\subsection{Experimental Setup}

We implemented EdgeMLBalancer as a mobile application, designed to run on Android Devices. The application was developed using Android Studio \cite{b24}, with the primary algorithms written in Kotlin\footnote{\url{https://kotlinlang.org/}}. The TensorFlow Lite library\footnote{\url{https://www.tensorflow.org/resources/libraries-extensions}} was employed for on-device ML model inference, ensuring compatibility with edge-devices. The application integrates \textit{CameraX API}\footnote{\url{https://developer.android.com/media/camera/camerax}} for real-time video feed processing and \textit{MetricLogger} for monitoring and logging system metrics, including CPU usage, and model accuracy. The logging functionality write metrics to CSV file for later analysis. The source code, datasets, and ML models are available here.\footnote{\url{https://github.com/sa4s-serc/EdgeMLBalancer}}

The experiments of EdgeMLBalancer were prototyped using the \textit{Qualcomm QIDK (Qualcomm Innovation Development Kit)}, a platform designed for testing and developing AI applications on edge devices. Equipped with Snapdragon Â® 8 Gen 2 processor, Adreno GPU, the QIDK's advanced AI engine and robust connectivity features provided flexibility to simulated various workloads and configurations. The prototyping phase enabled the simulation of various edge scenarios, which helped us to formulate optimization and deployment strategies for \textit{Samsung Galaxy M21} smartphone, on which we tested the primary deployment. 

The \textit{Samsung Galaxy M21} was equipped with an \textit{Exynos 9611 chipset}, featuring an octa-core CPU (4x Cortex-A73 cores clocked at 2.3 GHz and 4x Cortex-A53 cores clocked at 1.7 GHz), 6 GB RAM, and running One UI Core 4.1 based on Android 12. Its 48 MP rear camera (f/2.0) was used to capture experimental video, and its 6000 mAh battery provided sufficient endurance to conduct prolonged experiments without interruptions due to resource-constraints.

To simulate the real scenario of the experiment with as much fidelity as possible, we processed the video in real-time by the application from a 30-minute recording of the Indian-traffic data with 60 frames per second, running continuously throughout the experiment for each approach. This setup was chosen to ensure that the data remained consistent and fair in all approaches, providing a uniform benchmark for evaluation. For the evaluation, we measured different metrics metrics:

\smallskip
\noindent 1. \textit{Accuracy} was calculated as the percentage of correctly detected objects compared to the ground truth. 

\smallskip
\noindent 2. \textit{CPU utilization} of the system (in percentage) during inference while using different models 

%to ensure computational overhead. Lastly, 

\smallskip
\noindent 3. {\em Switching Overhead}, the latency incurred (in ms) while switching between different models when using each of the approaches. 

The approach was evaluated by comparing it against two other baselines resulting in a total of three different experiment candidates. Each of them was executed for a period of 30 minutes, with each run separated by a 30-minute cooldown gap to stabilize the system, preventing any carryover effects. The three experimental candidates are:

\smallskip
\noindent 1. \textit{Naive} approach, switching between models will occur based on the predefined thresholds to balance \textit{accuracy}, and \textit{CPU usage}

\smallskip
\noindent 2. \textit{Round Robin with Boosting} dynamically prioritizes the switching based on time slices and CPU usage, with boosting involving periodic recalibration of CPU usage for all models.

\smallskip
\noindent 3. The proposed \textit{EdgeMLBalancer approach} employed a probabilistic adaptive strategy, using real-time CPU monitoring and workload demands to dynamically select models, optimizing resource usage while maintaining responsiveness.

\subsection{Results}

\noindent
\textbf{RQ1.} \textit{How effective is our EdgeMLBalancer approach compared to other approaches in balancing trade-offs between computational efficiency and detection accuracy within ML-Enabled System?} 

\smallskip
\noindent
We examine our EdgeMLBalancer approach's effectiveness by comparing its performance with two other experiment candidates mentioned in the \textit{experimental setup} of this section, focusing on the balance between CPU usage and inference accuracy. \textit{Table}\ref{tab:table} showcases that Epsilon-Greedy (EdgeMLBalancer) demonstrates effective balance, achieving the highest average accuracy \(17.36\%\) while optimizing resource utilization with average CPU usage \(19.90\%\), despite processing fewer frames (1952). In contrast, the Naive approach processes the highest number of frames (2482), yet this is achieved at the cost of significantly lower average accuracy \(2.94\%\) with the highest average CPU usage \(20.63\%\) , indicating inefficient resource utilization and poor adaptability. However, Round Robin with Boosting processes slightly higher frames (2458) with average accuracy \(10.85\%\) and average CPU usage \(19.08\%\). The \textit{Figure}\ref{fig:scatter-plot} further reinforces these findings. Epsilon-Greedy (EdgeMLBalancer) strikes a balance between CPU usage and accuracy, with an average CPU usage of \(19.90\%\) and a detection accuracy of \(17.36\%\). Compared to Naive and Round Robin approaches, Epsilon-Greedy (EdgeMLBalancer) achieves a \(491.45\%\) (from 2.94\% to 17.36\%) and \(59.94\%\) (from 10.85\% to 17.36\%) higher average accuracy, while reducing average CPU usage by 3.51\% (from 20.63\% to 19.90\%) compared to Naive, and with only a 4.32\% (from 19.08\% to 19.90\%) increase in average CPU usage compared to Round Robin with Boosting. The \textit{Figure}\ref{fig:box-plot} also strengths support our findings that, compared to all approaches, our EdgeMLBalancer approach achieves better performance by effectively managing the trade-offs between computational efficiency and accuracy. 

\smallskip
\noindent
\textbf{RQ2.} \textit{Which model selection approach ensures the fair allocation of resources between models, effectively balancing detection accuracy and resource utilization, while avoiding model starvation and maintaining robust system performance?} 

\smallskip
\noindent
We assess the fairness of approaches by analyzing the distribution of model selection, given that the allocation of resources remains consistent across all approaches, as outlined in the \textit{experimental setup}. \textit{Figure}\ref{fig:model-usage} showcases, that Naive approach selected \textit{EfficientDet Lite1} model 1844 times (74.29\%) out of 2482 frames that are processed, as mentioned in the \textit{Table}\ref{tab:table}. In contrast, Round Robin with Boosting selected \textit{EfficientDet Lite0} model 2075 times (84.41\%) out of 2458 frames. However, Epsilon-Greedy (EdgeMLBalancer) approach selected \textit{EfficientDet Lite1} model 997 times (51.07\%), \textit{EfficientDet Lite0} is selected 771 times (39.49\%), \textit{EfficientDet Lite2} is selected 114 times (5.84\%), and \textit{MobileNet V1} model is selected 70 times (3.58\%) out of 1952 frames. From the \textit{Figure}\ref{fig:model-usage}, we can say that the Epsilon-Greedy (EdgeMLBalancer) represents an improvement in fairness of 43.62\% over Naive and 41.47\% over Round Robin with Boosting in terms of reducing the selection disparity between the models. This is due to the decision-making complexity in approaches like Naive and Round Robin with Boosting, where simplistic or rigid switching mechanisms prioritize certain models without adequately considering runtime conditions or the need for equitable model utilization. Compared to all approaches, our EdgeMLBalancer approach achieves fair distribution among models, reflecting its dynamic adaptability, effectively preventing model starvation. It is important to note that along with guaranteeing fairness, EdgeMLBalancer is also able to balance effectively between CPU Usage and accuracy as demonstrated in the results of RQ1.

\smallskip
\noindent
\textbf{RQ3.} \textit{How does the time taken for model switching in our EdgeMLBalancer approach compare to other approaches in terms of its impact on responsiveness and overall efficiency of the system during real-time operations?}

\smallskip
\noindent
To answer this question, we compare the time taken for model switching in real-time operations of all three approaches. The average switching time of Epsilon-Greedy (EdgeMLBalancer) is 0.85 seconds, as shown in \textit{Figure}\ref{fig:all-parameters-comparision}. This moderate switching time reflects its adaptive model selection mechanism, which evaluates runtime conditions and adjusts models accordingly. In contrast, the Naive and Round Robin with Boosting exhibits the average switching time of 0.50 seconds and 1.40 seconds respectively. While Naive's rapid switching time suggests minimal decision-making complexity, its model usage analysis from results of RQ2 highlights significant model starvation. Similarly, Round Robin with Boosting, takes the longest switching time, paired with model starvation. 

Our approach balanced switching-time, combined with fair model usage, as discussed in \textbf{RQ2}, showcases its superior decision-making mechanism. This underscores the capability of Epsilon-Greedy (EdgeMLBalancer) as the robust and well-rounded approach for real-time operations. 






 



