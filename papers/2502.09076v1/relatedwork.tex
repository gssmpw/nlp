\section{Related Work}
\label{sota}

In this section, we present the main fields in which we aim to contribute to. 
Firstly, we address the field of situated visualisation and SitA, then the field of AR guidance.
After presenting the related work and concepts relevant to each of these topics, we position ourselves in respect to the scientific challenges in these fields.

\subsection{Situated Visualisation}
\label{situated_visualisation}

\textit{Situated visualisation} is a form of visualisation which extends the physical world with virtual objects or a "\textit{visualisation that is related to and displayed in its environment}" as defined by White \& Freiner~\cite{white2009sitelens}. White later defined the key characteristics common to all situated visualisations~\cite{white2009interaction}: 
1) Data in the Visualization is related to the physical context.
2) Visualization is based on the relevance of the data to the physical context.
3) Display and presentation of the visualization is in the physical context.

This definition was later expanded on by Willett ~\textit{et al.}~\cite{willett2016embedded} with the inclusion of \textit{physical data referents} upon which virtual objects are associated with. This inclusion brought another form of visualisation to the table called "\textit{embedded data representations}" which differs from situated representations by strictly coinciding spatially with the associated data referents as opposed to simply being in proximity to the data referents. 
The main benefit of situated and embedded visualisations is to allow a user to understand data \textit{in situ}, without splitting attention across physical and virtual objects.

In a survey by Bressa~\textit{et al.}~\cite{bressa2021s},
these two definitions for situated visualisation are stated to be the most prevalent definitions of situated visualisations in literature. 
Furthermore, the authors also mention the relevance of \textit{Situated Analytics}~\cite{elsayed2015situated}(SitA) which is used to encompass the fields of situated visualisation and \textit{Immersive Analytics}(IA). Both of these fields highly benefit from each other with IA being "\textit{the use of engaging, embodied analysis tools to support data understanding and decision making.}"~\cite{marriott2018immersive}.

\subsection{Situated Analytics}

A recent work expanding on the theme of SitA is the work done by Lee ~\textit{et al.}~\cite{lee2023design} which has categorised the various design patterns of situated visualisation based on other existing works and serves as a clear base to start from within the field. The work also describes many guidelines and constraints imposed on the application of situated visualisation.

Concerning the potential problems with designing a system with SitA, it must be noted that the efficiency of the situated information is highly dependent on the \textit{Extent of World Knowledge} (EWK), as stated by the lesser-known part of Milgram \& Kishino's work~\cite{milgram1994taxonomy}. 
With high EWK, the visualisations are strongly grounded to the real world whereas with low EWK, interactions become more and more necessary to counterbalance the lack of immersion and ability to extract information from it. 
Lee ~\textit{et al.}~\cite{lee2023design} also state that within the EWK, important factors include: \textit{referent density}, where too little makes tasks trivial and too many lead to readability and field of view issues; \textit{referent size}, which can lead to occlusion and impracticality issues, especially for embedded visualisations; and \textit{location awareness}, which is very dependent on the location and frequency of updates of the data referents.

With work still being done on the guidelines and categorisation in the field of situated visualisation as shown by Lee ~\textit{et al.}~\cite{lee2023design}, there still exists numerous scientific hurdles to tackle such as a solid foundational knowledge and taxonomy encompassing the whole topic (mentioned by Lee \textit{et al.} and other recent surveys~\cite{bressa2021s,satriadi2023proxsituated,shin2023reality}).
These newly defined taxonomies also need accompanying performance analysis to demonstrate their usage of which we contribute to with this article.

With the context of SitA addressed, a field which can highly benefit from it, is that of AR guidance. AR guidance aims to carry a user through a series of physical tasks, so having a way to direct the user's attention using visual indicators can be seen as a huge benefit which we will detail now.

\subsection{AR Guidance}
\label{ar_guidance}

AR guidance can be defined by \textit{AR instructions} which instructs the user about elements involved in the physical task, to help form the spatial cognition of the interaction. This can be any information related to the physical task which can be presented virtually such as the spatial relationship, operation method, etc.~\cite{wang2021role}.

A topic which is commonly studied by researchers is the way to effectively transfer sufficient knowledge to a novice user of an AR guidance system~\cite{baxter2012human,wang2021role}. The main difference between novices and experts is their mental image of the task~\cite{baxter2012human} and this means that, depending on the user's proficiency, there is a varying need for more spatial cognition when they are presented with a new task which needs to be performed effectively~\cite{wang2021role}. This spatial cognition plays a large role in the effectiveness of the AR guidance as it involves the cognitive ability of the user to solve spatial problems.
With this limit on the cognitive ability being different for all users, AR guidance systems cannot currently support high precision tasks~\cite{wang2021role} and needs to be synchronized with the user's cognitive needs to reduce their difficulty in cognition.
Wang ~\textit{et al.}~\cite{wang2021role} therefore designed their own system called UcAI (user-centered AR instruction) which has the goal to let a novice user play the role of the "\textit{thinker}" using information provided by an expert.

In literature, the two main forms of visual AR instruction type are \textit{Static} which reflects the physical state of an assembly object and \textit{Dynamic/Moving} which reflects the guiding method of an assembly object~\cite{feiner1993knowledge,wang2016multi,wang2022comprehensive,maffei2023dynamic,wang2021role}. 
The difference between these forms can be seen tested in the field of teaching, with an AR learning application~\cite{montoya2016evaluating} which states that dynamic content was found to be more helpful in understanding concepts by students. 

It is however important to note that when tasks become complex, dynamic information can also be distracting~\cite{wang2022comprehensive} and that concise visual information is not always sufficient to convey very complex information, making operation intention difficult to understand and leads to higher cognitive load for the user~\cite{mizell2001fundamentals,fiorentino2009tangible}.
The act of shifting the user's attention when providing information is also a cause for higher cognitive load as the user must remember the information and return to perform the action, which is especially important in fields such as industrial assembly~\cite{vanneste2020cognitive}.
On the other hand, simplified information can lead to the aforementioned disparity between novice and expert users~\cite{wang2022comprehensive}.
It is relevant to mention that the design of AR guidance systems highly benefits from multi-modal interactions to trigger visual elements using tools such as head and eye tracking, haptic feedback and affective computing~\cite{wang2022comprehensive} which can compensate for simplified information. These interactions generally solve the problems of occlusion and visual clutter in AR~\cite{truong2021user} but can also lead to higher completion times and possible overload which is the case for the auditory interactions in~\cite{marquardt2020comparing}. 

An interesting example of AR guidance in terms of task model is that of the Holopit project~\cite{lallai2021engineering} which employs various situated visualisation guidance techniques to guide a novice pilot through a series of flight procedures using the knowledge and instructions provided by an expert.
A downside with their system was that the expert had to place the virtual objects over their respective locations which highlights an issue with the identification of data referents.

The various applications of XR are almost limitless as the fields in which virtual additions benefit the user is down to imagination. 
The main hold-back however is the existence of social and technological barriers for entry into the various fields of application~\cite{fast2018testing}.
Among the domains of application that have seen the appearance of SitA and AR guidance, the medical field is one that is of great interest to researchers due to the often complex and non-deterministic tasks such as surgery and diagnosis.

\subsection{AR Guidance for Medical Assistance}
\label{medical_ar}

The idea of using Extended Reality (XR) for surgical simulation was proposed by Satava's paper~\cite{satava1993virtual}, which used an off-the-shelve HMD in addition to a DataGlove to interact with a virtual abdomen to provide a virtual reality training simulator.
As for AR medical applications, the early thoughts were summarized through the review of Tang~\textit{et al.}~\cite{tang1998augmented}.
Yet, even today, many papers show promising results for medical application but little literature or actual surgical application prove its real world usage outside of training and education~\cite{barsom2016systematic,chen2017recent,eckert2019augmented,tang2020augmented}.

Nevertheless, the appearance of the MS Hololens made a huge mark in the field, being used in numerous medical prototype/proof-of-concept studies as mentioned in the review from Park~\textit{et al.}~\cite{park2021review}.
Recent applications of AR guidance include projects such as AR-Coach~\cite{ebnali2022ar} which simulates medical assistance with direct contact with the AR avatar of an expert in a control center.
Other research has proposed evaluations on the need for basic life support in out-of-hospital cases for example sudden cardiac arrest~\cite{9978596,info:doi/10.2196/14910} demonstrated through medical training simulations such as Viewpoint~\cite{info:doi/10.2196/28595} and RescuAR~\cite{javaheri2023rescuar}.

With our work, we contribute to the AR guidance and situated visualisation fields applied to a medical context by proposing an evaluation of the impact of visual AR guidance with the addition of SitA all whilst taking into account the mental image of an expert in order to improve the actions of a novice similar to the works of Baxter~\cite{baxter2012human} and Wang~\textit{et al.}~\cite{wang2021role}.