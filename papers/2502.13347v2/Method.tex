\section{Methodology}

\input{Figures/joint_distribution}

In this section, we introduce Web Data \textbf{Craw}ling for \textbf{LL}\textbf{M} Pretraining (\ours{}), an efficient crawling method that integrates LLM pretraining preference into the crawler.
The algorithm of \ours{} is presented in Algorithm~\ref{algo:crawl}.

\input{Other_Assets/crawl_algorithm}

Similar to traditional crawlers~\citep{pr-crawl}, \ours{} starts with a set of seed URLs.
For each unvisited outlink of them, \ours{} assigns a score using a pretraining-oriented URL scoring function $\textsc{Score\_URL}(\cdot;\mathcal{M})$, where $\mathcal{M}$ is a pretraining influence scorer which rates a document's influence for pretraining.
$\mathcal{M}$ can be derived from data classification models for pretraining data, which have been used to decide whether a document should be retained in or filtered out from the raw dataset~\citep{dclm,fineweb}.
Formally, given a pretraining influence scorer $\mathcal{M}$, the score $s$ of a URL $u$ is calculated as
\begin{equation}
\label{eq:score}
\small
    s \gets \textsc{Score\_URL}(u;\mathcal{M}) = \mathcal{M}(\textsc{FetchPage}(u)),
\end{equation}
where $\textsc{FetchPage}(u)$ gets the page content of $u$ and $\mathcal{M}(\cdot)$ returns the score.
Once all outlinks have been scored, following the standard procedures of existing crawlers, they are inserted into a priority queue, which automatically orders them based on their scores.
The top $n$ highest-scoring URLs are then dequeued for pretraining and serve as the sources for the next round of crawling.
This process repeats until $N$ documents have been collected, forming the final pretraining dataset $\mathcal{P}$.
% , which can be used for LLM pretraining.

In contrast, traditional crawlers typically rely on graph connectivity metrics, such as PageRank~\citep{pr-crawl} and harmonic centrality~\citep{cc-analysis}, which basically assign higher priority to pages with higher indegrees~\citep{pr-and-indegree}.
As shown in Figure~\ref{fig:joint_distribution:fasttext_indegree}, the indegrees of webpages exhibit a poor correlation with the scores assigned by the DCLM fastText classifier, a pretraining influence scorer for identifying high-quality pretraining data~\citep{dclm}.
This confirms that graph connectivity-based crawlers are inefficient in crawling pretraining data. 

\input{Tables/overall}

By incorporating a pretraining influence scorer, \ours{} traverses the web graph in a way that prioritizes high-quality pretraining documents.  
This makes the crawling more efficient and enables the discovery of documents dramatically different with connectivity-based crawlers.


