\section{Related Work}
In this section, we examine the existing dialogue generation strategies and explore the role of LLMs as human-like evaluators of generated dialogues.

\subsection{Single- vs.\ Dual-Prompt Dialogue Generation Strategies}
There are two different strategies for dialogue generation: single-prompt and dual-prompt. The \textit{single-prompt} strategy provides a dialogue type, information about the participants, and an optional seed ____ to an LLM whose task it is to generate the complete dialogue. In the \textit{dual-prompt} strategy on the other hand, two prompts are used, one for each dialogue participant. Each prompt typically describes a role (e.g., interviewer or candidate) and an objective for that role ____. This dual-prompt approach can be implemented in two different ways, either by alternating the prompts at each invocation of the same LLM, or alternatively by creating two agents ____ that execute their LLM calls independently and where we provide the output of one agent as input to the other agent.

Since the dual-prompt strategy requires continuous re-copying of dialogue history into the LLM prompts, it is significantly more expensive in terms of token count than the single-prompt strategy (see detailed discussion in Section 7). 

\subsection{Leveraging LLMs for Dialogue Quality Measurement}
Language models that are sufficiently large, suitably fineâ€“tuned for instruction following and have sufficient reasoning capabilities can be leveraged for zero-shot automated dialogue evaluation ____. Specifically, instruction-tuned LLM variants like ChatGPT have been shown to be promising substitutes for human judges when it comes to evaluating dialogues ____, with GPT-4 scoring the best on human alignment ____.