\section{Conclusion}
% In conclusion, this study highlights the efficacy and potential of integrating Parameter-Efficient Fine-Tuning (PEFT) methods with game theory principles through the innovative approach of LoRA with Mixture of Gamers (\ourmethod). By melding Low-Rank Adaptation (LoRA) with Mixture of Experts (MoE) and utilizing game theory-based dynamics, \ourmethod{} significantly advances the field by addressing critical gaps in flexibility and dynamic expert selection inherent in previous methods. The employment of submatrix decomposition alongside Shapley values in \ourmethod{} enables a more granular understanding of the interactions and contributions of different components within PEFT setups. The promising experimental outcomes across a variety of tasks not only underscore \ourmethod's superior performance but also illuminate its versatile applicability and the potential for future adaptations in complex, domain-specific applications. Moving forward, it will be crucial to refine these approaches, ensuring robustness and scalability, to fully harness the transformative power of PEFT in enhancing machine learning models.

In this paper, we introduce \ourmethod{}, a Med-LVLM that unifies medical vision-language comprehension and generation through a novel heterogeneous knowledge adaptation approach.
% integrates H-LoRA and a three-stage fine-tuning approach, aim at unifying medical understanding and generation tasks. 
% To enhance the multi-task performance of \ourmethod{}, we introduce the \texttt{VL-Health} dataset for training. 
Experimental results demonstrate that \ourmethod{} achieves significant performance improvements across multiple medical comprehension and generation tasks, showcasing its potential for healthcare applications. 