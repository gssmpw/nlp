% \documentclass[letterpaper, 10 pt, conference]{ieeeconf} 
\documentclass{article}
\usepackage{graphicx} % Required for inserting images
\usepackage{amsfonts}
\usepackage{amsmath,amsfonts,amsthm,bm}
\usepackage{amssymb}
\usepackage{subcaption}
\usepackage[a4paper, total={6in, 8in}]{geometry}
\usepackage{enumerate}% http://ctan.org/pkg/enumerate

\newtheorem{prop}{Proposition}

\graphicspath{ {./images/} }
\newcommand\norm[1]{\left\lVert#1\right\rVert}

\theoremstyle{definition}
\newtheorem{definition}{Definition}[section]
\usepackage[english]{babel}
\newtheorem{theorem}{Theorem}


\author{Share\LaTeX}
\title{\LARGE \bf Generalized Nash Equilibrium Solutions in Dynamic Games With Shared Constraints}
\author{%
 Mark Pustilnik\footnote{Corresponding author: pkmark@berkeley.edu} , Francesco Borrelli \\
 Department of Mechanical Engineering, \\ 
 University of California at Berkeley, Berkeley, CA 94701 USA }

\date{March 2025}

\begin{document}

\maketitle
\thispagestyle{empty}
\pagestyle{empty}


%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\begin{abstract}

In dynamic games with shared constraints, Generalized Nash Equilibria (GNE) are often computed using the normalized solution concept, which assumes identical Lagrange multipliers for shared constraints across all players. While widely used, this approach excludes other potentially valuable GNE. This paper presents a novel method based on the Mixed Complementarity Problem (MCP) formulation to compute non-normalized GNE, expanding the solution space. We also propose a systematic approach for selecting the optimal GNE based on predefined criteria, enhancing practical flexibility. Numerical examples illustrate the method’s effectiveness, offering an alternative to traditional normalized solutions.

\end{abstract}


%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\section{Introduction}
Computing a Nash Equilibrium (NE) in a Dynamic Game (DG) is a well-established concept. In DGs, players often share constraints, making each player's feasible strategy set dependent on others’ strategies. This extends the problem to a Generalized Nash Equilibrium Problem (GNEP). NE serves as a fundamental tool for analyzing competitive behavior across various domains, including economics \cite{arrow2024existence} and racing \cite{zhu2023sequential, spica2020real}.

In general, the existence or uniqueness of a GNE is not guaranteed.
We are interested in problems where GNEPs admit multiple solutions. The standard approach for solving GNEPs is to derive and combine the Karush-Kuhn-Tucker (KKT) conditions for each player’s optimization problem~\cite{dreves2011solution}. When shared constraints exist, the Lagrange multipliers associated with these constraints are typically assumed to be identical for all players. This concept, known as the ``normalized solution", was introduced by Rosen \cite{rosen1965existence}, who demonstrated its existence and uniqueness under specific conditions. This solution also arises from reformulating the DG as a Quasi Variational Inequality (QVI) problem. Harker \cite{harker1991generalized} and others \cite{facchinei2007generalized} further showed that this reformulation reduces the solution set to the normalized solution, provided it exists. The normalized solution is widely adopted in various applications, including racing \cite{zhu2023sequential, liu2023learning, spica2020real}, economics \cite{bacsar1998dynamic}, and traffic systems \cite{migot2019revisiting}, and has become the standard approach for solving DGs due to its computational, numerical, and conceptual advantages. Despite these benefits, the normalized solution may not always capture the complexity of real-world interactions, where other GNEs could better represent asymmetric or more intuitive behavior. However, computing non-normalized GNEs is challenging. Standard approaches to solving GNEPs, such as reformulating the KKT conditions as a QVI is inherently bias toward normalized solutions \cite{facchinei2007generalized}. Reformulating the problem as Mixed Complementarity Problem (MCP) is practically also biased toward the normalized solution by many numerical solvers even when no such constraint is imposed on the solution space. This paper tackles these limitations through two key contributions: 1) Proposing a method that extends the MCP framework to calculate non-normalized GNEs for GNEPs,  thereby broadening the solution space, and 2) Introducing a systematic approach for selecting an ``optimal" GNE from this expanded solution set, based on predefined criteria.




%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\section{Problem Formulation} \label{Problem}
Give $N$ players, each player $i \in \{1,...,N\}$ controls the variables $x^i \in \mathbb{R}^{n_i}$. 
The vector $x \in \mathbb{R}^n$ is formed by concatenating all the players' decision variables:

\begin{equation} \label{x_vec}
    x := [(x^1)^T, ..., (x^N)^T]^T
\end{equation}
where $n := \sum^N_{i=1}n_i$. $x^{-i}$ represent the decision variables of all players except player $i$. To emphasize the decision variables of player $i$ within $x$ we write $(x^i,x^{-i})$ instead of $x$. The aim of player $i$ is to choose the $x^i$ which minimizes its own cost function $J_i(x^i,x^{-i})$ refer to such decision as ``strategy".
The feasible set of the $i$-th decision depends on the strategies of the other players:
\begin{equation} \label{game_def}
    \min_{x^i} {J_i(x^i,x^{-i})} \quad \text{subject to} \quad x^i \in \mathcal{X}_i(x^{-i}) \subseteq \mathbb{R}^{n_i}
\end{equation}
The feasible set of each player can be represented in the following form:
\begin{equation} \label{feasible_set}
    \mathcal{X}_i(x_{-i}) := \{x_i \in \mathbb{R}^{n_i} | h_i(x_i) = 0,g_i(x_i) \leq 0, s(x_i,x_{-i}) \leq 0\}
\end{equation}
where, $h_i: \mathbb{R}^{n_i} \to \mathbb{R}^{k_i}$ defines private equality constraints that depend only on player $i$'s strategy, $g_i:\mathbb{R}^{n_i} \rightarrow \mathbb{R}^{m_i}$ defines the private inequality constraints of player $i$ that depends only on player $i$'s strategy. $s:\mathbb{R}^{n} \rightarrow \mathbb{R}^{m_0}$ defines the shared constraints that depends on the strategies of all players and shared by all players. The solution set of problem (\ref{game_def}) for player $i$ is denoted by $\mathcal{S}_i(\bar{x}^{-i})$. The Generalized Nash Equilibrium Problem (GNEP) is the problem of finding vector $\bar{x}$ such that:
\begin{equation} \label{game_sol}
    \bar{x}^i \in \mathcal{S}_i(\bar{x}^{-i}) \quad \forall i \in \{1,...,N\}
\end{equation}
A solution to the GNEP is the GNE. A GNE is the set of strategies that characterized by the fact that none of the players can improve unilaterally it's cost function by changing its strategy in a feasible direction. Furthermore, it is typical to assume the following assumptions:
\begin{enumerate}[(i)] \label{assm}
\item Rosen's setting \cite{rosen1965existence} - set $\mathcal{X} \subset \mathbb{R}^n$ is convex and compact.
\item Function $g_i: \mathbb{R}^n \rightarrow \mathbb{R}, i=1,...,m$ and $s: \mathbb{R}^n \rightarrow \mathbb{R}^{m_0}$ are convex and continuously differentiable.
\item The cost function of every player $J_i(x^i,x^{-i})$ is continuously differentiable in $x \in \mathcal{X}$.
\item The cost function of every player $J_i(x^i,x^{-i})$ is pseudo-convex in $x^i$ for every given $x^{-i}$.
\end{enumerate}


Define the Lagrangian function for each player as:
\begin{equation} \label{Lagrangian}
    \mathcal{L}_i := J_i(x_i,x_{-i})+ \mu_i^Th_i(x_i) + \lambda_i^T \cdot g_i(x_i) + \sigma_i^T \cdot s(x_i,x_{-i})
\end{equation}
where, $\mu_i \in \mathbb{R}^{k_i}$ are the Lagrange multipliers of the equality constraints of player $i$, $\lambda_i \in \mathbb{R}_+^{m_i}$ and $\sigma_i \in \mathbb{R}_+^{m_0}$ are the Lagrange multipliers of the private and shared inequality constraints of player $i$ respectively. For a point $x \in \mathcal{X}$ to be a GNE, the following KKT conditions have to be satisfied:
\begin{equation} \label{KKT}
\begin{split}
    & \nabla_{x^i}\mathcal{L}_i =0, \quad \forall i =1,...,N \\
    & 0 \leq \lambda_i \perp g_i \leq 0, \quad \forall i =1,...,N \\
    & 0 \leq \sigma_i \perp s \leq 0, \quad \forall i =1,...,N \\
    & \lambda_i \geq 0, \quad \forall i =1,...,N \\
    & \sigma_i \geq 0, \quad \forall i =1,...,N \\
    & h_i = 0, \quad \forall i =1,...,N \\
\end{split}
\end{equation}
The following theorem for calculating the GNE as a solution to a GNEP.
\begin{theorem} \cite{dreves2011solution, bueno2019optimality, facchinei2010generalized} \label{thm0}
Given the assumptions above and that some suitable Constraint Qualification (CQ) holds (e.g., Slater CQ, linear independence CQ,...), then
\begin{enumerate}
   \item If the tuple $(\bar{x}, \{\bar{\mu}_i\}_{i=1}^N, \{\bar{\lambda}_i\}_{i=1}^N,\{\bar{\sigma}_i\}_{i=1}^N)$ satisfies the KKT conditions (\ref{KKT}), then $\bar{x}$ is a solution of the GNEP. 
   \item If $\bar{x}$ is a solution of the GNEP, then there exists a suitable vectors of multipliers $(\{\bar{\mu}_i\}_{i=1}^N, \{\bar{\lambda}_i\}_{i=1}^N,\{\bar{\sigma}_i\}_{i=1}^N)$ that satisfy the KKT conditions (\ref{KKT}) when $x=\bar{x}$.
\end{enumerate}
\end{theorem}

\subsection{GNE of Car Racing Example} \label{exm_2cars}
To illustrate the formulation presented in Section \ref{Problem}, we consider a single-step, finite-horizon, discrete-time, general-sum, open-loop dynamic game in a racing scenario involving three cars on a two-lane track. Each car is a player in the generalized Nash equilibrium problem (GNEP), where it controls its velocity along a one-dimensional lane. Car 1 occupies the first lane, while Cars 2 and 3 share the second lane. $x_i$ and $v_i$ represent the final position and velocity of car $i$, respectively. The game is formulated as follows:

\begin{equation} \label{exm:setup}
\begin{alignedat}{3}
    &\min_{x_1, v_1} \quad -x_1 + x_2 + \frac{1}{2}v_1^2 
    &\qquad\qquad &\min_{x_2, v_2} \quad -x_2 + x_1 + \frac{1}{2}v_2^2 
    &\qquad\qquad &\min_{x_3, v_3} \quad -x_3 + x_2 + \frac{1}{2}v_3^2 \\
    &\text{s.t.} & &\text{s.t.} & &\text{s.t.} \\
    &x_1 = x_1(0) + \Delta t\cdot v_1 
    &\qquad\qquad &x_2 = x_2(0) + \Delta t\cdot v_2 
    &\qquad\qquad &x_3 = x_3(0) + \Delta t\cdot v_3 \\
    &x_2 \leq x_3 
    & &x_2 \leq x_3 
    & &x_2 \leq x_3 \\
    &x_1(0) = 0 
    & &x_2(0) = 0.5 
    & &x_3(0) = 0.75
\end{alignedat}
\end{equation}

where $\Delta t = 1[sec]$. The objective of Car 1 is to advance farther than Car 2 while minimizing control effort. Similarly, Car 2 aims to advance farther than Car 1 while minimizing its control effort. Car 3, however, seeks to assist Car 1 in winning the race while keeping its control effort minimal. A collision avoidance constraint between Cars 2 and 3 makes it possible for car 3 to affect car 2 trajectory. Figure \ref{fig:race} illustrates the initial conditions of the race. Throughout this paper, we will use this example to provide insights into the proposed methods.
\begin{figure} 
\centering 
\includegraphics[scale=0.5]{images/car_race.png} 
\caption{Illustration of the 1D racing example.} 
\label{fig:race} 
\end{figure}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\section{The Normalized Solution For Dynamic Games} \label{Normalized}
Rosen introduced the concept of the ``Normalized" solution for the Generalized Nash Equilibrium Problem (GNEP) in \cite{rosen1965existence}. Under the previously stated assumptions, the normalized solution corresponds to a scenario where the Lagrange multipliers associated with the shared constraints are identical for all players:
\begin{equation} \label{shared_sigma}
    \sigma^1 = \dots = \sigma^N = \sigma.
\end{equation}
Rosen showed that a unique normalized solution exists under the specified conditions. Subsequent works, including \cite{harker1991generalized,facchinei2007generalized}, showed that reformulating the GNEP as a Quasi-Variational Inequality (QVI) problem inherently reduces the solution set to the normalized solution, see \cite{facchinei2007generalized} section 3. \textit{As a result, the normalized solution has become the de facto standard in solving GNEPs, to the extent that many papers do not explicitly mention this assumption}. One popular method for solving GNEPs is to reformulate the Karush-Kuhn-Tucker (KKT) conditions as a Mixed Complementarity Problem (MCP). An MCP is defined for a function $F(z): \mathbb{R}^d \to \mathbb{R}^d$, with lower and upper bounds $l \in \mathbb{R}^d$ and $u \in \mathbb{R}^d$, respectively. The goal is to find a vector $z^* \in \mathbb{R}^d$ such that the following conditions hold for each element $j \in \{1, \dots, d\}$:
\begin{equation} \label{MCP}
\begin{split}
    z^*_j = l_j &\iff F_j(z^*) \geq 0, \\
    l_j < z^*_j < u_j &\iff F_j(z^*) = 0, \\
    z^*_j = u_j &\iff F_j(z^*) \leq 0.
\end{split}
\end{equation}

The KKT conditions of the GNEP can be reformulated as an MCP by defining the following $F$, $l$, and $u$:
\begin{align}
F(z) &= 
\begin{bmatrix}
\nabla_{x^1}\mathcal{L}_1 \\
\vdots \\
\nabla_{x^N}\mathcal{L}_N \\
h_1 \\
\vdots \\
h_N \\
-g_1 \\
\vdots \\
-g_N \\
-s \\
\vdots \\
-s
\end{bmatrix},
\quad
l = 
\begin{bmatrix}
-\infty \\
\vdots \\
-\infty \\
-\infty \\
\vdots \\
-\infty \\
0 \\
\vdots \\
0 \\
0 \\
\vdots \\
0
\end{bmatrix},
\quad
u = 
\begin{bmatrix}
\infty \\
\vdots \\
\infty \\
\infty \\
\vdots \\
\infty \\
\infty \\
\vdots \\
\infty \\
\infty \\
\vdots \\
\infty
\end{bmatrix},
\label{eq:full_MCP}
\end{align}
where $\bar{z} = [x^1, \dots, x^N, \mu_1, \dots, \mu_N, \lambda_1, \dots, \lambda_N, \sigma_1, \dots, \sigma_N]$ represents the vector of all decision variables and Lagrange multipliers, and the shared constraint $s$ is duplicated $N$ times. Solving the MCP above yields the normalized solution, as shown in \cite{facchinei2007generalized}. To simplify the formulation, the normalized solution assumption reduces the MCP by enforcing shared multipliers resulting in:
\begin{align}
F(z) &= 
\begin{bmatrix}
\nabla_{x^1}\mathcal{L}_1 \\
\vdots \\
\nabla_{x^N}\mathcal{L}_N \\
h_1 \\
\vdots \\
h_N \\
-g_1 \\
\vdots \\
-g_N \\
-s
\end{bmatrix},
\quad
l = 
\begin{bmatrix}
-\infty \\
\vdots \\
-\infty \\
-\infty \\
\vdots \\
-\infty \\
0 \\
\vdots \\
0 \\
0 
\end{bmatrix},
\quad
u = 
\begin{bmatrix}
\infty \\
\vdots \\
\infty \\
\infty \\
\vdots \\
\infty \\
\infty \\
\vdots \\
\infty \\
\infty
\end{bmatrix},
\label{eq:normalized_MCP}
\end{align}
where $z = [x^1, \dots, x^N, \mu_1, \dots, \mu_N, \lambda_1, \dots, \lambda_N, \sigma]$ and
$\sigma^1 = \cdots = \sigma^N = \sigma$.


Numerical solvers, such as PATH \cite{dirkse1995path}, are widely used to solve MCPs efficiently and are considered state-of-the-art tools for this purpose. The normalized solution remains a computationally efficient and conceptually straightforward approach for solving GNEPs, despite its limitations in representing more complex dynamics.

\subsection{Limitations of Normalized GNE solutions}

As described above, the normalized solution is usually just one of many possible solutions. In some cases, this solution may not provide a reasonable or intuitive solution. To illustrate this, we solve the problem presented in \ref{exm_2cars} using the normalized solution assumption. Assuming that the Lagrange multipliers of the shared constraints are identical for all players, the Lagrangian functions for the problem are:
\begin{equation} \label{norm_exp:Lag}
\begin{split}
    \mathcal{L}_1 = -x_1+x_2+\frac{1}{2}v_1^2 + \mu_1(x_1 - x_1(0) - \Delta t\cdot v_1) + \sigma(x_2-x_3) \\
    \mathcal{L}_2 = -x_2+x_1+\frac{1}{2}v_2^2 + \mu_2(x_2 - x_2(0) - \Delta t\cdot v_2) + \sigma(x_2-x_3) \\
    \mathcal{L}_3 = -x_1+x_2+\frac{1}{2}v_3^2 + \mu_3(x_3 - x_3(0) - \Delta t\cdot v_3) + \sigma(x_2-x_3)
\end{split}
\end{equation}
Applying the first-order optimality conditions - stationary:
\begin{equation} \label{norm_exp:station}
\begin{split}
    &\frac{\partial\mathcal{L}_1}{\partial[x_1,v_1]} = \begin{bmatrix}
-1 +\mu_1 \\
v_1-\mu_1\Delta t
\end{bmatrix} =0 \Rightarrow \mu_1=1 \Rightarrow v_1=\Delta t \\
    &\frac{\partial\mathcal{L}_2}{\partial[x_2,v_2]} = \begin{bmatrix}
-1 +\mu_2+\sigma \\
v_2-\mu_2\Delta t
\end{bmatrix} =0 \Rightarrow \mu_2=1-\sigma \Rightarrow v_2=\Delta t(1-\sigma) \\
&\frac{\partial\mathcal{L}_3}{\partial[x_3,v_3]} = \begin{bmatrix}
\mu_3-\sigma \\
v_3-\mu_3\Delta t
\end{bmatrix} =0 \Rightarrow \mu_3=\sigma \Rightarrow v_3=\Delta t\sigma
\end{split}
\end{equation}
By the complementary slackness condition, there are two options for a solution, either the constraint is active ($\sigma=0$), which gives the following solution:
\begin{equation} \label{norm_exp:sol1}
    (x_1,x_2,x_3) = (x_1(0)+\Delta t^2, x_2(0)+\Delta t^2, x_3(0)) = (1,1.5,0.75)
\end{equation}
This solution violates the shared constraint and is therefore eliminated.
The second option is that the shared constraint is active $(\sigma>0)$:
\begin{equation} \label{norm_exp:sol2}
\begin{split}
    &x_2=x_3 \Rightarrow x_2(0) + \Delta t\cdot v_2=x_3(0) + \Delta t\cdot v_3 \Rightarrow \\ 
    &x_2(0) + \Delta t^2(1-\sigma)=x_3(0) + \Delta t^2 \sigma \Rightarrow \sigma=\frac{\Delta t^2-x_3(0) + x_2(0)}{\Delta t^2}= \frac{1}{2}\Rightarrow \\
    &(x_1,x_2,x_3) = (x_1(0) + \Delta t^2, \frac{x_2(0) + x_3(0)+\Delta t^2}{2}, \frac{x_2(0) + x_3(0)+\Delta t^2)}{2} = (1,1.125,1.125)
\end{split}
\end{equation}
The solution obtained from the normalized approach is counterintuitive. In the normalized solution, Car 3 does not block Car 2 as expected. Instead, it moves forward, worsening its own cost function. If Car 3 remains stationary, it would achieve a lower cost. The normalize GNE constrained by the fact that $\sigma$ is shared by all players gives a solution that car 3 would not have chosen under any other reasonable condition. It can be easily verified that any solution of the form $x_2=x_3 \in [0.75,1.125]$ is a GNE. Therefore, the normalized solution is merely one possible option for Car 3, and at first glance, it is not the most appealing.

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\section{Non Normalized Solution For Dynamic Games} \label{Non_Normalized}
The non-normalized solution of a GNEP is a solution $x \in \mathcal{X}$ such that the KKT conditions hold and the Lagrange multipliers of the shared constraints are not the same for all players. As mentioned in Section~\ref{Normalized}, the most popular tools to solve a GNEP are QVI or MCP reformulations, which produce the normalized solution when used as discussed in the previous literature. While these formulations offer many mathematical and numerical advantages, including compatibility with widely available solvers, Generalizing these formulations to allow for non-normalized solutions can be beneficial in many cases as shown by the example in section \ref{exm_2cars}. Next, we proposes a novel method to exploit the MCP reformulation of a GNEP to calculate non-normalized solutions. Recall the KKT conditions from the original GNEP formulation (\ref{KKT}). The main idea was to compute a single set of shared Lagrange multipliers and introduce a strictly positive scaling factor for each player's shared constraints. Now let's define for every player $i$ a diagonal matrix of weights:
\begin{equation} \label{factors}
\begin{aligned}
    &A_i \in \mathcal{D}^+_m, \\
    \mathcal{D}^+_m := \{D \in \mathbb{R}^{m \times m} \mid D = &\text{diag}(d_1, \cdots, d_m), \, d_i > 0 \, \forall i = 1, \cdots, m \}.
\end{aligned}
\end{equation}

Each $A_i$ is used to scale the shared Lagrange multipliers for player $i$ relative to the other players. Incorporating these factor matrices into the Lagrangina function (\ref{Lagrangian}) produces:
\begin{equation} \label{modified_Lagrangian}
    \mathcal{L}_i := J_i(x_i,x_{-i})+ \mu_i^Th_i(x_i) + \lambda_i^T \cdot g_i(x_i) + (A_i \sigma)^T \cdot s(x_i,x_{-i})
\end{equation}
Thus, the KKT conditions in (\ref{KKT}) are reformulated as:
\begin{equation} \label{modifiedKKT}
\begin{aligned}
    & \nabla_{x^i}J_i(x^i, x^{-i}) + \nabla_{x^i}(\mu^\top h_i) + \nabla_{x^i}(\lambda_i^\top g_i) + \nabla_{x^i}((A_i \sigma)^\top s) = 0, \quad \forall i \in \{1, \dots, N\}, \\
    & 0 \leq \lambda_i \perp g_i \leq 0, \quad \forall i \in \{1, \dots, N\}, \\
    & 0 \leq \sigma \perp s \leq 0, \\
    & \lambda_i \geq 0, \quad \forall i \in \{1, \dots, N\}, \\
    & \sigma \geq 0. \\
    &h_i=0, \quad \forall i \in \{1, \dots, N\}
\end{aligned}
\end{equation}

In this formulation, a single set of shared Lagrange multipliers $\sigma$ is computed, with the scaling applied differently for each player using the factor matrices $A_i$.  The following theorem shows that a solution to the KKT conditions in (\ref{modifiedKKT}) is a GNE solution.

\begin{theorem} \label{thm1}
    Given a set of matrices $\{A_i\}_{i=1}^N$ as defined in (\ref{factors}) and the tuple $(\bar{x}, \{\bar{\mu}_i\}_{i=1}^N, \{\bar{\lambda}_i\}_{i=1}^N, \bar{\sigma})$ that solves the KKT conditions in (\ref{modifiedKKT}), then $\bar{x}$ is a solution to the GNEP if a suitable constraint qualification holds.
\end{theorem}

\begin{proof}
The proof of Theorem~\ref{thm1} follows directly from Theorem \ref{thm0}. Define the Lagrange multipliers $\bar{\sigma}_i \in \mathbb{R}^{m_0}$ for player $i$ as:
\begin{equation} \label{eff_sigma}
    \bar{\sigma}_i = A_i \bar{\sigma}, \quad \forall i \in \{1, \dots, N\}.
\end{equation}

The tuple $(\bar{x}, \{\bar{\mu}_i\}_{i=1}^N, \{\bar{\lambda}_i\}_{i=1}^N, \{\bar{\sigma}_i\}_{i=1}^N)$ that solves the KKT conditions in (\ref{KKT})
and thus by Theorem \ref{thm0}, $\bar{x}$ is a solution of the GNEP.
\end{proof}

Theorem~\ref{thm1} provides a method for calculating non-normalized solutions to a GNEP using the tools developed for normalized solutions. The solution process can use the same MCP formulation as in \ref{eq:normalized_MCP} with the same available solvers (e.g., PATH), with the modified Lagrangian that includes the factor matrices. If all factor matrices $A_i$ are identical, the solution reduces to the normalized GNE. The factor matrices $A_i$ can be interpreted as representing the relative ``aggressiveness" of each player: lower values in $A_i$ for active shared constraints indicate a reduction in the corresponding Lagrange multipliers, allowing the player to improve their cost relative to others. Notice that the diagonal entries of $A_i$ are strictly positive, and therefore any positive terms in $\bar{\sigma}$ (representing to active constraints) remain positive in $\bar{\sigma}_i$, while zero terms in $\bar{\sigma}$ remain zero in $\bar{\sigma}_i$. Furthermore, and without lose of generality, the factor matrix for player 1 can be defined as $A_1=I_{m_0}$. This is due to the fact that the factor matrices are all relative. The same solution $(\bar{x}, \{\bar{\mu}_i\}_{i=1}^N, \{\bar{\lambda}_i\}_{i=1}^N, \{\bar{\sigma}_i\}_{i=1}^N)$ is valid, if all factor matrices are divided by some factor and $\bar{\sigma}$ is multiplied by the same factor - this will ensure that the Lagrange multipliers $\bar{\sigma_i}$ will stay the same.



%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\section{Analytical Examples} \label{examples}
We use two examples to show the effectiveness of the method presented. The first is an example used in \cite{facchinei2007generalized,facchinei2009generalized}. The problem is a dynamic game between 2 player with the following setup (the variables notation are as in the original papers):
\begin{equation} \label{exm1:setup}
\begin{alignedat}{2}
    & \min_x \, (x-1)^2 \qquad \qquad \qquad && \min_y \, \left(y - \frac{1}{2}\right)^2 \\
    & \text{s.t.} \quad && \text{s.t.} \\
    & x + y \leq 1 \qquad && x + y \leq 1
\end{alignedat}
\end{equation}
Where $x$ and $y$ are the strategy of each player. Applying the technique presented in this paper, we write the Lagrangian for each player with $\alpha_1$ and $\alpha_2$ as the factors on the shared constraints Lagrangian of each player (since there is a single shared constraint, the factors are scalars):
\begin{equation} \label{exm1:Lagra}
\begin{split}
    &\mathcal{L}_1 = (x-1)^2 + \alpha_1\sigma (x+y-1) \\
    &\mathcal{L}_2 = (y-\frac{1}{2})^2 + \alpha_2\sigma (x+y-1)
\end{split}
\end{equation}
The KKT conditions of the problem are:
\begin{equation} \label{exm1:KKT}
\begin{split}
    &\nabla_x\mathcal{L}_1 = 0 \Rightarrow 2x-2 + \alpha_1\sigma =0 \Rightarrow x=1-\frac{1}{2}\alpha_1\sigma \\
    &\nabla_y\mathcal{L}_2 = 0 \Rightarrow 2y-1 + \alpha_2\sigma =0 \Rightarrow y=\frac{1}{2}-\frac{1}{2}\alpha_2\sigma\\
    &0 \leq \sigma \perp (x+y-1) \leq 0 \\
    &\sigma \geq 0, (x+y-1) \leq 0
\end{split}
\end{equation}
There now two options according to the complementary slackness condition. The first option is that the constraint is inactive. This option gives a solution of $x=1,y=\frac{1}{2}$ that violates the constraints and is therefore eliminated. The second option is that the constraint is active:
\begin{equation} \label{exm1:sol}
\begin{split}
    &x+y=1 \Rightarrow 1-\frac{1}{2}\alpha_1\sigma+\frac{1}{2}-\frac{1}{2}\alpha_2\sigma=1 \\
    &\Rightarrow \sigma=\frac{1}{\alpha_1+\alpha_2} \\
\end{split}
\end{equation}
According to Theorem \ref{thm1} for every given $\alpha_1$ and $\alpha_2$ $x^*$ and $^*$ are NE:
\begin{equation} \label{exm1:final_sol}
    x^*=1-\frac{\alpha_1}{2(\alpha_1+\alpha_2)} \qquad y^*=\frac{1}{2}-\frac{\alpha_2}{2(\alpha_1+\alpha_2)}
\end{equation}
Furthermore, we can define $\alpha$ such that:
\begin{equation} \label{exm1:final_sol2}
    \alpha = \frac{\alpha_1}{\alpha_1+\alpha_2} \Rightarrow 1-\alpha=\frac{\alpha_2}{\alpha_1+\alpha_2} \Rightarrow \left\{
\begin{aligned}
    & x^* = 1-\frac{1}{2}\alpha \\
    & y^* = \frac{\alpha}{2} \\
\end{aligned}
\right.
\end{equation}
Since $\alpha_1>0$ and $\alpha_2>0$ it suggests that $\alpha \in (0,1)$. The solution for $\alpha\rightarrow0$ gives the solution that converges to $(x^*=1,y^*=0)$ which is the unconstrained solution for player 1 and player 2 just responds - Stackelberg Equilibrium where player 1 is the leader and player 2 is the follower. The solution for $\alpha\rightarrow1$ gives the solution the converges to $(x^*=\frac{1}{2},y^*=\frac{1}{2})$ which is the unconstrained solution for player 2 and player 1 just responds - Stackelberg Equilibrium where player 2 is the leader and player 1 is the follower. For $\alpha=\frac{1}{2}$ the solution corresponds to the normalized solution $(x^*=\frac{3}{4},y^*=\frac{1}{4})$.

The second example given here is a dynamic game presented in \ref{exm_2cars}. Applying the technique presented in this paper the and notating the factor as $\alpha_1,\alpha_2,\alpha_3$ for the shared constraint, the Lagrangians are:
\begin{equation} \label{nonnorm_exp:Lag}
\begin{split}
    \mathcal{L}_1 = -x_1+x_2+\frac{1}{2}v_1^2 + \mu_1(x_1 - x_1(0) - \Delta t\cdot v_1) + \alpha_1\sigma(x_2-x_3) \\
    \mathcal{L}_2 = -x_2+x_1+\frac{1}{2}v_2^2 + \mu_1(x_2 - x_2(0) - \Delta t\cdot v_2) + \alpha_2\sigma(x_2-x_3) \\
    \mathcal{L}_3 = -x_1+x_2+\frac{1}{2}v_3^2 + \mu_1(x_3 - x_3(0) - \Delta t\cdot v_3) + \alpha_3\sigma(x_2-x_3)
\end{split}
\end{equation}
Applying the stationary condition:
\begin{equation} \label{norm_exp:station2}
\begin{split}
    &\frac{\partial\mathcal{L}_1}{\partial[x_1,v_1]} = \begin{bmatrix}
-1 +\mu_1 \\
v_1-\mu_1\Delta t
\end{bmatrix} =0 \Rightarrow \mu_1=1 \Rightarrow v_1=\Delta t \\
    &\frac{\partial\mathcal{L}_2}{\partial[x_2,v_2]} = \begin{bmatrix}
-1 +\mu_2+\alpha_2\sigma \\
v_2-\mu_2\Delta t
\end{bmatrix} =0 \Rightarrow \mu_2=1-\alpha_2\sigma \Rightarrow v_2=\Delta t(1-\alpha_2\sigma) \\
&\frac{\partial\mathcal{L}_3}{\partial[x_3,v_3]} = \begin{bmatrix}
\mu_3-\alpha_3\sigma \\
v_3-\mu_3\Delta t
\end{bmatrix} =0 \Rightarrow \mu_3=\alpha_3\sigma \Rightarrow v_3=\Delta t\alpha_3\sigma
\end{split}
\end{equation}
By the complementary slackness condition, there are two options for a solution, either the constraint is active ($\sigma=0$), which gives the following solution:
\begin{equation} \label{norm_exp:sol3}
    (x_1,x_2,x_3) = (x_1(0)+\Delta t^2, x_2(0)+\Delta t^2, x_3(0)) = (1,1.5,1)
\end{equation}
This solution violates the shared constraint and is therefore eliminated.
The second option is that the shared constraint is active $(\sigma>0)$:
\begin{equation} \label{norm_exp:sol4}
\begin{split}
    &x_2=x_3 \Rightarrow x_2(0) + \Delta t\cdot v_2=x_3(0) + \Delta t\cdot v_3 \Rightarrow \\ 
    &x_2(0) + \Delta t^2(1-\alpha_2\sigma)=x_3(0) + \Delta t^2 \alpha_3\sigma \Rightarrow \sigma=\frac{\Delta t^2-x_3(0) + x_2(0)}{(\alpha_2+\alpha_3)\Delta t^2}\Rightarrow \\
    &(x_1,x_2,x_3) = (x_1(0) + \Delta t^2, \frac{\alpha_3x_2(0) + \alpha_2x_3(0)+\alpha_3\Delta t^2}{\alpha_2+\alpha_3}, \frac{\alpha_3x_2(0) + \alpha_2x_3(0)+\alpha_3\Delta t^2}{\alpha_2+\alpha_3}
\end{split}
\end{equation}
It can be seen that the solution is independent of $\alpha_1$. Furthermore, we can define $\alpha$ such that:
\begin{equation} \label{exm1:final_sol3}
    \alpha = \frac{\alpha_2}{\alpha_2+\alpha_3} \Rightarrow 1-\alpha=\frac{\alpha_3}{\alpha_2+\alpha_3} \Rightarrow \left\{
\begin{aligned}
    & x^*_1 = 1 \\
    & x^*_2 = \alpha x_3(0) + (1-\alpha)(\Delta t^2+x_2(0))=\frac{3}{2}-\frac{3}{4}\alpha \\
    & x^*_3 = \alpha x_3(0) + (1-\alpha)(\Delta t^2+x_2(0))=\frac{3}{2}-\frac{3}{4}\alpha
\end{aligned}
\right.
\end{equation}
Since $\alpha_2>0$ and $\alpha_3>0$, it suggests that $\alpha \in (0,1)$. This gives all the solutions for $x_2=x_3 \in (0.75,1.5)$.

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\section{Selecting a GNE Point Among Many}
In previous section we have shown how to utilize an MCP formulation to calculate a set of possible GNE of a GNEP.  
To choose a solution from the possible GNE set, a bi-level optimization scheme is suggested in this paper. The optimization problem we proposes chooses the set of factor matrices $\{A_i\}_{i=1}^N$ which  that minimize a  given  cost function:
\begin{equation} \label{opt:biopt}
\begin{split}
    &\min_{A_i,..,A_N\in \mathcal{D}^+_m} {J_0(x^*)} \\
    & s.t. \\
    &(x^i)^* \in \mathcal{S}_i(x^{-i},A_1,...,A_N) \quad \forall i \in \{1,...,N\}
\end{split}
\end{equation}
In general, the bi-level optimization \ref{opt:biopt} can be hard to solve. The cost to minimize can be of any form and can try to achieve different goals. A few possible objectives include: 1) minimize the sum of all the players' costs. 2) Optimize for the cost of one of the players - this will lead to a strategy close to a Stackelberg Equilibrium (in a 2 players scenario). 3) Optimize over some property of the game - maximize the average velocity in a racing game or maximize the interaction between players. To see the effect of such bi-level optimization, the problems presented in section \ref{examples} are solved using cost 1):
\begin{equation} \label{opt:cost}
    J_0 = \sum_{i=1}^N{J_i(x^i,x^{-i})}
\end{equation}
In the case of the first example, the bi-level optimization is:
\begin{equation} \label{opt:opt1}
\begin{split}
    \min_{0<\alpha<1} &{(x^*-1)^2+(y^*-\frac{1}{2})^2} \\
    & s.t. \\
    &x^*=1-\frac{1}{2}\alpha \\
    &y^*=\frac{\alpha}{2}
\end{split}
\end{equation}
Substituting the optimal solution for both players into the cost:
\begin{equation} \label{opt:opt2}
\begin{split}
    &J_0(\alpha)=(1-\frac{1}{2}\alpha-1)^2+(\frac{\alpha}{2}-\frac{1}{2})^2 \\
    &\Rightarrow J_0(\alpha)=\frac{1}{4}(2\alpha^2-\alpha+1) \\
    &\Rightarrow \frac{dJ_0}{d\alpha}=\alpha-1
    \end{split}
\end{equation}
By setting $\frac{dJ_0}{d\alpha}=0$, the optimal solution given the chosen $J_0$ is $\alpha^*=1$. Even though the domain of $\alpha \in (0,1)$ technically doesn't include $1$, in this case $\alpha=1$ gives a feasible solution:
\begin{equation} \label{opt:opt3}
    x = y = \frac{1}{2}
\end{equation}
Recall that the normalized solution approach gives a different solution $(x=\frac{3}{4},y=\frac{1}{4})$. For the same choise of $J_0$ type, the second example give the following:
\begin{equation} \label{opt:opt4}
\begin{split}
    \min_{0<\alpha<1} &{-x^*_1+x^*_2+\frac{(v_1^*)^2+(v_2^*)^2+(v_3^*)^2}{2}} \\
    & s.t. \\
    &x^*_1=1 \\
    &x^*_2=(1-\alpha)(\Delta t^2+x_2(0)) + \alpha x_3(0) + (1- 2\alpha)\Delta t^2 \\
    &v_1^*=\Delta t \\
    &v_2^* = \frac{(1-\alpha)\Delta t^2+\alpha(x_3(0)-x_2(0))}{\Delta t} \\
    &v_3^* = \frac{(1-\alpha)\Delta t^2-(1-\alpha)(x_3(0)-x_2(0))}{\Delta t}
\end{split}
\end{equation}
Substituting the terms for $(x_1,v_1,x_2,v_2)^*$ into $J_0$ and taking the derivative with respect to $\alpha$:
\begin{equation}
    \frac{dJ(\alpha)}{d\alpha} =0 
\end{equation}

where, Solving for the optimal $\alpha^*$ gives a value greater than the maximal allowed, so the optimal value is $\alpha^*=1$ and this corresponds to the solution:
\begin{equation}
    (x_1^*,x_2^*,x_3^*) = (1,0.75,0.75)
\end{equation}
This solution is much more intuitive relative to the normalized solutions. In this case, car 3 actually helps car 1 win the race. This example illustrates a possible problem of considering only a single predefined solution of the GNEP, like the normalized solution.

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\section{Numerical Two-Car Racing Problem} \label{num_2cars}
One of the most popular ways to solve a problem of autonomous car racing is by using a DG approach. In a 2 cars race, each car has a unique dynamic model and a cost function to minimize. A DG formulation is set up for each car with some shared prediction horizon. The shared constraint of the game is Collision Avoidance (CA) between both players. The DG is solved by finding the GNE of the problem, usually using a MCP formulation solved with a numerical solver, and the shared constraints Lagrange multipliers are assumed to be the same \cite{zhu2023sequential,liu2023learning}. As in the problem presented in section \ref{exm_2cars}, this problem usually has more than one GNE and there is no good reason to prefer the normalized solution. The kinematic bicycle model for each car, with the following states:

\begin{equation}
    x^i_k = [v, \psi, s, t, X, Y], \quad i=1,2 \quad k = 0,...,N
\end{equation}

where, $v$ is the total velocity, $\psi$ is the angular state, and $s, v_t$ are the arc-length position of the car in the local Frenet reference frame relative to the center line of the track and lateral deviation from the center-line, respectively. $X$ and $Y$ are the inertial position of the car. $N$ is the prediction horizon. The inputs are:
\begin{equation}
    u^i_k = [u_a, u_\delta], \quad i=1,2 \quad k = 0,...,N-1
\end{equation}
where, $u_a$ is the longitudinal acceleration and $u_\delta$ is the steering of the front wheels. To illustrate the effectiveness of the proposed method, the same dynamic model and cost function is used for both players. The Dynamic Game formulation is given by:

\begin{align*}
    &i \in \{1,2\}\left\{
    \begin{aligned}
        &\min_{x^i, u^i} -s^i_N + s^{-i}_N + \frac{\beta}{2} \sum_{k=0}^{N-1} \|u^i_k\|^2 \\  
        &\text{s.t.} \\ 
        & x^i_{k+1} = f(x^i_k, u^i_k), \quad k = 0, \dots, N-1\\ 
        & x^i_k \in \mathcal{X}, \quad u^i_k \in \mathcal{U}, \quad k = 0, \dots, N-1 \\  
        & (X^1_k - X^2_k)^2 + (Y^1_k - Y^2_k)^2 \geq d_{safe}, \quad k = 0, \dots, N-1
    \end{aligned}
    \right.
\end{align*}

where, $f$ is the dynamics function, $\mathcal{X}$ is the feasible set of the states, $\mathcal{U}$ is the feasible set of the inputs, and $d_{safe}$ is the minimal distance between both vehicles. $\beta = 10^{-1}$. As can be seen, both cars have the same properties and the same cost function properties. Each car aims to maximize its own progress while minimizing control effort. A detailed description of the dynamics function $f$ and the feasible sets of states and inputs can be found in the Appendix \ref{AppA}. 

To find the GNE of this DG, an MCP formulation \ref{eq:normalized_MCP} is used. To define the Lagrangian of each car by the method presented in \ref{Non_Normalized}, a different factor should be given to every CA constraint. In this problem, there are $N$ Constraints for each car. To make the solution more trackable, the number of parameters of the optimization problem is lowered. The factor matrix of the first car is chosen to be $I_{m_0}$ as explained in section \ref{Non_Normalized} and the factor matrix of car 2 is reduced to $\alpha I_{m_0}$ which can further reduced to a scalar $\alpha$. This means that there is a single parameter that factors the shared constraints Lagrange multipliers:
\begin{align*}
&L_1 = -s^1_N + s^2_N + \frac{\beta}{2}\sum_{k=0}^{N-1}{\|u^1_k\|^2} + \mu_1^T \cdot h_1(x^1, u^1) + \lambda_1^T\cdot g_1(x^1,u^1) + \sigma^T\cdot g_{CA}(x^1,x^2) \\
&L_2 = -s^2_N + s^1_N + \frac{\beta}{2}\sum_{k=0}^{N-1}{\|u^2_k\|^2} + \mu_2^T \cdot H_2(x^2,u^2) + \lambda_2^T\cdot g_2(x^2,u^2) + \alpha\sigma^T\cdot g_{CA}(x^1,x^2)
\end{align*}
where  $\mu_1, \mu_2$ are the Lagrange multipliers associated with the dynamics (equality) constraints  $h_1, h_2$. $\lambda_1, \lambda_2$ are the Lagrange multipliers associated with the state and input constraints $g_1, g_2$. $\sigma$ is the Lagrange multiplier vector associated with the CA constraint $g_{CA}$. The next step to solve the MCP formulation is to apply the stationary condition on each Lagrangian and complementary slackness conditions:
\begin{align*}
&\frac{\partial L_1}{\partial(x^1,u^1)} = 0,\quad \frac{\partial L_2}{\partial(x^2,u^2)} = 0 \\
&x^1_{k+1} - f_1(x^1_k, u^1_k) = 0,\quad x^2_{k+1} - f_2(x^2_k, u^2_k) = 0 \\
& g_1(x^1,u^1) \leq 0,\quad  g_2(x^2,u^2) \leq 0 \\
& g_{CA}(x^1,x^2) \leq 0
\end{align*}
Solving the above KKT equations of any value of $\alpha \in (0,\infty)$ gives a valid GNE solution. The solution set of 2 examples are presented here. Each example contains the calculated GNE solutions of the race for a given initial states of the car on different tracks. The first example is calculated on a straight track. Car 1 is ahead of car 2 but has a velocity disadvantage. Figure \ref{fig:race_straight} shows the solution of the race for different $\alpha$. The solution for $\alpha \rightarrow 0$ gives a straight trajectory (red line) for car 1 and this corresponds to car 1 being more aggressive than car 2. The solution for $\alpha \rightarrow \infty$ gives a straight trajectory (magenta line) for car 2 and this corresponds to car 2 being more aggressive than car 1. The GNE solution changes continuously as $\alpha$ changes. The lower graph shows the cost function of both cars as function of $\alpha$, along with their sum. It can be seen that for $\alpha \approx2.5$ the sum of cost is minimized, and it corresponds to a trajectory that is very similar to a trajectory in which $\alpha \rightarrow \infty$. On the left side of the graph the velocity and steering profile of the cars are presented.

\begin{figure}
    \centering
    \includegraphics[scale=0.25]{images/Race_MultipleGNE_Straight.png}

    \caption{Racing Problem Solutions on a Straight Track}
    \label{fig:race_straight}
\end{figure}
The second example is calculated on a curved track. Car 1 is ahead of car 2 but has a velocity disadvantage. Figure \ref{fig:race_circle} shows the solution of the race for different $\alpha$. In this example there are 2 types of possibles solutions. For $\alpha \rightarrow 0$ Car 2 is much more aggressive and cuts into the corner which enforces Car 1 to take the wider turn. On the other hand, for $\alpha \rightarrow \infty$ car 1 is much more aggressive and it cuts into the corner before car 2 can do it - this enforces car 2 to take the wider turn. The GNE solution doesn't changes continuously as $\alpha$ changes. The lower graph shows the cost function of both cars as function of $\alpha$ and the their sum. It can be seen that for $\alpha \approx10$ there is a jump in the costs which corresponds to the jump in the solution types. In this example the sum of cost is minimized for an $\alpha$ close to the switching point. On the left side of the graph the velocity and steering profile of the cars are presented.
\begin{figure}
    \centering
    \includegraphics[scale=0.25]{images/Race_MultipleGNE_Circle.png}

    \caption{Racing Problem Solutions on a Curved Track}
    \label{fig:race_circle}
\end{figure}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\section{Conclusion}
This paper introduces a novel method for extending existing approaches used to solve dynamic games (DG) through Variational Inequality (VI) and Mixed Complementarity Problem (MCP) tools. While these traditional methods have been predominantly restricted to computing the normalized solution, the proposed framework allows for the computation of non-normalized solutions, significantly expanding the solution space in DGs while using the same powerful methods. The proposed method not only identifies non-normalized solutions but also provides a systematic approach to select a Generalized Nash Equilibrium (GNE) from the potentially large set of solutions. By leveraging bi-level optimization, the method enables solution selection based on specific objectives, such as minimizing the aggregate cost, optimizing the performance of individual players, or prioritizing game-specific properties. Furthermore, the examples demonstrate the effectiveness of the proposed framework in practical applications, highlighting its ability to identify diverse GNE solutions and to tailor these solutions to specific objectives. This approach addresses the limitations of normalized solutions by accounting for terms that are neglected in the standard solution. In conclusion, this work expands the computational toolbox for DGs by enabling exploration beyond normalized solutions and by offering a structured methodology for equilibrium selection. These contributions pave the way for more robust and flexible applications of game-theoretic principles in complex, real-world scenarios.

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%


\bibliographystyle{IEEEtran}
\bibliography{IEEEfull,bibliography.bib}

\section{Appendix A: Vehicle Model and Constraints} \label{AppA}
In this section, the dynamic model of the car used in section \ref{num_2cars} is presented. As presented, both cars in the example are the same and are based on the BARC $1/10$ scale racing car used in the MPC lab at UC Berkeley. The model is a kinematic bicycle model with the following states:
\begin{equation}
    x^i_k = [v, \psi, s, t, X, Y], \quad i=1,2 \quad k = 0,...,N
\end{equation}

where, $v$ is the total velocity, $\psi$ is the angular state, and $s, t$ are the position of the car in the local Frenet reference frame relative to the center line of the track. $X$ and $Y$ are the inertial position of the car. $N$ is the prediction horizon. The inputs to the model are:
\begin{equation}
    u^i_k = [u_a, u_\delta], \quad i=1,2 \quad k = 0,...,N-1
\end{equation}
where, $u_a$ is the longitudinal acceleration and $u_\delta$ is the steering of the front wheels. The equations of motion represented by $f_c$ in the local Frenet frame and Inertial Position are:

\begin{align*}
& \dot{v} = u_a \\
& \dot{\psi} = \frac{v \sin(\beta)}{l_r} - \frac{\kappa(s) v \cos(\psi + \beta)}{1 - t \kappa(s)} \\
& \dot{s} = \frac{v \cos(\psi + \beta)}{1 - t \kappa(s)} \\
& \dot{t} = v \sin(\psi + \beta) \\
& \dot{X} = v \cos(\psi + \beta + \theta(s)) \\
& \dot{Y} = v \sin(\psi + \beta + \theta(s))
\end{align*}
where, $\beta(u_\delta) = tan(u_\delta)\frac{l_f}{l_f+l_r}$ is the side slip angle, $l_f=0.13[m]$ , $l_r=0.13[m]$ are the distance from the center of mass to the front and rear axles of the BARC respectively, $\kappa(s)$ is the curvature of the track center-line at a given s, and $\theta(s)$ is the inertial angle of the track center-line at a given s.

The state constraints and input constraints are give in the following table:
\[
\begin{array}{|c|c|c|c|}
\hline
\text{Parameter} & \text{Min Value} & \text{Max Value} & \text{Units} \\
\hline
v & 0 & 2 & \text{m/s} \\
\psi & -180 & 180 & \text{deg} \\
s & 0 & \infty & \text{m} \\
t & -H/2 & H/2 & \text{m} \\
X & -\infty & \infty & \text{m} \\
Y & -\infty & \infty & \text{m} \\
u_a & -2 & 2 & \text{m/s}^2 \\
u_{\delta} & -25 & 25 & \text{deg} \\
\hline
\end{array}
\]
This equations of motion are the dynamics of the cars and used to advance the states of the car from some time $k$ to time $k+1$ using a 4th order Runge-Kutta integration method. The function that implements the integration along some time step $\Delta t$ is $f$:
\begin{equation}
    x^i_{k+1} = RK4(f_c,x_k,u_k, \Delta t) = f(x_k,u_k)
\end{equation}


\end{document}
