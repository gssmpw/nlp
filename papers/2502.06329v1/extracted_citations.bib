@inproceedings{10.1007/978-3-642-37487-6_2,
	abstract = {Although Web search engine technologies have made a great progress in recent years, they are still suffering from the low search performance (precision and recall) because of the following reasons:},
	address = {Berlin, Heidelberg},
	author = {Tanaka, Katsumi},
	booktitle = {Database Systems for Advanced Applications},
	editor = {Meng, Weiyi and Feng, Ling and Bressan, St{\'e}phane and Winiwarter, Werner and Song, Wei},
	isbn = {978-3-642-37487-6},
	pages = {2--2},
	publisher = {Springer Berlin Heidelberg},
	title = {Can We Predict User Intents from Queries?},
	year = {2013}
}

@misc{agarwal2024llmreasoningplanningsupportingincompleteuser,
      title={LLM+Reasoning+Planning for supporting incomplete user queries in presence of APIs}, 
      author={Sudhir Agarwal and Anu Sreepathy and David H. Alonso and Prarit Lamba},
      year={2024},
      eprint={2405.12433},
      archivePrefix={arXiv},
      primaryClass={cs.AI},
      url={https://arxiv.org/abs/2405.12433}, 
}

@article{boulila2024hallucination,
  title={Hallucination Rates and Reference Accuracy of ChatGPT and Bard for Systematic Reviews: Comparative Analysis},
  author={Chelli, Mikaël and Descamps, Jules and Lavoué, Vincent and Trojani, Christophe and Azar, Michel and Deckert, Marcel and Raynier, Jean-Luc and Clowez, Gilles and Boileau, Pascal and Ruetsch-Chelli, Caroline},
  journal={Journal of Medical Internet Research},
  volume={26},
  number={1},
  pages={e53164},
  year={2024},
  month={May},
  publisher={JMIR Publications Inc.},
  doi={10.2196/53164},
  url={https://www.jmir.org/2024/1/e53164/}
}

@article{du2023quantifying,
title={Quantifying and Attributing the Hallucination of Large Language Models via Association Analysis},
author={Du, Li and Ding, Zhuoye and Ding, Zhuoye and Huang, Xuanjing and Wei, Zhongyu},
journal={arXiv preprint arXiv:2309.05217},
year={2023}
}

@inproceedings{guo2023chatgptfinancialexpertevaluating,
    title = "Is {C}hat{GPT} a Financial Expert? Evaluating Language Models on Financial Natural Language Processing",
    author = "Guo, Yue  and
      Xu, Zian  and
      Yang, Yi",
    editor = "Bouamor, Houda  and
      Pino, Juan  and
      Bali, Kalika",
    booktitle = "Findings of the Association for Computational Linguistics: EMNLP 2023",
    month = dec,
    year = "2023",
    address = "Singapore",
    publisher = "Association for Computational Linguistics",
    url = "https://aclanthology.org/2023.findings-emnlp.58",
    doi = "10.18653/v1/2023.findings-emnlp.58",
    pages = "815--821",
    abstract = "The emergence of Large Language Models (LLMs), such as ChatGPT, has revolutionized general natural language preprocessing (NLP) tasks. However, their expertise in the financial domain lacks a comprehensive evaluation. To assess the ability of LLMs to solve financial NLP tasks, we present FinLMEval, a framework for Financial Language Model Evaluation, comprising nine datasets designed to evaluate the performance of language models. This study compares the performance of fine-tuned auto-encoding language models (BERT, RoBERTa, FinBERT) and the LLM ChatGPT. Our findings reveal that while ChatGPT demonstrates notable performance across most financial tasks, it generally lags behind the fine-tuned expert models, especially when dealing with proprietary datasets. We hope this study builds foundation evaluation benchmarks for continuing efforts to build more advanced LLMs in the financial domain.",
}

@article{hong2024hallucinations,
title={The Hallucinations Leaderboard -- An Open Effort to Measure Hallucinations in Large Language Models},
author={Hong, Giwon and Jang, Eunsol and Kim, Jeonghyeon and Shin, Jamin and Yoon, Soyoung and Yoon, Sungdong and Shin, Jongwon and Seo, Minjoon},
journal={arXiv preprint arXiv:2404.05904},
year={2024}
}

@article{islam2023financebenchnewbenchmarkfinancial,
      title={FinanceBench: A New Benchmark for Financial Question Answering}, 
      author={Pranab Islam and Anand Kannappan and Douwe Kiela and Rebecca Qian and Nino Scherrer and Bertie Vidgen},
      year={2023},
      eprint={2311.11944},
      archivePrefix={arXiv},
      journal={arXiv preprint arXiv:2311.11944},
      primaryClass={cs.CL},
      url={https://arxiv.org/abs/2311.11944}, 
}

@inproceedings{ji2024anah,
    title = "{ANAH}: Analytical Annotation of Hallucinations in Large Language Models",
    author = "Ji, Ziwei  and
      Gu, Yuzhe  and
      Zhang, Wenwei  and
      Lyu, Chengqi  and
      Lin, Dahua  and
      Chen, Kai",
    editor = "Ku, Lun-Wei  and
      Martins, Andre  and
      Srikumar, Vivek",
    booktitle = "Proceedings of the 62nd Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers)",
    month = aug,
    year = "2024",
    address = "Bangkok, Thailand",
    publisher = "Association for Computational Linguistics",
    url = "https://aclanthology.org/2024.acl-long.442",
    doi = "10.18653/v1/2024.acl-long.442",
    pages = "8135--8158",
    abstract = "Reducing the {`}$\textit{hallucination}$' problem of Large Language Models (LLMs) is crucial for their wide applications. A comprehensive and fine-grained measurement of the hallucination is the first key step for the governance of this issue but is under-explored in the community.Thus, we present $\textbf{ANAH}$, a bilingual dataset that offers $\textbf{AN}$alytical $\textbf{A}$nnotation of $\textbf{H}$allucinations in LLMs within Generative Question Answering.Each answer sentence in our dataset undergoes rigorous annotation, involving the retrieval of a reference fragment, the judgment of the hallucination type, and the correction of hallucinated content. ANAH consists of {\textasciitilde}12k sentence-level annotations for {\textasciitilde}4.3k LLM responses covering over 700 topics, constructed by a human-in-the-loop pipeline.Thanks to the fine granularity of the hallucination annotations, we can quantitatively confirm that the hallucinations of LLMs progressively accumulate in the answer and use ANAH to train and evaluate hallucination annotators. We conduct extensive experiments on studying generative and discriminative annotators and show that, although current open-source LLMs have difficulties in fine-grained hallucination annotation, the generative annotator trained with ANAH can surpass all open-source LLMs and GPT-3.5, obtain performance competitive with GPT-4, and exhibits better generalization ability on unseen questions.",
}

@inproceedings{jiang2024cost,
  title={Cost-Effective Hallucination Detection for LLMs},
  author={Valentin, Simon and Fu, Jinmiao and Detommaso, Gianluca and Xu, Shaoyuan and Zappella, Giovanni and Wang, Bryan},
  booktitle={Proceedings of the 30th ACM SIGKDD Conference on Knowledge Discovery and Data Mining},
  year={2024},
  month={August},
  publisher={Association for Computing Machinery},
  address={New York, NY, USA},
  series={KDD '24}
}

@article{jiang2024large,
title={On Large Language Models' Hallucination with Regard to Known Facts},
author={Jiang, Che and Qi, Biqing and Hong, Xiangyu and Fu, Dayuan},
journal={arXiv preprint arXiv:2403.20009},
year={2024}
}

@misc{langchain2022,
    author = "Chase, Harrison",
    month = "10",
    title = "LangChain",
    howpublished = "\url{https://docs.llamaindex.ai/en/stable/examples/chat_engine/chat_engine_condense_plus_context/}",
    year = "2022"
}

@article{liu2024findabenchbenchmarkingfinancialdata,
      title={FinDABench: Benchmarking Financial Data Analysis Ability of Large Language Models}, 
      author={Shu Liu and Shangqing Zhao and Chenghao Jia and Xinlin Zhuang and Zhaoguang Long and Jie Zhou and Aimin Zhou and Man Lan and Qingquan Wu and Chong Yang},
      year={2024},
      eprint={2401.02982},
      archivePrefix={arXiv},
      journal={arXiv preprint arXiv:2401.02982},
      primaryClass={cs.CL},
      url={https://arxiv.org/abs/2401.02982}, 
}

@book{queryunderstanding2020,
  title     = "Query Understanding for Search Engines",
  editor    = "Yi Chang, Hongbo Deng",
  year      = 2020,
  publisher = "Springer Cham",
  address   = "London"
}

@misc{steinigen2024factfinderenhancing,
      title={Fact Finder -- Enhancing Domain Expertise of Large Language Models by Incorporating Knowledge Graphs}, 
      author={Daniel Steinigen and Roman Teucher and Timm Heine Ruland and Max Rudat and Nicolas Flores-Herr and Peter Fischer and Nikola Milosevic and Christopher Schymura and Angelo Ziletti},
      year={2024},
      eprint={2408.03010},
      archivePrefix={arXiv},
      primaryClass={cs.CL},
      url={https://arxiv.org/abs/2408.03010}, 
}

@misc{wong2023translatingnaturallanguagequeries,
      title={Translating Natural Language Queries to SQL Using the T5 Model}, 
      author={Albert Wong and Lien Pham and Young Lee and Shek Chan and Razel Sadaya and Youry Khmelevsky and Mathias Clement and Florence Wing Yau Cheng and Joe Mahony and Michael Ferri},
      year={2023},
      eprint={2312.12414},
      archivePrefix={arXiv},
      primaryClass={cs.DB},
      url={https://arxiv.org/abs/2312.12414}, 
}

@article{xie2024finbenholisticfinancialbenchmark,
      title={FinBen: A Holistic Financial Benchmark for Large Language Models}, 
      author={Qianqian Xie and Weiguang Han and Zhengyu Chen and Ruoyu Xiang and Xiao Zhang and Yueru He and Mengxi Xiao and Dong Li and Yongfu Dai and Duanyu Feng and Yijing Xu and Haoqiang Kang and Ziyan Kuang and Chenhan Yuan and Kailai Yang and Zheheng Luo and Tianlin Zhang and Zhiwei Liu and Guojun Xiong and Zhiyang Deng and Yuechen Jiang and Zhiyuan Yao and Haohang Li and Yangyang Yu and Gang Hu and Jiajia Huang and Xiao-Yang Liu and Alejandro Lopez-Lira and Benyou Wang and Yanzhao Lai and Hao Wang and Min Peng and Sophia Ananiadou and Jimin Huang},
      year={2024},
      eprint={2402.12659},
      archivePrefix={arXiv},
      journal={arXiv preprint arXiv:2402.12659},
      primaryClass={cs.CL},
      url={https://arxiv.org/abs/2402.12659}, 
}

@inproceedings{xu2024dawn,
    title = "The Dawn After the Dark: An Empirical Study on Factuality Hallucination in Large Language Models",
    author = "Li, Junyi  and
      Chen, Jie  and
      Ren, Ruiyang  and
      Cheng, Xiaoxue  and
      Zhao, Xin  and
      Nie, Jian-Yun  and
      Wen, Ji-Rong",
    editor = "Ku, Lun-Wei  and
      Martins, Andre  and
      Srikumar, Vivek",
    booktitle = "Proceedings of the 62nd Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers)",
    month = aug,
    year = "2024",
    address = "Bangkok, Thailand",
    publisher = "Association for Computational Linguistics",
    url = "https://aclanthology.org/2024.acl-long.586",
    doi = "10.18653/v1/2024.acl-long.586",
    pages = "10879--10899",
    abstract = "In the era of large language models (LLMs), hallucination (the tendency to generate factually incorrect content) poses great challenges to trustworthy and reliable deployment of LLMs in real-world applications. To tackle the hallucination, three key questions should be well studied: how to detect hallucinations (detection), why do LLMs hallucinate (source), and what can be done to mitigate them (mitigation). To address these challenges, this work presents a systematic empirical study on LLM hallucinations, focused on the three aspects of hallucination detection, source and mitigation. Specially, we construct a new hallucination benchmark HaluEval 2.0, and design a simple yet effective detection method for LLM hallucinations. Furthermore, we zoom into the different training or utilization stages of LLMs and extensively analyze the potential factors that lead to the LLM hallucinations. Finally, we implement and examine a series of widely used techniques to mitigate the hallucinations in LLMs. Our work has led to several important findings to understand the hallucination origin and mitigate the hallucinations in LLMs.",
}

@article{xu2024measuring,
title={Measuring and Reducing LLM Hallucination without Gold-Standard Answers},
author={Xu, Jingfeng and Shen, Yikang and Ou, Yanan and Liang, Xiang and Xie, Xing and Jiang, Meng},
journal={arXiv preprint arXiv:2402.10412},
year={2024}
}

