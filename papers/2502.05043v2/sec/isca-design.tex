\section{EcoServe Design}~\label{sec:ecoserve}
\begin{figure*}[t]
\centering     \includegraphics[width=0.8\linewidth]{sec/design_short.pdf} 
\vspace{-1em}
    \caption{EcoServe system diagram: An optimization framework that minimizes operational and embodied carbon across hardware resources through 4R co-designed strategies. Outputs inform scheduling and resource allocation decisions. }\label{fig:ecoserve}
    \vspace{-1em}
\end{figure*}
EcoServe is a carbon-aware framework for serving large language models (LLMs) that jointly optimizes performance, cost, and environmental impact through systematic resource management. The framework operates on four key principles: Reuse, Right Size, Reduce, and Recycle (4R), orchestrating both software and hardware provisioning decisions to minimize the carbon footprint of LLM inference. Figure~\ref{fig:ecoserve} shows the overall EcoServe design architecture.

EcoServe's framework ingests hardware specifications, LLM characteristics, and production traces alongside carbon intensity data to make carbon-aware scheduling decisions. The output such as number of GPUs, CPU cores for each workloads are directly usable for commodity resource scheduler or autoscaler. 

\subsection{Design Principles}
EcoServe implements four strategies for carbon-efficient inference:
\begin{itemize}[leftmargin=*]
\item \textbf{Reuse (\textit{Software Runtime}):} Leverages idle CPU capacity in existing AI inference systems for offline/batch workloads, increasing throughput while reducing resource demand and embodied carbon.
\item \textbf{Right Size (\textit{Software Provisioning}):} Optimizes GPU provisioning across heterogeneous hardware (L4, A6000, A100, H100, etc.) for both online and offline inference, matching resources to workload characteristics.
\item \textbf{Reduce (\textit{Hardware SKU Design}):} Minimizes waste by eliminating underutilized host compute, memory, and storage resources that contribute to high embodied carbon overhead.
\item \textbf{Recycle (\textit{Hardware Provisioning}):} Extends hardware lifetimes asymmetrically across host processing systems and GPUs to balance operational and embodied emissions.
\end{itemize}
These strategies provide a comprehensive solution across software runtime optimization, software provisioning, and hardware provisioning to reduce the carbon footprint of AI inference systems. Below we detail on each strategy, then present how the output of the strategy interacts with the components in real systems.
\input{sec/reuse-revised}
\input{sec/rightsize}
\input{sec/reduce}
\input{sec/recycle}

\subsection{Putting it all together} \label{sec:ILP}
\input{sec/formulation_newer}
