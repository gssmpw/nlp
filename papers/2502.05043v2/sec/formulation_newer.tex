Deploying EcoServe at scale requires balancing multiple competing objectives across carbon, energy, performance, cost, and reliability. The interactions between our optimization strategies present complex trade-offs. For instance, aggressive CPU \textit{Reuse} may conflict with \textit{Reduce} goals, requiring careful capacity planning for CPU cores and memory subsystems.

To address these challenges, we propose a hierarchical approach:

\begin{enumerate}
    \item At the capacity planning phase, we provision a spectrum of server configurations optimized for different carbon-performance trade-offs based on offline profiling. Some servers emphasize \textit{Reuse} with expanded memory subsystems, while others focus on \textit{Reduce} with lean configurations.
    \item At runtime, a carbon-aware load balancer leverages these diverse configurations to optimize workload placement, request scheduling and resource allocation. The load balancer considers:
    \begin{itemize}
        \item Server configuration profiles
        \item Real-time workload characteristics and system load
        \item Dynamic KV cache transfer costs
    \end{itemize}
\end{enumerate}


\subsubsection{Offline profiling and online adaptation}
As shown in Figure~\ref{fig:ecoserve}, EcoServe optimizes LLM deployment by ingesting models, workload traces, SLOs, and hardware specs. It bootstraps initial deployment using CPU/GPU profiling data, then continuously adapts to changing workload patterns. The framework maintains separate resource pools for online, mixed and offline inference, with dynamic CPU offloading for decode phases. Pool sizes automatically adjust via periodically triggered ILP based on workload demands and carbon intensity.%

\subsubsection{ILP for co-design scheduling and allocation}

\textbf{Workload Slicing and Disaggregation}: We represent the workload in different slices within each phase {prompt} and {decode}. Let \( H(i,o) \) represent the request rate for inputs of length \( i \) and outputs of length \( o \). We put workload into histogram bucket \( b \), and further divided into \( S \) slices for fine-grained allocation, where slice factor \( f \) determines the granularity. For a bucket with request rate \( \lambda_b \), each slice \( s \) has rate \( \lambda_s = \lambda_b / f \). For each slice \( s \in S \), we define $\lambda_s$ as the request rate, $\text{Lat}(s,g,l, \phi_s,m_s)$ as expected latency for the prompt or decode phase on GPU \( g \) with allocated resources at load \( l \), required CPU cores \( \phi_s \), and memory \( m_s \). The load imposed by slice \( s \) on GPU type \( g \) is calculated separately for each phase:
\[\footnotesize
\text{Load}_{p/d}(s,g) = \frac{\lambda_s}{\text{MaxTput}_{p/d}(g,\text{size}(s),\text{SLO})}
\]
where \( \text{size}(s) \) represents the input/output length pair of slice \( s \).

\textbf{Performance and Carbon Model}: For each GPU type \( g \in G \), we define \( c_g,  c_\phi, c_m \) as hourly GPU, CPU, memory cost, \( \gamma_g(t) \) as GPU carbon intensity at time \( t \), which is both linear with operational power of the workload times the carbon intensity, and with unit-time embodied carbon of the hardware.
The carbon impact of a workload is the sum of both phases $\text{Carbon}(s,g,l, \phi_s,m_s) = \sum_{k \in \{p,d\}} \gamma_g(t) \cdot \text{Lat}_{k}(s,g,l,\phi_s,m_s)$. 




\textbf{ILP Formulation}: Our goal is to minimize the weighted carbon cost and latency-dependent hardware cost under service level objectives (SLO) based on both TTFT (time to first token) and TPOT (time per output token). Decision variables include GPU assignment matrix \( A \in \{0,1\}^{N \times M} \), GPU count vector \( B \in \mathbb{Z}_{\geq 0}^M \); CPU cores and memory allocated to slice \( s \) as \( \Phi_s, M_s  \).
\label{sec:optimization}
{\footnotesize
\[
\min_{A,B,\Phi,M} (1-\alpha) \Big[\sum_{j=1}^M B_j c_j + \sum_{s=1}^{N} (\Phi_s c_\phi + M_s c_m) \Big] + \alpha \sum_{s=1}^N \sum_{j=1}^M A_{s,j} \text{Carbon}(s,j,l, \Phi_s,M_s)
\]
\vspace{-2.em}
\begin{align*} 
\textbf{s.t.}\quad & \forall s, \quad \sum_{j=1}^M A_{sj} = 1 \\
& \forall j, \quad \sum_{s=1}^N A_{s,j} \cdot (\text{Load}_{p}(s,j) + \text{Load}_{d}(s,j)) \leq B_j \\
& \sum_{s=1}^N \Phi_s \leq \Phi, \quad \sum_{s=1}^N M_s \leq M \, \quad \forall s, \quad \Phi_s \geq \phi_s, \quad M_s \geq m_s \\
& \forall s,j \text{ where } A_{s,j} = 1, \quad \text{Lat}_{p/d}(s,j,l, \Phi_s,M_s) \leq \text{SLO}_{p/d}
\end{align*}
}\vspace{-2em}

where $\alpha \in (0,1)$ is a weighting variable between cost and carbon objectives. Unless otherwise stated, we choose $\alpha = 1$. A smaller value such as $\alpha = 0$ will simply optimize for cost. 
