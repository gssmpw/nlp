\subsubsection{\textbf{Right-sizing GPU Provisioning}} 
\label{sec:rightsize}
While CPU reuse amortized embodied carbon, efficient GPU provisioning is equally critical. EcoServe optimizes GPU allocation by considering three key factors: energy grid carbon intensity, workload characteristics, and hardware diversity. In regions with predominantly renewable energy, CPU reuse is prioritized; in fossil fuel-dependent regions, workloads may shift to more energy-efficient GPUs to minimize overall emissions.

LLM has distinct phases (prompting, decoding) and workload has various characteristics (architecture, sequence length)--this impose different compute and memory requirements. By dynamically matching these requirements to diverse GPU capabilities, EcoServe reduces both operational and embodied carbon while maintaining performance targets.




\textbf{Heterogeneous GPU partitioning.} 
Figure~\ref{fig:relative_carbon} compares the energy (bottom) and embodied carbon efficiency (top) of NVIDIA A100 vs. H100 for Gemma 27B across varying prompt lengths and batch sizes. The analysis separates prompt computation and decode (token generation)~\cite{patel2023splitwise}. A100 is preferable for smaller inputs and batches, while H100 becomes more efficient as they grow. However, for decode, A100 consistently outperforms H100 due to H100's low Model FLOPs Utilization (MFU), Memory Bandwidth Utilization (MBU), and high embodied carbon and energy cost.










We propose a workload-aware GPU provisioning strategy that optimizes resource allocation based on workload characteristics (not only on prompt/decode phases). Instead of provisioning only H100 for prompting (like what was done in Splitwise~\cite{patel2023splitwise}), we tailor GPU allocation per (workload slice, SLO) using offline profiling and performance modeling, distinguishing between workloads to match the available hardware heterogeneity.




\textbf{Exploiting tensor-model parallelism.}
The decision of how many levels of tensor parallelism (TP) is dependent on the target metrics. From latency perspective, sharding tensors across GPUs with high bandwidth communication links enables faster computation and more HBM bandwidth, it's generally favorable for large models to do higher level of TP (up to the tile and wave quantization effect~\cite{nvidia_matmul_guide}). However, the latency comes at a cost with more communication overheads. From carbon perspective, the TP level depends on the ratio between CPU embodied and GPU embodied carbon. Table~\ref{tab:tp} details the desiderata for TP level deployment. In practice, we tailor it to each hardware, model, batch size and SLO. %





\begin{figure}[!t]
\centering
    \begin{subfigure}[b]{\linewidth}
    \includegraphics[width=0.99\linewidth]{plots/Relative_combined.pdf}
        \label{fig:relative_carbon}
    \end{subfigure}
\vspace{-2em}    
\caption{Relative energy and carbon of prompt and decode for Gemma-27b model on NVIDIA H100 compared with A100 GPUs. The results are normalized (higher than 1 means  A100 is preferred). 
We find the optimal GPU varies based on LLM phase, context length, and batch-size, motivating the need for heterogeneous GPU \textit{rightsizing} for different workloads.}
\label{fig:relative_carbon}
\vspace{-1em}
\end{figure}

\begin{table}[h]
\centering \footnotesize
\begin{tabular}{ccc}\hline
\textbf{Metric} & \textbf{Relative Scale} & \textbf{Decision Criteria} \\ 
\hline
Power & $\frac{2n P_{GPU} + P_{CPU}}{n P_{GPU} + P_{CPU}}$ & Consider if $P_{CPU} \gg n P_{GPU}$ \\
Latency & $\approx 0.5 + C_{comm}$ & Favorable when model $>$ memory  \\
Cost/Model & $\approx 1$ & Near-constant when $C_{CPU} \ll n C_{GPU}$ \\
 Carbon & $\frac{CF^{emb}_{CPU} + n CF^{emb}_{GPU}}{CF^{emb}_{CPU}/2 + n CF^{emb}_{GPU}}$ & Better with higher $CF_{CPU}/CF_{GPU}$ \\
Energy & $\approx 0.5$ & Linear improvement with fixed CI \\
\hline 
\end{tabular} \caption{Power, latency, carbon, energy and cost when scaling up model and tensor-model parallelism.}\label{tab:tp}
\vspace{-2em}
\end{table}




 