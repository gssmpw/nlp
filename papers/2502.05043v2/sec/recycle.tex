\subsubsection{\textbf{Recycle: Asymmetric Lifetime for Host and GPUs.}}\label{sec:recycle}
Due to the nature of fast energy efficiency improvements of GPU and slow energy improvement on hosts, the optimal lifetime $T$ is also different, necessitating an asymmetric recycling strategy. 


\textbf{Host lifetime extension.}
Extending the lifespan of DRAM, SSDs, and CPUs helps reduce both embodied and operational carbon. This recycling opportunity arises because memory and storage bandwidth have not scaled proportionally with CPU/GPU performance in recent technology nodes. Our measurements across three server generations show that DRAM and SSD bandwidth are rarely the primary bottlenecks in modern inference serving systems, allowing older components to be reused without compromising performance.



\textbf{Carbon-aware GPU upgrade.} The GPU upgrade strategy depends on 1) inter-generational GPU energy efficiency improvement, 2) the workload and model characteristics, and 3) the upfront embodied carbon cost. Upgrading from V100 to GH200 incurs an upfront embodied carbon cost but significantly improves token processing efficiency per unit of operational carbon. Over time, this reduces the relative carbon footprint, especially in datacenters with lower renewable energy availability. Figure~\ref{fig:cf-relative} shows the optimal GPU usage duration across regions with varying carbon intensity.

\begin{figure}[t]
\centering
     \includegraphics[width=0.99\linewidth]{plots/relative_saving_recycle.pdf} \vspace{-1em}
    \caption{Relative carbon savings with various hardware compared with V100. (Left) prompt heavy workload with Carbon Intensity (CI)  400 gCO2e/KWh, (Middle) prompt heavy workload or  (Right) decode heavy with CI = 50 gCO2e/KWh, The optimal hardware is different. }\label{fig:cf-relative}
    \vspace{-1.05em}
\end{figure}
\begin{figure}[h]
    \centering
    \includegraphics[width=0.8\linewidth]{plots/reliability.pdf}
     \vspace{-1.05em}\caption{Effective age with deployment time.}
    \label{fig:reliability} \vspace{-1.05em}
\end{figure}

\textbf{Reliability implications. } Production data indicates that AI inference workloads typically utilize these host components at low levels. 
 In this section, we study how utilization and lifetime impact reliability. 
1) CPU: To understand the CPU aging over 5 years in a cloud setup, we use a 7nm composite processor model from a major fabrication company. The model faithfully represents CPU transistor logic and is used for design and compliance with reliability goals; details omitted due to confidentiality. In the usual spread of observed voltage levels, we found that even at 20\% utilization over 5 years, CPU aging is only 0.8 years, indicating significant potential for extended use (Figure~\ref{fig:reliability}).

2) DRAM: A study~\cite{Siddiqua2017} from a heavily utilized Cielo supercomputer showed that even at the end of lifetime of 5 years, the DRAM error rate did not increase, indicating a higher lifetime. Other recent studies have shown that DRAM retention rate based errors only meaningfully increase after 10 years of intense usage~\cite{liu2022new}. Given the low utilization of DRAM in the cloud~\cite{kanev2015profiling}, reusing old DRAM and SSDs in CPU-only servers has been proposed by prior work as well~\cite{greensku}, but EcoServe is the first to consider how to evaluate optimal and asymmetric lifetime extension. 
 
3) SSD: Age of an SSD primarily depends on the number of program/erase cycles the SSD has been through~\cite{failure-ssd,FlashFailure,schroeder2016flash,klein2021backblaze}. Therefore, an SSDâ€™s age is modeled as proportional to the number of writes in its lifetime. Even if we assume that the SSD is written all the time that the CPU is active, it will only age by 1 year over a period of 5 years for a 20\% utilization (shown in Figure~\ref{fig:reliability}). 
 

