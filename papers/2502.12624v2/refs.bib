@article{chowdhery2022palm,
  title={Palm: Scaling language modeling with pathways},
  author={Chowdhery, Aakanksha and Narang, Sharan and Devlin, Jacob and Bosma, Maarten and Mishra, Gaurav and Roberts, Adam and Barham, Paul and Chung, Hyung Won and Sutton, Charles and Gehrmann, Sebastian and others},
  journal={arXiv preprint arXiv:2204.02311},
  year={2022}
}

@misc{openai2023gpt4,
      title={GPT-4 Technical Report}, 
      author={OpenAI},
      year={2023},
      eprint={2303.08774},
      archivePrefix={arXiv},
      primaryClass={cs.CL}
}

@article{raffel2020exploring,
  title={Exploring the limits of transfer learning with a unified text-to-text transformer},
  author={Raffel, Colin and Shazeer, Noam and Roberts, Adam and Lee, Katherine and Narang, Sharan and Matena, Michael and Zhou, Yanqi and Li, Wei and Liu, Peter J},
  journal={The Journal of Machine Learning Research},
  volume={21},
  number={1},
  pages={5485--5551},
  year={2020},
  publisher={JMLRORG}
}

@article{sanh2019distilbert,
  title={DistilBERT, a distilled version of BERT: smaller, faster, cheaper and lighter},
  author={Sanh, Victor and Debut, Lysandre and Chaumond, Julien and Wolf, Thomas},
  journal={arXiv preprint arXiv:1910.01108},
  year={2019}
}

@inproceedings{choicompositional,
  title={Compositional Obverter Communication Learning from Raw Visual Input},
  author={Choi, Edward and Lazaridou, Angeliki and de Freitas, Nando},
  booktitle={International Conference on Learning Representations},
  year={2018}
}

@inproceedings{
Ren2020Compositional,
title={Compositional languages emerge in a neural iterated learning model},
author={Yi Ren and Shangmin Guo and Matthieu Labeau and Shay B. Cohen and Simon Kirby},
booktitle={International Conference on Learning Representations},
year={2020},
url={https://openreview.net/forum?id=HkePNpVKPB}
}

@article{bogin2018emergence,
  title={Emergence of communication in an interactive world with consistent speakers},
  author={Bogin, Ben and Geva, Mor and Berant, Jonathan},
  journal={arXiv preprint arXiv:1809.00549},
  year={2018}
}

@inproceedings{mordatch2018emergence,
  title={Emergence of grounded compositional language in multi-agent populations},
  author={Mordatch, Igor and Abbeel, Pieter},
  booktitle={Proceedings of the AAAI conference on artificial intelligence},
  volume={32},
  year={2018}
}

@article{foerster2016learning,
  title={Learning to communicate with deep multi-agent reinforcement learning},
  author={Foerster, Jakob and Assael, Ioannis Alexandros and De Freitas, Nando and Whiteson, Shimon},
  journal={Advances in neural information processing systems},
  volume={29},
  year={2016}
}

@article{jorge2016learning,
  title={Learning to play guess who? and inventing a grounded language as a consequence},
  author={Jorge, Emilio and K{\aa}geb{\"a}ck, Mikael and Johansson, Fredrik D and Gustavsson, Emil},
  journal={arXiv preprint arXiv:1611.03218},
  year={2016}
}

@article{havrylov2017emergence,
  title={Emergence of language with multi-agent games: Learning to communicate with sequences of symbols},
  author={Havrylov, Serhii and Titov, Ivan},
  journal={Advances in neural information processing systems},
  volume={30},
  year={2017}
}

@inproceedings{
lazaridou2017multiagent,
title={Multi-Agent Cooperation and the Emergence of (Natural) Language},
author={Angeliki Lazaridou and Alexander Peysakhovich and Marco Baroni},
booktitle={International Conference on Learning Representations},
year={2017},
url={https://openreview.net/forum?id=Hk8N3Sclg}
}

@inproceedings{ueda2021relationship,
  title={On the Relationship between Zipfâ€™s Law of Abbreviation and Interfering Noise in Emergent Languages},
  author={Ueda, Ryo and Washio, Koki},
  booktitle={Proceedings of the 59th Annual Meeting of the Association for Computational Linguistics and the 11th International Joint Conference on Natural Language Processing: Student Research Workshop},
  pages={60--70},
  year={2021}
}

@article{korbak2020measuring,
  title={Measuring non-trivial compositionality in emergent communication},
  author={Korbak, Tomasz and Zubek, Julian and R{\k{a}}czaszek-Leonardi, Joanna},
  journal={arXiv preprint arXiv:2010.15058},
  year={2020}
}

@inproceedings{galke2022emergent,
  title={Emergent Communication for Understanding Human Language Evolution: What's Missing?},
  author={Galke, Lukas and Ram, Yoav and Raviv, Limor},
  booktitle={Emergent Communication Workshop at ICLR 2022},
  year={2022}
}

@inproceedings{
chaabouni2022emergent,
title={Emergent Communication at Scale},
author={Rahma Chaabouni and Florian Strub and Florent Altch{\'e} and Eugene Tarassov and Corentin Tallec and Elnaz Davoodi and Kory Wallace Mathewson and Olivier Tieleman and Angeliki Lazaridou and Bilal Piot},
booktitle={International Conference on Learning Representations},
year={2022},
url={https://openreview.net/forum?id=AUGBfDIV9rL}
}

@article{chaabouni2019anti,
  title={Anti-efficient encoding in emergent communication},
  author={Chaabouni, Rahma and Kharitonov, Eugene and Dupoux, Emmanuel and Baroni, Marco},
  journal={Advances in Neural Information Processing Systems},
  volume={32},
  year={2019}
}

@article{sukhbaatar2016learning,
  title={Learning multiagent communication with backpropagation},
  author={Sukhbaatar, Sainbayar and Fergus, Rob and others},
  journal={Advances in neural information processing systems},
  volume={29},
  year={2016}
}

@inproceedings{kalinowska2022situated,
  title={Situated communication: A solution to over-communication between artificial agents},
  author={Kalinowska, Aleksandra and Davoodi, Elnaz and Strub, Florian and Mathewson, Kory and Murphey, Todd and Pilarski, Patrick},
  booktitle={Emergent Communication Workshop at ICLR 2022},
  year={2022}
}

@inproceedings{bouchacourt-baroni-2018-agents,
    title = "How agents see things: On visual representations in an emergent language game",
    author = "Bouchacourt, Diane  and
      Baroni, Marco",
    booktitle = "Proceedings of the 2018 Conference on Empirical Methods in Natural Language Processing",
    month = oct # "-" # nov,
    year = "2018",
    address = "Brussels, Belgium",
    publisher = "Association for Computational Linguistics",
    url = "https://aclanthology.org/D18-1119",
    doi = "10.18653/v1/D18-1119",
    pages = "981--985",
    abstract = "There is growing interest in the language developed by agents interacting in emergent-communication settings. Earlier studies have focused on the agents{'} symbol usage, rather than on their representation of visual input. In this paper, we consider the referential games of Lazaridou et al. (2017), and investigate the representations the agents develop during their evolving interaction. We find that the agents establish successful communication by inducing visual representations that almost perfectly align with each other, but, surprisingly, do not capture the conceptual properties of the objects depicted in the input images. We conclude that, if we care about developing language-like communication systems, we must pay more attention to the visual semantics agents associate to the symbols they use.",
}

@inproceedings{rita-etal-2020-lazimpa,
    title = "{``}{L}az{I}mpa{''}: Lazy and Impatient neural agents learn to communicate efficiently",
    author = "Rita, Mathieu  and
      Chaabouni, Rahma  and
      Dupoux, Emmanuel",
    booktitle = "Proceedings of the 24th Conference on Computational Natural Language Learning",
    month = nov,
    year = "2020",
    address = "Online",
    publisher = "Association for Computational Linguistics",
    url = "https://aclanthology.org/2020.conll-1.26",
    doi = "10.18653/v1/2020.conll-1.26",
    pages = "335--343",
    abstract = "Previous work has shown that artificial neural agents naturally develop surprisingly non-efficient codes. This is illustrated by the fact that in a referential game involving a speaker and a listener neural networks optimizing accurate transmission over a discrete channel, the emergent messages fail to achieve an optimal length. Furthermore, frequent messages tend to be longer than infrequent ones, a pattern contrary to the Zipf Law of Abbreviation (ZLA) observed in all natural languages. Here, we show that near-optimal and ZLA-compatible messages can emerge, but only if both the speaker and the listener are modified. We hence introduce a new communication system, {``}LazImpa{''}, where the speaker is made increasingly lazy, i.e., avoids long messages, and the listener impatient, i.e., seeks to guess the intended content as soon as possible.",
}

@inproceedings{ueda-washio-2021-relationship,
    title = "On the Relationship between {Z}ipf{'}s Law of Abbreviation and Interfering Noise in Emergent Languages",
    author = "Ueda, Ryo  and
      Washio, Koki",
    booktitle = "Proceedings of the 59th Annual Meeting of the Association for Computational Linguistics and the 11th International Joint Conference on Natural Language Processing: Student Research Workshop",
    month = aug,
    year = "2021",
    address = "Online",
    publisher = "Association for Computational Linguistics",
    url = "https://aclanthology.org/2021.acl-srw.6",
    doi = "10.18653/v1/2021.acl-srw.6",
    pages = "60--70",
    abstract = "This paper studies whether emergent languages in a signaling game follow Zipf{'}s law of abbreviation (ZLA), especially when the communication ability of agents is limited because of interfering noises. ZLA is a well-known tendency in human languages where the more frequently a word is used, the shorter it will be. Surprisingly, previous work demonstrated that emergent languages do not obey ZLA at all when neural agents play a signaling game. It also reported that a ZLA-like tendency appeared by adding an explicit penalty on word lengths, which can be considered some external factors in reality such as articulatory effort. We hypothesize, on the other hand, that there might be not only such external factors but also some internal factors related to cognitive abilities. We assume that it could be simulated by modeling the effect of noises on the agents{'} environment. In our experimental setup, the hidden states of the LSTM-based speaker and listener were added with Gaussian noise, while the channel was subject to discrete random replacement. Our results suggest that noise on a speaker is one of the factors for ZLA or at least causes emergent languages to approach ZLA, while noise on a listener and a channel is not.",
}

@book{zipf1999psycho,
  title={The psycho-biology of language: An introduction to dynamic philology},
  author={Zipf, George Kingsley},
  volume={21},
  year={1999},
  publisher={Psychology Press}
}

@article{oord2018representation,
  title={Representation learning with contrastive predictive coding},
  author={Oord, Aaron van den and Li, Yazhe and Vinyals, Oriol},
  journal={arXiv preprint arXiv:1807.03748},
  year={2018}
}

@inproceedings{dessi2021interpretable,
 author = {Dessi, Roberto and Kharitonov, Eugene and Marco, Baroni},
 booktitle = {Advances in Neural Information Processing Systems},
 editor = {M. Ranzato and A. Beygelzimer and Y. Dauphin and P.S. Liang and J. Wortman Vaughan},
 pages = {26937--26949},
 publisher = {Curran Associates, Inc.},
 title = {Interpretable agent communication from scratch (with a generic visual processor emerging on the side)},
 url = {https://proceedings.neurips.cc/paper_files/paper/2021/file/e250c59336b505ed411d455abaa30b4d-Paper.pdf},
 volume = {34},
 year = {2021}
}

@article{schulman2017proximal,
  title={Proximal policy optimization algorithms},
  author={Schulman, John and Wolski, Filip and Dhariwal, Prafulla and Radford, Alec and Klimov, Oleg},
  journal={arXiv preprint arXiv:1707.06347},
  year={2017}
}

@inproceedings{vieillard2020leverage,
 author = {Vieillard, Nino and Kozuno, Tadashi and Scherrer, Bruno and Pietquin, Olivier and Munos, Remi and Geist, Matthieu},
 booktitle = {Advances in Neural Information Processing Systems},
 editor = {H. Larochelle and M. Ranzato and R. Hadsell and M.F. Balcan and H. Lin},
 pages = {12163--12174},
 publisher = {Curran Associates, Inc.},
 title = {Leverage the Average: an Analysis of KL Regularization in Reinforcement Learning},
 url = {https://proceedings.neurips.cc/paper_files/paper/2020/file/8e2c381d4dd04f1c55093f22c59c3a08-Paper.pdf},
 volume = {33},
 year = {2020}
}

@inproceedings{he2016deep,
  title={Deep residual learning for image recognition},
  author={He, Kaiming and Zhang, Xiangyu and Ren, Shaoqing and Sun, Jian},
  booktitle={Proceedings of the IEEE conference on computer vision and pattern recognition},
  pages={770--778},
  year={2016}
}

@article{grill2020bootstrap,
  title={Bootstrap your own latent-a new approach to self-supervised learning},
  author={Grill, Jean-Bastien and Strub, Florian and Altch{\'e}, Florent and Tallec, Corentin and Richemond, Pierre and Buchatskaya, Elena and Doersch, Carl and Avila Pires, Bernardo and Guo, Zhaohan and Gheshlaghi Azar, Mohammad and others},
  journal={Advances in neural information processing systems},
  volume={33},
  pages={21271--21284},
  year={2020}
}

@article{ILSVRC15,
Author = {Olga Russakovsky and Jia Deng and Hao Su and Jonathan Krause and Sanjeev Satheesh and Sean Ma and Zhiheng Huang and Andrej Karpathy and Aditya Khosla and Michael Bernstein and Alexander C. Berg and Li Fei-Fei},
Title = {{ImageNet Large Scale Visual Recognition Challenge}},
Year = {2015},
journal   = {International Journal of Computer Vision (IJCV)},
doi = {10.1007/s11263-015-0816-y},
volume={115},
number={3},
pages={211-252}
}

@article{hochreiter1997long,
  title={Long short-term memory},
  author={Hochreiter, Sepp and Schmidhuber, J{\"u}rgen},
  journal={Neural computation},
  volume={9},
  number={8},
  pages={1735--1780},
  year={1997},
  publisher={MIT press}
}

@inproceedings{liu2015faceattributes,
  title = {Deep Learning Face Attributes in the Wild},
  author = {Liu, Ziwei and Luo, Ping and Wang, Xiaogang and Tang, Xiaoou},
  booktitle = {Proceedings of International Conference on Computer Vision (ICCV)},
  month = {December},
  year = {2015} 
}

@article{williams1992simple,
  title={Simple statistical gradient-following algorithms for connectionist reinforcement learning},
  author={Williams, Ronald J},
  journal={Machine learning},
  volume={8},
  pages={229--256},
  year={1992},
  publisher={Springer}
}

@article{rawlik2012stochastic,
  title={On stochastic optimal control and reinforcement learning by approximate inference},
  author={Rawlik, Konrad and Toussaint, Marc and Vijayakumar, Sethu},
  journal={Proceedings of Robotics: Science and Systems VIII},
  year={2012}
}

@inproceedings{chane2021goal,
  title={Goal-conditioned reinforcement learning with imagined subgoals},
  author={Chane-Sane, Elliot and Schmid, Cordelia and Laptev, Ivan},
  booktitle={International Conference on Machine Learning},
  pages={1430--1440},
  year={2021},
  organization={PMLR}
}

@inproceedings{pascanu2013difficulty,
  title={On the difficulty of training recurrent neural networks},
  author={Pascanu, Razvan and Mikolov, Tomas and Bengio, Yoshua},
  booktitle={International conference on machine learning},
  pages={1310--1318},
  year={2013},
  organization={Pmlr}
}

@article{loshchilov2017decoupled,
  title={Decoupled weight decay regularization},
  author={Loshchilov, Ilya and Hutter, Frank},
  journal={arXiv preprint arXiv:1711.05101},
  year={2017}
}

@Article{Lewis1979,
    author={Lewis, David},
    title={Scorekeeping in a language game},
    journal={Journal of Philosophical Logic},
    year={1979},
    month={Jan},
    day={01},
    volume={8},
    number={1},
    pages={339-359},
    issn={1573-0433},
    doi={10.1007/BF00258436},
    url={https://doi.org/10.1007/BF00258436}
}

@inproceedings{chaabouni-etal-2020-compositionality,
    title = "Compositionality and Generalization In Emergent Languages",
    author = "Chaabouni, Rahma  and
      Kharitonov, Eugene  and
      Bouchacourt, Diane  and
      Dupoux, Emmanuel  and
      Baroni, Marco",
    editor = "Jurafsky, Dan  and
      Chai, Joyce  and
      Schluter, Natalie  and
      Tetreault, Joel",
    booktitle = "Proceedings of the 58th Annual Meeting of the Association for Computational Linguistics",
    month = jul,
    year = "2020",
    address = "Online",
    publisher = "Association for Computational Linguistics",
    url = "https://aclanthology.org/2020.acl-main.407",
    doi = "10.18653/v1/2020.acl-main.407",
    pages = "4427--4442",
    abstract = "Natural language allows us to refer to novel composite concepts by combining expressions denoting their parts according to systematic rules, a property known as compositionality. In this paper, we study whether the language emerging in deep multi-agent simulations possesses a similar ability to refer to novel primitive combinations, and whether it accomplishes this feat by strategies akin to human-language compositionality. Equipped with new ways to measure compositionality in emergent languages inspired by disentanglement in representation learning, we establish three main results: First, given sufficiently large input spaces, the emergent language will naturally develop the ability to refer to novel composite concepts. Second, there is no correlation between the degree of compositionality of an emergent language and its ability to generalize. Third, while compositionality is not necessary for generalization, it provides an advantage in terms of language transmission: The more compositional a language is, the more easily it will be picked up by new learners, even when the latter differ in architecture from the original agents. We conclude that compositionality does not arise from simple generalization pressure, but if an emergent language does chance upon it, it will be more likely to survive and thrive.",
}

@article{guo2019emergence,
  title={The emergence of compositional languages for numeric concepts through iterated learning in neural agents},
  author={Guo, Shangmin and Ren, Yi and Havrylov, Serhii and Frank, Stella and Titov, Ivan and Smith, Kenny},
  journal={arXiv preprint arXiv:1910.05291},
  year={2019}
}

@inproceedings{
rita2022on,
title={On the role of population heterogeneity in emergent communication},
author={Mathieu Rita and Florian Strub and Jean-Bastien Grill and Olivier Pietquin and Emmanuel Dupoux},
booktitle={International Conference on Learning Representations},
year={2022},
url={https://openreview.net/forum?id=5Qkd7-bZfI}
}

@article{jang2016categorical,
  title={Categorical reparameterization with gumbel-softmax},
  author={Jang, Eric and Gu, Shixiang and Poole, Ben},
  journal={arXiv preprint arXiv:1611.01144},
  year={2016}
}

@article{DBLP:journals/corr/abs-2010-15896,
  author       = {Kalesha Bullard and
                  Franziska Meier and
                  Douwe Kiela and
                  Joelle Pineau and
                  Jakob N. Foerster},
  title        = {Exploring Zero-Shot Emergent Communication in Embodied Multi-Agent
                  Populations},
  journal      = {CoRR},
  volume       = {abs/2010.15896},
  year         = {2020},
  url          = {https://arxiv.org/abs/2010.15896},
  eprinttype    = {arXiv},
  eprint       = {2010.15896},
  timestamp    = {Tue, 03 Nov 2020 11:44:23 +0100},
  biburl       = {https://dblp.org/rec/journals/corr/abs-2010-15896.bib},
  bibsource    = {dblp computer science bibliography, https://dblp.org}
}

@article{premack1978does,
  title={Does the chimpanzee have a theory of mind?},
  author={Premack, David and Woodruff, Guy},
  journal={Behavioral and brain sciences},
  volume={1},
  number={4},
  pages={515--526},
  year={1978},
  publisher={Cambridge University Press}
}

@inproceedings{NEURIPS2019_b0cf188d,
 author = {Li, Fushan and Bowling, Michael},
 booktitle = {Advances in Neural Information Processing Systems},
 editor = {H. Wallach and H. Larochelle and A. Beygelzimer and F. d\textquotesingle Alch\'{e}-Buc and E. Fox and R. Garnett},
 pages = {},
 publisher = {Curran Associates, Inc.},
 title = {Ease-of-Teaching and Language Structure from Emergent Communication},
 url = {https://proceedings.neurips.cc/paper_files/paper/2019/file/b0cf188d74589db9b23d5d277238a929-Paper.pdf},
 volume = {32},
 year = {2019}
}

@article{tucker2021emergent,
  title={Emergent discrete communication in semantic spaces},
  author={Tucker, Mycal and Li, Huao and Agrawal, Siddharth and Hughes, Dana and Sycara, Katia and Lewis, Michael and Shah, Julie A},
  journal={Advances in Neural Information Processing Systems},
  volume={34},
  pages={10574--10586},
  year={2021}
}

@article{kucinski2021catalytic,
  title={Catalytic role of noise and necessity of inductive biases in the emergence of compositional communication},
  author={Kuci{\'n}ski, {\L}ukasz and Korbak, Tomasz and Ko{\l}odziej, Pawe{\l} and Mi{\l}o{\'s}, Piotr},
  journal={Advances in Neural Information Processing Systems},
  volume={34},
  pages={23075--23088},
  year={2021}
}

@book{zipf2013psycho,
  title={The psycho-biology of language: An introduction to dynamic philology},
  author={Zipf, George Kingsley},
  year={2013},
  publisher={Routledge}
}

@inproceedings{evtimova2018emergent,
  title={Emergent communication in a multi-modal, multi-step referential game},
  author={Evtimova, Katrina and Drozdov, Andrew and Kiela, Douwe and Cho, Kyunghyun},
  booktitle={6th International Conference on Learning Representations, ICLR 2018},
  year={2018}
}

@article{qiu2022emergent,
  title={Emergent graphical conventions in a visual communication game},
  author={Qiu, Shuwen and Xie, Sirui and Fan, Lifeng and Gao, Tao and Joo, Jungseock and Zhu, Song-Chun and Zhu, Yixin},
  journal={Advances in Neural Information Processing Systems},
  volume={35},
  pages={13119--13131},
  year={2022}
}

@inproceedings{graesser2019emergent,
  title={Emergent linguistic phenomena in multi-agent communication games},
  author={Graesser, Laura and Cho, Kyunghyun and Kiela, Douwe},
  booktitle={2019 Conference on Empirical Methods in Natural Language Processing and 9th International Joint Conference on Natural Language Processing, EMNLP-IJCNLP 2019},
  pages={3700--3710},
  year={2019},
  organization={Association for Computational Linguistics}
}

@article{MAVRIDIS201522,
title = {A review of verbal and non-verbal humanâ€“robot interactive communication},
journal = {Robotics and Autonomous Systems},
volume = {63},
pages = {22-35},
year = {2015},
issn = {0921-8890},
doi = {https://doi.org/10.1016/j.robot.2014.09.031},
url = {https://www.sciencedirect.com/science/article/pii/S0921889014002164},
author = {Nikolaos Mavridis},
keywords = {Verbal, Non-verbal, Humanâ€“robot interaction, Humanâ€“robot communication, Survey},
abstract = {In this paper, an overview of humanâ€“robot interactive communication is presented, covering verbal as well as non-verbal aspects. Following a historical introduction, and motivation towards fluid humanâ€“robot communication, ten desiderata are proposed, which provide an organizational axis both of recent as well as of future research on humanâ€“robot communication. Then, the ten desiderata are examined in detail, culminating in a unifying discussion, and a forward-looking conclusion.}
}

@inproceedings{lazaridou2018emergence,
  title={Emergence of Linguistic Communication from Referential Games with Symbolic and Pixel Input},
  author={Lazaridou, Angeliki and Hermann, Karl Moritz and Tuyls, Karl and Clark, Stephen},
  booktitle={6th International Conference on Learning Representations, ICLR 2018-Conference Track Proceedings},
  year={2018}
}

@article{cherry1966human,
  title={On human communication},
  author={Cherry, Colin},
  year={1966},
  publisher={MIT press Cambridge}
}

@book{sutton2018reinforcement,
  title={Reinforcement learning: An introduction},
  author={Sutton, Richard S and Barto, Andrew G},
  year={2018},
  publisher={MIT press}
}

@inproceedings{10.5555/3042573.3042686,
author = {Painter-Wakefield, Christopher and Parr, Ronald},
title = {Greedy algorithms for sparse reinforcement learning},
year = {2012},
isbn = {9781450312851},
publisher = {Omnipress},
address = {Madison, WI, USA},
abstract = {Feature selection and regularization are becoming increasingly prominent tools in the efforts of the reinforcement learning (RL) community to expand the reach and applicability of RL. One approach to the problem of feature selection is to impose a sparsity-inducing form of regularization on the learning method. Recent work on L1 regularization has adapted techniques from the supervised learning literature for use with RL. Another approach that has received renewed attention in the supervised learning community is that of using a simple algorithm that greedily adds new features. Such algorithms have many of the good properties of the L1 regularization methods, while also being extremely efficient and, in some cases, allowing theoretical guarantees on recovery of the true form of a sparse target function from sampled data. This paper considers variants of orthogonal matching pursuit (OMP) applied to reinforcement learning. The resulting algorithms are analyzed and compared experimentally with existing L1 regularized approaches. We demonstrate that perhaps the most natural scenario in which one might hope to achieve sparse recovery fails; however, one variant, OMP-BRM, provides promising theoretical guarantees under certain assumptions on the feature dictionary. Another variant, OMP-TD, empirically outperforms prior methods both in approximation accuracy and efficiency on several benchmark problems.},
booktitle = {Proceedings of the 29th International Coference on International Conference on Machine Learning},
pages = {867â€“874},
numpages = {8},
location = {Edinburgh, Scotland},
series = {ICML'12}
}

@article{nowak1999evolution,
  title={The evolution of language},
  author={Nowak, Martin A and Krakauer, David C},
  journal={Proceedings of the National Academy of Sciences},
  volume={96},
  number={14},
  pages={8028--8033},
  year={1999},
  publisher={National Acad Sciences}
}

@article{wagner2003progress,
  title={Progress in the simulation of emergent communication and language},
  author={Wagner, Kyle and Reggia, James A and Uriagereka, Juan and Wilkinson, Gerald S},
  journal={Adaptive Behavior},
  volume={11},
  number={1},
  pages={37--69},
  year={2003},
  publisher={SAGE Publications}
}

@article{winograd1972understanding,
  title={Understanding natural language},
  author={Winograd, Terry},
  journal={Cognitive psychology},
  volume={3},
  number={1},
  pages={1--191},
  year={1972},
  publisher={Elsevier}
}

@article{dubey2024llama,
  title={The llama 3 herd of models},
  author={Dubey, Abhimanyu and Jauhri, Abhinav and Pandey, Abhinav and Kadian, Abhishek and Al-Dahle, Ahmad and Letman, Aiesha and Mathur, Akhil and Schelten, Alan and Yang, Amy and Fan, Angela and others},
  journal={arXiv preprint arXiv:2407.21783},
  year={2024}
}

@article{dao2024transformers,
  title={Transformers are SSMs: Generalized models and efficient algorithms through structured state space duality},
  author={Dao, Tri and Gu, Albert},
  journal={arXiv preprint arXiv:2405.21060},
  year={2024}
}

@article{jiang2023mistral,
  title={Mistral 7B},
  author={Jiang, Albert Q and Sablayrolles, Alexandre and Mensch, Arthur and Bamford, Chris and Chaplot, Devendra Singh and Casas, Diego de las and Bressand, Florian and Lengyel, Gianna and Lample, Guillaume and Saulnier, Lucile and others},
  journal={arXiv preprint arXiv:2310.06825},
  year={2023}
}

@article{bisk2020experience,
  title={Experience grounds language},
  author={Bisk, Yonatan and Holtzman, Ari and Thomason, Jesse and Andreas, Jacob and Bengio, Yoshua and Chai, Joyce and Lapata, Mirella and Lazaridou, Angeliki and May, Jonathan and Nisnevich, Aleksandr and others},
  journal={arXiv preprint arXiv:2004.10151},
  year={2020}
}

@article{albert2018repair,
  title={Repair: the interface between interaction and cognition},
  author={Albert, Saul and De Ruiter, Jan P},
  journal={Topics in cognitive science},
  volume={10},
  number={2},
  pages={279--313},
  year={2018},
  publisher={Wiley Online Library}
}

@article{schegloff1977preference,
  title={The preference for self-correction in the organization of repair in conversation},
  author={Schegloff, Emanuel A and Jefferson, Gail and Sacks, Harvey},
  journal={Language},
  volume={53},
  number={2},
  pages={361--382},
  year={1977},
  publisher={Linguistic Society of America}
}

@inproceedings{lemon2022conversational,
  title={Conversational grounding in emergent communication--data and divergence},
  author={Lemon, Oliver},
  booktitle={Emergent Communication Workshop at ICLR 2022},
  year={2022}
}

@book{hayashi2013conversational,
  title={Conversational repair and human understanding},
  author={Hayashi, Makoto and Raymond, Geoffrey and Sidnell, Jack},
  number={30},
  year={2013},
  publisher={Cambridge University Press}
}

@inproceedings{nikolaus2023emergent,
  title={Emergent Communication with Conversational Repair},
  author={Nikolaus, Mitja},
  booktitle={The Twelfth International Conference on Learning Representations},
  year={2023}
}

@article{li2019ease,
  title={Ease-of-teaching and language structure from emergent communication},
  author={Li, Fushan and Bowling, Michael},
  journal={Advances in neural information processing systems},
  volume={32},
  year={2019}
}

@inproceedings{konda1999actor,
 author = {Konda, Vijay and Tsitsiklis, John},
 booktitle = {Advances in Neural Information Processing Systems},
 editor = {S. Solla and T. Leen and K. M\"{u}ller},
 pages = {},
 publisher = {MIT Press},
 title = {Actor-Critic Algorithms},
 url = {https://proceedings.neurips.cc/paper_files/paper/1999/file/6449f44a102fde848669bdd9eb6b76fa-Paper.pdf},
 volume = {12},
 year = {1999}
}
