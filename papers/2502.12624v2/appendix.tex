\section{Related Work} \label{app:rw}
One of the core properties of emergent communication is that agents learn a communication protocol on their own, where coordination is needed to solve the underlying task. The study of emergent communication with neural agents started with continuous communication channels during training. \citet{sukhbaatar2016learning} propose a communication channel that shares continuous vectors where each agent receives a combination of all messages broadcasted by all other agents. \citet{jorge2016learning} proposed a recurrent version of the Lewis Game with continuous messages. While such works have good performances, they benefit from having differential communication channels, making it possible for gradients to pass through. More recent works used a formulation of the Lewis Game to study emergent communication, where messages contain discrete tokens but still allow for gradients to pass through the communication channel~\citet{havrylov2017emergence,mordatch2018emergence,guo2019emergence,chaabouni-etal-2020-compositionality,rita2022on}. As such, these methods employ a DIAL paradigm~\citep{foerster2016learning}, allowing for an end-to-end training scheme (across agents) by sampling discrete tokens using straight-through Gumbel-Softmax estimator~\citep{jang2016categorical}. From a language evolution perspective, these approaches do not fully align with the properties of human communication, which is discrete and undifferentiable.

Other approaches, similarly to our work, close the gap to human language by using discrete channels to communicate at training and execution times, meaning gradients do not flow through the channel. In this case, we have a RIAL approach~\citep{foerster2016learning} where each agent perceives others as part of the environment. In most cases, these works rely on Reinforce~\citep{williams1992simple} or on an actor-critic~\citep{konda1999actor} variation to model the Speaker and Listener, where both agents try to maximize the game's reward. Primarily,~\citet{foerster2016learning,lazaridou2017multiagent} developed discrete communication channels composed of only one symbol. The former study designed games where two agents simultaneously have the Speaker and Listener roles to classify images. Nevertheless, the architecture having independent agents performed poorly for the mentioned task, when compared to a DIAL approach. The latter work implemented a simpler version of the Lewis Game where the Listener discriminates between two images. The Speaker also has information about the images that the Listener will receive. \citet{choicompositional} further extended the latter game design creating agents that can handle messages composed of multiple discrete symbols, called the \textit{Obverter} technique. The authors accomplish this by modeling the Speaker to choose the message that maximizes the Speaker's understanding. This assumption roots the theory of mind~\citep{premack1978does}, where the Speaker assumes the Listener's mind and its own are identical. Although this work is an improvement from past works regarding the emulation of human language, there are still severe limitations. For example, the environment considered has only two effective degrees of freedom that must be modeled (shape and color of simple 3D shapes), limiting severely the input diversity.

New extensions to the Obverter focus on studying specific properties of human language, like compositionality or pragmatics. \citet{Ren2020Compositional} developed an iterated learning strategy for the Lewis Game, trying to create highly compositional languages as a consequence of developing a new language protocol by having several distinct learning phases for each agent. From a linguistics perspective, compositionality is crucial since it encourages the expression of complex concepts through simpler ones. Another approach tries to leverage a population of agents to study its effect on simplifying the emerged language~\citep{graesser2019emergent}. The authors use a simple visual task where agents communicate binary messages through a fixed number of rounds to match an image to a caption. The image depicts a simple shape with a specific color. Since each agent observes only part of the image, they must cooperate to solve the task. \citet{NEURIPS2019_b0cf188d} also consider a variation of the Lewis Game with a discrete communication channel. The main objective is to give another perspective on how to evaluate the structure of the resulting communication protocol, giving experimental evidence that compositional languages are easier to teach to new Listeners. This additional external pressure surfaces when the Speaker interacts with new Listeners during training. The proposed experiments continue in the same line of simplicity since inputs are categorical values with two attributes, messages contain only two tokens, and the number of candidates the Listener discriminates is only five objects.

As a succeeding work, \citet{chaabouni2022emergent} proposed scaling several dimensions of the Lewis Game to create a setup closer to simulating human communication. The scaled dimensions are: the number of candidates received by the Listener, the dataset of images used, and the number of learning agents. Scaling such dimensions makes the referential game more complex, promoting the generality and validity of the experimental results. Moreover, this study also suggests that compositionality is not a natural emergent factor of generalization of a language as the environment becomes more complex (e.g., using real-world images). This work can be seen as the initial starting point of our proposed work. In particular, we follow this game setup and extensively make a more challenging environment where we add an RL agent as the Listener that only has information about the game's outcome and not which candidate is the correct guess (as in the original implementation). This modification alone brings advantages to the generalization capability of the communication protocol, where the game accuracy proportionally increases with the number of candidates when testing on unseen images. Additionally, we introduce a stochastic communication channel aiming to increase environmental pressure to study a specific linguistics property, denoted conversational repair mechanisms, see Sec. 1. As a result, the agents seek to create a protocol where information is given redundantly to overcome the noise effect. This type of robust communication is a form of an implicit repair mechanism.

Closely related to our work,~\citet{nikolaus2023emergent} explore explicit conversational repair mechanisms. The method proposed also introduced noise in the communication channel. As a way to study other initiate repair mechanisms, the authors propose adding a feedback loop where information flows from the Listener to the Speaker. Although this is a positive development, several simplifications are present, which increase the dissimilarity to human languages. Not only is the message sent by the Listener a single binary token but this feedback loop is also triggered after every token message the Speaker sends. As such, this communication loop breaks the turn-taking aspect of the human dialogue, and the feedback information received by the Speaker is extremely reduced. Comparing against our work, both studies have their distinct focus since each explores a different conversational repair mechanism. Nonetheless, our experiment is more complicated since the only feedback the Speaker receives is the outcome of the game. As such, the coordination of a communication protocol becomes more challenging, where only by trial and error can the Speaker understand that giving redundant information is advantageous in such noisy conditions.

Other works in the literature also consider noise in the communication channel. \citet{tucker2021emergent,kucinski2021catalytic} apply a DIAL scheme, where the noise is sampled and added in the continuous space before applying the Gumbel-Softmax trick. As such, the problem is simplified by learning a continuous latent space robust to noise. More closely related to our work is the study presented by~\citet{ueda-washio-2021-relationship}. In such work, we are in an emergent discrete communication setting where the authors use a noisy communication channel to test the Zipf's law of abbreviation~\citep{zipf2013psycho}. As such, the goal is to investigate conditions for which common messages become shorter. In this context, the authors propose an adversarial setting to try to deceive the Listener by giving other plausible messages (different from the Speaker's message), which, as training progresses, promotes the usage of shorter messages. Our method differs from this work since we assume the communication channel can suffer external perturbations, mimicking the loss of information. In our case, we apply noise by changing the corresponding token to a pre-defined token called the \textit{unknown} token. Therefore, we are interested in evaluating the communication protocols' robustness to handle different noise levels at test time. Additionally, our referential games are more complex since we use datasets with natural images for discrimination instead of categorical inputs.

\section{Lewis Game Variants} \label{app:lg}

\Cref{fig:emcom-lg} exposes a sketch for the LG (S) and LG (RL). The message sent to the Listener remains fully observable, without any external noise.

\begin{figure}[!t]
    \centering
    \includegraphics[width=0.7\linewidth,keepaspectratio]{figures/lg-new.pdf}
    \caption{Visual Representation of the Lewis Game (LG). In this illustration, the message, \(\vm\), contains three tokens (\(N=3\)).}
    \label{fig:emcom-lg}
\end{figure}

\section{Agent Architecture for LG (S)} \label{app:list-arch}
In this section, we detail the agent architecture proposed by~\citet{chaabouni2022emergent}. We denote this architecture as LG (S), meaning the Listener implements a supervised agent, see \Cref{sec:eval-variants}. We use this game as a frame of reference to benchmark our novel games and agent architectures.

The speaker architecture remains the same as in LG (RL) and NLG (\Cref{sec:meth-arch}). The Listener agent is the only one suffering modifications between games, which take place in the head module. Hence, the base modules that process the message and candidates also remain unchanged between games. We refer to \Cref{sec:meth-arch} for a thorough description of the unchanged modules. The head module of the Supervised agent sends the attention logits through a softmax to convert them into a distribution. The corresponding learning procedure invokes the InfoNCE loss~\cite{oord2018representation} to attract the message representation to the representation of the right candidate while, at the same time, repulsing all other candidates. Furthermore, our LG (S) implementation differs slightly from the original implementation~\citep{chaabouni2022emergent}, where we place the \(\tanh\) activation function before giving the message (\(\vl_m\)) and candidate representations (\(\vl_{j}\)) to the attention mechanism to match the Listener's architecture used in the LG (RL). \cref{fig:compare-lg-ss} illustrates the training procedure for both implementations, where we can see similar data efficiency since both curves jump to a mean reward (accuracy) of 0.8 before the \SI{50}{\kilo{}} steps. Additionally, as the training step increases, both implementations converge to similar values (around \(0.98\)). We also introduce test accuracies in \cref{table:compare-lg-ss}, where both implementations also yield identical results.

\begin{figure*}[!t]
  \begin{minipage}[!t]{0.49\textwidth}
    \centering
    \includegraphics[width=\linewidth,keepaspectratio]{figures/compare_lg_ss_orig_optim.pdf}
    \captionof{figure}{Accuracy during training of two implementations of LG (S), (1) Original~\cite{chaabouni2022emergent} and (2) Ours (\cref{app:list-arch}). The dataset used was ImageNet and \(|\sC|=1024\).}
    \label{fig:compare-lg-ss}
  \end{minipage}
  \hfill
  \begin{minipage}[!t]{0.49\textwidth}
        \linespread{0.6}\selectfont\centering
        \centering
        \captionof{table}{Test accuracy with SD for two implementations of LG (S), (1) Original~\cite{chaabouni2022emergent} and (2) Ours (\cref{app:list-arch}), using ImageNet dataset. During training \(|\sC|=1024\).}
        \label{table:compare-lg-ss}
        \begin{tabular}[t]{llrr}
        \toprule
        Game & Implementation & \multicolumn{2}{c}{\(|\sC|\) (test)} \\[1ex]\cmidrule(r){3-4}
         & & \multicolumn{1}{c}{\(1024\)} & \multicolumn{1}{c}{\(4096\)} \\
        \midrule
        LG {\scriptsize(S)} & Original (1)& 0.96 & 0.88 \\[1.1ex]
        LG {\scriptsize(S)} & Ours (2) & 0.96 & 0.88 \\
        \bottomrule
        \end{tabular}
    \end{minipage}
  \end{figure*}

\section{Architecture Implementation} \label{app:arch}
We now provide concrete network implementations for the Speaker and Listener agents playing LG (S), LG (RL), and NLG. As detailed previously, the Speaker network architecture remains unchanged for all games. Additionally, since the Listener implementation may vary between games, we first describe common submodules used in every architecture. This set of networks encodes the message and candidates, as described in \Cref{app:list-arch}. Afterward, we introduce the Listener's head implementation for each LG variant.

\subsection{Speaker} \label{app:arch-impl-speaker}
The network architecture implemented for the Speaker agent will receive as input an image and output a message composed of \(N\) discrete tokens, each retrieved from the same fixed vocabulary:
%
\begin{itemize}
    \item \(f\): A frozen ResNet-50~\citep{he2016deep} model trained with BYOL algorithm~\citep{grill2020bootstrap} on ImageNet dataset~\citep{ILSVRC15}. The output size of the resulting features is \num{2048}. For more details on the weights, see~\citep{chaabouni2022emergent}.
    \item \(g(\cdot\;;\vtheta)\): A single linear layer to reduce the features' dimensionality from \num{2048} to \num{512} in order to fit in the next layer, an LSTM~\citep{hochreiter1997long}. Additionally, we divide the resulting vector into two equal parts, denoting the initial hidden, \(\vz_{0,\vtheta}\), and cell values ,\(\vc_{0,\vtheta}\), of the LSTM.
    \item \(e(\cdot\;;\vtheta)\): Embedding layer to convert discrete tokens into continuous vectors. The embedding layer receives the discrete token \(m_t\), as an integer, and outputs a feature vector \(e(m_t;\vtheta)\) of size \num{10}. The number of embeddings of \(e(\cdot\;;\vtheta)\) is \(|\sW| + 1\).
    \item \(h(\cdot\;;\vtheta)\): Recurrent layer, implemented as a single LSTM of size \num{256}. The initial hidden and cell states are the output of \(g(\cdot\;;\vtheta)\). Additionally, \(h\) processes the continuous version of each message token \(e(m_{t-1};\vtheta)\) iteratively. Furthermore, the computed hidden value \(\vz_{t,\vtheta}\), in each iteration \(t\), will be the input to the value and critics heads, \(\pi_S(\cdot|\vz_{t,\vtheta})\) and \(v(\cdot\;;\vtheta)\), respectively.
    \item \(\pi_S(\cdot|\vz_{t,\vtheta};\vtheta)\): For a given iteration \(t\), the actor policy head uses a linear layer (output size of \(|\sW|\)) followed by the \(\text{softmax}\) function to convert the hidden state \(\vz_{t,\vtheta}\) into a categorical distribution \(\text{Cat}(|\sW|,\pi_S(\cdot|\vz_{t,\vtheta};\vtheta))\), where each value indicates the probability of choosing each token as the next one to add to the message, \(m_{t+1}\).
    \item \(v(\cdot\;;\vtheta)\): Critic value head to estimate the expected cumulative reward, in this case, the reward received for the game \(R(\vx,\hat{\vx})\), by implementing a linear layer with an output size of \num{1}.
\end{itemize}

\subsection{Listener}
The Listener architecture has two input entries to acquire the Speaker's message and the set of candidate images. This architecture suffers internal modifications to adapt to the specifications of the LG variant to play. Moreover, it is also possible to create different Listener architectures to solve the same game as we show in~\cref{sec:eval-variants}, where we have S and RL Listener architectures to play the LG. Hence, we first detail the implementation of common modules used in every Listener architecture. These sub-modules are the message and candidates' sub-modules used to extract information from the message and candidates, respectively. Afterward, we detail the sub-module specific to each different Listener, labeled as the \emph{Listener's head}.

\subsubsection{Common sub-modules}
We describe every network implementation contained in the common Listener's sub-modules (message and candidates sub-modules):
%
\begin{itemize}
    \item \(f\) \emph{(candidates)}: A frozen ResNet-50 trained with BYOL on the ImageNet dataset, where \(f\) converts the image into a vector with \num{2048} features. \(f\) is the same network used in the Speaker architecture, see~\cref{app:arch-impl-speaker}.
    \item \(c(\cdot\;;\vphi)\)  \emph{(candidates)}: This single linear layer, followed by the \(\tanh\) function, receives each candidate's feature vector, \(f(\vx_i)\), and reduces its dimensionality from \num{2048} to \num{256}. We denote the output for each candidate \(i\) as \(\vl_{i}=c(f(\vx_i);\vphi)\). 
    \item \(e(\cdot\;;\vphi)\) \emph{(message)}: A single embedding layer to convert a discrete message token \(m_t\) into a continuous vector of size \num{10}. The number of embeddings of \(e(\cdot\;;\vphi)\) is \(|\sW|\).
    \item \(h(\cdot\;;\vphi)\) \emph{(message)}: An LSTM layer with a size of \num{512}, receiving the continuous featuers of each message token \(e(m_t;\vphi)\) iteratively. The initial hidden \(\vz_{0,\vphi}\) and cell states \(\vc_{0,\vphi}\) are both \(\vzero\).
    \item \(g(\cdot\;;\vphi)\)  \emph{(message)}: Linear layer followed by the \(\tanh\) function to reduce the dimensionality of the last hidden state value \(\vz_{N,\phi}\) from a vector size \num{512} to \num{256}, denoted as \(\vl_\text{m}\). 
\end{itemize}

\subsubsection{LG (S)} \label{app:arch-list-ss}
Upon the message and candidate sub-modules outputting the respective hidden values, \(\vl_\text{m}\) and \(\vl_{j}\), the Listener architecture computes a single value score between \(\vl_\text{m}\) and each \(\vl_{j}\), using the cosine similarity function, \(\text{cos\_sim}=\vl_\text{m}\cdot \vl_{j} / (\|\vl_\text{m}\| \|\vl_{j}\|)\). Following this step, the similarity outputs pass through a \(\text{softmax}\) function, yielding a categorical distribution suitable to apply InfoNCE loss~\citep{oord2018representation}.

\subsubsection{LG (RL) \& NLG}
The Listener's head architecture for both LG (RL) and NLG has the same structure:
%
\begin{itemize}
    \item \(\vs\): Non-parametrizable function to combine information coming from the received message and candidate set. The attention mechanism \(s\) happens through a dot product between \(\vl_\text{m}\) and each \(\vl_{j}\), defined as \(\vs=\left[\begin{matrix}\vl_\text{m}\cdot \vl_{1} & \ldots & \vl_\text{m}\cdot \vl_{|\sC|}\end{matrix}\right]^T\).
    \item \(\pi_L(\cdot|\vs)\): \(\pi_L\) corresponds to the Listener's actor head and contains the \(\text{softmax}\) function to convert the logits \(\vs\) into a categorical distribution \(\text{Cat}(|\sC|,\pi_L(\cdot|\vs))\). Each distribution value maps the probability of choosing the candidate with the same index \(\pi_L(j|\vs_\phi))\), where \(j\in\{1,\ldots,|\sC|\}\).
    \item \(v(\cdot\;;\vphi)\): The Listener's critic head \(v\) receives the attention logits \(\vs\) and passes them through a multi-layer perceptron (MLP), outputting a one-dimension value corresponding to a prediction of the reward \(R(\vx,\hat{\vx})\) for the associated game. The hidden and output sizes of the MLP are \((\max(|\sC|/4,4),\allowbreak \max(|\sC| / 16,\allowbreak2),\allowbreak1)\), and the activation function used between layers is the \(\text{ReLU}\) function.
\end{itemize}

\subsection{Hyperparameters}
In this subsection, we detail the hyperparameters used to instantiate all LG experiments, exposed in \Cref{table:common-hyperparams,table:nlg-mrilg-hyperparams}.

\begin{table}[t]
\centering
\caption{Common hyperparameters for all games: LG (S), LG (RL), and NLG. The values of hyperparameters described as a set, \(\{\cdot\}\), means we run experiments with each value in the set.}
\label{table:common-hyperparams}
\begin{tabular}{lc}
\toprule
hyperparameter & value\\
\midrule
training steps & \SI{750}{\kilo{}} \\
\(|\sC|\) & \(\{\SI{16}{},\SI{64}{},\SI{256}{},\SI{1024}{}\}\) \\
\(|\mathcal{W}|\) & \SI{20}{} \\
\(T\) & \SI{10}{} \\
\(\alpha_{S,A}\) & 1 \\
\(\alpha_{S,C}\) & 1 \\
\(\alpha_{S,\mathcal{H}}\) & \SI{1e-4}{} \\
\(\alpha_{S,A}\) & \SI{0.5}{} \\
\(\alpha_{L,A}\) & 1 \\
\(\alpha_{L,C}\) & \SI{1e-3}{} \\
\(\alpha_{L,\mathcal{H}}\) & \SI{1e-4}{} \\
Speaker's optim & adam \\
Listener's optim & adam \\
Speaker's optim lr & \SI{1e-4}{} \\
Listener's optim lr & \SI{5e-5}{} \\
\(\eta\) & \SI{0.99}{}\\
\(\gamma\) & \SI{0.99}{}\\
\bottomrule
\end{tabular}
\end{table}

\begin{table}[t]
\centering
\caption{Hyperparameters exclusive to NLG. The values of hyperparameters described as a set, \(\{\cdot\}\), means we run experiments with each value in the set.}
\label{table:nlg-mrilg-hyperparams}
\begin{tabular}{lc}
\toprule
hyperparameter & value\\
\midrule
\(\lambda_\text{init}\) & \SI{0}{} \\
\(\lambda\) & \(\{\SI{0.25}{},\SI{0.5}{},\SI{0.75}{}\}\) \\
noise schedule & linear \\
noise schedule steps & \SI{300}{\kilo{}} \\
\bottomrule
\end{tabular}
\end{table}

\section{Training Details}
Following the concise introduction about the learning strategy of both agents (\cref{sec:meth-learn}), we now add complementary information detailing the loss functions used. We also propose an ablation study regarding essential architectural and training procedure choices given at the end of \cref{sec:meth-learn}.

\subsection{Learning Strategy} \label{app:learn-strat}
We model both agents as RL agents for the novel LG variants proposed in this study, LG (RL) and NLG. We also follow a RIAL procedure~\citep{foerster2016learning}, where each agent perceives others as part of the environment, meaning no gradients flow between agents, allowing us to completely isolate the loss function of each agent. We will detail, first, the Speaker's loss function and, secondly, the loss function used by the Listener agent.

\subsubsection{Speaker}
The Speaker's objective will converge on creating messages \(\vm=\left(m_t\right)_{t=1}^N\) in such a way as to facilitate the mapping between the generated message and the right candidate (\(\hat{\vx}=\vx\)), chosen by the Listener. The Speaker, parametrized by \(\theta\), generates messages iteratively, where the following message token results from sampling its actor's stochastic policy, \(m_t\sim\pi_S(\cdot|\vx,(m_{t'})_{t'=1}^{t-1})\), conditioned on the target input image \(\vx\) and previously sampled tokens \((m_{t'})_{t'=1}^{t-1}\). As a result, the Speaker will attempt to find the best policy to maximize the expected reward:
%
\begin{equation*}
    J\left(\vtheta\right) = \mathbb{E}_{\vx\sim\mathcal{U}\left(\sX\right)}\left[\mathbb{E}_{\pi_S(\cdot|\vx)}\left[R\left(\vx,\hat{\vx}\right)\right]\right],
\end{equation*}
%
where \(\mathbb{E}_{\vx\sim\mathcal{U}\left(\sX\right)}\) considers the expectation for \(\vx\) over the dataset \(\sX\). Since \(\mathcal{U}(\sX)\) is a discrete uniform distribution, each possible image \(\vx\) has the same likelihood of being sampled. Additionally, \(\mathbb{E}_{\pi_S(\cdot|\vx)}\) is over all possible outputs generated by \(\pi_S\), in this case, all sequences of messages \(\vm\), for each \(\vx\).

For a given target image \(\vx\), we define the expected reward as \(V^{\pi_S}(\vx,\hat{\vx})=\mathbb{E}_{\pi_S(\cdot|\vx)}\left[R\left(\vx,\hat{\vx}\right)\right]\). Using the policy gradient theorem, we can derive the gradient for the policy \(\pi_S\) as:
%
\begin{multline}
    \partial_\vtheta V^{\pi_S}\left(\vx,\hat{\vx}\right) = \mathbb{E}_{\pi_S(\cdot|\vx)}\Bigg[\\
    \sum_{t=1}^{N}R\left(\vx,\hat{\vx}\right)\partial_\vtheta\log{\pi_S\left(m_t|\vx,\left(m_{t'}\right)_{t'=1}^{t-1}\right)}\Bigg]. \label{eq:pol-grad-speaker-no-baseline}
\end{multline}
%
As we can see in \Eqref{eq:pol-grad-speaker-no-baseline}, we set the discounted cumulative reward as \(R(\vx,\hat{\vx})\). This is true when the Speaker's discount factor, \(\gamma_S\), is set to \(1\), which is our case. This is a valid assumption since messages have a fixed length where only the final Speaker's state (a message with \(N\) tokens) has an implication in the game result, given that it is when the message is sent to the Listener. As such, the Speaker only wants to maximize this final reward without considering delay through time. Moreover, to reduce the overall variance, we also subtract a baseline to \(R(\vx,\hat{\vx})\). In this case, the policy gradient becomes:
%
\begin{multline}
    \partial_\vtheta V^{\pi_S}\left(\vx,\hat{\vx}\right) =    \mathbb{E}_{\pi_S(\cdot|\vx)}\Bigg[\\
    \sum_{t=1}^{N}\left(R\left(\vx,\hat{\vx}\right)-V_{t-1}^{\pi_S}\left(\vx,\hat{\vx}\right)\right)\partial_\vtheta\log{\pi_S\left(m_t|\vx,\left(m_{t'}\right)_{t'=1}^{t-1}\right)}\Bigg], \label{eq:pol-grad-speaker}
\end{multline}
%
where \(V_{t-1}^{\pi_S}(\vx,\hat{\vx})=\mathbb{E}_{\pi_S(\cdot|\vx)}[R(\vx,\hat{\vx})|(m_{t'})_{t'=1}^{t-1}]\) contains the value currently conditioned on information gathered until timestep \(t-1\).

To approximate \eqref{eq:pol-grad-speaker}, the Speaker's learning strategy will minimize the following two losses. First, the critic's head \(v(\vz_{t,\vtheta};\vtheta)\) will adjust towards matching \(V_{t-1}^{\pi_S}\left(\vx,\hat{\vx}\right)\) by minimizing the critic loss \(L_\text{S,C}\left(\vtheta\right)\):
%
\begin{equation*}
    L_\text{S,C}\left(\vtheta\right) = \frac{1}{|\sX'|}\sum_{x\in\sX'}\sum_{t=1}^N\left(R\left(\vx,\hat{\vx}\right)-v\left(\vz_{t,\vtheta};\vtheta\right)\right)^2,
\end{equation*}
%
where \(\sX'\subset\sX\) is a random batch of the original dataset \(\sX\).

Secondly, the actor's policy loss \(L_\text{S,A}\left(\vtheta\right)\) will minimize the negative of the expected total reward:
%\vx,\hat{\vx}^{(i)};
%
\begin{multline*}
    L_\text{S,A}\left(\vtheta\right)=-\frac{1}{|\sX'|}\sum_{x\in\sX'}\sum_{t=1}^N\big[\\
    \text{sg}\left(R\left(\vx,\hat{\vx}\right)-v\left(\vz_{t,\vtheta};\vtheta\right)\right)\log{\pi_S\left(m_t|\vz_{t,\vtheta}\right)}\big],
\end{multline*}
%
where \(\text{sg}\) is the \emph{stop-gradient} function. Additionally, the Speaker's actor head \(\pi_S(\cdot|\vz_{t,\vtheta})\) estimates \(\pi_S(\cdot|\vx,(m_{t'})_{t'=1}^{t-1})\), which is a valid approximation since the conditioned variable, \(\vz_{t,\vtheta}\), jointly encodes information about the target image \(\vx\) and the tokens already present in the message \((m_{t'})_{t'=1}^{t-1}\), due to its recurrent nature.

Furthermore, as detailed in \cref{sec:meth-learn}, the Speaker adds two additional loss terms to optimize together with \eqref{eq:pol-grad-speaker}. One such supplementary loss term is the KL divergence, \(L_{\text{S,KL}}(\vtheta)\), which aims to minimize the relative entropy between the actor's policy \(\pi_S\) and a target version of this policy \(\overline{\pi}_S\), computed as an EMA, \(\overline{\vtheta}\leftarrow (1-\eta)\vtheta+\eta\overline{\vtheta}\), where \(\eta\) is a constant. As shown in previous studies~\citep{schulman2017proximal,vieillard2020leverage}, using an additional KL loss term helps achieve better performance and, especially, stabilizes training which considerably helps in our case. We define \(L_{\text{S,KL}}(\vtheta)\) as:
% \vx;
\begin{multline*}
    L_{\text{S,KL}}\left(\vtheta\right) = \frac{1}{|\sX'|}\sum_{x\in\sX'}\sum_{t=1}^{N} \mathbb{E}_{m\sim\pi_S\left(\cdot|\vz_{t,\vtheta}\right)}\vast[\\
    \pi_S\left(m|\vz_{t,\vtheta}\right)\log\frac{\pi_S\left(m|\vz_{t,\vtheta}\right)}{\overline{\pi}_S\left(m|\vz_{t,\overline{\vtheta}}\right)}\vast].
\end{multline*}
%
The other additional loss term is an entropy loss term \(L_{\text{S},\mathcal{H}}(\vtheta)\), where the objective passes to increase the actor's policy entropy to incentivize the exploration of new actions (tokens to create the message). Given \(\pi_S\), the entropy loss term minimizes the following negative sampled version of the entropy:
%
\begin{multline*}
    L_{\text{S},\mathcal{H}}\left(\vtheta\right) = \frac{1}{|\sX'|}\sum_{x\in\sX'}\sum_{t=1}^N \mathbb{E}_{m\sim\pi_S\left(\cdot|\vz_{t,\vtheta}\right)}\big[\\
    \pi_S\left(m|\vz_{t,\vtheta}\right)\log{\pi_S\left(m|\vz_{t,\vtheta}\right)}\big].
\end{multline*}

\subsubsection{Listener}
The Listener's policy, \(\pi_L\), aims at detecting the candidate \(\sC_j\) that corresponds to the target image \(\vx\) received by the Speaker. This reasoning process is also conditioned on the Speaker's message \(\vm\) to guide the discrimination of the candidates to the right one, see \Cref{sec:meth-nlg}. As such, we define the Listener's objective as the maximization of the expected reward of the game:
%Looking at the strategy used for the Listener agent, the policy \(\pi_L\) needs to reason with information from the message received, \(\vm\), and the candidates' set \(\sC\subset\sX\) in order to guess which candidate was also the input given to the Speaker. As a result, the Listener's goal passes to maximize the expected reward of the game:
%
\begin{multline}
    J\left(\vphi\right) = \mathbb{E}_{\vx\sim\mathcal{U}\left(\sX\right),\sC\sim\mathcal{U}\left(\sX\right),\vm\sim\pi_S(\cdot|\vx)}\big[\\
    \mathbb{E}_{\hat{\vx}\sim\pi_L(\cdot|\vm,\sC)}\left[R\left(\vx,\hat{\vx}\right)\right]\big],
\label{eq:list_exp_rwd}
\end{multline}
%
where the expectation \(\mathbb{E}_{\vx\sim\mathcal{U}(\sX),\sC\sim\mathcal{U}\left(\sX\right),\mM^{(N-1)}\sim\pi_S(\cdot|\vx)}\) considers the space containing all possible combinations of the target image \(\vx\) sampled from a discrete uniform distribution over the training dataset \(\mathcal{U}(\sX)\), set of candidates \(\sC\) also sampled independently from the same distribution \(\mathcal{U}(\sX)\), and all possible messages \(\vm\) generated by the Speaker's policy \(\pi_S\). Note that \(\sC\sim\mathcal{U}(\sX)\) is an abuse of notation (used for readability), where in reality, we have \(\sC'_1,\ldots,\sC'_{|\sC|-1}\stackrel{\text{i.i.d.}}{\sim}\mathcal{U}(\sX)\) and \(\sC=\{\vx\}\cup\sC'\), to make sure the target image \(\vx\) is also in \(\sC\). The second expectation \(\mathbb{E}_{\hat{\vx}\sim\pi_L(\cdot|\vm,\sC)}\) of \eqref{eq:list_exp_rwd} is over all possible actions for the listener's policy when fixing the target image \(\vx\), candidates \(\sC\), and message \(\vm\). We derive this expectation using policy gradient method to get:
%
\begin{alignat*}{2}
    \partial_\vphi V^{\pi_L}\left(\vx,\vm,\sC\right) = \mathbb{E}_{\pi_L}\left[ R\left(\vx,\hat{\vx}\right)\partial_\vphi\log{\left(\pi_L\left(\hat{\vx}|\vm,\sC\right)\right)}\right].
\end{alignat*}
%

Similarly to the Speaker, the main objective of the Listener's training encompasses minimizing a critic (value) loss \(L_\text{L,C}(\vphi)\) and an actor's policy loss term \(L_\text{L,A}(\vphi)\). Regarding the value loss term \(L_\text{L,C}(\vphi)\), the function takes the form:
%
\begin{equation*}
    L_\text{L,C}(\vphi) = \frac{1}{|\sX'|}\sum_{x\in\sX'}\left(R\left(\vx,\hat{\vx}\right)-v\left(\vs;\vphi\right)\right)^2.
\end{equation*}
%
Additionally, to derive the original policy \(\pi_L(\cdot|\vm,\sC)\), the Listener's actor head \(\pi_L(\cdot|\vs)\) targets the minimization of the negative of the expected rewards:
% \hat{\vx},\vx,I;
\begin{align*}
    L_\text{L,A}(\vphi) =
    -\frac{1}{|\sX'|}\sum_{x\in\sX'}\text{sg}\left(R\left(\vx,\hat{\vx}\right)-v\left(\vs;\phi\right)\right)\log\pi_L\left(\hat{\vx}|\vs\right),
\end{align*}
%
where \(\vs\) encodes information from the message sent by the Speaker and the candidates' set, see \Cref{sec:meth-arch}. At last, we also add an entropy loss term \(L_{\text{L},\mathcal{H}}(\vphi)\) to the Listener's loss to prevent early stagnation to specific actions:
% \hat{\vx},I;
\begin{align*}
    L_{\text{L},\mathcal{H}}\left(\vphi\right) = \frac{1}{|\sX'|}\sum_{x\in\sX'}\mathbb{E}_{\hat{\vx}\sim\pi_L\left(\cdot|\vs\right)}\left[\pi_L\left(\hat{\vx}|\vs\right)\log{\pi_L\left(\hat{\vx}|\vs\right)}\right].
\end{align*}

\subsection{Datasets} \label{app:data}
The datasets used to evaluate the proposed games are the ImageNet~\citep{ILSVRC15} and CelebA~\citep{liu2015faceattributes}. We use the datasets provided by \citet{chaabouni2022emergent}, where the authors preprocess the data, as we will explain next. The ImageNet dataset contains mainly RGB images of objects and animals clustered over 1000 labels. The training of the LG and ETL experiments uses 99\% of the original training data of ImageNet and the official validation set as the test set. The CelebA dataset contains RGB images of celebrity faces denoting 10177 different identities. This dataset also describes binary attributes for each image, like smiling, hair color, glasses, etc. Additionally, a new dataset split is performed to ensure there is overlapping for all identities between all sets (train, validation, and test), see \citet{chaabouni2022emergent}.

Finally, images from both datasets are down-sampled using bicubic sampling, forcing the shorted side to have 256 pixels, and then a center crop of 224x224 pixels is applied. The channel axis also suffers normalization using mean and SD obtained from the ImageNet train set~\citep{he2016deep}. Afterward, a ResNet architecture pre-trained with BYOL \citep{grill2020bootstrap} on ImageNet outputs the representation used in all experiments, see \Cref{app:arch-impl-speaker}.

\subsection{Computational Resources}
All experiments present in this work are computationally tractable with standard GPU hardware. Each experiment takes, at most, \SI{7}{\hour} to run on a single GPU (NVIDIA GeForce RTX 3090), with a peak of GPU memory of less than \SI{12}{\gibi\byte}.

\subsection{Scheduling Noise} \label{app:noise-schedule}
We analyze different approaches to schedule the addition of noise to the communication channel for NLG. Our objective resides on understanding if there is an impact on performance if the noise is introduced gradually instead of fixing it at the established value from the start of training. As such, we introduce two ways to schedule the noise threshold during training:
%
\begin{enumerate*}
  \item the noise value is fixed at its final value \(\lambda\) during the entire training procedure;
  \item a scheduler linearly scales the noise from \(0\) to \(\lambda\) during the first \(40\%\) of the training steps.
\end{enumerate*}
%
\Cref{fig:compare-mrilg-noise-sched} illustrates both experiments, (1) and (2), when fixing \(\lambda=0.5\). We observe that by gradually scheduling the noise, instead of fixing it at the specified end value, the mean reward leaves the zone near \(0\) considerably earlier, meaning the agents have an easier time starting coordinating on a shared communication protocol, see \Cref{fig:compare-mrilg-noise-sched-rwd}. Having the noise increasing gradually allows for the pair of agents to first focus on creating a common language and, only after, slowly adjust to the noise in the message. Note that introducing noise makes the environment highly stochastic since the noise introduced will mask random tokens of the message. Additionally, the Listener is the only one capable of perceiving this modification, which makes the coordination between the pair more challenging. \cref{fig:compare-mrilg-noise-sched-ent} also corroborates our analysis, where in (1), the Speaker's entropy only starts decreasing after \SI{120}{\kilo{}} steps, as opposed to (2), where the same happens just after \SI{50}{\kilo{}} steps. As such, a communication protocol starts to emerge much sooner in (2), where the Speaker begins conveying more stable and regular messages. Nonetheless and as we observed in \Cref{fig:compare-mrilg-noise-sched-rwd}, scheduling the noise threshold does not affect the final mean reward obtained, but only helps with sample efficiency.

\begin{figure*}[!t]
    \begin{center}
    \begin{subfigure}{.49\textwidth}
      \centering
      \centerline{\includegraphics[width=\linewidth]{figures/new_compare_noise_schedule_rwd.pdf}}
      \caption{}
      \label{fig:compare-mrilg-noise-sched-rwd}
    \end{subfigure}
    \hfill
    \begin{subfigure}{.49\textwidth}
      \centering
      \centerline{\includegraphics[width=\linewidth]{figures/new_compare_noise_schedule_ent.pdf}}
      \caption{}
      \label{fig:compare-mrilg-noise-sched-ent}
    \end{subfigure}
    \end{center}
    \caption{Mean reward (\subref{fig:compare-mrilg-noise-sched-rwd}) and the mean value for the Speaker's policy entropy (\subref{fig:compare-mrilg-noise-sched-ent}) on the ImageNet dataset of different implementations of NLG (RL), with \(|\sC|=1024\). The LG (RL) implementations differ on how to schedule the noise \(\lambda\) value during training: (1) \(\lambda\) remains constant at the end value \(0.5\); (2) \(\lambda\) linearly scales from \(0\) to \(0.5\) during the first \SI{300}{\kilo{}} steps, staying at this value afterward.}
    \label{fig:compare-mrilg-noise-sched}
    \vspace{-2ex}
\end{figure*}

\begin{comment}
\subsection{Compare Different Listener Head Configurations} \label{app:list-head-config}

\begin{figure*}[!t]
    \begin{center}
    \begin{subfigure}{.49\textwidth}
      \centering
      %\centerline{\includegraphics[width=\linewidth]{figures/compare_optim_details_reward_new.pdf}}
      \centerline{\includegraphics[width=\linewidth]{figures/compare_list_arch_nlg_reward}}
      \caption{}
      \label{fig:compare-lg-optim-list-arch-rwd}
    \end{subfigure}
    \hfill
    \begin{subfigure}{.49\textwidth}
      \centering
      \centerline{\includegraphics[width=\linewidth]{figures/compare_list_arch_nlg_entropy}}
      \caption{}
      \label{fig:compare-lg-optim-list-arch-ent}
    \end{subfigure}
    \end{center}
    \caption{Mean reward (\subref{fig:compare-mrilg-optim-rwd}) and the mean value for the Speaker's policy entropy (\subref{fig:compare-mrilg-optim-ent}) on the ImageNet dataset of different implementations of LG (RL), with \(\lambda=0.5\), \(\nu=-0.5\), and \(|\sC|=1024\). The LG (RL) implementations differ in the architecture used for the value head \(v(\cdot\;;\phi)\): (1) \(v(\cdot\;;\phi)\) is not implemented; (2) \(v(\cdot\;;\phi)\) is a single linear layer; (3) \(v(\cdot\;;\phi)\) is an MLP (w/ 2 hidden layers).}
    \label{fig:compare-mrilg-optim}
    \vspace{-2ex}
\end{figure*}

At the end of the \cref{sec:meth-learn}, we argued that the Listener must have a critic head complementary to its actor's head. The Listener requires this design choice to have sufficient conditions to learn and understand how to evaluate actions to further adjust its policy on mapping messages to the correct candidates (correct actions) accordingly. Only when the Listener has such capabilities can the pair of agents can coordinate on developing a communication protocol efficiently. 

We support such a claim in \cref{fig:compare-mrilg-optim}, where \cref{fig:compare-mrilg-optim-rwd} shows the game's mean reward obtained by the agents during training, and the Speaker's entropy progress during training appears in \cref{fig:compare-mrilg-optim-ent}. From \cref{fig:compare-mrilg-optim-rwd}, we observe the agents cannot learn how to communicate when we implement the Listener without a critic head (1), where the reward is the lowest possible until the end of the training phase. In this case, we also see that the Seaker's entropy remains high and constant throughout learning (\cref{fig:compare-mrilg-optim-ent}), indicating that the pair of agents never agree on a communication protocol.

When the Listener architecture includes a critic head (2), there is a considerable performance boost in the final reward obtained by both agents. The agents gradually learn how to coordinate, and a common language emerges starting from the 50k step mark. Validating this result, we observe that the speaker entropy starts decreasing around the same time. As such, since early training, the Speaker starts creating more systematic messages, further facilitating the Listerner's job of mapping messages to the positive candidates.
\end{comment}

\section{Evaluation's Additional Results} \label{app:add-results}

In this section, we present additional results to study and compare changes in performance as the number of candidates increases during training, as well as the impact of the noise level in NLG. For additional results regarding the evaluation in \Cref{sec:eval-comm}, please refer to \Cref{fig:compare-lg-imagenet-all} for the results obtained during the test phase for all game variants using the ImageNet dataset~\citep{ILSVRC15} and fixing different noise levels. The same results for the CelebA dataset~\citep{liu2015faceattributes} appear in \Cref{fig:compare-lg-celeba-all}. Regarding \Cref{sec:eval-mess-struct}, we present the results obtained in all experiments in \Cref{fig:compare-lg-mess-imagenet-all,fig:compare-lg-mess-celeba-all} as a function of the number of masked tokens, for the ImageNet and CelebA datasets, respectively. Additionally, we showcase particular results when masking a single token, aiming to show the difference in performance for the LG (S) and LG (RL) variants when the first message token is masked vs.\ any other token. \Cref{fig:compare-lg-mess-1-imagenet-all,fig:compare-lg-mess-1-celeba-all} depict these results for the ImageNet and CelebA datasets, respectively. Finally, the results obtained for all experiments where noise also appears in the inputs given to the Speaker and Listener at test time (\Cref{sec:eval-ext-noise}) appear in \Cref{fig:compare-lg-input-imagenet-all,fig:compare-lg-input-celeba-all}, for the ImageNet and CelebA datasets, respectively.

\begin{figure*}[!t]
\begin{minipage}[!t]{1\textwidth}
\centering
\includegraphics[width=0.55\linewidth]{figures/legend}
\caption*{}
%\vspace{-8ex}
\end{minipage}
%\vspace{-4ex}
\begin{minipage}[!t]{1\textwidth}
\vspace{-7ex}
\centering
\includegraphics[width=1\linewidth]{figures/acc_test_imagenet_all}
\caption{Mean test accuracy for all LG variants on the ImageNet dataset. Each row contains experiments trained with a particular candidate size, \(|\sC|\). From the first to the last row, the candidate sizes are \(\{16, 64, 256, 1024\}\). Each column depicts the test accuracy obtained by all experiments when setting the candidate size, \(|\sC_\text{test}|\), to a specific value at test time (the test candidate set size can be different from the value used during training). From the first to the last column, the test candidate sizes are \(\{16, 64, 256, 1024, 4096\}\). We report the average (plus SD) over 10 seeds.}
\label{fig:compare-lg-imagenet-all}
%\vspace{-2ex}
\end{minipage}
\end{figure*}

\begin{figure*}[!t]
\begin{minipage}[!t]{1\textwidth}
\centering
\includegraphics[width=0.55\linewidth]{figures/legend}
\caption*{}
%\vspace{-8ex}
\end{minipage}
%\vspace{-4ex}
\begin{minipage}[!t]{1\textwidth}
\vspace{-7ex}
\centering
\includegraphics[width=1\linewidth]{figures/acc_test_celeba_all}
\caption{Mean test accuracy for all LG variants on the CelebA dataset. Each row contains experiments trained with a particular candidate size, \(|\sC|\). From the first to the last row, the candidate sizes are \(\{16, 64, 256, 1024\}\). Each column depicts the test accuracy obtained by all experiments when setting the candidate size, \(|\sC_\text{test}|\), to a specific value at test time (the test candidate set size can be different from the value used during training). From the first to the last column, the test candidate sizes are \(\{16, 64, 256, 1024, 4096\}\). We report the average (plus SD) over 10 seeds.}
\label{fig:compare-lg-celeba-all}
%\vspace{-2ex}
\end{minipage}
\end{figure*}

\begin{figure*}[!t]
\begin{minipage}[!t]{1\textwidth}
\centering
\includegraphics[width=0.55\linewidth]{figures/legend}
\caption*{}
%\vspace{-8ex}
\end{minipage}
%\vspace{-4ex}
\begin{minipage}[!t]{1\textwidth}
\vspace{-7ex}
\centering
\includegraphics[width=1\linewidth]{figures/acc_testmessage_imagenet_all}
\caption{Mean test accuracy, when randomly masking a fixed number of message tokens (see \Cref{sec:eval-mess-struct}), for all LG variants on the ImageNet dataset. Each row contains experiments trained with a particular candidate size, \(|\sC|\). From the first to the last row, the candidate sizes are \(\{16, 64, 256, 1024\}\). Each column depicts the test accuracy obtained by all experiments when setting the candidate size, \(|\sC_\text{test}|\), to a specific value at test time (the test candidate set size can be different from the value used during training). From the first to the last column, the test candidate sizes are \(\{16, 64, 256, 1024, 4096\}\). We report the average (plus SD) over 10 seeds and 10 different combinations of masked tokens (except when no tokens are masked).}
\label{fig:compare-lg-mess-imagenet-all}
%\vspace{-2ex}
\end{minipage}
\end{figure*}

\begin{figure*}[!t]
\begin{minipage}[!t]{1\textwidth}
\centering
\includegraphics[width=0.55\linewidth]{figures/legend}
\caption*{}
%\vspace{-8ex}
\end{minipage}
%\vspace{-4ex}
\begin{minipage}[!t]{1\textwidth}
\vspace{-7ex}
\centering
\includegraphics[width=1\linewidth]{figures/acc_testmessage_celeba_all}
\caption{Mean test accuracy, when randomly masking a fixed number of message tokens (see \Cref{sec:eval-mess-struct}), for all LG variants on the CelebA dataset. Each row contains experiments trained with a particular candidate size, \(|\sC|\). From the first to the last row, the candidate sizes are \(\{16, 64, 256, 1024\}\). Each column depicts the test accuracy obtained by all experiments when setting the candidate size, \(|\sC_\text{test}|\), to a specific value at test time (the test candidate set size can be different from the value used during training). From the first to the last column, the test candidate sizes are \(\{16, 64, 256, 1024, 4096\}\). We report the average (plus SD) over 10 seeds and 10 different combinations of masked tokens (except when no tokens are masked).}
\label{fig:compare-lg-mess-celeba-all}
%\vspace{-2ex}
\end{minipage}
\end{figure*}

\begin{figure*}[!t]
\begin{minipage}[!t]{1\textwidth}
\centering
\includegraphics[width=0.55\linewidth]{figures/legend}
\caption*{}
%\vspace{-8ex}
\end{minipage}
%\vspace{-4ex}
\begin{minipage}[!t]{1\textwidth}
\vspace{-7ex}
\centering
\includegraphics[width=1\linewidth]{figures/acc_testmessage_1_imagenet_all}
\caption{Comparison of the mean test accuracy when masking the first message token vs.\ masking any other token, for all LG variants on the ImageNet dataset. Each row contains experiments trained with a particular candidate size, \(|\sC|\). From the first to the last row, the candidate sizes are \(\{16, 64, 256, 1024\}\). Each column depicts the test accuracy obtained by all experiments when setting the candidate size, \(|\sC_\text{test}|\), to a specific value at test time (the test candidate set size can be different from the value used during training). From the first to the last column, the test candidate sizes are \(\{16, 64, 256, 1024, 4096\}\). We report the average (plus SD) over 10 seeds.}
\label{fig:compare-lg-mess-1-imagenet-all}
%\vspace{-2ex}
\end{minipage}
\end{figure*}

\begin{figure*}[!t]
\begin{minipage}[!t]{1\textwidth}
\centering
\includegraphics[width=0.55\linewidth]{figures/legend}
\caption*{}
%\vspace{-8ex}
\end{minipage}
%\vspace{-4ex}
\begin{minipage}[!t]{1\textwidth}
\vspace{-7ex}
\centering
\includegraphics[width=1\linewidth]{figures/acc_testmessage_1_celeba_all}
\caption{Comparison of the mean test accuracy when masking the first message token vs.\ masking any other token, for all LG variants on the CelebA dataset. Each row contains experiments trained with a particular candidate size, \(|\sC|\). From the first to the last row, the candidate sizes are \(\{16, 64, 256, 1024\}\). Each column depicts the test accuracy obtained by all experiments when setting the candidate size, \(|\sC_\text{test}|\), to a specific value at test time (the test candidate set size can be different from the value used during training). From the first to the last column, the test candidate sizes are \(\{16, 64, 256, 1024, 4096\}\). We report the average (plus SD) over 10 seeds.}
\label{fig:compare-lg-mess-1-celeba-all}
%\vspace{-2ex}
\end{minipage}
\end{figure*}

\begin{figure*}[!t]
\begin{minipage}[!t]{1\textwidth}
\centering
\includegraphics[width=0.55\linewidth]{figures/legend}
\caption*{}
%\vspace{-8ex}
\end{minipage}
%\vspace{-4ex}
\begin{minipage}[!t]{1\textwidth}
\vspace{-7ex}
\centering
\includegraphics[width=1\linewidth]{figures/acc_testinput_imagenet_all}
\caption{Mean test accuracy, when noise is added to the inputs (see \Cref{sec:eval-ext-noise}), for all LG variants on the ImageNet dataset. Each row contains experiments trained with a particular candidate size, \(|\sC|\). From the first to the last row, the candidate sizes are \(\{16, 64, 256, 1024\}\). Each column depicts the test accuracy obtained by all experiments when setting the candidate size, \(|\sC_\text{test}|\), to a specific value at test time (the test candidate set size can be different from the value used during training). From the first to the last column, the test candidate sizes are \(\{16, 64, 256, 1024, 4096\}\). We report the average (plus SD) over 10 seeds.}
\label{fig:compare-lg-input-imagenet-all}
%\vspace{-2ex}
\end{minipage}
\end{figure*}

\begin{figure*}[!t]
\begin{minipage}[!t]{1\textwidth}
\centering
\includegraphics[width=0.55\linewidth]{figures/legend}
\caption*{}
%\vspace{-8ex}
\end{minipage}
%\vspace{-4ex}
\begin{minipage}[!t]{1\textwidth}
\vspace{-7ex}
\centering
\includegraphics[width=1\linewidth]{figures/acc_testinput_celeba_all}
\caption{Mean test accuracy, when noise is added to the inputs (see \Cref{sec:eval-ext-noise}), for all LG variants on the CelebA dataset. Each row contains experiments trained with a particular candidate size, \(|\sC|\). From the first to the last row, the candidate sizes are \(\{16, 64, 256, 1024\}\). Each column depicts the test accuracy obtained by all experiments when setting the candidate size, \(|\sC_\text{test}|\), to a specific value at test time (the test candidate set size can be different from the value used during training). From the first to the last column, the test candidate sizes are \(\{16, 64, 256, 1024, 4096\}\). We report the average (plus SD) over 10 seeds.}
\label{fig:compare-lg-input-celeba-all}
%\vspace{-2ex}
\end{minipage}
\end{figure*}

\section{Ease \& Transfer Learning} \label{app:etl}
Following~\citet{chaabouni2022emergent}, we also utilize secondary tasks to evaluate the generality and applicability of the languages learned in each LG variant. This evaluation procedure is called Ease \& Transfer Learning (ETL). The primary purpose of ETL is to evaluate if a preceding communication protocol, which was grounded in a particular task, can be used by new agents to solve new tasks. If this proposition holds, we get solid and empirical evidence about the generality of the emergent language since it can encode high-level descriptive information to solve different types of tasks related to the original environment.

ETL comprises four tasks: \emph{Discrimination}, \emph{Classification}, \emph{Attribute}, and \emph{Reconstruction}. We use the first two tasks to evaluate instances of games played with the ImageNet dataset and all four tasks when using the CelebA dataset. Due to the lack of description and reproducibility in~\citet{chaabouni2022emergent}, we thoroughly report the objective of each task accompanied by the training regime and hyper-parameters adopted.

We define new Listener agents to play the new tasks with a previously trained Speaker from one of the original LG games. Additionally, we freeze the Speaker weights, meaning the communication protocol remains fixed throughout training and evaluation of the ETL task. As such, we generate a new discrete dataset that depends on the Speaker (converting each image into a message). On this account, the only learning agent is the Listener. The Listener architecture has a common module used to process the received message that does not depend on the ETL task. This module is equal to the one implemented in the Listener architecture used in the LG, see \Cref{sec:meth-arch}. The difference between architectures occurs in the Listener's head module, as we will describe when introducing each task.

Similar to the tests employed for the LG games, we add a new dimension for the ETL tasks where we perturb the communication channel by adding noise. Accordingly, by varying this new dimension, we can analyze how it affects the generalization capabilities of the communication protocols. We will now describe each ETL task in detail, and afterward, the evaluation performed.

\subsection{Discrimination Task} \label{app:etl-discr}
This task is similar to the original LG task, where we add noise to the candidates and the Speaker's input, see \Cref{sec:eval-ext-noise}. The noise follows a Gaussian distribution with mean \(\mu\) and a standard deviation \(\sigma\), see \Cref{table:etl-classif-hyperparams}. Since we now have a fixed dataset, we regard this task as a supervised problem where we design the Listener to have a similar architecture to the one used in the original LG (S). As such, we define a distance loss to train the Listener to recognize similarities between messages and the correct candidate and, simultaneously, dissimilarities to opposing ones. To create a more challenging task, we set the size of the candidates' set, \(|\sC|\), to 4096.

\subsubsection{Listener's Head Architecture}
We plug the head defined for the LG (S) (\Cref{app:arch-list-ss}), where a distance function computes similarities between the message and each candidate. Then, a softmax function converts similarities into a categorical distribution to train using InfoNCE loss~\citep{oord2018representation}.

\subsubsection{Hyperparameters}
The hyperparameters adjusted for the Discrimination task appear in \Cref{table:etl-discr-hyperparams}.

\begin{table}[t]
\centering
\caption{Hyperparameters modified (from \Cref{table:etl-common-hyperparams}) for the Discrimination task.}
\label{table:etl-discr-hyperparams}
\begin{tabular}{lc}
\toprule
hyperparameter & value\\
\midrule
\(\mu\) & \SI{0}{} \\
\(\sigma\) & \SI{0.5}{} \\
\(|\sC|\) & \SI{4096}{} \\
batch size & \SI{4096}{} (\(=|\sC|\)) \\
\bottomrule
\end{tabular}
\end{table}

\subsection{Classification Task} \label{app:etl-classif}
With the classification task, we aim to evaluate whether the emerging language has any valuable information to identify the category of an image. In this task, the Speaker receives an image and encodes a message to the Listener. Afterward, the Listener tries to determine the class of the image while receiving only the message sent by the Speaker as input. For the ImageNet dataset, we use the label of each image as the target and the identity for the CelebA dataset.

\subsubsection{Listener's Head Architecture} \label{app:etl-classif-list}
Since the objective of the Classification task is to identify the class of the image received by the Speaker, the Listener's head architecture consists of only one MLP where the final layer has the same size as the number of classes (1000 and 10177, for the ImageNet and CelebA datasets, respectively) and is then used for prediction after applying softmax. The MLP mentioned above also has one hidden layer of size 256 and uses ReLU as the activation function.

\subsubsection{Hyperparameters}
\Cref{table:etl-classif-hyperparams} exposes the hyperparameters modified explicity for the Classification task.

\begin{table}[t]
\centering
\caption{Hyperparameters modified (from \Cref{table:etl-common-hyperparams}) for the Classification task.}
\label{table:etl-classif-hyperparams}
\begin{tabular}{lc}
\toprule
hyperparameter & value\\
\midrule
training steps (for ImageNet dataset only)& \SI{30}{\kilo{}} \\
\bottomrule
\end{tabular}
\end{table}

\subsection{Attribute Task} \label{app:etl-attr}
This task is very similar to the classification task, where instead of predicting the image class, the Listener tries to predict secondary binary information related to facial attributes, such as gender, hair color, age, etc.

\subsubsection{Listener's Head Architecture}
The Listener architecture is similar to the one described for the classification task, \cref{app:etl-classif-list}. In this case, we have an independent model to classify each attribute, where the loss adopted is the binary cross-entropy loss.

\begin{comment}
\subsubsection{Hyperparameters}
The modified hyperparameters are depicted in \Cref{table:etl-attr-hyperparams}.

\begin{table}[t]
\centering
\caption{Hyperparameters modified (from \Cref{table:etl-common-hyperparams}) for the Classification task.}
\label{table:etl-attr-hyperparams}
\begin{tabular}{lc}
\toprule
hyperparameter & value\\
\midrule
training steps (for ImageNet dataset only)& \SI{30}{\kilo{}} \\
\bottomrule
\end{tabular}
\end{table}
\end{comment}

\subsection{Reconstruction Task} \label{app:etl-reconst}
The final ETL task is the Reconstruction task, where the primary purpose is reconstructing the original image. The Listener's head promotes a convolutional decoder to reconstruct the original input image (Speaker's input) by taking into account only the discrete message sent by the Speaker. See \Cref{app:etl-reconst-list} for a complete description of the Listener's head architecture.

\subsubsection{Listener's Head Architecture} \label{app:etl-reconst-list}
The Listener's head architecture encapsulates a decoder to reconstruct the original image. Since the hidden message features \(\vz_{T,\phi}\) are the input of this module and have only one dimension, the first step addresses the redimension of \(\vz_{T,\phi}\) into a 3D shape. As such, a single linear layer of size \(2048\) upsamples \(\vz_{T,\phi}\), where the resulting dimension is \((4, 4, 128)\) (with layout \texttt{(height, width, channel)}) after reshaping, as \(128\times4\times4=2048\). Afterward, a decoding procedure aims to upsample the features' first two dimensions. The procedure occurs four times sequentially, and at each step, we upsample the dimensions of the current features by doubling the width and height, using nearest neighbor interpolation. Next, the upsampled features are given to a convolution layer followed by a ReLU to reduce the number of channels as part of the reconstruction process. The number of output channels is \(64, 32, 16, 16\) for each convolution, respectively. Finally, a concluding convolution layer, followed by \(\text{tanh}\), outputs the decoded image with dimensions \((64, 64, 3)\). With \(\text{tanh}\) as the final activation, the reconstructed image is the standardized version of the original one after normalization using the ImageNet coefficients~\citep{he2016deep}. Furthermore, the parameters for all convolutions are equal: kernel size of \((3\times3)\), padding \texttt{same}, stride \(1\), and without bias. Additionally, we use the MSE loss to train the Listener.

Finally, we employ the same optimizer parameters as the original work~\citep{chaabouni2022emergent}, where gradients are first clipped by their global norm when it is above a maximum threshold \(G_\text{max}\)~\citep{pascanu2013difficulty}. Then, \texttt{adam} with weight decay regularization~\citep{loshchilov2017decoupled} computes the update rule. For more information on the hyper-parameters used, see \Cref{app:etl-reconst-params}.

\subsubsection{Hyperparameters }\label{app:etl-reconst-params}
Please refer to \Cref{table:etl-recons-hyperparams} to consult the modified hyperparameters for the Reconstrunction task.

\begin{table}[t]
\centering
\caption{Hyperparameters modified (from \Cref{table:etl-common-hyperparams}) for the Reconstruction task.}
\label{table:etl-recons-hyperparams}
\begin{tabular}{lc}
\toprule
hyperparameter & value\\
\midrule
\(G_\text{max}\) & 500 \\
Listener's optimizer & \texttt{adam w/ weight decay reg.} \\
Listener's optimizer \texttt{lr} & \SI{3e-4}{} \\
Listener's optimizer \texttt{b1} & \SI{0.9}{} \\
Listener's optimizer \texttt{b2} & \SI{0.9}{} \\
Listener's optimizer \texttt{weight decay} & \SI{0.01}{} \\
\bottomrule
\end{tabular}
\end{table}

\subsection{Common Hyperparameters} \label{app:etl-params}

\Cref{table:etl-common-hyperparams} describes the hyperparameters commonly used by all ETL tasks.

\begin{table}[t]
\centering
\caption{Default hyperparameters used in all ETL tasks. Note that each ETL task can change some parameter values, as specified in \Cref{app:etl-discr,app:etl-classif,app:etl-reconst}}
\label{table:etl-common-hyperparams}
\begin{tabular}{lc}
\toprule
hyperparameter & value\\
\midrule
training steps & \SI{10}{\kilo{}} \\
batch size & \SI{128}{} \\
\(|\mathcal{W}|\) & \SI{20}{} \\
\(T\) & \SI{10}{} \\
Listener's optimizer & \texttt{adam} \\
Listener's optimizer lr & \SI{1e-3}{} \\
\bottomrule
\end{tabular}
\end{table}

\subsection{Evaluation}
In this sub-section, we present all results obtained by evaluating all ETL tasks regarding each LG variant trained. Similarly to the primary evaluation, \Cref{sec:eval}, we describe the results incrementally, where we start by comparing both implementations (S and RL) for the original LG. Afterward, we introduce noise, adding NLG to the comparison. Additionally, we compare the influence of the candidate set size in all LG variants. Regarding the metrics adopted, we report accuracy for all tasks except for the Reconstruction task, where we report the obtained final loss.

\subsubsection{SS \& RL implementations for LG} \label{app:etl-eval-lg}
We start the ETL evaluation by showcasing and comparing the performance of both prototypes of the LG (S and RL) when training without noise. We report the test performance for all applicable ETL tasks for the ImageNet and CelebA datasets in \Cref{table:compare_etl_lg_imagenet,table:compare_etl_lg_celeba}, respectively. As we will see next, our newly proposed variant, LG (RL), reports better results than LG (S).

Looking at the discrimination task, we continue to observe the same behavior encountered in the LG evaluation, \Cref{sec:eval}, where the RL version is superior to S. From this new perspective, we obtain further evidence that the communication protocol from the RL variant is more general than the S counterpart. In this case, the messages from the RL version are more appropriate to describe the noisy image, which facilitates the selection process by the new Listener agent. As such, the communication protocol from LG (RL) is more capable of dealing with other noise sources, such as detecting noise in the Speaker's input image.

Regarding the classification task, we see deficient performance for both datasets, with around \(0.14\) and \(0.01\) test accuracy for ImageNet and CelebA, respectively. Not only that, but we also observe the same results for all LG variants testing with or without noise. In \Cref{app:etl-classif-analysis}, we propose a simple explanation for these results that emerge from the messages' content and structure.

Taking a closer look at the results for the CelebA dataset, we observe similar and considerably high results (around \(0.85\)) for the attribute task, which does not depend on the LG version, S or RL.
%A more in-depth comparison is available in TABLE, where we can see the test accuracy obtained for each attribute independently.
We can then assess that there is a specific batch of images where the Listener agent cannot decode any relevant information from the message to accurately classify the attribute.

For the final task, Reconstruction, we showcase the loss function obtained in the test set. We observe that LG (RL) obtains lower loss than LG (S). To complement this analysis, \Cref{fig:etl-reconstruct-all-lg-s,fig:etl-reconstruct-all-lg-rl} show the reconstruction of several images for the LG (S) and LG (RL) variants, respectively. Both versions can reconstruct some particularities of the original image such as sunglasses, hat, hair color, and gender. On the other hand, information about orientation, age, or skin tone are not encoded in the messages. Additionally, we can clearly observe different facial layouts and different hair color, reconstructed by LG (S) and LG (RL), for the same image.

\begin{table*}[t]
\linespread{0.6}\selectfont\centering
\caption{Test accuracy, with SD, of every ETL task trained using, the ImageNet dataset and over 10 seeds. During the LG training (before ETL), we fixed \(|\sC|\) to \(1024\).}
\label{table:compare_etl_lg_imagenet}
\centering
\begin{tabular}[t]{lrrr}
\toprule
Game & \multicolumn{1}{c}{\(|\sC|\)} & \multicolumn{2}{c}{ETL tasks} \\[1ex]\cmidrule(r){3-4}
 & & \multicolumn{1}{c}{Discrimination} & \multicolumn{1}{c}{Classification} \\
\midrule
%LG {\scriptsize(S)} & \(16\) & \longcell{\(0.22\)\\{\tiny(\(0.02\))}} & \longcell{\(0.08\)\\{\tiny(\(0.01\))}} \\[2.2ex]
%LG {\scriptsize(S)} & \(64\) & \longcell{\(0.34\)\\{\tiny(\(0.04\))}} & \longcell{\(0.11\)\\{\tiny(\(0.01\))}} \\[2.2ex]
%LG {\scriptsize(S)} & \(256\) & \longcell{\(0.45\)\\{\tiny(\(0.06\))}} & \longcell{\(0.13\)\\{\tiny(\(0.01\))}} \\[2.2ex]
LG {\scriptsize(S)} & \(1024\) & \longcell{\(0.58\)\\{\tiny(\(0.05\))}} & \longcell{\(0.14\)\\{\tiny(\(0.01\))}} \\[2.2ex]
%LG {\scriptsize(RL)} & \(16\) & \longcell{\(0.35\)\\{\tiny(\(0.07\))}} & \longcell{\(0.07\)\\{\tiny(\(0.01\))}} \\[2.2ex]
%LG {\scriptsize(RL)} & \(64\) & \longcell{\(0.61\)\\{\tiny(\(0.10\))}} & \longcell{\(0.10\)\\{\tiny(\(0.02\))}} \\[2.2ex]
%LG {\scriptsize(RL)} & \(256\) & \longcell{\(0.78\)\\{\tiny(\(0.06\))}} & \longcell{\(0.12\)\\{\tiny(\(0.02\))}} \\[2.2ex]
LG {\scriptsize(RL)} & \(1024\) & \longcell{\(0.88\)\\{\tiny(\(0.01\))}} & \longcell{\(0.14\)\\{\tiny(\(0.01\))}} \\
\bottomrule
\end{tabular}
\end{table*}

\begin{table*}[t]
\linespread{0.6}\selectfont\centering
\caption{Test accuracy, with SD, of every ETL task trained, using the CelebA dataset and over 10 seeds. During the LG training (before ETL), we fixed \(|\sC|\) to \(1024\).}
\label{table:compare_etl_lg_celeba}
\centering
\begin{tabular}[t]{lrrrrr}
\toprule
Game & \multicolumn{1}{c}{\(|\sC|\)} & \multicolumn{4}{c}{ETL tasks} \\[1ex]\cmidrule(r){3-6}
 & & \multicolumn{1}{c}{Discrimination} & \multicolumn{1}{c}{Classification} & \multicolumn{1}{c}{Attribute} & \multicolumn{1}{c}{Reconstruction}\\
\midrule
%LG {\scriptsize(S)} & \(16\) & \longcell{\(0.20\)\\{\tiny(\(0.03\))}} & \longcell{\(0.00\)\\{\tiny(\(0.00\))}} & \longcell{\(0.85\)\\{\tiny(\(0.00\))}} & \longcell{\(6061\)\\{\tiny(\(88\))}} \\[2.2ex]
%LG {\scriptsize(S)} & \(64\) & \longcell{\(0.30\)\\{\tiny(\(0.02\))}} & \longcell{\(0.00\)\\{\tiny(\(0.00\))}} & \longcell{\(0.86\)\\{\tiny(\(0.00\))}} & \longcell{\(5984\)\\{\tiny(\(93\))}} \\[2.2ex]
%LG {\scriptsize(S)} & \(256\) & \longcell{\(0.39\)\\{\tiny(\(0.06\))}} & \longcell{\(0.01\)\\{\tiny(\(0.00\))}} & \longcell{\(0.86\)\\{\tiny(\(0.00\))}} & \longcell{\(5833\)\\{\tiny(\(148\))}} \\[2.2ex]
LG {\scriptsize(S)} & \(1024\) & \longcell{\(0.44\)\\{\tiny(\(0.05\))}} & \longcell{\(0.01\)\\{\tiny(\(0.00\))}} & \longcell{\(0.86\)\\{\tiny(\(0.00\))}} & \longcell{\(5814\)\\{\tiny(\(74\))}} \\[2.2ex]
%LG {\scriptsize(RL)} & \(16\) & \longcell{\(0.17\)\\{\tiny(\(0.07\))}} & \longcell{\(0.00\)\\{\tiny(\(0.00\))}} & \longcell{\(0.85\)\\{\tiny(\(0.00\))}} & \longcell{\(6050\)\\{\tiny(\(50\))}} \\[2.2ex]
%LG {\scriptsize(RL)} & \(64\) & \longcell{\(0.34\)\\{\tiny(\(0.11\))}} & \longcell{\(0.00\)\\{\tiny(\(0.00\))}} & \longcell{\(0.85\)\\{\tiny(\(0.00\))}} & \longcell{\(6012\)\\{\tiny(\(121\))}} \\[2.2ex]
%LG {\scriptsize(RL)} & \(256\) & \longcell{\(0.48\)\\{\tiny(\(0.09\))}} & \longcell{\(0.00\)\\{\tiny(\(0.00\))}} & \longcell{\(0.86\)\\{\tiny(\(0.00\))}} & \longcell{\(5750\)\\{\tiny(\(1544\))}} \\[2.2ex]
LG {\scriptsize(RL)} & \(1024\) & \longcell{\(0.62\)\\{\tiny(\(0.08\))}} & \longcell{\(0.01\)\\{\tiny(\(0.00\))}} & \longcell{\(0.85\)\\{\tiny(\(0.00\))}} & \longcell{\(5671\)\\{\tiny(\(192\))}} \\
\bottomrule
\end{tabular}
%\vspace{-2ex}
\end{table*}

\subsubsection{Introducing Noise} \label{app:etl-eval-noise}
To evaluate the robustness of the proposed LG variants to message perturbations, we add a new train/test regime to ETL where the communication channel disturbs messages sent by the Speaker by adding random noise, similar to NLG. To have an insightful analysis, we propose comparing LG (RL) and NLG in the case of train/test regimes without and with noise. We disregard LG (S) since LG (RL) achieved better results, see \Cref{app:etl-eval-lg}. Additionally, to have a contained analysis, we fixed the noise level to \(0.5\), and the candidate set size to 1024. The exhaustive version of these results appears at \Cref{table:etl_imagenet_0_eval,table:etl_celeba_0_eval,table:etl_imagenet_025_eval,table:etl_celeba_025_eval,table:etl_imagenet_05_eval,table:etl_celeba_05_eval,table:etl_imagenet_075_eval,table:etl_celeba_075_eval}.


The results for the ImageNet dataset appear in \Cref{table:compare_etl_noise_imagenet_det,table:compare_etl_noise_imagenet_noise} for the train/test regime without and with noise, respectively. Regarding the Discrimination task in the deterministic procedure (without noise), the accuracy obtained for NLG is slightly lower than in the LG (RL), around \(0.03\) below. Despite this minor decline, we continue to obtain evidence that the NLG generate robust communication protocols of similar efficiency to those induced by LG (RL). When introducing noise in the communication channel, we observe a performance increase, around \(0.05\), for NLG against LG (RL). Recall that the discrimination task adds continuous noise to the Speaker's input and candidates. Having noisy inputs creates a different type of uncertainty that the communication protocol is not optimized for. Even having robust agents to message noise practically does not impact the creation of more descriptive messages when a significant part of the noise comes from another source, in this case, combined with the input.

We perform a similar comparison for the CelebA dataset deployed in \Cref{table:compare_etl_noise_celeba_det,table:compare_etl_noise_celeba_noise}, for the deterministic and noisy regime, respectively. Focusing on the Discrimination task and the deterministic regime, LG (RL) and NLG have statistically equal accuracy values with mean \(0.62\), and \(0.60\), respectively.
%CelebA contains highly identical samples since it only includes images of persons, whereas ImageNet aggregates images from 1000 object categories. In this case, the performance obtained was similar between all variants.
When training and testing with noise, we observe a considerable drop in accuracy, around \(0.35\), for all variants. Similarly to what we discovered for the ImageNet dataset, the noise introduced to the inputs turns the discriminative task more challenging than the original game.

Regarding the Attribute task, all values vary between \(0.84\) and \(0.86\). As such, the performances for every LG variant are highly identical. We hypothesize that there is a considerable collection of samples where the identification of each attribute is accessible and effortlessly contemplated in the communication protocols. For the other minority of samples, the communication protocols cannot encode information about the attributes. For this reason, we observe a sharp rupture in accuracy for all methods, aroung \(85\%\).

Finally, we compare the results obtained in the Reconstruction task. The losses for all LG variants are statistically equal for the test regime without and with noise. No LG variant demonstrated superior performance for this challenging task, which is obviously expected since the reconstructed images originate from discrete tokens (message content), making extracting unique information from each image extremely difficult. Additionally, in \Cref{fig:etl-reconstruct-all-lg-s,fig:etl-reconstruct-all-lg-rl,fig:etl-reconstruct-all-nlg}, we show some reconstructed images for the compared LG variants (LG (S), LG (RL), and NLG, respectively). The level of reconstruction detail is similar accross variants, where we can see all variants encoding hat, sunglasses, hair color, and ignoring attributes not relevant to the original discrimination task, such as skin tone and face orientation.

\begin{table*}[t]
\linespread{0.6}\selectfont\centering
\caption{Test accuracy, with SD, of every ETL task trained, using the ImageNet dataset and over 10 seeds. We do not apply noise during ETL's train and test phase. During the LG training (before ETL), we fixed \(|\sC|\) to \(1024\), and \(\lambda\) to \(0.5\).}
\label{table:compare_etl_noise_imagenet_det}
\centering
\begin{tabular}[t]{lrrrrr}
\toprule
Game & \(\lambda\) & \multicolumn{1}{c}{\(|\sC|\)} & \multicolumn{2}{c}{ETL tasks} \\[1ex]\cmidrule(r){4-5}
 & & & \multicolumn{1}{c}{Discrimination} & \multicolumn{1}{c}{Classification} \\
\midrule
LG {\scriptsize(RL)} & \(0\) & \(1024\) & \longcell{\(0.88\)\\{\tiny(\(0.01\))}} & \longcell{\(0.14\)\\{\tiny(\(0.01\))}} \\[2.2ex]
NLG & \(0.5\) & \(1024\) & \longcell{\(0.85\)\\{\tiny(\(0.03\))}} & \longcell{\(0.14\)\\{\tiny(\(0.02\))}} \\[2.2ex]
%MRILG & \(0.5\) & \(-0.2\) & \(1024\) & \longcell{\(0.86\)\\{\tiny(\(0.03\))}} & \longcell{\(0.13\)\\{\tiny(\(0.01\))}} \\
\bottomrule
\end{tabular}
\end{table*}

\begin{table*}[t]
\linespread{0.6}\selectfont\centering
\caption{Test accuracy, with SD, of every ETL task trained, using the CelebA dataset and over 10 seeds. During the LG training (before ETL), we fixed \(|\sC|\) to \(1024\). We do not apply noise during ETL's train and test phase. During the LG training (before ETL), we fixed \(|\sC|\) to \(1024\), and \(\lambda\) to \(0.5\).}
\label{table:compare_etl_noise_celeba_det}
\centering
\begin{tabular}[t]{lrrrrrr}
\toprule
Game & \multicolumn{1}{c}{\(\lambda\)} & \multicolumn{1}{c}{\(|\sC|\)} & \multicolumn{4}{c}{ETL tasks} \\[1ex]\cmidrule(r){4-7}
 & & & \multicolumn{1}{c}{Discrimination} & \multicolumn{1}{c}{Classification} & \multicolumn{1}{c}{Attribute} & \multicolumn{1}{c}{Reconstruction}\\
\midrule
LG {\scriptsize(RL)} & \(0\) & \(1024\) & \longcell{\(0.62\)\\{\tiny(\(0.08\))}} & \longcell{\(0.01\)\\{\tiny(\(0.00\))}} & \longcell{\(0.85\)\\{\tiny(\(0.00\))}} & \longcell{\(5671\)\\{\tiny(\(192\))}} \\[2.2ex]
NLG & \(0.5\) & \(1024\) & \longcell{\(0.60\)\\{\tiny(\(0.10\))}} & \longcell{\(0.00\)\\{\tiny(\(0.00\))}} & \longcell{\(0.85\)\\{\tiny(\(0.00\))}} & \longcell{\(5659\)\\{\tiny(\(129\))}} \\[2.2ex]
%MRILG & \(0.5\) & \(-0.2\) & \(1024\) & \longcell{\(0.58\)\\{\tiny(\(0.12\))}} & \longcell{\(0.00\)\\{\tiny(\(0.00\))}} & \longcell{\(0.85\)\\{\tiny(\(0.00\))}} & \longcell{\(5644\)\\{\tiny(\(121\))}} \\
\bottomrule
\end{tabular}
%\vspace{-2ex}
\end{table*}

\begin{table*}[t]
\linespread{0.6}\selectfont\centering
\caption{Test accuracy, with SD, of every ETL task trained, using the ImageNet dataset and over 10 seeds. We fix the noise during ETL's train and test phase at \(0.5\). During the LG training (before ETL), we fixed \(|\sC|\) to \(1024\), and \(\lambda\) to \(0.5\).}
\label{table:compare_etl_noise_imagenet_noise}
\centering
\begin{tabular}[t]{lrrrr}
\toprule
Game & \(\lambda\) & \multicolumn{1}{c}{\(|\sC|\)} & \multicolumn{2}{c}{ETL tasks} \\[1ex]\cmidrule(r){4-5}
 & & & \multicolumn{1}{c}{Discrimination} & \multicolumn{1}{c}{Classification} \\
\midrule
LG {\scriptsize(RL)} & \(0\) & \(1024\) & \longcell{\(0.36\)\\{\tiny(\(0.02\))}} & \longcell{\(0.07\)\\{\tiny(\(0.00\))}} \\[2.2ex]
NLG & \(0.5\) & \(1024\) & \longcell{\(0.41\)\\{\tiny(\(0.02\))}} & \longcell{\(0.08\)\\{\tiny(\(0.01\))}} \\[2.2ex]
%MRILG & \(0.5\) & \(-0.2\) & \(1024\) & \longcell{\(0.41\)\\{\tiny(\(0.01\))}} & \longcell{\(0.07\)\\{\tiny(\(0.01\))}} \\
\bottomrule
\end{tabular}
\end{table*}

\begin{table*}[t]
\linespread{0.6}\selectfont\centering
\caption{Test accuracy, with SD, of every ETL task trained, using the CelebA dataset and over 10 seeds. We fix the noise during ETL's train and test phase at \(0.5\). During the LG training (before ETL), we fixed \(|\sC|\) to \(1024\), and \(\lambda\) to \(0.5\).}
\label{table:compare_etl_noise_celeba_noise}
\centering
\begin{tabular}[t]{lrrrrrr}
\toprule
Game & \multicolumn{1}{c}{\(\lambda\)} & \multicolumn{1}{c}{\(|\sC|\)} & \multicolumn{4}{c}{ETL tasks} \\[1ex]\cmidrule(r){4-7}
 & & & \multicolumn{1}{c}{Discrimination} & \multicolumn{1}{c}{Classification} & \multicolumn{1}{c}{Attribute} & \multicolumn{1}{c}{Reconstruction}\\
\midrule
LG {\scriptsize(RL)} & \(0\) & \(1024\) & \longcell{\(0.26\)\\{\tiny(\(0.03\))}} & \longcell{\(0.00\)\\{\tiny(\(0.00\))}} & \longcell{\(0.85\)\\{\tiny(\(0.00\))}} & \longcell{\(5871\)\\{\tiny(\(155\))}} \\[2.2ex]
NLG & \(0.5\) & 1024 & \longcell{\(0.31\)\\{\tiny(\(0.04\))}} & \longcell{\(0.00\)\\{\tiny(\(0.00\))}} & \longcell{\(0.85\)\\{\tiny(\(0.00\))}} & \longcell{\(5833\)\\{\tiny(\(103\))}} \\[2.2ex]
%MRILG & \(0.5\) & \(-0.2\) & \(1024\) & \longcell{\(0.30\)\\{\tiny(\(0.06\))}} & \longcell{\(0.00\)\\{\tiny(\(0.00\))}} & \longcell{\(0.85\)\\{\tiny(\(0.00\))}} & \longcell{\(5820\)\\{\tiny(\(92\))}} \\
\bottomrule
\end{tabular}
%\vspace{-2ex}
\end{table*}

\begin{comment}
\subsubsection{Varying IDK Reward}
From the original evaluation \Cref{eval:idk}, substantial evidence supported that the \emph{idk} reward considerably impacts the agent's overall performance in the MRILG. Thus, we continue this evaluation in the context of transfer learning, ETL, by comparing instances of MRILG with a fixed noise (\(0.5\)) and batch size (1024), where we only vary the idk reward. The evaluation description for the ImageNet dataset appears in \Cref{table:compare_etl_idk_imagenet,table:compare_etl_idk_imagenet_noise} for the train/test regime without and with noise, respectively. Similarly, and according to the same respective noise schemes, \Cref{table:compare_etl_idk_celeba,table:compare_etl_idk_celeba_noise} present the results for the CelebA dataset. The extensive report divided by the noise level and train/test regime appears in \Cref{table:etl_imagenet_0_eval,table:etl_celeba_0_eval,table:etl_imagenet_025_eval,table:etl_celeba_025_eval,table:etl_imagenet_05_eval,table:etl_celeba_05_eval,table:etl_imagenet_075_eval,table:etl_celeba_075_eval}.

Starting with the ImageNet dataset, we focus on the Discrimination task. In \Cref{table:compare_etl_idk_imagenet}, we place the deterministic train/test regime results and observe that the choice for the \emph{idk} impacts the overall performance moderately. The highest obtained test accuracy for the three reward levels (\(-0.5\), \(-0.2\), and \(-0.05\)) is around \(0.86\) when \emph{idk} is fixed at \(-0.2\), opposing a slight decrease to \(0.82\) when \(\nu=-0.5\) and a large decrease to \(0.65\) for the remain \emph{idk} level (\(-0.05\)). We can describe this conduct as, when having an \emph{idk} reward close to \(0\) can direct the Listener toward developing a communication protocol containing more redundant information (playing more rounds than necessary), having a higher likelihood of overfitting the training dataset.

When adding noise to the ETL task, we obtain similar results, where the \emph{idk} reward of \(-0.05\) outputs lower results than the other two levels. In this train/test regime, the new Listener agent has more difficulty reasoning and combining the two input noisy sources (message and candidates), decreasing the test accuracy by almost \(0.50\) (roughly \(0.8\) to \(0.4\)). Based on the difference in performance for both train/test regimes, we can infer that having access to the complete message generated by the Speaker (all information) is crucial to discriminate noisy inputs.

Addressing now the CelebA dataset, we observe a similar result for the Discrimination task in the deterministic train/test regime, where the \emph{idk} rewards of \(-0.5\) and \(-0.2\)) obtains the highest test accuracies of \(0.59\) and \(0.58\), against \(0.28\) got when setting the \emph{idk} reward at \(-0.05\). Thus, we can employ the same reasoning as described above for the ImageNet dataset, and since CelebA is a more challenging dataset (\Cref{app:etl-eval-noise}) the differences are even more prominent. Similarly, having an \emph{idk} away from \(0\) balances the creation of a communication protocol that leverages multi-round information in its development and, at the same time, is not redundant by only continuing playing when new information can be attained. Regarding the Attribute task, the results are the same when setting the \emph{idk} reward to \(-0.5\) or \(-0.2\). For the value \(-0.05\), the accuracy drops slightly to \(0.83\), which can be, again, a consequence of the presence of more redundant information in the communication protocol (see text above). Moving to the final task, Reconstruction, we point to the same reasoning since the obtained losses were similar for the \emph{idk} reward of \(-0.5\) and \(-0.2\), having mean values of \(5686\) and \(5644\), respectively. The loss when \(\nu=-0.05\) was higher at \(6182\).

Addressing now the noisy train/test regime, we observe, for each task, the same behavior as the deterministic regime. Focusing on the Discrimination task and similar to the deterministic train/test regime, the test accuracy is higher for the \emph{idk} rewards of \(-0.5\) and \(-0.2\) than the remaining level. The same happens for the Attribute task where the \emph{idk} rewards of \(-0.5\) and \(-0.2\) obtain the same value (\(0.85\)) against a slight decrease for the \(-0.05\) level (\(0.83\)). As such, we conclude that the same behavior occurs in the noisy regime, indicating that the noise robustness lowers when the \emph{idk} reward is too small. We also observe this in the Reconstruction task where the loss values are lower for the \emph{idk} reward values of \(-0.5\) and \(-0.2\), against the value of \(-0.05\).

\begin{table}[t]
\linespread{0.6}\selectfont\centering
\caption{Test accuracy, with SD, of every ETL task trained, using the ImageNet dataset and over 10 seeds. We do not apply noise during ETL's train and test phase. During the LG training (before ETL), we fixed \(|\sC|\) to \(1024\) and \(\lambda\) to \(0.5\).}
\label{table:compare_etl_idk_imagenet}
\centering
\begin{tabular}[t]{lrrrrr}
\toprule
Game & \(\lambda\) & \(\nu\) & \multicolumn{1}{c}{\(|\sC|\)} & \multicolumn{2}{c}{ETL tasks} \\[1ex]\cmidrule(r){5-6}
 & & & & \multicolumn{1}{c}{Discrimination} & \multicolumn{1}{c}{Classification} \\
\midrule
MRILG & \(0.5\) & \(-0.5\) & \(1024\) & \longcell{\(0.82\)\\{\tiny(\(0.03\))}} & \longcell{\(0.12\)\\{\tiny(\(0.02\))}} \\[2.2ex]
MRILG & \(0.5\) & \(-0.2\) & \(1024\) & \longcell{\(0.86\)\\{\tiny(\(0.03\))}} & \longcell{\(0.13\)\\{\tiny(\(0.01\))}} \\[2.2ex]
MRILG & \(0.5\) & \(-0.05\) & \(1024\) & \longcell{\(0.65\)\\{\tiny(\(0.34\))}} & \longcell{\(0.09\)\\{\tiny(\(0.05\))}} \\
\bottomrule
\end{tabular}
\end{table}

\begin{table}[t]
\linespread{0.6}\selectfont\centering
\caption{Test accuracy, with SD, of every ETL task trained, using the ImageNet dataset and over 10 seeds. We do not apply noise during ETL's train and test phase. During the LG training (before ETL), we fixed \(|\sC|\) to \(1024\) and \(\lambda\) to \(0.5\).}
\label{table:compare_etl_idk_celeba}
\centering
\begin{tabular}[t]{lrrrrrrr}
\toprule
Game & \multicolumn{1}{c}{\(\lambda\)} & \multicolumn{1}{c}{\(\nu\)} & \multicolumn{1}{c}{\(|\sC|\)} & \multicolumn{4}{c}{ETL tasks} \\[1ex]\cmidrule(r){5-8}
 & & & & \multicolumn{1}{c}{Discrimination} & \multicolumn{1}{c}{Classification} & \multicolumn{1}{c}{Attribute} & \multicolumn{1}{c}{Reconstruction}\\
\midrule
MRILG & \(0.5\) & \(-0.5\) & \(1024\) & \longcell{\(0.59\)\\{\tiny(\(0.09\))}} & \longcell{\(0.00\)\\{\tiny(\(0.00\))}} & \longcell{\(0.85\)\\{\tiny(\(0.00\))}} & \longcell{\(5686\)\\{\tiny(\(121\))}} \\[2.2ex]
MRILG & \(0.5\) & \(-0.2\) & \(1024\) & \longcell{\(0.58\)\\{\tiny(\(0.12\))}} & \longcell{\(0.00\)\\{\tiny(\(0.00\))}} & \longcell{\(0.85\)\\{\tiny(\(0.00\))}} & \longcell{\(5644\)\\{\tiny(\(121\))}} \\[2.2ex]
MRILG & \(0.5\) & \(-0.05\) & \(1024\) & \longcell{\(0.28\)\\{\tiny(\(0.32\))}} & \longcell{\(0.00\)\\{\tiny(\(0.00\))}} & \longcell{\(0.83\)\\{\tiny(\(0.02\))}} & \longcell{\(6182\)\\{\tiny(\(466\))}} \\
\bottomrule
\end{tabular}
\vspace{-2ex}
\end{table}

\begin{table}[t]
\linespread{0.6}\selectfont\centering
\caption{Test accuracy, with SD, of every ETL task trained, using the ImageNet dataset and over 10 seeds. We fix the noise during ETL's train and test phase at \(0.5\). During the LG training (before ETL), we fixed \(|\sC|\) to \(1024\) and \(\lambda\) to \(0.5\).}
\label{table:compare_etl_idk_imagenet_noise}
\centering
\begin{tabular}[t]{lrrrrr}
\toprule
Game & \(\lambda\) & \(\nu\) & \multicolumn{1}{c}{\(|\sC|\)} & \multicolumn{2}{c}{ETL tasks} \\[1ex]\cmidrule(r){5-6}
 & & & & \multicolumn{1}{c}{Discrimination} & \multicolumn{1}{c}{Classification} \\
\midrule
MRILG & \(0.5\) & \(-0.5\) & \(1024\) & \longcell{\(0.40\)\\{\tiny(\(0.02\))}} & \longcell{\(0.07\)\\{\tiny(\(0.01\))}} \\[2.2ex]
MRILG & \(0.5\) & \(-0.2\) & \(1024\) & \longcell{\(0.41\)\\{\tiny(\(0.01\))}} & \longcell{\(0.07\)\\{\tiny(\(0.01\))}} \\[2.2ex]
MRILG & \(0.5\) & \(-0.05\) & \(1024\) & \longcell{\(0.31\)\\{\tiny(\(0.16\))}} & \longcell{\(0.05\)\\{\tiny(\(0.03\))}} \\
\bottomrule
\end{tabular}
\end{table}

\begin{table}[t]
\linespread{0.6}\selectfont\centering
\caption{Test accuracy, with SD, of every ETL task trained, using the CelebA dataset and over 10 seeds. We fix the noise during ETL's train and test phase at \(0.5\). During the LG training (before ETL), we fixed \(|\sC|\) to \(1024\) and \(\lambda\) to \(0.5\).}
\label{table:compare_etl_idk_celeba_noise}
\centering
\begin{tabular}[t]{lrrrrrrr}
\toprule
Game & \multicolumn{1}{c}{\(\lambda\)} & \multicolumn{1}{c}{\(\nu\)} & \multicolumn{1}{c}{\(|\sC|\)} & \multicolumn{4}{c}{ETL tasks} \\[1ex]\cmidrule(r){5-8}
 & & & & \multicolumn{1}{c}{Discrimination} & \multicolumn{1}{c}{Classification} & \multicolumn{1}{c}{Attribute} & \multicolumn{1}{c}{Reconstruction}\\
\midrule
MRILG & \(0.5\) & \(-0.5\) & \(1024\) & \longcell{\(0.30\)\\{\tiny(\(0.04\))}} & \longcell{\(0.00\)\\{\tiny(\(0.00\))}} & \longcell{\(0.85\)\\{\tiny(\(0.00\))}} & \longcell{\(5860\)\\{\tiny(\(95\))}} \\[2.2ex]
MRILG & \(0.5\) & \(-0.2\) & \(1024\) & \longcell{\(0.30\)\\{\tiny(\(0.06\))}} & \longcell{\(0.00\)\\{\tiny(\(0.00\))}} & \longcell{\(0.85\)\\{\tiny(\(0.00\))}} & \longcell{\(5820\)\\{\tiny(\(92\))}} \\[2.2ex]
MRILG & \(0.5\) & \(-0.05\) & \(1024\) & \longcell{\(0.14\)\\{\tiny(\(0.15\))}} & \longcell{\(0.00\)\\{\tiny(\(0.00\))}} & \longcell{\(0.83\)\\{\tiny(\(0.02\))}} & \longcell{\(6275\)\\{\tiny(\(374\))}} \\
\bottomrule
\end{tabular}
\vspace{-2ex}
\end{table}
\end{comment}

\subsubsection{Varying Number of Candidates}
Finally, we study the last axis of the predominant hyper-parameters, which is the number of candidates. We do a quick analysis since the results comply with the main evaluation (\Cref{sec:eval-cand}), where increasing the number of candidates is essential to improve performance. By increasing the number of candidates, the Listener receives a broader variety of samples, facilitating learning and recalling unique and valuable information to discriminate all candidates. Consequently, a more sophisticated communication protocol is necessary as the number of candidates increases since the discriminative task becomes more difficult. For this evaluation and similar to the previous ones, we fix the noise at \(0.5\). The results are for the following game variants: LG (RL), and NLG.

\Cref{table:compare_etl_cand_imagenet,table:compare_etl_cand_imagenet_noise} display the results for the ImageNet dataset employing the deterministic and noisy regimes, respectively. Looking at the Discrimination task, we observe an increase in test accuracy for all tasks as the number of candidates (used in the original RL task) scales up. Another important and related observation is that the gap between accuracies decreases in the noisy train/test regime. For example, in the regular regime (deterministic), the gap between 256 and 1024 candidates for LG (RL) and NLG variants is about \(0.08\) for both. On the other hand, the gaps for the same variants in the noisy regime are \(0.01\) for both noiseless and noisy regimes.

A similar outcome occurs for the results obtained when training with the CelebA dataset, \Cref{table:compare_etl_cand_celeba,table:compare_etl_cand_celeba_noise} display the results for the deterministic and noisy regimes, respectively. In the case of the Discrimination and Reconstruction tasks applied in both train/test regimes, there is a clear benefit of having a Speaker trained in a more complex RL task (increased number of candidates). As such, we observe that the test accuracy increases for the Discrimination task as the number of candidates increases for all LG variants. Comparetively, the loss obtained at evaluation time for the Reconstruction task also decreases as the number of candidates increases. The performance gap is also more visible in the deterministic regime, where no message noise is involved. As an illustration, consider the Discrimination task where the growth in accuracy for the NLG variant, when increasing the number of candidates from 256 to 1024, is \(0.17\) and \(0.11\), referring to the deterministic and noise regimes, respectively. Comparatively, looking at the Reconstruction task and the same LG variant, the increment in the test loss from 256 to 1024 candidates is \(128\) and \(135\) for the deterministic and noisy train/test regimes, respectively. Finally, addressing the Attribute task, we observe no significant improvements in performance when expanding the number of candidates. Similarly to the previous evaluation analyzes (\Cref{app:etl-eval-noise}), the test accuracy stays fixed at \(0.85\)/\(0.86\).

\begin{table*}[t]
\linespread{0.6}\selectfont\centering
\caption{Test accuracy, with SD, of every ETL task trained, using the ImageNet dataset and over 10 seeds. We do not apply noise during ETL's train and test phase. During the LG training (before ETL), we fixed \(\lambda\) to \(0.5\).}
\label{table:compare_etl_cand_imagenet}
\centering
\begin{tabular}[t]{lrrrr}
\toprule
Game & \multicolumn{1}{c}{\(\lambda\)} & \multicolumn{1}{c}{\(|\sC|\)} & \multicolumn{2}{c}{ETL tasks} \\[1ex]\cmidrule(r){4-5}
 & & & \multicolumn{1}{c}{Discrimination} & \multicolumn{1}{c}{Classification} \\
\midrule
LG {\scriptsize(RL)} & \(0\) & \(16\) & \longcell{\(0.37\)\\{\tiny(\(0.06\))}} & \longcell{\(0.07\)\\{\tiny(\(0.01\))}} \\[2.2ex]
LG {\scriptsize(RL)} & \(0\) & \(64\) & \longcell{\(0.64\)\\{\tiny(\(0.09\))}} & \longcell{\(0.07\)\\{\tiny(\(0.01\))}} \\[2.2ex]
LG {\scriptsize(RL)} & \(0\) & \(256\) & \longcell{\(0.80\)\\{\tiny(\(0.04\))}} & \longcell{\(0.13\)\\{\tiny(\(0.01\))}} \\[2.2ex]
LG {\scriptsize(RL)} & \(0\) & \(1024\) & \longcell{\(0.88\)\\{\tiny(\(0.01\))}} & \longcell{\(0.14\)\\{\tiny(\(0.01\))}} \\[2.2ex]
NLG & \(0.5\) & \(16\) & \longcell{\(0.30\)\\{\tiny(\(0.05\))}} & \longcell{\(0.07\)\\{\tiny(\(0.01\))}} \\[2.2ex]
NLG & \(0.5\) & \(64\) & \longcell{\(0.54\)\\{\tiny(\(0.05\))}} & \longcell{\(0.07\)\\{\tiny(\(0.01\))}} \\[2.2ex]
NLG & \(0.5\) & \(256\) & \longcell{\(0.77\)\\{\tiny(\(0.04\))}} & \longcell{\(0.13\)\\{\tiny(\(0.01\))}} \\[2.2ex]
NLG & \(0.5\) & \(1024\) & \longcell{\(0.85\)\\{\tiny(\(0.03\))}} & \longcell{\(0.14\)\\{\tiny(\(0.02\))}} \\[2.2ex]
%MRILG & \(0.5\) & \(-0.2\) & \(16\) & \longcell{\(0.25\)\\{\tiny(\(0.14\))}} & \longcell{\(0.05\)\\{\tiny(\(0.03\))}} \\[2.2ex]
%MRILG & \(0.5\) & \(-0.2\) & \(64\) & \longcell{\(0.51\)\\{\tiny(\(0.19\))}} & \longcell{\(0.09\)\\{\tiny(\(0.03\))}} \\[2.2ex]
%MRILG & \(0.5\) & \(-0.2\) & \(256\) & \longcell{\(0.76\)\\{\tiny(\(0.05\))}} & \longcell{\(0.12\)\\{\tiny(\(0.02\))}} \\[2.2ex]
%MRILG & \(0.5\) & \(-0.2\) & \(1024\) & \longcell{\(0.86\)\\{\tiny(\(0.03\))}} & \longcell{\(0.13\)\\{\tiny(\(0.01\))}} \\
\bottomrule
\end{tabular}
\end{table*}

\begin{table*}[t]
\linespread{0.6}\selectfont\centering
\caption{Test accuracy, with SD, of every ETL task trained, using the CelebA dataset and over 10 seeds. We do not apply noise during ETL's train and test phase. During the LG training (before ETL), we fixed \(\lambda\) to \(0.5\).}
\label{table:compare_etl_cand_celeba}
\centering
\begin{tabular}[t]{lrrrrrrr}
\toprule
Game & \(\lambda\) & \(\nu\) & \multicolumn{1}{c}{\(|\sC|\)} & \multicolumn{4}{c}{ETL tasks} \\[1ex]\cmidrule(r){5-8}
 & & & & \multicolumn{1}{c}{Discrimination} & \multicolumn{1}{c}{Classification} & \multicolumn{1}{c}{Attribute} & \multicolumn{1}{c}{Reconstruction}\\
\midrule
LG {\scriptsize(RL)}  & \multicolumn{1}{c}{-}  & \multicolumn{1}{c}{-} & \(16\) & \longcell{\(0.17\)\\{\tiny(\(0.07\))}} & \longcell{\(0.00\)\\{\tiny(\(0.00\))}} & \longcell{\(0.85\)\\{\tiny(\(0.00\))}} & \longcell{\(6050\)\\{\tiny(\(50\))}} \\[2.2ex]
LG {\scriptsize(RL)}  & \multicolumn{1}{c}{-}  & \multicolumn{1}{c}{-} & \(64\) & \longcell{\(0.34\)\\{\tiny(\(0.11\))}} & \longcell{\(0.00\)\\{\tiny(\(0.00\))}} & \longcell{\(0.85\)\\{\tiny(\(0.00\))}} & \longcell{\(6012\)\\{\tiny(\(121\))}} \\[2.2ex]
LG {\scriptsize(RL)}  & \multicolumn{1}{c}{-}  & \multicolumn{1}{c}{-} & \(256\) & \longcell{\(0.48\)\\{\tiny(\(0.09\))}} & \longcell{\(0.00\)\\{\tiny(\(0.00\))}} & \longcell{\(0.86\)\\{\tiny(\(0.00\))}} & \longcell{\(5750\)\\{\tiny(\(1544\))}} \\[2.2ex]
LG {\scriptsize(RL)}  & \multicolumn{1}{c}{-}  & \multicolumn{1}{c}{-} & \(1024\) & \longcell{\(0.65\)\\{\tiny(\(0.09\))}} & \longcell{\(0.01\)\\{\tiny(\(0.00\))}} & \longcell{\(0.86\)\\{\tiny(\(0.00\))}} & \longcell{\(5633\)\\{\tiny(\(127\))}} \\[2.2ex]
NLG & \(0.5\) & \multicolumn{1}{c}{-} & \(16\) & \longcell{\(0.16\)\\{\tiny(\(0.06\))}} & \longcell{\(0.00\)\\{\tiny(\(0.00\))}} & \longcell{\(0.85\)\\{\tiny(\(0.00\))}} & \longcell{\(6071\)\\{\tiny(\(80\))}} \\[2.2ex]
NLG & \(0.5\) & \multicolumn{1}{c}{-} & \(64\) & \longcell{\(0.24\)\\{\tiny(\(0.08\))}} & \longcell{\(0.00\)\\{\tiny(\(0.00\))}} & \longcell{\(0.85\)\\{\tiny(\(0.00\))}} & \longcell{\(5992\)\\{\tiny(\(164\))}} \\[2.2ex]
NLG & \(0.5\) & \multicolumn{1}{c}{-} & \(256\) & \longcell{\(0.37\)\\{\tiny(\(0.10\))}} & \longcell{\(0.00\)\\{\tiny(\(0.00\))}} & \longcell{\(0.85\)\\{\tiny(\(0.00\))}} & \longcell{\(5815\)\\{\tiny(\(192\))}} \\[2.2ex]
NLG & \(0.5\) & \multicolumn{1}{c}{-} & \(1024\) & \longcell{\(0.54\)\\{\tiny(\(0.01\))}} & \longcell{\(0.00\)\\{\tiny(\(0.00\))}} & \longcell{\(0.85\)\\{\tiny(\(0.00\))}} & \longcell{\(5687\)\\{\tiny(\(157\))}} \\[2.2ex]
%MRILG & \(0.5\) & \(-0.2\) & \(16\) & \longcell{\(0.09\)\\{\tiny(\(0.05\))}} & \longcell{\(0.00\)\\{\tiny(\(0.00\))}} & \longcell{\(0.85\)\\{\tiny(\(0.00\))}} & \longcell{\(6179.81\)\\{\tiny(\(108.45\))}} \\[2.2ex]
%MRILG & \(0.5\) & \(-0.2\) & \(64\) & \longcell{\(0.20\)\\{\tiny(\(0.09\))}} & \longcell{\(0.00\)\\{\tiny(\(0.00\))}} & \longcell{\(0.85\)\\{\tiny(\(0.00\))}} & \longcell{\(6057.76\)\\{\tiny(\(205.67\))}} \\[2.2ex]
%MRILG & \(0.5\) & \(-0.2\) & \(256\) & \longcell{\(0.44\)\\{\tiny(\(0.12\))}} & \longcell{\(0.00\)\\{\tiny(\(0.00\))}} & \longcell{\(0.85\)\\{\tiny(\(0.00\))}} & \longcell{\(5696.28\)\\{\tiny(\(42.08\))}} \\[2.2ex]
%MRILG & \(0.5\) & \(-0.2\) & \(1024\) & \longcell{\(0.70\)\\{\tiny(\(0.02\))}} & \longcell{\(0.01\)\\{\tiny(\(0.00\))}} & \longcell{\(0.86\)\\{\tiny(\(0.00\))}} & \longcell{\(5571.15\)\\{\tiny(\(64.40\))}} \\
\bottomrule
\end{tabular}
%\vspace{-2ex}
\end{table*}

\begin{table*}[t]
\linespread{0.6}\selectfont\centering
\caption{Test accuracy, with SD, of every ETL task trained, using the ImageNet dataset and over 10 seeds. We fix the noise during ETL's train and test phase at \(0.5\). During the LG training (before ETL), we fixed \(\lambda\) to \(0.5\).}
\label{table:compare_etl_cand_imagenet_noise}
\centering
\begin{tabular}[t]{lrrrrr}
\toprule
Game & \multicolumn{1}{c}{\(\lambda\)} & \multicolumn{1}{c}{\(\nu\)} & \multicolumn{1}{c}{\(|\sC|\)} & \multicolumn{2}{c}{ETL tasks} \\[1ex]\cmidrule(r){5-6}
 & & & & \multicolumn{1}{c}{Discrimination} & \multicolumn{1}{c}{Classification} \\
\midrule
LG {\scriptsize(RL)} & \multicolumn{1}{c}{-}  & \multicolumn{1}{c}{-} & \(16\) & \longcell{\(0.11\)\\{\tiny(\(0.01\))}} & \longcell{\(0.04\)\\{\tiny(\(0.00\))}} \\[2.2ex]
LG {\scriptsize(RL)} & \multicolumn{1}{c}{-}  & \multicolumn{1}{c}{-} & \(64\) & \longcell{\(0.22\)\\{\tiny(\(0.03\))}} & \longcell{\(0.06\)\\{\tiny(\(0.01\))}} \\[2.2ex]
LG {\scriptsize(RL)} & \multicolumn{1}{c}{-}  & \multicolumn{1}{c}{-} & \(256\) & \longcell{\(0.31\)\\{\tiny(\(0.02\))}} & \longcell{\(0.06\)\\{\tiny(\(0.00\))}} \\[2.2ex]
LG {\scriptsize(RL)} & \multicolumn{1}{c}{-}  & \multicolumn{1}{c}{-} & \(1024\) & \longcell{\(0.36\)\\{\tiny(\(0.02\))}} & \longcell{\(0.07\)\\{\tiny(\(0.00\))}} \\[2.2ex]
NLG & \(0.5\) & \multicolumn{1}{c}{-} & \(16\) & \longcell{\(0.13\)\\{\tiny(\(0.02\))}} & \longcell{\(0.04\)\\{\tiny(\(0.00\))}} \\[2.2ex]
NLG & \(0.5\) & \multicolumn{1}{c}{-} & \(64\) & \longcell{\(0.23\)\\{\tiny(\(0.02\))}} & \longcell{\(0.04\)\\{\tiny(\(0.00\))}} \\[2.2ex]
NLG & \(0.5\) & \multicolumn{1}{c}{-} & \(256\) & \longcell{\(0.35\)\\{\tiny(\(0.02\))}} & \longcell{\(0.08\)\\{\tiny(\(0.00\))}} \\[2.2ex]
NLG & \(0.5\) & \multicolumn{1}{c}{-} & \(1024\) & \longcell{\(0.41\)\\{\tiny(\(0.02\))}} & \longcell{\(0.08\)\\{\tiny(\(0.01\))}} \\[2.2ex]
%MRILG & \(0.5\) & \(-0.2\) & \(16\) & \longcell{\(0.11\)\\{\tiny(\(0.06\))}} & \longcell{\(0.03\)\\{\tiny(\(0.02\))}} \\[2.2ex]
%MRILG & \(0.5\) & \(-0.2\) & \(64\) & \longcell{\(0.21\)\\{\tiny(\(0.08\))}} & \longcell{\(0.05\)\\{\tiny(\(0.02\))}} \\[2.2ex]
%MRILG & \(0.5\) & \(-0.2\) & \(256\) & \longcell{\(0.35\)\\{\tiny(\(0.03\))}} & \longcell{\(0.07\)\\{\tiny(\(0.01\))}} \\[2.2ex]
%MRILG & \(0.5\) & \(-0.2\) & \(1024\) & \longcell{\(0.41\)\\{\tiny(\(0.01\))}} & \longcell{\(0.07\)\\{\tiny(\(0.01\))}} \\
\bottomrule
\end{tabular}
\end{table*}

\begin{table*}[t]
\linespread{0.6}\selectfont\centering
\caption{Test accuracy, with SD, of every ETL task trained, using the CelebA dataset and over 10 seeds. We fix the noise during ETL's train and test phase at \(0.5\). During the LG training (before ETL), we fixed \(\lambda\) to \(0.5\).}
\label{table:compare_etl_cand_celeba_noise}
\centering
\begin{tabular}[t]{lrrrrrrr}
\toprule
Game & \(\lambda\) & \(\nu\) & \multicolumn{1}{c}{\(|\sC|\)} & \multicolumn{4}{c}{ETL tasks} \\[1ex]\cmidrule(r){5-8}
 & & & & \multicolumn{1}{c}{Discrimination} & \multicolumn{1}{c}{Classification} & \multicolumn{1}{c}{Attribute} & \multicolumn{1}{c}{Reconstruction}\\
\midrule
LG {\scriptsize(RL)} & \(0\) & \multicolumn{1}{c}{-} & \(16\) & \longcell{\(0.06\)\\{\tiny(\(0.02\))}} & \longcell{\(0.00\)\\{\tiny(\(0.00\))}} & \longcell{\(0.85\)\\{\tiny(\(0.00\))}} & \longcell{\(6210\)\\{\tiny(\(53\))}} \\[2.2ex]
LG {\scriptsize(RL)} & \(0\) & \multicolumn{1}{c}{-} & \(64\) & \longcell{\(0.13\)\\{\tiny(\(0.03\))}} & \longcell{\(0.00\)\\{\tiny(\(0.00\))}} & \longcell{\(0.85\)\\{\tiny(\(0.00\))}} & \longcell{\(6061\)\\{\tiny(\(140\))}} \\[2.2ex]
LG {\scriptsize(RL)} & \(0\) & \multicolumn{1}{c}{-} & \(256\) & \longcell{\(0.19\)\\{\tiny(\(0.03\))}} & \longcell{\(0.00\)\\{\tiny(\(0.00\))}} & \longcell{\(0.85\)\\{\tiny(\(0.00\))}} & \longcell{\(5896\)\\{\tiny(\(117\))}} \\[2.2ex]
LG {\scriptsize(RL)} & \(0\) & \multicolumn{1}{c}{-} & \(1024\) & \longcell{\(0.26\)\\{\tiny(\(0.03\))}} & \longcell{\(0.00\)\\{\tiny(\(0.00\))}} & \longcell{\(0.85\)\\{\tiny(\(0.00\))}} & \longcell{\(5871\)\\{\tiny(\(155\))}} \\[2.2ex]
NLG & \(0.5\) & \multicolumn{1}{c}{-} & \(16\) & \longcell{\(0.06\)\\{\tiny(\(0.02\))}} & \longcell{\(0.00\)\\{\tiny(\(0.00\))}} & \longcell{\(0.85\)\\{\tiny(\(0.00\))}} & \longcell{\(6196\)\\{\tiny(\(73\))}} \\[2.2ex]
NLG & \(0.5\) & \multicolumn{1}{c}{-} & \(64\) & \longcell{\(0.11\)\\{\tiny(\(0.04\))}} & \longcell{\(0.00\)\\{\tiny(\(0.00\))}} & \longcell{\(0.85\)\\{\tiny(\(0.00\))}} & \longcell{\(6096\)\\{\tiny(\(110\))}} \\[2.2ex]
NLG & \(0.5\) & \multicolumn{1}{c}{-} & \(256\) & \longcell{\(0.20\)\\{\tiny(\(0.04\))}} & \longcell{\(0.00\)\\{\tiny(\(0.00\))}} & \longcell{\(0.85\)\\{\tiny(\(0.00\))}} & \longcell{\(5968\)\\{\tiny(\(160\))}} \\[2.2ex]
NLG & \(0.5\) & \multicolumn{1}{c}{-} & \(1024\) & \longcell{\(0.31\)\\{\tiny(\(0.04\))}} & \longcell{\(0.00\)\\{\tiny(\(0.00\))}} & \longcell{\(0.85\)\\{\tiny(\(0.00\))}} & \longcell{\(5833\)\\{\tiny(\(103\))}} \\[2.2ex]
%MRILG & \(0.5\) & \(-0.2\) & \(16\) & \longcell{\(0.07\)\\{\tiny(\(0.03\))}} & \longcell{\(0.00\)\\{\tiny(\(0.00\))}} & \longcell{\(0.85\)\\{\tiny(\(0.00\))}} & \longcell{\(6203\)\\{\tiny(\(76\))}} \\[2.2ex]
%MRILG & \(0.5\) & \(-0.2\) & \(64\) & \longcell{\(0.12\)\\{\tiny(\(0.05\))}} & \longcell{\(0.00\)\\{\tiny(\(0.00\))}} & \longcell{\(0.85\)\\{\tiny(\(0.00\))}} & \longcell{\(6116\)\\{\tiny(\(234\))}} \\[2.2ex]
%MRILG & \(0.5\) & \(-0.2\) & \(256\) & \longcell{\(0.25\)\\{\tiny(\(0.04\))}} & \longcell{\(0.00\)\\{\tiny(\(0.00\))}} & \longcell{\(0.85\)\\{\tiny(\(0.00\))}} & \longcell{\(5844\)\\{\tiny(\(92\))}} \\[2.2ex]
%MRILG & \(0.5\) & \(-0.2\) & \(1024\) & \longcell{\(0.30\)\\{\tiny(\(0.06\))}} & \longcell{\(0.00\)\\{\tiny(\(0.00\))}} & \longcell{\(0.85\)\\{\tiny(\(0.00\))}} & \longcell{\(5820\)\\{\tiny(\(85\))}} \\
\bottomrule
\end{tabular}
%\vspace{-2ex}
\end{table*}

\subsubsection{Particular Analysis of the Classification Task} \label{app:etl-classif-analysis}
To conclude the ETL study, we now focus on the Classification task for both datasets (ImageNet and CelebA). In all experiments, the test accuracy is not higher than \(0.15\) and \(0.01\) when considering the ImageNet and CelebA datasets, respectively. We argue that this outcome is a consequence of the encoding qualities of the communication protocol. With these results, there is strong evidence that the emerged communication protocol does not encode any particular information about the class of each image since such information is irrelevant to solve the original setting (discriminating between images). Therefore, since the Listener architecture for the Classification task only receives the message sent by the Speaker as input, and it has no helpful information to solve the task.
%[TALK ABOUT OVERFITTING? - IF SO, NEED TO SHOW GRAPHS FOR TRAIN].

\begin{figure*}[!t]
    \begin{center}
    \begin{subfigure}{1.\textwidth}
      \centering
      \centerline{\includegraphics[width=1.02\linewidth]{figures/reconstruct/original.pdf}}
      \caption{Original CelebA images, randomly selected.}
      \label{fig:etl-reconstruct-original-ss}
    \end{subfigure}
    %
    \begin{subfigure}{1\textwidth}
      \centering
      \centerline{\includegraphics[width=1.02\linewidth]{figures/reconstruct/lg-rlss-0.0-0.0.pdf}}
      \caption{LG (S), train/test ETL Reconstruction task without noise.}
      \label{fig:etl-reconstruct-lg-ss}
    \end{subfigure}
    %
    \begin{subfigure}{1\textwidth}
    \centering
    \centerline{\includegraphics[width=1.02\linewidth]{figures/reconstruct/lg-rlss-0.0-0.25.pdf}}
    \caption{LG (S), train/test ETL Reconstruction task with a noise level of \(0.25\).}
    \label{fig:etl-reconstruct-lg-ss-0.25}
    \end{subfigure}
    %
    \begin{subfigure}{1\textwidth}
    \centering
    \centerline{\includegraphics[width=1.02\linewidth]{figures/reconstruct/lg-rlss-0.0-0.50.pdf}}
    \caption{LG (S), train/test ETL Reconstruction task with a noise level of \(0.5\).}
    \label{fig:etl-reconstruct-lg-ss-0.5}
    \end{subfigure}
    %
    \begin{subfigure}{1\textwidth}
    \centering
    \centerline{\includegraphics[width=1.02\linewidth]{figures/reconstruct/lg-rlss-0.0-0.75.pdf}}
    \caption{LG (S), train/test ETL Reconstruction task with a noise level of \(0.75\).}
    \label{fig:etl-reconstruct-lg-ss-0.75}
    \end{subfigure}
    %
    \end{center}
    \caption{Random outputs of ETL's Reconstruction task when using a Speaker trained in the LG (S). We report reconstructions when training and testing without (\Cref{sub@fig:etl-reconstruct-lg-ss}) and with noise (\Cref{sub@fig:etl-reconstruct-lg-ss-0.25,sub@fig:etl-reconstruct-lg-ss-0.5,sub@fig:etl-reconstruct-lg-ss-0.75}), in the ETL task. The faces shown in each column are a reconstruction of the original images available in the matching columns of \Cref{sub@fig:etl-reconstruct-original-ss}.}
    \label{fig:etl-reconstruct-all-lg-s}
    \vspace{-2ex}
\end{figure*}

\begin{figure*}[!t]
    \begin{center}
    \begin{subfigure}{1.\textwidth}
      \centering
      \centerline{\includegraphics[width=1.02\linewidth]{figures/reconstruct/original.pdf}}
      \caption{Original CelebA images, randomly selected.}
      \label{fig:etl-reconstruct-original-rl}
    \end{subfigure}
    %
    \begin{subfigure}{1\textwidth}
        \centering
        \centerline{\includegraphics[width=1.02\linewidth]{figures/reconstruct/lg-rlrl-0.0-0.0.pdf}}
        \caption{LG (RL), train/test ETL Reconstruction task without noise.}
        \label{fig:etl-reconstruct-lg-rl}
    \end{subfigure}
    %
    \begin{subfigure}{1\textwidth}
      \centering
      \centerline{\includegraphics[width=1.02\linewidth]{figures/reconstruct/lg-rlrl-0.0-0.25.pdf}}
      \caption{LG (RL), train/test ETL Reconstruction task with a noise level of \(0.25\).}
      \label{fig:etl-reconstruct-lg-rl-0.25}
    \end{subfigure}
    %
    \begin{subfigure}{1\textwidth}
      \centering
      \centerline{\includegraphics[width=1.02\linewidth]{figures/reconstruct/lg-rlrl-0.0-0.50.pdf}}
      \caption{LG (RL), train/test ETL Reconstruction task with a noise level of \(0.5\).}
      \label{fig:etl-reconstruct-lg-rl-0.5}
    \end{subfigure}
    %
    \begin{subfigure}{1\textwidth}
      \centering
      \centerline{\includegraphics[width=1.02\linewidth]{figures/reconstruct/lg-rlrl-0.0-0.75.pdf}}
      \caption{LG (RL), train/test ETL Reconstruction task with a noise level of \(0.75\).}
      \label{fig:etl-reconstruct-lg-rl-0.75}
    \end{subfigure}
    \end{center}
    \caption{Random outputs of ETL's Reconstruction task when using a Speaker trained in the LG (RL). We report reconstructions when training and testing without (\Cref{sub@fig:etl-reconstruct-lg-rl}) and with noise (\Cref{sub@fig:etl-reconstruct-lg-rl-0.25,sub@fig:etl-reconstruct-lg-rl-0.5,sub@fig:etl-reconstruct-lg-rl-0.75}), in the ETL task. The faces shown in each column are a reconstruction of the original images available in the matching columns of \Cref{sub@fig:etl-reconstruct-original-rl}.}
    \label{fig:etl-reconstruct-all-lg-rl}
    \vspace{-2ex}
\end{figure*}

\begin{figure*}[!t]
    \begin{center}
    \begin{subfigure}{1.\textwidth}
      \centering
      \centerline{\includegraphics[width=1.02\linewidth]{figures/reconstruct/original.pdf}}
      \caption{Original CelebA images, randomly selected.}
      \label{fig:etl-nlg-reconstruct-original}
    \end{subfigure}
    %
    \begin{subfigure}{1\textwidth}
      \centering
      \centerline{\includegraphics[width=1.02\linewidth]{figures/reconstruct/nlg-rlrl-0.25-0.0.pdf}}
      \caption{NLG with \(\lambda=0.25\), train/test ETL Reconstruction task without noise.}
      \label{fig:etl-reconstruct-nlg-0.25}
    \end{subfigure}
    %
    \begin{subfigure}{1\textwidth}
      \centering
      \centerline{\includegraphics[width=1.02\linewidth]{figures/reconstruct/nlg-rlrl-0.25-0.25.pdf}}
      \caption{NLG with \(\lambda=0.25\), train/test ETL Reconstruction task with a noise level of \(0.25\).}
      \label{fig:etl-reconstruct-nlg-0.25-0.25}
    \end{subfigure}
    %
    \begin{subfigure}{1\textwidth}
      \centering
      \centerline{\includegraphics[width=1.02\linewidth]{figures/reconstruct/nlg-rlrl-0.5-0.0.pdf}}
      \caption{NLG with \(\lambda=0.5\), train/test ETL Reconstruction task without noise.}
      \label{fig:etl-reconstruct-nlg-0.5}
    \end{subfigure}
    %
    \begin{subfigure}{1\textwidth}
      \centering
      \centerline{\includegraphics[width=1.02\linewidth]{figures/reconstruct/nlg-rlrl-0.5-0.5.pdf}}
      \caption{NLG with \(\lambda=0.5\), train/test ETL Reconstruction task with a noise level of \(0.75\).}
      \label{fig:etl-reconstruct-nlg-0.5-0.5}
    \end{subfigure}
    %
    \begin{subfigure}{1\textwidth}
      \centering
      \centerline{\includegraphics[width=1.02\linewidth]{figures/reconstruct/nlg-rlrl-0.75-0.0.pdf}}
      \caption{NLG with \(\lambda=0.75\), train/test ETL Reconstruction task without noise.}
      \label{fig:etl-reconstruct-nlg-0.75}
    \end{subfigure}
    %
    \begin{subfigure}{1\textwidth}
      \centering
      \centerline{\includegraphics[width=1.02\linewidth]{figures/reconstruct/nlg-rlrl-0.75-0.75.pdf}}
      \caption{NLG with \(\lambda=0.75\), train/test ETL Reconstruction task with a noise level of \(0.25\).}
      \label{fig:etl-reconstruct-nlg-0.75-0.75}
    \end{subfigure}
    \end{center}
    \caption{Random outputs of ETL's Reconstruction task when using a Speaker trained in the NLG. We report reconstructions when training and testing without (\Cref{sub@fig:etl-reconstruct-nlg-0.25,sub@fig:etl-reconstruct-nlg-0.5,sub@fig:etl-reconstruct-nlg-0.75}) and with noise (\Cref{sub@fig:etl-reconstruct-nlg-0.25-0.25,sub@fig:etl-reconstruct-nlg-0.5-0.5,sub@fig:etl-reconstruct-nlg-0.75-0.75}), in the ETL task. The faces shown in each column are a reconstruction of the original images available in the matching column of \Cref{sub@fig:etl-nlg-reconstruct-original}.}
    \label{fig:etl-reconstruct-all-nlg}
    \vspace{-2ex}
\end{figure*}

\begin{comment}
\begin{figure}[!t]
    \begin{center}
    \begin{subfigure}{1.\textwidth}
      \centering
      \centerline{\includegraphics[width=1.02\linewidth]{figures/reconstruct/original.pdf}}
      \caption{Original CelebA images, randomly selected.}
      \label{fig:etl-mrilg-0.25-reconstruct-original}
    \end{subfigure}
    %
    \begin{subfigure}{1\textwidth}
      \centering
      \centerline{\includegraphics[width=1.02\linewidth]{figures/reconstruct/mrilg-rlrl-0.25-0.0--0.5.pdf}}
      \caption{MRILG with \(\lambda=0.25\) and \(\nu=-0.5\), train/test ETL Reconstruction task without noise.}
      \label{fig:etl-reconstruct-mrilg-0.25-0.0--0.5}
    \end{subfigure}
    %
    \begin{subfigure}{1\textwidth}
      \centering
      \centerline{\includegraphics[width=1.02\linewidth]{figures/reconstruct/mrilg-rlrl-0.25-0.25--0.5.pdf}}
      \caption{MRILG with \(\lambda=0.25\) and \(\nu=-0.5\), train/test ETL Reconstruction task with a noise level of \(0.25\).}
      \label{fig:etl-reconstruct-mrilg-0.25-0.25--0.5}
    \end{subfigure}
    %
    \begin{subfigure}{1\textwidth}
      \centering
      \centerline{\includegraphics[width=1.02\linewidth]{figures/reconstruct/mrilg-rlrl-0.25-0.0--0.2.pdf}}
      \caption{MRILG with \(\lambda=0.25\) and \(\nu=-0.2\), train/test ETL Reconstruction task without noise.}
      \label{fig:etl-reconstruct-mrilg-0.25-0.0--0.2}
    \end{subfigure}
    %
    \begin{subfigure}{1\textwidth}
      \centering
      \centerline{\includegraphics[width=1.02\linewidth]{figures/reconstruct/mrilg-rlrl-0.25-0.25--0.2.pdf}}
      \caption{MRILG with \(\lambda=0.25\) and \(\nu=-0.2\), train/test ETL Reconstruction task with a noise level of \(0.25\).}
      \label{fig:etl-reconstruct-mrilg-0.25-0.25--0.2}
    \end{subfigure}
    %
    \begin{subfigure}{1\textwidth}
      \centering
      \centerline{\includegraphics[width=1.02\linewidth]{figures/reconstruct/mrilg-rlrl-0.25-0.0--0.05.pdf}}
      \caption{MRILG with \(\lambda=0.25\) and \(\nu=-0.05\), train/test ETL Reconstruction task without noise.}
      \label{fig:etl-reconstruct-mrilg-0.25-0.0--0.05}
    \end{subfigure}
    %
    \begin{subfigure}{1\textwidth}
      \centering
      \centerline{\includegraphics[width=1.02\linewidth]{figures/reconstruct/mrilg-rlrl-0.25-0.25--0.05.pdf}}
      \caption{MRILG with \(\lambda=0.25\) and \(\nu=-0.05\), train/test ETL Reconstruction task with a noise level of \(0.25\).}
      \label{fig:etl-reconstruct-mrilg-0.25-0.25--0.05}
    \end{subfigure}
    \end{center}
    \caption{Random outputs of ETL's Reconstruction task when using a Speaker trained in the MRILG, with noise \(\lambda=0.25\). We report reconstructions when training and testing without (\Cref{sub@fig:etl-reconstruct-mrilg-0.25-0.0--0.5,sub@fig:etl-reconstruct-mrilg-0.25-0.0--0.2,sub@fig:etl-reconstruct-mrilg-0.25-0.0--0.05}) and with noise (\Cref{sub@fig:etl-reconstruct-mrilg-0.25-0.25--0.5,sub@fig:etl-reconstruct-mrilg-0.25-0.25--0.2,sub@fig:etl-reconstruct-mrilg-0.25-0.25--0.05}), in the ETL task. The faces shown in each column are a reconstruction of the original images available in the matching column of \Cref{sub@fig:etl-mrilg-0.25-reconstruct-original}.}
    \label{fig:etl-reconstruct-mrilg-0.25}
    \vspace{-2ex}
\end{figure}

\begin{figure}[!t]
    \begin{center}
    \begin{subfigure}{1.\textwidth}
      \centering
      \centerline{\includegraphics[width=1.02\linewidth]{figures/reconstruct/original.pdf}}
      \caption{Original CelebA images, randomly selected.}
      \label{fig:etl-mrilg-0.5-reconstruct-original}
    \end{subfigure}
    %
    \begin{subfigure}{1\textwidth}
      \centering
      \centerline{\includegraphics[width=1.02\linewidth]{figures/reconstruct/mrilg-rlrl-0.5-0.0--0.5.pdf}}
      \caption{MRILG with \(\lambda=0.5\) and \(\nu=-0.5\), train/test ETL Reconstruction task without noise.}
      \label{fig:etl-reconstruct-mrilg-0.5-0.0--0.5}
    \end{subfigure}
    %
    \begin{subfigure}{1\textwidth}
      \centering
      \centerline{\includegraphics[width=1.02\linewidth]{figures/reconstruct/mrilg-rlrl-0.5-0.5--0.5.pdf}}
      \caption{MRILG with \(\lambda=0.5\) and \(\nu=-0.5\), train/test ETL Reconstruction task with a noise level of \(0.5\).}
      \label{fig:etl-reconstruct-mrilg-0.5-0.5--0.5}
    \end{subfigure}
    %
    \begin{subfigure}{1\textwidth}
      \centering
      \centerline{\includegraphics[width=1.02\linewidth]{figures/reconstruct/mrilg-rlrl-0.5-0.0--0.2.pdf}}
      \caption{MRILG with \(\lambda=0.5\) and \(\nu=-0.2\), train/test ETL Reconstruction task without noise.}
      \label{fig:etl-reconstruct-mrilg-0.5-0.0--0.2}
    \end{subfigure}
    %
    \begin{subfigure}{1\textwidth}
      \centering
      \centerline{\includegraphics[width=1.02\linewidth]{figures/reconstruct/mrilg-rlrl-0.5-0.5--0.2.pdf}}
      \caption{MRILG with \(\lambda=0.5\) and \(\nu=-0.2\), train/test ETL Reconstruction task with a noise level of \(0.5\).}
      \label{fig:etl-reconstruct-mrilg-0.5-0.5--0.2}
    \end{subfigure}
    %
    \begin{subfigure}{1\textwidth}
      \centering
      \centerline{\includegraphics[width=1.02\linewidth]{figures/reconstruct/mrilg-rlrl-0.5-0.0--0.05.pdf}}
      \caption{MRILG with \(\lambda=0.5\) and \(\nu=-0.05\), train/test ETL Reconstruction task without noise.}
      \label{fig:etl-reconstruct-mrilg-0.5-0.0--0.05}
    \end{subfigure}
    %
    \begin{subfigure}{1\textwidth}
      \centering
      \centerline{\includegraphics[width=1.02\linewidth]{figures/reconstruct/mrilg-rlrl-0.5-0.5--0.05.pdf}}
      \caption{MRILG with \(\lambda=0.5\) and \(\nu=-0.05\), train/test ETL Reconstruction task with a noise level of \(0.5\).}
      \label{fig:etl-reconstruct-mrilg-0.5-0.5--0.05}
    \end{subfigure}
    \end{center}
    \caption{Random outputs of ETL's Reconstruction task when using a Speaker trained in the MRILG, with noise \(\lambda=0.25\). We report reconstructions when training and testing without (\Cref{sub@fig:etl-reconstruct-mrilg-0.5-0.0--0.5,sub@fig:etl-reconstruct-mrilg-0.5-0.0--0.2,sub@fig:etl-reconstruct-mrilg-0.5-0.0--0.05}) and with noise (\Cref{sub@fig:etl-reconstruct-mrilg-0.5-0.5--0.5,sub@fig:etl-reconstruct-mrilg-0.5-0.5--0.2,sub@fig:etl-reconstruct-mrilg-0.5-0.5--0.05}), in the ETL task. The faces shown in each column are a reconstruction of the original images available in the matching column of \Cref{sub@fig:etl-mrilg-0.5-reconstruct-original}.}
    \label{fig:etl-reconstruct-mrilg-0.5}
    \vspace{-2ex}
\end{figure}

\begin{figure}[!t]
    \begin{center}
    \begin{subfigure}{1.\textwidth}
      \centering
      \centerline{\includegraphics[width=1.02\linewidth]{figures/reconstruct/original.pdf}}
      \caption{Original CelebA images, randomly selected.}
      \label{fig:etl-mrilg-0.75-reconstruct-original}
    \end{subfigure}
    %
    \begin{subfigure}{1\textwidth}
      \centering
      \centerline{\includegraphics[width=1.02\linewidth]{figures/reconstruct/mrilg-rlrl-0.75-0.0--0.5.pdf}}
      \caption{MRILG with \(\lambda=0.75\) and \(\nu=-0.5\), train/test ETL Reconstruction task without noise.}
      \label{fig:etl-reconstruct-mrilg-0.75-0.0--0.5}
    \end{subfigure}
    %
    \begin{subfigure}{1\textwidth}
      \centering
      \centerline{\includegraphics[width=1.02\linewidth]{figures/reconstruct/mrilg-rlrl-0.75-0.75--0.5.pdf}}
      \caption{MRILG with \(\lambda=0.75\) and \(\nu=-0.5\), train/test ETL Reconstruction task with a noise level of \(0.5\).}
      \label{fig:etl-reconstruct-mrilg-0.75-0.75--0.5}
    \end{subfigure}
    %
    \begin{subfigure}{1\textwidth}
      \centering
      \centerline{\includegraphics[width=1.02\linewidth]{figures/reconstruct/mrilg-rlrl-0.75-0.0--0.2.pdf}}
      \caption{MRILG with \(\lambda=0.75\) and \(\nu=-0.2\), train/test ETL Reconstruction task without noise.}
      \label{fig:etl-reconstruct-mrilg-0.75-0.0--0.2}
    \end{subfigure}
    %
    \begin{subfigure}{1\textwidth}
      \centering
      \centerline{\includegraphics[width=1.02\linewidth]{figures/reconstruct/mrilg-rlrl-0.75-0.75--0.2.pdf}}
      \caption{MRILG with \(\lambda=0.75\) and \(\nu=-0.2\), train/test ETL Reconstruction task with a noise level of \(0.75\).}
      \label{fig:etl-reconstruct-mrilg-0.75-0.75--0.2}
    \end{subfigure}
    %
    \begin{subfigure}{1\textwidth}
      \centering
      \centerline{\includegraphics[width=1.02\linewidth]{figures/reconstruct/mrilg-rlrl-0.75-0.0--0.05.pdf}}
      \caption{MRILG with \(\lambda=0.75\) and \(\nu=-0.05\), train/test ETL Reconstruction task without noise.}
      \label{fig:etl-reconstruct-mrilg-0.75-0.0--0.05}
    \end{subfigure}
    %
    \begin{subfigure}{1\textwidth}
      \centering
      \centerline{\includegraphics[width=1.02\linewidth]{figures/reconstruct/mrilg-rlrl-0.75-0.75--0.05.pdf}}
      \caption{MRILG with \(\lambda=0.75\) and \(\nu=-0.05\), train/test ETL Reconstruction task with a noise level of \(0.75\).}
      \label{fig:etl-reconstruct-mrilg-0.75-0.75--0.05}
    \end{subfigure}
    \end{center}
    \caption{Random outputs of ETL's Reconstruction task when using a Speaker trained in the MRILG, with noise \(\lambda=0.25\). We report reconstructions when training and testing without (\Cref{sub@fig:etl-reconstruct-mrilg-0.75-0.0--0.5,sub@fig:etl-reconstruct-mrilg-0.75-0.0--0.2,sub@fig:etl-reconstruct-mrilg-0.75-0.0--0.05}) and with noise (\Cref{sub@fig:etl-reconstruct-mrilg-0.75-0.75--0.5,sub@fig:etl-reconstruct-mrilg-0.75-0.75--0.2,sub@fig:etl-reconstruct-mrilg-0.75-0.75--0.05}), in the ETL task. The faces shown in each column are a reconstruction of the original images available in the matching column of \Cref{sub@fig:etl-mrilg-0.75-reconstruct-original}.}
    \label{fig:etl-reconstruct-mrilg-0.75}
    \vspace{-2ex}
\end{figure}
\end{comment}

\input{tables/etl_imagenet_0_eval}

\input{tables/etl_celeba_0_eval}

\input{tables/etl_imagenet_025_eval}

\input{tables/etl_celeba_025_eval}

\input{tables/etl_imagenet_05_eval}

\input{tables/etl_celeba_05_eval}

\input{tables/etl_imagenet_075_eval}

\input{tables/etl_celeba_075_eval}

\section{Additional Results}
Continuing the evaluation present in \Cref{sec:eval}, we present all tests performed for each LG variants with different hyperparameters, see \Cref{table:lg_imagenet_0_test_reward,table:lg_celeba_0_test_reward,table:lg_imagenet_025_test_reward,table:lg_celeba_025_test_reward,table:lg_imagenet_05_test_reward,table:lg_celeba_05_test_reward,table:lg_imagenet_075_test_reward,table:lg_celeba_075_test_reward}.

\input{tables/lg_imagenet_0_test_reward}

\input{tables/lg_celeba_0_test_reward}

\input{tables/lg_imagenet_025_test_reward}

\input{tables/lg_celeba_025_test_reward}

\input{tables/lg_imagenet_05_test_reward}

\input{tables/lg_celeba_05_test_reward}

\input{tables/lg_imagenet_075_test_reward}

\input{tables/lg_celeba_075_test_reward}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
