\section{Related Work}
% Your literature review goes here
\subsection{Emotion Annotation}

Annotating human emotions has consistently been a challenging task~\cite{8764449}, not only due to the inherent complexity of emotions~\cite{5771357} but also because annotators may have varying evaluation standards (or subjectivity)~\cite{10416364,10150364}. A significant issue in emotion annotation is the annotation method. Although the most reliable annotation standard requires individuals to perform the annotations themselves, real-time self-annotation can lead to distraction and affect the expression of emotions~\cite{devillers2005challenges}. On the other hand, retrospective annotation relies on individuals' recollections~\cite{10.1145/2971485.2971516,7160695}, which may lead to bias~\cite{hoelzemann2024matter} as well as high cost~\cite{10.1145/3491102.3517453}, and can cause embarrassment~\cite{afzal2011natural}. Another widely used annotation method involves external annotators observing and labeling human emotions~\cite{8854185}. By leveraging human cognition and understanding, and considering the context, external annotators provide reliable emotional labels based on various cues~\cite{troiano2023dimensional}. Although these two annotation methods can be combined~\cite{10494076}, they may not be suitable for large-scale data processing. Regardless, emotion annotation remains a labor-intensive task. Therefore, exploring more efficient emotion annotation methods is crucial.

Currently, many annotation methods involve semi-automated or automated labeling conducted by models~\cite{10253654,10701433,10.1145/2912147,7112127,sharma2020automated,devillers2005challenges,9158345}, which greatly improves annotation efficiency. However, such annotations are typically built upon prior preparations, meaning that before the annotation task begins, data with emotion annotations are still required to train the underlying annotation models~\cite{you2016building}. Furthermore, in some specific tasks, these labels cannot be easily shared due to task constraints, but instead require the preparation of pre-trained data that suits specific scenarios~\cite{nimmi2022pre}. This implies that the traditional challenges in annotation tasks still persist.

Another important issue in emotion annotation is the choice of emotion classification scheme. Considering that annotation is a time-consuming and laborious process, researchers often categorize emotions based on task requirements to reduce the difficulty of annotation and improve efficiency. Examples include categorizing emotions into positive and negative~\cite{1034632}, emotional and neutral states~\cite{batliner2003find}, classifying specific emotions by their intensities~\cite{10494076}, and using basic emotions~\cite{10.1145/3629606.3629646,5585726}. In this study, we consider the potential task requirements of these various classification standards and base our research based on the available ground truth emotion labels.


\subsection{LLM for Annotation}

The emergence and application of LLMs have introduced unprecedented opportunities in the field of data annotation. An increasing number of researchers and practitioners have recognized the vast potential of LLMs for enhancing annotation processes~\cite{pmlr-v239-mohta23a}. As researchers continue to explore and leverage the advancing capabilities of LLMs, particularly in multimodal interactions~\cite{zhang2024mmllmsrecentadvancesmultimodal} and improvements in processing power~\cite{10.1145/3442188.3445922}, the range of annotation tasks has expanded significantly. These tasks now encompass various data types, including text \cite{10.1145/3637528.3671552}, audio \cite{10447760}, images \cite{cheng2024emotion, sapkota2024zero}, and specialized domain-specific data \cite{tang2024pdfchatannotator, zhang2024qualitativeresearchmeetslarge}.

A recent survey has shed light on current trends and leading research in the application of LLMs for annotation tasks \cite{tan-etal-2024-large}. Within the scope of our study, which focuses on emotion annotation for image data, related work has explored various capabilities of LLMs. For instance, researchers have evaluated the ability of LLMs to predict emotions from captions generated from images-derived captions~\cite{10388198}, perform image retrieval \cite{10.1145/3626772.3657740}, and generate descriptive captions \cite{shvetsova2025howtocaption}. Notably, in early 2024, a study compared the performance of LLMs such as GPT-3.5, GPT-4, and Bard against traditional supervised models like Convolutional Neural Networks (CNNs) for emotion recognition in image data \cite{nadeem2024vision}. The findings revealed that deep learning models specifically trained for this task generally achieved higher accuracy than LLMs.

However, despite the superior accuracy of traditional supervised models, they also present significant limitations. Nonetheless, LLMs offer the potential to achieve performance that is comparable to traditional models while reducing training and application costs. Therefore, in this study, we further optimized prompt engineering and reorganized annotation strategies to harness the capabilities and advantages of LLMs. 

%