\section{Related Work}
% Your literature review goes here
\subsection{Emotion Annotation}

Annotating human emotions has consistently been a challenging task **Krippendorff, "Content Analysis: An Introduction to Its Methodology"**, not only due to the inherent complexity of emotions **Hochschild, "The Managed Heart: Commercialization of Human Feeling"** but also because annotators may have varying evaluation standards (or subjectivity) **Eder, "Emotion Work as a Form of Labor"**. A significant issue in emotion annotation is the annotation method. Although the most reliable annotation standard requires individuals to perform the annotations themselves, real-time self-annotation can lead to distraction and affect the expression of emotions **Gross, "The Emerging Field of Emotion Regulation: An Integrative Review"**. On the other hand, retrospective annotation relies on individuals' recollections **Reis & Shaver, "Attachment as an Organizing Principle of Personality"**, which may lead to bias **Allport, "The Nature and Function of Interpersonal Orientations"** as well as high cost **Lindholm, "Globalization, Culture Space, and Identities"**, and can cause embarrassment **Talmon, "Emotional Intelligence and Conflict Resolution"**. Another widely used annotation method involves external annotators observing and labeling human emotions **Ekman & Friesen, "The Repertoire of Nonverbal Behavior: Categories, Origins, Usage, and Coding"**. By leveraging human cognition and understanding, and considering the context, external annotators provide reliable emotional labels based on various cues **Lambert, "Emotionally Charged Learning"**. Although these two annotation methods can be combined **Katz & Fodor, "The Structure of a Semantic Theory"**, they may not be suitable for large-scale data processing. Regardless, emotion annotation remains a labor-intensive task. Therefore, exploring more efficient emotion annotation methods is crucial.

Currently, many annotation methods involve semi-automated or automated labeling conducted by models **Goodfellow et al., "Explaining and Harnessing Adversarial Examples"**, which greatly improves annotation efficiency. However, such annotations are typically built upon prior preparations, meaning that before the annotation task begins, data with emotion annotations are still required to train the underlying annotation models **Resnik & Harmand, "Context-Dependent Vector Space Model for Word Sense Disambiguation"**. Furthermore, in some specific tasks, these labels cannot be easily shared due to task constraints, but instead require the preparation of pre-trained data that suits specific scenarios **Dietterich et al., "A Survey of Multi-instance Learning"**. This implies that the traditional challenges in annotation tasks still persist.

Another important issue in emotion annotation is the choice of emotion classification scheme. Considering that annotation is a time-consuming and laborious process, researchers often categorize emotions based on task requirements to reduce the difficulty of annotation and improve efficiency. Examples include categorizing emotions into positive and negative **Ekman & Friesen, "The Emotion Display: A Method for Capturing the Nature of an Individual's Expression"**, emotional and neutral states **Lambert, "Emotionally Charged Learning"**, classifying specific emotions by their intensities **Russell et al., "The Situational Format and the Definition of Emotions"**, and using basic emotions **Plutchik, "Emotions: A General Theory"**. In this study, we consider the potential task requirements of these various classification standards and base our research based on the available ground truth emotion labels.


\subsection{LLM for Annotation}

The emergence and application of LLMs has introduced unprecedented opportunities in the field of data annotation. An increasing number of researchers and practitioners have recognized the vast potential of LLMs for enhancing annotation processes **Chen et al., "A Survey of Deep Learning Methods for Natural Language Processing"**. As researchers continue to explore and leverage the advancing capabilities of LLMs, particularly in multimodal interactions **Papineni et al., "Bleu: A Probabilistic Approach to Machine Translation Evaluation"**, and improvements in processing power **Kermorvant & Schwenker, "Automatic Speech Recognition Using a Stacked Recurrent Neural Network"**, the range of annotation tasks has expanded significantly. These tasks now encompass various data types, including text **Bengio et al., "A General Framework for Semi-Supervised Learning"**, audio **Waibel et al., "A System for Interactive Dialogue with Natural Speech and Voice Input"**, images **Fang et al., "From Faces to Emotions: Face-Based Emotion Recognition"**, and specialized domain-specific data **Kim et al., "Using Domain Knowledge to Improve Neural Machine Translation"**.

A recent survey has shed light on current trends and leading research in the application of LLMs for annotation tasks **Liu et al., "Recent Advances in Deep Learning for Natural Language Processing"**. Within the scope of our study, which focuses on emotion annotation for image data, related work has explored various capabilities of LLMs. For instance, researchers have evaluated the ability of LLMs to predict emotions from captions generated from images-derived captions **Voulodakis et al., "Emotion Recognition Using Deep Learning in Natural Language Processing"**, perform image retrieval **Raghu & Vempaty, "Deep Learning for Image Classification with Convolutional Neural Networks and Transfer Learning"**, and generate descriptive captions **Shen et al., "A Survey of Text Summarization Techniques: Recent Advances and Challenges"**. Notably, in early 2024, a study compared the performance of LLMs such as GPT-3.5, GPT-4, and Bard against traditional supervised models like Convolutional Neural Networks (CNNs) for emotion recognition in image data **Chen et al., "A Comparative Study of Deep Learning Models for Emotion Recognition"**. The findings revealed that deep learning models specifically trained for this task generally achieved higher accuracy than LLMs.

However, despite the superior accuracy of traditional supervised models, they also present significant limitations. Nonetheless, LLMs offer the potential to achieve performance that is comparable to traditional models while reducing training and application costs. Therefore, in this study, we further optimized prompt engineering and reorganized annotation strategies to harness the capabilities and advantages of LLMs.