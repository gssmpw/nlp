\section{Ablation Studies}

\input{Tables/5-phone_ablation_table}




















\input{Tables/6-address_ablation_table}

\subsection{Analysis of three stages in PPA}
%To better understand three stages of our method, we do the following three ablation studies.%: Only selected unlearning, Fix index mix selected unlearning, and Unlearning + Error injection. 


\textbf{Sensitivity Analysis + Selective Forgetting.}
To assess the effectiveness of sensitivity analysis combined with selective forgetting in preserving the PII of targeted persons, we applied this approach to protect PII, such as phone numbers and physical addresses. While selective forgetting marginally reduces performance degradation, the resulting model remains largely ineffective, as demonstrated in Table~\ref{phone_ablation_table} and Table~\ref{address_ablation_table}.


\textbf{Fix index Selective Privacy Amnesia.}
To evaluate the efficacy of sensitivity analysis in safeguarding the PII of targeted persons, we employed a fixed index Selective Privacy Amnesia approach, focusing on indices 0, 1, and 2 as the primary elements for removal. Our findings indicate that the fixed index Selective Privacy Amnesia falls short in adequately safeguarding users' phone numbers, as illustrated in Table~\ref{phone_ablation_table}. When it comes to preserving users' physical addresses, as depicted in Table~\ref{address_ablation_table}, employing the fixed index 0 and 1 Selective Privacy Amnesia, yielding address risk scores of 17.2 and 10.9 respectively, does not offer as robust protection as Proactive Privacy Amnesia, which yields an address risk score of 7.3. While the fixed index 2 Selective Privacy Amnesia, with an address risk score of 4.4, does provide superior protection compared to Proactive Privacy Amnesia, it comes with higher perplexity, indicative of lower model performance. This is attributed to the fixed index potentially altering the original meaning of words. For instance, in the case of "New York City," unlearning the single token "City" would compel the model to disregard the frequent occurrence of "City" following "New York," consequently compromising the model's performance.

\textbf{Unlearning + Memory Implanting.}
To assess the effectiveness of sensitivity analysis coupled with selective forgetting in safeguarding the PII of targeted persons, we implemented unlearning in conjunction with memory implanting, as shown in Table~\ref{phone_ablation_table} ~\ref{address_ablation_table}. Our findings revealed that Unlearning + Memory Implanting proved capable of safeguarding the majority of persons' phone numbers and physical addresses, resulting in phone number risk scores of 0.2 and address risk scores of 6.7. However, this approach exhibited higher perplexity levels, measuring 16.3 and 33.6, which signifies diminished model performance. This is because the unlearning method essentially erases entire PII sequences, thereby enhancing PII protection capabilities at the expense of model performance.

\begin{wrapfigure}{r}{0.5\textwidth}
    \centering
    \includegraphics[width=0.5\textwidth, height=1.5\textwidth, keepaspectratio]{./images/20240518_Address_dynamic_mix_selective_unlearning_forget_number_of_k_trade_off_ver2.png}
  \caption{\rebuttalcaption{Address PPA Risk score vs forget number of indexes: PPA tunes the parameter $k$, as defined in Equations \ref{eq:topk} and \ref{eq:selected_unlearning}.}}
  \label{address_current_method_trade_off}
\vspace{-12pt}
\end{wrapfigure}

\subsection{PPA Trade-Offs: Number of forgotten indexes}
% Analysis of Address Mix Selective Unlearning forget number of indexes trade off
Table \ref{phone_enron_defense_table} and \ref{address_enron_defense_table} reveal that, after applying PPA, the address risk score remains at 7.3, while the phone risk score drops to 0. This disparity may be due to physical addresses being longer and less structured than phone numbers.  Therefore, we have conducted an ablation study to quantify the drop-off in risk score as the number of forgotten indexes increases. We conducted experiments on Address PPA. Specifically, we set \( k = 1, 5, 10, 15, 20, 25 \) in Equations \ref{eq:topk} and \ref{eq:selected_unlearning}. 
Both stages followed the training protocols in Appendix \ref{training_setting} for a single epoch.
For Addresses, the PPA method improves the PII risk score if more than one index is selected for forgetting. However, selecting too many indexes causes the model performance to deteriorate, as shown in Figure~\ref{address_current_method_trade_off}. This ablation demonstrates that PPA is a flexible method, allowing for adjustments to the balance between defense capability and model performance by modifying the number of key elements to be forgotten.

% Therefore, we have conducted a ablation study to analyze the trade-off between the number of indices forgotten, the address risk score, and the model's 

\begin{comment}
The results indicate that as more $k$ are selected to forget, although more physical addresses are preserved, the model's performance deteriorates, as shown in Figure~\ref{address_current_method_trade_off}. We observed a significant drop in model performance when the number of $k$ reached 25.
\end{comment}





\begin{comment}
\begin{figure*}[t!]
\centering
  \includegraphics[width=0.43\textwidth]{./images/20240518_Address_dynamic_mix_selective_unlearning_forget_number_of_k_trade_off_ver2.png}
  \caption{Address PPA Risk score vs forget number of indexes: PPA tunes the parameter $k$, as defined in Equations \ref{eq:topk} and \ref{eq:selected_unlearning}.}
  \label{address_current_method_trade_off}
\end{figure*}
\end{comment}





\begin{comment}
\subsection{Unlearning method trade off}
To analyze the break-even point of the unlearning method, we conducted experiments focusing on both phone number and address unlearning. We tested the forgetting of 20, 50, 100, 200, and 400 data points. The results indicate that as more data points are forgotten, a greater number of phone numbers and physical addresses are preserved. However, this leads to a deterioration in the model's performance, as illustrated in Figure~\ref{phone_address_unlearning_break_even_trade_off}. We discovered that forgetting between 200 and 400 data points significantly increases perplexity. Therefore, in our attack and defense scenario, the break-even point for the unlearning method is when between 200 and 400 data points are forgotten.
\end{comment}
