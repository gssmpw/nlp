\section*{Limitations}

While our approach demonstrates superior performance compared to baseline methods, it is important to acknowledge the limitations of our current work as follows:

(1) Computational Inefficiency: Although the Monte Carlo (MC) sampling approach in STeCa achieves superior performance in constructing step rewards compared to alternative methods, it requires a substantial number of sampling iterations, resulting in significant computational overhead. This inefficiency represents a notable limitation of our current implementation. Future work should focus on developing more efficient methods for constructing step rewards while preserving the performance advantages of our approach.

(2) Limited Utilization of Step Rewards: While our approach leverages step rewards to identify and evaluate deviated actions effectively, it does not fully exploit the potential of step rewards for broader decision-making or optimization tasks. This constrained utilization may limit the overall performance improvements that could be achieved by incorporating step rewards into other aspects of the framework. Future research should explore strategies to better harness the rich information embedded in step rewards to enhance the overall effectiveness and adaptability of the system.


\section*{Ethics Statement}

This work aims to develop LLM agents within simulated environments. The VirtualHome and ALFWorld environment setup and related data strictly follow the specifications of VirtualHome \citep{puig2018virtualhome} and ALFWorld \citep{shridhar2020alfworld}. We utilize VirtualHome v2.3.0\footnote{\url{https://github.com/xavierpuigf/virtualhome/tree/master}} (MIT license\footnote{\url{https://github.com/xavierpuigf/virtualhome/blob/master/LICENSE}}) and ALFWorld\footnote{\url{https://github.com/alfworld/alfworld}} (MIT license\footnote{\url{https://github.com/alfworld/alfworld/blob/master/LICENSE}}) to conduct our experiments. 

In our paper, the models we use for fine-tuning are all open-source, and we will strictly follow the protocols for the academic use of these LLMs.
Additionally, we acknowledge the use of AI assistants, including Copilot and ChatGPT, in supporting our coding and writing processes.