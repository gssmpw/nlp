\begin{table*}[t]
\caption{Generic QP problem, size generalization. We fix the density hyperparameters or the average degree of nodes as compared to the training set. The size with the star symbol * is where we train the models on. The methods with postfix $\text{-G}$ are with the global node.}
\label{tab:size_gen_generic}
\centering
\resizebox{.7\textwidth}{!}{
\begin{tabular}{ccccccc}
\toprule
& \textbf{Fix} & -- &  \multicolumn{2}{c}{\textbf{Density}} & \multicolumn{2}{c}{\textbf{Degree}} \\
&  \textbf{Size} & 400* & 600 & 800 & 600 & 800 \\
\midrule


{\multirow{12}{*}{Obj. gap [\%]}}
& Naive \citeyear{chen2024qp} & 2.547\scriptsize$\pm$0.126 & 11.480\scriptsize$\pm$0.297 & 20.663\scriptsize$\pm$0.813
& 1.787\scriptsize$\pm$0.196 & 1.402\scriptsize$\pm$0.127  \\
& Naive-G \citeyear{chen2024qp} & 2.281\scriptsize$\pm$0.150 & 8.461\scriptsize$\pm$1.078 & 15.443\scriptsize$\pm$1.500
& 1.744\scriptsize$\pm$0.134 & 1.302\scriptsize$\pm$0.091 \\
\cmidrule{2-7}
& IPM \citeyear{pmlr-v238-qian24a} & 1.894\scriptsize$\pm$0.166 & 10.521\scriptsize$\pm$1.057 & 20.936\scriptsize$\pm$1.106
& 1.510\scriptsize$\pm$0.126 & 1.153\scriptsize$\pm$0.063 \\
& IPM-G \citeyear{pmlr-v238-qian24a} & 1.829\scriptsize$\pm$0.079 & 10.987\scriptsize$\pm$1.132 & 20.129\scriptsize$\pm$1.782
& 1.541\scriptsize$\pm$0.021 & 1.062\scriptsize$\pm$0.132 \\
\cmidrule{2-7}
& IPM$_{16}$ (Ours) & 10.679\scriptsize$\pm$4.351 & 22.448\scriptsize$\pm$1.307 & 29.633\scriptsize$\pm$1.739
& 11.982\scriptsize$\pm$4.683 & 11.989\scriptsize$\pm$5.584 \\
& IPM$_{32}$ (Ours) & 2.236\scriptsize$\pm$0.249 & 7.685\scriptsize$\pm$2.917 & 19.310\scriptsize$\pm$4.806
& 2.003\scriptsize$\pm$0.472 & 1.856\scriptsize$\pm$0.370\\
& IPM-G$_{16}$ (Ours) & 10.715\scriptsize$\pm$5.344 & 12.170\scriptsize$\pm$5.604 & 14.648\scriptsize$\pm$8.498
& 10.692\scriptsize$\pm$5.573 & 9.694\scriptsize$\pm$6.355 \\
& IPM-G$_{32}$ (Ours) & 1.661\scriptsize$\pm$0.199 & 4.961\scriptsize$\pm$1.219 & 3.462\scriptsize$\pm$0.692
& 1.648\scriptsize$\pm$0.238 & 1.350\scriptsize$\pm$0.243 \\
\cmidrule{2-7}
& Feas.$_{16}$ (Ours) & 0.119\scriptsize$\pm$0.013 & 0.948\scriptsize$\pm$0.111 & 5.867\scriptsize$\pm$0.667
& 0.118\scriptsize$\pm$0.062 & 0.127\scriptsize$\pm$0.002 \\
& Feas.$_{32}$ (Ours) & 0.049\scriptsize$\pm$0.015 & 0.615\scriptsize$\pm$0.064 & 4.839\scriptsize$\pm$0.602
& 0.045\scriptsize$\pm$0.011 & 0.046\scriptsize$\pm$0.007 \\
& Feas.-G$_{16}$ (Ours) & 0.163\scriptsize$\pm$0.003 & 1.480\scriptsize$\pm$0.049 & 8.609\scriptsize$\pm$0.660
& 0.180\scriptsize$\pm$0.037 & 0.184\scriptsize$\pm$0.005 \\
& Feas.-G$_{32}$ (Ours) & 0.070\scriptsize$\pm$0.004 & 0.991\scriptsize$\pm$0.031 & 7.607\scriptsize$\pm$0.607
& 0.077\scriptsize$\pm$0.010 & 0.071\scriptsize$\pm$0.005 \\
\midrule

{\multirow{12}{*}{Cons. vio.}}
& Naive \citeyear{chen2024qp} & 0.012\scriptsize$\pm$0.004 & 0.053\scriptsize$\pm$0.002 & 0.099\scriptsize$\pm$0.002
& 0.014\scriptsize$\pm$0.002 & 0.014\scriptsize$\pm$0.002  \\
& Naive-G \citeyear{chen2024qp} & 0.018\scriptsize$\pm$0.001 & 0.050\scriptsize$\pm$0.004 & 0.095\scriptsize$\pm$0.006
& 0.017\scriptsize$\pm$0.001 & 0.017\scriptsize$\pm$0.001 \\
\cmidrule{2-7}
& IPM \citeyear{pmlr-v238-qian24a} & 0.013\scriptsize$\pm$0.001 & 0.048\scriptsize$\pm$0.002 & 0.092\scriptsize$\pm$0.003
& 0.012\scriptsize$\pm$0.001 & 0.011\scriptsize$\pm$0.001 \\
& IPM-G \citeyear{pmlr-v238-qian24a} & 0.016\scriptsize$\pm$0.0003 & 0.048\scriptsize$\pm$0.002 & 0.089\scriptsize$\pm$0.003
& 0.016\scriptsize$\pm$0.001 & 0.016\scriptsize$\pm$0.0003\\
\cmidrule{2-7}
& IPM$_{16}$ (Ours) & 0.028\scriptsize$\pm$0.008 & 0.040\scriptsize$\pm$0.006 & 0.064\scriptsize$\pm$0.006
& 0.028\scriptsize$\pm$0.008 & 0.027\scriptsize$\pm$0.008\\
& IPM$_{32}$ (Ours) & 0.031\scriptsize$\pm$0.008 & 0.050\scriptsize$\pm$0.006 & 0.078\scriptsize$\pm$0.007
& 0.030\scriptsize$\pm$0.009 & 0.030\scriptsize$\pm$0.008\\
& IPM-G$_{16}$ (Ours) & 0.026\scriptsize$\pm$0.007 & 0.048\scriptsize$\pm$0.007 & 0.069\scriptsize$\pm$0.004
& 0.026\scriptsize$\pm$0.008 & 0.026\scriptsize$\pm$0.007 \\
& IPM-G$_{32}$ (Ours) & 0.029\scriptsize$\pm$0.009 & 0.053\scriptsize$\pm$0.007 & 0.076\scriptsize$\pm$0.004
& 0.029\scriptsize$\pm$0.009 & 0.028\scriptsize$\pm$0.009 \\
\cmidrule{2-7}
& Feas.$_{16}$ (Ours) & 9.786  \(\times\) \(10^{-8}\) & 1.138  \(\times\) \(10^{-7}\) & 1.279  \(\times\) \(10^{-7}\)
& 1.093  \(\times\) \(10^{-7}\) & 1.178  \(\times\) \(10^{-7}\) \\
& Feas.$_{32}$ (Ours) & 1.215  \(\times\) \(10^{-7}\) & 1.376  \(\times\) \(10^{-7}\) & 1.516  \(\times\) \(10^{-7}\)
& 1.318  \(\times\) \(10^{-7}\) & 1.396  \(\times\) \(10^{-7}\) \\
& Feas.-G$_{16}$ (Ours) & 9.080  \(\times\) \(10^{-8}\) & 1.161  \(\times\) \(10^{-7}\) & 1.546  \(\times\) \(10^{-7}\)
& 1.021  \(\times\) \(10^{-7}\) & 1.148  \(\times\) \(10^{-7}\) \\
& Feas.-G$_{32}$ (Ours) & 1.142  \(\times\) \(10^{-7}\) & 1.447  \(\times\) \(10^{-7}\) & 1.769  \(\times\) \(10^{-7}\)
& 1.228  \(\times\) \(10^{-7}\) & 1.346  \(\times\) \(10^{-7}\) \\

\bottomrule

\end{tabular}
}
\end{table*}


 




