\begin{table*}[t]
\caption{Markowitz portfolio problem, size generalization. We fix the density hyperparameters or the average degree of nodes as compared to the training set. The size with the star symbol * is where we train the models. The methods with postfix $\text{-G}$ are with the global node. }
\label{tab:size_gen_port}
\centering
\resizebox{.7\textwidth}{!}{
\begin{tabular}{ccccccc}
\toprule
& \textbf{Fix} & -- &  \multicolumn{2}{c}{\textbf{Density}} & \multicolumn{2}{c}{\textbf{Degree}} \\
& \textbf{Size} & 800* & 1000 & 1200 & 1000 & 1200 \\
\midrule

{\multirow{12}{*}{Obj. gap [\%]}}
& Naive \citeyear{chen2024qp} & 11.075\scriptsize$\pm$0.363 & 39.487\scriptsize$\pm$1.472 & 89.422\scriptsize$\pm$8.968
& 37.366\scriptsize$\pm$0.202 & 80.900\scriptsize$\pm$1.199 \\
& Naive-G \citeyear{chen2024qp} & 2.446\scriptsize$\pm$0.756 & 50.303\scriptsize$\pm$2.226 & 114.081\scriptsize$\pm$2.407
& 43.062\scriptsize$\pm$3.737 & 103.827\scriptsize$\pm$4.694 \\
\cmidrule{2-7}
& IPM \citeyear{pmlr-v238-qian24a} & 11.075\scriptsize$\pm$0.363 & 59.571\scriptsize$\pm$3.657 & 123.412\scriptsize$\pm$16.006
& 53.575\scriptsize$\pm$5.673 & 122.935\scriptsize$\pm$17.091 \\
& IPM-G \citeyear{pmlr-v238-qian24a} & 0.717\scriptsize$\pm$0.353 & 60.532\scriptsize$\pm$2.009 & 123.601\scriptsize$\pm$6.519
& 53.641\scriptsize$\pm$3.141 & 127.39\scriptsize$\pm$10.328 \\
\cmidrule{2-7}
& IPM$_{16}$ (Ours) & 1.241\scriptsize$\pm$0.123 & 59.885\scriptsize$\pm$1.284 & 134.475\scriptsize$\pm$4.046
& 48.010\scriptsize$\pm$1.222 & 107.825\scriptsize$\pm$3.340\\
& IPM$_{32}$ (Ours) & 1.168\scriptsize$\pm$0.048 & 58.791\scriptsize$\pm$0.902 & 133.522\scriptsize$\pm$3.104
& 46.299\scriptsize$\pm$0.963 & 104.649\scriptsize$\pm$3.020\\
& IPM-G$_{16}$ (Ours) & 1.672\scriptsize$\pm$0.302 & 50.184\scriptsize$\pm$2.841 & 120.491\scriptsize$\pm$3.303
& 41.294\scriptsize$\pm$3.882 & 97.128\scriptsize$\pm$10.011 \\
& IPM-G$_{32}$ (Ours) & 1.838\scriptsize$\pm$0.720 & 48.149\scriptsize$\pm$3.959 & 116.984\scriptsize$\pm$3.736
& 39.947\scriptsize$\pm$4.891 & 95.537\scriptsize$\pm$10.651 \\
\cmidrule{2-7}
& Feas.$_{16}$ (Ours) & 1.069\scriptsize$\pm$0.135 & 30.945\scriptsize$\pm$7.768 & 69.905\scriptsize$\pm$19.248
& 24.286\scriptsize$\pm$7.778 & 44.202\scriptsize$\pm$12.299 \\
& Feas.$_{32}$ (Ours) & 0.935\scriptsize$\pm$0.062 & 18.755\scriptsize$\pm$0.100 & 43.238\scriptsize$\pm$13.631
& 13.420\scriptsize$\pm$4.255 & 25.170\scriptsize$\pm$6.707 \\
& Feas.-G$_{16}$ (Ours) & 1.076\scriptsize$\pm$0.161 & 8.211\scriptsize$\pm$2.691 & 22.804\scriptsize$\pm$7.514
& 5.348\scriptsize$\pm$1.463 & 10.702\scriptsize$\pm$3.327 \\
& Feas.-G$_{32}$ (Ours) & 1.005\scriptsize$\pm$0.159 & 5.303\scriptsize$\pm$1.279 & 14.530\scriptsize$\pm$4.671
& 3.412\scriptsize$\pm$0.835 & 6.389\scriptsize$\pm$1.285 \\
\midrule

{\multirow{12}{*}{Cons. vio.}}
& Naive \citeyear{chen2024qp} & 0.083\scriptsize$\pm$0.001 & 0.266\scriptsize$\pm$0.011 & 0.397\scriptsize$\pm$0.015
& 0.271\scriptsize$\pm$0.008 & 0.382\scriptsize$\pm$0.009  \\
& Naive-G \citeyear{chen2024qp} & 0.017\scriptsize$\pm$0.006 & 0.184\scriptsize$\pm$0.012 & 0.330\scriptsize$\pm$0.017
& 0.176\scriptsize$\pm$0.012 & 0.331\scriptsize$\pm$0.017 \\
\cmidrule{2-7}
& IPM \citeyear{pmlr-v238-qian24a} & 0.011\scriptsize$\pm$0.005 & 0.237\scriptsize$\pm$0.027 & 0.435\scriptsize$\pm$0.039
& 0.235\scriptsize$\pm$0.034 & 0.440\scriptsize$\pm$0.048 \\
& IPM-G \citeyear{pmlr-v238-qian24a} & 0.006\scriptsize$\pm$0.003 & 0.239\scriptsize$\pm$0.004 & 0.409\scriptsize$\pm$0.011
& 0.231\scriptsize$\pm$0.002 & 0.422\scriptsize$\pm$0.013 \\
\cmidrule{2-7}
& IPM$_{16}$ (Ours) & 0.007\scriptsize$\pm$0.001 & 0.192\scriptsize$\pm$0.010 & 0.352\scriptsize$\pm$0.015
& 0.175\scriptsize$\pm$0.007 & 0.331\scriptsize$\pm$0.008\\
& IPM$_{32}$ (Ours) & 0.008\scriptsize$\pm$0.000 & 0.187\scriptsize$\pm$0.012 & 0.347\scriptsize$\pm$0.016
& 0.169\scriptsize$\pm$0.008 & 0.319\scriptsize$\pm$0.009\\
& IPM-G$_{16}$ (Ours) & 0.011\scriptsize$\pm$0.003 & 0.156\scriptsize$\pm$0.019 & 0.288\scriptsize$\pm$0.040
& 0.153\scriptsize$\pm$0.015 & 0.288\scriptsize$\pm$0.039 \\
& IPM-G$_{32}$ (Ours) & 0.015\scriptsize$\pm$0.005 & 0.162\scriptsize$\pm$0.015 & 0.297\scriptsize$\pm$0.038
& 0.160\scriptsize$\pm$0.011 & 0.293\scriptsize$\pm$0.037 \\
\cmidrule{2-7}
& Feas.$_{16}$ (Ours) & 2.228 \(\times\) \(10^{-8}\) & 3.054 \(\times\) \(10^{-8}\) & 3.377 \(\times\) \(10^{-8}\)
& 2.779 \(\times\) \(10^{-8}\) & 3.249 \(\times\) \(10^{-8}\) \\
& Feas.$_{32}$ (Ours) & 2.179 \(\times\) \(10^{-8}\) & 2.873 \(\times\) \(10^{-8}\) & 3.491 \(\times\) \(10^{-8}\)
& 2.693 \(\times\) \(10^{-8}\) & 3.386 \(\times\) \(10^{-8}\) \\
& Feas.-G$_{16}$ (Ours) & 2.086 \(\times\) \(10^{-8}\) & 2.570 \(\times\) \(10^{-8}\) & 2.980 \(\times\) \(10^{-8}\)
& 2.384 \(\times\) \(10^{-8}\) & 3.203 \(\times\) \(10^{-8}\) \\
& Feas.-G$_{32}$ (Ours) & 3.427 \(\times\) \(10^{-8}\) & 8.568 \(\times\) \(10^{-8}\) & 2.235 \(\times\) \(10^{-8}\)
& 2.692 \(\times\) \(10^{-8}\) & 2.160 \(\times\) \(10^{-8}\) \\

\bottomrule

\end{tabular}
}
\end{table*}


 




