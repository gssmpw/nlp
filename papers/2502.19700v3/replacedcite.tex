\section{Related work}
\label{Related work}

\subsection{Imbalanced-Small Sample Data (ISSD) HSIC}

Several prior works, including data augmentation, resampling (oversampling and undersampling) ____, deep transfer learning ____, and deep few-shot learning ____, have been proposed to address the ISSD HSIC problem. For instance, random oversampling (ROS) and random undersampling (RUS) simply replicate the training samples which leads to data redundancy ____. Synthetic minority oversampling technique (SMOTE) may contribute to better classification performance on conventional classifiers, but this method uses a simple linear combination of one random sample and its nearest neighbors to generate synthetic minority samples, which fails to capture the complex manifold structure and is hard to satisfy the nonlinear spatial-spectral relationship in the HSI data ____.

Latent variable models, especially represented by the deep generative models (DGMs), introduce uncertainty into the low-dimensional discriminative latent space during the reconstruction process, possessing the ability to stimulate the complex heterogeneity of HSI data and generate samples for the minority class. Particularly, GANs replace the complexity of resampling by searching for a Nash equilibrium of the generator and discriminator through adversarial training. Specifically, class-informed mixture GANs are developed to ensure the generated samples align with the actual data distribution. For example, Dam et al. proposed a parallel mixture generator spectral 1D-GAN ____ to generate class-dependent samples by fully exploiting the spectral feature. Auxiliary classifiers significantly improved the classification performance of imbalanced datasets. Zhu et al. proposed a 3D-GAN ____ that took both spatial and PCA-reduced spectral features into account to handle 3D patch samples. The discriminator not only distinguished the real data from the synthetic fake data but also leveraged the softmax classifier to produce the classification maps.

The common deep transfer learning methods mainly use some pre-trained models in the natural images field, such as VGG16 and ResNet50 with frozen parameters, to fine-tune the downstream tasks in the remote sensing community. Thanks to these pre-trained models, they can obtain promising results with a small sample size and lower computational burden. Jiao et al. proposed a deep multiscale feature extraction algorithm, which fully took advantage of pre-trained VGG-16, to exploit the spatial structure information of hyperspectral images by performing a full convolution operation, and then realized adaptive spatial-spectral information fusion by employing weighted strategy ____. Wang et al. first built three-spectral band hyperspectral datasets through random band selection (RBS) procedure, letting VGG-16 learn the feature of homogeneous areas with distinguished semantic and geometric properties ____. However, extracting features of HSI with models that are pre-trained on natural RGB images requires transforming hundred of bands into triple-band datasets, which will inevitably result in the loss of essential information.

\subsection{Image Synthesis for HSIC}
To estimate the data distribution for more realistic image synthesis and expand the small training data, scholars have developed several methods, which have achieved promising results. The commonly used algorithms include the mixture model (Gaussian Mixture Model, GMM), generative model (GAN, VAE), and DDPM.

Deep learning-based methods, with GAN and VAE being typical representatives, generate new samples of a given distribution. Specifically, this is achieved by training a generator to map random noise from the latent space to the data distribution. Instead of inferring the global distribution, scholars employed conditional generative models, which are designed to condition the output of the generator based on the hyperspectral classes. For instance, in ____, Audebert et al. used conditional GAN to generate an arbitrarily large number of hyperspectral samples that matched the distribution of any dataset. Considering spectral mixing, this method can synthesize any combination of classes by interpolating between vectors in the latent space. Due to the high-dimensional HSI data with complex noise, VAE is more suitable for processing HSI by introducing the Gaussian noise into the encoded results in latent space. In ____, Xi et al. proposed a DGSSC method, which can achieve minority-class data augmentation in the latent variable space to address the problem of imbalanced data. However, the condition was only based on one-hot encoding of hyperspectral classes. Considering the complex situations in the real-world application and the semantic context, it is likely that the one-hot-like encoding in probabilistic form, such as pixel abundance, instead of binary vector, will work better. 

Very recently, DDPMs have demonstrated superior performance in image inpainting and synthesis compared to GANs and VAEs. For instance, in ____, Zhang et al. proposed R2H-CCD, an algorithm for HSI generation that leveraged the conditional DDPM to produce high-fidelity HSI from RGB image through cascaded generation. Liu et al. proposed a diverse hyperspectral remote sensing image generation method based on latent diffusion models (HyperLDM) ____, employing a conditional vector quantized generative adversarial network (VQGAN) to compact high-dimensional information for accelerating the diffusion process. Additionally, HyperLDM incorporated abundance maps derived from VQGAN to condition the HSI generation via LDM. By doing so, the model effectively accounted for the spectral mixing of multiple materials within HSI pixels. However, a critical limitation of HyperLDM is its reliance on an accurately calibrated spectral library during the transformation of abundance maps into HSI using the linear mixture model (LMM).

However, the above methods, whether conditional GANs conditional VAEs, or latent conditional DDPMs, still require substantial quantities of paired remote sensing image observations (e.g., RGB image and corresponding HSI). This poses a significant challenge in practical applications, due to the limited availability of such paired datasets arising from satellite revisit period variations and heterogeneous sensor specifications across different observation platforms.

\subsection{Imageâ€“Text Pairing information in HSIC}
Hyperspectral image analysis demands intensive manual labeling, while, language representations are inherently more accessible straightforward for humans to express and acquire. Notably, recent advancements in AI methods, such as contrastive language image pre-training (CLIP) ____ has demonstrated the capability to model the bidirectional relationships between these two modalities (image and text). Moreover, these methods present exceptional transferability across diverse downstream visual and language tasks, making them promising candidates for addressing the data scarcity challenges in HSI-related applications ____.

Notably, Zhang et al. proposed a domain generalization network (LDGNet)  ____ for HSIC. This method learned visual-linguistic alignment features from source datasets and transferred cross-domain invariant knowledge to target domains. Similarly, Dang et al. ____ developed LIVEnet for cross-scene HSI classification, which enhanced the information exchange between linguistic and visual features while exploiting interclass correlation prevalent in imbalanced sample scenarios. Moreover, Cao et al. designed a three-aspect text description (color, label, shape) to extract linguistic prior information, enabling shared spatial and spectral features in a unified semantic space ____.

However, a critical limitation of these aforementioned methods lies in their inability to quantitatively evaluate pixel-level text-image correlations. In other words, these methods fail to assess the relative importance of different textual components in a specific text description, which is essential for understanding the contribution of individual linguistic features to the classification process.

\subsection{Latent Conditional Diffusion Model} \label{LDM_section}

Diffusion models ____ are probabilistic models designed to learn data distributions \(p(x)\) by gradual denoising a normally distributed variable, which corresponds to learning the reverse process of a fixed Markov Chain of total length \(T\).

However, for high-dimensional distributions, diffusion model training (see \autoref{ddpm_training}) and sampling (see \autoref{ddpm_sample}) require massive computational resources.
\begin{align}
    \mathcal{L}_{DM} = \mathbb{E}_{x, \epsilon \sim \mathcal{N}(0,1), t} [\lVert \epsilon - \epsilon_{\theta}(x_t, t)  \rVert _{2} ^{2}]
\label{ddpm_training}
\end{align}
\begin{align}
    q(x_{t-1} | x_{t}, t) = \mathcal{N}(x_{t-1}; \frac{1}{\sqrt{\alpha_{t}}}(x_{t} - \frac{\beta_{t}}{\sqrt{1-\bar{\alpha}_{t}}} \epsilon_{\theta} (x_{t}, t)), \beta_{t} \mathbf{I})
\label{ddpm_sample}
\end{align}
where, \(\alpha_{t} \coloneqq  1-\beta_{t}\), \(\bar{\alpha}_{t} \coloneqq  \prod \limits_{s=1}^t \alpha_{s}\), \(\epsilon \sim \mathcal{N}(0, \mathbf{I})\), \(\epsilon_{\theta}\) represents the diffusion model with parameter \(\theta\).

To enhance the efficiency of the training and sampling process, Rombach et al., the authors of Stable Diffusion ____ proposed latent diffusion models (LDMs), which performed the diffusion in the latent space of a pre-trained VAE. Specifically, given a frozen encoder \(\mathcal{E}\): \(\mathbb{R}^{n} \rightarrow \mathbb{R}^{k}\) and decoder \(\mathcal{D}\): \( \mathbb{R}^{k} \rightarrow \mathbb{R}^{n} \), train a diffusion model of representations \(z = \mathcal{E}(x_0) \), \(0\) represents the original data. The noisy samples can be created by:
\begin{align}
    q(z_{t} | \mathcal{E}(x_0), t) = \mathcal{N} (z_{t}; \sqrt{\bar \alpha_{t}} \mathcal{E}(x_0), (1-\bar \alpha_{t}) \mathbf{I})
\end{align}
The corresponding objective can be written as:
\begin{align}
    \mathcal{L}_{LDM} = \mathbb{E}_{z \sim \mathcal{E}(x), \epsilon \sim \mathcal{N}(0,1), t} [\lVert \epsilon - \epsilon_{\theta}(z_{t}, t)  \rVert _{2} ^{2}]
\end{align}

At inference time, new images can then be generated by sampling a clean representation \(z\) from the diffusion model and subsequently decoding it to an image with the learned decoder \(x = \mathcal{D}(z)\)

In principle, diffusion models have the capability to formulate conditional distributions in the form of \(p(z|c)\). This can be implemented with a conditional denoising autoencoder \(\epsilon_{\theta}(z_{t}, t, c)\), which paves the way to control the synthesis process through inputs \(c\), such as text ____, semantic maps ____, and other image translation tasks ____.