% This must be in the first 5 lines to tell arXiv to use pdfLaTeX, which is strongly recommended.
\pdfoutput=1
% In particular, the hyperref package requires pdfLaTeX in order to break URLs across lines.
%\documentclass[twoside,11pt]{fairmeta}

\PassOptionsToPackage{xcdraw,table}{xcolor}

%\documentclass[11pt]{article}

% In particular, the hyperref package requires pdfLaTeX in order to break URLs across lines.
\documentclass[twoside,11pt]{fairmeta}
% Change "review" to "final" to generate the final (sometimes called camera-ready) version.
% Change to "preprint" to generate a non-anonymous version with page numbers.
% \usepackage[review]{acl}
% \usepackage[final]{acl}
%\usepackage[review]{acl}

\usepackage{xspace}
% Remove the "review" option to generate the final version.

% Change "review" to "final" to generate the final (sometimes called camera-ready) version.
% Change to "preprint" to generate a non-anonymous version with page numbers.
% \usepackage[review]{acl}
% \usepackage[final]{acl}

% Standard package includes
\usepackage{times}
\usepackage{latexsym}
\usepackage{algorithm}
\usepackage{algpseudocode}
\usepackage{tikz}
\def\checkmark{\tikz\fill[scale=0.4](0,.35) -- (.25,0) -- (1,.7) -- (.25,.15) -- cycle;} 
% For proper rendering and hyphenation of words containing Latin characters (including in bib files)
%\usepackage[T1]{fontenc}
% For Vietnamese characters
%\usepackage[T5]{fontenc}
% See https://www.latex-project.org/help/documentation/encguide.pdf for other character sets

% This assumes your files are encoded as UTF8
\usepackage[utf8]{inputenc}
\usepackage{comment}
\usepackage[export]{adjustbox}
\providecommand{\annote}[2]{{\color{#2}
    $\blacktriangleright$\footnotesize\emph{#1}$\blacktriangleleft$}%
}
\providecommand\todo[1]{[\textcolor{red}{TODO: {#1}}]}
\providecommand\marta[1]{[\textcolor{magenta}{Marta: {#1}}]}
\providecommand\bokai[1]{[\textcolor{brown}{Bokai: {#1}}]}
\providecommand\pierre[1]{[\textcolor{blue}{Pierre: {#1}}]}
\providecommand\olive[1]{[\textcolor{teal}{Christophe: {#1}}]}
\providecommand\cihan[1]{[\textcolor{olive}{Cihan: {#1}}]}
\providecommand\joearina[1]{[\textcolor{orange}{joearina: {#1}}]}
\providecommand\david[1]{[\textcolor{brown}{David: {#1}}]}

% This is not strictly necessary and may be commented out.
% However, it will improve the layout of the manuscript,
% and will typically save some space.
\usepackage{microtype}

% This is also not strictly necessary and may be commented out.
% However, it will improve the aesthetics of text in
% the typewriter font.
\usepackage{inconsolata}
\usepackage{graphicx}
\usepackage{booktabs}



\newcommand{\spiritlm}{\textsc{Spiritlm}\xspace}
\newcommand{\llama}{\textsc{Llama}\xspace}
\newcommand{\llamatwobase}{\textsc{Llama-2}\xspace}
\newcommand{\llamathreebase}{\textsc{Llama-3}\xspace}
\newcommand{\llamatwochat}{\textsc{Llama-2-chat}\xspace}
\newcommand{\llamathreechat}{\textsc{Llama-3-chat}\xspace}
\newcommand{\llamatwo}{\textsc{Llama-2}\xspace}
\newcommand{\llamathree}{\textsc{Llama-3.1}\xspace}
\newcommand{\gpt}{\textsc{GPT-4o}\xspace}
\newcommand{\flores}{\textsc{FLORES-200}\xspace}
\newcommand{\mflores}{\textsc{2M-FLORES}\xspace}
\newcommand{\belebele}{\textsc{Belebele}\xspace}
\newcommand{\speechbelebele}{\textsc{2M-Belebele}\xspace}
\newcommand{\fleurs}{\textsc{FLEURS}\xspace}
\newcommand{\whisper}{\textsc{Whisper-large-v3}\xspace}
\newcommand{\whispers}{\textsc{Whisper}\xspace}
\newcommand{\mfourt}{\textsc{SeamlessM4T}\xspace}
\newcommand{\mms}{\textsc{MMS}\xspace}
%\newcommand{\mfourt}{\textsc{Seamless}\xspace}
\newcommand{\ssvpslt}{\textsc{SSVP$\_$SLT}\xspace}
\newcommand{\numlanguages}{\textsc{74}\xspace}

\newcommand{\bouquet}{BOUQuET\xspace}

\newcommand{\sourcebouquet}{Source-BOUQuET\xspace}
\newcommand{\fullbouquet}{Full-BOUQuET\xspace}


\title{BOUQuET \protect\includegraphics[height=1em]{bouquet.png}: dataset, Benchmark and Open initiative for Universal Quality Evaluation in Translation}
%Next Concept of Multi-Way Parallel Dataset for Machine Translation Evaluation}
%\author{OmnilingualMT Team, Pierre Andrews, Mikel Artetxe, Mariano Coria Meglioli, Marta R. Costa-juss\`a, Joe Chuang, David Dale, Cynthia Gao, Jean Maillard, Alex Mourachko, Christophe Ropers, Safiyyah Saleem, Eduardo Sánchez, Yiannis Tsiamas, Arina Turkatenko, Albert Ventayol, Shireen Yates \\\\ FAIR, Meta; University of London (UCL); University of the Basque Country (UPV/EHU)} 

\author[]{The~Omnilingual~MT~Team}
\author[\dagger \ddagger]{Pierre Andrews} 
\author[\ddagger ++]{Mikel Artetxe}
\author[\dagger]{Mariano Coria Meglioli}
\author[\dagger \ddagger]{Marta R. Costa-juss\`a}
\author[\dagger]{Joe Chuang}
\author[\dagger \ddagger]{David Dale}
\author[]{Cynthia Gao}
\author[\dagger]{Jean Maillard}
\author[]{Alex Mourachko}
\author[\dagger \ddagger]{Christophe Ropers}
\author[]{Safiyyah Saleem}
\author[\dagger +]{Eduardo S\'anchez}
\author[]{Ioannis Tsiamas}
\author[\dagger]{Arina Turkatenko}
\author[\dagger]{Albert Ventayol-Boada}
\author[]{Shireen Yates}




\affiliation[]{FAIR at Meta}
\affiliation[+]{FAIR at Meta and University College London}
\affiliation[++]{ University of the Basque Country (UPV/EHU)}
%\contribution[\S]{\textbf{M}odular and \textbf{E}xtensible \textbf{R}easoning in an \textbf{E}mbedding \textbf{S}pace}
%✝Core contributors, alphabetical order; ⁑Supervision/Leadership, alphabetical order, ꙳Corresponding author

\contribution[\dagger]{Core contributors, alphabetical order}
\contribution[\ddagger]{Supervision/Leadership, alphabetical order}
%\contribution[+]{}

%\date{February 7th, 2025}
\correspondence{Marta R. Costa-juss\`a at \email{costajussa@meta.com}}


\abstract{This paper presents \bouquet, a multicentric and multi-register/domain dataset and benchmark, and its broader collaborative extension initiative. This dataset is handcrafted in non-English languages first, each of these source languages being represented among the 23 languages commonly used by half of the world's population and therefore having the potential to serve as pivot languages that will enable more accurate translations.  The dataset is specially designed to avoid contamination and be multicentric, so as to enforce representation of multilingual language features. In addition, the dataset goes beyond the sentence level, as it is organized in paragraphs of various lengths. Compared with related machine translation (MT) datasets, we show that \bouquet has a broader representation of domains while simplifying the translation task for non-experts. Therefore, \bouquet is specially suitable for the open initiative and call for translation participation that we are launching to extend it to a multi-way parallel corpus to any written language.}% by combining a mixture of private and community efforts.}


\begin{document}
\maketitle
%\begin{abstract}

%\end{abstract}


\section{Introduction}

Although multilingual large-language model evaluation benchmarks are only starting \citep{dac2023okapi}, there is a rich research history in multilingual evaluation datasets for natural language processing; e.g., \cite{sun-duh-2020-clirmatrix,malmasi-etal-2022-multiconer,yu-etal-2022-beyond}, with Machine Translation (MT) being the task with the highest investment in multilinguality \citep{kocmi-etal-2024-findings}. This is evident from the nearly 15-year history of the Conference on Machine Translation (formerly a workshop, WMT), which has established an international evaluation campaign \citep{kocmi-etal-2024-findings}. The campaign has compiled a comprehensive collection of parallel data evaluations covering a broad range of language pairs, domains, and tasks. Although some datasets offer multi-way parallelism across languages (e.g., the TED parallel corpus),\footnote{\url{https://hal.science/hal-04702210v1}} the largest multi-way parallel corpus was only recently introduced with FLORES-101 \citep{goyal-etal-2022-flores}, later expanded to \flores \citep{nllbteam2022language} and to \mflores \citep{costajussà20242mbelebelehighlymultilingualspeech}. 

However, even if great progress has been made, advances in multilingual applications for diverse languages are hindered by limited evaluations. Existing datasets and benchmarks fall short due to having an English-centric focus, a narrow register, compromised quality from automated construction and mining, limited language coverage, or a static nature, in addition to being prone to contamination. 

Similarly, in parallel with the previous progress, there have been several initiatives that called for data annotation in a collaborative and open way, such as the translation data collection initiative reported in \cite{singh-etal-2024-aya}. 

This precisely sets the stage for the introduction of a multilingual evaluation dataset and a benchmark, \bouquet, which additionally combines community efforts. %\bouquet aims at providing a multi-way parallel dataset that addresses previous challenges. 
The purpose of this paper is two-fold. First, the paper details how we develop the \sourcebouquet dataset, which is the necessary stepping stone towards an open initiative. Second, it presents how we design the open initiative itself, which aims to build the \fullbouquet dataset; i.e., \sourcebouquet translated into any written language. 

\subsection{Definitions}
Before describing the \sourcebouquet dataset's characteristics and building methodology, we define our use of some frequently encountered terms that may cover a variety of meanings.

\paragraph{Domain.} By the term \textit{domain}, we mean different spaces in which language is produced in speech, sign, or writing (e.g., books, social media, news, Wikipedia, organization websites, official documents, direct messaging, texting). In this paper, we focus solely on the written modality.

\paragraph{Register.} We understand the term \textit{register} as a functional variety of language that includes socio-semiotic properties, as expressed in \cite{halliday-2004}, or more simply as a ``contextual style'', as presented in \cite{labov-1991}, pp.79–99). In that regard, a register is a specific variety of language used to best fit a specific communicative purpose in a specific situation.

\section{Dataset: \sourcebouquet}
\label{sec:source-bouquet}

In this section, we describe the creation criteria that have follow to design \sourcebouquet, as well as the languages it includes.

\subsection{Main characteristics}
As described in greater detail next, the \sourcebouquet dataset is mainly characterized by its non-English-centric focus, its diverse registers and domain (which is complementary to \flores), its manual and original composition, and its built-in dynamic extensibility.

\paragraph{Non-English-centric focus.} \sourcebouquet is handcrafted by proficient speakers of %Egyptian Arabic and MSA, 
French, German, Hindi, Indonesian, Mandarin Chinese, Russian, and Spanish. Each of those languages provides the same number of sentences to the final dataset. The languages for \sourcebouquet (see Table \ref{tab:lang} in Section \ref{sec:source-bouquet-lang}) are all part of the top 20 languages in the world in terms user population, as listed in \cite{ethnologue-27}. In addition, they are also used by a large number of both native and non-native speakers, which makes them good candidates for what we refer to as \textit{pivot} languages; i.e., higher-resource languages that can facilitate---as source languages---the translation of datasets into lower-resource languages. English is often used as such a pivot language, since numerous people have a high degree of proficiency in English as a second language. English is not the only language in this situation, however, and is not always the best pivot language option. For example, it is much easier to find Guarani-Spanish bilingual speakers than it is to find Guarani-English bilingual speakers. What is more, cultural proximity may also make translation slightly easier.   

\paragraph{Diverse registers and domains.} Registers derive from communicative purposes and, as such, are related to domains. However, the relationship between registers and domains is not one to one. For example, if we take a domain such as TV news, we can identify at least 3 registers:
\begin{itemize}
\item The register used by the news anchor, which is represented by fully scripted language that is read from a teleprompter with a very specific and unnatural form of diction (hypercorrect enunciation, unnatural intonation, homogeneous pace).
\item The register produced by communication specialists (i.e., people who have been trained to be spokespersons or surrogates). The points they make have been scripted%, agreed upon after legal and comms review, 
and rehearsed to the point of being known by heart. Communication specialists also learn rehearsed patterns of language to make sure they do not get surprised by a question and can redirect the conversation towards the points they need to make instead of answering unexpected questions. All the language they use has been written and rehearsed. It sounds spontaneous but it is not structured like informal language.
\item The register represented in person-in-the-street segments, which is more informal and spontaneous (possibly colloquial).
\end{itemize}

The example above is taken from a domain where both speech and writing are used but the situation is not significantly different in the written modality only. Language users all commonly shift between registers, which is typically referred to as \text{style-shifting}. Style-shifting (i.e., register-shifting) occurs within domains; so the domain itself is not a fool-proof way of getting a specific register. Although the norms of the domain can impose the degree of formality and of lexical specialization, it is often the register (which derives from the communicative purpose), not the domain, that determines many aspects of linguistic structure (lexical density, pronoun use, syntax, etc.). 

The registers we cover is \sourcebouquet are given in Figure \ref{fig:coveredregisters}.

\paragraph{Manual construction and original composition (not crawled) with accurate revisions} To develop \sourcebouquet, we set a variety of linguistic criteria that need to be covered. Guidelines are then shared with linguists who manually craft sentences covering examples of these linguistic criteria and compose paragraphs of various lengths. 

The main strategies for open collaboration are to design contribution guidelines and build the annotation tool that enables to freely collect translations in any language. For this, \bouquet is initially composed on 8 major languages plus the English translation and it is shared in a repository that allows language communities to easily add a new language even if they do not speak English, e.g. a native speaker of Quechua can translate from Spanish. This repository contains detailed guidelines on how to do it. \bouquet's innovative approach ensures universal language accessibility. This open collaborative initiative will enrich \bouquet with the following characteristics.

\paragraph{Language coverage extensibility}  Using both private and community-driven initiatives, we could potentially support any written language, as long as there is individual interest in contributing to multilingual advancements. 

\paragraph{Dynamic in nature} Since \bouquet includes the community, it can continuously evolve by constantly engaging it.

\subsection{Creation criteria}

For the design of the creation guidelines, which are reported in detail in Appendix \ref{app:guidance}, we prepared a list of linguistic coverage requirements as well as some statistical information.

\paragraph{Linguistic coverage requirements.} In order for \bouquet to be representative of various linguistic phenomena, linguistic coverage requirements are defined (as listed in Table \ref{tab:linguistic}), which are to be included in sentences that form paragraphs. This continuity will include variation in the number of sentences per paragraph and in the lengths of sentences themselves. 

\begin{table} [h!]
\scriptsize
\centering
% \resizebox{\textwidth}{!}{%
\begin{tabular}{l}
\toprule
\textsc{Phenomena}  \\
\midrule
 Paragraph-like continuity\\ 
\addlinespace[0.3em]
 Variation in sentence lengths \\
 \addlinespace[0.3em]
 Dominant (unmarked) and non-dominant (marked) word orders \\ 
 \addlinespace[0.3em]
Different emphasis or topicalization \\ \addlinespace[0.3em]
 Different sentence structures (affirmation, interrogation, negation, subordination, coordination) \\ \addlinespace[0.3em]
 Different verb moods, tenses, and aspects \\ \addlinespace[0.3em]
 Different morphosyntactic options \\\addlinespace[0.3em]
 Different grammatical persons (1st, 2nd, 3rd, singular, plural) \\ \addlinespace[0.3em]
 Different grammatical genders \\ \addlinespace[0.3em]
 Different grammatical number agreement\\ \addlinespace[0.3em]
 Different grammatical case or forms of inflection \\\addlinespace[0.3em]
 Most frequent words used in various registers\\\addlinespace[0.3em]
 Presence of named entities, numbers, slang, and emojis \\\addlinespace[0.3em]
\bottomrule
\end{tabular}%
% }
\caption{ \sourcebouquet Linguistic Requirements\label{tab:linguistic}}
\end{table}

\paragraph{Variety of domains.} \sourcebouquet is intended to cover 8 domains: narration (as in fiction writing), dialog, social media posts, social media comments, how-to, miscellaneous website content (excluding social media or news), opinion pieces, miscellaneous other (such as written speeches or signage). The choice of these domains optimizes for variety and popular usefulness. %\david{We need to motivate the choice of these 8 domains somehow}

\paragraph{Variety of registers.} \sourcebouquet is built with register variety in mind, differently from \flores, which covers a few different domains but remains largely within similar registers. We characterize the registers through 3 main aspects (connectedness, preparedness, and social differential), and a variety of options within these aspects (see Figure \ref{fig:coveredregisters} for detail). Connectedness attempts to describe the type of interaction typically available in a given domain. Preparedness aims to gauge how much time is typically used to produce or edit language content. Social differential tries to describe various social situations in which language content is typically produced in each of the domains. Options are not mutually exclusive at the level of the domain but become differentiated at the level of a single sentence.

By including new registers and domains, the new dataset is likely to be more generalizable to different contexts and applications.

\begin{figure*}[h!]
\centering
 \includegraphics[width=1\textwidth]{figures/registers} 
  \caption{Covered register characteristics.
\label{fig:coveredregisters}}
\end{figure*}


\paragraph{Statistical guidance.} In order to appropriately cover linguistic requirements and adequately represent the registers and domains, we performed a statistical analysis to understand each of the linguistic characteristics. In particular, our analysis covers % domains: AI chat interactions, Books, Dialog, Educational Articles, News and Online Content (blogs mostly, overlapping with news and ed articles).
most domains that we are including in \sourcebouquet by using diverse public datasets: narration (Books3, gutenberg \citep{gutenberg}); Social media posts (Reddit \citep{reddit}); Social media comments (Wikipedia comments\footnote{\url{https://www.kaggle.com/competitions/jigsaw-multilingual-toxic-comment-classification}}); Conversations / Dialogues (dialogsum \citep{chen-etal-2021-dialogsum-challenge}, Open Orca \citep{OpenOrca}); Tutorials/how-to articles (how-to Wikipedia-lingua \footnote{\url{https://huggingface.co/datasets/GEM/wiki_lingua}}); Website content (c4 \citep{c4}); News / Reflection pieces (cnndailymail \citep{cnndaily}, xsum \citep{xsum}) and Miscellaneous (Wikipedia). Note that we collect information from public data that do not always accurately match our categories but constitute a proxy. % two domains (promotional website content and blogs) from a single dataset (c4) that covers both at the same time. 
For each of these domains, we have analyzed dimensionality: characters per token; tokens per sentence and sentences per paragraph.


\begin{figure}[h!]
\centering
 \includegraphics[width=0.28\textwidth]{figures/tokens_per_sentence_nolegend.png} 
  \includegraphics[width=0.28\textwidth]{figures/sentences_per_paragraph_nolegend.png}
   \includegraphics[width=0.28\textwidth]{figures/percentage_of_c2_nolegend.png} 
   \includegraphics[width=0.10\textwidth]{figures/domains_legend.png} 
  \caption{ (Left) Tokens per sentence and (middle) sentences per paragraph (Right) CEFR per domain.
\label{fig:chrtokens}}
\end{figure}


Regarding tokens per sentence (Figure \ref{fig:chrtokens} left), we can see correlations between different domains, and clear differences in length, especially in dialogs which tend to be much shorter.

Regarding sentences per paragraph (Figure \ref{fig:chrtokens} middle), we can find correlation between different datasets representing the same domain, where fiction writing paragraphs tend to be much longer (averaging 5 but reaching up to 20~), dialogs and news articles are much shorter (barely reaching 3-4 sentences in a paragraph), and the rest of the categories are somewhere in between (normally staying between 1-5 but reaching up to 10 in some cases).



Furthermore, we have checked complexity: distribution of CEFR level\footnote{\url{https://rm.coe.int/common-european-framework-of-reference-for-languages-learning-teaching/16809ea0d4}} as a proxy. Including here the \% of C2 scores at sentence level for each dataset. This was labeled by a sonar-based model \citep{duquenne2023sonarsentencelevelmultimodallanguageagnostic} trained on CEFR-SP data CEFR Text Classification which greatly outperformed \llamathree \citep{touvron2023llama}. See Figure \ref{fig:chrtokens} right.


%\begin{figure}[h!]
%\centering
% \includegraphics[width=0.5\textwidth]{figures/percentage_of_c2.png} 
%  \caption{ CEFR per domain
%\label{fig:cefr}}
%\end{figure}

Wikipedia seems to be the only dataset with a more considerable share of C2 sentences, with some others like dialogues having no samples scored as such.


\paragraph{Annotations.} Each entry of \sourcebouquet includes the source text (in one of the 8 pivot languages from Table \ref{tab:lang}) and its translation into English, domain information, and contextual information for better translation accuracy.



\subsection{Languages} 
\label{sec:source-bouquet-lang}

\bouquet aims to be as multicentric as possible, in contrast with most existing datasets like \flores that are English-centric. The motivation is mainly to be representative of linguistic phenomena. To this effect, it is created in 7 non-English languages. Each language contributes with a similar number of sentences along with their English equivalents given by the sentence creators themselves. See languages in Table \ref{tab:lang}.

%French, Hindi, Indonesian, Mandarin, Russian, Spanish and Turkish

\begin{table*} [h!]
\centering
\scriptsize
\begin{tabular}{lllllllllll}
\toprule
\textsc{ISO 639-3} & \textsc{ISO 15924} & \textsc{Language} & \textsc{Family} & \textsc{Subgroup1} \\
\midrule
%arb	& Modern Stan. & Afro-Asiatic	& Semitic	& West Semitic&	VSO	& seg.	&fusional	&2	&none &Arab	\\
%& Arabic	\\
%arz	& Egyptian 	&Afro-Asiatic	&Semitic	&West Semitic&	SVO	&seg.&	fusional&	2	&none&	Arab\\
%& Arabic\\
\addlinespace[0.3em]
cmn	&Hans &	Mandarin Chinese	& Sino-Tibetan & Sinitic	\\
\addlinespace[0.3em]
deu & Latn & German	& Indo-European	& Germanic \\
\addlinespace[0.3em]
fra	& Latn &	French	&Indo-European	& Italic \\
\addlinespace[0.3em]
hin	& Deva &	Hindi&	Indo-European&	Indo-Aryan	\\
    \addlinespace[0.3em]
ind	& Latn &Indonesian&	Austronesian&	Malayo-Polynesian \\
\addlinespace[0.3em]
rus	& Cyrl &	Russian&	Indo-European	& Balto-Slavic	\\
\addlinespace[0.3em]
spa	& Latn &	Spanish	&Indo-European	& Italic \\
\bottomrule
\end{tabular}%

% }
\caption{ \sourcebouquet Languages\label{tab:lang}}
\end{table*}





\section{Benchmark}


\paragraph{Statistics}  In total, \bouquet currently contains 1,750 sentences. These sentences are split by doing a stratified selection among source languages and domains into development and test sets with an equivalent number of sentences. A portion of the development set (522) is intended to initially be kept hidden. Results in the following sections are presented with the test split of 889 sentences. %\bouquet is splits of 1,000 and 750 sentences each. %As it has been mentioned, we distinguish between \sourcebouquet and \fullbouquet. Basically, the former is the source set, whereas the latter comprises the source set and its corresponding translated version into any language. \sourcebouquet is presented in this paper and \fullbouquet will come as part of the open initiative 

Table \ref{tab:statistics} provides a comparison of several relevant statistics from \bouquet and the closest related datasets including \flores, NTREX-128 \citep{federmann-etal-2022-ntrex} and NLLB-MD \citep{nllbteam2022language}. 


\begin{table}[ht!]
\centering
\scriptsize
%\sisetup{table-format = 3.2}
%\resizebox{\textwidth}{!}{%
%\begin{tabular}{@{}p{2.2cm}ccccc@{}}
\begin{tabular}{ccccccc}
\toprule
\multicolumn{1}{l}{\textsc{Dataset}} &\multicolumn{1}{l}{\textsc{Sent.}} & \textsc{Parag.} &  \textsc{Reg.} &  \textsc{Dom.} & \textsc{Lang.} & \textsc{Dyn.} \\
\midrule
\textsc{\flores} & 3,003 & ($\checkmark$) & $\times$ & Wikipedia, News, Travel guides & 200 & $\times$ \\
\addlinespace[0.3em]
\textsc{NTREX-128} & 1,997& $\checkmark$ & $\times$ & News & 128 & $\times$ \\

\addlinespace[0.3em]
\textsc{NLLB-MD}& 9,000 & $\times$& $\times$ & Chat, News, Health & 6 & $\times$ \\ 
\addlinespace[0.3em]
\multirow{2}{*}{\bouquet} & \multirow{2}{*}{1,750} & \multirow{2}{*}{$\checkmark$} & \multirow{2}{*}{$\checkmark$} & Fiction, Conversation, Social media posts/comments & \multirow{2}{*}{8+} & \multirow{2}{*}{$\checkmark$}  \\
&&&& Tutorials, Website, Reflection pieces, Miscellaneous &\\


\bottomrule
\end{tabular}%
%}%resizebox
\caption{Main statistics from MT evaluation datasets including \bouquet: number of sentences, paragraph-information, registers, domains, languages, dynamism. \label{tab:statistics}}
\end{table}


\paragraph{Domain representation} The performance of the model in a new or unseen dataset depends on the similarity between the dataset that was used to fit the model and the new dataset. In order to more broadly evaluate an MT model, we are interested in covering a different set of domains.  We compare the domain coverage of \bouquet with that of \flores, NTREX-128 \citep{federmann-etal-2022-ntrex} and NLLB-MD \citep{Stolte_2024} . To do this comparison, we represent data (multi-domains public datasets from Figure \ref{fig:chrtokens} in grey, each alternative dataset \flores, NTREX-128 and NLLB-MD and \bouquet) with SONAR \citep{duquenne2023sonarsentencelevelmultimodallanguageagnostic}. %We represent these data with SONAR \citep{duquenne2023sonarsentencelevelmultimodallanguageagnostic}. 
From SONAR vectors, we do a PCA-dimensionality reduction, see Figure \ref{fig:domrep}. All domains from Figure \ref{fig:chrtokens} are represented in grey. Then, Figure \ref{fig:domrep} from left to right compares \bouquet against \flores, NTREX-128 and NLLB-MD, respectively. We qualitatively observe that \bouquet covers a wider range of domains.

Additionally, to quantify this coverage, we measure the overlap between each dataset with each of the domains using two metrics, the Wasserstein distance (implemented with POT library\footnote{\url{https://pythonot.github.io/}}) and the Silhouette coefficient (implemented with sklearn\footnote{\url{https://scikit-learn.org/stable/}}). The Wasserstein Distance (WD), also known as the Earth Mover’s Distance (EMD), is a metric that measures the "effort" required to transform one probability distribution into another. Lower results indicate a higher similarity between clusters. The lowest consistent results for all domains are obtained with the data set \bouquet. Alternatively, the Silhouette Score (SS) \footnote{\url{https://en.wikipedia.org/wiki/Silhouette_(clustering)}} measures how well each data point fits within its assigned cluster compared to other clusters, it ranges between -1 and 1 and the higher the coefficient, the more coherent the clusters are. Again, \bouquet shows a lower score, consistent across domains, meaning closer representation across domains. %specially for social media content and how-to.



\begin{figure}[h!]
\centering
 \includegraphics[width=0.3\textwidth]{figures/pca_bouquet_flores.png}
    \includegraphics[width=0.3\textwidth]{figures/pca_bouquet_ntrex.png}
  \includegraphics[width=0.3\textwidth]{figures/pca_bouquet_nllb.png}


  \caption{ Domain representation and overlap with datasets (\flores, NTREX-128, NLLB-MD)
\label{fig:domrep}}
\end{figure}


%\section{\fullbouquet{} description}

%\todo{In this section, we should provide a description of the resulting dataset (maybe, even comparing it with others) and maybe give several examples of sentences from the dev subset.}





\begin{table}
\scriptsize
\centering
\begin{tabular}{lcccccccccccccccc}
\hline
 & \multicolumn{2}{c}{\multirow{2}{*}{\tiny \textsc{Narration}}} & \multicolumn{2}{c}{\multirow{2}{*}{\tiny \textsc{Website}}} & \multicolumn{2}{c}{\multirow{2}{*}{\tiny \textsc{Opinion}}} & \multicolumn{2}{c}{\multirow{2}{*}{\tiny \textsc{Dialog}}} & \multicolumn{2}{c}{\tiny \textsc{Social media}} & \multicolumn{2}{c}{\tiny \textsc{Social media}} & \multicolumn{2}{c}{\multirow{2}{*}{\tiny \textsc{How-to}}} & \multicolumn{2}{c}{\multirow{2}{*}{\tiny \textsc{Misc.}}} \\
&  &  &  & & & & & & \multicolumn{2}{c}{\tiny \textsc{comments}} &   \multicolumn{2}{c}{\tiny \textsc{posts}} & \\
\hline
&{\tiny \textsc{WD}} & {\tiny \textsc{SC}} &{\tiny \textsc{WD}} & {\tiny \textsc{SC}}&{\tiny \textsc{WD}} & {\tiny \textsc{SC}} &{\tiny \textsc{WD}} & {\tiny \textsc{SC}} &{\tiny \textsc{WD}} & {\tiny \textsc{SC}}&{\tiny \textsc{WD}} & {\tiny \textsc{SC}}&{\tiny \textsc{WD}} & {\tiny \textsc{SC}} &{\tiny \textsc{WD}} & {\tiny \textsc{SC}} \\
\hline


\tiny{\textsc{\flores}} & 0.32 & 0.05& 0.32 & 0.03& 0.32 & 0.02& 0.31& 0.11 & 0.32& 0.09 & 0.31 &0.08 & 0.31 &0.06& 0.33 &0.03 \\

\tiny{\textsc{NTREX-128}} & 0.32 & 0.04 & 0.31& 0.03 & 0.32& 0.01 & 0.31& 0.09 & 0.31& 0.07 & 0.31& 0.6 & 0.31 &0.06 & 0.33 &0.03\\

\tiny{\textsc{NLLB-MD}} & 0.31 & 0.04 & 0.31 &0.02 & 0.31&0.00 & 0.30&0.08 & 0.31 & 0.06& 0.30 & 0.05 & 0.30& 0.05 & 0.32 &0.02 \\

\tiny{\textsc{Bouquet}} & \textbf{0.29} & \textbf{-0.02} & \textbf{0.29} &\textbf{-0.02}& \textbf{0.30}&\textbf{-0.03}  & \textbf{0.28} &\textbf{0.02} & \textbf{0.29} &\textbf{0.01} & \textbf{0.28} & \textbf{0.00} & \textbf{0.28} & \textbf{0.00}& \textbf{0.30} & \textbf{-0.01} \\
\hline
\end{tabular}
\caption{Wasserstein Distance (WD) and Silhouette Score (SS) for each domain and dataset. Lower WD and SS indicate better representation of the domain. Best results in bold.}
\label{tab:domain-distribution}
\end{table}

\paragraph{MT Benchmarking} To help the reader understand why the dataset is useful, we present preliminary results to demonstrate its use for its intended purpose: MT benchmarking. We evaluated on translation systems (\gpt \citep{wu2024gpt4ovisualperceptionperformance}, 
\llamathree (Llama-3.3-8B)\citep{touvron2023llama}, %Tower (tower-0.2-7b-instruct) \citep{rei-etal-2024-tower}, %Aya (Aya-Expanse-32B, Aya-Expanse-8B) \citep{aya} 
and NLLB (NLLB-3.3B) \citep{nllbteam2022language}) using two metrics: Comet (CometKiwi-da-xl, range 0-1 and $\uparrow$ better) \citep{chimoto-bassett-2022-comet} and MetricX (MetricX-24, range 0-25 and $\downarrow$ better) \citep{juraska-etal-2024-metricx}, following WMT 2024 \citep{kocmi-etal-2024-findings}. See results in Table \ref{tab:results}. We observe that \bouquet scores consistently higher than NLLB-MD on average and for all models, suggesting that \bouquet is easier to translate. This is an advantage for the open initiative, since the complexity of current MT test sets makes it harder to ask the community to participate in translations as it requires a high-level of expertise. Rankings across models nor languages is not preserved, which hints that \bouquet may be posing different challenges to the models. We need to further investigate which linguistic challenges \bouquet is adding. On this ranking, if we look at average \bouquet, LlaMa is the worst system according to Comet but the best system according to Metricx. This does not happen in NLLB-MD, where the ranking is consistent across metrics. If we look per language, ranking across metrics is consistent for 4 out of 7 languages for NLLB-MD and for 1 out of 7 languages for \bouquet. This raises a concern and may suggest that MT metrics themselves do not generalize well to the broader domains/registers in \bouquet. However, this requires further investigation and we want to specifically explore different alternatives to use \bouquet such as exploring the performance by domain and register. Note that we present only preliminary experiments, see Section \ref{sec:conclusions} for more details on ongoing experiments. %For examples, we want to specifically explore different alternatives to use \bouquet such as exploring the performance by domain and register.   %in English to the 7 \bouquet languages in Quality Estimation metrics that include Comet (CometKiwi-da-xl) \citep{chimoto-bassett-2022-comet}, MetricX (MetricX-24) \citep{juraska-etal-2024-metricx}. %, BLASER-QE \citep{dale-costa-jussa-2024-blaser}. 



\begin{table}[ht!]
\centering
\scriptsize
%\sisetup{table-format = 3.2}
%\resizebox{\textwidth}{!}{%
%\begin{tabular}{@{}p{2.2cm}ccccc@{}}
\begin{tabular}{lcccccccccccccccc}
\toprule
 M & \multicolumn{2}{c}{\textsc{cmn}} &  \multicolumn{2}{c}{\textsc{deu}} &  \multicolumn{2}{c}{\textsc{fra}} &  \multicolumn{2}{c}{\textsc{hin}} &  \multicolumn{2}{c}{\textsc{ind}} &  \multicolumn{2}{c}{\textsc{rus}} &  \multicolumn{2}{c}{\textsc{spa}} &   \multicolumn{2}{c}{\textsc{AVG}}   \\
 & {\tiny \textsc{COM($\uparrow$)}} & {\tiny \textsc{MetX($\downarrow$)}}  & {\tiny \textsc{COM}} & {\tiny \textsc{MetX}}   & {\tiny \textsc{COM}} & {\tiny \textsc{MetX}}  & {\tiny \textsc{COM}} & {\tiny \textsc{MetX}}   & {\tiny \textsc{COM}} & {\tiny \textsc{MetX}}   & {\tiny \textsc{COM}} & {\tiny \textsc{MetX}}   & {\tiny \textsc{COM}} & {\tiny \textsc{MetX}}  & {\tiny \textsc{COM}} & {\tiny \textsc{MetX}}   \\
\midrule
\addlinespace[0.3em]
\multicolumn{17}{c}{NLLB-MD} \\

\addlinespace[0.3em]
\midrule
%\midrule
%\addlinespace[0.3em]
 GPT4o & 0.76 & 14.34 & 0.77 & 6.80 & 0.76 & 13.86 & 0.68 & 6.63 & 0.79 & 16.16 & 0.78 & 3.96 & 0.80 & 13.99 & 0.76 & 10.81 \\
\addlinespace[0.3em]

%&Llama-3.1-70B \\
%\addlinespace[0.3em]

%& Aya-Expanse-32B \\

% & Aya-Expanse-8B \\

Llama  & 0.71 & 14.38 & 0.71 & 6.96 & 0.72 & 14.00 & 0.57 & 7.07 & 0.75 & 16.21 & 0.71 & 4.00 & 0.75 & 14.11 & 0.70 & 10.96 \\
%\addlinespace[0.5em]

% Tower\\

NLLB  & 0.61 & 14.80 & 0.70 & 7.01 & 0.70 & 13.98 & 0.64 & 6.72 & 0.73 & 16.20 & 0.72 & 4.43 & 0.76 & 14.06 & 0.69 & 11.03 \\

\midrule
\addlinespace[0.3em]

\multicolumn{17}{c}{\bouquet}\\
\addlinespace[0.3em]
\midrule
\addlinespace[0.3em]

GPT4o & 0.79 & 1.99 & 0.80 & 2.79 & 0.78 & 5.57 & 0.76 & 3.37 & 0.84 & 4.07 & 0.81 & 3.60 & 0.83 & 4.74 & 0.80 & 3.73 \\
%\addlinespace[0.3em]

\textsc{Llama} & 0.75 & 2.06 & 0.76 & 2.07 & 0.74 & 4.68 & 0.72 & 3.19 & 0.83 & 3.54 & 0.75 & 3.26 & 0.80 & 4.07 & 0.76& 3.27 \\
%\addlinespace[0.3em]

%& Aya-Expanse-32B \\

% & Aya-Expanse-8B \\

%&Llama-3.1-8B   \\
%\addlinespace[0.5em]

% Tower\\

\textsc{NLLB}  & 0.67 & 2.19 & 0.79 & 2.44 & 0.77 & 5.30 & 0.74 & 3.49 & 0.82 & 3.94 & 0.78 & 3.40 & 0.67 & 4.42 & 0.77 & 3.60 \\
%\addlinespace[0.5em]
\bottomrule
\end{tabular}%
%}%resizebox
\caption{Results on Quality Estimation from English to 7 \sourcebouquet languages on \bouquet evaluation dataset \label{tab:results}.}
\end{table}

\begin{comment}

\begin{table}[ht!]
\centering
\tiny
%\sisetup{table-format = 3.2}
%\resizebox{\textwidth}{!}{%
%\begin{tabular}{@{}p{2.2cm}ccccc@{}}
\begin{tabular}{lcccccccccccccc}
\toprule
 Model & \multicolumn{2}{c}{\textsc{nar}} &  \multicolumn{2}{c}{\textsc{soc-p}} &  \multicolumn{2}{c}{\textsc{soc-c}} &  \multicolumn{2}{c}{\textsc{how-to}} &  \multicolumn{2}{c}{\textsc{misc-w}} &  \multicolumn{2}{c}{\textsc{opi}} &  \multicolumn{2}{c}{\textsc{misc-o}}   \\
 & {\textsc{COM}} & \textsc{MetX} & {\textsc{COM}} & \textsc{MetX} & {\textsc{COM}} & \textsc{MetX} & {\textsc{COM}} & \textsc{MetX} & {\textsc{COM}} & \textsc{MetX} &  {\textsc{COM}} & \textsc{MetX}  &  {\textsc{COM}} & \textsc{MetX} \\
\midrule
\addlinespace[0.3em]
\multicolumn{15}{c}{\bouquet}\\
\addlinespace[0.3em]
\midrule
\addlinespace[0.3em]

 GPT-4o \\
%\addlinespace[0.3em]

Llama \\
%\addlinespace[0.3em]

%& Aya-Expanse-32B \\

% & Aya-Expanse-8B \\

%&Llama-3.1-8B   \\
%\addlinespace[0.5em]

% Tower\\

NLLB   \\
%\addlinespace[0.5em]
\bottomrule
\end{tabular}%
%}%resizebox
\caption{Results on Quality Estimation from English to 7 \sourcebouquet languages per domain \label{tab:resultsdomains}.}
\end{table}
\end{comment}

\section{Open initiative}

 \sourcebouquet is intended to be translated into any written language. This ambition can only be achieved with the support of the community. For this, we have organized an open collaborative effort which involves language communities that are interested in contributing to this effort. 
 
The purpose of this open initiative is to collect translations from \sourcebouquet.  To collect these annotations, we have chosen the ARGILLA tool\footnote{\url{https://argilla.io/}} which is a collaboration platform for building datasets, designed for use by AI engineers and domain experts. 

Together with setting the \sourcebouquet in this tool, we have designed annotation guidelines which very much resemble those from \flores \citep{nllbteam2022language}.

This open initiative is available in HuggingFace  \url{https://huggingface.co/spaces/facebook/bouquet
} and it is starting as part of the Meta Language Technology Partner Program\footnote{\url{https://docs.google.com/forms/d/e/1FAIpQLSdzcRdtkQCuTrXw727DgJgWbOPKDj5v0bArgGfQUTT6sEopFw/viewform}} publicly launched in AI Summit\footnote{\url{https://www.elysee.fr/en/sommet-pour-l-action-sur-l-ia}}. 
 
% This \bouquet launch includes: this paper and an ARGILLA entry shared in Hugging Face \todo{ADDLINK} with the \sourcebouquet and detailed translation guidelines in English. 
%\item Translation guidelines that are versionable to translate  \sourcebouquet into the annotators language. 
%\end{itemize}

\section{Conclusions and Next Steps}
\label{sec:conclusions}

In this paper, we have presented the \sourcebouquet dataset and the attached open initiative. This dataset is available in 8 languages. We have shown that consistent \bouquet gains in domain diversity by in two different metrics while keeping complexity lower than its competitors. The latter is specially relevant to simplify the translation for non-experts that may join the open initiative. This paper and \sourcebouquet is only a fraction of the ambitious project that we are starting by launching this open call for community efforts. Please join us in making Universal Quality Evaluation in Translation available in any language!

\paragraph{Limitations} \bouquet is work in progress; the \bouquet dataset is still limited in number of languages and translations. The benchmarking is also limited in several axes (dataset comparison, models and metrics evaluated). However, we prioritized starting the \bouquet open initiative in coordination with the Meta Language Technology Partner Program launch so that we could start raising the collaboration interest. As OmnilingualMT team, we continue actively investing on it, see next steps that we are planning to release soon. 

\paragraph{Coming Soon} \bouquet is actively evolving and we are currently working on making the following progress:

\begin{itemize}
\item Adding 250 sentences in \sourcebouquet in Egyptian Arabic.
\item Complete \sourcebouquet in all 7 languages from Table \ref{tab:lang} plus Egyptian Arabic.
\item The creation guidelines plus translation guidelines in all 8 pivot languages.
\item Designing quality control for each of the contributions and adding new languages to the incremental releases of \bouquet.
\item Extending the Benchmarking by further showing the capabilities of \bouquet, e.g. increasing the evaluation of linguistic signals over its alternatives (\flores, NTREX-128, and NLLB-MD). For this, we propose to explore the performance in different domains and see if we get difference in the performance ranking of translation systems.
\end{itemize}



%\section*{Limitations}

%Current work is under development

\section*{Acknowledgments}
We would like to extend our sincere gratitude to Luis Cadavid, Radhi Datla, Suci Fitriany, Christine Haugen, Stephanie Mauro, Carissa Ikka Pardamean, Gauri Shanware, and Jyoti Singh for their invaluable contributions to the work presented in this paper. 
\bibliographystyle{abbrvnat}
\bibliography{anthology,custom,bib-bouquet}

\appendix


\input{guidance}

\section{Contribution Statement}



\textbf{Pierre Andrews:} \textit{Open initiative}; Supervision/Leadership; core; tool deployment and design

\textbf{Mikel Artetxe:} \textit{ Benchmarking}; Supervision; support 

\textbf{Mariano Coria Meglioli:} \textit{ Dataset}; core; statistical analysis 

\textbf{Marta R. Costa-jussa:} \textit{ Dataset, Benchmarking, Tooling Supervision/Leadership}; core; corresponding author; research direction, paper editor

\textbf{Joe Chuang:} \textit{ Dataset}; core; source-bouquet creator

\textbf{David Dale:} \textit{ Benchmarking}; Supervision/Leadership; core; evaluation and experimental design

\textbf{Cynthia Gao:} \textit{ Dataset}; support

\textbf{Jean Maillard:} \textit{ Open initiative}; core, licensing

\textbf{Alex Mourachko:} \textit{ Management}; support

\textbf{Christophe Ropers: } \textit{Dataset and Open initiative}; Supervision/Leadership; core; dataset design and 
creation, guidelines design and creation, paper editor

\textbf{Safiyyah Saleem:} \textit{ Management}; support

\textbf{Eduardo Sánchez:} \textit{ Benchmarking}; core; experiments deployment

\textbf{Yiannis Tsiamas:} \textit{ Benchmarking}; support 

\textbf{Arina Turkatenko:} \textit{ Dataset}; core; dataset creation 

\textbf{Albert Ventayol-Boada:} \textit{ Dataset}; core; dataset creation 

\textbf{Shireen Yates: } \textit{Management}; support


\end{document}
