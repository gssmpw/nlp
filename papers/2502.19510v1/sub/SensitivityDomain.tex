%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\section{Sensitivity of a function depending on a subset of the boundary of a domain} \label{sec.Preliminaries}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\noindent Let $\Omega$ be a smooth bounded domain in $\R^d$ ($d=2,3$).
We consider a model shape and topology optimization problem of the form: 
\begin{equation}\label{eq.sopb}
\tag{\textcolor{gray}{${\mathcal P}$}}
 \min\limits_{G \subset \partial \Omega} J(G),
 \end{equation}
 where $J(G)$ is a given objective function depending on the region $G \subset \partial \Omega$ to be optimized. 
 This formulation omits constraints for simplicity of the presentation, but their treatment with the material developed in this article does not entail any additional difficulty from the conceptual viewpoint.
 
The analysis of the problem \cref{eq.sopb} hinges on the sensitivity of $J(G)$ with respect to ``small'' variations of $G$. In this section, we introduce two complementary means to appraise the notion of derivative with respect to a boundary region: 
\begin{itemize}
\item In \cref{sec.hadamard}, we adapt the ``classical'' boundary variation method of Hadamard to the context of a subset $G$ of the boundary $\partial\Omega$. This paves the way to a notion of shape derivative, that accounts for the sensitivity of $J(G)$ with respect to small perturbations of the boundary of $G$.
\item In \cref{sec.topderbc}, we define a suitable version of the concept of topological derivative, which appraises the sensitivity of $J(G)$ with respect to the addition of a ``small'' surface disk to $G$.
\end{itemize}
A sketch of our numerical solution strategy for \cref{eq.sopb} based on these ingredients is provided in \cref{sec.algoth}.\par\medskip

\noindent \textbf{Notation.} Throughout this article, $\Omega \subset \R^d$ is a fixed, smooth bounded domain, 
and the optimized design $G$ is a smooth open subset of its boundary $\partial \Omega$. Moreover,
\begin{itemize}
\item At any point $x \in \partial \Omega$, we denote by $n(x)$ the unit normal vector to $\partial \Omega$ at $x$, pointing outward $\Omega$.
\item The tangent plane $T_x\partial \Omega$ at $x \in \partial \Omega$ is the vector hyperplane defined by
$$ T_x \partial\Omega := \left\{ \tau = (\tau_1,\ldots,\tau_d) \in \R^d \text{ s.t. } n(x) \cdot \tau = 0 \right\}.$$
\item The tangential gradient of a smooth function $f : \partial \Omega \to \R$ is denoted by $\nabla_{\partial \Omega}f$. 
By definition, $\nabla_{\partial\Omega} f = \nabla \widetilde{f} - (\nabla \widetilde{f} \cdot n) n$, where $\widetilde{f} : \R^d \to \R$ is an arbitrary smooth extension of $f$ to $\R^d$. 
\item We denote by $\dv_{\partial \Omega}(V)$ the tangential divergence of a smooth vector field $V : \partial \Omega \to \R^d$. 
By definition, $\dv_{\partial \Omega}(V) = \dv(\widetilde{V}) - \nabla \widetilde{V} n \cdot n$,  for any smooth extension $\widetilde{V} : \R^d \to \R^d$ of $V$ to $\R^d$.
\item We denote by $\Sigma = \partial G$ the boundary of $G$, and by $\d\ell$ the integration on $\Sigma$, i.e. the restriction of the $(d-2)$-dimensional Hausdorff measure on this set. 
\item For any point $x \in \Sigma$, $n_\Sigma(x) \in T_x \partial \Omega$ is the unit conormal vector to $\Sigma$ at $x$, pointing outward $G$.
\item Obviously, the functionals $J(G)$ of interest depend not only on the region $G$ of $\partial \Omega$, 
but also on the whole domain $\Omega$. As the latter is fixed, this dependence is omitted. 
\end{itemize}
We refer to \cref{fig.bdyrep} for an illustration of some of these definitions.

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\subsection{Hadamard's boundary variation method}\label{sec.hadamard} 
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%


\noindent In this section, we adapt the classical method of Hadamard to estimate the sensitivity of a functional $J(G)$ with respect to perturbations of the boundary $\Sigma$ of $G$. Following \cite{allaire2020survey,allaire2007conception,henrot2018shape,murat1976controle}, we consider variations of the reference domain $\Omega$ of the form:
\begin{equation} \label{eq.Omtheta}
    \Omega_\theta := (\Id + \theta)(\Omega), \quad \text{where} \quad \theta \in \Winfty , \quad \lvert\lvert \theta \lvert\lvert_{\Winfty} < 1.
\end{equation}
The variations $G_\theta$ of $G \subset \partial \Omega$ induced by this operation read: 
\begin{equation} \label{eq.Gtheta}
G_\theta := (\Id + \theta)(G),
\end{equation}
see \cref{fig.bdyrep}. This leads to the following definition of the shape derivative of a functional $J$ depending on a region $G \subset \partial \Omega$.

\begin{definition}\label{def.SD}
The functional $J(G)$ is shape differentiable at $G \subset \partial \Omega$ if the mapping $\theta \mapsto J(G_\theta)$, defined from a neighborhood of $0$ in $\Winfty$ into $\mathbb{R}$, is Fr\'echet differentiable at $\theta = 0$. The corresponding shape derivative $J^\prime(G)(\theta)$ then satisfies the following expansion:
    \begin{equation}\label{eq.JGthetaHadamard}
        J(G_\theta) = J(G) + J^\prime(G)(\theta) + \o(\theta), \quad \mathrm{where} \quad \dfrac{\o(\theta)}{\lvert\lvert \theta \lvert\lvert_{\Winfty}} \xrightarrow{\theta \to 0} 0.
    \end{equation}
\end{definition}

The shape derivative $J^\prime(G)(\theta)$ of a functional $J(G)$ allows to identify descent directions for $J(G)$, i.e. vector fields $\theta$ such that $J^\prime(G)(\theta) < 0$.
Loosely speaking, the region $G_{\tau\theta}$ resulting from the deformation of $G$ via such a vector field $\theta$, for a small enough (pseudo-)time step $\tau >0$, performs ``better'' than $G$, i.e.: 
$$ J(G_{\tau\theta}) \approx J(G) + \tau J^\prime(G)(\theta) < 0.$$

\begin{figure}[!ht]
    \centering
    \includegraphics[width=0.6\linewidth]{figures/setoptbc}
    \caption{\it Perturbation $G_\theta$ of a region $G \subset \partial \Omega$ induced by a ``small'' vector field $\theta$ in \cref{sec.hadamard}. When $\theta \cdot n \equiv 0$, the boundary $\partial \Omega_\theta$ of the perturbed domain $\Omega_\theta$ coincides with $\partial \Omega$ at first order, and the deformation $\theta$ causes $G$ to ``slide'' within $\partial \Omega$.}
    \label{fig.bdyrep}
\end{figure}

\begin{remark}\label{rem.TG}
In practice, we shall restrict the set of deformations $\theta$ featured in our implementation of Hadamard's method so as to accommodate some specificities of our applications:
\begin{enumerate}[(i)]
\item We are especially interested in deformations $\theta$ which leave the domain $\Omega$ invariant, thus giving rise to perturbations $G_\theta$ resulting from a ``sliding'' of $G$ within $\partial \Omega$. Hence, we shall often restrict ourselves to tangential vector fields $\theta$, satisfying $\theta \cdot n \equiv 0$ on $\partial \Omega$. Note that, strictly speaking, these do not leave $\Omega$ invariant: they only do so ``at first order''.
Actually, if variations of $\Omega$ were defined within the alternative framework of the so-called velocity method \cite{delfour2011shapes,sokolowski1992introduction} instead of that of the method of Hadamard, i.e. if we were to set
\begin{multline*}
 \Omega_\theta = \chi_\theta(1,\Omega), \text{ where } (t,x) \mapsto \chi_\theta(t,x) \text{ is the flow of } \theta, \text{ defined by } \\
  \left\{
\begin{array}{cl}
\frac{\partial \chi_\theta}{\partial t}(t,x) = \theta(\chi_\theta(t,x)) & \text{for } t >0,\\
\chi_\theta(0,x) = x, &
\end{array}
\right.
\end{multline*}
then the action of a tangential vector field $\theta$ on $\Omega$ would ensure that $ \Omega_\theta$ coincide with $\Omega$.
For simplicity, and since the velocity method and the method of Hadamard induce the same notion of first-order shape derivative, we ignore this technicality in the following.
\item The boundary $\partial \Omega$ is often composed of several regions, $G$ being the only one subjected to optimization. Accordingly, the deformations $\theta$ considered in the method of Hadamard should vanish on those other regions of $\partial \Omega$ excluded from the optimization.  
\item The handling of some geometric quantities attached to $G$ requires the latter to be ``smooth enough'', as well as its variations $G_\theta$, see e.g. the results summarized in \cref{sec.distmanifold} about the geodesic signed distance function.
\end{enumerate}
As a result, we shall restrict the set of deformations $\theta$ to a subset $\Theta_G \subset \Winfty$ made of smooth tangential vector fields, vanishing ``far'' from the optimized region $G$. 
\end{remark}

The shape derivatives of the functionals $J(G)$ considered in this article often turn out to be of the form
\begin{equation} \label{eq.ShapeDerivatives.Structure}
\forall \theta \in \Theta_G, \quad J^\prime(G) (\theta) = \int_{\Sigma} v_G \:\theta\cdot n_{\Sigma} \:\d \ell,
 \end{equation}
where the scalar field $v_G : \Sigma \to \R$ depends on the region $G$ and the considered objective function $J(G)$. 
It may involve the solution to one or several boundary value problems attached to $\partial \Omega$ and $G$, see for instance \cref{sec.hepsconduc} below. 
The structure \cref{eq.ShapeDerivatives.Structure} is very reminiscent of the ``classical'' structure theorem for the derivative of functions of a bulk domain $\Omega$, see e.g. \S 5.9 in \cite{henrot2018shape}. 
It conveniently reveals a descent direction for $J(G)$; indeed, letting $\theta = - v_G n_{\Sigma}$ leads to: 
$$ J^\prime(G)(\theta)= -\int_\Sigma v_G^2 \:\d \ell \: <\: 0.$$

Before closing this section, let us introduce two simple and ubiquitous examples of functionals depending on the boundary region $G$, namely the area $\Area(G)$ and contour $\Cont(G)$, which are respectively defined by:
\begin{equation}\label{eq.volper}
 \Area(G) = \int_G \:\d s, \text{ and } \Cont(G) = \int_{\Sigma} \:\d \ell.
 \end{equation}
The next proposition supplies the shape derivatives of slightly more general versions of these quantities. 
Its proof is an elementary adaptation of classical arguments, found in e.g. \cite{henrot2018shape} and Chap. 17 of \cite{maggi2012sets}, and it is omitted for brevity.

\begin{proposition}\label{prop.simplesd}
Let $G$ be smooth region of the boundary $\partial \Omega$. Then, 
\begin{enumerate}[(i)]
\item For any smooth function $f : \R^d \to \R$, the functional $J(G)$ defined by:
$$ J(G) := \int_G f \:\d s$$
is shape differentiable; its shape derivative reads, for any tangential deformation $\theta$ (i.e. $\theta \cdot n=0$): 
$$ J^\prime(G)(\theta) = \int_{\Sigma} f \theta \cdot n_\Sigma \:\d \ell.$$
\item For any smooth function $g : \R^d \to \R$, the functional $K(G)$ defined by:
$$ K(G) := \int_\Sigma g \:\d \ell$$
is shape differentiable; its shape derivative reads, for any tangential deformation $\theta$: 
$$ K^\prime(G)(\theta) = \int_{\Sigma} (\nabla_{\partial \Omega} g \cdot n_\Sigma + \kappa g) \theta \cdot n_\Sigma \:\d \ell,$$
where $\kappa:= \dv_{\partial \Omega}(n_\Sigma)$ is the mean curvature of $\Sigma$.
\end{enumerate}
\end{proposition}  

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\subsection{Topological perturbations of subsets of the boundary of a domain}\label{sec.topderbc}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\noindent The variations $G_\theta$ of the region $G \subset \partial \Omega$ featured in the method of Hadamard of \cref{sec.hadamard} share the same topology as $G$, i.e. they have the same number of holes, and the same number of connected components \cite{evans2015measure}. 
Hence, strictly speaking, the notion of shape derivative in \cref{def.SD} does not account for the sensitivity of $J(G)$ to topological changes in $G$. 
Admittedly, in practice, certain topological changes may occur as $G$ evolves according to \cref{eq.Gtheta}: separate parts of the boundary $ \Sigma$ of $G$ may collide and merge by a slight abuse of the theoretical framework (i.e. when the norm constraint $\lvert\lvert \theta\lvert\lvert_{\Winfty} < 1$ is omitted in \cref{eq.Gtheta}), 
but in any event, no hole can emerge inside $G$, and no new connected component can be added to $G$, see \cite{allaire2020survey} for related discussions. 

We introduce in this section a complementary notion of derivative for functions $J$ of a region $G$ of $\partial \Omega$.
The latter proceeds via the addition of a small surface disk to $G$. 
More precisely, let us denote by
\begin{equation}\label{eq.LHS} 
H := \left\{ x = (x_1,\ldots,x_d) \text{ s.t. } x_d < 0 \right\}, \text{ and } \D_\e := \left\{ x = (x_1,\ldots,x_{d-1} , 0) \in \partial H \text{ s.t. } \lvert x \lvert < \e \right\}
\end{equation}
the lower half-space in $\R^d$ and the planar disk with center $0$ and radius $\e$, respectively. 
Let $x \in \partial \Omega \setminus \overline G$;
since the domain $\Omega$ is smooth, there exists an open neighborhood $\calO$ of $0$ in $\R^d$ and a smooth diffeomorphism $T: \calO \to T(\calO)$ such that:
\begin{equation}\label{eq.surfdisk}
T(0) = x \text{ and } T(H \cap \calO) = \Omega \cap T(\calO).
 \end{equation}
We then define the surface disk $\omega_{x,\e} \subset \partial \Omega$ with center $x$ and radius $\e$ by:
\begin{equation}\label{eq.defomeps}
 \omega_{x,\e} = T(\D_\e),
\end{equation}
and we consider variations $G_{x,\e}$ of $G$ of the form: 
\begin{equation}\label{eq.defGetopder}
 G_{x,\e} := G \cup \omega_{x,\e},
 \end{equation}
see \cref{fig.topderbc} for an illustration.

\begin{figure}[!ht]
    \centering
    \includegraphics[width=1.\linewidth]{figures/settopbc}
    \caption{\it Variation $G_{x,\e}$ in \cref{eq.defGetopder} of a surface region $G \subset \partial\Omega$ obtained by addition of a ``small'' surface disk $\omega_{x,\e}$.}
    \label{fig.topderbc}
\end{figure}


\begin{definition}\label{def.TD}
A function $J(G)$ has a topological derivative $\d_T J(G)(x)$ at $x \in \partial \Omega \setminus \overline G$ if there exists a function $\rho : \R_+ \to \R_+$ such that $\rho(\e) \to 0$ as $\e \to 0$, and the following asymptotic expansion holds: 
$$ J(G_{x,\e}) = J(G) + \rho(\e) \d_T J(G)(x) + \o(\rho(\e)).$$
\end{definition}

Loosely speaking, the negative values of $\d_T J(G)(x)$ indicate that it is beneficial to attach a ``small'' surface disk $\omega_{x,\e}$ to $G$ to decrease the value of the criterion $J(G)$.

\begin{remark}
At first sight, this definition might seem to depend on the choice of the local diffeomorphism $T$ in \cref{eq.surfdisk}; the analysis in the forthcoming sections reveals that this is not the case.
\end{remark}

\begin{remark}
One could alternatively think of topological perturbations of $G$ of the form $G \setminus \overline{\omega_{x,\e}}$, $x \in G$, i.e. perturbations resulting from the removal of a ``small'' surface disk from $G$. 
In our applications, where $G$ (resp. $\partial \Omega \setminus \overline G$) typically bears the homogeneous Dirichlet (resp. homogeneous Neumann) conditions of a boundary value problem, this would correspond to replacing a homogeneous Dirichlet boundary condition by a homogeneous Neumann condition in a ``small'' surface region $\omega_{x,\e} \subset G$, instead of replacing a homogeneous Neumann condition by a homogeneous Dirichlet condition, as we do by considering perturbations of $G$ of the form \cref{eq.defGetopder}. 
As explained in \cref{rem.repDirbyNeu}, such issues can be handled with a similar analysis as that discussed in this article, so that \cref{def.TD} is sufficient for our purpose.
\end{remark}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\subsection{Description of the general optimization strategy}\label{sec.algoth}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\noindent  The notions of shape and topological derivatives of functions of a region $G \subset \partial \Omega$, introduced in \cref{sec.hadamard,sec.topderbc},
pave the way to an optimization strategy for the solution of the problem \cref{eq.sopb}, a generic version of which is sketched in \cref{alg.sketchoptbc}. This method is reminiscent of the algorithm coupling shape and topological derivatives proposed in \cite{allaire2005structural} to deal with the optimization of ``bulk'' shapes. 

 Starting from an initial configuration $G^0$, the algorithm proceeds iteratively, producing shapes, states, descent directions, etc., indexed by the integer $n=0,\ldots$ and all 
 the corresponding instances of the various objects at play are denoted with an $^n$ superscript. 
At the $n^{\text{th}}$ stage of the process, the shape derivative $J^\prime(G^n)(\theta)$ of the objective function is calculated at $G^n$, and a descent direction $\theta^n$ is inferred from the structure \cref{eq.ShapeDerivatives.Structure}. The new shape $G^{n+1} := (\Id + \tau^n \theta^n)(G^n)$ is then obtained by displacing $G^n$ in this direction for a suitably small time step $\tau^n$. Every $\ntop$ iteration, this procedure is replaced with the calculation of the topological derivative $\d_T J(G^n)(x)$, and the addition of a small surface disk $\omega_{x,\e}$ to $G^n$ around the point $x \in \partial \Omega \setminus \overline{G^n}$ where $\d_T J(G^n)(x)$ takes the largest negative value.

\begin{algorithm}[!ht]
\caption{Shape and topology optimization of a region $G \subset \partial \Omega$.}
\label{alg.sketchoptbc}
\begin{algorithmic}[0]
\STATE \textbf{Initialization:} \begin{itemize}
        \item Fixed domain $\Omega \subset \R^d$,
        \item Initial region $G^0 \subset \partial \Omega$.
    \end{itemize}
\FOR{$n=0,...,$ until convergence}
\IF{$n \text{ mod. } \ntop = 0$}
\STATE  \begin{enumerate}
                \item Calculate the topological derivative $\d_TJ(G^n)(x)$;
                \item Find the point $x \in \partial\Omega$ where $\d_T J(G^n)(x)$ is minimum (negative);
                \item Update $G^n$ as $G^{n+1} = G^n \cup \omega_{x,\e}$ for $\e$ small enough. 
   \end{enumerate}
\ELSE 
\STATE   \begin{enumerate}
               \item Calculate the shape derivative $J^\prime(G^n)(\theta)$;
               \item Find a descent direction $\theta^n$;
               \item Update $G^n$ as $G^{n+1} := (\Id + \tau^n\theta^n)(G^n)$, where $\tau^n$ is a suitably small time step.
\end{enumerate}

\ENDIF
\ENDFOR
\RETURN Optimized region $G^n \subset \partial\Omega$.
\end{algorithmic}
\end{algorithm}

The key ingredients of this workflow are the analytical expressions of the shape and topological derivatives of $J(G)$, which
are extensively discussed in the sequel. 
 In the next \cref{sec.optbcconduc,sec.TopologicalSensitivity}, we detail the case of the conductivity equation:
we notably give a sketch of the proofs of the results contained in our former articles \cite{bonnetier2022small,dapogny2020optimization}, which can be easily reproduced and adapted to different situations. 
We discuss the more intricate physical contexts of the Helmholtz equation and the linear elasticity system, where such results are new to the best of our knowledge, in the next \cref{sec.Helmholtz,sec.Elasticity}, mainly highlighting the differences.
A more practical version of \cref{alg.sketchoptbc}, tailored to our numerical setting is provided in \cref{sec.Numerical}, see \cref{alg.CouplingMethods.SurfaceOptimization}. 

\begin{remark}
The framework introduced in \cref{sec.hadamard,sec.topderbc} can be adapted to handle the joint optimization of the ambient domain $\Omega$ and the region of interest $G$ on the boundary of the latter. Beyond technical implementation aspects, the main needed modification to achieve this goal is to allow for deformations $\theta$ that are not necessarily tangential to $\partial\Omega$ when computing the Hadamard derivative, see \cref{eq.Omtheta,eq.Gtheta}. This would lead to a more complex expression of the shape derivative of $J(G)$, that includes contributions from the normal component $\theta \cdot n$, thus encoding how to optimize the shape of $\Omega$ independently of that of the region $G$ on its boundary. This possibility, which was considered in our earlier work \cite{dapogny2020optimization}, is ignored in the present study, which focuses on the optimization of a region on the boundary of a fixed domain. 
\end{remark}




