[
  {
    "index": 0,
    "papers": [
      {
        "key": "fu2019metricgan",
        "author": "Fu, Szu-Wei and Liao, Chien-Feng and Tsao, Yu and Lin, Shou-De",
        "title": "Metricgan: Generative adversarial networks based black-box metric scores optimization for speech enhancement"
      },
      {
        "key": "liu2021voicefixer",
        "author": "Liu, Haohe and Kong, Qiuqiang and Tian, Qiao and Zhao, Yan and Wang, DeLiang and Huang, Chuanzeng and Wang, Yuxuan",
        "title": "VoiceFixer: Toward general speech restoration with neural vocoder"
      }
    ]
  },
  {
    "index": 1,
    "papers": [
      {
        "key": "vae_ref1",
        "author": "Fang, Huajian and Carbajal, Guillaume and Wermter, Stefan and Gerkmann, Timo",
        "title": "Variational autoencoder for speech enhancement with a noise-aware encoder"
      },
      {
        "key": "vae_ref2",
        "author": "Bie, Xiaoyu and Leglaive, Simon and Alameda-Pineda, Xavier and Girin, Laurent",
        "title": "Unsupervised speech enhancement using dynamical variational autoencoders"
      }
    ]
  },
  {
    "index": 2,
    "papers": [
      {
        "key": "flow_ref",
        "author": "Nugraha, Aditya Arie and Sekiguchi, Kouhei and Yoshii, Kazuyoshi",
        "title": "A flow-based deep latent variable model for speech spectrogram modeling and enhancement"
      }
    ]
  },
  {
    "index": 3,
    "papers": [
      {
        "key": "lemercier2023storm",
        "author": "Lemercier, Jean-Marie and Richter, Julius and Welker, Simon and Gerkmann, Timo",
        "title": "Storm: A diffusion-based stochastic regeneration model for speech enhancement and dereverberation"
      },
      {
        "key": "tai2024dose",
        "author": "Tai, Wenxin and Lei, Yue and Zhou, Fan and Trajcevski, Goce and Zhong, Ting",
        "title": "Dose: Diffusion dropout with adaptive prior for speech enhancement"
      },
      {
        "key": "yang2024is_diffse",
        "author": "Yang, Yiyuan and Trigoni, Niki and Markham, Andrew",
        "title": "Pre-training Feature Guided Diffusion Model for Speech Enhancement"
      },
      {
        "key": "scheibler2024is_diffse",
        "author": "Scheibler, Robin and Fujita, Yusuke and Shirahata, Yuma and Komatsu, Tatsuya",
        "title": "Universal Score-based Speech Enhancement with High Content Preservation"
      }
    ]
  },
  {
    "index": 4,
    "papers": [
      {
        "key": "le2024voicebox",
        "author": "Le, Matthew and Vyas, Apoorv and Shi, Bowen and Karrer, Brian and Sari, Leda and Moritz, Rashel and Williamson, Mary and Manohar, Vimal and Adi, Yossi and Mahadeokar, Jay and others",
        "title": "Voicebox: Text-guided multilingual universal speech generation at scale"
      },
      {
        "key": "yang2023uniaudio",
        "author": "Yang, Dongchao and Tian, Jinchuan and Tan, Xu and Huang, Rongjie and Liu, Songxiang and Chang, Xuankai and Shi, Jiatong and Zhao, Sheng and Bian, Jiang and Wu, Xixin and others",
        "title": "Uniaudio: An audio foundation model toward universal audio generation"
      },
      {
        "key": "wang2024speechx",
        "author": "Wang, Xiaofei and Thakker, Manthan and Chen, Zhuo and Kanda, Naoyuki and Eskimez, Sefik Emre and Chen, Sanyuan and Tang, Min and Liu, Shujie and Li, Jinyu and Yoshioka, Takuya",
        "title": "Speechx: Neural codec language model as a versatile speech transformer"
      }
    ]
  },
  {
    "index": 5,
    "papers": [
      {
        "key": "zhang2024speaking",
        "author": "Zhang, Xiangyu and Liu, Daijiao and Liu, Hexin and Zhang, Qiquan and Meng, Hanyu and Garcia, Leibny Paola and Chng, Eng Siong and Yao, Lina",
        "title": "Speaking in Wavelet Domain: A Simple and Efficient Approach to Speed up Speech Diffusion Model"
      }
    ]
  },
  {
    "index": 6,
    "papers": [
      {
        "key": "yao2024promptvc",
        "author": "Yao, Jixun and Yang, Yuguang and Lei, Yi and Ning, Ziqian and Hu, Yanni and Pan, Yu and Yin, Jingjing and Zhou, Hongbin and Lu, Heng and Xie, Lei",
        "title": "Promptvc: Flexible stylistic voice conversion in latent space driven by natural language prompts"
      },
      {
        "key": "yao2024stablevc",
        "author": "Yao, Jixun and Yan, Yuguang and Pan, Yu and Ning, Ziqian and Ye, Jiaohao and Zhou, Hongbin and Xie, Lei",
        "title": "StableVC: Style Controllable Zero-Shot Voice Conversion with Conditional Flow Matching"
      }
    ]
  },
  {
    "index": 7,
    "papers": [
      {
        "key": "liu2024aligning",
        "author": "Liu, Hexin and Zhang, Xiangyu and Garcia, Leibny Paola and Khong, Andy WH and Chng, Eng Siong and Watanabe, Shinji",
        "title": "Aligning Speech to Languages to Enhance Code-switching Speech Recognition"
      }
    ]
  },
  {
    "index": 8,
    "papers": [
      {
        "key": "yanggenhancer",
        "author": "Yang, Haici and Su, Jiaqi and Kim, Minje and Jin, Zeyu",
        "title": "Genhancer: High-Fidelity Speech Enhancement via Generative Modeling on Discrete Codec Tokens"
      }
    ]
  },
  {
    "index": 9,
    "papers": [
      {
        "key": "wang2024selm",
        "author": "Wang, Ziqian and Zhu, Xinfa and Zhang, Zihan and Lv, YuanJun and Jiang, Ning and Zhao, Guoqing and Xie, Lei",
        "title": "SELM: Speech enhancement using discrete tokens and language models"
      }
    ]
  },
  {
    "index": 10,
    "papers": [
      {
        "key": "hsu2021hubert",
        "author": "Hsu, Wei-Ning and Bolte, Benjamin and Tsai, Yao-Hung Hubert and Lakhotia, Kushal and Salakhutdinov, Ruslan and Mohamed, Abdelrahman",
        "title": "Hubert: Self-supervised speech representation learning by masked prediction of hidden units"
      }
    ]
  },
  {
    "index": 11,
    "papers": [
      {
        "key": "chen2022wavlm",
        "author": "Chen, Sanyuan and Wang, Chengyi and Chen, Zhengyang and Wu, Yu and Liu, Shujie and Chen, Zhuo and Li, Jinyu and Kanda, Naoyuki and Yoshioka, Takuya and Xiao, Xiong and others",
        "title": "Wavlm: Large-scale self-supervised pre-training for full stack speech processing"
      }
    ]
  },
  {
    "index": 12,
    "papers": [
      {
        "key": "borsos2023audiolm",
        "author": "Borsos, Zal{\\'a}n and Marinier, Rapha{\\\"e}l and Vincent, Damien and Kharitonov, Eugene and Pietquin, Olivier and Sharifi, Matt and Roblek, Dominik and Teboul, Olivier and Grangier, David and Tagliasacchi, Marco and others",
        "title": "Audiolm: a language modeling approach to audio generation"
      }
    ]
  },
  {
    "index": 13,
    "papers": [
      {
        "key": "defossez2022encodec",
        "author": "D{\\'e}fossez, Alexandre and Copet, Jade and Synnaeve, Gabriel and Adi, Yossi",
        "title": "High fidelity neural audio compression"
      }
    ]
  },
  {
    "index": 14,
    "papers": [
      {
        "key": "borsos2023audiolm",
        "author": "Borsos, Zal{\\'a}n and Marinier, Rapha{\\\"e}l and Vincent, Damien and Kharitonov, Eugene and Pietquin, Olivier and Sharifi, Matt and Roblek, Dominik and Teboul, Olivier and Grangier, David and Tagliasacchi, Marco and others",
        "title": "Audiolm: a language modeling approach to audio generation"
      }
    ]
  },
  {
    "index": 15,
    "papers": [
      {
        "key": "wang2023valle",
        "author": "Wang, Chengyi and Chen, Sanyuan and Wu, Yu and Zhang, Ziqiang and Zhou, Long and Liu, Shujie and Chen, Zhuo and Liu, Yanqing and Wang, Huaming and Li, Jinyu and others",
        "title": "Neural codec language models are zero-shot text to speech synthesizers"
      }
    ]
  },
  {
    "index": 16,
    "papers": [
      {
        "key": "dong2023polyvoice",
        "author": "Dong, Qianqian and Huang, Zhiying and Tian, Qiao and Xu, Chen and Ko, Tom and Zhao, Yunlong and Feng, Siyuan and Li, Tang and Wang, Kexin and Cheng, Xuxin and others",
        "title": "Polyvoice: Language models for speech to speech translation"
      }
    ]
  },
  {
    "index": 17,
    "papers": [
      {
        "key": "wang2023lmvc",
        "author": "Wang, Zhichao and Chen, Yuanzhe and Xie, Lei and Tian, Qiao and Wang, Yuping",
        "title": "Lm-vc: Zero-shot voice conversion via speech generation based on language models"
      }
    ]
  },
  {
    "index": 18,
    "papers": [
      {
        "key": "wu2023audiodec",
        "author": "Wu, Yi-Chiao and Gebru, Israel D and Markovi{\\'c}, Dejan and Richard, Alexander",
        "title": "Audiodec: An open-source streaming high-fidelity neural audio codec"
      },
      {
        "key": "kumar2024dac",
        "author": "Kumar, Rithesh and Seetharaman, Prem and Luebs, Alejandro and Kumar, Ishaan and Kumar, Kundan",
        "title": "High-fidelity audio compression with improved rvqgan"
      },
      {
        "key": "ai2024apcodec",
        "author": "Ai, Yang and Jiang, Xiao-Hang and Lu, Ye-Xin and Du, Hui-Peng and Ling, Zhen-Hua",
        "title": "APCodec: A Neural Audio Codec with Parallel Amplitude and Phase Spectrum Encoding and Decoding"
      }
    ]
  },
  {
    "index": 19,
    "papers": [
      {
        "key": "yang2023hifi",
        "author": "Yang, Dongchao and Liu, Songxiang and Huang, Rongjie and Tian, Jinchuan and Weng, Chao and Zou, Yuexian",
        "title": "Hifi-codec: Group-residual vector quantization for high fidelity audio codec"
      },
      {
        "key": "ji2024languagecodec",
        "author": "Ji, Shengpeng and Fang, Minghui and Jiang, Ziyue and Huang, Rongjie and Zuo, Jialung and Wang, Shulei and Zhao, Zhou",
        "title": "Language-codec: Reducing the gaps between discrete codec representation and speech language models"
      },
      {
        "key": "ji2024wavtokenizer",
        "author": "Ji, Shengpeng and Jiang, Ziyue and Cheng, Xize and Chen, Yifu and Fang, Minghui and Zuo, Jialong and Yang, Qian and Li, Ruiqi and Zhang, Ziang and Yang, Xiaoda and others",
        "title": "WavTokenizer: an Efficient Acoustic Discrete Codec Tokenizer for Audio Language Modeling"
      }
    ]
  },
  {
    "index": 20,
    "papers": [
      {
        "key": "ren2024ticodec",
        "author": "Ren, Yong and Wang, Tao and Yi, Jiangyan and Xu, Le and Tao, Jianhua and Zhang, Chu Yuan and Zhou, Junzuo",
        "title": "Fewer-token neural speech codec with time-invariant codes"
      },
      {
        "key": "ju2024naturalspeech3",
        "author": "Ju, Zeqian and Wang, Yuancheng and Shen, Kai and Tan, Xu and Xin, Detai and Yang, Dongchao and Liu, Yanqing and Leng, Yichong and Song, Kaitao and Tang, Siliang and others",
        "title": "Naturalspeech 3: Zero-shot speech synthesis with factorized codec and diffusion models"
      },
      {
        "key": "zhang2023speechtokenizer",
        "author": "Zhang, Xin and Zhang, Dong and Li, Shimin and Zhou, Yaqian and Qiu, Xipeng",
        "title": "Speechtokenizer: Unified speech tokenizer for speech large language models"
      },
      {
        "key": "du2024funcodec",
        "author": "Du, Zhihao and Zhang, Shiliang and Hu, Kai and Zheng, Siqi",
        "title": "Funcodec: A fundamental, reproducible and integrable open-source toolkit for neural speech codec"
      },
      {
        "key": "liu2024semanticodec",
        "author": "Liu, Haohe and Xu, Xuenan and Yuan, Yi and Wu, Mengyue and Wang, Wenwu and Plumbley, Mark D",
        "title": "SemantiCodec: An Ultra Low Bitrate Semantic Audio Codec for General Sound"
      }
    ]
  },
  {
    "index": 21,
    "papers": [
      {
        "key": "li2024singlecodec",
        "author": "Li, Hanzhao and Xue, Liumeng and Guo, Haohan and Zhu, Xinfa and Lv, Yuanjun and Xie, Lei and Chen, Yunlin and Yin, Hao and Li, Zhifei",
        "title": "Single-Codec: Single-Codebook Speech Codec towards High-Performance Speech Generation"
      },
      {
        "key": "ji2024wavtokenizer",
        "author": "Ji, Shengpeng and Jiang, Ziyue and Cheng, Xize and Chen, Yifu and Fang, Minghui and Zuo, Jialong and Yang, Qian and Li, Ruiqi and Zhang, Ziang and Yang, Xiaoda and others",
        "title": "WavTokenizer: an Efficient Acoustic Discrete Codec Tokenizer for Audio Language Modeling"
      }
    ]
  }
]