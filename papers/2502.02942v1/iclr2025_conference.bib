@inproceedings{wang2024selm,
  title={SELM: Speech enhancement using discrete tokens and language models},
  author={Wang, Ziqian and Zhu, Xinfa and Zhang, Zihan and Lv, YuanJun and Jiang, Ning and Zhao, Guoqing and Xie, Lei},
  booktitle={Proc. ICASSP},
  pages={11561--11565},
  year={2024}
}

@article{tai2024dose,
  title={Dose: Diffusion dropout with adaptive prior for speech enhancement},
  author={Tai, Wenxin and Lei, Yue and Zhou, Fan and Trajcevski, Goce and Zhong, Ting},
  journal={Advances in Neural Information Processing Systems},
  volume={36},
  year={2024}
}

@book{gay2012acoustic,
  title={Acoustic signal processing for telecommunication},
  author={Gay, Steven L and Benesty, Jacob},
  volume={551},
  year={2012},
  publisher={Springer Science \& Business Media}
}

 @article{VanBogaert_Doclo_Wouters_Moonen_2019,  
     title={Speech enhancement with multichannel Wiener filter techniques in multimicrophone binaural hearing aids}, 
     volume={125}, 
     number={1}, 
     journal={The Journal of the Acoustical Society of America}, 
     author={Van den Bogaert, Tim and Doclo, Simon and Wouters, Jan and Moonen, Marc}, 
     year={2019}, 
     pages={360â€“371}, 
 }

@article{tashev2021recent,
  title={Recent advances in human-machine interfaces for gaming and entertainment},
  author={Tashev, Ivan},
  journal={International journal of information technologies and security},
  volume={3},
  number={3},
  pages={69--76},
  year={2021}
}

@article{richter2023speech,
  title={Speech enhancement and dereverberation with diffusion-based generative models},
  author={Richter, Julius and Welker, Simon and Lemercier, Jean-Marie and Lay, Bunlong and Gerkmann, Timo},
  journal={IEEE/ACM Transactions on Audio, Speech, and Language Processing},
  volume={31},
  pages={2351--2364},
  year={2023},
}

@article{borsos2023audiolm,
  title={Audiolm: a language modeling approach to audio generation},
  author={Borsos, Zal{\'a}n and Marinier, Rapha{\"e}l and Vincent, Damien and Kharitonov, Eugene and Pietquin, Olivier and Sharifi, Matt and Roblek, Dominik and Teboul, Olivier and Grangier, David and Tagliasacchi, Marco and others},
  journal={IEEE/ACM transactions on audio, speech, and language processing},
  volume={31},
  pages={2523--2533},
  year={2023},
}

@article{agostinelli2023musiclm,
  title={Musiclm: Generating music from text},
  author={Agostinelli, Andrea and Denk, Timo I and Borsos, Zal{\'a}n and Engel, Jesse and Verzetti, Mauro and Caillon, Antoine and Huang, Qingqing and Jansen, Aren and Roberts, Adam and Tagliasacchi, Marco and others},
  journal={arXiv preprint arXiv:2301.11325},
  year={2023}
}

@article{peng2024voicecraft,
  title={VoiceCraft: Zero-Shot Speech Editing and Text-to-Speech in the Wild},
  author={Peng, Puyuan and Huang, Po-Yao and Li, Daniel and Mohamed, Abdelrahman and Harwath, David},
  journal={arXiv preprint arXiv:2403.16973},
  year={2024}
}

@article{zeghidour2021soundstream,
  title={Soundstream: An end-to-end neural audio codec},
  author={Zeghidour, Neil and Luebs, Alejandro and Omran, Ahmed and Skoglund, Jan and Tagliasacchi, Marco},
  journal={IEEE/ACM Transactions on Audio, Speech, and Language Processing},
  volume={30},
  pages={495--507},
  year={2021}
}

@article{defossez2022encodec,
  title={High fidelity neural audio compression},
  author={D{\'e}fossez, Alexandre and Copet, Jade and Synnaeve, Gabriel and Adi, Yossi},
  journal={arXiv preprint arXiv:2210.13438},
  year={2022}
}

@article{zhang2023speechtokenizer,
  title={Speechtokenizer: Unified speech tokenizer for speech large language models},
  author={Zhang, Xin and Zhang, Dong and Li, Shimin and Zhou, Yaqian and Qiu, Xipeng},
  journal={arXiv preprint arXiv:2308.16692},
  year={2023}
}

@article{kumar2024dac,
  title={High-fidelity audio compression with improved rvqgan},
  author={Kumar, Rithesh and Seetharaman, Prem and Luebs, Alejandro and Kumar, Ishaan and Kumar, Kundan},
  journal={Advances in Neural Information Processing Systems},
  volume={36},
  year={2024}
}

@article{wang2023valle,
  title={Neural codec language models are zero-shot text to speech synthesizers},
  author={Wang, Chengyi and Chen, Sanyuan and Wu, Yu and Zhang, Ziqiang and Zhou, Long and Liu, Shujie and Chen, Zhuo and Liu, Yanqing and Wang, Huaming and Li, Jinyu and others},
  journal={arXiv preprint arXiv:2301.02111},
  year={2023}
}

@article{borsos2023soundstorm,
  title={Soundstorm: Efficient parallel audio generation},
  author={Borsos, Zal{\'a}n and Sharifi, Matt and Vincent, Damien and Kharitonov, Eugene and Zeghidour, Neil and Tagliasacchi, Marco},
  journal={arXiv preprint arXiv:2305.09636},
  year={2023}
}

@article{copet2024musicgen,
  title={Simple and controllable music generation},
  author={Copet, Jade and Kreuk, Felix and Gat, Itai and Remez, Tal and Kant, David and Synnaeve, Gabriel and Adi, Yossi and D{\'e}fossez, Alexandre},
  journal={Advances in Neural Information Processing Systems},
  volume={36},
  year={2024}
}

@inproceedings{fu2019metricgan,
  title={Metricgan: Generative adversarial networks based black-box metric scores optimization for speech enhancement},
  author={Fu, Szu-Wei and Liao, Chien-Feng and Tsao, Yu and Lin, Shou-De},
  booktitle={International Conference on Machine Learning},
  pages={2031--2041},
  year={2019},
  organization={PmLR}
}

@inproceedings{vae_ref1,
  title={Variational autoencoder for speech enhancement with a noise-aware encoder},
  author={Fang, Huajian and Carbajal, Guillaume and Wermter, Stefan and Gerkmann, Timo},
  booktitle={ICASSP 2021-2021 IEEE international conference on acoustics, speech and signal processing (ICASSP)},
  pages={676--680},
  year={2021},
}

@article{vae_ref2,
  title={Unsupervised speech enhancement using dynamical variational autoencoders},
  author={Bie, Xiaoyu and Leglaive, Simon and Alameda-Pineda, Xavier and Girin, Laurent},
  journal={IEEE/ACM Transactions on Audio, Speech, and Language Processing},
  volume={30},
  pages={2993--3007},
  year={2022},
}

@article{flow_ref,
  title={A flow-based deep latent variable model for speech spectrogram modeling and enhancement},
  author={Nugraha, Aditya Arie and Sekiguchi, Kouhei and Yoshii, Kazuyoshi},
  journal={IEEE/ACM Transactions on Audio, Speech, and Language Processing},
  volume={28},
  pages={1104--1117},
  year={2020},
}

@article{lemercier2023storm,
  title={Storm: A diffusion-based stochastic regeneration model for speech enhancement and dereverberation},
  author={Lemercier, Jean-Marie and Richter, Julius and Welker, Simon and Gerkmann, Timo},
  journal={IEEE/ACM Transactions on Audio, Speech, and Language Processing},
  year={2023},
}

@inproceedings{lu2022cdiffuse,
  title={Conditional diffusion probabilistic model for speech enhancement},
  author={Lu, Yen-Ju and Wang, Zhong-Qiu and Watanabe, Shinji and Richard, Alexander and Yu, Cheng and Tsao, Yu},
  booktitle={ICASSP 2022-2022 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP)},
  pages={7402--7406},
  year={2022}
}

@article{yanggenhancer,
  title={Genhancer: High-Fidelity Speech Enhancement via Generative Modeling on Discrete Codec Tokens},
  author={Yang, Haici and Su, Jiaqi and Kim, Minje and Jin, Zeyu},
year={2024}
}

@article{conneau2020xlsr,
  title={Unsupervised cross-lingual representation learning for speech recognition},
  author={Conneau, Alexis and Baevski, Alexei and Collobert, Ronan and Mohamed, Abdelrahman and Auli, Michael},
  journal={arXiv preprint arXiv:2006.13979},
  year={2020}
}

@article{van2017vqvae,
  title={Neural discrete representation learning},
  author={Van Den Oord, Aaron and Vinyals, Oriol and others},
  journal={Advances in neural information processing systems},
  volume={30},
  year={2017}
}

@article{hsu2021hubert,
  title={Hubert: Self-supervised speech representation learning by masked prediction of hidden units},
  author={Hsu, Wei-Ning and Bolte, Benjamin and Tsai, Yao-Hung Hubert and Lakhotia, Kushal and Salakhutdinov, Ruslan and Mohamed, Abdelrahman},
  journal={IEEE/ACM transactions on audio, speech, and language processing},
  volume={29},
  pages={3451--3460},
  year={2021}
}

@article{chen2022wavlm,
  title={Wavlm: Large-scale self-supervised pre-training for full stack speech processing},
  author={Chen, Sanyuan and Wang, Chengyi and Chen, Zhengyang and Wu, Yu and Liu, Shujie and Chen, Zhuo and Li, Jinyu and Kanda, Naoyuki and Yoshioka, Takuya and Xiao, Xiong and others},
  journal={IEEE Journal of Selected Topics in Signal Processing},
  volume={16},
  number={6},
  pages={1505--1518},
  year={2022}
}

@article{wang2023lmvc,
  title={Lm-vc: Zero-shot voice conversion via speech generation based on language models},
  author={Wang, Zhichao and Chen, Yuanzhe and Xie, Lei and Tian, Qiao and Wang, Yuping},
  journal={IEEE Signal Processing Letters},
  year={2023}
}

@article{wang2024streamvoice,
  title={StreamVoice: Streamable Context-Aware Language Modeling for Real-time Zero-Shot Voice Conversion},
  author={Wang, Zhichao and Chen, Yuanzhe and Wang, Xinsheng and Chen, Zhuo and Xie, Lei and Wang, Yuping and Wang, Yuxuan},
  journal={arXiv preprint arXiv:2401.11053},
  year={2024}
}

@article{dong2023polyvoice,
  title={Polyvoice: Language models for speech to speech translation},
  author={Dong, Qianqian and Huang, Zhiying and Tian, Qiao and Xu, Chen and Ko, Tom and Zhao, Yunlong and Feng, Siyuan and Li, Tang and Wang, Kexin and Cheng, Xuxin and others},
  journal={arXiv preprint arXiv:2306.02982},
  year={2023}
}

@inproceedings{wu2023audiodec,
  title={Audiodec: An open-source streaming high-fidelity neural audio codec},
  author={Wu, Yi-Chiao and Gebru, Israel D and Markovi{\'c}, Dejan and Richard, Alexander},
  booktitle={ICASSP 2023-2023 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP)},
  pages={1--5},
  year={2023}
}

@article{ai2024apcodec,
  title={APCodec: A Neural Audio Codec with Parallel Amplitude and Phase Spectrum Encoding and Decoding},
  author={Ai, Yang and Jiang, Xiao-Hang and Lu, Ye-Xin and Du, Hui-Peng and Ling, Zhen-Hua},
  journal={arXiv preprint arXiv:2402.10533},
  year={2024}
}

@article{yang2023hifi,
  title={Hifi-codec: Group-residual vector quantization for high fidelity audio codec},
  author={Yang, Dongchao and Liu, Songxiang and Huang, Rongjie and Tian, Jinchuan and Weng, Chao and Zou, Yuexian},
  journal={arXiv preprint arXiv:2305.02765},
  year={2023}
}

@article{ji2024languagecodec,
  title={Language-codec: Reducing the gaps between discrete codec representation and speech language models},
  author={Ji, Shengpeng and Fang, Minghui and Jiang, Ziyue and Huang, Rongjie and Zuo, Jialung and Wang, Shulei and Zhao, Zhou},
  journal={arXiv preprint arXiv:2402.12208},
  year={2024}
}

@inproceedings{ren2024ticodec,
  title={Fewer-token neural speech codec with time-invariant codes},
  author={Ren, Yong and Wang, Tao and Yi, Jiangyan and Xu, Le and Tao, Jianhua and Zhang, Chu Yuan and Zhou, Junzuo},
  booktitle={ICASSP 2024-2024 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP)},
  pages={12737--12741},
  year={2024},
  organization={IEEE}
}

@article{ju2024naturalspeech3,
  title={Naturalspeech 3: Zero-shot speech synthesis with factorized codec and diffusion models},
  author={Ju, Zeqian and Wang, Yuancheng and Shen, Kai and Tan, Xu and Xin, Detai and Yang, Dongchao and Liu, Yanqing and Leng, Yichong and Song, Kaitao and Tang, Siliang and others},
  journal={arXiv preprint arXiv:2403.03100},
  year={2024}
}

@inproceedings{du2024funcodec,
  title={Funcodec: A fundamental, reproducible and integrable open-source toolkit for neural speech codec},
  author={Du, Zhihao and Zhang, Shiliang and Hu, Kai and Zheng, Siqi},
  booktitle={ICASSP 2024-2024 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP)},
  pages={591--595},
  year={2024}
}

@article{liu2024semanticodec,
  title={SemantiCodec: An Ultra Low Bitrate Semantic Audio Codec for General Sound},
  author={Liu, Haohe and Xu, Xuenan and Yuan, Yi and Wu, Mengyue and Wang, Wenwu and Plumbley, Mark D},
  journal={arXiv preprint arXiv:2405.00233},
  year={2024}
}

@inproceedings{kahn2020librilight,
  title={Libri-light: A benchmark for asr with limited or no supervision},
  author={Kahn, Jacob and Riviere, Morgane and Zheng, Weiyi and Kharitonov, Evgeny and Xu, Qiantong and Mazar{\'e}, Pierre-Emmanuel and Karadayi, Julien and Liptchinsky, Vitaliy and Collobert, Ronan and Fuegen, Christian and others},
  booktitle={ICASSP 2020-2020 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP)},
  pages={7669--7673},
  year={2020},
  organization={IEEE}
}

@article{zen2019libritts,
  title={Libritts: A corpus derived from librispeech for text-to-speech},
  author={Zen, Heiga and Dang, Viet and Clark, Rob and Zhang, Yu and Weiss, Ron J and Jia, Ye and Chen, Zhifeng and Wu, Yonghui},
  journal={arXiv preprint arXiv:1904.02882},
  year={2019}
}

@inproceedings{veaux2013voicebank,
  title={The voice bank corpus: Design, collection and data analysis of a large regional accent speech database},
  author={Veaux, Christophe and Yamagishi, Junichi and King, Simon},
  booktitle={2013 international conference oriental COCOSDA held jointly with 2013 conference on Asian spoken language research and evaluation (O-COCOSDA/CASLRE)},
  pages={1--4},
  year={2013}
}

@article{reddy2021dnsinterspeech,
  title={Interspeech 2021 deep noise suppression challenge},
  author={Reddy, Chandan KA and Dubey, Harishchandra and Koishida, Kazuhito and Nair, Arun and Gopal, Vishak and Cutler, Ross and Braun, Sebastian and Gamper, Hannes and Aichner, Robert and Srinivasan, Sriram},
  journal={arXiv preprint arXiv:2101.01902},
  year={2021}
}

@article{wichern2019wham,
  title={Wham!: Extending speech separation to noisy environments},
  author={Wichern, Gordon and Antognini, Joe and Flynn, Michael and Zhu, Licheng Richard and McQuinn, Emmett and Crow, Dwight and Manilow, Ethan and Roux, Jonathan Le},
  journal={arXiv preprint arXiv:1907.01160},
  year={2019}
}

@inproceedings{thiemann2013demand,
  title={The diverse environments multi-channel acoustic noise database (demand): A database of multichannel environmental noise recordings},
  author={Thiemann, Joachim and Ito, Nobutaka and Vincent, Emmanuel},
  booktitle={Proceedings of Meetings on Acoustics},
  volume={19},
  number={1},
  year={2013},
  organization={AIP Publishing}
}

@inproceedings{ko2017study,
  title={A study on data augmentation of reverberant speech for robust speech recognition},
  author={Ko, Tom and Peddinti, Vijayaditya and Povey, Daniel and Seltzer, Michael L and Khudanpur, Sanjeev},
  booktitle={2017 IEEE international conference on acoustics, speech and signal processing (ICASSP)},
  pages={5220--5224},
  year={2017},
}

@article{du2016chime4,
  title={The USTC-iFlytek system for CHiME-4 challenge},
  author={Du, Jun and Tu, Yan-Hui and Sun, Lei and Ma, Feng and Wang, Hai-Kun and Pan, Jia and Liu, Cong and Chen, Jing-Dong and Lee, Chin-Hui},
  journal={Proc. CHiME},
  volume={4},
  number={1},
  pages={36--38},
  year={2016}
}

@inproceedings{hao2021fullsubnet,
  title={Fullsubnet: A full-band and sub-band fusion model for real-time single-channel speech enhancement},
  author={Hao, Xiang and Su, Xiangdong and Horaud, Radu and Li, Xiaofei},
  booktitle={ICASSP 2021-2021 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP)},
  pages={6633--6637},
  year={2021},
}

@inproceedings{chen2023intersubnet,
  title={Inter-subnet: Speech enhancement with subband interaction},
  author={Chen, Jun and Rao, Wei and Wang, Zilin and Lin, Jiuxin and Wu, Zhiyong and Wang, Yannan and Shang, Shidong and Meng, Helen},
  booktitle={ICASSP 2023-2023 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP)},
  pages={1--5},
  year={2023},
  organization={IEEE}
}

@article{welker2022sgmse,
  title={Speech enhancement with score-based generative models in the complex STFT domain},
  author={Welker, Simon and Richter, Julius and Gerkmann, Timo},
  journal={arXiv preprint arXiv:2203.17004},
  year={2022}
}

@inproceedings{reddy2022dnsmos,
  title={DNSMOS P. 835: A non-intrusive perceptual objective speech quality metric to evaluate noise suppressors},
  author={Reddy, Chandan KA and Gopal, Vishak and Cutler, Ross},
  booktitle={ICASSP 2022-2022 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP)},
  pages={886--890},
  year={2022}
}

@article{saeki2022utmos,
  title={Utmos: Utokyo-sarulab system for voicemos challenge 2022},
  author={Saeki, Takaaki and Xin, Detai and Nakata, Wataru and Koriyama, Tomoki and Takamichi, Shinnosuke and Saruwatari, Hiroshi},
  journal={arXiv preprint arXiv:2204.02152},
  year={2022}
}

@article{liu2021voicefixer,
  title={VoiceFixer: Toward general speech restoration with neural vocoder},
  author={Liu, Haohe and Kong, Qiuqiang and Tian, Qiao and Zhao, Yan and Wang, DeLiang and Huang, Chuanzeng and Wang, Yuxuan},
  journal={arXiv preprint arXiv:2109.13731},
  year={2021}
}

@article{serra2022universal_sde,
  title={Universal speech enhancement with score-based diffusion},
  author={Serr{\`a}, Joan and Pascual, Santiago and Pons, Jordi and Araz, R Oguz and Scaini, Davide},
  journal={arXiv preprint arXiv:2206.03065},
  year={2022}
}

@article{jin2023semantic_indexers,
  title={Language models as semantic indexers},
  author={Jin, Bowen and Zeng, Hansi and Wang, Guoyin and Chen, Xiusi and Wei, Tianxin and Li, Ruirui and Wang, Zhengyang and Li, Zheng and Li, Yang and Lu, Hanqing and others},
  journal={arXiv preprint arXiv:2310.07815},
  year={2023}
}

@incollection{lehmann2023language,
  title={Language models as controlled natural language semantic parsers for knowledge graph question answering},
  author={Lehmann, Jens and Gattogi, Preetam and Bhandiwad, Dhananjay and Ferr{\'e}, S{\'e}bastien and Vahdati, Sahar},
  booktitle={ECAI 2023},
  pages={1348--1356},
  year={2023},
}

@inproceedings{panayotov2015librispeech,
  title={Librispeech: an asr corpus based on public domain audio books},
  author={Panayotov, Vassil and Chen, Guoguo and Povey, Daniel and Khudanpur, Sanjeev},
  booktitle={2015 IEEE international conference on acoustics, speech and signal processing (ICASSP)},
  pages={5206--5210},
  year={2015}
}

@article{fu2024vqscore,
  title={Self-Supervised Speech Quality Estimation and Enhancement Using Only Clean Speech},
  author={Fu, Szu-Wei and Hung, Kuo-Hsuan and Tsao, Yu and Wang, Yu-Chiang Frank},
  journal={arXiv preprint arXiv:2402.16321},
  year={2024}
}

@article{hsu2022revise,
  title={Revise: Self-supervised speech resynthesis with visual input for universal and generalized speech enhancement},
  author={Hsu, Wei-Ning and Remez, Tal and Shi, Bowen and Donley, Jacob and Adi, Yossi},
  journal={arXiv preprint arXiv:2212.11377},
  year={2022}
}

@article{kumar2020nu,
  title={NU-GAN: High resolution neural upsampling with GAN},
  author={Kumar, Rithesh and Kumar, Kundan and Anand, Vicki and Bengio, Yoshua and Courville, Aaron},
  journal={arXiv preprint arXiv:2010.11362},
  year={2020}
}

@inproceedings{maiti2020speaker,
  title={Speaker independence of neural vocoders and their effect on parametric resynthesis speech enhancement},
  author={Maiti, Soumi and Mandel, Michael I},
  booktitle={ICASSP 2020-2020 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP)},
  pages={206--210},
  year={2020}
}

@article{li2020noise,
  title={Noise tokens: Learning neural noise templates for environment-aware speech enhancement},
  author={Li, Haoyu and Yamagishi, Junichi},
  journal={arXiv preprint arXiv:2004.04001},
  year={2020}
}

@inproceedings{li2024sefvc,
  title={SEF-VC: Speaker Embedding Free Zero-Shot Voice Conversion with Cross Attention},
  author={Li, Junjie and Guo, Yiwei and Chen, Xie and Yu, Kai},
  booktitle={ICASSP 2024-2024 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP)},
  pages={12296--12300},
  year={2024}
}

@article{kato2024effects,
  title={The effects of acoustic and semantic enhancements on perception of native and non-native speech},
  author={Kato, Misaki and Baese-Berk, Melissa M},
  journal={Language and Speech},
  volume={67},
  number={1},
  pages={40--71},
  year={2024}
}

@article{mentzer2023fsq,
  title={Finite scalar quantization: Vq-vae made simple},
  author={Mentzer, Fabian and Minnen, David and Agustsson, Eirikur and Tschannen, Michael},
  journal={arXiv preprint arXiv:2309.15505},
  year={2023}
}

@article{yang2024is_diffse,
  title={Pre-training Feature Guided Diffusion Model for Speech Enhancement},
  author={Yang, Yiyuan and Trigoni, Niki and Markham, Andrew},
  journal={arXiv preprint arXiv:2406.07646},
  year={2024}
}

@article{scheibler2024is_diffse,
  title={Universal Score-based Speech Enhancement with High Content Preservation},
  author={Scheibler, Robin and Fujita, Yusuke and Shirahata, Yuma and Komatsu, Tatsuya},
  journal={arXiv preprint arXiv:2406.12194},
  year={2024}
}

@article{ji2024wavtokenizer,
  title={WavTokenizer: an Efficient Acoustic Discrete Codec Tokenizer for Audio Language Modeling},
  author={Ji, Shengpeng and Jiang, Ziyue and Cheng, Xize and Chen, Yifu and Fang, Minghui and Zuo, Jialong and Yang, Qian and Li, Ruiqi and Zhang, Ziang and Yang, Xiaoda and others},
  journal={arXiv preprint arXiv:2408.16532},
  year={2024}
}

@article{van2008visualizing,
  title={Visualizing data using t-SNE.},
  author={Van der Maaten, Laurens and Hinton, Geoffrey},
  journal={Journal of machine learning research},
  volume={9},
  number={11},
  year={2008}
}

@article{le2024voicebox,
  title={Voicebox: Text-guided multilingual universal speech generation at scale},
  author={Le, Matthew and Vyas, Apoorv and Shi, Bowen and Karrer, Brian and Sari, Leda and Moritz, Rashel and Williamson, Mary and Manohar, Vimal and Adi, Yossi and Mahadeokar, Jay and others},
  journal={Advances in neural information processing systems},
  volume={36},
  year={2024}
}

@article{yang2023uniaudio,
  title={Uniaudio: An audio foundation model toward universal audio generation},
  author={Yang, Dongchao and Tian, Jinchuan and Tan, Xu and Huang, Rongjie and Liu, Songxiang and Chang, Xuankai and Shi, Jiatong and Zhao, Sheng and Bian, Jiang and Wu, Xixin and others},
  journal={arXiv preprint arXiv:2310.00704},
  year={2023}
}

@article{wang2024speechx,
  title={Speechx: Neural codec language model as a versatile speech transformer},
  author={Wang, Xiaofei and Thakker, Manthan and Chen, Zhuo and Kanda, Naoyuki and Eskimez, Sefik Emre and Chen, Sanyuan and Tang, Min and Liu, Shujie and Li, Jinyu and Yoshioka, Takuya},
  journal={IEEE/ACM Transactions on Audio, Speech, and Language Processing},
  year={2024},
  publisher={IEEE}
}

@article{li2024singlecodec,
  title={Single-Codec: Single-Codebook Speech Codec towards High-Performance Speech Generation},
  author={Li, Hanzhao and Xue, Liumeng and Guo, Haohan and Zhu, Xinfa and Lv, Yuanjun and Xie, Lei and Chen, Yunlin and Yin, Hao and Li, Zhifei},
  journal={arXiv preprint arXiv:2406.07422},
  year={2024}
}

@article{siuzdak2023vocos,
  title={Vocos: Closing the gap between time-domain and Fourier-based neural vocoders for high-quality audio synthesis},
  author={Siuzdak, Hubert},
  journal={arXiv preprint arXiv:2306.00814},
  year={2023}
}

@article{liao2024fishspeech,
  title={Fish-Speech: Leveraging Large Language Models for Advanced Multilingual Text-to-Speech Synthesis},
  author={Liao, Shijia and Wang, Yuxuan and Li, Tianyu and Cheng, Yifan and Zhang, Ruoyi and Zhou, Rongzhi and Xing, Yijin},
  journal={arXiv preprint arXiv:2411.01156},
  year={2024}
}

@inproceedings{zheng2023online,
  title={Online clustered codebook},
  author={Zheng, Chuanxia and Vedaldi, Andrea},
  booktitle={Proceedings of the IEEE/CVF International Conference on Computer Vision},
  pages={22798--22807},
  year={2023}
}

@article{mentzer2023finite,
  title={Finite scalar quantization: Vq-vae made simple},
  author={Mentzer, Fabian and Minnen, David and Agustsson, Eirikur and Tschannen, Michael},
  journal={arXiv preprint arXiv:2309.15505},
  year={2023}
}

@article{zhang2024speaking,
  title={Speaking in Wavelet Domain: A Simple and Efficient Approach to Speed up Speech Diffusion Model},
  author={Zhang, Xiangyu and Liu, Daijiao and Liu, Hexin and Zhang, Qiquan and Meng, Hanyu and Garcia, Leibny Paola and Chng, Eng Siong and Yao, Lina},
  journal={arXiv preprint arXiv:2402.10642},
  year={2024}
}

@article{liu2024aligning,
  title={Aligning Speech to Languages to Enhance Code-switching Speech Recognition},
  author={Liu, Hexin and Zhang, Xiangyu and Garcia, Leibny Paola and Khong, Andy WH and Chng, Eng Siong and Watanabe, Shinji},
  journal={arXiv preprint arXiv:2403.05887},
  year={2024}
}

@inproceedings{yao2024promptvc,
  title={Promptvc: Flexible stylistic voice conversion in latent space driven by natural language prompts},
  author={Yao, Jixun and Yang, Yuguang and Lei, Yi and Ning, Ziqian and Hu, Yanni and Pan, Yu and Yin, Jingjing and Zhou, Hongbin and Lu, Heng and Xie, Lei},
  booktitle={ICASSP 2024-2024 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP)},
  pages={10571--10575},
  year={2024}
}

@article{yao2024stablevc,
  title={StableVC: Style Controllable Zero-Shot Voice Conversion with Conditional Flow Matching},
  author={Yao, Jixun and Yan, Yuguang and Pan, Yu and Ning, Ziqian and Ye, Jiaohao and Zhou, Hongbin and Xie, Lei},
  journal={arXiv preprint arXiv:2412.04724},
  year={2024}
}