\section{Related Work}
\noindent\textbf{Automatic Unit Test Generation. \hspace{0.5em}} Manually writing unit tests is laborious and often infeasible~\cite{chencodet,liu2024your}. Consequently, past research explores automatic UT generation~\citep[][\emph{inter alia}]{king1976symbolic,cadar2008klee,holler2012fuzzing,cha2015program}. The advent of LLMs has spurred recent efforts in using them for UT generation~\cite{chencodet,schafer2023empirical,liu2024your}. Specifically, \citet{schafer2023empirical} and \citet{liu2024your} focus on generating \emph{unit test inputs} via prompting frontier LLMs like GPT-4 and/or iterative prompting, assuming access to the \emph{gold} solution. 
In contrast, our models, trained with \method{}, generate \emph{both input-output UT pairs} based on the task description without relying on the gold implementation. 
While \citet{chencodet} also generate input-output UT pairs using standard LLM prompting, their primary focus is code generation -- \emph{not} the quality of generated UTs. On the other hand, we directly model the desiderata of UTs including output accuracy, and demonstrate its utility on code generation and debugging.

\vspace{0.35em}
\noindent\textbf{LLM Debugging. \hspace{0.5em}} Using LLMs for debugging faulty code, or program repair, has been extensively studied. Debugging approaches are divided into those training models to debug~\cite{moon2023coffee,ninext,chae2024coffee} and those providing external feedback to pretrained models~\cite{chen2023teaching,olausson2023self,zhong2024ldb}. Both rely on (gold) unit tests for training or feedback. Thus, \method{} complements both methods by providing generated unit tests when human-written tests are scarce or unavailable.  In \cref{ssec:debug}, we introduce \debugmethod{}, a debugging pipeline that addresses noisy feedback from inaccurate unit tests through test-time scaling and backtracking. Moreover, in \cref{sec:results} we show that \method{}'s unit tests can effectively provide feedback to LLMs for code generation and debugging.