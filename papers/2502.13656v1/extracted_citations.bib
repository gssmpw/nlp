@article{alizadeh2023open,
  title={Open-source large language models outperform crowd workers and approach ChatGPT in text-annotation tasks},
  author={Alizadeh, Meysam and Kubli, Ma{\"e}l and Samei, Zeynab and Dehghani, Shirin},
  journal={arXiv preprint arXiv:2307.02179},
  volume={101},
  year={2023},
  publisher={Technical Report}
}

@article{alizadeh2025open,
  title={Open-source LLMs for text annotation: a practical guide for model setting and fine-tuning},
  author={Alizadeh, Meysam and Kubli, Ma{\"e}l and Samei, Zeynab and Dehghani, Shirin and Zahedivafa, Mohammadmasiha and Bermeo, Juan D and Korobeynikova, Maria and Gilardi, Fabrizio},
  journal={Journal of Computational Social Science},
  volume={8},
  number={1},
  pages={1--25},
  year={2025},
  publisher={Springer}
}

@inproceedings{bowman2015large,
  title={A large annotated corpus for learning natural language inference},
  author={Bowman, Samuel and Angeli, Gabor and Potts, Christopher and Manning, Christopher D},
  booktitle={Proceedings of the 2015 Conference on Empirical Methods in Natural Language Processing},
  pages={632--642},
  year={2015}
}

@inproceedings{chen2022generate,
  title={Generate, Discriminate and Contrast: A Semi-Supervised Sentence Representation Learning Framework},
  author={Chen, Yiming and Zhang, Yan and Wang, Bin and Liu, Zuozhu and Li, Haizhou},
  booktitle={Proceedings of the 2022 Conference on Empirical Methods in Natural Language Processing},
  pages={8150--8161},
  year={2022}
}

@inproceedings{chuang2022diffcse,
  title={DiffCSE: Difference-based Contrastive Learning for Sentence Embeddings},
  author={Chuang, Yung-Sung and Dangovski, Rumen and Luo, Hongyin and Zhang, Yang and Chang, Shiyu and Solja{\v{c}}i{\'c}, Marin and Li, Shang-Wen and Yih, Scott and Kim, Yoon and Glass, James},
  booktitle={Proceedings of the 2022 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies},
  pages={4207--4218},
  year={2022}
}

@article{chung2024scaling,
  title={Scaling instruction-finetuned language models},
  author={Chung, Hyung Won and Hou, Le and Longpre, Shayne and Zoph, Barret and Tay, Yi and Fedus, William and Li, Yunxuan and Wang, Xuezhi and Dehghani, Mostafa and Brahma, Siddhartha and others},
  journal={Journal of Machine Learning Research},
  volume={25},
  number={70},
  pages={1--53},
  year={2024}
}

@inproceedings{ethayarajh2019contextual,
  title={How Contextual are Contextualized Word Representations? Comparing the Geometry of BERT, ELMo, and GPT-2 Embeddings},
  author={Ethayarajh, Kawin},
  booktitle={Proceedings of the 2019 Conference on Empirical Methods in Natural Language Processing and the 9th International Joint Conference on Natural Language Processing (EMNLP-IJCNLP)},
  pages={55--65},
  year={2019}
}

@inproceedings{gao2021simcse,
  title={SimCSE: Simple Contrastive Learning of Sentence Embeddings},
  author={Gao, Tianyu and Yao, Xingcheng and Chen, Danqi},
  booktitle={Proceedings of the 2021 Conference on Empirical Methods in Natural Language Processing},
  pages={6894--6910},
  year={2021}
}

@article{gilardi2023chatgpt,
  title={ChatGPT outperforms crowd workers for text-annotation tasks},
  author={Gilardi, Fabrizio and Alizadeh, Meysam and Kubli, Ma{\"e}l},
  journal={Proceedings of the National Academy of Sciences},
  volume={120},
  number={30},
  pages={e2305016120},
  year={2023},
  publisher={National Acad Sciences}
}

@inproceedings{hill2016learning,
  title={Learning Distributed Representations of Sentences from Unlabelled Data},
  author={Hill, Felix and Cho, Kyunghyun and Korhonen, Anna},
  booktitle={Proceedings of the 2016 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies},
  pages={1367--1377},
  year={2016}
}

@inproceedings{jiang2022promptbert,
  title={PromptBERT: Improving BERT Sentence Embeddings with Prompts},
  author={Jiang, Ting and Jiao, Jian and Huang, Shaohan and Zhang, Zihan and Wang, Deqing and Zhuang, Fuzhen and Wei, Furu and Huang, Haizhen and Deng, Denvy and Zhang, Qi},
  booktitle={Proceedings of the 2022 Conference on Empirical Methods in Natural Language Processing},
  pages={8826--8837},
  year={2022}
}

@inproceedings{kenton2019bert,
  title={Bert: Pre-training of deep bidirectional transformers for language understanding},
  author={Kenton, Jacob Devlin Ming-Wei Chang and Toutanova, Lee Kristina},
  booktitle={Proceedings of naacL-HLT},
  volume={1},
  number={2},
  year={2019},
  organization={Minneapolis, Minnesota}
}

@article{kiros2015skip,
  title={Skip-thought vectors},
  author={Kiros, Ryan and Zhu, Yukun and Salakhutdinov, Russ R and Zemel, Richard and Urtasun, Raquel and Torralba, Antonio and Fidler, Sanja},
  journal={Advances in neural information processing systems},
  volume={28},
  year={2015}
}

@article{lai2024enhancing,
  title={Enhancing Unsupervised Sentence Embeddings via Knowledge-Driven Data Augmentation and Gaussian-Decayed Contrastive Learning},
  author={Lai, Peichao and Zhang, Zhengfeng and Zhang, Wentao and Fu, Fangcheng and Cui, Bin},
  journal={arXiv preprint arXiv:2409.12887},
  year={2024}
}

@inproceedings{li2020sentence,
  title={On the Sentence Embeddings from Pre-trained Language Models},
  author={Li, Bohan and Zhou, Hao and He, Junxian and Wang, Mingxuan and Yang, Yiming and Li, Lei},
  booktitle={Proceedings of the 2020 Conference on Empirical Methods in Natural Language Processing (EMNLP)},
  pages={9119--9130},
  year={2020}
}

@article{liu2019roberta,
  title={Roberta: A robustly optimized bert pretraining approach},
  author={Liu, Yinhan},
  journal={arXiv preprint arXiv:1907.11692},
  volume={364},
  year={2019}
}

@inproceedings{liu2023rankcse,
  title={RankCSE: Unsupervised Sentence Representations Learning via Learning to Rank},
  author={Liu, Jiduan and Liu, Jiahao and Wang, Qifan and Wang, Jingang and Wu, Wei and Xian, Yunsen and Zhao, Dongyan and Chen, Kai and Yan, Rui},
  booktitle={Proceedings of the 61st Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers)},
  pages={13785--13802},
  year={2023}
}

@article{logeswaran2018efficient,
  title={An efficient framework for learning sentence representations},
  author={Logeswaran, Lajanugen and Lee, Honglak},
  journal={arXiv preprint arXiv:1803.02893},
  year={2018}
}

@inproceedings{miao2023debcse,
  title={DebCSE: Rethinking Unsupervised Contrastive Sentence Embedding Learning in the Debiasing Perspective},
  author={Miao, Pu and Du, Zeyao and Zhang, Junlin},
  booktitle={Proceedings of the 32nd ACM International Conference on Information and Knowledge Management},
  pages={1847--1856},
  year={2023}
}

@article{mikolov2013distributed,
  title={Distributed representations of words and phrases and their compositionality},
  author={Mikolov, Tomas and Sutskever, Ilya and Chen, Kai and Corrado, Greg S and Dean, Jeff},
  journal={Advances in neural information processing systems},
  volume={26},
  year={2013}
}

@article{su2021whitening,
  title={Whitening sentence representations for better semantics and faster retrieval},
  author={Su, Jianlin and Cao, Jiarun and Liu, Weijie and Ou, Yangyiwen},
  journal={arXiv preprint arXiv:2103.15316},
  year={2021}
}

@inproceedings{wang2022improving,
  title={Improving contrastive learning of sentence embeddings with case-augmented positives and retrieved negatives},
  author={Wang, Wei and Ge, Liangzhu and Zhang, Jingqiao and Yang, Cheng},
  booktitle={Proceedings of the 45th International ACM SIGIR Conference on Research and Development in Information Retrieval},
  pages={2159--2165},
  year={2022}
}

@inproceedings{wang2024large,
  title={Large Language Models can Contrastively Refine their Generation for Better Sentence Representation Learning},
  author={Wang, Huiming and Li, Zhaodonghui and Cheng, Liying and Bing, Lidong and others},
  booktitle={Proceedings of the 2024 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies (Volume 1: Long Papers)},
  pages={7867--7884},
  year={2024}
}

@inproceedings{williams2018broad,
  title={A broad-coverage challenge corpus for sentence understanding through inference},
  author={Williams, Adina and Nangia, Nikita and Bowman, Samuel R},
  booktitle={2018 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies, NAACL HLT 2018},
  pages={1112--1122},
  year={2018},
  organization={Association for Computational Linguistics (ACL)}
}

@inproceedings{wu2022pcl,
  title={PCL: Peer-Contrastive Learning with Diverse Augmentations for Unsupervised Sentence Embeddings},
  author={Wu, Qiyu and Tao, Chongyang and Shen, Tao and Xu, Can and Geng, Xiubo and Jiang, Daxin},
  booktitle={Proceedings of the 2022 Conference on Empirical Methods in Natural Language Processing},
  pages={12052--12066},
  year={2022}
}

@inproceedings{ye2022progen,
  title={ProGen: Progressive Zero-shot Dataset Generation via In-context Feedback},
  author={Ye, Jiacheng and Gao, Jiahui and Wu, Zhiyong and Feng, Jiangtao and Yu, Tao and Kong, Lingpeng},
  booktitle={Findings of the Association for Computational Linguistics: EMNLP 2022},
  pages={3671--3683},
  year={2022}
}

@inproceedings{zhang2023contrastive,
  title={Contrastive Learning of Sentence Embeddings from Scratch},
  author={Zhang, Junlei and Lan, Zhenzhong and He, Junxian},
  booktitle={Proceedings of the 2023 Conference on Empirical Methods in Natural Language Processing},
  pages={3916--3932},
  year={2023}
}

