\section{Lack of Distributional Structure Explains Deviations from Power Law Scaling}
\label{sec:no_dist_structure_no_power_law}


\begin{figure*}[t!]
    \centering
    \includegraphics[width=0.9\linewidth]{figures/92_schematic_distributional_fitting_attempt2/distributional_fitting_schematic.png}
    \caption{\textbf{Schematic: Two Estimators of Power Law Parameters for Scaling Inference Compute via Repeat Sampling.} (A) Both estimators begin by generating many samples per prompt, then computing the number of successes per prompt. In the standard least squares power law parameter estimator (top), (B) $\operatorname{pass_i@k}$ is estimated for each $i$-th problem at multiple $k$ values, then (C) averaged over problems and fit with linear regression in log-log space.
    In the distributional power law parameter estimator (bottom), (D) a distribution $\mathcal{D}$ is fit to estimates of $\operatorname{pass_i@1}$, then (E) the single-attempt success probability distribution is used to simulate $\operatorname{pass_{\mathcal{D}}@k}$ at arbitrary $k$ values for linear regression in log-log space.}
    \label{fig:schematic2}
\end{figure*}

Notably, previous papers observed that not every model exhibits power law scaling in every setting. To highlight one, \citet{hughes2024bestofnjailbreaking} observed that when jailbreaking Meta's Llama 3 8B Instruction Tuned (IT) model \cite{grattafiori2024llama3herdmodels}, the $-\log (\operatorname{ASR_{\mathcal{D}}@k})$ fell faster than any power law (Fig.~\ref{fig:power_laws_repeat_sampling}), i.e., the $\operatorname{ASR_{\mathcal{D}}@k}$ rose much more quickly than the other frontier AI systems. Based on our mathematical insights and the empirical per-problem single-attempt attack success rates (Fig.~\ref{fig:multiple_attempts_pass_at_1_per_datum}), we can understand why: Llama 3 8B IT could be successfully jailbroken on every prompt within the permitted sampling budget and thus had no heavy left tail necessary to create the aggregate power law scaling.
% Similarly, \citet{brown2024largelanguagemonkeysscaling} found that power law scaling was less apparent on MiniF2F-MATH \citep{zheng2022minif2fcrosssystembenchmarkformal}, a dataset of mathematics problems that have been formalized into Lean, a proof checking programming language. 


\begin{figure*}[t!]
    \centering
    \includegraphics[width=0.5\linewidth]{figures/51_pass_at_1_compare_power_law_with_distributional_fit/llmonkeys_y=scaling_law_exponent_x=distributional_fit_exponent_kumaraswamy_binomial.pdf}%
    \includegraphics[width=0.5\linewidth]{figures/51_pass_at_1_compare_power_law_with_distributional_fit/bon_jailbreaking_y=scaling_law_exponent_x=distributional_fit_exponent_kumaraswamy_binomial.pdf}
    \caption{\textbf{Comparing Estimators of Power Law Exponents.} We compare two estimators of the power law exponent $b$ in $-\log(\operatorname{pass_{\mathcal{D}}@k}) \approx a k^{-b}\;$: (1) the standard least-squares estimator between $k$ and $-\log(\operatorname{pass_{\mathcal{D}}@k})$ in log-log space, and (2) the distributional estimator of $\operatorname{pass_i@1}$ assuming a scaled Kumaraswamy-Binomial distribution. Using all available data to fit both estimators, we find agreement between the least-squares estimate (ordinate) and the distribution-derived estimate (abscissa) for both Pythia models on MATH (left) and for frontier AI systems on HarmBench (right). For an explanation of why the two estimators match more closely for Large Language Monkeys than for Best-of-N Jailbreaking, see Appendix~\ref{app:sec:clarification_of_data_sampling}.
    }
    \label{fig:comparison_power_law_exponents}
\end{figure*}



% Our previous results \josh{TODO: Finish}