\section{Introduction}
\label{sec:introduction}

Scaling behaviors of large neural language models have surprised and fascinated engineers, scientists and society alike \citep{hestness2017deep,kaplan2020scalinglawsneurallanguage,brown2020language,hoffmann2022trainingcomputeoptimallargelanguage,ganguli2022predictability,sorscher2022beyond,wei2022emergent,schaeffer2024mirage,openai2024gpt4technicalreport}, shaping engineering, economic and governmental interests in frontier AI systems \citep{bommasani2021opportunities,eloundou2023gptsgptsearlylook,anderljung2023frontierairegulationmanaging,wang2023scientificdiscovery,reuel2024openproblemstechnicalai,besiroglu2024economic,maslej2024artificialintelligenceindexreport}. For a more thorough exposition of relevant literature, please see Related Work (Section~\ref{sec:related_work}). 

\begin{figure}[t!]
    \centering
    \includegraphics[width=0.49\textwidth]{figures/02_large_language_monkeys_original_eda/y=neg_log_avg_score_vs_x=scaling_parameter_hue=model.pdf}
    \includegraphics[width=0.49\textwidth]{figures/00_bon_jailbreaking_eda/y=neg_log_avg_score_vs_x=scaling_parameter_hue=model.pdf}    
    \caption{\textbf{Power Law Scaling in Language Models from Repeat Sampling.} Top: \citet{brown2024largelanguagemonkeysscaling} found the negative log average pass rate $-\log(\operatorname{pass_{\mathcal{D}}@k})$ at solving mathematical problems scales polynomially (i.e., as a power law) with the number of independent attempts per problem $k$. Bottom: \citet{hughes2024bestofnjailbreaking} similarly found the negative log average attack success rate $-\log(\operatorname{ASR_{\mathcal{D}}@k})$ when jailbreaking multimodal language models scales polynomially with the number of jailbreak attempts per prompt. Should such power law scaling be expected?
    From where do large language monkeys obtain their power (laws)?
    }
    \label{fig:power_laws_repeat_sampling}
\end{figure}


\begin{figure*}[t!]
    \centering
    \includegraphics[width=\linewidth]{figures/90_schematic/combined_statistical_plots.pdf}
    \caption{\textbf{Schematic: The Origin of Power Laws from Scaling Inference Compute via Repeat Sampling.} The $- \log (\operatorname{pass_{\mathcal{D}}@k})$ scales as a power law with the number of attempts per problem $k$ (left). This arises from a combination of two factors: (1) for each problem, $-\log(\operatorname{pass_i@k})$ scales exponentially with $k$ (center), and (2) the distribution (over problems in the dataset) of single-attempt success rates $\operatorname{pass_i@1}$ itself has a left power-law tail of small values (right).}
    \label{fig:schematic}
\end{figure*}


One direction of renewed interest is inference-time compute scaling, whereby compute is controllably increased at inference to improve the performance of a model, e.g., \citet{openai2024o1}. In this direction, recent research discovered that language model success rates scale predictably with the number of independent attempts made at accomplishing a task.
Specifically, in a paper titled, ``Large Language Monkeys: Scaling Inference Compute with Repeated Sampling," \citet{brown2024largelanguagemonkeysscaling} studied how language model performance changes at mathematical problem solving and coding problems when $k$ independent attempts are sampled per problem. Performance on the $i$-th problem was measured using the expected (over attempts) success rate \citep{kulal2019spoc,chen2021evaluatinglargelanguagemodels}, defined as:
%
\begin{equation}
\begin{aligned}
&\operatorname{pass_i@k} \, \defeq \, \\
&\mathop{\raisebox{3pt}{$\mathbb{E}$}}_{\substack{k \text{ Attempts}}}\Big[ \mathbb{I}[\text{Any attempt on $i$-th problem succeeds}] \Big].
\end{aligned}
\end{equation}


Using the unbiased and numerically stable estimator of \citet{chen2021evaluatinglargelanguagemodels} (for details, see Appendix~\ref{app:sec:chen2021estimator}), \citet{brown2024largelanguagemonkeysscaling} found that the negative log averaged-over-$P$-problems success rate falls as a power law with the number of independent attempts per problem $k$:
%
\begin{equation}
-\log \Bigg( \frac{1}{P} \sum_{i=1}^P \operatorname{pass_i@k} \Bigg) \approx a k^{-b},
\end{equation}
%
for model-specific and benchmark-specific constants $a, b > 0$ (Fig.~\ref{fig:power_laws_repeat_sampling} Top). Soon after, on a separate topic of jailbreaking multimodal language models via text, image and audio attacks, independent work by \citet{hughes2024bestofnjailbreaking} studied jailbreaking success rates when $k$ independent attempts are made per harmful prompt. Performance was measured using Attack Success Rate (ASR) at $k$:
%
\begin{equation}
\begin{aligned}
&\operatorname{ASR_i@k} \, \defeq \,\\ &\mathop{\raisebox{3pt}{$\mathbb{E}$}}_{\substack{k \text{ Attempts}}}\Big[ \mathbb{I}[\text{Any attack on $i$-th prompt succeeds}] \Big].
\end{aligned}
\end{equation}
%
This ``Best-of-N Jailbreaking" attack similarly discovered that the negative log averaged-over-$P$-prompts attack success rate fell as a power law with the number of jailbreak attempts per prompt $k$:
%
\begin{equation}
-\log \Bigg( \frac{1}{P} \sum_{i=1}^P \operatorname{ASR_i@k} \Bigg)\approx a k^{-b},
\end{equation}
%
for model-specific and modality-specific constants $a, b > 0$ (Fig.~\ref{fig:power_laws_repeat_sampling} Bottom).
For the specific coefficients from both papers, see Appendix.~\ref{app:sec:power_law_fits_bon_and_llmonkey}.
As a minor matter of terminology, both papers frame their results in terms of ``coverage" -- the fraction of problems that can be solved after $k$ attempts per problem -- but as \citet{brown2024largelanguagemonkeysscaling} pointed out, coverage is equivalent to the average success rate (Appendix~\ref{app:sec:coverage_pass_at_k}); we prefer this latter framing as it avoids the binary implication that each problem either is or is not solved after $k$ attempts.