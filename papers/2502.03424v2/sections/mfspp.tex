\section{MFSP Predictor}
\label{sec:mfspp}

With the training of the MIDR predictor complete, we have developed a NN-based agent model that effectively serves as a surrogate for the FEA conducted using OpenSeesRT. This agent model presents two critical advantages over traditional FEA: (1) computational efficiency and (2) differentiability. These advantages are fully leveraged in training the MFSP predictor, designed to identify the location within the building structure that exhibits the highest vulnerability under fire conditions via the MIDR. Importantly, the training process for the MFSP predictor no longer depends on direct FEA results. Instead, the fixed parameters of the pretrained MIDR predictor are utilized as the computational platform. This allows the MIDR predictor to remain unchanged during the MFSP predictor's training, ensuring consistency and efficiency in the workflow. By relying solely on the outputs of the MIDR predictor, the MFSP predictor benefits from the speed and differentiability of the agent model while eliminating the need for repeated computationally expensive FEA simulations.

\subsection{Pseudo-Labeling and Loss Choice}
\label{subsec:mfspp_pseudo_label}
As illustrated in \figref{fig:system_overview}, the MFSP predictor operates as the ``argmaxer'' of the MIDR predictor. An intuitive choice of the loss function is to minimize the negative output of the MIDR predictor $L_{\text{MIDR}}$. This loss leverages the differentiable nature of the MIDR predictor as an agent. It is expressed as:  
\begin{equation}
    L_{\text{MIDR}} = - \frac{1}{\sum_{m}^{M}N_{m}}\sum_{m}^{M}\sum_{n}^{N_m} \widehat{d}_{m,n,\max}.
\end{equation}
This approach conceptually resembles the Actor-Critic framework in RL \cite{sutton2018reinforcement} where the MFSP predictor is the ``Actor'', proposing actions in the form of fire points, while the MIDR predictor is the ``Critic'', evaluating the quality of the Actor's actions. However, similar to challenges in RL, this method can lead to poor training outcome or convergence issues. MIDR predictor is a complex function and optimizing its output using gradient descent often results in local optima or unstable training. Additionally, the fixed nature of MIDR predictor limits the ability to introduce randomness for balancing exploration and exploitation, a core mechanism in RL.

To address these issues, we propose an alternative approach inspired by the computational efficiency of the MIDR predictor. Instead of directly using $L_{\text{MIDR}}$, we use the MIDR predictor to generate {\em{pseudo ground truths}} for the MFSP. This process is depicted in \figref{fig:pseudo_label}. Specifically, at the granularity of the rooms, we consider the center point of each room in a building as a potential fire point. The MIDR predictor estimates the MIDR for each fire point, and the one with the highest MIDR is selected as the pseudo ground truth MFSP for the building. This pseudo-labeling approach allows efficient labeling of unlabeled data at the room-level granularity.
\begin{figure*}[h!]
    \centering
    \includegraphics[width=1\linewidth]{figures/pseudo_label.pdf}
    \caption{Procedure of pseudo-labeling for building structure $m$.}
    \label{fig:pseudo_label}
\end{figure*}

For a given building structure $m$, let the pseudo ground truth MFSP coordinates be $\left( x_{m}^{\, \pgt}, y_{m}^{\, \pgt}, z_{m}^{\, \pgt}\right)$, with the corresponding MIDR $\widehat{d}_{m}^{\, \pgt}$. Using this pseudo-labeling, we define the Mean Squared Error (MSE) loss as follows:  
\begin{equation}
    \begin{aligned}
        L_{\text{MSE}} = \frac{1}{M}\sum_{m=1}^{M}&\left( \left( x_{m}^{\, \pgt} - \widehat{x}_{m} \right)^2 + \left( y_{m}^{\, \pgt} - \widehat{y}_{m} \right)^2 \right. \\  
        & \left.+ \left( z_{m}^{\, \pgt} - \widehat{z}_{m} \right)^2 \right),
    \end{aligned}
    \label{eq:MSE}
\end{equation}
where $\widehat{x}_{m}$, $\widehat{y}_{m}$, and $\widehat{z}_{m}$ are the MFSP predictor's outputs for structure $m$. Since the pseudo-labeling process provides ground truth at room-level granularity, it is beneficial to combine $L_{\text{MIDR}}$ and $L_{\text{MSE}}$ into a hybrid loss function via a weighted sum to train the MFSP predictor. In this way, the combined loss $L_{\text{Hybrid}}$ is defined as follows:  
\begin{equation}
    L_{\text{Hybrid}} = w_1 \, L_{\text{MIDR}} + w_2 \, L_{\text{MSE}},
    \label{eq:hybrid}
\end{equation}  
where $w_1$ and $w_2$ are weights balancing the contributions of the two loss components. In this study, we fix $w_2=1$, so that $w_1$ is interpreted as a measure of the distrust on the pseudo ground truth MFSP generated by the labeling process. This distrust increases as $w_1$ increases. This hybrid approach combines the strengths of leveraging differentiability through $L_{\text{MIDR}}$ and the guidance provided by pseudo ground truth through $L_{\text{MSE}}$, offering a robust method for training the MFSP predictor.

\subsection{TL with GNN in MIDR Predictor}
\label{subsec:mfspp_transfer_learning}
The MFSP predictor operates as an ``argmaxer'' for the MIDR predictor. While it could be designed as a completely new network and trained from scratch (i.e., De novo training), we propose leveraging the pretrained GNN module from the MIDR predictor through TL. The GNN module in the MIDR predictor captures comprehensive global structural information, making it a suitable platform for the MFSP predictor. Specifically, we reuse the GNN module as a feature extractor, replace the MLP task head with a new one tailored for the MFSP task, and fine-tune the entire model to optimize its performance.
% \subsubsection{Structural information via TL}
By reusing the pretrained GNN module, which encodes essential structural and gravity load features, the MFSP predictor can focus on learning the relationships necessary to identify the MFSP. This approach reduces training time and enhances model performance by building on the already-learned representations of the structural information, rather than starting from scratch.

% \paragraph*{The virtual fire point method}
% \subsubsection{The virtual fire point method}
\revise{A unique challenge arises when reusing the GNN in the MIDR predictor requiring a fire point as the input although not need for the MFSP prediction. Common practice to deal with such problem is {\em{masking}}, especially in computer vision or natural language processing. However, masking, such as zero-value masking (i.e., ignore certain inputs by setting them to zero), cannot be directly applied here, because the 3D coordinates $(0,0,0)$ represent a valid location --a possible fire at the bottom corner of the building structure.} To overcome this challenge, we introduce a randomized Virtual Fire Point (VFP). \revise{Essentially, this VFP can be regarded as a placeholder for the GNN input.} During training, a random virtual fire location is assigned to each structure for every iteration, independently of prior iterations. This randomized approach forces the network to learn the global structural features necessary for predicting the MFSP, while effectively ignoring the influence of specific fire locations. 
In the inference stage, different from training stage, we set the VFP to be the geometric center of the structure, i.e., not being randomized. This ensures that the MSFP predictor focuses on the overall structural information rather than being biased by the presence of specific fire locations. By combining TL and the VFP, the MFSP predictor achieves robust generalization and improved accuracy in identifying the MFSP in diverse structural configurations.
