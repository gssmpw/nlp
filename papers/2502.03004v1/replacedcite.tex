\section{Related Work}
\textbf{Optimizing LLMs for Medical and Biological Applications.} The application of LLMs in medical and biological domains has demonstrated significant improvements in reasoning-based question answering ____. One of the most notable advancements is Med-Gemini ____, a family of models fine-tuned specifically for medical reasoning. Med-Gemini has achieved state-of-the-art performance on the MedQA benchmark ____, surpassing previous models through an uncertainty-guided search strategy. This strategy enables the model to refine its responses based on external information retrieved through web search, ensuring greater factual accuracy and reliability.

Long-form question answering in medical and biological domains presents unique challenges, requiring models to generate coherent, factually accurate, and contextually rich responses. To address this, both Med-Gemini ____ and OLAPH ____ have adopted pairwise evaluation methodologies, allowing human experts to assess and compare generated answers against ground truth references. This approach ensures that models produce responses that align with expert consensus while minimizing factual errors and hallucinations.

OLAPH, on the other hand, employs a preference-based optimization framework to iteratively refine long-text generation. By constructing synthetic preference sets and training on preferred responses, OLAPH enhances factual consistency and linguistic fluency. In parallel, models such as BioGPT ____ and Flan-PaLM ____ have explored domain-specific fine-tuning to improve the accuracy of medical text generation through task-specific retrieval mechanisms.

These methodologies underline the need for robust evaluation frameworks in medical LFQA. Given the complexity of clinical reasoning, future research should focus on refining automated evaluation metrics and incorporating multi-expert consensus validation to ensure reliability in real-world applications.






\textbf{Search-based Text Generation for Medical and Biological Tasks.}
RAG has emerged as a critical technique for enhancing the reliability and factual accuracy of LLM-generated responses in medicine. Med-Gemini integrates a search retrieval mechanism that dynamically incorporates external knowledge sources into its generation pipeline. This approach, known as uncertainty-guided search, enables the model to refine its answers based on retrieved web documents, reducing the risk of hallucinated content.

Beyond structured search, Med-Gemini’s multimodal capabilities allow cross-modal retrieval and reasoning, integrating text, images, and structured data from electronic health records. These capabilities make it particularly suitable for real-world applications such as clinical decision support, medical summarization, and literature synthesis.

Search-based text generation represents a promising direction for medical AI, enabling models to dynamically incorporate external knowledge while maintaining fluency and coherence.

\begin{figure}
\vskip 0.2in
\begin{center}
\centerline{\includegraphics[width=\columnwidth]{RAG_mechanism.pdf}}
\caption{Illustration of the Retrieval-Augmented Generation (RAG) process. The system consists of three main components: (1) \textbf{Query Encoder}, which processes the input query into tokenized representations (\(T_1, T_2, \dots, T_n \)), (2) \textbf{Knowledge Searching and Retrieving}, where the system performs document cracking, chunking, and index projection to retrieve relevant knowledge (\(K_1, K_2, \dots, K_n\)), and (3) \textbf{Answer Generator}, which integrates retrieved data into the response generation process. Here, \(T_i\) represents tokenized query input, while \(K_i\) denotes retrieved knowledge chunks. This approach enhances factual accuracy by incorporating external knowledge into the model’s output.}
\label{RAG_mechanism}
\end{center}
\vskip -0.2in
\end{figure}