[
  {
    "index": 0,
    "papers": [
      {
        "key": "hinton2015distilling",
        "author": "Hinton, G",
        "title": "Distilling the Knowledge in a Neural Network"
      }
    ]
  },
  {
    "index": 1,
    "papers": [
      {
        "key": "chen2017learning",
        "author": "Chen, Guobin and Choi, Wongun and Yu, Xiang and Han, Tony and Chandraker, Manmohan",
        "title": "Learning efficient object detection models with knowledge distillation"
      }
    ]
  },
  {
    "index": 2,
    "papers": [
      {
        "key": "yim2017gift",
        "author": "Yim, Junho and Joo, Donggyu and Bae, Jihoon and Kim, Junmo",
        "title": "A gift from knowledge distillation: Fast optimization, network minimization and transfer learning"
      }
    ]
  },
  {
    "index": 3,
    "papers": [
      {
        "key": "reddi2021rankdistil",
        "author": "Reddi, Sashank and Pasumarthi, Rama Kumar and Menon, Aditya and Rawat, Ankit Singh and Yu, Felix and Kim, Seungyeon and Veit, Andreas and Kumar, Sanjiv",
        "title": "Rankdistil: Knowledge distillation for ranking"
      }
    ]
  },
  {
    "index": 4,
    "papers": [
      {
        "key": "wu2023ad",
        "author": "Wu, Siyue  and\nChen, Hongzhan  and\nQuan, Xiaojun  and\nWang, Qifan  and\nWang, Rui",
        "title": "{AD}-{KD}: Attribution-Driven Knowledge Distillation for Language Model Compression"
      }
    ]
  },
  {
    "index": 5,
    "papers": [
      {
        "key": "liu2020adaptive",
        "author": "Liu, Yuang and Zhang, Wei and Wang, Jun",
        "title": "Adaptive multi-teacher multi-level knowledge distillation"
      }
    ]
  },
  {
    "index": 6,
    "papers": [
      {
        "key": "gu2024minillm",
        "author": "Gu, Yuxian and Dong, Li and Wei, Furu and Huang, Minlie",
        "title": "MiniLLM: Knowledge distillation of large language models"
      }
    ]
  },
  {
    "index": 7,
    "papers": [
      {
        "key": "ko2024distillm",
        "author": "Ko, Jongwoo and Kim, Sungnyun and Chen, Tianyi and Yun, Se-Young",
        "title": "DistiLLM: Towards Streamlined Distillation for Large Language Models"
      }
    ]
  },
  {
    "index": 8,
    "papers": [
      {
        "key": "wen2023f",
        "author": "Wen, Yuqiao and Li, Zichao and Du, Wenyu and Mou, Lili",
        "title": "f-Divergence Minimization for Sequence-Level Knowledge Distillation"
      }
    ]
  },
  {
    "index": 9,
    "papers": [
      {
        "key": "wu2024rethinking",
        "author": "Wu, Taiqiang and Tao, Chaofan and Wang, Jiahao and Zhao, Zhe and Wong, Ngai",
        "title": "Rethinking Kullback-Leibler Divergence in Knowledge Distillation for Large Language Models"
      }
    ]
  },
  {
    "index": 10,
    "papers": [
      {
        "key": "vicuna2023",
        "author": "Chiang, Wei-Lin and Li, Zhuohan and Lin, Zi and Sheng, Ying and Wu, Zhanghao and Zhang, Hao and Zheng, Lianmin and Zhuang, Siyuan and Zhuang, Yonghao and Gonzalez, Joseph E. and Stoica, Ion and Xing, Eric P.",
        "title": "Vicuna: An Open-Source Chatbot Impressing GPT-4 with 90\\%* ChatGPT Quality"
      }
    ]
  },
  {
    "index": 11,
    "papers": [
      {
        "key": "chen2023mcc",
        "author": "Chen, Hongzhan and Wu, Siyue and Quan, Xiaojun and Wang, Rui and Yan, Ming and Zhang, Ji",
        "title": "MCC-KD: Multi-CoT Consistent Knowledge Distillation"
      }
    ]
  },
  {
    "index": 12,
    "papers": [
      {
        "key": "ouyang2022training",
        "author": "Ouyang, Long and Wu, Jeffrey and Jiang, Xu and Almeida, Diogo and Wainwright, Carroll and Mishkin, Pamela and Zhang, Chong and Agarwal, Sandhini and Slama, Katarina and Ray, Alex and others",
        "title": "Training language models to follow instructions with human feedback"
      }
    ]
  },
  {
    "index": 13,
    "papers": [
      {
        "key": "schulman2017proximal",
        "author": "Schulman, John and Wolski, Filip and Dhariwal, Prafulla and Radford, Alec and Klimov, Oleg",
        "title": "Proximal policy optimization algorithms"
      }
    ]
  },
  {
    "index": 14,
    "papers": [
      {
        "key": "rafailov2024direct",
        "author": "Rafailov, Rafael and Sharma, Archit and Mitchell, Eric and Manning, Christopher D and Ermon, Stefano and Finn, Chelsea",
        "title": "Direct preference optimization: Your language model is secretly a reward model"
      }
    ]
  },
  {
    "index": 15,
    "papers": [
      {
        "key": "zhao2023slic",
        "author": "Zhao, Yao and Joshi, Rishabh and Liu, Tianqi and Khalman, Misha and Saleh, Mohammad and Liu, Peter J",
        "title": "Slic-hf: Sequence likelihood calibration with human feedback"
      }
    ]
  },
  {
    "index": 16,
    "papers": [
      {
        "key": "yang2024preference",
        "author": "Yang, Shentao and Zhang, Shujian and Xia, Congying and Feng, Yihao and Xiong, Caiming and Zhou, Mingyuan",
        "title": "Preference-grounded token-level guidance for language model fine-tuning"
      }
    ]
  },
  {
    "index": 17,
    "papers": [
      {
        "key": "yoon2024tlcr",
        "author": "Yoon, Eunseop and Yoon, Hee Suk and Eom, SooHwan and Han, Gunsoo and Nam, Daniel and Jo, Daejin and On, Kyoung-Woon and Hasegawa-Johnson, Mark and Kim, Sungwoong and Yoo, Chang",
        "title": "TLCR: Token-Level Continuous Reward for Fine-grained Reinforcement Learning from Human Feedback"
      }
    ]
  },
  {
    "index": 18,
    "papers": [
      {
        "key": "lee2023rlaif",
        "author": "Lee, Harrison and Phatale, Samrat and Mansoor, Hassan and Lu, Kellie and Mesnard, Thomas and Bishop, Colton and Carbune, Victor and Rastogi, Abhinav",
        "title": "Rlaif: Scaling reinforcement learning from human feedback with ai feedback"
      }
    ]
  },
  {
    "index": 19,
    "papers": [
      {
        "key": "tunstall2023zephyr",
        "author": "Tunstall, Lewis and Beeching, Edward and Lambert, Nathan and Rajani, Nazneen and Rasul, Kashif and Belkada, Younes and Huang, Shengyi and von Werra, Leandro and Fourrier, Cl{\\'e}mentine and Habib, Nathan and others",
        "title": "Zephyr: Direct distillation of lm alignment"
      }
    ]
  },
  {
    "index": 20,
    "papers": [
      {
        "key": "starling2023",
        "author": "Zhu, Banghua and Frick, Evan and Wu, Tianhao and Zhu, Hanlin and Ganesan, Karthik and Chiang, Wei-Lin and Zhang, Jian and Jiao, Jiantao",
        "title": "Starling-7b: Improving helpfulness and harmlessness with rlaif"
      }
    ]
  },
  {
    "index": 21,
    "papers": [
      {
        "key": "li2024direct",
        "author": "Li, Yixing and Gu, Yuxian and Dong, Li and Wang, Dequan and Cheng, Yu and Wei, Furu",
        "title": "Direct Preference Knowledge Distillation for Large Language Models"
      }
    ]
  },
  {
    "index": 22,
    "papers": [
      {
        "key": "zhang2024plad",
        "author": "Zhang, Rongzhi  and\nShen, Jiaming  and\nLiu, Tianqi  and\nWang, Haorui  and\nQin, Zhen  and\nHan, Feng  and\nLiu, Jialu  and\nBaumgartner, Simon  and\nBendersky, Michael  and\nZhang, Chao",
        "title": "{PL}a{D}: Preference-based Large Language Model Distillation with Pseudo-Preference Pairs"
      }
    ]
  },
  {
    "index": 23,
    "papers": [
      {
        "key": "yang2023rlcd",
        "author": "Yang, Kevin and Klein, Dan and Celikyilmaz, Asli and Peng, Nanyun and Tian, Yuandong",
        "title": "RLCD: Reinforcement Learning from Contrastive Distillation for LM Alignment"
      }
    ]
  },
  {
    "index": 24,
    "papers": [
      {
        "key": "fisch2024robust",
        "author": "Fisch, Adam and Eisenstein, Jacob and Zayats, Vicky and Agarwal, Alekh and Beirami, Ahmad and Nagpal, Chirag and Shaw, Pete and Berant, Jonathan",
        "title": "Robust preference optimization through reward model distillation"
      }
    ]
  }
]