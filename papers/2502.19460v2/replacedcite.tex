\section{Background and related work}
\label{sec:background_and_related_work}

\subsection{Survival data and notation}
Many survival analysis models estimate the probability that a specific event will occur for an individual at a time $T$ later than $t$, for all times $t > 0$. Examples include predicting the time to death in patients with amyotrophic lateral sclerosis (ALS)____, predicting the time to a fall in older adults____, or evaluating a new experimental treatment for cancer____. Most often, the observation for a given instance will consist of a random variable, $E$, representing the time from a given origin ($t=0$) to the occurrence of the event, \eg "death". The distribution of $E$ can be characterized by the probability distribution function $F_E(t) = \Pr(E \leq t)$ or, equivalently, by the survival function $S_E(t) = 1 - F_E(t) = \Pr(E > t)$. 
Note that $S_E(t)$ (resp., $F_E(t)$) correspond to the probabilities of being event-free
(resp., having experienced the event by) time $t$.
We can estimate $S_E\br{t}$ nonparametrically, \eg using the Kaplan-Meier____ estimator (see Appendix~\ref{app:derivations} for a detailed derivation).
\begin{definition}
The Kaplan-Meier (KM) estimator\\[-1ex]
\begin{equation}
\label{def:km_estimator}
\begin{split}
\hat{S}(t)\  &= \prod_{t_i \leq t, d_i = 1} \left(1 - \frac{1}{n_i}\right), 
\quad % \\
%  &\leq t \leq t_{\text{max}}
\hbox{\rm for}\quad t \leq t_{\text{max}} 
\end{split}
\end{equation}
where $n_i = \sum_{\ell=1}^n I(t_\ell \geq t_i)$ is the \textit{number at-risk} at time $t_i$; $\hat{S}(t) = 1$ if no death occurs up to time $t$; $\hat{S}(t)$ is undefined for $t > t_{\text{max}}$____. 
\end{definition}

If features are entered into the model, popular methods include the CoxPH model____, gradient-boosted regression____, Random Survival Forest____ and Multi-Task Logistic Regression (MTLR)____. 
In this context, we may define our survival dataset $\mathcal{D}$ as a set of observations, 
\ie we have $\mathcal{D} = \left\lbrace \br{\bm{x}_{i}, t_i, \delta_i} \right\rbrace_{i=1}^N$, where $\bm{x}_i \in \mathbb{R}^{d}$ is a feature (covariate) vector for instance $i$, $t_i \in \mathbb{R}^{\geq 0}$ is the time of either censoring or event, depending on which occurred first, and $\delta_i \in \{0, 1\}$ is a event indicator where $\delta_i = 0$ means the event has not happened by $t_i$ (right-censored) and $\delta_i = 1$ means the event occurred at $t_i$ (uncensored). We consider each instance to have a potential event time $e_i$ and a right-censoring time $c_i$, where we observe only the earlier of the two. Therefore, we define the observed time and event indicator as:
\\ \hspace*{3em} $ %\begin{align*} 
t_i \ := \ \min\{e_i, c_i\}, \quad \text{and} \quad \delta_i \ := \ \mathbbm{1}[e_i \leq c_i],
$ \\ % \end{align*} 
\noindent where $\mathbbm{1}[\cdot]$ represents the indicator function.

Given survival data $\mathcal{D}$, let $f_{E\mid \bm{X}}(\cdot)$ and $F_{E\mid \bm{X}}(\cdot)$ represent the conditional density and cumulative distribution functions, respectively, over the event horizon (\ie from $0$ to $t_{\text{max}}$). With these two functions, we then have the following useful definitions:

\begin{definition}
The survival function\\[-2ex]
\begin{equation}
\label{def:survival_function}
S_{E\mid \bm{X}}(t\mid \bm{X}) = \Pr(E > t \mid  \bm{X}) = 1 - F_{E\mid \bm{X}}(t \mid  \bm{X}),
\end{equation}
represents the probability the event occurs at time $t$~\cite[Ch. 11]{gareth_introduction_2021}.
\end{definition}
\begin{definition}

The hazard function\\[-2ex]
\begin{eqnarray}
% \begin{equation}
% \label{def:hazard_function}
% \begin{split}
h_{E\mid \bm{X}}(t\mid \bm{X})& = \ & \lim_{\epsilon \to 0} \Pr(E \in [t, t+\epsilon) \mid E \geq t, \bm{X})
 \nonumber\\
 &=\ & \frac{f_{E\mid \bm{X}}(t\mid \bm{X})}{S_{E\mid \bm{X}}(t\mid \bm{X})}
   \label{def:hazard_function}
% \end{split}
\end{eqnarray} % \end{equation}
represents the instantaneous event rate at given time $t$, conditional on surviving $t$~\cite[Ch. 11]{gareth_introduction_2021}.
\end{definition}

\subsection{Copula-Based Estimation} % 2.2
\label{sec:depCensor}
A \textit{copula} is a function that links two or more random variables by specifying their dependence structure____. 
Among the various types of copulas, the Archimedean copula family is the most used, and enables modeling of dependencies in arbitrarily high dimensions using a single parameter, $\theta$. This family of copulas is defined by a generator function, $\varphi_\theta(t): [0, 1] \to [0, \infty]$, which is continuous, strictly decreasing, and satisfies the boundary conditions $\varphi(0) = \infty$ and $\varphi(1) = 0$~\cite[Ch. 3]{Emura2018}. Here, we will focus on two common Archimedean copulas: Clayton~\hbox{____} and Frank~\hbox{____}.

____ generalized the KM estimator under independent censoring to the Copula-Graphic (CG) estimator under dependent censoring, which has become an important tool for analyzing survival data____. 
____ obtained the first explicit expression of the CG estimator under an assumed copula from the Archimedean family (\eg Clayton or Frank). We can estimate the survival function using the CG estimator (see Appendix~\ref{app:derivations} for a detailed derivation):
\begin{definition}
The Copula-Graphic (CG) estimator
\begin{equation} \small
\label{def:cg:estimator}
\begin{split}
\hat{S}_E(t) &= \varphi^{-1} \left(\sum_{
% \add[RG]
{i:\,}t_i \leq t,\delta_i=1} 
\varphi\left(\frac{n_i - 1}{n}\right) - \varphi\left(\frac{n_i}{n}\right) \right), \\
\hbox{for} & \quad t\ \leq\ t_{\text{max}} 
   % \in\ [0, \,t_{\text{max}}]\ ,
\end{split}
\end{equation}
where $n_i = \sum_{\ell=1}^n I(t_\ell \geq t_i)$ is the number at risk at time $t_i$; $\hat{S}_E(t) = 1$ if no death occurs up to time $t$; $\hat{S}_E(t)$ is undefined for $t > t_{\text{max}}$____.
\end{definition}
Note that when $\varphi(\cdot)$ is uniform, this reduces to the standard KM estimator. See Appendix~\ref{app:copulas_and_definitions} for more details.

\subsection{Evaluation metrics and limitations} % 2.3
\label{sec:Eval-bias}
We now outline the conventional evaluation metrics in survival analysis. The detailed calculation of these metrics is outlined in Appendix~\ref{app:exist_metrics} and here we mainly focus on why those metrics are problematic under dependent censoring.

\textbf{Concordance index (CI)} evaluates the ranking of individuals when their relative ordering is of primary interest. It measures the proportion of concordant pairs -- pairs where the predicted ranking of risk scores aligns with the true ordering of event times -- among all comparable pairs____. A pair $(i,j)$ is defined as \textit{comparable} if $\delta_i = 1$ and $t_i < t_j$, which means that the earlier individual has experienced the event and the observed time of the later individual is greater than the first. Even under the random censoring assumption, it is evident that the comparable pairs selected using the above criteria do not represent all possible pairs based on their true event times: 
\\ \hspace*{3em} $ %\begin{align*} 
\Pr(\delta_i=1, t_i<t_j) \quad \neq\quad \Pr(e_{i}<e_{j}). 
$ \\ % \end{align*} 
This inequality arises because the left-hand term can be decomposed as:\\[-1ex]
$$\begin{array}{l} %\begin{align*} 
\Pr(\, \delta_i=1, \ t_i<t_j) \\
=\quad  \Pr(\, e_{i} < c_{i},\ \ e_{i}\ <\ \min \{ c_{j}, e_{j}\}\ )\\
= \quad \Pr(\, e_{i} < c_{i},\ t_{e,i}< c_{j},\ e_{i}< e_{j})\\
=\quad  \underline{\Pr(\, c_{i} < c_{i})\ \Pr( e_{i}< c_{j})} \quad 
  \Pr( e_{i}< e_{j})\ , 
\end{array} % \end{align*} 
$$
where the factorization follows from the independent censoring assumption. 
Compared to the right-hand side term, this expression includes additional underlined
terms related to the censoring distribution, confirming the findings of____.

To address this limitation, ____ introduced a modified version of CI that employs inverse probability of censoring weights (IPCW), ensuring consistency with the true CI. The IPCW approach estimates the probability of being uncensored at each time point and reweights the uncensored instances accordingly.

\textbf{Integrated Brier Score (IBS)} evaluates the overall accuracy of predicted survival functions by integrating the Brier Score (BS)____ over a range of time points. It measures the average squared difference between the predicted survival probabilities and actual survival outcomes over time____. To handle censored instances, IPCW can be used to reweight uncensored instances when computing both BS and IBS____. Similar to IPCW-CI, IPCW weights are often approximated using the KM estimator, which is biased under dependent censoring____.

\textbf{Mean Absolute Error (MAE)} quantifies the accuracy of point predictions for event times by measuring the absolute difference between the predicted and true event times. For censored instances, ____ proposed an approach that approximates that subject's event time as the mean of the KM estimator (Equation~\ref{def:km_estimator}), renormalized at that individual's censoring time. This proxy event time, weighted by confidence estimates (also derived from KM), is then used to compute the absolute error. We will refer to this method as MAE-Margin. Given a subject is censored at time $c_i$, its margin time is calculated as:
\begin{equation}\label{eq:e_margin}
e^{\text{margin}}(\hat{S}, t_i) = \mathbb{E}[E \mid E > t_i] = t_i + \frac{\int_{t_i}^{\infty} \hat{S}_{}(t) \, dt}{\hat{S}(t_i)},
\end{equation}
\noindent where $\hat{S}(t)$ is an estimator, \eg the KM, derived from the training dataset.

\textbf{Limitations.} All the aforementioned metrics typically rely on KM estimates to approximate either the marginal time-to-event or the marginal time-to-censoring distribution. While KM is advantageous due to its consistency under the independent censoring assumption and its computational simplicity -- requiring no interaction with the covariates -- it becomes problematic when censoring and event times are dependent____. 
In such cases, the KM estimates may be biased and inconsistent____. 
To mitigate these issues, researchers have proposed modifying these metrics by replacing KM with a conditional estimator (\eg~CoxPH) to account for the dependency between covariates and censoring distributions____. 
However, this approach still has two major limitations: (1)~\textit{model misspecification:} if the conditional estimator is inaccurately specified, the resulting estimates may be unreliable, 
and 
(2)~\textit{uncaptured dependencies:} under dependent censoring (\ie~when unobserved confounders exist), even a well-specified conditional estimator may fail to fully account for the dependency if there are important covariates missing in the analysis. These challenges highlight the need for robust estimation methods that can better handle dependent censoring scenarios.