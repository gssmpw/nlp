\section{\model} \label{gsrbench}
In this section, we provide the problem statement for code deployment in \model, introduce the code repository collection process of computer science research projects, and show their statistics.
% \vspace{-1em}
% \vspace{-0.5em}
\subsection{Problem Statement}
% \vspace{-0.5em}
The \model consists of a collection of computer science research repositories from GitHub and these repositories are used for evaluating the capabilities of LLMs in code deployment tasks. For each repository, the deployment tasks typically include: (1) setting up the environment; (2) preparing necessary data and model files; (3) conducting model training; (4) demonstration of inference; (5) performance evaluation. To complete these tasks, we prompt LLMs to generate executable bash commands by using the README file as the primary source of information and other repository contents (source code, bash scripts, directory structure, and etc.) as supplementary information.

%\textbf{Input Data.}
%The input data for the model is the GitHub repository itself, with a particular focus on the README file located in the root folder. The model has access to all files within the repository. The LLM agent can also leverage the repository's file structure to set up the correct path, rather than relying on placeholder paths.

%\textbf{Generation Goal.}
%The goal is to generate bash scripts for deploying and verifying the repositories and to produce a summary of the deployment process. In some instances, manual intervention may be required, such as setting up an API key or providing a download link for files requiring verification (e.g., for LLaMA models). The summary will be presented to users, allowing them to provide feedback on the large language model to address any issues or gaps.

%\textbf{Performance Evaluation.}
%For code repositories of empirical and experimental computer science research projects, typical deployment steps include environment setup, installation, data and model file preparation and download, training deployment, testing and evaluation, and demonstration or inference examples.

\textbf{Metric.}
During the evaluation in \model, the large language model will be prompted to generate executable commands for the corresponding sections for each repository. %Currently, large language model agents still require further development to fully and comprehensively understand and deploy repositories without errors. Therefore, 
we use the completion rate as a key metric, defined as the ratio between number of successfully executed commands %with a return code of zero 
and the total number of commands executed.
\subsection{Repository Collection}
% \vspace{-0.5em}
%\textbf{Construction} 
In \model, we aim to collect a diverse and comprehensive collection of code repositories of computer science-related research projects. GitHub is a good data source for this purpose and it provides tags for identifying most relevant repositories. Some example tags are “nlp”, “naacl”, and “emnlp2024”. Since \model focuses on computer science-related repositories, we filter the repositories by tags of various conference names and categories to ensure they include diverse topics. %, such as natural language processing, computer vision, data mining, machine learning and etc.

For repository selection, we use GitHub tags to obtain an initial set of over 1500 repositories that are relevant to computer science research topics and categorizing them into five areas: Natural Language Processing, Computer Vision, Large Language Models, Machine Learning, and Interdisciplinary topics. Notably, we collect repositories related to large language models because nowadays LLM-related research projects are increasingly popular due to its foundational impact in various areas of computer science. 

\begin{figure*}[htbp]
    \centering
    \begin{minipage}[b]{0.45\linewidth}
        \centering
        \includegraphics[width=\linewidth]{assets/GSRBench_Conf.pdf}
        \caption{Conf Distribution of \model}
        \label{fig:conf}
    \end{minipage}
    \hfill
    \begin{minipage}[b]{0.45\linewidth}
        \centering
        \includegraphics[width=\linewidth]{assets/GSRBench_Sunburst.pdf}
        \caption{Topic Distribution of \model}
        \label{fig:topic}
    \end{minipage}
    \vspace{-1em}
\end{figure*}


We obtain 100 high-quality code repositories for \model in the following steps. First, we categorize this initial set and sort them by the number of GitHub stars. Next, we manually check the content of each repository starting from the top of the sorted list. In this step, we only keep repositories that contain sufficient information in their README files. We also skip the repositories that do not contain deployable code. Finally, we check the licenses of the repositories and make sure they are permissive.
%We manually select the most representative, research-oriented large language model repositories from the top 50 repositories tagged with ``large language model".

% % \vspace{-1em}

% \vspace{-0.5em}
\subsection{Statistics of \model}

This section provides an in-depth analysis of the traits of repositories in \model. We examine the diversity and breadth of topics covered, as well as detailed statistics about the documentation and structure of these repositories.

% \textit{Category Distribution}

% Detailed analysis of the category distribution will illustrate how the repositories span across various scientific disciplines. This information helps to understand the interdisciplinary nature of the dataset and the predominant fields of study.
% % \vspace{-0.5em}


% \begin{figure}[htbp]
%     \centering
%     \includegraphics[width=0.95\linewidth]{assets/readme_word_count_distribution.pdf}
%     \caption{Distribution of Word Count in README Files}
%     \label{fig:readme_word_distribution}
% \end{figure}

% \begin{figure}[htbp]
%     \centering
%     \includegraphics[width=0.95\linewidth]{assets/repo_file_count_distribution.pdf}
%     \caption{Distribution of Repository File Count. This figure shows the distribution of repository file counts, with a histogram depicting the number of repositories against the count of files they contain.}
%     \label{fig:repo_file_distribution}
% \end{figure}

%% \vspace{-1.25em}





% \begin{figure}[ht]
%     \centering
%     \begin{minipage}[b]{0.95\linewidth}
%         \centering
%         \includegraphics[width=\linewidth]{assets/file_count_distribution.pdf}
%         \vspace{-1.5em}
%         \caption{Number of Files per 
%         Repository}
%         \label{fig:file_count_distribution}
%     \end{minipage}
%     % \hspace{0.05\linewidth}
%     \begin{minipage}[b]{0.95\linewidth}
%         \centering
%         \includegraphics[width=\linewidth]{assets/token_count_distribution.pdf}
%         \vspace{-1.5em}
%         \caption{Number of Tokens per README}
%         \label{fig:token_count_distribution}
%     \end{minipage}
% \end{figure}
% %% \vspace{-1.25em}
% \begin{figure}[htbp]
%     \centering
%     \begin{minipage}[b]{0.95\linewidth}
%         \centering
%         \includegraphics[width=\linewidth]{assets/star_count_distribution.pdf}
%         \vspace{-1.5em}
%         \caption{Stargazer Distribution}
%         \label{fig:stars_distribution}
%     \end{minipage}
%     % \hspace{0.05\linewidth}
%     \begin{minipage}[b]{0.95\linewidth}
%         \centering
%         \includegraphics[width=\linewidth]{assets/issue_count_distribution.pdf}
%         \vspace{-1.5em}
%         \caption{Size of Issue Database}
%         \label{fig:issue_count_distribution}
%     \end{minipage}
% \end{figure}


% %% \vspace{-1em}
% Figure \ref{fig:token_count_distribution} illustrates the distribution of word counts in README files, shedding light on the extent of documentation provided across the repositories. This metric is crucial for assessing the completeness of information necessary for users to understand and use the repositories effectively.

% Figure \ref{fig:file_count_distribution} shows the distribution of file counts of repositories, with a histogram depicting the number of repositories against the count of files they contain. The number of files can reflect the complexity and scale of its corresponding repository.

In \model, the README files and directory structures provide critical insights into the usability and organization of repositories. We use the following figures to analyze the lengths of README file and number of files, and offer a quantitative view of content complexity and organizational depth. The length of README file is an important metric because the most LLMs have limits on the input token length. The number of files indicate the complexity of the code repository.

\begin{figure}[ht]
    \centering
    \includegraphics[width=\linewidth]{assets/token_count_distribution.pdf}
    \vspace{-1.5em}
    \caption{Number of Tokens per README}
    \label{fig:token_count_distribution}
\end{figure}

Figure \ref{fig:token_count_distribution} shows the distribution of token counts in README files, highlighting the extent of documentation, which is essential for user understanding and repository usability. Since the mean token counts is just over 1000 and the maximum counts is around 3000, most LLMs can take the full README files as input.

\begin{figure}[ht]
    \centering
    \includegraphics[width=\linewidth]{assets/file_count_distribution.pdf}
    \vspace{-1.5em}
    \caption{Number of Files per Repository}
    \label{fig:file_count_distribution}
\end{figure}

Figure \ref{fig:file_count_distribution} depicts the distribution of file counts in repositories, reflecting their complexity and scale based on the number of files. Because the number of files in most repositories are in the lower hundreds, it is feasible to leverage directory structure for code deployment with LLMs.

\begin{figure}[ht]
    \centering
    \includegraphics[width=\linewidth]{assets/star_count_distribution.pdf}
    \vspace{-1.5em}
    \caption{Stargazer Distribution}
    \label{fig:stars_distribution}
\end{figure}


Figure \ref{fig:stars_distribution} shows the distribution of star counts in selected repositories. The average count is over 590, which means that these repositories receives significant attention and indicates they are generally well maintained.



\begin{figure}[ht]
    \centering
    \includegraphics[width=\linewidth]{assets/issue_count_distribution.pdf}
    \vspace{-1.5em}
    \caption{Size of Issue Database}
    \label{fig:issue_count_distribution}
\end{figure}

Figure \ref{fig:issue_count_distribution} shows the distribution of issues counts in selected repositories. On average, each repository contains over 48 issues, indicating these repositories have a good amount of engagements with the open-source community and sufficient support from the authors. Therefore, the information in the issues are valuable for the deployment tasks.



% \vspace{-1em}
% Note that the repository ``HIPT'' is excluded from these plots due to its outlier large size (`readme': 3117 words, `files': 14246, `folders': 970), which significantly skews the average. This exclusion ensures the data presented reflects a more typical repository profile within the dataset.


