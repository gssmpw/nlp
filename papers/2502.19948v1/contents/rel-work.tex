\section{Related Work} \label{sec:rel-work}

Overfitting occurs when a model excels during the training phase but performs inadequately on unseen test data. A typical approach to counter overfitting involves incorporating regularization terms into the objective function, such as the L1 or L2 norms of the learnable parameters. These regularization terms are designed to encourage the development of simpler relationships between features and targets, thus mitigating the risk of overfitting. Early stopping is another frequently adopted strategy to prevent overfitting. This technique involves ceasing the parameter updates once the loss on the validation set begins to show signs of increase, thereby avoiding the overfitting of the training data. Additional well-established methods to combat overfitting include data augmentation~\cite{krizhevsky2017imagenet}, employing model ensembles~\cite{ke2017lightgbm}, and modifying the architecture of neural networks by reducing their depth or width. These methods have been proven to be effective in enhancing the generalizability of models across unseen datasets.

Dropout is another widely recognized method specifically utilized in neural networks to curb overfitting~\cite{srivastava2014dropout}. During training, Dropout randomly deactivates a subset of neurons, ensuring that the neural network does not become overly dependent on any particular set of neurons. This technique effectively simulates the use of multiple neural network models and aggregates their predictions, which enhances the robustness of the model. Notably, the random neuron deactivation is only applied during the training phase and not during inference. To maintain consistent expected values between training and inference, Inverted Dropout is commonly utilized.

DropConnect extends the idea of Dropout by randomly omitting connections, or edges, between neurons during the training phase. This approach is similar to Dropout in that masking a neuron in Dropout is analogous to masking both the incoming and outgoing connections of that neuron in DropConnect. Empirically, both Dropout and DropConnect often result in models with comparable performance levels.

From a Bayesian perspective, Dropout can also be interpreted as performing an approximated Bayesian inference in deep Gaussian processes~\cite{gal2016dropout}. Notable techniques within this framework include Monte Carlo Dropout~\cite{gal2016dropout}, fast dropout~\cite{wang2013fast}, and variational dropout~\cite{kingma2015variational}, each offering unique approaches to implementing Dropout within a Bayesian inference context.

Some recent studies have explored the idea of varying the dropping rate throughout the training process. A notable example is Standout~\cite{ba2013adaptive}, which dynamically adjusts the dropping rate based on the values of the model parameters. Unlike other variations of Standout, which often necessitate additional learning parameters, our approach simplifies the process by avoiding extra learning mechanisms. This not only reduces training time and memory requirements but also provides a more transparent method for determining dynamic dropping rates. Furthermore, our research has explored the efficacy of utilizing gradient values rather than parameter values for adjusting drop rates, which has shown promising results in our experimental evaluations.

For a comprehensive review of Dropout and its various adaptations, please refer to the survey by Labach et al.~\cite{labach2019survey}.