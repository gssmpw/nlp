\section{Related Work}
Recently, the self-supervised learning (SSL) framework____ is introduced for the research domain of computer vision. The goal of SSL is to train a deep learning model to understand the semantic-level invariance characteristics through carefully designed pretext tasks from  high-level semantic understanding related to image data (e.g. learning rotation-invariant representation for images)____. An increasingly amount of time series representation learning research has been focused on designing the self-supervised deep learning framework____. Most models are designed based on the unsupervised contrastive learning framework such as SimCLR ____. 

Franceschi et al.____ introduces an unsupervised contrastive learning framework by introducing a novel triplet selection approach based on a segment's context. Similarly, Tonekaboni et al. proposed a framework named Temporal Neighborhood Coding (TNC) ____. TNC aims to utilize the temporal correlation along neighboring segments to learn representations. Eldele et al. ____ introduces a Temporal and Contextual Contrast (TS-TCC) based framework.  In TS-TCC, two types of augments, strong augmentation and weak augmentation are used to perform contrastive learning. Zhang et al. ____ proposed a time-frequency consistent loss (TFC) for contrastive learning where temporal and frequency of the same neighborhoods are pushed closer together often focus on the problem of out-of-distribution generalization ability. 

Recently, Yue et al. ____ proposed a framework named ts2vec. The proposed framework introduces a random cropping based augmentation and a hierarchical loss, which aims to extract semantic information in all resolutions, in order to obtain a generalizeable embedding representation. Wang et al.____ proposed a task-driven multi-resolution contrastive learning framework, which aims at contrasting semantic information in different levels for medicial time series.  Both achieved significantly better performance compared with previous methods. However, the extensive computational burden of performing contrastive loss in all resolutions also leads to higher comptuational cost.