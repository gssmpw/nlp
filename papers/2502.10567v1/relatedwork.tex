\section{Related Work}
Recently, the self-supervised learning (SSL) framework~\cite{zhai2019s4l,misra2020self,hendrycks2019using,chen2020simple,he2020momentum,chen2020improved,grill2020bootstrap} is introduced for the research domain of computer vision. The goal of SSL is to train a deep learning model to understand the semantic-level invariance characteristics through carefully designed pretext tasks from  high-level semantic understanding related to image data (e.g. learning rotation-invariant representation for images)~\cite{zhai2019s4l,jang2018grasp2vec,gidaris2018unsupervised}. An increasingly amount of time series representation learning research has been focused on designing the self-supervised deep learning framework~\cite{yue2022ts2vec,franceschi2019unsupervised,tonekaboni2021unsupervised,eldele2021time}. Most models are designed based on the unsupervised contrastive learning framework such as SimCLR ~\cite{chen2020simple}. 

Franceschi et al.\cite{franceschi2019unsupervised} introduces an unsupervised contrastive learning framework by introducing a novel triplet selection approach based on a segment's context. Similarly, Tonekaboni et al. proposed a framework named Temporal Neighborhood Coding (TNC) \cite{tonekaboni2021unsupervised}. TNC aims to utilize the temporal correlation along neighboring segments to learn representations. Eldele et al. \cite{eldele2021time} introduces a Temporal and Contextual Contrast (TS-TCC) based framework.  In TS-TCC, two types of augments, strong augmentation and weak augmentation are used to perform contrastive learning. Zhang et al. \cite{zhang2022self} proposed a time-frequency consistent loss (TFC) for contrastive learning where temporal and frequency of the same neighborhoods are pushed closer together often focus on the problem of out-of-distribution generalization ability. 

Recently, Yue et al. \cite{yue2022ts2vec} proposed a framework named ts2vec. The proposed framework introduces a random cropping based augmentation and a hierarchical loss, which aims to extract semantic information in all resolutions, in order to obtain a generalizeable embedding representation. Wang et al.\cite{wang2024contrast} proposed a task-driven multi-resolution contrastive learning framework, which aims at contrasting semantic information in different levels for medicial time series.  Both achieved significantly better performance compared with previous methods. However, the extensive computational burden of performing contrastive loss in all resolutions also leads to higher comptuational cost.