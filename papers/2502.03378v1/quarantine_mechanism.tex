%\vspace{-10pt}
\section{Quarantine} \label{subsec:quarantine}
As mentioned in Section \ref{sec:lov_overview}, we employ a quarantine mechanism for further inspection to ensure the quality of the whitelist.
We employ different strategies to assess quarantined routes for reliable whitelisting, tailoring these strategies to the priority level of the routes while also considering whitelist quantity and efficiency. 

Benign conflicts identified by the classifier are given high priority for whitelisting, as the classifier's false negative rate (misclassifying hijacks as benign conflicts) is expected to be very low, given its design goal. Nevertheless, reviewing these routes will be beneficial for countering adversarial attacks, specifically evasion attacks, as described in Section \ref{subsubsec:robustness}.

Recall that the tighter the relationship between two origins involved in a BGP route, the more likely the route is to be benign.
For these routes, we thus examine the overall tightness level between the two origins. We evaluate the tightness between the two origins by defining a formula: {$T = w_{0}*OriginMatch + w_{1}*PC + w_{2}*MOAS + w_{3}*Parent + w_{4}*Depen + w{5}*AltSources - w_{6}*ASdist$}, where $T$ refers to the overall tightness value, and $w_{0}, w_{1}, w_{2}, w_{3}, w_{4}, w_{5}, w_{6}$ represents the positive weight values for the seven features used.
This formula is designed to be straightforward in computation and is based on the intuitive concept that two origins with more relations and smaller distance values (such as $PC = 1$ and $Depen = 1$ and $ASdist = 0.01$) exhibit greater tightness.
We specify the $w_{0}, w_{1}, w_{2}, w_{3}, w_{4}, w_{5}, w_{6}$ values using the feature importance scores computed in Section \ref{subsubsec:lov_feature_importance}.
The first strategy we utilize is to whitelist routes that exhibit a $T$ value greater than $T_{thr}$ (the threshold value to be determined in our measurements).
This approach ensures a sufficient number of routes in the whitelist while maintaining high efficiency due to its simplicity.

Next, for routes excluded by the first strategy and those not confirmed by the post-analyzer, we carefully monitor their behavior—including their longevity and activity levels—drawing inspiration from the PGBGP tool (as mentioned in Section \ref{sec:relatedwork}).
A longer monitoring period increases confidence that whitelisted routes are indeed benign, given that benign routes typically persist longer.
However, extending this period decreases the efficiency of the whitelisting process.
Based on our empirical observations, we set the quarantine period to 14 days, sufficiently long to determine whether a route is benign while maintaining reasonable efficiency. Additionally, to guarantee the relevance of the whitelist, our primary focus is on whitelisting actively used routes. \lov\ employs two criteria for this whitelisting. First, the route must appear on at least two days within a week, ensuring adequate frequency of occurrence. Second, the most recent appearance of the route should be no more than a week before the end of quarantine, guaranteeing that the route is likely still active.
Note that this behavior monitoring strategy is more rigorous (i.e., involving long-term monitoring and focusing solely on routes in active use) compared to the first one, as it addresses routes that are considered to have a relatively lower likelihood of being benign.
This approach whitelists fewer routes and exhibits lower efficiency due to the stringent rules.

Moreover, we introduce human intervention as a strategy for whitelisting. As mentioned earlier, evidence obtained from the analysis of hijacking events through email surveys assists security analysts in implementing this intervention. For instance, if email surveys indicate that routes of interest, which have conflicting origins with ROAs, are genuinely benign and not due to correctable errors, we manually add these routes to the whitelist if they are not already included. Conversely, if it is confirmed that the conflicting origins are the result of hijacking, we ensure these routes do not pollute the whitelist. Human intervention enhances the effectiveness and reliability of the whitelist. 


