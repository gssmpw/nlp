\vspace{-5pt}
\section{Key Questions} \label{sec:questions}
This section addresses key questions about \lov.
%In this section, we address several key questions regarding the implementation and deployment aspects of \lov.

\textit{Does ML-Classifier need to retrain?}
In this work, we do not retrain the ML classifier with new data, primarily because the features used can help reduce issues with model generalization to newly emerging data, as described in Section \ref{subsubsec:model_general}.
Nevertheless, expanding the size and diversity of the training data could potentially enhance the classifier's effectiveness and adaptability to various scenarios.

\textit{Why is post-analyzer necessary?}
The post-analyzer not only identifies potential benign conflicts mistakenly flagged as hijacks by the ML classifier but also detects possible hijacking events.
The classifier identifies each hijack as an individual instance within an event, without automatically linking them to hijacking events. To associate hijacks with a specific event, the first step is to identify the perpetrator AS that initiated the event, along with the occurrence time. The post-analyzer helps in identifying these initiators and the event time, assisting security analysts in subsequent event analysis.

\textit{Can \lov\ be deployed in individual networks?}
\lov\ can be deployed within a network that has ROV in practice, to create a local whitelist, ensuring that legitimate traffic with benign ROA conflicts is not mistakenly filtered by ROV. This approach removes the reliance on, and potential distrust of, third-party whitelists. However, to prevent any impact on BGP convergence, \lov\ must operate separately from ROV. For instance, \lov\ can function in the background without interfering with the ongoing ROV processes.

Additionally, \lov\ employs various mechanisms, including ML-based, signature-based, heuristic-based, and analyst-driven approaches, which may require security personnel with expertise in areas such as ML technologies. In addition, deploying \lov\ independently may also incur significant costs associated with hardware, software, and maintenance.

We do not recommend directly incorporating the ML classifier into the existing ROV mechanism (as SROV is expected to do). Although this approach might seem straightforward to implement and deploy, the ML-based system is vulnerable to adversarial attacks, which could impair the ROV's ability to detect hijacks.

\textit{What are the differences between SROV and \lov?}
Both SROV and \lov\ incorporate classifiers to distinguish between benign conflicts and real hijacks. The primary difference between the two classifiers is not the use of different technologies—non-ML versus ML—but their design goals. \lov\ aims to preserve as many benign conflicts as possible while maintaining the ROV system's existing ability to prevent hijacks. In contrast, SROV seems to overlook the importance of this balance, leading to an impractical approach. Furthermore, we do not integrate SROV's route duration-based method into \lov\ because it relies on longitudinal route observation, which could affect the whitelist's timeliness. However, during quarantine, \lov\ monitors route behavior (e.g., its duration), complementing the ML classifier.

\textit{What are the differences between \lov\ and BGPmon?}
BGPmon is often considered a reliable monitoring service for BGP anomalies.
\lov\ and BGPmon have a different focus: \lov\ identifies and analyzes benign conflicts, while BGPmon targets the detection of BGP route anomalies such as hijacks. Looking towards the future, there are opportunities for collaboration between \lov\ and BGPmon. For instance, hijacks or events detected by BGPmon could enhance \lov\, such as updating \lov's classifier with new hijacks. Conversely, BGPmon could leverage benign conflicts detected by \lov\ to minimize potential false positives.

Unlike BGPmon, the hijacking events identified by \lov\ are not publicly disclosed. \lov\ focuses exclusively on confirming hijacking events through email surveys to provide evidence for possible human intervention. Consequently, the accuracy in identifying these events has a limited impact on the reliability of the whitelist.

\textit{What are the advantages, limitations, and security considerations of \lov?}
The whitelist provided by \lov\ is easy to update, maintain, and manage, with minimal resource overhead. More importantly, the additional step after ROV enforcement—checking whether the RPKI-invalid route is on the list—incurs negligible time cost, thus minimizing the impact on BGP convergence.
However, behavior monitoring and human intervention in quarantine often require days of route observation, potentially delaying the addition of some benign conflicts to the whitelist and affecting its timeliness. Future work will explore more efficient inspection mechanisms. In rare cases where the victim network is the provider of the attacker's network, the ML classifier may fail to detect the hijack. However, proximity between the victim and malicious networks can often facilitate quicker attack detection and mitigation, provided appropriate monitoring systems are in place. Future work will incorporate additional features to address such attacks.
Additionally, all codes, data, and models are kept confidential and are not publicly available. The operational process of \lov\ is also not transparent.
While these measures can help prevent potential vulnerability exposure to adversaries, ensuring data security and service integrity, they may lead to distrust in the whitelist and hinder its broader adoption. One potential solution might be to involve authoritative organizations (e.g., cybersecurity agencies) to regularly monitor and assess \lov, certifying its effectiveness and reliability. The potential misuse of the whitelist represents another limitation in the deployment of \lov. As previously mentioned, users can access the whitelist through the APIs we provide. Similarly, adversaries might acquire the whitelist, alter it, and distribute a falsified version under the guise of \lov.
One way to mitigate this risk could be to restrict access to the whitelist of benign conflicts to users who verify their identities. For example, users might be required to submit an email request from an organizational address and provide certification of their identity before gaining access.












