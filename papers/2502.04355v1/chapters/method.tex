\begin{figure*}[htbp]
\centerline{\includegraphics[scale=0.55]{figures/The_Overview_of_LLM-ProS.png}}
\caption{The Overview of \Name{}}
\label{fig:overview}
\end{figure*}
\section{Methodology}
Figure \ref{fig:overview} illustrates the overview of our proposed technique, \Name{}. \Name{} consists of four major steps: data collection, data preprocessing, model testing, and solution generation and submission. The details of each step are discussed in the following subsections.

\subsection{Data Collection}
We scrape a total of 166 competitive programming problems from the ICPC official website \cite{b8}, specifically from the World Finals editions spanning the years 2011 to 2024 World Finals. We select these years to avoid potential overlap with the training data of major LLMs, ensuring a more accurate evaluation of their performance. Table \ref{tab:problemst} shows a sample problem structure that we have collected. Each problem includes comprehensive details such as problem statements, input formats, output formats, sample inputs and outputs, notes, and specified time and memory limits. This dataset provides a diverse and challenging set of tasks that effectively test the reasoning and computational abilities of LLMs.
\begin{table}[htbp]
\centering
\caption{Sample Problem Data}
\label{tab:problemst}
\begin{tabular}{|l|p{5cm}|}
\hline
\textbf{Problem Statement} & Allied Chute Manufacturers is a company that builds trash chutes. A trash chute ... \\
\hline
\textbf{Input-Output} & The input contains several test cases. Each test case starts with an integer $n$, representing the number of points in the polygon that models the trash item ($3 \leq n \leq 100$)... \\
\hline
\textbf{Sample testcase} & 
\textbf{Sample Input:} \newline
\texttt{3} \newline
\texttt{0 0} \newline
%\texttt{3 0} \newline
\texttt{...} \newline
%\texttt{4} \newline
%\texttt{0 10} \newline
%\texttt{10 0} \newline
%\texttt{20 10} \newline
%\texttt{10 20} \newline
%\texttt{0} \newline
\textbf{Sample Output:} \newline
\texttt{Case 1: 2.40} \newline
\texttt{Case 2: 14.15} \\
\hline
\end{tabular}
\end{table}

\subsection{Data Preprocessing}
Before generating solutions, we systematically preprocess each of the 166 ICPC World Finals problems to ensure compatibility and consistency across different LLMs. The preprocessing steps include:\\
\textbf{Extraction of Problem Components}: We break down each problem into its fundamental components, including the problem statement, input format, output format, sample inputs and outputs, notes, and specified time and memory limits. This structured extraction helps us create comprehensive prompts for the models.\\
\textbf{Standardized Prompt Formatting}: We format the extracted components into a consistent template to maintain uniformity across all prompts. The template includes sections such as ``Problem Statement", ``Input", ``Output", and ``Sample Test Cases", ensuring that each prompt provides all the necessary information for the model to generate an accurate solution.\\
\textbf{Text Cleaning and Normalization}: We clean all textual data to remove extraneous characters, ensure proper encoding, and maintain clarity. This step includes correcting formatting inconsistencies, standardizing terminology, and ensuring that mathematical notations and symbols are appropriately represented.\\
\textbf{Template Customization for Each Model}: Recognizing the unique characteristics and requirements of each LLM, we slightly adjust the templates to optimize prompt comprehension. For example, we provide models fine-tuned for chain-of-thought reasoning, such as o1-mini and o1-preview, with additional guiding instructions to facilitate step-by-step solution generation.\\
\textbf{Validation of Preprocessed Data}: We manually review the preprocessed prompts to ensure that all relevant information is accurately captured and that the prompts adhere to the standardized format. This validation step helps us identify and correct any discrepancies or omissions.

\subsection{Model Testing}
We evaluate five state-of-the-art LLMs: GPT-4o, Mistral Large, Llama-3.1-405B, and the OpenAI o1 Family, which consists o1-mini and o1-preview. Each model represents a different architecture, training methodology, and reasoning capability. We apply all five models to our preprocessed data. We select these models for their diverse training approaches, which represent a mix of general-purpose and task-optimized LLMs. We test them in a pass@1 setting to assess their ability to generalize to ICPC-style problems \cite{b1,b2}.

\ignore{
\subsubsection{GPT-4o}
GPT-4o \cite{b27} is a general-purpose model known for high accuracy in code generation and reasoning tasks but is less optimized for structured problem-solving compared to the o1 models.

\subsubsection{Mistral Large}
Mistral Large \cite{b11} specializes in handling domain-specific tasks with efficient resource usage. Its performance on ICPC problems provides insights into model efficiency versus generality.

\subsubsection{Llama-3.1-405B}
Llama-3.1-405B \cite{b10} is a smaller, computationally efficient model designed for general-purpose use, serving as a benchmark for lightweight LLMs in competitive programming.

\subsubsection{OpenAI o1 Family}
The o1-mini and o1-preview models \cite{b4} are fine-tuned for chain-of-thought (CoT) reasoning and iterative refinement, making them well-suited for solving structured, multi-step problems.
}

\subsection{Solution Generation and Submission}
We generate solutions to the scraped ICPC problems using the selected LLMs through their respective API keys. The generated solutions, which include code implementations aligned with the provided problem statements and constraints, are then submitted to the Codeforces Gym ICPC section contests \cite{b8}. Codeforces Gym provides automated feedback on correctness and efficiency, with verdicts such as ``Accepted" (AC), ``Wrong Answer" (WA), ``Time Limit Exceeded" (TLE), ``Runtime Error" (RE), and ``Compile Error" (CE). Submissions to Codeforces Gym are logged for reproducibility.\cite{b24}.