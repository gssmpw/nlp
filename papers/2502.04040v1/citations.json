[
  {
    "index": 0,
    "papers": [
      {
        "key": "gcg",
        "author": "Zou, Andy and Wang, Zifan and Carlini, Nicholas and Nasr, Milad and Kolter, J Zico and Fredrikson, Matt",
        "title": "Universal and transferable adversarial attacks on aligned language models"
      },
      {
        "key": "liu2023autodan",
        "author": "Liu, Xiaogeng and Xu, Nan and Chen, Muhao and Xiao, Chaowei",
        "title": "Autodan: Generating stealthy jailbreak prompts on aligned large language models"
      },
      {
        "key": "geisler2024attacking",
        "author": "Geisler, Simon and Wollschl{\\\"a}ger, Tom and Abdalla, MHI and Gasteiger, Johannes and G{\\\"u}nnemann, Stephan",
        "title": "Attacking large language models with projected gradient descent"
      }
    ]
  },
  {
    "index": 1,
    "papers": [
      {
        "key": "PAIR",
        "author": "Chao, Patrick and Robey, Alexander and Dobriban, Edgar and Hassani, Hamed and Pappas, George J and Wong, Eric",
        "title": "Jailbreaking black box large language models in twenty queries"
      },
      {
        "key": "wei2023jailbroken",
        "author": "Alexander Wei and Nika Haghtalab and Jacob Steinhardt",
        "title": "Jailbroken: How Does {LLM} Safety Training Fail?"
      },
      {
        "key": "shen2024anything",
        "author": "Shen, Xinyue and Chen, Zeyuan and Backes, Michael and Shen, Yun and Zhang, Yang",
        "title": "\" do anything now\": Characterizing and evaluating in-the-wild jailbreak prompts on large language models"
      },
      {
        "key": "gptsmart",
        "author": "Yuan, Youliang and Jiao, Wenxiang and Wang, Wenxuan and Huang, Jen-tse and He, Pinjia and Shi, Shuming and Tu, Zhaopeng",
        "title": "Gpt-4 is too smart to be safe: Stealthy chat with llms via cipher"
      },
      {
        "key": "zeng2024johnny",
        "author": "Zeng, Yi and Lin, Hongpeng and Zhang, Jingwen and Yang, Diyi and Jia, Ruoxi and Shi, Weiyan",
        "title": "How johnny can persuade llms to jailbreak them: Rethinking persuasion to challenge ai safety by humanizing llms"
      }
    ]
  },
  {
    "index": 2,
    "papers": [
      {
        "key": "mazeika2024harmbench",
        "author": "Mazeika, Mantas and Phan, Long and Yin, Xuwang and Zou, Andy and Wang, Zifan and Mu, Norman and Sakhaee, Elham and Li, Nathaniel and Basart, Steven and Li, Bo and others",
        "title": "Harmbench: A standardized evaluation framework for automated red teaming and robust refusal"
      }
    ]
  },
  {
    "index": 3,
    "papers": [
      {
        "key": "gcg",
        "author": "Zou, Andy and Wang, Zifan and Carlini, Nicholas and Nasr, Milad and Kolter, J Zico and Fredrikson, Matt",
        "title": "Universal and transferable adversarial attacks on aligned language models"
      }
    ]
  },
  {
    "index": 4,
    "papers": [
      {
        "key": "liu2023autodan",
        "author": "Liu, Xiaogeng and Xu, Nan and Chen, Muhao and Xiao, Chaowei",
        "title": "Autodan: Generating stealthy jailbreak prompts on aligned large language models"
      }
    ]
  },
  {
    "index": 5,
    "papers": [
      {
        "key": "DANismy",
        "author": "Walkerspider",
        "title": "Do-Anything-Now"
      }
    ]
  },
  {
    "index": 6,
    "papers": [
      {
        "key": "PAIR",
        "author": "Chao, Patrick and Robey, Alexander and Dobriban, Edgar and Hassani, Hamed and Pappas, George J and Wong, Eric",
        "title": "Jailbreaking black box large language models in twenty queries"
      }
    ]
  },
  {
    "index": 7,
    "papers": [
      {
        "key": "youliang",
        "author": "Yuan, Youliang and Jiao, Wenxiang and Wang, Wenxuan and Huang, Jen-tse and Xu, Jiahao and Liang, Tian and He, Pinjia and Tu, Zhaopeng",
        "title": "Refuse whenever you feel unsafe: Improving safety in llms via decoupled refusal training"
      },
      {
        "key": "qi2024safety",
        "author": "Qi, Xiangyu and Panda, Ashwinee and Lyu, Kaifeng and Ma, Xiao and Roy, Subhrajit and Beirami, Ahmad and Mittal, Prateek and Henderson, Peter",
        "title": "Safety Alignment Should Be Made More Than Just a Few Tokens Deep"
      }
    ]
  },
  {
    "index": 8,
    "papers": [
      {
        "key": "zou2024improving",
        "author": "Andy Zou and Long Phan and Justin Wang and Derek Duenas and Maxwell Lin and Maksym Andriushchenko and J Zico Kolter and Matt Fredrikson and Dan Hendrycks",
        "title": "Improving Alignment and Robustness with Circuit Breakers"
      },
      {
        "key": "sheshadri2024latent",
        "author": "Sheshadri, Abhay and Ewart, Aidan and Guo, Phillip and Lynch, Aengus and Wu, Cindy and Hebbar, Vivek and Sleight, Henry and Stickland, Asa Cooper and Perez, Ethan and Hadfield-Menell, Dylan and others",
        "title": "Latent adversarial training improves robustness to persistent harmful behaviors in llms"
      }
    ]
  },
  {
    "index": 9,
    "papers": [
      {
        "key": "kumar2022fine",
        "author": "Kumar, Ananya and Raghunathan, Aditi and Jones, Robbie and Ma, Tengyu and Liang, Percy",
        "title": "Fine-tuning can distort pretrained features and underperform out-of-distribution"
      }
    ]
  },
  {
    "index": 10,
    "papers": [
      {
        "key": "izmailov2022feature",
        "author": "Izmailov, Pavel and Kirichenko, Polina and Gruver, Nate and Wilson, Andrew G",
        "title": "On feature learning in the presence of spurious correlations"
      },
      {
        "key": "lee2022diversify",
        "author": "Lee, Yoonho and Yao, Huaxiu and Finn, Chelsea",
        "title": "Diversify and disambiguate: Learning from underspecified data"
      }
    ]
  },
  {
    "index": 11,
    "papers": [
      {
        "key": "uesato2022solving",
        "author": "Uesato, Jonathan and Kushman, Nate and Kumar, Ramana and Song, Francis and Siegel, Noah and Wang, Lisa and Creswell, Antonia and Irving, Geoffrey and Higgins, Irina",
        "title": "Solving math word problems with process-and outcome-based feedback"
      },
      {
        "key": "lightman2023let",
        "author": "Lightman, Hunter and Kosaraju, Vineet and Burda, Yura and Edwards, Harri and Baker, Bowen and Lee, Teddy and Leike, Jan and Schulman, John and Sutskever, Ilya and Cobbe, Karl",
        "title": "Let's verify step by step"
      }
    ]
  },
  {
    "index": 12,
    "papers": [
      {
        "key": "yu2023metamath",
        "author": "Yu, Longhui and Jiang, Weisen and Shi, Han and Yu, Jincheng and Liu, Zhengying and Zhang, Yu and Kwok, James T and Li, Zhenguo and Weller, Adrian and Liu, Weiyang",
        "title": "MetaMath: Bootstrap Your Own Mathematical Questions for Large Language Models"
      },
      {
        "key": "mitra2024orca",
        "author": "Mitra, Arindam and Khanpour, Hamed and Rosset, Corby and Awadallah, Ahmed",
        "title": "Orca-math: Unlocking the potential of slms in grade school math"
      }
    ]
  },
  {
    "index": 13,
    "papers": [
      {
        "key": "zelikman2022star",
        "author": "Zelikman, Eric and Wu, Yuhuai and Mu, Jesse and Goodman, Noah",
        "title": "Star: Bootstrapping reasoning with reasoning"
      },
      {
        "key": "yuan2023scaling",
        "author": "Yuan, Zheng and Yuan, Hongyi and Li, Chengpeng and Dong, Guanting and Lu, Keming and Tan, Chuanqi and Zhou, Chang and Zhou, Jingren",
        "title": "Scaling relationship on learning mathematical reasoning with large language models"
      },
      {
        "key": "wang2024math",
        "author": "Wang, Peiyi and Li, Lei and Shao, Zhihong and Xu, Runxin and Dai, Damai and Li, Yifei and Chen, Deli and Wu, Yu and Sui, Zhifang",
        "title": "Math-shepherd: Verify and reinforce llms step-by-step without human annotations"
      },
      {
        "key": "guan2025rstar",
        "author": "Guan, Xinyu and Zhang, Li Lyna and Liu, Yifei and Shang, Ning and Sun, Youran and Zhu, Yi and Yang, Fan and Yang, Mao",
        "title": "rStar-Math: Small LLMs Can Master Math Reasoning with Self-Evolved Deep Thinking"
      }
    ]
  },
  {
    "index": 14,
    "papers": [
      {
        "key": "qu2024recursive",
        "author": "Yuxiao Qu and Tianjun Zhang and Naman Garg and Aviral Kumar",
        "title": "Recursive Introspection: Teaching Language Model Agents How to Self-Improve"
      },
      {
        "key": "kumar2024training",
        "author": "Kumar, Aviral and Zhuang, Vincent and Agarwal, Rishabh and Su, Yi and Co-Reyes, John D and Singh, Avi and Baumli, Kate and Iqbal, Shariq and Bishop, Colton and Roelofs, Rebecca and others",
        "title": "Training language models to self-correct via reinforcement learning"
      }
    ]
  },
  {
    "index": 15,
    "papers": [
      {
        "key": "o1",
        "author": "OpenAI",
        "title": "Learning to reason with LLMs"
      },
      {
        "key": "guo2025deepseek",
        "author": "Guo, Daya and Yang, Dejian and Zhang, Haowei and Song, Junxiao and Zhang, Ruoyu and Xu, Runxin and Zhu, Qihao and Ma, Shirong and Wang, Peiyi and Bi, Xiao and others",
        "title": "DeepSeek-R1: Incentivizing Reasoning Capability in LLMs via Reinforcement Learning"
      }
    ]
  },
  {
    "index": 16,
    "papers": [
      {
        "key": "guan2024deliberative",
        "author": "Guan, Melody Y and Joglekar, Manas and Wallace, Eric and Jain, Saachi and Barak, Boaz and Heylar, Alec and Dias, Rachel and Vallone, Andrea and Ren, Hongyu and Wei, Jason and others",
        "title": "Deliberative alignment: Reasoning enables safer language models"
      }
    ]
  }
]