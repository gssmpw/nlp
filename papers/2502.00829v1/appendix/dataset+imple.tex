\section{Supplementary Materials for LLMNodeBed}

\subsection{Datasets}\label{sec:dataset}

\begin{table}[!h]
    \centering
    \caption{\textbf{Statistics of supported datasets in LLMNodeBed.}}
    \resizebox{0.95\linewidth}{!}{
    \begin{tabular}{c|cccc|c|cc|ccc}
       \toprule
       \rowcolor{COLOR_MEAN}  &  \multicolumn{4}{c|}{\textbf{Academic}} & \textbf{Web Link} & \multicolumn{2}{c|}{\textbf{Social}} & \multicolumn{3}{c}{\textbf{E-Commerce}} \\ 
       \rowcolor{COLOR_MEAN} \multirow{-2}{*}{\textbf{Statistics}} & Cora & Citeseer & Pubmed & arXiv & WikiCS & Instagram & Reddit & Books & Photo & Computer \\ \midrule
        \# Classes & 7 & 6 & 3 & 40 & 10 & 2 & 2 & 12 & 12 & 10 \\
       \# Nodes & 2,708 & 3,186 & 19,717 & 169,343 & 11,701 & 11,339 & 33,434 & 41,551 & 48,362 & 87,229 \\ 
       \# Edges & 5,429 & 4,277 & 44,338 & 1,166,243 & 215,863 & 144,010 & 198,448 & 358,574 & 500,928 & 721,081 \\ 
       Avg. \# Token & 183.4 & 210.0  & 446.5 & 239.8 & 629.9 & 56.2 & 197.3 & 337.0 & 201.5 & 123.1  \\
       Homophily (\%) & 82.52 & 72.93 & 79.24 & 63.53 & 68.67 & 63.35 & 55.52 & 78.05 & 78.50 & 85.28 \\
       \bottomrule
    \end{tabular}
    }
    \label{tab:dataset}
\end{table}

\begin{table}[!t]
    \centering
    \caption{\textbf{Details of datasets: label space and training data percentages with supervision}.}
    \resizebox{0.95\linewidth}{!}{
    \begin{tabular}{c|cc} 
      \toprule
      \rowcolor{COLOR_MEAN} \textbf{Domain} &  \textbf{Dataset}  & \textbf{Label Space} \\ \midrule
       \multirow{9}{*}{\textbf{Academic}} & Cora  & \begin{tabular}{c}
          Rule\_Learning, Neural\_Networks, Case\_Based, Genetic\_Algorithms,\\ Theory, Reinforcement\_Learning, Probabilistic\_Methods
       \end{tabular} \\
       & Citeseer & \begin{tabular}{c}
            Agents, ML (Machine Learning), IR (Information Retrieval), DB (Databases), \\ HCI (Human-Computer Interaction), AI (Artificial Intelligence)
       \end{tabular} \\ 
       & Pubmed & Experimentally induced diabetes, Type 1 diabetes, Type 2 diabetes \\ 
      &  arXiv & \begin{tabular}{c}
           cs.NA, cs.MM, cs.LO, cs.CY, cs.CR, cs.DC, cs.HC, cs.CE, cs.NI, cs.CC,\\ cs.AI, cs.MA, cs.GL, cs.NE, cs.SC, cs.AR, cs.CV, cs.GR, cs.ET, cs.SY,\\ cs.CG, cs.OH, cs.PL, cs.SE, cs.LG, cs.SD, cs.SI, cs.RO, cs.IT, cs.PF,\\ cs.CL, cs.IR, cs.MS, cs.FL, cs.DS, cs.OS, cs.GT, cs.DB, cs.DL, cs.DM
      \end{tabular}\\ \midrule 

      \textbf{Web Link} & WikiCS & \begin{tabular}{c} 
           Computational Linguistics, Databases, Operating Systems, Computer Architecture,\\ Computer Security, Internet Protocols, Computer File Systems,\\ Distributed Computing Architecture, Web Technology, Programming Language Topics
      \end{tabular} \\ \midrule

      \multirow{2}{*}{\textbf{Social}} & Instagram & Normal User, Commercial User \\ 
      & Reddit & Normal User, Popular User \\ \midrule

      \multirow{6}{*}{\textbf{E-Commerce}} & Books & \begin{tabular}{c} 
          World, Americas, Asia, Military, Europe, Russia, Africa, \\ Ancient Civilizations,  Middle East, Historical Study \& Educational Resources,\\ Australia \& Oceania, Arctic \& Antarctica
      \end{tabular} \\ 
      & Photo & \begin{tabular}{c} \small
           Video Surveillance, Accessories, Binoculars \& Scopes, Video,\\ Lighting \& Studio, Bags \& Cases,  Tripods \& Monopods, Flashes, \\ Digital Cameras, Film Photography, Lenses, Underwater Photography
      \end{tabular} \\ 
      & Computer & \begin{tabular}{c} 
          Computer Accessories \& Peripherals, Tablet Accessories, Laptop Accessories, \\ Computers \& Tablets,  Computer Components, Data Storage, Networking Products,\\ Monitors, Servers, Tablet Replacement Parts
      \end{tabular}
      
      \\ \bottomrule 
        
    \end{tabular}
    }
    \vspace*{10pt}
    \resizebox{0.95\linewidth}{!}{
     \begin{tabular}{c|cccccccccc} 
         \toprule
        \rowcolor{COLOR_MEAN} \textbf{Setting} &  \textbf{Cora} & \textbf{Citeseer} & \textbf{Pubmed} & \textbf{arXiv} & \textbf{WikiCS} & \textbf{Instagram} & \textbf{Reddit} & \textbf{Books} & \textbf{Photo} & \textbf{Computer} \\ \midrule
         Semi-supervised & 5.17\% & 3.77\% & 0.30\% & - & 4.96\% & 10.00\% & 10.00\% & 10.00\% & 10.00\% & 10.00\%  \\
         Supervised & 60.0\% & 60.0\% & 60.0\% & 53.7\% & 60.0\% & 60.0\% & 60.0\% & 60.0\% & 60.0\% & 60.0\% \\
        \bottomrule
     \end{tabular}
    }
    \label{tab:dataset_detail}
\end{table}

We selected 10 datasets from academic, web link, social, and e-commerce domains to create a diverse graph database. Within LLMNodeBed, each dataset is stored in \texttt{.pt} format using PyTorch, which includes shallow embeddings, raw text of nodes, edge indices, labels, and data splits for convenient loading. The datasets are described below, while their statistics and additional details are provided in Table \ref{tab:dataset} and Table \ref{tab:dataset_detail}, respectively. 

\begin{itemize} % [leftmargin=*, topsep=2pt]
    \item \textbf{Academic Networks: }The \textbf{Cora} \cite{Sen2008CollectiveCora}, \textbf{Citeseer} \cite{Giles1998CiteSeerAA}, \textbf{Pubmed} \cite{Yang2016RevisitingSL}, and \textbf{ogbn-arXiv} (abbreviated as ``arXiv'') \cite{hu2020open} datasets consist of nodes representing papers, with edges indicating citation relationships. The associated text attributes include each paper's title and abstract, which we use the collected version as follows: Cora and Pubmed from \citet{he2023TAPE}, Citeseer from \citet{chen2024exploring}. Within the dataset, each node is labeled according to its category. For example, the arXiv dataset includes 40 CS sub-categories such as cs.AI (Artificial Intelligence) and cs.DB (Databases).

    \item  \textbf{Web Link Network: }In the \textbf{WikiCS} dataset \cite{Mernyei2020WikiCSAW}, each node represents a Wikipedia page, and edges indicate reference links between pages. The raw text for each node includes the page name and content, which was collected by \citet{liu2023one}. The classification goal is to categorize each entity into different Wikipedia categories. 
    
    \item \textbf{Social Networks: }The \textbf{Reddit} and \textbf{Instagram} datasets, originally released in \citet{Huang2024GraphAdapter}, feature nodes representing users, with edges denoting social connections like following relationships. For Reddit, each user's associated text consists of their historically published sub-reddits, while for Instagram, it includes the userâ€™s profile page introduction. In Reddit, nodes are labeled to indicate whether the user is popular or normal, while in Instagram, labels specify whether a user is commercial or normal.  

    \item \textbf{E-Commerce Networks: }The \textbf{Ele-Photo} (abbreviated as ``Photo'') and \textbf{Ele-Computer} (abbreviated as ``Computer'') datasets are derived from the Amazon Electronics dataset \cite{Ni2019Amazon}, where each node represents an item in the Photo or Computer category. The \textbf{Books-History} (abbreviated as ``Books'') dataset comes from the Amazon Books dataset, where each node corresponds to a book in the history category. We utilize the processed datasets released in \citet{yan2023comprehensive}. In these e-commerce networks, edges indicate co-purchase or co-view relationships. The associated text for each item includes descriptions, e.g., book titles and summaries, or user reviews. The classification task involves categorizing these products into fine-grained sub-categories.
\end{itemize}



\subsection{Implementation Details and Hyperparameters Setting}\label{sec:hyperparam}

\begin{itemize}
    \item For \textbf{GNNs} with arbitrary input embeddings, either from shallow embeddings or those generated by LMs or LLMs, we perform a grid-search on the hyperparameters as follows:
    
    \texttt{num\_layers} in $[2, 3, 4]$, \texttt{hidden\_dimension} in $[32, 64, 128, 256]$, and \texttt{dropout} in $[0.3, 0.5, 0.7]$.

    Additionally, we explore the design space by considering the inclusion or exclusion of \texttt{batch\_normalization} and \texttt{residual\_connection}. 
    
    For \textbf{shallow embeddings}, the Cora, Citeseer, Pubmed, WikiCS, and arXiv datasets provide initialized embeddings in their released versions \cite{hu2020open, Sen2008CollectiveCora}. For remaining datasets lacking shallow embeddings, we construct these embeddings using \textbf{Node2Vec} \cite{Grover2016node2vecSF} techniques, generating a fixed $300$-dimensional embedding for each node based on a walk length of $30$ and a total of $10$ walks. 
    
    \item For \textbf{MLPs} with arbitrary input embeddings, we perform a grid-search on the hyperparameters as follows: 

    \texttt{num\_layers} in $[2, 3, 4]$, \texttt{hidden\_dimension} in $[128, 256, 512]$, and \texttt{dropout} in $[0.5, 0.6, 0.7]$.

    For both GNNs and MLPs across experimental datasets, the \texttt{learning\_rate} is consistently set to $1e-2$, following previous studies \cite{he2023TAPE, Li2024GLBench}. The total number of epochs is set to $500$ with a patience of $100$. 


    \item For \textbf{SenBERT-66M} and \textbf{RoBERTa-355M}, we set the training epochs to $10$ for semi-supervised settings and $4$ for supervised settings. The \texttt{batch\_size} is set to $32$, and the \texttt{learning\_rate} is set to $2e-5$.  


    \item For \textbf{ENGINE} \cite{Zhu2024ENGINE}, we refer to the hyperparameter settings outlined in the original paper to determine the hyperparameter search space as follows:
    
    \texttt{num\_layers} in $[1, 2, 3]$, $\texttt{hidden\_dimension}$ in $[64, 128]$, and \texttt{learning\_rate} in $[5e-4, 1e-3]$. 
    
    The neighborhood sampler is set to ``Random Walk'' for Cora while ``$k$-Hop'' with $k=2$ for the remaining datasets. 


    \item For \textbf{TAPE} \cite{he2023TAPE}, we utilize the provided prompt templates to guide Mistral-7B and GPT-4o in conducting reasoning. The LM, RoBERTa-355M, is fine-tuned based on its default parameter settings, while the GNN hyperparameters are explored with \texttt{num\_layers} in $[2,3,4]$, \texttt{hidden\_dimension} in $[128,256]$, and with or without \texttt{batch\_normalization}.

    \item For \textbf{LLM Instruction Tuning}, we use the LoRA \cite{Hu2021LoRALA} techniques to fine-tune LLMs. The \texttt{lora\_r} parameter (dimension for LoRA update matrices) is set to $8$ and the \texttt{lora\_alpha} (scaling factor) to $16$. The \texttt{dropout} ratio is set to $0.1$, the \texttt{batch\_size} to $16$, and the \texttt{learning\_rate} to $1e-5$. For each dataset, the input consists of the node's original text along with a carefully crafted task prompt designed to guide the LLMs in performing the classification task. The expected output is the corresponding label. For small-scale datasets such as Cora, Citeseer, and Instagram, the number of training epochs is $10$ in semi-supervised settings and $4$ in supervised settings. For the remaining datasets, the training epochs are $2$ and $1$ for semi-supervised and supervised settings, respectively. The maximum input and output lengths are determined based on the average token lengths of each dataset.

    \item For \textbf{LLaGA} \cite{chen23llaga}, we empirically find that the HO templates consistently outperform the ND templates. Therefore, we set the HO templates as the default configuration, with \texttt{num\_hop} set to $4$. We use the text encoder as RoBERTa-355M. The linear projection layer $\phi_{\theta}(\cdot)$ consists of a $2-$layer MLP with a \texttt{hidden\_dimension} of $2048$. The \texttt{batch\_size} is set to $64$ and \texttt{learning\_rate} to $1e-4$. The number of training epochs is set to $10$ for semi-supervised settings and $4$ for supervised settings. For Qwen2.5-series, we encounter over-fitting issues in the Photo, Computer, and Books datasets,  leading us to adjust the learning rate to $5e-5$ and reduce the number of epochs to $2$ under supervised settings.

    \item For \textbf{GraphGPT} \cite{tang2023graphgpt}, it includes three distinct stages: (1) text-graph grounding, (2) self-supervised instruction tuning, and (3) task-specific instruction tuning. Our empirical findings indicate that the inclusion of stage (1) does not consistently lead to performance improvements, thereby rendering this stage optional. For stage (2), we construct self-supervised training data for each dataset to perform dataset-specific graph matching tasks, adhering to the provided data format\footnote{\href{https://huggingface.co/datasets/Jiabin99/graph-matching}{https://huggingface.co/datasets/Jiabin99/graph-matching}}. In stage (3), we utilize the training data to create $\langle$instruction, ground-truth label$\rangle$ pairs following the original prompt design. The training parameters for stage (2) include $2$ epochs with a \texttt{learning\_rate} of $1e-4$ and a \texttt{batch\_size} of $16$. For stage (3), we train for $10$ epochs in semi-supervised settings and $6$ epochs in supervised settings, with a \texttt{batch\_size} of $32$. Additionally, we adjust the maximum input and output lengths for each stage based on the dataset's text statistics.

    \item For \textbf{LLM Direct Inference}, we adopt two distinct categories of prompt templates: (1) advanced prompts that enhance the reasoning capabilities of LLMs, and (2) prompts enriched with structural information. These templates are illustrated in Appendix \ref{sec:zeroshot_prompt} and strictly adhere to the zero-shot setting.

    \item For \textbf{ZeroG}, we adhere to its original parameter configurations by setting $k=2$, the number of SGC iterations to $10$, and the \texttt{learning\_rate} to $1e-4$. In experiments involving \textbf{GFMs}, the intra-domain training mode utilizes the following source-target pairs: arXiv $\rightarrow$ Cora, arXiv $\rightarrow$ WikiCS, Reddit $\rightarrow$ Instagram, and Computer $\rightarrow$ Photo. 
\end{itemize}


\subsection{Distinct Features}\label{sec:distinct_llmnodebed}
A fair comparison necessitates a benchmark that evaluates all methods using consistent dataloaders, learning paradigms, backbone architectures, and implementation codebases. Our LLMNodeBed carefully follows these guidelines to support systematic and comprehensive evaluation of LLM-based node classification algorithms. Unlike existing benchmarks \cite{Li2024GLBench}, which primarily rely on each algorithm's official implementation, LLMNodeBed distinguishes itself in the following ways:

\begin{itemize}
    \item \textbf{Systematical Implementation: }We consolidate common components (e.g., DataLoader, Evaluation, Backbones) across algorithms to avoid code redundancy and enable fair comparisons and streamlined deployment. For example, several official implementations involve extensive code snippets, and we have produced cleaner, more streamlined versions that enhance both readability and usability. This systematic approach makes LLMNodeBed easily extendable to new datasets or algorithms.

    \item  \textbf{Flexible Selection of Backbones: } LLMNodeBed incorporates a diverse selection of GNNs, LMs, and LLMs, which can be seamlessly integrated as components in baseline methods. 
    \begin{itemize}
        \item \textbf{GNNs: }Our framework supports a wide range of variants, including GCN \cite{kipf2017GCN}, GraphSAGE \cite{hamilton2017SAGE}, GAT \cite{velickovic2018GAT}, GIN \cite{xu2018GIN}, and Graph Transformers \cite{Shi2020GraphTransformer}. These GNNs can be customized with various layers and embedding dimensions.
        \item \textbf{LMs and LLMs: }Open-source models can be easily loaded via the Transformers library\footnote{\href{https://huggingface.co/docs/transformers}{https://huggingface.co/docs/transformers}}. In our experiments, we primarily utilize SenBERT-66M \cite{reimers-2019-sentence-bert}, RoBERTa-355M \cite{Liu2019roberta}, Qwen2.5-Series \cite{Yang2024Qwen2TR}, Mistral-7B \cite{Jiang2023Mistral7B}, and LLaMA3.1-8B \cite{llama3modelcard}. For close-source LLMs, we have formatted the invocation functions of DeepSeek-Chat \cite{Shao2024DeepSeekV2AS} and GPT-4o \cite{Achiam2023GPT4TR}. Additionally, LLMNodeBed allows users to specify and invoke any LM or LLM of their choice, providing flexibility for diverse research needs.
    \end{itemize}

    \item \textbf{Robust Evaluation Protocols: }LLMNodeBed incorporates comprehensive hyperparameter tuning and design space exploration to fully leverage the potential of the algorithms. For instance, recent research \cite{luo2024classic} highlights that classic GNNs remain strong baselines for node classification tasks, especially when the design space is expanded through techniques like residual connections, jumping knowledge, and selectable batch normalization. LLMNodeBed supports these enhancements, enabling the full utilization of GNNs. Furthermore, we conduct multiple experimental runs to enhance reliability and account for variability, which was often overlooked in previous studies.

\end{itemize}


\clearpage
\newpage
