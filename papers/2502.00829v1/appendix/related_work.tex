\section{Related Works and Discussion}\label{sec:related_works}

In this section, we present a comprehensive taxonomy of node classification methods, ranging from classic approaches to those leveraging LLMs. 


\subsection{Classic Methods}

Early approaches for node classification tasks relied on structural techniques such as Laplacian regularization \cite{belkin2006manifold}, graph embeddings \cite{yang2016revisiting}, and label propagation \cite{zhu2003semi}. These methods infer node labels by leveraging the connectivity and similarity among nodes within the graph. 

Over the past decade, GNNs have emerged as the dominant paradigm for node classification, demonstrating superior performance across various benchmarks \cite{kipf2017GCN, velickovic2018GAT, hamilton2017SAGE, xu2018GIN}. GNNs enhance node representations by aggregating and transforming feature information from their local neighborhoods. Formally, given a graph's feature matrix $\bm{X}$ and structure $\mathcal{E}$, a GNN produces the predicted label matrix as $\bm{Y} = \text{GNN}_{\Theta}(\bm{X}, \mathcal{E}) \in \mathbb{R}^{|\mathcal{V}| \times C}$, where $C$ is the number of classes, and $\Theta$ represents the learned parameters. 

Beyond structural methods, node classification can also be approached using LMs by treating each node as a text entity. Fine-tuning LMs \cite{Liu2019roberta, reimers-2019-sentence-bert, Wang2022e5-large} allows these models to map textual information directly to node labels, leveraging their strong language understanding capabilities to predict labels. To harness the complementary strengths of GNNs and LMs, i.e., structural and textual information, hybrid LM+GNN architectures have been developed \cite{jin2023patton, zhao2022GLEM, Wen2023G2P2}. These models integrate LM-encoded textual features with GNN-processed structural features, enhancing node classification performance by combining both modalities. 

% However, we exclude these methods from our discussion of LLMs, as they do not leverage LLMs and have shown inferior performance and efficiency in previous studies \cite{he2023TAPE, Zhu2024ENGINE}. We distinguish between LMs and LLMs, as LLMs typically have significantly more parameters (i.e., billion-scale) and possess advanced generative and reasoning abilities that set them apart from smaller counterparts. 

\subsection{LLM-based Methods}
\textbf{LLM as Encoder: }LLMs possess an extensive number of parameters, enabling them to generate highly expressive representations. These representations can replace shallow node embeddings, promising to enhance expressiveness and improve the performance of downstream task. A notable approach is ENGINE \cite{Zhu2024ENGINE}, which utilizes hidden embeddings from LLMs to construct node embeddings. ENGINE integrates these embeddings with GNNs to propagate and update representations. Specifically, it aggregates hidden embeddings from each LLM layer that processes a node's text and incorporates them into a cascaded GNN structure.


\textbf{LLM as Reasoner: }A significant advantage of LLMs is their reasoning and planning capabilities \cite{luo2024rog, wu2024graph}. Guided by carefully crafted prompts, LLMs can intelligently execute a variety of downstream tasks. Motivated by this strength, \citet{he2023TAPE} introduced TAPE, a method that leverages LLM as Reasoner for node classification. Specifically, TAPE prompts the LLM to generate predictions along with a chain-of-thought reasoning process that includes explanations, denoted as $s_v^{\text{exp}} = \text{LLM}(s_v^{\text{orig}}, p)$, where $p$ denotes the textual prompt, and $s_v^{\text{orig}}$ and $s_v^{\text{exp}}$ represent the original and generated texts for node $v$, respectively. Both the original and generated texts are processed by an LM to produce embeddings as $\bm{x}_v^{\text{orig}} = \text{LM}(s_v^{\text{orig}})$ and $\bm{x}_v^{\text{exp}} = \text{LM}(s_v^{\text{exp}})$, which are subsequently processed by GNNs for the classification task as: 

\begin{equation*}
    \bm{Y} = \text{Ensemble}( \text{GNN}_{\Theta_1}(\bm{X}^{\text{orig}}, \mathcal{E}),  \text{GNN}_{\Theta_2}(\bm{X}^{\text{exp}}, \mathcal{E})).
\end{equation*}

Subsequent works have enhanced the reliability of LLM reasoning. For example, KEA \cite{chen2024exploring} prompts LLMs to extract and explain specific technical terms from a node's original text instead of making direct predictions, thereby mitigating potential misguidance. Overall, the LLM-as-Reasoner paradigm leverages LLMs' reasoning capabilities to generate reliable explanations, thus augmenting the original graph data.


\textbf{LLM as Predictor: }LLMs' strong reasoning abilities make them effective for direct downstream classification tasks. In the LLM-as-Predictor paradigm, a node's textual and structural information, along with task-specific instructions, are tokenized and input into an LLM for prediction. A notable method in this category is LLaGA \cite{chen23llaga}. Firstly, the original text $s_v$ of node $v$ is encoded via LM as $\bm{x}_v^{\text{LM}} = \text{LM}(s_v)$. Then, a parameter-free GNN, i.e., SGC \cite{Wu2019SimplifyingGC}, updates the node embeddings based on the graph structure, initializing with $\bm{h}_v^{(0)} = \bm{x}_v^{\text{LM}}$. The embeddings from each SGC layer are concatenated into $\bm{H}_v = [ \bm{h}_v^{(0)}, \ldots, \bm{h}_v^{(L)} ] $ and further projected into the LLM's dimensionality using a projection layer $\phi_{\theta}$. These projected embeddings are then combined with tokenized instructions $\bm{T}$ and input into the LLM to generate the predicted label as:

\begin{equation*}
    \ell_v = \text{LLM}( [  \phi_{\theta}(\bm{H}_v ) \; \| \;  \bm{T}  ] ).
\end{equation*}

In the LLaGA framework, only the parameters of the projection layer are tuned, utilizing the next-token-prediction loss based on ground-truth labels and generated outputs. GraphGPT employs a more complex framework with three distinct pre-training and instruction tuning stages. Other LLM-as-Predictor methods \cite{chai2023graphllm, perozzi2024graphtoken, Kong2024GOFAAG, Huang2024GraphAdapter, Zhao2023GraphTextGR, Ji2024NTLLMAN} share similar frameworks with LLaGA but vary in integration approaches, training objectives, and tackled tasks.


\subsection{Zero-shot Learning with LLMs}
Supervised learning approaches, which rely on labeled data, often struggle to keep pace with the rapid evolution of real-world graph data. Zero-shot learning methods address this limitation by enabling models to generalize to unseen data without requiring explicit labels. These methods can be broadly categorized into two approaches: LLM Direct Inference and GFMs.

\textbf{LLM Direct Inference} involves using LLMs to make predictions directly on the node's information through various prompt engineering techniques. Advanced prompt templates for reasoning tasks include Chain-of-Thought \cite{Wei2022ChainOT}, ReAct \cite{Yao2022ReActSR}, and Tree-of-Thought \cite{yao2023tree}. Besides, structural information can also be integrated into extended prompts \cite{tang2023graphgpt, wang2023can, Huang2023CanLE}, enriching the input provided to LLMs and facilitating more accurate predictions.

On the other hand, \textbf{GFMs} are foundation models pre-trained on extensive graph corpora to achieve general graph intelligence. Approaches such as ZeroG \cite{li2024zerog} and OFA \cite{liu2023one} fine-tune LMs or GNNs on multiple graphs, enabling these models to generalize to unseen graph datasets without extensive retraining. There also exist other zero-shot learning methods utilizing LLMs. For example, \citet{chen2024label} leverage LLMs as annotators to generate pseudo-labels for GNN training, enabling classification tasks. These approaches are not considered in this work, as our focus is primarily on LLMs directly solving node classification tasks in zero-shot scenarios.


\subsection{Benchmarks of LLMs for Graphs}
In addition to developments in node classification algorithms, we discuss existing benchmarks that leverage LLMs for graph-related tasks. These benchmarks can be categorized based on the type of tasks they address.

The first category primarily utilizes LLMs for basic graph reasoning tasks, e.g., shortest path and connectivity. For instance, NLGraph \cite{wang2023can} is a pioneering benchmark that encompasses eight different graph reasoning tasks presented in natural language. LLM4DyG \cite{zhang2023LLM4DyG} further extends these reasoning tasks to dynamic graph settings. GraphArena \cite{tang2024GraphArena} deals with more complex graph computational problems, with the complexity of tasks ranging from polynomial to NP-Complete like the Traveling Salesman Problem.  ProGraph \cite{li2024prograph} evaluates the scalability of LLMs by handling large graphs with up to $10^6$ nodes, necessitating the use of Python APIs for graph analysis rather than relying solely on direct reasoning of LLMs. Additionally, \citet{dai2024llm4pattern} investigates whether LLMs can recognize graph patterns, e.g., triangles or squares, based on terminological or topological descriptions.

The second category focuses on the potential of LLMs for node classification tasks. While numerous surveys discuss the progress in this area \cite{li2023survey, jin@llmgraph}, benchmarks that systematically evaluate LLM-based node classification methods remain limited. In the preliminary work by \citet{chen2024exploring}, the exploration is confined to a narrow range of LLM-as-Encoder and LLM-as-Reasoner approaches, primarily focusing on a limited set of language models. GLBench \cite{Li2024GLBench} emerges as the first comprehensive benchmark for LLM-based node classification, offering consistent data splits to evaluate representative methods in both semi-supervised and zero-shot settings. However, variations in backbone models and implemented codebases impede fair and rigorous comparisons. 

Our benchmark, LLMNodeBed, distinguishes itself from existing benchmarks like GLBench by standardizing implementations of baselines, extending learning paradigms and datasets to encompass more real-world contexts, and incorporating influential factors like model type and size, homophily, and prompt design. This comprehensive approach provides more practical guidelines for effectively leveraging LLMs to enhance node classification tasks. 


\clearpage
\newpage
