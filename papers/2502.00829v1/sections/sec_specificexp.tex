\section{Fine-grained Analysis Within Each Category}
In this section, we present empirical results within each category. For LLM-as-Encoder, we explore the conditions under which LLMs outperform traditional LMs. Additionally, we examine how key components (e.g., model type and size) influence the effectiveness of LLM-as-Reasoner and LLM-as-Predictor. 

\subsection{LLM-as-Encoder: Compared with LMs}\label{exp:encoder_comp}
\input{tables/tape_llm}


\textbf{Motivation and Settings: }Both LLMs and small-scale LMs can encode nodes' associated texts. This raises the question: When do LLMs surpass LMs as encoders? To address this, we evaluate various methods using node features derived from LLMs and LMs, observing the resulting performance differences. For LMs, we select SenBERT-66M \cite{reimers-2019-sentence-bert} and RoBERTa-355M \cite{Liu2019roberta}. For LLMs, we choose Qwen2.5-3B \cite{Yang2024Qwen2TR} and Mistral-7B \cite{Jiang2023Mistral7B}. The considered methods include: (1) \textbf{MLP}, which solely utilizes node features as input to predict labels without incorporating any graph information, (2) \textbf{GCN}, and (3) \textbf{GraphSAGE}. For each method, we input node features initialized from various LM or LLM backbones while keeping all other components consistent.  From the results shown in Table \ref{tab:encoder_comp} and Table \ref{tab:encoder_comp_fullysupervised} in the Appendix, we can observe that: 


\textbf{Takeaway 8: LLM-as-Encoder significantly outperforms LMs in heterophilic graphs.} In heterophilic datasets such as Reddit, LLM-based encoders achieve 2\% - 8\% higher accuracy than their LM counterparts. This performance gap is most evident with the MLP method (4\%â€“8\%). The performance gain is less obvious in homophilic settings. We can also leverage the mutual information \eqref{eq:mutual_info} to give theoretical insights. In homophilic graphs, edges often connect nodes with the same labels, whereas this does not hold in heterophilic graphs. Therefore, in homophilic graphs, the first term in \eqref{eq:mutual_info} dominates, and the room for a better encoder, e.g., LLM, to improve is limited. 


\input{tables/llaga_llm_s}
\input{tables/llaga_llm_s_f1}




\subsection{LLM-as-Reasoner: Impact of LLM Reasoning Capabilities}

\textbf{Motivation and Settings: }In the LLM-as-Reasoner paradigm, as the language model should generate reasoning texts, the adopted language models should be auto-regressive and the model size should be large. To investigate how the advanced reasoning capabilities of LLMs influence overall performance, we replace the default Mistral-7B model in the TAPE method with the more powerful GPT-4o model, keeping all other components unchanged. 

\textbf{Results and Analysis: } As presented in Table \ref{tab:tape_llm_semi} (semi-supervised settings) and Table \ref{tab:tape_llm_fully} (supervised settings), the effectiveness of LLM-as-Reasoner methods positively correlates with the strength of the underlying LLMs. In semi-supervised settings, TAPE utilizing GPT-4o consistently outperforms its Mistral-7B counterpart, achieving performance gains of up to 4\% on the Pubmed dataset. However, in supervised scenarios, the performance gap between GPT-4o and Mistral-7B narrows. This reduction is attributed to the abundance of labeled data, which increases the mutual information $I(\mathcal{E}; \mathcal{Y}_l)$ in \eqref{eq:mutual_info}. Consequently, the dependency on node attributes decreases, thereby diminishing the relative advantages of more powerful LLMs. 

Based on these findings, we recommend that when abundant supervision is available, practitioners may opt for open-source LLMs instead of more powerful and costlier models for the LLM-as-Reasoner method. This practice can achieve comparable performance without incurring additional costs.

\subsection{LLM-as-Predictor: Sensitivity to LLM Backbones}

\textbf{Motivation and Settings: } For most LLM-as-Predictor methods, only open-source LLMs are compatible. Given the diverse choices and varying scales of these models, we aim to investigate the sensitivity of performance to different LLM backbones. This examination seeks to identify potential scaling laws and determine which LLMs excel at the node classification task. Therefore, we choose the best predictor method LLaGA as the baseline, include models of different sizes within the same series, i.e., Qwen2.5-series \cite{Yang2024Qwen2TR}. Additionally, we consider similar-scaled models to identify the most suitable for this task, including Qwen2.5-7B, Mistral-7B, and LLaMA3.1-8B. All experiments maintain consistency by only varying the backbone LLMs while keeping other components, training configurations, and hyperparameters unchanged.

\textbf{Results and Analysis: } \textbf{(1) Scaling within the same series: }Comparing Qwen-3B to Qwen-32B (performance shown in Tables \ref{tab:llaga_llm_s} and \ref{tab:llaga_llm_s_f1}, efficiency in Table \ref{tab:qwen_cost}, and performance trends in Figures \ref{fig:llaga_scaling} and \ref{fig:llaga_scaling_s} in the Appendix), we observe that performance generally improves with larger model sizes. However, beyond Qwen-7B and Qwen-14B, the performance gains become marginal while training and inference times increase significantly. For instance, Qwen-32B takes over 200 milliseconds per sample for inference, which is five times longer than Qwen-7B. Therefore, Qwen-7B or Qwen-14B are recommended as practical choices balancing performance and efficiency. \textbf{(2) Model selection at similar scales: }When comparing models of similar sizes (Tables \ref{tab:llaga_llm_s} and \ref{tab:llaga_llm_s_f1}, and Table \ref{tab:llaga_llm} in the Appendix), Mistral-7B outperforms other LLMs of comparable scale. Its superior performance makes Mistral-7B the recommended backbone LLM for node classification tasks.


