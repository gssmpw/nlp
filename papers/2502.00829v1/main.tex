\documentclass{article}

\usepackage{microtype}
% \usepackage{subfigure}
\usepackage{booktabs} 
\usepackage{hyperref}
\usepackage{tabularx}
\newcommand{\theHalgorithm}{\arabic{algorithm}}

\usepackage[accepted]{icml2025}
% \usepackage{icml2025}
\usepackage{amsmath}
\usepackage{amssymb}
\usepackage{mathtools}
\usepackage{amsthm}
\usepackage{graphicx}
\usepackage{caption}
\usepackage{subcaption}
\usepackage{wrapfig}
\usepackage{bm}
\usepackage{bbm}
\usepackage{url}
\usepackage{multirow}
\usepackage{enumitem}
\usepackage{diagbox}
\usepackage{color,colortbl}
\usepackage{xcolor}
\usepackage{makecell}
\usepackage{tcolorbox}
\definecolor{COLOR_MEAN}{HTML}{f0f0f0}

% if you use cleveref..
\usepackage[capitalize,noabbrev]{cleveref}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% THEOREMS
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\theoremstyle{plain}
\newtheorem{theorem}{Theorem}[section]
\newtheorem{proposition}[theorem]{Proposition}
\newtheorem{lemma}[theorem]{Lemma}
\newtheorem{corollary}[theorem]{Corollary}
\theoremstyle{definition}
\newtheorem{definition}[theorem]{Definition}
\newtheorem{assumption}[theorem]{Assumption}
\theoremstyle{remark}
\newtheorem{remark}[theorem]{Remark}

% Todonotes is useful during development; simply uncomment the next line
%    and comment out the line below the next line to turn off comments
%\usepackage[disable,textsize=tiny]{todonotes}
\usepackage[textsize=tiny]{todonotes}


% The \icmltitle you define below is probably too long as a header.
% Therefore, a short form for the running title is supplied here:
\icmltitlerunning{A Comprehensive Analysis on LLM-based Node Classification Algorithms}

\begin{document}

\twocolumn[
\icmltitle{A Comprehensive Analysis on LLM-based Node Classification Algorithms}

% It is OKAY to include author information, even for blind
% submissions: the style file will automatically remove it for you
% unless you've provided the [accepted] option to the icml2025
% package.

% List of affiliations: The first argument should be a (short)
% identifier you will use later to specify author affiliations
% Academic affiliations should list Department, University, City, Region, Country
% Industry affiliations should list Company, City, Region, Country

% You can specify symbols, otherwise they are numbered in order.
% Ideally, you should not use this facility. Affiliations will be numbered
% in order of appearance and this is the preferred way.
\icmlsetsymbol{equal}{*}

\begin{icmlauthorlist}
\icmlauthor{Xixi Wu}{cuhk}
\icmlauthor{Yifei Shen}{msra}
\icmlauthor{Fangzhou Ge}{cuhk}
\icmlauthor{Caihua Shan}{msra}
\icmlauthor{Yizhu Jiao}{uiuc}
\icmlauthor{Xiangguo Sun}{cuhk}
\icmlauthor{Hong Cheng}{cuhk}
%\icmlauthor{}{sch}
%\icmlauthor{}{sch}
\end{icmlauthorlist}

\icmlaffiliation{cuhk}{The Chinese University of Hong Kong}
\icmlaffiliation{msra}{Microsoft Research Asia}
\icmlaffiliation{uiuc}{University of Illinois Urbana-Champaign}

\icmlcorrespondingauthor{Yifei Shen}{\texttt{yifeishen@microsoft.com}}
\icmlcorrespondingauthor{Hong Cheng}{\texttt{hcheng@se.cuhk.edu.hk}}


% You may provide any keywords that you
% find helpful for describing your paper; these are used to populate
% the "keywords" metadata in the PDF but will not be shown in the document
\icmlkeywords{Large Language Models, Graph Neural Networks, Node Classification}

\vskip 0.3in
]

% this must go after the closing bracket ] following \twocolumn[ ...

% This command actually creates the footnote in the first column
% listing the affiliations and the copyright notice.
% The command takes one argument, which is text to display at the start of the footnote.
% The \icmlEqualContribution command is standard text for equal contribution.
% Remove it (just {}) if you do not need this facility.

% \printAffiliationsAndNotice{}  % leave blank if no need to mention equal contribution
\printAffiliationsAndNotice{} % otherwise use the standard text.

\begin{abstract}
Node classification is a fundamental task in graph analysis, with broad applications across various fields. Recent breakthroughs in Large Language Models (LLMs) have enabled LLM-based approaches for this task. Although many studies demonstrate the impressive performance of LLM-based methods, the lack of clear design guidelines may hinder their practical application.  In this work, we aim to establish such guidelines through a fair and systematic comparison of these algorithms. As a first step, we developed LLMNodeBed, a comprehensive codebase and testbed for node classification using LLMs. It includes ten datasets, eight LLM-based algorithms, and three learning paradigms, and is designed for easy extension with new methods and datasets. Subsequently, we conducted extensive experiments, training and evaluating over 2,200 models, to determine the key settings (e.g., learning paradigms and homophily) and components (e.g., model size) that affect performance. Our findings uncover eight insights, e.g., (1) LLM-based methods can significantly outperform traditional methods in a semi-supervised setting, while the advantage is marginal in a supervised setting; (2) Graph Foundation Models can beat open-source LLMs but still fall short of strong LLMs like GPT-4o in a zero-shot setting. We hope that the release of LLMNodeBed, along with our insights, will facilitate reproducible research and inspire future studies in this field. Codes and datasets are released at \href{https://llmnodebed.github.io/}{\texttt{https://llmnodebed.github.io/}}.


\end{abstract}

\input{sections/sec_intro}
\input{sections/sec_llmnodebed}
\input{sections/sec_mainexp}
\input{sections/sec_specificexp}

\section{Conclusion}

This paper provides guidelines for leveraging LLMs to enhance node classification tasks across diverse real-world applications. We introduce LLMNodeBed, a codebase and testbed for systematic comparisons, featuring ten datasets, eight LLM-based algorithms, and three learning paradigms. Through extensive experiments involving 2,200 models, we uncover key insights: In supervised settings, each category offers unique advantages, but LLM-based approaches deliver marginal improvements over classic methods when ample supervision is available. In zero-shot scenarios, directing powerful LLMs to perform inference with integrated structural context yields the best performance.

Our findings offer practical guidance for practitioners applying LLMs to node classification tasks and highlight research gaps, e.g., the limited exploration of LLMs on heterophilic graphs and the scarcity of such text-rich datasets. We intend to address these gaps in future work. We hope that LLMNodeBed will inspire and serve as a valuable toolkit for further research.

\clearpage
\newpage

\section*{Impact Statement}
This paper presents work whose goal is to advance the field of Machine Learning. There are many potential societal consequences of our work, none of which we feel must be specifically highlighted here.



\bibliography{reference}
\bibliographystyle{icml2025}



%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% APPENDIX
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\newpage
\appendix
\onecolumn

\input{appendix/related_work}
\input{appendix/prompt}
\input{appendix/dataset+imple}
\input{appendix/mainexp}
\input{appendix/role_exp}
\input{appendix/cost_analysis}

\end{document}

