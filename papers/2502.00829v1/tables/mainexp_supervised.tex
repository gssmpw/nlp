\begin{table*}[!t]
    \centering
    \caption{\textbf{Performance comparison under semi-supervised and supervised settings with Accuracy ($\%$) reported.} \\\small{The \colorbox{orange!25}{\textbf{best}} and \colorbox{orange!10}{second-best} results are highlighted. Results of Macro-F1 are shown in Table \ref{tab:mainexp_f1} in the Appendix. LLM\textsubscript{IT} on the arXiv dataset requires 30+ hours per run, preventing multiple executions.}} 
    \vspace*{-8pt}
    \resizebox{\linewidth}{!}{
    \begin{tabular}{cc|cccccccccc}
      \toprule
     \rowcolor{COLOR_MEAN} \multicolumn{2}{c|}{\textbf{Semi-supervised}}  & \textbf{Cora} & \textbf{Citeseer} & \textbf{Pubmed} & \textbf{WikiCS} & \textbf{Instagram} & \textbf{Reddit} & \textbf{Books} & \textbf{Photo} & \textbf{Computer} & \textbf{Avg.} \\ \midrule
       \multirow{5}{*}{\textbf{Classic}} & {GCN\tiny{ShallowEmb}} & 82.30$_{\pm \text{0.19}}$ & 70.55$_{\pm \text{0.32}}$ & \cellcolor{orange!10} 78.94$_{\pm \text{0.27}}$ & 79.86$_{\pm \text{0.19}}$ & 63.50$_{\pm \text{0.11}}$ & 61.44$_{\pm \text{0.38}}$ & 68.79$_{\pm \text{0.46}}$ & 69.25$_{\pm \text{0.81}}$ & 71.44$_{\pm \text{1.19}}$ & 71.79 \\ 
        & SAGE\tiny{ShallowEmb} & 82.27$_{\pm \text{0.37}}$ & 69.56$_{\pm \text{0.43}}$ & 77.88$_{\pm \text{0.44}}$ & 79.67$_{\pm \text{0.25}}$ & 63.57$_{\pm \text{0.10}}$ & 56.65$_{\pm \text{0.33}}$ & 72.01$_{\pm \text{0.33}}$& 78.50$_{\pm \text{0.15}}$ & 81.43$_{\pm \text{0.27}}$ & 73.50 \\ 
         & {GAT\tiny{ShallowEmb}} & 81.30$_{\pm \text{0.67}}$ & 69.94$_{\pm \text{0.74}}$ & 78.49$_{\pm \text{0.70}}$ & 79.99$_{\pm \text{0.65}}$ & 63.56$_{\pm \text{0.04}}$ & 60.60$_{\pm \text{1.17}}$ & 74.35$_{\pm \text{0.35}}$ & 80.40$_{\pm \text{0.45}}$ & 83.39$_{\pm \text{0.22}}$ & 74.67 \\ 
         & SenBERT-66M & 66.66$_{\pm \text{1.42}}$ & 60.52$_{\pm \text{1.62}}$ & 36.04$_{\pm \text{2.92}}$ & 77.77$_{\pm \text{0.75}}$ & 59.00$_{\pm \text{1.17}}$ & 56.05$_{\pm \text{0.41}}$ & 83.68$_{\pm \text{0.19}}$ & 73.89$_{\pm \text{0.31}}$ & 70.76$_{\pm \text{0.15}}$ & 64.93 \\
         & {RoBERTa-355M} & 72.24$_{\pm \text{1.14}}$ & 66.68$_{\pm \text{2.03}}$ & 42.32$_{\pm \text{1.56}}$ & 76.81$_{\pm \text{1.04}}$ & 63.52$_{\pm \text{0.44}}$ & 59.27$_{\pm \text{0.34}}$ & \cellcolor{orange!10} 84.62$_{\pm \text{0.16}}$ & 74.79$_{\pm \text{1.13}}$ & 72.31$_{\pm \text{0.37}}$ & 68.06 \\ \midrule
         
        \multirow{2}{*}{\textbf{Encoder}} 
       & $\text{GCN}_{\text{LLMEmb}}$ & 83.33$_{\pm \text{0.75}}$ & 71.39$_{\pm \text{0.90}}$ & 78.71$_{\pm \text{0.45}}$ & \cellcolor{orange!10} 80.94$_{\pm \text{0.16}}$ & \cellcolor{orange!25} \textbf{67.49$_{\pm \text{0.43}}$} & 68.65$_{\pm \text{0.75}}$ &  83.03$_{\pm \text{0.34}}$ & \cellcolor{orange!10} 84.84$_{\pm \text{0.47}}$ & \cellcolor{orange!10} 88.22$_{\pm \text{0.16}}$ & \cellcolor{orange!25} \textbf{78.51} \\ 
       & ENGINE & \cellcolor{orange!25} \textbf{84.22$_{\pm \text{0.46}}$} & \cellcolor{orange!25} \textbf{72.14$_{\pm \text{0.74}}$}
        & 77.84$_{\pm \text{0.27}}$ & 80.94$_{\pm \text{0.19}}$ & \cellcolor{orange!10} 67.14$_{\pm \text{0.46}}$ & \cellcolor{orange!10} 69.67$_{\pm \text{0.16}}$ & 82.89$_{\pm \text{0.14}}$ & 84.33$_{\pm \text{0.57}}$ & 86.42$_{\pm \text{0.23}}$ & 78.40  \\ \midrule
        
       \textbf{Reasoner} & TAPE &  \cellcolor{orange!10} 84.04$_{\pm \text{0.24}}$ & \cellcolor{orange!10} 71.87$_{\pm \text{0.35}}$ & 78.61$_{\pm \text{1.23}}$ & \cellcolor{orange!25} \textbf{81.94$_{\pm \text{0.16}}$} & 66.07$_{\pm \text{0.10}}$ & 62.43$_{\pm \text{0.47}}$ & \cellcolor{orange!25} \textbf{84.92$_{\pm \text{0.26}}$} & \cellcolor{orange!25} \textbf{86.46$_{\pm \text{0.12}}$} & \cellcolor{orange!25} \textbf{89.52$_{\pm \text{0.04}}$} & \cellcolor{orange!10} 78.43  \\  \midrule
       
      \multirow{3}{*}{\textbf{Predictor}} & $\text{LLM}_{\text{IT}}$  &  67.00$_{\pm \text{0.16}}$ & 54.26$_{\pm \text{0.22}}$ & \cellcolor{orange!25} \textbf{80.99$_{\pm \text{0.43}}$} & 75.02$_{\pm \text{0.16}}$ & 41.83$_{\pm \text{0.47}}$ & 54.09$_{\pm \text{1.02}}$ & 80.92$_{\pm \text{1.38}}$ & 71.28$_{\pm \text{1.81}}$ & 66.99$_{\pm \text{2.02}}$ & 65.76 \\ 
       & GraphGPT & 64.72$_{\pm \text{1.50}}$ & 64.58$_{\pm \text{1.55}}$ & 70.34$_{\pm \text{2.27}}$ & 70.71$_{\pm \text{0.37}}$ & 62.88$_{\pm \text{2.14}}$ & 58.25$_{\pm \text{0.37}}$ & 81.13$_{\pm \text{1.52}}$ & 77.48$_{\pm \text{0.78}}$ & 80.10$_{\pm \text{0.76}}$ & 70.02 \\ 
       & LLaGA & 78.94$_{\pm \text{1.14}}$ & 62.61$_{\pm \text{3.63}}$ & 65.91$_{\pm \text{2.09}}$ & 76.47$_{\pm \text{2.20}}$ & 65.84$_{\pm \text{0.72}}$ &  \cellcolor{orange!25} \textbf{70.10$_{\pm \text{0.38}}$} & 83.47$_{\pm \text{0.45}}$ & 84.44$_{\pm \text{0.90}}$ & 87.82$_{\pm \text{0.53}}$  & 75.07 \\
       \bottomrule
    \end{tabular}
    }

   \vspace*{5pt}
    \resizebox{\linewidth}{!}{
    \begin{tabular}{cc|ccccccccccc}
      \toprule
      \rowcolor{COLOR_MEAN} \multicolumn{2}{c|}{\textbf{Supervised}} & \textbf{Cora} & \textbf{Citeseer} & \textbf{Pubmed} & \textbf{arXiv} & \textbf{WikiCS} & \textbf{Instagram} & \textbf{Reddit} & \textbf{Books} & \textbf{Photo} & \textbf{Computer} & \textbf{Avg.} \\ \midrule

     \multirow{5}{*}{\textbf{Classic}} & {GCN\tiny{ShallowEmb}} & 87.41$_{\pm \text{2.08}}$ & 75.74$_{\pm \text{1.20}}$ & 89.01$_{\pm \text{0.59}}$ & 71.39$_{\pm \text{0.28}}$ & 83.67$_{\pm \text{0.63}}$ & 63.94$_{\pm \text{0.61}}$ & 65.07$_{\pm \text{0.38}}$ & 76.94$_{\pm \text{0.26}}$ & 73.34$_{\pm \text{1.34}}$ & 77.16$_{\pm \text{3.80}}$ & 76.37 \\ 
     & {SAGE\tiny{ShallowEmb}} & 87.44$_{\pm \text{1.74}}$ & 74.96$_{\pm \text{1.20}}$ & 90.47$_{\pm \text{0.25}}$ & 71.21$_{\pm \text{0.18}}$ & 84.86$_{\pm \text{0.91}}$ & 64.14$_{\pm \text{0.47}}$ & 61.52$_{\pm \text{0.60}}$ & 79.40$_{\pm \text{0.45}}$ & 84.59$_{\pm \text{0.32}}$ & 87.77$_{\pm \text{0.34}}$ & 78.64 \\

     & {GAT\tiny{ShallowEmb}} & 86.68$_{\pm \text{1.12}}$ & 73.73$_{\pm \text{0.94}}$ & 88.25$_{\pm \text{0.47}}$ & 71.57$_{\pm \text{0.25}}$ & 83.94$_{\pm \text{0.61}}$ & 64.93$_{\pm \text{0.75}}$ & 64.16$_{\pm \text{1.05}}$ & 80.61$_{\pm \text{0.49}}$ & 84.84$_{\pm \text{0.69}}$ & 88.32$_{\pm \text{0.24}}$ & 78.70 \\ 
     & SenBERT-66M & 79.61$_{\pm \text{1.40}}$ & 74.06$_{\pm \text{1.26}}$ & \cellcolor{orange!10} 94.47$_{\pm \text{0.33}}$ & 72.66$_{\pm \text{0.24}}$ & 86.51$_{\pm \text{0.86}}$ & 60.11$_{\pm \text{0.93}}$ & 58.70$_{\pm \text{0.54}}$ & \cellcolor{orange!10} 85.99$_{\pm \text{0.58}}$ & 77.72$_{\pm \text{0.35}}$ & 74.22$_{\pm \text{0.21}}$ & 76.40 \\ 
     & {RoBERTa-355M} & 83.17$_{\pm \text{0.84}}$ & 75.90$_{\pm \text{1.69}}$ & \cellcolor{orange!25} \textbf{94.84$_{\pm \text{0.06}}$} & 74.12$_{\pm \text{0.12}}$ & \cellcolor{orange!25}\textbf{87.47$_{\pm \text{0.83}}$} & 63.75$_{\pm \text{1.13}}$ & 60.61$_{\pm \text{0.24}}$ & 
      \cellcolor{orange!25} \textbf{86.65$_{\pm \text{0.38}}$} & 79.45$_{\pm \text{0.37}}$ & 75.76$_{\pm \text{0.30}}$ & 78.17 \\ \midrule
      
      \multirow{2}{*}{\textbf{Encoder}} & $\text{GCN}_{\text{LLMEmb}}$ & 
      \cellcolor{orange!25} \textbf{88.15$_{\pm \text{1.79}}$} & \cellcolor{orange!10} 76.45$_{\pm \text{1.19}}$ & 88.38$_{\pm \text{0.68}}$ & 74.39$_{\pm \text{0.31}}$ & 84.78$_{\pm \text{0.86}}$ & 68.27$_{\pm \text{0.45}}$ & 70.65$_{\pm \text{0.75}}$ & 84.23$_{\pm \text{0.20}}$ & 86.07$_{\pm \text{0.20}}$ & 89.52$_{\pm \text{0.31}}$ & 81.09 \\ 
      & ENGINE & 87.00$_{\pm \text{1.60}}$ & 75.82$_{\pm \text{1.52}}$ & 90.08$_{\pm \text{0.16}}$ & 74.69$_{\pm \text{0.36}}$ & 85.44$_{\pm \text{0.53}}$ & \cellcolor{orange!10} 68.87$_{\pm \text{0.25}}$ & \cellcolor{orange!25} \textbf{71.21$_{\pm \text{0.77}}$} & 84.09$_{\pm \text{0.09}}$ & 86.98$_{\pm \text{0.06}}$ & 89.05$_{\pm \text{0.13}}$ & 81.32 \\  \midrule
      \textbf{Reasoner} & TAPE &  \cellcolor{orange!10} 88.05$_{\pm \text{1.76}}$ & 76.45$_{\pm \text{1.60}}$ & 93.00$_{\pm \text{0.13}}$ & 74.96$_{\pm \text{0.14}}$ & \cellcolor{orange!10} 87.11$_{\pm \text{0.66}}$ & 68.11$_{\pm \text{0.54}}$ & 66.22$_{\pm \text{0.83}}$ &  85.95$_{\pm \text{0.59}}$ & \cellcolor{orange!25} \textbf{87.72$_{\pm \text{0.28}}$} & \cellcolor{orange!25} \textbf{90.46$_{\pm \text{0.18}}$} & \cellcolor{orange!25}\textbf{81.80} \\  \midrule
      \multirow{3}{*}{\textbf{Predictor}} & $\text{LLM}_{\text{IT}}$ & 71.93$_{\pm \text{1.47}}$ & 60.97$_{\pm \text{3.97}}$ &  94.16$_{\pm \text{0.19}}$ & \cellcolor{orange!25} \textbf{76.08} & 80.61$_{\pm \text{0.47}}$ & 44.20$_{\pm \text{3.06}}$ & 58.30$_{\pm \text{0.48}}$ & 84.80$_{\pm \text{0.13}}$ & 78.27$_{\pm \text{0.54}}$ & 74.51$_{\pm \text{0.53}}$ & 72.38 \\ 
      & GraphGPT & 82.29$_{\pm \text{0.26}}$ & 74.67$_{\pm \text{1.15}}$ & 93.54$_{\pm \text{0.22}}$ & \cellcolor{orange!10} 75.15$_{\pm \text{0.14}}$ & 82.54$_{\pm \text{0.23}}$ & 67.00$_{\pm \text{1.22}}$  & 60.72$_{\pm \text{1.47}}$ & 85.38$_{\pm \text{0.72}}$ & 84.46$_{\pm \text{0.36}}$ & 86.78$_{\pm \text{1.14}}$ & 79.25  \\ 
      & LLaGA & 87.55$_{\pm \text{1.15}}$ & \cellcolor{orange!25} \textbf{76.73$_{\pm \text{1.70}}$} & 90.28$_{\pm \text{0.91}}$ & 74.49$_{\pm \text{0.23}}$ & 84.03$_{\pm \text{1.10}}$ & \cellcolor{orange!25} \textbf{69.16$_{\pm \text{0.72}}$} & \cellcolor{orange!10} 71.06$_{\pm \text{0.38}}$ & 85.56$_{\pm \text{0.30}}$ & \cellcolor{orange!10} 87.62$_{\pm \text{0.30}}$ & \cellcolor{orange!10} 90.41$_{\pm \text{0.12}}$ & \cellcolor{orange!10}81.69 \\ \bottomrule
    \end{tabular}
    }

    \label{tab:mainexp}
\end{table*}