%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\section{Bit-Flip Attack Verification Problem}\label{sec:pro}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

In this section, we define the verification problem considered in this work and discuss a naive baseline solution based on \deepPoly.

\subsection{Problem Definition}\label{sec:proDef}

\begin{definition}[BFA-tolerance]
Let $\mN:\mathbb{R}^n\rightarrow\mathbb{R}^s$ be a QNN. Given a pre-condition $\phi$ over the input $\bs{x}\in\mathbb{R}^n$ and post-condition $\psi$ over the output $\mN(\bs{x})\in\mathbb{R}^s$. We use $\mN \models^\rho_{\mm,\nn} \langle \phi,\psi\rangle$ to denote that for any $(\mm,\nn)$-attack vector $\rho$, $\phi(\bs{x})\Rightarrow \psi(\mN^\rho(\bs{x}))$ always holds, where $\mN^\rho$ is the network obtained from $\mN$ given the attack vector $\rho$.
\end{definition}

If $\mN \models^\rho_{\mm,\nn} \langle \phi,\psi\rangle$ holds,  we say that $\mN$ is BFA-tolerant to the property $\langle \psi,\phi\rangle$. Note that, such a formulation of the problem is expressive enough to cover a range of desired neural network properties, including safety, robustness, (counterfactual) fairness, and backdoor-absence.
% \begin{definition}
% Let $\mN:\mathbb{R}^n\rightarrow\mathbb{R}^s$ be a QNN. Given a pre-condition $\phi$ over the input $\bs{x}\in\mathbb{R}^n$ and post-condition $\psi$ over the output $\mN(\bs{x})\in\mathbb{R}^s$. We use $\mN^\rho \models_{\mm,\nn} \langle \phi,\psi\rangle$ to denote that for any $(\mm,\nn)$-attack vector $\rho$, $\phi(\bs{x})\Rightarrow \psi(\mN^\rho(\bs{x}))$ always holds.
% \end{definition}


\begin{theorem}\label{the:npc}
Verifying whether $\mN \models^\rho_{\mm,\nn} \langle \phi,\psi\rangle$ holds is NP-complete. \hfill \qed
\end{theorem}

% \begin{proof}
% To show that the problem of checking whether $\mN\models^\rho_{\mm,\nn}\langle \phi,\psi \rangle$ holds is in NP, we can
% \begin{enumerate}
%   \item {\bf Step 1:} non-deterministically guess an input $\bs{x}\in \mathbb{R}^n$ and an $(k,\nn)$-attack vector $\rho=\{(\alpha_1,P_1),\cdots, (\alpha_k,P_k)\}$ for $k\leq \mm$;
%   \item {\bf Step 2:} build a new neural network $\mN^\rho$ according to the $(k,\nn)$-fault attack vector $\rho$;
%   \item {\bf Step 3:} compute $\mN^\rho(\bs{x})$  by feeding the values of the input $\bs{x}$ forward through the network;
%   \item {\bf Step 4:} check if both $\phi(\bs{x})$ and $\psi(\mN^\rho(\bs{x}))$ hold, and return satisfiable if both $\phi(\bs{x})$ and $\psi(\mN^\rho(\bs{x}))$ hold.
% \end{enumerate}
% Since Steps 2--4 can be done in polynomial time, we conclude the proof.


% The NP-hardness is proved by reducing from the satisfiability problem of the vanilla neural network verification problem $\mN\models \langle \phi,\psi\rangle$ which is NP-complete~\cite{GuyKatz2017ReluplexAE}.
% Consider a vanilla neural network verification problem of checking whether $\mN\models \langle \phi,\psi\rangle$ holds.
% Suppose the inputs and outputs of the neural network are $\bs{x}$ and $\bs{y} = \mN(\bs{x})$, respectively.
% We construct a neural network  $\mN'$ as follows:
% \begin{itemize}
%   \item $\mN'$ comprises $\nn+1$ copies of the network verification $\mN$ in parallel,
%   \item all the copies share the same inputs $\bs{x}$,
%   \item the outputs of the $i$-th copy are renamed by $\bs{y}_i$,
%   \item the weights of the edges between two neurons in two different copies are $0$,  ensuring that the neurons
%   in the $i$-th copy are not affected by the neurons in other copies.
% \end{itemize}
% Let $\psi'=\bigvee_{i=1}^{\nn+1}\psi_i$, where $\psi_i$ is obtained from the property $\psi$ by renaming
% the outputs $\bs{y}$ with the outputs $\bs{y}_i$.

% {\bf Claim.} \textit{For any fixed constants $\mm$ and $\nn$,
% $\mN' \models^\rho_{\mm,\nn} \langle \phi',\psi'\rangle$ holds
% iff $\mN \models \langle \phi,\psi\rangle$ holds.}

% $(\Leftarrow)$ Suppose the vanilla neural network verification $\mN\models\langle \phi,\psi\rangle$ holds,
% then for any inputs $\bs{x}\in \mathbb{R}^n$ that satisfies the pre-condition $\phi$, $\bs{y}=N(\bs{x})$ also satisfies
% the post-condition $\phi$. According to the construction of $N'$, 
% for any $(k,\nn)$-fault attack vector $\rho$ with $k\leq \mm$, 
% there exists a copy of $N$, say
% the $i$-th copy of $N$, such that the outputs $\bs{y}_i$ are the same as the outputs $\bs{y}$.
% It implies that $N'(\bs{x})$ satisfies $\psi_i$, hence $\psi'$.
% Thus, $\mN'\models^\rho_{\mm,\nn}\langle \phi,\psi'\rangle$ holds.

% $(\Rightarrow)$
% Suppose the vanilla neural network verification problem $\mN\models \langle \phi,\psi\rangle$ does not hold, then 
% there exists a counterexample $\bs{x}\in \mathbb{R}^n$ such that
% $\bs{x}$ satisfies the pre-condition $\phi$ but $\bs{y}=\mN(\bs{x})$ does not satisfy
% the post-condition $\phi$. According to the construction of $\mN'$, 
% the outputs $\mN'(\bs{x})$ of $\mN'$ under an $(\mm,0)$-fault attack vector $\rho$ (i.e., no weights can be changed)
% are $\nn+1$ copies of $\bs{y}=\mN(\bs{x})$.
% Thus, $\mN'(\bs{x})$ does not satisfy $\psi'=\bigvee_{i=1}^{\nn+1}\psi_i$,
% i.e., $\mN'\models^\rho_{\mm,\nn}\langle \phi,\psi'\rangle$ does not hold.
% \end{proof}

In the following, for the sake of readability, our discussion focuses on the following general BFA-tolerant robustness property.
% \begin{definition}[BFA-tolerant Robustness]
%     Let $\mN:\mathbb{R}^n\rightarrow\mathbb{R}^m$ be a QNN, $\mI^r_\bs{u}=\{\bs{x}\in\mathbb{R}^n\mid || \bs{x}-\bs{u}||_\infty \le r\}$ be an input region around an input $\bs{u}\in\mathbb{R}^n$, and $\mO_\bs{u}=\{\bs{y}\in\mathbb{R}^s\mid \text{argmax}(\bs{y})=\text{argmax}(\mN(\bs{u}))\}$. $\mN$ is BFA-tolerant for robustness if $\mN^\rho\models_{\mm,\nn}\langle \phi,\psi\rangle$ returns true, where $\phi(\bs{x}):= \bs{x}\in\mI^r_\bs{u}$, $\psi(\bs{y}):= \bs{y}\in\mO_{\bs{u}}$.
% \end{definition}

\begin{definition}[BFA-tolerant Robustness]
    Let $\mN:\mathbb{R}^n\rightarrow\mathbb{R}^m$ be a QNN, $\mI \subset \mathbb{R}^n$ be an input region, and $g$ is a target class. $\mN$ is BFA-tolerant for robustness with respect to the region $\mI$ and the class $g$ if $\mN\models^\rho_{\mm,\nn}\langle \phi,\psi\rangle$ returns true, where $\phi(\bs{x}):= \bs{x}\in\mI$, $\psi(\bs{y}):= \text{argmax}(\bs{y})=g$.
\end{definition}

Intuitively, the BFA-tolerant robustness verification problem with $\mm=\nn=0$ is the vanilla robustness verification problem $\mN\models\langle \phi,\psi\rangle$ of neural networks, following the prior works~\cite{GuyKatz2017ReluplexAE}. 
% In this work, we also call the BFA-tolerant robustness property the BFA-tolerant prediction property when $r=0$.
In this work, we consider input regions that are expressible by polyhedra, \minor{following the literature, e.g., ~\cite{GMDTCV18,LiLYCHZ19,LiLHY0ZXH20,SGMPV18,SGPV19,TranBXJ20,TranLMYNXJ19,WangPWYJ18,YLLHWSXZ20,GiacobbeHL20,scaleQNN21,ZZCSZC22,ZhangCSSD24} to cite a few}. 

\subsection{A Naive Method by \deepPoly}\label{sec:naiveMethod}

Next, we present a baseline approach that reduces the BFA verification problem to a classic neural network verification problem so that the existing verifier, such as \deepPoly~\cite{SGPV19}, can be used to verify the above BFA-tolerant properties.

% \paragraph{Review of \deepPoly}

\smallskip
\noindent
{\bf Review of \deepPoly.}
The key idea of \deepPoly is to approximate the behavior of the neural network based on an abstract interpreter specifically tailored to the setting of neural networks. Specifically, the abstract domain $\mA$ is a combination of polyhedra, coupled with abstract transformers for neural network functions, including affine functions and activation functions. To achieve this, each neuron in the hidden layer $\bs{x}^i_j$ (the $j$-th neuron in the $i$-th layer) with $\bs{x}^i_j = \text{ReLU}(\bs{W}^i\bs{x}^{i-1}+\bs{b}^i)$ is seen into two nodes $\bs{x}^i_{j,1}$ and $\bs{x}^{i}_{j,2}$ such that $\bs{x}^{i}_{j,1}=\bs{W}^i_{j,:}\bs{x}^{i-1}+\bs{b}^i_j$ and $\bs{x}^i_{j,2}=\text{ReLU}(\bs{x}^i_{j,1})$, where $\bs{x}^{i-1}_{k}=\bs{x}^{i-1}_{k,2}$ for $k\in[n_{i-1}]$.
% 
Formally, the abstract element $\bs{a}^i_{j,s}\in\mA$ for each neuron $\bs{x}^i_{j,s}$ ($s\in\{1,2\}$) is a tuple $\langle a^{i,\le}_{j,s}, a^{i,\ge}_{j,s}, l^i_{j,s}, u^i_{j,s}\rangle$, where $a^{i,\le}_{j,s}$ (resp. $a^{i,\ge}_{j,s}$) is a symbolic lower (resp. upper) bound in the form of a linear combination of variables which appear before it and $l^i_{j,s},u^i_{j,s}\in\mathbb{R}$. 
% 
For an affine function $\bs{x}^i_{j,1}=\bs{W}^i_{j,:}\bs{x}^{i-1}+\bs{b}^i_j$, the abstract transformer sets $a^{i,\le}_{j,1}=a^{i,\ge}_{j,1}=\bs{W}^i_{j,:}\bs{x}^{i-1}+\bs{b}^i_j$. To compute the concrete lower (resp. upper) bound $l^i_{j,1}$ (resp. $u^i_{j,1}$), we first repeatedly substitute the variables in $a^{i,\le}_{j,1}$ (resp. $a^{i,\ge}_{j,1}$) with their symbolic bounds according to the coefficient until no further substitution is possible. Then, we can obtain a sound lower (resp. upper) bound in the form of the linear combination of input variables, and $l^i_{j,1}$ (resp. $u^i_{j,1}$) can be computed immediately from the input domain.
% 
For an activation function $\bs{x}^{i}_{j,2}=\text{ReLU}(\bs{x}^i_{j,1})$, the abstract transformers set the abstract element $\bs{a}^i_{j,2}=\langle a^{i,\le}_{j,2},a^{i,\ge}_{j,2}, l^i_{j,2}, u^i_{j,2}\rangle$ as follows:
\begin{itemize}
    \item If $l^i_{j,1}\ge 0$: $a^{i,\le}_{j,2}= a^{i,\le}_{j,1}$, $a^{i,\ge}_{j,2}=a^{i,\ge}_{j,1}$, $l^i_{j,2}=l^i_{j,1}$, and $u^i_{j,2}=u^i_{j,1}$;
    \item If $u^i_{j,1}\le 0$: $a^{i,\le}_{j,2}=a^{i,\ge}_{j,2}=l^i_{j,2}=u^i_{j,2}=0$; 
    \item If $l^i_{j,1}< 0 < u^i_{j,1}$: $a^{i,\ge}_{j,2}=u^i_{j,1}(\bs{x}^{i}_{j,1}-l^i_{j,1})/(u^i_{j,1}-l^i_{j,1})$, $a^{i,\le}_{j,2}=\lambda\bs{x}^i_{j,1}$ where $\lambda\in\{0,1\}$ such that the area of resulting shape by $a^{i,\le}_{j,2}$ and $a^{i,\ge}_{j,2}$ is minimal, $l^i_{j,2}=\lambda l^i_{j,1}$ and $u^i_{j,2}=u^i_{j,1}$.
\end{itemize}

\smallskip
\noindent
{\bf A naive method.}
% \paragraph{A naive method by \deepPoly.}
Given the problem of verifying whether $\mN \models^\rho_{\mm,\nn} \langle \phi,\psi \rangle$ holds, a naive solution is to iteratively create an attacked network $\mN^\rho$ for each possible $(\mm,\nn)$-attack vector $\rho$ and check the vanilla robustness verification problem $ \mN^\rho \models \langle \phi,\psi \rangle$ by \deepPoly, which conducts a reachability analysis and returns a sound and incomplete verification result. 
% 
Following this method, the number of possible attack vectors increases quickly with $\mm$, $\nn$, and the number of parameters in $\mN$, causing the infamous combinatorial explosion problem. 
% 
For instance, suppose the number of parameters of a QNN is $K$ and the quantization bit-width is $Q$, the number of possible attack vectors (or the number of attacked networks $\mN^\rho$) is 
$\binom{K}{\mm}\times (\sum_{i=1}^\nn\binom{Q}{i})^\mm$. 

% In this work, we assume that the adversary can only attack one parameter and one bit in a QNN, i.e., $\mm=\nn=1$. The rationale behind the assumption is twofold: i) the adversaries cannot flip as many bits as they desire at any desired location. State-of-the-art BFA tools like DeepHammer~\cite{yao2020deephammer} can support only one bit flip in a 4KB space in memory, and ii) the recent research~\cite{1bitallyouneed} shows that an adversary can easily attack a QNN by flipping only one critical bit on average in the deployment stage. 
% Remark that even if bit-flip attacks are limited to flipping only one parameter, the number of possible $(1,1)$-attack vectors is still $K\times Q$.
% $K\cdot\sum_{i=1}^\nn\binom{Q}{i}$.
