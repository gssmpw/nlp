\section{Related Work}
\label{sec:relatedwork}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
In this section, we discuss the \minor{existing works closely related} to the contributions of this paper.
% existing formal verification techniques of QNNs and examine strategies for both attacking these networks through bit-flip methods and defending against such attacks.
\vspace{2mm}

% \smallskip
\noindent
{\bf Verification of QNNs.}
In the literature, quantization is broadly categorized into two types~\cite{gholami2021survey}: parameter-only quantization and quantization applied to both parameters and activations, leading to significant differences in verification methodologies. 
For parameter-only quantization, existing white-box DNN verification methods ~\cite{KBDJK17,LiLHY0ZXH20,betaCrown,GuoWZZSW21,backVerify22} can be applied directly, while
primarily leverage constraint-solving or abstraction. A constraint-solving-based method reduces the verification problem into 
SMT/MILP solving~\cite{KBDJK17,KatzHIJLLSTWZDK19,ChengNR17,PrabhakarA19,fischetti2018deep}. While sound and complete, they often suffer from scalability limitations. To improve efficiency, various abstraction-based methods are proposed, such as computing a conservative bound of the output range based on different abstract domains~\cite{GMDTCV18,LiLHY0ZXH20,SGMPV18,SGPV19} or obtaining abstract neural networks, rendering them more suitable for verification~\cite{AshokHKM20,ZZCSCL22,ElboherGK20,OBKatz22,LXSSXM22}. \minor{A key distinction between \symPoly and other symbolic or polyhedral abstraction-based approaches in neural network verification is that existing methods abstract only neuron value ranges with fixed parameters, focusing solely on input interval propagation. In contrast, \symPoly extends abstraction to both neuron and parameter value ranges, enabling simultaneous propagation of both input and weight intervals.}
For QNNs where both parameters and activations are quantized, existing techniques primarily rely on constraint solving~\cite{GiacobbeHL20,scaleQNN21,huang2023towards,zhang2023qebverif} or BDD~\cite{BDD4BNN,zhang2023precise}, mainly for robustness properties. 
\vspace{2mm}

% \smallskip
\noindent
{\bf Bit-flip attacks and defense of neural networks.}
DNNs are notably vulnerable to BFAs, where a single bit alternation can cause severe performance degradation~\cite{HONG_USENIX19,SURVEY,liyes}. To mitigate this, QNNs have been explored as a more resilient alternative. Building on the foundational work by Rakin et al.~\cite{BFAICCV19}, a variety of attack technologies specifically designed for QNNs have then been investigated~\cite{DONTKNOCK,PRACTICALATTACK,SPARSEBFA,glitchinjection}. These attacks primarily manipulate bits in non-volatile memory, affecting mainly the weights and occasionally the biases (e.g., DRAM), as well as introducing faults into certain neuron activation functions. Common BFA methodologies on networks include the Rowhammer attack~\cite{ROWHAMMER,BFAICCV19,DONTKNOCK}, clock glitching attack~\cite{PRACTICALATTACK}, Voltage Frequency Scaling (VFS) attack~\cite{VFSBFA}, and lase injection attack~\cite{ovrvwlaser}. Notably, the Rowhammer, VFS, and laser inject attacks primarily manipulate the binary representations of weights and biases stored in memory~\cite{BFAICCV19,1bitallyouneed,DONTKNOCK,SPARSEBFA,VFSBFA}, while the clock glitching attack specifically disrupts the functionality of the activation functions~\cite{PRACTICALATTACK,glitchinjection}.

The primary objective of defensive techniques is to enhance accuracy and/or robustness in the presence of BFAs. A natural approach to achieving this is to implement countermeasures against the underlying mechanisms that cause attacks, specifically by addressing the attacks from a hardware or system architecture perspective. For example,~\cite{yauglikcci2021blockhammer} selectively throttles memory accesses that could otherwise potentially cause Rowhammer bit-flips. Error correction Code~\cite{cojocar2019exploiting,di2023copy} is also an effective defense mechanism, typically implemented by the memory controller. 
% 
% There is also an increasing research effort aimed at directly addressing the impact of bit-flip attacks on networks by retraining or designing them to be more robust against such attacks. These explorations can be primarily classified into two categories: i) raising the bit-flip attack threshold as a defense method and ii) detecting and then protecting. 
% For the first category, one of the most effective methods is quantization~\cite{rakin2021rabnn,chitsaz2023training}. 
% For the second category, common approaches include calculating hash signatures for weights~\cite{AshokHKM20,9643556}, extracting neural network features in real-time~\cite{9486685,NeuroPots}, trying different number encoding~\cite{velvcicky2024deepncode}, and employing proactive detective strategies~\cite{NeuroPots}. 
However, no existing defense method can provide a definitive guarantee of eliminating all potential risks posed by bit-flip attacks.
\vspace{2mm}

% \smallskip
\noindent
\minor{{\bf Other related works.} \cite{weng2020towards} proposes a method that formulates certified weight perturbations as an optimization problem, employing a uniform $L_\infty$ norm perturbation within each layer. Their approach focuses on precision at the level of individual inputs, in contrast to ours \tool, which examines robustness against the BFAs over an input region. Another closely related study~\cite{wicker2020probabilistic} investigates probabilistic safety verification of Bayesian networks utilizing weight interval propagation to identify disjoint safe weight spaces based on weight distributions. Although a direct comparison between their work and ours is not feasible due to the differences in network types and verification tasks, their methodology aligns with our naive abstraction approach depicted in Figure~\ref{fig:TransAct}, which, as analyzed, exhibits lower abstract precision compared to the abstraction technique proposed in this work (cf. Figure~\ref{fig:TransX}).} 


% % \smallskip
% % \noindent {\bf Bit-Flip Attack of QNNs.}
% The primary effects of known bit-flip attacks predominantly result in the alternation of bits within non-volatile memory, affecting mainly the weights and occasionally the biases (e.g., DRAM), as well as introducing faults into certain neuron activation functions. Common methodologies for bit-flip attacks targeting neural networks include the RowHammer attack~\cite{ROWHAMMER,BFAICCV19,DONTKNOCK}, clock glitching attack~\cite{PRACTICALATTACK}, Voltage Frequency Scaling (VFS) attack~\cite{VFSBFA}, and lase injection attack~\cite{ovrvwlaser}. Notably, the RowHammer, VFS, and laser inject attacks primarily manipulate the binary representations of weights and biases stored in memory~\cite{BFAICCV19,1bitallyouneed,DONTKNOCK,SPARSEBFA,VFSBFA}, while the clock glitching attack specifically disrupts the functionality of the activation functions~\cite{PRACTICALATTACK,glitchinjection}.



% % \smallskip
% % \noindent {\bf Bit-Flip Defense of QNNs.}
% % Currently, existing bit-flip defense and detection methodologies are insufficient to ensure the absence of vulnerabilities to BFAs. 
% The primary goals of defensive techniques are to enhance accuracy in the presence of BFAs and to increase the complexity involved in launching such attacks on neural networks. Common defense strategies include optimizing weight computations to alleviate bit-flip vulnerabilities~\cite{randomDNN}, employing binarization techniques~\cite{rakin2021rabnn}, introducing redundant neurons~\cite{SmartRedundancy}, and exploring diverse number encoding schemes~\cite{advwa}. Detection methodologies aim to promptly and cost-effectively identify bit-flip occurrences during runtime. Common approaches of detection include calculating hash signatures for weights~\cite{AshokHKM20}, extracting neural network features in real-time, and employing proactive detective strategies~\cite{NeuroPots}. However, so far, neither defense nor detection methods can offer a conclusive guarantee of eliminating all potential attack risks.