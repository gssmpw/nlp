%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\section{Introduction}\label{sec:intro}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
Neural networks have demonstrated their potential to achieve human-level performance in multiple domains~\cite{dong2021survey,MusaHLLY23}. 
However, they are fragile in many ways and can be easily manipulated through various attacks~\cite{khalid2021exploiting,LiuWLX17,yao2020deephammer,HONG_USENIX19,CCFDZSL20,SongLCFL21,DZBS21,ChenZZS23,ZhaoCLLSWS24,ChenZS24}.
Recently, bit-flip attacks (BFAs)~\cite{BFAICCV19,liyes,1bitallyouneed,SURVEY} have become a critical class of hardware-based adversarial threats that exploit the physical vulnerability of neural networks. These attacks involve maliciously flipping the bits in the memory cells that store the parameters of a neural network during the deployment stage or changing the real-time activation values during the inference stage. Such attacks have been demonstrated to be feasible in practice for altering the behavior of networks in multiple cases~\cite{walker2021dram,PRACTICALATTACK,tol2022toward}. For instance, RowHammer~\cite{DONTKNOCK,ROWHAMMER} is one of the most widely used BFA methods which exploits a vulnerability in DRAM by repeatedly accessing memory rows to induce unintended bit flips in adjacent rows, compromising data integrity and security for network parameters. 
Unlike traditional software-level adversarial attacks, which typically require modifications to input data, BFAs directly target the underlying hardware (e.g., memory), making them particularly effective and difficult to defend against. 

\begin{figure}
    \centering
    \includegraphics[width=.98\textwidth]{figs/illu.pdf}
    \caption{An illustration example of bit-flip attacks on an 8-bit quantized neural network. The attacker flips a single bit in the final/output layer, altering the value of parameter $\widehat{\bs{W}}^i_{j,k}$ from 85 to -43 (represented in two's complement) and misleading the network behavior.}
    \Description{An illustration of bit-flip attacks on an 8-bit quantized neural network.}
    \label{fig:illu}
\end{figure}

Modern DNNs, characterized by their large sizes and 32-bit floating-point parameters, face high computational and storage demands, hindering their deployment on resource-limited embedded devices. Quantization~\cite{DSQ,HanMD15,JacobKCZTHAK18}, reducing the precision of parameters and/or activation values, offers a promising solution to compress the network, and enable{s} the deployment of quantized neural networks (QNNs) on such devices. For example, the Tesla-FSD chip~\cite{FSDChip} employs an 8-bit integer format to store all network weights. On the other hand, QNNs have been demonstrated to exhibit greater resilience to BFAs compared to their real-valued counterparts. Specifically, DNNs are highly susceptible to BFAs, with successful attack rates reaching nearly 99\%~\cite{HONG_USENIX19}, particularly through the manipulation of the exponential bit of compromised parameters. In response, numerous defense strategies have been proposed \cite{advwa,HARDeNN,randomDNN}, leveraging parameter quantization to fortify network security against bit-flip attacks. Despite these measures, QNNs remain vulnerable to BFAs, as existing defense techniques fall short of providing formal security assurances against such attacks. This vulnerability underscores the critical need for developing a rigorous verification method to ascertain the absence of BFAs, ensuring the integrity and reliability of QNNs in security-sensitive applications. An illustration example of bit-flip attacks on an 8-bit QNN can be found in Figure~\ref{fig:illu}.


\smallskip
\noindent{\bf Main contributions.} 
In this work, we propose the first \textbf{B}it-\textbf{F}lip \textbf{A}ttacks \textbf{V}erification method (\tool) to efficiently and effectively verify if the bit-flip attacks are absent given a QNN, concerning a given input region, that is also sound and complete. It guarantees the safety of the QNN (such as robustness with respect to a specified input region) when facing potential bit-flip attacks. Given a QNN and an input region, \tool first conducts a novel reachability analysis to compute an overapproximation of the output range of the network under the potential attacks. Such an analysis generates two outcomes: i) \texttt{Proved}, meaning the absence of the potential BFAs, or ii) \texttt{Unknown}, meaning that it fails to prove the absence of successful attacks possibly due to a conservative approximation of the abstraction throughout the reachability analysis process. If the result is \texttt{Unknown}, we further encode this bit-flip attacks verification problem into an equivalent mixed-integer linear programming (MILP) problem, which can be solved by off-the-shelf solvers.

A key technical challenge is how to conduct the reachability analysis for QNNs, given the interested input region and the threat of potential bit-flip attacks (i.e., some network parameters become symbolic with unknown values). To tackle the challenge, we propose \symPoly, an advanced abstract domain that is built on \deepPoly and is equipped with new abstract transformers specifically designed for handling symbolic parameters. Initially, symbolic parameters are determined with specific parameter intervals for the QNN concerning the potential bit-flip attacks. Subsequent reachability analysis can then be conducted on the modified QNN, which is equipped with symbolic parameters, using \symPoly. To enhance the precision of our reachability analysis results, we also propose two optimization strategies, namely, \emph{sub-interval division} and \emph{binary search strategy}, to reduce the precision loss that arises from the abstract transformation concerning large value discrepancies with a single interval.


\smallskip
\noindent
{\bf Experimental results.}
We implement our method as an end-to-end tool that uses Gurobi~\cite{Gurobi} as the back-end MILP solver. We extensively evaluate it on a large set of verification tasks using multiple QNNs for the MNIST~\cite{MNIST} and ACAS Xu~\cite{julian2019deep} datasets, where the number of hidden neurons varies from 30 to 5120, the quantization bit-width of QNNs ranges from 4 to 8, and the number of bits for bit-flip attacks ranges from 1 to 4 bits. For the reachability analysis, we compare \tool with a naive method that iteratively generates a new QNN $\mN'$ for each possible bit-flip attack and verifies whether the $\mN'$ still preserves the robustness property within the given input region via \deepPoly. The experimental results show that our method is much more efficient than the naive method (up to 30x faster), successfully proving a similar number of verification tasks and even proving some tasks that return unknown by the naive method. Moreover, with the binary search strategy, we can prove even more tasks. The results also confirm the effectiveness of the MILP-based method, which can help verify many tasks that cannot be solved by \symPoly solely. The experimental results also show that \tool can verify the absence of BFAs for most of the benign neural networks in our benchmark.

Our contributions are summarized as follows.
\begin{itemize}
    \item We propose a novel abstract domain \symPoly to conduct reachability analysis for neural networks with symbolic parameters soundly and efficiently;
    \item We introduced the first sound, complete, and reasonably efficient bit-flip attacks verification method \tool for QNNs by combining \symPoly and an MILP-based method;
    \item We implement \tool as an end-to-end tool and conduct an extensive evaluation of various verification tasks, demonstrating its effectiveness and efficiency.
\end{itemize}


\smallskip
\noindent
{\bf Outline.} Section~\ref{sec:pre} presents the preliminary. Section~\ref{sec:pro} defines our problem and a naive method for solving the problem based on \deepPoly is given. We present our method in Section~\ref{sec:method}. Section~\ref{sec:exp} reports experimental results. Section~\ref{sec:relatedwork} discusses related work and finally, Section~\ref{sec:con} concludes this work. 
Missing proofs can be found in the appendix.


