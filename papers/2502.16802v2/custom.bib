% Use this file for citations not found in the ACL Anthology (contained in "anthology.bib").

@article{dubey2024llama,
  title={The llama 3 herd of models},
  author={Dubey, Abhimanyu and Jauhri, Abhinav and Pandey, Abhinav and Kadian, Abhishek and Al-Dahle, Ahmad and Letman, Aiesha and Mathur, Akhil and Schelten, Alan and Yang, Amy and Fan, Angela and others},
  journal={arXiv preprint arXiv:2407.21783},
  year={2024}
}
@misc{eval-harness,
  author       = {Gao, Leo and Tow, Jonathan and Abbasi, Baber and Biderman, Stella and Black, Sid and DiPofi, Anthony and Foster, Charles and Golding, Laurence and Hsu, Jeffrey and Le Noac'h, Alain and Li, Haonan and McDonell, Kyle and Muennighoff, Niklas and Ociepa, Chris and Phang, Jason and Reynolds, Laria and Schoelkopf, Hailey and Skowron, Aviya and Sutawika, Lintang and Tang, Eric and Thite, Anish and Wang, Ben and Wang, Kevin and Zou, Andy},
  title        = {A framework for few-shot language model evaluation},
  month        = 12,
  year         = 2023,
  publisher    = {Zenodo},
  version      = {v0.4.0},
  doi          = {10.5281/zenodo.10256836},
  url          = {https://zenodo.org/records/10256836}
}

@article{mu2024addressing,
  title={Addressing Topic Granularity and Hallucination in Large Language Models for Topic Modelling},
  author={Mu, Yida and Bai, Peizhen and Bontcheva, Kalina and Song, Xingyi},
  journal={arXiv preprint arXiv:2405.00611},
  year={2024}
}

@inproceedings{rijcken2023towards,
  title={Towards interpreting topic models with ChatGPT},
  author={Rijcken, Emil and Scheepers, Floortje and Zervanou, Kalliopi and Spruit, Marco and Mosteiro, Pablo and Kaymak, Uzay},
  booktitle={The 20th World Congress of the International Fuzzy Systems Association},
  year={2023}
}

@article{mu2024large,
  title={Large Language Models Offer an Alternative to the Traditional Approach of Topic Modelling},
  author={Mu, Yida and Dong, Chun and Bontcheva, Kalina and Song, Xingyi},
  journal={arXiv preprint arXiv:2403.16248},
  year={2024}
}

@article{chen2024towards,
  title={Towards Effective and Efficient Continual Pre-training of Large Language Models},
  author={Chen, Jie and Chen, Zhipeng and Wang, Jiapeng and Zhou, Kun and Zhu, Yutao and Jiang, Jinhao and Min, Yingqian and Zhao, Wayne Xin and Dou, Zhicheng and Mao, Jiaxin and others},
  journal={arXiv preprint arXiv:2407.18743},
  year={2024}
}

@article{li2023can,
  title={Can Large Language Models (LLM) label topics from a topic model?},
  author={Li, Dai and Zhang, Bolun and Zhou, Yimang},
  year={2023},
  publisher={OSF}
}

@article{zhang2024benchmarking,
  title={Benchmarking large language models for news summarization},
  author={Zhang, Tianyi and Ladhak, Faisal and Durmus, Esin and Liang, Percy and McKeown, Kathleen and Hashimoto, Tatsunori B},
  journal={Transactions of the Association for Computational Linguistics},
  volume={12},
  pages={39--57},
  year={2024},
  publisher={MIT Press One Broadway, 12th Floor, Cambridge, Massachusetts 02142, USA~â€¦}
}

@misc{bge_embedding,
      title={C-Pack: Packaged Resources To Advance General Chinese Embedding}, 
      author={Shitao Xiao and Zheng Liu and Peitian Zhang and Niklas Muennighoff},
      year={2023},
      eprint={2309.07597},
      archivePrefix={arXiv},
      primaryClass={cs.CL}
}

@article{abdelrazek2023topic,
  title={Topic modeling algorithms and applications: A survey},
  author={Abdelrazek, Aly and Eid, Yomna and Gawish, Eman and Medhat, Walaa and Hassan, Ahmed},
  journal={Information Systems},
  volume={112},
  pages={102131},
  year={2023},
  publisher={Elsevier}
}

@misc{slimpajama,
author = {Soboleva, Daria and Al-Khateeb, Faisal and Myers, Robert and Steeves, Jacob R and Hestness, Joel and Dey, Nolan},
title = {{SlimPajama: A 627B token cleaned and deduplicated version of RedPajama}},
month = June,
year = 2023,
url = {https://huggingface.co/datasets/cerebras/SlimPajama-627B},
}

@inproceedings{pretrainersguide,
    title = "A Pretrainer{'}s Guide to Training Data: Measuring the Effects of Data Age, Domain Coverage, Quality, {\&} Toxicity",
    author = "Longpre, Shayne  and
      Yauney, Gregory  and
      Reif, Emily  and
      Lee, Katherine  and
      Roberts, Adam  and
      Zoph, Barret  and
      Zhou, Denny  and
      Wei, Jason  and
      Robinson, Kevin  and
      Mimno, David  and
      Ippolito, Daphne",
    editor = "Duh, Kevin  and
      Gomez, Helena  and
      Bethard, Steven",
    booktitle = "Proceedings of the 2024 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies (Volume 1: Long Papers)",
    month = jun,
    year = "2024",
    address = "Mexico City, Mexico",
    publisher = "Association for Computational Linguistics",
    url = "https://aclanthology.org/2024.naacl-long.179",
    doi = "10.18653/v1/2024.naacl-long.179",
    pages = "3245--3276",
}

@inproceedings{dataeverywhere,
    title = "Data, Data Everywhere: A Guide for Pretraining Dataset Construction",
    author = "Parmar, Jupinder  and
      Prabhumoye, Shrimai  and
      Jennings, Joseph  and
      Liu, Bo  and
      Jhunjhunwala, Aastha  and
      Wang, Zhilin  and
      Patwary, Mostofa  and
      Shoeybi, Mohammad  and
      Catanzaro, Bryan",
    editor = "Al-Onaizan, Yaser  and
      Bansal, Mohit  and
      Chen, Yun-Nung",
    booktitle = "Proceedings of the 2024 Conference on Empirical Methods in Natural Language Processing",
    month = nov,
    year = "2024",
    address = "Miami, Florida, USA",
    publisher = "Association for Computational Linguistics",
    url = "https://aclanthology.org/2024.emnlp-main.596",
    doi = "10.18653/v1/2024.emnlp-main.596",
    pages = "10671--10695",
}

@article{phi,
  title={Textbooks are all you need},
  author={Gunasekar, Suriya and Zhang, Yi and Aneja, Jyoti and Mendes, Caio C{\'e}sar Teodoro and Del Giorno, Allie and Gopi, Sivakanth and Javaheripi, Mojan and Kauffmann, Piero and de Rosa, Gustavo and Saarikivi, Olli and others},
  journal={arXiv preprint arXiv:2306.11644},
  year={2023}
}

@article{gopher,
  title={Scaling language models: Methods, analysis \& insights from training gopher},
  author={Rae, Jack W and Borgeaud, Sebastian and Cai, Trevor and Millican, Katie and Hoffmann, Jordan and Song, Francis and Aslanides, John and Henderson, Sarah and Ring, Roman and Young, Susannah and others},
  journal={arXiv preprint arXiv:2112.11446},
  year={2021}
}

@article{refinedweb,
  title={The RefinedWeb dataset for Falcon LLM: outperforming curated corpora with web data, and web data only},
  author={Penedo, Guilherme and Malartic, Quentin and Hesslow, Daniel and Cojocaru, Ruxandra and Cappelli, Alessandro and Alobeidli, Hamza and Pannier, Baptiste and Almazrouei, Ebtesam and Launay, Julien},
  journal={arXiv preprint arXiv:2306.01116},
  year={2023}
}


@article{dolma,
  title={Dolma: An open corpus of three trillion tokens for language model pretraining research},
  author={Soldaini, Luca and Kinney, Rodney and Bhagia, Akshita and Schwenk, Dustin and Atkinson, David and Authur, Russell and Bogin, Ben and Chandu, Khyathi and Dumas, Jennifer and Elazar, Yanai and others},
  journal={arXiv preprint arXiv:2402.00159},
  year={2024}
}

@article{fineweb,
  title={The FineWeb Datasets: Decanting the Web for the Finest Text Data at Scale},
  author={Penedo, Guilherme and Kydl{\'\i}{\v{c}}ek, Hynek and Lozhkov, Anton and Mitchell, Margaret and Raffel, Colin and Von Werra, Leandro and Wolf, Thomas and others},
  journal={arXiv preprint arXiv:2406.17557},
  year={2024}
}

@inproceedings{qurating,
    title={QuRating: Selecting High-Quality Data for Training Language Models},
    author={Alexander Wettig and Aatmik Gupta and Saumya Malik and Danqi Chen},
    booktitle={Forty-first International Conference on Machine Learning},
    year={2024},
    url={https://openreview.net/forum?id=GLGYYqPwjy}
}

@inproceedings{dsir,
     author = {Xie, Sang Michael and Santurkar, Shibani and Ma, Tengyu and Liang, Percy S},
     booktitle = {Advances in Neural Information Processing Systems},
     editor = {A. Oh and T. Naumann and A. Globerson and K. Saenko and M. Hardt and S. Levine},
     pages = {34201--34227},
     publisher = {Curran Associates, Inc.},
     title = {Data Selection for Language Models via Importance Resampling},
     url = {https://proceedings.neurips.cc/paper_files/paper/2023/file/6b9aa8f418bde2840d5f4ab7a02f663b-Paper-Conference.pdf},
     volume = {36},
     year = {2023}
}


@article{clusteringsurvey,
  title={A survey of parallel clustering algorithms based on spark},
  author={Xiao, Wen and Hu, Juan},
  journal={Scientific Programming},
  volume={2020},
  number={1},
  pages={8884926},
  year={2020},
  publisher={Wiley Online Library}
}

@article{weber2024redpajama,
  title={RedPajama: an Open Dataset for Training Large Language Models},
  author={Weber, Maurice and Fu, Daniel and Anthony, Quentin and Oren, Yonatan and Adams, Shane and Alexandrov, Anton and Lyu, Xiaozhong and Nguyen, Huu and Yao, Xiaozhe and Adams, Virginia and others},
  journal={arXiv preprint arXiv:2411.12372},
  year={2024}
}

@article{topicsurvey,
    title={A Survey on Neural Topic Models: Methods, Applications, and Challenges},
    author={Wu, Xiaobao and Nguyen, Thong and Luu, Anh Tuan},
    journal={Artificial Intelligence Review},
    url={https://doi.org/10.1007/s10462-023-10661-7},
    year={2024},
    publisher={Springer}
}

@article{blei2003latent,
  title={Latent dirichlet allocation},
  author={Blei, David M and Ng, Andrew Y and Jordan, Michael I},
  journal={Journal of machine Learning research},
  volume={3},
  number={Jan},
  pages={993--1022},
  year={2003}
}

@article{grootendorst2020bertopic,
  title={BERTopic: Leveraging BERT and c-TF-IDF to create easily interpretable topics},
  author={Grootendorst, Maarten},
  journal={Zenodo, Version v0},
  volume={9},
  number={10.5281},
  year={2020}
}

@article{yang2023baichuan,
  title={Baichuan 2: Open large-scale language models},
  author={Yang, Aiyuan and Xiao, Bin and Wang, Bingning and Zhang, Borong and Bian, Ce and Yin, Chao and Lv, Chenxu and Pan, Da and Wang, Dian and Yan, Dong and others},
  journal={arXiv preprint arXiv:2309.10305},
  year={2023}
}

@article{chowdhery2023palm,
  title={Palm: Scaling language modeling with pathways},
  author={Chowdhery, Aakanksha and Narang, Sharan and Devlin, Jacob and Bosma, Maarten and Mishra, Gaurav and Roberts, Adam and Barham, Paul and Chung, Hyung Won and Sutton, Charles and Gehrmann, Sebastian and others},
  journal={Journal of Machine Learning Research},
  volume={24},
  number={240},
  pages={1--113},
  year={2023}
}

@inproceedings{silhouette,
  title={Cluster quality analysis using silhouette score},
  author={Shahapure, Ketan Rajshekhar and Nicholas, Charles},
  booktitle={2020 IEEE 7th international conference on data science and advanced analytics (DSAA)},
  pages={747--748},
  year={2020},
  organization={IEEE}
}

@article{li2023can,
  title={Can Large Language Models (LLM) label topics from a topic model?},
  author={Li, Dai and Zhang, Bolun and Zhou, Yimang},
  year={2023},
  publisher={OSF}
}


@inproceedings{bert,
    title = "{BERT}: Pre-training of Deep Bidirectional Transformers for Language Understanding",
    author = "Devlin, Jacob  and
      Chang, Ming-Wei  and
      Lee, Kenton  and
      Toutanova, Kristina",
    booktitle = "Proceedings of the 2019 Conference of the North {A}merican Chapter of the Association for Computational Linguistics: Human Language Technologies, Volume 1 (Long and Short Papers)",
    year = "2019",
    address = "Minneapolis, Minnesota",
    publisher = "Association for Computational Linguistics",
    url = "https://aclanthology.org/N19-1423",
    doi = "10.18653/v1/N19-1423",
    pages = "4171--4186",
}


@article{paster2023openwebmath,
  title={Openwebmath: An open dataset of high-quality mathematical web text},
  author={Paster, Keiran and Santos, Marco Dos and Azerbayev, Zhangir and Ba, Jimmy},
  journal={arXiv preprint arXiv:2310.06786},
  year={2023}
}
% datamix
@article{dmlaw,
  title={Data mixing laws: Optimizing data mixtures by predicting language modeling performance},
  author={Ye, Jiasheng and Liu, Peiju and Sun, Tianxiang and Zhou, Yunhua and Zhan, Jun and Qiu, Xipeng},
  journal={arXiv preprint arXiv:2403.16952},
  year={2024}
}

@article{regmix,
  title={RegMix: Data Mixture as Regression for Language Model Pre-training},
  author={Liu, Qian and Zheng, Xiaosen and Muennighoff, Niklas and Zeng, Guangtao and Dou, Longxu and Pang, Tianyu and Jiang, Jing and Lin, Min},
  journal={arXiv preprint arXiv:2407.01492},
  year={2024}
}

@inproceedings{doge,
    title={{DOGE}: Domain Reweighting with Generalization Estimation},
    author={Simin Fan and Matteo Pagliardini and Martin Jaggi},
    booktitle={Forty-first International Conference on Machine Learning},
    year={2024},
    url={https://openreview.net/forum?id=7rfZ6bMZq4}
}

@inproceedings{doremi,
     author = {Xie, Sang Michael and Pham, Hieu and Dong, Xuanyi and Du, Nan and Liu, Hanxiao and Lu, Yifeng and Liang, Percy S and Le, Quoc V and Ma, Tengyu and Yu, Adams Wei},
     booktitle = {Advances in Neural Information Processing Systems},
     pages = {69798--69818},
     publisher = {Curran Associates, Inc.},
     title = {DoReMi: Optimizing Data Mixtures Speeds Up Language Model Pretraining},
     url = {https://proceedings.neurips.cc/paper_files/paper/2023/file/dcba6be91359358c2355cd920da3fcbd-Paper-Conference.pdf},
     volume = {36},
     year = {2023}
}

% tasks
@inproceedings{race,
    title = "{RACE}: Large-scale {R}e{A}ding Comprehension Dataset From Examinations",
    author = "Lai, Guokun  and
      Xie, Qizhe  and
      Liu, Hanxiao  and
      Yang, Yiming  and
      Hovy, Eduard",
    booktitle = "Proceedings of the 2017 Conference on Empirical Methods in Natural Language Processing",
    month = sep,
    year = "2017",
    address = "Copenhagen, Denmark",
    publisher = "Association for Computational Linguistics",
    url = "https://aclanthology.org/D17-1082",
    doi = "10.18653/v1/D17-1082",
    pages = "785--794",
}

@inproceedings{winogrande,
  title={WinoGrande: An Adversarial Winograd Schema Challenge at Scale},
  author={Sakaguchi, Keisuke and Le Bras, Ronan and Bhagavatula, Chandra and Choi, Yejin},
  booktitle={Proceedings of the AAAI Conference on Artificial Intelligence},
  volume={34},
  number={05},
  pages={8732--8740},
  year={2020}
}

@inproceedings{commonsenseqa,
    title = "{C}ommonsense{QA}: A Question Answering Challenge Targeting Commonsense Knowledge",
    author = "Talmor, Alon  and
      Herzig, Jonathan  and
      Lourie, Nicholas  and
      Berant, Jonathan",
    booktitle = "Proceedings of the 2019 Conference of the North {A}merican Chapter of the Association for Computational Linguistics: Human Language Technologies, Volume 1 (Long and Short Papers)",
    month = jun,
    year = "2019",
    address = "Minneapolis, Minnesota",
    publisher = "Association for Computational Linguistics",
    url = "https://aclanthology.org/N19-1421",
    doi = "10.18653/v1/N19-1421",
    pages = "4149--4158",
}


@inproceedings{openbookqa,
    title = "Can a Suit of Armor Conduct Electricity? A New Dataset for Open Book Question Answering",
    author = "Mihaylov, Todor  and
      Clark, Peter  and
      Khot, Tushar  and
      Sabharwal, Ashish",
    booktitle = "Proceedings of the 2018 Conference on Empirical Methods in Natural Language Processing",
    year = "2018",
    address = "Brussels, Belgium",
    publisher = "Association for Computational Linguistics",
    url = "https://aclanthology.org/D18-1260",
    doi = "10.18653/v1/D18-1260",
    pages = "2381--2391",
}

@article{arc,
  title={Think you have solved question answering? try arc, the ai2 reasoning challenge},
  author={Clark, Peter and Cowhey, Isaac and Etzioni, Oren and Khot, Tushar and Sabharwal, Ashish and Schoenick, Carissa and Tafjord, Oyvind},
  journal={arXiv preprint arXiv:1803.05457},
  year={2018}
}

@inproceedings{sciq,
    title = "Crowdsourcing Multiple Choice Science Questions",
    author = "Welbl, Johannes  and
      Liu, Nelson F.  and
      Gardner, Matt",
    booktitle = "Proceedings of the 3rd Workshop on Noisy User-generated Text",
    month = sep,
    year = "2017",
    address = "Copenhagen, Denmark",
    publisher = "Association for Computational Linguistics",
    url = "https://aclanthology.org/W17-4413",
    doi = "10.18653/v1/W17-4413",
    pages = "94--106"
 }
 
 @inproceedings{hellaswag,
    title = "{H}ella{S}wag: Can a Machine Really Finish Your Sentence?",
    author = "Zellers, Rowan  and
      Holtzman, Ari  and
      Bisk, Yonatan  and
      Farhadi, Ali  and
      Choi, Yejin",
    editor = "Korhonen, Anna  and
      Traum, David  and
      M{\`a}rquez, Llu{\'\i}s",
    booktitle = "Proceedings of the 57th Annual Meeting of the Association for Computational Linguistics",
    month = jul,
    year = "2019",
    address = "Florence, Italy",
    publisher = "Association for Computational Linguistics",
    url = "https://aclanthology.org/P19-1472",
    doi = "10.18653/v1/P19-1472",
    pages = "4791--4800"
 }
 
@inproceedings{bisk2020piqa,
  title={Piqa: Reasoning about physical commonsense in natural language},
  author={Bisk, Yonatan and Zellers, Rowan and Gao, Jianfeng and Choi, Yejin and others},
  booktitle={Proceedings of the AAAI conference on artificial intelligence},
  volume={34},
  number={05},
  pages={7432--7439},
  year={2020}
}

@inproceedings{siqa,
    title = "Social {IQ}a: Commonsense Reasoning about Social Interactions",
    author = "Sap, Maarten  and
      Rashkin, Hannah  and
      Chen, Derek  and
      Le Bras, Ronan  and
      Choi, Yejin",
    booktitle = "Proceedings of the 2019 Conference on Empirical Methods in Natural Language Processing and the 9th International Joint Conference on Natural Language Processing (EMNLP-IJCNLP)",
    month = nov,
    year = "2019",
    address = "Hong Kong, China",
    publisher = "Association for Computational Linguistics",
    url = "https://aclanthology.org/D19-1454",
    doi = "10.18653/v1/D19-1454",
    pages = "4463--4473"
}


@inproceedings{boolq,
  title={BoolQ: Exploring the Surprising Difficulty of Natural Yes/No Questions},
  author={Clark, Christopher and Lee, Kenton and Chang, Ming-Wei and Kwiatkowski, Tom and Collins, Michael and Toutanova, Kristina},
  booktitle={Proceedings of the 2019 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies, Volume 1 (Long and Short Papers)},
  pages={2924--2936},
  year={2019}
}


@article{su2024roformer,
  title={Roformer: Enhanced transformer with rotary position embedding},
  author={Su, Jianlin and Ahmed, Murtadha and Lu, Yu and Pan, Shengfeng and Bo, Wen and Liu, Yunfeng},
  journal={Neurocomputing},
  volume={568},
  pages={127063},
  year={2024},
  publisher={Elsevier}
}

@article{llama,
  title={Llama: Open and efficient foundation language models},
  author={Touvron, Hugo and Lavril, Thibaut and Izacard, Gautier and Martinet, Xavier and Lachaux, Marie-Anne and Lacroix, Timoth{\'e}e and Rozi{\`e}re, Baptiste and Goyal, Naman and Hambro, Eric and Azhar, Faisal and others},
  journal={arXiv preprint arXiv:2302.13971},
  year={2023}
}

@article{bianchi2020pre,
  title={Pre-training is a hot topic: Contextualized document embeddings improve topic coherence},
  author={Bianchi, Federico and Terragni, Silvia and Hovy, Dirk},
  journal={arXiv preprint arXiv:2004.03974},
  year={2020}
}
@article{bouma2009normalized,
  title={Normalized (pointwise) mutual information in collocation extraction},
  author={Bouma, Gerlof},
  journal={Proceedings of GSCL},
  volume={30},
  pages={31--40},
  year={2009},
  publisher={Potsdam}
}

