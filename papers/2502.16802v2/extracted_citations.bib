@article{blei2003latent,
  title={Latent dirichlet allocation},
  author={Blei, David M and Ng, Andrew Y and Jordan, Michael I},
  journal={Journal of machine Learning research},
  volume={3},
  number={Jan},
  pages={993--1022},
  year={2003}
}

@article{chen2024towards,
  title={Towards Effective and Efficient Continual Pre-training of Large Language Models},
  author={Chen, Jie and Chen, Zhipeng and Wang, Jiapeng and Zhou, Kun and Zhu, Yutao and Jiang, Jinhao and Min, Yingqian and Zhao, Wayne Xin and Dou, Zhicheng and Mao, Jiaxin and others},
  journal={arXiv preprint arXiv:2407.18743},
  year={2024}
}

@inproceedings{dataeverywhere,
    title = "Data, Data Everywhere: A Guide for Pretraining Dataset Construction",
    author = "Parmar, Jupinder  and
      Prabhumoye, Shrimai  and
      Jennings, Joseph  and
      Liu, Bo  and
      Jhunjhunwala, Aastha  and
      Wang, Zhilin  and
      Patwary, Mostofa  and
      Shoeybi, Mohammad  and
      Catanzaro, Bryan",
    editor = "Al-Onaizan, Yaser  and
      Bansal, Mohit  and
      Chen, Yun-Nung",
    booktitle = "Proceedings of the 2024 Conference on Empirical Methods in Natural Language Processing",
    month = nov,
    year = "2024",
    address = "Miami, Florida, USA",
    publisher = "Association for Computational Linguistics",
    url = "https://aclanthology.org/2024.emnlp-main.596",
    doi = "10.18653/v1/2024.emnlp-main.596",
    pages = "10671--10695",
}

@article{dmlaw,
  title={Data mixing laws: Optimizing data mixtures by predicting language modeling performance},
  author={Ye, Jiasheng and Liu, Peiju and Sun, Tianxiang and Zhou, Yunhua and Zhan, Jun and Qiu, Xipeng},
  journal={arXiv preprint arXiv:2403.16952},
  year={2024}
}

@inproceedings{doge,
    title={{DOGE}: Domain Reweighting with Generalization Estimation},
    author={Simin Fan and Matteo Pagliardini and Martin Jaggi},
    booktitle={Forty-first International Conference on Machine Learning},
    year={2024},
    url={https://openreview.net/forum?id=7rfZ6bMZq4}
}

@inproceedings{doremi,
     author = {Xie, Sang Michael and Pham, Hieu and Dong, Xuanyi and Du, Nan and Liu, Hanxiao and Lu, Yifeng and Liang, Percy S and Le, Quoc V and Ma, Tengyu and Yu, Adams Wei},
     booktitle = {Advances in Neural Information Processing Systems},
     pages = {69798--69818},
     publisher = {Curran Associates, Inc.},
     title = {DoReMi: Optimizing Data Mixtures Speeds Up Language Model Pretraining},
     url = {https://proceedings.neurips.cc/paper_files/paper/2023/file/dcba6be91359358c2355cd920da3fcbd-Paper-Conference.pdf},
     volume = {36},
     year = {2023}
}

@article{dubey2024llama,
  title={The llama 3 herd of models},
  author={Dubey, Abhimanyu and Jauhri, Abhinav and Pandey, Abhinav and Kadian, Abhishek and Al-Dahle, Ahmad and Letman, Aiesha and Mathur, Akhil and Schelten, Alan and Yang, Amy and Fan, Angela and others},
  journal={arXiv preprint arXiv:2407.21783},
  year={2024}
}

@article{grootendorst2020bertopic,
  title={BERTopic: Leveraging BERT and c-TF-IDF to create easily interpretable topics},
  author={Grootendorst, Maarten},
  journal={Zenodo, Version v0},
  volume={9},
  number={10.5281},
  year={2020}
}

@article{mu2024addressing,
  title={Addressing Topic Granularity and Hallucination in Large Language Models for Topic Modelling},
  author={Mu, Yida and Bai, Peizhen and Bontcheva, Kalina and Song, Xingyi},
  journal={arXiv preprint arXiv:2405.00611},
  year={2024}
}

@article{mu2024large,
  title={Large Language Models Offer an Alternative to the Traditional Approach of Topic Modelling},
  author={Mu, Yida and Dong, Chun and Bontcheva, Kalina and Song, Xingyi},
  journal={arXiv preprint arXiv:2403.16248},
  year={2024}
}

@inproceedings{pretrainersguide,
    title = "A Pretrainer{'}s Guide to Training Data: Measuring the Effects of Data Age, Domain Coverage, Quality, {\&} Toxicity",
    author = "Longpre, Shayne  and
      Yauney, Gregory  and
      Reif, Emily  and
      Lee, Katherine  and
      Roberts, Adam  and
      Zoph, Barret  and
      Zhou, Denny  and
      Wei, Jason  and
      Robinson, Kevin  and
      Mimno, David  and
      Ippolito, Daphne",
    editor = "Duh, Kevin  and
      Gomez, Helena  and
      Bethard, Steven",
    booktitle = "Proceedings of the 2024 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies (Volume 1: Long Papers)",
    month = jun,
    year = "2024",
    address = "Mexico City, Mexico",
    publisher = "Association for Computational Linguistics",
    url = "https://aclanthology.org/2024.naacl-long.179",
    doi = "10.18653/v1/2024.naacl-long.179",
    pages = "3245--3276",
}

@article{regmix,
  title={RegMix: Data Mixture as Regression for Language Model Pre-training},
  author={Liu, Qian and Zheng, Xiaosen and Muennighoff, Niklas and Zeng, Guangtao and Dou, Longxu and Pang, Tianyu and Jiang, Jing and Lin, Min},
  journal={arXiv preprint arXiv:2407.01492},
  year={2024}
}

@inproceedings{rijcken2023towards,
  title={Towards interpreting topic models with ChatGPT},
  author={Rijcken, Emil and Scheepers, Floortje and Zervanou, Kalliopi and Spruit, Marco and Mosteiro, Pablo and Kaymak, Uzay},
  booktitle={The 20th World Congress of the International Fuzzy Systems Association},
  year={2023}
}

@article{topicsurvey,
    title={A Survey on Neural Topic Models: Methods, Applications, and Challenges},
    author={Wu, Xiaobao and Nguyen, Thong and Luu, Anh Tuan},
    journal={Artificial Intelligence Review},
    url={https://doi.org/10.1007/s10462-023-10661-7},
    year={2024},
    publisher={Springer}
}

