\documentclass{article}
\usepackage{arxiv}
\usepackage{authblk}
\usepackage{microtype}
\usepackage{graphicx}
\usepackage{subfigure}
\usepackage{booktabs}
\usepackage{enumitem}
\usepackage{hyperref}
\usepackage[numbers]{natbib}
\newcommand{\theHalgorithm}{\arabic{algorithm}}
\usepackage{algorithm}
\usepackage{algorithmic}
\usepackage{amsmath}
\usepackage{amssymb}
\usepackage{mathtools}
\usepackage{amsthm}
\newlength{\myindent}
\setlength{\myindent}{2em} 
\newcommand{\INDSTATE}[1][1]{\STATE\hspace{#1\myindent}}
\newcommand{\specialcell}[2]{#1 {\scriptsize $\pm$ #2}}
\usepackage[capitalize,noabbrev]{cleveref}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% THEOREMS
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\theoremstyle{plain}
\newtheorem{theorem}{Theorem}[section]
\newtheorem{proposition}[theorem]{Proposition}
\newtheorem{lemma}[theorem]{Lemma}
\newtheorem{corollary}[theorem]{Corollary}
\theoremstyle{definition}
\newtheorem{definition}[theorem]{Definition}
\newtheorem{assumption}[theorem]{Assumption}
\theoremstyle{remark}
\newtheorem{remark}[theorem]{Remark}

\title{PLayer-FL: A Principled Approach to Personalized Layer-wise Cross-Silo Federated Learning}

\newcommand{\shorttitle}{PLayer-FL: Personalized Layer-wise FL}


% Authors with affiliations
\author{
Ahmed Elhussein$^{1,2}$ \quad Gamze G\"{u}rsoy$^{1,2,3}$ \\
\texttt{ae2722@cumc.columbia.edu} \quad \texttt{gamze.gursoy@columbia.edu}
}

% Affiliations
\affil{$^1$Department of Biomedical Informatics, Columbia University, NY, USA}
\vspace{-15mm}
\affil{$^2$New York Genome Center, NY, USA}
\vspace{-15mm}
\affil{$^3$Department of Computer Science, Columbia University, NY, USA}

% Begin document
\begin{document}
\date{}
\newcommand{\undertitle}{}
\maketitle
\vspace{-10mm}
\begin{abstract}
\end{abstract}
Non-identically distributed data is a major challenge in Federated Learning (FL). Personalized FL tackles this by balancing local model adaptation with global model consistency. One variant, partial FL, leverages the observation that early layers learn more transferable features by federating only early layers. However, current partial FL approaches use predetermined, architecture-specific rules to select layers, limiting their applicability. We introduce Principled Layer-wise-FL (PLayer-FL), which uses a novel federation sensitivity metric to identify layers that benefit from federation. This metric, inspired by model pruning, quantifies each layer's contribution to cross-client generalization after the first training epoch, identifying a transition point in the network where the benefits of federation diminish. We first demonstrate that our federation sensitivity metric shows strong correlation with established generalization measures across diverse architectures. Next, we show that PLayer-FL outperforms existing FL algorithms on a range of tasks, also achieving more uniform performance improvements across clients.
\vspace{-3mm}
\section*{Software and data} 
\vspace{-1mm}
Code for reproducing this paper can be found at \url{https://github.com/gaiters-aerials/player_fl}.

\section{Introduction}
Federated Learning (FL) is a distributed learning framework that enables collaborative model training without data-sharing. Early FL algorithms such as Federated Averaging (FedAvg) focused on developing a unified global model \cite{mcmahan2017communication}. However, when data among clients is non-independently identically distributed (non-IID), the performance of a global model diminishes. This largely stems from the fact that clients, each optimizing their local models using non-IID datasets, often generate model updates that diverge from each other \cite{zhao2018federated}. A weighted averaging of these updates then causes the global model to settle outside of local minima, which reduces the performance. To address this, personalized FL methods have been developed that allow client models to diverge, typically by guiding the training of a local model with a global model \cite{smith2017federated, dinh2021fedu, t2020pfedme}. In certain non-IID settings, Personalized FL algorithms have improved performance, yet they do not consistently outperform FedAvg. Moreover, their benefits are not always equitably distributed among all participating clients \cite{li2022federated, divi2021new}. That is, only a subset of clients might experience increased performance compared to a model trained only on their local data.  

Partial FL, in which only a subset of layers are federated, is a form of personalized FL \citep{arivazhagan2019federated, oh2021fedbabu,collins2021exploiting}. Partial FL is based on an implicit assumption that the greatest divergence in model weights primarily occurs in the model's final layers. By federating early layers and only locally updating later layers, partial FL retains the benefits of FL even with non-IID data. This approach is informed by insights from representation learning regarding layer function and generalizability. It is well-established that early layers in neural networks typically capture universal features that are more generalizable across tasks \cite{yosinski2014transferable, simonyan2013deep, zeiler2014visualizing, mallat2016understanding}. In contrast, later layers are often more task-specific, thus tend to benefit from localized training or fine-tuning \cite{yosinski2014transferable}. This transition in layer function and generalizability is also observed in the model loss landscape. Early layers, which are linked to feature representation, generally occupy flatter areas of the loss function, suggesting a lower sensitivity to perturbations. \cite{chaudhari2019entropy, jiang2019fantastic, yosinski2014transferable}. However, existing partial FL methods \citep{arivazhagan2019federated, oh2021fedbabu,collins2021exploiting} determine which layers to federate in an ad hoc manner, which limits their generalizability across different architectures and tasks.

Here, we propose that insights from model pruning can be leveraged to establish a more principled approach to federation assignment in partial FL. Model pruning involves reducing model complexity by eliminating unnecessary parameters. Similar to representation learning, model pruning offers insights into parameter and layer function that can be leveraged in partial FL. While model pruning involves identifying parameters that can be removed with minimal performance loss— a different focus from that of partial FL- the underlying principles still hold relevance. Studies have shown that layer-specific pruning can achieve high model performance despite significant reductions in model size \cite{dong2017learning, chen2018shallowing,fan2021layer}. This process highlights that certain parameters are critical for the model’s output and must be retained, while others may be redundant \cite{liu2018rethinking}. Further, the degree of pruning in a layer often correlates with its feature representation \cite{chen2018shallowing}. Crucially, work in model pruning aims to find computationally simple metrics for pruning that work across a range of architectures. We posit that a similar approach can be adopted in partial FL.

Building on these insights, we propose Principled Layer-wise-FL (PLayer-FL), a partial FL approach that utilizes a novel federation sensitivity metric to identify which layers are more suited for federation. This metric, inspired by model pruning, uses a first-order approximation of weight importance to determine which layers would benefit from federation. Importantly, our method identifies this during the first epoch of training rather than relying on model-specific heuristics. We validate our approach across various model architectures and real-world non-IID datasets, demonstrating consistent improvements in performance, fairness, and incentivization.

\section{Contribution and significance}
In this study, we make several contributions to FL with non-IID data:
\begin{itemize}[leftmargin=*]
    \setlength\itemsep{0.5em}
    \item  \textbf{Early identification of layer-specific divergence.} We show that models with \emph{identical initialization but independent training} exhibit consistent generalization patterns across corresponding layers, even after just one epoch of non-IID training. This enables early, reliable decisions about which layers to federate.
    \item \textbf{Federation sensitivity metric.} We introduce a novel metric, federation sensitivity, that estimates each layer's cross-client generalization. This metric identifies a transition point where the benefits of federation diminish. This metric correlates strongly with established generalization measures, emerges from the first epoch, and imposes minimal computational overhead. Notably, it holds across diverse network architectures.
    \item  \textbf{Principled partial FL algorithm.} We develop PLayer-FL that uses \emph{federation sensitivity} to determine which layers to federate after only one epoch of training. PLayer-FL outperforms other approaches on various non-IID datasets (including real-world tasks), while also achieving fairer outcomes and stronger incentives for FL participation.
\end{itemize}
\section{Background}
\subsection{Federated Learning}
In each training round $k$, the server broadcasts global model parameters $\Theta^{k-1}$ to clients $c \in C$. These clients update their local model to produce $\Theta_c^k$ which are sent back to the server. The central server then aggregates these parameters and rebroadcasts the updated global model. This is repeated until convergence. In FedAvg, the aggregation is defined as $\Theta^k = \sum_{c=1}^n \alpha_c{\Theta_c^k}$, where $\alpha_c$ is the weight of each client determined by sample size. 

\subsubsection{Cross-Silo FL}
\label{background:cross_fl}
FL has two main settings, cross-silo and cross-device, each with distinct use cases and challenges \cite{kairouz2021advances}. This work concentrates on cross-silo FL, a setting common in sectors such as healthcare to overcome data-sharing constraints. In healthcare, cross-silo FL has advanced research on poorly understood diseases by enabling training on larger datasets \cite{pati2022federated, dayan2021federated}. Cross-silo FL involves a few clients with medium to large datasets. A key challenge is non-IID data as institutions often have different populations, data collection practices, and operational protocols \cite{pati2021federated, terrail2022flamby}. Further, since clients frequently possess enough data to train adequately performant models on their own, FL must surpass local training to motivate participation \cite{huang2022cross}. In contrast, cross-device FL manages numerous edge devices with limited data, prioritizing communication efficiency. While most FL methods target cross-device scenarios, fewer address cross-silo FL's unique challenges \cite{huang2022cross, terrail2022flamby}, highlighting the need for specialized approaches.

\subsection{Model pruning}
Model pruning reduces the size of a model by removing parameters that have limited impact on the output \cite{reed1993pruning}. Simple, yet effective metrics include weight magnitude or the scaling parameter in batch normalization \cite{han2015learning, liu2017learning}. Other methods leverage a first or second-order approximation of the change in loss following the removal of parameter $w_s$ to quantify its importance, denoted as $\mathcal{I}_s(w)$  \cite{lecun1989optimal, molchanov2019importance}. The importance of a parameter set, $W_\mathcal{S}$, where $w_s \in W_\mathcal{S}$, is defined as \cite{molchanov2019importance}:
\begin{equation}
\label{eqn:first_order_approx}
    \mathcal{I}_\mathcal{S}(W) \triangleq \sum_{s\in \mathcal{S}} \mathcal{I}_s(w)= \sum_{s \in \mathcal{S}} (g_sw_s) ^2
\end{equation}
where $g_s$ is the gradient with respect to the parameter $w_s$. Importantly, many of these simple methods have been shown to be reliably effective across diverse model architectures. 

\subsection{Model generalization}
Many studies in representation learning have sought to understand when and how models generalize. One method is to examine the loss landscape. Parameters located in flatter regions of the loss landscape exhibit reduced sensitivity to perturbations and are more generalizable. Multiple studies have also made the link that generalizable layers identify low-level features that are common across tasks \cite{yosinski2014transferable}. To estimate the characteristics of the loss landscape, first and second-order gradient approximations are used.  \citet{jiang2019fantastic} showed that gradient variance of a layer, even after one epoch, correlates with its generalizability. \citet{chaudhari2019entropy} used the eigenspectrum of the Hessian, which reflects the steepness of the loss function, as a measure of generalizability. They showed that biasing model optimization towards wide valleys improves a model's sensitivity to perturbation.  

Another approach to measuring model generalization is comparing representational similarity across models \cite{li2015convergent, morcos2018insights}. Typically, the same model is randomly initialized and trained on the same dataset a number of times. The representation of a set of samples after each layer is then compared across all models \cite{kornblith2019similarity,  williams2021generalized}. One key insight is that generalizing networks create similar representations across samples, while overfit, memorizing networks, trained on random labels, do not. \cite{morcos2018insights}. 

\textbf{Relation to our work:} We apply these techniques to address a related but distinct question more relevant for FL:

\emph{To what extent do identically initialized models trained on non-IID data resemble each other?} 

In other words, how much model divergence do we observe in FL and can this be reliably estimated? A natural question to ask is why not directly compare the weights. However, this approach has several limitations. First, there is not a straightforward, effective metric for capturing weight divergence. Common metrics such as L2-norm and cosine similarity are not invariant to linear transformation and may lack the sensitivity to detect subtle, yet significant differences in weights. Second, unlike gradients, differences in weights may not always emerge early in training. Early emergence helps to limit computational cost and mitigates the negative impacts of model training on non-IID data.
 
\section{Related works}
\textbf{Global FL} aims to generate a global model for all clients. In FedAvg, a global model is updated using a weighted average of local updates from each client \cite{mcmahan2017communication}. While this simple procedure has achieved remarkable success, it struggles when clients have non-IID data \cite{li2020federated}. Some attempts to solve this problem while retaining a global model include sharing a subset of public data \cite{zhao2018federated}, augmenting the data to be more IID \cite{duan2019astraea}, and adding a regularization term to keep local updates close to the global model \cite{li2020federated}. While these methods mitigate some of the loss in performance, they still only train a single global model that is not optimized for each individual client.

\textbf{Personalized FL} aims to learn a model for each client that is informed by a global model. One approach is to cluster similar clients together and train a separate model for each cluster \cite{briggs2020federated, mansour2020three}. However, identifying clusters can be challenging. Another related approach is multi-task learning, where clients with similar data can share model parameters more extensively \cite{smith2017federated, dinh2021fedu}. There are also regularization-based approaches that train a local model but adapt the loss function to ensure updates remain close to the global model \cite{li2021ditto, t2020pfedme}. Additional hyperparameters add complexity to the training process. In local adaptation, clients fine-tune the global model locally after convergence \cite{yu2020salvaging}. This works well when the global model is already near the optimal local model for each client which may not hold with non-IID data.

\textbf{Partial FL} is a type of personalized FL that involves selectively federating specific subsets of the model, with the remaining parts undergoing local training only. Typically, the early layers are federated and later layers are kept for local training. FedPer trains the full model during local updates but federates only the bottom layers \cite{arivazhagan2019federated}. FedBABU trains and federates the bottom layers while keeping the top layers fixed until convergence \cite{oh2021fedbabu}. FedRep decouples the body and head, jointly training a body to build low-dimensional representations of the data while leaving the head for local training \cite{collins2021exploiting}. One drawback common to these methods is that the layers for federation or local training are pre-determined before the training process begins. This requires prior knowledge or relies on heuristics. Consequently, much of the work is focused on Convolutional Neural Networks (CNNs). Other methods such as FedLP and FedLAMA select layers dynamically during training \cite{zhu2023fedlp, lee2023layer}. However, they primarily address communication cost by limiting the layers sent to federation while maintaining similar performance to FedAvg, \emph{i.e.,} they do not deal with non-IID data. pFedLA introduces personalized layer-wise aggregation to address non-IID data. It achieves this by training server-side hypernetworks for each client, which learn specific aggregation weights for each layer \cite{ma2022layer}. However, the use of hypernetworks introduces additional complexity. Finally, pFedHR proposes server-side model reassembly after grouping functionally related layers \cite{wang2024towards}. However, it requires sharing data, which is often prohibited in cross-silo FL.


\section{Comparing models trained on non-IID data}
\label{sec:gen_sim}
To understand the impact of federated training on non-IID data, we examine generalization metrics on models that are \textbf{identically initialized but trained on non-IID data}. We look at two scenarios, independent and FL training. The former allows us to capture the extent of divergence in the most extreme case, and the latter allows us to capture the typical divergence observed in FL. In Figures \ref{fig:grad_var}-\ref{fig:layer_imp} we present results from the first epoch.  Note, after one epoch (prior to federation), the models from independent and federated training are identical. In Figures \ref{sfig:grad_var_best}-\ref{sfig:layer_imp_best_fl} we present final model results for independent and FL training (the layer-wise pattern of generalization capabilities are the same).

Previous studies have shown that randomly initialized models trained on IID  data follow a similar training trajectory \cite{wang2018towards}. We reverse this analysis by examining the trajectory of identically initialized models trained on non-IID subsets of data. We decompose our analysis to the level of individual layers and identify similarities in the role of each layer across the models. We find that early layers converge to more similar and generalizable solutions, whereas later layers do not. This is similar to the situation of randomly initialized models on the same dataset. Additionally, in most models, we observe a point that we postulate marks the transition from functioning as generalizable feature-extractors to serving as task specific feature utilizers. Importantly, these dynamics emerge just after a single epoch of training and are retained throughout training. Definitions for all metrics are in Section \ref{metric_defn}.

\subsection{Layer generalizability}
Figures \ref{fig:grad_var} and \ref{fig:hess_ev_sum} show the gradient variance (eqn. \ref{eqn:grad_var}) and sum of Hessian eigenvalues (eqn. \ref{eqn:hess_ev}) after one epoch of training for four datasets (independent and FL training are equivalent after one epoch). Refer to Figures \ref{sfig:grad_var_first}- \ref{sfig:hess_eig_best_fl} for comparable analyses for all datasets at the conclusion of independent or FL training. To account for the size of a layer, we divide gradient variance and sum of Hessian eigenvalues by the total number of parameters in that layer. A consistent pattern appears in which both metrics rapidly increase in the final layers (note the log scale). These results suggest that the early layers have a higher generalization capacity, hence less sensitivity to perturbation, than final layers. Although this observation is well-established, it leads to an intriguing implication in the context of FL in non-IID settings: \emph{assuming that the optimal global and client models are in close proximity, we can infer that federating the early layers should, at the very least, \textbf{not negatively impact} a client's performance}. That is, if we consider federated weight aggregation as a form of 'perturbation', then the early layers should continue to reside in locally flat regions of the loss-landscape. The open question is now to determine if global and local models are located in nearby regions. 
\vspace{2mm}
\begin{figure*}[ht!]
\begin{center}
\makebox[\linewidth][c]{  % Center the four subfigures in a line
\begin{minipage}{.22\linewidth}  % Adjust the width to 25% for each subfigure
  \centering
  \raisebox{-\height}{\includegraphics[width=\linewidth]{figures/FMNIST_Gradient_Variance_first-1.png}}
  \makebox[\linewidth][c]{\scriptsize\textit{(A) FashionMNIST}}  % Subfigure label
\end{minipage}%
\begin{minipage}{.22\linewidth}  % Adjust the width to 25% for each subfigure
  \centering
  \raisebox{-\height}{\includegraphics[width=\linewidth]{figures/EMNIST_Gradient_Variance_first-1.png}}
  \makebox[\linewidth][c]{\scriptsize\textit{(B) EMNIST}}  % Subfigure label
\end{minipage}%
\begin{minipage}{.22\linewidth}  % Adjust the width to 25% for each subfigure
  \centering
  \raisebox{-\height}{\includegraphics[width=\linewidth]{figures/CIFAR_Gradient_Variance_first-1.png}}
  \makebox[\linewidth][c]{\scriptsize\textit{(C) CIFAR-10}}  % Subfigure label
\end{minipage}%
\begin{minipage}{.22\linewidth}  % Adjust the width to 25% for each subfigure
  \centering
  \raisebox{-\height}{\includegraphics[width=\linewidth]{figures/mimic_Gradient_Variance_first-1.png}}
  \makebox[\linewidth][c]{\scriptsize\textit{(D) MIMIC-III}}  % Subfigure label
\end{minipage}
}
\caption{\textbf{Layer gradient variance after one epoch}. All models identically initialized and independently trained on non-IID data.}
\label{fig:grad_var}
\end{center}

\end{figure*}


\begin{figure*}[ht]
\begin{center}
\makebox[\linewidth][c]{  % Center the four subfigures in a line
\begin{minipage}{.22\linewidth}  % Adjust the width to 25% for each subfigure
  \centering
  \raisebox{-\height}{\includegraphics[width=\linewidth]{figures/FMNIST_Hessian_EV_sum_first-1.png}}
  \makebox[\linewidth][c]{\scriptsize\textit{(A) FashionMNIST}}  % Subfigure label
\end{minipage}%
\begin{minipage}{.22\linewidth}  % Adjust the width to 25% for each subfigure
  \centering
  \raisebox{-\height}{\includegraphics[width=\linewidth]{figures/EMNIST_Hessian_EV_sum_first-1.png}}
  \makebox[\linewidth][c]{\scriptsize\textit{(B) EMNIST}}  % Subfigure label
\end{minipage}%
\begin{minipage}{.22\linewidth}  % Adjust the width to 25% for each subfigure
  \centering
  \raisebox{-\height}{\includegraphics[width=\linewidth]{figures/CIFAR_Hessian_EV_sum_first-1.png}}
  \makebox[\linewidth][c]{\scriptsize\textit{(C) CIFAR-10}}  % Subfigure label
\end{minipage}%
\begin{minipage}{.22\linewidth}  % Adjust the width to 25% for each subfigure
  \centering
  \raisebox{-\height}{\includegraphics[width=\linewidth]{figures/mimic_Hessian_EV_sum_first-1.png}}
  \makebox[\linewidth][c]{\scriptsize\textit{(D) MIMIC-III}}  % Subfigure label
\end{minipage}
}
\caption{\textbf{Hessian eigenvalue sum after one epoch}. Each model was identically initialized and trained on respective non-IID datasets.}
\label{fig:hess_ev_sum}
\end{center}

\end{figure*}


\subsection{Sample representation}
To determine if global and local models are located in nearby regions, we compare the models' internal, layer-wise representations for a set of samples using Centered Kernel Alignment (see equation \ref{eqn:sample_rep}) \cite{kornblith2019similarity}. Figure \ref{fig:sample_rep} shows the average sample representation for each model \textit{vs.} all other models. That is, we conduct a pairwise comparison of representation similarity across all models and take the average for each model. Again, a consistent pattern appears, in which a large increase in layer representation dissimilarity is observed in the later layers. This also emerges after a single epoch of training and becomes more extreme with more training (for comparable figures at the conclusion of training and all datasets see Figures \ref{sfig:sample_rep_first} and \ref{sfig:sample_rep_best}). This finding suggests that internal representations, and presumably layer weights, show a large divergence at the same point that weights become more sensitive to perturbation. We can now extend our hypothesis: \emph{even in non-IID settings, since the early layers converge to similar solutions, we expect that federating these layers should, at the very least, \textbf{not negatively impact} a client's performance}. Conversely, we can expect that federating later layers may reduce performance as these layers are specific to the clients' dataset distribution.
\vspace{3mm}
\begin{figure*}[ht]
\begin{center}
\makebox[\linewidth][c]{  % Center the four subfigures in a line
\begin{minipage}{.22\linewidth}  % Adjust the width to 25% for each subfigure
  \centering
  \raisebox{-\height}{\includegraphics[width=\linewidth]{figures/FMNIST_similarity_first-1.png}}
  \makebox[\linewidth][c]{\scriptsize\textit{(A) FashionMNIST}}  % Subfigure label
\end{minipage}%
\begin{minipage}{.22\linewidth}  % Adjust the width to 25% for each subfigure
  \centering
  \raisebox{-\height}{\includegraphics[width=\linewidth]{figures/EMNIST_similarity_first-1.png}}
  \makebox[\linewidth][c]{\scriptsize\textit{(B) EMNIST}}  % Subfigure label
\end{minipage}%
\begin{minipage}{.22\linewidth}  % Adjust the width to 25% for each subfigure
  \centering
  \raisebox{-\height}{\includegraphics[width=\linewidth]{figures/CIFAR_similarity_first-1.png}}
  \makebox[\linewidth][c]{\scriptsize\textit{(C) CIFAR-10}}  % Subfigure label
\end{minipage}%
\begin{minipage}{.22\linewidth}  % Adjust the width to 25% for each subfigure
  \centering
  \raisebox{-\height}{\includegraphics[width=\linewidth]{figures/mimic_similarity_first-1.png}}
  \makebox[\linewidth][c]{\scriptsize\textit{(D) MIMIC-III}}  % Subfigure label
\end{minipage}
}
\caption{\textbf{Model representation similarity by layer}. Models identically initialized and independently trained on non-IID data.}
\label{fig:sample_rep}
\end{center}
\end{figure*}

\subsection{Federation sensitivity}
Having established that early layers consistently show greater cross-client generalization, we seek a principled method to identify the transition point between generalizable and client-specific layers across different architectures. While previous work in partial FL has relied on architecture-specific heuristics to select federated layers, we aim to develop a universal, data-driven approach. Our key insight comes from observing that layers with strong cross-client generalization tend to occupy flatter regions of the loss landscape - a property that can be efficiently measured using techniques from model pruning literature. Drawing on this connection, we adapt the concept of parameter importance to quantify each layer's potential for successful federation, which we term the layer's federation sensitivity. We define federation sensitivity of layer $l$, denoted $\mathcal{F}_l(\Theta)$, as:
\begin{equation}
\label{eqn:fo_approx}
    \mathcal{F}_l(\Theta) \triangleq \sum_{k=1}^l \frac{1}{n_k} \sum_{p =1}^{n_k} \mathcal{I}_p(\theta) = \sum_{k=1}^l \frac{1}{n_k} \sum_{p=1}^{n_k} (\theta_p\nabla\theta_p)^2
\end{equation}
where $\Theta$ is the set of all model parameters, $\theta_p$ is parameter $p$ within any given layer $k$, $\nabla\theta_p$ is the gradient with respect to $\theta_p$, and $n_k$ is number of parameters in layer $k$. There are two major differences between our federation sensitivity metric and the parameter importance metric in eqn. \ref{eqn:first_order_approx}. First, we normalize by the number of parameters in each layer ($n_k$) to enable fair comparison across layers of different sizes. This accounts for architectural variations where some layers may have significantly more parameters than others. Second, we incorporate the cumulative contributions of all preceding layers up to layer $l$, reflecting an inherent constraint of partial federation - the selection of any layer for federation necessarily requires including all previous layers. Note that this reinterpretation of parameter importance to federation sensitivity does not require altering the calculation. Given that all parameters are subjected to the same aggregation process, setting a parameter to zero, much like what is done in pruning, can be viewed as an extreme update step during federated training. Therefore, the original metric remains accurate, except for the need to apply a normalizing constant. However, since our focus is on the relative importance between layers, such a normalizing constant is not necessary. Figure \ref{fig:layer_imp} presents results of the federation sensitivity metric after one epoch with values expressed as a \% of federation sensitivity in the first layer (see Figures \ref{sfig:layer_imp_best} and \ref{sfig:layer_imp_best_fl} for federation sensitivity at the conclusion of independent or FL training). We observe a characteristic spike in later layers across all model architectures. Notably, we observe that this spike reliably coincides with the metrics on layer generalizability and sample representation presented in Section \ref{sec:gen_sim}. This metric offers two main advantages. Firstly, it is computationally efficient as the weight and gradient calculations are already performed. Secondly, it shows a remarkably consistent pattern across various model architectures including Fully-Connected Networks (FCNs), CNNs, and Transformers. This consistency makes it broadly applicable to a wide range of tasks and scenarios (Table \ref{supp:layer-table} for details).

\begin{figure}[ht]
\begin{center}

% First four subfigures
\makebox[\linewidth][c]{
\begin{minipage}{.24\linewidth}
  \centering
  \raisebox{-\height}{\includegraphics[width=\linewidth]{figures/FMNIST_Layer_importance_first-1.png}}
  \makebox[\linewidth][c]{\scriptsize\textit{(A) FashionMNIST}}  % Subfigure label
\end{minipage}%
\begin{minipage}{.24\linewidth}
  \centering
  \raisebox{-\height}{\includegraphics[width=\linewidth]{figures/EMNIST_Layer_importance_first-1.png}}
  \makebox[\linewidth][c]{\scriptsize\textit{(B) EMNIST}}  % Subfigure label
\end{minipage}%
\begin{minipage}{.24\linewidth}
  \centering
  \raisebox{-\height}{\includegraphics[width=\linewidth]{figures/CIFAR_Layer_importance_first-1.png}}
  \makebox[\linewidth][c]{\scriptsize\textit{(C) CIFAR-10}}  % Subfigure label
\end{minipage}%
\begin{minipage}{.24\linewidth}
  \centering
  \raisebox{-\height}{\includegraphics[width=\linewidth]{figures/ISIC_Layer_importance_first-1.png}}
  \makebox[\linewidth][c]{\scriptsize\textit{(D) ISIC-2019}}  % Subfigure label
\end{minipage}
}

% Next three subfigures
\makebox[\linewidth][c]{
\begin{minipage}{.24\linewidth}
  \centering
  \raisebox{-\height}{\includegraphics[width=\linewidth]{figures/Sentiment_Layer_importance_first-1.png}}
  \makebox[\linewidth][c]{\scriptsize\textit{(E) Sent-140}}  % Subfigure label
\end{minipage}%
\begin{minipage}{.24\linewidth}
  \centering
  \raisebox{-\height}{\includegraphics[width=\linewidth]{figures/mimic_Layer_importance_first-1.png}}
  \makebox[\linewidth][c]{\scriptsize\textit{(F) MIMIC-III}}  % Subfigure label
\end{minipage}%
\begin{minipage}{.24\linewidth}
  \centering
  \raisebox{-\height}{\includegraphics[width=\linewidth]{figures/Heart_Layer_importance_first-1.png}}
  \makebox[\linewidth][c]{\scriptsize\textit{(G) Fed-Heart-Disease}}  % Subfigure label
\end{minipage}
}
\caption{\textbf{Federation sensitivity after one epoch}. All models identically initialized and trained on non-IID data subsets. Values expressed as \% of first layer value}
\label{fig:layer_imp}
\end{center}
\end{figure} 
\vspace{-5mm}
\section{Proposed Framework}
We propose Principled Layer-wise-FL (PLayer-FL), a partial FL approach that uses federation sensitivity to dynamically determine which layers to federate (Algorithm \ref{alg:PLayer-FL-main}). A key advantage of our method is its computational efficiency - federation sensitivity is calculated during the first epoch of training using weights and gradients that are already computed as part of the standard training process. To identify the transition point between federated and local layers, we compare the relative federation sensitivity between consecutive layers against a threshold $t$ (eqn. \ref{eqn:layer_select}). While this threshold controls how aggressively the algorithm federates layers, with higher values leading to more federated layers, we found in our experiments that the transition point remains stable across a wide range of threshold values (Figure \ref{fig:layer_imp}).

PLayer-FL stands out by offering a light-weight and principled approach for determining the layers to federate during training specifically to address that challenges of non-IID data. Algorithms \ref{alg:PLayer-FL-main} - \ref{alg:layer-split} present the formal pseudocode. For brevity, we omit procedures C\textsc{lient}U\textsc{pdate} and S\textsc{erver}A\textsc{ggregate} that are identical to FedAvg. Note that PLayer-FL conducts simultaneous updates to both the federated and localized layers. However, only the federated layers are sent to the central server for aggregation. We use the same learning rate for both federated and localized training, but this can be altered. Additionally, as our algorithm's sole purpose is to delineate layers to be federated, it can be used in conjunction with other personalized FL algorithms. 

\begin{algorithm}
   \caption{PLayer-FL: Main Algorithm}
   \label{alg:PLayer-FL-main}
\begin{algorithmic}
   \STATE {\bfseries Input:} Number of rounds $N$, set of clients $C$, threshold $t$
   \STATE {\bfseries Output:} Model parameters $\Theta_{c}$ for $c\in C$
   
   \STATE \textbf{Initialize} global model parameters $\Theta^0$
      \FORALL{clients $c \in C$ in parallel}
         \STATE $\Theta^1_{c} \leftarrow$ C\textsc{lient}U\textsc{pdate}($\Theta^0$)
         \STATE Calculate layer federation sensitivity (Algorithm \ref{alg:fed-sensitivity}):
         \STATE $\mathcal{F}(\Theta_c) \leftarrow$ C\textsc{alculate}F\textsc{ed}S\textsc{ensitivity}($\Theta_{c}$)
      \ENDFOR
      \STATE Determine federated and local layers (Algorithm \ref{alg:layer-split}):
      \STATE\hspace{5mm} $\Theta_{fed}, \Theta_{local}$ $\leftarrow \text{L\textsc{ayer}S\textsc{plit}}(\Theta, \{\mathcal{F}(\Theta_c)\}, t)$
    \STATE Execute FL on selected layers:      
   \FOR{$r = 1$ {\bfseries to} $N$}
      \FORALL{clients $c \in C$}
          \STATE $\Theta_{c}^{r} \leftarrow$ C\textsc{lient}U\textsc{pdate}($\Theta^{r}$)
      \ENDFOR
      \STATE $\Theta_{fed}^{r+1} \leftarrow \text{S\textsc{erver}A\textsc{ggregate}}(\{\Theta_{c,fed}^{r}\}, C)$
   \ENDFOR
\end{algorithmic}
\end{algorithm}
\begin{algorithm}
   \caption{PLayer-FL: C\textsc{alculate}F\textsc{ed}S\textsc{ensitivity}}
   \label{alg:fed-sensitivity}
\begin{algorithmic}
\STATE {\bfseries Input:} Client model parameters $\Theta_c$
\STATE {\bfseries Output:} Layer-wise federation sensitivity array $\mathcal{F}(\Theta_c)$
\STATE Initialize $\mathcal{F}(\Theta_c)$ as an empty array
\STATE Let $L$ be the set of all layers in $\Theta_c$
\STATE {\bfseries for all } {layers $l \in L$} {\bfseries do } 
       \INDSTATE Calculate federation sensitivity, $\mathcal{F}_{l}(\Theta_c)$, for layer $l$ as in equation \ref{eqn:fo_approx}
       \INDSTATE Append $\mathcal{F}_{l}(\Theta_c)$ to $\mathcal{F}(\Theta_c)$
\STATE {\bfseries end for }
\STATE {\bfseries Return} $\mathcal{F}(\Theta_c)$ 
\end{algorithmic}
\end{algorithm}
\begin{algorithm}
   \caption{PLayer-FL: \text{L\textsc{ayer}S\textsc{plit}}}
   \label{alg:layer-split}
\begin{algorithmic}
\STATE {\bfseries Input:} Model parameters $\Theta$, client sensitivities $\{\mathcal{F}(\Theta_c)\}$, threshold $t$
\STATE {\bfseries Output:} Federated layers $\Theta_{fed}$, local layers $\Theta_{local}$
   \STATE Aggregate client federation sensitivities:
   \STATE \hspace{5mm} $\mathcal{F}(\Theta) \leftarrow \sum^C_{c=1} \mathcal{F}(\Theta_c)$
   \STATE Find transition point $p$ where relative sensitivity exceeds threshold $t$:
   \STATE \vspace{-4mm}\begin{equation}  \hspace{-15mm}
       p \leftarrow \min \{p: \mathcal{F}_{p+1}(\Theta_c) \mathcal{F}_p(\Theta) > t \}
       \label{eqn:layer_select}
   \end{equation}
   \vspace{-5mm}
   \STATE Partition model at point $p$:
   \STATE \hspace{5mm} $\Theta_{fed} \leftarrow \Theta_{l \leq p}$, $\Theta_{local} \leftarrow \Theta_{l > p}$
   \STATE {\bfseries Return} $\Theta_{fed}, \Theta_{local}$  
\end{algorithmic}
\end{algorithm}

PLayer-FL has the same computational complexity as FedAvg. This is because, compared to FedAvg, PLayer-FL introduces two procedures, both executed once during training: C\textsc{alculate}F\textsc{ed}S\textsc{ensitivity} (Algorithm \ref{alg:fed-sensitivity} and L\textsc{ayer}S\textsc{plit} (Algorithm \ref{alg:layer-split} with computational complexity of $O(P)$, where $P$ is the number of parameters, and $O(L)$, where $L$ is the number of layers, respectively.


\section{Evaluation}
\label{evaluation}
\subsection{Methods}
Our setup focuses on cross-silo FL: we use highly non-IID datasets from a limited number of clients, all of whom have sufficient data to train a local model and are available for each round of training (see Section\ref{background:cross_fl} for justification).

\subsubsection{Datasets}
We evaluate performance on FashionMNIST, ExtendedMNIST, CIFAR-10, ISIC2019, Fed-Heart-Disease, Sentiment-140 and MIMIC-III. The datasets cover tabular, imaging, and natural language modalities. The first three datasets do not have a natural partition, thus we introduce label skew using a Dirichlet distribution ($\alpha=0.5$) following \citet{li2022federated}. The other datasets have natural partitions:
\begin{itemize}[nosep, leftmargin=*]
    \item Fed-ISIC-2019 \cite{terrail2022flamby}: Dermoscopy skin lesion classification (4 classes); partitioned by hospital.
    \item Fed-Heart-Disease \cite{terrail2022flamby}: Patient heart disease classification (5 classes); partitioned by hospital.
    \item Sent-140 \cite{caldas2018leaf}: Classification of tweet sentiments; partitioned by users, selecting the top 15 users. 
    \item MIMIC-III \cite{johnson2016mimic}: Mortality prediction using hospital admission notes; partitioned by diagnosis. 
\end{itemize}

\subsubsection{Performance}
We evaluate our method against three categories of baselines: (1) standard approaches - local site training and FedAvg \cite{mcmahan2017communication}, (2) established personalized FL algorithms - FedProx \cite{li2020federated}, pFedMe \cite{t2020pfedme}, Ditto \cite{li2021ditto}, and Local Adaptation \cite{yu2020salvaging}, and (3) existing partial FL methods - FedBABU \cite{oh2021fedbabu}, FedLP \cite{zhu2023fedlp}, FedLAMA \cite{lee2023layer}, and pFedLA \cite{ma2022layer}. We also evaluate PLayer-FL-Random, which federate up to a randomly selected layer. This serves as proxy for \textbf{non-principled} partial FL approaches. Full training and evaluation details are in Section \ref{supp:model_training}.

We evaluate performance using F1 score (macro-averaged \emph{i.e.,} treating each label equally, see eqn. \ref{eqn:f1}), accuracy, and test loss. The macro-F1 score serves as our primary metric due to its robustness to class imbalance. Results for accuracy and test loss are presented in Sections \ref{supp:accuracy_results} and \ref{supp:loss_results}. For personalized FL algorithms, we also study per-site metrics. This is important as personalized models that achieve the highest average performance may not necessarily uniformly benefit every site \cite{divi2021new}. To evaluate fairness, we compare the variance in performance across clients (eqn. \ref{eqn:fairness}) \cite{divi2021new}. We also evaluate participation incentive by calculating the percentage of clients where performance surpasses both local site training and FedAvg (eqn. \ref{eqn:incentive}) \cite{cho2022federate}. If our intuition that federating generalizable layers should not negatively impact performance holds true, we anticipate our method to exhibit high fairness and participation incentive. To make conclusions across multiple datasets, we use the Friedman test \cite{demvsar2006statistical}.

\subsection{Results}
\vspace{-5mm}
\begin{table*}[htbp]
\caption{Macro-averaged F1 Score and average rank. In \textbf{bold} is top-performing model. Friedman rank test p-value $<5\times10^{-3}$}
\label{f1-table}
\begin{center}
\setlength{\tabcolsep}{5.3pt}
\begin{tabular}{lcccccccc}
\toprule
Algorithm & FMNIST & EMNIST & CIFAR & ISIC & Heart & Sentiment & mimic & Mean Rank \\
\midrule
Local & \specialcell{75.9}{1.6} & \specialcell{56.9}{1.4} & \specialcell{61.6}{3.2} & \textbf{\specialcell{53.1}{1.3}} & \textbf{\specialcell{42.0}{0.8}} & \specialcell{57.4}{1.0} & \specialcell{58.6}{1.5} & 6.9 \\
FedAvg & \specialcell{75.6}{1.8} & \specialcell{64.2}{1.1} & \specialcell{65.4}{4.5} & \specialcell{43.3}{0.7} & \specialcell{40.4}{1.0} & \specialcell{52.6}{0.3} & \specialcell{63.0}{1.7} & 6.0 \\
FedProx & \specialcell{76.4}{1.8} & \specialcell{65.3}{1.9} & \specialcell{65.8}{4.9} & \specialcell{40.6}{2.6} & \specialcell{37.2}{1.6} & \specialcell{52.6}{0.3} & \specialcell{63.2}{0.8} & 6.3 \\
pFedMe & \specialcell{77.3}{1.8} & \specialcell{66.2}{0.7} & \specialcell{48.9}{2.5} & \specialcell{44.9}{2.6} & \specialcell{42.5}{0.8} & \specialcell{58.9}{0.4} & \specialcell{60.9}{0.4} & 5.3 \\
Ditto & \specialcell{77.8}{1.2} & \specialcell{61.6}{0.8} & \specialcell{48.7}{1.9} & \specialcell{43.4}{0.7} & \specialcell{40.7}{1.0} & \specialcell{58.9}{0.9} & \specialcell{61.0}{0.5} & 6.0 \\
LocalAdaptation & \specialcell{76.9}{1.5} & \specialcell{63.8}{1.8} & \specialcell{65.5}{3.3} & \specialcell{43.5}{1.9} & \specialcell{39.8}{0.9} & \specialcell{53.2}{0.6} & \specialcell{62.6}{1.6} & 6.4 \\
FedBABU & \specialcell{77.2}{1.0} & \textbf{\specialcell{66.1}{0.2}} & \textbf{\specialcell{67.7}{4.0}} & \specialcell{49.1}{3.5} & \specialcell{40.3}{0.8} & \specialcell{58.3}{0.2} & \specialcell{62.7}{0.4} & 4.1 \\
FedLP & \specialcell{77.2}{1.3} & \specialcell{64.1}{0.9} & \specialcell{63.7}{5.1} & \specialcell{40.2}{2.1} & \specialcell{40.1}{1.0} & \specialcell{54.4}{1.1} & \specialcell{62.1}{1.3} & 6.7 \\
FedLama & \specialcell{71.6}{1.7} & \specialcell{56.9}{1.3} & \specialcell{41.8}{3.0} & \specialcell{36.0}{1.1} & \specialcell{39.7}{0.8} & \specialcell{50.3}{0.4} & \textbf{\specialcell{66.7}{1.0}} & 10.1 \\
pFedLA & \specialcell{47.1}{0.9} & \specialcell{07.1}{0.0} & \specialcell{10.5}{1.6} & \specialcell{28.4}{1.9} & \specialcell{40.1}{0.8} & \specialcell{50.3}{0.4} & \specialcell{65.0}{2.6} & 11.4 \\
\midrule
PLayer-FL & \textbf{\specialcell{79.3}{1.4}} & \specialcell{62.2}{1.2} & \specialcell{67.1}{3.7} & \specialcell{52.1}{1.5} & \specialcell{41.9}{1.0} & \textbf{\specialcell{59.6}{1.2}} & \specialcell{63.0}{0.7} & \textbf{2.6} \\
PLayer-FL-Random & \specialcell{76.5}{2.3} & \specialcell{57.1}{1.1} & \specialcell{65.7}{2.3} & \specialcell{52.1}{1.5} & \specialcell{41.3}{0.9} & \specialcell{55.7}{0.9} & \specialcell{61.0}{1.4} & 6.1 \\
\bottomrule
\end{tabular}
\end{center}
\end{table*}


Table \ref{f1-table} presents the F1 scores and average ranks across all datasets (with accuracy and loss results shown in Tables \ref{supp:acc-table} and \ref{supp:loss-table}, respectively; \textbf{the conclusions remain consistent across metrics}). PLayer-FL achieves the highest mean rank with statistical significance ($p<5\times10^{-3}$), demonstrating consistently competitive performance across various model architectures even when not achieving the top score in individual cases. These results highlight PLayer-FL's versatility and robustness across diverse tasks and realistic non-IID conditions, while maintaining computational efficiency and implementation simplicity.

PLayer-FL also excels in fairness and participation incentive metrics, achieving the highest average rank in both categories (Table \ref{rank-table}, full results in Tables \ref{supp:fairness-table} and \ref{supp:incentive-table}). This aligns with our core intuition that federating early, generalizable layers should maintain or enhance client performance. The superiority of PLayer-FL over PLayer-FL-Random indicates that federating up to the specific layer identified by federation sensitivity offers advantages beyond those provided by general partial FL approaches. These empirical results validate federation sensitivity as an effective guiding principle for partial model federation.

Notably, in line with typical observations in cross-silo FL settings where data is highly non-IID \citep{huang2022cross}, local site training is competitive when compared to FL algorithms, as each site can effectively train its own model.

\begin{table}[htbp]
\centering
\caption{Fairness and incentivization average ranks, Friedman rank test p-value $<5\times10^{-3}$ and $=0.043$, respectively}
\label{rank-table}
\setlength{\tabcolsep}{2.7pt}
\begin{tabular}{lcc}
\toprule
Algorithm & Fairness & Incentivization \\ 
\midrule
FedProx           & 7.7 & 5.4 \\
pFedMe            & 4.3 & 5.1 \\
Ditto             & 5.0 &  5.6 \\
LocalAdaptation   & 6.4 & 5.2 \\
FedBABU           & 4.4 &  4.4 \\
FedLP             & 6.1 &  6.2 \\
FedLAMA           & 5.6 & 7.3 \\
pFedLA            & 5.1 &  7.7 \\
\midrule
PLayer-FL          & \textbf{3.8} &  \textbf{3.4} \\
PLayer-FL-Random       & 6.5 &  4.8 \\
\bottomrule
\end{tabular}
\end{table}


\section{Conclusion}
In this work, we present PLayer-FL, a principled partial FL algorithm that uses a novel federation sensitivity metric to determine which layers to federate and which to locally train. We show that this metric correlates with known measures of generalizability and model similarity and that it emerges after only one epoch of training. As such, it can be readily incorporated into the training algorithm with minimal computational overhead. Over a set of rigorous experiments that include benchmark and real-world datasets, we show that PLayer-FL outperforms existing algorithms in cross-silo settings. We also show that it produces fairer outcomes and is more likely to incentivize participation in FL.

\textbf{Limitations}: Our work demonstrates strong empirical evidence for the federation sensitivity metric across diverse model architectures but currently lacks theoretical guarantees.However, the success of similar metrics in related fields and the established understanding of generalizable versus task-specific layers reinforces the validity and utility of our approach. Developing formal theoretical foundations presents a promising direction for future research. Additionally, our study primarily focuses on cross-silo FL, where clients have sufficient data to calculate federation sensitivity, rather than the cross-device setting. However, this focus is deliberate, as cross-silo FL represents a significant sub-field with critical applications in industries like healthcare. These settings face unique challenges, making the development of tailored method essential \cite{terrail2022flamby, huang2022cross, kairouz2021advances, pati2021federated}.


\section*{Impact Statement} This work contributes to Federated Learning. As the work can be applied to sensitive domains like healthcare, there are many potential societal consequences to consider. We believe these are well established and there are none which we feel must be specifically highlighted here.

\bibliographystyle{plainnat}
\bibliography{bibliography}


%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% APPENDIX
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\newpage
\appendix
\onecolumn
\renewcommand{\thetable}{A.\arabic{table}}
\renewcommand{\thefigure}{A.\arabic{figure}}
\renewcommand{\theequation}{A.\arabic{equation}} 
\renewcommand{\thesection}{A.\arabic{section}}
\setcounter{section}{0}
\setcounter{table}{0}
\setcounter{figure}{0}
\setcounter{equation}{0}

\section{Metric definitions}
\label{metric_defn}
\subsection{Gradient variance}
Gradient variance is proposed by \citet{jiang2019fantastic} and is defined as:
\begin{equation}
\label{eqn:grad_var}
    \text{Var}(\nabla\theta_i):=\frac{1}{n}\sum_{j=1}^n\left( \nabla\theta_i^j - \overline{\nabla\theta_i}  \right)^T\left( \nabla\theta_i^j - \overline{\nabla\theta_i}  \right)
\end{equation}
where $\theta_i^j$ is parameter $j$ in layer $i$, $ \nabla\theta_i^j$ is the gradient with respect to that parameter and $\overline{\nabla\theta_i}$ is the mean gradient of all parameters in layer $i$.
\subsection{Hessian eigenvalue sum}
Hessian eigenvalue sum is proposed by \citet{chaudhari2019entropy}. The Hessian at layer $i$, denoted $H_i$, is a square matrix of second-order partial derivatives with respect to parameters at layer $i$. Each entry in $H_i$ is defined as:
\begin{equation*}
    (H_i)_{jk} = \frac{\partial^2L}{\partial\theta_i^j\partial\theta_i^k}
\end{equation*}
where $\theta_i^j$ and $\theta_i^k$ are parameters $j$ and $k$ in layer $i$, $L$ is the loss and $\partial.$ is the partial derivative with respect to that parameter. The sum of the eigenvalues is then calculated as:
\begin{equation}
\label{eqn:hess_ev}
    \text{Tr}(H_i) = \sum_{p=1}^n \lambda_i^p
\end{equation}
where $\lambda_i^p$ is the $p^{th}$ eigenvalue of $H_i$.

\subsection{Sample representation similarity}
Sample representation similarity is calculated via Centered Kernel Alignment (CKA) which is proposed by \citet{kornblith2019similarity}. Its calculated as:
\begin{equation}
\label{eqn:sample_rep}
    \frac{||Y_i^TX_i||_F^2}{||X_i^TX_i||_F^2||Y_i^TY_i||_F^2}
\end{equation}
where $X_i$ and $Y_i$ are sample representations after layer $i$ coming from two distinct models.

\subsection{F1 score}
Multi-class  macro-averaged F1 score is calculated as
\begin{equation}
\label{eqn:f1}
\text{F1}_{\text{macro}} = \frac{1}{N}\sum_{i=1}^N 2 \cdot \frac{\text{precision}_i \cdot \text{recall}_i}{\text{precision}_i + \text{recall}_i}
\end{equation}
where $N$ is the number of classes, and precision$_i$ and recall$_i$ are the precision and recall for class $i$. This equation gives equal weight to all classes which is useful in imbalanced datasets like ours.

\subsection{Algorithm Fairness}
Fairness is calculated as described in \cite{divi2021new} - the variance in individual client performances on their local test set:
\begin{equation}
\label{eqn:fairness}
\text{Fairness} = \frac{1}{C}\sum_{c=1}^C \left( P_c - \overline{P_c}\right)^2
\end{equation}
where $C$ is the number of clients, $P_c$ is the performance of client $c$ and $\overline{P_c}$ is the average performance of all clients for a given personalized algorithm.

\subsection{Algorithm Incentivization}
Incentivization is defined as in \cite{cho2022federate} - the percentage of clients that outperform their local site model or global model from FedAvg:
\begin{equation}
\label{eqn:incentive}
\text{Incentivization} = \frac{1}{C}\sum_{c=1}^C \mathbb{I} \{ P_c > \max(S_c, G_c) \}
\end{equation}
where $C$ is the number of clients, $P_c$ is performance of the personalized model in client $c$, $S_c$ is the performance of the local site model in client $c$, and $G_c$ is the performance of the global Fed Avg model in client $c$
\section{Datasets}
Table \ref{supp:dataset-table} provides a description of the datasets which include: 4 image, 1 tabular and 2 NLP tasks. For FashionMNIST, EMNIST, and CIFAR-10 we create non-IID datasets by via label skew using a a dirichlet distribution ($\alpha = 0.5)$. The remaining datasets have a natural partition that we adhere to. For Sent-140 we select the top 15 users by tweet count. 

\begin{table}[ht]
\caption{Dataset descriptions}
\label{supp:dataset-table}
\begin{center}
\begin{small}
\begin{tabular}{l p{4.5cm} l p{4.5cm}}
\toprule
Dataset & Description & Classes & Partition \\
\midrule
FashionMNIST    & Fashion images & 10 & Label skew $Dir \sim (0.5)$  \\
EMNIST & Handwritten digit and character images  & 62 &  Label skew $Dir \sim (0.5)$ \\
CIFAR-10    & Color images & 10 & Label skew $Dir \sim (0.5)$ \\
ISIC-2019    & Skin lesion images taken via dermoscopy & 4 &  Data collected from 4 hospitals     \\
Fed-Heart-Disease    & Tabular data of patients with heart disease & 5 & Data collected from 5 hospitals \\
Sent-140     & Sentiment classification of tweets & 2 & Data collected from 15 users \\
MIMIC-III      & Mortality prediction using patient admission note & 2  & Data grouped by patient admitting diagnosis  \\
\bottomrule
\end{tabular}
\end{small}
\end{center}
\end{table}

\section{Model architectures and Transition point}
Table \ref{supp:layer-table} shows the model architecture and transition point identified by the federation sensitivity metric for each dataset. Of note, 

\begin{table}[ht]
\centering
\caption{Model architectures and transition points identified by federation sensitivity metric.}
\label{supp:layer-table}
\begin{small}
\begin{tabular}{lcc}
\toprule
Dataset & Architecture & Transition Point \\ 
\midrule
FashionMNIST & \{3$\times$Conv-2$\times$FC\} & Conv$_3$ \\
EMNIST & \{3$\times$Conv-2$\times$FC\} & Conv$_3$ \\
CIFAR-10 & \{5$\times$Conv-2$\times$FC\} & Conv$_5$ \\
ISIC-2019 & \{5$\times$Conv-2$\times$FC\} & Conv$_5$ \\
Sent-140 & \{Position$\oplus$Token Emb-Attention$\oplus$Residual-FC$\oplus$Projection-FC\} & FC$_1\oplus$Projection  \\
MIMIC-III & \{Position$\oplus$Token  Emb-Attention$\oplus$Residual-FC$\oplus$Projection-FC\} & FC$_1\oplus$Projection \\
Fed-Heart & \{4$\times$ FC\} & FC$_2$ \\
\bottomrule
\end{tabular}
\\
\footnotesize{*FC = Fully connected layer}
\end{small}
\end{table}

\section{Model training}
\label{supp:model_training}
Table \ref{supp:lr} presents the learning rates utilized for each algorithm and Table \ref{supp:hyperparams} presents the learning rate grid explored, in addition to the loss function, the number of training epochs, and the count of independent training runs. With the exception of pFedME, the AdamW optimizer was used for all algorithms. For pFedME, we adopted the specific optimizer presented by the original authors, which integrates Moreau envelopes into the training process \cite{t2020pfedme}. To account for this, we multiply the learning rate grid tested by 100 as early testing showed the pFedME optimizer demonstrated improved performance with higher learning rates. All experiments were ran on 1 Tesla V100  16GB node.

\begin{table}[ht!]
\caption{Learning rates used}
\label{supp:lr}

\begin{center}
\begin{small}
\begin{tabular}{lccccccc}
\toprule
Algorithm & FMNIST & EMNIST & CIFAR & ISIC & Heart & Sent-140 & MIMIC-III \\ 
\midrule
Local client &  $1\cdot 10^{-3}$ & $1\cdot 10^{-3}$ & $1\cdot 10^{-3}$ & $1\cdot 10^{-3}$ & $5\cdot 10^{-2}$ & $5\cdot 10^{-4}$ & $8\cdot 10^{-5}$  \\
FedAvg &  $5\cdot 10^{-4}$ & $1\cdot 10^{-3}$ & $1\cdot 10^{-3}$ & $1\cdot 10^{-3}$ & $1\cdot 10^{-1}$ & $1\cdot 10^{-3}$ & $5\cdot 10^{-4}$ \\
FedProx &  $5\cdot 10^{-4}$ & $5\cdot 10^{-3}$ & $1\cdot 10^{-3}$ & $1\cdot 10^{-3}$ & $5\cdot 10^{-2}$ & $1\cdot 10^{-3}$ & $5\cdot 10^{-4}$ \\
pFedMe & $5\cdot 10^{-2}$ & $5\cdot 10^{-2}$ & $5\cdot 10^{-2}$ & $5\cdot 10^{-3}$ & $1\cdot 10^{-1}$ & $1\cdot 10^{-2}$ & $1\cdot 10^{-3}$ \\
Ditto &  $5\cdot 10^{-4}$ & $1\cdot 10^{-3}$ & $1\cdot 10^{-3}$ & $1\cdot 10^{-3}$ & $5\cdot 10^{-2}$ & $1\cdot 10^{-3}$ & $5\cdot 10^{-4}$ \\
LocalAdaptation &  $5\cdot 10^{-4}$ & $1\cdot 10^{-3}$ & $1\cdot 10^{-3}$ & $1\cdot 10^{-3}$ & $1\cdot 10^{-2}$ & $1\cdot 10^{-3}$ & $5\cdot 10^{-4}$ \\
BABU &  $1\cdot 10^{-3}$ & $1\cdot 10^{-3}$ & $5\cdot 10^{-4}$ & $1\cdot 10^{-3}$ & $1\cdot 10^{-1}$ & $8\cdot 10^{-5}$ & $5\cdot 10^{-4}$ \\
PLayer-FL &  $1\cdot 10^{-3}$ & $1\cdot 10^{-3}$ & $1\cdot 10^{-3}$ & $5\cdot 10^{-4}$ & $1\cdot 10^{-2}$ & $8\cdot 10^{-5}$ & $3\cdot 10^{-4}$ \\
PLayer-FL-1 & $1\cdot 10^{-3}$ & $5\cdot 10^{-4}$ & $1\cdot 10^{-3}$ & $5\cdot 10^{-4}$ & $5\cdot 10^{-2}$ & $8\cdot 10^{-5}$ & $8\cdot 10^{-5}$ \\
PLayer-FL+1 & $1\cdot 10^{-3}$ & $1\cdot 10^{-3}$ & $5\cdot 10^{-4}$ & $1\cdot 10^{-3}$ & $5\cdot 10^{-2}$ & $1\cdot 10^{-4}$ & $5\cdot 10^{-4}$ \\
\bottomrule
\end{tabular}
\end{small}
\end{center}
\end{table}

\begin{table}
\centering
\caption{Learning rate grid, loss function, number of epochs and number of runs for each dataset}
\label{supp:hyperparams}
\begin{small}
\begin{tabular}{l p{6cm} ccc}
\toprule
Dataset & Learning rate grid & Loss & Epochs & Runs\\ 
\midrule
FashionMNIST & $1\cdot10^{-3}$, $5\cdot10^{-4}$, $1\cdot10^{-4}$, $8\cdot10^{-5}$ & Cross Entropy & 75 & 10\\
EMNIST & $5\cdot10^{-3}$, $1\cdot10^{-3}$, $5\cdot10^{-4}$, $1\cdot10^{-4}$, $8\cdot10^{-5}$ &Cross Entropy& 75 & 10\\
CIFAR-10 & $5\cdot10^{-3}$, $1\cdot10^{-3}$, $5\cdot10^{-4}$, $1\cdot10^{-4}$ & Cross Entropy& 50 & 10\\
ISIC-2019 & $1\cdot10^{-3}$, $5\cdot10^{-3}$, $1\cdot10^{-4}$ & Multiclass Focal & 50 & 3\\
Sent-140 & $1\cdot10^{-3}$, $5\cdot10^{-4}$, $1\cdot10^{-4}$, $8\cdot10^{-5}$ & Cross Entropy & 75 & 20\\
Heart & $5\cdot10^{-1}$, $1\cdot10^{-1}$, $5\cdot10^{-2}$, $1\cdot10^{-2}$, $5\cdot10^{-3}$ & Multiclass Focal& 50 & 50 \\
MIMIC-III & $5\cdot10^{-4}$, $1\cdot10^{-4}$, $3\cdot10^{-4}$, $8\cdot10^{-5}$ & Multiclass Focal& 50 & 10\\
\bottomrule
\end{tabular}
\end{small}
\end{table}

\section{Comparing models trained on non-IID data}

\subsection{Gradient variance}
Figures \ref{sfig:grad_var_first}, \ref{sfig:grad_var_best}, and \ref{sfig:grad_var_best_fl} display the gradient variance across all datasets, corresponding to the models trained for a single epoch, final model after independent training, and final model after FL training, respectively.

\begin{figure}[ht]

\begin{center}

% First four subfigures
\makebox[\linewidth][c]{
\begin{minipage}{.24\linewidth}
  \centering
  \raisebox{-\height}{\includegraphics[width=\linewidth]{figures/FMNIST_Gradient_Variance_first-1.png}}
  \makebox[\linewidth][c]{\scriptsize\textit{(A) FashionMNIST}}  % Subfigure label
\end{minipage}%
\begin{minipage}{.24\linewidth}
  \centering
  \raisebox{-\height}{\includegraphics[width=\linewidth]{figures/EMNIST_Gradient_Variance_first-1.png}}
  \makebox[\linewidth][c]{\scriptsize\textit{(B) EMNIST}}  % Subfigure label
\end{minipage}%
\begin{minipage}{.24\linewidth}
  \centering
  \raisebox{-\height}{\includegraphics[width=\linewidth]{figures/CIFAR_Gradient_Variance_first-1.png}}
  \makebox[\linewidth][c]{\scriptsize\textit{(C) CIFAR-10}}  % Subfigure label
\end{minipage}%
\begin{minipage}{.24\linewidth}
  \centering
  \raisebox{-\height}{\includegraphics[width=\linewidth]{figures/ISIC_Gradient_Variance_first-1.png}}
  \makebox[\linewidth][c]{\scriptsize\textit{(D) ISIC-2019}}  % Subfigure label
\end{minipage}
}
\makebox[\linewidth][c]{
\begin{minipage}{.24\linewidth}
  \centering
  \raisebox{-\height}{\includegraphics[width=\linewidth]{figures/Sentiment_Gradient_Variance_first-1.png}}
  \makebox[\linewidth][c]{\scriptsize\textit{(E) Sent-140}}  % Subfigure label
\end{minipage}%
\begin{minipage}{.24\linewidth}
  \centering
  \raisebox{-\height}{\includegraphics[width=\linewidth]{figures/mimic_Gradient_Variance_first-1.png}}
  \makebox[\linewidth][c]{\scriptsize\textit{(F) MIMIC-III}}  % Subfigure label
\end{minipage}%
\begin{minipage}{.24\linewidth}
  \centering
  \raisebox{-\height}{\includegraphics[width=\linewidth]{figures/Heart_Gradient_Variance_first-1.png}}
  \makebox[\linewidth][c]{\scriptsize\textit{(G) Fed-Heart-Disease}}  % Subfigure label
\end{minipage}
}

\caption{\textbf{Layer gradient variance after one epoch}. All models identically initialized and independently trained on non-IID data.}
\label{sfig:grad_var_first}
\end{center}

\end{figure}


\begin{figure}[ht]

\begin{center}

% First four subfigures
\makebox[\linewidth][c]{
\begin{minipage}{.24\linewidth}
  \centering
  \raisebox{-\height}{\includegraphics[width=\linewidth]{figures/FMNIST_Gradient_Variance_best-1.png}}
  \makebox[\linewidth][c]{\scriptsize\textit{(A) FashionMNIST}}  % Subfigure label
\end{minipage}%
\begin{minipage}{.24\linewidth}
  \centering
  \raisebox{-\height}{\includegraphics[width=\linewidth]{figures/EMNIST_Gradient_Variance_best-1.png}}
  \makebox[\linewidth][c]{\scriptsize\textit{(B) EMNIST}}  % Subfigure label
\end{minipage}%
\begin{minipage}{.24\linewidth}
  \centering
  \raisebox{-\height}{\includegraphics[width=\linewidth]{figures/CIFAR_Gradient_Variance_best-1.png}}
  \makebox[\linewidth][c]{\scriptsize\textit{(C) CIFAR-10}}  % Subfigure label
\end{minipage}%
\begin{minipage}{.24\linewidth}
  \centering
  \raisebox{-\height}{\includegraphics[width=\linewidth]{figures/ISIC_Gradient_Variance_best-1.png}}
  \makebox[\linewidth][c]{\scriptsize\textit{(D) ISIC-2019}}  % Subfigure label
\end{minipage}
}
\makebox[\linewidth][c]{
\begin{minipage}{.24\linewidth}
  \centering
  \raisebox{-\height}{\includegraphics[width=\linewidth]{figures/Sentiment_Gradient_Variance_best-1.png}}
  \makebox[\linewidth][c]{\scriptsize\textit{(E) Sent-140}}  % Subfigure label
\end{minipage}%
\begin{minipage}{.24\linewidth}
  \centering
  \raisebox{-\height}{\includegraphics[width=\linewidth]{figures/mimic_Gradient_Variance_best-1.png}}
  \makebox[\linewidth][c]{\scriptsize\textit{(F) MIMIC-III}}  % Subfigure label
\end{minipage}%
\begin{minipage}{.24\linewidth}
  \centering
  \raisebox{-\height}{\includegraphics[width=\linewidth]{figures/Heart_Gradient_Variance_best-1.png}}
  \makebox[\linewidth][c]{\scriptsize\textit{(G) Fed-Heart-Disease}}  % Subfigure label
\end{minipage}
}

\caption{\textbf{Layer gradient variance for final models}. All models identically initialized and independently trained on non-IID data.}
\label{sfig:grad_var_best}
\end{center}

\end{figure}

\begin{figure}[ht]

\begin{center}

% First four subfigures
\makebox[\linewidth][c]{
\begin{minipage}{.24\linewidth}
  \centering
  \raisebox{-\height}{\includegraphics[width=\linewidth]{figures/FMNIST_Gradient_Variance_best_federated-1.png}}
  \makebox[\linewidth][c]{\scriptsize\textit{(A) FashionMNIST}}  % Subfigure label
\end{minipage}%
\begin{minipage}{.24\linewidth}
  \centering
  \raisebox{-\height}{\includegraphics[width=\linewidth]{figures/EMNIST_Gradient_Variance_best_federated-1.png}}
  \makebox[\linewidth][c]{\scriptsize\textit{(B) EMNIST}}  % Subfigure label
\end{minipage}%
\begin{minipage}{.24\linewidth}
  \centering
  \raisebox{-\height}{\includegraphics[width=\linewidth]{figures/CIFAR_Gradient_Variance_best_federated-1.png}}
  \makebox[\linewidth][c]{\scriptsize\textit{(C) CIFAR-10}}  % Subfigure label
\end{minipage}%
\begin{minipage}{.24\linewidth}
  \centering
  \raisebox{-\height}{\includegraphics[width=\linewidth]{figures/ISIC_Gradient_Variance_best_federated-1.png}}
  \makebox[\linewidth][c]{\scriptsize\textit{(D) ISIC-2019}}  % Subfigure label
\end{minipage}
}
\makebox[\linewidth][c]{
\begin{minipage}{.24\linewidth}
  \centering
  \raisebox{-\height}{\includegraphics[width=\linewidth]{figures/Sentiment_Gradient_Variance_best_federated-1.png}}
  \makebox[\linewidth][c]{\scriptsize\textit{(E) Sent-140}}  % Subfigure label
\end{minipage}%
\begin{minipage}{.24\linewidth}
  \centering
  \raisebox{-\height}{\includegraphics[width=\linewidth]{figures/mimic_Gradient_Variance_best_federated-1.png}}
  \makebox[\linewidth][c]{\scriptsize\textit{(F) MIMIC-III}}  % Subfigure label
\end{minipage}%
\begin{minipage}{.24\linewidth}
  \centering
  \raisebox{-\height}{\includegraphics[width=\linewidth]{figures/Heart_Gradient_Variance_best_federated-1.png}}
  \makebox[\linewidth][c]{\scriptsize\textit{(G) Fed-Heart-Disease}}  % Subfigure label
\end{minipage}
}

\caption{\textbf{Layer gradient variance for final models}. Models trained via FL on non-IID data.}
\label{sfig:grad_var_best_fl}
\end{center}

\end{figure}


\subsection{Hessian eigenvalue sum}

Figures \ref{sfig:hess_eig_first}, \ref{sfig:hess_eig_best}, and \ref{sfig:hess_eig_best_fl} display the hessian eigenvalue sum across all datasets, corresponding to the models trained for a single epoch, final model after independent training, and final model after FL training, respectively.

\begin{figure}[ht]

\begin{center}

% First four subfigures
\makebox[\linewidth][c]{
\begin{minipage}{.24\linewidth}
  \centering
  \raisebox{-\height}{\includegraphics[width=\linewidth]{figures/FMNIST_Hessian_EV_sum_first-1.png}}
  \makebox[\linewidth][c]{\scriptsize\textit{(A) FashionMNIST}}  % Subfigure label
\end{minipage}%
\begin{minipage}{.24\linewidth}
  \centering
  \raisebox{-\height}{\includegraphics[width=\linewidth]{figures/EMNIST_Hessian_EV_sum_first-1.png}}
  \makebox[\linewidth][c]{\scriptsize\textit{(B) EMNIST}}  % Subfigure label
\end{minipage}%
\begin{minipage}{.24\linewidth}
  \centering
  \raisebox{-\height}{\includegraphics[width=\linewidth]{figures/CIFAR_Hessian_EV_sum_first-1.png}}
  \makebox[\linewidth][c]{\scriptsize\textit{(C) CIFAR-10}}  % Subfigure label
\end{minipage}%
\begin{minipage}{.24\linewidth}
  \centering
  \raisebox{-\height}{\includegraphics[width=\linewidth]{figures/ISIC_Hessian_EV_sum_first-1.png}}
  \makebox[\linewidth][c]{\scriptsize\textit{(D) ISIC-2019}}  % Subfigure label
\end{minipage}
}
\makebox[\linewidth][c]{
\begin{minipage}{.24\linewidth}
  \centering
  \raisebox{-\height}{\includegraphics[width=\linewidth]{figures/Sentiment_Hessian_EV_sum_first-1.png}}
  \makebox[\linewidth][c]{\scriptsize\textit{(E) Sent-140}}  % Subfigure label
\end{minipage}%
\begin{minipage}{.24\linewidth}
  \centering
  \raisebox{-\height}{\includegraphics[width=\linewidth]{figures/mimic_Hessian_EV_sum_first-1.png}}
  \makebox[\linewidth][c]{\scriptsize\textit{(F) MIMIC-III}}  % Subfigure label
\end{minipage}%
\begin{minipage}{.24\linewidth}
  \centering
  \raisebox{-\height}{\includegraphics[width=\linewidth]{figures/Heart_Hessian_EV_sum_first-1.png}}
  \makebox[\linewidth][c]{\scriptsize\textit{(G) Fed-Heart-Disease}}  % Subfigure label
\end{minipage}
}

\caption{\textbf{Layer hessian eigenvalue sum after one epoch}. All models identically initialized and independently trained on non-IID data.}
\label{sfig:hess_eig_first}
\end{center}
\end{figure}


\begin{figure}[ht]

\begin{center}

% First four subfigures
\makebox[\linewidth][c]{
\begin{minipage}{.24\linewidth}
  \centering
  \raisebox{-\height}{\includegraphics[width=\linewidth]{figures/FMNIST_Hessian_EV_sum_best-1.png}}
  \makebox[\linewidth][c]{\scriptsize\textit{(A) FashionMNIST}}  % Subfigure label
\end{minipage}%
\begin{minipage}{.24\linewidth}
  \centering
  \raisebox{-\height}{\includegraphics[width=\linewidth]{figures/EMNIST_Hessian_EV_sum_best-1.png}}
  \makebox[\linewidth][c]{\scriptsize\textit{(B) EMNIST}}  % Subfigure label
\end{minipage}%
\begin{minipage}{.24\linewidth}
  \centering
  \raisebox{-\height}{\includegraphics[width=\linewidth]{figures/CIFAR_Hessian_EV_sum_best-1.png}}
  \makebox[\linewidth][c]{\scriptsize\textit{(C) CIFAR-10}}  % Subfigure label
\end{minipage}%
\begin{minipage}{.24\linewidth}
  \centering
  \raisebox{-\height}{\includegraphics[width=\linewidth]{figures/ISIC_Hessian_EV_sum_best-1.png}}
  \makebox[\linewidth][c]{\scriptsize\textit{(D) ISIC-2019}}  % Subfigure label
\end{minipage}
}
\makebox[\linewidth][c]{
\begin{minipage}{.24\linewidth}
  \centering
  \raisebox{-\height}{\includegraphics[width=\linewidth]{figures/Sentiment_Hessian_EV_sum_best-1.png}}
  \makebox[\linewidth][c]{\scriptsize\textit{(E) Sent-140}}  % Subfigure label
\end{minipage}%
\begin{minipage}{.24\linewidth}
  \centering
  \raisebox{-\height}{\includegraphics[width=\linewidth]{figures/mimic_Hessian_EV_sum_best-1.png}}
  \makebox[\linewidth][c]{\scriptsize\textit{(F) MIMIC-III}}  % Subfigure label
\end{minipage}%
\begin{minipage}{.24\linewidth}
  \centering
  \raisebox{-\height}{\includegraphics[width=\linewidth]{figures/Heart_Hessian_EV_sum_best-1.png}}
  \makebox[\linewidth][c]{\scriptsize\textit{(G) Fed-Heart-Disease}}  % Subfigure label
\end{minipage}
}

\caption{\textbf{Layer hessian eigenvalue sum for the final models}. All models identically initialized and independently trained on non-IID data.}
\label{sfig:hess_eig_best}
\end{center}

\end{figure}

\begin{figure}[ht]

\begin{center}

% First four subfigures
\makebox[\linewidth][c]{
\begin{minipage}{.24\linewidth}
  \centering
  \raisebox{-\height}{\includegraphics[width=\linewidth]{figures/FMNIST_Hessian_EV_sum_best_federated-1.png}}
  \makebox[\linewidth][c]{\scriptsize\textit{(A) FashionMNIST}}  % Subfigure label
\end{minipage}%
\begin{minipage}{.24\linewidth}
  \centering
  \raisebox{-\height}{\includegraphics[width=\linewidth]{figures/EMNIST_Hessian_EV_sum_best_federated-1.png}}
  \makebox[\linewidth][c]{\scriptsize\textit{(B) EMNIST}}  % Subfigure label
\end{minipage}%
\begin{minipage}{.24\linewidth}
  \centering
  \raisebox{-\height}{\includegraphics[width=\linewidth]{figures/CIFAR_Hessian_EV_sum_best_federated-1.png}}
  \makebox[\linewidth][c]{\scriptsize\textit{(C) CIFAR-10}}  % Subfigure label
\end{minipage}%
\begin{minipage}{.24\linewidth}
  \centering
  \raisebox{-\height}{\includegraphics[width=\linewidth]{figures/ISIC_Hessian_EV_sum_best_federated-1.png}}
  \makebox[\linewidth][c]{\scriptsize\textit{(D) ISIC-2019}}  % Subfigure label
\end{minipage}
}
\makebox[\linewidth][c]{
\begin{minipage}{.24\linewidth}
  \centering
  \raisebox{-\height}{\includegraphics[width=\linewidth]{figures/Sentiment_Hessian_EV_sum_best_federated-1.png}}
  \makebox[\linewidth][c]{\scriptsize\textit{(E) Sent-140}}  % Subfigure label
\end{minipage}%
\begin{minipage}{.24\linewidth}
  \centering
  \raisebox{-\height}{\includegraphics[width=\linewidth]{figures/mimic_Hessian_EV_sum_best_federated-1.png}}
  \makebox[\linewidth][c]{\scriptsize\textit{(F) MIMIC-III}}  % Subfigure label
\end{minipage}%
\begin{minipage}{.24\linewidth}
  \centering
  \raisebox{-\height}{\includegraphics[width=\linewidth]{figures/Heart_Hessian_EV_sum_best_federated-1.png}}
  \makebox[\linewidth][c]{\scriptsize\textit{(G) Fed-Heart-Disease}}  % Subfigure label
\end{minipage}
}

\caption{\textbf{Layer hessian eigenvalue sum for the final models}. Models trained via FL on non-IID data.}
\label{sfig:hess_eig_best_fl}
\end{center}

\end{figure}

\subsection{Sample representation}
Figures \ref{sfig:sample_rep_first} and \ref{sfig:sample_rep_best} display the sample representation across all datasets, corresponding to the models trained for a single epoch and the final models, respectively.

\begin{figure}[ht]

\begin{center}

% First four subfigures
\makebox[\linewidth][c]{
\begin{minipage}{.24\linewidth}
  \centering
  \raisebox{-\height}{\includegraphics[width=\linewidth]{figures/FMNIST_similarity_first-1.png}}
  \makebox[\linewidth][c]{\scriptsize\textit{(A) FashionMNIST}}  % Subfigure label
\end{minipage}%
\begin{minipage}{.24\linewidth}
  \centering
  \raisebox{-\height}{\includegraphics[width=\linewidth]{figures/EMNIST_similarity_first-1.png}}
  \makebox[\linewidth][c]{\scriptsize\textit{(B) EMNIST}}  % Subfigure label
\end{minipage}%
\begin{minipage}{.24\linewidth}
  \centering
  \raisebox{-\height}{\includegraphics[width=\linewidth]{figures/CIFAR_similarity_first-1.png}}
  \makebox[\linewidth][c]{\scriptsize\textit{(C) CIFAR-10}}  % Subfigure label
\end{minipage}%
}
\makebox[\linewidth][c]{
\begin{minipage}{.24\linewidth}
  \centering
  \raisebox{-\height}{\includegraphics[width=\linewidth]{figures/Sentiment_similarity_first-1.png}}
  \makebox[\linewidth][c]{\scriptsize\textit{(E) Sent-140}}  % Subfigure label
\end{minipage}%
\begin{minipage}{.24\linewidth}
  \centering
  \raisebox{-\height}{\includegraphics[width=\linewidth]{figures/mimic_similarity_first-1.png}}
  \makebox[\linewidth][c]{\scriptsize\textit{(F) MIMIC-III}}  % Subfigure label
\end{minipage}%
\begin{minipage}{.24\linewidth}
  \centering
  \raisebox{-\height}{\includegraphics[width=\linewidth]{figures/Heart_similarity_first-1.png}}
  \makebox[\linewidth][c]{\scriptsize\textit{(G) Fed-Heart-Disease}}  % Subfigure label
\end{minipage}
}

\caption{\textbf{Layer sample representation similarity after one epoch}. All models identically initialized and independently trained on non-IID data.}
\label{sfig:sample_rep_first}
\end{center}
   
\end{figure}


\begin{figure}[ht]

\begin{center}

% First four subfigures
\makebox[\linewidth][c]{
\begin{minipage}{.24\linewidth}
  \centering
  \raisebox{-\height}{\includegraphics[width=\linewidth]{figures/FMNIST_similarity_best-1.png}}
  \makebox[\linewidth][c]{\scriptsize\textit{(A) FashionMNIST}}  % Subfigure label
\end{minipage}%
\begin{minipage}{.24\linewidth}
  \centering
  \raisebox{-\height}{\includegraphics[width=\linewidth]{figures/EMNIST_similarity_best-1.png}}
  \makebox[\linewidth][c]{\scriptsize\textit{(B) EMNIST}}  % Subfigure label
\end{minipage}%
\begin{minipage}{.24\linewidth}
  \centering
  \raisebox{-\height}{\includegraphics[width=\linewidth]{figures/CIFAR_similarity_best-1.png}}
  \makebox[\linewidth][c]{\scriptsize\textit{(C) CIFAR-10}}  % Subfigure label
\end{minipage}%
}
\makebox[\linewidth][c]{
\begin{minipage}{.24\linewidth}
  \centering
  \raisebox{-\height}{\includegraphics[width=\linewidth]{figures/Sentiment_similarity_best-1.png}}
  \makebox[\linewidth][c]{\scriptsize\textit{(E) Sent-140}}  % Subfigure label
\end{minipage}%
\begin{minipage}{.24\linewidth}
  \centering
  \raisebox{-\height}{\includegraphics[width=\linewidth]{figures/mimic_similarity_best-1.png}}
  \makebox[\linewidth][c]{\scriptsize\textit{(F) MIMIC-III}}  % Subfigure label
\end{minipage}%
\begin{minipage}{.24\linewidth}
  \centering
  \raisebox{-\height}{\includegraphics[width=\linewidth]{figures/Heart_similarity_best-1.png}}
  \makebox[\linewidth][c]{\scriptsize\textit{(G) Fed-Heart-Disease}}  % Subfigure label
\end{minipage}
}

\caption{\textbf{Layer sample representation similarity for final models}. All models identically initialized and independently trained on non-IID data.}
\label{sfig:sample_rep_best}
\end{center}

\end{figure}

\subsection{Federated sensitivity}
Figures \ref{sfig:layer_imp_best} and \ref{sfig:layer_imp_best_fl} display the federated sensitivity score across all datasets for the final model after independent training, and final model after FL training, respectively. 

\begin{figure}[ht]

\begin{center}

% First four subfigures
\makebox[\linewidth][c]{
\begin{minipage}{.24\linewidth}
  \centering
  \raisebox{-\height}{\includegraphics[width=\linewidth]{figures/FMNIST_Layer_importance_best-1.png}}
  \makebox[\linewidth][c]{\scriptsize\textit{(A) FashionMNIST}}  % Subfigure label
\end{minipage}%
\begin{minipage}{.24\linewidth}
  \centering
  \raisebox{-\height}{\includegraphics[width=\linewidth]{figures/EMNIST_Layer_importance_best-1.png}}
  \makebox[\linewidth][c]{\scriptsize\textit{(B) EMNIST}}  % Subfigure label
\end{minipage}%
\begin{minipage}{.24\linewidth}
  \centering
  \raisebox{-\height}{\includegraphics[width=\linewidth]{figures/CIFAR_Layer_importance_best-1.png}}
  \makebox[\linewidth][c]{\scriptsize\textit{(C) CIFAR-10}}  % Subfigure label
\end{minipage}%
\begin{minipage}{.24\linewidth}
  \centering
  \raisebox{-\height}{\includegraphics[width=\linewidth]{figures/ISIC_Layer_importance_best-1.png}}
  \makebox[\linewidth][c]{\scriptsize\textit{(D) ISIC-2019}}  % Subfigure label
\end{minipage}
}
\makebox[\linewidth][c]{
\begin{minipage}{.24\linewidth}
  \centering
  \raisebox{-\height}{\includegraphics[width=\linewidth]{figures/Sentiment_Layer_importance_best-1.png}}
  \makebox[\linewidth][c]{\scriptsize\textit{(E) Sent-140}}  % Subfigure label
\end{minipage}%
\begin{minipage}{.24\linewidth}
  \centering
  \raisebox{-\height}{\includegraphics[width=\linewidth]{figures/mimic_Layer_importance_best-1.png}}
  \makebox[\linewidth][c]{\scriptsize\textit{(F) MIMIC-III}}  % Subfigure label
\end{minipage}%
\begin{minipage}{.24\linewidth}
  \centering
  \raisebox{-\height}{\includegraphics[width=\linewidth]{figures/Heart_Layer_importance_best-1.png}}
  \makebox[\linewidth][c]{\scriptsize\textit{(G) Fed-Heart-Disease}}  % Subfigure label
\end{minipage}
}

\caption{\textbf{Federation sensitivity for final models}. All models identically initialized and independently trained on non-IID data.}
\label{sfig:layer_imp_best}
\end{center}

\end{figure}

\begin{figure}[ht]

\begin{center}

% First four subfigures
\makebox[\linewidth][c]{
\begin{minipage}{.24\linewidth}
  \centering
  \raisebox{-\height}{\includegraphics[width=\linewidth]{figures/FMNIST_Layer_importance_best_federated-1.png}}
  \makebox[\linewidth][c]{\scriptsize\textit{(A) FashionMNIST}}  % Subfigure label
\end{minipage}%
\begin{minipage}{.24\linewidth}
  \centering
  \raisebox{-\height}{\includegraphics[width=\linewidth]{figures/EMNIST_Layer_importance_best_federated-1.png}}
  \makebox[\linewidth][c]{\scriptsize\textit{(B) EMNIST}}  % Subfigure label
\end{minipage}%
\begin{minipage}{.24\linewidth}
  \centering
  \raisebox{-\height}{\includegraphics[width=\linewidth]{figures/CIFAR_Layer_importance_best_federated-1.png}}
  \makebox[\linewidth][c]{\scriptsize\textit{(C) CIFAR-10}}  % Subfigure label
\end{minipage}%
\begin{minipage}{.24\linewidth}
  \centering
  \raisebox{-\height}{\includegraphics[width=\linewidth]{figures/ISIC_Layer_importance_best_federated-1.png}}
  \makebox[\linewidth][c]{\scriptsize\textit{(D) ISIC-2019}}  % Subfigure label
\end{minipage}
}
\makebox[\linewidth][c]{
\begin{minipage}{.24\linewidth}
  \centering
  \raisebox{-\height}{\includegraphics[width=\linewidth]{figures/Sentiment_Layer_importance_best_federated-1.png}}
  \makebox[\linewidth][c]{\scriptsize\textit{(E) Sent-140}}  % Subfigure label
\end{minipage}%
\begin{minipage}{.24\linewidth}
  \centering
  \raisebox{-\height}{\includegraphics[width=\linewidth]{figures/mimic_Layer_importance_best_federated-1.png}}
  \makebox[\linewidth][c]{\scriptsize\textit{(F) MIMIC-III}}  % Subfigure label
\end{minipage}%
\begin{minipage}{.24\linewidth}
  \centering
  \raisebox{-\height}{\includegraphics[width=\linewidth]{figures/Heart_Layer_importance_best_federated-1.png}}
  \makebox[\linewidth][c]{\scriptsize\textit{(G) Fed-Heart-Disease}}  % Subfigure label
\end{minipage}
}

\caption{\textbf{Federation sensitivity for final models}. Models trained via FL on non-IID data.}
\label{sfig:layer_imp_best_fl}
\end{center}

\end{figure}
\clearpage

\section{Results}
\subsection{F1 score: fairness and incentive}
Table \ref{supp:fairness-table} shows the variance in client results and Table \ref{supp:incentive-table} shows the \% of clients that beat local site or FedAvg training. 
\begin{table}[ht]
\caption{Variance in clients' F1 score (fairness). In \textbf{bold} is fairest model. Friedman rank test p-value $<5\times10^{-3}$}
\label{supp:fairness-table}
\begin{center}
\fontsize{9pt}{7pt}\selectfont
\begin{tabular}{lcccccccc}
\toprule
Algorithm & FMNIST & EMNIST & CIFAR & ISIC & Heart & Sent-140 & MIMIC-III & Rank \\
\midrule
Fedprox & $3.0\cdot 10^{-4}$ & $8.0\cdot 10^{-4}$ & $4.0\cdot 10^{-4}$ & $1.1\cdot 10^{-2}$ & $9.0\cdot 10^{-2}$ & $4.1\cdot 10^{-3}$ & $1.7\cdot 10^{-3}$ & 7.7 \\
pFedMe & $3.0\cdot 10^{-4}$ & $6.0\cdot 10^{-4}$ & $5.0\cdot 10^{-4}$ & $4.2\cdot 10^{-3}$ & $\mathbf{7.1\cdot 10^{-2}}$ & $3.7\cdot 10^{-2}$ & $\mathbf{1.4\cdot 10^{-3}}$ & 4.3 \\
Ditto & $5.0\cdot 10^{-4}$ & $6.0\cdot 10^{-4}$ & $2.0\cdot 10^{-4}$ & $3.6\cdot 10^{-3}$ & $8.2\cdot 10^{-2}$ & $3.6\cdot 10^{-2}$ & $1.6\cdot 10^{-3}$ & 5.0 \\
LocalAdaptation & $\mathbf{1.0\cdot 10^{-4}}$ & $7.0\cdot 10^{-4}$ & $4.0\cdot 10^{-4}$ & $9.0\cdot 10^{-3}$ & $8.3\cdot 10^{-2}$ & $4.1\cdot 10^{-2}$ & $2.2\cdot 10^{-3}$ & 6.4 \\
FedBABU & $2.0\cdot 10^{-4}$ & $4.0\cdot 10^{-4}$ & $4.0\cdot 10^{-4}$ & $2.1\cdot 10^{-3}$ & $8.4\cdot 10^{-2}$ & $3.5\cdot 10^{-2}$ & $2.0\cdot 10^{-3}$ & 4.4 \\
FedLP & $3.0\cdot 10^{-4}$ & $4.0\cdot 10^{-4}$ & $1.0\cdot 10^{-3}$ & $1.1\cdot 10^{-2}$ & $8.5\cdot 10^{-2}$ & $3.7\cdot 10^{-2}$ & $1.6\cdot 10^{-3}$ & 6.1 \\
FedLAMA & $2.0\cdot 10^{-4}$ & $6.0\cdot 10^{-4}$ & $5.0\cdot 10^{-4}$ & $4.7\cdot 10^{-3}$ & $8.7\cdot 10^{-2}$ & $4.1\cdot 10^{-2}$ & $2.0\cdot 10^{-3}$ & 5.6 \\
pFedLA & $4.0\cdot 10^{-4}$ & $1.0\cdot 10^{-4}$ & $\mathbf{1.0\cdot 10^{-4}}$ & $3.5\cdot 10^{-3}$ & $7.4\cdot 10^{-2}$ & $4.1\cdot 10^{-2}$ & $2.1\cdot 10^{-3}$ & 5.1 \\
\midrule
PLayer-FL & $4.0\cdot 10^{-4}$ & $5.0\cdot 10^{-4}$ & $6.0\cdot 10^{-4}$ & $1.3\cdot 10^{-3}$ & $7.3\cdot 10^{-2}$ & $\mathbf{3.3\cdot 10^{-2}}$ & $1.5\cdot 10^{-3}$ & \textbf{3.8} \\
PLayer-FL-Random & $8.0\cdot 10^{-4}$ & $\mathbf{3.0\cdot 10^{-4}}$ & $1.0\cdot 10^{-3}$ & $\mathbf{7.0\cdot 10^{-4}}$ & $7.3\cdot 10^{-2}$ & $3.4\cdot 10^{-2}$ & $1.9\cdot 10^{-3}$ & 6.5 \\
\bottomrule
\end{tabular}
\end{center}
\end{table}
\begin{table}[ht]
\centering
\caption{Incentivized participation rate (\%) using F1 score. In \textbf{bold} is model with highest IPR. Friedman rank test p-value $=0.043$}

\label{supp:incentive-table}
\begin{tabular}{lcccccccc}
\toprule
Algorithm & FMNIST & EMNIST & CIFAR & ISIC & Heart & Sentiment & Mimic-III & Rank \\
\midrule
FedProx & 0.0 & 20.0 & 40.0 & 0.0 & 0.0 & 6.7 & 50.0 & 5.4 \\
pFedMe & 80.0 & 20.0 & 0.0 & 0.0 & \textbf{50.0} & 6.7 & 0.0 & 5.1 \\
Ditto & 60.0 & 0.0 & 0.0 & 0.0 & 0.0 & \textbf{26.7} & 25.0 & 5.6 \\
LocalAdaptation & 0.0 & 40.0 & 40.0 & 0.0 & 0.0 & 0.0 & \textbf{75.0} & 5.2 \\
FedBABU & 0.0 & 40.0 & 80.0 & 0.0 & 0.0 & 20.0 & 50.0 & 4.4 \\
FedLP & 0.0 & \textbf{60.0} & 0.0 & 0.0 & 0.0 & 6.7 & 50.0 & 6.2 \\
FedLAMA & 0.0 & 0.0 & 0.0 & 0.0 & 0.0 & 0.0 & 25.0 & 7.3 \\
pFedLA & 0.0 & 0.0 & 0.0 & 0.0 & 0.0 & 0.0 & 0.0 & 7.7 \\
\midrule
PLayer-FL & \textbf{100.0} & 0.0 & \textbf{100.0} & 0.0 & 25.0 & 20.0 & 50.0 & \textbf{3.4} \\
PLayer-FL-Random & 60.0 & 0.0 & 80.0 & 0.0 & 25.0 & 6.7 & 25.0 & 4.8 \\
\bottomrule
\end{tabular}
\end{table}



\subsection{Accuracy}
\label{supp:accuracy_results}
Table \ref{supp:acc-table} shows clients' median accuracy scores (95\% confidence interval), Table \ref{supp:fairness_accuracy} shows the variance in client accuracy scores and Table \ref{supp:incentive_accuracy} shows the \% of clients that beat single or FedAvg training in accuracy. 

\begin{table*}[ht]
\caption{Accuracy and average rank. In \textbf{bold} is the top-performing model. Friedman rank test p-value $<5\times10^{-3}$}
\label{supp:acc-table}
\begin{center}
\setlength{\tabcolsep}{5.4pt}
\begin{tabular}{lcccccccc}
\toprule
Algorithm & FMNIST & EMNIST & CIFAR & ISIC & Heart & Sentiment & mimic & Avg Rank \\
\midrule
Local & \specialcell{88.7}{0.9} & \specialcell{84.2}{0.9} & \specialcell{79.4}{1.3} & \textbf{\specialcell{68.9}{1.8}} & \specialcell{53.7}{1.0} & \specialcell{79.8}{0.3} & \specialcell{74.7}{2.1} & 6.7 \\
FedAvg & \specialcell{89.1}{0.5} & \textbf{\specialcell{86.5}{0.6}} & \specialcell{80.0}{0.6} & \specialcell{66.4}{1.2} & \specialcell{54.1}{0.7} & \specialcell{78.8}{0.2} & \specialcell{74.7}{0.6} & 6.4 \\
FedProx & \specialcell{89.2}{0.4} & \specialcell{86.2}{0.9} & \specialcell{80.2}{0.6} & \specialcell{66.5}{1.6} & \specialcell{52.9}{1.6} & \specialcell{78.8}{0.2} & \textbf{\specialcell{75.7}{1.7}} & 6.4 \\
pFedMe & \specialcell{88.2}{0.8} & \specialcell{85.7}{0.9} & \specialcell{67.4}{1.1} & \specialcell{66.8}{0.6} & \specialcell{55.0}{1.0} & \specialcell{80.0}{0.2} & \specialcell{73.3}{0.9} & 6.9 \\
Ditto & \specialcell{89.0}{0.6} & \specialcell{85.6}{1.1} & \specialcell{67.8}{0.8} & \specialcell{66.0}{1.0} & \textbf{\specialcell{55.5}{1.0}} & \specialcell{80.3}{0.6} & \specialcell{73.5}{0.9} & 7.0 \\
LocalAdaptation & \specialcell{89.3}{0.8} & \specialcell{86.3}{0.6} & \specialcell{80.0}{1.1} & \specialcell{66.9}{0.2} & \specialcell{53.8}{0.8} & \specialcell{78.9}{0.3} & \specialcell{74.0}{2.2} & 6.3 \\
FedBABU & \specialcell{89.2}{0.6} & \specialcell{86.4}{0.7} & \specialcell{80.7}{1.4} & \specialcell{67.3}{1.6} & \specialcell{54.2}{0.7} & \textbf{\specialcell{81.0}{0.2}} & \specialcell{74.9}{0.6} & 3.4 \\
FedLP & \specialcell{89.1}{0.6} & \specialcell{86.3}{0.9} & \specialcell{78.6}{1.6} & \specialcell{66.6}{0.7} & \specialcell{54.1}{0.7} & \specialcell{79.4}{0.3} & \specialcell{74.6}{1.3} & 7.0 \\
FedLama & \specialcell{86.3}{0.8} & \specialcell{83.3}{0.6} & \specialcell{63.4}{2.0} & \specialcell{62.4}{1.5} & \specialcell{54.7}{0.8} & \specialcell{78.0}{0.1} & \specialcell{75.2}{1.2} & 8.9 \\
pFedLA & \specialcell{70.8}{0.2} & \specialcell{41.2}{2.7} & \specialcell{37.1}{2.3} & \specialcell{56.7}{1.6} & \specialcell{52.6}{1.4} & \specialcell{78.0}{0.0} & \specialcell{74.7}{2.6} & 11.1 \\
\midrule
PLayer-FL & \textbf{\specialcell{89.8}{0.7}} & \specialcell{86.1}{0.8} & \textbf{\specialcell{81.5}{1.1}} & \specialcell{68.6}{0.8} & \specialcell{55.4}{1.2} & \specialcell{80.7}{0.7} & \textbf{\specialcell{75.7}{0.6}} & \textbf{2.2} \\
PLayer-FL-Random & \specialcell{89.2}{0.7} & \specialcell{84.1}{0.8} & \specialcell{81.2}{1.2} & \specialcell{68.6}{0.8} & \specialcell{54.4}{1.2} & \specialcell{79.0}{0.4} & \specialcell{74.5}{2.0} & 5.8 \\
\bottomrule
\bottomrule
\end{tabular}
\end{center}
\end{table*}


\begin{table}[h]
\caption{Variance in clients' accuracy (fairness). In \textbf{bold} is the fairest model. Friedman rank test p-value $<5\times10^{-3}$}
\label{supp:fairness_accuracy}

\begin{center}
\begin{small}
\begin{tabular}{lcccccccc}
\toprule
Algorithm & FMNIST & EMNIST & CIFAR & ISIC & Heart & Sentiment & mimic & Avg Rank \\
\midrule
FedProx & $1.0\cdot 10^{-4}$ & $3.0\cdot 10^{-4}$ & $1.0\cdot 10^{-4}$ & $3.5\cdot 10^{-2}$ & $6.7\cdot 10^{-2}$ & $2.4\cdot 10^{-2}$ & $1.1\cdot 10^{-2}$ & 5.7 \\
pFedMe & $\mathbf{1.0\cdot 10^{-5}}$ & $3.0\cdot 10^{-4}$ & $4.0\cdot 10^{-4}$ & $3.3\cdot 10^{-2}$ & $4.6\cdot 10^{-2}$ & $2.1\cdot 10^{-2}$ & $1.4\cdot 10^{-2}$ & 5.0 \\
ditto & $1.0\cdot 10^{-4}$ & $2.0\cdot 10^{-4}$ & $3.0\cdot 10^{-4}$ & $3.5\cdot 10^{-2}$ & $5.7\cdot 10^{-2}$ & $2.3\cdot 10^{-2}$ & $1.3\cdot 10^{-2}$ & 5.3 \\
LocalAdaptation & $1.0\cdot 10^{-4}$ & $2.0\cdot 10^{-4}$ & $2.0\cdot 10^{-4}$ & $3.2\cdot 10^{-2}$ & $5.7\cdot 10^{-2}$ & $2.4\cdot 10^{-2}$ & $1.4\cdot 10^{-2}$ & 5.5 \\
FedBABU & $1.0\cdot 10^{-4}$ & $2.0\cdot 10^{-4}$ & $1.0\cdot 10^{-4}$ & $3.3\cdot 10^{-2}$ & $6.0\cdot 10^{-2}$ & $\mathbf{1.8\cdot 10^{-2}}$ & $1.2\cdot 10^{-2}$ & 4.9 \\
FedLP & $1.0\cdot 10^{-4}$ & $2.0\cdot 10^{-4}$ & $1.0\cdot 10^{-4}$ & $3.6\cdot 10^{-2}$ & $5.7\cdot 10^{-2}$ & $2.2\cdot 10^{-2}$ & $1.5\cdot 10^{-2}$ & 5.3 \\
FedLama & $1.0\cdot 10^{-4}$ & $2.0\cdot 10^{-4}$ & $3.0\cdot 10^{-4}$ & $4.2\cdot 10^{-3}$ & $6.3\cdot 10^{-2}$ & $2.6\cdot 10^{-2}$ & $1.3\cdot 10^{-2}$ & 7.1 \\
pFedLA & $9.0\cdot 10^{-4}$ & $6.0\cdot 10^{-4}$ & $2.3\cdot 10^{-3}$ & $6.3\cdot 10^{-2}$ & $5.1\cdot 10^{-2}$ & $2.6\cdot 10^{-2}$ & $2.5\cdot 10^{-2}$ & 8.9 \\
\midrule
PLayer-FL & $1.0\cdot 10^{-4}$ & $\mathbf{1.0\cdot 10^{-4}}$ & $1.0\cdot 10^{-4}$ & $\mathbf{2.9\cdot 10^{-2}}$ & $4.7\cdot 10^{-2}$ & $1.9\cdot 10^{-2}$ & $1.3\cdot 10^{-2}$ & \textbf{2.5} \\
PLayer-FL-Random & $1.0\cdot 10^{-4}$ & $3.0\cdot 10^{-4}$ & $\mathbf{1.0\cdot 10^{-4}}$ & $\mathbf{2.9\cdot 10^{-2}}$ & $5.7\cdot 10^{-2}$ & $2.5\cdot 10^{-2}$ & $\mathbf{9.7\cdot 10^{-3}}$ & 4.9 \\
\bottomrule
\end{tabular}
\end{small}
\end{center}

\end{table}

\begin{table}[h]
\centering
\caption{Incentivized Participation Rate using accuracy (\%). In \textbf{bold} is model with highest IPR. Friedman rank test p-value $<5\times10^{-3}$}
\label{supp:incentive_accuracy}
\begin{tabular}{lcccccccc}
\toprule
Algorithm & FMNIST & EMNIST & CIFAR & ISIC & Heart & Sent-140 & Mimic-III & Avg Rank \\ 
\midrule
FedProx & 20.0 & \textbf{40.0} & 40.0 & 0.0 & 0.0 & 0.0 & 50.0 & 5.6 \\
pFedMe & 40.0 & \textbf{40.0} & 0.0 & 0.0 & \textbf{25.0} & 6.7 & 0.0 & 5.6 \\
Ditto & 60.0 & 0.0 & 0.0 & 0.0 & 0.0 & 6.7 & 0.0 & 6.8 \\
LocalAdaptation & 60.0 & 40.0 & 60.0 & 0.0 & 0.0 & 0.0 & 25.0 & 5.3 \\
FedBABU & 80.0 & 20.0 & 60.0 & 0.0 & 0.0 & \textbf{20.0} & \textbf{25.0} & 4.3 \\
FedLP & 60.0 & 20.0 & 20.0 & 0.0 & 0.0 & 6.7 & \textbf{25.0} & 5.4 \\
FedLama & 0.0 & 0.0 & 0.0 & 0.0 & 0.0 & 0.0 & 0.0 & 8.1 \\
pFedLA & 0.0 & 0.0 & 0.0 & 0.0 & 25.0 & 0.0 & 50.0 & 6.5 \\
\midrule
PLayer-FL & \textbf{80.0} & 0.0 & \textbf{100.0} & \textbf{25.0} & \textbf{25.0} & \textbf{20.0} & \textbf{75.0} & \textbf{2.4} \\
PLayer-FL-Random & 40.0 & 0.0 & \textbf{100.0} & \textbf{25.0} & 0.0 & 6.7 & 25.0 & 4.9 \\
\bottomrule
\end{tabular}
\end{table}


\subsection{Loss}
\label{supp:loss_results}
Table \ref{supp:loss-table} shows clients' median test loss (95\% confidence interval), Table \ref{supp:fairness_loss} shows the variance in client test loss and Table \ref{supp:incentive_loss} shows the \% of clients that beat single or FedAvg training in test loss. 

\begin{table*}[ht]
\caption{Test loss ($\times 1\cdot10^{-4}$) and average rank. In \textbf{bold} is the top-performing model. Friedman rank test p-value $<5\times10^{-3}$}
\label{supp:loss-table}
\begin{center}
\setlength{\tabcolsep}{4.5pt}
\begin{tabular}{lcccccccc}
\toprule
Algorithm & FMNIST & EMNIST & CIFAR & ISIC & Heart & Sentiment & mimic & Avg Rank \\
\midrule
Local client & \specialcell{34.7}{2.0} & \specialcell{58.6}{3.7} & \specialcell{60.7}{4.3} & \textbf{\specialcell{111.2}{0.3}} & \specialcell{29.6}{0.8} & \specialcell{43.7}{0.3} & \specialcell{71.4}{0.8} & 8.3 \\
FedAvg & \specialcell{30.7}{1.1} & \specialcell{42.2}{2.8} & \specialcell{57.4}{3.1} & \specialcell{121.8}{1.6} & \specialcell{27.5}{0.5} & \specialcell{44.1}{0.2} & \specialcell{65.8}{0.9} & 6.1 \\
FedProx & \specialcell{31.5}{1.9} & \specialcell{41.6}{2.9} & \specialcell{56.3}{1.3} & \specialcell{121.6}{1.1} & \specialcell{28.4}{0.9} & \specialcell{43.9}{0.2} & \specialcell{65.8}{1.1} & 6.3 \\
pFedMe & \specialcell{30.4}{2.3} & \specialcell{42.9}{2.7} & \specialcell{90.9}{2.8} & \specialcell{118.0}{1.0} & \specialcell{26.4}{0.9} & \specialcell{42.2}{0.6} & \specialcell{67.4}{0.8} & 5.1 \\
Ditto & \specialcell{30.8}{0.2} & \specialcell{45.0}{3.0} & \specialcell{89.9}{3.9} & \specialcell{120.6}{2.5} & \textbf{\specialcell{26.2}{0.4}} & \specialcell{42.5}{0.6} & \specialcell{67.3}{0.1} & 5.9 \\
LocalAdaptation & \specialcell{30.5}{1.9} & \textbf{\specialcell{41.1}{3.4}} & \specialcell{57.0}{3.0} & \specialcell{121.4}{1.3} & \specialcell{28.1}{0.6} & \specialcell{43.6}{0.1} & \specialcell{65.7}{0.6} & 4.9 \\
FedBABU & \specialcell{30.0}{1.9} & \specialcell{42.2}{3.5} & \specialcell{55.2}{2.8} & \specialcell{120.6}{1.5} & \specialcell{29.1}{1.0} & \specialcell{41.8}{0.2} & \specialcell{65.5}{0.7} & 3.8 \\
FedLP & \specialcell{30.1}{1.0} & \specialcell{43.1}{3.2} & \specialcell{61.4}{3.6} & \specialcell{128.7}{1.5} & \specialcell{27.3}{0.5} & \specialcell{42.9}{0.2} & \specialcell{65.8}{0.6} & 6.7 \\
FedLAMA & \specialcell{37.6}{2.0} & \specialcell{53.2}{2.3} & \specialcell{102.4}{3.0} & \specialcell{133.0}{1.8} & \specialcell{27.2}{0.5} & \specialcell{45.0}{0.3} & \textbf{\specialcell{65.2}{0.5}} & 8.3 \\
pFedLA & \specialcell{88.6}{6.9} & \specialcell{253.4}{11.2} & \specialcell{176.2}{10.6} & \specialcell{151.2}{1.8} & \specialcell{36.1}{4.9} & \specialcell{47.2}{0.6} & \specialcell{75.4}{0.6} & 12.0 \\
\midrule
PLayer-FL & \textbf{\specialcell{27.7}{2.0}} & \specialcell{45.4}{3.9} & \textbf{\specialcell{52.6}{2.6}} & \specialcell{113.4}{0.6} & \specialcell{26.7}{0.6} & \textbf{\specialcell{41.4}{0.4}} & \specialcell{66.2}{0.7} & \textbf{3.4} \\
PLayer-FL-Random & \specialcell{33.3}{2.3} & \specialcell{58.2}{1.8} & \specialcell{55.6}{3.7} & \specialcell{113.1}{1.6} & \specialcell{27.9}{1.0} & \specialcell{44.6}{0.7} & \specialcell{69.9}{1.2} & 7.4 \\
\bottomrule
\end{tabular}
\end{center}
\end{table*}


\begin{table}[h]
\caption{Variance in clients' test loss (fairness). In \textbf{bold} is the fairest model. Friedman rank test p-value $<5\times10^{-3}$}
\label{supp:fairness_loss}
\begin{center}
\begin{small}
\begin{tabular}{lcccccccc}
\toprule
Algorithm & FMNIST & EMNIST & CIFAR & ISIC & Heart & Sent-140 & MIMIC-III & Avg Rank \\ 
\midrule
FedProx & $1.1\cdot 10^{-3}$ & $1.7\cdot 10^{-3}$ & $1.1\cdot 10^{-3}$ & $3.8\cdot 10^{-1}$ & $1.8\cdot 10^{-2}$ & $5.5\cdot 10^{-2}$ & $4.7\cdot 10^{-2}$ & 6.4 \\
pFedMe & $5.0\cdot 10^{-4}$ & $2.3\cdot 10^{-3}$ & $1.8\cdot 10^{-3}$ & $3.6\cdot 10^{-1}$ & $1.3\cdot 10^{-2}$ & $5.2\cdot 10^{-2}$ & $3.5\cdot 10^{-2}$ & 4.1 \\
Ditto & $6.0\cdot 10^{-4}$ & $2.2\cdot 10^{-3}$ & $2.3\cdot 10^{-4}$ & $3.8\cdot 10^{-1}$ & $1.7\cdot 10^{-2}$ & $5.2\cdot 10^{-2}$ & $3.8\cdot 10^{-2}$ & 4.6 \\
LocalAdaptation & $1.0\cdot 10^{-3}$ & $2.1\cdot 10^{-3}$ & $1.2\cdot 10^{-3}$ & $4.0\cdot 10^{-1}$ & $1.9\cdot 10^{-2}$ & $5.5\cdot 10^{-2}$ & $4.8\cdot 10^{-2}$ & 7.1 \\
FedBABU & $4.0\cdot 10^{-4}$ & $\mathbf{1.2\cdot 10^{-3}}$ & $7.0\cdot 10^{-4}$ & $4.1\cdot 10^{-1}$ & $2.1\cdot 10^{-2}$ & $\mathbf{4.6\cdot 10^{-2}}$ & $4.5\cdot 10^{-2}$ & 4.4 \\
FedLP & $7.0\cdot 10^{-4}$ & $1.9\cdot 10^{-3}$ & $8.0\cdot 10^{-4}$ & $4.3\cdot 10^{-1}$ & $1.7\cdot 10^{-2}$ & $5.2\cdot 10^{-2}$ & $4.3\cdot 10^{-2}$ & 5.1 \\
FedLAMA & $\mathbf{2.0\cdot 10^{-4}}$ & $2.9\cdot 10^{-3}$ & $2.4\cdot 10^{-3}$ & $4.6\cdot 10^{-1}$ & $1.8\cdot 10^{-2}$ & $5.3\cdot 10^{-2}$ & $4.3\cdot 10^{-2}$ & 6.7 \\
pFedLA & $1.0\cdot 10^{-3}$ & $2.3\cdot 10^{-2}$ & $5.1\cdot 10^{-2}$ & $5.7\cdot 10^{-1}$ & $2.6\cdot 10^{-1}$ & $5.1\cdot 10^{-2}$ & $\mathbf{3.2\cdot 10^{-2}}$ & 7.6 \\
\midrule
PLayer-FL & $7.0\cdot 10^{-4}$ & $2.5\cdot 10^{-3}$ & $4.0\cdot 10^{-4}$ & $\mathbf{3.2\cdot 10^{-1}}$ & $\mathbf{1.4\cdot 10^{-2}}$ & $5.1\cdot 10^{-2}$ & $4.2\cdot 10^{-2}$ & \textbf{3.6} \\
PLayer-FL-Random & $8.0\cdot 10^{-4}$ & $4.1\cdot 10^{-3}$ & $\mathbf{1.0\cdot 10^{-4}}$ & $\mathbf{3.2\cdot 10^{-1}}$ & $1.6\cdot 10^{-2}$ & $6.1\cdot 10^{-2}$ & $4.0\cdot 10^{-2}$ & 5.2 \\
\bottomrule
\end{tabular}
\end{small}
\end{center}
\end{table}

\begin{table}[h]
\centering
\caption{Incentivized Participation Rate using test loss (\%) and Average Algorithm Rank. Friedman rank test p-value $=0.084$}
\label{supp:incentive_loss}
\begin{tabular}{lcccccccc}
\toprule
Algorithm & FMNIST & EMNIST & CIFAR & ISIC & Heart & Sent-140 & Mimic-III & Avg Rank \\ 
\midrule
FedProx & 40.0 & \textbf{80.0} & 40.0 & 0.0 & 25.0 & 33.3 & 25.0 & 5.1 \\
pFedMe & 40.0 & 40.0 & 0.0 & 0.0 & \textbf{100.0} & 33.3 & 0.0 & 5.7 \\
Ditto & 40.0 & 0.0 & 0.0 & 0.0 & 75.0 & 33.3 & 0.0 & 6.5 \\
LocalAdaptation & 20.0 & 60.0 & 80.0 & 0.0 & 25.0 & 40.0 & 25.0 & 4.8 \\
FedBABU & 80.0 & 40.0 & 60.0 & 0.0 & 0.0 & 40.0 & 25.0 & 4.6 \\
FedLP & 60.0 & \textbf{80.0} & 20.0 & 0.0 & 75.0 & 40.0 & 50.0 & 3.6 \\
FedLAMA & 0.0 & 0.0 & 0.0 & 0.0 & 50.0 & 20.0 &  \textbf{75.0} & 6.7 \\
pFedLA & 0.0 & 0.0 & 0.0 & 0.0 & 0.0 & 6.7 & 0.0 & 8.5 \\
\midrule
PLayer-FL & \textbf{80.0} & 0.0 & \textbf{100.0} & \textbf{50.0} & \textbf{100.0} & 40.0 & 0.0 & \textbf{3.5} \\
PLayer-FL-Random & 0.0 & 0.0 & \textbf{100.0} & \textbf{50.0} & 50.0 & 20.0 & 0.0 & 6.0 \\
\bottomrule
\end{tabular}
\end{table}


%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%


\end{document}

