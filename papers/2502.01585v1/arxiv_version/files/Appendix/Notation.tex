\section{Notations}
\label{app:notation}

\begin{table}[H]
\begin{threeparttable}
\caption{Core notations used the main text and appendix.}
\label{table:symbols_and_notations}
\small
\centering
\fontsize{7}{7}\selectfont
\begin{tabular}{c | c | c}
\toprule
Notation & Dimension(s) & Definition \\
\midrule
\(\mathcal{N}_{\lambda}^{\tt LS}\) & - & The \(\ell_2\) norm of the linear regression estimator under regularization \(\lambda\) for linear regression \\
\(\mathcal{B}_{\mathcal{N},\lambda}^{\tt LS}\) & - & The bias of \(\mathcal{N}_{\lambda}^{\tt LS}\) \\
\(\mathcal{V}_{\mathcal{N},\lambda}^{\tt LS}\) & - & The variance of \(\mathcal{N}_{\lambda}^{\tt LS}\) \\ \midrule
\(\sN_{\lambda}^{\tt LS}\) & - & The deterministic equivalent of \(\mathcal{N}_{\lambda}^{\tt LS}\) \\
\(\sB_{\sN, \lambda}^{\tt LS}\) & - & The deterministic equivalent of \(\mathcal{B}_{\mathcal{N},\lambda}^{\tt LS}\) \\
\(\sV_{\sN, \lambda}^{\tt LS}\) & - & The deterministic equivalent of \(\mathcal{V}_{\mathcal{N},\lambda}^{\tt LS}\) \\
\midrule
$\left \| \bm{v} \right \|_2$ & - & Euclidean norms of vectors $\bm{v}$ \\
$\left \| \bm{v} \right \|_\bSigma$ & - & $\sqrt{\bv^\sT \bSigma \bv}$ \\
\midrule
$n$ & - & Number of training samples \\
$d$ & - & Dimension of the data for linear regression \\
$p$ & - & Number of features for random feature model \\
$\lambda$ & - & Regularization parameter \\
$\lambda_*$ & - & Effective regularization parameter for linear ridge regression \\
$\nu_1\,,\nu_2$ & - & Effective regularization parameters for random feature ridge regression \\
$\sigma_k(\bM)$ & - & The $k$-th eigenvalue of $\bM$ \\
\midrule
$\bm{x}$ & $\mathbb{R}^{d}$ & The data vector \\
$\bX$ & $\mathbb{R}^{n \times d}$ & The data matrix\\
$\bSigma$ & $\mathbb{R}^{d \times d}$ & The covariance matrix of $\bx$\\
$y$ & $\mathbb{R}$ & The label \\
$\by$ & $\mathbb{R}^{n}$ & The label vector \\
$\bbeta_*$ & $\mathbb{R}^{d}$ & The target function for linear regression \\
$\hat{\bbeta}$ & $\mathbb{R}^{d}$ & The estimator of ridge regression model \\
$\hat{\bbeta}_{\min}$ & $\mathbb{R}^{d}$ & The min-$\ell_2$-norm estimator of ridge regression model \\
$\varepsilon$ & $\mathbb{R}$ & The noise \\
$\varepsilon_i$ & $\mathbb{R}$ & The $i$-th noise \\
$\bm\varepsilon$ & $\mathbb{R}^{n}$ & The noise vector \\
$\sigma^2$ & $\mathbb{R}$ & The variance of the noise\\ \midrule
$\bw_i$ & $\mathbb{R}^{d}$ & The $i$-th weight vector for random feature model \\ 
$\varphi(\cdot;\cdot)$ & - & Nonlinear activation function for random feature model \\
$\bz_i$ & $\mathbb{R}^{p}$ & The $i$-th feature for random feature model \\
$\bZ$ & $\mathbb{R}^{n \times p}$ & Feature matrix for random feature model \\
$\hat{\ba}$ & $\mathbb{R}^{p}$ & The estimator of random feature ridge regression model\\
$\hat{\ba}_{\min}$ & $\mathbb{R}^{p}$ & The min-$\ell_2$-norm estimator of random feature ridge regression model\\ \midrule
$f_*(\cdot)$ & - & The target function \\
$\mu_\bx$ & - & The distribution of $\bx$ \\
$\mu_\bw$ & - & The distribution of $\bw$ \\
$\mathbb{T}$ & - & An integral
operator defined by $(\mathbb{T}f)(\bw) := \int_{\mathbb{R}^d} \varphi(\bx; \bw) f(\bx) \mathrm{d}\mu_\bx \,,\quad \forall f \in L_2(\mu_\bx)$ \\
$\mathcal{V}$ & - & The image of $\mathbb{T}$\\
$\xi_k$ & $\mathbb{R}$ & The $k$-th eigenvalue of $\mathbb{T}$, defined by
$\mathbb{T} = \sum_{k=1}^\infty \xi_k \psi_k \phi_k^*$ \\
$\psi_k$ & - & The $k$-th eigenfunction of $\mathbb{T}$ in the space $L_2(\mu_\bx)$, defined by the decomposition
$\mathbb{T} = \sum_{k=1}^\infty \xi_k \psi_k \phi_k^*$ \\
$\phi_k$ & - & The $k$-th eigenfunction of $\mathbb{T}$ in the space $\mathcal{V}$, defined by the decomposition
$\mathbb{T} = \sum_{k=1}^\infty \xi_k \psi_k \phi_k^*$ \\
$\bLambda$ & $\mathbb{R}^{\infty \times \infty}$ & The spectral matrix of $\mathbb{T}$, $\bLambda = \operatorname{diag}(\xi_1^2, \xi_2^2, \ldots) \in \mathbb{R}^{\infty \times \infty}$ \\
$\bg_i$ & $\mathbb{R}^{\infty}$ & $\bg_i := (\psi_k(\bx_i))_{k \geq 1}$\\
$\boldf_i$ & $\mathbb{R}^{\infty}$ & $\boldf_i := (\xi_k\phi_k(\bw_i))_{k \geq 1}$\\
$\bG$ & $\mathbb{R}^{n \times \infty}$ & 
$\bG \!:=\! [\bg_1, \ldots, \bg_n]^\sT \!\in\! \mathbb{R}^{n \times \infty}$ with $\bg_i := (\psi_k(\bx_i))_{k \geq 1}$\\
$\bF$ & $\mathbb{R}^{p \times \infty}$ & $\bF \!:=\! [\boldf_1, \ldots, \boldf_p]^\sT \!\in\! \mathbb{R}^{p \times \infty}$\\
$\hbLambda_\bF$ & $\mathbb{R}^{p \times p}$ & $\hbLambda_\bF := \E_\bz[\bz\bz^\sT|\bF] = \frac{1}{p}\bF\bF^\sT \in \R^{p \times p}$ \\
$\btheta_{*,k}$ & $\mathbb{R}$ & The coefficients associated with the eigenfunction $\psi_k$ in the expansion of $f_*(\bx)=\sum_{k\geq1}\btheta_{*,k}\psi_k(\bx)$ \\
$\btheta_*$ & $\mathbb{R}^{\infty}$ & $\btheta_* = (\btheta_{*,k})_{k \geq 1}$ \\
\midrule
\end{tabular}
\begin{tablenotes}
    \footnotesize
    \item[1] Replacing $\mathcal{N}$ with $\mathcal{R}$ ($\sN$ with $\sR$), we get the notations associated to the test risk.
    \item[2] Replacing $\lambda$ with $0$, we get the notations associated to the min-$\ell_2$-norm solution.
    \item[3] Replacing ${\tt LS}$ with ${\tt RFM}$, we get the notations associated to random feature regression.
\end{tablenotes}
\end{threeparttable}
\end{table}