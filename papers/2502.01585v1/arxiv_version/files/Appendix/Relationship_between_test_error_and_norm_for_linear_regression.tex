\subsection{Proofs on relationship between the test risk and \texorpdfstring{$\ell_2$}{L2} norm of ridge regression estimator}
\label{app:relationship}

In this section, we will prove the relationship between the test risk and $\ell_2$ norm of the ridge regression estimator that we give in the main text.



\label{proof:linear:relation}
\begin{proof}[Proof of \cref{prop:relation_id}]
According to the formulation of $\sB_{\sN,\lambda}^{\tt LS}$ and $\sV_{\sN,\lambda}^{\tt LS}$ in \cref{eq:equiv-linear}, for $\bSigma=\id_d$, we have
\[
    \sB_{\sN,\lambda}^{\tt LS} = \frac{1}{(1+\lambda_*)^2}\|\bbeta_*\|_2^2 + \frac{d}{n(1+\lambda_*)^2} \cdot \frac{\lambda_*^2 \frac{1}{(1+\lambda_*)^2}\|\bbeta_*\|_2^2}{1-\frac{d}{n(1+\lambda_*)^2}} \,, \quad \sV_{\sN,\lambda}^{\tt LS} = \frac{\sigma^2\frac{d}{(1+\lambda_*)^2}}{n-\frac{d}{(1+\lambda_*)^2}}\,,
\]
\[
    \sN_{\lambda}^{\tt LS} = \frac{d}{(1+\lambda_*)^2}\|\bbeta_*\|_2^2 + \frac{d}{n(1+\lambda_*)^2} \cdot \frac{\lambda_*^2 \frac{d}{(1+\lambda_*)^2}\|\bbeta_*\|_2^2}{1-\frac{d}{n(1+\lambda_*)^2}} + \frac{\sigma^2\frac{d}{(1+\lambda_*)^2}}{n-\frac{d}{(1+\lambda_*)^2}}\,,
\]
where $\lambda_*$ admits a closed-form solution
\[
\lambda_*=\frac{d+\lambda-n+\sqrt{4\lambda n + (n-d-\lambda)^2}}{2n} \,.
\]
Recall the formulation $\sB_{\sR,\lambda}^{\tt LS}$ and $\sV_{\sR,\lambda}^{\tt LS}$ (for test risk) in \cref{eq:de_risk}, for $\bSigma=\id_d$, we have
\[
\begin{aligned}
    \sB_{\sR,\lambda}^{\tt LS} = \frac{\lambda_*^2 \frac{1}{(1+\lambda_*)^2}\|\bbeta_*\|_2^2}{1-\frac{d}{n(1+\lambda_*)^2}} \,, \quad \sV_{\sR,\lambda}^{\tt LS} = \frac{\sigma^2\frac{d}{(1+\lambda_*)^2}}{n-\frac{d}{(1+\lambda_*)^2}}\,, \quad
    \sR_{\lambda}^{\tt LS} = \frac{\lambda_*^2 \frac{d}{(1+\lambda_*)^2}\|\bbeta_*\|_2^2}{1-\frac{d}{n(1+\lambda_*)^2}} + \frac{\sigma^2\frac{d}{(1+\lambda_*)^2}}{n-\frac{d}{(1+\lambda_*)^2}}\,.
\end{aligned}
\]
Accordingly, to establish the relationship between $\sR_{\lambda}^{\tt LS}$ and $\sN_{\lambda}^{\tt LS}$, we combine their formulation and eliminate $n$ to obtain\footnote{Due to the complexity of the calculations, we use Mathematica Wolfram to eliminate $n$. The same approach is applied later whenever $n$ or $p$ elimination is required.}
\[
\begin{aligned}
    2( (\sR^{\tt LS}_{\lambda} - \sN^{\tt LS}_{\lambda})^2 - \|\bbeta_*\|_2^4 ) d \sigma^2 =&~ (\|\bbeta_*\|_2^2 - \sR^{\tt LS}_{\lambda} - \sN^{\tt LS}_{\lambda})(\|\bbeta_*\|_2^2 + \sR^{\tt LS}_{\lambda} - \sN^{\tt LS}_{\lambda})^2d\\
    &~+ 2\|\bbeta_*\|_2^2((\|\bbeta_*\|_2^2 + \sR^{\tt LS}_{\lambda} - \sN^{\tt LS}_{\lambda})^2-4\|\bbeta_*\|_2^2\sR^{\tt LS}_{\lambda} ) \lambda\,.
\end{aligned}
\]
\end{proof}

\begin{proof}[Proof of \cref{prop:relation_minnorm_id}]
According to \cref{prop:asy_equiv_error_LR_minnorm} and \cref{prop:asy_equiv_norm_LR_minnorm}, for minimum $\ell_2$-norm estimator and $\bSigma = \id_d$, for the under-parameterized regime ($d<n$), we have
\[
\begin{aligned}
\sB_{\sR,0}^{\tt LS} = 0\,, \quad \sV_{\sR,0}^{\tt LS} = \frac{\sigma^2d}{n-d}\,; \quad \quad \sB_{\sN,0}^{\tt LS} = \|\bbeta_*\|_2^2\,, \quad \sV_{\sN,0}^{\tt LS} = \frac{\sigma^2d}{n-d}\,. 
\end{aligned}
\]
From these expressions, we can conclude that
\[
\begin{aligned}
    \sR_{0}^{\tt LS} = \sB_{\sR,0}^{\tt LS} + \sV_{\sR,0}^{\tt LS} = \frac{\sigma^2d}{n-d}\,; \quad \quad \sN_{0}^{\tt LS} = \sB_{\sN,0}^{\tt LS} + \sV_{\sN,0}^{\tt LS} = \|\bbeta_*\|_2^2 + \frac{\sigma^2d}{n-d}\,. 
\end{aligned}
\]
Finally, in the under-parameterized regime, it follows that
\begin{equation*}
 \sR_{0}^{\tt LS} = \sN_{0}^{\tt LS} - \|\bbeta_*\|_2^2\,.   
\end{equation*}

In the over-parameterized regime ($d>n$), the effective regularization $\lambda_*$ will have an explicit formulation as $\lambda_* = \frac{d-n}{n}$, thus for the bias and variance of the test error, we have
\[
\begin{aligned}
\sB_{\sR,0}^{\tt LS} = \frac{\lambda_n^2\<\bbeta_*,\bSigma(\bSigma+\lambda_n\id)^{-2}\bbeta_*\>}{1-n^{-1}\Tr(\bSigma^2(\bSigma+\lambda_n)^{-2})} = \frac{\lambda_n^2 \frac{1}{(1 + \lambda_n)^2}\|\bbeta_*\|_2^2}{1 - \frac{1}{n}\frac{d}{(1+\lambda_n)^2}} = \|\bbeta_*\|_2^2\frac{d-n}{d}\,,
\end{aligned}
\]
\[
\begin{aligned}
\sV_{\sR,0}^{\tt LS} = \frac{\sigma^2\Tr(\bSigma^2(\bSigma+\lambda_n\id)^{-2})}{n-\Tr(\bSigma^2(\bSigma+\lambda_n\id)^{-2})} = \frac{\sigma^2\frac{d}{(1+\lambda_n)^2}}{n-\frac{d}{(1+\lambda_n)^2}} = \sigma^2\frac{n}{d-n}\,,
\end{aligned}
\]
and combining the bias and variance, we have
\begin{align}\label{eq:r_under}
\sR_{0}^{\tt LS} = \sB_{\sR,0}^{\tt LS} + \sV_{\sR,0}^{\tt LS} = \|\bbeta_*\|_2^2\frac{d-n}{d} + \sigma^2\frac{n}{d-n}\,.
\end{align}
For the bias and variance of the norm, we have
\[
\begin{aligned}
\sB_{\sN,0}^{\tt LS} = \<\bbeta_*,\bSigma(\bSigma+\lambda_n\id)^{-1}\bbeta_*\> = \frac{1}{1+\lambda_n}\|\bbeta_*\|_2^2 = \|\bbeta_*\|_2^2\frac{n}{d}\,,
\end{aligned}
\]
\[
\begin{aligned}
\sV_{\sN,0}^{\tt LS} = \frac{\sigma\Tr(\bSigma(\bSigma+\lambda_n\id)^{-2})}{n-\Tr(\bSigma^2(\bSigma+\lambda_n\id)^{-2})} = \frac{\sigma^2\frac{d}{(1+\lambda_n)^2}}{n-\frac{d}{(1+\lambda_n)^2}} = \sigma^2\frac{n}{d-n}\,,
\end{aligned}
\]
and combining the bias and variance, we have

\begin{align}\label{eq:n_under}
\sN_{0}^{\tt LS} = \sB_{\sN,0}^{\tt LS} + \sV_{\sN,0}^{\tt LS} = \|\bbeta_*\|_2^2\frac{n}{d} + \sigma^2\frac{n}{d-n}\,.
\end{align}
Finally, combining \cref{eq:r_under} and \cref{eq:n_under}, we eliminate $n$ and thus obtain
\[
\begin{aligned}
    \sR_{0}^{\tt LS} = \sqrt{(\sN^{\tt LS}_0)^2 \!-\! 2(\|\bbeta_*\|_2^2 \!-\! \sigma^2)\sN^{\tt LS}_0 + (\|\bbeta_*\|_2^2 \!+\! \sigma^2)^2} \!-\!\sigma^2\,.
\end{aligned}
\]
By taking the derivative of $\sR_{0}^{\tt LS}$ with respect to $\sN_{0}^{\tt LS}$, we get
\[
\frac{\partial \sR_{0}^{\tt LS}}{\partial \sN_{0}^{\tt LS}} = \frac{\sN_{0}^{\tt LS} - (\|\bbeta_*\|_2^2 - \sigma^2)}{\sqrt{(\sN_{0}^{\tt LS})^2 - 2(\|\bbeta_*\|_2^2 - \sigma^2)\sN_{0}^{\tt LS} + (\|\bbeta_*\|_2^2 + \sigma^2)^2}}\,.
\]
From the derivative function, we observe that $\sR_{0}^{\tt LS}$ decreases monotonically with $\sN_{0}^{\tt LS}$ when $\sN_{0}^{\tt LS} < \|\boldsymbol{\beta}_*\|_2^2 - \sigma^2$, and increases monotonically with $\sN_{0}^{\tt LS}$ when $\sN_{0}^{\tt LS} > \|\boldsymbol{\beta}_*\|_2^2 - \sigma^2$.
\end{proof}

\begin{proof}[Proof of \cref{prop:relation_minnorm_underparam}]
According to \cref{prop:asy_equiv_error_LR_minnorm} and \cref{prop:asy_equiv_norm_LR_minnorm}, for minimum $\ell_2$-norm estimator, in the under-parameterized regime ($d<n$), we have
\[
\begin{aligned}
\sB_{\sR,0}^{\tt LS} = 0\,, \quad \sV_{\sR,0}^{\tt LS} = \frac{\sigma^2d}{n-d}\,; \quad \quad \sB_{\sN,0}^{\tt LS} = \|\bbeta_*\|_2^2\,, \quad \sV_{\sN,0}^{\tt LS} = \frac{\sigma^2\Tr(\bSigma^{-1})}{n-d}\,. 
\end{aligned}
\]
From these expressions, we can conclude that
\[
\begin{aligned}
    \sR_{0}^{\tt LS} = \sB_{\sR,0}^{\tt LS} + \sV_{\sR,0}^{\tt LS} = \frac{\sigma^2d}{n-d}\,; \quad \quad \sN_{0}^{\tt LS} = \sB_{\sN,0}^{\tt LS} + \sV_{\sN,0}^{\tt LS} = \|\bbeta_*\|_2^2 + \frac{\sigma^2\Tr(\bSigma^{-1})}{n-d}\,. 
\end{aligned}
\]
Finally, combing the above equation and eliminate \(n\), in the under-parameterized regime, it follows that
\begin{equation}\label{eq:rn_under}
 \sR_{0}^{\tt LS} = \frac{d}{\Tr(\bSigma^{-1})}\left(\sN_{0}^{\tt LS} - \|\bbeta_*\|_2^2\right)\,.   
\end{equation}
\end{proof}


\begin{proof}[Proof of \cref{prop:relation_minnorm_pl}]
In the over-parameterized regime ($d > n$), according to \cref{prop:asy_equiv_error_LR_minnorm} and \cref{prop:asy_equiv_norm_LR_minnorm}, under \cref{ass:powerlaw}, we have
\[
\begin{aligned}
    \sB_{\sR,0}^{\tt LS} =&~ \frac{\lambda_n^2\<\bbeta_*,\bSigma(\bSigma+\lambda_n\id)^{-2}\bbeta_*\>}{1-n^{-1}\Tr(\bSigma^2(\bSigma+\lambda_n\id)^{-2})} = \frac{\lambda_n^2\Tr(\bSigma^{1+\beta}(\bSigma+\lambda_n\id)^{-2})}{1-n^{-1}\Tr(\bSigma^2(\bSigma+\lambda_n\id)^{-2})}\,,\\
    \sV_{\sR,0}^{\tt LS} =&~ \frac{\sigma^2 \Tr\left(\bSigma^2 (\bSigma + \lambda_n\id)^{-2}\right)}{n - \Tr\left(\bSigma^2 (\bSigma + \lambda_n\id)^{-2}\right)}\,,\\
    \sB_{\sN,0}^{\tt LS} =&~ \<\bbeta_*,\bSigma(\bSigma+\lambda_n\id)^{-1}\bbeta_*\> = \Tr(\bSigma^{1+\beta}(\bSigma+\lambda_n\id)^{-1})\,,\\
    \sV_{\sN,0}^{\tt LS} =&~ \frac{\sigma^2 \Tr\left(\bSigma (\bSigma + \lambda_n\id)^{-2}\right)}{n - \Tr\left(\bSigma^2 (\bSigma + \lambda_n\id)^{-2}\right)}\,.
\end{aligned}
\]
To compute these quantities, here we introduce the following continuum approximations to eigensums.
\begin{equation}\label{eq:df1_inter_approx} 
\int_{1}^{d+1} \frac{k^{-\alpha}}{k^{-\alpha} + \lambda_n}\, \mathrm{d}k \leq \Tr(\bSigma(\bSigma+\lambda_n)^{-1}) = \sum_{i=1}^{d} \frac{\sigma_i}{\sigma_i + \lambda_n} \leq 
   \int_{0}^{d} \frac{k^{-\alpha}}{k^{-\alpha} + \lambda_n}\, \mathrm{d}k \,,
\end{equation}
due to the fact that the integrand is non-increasing function of $k$.
Similarly, we also have
\begin{equation}\label{eq:df2_inter_approx}\int_{1}^{d+1} \frac{k^{-2\alpha}}{(k^{-\alpha} + \lambda_n)^2}\, \mathrm{d}k \leq \Tr(\bSigma^2(\bSigma+\lambda_n)^{-2}) = \sum_{i=1}^{d} \frac{\sigma_i^2}{(\sigma_i + \lambda_n)^2} \leq  \int_{0}^{d} \frac{k^{-2\alpha}}{(k^{-\alpha} + \lambda_n)^2}\, \mathrm{d}k \,.
\end{equation}


We consider some special cases that are useful for discussion.
When $\alpha=1$, we have

\begin{equation}\label{eq:df1_inter_approx_alpha1}
   \frac{\log(1+d\lambda_n + \lambda_n) - \log (1+\lambda_n)}{\lambda_n}  \leq \Tr(\bSigma(\bSigma+\lambda_n)^{-1}) \leq  \frac{\log(1+d\lambda_n)}{\lambda_n} \,,
\end{equation}

\begin{equation}\label{eq:df2_inter_approx_alpha1}
\frac{d+1}{\lambda_n d +\lambda_n +1} - \frac{1}{\lambda_n+1} \leq    \Tr(\bSigma^2(\bSigma+\lambda_n)^{-2}) = \sum_{i=1}^{d} \frac{\sigma_i^2}{(\sigma_i + \lambda_n)^2} \leq \frac{d}{1+d\lambda_n}\,.
\end{equation}
Recall that \(\lambda_n\) is defined by \(\Tr(\bSigma(\bSigma + \lambda_n \id)^{-1}) = n\). Using \cref{eq:df1_inter_approx}, we have 
\[
\frac{\log(1 + d\lambda_n)}{\lambda_n} \approx n.
\]
Observe that as \(n \to d\), \(\lambda_n \to 0\), allowing us to apply a Taylor expansion:
\[
\frac{\log(1 + d\lambda_n)}{\lambda_n} \approx \frac{d\lambda_n - \frac{1}{2}(d\lambda_n)^2}{\lambda_n} = d - \frac{1}{2}d^2\lambda_n.
\]
Based on this approximation, \(\lambda_n\) can be expressed as
\[
\lambda_n \approx \frac{2(d - n)}{d^2}.
\]
In the following discussion, we consider the case $n \to d$. Thus, we have the approximation
\[
\Tr(\bSigma(\bSigma+\lambda_n)^{-1}) \approx n\,, \quad \Tr(\bSigma^2(\bSigma+\lambda_n)^{-2}) \approx \frac{d}{1+d\lambda_n}\,.
\]
Then we have
\[
\begin{aligned}
    \sV_{\sR,0}^{\tt LS} =&~ \frac{\sigma^2 \Tr\left(\bSigma^2 (\bSigma + \lambda_n\id)^{-2}\right)}{n - \Tr\left(\bSigma^2 (\bSigma + \lambda_n\id)^{-2}\right)} \approx \frac{\sigma^2\frac{d}{1+d\lambda_n}}{n-\frac{d}{1+d\lambda_n}} = \frac{\sigma^2 d}{n+d(n\lambda_n-1)}\,,\\
    \sV_{\sN,0}^{\tt LS} =&~ \frac{\sigma^2 \Tr\left(\bSigma (\bSigma + \lambda_n\id)^{-2}\right)}{n - \Tr\left(\bSigma^2 (\bSigma + \lambda_n\id)^{-2}\right)} \approx \frac{\sigma^2\frac{1}{\lambda_n}(d - \frac{1}{2}d^2\lambda_n - \frac{d}{1+d\lambda_n})}{n-\frac{d}{1+d\lambda_n}} = \frac{\sigma^2d^2(d\lambda_n-1)}{2(n+d(n\lambda_n-1))}\,.
\end{aligned}
\]
Use these two formulation to eliminate $n$, we obtain
\[
\sV_{\sR, 0}^{\tt LS} \approx \frac{2(\sV_{\sN, 0}^{\tt LS})^2}{d\sV_{\sN, 0}^{\tt LS}-d^2\sigma^2}\,.
\]

Next we discuss the situation under different $\beta$.

For $\beta=0$, we have
\[
\begin{aligned}
    \sB_{\sR,0}^{\tt LS} =&~ \frac{\lambda_n^2\Tr(\bSigma(\bSigma+\lambda_n\id)^{-2})}{1-n^{-1}\Tr(\bSigma^2(\bSigma+\lambda_n\id)^{-2})} \approx \frac{\lambda_n(d - \frac{1}{2}d^2\lambda_n - \frac{d}{1+d\lambda_n})}{1-\frac{d}{n(1+d\lambda_n)}} = n\lambda_n\,,\\
    \sB_{\sN,0}^{\tt LS} =&~ \Tr(\bSigma(\bSigma+\lambda_n\id)^{-1}) \approx d - \frac{1}{2}d^2\lambda_n\,,\\
\end{aligned}
\]
Use these two formulation to eliminate $n$, we obtain
\[
\sB_{\sR,0}^{\tt LS} \approx \frac{2\sB_{\sN, 0}^{\tt LS}(d-\sB_{\sN, 0}^{\tt LS})}{d^2}\,.
\]

For $\beta=1$, we have
\[
\begin{aligned}
    \sB_{\sR,0}^{\tt LS} =&~ \frac{\lambda_n^2\Tr(\bSigma^2(\bSigma+\lambda_n\id)^{-2})}{1-n^{-1}\Tr(\bSigma^2(\bSigma+\lambda_n\id)^{-2})} \approx \frac{\lambda_n^2\frac{d}{1+d\lambda_n}}{1-\frac{d}{n(1+d\lambda_n)}} = \frac{nd\lambda_n^2}{n(1+d\lambda_n)-d}\,,\\
    \sB_{\sN,0}^{\tt LS} =&~ \Tr(\bSigma^2(\bSigma+\lambda_n\id)^{-1}) = \Tr(\bSigma) - \lambda_n\Tr(\bSigma(\bSigma+\lambda_n\id)^{-1}) \approx \Tr(\bSigma) - n\lambda_n\,.\\
\end{aligned}
\]
Use these two formulation to eliminate $n$, we obtain
\[
\sB_{\sR,0}^{\tt LS} \approx \frac{2\sqrt{(\sB_{\sN, 0}^{\tt LS})^2-2\Tr(\bSigma)\sB_{\sN, 0}^{\tt LS}+\Tr(\bSigma)^2}}{\sqrt{d^2+2d^2\sB_{\sN, 0}^{\tt LS}-2d^2\Tr(\bSigma)}} = \frac{2(\sB_{\sN, 0}^{\tt LS} - \Tr(\bSigma))}{d\sqrt{1+2\sB_{\sN, 0}^{\tt LS}-2\Tr(\bSigma)}}\,.
\]

For $\beta=-1$, we need to use another two continuum approximations to eigensums
\begin{equation*}
    \Tr((\bSigma+\lambda_n)^{-1}) = \sum_{i=1}^{d} \frac{1}{\sigma_i + \lambda_n} \approx \int_{0}^{d} \frac{1}{k^{-\alpha} + \lambda_n}\, \mathrm{d}k = \frac{d\lambda_n - \log(1+d\lambda_n)}{\lambda_n^2}\,,
\end{equation*}
\begin{equation*}
    \Tr((\bSigma+\lambda_n)^{-2}) = \sum_{i=1}^{d} \frac{1}{(\sigma_i + \lambda_n)^2} \approx \int_{0}^{d} \frac{1}{(k^{-\alpha} + \lambda_n)^2}\, \mathrm{d}k = \frac{\frac{d\lambda_n(2+d\lambda_n)}{1+d\lambda_n}-2\log(1+d\lambda_n)}{\lambda_n^3}\,.
\end{equation*}
Once again, we apply the Taylor expansion, but this time expanding to the third order
\[
\log(1 + d\lambda_n) \approx d\lambda_n - \frac{1}{2}(d\lambda_n)^2 + \frac{1}{3}(d\lambda_n)^3\,.
\]
Then we have
\begin{equation*}
    \Tr((\bSigma+\lambda_n)^{-1}) \approx \frac{d\lambda_n - \log(1+d\lambda_n)}{\lambda_n^2} \approx \frac{1}{2}d^2-\frac{1}{3}d^3\lambda_n\,,
\end{equation*}
\begin{equation*}
    \Tr((\bSigma+\lambda_n)^{-2}) \approx \frac{\frac{d\lambda_n(2+d\lambda_n)}{1+d\lambda_n}-2\log(1+d\lambda_n)}{\lambda_n^3} = \frac{\frac{1}{3}d^3-\frac{2}{3}d^4\lambda_n}{1+d\lambda_n}\,.
\end{equation*}
Using the approximation sated above, we have
\[
\begin{aligned}
    \sB_{\sR,0}^{\tt LS} =&~ \frac{\lambda_n^2\Tr((\bSigma+\lambda_n\id)^{-2})}{1-n^{-1}\Tr(\bSigma^2(\bSigma+\lambda_n\id)^{-2})} \approx \frac{\lambda_n^2(\nicefrac{(\frac{1}{3}d^3-\frac{2}{3}d^4\lambda_n)}{(1+d\lambda_n)})}{1-\frac{d}{n(1+d\lambda_n)}} \,,\\
    \sB_{\sN,0}^{\tt LS} =&~ \Tr((\bSigma+\lambda_n\id)^{-1}) = \frac{1}{2}d^2-\frac{1}{3}d^3\lambda_n \,.\\
\end{aligned}
\]
Use these two formulation to eliminate $n$, we obtain
\[
\sB_{\sR,0}^{\tt LS} \approx \frac{216 (\sB_{\sN, 0}^{\tt LS})^4 \!-\! 324d^2 (\sB_{\sN, 0}^{\tt LS})^3 \!+\! 126d^4 (\sB_{\sN, 0}^{\tt LS})^2 \!+\! d^6 \sB_{\sN, 0}^{\tt LS} \!-\! 5d^8}{2d^5(6 \sB_{\sN, 0}^{\tt LS}-d^2)}\,.
\]
\end{proof}

Here we present some experimental results to check the relationship between $\sB_{\sR,0}^{\tt LS}$ and $\sB_{\sN,0}^{\tt LS}$, as well as $\sV_{\sR,0}^{\tt LS}$ and $\sV_{\sN,0}^{\tt LS}$, see \cref{fig:linear_regression_power_law}.
We can see that our approximate relationship on variance (see the {\color{red}red} line in \cref{fig:lrpld}) provides the precise estimation.
For the bias (see the left three figures of \cref{fig:linear_regression_power_law}), our approximate relationship is accurate if $\sB_{\sN,0}^{\tt LS}$ is large.



