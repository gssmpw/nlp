\section{Related Work}
\paragraph{Slot and Intent Detection.}
Traditional approaches to spoken language understanding (SLU) often treat SID separately using domain-specific classification or sequence tagging approaches **Devlin et al., "BERT: Pre-training of Deep Bidirectional Transformers for Language Understanding"**. More recent transformer-based solutions unify both tasks, leveraging contextual embeddings to improve performance **Vilnis et al., "Improving Neural Language Modelling with Alignment"** with models like BERT **Sennrich et al., "Controlling Politeness in Neural Machine Translation"**. However, many of these solutions still presume tailored sequence labeling datasets or full-size transformer backends. Our work aligns with the shift to more expressive transformer models for SLU, but we push inference to a local environment while also adding dynamic text generation.

\paragraph{Running LLMs on Edge Devices.}
While training large-scale LLMs remains computationally expensive, numerous works explore strategies for \emph{deploying} them on edge hardware. **Gupta et al., "FPGA-based Accelerators for Deep Learning"** propose FPGA-based accelerators to reduce memory overhead for LLM inference. **Narayanan et al., "Distributed Training of Large-Scale Neural Networks"** distribute an LLM across multiple low-power devices to increase throughput. An empirical footprint study by **Bourlard et al., "High-Level Symbolic Representation of Continuous Acoustic Signal Processing"** shows that even 7B-parameter models can strain embedded hardware if not sufficiently compressed. Our approach uses a much smaller LLM (0.5B--1.5B parameters) plus weight quantization, showing that near-commodity devices with 8GB RAM can handle both intent classification and text generation if the domain is sufficiently specialized.