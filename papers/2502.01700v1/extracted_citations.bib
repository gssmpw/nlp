@article{Abadade2023,
   author = {Youssef Abadade and Anas Temouden and Hatim Bamoumen and Nabil Benamar and Yousra Chtouki and Abdelhakim Senhaji Hafid},
   doi = {10.1109/ACCESS.2023.3294111},
   issn = {2169-3536},
   journal = {IEEE Access},
   pages = {96892-96922},
   title = {A Comprehensive Survey on TinyML},
   volume = {11},
   year = {2023},
}

@article{Baciu2024,
   author = {Vlad-Eusebiu Baciu and Johan Stiens and Bruno da Silva},
   doi = {10.1016/j.sysarc.2024.103262},
   issn = {13837621},
   journal = {Journal of Systems Architecture},
   month = {10},
   pages = {103262},
   title = {MLino bench: A comprehensive benchmarking tool for evaluating ML models on edge devices},
   volume = {155},
   year = {2024},
}

@article{Banbury2020,
   abstract = {Recent advancements in ultra-low-power machine learning (TinyML) hardware promises to unlock an entirely new class of smart applications. However, continued progress is limited by the lack of a widely accepted benchmark for these systems. Benchmarking allows us to measure and thereby systematically compare, evaluate, and improve the performance of systems and is therefore fundamental to a field reaching maturity. In this position paper, we present the current landscape of TinyML and discuss the challenges and direction towards developing a fair and useful hardware benchmark for TinyML workloads. Furthermore, we present our four benchmarks and discuss our selection methodology. Our viewpoints reflect the collective thoughts of the TinyMLPerf working group that is comprised of over 30 organizations.},
   author = {Colby R. Banbury and Vijay Janapa Reddi and Max Lam and William Fu and Amin Fazel and Jeremy Holleman and Xinyuan Huang and Robert Hurtado and David Kanter and Anton Lokhmotov and David Patterson and Danilo Pau and Jae-sun Seo and Jeff Sieracki and Urmish Thakker and Marian Verhelst and Poonam Yadav},
   journal = {ArXiv},
   month = {3},
   title = {Benchmarking TinyML Systems: Challenges and Direction},
   year = {2020},
}

@article{Capogrosso2024,
   author = {Luigi Capogrosso and Federico Cunico and Dong Seon Cheng and Franco Fummi and Marco Cristani},
   doi = {10.1109/ACCESS.2024.3365349},
   issn = {2169-3536},
   journal = {IEEE Access},
   pages = {23406-23426},
   title = {A Machine Learning-Oriented Survey on Tiny Machine Learning},
   volume = {12},
   year = {2024},
}

@article{Immonen2022,
   abstract = {<p>We use 250 billion microcontrollers daily in electronic devices that are capable of running machine learning models inside them. Unfortunately, most of these microcontrollers are highly constrained in terms of computational resources, such as memory usage or clock speed. These are exactly the same resources that play a key role in teaching and running a machine learning model with a basic computer. However, in a microcontroller environment, constrained resources make a critical difference. Therefore, a new paradigm known as tiny machine learning had to be created to meet the constrained requirements of the embedded devices. In this review, we discuss the resource optimization challenges of tiny machine learning and different methods, such as quantization, pruning, and clustering, that can be used to overcome these resource difficulties. Furthermore, we summarize the present state of tiny machine learning frameworks, libraries, development environments, and tools. The benchmarking of tiny machine learning devices is another thing to be concerned about; these same constraints of the microcontrollers and diversity of hardware and software turn to benchmark challenges that must be resolved before it is possible to measure performance differences reliably between embedded devices. We also discuss emerging techniques and approaches to boost and expand the tiny machine learning process and improve data privacy and security. In the end, we form a conclusion about tiny machine learning and its future development.</p>},
   author = {Riku Immonen and Timo H채m채l채inen},
   doi = {10.1155/2022/7437023},
   issn = {1687-7268},
   journal = {Journal of Sensors},
   month = {11},
   pages = {1-11},
   title = {Tiny Machine Learning for Resource-Constrained Microcontrollers},
   volume = {2022},
   year = {2022},
}

@inproceedings{MLonMCU,
   author = {Philipp van Kempen and Rafael Stahl and Daniel Mueller-Gritschneder and Ulf Schlichtmann},
   city = {New York, NY, USA},
   doi = {10.1145/3615338.3618128},
   isbn = {9798400703379},
   booktitle = {Proceedings of the 2023 Workshop on Compilers, Deployment, and Tooling for Edge AI},
   month = {9},
   pages = {32-36},
   publisher = {ACM},
   title = {MLonMCU: TinyML Benchmarking with Fast Retargeting},
   year = {2023},
}

@article{Njor2024,
   author = {Emil Njor and Mohammad Amin Hasanpour and Jan Madsen and Xenofon Fafoutis},
   doi = {10.1109/ACCESS.2024.3512860},
   issn = {2169-3536},
   journal = {IEEE Access},
   month = {12},
   pages = {1-1},
   title = {A Holistic Review of the TinyML Stack for Predictive Maintenance},
   year = {2024},
}

@InProceedings{Osman2022,
author="Osman, Anas
and Abid, Usman
and Gemma, Luca
and Perotto, Matteo
and Brunelli, Davide",
editor="Saponara, Sergio
and De Gloria, Alessandro",
title="TinyML Platforms Benchmarking",
booktitle="Applications in Electronics Pervading Industry, Environment and Society",
year="2022",
publisher="Springer International Publishing",
address="Cham",
pages="139--148",
abstract="Recent advances in state-of-the-art ultra-low power embedded devices for machine learning (ML) have permitted a new class of products whose key features enable ML capabilities on microcontrollers with less than 1 mW power consumption (TinyML). TinyML provides a unique solution by aggregating and analyzing data at the edge on low-power embedded devices. However, we have only recently been able to run ML on microcontrollers, and the field is still in its infancy, which means that hardware, software, and research are changing extremely rapidly. Consequently, many TinyML frameworks have been developed for different platforms to facilitate the deployment of ML models and standardize the process. Therefore, in this paper, we focus on benchmarking two popular frameworks: Tensorflow Lite Micro (TFLM) on the Arduino Nano BLE and CUBE AI on the STM32-NucleoF401RE to provide a standardized framework selection criterion for specific applications.",
isbn="978-3-030-95498-7"
}

@article{Ray2022,
   author = {Partha Pratim Ray},
   doi = {10.1016/j.jksuci.2021.11.019},
   issn = {13191578},
   issue = {4},
   journal = {Journal of King Saud University - Computer and Information Sciences},
   month = {4},
   pages = {1595-1623},
   title = {A review on TinyML: State-of-the-art and prospects},
   volume = {34},
   year = {2022},
}

@article{Saha2022,
   author = {Swapnil Sayan Saha and Sandeep Singh Sandha and Mani Srivastava},
   doi = {10.1109/JSEN.2022.3210773},
   issn = {1530-437X},
   issue = {22},
   journal = {IEEE Sensors Journal},
   month = {11},
   pages = {21362-21390},
   title = {Machine Learning for Microcontroller-Class Hardware: A Review},
   volume = {22},
   year = {2022},
}

@article{Sanchez2020,
   author = {Ramon Sanchez-Iborra and Antonio F. Skarmeta},
   doi = {10.1109/MCAS.2020.3005467},
   issn = {1531-636X},
   issue = {3},
   journal = {IEEE Circuits and Systems Magazine},
   month = {8},
   pages = {4-18},
   title = {TinyML-Enabled Frugal Smart Objects: Challenges and Opportunities},
   volume = {20},
   year = {2020},
}

@article{Tsoukas2024,
   abstract = {<p>Tiny Machine Learning (TinyML) is an emerging technology proposed by the scientific community for developing autonomous and secure devices that can gather, process, and provide results without transferring data to external entities. The technology aims to democratize AI by making it available to more sectors and contribute to the digital revolution of intelligent devices. In this work, a classification of the most common optimization techniques for Neural Network compression is conducted. Additionally, a review of the development boards and TinyML software is presented. Furthermore, the work provides educational resources, a classification of the technology applications, and future directions and concludes with the challenges and considerations.</p>},
   author = {Vasileios Tsoukas and Anargyros Gkogkidis and Eleni Boumpa and Athanasios Kakarountas},
   doi = {10.1145/3661820},
   issn = {0360-0300},
   issue = {10},
   journal = {ACM Computing Surveys},
   month = {10},
   pages = {1-37},
   title = {A Review on the emerging technology of TinyML},
   volume = {56},
   year = {2024},
}

@article{Wulfert2024,
   author = {Lars Wulfert and Johannes K체hnel and Lukas Krupp and Justus Viga and Christian Wiede and Pierre Gembaczka and Anton Grabmaier},
   doi = {10.1109/TPAMI.2024.3355495},
   issn = {0162-8828},
   issue = {6},
   journal = {IEEE Transactions on Pattern Analysis and Machine Intelligence},
   month = {6},
   pages = {4519-4533},
   title = {AIfES: A Next-Generation Edge AI Framework},
   volume = {46},
   year = {2024},
}

