\section{Experiments}
\label{sec:experiments}

In this section, we use \oursystem to teleoperate the \texttt{LEAP Hand}~\cite{shaw2023leaphand} mounted on the \texttt{Franka Robot Arm} to evaluate its effectiveness through a series of challenging tasks across three key aspects:

\vspace{1mm}

\hangindent=1em
\noindent\textbullet\hspace{0.5em}\textbf{Haptic Force Perception:} Without visual feedback, how effectively can \oursystem assist human operators in perceiving object properties through haptic force feedback?

\hangindent=1em
\noindent\textbullet\hspace{0.5em}\textbf{Teleoperation Efficiency:} Does integrating haptic force feedback improve vision-based teleoperation success rates and reduce task completion time? Can \oursystem enable human operators to perform challenging, contact-rich manipulation tasks?

\hangindent=1em
\noindent\textbullet\hspace{0.5em}\textbf{IL Compatibility:} Can the data collected via \oursystem be leveraged to train IL policies for dexterous manipulation?

\vspace{1mm}

\noindent \textbf{Evaluation Setup:} To evaluate the effectiveness of haptic force perception, we conduct a user study (Section~\ref{sec::user_study}) and a quantitative experiment (Section~\ref{sec::bottle-slipping}). Teleoperation efficiency is assessed in Experiment~\ref{sec::milk_box}, while IL compatibility is evaluated in Experiment~\ref{sec::IL}.

\vspace{1mm}

\noindent \textbf{Comparisons:} All experiments share the following comparison conditions, although a subset of these may be selected depending on the specific task setup:

\hangindent=1em
\noindent\textbullet\hspace{0.5em}\scaletexttt{Only Force:} Force feedback is enabled only when the force sensor readings exceed 10~g.

\hangindent=1em
\noindent\textbullet\hspace{0.5em}\scaletexttt{Only Haptic:} Haptic feedback is enabled only when the force sensor readings exceed 10~g.

\hangindent=1em
\noindent\textbullet\hspace{0.5em}\scaletexttt{Haptic+Force:} A combined feedback strategy is applied, as detailed in Section~\ref{sec::haptic_force_retargeting}.

\hangindent=1em
\noindent\textbullet\hspace{0.5em}\scaletexttt{No Haptic/Force:} \oursystem is used solely for MoCap, with no feedback provided.

\hangindent=1em
\noindent\textbullet\hspace{0.5em}\scaletexttt{Baseline:} AnyTeleop~\cite{qin2023anyteleop}, a widely recognized vision-based hand retargeting method, is used as the MoCap baseline.

\subsection{User Study: Object Perception \textbf{w/o Visual Feedback}}
\label{sec::user_study}

\input{captions/fg9-user-study}

\noindent \textbf{Task:} 
Five untrained human operators participate in this user study. During the experiment, they are required to distinguish between five pairs of objects solely through feedback from \oursystem, without any visual or auditory input (achieved by wearing an eyemask and headphones). In each trial, a pair of objects is randomly selected, and users provide their answers immediately after experiencing feedback from \oursystem for both objects.
%
Figure~\ref{fig:user_study} illustrates the experiment setup and the five object pairs, selected based on factors such as shape, size, and softness.

\noindent \textbf{Metrics:} 
Users' ability to distinguish object pairs is evaluated based on their success rate.

\noindent \textbf{Challenges:} 
The five object pairs are intentionally chosen based on the following considerations:

\hangindent=1em  
\noindent\textbullet\hspace{0.5em}{Pair 1:} \ul{Basic Pair}, different shape. The ball and the box have distinctly different shapes~(Fig~\ref{fig:user_study}b).

\hangindent=1em  
\noindent\textbullet\hspace{0.5em}{Pair 2:} \ul{Basic Pair}, similar shape, different size. The peanut bottle and the coffee paper cup share a similar cylindrical shape, but their diameters differ slightly~(Fig~\ref{fig:user_study}c).

\hangindent=1em  
\noindent\textbullet\hspace{0.5em}{Pair 3:} \ul{Basic Pair}, similar softness, different size. The two toys have similar softness and shapes but vary in size~(Fig~\ref{fig:user_study}d).

\hangindent=1em  
\noindent\textbullet\hspace{0.5em}{Pair 4:} \ul{Challenging Pair}, similar size and shape, different softness. Two identical bottles are used, one filled with pure water (soft) and the other filled with carbonated cola, shaken to increase its hardness~(Fig~\ref{fig:user_study}e).

\hangindent=1em  
\noindent\textbullet\hspace{0.5em}{Pair 5:} \ul{Challenging Pair}, similar shape, different size and softness. A toy cabbage (softer, larger) and a real cabbage~(Fig~\ref{fig:user_study}f).

\input{captions/tb2-user-study}

\noindent \textbf{Performance:}
As shown in Table~\ref{tab:user_study}, even without visual and auditory feedback, all participants effortlessly distinguish basic pairs 1-3.
%
For challenging pair 4, most participants can perceive softness using only force feedback. Some also discern softness using only haptic feedback by evaluating the duration of contact during deformation.

For challenge pair 5, when the robotic hand grasps the softer toy cabbage, it deforms to resemble the size of the real cabbage. This deformation increases its perceived softness, making it difficult for participants to distinguish using force feedback alone.

For both challenge pairs, combining haptic and force feedback slightly reduces user sensitivity, leading to a marginally lower accuracy.


\subsection{Bottle-Slipping}
\label{sec::bottle-slipping}

\input{captions/fg10-bottle}

\noindent\textit{1) Teleoperation w/o Visual Feedback}


\noindent \textbf{Task:} 
In this experiment, the human operator must perform a bottle-slipping action relying solely on feedback from \oursystem. A 15-second countdown timer is set for each trial. If the bottle successfully slips without falling within the 15 seconds, the trial is denoted as successful.

\noindent \textbf{Metrics:} 
The success rate.

\noindent \textbf{Challenges:} 
Without any visual or auditory input (achieved by wearing an eyemask and headphones), the operator must determine if the bottle is slipping at the right speed or too quickly, risking a fall.

\noindent \textbf{Performance:}
As shown in Fig~\ref{fig:bottle}a, force feedback significantly improves the success rate of this task. Additionally, incorporating haptic feedback further enhances overall performance. However, since the fingers of the LEAP Hand maintain continuous contact with the bottle during the task, haptic feedback does not provide additional information beyond using the glove solely as a MoCap device, resulting in the same success rate for both conditions.

Due to differences in retargeting strategies, even a slight change in human finger position can lead to a significant deviation in the LEAP Hand’s movements. As a result, AnyTeleop~\cite{qin2023anyteleop} struggles to perform the slipping task effectively.

\vspace{1.5mm}

\noindent\textit{2) Teleoperation with Visual Feedback}


\noindent \textbf{Task:} 
Unlike the previous blindfolded experiment, this experiment allows operators to have visual feedback. To further evaluate the operator's control ability, they are required to slip the bottle to a specified distance~(9~cm). A trial is denoted as successful if the bottle slips without falling. Additionally, We measure the deviation between the actual slipping distance and the target distance~(9~cm).

\noindent \textbf{Metrics:} 
Performance is evaluated using two metrics:

\hangindent=1em
\noindent\textbullet\hspace{0.5em}\ul{Success Rate:} A trial is denoted as successful if the bottle slips without falling.

\hangindent=1em
\noindent\textbullet\hspace{0.5em}\ul{Slipping Deviation:} This measures the difference between the target sliding distance (9~cm) and the actual slipping distance, with a smaller deviation indicating greater operational accuracy.

\noindent \textbf{Challenges:} 
Operators must precisely control the bottle to achieve the desired distance. While a greedy approach often causes the bottle to fall and results in failure, a conservative approach leads to an unsatisfactory distance deviation.

\noindent \textbf{Performance:}
This task evaluates not only success rate but also teleoperation precision. To minimize slipping deviation, operators are instructed to control the LEAP Hand carefully and optimally. As shown in Fig~\ref{fig:bottle}a, similar to previous results, haptic feedback does not provide additional information and may even interfere with task precision. However, force feedback enables operators to minimize slipping deviation more effectively. While using \oursystem solely as a MoCap device achieves the same success rate as with haptic force feedback, it results in a larger average slipping deviation.


\subsection{Rotating and Placing the Carton}
\label{sec::milk_box}

\input{captions/tb4-milk-box}
\input{captions/fg11-il}

\noindent \textbf{Task:} 
This is a long-horizon contact-rich task. As shown in Fig~\ref{fig:bottle}b, the operator must first pick up the carton horizontally, then perform an in-hand rotation, orienting the carton vertically before placing it into a small bucket.

\noindent \textbf{Metrics:} 
Performance is evaluated using two metrics:

\hangindent=1em
\noindent\textbullet\hspace{0.5em}\ul{Success Rate:} A trial is denoted as successful if the carton rotates more than 45 degrees and is successfully placed into the bucket.

\hangindent=1em
\noindent\textbullet\hspace{0.5em}\ul{Completion Time:} The total time taken to complete the entire process.

\noindent \textbf{Challenges:} 

\hangindent=1em
\noindent\textbullet\hspace{0.5em}\ul{Precise Manipulation:} The operator must accurately teleoperate to rotate the carton while preventing it from falling.

\hangindent=1em
\noindent\textbullet\hspace{0.5em}\ul{Visual Obstacle:} Grasping the carton is hindered by visual obstacles, as the operator cannot see the contact points between the robotic hand’s fingers and the carton.

\noindent \textbf{Performance:}
Table~\ref{tab:milk_box} shows that both haptic and force feedback significantly improve the teleoperation success rate and reduce completion time. While force feedback alone results in a comparable average completion time, haptic force feedback achieves a higher success rate. The vision-based MoCap method AnyTeleop~\cite{qin2023anyteleop} struggles with in-hand rotation in this task.


\subsection{Imitation Learning}
\label{sec::IL}

We show \oursystem is capable of collecting high-quality demonstrations. \textbf{3D Diffusion Policy~(DP3)}~\cite{Ze2024DP3} is selected as our imitation learning algorithm, and we use \texttt{Realsense L515} to acquire the point cloud inputs, which are then downsampled to 1024 points using farthest point sampling~\cite{qi2017pointnet}. The data collected by \oursystem is used to train policies for various downstream tasks.
%
We evaluate imitation learning performance on 2 basic contact-rich tasks and 1 long-horizon task: 

\noindent \textbf{Press and Move Box:} As shown in Fig~\ref{fig:il}a, the robot must continuously press down on a box and move it to a specified target location. During data collection, the box is randomly placed within a 30$\times$20 cm area, and \oursystem collects 40 demonstrations to train the policy. In evaluation, the box is also randomly placed in the same area. Across 20 trials, the success rate is 85\%~(17/20). 

\noindent \textbf{Pick and Place Teddy Bear:} As shown in Fig~\ref{fig:il}b, the robot must grasp a teddy bear and place it into a designated box. During data collection, the teddy bear’s initial position is randomized within a 30$\times$20 cm area, and \oursystem collects 40 demonstrations to train the policy. In evaluation, the bear is again randomly placed in the same area. Across 20 trials, the success rate is 70\%~(14/20), with failures primarily due to the teddy bear slipping out of the robotic hand when not grasped firmly.

\noindent \textbf{Rotating and Placing the Carton}. This task follows the same setup as Section~\ref{sec::milk_box}. For this contact-rich task, we use 3 human-collected demonstrations to train the policy. Across 10 trials, the success rate is 90\%~(9/10).
