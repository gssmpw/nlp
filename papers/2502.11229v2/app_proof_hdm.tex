\section{Proof of Results in Section \ref{sec:hdm}}  \label{app:proof-hdm}

\subsection{Proof of Theorem \ref{thm:adaptivity}}

Plugging \eqref{eqn:ogd-constant} from \Cref{lem:regret-sublinear} into \Cref{lem:hypergrad-to-online} completes the proof.

\subsection{Proof of Theorem \ref{thm:dynamic-adaptivity}}
Invoking Lipschitzness from \Cref{lem:hx-properties} and \eqref{eqn:auxi-ogd-dynamic-regret} from \Cref{lem:auxi-dynamic} with $\gamma =1+LD,\eta = \frac{D}{(LD+1)\sqrt{K}}$ gives

\begin{equation}
	\textstyle \sum_{k = 1}^K h_{x^k} (P_k) - h_{x^k} (\hat{P}_k) \leq \rho_K + \frac{LD+1}{2} \sqrt{K}\sum_{k = 1}^K \| \hat{P}_k
   - \hat{P}_{k + 1} \|_F\nonumber.
\end{equation}

Plugging the relation into \Cref{lem:hypergrad-to-online} completes the proof.

\subsection{Proof of Theorem \ref{thm:superlin}}

For \Cref{thm:superlin} and \Cref{lem:scalmat-conv} only, we will define the following modified feedback function by replacing $f(x^k)$ in the numerator by $f(x^\star)$:
\[ \hat{h}_x (P) \assign \tfrac{f (x - P \nabla f (x)) - f (x^{\star}) }{\|
   \nabla f (x) \|^2}\geq 0. \]
For a fixed $x$, $\hat{h}_x (P)$ only differs from the original hypergradient
feedback by a constant; it has the same properties as the original feedback function, and the algorithm is exactly the same since only the gradient of $\hat{h}_x$ is considered in the algorithm update.  Using the definition of $\hat{h}_x (P)$, we deduce that 
\begin{align}
  \tfrac{f (x^{K + 1}) - f (x^{\star})}{f (x^1) - f (x^{\star})} ={} & \textstyle \prod_{k = 1}^K \tfrac{f (x^{k + 1}) - f
  (x^{\star})}{f (x^k) - f (x^{\star})} \nonumber\\
  \leq{} & ( \tfrac{1}{K} \textstyle \sum_{k = 1}^K \tfrac{f (x^{k + 1}) - f
  (x^{\star})}{f (x^k) - f (x^{\star})} )^K \nonumber\\
  ={} & ( \tfrac{1}{K} \textstyle \sum_{k = 1}^K \min \{ \tfrac{\hat{h}_{x^k} (P_k) \|
  \nabla f (x^k) \|^2}{f (x^k) - f (x^{\star})}, 1 \} )^K
  \label{eqn:proof-3-1-15} \\
  \leq{} & ( \tfrac{1}{K} \textstyle \sum_{k = 1}^K \min \{ 2 L \hat{h}_{x^k} (P_k), 1 \}
  )^K \label{eqn:proof-3-1-16}\\
  \leq{} & ( \min \{ \tfrac{2 L}{K} \textstyle \sum_{k = 1}^K \hat{h}_{x^k} (P_k), 1
  \} )^K, \nonumber
\end{align}
where \eqref{eqn:proof-3-1-15} plugs in the definition of $\hat{h}_x$; \eqref{eqn:proof-3-1-16} uses $L$-smoothness and that $\hat{h}_x$ is nonnegative. Using \Cref{lem:regret-sublinear}, we get  $\textstyle \sum_{k = 1}^K \hat{h}_{x^k} (P_k) \leq \textstyle \sum_{k = 1}^K \hat{h}_{x^k} (P) + \rho_K$
for any $P \in \mathcal{P}$. Next, we consider the quantity $\hat{h}_x ([\nabla^2 f (x^{\star})]^{- 1})$ and deduce that
\begin{align}
  \hat{h}_x ([\nabla^2 f (x^{\star})]^{- 1}) ={} & \tfrac{f (x - [\nabla^2 f
  (x^{\star})]^{- 1} \nabla f (x)) - f (x^{\star})}{\| \nabla f (x) \|^2}
  \nonumber\\
  \leq{} & \tfrac{\frac{L}{2} \| x - [\nabla^2 f (x^{\star})]^{- 1} \nabla f
  (x) - x^{\star} \|^2}{\| x - x^{\star} \|^2} \tfrac{\| x - x^{\star}
  \|^2}{\| \nabla f (x) \|^2} \label{eqn:proof-3-1-17} \\
  \leq{} & \tfrac{L}{2 \mu^2} \tfrac{\| x - [\nabla^2 f (x^{\star})]^{- 1}
  \nabla f (x) - x^{\star} \|^2}{\| x - x^{\star} \|^2}, \label{eqn:proof-3-1-18}
\end{align}
where \eqref{eqn:proof-3-1-17} uses $L$-smoothness $f (x) - f (x^{\star}) \leq \tfrac{L}{2} \| x - x^{\star} \|^2$
and \eqref{eqn:proof-3-1-18} uses $\| \nabla f (x) \|^2 \geq \mu^2 \| x - x^{\star} \|^2$. Then,
\begin{align}
  x - [\nabla^2 f (x^{\star})]^{- 1} \nabla f (x) - x^{\star}={} & x - x^{\star} - [\nabla^2 f (x^{\star})]^{- 1} \nabla f (x) \nonumber\\
  ={} & [\nabla^2 f (x^{\star})]^{- 1} [\nabla^2 f (x^{\star}) (x - x^{\star}) -
  (\nabla f (x) - \nabla f (x^{\star}))]\nonumber
\end{align}
since $\nabla f(x^\star) = 0$. Plugging in $\nabla f (x) - \nabla f (x^{\star}) = \textstyle \int_0^1 \nabla^2 f (x^{\star} +
t (x - x^{\star})) (x - x^{\star}) \mathd t$, we deduce that
\begin{align}
\| \nabla^2 f (x^{\star}) (x - x^{\star}) - (\nabla f (x) - \nabla f
  (x^{\star}))\|={} & \|\nabla^2 f (x^{\star}) (x - x^{\star}) - \textstyle \int_0^1 \nabla^2 f (x^{\star}
  + t (x - x^{\star})) (x - x^{\star}) \mathd t \|\nonumber\\
  ={} & \|\textstyle \int_0^1 [\nabla^2 f (x^{\star}) - \nabla^2 f (x^{\star} + t (x -
  x^{\star}))] (x - x^{\star}) \mathd t \|\nonumber\\
  \leq{} & \textstyle \int_0^1 t H \| x - x^{\star} \|^2 \mathd t = \tfrac{H}{2} \| x -
  x^{\star} \|^2, \label{eqn:proof-3-1-19}
\end{align}
where \eqref{eqn:proof-3-1-19} uses $H$-Lipschitz continuity of $\nabla^2f(x)$
and, consequently,
\begin{align}
  & \| x - [\nabla^2 f (x^{\star})]^{- 1} \nabla f (x) - x^{\star} \|
  \nonumber\\
  ={} & \| [\nabla^2 f (x^{\star})]^{- 1} [\nabla^2 f (x^{\star}) (x -
  x^{\star}) - (\nabla f (x) - \nabla f (x^{\star}))] \| \leq \tfrac{H}{2 \mu}
  \| x - x^{\star} \|^2 \label{eqn:proof-3-1-auxi2}
\end{align}
since $\nabla^2 f(x^\star) \succeq \mu I$ due to strong convexity.
Plugging the relation back, we get
\begin{equation} \label{eqn:proof-2-1}
  \hat{h}_x ([\nabla^2 f (x^{\star})]^{- 1}) \leq \tfrac{L}{2 \mu^2}
   \tfrac{\tfrac{H^2}{4 \mu^2} \| x - x^{\star} \|^4}{\| x - x^{\star} \|^2} ={}
   \tfrac{H^2 \kappa}{8 \mu^3} \| x - x^{\star} \|^2.
\end{equation}
Since $[\nabla^2 f(x^\star)]^{-1} \in \Pcal$ by assumption, 
\[ \textstyle \sum_{k = 1}^K \hat{h}_{x^k} (P_k) \leq \textstyle \sum_{k = 1}^K \hat{h}_{x^k} ([\nabla^2 f
   (x^{\star})]^{- 1}) + \rho_K \leq \tfrac{H^2 \kappa}{8 \mu^3} \textstyle \sum_{k =
   1}^K \| x^k - x^{\star} \|^2 + \rho_K, \]
and we get
\[ f (x^{K + 1}) - f (x^{\star}) \leq [f(x^1) - f(x^\star) ]\big(\min \big\{\tfrac{H^2 \kappa^2}{4 \mu^2 K}
   \textstyle \sum_{k = 1}^K \| x^k - x^{\star} \|^2 + \tfrac{2L \rho_K}{K}, 1\big\} \big)^K, \]
which completes the proof.

\subsection{Proof of Lemma \ref{lem:scalmat-conv}}

For brevity let $P^{\star} = [\nabla^2 f (x^{\star})]^{- 1}$. We have, according to the
update of online gradient descent, that,
\begin{align}
 \| P_{k + 1} - P^{\star} \|_F^2  ={} & \| \Pi_{\mathcal{P}} [P_k - \eta \nabla \hat{h}_{x^k} (P_k) - P^{\star}]
  \|_F^2 \nonumber\\
  \leq{} & \| P_k - \eta \nabla \hat{h}_{x^k} (P_k) - P^{\star} \|_F^2 \nonumber\\
  ={} & \| P_k - P^{\star} \|_F^2 - 2 \eta \langle \nabla \hat{h}_{x^k} (P_k), P_k -
  P^{\star} \rangle + \eta^2 \| \nabla \hat{h}_{x^k} (P_k) \|_F^2 \nonumber\\
  \leq{} & \| P_k - P^{\star} \|_F^2 - 2 \eta [\hat{h}_{x^k} (P_k) - \hat{h}_{x^k}
  (P^{\star})] + 2 L \eta^2 [\hat{h}_{x^k} (P_k) - \inf_{P \in \Rbb^{n\times n}} \hat{h}_{x^k} (P)] \label{eqn:proof-3-6-1}\\
  ={} & \| P_k - P^{\star} \|_F^2 - 2 \eta [\hat{h}_{x^k} (P_k) - \hat{h}_{x^k} (P^{\star})]
  + 2 L \eta^2 [\hat{h}_{x^k} (P_k) - \hat{h}_{x^k} (P^{\star})] + 2L \eta^2 \hat{h}_{x^k}
  (P^{\star}) \label{eqn:proof-3-6-2}\\
  ={} & \| P_k - P^{\star} \|_F^2 - 2 \eta(1 - \eta L) [\hat{h}_{x^k} (P_k) -
  \hat{h}_{x^k} (P^{\star})] + 2L \eta^2 \hat{h}_{x^k} (P^{\star}), \label{eqn:proof-3-6-3}
\end{align}
where \eqref{eqn:proof-3-6-1} uses $L$-smoothness and $\inf_{P \in \Rbb^{n\times n}} \hat{h}_{x} (P)= 0$ for all $x \nin \Xcal^\star$; \eqref{eqn:proof-3-6-2} is a simple re-arrangement.

Next we lower bound $\hat{h}_{x^k} (P_k) - \hat{h}_{x^k} (P^{\star})$. Using strong
convexity,
\begin{align}
  & f (x^k - P_k \nabla f (x^k)) - f (x^k - P^{\star} \nabla f (x^k))
  \nonumber\\
  ={} & f (x^k - P_k \nabla f (x^k)) - f (x^{\star}) + f (x^{\star}) - f (x^k -
  P^{\star} \nabla f (x^k)) \nonumber\\
  \geq{} & \tfrac{\mu}{2} \| x^k - x^{\star} - P_k \nabla f (x^k) \|^2 + f
  (x^{\star}) - f (x^k - P^{\star} \nabla f (x^k)),\label{eqn:proof-3-6-4}
\end{align}
where \eqref{eqn:proof-3-6-4} uses $f(x) - f(x^\star) \geq \frac{\mu}{2}\|x-x ^\star\|^2$.
The first term can be bounded as follows:
\begin{align}
  & \| x^k - x^{\star} - P_k \nabla f (x^k) \|^2 \nonumber\\
  ={} & \| x^k - P^{\star} \nabla f (x^k) - x^{\star} + (P^{\star} - P_k) \nabla
  f (x^k) \|^2 \nonumber\\
  ={} & \| x^k - P^{\star} \nabla f (x^k) - x^{\star} \|^2 + 2 \langle x^k -
  P^{\star} \nabla f (x^k) - x^{\star}, (P^{\star} - P_k) \nabla f (x^k)
  \rangle + \| (P^{\star} - P_k) \nabla f (x^k) \|^2 \nonumber\\
  \geq{} & \tfrac{1}{2} \| (P^{\star} - P_k) \nabla f (x^k) \|^2 - \| x^k -
  P^{\star} \nabla f (x^k) - x^{\star} \|^2, \nonumber
\end{align}

where we use the inequality $2 \langle a, b \rangle \geq - \theta \| a \|^2 -
\theta^{- 1} \| b \|^2$ with $\theta = 2$. Plugging the relation back into \eqref{eqn:proof-3-6-4} and
dividing both sides by $\| \nabla f (x^k) \|^2$,
\begin{align}
\hat{h}_{x^k} (P_k) - \hat{h}_{x^k} (P^{\star})  ={} & \tfrac{f (x^k - P_k \nabla f (x^k)) - f(x^\star) + f(x^\star) - f (x^k - P^{\star} \nabla f
  (x^k))}{\| \nabla f (x^k) \|^2} \nonumber\\
  \geq{} & \tfrac{\mu}{4} \| (P^{\star} - P_k) \tfrac{\nabla f (x^k)}{\|
  \nabla f (x^k) \|} \|^2 - \tfrac{\mu}{2} \tfrac{\| x^k - P^{\star}
  \nabla f (x^k) - x^{\star} \|^2}{\| \nabla f (x^k) \|^2} + \tfrac{f
  (x^{\star}) - f (x^k - P^{\star} \nabla f (x^k))}{\| \nabla f (x^k) \|^2}
  \nonumber\\
  ={} & \tfrac{\mu}{4} \| (P^{\star} - P_k) \tfrac{\nabla f (x^k)}{\|
  \nabla f (x^k) \|} \|^2 - \tfrac{\mu}{2} \tfrac{\| x^k - P^{\star}
  \nabla f (x^k) - x^{\star} \|^2}{\| \nabla f (x^k) \|^2} - \hat{h}_{x^k}
  (P^{\star}) \label{eqn:proof-3-6-5} \\
  \geq{} & \tfrac{\mu}{4} \| (P^{\star} - P_k) \tfrac{\nabla f (x^k)}{\|
  \nabla f (x^k) \|} \|^2 - \tfrac{H^2}{8 \mu} \tfrac{\| x^k - x^{\star}
  \|^4}{\| \nabla f (x^k) \|^2} - \hat{h}_{x^k} (P^{\star}) \label{eqn:proof-3-6-6}\\
  \geq{} & \tfrac{\mu}{4} \| (P^{\star} - P_k) \tfrac{\nabla f (x^k)}{\|
  \nabla f (x^k) \|} \|^2 - \tfrac{H^2 \kappa}{8 \mu^3} \| x^k -
  x^{\star} \|^2 - \hat{h}_{x^k} (P^{\star}),\label{eqn:proof-3-6-7}
\end{align}
where \eqref{eqn:proof-3-6-5} uses the definition of $\hat{h}_{x^k}$; \eqref{eqn:proof-3-6-6} applies the relation $ \| x - P^\star \nabla f (x) - x^{\star} \| \leq \frac{H}{2\mu} \|x - x^\star\|^2$ from \eqref{eqn:proof-3-1-auxi2}; \eqref{eqn:proof-3-6-7} again uses the fact $\|\nabla f(x) \|^2 \geq \mu^2 \|x - x^\star\|^2$. Putting the relations back into \eqref{eqn:proof-3-6-3} and assuming $\eta \leq \frac{1}{2L}$,
\begin{align}
& \| P_{k + 1} - P^{\star} \|_F^2\nonumber \\
   \leq{} & \| P_k - P^{\star} \|_F^2 -
  \tfrac{\mu (\eta - L \eta^2)}{2} \| (P_k - P^{\star}) \tfrac{\nabla
  f (x^k)}{\| \nabla f (x^k) \|} \|^2 \nonumber\\
  & + \tfrac{H^2 \kappa (\eta - L \eta^2)}{4 \mu^3} \| x^k - x^{\star}
  \|^2 + 2 (\eta - L \eta^2) \hat{h}_{x^k} (P^{\star}) + 2 L \eta^2 \hat{h}_{x^k}
  (P^{\star}) \nonumber\\
  ={} & \| P_k - P^{\star} \|_F^2 - \tfrac{\mu (\eta - L \eta^2)}{2} \|
  (P_k - P^{\star}) \tfrac{\nabla f (x^k)}{\| \nabla f (x^k) \|} \|^2
  +  \tfrac{H^2 \kappa (\eta - L \eta^2)}{4 \mu^3} \| x^k - x^{\star}
  \|^2 + 2 \eta \hat{h}_{x^k} (P^{\star}) \nonumber\\
  \leq{} & \| P_k - P^{\star} \|_F^2 - \tfrac{\mu (\eta - L \eta^2)}{2}
  \| (P_k - P^{\star}) \tfrac{\nabla f (x^k)}{\| \nabla f (x^k) \|}
  \|^2 + \tfrac{H^2 \kappa (\eta - L \eta^2)}{4 \mu^3} \| x^k - x^{\star}
  \|^2 + 2 \eta \tfrac{H^2 \kappa}{8 \mu^3} \| x^k - x^{\star} \|^2 \label{eqn:proof-3-6-8} \\
  ={} & \| P_k - P^{\star} \|_F^2 - \tfrac{\mu (\eta - L \eta^2)}{2} \|
  (P_k - P^{\star}) \tfrac{\nabla f (x^k)}{\| \nabla f (x^k) \|} \|^2 +
  (2\eta - L \eta^2) \tfrac{H^2 \kappa}{4 \mu^3}\| x^k - x^{\star} \|^2, \nonumber
\end{align}
where \eqref{eqn:proof-3-6-8} uses the relation \eqref{eqn:proof-2-1} and this completes the proof.

\subsection{Proof of Theorem \ref{thm:scal-mat-conv}} \label{app:thm-pf-scal-mat-conv}

The proof of \Cref{thm:scal-mat-conv} relies on the following auxiliary results.

\begin{lem} \label{lem:scal-mat-conv-aux} Under \ref{A1} to \ref{A3}, $h_x (P) - \inf_{Q \in \mathbb{R}^{n \times n}} h_x (Q) \leq
  \tfrac{1}{2 \mu} (L D + 1)^2$.
\end{lem}

\begin{proof}
  Note that $h_x (P) = \tfrac{f (x - P \nabla f (x)) - f (x)}{\| \nabla f (x)
  \|^2} \geq \tfrac{f (x^{\star}) - f (x)}{\| \nabla f (x) \|^2}$ for all $P
  \in \mathcal{P}$, we deduce that
  \begin{align}
    h_x (P) - \inf_{Q \in \mathbb{R}^{n \times n}} h_x (Q) \leq{} & \tfrac{f (x
    - P \nabla f (x)) - f (x)}{\| \nabla f (x) \|^2} - \tfrac{f (x^{\star}) -
    f (x)}{\| \nabla f (x) \|^2} \label{eqn:proof-scalmatconv-aux-1}\\
    ={} & \tfrac{f (x - P \nabla f (x)) - f (x^{\star})}{\| \nabla f (x) \|^2}
    \nonumber\\
    \leq{} & \tfrac{1}{2 \mu} \tfrac{\| \nabla f (x - P \nabla f (x)) \|^2}{\|
    \nabla f (x) \|^2} \label{eqn:proof-scalmatconv-aux-2} \\
    \leq{} & \tfrac{1}{2 \mu} \tfrac{[\| \nabla f (x) \| + \| P \| \cdot \|
    \nabla f (x) \|]^2}{\| \nabla f (x) \|^2} \label{eqn:proof-scalmatconv-aux-3} \\
    \leq{} & \tfrac{1}{2 \mu} (L D + 1)^2,  \label{eqn:proof-scalmatconv-aux-4}
  \end{align}
  
where \eqref{eqn:proof-scalmatconv-aux-1} applies $h_x(P) \geq \tfrac{f (x^{\star}) - f (x)}{\| \nabla f (x) \|^2}$; \eqref{eqn:proof-scalmatconv-aux-2} uses $f(x) - f(x^\star) \leq \frac{1}{2\mu} \|\nabla f(x)\|^2$; \eqref{eqn:proof-scalmatconv-aux-3} uses $L$-smoothness and \eqref{eqn:proof-scalmatconv-aux-4} uses $\|P\| \leq D$. 
\end{proof}

Then we show that {\hdm} converges even when $\eta$ is a constant that does not depend on $K$. 

\begin{lem} \label{lem:scal-mat-conv-aux-2} Under \ref{A1} to \ref{A3}, \Cref{alg:hdm} with $\eta_k \equiv \eta \in (0, \frac{1}{2 L (L D + 1)^2 \kappa}]$ satisfies
  \begin{itemize}[leftmargin=15pt]
    \item $\lim_{k \rightarrow \infty} \| x^k - x^{\star} \| = 0$. 
    
    \item $\lim_{K \rightarrow \infty} \sum_{k = 1}^K \| x^k - x^{\star} \|^2
    < \infty$.
  \end{itemize}
\end{lem}

\begin{proof}
	Using the online gradient descent
update, we have
\begin{align}
  \| P_{k + 1} - P \|_F^2 \leq{} & \| P_k - \eta \nabla h_{x^k} (P_k) - P \|_F^2
  \nonumber\\
  ={} & \| P_k - P \|_F^2 - 2 \eta \langle \nabla h_{x^k} (P_k), P_k - P \rangle
  + \eta^2 \| \nabla h_{x^k} (P_k) \|_F^2 \nonumber\\
  \leq{} & \| P_k - P \|_F^2 - 2 \eta [h_{x^k} (P_k) - h_{x^k} (P)] + 2 L \eta^2
  [h_{x^k} (P_k) - \inf_{P \in \mathbb{R}^{n \times n}} h_{x^k} (P)]
  \label{eqn:proof-scalmatconv-aux-5}
 \\
  ={} & \| P_k - P \|_F^2 - 2 \eta h_{x^k} (P_k) + 2 \eta h_{x^k} (P) + 2 L
  \eta^2 [h_{x^k} (P_k) - \inf_{P \in \mathbb{R}^{n \times n}} h_{x^k} (P)],
  \nonumber
\end{align}

where \eqref{eqn:proof-scalmatconv-aux-5} follows from convexity $h_{x^k} (P) \geq h_{x^k}
(P_k) + \langle \nabla h_{x^k} (P_k), P - P_k \rangle$ and $L$-smoothness of
$h_x (P)$. Next, we invoke the upperbound on $h_{x^k} (P_k) - \inf_{Q \in
\mathbb{R}^{n \times n}} h_{x^k} (Q)$ from \Cref{lem:scal-mat-conv-aux}:
\[ {2 L \eta^2 [h_{x^k} (P_k) - \inf_{P \in \mathbb{R}^{n \times
   n}} h_{x^k} (P)]} \leq \tfrac{2 L}{2 \mu} (L D + 1)^2 \eta^2 = \kappa (L D
   + 1)^2 \eta^2 . \]
and deduce that
\begin{align}
  2 \eta h_{x^k} (P_k) \leq{} & 2 \eta h_{x^k} (P) + \| P_k - P \|_F^2 - \| P_{k
  + 1} - P \|_F^2 + {2 L \eta^2 [h_{x^k} (P_k) - \inf_{P \in
  \mathbb{R}^{n \times n}} h_{x^k} (P)]} \nonumber\\
  \leq{} & 2 \eta h_{x^k} (P) + \| P_k - P \|_F^2 - \| P_{k + 1} - P \|_F^2 +
  \eta^2 \kappa (L D + 1)^2 . \nonumber
\end{align}

Next, we divide both sides of the inequality by $2 \eta$ and
\[ h_{x^k} (P_k) \leq h_{x^k} (P) + \tfrac{\| P_k - P \|_F^2 - \| P_{k + 1} -
   P \|_F^2}{2 \eta} + \tfrac{\eta \kappa (L D + 1)^2}{2} . \]
Telescoping the relation and using $\tmop{diam} (\mathcal{P}) \leq D$, we get
\[\textstyle \sum_{k = 1}^K h_{x^k} (P_k) \leq \sum_{k = 1}^K h_{x^k} (P) +
   \tfrac{D^2}{2 \eta} + \tfrac{\eta \kappa (L D + 1)^2}{2} K \]
Taking $P = (1 / L) I$ and taking average, $\sum_{k = 1}^K h_{x^k} (P) \leq
{- \tfrac{1}{2 L}} K$ and
\begin{align}
\textstyle  \tfrac{1}{K} \sum_{k = 1}^K h_{x^k} (P_k) \leq{} & {-
  \tfrac{1}{2 L}} + \tfrac{D^2}{2 \eta K} + \tfrac{\eta \kappa (L D + 1)^2}{2}
    ={} - \tfrac{1}{4 L} + \tfrac{D^2}{2 \eta K} + \tfrac{\eta \kappa (L D +
  1)^2}{2} - \tfrac{1}{4 L} \nonumber
\end{align}

With $\eta \leq \frac{1}{2 L (L D + 1)^2 \kappa}$, we have $\tfrac{\eta \kappa
(L D + 1)^2}{2} - \tfrac{1}{4 L} \leq 0$ and
\[ \textstyle \tfrac{1}{K} \sum_{k = 1}^K h_{x^k} (P_k) \leq - \tfrac{1}{4 L} +
   \tfrac{D^2 L (L D + 1)^2 \kappa}{K} . \]
Using the reduction \Cref{lem:hypergrad-to-online}, we get, for any $k \geq 1$ (since $\eta$ does not depend
on the iteration number),
\[ f (x^{k + 1}) - f (x^{\star}) \leq [f (x^1) - f (x^{\star})] ( 1 - 2
   \mu \max \{ \tfrac{1}{4 L} - \tfrac{D^2 L (L D + 1)^2 \kappa}{k}, 0
   \} )^k \]
and there exists some $K_0$ such that for all $k \geq K_0$, that $[f (x^k) - f (x^{\star})] ( 1 -
\tfrac{1}{4 \kappa} )^k \leq  [f (x^1) - f (x^{\star})]$ since
\[ \lim_{k \rightarrow \infty} 1 - 2 \mu \max \{ \tfrac{1}{4 L} -
   \tfrac{2 D^2 L (L D + 1)^2 \kappa}{k}, 0 \} = 1 - \tfrac{1}{2 \kappa}
   < 1 - \tfrac{1}{4 \kappa} . \]
   This proves the first relation $\lim_{k \rightarrow \infty} \| x^k - x^{\star} \| = 0$ since $\|x - x^\star\|^2 \leq \frac{2}{\mu} [f(x) - f(x^\star)] $ and the second relation follows directly from    
\begin{align}
\textstyle \sum_{k=1}^\infty \|x^k - x^\star\|^2 ={} & \textstyle\sum_{k=1}^{K_0} \|x^k - x^\star\|^2 + \sum_{k=K_0}^{\infty} \|x^k - x^\star\|^2 \\
 ={} & \textstyle\sum_{k=1}^{K_0} \|x^k - x^\star\|^2 + \sum_{k=K_0}^{\infty} \frac{2}{\mu}[f(x^1)-f(x^\star)](1-\frac{1}{4\kappa})^{-k} < \infty.
\end{align}
\end{proof}


Now we are ready to prove \Cref{thm:scal-mat-conv}, and we start by stating the precise definition of a uniformly independent sequence.

\begin{definition}[Uniformly linearly indepdendent sequence {\cite{conn1991convergence}}]
  A sequence of unit-norm vectors $\{ g^k \}, g^k \in \mathbb{R}^n, \| g^k \|
  = 1$ is uniformly linearly independent if there exists a constant $c > 0, K_0 \geq 0$ and $m \geq n$ such that for each $k \geq K_0$, one can
  choose $n$ distinct indices
  \[ k \leq k_1 < \cdots < k_n \leq k + m \]
  with $\sigma_{\min} ([g^{k_1}, \ldots, g^{k_n}]) \geq c$.
\end{definition}

We prove by contradiction.
For brevity we denote $g^k \assign \tfrac{\nabla f (x^k)}{\| \nabla f (x^k)
\|}$ and $e_k \assign \| P_k - P^{\star} \|_F^2$. Recall that
$P^{\star} = [\nabla^2 f (x^{\star})]^{- 1}$. First, using \Cref{lem:scal-mat-conv-aux-2}, for any $\varepsilon > 0$, there exists some index $K_1$ such that for
all $k \geq K_1$ we have $\| x^k - x^{\star} \|^2 \leq \varepsilon$ and that
$\textstyle \sum_{k = 1}^{\infty} \| x^k - x^{\star} \|^2$ is bounded. 
Then we show that $\lim_{k \rightarrow \infty} \| \nabla h_{x^k} (P_k) \|_F =
0$ using \eqref{eqn:proof-3-6-3}: after re-arrangement, for any $K \geq 1$,
\begin{align}
  \textstyle \sum_{k = 1}^K \hat{h}_{x^k} (P_k) \leq{} & \tfrac{2 \eta}{2 \eta (1 - \eta
  L)} \textstyle \sum_{k = 1}^K \hat{h}_{x^k} (P^{\star}) + \tfrac{1}{2 \eta (1 - \eta
  L)} \| P_1 - P^{\star} \|_F^2 \nonumber\\
  \leq{} & \tfrac{2 \eta}{2 \eta (1 - \eta L)} \tfrac{H^2 \kappa}{8 \mu^3}
  \textstyle \sum_{k = 1}^K \| x^k - x^{\star} \|^2 + \tfrac{1}{2 \eta (1 - \eta L)} \|
  P_1 - P^{\star} \|_F^2 . \label{eqn:proof-scalconv-auxi}\\
  \leq{} & \tfrac{2 \eta}{2 \eta (1 - \eta L)} \tfrac{H^2 \kappa}{8 \mu^3}
  \textstyle \sum_{k = 1}^{\infty} \| x^k - x^{\star} \|^2 + \tfrac{1}{2 \eta (1 - \eta
  L)} \| P_1 - P^{\star} \|_F^2, \nonumber
\end{align}
where \eqref{eqn:proof-scalconv-auxi} applies \eqref{eqn:proof-2-1}. Since $\textstyle \sum_{k = 1}^{\infty} \| x^k - x^{\star} \|^2$ is bounded and
$\hat{h}_x (P)$ is nonnegative, we must have $\lim_{k \rightarrow \infty}
\hat{h}_{x^k} (P_k) = 0$. Further notice that $\| \nabla \hat{h}_{x^k} (P_k) \|_F^2 \leq 2 L
\hat{h}_{x^k} (P_k)$, it implies $\lim_{k \rightarrow \infty} \sum_{k=1}^K \| \nabla
h_{x^k} (P_k) \|_F^2 < \infty$, giving $\lim_{k \rightarrow \infty} \| \nabla
h_{x^k} (P_k) \|_F = 0$ and $\lim_{k \rightarrow \infty} P_k = \bar{P}$ also
exists. Now suppose by contradiction that $\| \bar{P} - P^{\star} \|_F = \theta
> 0$. Then there exists some $K_2 > 0$ such that for all $k \geq K_2$, $\| P_k
- \bar{P} \|_F \leq \varepsilon$. For $k \geq \max \{ K_0, K_1, K_2 \} + 1$, we invoke \Cref{lem:scalmat-conv} with $\eta \in (0, \frac{1}{2L}]$ to get
\begin{align}
  \| P_{k + 1} - P^{\star} \|_F^2 \leq{} & \| P_k - P^{\star} \|_F^2 - \alpha_1
  \| (P_k - P^{\star}) g^k \|^2 + \alpha_2 \varepsilon \nonumber\\
  ={} & \| P_k - P^{\star} \|_F^2 - \alpha_1 \| (P_k - \bar{P} + \bar{P} -
  P^{\star}) g^k \|^2 + \alpha_2 \varepsilon \nonumber\\
  \leq{} & \| P_k - P^{\star} \|_F^2 - \tfrac{\alpha_1}{2} \| (\bar{P} -
  P^{\star}) g^k \|^2 + 3 \alpha_1 \| (P_k - \bar{P}) g^k \|^2 + \alpha_2
  \varepsilon \nonumber\\
  \leq{} & \| P_k - P^{\star} \|_F^2 - \tfrac{\alpha_1}{2} \| (\bar{P} -
  P^{\star}) g^k \|^2 + 3 \alpha_1 \varepsilon^2 + \alpha_2 \varepsilon
  \label{eqn:proof-thm-scal-conv-0} \\
  ={} & \| P_k - P^{\star} \|_F^2 - \tfrac{\alpha_1}{2} \tmop{tr} (g^k
  (g^k)^{\top}, (\bar{P} - P^{\star})^{\top} (\bar{P} - P^{\star})) + 3
  \alpha_1 \varepsilon^2 + \alpha_2 \varepsilon ,\label{eqn:proof-thm-scal-conv-1}
\end{align}
where $\alpha_1 = \tfrac{\mu (\eta - L \eta^2)}{2} > 0$, $\alpha_2 = \frac{1}{4}
(2\eta - L \eta^2) H^2 \kappa \mu^{- 3}$, and \eqref{eqn:proof-thm-scal-conv-0} uses the fact that $\| P_k - P^{\star} \|_F\leq \varepsilon$.\\
Telescoping \eqref{eqn:proof-thm-scal-conv-1} for the next $m + 1$ iterations, we deduce that
\begin{align}
  e_{k + m + 1} ={} & \| P_{k + m + 1} - P^{\star} \|_F^2 \nonumber\\
  \leq{} & \| P_k - P^{\star} \|_F^2 - \tfrac{\alpha_1}{2} \textstyle \sum_{j = 0}^m
  \tmop{tr} (g^{k + j} (g^{k + j})^{\top}, (\bar{P} - P^{\star})^{\top} (\bar{P} -
  P^{\star})) + (3 \alpha_1 \varepsilon^2 + \alpha_2 \varepsilon) (m + 1)
  \nonumber\\
  ={} & e_k - \tfrac{\alpha_1}{2} \tmop{tr} ( \textstyle \sum_{j = 0}^m g^{k + j}
  (g^{k + j})^{\top}, (\bar{P} - P^{\star})^{\top} (\bar{P} - P^{\star})) +
  (3 \alpha_1 \varepsilon^2 + \alpha_2 \varepsilon) (m + 1) \nonumber
\end{align}

and using the independent sequence assumption, we can pick $k_1, \ldots, k_n$
such that
\[ \sigma_{\min} ([g^{k_1}, \ldots, g^{k_n}]) \geq c \]
and $\sum_{j = 0}^m g^{k + j} (g^{k + j})^{\top} \succeq \sum_{i = 1}^n
g^{k_i} (g^{k_i})^{\top} \succeq c^2 I$. Hence
\begin{align}
 & \textstyle \tmop{tr} (\sum_{j = 0}^m g^{k + j} (g^{k + j})^{\top}, (\bar{P} -
  P^{\star})^{\top} (\bar{P} - P^{\star})) \geq{}  c^2 \tmop{tr} ((\bar{P} - P^{\star})^{\top} (\bar{P} -
  P^{\star})) 
  ={}  c^2 \| \bar{P} - P^{\star} \|_F^2 = c^2 \theta^2 \nonumber
\end{align}
and $e_{k + m + 1} \leq e_k - \frac{\alpha_1 c^2 \theta^2}{2} + (3 \alpha_1 \varepsilon^2 + \alpha_2\varepsilon) (m + 1)$. Since $\varepsilon$ is arbitrary, we can repeat the argument till $e_{k + m +1} <0 $, which leads to contradiction unless $\theta = 0$. This completes the proof.