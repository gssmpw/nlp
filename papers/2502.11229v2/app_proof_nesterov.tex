\subsection{{\hdm} + Nesterov Momentum ({\hdmagd})}
\label{app:nesterov}

\subsubsection{Auxiliary Results}
\begin{lem}\label{lem:osnes-auxi}
  Suppose a nonnegative sequence $\{ A_k \}$ satisfies $A_{k + 1} = (A_{k + 1}
  - A_k)^2$ and $A_0 = 0$, then $A_{k + 1} - A_k \leq k + 1$ for all $k \geq 1$.
\end{lem}

\begin{proof}
	We prove by induction. The induction hypothesis is $A_{k + 1} - A_k \leq k$.
	
\textbf{Base case}. For $k = 1$, $A_2 - A_1 = \frac{\sqrt{5} + 1}{2} < 2$
and the relation holds.

\textbf{Inductive step}. Suppose $A_{k + 1} - A_k \leq k$. Using $A_{k + 2} = A_{k + 1} + \frac{1}{2} \left( 1 + \sqrt{4 A_{k + 1} + 1}
\right)$, we deduce that
\begin{align}
  A_{k + 2} - A_{k + 1} ={} & \tfrac{1}{2} ( 1 + \sqrt{4 A_{k + 1} + 1}
  ) \nonumber\\
  ={} & \tfrac{1}{2} ( 1 + \sqrt{4 (A_{k + 1} - A_k)^2 + 1} )
  \nonumber\\
  \leq{} & \tfrac{1}{2} (1 + 2 (A_{k + 1} - A_k) + 1) \label{eqn:c-2-1-auxi-1} \\
  \leq{} & 1 + A_{k + 1} - A_k \nonumber\\
  \leq{} & k + 2, \label{eqn:c-2-1-auxi-2}
\end{align}
where \eqref{eqn:c-2-1-auxi-1} uses $\sqrt{a + b} \leq \sqrt{a}+ \sqrt{b}$ and \eqref{eqn:c-2-1-auxi-2} uses the induction hypothesis $A_{k + 1} - A_k \leq k + 1$. By the principle of mathematical induction, this completes the proof.
\end{proof}

\begin{lem}[{\cite{d2021acceleration}}]\label{lem:osnes-auxi-2}
Under the same conditions as \Cref{lem:osnes-auxi}, $A_k \geq \frac{k^2}{4}$ for all $k \geq 1$.
\end{lem}

\subsubsection{Proof of \Cref{thm:osnes}} \label{app:proof-osnes}
Using the definition $h_y (P) = \tfrac{f (y - P \nabla f (y)) - f (y)}{\| \nabla f (y) \|^2}$ and the $x$-update in \Cref{alg:osnes}:
\begin{equation*}
  x^{k+1} = \underset{x \in \{ y^k - \frac{1}{L} \nabla f (y^k), y^k
  - P_k \nabla f (y^k), x^k \}}{\argmin} f (x),
\end{equation*}
we have the following two inequalities:
\begin{align}
  f (x^{k + 1}) - f (y^k) \leq{} & \min \{ h_{y^k} (P_k), - \tfrac{1}{2 L}
  \} \| \nabla f (y^k) \|^2 \label{eqn:proof-3-1-1}\\
  f (x^{k + 1}) \leq{} & f (x^k). \label{eqn:proof-3-1-2}
\end{align}

In other words, with $v_k = \max \{ - \tfrac{1}{2 \min \{ h_{y^k} (P_k), - 1 / (2 L) \}},
   \tfrac{L}{2 \theta} \} $, we have
\begin{equation}
f (y^k) - \tfrac{1}{2 v_k} \| \nabla f (y^k) \|^2 \geq f (x^{k + 1})
  \label{eqn:proof-3-1-3}
\end{equation}
and using $z^{k+1} = z^k + \tfrac{(A_{k + 1} - A_k)}{v_k}
  \nabla f (y^k)$,  by algebraic rearrangement
\begin{align}
   & \tfrac{v_k}{2}\|z^{k+1} - x^\star\|^2 \\
  = {} & \tfrac{v_k}{2} \| z^k - x^{\star} + \tfrac{(A_{k + 1} - A_k)}{v_k}
  \nabla f (y^k) \|^2 \nonumber\\
  ={} & \tfrac{v_k}{2} \| z^k - x^{\star} \|^2 - (A_{k + 1} - A_k) \langle
  \nabla f (y^k), z^k - x^{\star} \rangle + \tfrac{1}{2 v_k} (A_{k + 1} -
  A_k)^2 \| \nabla f (y^k) \|^2 . \label{eqn:proof-3-1-aux-1}
\end{align}

Next, we apply convexity and have
\begin{align}
  f (x^{\star}) \geq{} & f (y^k) + \langle \nabla f (y^k), x^{\star} - y^k
  \rangle \label{eqn:proof-3-1-4}\\
  f (x^k) \geq{} & f (y^k) + \langle \nabla f (y^k), x^k - y^k \rangle
  \label{eqn:proof-3-1-5}
\end{align}
Taking a weighted summation between \eqref{eqn:proof-3-1-3}, \eqref{eqn:proof-3-1-4} and \eqref{eqn:proof-3-1-5}, we deduce that
\begin{align}
  0 \geq{} & (A_{k + 1} - A_k) [f (y^k) + \langle \nabla f (y^k), x^{\star} -
  y^k \rangle - f (x^{\star})]  + A_k [f (y^k) + \langle \nabla f (y^k), x^k - y^k \rangle - f (x^k)]
  \nonumber\\
  & + A_{k + 1} [ f (x^{k + 1}) - f (y^k) + \tfrac{1}{2 v_k} \| \nabla f
  (y^k) \|^2 ] \nonumber\\
  ={} & (A_{k + 1} - A_k) \langle \nabla f (y^k), x^{\star} - y^k \rangle -
  (A_{k + 1} - A_k) f (x^{\star}) \nonumber\\
  & + A_k \langle \nabla f (y^k), x^k - y^k \rangle - A_k f (x^k) + A_{k + 1}
  f (x^{k + 1}) + \tfrac{A_{k + 1}}{2 v_k} \| \nabla f (y^k) \|^2 \label{eqn:proof-3-1-6} \\
  ={} & A_{k + 1} [f (x^{k + 1}) - f (x^{\star})] - A_k [f (x^k) - f
  (x^{\star})] \nonumber\\
  & + (A_{k + 1} - A_k) \langle \nabla f (y^k), x^{\star} - y^k \rangle + A_k
  \langle \nabla f (y^k), x^k - y^k \rangle + \tfrac{A_{k + 1}}{2 v_k} \|
  \nabla f (y^k) \|^2 \label{eqn:proof-3-1-7}\\
  ={} & A_{k + 1} [f (x^{k + 1}) - f (x^{\star})] - A_k [f (x^k) - f
  (x^{\star})] \nonumber\\
  & A_{k + 1} \langle \nabla f (y^k), x^{\star} - y^k \rangle + A_k \langle
  \nabla f (y^k), x^k - x^{\star} \rangle + \tfrac{A_{k + 1}}{2 v_k} \| \nabla
  f (y^k) \|^2, \nonumber\\
  ={} & A_{k + 1} [f (x^{k + 1}) - f (x^{\star})] - A_k [f (x^k) - f
  (x^{\star})] \nonumber\\ 
  &- (A_{k + 1} - A_k) \langle \nabla f (y^k), z^k - x^{\star} \rangle + \tfrac{A_{k + 1}}{2 v_k} \| \nabla
  f (y^k) \|^2, \label{eqn:proof-3-1-8}
\end{align}

where \eqref{eqn:proof-3-1-6} to \eqref{eqn:proof-3-1-7} simply re-arrange the terms and \eqref{eqn:proof-3-1-8} uses the identity $y^k = x^k + ( 1 - \tfrac{A_k}{A_{k + 1}} ) (z^k - x^k)$:
\begin{align}
  & A_{k + 1} \langle \nabla f (y^k), x^{\star} - y^k \rangle + A_k \langle
  \nabla f (y^k), x^k - x^{\star} \rangle 
  =  - (A_{k + 1} - A_k) \langle \nabla f (y^k), z^k - x^{\star} \rangle .
  \nonumber
\end{align}

Putting the relations together, we arrive at
\begin{align}
  & A_{k + 1} [f (x^{k + 1}) - f (x^{\star})]
  \leq  A_k [f (x^k) - f (x^{\star})] + (A_{k + 1} - A_k) \langle \nabla f
  (y^k), z^k - x^{\star} \rangle - \tfrac{A_{k + 1}}{2 v_k} \| \nabla f (y^k)
  \|^2 . \nonumber
\end{align}
and adding \eqref{eqn:proof-3-1-aux-1} gives
\begin{align}
  & A_{k + 1} [f (x^{k + 1}) - f (x^{\star})] + \tfrac{v_k}{2} \| z^{k + 1}
  - x^{\star} \|^2 \nonumber\\
  \leq{} & A_k [f (x^k) - f (x^{\star})] + \tfrac{v_k}{2} \| z^k - x^{\star}
  \|^2 + \tfrac{A_{k + 1} - (A_{k + 1} - A_k)^2}{2 v_k} \| \nabla f (y^k)
  \|^2 \nonumber\\
  ={} & A_k [f (x^k) - f (x^{\star})] + \tfrac{v_k}{2} \| z^k - x^{\star} \|^2, \label{eqn:proof-3-1-10}
\end{align}

where \eqref{eqn:proof-3-1-10} uses the relation $A_{k + 1} - (A_{k + 1} - A_k)^2 = 0 $.\\

We are now ready to analyze the acceleration effect of online hypergradient. Recall that we can guarantee
\begin{align}
  \tfrac{1}{K}\textstyle \sum_{k = 1}^K h_{y^k} (P_k) \leq & - \gamma^{\star}_K +
  \tfrac{\rho_K}{K}, \label{eqn:proof-3-1-11}
\end{align}
where $\gamma^{\star}_K := -\min_{P \in \Pcal} \sum_{k = 1}^K h_{y^k} (P)$ is expected to be larger than $1 / (2 L)$ to improve
performance. Recall that $\gamma^{\star}_K \assign
\tfrac{\omega^\star_K}{L}, \omega^\star_K \geq 0$ and note that $\omega^\star_K$ depends on the
iteration trajectory. Moreover, we have, by convexity of $f (x)$,
\[ \tfrac{f (x - P \nabla f (x)) - f (x)}{\| \nabla f (x) \|^2} \geq \tfrac{f
   (x) - \langle \nabla f (x), P \nabla f (x) \rangle - f (x)}{\| \nabla f (x)
   \|^2} = - \tfrac{\langle \nabla f (x), P \nabla f (x) \rangle}{\| \nabla f
   (x) \|^2} \geq - D \]
and $\gamma^{\star}_K \leq D$ implies $\omega^\star_K \leq L D$. Define $\mathcal{I}
\assign \{ k : h_{y^k} (P_k) \leq - \tfrac{\theta}{L} \}$ for
$\theta \in [\tfrac{1}{2}, L D)$. Then, according to \eqref{eqn:proof-3-1-11}, 
\[ \textstyle - \tfrac{\omega^\star_K}{L} + \tfrac{\rho_K}{K} \geq \tfrac{1}{K} \sum_{k = 1}^K
   h_{y^k} (P_k) = \tfrac{1}{K} [ \sum_{k \in \mathcal{I}} h_{y^k} (P_k)
   + \sum_{k \in \bar{\mathcal{I}}} h_{y^k} (P_k) ] \geq \tfrac{1}{K}
   \sum_{k \in \mathcal{I}} h_{y^k} (P_k) - \tfrac{\theta}{L} \tfrac{K - |
   \mathcal{I} |}{K} . \]
Using $h_{y^k} (P_k) \geq - D$, we get
\[ \textstyle- \tfrac{D}{K} | \mathcal{I} | \leq \tfrac{1}{K} \sum_{k \in \mathcal{I}}
   h_{y^k} (P_k) \leq - \tfrac{\omega^\star_K}{L} + \tfrac{\theta}{L} \tfrac{K - |
   \mathcal{I} |}{K} + \tfrac{\rho_K}{K} . \]
Re-arranging the terms,
\[ ( - \tfrac{D}{K} + \tfrac{\theta}{K L} ) | \mathcal{I} | \leq
   \tfrac{\theta - \omega^\star_K}{L} + \tfrac{\rho_K}{K} . \]
Using $D > \tfrac{\theta}{L}$, we get
\[ | \mathcal{I} | \geq \tfrac{\tfrac{\theta - \omega^\star_K}{L} +
   \tfrac{\rho_K}{K}}{- \tfrac{D}{K} + \tfrac{\theta}{K L}} = \tfrac{(\theta -
   \omega^\star_K) K + L \rho_K}{\theta - L D} = \tfrac{(\omega^\star_K - \theta) K}{L D -
   \theta} - \tfrac{L}{L D - \theta} \rho_K . \]
We have, if $k \in \mathcal{I}$, that using the fact that \eqref{eqn:proof-3-1-10} holds for $v_k = \max \{ - \tfrac{1}{2 \min \{ h_{y^k} (P_k), - 1 / (2 L) \}},
   \tfrac{L}{2 \theta} \}  = \tfrac{L}{2 \theta}$,
\begin{align}
  A_{k + 1} [f (x^{k + 1}) - f (x^{\star})] + \tfrac{L}{4 \theta} \| z^{k + 1}
  - x^{\star} \|^2 \leq{} & A_k [f (x^k) - f (x^{\star})] + \tfrac{L}{4 \theta}
  \| z^k - x^{\star} \|^2. \label{eqn:proof-3-1-12}
\end{align}
On the other hand, if $k \nin \mathcal{I}$, $v_k \leq L$ and 
\begin{align}
  A_{k + 1} [f (x^{k + 1}) - f (x^{\star})] + \tfrac{v_k}{2} \| z^{k + 1} -
  x^{\star} \|^2 \leq{} & A_k [f (x^k) - f (x^{\star})] + \tfrac{v_k}{2} \| z^k -
  x^{\star} \|^2 \label{eqn:proof-3-1-13}
\end{align}

and  $f (x^{k + 1}) \leq f (x^k)$ implies
\begin{align}
  A_{k + 1} [f (x^{k + 1}) - f (x^{\star})] \leq{} & A_{k + 1} [f (x^k) - f
  (x^{\star})] \nonumber\\
  \leq{} & A_k [f (x^k) - f (x^{\star})] + (k + 1) [f (x^k) - f (x^{\star})] \label{eqn:proof-3-1-14},
\end{align}
where \eqref{eqn:proof-3-1-14} uses the condition that $A_{k + 1} - A_k \leq k + 1$ from \Cref{lem:osnes-auxi}.\\

Taking a weighted summation of \eqref{eqn:proof-3-1-13} and \eqref{eqn:proof-3-1-14}, combining \eqref{eqn:proof-3-1-12},
\begin{align}
  & A_{k + 1} [f (x^{k + 1}) - f (x^{\star})] + \tfrac{L}{4 \theta} \| z^{k +
  1} - x^{\star} \|^2 \nonumber\\
  \leq{} & A_k [f (x^k) - f (x^{\star})] + \tfrac{L}{4 \theta} \| z^k -
  x^{\star} \|^2 + ( 1 - \tfrac{L}{2 \theta v_k} ) (k + 1) [f (x^k) - f
  (x^{\star})] \cdummy \mathbb{I} \{ k \in \bar{\mathcal{I}} \} \nonumber\\
  \leq {} & A_k [f (x^k) - f (x^{\star})] + \tfrac{L}{4 \theta} \| z^k -
  x^{\star} \|^2 + ( 1 - \tfrac{1}{2 \theta} ) (k + 1) [f (x^k) - f
  (x^{\star})] \cdummy \mathbb{I} \{ k \in \bar{\mathcal{I}} \} . \nonumber
\end{align}
Telescoping the relation from 1 to $K$,
\[ \textstyle A_{K + 1} [f (x^{K + 1}) - f (x^{\star})] \leq \tfrac{L}{4 \theta} \| z^1
   - x^{\star} \|^2 + \sum_{k \in \bar{\mathcal{I}}} ( 1 - \tfrac{1}{2
   \theta} ) (k + 1) [f (x^k) - f (x^{\star})] . \]
Using $A_{K + 1} \geq \tfrac{K^2}{4}$ from \Cref{lem:osnes-auxi-2} and that $| \bar{\mathcal{I}} | = K - |
\mathcal{I} | \leq K - \tfrac{(\omega^\star_K - \theta) K}{L D - \theta} + \tfrac{L
\rho_K}{L D - \theta}$,
\begin{align}
  f (x^{K + 1}) - f (x^{\star}) \leq{} & \tfrac{L}{4 \theta A_{K + 1}} \| z^1 -
  x^{\star} \|^2 + \tfrac{1}{A_{K + 1}} ( 1 - \tfrac{1}{2 \theta} )
  \textstyle\sum_{k \in \bar{\mathcal{I}}} (k + 1) [f (x^k) - f (x^{\star})] \nonumber\\
  \leq{} & \tfrac{L}{\theta K^2} \| z^1 - x^{\star} \|^2 + \tfrac{4}{K^2}
  ( 1 - \tfrac{1}{2 \theta} ) \textstyle\sum_{k \in \bar{\mathcal{I}}} (k + 1) [f
  (x^k) - f (x^{\star})] \nonumber\\
  \leq{} & \tfrac{L}{\theta K^2} \| z^1 - x^{\star} \|^2 + \tfrac{4}{K} (
  1 - \tfrac{1}{2 \theta} ) [f (x^1) - f (x^{\star})] \cdummy |
  \bar{\mathcal{I}} | \nonumber\\
  \leq{} & \tfrac{L}{\theta K^2} \| z^1 - x^{\star} \|^2 + 4 ( 1 -
  \tfrac{1}{2 \theta} ) [f (x^1) - f (x^{\star})] ( 1 -
  \tfrac{\omega^\star_K - \theta}{L D - \theta} + \tfrac{L}{L D - \theta}
  \tfrac{\rho_K}{K} ) . \nonumber
\end{align}

Suppose we run accelerated gradient descent from $z'$ for $K$ iterations and
obtain $x^1$. \\

Plugging in $f (x^1) - f (x^{\star}) \leq \tfrac{2 L}{K^2} \| z' - x^{\star}
\|^2$ we get, using $z^1 = z'$, that
\begin{align}
  f (x^{K + 1}) - f (x^{\star}) \leq{} & \tfrac{L}{\theta K^2} \| z' - x^{\star}
  \|^2 + \tfrac{L}{\theta K^2} \| z' - x^{\star} \|^2 8 (2 \theta - 1)
  ( 1 - \tfrac{\omega^\star_K - \theta}{L D - \theta} ) +\mathcal{O} (
  \tfrac{\rho_K}{K^3} ) \nonumber\\
  ={} & \tfrac{L}{\theta K^2} \| z' - x^{\star} \|^2 + \tfrac{L}{K^2} \| z' -
  x^{\star} \|^2  ( 16 - \tfrac{8}{\theta} ) \tfrac{L D -
  \omega^\star_K}{L D - \theta} +\mathcal{O} ( \tfrac{\rho_K}{K^3} )
  \nonumber\\
  \leq{} & \tfrac{L}{\theta K^2} \| z' - x^{\star} \|^2 + \tfrac{L}{K^2} \| z' -
  x^{\star} \|^2 (16 - \tfrac{8}{\theta} ) \tfrac{L D -
  \omega^\star_K}{L D - \theta} +\mathcal{O} ( \tfrac{\rho_K}{K^3} )
  \nonumber\\
  \leq{} & [ \tfrac{1}{2 \theta} +  ( 8 - \tfrac{4}{\theta} )
  ( \tfrac{L D - \omega^\star_K}{L D - \theta} ) ] \tfrac{2 L \| z' -
  x^{\star} \|^2}{K^2} +\mathcal{O} ( \tfrac{\rho_K}{K^3} ) .
  \nonumber
\end{align}
This completes the proof.
