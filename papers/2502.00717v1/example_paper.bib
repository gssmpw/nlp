@inproceedings{chen2025fastv,
  title={An image is worth 1/2 tokens after layer 2: Plug-and-play inference acceleration for large vision-language models},
  author={Chen, Liang and Zhao, Haozhe and Liu, Tianyu and Bai, Shuai and Lin, Junyang and Zhou, Chang and Chang, Baobao},
  booktitle={European Conference on Computer Vision},
  pages={19--35},
  year={2025},
  organization={Springer}
}

@inproceedings{leng2024vcd,
  title={Mitigating object hallucinations in large vision-language models through visual contrastive decoding},
  author={Leng, Sicong and Zhang, Hang and Chen, Guanzheng and Li, Xin and Lu, Shijian and Miao, Chunyan and Bing, Lidong},
  booktitle={Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition},
  pages={13872--13882},
  year={2024}
}

@inproceedings{li2023cd,
  title={Contrastive Decoding: Open-ended Text Generation as Optimization},
  author={Li, Xiang Lisa and Holtzman, Ari and Fried, Daniel and Liang, Percy and Eisner, Jason and Hashimoto, Tatsunori B and Zettlemoyer, Luke and Lewis, Mike},
  booktitle={Proceedings of the 61st Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers)},
  pages={12286--12312},
  year={2023}
}


@article{wang2024ICD,
  title={Mitigating hallucinations in large vision-language models with instruction contrastive decoding},
  author={Wang, Xintong and Pan, Jingheng and Ding, Liang and Biemann, Chris},
  journal={arXiv preprint arXiv:2403.18715},
  year={2024}
}

@inproceedings{manevich2024LCD,
  title={Mitigating Hallucinations in Large Vision-Language Models (LVLMs) via Language-Contrastive Decoding (LCD)},
  author={Manevich, Avshalom and Tsarfaty, Reut},
  booktitle={Findings of the Association for Computational Linguistics ACL 2024},
  pages={6008--6022},
  year={2024}
}

@inproceedings{huang2024opera,
  title={Opera: Alleviating hallucination in multi-modal large language models via over-trust penalty and retrospection-allocation},
  author={Huang, Qidong and Dong, Xiaoyi and Zhang, Pan and Wang, Bin and He, Conghui and Wang, Jiaqi and Lin, Dahua and Zhang, Weiming and Yu, Nenghai},
  booktitle={Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition},
  pages={13418--13427},
  year={2024}
}

@inproceedings{li2023pope,
  title={Evaluating Object Hallucination in Large Vision-Language Models},
  author={Li, Yifan and Du, Yifan and Zhou, Kun and Wang, Jinpeng and Zhao, Wayne Xin and Wen, Ji-Rong},
  booktitle={Proceedings of the 2023 Conference on Empirical Methods in Natural Language Processing},
  pages={292--305},
  year={2023}
}

@article{fu2023mme,
  title={MME: A Comprehensive Evaluation Benchmark for Multimodal Large Language Models},
  author={Fu, Chaoyou and Chen, Peixian and Shen, Yunhang and Qin, Yulei and Zhang, Mengdan and Lin, Xu and Yang, Jinrui and Zheng, Xiawu and Li, Ke and Sun, Xing and others},
  journal={arXiv preprint arXiv:2306.13394},
  year={2023}
}

@inproceedings{ben2024lvlm-interpret,
  title={LVLM-Intrepret: An Interpretability Tool for Large Vision-Language Models},
  author={Ben Melech Stan, Gabriela and Aflalo, Estelle and Rohekar, Raanan Yehezkel and Bhiwandiwalla, Anahita and Tseng, Shao-Yen and Olson, Matthew Lyle and Gurwicz, Yaniv and Wu, Chenfei and Duan, Nan and Lal, Vasudev},
  booktitle={Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition},
  pages={8182--8187},
  year={2024}
}

@inproceedings{liu2025pai,
  title={Paying more attention to image: A training-free method for alleviating hallucination in lvlms},
  author={Liu, Shi and Zheng, Kecheng and Chen, Wei},
  booktitle={European Conference on Computer Vision},
  pages={125--140},
  year={2025},
  organization={Springer}
}

@inproceedings{fu2025blink,
  title={Blink: Multimodal large language models can see but not perceive},
  author={Fu, Xingyu and Hu, Yushi and Li, Bangzheng and Feng, Yu and Wang, Haoyu and Lin, Xudong and Roth, Dan and Smith, Noah A and Ma, Wei-Chiu and Krishna, Ranjay},
  booktitle={European Conference on Computer Vision},
  pages={148--166},
  year={2025},
  organization={Springer}
}

@inproceedings{tong2024mmvp,
  title={Eyes wide shut? exploring the visual shortcomings of multimodal llms},
  author={Tong, Shengbang and Liu, Zhuang and Zhai, Yuexiang and Ma, Yi and LeCun, Yann and Xie, Saining},
  booktitle={Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition},
  pages={9568--9578},
  year={2024}
}

@inproceedings{you2024ferret,
  title={Ferret: Refer and Ground Anything Anywhere at Any Granularity},
  author={You, Haoxuan and Zhang, Haotian and Gan, Zhe and Du, Xianzhi and Zhang, Bowen and Wang, Zirui and Cao, Liangliang and Chang, Shih-Fu and Yang, Yinfei},
  booktitle={The Twelfth International Conference on Learning Representations}
}

@inproceedings{chen2024spatialvlm,
  title={Spatialvlm: Endowing vision-language models with spatial reasoning capabilities},
  author={Chen, Boyuan and Xu, Zhuo and Kirmani, Sean and Ichter, Brain and Sadigh, Dorsa and Guibas, Leonidas and Xia, Fei},
  booktitle={Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition},
  pages={14455--14465},
  year={2024}
}

@inproceedings{wu2024q-instruct,
  title={Q-instruct: Improving low-level visual abilities for multi-modality foundation models},
  author={Wu, Haoning and Zhang, Zicheng and Zhang, Erli and Chen, Chaofeng and Liao, Liang and Wang, Annan and Xu, Kaixin and Li, Chunyi and Hou, Jingwen and Zhai, Guangtao and others},
  booktitle={Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition},
  pages={25490--25500},
  year={2024}
}

@inproceedings{liu2024improved-llava,
  title={Improved baselines with visual instruction tuning},
  author={Liu, Haotian and Li, Chunyuan and Li, Yuheng and Lee, Yong Jae},
  booktitle={Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition},
  pages={26296--26306},
  year={2024}
}

@inproceedings{
hu2022lora,
title={Lo{RA}: Low-Rank Adaptation of Large Language Models},
author={Edward J Hu and Yelong Shen and Phillip Wallis and Zeyuan Allen-Zhu and Yuanzhi Li and Shean Wang and Lu Wang and Weizhu Chen},
booktitle={International Conference on Learning Representations},
year={2022},
url={https://openreview.net/forum?id=nZeVKeeFYf9}
}

@inproceedings{yu2024rlhf,
  title={Rlhf-v: Towards trustworthy mllms via behavior alignment from fine-grained correctional human feedback},
  author={Yu, Tianyu and Yao, Yuan and Zhang, Haoye and He, Taiwen and Han, Yifeng and Cui, Ganqu and Hu, Jinyi and Liu, Zhiyuan and Zheng, Hai-Tao and Sun, Maosong and others},
  booktitle={Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition},
  pages={13807--13816},
  year={2024}
}

@inproceedings{
wu2024reft,
title={Re{FT}: Representation Finetuning for Language Models},
author={Zhengxuan Wu and Aryaman Arora and Zheng Wang and Atticus Geiger and Dan Jurafsky and Christopher D Manning and Christopher Potts},
booktitle={The Thirty-eighth Annual Conference on Neural Information Processing Systems},
year={2024},
url={https://openreview.net/forum?id=fykjplMc0V}
}

@inproceedings{gunjal2024fdpo,
  title={Detecting and preventing hallucinations in large vision language models},
  author={Gunjal, Anisha and Yin, Jihan and Bas, Erhan},
  booktitle={Proceedings of the AAAI Conference on Artificial Intelligence},
  volume={38},
  number={16},
  pages={18135--18143},
  year={2024}
}

@article{dosovitskiy2020vit,
  title={An image is worth 16x16 words: Transformers for image recognition at scale},
  author={Dosovitskiy, Alexey},
  journal={arXiv preprint arXiv:2010.11929},
  year={2020}
}

@inproceedings{darcet2024vit-flaw,
  title={Vision Transformers Need Registers},
  author={Darcet, Timoth{\'e}e and Oquab, Maxime and Mairal, Julien and Bojanowski, Piotr},
  booktitle={The Twelfth International Conference on Learning Representations},
  year={2024}
}

@inproceedings{wu2024vstar,
  title={V*: Guided Visual Search as a Core Mechanism in Multimodal LLMs},
  author={Wu, Penghao and Xie, Saining},
  booktitle={Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition},
  pages={13084--13094},
  year={2024}
}

@inproceedings{
dong2024internlmxcomposerhd,
title={Intern{LM}-{XC}omposer2-4{KHD}: A Pioneering Large Vision-Language Model Handling Resolutions from 336 Pixels to 4K {HD}},
author={Xiaoyi Dong and Pan Zhang and Yuhang Zang and Yuhang Cao and Bin Wang and Linke Ouyang and Songyang Zhang and Haodong Duan and Wenwei Zhang and Yining Li and Hang Yan and Yang Gao and Zhe Chen and xinyue zhang and Wei Li and Li Jingwen and Wenhai Wang and Kai Chen and Conghui He and Xingcheng ZHANG and Jifeng Dai and Yu Qiao and Dahua Lin and Jiaqi Wang},
booktitle={The Thirty-eighth Annual Conference on Neural Information Processing Systems},
year={2024},
url={https://openreview.net/forum?id=nRp0XhTf61}
}

@misc{liu2024llavanext,
    title={LLaVA-NeXT: Improved reasoning, OCR, and world knowledge},
    url={https://llava-vl.github.io/blog/2024-01-30-llava-next/},
    author={Liu, Haotian and Li, Chunyuan and Li, Yuheng and Li, Bo and Zhang, Yuanhan and Shen, Sheng and Lee, Yong Jae},
    month={January},
    year={2024}
}

@inproceedings{xiao2023streamllm,
  title={Efficient Streaming Language Models with Attention Sinks},
  author={Xiao, Guangxuan and Tian, Yuandong and Chen, Beidi and Han, Song and Lewis, Mike},
  booktitle={The Twelfth International Conference on Learning Representations},
  year={2023}
}

@inproceedings{yu2025api,
  title={Attention prompting on image for large vision-language models},
  author={Yu, Runpeng and Yu, Weihao and Wang, Xinchao},
  booktitle={European Conference on Computer Vision},
  pages={251--268},
  year={2025},
  organization={Springer}
}

@article{touvron2023llama,
  title={Llama: Open and efficient foundation language models},
  author={Touvron, Hugo and Lavril, Thibaut and Izacard, Gautier and Martinet, Xavier and Lachaux, Marie-Anne and Lacroix, Timoth{\'e}e and Rozi{\`e}re, Baptiste and Goyal, Naman and Hambro, Eric and Azhar, Faisal and others},
  journal={arXiv preprint arXiv:2302.13971},
  year={2023}
}

@misc{vicuna2023,
    title = {Vicuna: An Open-Source Chatbot Impressing GPT-4 with 90\%* ChatGPT Quality},
    url = {https://lmsys.org/blog/2023-03-30-vicuna/},
    author = {Chiang, Wei-Lin and Li, Zhuohan and Lin, Zi and Sheng, Ying and Wu, Zhanghao and Zhang, Hao and Zheng, Lianmin and Zhuang, Siyuan and Zhuang, Yonghao and Gonzalez, Joseph E. and Stoica, Ion and Xing, Eric P.},
    month = {March},
    year = {2023}
}

@article{bai2023qwen,
  title={Qwen technical report},
  author={Bai, Jinze and Bai, Shuai and Chu, Yunfei and Cui, Zeyu and Dang, Kai and Deng, Xiaodong and Fan, Yang and Ge, Wenbin and Han, Yu and Huang, Fei and others},
  journal={arXiv preprint arXiv:2309.16609},
  year={2023}
}

@article{bai2023qwen-vl,
  title={Qwen-vl: A frontier large vision-language model with versatile abilities},
  author={Bai, Jinze and Bai, Shuai and Yang, Shusheng and Wang, Shijie and Tan, Sinan and Wang, Peng and Lin, Junyang and Zhou, Chang and Zhou, Jingren},
  journal={arXiv preprint arXiv:2308.12966},
  year={2023}
}

@inproceedings{radford2021clip,
  title={Learning transferable visual models from natural language supervision},
  author={Radford, Alec and Kim, Jong Wook and Hallacy, Chris and Ramesh, Aditya and Goh, Gabriel and Agarwal, Sandhini and Sastry, Girish and Askell, Amanda and Mishkin, Pamela and Clark, Jack and others},
  booktitle={International conference on machine learning},
  pages={8748--8763},
  year={2021},
  organization={PMLR}
}

@article{yao2024deco,
  title={DeCo: Decoupling Token Compression from Semantic Abstraction in Multimodal Large Language Models},
  author={Yao, Linli and Li, Lei and Ren, Shuhuai and Wang, Lean and Liu, Yuanxin and Sun, Xu and Hou, Lu},
  journal={arXiv preprint arXiv:2405.20985},
  year={2024}
}

@inproceedings{cha2024honeybee,
  title={Honeybee: Locality-enhanced projector for multimodal llm},
  author={Cha, Junbum and Kang, Wooyoung and Mun, Jonghwan and Roh, Byungseok},
  booktitle={Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition},
  pages={13817--13827},
  year={2024}
}

@inproceedings{lai2024lisa,
  title={Lisa: Reasoning segmentation via large language model},
  author={Lai, Xin and Tian, Zhuotao and Chen, Yukang and Li, Yanwei and Yuan, Yuhui and Liu, Shu and Jia, Jiaya},
  booktitle={Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition},
  pages={9579--9589},
  year={2024}
}

@inproceedings{zhang2025llava-grounded,
  title={Llava-grounding: Grounded visual chat with large multimodal models},
  author={Zhang, Hao and Li, Hongyang and Li, Feng and Ren, Tianhe and Zou, Xueyan and Liu, Shilong and Huang, Shijia and Gao, Jianfeng and Li, Chunyuan and Yang, Jainwei and others},
  booktitle={European Conference on Computer Vision},
  pages={19--35},
  year={2025},
  organization={Springer}
}

@inproceedings{wen2023dilu,
  title={DiLu: A Knowledge-Driven Approach to Autonomous Driving with Large Language Models},
  author={Wen, Licheng and Fu, Daocheng and Li, Xin and Cai, Xinyu and Tao, MA and Cai, Pinlong and Dou, Min and Shi, Botian and He, Liang and Qiao, Yu},
  booktitle={The Twelfth International Conference on Learning Representations},
  year={2023}
}

@inproceedings{yan2024medicalvqa,
  title={Multi-modal Concept Alignment Pre-training for Generative Medical Visual Question Answering},
  author={Yan, Quan and Duan, Junwen and Wang, Jianxin},
  booktitle={Findings of the Association for Computational Linguistics ACL 2024},
  pages={5378--5389},
  year={2024}
}

@article{zhu2023minigpt,
  title={Minigpt-4: Enhancing vision-language understanding with advanced large language models},
  author={Zhu, Deyao and Chen, Jun and Shen, Xiaoqian and Li, Xiang and Elhoseiny, Mohamed},
  journal={arXiv preprint arXiv:2304.10592},
  year={2023}
}

@inproceedings{rohrbach2018chair,
  title={Object Hallucination in Image Captioning},
  author={Rohrbach, Anna and Hendricks, Lisa Anne and Burns, Kaylee and Darrell, Trevor and Saenko, Kate},
  booktitle={Proceedings of the 2018 Conference on Empirical Methods in Natural Language Processing},
  pages={4035--4045},
  year={2018}
}

@article{liu2024llava,
  title={Visual instruction tuning},
  author={Liu, Haotian and Li, Chunyuan and Wu, Qingyang and Lee, Yong Jae},
  journal={Advances in neural information processing systems},
  volume={36},
  year={2024}
}

@inproceedings{lin2014mscoco,
  title={Microsoft coco: Common objects in context},
  author={Lin, Tsung-Yi and Maire, Michael and Belongie, Serge and Hays, James and Perona, Pietro and Ramanan, Deva and Doll{\'a}r, Piotr and Zitnick, C Lawrence},
  booktitle={Computer Vision--ECCV 2014: 13th European Conference, Zurich, Switzerland, September 6-12, 2014, Proceedings, Part V 13},
  pages={740--755},
  year={2014},
  organization={Springer}
}