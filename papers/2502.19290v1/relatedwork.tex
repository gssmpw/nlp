\section{Related Works}
\label{sec: related_works}
\textbf{Traditional Numerical Methods} As a fundamental scientific problem, obtaining analytical solutions for partial differential equations is often difficult. Consequently, PDEs are usually discretized into meshes and solved using numerical methods in practice, such as finite difference method\cite{sod1978survey}, finite element methods \cite{huebner2001finite}, spectral methods \cite{shen2011spectral}, etc. However, these numerical methods usually take a few hours or even days for complex structures \cite{umetani2018learning} and perform badly on the forecasting problem.

\textbf{Data-free deep learning Method} One of the most popular data-free deep learning methods is PINNs. This approach formalizes the constraints of PDEs, including the equations themselves, as well as initial and boundary conditions, as the objective functions within deep learning models \cite{raissi2019physics,yu2018deep}. During the training process, the outputs of these models gradually align with the PDE constraints, allowing them to effectively approximate the solutions to the PDEs. However, this method mainly relies
on convolutional neural networks, ignoring the crucial temporal dependencies inherent in practical physics systems, making it challenging to forecast solutions outside the given training grids. Also, directly using PINNs will fail to learn the solution of PDEs in some complex scenarios. For instance, \cite{jin2023asymptotic,liu2024asymptotic} propose the Asymptotic-Preserving PINNs to solve the difficulties caused by multiscale equations.

\textbf{Operator Learning-Based Methods} 
Operator learning-based methods constitute a significant class within data-driven deep learning approaches, which involve training neural operators to approximate the input-output relationships in tasks governed by partial differential equations. This method can be applied to many physical scenarios, such as predicting future fluid behaviour based on past observations or estimating the internal stress in solid materials \cite{lu2021learning}. Some of the most well-known models in this area include the Fourier Neural Operator \cite{li2020fourier} and its variants, such as those described in  \cite{li2024geometry} and \cite{rahman2022u}. There have been some works \cite{yin2022continuous} focusing on forecasting the dynamics in PDEs. However, they often require a large volume of data and mostly they often ignore utilizing the intrinsic physical mechanism inside the PDEs.

\textbf{Transformer-Based Models}
The Transformer model \cite{vaswani2017attention} has garnered considerable attention for its capability to capture long-term dependencies, resulting in substantial advancements in natural language processing tasks \cite{kalyan2021ammus}. Additionally, Transformers have been adapted for use in various other fields, including computer vision, speech recognition, and time-series analysis \cite{dong2018speech, han2022survey,wen2022transformers}. However, there are few researches on the application of transformers in solving PDEs. Recent researchers have used transformer to learn the solution of given PDEs \cite{cao2021choose, wu2024transolver,zhao2023pinnsformer}. However, the combination of PINNs and transformer hasn't been fused that well and forecasting tasks in PDEs have not been studied enough.