@article{cao2021choose,
  title={Choose a transformer: Fourier or galerkin},
  author={Cao, Shuhao},
  journal={Advances in neural information processing systems},
  volume={34},
  pages={24924--24940},
  year={2021}
}

@inproceedings{dong2018speech,
  title={Speech-transformer: a no-recurrence sequence-to-sequence model for speech recognition},
  author={Dong, Linhao and Xu, Shuang and Xu, Bo},
  booktitle={2018 IEEE international conference on acoustics, speech and signal processing (ICASSP)},
  pages={5884--5888},
  year={2018},
  organization={IEEE}
}

@article{han2022survey,
  title={A survey on vision transformer},
  author={Han, Kai and Wang, Yunhe and Chen, Hanting and Chen, Xinghao and Guo, Jianyuan and Liu, Zhenhua and Tang, Yehui and Xiao, An and Xu, Chunjing and Xu, Yixing and others},
  journal={IEEE transactions on pattern analysis and machine intelligence},
  volume={45},
  number={1},
  pages={87--110},
  year={2022},
  publisher={IEEE}
}

@book{huebner2001finite,
  title={The finite element method for engineers},
  author={Huebner, Kenneth H and Dewhirst, Donald L and Smith, Douglas E and Byrom, Ted G},
  year={2001},
  publisher={John Wiley \& Sons}
}

@article{jin2023asymptotic,
  title={Asymptotic-preserving neural networks for multiscale kinetic equations},
  author={Jin, Shi and Ma, Zheng and Wu, Keke},
  journal={arXiv preprint arXiv:2306.15381},
  year={2023}
}

@article{kalyan2021ammus,
  title={Ammus: A survey of transformer-based pretrained models in natural language processing},
  author={Kalyan, Katikapalli Subramanyam and Rajasekharan, Ajit and Sangeetha, Sivanesan},
  journal={arXiv preprint arXiv:2108.05542},
  year={2021}
}

@article{li2020fourier,
  title={Fourier neural operator for parametric partial differential equations},
  author={Li, Zongyi and Kovachki, Nikola and Azizzadenesheli, Kamyar and Liu, Burigede and Bhattacharya, Kaushik and Stuart, Andrew and Anandkumar, Anima},
  journal={arXiv preprint arXiv:2010.08895},
  year={2020}
}

@article{li2024geometry,
  title={Geometry-informed neural operator for large-scale 3d pdes},
  author={Li, Zongyi and Kovachki, Nikola and Choy, Chris and Li, Boyi and Kossaifi, Jean and Otta, Shourya and Nabian, Mohammad Amin and Stadler, Maximilian and Hundt, Christian and Azizzadenesheli, Kamyar and others},
  journal={Advances in Neural Information Processing Systems},
  volume={36},
  year={2024}
}

@article{liu2024asymptotic,
  title={Asymptotic-preserving neural networks for the semiconductor Boltzmann equation and its application on inverse problems},
  author={Liu, Liu and Wang, Yating and Zhu, Xueyu and Zhu, Zhenyi},
  journal={arXiv preprint arXiv:2407.16169},
  year={2024}
}

@article{lu2021learning,
  title={Learning nonlinear operators via DeepONet based on the universal approximation theorem of operators},
  author={Lu, Lu and Jin, Pengzhan and Pang, Guofei and Zhang, Zhongqiang and Karniadakis, George Em},
  journal={Nature machine intelligence},
  volume={3},
  number={3},
  pages={218--229},
  year={2021},
  publisher={Nature Publishing Group UK London}
}

@article{rahman2022u,
  title={U-no: U-shaped neural operators},
  author={Rahman, Md Ashiqur and Ross, Zachary E and Azizzadenesheli, Kamyar},
  journal={arXiv preprint arXiv:2204.11127},
  year={2022}
}

@article{raissi2019physics,
  title={Physics-informed neural networks: A deep learning framework for solving forward and inverse problems involving nonlinear partial differential equations},
  author={Raissi, Maziar and Perdikaris, Paris and Karniadakis, George E},
  journal={Journal of Computational physics},
  volume={378},
  pages={686--707},
  year={2019},
  publisher={Elsevier}
}

@book{shen2011spectral,
  title={Spectral methods: algorithms, analysis and applications},
  author={Shen, Jie and Tang, Tao and Wang, Li-Lian},
  volume={41},
  year={2011},
  publisher={Springer Science \& Business Media}
}

@article{sod1978survey,
  title={A survey of several finite difference methods for systems of nonlinear hyperbolic conservation laws},
  author={Sod, Gary A},
  journal={Journal of computational physics},
  volume={27},
  number={1},
  pages={1--31},
  year={1978},
  publisher={Elsevier}
}

@article{umetani2018learning,
  title={Learning three-dimensional flow for interactive aerodynamic design},
  author={Umetani, Nobuyuki and Bickel, Bernd},
  journal={ACM Transactions on Graphics (TOG)},
  volume={37},
  number={4},
  pages={1--10},
  year={2018},
  publisher={ACM New York, NY, USA}
}

@article{vaswani2017attention,
  title={Attention is all you need},
  author={Vaswani, A},
  journal={Advances in Neural Information Processing Systems},
  year={2017}
}

@article{wen2022transformers,
  title={Transformers in time series: A survey},
  author={Wen, Qingsong and Zhou, Tian and Zhang, Chaoli and Chen, Weiqi and Ma, Ziqing and Yan, Junchi and Sun, Liang},
  journal={arXiv preprint arXiv:2202.07125},
  year={2022}
}

@article{wu2024transolver,
  title={Transolver: A fast transformer solver for pdes on general geometries},
  author={Wu, Haixu and Luo, Huakun and Wang, Haowen and Wang, Jianmin and Long, Mingsheng},
  journal={arXiv preprint arXiv:2402.02366},
  year={2024}
}

@article{yin2022continuous,
  title={Continuous pde dynamics forecasting with implicit neural representations},
  author={Yin, Yuan and Kirchmeyer, Matthieu and Franceschi, Jean-Yves and Rakotomamonjy, Alain and Gallinari, Patrick},
  journal={arXiv preprint arXiv:2209.14855},
  year={2022}
}

@article{yu2018deep,
  title={The deep Ritz method: a deep learning-based numerical algorithm for solving variational problems},
  author={Yu, Bing and others},
  journal={Communications in Mathematics and Statistics},
  volume={6},
  number={1},
  pages={1--12},
  year={2018},
  publisher={Springer}
}

@article{zhao2023pinnsformer,
  title={Pinnsformer: A transformer-based framework for physics-informed neural networks},
  author={Zhao, Zhiyuan and Ding, Xueying and Prakash, B Aditya},
  journal={arXiv preprint arXiv:2307.11833},
  year={2023}
}

