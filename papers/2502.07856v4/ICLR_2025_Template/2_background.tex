\section{Background}

In this section, we briefly review the basic definitions and characteristics of diffusion probabilistic models and mean-reverting diffusion models.

\subsection{Diffusion Probabilistic Models}

According to \cite{song2020sde}, Diffusion Probabilistic Models (DPMs) can be defined as the solution of the following Itô stochastic differential equation (SDE), which is a stochastic process $\{\boldsymbol{x}_t\}_{t\in [0,T]}$ with $T>0$, called \textit{forward process}, where $\boldsymbol{x}_t\in \mathbb{R}^D$ is a D-dimensional random variable.
\begin{equation}
    \mathrm{d}\boldsymbol{x}=f(\boldsymbol{x},t)\mathrm{d}t + g(t) \mathrm{d}\boldsymbol{w}. \label{1}
\end{equation}
The forward process performs adding noise to the data $\boldsymbol{x}_0$, while there exists a corresponding reverse process that gradually removes the noise and recovers $\boldsymbol{x}_0$. \cite{anderson1982reverse} shows that the reverse of the forward process is also a solution of an Itô SDE:
\begin{equation}
    \mathrm{d}\boldsymbol{x}=[f(\boldsymbol{x},t)-g(t)^2\nabla_{\boldsymbol{x}}\log{p_t(\boldsymbol{x})}]\mathrm{d}t + g(t)\mathrm{d}\bar{\boldsymbol{w}}, \label{2}
\end{equation}
where $f$ and $g$ are the drift and diffusion coefficients respectively, $\bar{\boldsymbol{w}}$ is a standard Wiener process running backwards in time, and time $t$ flows from $T$ to $0$, which means $\mathrm{d}t<0$. The score function $\nabla_{\boldsymbol{x}}\log{p_t(\boldsymbol{x})}$ is generally intractable and thus a neural network $\boldsymbol{s}_\theta(\boldsymbol{x},t)$ is used to estimate it by optimizing the following objective \citep{song2020sde,hyvarinen2005scorematch}:
\begin{equation}
    \boldsymbol{\theta}^{*}=\arg\min_{\boldsymbol{\theta}}\mathbb{E}_{t}\Big\{\lambda(t)\mathbb{E}_{\boldsymbol{x}_0}\mathbb{E}_{\boldsymbol{x}_t|\boldsymbol{x}_0}\Big[\left\|\boldsymbol{s}_{\boldsymbol{\theta}}(\boldsymbol{x}_t,t)-\nabla_{\boldsymbol{x}_t}\log p(\boldsymbol{x}_t|\boldsymbol{x}_0)\right\|_{2}^{2}\Big]\Big\}.
    \label{3}
\end{equation}
where $\lambda(t):[0,T]\rightarrow\mathbb{R}^+$ is a positive weighting function, $t$ is uniformly sampled over $[0,T]$, $\boldsymbol{x}_0\sim p_0(\boldsymbol{x})$ and $\boldsymbol{x}_t\sim p(\boldsymbol{x}_t|\boldsymbol{x}_0)$. To facilitate the computation of $p(\boldsymbol{x}_t|\boldsymbol{x}_0)$, the drift coefficient $f(\boldsymbol{x},t)$ is typically defined as a linear function of $\boldsymbol{x}$, as presented in Eq.(\ref{4}). Based on the inference by \cite{sarkka2019applied} in Section 5.5, the transition probability $p(\boldsymbol{x}_t|\boldsymbol{x}_0)$ corresponding to Eq.(\ref{4}) follows Gaussian distribution, as shown in Eq.(\ref{5}).
\begin{equation}
    \mathrm{d}\boldsymbol{x}=f(t)\boldsymbol{x}\mathrm{d}t + g(t) \mathrm{d}\boldsymbol{w}, \label{4}
\end{equation}
\begin{equation}
    p(\boldsymbol{x}_t|\boldsymbol{x}_0)\sim\mathcal{N}\left(\boldsymbol{x}_t;\boldsymbol{x}_0e^{\int_0^tf(\tau)\mathrm{d}\tau},\int_0^te^{2\int_\tau^t f(\xi)\mathrm{d}\xi}g^2(\tau)\mathrm{d}\tau\cdot\boldsymbol{I} \right). \label{5}
\end{equation}
\cite{song2020sde} proved that Denoising Diffusion Probabilistic Models \citep{ho2020ddpm} and Noise Conditional
Score Networks \citep{song2019ncsn} can be regarded as discretizations of Variance Preserving SDE (VPSDE) and Variance Exploding SDE (VESDE), respectively. As shown in Table~\ref{table1}, the SDEs corresponding to the two most commonly used diffusion models both follow the form of Eq.(\ref{4}).

\renewcommand{\arraystretch}{1.5}
\begin{table}[hb]
\caption{Two popular SDEs, Variance Preserving SDE (VPSDE) and Variance Exploding SDE (VESDE). $m(t)$ and $v(t)$ refer to mean and variance of the transition probability $p(\boldsymbol{x}_t|\boldsymbol{x}_0)$.}
\vspace{-10pt}
\label{table1}
\begin{center}
\begin{tabular}{ccccc}
\toprule[1pt]
SDE & $f(t)$ & $g(t)$ & $m(t)$ & $v(t)$\\
\cmidrule(lr){1-5}
VPSDE\citep{ho2020ddpm}     &$-\frac12\beta(t)$ &$\sqrt{\beta(t)}$   &$\boldsymbol{x}_0e^{-\frac12\int_0^t\beta(\tau)\mathrm{d}\tau}$   &$\boldsymbol{I}-\boldsymbol{I}e^{-\int_0^t\beta(\tau)\mathrm{d}\tau}$\\

VESDE\citep{song2019ncsn}   &$0$                &$\sqrt{\frac{\mathrm{d}[\sigma^{2}(t)]}{\mathrm{d}t}}$     &$\boldsymbol{x}_0$     &$\left[\sigma^2(t)-\sigma^2(0)\right]\boldsymbol{I}$\\
\bottomrule[1pt]
\end{tabular}
\end{center}
\end{table}

\subsection{Mean Reverting Diffusion Models}
\label{section2.2}

\cite{luo2023mrsde} proposed a special case of Itô SDE named Mean Reverting SDE (MRSDE), as follows:
\begin{equation}
    \mathrm{d}\boldsymbol{x}=f(t)\left(\boldsymbol{\mu}-\boldsymbol{x}\right)\mathrm{d}t+g(t)\mathrm{d}\boldsymbol{w},
    \label{6}
\end{equation}
where $\boldsymbol{\mu}$ is a parameter vector that has the same shape of variable $\boldsymbol{x}$, and $f(t), g(t)$ are time-dependent non-negative parameters that control the speed of the mean reversion and stochastic volatility, respectively. To prevent potential confusion, we have substituted the notation used in the original paper \citep{luo2023mrsde}. For further details, please refer to Appendix \ref{appb}. Under the assumption that $g^2(t)/f(t)=2\sigma_\infty^2$ for any $t\in [0,T]$ with $T>0$, Eq.(\ref{6}) has a closed-form solution, given by
\begin{equation}
    \boldsymbol{x}_t=\boldsymbol{x}_0e^{-\int_0^t f(\tau)\mathrm{d}\tau}+\boldsymbol{\mu}(1-e^{-\int_0^t f(\tau)\mathrm{d}\tau})+\sigma_\infty\sqrt{1-e^{-2\int_0^t f(\tau)\mathrm{d}\tau}}\boldsymbol{z},
    \label{7}
\end{equation}
where $\sigma_\infty$ is a positive hyper-parameter that determines the standard deviation of $\boldsymbol{x}_t$ when $t\rightarrow\infty$ and $\boldsymbol{z}\sim\mathcal{N}(\boldsymbol{0},\boldsymbol{I})$. Note that $\boldsymbol{x}_t$ starts from $\boldsymbol{x}_0$, and converges to $\boldsymbol{\mu}+\sigma_\infty\boldsymbol{z}$ as $t\rightarrow\infty$. According to \cite{anderson1982reverse}'s result, we can derive the following reverse-time SDE:
\begin{equation}
    \mathrm{d}\boldsymbol{x}=\left[f(t)\left(\boldsymbol{\mu}-\boldsymbol{x}\right)-g^2(t)\nabla_{\boldsymbol{x}}\log p_t(\boldsymbol{x})\right]\mathrm{d}t+g(t)\mathrm{d}\bar{\boldsymbol{w}}.
    \label{8}
\end{equation}
Similar to DPMs, the score function in Eq.(\ref{8}) can also be estimated by score matching methods \cite{song2019ncsn,song2021maximum}. Once the score function is known, we can generate $\boldsymbol{x}_0$ from a noisy state $\boldsymbol{x}_T$. In summary, MRSDE illustrates the conversion between two distinct types of data and has demonstrated promising results in image restoration tasks \citep{luo2023refusion}.

Various algorithms have been developed to accelerate sampling of VPSDE, including methods like CCDF \citep{chung2022come}, DDIM \citep{song2020ddim}, PNDM \citep{liu2022pndm}, DPM-Solver \citep{lu2022dpmsolver} and UniPC \citep{zhao2024unipc}. Additionally, \cite{karras2022elucidating} and \cite{zhou2024amed} have introduced techniques for accelerating sampling of VESDE. However, the drift coefficient of VPSDE and VESDE is a linear function of $\boldsymbol{x}$, while the drift coefficient in MRSDE is an affine function w.r.t. $\boldsymbol{x}$, adding an intercept $\boldsymbol{\mu}$ (see Eq.(\ref{4}) and Eq.(\ref{6})). Therefore, current sampling acceleration algorithms cannot be applied to MR Diffusion. To the best of our knowledge, \ourmethod~has been the first sampling acceleration algorithm for MR Diffusion so far.