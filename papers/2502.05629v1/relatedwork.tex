\section{Related Work}
%贝叶斯滤波的核心机制是使用新息来更新先验估计。现实模型往往是非线性的，几种经典方法被用来处理非线性。EKF\cite{}是一种局部线性近似方法，当非线性程度很大时，会加剧线性化误差。UKF\cite{}通过无迹变换（Unscented Transform, UT）采样一些“sigma点”来估计非线性系统的状态，从而避免了EKF中的一阶线性化误差。对于更复杂的模型，对于更复杂的SS模型，并且当噪声不能被建模为高斯时，提出了基于顺序MC的PF的多个变体[11]-[13]，[41]-[45]。这些方法的性能直接取决于假设的SSM和真实系统的匹配程度。
%传统贝叶斯滤波器的最优性取决于先验SSM的正确性[8]，因此，在存在模型失配的情况下，其性能会显著下降，而在复杂且非合作的环境中，则很难获得完整且正确的先验SSM。

%更重要的是，在线贝叶斯优化方法只处理实时测量数据，而忽略了丰富的离线数据。随着传感器的广泛部署和仿真技术的进步，在线数据的可用性显著增加，导致深度学习（DL）的使用激增。通过其强大的非线性拟合能力和记忆迭代机制捕捉状态演化中的时间规律，

%机器学习和SSM的结合，的数据驱动的方法优点是什么，目前的基于数据驱动方法依然都还是在卡尔曼滤波框架下完成的，

%扩散模型在CV领域已经图像生成领域已经被广泛使用。并已经拓展到offline RL中decision making。
%总结，扩散模型可以学习数据的分布并基于此产生XX。motivated by XX, 我们尝试设计了一种基于扩散模型的新型贝叶斯滤波器。

% 贝叶斯滤波的关键是得到后验概率密度函数，即使用新的观测信息更新先验估计。然而在实践中许多问题受到非线性运动学的影响，SSM不能满足线性假设，it is always infeasible for us to obtain an optimal or analytic solution\cite{4982682} \cite{1098671}。经典的方法有，基于局部线性化的EKF,当非线性程度更高时，会采用基于Unscented Transform的UKF\cite{Julier1997NewEO}。对于更复杂模型，尤其是噪声无法建模为高斯时，提出了基于顺序蒙特-卡罗（MC）采样的方法，例如粒子滤波器（PF）家族\cite{DELMORAL1997653, doi:10.1049/ip-f-2.1993.0015, 7079001}。这些MB的方法的性能受到SSM模型建模准确性影响很大，当建模的SSM与真实数据不匹配时，性能会大大降低。上述方法可能仍无法近似后验概率分布，可能的一个原因是，非线性卡尔曼滤波器受到线性化误差影响\cite{8922805}。机器学习和贝叶斯滤波的结合，受到越来越多的研究关注。一类纯数据驱动学习的方法，当训练数据可用时，会采用端到端训练的方式学习全部或部分系统SSM\cite{YAN2024102580, 10502278}。例如\cite{9398578}基于卡尔曼滤波器的框架，采用LSTM拟合state-evolution function。\cite{10320373}结合变分贝叶斯推理，在beam tracking 任务中拟合系统的state-evolution function。PF上也有发展\cite{ma2020particle, Kloss2021, corenflos2021differentiable, 9561889}, \cite{jonschkowski2018differentiable}提出基于PF和RNNs参数化的SSM的Differentiable particle filters。  这类方法没有使用NN结构化 SS 模型等领域知识。因此，即使对于简单的序列\cite{zaheer2017latent}，这些DD的方法也需要许多可训练的参数和大型数据集，并且缺乏MB方法的可解释性。此外，这类方法大多只学习一种运动模型，无法泛化到系统运动模型发生变化的情况。

% 另一种是MB结合DL的方法来动态调整系统噪声统计量\cite{10120968, 10632588}，仍然使用system dynamic model的领域知识。经典的例如KalmanNet\cite{9733186}，采用RNNs动态调整过程噪声和观测噪声参数，从而学习最优卡尔曼增益。之后，\cite{10288023}learn the optimal Kalman gain together with the errors in the IMU measurements。\cite{10566495}拓展到了无监督学习上，基于Measurement Residual Log-Likelihood学习Kalman gain。目前这类方法动态调整系统噪声参数在一定程度可以缓解模型不匹配而带来的非线性加剧的影响，但是当模型非线性程度很高时，由于依然是采用和EKF一样的局部线性化的方法，这类方法无法克服非线性误差累积。此外，当系统噪声不满足高斯假设时，这类方法将无法近似后验概率密度函数。

% 而我们的问题是当只有极少SSM知识，例如只有state-evolution的先验知识，甚至噪声模型未知的情况，我们是否可以找到一种更通用的逼近后验概率密度函数的方法。扩散模型起初在学习图像和文本数据的生成模型方面显示出强大能力，上述工作集中在文本或图像生成领域。现在在生成任务上已经应用到其他across various domains. 最近的工作使用扩散模型在offline RL中参数化policy，XX等人\cite{}使用条件扩散模型生成符合高价值奖励条件的轨迹。在Time series forecasting\cite{10.5555/3666122.3667354， fan2024mgtsd}，\cite{10.5555/3666122.3667354}把forecasters设计成Observation Self-Guidance diffusion model，使用学习到的数据分布迭代地细化基本预测器的预测。图像和时间序列中，数据是高维非线性的，上述示例已经证明扩散模型在复杂分布建模中的优势。这motivated us 把扩散模型应用到贝叶斯滤波中。

% The key to bayesian filtering is obtaining the posterior probability density distribution, which involves updating the prior state estimate with the new measurement. However, in practice, many problems are influenced by non-linear dynamics as the SSM cannot satisfy linear assumptions, making it often infeasible to obtain an optimal or analytical solution \cite{4982682, 1098671}. Classical MB methods include EKF \cite{4982682, 1098671}, which is based on local linearization. When the degree of nonlinearity is higher, the Unscented Transform based UKF \cite {Julier1997NewEO} is used. For more complex SSM, especially when noise cannot be modeled as Gaussian process, sequential Monte Carlo (MC) sampling methods have been proposed, such as the PF family \cite{DELMORAL1997653, doi:10.1049/ip-f-2.1993.0015, 7079001}. The performance of these MB methods heavily depends on the accuracy of the SSM. When the modeled SSM does not meet the real data, performance can degrade significantly \cite{9733186}. 

% The combination of machine learning and Bayesian filtering is receiving increasing research attention. One class of purely data-driven learning approaches adopts an end-to-end training approach to learn the system dynamics when training data is available \cite{YAN2024102580, 10502278}. For example, \cite{9398578} proposes an LSTM-based approach within the Kalman filter framework to fit the state-evolution function. \cite{10320373} combines variational Bayesian inference to fit the state-evolution function in beam tracking task. There have also been developments in PF-based methods \cite{ma2020particle, Kloss2021, corenflos2021differentiable, 9561889}. 

% \cite{jonschkowski2018differentiable} introduced differentiable particle filters that parameterize the SSM using RNNs. These methods do not learn a structured system dynamics model but instead focus solely on learning a mapping relationship. Therefore, even for simple sequences \cite{zaheer2017latent}, these purely data-driven methods require many trainable parameters and large datasets, while lacking the interpretability of MB methods. Moreover, these methods mostly learn a single system dynamics model mapping, making them incapable of generalizing when the system dynamics model changes.

% Another approach combines purely data-driven methods with MB methods, creating a hybrid approach that employs RNNs to dynamically adjust certain parameters of the SSM while still utilizing the system dynamics model. A classic example is KalmanNet \cite{9733186}, which uses RNNs to dynamically adjust process and measurement noise parameters, thereby learning the optimal Kalman gain. Later, \cite{10288023} learns the optimal Kalman gain along with errors in IMU measurements. \cite{10566495} extended it to unsupervised learning, where the Kalman gain is learned based on the Measurement Residual Log-Likelihood. Currently, this type of method dynamically adjusts system noise parameters, which can mitigate the impact of increased nonlinearity due to model mismatches. However, when the nonlinearity is severe, these methods still use local linearization and are unable to overcome the accumulation of non-linear errors. Additionally, when the system noise does not follow the Gaussian process assumption, these methods cannot obtain the posterior probability density distribution.

% Considering non-cooperative scenarios, we have limited prior domain knowledge of the non-linear SSM. Specifically, we only possess prior knowledge of the system dynamics, with no information about the noise model or even the measurement model.
% Our problem arises can we find a more general method to approximate the posterior probability density distribution?
\subsection{Bayesian filtering}

Depending on whether deep learning is used, existing Bayesian filtering algorithms can be categorized into two groups, i.e., model-based and data-driven approaches.
Model-based approaches are based on the state space model. The most representative one is the EKF \cite {4982682, 1098671}, an extension of KF, which is based on local linearization with low computational efforts.
When the degree of nonlinearity is higher, the Unscented Transform based UKF \cite {Julier1997NewEO} is proposed, which computes the sigma points avoiding the computation of the Jacobi matrix.
For more complex SSMs, particularly a non-Gaussian process, Sequential Monte Carlo sampling methods have been proposed, such as the PF family  \cite{DELMORAL1997653, 7079001}, which distributes a large number of particles to approximate the posterior distribution.
However, filtering performances of these MB methods heavily depend on the accuracy of the SSM.

Alternatively, recent advances in simulation technology and sensor deployment \cite{10508326} have led to data-driven using deep learning. 
The current approaches are categorized into two types depending on whether a priori SSM is used or not.
The purely data-driven approach, i.e. end-to-end approach \cite{10320373, YAN2024102580}, abandons valuable dynamic model structures, and approximates the state-evolution function directly. 
However, even for simple sequences \cite{zaheer2017latent}, purely data-driven methods require vast amounts of data while lacking interpretability compared with MB methods.
The other is a hybrid approach combining SSM and RNN, which employs neural networks to dynamically adjust some of the parameters in SSM. 
A typical method is KalmanNet \cite {9733186}, which uses RNNs to dynamically adjust process and measurement noise parameters, thereby learning the optimal Kalman gain. 
Later, \cite{ 10288023} learns the optimal Kalman gain along with errors in IMU measurements. \cite{10566495} extended it to unsupervised learning, in which the Kalman gain is learned based on the Measurement Residual Log-Likelihood. 
Currently, hybrid methods dynamically adjust noise parameters, which can mitigate the impact of the SSM mismatch.

\subsection{Diffusion model}

Diffusion model has initially demonstrated strong capabilities in learning generative models for image and text data \cite{ho2022video, xu2023versatile}, and have since been applied in various domains for generative tasks. 
Recent work have used diffusion models to parameterize policies in offline reinforcement learning (RL), where \cite{ajay2023is, 10.5555/3618408.3619493} employed conditional diffusion models to generate trajectories aligned with high-reward conditions. 
In time series forecasting \cite{10.5555/3666122.3667354, fan2024mgtsd}, forecasters are designed as observation self-guidance diffusion models, iteratively refining the basic predictor forecasts by leveraging learned data distributions \cite{10.5555/3666122.3667354}.


% Diffusion models initially demonstrated strong capabilities in learning generative models for image and text data \cite{ho2022video, xu2023versatile}, they are now being applied across various domains for generative tasks. Recent work has used diffusion models to parameterize policies in offline reinforcement learning (RL), where \cite{ajay2023is, 10.5555/3618408.3619493} employed conditional diffusion models to generate trajectories aligned with high-reward conditions. In time series forecasting \cite{10.5555/3666122.3667354, fan2024mgtsd}, \cite{10.5555/3666122.3667354} designed forecasters as observation self-guidance diffusion models, iteratively refining the basic predictor forecasts using learned data distributions.

%tip最后一段可以再加一些扩散模型本身技术相关