@inproceedings{10.5555/3618408.3619493,
author = {Ni, Fei and Hao, Jianye and Mu, Yao and Yuan, Yifu and Zheng, Yan and Wang, Bin and Liang, Zhixuan},
title = {MetaDiffuser: diffusion model as conditional planner for offline meta-RL},
year = {2023},
publisher = {JMLR.org},
abstract = {Recently, diffusion model shines as a promising backbone for the sequence modeling paradigm in offline reinforcement learning (RL). However, these works mostly lack the generalization ability across tasks with reward or dynamics change. To tackle this challenge, in this paper we propose a task-oriented conditioned diffusion planner for offline meta-RL (MetaDiffuser), which considers the generalization problem as conditional trajectory generation task with contextual representation. The key is to learn a context conditioned diffusion model which can generate task-oriented trajectories for planning across diverse tasks. To enhance the dynamics consistency of the generated trajectories while encouraging trajectories to achieve high returns, we further design a dual-guided module in the sampling process of the diffusion model. The proposed framework enjoys the robustness to the quality of collected warm-start data from the testing task and the flexibility to incorporate with different task representation method. The experiment results on MuJoCo benchmarks show that MetaDiffuser outperforms other strong offline meta-RL baselines, demonstrating the outstanding conditional generation ability of diffusion architecture. More visualization results are released on project page.},
booktitle = {Proceedings of the 40th International Conference on Machine Learning},
articleno = {1085},
numpages = {19},
location = {Honolulu, Hawaii, USA},
series = {ICML'23}
}

@inproceedings{10.5555/3666122.3667354,
author = {Kollovieh, Marcel and Ansari, Abdul Fatir and Bohlke-Schneider, Michael and Zschiegner, Jasper and Wang, Hao and Wang, Yuyang},
title = {Predict, refine, synthesize: self-guiding diffusion models for probabilistic time series forecasting},
year = {2024},
publisher = {Curran Associates Inc.},
address = {Red Hook, NY, USA},
abstract = {Diffusion models have achieved state-of-the-art performance in generative modeling tasks across various domains. Prior works on time series diffusion models have primarily focused on developing conditional models tailored to specific forecasting or imputation tasks. In this work, we explore the potential of task-agnostic, unconditional diffusion models for several time series applications. We propose TSDiff, an unconditionally-trained diffusion model for time series. Our proposed self-guidance mechanism enables conditioning TSDiff for downstream tasks during inference, without requiring auxiliary networks or altering the training procedure. We demonstrate the effectiveness of our method on three different time series tasks: forecasting, refinement, and synthetic data generation. First, we show that TSDiff is competitive with several task-specific conditional forecasting methods (predict). Second, we leverage the learned implicit probability density of TSDiff to iteratively refine the predictions of base forecasters with reduced computational overhead over reverse diffusion (refine). Notably, the generative performance of the model remains intact — downstream forecasters trained on synthetic samples from TSDiff outperform forecasters that are trained on samples from other state-of-the-art generative time series models, occasionally even outperforming models trained on real data (synthesize).},
booktitle = {Proceedings of the 37th International Conference on Neural Information Processing Systems},
articleno = {1232},
numpages = {24},
location = {New Orleans, LA, USA},
series = {NIPS '23}
}

@article{10120968,
  author={Choi, Geon and Park, Jeonghun and Shlezinger, Nir and Eldar, Yonina C. and Lee, Namyoon},
  journal={IEEE Transactions on Vehicular Technology}, 
  title={Split-KalmanNet: A Robust Model-Based Deep Learning Approach for State Estimation}, 
  year={2023},
  volume={72},
  number={9},
  pages={12326-12331},
  keywords={Kalman filters;Covariance matrices;Computational modeling;State estimation;Jacobian matrices;Gain measurement;Signal processing algorithms;Kalman filter;model-based deep learning;state-space model;sequential state estimation},
  doi={10.1109/TVT.2023.3270353}}

@article{10288023,
  author={Li, Shuo and Mikhaylov, Maxim and Pany, Thomas and Mikhaylov, Nikolay},
  journal={IEEE Transactions on Aerospace and Electronic Systems}, 
  title={Exploring the Potential of the Deep-Learning-Aided Kalman Filter for GNSS/INS Integration: A Study on 2-D Simulation Datasets}, 
  year={2024},
  volume={60},
  number={3},
  pages={2683-2691},
  keywords={Global navigation satellite system;Navigation;Gyroscopes;Accelerometers;Position measurement;Measurement uncertainty;Kalman filters;Deep learning;global navigation satellite system (GNSS);inertial navigation;Kalman filters},
  doi={10.1109/TAES.2023.3325791}}

@article{10320373,
  author={Liang, Chentao and Kuang, Jinsheng and Wu, Fan and Chen, Jienan},
  journal={IEEE Transactions on Cognitive Communications and Networking}, 
  title={Millimetre-Wave Beam Tracking: An Intelligent Machine Learning and Kalman Filter Fusion Technology}, 
  year={2024},
  volume={10},
  number={2},
  pages={487-498},
  keywords={Prediction algorithms;Millimeter wave communication;Robustness;Predictive models;Kalman filters;Estimation;Machine learning;Millimeter-wave;beam tracking;machine learning;Kalman filter;information fusion},
  doi={10.1109/TCCN.2023.3334206}}

@article{10502278,
  author={Bertipaglia, Alberto and Alirezaei, Mohsen and Happee, Riender and Shyrokau, Barys},
  journal={IEEE Transactions on Vehicular Technology}, 
  title={An Unscented Kalman Filter-Informed Neural Network for Vehicle Sideslip Angle Estimation}, 
  year={2024},
  volume={73},
  number={9},
  pages={12731-12746},
  keywords={Estimation;Vehicle dynamics;Kinematics;Convolutional neural networks;Tires;Kalman filters;Sensors;State estimation;sideslip angle;physics-informed neural network;unscented Kalman filter;machine learning},
  doi={10.1109/TVT.2024.3389493}}

@article{10508326,
  author={Yan, Shi and Liang, Yan and Zheng, Le and Fan, Mingyang and Wang, Xiaoxu and Wang, Binglu},
  journal={IEEE Transactions on Signal Processing}, 
  title={Explainable Gated Bayesian Recurrent Neural Network for Non-Markov State Estimation}, 
  year={2024},
  volume={72},
  number={},
  pages={4302-4317},
  keywords={Computational modeling;Logic gates;Bayes methods;Data models;State estimation;Turning;Correlation;State estimation;gated recurrent neural network;Bayesian filtering},
  doi={10.1109/TSP.2024.3390139}}

@article{10566495,
  author={Xu, Liang and Niu, Ruixin},
  journal={IEEE Transactions on Signal Processing}, 
  title={EKFNet: Learning System Noise Covariance Parameters for Nonlinear Tracking}, 
  year={2024},
  volume={72},
  number={},
  pages={3139-3152},
  keywords={Noise;Loss measurement;Noise measurement;Kalman filters;Covariance matrices;Time measurement;Mathematical models;EKF;fine-tuning;recurrent neural network;machine learning;backpropagation through time},
  doi={10.1109/TSP.2024.3417350}}

@article{10632588,
  author={Buchnik, Itay and Sagi, Guy and Leinwand, Nimrod and Loya, Yuval and Shlezinger, Nir and Routtenberg, Tirza},
  journal={IEEE Transactions on Signal Processing}, 
  title={GSP-KalmanNet: Tracking Graph Signals via Neural-Aided Kalman Filtering}, 
  year={2024},
  volume={72},
  number={},
  pages={3700-3716},
  keywords={Complexity theory;Computational modeling;Kalman filters;Frequency-domain analysis;Filtering algorithms;Numerical models;Heuristic algorithms;Graph signal processing (GSP);graph filters;deep learning;Kalman filtering},
  doi={10.1109/TSP.2024.3435935}}

@article{1098671,
  author={Kushner, H.},
  journal={IEEE Transactions on Automatic Control}, 
  title={Approximations to optimal nonlinear filters}, 
  year={1967},
  volume={12},
  number={5},
  pages={546-556},
  keywords={Nonlinear filters;Signal processing;Control system synthesis;Information filtering;Information filters;Industrial electronics;Electrical equipment industry;Electronics industry;Industrial control;Books},
  doi={10.1109/TAC.1967.1098671}}

@article{4982682,
  author={Arasaratnam, Ienkaran and Haykin, Simon},
  journal={IEEE Transactions on Automatic Control}, 
  title={Cubature Kalman Filters}, 
  year={2009},
  volume={54},
  number={6},
  pages={1254-1269},
  keywords={Nonlinear filters;State estimation;Kalman filters;Heart;Bayesian methods;Filtering;Numerical stability;Testing;Statistics;Random variables;Bayesian filters;cubature rules;Gaussian quadrature rules;invariant theory;Kalman filter;nonlinear filtering},
  doi={10.1109/TAC.2009.2019800}}

@article{7079001,
  author={Li, Tiancheng and Bolic, Miodrag and Djuric, Petar M.},
  journal={IEEE Signal Processing Magazine}, 
  title={Resampling Methods for Particle Filtering: Classification, implementation, and strategies}, 
  year={2015},
  volume={32},
  number={3},
  pages={70-86},
  keywords={Approximation methods;Filtering;Atmospheric measurements;Particle measurements;Approximation algorithms;Signal processing algorithms;Systematics},
  doi={10.1109/MSP.2014.2330626}}

@article{8922805,
  author={Wang, Cailu and Tao, Yuegang and Shi, Ling},
  journal={IEEE Transactions on Control of Network Systems}, 
  title={Time Decision for Multi-Input and Multi-Output Networked Control Systems}, 
  year={2020},
  volume={7},
  number={2},
  pages={558-567},
  keywords={Networked control systems;Actuators;Delay effects;Law;Mathematical model;Algorithm;legal send time;linearization;multi-input and multi-output;networked control system;robustness;time decision},
  doi={10.1109/TCNS.2019.2957470}}

@article{9398578,
  author={Vural, N. Mert and Ergüt, Salih and Kozat, Suleyman S.},
  journal={IEEE Transactions on Signal Processing}, 
  title={An Efficient and Effective Second-Order Training Algorithm for LSTM-Based Adaptive Learning}, 
  year={2021},
  volume={69},
  number={},
  pages={2541-2554},
  keywords={Signal processing algorithms;Training;Approximation algorithms;Adaptive systems;Adaptive learning;Adaptation models;Prediction algorithms;Adaptive learning;online learning;truly online;long short term memory (LSTM);Kalman filtering;regression;stochastic gradient descent (SGD) EDICS Category: MLR-SLER;MLR-DEEP},
  doi={10.1109/TSP.2021.3071566}}

@INPROCEEDINGS{9561889,
  author={Wen, Hao and Chen, Xiongjie and Papagiannis, Georgios and Hu, Conghui and Li, Yunpeng},
  booktitle={2021 IEEE International Conference on Robotics and Automation (ICRA)}, 
  title={End-to-End Semi-supervised Learning for Differentiable Particle Filters}, 
  year={2021},
  volume={},
  number={},
  pages={5825-5831},
  keywords={Atmospheric measurements;Neural networks;Semisupervised learning;Particle measurements;Particle filters;History;Task analysis},
  doi={10.1109/ICRA48506.2021.9561889}}

@article{9733186,
  author={Revach, Guy and Shlezinger, Nir and Ni, Xiaoyong and Escoriza, Adrià López and van Sloun, Ruud J. G. and Eldar, Yonina C.},
  journal={IEEE Transactions on Signal Processing}, 
  title={KalmanNet: Neural Network Aided Kalman Filtering for Partially Known Dynamics}, 
  year={2022},
  volume={70},
  number={},
  pages={1532-1547},
  keywords={Kalman filters;Data models;Task analysis;Real-time systems;Numerical models;Heuristic algorithms;Mathematical models;Kalman filters;deep learning;recurrent neural networks},
  doi={10.1109/TSP.2022.3158588}}

@article{DELMORAL1997653,
title = {Nonlinear filtering: Interacting particle resolution},
journal = {Comptes Rendus de l'Académie des Sciences - Series I - Mathematics},
volume = {325},
number = {6},
pages = {653-658},
year = {1997},
issn = {0764-4442},
doi = {https://doi.org/10.1016/S0764-4442(97)84778-7},
url = {https://www.sciencedirect.com/science/article/pii/S0764444297847787},
author = {Pierre {Del Moral}},
abstract = {In this Note, we study interacting particle approximations of discrete time and measure valued dynamical systems. Such systems have arisen in such diverse scientific disciplines as in Propagation of Chaos Theory (see [12] and [19]), and in Nonlinear Filtering Theory. The main contribution of this Note is to prove the convergences to the optimal filter of such approximations, yielding what seemed to be the first mathematically well-founded convergence results for such approximations of the nonlinear filtering equations. This new treatment was influenced primarily by the development of genetic algorithms (see [16] and [3]), and secondarily by the papers of H. Kunita and L. Stettner, [17] and [18] respectively.
Résumé
Cette Note présente une méthode de résolution particulaire de systèmes dynamiques à valeurs mesures, basée sur la simulation de systèmes de particules en interaction. Ces techniques permettent d'aborder l'étude de certaines équations étudiées dans la Théorie de la propagation du chaos (voir [12] et [19]), et tout particulièrement les équations du filtrage non-linéaire. Un des principaux résultats de cette Note concerne la convergence vers le filtre optimal de ces approximations particulaires. Ces résultats constituent, à la connaissance de l'auteur, la première démonstration de convergence de telles approximations des équations du filtrage non-linéaire. Cette nouvelle approche a été influencée par le développement des Algorithmes Génétiques (voir [16] et [3]), et par les articles de H. Kunita et L. Stettner,[17] et [18] respectivement.}
}

@inproceedings{Julier1997NewEO,
  title={New extension of the Kalman filter to nonlinear systems},
  author={Simon J. Julier and Jeffrey K. Uhlmann},
  booktitle={Defense, Security, and Sensing},
  year={1997},
  url={https://api.semanticscholar.org/CorpusID:7937456}
}

@article{Kloss2021,
author={Kloss, Alina
and Martius, Georg
and Bohg, Jeannette},
title={How to train your differentiable filter},
journal={Autonomous Robots},
year={2021},
month={May},
day={01},
volume={45},
number={4},
pages={561-578},
abstract={In many robotic applications, it is crucial to maintain a belief about the state of a system, which serves as input for planning and decision making and provides feedback during task execution. Bayesian Filtering algorithms address this state estimation problem, but they require models of process dynamics and sensory observations and the respective noise characteristics of these models. Recently, multiple works have demonstrated that these models can be learned by end-to-end training through differentiable versions of recursive filtering algorithms. In this work, we investigate the advantages of differentiable filters (DFs) over both unstructured learning approaches and manually-tuned filtering algorithms, and provide practical guidance to researchers interested in applying such differentiable filters. For this, we implement DFs with four different underlying filtering algorithms and compare them in extensive experiments. Specifically, we (i) evaluate different implementation choices and training approaches, (ii) investigate how well complex models of uncertainty can be learned in DFs, (iii) evaluate the effect of end-to-end training through DFs and (iv) compare the DFs among each other and to unstructured LSTM models.},
issn={1573-7527},
doi={10.1007/s10514-021-09990-9},
url={https://doi.org/10.1007/s10514-021-09990-9}
}

@article{YAN2024102580,
title = {Memory-biomimetic deep Bayesian filtering},
journal = {Information Fusion},
volume = {112},
pages = {102580},
year = {2024},
issn = {1566-2535},
doi = {https://doi.org/10.1016/j.inffus.2024.102580},
url = {https://www.sciencedirect.com/science/article/pii/S1566253524003580},
author = {Shi Yan and Yan Liang and Le Zheng and Mingyang Fan and Binglu Wang},
keywords = {Bayesian filtering, Deep learning, Memory-biomimetic},
abstract = {The widely used Bayesian filtering has a solid theoretical foundation and an efficient computational architecture, but it suffers from first-order Markovianity and the inability to learn from offline data. While recent research has utilized deep learning to overcome these limitations, issues remain with respect to theoretical rigor and scalability, resulting in the non-guaranteed optimality of filtering. In this work, we approach these problems from a biomimetic perspective. Firstly, a memory-based state evolution model is constructed inspired by the human cognitive mechanism, which enables recursive filtering while incorporating long-term state information. Secondly, a memory-biomimetic deep Bayesian filtering algorithm with good interpretability is designed, which improves the filtering process at multiple levels by naturally integrating recurrent neural networks and Bayesian filtering architecture. Thirdly, the Gaussian approximation implementation of the proposed filtering method is derived, which brings an efficient computational process with good analytical properties. Extensive experiments for airborne target tracking are performed to demonstrate the excellent estimation performance of the proposed method.}
}

@inproceedings{corenflos2021differentiable,
  title={Differentiable particle filtering via entropy-regularized optimal transport},
  author={Corenflos, Adrien and Thornton, James and Deligiannidis, George and Doucet, Arnaud},
  booktitle={International Conference on Machine Learning},
  pages={2100--2111},
  year={2021},
  organization={PMLR}
}

@article{doi:10.1049/ip-f-2.1993.0015,
author = {N.J. Gordon  and D.J. Salmond  and A.F.M. Smith },
title = {Novel approach to nonlinear/non-Gaussian Bayesian state estimation},
journal = {IEE Proceedings F (Radar and Signal Processing)},
volume = {140},
issue = {2},
pages = {107-113},
year = {1993},
doi = {10.1049/ip-f-2.1993.0015},

URL = {https://digital-library.theiet.org/doi/abs/10.1049/ip-f-2.1993.0015},
eprint = {https://digital-library.theiet.org/doi/pdf/10.1049/ip-f-2.1993.0015}
,
    abstract = { An algorithm, the bootstrap filter, is proposed for implementing recursive Bayesian filters. The required density of the state vector is represented as a set of random samples, which are updated and propagated by the algorithm. The method is not restricted by assumptions of linearity or Gaussian noise: it may be applied to any state transition or measurement model. A simulation example of the bearings only tracking problem is presented. This simulation includes schemes for improving the efficiency of the basic algorithm. For this example, the performance of the bootstrap filter is greatly superior to the standard extended Kalman filter. }
}

@article{ho2022video,
  title={Video diffusion models},
  author={Ho, Jonathan and Salimans, Tim and Gritsenko, Alexey and Chan, William and Norouzi, Mohammad and Fleet, David J},
  journal={Advances in Neural Information Processing Systems},
  volume={35},
  pages={8633--8646},
  year={2022}
}

@article{jonschkowski2018differentiable,
  title={Differentiable particle filters: End-to-end learning with algorithmic priors},
  author={Jonschkowski, Rico and Rastogi, Divyam and Brock, Oliver},
  journal={arXiv preprint arXiv:1805.11122},
  year={2018}
}

@inproceedings{ma2020particle,
  title={Particle filter recurrent neural networks},
  author={Ma, Xiao and Karkus, Peter and Hsu, David and Lee, Wee Sun},
  booktitle={Proceedings of the AAAI conference on artificial intelligence},
  volume={34},
  number={04},
  pages={5101--5108},
  year={2020}
}

@inproceedings{xu2023versatile,
  title={Versatile diffusion: Text, images and variations all in one diffusion model},
  author={Xu, Xingqian and Wang, Zhangyang and Zhang, Gong and Wang, Kai and Shi, Humphrey},
  booktitle={Proceedings of the IEEE/CVF International Conference on Computer Vision},
  pages={7754--7765},
  year={2023}
}

@inproceedings{zaheer2017latent,
  title={Latent LSTM allocation: Joint clustering and non-linear dynamic modeling of sequence data},
  author={Zaheer, Manzil and Ahmed, Amr and Smola, Alexander J},
  booktitle={International Conference on Machine Learning},
  pages={3967--3976},
  year={2017},
  organization={PMLR}
}

