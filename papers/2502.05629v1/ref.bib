@article{1228524,
  author={Fox, V. and Hightower, J. and Lin Liao and Schulz, D. and Borriello, G.},
  journal={IEEE Pervasive Computing}, 
  title={Bayesian filtering for location estimation}, 
  year={2003},
  volume={2},
  number={3},
  pages={24-33},
  keywords={Bayesian methods;Filtering;Filters;Pervasive computing;Infrared sensors;Sensor systems and applications;State estimation;Time measurement;Cameras;Sensor systems},
  doi={10.1109/MPRV.2003.1228524}
}

@inproceedings{
venkatraman2024reasoning,
title={Reasoning with Latent Diffusion in Offline Reinforcement Learning},
author={Siddarth Venkatraman and Shivesh Khaitan and Ravi Tej Akella and John Dolan and Jeff Schneider and Glen Berseth},
booktitle={The Twelfth International Conference on Learning Representations},
year={2024},
url={https://openreview.net/forum?id=tGQirjzddO}
}

@misc{jun2023shapegeneratingconditional3d,
      title={Shap-E: Generating Conditional 3D Implicit Functions}, 
      author={Heewoo Jun and Alex Nichol},
      year={2023},
      eprint={2305.02463},
      archivePrefix={arXiv},
      primaryClass={cs.CV},
      url={https://arxiv.org/abs/2305.02463}, 
}

@inproceedings{10.5555/3495724.3496298,
author = {Ho, Jonathan and Jain, Ajay and Abbeel, Pieter},
title = {Denoising diffusion probabilistic models},
year = {2020},
isbn = {9781713829546},
publisher = {Curran Associates Inc.},
address = {Red Hook, NY, USA},
abstract = {We present high quality image synthesis results using diffusion probabilistic models, a class of latent variable models inspired by considerations from nonequilibrium thermodynamics. Our best results are obtained by training on a weighted variational bound designed according to a novel connection between diffusion probabilistic models and denoising score matching with Langevin dynamics, and our models naturally admit a progressive lossy decompression scheme that can be interpreted as a generalization of autoregressive decoding. On the unconditional CIFAR10 dataset, we obtain an Inception score of 9.46 and a state-of-the-art FID score of 3.17. On 256x256 LSUN, we obtain sample quality similar to ProgressiveGAN.},
booktitle = {Proceedings of the 34th International Conference on Neural Information Processing Systems},
articleno = {574},
numpages = {12},
location = {Vancouver, BC, Canada},
series = {NIPS '20}
}

@inproceedings{10.5555/3618408.3619493,
author = {Ni, Fei and Hao, Jianye and Mu, Yao and Yuan, Yifu and Zheng, Yan and Wang, Bin and Liang, Zhixuan},
title = {MetaDiffuser: diffusion model as conditional planner for offline meta-RL},
year = {2023},
publisher = {JMLR.org},
abstract = {Recently, diffusion model shines as a promising backbone for the sequence modeling paradigm in offline reinforcement learning (RL). However, these works mostly lack the generalization ability across tasks with reward or dynamics change. To tackle this challenge, in this paper we propose a task-oriented conditioned diffusion planner for offline meta-RL (MetaDiffuser), which considers the generalization problem as conditional trajectory generation task with contextual representation. The key is to learn a context conditioned diffusion model which can generate task-oriented trajectories for planning across diverse tasks. To enhance the dynamics consistency of the generated trajectories while encouraging trajectories to achieve high returns, we further design a dual-guided module in the sampling process of the diffusion model. The proposed framework enjoys the robustness to the quality of collected warm-start data from the testing task and the flexibility to incorporate with different task representation method. The experiment results on MuJoCo benchmarks show that MetaDiffuser outperforms other strong offline meta-RL baselines, demonstrating the outstanding conditional generation ability of diffusion architecture. More visualization results are released on project page.},
booktitle = {Proceedings of the 40th International Conference on Machine Learning},
articleno = {1085},
numpages = {19},
location = {Honolulu, Hawaii, USA},
series = {ICML'23}
}

@Inbook{Lorenz2004,
author="Lorenz, Edward N.",
editor="Hunt, Brian R.
and Li, Tien-Yien
and Kennedy, Judy A.
and Nusse, Helena E.",
title="Deterministic Nonperiodic Flow",
bookTitle="The Theory of Chaotic Attractors",
year="2004",
publisher="Springer New York",
address="New York, NY",
pages="25--36",
abstract="Finite systems of deterministic ordinary nonlinear differential equations may be designed to represent forced dissipative hydrodynamic flow. Solutions of these equations can be identified with trajectories in phase space For those systems with bounded solutions, it is found that nonperiodic solutions are ordinarily unstable with respect to small modifications, so that slightly differing initial states can evolve into consider­ably different states. Systems with bounded solutions are shown to possess bounded numerical solutions.",
isbn="978-0-387-21830-4",
doi="10.1007/978-0-387-21830-4_2",
url="https://doi.org/10.1007/978-0-387-21830-4_2"
}

@book{bar2004estimation,
  title={Estimation with applications to tracking and navigation: theory algorithms and software},
  author={Bar-Shalom, Yaakov and Li, X Rong and Kirubarajan, Thiagalingam},
  year={2004},
  publisher={John Wiley \& Sons}
}

@article{10.1177/0278364915614638, author = {Carlevaris-Bianco, N. and Ushani, A. K. and Eustice, R. M.}, title = {University of michigan north campus long-term vision and lidar dataset}, journal = {The International Journal of Robotics Research}, year = {2015}, volume = {35}, issue = {9}, pages = {1023-1035}, doi = {10.1177/0278364915614638} }

@inproceedings{
gilpin2021chaos,
title={Chaos as an interpretable benchmark for forecasting and data-driven modelling},
author={William Gilpin},
booktitle={Thirty-fifth Conference on Neural Information Processing Systems Datasets and Benchmarks Track (Round 2)},
year={2021},
url={https://openreview.net/forum?id=enYjtbjYJrf}
}

@inproceedings{
anonymous2024physicsinformed,
title={Physics-Informed Diffusion Models},
author={Anonymous},
booktitle={Submitted to The Thirteenth International Conference on Learning Representations},
year={2024},
url={https://openreview.net/forum?id=tpYeermigp},
note={under review}
}

@inproceedings{xu2023versatile,
  title={Versatile diffusion: Text, images and variations all in one diffusion model},
  author={Xu, Xingqian and Wang, Zhangyang and Zhang, Gong and Wang, Kai and Shi, Humphrey},
  booktitle={Proceedings of the IEEE/CVF International Conference on Computer Vision},
  pages={7754--7765},
  year={2023}
}

@article{ho2022video,
  title={Video diffusion models},
  author={Ho, Jonathan and Salimans, Tim and Gritsenko, Alexey and Chan, William and Norouzi, Mohammad and Fleet, David J},
  journal={Advances in Neural Information Processing Systems},
  volume={35},
  pages={8633--8646},
  year={2022}
}

@inproceedings{
ajay2023is,
title={Is Conditional Generative Modeling all you need for Decision Making?},
author={Anurag Ajay and Yilun Du and Abhi Gupta and Joshua B. Tenenbaum and Tommi S. Jaakkola and Pulkit Agrawal},
booktitle={The Eleventh International Conference on Learning Representations },
year={2023},
url={https://openreview.net/forum?id=sP1fo2K9DFG}
}

@article{9689974,
  author={Barrau, Axel and Bonnabel, Silvère},
  journal={IEEE Transactions on Automatic Control}, 
  title={The Geometry of Navigation Problems}, 
  year={2023},
  volume={68},
  number={2},
  pages={689-704},
  keywords={Observers;Simultaneous localization and mapping;Kalman filters;Vehicle dynamics;Inertial navigation;Convergence;Manipulators;Aircraft navigation;autonomous vehicles;geometry;Kalman filters;nonlinear filters;observers;state estimation},
  doi={10.1109/TAC.2022.3144328}}

@article{8961145,
  author={Sun, Shuli},
  journal={IEEE Transactions on Signal Processing}, 
  title={Distributed Optimal Linear Fusion Predictors and Filters for Systems With Random Parameter Matrices and Correlated Noises}, 
  year={2020},
  volume={68},
  number={},
  pages={1064-1074},
  keywords={Sensor fusion;Noise measurement;Estimation;Maximum likelihood detection;Stability analysis;Prediction algorithms;Distributed fusion predictor;distributed fusion filter;multisensor;random parameter matrix;correlated noise},
  doi={10.1109/TSP.2020.2967180}}

@article{Kaufmann2023,
author={Kaufmann, Elia
and Bauersfeld, Leonard
and Loquercio, Antonio
and M{\"u}ller, Matthias
and Koltun, Vladlen
and Scaramuzza, Davide},
title={Champion-level drone racing using deep reinforcement learning},
journal={Nature},
year={2023},
month={Aug},
day={01},
volume={620},
number={7976},
pages={982-987},
abstract={First-person view (FPV) drone racing is a televised sport in which professional competitors pilot high-speed aircraft through a 3D circuit. Each pilot sees the environment from the perspective of their drone by means of video streamed from an onboard camera. Reaching the level of professional pilots with an autonomous drone is challenging because the robot needs to fly at its physical limits while estimating its speed and location in the circuit exclusively from onboard sensors1. Here we introduce Swift, an autonomous system that can race physical vehicles at the level of the human world champions. The system combines deep reinforcement learning (RL) in simulation with data collected in the physical world. Swift competed against three human champions, including the world champions of two international leagues, in real-world head-to-head races. Swift won several races against each of the human champions and demonstrated the fastest recorded race time. This work represents a milestone for mobile robotics and machine intelligence2, which may inspire the deployment of hybrid learning-based solutions in other physical systems.},
issn={1476-4687},
doi={10.1038/s41586-023-06419-4},
url={https://doi.org/10.1038/s41586-023-06419-4}
}

@article{de2020normalizing,
  title={Normalizing kalman filters for multivariate time series analysis},
  author={de B{\'e}zenac, Emmanuel and Rangapuram, Syama Sundar and Benidis, Konstantinos and Bohlke-Schneider, Michael and Kurle, Richard and Stella, Lorenzo and Hasson, Hilaf and Gallinari, Patrick and Januschowski, Tim},
  journal={Advances in Neural Information Processing Systems},
  volume={33},
  pages={2995--3007},
  year={2020}
}

@incollection{athans1974importance,
  title={The importance of Kalman filtering methods for economic systems},
  author={Athans, Michael},
  booktitle={Annals of Economic and Social Measurement, Volume 3, number 1},
  pages={49--64},
  year={1974},
  publisher={NBER}
}

@inproceedings{10.5555/3666122.3667354,
author = {Kollovieh, Marcel and Ansari, Abdul Fatir and Bohlke-Schneider, Michael and Zschiegner, Jasper and Wang, Hao and Wang, Yuyang},
title = {Predict, refine, synthesize: self-guiding diffusion models for probabilistic time series forecasting},
year = {2024},
publisher = {Curran Associates Inc.},
address = {Red Hook, NY, USA},
abstract = {Diffusion models have achieved state-of-the-art performance in generative modeling tasks across various domains. Prior works on time series diffusion models have primarily focused on developing conditional models tailored to specific forecasting or imputation tasks. In this work, we explore the potential of task-agnostic, unconditional diffusion models for several time series applications. We propose TSDiff, an unconditionally-trained diffusion model for time series. Our proposed self-guidance mechanism enables conditioning TSDiff for downstream tasks during inference, without requiring auxiliary networks or altering the training procedure. We demonstrate the effectiveness of our method on three different time series tasks: forecasting, refinement, and synthetic data generation. First, we show that TSDiff is competitive with several task-specific conditional forecasting methods (predict). Second, we leverage the learned implicit probability density of TSDiff to iteratively refine the predictions of base forecasters with reduced computational overhead over reverse diffusion (refine). Notably, the generative performance of the model remains intact — downstream forecasters trained on synthetic samples from TSDiff outperform forecasters that are trained on samples from other state-of-the-art generative time series models, occasionally even outperforming models trained on real data (synthesize).},
booktitle = {Proceedings of the 37th International Conference on Neural Information Processing Systems},
articleno = {1232},
numpages = {24},
location = {New Orleans, LA, USA},
series = {NIPS '23}
}

@inproceedings{
fan2024mgtsd,
title={{MG}-{TSD}: Multi-Granularity Time Series Diffusion Models with Guided Learning Process},
author={Xinyao Fan and Yueying Wu and Chang Xu and Yuhao Huang and Weiqing Liu and Jiang Bian},
booktitle={The Twelfth International Conference on Learning Representations},
year={2024},
url={https://openreview.net/forum?id=CZiY6OLktd}
}

@article{10566495,
  author={Xu, Liang and Niu, Ruixin},
  journal={IEEE Transactions on Signal Processing}, 
  title={EKFNet: Learning System Noise Covariance Parameters for Nonlinear Tracking}, 
  year={2024},
  volume={72},
  number={},
  pages={3139-3152},
  keywords={Noise;Loss measurement;Noise measurement;Kalman filters;Covariance matrices;Time measurement;Mathematical models;EKF;fine-tuning;recurrent neural network;machine learning;backpropagation through time},
  doi={10.1109/TSP.2024.3417350}}

@article{9733186,
  author={Revach, Guy and Shlezinger, Nir and Ni, Xiaoyong and Escoriza, Adrià López and van Sloun, Ruud J. G. and Eldar, Yonina C.},
  journal={IEEE Transactions on Signal Processing}, 
  title={KalmanNet: Neural Network Aided Kalman Filtering for Partially Known Dynamics}, 
  year={2022},
  volume={70},
  number={},
  pages={1532-1547},
  keywords={Kalman filters;Data models;Task analysis;Real-time systems;Numerical models;Heuristic algorithms;Mathematical models;Kalman filters;deep learning;recurrent neural networks},
  doi={10.1109/TSP.2022.3158588}}

@article{Khodarahmi2023,
author={Khodarahmi, Masoud
and Maihami, Vafa},
title={A Review on Kalman Filter Models},
journal={Archives of Computational Methods in Engineering},
year={2023},
month={Jan},
day={01},
volume={30},
number={1},
pages={727-747},
abstract={Kalman Filter (KF) that is also known as linear quadratic estimation filter estimates current states of a system through time as recursive using input measurements in mathematical process model. Thus algorithm is implemented in two steps: in the prediction step an estimation of current state of variables in uncertainty conditions is presented. In the next step, after obtaining the measurement, previous estimation is updated by weighted arithmetic mean. Accordingly, using KF in non-linear systems can be difficult. For nonlinear systems Extended KF (EKF) and Unscented KF (UKF) represent the first-order and higher order linear approximations. KF cannot predict appropriate values for modeling system behavior in more complicated systems. In the current study, in addition to referring to basic methods, a review on recent researches on Multiple Model (MM) filters has been done. More reliable estimations obtain by using two or more filters with different models in parallel, by allocating an estimation to each filter, outputs of each filter are calculated. MM Adaptive Estimation (MMAE) and Interacting MM (IMM) are the most used methods for estimating MMs.},
issn={1886-1784},
doi={10.1007/s11831-022-09815-7},
url={https://doi.org/10.1007/s11831-022-09815-7}
}

@article{10508326,
  author={Yan, Shi and Liang, Yan and Zheng, Le and Fan, Mingyang and Wang, Xiaoxu and Wang, Binglu},
  journal={IEEE Transactions on Signal Processing}, 
  title={Explainable Gated Bayesian Recurrent Neural Network for Non-Markov State Estimation}, 
  year={2024},
  volume={72},
  number={},
  pages={4302-4317},
  keywords={Computational modeling;Logic gates;Bayes methods;Data models;State estimation;Turning;Correlation;State estimation;gated recurrent neural network;Bayesian filtering},
  doi={10.1109/TSP.2024.3390139}}

@article{6795963,
  author={Hochreiter, Sepp and Schmidhuber, Jürgen},
  journal={Neural Computation}, 
  title={Long Short-Term Memory}, 
  year={1997},
  volume={9},
  number={8},
  pages={1735-1780},
  keywords={},
  doi={10.1162/neco.1997.9.8.1735}}

@inproceedings{69e088c8129341ac89810907fe6b1bfe,
title = "Empirical evaluation of gated recurrent neural networks on sequence modeling",
author = "Junyoung Chung and Caglar Gulcehre and Kyunghyun Cho and Yoshua Bengio",
year = "2014",
language = "English (US)",
booktitle = "NIPS 2014 Workshop on Deep Learning, December 2014",
}

@article{9146931,
  author={Lin, Changjian and Wang, Hongjian and Fu, Mingyu and Yuan, Jianya and Gu, Jason},
  journal={IEEE Transactions on Instrumentation and Measurement}, 
  title={A Gated Recurrent Unit-Based Particle Filter for Unmanned Underwater Vehicle State Estimation}, 
  year={2021},
  volume={70},
  number={},
  pages={1-12},
  keywords={State estimation;Particle filters;Unmanned underwater vehicles;Target tracking;Vehicle dynamics;Logic gates;Atmospheric measurements;Deep neural networks;gated recurrent units (GRUs);particle filter (PF);target state estimation;unmanned underwater vehicle (UUV)},
  doi={10.1109/TIM.2020.3011789}}

@article{9761897,
  author={Lin, Changjian and Cheng, Yuhu and Wang, Xuesong},
  journal={IEEE Transactions on Instrumentation and Measurement}, 
  title={A Convolutional Neural Network Particle Filter for UUV Target State Estimation}, 
  year={2022},
  volume={71},
  number={},
  pages={1-12},
  keywords={State estimation;Computational modeling;Load modeling;Particle measurements;Estimation;Convolutional neural networks;Atmospheric measurements;Convolutional neural network (CNN);non-Gaussian noise;nonlinear measurement;underwater target state estimation;unmanned underwater vehicle (UUV)},
  doi={10.1109/TIM.2022.3169539}}

@article{9110734,
  author={Jung, Steffen and Schlangen, Isabel and Charlish, Alexander},
  journal={IEEE Signal Processing Letters}, 
  title={A Mnemonic Kalman Filter for Non-Linear Systems With Extensive Temporal Dependencies}, 
  year={2020},
  volume={27},
  number={},
  pages={1005-1009},
  keywords={Kalman filters;Vehicle dynamics;Markov processes;Standards;Neural networks;Dynamics;Mathematical model;Dynamic models;single target tracking;long short-term memory;recurrent neural network;Kalman filter},
  doi={10.1109/LSP.2020.3000679}}

@inproceedings{10.5555/3294996.3295118,
author = {Fraccaro, Marco and Kamronn, Simon and Paquet, Ulrich and Winther, Ole},
title = {A disentangled recognition and nonlinear dynamics model for unsupervised learning},
year = {2017},
isbn = {9781510860964},
publisher = {Curran Associates Inc.},
address = {Red Hook, NY, USA},
abstract = {This paper takes a step towards temporal reasoning in a dynamically changing video, not in the pixel space that constitutes its frames, but in a latent space that describes the non-linear dynamics of the objects in its world. We introduce the Kalman variational auto-encoder, a framework for unsupervised learning of sequential data that disentangles two latent representations: an object's representation, coming from a recognition model, and a latent state describing its dynamics. As a result, the evolution of the world can be imagined and missing data imputed, both without the need to generate high dimensional frames at each time step. The model is trained end-to-end on videos of a variety of simulated physical systems, and outperforms competing methods in generative and missing data imputation tasks.},
booktitle = {Proceedings of the 31st International Conference on Neural Information Processing Systems},
pages = {3604–3613},
numpages = {10},
location = {Long Beach, California, USA},
series = {NIPS'17}
}


@InProceedings{pmlr-v97-becker19a,
  title = 	 {Recurrent Kalman Networks: Factorized Inference in High-Dimensional Deep Feature Spaces},
  author =       {Becker, Philipp and Pandya, Harit and Gebhardt, Gregor and Zhao, Cheng and Taylor, C. James and Neumann, Gerhard},
  booktitle = 	 {Proceedings of the 36th International Conference on Machine Learning},
  pages = 	 {544--552},
  year = 	 {2019},
  editor = 	 {Chaudhuri, Kamalika and Salakhutdinov, Ruslan},
  volume = 	 {97},
  series = 	 {Proceedings of Machine Learning Research},
  month = 	 {09--15 Jun},
  publisher =    {PMLR},
  pdf = 	 {http://proceedings.mlr.press/v97/becker19a/becker19a.pdf},
  url = 	 {https://proceedings.mlr.press/v97/becker19a.html},
  abstract = 	 {In order to integrate uncertainty estimates into deep time-series modelling, Kalman Filters (KFs) (Kalman et al., 1960) have been integrated with deep learning models, however, such approaches typically rely on approximate inference tech- niques such as variational inference which makes learning more complex and often less scalable due to approximation errors. We propose a new deep approach to Kalman filtering which can be learned directly in an end-to-end manner using backpropagation without additional approximations. Our approach uses a high-dimensional factorized latent state representation for which the Kalman updates simplify to scalar operations and thus avoids hard to backpropagate, computationally heavy and potentially unstable matrix inversions. Moreover, we use locally linear dynamic models to efficiently propagate the latent state to the next time step. The resulting network architecture, which we call Recurrent Kalman Network (RKN), can be used for any time-series data, similar to a LSTM (Hochreiter &amp; Schmidhuber, 1997) but uses an explicit representation of uncertainty. As shown by our experiments, the RKN obtains much more accurate uncertainty estimates than an LSTM or Gated Recurrent Units (GRUs) (Cho et al., 2014) while also showing a slightly improved prediction performance and outperforms various recent generative models on an image imputation task.}
}

@article{10288023,
  author={Li, Shuo and Mikhaylov, Maxim and Pany, Thomas and Mikhaylov, Nikolay},
  journal={IEEE Transactions on Aerospace and Electronic Systems}, 
  title={Exploring the Potential of the Deep-Learning-Aided Kalman Filter for GNSS/INS Integration: A Study on 2-D Simulation Datasets}, 
  year={2024},
  volume={60},
  number={3},
  pages={2683-2691},
  keywords={Global navigation satellite system;Navigation;Gyroscopes;Accelerometers;Position measurement;Measurement uncertainty;Kalman filters;Deep learning;global navigation satellite system (GNSS);inertial navigation;Kalman filters},
  doi={10.1109/TAES.2023.3325791}}

@article{10120968,
  author={Choi, Geon and Park, Jeonghun and Shlezinger, Nir and Eldar, Yonina C. and Lee, Namyoon},
  journal={IEEE Transactions on Vehicular Technology}, 
  title={Split-KalmanNet: A Robust Model-Based Deep Learning Approach for State Estimation}, 
  year={2023},
  volume={72},
  number={9},
  pages={12326-12331},
  keywords={Kalman filters;Covariance matrices;Computational modeling;State estimation;Jacobian matrices;Gain measurement;Signal processing algorithms;Kalman filter;model-based deep learning;state-space model;sequential state estimation},
  doi={10.1109/TVT.2023.3270353}}

@article{10632588,
  author={Buchnik, Itay and Sagi, Guy and Leinwand, Nimrod and Loya, Yuval and Shlezinger, Nir and Routtenberg, Tirza},
  journal={IEEE Transactions on Signal Processing}, 
  title={GSP-KalmanNet: Tracking Graph Signals via Neural-Aided Kalman Filtering}, 
  year={2024},
  volume={72},
  number={},
  pages={3700-3716},
  keywords={Complexity theory;Computational modeling;Kalman filters;Frequency-domain analysis;Filtering algorithms;Numerical models;Heuristic algorithms;Graph signal processing (GSP);graph filters;deep learning;Kalman filtering},
  doi={10.1109/TSP.2024.3435935}}

@article{10502278,
  author={Bertipaglia, Alberto and Alirezaei, Mohsen and Happee, Riender and Shyrokau, Barys},
  journal={IEEE Transactions on Vehicular Technology}, 
  title={An Unscented Kalman Filter-Informed Neural Network for Vehicle Sideslip Angle Estimation}, 
  year={2024},
  volume={73},
  number={9},
  pages={12731-12746},
  keywords={Estimation;Vehicle dynamics;Kinematics;Convolutional neural networks;Tires;Kalman filters;Sensors;State estimation;sideslip angle;physics-informed neural network;unscented Kalman filter;machine learning},
  doi={10.1109/TVT.2024.3389493}}


@inproceedings{zaheer2017latent,
  title={Latent LSTM allocation: Joint clustering and non-linear dynamic modeling of sequence data},
  author={Zaheer, Manzil and Ahmed, Amr and Smola, Alexander J},
  booktitle={International Conference on Machine Learning},
  pages={3967--3976},
  year={2017},
  organization={PMLR}
}

@article{4982682,
  author={Arasaratnam, Ienkaran and Haykin, Simon},
  journal={IEEE Transactions on Automatic Control}, 
  title={Cubature Kalman Filters}, 
  year={2009},
  volume={54},
  number={6},
  pages={1254-1269},
  keywords={Nonlinear filters;State estimation;Kalman filters;Heart;Bayesian methods;Filtering;Numerical stability;Testing;Statistics;Random variables;Bayesian filters;cubature rules;Gaussian quadrature rules;invariant theory;Kalman filter;nonlinear filtering},
  doi={10.1109/TAC.2009.2019800}}

@article{1098671,
  author={Kushner, H.},
  journal={IEEE Transactions on Automatic Control}, 
  title={Approximations to optimal nonlinear filters}, 
  year={1967},
  volume={12},
  number={5},
  pages={546-556},
  keywords={Nonlinear filters;Signal processing;Control system synthesis;Information filtering;Information filters;Industrial electronics;Electrical equipment industry;Electronics industry;Industrial control;Books},
  doi={10.1109/TAC.1967.1098671}}

@inproceedings{Julier1997NewEO,
  title={New extension of the Kalman filter to nonlinear systems},
  author={Simon J. Julier and Jeffrey K. Uhlmann},
  booktitle={Defense, Security, and Sensing},
  year={1997},
  url={https://api.semanticscholar.org/CorpusID:7937456}
}

@article{doi:10.1049/ip-f-2.1993.0015,
author = {N.J. Gordon  and D.J. Salmond  and A.F.M. Smith },
title = {Novel approach to nonlinear/non-Gaussian Bayesian state estimation},
journal = {IEE Proceedings F (Radar and Signal Processing)},
volume = {140},
issue = {2},
pages = {107-113},
year = {1993},
doi = {10.1049/ip-f-2.1993.0015},

URL = {https://digital-library.theiet.org/doi/abs/10.1049/ip-f-2.1993.0015},
eprint = {https://digital-library.theiet.org/doi/pdf/10.1049/ip-f-2.1993.0015}
,
    abstract = { An algorithm, the bootstrap filter, is proposed for implementing recursive Bayesian filters. The required density of the state vector is represented as a set of random samples, which are updated and propagated by the algorithm. The method is not restricted by assumptions of linearity or Gaussian noise: it may be applied to any state transition or measurement model. A simulation example of the bearings only tracking problem is presented. This simulation includes schemes for improving the efficiency of the basic algorithm. For this example, the performance of the bootstrap filter is greatly superior to the standard extended Kalman filter. }
}

@article{6400245,
  author={Auger, François and Hilairet, Mickael and Guerrero, Josep M. and Monmasson, Eric and Orlowska-Kowalska, Teresa and Katsura, Seiichiro},
  journal={IEEE Transactions on Industrial Electronics}, 
  title={Industrial Applications of the Kalman Filter: A Review}, 
  year={2013},
  volume={60},
  number={12},
  pages={5458-5471},
  keywords={Estimation;Rotors;Kalman filters;Covariance matrix;Stators;Mathematical model;Equations;Implementation issues;industrial applications;Kalman filter (KF);state estimation},
  doi={10.1109/TIE.2012.2236994}}


@article{DELMORAL1997653,
title = {Nonlinear filtering: Interacting particle resolution},
journal = {Comptes Rendus de l'Académie des Sciences - Series I - Mathematics},
volume = {325},
number = {6},
pages = {653-658},
year = {1997},
issn = {0764-4442},
doi = {https://doi.org/10.1016/S0764-4442(97)84778-7},
url = {https://www.sciencedirect.com/science/article/pii/S0764444297847787},
author = {Pierre {Del Moral}},
abstract = {In this Note, we study interacting particle approximations of discrete time and measure valued dynamical systems. Such systems have arisen in such diverse scientific disciplines as in Propagation of Chaos Theory (see [12] and [19]), and in Nonlinear Filtering Theory. The main contribution of this Note is to prove the convergences to the optimal filter of such approximations, yielding what seemed to be the first mathematically well-founded convergence results for such approximations of the nonlinear filtering equations. This new treatment was influenced primarily by the development of genetic algorithms (see [16] and [3]), and secondarily by the papers of H. Kunita and L. Stettner, [17] and [18] respectively.
Résumé
Cette Note présente une méthode de résolution particulaire de systèmes dynamiques à valeurs mesures, basée sur la simulation de systèmes de particules en interaction. Ces techniques permettent d'aborder l'étude de certaines équations étudiées dans la Théorie de la propagation du chaos (voir [12] et [19]), et tout particulièrement les équations du filtrage non-linéaire. Un des principaux résultats de cette Note concerne la convergence vers le filtre optimal de ces approximations particulaires. Ces résultats constituent, à la connaissance de l'auteur, la première démonstration de convergence de telles approximations des équations du filtrage non-linéaire. Cette nouvelle approche a été influencée par le développement des Algorithmes Génétiques (voir [16] et [3]), et par les articles de H. Kunita et L. Stettner,[17] et [18] respectivement.}
}

@article{7079001,
  author={Li, Tiancheng and Bolic, Miodrag and Djuric, Petar M.},
  journal={IEEE Signal Processing Magazine}, 
  title={Resampling Methods for Particle Filtering: Classification, implementation, and strategies}, 
  year={2015},
  volume={32},
  number={3},
  pages={70-86},
  keywords={Approximation methods;Filtering;Atmospheric measurements;Particle measurements;Approximation algorithms;Signal processing algorithms;Systematics},
  doi={10.1109/MSP.2014.2330626}}

@article{8922805,
  author={Wang, Cailu and Tao, Yuegang and Shi, Ling},
  journal={IEEE Transactions on Control of Network Systems}, 
  title={Time Decision for Multi-Input and Multi-Output Networked Control Systems}, 
  year={2020},
  volume={7},
  number={2},
  pages={558-567},
  keywords={Networked control systems;Actuators;Delay effects;Law;Mathematical model;Algorithm;legal send time;linearization;multi-input and multi-output;networked control system;robustness;time decision},
  doi={10.1109/TCNS.2019.2957470}}

@article{YAN2024102580,
title = {Memory-biomimetic deep Bayesian filtering},
journal = {Information Fusion},
volume = {112},
pages = {102580},
year = {2024},
issn = {1566-2535},
doi = {https://doi.org/10.1016/j.inffus.2024.102580},
url = {https://www.sciencedirect.com/science/article/pii/S1566253524003580},
author = {Shi Yan and Yan Liang and Le Zheng and Mingyang Fan and Binglu Wang},
keywords = {Bayesian filtering, Deep learning, Memory-biomimetic},
abstract = {The widely used Bayesian filtering has a solid theoretical foundation and an efficient computational architecture, but it suffers from first-order Markovianity and the inability to learn from offline data. While recent research has utilized deep learning to overcome these limitations, issues remain with respect to theoretical rigor and scalability, resulting in the non-guaranteed optimality of filtering. In this work, we approach these problems from a biomimetic perspective. Firstly, a memory-based state evolution model is constructed inspired by the human cognitive mechanism, which enables recursive filtering while incorporating long-term state information. Secondly, a memory-biomimetic deep Bayesian filtering algorithm with good interpretability is designed, which improves the filtering process at multiple levels by naturally integrating recurrent neural networks and Bayesian filtering architecture. Thirdly, the Gaussian approximation implementation of the proposed filtering method is derived, which brings an efficient computational process with good analytical properties. Extensive experiments for airborne target tracking are performed to demonstrate the excellent estimation performance of the proposed method.}
}

@article{9398578,
  author={Vural, N. Mert and Ergüt, Salih and Kozat, Suleyman S.},
  journal={IEEE Transactions on Signal Processing}, 
  title={An Efficient and Effective Second-Order Training Algorithm for LSTM-Based Adaptive Learning}, 
  year={2021},
  volume={69},
  number={},
  pages={2541-2554},
  keywords={Signal processing algorithms;Training;Approximation algorithms;Adaptive systems;Adaptive learning;Adaptation models;Prediction algorithms;Adaptive learning;online learning;truly online;long short term memory (LSTM);Kalman filtering;regression;stochastic gradient descent (SGD) EDICS Category: MLR-SLER;MLR-DEEP},
  doi={10.1109/TSP.2021.3071566}}


@article{10320373,
  author={Liang, Chentao and Kuang, Jinsheng and Wu, Fan and Chen, Jienan},
  journal={IEEE Transactions on Cognitive Communications and Networking}, 
  title={Millimetre-Wave Beam Tracking: An Intelligent Machine Learning and Kalman Filter Fusion Technology}, 
  year={2024},
  volume={10},
  number={2},
  pages={487-498},
  keywords={Prediction algorithms;Millimeter wave communication;Robustness;Predictive models;Kalman filters;Estimation;Machine learning;Millimeter-wave;beam tracking;machine learning;Kalman filter;information fusion},
  doi={10.1109/TCCN.2023.3334206}}

@inproceedings{ma2020particle,
  title={Particle filter recurrent neural networks},
  author={Ma, Xiao and Karkus, Peter and Hsu, David and Lee, Wee Sun},
  booktitle={Proceedings of the AAAI conference on artificial intelligence},
  volume={34},
  number={04},
  pages={5101--5108},
  year={2020}
}

@inproceedings{corenflos2021differentiable,
  title={Differentiable particle filtering via entropy-regularized optimal transport},
  author={Corenflos, Adrien and Thornton, James and Deligiannidis, George and Doucet, Arnaud},
  booktitle={International Conference on Machine Learning},
  pages={2100--2111},
  year={2021},
  organization={PMLR}
}

@INPROCEEDINGS{9561889,
  author={Wen, Hao and Chen, Xiongjie and Papagiannis, Georgios and Hu, Conghui and Li, Yunpeng},
  booktitle={2021 IEEE International Conference on Robotics and Automation (ICRA)}, 
  title={End-to-End Semi-supervised Learning for Differentiable Particle Filters}, 
  year={2021},
  volume={},
  number={},
  pages={5825-5831},
  keywords={Atmospheric measurements;Neural networks;Semisupervised learning;Particle measurements;Particle filters;History;Task analysis},
  doi={10.1109/ICRA48506.2021.9561889}}


@article{jonschkowski2018differentiable,
  title={Differentiable particle filters: End-to-end learning with algorithmic priors},
  author={Jonschkowski, Rico and Rastogi, Divyam and Brock, Oliver},
  journal={arXiv preprint arXiv:1805.11122},
  year={2018}
}

﻿@article{Kloss2021,
author={Kloss, Alina
and Martius, Georg
and Bohg, Jeannette},
title={How to train your differentiable filter},
journal={Autonomous Robots},
year={2021},
month={May},
day={01},
volume={45},
number={4},
pages={561-578},
abstract={In many robotic applications, it is crucial to maintain a belief about the state of a system, which serves as input for planning and decision making and provides feedback during task execution. Bayesian Filtering algorithms address this state estimation problem, but they require models of process dynamics and sensory observations and the respective noise characteristics of these models. Recently, multiple works have demonstrated that these models can be learned by end-to-end training through differentiable versions of recursive filtering algorithms. In this work, we investigate the advantages of differentiable filters (DFs) over both unstructured learning approaches and manually-tuned filtering algorithms, and provide practical guidance to researchers interested in applying such differentiable filters. For this, we implement DFs with four different underlying filtering algorithms and compare them in extensive experiments. Specifically, we (i) evaluate different implementation choices and training approaches, (ii) investigate how well complex models of uncertainty can be learned in DFs, (iii) evaluate the effect of end-to-end training through DFs and (iv) compare the DFs among each other and to unstructured LSTM models.},
issn={1573-7527},
doi={10.1007/s10514-021-09990-9},
url={https://doi.org/10.1007/s10514-021-09990-9}
}



@inproceedings{
karl2017deep,
title={Deep Variational Bayes Filters: Unsupervised Learning of State Space Models from Raw Data},
author={Maximilian Karl and Maximilian Soelch and Justin Bayer and Patrick van der Smagt},
booktitle={International Conference on Learning Representations},
year={2017},
url={https://openreview.net/forum?id=HyTqHL5xg}
}



