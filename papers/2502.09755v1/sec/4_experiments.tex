\section{Experiments}
\label{section:experiments}

% First, we describe our experimental setting in Section \cref{subsec:exp_setting}. This is followed by our experimental results in Section \cref{subsec:exp_results}.

%  We seek to address three key research questions: 
% \begin{itemize}
%     \item (RQ1) Can $CRI$ increase attack convergence rate?
    
%     \item (RQ2) How do the generated attacks differ when utilizing $CRI$?
    
%     \item (RQ3) How does $CRI$ compare with $U\text{-}CRI$ in between different models?

% \end{itemize}
We evaluate our proposed method on the $AdvBench$ dataset \cite{zou2023universal} over multiple models and compare it with standard and random initializations. We present attacks' $ASR$ and loss, dependent on the number of optimization steps. \cref{subsec:exp_setting} details the experimental setup, \cref{subsec:exp_results} discusses our main findings, and \cref{subsec:ablation} present a short ablation study of our method. 
We seek to address three key research questions: 
\begin{itemize}
    \item \textbf{(RQ1)} Does $CRI$ present a viable method for enhancing attacks' $ASR$?
    \item \textbf{(RQ2)} Can $CRI$ reduce the computational overhead of attacks and enable faster generation of jailbreak prompts?    
    \item \textbf{(RQ3)} How do $CRI$ and $U\text{-}CRI$ compare in terms of $ASR$ and computational overhead of the resulting attacks? 
\end{itemize}


\subsection{Experimental Setting}
\label{subsec:exp_setting}

\paragraph{Dataset}
We present our experiments on the $AdvBench$ dataset \cite{zou2023universal}, which provides user prompt--target response pairs $(x, t)$. 
We utilize $5$ disjointed sets:
\begin{itemize}
    \item A $100$ sample test set, over which we present the experimental results
    \item A $25$ sample optimization set for the $GCG\text{-}M$ setting
    \item A $25$ sample validation set for the $GCG\text{-}M$ setting
    \item A $25$ sample optimization set for our $CRI,U\text{-}CRI$
    \item A $25$ sample validation set for our $U\text{-}CRI$
\end{itemize}
The test set and those concerning $GCG\text{-}M$ are then the same as suggested by the authors \citet{zou2023universal}. For our $CRI,U\text{-}CRI$, we fine-tune the initializations on the optimization set, and for $U\text{-}CRI$, we take the best-performing initialization over the validation set.


\paragraph{Models}
We evaluate the attacks on three LLMs:
\begin{itemize}
    \item Llama-2-7b-chat-hf \cite{touvron2023llama}
    \item Vicuna-7b-1.3 \cite{vicuna2023}
    \item Meta-Llama-3-8B-Instruct \cite{meta2024llama3}
\end{itemize}
We correspondingly denote these models as Llama-2, Vicuna, and Llama-3. We consider Llama-2 and Vicuna as in the default settings presented by the $GCG$ and $AutoDAN$ baseline attacks. Llama-3 is then considered a more robust alternative. In addition, we present transfer attacks produced over the source models Llama-2 and Vicuna and deployed over five additional open-source models referenced in \cref{appendix:Black-Box Models}.



% Llama-2 and Vicuna are used to test the proposed attacks under their default configurations, while Llama-3 serves as a more \emph{robust} case study, allowing us to investigate the generalizability of $CRI$. To examine the transferability of $GCG\text{-}M$, we also employ nine additional open-source models (see \cref{tab:llama2_gcg-m_asr_transposed} and \cref{tab:vicuna_gcg-m_asr_transposed}).

\paragraph{Attacks.}
We consider four baseline attacks:
\begin{itemize}
    \item $GCG$: the individual attack variant suggested by \citet{zou2023universal}
    \item $GCG\text{-}M$: the universal attack variant suggested by \citet{zou2023universal}
    \item $AutoDAN\text{-}GA$: the individual genetic attack variant suggested by \citet{liu2023autodan}
    \item $AutoDAN\text{-}HGA$: the individual hierarchical genetic attack variant suggested by \citet{liu2023autodan}
\end{itemize}
We present the results depending on the number of optimization steps for each individual attack. For $GCG$, we utilize the individual and universal variants correspondingly with $CRI,U\text{-}CRI$. For $AutoDAN$, we only compare $CRI$ to the standard initialization. In addition, we present the transfer attacks produced via the universal $GCG\text{-}M$. 

\paragraph{Configurations and Adaptations}
We use the default settings suggested by the authors for all the compared attacks in all the presented settings. The number of optimization steps in either the pre-training of our $CRI,U\text{-}CRI$ and the attack deployment is then $K=500$ for $GCG$ and $K=100$ for $AutoDAN$.


% When creating $CRI$ and $U\text{-}CRI$ for $GCG$, we use 300 optimization steps, whereas in the attacks, $GCG$ and $GCG\text{-}M$ each undergo 500 optimization steps, primarily to examine their convergence. For both $AutoDAN$ variants, 100 optimization steps are taken for constructing $CRI$ and for the regular attacks. After generating the initialization for $AutoDAN$, we update its reference set (initially containing manually constructed $DAN$ prompts) with our custom initialization and adjust the batch size accordingly.

% \paragraph{Initializations.}
% We initialize each attack with standard or random initialization and compare the results to our suggested initialization.

% We evaluate both $GCG$ and $AutoDAN$ under multiple initialization schemes. Alongside each method’s default initialization, we incorporate $CRI$. As outlined in \cref{subsec:objective}, we additionally test $U\text{-}CRI$ with $GCG$. To further measure the effectiveness of $CRI$, we include a randomly generated initialization (by sampling tokens for a suffix) within $GCG$ and compare its performance against both standard and $CRI$-based initializations.

\paragraph{Metrics.}
Each baseline attack considers a different evaluation framework, differing only in their definition of \emph{refusal} outputs. We, therefore, evaluate each attack via the corresponding evaluation framework suggested by the authors. In addition, we provide the lists of output prefixes considered as \emph{refusal} strings by each work in the supplementary material \cref{appendix:refusal-lists}. Our primary evaluation metric is then $ASR$, where attacks are successful if the model’s output does not contain any refusal string from its associated \textit{refusal-list}. We additionally report the metrics of Mean Steps to Success ($MSS$), Average Steps to Success ($ASS$), and Loss in the First Step ($LFS$). Where the metrics of $MSS$ and $ASS$ aim to estimate the attacks' convergence rate, and $LFS$ aims to estimate the proximity of initializations to the \emph{compliance} subspace. 


% Since no standardized evaluation framework exists for jailbreak attacks, we follow $GCG$ and $AutoDAN$ in using Attack Success Rate ($ASR$) as our primary metric. An attack is considered successful if the model’s output does not contain any refusal string from its associated \textit{refusal-list} (see \cref{appendix:refusal-lists}). We also report Mean Steps to Success ($MSS$), Average Steps to Success ($ASS$), and Loss in the First Step ($LFS$). While $MSS$ and $ASS$ capture how quickly each attack converges (vital for our proposed initializations), $LFS$ provides empirical evidence of whether $CRI$ lowers the initial loss on unseen prompts, as theoretically discussed in \cref{section:method}.

\input{vis/fig_autodan_ga_asr_row}
\input{vis/fig_autodan_hga_asr_row}
\input{vis/fig_attack_losses}

\input{vis/table_individual_results}





% \subsection{Experimental Setting}
% \label{subsec:exp_setting}

% \paragraph{Dataset.}
% All experiments were conducted using the $AdvBench$ dataset \cite{zou2023universal}, which contains pairs of user prompts $x$ and corresponding target responses $t$. We used the following split on the $GCG$ individual variant and $AutoDAN$: fine-tuning set consisting of $25$ samples, and test set consisting of $100$ samples. For $GCG\text{-}M$, a further $25$ samples were utilized as an evaluation set for each attack. Moreover, $25$ samples were utilized to create the actual attack, and $100$ samples were used to test the attack by only running inference. We made sure there was no overlap between the used sets.

% \paragraph{Models.}
% We evaluated our approach using three language models: Llama-2-7b-chat-hf \cite{touvron2023llama2}, Vicuna-7b-1.3 \cite{vicuna2023}, and Meta-Llama-3-8B-Instruct \cite{meta2024llama3}. Llama-2 and Vicuna were chosen to assess the proposed attacks in their respective default settings. Llama-3 was selected to evaluate our approach under a more \emph{robust} scenario, thereby testing the generalizability of $CRI$. Moreover, in order to test the transferability of $GCG\text{-}M$, we utilize $9$ additional open-source models, as described in \cref{tab:llama2_gcg-m_asr_transposed} and \cref{tab:vicuna_gcg-m_asr_transposed}.

% \paragraph{Attacks.}
% We tested four attacks in total: the $GCG$ individual attack, $GCG\text{-}M$ (the universal variant of $GCG$) and the two variants from $AutoDAN$, namely $AutoDAN\text{-}GA$ and $AutoDAN\text{-}HGA$. 

% \paragraph{Configurations and Adaptations.}
% In our experiments with Llama-2 and Vicuna, we used the default parameter settings for all attacks. For Llama-3, the $GCG$ attack required reducing the batch size from $512$ to $16$ \rom{we don't talk about $GCG\text{-}M$ not running on Llama-3}. In addition, when creating $CRI$ and $U\text{-}CRI$ in $GCG$, $300$ optimization steps were taken. For $GCG$ and $GCG\text{-}M$, $500$ 
% optimization steps were taken, this was mainly to view convergence of results. For $AutoDAN$ (both variants), $100$ optimization steps were taken both for creating the $CRI$ and regular attacks. After generating the initialization for $AutoDAN$, we adapted the reference set (which originally contained manually constructed $DAN$ prompts) by incorporating our initialization. The batch size was subsequently adjusted to accommodate the updated reference set.

% \paragraph{Initializations.}
% In our experiments, we evaluate $GCG$ and $AutoDAN$ using multiple initialization strategies. For both attacks, we apply their respective standard initializations along with $CRI$. As described in \cref{subsec:objective}, we also test $U\text{-}CRI$ with $GCG$. Additionally, in $GCG$, to assess whether our initialization outperforms not just the standard one but other alternatives as well, we generate a random initialization by sampling tokens for a suffix and include it in our evaluations.

% \paragraph{Metrics.}
% Because jailbreak attacks still lack a standardized evaluation framework, we follow the metrics used by $GCG$ and $AutoDAN$ and adopt Attack Success Rate ($ASR$) as our primary measure. In each attack, success is defined according to its respective $refusal\text{-}list$ (see \cref{appendix:refusal-lists}). If an output does not contain any refusal string in this list, the attack is deemed successful. We also report the Mean Steps to Success ($MSS$), Average Steps to Success ($ASS$), and Loss in the First Step ($LFS$). $MSS$ and $ASS$ quantify how quickly the attacks converge (an important consideration for our proposed initialization), while $LFS$ provides insight into whether $CRI$ indeed reduces the loss on unseen prompts, as theoretically discussed in \cref{section:method}.


\subsection{Experimental Results}
\label{subsec:exp_results}

In \cref{fig:gcg_asr}, we present the $GCG$ attack’s $ASR$ for all three models, depending on the optimization steps. Our $U\text{-}CRI$ achieves the best $ASR$ for all the presented settings. Moreover, on Llama-2 and Llama-3, we show substantial improvement in the convergence rate over other initializations. On Vicuna, all initializations quickly achieve nearly $100\%$ $ASR$, which may indicate this model's susceptibility to jailbreak attacks. Our supplementary material additionally presents an example of $CRI$'s $JT$ set over this setting in \cref{Initialization IPA Set for Llama2}.

% , comparing four initializations: the standard $GCG$ setup, a random initialization, $CRI$, and $U\text{-}CRI$. Overall, our initializations converges more quickly on most prompts for each model. This improvement is especially pronounced for Llama-2 and Llama-3, likely because Vicuna is inherently less robust to jailbreak attacks and thus reaches high $ASR$ with fewer steps. Moreover, on Llama-2 and Llama-3, our initialization achieves a higher final $ASR$, indicating CRI systematically boosting the attack performance.%more successfully jailbroken prompts.
In \cref{fig:autodan-ga_asr}, we present the $AutoDAN\text{-}GA$ attack’s $ASR$ for all three models, depending on the optimization steps. Our $CRI$ achieves the best $ASR$ for Llama-2 and substantially improves the $ASR$ in this setting. For Vicuna and Llama-3, all initializations quickly achieve $100\%$ $ASR$. This supports our previous indication that Vicuna is susceptible to jailbreak attacks and suggests that the genetic algorithm of $AutoDAN$ is better performing on Llama-3 than on Llama-2.

In \cref{fig:autodan-hga_asr}, we present the $AutoDAN\text{-}HGA$ attack’s $ASR$ for all three models, depending on the optimization steps. Similarly, our $CRI$ achieves the best $ASR$ for Llama-2 and substantially improves both $ASR$ and the convergence rate. For Vicuna and Llama-3, again, all initializations quickly achieve an $ASR$ of $100$. This aligns with our previous indications that Vicuna is susceptible to jailbreak attacks and that $AutoDAN$ performs better on Llama-3. Our supplementary material additionally presents examples of the resulting jailbreak prompts in \cref{appendix:Results examples AutoDan}.

In \cref{fig:gcg_losses}, we present the $GCG$ attack’s loss for Llama-2 and Vicuna, depending on the optimization steps. Our $CRI$ achieves the best loss for all the presented settings. Moreover, on Llama-2, we again show substantial improvement in the convergence rate over other initializations.

% Finally, we highlight the $LFS$ metric in \cref{tab:individual_attack_asr} to illustrate how our initializations affects initial loss. As hypothesized, our initializations lower the objective loss (\cref{eq:objective}) compared to the standard initialization, confirming its ability to generalize to unseen prompts. Further evidence appears in \cref{fig:gcg_losses}, which depicts $GCG$ attack losses. For Llama-2 in particular, our initializations converge to a lower final loss than the standard one, suggesting it finds a better minimum and thus delivering stronger overall performance.

In \cref{tab:individual_attack_asr}, we compare $ASR$, $MSS$, $ASS$, and $LFS$ over all attacks, initializations and models. Again, our initializations achieve the best $ASR$ for all the presented settings. Moreover, for Llama-2, we substantially improve the $ASR$ for all attacks, and similarly so for the $GCG$ attack in Llama-3. In addition, we achieve the best $MSS$ in all settings, and similarly for $ASS$, where we are otherwise comparable. We substantially improve $MSS,ASS$ for the $GCG$ attack over all the models, and for $AutoDAN\text{-}HGA$ over Llama-2. This supports our previous indications that $CRI,U\text{-}CRI$ achieve a faster convergence rate over $GCG$. As for $LFS$, we substantially improve the initial loss in all the presented settings.



% Turning to $AutoDAN\text{-}GA$, \cref{fig:autodan-ga_asr} compares $ASR$ on the same three models, but this time only with the standard initialization and $CRI$\amit{standard its mean k=25?}. Here, $CRI$ again displays faster convergence across all models. Notably, Llama-2 exhibits a substantially lower $ASR$ overall, whereas Llama-3 rapidly converges to $100\%$ $ASR$. Vicuna remains the least robust, as expected. The benefits of $CRI$ for $AutoDAN\text{-}GA$ are most evident in Llama-2, where the final $ASR$ rises substantially. We repeat this analysis for $AutoDAN\text{-}HGA$ 

% in \cref{fig:autodan-hga_asr}, again finding faster convergence and higher final $ASR$ under $CRI$ than the standard. Consistent with the original $AutoDAN$ results, Llama-2 fares better with $AutoDAN\text{-}HGA$ than with $AutoDAN\text{-}GA$, as indicated by a higher final $ASR$ overall. 

% \cref{tab:individual_attack_asr} summarizes the $ASR$, $MSS$, $ASS$, and $LFS$ for each attack, initialization, and model, highlighting the top results in bold. Overall, our initializations outperforms both the standard and random initializations in most scenarios. Under $GCG$, we provide especially large gains on Llama-2 and Llama-3: in Llama-2, $MSS$ decreases by $\times64$ and $ASS$ by $\times63$, while in Llama-3, $MSS$ is reduced by $\times38$ and $ASS$ by $\times7$. Although Vicuna also benefits from our initializations, their effect is less dramatic given its inherently faster convergence.

% For $AutoDAN\text{-}GA$, $CRI$ improves $ASS$ consistently and increases Llama-2’s final $ASR$ from 19\% to 30\%. With $AutoDAN\text{-}HGA$, $CRI$ lowers both $MSS$ and $ASS$ on Llama-2 and boosts its final $ASR$. On Llama-3, $CRI$ enhances $ASS$ slightly on both attacks, whereas in $AutoDAN\text{-}HGA$, Vicuna experiences a small ($0.06$) decrease in $ASS$, likely due to noise and Vicuna’s lower robustness.



In \cref{tab:llama2_gcg-m_asr_transposed,tab:vicuna_gcg-m_asr_transposed}, we compare the $ASR$ over $GCG\text{-}M$ transfer attack, where the source models are Llama-2 and Vicuna, correspondingly. Our initializations achieve the best $ASR$ in all the presented settings. Moreover, we show substantial improvements for nearly all the presented models, and similarly so over the median and average $ASR$s. Our supplementary material additionally presents examples of the resulting jailbreak prompts in \cref{Results examples $GCG-M$}.

% Moving on to universality and transferability, \cref{tab:llama2_gcg-m_asr_transposed} and \cref{tab:vicuna_gcg-m_asr_transposed} display results using Llama-2 and Vicuna as the source models, respectively. Under universality, both Llama-2 and Vicuna achieve their highest $ASR$ when applying our initializations trained on the same source model. Regarding transferability, for both Llama-2 and Vicuna, our initializations again deliver superior $ASR$. Examining median and average $ASR$ across target models shows a large margin of improvement, pointing to our initializations providing transferability as well.







% \subsection{Experimental Results}
% \label{subsec:exp_results}

% In \cref{fig:gcg_asr}, we compare the $GCG$ attack's $ASR$ across steps on all three models. The comparison includes four initializations: $GCG$'s standard, a random initialization, $CRI$, and $U\text{-}CRI$. As shown, our proposed $CRI$ converge more quickly on most prompts for all models. This effect is especially pronounced for Llama-2 and Llama-3, likely because Vicuna is inherently less robust to jailbreak attacks. Moreover, on Llama-2 and Llama-3, our initialization yields a higher final $ASR$, indicating a greater number of successfully jailbroken prompts when utilizing $CRI$.

% In \cref{fig:autodan-ga_asr}, we compare $AutoDAN\text{-}GA$'s $ASR$ across the same models, this time using only its standard initialization and $CRI$. Again, $CRI$ exhibits faster convergence across all models. Interestingly, Llama-2 shows a substantially lower $ASR$ overall in both initializations, whereas Llama-3 converges to $100\%$ $ASR$ very quickly. Vicuna remains the least robust, as expected. The benefit of $CRI$ in this setting is most notable on Llama-2, where the final $ASR$ also improves considerably. In \cref{fig:autodan-hga_asr}, we repeat this comparison for $AutoDAN\text{-}HGA$, again observing faster convergence and higher final $ASR$ with $CRI$. Here, Llama-2 performs better than it does under $AutoDAN\text{-}GA$, consistent with findings in the original $AutoDAN$ paper. The boost offered by $CRI$ is especially pronounced in reducing convergence time and improving the final $ASR$ on Llama-2.

% \cref{tab:individual_attack_asr} presents the $ASR$, $MSS$, $ASS$, and $LFS$ for each attack, initialization, and model, with the best results highlighted in bold. Overall, $CRI$ outperforms both the standard and random initializations in most scenarios. Notably, under $GCG$, $CRI$ produces substantial gains on Llama-2 and Llama-3: in Llama-2, the $MSS$ decreases by $\times64$ and $ASS$ by $\times63$, while in Llama-3, $MSS$ is reduced by $\times38$ and $ASS$ by $\times7$. Although Vicuna also benefits from $CRI$, the improvement is less dramatic because it converges more quickly.

% For $AutoDAN\text{-}GA$, $CRI$ yields consistent improvements in $ASS$ and notably raises Llama-2's final $ASR$ from $19\%$ to $30\%$. For $AutoDAN\text{-}HGA$, $CRI$ similarly lowers $MSS$ and $ASS$ on Llama-2 and increases its final $ASR$. On Llama-3, it improves $ASS$, while on Vicuna there is a minor decrease in $ASS$ (by $0.06$), which may be due to noise and Vicuna's lower robustness to these attacks.

% \cref{tab:llama2_gcg-m_asr_transposed} and \cref{tab:vicuna_gcg-m_asr_transposed} present the universality and transferability results, using Llama-2 and Vicuna as source models, respectively. Beginning with universality, both Llama-2 and Vicuna achieve the highest $ASR$ when utilizing our initializations, that were created on the same source model. Moving to transferability, on both Llama-2 and Vicuna, utilizing our initializations achieve superior $ASR$. Looking at the median and average $ASR$ across models, our initializations massively surpass the standard one in terms of $ASR$, hinting at $CRI$ achieving transferability as well.

% Finally, focusing on the loss of our attacks, we examine the $LFS$ metric in \cref{tab:individual_attack_asr}. As hypothesized, $CRI$ succeeds in reducing our objective loss (\cref{eq:objective}) compared to standard initialization, providing empirical evidence of its generalizability to unseen prompts. Additional evidence supporting $CRI$'s effect on loss can be found in \cref{fig:gcg_losses}, which presents $GCG$'s attack losses. These figures demonstrate the importance of using an informative initialization. $CRI$ on Llama-2 demonstrates a convergence to a lower loss at the end of the attack when compare to the standard one, converging into a better minima. This is a further explanation to its superior performance.
\input{vis/table_gcg-m_llama2} 
\input{vis/table_gcg-m_vicuna}

\subsection{Ablation Study}
\label{subsec:ablation}

In our $GCG$ experiments (\cref{fig:gcg_asr,fig:gcg_losses}), we compare our $CRI$ and $U\text{-}CRI$. $U\text{-}CRI$ achieves the best $ASR$, and $CRI$ achieves the best loss. In addition, $U\text{-}CRI$ converges consistently faster, which aligns with the lower $ASS$ on all models as presented in \cref{tab:individual_attack_asr}. This aligns with our previous assumptions that $U\text{-}CRI$ boasts higher transferability to unseen prompts and that $CRI$ achieves better loss. As such, it may indicate that each approach optimizes an equally important yet differing aspect of the initialization. This is supported by our experiments in \cref{tab:vicuna_gcg-m_asr_transposed,tab:llama2_gcg-m_asr_transposed}, where $CRI$ consistently achieves better results when the source model is Llama-2, and similarly for $U\text{-}CRI$ when the source model is Vicuna.

% Turning to our $GCG\text{-}M$ experiments in \cref{tab:llama2_gcg-m_asr_transposed} and \cref{tab:vicuna_gcg-m_asr_transposed}, using Vicuna as a source model yields superior results under $U\text{-}CRI$ compared to $CRI$ on nearly all models, underscoring its broader universality and transferability. In contrast, with Llama-2 as a source model, $CRI$ achieves higher $ASR$ on almost all target models.


% we compare two variants of $CRI$: the original $CRI$ and $U\text{-}CRI$. As shown in both \cref{fig:gcg_asr} and \cref{tab:individual_attack_asr}, $U\text{-}CRI$ converges consistently faster, evident from its lower $ASS$ and reduced $MSS$ on Llama-3, and also achieves the highest $ASR$. Despite this superior performance, $U\text{-}CRI$ does not exhibit a lower $LFS$, implying that its initial loss is not necessarily lower than that of $CRI$. This is also presented in \cref{fig:gcg_losses}, with the loss of $CRI$ being consistently below $U\text{-}CRI$ on both models. A possible explanation for this phenomena is that $CRI$ begins close to a less optimal local minimum, while $U\text{-}CRI$ begins in a more general spot, and more successfully manages to locate a better one.

% Turning to our $GCG\text{-}M$ experiments in \cref{tab:llama2_gcg-m_asr_transposed} and \cref{tab:vicuna_gcg-m_asr_transposed}, using Vicuna as a source model yields superior results under $U\text{-}CRI$ compared to $CRI$ on nearly all models, underscoring its broader universality and transferability. In contrast, with Llama-2 as a source model, $CRI$ achieves higher $ASR$ on almost all target models.

% \subsection{Ablation Study}
% \label{subsec:ablation}
% In our $GCG$ experiments, we compare two $CRI$ implementations: $CRI$ and $U\text{-}CRI$. As shown in both \cref{fig:gcg_asr} and \cref{tab:individual_attack_asr}, $U\text{-}CRI$ converges consistently faster, indicated by lower $ASS$ and reduced $MSS$ on Llama-3. Additionally, it achieves the highest $ASR$, highlighting its effectiveness as a strong initial starting point. Interestingly, despite its superior performance, $U\text{-}CRI$ does not yield a lower $LFS$, suggesting that its initial loss is not necessarily lower than that of $CRI$. This is counterintuitive given its improved results. One possible explanation for this is that $CRI$ tends to initialize inside a poor local minima, whereas $U\text{-}CRI$ finds a more optimal minimum.

% Moreover, moving to our $GCG\text{-}M$ experiment in \cref{tab:llama2_gcg-m_asr_transposed} and \cref{tab:vicuna_gcg-m_asr_transposed}. Vicuna as a source model demonstrated superior results when utilizing $U\text{-}CRI$, when compared to $CRI$ on almost all models, demonstrating better universality and transferability. In contrast, when utilizing Llama-2 as a source model, $CRI$ gained the lead with significantly better $ASR$ on almost all models.
