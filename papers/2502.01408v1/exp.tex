\section{Experimental evaluation}\label{sec:exp}

In this section we present our experimental evaluation which has the following goals: 
($i$)  Test how well \algpartition finds ground-truth hierarchy in synthetic dataset,
  and assess the impact of prevailing  noise level in labels, in terms of the Kendall's $\tau$ coefficient.\!\footnote{A measure of rank correlation which indicates the similarity between two rankings.}
($ii$) Compare the agony scores of \algpartition against the scores of hierarchies obtained without using any labels.
	Here we used \cite{nikolaj2017tiers}, which we call \algexact.
($iii$) Study how the constraint $k$ influences the agony score.
($iv$) Explore the hierarchies in real-world labeled datasets.

We implemented the algorithm in Python\footnote{See \url{https://version.helsinki.fi/dacs/} for the code.
\label{foot:code}}
and used a 2.4GHz Intel Core i5 processor and 16GB RAM.


\paragraph{Synthetic datasets:}


To test our algorithm, we generated  $7$ synthetic networks in which the characteristics are stated in
Table~\ref{tab:stats1}.
For each network, we first set our basic parameters; number of nodes $n$, number of edges $m$, and number of ranks $h$. Next we  randomly assigned the 
ranks for each node, with equal probability.
Note that, each rank has its own specific label, we call them as \emph{true} labels. Initially,  we  assigned true labels to  vertices such that  a node which belongs to the rank $r_{i}$, receives  the label $l_{i}$. This can be considered as true label assignment which is done prior to the noisy label assignment. Afterwards, we fixed two  noise parameters, $\theta$ and $\mu$, where $\theta$ indicates the percentage of nodes which contains \emph{false}  labels and $\mu$ indicates the percentage of nodes which contains \emph{noise}  labels.  To add those \emph{false} labels, we first chose a subset of vertices in accordance with $\theta$ and then added a random label chosen from  label universe $U_{true}$ to each node, without repeating the available labels for that node. Similarly, we assigned  \emph{noise} labels for a percentage of nodes determined by parameter $\mu$, randomly chosen from  $U_{noise}$, a label set of size $100$. 

After being set all noise parameter values, we fixed a certain percentage value, $\eta$ as a controlling parameter of the proportion of forward edges. 
Next, we uniformly sampled $m$ number of vertex pairs as follows:
For each rank $i = 1, \ldots, h - 1$, we generated $m / (h - 1)$ edges, between the nodes with rank $i$ and rank $i + 1$.
For each vertex pair, we determined whether the chosen edge is either forward or backward. 
This choice can be viewed in terms of a
coin-flipping experiment of a biased coin with probability $\eta$.
% We repeated the same process $m$ times to generate all the edges. 
Finally, we removed all self-loops and aggregated the same directed edges together by assigning their accumulated  weights.

\input{statstable}
\input{statstable-com}

\paragraph{Real-world datasets:}

We explore label hierarchies in $7$ publicly available, labeled, real-world datasets. The details of the  datasets  are shown in Table~\ref{tab:stats3}. \dtname{EIES} is a  network of researchers working on social network analysis, known as \emph{Freeman's EIES networks}\footnote{\url{https://toreopsahl.com/datasets/}}. It contains a set of message links among $32$ researchers, weighted based on the number of messages sent. Each researcher is attributed based on his/her main disciplinary affiliation and the number of citations each researcher had in the social science citation index in $1978$.
\dtname{School} dataset\footnote{\url{http://www.sociopatterns.org/datasets/} } 
contains directed contact links between students in a high school in France, weighted by the length of interval where the contact was active. Students are labeled with their class labels. 
\dtname{Cora}~\cite{nr2015}\footnote{\url{https://networkrepository.com} \label{foot:nw-repo}}  and \dtname{Cite-seer}~\cite{nr2015}\footref{foot:nw-repo} datasets are citation networks where papers are attributed with a category and a class respectively.
\dtname{Patent-citation}~\cite{UDMS_dataset}\footnote{\url{https://www2.helsinki.fi/en/researchgroups/unified-database-management-systems-udbms/datasets/patent-dataset}}  contains patent citations data.
Each patent is a vertex and each citation is an edge in our network. Each patent has a class, a technological
category, and a technological sub-category which we consider as node labels. For our experiments, we extracted a sub-network which contains first $7\,000$ citations and then filtered out the nodes whose category details are missing from the dataset.
\dtname{DBLP-citation}~\cite{tang2008arnetminer}\footnote{\url{https://www.aminer.org/citation}} contains  citation relationships from top venues in Data Mining and Machine Learning~(SDM, NIPS, ICDM, KDD, ECMLPKDD, and WWW). We extracted set of labels by stemming the titles of the papers and removing stop words. \dtname{Physics-citation}\footnote{\url{https://github.com/chriskal96/physics-theory-citation-network}} is a citation network  extracted from Journals in the High Energy Physics Theory category. Herein, we use the title of the publication as labels, after stemming the titles and removing stop words. 
 


%%%%%%%%%%%%%%%%%%%%%RESULTS-SYNTHETIC

\paragraph{Results of synthetic datasets:}

The detailed statistics and the running times  are given in Table~\ref{tab:stats2}.
First, we observe  $2nd$, $3rd$, and $4th$ columns in Table~\ref{tab:stats2}. These columns display  ground truth agony scores of the datasets, followed by the scores obtained with \algpartition and  \algexact.
Generally, the discovered agony score obtained by \algpartition is  more closer to the ground truth agony score, as opposed to the  score found by  \algexact.
Secondly, consider  $k\tau_{dis}$ column of Table~\ref{tab:stats2}, which exhibits the Kendall's $\tau$ measures attained by our algorithm. For all these experiments Kendall's $\tau$ coefficient  exceeds $0.9$; which indicates a high quality match of the discovered hierarchies with compared to the ground truth, even under the presence of $10\%$ false labels. 

Let us now compare Kendall's $\tau$ measures achieved by \algpartition with the scores by \algexact, which is shown in the $k\tau_{base}$ column.
We can observe that Kendall's $\tau$ measures obtained by \algpartition is significantly higher than the ones by baseline, except for one outlier case.
Next, let us consider  the $5th$ column of Table~\ref{tab:stats2}, which shows the number of ranks discovered by \algpartition. Interestingly, this is equal to the number of ground truth ranks.
Moreover, the numbers of ranks discovered by \algexact ($6th$ column) are  much higher than the ground truth.
Finally, from the
computational time results which are stated in the last column in Table~\ref{tab:stats2}, we see that the running times
are  reasonably practical to run our algorithm nearly in $3$ minutes for a graph with over $40\,000$ vertices and $100\,000$ edges.
 


%%%%%FIGURE-1%%%%%%%

\begin{figure}[t!]
\begin{center}
% \begin{figure}[t!]
\setlength{\tabcolsep}{0pt}
% \begin{tabular}{ll}
\begin{tikzpicture}
\begin{axis}[xlabel={  Percentage of forward edges~($\eta$)  }, ylabel= {Kendall's  $\tau$},
    width = 6.9cm,
    height = 3.5cm,
    xmin = 20,
    xmax = 100,
    ymin = -1,
    ymax = 1,
    scaled y ticks = false,
    cycle list name=yaf,
    yticklabel style={/pgf/number format/fixed},
    legend entries = {$\theta=0\%$,$\theta=5\%$, $\theta=10\%$, $\theta=20\%$, $\theta=30\%$},
    %legend style={at={(0.95,0.27)},anchor=east},
	legend pos=outer north east,
    no markers,
]
\addplot table [x=x, y=y1, col sep=comma] {agony-vs-per.csv};
\addplot table [x=x, y=y2, col sep=comma] {agony-vs-per.csv};
\addplot table [x=x, y=y3, col sep=comma] {agony-vs-per.csv};
% \addplot table [x=x, y=y4, col sep=comma] {agony-vs-per.csv};
\addplot table [x=x, y=y5, col sep=comma] {agony-vs-per.csv};
\addplot table [x=x, y=y6, col sep=comma] {agony-vs-per.csv};
\pgfplotsextra{\yafdrawaxis{20}{100}{-1}{1}}
\end{axis}
\end{tikzpicture}

\caption{Kendall's  $\tau$ coefficient  as a function of $\eta$ for the cases of several false label probabilities~($\theta$) shown in the legend. This experiment is done for  $\abs{V}=4\,000$, $\abs{E}=7\,000$, $\mu=0.05$, and $h=10$ using \algpartition.}
\label{fig:per-kendall}
\end{center}
\end{figure}

%%%%%FIGURE-2%%%%%%%

\begin{figure}[t!]
\begin{center}
% \begin{figure}[t!]
\setlength{\tabcolsep}{0pt}
% \begin{tabular}{ll}
\begin{tikzpicture}
\begin{axis}[xlabel={Percentage of forward edges~($\eta$)  }, ylabel= {Kendall's  $\tau$},
    width = 6.9cm,
    height = 3.5 cm,
    xmin = 20,
    xmax = 100,
    ymin = -1,
    ymax = 1,
    scaled y ticks = false,
    cycle list name=yaf,
    yticklabel style={/pgf/number format/fixed},
    legend entries = {$\mu=10\%$,$\mu=20\%$, $\mu=30\%$, $\mu=50\%$, $\mu=70\%$},
    %legend style={at={(0.95,0.27)},anchor=east},
	legend pos=outer north east,
    no markers,
]
\addplot table [x=x, y=y1, col sep=comma] {agony-vs-per-ind.csv};
\addplot table [x=x, y=y2, col sep=comma] {agony-vs-per-ind.csv};
\addplot table [x=x, y=y3, col sep=comma] {agony-vs-per-ind.csv};
\addplot table [x=x, y=y4, col sep=comma] {agony-vs-per-ind.csv};
\addplot table [x=x, y=y5, col sep=comma] {agony-vs-per-ind.csv};
\pgfplotsextra{\yafdrawaxis{20}{100}{-1}{1}}
\end{axis}
\end{tikzpicture}

\caption{Kendall's  $\tau$ coefficient  as a function of $\eta$  for the cases of several  noise label probabilities~($\mu$) shown in the legend. This experiment is done for  $\abs{V}=4\,000$, $\abs{E}=7\,000$, $\theta=0.15$, and $h=10$ using \algpartition.}
\label{fig:per-kendall-ind}
\end{center}
\end{figure}

Let us now consider Figure~\ref{fig:per-kendall} which demonstrates how Kendall's $\tau$ metric changes with respect to the percentage of forward edges in the network. In general, we see that Kendall's $\tau$  gradually increases when the percentage of forward edges increases.  The coefficient  significantly increases nearly at the $50\%$ percentage, from negative to positive, due to the fact that there are more forward edges than backward edges after $50\%$. We repeat this experiment by adjusting the false label probability  $\theta$ to be $0\%, 5\%, 10\%$, $20\%$, and $30\%$. When there are no false labels,  the coefficient achieves $1$ which implies a perfect match in hierarchy, while the percentage of forward edges reaches nearly $50\%$. The coefficient  achieves its max at $60\%$ for the case of $5\%$ of false  labels, whereas same is obtained nearly at $95\%$ for the case of $30\%$ of false labels. Hence we  conclude that lesser the amount of \emph{false} label noise is present, more accurate hierarchies could be extracted and more percentage of backward edges can be withstood.

Let us now investigate the effect of noise label probability $\mu$; which is shown in Figure~\ref{fig:per-kendall-ind}. On  contrary to the previous experiment, we fix $\theta$ and then repeat the same experiment by varying   $\mu$. Unlike false label probability $\theta$, even if we increase $\mu$ to be $70\%$, we can conclude that $\mu$ does not significantly affect our performance metric,  Kendall's $\tau$ coefficient.

%%%%%FIGURE-3%%%%%%%

\begin{figure}[t!]
\begin{center}
% \begin{figure}[t!]
\setlength{\tabcolsep}{0pt}
\begin{tabular}{ll}
\begin{tikzpicture}
\begin{axis}[xlabel={k  }, ylabel= {Agony score},
    width = 6.5cm,
    height = 3.5cm,
    xmin = 0,
    xmax = 20,
    ymin = 0,
    ymax = 14000,
    scaled y ticks = false,
    cycle list name=yaf,
    no markers,
    legend entries = { $\theta=0\%$, $\theta=10\%$, $\theta=20\%$, $\theta=21\%$, $\theta=23\%$, $\theta=25\%$, $\theta=30\%$},
    %legend style={at={(0.29,0.34)},anchor=east},
	legend pos=outer north east,
    no markers,
]
\addplot table [x=x, y=y1, col sep=comma] {agony-k.csv};
\addplot table [x=x, y=y2, col sep=comma] {agony-k.csv};
\addplot table [x=x, y=y3, col sep=comma] {agony-k.csv};
\addplot table [x=x, y=y4, col sep=comma] {agony-k.csv};
\addplot table [x=x, y=y5, col sep=comma] {agony-k.csv};
\addplot table [x=x, y=y6, col sep=comma] {agony-k.csv};
\addplot table [x=x, y=y7, col sep=comma] {agony-k.csv};
\pgfplotsextra{\yafdrawaxis{0}{20}{0}{14000}}
\end{axis}
\end{tikzpicture}
\end{tabular}

\caption{Agony score  ($\score{T}$)  as a function of the constraint $k$  for the cases of
 several false label probabilities~($\theta$) as shown in the legend. This experiment is done  for  $\abs{V}=4\,000$, $\abs{E} \approx 7\,000$, $h=15$, $\mu=0.05$, and $\eta=0.9$
 using \algpartition.}
\label{fig:agony-k}
\end{center}
\end{figure}

Next Figure~\ref{fig:agony-k} demonstrates the agony score as a function of $k$.  Here we repeat the experiment at different false label probabilities such as $ 0\%, 10\%, 20\%, 21\%, 23\%, 25\%$, and $30\%$. From the results we see that, for the first $3$ cases,  in which no false labels, $10\%$  and $20\%$ of false labels, agony score decreases
more prominently until it approaches $k=15$ and then it remains constant even if we increase $k$ further. Similar phenomenon happens at $k=14$, $k=13$, $k=9$, and $k=8$, for the cases of $ 21\%, 23\%, 25\%,$ and $30\%$ of  false labels respectively. This is because in latter experiments the tree contains at most $14$, $13$, $9$,  and $8$  leaves and can not improve the agony score by splitting further. In addition, we  observe that the elbow point is reached at the earliest for \emph{high-noisy} labels, with compared to the \emph{low-noisy} labels. 



%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%REAL-WORLD-RESULTS%%%%%%%

\paragraph{Results of real-world datasets:}

\input{statstable-real}
\input{statstable-real-com}

For each dataset, we computed the agony using \algpartition and \algexact. The statistics of  discovered hierarchical  structures for real-world  datasets  are shown in Table~\ref{tab:stats4}. 
First, let us look at the discovered number of ranks, which are given in Table~\ref{tab:stats4}. 
% These columns display  number of hierarchy levels discovered by
% \algpartition and 
% baseline respectively. 
Generally, $h_{base}$ is higher with compared to $h_{dis}$ except for \dtname{EIES} and \dtname{Patent-citation} datasets.
% The reason for this might be due to weighted network
Next, $2nd$ and $3rd$ columns in Table~\ref{tab:stats4} display  agony scores obtained by \algpartition and 
\algexact. As you can see in $q_{base}$, $\score{G, r} = 0$ is reached  twice  for \dtname{Cite-seer} and \dtname{Patent-citation} datasets by \algexact. The column \emph{d} in Table~\ref{tab:stats4} shows the depth of the constructed tree which is significantly smaller than $\abs{V}$. The last column in Table~\ref{tab:stats4} shows that running times are reasonably practical so that we could construct the label tree for a label graph with more than $300\,000$ edges, $80\,000$ vertices, and $4\,000$ labels in less than $22$ minutes.

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%SINGLE LABEL%%%%%%%

Note that we can solve \prblagy exactly
if each node has only a single label with a new graph
by using the set of labels
as new nodes and  combined edges as its edges.
We then run the \algexact algorithm for this new label-free network to obtain
the optimal rank.
We do this 
for \dtname{Cora} and \dtname{Cite-seer}
datasets as each paper has only one label. 
The results of those experiments are shown in Table~\ref{tab:stats5}.
Let us focus on  $q_{dis}$ and $q_{new}$ columns in Table~\ref{tab:stats5}. The
discovered agony scores obtained using our algorithm and baseline are
approximately similar, on newly formed label-free networks, implying that our
heuristic finds either optimal or close to optimal rankings for these networks.
 
\input{statstable-single-real}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%CASE STUDY%%%%%%%

\paragraph{Case study:}

To conclude the experimental section, we take a closer look at  hierarchical groups found by  \algpartition  for some of the datasets. 
We highlight two datasets, additional trees are given in Appendix.

The label tree obtained for \dtname{Physics-citation} dataset is given in the top of Figure~\ref{fig:tree-dblp-2}. Our algorithm  first partitions the physics publications based on whether it is theoretical  or application-based, suggesting that application-based papers cite more theoretical papers. Next, the label \emph{conjecture} divides the set of theoretical papers further in to two halves, suggesting that  more conjectures are likely to be presented in theoretical papers. Application-based publications are then divided further with the label \emph{braneworld} which is a cosmology related scientific term. The labels like \emph{holographic}, \emph{gravity}, and \emph{braneworld} are in the same line of research  which is sensible. 


%%%%%FIGURE-7%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%


\begin{figure}[t!]
\begin{center}
% \begin{figure}[t!]
\setlength{\tabcolsep}{0pt}
\begin{tabular}{ll}

\begin{tikzpicture}[baseline = 0pt, yscale=0.5]
\tikzstyle{node1}=[inner sep=0pt]
\node[node1] (n1) at (0, 0) {$\shortstack{Theory}$};

\node[node1] (n2)  at (-2, -1.7) {$\shortstack{Braneworld}
 $};
\node[node1] (n3) at (2, -1.7) {$\shortstack{Conjecture}
 $};

\node[node1] (n4) at (-3, -3.4) {$\shortstack{Holographic}$};

\node[node1] (n10) at (-3.7, -5.0) {$ \shortstack{ Gravity}$};
\node[node1] (n14) at (-4.0, -6.4) {$ \shortstack{ \color{purple} R1}$};
\node[node1] (n15) at (-3.4, -6.4) {$ \shortstack{ \color{purple} R2}$};

\node[node1] (n11) at (-2.3, -5.0) {$ \shortstack{ Duality}$};
\node[node1] (n16) at (-2.6, -6.4) {$ \shortstack{ \color{purple} R3}$};
\node[node1] (n17) at (-2.0, -6.4) {$ \shortstack{ \color{purple} R4}$};

\node[node1] (n5) at (-1, -3.4) {$\shortstack{World}$};
\node[node1] (n12) at (-.5, -5.0) {$ \shortstack{ \color{purple} R6}$};
\node[node1] (n13) at (-1.5, -5.0) {$ \shortstack{ \color{purple} R5}$};

\node[node1] (n6) at (1, -3.4) {$\shortstack{Electric}$};
\node[node1] (n7) at (3, -3.4) {$\shortstack{ \color{purple} R9}$};

\node[node1] (n8) at (0.5, -5) {$ \shortstack{ \color{purple} R7}$};
\node[node1] (n9) at (1.5, -5) {$ \shortstack{ \color{purple} R8}$};


\draw[yafcolor3, ->, >=latex, thick, dashed, in=90, out=-90] (n1) edge (n2);
\draw[yafcolor3, ->, >=latex, thick, in=90, out=-90] (n1) edge (n3);

\draw[yafcolor3, ->, >=latex, thick, in=90, out=-90] (n2) edge (n4);
\draw[yafcolor3, ->, >=latex, thick, dashed, in=90, out=-90] (n2) edge (n5);

\draw[yafcolor3, ->, >=latex, thick, dashed, in=90, out=-90] (n3) edge (n6);
\draw[yafcolor3, ->, >=latex, thick, in=90, out=-90] (n3) edge (n7);

\draw[yafcolor3, ->, >=latex, thick, in=90, out=-90] (n4) edge (n10);
\draw[yafcolor3, ->, >=latex, thick, dashed, in=90, out=-90] (n4) edge (n11);

\draw[yafcolor3, ->, >=latex, thick, dashed, in=90, out=-90] (n5) edge (n12);
\draw[yafcolor3, ->, >=latex, thick, in=90, out=-90] (n5) edge (n13);

\draw[yafcolor3, ->, >=latex, thick, dashed, in=90, out=-90] (n6) edge (n8);
\draw[yafcolor3, ->, >=latex, thick, in=90, out=-90] (n6) edge (n9);

\draw[yafcolor3, ->, >=latex, thick, in=90, out=-90] (n10) edge (n14);
\draw[yafcolor3, ->, >=latex, thick, dashed, in=90, out=-90] (n10) edge (n15);

\draw[yafcolor3, ->, >=latex, thick, in=90, out=-90] (n11) edge (n16);
\draw[yafcolor3, ->, >=latex, thick, dashed, in=90, out=-90] (n11) edge (n17);


\end{tikzpicture}\\


%%%%%FIGURE-8%%%%%%%

\begin{tikzpicture}[baseline = 0pt, yscale=0.5,xscale=0.9]
\tikzstyle{node1}=[inner sep=0pt]

\node[node1] (n1) at (0, 0) {$\shortstack{Algorithm}$};

\node[node1] (n2)  at (-1.8, -1.7) {$\shortstack{Recommendation}$};
\node[node1] (n3) at (1.8, -1.7) {$\shortstack{Database}$};

\node[node1] (n4) at (-3.0, -3.4) {$\shortstack{Sequential}$};

\node[node1] (n10) at (-4.2, -5.0) {$ \shortstack{ Network}$};
\node[node1] (n14) at (-4.9, -6.4) {$ \shortstack{ \color{purple} R1}$};
\node[node1] (n18) at (-4.0, -7.6) {$ \shortstack{\color{purple} R2}$};
\node[node1] (n19) at (-3.0, -7.6) {$ \shortstack{ \color{purple} R3}$};

\node[node1] (n15) at (-3.5, -6.4) {$ \shortstack{ Attentional}$};

\node[node1] (n11) at (-1.8, -5.0) {$ \shortstack{ Generalized}$};
\node[node1] (n16) at (-2.3, -6.4) {$ \shortstack{ \color{purple} R4}$};
\node[node1] (n17) at (-1.3, -6.4) {$ \shortstack{ \color{purple} R5}$};

\node[node1] (n5) at (-.6, -3.4) {$\shortstack{\color{purple} R6}$};

\node[node1] (n6) at (1, -3.4) {$\shortstack{\color{purple} R7}$};
\node[node1] (n7) at (2.7, -3.4) {$\shortstack{ Discovering}$};

\node[node1] (n8) at (2.2, -5) {$ \shortstack{ \color{purple} R8}$};
\node[node1] (n9) at (3.2, -5) {$ \shortstack{ \color{purple} R9}$};


\draw[yafcolor3, ->, >=latex, thick, dashed, in=90, out=-90] (n1) edge (n2);
\draw[yafcolor3, ->, >=latex, thick, in=90, out=-90] (n1) edge (n3);

\draw[yafcolor3, ->, >=latex, thick, in=90, out=-90] (n2) edge (n4);
\draw[yafcolor3, ->, >=latex, thick, dashed, in=90, out=-90] (n2) edge (n5);

\draw[yafcolor3, ->, >=latex, thick, dashed, in=90, out=-90] (n3) edge (n6);
\draw[yafcolor3, ->, >=latex, thick, in=90, out=-90] (n3) edge (n7);

\draw[yafcolor3, ->, >=latex, thick, in=90, out=-90] (n4) edge (n10);
\draw[yafcolor3, ->, >=latex, thick, dashed, in=90, out=-90] (n4) edge (n11);


\draw[yafcolor3, ->, >=latex, thick, dashed, in=90, out=-90] (n7) edge (n8);
\draw[yafcolor3, ->, >=latex, thick, in=90, out=-90] (n7) edge (n9);

\draw[yafcolor3, ->, >=latex, thick, in=90, out=-90] (n10) edge (n14);
\draw[yafcolor3, ->, >=latex, thick, dashed, in=90, out=-90] (n10) edge (n15);

\draw[yafcolor3, ->, >=latex, thick, in=90, out=-90] (n11) edge (n16);
\draw[yafcolor3, ->, >=latex, thick, dashed, in=90, out=-90] (n11) edge (n17);

\draw[yafcolor3, ->, >=latex, thick, in=90, out=-90] (n15) edge (n18);
\draw[yafcolor3, ->, >=latex, thick, dashed, in=90, out=-90] (n15) edge (n19);


\end{tikzpicture}
\end{tabular}
\caption{Discovered label trees for \dtname{Physics} (above) and \dtname{DBLP} (below) datasets. Solid lines indicate the branch for the nodes with the corresponding label.
}
\label{fig:tree-dblp-2}
\end{center}
\end{figure}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
The label tree obtained for \dtname{DBLP-citation} dataset is 
shown in the bottom tree of Figure~\ref{fig:tree-dblp-2}. This tree shows $9$ ranks in total. Our algorithm  first partitions the  publications based on whether the title contains the word, \emph{algorithm}, suggesting  that the papers which contain word, \emph{algorithm} are cited more by the papers which does not contain the word, \emph{algorithm}.  Likewise, this label tree postulates that the publications which contain the words,  \emph{algorithm}, \emph{database}, and  \emph{discovering} are cited more by the publications which contain \emph{recommendation}, \emph{sequential}, and  \emph{network} in their titles.
