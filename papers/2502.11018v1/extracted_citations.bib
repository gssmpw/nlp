@article{ankner2024hydra,
  title={Hydra: Sequentially-dependent draft heads for medusa decoding},
  author={Ankner, Zachary and Parthasarathy, Rishab and Nrusimha, Aniruddha and Rinard, Christopher and Ragan-Kelley, Jonathan and Brandon, William},
  journal={arXiv preprint arXiv:2402.05109},
  year={2024}
}

@article{cai2024medusa,
  title={Medusa: Simple llm inference acceleration framework with multiple decoding heads},
  author={Cai, Tianle and Li, Yuhong and Geng, Zhengyang and Peng, Hongwu and Lee, Jason D and Chen, Deming and Dao, Tri},
  journal={arXiv preprint arXiv:2401.10774},
  year={2024}
}

@article{chen2023cascade,
  title={Cascade speculative drafting for even faster llm inference},
  author={Chen, Ziyi and Yang, Xiaocong and Lin, Jiacheng and Sun, Chenkai and Chang, Kevin Chen-Chuan and Huang, Jie},
  journal={arXiv preprint arXiv:2312.11462},
  year={2023}
}

@article{chen2024sequoia,
  title={Sequoia: Scalable, robust, and hardware-aware speculative decoding},
  author={Chen, Zhuoming and May, Avner and Svirschevski, Ruslan and Huang, Yuhsun and Ryabinin, Max and Jia, Zhihao and Chen, Beidi},
  journal={arXiv preprint arXiv:2402.12374},
  year={2024}
}

@article{cheng2024recurrent,
  title={Recurrent drafter for fast speculative decoding in large language models},
  author={Cheng, Yunfei and Zhang, Aonan and Zhang, Xuanyu and Wang, Chong and Wang, Yi},
  journal={arXiv preprint arXiv:2403.09919},
  year={2024}
}

@article{du2024glide,
  title={Glide with a cape: A low-hassle method to accelerate speculative decoding},
  author={Du, Cunxiao and Jiang, Jing and Yuanchen, Xu and Wu, Jiawei and Yu, Sicheng and Li, Yongqi and Li, Shenggui and Xu, Kai and Nie, Liqiang and Tu, Zhaopeng and others},
  journal={arXiv preprint arXiv:2402.02082},
  year={2024}
}

@article{fu2024break,
  title={Break the sequential dependency of llm inference using lookahead decoding},
  author={Fu, Yichao and Bailis, Peter and Stoica, Ion and Zhang, Hao},
  journal={arXiv preprint arXiv:2402.02057},
  year={2024}
}

@article{gui2024boosting,
  title={Boosting Lossless Speculative Decoding via Feature Sampling and Partial Alignment Distillation},
  author={Gui, Lujun and Xiao, Bin and Su, Lei and Chen, Weipeng},
  journal={arXiv preprint arXiv:2408.15562},
  year={2024}
}

@article{he2023rest,
  title={Rest: Retrieval-based speculative decoding},
  author={He, Zhenyu and Zhong, Zexuan and Cai, Tianle and Lee, Jason D and He, Di},
  journal={arXiv preprint arXiv:2311.08252},
  year={2023}
}

@article{kim2024speculative,
  title={Speculative decoding with big little decoder},
  author={Kim, Sehoon and Mangalam, Karttikeya and Moon, Suhong and Malik, Jitendra and Mahoney, Michael W and Gholami, Amir and Keutzer, Kurt},
  journal={Advances in Neural Information Processing Systems},
  volume={36},
  year={2024}
}

@article{kou2024cllms,
  title={Cllms: Consistency large language models},
  author={Kou, Siqi and Hu, Lanxiang and He, Zhezhi and Deng, Zhijie and Zhang, Hao},
  journal={arXiv preprint arXiv:2403.00835},
  year={2024}
}

@article{li2024eagle,
  title={Eagle: Speculative sampling requires rethinking feature uncertainty},
  author={Li, Yuhui and Wei, Fangyun and Zhang, Chao and Zhang, Hongyang},
  journal={arXiv preprint arXiv:2401.15077},
  year={2024}
}

@article{li2024eagle2,
  title={Eagle-2: Faster inference of language models with dynamic draft trees},
  author={Li, Yuhui and Wei, Fangyun and Zhang, Chao and Zhang, Hongyang},
  journal={arXiv preprint arXiv:2406.16858},
  year={2024}
}

@article{liu2023online,
  title={Online speculative decoding},
  author={Liu, Xiaoxuan and Hu, Lanxiang and Bailis, Peter and Cheung, Alvin and Deng, Zhijie and Stoica, Ion and Zhang, Hao},
  journal={arXiv preprint arXiv:2310.07177},
  year={2023}
}

@inproceedings{miao2024specinfer,
  title={Specinfer: Accelerating large language model serving with tree-based speculative inference and verification},
  author={Miao, Xupeng and Oliaro, Gabriele and Zhang, Zhihao and Cheng, Xinhao and Wang, Zeyu and Zhang, Zhengxin and Wong, Rae Ying Yee and Zhu, Alan and Yang, Lijie and Shi, Xiaoxiang and others},
  booktitle={Proceedings of the 29th ACM International Conference on Architectural Support for Programming Languages and Operating Systems, Volume 3},
  pages={932--949},
  year={2024}
}

@misc{saxena2023prompt,
    title = {Prompt Lookup Decoding},
    author = {Apoorv Saxena},
    year = {2023},
    month = {November},
    url = {https://github.com/apoorvumang/prompt-lookup-decoding/}
}

@article{sun2024spectr,
  title={Spectr: Fast speculative decoding via optimal transport},
  author={Sun, Ziteng and Suresh, Ananda Theertha and Ro, Jae Hun and Beirami, Ahmad and Jain, Himanshu and Yu, Felix},
  journal={Advances in Neural Information Processing Systems},
  volume={36},
  year={2024}
}

@article{svirschevski2024specexec,
  title={SpecExec: Massively Parallel Speculative Decoding for Interactive LLM Inference on Consumer Devices},
  author={Svirschevski, Ruslan and May, Avner and Chen, Zhuoming and Chen, Beidi and Jia, Zhihao and Ryabinin, Max},
  journal={arXiv preprint arXiv:2406.02532},
  year={2024}
}

@article{zeng2024chimera,
  title={Chimera: A Lossless Decoding Method for Accelerating Large Language Models Inference by Fusing all Tokens},
  author={Zeng, Ziqian and Yu, Jiahong and Pang, Qianshi and Wang, Zihao and Zhuang, Huiping and Shao, Hongen and Zou, Xiaofeng},
  journal={arXiv preprint arXiv:2402.15758},
  year={2024}
}

@article{zhang2024learning,
  title={Learning Harmonized Representations for Speculative Sampling},
  author={Zhang, Lefan and Wang, Xiaodan and Huang, Yanhua and Xu, Ruiwen},
  journal={arXiv preprint arXiv:2408.15766},
  year={2024}
}

@article{zhao2024ouroboros,
  title={Ouroboros: Speculative Decoding with Large Model Enhanced Drafting},
  author={Zhao, Weilin and Huang, Yuxiang and Han, Xu and Xiao, Chaojun and Liu, Zhiyuan and Sun, Maosong},
  journal={arXiv preprint arXiv:2402.13720},
  year={2024}
}

