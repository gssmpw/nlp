\section{Experiments}

\subsection{Experimental Settings}
\paragraph{Evaluation Metric} For our end-to-end evaluation, we employed a model-based assessment using GPT-4o, which involved assigning scores from 1 to 5 by comparing the reference answer with the final answer. Answers receiving scores of 4 or above were considered correct, and we subsequently calculate accuracy as the evaluation metric. For retrieval evaluation, we use recall as the metric.

\paragraph{Baselines and Oracle.} 
We selecte Nv-embed-V2\cite{lee2024nv} and ColQwen2\cite{faysse2024colpali} as the retrievers for the TextRAG and VisualRAG baselines, respectively. Based on their original settings, we choose the top-5 recall results as the generation input, which equals the average length of dynamic recall results. This ensures a fair comparison and highlights the advantages of our method. The \textbf{Oracle} serves as the upper bound performance, where the model responds based on the golden page without retrieval or other operations. 

\subsection{Main Results}
As shown in Table. \ref{tab:overall}, we conducted experiments on both closed-source and open-source models: GPT-4o, Qwen2.5-7B-Instruct, Qwen2.5-VL-7B\cite{yang2024qwen2}-Instruct, Llama3.2-Vision-90B-Instruct. Closed-source models generally outperform open-source models performance. 
It is worth mentioning that the qwen2.5-VL-7B has shown excellent instruction-following and reasoning capabilities within our framework. In contrast, we found that the llama3.2-VL requires 90B parameters to accomplish the same instructions, which may be related to the model's pre-training domain.
The results suggest that while API-based models offer strong baseline performance, our method is also effective in enhancing the performance of open-source models, offering promising potential for future applications. 
To further demonstrate the robustness of the framework, we constructed a pipeline using data to rewrite queries from SlideVQA\cite{tanaka2023slidevqa}, making the queries suitable for scenarios involving large corpora. The experimental results are presented the analysis.
