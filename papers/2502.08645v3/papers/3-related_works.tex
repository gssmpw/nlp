% \noindent\textbf{Multi-view 3D Reconstruction.}
% \todo{xiaoyang}

% We do not need this
% \noindent\textbf{Manipulation policy.}
% Recently, a series of algorithms have achieved impressive results in robotics manipulation tasks. Algorithms such as ACT~\citep{zhao2023learning}, Diffusion Policy~\citep{chi2023diffusion}, RVT~\citep{goyal2023rvt}, and 3D Diffusion Policy~\citep{ze20243d} have demonstrated strong performance on in-domain tasks even when trained on small-scale real-world datasets. Simultaneously, algorithms~\citep{li2023vision, brohan2022rt,o2023open, kim2024openvla,wu2023unleashing,cheang2024gr2generativevideolanguageactionmodel, tian2024seer} leverage pre-trained datasets to train models that exhibit generalization across multiple tasks and diverse scenarios. Meanwhile, many algorithms utilizing pre-trained vision language models to finish robotics tasks, such as R3M~\citep{nairr3m}, MVP~\citep{xiao2022mvp,radosavovic2023mvp}, VIP~\citep{ma2023vip}, and VC-1~\citep{majumdar2023vc1} pre-trained the vision models on ego-centric dataset~\citep{grauman2022ego4d}. 

% object-centric human motion dataset
% robot dataset

% \todo{Real-to-Real?}

\section{Related Work}
\noindent\textbf{Sim-to-real.}
Sim-to-real transfer requires techniques to enable policies to successfully adapt from simulation to the real world. The most direct approach is improving simulators \citep{todorov2012mujoco, makoviychuk2021isaac, mittal2023orbit, Xiang_2020_SAPIEN}, which reduces the sim-to-real gap. Other methods, such as domain randomization~\citep{tobin2017domain, mehta2020active, chen2021understanding, tremblay2018training, loquercio2019deep, tobin2018domain} and system identification~\citep{ramaswamy2024adaptation, allevato2020iterative, song2024systemid, pmlr-v100-allevato20a}, also aim to bridge this gap.

\noindent\textbf{Real-to-sim-to-real.}
Many recent works leverage real-world data to enhance simulation models. Reconstruction methods integrated with grasping techniques, such as Evo-NeRF~\citep{kerr2023evo} and LERF-TOGO~\citep{lerftogo2023}, enable the grasping of objects using only RGB images. 
% Prior approaches, such as GraspNerf~\citep{dai2023graspnerf}, introduced a generalizable NeRF that achieves real-time grasping. Other works, including Evo-NeRF~\citep{kerr2023evo} and LERF-TOGO~\citep{lerftogo2023}, utilize depth images rendered by NeRF to generate grasping poses.
% Specifically, LERF-TOGO leverages depth information from multiple views to create a dense point cloud, which is subsequently processed by GraspNet~\citep{fang2020graspnet}.
% Recently, 3D Gaussian splatting~\citep{kerbl3Dgaussians} has gained significant attention in robotics due to its fast rendering speed and explicit representation. GaussianGrasper~\citep{zheng2024gaussiangrasper} uses 3DGS for scene reconstruction and normal-guided grasp generation. Similarly, SplatMover~\citep{shorinwa2024splat} introduces a grasp-splat module integrating affordance and semantics within 3DGS. GraspSplats~\citep{ji2024graspsplats} replaces object representation in earlier grasping networks with 3DGS.
Meanwhile, GaussianGrasper~\citep{zheng2024gaussiangrasper}, SplatMover~\citep{shorinwa2024splat}, and GraspSplats~\citep{ji2024graspsplats}, use 3D Gaussian splatting~\citep{kerbl3Dgaussians} for fast rendering and explicit representation in robotics tasks. Additionally, methods like URDFormer~\citep{urdformer}, Digital Cousins~\citep{acdcdai2024}, and Articulate Anything~\citep{articulateanythingle2024} use a single image to reconstruct the environment directly, allowing for collecting large amounts of data for imitation learning or reinforcement learning. These approaches enhance data by varying articulations and leveraging various articulations from simulation datasets to train models deployable in the real world.

% Another approach involves constructing a simulator with a smaller sim-to-real gap using real2sim methods. This allows for the collection of large amounts of data in the simulator for imitation learning or the use of reinforcement learning to interact with the environment, training an end-to-end model rather than using a scripted policy as the actuator. Specifically, URDFormer~\citep{urdformer}, Digital Cousins~\citep{acdcdai2024}, and Articulate Anything~\citep{articulateanythingle2024} use a single image to reconstruct the environment. 
% URDFormer utilizes URDF as a representation, employing generative models to create a photo-URDF dataset, thereby training models to generate URDFs from images. Digital Cousin and Articulate-Anything retrieve similar meshes from datasets to construct scenes in simulation.
% They enhance their data by using different articulations of similar sizes from simulation datasets, and by collecting a large amount of data similar to real environments in geometry and semantics, they train models that are able to be deployed in the real world. 

With the help of 3DGS works like RoboStudio~\citep{robostudio}, SplatSim~\citep{qureshi2024splatsim}
and RoboGSim~\citep{li2024robogsim} use multi-view images or video for world reconstruction, improving multi-view rendering quality with minimal cost. These methods are especially effective in manipulation tasks involving multiple objects or occlusions. 1) RoboStudio focuses on reconstructing the URDF of a robot, offering a photorealistic rendering result and accurate collision mesh.
2) SplatSim utilizes pre-obtained 3D models of objects and backgrounds to collect trajectories in the physics simulator and then re-render them with 3DGS to reduce the visual gap between simulated and real-world environments, but acquiring the 3D models is hard for many tasks. 
3) RoboGSim compares rendering quality, validates high-quality rendering results for novel pose synthesis, and shows the potential for evaluating various manipulation algorithms. However, its sim-to-real validation remains limited.
Different from them, \our reconstructs both geometric and visual aspects with small gaps, and validates robot policies trained on simulated data through extensive experiments in the real world.



% We also includes a simple and efficient alignment method, allowing the integration of objects from various sources. 


% GRS\citep{zook2024grs}
% \noindent{\textbf{3D Recontruction for Robotic Manipution}}
% simply introduce Gaussian splatting
% Gaussian splatting~\citep{kerbl3Dgaussians}, a powerful approach allowing real-time, high-quality radiance field rendering, has been recently applied in robotics manipulation~\citep{lou2024robo, qiu2024feature, qureshi2024splatsim, lu2024manigaussian, abou2024physically}.  



% \todo{Difference between 3D gaussian splitting for object grasping}

% TODO: Mani gaussian (haven't finished reading)
% For instance, ManiGaussian~\citep{lu2024manigaussian} estimates the propagation of diverse semantic features within the Gaussian embedding space to help improve multi-task robotic manipulation.
% For instance, R2SGrasp~\citep{r2sgrasp} employs a real2sim approach to integrate a repair module and an enhancer as part of the model, enabling it to handle noisy real-world RGBD inputs effectively.

% \begin{table}[t]
% \setlength{\tabcolsep}{0pt}
%     \centering
%     \caption{\textbf{Comparison with Existing Tabletop Manipulation Frameworks in Robotics.} ``S.G.'' represents the scene graph-based evaluation. \todo{looks like gembench table}}
%     \resizebox{\textwidth}{!}{%
%         \begin{tabular}{l|cccc}
%         \toprule

%         \textbf{Simulators}
%         & \begin{tabular}[c]{@{}c@{}}\rotatebox{30}{\textbf{\method}\end{tabular}
%         & \begin{tabular}[c]{@{}c@{}}\rotatebox{30}{\textbf{RialTo}~\citep{ritotorne2024rialto}}}\end{tabular}
%         &
%         &
        
%         \\ \midrule
%         %  \todo{} & Isaac Sim & Mujuco & RLBench & AI2-THOR & PyBullet & PyBullet & Isaac Sim & Ravens & RLBench & RLBench \\
%         High-fidelity rendering & - & - & - & - \\
%         Auto-align & \\
%         % \# Articulated Objects & - & - & - & - & - & - & - & - & - \\
%         no-real demo & - & - & - & - & - & - & - & - & - \\
%         object-level extensible & - & - & - & - & - & - & - & - & - \\
%         \# Common Sense & - & - & - & - & - & - & - & - & - \\
%         \# Long Horizon & - & - & - & - & - & - & - & - & - \\
%         \# AI-generated Scenarios & - & - & - & - & - & - & - & - & - \\
%         \# AI-generated Demo & - & - & - & - & - & - & - & - & - \\
%         Benchmark & \greencheck & \redcross & \redcross & \redcross & \redcross & &  \redcross & \redcross & \redcross & \redcross & \redcross \\
%         RayTracing & \greencheck &  & \redcross & \redcross & \redcross & &  \redcross & \redcross & \redcross & \redcross & \redcross \\
%         Evaluation Method & Scene Graph & - & - & - & - & - & - & - & - & \\
%         \bottomrule
%         \end{tabular}
%     }
%     \label{tab:benchmark_comparison_transposed}
% \end{table}