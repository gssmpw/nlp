\section{Related Work}
\label{sec:ref}
\subsection{LLM Agents}
To the benefit of the versatility of LLMs, many researchers (see \cite{xi2023rise, guo2024large, li2024personal}) utilized LLMs as the foundation to build AI agents that adapt to diverse scenarios. Treating LLMs as universal approximate knowledge sources with reasonable randomness, some researchers (see \cite{chen2024can,gundawar2024robust,song2023llm,kambhampati2024llms}) investigated the way to leverage LLMs to facilitate the planning or reasoning tasks. Other researchers (see \cite{singh2021pre}) tried to integrate LLMs into gaming scenarios, mimicking human players to interact with virtual worlds with sufficient environmental understanding. 
Besides single agents, some researchers (see \cite{park2023generative, gong2023mindagent, abdelnabi2023llm}) considered the collaboration of multiple agents powered by LLMs, targeting believable simulations of human behavior with proposed frameworks.
However, these are not designed for XR environments that are characterized by natural interactions among human users, virtual content, and real-world environments.


\subsection{LLM in XR}
The fusion of LLM with XR environments significantly facilitates human interaction within XR environments. Researchers have raised interest in how to provide seamless integration with more convenient and powerful interactions compared with specific hand gestures or menus. Authors in \cite{fang2024enabling} simplified robotic programming by enabling LLM for prompt processing and AR for visualizing the generated waypoints. DreamCodeVR \cite{giunchi2024dreamcodevr}, powered by LLM, assists users in programming VR environments by translating spoken language into code, simplifying VR development, and enhancing accessibility for users of varying technical skills. LLMR \cite{de2023llmr} facilitates the real-time creation and modification of interactive XR experiences, leveraging novel strategies and the Unity game engine to handle complex scenarios with limited ideal training data.  PaLM-E \cite{driess2023palm} incorporated real-world continuous sensor modalities into language models. MagicItem \cite{kurai2024magicitem} integrated cluster scripts into LLMs to accelerate the generation. However, all of them are code-based designs, which usually suffer from the hallucination issue of LLMs and potentially lead to crashes of applications.
Authors in \cite{huang2023real} utilized LLM to generate and control real-time animations created by parsing structured strings that define joint movements demonstrated across various models and motions. However, they did not consider the deep fusion with the XR environments while our work provides a seamless integration for better interactions with human users.


\subsection{3D Objects and Interactive Environment}
Users in XR environments often require the creation of 3D objects for an enhanced immersive experience. Recent studies have put efforts into how to dynamically create 3D objects based on users' requests.
DreamFusion \cite{poole2022dreamfusion} generated high-fidelity coherent 3D objects and scenes for a diverse set of user-provided text prompts. Subsequently, Magic3D \cite{lin2023magic3d} was introduced to create high-quality 3D models faster than previous methods such as DreamFusion. In addition to generating objects, the creation of interactive 3D environments has been further explored. Chat-3D \cite{wang2023chat} is the dialogue system for 3D scenes, which combines LLM and 3D representations to comprehend diverse instructions for 3D scenes. 3D-LLM \cite{hong20233d} performed better on capturing 3D spatial information after introducing a 3D localization mechanism to training. However, those approaches usually pose significant generation delays and are difficult to integrate into real-time systems.