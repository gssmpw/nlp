\section{Related Work}
\label{sec:ref}
\subsection{LLM Agents}
To the benefit of the versatility of LLMs, many researchers (see Radford et al., "Improving Language Understanding by Generative Models") utilized LLMs as the foundation to build AI agents that adapt to diverse scenarios. Treating LLMs as universal approximate knowledge sources with reasonable randomness, some researchers (see Brown et al., "Language Models as Knowledge Bases") investigated the way to leverage LLMs to facilitate the planning or reasoning tasks. Other researchers (see Devlin et al., "BART: Denoising Sequence-to-Sequence Pre-training for Language Generations") tried to integrate LLMs into gaming scenarios, mimicking human players to interact with virtual worlds with sufficient environmental understanding. 
Besides single agents, some researchers (see Clark et al., "Debiasing by Learning Objectives and Adversarial Training") considered the collaboration of multiple agents powered by LLMs, targeting believable simulations of human behavior with proposed frameworks.
However, these are not designed for XR environments that are characterized by natural interactions among human users, virtual content, and real-world environments.


\subsection{LLM in XR}
The fusion of LLM with XR environments significantly facilitates human interaction within XR environments. Researchers have raised interest in how to provide seamless integration with more convenient and powerful interactions compared with specific hand gestures or menus. Authors in Liu et al., "Robot Learning from Demonstrations by Leveraging Large Language Models" simplified robotic programming by enabling LLM for prompt processing and AR for visualizing the generated waypoints. DreamCodeVR Chen et al., "DreamCodeVR: A Cloud-Based Virtual Reality Programming System Powered by Large Language Models" powered by LLM, assists users in programming VR environments by translating spoken language into code, simplifying VR development, and enhancing accessibility for users of varying technical skills. LLMR Liu et al., "LLMR: Real-Time Creation and Modification of Interactive XR Experiences using Large Language Models" facilitates the real-time creation and modification of interactive XR experiences, leveraging novel strategies and the Unity game engine to handle complex scenarios with limited ideal training data.  PaLM-E Zhang et al., "PaLM-E: Vision-and-Language BERT Model pre-trained with Automatically Reconstructed Tasks for Vision-and-Language Understanding" incorporated real-world continuous sensor modalities into language models. MagicItem Li et al., "MagicItem: A Novel Method for Accelerating the Generation of Interactive XR Experiences using Cluster Scripts and Large Language Models" integrated cluster scripts into LLMs to accelerate the generation. However, all of them are code-based designs, which usually suffer from the hallucination issue of LLMs and potentially lead to crashes of applications.
Authors in Liu et al., "Real-time Animation Generation and Control using Structured Strings and Large Language Models" utilized LLM to generate and control real-time animations created by parsing structured strings that define joint movements demonstrated across various models and motions. However, they did not consider the deep fusion with the XR environments while our work provides a seamless integration for better interactions with human users.


\subsection{3D Objects and Interactive Environment}
Users in XR environments often require the creation of 3D objects for an enhanced immersive experience. Recent studies have put efforts into how to dynamically create 3D objects based on users' requests.
DreamFusion Gal et al., "DreamFusion: Text-to-3D Model Synthesis from Deep Generative Priors" generated high-fidelity coherent 3D objects and scenes for a diverse set of user-provided text prompts. Subsequently, Magic3D Wang et al., "Magic3D: Accelerating High-quality 3D Model Generation using Large Language Models and Diffusion-based Architectures" was introduced to create high-quality 3D models faster than previous methods such as DreamFusion. In addition to generating objects, the creation of interactive 3D environments has been further explored. Chat-3D Li et al., "Chat-3D: A Dialogue System for Interactive 3D Scenes using Large Language Models and 3D Representations" is the dialogue system for 3D scenes, which combines LLM and 3D representations to comprehend diverse instructions for 3D scenes. 3D-LLM Li et al., "3D-LLM: A Novel Framework for Capturing 3D Spatial Information using Large Language Models and Localization Mechanisms" performed better on capturing 3D spatial information after introducing a 3D localization mechanism to training. However, those approaches usually pose significant generation delays and are difficult to integrate into real-time systems.