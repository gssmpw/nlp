@string{ICCV="ICCV"}
@string{CVPR="CVPR"}
@string{NIPS="NeurIPS"}
@string{WACV="WACV"}
@string{ECCV="ECCV"}
@string{BMVC="BMVC"}
@string{ICML="ICML"}
@string{ICLR="ICLR"}
@string{ICASSP="ICASSP"}
@string{AISTATS="AISTATS"}
@string{IJCV="IJCV"}
@string{CIVR="CIVR"}
@string{IJRR="IJRR"}
@string{FACCT="FAcct"}
@string{ICVGIP="ICVGIP"}
@string{TPAMI="TPAMI"}
@string{TMLR="TMLR"}
@string{LREC="LREC"}
@string{ICPR="ICPR"}
@string{PMLR="PMLR"}
@string{JMLR="JMLR"}
@string{EMNLP="EMNLP"}
@string{ICNLP="ICNLP"}


@article{huber1964robust,
  title   = {Robust Estimation of a Location Parameter},
  author  = {Huber, Peter J},
  journal = {Ann. Math. Statist.},
  volume  = {35},
  number  = {4},
  pages   = {73--101},
  year    = {1964}
}

@inproceedings{jaegle2021perceiver,
  title     = {Perceiver: General perception with iterative attention},
  author    = {Jaegle, Andrew and Gimeno, Felix and Brock, Andy and Vinyals, Oriol and Zisserman, Andrew and Carreira, Joao},
  booktitle = ICML,
  year      = {2021}
}

@inproceedings{wang2023cut,
  title     = {Cut and learn for unsupervised object detection and instance segmentation},
  author    = {Wang, Xudong and Girdhar, Rohit and Yu, Stella X and Misra, Ishan},
  booktitle = CVPR,
  year      = {2023}
}

@article{dinov2,
  title   = {DINOv2: Learning robust visual features without supervision},
  author  = {Oquab, Maxime and Darcet, Timoth{\'e}e and Moutakanni, Th{\'e}o and Vo, Huy and Szafraniec, Marc and Khalidov, Vasil and Fernandez, Pierre and Haziza, Daniel and Massa, Francisco and El-Nouby, Alaaeldin and others},
  journal = TMLR,
  year    = {2024}
}

@inproceedings{goyal2017something,
  title     = {The "something something" video database for learning and evaluating visual common sense},
  author    = {Goyal, Raghav and Ebrahimi Kahou, Samira and Michalski, Vincent and Materzynska, Joanna and Westphal, Susanne and Kim, Heuna and Haenel, Valentin and Fruend, Ingo and Yianilos, Peter and Mueller-Freitag, Moritz and others},
  booktitle = ICCV,
  year      = {2017}
}

@article{kay2017kinetics,
  title   = {The kinetics human action video dataset},
  author  = {Kay, Will and Carreira, Joao and Simonyan, Karen and Zhang, Brian and Hillier, Chloe and Vijayanarasimhan, Sudheendra and Viola, Fabio and Green, Tim and Back, Trevor and Natsev, Paul and others},
  journal = {arXiv},
  year    = {2017}
}

@article{soomro2012ucf101,
  title   = {UCF101: A dataset of 101 human actions classes from videos in the wild},
  author  = {Soomro, Khurram and Zamir, Amir Roshan and Shah, Mubarak},
  journal = {arXiv},
  year    = {2012}
}

@inproceedings{zhou2017scene,
  title     = {Scene parsing through ade20k dataset},
  author    = {Zhou, Bolei and Zhao, Hang and Puig, Xavier and Fidler, Sanja and Barriuso, Adela and Torralba, Antonio},
  booktitle = CVPR,
  year      = {2017}
}

@inproceedings{barbu2019objectnet,
  title     = {Objectnet: A large-scale bias-controlled dataset for pushing the limits of object recognition models},
  author    = {Barbu, Andrei and Mayo, David and Alverio, Julian and Luo, William and Wang, Christopher and Gutfreund, Dan and Tenenbaum, Josh and Katz, Boris},
  booktitle = NIPS,
  year      = {2019}
}

@inproceedings{cordts2016cityscapes,
  title     = {The cityscapes dataset for semantic urban scene understanding},
  author    = {Cordts, Marius and Omran, Mohamed and Ramos, Sebastian and Rehfeld, Timo and Enzweiler, Markus and Benenson, Rodrigo and Franke, Uwe and Roth, Stefan and Schiele, Bernt},
  booktitle = CVPR,
  year      = {2016}
}

@article{radford2017learning,
  title   = {Learning to generate reviews and discovering sentiment},
  author  = {Radford, Alec and Jozefowicz, Rafal and Sutskever, Ilya},
  journal = {arXiv},
  year    = {2017}
}

@inproceedings{zhou2022understanding,
  title        = {Understanding the robustness in vision transformers},
  author       = {Zhou, Daquan and Yu, Zhiding and Xie, Enze and Xiao, Chaowei and Anandkumar, Animashree and Feng, Jiashi and Alvarez, Jose M},
  booktitle    = {International Conference on Machine Learning},
  pages        = {27378--27394},
  year         = {2022},
  organization = {PMLR}
}

@inproceedings{ng2020solar,
  title        = {SOLAR: second-order loss and attention for image retrieval},
  author       = {Ng, Tony and Balntas, Vassileios and Tian, Yurun and Mikolajczyk, Krystian},
  booktitle    = {European conference on computer vision},
  pages        = {253--270},
  year         = {2020},
  organization = {Springer}
}

@inproceedings{tian2021divide,
  title     = {Divide and contrast: Self-supervised learning from uncurated data},
  author    = {Tian, Yonglong and Henaff, Olivier J and van den Oord, A{\"a}ron},
  booktitle = {ICCV},
  year      = {2021}
}

@article{henaff2022object,
  title   = {Object discovery and representation networks},
  author  = {H{\'e}naff, Olivier J and Koppula, Skanda and Shelhamer, Evan and Zoran, Daniel and Jaegle, Andrew and Zisserman, Andrew and Carreira, Jo{\~a}o and Arandjelovi{\'c}, Relja},
  journal = {arXiv},
  year    = {2022}
}

@article{yalniz2019billion,
  title   = {Billion-scale semi-supervised learning for image classification},
  author  = {Yalniz, I Zeki and J{\'e}gou, Herv{\'e} and Chen, Kan and Paluri, Manohar and Mahajan, Dhruv},
  journal = {arXiv},
  year    = {2019}
}

@article{goyal2022vision,
  title   = {Vision Models Are More Robust And Fair When Pretrained On Uncurated Images Without Supervision},
  author  = {Goyal, Priya and Duval, Quentin and Seessel, Isaac and Caron, Mathilde and Singh, Mannat and Misra, Ishan and Sagun, Levent and Joulin, Armand and Bojanowski, Piotr},
  journal = {arXiv},
  year    = {2022}
}

@inproceedings{gupta2019lvis,
  title     = {{LVIS}: A Dataset for Large Vocabulary Instance Segmentation},
  author    = {Gupta, Agrim and Dollar, Piotr and Girshick, Ross},
  booktitle = {Proceedings of the {IEEE} Conference on Computer Vision and Pattern Recognition},
  year      = {2019}
}

@inproceedings{ibot,
  title     = {iBOT: Image bert pre-training with online tokenizer},
  author    = {Zhou, Jinghao and Wei, Chen and Wang, Huiyu and Shen, Wei and Xie, Cihang and Yuille, Alan and Kong, Tao},
  booktitle = ICLR,
  year      = {2022}
}

@inproceedings{he2021masked,
  title     = {Masked autoencoders are scalable vision learners},
  author    = {He, Kaiming and Chen, Xinlei and Xie, Saining and Li, Yanghao and Doll{\'a}r, Piotr and Girshick, Ross},
  booktitle = CVPR,
  year      = {2022}
}

@article{junnan2021prototypical,
  title   = {Prototypical Contrastive Learning of Unsupervised Representations},
  author  = {Junnan Li and Pan Zhou and Caiming Xiong and Steven C.H. Hoi},
  journal = {ICLR},
  year    = {2021}
}

@inproceedings{noroozi2018boosting,
  title     = {Boosting self-supervised learning via knowledge transfer},
  author    = {Noroozi, Mehdi and Vinjimoor, Ananth and Favaro, Paolo and Pirsiavash, Hamed},
  booktitle = CVPR,
  year      = {2018}
}

@inproceedings{eva,
  title     = {Eva: Exploring the limits of masked visual representation learning at scale},
  author    = {Fang, Yuxin and Wang, Wen and Xie, Binhui and Sun, Quan and Wu, Ledell and Wang, Xinggang and Huang, Tiejun and Wang, Xinlong and Cao, Yue},
  booktitle = CVPR,
  year      = {2023}
}

@inproceedings{fang2021seed,
  title     = {SEED: Self-supervised Distillation For Visual Representation},
  author    = {Fang, Zhiyuan and Wang, Jianfeng and Wang, Lijuan and Zhang, Lei and Yang, Yezhou and Liu, Zicheng},
  booktitle = ICLR,
  year      = {2021}
}

@article{xu2021seed,
  title   = {Seed the Views: Hierarchical Semantic Alignment for Contrastive Representation Learning},
  author  = {Xu, Haohang and Zhang, Xiaopeng and Li, Hao and Xie, Lingxi and Xiong, Hongkai and Tian, Qi},
  journal = {arXiv},
  year    = {2021}
}

@inproceedings{weinzaepfel2021learning,
  title     = {Learning Super-Features for Image Retrieval},
  author    = {Weinzaepfel, Philippe and Lucas, Thomas and Larlus, Diane and Kalantidis, Yannis},
  booktitle = ICLR,
  year      = {2021}
}

@article{radenovic2018fine,
  title   = {Fine-tuning CNN image retrieval with no human annotation},
  author  = {Radenovi{\'c}, Filip and Tolias, Giorgos and Chum, Ond{\v{r}}ej},
  journal = TPAMI,
  year    = {2018}
}

@article{gidaris2020obow,
  title   = {Online Bag-of-Visual-Words Generation for Unsupervised Representation Learning},
  author  = {Gidaris, Spyros and Bursuc, Andrei and Puy, Gilles and Komodakis, Nikos and Cord, Matthieu and P{\'e}rez, Patrick},
  journal = {arXiv},
  year    = {2020}
}

@article{berman2019multigrain,
  title   = {{{MultiGrain}: a unified image embedding for classes and instances}},
  author  = {Berman, Maxim and J{\'e}gou, Herv{\'e} and Vedaldi Andrea and Kokkinos, Iasonas and Douze, Matthijs},
  journal = {arXiv},
  year    = {2019}
}

% Use 2016 version below
article{thomee2015yfcc100m,
  title={{YFCC100M:} The new data in multimedia research},
  author={Thomee, Bart and Shamma, David A. and Friedland, Gerald and Elizalde, Benjamin and Ni, Karl and Poland, Douglas and Borth, Damian and Li, Li-Jia},
  journal={arXiv},
  year={2015}
}

@article{zhou2022mugs,
  title   = {Mugs: A multi-granular self-supervised learning framework},
  author  = {Zhou, Pan and Zhou, Yichen and Si, Chenyang and Yu, Weihao and Ng, Teck Khim and Yan, Shuicheng},
  journal = {arXiv},
  year    = {2022}
}

@article{thomee2016yfcc100m,
  title   = {YFCC100M: The New Data in Multimedia Research},
  author  = {Thomee, Bart and Shamma, David A. and Friedland, Gerald and Elizalde, Benjamin and Ni, Karl and Poland, Douglas and Borth, Damian and Li, Li-Jia},
  journal = {Communications of the ACM},
  volume  = {59},
  number  = {2},
  year    = {2016},
  pages   = {64--73}
}

@inproceedings{douze2009evaluation,
  title     = {Evaluation of gist descriptors for web-scale image search},
  author    = {Douze, Matthijs and J{\'e}gou, Herv{\'e} and Sandhawalia, Harsimrat and Amsaleg, Laurent and Schmid, Cordelia},
  booktitle = CIVR,
  year      = {2009}
}

@article{sariyildiz2020concept,
  title   = {Concept generalization in visual representation learning},
  author  = {Sariyildiz, Mert Bulent and Kalantidis, Yannis and Larlus, Diane and Alahari, Karteek},
  journal = {arXiv},
  year    = {2020}
}

@inproceedings{tolias2015particular,
  title     = {Particular object retrieval with integral max-pooling of CNN activations},
  author    = {Tolias, Giorgos and Sicre, Ronan and J{\'e}gou, Herv{\'e}},
  booktitle = ICLR,
  year      = {2016}
}

@inproceedings{revaud2019learning,
  title     = {Learning with average precision: Training image retrieval with a listwise loss},
  author    = {Revaud, Jerome and Almaz{\'a}n, Jon and Rezende, Rafael S and Souza, Cesar Roberto de},
  booktitle = ICCV,
  year      = {2019}
}

@inproceedings{weyand2020google,
  title     = {Google Landmarks Dataset v2 -- A Large-Scale Benchmark for Instance-Level Recognition and Retrieval},
  author    = {Weyand, Tobias and Araujo, Andre and Cao, Bingyi and Sim, Jack},
  booktitle = CVPR,
  year      = {2020}
}

@inproceedings{philbin2008lost,
  title     = {Lost in quantization: Improving particular object retrieval in large scale image databases},
  author    = {Philbin, James and Chum, Ondrej and Isard, Michael and Sivic, Josef and Zisserman, Andrew},
  booktitle = CVPR,
  year      = {2008}
}

@inproceedings{radenovic2018revisiting,
  title     = {Revisiting Oxford and Paris: Large-scale image retrieval benchmarking},
  author    = {Radenovi{\'c}, Filip and Iscen, Ahmet and Tolias, Giorgos and Avrithis, Yannis and Chum, Ond{\v{r}}ej},
  booktitle = CVPR,
  year      = {2018}
}


@inproceedings{beit,
  title     = {BEiT: BERT Pre-Training of Image Transformers},
  author    = {Bao, Hangbo and Dong, Li and Wei, Furu},
  booktitle = ICLR,
  year      = {2021}
}

@article{xie2021simmim,
  title   = {Simmim: A simple framework for masked image modeling},
  author  = {Xie, Zhenda and Zhang, Zheng and Cao, Yue and Lin, Yutong and Bao, Jianmin and Yao, Zhuliang and Dai, Qi and Hu, Han},
  journal = {arXiv},
  year    = {2021}
}

@inproceedings{simeoni2021localizing,
  title     = {Localizing Objects with Self-Supervised Transformers and no Labels},
  author    = {Sim{\'e}oni, Oriane and Puy, Gilles and Vo, Huy V and Roburin, Simon and Gidaris, Spyros and Bursuc, Andrei and P{\'e}rez, Patrick and Marlet, Renaud and Ponce, Jean},
  booktitle = BMVC,
  year      = {2021}
}

@inproceedings{schwenk2018filtering,
  title     = {Filtering and Mining Parallel Data in a Joint Multilingual Space},
  author    = {Schwenk, Holger},
  booktitle = {Proc. ACL},
  year      = {2018}
}

@inproceedings{schwenk2021wikimatrix,
  title     = {WikiMatrix: Mining 135M Parallel Sentences in 1620 Language Pairs from Wikipedia},
  author    = {Schwenk, Holger and Chaudhary, Vishrav and Sun, Shuo and Gong, Hongyu and Guzm{\'a}n, Francisco},
  booktitle = {Proc. EACL},
  year      = {2021}
}

@article{dwibedi2021little,
  title   = {With a little help from my friends: Nearest-neighbor contrastive learning of visual representations},
  author  = {Dwibedi, Debidatta and Aytar, Yusuf and Tompson, Jonathan and Sermanet, Pierre and Zisserman, Andrew},
  journal = {arXiv},
  year    = {2021}
}

@article{schwenk2019ccmatrix,
  title   = {Ccmatrix: Mining billions of high-quality parallel sentences on the web},
  author  = {Schwenk, Holger and Wenzek, Guillaume and Edunov, Sergey and Grave, Edouard and Joulin, Armand},
  journal = {arXiv},
  year    = {2019}
}

@inproceedings{pinheiro2020unsupervised,
  title     = {Unsupervised Learning of Dense Visual Representations},
  author    = {Pinheiro, Pedro O and Almahairi, Amjad and Benmaleck, Ryan Y and Golemo, Florian and Courville, Aaron},
  booktitle = NIPS,
  year      = {2020}
}

@inproceedings{jabri2020space,
  title     = {Space-time correspondence as a contrastive random walk},
  author    = {Jabri, Allan and Owens, Andrew and Efros, Alexei A},
  booktitle = NIPS,
  year      = {2020}
}

@article{polyak1992acceleration,
  title     = {Acceleration of stochastic approximation by averaging},
  author    = {Polyak, Boris T and Juditsky, Anatoli B},
  journal   = {SIAM journal on control and optimization},
  year      = {1992},
  publisher = {SIAM}
}

@article{asano2021pass,
  author  = {Yuki M. Asano and Christian Rupprecht and Andrew Zisserman and Andrea Vedaldi},
  title   = {PASS: An ImageNet replacement for self-supervised pretraining without humans},
  journal = {NeurIPS Track on Datasets and Benchmarks},
  year    = {2021}
}

@inproceedings{asano2019self,
  title     = {Self-labelling via simultaneous clustering and representation learning},
  author    = {Asano, Yuki Markus and Rupprecht, Christian and Vedaldi, Andrea},
  booktitle = ICLR,
  year      = {2020}
}


@inproceedings{deepcluster,
  title     = {Deep clustering for unsupervised learning of visual features},
  author    = {Caron, Mathilde and Bojanowski, Piotr and Joulin, Armand and Douze, Matthijs},
  booktitle = ECCV,
  year      = {2018}
}

@inproceedings{chen2021empirical,
  title     = {An empirical study of training self-supervised vision transformers},
  author    = {Chen, Xinlei and Xie, Saining and He, Kaiming},
  booktitle = ICCV,
  year      = {2021}
}

@article{el2021large,
  title   = {Are Large-scale Datasets Necessary for Self-Supervised Pre-training?},
  author  = {El-Nouby, Alaaeldin and Izacard, Gautier and Touvron, Hugo and Laptev, Ivan and Jegou, Herv{\'e} and Grave, Edouard},
  journal = {arXiv},
  year    = {2021}
}

@inproceedings{wu2018unsupervised,
  title     = {Unsupervised feature learning via non-parametric instance discrimination},
  author    = {Wu, Zhirong and Xiong, Yuanjun and Yu, Stella X and Lin, Dahua},
  booktitle = CVPR,
  year      = {2018}
}

@inproceedings{caron2019unsupervised,
  title     = {Unsupervised pre-training of image features on non-curated data},
  author    = {Caron, Mathilde and Bojanowski, Piotr and Mairal, Julien and Joulin, Armand},
  booktitle = ICCV,
  year      = {2019}
}

@inproceedings{lin2014microsoft,
  title     = {Microsoft coco: Common objects in context},
  author    = {Lin, Tsung-Yi and Maire, Michael and Belongie, Serge and Hays, James and Perona, Pietro and Ramanan, Deva and Doll{\'a}r, Piotr and Zitnick, C Lawrence},
  booktitle = ECCV,
  year      = {2014}
}

@inproceedings{he2017mask,
  title     = {Mask r-cnn},
  author    = {He, Kaiming and Gkioxari, Georgia and Doll{\'a}r, Piotr and Girshick, Ross},
  booktitle = ICCV,
  year      = {2017}
}

@article{you2017large,
  title   = {Large Batch Training of Convolutional Networks},
  author  = {Yang You and Igor Gitman and Boris Ginsburg},
  journal = {preprint arXiv:1708.03888},
  year    = {2017}
}

@article{mairal2019cyanure,
  title   = {Cyanure: An Open-Source Toolbox for Empirical Risk Minimization for Python, C++, and soon more},
  author  = {Julien Mairal},
  journal = {preprint arXiv:1912.08165},
  year    = {2019}
}

@inproceedings{touvron2019fixing,
  title     = {Fixing the train-test resolution discrepancy},
  author    = {Touvron, Hugo and Vedaldi, Andrea and Douze, Matthijs and J{\'e}gou, Herv{\'e}},
  booktitle = NIPS,
  year      = {2019}
}


@inproceedings{he2020momentum,
  title     = {Momentum contrast for unsupervised visual representation learning},
  author    = {He, Kaiming and Fan, Haoqi and Wu, Yuxin and Xie, Saining and Girshick, Ross},
  booktitle = CVPR,
  year      = {2020}
}

@inproceedings{misra2020self,
  title     = {Self-supervised learning of pretext-invariant representations},
  author    = {Misra, Ishan and Maaten, Laurens van der},
  booktitle = CVPR,
  year      = {2020}
}

@inproceedings{miech2020end,
  title     = {End-to-end learning of visual representations from uncurated instructional videos},
  author    = {Miech, Antoine and Alayrac, Jean-Baptiste and Smaira, Lucas and Laptev, Ivan and Sivic, Josef and Zisserman, Andrew},
  booktitle = CVPR,
  year      = {2020}
}

@inproceedings{yan2020clusterfit,
  title     = {ClusterFit: Improving Generalization of Visual Representations},
  author    = {Yan, Xueting and Misra, Ishan and Gupta, Abhinav and Ghadiyaram, Deepti and Mahajan, Dhruv},
  booktitle = CVPR,
  year      = {2020}
}

@inproceedings{chen2020big,
  title     = {Big self-supervised models are strong semi-supervised learners},
  author    = {Chen, Ting and Kornblith, Simon and Swersky, Kevin and Norouzi, Mohammad and Hinton, Geoffrey E},
  booktitle = NIPS,
  year      = {2020}
}

@inproceedings{assran2021semi,
  title     = {Semi-supervised learning of visual features by non-parametrically predicting view assignments with support samples},
  author    = {Assran, Mahmoud and Caron, Mathilde and Misra, Ishan and Bojanowski, Piotr and Joulin, Armand and Ballas, Nicolas and Rabbat, Michael},
  booktitle = {Proceedings of the IEEE/CVF International Conference on Computer Vision},
  pages     = {8443--8452},
  year      = {2021}
}

@inproceedings{mahajan2018exploring,
  title     = {Exploring the limits of weakly supervised pretraining},
  author    = {Mahajan, Dhruv and Girshick, Ross and Ramanathan, Vignesh and He, Kaiming and Paluri, Manohar and Li, Yixuan and Bharambe, Ashwin and van der Maaten, Laurens},
  booktitle = ECCV,
  year      = {2018}
}

@inproceedings{joulin2016learning,
  title     = {Learning visual features from large weakly supervised data},
  author    = {Joulin, Armand and Van Der Maaten, Laurens and Jabri, Allan and Vasilache, Nicolas},
  booktitle = ECCV,
  year      = {2016}
}

@inproceedings{simclr,
  title     = {A simple framework for contrastive learning of visual representations},
  author    = {Chen, Ting and Kornblith, Simon and Norouzi, Mohammad and Hinton, Geoffrey},
  booktitle = ICML,
  year      = {2020}
}

@inproceedings{grill2020bootstrap,
  title     = {Bootstrap your own latent: A new approach to self-supervised learning},
  author    = {Grill, Jean-Bastien and Strub, Florian and Altch{\'e}, Florent and Tallec, Corentin and Richemond, Pierre H and Buchatskaya, Elena and Doersch, Carl and Pires, Bernardo Avila and Guo, Zhaohan Daniel and Azar, Mohammad Gheshlaghi and Piot, Bilal and Kavukcuoglu, Koray and Munos, Rémi and Valko, Michal},
  booktitle = NIPS,
  year      = {2020}
}

@inproceedings{swav,
  title     = {Unsupervised learning of visual features by contrasting cluster assignments},
  author    = {Caron, Mathilde and Misra, Ishan and Mairal, Julien and Goyal, Priya and Bojanowski, Piotr and Joulin, Armand},
  booktitle = NIPS,
  year      = {2020}
}

@inproceedings{oyallon2017scaling,
  title     = {Scaling the scattering transform: Deep hybrid networks},
  author    = {Oyallon, Edouard and Belilovsky, Eugene and Zagoruyko, Sergey},
  booktitle = ICCV,
  year      = {2017}
}

@inproceedings{bojanowski2017unsupervised,
  title     = {Unsupervised learning by predicting Noise},
  author    = {Bojanowski, Piotr and Joulin, Armand},
  booktitle = ICML,
  year      = {2017}
}

@misc{radford2019language,
  title  = {Language models are unsupervised multitask learners},
  author = {Radford, Alec and Wu, Jeffrey and Child, Rewon and Luan, David and Amodei, Dario and Sutskever, Ilya}
}


@inproceedings{schneider2019wav2vec,
  title     = {wav2vec: Unsupervised pre-training for speech recognition},
  author    = {Schneider, Steffen and Baevski, Alexei and Collobert, Ronan and Auli, Michael},
  booktitle = {preprint arXiv:1904.05862},
  year      = {2019}
}

@inproceedings{riviere2020unsupervised,
  title     = {Unsupervised pretraining transfers well across languages},
  author    = {Rivi{\`e}re, Morgane and Joulin, Armand and Mazar{\'e}, Pierre-Emmanuel and Dupoux, Emmanuel},
  booktitle = ICASSP,
  year      = {2020}
}

@inproceedings{baevski2020wav2vec,
  title     = {wav2vec 2.0: A framework for self-supervised learning of speech representations},
  author    = {Baevski, Alexei and Zhou, Henry and Mohamed, Abdelrahman and Auli, Michael},
  booktitle = NIPS,
  year      = {2020}
}


@article{liu2022dbot,
  title   = {Exploring target representations for masked autoencoders},
  author  = {Liu, Xingbin and Zhou, Jinghao and Kong, Tao and Lin, Xianming and Ji, Rongrong},
  journal = {arXiv},
  year    = {2022}
}

@article{dong2021peco,
  title   = {Peco: Perceptual codebook for bert pre-training of vision transformers},
  author  = {Dong, Xiaoyi and Bao, Jianmin and Zhang, Ting and Chen, Dongdong and Zhang, Weiming and Yuan, Lu and Chen, Dong and Wen, Fang and Yu, Nenghai},
  journal = {arXiv},
  year    = {2021}
}

@inproceedings{kahn2020libri,
  title     = {Libri-light: A benchmark for asr with limited or no supervision},
  author    = {Kahn, Jacob and Rivi{\`e}re, Morgane and Zheng, Weiyi and Kharitonov, Evgeny and Xu, Qiantong and Mazar{\'e}, Pierre-Emmanuel and Karadayi, Julien and Liptchinsky, Vitaliy and Collobert, Ronan and Fuegen, Christian and others},
  booktitle = ICASSP,
  year      = {2020}
}

@inproceedings{brown2020language,
  title     = {Language models are few-shot learners},
  author    = {Brown, Tom B and Mann, Benjamin and Ryder, Nick and Subbiah, Melanie and Kaplan, Jared and Dhariwal, Prafulla and Neelakantan, Arvind and Shyam, Pranav and Sastry, Girish and Askell, Amanda and others},
  booktitle = NIPS,
  year      = {2020}
}

@article{raffel2019exploring,
  title   = {Exploring the limits of transfer learning with a unified text-to-text transformer},
  author  = {Raffel, Colin and Shazeer, Noam and Roberts, Adam and Lee, Katherine and Narang, Sharan and Matena, Michael and Zhou, Yanqi and Li, Wei and Liu, Peter J},
  journal = {preprint arXiv:1910.10683},
  year    = {2019}
}

@article{henaff2019data,
  title   = {Data-efficient image recognition with contrastive predictive coding},
  author  = {H{\'e}naff, Olivier J and Srinivas, Aravind and De Fauw, Jeffrey and Razavi, Ali and Doersch, Carl and Eslami, SM and Oord, Aaron van den},
  journal = PMLR,
  year    = {2019}
}

@inproceedings{kolesnikov2019big,
  title     = {Big transfer (BiT): General visual representation learning},
  author    = {Kolesnikov, Alexander and Beyer, Lucas and Zhai, Xiaohua and Puigcerver, Joan and Yung, Jessica and Gelly, Sylvain and Houlsby, Neil},
  booktitle = ECCV,
  year      = {2020}
}

@inproceedings{kolesnikov2019revisiting,
  title     = {Revisiting self-supervised visual representation learning},
  author    = {Kolesnikov, Alexander and Zhai, Xiaohua and Beyer, Lucas},
  booktitle = CVPR,
  year      = {2019}
}


@inproceedings{dino,
  title     = {Emerging properties in self-supervised vision transformers},
  author    = {Caron, Mathilde and Touvron, Hugo and Misra, Ishan and J{\'e}gou, Herv{\'e} and Mairal, Julien and Bojanowski, Piotr and Joulin, Armand},
  booktitle = ICCV,
  year      = {2021}
}


@article{henaff2021efficient,
  title   = {Efficient visual pretraining with contrastive detection},
  author  = {H{\'e}naff, Olivier J and Koppula, Skanda and Alayrac, Jean-Baptiste and Oord, Aaron van den and Vinyals, Oriol and Carreira, Jo{\~a}o},
  journal = {arXiv},
  year    = {2021}
}

@inproceedings{li2021efficient,
  title     = {Efficient self-supervised vision transformers for representation learning},
  author    = {Li, Chunyuan and Yang, Jianwei and Zhang, Pengchuan and Gao, Mei and Xiao, Bin and Dai, Xiyang and Yuan, Lu and Gao, Jianfeng},
  booktitle = ICLR,
  year      = {2022}
}

@inproceedings{he2016deep,
  title     = {Deep residual learning for image recognition},
  author    = {He, Kaiming and Zhang, Xiangyu and Ren, Shaoqing and Sun, Jian},
  booktitle = CVPR,
  year      = {2016}
}

@article{tan2019efficientnet,
  title   = {Efficientnet: Rethinking model scaling for convolutional neural networks},
  author  = {Tan, Mingxing and Le, Quoc V},
  journal = {preprint arXiv:1905.11946},
  year    = {2019}
}

@inproceedings{xie2017aggregated,
  title     = {Aggregated residual transformations for deep neural networks},
  author    = {Xie, Saining and Girshick, Ross and Doll{\'a}r, Piotr and Tu, Zhuowen and He, Kaiming},
  booktitle = CVPR,
  year      = {2017}
}

@article{bardes2021vicreg,
  title   = {Vicreg: Variance-invariance-covariance regularization for self-supervised learning},
  author  = {Bardes, Adrien and Ponce, Jean and LeCun, Yann},
  journal = {arXiv},
  year    = {2021}
}

@inproceedings{zbontar2021barlow,
  title     = {Barlow twins: Self-supervised learning via redundancy reduction},
  author    = {Zbontar, Jure and Jing, Li and Misra, Ishan and LeCun, Yann and Deny, St{\'e}phane},
  booktitle = {International Conference on Machine Learning},
  year      = {2021}
}

@inproceedings{xie2016unsupervised,
  title     = {Unsupervised deep embedding for clustering analysis},
  author    = {Xie, Junyuan and Girshick, Ross and Farhadi, Ali},
  booktitle = ICML,
  year      = {2016}
}

@inproceedings{yang2016joint,
  title     = {Joint unsupervised learning of deep representations and image clusters},
  author    = {Yang, Jianwei and Parikh, Devi and Batra, Dhruv},
  booktitle = CVPR,
  year      = {2016}
}


@inproceedings{doersch2015unsupervised,
  title     = {Unsupervised visual representation learning by context prediction},
  author    = {Doersch, Carl and Gupta, Abhinav and Efros, Alexei A},
  booktitle = ICCV,
  year      = {2015}
}

@inproceedings{vincent2008extracting,
  author    = {P. Vincent and H. Larochelle and Y. Bengio and P.-A. Manzagol},
  title     = {Extracting and composing robust features with denoising autoencoders},
  booktitle = ICML,
  year      = {2008}
}

@inproceedings{ranzato2007unsupervised,
  author    = {Marc’Aurelio Ranzato and Fu-Jie Huang and Y-Lan Boureau and Yann LeCun},
  title     = {Unsupervised Learning of Invariant Feature Hierarchies with Applications to Object Recognition},
  booktitle = CVPR,
  year      = {2007}
}

@inproceedings{hadsell2006dimensionality,
  title     = {Dimensionality reduction by learning an invariant mapping},
  author    = {Hadsell, Raia and Chopra, Sumit and LeCun, Yann},
  booktitle = CVPR,
  year      = {2006}
}

@article{olshausen1996,
  author  = {B. A. Olshausen and D. J. Field},
  title   = {Emergence of simple-cell receptive field properties by learning a sparse code for natural images},
  journal = {Nature},
  volume  = {381},
  number  = {6583},
  pages   = {607},
  year    = {1996}
}

@inproceedings{coates2011analysis,
  title     = {An analysis of single-layer networks in unsupervised feature learning},
  author    = {Coates, Adam and Ng, Andrew and Lee, Honglak},
  booktitle = AISTATS,
  year      = {2011}
}

@article{li2020prototypical,
  title   = {Prototypical Contrastive Learning of Unsupervised Representations},
  author  = {Li, Junnan and Zhou, Pan and Xiong, Caiming and Socher, Richard and Hoi, Steven CH},
  journal = {preprint arXiv:2005.04966},
  year    = {2020}
}

@article{dosovitskiy2016discriminative,
  title   = {Discriminative unsupervised feature learning with exemplar convolutional neural networks},
  author  = {Dosovitskiy, Alexey and Fischer, Philipp and Springenberg, Jost Tobias and Riedmiller, Martin and Brox, Thomas},
  journal = TPAMI,
  year    = {2016}
}

@article{oord2018representation,
  title   = {Representation learning with contrastive predictive coding},
  author  = {Oord, Aaron van den and Li, Yazhe and Vinyals, Oriol},
  journal = {preprint arXiv:1807.03748},
  year    = {2018}
}

@article{goyal2017accurate,
  title   = {Accurate, large minibatch sgd: Training imagenet in 1 hour},
  author  = {Goyal, Priya and Doll{\'a}r, Piotr and Girshick, Ross and Noordhuis, Pieter and Wesolowski, Lukasz and Kyrola, Aapo and Tulloch, Andrew and Jia, Yangqing and He, Kaiming},
  journal = {preprint arXiv:1706.02677},
  year    = {2017}
}

@inproceedings{djolonga2021robustness,
  title     = {On robustness and transferability of convolutional neural networks},
  author    = {Djolonga, Josip and Yung, Jessica and Tschannen, Michael and Romijnders, Rob and Beyer, Lucas and Kolesnikov, Alexander and Puigcerver, Joan and Minderer, Matthias and D'Amour, Alexander and Moldovan, Dan and others},
  booktitle = {Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition},
  pages     = {16458--16468},
  year      = {2021}
}

@inproceedings{hendrycks2021natural,
  title     = {Natural Adversarial Examples},
  author    = {Hendrycks, Dan and Zhao, Kevin and Basart, Steven and Steinhardt, Jacob and Song, Dawn},
  booktitle = CVPR,
  year      = {2021}
}

@inproceedings{hendrycks2021many,
  title     = {The many faces of robustness: A critical analysis of out-of-distribution generalization},
  author    = {Hendrycks, Dan and Basart, Steven and Mu, Norman and Kadavath, Saurav and Wang, Frank and Dorundo, Evan and Desai, Rahul and Zhu, Tyler and Parajuli, Samyak and Guo, Mike and others},
  booktitle = ICCV,
  year      = {2021}
}

@inproceedings{hendrycks2018benchmarking,
  title     = {Benchmarking Neural Network Robustness to Common Corruptions and Perturbations},
  author    = {Dan Hendrycks and Thomas Dietterich},
  booktitle = ICLR,
  year      = {2019}
}

@article{hooker2019selective,
  title  = {Selective brain damage: Measuring the disparate impact of model pruning},
  author = {Hooker, Sara and Dauphin, Yann and Courville, Aaron and Frome, Andrea},
  year   = {2019}
}

@article{beyer2020we,
  title   = {Are we done with imagenet?},
  author  = {Beyer, Lucas and H{\'e}naff, Olivier J and Kolesnikov, Alexander and Zhai, Xiaohua and Oord, A{\"a}ron van den},
  journal = {arXiv},
  year    = {2020}
}

@inproceedings{recht2019imagenet,
  title     = {Do imagenet classifiers generalize to imagenet?},
  author    = {Recht, Benjamin and Roelofs, Rebecca and Schmidt, Ludwig and Shankar, Vaishaal},
  booktitle = ICML,
  year      = {2019}
}

@article{russakovsky2015imagenet,
  title   = {Imagenet large scale visual recognition challenge},
  author  = {Russakovsky, Olga and Deng, Jia and Su, Hao and Krause, Jonathan and Satheesh, Sanjeev and Ma, Sean and Huang, Zhiheng and Karpathy, Andrej and Khosla, Aditya and Bernstein, Michael and Berg, Alexander C and Fei-Fei, Li },
  journal = IJCV,
  year    = {2015}
}

@inproceedings{assran2022masked,
  title     = {Masked siamese networks for label-efficient learning},
  author    = {Assran, Mahmoud and Caron, Mathilde and Misra, Ishan and Bojanowski, Piotr and Bordes, Florian and Vincent, Pascal and Joulin, Armand and Rabbat, Michael and Ballas, Nicolas},
  booktitle = ECCV,
  year      = {2022}
}

@article{xu2022masked,
  title   = {Masked autoencoders that listen},
  author  = {Xu, Hu and Li, Juncheng and Baevski, Alexei and Auli, Michael and Galuba, Wojciech and Metze, Florian and Feichtenhofer, Christoph and others},
  journal = {arXiv},
  year    = {2022}
}

@inproceedings{tong2022videomae,
  title     = {Videomae: Masked autoencoders are data-efficient learners for self-supervised video pre-training},
  author    = {Tong, Zhan and Song, Yibing and Wang, Jue and Wang, Limin},
  booktitle = NIPS,
  year      = {2022}
}

@inproceedings{girdhar2022omnimae,
  title     = {OmniMAE: Single Model Masked Pretraining on Images and Videos},
  author    = {Girdhar, Rohit and El-Nouby, Alaaeldin and Singh, Mannat and Alwala, Kalyan Vasudev and Joulin, Armand and Misra, Ishan},
  booktitle = CVPR,
  year      = {2023}
}

@inproceedings{goyal2019scaling,
  title     = {Scaling and benchmarking self-supervised visual representation learning},
  author    = {Goyal, Priya and Mahajan, Dhruv and Gupta, Abhinav and Misra, Ishan},
  booktitle = ICCV,
  year      = {2019}
}

@article{rajbhandari2019zero,
  author  = {Rajbhandari, Samyam and Rasley, Jeff and Ruwase, Olatunji and He, Yuxiong},
  title   = {ZeRO: Memory Optimizations Toward Training Trillion Parameter Models},
  journal = {preprint arXiv:1910.02054},
  year    = {2019}
}

@article{chen2016grad,
  author  = {Tianqi Chen and Bing Xu and Chiyuan Zhang and Carlos Guestrin},
  title   = {Training Deep Nets with Sublinear Memory Cost},
  journal = {preprint arXiv:1604.06174},
  year    = {2016}
}

@inproceedings{sohn2020fixmatch,
  title     = {Fixmatch: Simplifying semi-supervised learning with consistency and confidence},
  author    = {Sohn, Kihyuk and Berthelot, David and Li, Chun-Liang and Zhang, Zizhao and Carlini, Nicholas and Cubuk, Ekin D and Kurakin, Alex and Zhang, Han and Raffel, Colin},
  booktitle = NIPS,
  year      = {2020}
}

@article{xu2020self,
  title   = {Self-training and Pre-training are Complementary for Speech Recognition},
  author  = {Xu, Qiantong and Baevski, Alexei and Likhomanenko, Tatiana and Tomasello, Paden and Conneau, Alexis and Collobert, Ronan and Synnaeve, Gabriel and Auli, Michael},
  journal = {preprint arXiv:2010.11430},
  year    = {2020}
}

@article{xu2020iterative,
  title   = {Iterative pseudo-labeling for speech recognition},
  author  = {Xu, Qiantong and Likhomanenko, Tatiana and Kahn, Jacob and Hannun, Awni and Synnaeve, Gabriel and Collobert, Ronan},
  journal = {preprint arXiv:2005.09267},
  year    = {2020}
}


@article{french2020milking,
  title   = {Milking CowMask for Semi-Supervised Image Classification},
  author  = {French, Geoff and Oliver, Avital and Salimans, Tim},
  journal = {preprint arXiv:2003.12022},
  year    = {2020}
}

@inproceedings{dosovitskiy2020image,
  title     = {An Image is Worth 16x16 Words: Transformers for Image Recognition at Scale},
  author    = {Dosovitskiy, Alexey and Beyer, Lucas and Kolesnikov, Alexander and Weissenborn, Dirk and Zhai, Xiaohua and Unterthiner, Thomas and Dehghani, Mostafa and Minderer, Matthias and Heigold, Georg and Gelly, Sylvain and others},
  booktitle = ICLR,
  year      = {2021}
}

@inproceedings{sun2017revisiting,
  title     = {Revisiting unreasonable effectiveness of data in deep learning era},
  author    = {Sun, Chen and Shrivastava, Abhinav and Singh, Saurabh and Gupta, Abhinav},
  booktitle = ICCV,
  year      = {2017}
}

@inproceedings{hu2018squeeze,
  title     = {Squeeze-and-excitation networks},
  author    = {Hu, Jie and Shen, Li and Sun, Gang},
  booktitle = CVPR,
  year      = {2018}
}

@inproceedings{van2018inaturalist,
  title     = {The inaturalist species classification and detection dataset},
  author    = {Van Horn, Grant and Mac Aodha, Oisin and Song, Yang and Cui, Yin and Sun, Chen and Shepard, Alex and Adam, Hartwig and Perona, Pietro and Belongie, Serge},
  booktitle = CVPR,
  year      = {2018}
}

@article{kuznetsova2018open,
  title   = {The Open Images Dataset V4: Unified image classification, object detection, and visual relationship detection at scale},
  author  = {Alina Kuznetsova and Mohamad Hassan Mohamad Rom and Neil Alldrin and Jasper Uijlings and Ivan Krasin and Jordi Pont-Tuset and Shahab Kamali and Stefan Popov and Matteo Malloci and Alexander Kolesnikov and Tom Duerig and Vittorio Ferrari},
  journal = IJCV,
  year    = {2020}
}


@inproceedings{zhou2014learning,
  title     = {Learning deep features for scene recognition using places database},
  author    = {Zhou, Bolei and Lapedriza, Agata and Xiao, Jianxiong and Torralba, Antonio and Oliva, Aude},
  booktitle = NIPS,
  year      = {2014}
}

@article{everingham2010pascal,
  title   = {The pascal visual object classes (voc) challenge},
  author  = {Everingham, Mark and Van Gool, Luc and Williams, Christopher KI and Winn, John and Zisserman, Andrew},
  journal = IJCV,
  year    = {2010}
}

@article{loshchilov2016sgdr,
  title   = {Sgdr: Stochastic gradient descent with warm restarts},
  author  = {Loshchilov, Ilya and Hutter, Frank},
  journal = {preprint arXiv:1608.03983},
  year    = {2016}
}

@article{du2020self,
  title   = {Self-training improves pre-training for natural language understanding},
  author  = {Du, Jingfei and Grave, Edouard and Gunel, Beliz and Chaudhary, Vishrav and Celebi, Onur and Auli, Michael and Stoyanov, Ves and Conneau, Alexis},
  journal = {preprint arXiv:2010.02194},
  year    = {2020}
}

@article{zoph2020rethinking,
  title   = {Rethinking pre-training and self-training},
  author  = {Zoph, Barret and Ghiasi, Golnaz and Lin, Tsung-Yi and Cui, Yin and Liu, Hanxiao and Cubuk, Ekin D and Le, Quoc V},
  journal = {preprint arXiv:2006.06882},
  year    = {2020}
}

@article{zhang2020pushing,
  title   = {Pushing the Limits of Semi-Supervised Learning for Automatic Speech Recognition},
  author  = {Zhang, Yu and Qin, James and Park, Daniel S and Han, Wei and Chiu, Chung-Cheng and Pang, Ruoming and Le, Quoc V and Wu, Yonghui},
  journal = {preprint arXiv:2010.10504},
  year    = {2020}
}

@article{richemond2020byol,
  title   = {BYOL works even without batch statistics},
  author  = {Richemond, Pierre H and Grill, Jean-Bastien and Altch{\'e}, Florent and Tallec, Corentin and Strub, Florian and Brock, Andrew and Smith, Samuel and De, Soham and Pascanu, Razvan and Piot, Bilal and others},
  journal = {preprint arXiv:2010.10241},
  year    = {2020}
}

@inproceedings{bucilua2006model,
  title     = {Model compression},
  author    = {Buciluǎ, Cristian and Caruana, Rich and Niculescu-Mizil, Alexandru},
  booktitle = {SIGKDD},
  year      = {2006}
}

@inproceedings{hinton2015distilling,
  title     = {Distilling the knowledge in a neural network},
  author    = {Hinton, Geoffrey and Vinyals, Oriol and Dean, Jeff},
  booktitle = {NeurIPS Deep Learning Workshop},
  year      = {2014}
}

@article{tarvainen2017mean,
  title   = {Mean teachers are better role models: Weight-averaged consistency targets improve semi-supervised deep learning results},
  author  = {Tarvainen, Antti and Valpola, Harri},
  journal = {preprint arXiv:1703.01780},
  year    = {2017}
}

@article{touvron2020training,
  title   = {Training data-efficient image transformers \& distillation through attention},
  author  = {Touvron, Hugo and Cord, Matthieu and Douze, Matthijs and Massa, Francisco and Sablayrolles, Alexandre and J{\'e}gou, Herv{\'e}},
  journal = {preprint arXiv:2012.12877},
  year    = {2020}
}

@inproceedings{chen2020exploring,
  title     = {Exploring Simple Siamese Representation Learning},
  author    = {Chen, Xinlei and He, Kaiming},
  booktitle = CVPR,
  year      = {2021}
}

@article{chen2020improved,
  title   = {Improved baselines with momentum contrastive learning},
  author  = {Chen, Xinlei and Fan, Haoqi and Girshick, Ross and He, Kaiming},
  journal = {preprint arXiv:2003.04297},
  year    = {2020}
}


@article{bautista2016cliquecnn,
  title   = {Cliquecnn: Deep unsupervised exemplar learning},
  author  = {Bautista, Miguel A and Sanakoyeu, Artsiom and Sutter, Ekaterina and Ommer, Bj{\"o}rn},
  journal = {preprint arXiv:1608.08792},
  year    = {2016}
}

@inproceedings{huang2019unsupervised,
  title     = {Unsupervised deep learning by neighbourhood discovery},
  author    = {Huang, Jiabo and Dong, Qi and Gong, Shaogang and Zhu, Xiatian},
  booktitle = ICML,
  year      = {2019}
}

@inproceedings{zhuang2019local,
  title     = {Local aggregation for unsupervised learning of visual embeddings},
  author    = {Zhuang, Chengxu and Zhai, Alex Lin and Yamins, Daniel},
  booktitle = ICCV,
  year      = {2019}
}

@inproceedings{gutmann2010noise,
  title     = {Noise-contrastive estimation: A new estimation principle for unnormalized statistical models},
  author    = {Gutmann, Michael and Hyv{\"a}rinen, Aapo},
  booktitle = {International Conference on Artificial Intelligence and Statistics},
  year      = {2010}
}

@article{ermolov2020whitening,
  title   = {Whitening for self-supervised representation learning},
  author  = {Ermolov, Aleksandr and Siarohin, Aliaksandr and Sangineto, Enver and Sebe, Nicu},
  journal = {preprint arXiv:2007.06346},
  year    = {2020}
}

@inproceedings{douze2018low,
  title     = {Low-shot learning with large-scale diffusion},
  author    = {Douze, Matthijs and Szlam, Arthur and Hariharan, Bharath and J{\'e}gou, Herv{\'e}},
  booktitle = {Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition},
  pages     = {3349--3358},
  year      = {2018}
}

@inproceedings{lee2013pseudo,
  title     = {Pseudo-label: The simple and efficient semi-supervised learning method for deep neural networks},
  author    = {Lee, Dong-Hyun and others},
  booktitle = {Workshop on challenges in representation learning, ICML},
  year      = {2013}
}

@inproceedings{xie2020self,
  title     = {Self-training with noisy student improves imagenet classification},
  author    = {Xie, Qizhe and Luong, Minh-Thang and Hovy, Eduard and Le, Quoc V},
  booktitle = CVPR,
  year      = {2020}
}

@inproceedings{vaswani2017attention,
  title     = {Attention is all you need},
  author    = {Vaswani, Ashish and Shazeer, Noam and Parmar, Niki and Uszkoreit, Jakob and Jones, Llion and Gomez, Aidan N and Kaiser, {\L}ukasz and Polosukhin, Illia},
  booktitle = NIPS,
  year      = {2017}
}

@inproceedings{zhao2020exploring,
  title     = {Exploring self-attention for image recognition},
  author    = {Zhao, Hengshuang and Jia, Jiaya and Koltun, Vladlen},
  booktitle = CVPR,
  year      = {2020}
}

@inproceedings{parmar2018image,
  title     = {Image transformer},
  author    = {Parmar, Niki and Vaswani, Ashish and Uszkoreit, Jakob and Kaiser, Lukasz and Shazeer, Noam and Ku, Alexander and Tran, Dustin},
  booktitle = ICML,
  year      = {2018}
}

@article{child2019generating,
  title   = {Generating long sequences with sparse transformers},
  author  = {Child, Rewon and Gray, Scott and Radford, Alec and Sutskever, Ilya},
  journal = {preprint arXiv:1904.10509},
  year    = {2019}
}

@article{hoffer2019mix,
  title   = {Mix \& Match: training convnets with mixed image sizes for improved accuracy, speed and scale resiliency},
  author  = {Hoffer, Elad and Weinstein, Berry and Hubara, Itay and Ben-Nun, Tal and Hoefler, Torsten and Soudry, Daniel},
  journal = {preprint arXiv:1908.08986},
  year    = {2019}
}

@article{bahdanau2014neural,
  title   = {Neural machine translation by jointly learning to align and translate},
  author  = {Bahdanau, Dzmitry and Cho, Kyunghyun and Bengio, Yoshua},
  journal = {preprint arXiv:1409.0473},
  year    = {2014}
}

@article{klein2017opennmt,
  title   = {Opennmt: Open-source toolkit for neural machine translation},
  author  = {Klein, Guillaume and Kim, Yoon and Deng, Yuntian and Senellart, Jean and Rush, Alexander M},
  journal = {preprint arXiv:1701.02810},
  year    = {2017}
}

@article{chen2018best,
  title   = {The best of both worlds: Combining recent advances in neural machine translation},
  author  = {Chen, Mia Xu and Firat, Orhan and Bapna, Ankur and Johnson, Melvin and Macherey, Wolfgang and Foster, George and Jones, Llion and Parmar, Niki and Schuster, Mike and Chen, Zhifeng and others},
  journal = {preprint arXiv:1804.09849},
  year    = {2018}
}

@inproceedings{radosavovic2020designing,
  title     = {Designing network design spaces},
  author    = {Radosavovic, Ilija and Kosaraju, Raj Prateek and Girshick, Ross and He, Kaiming and Doll{\'a}r, Piotr},
  booktitle = CVPR,
  year      = {2020}
}

@article{loshchilov2018fixing,
  title  = {Fixing weight decay regularization in adam},
  author = {Loshchilov, Ilya and Hutter, Frank},
  year   = {2018}
}

@inproceedings{zhang2016colorful,
  title     = {Colorful image colorization},
  author    = {Zhang, Richard and Isola, Phillip and Efros, Alexei A},
  booktitle = ECCV,
  year      = {2016}
}

@article{tian2020makes,
  title   = {What makes for good views for contrastive learning},
  author  = {Tian, Yonglong and Sun, Chen and Poole, Ben and Krishnan, Dilip and Schmid, Cordelia and Isola, Phillip},
  journal = NIPS,
  year    = {2020}
}

@article{salimans2016weight,
  title   = {Weight normalization: A simple reparameterization to accelerate training of deep neural networks},
  author  = {Salimans, Tim and Kingma, Diederik P},
  journal = NIPS,
  year    = {2016}
}

@inproceedings{bach2011non,
  title     = {Non-asymptotic analysis of stochastic approximation algorithms for machine learning},
  author    = {Bach, Francis and Moulines, Eric},
  booktitle = NIPS,
  year      = {2011}
}

@techreport{ruppert1988efficient,
  title  = {Efficient estimations from a slowly convergent Robbins-Monro process},
  author = {Ruppert, David},
  year   = {1988}
}

@article{izmailov2018averaging,
  title   = {Averaging weights leads to wider optima and better generalization},
  author  = {Izmailov, Pavel and Podoprikhin, Dmitrii and Garipov, Timur and Vetrov, Dmitry and Wilson, Andrew Gordon},
  journal = {preprint arXiv:1803.05407},
  year    = {2018}
}

@article{jean2014using,
  title   = {On using very large target vocabulary for neural machine translation},
  author  = {Jean, S{\'e}bastien and Cho, Kyunghyun and Memisevic, Roland and Bengio, Yoshua},
  journal = {preprint arXiv:1412.2007},
  year    = {2014}
}

@inproceedings{lai2020mast,
  title     = {MAST: A memory-augmented self-supervised tracker},
  author    = {Lai, Zihang and Lu, Erika and Xie, Weidi},
  booktitle = CVPR,
  year      = {2020}
}

@inproceedings{oh2019video,
  title     = {Video object segmentation using space-time memory networks},
  author    = {Oh, Seoung Wug and Lee, Joon-Young and Xu, Ning and Kim, Seon Joo},
  booktitle = ICCV,
  year      = {2019}
}

@inproceedings{wang2019learning,
  title     = {Learning correspondence from the cycle-consistency of time},
  author    = {Wang, Xiaolong and Jabri, Allan and Efros, Alexei A},
  booktitle = CVPR,
  year      = {2019}
}

@inproceedings{wang2019learningrobust,
  title     = {Learning Robust Global Representations by Penalizing Local Predictive Power},
  author    = {Wang, Haohan and Ge, Songwei and Lipton, Zachary and Xing, Eric P},
  booktitle = {Advances in Neural Information Processing Systems},
  pages     = {10506--10518},
  year      = {2019}
}

@article{gur2020visualization,
  title   = {Visualization of Supervised and Self-Supervised Neural Networks via Attribution Guided Factorization},
  author  = {Gur, Shir and Ali, Ameen and Wolf, Lior},
  journal = {preprint arXiv:2012.02166},
  year    = {2020}
}

@article{goyal2021self,
  title   = {Self-supervised Pretraining of Visual Features in the Wild},
  author  = {Goyal, Priya and Caron, Mathilde and Lefaudeux, Benjamin and Xu, Min and Wang, Pengchao and Pai, Vivek and Singh, Mannat and Liptchinsky, Vitaliy and Misra, Ishan and Joulin, Armand and others},
  journal = {preprint arXiv:2103.01988},
  year    = {2021}
}

@article{el2021training,
  title   = {Training Vision Transformers for Image Retrieval},
  author  = {El-Nouby, Alaaeldin and Neverova, Natalia and Laptev, Ivan and J{\'e}gou, Herv{\'e}},
  journal = {preprint arXiv:2102.05644},
  year    = {2021}
}

@article{pont20172017,
  title   = {The 2017 davis challenge on video object segmentation},
  author  = {Pont-Tuset, Jordi and Perazzi, Federico and Caelles, Sergi and Arbel{\'a}ez, Pablo and Sorkine-Hornung, Alex and Van Gool, Luc},
  journal = {preprint arXiv:1704.00675},
  year    = {2017}
}

@inproceedings{cuturi2013sinkhorn,
  title     = {Sinkhorn distances: Lightspeed computation of optimal transport},
  author    = {Cuturi, Marco},
  booktitle = NIPS,
  year      = {2013}
}

@article{lowe2004distinctive,
  title   = {Distinctive image features from scale-invariant keypoints},
  author  = {Lowe, David G},
  journal = IJCV,
  year    = {2004}
}

@inproceedings{nilsback2008automated,
  title     = {Automated flower classification over a large number of classes},
  author    = {Nilsback, Maria-Elena and Zisserman, Andrew},
  booktitle = ICVGIP,
  year      = {2008}
}

@article{pham2020meta,
  title   = {Meta pseudo labels},
  author  = {Pham, Hieu and Xie, Qizhe and Dai, Zihang and Le, Quoc V},
  journal = {preprint arXiv:2003.10580},
  year    = {2020}
}

@article{xie2020unsupervised,
  title   = {Unsupervised Data Augmentation for Consistency Training},
  author  = {Xie, Qizhe and Dai, Zihang Dai and Hovy, Eduard and Luong, Minh-Thang and Le, Quoc V.},
  journal = {preprint arXiv:1904.12848},
  year    = {2020}
}

@article{assran2020recovering,
  title   = {Recovering Petaflops in Contrastive Semi-Supervised Learning of Visual Representations},
  author  = {Assran, Mahmoud and Ballas, Nicolas and Castrejon, Lluis and Rabbat, Michael},
  journal = {preprint arXiv:2006.10803},
  year    = {2020}
}

@article{anil2018large,
  title   = {Large scale distributed neural network training through online distillation},
  author  = {Anil, Rohan and Pereyra, Gabriel and Passos, Alexandre and Ormandi, Robert and Dahl, George E and Hinton, Geoffrey E},
  journal = {arXiv},
  year    = {2018}
}

@inproceedings{Arandjelovic_2018_ECCV,
  author    = {Arandjelovic, Relja and Zisserman, Andrew},
  title     = {Objects that Sound},
  booktitle = {Proceedings of the European Conference on Computer Vision (ECCV)},
  month     = {September},
  year      = {2018}
}

@misc{bain2021frozen,
  title         = {Frozen in Time: A Joint Video and Image Encoder for End-to-End Retrieval},
  author        = {Max Bain and Arsha Nagrani and Gül Varol and Andrew Zisserman},
  year          = {2021},
  eprint        = {2104.00650},
  archiveprefix = {arXiv},
  primaryclass  = {cs.CV}
}

@misc{banville2020uncovering,
  title         = {Uncovering the structure of clinical EEG signals with self-supervised learning},
  author        = {Hubert Banville and Omar Chehab and Aapo Hyvärinen and Denis-Alexander Engemann and Alexandre Gramfort},
  year          = {2020},
  eprint        = {2007.16104},
  archiveprefix = {arXiv},
  primaryclass  = {stat.ML}
}



@article{Benjamens2020,
  author   = {Benjamens, Stan
              and Dhunnoo, Pranavsingh
              and Mesk{\'o}, Bertalan},
  title    = {The state of artificial intelligence-based FDA-approved medical devices and algorithms: an online database},
  journal  = {npj Digital Medicine},
  year     = {2020},
  month    = {Sep},
  day      = {11},
  volume   = {3},
  number   = {1},
  pages    = {118},
  abstract = {At the beginning of the artificial intelligence (AI)/machine learning (ML) era, the expectations are high, and experts foresee that AI/ML shows potential for diagnosing, managing and treating a wide variety of medical conditions. However, the obstacles for implementation of AI/ML in daily clinical practice are numerous, especially regarding the regulation of these technologies. Therefore, we provide an insight into the currently available AI/ML-based medical devices and algorithms that have been approved by the US Food {\&} Drugs Administration (FDA). We aimed to raise awareness of the importance of regulatory bodies, clearly stating whether a medical device is AI/ML based or not. Cross-checking and validating all approvals, we identified 64 AI/ML based, FDA approved medical devices and algorithms. Out of those, only 29 (45{\%}) mentioned any AI/ML-related expressions in the official FDA announcement. The majority (85.9{\%}) was approved by the FDA with a 510(k) clearance, while 8 (12.5{\%}) received de novo pathway clearance and one (1.6{\%}) premarket approval (PMA) clearance. Most of these technologies, notably 30 (46.9{\%}), 16 (25.0{\%}), and 10 (15.6{\%}) were developed for the fields of Radiology, Cardiology and Internal Medicine/General Practice respectively. We have launched the first comprehensive and open access database of strictly AI/ML-based medical technologies that have been approved by the FDA. The database will be constantly updated.},
  issn     = {2398-6352},
  doi      = {10.1038/s41746-020-00324-0},
  url      = {https://doi.org/10.1038/s41746-020-00324-0}
}

@misc{bennequin2021bridging,
  title         = {Bridging Few-Shot Learning and Adaptation: New Challenges of Support-Query Shift},
  author        = {Etienne Bennequin and Victor Bouvier and Myriam Tami and Antoine Toubhans and Céline Hudelot},
  year          = {2021},
  eprint        = {2105.11804},
  archiveprefix = {arXiv},
  primaryclass  = {cs.LG}
}



@misc{charachon2021leveraging,
  title         = {Leveraging Conditional Generative Models in a General Explanation Framework of Classifier Decisions},
  author        = {Martin Charachon and Paul-Henry Cournède and Céline Hudelot and Roberto Ardon},
  year          = {2021},
  eprint        = {2106.10947},
  archiveprefix = {arXiv},
  primaryclass  = {cs.LG}
}

@article{chefer2020transformerInterpretability,
  title   = {Transformer Interpretability Beyond Attention Visualization},
  author  = {Chefer, Hila and Gur, Shir and Wolf, Lior},
  journal = {arXiv},
  year    = {2020}
}



@misc{doersch2016unsupervised,
  title         = {Unsupervised Visual Representation Learning by Context Prediction},
  author        = {Carl Doersch and Abhinav Gupta and Alexei A. Efros},
  year          = {2016},
  eprint        = {1505.05192},
  archiveprefix = {arXiv},
  primaryclass  = {cs.CV}
}

@misc{doersch2021crosstransformers,
  title         = {CrossTransformers: spatially-aware few-shot transfer},
  author        = {Carl Doersch and Ankush Gupta and Andrew Zisserman},
  year          = {2021},
  eprint        = {2007.11498},
  archiveprefix = {arXiv},
  primaryclass  = {cs.CV}
}

@article{dosovitskiy2014disc,
  author  = {Alexey Dosovitskiy and
             Jost Tobias Springenberg and
             Martin A. Riedmiller and
             Thomas Brox},
  title   = {Discriminative Unsupervised Feature Learning with Convolutional Neural Networks},
  journal = {CoRR},
  year    = {2014}
}

@article{beyer2020imagenetreal,
  author     = {Lucas Beyer and
                Olivier J. H{\'{e}}naff and
                Alexander Kolesnikov and
                Xiaohua Zhai and
                A{\"{a}}ron van den Oord},
  title      = {Are we done with ImageNet?},
  journal    = {CoRR},
  volume     = {abs/2006.07159},
  year       = {2020},
  url        = {https://arxiv.org/abs/2006.07159},
  eprinttype = {arXiv},
  eprint     = {2006.07159}
}

@inproceedings{recht2019imagenetv2,
  title     = {Do {I}mage{N}et Classifiers Generalize to {I}mage{N}et?},
  author    = {Recht, Benjamin and Roelofs, Rebecca and Schmidt, Ludwig and Shankar, Vaishaal},
  booktitle = {Proceedings of the 36th International Conference on Machine Learning},
  pages     = {5389--5400},
  year      = {2019},
  editor    = {Chaudhuri, Kamalika and Salakhutdinov, Ruslan},
  volume    = {97},
  series    = {Proceedings of Machine Learning Research},
  month     = {09--15 Jun},
  publisher = {PMLR}
}

@misc{elnouby2021xcit,
  title         = {XCiT: Cross-Covariance Image Transformers},
  author        = {Alaaeldin El-Nouby and Hugo Touvron and Mathilde Caron and Piotr Bojanowski and Matthijs Douze and Armand Joulin and Ivan Laptev and Natalia Neverova and Gabriel Synnaeve and Jakob Verbeek and Hervé Jegou},
  year          = {2021},
  eprint        = {2106.09681},
  archiveprefix = {arXiv},
  primaryclass  = {cs.CV}
}

@misc{fu2021meNDT,
  title         = {Me-NDT: Neural-backed Decision Tree for visual Explainability of deep Medical models},
  author        = {Guanghui FU and Ruiqian Wang and Jianqiang Li and Maria Vakalopoulou and Vicky Kalogeiton},
  year          = {2021},
  eprint        = {pL_aFZKNO5N},
  archiveprefix = {openreview},
  primaryclass  = {cs.CV}
}

@misc{gamper2021multiple,
  title         = {Multiple Instance Captioning: Learning Representations from Histopathology Textbooks and Articles},
  author        = {Jevgenij Gamper and Nasir Rajpoot},
  year          = {2021},
  eprint        = {2103.05121},
  archiveprefix = {arXiv},
  primaryclass  = {cs.CV}
}

@inproceedings{gidaris2018unsupervised,
  title     = {Unsupervised Representation Learning by Predicting Image Rotations},
  author    = {Spyros Gidaris and Praveer Singh and Nikos Komodakis},
  booktitle = ICLR,
  year      = {2018}
}

@article{guillot2021robust,
  title    = {RobustSleepNet: Transfer Learning for Automated Sleep Staging at Scale},
  author   = {Guillot, Antoine and Thorey, Valentin},
  doi      = {10.1109/tnsre.2021.3098968},
  volume   = {29},
  year     = {2021},
  journal  = {IEEE transactions on neural systems and rehabilitation engineering : a publication of the IEEE Engineering in Medicine and Biology Society},
  issn     = {1534-4320},
  pages    = {1441—1451},
  abstract = {Sleep disorder diagnosis relies on the analysis of polysomnography (PSG) records. As a preliminary step of this examination, sleep stages are systematically determined. In practice, sleep stage classification relies on the visual inspection of 30-second epochs of polysomnography signals. Numerous automatic approaches have been developed to replace this tedious and expensive task. Although these methods demonstrated better performance than human sleep experts on specific datasets, they remain largely unused in sleep clinics. The main reason is that each sleep clinic uses a specific PSG montage that most automatic approaches cannot handle out-of-the-box. Moreover, even when the PSG montage is compatible, publications have shown that automatic approaches perform poorly on unseen data with different demographics. To address these issues, we introduce RobustSleepNet, a deep learning model for automatic sleep stage classification able to handle arbitrary PSG montages. We trained and evaluated this model in a leave-one-out-dataset fashion on a large corpus of 8 heterogeneous sleep staging datasets to make it robust to demographic changes. When evaluated on an unseen dataset, RobustSleepNet reaches 97% of the F1 of a model explicitly trained on this dataset. Hence, RobustSleepNet unlocks the possibility to perform high-quality out-of-the-box automatic sleep staging with any clinical setup. We further show that finetuning RobustSleepNet, using a part of the unseen dataset, increases the F1 by 2% when compared to a model trained specifically for this dataset. Therefore, finetuning might be used to reach a state-of-the-art level of performance on a specific population.},
  url      = {https://doi.org/10.1109/TNSRE.2021.3098968}
}

@misc{hatamizadeh2021unetr,
  title         = {UNETR: Transformers for 3D Medical Image Segmentation},
  author        = {Ali Hatamizadeh and Dong Yang and Holger Roth and Daguang Xu},
  year          = {2021},
  eprint        = {2103.10504},
  archiveprefix = {arXiv},
  primaryclass  = {eess.IV}
}


@inproceedings{moco,
  author    = {He, Kaiming and Fan, Haoqi and Wu, Yuxin and Xie, Saining and Girshick, Ross},
  title     = {Momentum Contrast for Unsupervised Visual Representation Learning},
  booktitle = CVPR,
  year      = {2020}
}

@misc{jun2021medical,
  title         = {Medical Transformer: Universal Brain Encoder for 3D MRI Analysis},
  author        = {Eunji Jun and Seungwoo Jeong and Da-Woon Heo and Heung-Il Suk},
  year          = {2021},
  eprint        = {2104.13633},
  archiveprefix = {arXiv},
  primaryclass  = {cs.CV}
}

@article{Li2020,
  author   = {Li, Yikuan
              and Rao, Shishir
              and Solares, Jos{\'e} Roberto Ayala
              and Hassaine, Abdelaali
              and Ramakrishnan, Rema
              and Canoy, Dexter
              and Zhu, Yajie
              and Rahimi, Kazem
              and Salimi-Khorshidi, Gholamreza},
  title    = {BEHRT: Transformer for Electronic Health Records},
  journal  = {Scientific Reports},
  year     = {2020},
  month    = {Apr},
  day      = {28},
  volume   = {10},
  number   = {1},
  pages    = {7155},
  abstract = {Today, despite decades of developments in medicine and the growing interest in precision healthcare, vast majority of diagnoses happen once patients begin to show noticeable signs of illness. Early indication and detection of diseases, however, can provide patients and carers with the chance of early intervention, better disease management, and efficient allocation of healthcare resources. The latest developments in machine learning (including deep learning) provides a great opportunity to address this unmet need. In this study, we introduce BEHRT: A deep neural sequence transduction model for electronic health records (EHR), capable of simultaneously predicting the likelihood of 301 conditions in one's future visits. When trained and evaluated on the data from nearly 1.6 million individuals, BEHRT shows a striking improvement of 8.0--13.2{\%} (in terms of average precision scores for different tasks), over the existing state-of-the-art deep EHR models. In addition to its scalability and superior accuracy, BEHRT enables personalised interpretation of its predictions; its flexible architecture enables it to incorporate multiple heterogeneous concepts (e.g., diagnosis, medication, measurements, and more) to further improve the accuracy of its predictions; its (pre-)training results in disease and patient representations can be useful for future studies (i.e., transfer learning).},
  issn     = {2045-2322},
  doi      = {10.1038/s41598-020-62922-y},
  url      = {https://doi.org/10.1038/s41598-020-62922-y}
}

@inproceedings{lovelace-mortazavi-2020-learning,
  title     = {Learning to Generate Clinically Coherent Chest {X}-Ray Reports},
  author    = {Lovelace, Justin  and
               Mortazavi, Bobak},
  booktitle = {Findings of the Association for Computational Linguistics: EMNLP 2020},
  month     = nov,
  year      = {2020},
  address   = {Online},
  publisher = {Association for Computational Linguistics},
  url       = {https://aclanthology.org/2020.findings-emnlp.110},
  doi       = {10.18653/v1/2020.findings-emnlp.110},
  pages     = {1235--1243},
  abstract  = {Automated radiology report generation has the potential to reduce the time clinicians spend manually reviewing radiographs and streamline clinical care. However, past work has shown that typical abstractive methods tend to produce fluent, but clinically incorrect radiology reports. In this work, we develop a radiology report generation model utilizing the transformer architecture that produces superior reports as measured by both standard language generation and clinical coherence metrics compared to competitive baselines. We then develop a method to differentiably extract clinical information from generated reports and utilize this differentiability to fine-tune our model to produce more clinically coherent reports.}
}

@misc{naseer2021intriguing,
  title         = {Intriguing Properties of Vision Transformers},
  author        = {Muzammal Naseer and Kanchana Ranasinghe and Salman Khan and Munawar Hayat and Fahad Shahbaz Khan and Ming-Hsuan Yang},
  year          = {2021},
  eprint        = {2105.10497},
  archiveprefix = {arXiv},
  primaryclass  = {cs.CV}
}

@inproceedings{noroozi2016jigsaw,
  author    = {Noroozi, Mehdi
               and Favaro, Paolo},
  title     = {Unsupervised Learning of Visual Representations by Solving Jigsaw Puzzles},
  booktitle = ECCV,
  year      = {2016}
}

@misc{ouali2020target,
  title         = {Target Consistency for Domain Adaptation: when Robustness meets Transferability},
  author        = {Yassine Ouali and Victor Bouvier and Myriam Tami and Céline Hudelot},
  year          = {2020},
  eprint        = {2006.14263},
  archiveprefix = {arXiv},
  primaryclass  = {cs.LG}
}
	
@inproceedings{pathakCVPR16context,
  author    = {Pathak, Deepak and
               Kr\"ahenb\"uhl, Philipp and
               Donahue, Jeff and
               Darrell, Trevor and
               Efros, Alexei},
  title     = {Context Encoders:
               Feature Learning by Inpainting},
  booktitle = CVPR,
  year      = {2016}
}

@article{Pierrard2021explainable,
  title    = {Spatial relation learning for explainable image classification and annotation in critical applications},
  journal  = {Artificial Intelligence},
  volume   = {292},
  pages    = {103434},
  year     = {2021},
  issn     = {0004-3702},
  doi      = {https://doi.org/10.1016/j.artint.2020.103434},
  url      = {https://www.sciencedirect.com/science/article/pii/S0004370220301818},
  author   = {Régis Pierrard and Jean-Philippe Poli and Céline Hudelot},
  keywords = {Explainable artificial intelligence, Relation learning, Fuzzy logic},
  abstract = {With the recent successes of black-box models in Artificial Intelligence (AI) and the growing interactions between humans and AIs, explainability issues have risen. In this article, in the context of high-stake applications, we propose an approach for explainable classification and annotation of images. It is based on a transparent model, whose reasoning is accessible and human understandable, and on interpretable fuzzy relations that enable to express the vagueness of natural language. The knowledge about relations is set beforehand by an expert and thus training instances do not need to be annotated. The most relevant relations are extracted using a fuzzy frequent itemset mining algorithm in order to build rules, for classification, and constraints, for annotation. We also present two heuristics that make the process of evaluating relations faster. Since the strengths of our approach are the transparency of the model and the interpretability of the relations, an explanation in natural language can be generated. Supported by experimental results, we show that, given a segmentation of the input, our approach is able to successfully perform the target task and generate explanations that were judged as consistent and convincing by a set of participants.}
}

@inproceedings{pooch2020trust,
  author    = {Pooch, Eduardo H. P.
               and Ballester, Pedro
               and Barros, Rodrigo C.},
  editor    = {Petersen, Jens
               and San Jos{\'e} Est{\'e}par, Ra{\'u}l
               and Schmidt-Richberg, Alexander
               and Gerard, Sarah
               and Lassen-Schmidt, Bianca
               and Jacobs, Colin
               and Beichel, Reinhard
               and Mori, Kensaku},
  title     = {Can We Trust Deep Learning Based Diagnosis? The Impact of Domain Shift in Chest Radiograph Classification},
  booktitle = {Thoracic Image Analysis},
  year      = {2020},
  publisher = {Springer International Publishing},
  address   = {Cham},
  pages     = {74--83},
  abstract  = {While deep learning models become more widespread, their ability to handle unseen data and generalize for any scenario is yet to be challenged. In medical imaging, there is a high heterogeneity of distributions among images based on the equipment that generates them and their parametrization. This heterogeneity triggers a common issue in machine learning called domain shift, which represents the difference between the training data distribution and the distribution of where a model is employed. A high domain shift often results in a poor generalization performance from the models. In this work, we evaluate the extent of which domain shift damages model performance on four of the largest datasets of chest radiographs. We show how training and testing with different datasets (e.g., training in ChestX-ray14 and testing in CheXpert) drastically affects model performance, posing a big question over the reliability of deep learning models trained on public datasets. We also show that models trained on CheXpert and MIMIC-CXR generalized better to other datasets.},
  isbn      = {978-3-030-62469-9}
}

@inproceedings{ramesh2021clip,
  title     = {Zero-Shot Text-to-Image Generation},
  author    = {Ramesh, Aditya and Pavlov, Mikhail and Goh, Gabriel and Gray, Scott and Voss, Chelsea and Radford, Alec and Chen, Mark and Sutskever, Ilya},
  booktitle = ICML,
  year      = {2021}
}

@inproceedings{sahasrabudhe2020slide,
  title       = {{Self-supervised Nuclei Segmentation in Histopathological Images Using Attention}},
  author      = {Sahasrabudhe, Mihir and Christodoulidis, Stergios and Salgado, Roberto and Michiels, Stefan and Loi, Sherene and Andr{\'e}, Fabrice and Paragios, Nikos and Vakalopoulou, Maria},
  url         = {https://hal.archives-ouvertes.fr/hal-03087006},
  booktitle   = {{MICCAI 2020 - 23rd International Conference on Medical Image Computing and Computer Assisted Intervention}},
  address     = {Lima, Peru},
  pages       = {393-402},
  year        = {2020},
  month       = Sep,
  doi         = {10.1007/978-3-030-59722-1\_38},
  keywords    = {Pathology ; Whole Slide Images ; Nuclei Segmentation ; Deep Learning ; Self-Supervision ; Attention Models},
  pdf         = {https://hal.archives-ouvertes.fr/hal-03087006/file/arxiv.pdf},
  hal_id      = {hal-03087006},
  hal_version = {v1}
}

@article{Sahasrabudhe2021,
  doi       = {10.1109/jbhi.2020.3038889},
  url       = {https://doi.org/10.1109/jbhi.2020.3038889},
  year      = {2021},
  month     = jun,
  publisher = {Institute of Electrical and Electronics Engineers ({IEEE})},
  volume    = {25},
  number    = {6},
  pages     = {2125--2136},
  author    = {Mihir Sahasrabudhe and Pierre Sujobert and Evangelia I. Zacharaki and Eugenie Maurin and Beatrice Grange and Laurent Jallades and Nikos Paragios and Maria Vakalopoulou},
  title     = {Deep Multi-Instance Learning Using Multi-Modal Data for Diagnosis of Lymphocytosis},
  journal   = {{IEEE} Journal of Biomedical and Health Informatics}
}

@misc{shao2021transmil,
  title         = {TransMIL: Transformer based Correlated Multiple Instance Learning for Whole Slide Image Classication},
  author        = {Zhuchen Shao and Hao Bian and Yang Chen and Yifeng Wang and Jian Zhang and Xiangyang Ji and Yongbing Zhang},
  year          = {2021},
  eprint        = {2106.00908},
  archiveprefix = {arXiv},
  primaryclass  = {cs.CV}
}

@article{Sharma2021,
  doi       = {10.1158/2159-8290.cd-20-1680},
  url       = {https://doi.org/10.1158/2159-8290.cd-20-1680},
  year      = {2021},
  month     = apr,
  publisher = {American Association for Cancer Research ({AACR})},
  volume    = {11},
  number    = {4},
  pages     = {838--857},
  author    = {Padmanee Sharma and Bilal A. Siddiqui and Swetha Anandhan and Shalini S. Yadav and Sumit K. Subudhi and Jianjun Gao and Sangeeta Goswami and James P. Allison},
  title     = {The Next Decade of Immune Checkpoint Therapy},
  journal   = {Cancer Discovery}
}

@misc{shen2021cotr,
  title         = {COTR: Convolution in Transformer Network for End to End Polyp Detection},
  author        = {Zhiqiang Shen and Chaonan Lin and Shaohua Zheng},
  year          = {2021},
  eprint        = {2105.10925},
  archiveprefix = {arXiv},
  primaryclass  = {cs.CV}
}

@misc{srinivasan2021robustness,
  title         = {On the Robustness of Pretraining and Self-Supervision for a Deep Learning-based Analysis of Diabetic Retinopathy},
  author        = {Vignesh Srinivasan and Nils Strodthoff and Jackie Ma and Alexander Binder and Klaus-Robert Müller and Wojciech Samek},
  year          = {2021},
  eprint        = {2106.13497},
  archiveprefix = {arXiv},
  primaryclass  = {cs.CV}
}

@misc{tan2021vimpac,
  title         = {VIMPAC: Video Pre-Training via Masked Token Prediction and Contrastive Learning},
  author        = {Hao Tan and Jie Lei and Thomas Wolf and Mohit Bansal},
  year          = {2021},
  eprint        = {2106.11250},
  archiveprefix = {arXiv},
  primaryclass  = {cs.CV}
}



@article{selvaraju2016gradcam,
  author     = {Ramprasaath R. Selvaraju and
                Abhishek Das and
                Ramakrishna Vedantam and
                Michael Cogswell and
                Devi Parikh and
                Dhruv Batra},
  title      = {Grad-CAM: Why did you say that? Visual Explanations from Deep Networks
                via Gradient-based Localization},
  journal    = {CoRR},
  volume     = {abs/1610.02391},
  year       = {2016},
  url        = {http://arxiv.org/abs/1610.02391},
  eprinttype = {arXiv},
  eprint     = {1610.02391},
  timestamp  = {Mon, 13 Aug 2018 16:46:58 +0200},
  biburl     = {https://dblp.org/rec/journals/corr/SelvarajuDVCPB16.bib},
  bibsource  = {dblp computer science bibliography, https://dblp.org}
}

@misc{bahdanau2016neural,
  title         = {Neural Machine Translation by Jointly Learning to Align and Translate},
  author        = {Dzmitry Bahdanau and Kyunghyun Cho and Yoshua Bengio},
  year          = {2016},
  eprint        = {1409.0473},
  archiveprefix = {arXiv},
  primaryclass  = {cs.CL}
}

@inproceedings{shen2019discovery,
  title     = {Discovering Visual Patterns in Art Collections with Spatially-consistent Feature Learning},
  author    = {Shen, Xi and Efros, Alexei A and Aubry, Mathieu},
  booktitle = {Proceedings IEEE Conf. on Computer Vision and Pattern Recognition (CVPR)},
  year      = {2019}
}

@inproceedings{cao2019cross,
  title     = {Cross-domain adaptation for animal pose estimation},
  author    = {Cao, Jinkun and Tang, Hongyang and Fang, Hao-Shu and Shen, Xiaoyong and Lu, Cewu and Tai, Yu-Wing},
  booktitle = {Proceedings of the IEEE/CVF International Conference on Computer Vision},
  pages     = {9498--9507},
  year      = {2019}
}

@misc{joska2021acinoset,
  title         = {AcinoSet: A 3D Pose Estimation Dataset and Baseline Models for Cheetahs in the Wild},
  author        = {Daniel Joska and Liam Clark and Naoya Muramatsu and Ricardo Jericevich and Fred Nicolls and Alexander Mathis and Mackenzie W. Mathis and Amir Patel},
  year          = {2021},
  eprint        = {2103.13282},
  archiveprefix = {arXiv},
  primaryclass  = {cs.CV}
}

@misc{yu2021ap10k,
  title         = {AP-10K: A Benchmark for Animal Pose Estimation in the Wild},
  author        = {Hang Yu and Yufei Xu and Jing Zhang and Wei Zhao and Ziyu Guan and Dacheng Tao},
  year          = {2021},
  eprint        = {2108.12617},
  archiveprefix = {arXiv},
  primaryclass  = {cs.CV}
}

@article{dolz2018ivdnet,
  author     = {Jose Dolz and
                Christian Desrosiers and
                Ismail Ben Ayed},
  title      = {IVD-Net: Intervertebral disc localization and segmentation in {MRI}
                with a multi-modal UNet},
  journal    = {CoRR},
  volume     = {abs/1811.08305},
  year       = {2018},
  url        = {http://arxiv.org/abs/1811.08305},
  eprinttype = {arXiv},
  eprint     = {1811.08305},
  timestamp  = {Mon, 26 Nov 2018 12:52:45 +0100},
  biburl     = {https://dblp.org/rec/journals/corr/abs-1811-08305.bib},
  bibsource  = {dblp computer science bibliography, https://dblp.org}
}

@misc{irvin2019chexpert,
  title         = {CheXpert: A Large Chest Radiograph Dataset with Uncertainty Labels and Expert Comparison},
  author        = {Jeremy Irvin and Pranav Rajpurkar and Michael Ko and Yifan Yu and Silviana Ciurea-Ilcus and Chris Chute and Henrik Marklund and Behzad Haghgoo and Robyn Ball and Katie Shpanskaya and Jayne Seekins and David A. Mong and Safwan S. Halabi and Jesse K. Sandberg and Ricky Jones and David B. Larson and Curtis P. Langlotz and Bhavik N. Patel and Matthew P. Lungren and Andrew Y. Ng},
  year          = {2019},
  eprint        = {1901.07031},
  archiveprefix = {arXiv},
  primaryclass  = {cs.CV}
}

@inproceedings{xu2018towards,
  title     = {Towards End-to-End License Plate Detection and Recognition: A Large Dataset and Baseline},
  author    = {Xu, Zhenbo and Yang, Wei and Meng, Ajin and Lu, Nanxue and Huang, Huan},
  booktitle = {Proceedings of the European Conference on Computer Vision (ECCV)},
  pages     = {255--271},
  year      = {2018}
}

@article{johnson2019billion,
  title   = {Billion-scale similarity search with {GPUs}},
  author  = {Johnson, Jeff and Douze, Matthijs and J{\'e}gou, Herv{\'e}},
  journal = {IEEE Transactions on Big Data},
  year    = {2019}
}

@article{johnson2019mimic-cxr,
  author   = {Johnson, Alistair E. W.
              and Pollard, Tom J.
              and Berkowitz, Seth J.
              and Greenbaum, Nathaniel R.
              and Lungren, Matthew P.
              and Deng, Chih-ying
              and Mark, Roger G.
              and Horng, Steven},
  title    = {MIMIC-CXR, a de-identified publicly available database of chest radiographs with free-text reports},
  journal  = {Scientific Data},
  year     = {2019},
  month    = {Dec},
  day      = {12},
  volume   = {6},
  number   = {1},
  pages    = {317},
  abstract = {Chest radiography is an extremely powerful imaging modality, allowing for a detailed inspection of a patient's chest, but requires specialized training for proper interpretation. With the advent of high performance general purpose computer vision algorithms, the accurate automated analysis of chest radiographs is becoming increasingly of interest to researchers. Here we describe MIMIC-CXR, a large dataset of 227,835 imaging studies for 65,379 patients presenting to the Beth Israel Deaconess Medical Center Emergency Department between 2011--2016. Each imaging study can contain one or more images, usually a frontal view and a lateral view. A total of 377,110 images are available in the dataset. Studies are made available with a semi-structured free-text radiology report that describes the radiological findings of the images, written by a practicing radiologist contemporaneously during routine clinical care. All images and reports have been de-identified to protect patient privacy. The dataset is made freely available to facilitate and encourage a wide range of research in computer vision, natural language processing, and clinical data mining.},
  issn     = {2052-4463},
  doi      = {10.1038/s41597-019-0322-0},
  url      = {https://doi.org/10.1038/s41597-019-0322-0}
}

@inproceedings{imagenet_cvpr09,
  author    = {Deng, J. and Dong, W. and Socher, R. and Li, L.-J. and Li, K. and Fei-Fei, L.},
  title     = {{ImageNet: A Large-Scale Hierarchical Image Database}},
  booktitle = {CVPR09},
  year      = {2009},
  bibsource = {http://www.image-net.org/papers/imagenet_cvpr09.bib}
}

@article{wang17nih,
  title     = {ChestX-Ray8: Hospital-Scale Chest X-Ray Database and Benchmarks on Weakly-Supervised Classification and Localization of Common Thorax Diseases},
  isbn      = {9781538604571},
  url       = {http://dx.doi.org/10.1109/CVPR.2017.369},
  doi       = {10.1109/cvpr.2017.369},
  journal   = {2017 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)},
  publisher = {IEEE},
  author    = {Wang, Xiaosong and Peng, Yifan and Lu, Le and Lu, Zhiyong and Bagheri, Mohammadhadi and Summers, Ronald M.},
  year      = {2017},
  month     = {Jul}
}

@misc{yuan2021largescale,
  title         = {Large-scale Robust Deep AUC Maximization: A New Surrogate Loss and Empirical Studies on Medical Image Classification},
  author        = {Zhuoning Yuan and Yan Yan and Milan Sonka and Tianbao Yang},
  year          = {2021},
  eprint        = {2012.03173},
  archiveprefix = {arXiv},
  primaryclass  = {cs.LG}
}

@misc{azizi2021big,
  title         = {Big Self-Supervised Models Advance Medical Image Classification},
  author        = {Shekoofeh Azizi and Basil Mustafa and Fiona Ryan and Zachary Beaver and Jan Freyberg and Jonathan Deaton and Aaron Loh and Alan Karthikesalingam and Simon Kornblith and Ting Chen and Vivek Natarajan and Mohammad Norouzi},
  year          = {2021},
  eprint        = {2101.05224},
  archiveprefix = {arXiv},
  primaryclass  = {eess.IV}
}

@article{mckinney2020international,
  title     = {International evaluation of an AI system for breast cancer screening},
  author    = {McKinney, Scott Mayer and Sieniek, Marcin and Godbole, Varun and Godwin, Jonathan and Antropova, Natasha and Ashrafian, Hutan and Back, Trevor and Chesus, Mary and Corrado, Greg S and Darzi, Ara and others},
  journal   = {Nature},
  volume    = {577},
  number    = {7788},
  pages     = {89--94},
  year      = {2020},
  publisher = {Nature Publishing Group}
}

@article{liu2020deep,
  title     = {A deep learning system for differential diagnosis of skin diseases},
  author    = {Liu, Yuan and Jain, Ayush and Eng, Clara and Way, David H and Lee, Kang and Bui, Peggy and Kanada, Kimberly and de Oliveira Marinho, Guilherme and Gallegos, Jessica and Gabriele, Sara and others},
  journal   = {Nature medicine},
  volume    = {26},
  number    = {6},
  pages     = {900--908},
  year      = {2020},
  publisher = {Nature Publishing Group}
}

@inproceedings{menegola2017knowledge,
  title        = {Knowledge transfer for melanoma screening with deep learning},
  author       = {Menegola, Afonso and Fornaciali, Michel and Pires, Ramon and Bittencourt, Fl{\'a}via Vasques and Avila, Sandra and Valle, Eduardo},
  booktitle    = {2017 IEEE 14th International Symposium on Biomedical Imaging (ISBI 2017)},
  pages        = {297--300},
  year         = {2017},
  organization = {IEEE}
}

@article{alzubaidi2020towards,
  title     = {Towards a better understanding of transfer learning for medical imaging: a case study},
  author    = {Alzubaidi, Laith and Fadhel, Mohammed A and Al-Shamma, Omran and Zhang, Jinglan and Santamar{\'\i}a, J and Duan, Ye and R Oleiwi, Sameer},
  journal   = {Applied Sciences},
  volume    = {10},
  number    = {13},
  pages     = {4523},
  year      = {2020},
  publisher = {Multidisciplinary Digital Publishing Institute}
}

@article{raghu2019transfusion,
  title   = {Transfusion: Understanding transfer learning for medical imaging},
  author  = {Raghu, Maithra and Zhang, Chiyuan and Kleinberg, Jon and Bengio, Samy},
  journal = {arXiv},
  year    = {2019}
}

@article{douze20212021,
  title   = {The 2021 Image Similarity Dataset and Challenge},
  author  = {Douze, Matthijs and Tolias, Giorgos and Pizzi, Ed and Papakipos, Zo{\"e} and Chanussot, Lowik and Radenovic, Filip and Jenicek, Tomas and Maximov, Maxim and Leal-Taix{\'e}, Laura and Elezi, Ismail and others},
  journal = {arXiv},
  year    = {2021}
}

@inproceedings{zhou2021detecting,
  title     = {Detecting Twenty-thousand Classes using Image-level Supervision},
  author    = {Zhou, Xingyi and Girdhar, Rohit and Joulin, Armand and Kr{\"a}henb{\"u}hl, Philipp and Misra, Ishan},
  booktitle = {arXiv},
  year      = {2021}
}

@inproceedings{liu2021Swin,
  title     = {Swin Transformer: Hierarchical Vision Transformer using Shifted Windows},
  author    = {Liu, Ze and Lin, Yutong and Cao, Yue and Hu, Han and Wei, Yixuan and Zhang, Zheng and Lin, Stephen and Guo, Baining},
  booktitle = {Proceedings of the IEEE/CVF International Conference on Computer Vision (ICCV)},
  year      = {2021}
}

@article{hazirbas2021towards,
  title   = {Towards measuring fairness in ai: the casual conversations dataset},
  author  = {Hazirbas, Caner and Bitton, Joanna and Dolhansky, Brian and Pan, Jacqueline and Gordo, Albert and Ferrer, Cristian Canton},
  journal = {IEEE Transactions on Biometrics, Behavior, and Identity Science},
  year    = {2021}
}

@article{krizhevsky2009learning,
  title  = {Learning multiple layers of features from tiny images},
  author = {Krizhevsky, Alex and Hinton, Geoffrey and others},
  year   = {2009}
}

@inproceedings{dataset-caltech101,
  title     = {Learning generative visual models from few training examples: An incremental bayesian approach tested on 101 object categories},
  author    = {Fei-Fei, Li and Fergus, Rob and Perona, Pietro},
  booktitle = CVPR,
  year      = {2004}
}

@inproceedings{dataset-pets,
  author    = {Omkar M. Parkhi and Andrea Vedaldi and Andrew Zisserman and C. V. Jawahar},
  title     = {Cats and Dogs},
  booktitle = CVPR,
  year      = {2012}
}



@inproceedings{dataset-birdsnap,
  title     = {Birdsnap: Large-scale fine-grained visual categorization of birds},
  author    = {Berg, Thomas and Liu, Jiongxin and Woo Lee, Seung and Alexander, Michelle L and Jacobs, David W and Belhumeur, Peter N},
  booktitle = {Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition},
  pages     = {2011--2018},
  year      = {2014}
}

@techreport{dataset-cub,
  author = {P. Welinder and S. Branson and T. Mita and C. Wah and F. Schroff and S. Belongie and P. Perona},
  number = {CNS-TR-2010-001},
  title  = {{Caltech-UCSD Birds 200}},
  year   = {2010}
}

@inproceedings{dataset-food101,
  title     = {Food-101 -- Mining Discriminative Components with Random Forests},
  author    = {Bossard, Lukas and Guillaumin, Matthieu and Van Gool, Luc},
  booktitle = ECCV,
  year      = {2014}
}

@inproceedings{xiao2010sun,
  title     = {Sun database: Large-scale scene recognition from abbey to zoo},
  author    = {Xiao, Jianxiong and Hays, James and Ehinger, Krista A and Oliva, Aude and Torralba, Antonio},
  booktitle = CVPR,
  year      = {2010}
}

@inproceedings{dataset-stanfordcars,
  title     = {3D Object Representations for Fine-Grained Categorization},
  booktitle = {3DRR},
  year      = {2013},
  author    = {Jonathan Krause and Michael Stark and Jia Deng and Li Fei-Fei}
}

@techreport{dataset-aircraft,
  title         = {Fine-Grained Visual Classification of Aircraft},
  author        = {S. Maji and J. Kannala and E. Rahtu
                   and M. Blaschko and A. Vedaldi},
  year          = {2013},
  archiveprefix = {arXiv},
  eprint        = {1306.5151},
  primaryclass  = {cs-cv}
}



@inproceedings{dataset-dtd,
  author    = {M. Cimpoi and S. Maji and I. Kokkinos and S. Mohamed and and A. Vedaldi},
  title     = {Describing Textures in the Wild},
  booktitle = CVPR,
  year      = {2014}
}
	    
	    
@inproceedings{pizzi2022self,
  title     = {A Self-Supervised Descriptor for Image Copy Detection},
  author    = {Pizzi, Ed and Roy, Sreya Dutta and Ravindra, Sugosh Nagavara and Goyal, Priya and Douze, Matthijs},
  booktitle = CVPR,
  year      = {2022}
}

@inproceedings{pham2021,
  author    = {Pham, Hieu and Dai, Zihang and Xie, Qizhe and Le, Quoc V.},
  title     = {Meta Pseudo Labels},
  booktitle = {Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)},
  month     = {June},
  year      = {2021},
  pages     = {11557-11568}
}

@inproceedings{li2020selectivemining,
  author    = {Li, Yandong
               and Huang, Di
               and Qin, Danfeng
               and Wang, Liqiang
               and Gong, Boqing},
  editor    = {Vedaldi, Andrea
               and Bischof, Horst
               and Brox, Thomas
               and Frahm, Jan-Michael},
  title     = {Improving Object Detection with Selective Self-supervised Self-training},
  booktitle = {Computer Vision -- ECCV 2020},
  year      = {2020},
  publisher = {Springer International Publishing},
  address   = {Cham},
  pages     = {589--607},
  abstract  = {We study how to leverage Web images to augment human-curated object detection datasets. Our approach is two-pronged. On the one hand, we retrieve Web images by image-to-image search, which incurs less domain shift from the curated data than other search methods. The Web images are diverse, supplying a wide variety of object poses, appearances, their interactions with the context, etc. On the other hand, we propose a novel learning method motivated by two parallel lines of work that explore unlabeled data for image classification: self-training and self-supervised learning. They fail to improve object detectors in their vanilla forms due to the domain gap between the Web images and curated datasets. To tackle this challenge, we propose a selective net to rectify the supervision signals in Web images. It not only identifies positive bounding boxes but also creates a safe zone for mining hard negative boxes. We report state-of-the-art results on detecting backpacks and chairs from everyday scenes, along with other challenging object classes.},
  isbn      = {978-3-030-58526-6}
}

@inproceedings{xie2020noisystudent,
  author    = {Xie, Qizhe and Luong, Minh-Thang and Hovy, Eduard and Le, Quoc V.},
  title     = {Self-Training With Noisy Student Improves ImageNet Classification},
  booktitle = {Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)},
  month     = {June},
  year      = {2020}
}

@inproceedings{xu2021w2vw2l,
  author    = {Xu, Qiantong and Baevski, Alexei and Likhomanenko, Tatiana and Tomasello, Paden and Conneau, Alexis and Collobert, Ronan and Synnaeve, Gabriel and Auli, Michael},
  booktitle = {ICASSP 2021 - 2021 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP)},
  title     = {Self-Training and Pre-Training are Complementary for Speech Recognition},
  year      = {2021},
  volume    = {},
  number    = {},
  pages     = {3030-3034},
  doi       = {10.1109/ICASSP39728.2021.9414641}
}

@article{park2020noisystudent,
  title     = {Improved Noisy Student Training for Automatic Speech Recognition},
  url       = {http://dx.doi.org/10.21437/Interspeech.2020-1470},
  doi       = {10.21437/interspeech.2020-1470},
  journal   = {Interspeech 2020},
  publisher = {ISCA},
  author    = {Park, Daniel S. and Zhang, Yu and Jia, Ye and Han, Wei and Chiu, Chung-Cheng and Li, Bo and Wu, Yonghui and Le, Quoc V.},
  year      = {2020},
  month     = {Oct}
}

@inproceedings{likhomanenko2021,
  title     = {slim{IPL}: Language-model-free iterative pseudo-labeling},
  author    = {T. Likhomanenko and Q. Xu and J. Kahn and G. Synnaeve and R. Collobert},
  booktitle = {Interspeech},
  year      = {2021}
}

@article{synnaeve2019,
  author     = {Gabriel Synnaeve and
                Qiantong Xu and
                Jacob Kahn and
                Edouard Grave and
                Tatiana Likhomanenko and
                Vineel Pratap and
                Anuroop Sriram and
                Vitaliy Liptchinsky and
                Ronan Collobert},
  title      = {End-to-end {ASR:} from Supervised to Semi-Supervised Learning with
                Modern Architectures},
  journal    = {CoRR},
  volume     = {abs/1911.08460},
  year       = {2019},
  url        = {http://arxiv.org/abs/1911.08460},
  eprinttype = {arXiv},
  eprint     = {1911.08460}
}


@article{bommasani2021opportunities,
  title   = {On the opportunities and risks of foundation models},
  author  = {Bommasani, Rishi and Hudson, Drew A and Adeli, Ehsan and Altman, Russ and Arora, Simran and von Arx, Sydney and Bernstein, Michael S and Bohg, Jeannette and Bosselut, Antoine and Brunskill, Emma and others},
  journal = {arXiv},
  year    = {2021}
}

@inproceedings{wenzek2019ccnet,
  title     = {Ccnet: Extracting high quality monolingual datasets from web crawl data},
  author    = {Wenzek, Guillaume and Lachaux, Marie-Anne and Conneau, Alexis and Chaudhary, Vishrav and Guzm{\'a}n, Francisco and Joulin, Armand and Grave, Edouard},
  booktitle = LREC,
  year      = {2020}
}


@article{jegou2010product,
  title   = {Product quantization for nearest neighbor search},
  author  = {Jegou, Herve and Douze, Matthijs and Schmid, Cordelia},
  journal = TPAMI,
  year    = {2010}
}

@article{alayrac2022flamingo,
  title   = {Flamingo: a visual language model for few-shot learning},
  author  = {Alayrac, Jean-Baptiste and Donahue, Jeff and Luc, Pauline and Miech, Antoine and Barr, Iain and Hasson, Yana and Lenc, Karel and Mensch, Arthur and Millican, Katie and Reynolds, Malcolm and others},
  journal = {arXiv},
  year    = {2022}
}


@inproceedings{chum2007total,
  title     = {Total recall: Automatic query expansion with a generative feature model for object retrieval},
  author    = {Chum, Ondrej and Philbin, James and Sivic, Josef and Isard, Michael and Zisserman, Andrew},
  booktitle = {International Conference on Computer Vision},
  year      = {2007}
}

@article{salton1990improving,
  title   = {Improving retrieval performance by relevance feedback},
  author  = {Salton, Gerard and Buckley, Chris},
  journal = {Journal of the American society for information science},
  year    = {1990}
}

@inproceedings{sablayrolles2018spreading,
  title     = {Spreading vectors for similarity search},
  author    = {Sablayrolles, Alexandre and Douze, Matthijs and Schmid, Cordelia and J{\'e}gou, Herv{\'e}},
  booktitle = ICLR,
  year      = {2019}
}

@article{beirlant1997nonparametric,
  title   = {Nonparametric entropy estimation: An overview},
  author  = {Beirlant, Jan and Dudewicz, Edward J and Gy{\"o}rfi, L{\'a}szl{\'o} and Van der Meulen, Edward C and others},
  journal = {International Journal of Mathematical and Statistical Sciences},
  year    = {1997}
}

@article{delattre2017kozachenko,
  title   = {On the Kozachenko--Leonenko entropy estimator},
  author  = {Delattre, Sylvain and Fournier, Nicolas},
  journal = {Journal of Statistical Planning and Inference},
  year    = {2017}
}

@inproceedings{clip,
  title     = {Learning transferable visual models from natural language supervision},
  author    = {Radford, Alec and Kim, Jong Wook and Hallacy, Chris and Ramesh, Aditya and Goh, Gabriel and Agarwal, Sandhini and Sastry, Girish and Askell, Amanda and Mishkin, Pamela and Clark, Jack and others},
  booktitle = ICML,
  year      = {2021}
}

@article{pham2021combined,
  title   = {Combined Scaling for Open-Vocabulary Image Classification},
  author  = {Pham, Hieu and Dai, Zihang and Ghiasi, Golnaz and Kawaguchi, Kenji and Liu, Hanxiao and Yu, Adams Wei and Yu, Jiahui and Chen, Yi-Ting and Luong, Minh-Thang and Wu, Yonghui and others},
  journal = {arXiv},
  year    = {2021}
}

@inproceedings{jia2021scaling,
  title        = {Scaling up visual and vision-language representation learning with noisy text supervision},
  author       = {Jia, Chao and Yang, Yinfei and Xia, Ye and Chen, Yi-Ting and Parekh, Zarana and Pham, Hieu and Le, Quoc and Sung, Yun-Hsuan and Li, Zhen and Duerig, Tom},
  booktitle    = {International Conference on Machine Learning},
  pages        = {4904--4916},
  year         = {2021},
  organization = {PMLR}
}

@inproceedings{wortsman2022robust,
  title     = {Robust fine-tuning of zero-shot models},
  author    = {Wortsman, Mitchell and Ilharco, Gabriel and Kim, Jong Wook and Li, Mike and Kornblith, Simon and Roelofs, Rebecca and Lopes, Raphael Gontijo and Hajishirzi, Hannaneh and Farhadi, Ali and Namkoong, Hongseok and others},
  booktitle = {Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition},
  pages     = {7959--7971},
  year      = {2022}
}

@inproceedings{schuhmann2021laion,
  title     = {Laion-400m: Open dataset of clip-filtered 400 million image-text pairs},
  author    = {Schuhmann, Christoph and Vencu, Richard and Beaumont, Romain and Kaczmarczyk, Robert and Mullis, Clayton and Katta, Aarush and Coombes, Theo and Jitsev, Jenia and Komatsuzaki, Aran},
  booktitle = {NeurIPS Data Centric AI Workshop},
  year      = {2021}
}

@article{ilharco_gabriel_2021_5143773,
  author = {Ilharco, Gabriel and
            Wortsman, Mitchell and
            Wightman, Ross and
            Gordon, Cade and
            Carlini, Nicholas and
            Taori, Rohan and
            Dave, Achal and
            Shankar, Vaishaal and
            Namkoong, Hongseok and
            Miller, John and
            Hajishirzi, Hannaneh and
            Farhadi, Ali and
            Schmidt, Ludwig},
  title  = {OpenCLIP},
  year   = 2021
}

@article{li2022binsformer,
  title   = {BinsFormer: Revisiting Adaptive Bins for Monocular Depth Estimation},
  author  = {Li, Zhenyu and Wang, Xuyang and Liu, Xianming and Jiang, Junjun},
  journal = {arXiv},
  year    = {2022}
}

@article{li2022depthformer,
  title   = {DepthFormer: Exploiting Long-Range Correlation and Local Information for Accurate Monocular Depth Estimation},
  author  = {Li, Zhenyu and Chen, Zehui and Liu, Xianming and Jiang, Junjun},
  journal = {arXiv},
  year    = {2022}
}

@inproceedings{ranftl2021vision,
  title     = {Vision transformers for dense prediction},
  author    = {Ranftl, Ren{\'e} and Bochkovskiy, Alexey and Koltun, Vladlen},
  booktitle = ICCV,
  year      = {2021}
}

@misc{yu2022coca,
  title   = {Coca: Contrastive captioners are image-text foundation models},
  author  = {Yu, Jiahui and Wang, Zirui and Vasudevan, Vijay and Yeung, Legg and Seyedhosseini, Mojtaba and Wu, Yonghui},
  journal = {arXiv},
  year    = {2022}
}



@misc{beitv2,
  title   = {Beit v2: Masked image modeling with vector-quantized visual tokenizers},
  author  = {Peng, Zhiliang and Dong, Li and Bao, Hangbo and Ye, Qixiang and Wei, Furu},
  journal = {arXiv},
  year    = {2022}
}

@article{beit3,
  title   = {Image as a Foreign Language: BEiT Pretraining for All Vision and Vision-Language Tasks},
  author  = {Wang, Wenhui and Bao, Hangbo and Dong, Li and Bjorck, Johan and Peng, Zhiliang and Liu, Qiang and Aggarwal, Kriti and Mohammed, Owais Khan and Singhal, Saksham and Som, Subhojit and others},
  journal = {arXiv},
  year    = {2022}
}


@article{eva02,
  title   = {Eva-02: A visual representation for neon genesis},
  author  = {Fang, Yuxin and Sun, Quan and Wang, Xinggang and Huang, Tiejun and Wang, Xinlong and Cao, Yue},
  journal = {Image and Vision Computing},
  year    = {2024}
}

@inproceedings{chen2022vision,
  title     = {Vision Transformer Adapter for Dense Predictions},
  author    = {Chen, Zhe and Duan, Yuchen and Wang, Wenhai and He, Junjun and Lu, Tong and Dai, Jifeng and Qiao, Yu},
  booktitle = ICLR,
  year      = {2023}
}

@article{guo2022segnext,
  title   = {SegNeXt: Rethinking Convolutional Attention Design for Semantic Segmentation},
  author  = {Guo, Meng-Hao and Lu, Cheng-Ze and Hou, Qibin and Liu, Zhengning and Cheng, Ming-Ming and Hu, Shi-Min},
  journal = {arXiv},
  year    = {2022}
}

@article{liu2021polarized,
  title   = {Polarized self-attention: towards high-quality pixel-wise regression},
  author  = {Liu, Huajun and Liu, Fuqiang and Fan, Xinyi and Huang, Dong},
  journal = {arXiv},
  year    = {2021}
}

@inproceedings{cheng2022masked,
  title     = {Masked-attention mask transformer for universal image segmentation},
  author    = {Cheng, Bowen and Misra, Ishan and Schwing, Alexander G and Kirillov, Alexander and Girdhar, Rohit},
  booktitle = CVPR,
  year      = {2022}
}

@article{steiner2021train,
  title   = {How to train your vit? data, augmentation, and regularization in vision transformers},
  author  = {Steiner, Andreas and Kolesnikov, Alexander and Zhai, Xiaohua and Wightman, Ross and Uszkoreit, Jakob and Beyer, Lucas},
  journal = TMLR,
  year    = {2021}
}


@inproceedings{touvron2022deit,
  title     = {Deit iii: Revenge of the vit},
  author    = {Touvron, Hugo and Cord, Matthieu and J{\'e}gou, Herv{\'e}},
  booktitle = ECCV,
  year      = {2022}
}

@article{wightman2021resnet,
  title   = {Resnet strikes back: An improved training procedure in timm},
  author  = {Wightman, Ross and Touvron, Hugo and J{\'e}gou, Herv{\'e}},
  journal = {arXiv},
  year    = {2021}
}

@misc{lecun2022path,
  title  = {A Path Towards Autonomous Machine Intelligence},
  author = {LeCun, Yann},
  year   = {2022}
}


@inproceedings{zhai2022scaling,
  title     = {Scaling vision transformers},
  author    = {Zhai, Xiaohua and Kolesnikov, Alexander and Houlsby, Neil and Beyer, Lucas},
  booktitle = CVPR,
  year      = {2022}
}

@inproceedings{melas2022deep,
  title     = {Deep Spectral Methods: A Surprisingly Strong Baseline for Unsupervised Semantic Segmentation and Localization},
  author    = {Melas-Kyriazi, Luke and Rupprecht, Christian and Laina, Iro and Vedaldi, Andrea},
  booktitle = CVPR,
  year      = {2022}
}

@article{petersdeep,
  title  = {Deep contextualized word representations},
  author = {Peters, Matthew E and Neumann, Mark and Iyyer, Mohit and Gardner, Matt and Clark, Christopher and Lee, Kenton and Zettlemoyer, Luke},
  year   = 2018
}

@article{mikolov2013distributed,
  title   = {Distributed representations of words and phrases and their compositionality},
  author  = {Mikolov, Tomas and Sutskever, Ilya and Chen, Kai and Corrado, Greg S and Dean, Jeff},
  journal = {Advances in neural information processing systems},
  volume  = {26},
  year    = {2013}
}

@article{raffel2020exploring,
  title   = {Exploring the limits of transfer learning with a unified text-to-text transformer.},
  author  = {Raffel, Colin and Shazeer, Noam and Roberts, Adam and Lee, Katherine and Narang, Sharan and Matena, Michael and Zhou, Yanqi and Li, Wei and Liu, Peter J and others},
  journal = JMLR,
  year    = {2020}
}

@article{bengio2000neural,
  title   = {A neural probabilistic language model},
  author  = {Bengio, Yoshua and Ducharme, R{\'e}jean and Vincent, Pascal},
  journal = {Advances in neural information processing systems},
  volume  = {13},
  year    = {2000}
}

@inproceedings{dao2022flashattention,
  title     = {FlashAttention: Fast and Memory-Efficient Exact Attention with IO-Awareness},
  author    = {Dao, Tri and Fu, Daniel Y. and Ermon, Stefano and Rudra, Atri and R{\'e}, Christopher},
  booktitle = NIPS,
  year      = {2022}
}

@article{zhang2022opt,
  title   = {Opt: Open pre-trained transformer language models},
  author  = {Zhang, Susan and Roller, Stephen and Goyal, Naman and Artetxe, Mikel and Chen, Moya and Chen, Shuohui and Dewan, Christopher and Diab, Mona and Li, Xian and Lin, Xi Victoria and others},
  journal = {arXiv},
  year    = {2022}
}

@article{shazeer2020glu,
  title   = {Glu variants improve transformer},
  author  = {Shazeer, Noam},
  journal = {arXiv},
  year    = {2020}
}

@inproceedings{ypsilantis2021met,
  title     = {The met dataset: Instance-level recognition for artworks},
  author    = {Ypsilantis, Nikolaos-Antonios and Garcia, Noa and Han, Guangxing and Ibrahimi, Sarah and Van Noord, Nanne and Tolias, Giorgos},
  booktitle = {NeurIPS Datasets and Benchmarks Track},
  year      = {2021}
}

@inproceedings{yildiz2022amstertime,
  title     = {AmsterTime: A Visual Place Recognition Benchmark Dataset for Severe Domain Shift},
  author    = {Yildiz, Burak and Khademi, Seyran and Siebes, Ronald Maria and van Gemert, Jan},
  booktitle = ICPR,
  year      = {2022}
}

@inproceedings{silberman2012indoor,
  title     = {Indoor segmentation and support inference from rgbd images},
  author    = {Silberman, Nathan and Hoiem, Derek and Kohli, Pushmeet and Fergus, Rob},
  booktitle = ECCV,
  year      = {2012}
}

@article{geiger2013vision,
  title   = {Vision meets robotics: The kitti dataset},
  author  = {Geiger, Andreas and Lenz, Philip and Stiller, Christoph and Urtasun, Raquel},
  journal = IJRR,
  year    = {2013}
}

@inproceedings{song2015sun,
  title     = {Sun rgb-d: A rgb-d scene understanding benchmark suite},
  author    = {Song, Shuran and Lichtenberg, Samuel P and Xiao, Jianxiong},
  booktitle = CVPR,
  year      = {2015}
}

@misc{FairScale2021,
  author       = {FairScale authors},
  title        = {FairScale:  A general purpose modular PyTorch library for high performance and large scale training},
  howpublished = {\url{https://github.com/facebookresearch/fairscale}},
  year         = {2021}
}

@article{scikit-learn,
  title   = {Scikit-learn: Machine Learning in {P}ython},
  author  = {Pedregosa, F. and Varoquaux, G. and Gramfort, A. and Michel, V.
             and Thirion, B. and Grisel, O. and Blondel, M. and Prettenhofer, P.
             and Weiss, R. and Dubourg, V. and Vanderplas, J. and Passos, A. and
             Cournapeau, D. and Brucher, M. and Perrot, M. and Duchesnay, E.},
  journal = {Journal of Machine Learning Research},
  volume  = {12},
  pages   = {2825--2830},
  year    = {2011}
}

@article{lacoste2019quantifying,
  title   = {Quantifying the Carbon Emissions of Machine Learning},
  author  = {Lacoste, Alexandre and Luccioni, Alexandra and Schmidt, Victor and Dandres, Thomas},
  journal = {arXiv},
  year    = {2019}
}

@inproceedings{bhat2019adabins,
  year      = 2021,
  author    = {Shariq Farooq Bhat and Ibraheem Alhashim and Peter Wonka},
  title     = {{AdaBins}: Depth Estimation Using Adaptive Bins},
  booktitle = CVPR
}

@inproceedings{ziegler2022self,
  title     = {Self-Supervised Learning of Object Parts for Semantic Segmentation},
  author    = {Ziegler, Adrian and Asano, Yuki M},
  booktitle = {Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition},
  pages     = {14502--14511},
  year      = {2022}
}


@article{bardes2022vicregl,
  title   = {VICRegL: Self-Supervised Learning of Local Visual Features},
  author  = {Bardes, Adrien and Ponce, Jean and LeCun, Yann},
  journal = {arXiv},
  year    = {2022}
}
@inproceedings{singh2022revisiting,
  title     = {{Revisiting Weakly Supervised Pre-Training of Visual Perception Models}},
  author    = {Singh, Mannat and Gustafson, Laura and Adcock, Aaron and Reis, Vinicius de Freitas and Gedik, Bugra and Kosaraju, Raj Prateek and Mahajan, Dhruv and Girshick, Ross and Doll{\'a}r, Piotr and van der Maaten, Laurens},
  booktitle = {CVPR},
  year      = {2022}
}

@article{hoffmann2022training,
  title   = {Training compute-optimal large language models},
  author  = {Hoffmann, Jordan and Borgeaud, Sebastian and Mensch, Arthur and Buchatskaya, Elena and Cai, Trevor and Rutherford, Eliza and Casas, Diego de Las and Hendricks, Lisa Anne and Welbl, Johannes and Clark, Aidan and others},
  journal = {arXiv},
  year    = {2022}
}


@article{touvron2023llama,
  title   = {LLaMA: Open and Efficient Foundation Language Models},
  author  = {Touvron, Hugo and Lavril, Thibaut and Izacard, Gautier and Martinet, Xavier and Lachaux, Marie-Anne and Lacroix, Timoth{\'e}e and Rozi{\`e}re, Baptiste and Goyal, Naman and Hambro, Eric and Azhar, Faisal and Rodriguez, Aurelien and Joulin, Armand and Grave, Edouard and Lample, Guillaume},
  journal = {arXiv},
  year    = {2023}
}

@article{chowdhery2022palm,
  title   = {Palm: Scaling language modeling with pathways},
  author  = {Chowdhery, Aakanksha and Narang, Sharan and Devlin, Jacob and Bosma, Maarten and Mishra, Gaurav and Roberts, Adam and Barham, Paul and Chung, Hyung Won and Sutton, Charles and Gehrmann, Sebastian and others},
  journal = {arXiv},
  year    = {2022}
}

@misc{xFormers2022,
  author       = {Benjamin Lefaudeux and Francisco Massa and Diana Liskovich and Wenhan Xiong and Vittorio Caggiano and Sean Naren and Min Xu and Jieru Hu and Marta Tintore and Susan Zhang and Patrick Labatut and Daniel Haziza},
  title        = {xFormers: A modular and hackable Transformer modelling library},
  howpublished = {\url{https://github.com/facebookresearch/xformers}},
  year         = {2022}
}

@inproceedings{wang2022internimage,
  title     = {Internimage: Exploring large-scale vision foundation models with deformable convolutions},
  author    = {Wang, Wenhai and Dai, Jifeng and Chen, Zhe and Huang, Zhenhang and Li, Zhiqi and Zhu, Xizhou and Hu, Xiaowei and Lu, Tong and Lu, Lewei and Li, Hongsheng and others},
  booktitle = CVPR,
  year      = {2022}
}

@article{strubell2019energy,
  title   = {Energy and policy considerations for deep learning in NLP},
  author  = {Strubell, Emma and Ganesh, Ananya and McCallum, Andrew},
  journal = {ACL},
  year    = {2019}
}

@article{patterson2021carbon,
  title   = {Carbon emissions and large neural network training},
  author  = {Patterson, David and Gonzalez, Joseph and Le, Quoc and Liang, Chen and Munguia, Lluis-Miquel and Rothchild, Daniel and So, David and Texier, Maud and Dean, Jeff},
  journal = {arXiv},
  year    = {2021}
}

@inproceedings{chen2018encoder,
  title     = {Encoder-Decoder with Atrous Separable Convolution for Semantic Image Segmentation},
  author    = {Chen, Liang-Chieh and Zhu, Yukun and Papandreou, George and Schroff, Florian and Adam, Hartwig},
  booktitle = ECCV,
  year      = {2018}
}

@inproceedings{de2019does,
  title     = {Does object recognition work for everyone?},
  author    = {De Vries, Terrance and Misra, Ishan and Wang, Changhan and Van der Maaten, Laurens},
  booktitle = {CVPR workshops},
  year      = {2019}
}

@inproceedings{goyal2022fairness,
  title     = {Fairness indicators for systematic assessments of visual feature extractors},
  author    = {Goyal, Priya and Soriano, Adriana Romero and Hazirbas, Caner and Sagun, Levent and Usunier, Nicolas},
  booktitle = FACCT,
  year      = {2022}
}

@inproceedings{ruan2022weighted,
  title     = {Weighted Ensemble Self-Supervised Learning},
  author    = {Ruan, Yangjun and Singh, Saurabh and Morningstar, Warren and Alemi, Alexander A and Ioffe, Sergey and Fischer, Ian and Dillon, Joshua V},
  booktitle = ICLR,
  year      = {2023}
}


@article{chen2023symbolic,
  title   = {Symbolic discovery of optimization algorithms},
  author  = {Chen, Xiangning and Liang, Chen and Huang, Da and Real, Esteban and Wang, Kaiyuan and Liu, Yao and Pham, Hieu and Dong, Xuanyi and Luong, Thang and Hsieh, Cho-Jui and others},
  journal = {arXiv},
  year    = {2023}
}

@misc{rw2019timm,
  author       = {Ross Wightman},
  title        = {PyTorch Image Models},
  year         = {2019},
  publisher    = {GitHub},
  journal      = {GitHub repository},
  doi          = {10.5281/zenodo.4414861},
  howpublished = {\url{https://github.com/rwightman/pytorch-image-models}}
}

@article{duval2023simple,
  title   = {A Simple Recipe for Competitive Low-compute Self supervised Vision Models},
  author  = {Duval, Quentin and Misra, Ishan and Ballas, Nicolas},
  journal = {arXiv},
  year    = {2023}
}

@inproceedings{van2021benchmarking,
  title     = {Benchmarking representation learning for natural world image collections},
  author    = {Van Horn, Grant and Cole, Elijah and Beery, Sara and Wilber, Kimberly and Belongie, Serge and Mac Aodha, Oisin},
  booktitle = CVPR,
  year      = {2021}
}


@inproceedings{ijepa,
  title     = {Self-Supervised Learning from Images with a Joint-Embedding Predictive Architecture},
  author    = {Assran, Mahmoud and Duval, Quentin and Misra, Ishan and Bojanowski, Piotr and Vincent, Pascal and Rabbat, Michael and LeCun, Yann and Ballas, Nicolas},
  booktitle = CVPR,
  year      = {2023}
}

@inproceedings{huang2016deep,
  title     = {Deep networks with stochastic depth},
  author    = {Huang, Gao and Sun, Yu and Liu, Zhuang and Sedra, Daniel and Weinberger, Kilian Q},
  booktitle = ECCV,
  year      = {2016}
}

@inproceedings{amir2021deep,
  title     = {Deep vit features as dense visual descriptors},
  author    = {Amir, Shir and Gandelsman, Yossi and Bagon, Shai and Dekel, Tali},
  booktitle = {ECCV workshop on "What is Motion For?"},
  year      = {2022}
}


@inproceedings{tumanyan2022splicing,
  title     = {Splicing vit features for semantic appearance transfer},
  author    = {Tumanyan, Narek and Bar-Tal, Omer and Bagon, Shai and Dekel, Tali},
  booktitle = CVPR,
  year      = {2022}
}

@inproceedings{ofri2023neural,
  title     = {Neural congealing: Aligning images to a joint semantic atlas},
  author    = {Ofri-Amar, Dolev and Geyer, Michal and Kasten, Yoni and Dekel, Tali},
  booktitle = CVPR,
  year      = {2023}
}

@inproceedings{likhomanenko2021cape,
  title     = {Cape: Encoding relative positions with continuous augmented positional embeddings},
  author    = {Likhomanenko, Tatiana and Xu, Qiantong and Synnaeve, Gabriel and Collobert, Ronan and Rogozhnikov, Alex},
  booktitle = NIPS,
  year      = {2021}
}

@inproceedings{schuhmann2022laion,
  title     = {Laion-5b: An open large-scale dataset for training next generation image-text models},
  author    = {Schuhmann, Christoph and Beaumont, Romain and Vencu, Richard and Gordon, Cade and Wightman, Ross and Cherti, Mehdi and Coombes, Theo and Katta, Aarush and Mullis, Clayton and Wortsman, Mitchell and others},
  booktitle = NIPS,
  year      = {2022}
}

@inproceedings{cherti2023reproducible,
  title     = {Reproducible scaling laws for contrastive language-image learning},
  author    = {Cherti, Mehdi and Beaumont, Romain and Wightman, Ross and Wortsman, Mitchell and Ilharco, Gabriel and Gordon, Cade and Schuhmann, Christoph and Schmidt, Ludwig and Jitsev, Jenia},
  booktitle = CVPR,
  year      = {2023}
}

@inproceedings{beyer2023flexivit,
  title     = {Flexivit: One model for all patch sizes},
  author    = {Beyer, Lucas and Izmailov, Pavel and Kolesnikov, Alexander and Caron, Mathilde and Kornblith, Simon and Zhai, Xiaohua and Minderer, Matthias and Tschannen, Michael and Alabdulmohsin, Ibrahim and Pavetic, Filip},
  booktitle = CVPR,
  year      = {2023}
}

@inproceedings{hamilton2022unsupervised,
  title     = {Unsupervised semantic segmentation by distilling feature correspondences},
  author    = {Hamilton, Mark and Zhang, Zhoutong and Hariharan, Bharath and Snavely, Noah and Freeman, William T},
  booktitle = ICLR,
  year      = {2022}
}



@article{paszke2019pytorch,
  title   = {Pytorch: An imperative style, high-performance deep learning library},
  author  = {Paszke, Adam and Gross, Sam and Massa, Francisco and Lerer, Adam and Bradbury, James and Chanan, Gregory and Killeen, Trevor and Lin, Zeming and Gimelshein, Natalia and Antiga, Luca and others},
  journal = NIPS,
  year    = {2019}
}


@inproceedings{xue2023adaptive,
  title     = {Adaptive Computation with Elastic Input Sequence},
  author    = {Xue, Fuzhao and Likhosherstov, Valerii and Arnab, Anurag and Houlsby, Neil and Dehghani, Mostafa and You, Yang},
  booktitle = ICML,
  year      = {2023}
}


@article{burtsev2020memory,
  title   = {Memory transformer},
  author  = {Burtsev, Mikhail S and Kuratov, Yuri and Peganov, Anton and Sapunov, Grigory V},
  journal = {arXiv},
  year    = {2020}
}


@inproceedings{bulatov2022recurrent,
  title     = {Recurrent memory transformer},
  author    = {Bulatov, Aydar and Kuratov, Yury and Burtsev, Mikhail},
  booktitle = NIPS,
  year      = {2022}
}


@article{graves2014neural,
  title   = {Neural turing machines},
  author  = {Graves, Alex and Wayne, Greg and Danihelka, Ivo},
  journal = {arXiv},
  year    = {2014}
}


@inproceedings{song2021vidt,
  title     = {ViDT: An Efficient and Effective Fully Transformer-based Object Detector},
  author    = {Song, Hwanjun and Sun, Deqing and Chun, Sanghyuk and Jampani, Varun and Han, Dongyoon and Heo, Byeongho and Kim, Wonjae and Yang, Ming-Hsuan},
  booktitle = ICLR,
  year      = {2021}
}

@inproceedings{fang2021you,
  title     = {You only look at one sequence: Rethinking transformer in vision through object detection},
  author    = {Fang, Yuxin and Liao, Bencheng and Wang, Xinggang and Fang, Jiemin and Qi, Jiyang and Wu, Rui and Niu, Jianwei and Liu, Wenyu},
  booktitle = NIPS,
  year      = {2021}
}

@inproceedings{li2021prefix,
  title     = {Prefix-Tuning: Optimizing Continuous Prompts for Generation},
  author    = {Li, Xiang Lisa and Liang, Percy},
  booktitle = ICNLP,
  year      = {2021}
}

@inproceedings{lester2021power,
  title     = {The Power of Scale for Parameter-Efficient Prompt Tuning},
  author    = {Lester, Brian and Al-Rfou, Rami and Constant, Noah},
  booktitle = EMNLP,
  year      = {2021}
}


@inproceedings{sandler2022fine,
  title     = {Fine-tuning image transformers using learnable memory},
  author    = {Sandler, Mark and Zhmoginov, Andrey and Vladymyrov, Max and Jackson, Andrew},
  booktitle = CVPR,
  year      = {2022}
}



@inproceedings{carion2020end,
  title     = {End-to-end object detection with transformers},
  author    = {Carion, Nicolas and Massa, Francisco and Synnaeve, Gabriel and Usunier, Nicolas and Kirillov, Alexander and Zagoruyko, Sergey},
  booktitle = ECCV,
  year      = {2020}
}

@inproceedings{dehghani2023scaling,
  title     = {Scaling vision transformers to 22 billion parameters},
  author    = {Dehghani, Mostafa and Djolonga, Josip and Mustafa, Basil and Padlewski, Piotr and Heek, Jonathan and Gilmer, Justin and Steiner, Andreas Peter and Caron, Mathilde and Geirhos, Robert and Alabdulmohsin, Ibrahim and others},
  booktitle = ICML,
  year      = {2023}
}

@inproceedings{zheng2021rethinking,
  title     = {Rethinking semantic segmentation from a sequence-to-sequence perspective with transformers},
  author    = {Zheng, Sixiao and Lu, Jiachen and Zhao, Hengshuang and Zhu, Xiatian and Luo, Zekun and Wang, Yabiao and Fu, Yanwei and Feng, Jianfeng and Xiang, Tao and Torr, Philip HS and others},
  booktitle = CVPR,
  year      = {2021}
}

@article{kirillov2023segment,
  title   = {Segment anything},
  author  = {Kirillov, Alexander and Mintun, Eric and Ravi, Nikhila and Mao, Hanzi and Rolland, Chloe and Gustafson, Laura and Xiao, Tete and Whitehead, Spencer and Berg, Alexander C and Lo, Wan-Yen and others},
  journal = {arXiv},
  year    = {2023}
}

@article{wu2023mofi,
  title   = {MOFI: Learning Image Representations from Noisy Entity Annotated Images},
  author  = {Wu, Wentao and Timofeev, Aleksei and Chen, Chen and Zhang, Bowen and Duan, Kun and Liu, Shuangning and Zheng, Yantao and Shlens, Jon and Du, Xianzhi and Gan, Zhe and others},
  journal = {arXiv},
  year    = {2023}
}

@article{edstedt2023dedode,
  title   = {DeDoDe: Detect, Don't Describe--Describe, Don't Detect for Local Feature Matching},
  author  = {Edstedt, Johan and B{\"o}kman, Georg and Wadenb{\"a}ck, M{\aa}rten and Felsberg, Michael},
  journal = {arXiv},
  year    = {2023}
}



@article{zhang2023tale,
  title   = {A Tale of Two Features: Stable Diffusion Complements DINO for Zero-Shot Semantic Correspondence},
  author  = {Zhang, Junyi and Herrmann, Charles and Hur, Junhwa and Cabrera, Luisa Polania and Jampani, Varun and Sun, Deqing and Yang, Ming-Hsuan},
  journal = {arXiv},
  year    = {2023}
}

@article{edstedt2023roma,
  title   = {RoMa: Revisiting Robust Losses for Dense Feature Matching},
  author  = {Edstedt, Johan and Sun, Qiyu and B{\"o}kman, Georg and Wadenb{\"a}ck, M{\aa}rten and Felsberg, Michael},
  journal = {arXiv},
  year    = {2023}
}

@article{yan2023learning,
  title   = {Learning from Multi-View Representation for Point-Cloud Pre-Training},
  author  = {Yan, Siming and Song, Chen and Kong, Youkang and Huang, Qixing},
  journal = {arXiv},
  year    = {2023}
}

@inproceedings{alexnet,
  author    = {Krizhevsky, Alex and Sutskever, Ilya and Hinton, Geoffrey E},
  booktitle = NIPS,
  title     = {ImageNet Classification with Deep Convolutional Neural Networks},
  year      = {2012}
}

@inproceedings{torralba2014dataset,
  author    = {Torralba, Antonio and Efros, Alexei A.},
  booktitle = CVPR,
  title     = {Unbiased look at dataset bias.},
  year      = {2011}
}

@article{weston2014memory,
  abstract    = {We describe a new class of learning models called memory networks. Memory
                 networks reason with inference components combined with a long-term memory
                 component; they learn how to use these jointly. The long-term memory can be
                 read and written to, with the goal of using it for prediction. We investigate
                 these models in the context of question answering (QA) where the long-term
                 memory effectively acts as a (dynamic) knowledge base, and the output is a
                 textual response. We evaluate them on a large-scale QA task, and a smaller, but
                 more complex, toy task generated from a simulated world. In the latter, we show
                 the reasoning power of such models by chaining multiple supporting sentences to
                 answer questions that require understanding the intension of verbs.},
  added-at    = {2019-03-21T13:37:52.000+0100},
  author      = {Weston, Jason and Chopra, Sumit and Bordes, Antoine},
  biburl      = {https://www.bibsonomy.org/bibtex/2f3d51ba55acd2f7b50c18830c1f1fbe6/kirk86},
  description = {[1410.3916] Memory Networks},
  interhash   = {accbef7c6a665a063f7d6dc8f187de88},
  intrahash   = {f3d51ba55acd2f7b50c18830c1f1fbe6},
  keywords    = {deep-learning memory},
  note        = {cite arxiv:1410.3916},
  timestamp   = {2019-03-21T13:37:52.000+0100},
  title       = {Memory Networks},
  url         = {http://arxiv.org/abs/1410.3916},
  year        = 2014
}

@inproceedings{Sukhbaatar2015EndToEndMN,
  abstract  = {We introduce a neural network with a recurrent attention model over a possibly
               large external memory. The architecture is a form of Memory Network [23]
               but unlike the model in that work, it is trained end-to-end, and hence requires
               significantly less supervision during training, making it more generally applicable
               in realistic settings. It can also be seen as an extension of RNNsearch [2] to the
               case where multiple computational steps (hops) are performed per output symbol.
               The flexibility of the model allows us to apply it to tasks as diverse as (synthetic)
               question answering [22] and to language modeling. For the former our approach
               is competitive with Memory Networks, but with less supervision. For the latter,
               on the Penn TreeBank and Text8 datasets our approach demonstrates comparable
               performance to RNNs and LSTMs. In both cases we show that the key concept
               of multiple computational hops yields improved results.},
  added-at  = {2021-05-22T16:50:10.000+0200},
  author    = {Sukhbaatar, Sainbayar and Szlam, Arthur and Weston, Jason and Fergus, Rob},
  biburl    = {https://www.bibsonomy.org/bibtex/203f5581e3098cb5210a8aea4db1b657c/yannik.bonda},
  booktitle = {NIPS},
  interhash = {8d78e4f5165a609eba5c8ed887cf2498},
  intrahash = {03f5581e3098cb5210a8aea4db1b657c},
  keywords  = {final thema:rum},
  timestamp = {2021-05-22T16:50:10.000+0200},
  title     = {End-To-End Memory Networks},
  year      = 2015
}

@article{graves2016hybrid,
  author   = {Graves, Alex and Wayne, Greg and Reynolds, Malcolm and Harley, Tim and Danihelka, Ivo and Grabska-Barwińska, Agnieszka and Colmenarejo, Sergio Gómez and Grefenstette, Edward and Ramalho, Tiago and Agapiou, John and Badia, Adrià Puigdomènech and Hermann, Karl Moritz and Zwols, Yori and Ostrovski, Georg and Cain, Adam and King, Helen and Summerfield, Christopher and Blunsom, Phil and Kavukcuoglu, Koray and Hassabis, Demis},
  journal  = {Nature},
  keywords = {access deep direct learning memory network neural rnn toread},
  title    = {Hybrid computing using a neural network with dynamic external memory},
  url      = {http://dx.doi.org/10.1038/nature20101},
  volume   = 538,
  year     = 2016
}

@inproceedings{Jaegle2021PerceiverIO,
  title     = {Perceiver IO: A General Architecture for Structured Inputs \& Outputs},
  author    = {Andrew Jaegle and Sebastian Borgeaud and Jean-Baptiste Alayrac and Carl Doersch and Catalin Ionescu and David Ding and Skanda Koppula and Andrew Brock and Evan Shelhamer and Olivier J. H'enaff and Matthew M. Botvinick and Andrew Zisserman and Oriol Vinyals and Jo{\~a}o Carreira},
  booktitle = ICLR,
  year      = {2022}
}



@inproceedings{locatello2020object,
  title     = {Object-centric learning with slot attention},
  author    = {Locatello, Francesco and Weissenborn, Dirk and Unterthiner, Thomas and Mahendran, Aravindh and Heigold, Georg and Uszkoreit, Jakob and Dosovitskiy, Alexey and Kipf, Thomas},
  booktitle = NIPS,
  year      = {2020}
}


@inproceedings{igpt,
  title     = {Generative pretraining from pixels},
  author    = {Chen, Mark and Radford, Alec and Child, Rewon and Wu, Jeffrey and Jun, Heewoo and Luan, David and Sutskever, Ilya},
  booktitle = ICML,
  year      = {2020}
}

@article{bert,
  author  = {Jacob Devlin and
             Ming{-}Wei Chang and
             Kenton Lee and
             Kristina Toutanova},
  title   = {{BERT:} Pre-training of Deep Bidirectional Transformers for Language
             Understanding},
  journal = {CoRR},
  year    = {2018}
}

@misc{gpt,
  title  = {Improving language understanding by generative pre-training},
  author = {Radford, Alec and
            Narasimhan, Karthik and
            Salimans, Tim and
            Sutskever, Ilya
            },
  year   = {2018}
}

@article{lecun1989backpropagation,
  title   = {Backpropagation applied to handwritten zip code recognition},
  author  = {LeCun, Yann and Boser, Bernhard and Denker, John S and Henderson, Donnie and Howard, Richard E and Hubbard, Wayne and Jackel, Lawrence D},
  journal = {Neural computation},
  year    = {1989}
}

@inproceedings{aim,
  title     = {Scalable Pre-training of Large Autoregressive Image Models},
  author    = {Alaaeldin El-Nouby and Michal Klein and Shuangfei Zhai and Miguel Angel Bautista and Alexander Toshev and Vaishaal Shankar and Joshua M Susskind and Armand Joulin},
  booktitle = ICML,
  year      = {2024}
}

@misc{bardes2023v,
  title  = {V-jepa: Latent video prediction for visual representation learning},
  author = {Bardes, Adrien and Garrido, Quentin and Ponce, Jean and Chen, Xinlei and Rabbat, Michael and LeCun, Yann and Assran, Mido and Ballas, Nicolas},
  year   = {2023}
}

@article{rope,
  title   = {Roformer: Enhanced transformer with rotary position embedding},
  author  = {Su, Jianlin and Ahmed, Murtadha and Lu, Yu and Pan, Shengfeng and Bo, Wen and Liu, Yunfeng},
  journal = {Neurocomputing},
  year    = {2024}
}

@misc{crossmae,
  title         = {Rethinking Patch Dependence for Masked Autoencoders},
  author        = {Fu, Letian and Lian, Long and Wang, Renhao and Shi, Baifeng and Wang, Xudong and Yala, Adam and Darrell, Trevor and Efros, Alexei A and Goldberg, Ken},
  archiveprefix = {arXiv},
  year          = {2024}
}


@inproceedings{data2vec,
  title     = {data2vec: A General Framework for Self-supervised Learning in Speech, Vision and Language},
  author    = {Baevski, Alexei and Hsu, Wei-Ning and Xu, Qiantong and Babu, Arun and Gu, Jiatao and Auli, Michael},
  booktitle = ICML,
  year      = {2022}
}

@inproceedings{adam,
  title     = {Adam: A method for stochastic optimization},
  author    = {Kingma, Diederik P},
  booktitle = ICLR,
  year      = {2014}
}

@misc{adamw,
  title   = {Decoupled weight decay regularization},
  author  = {Loshchilov, I},
  journal = {arXiv},
  year    = {2017}
}
@inproceedings{vitneedreg,
  title     = {Vision Transformers Need Registers},
  author    = {Darcet, Timoth{\'e}e and Oquab, Maxime and Mairal, Julien and Bojanowski, Piotr},
  booktitle = ICLR,
  year      = {2024}
}

@inproceedings{minibatchkmeans,
  title     = {Web-scale k-means clustering},
  author    = {Sculley, David},
  booktitle = {WWW},
  year      = {2010}
}

@inproceedings{data2vec2,
  title     = {Efficient self-supervised learning with contextualized target representations for vision, speech and language},
  author    = {Baevski, Alexei and Babu, Arun and Hsu, Wei-Ning and Auli, Michael},
  booktitle = ICML,
  year      = {2023}
}

@inproceedings{bai2024sequential,
  title     = {Sequential modeling enables scalable learning for large vision models},
  author    = {Bai, Yutong and Geng, Xinyang and Mangalam, Karttikeya and Bar, Amir and Yuille, Alan L and Darrell, Trevor and Malik, Jitendra and Efros, Alexei A},
  booktitle = CVPR,
  year      = {2024}
}

#################### DINOv2 applications ####################

# keypoint matching

@inproceedings{roma,
  title     = {RoMa: Robust dense feature matching},
  author    = {Edstedt, Johan and Sun, Qiyu and B{\"o}kman, Georg and Wadenb{\"a}ck, M{\aa}rten and Felsberg, Michael},
  booktitle = {Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition},
  pages     = {19790--19800},
  year      = {2024}
}

# keypoint tracking
@inproceedings{dinotracker,
  title     = {Dino-tracker: Taming dino for self-supervised point tracking in a single video},
  author    = {Tumanyan, Narek and Singer, Assaf and Bagon, Shai and Dekel, Tali},
  booktitle = ECCV,
  year      = {2025}
}

# monodepth

@inproceedings{depthanything,
  title     = {Depth anything: Unleashing the power of large-scale unlabeled data},
  author    = {Yang, Lihe and Kang, Bingyi and Huang, Zilong and Xu, Xiaogang and Feng, Jiashi and Zhao, Hengshuang},
  booktitle = CVPR,
  year      = {2024}
}

@misc{depthanythingv2,
  title   = {Depth Anything V2},
  author  = {Yang, Lihe and Kang, Bingyi and Huang, Zilong and Zhao, Zhen and Xu, Xiaogang and Feng, Jiashi and Zhao, Hengshuang},
  journal = {arXiv},
  year    = {2024}
}

@misc{depthpro,
  title   = {Depth pro: Sharp monocular metric depth in less than a second},
  author  = {Bochkovskii, Aleksei and Delaunoy, Ama{\"e}l and Germain, Hugo and Santos, Marcel and Zhou, Yichao and Richter, Stephan R and Koltun, Vladlen},
  journal = {arXiv},
  year    = {2024}
}

# histopatho

@misc{phikonv2,
  title   = {Phikon-v2, a large and public feature extractor for biomarker prediction},
  author  = {Filiot, Alexandre and Jacob, Paul and Mac Kain, Alice and Saillard, Charlie},
  journal = {arXiv},
  year    = {2024}
}

@article{gigapath,
  title   = {A whole-slide foundation model for digital pathology from real-world data},
  author  = {Xu, Hanwen and Usuyama, Naoto and Bagga, Jaspreet and Zhang, Sheng and Rao, Rajesh and Naumann, Tristan and Wong, Cliff and Gero, Zelalem and Gonz{\'a}lez, Javier and Gu, Yu and others},
  journal = {Nature},
  year    = {2024}
}


@article{virchow,
  title   = {A foundation model for clinical-grade computational pathology and rare cancers detection},
  author  = {Vorontsov, Eugene and Bozkurt, Alican and Casson, Adam and Shaikovski, George and Zelechowski, Michal and Severson, Kristen and Zimmermann, Eric and Hall, James and Tenenholtz, Neil and Fusi, Nicolo and others},
  journal = {Nature medicine},
  year    = {2024}
}

@misc{virchow2,
  title   = {Virchow2: Scaling self-supervised mixed magnification models in pathology},
  author  = {Zimmermann, Eric and Vorontsov, Eugene and Viret, Julian and Casson, Adam and Zelechowski, Michal and Shaikovski, George and Tenenholtz, Neil and Hall, James and Klimstra, David and Yousfi, Razik and others},
  journal = {arXiv},
  year    = {2024}
}

@software{hoptimus0,
  author = {Saillard, Charlie and Jenatton, Rodolphe and Llinares-López, Felipe and Mariet, Zelda and Cahané, David and Durand, Eric and Vert, Jean-Philippe},
  title  = {H-optimus-0},
  url    = {https://github.com/bioptimus/releases/tree/main/models/h-optimus/v0},
  year   = {2024}
}

@misc{kaiko,
  title   = {Towards Large-Scale Training of Pathology Foundation Models},
  author  = {Aben, Nanne and de Jong, Edwin D and Gatopoulos, Ioannis and K{\"a}nzig, Nicolas and Karasikov, Mikhail and Lagr{\'e}, Axel and Moser, Roman and van Doorn, Joost and Tang, Fei and others},
  journal = {arXiv},
  year    = {2024}
}

@misc{hibou,
  title   = {Hibou: A Family of Foundational Vision Transformers for Pathology},
  author  = {Nechaev, Dmitry and Pchelnikov, Alexey and Ivanova, Ekaterina},
  journal = {arXiv},
  year    = {2024}
}

@misc{rudolfv,
  title   = {RudolfV: a foundation model by pathologists for pathologists},
  author  = {Dippel, Jonas and Feulner, Barbara and Winterhoff, Tobias and Milbich, Timo and Tietz, Stephan and Schallenberg, Simon and Dernbach, Gabriel and Kunft, Andreas and Heinke, Simon and Eich, Marie-Lisa and others},
  journal = {arXiv},
  year    = {2024}
}

@article{chen2024towards,
  title   = {Towards a general-purpose foundation model for computational pathology},
  author  = {Chen, Richard J and Ding, Tong and Lu, Ming Y and Williamson, Drew FK and Jaume, Guillaume and Song, Andrew H and Chen, Bowen and Zhang, Andrew and Shao, Daniel and Shaban, Muhammad and others},
  journal = {Nature Medicine},
  year    = {2024}
}

@inproceedings{pluto,
  title     = {PLUTO: Pathology-Universal Transformer},
  author    = {Juyal, Dinkar and Padigela, Harshith and Shah, Chintan and Shenker, Daniel and Harguindeguy, Natalia and Liu, Yi and Martin, Blake and Zhang, Yibo and Nercessian, Michael and Markey, Miles and others},
  year      = {2024},
  booktitle = {ICML 2024 Workshop on Efficient and Accessible Foundation Models for Biological Discovery}
}

# other medical

@misc{moutakanni2024advancing,
  title   = {Advancing human-centric AI for robust X-ray analysis through holistic self-supervised learning},
  author  = {Moutakanni, Th{\'e}o and Bojanowski, Piotr and Chassagnon, Guillaume and Hudelot, C{\'e}line and Joulin, Armand and LeCun, Yann and Muckley, Matthew and Oquab, Maxime and Revel, Marie-Pierre and Vakalopoulou, Maria},
  journal = {arXiv},
  year    = {2024}
}
@misc{endodino,
  title   = {EndoDINO: A Foundation Model for GI Endoscopy},
  author  = {Dermyer, Patrick and Kalra, Angad and Schwartz, Matt},
  journal = {arXiv},
  year    = {2025}
}

# satellite imagery
@article{tolan2024very,
  title   = {Very high resolution canopy height maps from RGB imagery using self-supervised vision transformer and convolutional decoder trained on aerial lidar},
  author  = {Tolan, Jamie and Yang, Hung-I and Nosarzewski, Benjamin and Couairon, Guillaume and Vo, Huy V and Brandt, John and Spore, Justine and Majumdar, Sayantan and Haziza, Daniel and Vamaraju, Janaki and others},
  journal = {Remote Sensing of Environment},
  year    = {2024}
}

#################################
@misc{caev2,
  title   = {CAE v2: Context Autoencoder with CLIP Target},
  author  = {Zhang, Xinyu and Chen, Jiahui and Yuan, Junkun and Chen, Qiang and Wang, Jian and Wang, Xiaodi and Han, Shumin and Chen, Xiaokang and Pi, Jimin and Yao, Kun and others},
  journal = {arXiv},
  year    = {2022}
}

@misc{torchvision,
  title        = {TorchVision: PyTorch's Computer Vision library},
  author       = {maintainers and contributors, TorchVision},
  year         = {2016},
  journal      = {GitHub repository},
  publisher    = {GitHub},
  howpublished = {\url{https://github.com/pytorch/vision}}
}


@article{lbfgs,
  title   = {A limited memory algorithm for bound constrained optimization},
  author  = {Byrd, Richard H and Lu, Peihuang and Nocedal, Jorge and Zhu, Ciyou},
  journal = {SIAM},
  year    = {1995}
}

@misc{cuml,
  title   = {Machine Learning in Python: Main developments and technology trends in data science, machine learning, and artificial intelligence},
  author  = {Raschka, Sebastian and Patterson, Joshua and Nolet, Corey},
  journal = {arXiv},
  year    = {2020}
}

@inproceedings{barstochastic,
  title={Stochastic positional embeddings improve masked image modeling},
  author={Bar, Amir and Bordes, Florian and Shocher, Assaf and Assran, Mido and Vincent, Pascal and Ballas, Nicolas and Darrell, Trevor and Globerson, Amir and LeCun, Yann},
  booktitle=ICML,
year={2024},
}


@misc{deepseekv3,
  title={Deepseek-v3 technical report},
  author={Liu, Aixin and Feng, Bei and Xue, Bing and Wang, Bingxuan and Wu, Bochao and Lu, Chengda and Zhao, Chenggang and Deng, Chengqi and Zhang, Chenyu and Ruan, Chong and others},
  journal={arXiv},
  year={2024}
}

@misc{mimrefiner,
  title={Mim-refiner: A contrastive learning boost from intermediate pre-trained representations},
  author={Alkin, Benedikt and Miklautz, Lukas and Hochreiter, Sepp and Brandstetter, Johannes},
  journal={arXiv},
  year={2024}
}

@article{huang2023contrastive,
  title={Contrastive masked autoencoders are stronger vision learners},
  author={Huang, Zhicheng and Jin, Xiaojie and Lu, Chengze and Hou, Qibin and Cheng, Ming-Ming and Fu, Dongmei and Shen, Xiaohui and Feng, Jiashi},
  journal=TPAMI,
  year={2023},
}

@article{sinkhorn1967concerning,
  title={Concerning nonnegative matrices and doubly stochastic matrices},
  author={Sinkhorn, Richard and Knopp, Paul},
  journal={Pacific Journal of Mathematics},
  year={1967},
}


@Article{matplotlib,
  Author    = {Hunter, J. D.},
  Title     = {Matplotlib: A 2D graphics environment},
  Journal   = {Computing in Science \& Engineering},
  year      = {2007}
}
