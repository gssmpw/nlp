\section{Discussion and Concluding Remarks}
In this paper, we have proposed a novel reconstruction-based self-supervised learning algorithm.
Our algorithm is based on an online clustering of dense features computed with a teacher network.
The latent assignments are used as targets to train the student.
We propose to implement the student as an encoder followed by a predictor: a cross-attention decoder.
The teacher is updated as an EMA of the encoder.
The proposed algorithm is simple and allows the training of a state-of-the-art model.
Our ViT-L outperforms all available reconstruction-based models, including much larger architectures.
We have shown promising scaling trends until the 300M model sizes of the ViT family, opening up a potential for further scaling in future work.

\subsubsection*{Acknowledgments}
We thank Momo for \cref{fig:quali}.
Julien Mairal was supported by ERC grant number 101087696 (APHELEIA project).
