\section{Discussion}
\label{sec:discussion}

\subsection{Error-Prone Points Identification}


In our Focused-DPO method, we introduce a dataset construction technique called \textbf{Error Prone Identification} to automatically identify error-prone points in generated code. To assess the correctness of the code, we employ a self-generation-and-validation mechanism based on PageRank, which captures the relative quality of different code snippets \cite{codedpo}. We are not like approaches such as Magicoder \cite{wei2023magicoder}, which directly use all test cases as ground truth. In our experiments we use the policy model to generate datasets. Since the policy model's generation quality is not as robust as that of more powerful models like GPT-4 (used in Magicoder), the PageRank-based method allows us to automatically filter out lower-quality test cases (those with lower scores after iteration), thereby ensuring higher overall dataset quality.

We find that different models exhibit varying levels of accuracy across different problems. Therefore, for each model's training dataset, we performed necessary filtering by removing code problems with excessively high or low accuracy rates, ensuring a consistent number of code problems in the final dataset. Moreover, we observe that models tend to exhibit similarities in error-prone points when solving the same problems. For example, when comparing the error-prone points identified by \textit{DeepSeekCoder-instruct-6.7B} and \textit{Qwen2.5-Coder-instruct-7B} models on the same set of programming problems, we found a 32\% overlap. This indicates that there are commonalities in the error-prone points across different models.

In our ablation studies, we compare error-prone points constructed using the \textit{git-diff} method and the \textit{Step-DPO} method, noting slight differences in the final results. 
% We also explored additional identification methods, including those from error localization work in the software engineering domain \cite{TODO}. However, their effectiveness in scenarios involving model-generated code remains limited based on our preliminary attempts and analysis.
Balancing effectiveness and efficiency, we use the method based on \textit{prefix} and \textit{suffix}, which allows us to identify error-prone points in generated code in a simple yet effective manner. We plan to further explore more identification strategies in future work.

\subsection{Data Scaling For Focused-DPO}

In our experiments, we use the policy model to sample the dataset for training, with the dataset statistics provided in Table \ref{tab:dataset-statistics}. We also explore how scaling the training data affects the final performance of Focused-DPO. Specifically, we investigate two additional settings: doubling the original training dataset to 10k samples and halving the dataset to 2.5k samples, to observe how these changes impact the effectiveness of the model after Focused-DPO training. 
The experimental results are presented in Table \ref{tab:datascaling}. The results indicate that fine-grained preference optimization converges efficiently within our given data range, and increasing the dataset size does not significantly improve the results.

\begin{table}[h!]
    \centering
    \resizebox{\linewidth}{!}{
    \begin{tabular}{lcc}
        \toprule
        \textbf{Data Scaling} & \textbf{HumanEval / HumanEval+} & \textbf{MBPP / MBPP+} \\
        \midrule
        Qwen2.5-coder-instruct-7B & 0.915 / 0.841 & 0.828 / 0.714 \\
        \midrule
        Focused-DPO (5k) & 0.926 / 0.878 & 0.846 / 0.761 \\
        \midrule
        Decrease to 2.5k & 0.926 / 0.847 & 0.830 / 0.719 \\
        Increase to 10k & 0.926 / 0.878 & 0.843 / 0.756 \\
        \bottomrule
    \end{tabular}
    }
    \caption{Dataset Scaling for Focused-DPO based on \textit{Qwen2.5-Coder-Instruct-7B}}
    \label{tab:datascaling}
\end{table}


\section{Dataset Statistics}

\begin{table}[h]
    \centering
    
    \resizebox{\linewidth}{!}{
    \begin{tabular}{lccc}
        \toprule
        \textbf{Dataset}            & \multicolumn{2}{c}{\textbf{Problems}} & \textbf{Avg. Hidden Tests} \\
        \midrule
        HumanEval                   & \multicolumn{2}{c}{\multirow{2}{*}{164}} & 9.57 \\
        HumanEval+                  & \multicolumn{2}{c}{}                      & 748.07 \\
        MBPP                        & \multicolumn{2}{c}{\multirow{2}{*}{378}} & 3.11   \\
        MBPP+                       & \multicolumn{2}{c}{}                      & 105.40 \\
        \multirow{3}{*}{LiveCodeBench} & Easy  & 279        & 18.07 \\
                                       & Medium   & 331     & 21.81 \\
                                       & Hard  & 270        & 24.78 \\
        \bottomrule
    \end{tabular}
    }
    \caption{Statistics of Evaluation Benchmark.}
    \label{tab:dataset-statistics}
\end{table}


\begin{table}[h]
    \centering
    \resizebox{0.8\linewidth}{!}{
    \scriptsize
    \begin{tabular}{lc}
        \toprule
        \textbf{Statistics based on Qwen2.5-Coder-Instruct-7B}             &    \\
        \midrule
        \multicolumn{1}{l}{\textit{Problems}} & \\
        \midrule
        Training Set                  & 5000              \\
        Validation Set                & 1000              \\
        \midrule
        \multicolumn{1}{l}{\textit{Average Token Lengths}} & \\
        \midrule
        Common Prefix                 & 78.17      \\
        Common Suffix                 & 33.98       \\
        Chosen Mid                    & 57.37      \\
        \hspace{2em} of Total Chosen Code  & 34\%              \\
        Rejected Mid                  & 42.63       \\
        \hspace{2em} of Total Rejected Code  & 28\%              \\
        \bottomrule
    \end{tabular}
    }
    \caption{Training Dataset Statistics based on Qwen2.5-Coder-Instruct-7B}
    \label{tab:training-dataset-statistics}
\end{table}


\section{Improvement in Error-Prone Points}
\label{sec:improveerrorpronepoints}
We further evaluate how Focused-DPO enhances the quality in error-prone points. 
Using our validation dataset (Table \ref{tab:dataset-statistics}), we measure the model's performance on these error-prone parts. 
The generation probability difference between \textit{chosen\_mid} and \textit{reject\_mid} in error-prone points is illustrated in Figure \ref{fig:diffaftertraining} for the \textit{Qwen2.5-Coder-Instruct-7B} model.

Compared to pre-Focused-DPO results (Figure \ref{fig:motivationprob}), Focused-DPO demonstrates a strong preference for generating more accurate code at error-prone points. 
This improvement is particularly critical in complex coding tasks, where precise decisions in error-prone points directly impact the correctness of the generated code. 
For instance, on the \textbf{LiveCodeBench-Hard} dataset—which consists of challenging, dynamically problems—Focused-DPO achieves a significant improvement of 42.8\% in correctness for the \textit{Qwen2.5-Coder-Instruct} model. 
Notably, on this dataset, Focused-DPO achieves performance on par with \textbf{GPT-4o}, highlighting its ability to address difficult code generation tasks effectively.

\begin{figure}[h]
\centering
  \includegraphics[width=\columnwidth]{diff_dis_after.png}  
\caption{Generation Probability Difference (p(chose\_mid) - p(reject\_mid)) after Focused-DPO.}
\label{fig:diffaftertraining}
\end{figure}


\section{Case Studies for Error-Prone Points}

We show some case studies for error-prone points based on \textit{Qwen2.5-Coder-instruct} in the following Figure \ref{fig:casestudy1}, \ref{fig:casestudy2} and \ref{fig:casestudy3}.
\begin{figure*}[h]
\centering
  \includegraphics[width=2\columnwidth]{casestudy1.png}  
\caption{Case Study: convert to valid variable name}
\label{fig:casestudy1}
\end{figure*}
\begin{figure*}[h]
\centering
  \includegraphics[width=2\columnwidth]{casestudy2.png}  
\caption{Case Study: parse version}
\label{fig:casestudy2}
\end{figure*}

\begin{figure*}[h]
\centering
  \includegraphics[width=2\columnwidth]{casestudy3.png}  
\caption{Case Study: max product}
\label{fig:casestudy3}
\end{figure*}