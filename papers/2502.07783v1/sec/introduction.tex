The scaling of model and data sizes has given rise to foundation models, such as Llama3 \cite{dubey2024llama} for natural language processing (NLP), DINOv2 \cite{oquab2023dinov2} for computer vision (CV), CLIP \cite{radford2021clip}and SigLIP \cite{zhai2023siglip} for multimodal tasks, and OpenVLA \cite{kim2024openvla} for embodied agent. These models are more universally capable than ever, accelerating a paradigm shift in artificial intelligence (AI): transitioning from training task-specific models from scratch to leveraging models pretrained on large datasets and fine-tuning them for downstream applications.

\begin{figure*}[t]
\vskip 0.1in
\begin{center}
\centerline{\includegraphics[width=\linewidth]{fig/ct_working_meachanism.pdf}}
\caption{\small Illustration of the \textbf{Curvature Tuning (CT)} mechanism for model steering. \textbf{CT steers a pretrained model by replacing ReLUs with a $\beta$-parameterized activation function and tuning $\beta$ from 1 to 0, progressively smoothing the model's decision boundary across tasks (e.g., classification and regression).} The $\beta$-parameterized activation function is defined in \cref{eq:CT}.}
\label{fig:CT}
\end{center}
\vskip -0.1in
\end{figure*}

Full fine-tuning, the process of steering a pretrained model by adapting all its parameters to downstream datasets, was once the primary approach for transferring knowledge. While it effectively enhances generalization \cite{radford2018gpt} and robustness \cite{jeddi2020finetune4robustness}, it is computationally expensive. To mitigate this, parameter-efficient fine-tuning (PEFT) methods such as Serial Adapter \cite{houlsby2019serialadapter} and LoRA \cite{hu2021lora} have been introduced, which partially alleviate the computational burden (as further training is still required) by fine-tuning only a small subset of parameters. However, these approaches face two additional challenges: a lack of principled design and limited interpretability. For instance, they rely on heuristic choices--such as LoRA’s rank, placement, and initialization--with minimal theoretical guidance. Moreover, they treat the model as a black box, making it unclear how pretrained knowledge is preserved or how the model is steered for downstream tasks. This combination of partial efficiency, heuristic-driven design, and poor interpretability underscores the need for fine-tuning methods that are efficient, principled, and interpretable. We thus ask the following question:
{\em How can we construct principled steering solutions addressing both efficiency and interpretability?}

We take a first step toward an overarching answer to how new PEFT solutions can be derived from theoretically grounded frameworks. Leveraging the spline framework of Deep Learning \cite{montufar2014numoflinreg, balestriero2018spline}, we develop a novel solution--\textbf{Curvature Tuning (CT)}--which modulates a model’s decision boundary curvature through a single parameter, $\beta$. CT offers several advantages, which we briefly outline below.

{\bf CT steers a model in inference mode without backpropagation.}~Since CT uses a single parameter to modulate the model's curvature, its optimal value can be determined via cross-validation without requiring training or backpropagation. This property ensures maximal computational and memory efficiency.

{\bf CT is interpretable for any value of $\beta$.}~CT replaces internal activation functions such as ReLU and Leaky ReLU with a convex combination of a reparameterized Swish function \cite{ramachandran2017swish} and a Softplus function, controlled by the parameter $\beta$. This theoretically grounded construction directly modulates the model’s decision boundary curvature. When $\beta = 1$, the original activation function is recovered, resulting in a piecewise affine decision boundary. When $\beta = 0$, the model becomes entirely linear, making the decision boundary globally affine. Intermediate values of $\beta$ gradually smooth the decision boundary, offering a continuous transition between these two extremes.

% By adjusting $\beta$ from 1 to 0, we can provably smooth the model's decision boundary or regression surface without altering its original parameters. Within our study, the steering parameter $\beta$ is obtained through cross-validation--but the parametrization is differentiable hence opening many avenues for training. 

% Unlike existing fine-tuning methods such as LoRA, which, despite being parameter-efficient, still require training multiple parameters even when the rank is set to one, CT operates in an extreme regime of efficiency, requiring only a single tunable parameter. Furthermore, the optimal parameter value is identified via search, completely avoiding the computationally expensive backpropagation required in fine-tuning methods. This makes CT particularly well-suited for scenarios with stringent computational constraints. 

% CT also eliminates the need for complex hyperparameter tuning, requiring only the definition of a simple bounded search range in $[0, 1]$ for its single parameter. This simplicity enhances efficiency and provides a theoretically grounded framework free of the intricate heuristic choices required by methods like LoRA, such as rank selection, module placement, or initialization.

% Beyond its efficiency and principled design, CT offers significantly better interpretability compared to existing fine-tuning methods. By provably modulating the curvature of the model’s decision boundary, CT provides a transparent mechanism for steering pretrained models. This interpretability is particularly critical in high-stakes applications such as medical AI, where understanding the model’s behavior is paramount.

{\bf CT significantly improves a model's performance across tasks and domains while enhancing robustness.}~We empirically validate the effectiveness of CT through extensive experiments, demonstrating improvements in both generalization and robustness. For same-task generalization, transferring ResNet-18 \cite{he2016resnet} across seventeen image classification datasets—including MNIST, CIFAR-10, CIFAR-100 \cite{krizhevsky2009learning}, and ImageNet \cite{deng2009imagenet}—yields a relative accuracy gain of 2.57\%. For cross-task generalization, CT achieves a relative improvement of 0.41\% in the mIoU of a PSPNet \cite{zhao2017psp} using an ImageNet-pretrained ResNet-50 as backbone on VOC2012 \cite{everingham2012voc}. Moreover, CT delivers a relative improvement of 11.76\% in the robust accuracy of an ImageNet-pretrained ResNet-18 on RobustBench \cite{croce2020robustbench}. Additional experiments with models such as ResNet-50/152, Swin-T/S, as well as additional datasets, further confirm CT's effectiveness.

A visual depiction of the CT mechanism is shown in \cref{fig:CT}, and our key contributions are summarized below:
\begin{enumerate}
    \item \textbf{Theoretical Contribution:} We introduce Curvature Tuning (CT), a training-free model steering technique that provably adjusts the curvature of model decision boundaries using a single parameter. This principled design ensures both efficiency and interpretability. Details are provided in \cref{sec:method}.
    \item \textbf{Empirical Contribution:} We demonstrate in \cref{sec:exp} that CT enhances generalization and robustness across various models, datasets, and tasks. For example, CT improves out-of-distribution transfer performances of ResNet-18/50 by 2.57\%/1.74\% across seventeen downstream datasets, and improves RobustBench robust accuracy by 11.76\%/348.44\%. It also improves generalization of ReLU-based Swin-T/S on nine downstream datasets by 2.43\%/3.33\%.
\end{enumerate}

The remainder of this paper is organized as follows: \cref{sec:background} reviews current fine-tuning techniques and introduces relevant spline concepts, the foundation for our method. \cref{sec:method} details our proposed method and its theoretical guarantees. \cref{sec:exp} presents experimental results, and \cref{sec:conclusion} summarizes our findings and potential future directions.