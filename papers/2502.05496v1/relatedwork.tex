\section{Related works}
\label{sec:Related works}
The proposed OSD aims to improve the accuracy of outlier detection algorithms by introducing physical principles into data analysis, therefore we discuss current related works on outlier detection algorithms and physics-based data analysis methods.

\textbf{Physics-based Data Analysis Methods.} Wright \cite{wright1977gravitational} first introduces gravity from physics into data analysis. He treats each object as a particle, with gravity existing between objects. Under the pull of gravity, all objects move in the feature space. Since then, many researchers begin to explore the application of gravity in the clustering task â€” a task in data analysis as critical as outlier detection. They usually adjust the distance between objects through gravity, so that objects within the same cluster become closer together, thereby reducing the difficulty of clustering algorithms in identifying clusters. Specifically, Newton \cite{blekas2007newtonian} believes that the dataset follows a Gaussian distribution, so it forces objects to move towards the cluster center in order to make the features of the Gaussian distribution more prominent. Herd \cite{wong2014herd} is similar to Newton, but it focuses more on the magnitude of force and sets a speed limit to avoid objects moving beyond the cluster center. In recent years, instead of forcing objects to be experienced by gravity in a fixed direction, many methods draw on the laws of celestial motion to stipulate that each object is experienced by gravities from multiple surrounding objects. HIBOG \cite{li2021hibog} is one of the most representative methods, and a large number of experiments have confirmed that HIBOG can improve the accuracy of tested clustering algorithms by more than twice. In order to avoid abnormal proximity of adjacent clusters, HIAC \cite{li2023improve} proposed a limited version of the gravity model, which stipulates that gravity only exists between valid neighbors. KDE-AHIAC \cite{pu2024adaptive} further improves HIAC by constructing a decision graph based on kernel density function and introducing an adaptive threshold selection method, making the selection of valid neighbors more convenient. DCLCMS \cite{zhang2022novel} identifies core objects based on the square ratio of gravity to mass, in order to improve the performance of clustering algorithms on datasets with large variations in density and manifold structure. PGCGP \cite{chen2023parallel} converts object movement into grid movement, significantly reducing the complexity of computing gravity on large-scale datasets. HCEG \cite{hao2024hceg} proposes a heterogeneous ensemble clustering method based on gravity to achieve intelligent data pricing. A small number of researchers also attempt to introduce gravity models into the outlier detection task and propose some gravity-based outlier detection algorithms \cite{zhu2022high, xie2020local}. These algorithms do not change the distance between objects just measure the similarity between objects based on gravity. However, they cannot reduce the difficulty of outlier detection algorithms in distinguishing between outliers and normal objects in the same way that the above-mentioned methods reduce the difficulty of clustering algorithms in detecting clusters. \emph{In this paper, for the outlier detection task, we propose an explosion shock force model that forces outliers and normal objects to move away from each other, radically reducing the difficulty of outlier detection algorithms in distinguishing between outliers and normal objects.}


\textbf{Outlier Detection Algorithms.} Outlier detection algorithms can be broadly classified as statistics-based algorithms, density-based algorithms, deep learning-based algorithms, and clustering-based algorithms. Specifically, statistics-based algorithms \cite{aydin2023boundary, li2023ecod, li2020copod, rousseeuw2011robust} usually assume that the dataset follows a certain distribution, and by analyzing the statistical properties of the objects, detect those objects that are significantly different from the overall distribution as outliers. Typically, the principles of statistical-based algorithms are easy to explain and perform well on small and low-dimensional datasets, but perform poorly on datasets that do not conform to known distributions. Density-based algorithms \cite{huang2023novel, zhou2024outlier, aydin2023boundary, breunig2000lof} detect outliers by comparing the local density of an object with its neighbors. Due to the focus on local information, density-based algorithms can identify local outliers, especially on datasets with uneven distribution. Clustering-based algorithms \cite{chen2021block, li2024detecting, rodriguez2014clustering} divide objects into different clusters and then detect those objects that do not belong to any cluster or are at the boundary of a cluster as outliers. Different cluster divisions may lead to vastly different outlier detection results. Deep learning-based algorithms \cite{hojjati2024dasvdd, goodge2022lunar, liu2021rca} have received a lot of attention in recent years, they embed the outlier detection task into neural networks. For example, by calculating the reconstruction error of objects in a self-encoder network, some deep learning-based algorithms detect an object with a large reconstruction error as an outlier. \emph{Obviously, there is an obvious principal barrier between different classes of outlier detection algorithms, which leads to the fact that existing optimization strategies cannot be suitable for different classes of outlier detection algorithms. In this paper, the optimization strategy we propose, OSD, is independent of the outlier detection principles, thus breaking down the barriers between different classes of outlier detection algorithms. As a result, OSD can optimize diverse outlier detection algorithms with vastly different principles.}