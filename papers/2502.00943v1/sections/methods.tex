\section{Universal Abstraction with \ours}

We propose \ours (pronounced as \textipa{~["u:ma"]}), a universal abstraction framework to leverage large language models to structure real world data from unstructured patient notes in a zero-shot manner. We design a flexible prompt template that allows users to define the specific set of attributes in interest. The prompt template includes predefined components, task-specific configurations, and per-patient input modules. We will detail each part below. In addition to covering the essential components for abstracting all types of attributes, \ours offers advanced components for handling complex, long-context attributes requiring long-term reasoning. The universal template is illustrated in \Cref{fig:gpt-universal-prompt-template}. 



\begin{figure}[t!]
\centering
\includegraphics[width=8cm]{figures/overview_figure_v3.pdf}
\caption{Illustration of \ours prompt template for universal abstraction. Shaded boxes are pre-defined elements and others are provided by or processed from user input. Dotted boxes indicate optional components. The template starts with the predefined role definition and the general extraction instruction. The users can provide specific task configurations including task definition alongside optional clinical guideline (further summarized by \ac{LLM}) and the output format. The user will also provide the data source where we process each patient's data and pass in either a single note at a time or an \ac{LLM}-summarized note from the patient history into the template. Optionally, we can retrieve and insert existing structured patient data alongside the patient note into the prompt template for enriched context. \Cref{fig:gpt-universal-prompt-template-simple} and \Cref{fig:gpt-universal-prompt-template-complex} show instantiations of the template for short-context and long-context attribute abstraction respectively. }
\label{fig:gpt-universal-prompt-template}
\end{figure}

\subsection{Pre-defined: general task introduction}
We begin by equipping the \ac{LLM} with a general understanding of the medical abstraction task, enabling it to apply this knowledge across various attributes. To achieve this, our universal prompt template starts with predefined, generic instructions common to all attribute extraction tasks. We first design the role definition as an AI assistant for medical abstraction, and then introduce the medical abstraction task. We define the attribute abstraction task as an event extraction task where we define an event group as an occurrence of the attribute from the patient report. In each event group (or attribute occurrence), there will be specific descriptors that describe the event.
With the generic setup, the users can later on add the attribute definition, the specific descriptors and the expected values they want the model to output for each attribute occurrence. 

\subsection{Task-specific configurations}


We modularize the task configurations to ensure scalability for new attributes. For each attribute, we configure the following components:

\paragraph{Attribute definition} For each task, we set up an attribute definition block in the prompt where the user can provide the specific task requirements for the attribute. Alongside providing the meaning of the attribute, the user can also define specific descriptors that can describe an attribute occurrence event. The value output for these descriptors should also be defined. For example, the values can be verbatim strings from the note or categorization according to a list of multiple choices described in the prompt. 
Below is an example definition for the two descriptors with the expected values for the performance status attribute:

\begin{verbatim}
"performance status measurement type": 
    name of measurement type: ECOG, KPS, PPS, or Lansky
"performance status value":
    the measured value of performance status measurement type.
    Extract only the numerical value.

\end{verbatim}

To enhance the utility and interpretability of the extracted attributes, additional contextual descriptors can be defined, such as the note date, degree of certainty, source text spans, and model reasoning. 
These descriptors can be used for postprocessing to improve quality, and support downstream analysis. They can also lead to better extraction accuracy by providing grounding and context that guide the \ac{LLM} in identifying the correct attribute values (as demonstrated in our ablation studies\Cref{table:ablation_study}).


\paragraph{Output format} 
To streamline extraction and post-processing, the output is formatted as a list of JSON objects for all tasks. To ensure the \ac{LLM} understands the desired structure, we provide a template example of the formatted output: a list of attribute occurrences. Each attribute occurrence is represented as a dictionary, where the keys correspond to descriptor names and the values are populated by the \ac{LLM} based on the extraction process.
For instance, the output format for performance status abstraction is structured as follows:


\begin{verbatim}
[
  {
  "performance status measurement type":
  <performance status type>,
  "performance status value":
  <performance status value>
  }
  ...
  ]
\end{verbatim}

\paragraph{Long-context Attribute: Incorporating clinical guidelines}
For certain tasks, users may provide complex clinical guidelines to help the \ac{LLM} understand specific attribute requirements. However, these guidelines are often comprehensive and lengthy, making it challenging to incorporate them directly into the prompt template due to \ac{LLM} context window limitations. For example, the guidelines for identifying tumor sites and histology are detailed in the International Classification of Diseases for Oncology (ICD-O) manual, which spans over 240 pages, while the cancer staging guidelines in the AJCC Cancer Staging Manual exceed 600 pages.

 To address the long clinical guideline challenge, we structured the guidelines in a one-time process to ensure that relevant information can be efficiently incorporated into the appropriate prompts.  We employ GPT-4 to perform the summarization. In addition, to make the summarization relevant for the attribute in focus, we incorporate the attribute definition block into the summarization prompt and instruct GPT-4 to generate attribute-specific summaries from the clinical guideline (See \Cref{fig:gpt-universal-prompt-template-complex}).









\subsection{Patient Input}
Once all instructions and requirements are set up in the prompt template, we can input patient data for the abstraction. Most patient data is in the form of unstructured text, including pathology reports, imaging reports, surgical notes, progress notes, encounter notes, and operative notes. Our universal prompt template is designed to flexibly accommodate any type of these notes.

\paragraph{Long-context Attribute: Reasoning over multiple notes from patient history}

In the basic setup of \ours, we can insert each single note independently to the patient input block of the prompt template and perform medical abstraction on the note level. However, some attribute abstraction tasks require reasoning over the entire patient history. A patient typically has multiple notes and some patients with a long clinical history can have more than 20 notes. To address long patient inputs, similar to how we summarize clinical guidelines, we use GPT-4 to perform an attribute-specific summarization step that extracts information relevant to the attribute from each note, creating a chronological patient summary (see \Cref{fig:gpt-universal-prompt-template-complex}). We can then input this summarized note in the patient input block of the template.
Notice that summarizing patient notes comes with the benefit of reducing computational cost and latency, as well as improving \ac{LLM} performance by avoiding duplicated content and removing irrelevant information such as boilerplate text, which are well-known challenges in processing patient records~\cite{searle2021estimating}. 
It has been widely shown that including irrelevant information not only heightens the computational demands but also detracts from the response quality in most \acp{LLM}~\cite{liu2024lost,mirzadeh2024gsm}. Our specific use case reaffirms this and we will demonstrate the positive impact of the summarization step later in our ablation study (see \Cref{table:ablation_study}). 


\paragraph{Long-context attribute: Leveraging existing or previously extracted structured data}
The prompt template has an optional block to incorporate any existing or previously extracted structured data to the patient input block to complement the unstructured input. These existing structured data can provide useful context, allowing extraction to focus on a more limited set of unstructured information. For example, clinical tumor staging should only incorporate information collected prior to treatment, and therefore it is helpful to provide the treatment date information when extracting clinical staging attributes. Another example is the staging attributes which benefit from knowing the coarse-grained tumor site prior to extraction. 
In fact, many attributes can be seen as part of a graph of related extractions, where previous attributes contribute to the extraction of subsequent attributes. Our framework provides the ability for users to configure such related extractions across different attributes so that the user can decide on the order of the attribute abstraction process and incorporate previously extracted attributes in the subsequent attribute extraction tasks. 






















\begin{figure}[t!]
\centering
\includegraphics[width=11cm]{figures/simple_attribute_figure_v2.pdf}
\caption{\ours template for short-context attributes which can be extracted from within a single note.}
\label{fig:gpt-universal-prompt-template-simple}
\end{figure}

\begin{figure}[t!]
\centering
\includegraphics[width=13cm]{figures/complex_attribute_figure_v2.pdf}
\caption{\ours template for long-context attributes (e.g. staging attributes) which require long-term reasoning over multiple notes and long clinical guidelines. We also provide the flexibility to chain the prompts to leverage previously extracted attributes.}
\label{fig:gpt-universal-prompt-template-complex}
\end{figure}
\subsection{Postprocessing \label{subsection: integrating LLM}}

Thanks to the modular and structured design, integrating \ours into the attribute abstraction pipeline is seamless. Once we obtain the JSON output from the \ac{LLM}, we implement post-processing steps to refine the extracted data to perform the final step for the abstraction.
In some cases, the descriptors in the \ac{LLM} output provide explicit criteria that can refine the attribute definitions. We can optionally use these descriptors to filter for high-quality occurrences, improving precision. For instance, we defined a disease type descriptor that specifies whether a response event refers to a tumor, lymph node, or non-cancerous tissue. This allows us to filter out non-cancerous events when extracting the response attribute, ensuring more accurate results.

The extracted attribute values are then standardized to medical ontologies, such as ICD-10-CM, NCI Thesaurus, the HUGO Gene Nomenclature Committee (HGNC), alongside nomenclatures standards like the Human Genome Variation Society (HGVS), or specific numerical values from laboratory tests (e.g., PD-L1 CPS 10\%). We introduce heuristics to generate a broader array of synonyms for each entity within our ontology, and then we use string matching to normalize the extracted values. 



After the entity normalization step, it is possible that there are redundant extractions both within a note and across notes. To resolve this, for attribute occurrences with the same value that are documented multiple times with closely aligned dates, we amalgamate and deduplicate them into a singular attribute group. Lastly, we associate each attribute occurrence with the patient ID. We can also attach the time stamp from the note to obtain a patient timeline that can be used to do further downstream applications.









































































    




































    
    
    



    






































