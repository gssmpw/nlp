

\section{Introduction}

\Ac{RWD} in healthcare refers to information collected from records representing standard medical care as opposed to data from research clinical trials. 
\Ac{RWD} can offer a more comprehensive view of patient experiences, helps optimize healthcare delivery, and supports more informed decision-making across the healthcare ecosystem. Particularly, \ac{RWD} can be used to generate \ac{RWE} which is increasingly utilized for medical evidence generation, providing a complement to the existing standard use of a \ac{RCT}. A significant proportion of \ac{RWD} comes from unstructured patient data, such as dictated progress notes and radiology reports, which store much of the patient information needed to improve care and clinical research. Medical abstraction is a process that structures \ac{RWD} by extracting and normalizing information from unstructured patient records. This study explores the use of \acp{LLM} to scale medical abstraction and achieve \textit{universal} abstraction. Here we define universal abstraction as an approach that can efficiently scale to extract new attributes from any ontology, adapt to evolving guidelines, and handle new patients and datasets\eat{across different institutions}. Such an approach promises to facilitate the rapid development of large-scale, structured patient data, unlocking significant opportunities in precision health and \ac{RWE} applications such as clinical trial matching and post-market surveillance. 


In contrast, traditional medical abstraction methods for structuring \ac{RWD} still require substantial manual efforts, such as crafting extraction rules or annotating examples for supervised learning. These manual efforts are expensive and time-consuming. In the U.S. alone, there are close to two million new cancer patients each year and curating key information for a single patient takes hours. As such, traditional abstraction is a significant barrier to realizing the full opportunity presented by the digitization of medical records~\citep{rudrapatna2020opportunities}. 
Moreover, evolving guidelines for defining key cancer attributes further compounds the challenge, leading to semantic drift and therefore often rendering previously collected labels outdated~\cite{gao2021limitations,gao2019classifying,preston2023toward}. For example, the \ac{AJCC} Cancer Staging Manual is now in its 8th edition, meaning the same tumor could be classified differently—as T2 before December 31st and T3 after January 1st—depending on the guideline version in use.


While traditional methods face challenges in efficiently scaling up medical abstraction due to the need to develop specialized models for each specific attribute,  state-of-the-art \acp{LLM} such as GPT-4 and GPT-4o have demonstrated emergent capabilities in biomedical applications without requiring any specialized training~\cite{lee2023benefits, nori2023can}. 
In this paper, we propose \oursfull, a framework that harnesses the universal structuring capabilities of \acp{LLM} for zero-shot universal abstraction. The key to \ours is a modular template that can flexibly incorporate patient data and the user-defined task definitions for each attribute, making our zero-shot approach fast, scalable, and highly adaptable. \ours also provides a post-processing step to further filter, normalize and aggregate the final abstractions ready for real-world applications such as clinical trial matching (\Cref{fig:gpt-overview}). 
We test \ours in oncology, where medical abstraction is particularly challenging. Specifically, we consider fifteen attributes encompassing staging diagnostics (e.g., tumor site, histology, staging), performance status, biomarker, treatment, and outcome (progression and response). 
These attributes capture key information for the longitudinal cancer patient journey and are immediately useful for a wide array of high-value applications such as cancer registries, molecular tumor boards, clinical trial matching, and post-market surveillance.
Moreover, the attributes are representative of a  spectrum of challenges in medical abstraction. Some attributes are short-context attributes which are self-contained within individual notes, such as performance status and biomarker status. Others are long-context attributes which require synthesizing information from multiple notes across the entire patient records and following lengthy and ever-changing clinical guidelines.

\ours offers a solution that can accommodate both short-context and long-context attribute abstraction as it can be conditioned on different types of input and requirements.
For long-context attributes, as the \ac{LLM} may not be able to hold the entire patient history and the entire clinical document in the context, we first pre-process the medical records and long clinical guidelines by prompting the \ac{LLM} to perform attribute-specific summarization. The resulting summaries are then inserted into predefined locations within the universal template for attribute extraction. In addition, \ours introduces several advanced techniques to enhance performance and interpretability. For each attribute, complementary descriptors such as chain-of-thought reasoning and supporting evidence are defined, improving the interpretability of the extracted data. Moreover, \ours enables prompt chaining, allowing the system to utilize previously extracted attributes to inform and refine subsequent extractions. 




We conduct our experiments on real-world data from the Providence Health System, a large integrated delivery network. We compare our approach to state-of-the-art supervised or heuristics-based baselines. 
Without requiring any specialized training, \ours displays impressive universal abstraction capabilities. \ours with GPT-4o surpasses baselines in the overall performance by around 2 absolute points in F1/accuracy scores for both short-context and long-context attribute abstraction tasks.
In some cases, such as pathologic T in cancer staging, \ours even outperforms the supervised method by over 20 absolute points in accuracy. 









\eat{
Through this exploration we make the following contributions:
\begin{itemize}
    \item We evaluate the performance of recent large language models on the extraction of fifteen key attributes from patient records, a level of performance that suggests to a universal structuring capacity and may enable the creation of fit-for-purpose structured patient representations.
    \item We demonstrate that GPT-4 can effectively abstract attributes by ingesting relevant standard guidelines provided in the prompt, enabling rapid development of abstraction processes to adapt to new guideline versions or new attributes without additional supervised training.
    \item We provide a thorough ablation study on prompt configuration and identify best practices in handling challenges that typify clinical text, such as context length limits.
\end{itemize}
}


\begin{figure}[t!]
\centering
\includegraphics[width=14cm]{figures/overview_v2.pdf}
\caption{In contrast with the conventional approach that build specialized models for each specific attribute (slow and costly due to the manual collection of training labels or heuristic rules), \ours is a one-model-for-all approach that can be quickly configured to abstract any user-defined medical attributes from unstructured patient data in a zero-shot manner. The outcome of the pipeline is structured real-world data that serves as the foundation for real-world applications such as clinical trial matching, drug discovery and etc.}
\label{fig:gpt-overview}
\end{figure}
