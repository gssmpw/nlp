
\section{Discussion}


\subsection{The Potential for \ours Integration into Clinical Workflows}

The strong performance and the rapid development time of \ours opens up significant opportunities to scale universal abstraction. Compared to conventional methods, which can take months or even years to collect training data or develop data-specific heuristics, \ours is scalable and fast as the time for onboarding a new attribute is essentially only the time for defining the attributes and tasks. Therefore, we can quickly build large-scale structured patient records that can serve many downstream clinical analyses ranging from care delivery in the hospital to recruitment for clinical trial matching. 
\eat{
As shown in the Providence / Johns Hopkins comparison, \ours also generalizes better. This is directly due to the system’s zero-shot nature – the abstraction is done only based on dataset-independent guidelines and definitions, not on the idiosyncrasies of a particular dataset. }
Beyond saving initial training time, \ours also makes it simple to update the abstraction to support new guideline versions quickly. This is increasingly important as many guidelines have moved to “rolling” updates that occur yearly or even more frequently. In cancer staging the requirement is to use the appropriate guideline version based on the date of diagnosis, therefore multiple guideline versions may need to be supported simultaneously and \ours can seamlessly incorporate this requirement. 

While the \ours performance is impressive, most clinical applications will still require human verification. It is therefore critical that our framework produces outputs that allow rapid review of the generated results. Fortunately, \ours can
naturally provide metadata that allow for rapid human review. For example, the summarized patient history allows a user to quickly understand the overall context of patient care. 
The chain-of-thought reasoning descriptor provides additional details of the reasoning used by the system. The contextual evidence descriptor in the extracted output provides further context and clarity for the attributes.

Another practical advantage of \ours in abstracting long-context attributes is its efficiency. As previously discussed, the task-specific summarization allows accelerated human review and improved token efficiency. The efficiency gain is far more significant in realistic use cases where the patient history is continually updated with new notes from ongoing care. In this case, an updated summary can be generated by summarizing new notes and appending the results to the existing patient summary. This updated summary can then be used to update the abstracted data elements.



\subsection{Limitations}
A notable limitation of our study is the data quality, and specifically the problem of missing data. This arises from the fragmented nature of patient records, often spread across multiple providers. While gold-standard processes such as cancer registries access patient records across providers, our records are limited to content from the EHR system of a single provider. The absence of notes from other hospitals and clinics restricts our ability to comprehensively capture the full spectrum of a patient's medical history. Future endeavors would benefit greatly from integrating patient notes from diverse hospital systems and clinics. Such an expansion would not only enrich the data set but also enhance the accuracy and completeness of the longitudinal patient history, offering a more detailed and holistic view of patient care trajectories. 

Additionally, our study serves as a proof-of-concept, demonstrating what can be achieved using LLM with basic prompting techniques. While we show that our basic prompting techniques already achieve on-par or even better performance than conventional methods, we did not fully exhaust all available prompting techniques, such as self-verification, self-consistency and more advanced few-shot learning approaches, which could further enhance model performance in future research.








