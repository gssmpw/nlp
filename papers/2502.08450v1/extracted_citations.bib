@book{criterial_feature,
  title={Criterial features in L2 English: Specifying the reference levels of the Common European Framework},
  author={Hawkins, JA},
  year={2012},
  publisher={Cambridge University Press}
}

@inproceedings{gec_aes1,
    title = "Investigating the effect of auxiliary objectives for the automated grading of learner {E}nglish speech transcriptions",
    author = "Craighead, Hannah  and
      Caines, Andrew  and
      Buttery, Paula  and
      Yannakoudakis, Helen",
    editor = "Jurafsky, Dan  and
      Chai, Joyce  and
      Schluter, Natalie  and
      Tetreault, Joel",
    booktitle = "Proceedings of the 58th Annual Meeting of the Association for Computational Linguistics",
    month = jul,
    year = "2020",
    address = "Online",
    publisher = "Association for Computational Linguistics",
    url = "https://aclanthology.org/2020.acl-main.206",
    doi = "10.18653/v1/2020.acl-main.206",
    pages = "2258--2269",
    abstract = "We address the task of automatically grading the language proficiency of spontaneous speech based on textual features from automatic speech recognition transcripts. Motivated by recent advances in multi-task learning, we develop neural networks trained in a multi-task fashion that learn to predict the proficiency level of non-native English speakers by taking advantage of inductive transfer between the main task (grading) and auxiliary prediction tasks: morpho-syntactic labeling, language modeling, and native language identification (L1). We encode the transcriptions with both bi-directional recurrent neural networks and with bi-directional representations from transformers, compare against a feature-rich baseline, and analyse performance at different proficiency levels and with transcriptions of varying error rates. Our best performance comes from a transformer encoder with L1 prediction as an auxiliary task. We discuss areas for improvement and potential applications for text-only speech scoring.",
}

@inproceedings{gec_aes2,
    title = "Score It All Together: A Multi-Task Learning Study on Automatic Scoring of Argumentative Essays",
    author = "Ding, Yuning  and
      Bexte, Marie  and
      Horbach, Andrea",
    editor = "Rogers, Anna  and
      Boyd-Graber, Jordan  and
      Okazaki, Naoaki",
    booktitle = "Findings of the Association for Computational Linguistics: ACL 2023",
    month = jul,
    year = "2023",
    address = "Toronto, Canada",
    publisher = "Association for Computational Linguistics",
    url = "https://aclanthology.org/2023.findings-acl.825",
    doi = "10.18653/v1/2023.findings-acl.825",
    pages = "13052--13063",
    abstract = "When scoring argumentative essays in an educational context, not only the presence or absence of certain argumentative elements but also their quality is important. On the recently published student essay dataset PERSUADE, we first show that the automatic scoring of argument quality benefits from additional information about context, writing prompt and argument type. We then explore the different combinations of three tasks: automated span detection, type and quality prediction. Results show that a multi-task learning approach combining the three tasks outperforms sequential approaches that first learn to segment and then predict the quality/type of a segment.",
}

@inproceedings{gec_aes3,
    title = "Multi-task Learning for Automated Essay Scoring with Sentiment Analysis",
    author = "Muangkammuen, Panitan  and
      Fukumoto, Fumiyo",
    editor = "Shmueli, Boaz  and
      Huang, Yin Jou",
    booktitle = "Proceedings of the 1st Conference of the Asia-Pacific Chapter of the Association for Computational Linguistics and the 10th International Joint Conference on Natural Language Processing: Student Research Workshop",
    month = dec,
    year = "2020",
    address = "Suzhou, China",
    publisher = "Association for Computational Linguistics",
    url = "https://aclanthology.org/2020.aacl-srw.17",
    pages = "116--123",
    abstract = "Automated Essay Scoring (AES) is a process that aims to alleviate the workload of graders and improve the feedback cycle in educational systems. Multi-task learning models, one of the deep learning techniques that have recently been applied to many NLP tasks, demonstrate the vast potential for AES. In this work, we present an approach for combining two tasks, sentiment analysis, and AES by utilizing multi-task learning. The model is based on a hierarchical neural network that learns to predict a holistic score at the document-level along with sentiment classes at the word-level and sentence-level. The sentiment features extracted from opinion expressions can enhance a vanilla holistic essay scoring, which mainly focuses on lexicon and text semantics. Our approach demonstrates that sentiment features are beneficial for some essay prompts, and the performance is competitive to other deep learning models on the Automated StudentAssessment Prize (ASAP) benchmark. TheQuadratic Weighted Kappa (QWK) is used to measure the agreement between the human grader{'}s score and the model{'}s prediction. Ourmodel produces a QWK of 0.763.",
}

@article{gec_aes5,
  title={Neural Multi-task Learning in Automated Assessment},
  author={Ronan Cummins and Marek Rei},
  journal={ArXiv},
  year={2018},
  volume={abs/1801.06830},
  url={https://api.semanticscholar.org/CorpusID:9111290}
}

@inproceedings{gec_aes6,
    title = "Automated Essay Scoring Using Grammatical Variety and Errors with Multi-Task Learning and Item Response Theory",
    author = "Doi, Kosuke  and
      Sudoh, Katsuhito  and
      Nakamura, Satoshi",
    editor = {Kochmar, Ekaterina  and
      Bexte, Marie  and
      Burstein, Jill  and
      Horbach, Andrea  and
      Laarmann-Quante, Ronja  and
      Tack, Ana{\"\i}s  and
      Yaneva, Victoria  and
      Yuan, Zheng},
    booktitle = "Proceedings of the 19th Workshop on Innovative Use of NLP for Building Educational Applications (BEA 2024)",
    month = jun,
    year = "2024",
    address = "Mexico City, Mexico",
    publisher = "Association for Computational Linguistics",
    url = "https://aclanthology.org/2024.bea-1.26",
    pages = "316--329",
    abstract = "This study examines the effect of grammatical features in automatic essay scoring (AES). We use two kinds of grammatical features as input to an AES model: (1) grammatical items that writers used correctly in essays, and (2) the number of grammatical errors. Experimental results show that grammatical features improve the performance of AES models that predict the holistic scores of essays. Multi-task learning with the holistic and grammar scores, alongside using grammatical features, resulted in a larger improvement in model performance. We also show that a model using grammar abilities estimated using Item Response Theory (IRT) as the labels for the auxiliary task achieved comparable performance to when we used grammar scores assigned by human raters. In addition, we weight the grammatical features using IRT to consider the difficulty of grammatical items and writers{'} grammar abilities. We found that weighting grammatical features with the difficulty led to further improvement in performance.",
}

@article{gec_aes7,
title = {Automated Essay Scoring based on Two-Stage Learning},
author = {Liu, Jiawei and Xu, Yang and Zhao, Lingzhe},
journal={ArXiv},
year = {2019},
doi = {10.48550/arXiv.1901.07744}
}

