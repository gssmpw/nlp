% Use this file for citations not found in the ACL Anthology (contained in "anthology.bib").

@inproceedings{gec_aes1,
    title = "Investigating the effect of auxiliary objectives for the automated grading of learner {E}nglish speech transcriptions",
    author = "Craighead, Hannah  and
      Caines, Andrew  and
      Buttery, Paula  and
      Yannakoudakis, Helen",
    editor = "Jurafsky, Dan  and
      Chai, Joyce  and
      Schluter, Natalie  and
      Tetreault, Joel",
    booktitle = "Proceedings of the 58th Annual Meeting of the Association for Computational Linguistics",
    month = jul,
    year = "2020",
    address = "Online",
    publisher = "Association for Computational Linguistics",
    url = "https://aclanthology.org/2020.acl-main.206",
    doi = "10.18653/v1/2020.acl-main.206",
    pages = "2258--2269",
    abstract = "We address the task of automatically grading the language proficiency of spontaneous speech based on textual features from automatic speech recognition transcripts. Motivated by recent advances in multi-task learning, we develop neural networks trained in a multi-task fashion that learn to predict the proficiency level of non-native English speakers by taking advantage of inductive transfer between the main task (grading) and auxiliary prediction tasks: morpho-syntactic labeling, language modeling, and native language identification (L1). We encode the transcriptions with both bi-directional recurrent neural networks and with bi-directional representations from transformers, compare against a feature-rich baseline, and analyse performance at different proficiency levels and with transcriptions of varying error rates. Our best performance comes from a transformer encoder with L1 prediction as an auxiliary task. We discuss areas for improvement and potential applications for text-only speech scoring.",
}

@inproceedings{gec_aes2,
    title = "Score It All Together: A Multi-Task Learning Study on Automatic Scoring of Argumentative Essays",
    author = "Ding, Yuning  and
      Bexte, Marie  and
      Horbach, Andrea",
    editor = "Rogers, Anna  and
      Boyd-Graber, Jordan  and
      Okazaki, Naoaki",
    booktitle = "Findings of the Association for Computational Linguistics: ACL 2023",
    month = jul,
    year = "2023",
    address = "Toronto, Canada",
    publisher = "Association for Computational Linguistics",
    url = "https://aclanthology.org/2023.findings-acl.825",
    doi = "10.18653/v1/2023.findings-acl.825",
    pages = "13052--13063",
    abstract = "When scoring argumentative essays in an educational context, not only the presence or absence of certain argumentative elements but also their quality is important. On the recently published student essay dataset PERSUADE, we first show that the automatic scoring of argument quality benefits from additional information about context, writing prompt and argument type. We then explore the different combinations of three tasks: automated span detection, type and quality prediction. Results show that a multi-task learning approach combining the three tasks outperforms sequential approaches that first learn to segment and then predict the quality/type of a segment.",
}

@inproceedings{gec_aes3,
    title = "Multi-task Learning for Automated Essay Scoring with Sentiment Analysis",
    author = "Muangkammuen, Panitan  and
      Fukumoto, Fumiyo",
    editor = "Shmueli, Boaz  and
      Huang, Yin Jou",
    booktitle = "Proceedings of the 1st Conference of the Asia-Pacific Chapter of the Association for Computational Linguistics and the 10th International Joint Conference on Natural Language Processing: Student Research Workshop",
    month = dec,
    year = "2020",
    address = "Suzhou, China",
    publisher = "Association for Computational Linguistics",
    url = "https://aclanthology.org/2020.aacl-srw.17",
    pages = "116--123",
    abstract = "Automated Essay Scoring (AES) is a process that aims to alleviate the workload of graders and improve the feedback cycle in educational systems. Multi-task learning models, one of the deep learning techniques that have recently been applied to many NLP tasks, demonstrate the vast potential for AES. In this work, we present an approach for combining two tasks, sentiment analysis, and AES by utilizing multi-task learning. The model is based on a hierarchical neural network that learns to predict a holistic score at the document-level along with sentiment classes at the word-level and sentence-level. The sentiment features extracted from opinion expressions can enhance a vanilla holistic essay scoring, which mainly focuses on lexicon and text semantics. Our approach demonstrates that sentiment features are beneficial for some essay prompts, and the performance is competitive to other deep learning models on the Automated StudentAssessment Prize (ASAP) benchmark. TheQuadratic Weighted Kappa (QWK) is used to measure the agreement between the human grader{'}s score and the model{'}s prediction. Ourmodel produces a QWK of 0.763.",
}

@book{criterial_feature,
  title={Criterial features in L2 English: Specifying the reference levels of the Common European Framework},
  author={Hawkins, JA},
  year={2012},
  publisher={Cambridge University Press}
}

@inproceedings{gec_simple,
    title = "A Simple Recipe for Multilingual Grammatical Error Correction",
    author = "Rothe, Sascha  and
      Mallinson, Jonathan  and
      Malmi, Eric  and
      Krause, Sebastian  and
      Severyn, Aliaksei",
    editor = "Zong, Chengqing  and
      Xia, Fei  and
      Li, Wenjie  and
      Navigli, Roberto",
    booktitle = "Proceedings of the 59th Annual Meeting of the Association for Computational Linguistics and the 11th International Joint Conference on Natural Language Processing (Volume 2: Short Papers)",
    month = aug,
    year = "2021",
    address = "Online",
    publisher = "Association for Computational Linguistics",
    url = "https://aclanthology.org/2021.acl-short.89",
    doi = "10.18653/v1/2021.acl-short.89",
    pages = "702--707",
    abstract = "This paper presents a simple recipe to trainstate-of-the-art multilingual Grammatical Error Correction (GEC) models. We achieve this by first proposing a language-agnostic method to generate a large number of synthetic examples. The second ingredient is to use large-scale multilingual language models (up to 11B parameters). Once fine-tuned on language-specific supervised sets we surpass the previous state-of-the-art results on GEC benchmarks in four languages: English, Czech, German and Russian. Having established a new set of baselines for GEC, we make our results easily reproducible and accessible by releasing a CLANG-8 dataset. It is produced by using our best model, which we call gT5, to clean the targets of a widely used yet noisy Lang-8 dataset. cLang-8 greatly simplifies typical GEC training pipelines composed of multiple fine-tuning stages {--} we demonstrate that performing a single fine-tuning stepon cLang-8 with the off-the-shelf language models yields further accuracy improvements over an already top-performing gT5 model for English.",
}

@inproceedings{errant,
    title = "Automatic Annotation and Evaluation of Error Types for Grammatical Error Correction",
    author = "Bryant, Christopher  and
      Felice, Mariano  and
      Briscoe, Ted",
    editor = "Barzilay, Regina  and
      Kan, Min-Yen",
    booktitle = "Proceedings of the 55th Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers)",
    month = jul,
    year = "2017",
    address = "Vancouver, Canada",
    publisher = "Association for Computational Linguistics",
    url = "https://aclanthology.org/P17-1074",
    doi = "10.18653/v1/P17-1074",
    pages = "793--805",
    abstract = "Until now, error type performance for Grammatical Error Correction (GEC) systems could only be measured in terms of recall because system output is not annotated. To overcome this problem, we introduce ERRANT, a grammatical ERRor ANnotation Toolkit designed to automatically extract edits from parallel original and corrected sentences and classify them according to a new, dataset-agnostic, rule-based framework. This not only facilitates error type evaluation at different levels of granularity, but can also be used to reduce annotator workload and standardise existing GEC datasets. Human experts rated the automatic edits as {``}Good{''} or {``}Acceptable{''} in at least 95{\%} of cases, so we applied ERRANT to the system output of the CoNLL-2014 shared task to carry out a detailed error type analysis for the first time.",
}

@article{gec_aes7,
title = {Automated Essay Scoring based on Two-Stage Learning},
author = {Liu, Jiawei and Xu, Yang and Zhao, Lingzhe},
journal={ArXiv},
year = {2019},
doi = {10.48550/arXiv.1901.07744}
}

@article{gec_aes5,
  title={Neural Multi-task Learning in Automated Assessment},
  author={Ronan Cummins and Marek Rei},
  journal={ArXiv},
  year={2018},
  volume={abs/1801.06830},
  url={https://api.semanticscholar.org/CorpusID:9111290}
}

@inproceedings{ryu24_interspeech,
  title     = {Key-Element-Informed sLLM Tuning for Document Summarization},
  author    = {Sangwon Ryu and Heejin Do and Yunsu Kim and Gary Geunbae Lee and Jungseul Ok},
  year      = {2024},
  booktitle = {Interspeech 2024},
  pages     = {1940â€“1944},
  doi       = {10.21437/Interspeech.2024-2389},
  issn      = {2958-1796},
}

@inproceedings{gec_aes6,
    title = "Automated Essay Scoring Using Grammatical Variety and Errors with Multi-Task Learning and Item Response Theory",
    author = "Doi, Kosuke  and
      Sudoh, Katsuhito  and
      Nakamura, Satoshi",
    editor = {Kochmar, Ekaterina  and
      Bexte, Marie  and
      Burstein, Jill  and
      Horbach, Andrea  and
      Laarmann-Quante, Ronja  and
      Tack, Ana{\"\i}s  and
      Yaneva, Victoria  and
      Yuan, Zheng},
    booktitle = "Proceedings of the 19th Workshop on Innovative Use of NLP for Building Educational Applications (BEA 2024)",
    month = jun,
    year = "2024",
    address = "Mexico City, Mexico",
    publisher = "Association for Computational Linguistics",
    url = "https://aclanthology.org/2024.bea-1.26",
    pages = "316--329",
    abstract = "This study examines the effect of grammatical features in automatic essay scoring (AES). We use two kinds of grammatical features as input to an AES model: (1) grammatical items that writers used correctly in essays, and (2) the number of grammatical errors. Experimental results show that grammatical features improve the performance of AES models that predict the holistic scores of essays. Multi-task learning with the holistic and grammar scores, alongside using grammatical features, resulted in a larger improvement in model performance. We also show that a model using grammar abilities estimated using Item Response Theory (IRT) as the labels for the auxiliary task achieved comparable performance to when we used grammar scores assigned by human raters. In addition, we weight the grammatical features using IRT to consider the difficulty of grammatical items and writers{'} grammar abilities. We found that weighting grammatical features with the difficulty led to further improvement in performance.",
}

@book{Aho:72,
    author  = {Alfred V. Aho and Jeffrey D. Ullman},
    title   = {The Theory of Parsing, Translation and Compiling},
    year    = "1972",
    volume  = "1",
    publisher = {Prentice-Hall},
    address = {Englewood Cliffs, NJ}
}

@book{APA:83,
    author  = {{American Psychological Association}},
    title   = {Publications Manual},
    year    = "1983",
    publisher = {American Psychological Association},
    address = {Washington, DC}
}

@article{Chandra:81,
	author = {Ashok K. Chandra and Dexter C. Kozen and Larry J. Stockmeyer},
	year = "1981",
	title = {Alternation},
	journal = {Journal of the Association for Computing Machinery},
	volume = "28",
	number = "1",
	pages = "114--133",
	doi = "10.1145/322234.322243",
}

@inproceedings{andrew2007scalable,
  title={Scalable training of {$L_1$}-regularized log-linear models},
  author={Andrew, Galen and Gao, Jianfeng},
  booktitle={Proceedings of the 24th International Conference on Machine Learning},
  pages={33--40},
  year={2007},
  url={https://dl.acm.org/doi/abs/10.1145/1273496.1273501}
}

@book{Gusfield:97,
    author  = {Dan Gusfield},
    title   = {Algorithms on Strings, Trees and Sequences},
    year    = "1997",
    publisher = {Cambridge University Press},
    address = {Cambridge, UK},
    url={https://www.cambridge.org/core/books/algorithms-on-strings-trees-and-sequences/F0B095049C7E6EF5356F0A26686C20D3}
}

@article{rasooli-tetrault-2015,
    author    = {Mohammad Sadegh Rasooli and Joel R. Tetreault},
    title     = {Yara Parser: {A} Fast and Accurate Dependency Parser},
    journal   = {Computing Research Repository},
    volume    = {arXiv:1503.06733},
    year      = {2015},
    url       = {http://arxiv.org/abs/1503.06733},
    note    = {version 2}
}

@article{Ando2005,
	Acmid = {1194905},
	Author = {Ando, Rie Kubota and Zhang, Tong},
	Issn = {1532-4435},
	Issue_Date = {12/1/2005},
	Journal = {Journal of Machine Learning Research},
	Month = dec,
	Numpages = {37},
	Pages = {1817--1853},
	Publisher = {JMLR.org},
	Title = {A Framework for Learning Predictive Structures from Multiple Tasks and Unlabeled Data},
	Volume = {6},
	Year = {2005},
	url={https://www.jmlr.org/papers/volume6/ando05a/ando05a.pdf}
}

@article{ct1965,
  title={An algorithm for the machine calculation of complex {F}ourier series},
  author={Cooley, James W. and Tukey, John W.},
  journal={Mathematics of Computation},
  volume={19},
  number={90},
  pages={297--301},
  year={1965},
  url={https://www.ams.org/journals/mcom/1965-19-090/S0025-5718-1965-0178586-1/S0025-5718-1965-0178586-1.pdf}
}

@book{em:86,
  editor  = "Engelmore, Robert and Morgan, Anthony",
  title   = "Blackboard Systems",
  year    = 1986,
  address = "Reading, Mass.",
  publisher = "Addison-Wesley",
}

@inproceedings{c:83,
  author  = "Clancey, William J.",
  year    = 1983,
  title   = "{Communication, Simulation, and Intelligent
Agents: Implications of Personal Intelligent Machines
for Medical Education}",
  booktitle="Proceedings of the Eighth International Joint Conference on Artificial Intelligence {(IJCAI-83)}", 
  pages   = "556-560",
  address = "Menlo Park, Calif",
  publisher = "{IJCAI Organization}",
}
@inproceedings{c:84,
  author  = "Clancey, William J.",
  year    = 1984,
  title   = "{Classification Problem Solving}",
  booktitle = "Proceedings of the Fourth National 
              Conference on Artificial Intelligence",
  pages   = "45-54",
  address = "Menlo Park, Calif.",
  publisher="AAAI Press",
}
@article{r:80,
  author = {Robinson, Arthur L.},
  title = {New Ways to Make Microcircuits Smaller},
  volume = {208},
  number = {4447},
  pages = {1019--1022},
  year = {1980},
  doi = {10.1126/science.208.4447.1019},
  publisher = {American Association for the Advancement of Science},
  issn = {0036-8075},
  URL = {https://science.sciencemag.org/content/208/4447/1019},
  eprint = {https://science.sciencemag.org/content/208/4447/1019.full.pdf},
  journal = {Science},
}
@article{r:80x,
  author  = "Robinson, Arthur L.",
  year    = 1980,
  title   = "{New Ways to Make Microcircuits Smaller---Duplicate Entry}",
  journal = "Science",
  volume  =  208,
  pages   = "1019-1026",
}
@article{hcr:83,
title = {Strategic explanations for a diagnostic consultation system},
journal = {International Journal of Man-Machine Studies},
volume = {20},
number = {1},
pages = {3-19},
year = {1984},
issn = {0020-7373},
doi = {https://doi.org/10.1016/S0020-7373(84)80003-6},
url = {https://www.sciencedirect.com/science/article/pii/S0020737384800036},
author = {Diane Warner Hasling and William J. Clancey and Glenn Rennels},
abstract = {This article examines the problem of automatte explanation of reasoning, especially as it relates to expert systems. By explanation we mean the ability of a program to discuss what it is doing in some understandable way. We first present a general framework in which to view explanation and review some of the research done in this area. We then focus on the explanation system for NEOMYCIN, a medical consultation program. A consultation program interactively helps a user to solve a problem. Our goal is to have NEOMYCIN explain its problem-solving strategies. An explanation of strategy describes the plan the program is using to reach a solution. Such an explanation is usually concrete, referring to aspects of the current problem situation. Abstract explanations articulate a general principle, which can be applied in different situations; such explanations are useful in teaching and in explaining by analogy. We describe the aspects of NEOMYCIN that make abstract strategic explanations possibleâ€”the representation of strategic knowledge explicitly and separately from domain knowledgeâ€” and demonstrate how this representation can be used to generate explanations.}
}

@inproceedings{bryant-etal-2019-bea,
    title = "The {BEA}-2019 Shared Task on Grammatical Error Correction",
    author = "Bryant, Christopher  and
      Felice, Mariano  and
      Andersen, {\O}istein E.  and
      Briscoe, Ted",
    editor = "Yannakoudakis, Helen  and
      Kochmar, Ekaterina  and
      Leacock, Claudia  and
      Madnani, Nitin  and
      Pil{\'a}n, Ildik{\'o}  and
      Zesch, Torsten",
    booktitle = "Proceedings of the Fourteenth Workshop on Innovative Use of NLP for Building Educational Applications",
    month = aug,
    year = "2019",
    address = "Florence, Italy",
    publisher = "Association for Computational Linguistics",
    url = "https://aclanthology.org/W19-4406/",
    doi = "10.18653/v1/W19-4406",
    pages = "52--75",
    abstract = "This paper reports on the BEA-2019 Shared Task on Grammatical Error Correction (GEC). As with the CoNLL-2014 shared task, participants are required to correct all types of errors in test data. One of the main contributions of the BEA-2019 shared task is the introduction of a new dataset, the Write{\&}Improve+LOCNESS corpus, which represents a wider range of native and learner English levels and abilities. Another contribution is the introduction of tracks, which control the amount of annotated data available to participants. Systems are evaluated in terms of ERRANT F{\_}0.5, which allows us to report a much wider range of performance statistics. The competition was hosted on Codalab and remains open for further submissions on the blind test set."
}

@inproceedings{ng-etal-2014-conll,
    title = "The {C}o{NLL}-2014 Shared Task on Grammatical Error Correction",
    author = "Ng, Hwee Tou  and
      Wu, Siew Mei  and
      Briscoe, Ted  and
      Hadiwinoto, Christian  and
      Susanto, Raymond Hendy  and
      Bryant, Christopher",
    editor = "Ng, Hwee Tou  and
      Wu, Siew Mei  and
      Briscoe, Ted  and
      Hadiwinoto, Christian  and
      Susanto, Raymond Hendy  and
      Bryant, Christopher",
    booktitle = "Proceedings of the Eighteenth Conference on Computational Natural Language Learning: Shared Task",
    month = jun,
    year = "2014",
    address = "Baltimore, Maryland",
    publisher = "Association for Computational Linguistics",
    url = "https://aclanthology.org/W14-1701/",
    doi = "10.3115/v1/W14-1701",
    pages = "1--14"
}

@inproceedings{do-etal-2024-autoregressive-multi,
    title = "Autoregressive Multi-trait Essay Scoring via Reinforcement Learning with Scoring-aware Multiple Rewards",
    author = "Do, Heejin  and
      Ryu, Sangwon  and
      Lee, Gary",
    editor = "Al-Onaizan, Yaser  and
      Bansal, Mohit  and
      Chen, Yun-Nung",
    booktitle = "Proceedings of the 2024 Conference on Empirical Methods in Natural Language Processing",
    month = nov,
    year = "2024",
    address = "Miami, Florida, USA",
    publisher = "Association for Computational Linguistics",
    url = "https://aclanthology.org/2024.emnlp-main.917/",
    doi = "10.18653/v1/2024.emnlp-main.917",
    pages = "16427--16438",
    abstract = "Recent advances in automated essay scoring (AES) have shifted towards evaluating multiple traits to provide enriched feedback. Like typical AES systems, multi-trait AES employs the quadratic weighted kappa (QWK) to measure agreement with human raters, aligning closely with the rating schema; however, its non-differentiable nature prevents its direct use in neural network training. In this paper, we propose Scoring-aware Multi-reward Reinforcement Learning (SaMRL), which integrates actual evaluation schemes into the training process by designing QWK-based rewards with a mean-squared error penalty for multi-trait AES. Existing reinforcement learning (RL) applications in AES are limited to classification models despite associated performance degradation, as RL requires probability distributions; instead, we adopt an autoregressive score generation framework to leverage token generation probabilities for robust multi-trait score predictions. Empirical analyses demonstrate that SaMRL facilitates model training, notably enhancing scoring of previously inferior prompts."
}

@inproceedings{kim-2014-convolutional,
    title = "Convolutional Neural Networks for Sentence Classification",
    author = "Kim, Yoon",
    editor = "Moschitti, Alessandro  and
      Pang, Bo  and
      Daelemans, Walter",
    booktitle = "Proceedings of the 2014 Conference on Empirical Methods in Natural Language Processing ({EMNLP})",
    month = oct,
    year = "2014",
    address = "Doha, Qatar",
    publisher = "Association for Computational Linguistics",
    url = "https://aclanthology.org/D14-1181",
    doi = "10.3115/v1/D14-1181",
    pages = "1746--1751",
}

@article{2020t5,
  author  = {Colin Raffel and Noam Shazeer and Adam Roberts and Katherine Lee and Sharan Narang and Michael Matena and Yanqi Zhou and Wei Li and Peter J. Liu},
  title   = {Exploring the Limits of Transfer Learning with a Unified Text-to-Text Transformer},
  journal = {Journal of Machine Learning Research},
  year    = {2020},
  volume  = {21},
  number  = {140},
  pages   = {1-67},
  url     = {http://jmlr.org/papers/v21/20-074.html}
}

@inproceedings{jiang-etal-2022-promptbert,
    title = "{P}rompt{BERT}: Improving {BERT} Sentence Embeddings with Prompts",
    author = "Jiang, Ting  and
      Jiao, Jian  and
      Huang, Shaohan  and
      Zhang, Zihan  and
      Wang, Deqing  and
      Zhuang, Fuzhen  and
      Wei, Furu  and
      Huang, Haizhen  and
      Deng, Denvy  and
      Zhang, Qi",
    editor = "Goldberg, Yoav  and
      Kozareva, Zornitsa  and
      Zhang, Yue",
    booktitle = "Proceedings of the 2022 Conference on Empirical Methods in Natural Language Processing",
    month = dec,
    year = "2022",
    address = "Abu Dhabi, United Arab Emirates",
    publisher = "Association for Computational Linguistics",
    url = "https://aclanthology.org/2022.emnlp-main.603",
    doi = "10.18653/v1/2022.emnlp-main.603",
    pages = "8826--8837",
    abstract = "We propose PromptBERT, a novel contrastive learning method for learning better sentence representation. We firstly analysis the drawback of current sentence embedding from original BERT and find that it is mainly due to the static token embedding bias and ineffective BERT layers. Then we propose the first prompt-based sentence embeddings method and discuss two prompt representing methods and three prompt searching methods to make BERT achieve better sentence embeddings .Moreover, we propose a novel unsupervised training objective by the technology of template denoising, which substantially shortens the performance gap between the supervised and unsupervised settings. Extensive experiments show the effectiveness of our method. Compared to SimCSE, PromptBert achieves 2.29 and 2.58 points of improvement based on BERT and RoBERTa in the unsupervised setting.",
}

@article{hcrt:83,
  author  = "Hasling, Diane Warner and Clancey, William J. and Rennels, Glenn R. and Test, Thomas",
  year    = 1983,
  title   = "{Strategic Explanations in Consultation---Duplicate}",
  journal = "The International Journal of Man-Machine Studies",
  volume  = 20,
  number  = 1,
  pages   = "3-19",
}
@techreport{r:86,
  author  = "Rice, James",
  year    = 1986,
  title   = "{Poligon: A System for Parallel Problem Solving}",
  type    = "Technical Report", 
  number  = "KSL-86-19", 
  institution = "Dept.\ of Computer Science, Stanford Univ.",
}
@phdthesis{c:79,
  author  = "Clancey, William J.",
  year    = 1979,
  title   = "{Transfer of Rule-Based Expertise
through a Tutorial Dialogue}",
  type    = "{Ph.D.} diss.",
  school  = "Dept.\ of Computer Science, Stanford Univ.",
  address = "Stanford, Calif.",
}
@unpublished{c:21,
  author  = "Clancey, William J.",
  title   = "{The Engineering of Qualitative Models}",
  year    = 2021,
  note    = "Forthcoming",
}
@misc{c:22,
      title={Crime and punishment in scientific research}, 
      author={Mathieu Bouville},
      year={2008},
      eprint={0803.4058},
      archivePrefix={arXiv},
      primaryClass={physics.soc-ph}
}
@misc{c:23,
  title        = "Pluto: The 'Other' Red Planet",
  author       = "{NASA}",
  howpublished = "\url{https://www.nasa.gov/nh/pluto-the-other-red-planet}",
  year         = 2015,
  note         = "Accessed: 2018-12-06"
}
% Use this file for citations not found in the ACL Anthology (contained in "anthology.bib").

@book{Aho:72,
    author  = {Alfred V. Aho and Jeffrey D. Ullman},
    title   = {The Theory of Parsing, Translation and Compiling},
    year    = "1972",
    volume  = "1",
    publisher = {Prentice-Hall},
    address = {Englewood Cliffs, NJ}
}

@book{APA:83,
    author  = {{American Psychological Association}},
    title   = {Publications Manual},
    year    = "1983",
    publisher = {American Psychological Association},
    address = {Washington, DC}
}

@article{Chandra:81,
	author = {Ashok K. Chandra and Dexter C. Kozen and Larry J. Stockmeyer},
	year = "1981",
	title = {Alternation},
	journal = {Journal of the Association for Computing Machinery},
	volume = "28",
	number = "1",
	pages = "114--133",
	doi = "10.1145/322234.322243",
}

@inproceedings{andrew2007scalable,
  title={Scalable training of {L1}-regularized log-linear models},
  author={Andrew, Galen and Gao, Jianfeng},
  booktitle={Proceedings of the 24th International Conference on Machine Learning},
  pages={33--40},
  year={2007},
}

@book{Gusfield:97,
    author  = {Dan Gusfield},
    title   = {Algorithms on Strings, Trees and Sequences},
    year    = "1997",
    publisher = {Cambridge University Press},
    address = {Cambridge, UK}
}

@article{rasooli-tetrault-2015,
    author    = {Mohammad Sadegh Rasooli and Joel R. Tetreault},
    title     = {Yara Parser: {A} Fast and Accurate Dependency Parser},
    journal   = {Computing Research Repository},
    volume    = {arXiv:1503.06733},
    year      = {2015},
    url       = {http://arxiv.org/abs/1503.06733},
    note    = {version 2}
}

@article{Ando2005,
	Acmid = {1194905},
	Author = {Ando, Rie Kubota and Zhang, Tong},
	Issn = {1532-4435},
	Issue_Date = {12/1/2005},
	Journal = {Journal of Machine Learning Research},
	Month = dec,
	Numpages = {37},
	Pages = {1817--1853},
	Publisher = {JMLR.org},
	Title = {A Framework for Learning Predictive Structures from Multiple Tasks and Unlabeled Data},
	Volume = {6},
	Year = {2005}
}

@article{attali2006automated,
  title={Automated essay scoring with e-rater{\textregistered} V. 2},
  author={Attali, Yigal and Burstein, Jill},
  journal={The Journal of Technology, Learning and Assessment},
  volume={4},
  number={3},
  year={2006}
}

@article{landauer2003automated,
  title={Automated scoring and annotation of essays with the Intelligent Essay Assessor},
  author={Landauer, Thomas K},
  journal={Automated essay scoring: A cross-disciplinary perspective},
  year={2003},
  publisher={Erlbaum}
}

@article{miltsakaki2004evaluation,
  title={Evaluation of text coherence for electronic essay scoring systems},
  author={Miltsakaki, Eleni and Kukich, Karen},
  journal={Natural Language Engineering},
  volume={10},
  number={1},
  pages={25--55},
  year={2004},
  publisher={Cambridge University Press}
}

@inproceedings{klebanov2016topicality,
  title={Topicality-based indices for essay scoring},
  author={Klebanov, Beata Beigman and Flor, Michael and Gyawali, Binod},
  booktitle={Proceedings of the 11th Workshop on Innovative Use of NLP for Building Educational Applications},
  pages={63--72},
  year={2016}
}

@inproceedings{larkey1998automatic,
  title={Automatic essay grading using text categorization techniques},
  author={Larkey, Leah S},
  booktitle={Proceedings of the 21st annual international ACM SIGIR conference on Research and development in information retrieval},
  pages={90--95},
  year={1998}
}

@article{rudner2002automated,
  title={Automated essay scoring using Bayes' theorem},
  author={Rudner, Lawrence M and Liang, Tahung},
  journal={The Journal of Technology, Learning and Assessment},
  volume={1},
  number={2},
  year={2002}
}

@inproceedings{taghipour2016neural,
  title={A neural approach to automated essay scoring},
  author={Taghipour, Kaveh and Ng, Hwee Tou},
  booktitle={Proceedings of the 2016 conference on empirical methods in natural language processing},
  pages={1882--1891},
  year={2016}
}

@inproceedings{dong2016automatic,
  title={Automatic Features for Essay Scoring-An Empirical Study.},
  author={Dong, Fei and Zhang, Yue},
  booktitle={EMNLP},
  volume={435},
  pages={1072--1077},
  year={2016}
}

@article{vaswani2017attention,
  title={Attention is all you need},
  author={Vaswani, Ashish and Shazeer, Noam and Parmar, Niki and Uszkoreit, Jakob and Jones, Llion and Gomez, Aidan N and Kaiser, {\L}ukasz and Polosukhin, Illia},
  journal={Advances in neural information processing systems},
  volume={30},
  year={2017}
}

@article{uto2021review,
  title={A review of deep-neural automated essay scoring models},
  author={Uto, Masaki},
  journal={Behaviormetrika},
  volume={48},
  number={2},
  pages={459--484},
  year={2021},
  publisher={Springer}
}

@inproceedings{tay2018skipflow,
  title={SkipFlow: Incorporating neural coherence features for end-to-end automatic text scoring},
  author={Tay, Yi and Phan, Minh and Tuan, Luu Anh and Hui, Siu Cheung},
  booktitle={Proceedings of the AAAI conference on artificial intelligence},
  volume={32},
  number={1},
  year={2018}
}

@incollection{li2018coherence,
  title={Coherence-based automated essay scoring using self-attention},
  author={Li, Xia and Chen, Minping and Nie, Jianyun and Liu, Zhenxing and Feng, Ziheng and Cai, Yingdan},
  booktitle={Chinese computational linguistics and natural language processing based on naturally annotated big data},
  pages={386--397},
  year={2018},
  publisher={Springer}
}

@inproceedings{persing2010modeling,
  title={Modeling organization in student essays},
  author={Persing, Isaac and Davis, Alan and Ng, Vincent},
  booktitle={Proceedings of the 2010 conference on empirical methods in natural language processing},
  pages={229--239},
  year={2010}
}

@inproceedings{wachsmuth2016using,
  title={Using argument mining to assess the argumentation quality of essays},
  author={Wachsmuth, Henning and Al Khatib, Khalid and Stein, Benno},
  booktitle={Proceedings of COLING 2016, the 26th international conference on Computational Linguistics: Technical papers},
  pages={1680--1691},
  year={2016}
}

@inproceedings{ke2018learning,
  title={Learning to Give Feedback: Modeling Attributes Affecting Argument Persuasiveness in Student Essays.},
  author={Ke, Zixuan and Carlile, Winston and Gurrapadi, Nishant and Ng, Vincent},
  booktitle={IJCAI},
  pages={4130--4136},
  year={2018}
}

@inproceedings{mathias2018asap++,
  title={ASAP++: Enriching the ASAP automated essay grading dataset with essay attribute scores},
  author={Mathias, Sandeep and Bhattacharyya, Pushpak},
  booktitle={Proceedings of the eleventh international conference on language resources and evaluation (LREC 2018)},
  year={2018}
}

@inproceedings{mathias2020can,
  title={Can Neural Networks Automatically Score Essay Traits?},
  author={Mathias, Sandeep and Bhattacharyya, Pushpak},
  booktitle={Proceedings of the Fifteenth Workshop on Innovative Use of NLP for Building Educational Applications},
  pages={85--91},
  year={2020}
}

@inproceedings{dong2017attention,
  title={Attention-based Recurrent Convolutional Neural Network for Automatic Essay Scoring.},
  author={Dong, Fei and Zhang, Yue and Yang, Jie},
  booktitle={CoNLL},
  pages={153--162},
  year={2017}
}

@article{hussein2020trait,
  title={A trait-based deep learning automated essay scoring system with adaptive feedback},
  author={Hussein, Mohamed A and Hassan, Hesham A and Nassef, Mohammad},
  journal={Int J Adv Comput Sci Appl},
  volume={11},
  number={5},
  pages={287--293},
  year={2020}
}

@article{attali2010performance,
  title={Performance of a generic approach in automated essay scoring},
  author={Attali, Yigal and Bridgeman, Brent and Trapani, Catherine},
  journal={The Journal of Technology, Learning and Assessment},
  volume={10},
  number={3},
  year={2010}
}

@inproceedings{phandi2015flexible,
  title={Flexible domain adaptation for automated essay scoring using correlated linear regression},
  author={Phandi, Peter and Chai, Kian Ming A and Ng, Hwee Tou},
  booktitle={Proceedings of the 2015 Conference on Empirical Methods in Natural Language Processing},
  pages={431--439},
  year={2015}
}

@inproceedings{cummins2016constrained,
  title={Constrained multi-task learning for automated essay scoring},
  author={Cummins, Ronan and Zhang, Meng and Briscoe, Edward},
  year={2016},
  organization={Association for Computational Linguistics}
}

@inproceedings{jin2018tdnn,
  title={TDNN: a two-stage deep neural network for prompt-independent automated essay scoring},
  author={Jin, Cancan and He, Ben and Hui, Kai and Sun, Le},
  booktitle={Proceedings of the 56th Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers)},
  pages={1088--1097},
  year={2018}
}

@article{li2020sednn,
  title={SEDNN: shared and enhanced deep neural network model for cross-prompt automated essay scoring},
  author={Li, Xia and Chen, Minping and Nie, Jian-Yun},
  journal={Knowledge-Based Systems},
  volume={210},
  pages={106491},
  year={2020},
  publisher={Elsevier}
}

@article{ridley2020prompt,
  title={Prompt Agnostic Essay Scorer: A Domain Generalization Approach to Cross-prompt Automated Essay Scoring},
  author={Ridley, Robert and He, Liang and Dai, Xinyu and Huang, Shujian and Chen, Jiajun},
  journal={arXiv preprint arXiv:2008.01441},
  year={2020}
}

@inproceedings{ridley2021automated,
  title={Automated Cross-prompt Scoring of Essay Traits},
  author={Ridley, Robert and He, Liang and Dai, Xin-yu and Huang, Shujian and Chen, Jiajun},
  booktitle={Proceedings of the AAAI conference on artificial intelligence},
  volume={35},
  pages={13745--13753},
  year={2021}
}

@article{hochreiter1997long,
  title={Long short-term memory},
  author={Hochreiter, Sepp and Schmidhuber, J{\"u}rgen},
  journal={Neural computation},
  volume={9},
  number={8},
  pages={1735--1780},
  year={1997},
  publisher={MIT Press}
}

@article{blei2003latent,
  title={Latent dirichlet allocation},
  author={Blei, David M and Ng, Andrew Y and Jordan, Michael I},
  journal={Journal of machine Learning research},
  volume={3},
  number={Jan},
  pages={993--1022},
  year={2003}
}

@inproceedings{hoblos2020experimenting,
  title={Experimenting with latent semantic analysis and latent dirichlet allocation on automated essay grading},
  author={Hoblos, Jalaa},
  booktitle={2020 Seventh International Conference on Social Networks Analysis, Management and Security (SNAMS)},
  pages={1--7},
  year={2020},
  organization={IEEE}
}

@inproceedings{kakkonen2006applying,
  title={Applying latent Dirichlet allocation to automatic essay grading},
  author={Kakkonen, Tuomo and Myller, Niko and Sutinen, Erkki},
  booktitle={International Conference on Natural Language Processing (in Finland)},
  pages={110--120},
  year={2006},
  organization={Springer}
}

@article{alikaniotis2016automatic,
  title={Automatic text scoring using neural networks},
  author={Alikaniotis, Dimitrios and Yannakoudakis, Helen and Rei, Marek},
  journal={arXiv preprint arXiv:1606.04289},
  year={2016}
}

@article{dauphin2015equilibrated,
  title={Equilibrated adaptive learning rates for non-convex optimization},
  author={Dauphin, Yann and De Vries, Harm and Bengio, Yoshua},
  journal={Advances in neural information processing systems},
  volume={28},
  year={2015}
}

@inproceedings{chen-li-2023-pmaes,
    title = "{PMAES}: Prompt-mapping Contrastive Learning for Cross-prompt Automated Essay Scoring",
    author = "Chen, Yuan  and
      Li, Xia",
    editor = "Rogers, Anna  and
      Boyd-Graber, Jordan  and
      Okazaki, Naoaki",
    booktitle = "Proceedings of the 61st Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers)",
    month = jul,
    year = "2023",
    address = "Toronto, Canada",
    publisher = "Association for Computational Linguistics",
    url = "https://aclanthology.org/2023.acl-long.83",
    doi = "10.18653/v1/2023.acl-long.83",
    pages = "1489--1503",
    abstract = "Current cross-prompt automated essay scoring (AES) is a challenging task due to the large discrepancies between different prompts, such as different genres and expressions. The main goal of current cross-prompt AES systems is to learn enough shared features between the source and target prompts to grade well on the target prompt. However, because the features are captured based on the original prompt representation, they may be limited by being extracted directly between essays. In fact, when the representations of two prompts are more similar, we can gain more shared features between them. Based on this motivation, in this paper, we propose a learning strategy called {``}prompt-mapping{''} to learn about more consistent representations of source and target prompts. In this way, we can obtain more shared features between the two prompts and use them to better represent the essays for the target prompt. Experimental results on the ASAP++ dataset demonstrate the effectiveness of our method. We also design experiments in different settings to show that our method can be applied in different scenarios. Our code is available at \url{https://github.com/gdufsnlp/PMAES}.",
}

@inproceedings{chen-li-2024-plaes,
    title = "{PLAES}: Prompt-generalized and Level-aware Learning Framework for Cross-prompt Automated Essay Scoring",
    author = "Chen, Yuan  and
      Li, Xia",
    editor = "Calzolari, Nicoletta  and
      Kan, Min-Yen  and
      Hoste, Veronique  and
      Lenci, Alessandro  and
      Sakti, Sakriani  and
      Xue, Nianwen",
    booktitle = "Proceedings of the 2024 Joint International Conference on Computational Linguistics, Language Resources and Evaluation (LREC-COLING 2024)",
    month = may,
    year = "2024",
    address = "Torino, Italia",
    publisher = "ELRA and ICCL",
    url = "https://aclanthology.org/2024.lrec-main.1118",
    pages = "12775--12786",
    abstract = "Current cross-prompt automatic essay scoring (AES) systems are primarily concerned with obtaining shared knowledge specific to the target prompt by using the source and target prompt essays. However, it may not be feasible in practical situations because the target prompt essays may not be available as training data. When constructing a model solely from source prompt essays, its capacity to generalize to the target prompt may be hindered by significant discrepancies among different prompt essays. In this study, a novel learning framework for cross-prompt AES is proposed in order to capture more general knowledge across prompts and improve the model{'}s capacity to distinguish between writing levels. To acquire generic knowledge across different prompts, a primary model is trained via meta learning with all source prompt essays. To improve the model{'}s ability to differentiate writing levels, we present a level-aware learning strategy consisting of a general scorer and three level scorers for low-, middle-, and high-level essays. Then, we introduce a contrastive learning strategy to bring the essay representation of the general scorer closer to its corresponding level representation and far away from the other two levels, thereby improving the system{'}s ability to differentiate writing levels as well as boosting scoring performance. Experimental results on public datasets illustrate the efficacy of our method.",
}

@inproceedings{li-ng-2024-conundrums,
    title = "Conundrums in Cross-Prompt Automated Essay Scoring: Making Sense of the State of the Art",
    author = "Li, Shengjie  and
      Ng, Vincent",
    editor = "Ku, Lun-Wei  and
      Martins, Andre  and
      Srikumar, Vivek",
    booktitle = "Proceedings of the 62nd Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers)",
    month = aug,
    year = "2024",
    address = "Bangkok, Thailand",
    publisher = "Association for Computational Linguistics",
    url = "https://aclanthology.org/2024.acl-long.414",
    doi = "10.18653/v1/2024.acl-long.414",
    pages = "7661--7681",
    abstract = "Cross-prompt automated essay scoring (AES), an under-investigated but challenging task that has gained increasing popularity in the AES community, aims to train an AES system that can generalize well to prompts that are unseen during model training. While recently-developed cross-prompt AES models have combined essay representations that are learned via sophisticated neural architectures with so-called prompt-independent features, an intriguing question is: are complex neural models needed to achieve state-of-the-art results? We answer this question by abandoning sophisticated neural architectures and developing a purely feature-based approach to cross-prompt AES that adopts a simple neural architecture. Experiments on the ASAP dataset demonstrate that our simple approach to cross-prompt AES can achieve state-of-the-art results.",
}


@inproceedings{do-etal-2024-autoregressive,
    title = "Autoregressive Score Generation for Multi-trait Essay Scoring",
    author = "Do, Heejin  and
      Kim, Yunsu  and
      Lee, Gary",
    editor = "Graham, Yvette  and
      Purver, Matthew",
    booktitle = "Findings of the Association for Computational Linguistics: EACL 2024",
    month = mar,
    year = "2024",
    address = "St. Julian{'}s, Malta",
    publisher = "Association for Computational Linguistics",
    url = "https://aclanthology.org/2024.findings-eacl.115",
    pages = "1659--1666",
    abstract = "Recently, encoder-only pre-trained models such as BERT have been successfully applied in automated essay scoring (AES) to predict a single overall score. However, studies have yet to explore these models in multi-trait AES, possibly due to the inefficiency of replicating BERT-based models for each trait. Breaking away from the existing sole use of *encoder*, we propose an autoregressive prediction of multi-trait scores (ArTS), incorporating a *decoding* process by leveraging the pre-trained T5. Unlike prior regression or classification methods, we redefine AES as a score-generation task, allowing a single model to predict multiple scores. During decoding, the subsequent trait prediction can benefit by conditioning on the preceding trait scores. Experimental results proved the efficacy of ArTS, showing over 5{\%} average improvements in both prompts and traits.",
}


@inproceedings{yang2020enhancing,
  title={Enhancing automated essay scoring performance via fine-tuning pre-trained language models with combination of regression and ranking},
  author={Yang, Ruosong and Cao, Jiannong and Wen, Zhiyuan and Wu, Youzheng and He, Xiaodong},
  booktitle={Findings of the Association for Computational Linguistics: EMNLP 2020},
  pages={1560--1569},
  year={2020}
}



@inproceedings{do2023prompt,
    title = "Prompt- and Trait Relation-aware Cross-prompt Essay Trait Scoring",
    author = "Do, Heejin  and
      Kim, Yunsu  and
      Lee, Gary Geunbae",
    editor = "Rogers, Anna  and
      Boyd-Graber, Jordan  and
      Okazaki, Naoaki",
    booktitle = "Findings of the Association for Computational Linguistics: ACL 2023",
    month = jul,
    year = "2023",
    address = "Toronto, Canada",
    publisher = "Association for Computational Linguistics",
    url = "https://aclanthology.org/2023.findings-acl.98",
    doi = "10.18653/v1/2023.findings-acl.98",
    pages = "1538--1551",
    abstract = "Automated essay scoring (AES) aims to score essays written for a given prompt, which defines the writing topic. Most existing AES systems assume to grade essays of the same prompt as used in training and assign only a holistic score. However, such settings conflict with real-education situations; pre-graded essays for a particular prompt are lacking, and detailed trait scores of sub-rubrics are required. Thus, predicting various trait scores of unseen-prompt essays (called cross-prompt essay trait scoring) is a remaining challenge of AES. In this paper, we propose a robust model: prompt- and trait relation-aware cross-prompt essay trait scorer. We encode prompt-aware essay representation by essay-prompt attention and utilizing the topic-coherence feature extracted by the topic-modeling mechanism without access to labeled data; therefore, our model considers the prompt adherence of an essay, even in a cross-prompt setting. To facilitate multi-trait scoring, we design trait-similarity loss that encapsulates the correlations of traits. Experiments prove the efficacy of our model, showing state-of-the-art results for all prompts and traits. Significant improvements in low-resource-prompt and inferior traits further indicate our model{'}s strength.",
}


@inproceedings{uto2020neural,
  title={Neural automated essay scoring incorporating handcrafted features},
  author={Uto, Masaki and Xie, Yikuan and Ueno, Maomi},
  booktitle={Proceedings of the 28th International Conference on Computational Linguistics},
  pages={6077--6088},
  year={2020}
}

@inproceedings{nguyen2018argument,
  title={Argument mining for improving the automated scoring of persuasive essays},
  author={Nguyen, Huy and Litman, Diane},
  booktitle={Proceedings of the AAAI Conference on Artificial Intelligence},
  volume={32},
  number={1},
  year={2018}
}

@inproceedings{dascalu2017readerbench,
  title={ReaderBench learns Dutch: building a comprehensive automated essay scoring system for Dutch language},
  author={Dascalu, Mihai and Westera, Wim and Ruseti, Stefan and Trausan-Matu, Stefan and Kurvers, Hub},
  booktitle={International Conference on Artificial Intelligence in Education},
  pages={52--63},
  year={2017},
  organization={Springer}
}

@article{marinho2022essay,
  title={Essay-br: a brazilian corpus to automatic essay scoring task},
  author={Marinho, Jeziel C and Anchi{\^e}ta, Rafael T and Moura, Raimundo S},
  journal={Journal of Information and Data Management},
  volume={13},
  number={1},
  year={2022}
}

@article{kumar2021many,
  title={Many Hands Make Light Work: Using Essay Traits to Automatically Score Essays},
  author={Kumar, Rahul and Mathias, Sandeep and Saha, Sriparna and Bhattacharyya, Pushpak},
  journal={arXiv preprint arXiv:2102.00781},
  year={2021}
}

@inproceedings{jin2017study,
  title={A study of distributed semantic representations for automated essay scoring},
  author={Jin, Cancan and He, Ben and Xu, Jungang},
  booktitle={Knowledge Science, Engineering and Management: 10th International Conference, KSEM 2017, Melbourne, VIC, Australia, August 19-20, 2017, Proceedings 10},
  pages={16--28},
  year={2017},
  organization={Springer}
}

@inproceedings{he2022automated,
  title={Automated Chinese Essay Scoring from Multiple Traits},
  author={He, Yaqiong and Jiang, Feng and Chu, Xiaomin and Li, Peifeng},
  booktitle={Proceedings of the 29th International Conference on Computational Linguistics},
  pages={3007--3016},
  year={2022}
}

@inproceedings{amorim2018automated,
  title={Automated essay scoring in the presence of biased ratings},
  author={Amorim, Evelin and Can{\c{c}}ado, Marcia and Veloso, Adriano},
  booktitle={Proceedings of the 2018 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies, Volume 1 (Long Papers)},
  pages={229--237},
  year={2018}
}

@article{shin2022evaluating,
  title={Evaluating Coherence in Writing: Comparing the Capacity of Automated Essay Scoring Technologies},
  author={Shin, Jinnie and Gierl, Mark J},
  journal={Journal of Applied Testing Technology},
  year={2022}
}

@article{zhang2019co,
  title={Co-attention based neural network for source-dependent essay scoring},
  author={Zhang, Haoran and Litman, Diane},
  journal={arXiv preprint arXiv:1908.01993},
  year={2019}
}

@article{hussein2019automated,
  title={Automated language essay scoring systems: A literature review},
  author={Hussein, Mohamed Abdellatif and Hassan, Hesham and Nassef, Mohammad},
  journal={PeerJ Computer Science},
  volume={5},
  pages={e208},
  year={2019},
  publisher={PeerJ Inc.}
}

@inproceedings{ke2019automated,
  title={Automated Essay Scoring: A Survey of the State of the Art.},
  author={Ke, Zixuan and Ng, Vincent},
  booktitle={IJCAI},
  volume={19},
  pages={6300--6308},
  year={2019}
}

@article{wang2022use,
  title={On the Use of BERT for Automated Essay Scoring: Joint Learning of Multi-Scale Essay Representation},
  author={Wang, Yongjie and Wang, Chuan and Li, Ruobing and Lin, Hui},
  journal={arXiv preprint arXiv:2205.03835},
  year={2022}
}

@inproceedings{pennington2014glove,
  title={Glove: Global vectors for word representation},
  author={Pennington, Jeffrey and Socher, Richard and Manning, Christopher D},
  booktitle={Proceedings of the 2014 conference on empirical methods in natural language processing (EMNLP)},
  pages={1532--1543},
  year={2014}
}
