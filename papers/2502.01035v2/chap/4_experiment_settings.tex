\textbf{Dataset.} We use the Boson-nighttime real-world thermal dataset~\cite{stl, STHN}, which includes paired satellite-thermal images and unpaired satellite images. The 8-bit thermal images were captured with a Boson Thermal Camera during nighttime flights (9:00 PM to 4:00 AM), covering landscapes such as deserts, farms, and roads over $33~\si{km^2}$ for thermal and $216~\si{km^2}$ for satellite images. The dataset uses Bing Satellite Maps, with thermal images ($W_T=512$) aligned to satellite images ($W_S=1536$). It contains $10$K training, $13$K validation, and $27$K test pairs, with test data from different regions and times. Additionally, there are $160$K unpaired satellite images for optional thermal synthesis, excluding validation and test regions to evaluate generalization.



\textbf{Baselines.} We use the following DHE baselines: DHN \cite{detone2016deep}, IHN \cite{cao2022iterative}, and STHN~\cite{STHN}. DHN introduces DHE with four-corner displacement, while IHN adds an iterative approach with a correlation module. STHN uses TGM~\cite{stl} to synthesize thermal images and a two-stage method for DHE in TG. We apply UE only for the first stage. The Direct Modeling (DM) method~\cite{feng2021review} is our data uncertainty baseline.

\textbf{Metrics.} We employ the \textit{Mean Average Corner Error (MACE)} to evaluate homography estimation accuracy and the \textit{Center Error (CE)} to assess geo-localization accuracy. MACE~\cite{detone2016deep, cao2022iterative} is calculated as the average Euclidean distance between predicted and ground truth corners. CE~\cite{STHN} measures the Euclidean distance between predicted and ground truth centers. The \textit{Distance of Centers ($D_C$)} indicates the maximum center distance between thermal and satellite images, with smaller $D_C$ indicating high-frequency localization and larger $D_C$ indicating low-frequency localization. For UE, we use the \textit{Success Rate (SR)}, quantifying the proportion of non-rejected samples.



\textbf{Implementation Details.}\label{imp}
We set the iteration numbers for the homography networks to $K_1=6$ for the first stage and $K_2=6$ for the second stage, with a resizing width $W_R$ of $256$ and a decay factor $\gamma$ of $0.85$. We first train $F_H$ for $100$k steps without CropTTA, then fine-tune it for an additional $200$K steps with CropTTA. For two-stage methods, we apply bounding box augmentation~\cite{STHN}, perturbing the first-stage results by 64 pixels. During the evaluation, the bounding box width $W_B$ is expanded by 64 pixels. All uncertainty estimation methods are evaluated with 5 samples. $F_H$ is trained using the AdamW optimizer~\cite{loshchilov2017decoupled}, with a linear decay scheduler and a maximum learning rate of $1\times10^{-4}$.
\vspace{-5pt}

\begin{table*}[]
    \centering
        \caption{Comparison of test MACE (m), CE (m), and Success Rates (SR) across different UE methods with DHE baselines at $W_S=1536$. All baselines were trained with real and synthesized thermal data. $^\dagger$~denotes methods with a narrow standard deviation range, consistently yielding $100\%$ success rates.}
        \resizebox{\linewidth}{!}{
    \begin{tabular}{lcccccccccccccc}
    \toprule
       \multirow{2}{4em}{DHE Methods} &\multirow{2}{3em}{UE Methods}&\multirow{2}{5em}{Uncertainty} & &\multicolumn{3}{c}{$D_C=128~\si{m}$}& & \multicolumn{3}{c}{$D_C=256~\si{m}$} & & \multicolumn{3}{c}{$D_C=512~\si{m}$}\\
        \cline{5-7}\cline{9-11}\cline{13-15}\vspace{-9pt}\\
        & & & & MACE& CE &SR & & MACE & CE & SR & & MACE & CE &SR\\
         \midrule
         \multirow{5}{3em}{DHN~\cite{detone2016deep}} & -& - & &73.60 &73.58 & 100\% & & 171.93& 171.02 & 100\% & &342.41 & 341.11 & 100\%\\
         & DE & model & &\textbf{61.91} & \textbf{61.90} & 97.3\% & &162.77 &162.75 & 96.4\% & & 346.26 & 346.21 & 93.6\% \\
         & DM & data  & &66.77 &66.76 &99.3\% &  &164.19 &164.17  & 99.7\% & &\textbf{335.81} & \textbf{335.77} & 91.7\% \\
         & CropTTA & data & &64.18 &62.78 & 98.6\% & &\underline{162.04} &\underline{161.82} & 95.1\% & & 337.90 & 337.84 & 91.5\%\\
         & CropTTA + DE & data + model & &\underline{64.09} &\underline{62.70} &96.6\% & &\textbf{161.84}  &  \textbf{161.62}& 96.1\% & & \underline{336.41} &\underline{336.47} & 93.6\%\\
         \midrule
         % \multirow{5}{3em}{IHN~\cite{cao2022iterative}} & -& - & & 12.61 &12.44 & 100\% & &18.02&17.75 & 100\% & &47.27 & 46.85 & 100\% \\
         % & DE  & model & & 6.91 &6.85 & 91.9\% & &11.00  &10.87  & 92.8\% & & &  & \%\\
         % & DM  & data & &10.71 &10.68 &100\%$^\dagger$ & & & & \% & &  &  & \%\\
         % & CropTTA  & data & & & & 100\% & & & & 100\%& &  & & \%\\
         % & CropTTA + DE & data + model & & & & 100\% & & & & 100\% & &  &  & \\
         %  \midrule
         \multirow{5}{3em}{IHN~\cite{cao2022iterative}} & -& -& &7.27 & 7.24& 100\% & & 16.78 & 16.42 & 100\% & & 16.42& 15.90 & 100\%\\
          & DE & model & &\textbf{6.07} &\textbf{6.06}  & 97.9\% & & 12.31 &12.13 & 97.6\% & &13.73  & 13.37 & 94.5\%\\
          & DM & data  & &\underline{7.02} &\underline{6.99} &100\%$^\dagger$ & &\underline{11.81} &11.40 & 100\%$^\dagger$ & &11.48 & 11.14& 94.1\% \\
         & CropTTA & data & &7.46 &7.47 & 97.4\% & &11.91 &\underline{10.80} & 97.5\%& &\textbf{9.27} & \textbf{8.06}& 95.0\% \\
         & CropTTA + DE & data + model & &7.25 &7.26 & 95.7\% & &\textbf{11.57} &\textbf{10.44} & 97.1\% & &\underline{10.67} & \underline{9.41} & 93.8\%\\
          \midrule
         \multirow{5}{3em}{STHN~\cite{STHN}} & -& - & &\textbf{7.51} &\textbf{6.66} & 100\% & &14.99&14.34 &100\% & &12.70& 12.12 &100\% \\
          & DE & model & &9.45 &8.72 &98.1\% & &9.98 &9.09 & 95.3\%& &8.29 &7.58  & 97.3\%\\
          & DM & data  & &9.75 &8.68 & 100\%$^\dagger$ & &13.64 & 12.91& 100\%$^\dagger$ & &11.35 &10.64  & 100\%$^\dagger$ \\
         & CropTTA & data & &8.26 &7.75 & 98.5\%& &\underline{7.85} &\underline{7.31} & 95.8\% & &\underline{7.93} &\underline{7.25} & 97.5\%\\
         & CropTTA + DE & data + model & &\underline{8.16} &\underline{7.65} &98.1\% & &\textbf{7.50} &\textbf{6.97} & 94.5\% & &\textbf{7.83} & \textbf{7.15} & 97.0\%\\

    \bottomrule
    \end{tabular}}
    \label{baseline}
    \vspace{-10pt}
\end{table*}

\begin{table}
    \centering
    \caption{Comparison of inference time (\si{ms}) for different UE methods with or without early stopping. We evaluate with 5 samples and in an NVIDIA RTX 2080Ti GPU.}
        \resizebox{0.48\textwidth}{!}{
    \begin{tabular}{lccccc}
    \toprule
       Methods & Early Stopping & w/o UE & CropTTA & DE & CropTTA + DE\\
         \midrule
         \multirow{2}{4em}{IHN~\cite{cao2022iterative}} & \xmark & 35.2 & 64.6 & 114.6 & 164.2  \\
         & \checkmark & - & 54.6 &63.1 & 92.1\\\midrule
         \multirow{2}{4em}{STHN~\cite{STHN}} &\xmark & 63.9  &87.0 & 130.2  & 186.0\\
         & \checkmark &  - &78.2 & 81.9 & 118.6\\
    \bottomrule
    \end{tabular}}
    \label{time}
    \vspace{-15pt}
\end{table}

