% \section{Introduction}
% Text-to-Image (T2I) models have recently shown remarkable ability to produce high-quality images that can be highly alinged with textual prompts given by users~\cite{stable_diffusion}. For example, this enables users to give a lot of freedom to generate sophisticated images following their prompts without professional training. However, since T2I models are trained using vast amount of text-image paired datasets crawled from the internet, these models easily replicate copyrighted, explicit, and private concepted images~\cite{Somepalli2022DiffusionAO,Somepalli2023UnderstandingAM}. Users' freedom with such concepts enables malicious actors to generate content for misinformation or public opinion manipulations.

% In response to the challenges posed by malicious users, recent works develop post-hoc methods to embed safety protocols (e.g., watermark) into the T2I models' pipeline~\cite{WOUAF,stable_signature,kim2020decentralized,nie2023attributing,tree-ring}. These methods have great values to identify the responsible source of the generated images. However, their reactive characteristics are only able to be appliable after malicious images already badly affect society or person who are targeted.  

% With the reactive methods for mitigating misused of T2I models, proactive methods are also getting increasing attention. These methods are erasing protected concepts from the T2I models, we call concept erasing. Compared to the reactive methods, these methods supress T2I models not to generate such protected concepts from T2I models. To achieve this, these methods modifies components or inference of T2I models. In this context, T2I models, even they get the request to generate protected concepts, supresses to generate such concepted images.

% %compare with previous surveys
% With great attention of security perspective of T2I models, there are comprehensive surveys are available. \cite{Liu2024MachineUI} is broad survey about machine unlearning of generative models which includes language generative models. \cite{Zhang2024AdversarialAA} and \cite{Truong2024AttacksAD} are discussing adversarial attack and defense for T2I diffusion models and diffusion based image generative models. However, the lack of comprehensive survey focusing on T2I concept erasuers makes it hard to know the whole landscape of this field. To resolve this, we aim to present more detailed categorization of concept erasing methods by categorizing them based on their optimization methods and component they are selected to erase. With that, we also covers adversarial attacks and defenses targeting concept erasing methods. 

% We expect that our survey can make significant contributions to both the research and development of concept erasing in T2I. Readers will gain a comprehensive overview of concept erasing methods, grasp the fundamental concepts involved in establishing them, and catch the latest research trends and applications in this field. We recognize that this field is in its early stages and is rapidly evolving with fresh methodologies and applications. To provide a sustainable resource complementing our survey paper, we maintain an open-source GitHub repository. We hope that our survey will inspire further exploration and innovation in this field, as well as applications across a wide array of research disciplines.

% To assist individuals from various backgrounds in understanding T2I concept erasing techniques and to complement existing surveys, we have organized
% our survey paper in the following manner. After laying out
% the background knowledge in Sec.~\ref{sec:preliminaries}, we address a pivotal question: How are erasing methods are achieved? and Which component of T2I model is modified? To answer this, we categorize each methods based on their optimization methods and component they are selected to erase in Sec.~\ref{sec:method}. Following that, we also introduce threats of adversarial attacks which are desinged to attack erasing methods and counter methods in Sec.~\ref{sec:robustness}. In Sec.~\ref{sec:evaluation}, we introduce widely employed metrics and datasets to measure the effectiveness of erasing methods. Based on the previous sections, we discuss the future research challenges and opportunities in Sec.~\ref{sec:future_research}. After that, we summarize and conclude this survey in Sec.~\ref{sec:conclusion}.



%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%


\begin{figure}[t]
    \centering
    \includegraphics[width=\linewidth]{figs/outlines_v4.pdf}
    \caption{ Concept Erasure for Text-to-Image Diffusion Model Pipeline. The model synthesizes images from textual prompts. In Figure (a), the model faithfully follows the input prompt, generating an image that aligns with the specified concept. In contrast, Figure (b) illustrates the effect of concept erasure, where the model suppresses the erased concept, ``Van Gogh’’, ensuring its exclusion from the generated output. For a detailed explanation, refer to Sec.~\ref{sec:preliminaries}.
    % Text-to-Image Diffusion Model Pipeline. The model generates images from textual prompts. Without concept erase the model directly follows text prompt as shown in the figure (a). However, after erasing concept ,``Van Gogh'', the model generates image that does not include concept. For a detailed explanation, refer to Sec.~\ref{sec:preliminaries}.For a detailed explanation, refer to Sec.~\ref{sec:preliminaries}.
    % Figures (a) and (b) depict the model’s output before and after the erasure of the concept “Van Gogh.” For a detailed explanation, refer to Sec.~\ref{sec:preliminaries}.
    }
    \label{fig:overview}
\end{figure}





\section{Introduction}

Recent advancements in Text-to-Image (T2I) models significantly enhance their ability to generate high-quality images that align closely with user-provided textual prompts~\cite{stable_diffusion}. These models empower users with unprecedented creative freedom, enabling the production of sophisticated and photorealistic images without requiring professional expertise. However, as T2I models are trained on vast text-image datasets scraped from the internet, they inherit both the strengths and biases of their training data. Specifically, they can replicate copyrighted artistic styles, explicit content, and private or sensitive visual concepts~\cite{Somepalli2023UnderstandingAM,Somepalli2022DiffusionAO},
%,Somepalli2023UnderstandingAM
raising ethical and legal concerns. The unconstrained generative capabilities of these models can be exploited for malicious purposes, such as creating misleading or harmful content, generating deepfake imagery, or manipulating public opinion.

To address these concerns, researchers have developed post-hoc safety mechanisms that integrate security protocols into the T2I model pipeline~\cite{WOUAF,stable_signature,kim2020decentralized,nie2023attributing,tree_ring}. These methods include watermarking, model attribution, and forensic tracking techniques that help identify the sources responsible for AI-generated content. While these approaches provide valuable forensic tools for mitigating misuse, they remain \textit{reactive solutions} that only take effect after potentially harmful images have been generated and disseminated. 

% Given the constraints of reactive methods, an emerging line of research explores \textit{proactive solutions}, specifically concept erasure, which aims to systematically remove targeted concepts from a model’s generative capability. As illustrated in Fig.~\ref{fig:overview}, concept erasure techniques aim to suppress a model’s ability to generate protected or undesired content, ensuring that even when explicitly prompted, the model does not produce outputs containing erased concepts. These methods operate by either modifying the model’s internal components or intervening in the inference process, preventing the unauthorized reproduction of sensitive or restricted concepts.

Given the constraints of reactive methods, an emerging line of research explores \textit{proactive solutions}, specifically concept erasure, which aims to systematically remove targeted concepts from a model’s generative capability. As illustrated in Fig.~\ref{fig:overview}, concept erasure techniques suppress a model’s ability to generate protected or undesired content, ensuring that even when explicitly prompted, the model does not produce outputs containing erased concepts. These methods operate by either modifying the model’s internal components or intervening in the inference process, preventing the unauthorized reproduction of sensitive or restricted concepts. 
% Other related approaches include machine unlearning and image editing. Machine unlearning focuses on removing specific data points to comply with privacy regulations, whereas concept erasure eliminates entire content categories, such as explicit or copyrighted styles, ensuring they cannot be regenerated~\cite{gandikota2024erasingconceptualknowledgelanguage}. Similarly, image editing modifies attributes within a given image while preserving the model’s overall generative capabilities, whereas concept erasure enforces persistent modifications that prevent the generation of targeted concepts across all inputs~\cite{Arad2023ReFACTUT}.
Other related approaches include image editing, which modifies attributes within a given image. In contrast, concept erasure enforces persistent modifications that prevent the generation of targeted concepts across all inputs~\cite{Arad2023ReFACTUT}.



Research on securing T2I models has gained significant attention, leading to comprehensive surveys on various aspects of generative model security. 
% \cite{Liu2024MachineUI} provides an extensive review of machine unlearning across generative models, including language-based systems. 
Recent studies from \cite{Zhang2024AdversarialAA} and \cite{Truong2024AttacksAD} focus on surveying adversarial attacks and defenses, with the former specifically addressing T2I diffusion models and the latter examining threats in diffusion-based image generation. While these works offer valuable insights, they do not provide a focused analysis of concept erasure in T2I models. The absence of a dedicated survey makes it difficult to systematically understand and compare existing concept erasure techniques. 

To bridge this gap, we present a structured and comprehensive survey on concept erasure techniques in T2I diffusion models, offering the following key contributions:
\begin{itemize}
    \item \textbf{Comprehensive Taxonomy of Concept Erasure Methods.} We systematically classify existing concept erasure techniques based on their optimization strategies and the model components they modify, as illustrated in Fig.~\ref{fig:taxonomy}. This categorization provides a structured taxonomy for understanding different concept erasure approaches.
    
    \item \textbf{Analysis of Adversarial Attacks and Defense Mechanisms.} We investigate adversarial attacks designed to circumvent concept erasure, categorizing them based on access to the T2I model’s internal components. Additionally, we explore emerging defense strategies aimed at enhancing the robustness of concept erasure techniques.
    
    \item \textbf{Evaluation Benchmark for Concept Erasure.} We consolidate widely used datasets and metrics for assessing erasure effectiveness, model fidelity, and resilience against adversarial attacks, providing a standardized benchmark for future research and evaluation.
    
    % \item \textbf{Future Research Directions and Open Challenges.} We introduce research opportunities in concept erasure, including improving generalization across different modalities such as text-to-video, balancing model fidelity with effective erasure, and addressing novel adversarial threats.
    \item \textbf{Future Research Directions and Open Challenges.} We introduce research opportunities in concept erasure, including improving generalization across different modalities such as text-to-video, developing fine-grained benchmarks to evaluate erasure effectiveness while capturing unintended distortions in related attributes, and addressing novel adversarial threats.
    
\end{itemize}

To provide a comprehensive understanding of concept erasure in T2I models, we structure this paper as follows. Sec.~\ref{sec:preliminaries} provides background knowledge on the architecture of T2I models and introduces key technical concepts relevant to concept erasure. Sec.~\ref{sec:method} categorizes concept erasure techniques based on their optimization methods and the model components they modify. Sec.~\ref{sec:robustness} examines adversarial attacks that attempt to circumvent concept erasure, along with emerging defense strategies designed to enhance robustness. Sec.~\ref{sec:evaluation} reviews commonly used evaluation metrics and datasets for benchmarking concept erasure methods. Based on these findings, Sec.~\ref{sec:future_research} discusses future research directions, open challenges, and opportunities in this field, followed by conclusions in Sec.~\ref{sec:conclusion}.

