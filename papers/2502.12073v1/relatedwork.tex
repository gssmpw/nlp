\section{Related Work}
AI-driven social media content generation has been explored across various domains. \citet{lim2023artificial} studied prompt engineering for health awareness messages, showing AI-generated content can match or exceed human quality, but their work focused on general messages rather than personalized engagement. \citet{yu2024repalm} introduced RePALM, a model optimizing quote tweets for likes, yet it did not account for diverse engagement types like retweets and rewrites or user-specific behaviors. \citet{rossetti2024social} introduced Y SOCIAL, a digital twin of a physical social media platform, but it lacks a direct comparison with real-world social media interactions. \citet{dmonte2024classifying} proposed HiSim, a hybrid scalable framework for social media simulation, but it lacks a detailed step-by-step accuracy analysis of LLM-driven user simulation. 

While these studies primarily focus on the feasibility and scalability of LLM-driven social media simulations, our work takes a different approach by focusing on examining the performance of LLMs in capturing user engagement dynamics.
Rather than optimizing for engagement metrics or developing large-scale simulation frameworks, we aim to understand how well LLMs align with human behavior in social media interactions, investigating both their successes and limitations in action-guided response generation.