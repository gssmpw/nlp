\section{Experiments}
\subsection{Experiment Setup} 
\paragraph{Models.}

\input{latex/tables/ours}
% \input{latex/tables/global}
Our experiments evaluate the EFCG task using one mainstream instruction-tuned base model: Llama-3.2-3B-Instruct ~\cite{dubey2024llama}, chosen for its demonstrated proficiency in instruction-following tasks within the 3B parameter range. To systematically assess the impact of our methodology, we compare three training paradigms: (1) \textbf{BASE}, which directly employs the unmodified base models to establish a performance baseline; (2) \textbf{AR}, where models undergo the auto-reconstruction stage on our meticulously constructed FineWeb dataset (§3.2), enriched with fine-grained attributes to enhance multi-constraint adherence; and (3) \textbf{AR+GPO}, a hybrid optimization approach combining direct preference optimization with global embedding space adaption.

\subsection{Evaluation Results on UltraBench}

Our experimental findings, summarized in Table \ref{tab:ultrabench}, demonstrate the substantial advancements achieved by applying the UltraGen paradigm to EFCG. The evaluation leverages the validation set of FineWeb and Global splits to assess model performance under both local and global constraints.

The application of AR yielded significant improvements over the base model. On the FineWeb split, the AR model attained an overall score of 56.05, representing a relative improvement of 11.4\%. The soft score rose to 81.44, indicating enhanced adherence to semantic and stylistic attributes, while the hard score increased to 30.65, reflecting better performance on programmatically verifiable constraints. On the Global split, the AR model demonstrated its ability to generalize, achieving an overall score of 50.15.

Further optimization through GPO demonstrated remarkable performance on the Global split, where the model achieved an overall score of 57.23 and an impressive hard score of 45.44. This highlights the model's robust generalization and optimization capabilities when dealing with diverse and challenging global constraints. Notably, despite being trained on the Global split, the AR+GPO model exhibited strong performance on the FineWeb split as well, achieving an overall score of 59.61, a soft score of 84.33, and a hard score of 34.89. This result underscores the model's ability to transfer its learned capabilities from the broader and more diverse Global split to the more localized FineWeb split.

\paragraph{Ablation}
To evaluate the contribution of key components in our UltraGen framework, we conducted ablation studies by systematically modifying the training process. We tested the impact of reducing the number of attributes during AR, removing the AR stage, replacing curated attributes with random sampling, and eliminating the high-correlation or low-redundancy selection steps. The results demonstrate that both AR and GPO stages are crucial for achieving strong performance, as reducing constraints, removing correlation modeling, or neglecting redundancy minimization leads to performance degradation.
% \paragraph{Ablation}
% To evaluate the contribution of key components in our UltraGen framework, we conducted several ablation studies by systematically modifying the training process. The following ablations were performed:
% \begin{enumerate}
%     \item \textbf{SFT with limited attributes}: To examine the impact of attribute numbers during the supervised fine-tuning stage, we trained an SFT model using a reduced set of attributes (fewer than 10 per sample).
%     \item \textbf{DPO only}: We directly train the DPO on the global split without SFT stage.
%     \item \textbf{SFT + DPO random sampling}: In this ablation, we replaced the curated high correlation and low redundancy attribute combinations with random sampling during the RL stage. 
%     \item \textbf{SFT + DPO w/o high correlation}: This experiment removed the attribute correlation modeling step, where attributes with strong relationships were prioritized.
%     \item \textbf{SFT + DPO w/o low redundancy}: In this setup, we did not enforce diversity in attribute sets by minimizing semantic redundancy.
% \end{enumerate}
% The ablation study shows that SFT with fewer constraints significantly underperforms the standard SFT. And DPO variants with fewer constraints, random sampling, or reduced correlation emphasize the importance of optimized attribute selection in the global space.
\subsection{Data Synthesis Improvement}

\input{latex/tables/data_synthesize}
To demonstrate the improvement in the usage of texts synthesized by UltraGen, we utilize several diverse well-established text classification benchmarks to test the data synthesis capability, such as sentiment analysis \textbf{(1) Emotion} ~\cite{saravia-etal-2018-carer}, attitude classification towards a particular public figure \textbf{(2) Hillary} ~\cite{barbieri2020tweeteval}, topic classification \textbf{(3) AG News} ~\cite{Zhang2015CharacterlevelCN}, question type classification \textbf{(4) TREC} ~\cite{li-roth-2002-learning}.

For each dataset, we analyze the unique properties and paraphrase these properties as hard and soft attributes. Then using a uniform prompt tailored for each dataset, we generate 2,000 synthetic samples per dataset. These generated samples are then used to train a classifier, which is subsequently evaluated on the original test set of the dataset. This procedure allows for a fair comparison of model performance on synthetic data. 

The results, summarized in Table \ref{tab:data_synthesis}, demonstrate the superior generalization ability of the AR+GPO model trained on the Global split. Notably, the AR+GPO model achieved the highest average score of 57.91 across the benchmarks, significantly outperforming both the base model and the AR models. While the AR model’s performance stagnated (45.76, lower than the original one) on the Hillary benchmark, reflecting a focus on localized attributes, the AR+GPO model excelled with a score of 58.31, indicating its generalization and adaptability beyond localized training objectives.

\subsection{Trade-Offs in EFCG}
\begin{figure}[t]
    \centering
        \includegraphics[width=0.49\textwidth]{figs/tradeoff.pdf}
    \caption{The Trade-off between F1 score and CSR. While BERTScore tends to improve with more attributes, CSR declines}
    \vspace{-1.5em}
    \label{fig:tradeoff}
\end{figure}

Figure~\ref{fig:tradeoff} illustrates the interplay between BERTScore and CSR across different numbers of attributes from 10 to 50 for each model. As the figure shows, increasing the number of attributes presents a clear double-edged effect: while more attributes can enhance fine-grained control (e.g., higher F1 score) over the generated text, the added complexity makes it more difficult for the model to maintain high constraint adherence.

\paragraph{Better Multi-Objective Alignment Under EFCG.}
\begin{figure*}[htbp]
    \centering
        \includegraphics[width=0.98\textwidth]{figs/case_study.pdf}
    \caption{In a case study on travel itinerary generation, the attention flow illustrates improved constraint awareness in AR+GPO.}
    \vspace{-1em}
    \label{fig:case_study}
\end{figure*}

When looking at the 30, 40, and 50 attribute conditions:
AR+GPO consistently attains CSR values 5--10 points higher than the other two models without sacrificing F1.
For example, at 50 attributes, AR+GPO’s CSR (44.76\%) is considerably above AR’s (35.86\%) and Original’s (37.40\%), while also delivering the highest F1 (0.6348 vs. 0.6310 for AR and 0.6076 for Original).



This pattern illustrates a more favorable trade-off for AR+GPO: it does not simply chase high BERTScore by ignoring constraints, nor does it force all constraints at the expense of overall text quality. Instead, AR+GPO’s global optimization helps coordinate multiple constraints while retaining strong semantic alignment. In contrast, AR appears effective at moderate attribute counts but loses ground on CSR once the load goes beyond 30 attributes, and the Original model experiences an even steeper decline.

% \paragraph{Implications.} In extreme fine-grained control (EFCG) tasks, these findings confirm that:
% \begin{enumerate}
%     \item Light to Moderate Constraints (e.g., up to 20 attributes) can be addressed by simpler fine-tuning without major F1 loss.
%     \item High Constraint Settings (30+ attributes), especially when semantic overlap among attributes is low or conflicts are frequent, demand methods like DPO or other preference-optimization approaches to prevent a precipitous drop in CSR.
% \end{enumerate}
% Table~\ref{tab:data_synthesis} presents the performance comparison between the original baselines and the SFT model across three traditional text classification benchmarks: Emotion, AG-News, and TREC. The results highlight significant improvements achieved by the SFT model, particularly for Emotion and TREC datasets. On the Emotion dataset, the SFT model achieves a 42.3\% accuracy, representing a substantial improvement of 14.0 percentage points over the baseline. Similarly, on the TREC dataset, which focuses on question type classification, the SFT model attains a 55.0\% accuracy, outperforming the baseline by 17.0 percentage points.



% \subsection{Toxicity Control}
% \label{sec:toxic}
% In this section, we use a toxic classifier~\cite{Detoxify} to identify 171 harmful examples from FineWeb. Using the same attribute extraction methods as described in Section 3, we then generate texts based on these attributes.

% The results in Figure \ref{fig:toxicity} clearly demonstrate that the SFT model struggles to handle toxicity control effectively, particularly as the number of attributes increases. While the Original Model maintains a consistently low toxicity rate across all levels of attribute complexity, the SFT model shows a significant and steady rise in toxicity rate, reaching over 25\% when handling 60 attributes. 

% This trend suggests that the SFT model fails to generalize well under highly constrained conditions and becomes increasingly susceptible to generating toxic content as it attempts to satisfy a growing number of attributes. The inability to properly balance attribute satisfaction with toxicity control highlights a critical limitation of the SFT approach, emphasizing the need for more robust mechanisms to enforce safety constraints, especially in scenarios involving complex or numerous attributes.

% \begin{figure}[t] 
%     \centering
%         \includegraphics[width=0.5\textwidth]{figs/toxicity.pdf}
%     \caption{Comparison of toxicity. }
%     \label{fig:toxicity}
% \end{figure}

% \subsection{Attention Flow}


% In this section, we test whether our UltraGen adapt well in out of domain downstream tasks. We test two capabilities, the first one is the factual, the

