\section{Related Work}
\paragraph{Image-to-Image Generation Models}
Image-to-image translation models have become increasingly significant in the field of computer vision. Generative Adversarial Networks (GANs) and auto-regressive models have been pivotal, with notable architectures like Instruct Pix2Pix, CycleGAN, and PixelCNN demonstrating impressive results____. Diffusion models, such as SR3 and ADM, have emerged as powerful alternatives, offering superior quality and diversity in image generation tasks by progressively refining noisy images to high-quality outputs____. 

The Instruct Pix2Pix framework represents a significant advancement in the field of image editing____. This model has been widely used in various image-to-image generation tasks, such as converting hand-drawn sketches into photographs____, transforming abstract maps into realistic map images____ and de-noising images taken in harsh environments for crowd counting____. Instruct Pix2Pix employs Classifier-Free Guidance (CFG) for both image and text conditions, adjusting the weights of these inputs to control the generated output. It enables users to use natural language instructions for image editing, leveraging the model's ability to implement detailed modifications. The system manipulates the internal attention mechanisms of generative models, offering precise alterations without the need for additional input masks. Innovations such as DALLE-3 and CLIP integrate multi-modal learning, leveraging large-scale text and image datasets to enhance contextual understanding and generation capabilities____. 

However, a common limitation persists across most state-of-the-art approaches: they typically rely on some form of mask guidance to achieve precise local editing. Whether through manual mask annotations____, attention map analysis____, or semantic segmentation, the dependence on mask priors creates a barrier for non-expert users and limits the flexibility of these systems. BayesGenie addresses this limitation by enhancing the diffusion model with automated parameter optimization, enabling it to follow instructions more accurately while preserving the high quality of the generated images without requiring any form of mask guidance.


\paragraph{LLM-assisted Image Generation}
LLMs have significantly advanced numerous NLP tasks through their exceptional generalization capabilities, which have also been effectively harnessed to enhance image-to-image generation processes. Flamingo combines visual information with the multimodal generalization capabilities of LLMs, enabling it to handle new tasks without specific training ____. LayoutGPT utilizes LLMs to interpret structured diagrams, akin to CSS, enabling the accurate positioning of objects within a generated scene, which allows it to understand spatial relationships and apply them consistently across various layouts ____. 
% Ranni, on the other hand, employs LLMs to assist in the semantic segmentation of images, meticulously adjusting object placements based on contextual cues provided by the language model ____. 
% BayesGenie uses LLM's multimodal visual understanding capabilities to score generated results, ensuring that the images align closely with user specifications, thus enhancing the overall accuracy and utility of the generated content.


\begin{figure*}[ht]
    \centering
    \includegraphics[width=\linewidth]{flow.drawio-1.pdf}
    \caption{The System Architecture for Fine-Grained Image Control Using LLMs and Bayesian Optimization is detailed herein. Figure (a) illustrates the conventional method for comparison purposes.}
    \label{fig:flow}
\end{figure*}
 

\paragraph{Bayesian learning}
Black-box functions are frequently encountered across various domains, particularly in the intricate task of parameter tuning within machine learning ____. Bayesian learning ____, a statistical method, facilitates the inference of model parameters by integrating prior knowledge with the likelihood derived from observed data. In the context of BayesGenie, Bayesian learning is leveraged to optimize the parameters of generative models, thereby enhancing both the quality and diversity of generated images through the minimization of the loss function. Specifically, Bayesian Optimization approximates the objective function by constructing a surrogate model, such as a Gaussian process ____, and employs global optimization techniques to identify the optimal model parameters. Currently, Bayesian optimization is widely used for finding the optimal hyperparameters of models____.