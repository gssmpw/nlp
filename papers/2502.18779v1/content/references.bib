@inproceedings{leviathan2023fast,
  title={Fast inference from transformers via speculative decoding},
  author={Leviathan, Yaniv and Kalman, Matan and Matias, Yossi},
  booktitle={International Conference on Machine Learning},
  pages={19274--19286},
  year={2023},
  organization={PMLR}
}

@article{chen2023accelerating,
  title={Accelerating large language model decoding with speculative sampling},
  author={Chen, Charlie and Borgeaud, Sebastian and Irving, Geoffrey and Lespiau, Jean-Baptiste and Sifre, Laurent and Jumper, John},
  journal={arXiv preprint arXiv:2302.01318},
  year={2023}
}

@inproceedings{NEURIPS2020_1457c0d6,
 author = {Brown, Tom and Mann, Benjamin and Ryder, Nick and Subbiah, Melanie and Kaplan, Jared D and Dhariwal, Prafulla and Neelakantan, Arvind and Shyam, Pranav and Sastry, Girish and Askell, Amanda and Agarwal, Sandhini and Herbert-Voss, Ariel and Krueger, Gretchen and Henighan, Tom and Child, Rewon and Ramesh, Aditya and Ziegler, Daniel and Wu, Jeffrey and Winter, Clemens and Hesse, Chris and Chen, Mark and Sigler, Eric and Litwin, Mateusz and Gray, Scott and Chess, Benjamin and Clark, Jack and Berner, Christopher and McCandlish, Sam and Radford, Alec and Sutskever, Ilya and Amodei, Dario},
 booktitle = {Advances in Neural Information Processing Systems},
 editor = {H. Larochelle and M. Ranzato and R. Hadsell and M.F. Balcan and H. Lin},
 pages = {1877--1901},
 publisher = {Curran Associates, Inc.},
 title = {Language Models are Few-Shot Learners},
 volume = {33},
 year = {2020}
}
@article{touvron2023llama,
  title={Llama: Open and efficient foundation language models},
  author={Touvron, Hugo and Lavril, Thibaut and Izacard, Gautier and Martinet, Xavier and Lachaux, Marie-Anne and Lacroix, Timoth{\'e}e and Rozi{\`e}re, Baptiste and Goyal, Naman and Hambro, Eric and Azhar, Faisal and others},
  journal={arXiv preprint arXiv:2302.13971},
  year={2023}
}
@article{luo2022critical,
  title={A critical review of state-of-the-art chatbot designs and applications},
  author={Luo, Bei and Lau, Raymond YK and Li, Chunping and Si, Yain-Whar},
  journal={Wiley Interdisciplinary Reviews: Data Mining and Knowledge Discovery},
  volume={12},
  number={1},
  pages={e1434},
  year={2022},
  publisher={Wiley Online Library}
}

@article{chen2021evaluating,
  title={Evaluating large language models trained on code},
  author={Chen, Mark and Tworek, Jerry and Jun, Heewoo and Yuan, Qiming and Pinto, Henrique Ponde De Oliveira and Kaplan, Jared and Edwards, Harri and Burda, Yuri and Joseph, Nicholas and Brockman, Greg and others},
  journal={arXiv preprint arXiv:2107.03374},
  year={2021}
}

@inproceedings{miao2024specinfer,
  title={Specinfer: Accelerating large language model serving with tree-based speculative inference and verification},
  author={Miao, Xupeng and Oliaro, Gabriele and Zhang, Zhihao and Cheng, Xinhao and Wang, Zeyu and Zhang, Zhengxin and Wong, Rae Ying Yee and Zhu, Alan and Yang, Lijie and Shi, Xiaoxiang and others},
  booktitle={Proceedings of the 29th ACM International Conference on Architectural Support for Programming Languages and Operating Systems, Volume 3},
  pages={932--949},
  year={2024}
}

@article{cai2024medusa,
  title={Medusa: Simple llm inference acceleration framework with multiple decoding heads},
  author={Cai, Tianle and Li, Yuhong and Geng, Zhengyang and Peng, Hongwu and Lee, Jason D and Chen, Deming and Dao, Tri},
  journal={arXiv preprint arXiv:2401.10774},
  year={2024}
}

@article{li2024eagle,
  title={Eagle: Speculative sampling requires rethinking feature uncertainty},
  author={Li, Yuhui and Wei, Fangyun and Zhang, Chao and Zhang, Hongyang},
  journal={arXiv preprint arXiv:2401.15077},
  year={2024}
}

@article{spector2023accelerating,
  title={Accelerating llm inference with staged speculative decoding},
  author={Spector, Benjamin and Re, Chris},
  journal={arXiv preprint arXiv:2308.04623},
  year={2023}
}

@article{yang2024multi,
  title={Multi-candidate speculative decoding},
  author={Yang, Sen and Huang, Shujian and Dai, Xinyu and Chen, Jiajun},
  journal={arXiv preprint arXiv:2401.06706},
  year={2024}
}

@article{sun2024spectr,
  title={Spectr: Fast speculative decoding via optimal transport},
  author={Sun, Ziteng and Suresh, Ananda Theertha and Ro, Jae Hun and Beirami, Ahmad and Jain, Himanshu and Yu, Felix},
  journal={Advances in Neural Information Processing Systems},
  volume={36},
  year={2024}
}

@article{zhou2023distillspec,
  title={Distillspec: Improving speculative decoding via knowledge distillation},
  author={Zhou, Yongchao and Lyu, Kaifeng and Rawat, Ankit Singh and Menon, Aditya Krishna and Rostamizadeh, Afshin and Kumar, Sanjiv and Kagy, Jean-Fran{\c{c}}ois and Agarwal, Rishabh},
  journal={arXiv preprint arXiv:2310.08461},
  year={2023}
}

@article{monea2023pass,
  title={Pass: Parallel speculative sampling},
  author={Monea, Giovanni and Joulin, Armand and Grave, Edouard},
  journal={arXiv preprint arXiv:2311.13581},
  year={2023}
}

@article{sun2024triforce,
  title={TriForce: Lossless Acceleration of Long Sequence Generation with Hierarchical Speculative Decoding},
  author={Sun, Hanshi and Chen, Zhuoming and Yang, Xinyu and Tian, Yuandong and Chen, Beidi},
  journal={arXiv preprint arXiv:2404.11912},
  year={2024}
}
@article{yang2023inference,
  title={Inference with reference: Lossless acceleration of large language models},
  author={Yang, Nan and Ge, Tao and Wang, Liang and Jiao, Binxing and Jiang, Daxin and Yang, Linjun and Majumder, Rangan and Wei, Furu},
  journal={arXiv preprint arXiv:2304.04487},
  year={2023}
}

@article{he2023rest,
  title={Rest: Retrieval-based speculative decoding},
  author={He, Zhenyu and Zhong, Zexuan and Cai, Tianle and Lee, Jason D and He, Di},
  journal={arXiv preprint arXiv:2311.08252},
  year={2023}
}

@article{ou2024lossless,
  title={Lossless Acceleration of Large Language Model via Adaptive N-gram Parallel Decoding},
  author={Ou, Jie and Chen, Yueming and Tian, Wenhong},
  journal={arXiv preprint arXiv:2404.08698},
  year={2024}
}

@article{chen2023cascade,
  title={Cascade speculative drafting for even faster llm inference},
  author={Chen, Ziyi and Yang, Xiaocong and Lin, Jiacheng and Sun, Chenkai and Huang, Jie and Chang, Kevin Chen-Chuan},
  journal={arXiv preprint arXiv:2312.11462},
  year={2023}
}

@article{jeon2024recursive,
  title={Recursive speculative decoding: Accelerating llm inference via sampling without replacement},
  author={Jeon, Wonseok and Gagrani, Mukul and Goel, Raghavv and Park, Junyoung and Lee, Mingu and Lott, Christopher},
  journal={arXiv preprint arXiv:2402.14160},
  year={2024}
}

@inproceedings{anonymous2024spechub,
    title = "{S}pec{H}ub: Provable Acceleration to Multi-Draft Speculative Decoding",
    author = "Sun, Ryan  and
      Zhou, Tianyi  and
      Chen, Xun  and
      Sun, Lichao",
    editor = "Al-Onaizan, Yaser  and
      Bansal, Mohit  and
      Chen, Yun-Nung",
    booktitle = "Proceedings of the 2024 Conference on Empirical Methods in Natural Language Processing",
    month = nov,
    year = "2024",
    address = "Miami, Florida, USA",
    publisher = "Association for Computational Linguistics",
    doi = "10.18653/v1/2024.emnlp-main.1148",
    pages = "20620--20641",
}

@article{chen2024sequoia,
  title={Sequoia: Scalable, robust, and hardware-aware speculative decoding},
  author={Chen, Zhuoming and May, Avner and Svirschevski, Ruslan and Huang, Yuhsun and Ryabinin, Max and Jia, Zhihao and Chen, Beidi},
  journal={arXiv preprint arXiv:2402.12374},
  year={2024}
}

@book{biggs1993algebraic,
title={Algebraic graph theory},
author={Biggs, Norman},
number={67},
year={1993},
publisher={Cambridge university press}
}


@article{commoner1973sufficient,
title={A sufficient condition for a matrix to be totally unimodular},
author={Commoner, Frederic G},
journal={Networks},
volume={3},
number={4},
pages={351--365},
year={1973},
publisher={Wiley Online Library}
}


@article{hoffman2010integral,
title={Integral boundary points of convex polyhedra},
author={Hoffman, Alan J and Kruskal, Joseph B},
journal={50 Years of Integer Programming 1958-2008: From the Early Years to the State-of-the-Art},
pages={49--76},
year={2010},
publisher={Springer}
}

@book{schrijver2003combinatorial,
  title={Combinatorial optimization: polyhedra and efficiency},
  author={Schrijver, Alexander and others},
  volume={24},
  number={2},
  year={2003},
  publisher={Springer}
}

@article{hitchcock1941distribution,
  title={The distribution of a product from several sources to numerous localities},
  author={Hitchcock, Frank L},
  journal={Journal of mathematics and physics},
  volume={20},
  number={1-4},
  pages={224--230},
  year={1941},
  publisher={Wiley Online Library}
}

@misc{alpaca,
  author = {Rohan Taori and Ishaan Gulrajani and Tianyi Zhang and Yann Dubois and Xuechen Li and Carlos Guestrin and Percy Liang and Tatsunori B. Hashimoto },
  title = {Stanford Alpaca: An Instruction-following LLaMA model},
  year = {2023},
  publisher = {GitHub},
  journal = {GitHub repository},
}

@inproceedings{bojar2014findings,
  title={Findings of the 2014 workshop on statistical machine translation},
  author={Bojar, Ond{\v{r}}ej and Buck, Christian and Federmann, Christian and Haddow, Barry and Koehn, Philipp and Leveling, Johannes and Monz, Christof and Pecina, Pavel and Post, Matt and Saint-Amand, Herve and others},
  booktitle={Proceedings of the ninth workshop on statistical machine translation},
  pages={12--58},
  year={2014}
}


@inproceedings{DBLP:conf/nips/HermannKGEKSB15,
  author={Karl Moritz Hermann and Tomás Kociský and Edward Grefenstette and Lasse Espeholt and Will Kay and Mustafa Suleyman and Phil Blunsom},
  title={Teaching Machines to Read and Comprehend},
  year={2015},
  cdate={1420070400000},
  pages={1693-1701},
  booktitle={Twenty-eighth Conference on Neural Information Processing Systems},
}

@article{zhang2022opt,
  title={Opt: Open pre-trained transformer language models},
  author={Zhang, Susan and Roller, Stephen and Goyal, Naman and Artetxe, Mikel and Chen, Moya and Chen, Shuohui and Dewan, Christopher and Diab, Mona and Li, Xian and Lin, Xi Victoria and others},
  journal={arXiv preprint arXiv:2205.01068},
  year={2022}
}

@misc{vicuna2023,
    title = {Vicuna},
    author = {Chiang, Wei-Lin and Li, Zhuohan and Lin, Zi and Sheng, Ying and Wu, Zhanghao and Zhang, Hao and Zheng, Lianmin and Zhuang, Siyuan and Zhuang, Yonghao and Gonzalez, Joseph E. and Stoica, Ion and Xing, Eric P.},
    month = {March},
    year = {2023}
}

@article{yang2024qwen2,
  title={Qwen2 technical report},
  author={Yang, An and Yang, Baosong and Hui, Binyuan and Zheng, Bo and Yu, Bowen and Zhou, Chang and Li, Chengpeng and Li, Chengyuan and Liu, Dayiheng and Huang, Fei and others},
  journal={arXiv preprint arXiv:2407.10671},
  year={2024}
}

@article{miao2023specinfer,
  title={SpecInfer: Accelerating Generative LLM Serving with Speculative Inference and Token Tree Verification},
  author={Miao, Xupeng and Oliaro, Gabriele and Zhang, Zhihao and Cheng, Xinhao and Wang, Zeyu and Wong, Rae Ying Yee and Chen, Zhuoming and Arfeen, Daiyaan and Abhyankar, Reyna and Jia, Zhihao},
  journal={arXiv preprint arXiv:2305.09781},
  year={2023}
}

@article{iwata2008submodular,
  title={Submodular function minimization},
  author={Iwata, Satoru},
  journal={Mathematical Programming},
  volume={112},
  pages={45--64},
  year={2008},
  publisher={Springer}
}

@inproceedings{
khisti2024importanceweighted,
title={Importance Weighted Multi-Draft Speculative Sampling},
author={Ashish J Khisti and Arash Behravesh and Hassan Dbouk and Arash Behboodi and Roland Memisevic and Christos Louizos},
booktitle={ICML 2024 Workshop on Theoretical Foundations of Foundation Models},
year={2024},
}

@article{zheng2023judging,
  title={Judging llm-as-a-judge with mt-bench and chatbot arena},
  author={Zheng, Lianmin and Chiang, Wei-Lin and Sheng, Ying and Zhuang, Siyuan and Wu, Zhanghao and Zhuang, Yonghao and Lin, Zi and Li, Zhuohan and Li, Dacheng and Xing, Eric and others},
  journal={Advances in Neural Information Processing Systems},
  volume={36},
  pages={46595--46623},
  year={2023}
}

@inproceedings{huaccelerated,
  title={Accelerated Speculative Sampling Based on Tree Monte Carlo},
  author={Hu, Zhengmian and Huang, Heng},
  booktitle={Forty-first International Conference on Machine Learning},
  year={2024}
}

@article{sun2024optimal,
  title={Optimal Block-Level Draft Verification for Accelerating Speculative Decoding},
  author={Sun, Ziteng and Ro, Jae Hun and Beirami, Ahmad and Suresh, Ananda Theertha},
  journal={arXiv preprint arXiv:2403.10444},
  year={2024},
}

@inproceedings{sunblock,
  title={Block Verification Accelerates Speculative Decoding},
  author={Sun, Ziteng and Mendlovic, Uri and Leviathan, Yaniv and Aharoni, Asaf and Beirami, Ahmad and Ro, Jae Hun and Suresh, Ananda Theertha},
  booktitle={Workshop on Efficient Systems for Foundation Models II@ ICML2024},
  year={2024}
}