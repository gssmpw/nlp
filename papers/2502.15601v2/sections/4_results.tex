\begin{figure*}[t]
\begin{center}
    \includegraphics[width=1.0\linewidth]{figures/gellery.pdf}
\end{center}
\caption{\textbf{Language-guided complex scene generation.} Examples illustrating our method’s capability to generate expansive 3D indoor and outdoor scenes, richly populated with diverse objects.}
\label{fig:gallery_1}
\end{figure*}

\begin{figure*}[t]
\begin{center}
    \includegraphics[width=1.0\linewidth]{figures/bridge2.pdf}
\end{center}
\caption{\textbf{Language-guided scene generation and editing.}  Examples demonstrating our method's ability to generate complex large-scale outdoor scenes. Users can interact with our approach using natural language to further edit the created scenes.}
\label{fig:gallery_2}
\end{figure*}


\section{Experiments}
In this section, we evaluate the effectiveness of our proposed WorldCraft for 3D world creation across a range of challenging settings, comparing it qualitatively and quantitatively with state-of-the-art methods. Through evaluations and ablation studies, we provide empirical evidence of the effectiveness of its core modules. We then showcase our approach's capability to synthesize highly complex scenes.
We kindly refer the reader to our \emph{supplementary document and video} for additional experimental details and results.

\subsection{Experimental Setup}
\noindent\textbf{Implementation details.} We leverage OpenAI’s \textsc{gpt-4-0314}~\cite{achiam2023gpt} as both our agent and the critic model in the ForgeIt system. The ForgeIt agent navigates Infinigen~\cite{infinigen2023infinite,infinigen2024indoors} to procedurally generate 3D assets. We use Meshy\footnote{https://www.meshy.ai/api} as our additional deep 3D generator. CineGPT~\cite{liu2024chatcam}, originally designed for camera control, now serves as our text-to-trajectory model in the trajectory control module, is utilized without fine-tuning for general objects.

\noindent\textbf{Evaluation metrics.}
We evaluate the generated scene from three aspects: consistency with the input text, aesthetics (whether it is realistic and visually pleasing), and functionality (whether it respects ergonomics). Each of these aspects is rated on a scale from 1 to 10 by both users and the GPT-4 model. For consistency, we additionally report a CLIP score measuring the similarity between the rendered image of the generated scene and the input text. We also report the approach's runtime for synthesizing a single scene.



\subsection{Complex Scene Generation}
To better showcase the exceptional capabilities of our method in generating highly complex scenes, we present compelling examples in \Cref{fig:gallery_1} and \Cref{fig:gallery_2}.
%
In the first example in \Cref{fig:gallery_1}, our approach synthesizes a large, fully-furnished house tailored to the user-specified style. It further demonstrates our capability to adhere to user instructions by invoking a deep 3D generator to integrate additional objects into the scene seamlessly. The second example in \Cref{fig:gallery_1} depicts a cityscape where skyscrapers are neatly arranged beside a park filled with golden, autumnal trees.
%
\Cref{fig:gallery_2} showcases our method's proficiency in creating expansive outdoor scenes, featuring procedurally generated natural elements alongside artistically crafted objects from the deep 3D generator. This example also allows the user to edit further and enhance the scene using natural language, illustrating the adaptability of our interface.
This example also highlights our trajectory control module's capability of turning user instructions into corresponding object movements (see our supplementary video).

\begin{table}[t]
\centering
\caption{\textbf{Quantitative comparison on 3D scene generation.} Our approach achieves the best performance in terms of consistency, aesthetics, and functionality.}
\label{tab:comparison}
\resizebox{\linewidth}{!}{
\begin{tabular}{@{}lcccccccc@{}}
\toprule
\multirow{2}{*}{Method} & \multicolumn{3}{c}{Consistency ($\uparrow$)} & \multicolumn{2}{c}{Aesthetics ($\uparrow$)} & \multicolumn{2}{c}{Functionality ($\uparrow$)} & \multirow{2}{*}{Runtime ($\downarrow$)} \\
\cmidrule(r){2-4} \cmidrule(r){5-6} \cmidrule(r){7-8} 
 & CLIP & GPT-4 & User & GPT-4 & User & GPT-4 & User & \\
\midrule
\cite{yang2024holodeck} & 0.322 &  6.00 & 5.30 & 5.00 & 5.18 & 6.50 & 7.82&\textbf{5 min} \\
\cite{li2025dreamscene} & 0.281 &  7.00 & 5.11 & 6.00 & 6.72 & 7.00 & 4.31 & 53 min \\
Ours & \textbf{0.384} & \textbf{8.50} & \textbf{6.39} &  \textbf{8.00} & \textbf{7.15} & \textbf{7.00} & \textbf{8.01} & 18 min \\
\bottomrule
\end{tabular}
}
\end{table}



\begin{figure*}[t]
\begin{center}
    \includegraphics[width=1.0\linewidth]{figures/comparison.pdf}
\end{center}
\caption{\textbf{Qualitative comparison of 3D scene generation. } Compared with \cite{yang2024holodeck} and \cite{li2025dreamscene}, our method produces more realistic and visually consistent scenes, with accurate object placement and better adherence to the input text, demonstrating superior quality in both aesthetics and functionality.
}
\label{fig:comparison}
\end{figure*}


\subsection{Comparison}
As shown in \Cref{fig:comparison}, WorldCraft produces high-quality indoor 3D scenes. Compared to baseline approaches, our method produces more realistic appearance and geometry. Our approach generates layouts that are reasonable in terms of functionality, while the baselines may violate common sense, such as placing a basketball hoop over the bed. Moreover, our approach generates scenes with a style that is consistent with the input text, while automatically customizing objects, such as their material, texture, and shape. It also appropriately invokes a deep 3D generator to insert objects like a bicycle for ``a sporty boy's bedroom'' or a Chinese knot for ``a classic Chinese dining room,'' accurately reflecting the required styles. According to \Cref{tab:comparison}, our approach achieves the highest score, further validating its strength in consistency, aesthetics, and functionality. In addition, compared with diffusion-based baselines, our method is more efficient with a shorter runtime.




\begin{figure*}[t]
\begin{center}
    \includegraphics[width=0.8\linewidth]{figures/forgeit.pdf}
\end{center}
\caption{\textbf{Qualitative results of ForgeIt.}
Our results demonstrate ForgeIt's ability to control object geometry and appearance. The user can refine and edit the results via multi-turn conversations and provide supplementary inputs, such as textures, to align with design intentions.
}
\label{fig:forgeit_result1}
\end{figure*}


\begin{figure*}[t]
\begin{center}
    \includegraphics[width=\linewidth]{figures/arrangeit_single.pdf}
\end{center}
\caption{\textbf{Qualitative results of ArrangeIt.} The agent extracts hierarchical relationships between objects and decomposes the task into several sub-problems to achieve a layout arrangement with good functionality and consistency with user requirements. The red box corresponds to the shelf in the first row.
}
\label{fig:arrangeit_result}
\end{figure*}







\noindent\textbf{Baselines.}
We compare our method to recent baseline methods for 3D scene generation: the LLM-based Holodeck~\cite{yang2024holodeck} and the diffusion-based DreamScene~\cite{li2025dreamscene}. Additionally, for the evaluation of our ArrangeIt module, we compare it with LayoutGPT~\cite{feng2024layoutgpt}, an LLM-based approach for generating layouts.













\subsection{Evaluation}
\noindent \textbf{ForgeIt.} In \Cref{fig:forgeit_result1}, we present qualitative results of the \textit{ForgeIt} module, demonstrating its ability to control object geometry and appearance through natural language. Users can engage in multi-turn conversations to progressively refine the generated results and provide supplementary inputs, such as textures, to better align with specific design intentions.
%
We also present quantitative validation of the dynamic manual construction procedure in ForgeIt. Specifically, we experiment with two variants: one without manual input (zero-shot generation) and one with a static user-coded manual. As shown in \Cref{tab:manual_procedures}, the ForgeIt module with dynamic manual reconstruction achieves the best performance in terms of consistency and aesthetics.

\begin{table}[t]
\centering
\caption{\textbf{Quantitative evaluation of the dynamic manual construction of ForgeIt.}
Our dynamic manual coaches the agent to master procedural generation, achieving the highest consistency and aesthetics score.}
\label{tab:manual_procedures}
\resizebox{\linewidth}{!}{%
\begin{tabular}{@{}ccccccc@{}}
\toprule
\multirow{2}{*}{{Manual Construction}} & \multicolumn{3}{c}{{Consistency}} & \multicolumn{2}{c}{{Aesthetics}} \\
\cmidrule(r){2-4} \cmidrule(r){5-6}
 & CLIP & User & GPT-4 & User & GPT-4 \\
\midrule
\xmark      & 0.271 & 4.59 & 6.50 & 5.60 & 7.50 \\
Static         & 0.273 & 4.31 & 6.00 & 5.57 & 7.50 \\
Dynamic        & \textbf{0.378} & \textbf{6.29} & \textbf{8.00} & \textbf{7.01} & \textbf{8.00} \\
\bottomrule
\end{tabular}}
\end{table}




\begin{table}[t]
\centering
\caption{\textbf{Quantitative evaluation of ArrangeIt.} ArrangeIt with hierarchical modeling generates a layout with the highest consistency and functionality scores.}

\label{tab:arrangeit}
\resizebox{\linewidth}{!}{%
\begin{tabular}{@{}lccccc@{}}
\toprule
\multirow{2}{*}{Layout Module} & \multicolumn{3}{c}{\textbf{Consistency}} & \multicolumn{2}{c}{\textbf{Functionality}} \\
\cmidrule(r){2-4} \cmidrule(r){5-6}
               &CLIP & User & GPT-4 & User & GPT-4 \\
\midrule
LayoutGPT            & 0.272    & 4.90 & 7.00 & 5.41 & 7.50 \\
ArrangeIt (w/o hierarchy)   & 0.340   &3.81 & 6.00 & 5.67 & 7.00 \\
ArrangeIt   & \textbf{0.361}   & \textbf{8.58} & \textbf{7.50} & \textbf{7.63} & \textbf{8.50} \\
\bottomrule
\end{tabular}}
\end{table}


\noindent \textbf{ArrangeIt.} In \Cref{fig:arrangeit_result}, we present qualitative results of the \textit{ArrangeIt} module, where the agent extracts hierarchical relationships between objects and decomposes the task into several sub-problems. For example, it separates the arrangement of smaller objects on a shelf from the placement of larger objects in a bathroom. For each sub-task, the user retains control, enabling layout adjustments at various levels. This capability results in a layout with good consistency to user requirements and functionality. This is further illustrated by the quantitative evaluation in \Cref{tab:arrangeit}, where we perform an ablation study on the layout module using LayoutGPT or ArrangeIt without hierarchical modeling.





\section{Conclusion}
 This work introduces WorldCraft, an LLM agent that utilizes procedural generation to create customizable indoor and outdoor scenes populated with various objects. With WorldCraft, users can interact using natural language to control individual object attributes and the overall scene layout. We propose ForgeIt, which develops an ever-growing manual through auto-verification to facilitate precise customization of individual objects. We also introduce ArrangeIt, which formulates hierarchical optimization problems to determine layouts that consider both ergonomic and aesthetic aspects. To complete our pipeline,  a trajectory control module is designed that enables users to animate the scene and operate the camera through natural language interactions. Our agent's 3D visual programming capabilities are compatible with off-the-shelf deep 3D generators for enhancing scene assets.
%
Our experiments demonstrate the versatility of WorldCraft in customizing complex 3D scenes and assisting non-professionals in realizing their creative visions.