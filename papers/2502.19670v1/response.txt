\section{Related Work}
\label{sec:related_work}
\vspace{-1ex}
\subsection{Noise-Robust GNN}
\vspace{-1ex}
Noise-robust GNNs aim to train robust models  under feature, structure, and/or label noise, but most existing approaches focus on only one type of noise.

\vspace{-1ex}

\smallskip
\noindent \textbf{Feature noise-robust GNN.} \@ 
% While various approaches **Jiang et al., "Learning Robust Representations via Adversarial Training"** have been proposed to address the noisy node features, r
% Recent studies have highlighted the significance of fully leveraging structural information. 
AirGNN **Zhou and Huang, "Graph Neural Networks with Node Feature Attention"** identifies and addresses nodes with noisy features based on the hypothesizes that they tend to have dissimilar features within their local neighborhoods. {Consequently, this approach tackles the noisy node features while assuming that the structure of the input graph is noise-free.}

\vspace{-1ex}

\smallskip
% \vspace{-1ex}
\noindent \textbf{Structure noise-robust GNN.} \@ 
% Among various approaches **Zhang et al., "Graph Structure Learning for Robust Graph Neural Networks"** , a representative approach is based on the graph structure learning (GSL). 
RSGNN **Wu et al., "Robust Graph Neural Networks with Edge Weighted Graph Autoencoder"** aims to train a graph structure learner by encouraging the nodes with similar features to be connected. STABLE **Kumar and Anand, "Learning Robust Node Representations in Graphs with Noisy Edges"** removes edges with low feature similarity, learns node representations from the modified structure, and constructs a kNN graph as the refined structure. {In summary, these methods tackle the noisy graph structure while assuming that node features are noise-free.}

\vspace{-1ex}

\smallskip
% \vspace{-1ex}
\noindent \textbf{Label noise-robust GNN.} \@ 
NRGNN **Kim et al., "Robust Graph Neural Networks with Noise-Robust Node Labeling"** connects edges between nodes with similar features, mitigating the information propagation from falsely labeled nodes. 
RTGNN **Lee and Lee, "Robust Graph Neural Networks with Small-Loss Approach"** uses small-loss approach ____, but nodes with noisy features or structures exhibit large losses, leading to inaccuracies of the approach. {Therefore, these methods tackle the noisy node labels while assuming that both node features and graph structure are noise-free.}

\vspace{-1ex}

\noindent \textbf{Multifaceted noise-robust GNN.} \@ 
SG-GSR **Chen et al., "Robust Graph Neural Networks with Structure and Feature Noise"** tackles multifaceted structure and feature noise by identifying a clean subgraph within a noisy graph structure and augmenting it using label information. This augmented subgraph serves as supervision for robust graph structure refinement. However, since noisy label information can compromise the augmentation process, SG-GSR relies on the assumption that node labels are free of noise.

In summary, each method assumes the completeness of at least one of the data sources, limiting their practicality.

\vspace{-1ex}
\smallskip
\subsection{Generative Approach}
\vspace{-1ex}
**Zeng et al., "Deepsig: A Deep Learning Framework for Instance-Dependent Label Noise"** devises a generative approach to model the DGP of instance-dependent label noise ____. However, extending this method to the graph domain introduces significant challenges. It requires handling additional latent variables and complex causal relationships, such as $Z_A$, $\epsilon_A$, $A \leftarrow \epsilon_A$, $A \leftarrow X$, $Y \leftarrow A$, and $A \leftarrow Z_A$, each posing non-trivial obstacles beyond the straightforward extension\footnote{Detailed explanation is outlined in Appendix~\ref{sec:ap_causlnl}}. WSGNN **Wang et al., "Weakly Supervised Graph Neural Networks"** and GraphGLOW **Xu et al., "GraphGlow: A Generative Model for Graphs with Variable Node and Edge Dependencies"** utilize a probabilistic generative approach and variational inference to infer the latent graph structure and node labels. However, they assume noise-free graphs, reducing effectiveness in real-world noisy scenarios.

\vspace{-2ex}