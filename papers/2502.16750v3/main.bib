@article{perez2022ignore,
  title={Ignore previous prompt: Attack techniques for language models},
  author={Perez, F{\'a}bio and Ribeiro, Ian},
  journal={arXiv preprint arXiv:2211.09527},
  year={2022}
}

@article{barua2024exploring,
  title={Exploring autonomous agents through the lens of large language models: A review},
  author={Barua, Saikat},
  journal={arXiv preprint arXiv:2404.04442},
  year={2024}
}

@article{barua2023kaxai,
  title={Kaxai: An integrated environment for knowledge analysis and explainable ai},
  author={Barua, Saikat and Momen, Sifat},
  journal={arXiv preprint arXiv:2401.00193},
  year={2023}
}

@inproceedings{barua2024elmagic,
  title={ELMAGIC: energy-efficient lean model for reliable medical image generation and classification using forward forward algorithm},
  author={Barua, Saikat and Rahman, Mostafizur and Saad, Mezbah Uddin and Islam, Rafiul and Sadek, Md Jafor},
  booktitle={2024 IEEE 3rd International Conference on Computing and Machine Intelligence (ICMI)},
  pages={1--5},
  year={2024},
  organization={IEEE}
}

@article{barua2024pygen,
  title={PyGen: A Collaborative Human-AI Approach to Python Package Creation},
  author={Barua, Saikat and Rahman, Mostafizur and Sadek, Md Jafor and Islam, Rafiul and Khaled, Shehnaz and Hossain, Md Shohrab},
  journal={arXiv preprint arXiv:2411.08932},
  year={2024}
}

@article{Zou2023Jailbreaking,
  author = {Zou, Andy and Wang, Zifan and Carlini, Nicholas and Nasr, Milad and Kolter, J. Zico and Fredrikson, Matt},
  title = {Universal and Transferable Adversarial Attacks on Aligned Language Models},
  journal = {arXiv preprint arXiv:2307.15043},
  year = {2023},
  url = {https://arxiv.org/abs/2307.15043}
}

@article{Anil2024manyshot,
  author = {Anil, Cem and Carlini, Nicholas and Deng, Jie and Du, Wei and Li, Yuhuai and Madras, Daniel and McMahan, H. Brendan and Narayanan, Deepak and Nystrom, Nathan and Perez, Ethan and Ramasesh, Vinay and Resnick, Paul and Shorten, Connor and Wang, Zifan},
  title = {Many-Shot Jailbreaking},
  journal = {arXiv preprint arXiv:2401.14652},
  year = {2024},
  url = {https://arxiv.org/abs/2401.14652}
}

@article{Zhang2024Unpacking,
  author = {Zhang, Xinrui and Li, Peng and Wang, Tianyu and Chen, Wei},
  title = {Unpacking the Black Box: Understanding the Deceptive Capabilities of Large Language Models},
  journal = {arXiv preprint arXiv:2401.14652},
  year = {2024},
  url = {https://arxiv.org/abs/2401.14652}
}

@article{Wei2022Chainofthought,
  author = {Wei, Jason and Wang, Xuezhi and Schuurmans, Dale and Bosma, Maarten and Ichter, Brian and Xia, Fei and Chi, Ed and Le, Quoc and Zhou, Denny},
  title = {Chain-of-Thought Prompting Elicits Reasoning in Large Language Models},
  journal = {arXiv preprint arXiv:2201.11903},
  year = {2022},
  url = {https://arxiv.org/abs/2201.11903}
}

@article{Kaplan2020Scaling,
  author = {Kaplan, Jared and McCandlish, Sam and Henighan, Tom and Brown, Tom B. and Chess, Benjamin and Child, Rewon and Gray, Scott and Radford, Alec and Wu, Jeffrey and Amodei, Dario},
  title = {Scaling Laws for Neural Language Models},
  journal = {arXiv preprint arXiv:2001.08361},
  year = {2020},
  url = {https://arxiv.org/abs/2001.08361}
}

@article{Goodfellow2014Explaining,
  author = {Goodfellow, Ian J. and Shlens, Jonathon and Szegedy, Christian},
  title = {Explaining and Harnessing Adversarial Examples},
  journal = {arXiv preprint arXiv:1412.6572},
  year = {2014},
  url = {https://arxiv.org/abs/1412.6572}
}

@article{Ouyang2022Training,
  author = {Ouyang, Long and Wu, Jeff and Jiang, Xu and Almeida, Diogo and Wainwright, Carroll L. and Mishkin, Pamela and Zhang, Chong and Agarwal, Sandhini and Slama, Katarina and Ray, Alex and Schulman, John and Hilton, Jacob and Kelton, Fraser and Miller, Luke and Simonyan, Karen and Askell, Amanda and Welinder, Peter and Christiano, Paul and Leike, Jan and Lowe, Ryan},
  title = {Training Language Models to Follow Instructions with Human Feedback},
  journal = {arXiv preprint arXiv:2203.02155},
  year = {2022},
  url = {https://arxiv.org/abs/2203.02155}
}

@article{Bai2022Constitutional,
  author = {Bai, Yuntao and Kadavath, Saurav and Kundu, Sandipan and Askell, Amanda and Kernion, Jackson and Jones, Andy and Chen, Anna and Goldie, Anna and Mirhoseini, Azalia and McKinnon, Cameron and Chen, Carol and Olsson, Catherine and Olah, Christopher and Dhariwal, Danny and Schubert, Dario and Perez, Ethan and Radford, Alec and Schulman, John},
  title = {Constitutional AI: Harmlessness from AI Feedback},
  journal = {arXiv preprint arXiv:2212.08073},
  year = {2022},
  url = {https://arxiv.org/abs/2212.08073}
}

@article{Ribeiro2016Why,
  author = {Ribeiro, Marco Tulio and Singh, Sameer and Guestrin, Carlos},
  title = {"Why Should I Trust You?": Explaining the Predictions of Any Classifier},
  journal = {Proceedings of the 22nd ACM SIGKDD International Conference on Knowledge Discovery and Data Mining},
  pages = {1135--1144},
  year = {2016},
  url = {https://dl.acm.org/doi/10.1145/2939672.2939778}
}

@article{Vaswani2017Attention,
  title={Attention is all you need},
  author={Vaswani, Ashish and Shazeer, Noam and Parmar, Niki and Uszkoreit, Jakob and Jones, Llion and Gomez, Aidan N and Kaiser, {\L}ukasz and Polosukhin, Illia},
  journal={Advances in neural information processing systems},
  volume={30},
  year={2017}
}

@article{Brown2020Language,
  title={Language models are few-shot learners},
  author={Brown, Tom B and Mann, Benjamin and Ryder, Nick and Subbiah, Melanie and Kaplan, Jared and Dhariwal, Prafulla and Neelakantan, Arvind and Shyam, Pranav and Sastry, Girish and Askell, Amanda and others},
  journal={Advances in neural information processing systems},
  volume={33},
  pages={1877--1901},
  year={2020}
}



@article{Hendrycks2023Systematic,
    title={Systematic Evaluation of Safety in Large Language Models: A New Hope and a Challenge},
    author={Hendrycks, Dan and Mazeika, Mantas and Dan, Angel and Sharma, Nishant and Lam, David and Basart, Jacob},
    journal={arXiv preprint arXiv:2311.17211},
    year={2023}
}






@inproceedings{Carlini2019Adversarial,
    title={Adversarial examples are not easily detected: Bypassing ten detection methods},
    author={Carlini, Nicholas and Wagner, David},
    booktitle={Proceedings of the 10th ACM Workshop on Artificial Intelligence and Security},
    pages={103--118},
    year={2019}
}


@inproceedings{Ziegler2019Fine,
    title={Fine-tuning language models from human preferences},
    author={Ziegler, Daniel M and Stiennon, Nisan and Wu, Jeff and Brown, Tom B and Evans, Alec and Englert, Paul and Gandhi, Swapnil and Haldane, Christopher and  Gaurav, Ram and  Kumar, Ankur and others},
    booktitle={arXiv preprint arXiv:1909.08593},
    year={2019}
}

@inproceedings{Ganguli2022Red,
    title={Red teaming language models to reduce harms: methods, scaling behaviors, and lessons learned},
    author={Ganguli, Deep and Lovitt, Ian and  O'Brien, Andrew and  Jawahar, Sanmi and  Ramesh, Kamal and  Amodei, Dario and  Askell, Amanda and  Bailey, Jack and  Brundage, Miles and  Das, Dawn and others},
    booktitle={arXiv preprint arXiv:2209.07858},
    year={2022}
}

@article{He2024,
  title = {Security of AI Agents},
  author = {He, Yifeng and Wang, Ethan and Rong, Yuyang and Cheng, Zifei and Chen, Hao},
    journal={NA},
  year = {2024},
  url = {https://arxiv.org/abs/2406.08689}
}

@article{Khan2024,
  title = {Security Threats in Agentic AI System},
  author = {Khan, Raihan and Sarkar, Sayak and Mahata, Sainik Kumar and Jose, Edwin},
    journal={NA},
  year = {2024},
  url = {https://arxiv.org/abs/2410.14728}
}




