\begin{table*}[h]
\caption{Wav2Vec 2.0 results and training time. We report the number of transformer layers trained (`Layers'), activation and valence CCC on MSP-Podcast ``Test1" split (`Act' and `Val'), wall-clock training time in hours for 5 epochs (`Time'), and number of trainable parameters ('Params'). We report results for single precision (SP) and mixed precision (MP) separately. * indicates statistically significant improvement, and $\dagger$ indicates statistically significant decrease from full 12-layer finetune. Caching results are reported relative to their partial finetuning counterpart. $\uparrow$, $\downarrow$ represent increase and decrease in the value respectively. These experiments were conducted on NVIDIA A40 (non-caching) and RTX 2080 Ti (caching) GPUs.}
\label{tab:combined_results_table}
\centering
\begin{tabular}{l c c c c c||c c c c}
\hline
\multicolumn{6}{c||}{\textbf{Non-Caching Results}} & \multicolumn{4}{c}{\textbf{Relative Caching Results}} \\

\textbf{Layers} & \textbf{Precision} & \textbf{Act} & \textbf{Val} & \textbf{Time (h)} & \textbf{Params} & \textbf{Act} & \textbf{Val} & \textbf{Time (h)} & \textbf{Params} \\

% \textbf{Layers} & \textbf{Precision} & \textbf{Act} & \textbf{Val} & \textbf{Time (h)} & \textbf{Params} \\
% &&&&&&\textbf{Act}&\textbf{Val}&\textbf{Time (h)}&\textbf{Params}\\
\hline
\multirow{1}{*}{LoRA} & SP & 0.623±0.02 & 0.506$\dagger$±0.01 & 2.476±0.02 & 300K & -- & -- & -- & -- \\
\hline
\multirow{2}{*}{1} & SP & 0.622±0.02 & 0.458$\dagger$±0.01 & 2.443±0.002 & \multirow{2}{*}{12M} & .015$\uparrow$ & .049$\uparrow$ & 1.75$\downarrow$ & \multirow{2}{*}{7M}\\
& MP & 0.625±0.01 & 0.462$\dagger$±0.01 & 0.965±0.01&& .009$\uparrow$ & .046$\uparrow$ & 0.71$\downarrow$ & \\
\hline
\multirow{2}{*}{2} & SP & 0.638±0.01 & 0.508$\dagger$±0.01 & 2.477±0.01 & \multirow{2}{*}{19M}& .001$\downarrow$ & .001$\downarrow$ & 1.79$\downarrow$& \multirow{2}{*}{14M} \\
& MP & 0.645±0.01 & 0.507$\dagger$±0.004 & 0.982±0.003 && .011$\downarrow$ & .001$\uparrow$ & 0.73$\downarrow$ & \\
\hline
\multirow{2}{*}{\textbf{3}} & SP & 0.648±0.01 & 0.565±0.002 & 2.519±0.02 & \multirow{2}{*}{26M} & .004$\downarrow$ & .007$\downarrow$* & 1.50$\downarrow$ & \multirow{2}{*}{21M}\\
& \textbf{MP} & \textbf{0.655*±0.01} & \textbf{0.568±0.01} & 0.991±0.003 && .016$\downarrow$* & .013$\downarrow$ & 0.64$\downarrow$ & 
\\
\hline
\multirow{2}{*}{12} & SP & 0.637±0.01 & 0.567±0.02 & 2.980±0.01 & \multirow{2}{*}{90M} & \multirow{2}{*}{--} & \multirow{2}{*}{--} & \multirow{2}{*}{--} & \multirow{2}{*}{--}\\
 & MP & 0.641±0.01 & 0.566±0.01 & 1.145±0.01 & & \\
%& & & & & \\
\hline
\end{tabular}
\end{table*}

