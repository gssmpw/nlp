Although deep learning systems generalize poorly to distribution shifts ~\cite{d2022underspecification, teney2022predictingunderstandingrecognizingaddressing}, generalization of synthetic speech detectors is paramount ~\cite{muller2022does,chen20_odyssey}: they are deployed in security-critical systems \cite{kassis2023breaking} to detect synthetic speech from many speakers in the presence of varying acoustic conditions. Harder yet, synthetic speech detectors must generalize to novel spoofing attacks powered by the rapid pace of change in generative speech technology \cite{marek2024audiodeepfakedetectionmodels, m√ºller2024doesaudiodeepfakedetection}---including voice conversion (VC) and text-to-speech (TTS)---used in consumer products, such as e-readers, voice-assistants and chatbots~\cite{yang2024streamvcrealtimelowlatencyvoice, kameoka2018starganvcnonparallelmanytomanyvoice, choi2023dddmvcdecoupleddenoisingdiffusion, casanova2023yourttszeroshotmultispeakertts, qian2019autovczeroshotvoicestyle, kaneko2019cycleganvc2improvedcycleganbasednonparallel, bargum2023reimaginingspeechscopingreview}.
State-of-the-art synthetic speech detectors use self-supervised representations of speech \cite{tak2022automaticspeakerverificationspoofing, kang2024experimentalstudyenhancingvoice,wang2022investigatingselfsupervisedendsspeech}. These representations are extracted from models trained on vast amounts of unlabeled audio containing a significant number of speakers, acoustic conditions, and even possibly synthetic speech. While broad domain coverage of self-supervised learning (SSL) models may mitigate cross-domain performance degradation, few prior studies \cite{muller2024mlaad,muller2022does,khan2023battling} have explored the robustness of these models to specific distribution shifts.

In this paper, we aim to characterize the robustness of SSL-based synthetic speech detectors much more generally and answer the questions: Are SSL-based models more robust to distributon shifts? Which distribution shifts, if any, affect or degrade detection performance? How does the choice of training data impact generalization? 

Answering these questions requires fine-grained control of test time distribution shifts.
However, as existing benchmark datasets such as those introduced in the ASVspoof challenge encompass only a narrow range of domains, we develop a new benchmark called \methodName\footnote{The dataset is publicly available and can be downloaded from: \url{https://huggingface.co/datasets/ash56/ShiftySpeech}}, with over 3000 hours of real and synthetic speech from a wide range of state-of-the-art vocoders, TTS systems, languages, and domains \cite{wu15e_interspeech,Nautsch_2021,Liu_2023}. Using this benchmark, we explore the impact of a wide range of controlled distribution shifts on detector performance.


\textbf{Main contributions:} (i) We systematically study the generalization of SSL-based synthetic speech detectors. (ii) We create a benchmark dataset comprising synthesized speech from a variety of systems to help further research in robust detection. (iii) We find that especially the YouTube domain and languages not seen in training pose a significant challenge to our best performing detector. (iv) We find that careful data selection can significantly improve the generalization of synthetic speech detectors, resulting in state-of-the-art performance on the challenging In-The-Wild benchmark.\footnote{Scripts to reproduce our experiments as well as to download trained models are available at: \url{https://github.com/Ashigarg123/ShiftySpeech/}}
