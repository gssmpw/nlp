The ASVspoof benchmark \cite{wu15e_interspeech} includes data generated from diverse synthesis methods, but the data are all clean and models trained on these data do not seem to generalize well. For instance, prior work on generalization \cite{müller2021speechsilversilencegolden} found that models relied on spurious correlations with the amount of silence to make predictions, performing worse when silence was trimmed from the audio.

\cite{müller2024harderdifferentunderstandinggeneralization} note that poor cross-domain performance could be due to the innate ``hardness" of the data, and the ``difference", i.e., mismatch, between the training and test sets. They found that degradation is largely due to the difference gap. Prior work has sought to reduce this gap by training models on more data with greater diversity of domain \cite{shim2023multidatasetcotrainingsharpnessawareoptimization} or to improve on ``hard'' data by increasing model capacity \cite{7993036,8398462,8812621,chen17_interspeech}.
Prior work \cite{wang2022investigatingselfsupervisedendsspeech,kulkarni24_asvspoof} has also explored the effect of various front-end SSL-based models on the generalization of synthetic speech detectors using WavLM \cite{Chen_2022}, HuBERT \cite{hsu2021hubert} and Wav2Vec2 \cite{baevski2020wav2vec20frameworkselfsupervised}, as well as the effect of various backends \citet{kang2024experimentalstudyenhancingvoice}, such as RawNet2 \cite{jung2020improvedrawnetfeaturemap}, LCNN \cite{wu2018lightcnndeepface}, GMM and AASIST \cite{jung2021aasistaudioantispoofingusing}, to improve generalization. However, evaluations are conducted only on the ASVspoof or In-the-Wild datasets.

Training a generalizable detector is typically thought to require training data generated using multiple TTS or VC systems, but this is computationally expensive and not always feasible. Prior studies \cite{wang2023largescalevocodedspoofeddata, wang2023spoofedtrainingdataspeech, sanchez14b_interspeech} have found that using re-vocoded authentic speech is a useful alternative method for creating additional training data. We take a similar approach in this work to train synthentic speech detection models. Furthermore, very little work has explored generalization of synthetic speech detectors to other languages, or the effect of multilingual training of detectors on language shift. \citet{marek2024audiodeepfakedetectionmodels} studied generalization with respect to language shift and found that fine-tuning English-based models on the target language improves generalization. 
In this study, we further investigate this by training two separate detectors: one trained solely on Chinese speech and another only on English speech (see \autoref{sec:exp-10}). Our results provide insights into how language-specific training influences cross-lingual generalization.
