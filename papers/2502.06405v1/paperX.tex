\documentclass{article}
\usepackage{a4wide}
% SIAM Article Template
%\documentclass[review,onefignum,onetabnum]{siamart220329}
%\documentclass[review,hidelinks,onefignum,onetabnum]{siamart220329}
%\documentclass[final,onefignum,onetabnum]{siamart220329}

%\input{ex_shared}

% SIAM Shared Information Template
% This is information that is shared between the main document and any
% supplement. If no supplement is required, then this information can
% be included directly in the main document.

\usepackage[english]{babel}

% Packages and macros go here
\usepackage{lipsum}
\usepackage{amsfonts}
\usepackage{graphicx}
\usepackage{epstopdf}
\usepackage{algorithmic}
\usepackage{amsmath}
\usepackage{amsthm}
\usepackage{amssymb}
\usepackage{graphicx}
\usepackage{mathrsfs}
\usepackage{bm}             % boldface symbols (\bm)
\usepackage{enumitem}
%\usepackage{paralist}
\setlist[enumerate]{leftmargin=*,noitemsep, topsep=3pt,parsep=0pt,partopsep=0pt}
\setlist[itemize]{leftmargin=*,noitemsep, topsep=3pt,parsep=0pt,partopsep=0pt}

%\usepackage{algorithmic}
%\usepackage[colorlinks=true, allcolors=blue]{hyperref}

\usepackage{setspace}
\usepackage{algorithmic}
\usepackage[linesnumbered,ruled]{algorithm2e}
\usepackage{rotating}

\ifpdf
  \DeclareGraphicsExtensions{.eps,.pdf,.png,.jpg}
\else
  \DeclareGraphicsExtensions{.eps}
\fi

% Add a serial/Oxford comma by default.
\newcommand{\creflastconjunction}{, and~}

% Used for creating new theorem and remark environments
%\newsiamremark{remark}{Remark}
%\newsiamremark{hypothesis}{Hypothesis}
%\newsiamremark{assumption}{Assumption}
%\crefname{hypothesis}{Hypothesis}{Hypotheses}
%\newsiamthm{claim}{Claim}

% Sets running headers as well as PDF title and authors
%\headers{Hybrid Schwarz preconditioners for $hp$-DGM}{V.  Dolej{\v s}{\'\i}, and T. Hammerbauer}

% Title. If the supplement option is on, then "Supplementary Material"
% is automatically inserted before the title.
\title{Hybrid Schwarz preconditioners for linear systems arising from
  $hp$-discontinuous Galerkin method\thanks{Submitted to the editors DATE.
    %\funding{This work was funded by .......}
}}

% Authors: full names plus addresses.
\author{V{\'i}t Dolej{\v s}{\'\i}\thanks{Charles University, Faculty of Mathematics and Physics, Prague, Czech Republic  
  ({vit.dolejsi@matfyz.cuni.cz}, {hammerbt@karlin.mff.cuni.cz}).}%, \url{http://www.imag.com/\string~ddoe/}).}
\and Tom\'a{\v s} Hammerbauer\footnotemark[1]}

%\and Jane E. Smith\footnotemark[3]}

%\usepackage{amsopn}
%\DeclareMathOperator{\diag}{diag}

% Language setting
% Replace `english' with e.g. `spanish' to change the document language
%\usepackage[english]{babel}

% Set page size and margins
% Replace `letterpaper' with `a4paper' for UK/EU standard size
%\usepackage[letterpaper,top=2cm,bottom=2cm,left=3cm,right=3cm,marginparwidth=1.75cm]{geometry}
%\usepackage{a4wide}
% Useful packages


%\input{def.tex}

%\renewcommand{\S}{Section~}
%\newcommand{\Ss}{Sections~}

%\renewcommand{\S}{\S~}
\newcommand{\Ss}{\S}

\newcommand{\vertical}[1]{\begin{sideways}{#1}\end{sideways}}


%\usepackage{amsopn}

\DeclareMathOperator*{\argmin}{\arg\min}
\DeclareMathOperator*{\argmax}{\arg\max}
%\DeclareMathOperator*{\supp}{\mathrm{supp}}
%\DeclareMathOperator*{\diag}{\mathrm{diag}}
%\DeclareMathOperator*{\rank}{\mathrm{rank}}
\DeclareMathOperator*{\supp}{{supp}}
\DeclareMathOperator*{\diag}{{diag}}
\DeclareMathOperator*{\rank}{{rank}}

\newcommand{\range}{\mathrm{Range\,}}

\newtheorem{theorem}{Theorem}[section]
\newtheorem{lemma}[theorem]{Lemma}
%\theoremstyle{definition}
\newtheorem{definition}[theorem]{Definition}
%% %\newtheorem{example}[theorem]{Example}
%\newtheorem{remark}[theorem]{Remark}
%\newsiamthm{remark}{Remark}
%\newsiamremark{remark}{Remark}

\newtheorem{assumption}[theorem]{Assumption}
%% \newtheorem{proposition}[theorem]{Proposition}
\newtheorem{corollary}[theorem]{Corollary}
%% \newtheorem{xca}[theorem]{Exercise}
% \newtheorem{problem}[theorem]{Problem}
% \newtheorem{exam}[theorem]{Example}

%\theoremstyle{remark}
%\theoremstyle{definition}
%\newtheorem{algorithm}[theorem]{Algorithm}
\newtheorem{remark}{Remark}


\usepackage{thmtools}   %% JE-LI TOTO PRED \newsiamremark, TAK SPATNE CISLUJE !!!!
\newcommand\bifont {\bm}


% maticove symboly
\newcommand\matA{\mathbb{A}}
\newcommand\matB{\mathbb{B}}
\newcommand\matC{\mathbb{C}}
\newcommand\matD{\mathbb{D}}
\newcommand\matE{\mathbb{E}}
\newcommand\matF{\mathbb{F}}
\newcommand\matG{\mathbb{G}}
\newcommand\matH{\mathbb{H}}
\newcommand\matI{\mathbb{I}}
\newcommand\matJ{\mathbb{J}}
\newcommand\matK{\mathbb{K}}
\newcommand\matL{\mathbb{L}}
\newcommand\matM{\mathbb{M}}
\newcommand\matN{\mathbb{N}}
\newcommand\matO{\mathbb{O}}
\newcommand\matP{\mathbb{P}}
\newcommand\matQ{\mathbb{Q}}
\newcommand\matR{\mathbb{R}}
\newcommand\matS{\mathbb{S}}
\newcommand\matT{\mathbb{T}}
\newcommand\matU{\mathbb{U}}
\newcommand\matV{\mathbb{V}}
\newcommand\matX{\mathbb{X}}
\newcommand\matY{\mathbb{Y}}
\newcommand\matZ{\mathbb{Z}}


\newcommand\ms{{\rm s}}
\newcommand\mt{{\rm t}}
\newcommand\mc{{\rm c}}
\newcommand\mq{{\rm q}}


% kroucena pismenka
\newcommand\kra{{\mathscr A}}
\newcommand\krb{{\mathscr B}}
\newcommand\krc{{\mathscr C}}
\newcommand\kre{{\mathscr E}}
\newcommand\krf{{\mathscr F}}
\newcommand\krg{{\mathscr G}}
\newcommand\kri{{\mathscr I}}
\newcommand\krj{{\mathscr J}}
\newcommand\krk{{\mathscr K}}
\newcommand\krl{{\mathscr L}}
\newcommand\krm{{\mathscr M}}
\newcommand\krn{{\mathscr N}}
\newcommand\krp{{\mathscr P}}
\newcommand\krq{{\mathscr Q}}
\newcommand\krr{{\mathscr R}}
\newcommand\krs{{\mathscr S}}
\newcommand\krt{{\mathscr T}}
\newcommand\krv{{\mathscr V}}
\newcommand\krw{{\mathscr W}}
\newcommand\krx{{\mathscr X}}
\newcommand\krz{{\mathscr Z}}

\def\krL{{\mathcal L}}
\def\grad{\nabla}

\newcommand\It{{\kri_{\tau}}}

%\newcommand\GG{{\krg}}
\newcommand\Gg{g}
\newcommand\GG{G}
\newcommand\tGG{\tilde{\GG}}

\newcommand\bD{\mathrm{D}}  % Dirichlet interface BC
\newcommand\bR{\mathrm{R}}  % Robin interface BC


\newcommand\Tr{{\krt_h}}
\newcommand\Th{{\krt_h}}
\newcommand\Thi{{\krt_{h,i}}}
\newcommand\ThH{{\krt_H}}
\newcommand\Thk{{\krt_h^k}}
\newcommand\Thkk{{\krt_h^{k+1}}}
\newcommand\ThN{{\krt_h^0}}
\newcommand\Thtau{{\krt_{h,\tau}}}
\newcommand\Thm{{\krt_{h,m}}}
%%%\newcommand\TH{{\widehat T}}

\newcommand\Thh{{\krt_h^\prime}}
\newcommand\Fhh{{\krf_h^\prime}}


\newcommand\Fh{{\Gamma_h}}
\newcommand\FhI{{\Gamma_h^I}}
%%\newcommand\FhD{{\Gamma_h^D}}
\newcommand\FhD{{\Gamma_h^B}}
\newcommand\FhN{{\Gamma_h^N}}
\newcommand\FhB{{\Gamma_h^B}}
%%\newcommand\FhID{{\Gamma_h^{I\!D}}}
\newcommand\FhID{{\Gamma_h}}

\newcommand\Fhi{{\Gamma_{h,i}}}
\newcommand\Fhij{{\Gamma_{h,ij}}}
\newcommand\Fhj{{\Gamma_{h,j}}}
%%\newcommand\FhiD{{\Gamma_{h,i}^D}}
\newcommand\FhiD{{\Gamma_{h,i}^B}}
%\newcommand\FhiID{{\Gamma_{h,i}^{I\!D}}}
\newcommand\FhiID{{\Gamma_{h,i}}}
\newcommand\FhiN{{\Gamma_{h,i}^N}}
\newcommand\FhiI{{\Gamma_{h,i}^I}}



%\newcommand\Fho{{\Gamma_h^o}}
%\newcommand\Fhio{{\Gamma_h^{io}}}
%\newcommand\FhW{{\Gamma_h^W}}


\newcommand\Qhm{{\krq_{h,m}}}

% operatory
%\newcommand\div{{\rm div}}
\newcommand\rot{{\rm rot}}
%\newcommand\grad{\nabla}
\newcommand\lapl{\Delta}
\newcommand\card{{\rm card}}
\newcommand\dist{{\rm dist}}
\newcommand\diam{{\rm diam}}
%\newcommand\diag{{\rm diag}}
%\newcommand\Span{{\rm span}}
\newcommand\Span{{\sf span}}
\newcommand\meas{{\rm meas}}
%\newcommand\supp{{\rm supp}}
%\newcommand\dim{{\rm dim}}
\newcommand\vni{{\rm int}}
\newcommand\tr{{\rm tr}}

%tucna pismenka
\newcommand\bnul{{\bf 0}}
\newcommand\bx{{\bf x}}
\newcommand\by{{\bf y}}
\newcommand\bo{{\bf o}}
\newcommand\bu{{\bf u}}
\newcommand\bv{{\bf v}}
\newcommand\bz{{\bf z}}
\newcommand\bZ{{\bf Z}}
\newcommand\bK{{\bf K}}
\newcommand\bI{{\bf I}}

%tucna kurziva
\newcommand\bka{\mbox{\boldmath$a$\unboldmath}}
\newcommand\bkb{\mbox{\boldmath$b$\unboldmath}}
\newcommand\bkc{\mbox{\boldmath$c$\unboldmath}}
\newcommand\bkd{\mbox{\boldmath$d$\unboldmath}}
\newcommand\bke{\mbox{\boldmath$e$\unboldmath}}
\newcommand\bkf{\mbox{\boldmath$f$\unboldmath}}
\newcommand\bkg{\mbox{\boldmath$g$\unboldmath}}
\newcommand\bkh{\mbox{\boldmath$h$\unboldmath}}
\newcommand\bki{\mbox{\boldmath$i$\unboldmath}}
\newcommand\bkm{\mbox{\boldmath$m$\unboldmath}}
\newcommand\bkn{\mbox{\boldmath$n$\unboldmath}}
\newcommand\bko{\mbox{\boldmath$o$\unboldmath}}
\newcommand\bkp{\mbox{\boldmath$p$\unboldmath}}
\newcommand\bkr{\mbox{\boldmath$r$\unboldmath}}
\newcommand\bkq{\mbox{\boldmath$q$\unboldmath}}
\newcommand\bks{\mbox{\boldmath$s$\unboldmath}}
\newcommand\bkt{\mbox{\boldmath$t$\unboldmath}}
\newcommand\bku{\mbox{\boldmath$u$\unboldmath}}
\newcommand\bkv{\mbox{\boldmath$v$\unboldmath}}
\newcommand\bkw{\mbox{\boldmath$w$\unboldmath}}
\newcommand\bkx{\mbox{\boldmath$x$\unboldmath}}
\newcommand\bky{\mbox{\boldmath$y$\unboldmath}}
\newcommand\bkz{\mbox{\boldmath$z$\unboldmath}}
\newcommand\bkA{\mbox{\boldmath$A$\unboldmath}}
\newcommand\bkB{\mbox{\boldmath$B$\unboldmath}}
\newcommand\bkC{\mbox{\boldmath$C$\unboldmath}}
\newcommand\bkD{\mbox{\boldmath$D$\unboldmath}}
\newcommand\bkF{\mbox{\boldmath$F$\unboldmath}}
\newcommand\bkG{\mbox{\boldmath$G$\unboldmath}}
\newcommand\bkH{\mbox{\boldmath$H$\unboldmath}}
\newcommand\bkI{\mbox{\boldmath$I$\unboldmath}}
\newcommand\bkJ{\mbox{\boldmath$J$\unboldmath}}
\newcommand\bkK{\mbox{\boldmath$K$\unboldmath}}
\newcommand\bkL{\mbox{\boldmath$L$\unboldmath}}
\newcommand\bkP{\mbox{\boldmath$P$\unboldmath}}
\newcommand\bkQ{\mbox{\boldmath$Q$\unboldmath}}
\newcommand\bkR{\mbox{\boldmath$R$\unboldmath}}
\newcommand\bkS{\mbox{\boldmath$S$\unboldmath}}
\newcommand\bkT{\mbox{\boldmath$T$\unboldmath}}
\newcommand\bkU{\mbox{\boldmath$U$\unboldmath}}
\newcommand\bkW{\mbox{\boldmath$W$\unboldmath}}
\newcommand\bkX{\mbox{\boldmath$X$\unboldmath}}

\newcommand\bkzeta{\mbox{\boldmath$\zeta$\unboldmath}}

\newcommand\bfzero {\bifont{0}}
\newcommand\mA{\bifont{A}}
\newcommand\tmA{\tilde{\bifont{A}}}
\newcommand\tA{\tilde{A}}
\newcommand\mM{\bifont{M}}
\newcommand\mD{\bifont{D}}
\newcommand\mR{\bifont{R}}
\newcommand\mP{\bifont{P}}
\newcommand\mI{\bifont{I}}
\newcommand\mN{\bifont{N}}
\newcommand\mT{\bifont{T}}
%\newcommand\mAi{\mA_i}
\newcommand\Ri{R_i}
\newcommand\RiT{R_i^\T}
\newcommand\RjT{R_j^\T}
\newcommand\mRi{\mR_i}
\newcommand\mRiT{\mR_i^\T}
\newcommand\mRjT{\mR_j^\T}
\newcommand\tPi{\tilde{P}_i}
\newcommand\mtPi{\tilde{\mP}_i}
\newcommand\PPi{P_i}
\newcommand\mPP{\mP}
\newcommand\mPPi{\mPP_i}

\newcommand\RN{R_0}
\newcommand\RNT{R_0^\T}
\newcommand\mRN{\mR_0}
\newcommand\mRNT{\mR_0^\T}
\newcommand\tPN{\tilde{P}_0}
\newcommand\mtPN{\tilde{\mP}_0}
\newcommand\PPN{P_0}
\newcommand\mPPN{\mP_0}

\newcommand\add{\mathrm{add},2}
\newcommand\adj{\mathrm{add},1}
\newcommand\Padd{P_{\add}}
\newcommand\Pad{P_{\addj}}
\newcommand\mPadd{\mP_{\add}}
\newcommand\mPad{\mP_{\adj}}
\newcommand\mNadd{\mN_{\add}}
\newcommand\mNad{\mN_{\adj}}
\newcommand\hmNMadd{\hat{\mN}_{\add}}

\newcommand\hy{\mathrm{hyb}}
\newcommand\hyb{\mathrm{hyb,S}}
\newcommand\mNhy{\mN_{\hy}}
\newcommand\mNhyb{\mN_{\hyb}}
\newcommand\mPhy{\mP_{\hy}}
\newcommand\mPhyb{\mP_{\hyb}}
\newcommand\Phyb{\P_{\hyb}}



\newcommand\R{{\mathbb R}}
\newcommand\IR{{\mathbb R}}
\newcommand\I{{\mathbb I}}
\newcommand\hK{{h_K}}
\newcommand\hKp{{h_{K'}}}
\newcommand\nng{\bkn_{\gamma}}
\newcommand\hg{h_\gamma}
\newcommand\pg{p_\gamma}

% parcialni derivace
\newcommand\pd {{\partial}}
\newcommand\pdK {\partial K}

\newcommand\dxj{\frac{\pd}{\pd x_j}}
\newcommand\dxd{\frac{\pd}{\pd x_2}}
\newcommand{\ddt}[1]{\frac{\pd{#1}}{\pd t}}
\newcommand{\dpd}[2]{\frac{\pd{#1}}{\pd {#2}}}
%\newcommand\dpd[2]{\frac{\pd#1}{\pd {#2}}}

\newcommand\dd {{\rm d}}
\newcommand\dtot{\frac{{\rm d}}{{\rm d}t}}
\newcommand\dtox{\frac{{\rm d}}{{\rm d}x}}

% integraly
\newcommand\dx{\,{\rm d}x}
\newcommand\dvx{\,{\rm d}\hat{x}}
\newcommand\dvy{\,{\rm d}\hat{y}}
\newcommand\dt{\,{\rm d}t}
\newcommand\dr{\,{\rm d}r}
\newcommand\dbx{\,{\rm d}\bx}
\newcommand\ds{\,{\rm d}\sigma}
\newcommand\dS{\,{\rm d}S}

\newcommand\Om{\Omega}
\newcommand\oOm  {\overline{\Om}}
%\newcommand\gom{{\pd\Om}}
%\newcommand\gomN{{\pd\Om_N}}
%\newcommand\gomD{{\pd\Om_D}}
\newcommand\gom{{\Gamma}}
\newcommand\gomN{{\Gamma_N}}
\newcommand\gomD{{\Gamma_D}}
%\newcommand\gomD{{\Gamma}}
\newcommand\gomP{{\Gamma^+}}
\newcommand\gomM{{\Gamma^-}}
\newcommand\gomZ{{\Gamma^0}}

\newcommand\Cn{C(\overline\Om)}
\newcommand\Cj{C^1(\overline\Om)}
\newcommand\Cd{C^2(\overline\Om)}
\newcommand\Ci{C^\infty(\overline\Om)}
\newcommand\Cin{C^\infty_0(\Om)}

\newcommand\Linf{L^{\infty}(\Om)}
\newcommand\Ldo{L^2(\Om)}
\newcommand\Ldoi{L^2(\Om_i)}
\newcommand\Lpo{L^p(\Om)}
\newcommand\Ldno{L^2_0(\Om)}
\newcommand\Ldd{L^2(\gom)}

\newcommand\Wkp[2]{W^{#1,{#2}}(\Om)}

\newcommand\Hjd{H^{\frac12}(\gom)}
\newcommand\Htd{H^{\frac32}(\gom)}
\newcommand\Hj{H^1(\Om)}
\newcommand\Hk{H^k(\Om)}
\newcommand\Hjn{H^1_0(\Om)}
\newcommand\Hd{H^2(\Om)}

\providecommand{\Homega}{H^1(\Omega)}
\providecommand{\HomegaTwoBroken}{H^2(\Omega, \mesh)}
\providecommand{\homega}{H^1_{0}(\Omega)}

\newcommand\HjTh{H^2(\Th)}
\newcommand\HdTh{H^2(\Th)}


\newcommand\NN[3]{\|{#1}\|_{{#2},{#3},\Om}^{}}
\newcommand\nn[3]{|{#1}|_{{#2},{#3},\Om}^{}}
\newcommand\N[2]{\|{#1}\|_{{#2},\Om}^{}}
\newcommand\n[2]{|{#1}|_{{#2},\Om}^{}}
\newcommand\Ng[2]{\|{#1}\|_{{#2},\gom}^{}}
%\newcommand\nng[2]{|{#1}|_{{#2},\gom}^{}}
\newcommand\norm[2]{{\left\|{#1}\right\|_{#2}^{}} }
\newcommand\snorm[2]{{\left|{#1}\right|_{#2}^{}} }
\newcommand\normP[3]{{\left\|{#1}\right\|_{#2}^{#3}} }
\newcommand\snormP[3]{{\left|{#1}\right|_{#2}^{#3}} }

\newcommand\llbracket {[\![}
\newcommand\rrbracket {]\!]}
\newcommand\dual[2]{\langle{#1},{#2}\rangle}
\newcommand\jump[1]{\llbracket{#1}\rrbracket}
%\def{\tjump}[1]{\{\!\!\{{#1}\}\!\!\}}
\newcommand\Taver[1]{\{\!\!\{{#1}\}\!\!\}}
\newcommand\aver[1]{\left\langle{#1}\right\rangle}
%\newcommand{\Lsp}[2]{({#1},{#2})_{L^2(\Omega)}}
\newcommand{\LSP}[2]{\left({#1},{#2}\right)}
\newcommand\Lsp[3]{{( {#1}, {#2} )_{#3} }}
\newcommand\LspK[2]{{( {#1}, {#2} )_{K} }}
\newcommand\Lspg[2]{{( {#1}, {#2} )_{\gamma} }}


\newcommand\nolim {}
%\newcommand\nolim {\nolimits}

\newcommand\sumK  {{ \sum\nolim_{K\in\Th}     }}
\newcommand\sumF  {{ \sum\nolim_{\gamma\in\Fh} }}
\newcommand\sumFI {{ \sum\nolim_{\gamma\in\FhI} }}
\newcommand\sumFID{{ \sum\nolim_{\gamma\in\FhID} }}
\newcommand\sumFB {{ \sum\nolim_{\gamma\in\FhB} }}
\newcommand\sumFD {{ \sum\nolim_{\gamma\in\FhD} }}
\newcommand\sumFN {{ \sum\nolim_{\gamma\in\FhN} }}

\newcommand\sumKi  {{ \sum\nolim_{K\in\Thi}    }}
\newcommand\sumFi  {{ \sum\nolim_{\gamma\in\Fhi} }}
\newcommand\sumFiI {{ \sum\nolim_{\gamma\in\FhiI}}}
\newcommand\sumFiID{{ \sum\nolim_{\gamma\in\FhiID} }}
\newcommand\sumFiB {{ \sum\nolim_{\gamma\in\FhiB} }}
\newcommand\sumFiD {{ \sum\nolim_{\gamma\in\FhiD} }}
\newcommand\sumFiN {{ \sum\nolim_{\gamma\in\FhiN} }}


\newcommand\normK[1]{\norm{{#1}}{K}}
\newcommand\normdK[1]{\norm{{#1}}{\dK}}

\newcommand\normKP[1]{\normP{{#1}}{K}{2}}
\newcommand\normdKP[1]{\normP{{#1}}{\dK}{2}}

%\newcommand\ss {{\sf s}}
%\newcommand\pp {{\sf p}}
%\newcommand\qq {{\sf q}}
%\newcommand\ss {{\bks}}
%\newcommand\pp {{\sf p}}
%\newcommand\pp {{\mathbf{p}}}
\newcommand\pp {{p}}
%\newcommand\pp {{\bf p}}
\newcommand\qq {{q}}
\newcommand\ppp {{\pp+1}}

%\newcommand\Shp {S_{h\pp}}
%\newcommand\bShp {\bkS_{h\pp}}

%% OLD VARINAT
%\newcommand\bH{\bkH} 
%\newcommand\bS{\bkS} 

%% NEW variant
\newcommand\mbH{\pmb{H}} 
\newcommand\mbS{\pmb{S}} 


%\newcommand\Shp {S_{h}^{\pp}}
%\newcommand\bShp {\mbS_{h}^{\pp}}
%\newcommand\bShpp {\mbS_{h}^{\ppp}}

%\newcommand\bShp {\mbS_{h,\pp}}

%\newcommand\Shpm {S_{h,\pp_m}^{\tau,\qq_m}}
%\newcommand\Shp {S_{h,\pp}^{\tau,\qq}}
\newcommand\Shpq {S_{h,\pp}^{\tau,\qq}}
%\newcommand\bShpq {\mbS_{h,\pp}^{\tau,q}}
\newcommand\bShpqS {\mbS_{h,\pp+1}^{\tau,\qq}}
\newcommand\bShpqT {\mbS_{h,\pp}^{\tau,\qq+1}}
\newcommand\bShpqST {\mbS_{h,\pp+1}^{\tau,\qq+1}}
\newcommand\bShpqN {\mbS_{h,\pp}^{\tau,0}}
\newcommand\bShpqJ {\mbS_{h,\pp}^{\tau,1}}


\newcommand\HHd{\mbH^2(\Om)}

%\newcommand\bHd{H^{2}(\Om,\Th)}
%\newcommand\bbHd{\mbH^{2}(\Om,\Th)}
%
\newcommand\bHj{H^{1}(\Th)}
\newcommand\bbHj{\mbH^{1}(\Th)}

\newcommand\bHd{H^{2}(\Th)}
\newcommand\bbHd{\mbH^{2}(\Th)}

\newcommand\bH{H^{s}(\Om,\Th)}
\newcommand\bbH{\mbH^{s}(\Om,\Th)}

\newcommand\bST{H^1(\It, \bbHd)} % broken space-time space

\newcommand\bHShp {H^1(\It;\bShp)}
\newcommand\bSqH {S_{\tau}^q(\It;\bbHd)}
\newcommand\bSnH {S_{\tau}^0(\It;\bbHd)}
\newcommand\bShpq {S_{\tau}^q(\It;\bShp)}
\newcommand\bShpn {S_{\tau}^0(\It;\bShp)}
\newcommand\PShpq {P_{\tau}^q(\It;\bShp)}
\newcommand\PShpN {P_{\tau}^n(\It;\bShp)}

\newcommand\bShppn {S_{\tau}^0(\It;\bShpp)}
\newcommand\bShppq {S_{\tau}^q(\It;\bShpp)}

\newcommand\bShpN {S_{\tau}^n(\It;\bShp)}
\newcommand\bShppN {S_{\tau}^n(\It;\bShpp)}


\newcommand\BQ {B_{Q}^{p,q}}

%\newcommand\Shm {S_{h,\pp_m}}
%\newcommand\Shmm {S_{h,{\pp}_{m-1}}}
%\newcommand\Shnull {S_{h,\pp_0}}

\newcommand\emp {\emptyset}
\newcommand\uht {{u_{h\tau}}}
\newcommand\uhtm {{u_{h\tau}^m}}
\newcommand\uhtmm {{u_{h\tau}^{m-1}}}
\newcommand\whmm {{w_h^{m-1}}}
%\newcommand\dof {\mathrm{dof}}
%\newcommand\dof {\bar{p}}
%\newcommand\dof {D}
\newcommand\dof {n}
\newcommand\p {^\prime}
\newcommand\ui {u_i}
\newcommand\vi {v_i}
\newcommand\uhi {u_{h,i}}
\newcommand\uhj {u_{h,j}}
\newcommand\vhi {v_{h,i}}
\newcommand\uil {u_{il}}
\newcommand\ujm {u_{jm}}


%\newcommand\a {^{\ast}}

%\newcommand\W {\bkW}
\newcommand\W {\mbox{\boldmath$\xi$}}
\newcommand\w {\bkw}
\newcommand\wht {{\w_{h\tau}}}
\newcommand\whk {{\w_{h}^k}}
\newcommand\twht {{\tilde{\w}_{h\tau}}}
\newcommand\wtk {{\w_{\tau}^k}}
\newcommand\twhk {{\tilde{\w}_{h}^k}}
\newcommand\bw {\bar{\w}_{h\tau}}
\newcommand\bwt {\bar{\w}_{\tau}}
%\newcommand\tbw {\tilde{\bar{\w}}_{h\tau}}
\newcommand\tbw {\bar{\tilde{\w}}_{h\tau}}

\newcommand\f {\bkf}
\newcommand\K {\bK} %{\bkK}
\newcommand\cK {\mathcal{K}}
\newcommand\A {\bkA}
\newcommand\PP {\bkP}

%\newcommand\cA {\kra}
\newcommand\cA {\mathcal{A}}
\newcommand\Ah {\cA_h}
\newcommand\tAh {\tilde{\cA}_h}
\newcommand\Ahi {\cA_{h,i}}
\newcommand\AhN {\cA_{h,0}}
\newcommand\AhDi {\cA_{h,i}^{\bD}}
\newcommand\AhRi {\cA_{h,i}^{\bR}}
\newcommand\tAhDi {\tilde{\cA}_{h,i}^{\bD}}
\newcommand\tAhRi {\tilde{\cA}_{h,i}^{\bR}}
\newcommand\tAhi {{\tilde{\cA}_{h,i}}}
\newcommand\tgi {{\tilde{\bkg}_{i}}}

\newcommand\Aht {\bkA_{h\tau}}
\newcommand\bAht {\overline{\bkA}_{h\tau}}
\newcommand\Bh {\mathcal{B}_h}
\newcommand\Bhi {\mathcal{B}_{h,i}}
\newcommand\Bhj {\mathcal{B}_{h,j}}
%\newcommand\Bt {\bkB_{\tau}}
\newcommand\Btk {\bkA_{h\tau}^k}

\newcommand\vb { {\bkb}} 
\newcommand\vf { {\vec{f}}} 
\newcommand\vR { {\vec{R}}} 
\newcommand\vK { {\vec{K}}} 
%\newcommand\ipg {{\theta}}
\newcommand\ipg {{\rm g}}

\newcommand\ah {{a_h}}
\newcommand\ahi {{a_{h,i}}}
\newcommand\ahDi {{a_{h,i}^\bD}}
\newcommand\tahRi {{\tilde{a}_{h,i}^\bR}}
\newcommand\tahDi {{\tilde{a}_{h,i}^\bD}}
\newcommand\ahRi {{a_{h,i}^\bR}}
\newcommand\tah {{\tilde{a}_h}}
\newcommand\bh {{b_h}}
\newcommand\bhi {{b_{h,i}}}
%\newcommand\lh {{\ell_h}}
%\newcommand\lhi {{\ell_{h,i}}}
\newcommand\lh {{g_h}}
\newcommand\lhi {{g_{h,i}}}
\newcommand\lhDi {{g_{h,i}^\bD}}
\newcommand\lhRi {{g_{h,i}^\bR}}
\newcommand\tlhDi {{\tilde{g}_{h,i}^\bD}}
\newcommand\tlhRi {{\tilde{g}_{h,i}^\bR}}
\newcommand\lhDij {{{g}_{h,ij}^\bD}}
\newcommand\lhRij {{{g}_{h,ij}^\bR}}
\newcommand\tlhDij {{\tilde{g}_{h,ij}^\bD}}
\newcommand\tlhRij {{\tilde{g}_{h,ij}^\bR}}

\newcommand\tbh {{\tilde{b}_h}}
\newcommand\ch {{c_h}}
\newcommand\tch {{\tilde{c}_h}}
%\newcommand\tuh {{\tilde{u}_h}}
\newcommand\tu {{\tilde{u}}}
%\newcommand\dh {{d_h}}

\newcommand\bah {{\bka_h}}
\newcommand\bbh {{\bkb_h}}
\newcommand\bch {{\bkc_h}}
\newcommand\bchL {{\bkc_h^L}}
\newcommand\bdh {{\bkd_h}}
\newcommand\bJh {{\bkJ_h^{\sigma}}}

\newcommand\T{{\intercal}}
\newcommand\TT {{\rm T}}
\newcommand\bF {{\bar{F}}}

\newcommand\F {\bkF}
\newcommand\bFF {{\bar{\F}}}
\newcommand\U {{\bkU}}
\newcommand\G {{\bkG}}
\newcommand\Q {{\bkQ}}
\newcommand\D {{\bkD}}
\newcommand\bkdh {{\bkq_h}}
\newcommand\tbkd {\mbox{\boldmath$\delta$\unboldmath}}

\newcommand{\DOF} {{\sf dof}}

\newcommand{\DoF} {{\mathrm{DoF}}}

\newcommand{\LRP} {{LRP}}

\newcommand{\CFP} {{\sf CFP}}
\newcommand{\sCFP} {{\sf sCFP}}

%\newcommand{\res} {\mbox{\rm res}}
%\newcommand{\res} {{\cal R}}

\newcommand{\Tau} {{\bkt}}
\newcommand{\Rey} { \mbox{Re} }
\newcommand{\Pra} { \mbox{Pr} }

\newcommand\ve {\varepsilon}
\newcommand{\bve}{\bm\varepsilon}

% NEW variant

\newcommand{\va} {\pmb{\varphi}}
%\newcommand{\vp} {\pmb{\varphi}}
\newcommand{\vp} {{\varphi}}
\newcommand{\vas} {\varphi}
\newcommand{\bpsi} {\pmb{\psi}}
\newcommand{\bbpsi} {\bar{\pmb{\psi}}}
\newcommand{\balpha} {\pmb{\alpha}}

%%% OLD variant
%\newcommand{\va} {\mbox{\boldmath $\varphi$}}
%\newcommand{\vp} {\mbox{\boldmath $\varphi$}}
%\newcommand{\vas} {\varphi}
%\newcommand{\bpsi} {\mbox{\boldmath$\psi$}}
%\newcommand{\bbpsi} {\bar{\mbox{\boldmath$\psi$}}}
%\newcommand{\balpha} {\mbox{\boldmath$\alpha$}}



\newcommand{\cV} {{\cal V}}
\newcommand{\BC} {{\cal B}}
\newcommand{\io} {io}

%%\newcommand\qed {{$\hfill\Box$}}
\newcommand\vv {\bkv}
\newcommand\pr {\pi}
\newcommand\etaA {\eta_{\rm A}}
\newcommand\etaS {\eta_{\rm S}}
\newcommand\etaT {\eta_{\rm T}}
\newcommand\etaST {\eta_{\rm ST}}
\newcommand\etaAk {\eta_{\rm A}^k}
\newcommand\etaSk {\eta_{\rm S}^k}
\newcommand\etaTk {\eta_{\rm T}^k}
\newcommand\etaSTk {\eta_{\rm ST}^k}
\newcommand\etaAkK {\eta_{\rm A}^{k,K}}
\newcommand\etaSkK {\eta_{\rm S}^{k,K}}
\newcommand\etaTkK {\eta_{\rm T}^{k,K}}
\newcommand\etaSTkK {\eta_{\rm ST}^{k,K}}
\newcommand\etas {\eta_\star}
\newcommand\etask {\eta_\star^k}
\newcommand\etaskK {\eta_\star^{k,K}}

\newcommand\err {\kre}
\newcommand\errST {\kre^{ST}}
\newcommand\errT  {\kre^{T}}
\newcommand\errS  {\kre^{S}}
\newcommand\errA  {\kre^{A}}

\newcommand\errX  {\norm{e_{h\tau}}{1}}
\newcommand\errY  {\norm{e_{h\tau}}{0}}

\newcommand{\afrac}[2]{\genfrac{}{}{0pt}{2}{#1}{#2}}

\newcommand\Vh {V_h}
\newcommand\hp {h{\pp}}
%\newcommand\hp {{hp}}
\newcommand\Shp {S_{h}}%^{\pp}}
\newcommand\Shpp {S_h}%^{\ppp}}
\newcommand\Ship {S_{h,i}}%^{\pp}}
\newcommand\Shjp {S_{h,j}}%^{\pp}}
\newcommand\SHP {S_{h,0}}%^{\pp}}
\newcommand\SHHP {S_{H}}%^{\qq}}

\newcommand\uhp {u_{\hp}}
\newcommand\ehp {e_{\hp}}
\newcommand\Thp {\krt_{\hp}}
\newcommand\ThpN {\krt_{\hp}^N}
%\newcommand\ThN {\krt_{h}^N}
%\newcommand\rh {\Pi_{\hp}}

\newcommand\barx {{\bar{x}}}


%\newcommand\rhK {\pi_{x_K,p_K}}
\newcommand\Rh {\Pi_{\hp}}
\newcommand\Nhp {N_{\hp}}
\newcommand\eh {e_{h}}

%\newcommand\cM {{\krm}}   % metric
%\newcommand\cM {{\mM}}   % metric
%\newcommand\cM {{\bf M}}   % metric
\newcommand\e {{\bke}}
\newcommand\Fp   {{\Phi}}
\newcommand\cM {{\mathcal{M}}} 
\newcommand\vps {{\varphi}}
%\newcommand\vpp {{\varphi_{p}}}
%\newcommand\Ap  { A_{p} }
%\newcommand\Apq  {{ A_{p}^{2}}}
\newcommand\Apbot  {{ A_{p}^{\bot} }}
\newcommand\xip  {{ \xi_{p} }}
\newcommand\xibot  {{ \xi_{p}^{\bot} }}
%\newcommand\rop  {{ \rho_{p} }}

\newcommand\Apl  {{ A_{p}^{(l)} }}
\newcommand\ropl  {{ \rho_{p}^{(l)} }}

\newcommand\barp {{\bar{p}}}


\newcommand\DegpD {2\Deg}

\newcommand\vpt {{\tilde{\varphi}_{p}}}
\newcommand\At  {{ \tilde{A}_{p} }}
\newcommand\Atbot  {{ \tilde{A}_{p}^{\bot} }}
\newcommand\xit  {{ \tilde{\xi}_{p} }}
\newcommand\xitbot  {{ \tilde{\xi}_{p}^{\bot} }}
\newcommand\rhot  {{ \tilde{\rho}_{p} }}


\newcommand\vpj {{\varphi_{1}}}
\newcommand\Aj  {{ A_{1} }}
\newcommand\Ajbot  {{ A_{1}^{\bot} }}
\newcommand\xij  {{ \xi_{1} }}
\newcommand\xijbot  {{ \xi_{1}^{\bot} }}
\newcommand\roj  {{ \rho_{1} }}

\newcommand\ro  {{ \rho^{-\frac{2}{p+1}} }}
%\newcommand\ropp  {{ \rho_{p}^{-\frac{2}{p+1}} }}
\newcommand\ropP  {{ \rho_{p}^{\,\frac{1}{p+1}} }}
\newcommand\ropPh  {{ \rho_{p}^{\,\frac{2}{p+1}} }}
\newcommand\ropM  {{ \rho_{p}^{-\frac{1}{p+1}} }}
\newcommand\ropMA  {{ \rho_{p}^{-\frac12} }}
\newcommand\ropPA  {{ \rho_{p}^{\, \frac12} }}
\newcommand\ropQP  {{ \rho_{p}^{\, \frac{q}{2}} }}
\newcommand\ropQM   {{ \rho_{p}^{ -\frac{q}{2}} }}
%\newcommand\ro  {{ \rho^{-2/(p+1)} }}
%\newcommand\ropp  {{ \rho_{p}^{-2/(p+1)} }}
%\newcommand\ropP  {{ \rho_{p}^{1/(p+1)} }}
%\newcommand\ropPh  {{ \rho_{p}^{2/(p+1)} }}
%\newcommand\ropM  {{ \rho_{p}^{-1/(p+1)} }}
%\newcommand\ropMA  {{ \rho_{p}^{-1/2} }}
%\newcommand\ropPA  {{ \rho_{p}^{ 1/2} }}
%\newcommand\ropPAq  {{ \rho_{p}^{ q/2} }}


%\newcommand\ro  {{ \rho^{-1} }}
%\newcommand\ropp  {{ \rho_{p+1}^{-1} }}
%\newcommand\ropP  {{ \rho_{p+1}^{1/2} }}
%\newcommand\ropM  {{ \rho_{p+1}^{-1/2} }}




%\newcommand\EIp  {{E_{\rm I}^{p}}}
\newcommand\EIj  {{{e}_{\barx,1}^{\rm int}}}
\newcommand\EIpx  {{{e}_{{x},p}^{\rm int}}}
\newcommand\EIpK  {{{e}_{x_K,p_K}^{\rm int}}}
\newcommand\EIK  {{{e}_{x_K,p}^{\rm int}}}
\newcommand\mg  {{\bar{g}}}
\newcommand\mmG  {{\bar{\mG}}}
\newcommand\Sym {{\rm Sym}}
\newcommand\cN {{{N}}}

\newcommand\TOL {{{\omega}}}
\newcommand\tol {{\bar{\omega}}}
\newcommand\vol {{\bar{\nu}}}
%\newcommand\volE {{{\nu}_E}}
\newcommand\volE {{{\nu}_{\barx,p}}}
\newcommand\volEp {{{\nu}_{\barx,\bar{p}}}}
\newcommand\xix {{\zeta}}
\newcommand\xixt {{\tilde{\zeta}}}
\newcommand\Ke  {{K}}
\newcommand\Kxp  {{K_{\barx,p}}}


\def \e {{e_h}} 
\def \eDual {{e_h^*}}
\def \u {{u}} 
\def \z {{z}} 
\def \uh {u_h}
\def \uH {u_H}
\def \tuH {\tilde{u}_H}
\def \wh {w_h}
\def \wH {w_H}
\def \twH {\tilde{w}_H}
\def \zh {{z_h}}
\def \uhk {{u_h^k}}
\def \tuh {{\tilde{u}_h}}
\def \tuhk {{\tilde{u}_h^k}}
\def \tuhN {{\tilde{u}_h^0}}

\def \zhk {{z_h^k}}
\def \tzh {{\tilde{z}_h}}
\def \tzhk {{\tilde{z}_h^k}}
\def \tzhN {{\tilde{z}_h^0}}
\def \Proj{\Pi}
\def \Ptuh {{\Proj\tilde{u}_h}}
\def \Ptzh {{\Proj\tilde{z}_h}}
\def \Rtuh {{P\tilde{u}_h}}
\def \Rtzh {{P\tilde{z}_h}}

\providecommand{\resu}[1]{r_h(\u)(#1) }
\providecommand{\res}[1]{r_h(\uh)(#1) }
\providecommand{\resD}[1]{r_h^*(\zh)(#1) }

\providecommand{\resK}[1]{r_K(u_h)(#1) }
\providecommand{\resKD}[1]{r_K^*(\zh)(#1) }


\providecommand{\intkk}[1]{\int_{K}#1\dx} 
\providecommand{\intx}[4]{\int\limits_{#1}^{#2}#3\,\mathrm{d}#4} 
\providecommand{\intX}[4]{\int_{#1}^{#2}#3\,\mathrm{d}#4} 
\providecommand{\inte}[1]{\int_{\gamma}#1\dS} 
\providecommand{\intS}[2]{\int_{#1}#2\dS} 
\providecommand{\JhSigma}[2]{ J_h^{\sigma}(#1,#2)}
\providecommand{\JhSigmai}[2]{ J_{h,i}^{\sigma}(#1,#2)}
\providecommand{\JhSigmaDi}[2]{ J_{h,i}^{\sigma,\bD}(#1,#2)}
\providecommand{\JhSigmaRi}[2]{ J_{h,i}^{\sigma,\bR}(#1,#2)}

%\providecommand{\bcD}{ \Gamma_{D}}
%\providecommand{\bcN}{ \Gamma_{N}}
%\providecommand{\bcZero}{ \Gamma_{0}}
%\providecommand{\bcMinus}{ \Gamma_{-}}
%\providecommand{\bcPlus}{ \Gamma_{+}}

\newcommand\restr[2]{{% we make the whole thing an ordinary symbol
  \left.\kern-\nulldelimiterspace % automatically resize the bar with \right
  #1 % the function
  \vphantom{\big|} % pretend it's a little taller at normal size
  \right|_{#2} % this is the delimiter
  }}

\newcommand\pK{p_K}
\newcommand\pKp{p_{K'}}
\newcommand\qK{q_{\cK}}
%\newcommand\dK{{d_K}}
\newcommand\dK{{\pd K}}
\newcommand\di{{d_i}}
\newcommand\dvK{{\pd \hat{K}}}
\newcommand\dvE{{\pd \hat{E}}}
\newcommand\RV{{r_{K,\mathrm{V}}}}
\newcommand\RB{{r_{K,\mathrm{B}}}}
\newcommand\RD{{r_{K,\mathrm{D}}}}

\newcommand\RVD{{r^*_{K,\mathrm{V}}}}
\newcommand\RBD{{r^*_{K,\mathrm{B}}}}
\newcommand\RDD{{r^*_{K,\mathrm{D}}}}

%%% VARIANT eta^I and eta^II
%% \newcommand\EKI{{\eta_{K}^{\mathrm{I}}}}
%% \newcommand\EKII{{\eta_{K}^{\mathrm{I\!I}}}}
%% \newcommand\EKIIB{{\bar{\eta}_{K}^{\mathrm{I\!I}}}}
%% \newcommand\EE{{\eta^{\mathrm{I\!I}}}}
%% \newcommand\EEN{{\eta^{\mathrm{I\!I}}_0}}
%% \newcommand\EEk{{\eta^{\mathrm{I\!I}}_k}}

%%% VARIANT only eta = eta^II
%\newcommand\EKI{{\eta_{K}^{\mathrm{I}}}}
\newcommand\EKII{{\eta_{K}}}
\newcommand\EKIIB{{\bar{\eta}_{K}}}
\newcommand\EE{{\eta_h}}
\newcommand\EEN{{\eta_{h,0}}}
\newcommand\EEk{{\eta_{h,k}}}


\newcommand\EV{R_{K,\mathrm{V}}}
\newcommand\EB{R_{K,\mathrm{B}}}
\newcommand\ED{R_{K,\mathrm{D}}}
\newcommand\EVD{R^*_{K,\mathrm{V}}}
\newcommand\EBD{R^*_{K,\mathrm{B}}}
\newcommand\EDD{R^*_{K,\mathrm{D}}}

\newcommand\WV{\theta_{K,\mathrm{V}}}
\newcommand\WB{\theta_{K,\mathrm{B}}}
\newcommand\WD{\theta_{K,\mathrm{D}}}
\newcommand\WVD{\theta^*_{K,\mathrm{V}}}
\newcommand\WBD{\theta^*_{K,\mathrm{B}}}
\newcommand\WDD{\theta^*_{K,\mathrm{D}}}

\newcommand\fun{w}
\newcommand\Deg{p}
%\newcommand\DegK{p_K}
\newcommand\DegK{p}
\newcommand\Degp{\bar{p}}
\newcommand\Degq{q}
\newcommand\bmA{\bar{\matA}}
\newcommand\bmG{\bar{\matG}}
\newcommand\tmG{\tilde{\mG}}
\newcommand\EIp  {{{\fun}_{\barx,\Deg}^{\rm int}}}
\newcommand\rh {\Pi_{\barx,\Deg}}
\newcommand\rhK {\Pi_{x_K,\Deg}}

%%% generic function
\newcommand\Ap  {{ A_{\fun} }}
\newcommand\Apq  {{ A_{\fun}^{2}}}
\newcommand\rop  {{ \rho_{\fun} }}
\newcommand\ropp  {{ \rho_{\fun}^{-\frac{2}{\Deg+1}} }}
\newcommand\ropq  {{ \rho^{-{2}/{\Degq_2}} }}

\newcommand\vpp {{\varphi_{\fun}}}

%%%  generic function  -- its gradient
\newcommand\vppD {{ \tilde{\varphi}_{\fun}}}
\newcommand\ApD  { \tilde{A}_{\fun} }
\newcommand\ropD  {{ \tilde{\rho}_{\fun} }}

%%% primal solution
\newcommand\prim{\u}
\newcommand\vpu {{ {\varphi}_{\prim}}}
\newcommand\Au  { {A}_{\prim} }
\newcommand\Auq  { {A}_{\prim}^2 }
\newcommand\rou  {{ {\rho}_{\prim} }}

\newcommand\vpuD {{ \tilde{\varphi}_{\prim}}}
\newcommand\AuD  { \tilde{A}_{\prim} }
\newcommand\rouD  {{ \tilde{\rho}_{\prim} }}

%%% dual solution

\newcommand\dua{\z}
\newcommand\vpz {{ {\varphi}_{\dua}}}
\newcommand\Az  { {A}_{\dua} }
\newcommand\Azq  { {A}_{\dua}^2 }
\newcommand\roz  {{ {\rho}_{\dua} }}

\newcommand\vpzD {{ \tilde{\varphi}_{\dua}}}
\newcommand\AzD  { \tilde{A}_{\dua} }
\newcommand\rozD  {{ \tilde{\rho}_{\dua} }}



\newcommand\Fun{\mu}
%\newcommand\Aq  {{ A_{\Degq} }}
%\newcommand\roq  {{ \rho_{\Degq} }}
%\newcommand\vpq {{\varphi_{\Degq}}}
%\newcommand\roDeg  {{ \rho_\Degq^{-{2}/{\Degq}} }}
\newcommand\Aq  {{ A }}
\newcommand\roq  {{ \rho }}
\newcommand\vpq {{\varphi}}
\newcommand\roDeg  {{ \rho^{-{2}/{\Degq}} }}

%\newcommand\ropp  {{ \rho_{p}^{-\frac{2}{\Deg+1}} }}

\newcommand\lambarK{{\lambda}_K}
%\newcommand\lambarK{\bar{\lambda}_K}
\newcommand\mIPG{{\theta}}

\newcommand\ND{{\krn}} %_\mathrm{D}}}
\newcommand\NKD{{\krn_{K}}}%,\mathrm{D}}}}

\newcommand\DD[2]{ \mD_{{#1}}^{{#2}}}

\newcommand\errV{{ e_{\sigma,\phi}^{\mathrm{v},q}}}
\newcommand\errB{{ e_{\sigma,\phi}^{\mathrm{b},q}}}
\newcommand\errD{{ e_{\sigma,\phi}^{\mathrm{g},q}}}

\newcommand\estV{{ \ve_{\sigma,\phi}^{\mathrm{v},q}}}
\newcommand\estB{{ \ve_{\sigma,\phi}^{\mathrm{b},q}}}
\newcommand\estD{{ \ve_{\sigma,\phi}^{\mathrm{g},q}}}

\newcommand\ieffV{{ I_{\sigma,\phi}^{\mathrm{v},q}}}
\newcommand\ieffB{{ I_{\sigma,\phi}^{\mathrm{b},q}}}
\newcommand\ieffD{{ I_{\sigma,\phi}^{\mathrm{g},q}}}
\newcommand\ieffX{{ I_{\sigma,\phi}^{\mathrm{X},q}}}
\newcommand\ieffM{  M_{\sigma}^{\mathrm{X}, q} }
\newcommand\ieffm{  m_{\sigma}^{\mathrm{X}, q} }


%\newcommand \st{\hspace{-7pt}$\star$\,}
\newcommand \st{}
\newcommand\plus{^{\scriptscriptstyle (+)}}
\newcommand\minus{^{\scriptscriptstyle (-)}}
\newcommand\bkbnp {\bkb_{\bkn}^{\scriptscriptstyle (+)}}
\newcommand\bkbnm {\bkb_{\bkn}^{\scriptscriptstyle (-)}}
\newcommand\NS {N_S}
\newcommand\rrel {r_{\mathrm{rel}}}


\newcommand\fac{\mathrm{fac}}
\newcommand\ass{\mathrm{ass}}
\newcommand\fl {\mathsf{fl}}
\newcommand\flfac {\fl_{\fac}}
\newcommand\flass {\fl_{\ass}}
\newcommand\FFfac {\mathsf{Fl}_{\fac}}
\newcommand\FFass {\mathsf{Fl}_{\ass}}
\newcommand\Fl {\mathsf{flops}}
\newcommand\MFl {\mathsf{Mflops}}

%\newcommand\iter {k_{\mathrm{it}}}
\newcommand\iter {\mathsf{iter}}
\newcommand\iterN {\iter_{\mathrm{N}}}
\newcommand\iterL {\iter_{\mathrm{L}}}
\newcommand\comm {\mathsf{com}}
\newcommand\Mcomm {\mathsf{Mcom}}



% TOMAS ; Kdyztak prepis
\newcommand{\Ldk}{L^2(\partial\cK)}
\newcommand{\dg}{\vert \! \vert \! \vert}
\newcommand{\HTh}{H^1(\Th)}
\newcommand{\Lf}{L^2(\gamma)}
\newcommand{\Co}{C_0^2}
\newcommand{\vh}{v_h}
\newcommand{\vhh}{v_H}
%\newcommand{\dx}{\, \mathrm{d}x}
%\newcommand{\ds}{\, \mathrm{d}S}
\newcommand{\Grh}{\mathscr{G}_h}
\newcommand{\lift}{l_\gamma}
\newcommand{\sumck}{\sum_{\cK \in \Th}}
%\newcommand{\sumfhI}{\sum_{\gamma \in \FhI}}
%\newcommand{\sumfh}{\sum_{\gamma \in \Fh}}
\newcommand{\sumfhI}{\sumFI}
\newcommand{\sumfh}{\sumF}
\newcommand{\Lt}[1]{L^2({#1})}
\newcommand{\ngam}{\bm{n}_\gamma}
\newcommand{\cW}{c_W}
\newcommand{\hh}[1]{\mathcal{H}({#1})}
\newcommand{\projad}{\sum_{i=1}^{N}T_i}
\newcommand{\HH}{{H}}
\newcommand{\bss}{{\HH^s(\Th)}}
\newcommand{\bsj}{{\HH^1(\Th)}}
\newcommand{\bsd}{{\HH^2(\Th)}}
\newcommand{\hsn}[1]{\vert {#1} \vert_{\HH^1(\Th)}}
\newcommand{\sbar}{\overline{\sigma}}



%%% Local Variables: 
%%% mode:latex
%%% TeX-master: "paper"
%%% End: 


%\usepackage{jabbrv}



%% % Language setting
%% % Replace `english' with e.g. `spanish' to change the document language
%% \usepackage[english]{babel}

%% % Set page size and margins
%% % Replace `letterpaper' with `a4paper' for UK/EU standard size
%% %\usepackage[letterpaper,top=2cm,bottom=2cm,left=3cm,right=3cm,marginparwidth=1.75cm]{geometry}
%% \usepackage{a4wide}
%% % Useful packages
%% \usepackage{amsmath}
%% \usepackage{amsthm}
%% \usepackage{amssymb}
%% \usepackage{graphicx}
%% \usepackage{mathrsfs}
%% \usepackage{bm}             % boldface symbols (\bm)
%% \usepackage{enumitem}
%% \setlist[enumerate]{noitemsep, topsep=5pt}
%% \setlist[itemize]{noitemsep, topsep=5pt}

%% \usepackage{algorithmic}
%% \usepackage[colorlinks=true, allcolors=blue]{hyperref}

%% \usepackage{setspace}
%% \usepackage{algorithmic}
%% \usepackage[linesnumbered,ruled]{algorithm2e}
%% \usepackage{rotating}

%% \usepackage{fancyhdr}
%% \usepackage{datetime}
%% %\fancyhf{}
%% %\fancyfoot[L]{\today\ \currenttime}
%% \fancyhead[L]{\today\ \currenttime}
%% \pagestyle{fancy}

\usepackage[dvipsnames]{xcolor}
\newcommand{\vit}[1]{{\color{red}{#1}}}
%\newcommand{\vit}[1]{{{#1}}}
\newcommand{\Vit}[1]{{\color{blue}{VD:} \color{blue}{#1}}}
%\newcommand{\smaz}[1]{{\color{blue}{SMAZ:} \color{brown}{#1}}}
\newcommand{\smaz}[1]{} 
\newcommand{\tom}[1]{{\color{magenta}{#1}}}

\usepackage[scientific-notation=true]{siunitx} %VVV
\sisetup{round-mode = places, round-precision = 3} %VVV
\newcommand{\numm}[1]{\num{#1}}
\newcommand{\numf}[1]{\num[round-mode=places, scientific-notation=false, round-precision=0]{#1}}


%\title{Hybrid Schwarz preconditioners for linear systems arising from
%  $hp$-discontinuous Galerkin method}
%\author{V. Dolej{\v s}{\'\i}, Tom{\'a}{\v s} Hammerbauer}

\begin{document}
\maketitle

\begin{abstract}
  We deal with the numerical solution of elliptic problems by
  the $hp$-discontinuous Galerkin method.
  We develop a two-level hybrid Schwarz preconditioner for the arising linear algebraic systems.
  The preconditioner is additive with respect to the local components and multiplicative
  with respect to the mesh levels. 
  We derive the $hp$ spectral bound of the preconditioned operator in the form $O((H/h)(p^2/q))$,
  where $H$ and $h$ are the element sizes
  of the coarse and fine meshes, respectively, and $p$ and $q$ are the polynomial approximation
  degrees on the fine and coarse meshes. Further, we present a numerical study
  showing that the hybrid Schwarz preconditioner dominates the additive one
  from the point of view of the speed of convergence and also
  computational costs. Finally, the combination with
  a $hp$-mesh adaptation for the solution of nonlinear problem demonstrates the potential
  of this approach.
\end{abstract}

% REQUIRED
%\begin{keywords}
{\bf Keywords:}
discontinuous Galerkin, two-level hybrid Schwarz preconditioner, $hp$-adaptation
%\end{keywords}

% REQUIRED
%\begin{MSCcodes}
{\bf MSCcodes:}
65N55, 65N30, 65N50
%\end{MSCcodes}

\section{Introduction}
\label{sec:intro}

The discontinuous Galerkin (DG) method \cite{PietroErn2012,DGM-book}
exhibits a powerful technique for the
numerical solution of partial differential equations. 
In particular, the piecewise polynomial discontinuous approximation is well suited
for $hp$-mesh adaptation which exhibits an excellent strategy for problems with
local singularities, material interfaces, and it
gives, under some assumption, an exponential rate of convergence.
On the other hand, the DG discretization leads to larger (but sparser)  algebraic systems
in comparison to conforming finite element methods.

Therefore, a development of efficient iterative solvers is demanding.
Among many techniques,
a prominent role is played by the {\em domain decomposition} (DD)  methods
\cite{QuarteroniValli00,Nataf-DDM,ToselliWidlund-DD05,Gander_ETNA08}
which can use the power of multiprocessor computers.
The main idea is to divide the global problem into several subproblems
(based on the decomposition of the computational domain) and solve them 
independently. The transfer of information among the subproblems 
can be accelerated by considering a global (coarse) problem.
More frequent approach is the use of the DD techniques as preconditioners
for Krylov space iterative methods, such as the conjugate gradient method.

The domain decomposition techniques
for discontinuous Galerkin approximations were considered
in many works, let us mention 
\cite{Karashian2001,AntoniettiAyuso_M2NA07,AntoniettiALL_JSC14,AntoniettiALL_MC20,PaznerKolev_CAMC22,GopalakrishnanKanschat_23}, 
further paper \cite{AntoniettiAyuso_CCP09} related to super-penalty DG technique, 
works \cite{GanderHajian_SINUM14,GanderHajian_MC18,BarrenecheaALL_CMAM19}
dealing with hybridizable DG methods, and
papers
\cite{Canuto-2013-BPC,Kim-2014-BAC,Tu-2021-BAA,Dryja-2007-DGD}
related to
balancing domain decomposition by constraints (BDDC) variants of domain decomposition.
In particular, we mention papers
\cite{AntoniettiHouston_JSC11,AntoniettiALL_IJNAM16}  analyzing the two-level
non-overlapping additive and multiplicative Schwarz preconditioners.
%In \cite{AntoniettiALL_IJNAM16},
%the authors derived the $hp$ spectral bounds of the
%two-level nonoverlapping additive Schwarz preconditioner and
%in
%the form $O((H/h)(p^2/q))$, where $H$ and $h$ are the element sizes
%of the coarse and fine meshes, respectively, and $p$ and $q$ are the polynomial approximation
%degrees on the fine and coarse meshes, respectively.
%these bounds were numerically justified in \cite{AntoniettiHouston_JSC11}.
See also \cite{DryjaKrzyzanowski_NM16,Krzyzanowski_NMPDE16}
containing an alternative approach when the
coarse mesh is created by several subdomains treated in parallel. 

In contrary to conforming finite element methods (FEM), the advantage of
non-overlapping discontinuous Galerkin domain decomposition approach is
that each degree of freedom belongs to only one subdomain,
any specific operator at subdomain interfaces need not to be
constructed and the coarse operator is defined using the same variational formulation
as the original problem.


In this paper, we introduce the {\em two-level non-overlapping hybrid Schwarz} technique
proposed in \cite{Mandel_94} for FEM,
when the preconditioner operator is additive with respect to the local components and multiplicative
with respect to the mesh levels. 
The hybrid Schwarz technique was used in various applications, for example
\cite{BarkerCai_SISC10,Scacchi_CMAME08,HeinleinLanser_SISC20}.
%%in \cite{Dolean2001287} for the numerical solution
%%of the compressible Navier-Stokes equations, 
%in \cite{BarkerCai_SISC10}  for fluid-structure interaction problems, and
%in \cite{Scacchi_CMAME08} for numerical simulation of the electrical activity of the heart, 
%for example.
%In addition, hybrid methods were studied in \cite{HeinleinLanser_SISC20} in
%the context of nonlinear domain decomposition techniques.

We present the discretization of a linear elliptic problem using the symmetric
interior penalty Galerkin (SIPG) method. Assuming a suitable indexing of mesh elements,
the one-level additive Schwarz method is equivalent to the block Jacobi iterative method.
Then we introduce the two-level additive and hybrid Schwarz methods, and adapting the techniques
from \cite{AntoniettiALL_IJNAM16}, we derive the $hp$ spectral bound of the
two-level non-overlapping hybrid Schwarz preconditioner which is the first novelty of this paper.

Moreover, we present a detailed numerical study of the convergence of the conjugate
gradient (CG) method with the two-level additive and hybrid Schwarz preconditioners.
The aim is to achieve the {\em weak scalability} of the solver, namely
the number of iterations of the algebraic solver does not increase when the size
of sub-problems is kept fixed. Additionally, we compare both preconditioners from the
point of view of the number of floating point operations and number of communications among
the computer cores.

Finally, the potential of both techniques is demonstrated by numerical solution of a nonlinear elliptic equation
in combination with a mesh adaptation. In particular, the arising nonlinear algebraic system is
solved by the Newton method and at each Newton step, the corresponding linear system is solved
by CG with the presented preconditioners. The mesh adaptation is carried out by
the {\em anisotropic $hp$-mesh adaptation} technique from \cite{AMA-book}, which serves as a test
of the robustness of the hybrid and additive preconditioners with respect to $hp$-adaptation
and the anisotropy of the mesh elements.

The rest of the paper is the following.
In Section~\ref{sec:DGM}, we introduce the SIPG discretization of the model problem.
%and recall several technical results.
In Section~\ref{sec:DDM}, we introduce the
two-level hybrid Schwarz preconditioner and in Section~\ref{sec:anal} we derive the corresponding
spectral bound. The numerical study demonstrating the performance of the additive and hybrid preconditioners is given in Section~\ref{sec:numer}.
Several concluding remarks are given in Section~\ref{sec:concl}.


\section{Problem definition}
\label{sec:DGM}

In the following, we use the standard notation for the Lebesgue space $L^2(\Om)$, the Sobolev space $H^{k}(\Om) = W^{k,2}(\Om)$, and $P^p(M)$ is the space of polynomials of degree at most $p$ on
$M \subset \R^d$.  
Moreover, we use the notation
\begin{align}
  \label{Lsp}
  \Lsp{u}{v}{M}&=\int_M u\, v \dx\qquad \mbox{ for } M \subset \R^s,\ s=1,\dots, d.
\end{align}


Let $\Om \in \R^d$, $d=2,3$ be a bounded polygonal domain with Lipschitz boundary $\gom:=\pd\Om$.
%having two disjoint parts $\gomD$ and $\gomN$. By $\bkn$ we denote the unit outer normal to $\gom$.
%Let $\bkb = \{b_i\}_{i=1}^d$ be a linear convection whose entries $b_i$ are
%Lipschitz continuous real-valued functions in $\Om$, %$c$ denote the reaction coefficient 
%$\ve > 0$ be a diffusion coefficient,
Let $f\in L^2(\Om)$ be a source term and
$\K\in\R^{d\times d}$ be a symmetric positive-definite diffusion tensor such that
\begin{align}\label{Kij}
  \xi \cdot \K\xi \ge k_0 |\xi|^2\qquad \mbox{and} \qquad 
  |\K\xi| \leq k_1 |\xi| \qquad \forall \xi \in\R^d
\end{align}
for real values $0 <k_0 \leq k_1$. % are a positive numbers.
%By $\bkn(x)$ we denote the unit outward normal vector to $\Om$ at $x \in \Om$. 
%In some situations, $\K=\ve\mI$ where $\ve > 0$ is a diffusion coefficient.

We consider the linear %convection-diffusion
model problem with the Dirichlet boundary condition
\begin{subequations}
\label{prob1}
  \begin{align}
  \label{prob1a}
  - \nabla\cdot(\K \nabla u) %+ \nabla \cdot (\bkb u)
  &= f \ \ \qquad \text{in } \Om, \\ %+ \nabla \cdot (\bkb u)
  \label{prob1b}
  u &= u_D  \qquad\text{on } \gom,
%  \\
%  \label{prob1c}
%  \K \nabla u\cdot\bkn &= g_N  \qquad\text{on } \gomN,  
  \end{align}
 \end{subequations}
where $u: \Om \to \R$ is an unknown scalar function defined on $\Om$, and
$u_D\in L^2(\gomD)$. %, and $g_N\in L^2(\gomN)$.
%All considerations are valid also for a general mixed Dirichlet-Neumann boundary conditions.
Obviously, problem \eqref{prob1} possesses a unique weak solution.

\subsection{DG discretization} 

Let  $\Th$ be a partition of $\oOm$ consisting of a finite
number of $d$-dimensional simplices $K$ with mutually
disjoint interiors. The symbol $\dK$ denotes a boundary of $K \in \Th$,
and $h_K = \diam(K)$ is its diameter.
%and $|K|$ its d-dimensional Lebesgue measure.
The approximate solution of \eqref{prob1} is sought in
%To each $K \in \Th$ we assign its local polynomial degree $p_K$. 
%Then we define set $\pp := \{ p_K; \, K \in \Th\}$ and the
the finite dimensional space 
\begin{align}
  \label{Shp}
  \Shp  = \left\{ v \in \Ldo; \, \restr{v}{K} \in P^{\pK}(K) \, \forall K \in \Th \right\}, 
\end{align}
where $\pK$ is local polynomial degree assigned to each $K\in\Th$. 
We assume that the ratio of polynomial degrees $\pK$ and $\pKp$  of any pair of elements
$K$ and $K'$
that share a face (edge for $d=2$) is bounded.
%The dimension of $\Shp$ corresponding to the number of {\em degrees of freedom } $\dof$ 
%can be calculated as
%\begin{align}
%  \label{Shp1}
% \dof := \text{dim} \Shp = \sum\nolimits_{K \in \Th} \dK,\qquad \mbox{where}\quad
% \dK=(\pK+1)\dots(\pK + d)/d!
%\end{align}
%is the dimension of the space $P^{\pK}(K)$, $K\in\Th$.

By $\Fh$ we denote the union of all faces $\gamma$ contained in $\Th$.
Moreover,
$\FhI$ and $\FhB$ denotes the union of interior and boundary faces of $\Fh$, respectively.
%$\FhI$ denotes the union of interior faces, and let 
%$\FhD$ and $\FhN$ denote the union of boundary faces belonging to
%$\gomD$ and $\gomN$, respectively. We set $\FhB:=\FhD\cup \FhN$
%and $\FhID:=\FhI\cup\FhD$.
%thus, $\Fh = \FhI \cup \FhB = \FhI \cup \FhD \cup \FhN$.
For each $\gamma\in\Fh$, we consider a unit normal vector $\nng$,
its orientation can be chosen arbitrarily for the interior faces.
Symbols $\jump{v}_\gamma$ and $\aver{v}_\gamma$ denote
the jump of $v$ multiplied by $\nng$  and the mean value of $v\in\Shp$
on $\gamma\in\FhI$, respectively.
For $\gamma\in\FhB$, we put  $\jump{v}_\gamma = v\bkn_\gamma$ and $\aver{v}_\gamma=v$.
If there is no risk of misunderstanding
we drop the subscripts $_\gamma$.
%these symbols denote just the traces of $v$.

%% If $\gamma\in\FhB$ then
%% $\nng$ is outer normal to $\Om$.
%% We define the traces of $v\in\Shp$ on $\gamma \subset \Fh$ by
%% \begin{align}
%%   \label{jump0}
%%   v(x)|_\gamma^{+} &:= \lim_{t\to 0^+}  v(x - t\nng),\quad x\in\gamma,\ \gamma\in\Fh, \\
%%   v(x)|_\gamma^{-} &:= \lim_{t\to 0^+}  v(x + t\nng),\quad x\in\gamma,\ \gamma\in\FhI, \notag
%% \end{align}
%% and set the mean value and jump of $v$ on $\gamma$ by
%% \begin{align}
%%   \label{jumps}
%%   \aver{v}_\gamma :=
%%   \begin{cases}
%%   ( v|_\gamma^+  + v|_\gamma^-) /2 & \gamma\in\FhI, \\
%%     v|_\gamma^+   & \gamma\in\FhB, \\
%%   \end{cases}
%%   \quad \mbox{ and } \quad
%%   \jump{v}_\gamma :=
%%   \begin{cases}
%%     ( v|_\gamma^+  - v|_\gamma^-) \nng & \gamma\in\FhI, \\
%%     v|_\gamma^+  \nng  & \gamma\in\FhB. \\
%%   \end{cases}
%% \end{align}

%Furthermore, $\hK$ denotes the diameter of $K\in\Th$.
Let $\gamma\in \FhI$ and
$\gamma \subset \pdK\cap \pdK'$, $K\not=K'$, we set
\begin{align}
  \label{gamma}
  \hg = \max(\hK, \hKp), \qquad 
  \pg = \max(\pK, \pKp).
\end{align}
For $\gamma\subset \pdK \cap\FhB$, we set $\hg=\hK$ and $\pg = \pK$.

Using \eqref{Lsp}, we define the forms for $u,v \in \Shp$,
(cf. \cite[Section~4.6]{DGM-book} or \cite{Houston-book})
%\begin{subequations} \label{eq:forms}
\begin{align} %  \label{Ah}% \label{eq:ah}
  %\ah(u,v)
  \Ah(u,v):= &  \sumK\LspK{\K \nabla u}{ \nabla v } 
   -  \sumFID\Big( \Lspg{ \aver{\K\nabla \u} -\sigma\jump{\u}}{\jump{v}}
  +  \Lspg{ \aver{\K\nabla v} }{\jump{u}} 
  %- \Lspg{ \sigma \jump{\u}} {\jump{v} }
  \big), \notag  \\  
% \label{eq:bh} 
%% \bh(u,v) &:= -\sumK\LspK{u\bkb}{ \nabla v }
%% - \sumF\Lspg{ H(u|_\gamma^+, u|_\gamma^-,\nng)} {\jump{v}\nng}, \\
% \bh(u,v) &:= -\sumK\LspK{u\bkb}{ \nabla v }
% + \sumK \Lsp{\bkbnp u + \bkbnm u\minus } {v } {\pd K\setminus \gom} \\
% & \qquad 
%  + \sumK \Lsp{\bkbnp u + \bkbnm u } {v } {\pd K\setminus \gomN}, \notag \\
  \label{Ah}
%  \label{eq:lh}
  \lh( v ) := & \Lsp{f}{v}{\Om}
  - \sumFD \Big(\Lspg{ \K \nabla v }{u_D\,\nng} - \Lspg{ \sigma u_D} { v }\Big),
  %+\sumFN\Lspg{ g_N} {v }, %\\
  %  &\qquad - \sumK \Lsp{\bkbnp u + \bkbnm u_D } {v } {\pd K\setminus \gomD}, \notag
\end{align} 
%\end{subequations}
where
%$u\minus$ denotes the exterior trace of $u$  defined on $\pd K\setminus\gom$,
%$\bkbnp = \max(\bkb\cdot \bkn_{\pd K}, 0 )$,
%and
%$\bkbnm = \min(\bkb\cdot \bkn_{\pd K}, 0 )$. 
%I.e, the convective flux $\bkn u$ through $\pd K$ is discretized by upwinding.
%%$H$ is the numerical flux approximating the physical one $\bkb\, u|_\gamma$ chosen, e.g.,
%%as upwinding
%% \begin{align} 
%%   H(u_1,u_2,\bkn) := 
%%   \begin{cases} 
%%     %    (\bkb \cdot \bkn) u_1,   & \text{ if } \bkb \cdot \bkn \geq 0 \\       
%%     %    (\bkb \cdot \bkn) u_2,   & \text{ if } \bkb \cdot \bkn < 0.
%%     \bkb \, u_1,   & \text{ if } \bkb \cdot \bkn \geq 0 \\       
%%     \bkb \, u_2,   & \text{ if } \bkb \cdot \bkn < 0.
%%   \end{cases}
%% \end{align}
%% In \eqref{eq:bh}, we set $u|_\gamma^-:=u_D$ for $\gamma\in\FhB$.   
%The choices of $\theta = -1,0,1$ lead to the
%non-symmetric, incomplete ans symmetric (NIPG, IIPG, SIPG)
%variants of the discontinuous Galerkin method. 
the penalty parameter $\sigma$
is chosen by
%\begin{align}
%  \label{sigma}
$  \restr{\sigma}{\gamma} %= \sigma_\gamma
  = {C_W k_0 \pg^2}/{\hg},\ \gamma \in \FhID$,
%\end{align}
%$\ve$ denotes the amount of diffusivity ($\approx |\K|$),
%$h_\gamma = \text{diam}(\gamma)$ 
%and
with a constant $C_W > 0$, % chosen sufficiently large to guarantee convergence of the method,
see \cite[Chapter~2]{DGM-book}.  Then the discrete problem reads.
%For SIPG, $c_W$ depends  on $\pK^2$ of $K$ sharing $\gamma$
%% Finally, we put 
%% \begin{align}
%%   \label{Ah}
%%  \Ah(\u,v) := \ah(\u,v) +  \bh(\u,v),\qquad u,v\in \Shp.
%% \end{align} 
%We are ready to define the discrete problem.
\begin{definition}
  We say that $\uh \in \Shp$ is the {\em approximate solution} of \eqref{prob1}
  by {\em symmetric interior penalty Galerkin (SIPG)} method
  if 
\begin{align} \label{DG}
 \Ah(\uh,v_h) = \lh(v_h)\quad \forall v_h \in \Shp.
\end{align} 
\end{definition}


\section{Domain decomposition method}
\label{sec:DDM}

%In this section
We follow the approach from
\cite{AntoniettiHouston_JSC11,AntoniettiALL_IJNAM16}, where more details can be found.
We consider a non-overlapping domain decomposition of $\Om$ as a set of open sub-domains
$\Om_i,\ i=1,\dots,N$ such that $\Om_i\cap\Om_j=\emptyset$ and $\oOm = \cup_{i=1,\dots, N}\oOm_i$.
The sub-domains $\Om_i$ are constructed as a union of some elements $K\in\Th$,
the corresponding meshes are denoted as $\Thi,\ i=1,\dots, N$.
%The number of elements $K\in\Th$ belonging to $\Om_i$ are denoted by $n_i$, $i=1,\dots,N$,
%i.e., $n = \sum\nolimits_{i=1}^N n_i$.
We consider the finite dimensional spaces
\begin{align}
  \label{Ship}
  \Ship  = \left\{ v \in \Ldoi; \, \restr{v}{K} \in P^{\pK}(K) \, \forall K \in \Thi \right\},
  \qquad i=1,\dots, N.
\end{align}
%The dimension of $\Ship$ is denoted by $\dof_i = \sum\nolimits_{K \in \Thi} \dK$, cf.
%\eqref{Shp1}. Obviously, $\dof = \sum\nolimits_{i=1}^N \dof_i$. We note that this
%property is valid only for non-overlapping discontinuous Galerkin method.
%In the case of (non-overlapping) conforming finite element method,
%we have  $\dof < \sum\nolimits_{i=1}^N \dof_i$ for $N\ge 2$.
%By $\NS$, we denote
%the maximal number of adjacent subdomains to any given subdomain in the domain decomposition, i.e.
%\begin{align}
%  \label{NS}
%  \NS = \max_{i=1,\dots,N} \#\{\Om_j,\ \Om_j\mbox{ is adjacent to } \Om_i,\ i\not=j\}.
%\end{align}

Besides the mesh $\Th$, we consider a coarser mesh $\ThH=\{\cK\}$ which typically
consists of polygonal/polyhedral elements $\cK$ defined as a union of some $K\in\Om_i$,
$i=1,\dots,N$.
We assume that any $\cK\in\ThH$ belongs to only one subdomain $\Om_i$ 
including the case $\cK=\oOm_i$ for some $i=1,\dots,N$.
Let $\qK= \min_{K\subset \cK} \pK$, $\cK\in\ThH$, we define the coarse finite element space
(cf. \eqref{Shp})
\begin{align}
  \label{SHP}
  \SHP:= %\SHHP=
   \left\{ v \in \Ldo; \, \restr{v}{\cK} \in P^{\qK}(\cK) \, \forall \cK \in \ThH \right\},
\end{align}
%We use the double notation in \eqref{SHP} for the same space since
%the notation $\SHP$ indicates that the coarse mesh $\ThH$ is related
%to
and set
%\begin{align}
%  \label{HH}
$  H:=\max_{\cK\in\ThH} H_{\cK}$ with $H_{\cK}= \diam(\cK),\ \cK\in\ThH$.
%\end{align}
%whereas the notation $\SHP$ simplifies the forthcoming formulas.

\subsection{Local problems}
\label{sec:local}
We introduce the restriction operators $\Ri: \Shp \to \Ship$,  $i=1,\dots,N$ as
$\Ri v_h = v_h|_{\Om_i}$, $i=1,\dots, N$, $v_h\in\Shp$. The corresponding prolongation
operators $\RiT:\Ship\to\Shp$ are given by
$\RiT v_h = v_h$ on $\Om_i$ and
$\RiT v_h = 0$ on $\Om\setminus\Om_i$ for
$v_h\in\Ship$, $i=1,\dots,N$.
Moreover, since $\SHP\subset \Shp$, we define the prolongation operator
$\RNT: \SHP \to \Shp$ as a standard injection from  $\SHP$ to $\Shp$.
The restriction operator $\RN: \Shp \to \SHP$  is given as the dual operator
to $\RNT$ with respect to the $L^2(\Om)$ duality.
%The algebraic representation of the restriction operators $\Ri$ are the transposed matrices
%$\mRi$, $i=1,\dots, N$.

Furthermore, using \eqref{Ah}, we define the {\em local forms} $\Ahi:\Ship\times\Ship\to \R$ by
\begin{align}
  \label{Ahi}
  \Ahi(u_i, v_i) := \Ah(\RiT u_i, \RiT v_i),\quad u_i,v_i\in\Ship,\quad i=0,\dots, N,
\end{align}
%where $\Ah$ is given by 
%The algebraic representation of the form $\Ahi$, $i=1,\dots,N$
%are matrices $\mA_{ii} = \mRi\mA\mRiT$,  $i=1,\dots,N$ which are the same as the diagonal block in
%\eqref{dd1}.
and the {\em local projections} $\tPi:\Shp\to\Ship$ and $\PPi:\Shp\to\Shp$ by
\begin{align}
  \label{Phi}
  \Ahi(\tPi u, v_i) = \Ah(u, \RiT v_i)\quad \forall v_i\in\Ship
\quad \mbox{ and } \quad \PPi:=\RiT\tPi,   \quad i=0,\dots, N,
\end{align}
respectively.
%The algebraic representations
%of $\tPi$ and $\PPi$ are then
%\begin{align}
%  \label{mPhi}
%  \mtPi = \mA_{ii}^{-1} \mRi \mA\quad \mbox{ and }
%  \mPPi = \mRiT \mA_{ii}^{-1} \mRi \mA, \qquad i=1,\dots,N,
%\end{align}
%respectively.
Finally, the {\em two-level additive Schwarz preconditioned operator} reads
\begin{align}
  \label{Padd}
  \Padd:=\sum\nolimits_{i=0}^N \PPi.
\end{align}
%where the subscript $_{\add}$ indicates two-level additive Schwarz.
%  having the representation
%\begin{align}
%  \label{add1}
%  \mPadd=\sum_{i=1}^N \mPPi = \sum_{i=1}^N \mRiT \mA_{ii}^{-1} \mRi \mA =: \mNadd^{-1} \mA,
%\end{align}
%where $\mNadd^{-1}$ is the preconditioner.

\subsection{Algebraic representation}

%In order to simplify notation, we number elements $K\in\Th$, so we write
%$\Th=\{K_k\}_{k=1}^{n}$, where $n$ is the number of elements of $\Th$.
%Moreover, we write $d_k := d_{K_k} = (p_{K_k}+1)\dots(p_{K_k} + d)/d!$ for $k=1,\dots, n$, cf.
%\eqref{Shp1}.
Let $\Bh:=\{\vp_{k}\}_{k=1}^\dof$ be a basis 
of $\Shp$ ($\dof = \dim\Shp$),
%chosen such that
the support of %each $\vp_k$, $k=1,\dots,\dof$
each basis function $\vp\in\Bh$ is just a one $K\in\Th$. 
We assume that the basis functions are numbered such that 
first we number test functions with support in $\Om_1$,
then functions with support in $\Om_2$, etc.
%The numbering is illustrated in Figure~\ref{fig:meshDD}.
%
%\begin{figure}
%  \begin{center}
%    \includegraphics[width=0.75\textwidth]{Figs_DDM/meshDD.pdf}
%  \end{center}
%  \caption{Example of the numerating of mesh elements, bolted lines correspond to the
%  boundaries among subdomains $\Om_i$, $i=1,\dots,N$.}
%  \label{fig:meshDD}
%\end{figure}


Then problem \eqref{DG} is equivalent to linear algebraic system
\begin{align}
  \label{alg1}
  \mA \bku = \bkg,
\end{align}
where $\mA$, $\bku$, and $\bkg$  are algebraic representation
of $\Ah$, $\uh$, and $\lh$, respectively, with respect to basis $\Bh$.
%% $\mA\in \R^{\dof\times\dof}$ is a matrix with entries
%% $A_{k,l} = \Ah(\vp_{l},\vp_{k})$, $k,l=1,\dots, \dof$,
%% $\bkg \in \R^{\dof}$ is the vector with entries
%% $g_{k} = \lh(\vp_{k})$, $k=1,\dots, \dof$, and
%% $\bku \in \R^{\dof}$ is the sought vector with entries
%% $u_{k}$,  $k=1,\dots, \dof$.
%% Then the approximate solution of \eqref{DG} is given by 
%% $u_h(x) = \sum\nolimits_{k=1}^\dof u_{k} \vp_{k}(x)$.
Similarly, let $\mRi$ and $\mRiT$ denote the algebraic
representations of the operators $\Ri$ and $\RiT$ (cf.~\eqref{sec:local})
with respect to $\Bh$,
respectively for $i=0,\dots, N$.
Particularly, 
the matrices $\mRiT$ for $i=1,\dots, N$ are just extensions of unit matrices
of the corresponding sizes by zero blocks and $\mRNT$ is given by an evaluation of
the basis functions of $\SHHP$ by basis functions of $\Bh$,
we refer, e.g. \cite{AntoniettiALL_JSC14} for details. Obviously, 
$\mRi$ are transposed matrices of $\mRiT$ for $i=0,\dots, N$.

Moreover, the algebraic representation of the local bilinear forms $\Ahi$, the operators
$\tPi$, $\PPi$ 
from \eqref{Ahi}--\eqref{Phi} reads
(cf. \cite{Karashian2001,AntoniettiHouston_JSC11,AntoniettiALL_IJNAM16,DryjaKrzyzanowski_NM16})
\begin{align}
  \label{repre}
  &\mA_i= \mRi\mA\mRiT,\qquad
  \mtPi = \mA_{i}^{-1} \mRi \mA, \qquad
  \mPPi = \mRiT \mA_{i}^{-1} \mRi \mA, \quad  i=0,\dots, N, 
\end{align}
and the representation of the additive Schwarz operator $\Padd$ from \eqref{Padd} is
\begin{align}
  \label{repre2}
  \mPadd=\sum\nolimits_{i=0}^N \mPPi
  = \sum\nolimits_{i=0}^N \mRiT \mA_{i}^{-1} \mRi \mA =: \mNadd^{-1} \mA,
\end{align}
The matrix $\mNadd^{-1}$ is the two-level additive Schwarz preconditioner.
Furthermore, we denote the one-level additive Schwarz preconditioner by
\begin{align}
  \label{repre3}
  \mNad^{-1}:=   \sum\nolimits_{i=1}^N \mRiT \mA_{i}^{-1} \mRi = \diag(\mA_1^{-1},\dots, \mA_N^{-1}).
\end{align}
The above matrix-block equality is valid due to the used
numbering of basis functions. %, cf. Figure~\ref{fig:meshDD}.
Finally, we note that $\mPPi$ %, $i=0,\dots,N$
are projections, since, in virtue of \eqref{repre},
we have
\begin{align}
  \label{proj2}
  \mPPi^2 =  \mRiT \mA_{i}^{-1} \mRi \mA \,  \mRiT \mA_{i}^{-1} \mRi \mA
  %=  \mRiT \mA_{i}^{-1} (\mRi \mA  \mRiT ) \mA_{i}^{-1} \mRi \mA
  = \mRiT \mA_{i}^{-1}\mA_{i}\mA_{i}^{-1} \mRi \mA
  %=  \mRiT \mA_{i}^{-1} \mRi \mA
  = \mPPi, \quad i=0,\dots,N
\end{align}
provided that the performance of local solvers $\mA_{i}^{-1}$ is carried out exactly.

%% \subsection{Condition numbers}
%% We recall the results related to the condition numbers of matrix $\mA$ in \eqref{alg1} and
%% the preconditioned matrix $\mPadd$ in \eqref{repre2} for $k_0=k_1=1$ in \eqref{Kij}.
%% \begin{theorem}{\cite[Corollary~2.9]{AntoniettiHouston_JSC11}}
%%   \label{th:1}
%%   Let the mesh $\Th$ and the polynomial approximation degrees
%%   be globally quasi-uniform, i.e., $h_K\sim h$ and $p_K\sim p$ for any $K\in\Th$.
%%   Then the condition number of matrix $\mA$ from \eqref{alg1} is bounded by
%%   \begin{align}
%%     \label{cond1}
%%     \kappa(\mA) \lesssim C_W p^4 / h^2,
%%   \end{align}
%%   where $C_W$ is the constant from \eqref{sigma}.
%% \end{theorem}

%% \begin{theorem}{\cite[Theorem~5.2]{AntoniettiALL_IJNAM16}}
%%   \label{th:2}
%%   Let the meshes $\Th$, $\ThH$ and the polynomial approximation degrees $p_K$ and $q_{\cK}$
%%   be globally quasi-uniform, i.e., $h_K\sim h$, $p_K\sim p$ for any $K\in\Th$ and
%%    $H_{\cK}\sim H$, $q_{\cK}\sim q$ for any $\cK\in\ThH$.
%%   Then the condition number of matrix $\mPadd$ from \eqref{repre2} is bounded by
%%   \begin{align}
%%     \label{cond2}
%%     \kappa(\mPadd) \lesssim C_W (N_s + 2) H p^2/(hq) ,
%%   \end{align}
%%   where $C_W$ is the constant from \eqref{sigma} and $\NS$ is the
%%   maximal number of adjacent subdomains to any given subdomain in the domain decomposition,
%%   cf.~\eqref{NS}.
%% \end{theorem}


\subsection{Iterative methods}

To have better view in the performance of preconditioner, we consider
the (one and two levels) iterative additive Schwarz schemes solving \eqref{alg1}.
The matrix $\mA$ has blocks $\mA=\{\mA_{ij}\}_{i,j=1}^N$
such that each block $\mA_{ij}$ contains entries corresponding to $\Ah(\vp_{k},\vp_{l})$,
$k,l=1,\dots,\dof$ satisfying $\supp(\vp_{k}) \subset \oOm_j$
and $\supp(\vp_{l}) \subset \oOm_i$.  
Obviously, if $i\not=j$ and %$\mbox{meas}_{d-1}(\oOm_i\cap \oOm_j)= 0$
$\Om_i$ and $\Om_j$ have no common edge ($d=2$) or face ($d=3$)
then $\mA_{ij}=\bfzero$. Moreover, due to \eqref{repre},
the diagonal blocks $\mA_{ii} = \mA_i$, $i=1,\dots,N$, and $\mA_{ij} = \mRi\mA\mRjT$, $i,j=1,\dots,N$.
%% Figure~\ref{fig:matrixDD}, which shows an illustrative mesh with sub-domain partition
%% and the shape of corresponding matrix $\mA$ and diagonal block $\mA_{ii},\ i=1,\dots,N$.
%% Similarly, $\bku_i$ and $\bkg_i$, $i=1,\dots,N$ are the row-blocks of vectors $\bku$ and $\bkg$,
%% respectively, corresponding to sub-domains $\Om_i$, $i=1\dots,N$.

%% \begin{figure}
%%   \begin{center}
%%     \includegraphics[width=0.48\textwidth]{Figs_DDM/DDM_mesh.pdf}
%%     \hspace{0.02\textwidth}
%%     \includegraphics[width=0.48\textwidth]{Figs_DDM/DDM_matrix.pdf}
%%   \end{center}
%%   \caption{Example of mesh elements $K\in\Th$ (red)
%%     with polynomial degree $\pK,\ K\in\Th$ (the integers inside of elements) and boundaries
%%     of sub-domains $\Om_i,\ i=1,\dots, 4$ (blue) (left);
%%     the shape of the corresponding non-vanishing blocks (red) and the blocks
%%     $\mA_{ii}$, $i=1,\dots,4$ (blue) (right).}
%%   \label{fig:matrixDD}
%% \end{figure}


First, we solve \eqref{alg1} iteratively by the one-level
additive Schwarz method which is (in the DG context) equivalent to 
the block Jacobi method. Let
$\bku^\ell = (\bku_1^{\ell},\dots, \bku_N^\ell)^\T$ denote the $\ell$ -th approximation of
$\bku$, then  we have %define the iterative scheme 
\begin{align}
  \label{dd1}
  \mA_{i} \bku_i^{\ell+1} = \bkg_i - \sum\nolimits_{j=1, j\not=i}^N \mA_{ij} \bku_j^{\ell},\quad
  i=1,\dots,N,\qquad \ell=0,1,2,\dots.
\end{align}
In virtue of \eqref{repre3}, scheme \eqref{dd1} is equivalent to
\begin{align}
  \label{dd2}
  \bku^{\ell+1} = \bku^{\ell} + \mNad^{-1}( \bkg   -  \mA\bku^{\ell}),
  \qquad \ell=0,1,2,\dots.
\end{align}

Additionally, the two-level method read: For $\ell=1,2,\dots$, set
\begin{subequations}
  \label{2add}
  \begin{align}
    \label{2add1a}
    \mbox{step (i)} & \quad
    %\begin{cases}
    %\mbox{ set }
    \bku^{\ell+1/2} := \bku^{\ell} + \mNad^{-1}( \bkg   -  \mA\bku^{\ell}), 
    %\end{cases}
    \\
    \label{2add2}
  \mbox{step (ii)} & \quad
  \bku^{\ell+1} := \bku^{\ell+1/2} + \mRNT \mA_{0}^{-1} \mRN (\bkg - \mA \bku^{\ell+1/2}),
    %    \mbox{step (ii)} &
%    \begin{cases}
%      \mbox{ set } & \bkr^{\ell+1/2} := \mRN (\bkg - \mA \bku^{\ell+1/2}), \\
%      \mbox{ solve }& \mA_{0}\bkd^{\ell+1/2} =  \bkr^{\ell+1/2},  \\
%      \mbox{ set } & \bku^{\ell+1} := \bku^{\ell+1/2} + \mRNT \bkd^{\ell+1/2}. 
%  \end{cases}
  \end{align}
\end{subequations}
%The coarse correction step (ii) can be written in a compact form
%\begin{align}
%  \label{2add2}
%  \mbox{step (ii)} \qquad
%  \bku^{\ell+1} := \bku^{\ell+1/2} + \mRNT \mA_{0}^{-1} \mRN (\bkg - \mA \bku^{\ell+1/2}).
%\end{align}
which means that the residual of the approximate solution computed locally on fine meshes
is restricted to the coarse global mesh, the coarse problem is solved, and the ``coarse'' residual
is projected back to the fine mesh to update the solution.


Let us consider a modification of \eqref{2add2} in the form
\begin{align}
  \label{2add3}
  \mbox{step (ii')} \qquad
  \bku^{\ell+1} := \bku^{\ell+1/2} + \mRNT \mA_{0}^{-1} \mRN (\bkg - \mA \bku^{\ell}),
\end{align}
which can be executed
independently of step (i). However, it does not converge in general but can be used as a
preconditioner, cf. Section~\ref{sec:iip}. In the following, we discuss both variants
(ii) and (ii').



\subsubsection{Variant (ii')}
\label{sec:iip}

Inserting \eqref{2add1a} into \eqref{2add3} and using \eqref{repre2}--\eqref{repre3} gives
\begin{align}
  \label{2add4}
  \bku^{\ell+1} & =\bku^{\ell} + \mNad^{-1}( \bkg   -  \mA\bku^{\ell})
  + \mRNT \mA_{0}^{-1} \mRN (\bkg - \mA \bku^{\ell}) \\
  & = \bku^{\ell} + \mNadd^{-1}( \bkg   -  \mA\bku^{\ell}), \qquad \ell=0,1,\dots.
  \notag
\end{align}
If $\bku^\ell \to \bku$ for $\ell \to \infty$, then the limit $\bku$
is also the solution of \eqref{alg1}. Moreover, with respect to \eqref{2add4}, the vector $\bku$
fulfills
\begin{align}
  \label{2add5}
  \mPadd \bku = \mNadd^{-1} \mA \bku = \mNadd^{-1} \bkg.
\end{align}
Therefore, the two-level additive Schwarz preconditioner \eqref{repre2} corresponds  to
the iterative method \eqref{2add1a} \& \eqref{2add3}.

\subsubsection{Variant (ii)}
\label{sec:ii}

Similarly as in Section~\ref{sec:iip}, inserting \eqref{2add1a} into \eqref{2add2}
and using \eqref{repre2}--\eqref{repre3}, we get
\begin{align}
  \label{2add11}
  \bku^{\ell+1} & =
  \bku^{\ell} + \mNad^{-1}( \bkg \! -  \mA\bku^{\ell}) 
  + \mRNT \mA_{0}^{-1} \mRN \Big(\bkg - \mA \big( \bku^{\ell}
  + \mNad^{-1}( \bkg   -  \mA\bku^{\ell})\big) \Big)
  \\
  & = \bku^{\ell} + \Big(\mNad^{-1} + \mRNT \mA_{0}^{-1}\mRN - \mRNT \mA_{0}^{-1} \mRN \mA \mNad^{-1}\Big)
  ( \bkg  -  \mA\bku^{\ell}).    \notag
\end{align}
Therefore, using the same argumentation as in \eqref{2add5}, the preconditioner corresponding
to the iterative method \eqref{2add1a} \& \eqref{2add2} reads
\begin{align}
  \label{hyb1}
  \mNhy^{-1} &:= \mNad^{-1} + \mRNT \mA_{0}^{-1}\mRN - \mRNT \mA_{0}^{-1} \mRN \mA \mNad^{-1} \\
  & =  \sum\nolimits_{i=1}^N \mRiT \mA_{i}^{-1} \mRi
  + \mRNT \mA_{0}^{-1}\mRN \Big(\mI - \mA \sum\nolimits_{i=1}^N \mRiT \mA_{i}^{-1} \mRi\Big).
  \notag
\end{align}
Due to \eqref{repre}--\eqref{repre3}, the preconditioner operator has the form
\begin{align}
  \label{hyb2}
  \mPhy &:=  \mNhy^{-1} \mA
  %=  \Big(\mNad^{-1} + \mRNT \mA_{0}^{-1}\mRN - \mRNT \mA_{0}^{-1} \mRN \mA \mNad^{-1}\Big)\mA \\
 =   \mPad + \mPPN - \mPPN \mPad  
  = \mI - \big(\mI - \mPPN\big)\big(\mI - \mPad \big) \\
  &= \mI - \big(\mI - \mPPN \big)\big(\mI - \sum\nolimits_{i=1}^N \mPPi \big),
  \notag
\end{align}
which is actually a {\em hybrid operator}, it is additive with respect to the local
components and multiplicative with respect to the levels.

However, the preconditioner $\mPhy$ is not symmetric so it is not possible to use it in combination
with, e.g. conjugate gradient method.
%On the other hand, the use of the preconditioner $\mPhy$ in combination with GMRES method gives
%faster convergence in comparison to $\mPadd$ even for nonsymmetric systems.
%\vit{cf. numerical experiments?}
The symmetric variant of \eqref{hyb2} was proposed
in \cite{Mandel_94} in context of conforming finite element method, see also
\cite[Section~2.5.2]{ToselliWidlund-DD05}. Therefore, we introduce a symmetric variant
of \eqref{hyb2}
\begin{align}
  \label{hyb3}
  \mPhyb & :=  \mI - \big(\mI - \mPPN \big)\big(\mI - \sum\nolimits_{i=1}^N \mPPi \big)
  \big(\mI - \mPPN \big) \\
  & = \mPPN +  \big(\mI - \mPPN \big)\sum\nolimits_{i=1}^N \mPPi \big(\mI - \mPPN \big), \notag
\end{align}
where last equality follows from \eqref{proj2}.
We analyze the preconditioned operator $\mPhyb$ in Section~\ref{sec:anal}.
The preconditioner $\mNhyb^{-1}$ corresponding to the preconditioner operator
$\mPhyb =: \mNhyb^{-1}\mA $ from \eqref{hyb3} can be derived as
\begin{align}
  \label{hyb4}
  %& \mPhyb = \mPPN +  \big(\mI - \mPPN \big)\sum_{i=1}^N \mPPi \big(\mI - \mPPN \big) \\
  %&= \mRNT \mA_{0}^{-1} \mRN\mA +
  %\big(\mI - \mPPN \big)\sum_{i=1}^N \mRiT \mA_{i}^{-1} \mRi \mA
  %\big(\mI - \mRNT \mA_{0}^{-1} \mRN\mA \big) \notag \\
  %&=
   \mNhyb^{-1} =
  \mRNT \mA_{0}^{-1} \mRN + \big(\mI - \mRNT \mA_{0}^{-1} \mRN\mA \big)
  \sum_{i=1}^N \mRiT \mA_{i}^{-1} \mRi \big(\mI - \mA \mRNT \mA_{0}^{-1} \mRN\big).
 % \notag \\
 % &=:   \mNhyb^{-1}\mA.
 % \notag
\end{align}

Algorithms~\ref{alg:ASM} %, \ref{alg:ASM2}
and \ref{alg:ASM3} describe
the applications of preconditioners $\mNadd^{-1}$ %, $\mPhy$
and $\mNhyb^{-1}$ introduced in
\eqref{repre2} %, \eqref{hyb1}
and \eqref{hyb4}, respectively.
Whereas Algorithm~\ref{alg:ASM} allows  to solve the local fine problems
(with $\mA_i$, $i=1,\dots,N$) together  with the global coarse problem (with $\mA_0$)
in parallel,
%Algorithm~\ref{alg:ASM2} requires solving the local fine problems at first
%and then solve the global coarse problem. Additionally, one multiplication by
%$\mA$ has to be performed.
%Finally,
Algorithm~\ref{alg:ASM3} requires solving the global coarse problem first,
then the local fine problems, and finally
the global coarse problem. Additionally, two multiplications by
$\mA$ have to be performed. The multiplication by $\mA$ is typically much cheaper than
solution of local or global problems. Moreover, if the global coarse problem is smaller
than a local one then the application of the preconditioner %s $\mNhy^{-1}$ or
$\mNhyb^{-1}$
exhibits only  a small increase of the computational time in comparison to
the preconditioner $\mNadd^{-1}$.
  
\begin{algorithm}[ht]
  \caption{Application of preconditioner $\mNadd^{-1}$ from \eqref{repre2}:
    $\bku \leftarrow \mNadd^{-1}\bkx$}
  \label{alg:ASM}
  \begin{spacing}{1.15}
    \begin{algorithmic}[1]
      \STATE \textbf{input} matrices $\mA$, $\mA_{i}$, $\mRi$, $i=0,\dots,N$, vector $\bkx$
      \STATE $\bkx_i := \mRi \bkx$ and solve $\mA_{i} \bky_i = \bkx_i$ for $i=0,\dots,N$
      \STATE \textbf{output} vector  $\bku := \sum_{i=0}^N \mRi^T \bky_i$
    \end{algorithmic}
  \end{spacing}
\end{algorithm}

%% \begin{algorithm}[ht]
%%   \caption{Application of preconditioner $\mNhy^{-1}$ from \eqref{hyb1}:
%%     $\bku \leftarrow \mNhy^{-1}\bkx$}
%%   \label{alg:ASM2}
%%   \begin{spacing}{1.15}
%%     \begin{algorithmic}[1]
%%       \STATE \textbf{input} matrices $\mA$, $\mA_{i}$, $\mRi$, $i=0,\dots,N$, vector $\bkx$
%%       \STATE $\bkx_i := \mRi \bkx$ and  solve $\mA_{i} \bky_i = \bkx_i$ for $i=1,\dots,N$
%%       \STATE $\bky := \sum_{i=1}^N \mRi^T \bky_i$
%%       \STATE $\bkz := \bkx -\mA \bky $ \label{asm2_m1}
%%       \STATE $\bkx_0 := \mRN \bkz$ and solve $\mA_{0} \bky_0 = \bkx_0$ \label{asm2_c1}
%%       \STATE \textbf{output} vector $\bku := \mRN^T \bky_0 + \bky$
%%     \end{algorithmic}
%%   \end{spacing}
%% \end{algorithm}



  
\begin{algorithm}[ht]
  \caption{Application of preconditioner $\mNhyb^{-1}$ from \eqref{hyb4}:
    $\bku \leftarrow \mNhyb^{-1}\bkx$}
  \label{alg:ASM3}
  \begin{spacing}{1.15}
    \begin{algorithmic}[1]
      \STATE \textbf{input} matrices $\mA$, $\mA_{i}$, $\mRi$, $i=0,\dots,N$, vector $\bkx$
      \STATE $\bkx_0 := \mRN \bkx$  and solve $\mA_{0} \bky_0 = \bkx_0$ \label{asm3_c1}
      \STATE $\bkz_0 :=  \mRN^T \bky_0$,  %  \label{asm3_m1}
      %\STATE
            $\bkz := \bkx - \mA \bkz_0$  \label{asm3_m2}
      \STATE $\bkz_i := \mRi \bkz$  and solve $\mA_{i} \bky_i = \bkz_i$ for $i=1,\dots,N$
      \STATE $\bky := \sum_{i=1}^N \mRi^T \bky_i$
      \STATE $\bkw_0 : = \mRN \mA \bky$ and solve $\mA_{0} \bkv_0 = \bkw_0$ \label{asm3_c2}
      \STATE \textbf{output} vector $\bku = \bkz_0 + \bky - \mRN^T \bkv_0$
    \end{algorithmic}
  \end{spacing}
\end{algorithm}



\section{Numerical analysis}
\label{sec:anal}

In this section we derive the bound of the hybrid Schwarz operator \eqref{hyb3}.
For the sake of simplicity, we consider
a quasi-uniform meshes $\Th$ and $\ThH$ with mesh steps $h$ and $H$, respectively,
and constant polynomial degrees $p$ and $q$. 
Let $\bss$ be the broken Sobolev space consisting of
piece-wise regular functions belonging to 
$\HH^s(K)$ for $K\in\Th$, $s=1,2$. Moreover, we assume $\K$ being constant
in $\Om$, hence, we put $k_0=k_1=1$ in \eqref{Kij}.
%We note that for a varying $\K$,
%the regularity of the dual problem \eqref{dual} is not guaranteed
%and depends on the regularity of $\K$.
The notation  $a \lesssim b$ means that there exists a constant $C$ independent of
discretization parameters such that $a \leq C\, b$.

We assume that $\Om$ is convex, $g\in L^2(\Om)$, and consider the dual problem
\begin{align}
  \label{dual}
  - \nabla\cdot (\nabla \z) & = g\qquad\mbox{ in } \Om, \\
  \z & = 0   \qquad  \mbox{ on } \gom.  \notag
\end{align}
%for $g\in L^2(\Om)$ and a convex  $\Om$,
The weak solution of \eqref{dual} fulfills $\z\in \HH^2(\Om)$ and
$\norm{z}{\HH^2(\Om)} \lesssim \norm{g}{L^2(\Om)}$.
%we assume that $\Om$ is convex for example. % and $\K$ is sufficiently regular.
%Some aspects were discussed in \cite{Krzyzanowski_NMPDE16}.
We note that the adjoint consistency of $\Ah$ implies (e.g., \cite[Lemma~2.48]{DGM-book})
\begin{align}\label{cons}
  \Ah (\vp,\z) = \Lsp{g}{\vp} \qquad \forall\vp\in \bsd.
\end{align}
  



\subsection{Properties of $\Ah$}
%In the following, and
We use the DG-norm defined as follows
\begin{align}
  \label{DGnorm}
    \dg \vh \dg^2 = \snormP{\nabla \vh}{\bsj}{2} +\sbar \sumfh  \normP{ \jump{\vh}}{\Lt{\gamma}}{2},
\end{align}
where $\sbar = {p^2}/{h}$.
The form $\Ah$ from \eqref{Ah} is coercive and continuous, namely
\begin{align}
  \label{coerc}
  %k_0\,
  \dg \uh \dg^2 & \lesssim \Ah(\uh,\uh),\qquad \uh\in\Shp, \\
  \label{cont1}
  |\Ah (\uh,\vh)| & \lesssim  %k_1
  \dg \uh \dg\, \dg \vh \dg,\qquad \uh,\vh \in \Shp, \\
  \label{cont2}
  |\Ah (\uh,v)| & \lesssim  %k_1
  \dg{\uh} \dg\, \norm{v}{\sigma},\qquad \u\in\Shp,\, v \in \bsd,
\end{align}
%where $k_0$ and $k_1$ are the problems parameters from \eqref{Kij}.
%% Additionally,
%% let $\tAh$ be the bilinear form defined as in \eqref{Ah} with $\K=\mI$. Then,
%% \begin{align}
%%   \label{cont2}
%%   |\tAh (\u,\vh)| & \lesssim  \norm{\u}{\sigma} \, \dg \vh \dg,\qquad \u\in\bsd,\vh\in\Shp, 
%% \end{align}
where
$\normP{\u}{\sigma}{2}:= \dg\u\dg^2 +(\sbar)^{-1} \sumfh  \normP{ \aver{\nabla\u}\cdot\bkn_\gamma}{\Lt{\gamma}}{2}$.
Finally, we use the following interpolation estimates following, e.g. from
\cite[Section~2]{AntoniettiALL_IJNAM16} or \cite[Section~3.3]{Houston-book}:
let $\z\in \HH^2(\cK)$, $\cK\in\ThH$ and $\Pi_0\z$ be its piece-wise polynomial interpolation
in $\SHP$ then
\begin{align}
  \label{approx0}
  \norm{\z-\Pi_0\z}{\HH^r(\cK)} & \lesssim \frac{H^{2-r}}{q^{2-r}} \norm{z}{\HH^2(\cK)},\qquad r=0,1,\\
  \norm{D^{\alpha}(\z-\Pi_0\z)}{L^2(\pd\cK)}  &
  \lesssim \frac{H^{2-|\alpha|-1/2}}{q^{2-|\alpha|-1/2}} \norm{z}{\HH^2(\cK)},\qquad 0\leq|\alpha|\leq 1,
  \notag
\end{align}
where $\alpha$ is a multi-index of length $|\alpha|$.
Using estimates \eqref{approx0}, we can derive 
\begin{align}
  \label{approx}
  \norm{\z-\Pi_0\z}{\sigma}\lesssim \frac{H}{q}\, \norm{z}{\HH^2(\Om)},\qquad z\in \HH^2(\Om).
\end{align}


\subsection{Auxiliary results}
  For any $\wh\in\Shp$, we define its projection $\wH:= \PPN \wh = \RNT\tPN \wh$,
  %\begin{align}
  %  \label{anal0}
  %  \twH\in\SHP,\ \twH:=\tPN \wh, \qquad 
  %  \wH\in \Shp,\ \wH:= \RNT \twH = \PPN \wh,
  %\end{align}
  where operators $\RNT$, $\tPN$ and $\PPN$ are given by \eqref{Phi}.
  Therefore, using
  \eqref{Ahi} -- \eqref{Phi}, we have the Galerkin orthogonality %of the projection
  %\begin{align}
  %  \label{anal1}
  %  \Ah(\wh, \RNT v_0) =  \AhN(\twH, v_0) =\Ah(\RNT \twH, \RNT v_0) , \qquad v_0\in \SHP,
  %\end{align}
  %which implies the Galerkin orthogonality of the projection
  \begin{align}
    \label{anal2}
    \Ah(\wh - \wH, \RNT v_0) =  0 \qquad \forall v_0\in \SHP.
  \end{align}


\begin{lemma}
  \label{lem1}
  Let $\wh\in\Shp$ and $\wH\in\SHP$ be its projection satisfying \eqref{anal2}. Then
  \begin{align}
  \label{anal3}
  \dg \wh - \wH \dg \lesssim  %\frac{k_1}{k_0}
  \dg \wh \dg, \qquad
   \norm{\wh - \wH}{L^2(\Om)} \lesssim  \frac{H}{q}\dg \wh\|.  %k_1^{1/2} \Ah(\wh,\wh)^{1/2}.
  \end{align}
\end{lemma}

\begin{proof}
  Using the  coercivity and boundedness \eqref{cont1}--\eqref{coerc}
  and \eqref{anal2}, we have
  \begin{align*}
  % %\label{anal4}
    %k_0
    \dg \wh - \wH \dg^2  \lesssim  \Ah(\wh - \wH, \wh - \wH)
    = \Ah(\wh - \wH, \wh) \lesssim %k_1
    \dg \wh -\wH \dg\, \dg \wh \dg,
  \end{align*}
  which proves first inequality in \eqref{anal3}.
  \par
  To prove the second, we consider the dual problem \eqref{dual} with $g:= \wh - \wH$.
  Putting $\vp:=\wh - \wH$ in \eqref{cons}, using \eqref{anal2} and \eqref{cont2}, we have
  \begin{align}
    \label{anal5}
    \normP{\wh - \wH}{L^2(\Om)}{2}  &=  \Ah(\wh - \wH,\z)
    =  \Ah(\wh - \wH,\z - \Pi_0\z) \\ &
    \lesssim \dg \wh-\wH\dg\,\norm{\z - \Pi_0\z}{\sigma}, \notag 
  \end{align}
  where $\Pi_0\z$ is the projection of $\z$ in $\SHP$. The approximation bound
  \eqref{approx}, the first estimate in \eqref{anal3}
  and the bound of $\norm{z}{\HH^2(\Om)}$ gives the second estimate in \eqref{anal3}.
  %since $\Ah(\wh - \wH,\wh-\wH)\leq \Ah(\wh - \wH,\wh-\wH)$. 
\end{proof}

\begin{lemma}
  \label{lem2}
  Let $\uh\in\Shp$ and $\uh\in\range (I - \PPN)$.
  %Let $\uH=\PPN\uh$ be its projection given by \eqref{anal0}.
  Then   $\uh - \PPN\uh = \uh$ and 
  \begin{align}
    \label{anal3a}
    %\dg \wh - \wH \dg \lesssim  \dg \wh \dg, \qquad
    \norm{\uh}{L^2(\Om)} \lesssim  \frac{H}{q} %k_1^{1/2} \Ah(\uh,\uh)^{1/2}   %
    \dg \uh \dg.
  \end{align}
\end{lemma}
\begin{proof}
  As $\uh\in\range (I - \PPN)$, %there exists $\wh\in\Shp$
  %such that
  then $\uh = \wh-\PPN\wh$ for some $\wh\in\Shp$. Hence,
  \begin{align*} 
    \uh - \PPN\uh = (\wh-\PPN\wh) - \PPN(\wh-\PPN\wh) 
    = \wh - \PPN\wh = \uh
  \end{align*}
  since $\PPN^2=\PPN$, cf.~\eqref{proj2}.
  Moreover, estimate \eqref{anal3a} follows directly from \eqref{anal3}.
\end{proof}


\smaz{
  
In the following analysis we will be using the following definition of jump parameter $\restr{\sigma}{\gamma} = {C_W \pg^2}/{\hg},\ \gamma \in \FhID$, and we use the DG-norm defined as follows
\begin{align}
  \label{DGnorm1}
    \dg \vh \dg^2 = \hsn{\nabla \vh}^2 + \sumfh \sigma \normP{ \jump{\vh}}{\Lt{\gamma}}{2}.
\end{align}
To avoid confusion in the text we use also the generalization jump parameter as follows $\sbar = {C_W p^2}/{h}$, where $p = \max_{K \in \Th} \pK$ and $h = \min_{K \in \Th} \hK$. We also use the following properties of the bilinear form $\Ah$. The proof of these properties can be found in \cite{DGM-book}.
For all $\uh,\, \vh \in \Shp$ we have
\begin{align}\label{cont}
    \Ah (\uh,\vh) & \lesssim 2 C_\sigma k_1 \dg \uh \dg \, \dg \vh \dg \\
    \Ah (\vh,\vh) & \gtrsim \frac{k_0}{2} \dg \vh \dg^2
\end{align}
We will also need the following norms defined as
\begin{align}
    \Vert v \Vert_{\Lt{\FhI}}^2 & = \sumfh \Vert v \Vert_{\Lt{\gamma}}^2, \\
    \Vert v \Vert_{\Lt{\Omega}}^2 & = \sumck \Vert v \Vert_{\Lt{\cK}}.
\end{align}
To exploit the approximation of $\vh \in \Shp$ by an $H^1$-function as in \cite{AntoniettiALL_IJNAM16}, we introduce the discrete operator $\Grh (\vh)$ defined by the following
\begin{align}\label{gradgh}
    \Grh(\vh) = \nabla \vh - \sumfh \lift (\jump{\vh}),
\end{align}
where $\lift \, : L^2 (\gamma) \rightarrow [P_p (\cK_\gamma)]^d$, is the lifting operator defined in \cite{hp_robust} as follows
\begin{align}\label{lift_op}
    \int_{\cK_\gamma} \lift (\jump{\vh}) \cdot \bm{w} \dx = \int_{\gamma} \aver{\bm{w}} \cdot \ngam \jump{\vh} \dS    \qquad \forall \bm{w} \in [P_p(\cK_\gamma)]^d
\end{align}
and $\cK_\gamma$ denotes the elements of the %nonmatching
 mesh $\Th$ sharing the edge $\gamma$. More on the lifting operator can be found in \cite{DGM-book}.
For the lifting operator we have the following bound
\begin{lemma}
    For any $\vh \in \Shp$ we have 
    \begin{align}\label{liftbound}
        \Vert \lift (\jump{\vh}) \Vert_{\Lt{\cK_\gamma}} \lesssim  \sigma \Vert \jump{\vh} \Vert_{\Lt{\gamma}}
    \end{align} 
\end{lemma}
\begin{proof}
    Let $\bm{w} = \lift (\jump{\vh}) $, then we have the following
    \begin{align}
        \Vert \lift (\jump{\vh}) \Vert_{\Lt{\cK_\gamma}}^2 & = \int_{\cK_\gamma} \lift (\jump{\vh}) \cdot \lift (\jump{\vh}) \dx = \int_{\gamma} \aver{\lift (\jump{\vh})} \cdot \ngam \jump{\vh} \dS \notag \\ 
        & \lesssim \sigma^{-1} \Vert \aver{\lift (\jump{\vh})} \Vert_{\Lt{\gamma}} \sigma \Vert \jump{\vh} \Vert_{\Lt{\gamma}} \\
        & \lesssim \frac{\hg}{{\pg}^2 \cW} \Vert \lift (\jump{\vh}) \Vert_{\Lt{\gamma}} \sigma \Vert \jump{\vh} \Vert_{\Lt{\gamma}} \notag \\ 
        & \lesssim \frac{1}{\cW} \Vert \lift (\jump{\vh}) \Vert_{\Lt{\cK_\gamma}}\sigma \Vert \jump{\vh} \Vert_{\Lt{\gamma}},
    \end{align}
    where we used the Cauchy-Schwarz inequality, bound of the norm of a jump on the edge and the multiplicative trace inequality and inverse inequality from \cite{DGM-book}.
\end{proof}
Hence we can sum over all edges and get the following result for $\vh \in \Shp$
\begin{align}\label{liftboundsum}
    \Vert \sumfh \lift (\jump{\vh}) \Vert_{\Lt{\Omega}} \lesssim \sumfh \Vert \lift (\jump{\vh}) \Vert_{\Lt{\Omega}} \lesssim \Vert\sigma^{1/2} \jump{\vh} \Vert_{\Lt{\FhI}}.
\end{align}
We exploit approximation result, which demonstrates that any function $\vh \in \Shp$ can be approximated by $H^1$-function. This was presented in \cite{AntoniettiALL_IJNAM16}, where this result was used in the analysis of additive Schwarz preconditioner.   
First we define the following problem: for given $\vh \in \Shp$ find $\hh{\vh} \in H^1 (\Omega)$, $\hh{\vh} = \nabla \vh$ on $\Gamma_D$ such that
\begin{align}\label{variant:iii}
    \int_{\Omega} \nabla \hh{\vh} \cdot \nabla w \, \mathrm{d}x = \int_{\Omega} \Grh (\vh) \cdot \nabla w \, \mathrm{d}x \quad \forall w \in H_0^1 (\Omega),
\end{align}
where $\Grh$ is the operator defined in \eqref{gradgh}. We should mention, that $\hh{\vh}$ is not a element of $\Shp$, however, we show that this function possesses good approximation properties, that we can later exploit. 
\begin{lemma}
    Let $\Omega \subset \mathbb{R}^d$ be a bounded polyhedral convex domain. For given $\vh \in \Shp$ let the approximant $\hh{\vh}$ be as defined above. Then the following holds
    \begin{align}
        \Vert \vh - \hh{\vh} \Vert_{\Ldo} &\lesssim \frac{h}{p}\Vert \sigma^\frac{1}{2} \jump{\vh} \Vert_{L^2(\FhI)},  \\ 
        \vert \hh{\vh} \vert_{H^1(\Omega)} &\lesssim \dg \vh \dg.
    \end{align}
\end{lemma}

\begin{proof}
    %\tom{Je potreba dodelat!!!!!}

    First we assume that $\Omega$ is convex domain. Then there exists function $\vp \in H^2 (\Omega) \cap H_0^1 (\Omega)$, that is the solution of dual problem defined as 
    \begin{align}
      - \triangle \vp & = \vh - \hh{\vh} \quad \mathrm{in } \Omega \\
      \vp & = 0   \qquad \mathrm{on } \partial \Omega. 
    \end{align}
    Moreover we immediately have the bound $\Vert \vp \Vert_{H^2(\Omega)} \lesssim \Vert \vh - \hh{\vh} \Vert_{\Lt{\Omega}}$.
    Using the integration by part, we deduce that
    \begin{align}
        \Vert \vh - \hh{\vh} \Vert_{\Lt{\Omega}}^2 & = \int_{\Omega} (\vh - \hh{\vh}) \triangle \vp \dx \notag \\
        & = \sumck \int_{\cK} \nabla (\vh - \hh{\vh}) \nabla \vp \dx - \sumfh \int_{\gamma} \nabla \vp \cdot \jump{\vh} \dS \notag \\ 
        & = \sumck \int_{\cK} (\Grh(\vh) - \hh{\vh} ) \cdot \nabla \vp \dx - \sumfh \int_\gamma \nabla \vp \cdot \jump{\vh} \dS \notag \\ 
        & + \sumfh \int_{\cK_\gamma} \lift (\jump{\vh}) \cdot \nabla \vp \dx.
    \end{align}
    Using the definition of $\hh{\vh}$ we know, that the first term is equal to zero. Using \eqref{variant:iii} and the definition of lift operator \eqref{lift_op}, we get $\forall \vp_h \in \Shp$
    \begin{align}
         - \sumfh \int_\gamma & \nabla \vp \cdot \jump{\vh} \dS + \sumfh \int_{\cK_\gamma} \lift (\jump{\vh}) \cdot \nabla \vp \dx \notag \\
        & = - \sumfh \int_\gamma \nabla \vp \cdot \jump{\vh} \dS + \sumfh \int_{\cK_\gamma} \lift (\jump{\vh}) \cdot \nabla \vp \dx \notag \\ 
        & \pm \sumfh \int_{\cK_\gamma} \lift (\jump{\vh}) \cdot \nabla \vp_h \dx \notag \\
        & = - \sumfh \int_\gamma \nabla \vp \cdot \jump{\vh} \dS + \sumfh \int_{\cK_\gamma} \lift (\jump{\vh}) \cdot (\nabla \vp - \nabla \vp_h) \dx \notag \\
        & + \sumfh \int_{\cK_\gamma} \lift (\jump{\vh}) \cdot \nabla \vp_h \dx .
    \end{align}  
    Selecting $\vp_h$ as the $L^2$ projection, i.e. $\vp_h = \Pi_h \vp$ we can use the interpolation bound and get following
    \begin{align}
        \sumfh \int_{\cK_\gamma} \lift (\jump{\vh}) \cdot (\nabla \vp - \nabla \vp_h) \dx \lesssim \frac{h}{p} \Vert \vp \Vert_{H^2(\Omega)} \Vert\sigma^{1/2} \jump{\vh} \Vert_{\Lt{\FhI}}.
    \end{align}
    For the remaining term we use the fact, that $\vp \in H^2(\Omega)$, hence $\aver{\nabla \vp} = \nabla \vp$ for all edges. Hence, using the definition of $\lift$ we get
    \begin{align}
        & - \sumfh \int_\gamma \nabla \vp \cdot \jump{\vh} \dS + \sumfh \int_{\cK_\gamma} \lift (\jump{\vh}) \cdot \nabla \vp_h \dx \notag \\ 
        & =  - \sumfh \int_\gamma \aver{\nabla \vp} \cdot \jump{\vh} \dS + \sumfh \int_\gamma \aver{\nabla \vp_h} \cdot \jump{\vh} \dS  \notag \\
        & = \sumfh \int_\gamma \aver{\nabla \vp_h - \nabla \vp} \cdot \jump{\vh} \dS \lesssim \frac{h}{p} \Vert \vp \Vert_{H^2(\Omega)} \Vert\sigma^{1/2} \jump{\vh} \Vert_{\Lt{\FhI}}.
    \end{align}
    The last inequality we get using the $L^2$ projection $\vp_h = \Pi_h \vp$. Finally, from the bound $\Vert \vp \Vert_{H^2(\Omega)} \lesssim \Vert \vh - \hh{\vh} \Vert_{\Lt{\Omega}}$ we can get the result
    \begin{align}
        \Vert \vh - \hh{\vh} \Vert_{\Ldo} &\lesssim \frac{h}{p}\Vert \sigma^\frac{1}{2} \jump{\vh} \Vert_{L^2(\FhI)}.
    \end{align}

    To prove the other result we first show that
    \begin{align}
        \vert \hh{\vh} \vert_{H^1(\Omega)} \leq \Vert \Grh (\vh) \Vert_{\Lt{\Omega}}.
    \end{align}
    This result easily follows from \eqref{variant:iii}, using $\bm{w} = \hh{\vh}$ and the Cauchy-Schwarz inequality. %\tom{Potreba odhadnout pomoci DG normy} 
    Moreover, using the definition of $\Grh$ we have
    \begin{align}\label{grbound}
        \Vert \Grh (\vh) \Vert_{\Ldo} \leq \vert \vh \vert_{H^1(\Omega)} + \Vert \sumfh \lift (\jump{\vh})\Vert_{\Ldo}. 
    \end{align}
    Now using the \eqref{liftboundsum} we get
    \begin{align}\label{liftboundeq}
        \Vert \sumfh \lift (\jump{\vh})\Vert_{\Ldo} \lesssim  \Vert \sigma^{1/2} \jump{\vh} \Vert_{\Lt{\Fh}}.
    \end{align}
    Putting \eqref{grbound} and \eqref{liftboundeq} together we get 
    \begin{align}
        \vert \hh{\vh} \vert_{H^1(\Omega)} &\lesssim \dg \vh \dg.
    \end{align}
    
\end{proof}

Now we can look at the approximation properties of the coarse function $\vhh$, that is the coarse solution in the two level domain decomposition technique. 
\begin{lemma}
    \label{vH_Bounds}
    Let $\vh \in \Shp$, then there exists $\vhh \in \SHHP$ such that the following inequalities holds
    \begin{align}
        \Vert \vh - \vhh \Vert_{\Ldo} & \lesssim \frac{H}{q} \dg \vh \dg \\
        \vert \vh - \vhh \vert_{\HTh} & \lesssim \dg \vh \dg. %\notag
    \end{align} 
\end{lemma}
Proof of this lemma can be found in \cite{AntoniettiALL_IJNAM16}.

}

Finally, we employ the following auxiliary lemmas.
%, that we use to proof the assumption needed for condition number bound. %These lemmas and their proof can be found in \tom{cite}.
\begin{lemma}[\cite{AntoniettiHouston_JSC11}, Lemma~4.2]
    \label{stable_aux_lemma}
    Let $u \in \Shp$ such that it has a unique decomposition $u = \sum_{i=1}^{N} \RiT u_i$
    with $u_i \in \Ship$. Then %, we then have the following upper bound
    \begin{align}
      \bigg\lvert \sum_{\substack{i,j = 1, i \neq j}}^N \Ah(\RiT u_i, \RjT u_j) \bigg\rvert
      \lesssim %k_1
      \bigg( \dg u \dg^2 + \sbar \sum_{\cK \in \ThH}\Vert u \Vert_{\Ldk}^2 \bigg).
    \end{align}
\end{lemma}

\begin{lemma}
  \label{trace_ineq}
  For any $\vh \in \Shp$, we have the following inequality
%  \begin{align}
%    \label{trace}
%    \sum_{\cK \in \ThH} \normP{\vh}{\Ldk}{2} \lesssim  & \snorm{\vh}{\HTh} \norm{\vh}{\Ldo}
%    + \frac{1}{H} \normP{\vh}{\Ldo}{2} \notag \\
%    & + \left( \sum_{\cK \in \ThH} \sum_{\substack{\gamma \in \FhI  \gamma \subset \cK}}
%    \sbar \normP{\jump{\vh}}{\Lf}{2} \right)^{1/2} \norm{\vh}{\Ldo}.
%  \end{align}
\begin{align}
  \label{trace1}
  \sum_{\cK \in \ThH} \normP{\vh}{\Ldk}{2} \lesssim  &  \dg \vh\dg  \norm{\vh}{\Ldo}
  + \frac{1}{H} \normP{\vh}{\Ldo}{2}, \quad \vh\in\Shp.
\end{align}
\end{lemma}
\begin{proof}
  The proof is a direct consequence of \cite[Lemma~5]{Smears_JSC18}.
\end{proof}
%From \eqref{DGnorm} and \eqref{trace}, we deduce



\smaz{

\begin{lemma}{Friedrich-Poincare inequality}\label{FriPoin:Ineq} Let $M \subset \Omega$ be an open connected polyhedral domain such that $M$ is an union of elements from $\Th$. Let the diameter of $M$ be $H_M$. Then for any function $v \in H^1(\Omega,\Th)$ the following holds
    \begin{equation}
    \label{eq:FP}
        \Vert v \Vert_{0,M}^2 \leq C H_M^2 \left( \sum_{\substack{K \in \mathcal{T}_h \\ K \subset M}} \vert v \vert_{1,K}^2 + \sum_{\substack{\gamma \in \FhI \\ \gamma \subset M}} \Vert h_\gamma^{-\frac{1}{2}} \left[ v \right] \Vert_{0,\gamma}^2 + \sum_{\substack{\gamma \in \FhI \\ \gamma \subset \partial M}} \Vert h_\gamma^{-\frac{1}{2}} v \Vert_{0,\gamma}^2 \right),
    \end{equation} 
        where $C > 0$. Moreover if  $v$ has a zero average over $M$, then we have
        \begin{equation}
    \label{eq:FP2}
            \Vert v \Vert_{0,M}^2 \leq C H_M^2 \left( \sum_{\substack{K \in \mathcal{T}_h \\ K \subset M}} \vert v \vert_{1,K}^2 + \sum_{\substack{\gamma \in \FhI \\ \gamma \subset M}} \Vert h_\gamma^{-\frac{1}{2}} \left[ v \right] \Vert_{0,\gamma}^2 \right)
        \end{equation}
    
\end{lemma}
}

\subsection{Main theoretical results} We derive a bound of the preconditioned operator
using the approach from \cite{ToselliWidlund-DD05}.
%for an abstract hybrid Schwarz preconditioner
%employing
The following three assumptions are required.
%It is based on
%Before moving to the theorem dealing with the condition number bound of the hybrid Schwarz method we need to state 3 assumption needed. These assumptions are taken from the book \cite[Assumption 2.12, 2.3 and 2.4]{ToselliWidlund-DD05}. These assumptions need to be proven for the proof of the theorem in the book to hold. This is easy for the first two assumptions.

\begin{assumption}{(Local stability)}\label{assum1}
    There exists a constant $\omega$, $0 \leq \omega \leq 2$, such that
\begin{alignat*}{1}
\begin{split}
  \Ah (\RiT u_i,\RiT u_i) & \leq \omega \Ahi (u_i,u_i) \quad \forall u_i \in \Ship,
  \ \ i = 0, \dots ,N.
%    \Ah (\RNT u_0,\RNT u_0) &\leq \omega \AhN (u_0,u_0) \quad \forall u_0 \in \SHP .
\end{split}
\end{alignat*}
\end{assumption}

\begin{assumption}{(Strengthened Cauchy-Schwarz inequalities)}\label{assum2}
    There exist constants $0 \leq \ve_{ij} \leq 1$, $i,j = 1, \dots ,N$, such that 
\begin{equation*}
  \vert \Ah (\RiT u_i,\RjT u_j) \vert \leq \ve_{ij}
  \Ah (\RiT u_i,\RiT u_i)^{1/2} \Ah (\RjT u_j,\RjT u_j)^{1/2}, \quad i,j = 1, \dots N,
\end{equation*}
for all $u_i \in \Ship$, $u_j \in \Shjp$. By $\rho(\bve)$ we denote the spectral radius of
$\bve = \{ \ve_{ij} \}_{i,j = 1}^N$.
\end{assumption}

\begin{assumption}{(Stable decomposition)}\label{assum3}
  There exists a constant $\Co$, such that  any
  $u \in \range(I-\PPN)$ admits the decomposition $u = \sum_{i=1}^{N} \RiT u_i, \, u_i \in \Ship$ that satisfies
\begin{align}
  \label{eq:assum3}
  \sum\nolimits_{i=1}^{N} \Ahi(u_i,u_i) \leq \Co \Ah (u,u).
\end{align}
\end{assumption}

%Under the Assumptions~\ref{assum1}--\ref{assum3} %, and the assumption of Local stability and the strengthened Cauchy-Schwarz inequalities,
%we can proof the following
The condition number bound of hybrid Schwarz preconditioner is the following.
%The proof can be found in \cite[Theorem 2.13]{ToselliWidlund-DD05}.
\begin{theorem}{\cite[Theorem 2.13]{ToselliWidlund-DD05}}
  \label{thm:1}
  Let Assumptions~\ref{assum1}--\ref{assum3} be satisfied.
  Then the condition number of the hybrid preconditioned operator \eqref{hyb3} satisfies
    \begin{align}
        \kappa(\mPhyb) \leq \max{ \{ 1,\Co \}} \max{ \{1,\omega \rho (\bve)\}},
\end{align}
where $\Co$, $\rho(\bve)$ and $\omega$ are constants from \eqref{assum3}, \eqref{assum2}
    and \eqref{assum1}, respectively. 
    % and the condition number of projected additive operator $ \projad $ satisfies
    % \begin{equation}
    %     \kappa (\projad) \leq \Co \omega \rho (\epsilon).
    % \end{equation}
\end{theorem}


Assumption~\ref{assum1} is valid due to \eqref{Ahi} with equality for $\omega = 1$.
Since $\Ah$ is symmetric and coercive, the inequality in
Assumption~\ref{assum2} gives $ \epsilon_{ij} = 1$
if $i=j$ or $\Om_i$ and $\Om_j$ are neighboring. Otherwise, $\epsilon_{ij} = 0$.
Then Assumption~\ref{assum2} is valid with $\rho(\bve)= \NS + 1$, where $\NS$ is the
maximum number of adjacent subdomains to any given subdomain in the domain decomposition.
Finally, we prove the last assumption.
\begin{lemma}
  \label{lem3}
  The estimate \eqref{eq:assum3} is fulfilled  with the constant
  \begin{align}
    \label{C0}
    \Co = C_\sigma %\frac{k_1}{k_0}
    \frac{H}{h} \frac{p^2}{q},
  \end{align}
  where
  $C_\sigma>0$ is independent of the mesh sizes $h$, $H$ and the polynomial degrees $p$, $q$.
  %and  the bounds $k_0$, $k_1$. 
\end{lemma}


%The constant $\Co$ has the following form
%$\Co = C_\sigma \frac{k_1}{k_0} \frac{H}{h} \frac{p^2}{q}.$ 
%%
%
%We now proof the last assumption, that is crucial for our condition number bound. This assumption will give us the dependency of the condition number on the mesh sizes $h, \,  H$, polynomial degrees $p, \, q$ and on the bounds $k_1, \, k_0$. 
\begin{proof}
    Let $u \in \range(I - \PPN)$ with the unique decomposition 
    $u = \sum_{i=1}^{N} \RiT u_i.$
    Hence, we can write the following identity
    \begin{align}
      \label{anal13}
      \Ah (u,u) = \sum_{i=1}^{N} \Ahi(u_i,u_i)
      + \sum_{\substack{i,j = 1,  i \neq j}}^{N} \Ah ( \RiT u_i, \RjT u_j).
    \end{align}
    The triangle inequality gives
    \begin{align}
      \label{anal14}
        \bigg\vert 
            \sum_{i=1}^{N} \Ahi(u_i,u_i)
        \bigg\vert
        \leq
        \vert \Ah (u,u) \vert + \bigg\vert
            \sum_{\substack{i,j = 1, i \neq j}}^{N} \Ah ( \RiT u_i, \RjT u_j)
         \bigg\vert.
    \end{align} 
    %Exploiting the continuity of the bilinear form $\Ah$ the first term on the right hand side can be bounded as $\vert \Ah (u,u) \vert \lesssim \dg u \dg^2$. Hence, we get 
    We bound the last term in \eqref{anal14} by Lemma~\ref{stable_aux_lemma} and get
    \begin{align}
      \label{anal15}
        \bigg\vert 
            \sum_{i=1}^{N} \Ahi(u_i,u_i)
        \bigg\vert
        \lesssim
        \vert \Ah (u,u) \vert + %k_1
        \bigg( \dg u \dg^2 + \sbar \sum_{\cK \in \ThH}\Vert u \Vert_{\Ldk}^2 \bigg).
    \end{align} 
    Moreover, using %\eqref{DGnorm},
    \eqref{coerc},
    \eqref{anal3a}, and \eqref{trace1}, we have
    \begin{align*}
      %\label{anal16}
      \dg u \dg^2 + \sbar \sum_{\cK \in \ThH} \normP{\u}{\Ldk}{2}
      %\lesssim  & \left(
      %\frac{H}{q} \left(\frac{k_1}{k_0}\right)^{1/2}   + \frac{H}{q^2} k_1 \right)  \Ah (u,u).
      \lesssim  \left(1 + \sbar \frac{H}{q}+ \sbar\frac{H^2}{H q} \right)  \dg \u \dg^2
      \lesssim \frac{p^2}{h} \frac{H}{q} \Ah(u,u),
    \end{align*}
    which together with \eqref{anal15} proves \eqref{C0}. 
    %% Finally, using \eqref{cont1}--\eqref{coerc}, we obtain from \eqref{anal15}--\eqref{anal16}
    %% the estimate
    %% \begin{align}
    %%   \label{anal17}
    %%     \left\vert 
    %%         \sum_{i=1}^{N} \Ahi(u_i,u_i)
    %%     \right\vert
    %%     \lesssim
    %%     \vert \Ah (u,u) \vert + \frac{k_1}{k_0} \Ah(u,u) +
    %%     k_1 \sbar \left(
    %%      \frac{H}{q} \left(\frac{k_1}{k_0}\right)^{1/2}   + \frac{H}{q^2} k_1 \right)
    %%     \Ah (u,u).
    %% \end{align} 
    %% which proves
    %% \eqref{C0}. \Vit{$ (k_1 / k_0)^3$ ???}
\smaz{

    Finally to bound the third term on the right hand side we use the trace inequality \ref{trace_ineq}. But first we need to add and subtract the $\RNT u_0$, where $u_0$ defined as in Lemma \ref{vH_Bounds}, and use the triangle inequality
    \begin{align}
        \Vert u - \RNT u_0 + \RNT u_0 \Vert_{\Ldk}^2 \leq \Vert u - \RNT u_0 \Vert_{\Ldk}^2 + \Vert \RNT u_0 \Vert_{\Ldk}^2.
    \end{align}
    Now using the trace inequality as defined in Lemma \ref{trace_ineq} on both terms, we get the following
    \begin{align}
        \sbar \sum_{\cK \in \ThH}\Vert u - \RNT u_0 \Vert_{\Ldk}^2 \lesssim & \sbar \vert u - \RNT u_0 \vert_{\HTh} \Vert u - \RNT u_0 \Vert_{\Ldo} + \sbar \frac{1}{H} \Vert u - \RNT u_0 \Vert_{\Ldo}^2 \notag \\
        & + \sbar \left( \sum_{\cK \in \ThH} \sum_{\substack{\gamma \in \FhI \\ \gamma \subset \cK}} \sbar \Vert \jump{u - \RNT u_0} \Vert_{\Lf}^2 \right)^{1/2} \Vert u - \RNT u_0 \Vert_{\Ldo} \notag \\
        & \lesssim \sbar \dg u \dg \frac{H}{q} \dg u \dg + \frac{\sbar}{H}\frac{H^2}{q^2}\dg u \dg^2 + 0 \lesssim \sbar \frac{H}{q}(1+\frac{1}{q})\dg u \dg^2
    \end{align}
    and
    \begin{align}
        \sbar \sum_{\cK \in \ThH}\Vert \RNT u_0 \Vert_{\Ldk}^2 & \lesssim \sbar \vert \RNT u_0 \vert_{\HTh} \Vert \RNT u_0 \Vert_{\Ldo} + \sbar \frac{1}{H} \Vert \RNT u_0 \Vert_{\Ldo}^2 \\
        & \lesssim \sbar H 2 \dg \RNT u_0 \dg^2 \lesssim \sbar H 2 \frac{k_1}{k_0} \dg u \dg^2,
    \end{align}
    where we use the \ref{FriPoin:Ineq} and the fact, that $\dg \RNT u_0 \dg^2 \lesssim \frac{k_1}{k_0} \dg u \dg^2$. Adding all together and using the coercivity of the form \eqref{cont}, we get the desired result.
}
\end{proof}


\begin{corollary}
  Theorem~\ref{thm:1} and Lemma~\ref{lem3} implies that 
  the condition number of the hybrid Schwarz operator \eqref{hyb3} satisfies
  \begin{align}
    \label{RES1}
    \kappa(\mPhyb) \lesssim \frac{H}{h}\,\frac{p^2}{q}\, (\NS + 1),
  \end{align}
  where $h$, $p$, $H$, $q$ are the discretization parameters and  $\NS$ is the maximum number of neighboring subdomains.
\end{corollary}

\begin{remark}
 The spectral bound of the additive Schwarz operator \eqref{repre2} is
 (cf.~\cite{AntoniettiALL_IJNAM16})
  \begin{align}
    \label{RES2}
    \kappa(\mPadd) \lesssim \frac{H}{h}\,\frac{p^2}{q}\, (\NS + 2).
  \end{align}
  In practice, the constant $\NS$ is usually between 7 and 12.
  Hence, the bound \eqref{RES1} of
  the hybrid preconditioner is only slightly better than bound \eqref{RES2}
  of the additive one. They are the same in terms of $h$, $H$, $p$, and $q$.
\end{remark}


%%% Local Variables: 
%%% mode:latex
%%% TeX-master: "paper"
%%% End: 



\subsection{Computational costs}

Finally, we discuss the computational costs of an iterative solver employing the presented
preconditioners. 
The most expensive part
of Algorithms~\ref{alg:ASM}--\ref{alg:ASM3} is the performance of the preconditioner,
which exhibits the solution of the local (fine) systems and the global (coarse) one
\begin{align}
  \label{flops0}
  \mA_{i} \bky_i = \bkx_i,\quad i=1,\dots,N,\qquad \mbox{and} \qquad
  \mA_{0} \bky_0 = \bkx_0,
\end{align}
respectively. These systems are usually solved by a direct method,
e.g., MUMPS library \cite{MUMPS,MUMPS1,MUMPS2}.
%  $  \mA_{i} \bky_i = \bkx_i$ for $i=1,\dots,N$ and the coarse global one $\mA_{0} \bky_0 = \bkx_0$
%which are solved directly by a factorization.
For simplicity, we neglect the other parts of the computation, such as applications of
the prolongation and restrictions operators or the multiplication of a vector by
the (total) matrix $\mA$ which is executed in iterative solvers.
Moreover, we assume that
we have enough computer cores and that
each algebraic system from \eqref{flops0}
is solved by one core
so that all independent algebraic systems can be solved in parallel. 
We measure computational costs by
\begin{enumerate}[label=({\roman*})]
\item $\Fl$ -- the maximum of the number of {\em floating point operations} per one core,
  %of the preconditioners
  %over all cores,
\item $\comm$ -- the number of {\em communication operations} between a core and other ones.
\end{enumerate}


%% \begin{figure} [t]
%%   \begin{center}
%%     \includegraphics[width=0.47\textwidth]{Figs_flops/flopsF1.pdf}
%%     \includegraphics[width=0.47\textwidth]{Figs_flops/flopsC1.pdf}
%% \end{center}
%%   \caption{Number of the floating point operations for the matrix factorization:
%%     dependence of ($\flfac(n) / n^{3/2}$) vs. the system size $n$ corresponding to
%%     triangular (left) and polygonal (right) grids.}
%%   \label{fig:flops}
%% \end{figure}
%% \begin{figure} [t]
%%   \begin{center}
%%     \includegraphics[width=0.48\textwidth]{Figs_flops/flopsF3.pdf}
%%     \includegraphics[width=0.48\textwidth]{Figs_flops/flopsC3.pdf}
%% \end{center}
%%   \caption{Number of the floating point operations for the solution assembling:
%%     dependence of ($\flass(n) / n^{5/4}$)  vs. the system size $n$ corresponding to
%%     triangular (left) and polygonal (right) grids.}
%%   \label{fig:flops2}
%% \end{figure}

\subsubsection{Floating point operations}

The solution of each linear algebraic system from \eqref{flops0} by MUMPS has two steps:
\begin{enumerate}[label=({\arabic*})]
\item the {\em factorization} of the system, which is carried out using $\flfac(n)$
  floating point operations, where $n$ denotes the size of the system,
\item the {\em assembling} of the solution using $\flass(n)$ floating point operations.
\end{enumerate}
The factorization is performed only once before the start of the iterative solver, whereas
the assembling is performed at each solver iteration.
Both values $\flfac$ and $\flass$ are provided by MUMPS.

%% \begin{remark}
%%   For curiosity, we present Figures~\ref{fig:flops} and \ref{fig:flops2}, which show the dependence of the values $\flfac(n)/n^{3/2}$ and $\flass(n)/n^{5/4}$ on $n$, respectively, for systems corresponding to several triangular (fine local systems) and polygonal (coarse global systems) grids and polynomial degrees.
%%   These results indicate the asymptotic dependence $\flfac(n) \sim n^{3/2}$ and $\flass(n) \sim n^{5/4}$.
%%   More detailed inspection leads to the conjecture that $\flfac(n) \sim ((p+1)(p+2)m)^{3/2}$, and $\flass(n) \sim ((p+1)(p+2)m)^{5/4}$ where $m$ is the number of mesh elements and $p$ the degree of polynomial approximation.
%%   Figures~\ref{fig:flops} and \ref{fig:flops2} indicate that factorization requires about almost 20 times the number of operations than solution assembling.
%%   We note that these expressions are not used in the numerical experiments in
%%   Section~\ref{sec:numer} since $\flfac(n)$ and $\flass(n)$ are provided directly by MUMPS.
%% \end{remark} 

We estimate the maximum of the number of floating-point operations per one core of the
iterative solver.
Let $n_i:= \dim\Ship$, $i=1,\dots,N$ denote the dimension of the local spaces \eqref{Ship}
and similarly $n_0:=\dim\SHP$, cf.~\eqref{SHP}.
The {\em factorization} of matrices  $\mA_i\in\R^{n_i\times n_i}$ can be carried out independently for
each $i=0,\dots,N$, so the maximum of the number of floating point operations per core is 
\begin{align}
  \label{flops1}
 \FFfac := \max\nolimits_{i=0,\dots,N} \flfac(n_i).
\end{align}

The {\em assembling} of the solutions of the local systems and the global coarse one
can be executed in parallel only for the additive preconditioner $\mNadd^{-1}$.
For the hybrid preconditioner  $\mNhyb^{-1}$, we solve the local systems in parallel
and (twice) the global system sequentially. Hence, the corresponding
maximum of the number of floating point operations per core for assembling is
\begin{align}
  \label{flops2}
  \FFass :=
  \begin{cases}
    \max_{i=0,\dots,N} \flass(n_i) & \mbox{ for } \mNadd^{-1},\\
    \max_{i=1,\dots,N} \flass(n_i)  + 2 \flass(n_0) & \mbox{ for } \mNhyb^{-1},\\
  \end{cases}
\end{align}
at each solver iteration. Let $\iter$ denote the number of iterations of the iterative solver then,
using \eqref{flops1}--\eqref{flops2}, the maximum of the  number of floating point operations
per one core is
\begin{align}
  \label{flops3}
  \Fl :=\FFfac + \iter\, \FFass.
\end{align}
%This value does not depend on the number of subdomains $N$ since we assume a sufficient number
%of cores such that each $\Om_i$ can be treated in parallel.

\subsection{Communication operations} 

We are aware that the following considerations exhibit a significant simplification and that
the number of the communication operations strongly depends on the implementation. We assume that
all vectors appearing in the computations are stored in copies at each computer core and that
each matrix $\mA_i$, $i=0,\dots,N$ is allocated only at one processor. However, for the
hybrid operator case, we assume that the ``coarse'' matrix $\mA_0$ is stored in copies at each
core. This causes a (small) increase of the memory requirements, but
the same coarse global problem can be solved at each core, which keeps
the maximum of the floating point operations whereas reduces the communication among
the cores.

Therefore,
all communication operators among the cores are given by the distribution of the solution of local
problems, i.e., the vectors of size approximately $n/N$, $n$ is the size of $\mA$ and
$N$ is number of cores. Hence, each core communicates with the other $N-1$ cores and then
 the number of {\em communication operations} per one core can be estimated by
\begin{align}
  \label{comm5}
  \comm =  \iter \,{n}\, (N-1)/{N}, % =  \iter(N-1)n,
\end{align}
where $\iter$ is the number of iterations of the iterative solver.
%In contrary to the floating-point iterations, the number of communications is increasing with the
%number of subdomains (= number of used cores).

We remind that both \eqref{flops3} and \eqref{comm5} have only an informative character since
some parts of the iterative solvers (multiplication by $\mA$,  application of $\mRi$, $\mRiT$)
are not considered. Nevertheless, they provide additional information related to the computational
costs.

\section{Numerical examples}
\label{sec:numer}

In this section, we present the numerical study of the convergence of the preconditioners
presented in Section~\ref{sec:DDM}.
The aims is to show
\begin{itemize}
\item the {\em weak scalability} of the iterative methods, i.e,
 the computational costs are ideally
 constant for a fixed ratio between the size of the problem and the number of computer cores, 
\item the comparison of efficiency of the additive and hybrid Schwarz preconditioners.
\end{itemize}
Therefore, we performed computations using a sequence of (quasi) uniform
meshes with increasing numbers of elements $\#\Th$ and
the number of subdomains $N$ is chosen such that the number of elements
within each $\Om_i$, $i=1,\dots,N$ is (approximately constant). Namely we keep the
ratio $\#\Th/N\approx 100$ and $\#\Th/N\approx \numf{1000}$.
The coarse mesh $\ThH$ is chosen such that each $\cK$ is just one
subdomain $\Om_i$, $i=1,\dots,N$ or each $\Om_i$ is divided into several $\cK$.

Linear systems \eqref{alg1} are solved using the conjugate gradient (CG) method with
the preconditioners $\mNadd^{-1}$ and $\mNhyb^{-1}$ given by \eqref{repre2}
and \eqref{hyb4}, respectively.
The CG algorithm is stopped when the relative preconditioned residual $\rrel$ fulfills
\begin{align}
  \label{alg:stop}
  \rrel^\ell := \| \mN^{-1}(\mA \bku^\ell - \bkg)\|/ \| \mN^{-1}(\mA \bku^0 -\bkg)\| \leq \TOL,
\end{align}
where $\mN^{-1}$ denotes a preconditioner and $\TOL>0$ is the prescribed user tolerance.
We employ $P_p$, $p=1,2,3$ polynomial approximations for each case.

\subsection{Laplace problem}
\label{sec:lapl}
First, we consider a simple toy example 
\begin{align}
  \label{lapl}
  -\Delta u = -2x_1(1-x_1) - 2x_2(1-x_2) \qquad \mbox{in } \Om=(0,1)^2, 
\end{align}
with the homogeneous Dirichlet boundary condition on $\Gamma$ which gives the exact solution
$u=x_1(1-x_1)x_2(1-x_2)$. %We perform the computations using a sequence of 6 uniform meshes.
The initial approximation $\bku^0$ corresponds to a highly oscillating function
(namely $u=\sum_{i,j=1}^3 \sin(2\pi i x_1) \sin(2\pi j x_2)$) in order to avoid
a possible superconvergence due to the presence of particular frequency modes, cf.
\cite{GanderTalk}. We set $\TOL=10^{-12}$ in \eqref{alg:stop}.

The results achieved are given in Tables~\ref{tab:Lapl}--\ref{tab:Lapl3}, where we present
\begin{itemize}
  \renewcommand\labelitemi{--}
\item $\#\Th$ -- the number of elements of the fine mesh,
\item $N$ -- the number of subdomains $\Om_i$ generated by METIS \cite{metis},
\item  $\#\Thi:=\#\Th/N$ -- the average number of elements in $\Om_i$, $i=1,\dots,N$,
\item $\#\ThH$ -- the number of elements of the coarse  mesh,
\item $\iter$ -- the number of (preconditioned) CG iterations necessary to achieve \eqref{alg:stop},
\item  $\MFl$ -- the number of floating point operations given by \eqref{flops3},
  $\MFl = 10^6\Fl$,
\item  $\Mcomm$ -- the number of communication operations given by  \eqref{comm5}, $\Mcomm = 10^6\comm$.
\end{itemize}
Table~\ref{tab:Lapl} shows the results corresponding to
$\#\Th/N = \#\Thi\approx 100$ and
each subdomain $\Om_i$, $i=1,\dots,N$ is just one element $\cK\in\ThH$.
Furthermore, Table~\ref{tab:Lapl2} contains the results with
$\#\Th/N = \#\Thi\approx 1000$ and each subdomain $\Om_i$ consists of 1, 5, and 10
coarse elements $\cK\in\ThH$. 

Moreover, Table~\ref{tab:Lapl3} presents the results for the finest mesh $\Th$ having
$\numf{32768}$ elements, the number of sub-domains is $N=8,\ 16,\ 32,\ 64$, and
the number of elements of the coarse mesh is fixed to 128
(however, the coarse meshes are not the same due to kind of construction).
Finally, Figure~\ref{fig:Lapl} shows the convergence of the CG method
for the setting from Table~\ref{tab:Lapl}, 
namely the dependence of $\rrel^\ell$ with respect to $\ell=0,1,\dots$, cf.~\eqref{alg:stop}.
We observe the following.
\begin{itemize}
%\begin{compactitem}
\item Tables~\ref{tab:Lapl}--\ref{tab:Lapl2}:
  For each particular $p$ and particular preconditioner, the number of CG iterations is almost
  constant for increasing $\#\Th$, which implies the weak scalability of both preconditioners
  provided that the computational costs of the coarse solver are neglected.
  This is not the case for the finer meshes in Table~\ref{tab:Lapl} where $\#\ThH > \#\Thi$ and thus the number of $\Fl$ increases for the increasing size of the problem.
  However, the results of Table~\ref{tab:Lapl2}, when $\#\ThH \ll \#\Thi$, support the scalability in terms of $\Fl$.
\item Table~\ref{tab:Lapl3}: When  $\#\ThH$ and $\#\Thi$ are fixed
  (i.e.,  $h$ and $H$ are fixed too),
  we observe a slight increase in the number of $\iter$ for an increasing number
  of subdomains $N$. Consequently, the number of $\Fl$ is reducing by
  factor at least two
  since the parallelism can be employed more effectively. On the other hand,
  the number of communication operations $\comm$ is slightly increasing.
  So, the optimal choice of the number of subdomains is open and it will be the subject of further
  research.
\item Tables~\ref{tab:Lapl}--\ref{tab:Lapl3}:
the performance of the hybrid preconditioner $\mNhyb^{-1}$ saves about 25 -- 30\% of the CG iterations compared to the additive preconditioner $\mNadd^{-1}$.
  The value 25 -- 30\% also exhibits a potential benefit in computational time if the computational costs of the coarse solver are negligible (e.g., $N \ll \#\Th/N$).
\item  Figure~\ref{fig:Lapl}: All graphs showing the convergence of the residual with respect to the
  number of CG iterations support the scalability of the methods. Moreover,
for the $P_2$ and $P_3$ approximation, we observe that the tolerance level $\TOL=10^{-6}$ in \eqref{alg:stop} is achieved using the smaller number of CG iterations for the increasing size of the problem.
\end{itemize}
%\end{compactitem}

\begin{table}
  \caption{Laplace problem \eqref{lapl}, convergence of CG method with preconditioners
    $\mNadd^{-1}$ and $\mNhyb^{-1}$, the subdomains splitting $\#\Th/N\approx100$.}
  \label{tab:Lapl}
  \begin{center}
  %additive Schwarz preconditioner $\mNadd^{-1}$\\
    %\vertical{\footnotesize\hspace{-12mm} additive  $\mNadd^{-1}$}
  \input{Figs_Lapl/asm_conv_Lapl_CG_ASM_A1.tex}
  
  \vspace{2mm}
  
  %symmetric hybrid Schwarz preconditioner $\mNhyb^{-1}$\\
  %\vertical{\footnotesize\hspace{-12mm} hybrid $\mNhyb^{-1}$}
  \input{Figs_Lapl/asm_conv_Lapl_CG_ASM3_A1.tex}
  \end{center}
\end{table}

\begin{table}
\caption{Laplace problem \eqref{lapl}, convergence of CG method with preconditioners
    $\mNadd^{-1}$ and $\mNhyb^{-1}$, the subdomains splitting $\#\Th/N\approx\numf{1000}$.}
  \label{tab:Lapl2}
  %additive Schwarz preconditioner $\mNadd^{-1}$\\
  %\vertical{\footnotesize\hspace{-12mm} additive  $\mNadd^{-1}$}
  \input{Figs_Lapl/asm_conv_Lapl_CG_ASM_AA.tex}

  \vspace{2mm}
  
  %symmetric hybrid Schwarz preconditioner $\mNhyb^{-1}$\\
  %\vertical{\footnotesize\hspace{-12mm} hybrid $\mNhyb^{-1}$}
  \input{Figs_Lapl/asm_conv_Lapl_CG_ASM3_AA.tex}
\end{table}


\begin{figure}
  %additive Schwarz preconditioner $\mNadd^{-1}$ \\
  \vertical{\footnotesize\hspace{4mm} additive  $\mNadd^{-1}$}
  \includegraphics[width=0.31\textwidth]{Figs_Lapl/asm_conv_CG_ASM_P1_L1_a1.00E+00.pdf}
  \includegraphics[width=0.31\textwidth]{Figs_Lapl/asm_conv_CG_ASM_P2_L1_a1.00E+00.pdf}
  \includegraphics[width=0.31\textwidth]{Figs_Lapl/asm_conv_CG_ASM_P3_L1_a1.00E+00.pdf}

  \vspace{2mm}
  
  %symmetric hybrid Schwarz preconditioner $\mNhyb^{-1}$ \\
  \vertical{\footnotesize\hspace{4mm} additive  $\mNhyb^{-1}$}
  \includegraphics[width=0.31\textwidth]{Figs_Lapl/asm_conv_CG_ASM3_P1_L1_a1.00E+00.pdf}
  \includegraphics[width=0.31\textwidth]{Figs_Lapl/asm_conv_CG_ASM3_P2_L1_a1.00E+00.pdf}
  \includegraphics[width=0.31\textwidth]{Figs_Lapl/asm_conv_CG_ASM3_P3_L1_a1.00E+00.pdf}
  \caption{Laplace problem \eqref{lapl}, convergence of CG method
    ($\rrel^\ell$ for $\ell=0,1,\dots$, cf.~\eqref{alg:stop})  for preconditioners
    $\mNadd^{-1}$ and $\mNhyb^{-1}$ with the subdomains splitting $\#\Th/N\approx100$.}
  \label{fig:Lapl}
\end{figure}

\begin{table}
  \caption{Laplace problem \eqref{lapl}, convergence of CG method
    with preconditioners
    $\mNadd^{-1}$ and $\mNhyb^{-1}$ for the finest mesh using various domain decomposition.}
  \label{tab:Lapl3}
  %additive Schwarz preconditioner $\mNadd^{-1}$\\
  %\vertical{\footnotesize\hspace{-12mm} additive  $\mNadd^{-1}$}
  \input{Figs_Lapl/asm_conv_Lapl_CG_ASM_comp.tex}
  \vspace{2mm}
  
  %symmetric hybrid Schwarz preconditioner $\mNhyb^{-1}$\\
  %\vertical{\footnotesize\hspace{-12mm} hybrid $\mNhyb^{-1}$}
  \input{Figs_Lapl/asm_conv_Lapl_CG_ASM3_comp.tex}

\end{table}


\subsection{Alternator (linearized)}
\label{sec:alter}
This example exhibits a linearized variant of
the magnetic state in the cross-section of an alternator from Section~\ref{sec:alterN},
which originates from \cite{Glowinski74}.
The computational domain $\Om$ (one quarter of the alternator)
consists of the stator ($\Omega_s$) and the rotor ($\Omega_r$)
with a gap filled by air ($\Omega_a$);
see Figure~\ref{fig:alter_geom}, left, where the geometry of the domain is shown.
We consider problem \eqref{prob1a} with %$u_D = 0$ in \eqref{prob1b} on $\gomD$,
%$g_N=0$ in \eqref{prob1c} on $\gomN$,
$f =  5\cdot 10^{4}$ 
and $\K = \nu(x) \bI$ such that
\begin{align}
  \label{alter1}
  \nu(x) = 
  \begin{cases}
    \mu_0^{-1} & \mbox{ for } x\in \Om_a, \\
    \mu_1^{-1} &  \mbox{ for } x\in \Om_s\cup\Om_r, \\
  \end{cases}
\end{align}
where $\mu_0 =  1.256\cdot 10^{-6}$, $\mu_1 = \zeta \mu_0$, $\zeta > 1$. Particularly,
we use the values $\zeta=100$ and $\zeta=\numf{10000}$.
We prescribe %homogeneous Neumann boundary condition on
$\nabla u\cdot\bkn = 0$ on $\gomN:=(0,1)\times\{0\}\cup \{0\} \times (0,1)$ and
$u=0$  %the homogeneous Dirichlet boundary condition
on the rest of the boundary. %$\gomD:=\gom\setminus\gomN$(= the circular part).


Figure~\ref{fig:alter_geom}, center and right, shows the two examples of the used meshes
and the corresponding domain partition by METIS \cite{metis}. We note that this domain splitting
is not aligned with the material interfaces. Usually, it is not the optimal strategy, but
the presented experiments indicate a robustness of the algorithm with respect to the domain
splitting.
In the same way as in Section~\ref{sec:lapl},
we present the quantities $\#\Th$, $\#\Thi$,  $N$ and $\#\ThH$ together with 
the number of (preconditioned) CG iterations $\iter$ necessary to achieve \eqref{alg:stop}
(with $\TOL=10^{-10}$),
and the computational costs in $\MFl$ and $\Mcomm$.

Tables~\ref{tab:alter} and \ref{tab:alter2} show the results for
$\zeta = \mu_1/\mu_0=100$ in \eqref{alter1} for $\#\Th/N\approx\numf{100}$ and
$\#\Th/N\approx\numf{1000}$, respectively.
Moreover, Tables~\ref{tab:alter4} and \ref{tab:alter5} present results
corresponding to $\zeta=\numf{10000}$ for $\#\Th/N\approx\numf{100}$ and
$\#\Th/N\approx\numf{1000}$, respectively.
%Finally, Figure~\ref{fig:alter} shows the convergence of CG method for
%the setting from Table~\ref{tab:alter4}
%namely the dependence of $\rrel^\ell$ with respect to  $\ell=0,1,\dots$, cf.~\eqref{alg:stop}.

\begin{figure} [t]
  \begin{center}
    \includegraphics[width=0.31\textwidth]{Figs_alter0/alter_geom.pdf}
    \hspace{0.01\textwidth}
    \includegraphics[width=0.31\textwidth]{Figs_alter0/alter1000_DDM.pdf}
    \hspace{0.01\textwidth}
    \includegraphics[width=0.31\textwidth]{Figs_alter0/alter8000_DDM.pdf}
  \end{center}
  \caption{Linearized alternator, the computational domain $\Om$ with its components (left)
    and the computational meshes $\Th$ (red) and $\ThH$ (blue), with $\#\Th=1112$ \& $N=\#\ThH=11$
    (center) and   $\#\Th=7549$ \& $N=\#\ThH=75$ (right).}
  \label{fig:alter_geom}
\end{figure}



\begin{table}
  \caption{Linearized alternator \eqref{alter1} with $\zeta=100$,
    convergence of CG method with preconditioners
    $\mNadd^{-1}$ and $\mNhyb^{-1}$ with the subdomains splitting $\#\Th/N\approx100$.}
  \label{tab:alter}
  %additive Schwarz preconditioner $\mNadd^{-1}$ \\
  %\vertical{\footnotesize\hspace{-12mm} additive  $\mNadd^{-1}$}
  \input{Figs_alter/asm_conv_alter_CG_ASM_A1.tex}

  \vspace{2mm}
  
  %symmetric hybrid Schwarz preconditioner $\mNhyb^{-1}$ \\
  %\vertical{\footnotesize\hspace{-12mm} hybrid $\mNhyb^{-1}$}
  \input{Figs_alter/asm_conv_alter_CG_ASM3_A1.tex}
\end{table}

\begin{table}
  \caption{Linearized alternator \eqref{alter1} with $\zeta=100$,
    convergence of CG method with preconditioners
    $\mNadd^{-1}$ and $\mNhyb^{-1}$ with the subdomains splitting $\#\Th/N\approx\numf{1000}$.}
  \label{tab:alter2}
  %additive Schwarz preconditioner $\mNadd^{-1}$ \\
  %\vertical{\footnotesize\hspace{-10mm} additive  $\mNadd^{-1}$}
  \input{Figs_alter/asm_conv_alter_CG_ASM_B1.tex}

  \vspace{2mm}
  
  %symmetric hybrid Schwarz preconditioner $\mNhyb^{-1}$ \\
  %\vertical{\footnotesize\hspace{-10mm} hybrid $\mNhyb^{-1}$}
  \input{Figs_alter/asm_conv_alter_CG_ASM3_B1.tex}
\end{table}


%% \begin{figure}
%%   %additive Schwarz preconditione4 $\mNadd^{-1}$ \\
%%   \vertical{\footnotesize\hspace{2mm} additive  $\mNadd^{-1}$}
%%   \includegraphics[width=0.31\textwidth]{Figs_alter/asm_conv_CG_ASM_P1_L1_a1.00E+00.pdf}
%%   \includegraphics[width=0.31\textwidth]{Figs_alter/asm_conv_CG_ASM_P2_L1_a1.00E+00.pdf}
%%   \includegraphics[width=0.31\textwidth]{Figs_alter/asm_conv_CG_ASM_P3_L1_a1.00E+00.pdf}

%%   \vspace{2mm}
  
%%   %symmetric hybrid Schwarz preconditioner $\mNhyb^{-1}$ \\
%%   \vertical{\footnotesize\hspace{4mm} hybrid  $\mNhyb^{-1}$}
%%   \includegraphics[width=0.31\textwidth]{Figs_alter/asm_conv_CG_ASM3_P1_L1_a1.00E+00.pdf}
%%   \includegraphics[width=0.31\textwidth]{Figs_alter/asm_conv_CG_ASM3_P2_L1_a1.00E+00.pdf}
%%   \includegraphics[width=0.31\textwidth]{Figs_alter/asm_conv_CG_ASM3_P3_L1_a1.00E+00.pdf}
%%   \caption{Linearized alternator \eqref{alter1} with $\zeta=100$,
%%     convergence of CG method ($\rrel^\ell$ for $\ell=0,1,\dots$, cf.~\eqref{alg:stop})
%%     for preconditioners  $\mNadd^{-1}$ and $\mNhyb^{-1}$
%%     with the subdomains splitting $\#\Th/N\approx100$.}
%%   \label{fig:alter}
  
%% \end{figure}


\begin{table}
  \caption{Linearized alternator \eqref{alter1} with $\zeta=\numf{10000}$,
    convergence of CG method with preconditioners
    $\mNadd^{-1}$ and $\mNhyb^{-1}$ with the subdomains splitting $\#\Th/N\approx100$.}
  \label{tab:alter4}
  %additive Schwarz preconditioner $\mNadd^{-1}$ \\
  %\vertical{\footnotesize\hspace{-12mm} additive  $\mNadd^{-1}$}
  \input{Figs_alter4/asm_conv_alter4_CG_ASM_A1.tex}

  \vspace{2mm}
  
  %symmetric hybrid Schwarz preconditioner $\mNhyb^{-1}$ \\
  %\vertical{\footnotesize\hspace{-12mm} hybrid $\mNhyb^{-1}$}
  \input{Figs_alter4/asm_conv_alter4_CG_ASM3_A1.tex}
\end{table}

\begin{table}
  \caption{Linearized alternator \eqref{alter1} with $\zeta=\numf{10000}$,
    convergence of CG method with preconditioners
    $\mNadd^{-1}$ and $\mNhyb^{-1}$ with the subdomains splitting $\#\Th/N\approx\numf{1000}$.}
  \label{tab:alter5}
  %additive Schwarz preconditioner $\mNadd^{-1}$ \\
  %\vertical{\footnotesize\hspace{-10mm} additive $\mNadd^{-1}$}
  \input{Figs_alter4/asm_conv_alter4_CG_ASM_B1.tex}

  \vspace{2mm}
  
  %symmetric hybrid Schwarz preconditioner $\mNhyb^{-1}$ \\
  %\vertical{\footnotesize\hspace{-10mm} hybrid $\mNhyb^{-1}$}
  \input{Figs_alter4/asm_conv_alter4_CG_ASM3_B1.tex}
\end{table}


The observations for this more complicated case are, in principle, the same as in
Section~\ref{sec:lapl}.
Neglecting the computational costs of the coarse solver, we have the weak scalability
of the algebraic solvers, cf. Tables~\ref{tab:alter2} and \ref{tab:alter5}.
The hybrid preconditioner $\mNhyb^{-1}$ saves about 25 -- 30\% of
the computational costs compared to the additive preconditioner $\mNadd^{-1}$.
Similarly, the finer (coarse) mesh $\ThH$ provides a more accurate approximation
and reduces the number of iterations.
Additionally, these observations are robust for the problem data. That is,
the increase of the ratio $\zeta=k_1/k_0 = \mu_0 /\mu_1$ (cf. \eqref{Kij} and \eqref{alter1})
by factor 100 leads to the increase of $\iter$ by 50 -- 75\% only.

\subsection{Nonlinear problem with $hp$-mesh adaptation}
\label{sec:alterN}

Finally, we employ the presented iterative method for the numerical solution
of a nonlinear elliptic problem in the combination with the anisotropic $hp$-mesh
adaptation. Following  \cite{Glowinski74,DolCon_JCAM23}, the problem geometry is the
same as in Figure~\ref{fig:alter_geom} and the magnetic potential $u$ fulfills 
\begin{align}
  \label{alt6}
  -\nabla\cdot \left(\nu (x, |\nabla u(x)|^2) \nabla u\right) &= f\qquad \mbox{ in }\Om
\end{align}
with \begin{align}
  \label{alt3}
  \nu(x, r) = 
  \begin{cases}
    \frac{1}{\mu_0} & \mbox{ for } x\in \Om_a, \\
    \frac{1}{\mu_0}\left(\alpha + (1-\alpha)\frac{r^4}{\beta+ r^4}\right) &
    \mbox{ for } x\in \Om_s\cup\Om_r. \\
  \end{cases}
\end{align}
The quantity
$\mu_0=1.256\times10^{-6}\, \mathrm{kg}\cdot\mathrm{m}\cdot\mathrm{A}^{-2}\cdot\mathrm{s}^{-2}$
denotes the permeability of
the vacuum and the material coefficients are $\alpha = 0.0003$, $\beta = 16000$ according
to \cite{Glowinski74}.
We consider the constant current density $f=5\times10^{4}\, \mathrm{A}\cdot\mathrm{m}^{-2}$ and
prescribe the mixed Dirichlet/Neumann boundary conditions as in Section~\ref{sec:alter}.
We note that these conditions differ from those in \cite{DolCon_JCAM23}.

We discretize \eqref{alt6} again by SIPG %by the symmetric variant of the interior penalty Galerkin
method (cf. \cite{DolCon_JCAM23}), which leads to the similar form as
\eqref{Ah} but $\Ah$ is nonlinear in the first argument since $\K = \nu(x, |\nabla u(x)|^2) \mI$
depends on $u$. The arising nonlinear algebraic system is solved iteratively by
the Newton method where the Jacobian is evaluated by the differentiation 
of $\Ah$.

The iterative Newton method is stopped when the ratio between the algebraic error estimator
and the discretization error estimator is below $10^{-3}$, cf. \cite{hp-steady} for details.
At each Newton iteration, we solve a linear algebraic system by
the conjugate gradient method with additive and/or hybrid Schwarz preconditioners,
we employ the stopping criterion \eqref{alg:stop} with $\TOL=10^{-2}$.
The lower value of $\TOL$  leads to a small decrease in the number of Newton steps $\iterN$ but
a significant increase in the CG iterations $\iterL$.

Moreover, when the criterion for the Newton method is reached, we perform the re-meshing
using the anisotropic $hp$-mesh adaptation based on the interpolation error control, we refer
to \cite[Chapters~5-6]{AMA-book} for details. After the re-meshing (including the variation
of polynomial approximation degrees), a new domain decomposition of $\Om$ is employed and
the computational process is repeated.
We carried out eight levels of mesh refinement; at each adaptation level,
$\Om$ is divided into $N=12$ subdomains,
and the coarse mesh always has $\#\ThH=48$ elements. Figure~\ref{fig:alterN} shows the isolines
of the solution and the final $hp$-mesh obtained using the hybrid preconditioner
(the mesh is very similar for the additive preconditioner).

\begin{figure}
  \includegraphics[height=0.45\textwidth]{Figs_alterN/alterN_ASM3_iso.pdf}
  \hspace{0.02\textwidth}
  \includegraphics[height=0.45\textwidth]{Figs_alterN/alterN_ASM3_hpmesh.pdf}
  \caption{Nonlinear alternator \eqref{alt6}--\eqref{alt3}, isolines of the solution (left)
  and the $hp$-mesh after 8~levels of mesh adaptation.}
  \label{fig:alterN} 
\end{figure}


Table~\ref{tab:alterN} presents
the comparison of the performance of the additive and hybrid Schwarz preconditioners.
For each mesh adaptation level, we show the number of mesh elements $\#\Th$, number
of degrees of freedom $\DoF=\dim\Shp$ and the accumulated number of
the Newton iterations  $\iterN$ and the CG iterations $\iterL$.
In the last line of this table, we give the total number of $\MFl$ and $\Mcomm$.
Furthermore, Figure~\ref{fig:alterNc} shows the convergence of the Newton method
using CG solver with additive and hybrid Schwarz preconditioners
The horizontal axes corresponds to the mesh adaptation level, each node corresponds
to one Newton iteration. We plot the estimators of the algebraic and discretization errors
from \cite{hp-steady} for both preconditioners. We observe that space errors stagnate
in each mesh adaptation loop at the
level between $10^{-8}$ and $10^{-7}$ and the nonlinear solver stops when the
ratio between the algebraic and discretization estimators is $10^{-3}$.
We can deduce a mild dominance of the hybrid preconditioner.
However, we are aware that a rigorous comparison requires a
deeper study and it will be the subject of the further research.
\begin{table}
  \caption{Nonlinear alternator \eqref{alt6}--\eqref{alt3}, the convergence of the
    mesh adaptive algorithm.}
  \label{tab:alterN}
  \begin{center}
    \input{Figs_alterN/alterN_table.tex}
  \end{center}
\end{table}


\begin{figure}
  \begin{center}
    \includegraphics[width=0.95\textwidth]{Figs_alterN/alterN_ASM3_conv.pdf}
  \end{center}
  \caption{Nonlinear alternator \eqref{alt6}--\eqref{alt3}, comparison of the convergence
  of the Newton method using CG solver with additive and hybrid Schwarz preconditioners.}
  \label{fig:alterNc}
\end{figure}

%%% Local Variables: 
%%% mode:latex
%%% TeX-master: "paper"
%%% End: 


\section{Conclusion}
\label{sec:concl}

We presented the two-level hybrid Schwarz preconditioner for the $hp$-discontinuous
Galerkin discretization of elliptic problems as an alternative to
the well-established additive Schwarz approach. Whereas numerical analysis shows
only a slightly better spectral bound, the the numerical experiments
demonstrate about 25 -- 30\% saving of computational costs.
Moreover, the weak scalability is shown
provided that the computational costs of the coarse solver are neglected.
Finally, the robustness with respect to the data problem, anisotropy of the meshes
and varying polynomial degree is demonstrated.

The future research will orient to more challenging problems (nonlinear, nonsymmetric,
systems of equations). Additionally, the optimal choice of subdomains and coarse grid
deserve a deeper insight in order to balance the number of floating point operations
and communication operations.

\section*{Acknowledgments}
We are thankful to prof. Martin Gander (University of Geneva)
for a fruitful discussion during his stay at the Charles University in Prague and
our colleagues Michal Outrata and Petr Tich\'y inspiring suggestions and ideas.


%\bibliographystyle{plain}
%\bibliography{ref}

\begin{thebibliography}{10}

\bibitem{MUMPS1}
P.~R. Amestoy, A.~Buttari, J.-Y. L’Excellent, and T.~Mary.
\newblock Performance and scalability of the block low-rank multifrontal
  factorization on multicore architectures.
\newblock {\em ACM Transactions on Mathematical Software}, 45(1):2:1--2:26,
  2019.

\bibitem{MUMPS2}
P.~R. Amestoya, I.~S. Duff, J.~Koster, and J.-Y. L’Excellent.
\newblock A fully asynchronous multifrontal solver using distributed dynamic
  scheduling.
\newblock {\em SIAM J. Mat. Anal. Appl.}, 23(1):15--42, 2001.

\bibitem{AntoniettiALL_JSC14}
P.~Antonietti, S.~Giani, and P.~Houston.
\newblock Domain decomposition preconditioners for discontinuous {G}alerkin
  methods for elliptic problems on complicated domains.
\newblock {\em Journal of Scientific Computing}, 60:203--227, 2014.

\bibitem{AntoniettiAyuso_M2NA07}
Paola~F. Antonietti and Blanca Ayuso.
\newblock Schwarz domain decomposition preconditioners for discontinuous
  {G}alerkin approximations of elliptic problems: Non-overlapping case.
\newblock {\em Mathematical Modelling and Numerical Analysis}, 41(1):21--54,
  2007.

\bibitem{AntoniettiAyuso_CCP09}
Paola~F. Antonietti and Blanca Ayuso.
\newblock Two-level {S}chwarz preconditioners for super penalty discontinuous
  {G}alerkin methods.
\newblock {\em Communications in Computational Physics}, 5(2-4):398--412, 2009.

\bibitem{AntoniettiHouston_JSC11}
Paola~F. Antonietti and Paul Houston.
\newblock A class of domain decomposition preconditioners for
  $hp$-discontinuous {G}alerkin finite element methods.
\newblock {\em J. Sci. Comput.}, 46(1):124--149, 2011.

\bibitem{AntoniettiALL_IJNAM16}
Paola~F. Antonietti, Paul Houston, and Iain Smears.
\newblock A note on optimal spectral bounds for nonoverlapping domain
  decomposition preconditioners for $hp$-version discontinuous {G}alerkin
  methods.
\newblock {\em International Journal of Numerical Analysis and Modeling},
  13(4):513--524, 2016.

\bibitem{AntoniettiALL_MC20}
P.F. Antonietti, P.~Houston, G.~Pennesi, and E.~S\"uli.
\newblock An agglomeration-based massively parallel non-overlapping additive
  {S}chwarz preconditioner for high-order discontinuous {G}alerkin methods on
  polytopic grids.
\newblock {\em Math. Comput.}, 89(325):2047--2083, 2020.

\bibitem{BarkerCai_SISC10}
Andrew~T. Barker and Xiao-Chuan Cai.
\newblock Two-level newton and hybrid {S}chwarz preconditioners for
  fluid-structure interaction.
\newblock {\em SIAM J. Sci. Comput.}, 32(4):2395--2417, 2010.

\bibitem{BarrenecheaALL_CMAM19}
Gabriel~R. Barrenechea, Michał Bosy, Victorita Dolean, Frédéric Nataf, and
  Pierre-Henri Tournier.
\newblock Hybrid discontinuous {G}alerkin discretisation and domain
  decomposition preconditioners for the {S}tokes problem.
\newblock {\em Computational Methods in Applied Mathematics}, 19(4):703--722,
  2019.

\bibitem{Houston-book}
Andrea Cangiani, Zhaonan Dong, Emmanuil~H. Georgoulis, and Paul Houston.
\newblock {\em $hp$-Version Discontinuous {G}alerkin Methods on Polygonal and
  Polyhedral Meshes}.
\newblock Springer Cham, 2017.

\bibitem{Canuto-2013-BPC}
Claudio Canuto, Luca~F. Pavarino, and Alexandre~B. Pieri.
\newblock {{BDDC} preconditioners for continuous and discontinuous {G}alerkin
  methods using spectral/hp elements with variable local polynomial degree}.
\newblock {\em IMA J. Numer. Anal.}, 34(3):879--903, 2013.

\bibitem{PietroErn2012}
D.A. Di~Pietro and A.~Ern.
\newblock {\em Mathematical Aspects of Discontinuous {G}alerkin Methods}.
\newblock Mathematiques et {A}pplications 69. Springer Berlin Heidelberg, 2012.

\bibitem{Nataf-DDM}
Victorita Dolean, Pierre Jolivet, and Fr\'ed\'eric Nataf.
\newblock {\em An Introduction to Domain Decomposition Methods Algorithms,
  Theory, and Parallel Implementation}.
\newblock Society for Industrial and Applied Mathematics, 2015.

\bibitem{hp-steady}
V.~Dolej{\v s}{\'\i}.
\newblock $hp$-{DGFEM} for nonlinear convection-diffusion problems.
\newblock {\em Math. Comput. Simul.}, 87:87--118, 2013.

\bibitem{DolCon_JCAM23}
V.~Dolej{\v s}{\'\i} and S.~Congreve.
\newblock Goal-oriented error analysis of iterative {G}alerkin discretizations
  for nonlinear problems including linearization and algebraic errors.
\newblock {\em J. Comput. Appl. Math.}, 427:115134, 2023.

\bibitem{DGM-book}
V.~Dolej{\v s}{\'\i} and M.~Feistauer.
\newblock {\em Discontinuous {G}alerkin Method -- Analysis and Applications to
  Compressible Flow}.
\newblock Springer Series in Computational Mathematics 48. Springer, Cham,
  2015.

\bibitem{AMA-book}
V.~Dolej{\v s}{\'\i} and G.~May.
\newblock {\em Anisotropic $hp$-Mesh Adaptation Methods}.
\newblock Birkh\"auser, 2022.

\bibitem{Dryja-2007-DGD}
Maksymilian Dryja, Juan Galvis, and Marcus Sarkis.
\newblock {BDDC} methods for discontinuous {G}alerkin discretization of
  elliptic problems.
\newblock {\em Journal of Complexity}, 23(4-6):715--739, 2007.

\bibitem{DryjaKrzyzanowski_NM16}
Maksymilian Dryja and Piotr Krzyżanowski.
\newblock A massively parallel nonoverlapping additive {S}chwarz method for
  discontinuous {G}alerkin discretization of elliptic problems.
\newblock {\em Numer. Math.}, 132(2):347--367, 2016.

\bibitem{Karashian2001}
X.~Feng and O.~Karashian.
\newblock Two-level additive {S}chwarz methods for a discontinuous {G}alerkin
  approximation of second order elliptic problems.
\newblock {\em SIAM J. Numer. Anal.}, 39:1343--1365, 01 2002.

\bibitem{GanderTalk}
M.~Gander.
\newblock Private communication, 2024.

\bibitem{Gander_ETNA08}
Martin~J. Gander.
\newblock Schwarz methods over the course of time.
\newblock {\em Electronic Transactions on Numerical Analysis}, 31:228--255,
  2008.

\bibitem{GanderHajian_SINUM14}
Martin~J. Gander and Soheil Hajian.
\newblock Analysis of {S}chwarz methods for a hybridizable discontinuous
  {G}alerkin discretization.
\newblock {\em SIAM Journal on Numerical Analysis}, 53(1):573--597, 2014.

\bibitem{GanderHajian_MC18}
Martin~J. Gander and Soheil Hajian.
\newblock Analysis of {S}chwarz methods for a hybridizable discontinuous
  {G}alerkin discretization: The many-subdomain case.
\newblock {\em Mathematics of Computation}, 87(312):1635--1657, 2018.

\bibitem{Glowinski74}
R.~Glowinski and A.~Marrocco.
\newblock Analyse num\'erique du champ magnetique d’un alternateur par
  elements finis et sur-relaxation ponctuelle non lineaire.
\newblock {\em Comput. Methods Appl. Mech. Engrg.}, 3:55--85, 1974.

\bibitem{GopalakrishnanKanschat_23}
J.~Gopalakrishnan and G.~Kanschat.
\newblock A multilevel discontinuous {G}alerkin method.
\newblock {\em Numer. Math.}, 95(3):527--550, 2023.

\bibitem{HeinleinLanser_SISC20}
Alexander Heinlein and Martin Lanser.
\newblock Additive and hybrid nonlinear two-level {S}chwarz methods and energy
  minimizing coarse spaces for unstructured grids.
\newblock {\em SIAM J. Sci. Comput.}, 42(4):A2461--A2488, 2020.

\bibitem{metis}
G.~Karypis and V.~Kumar.
\newblock {\em {METIS} -- A Software Package for Partitioning Unstructured
  Graphs, Partitioning Meshes, and Computing Fill-Reducing Orderings of Sparse
  Matrices}, 2011.
\newblock
  \verb+<http://glaros.dtc.umn.edu/gkhome/metis/metis/+\verb+overview>+.

\bibitem{Kim-2014-BAC}
Hyea~Hyun Kim, Eric~T. Chung, and Chak~Shing Lee.
\newblock A {BDDC} algorithm for a class of staggered discontinuous {G}alerkin
  methods.
\newblock {\em Comput. Math. Appl.}, 67(7):1373--1389, 2014.

\bibitem{Krzyzanowski_NMPDE16}
Piotr Krzyżanowski.
\newblock On a nonoverlapping additive {S}chwarz method for $h$-$p$
  discontinuous {G}alerkin discretization of elliptic problems.
\newblock {\em Numerical Methods for Partial Differential Equations},
  32(6):1572--1590, 2016.

\bibitem{Mandel_94}
Jan Mandel.
\newblock Hybrid domain decomposition with unstructured subdomains.
\newblock In Jan Mandel, Charbel Fkrhat, and Xiao-Chuan Cai, editors, {\em
  Domain Decomposition Methods in Science and Engineering. Sixth International
  Conference of Domain Decomposition}, volume 157, pages 103--112. Contemporary
  Mathematics, 1994.

\bibitem{MUMPS}
{\em MUMPS: MUltifrontal Massively Parallel sparse direct Solver}, 2024.
\newblock mumps-solver.org.

\bibitem{PaznerKolev_CAMC22}
Will Pazner and Tzanio Kolev.
\newblock Uniform subspace correction preconditioners for discontinuous
  {G}alerkin methods with hp-refinement.
\newblock {\em Communications on Applied Mathematics and Computation},
  4(2):697--727, 2022.

\bibitem{QuarteroniValli00}
Alfio Quarteroni and Alberto Valli.
\newblock {\em Domain Decomposition Methods for Partial Differential
  Equations}.
\newblock Numerical Mathematics and Scientific Computation. Clarendon Press,
  Oxford, 1999.

\bibitem{Scacchi_CMAME08}
Simone Scacchi.
\newblock A hybrid multilevel {S}chwarz method for the bidomain model.
\newblock {\em Computer Methods in Applied Mechanics and Engineering},
  197(45-48):4051--4061, 2008.

\bibitem{Smears_JSC18}
Iain Smears.
\newblock Nonoverlapping domain decomposition preconditioners for discontinuous
  {G}alerkin approximations of {H}amilton--{J}acobi--{B}ellman equations.
\newblock {\em Journal of Scientific Computing}, 74(1):145--174, 2018.

\bibitem{ToselliWidlund-DD05}
Andrea Toselli and Olof Widlund.
\newblock {\em Domain decomposition methods---algorithms and theory}, volume~34
  of {\em Springer Series in Computational Mathematics}.
\newblock Springer-Verlag, Berlin, 2005.

\bibitem{Tu-2021-BAA}
Xuemin Tu and Jinjin Zhang.
\newblock {BDDC} algorithms for advection-diffusion problems with {HDG}
  discretizations.
\newblock {\em Comput. Math. Appl.}, 101:74--106, 2021.

\end{thebibliography}


\end{document}


%% %% \begin{table}
%% %%   \caption{$\rank(T)$ RENEW}
%% %%   \setlength{\tabcolsep}{5pt}
%% %%   \footnotesize{
%% %%     \input{Figs_T_rank/T_rank_1D_A1lev_tab.tex}
%% %%     \input{Figs_T_rank/T_rank_1D_A2lev_tab.tex}
%% %%     }
%% %%   \label{tab:rankT_Laplace}
%% %% \end{table}
%% %% \begin{table}
%% %%   \caption{$\rank(T)$ RENEW 2}
%% %%   \setlength{\tabcolsep}{5pt}
%% %%   \footnotesize{
%% %%     \input{Figs_T_rank/T_rank_1D_1lev_tab.tex}
%% %%     \input{Figs_T_rank/T_rank_1D_A1lev_tab.tex}
%% %%     }
%% %%   \label{tab:rankT_Laplace}
%% %% \end{table}
%% %% \begin{table}
%% %%   \caption{$\rank(T)$ RENEW 3}
%% %%   \setlength{\tabcolsep}{5pt}
%% %%   \footnotesize{
%% %%     \input{Figs_T_rank/T_rank_1D_2lev_tab.tex}
%% %%     \input{Figs_T_rank/T_rank_1D_A2lev_tab.tex}
%% %%     }
%% %%   \label{tab:rankT_Laplace}
%% %% \end{table}

%% \begin{table}
%%   \caption{1D case (symmetric case), one-level (left) and two-level (right) methods.}
%%   \setlength{\tabcolsep}{5pt}
%%   \footnotesize{
%%     \input{Figs_T_rank/T_rank_1Da_A1lev_tab.tex}
%%     \input{Figs_T_rank/T_rank_1Da_A2lev_tab.tex}
%%     }
%%   \label{tab:rankT_1Da}
%% \end{table}

%% \begin{table}
%%   \caption{1D case (non-symmetric case), one-level (left) and two-level (right) methods.}
%%   \setlength{\tabcolsep}{5pt}
%%   \footnotesize{
%%     \input{Figs_T_rank/T_rank_1Da_A1lev_tab.tex}
%%     \input{Figs_T_rank/T_rank_1Da_A2lev_tab.tex}
%%     }
%%   \label{tab:rankT_1D}
%% \end{table}

%% \begin{table}
%%   \caption{Laplace equation (symmetric case), one-level (left) and two-level (right) methods.}
%%   \setlength{\tabcolsep}{5pt}
%%   \footnotesize{
%%     \input{Figs_T_rank/T_rank_Lapl_A1lev_tab.tex}
%%     \input{Figs_T_rank/T_rank_Lapl_A2lev_tab.tex}
%%     }
%%   \label{tab:rankT_Laplace2}
%% \end{table}

%% \begin{table}
%%   \caption{Convection-diffusion  equation (non-symmetric case), one-level (left) and two-level (right) methods.}
%%   \setlength{\tabcolsep}{5pt}
%%   \footnotesize{
%%     %\input{Figs_T_rank/T_rank_2D_1lev_tab.tex}
%%     %\input{Figs_T_rank/T_rank_2D_2lev_tab.tex}
%%     %\input{Figs_T_rank/T_rank_2D2_1lev_tab.tex}
%%     %\input{Figs_T_rank/T_rank_2D2_2lev_tab.tex}
%%     \input{Figs_T_rank/T_rank_2D_A1lev_tab.tex}
%%     \input{Figs_T_rank/T_rank_2D_A2lev_tab.tex}
%%     }
%%   \label{tab:rankT_2D}
%% \end{table}

%\cite{GanderALL_SISC23,GanderVandewalle_SICC07,Lions2001661,RannacherBook}
\bibliographystyle{plain}
\bibliography{ref}

\end{document}
