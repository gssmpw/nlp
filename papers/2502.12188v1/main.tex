\documentclass{article}

% 页面设置
\usepackage{fullpage}
\usepackage[utf8]{inputenc}
\usepackage[T1]{fontenc}
\usepackage{microtype}
\usepackage{indentfirst}

% 数学相关包
\usepackage{amsmath}
\usepackage{amsfonts}
\usepackage{amssymb}
\usepackage{amsthm}
\usepackage{mathtools}
\usepackage{bm}
\usepackage{commath}
\usepackage{relsize}
\usepackage{bbm}
\usepackage{nicefrac}
\usepackage{mysymbol}

% 图形和表格
\usepackage{graphicx}
\usepackage{subfigure}
\usepackage{diagbox}
\usepackage{multirow}
\usepackage{booktabs}
\usepackage{hhline}
\usepackage{array}
\usepackage{pgfplots}
\usepackage{tikz}
\usetikzlibrary{positioning}

% 颜色和盒子
\usepackage{color}
% \usepackage[table]{xcolor}
\usepackage{tcolorbox}

% 算法和代码
\usepackage{algorithm}
\usepackage{algorithmic}
\usepackage{listings}

% 参考文献
% \usepackage{natbib}
\usepackage{cite}
\usepackage{url}

% 其他功能包
\usepackage{pifont}
\usepackage{newfloat}
\usepackage{enumerate}
\usepackage{enumitem}
\usepackage[title]{appendix}
\usepackage[font={small}]{caption}

% 定理环境设置
\newtheorem{theorem}{Theorem}[section]
\newtheorem{proposition}[theorem]{Proposition}
\newtheorem{lemma}[theorem]{Lemma}
\newtheorem{corollary}[theorem]{Corollary}
\theoremstyle{definition}
\newtheorem{definition}[theorem]{Definition}
\newtheorem{assumption}[theorem]{Assumption}
\theoremstyle{remark}
\newtheorem{remark}[theorem]{Remark}

% 数学命令定义
\newcommand{\revise}{}
\newcommand{\gr}{\nabla}
\newcommand{\grw}{\nabla_{\w}}
\newcommand{\grd}{\nabla_{\delta}}
\newcommand{\grL}{\nabla_{\Lambda}}
\newcommand{\grpsi}{\nabla_{\bpsi}}
\newcommand{\grPsi}{\nabla_{\Psi}}
\newcommand{\sgr}{\tilde{\nabla}}
\newcommand{\sgrw}{\sgr_{\w}}
\newcommand{\sgrd}{\sgr_{\delta}}
\newcommand{\sgrL}{\sgr_{\Lambda}}
\newcommand{\sgrpsi}{\sgr_{\psi}}
\newcommand{\sgrbpsi}{\sgr_{\bpsi}}
\newcommand{\sgrPsi}{\sgr_{\Psi}}
\newcommand{\w}{\bm{w}}
\newcommand{\bpsi}{\bm{\psi}}
\newcommand{\bPsi}{\bm{\Psi}}
\newcommand{\E}{\mathbb{E}}
\newcommand{\wbar}{\overline{\w}}
\newcommand{\sigmaw}{\sigma^2_{\w}}
\newcommand{\sigmapsi}{\sigma^2_{\psi}}

% 其他设置
\allowdisplaybreaks
\newcolumntype{?}{!{\vrule width 1pt}}

 


\makeatletter
\def\Let@{\def\\{\notag\math@cr}}
%\def\changenumberingoff{\def\Let@{\def\\{\notag\math@cr}}}
%\def\changenumberingon{\def\Let@{\def\\{\tag\math@cr}}}
\makeatother


\DeclarePairedDelimiter\floor{\lfloor}{\rfloor}

\usepackage[hidelinks,backref=page]{hyperref}
\definecolor{darkred}{RGB}{150,0,0}
\definecolor{darkgreen}{RGB}{0,150,0}
\definecolor{darkblue}{RGB}{0,0,150}
\hypersetup{colorlinks=true, linkcolor=darkred, citecolor=darkblue, urlcolor=darkblue}

\renewcommand*{\backref}[1]{}
\renewcommand*{\backrefalt}[4]{%
    \ifcase #1 (Not cited.)%
    \or        (Cited on page~#2.)%
    \else      (Cited on pages~#2.)%
    \fi}
    
%\newcommand\NoDo{\renewcommand\algorithmicdo{}}
%\newcommand\ReDo{\renewcommand\algorithmicdo{\textbf{do}}}
%\newcommand\NoThen{\renewcommand\algorithmicthen{}}
%\newcommand\ReThen{\renewcommand\algorithmicthen{\textbf{then}}}
%\everymath{\displaystyle}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%% Amir added (end) %%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\newcommand\blfootnote[1]{%
  \begingroup
  \renewcommand\thefootnote{}\footnote{#1}%
  \addtocounter{footnote}{-1}%
  \endgroup
}


\title{\textbf{Boosting Generalization in Diffusion-Based Neural Combinatorial Solver via Energy-guided Sampling}}

\date{}


    
\newcommand*\samethanks[1][\value{footnote}]{\footnotemark[#1]}

\author{
Haoyu LEI\thanks{Department of Computer Science and Engineering, The Chinese University of Hong Kong, hylei22@cse.cuhk.edu.hk}, 
Kaiwen Zhou\thanks{Huawei Noah's Ark Lab, zhoukaiwen2@huawei.com}, 
Yinchuan Li\thanks{Huawei Noah's Ark Lab, liyinchuan@huawei.com},
Zhitang Chen\thanks{Huawei Noah's Ark Lab, chenzhitang2@huawei.com},
Farzan~Farnia\thanks{Department of Computer Science and Engineering, The Chinese University of Hong Kong, farnia@cse.cuhk.edu.hk}
	}     

  
%% Title
%\title{On the Role of Generalization in Transferability of Adversarial Examples}


\begin{document}
\maketitle

\begin{abstract}
Diffusion-based Neural Combinatorial Optimization (NCO) has demonstrated effectiveness in solving NP-complete (NPC) problems by learning discrete diffusion models for solution generation, eliminating hand-crafted domain knowledge. Despite their success, existing NCO methods face significant challenges in both cross-scale and cross-problem generalization, and high training costs compared to traditional solvers. While recent studies have introduced training-free guidance approaches that leverage pre-defined guidance functions for zero-shot conditional generation, such methodologies have not been extensively explored in combinatorial optimization. To bridge this gap, we propose a general energy-guided sampling framework during inference time that enhances both the cross-scale and cross-problem generalization capabilities of diffusion-based NCO solvers without requiring additional training. We provide theoretical analysis that helps understanding the cross-problem transfer capability. Our experimental results demonstrate that a diffusion solver, trained exclusively on the Traveling Salesman Problem (TSP), can achieve competitive zero-shot solution generation on TSP variants, such as Prize Collecting TSP (PCTSP) and the Orienteering Problem (OP), through energy-guided sampling across different problem scales.
\end{abstract}

%\vspace{-.1cm}
\section{Introduction}
\begin{figure*}
    \centering
    \includegraphics[width=0.9\linewidth]{figure_1.png}
    \caption{Overview of energy-guided sampling framework for achieving cross-problem generalization. Left: Pre-trained diffusion model performs denoising on original problem $G$ (TSP). Right: Proposed energy-guided sampling on target problem $G'$ (PCTSP) conducts $K$ rewrite iterations of noise addition and guided denoising.}
    \label{img:overview}
\end{figure*}

Combinatorial optimization (CO) problems are fundamental challenges across numerous domains, from logistics and supply chain management to network design and resource allocation. While traditional exact solvers and heuristic methods have been widely studied, they often struggle with scalability and require significant domain expertise to design problem-specific algorithms \cite{arora1998polynomial, gonzalez2007handbook}.

Recent advances in deep learning have sparked interest in Neural Combinatorial Optimization (NCO), which aims to learn reusable solving strategies directly from data, eliminating the need for hand-crafted heuristics \cite{bengio2021machine}. Among various deep learning approaches, diffusion-based models \cite{ho2020denoising, song2020score} have emerged as a particularly promising direction for solving combinatorial optimization problems. These models have demonstrated remarkable capabilities in learning complex solution distributions by adapting discrete diffusion processes to graph structures. Recent works like \cite{sun2023difusco, li2024distribution} have achieved state-of-the-art performance on classical problems such as the Traveling Salesman Problem (TSP), showcasing the potential of diffusion-based approaches in combinatorial optimization.

However, the practical applicability of existing NCO approaches is limited by several generalization challenges. First, current models suffer from cross-scale generalization, with performance degrading significantly when applied to larger problem instances than those seen during training, especially for auto-regression-based solvers \cite{khalil2017learning, kool2018attention} including transformer and reinforcement learning methods. Second, these models show limited cross-problem transfer capabilities, struggling to adapt to problem variants with modified objectives or additional constraints. While several studies have attempted to enhance learning-based solvers' generalization through approaches such as training additional networks \cite{wang2024asp} and fine-tuning \cite{lin2024cross}, these methods require substantial computational costs for training separate models for each problem type and scale.

In parallel, recent advances in diffusion models, particularly in computer vision, have demonstrated the effectiveness of training-free guidance approaches for enhancing conditional generation \cite{bansal2023universal, chung2022diffusion, yu2023freedom, shen2024understanding}. These approaches leverage pre-defined guidance functions or pre-trained networks to enable zero-shot conditional generation without additional training overhead. Inspired by these developments, we explore the adaptation of energy-based guidance to address the generalization challenges in combinatorial optimization.

In this work, we propose an energy-guided sampling framework (Figure \ref{img:overview}) that enhances the generalization capabilities of diffusion-based NCO solvers without requiring additional training costs. By incorporating problem-specific objectives and constraints during inference time, this approach enables zero-shot cross-problem transfer while maintaining solution feasibility. We conduct theoretical analysis that deepen our understanding on the problem transfer capability of the energy-guided sampling framework. Through experimental evaluation of the TSP-trained diffusion model on more complex variants, the Prize Collecting TSP (PCTSP) and the Orienteering Problem (OP), we empirically demonstrate its effective zero-shot transferability across problem classes of increasing complexity, while maintaining consistent performance across different problem scales. Our work represents a significant step toward more flexible and generalizable diffusion-based combinatorial optimization solvers, potentially reducing the need for problem-specific model training while maintaining competitive performance.

\section{Related Works}

\noindent\textbf{Neural Network-based Combinatorial Solvers.} Neural Combinatorial Optimization (NCO) approaches focus on leveraging neural networks to learn feasible solution distributions for combinatorial optimization problems \cite{bengio2021machine, zhang2023survey}. Autoregressive construction solvers \cite{khalil2017learning, kool2018attention, kwon2020pomo, kim2022sym, hottung2021learning} are built upon the success of transformer-based \cite{vaswani2017attention} and reinforcement learning architectures in sequential generation tasks. However, non-autoregressive construction solvers \cite{joshi2019efficient, fu2021generalize, qiu2022dimes, wang2024asp, sun2023difusco, sanokowski2024diffusion} have also been proposed to learn high-quality solution distributions.
% In parallel, improvement solvers have explored various local search strategies, including 2OPT operations \cite{da2021learning, wu2021learning}, sub-problem resolution techniques \cite{li2021learning, hou2023generalize}. Our proposed training-free guidance framework extends this paradigm by introducing a plug-and-play improvement solver that enhances both cross-domain and cross-size generalization through diffusion-based generative construction models.

\noindent\textbf{Diffusion-based Generative Modeling.} Recent advances in generative modeling have revolutionized various domains through diverse approaches, including Variational Autoencoders (VAE) \cite{kingma2013auto}, Generative Adversarial Networks (GAN) \cite{goodfellow2020generative}, Diffusion models \cite{ho2020denoising}, and GFlowNet \cite{bengio2023gflownet}. In particular, score-based diffusion models \cite{ho2020denoising, song2020score, sohl2015deep, song2019generative, dhariwal2021diffusion} have emerged as a powerful framework operating in continuous domains.
% by progressively adding Gaussian noise during the forward process and learning to reverse this corruption through neural network-based denoising. 

Beyond their state-of-the-art performance in traditional generative tasks, these models have shown remarkable potential in combinatorial optimization (CO). Pioneering work by \cite{sun2023difusco} established new state-of-the-art results for the Traveling Salesman Problem (TSP) by adapting discrete diffusion models \cite{austin2021structured} to graph structures. Building upon this foundation, \cite{li2024distribution} enhanced the framework's performance through gradient search iterations during testing. \cite{sanokowski2024diffusion} proposed the first diffusion-based unsupervised learning framework.
% Notably, these diffusion-based approaches demonstrate superior cross-size generalization compared to autoregressive alternatives, marking a significant advancement in scalable CO solvers.

\noindent\textbf{Training-free Guidance for Diffusion Models.} Conditional generation has emerged as a crucial component in real-world applications, enabling precise control over generated outputs. While traditional approaches such as classifier guidance \cite{dhariwal2021diffusion} and classifier-free guidance \cite{ho2022classifier} have proven effective, they require substantial computational overhead due to additional training requirements for either the classifier or the diffusion model.

A promising alternative has emerged through training-free guidance methods \cite{bansal2023universal, chung2022diffusion, yu2023freedom, shen2024understanding}, which are guided by pre-trained networks or loss functions. In the context of discrete diffusion models, this approach remained largely unexplored until \cite{li2024distribution} pioneered the adaptation of loss-based guidance during inference, building upon the pre-trained discrete diffusion solver framework \cite{sun2023difusco}. Our work demonstrates the significant potential of energy-guided sampling in enhancing the cross-problem generalization capabilities of diffusion-based NCO solvers.


\section{Preliminaries}

\subsection{Variants of the Traveling Salesman Problem}
\begin{itemize}
    \item \textbf{Traveling Salesman Problem (TSP)} requires finding the minimal-length Hamiltonian cycle in a complete graph, where the salesman must visit each city exactly once before returning to the starting point.
    \item \textbf{Prize Collecting TSP (PCTSP)} \cite{balas1989prize} extends the classical TSP by introducing node-specific prizes and penalties. The objective is to optimize a trade-off between minimizing tour length and unvisited node penalties while ensuring collected prizes exceed a predefined threshold. This formulation creates a more complex optimization landscape where node visitation decisions must balance multiple competing factors.
    \item \textbf{The Orienteering Problem (OP)}, first introduced by \cite{golden1987orienteering}, is a fundamental combinatorial optimization problem with widespread applications in real-world scenarios. In the OP, each node in the network is associated with a non-negative prize value, and the objective is to determine an optimal tour that begins and ends at a designated depot node. The tour must satisfy two key constraints: maximize the total collected prizes from the visited nodes, and ensure the total tour length does not exceed a predetermined distance limit. This problem effectively captures the trade-off between reward collection and resource constraints.
\end{itemize}

\subsection{Graph-based CO Problems}
Combinatorial optimization (CO) problems on graphs are fundamental to numerous real-world applications. Following recent advances \cite{sun2023difusco,li2024distribution}, we address these problems by formalizing graph-based CO instances as follows.

We represent each problem instance as an undirected graph $G(V,E)\in\mathcal{G}$, where $V$ and $E$ denote the vertex and edge sets, respectively. This representation encompasses both vertex selection and edge selection problems, covering a broad spectrum of practical CO scenarios. For any instance $G\in\mathcal{G}$, we define a binary decision variable $\mathbf{x}\in\mathcal{X}_{\mathcal{G}}$, where $\mathcal{X}_{\mathcal{G}}=\{0,1\}^{N}$ represents the feasible solution space. The optimization objective is to find the optimal solution $\mathbf{x}^*$ that minimizes a problem-specific objective function $f(\cdot;G):\{0,1\}^{N}\rightarrow\mathbb{R}$:
\begin{align}
\mathbf{x}^* = \underset{\mathbf{x}\in\mathcal{X}_{\mathcal{G}}}{\text{argmin}}\; f(\mathbf{x};G),
\end{align}
where the objective function decomposes into:
\begin{align}
f(\mathbf{x};G)=f_{\text{cost}}(\mathbf{x};G)+\beta\cdot f_{\text{valid}}(\mathbf{x};G).
\end{align}
Here $f_{\text{cost}}(\cdot;G)$ measures the solution quality, and $f_{\text{valid}}(\cdot;G)$ enforces problem-specific constraints through a penalty coefficient $\beta>0$. The validity function returns $0$ for feasible solutions and is strictly positive for \mbox{infeasible ones}. 

As a concrete example, consider the classical Traveling Salesman Problem (TSP): given a complete graph $G$ with edge weights, the objective is to find a minimum-weight Hamiltonian cycle. The decision variable $\mathbf{x}\in\{0,1\}^{N}$ encodes edge selections, where $f_{\text{cost}}(\cdot;G)$ measures the total tour length and $f_{\text{valid}}(\cdot;G)$ ensures the solution forms a valid Hamiltonian cycle following \cite{sun2023difusco}. For the Prize Collecting TSP (PCTSP) that we considered, each vertex has a prize $r_i>0$ and penalty $p_i>0$. $f_{\text{cost}}(\cdot;G)$ measures the difference between total tour length and uncollected penalties, while $f_{\text{valid}}(\cdot;G)$ ensures the total prizes are greater than the constraint and the solution forms a valid Hamiltonian cycle. For the Orienteering Problem (OP), $f_{\text{cost}}$ aims to maximize the total collected scores from visited nodes, while $f_{\text{valid}}(\cdot;G)$ ensures both tour connectivity and the total length within the given budget.

\subsection{Probabilistic Modeling for CO}
To leverage recent advances in deep generative models, we reformulate the CO objective through an energy-based perspective \cite{lucas2014ising}. Specifically, we establish an energy function $\mathcal{E}(\cdot;G):=|y-f(\cdot;G)|$ that maps each solution to its corresponding energy state. This energy-based formulation naturally leads to a probabilistic framework through the Boltzmann distribution \cite{lecun2006tutorial}:
\begin{align}
p(y|\mathbf{x};G) = \frac{\exp\big(-\frac{1}{\tau}\mathcal{E}(y,\mathbf{x};G)\big)}{\mathcal{Z}},
\;\text{where}\;\mathcal{Z} = \sum_{\mathbf{x}}\exp\Big(-\frac{1}{\tau}\mathcal{E}(y,\mathbf{x};G)\Big),
\label{eq:boltzmann}
\end{align}
where $\tau$ controls the temperature of the system and $\mathcal{Z}$ denotes the partition function that normalizes the distribution.

Recent works have demonstrated promising approaches to approximate this distribution using diffusion-based deep generative models by parameterizing a conditional distribution $p_{\theta}(\mathbf{x}|G)$ to minimize the energy function. Both supervised \cite{sun2023difusco,li2024distribution} and unsupervised \cite{sanokowski2024diffusion} learning paradigms have shown significant advances. Since our proposed training-free guidance mechanism is applicable to any pre-trained diffusion-based solver, we focus on the supervised learning framework in this work for ease of presentation.

Given a training set $\mathcal{G}=\{G_i\}_{i=1}^k$ of i.i.d. problem instances with their optimal solutions $\mathbf{x}$ and the corresponding optimal objective values $y_G^*$, we optimize the model parameters $\theta$ by maximizing the likelihood of the optimal solutions 
\begin{equation}
L(\theta) = \mathbb{E}_{G\sim\mathcal{G}}[-\log p_{\theta}(\mathbf{x}|y_G^*,G)].
\end{equation}

\section{Theoretical Results}

\subsection{Discrete Diffusion Generation Modeling}
We adopt a discrete diffusion framework \cite{austin2021structured} to effectively sample optimal solutions from the learned distribution $p_{\theta}(\mathbf{x}|y^*,G)$. In contrast to continuous diffusion models that employ Gaussian noise, our discrete formulation is particularly well-suited for graph-based combinatorial optimization problems \cite{sun2023difusco, li2024distribution}.

The diffusion process consists of two key components: a forward process that gradually corrupts the data, and a reverse process that learns to reconstruct the original distribution. The forward process $q(\mathbf{x}_{1:T}|\mathbf{x}_{0})=\prod_{t=1}^{T}q(\mathbf{x}_{t}|\mathbf{x}_{t-1})$ maps clean data $\mathbf{x}_{0}\sim q(\mathbf{x}_{0}|G)$ to a sequence of increasingly corrupted latent variables $\mathbf{x}_{1:T}$. The reverse process $p_{\theta}(\mathbf{x}_{0:T}|G)=p(\mathbf{x}_{T})\prod_{t=1}^{T}p_{\theta}(\mathbf{x}_{t-1}|\mathbf{x}_{t},G)$ learns to gradually denoise these latent variables to recover the original distribution. From a variational perspective, we optimize the model by minimizing an upper bound on the negative log-likelihood, where $C$ is a constant:
\begin{equation}
\begin{aligned}
L(\theta) &= \mathbb{E}_{G\sim\mathcal{G}}[-\log p_{\theta}(\mathbf{x}_{0}|G)] \\
&\leq \sum_{t=2}^T \mathbb{E}_{q(\mathbf{x}_t|\mathbf{x}_0)}\bigg[D_{KL}[q(\mathbf{x}_{t-1}|\mathbf{x}_t, \mathbf{x}_0)||p_\theta(\mathbf{x}_{t-1}|\mathbf{x}_t,G)]
- \log p_\theta(\mathbf{x}_0|\mathbf{x}_1,G)\bigg]+C.
\end{aligned}
\end{equation}
For discrete state spaces, we define the forward process using a categorical distribution:
\begin{align}
q(\mathbf{x}_{t}|\mathbf{x}_{t-1})= \text{Cat}(\mathbf{x}_{t};\mathbf{p}=\mathbf{\widetilde{x}}_{t-1}\mathbf{Q}_{t}),
\end{align}
where $\mathbf{\widetilde{x}}_{t}\in\{0,1\}^{N\times2}$ represents the one-hot encoding of $\mathbf{x}_{t}\in\{0,1\}^{N}$. The forward transition matrix $\mathbf{Q}_t$ is defined as:
\begin{align}
\mathbf{Q}_t = \begin{bmatrix} (1-\beta_t) & \beta_t \\ \beta_t & (1-\beta_t) \end{bmatrix}, \quad \beta_t\in[0,1],
\end{align}
where $[\mathbf{Q}_t]_{ij}$ denotes the state transition probability from state $i$ to state $j$. The $t$-step marginal distribution and posterior can be derived as:
\begin{equation}
\begin{aligned}
q(\mathbf{x}_t|\mathbf{x}_0) &= \text{Cat}(\mathbf{x}_t; \mathbf{p} = \mathbf{\widetilde{x}}_0\overline{\mathbf{Q}}_t), \\
q(\mathbf{x}_{t-1}|\mathbf{x}_t, \mathbf{x}_0) &= \text{Cat}\left(\mathbf{x}_{t-1}; \mathbf{p} = \frac{\mathbf{\widetilde{x}}_t\mathbf{Q}_t^\top \odot \mathbf{\widetilde{x}}_0\overline{\mathbf{Q}}_{t-1}}{\mathbf{\widetilde{x}}_0\overline{\mathbf{Q}}_t\mathbf{\widetilde{x}}_t^\top}\right),
\end{aligned}
\end{equation}
where $\overline{\mathbf{Q}}_t = \mathbf{Q}_1\mathbf{Q}_2\ldots\mathbf{Q}_t$ and $\odot$ denotes element-wise multiplication.

To capture the structural properties of CO problems, we employ an anisotropic graph neural network architecture \cite{joshi2019efficient}. For a given instance $G$, the network learns to predict the clean data distribution $p_{\theta}(\mathbf{\widetilde{x}}_0|\mathbf{x}_t,G)$. Taking TSP as an example, where $G$ encodes the 2D Euclidean coordinates of vertices, the network outputs a probability matrix $p_{\theta}(\mathbf{\widetilde{x}}_0|\mathbf{x}_t,G)\in [0,1]^{N\times 2}$. This matrix parameterizes $N$ independent Bernoulli distributions, each corresponding to a binary decision variable in $\mathbf{\widetilde{x}}_0$. The reverse process during sampling follows:
\begin{align}
p_\theta(\mathbf{x}_{t-1}|\mathbf{x}_t,G) = \sum_{\widetilde{\mathbf{x}}_0} q(\mathbf{x}_{t-1}|\mathbf{x}_t, \widetilde{\mathbf{x}}_0)p_\theta(\widetilde{\mathbf{x}}_0|\mathbf{x}_t,G).
\label{reverse}
\end{align}

\subsection{Energy-guided Sampling for Problem Transfer}
While training-free guidance has been extensively studied in computer vision \cite{bansal2023universal, chung2022diffusion, yu2023freedom, shen2024understanding}, its application to combinatorial optimization problems has only recently emerged \cite{li2024distribution}. We firstly extend this approach by introducing energy-based training-free guidance for new problem instances during inference, enabling flexible incorporation of additional constraints into pre-trained diffusion-based CO solvers and enhancing their cross-problem generalization capabilities.

Let $\mathcal{G}'=\{G'_i\}_{i=1}^n$ denote a set of test instances representing variants of the original training problems, such as problems with additional constraints or multiple objectives. For a new instance $G'$ with its optimal solution pair $(\mathbf{x}, y_{G'}^*)$, we need to estimate the new reverse process $p_\theta(\mathbf{x}_{t-1}|\mathbf{x}_t,y_{G'}^*,G')$ according to (\ref{reverse}). Following the score estimation perspective of diffusion processes \cite{song2020score}, we decompose the conditional score function at time step $t$ into two components:
\begin{equation}
\begin{aligned}
\underbrace{\nabla_{\mathbf{x}_t} \log p_\theta(\mathbf{x}_t|y^*_{G'},G')}_{\text{posterior score}} &= \underbrace{\nabla_{\mathbf{x}_t} \log p_\theta(\mathbf{x}_t|G')}_{\text{pre-trained prior score}}
+ \underbrace{\nabla_{\mathbf{x}_t} \log p_t(y^*_{G'}|\mathbf{x}_t,G')}_{\text{energy-guided score}}.
\end{aligned}
\label{eq:log_decomp}
\end{equation}
From the Bayesian perspective, $p_\theta(\mathbf{x}_t|G')$ can be understood as the \textit{prior}, which contains knowledge of the pre-trained problems (i.e. TSP problem in our experimental settings), and $p_t(y^*_{G'}|\mathbf{x}_t,G')$ corresponds to the \textit{guided likelihood} that incorporates additional constraints or objectives of the variant problem. We sample from the \textit{posterior} $p_\theta(\mathbf{x}_t|y^*_{G'},G')$ to generate high-quality solutions to the variant of the original training problems. 

Drawing upon this theoretical framework, we leverage the pre-trained diffusion model to estimate the first term $\nabla_{\mathbf{x}} \log p_\theta(\mathbf{x}_t|G')$. In the context of cross-problem transfer, while the pre-trained model yields only a \textit{biased} score function for new problem instances, we analyze their underlying connection for TSP variants in the subsequent subsection. 

Meanwhile, we compute the second energy-guided term $\nabla_{\mathbf{x}_t} \log p_t(y^*_{G'}|\mathbf{x}_t,G')$ using an energy function that specifically accounts for the additional objectives and constraints of the variant problem:
\begin{equation}
\nabla_{\mathbf{x}_t} \log p_t(y^*_{G'}|\mathbf{x}_t,G') \propto -\nabla_{\mathbf{x}_t}\mathcal{E}(y^*_{G'}, \mathbf{x}_0(\mathbf{x}_t);G'),
\label{eq:energy_grad}
\end{equation}
where $\mathcal{E}(y^*_{G'}, \mathbf{x}_t;G') = |y^*_{G'}-f(\widetilde{\mathbf{x}}_0(\mathbf{x}_t);G')|$ measures the energy between the optimal value and the predicted solution. Here, $\widetilde{\mathbf{x}}_0(\mathbf{x}_t)$ represents the predicted clean sample from the current noisy state $\mathbf{x}_t$. To overcome this issue, we parameterize the model outputs as the logits of $N$ independent Bernoulli samples, and estimate $\widetilde{\mathbf{x}}_0(\mathbf{x}_t)=\mathbb{E}_{\widetilde{\mathbf{x}}_0\sim p_\theta(\widetilde{\mathbf{x}}_0|\mathbf{x}_t)}[\widetilde{\mathbf{x}}_0]$. Combining equations \eqref{eq:log_decomp} and \eqref{eq:energy_grad}, we derive an energy-guided reverse sampling process:
\begin{equation}
\begin{aligned}
    p_\theta(\mathbf{x}_{t-1}|\mathbf{x}_t, y^*_{G'},G') \propto p_\theta(\mathbf{x}_{t-1}|\mathbf{x}_t, G')p_t(y^*_{G'}|\mathbf{x}_{t},G'),\\
    p(y^*_{G'}|\mathbf{x}_{t},G')=\exp\left(-\frac{1}{\tau}\nabla_{\mathbf{x}_t}f\left(\widetilde{\mathbf{x}}_0(\mathbf{x}_t);G'\right)\right).
\end{aligned}
\end{equation}

\subsection{Analysis of Problem Transfer}

Consider the scenario where we aim to transfer knowledge from the original Traveling Salesman Problem (TSP) to its variants: the Prize Collecting TSP (PCTSP) and the Orienteering Problem (OP). The diffusion model, trained on optimal TSP instances, estimates $p_\theta(\mathbf{x}_t|G')$ such that, under the assumption of perfect optimization, $p_\theta (\mathbf{x}_0 | G')$ approximates $q_{\textup{TSP}}(\mathbf{x}_0 | G')$, where the latter represents the distribution of ground-truth TSP solutions for instance $G'$. Through the Bayesian equation established in \eqref{eq:log_decomp}, we expect such a pre-trained prior would substantially enhance posterior sampling solution quality, as TSP shares fundamental structural similarities with PCTSP and OP, thereby encoding relevant domain knowledge. We formalize such similarities in the following analysis. The complete proof is provided in Appendix \ref{app:proofs}. We make use of the following definition to facilitate the analysis. 

\begin{definition}[Marginal Decrease]
\label{def:md_main}
   For a non-empty subset of nodes $S \subseteq V$, let $\textup{TSP}(S)$ denote the cost of the optimal TSP tour visiting all nodes in $S$. The marginal decrease of a subset $S$ is defined as 
   \[
   \Delta(S) = \textup{TSP}(V) - \textup{TSP}(V\setminus S).
   \]
\end{definition}

The marginal decrease measures the cost reduction of not visiting a subset of nodes $S$, which helps quantify the difference between the optimal tours. Take PCTSP as an example. If for any non-empty subset of nodes $S \subseteq V$, the penalty of not visiting the nodes in $S$ satisfies 
$\sum_{i\in S} {p_i} \geq \Delta(S)$,
then PCTSP and TSP share the same optimal tours. Based on this notion, we formalize the structural similarities in the following theorem.

\begin{theorem}\label{thm:prior_bound}
     For a non-empty subset of nodes $S\subseteq V$, let $\textup{TSP}(S)$ and $\textup{argTSP}(S)$ denote the optimal cost and optimal tours of TSP on the subgraph specified by $S$. Under Assumptions \ref{ass:pctsp} and \ref{ass:op}, the optimal tours of PCTSP are
     $\textup{argTSP}(V\setminus S_{\textup{PCTSP}})$, where
     \[
     S_{\textup{PCTSP}} \in \arg\min_{S\subseteq V} {\sum_{i\in S} {p_i} - \Delta(S)},
     \]
     and the optimal tours of OP are $\textup{argTSP}(V\setminus S_{\textup{OP}})$, where
    \[
    \begin{aligned}
    S_{\textup{OP}} \in &\arg\min_{S\subseteq V} {\Delta(S)},\;\textup{ s.t. } \Delta(S) \geq \textup{TSP}(V) -D_{\textup{OP}}.
    \end{aligned}
    \]
    Here $D_{\textup{OP}}$ is the distance limit  of the total tour length, and $\Delta(S)$ denotes the marginal decrease of a non-empty subset of nodes $S$. 
\end{theorem}

Theorem \ref{thm:prior_bound} shows that the optimal solutions of PCTSP and OP  are indeed the optimal tours of TSP on some subgraph of $G'$, revealing their fundamental structural similarities. We expect that the pre-trained diffusion model is powerful enough to generate high quality TSP solutions given test instances with various graph size. We can therefore understand the energy-guided sampling in this scenario as forcing the pre-trained model to focus on a subgraph of $G'$. Through this theoretical analysis, we deepen our understanding on how the proposed training-free energy-guided sampling works when transferring from a pre-trained network to its variants.

% We then establish the convergence property of our energy-guided sampling in the following theorem.

% \begin{theorem}\label{thm:guidance_convergence}
%     Assume that the guidance loss function is $\mu$-PL and $L_f$-Lipschitz with respect to clean images $x_0$, and the score function $\nabla \log p_t(x_t)$ is $L_p$-Lipschitz with respect to noisy image $x_t$.
%     Denote $\lambda_{min}$ as the minimum eigenvalue of the (semi)-definite matrix $Cov[x_0|x_t]$. Then the following conditions hold: (1) After one gradient step, the energy function is decreased by a fixed ratio; (2) Consider a diffusion process that adheres to a bounded change in the objective function, the energy-guided sampling procedure converges
% \end{theorem}

% Theorem \ref{thm:guidance_convergence} demonstrates that, under appropriate conditions, the energy-guided sampling procedure converges systematically toward the energy function's global minimum. Through this theoretical analysis, we establish that our proposed training-free energy-guided sampling achieves efficient performance when transferring from a pre-trained network to its variants, while maintaining bounded approximation error and theoretical convergence guarantees.

\section{Proposed Approach}

\begin{algorithm}[t]
\caption{Energy-guided Diffusion Sampling for Cross-problem Transfer}
\label{alg:main}
\begin{algorithmic}[1]
\REQUIRE 
\STATE $p_\theta$: Pre-trained diffusion model
\STATE $G'$: Target problem instance
\STATE $T$: Number of diffusion steps
\STATE $\tau$: Energy guidance temperature
\STATE $K$: Number of re-inference iterations
\ENSURE Optimal solution $\mathbf{t}_K$ for problem instance $G'$

\STATE Initialize $\mathbf{x}_T$ with random binary values
\FOR{$k = 1$ \TO $K$}
    \STATE Initialize $\mathbf{x}_T$ with previous best solution $\mathbf{t}_{k-1}$
    \FOR{$t = T$ \TO $1$}
        \STATE Compute $p_\theta(\mathbf{x}_t|G')$ from pre-trained model
        \STATE Compute energy gradient: $\nabla_{\mathbf{x}_t}f(\widetilde{\mathbf{x}}_0(\mathbf{x}_t);G')$
        \STATE Compute $p_t(y^*_{G'}|\mathbf{x}_t,G') \propto \exp(-\nabla_{\mathbf{x}_t}f/\tau)$
        \STATE Compute posterior: $p_\theta(\mathbf{x}_{t-1}|\mathbf{x}_t, y^*_{G'},G') \propto p_\theta(\mathbf{x}_{t-1}|\mathbf{x}_t,G') p_t(y^*_{G'}|\mathbf{x}_t,G')$
        \STATE Update next state with Bernoulli Sampling: $\mathbf{x}_{t-1} \sim \text{Cat}(\mathbf{x}_{t-1}; p_\theta(\mathbf{x}_{t-1}|\mathbf{x}_t, y^*_{G'},G'))$
    \ENDFOR
    \STATE Decode $\mathbf{x}_0$ to the best solution $\mathbf{t}_k$
\ENDFOR
\RETURN $\mathbf{t}_K$
\end{algorithmic}
\end{algorithm}

\noindent\textbf{Heatmap Generation.} Building upon our theoretical analysis of the graph-based discrete diffusion model, we employ it to generate transition matrices for combinatorial optimization problems. To effectively process the input structure, we introduce an anisotropic graph neural network equipped with edge-gating mechanisms \cite{bresson2018experimental, joshi2020learning}. This network encodes the input into a state matrix, where each element represents the selection probability $p_\theta(\mathbf{x}_0=1|G')$ of nodes or edges as a heatmap representation. The pre-trained diffusion model then operates by progressively denoising a randomly perturbed graph structure to generate these probability heatmaps, which serve as the foundation for subsequent decoding steps.

\noindent\textbf{Energy-guided Cross-problem Sampling.} We propose a conditional energy-guided sampling framework that enhances cross-scale and cross-problem generalization without requiring additional training. We leverage DDIM \cite{song2020denoising} to accelerate the sampling process to 10 or 20 steps. While our initial experiments reveal that single-round sampling with energy function gradients yields suboptimal cross-problem performance, we address this limitation by adopting the rewrite technique from \cite{li2024distribution}. Specifically, we initialize each round by adding noise to the previous round's best solution and iteratively apply energy-guided sampling (Algo. \ref{alg:main}). This iterative process establishes a natural trade-off between solution quality and computational efficiency.

\noindent\textbf{Decoding and Solution Selection.} To construct feasible solutions from the generated heatmaps, we employ a greedy decoding strategy that iteratively selects nodes or edges with the highest probabilities until reaching termination conditions (e.g., forming a complete cycle in TSP applications). Our framework is also flexible in incorporating advanced decoding strategies to generate better results, such as 2-opt heuristics \cite{lin1973efficient} and Monte Carlo Tree Search (MCTS) \cite{fu2021generalize, sun2023difusco}.

\begin{figure}[htbp] 
\centering        
\includegraphics[width=0.75\columnwidth]{visual.png}
\caption{Visualization of the node connectivity process. The first three images show the denoising steps of the pre-trained diffusion model for TSP solution generation, while the last shows the final PCTSP solution obtained through energy-guided sampling.}
\label{Fig: visual}       
\end{figure}



\section{Numerical Results}

\textbf{Dataset.} We evaluate our approach on the classical NP-complete combinatorial optimization problems: the Traveling Salesman Problem (TSP) together with its variants, the Prize Collecting Traveling Salesman Problem (PCTSP) and Orienteering Problem (OP).

\noindent\textbf{Evaluation.} Following \cite{kool2018attention}, we generate 1000 test instances for each problem scale: 20, 50, and 100, which denotes the node counts for PCTSP and OP. We evaluate model performance using two primary metrics: average solution cost and optimality gap relative to the exact solution. Additionally, we measure computational efficiency through total training time and per-instance inference time.

\noindent\textbf{Baselines.} We compare our approach against multiple baseline categories. For PCTSP, (1) Exact solver: Gurobi; (2) OR-based heuristics: OR-Tools and Iterated Local Search (ILS); (3) Learning-based methods: AM \cite{kool2018attention}, MDAM \cite{xin2021multi}, AM-FT \cite{lin2024cross}, ASP \cite{wang2024asp}. For OP, (1) Exact solver: Gurobi; (2) OR-based heuristics: Compass \cite{kobeaga2018efficient} and Tsili \cite{tsiligirides1984heuristic}; (3) Learning-based methods: AM \cite{kool2018attention}, AM-FT \cite{lin2024cross}. 

Our proposed DIF-Trans builds upon DIFUSCO's TSP-trained checkpoints in three different scales without additional training. The results of DIF-Trans are recorded under 50 iterations with greedy decoding strategy. The inference steps are accelerated by DDIM \cite{song2020denoising} from 1000 training steps to 10 steps. The energy function used in guided sampling follows \cite{lucas2014ising} which provides energy formulation for NP-complete CO problems, see \ref{app:energy}. The guidance temperature $\lambda$ is fixed to be 0.1 and the constraint coefficient $\beta$ is set to be 1.1. All experiments are conducted on a single Tesla V100 GPU.

\subsection{Generalization Results}

First, we conduct comprehensive generalization experiments following \cite{wang2024asp}, examining our method's transferability across both problem scales and variants. Our evaluation framework specifically examines: cross-scale generalization, where we assess performance across varying problem scales, and cross-problem generalization, focusing on adaptation to different problem variants. For cross-scale evaluation, we utilize a single model that exhibits optimal performance across all scales, eliminating the need for scale-specific training. Notably, while existing learning-based approaches require problem-specific retraining for PCTSP and OP instances, our DIF-Trans framework operates in a zero-shot generation.

\begin{table*}[htbp]\Large
\renewcommand{\arraystretch}{1.5}
\centering
\resizebox{1.0\textwidth}{!}{
    \begin{tabular}{llccccccccc}
    \hline
    \hline
     &  & \multicolumn{2}{c}{\textbf{PCTSP-20}} & \multicolumn{2}{c}{\textbf{PCTSP-50}} & \multicolumn{2}{c}{\textbf{PCTSP-100}} & & & \\
    \cmidrule(l){3-4}
    \cmidrule(l){5-6}
    \cmidrule(l){7-8}
     & Method & \textbf{Gap} $\downarrow$ & \textbf{Time} $\downarrow$ & \textbf{Gap} $\downarrow$ & \textbf{Time} $\downarrow$ & \textbf{Gap} $\downarrow$ & \textbf{Time} $\downarrow$ & \textbf{Avg Gap} $\downarrow$ & \textbf{Training-free} & \textbf{Training Time} $\downarrow$ \\
    \hline
    \multirow{4}{*}{\rotatebox[origin=c]{90}{OR}} 
    & Gurobi & \textbf{\underline{0.00\%}} & 3.10s & --- & --- & --- & --- & --- & --- & --- \\
    & OR-Tools & 2.13\% & 12.31s  & 4.85\% & 2.02m  & 10.33\% & 5.84m & 5.77\% & --- & --- \\
    & ILS (C++)  & 1.07\% & 2.13s  & \textbf{\underline{0.00\%}} & 18.30s  & \textbf{\underline{0.00\%}} & 56.11s & 0.36\% & --- & --- \\
    & ILS (Python 10x)$^*$   & 63.23\% & 3.05s  & 148.05\% & 4.70s  & 209.78\% & 5.27s & 140.35\% & --- & --- \\
    \hline
    \multirow{8}{*}{\rotatebox[origin=c]{90}{Learning-based}}
     & AM (Greedy)  & 2.76\% & 0.02s  & 18.20\% & 0.07s  & 28.98\% & 0.15s & 16.65\% & \textcolor{red}{\ding{55}} & 3.5 days \\
     & AM (Sampling)  & 2.54\% & 2.43s & 14.58\% & 7.08s & 22.20\% & 15.13s & 13.11\% & \textcolor{red}{\ding{55}} & 3.5 days \\
     & MDAM$^*$ (Greedy) & 11.76\% & 41.10s  & 24.73\% & 1.31m & 30.07\% & 1.96m & 22.19\% & \textcolor{red}{\ding{55}} & 4.3 days \\
     & MDAM$^*$ (Beam Search)  & 5.88\% & 2.70m  & 18.81\% & 4.77m & 26.09\% & 6.97m & 16.93\% & \textcolor{red}{\ding{55}} & 4.3 days \\
     & ASP$^*$  & 12.05\% & 0.03s  & 10.34\% & 0.08s & \textbf{\underline{11.56\%}} & 0.18s & 11.32\% & \textcolor{red}{\ding{55}} & 4.6 days \\
     & AM-FT (greedy) & 2.11\% & 0.03s & 16.58\% & 0.07s & 29.08\% & 0.16s & 15.92\% & \textcolor{red}{\ding{55}} & 4.9 days \\
    & AM-FT (Sampling) & \textbf{\underline{1.02\%}} & 2.51s & 14.11\% & 8.02s & 25.19\% & 17.21s & 13.44\% & \textcolor{red}{\ding{55}} & 4.9 days \\
    & \textbf{DIF-Trans (Ours)} & 4.91\% & 8.32s & \textbf{\underline{8.77\%}} & 10.46s & 18.02\% & 20.18s & \textbf{\underline{10.56\%}} & \textcolor{green}{\ding{51}} & \textbf{0 day} \\
    \hline
    \hline
    \end{tabular}
}
\caption{Comprehensive evaluation of cross-scale generalization capabilities across different solver categories on PCTSP instances. Comparison includes exact solvers (Gurobi), OR-based heuristics (OR-Tools, ILS), learning-based models (AM, MDAM, ASP, AM-FT, DIF-Trans). Performance metrics include optimality gap, inference time, and training time. The results marked with $*$ are reported from \cite{wang2024asp}. The proposed DIF-Trans achieves competitive performance while requiring no training.}
\label{tab:pctsp}

\renewcommand{\arraystretch}{1.5}
\centering
\resizebox{1.0\textwidth}{!}{
\begin{tabular}{llccccccccc}
\hline
\hline
 &  & \multicolumn{2}{c}{\textbf{OP-20}} & \multicolumn{2}{c}{\textbf{OP-50}} & \multicolumn{2}{c}{\textbf{OP-100}} &  & & \\
\cmidrule(l){3-4}
\cmidrule(l){5-6}
\cmidrule(l){7-8}
 & Method & \textbf{Gap} $\downarrow$ & \textbf{Time} $\downarrow$ & \textbf{Gap} $\downarrow$ & \textbf{Time} $\downarrow$ & \textbf{Gap} $\downarrow$ & \textbf{Time} $\downarrow$ & \textbf{Avg Gap} $\downarrow$ & \textbf{Training-free} & \textbf{Training Time} $\downarrow$ \\
\hline
\multirow{4}{*}{\rotatebox[origin=c]{90}{OR}} 
& Gurobi & \textbf{\underline{0.00\%}} & 10.22s & --- & --- & --- & --- & --- & --- & --- \\
& Compass & 0.15\% & 0.27s & \textbf{\underline{0.00\%}} & 1.02s & \textbf{\underline{0.00\%}} & 6.74s & 0.05\% & --- & --- \\
& Tsili (Greedy)$^*$ & 16.58\% & 0.02s & 19.22\% & 0.03s & 19.71\% & 0.03s & 18.50\% & --- & --- \\
& Tsili (Sampling)$^*$ & 0.85\% & 0.55s & 4.46\% & 2.45s & 8.56\% & 9.08s & 4.62\% & --- & --- \\
\hline
\multirow{5}{*}{\rotatebox[origin=c]{90}{Learning-based}}
& AM (Greedy) & 5.78\% & 0.04s & 12.10\% & 0.09s & 28.75\% & 0.19s & 15.54\% & \textcolor{red}{\ding{55}} & 3.2 days \\
& AM (Sampling) & 2.62\% & 2.87s & 8.81\% & 8.12s & 22.17\% & 14.98s & 11.20\% & \textcolor{red}{\ding{55}} & 3.2 days \\
& AM-FT (Greedy) & 5.50\% & 0.04s & 11.51\% & 0.08s & 23.40\% & 0.18s & 13.47\% & \textcolor{red}{\ding{55}} & 4.7 days \\
& AM-FT (Sampling) & \textbf{\underline{1.01\%}} & 2.76s & 7.19\% & 8.44s & 19.51\% & 18.15s & 9.24\% & \textcolor{red}{\ding{55}} & 4.7 days \\
& \textbf{DIF-Trans (Ours)} & 3.59\% & 7.89s & \textbf{\underline{6.83\%}} & 10.77s & \textbf{\underline{14.33\%}} & 19.06s & \textbf{\underline{8.25\%}} & \textcolor{green}{\ding{51}} & \textbf{0 day} \\
\hline
\hline
\end{tabular}
}
\caption{Comprehensive evaluation of cross-scale generalization capabilities across different solver categories on OP instances. Comparison includes exact solvers (Gurobi), OR-based heuristics (Compass, Tsili), learning-based models (AM, AM-FT, DIF-Trans). The results marked with $*$ are reported from \cite{lin2024cross}.}
\label{tab:op}
\end{table*}

Experimental results presented in Table \ref{tab:pctsp} and Table \ref{tab:op} demonstrate the superior generalization capabilities of our approach. DIF-Trans achieves competitive average optimality gaps ($10.56\%$ for PCTSP and $8.25\%$ for OP) across all problem scales while maintaining zero-shot inference capability. It eliminates the substantial computational overhead (3-5 days for existing methods) and well-labeled training data associated with problem-specific training. While OR-based heuristics like Compass showcase strong performance only on specific problem types, DIF-Trans's ability to leverage pre-trained diffusion models for different CO problem variants without additional training offers both scalability and adaptability in NCO solvers.

\subsection{Ablation Studies}

To validate the effectiveness of our energy-guided sampling framework in cross-problem transfer scenarios, we conduct comprehensive ablation studies while maintaining consistent problem scales. As demonstrated in Table \ref{tab:op_abla}, our method achieves significant zero-shot performance improvements when applied to the pre-trained DIFUSCO model on TSP. These improvements are evident across all PCTSP and OP problem scales, manifesting in both enhanced solution quality and reduced optimality gaps compared to traditional OR-based solvers.

\begin{figure}[htbp] 
\centering    
\subfigure{  
\includegraphics[width=0.33\columnwidth]{pctsp_gap.png}
}
\subfigure{     
\includegraphics[width=0.33\columnwidth]{pctsp_time.png}     
}
\caption{Trade-off between optimality gap and inference time of energy-guided sampling with respect to rewriting iterations on PCTSP.}
\label{Fig: tradeoff_1}
 
\subfigure{  
\includegraphics[width=0.33\columnwidth]{op_gap.png}
}
\subfigure{     
\includegraphics[width=0.33\columnwidth]{op_time.png}     
}
\caption{Optimality gap and inference time on OP.}
\label{Fig: tradeoff_2}       
\end{figure}

The cross-problem transfer capabilities exhibit progressive enhancement through our iterative rewriting mechanism, where each round's noisy data $\mathbf{x}_T$ is initialized using the previously obtained optimal solution. Figures \ref{Fig: tradeoff_1} and \ref{Fig: tradeoff_2} quantitatively demonstrate the solution adaptation trajectory as iterations proceed. While this iterative sampling paradigm causes additional computational overhead during inference, our training-free approach maintains computational efficiency and scalability compared to conventional OR solvers, which are inherently constrained by strict problem formulations and scale limitations. 

\begin{figure}[htbp] 
\centering    
\subfigure{  
\includegraphics[width=0.33\columnwidth]{pctsp_temp.png}
}
\subfigure{     
\includegraphics[width=0.33\columnwidth]{op_temp.png}     
}
\caption{Optimality gap changes with respect to the guided temperature ($-\lambda$ as the x-axis label) on PCTSP and OP.}
\label{Fig: temp}       
\end{figure}

\begin{table}[htbp]\LARGE
\renewcommand{\arraystretch}{1.5}
\centering
\resizebox{0.7\textwidth}{!}{
\begin{tabular}{llccccccccc}
\hline
\hline
& \multicolumn{3}{c}{\textbf{PCTSP-20}} & \multicolumn{3}{c}{\textbf{PCTSP-50}} & \multicolumn{3}{c}{\textbf{PCTSP-100}} \\
\cmidrule(l){2-4}
\cmidrule(l){5-7}
\cmidrule(l){8-10}
Method & \textbf{Cost}$\downarrow$ & \textbf{Gap}$\downarrow$ & \textbf{Time}$\downarrow$ & \textbf{Cost}$\downarrow$ & \textbf{Gap}$\downarrow$ & \textbf{Time}$\downarrow$ & \textbf{Cost}$\downarrow$ & \textbf{Gap}$\downarrow$ & \textbf{Time}$\downarrow$ \\
\hline
DIFUSCO & 3.78 & 19.21\% & 1.04s & 5.20 & 15.97\% & 1.35s & 8.14 & 35.61\% & 2.85s \\
\textbf{DIF-Trans (Ours)} & \textbf{3.32} & \textbf{4.83\%} & 7.20s & \textbf{4.69} & \textbf{3.79\%} & 9.15s & \textbf{6.67} & \textbf{12.31\%} & 18.41s \\
\hline
\hline
\end{tabular}
}

\vspace{0.4cm}

\resizebox{0.7\textwidth}{!}{
\begin{tabular}{llccccccccc}
\hline
\hline
& \multicolumn{3}{c}{\textbf{OP-20}} & \multicolumn{3}{c}{\textbf{OP-50}} & \multicolumn{3}{c}{\textbf{OP-100}} \\
\cmidrule(l){2-4}
\cmidrule(l){5-7}
\cmidrule(l){8-10}
Method & \textbf{Prize}$\uparrow$ & \textbf{Gap}$\downarrow$ & \textbf{Time}$\downarrow$ & \textbf{Prize}$\uparrow$ & \textbf{Gap}$\downarrow$ & \textbf{Time}$\downarrow$ & \textbf{Prize}$\uparrow$ & \textbf{Gap}$\downarrow$ & \textbf{Time}$\downarrow$ \\
\hline
DIFUSCO & 9.25 & 12.48\% & 1.51s & 25.60 & 13.45\% & 1.88s & 45.27 & 23.72\% & 2.97s \\
\textbf{DIF-Trans (Ours)} & \textbf{10.19} & \textbf{3.59\%} & 6.97s & \textbf{28.15} & \textbf{4.82\%} & 10.44s & \textbf{53.35} & \textbf{9.85\%} & 19.20s \\
\hline
\hline
\end{tabular}
}
\caption{Zero-shot cross-problem transfer performance comparison between TSP-trained DIFUSCO and our DIF-Trans approach on PCTSP and OP instances. The results show solution cost, optimality gap, and inference time across three problem scales (20, 50, and 100 nodes).}
\label{tab:op_abla}
\end{table}



Figure \ref{Fig: temp} demonstrates the effect of the temperature parameter in modulating the guidance strength of our framework. Higher temperature values effectively preserve the structural information in the original problem instances, whereas lower temperatures adapt to the characteristics of new problem instances. This temperature-dependent behavior enables fine-grained control over the balance between maintaining prior knowledge and new problem features.

\section{Conclusions and Limitations}

In this work, we introduced an energy-guided sampling framework enabling zero-shot cross-problem generalization for diffusion-based solvers. Through an energy-based guidance mechanism during inference, our approach successfully transfers pre-trained diffusion models to address TSP variants without requiring additional training. We conducted theoretical analysis in this scenario to deepen our understanding of the problem transfer capability. Extensive experiments on OP and PCTSP demonstrate that our framework achieves competitive performance against existing learning-based methods across various problem scales. 

This work demonstrates the considerable potential of adapting diffusion-based generative neural solvers to address real-world combinatorial optimization problems, particularly those involving dynamic constraints and objectives. Our approach reduces the computational costs of retraining large-scale neural solvers by providing a flexible, off-the-shelf sampling scheme that enhances generalization capabilities. Nevertheless, several limitations and opportunities for future research consideration still exist. First, while our method exhibits promising results on TSP variants, its applicability to a broader spectrum of combinatorial optimization problems beyond routing domains remains to be validated. Second, the computational complexity introduced by the energy-guided sampling process during inference requires further optimization. Future research directions could focus on extending the framework to diverse combinatorial optimization paradigms and developing more efficient guided-sampling scheme.


\bibliographystyle{unsrt}
\bibliography{main}

\begin{appendices}

\section{Appendix}

\subsection{Proof of Theorem \ref{thm:prior_bound}}
\label{app:proofs}
% \subsubsection{Proof of Theorem \ref{thm:prior_bound}}

To analyze the relation between the optimal solutions of TSP and that of PCTSP/OP, we make use of the following definitions. 

\begin{definition}[Marginal Decrease]
\label{def:md}
   For a non-empty subset of nodes $S \subseteq V$, let $\textup{TSP}(S)$ denote the cost of the optimal TSP tour visiting all nodes in $S$. The marginal decrease of a subset $S$ is defined as 
   \[
   \Delta(S) = \textup{TSP}(V) - \textup{TSP}(V\setminus S).
   \]
\end{definition}

The marginal decrease measures the cost reduction of not visiting a subset of nodes $S$. This concept helps quantify the relation between the optimal solutions of TSP/PCTSP/OP. We first make the following assumptions on the PCTSP and OP problems in the analysis. Note that we make these assumptions just for the simplicity of presentation.

\begin{assumption} [PCTSP Setting]
\label{ass:pctsp}
     We consider PCTSP without the minimum prize constraint.
\end{assumption}

\begin{assumption}[OP Setting]
\label{ass:op}
    For OP, we assume an identical reward at each city.
\end{assumption}

The above identical reward assumption can be relaxed by considering a node-weighted TSP, which can be transformed into a standard TSP with some effort. Then, we can apply the following arguments for OP to build a connection with the optimal solutions of standard TSP.

Under these assumptions, we compare the optimal solutions of PCTSP/OP with that of TSP as follows.

(i) For PCTSP, if for any non-empty subset of nodes $S \subseteq V$, the penalty of not visiting the nodes in $S$ satisfies 
\[
\sum_{i\in S} {p_i} \geq \Delta(S), 
\]
then PCTSP and TSP share the same optimal solutions, since not visiting any subset of nodes would result in a higher total cost. We can thus formulate the optimal cost (tour length + penalty) of PCTSP as
\begin{equation}
\label{eq:pctsp_opt}
    \text{PCTSP}(V) = \text{TSP}(V) + \min_{S\subseteq V} {\sum_{i\in S} {p_i} - \Delta(S)}.
\end{equation}
And we have the optimal solutions of PCTSP being the tours in $\text{TSP}(V\setminus S)$ with 
\[
S \in \arg\min_{S\subseteq V} {\sum_{i\in S} {p_i} - \Delta(S)},
\]
completing the proof for PCTSP.

(ii) For OP, since we assume a uniform reward at each city, the optimization objective becomes visiting as much nodes as possible under the distance limit of the total tour length. This objective is identical to minimizing the travel cost while respecting the budget, because the optimal cost of TSP satisfies the following property:
\[
    \text{For any non-empty subsets of nodes } S, V, \text{ if }  S\subseteq V, \text{ then } \text{TSP}(S) \leq \text{TSP}(V). 
\]
We can thus formulate the optimal tour length of OP as
\begin{align}
 \text{OP}(V) ={}& \max_{S\subseteq V} {\text{TSP}(V\setminus S)} \nonumber\\ &\ \ \text{ s.t. } \text{TSP}(V\setminus S) \leq D_{\text{OP}} \nonumber \\
 ={}& \text{TSP}(V) + \min_{S\subseteq V} {\Delta(S)} \label{eq:op_opt} \\ & \qquad\qquad \ \ \ \  \text{ s.t. } \Delta(S) \geq \text{TSP}(V) -D_{\text{OP}}, \nonumber
\end{align}
where $D_{\text{OP}}$ is the distance limit of OP. And we have the optimal solutions of OP being the tours in $\text{TSP}(V\setminus S)$ with 
\[
\begin{aligned}
S \in &\arg\min_{S\subseteq V} {\Delta(S)} \\
&\qquad\text{ s.t. } \Delta(S) \geq \text{TSP}(V) -D_{\text{OP}},
\end{aligned}
\]
completing the proof for OP.

\subsection{Energy Formulations for TSP Variants}
\label{app:energy}

In our experimental setup, we employ an anisotropic graph neural network architecture enhanced with edge-gating mechanisms \cite{bresson2018experimental, joshi2020learning}. This encoder transforms the input 2D coordinates and TSP variant paths into a binary edge-selection graph. Additional problem-specific information - such as prizes and penalties in PCTSP and prizes in OP - is incorporated into the gradient calculation of the guidance objective function. The constraint coefficients $\beta$ are chosen to be $1.1$ in experiments.

\begin{proposition}[Traveling Salesman Problem (TSP)]
Given a complete graph $G=(V,E)$ with edge weights $w:E\rightarrow\mathbb{R}^+$, find $\mathbf{x}\in\{0,1\}^{|E|}$ that minimizes:
\begin{align*}
f(\mathbf{x};G) &= f_{\text{cost}}(\mathbf{x};G) + \beta\cdot f_{\text{valid}}(\mathbf{x};G) \\
\text{where}\quad f_{\text{cost}}(\mathbf{x};G) &= \sum_{e\in E} w_e x_e \\
% f_{\text{valid}}(\mathbf{x};G) &= \sum_{v\in V}\big|\sum_{e\in\delta(v)} x_e - 2\big| + \sum_{S\subset V}\max(0, 2-\sum_{e\in\delta(S)} x_e)
\end{align*}
\end{proposition}

\begin{proposition}[Prize Collecting TSP (PCTSP)]
Given a complete graph $G=(V,E)$ with edge weights $w:E\rightarrow\mathbb{R}^+$, vertex prizes $r:V\rightarrow\mathbb{R}^+$, penalties $p:V\rightarrow\mathbb{R}^+$, and prize threshold $R$, find $\mathbf{x}\in\{0,1\}^{|E|}$, $\mathbf{y}\in\{0,1\}^{|V|}$ that minimizes:
\begin{align*}
f(\mathbf{x},\mathbf{y};G) &= f_{\text{cost}}(\mathbf{x},\mathbf{y};G) + \beta\cdot f_{\text{valid}}(\mathbf{x},\mathbf{y};G) \\
\text{where}\quad f_{\text{cost}}(\mathbf{x},\mathbf{y};G) &= \sum_{e\in E} w_e x_e + \sum_{v\in V} p_v(1-y_v) \\
f_{\text{valid}}(\mathbf{x},\mathbf{y};G) &= \max(0, R-\sum_{v\in V} r_v y_v)
\end{align*}
\end{proposition}

\begin{proposition}[Orienteering Problem (OP)]
Given a complete graph $G=(V,E)$ with edge weights $w:E\rightarrow\mathbb{R}^+$, vertex scores $s:V\rightarrow\mathbb{R}^+$, and budget $B$, find $\mathbf{x}\in\{0,1\}^{|E|}$, $\mathbf{y}\in\{0,1\}^{|V|}$ that minimizes:
\begin{align*}
f(\mathbf{x},\mathbf{y};G) &= f_{\text{cost}}(\mathbf{x},\mathbf{y};G) + \beta\cdot f_{\text{valid}}(\mathbf{x},\mathbf{y};G) \\
\text{where}\quad f_{\text{cost}}(\mathbf{x},\mathbf{y};G) &= -\sum_{v\in V} s_v y_v \\
f_{\text{valid}}(\mathbf{x},\mathbf{y};G) &= \max(0, \sum_{e\in E} w_e x_e - B)
\end{align*}
\end{proposition}

\end{appendices}
\end{document}
