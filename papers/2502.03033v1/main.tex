%%
%% This is file `sample-sigconf.tex',
%% generated with the docstrip utility.
%%
%% The original source files were:
%%
%% samples.dtx  (with options: `all,proceedings,bibtex,sigconf')
%% 
%% IMPORTANT NOTICE:
%% 
%% For the copyright see the source file.
%% 
%% Any modified versions of this file must be renamed
%% with new filenames distinct from sample-sigconf.tex.
%% 
%% For distribution of the original source see the terms
%% for copying and modification in the file samples.dtx.
%% 
%% This generated file may be distributed as long as the
%% original source files, as listed above, are part of the
%% same distribution. (The sources need not necessarily be
%% in the same archive or directory.)
%%
%%
%% Commands for TeXCount
%TC:macro \cite [option:text,text]
%TC:macro \citep [option:text,text]
%TC:macro \citet [option:text,text]
%TC:envir table 0 1
%TC:envir table* 0 1
%TC:envir tabular [ignore] word
%TC:envir displaymath 0 word
%TC:envir math 0 word
%TC:envir comment 0 0
%%
%%
%% The first command in your LaTeX source must be the \documentclass
%% command.
%%
%% For submission and review of your manuscript please change the
%% command to \documentclass[manuscript, screen, review]{acmart}.
%%
%% When submitting camera ready or to TAPS, please change the command
%% to \documentclass[sigconf]{acmart} or whichever template is required
%% for your publication.
%%
%%
\documentclass[sigconf]{acmart}

\usepackage{subfigure}
\usepackage{bm,bbm}
\usepackage{multirow}
\usepackage[ruled,vlined,linesnumbered]{algorithm2e}

%%
%% \BibTeX command to typeset BibTeX logo in the docs
\AtBeginDocument{%
  \providecommand\BibTeX{{%
    Bib\TeX}}}

%% Rights management information.  This information is sent to you
%% when you complete the rights form.  These commands have SAMPLE
%% values in them; it is your responsibility as an author to replace
%% the commands and values with those provided to you when you
%% complete the rights form.
\copyrightyear{2025}
\acmYear{2025}
\setcopyright{cc}
\setcctype{by}
\acmConference[WWW '25]{Proceedings of the ACM Web Conference 2025}{April 28-May 2, 2025}{Sydney, NSW, Australia}
\acmBooktitle{Proceedings of the ACM Web Conference 2025 (WWW '25), April 28-May 2, 2025, Sydney, NSW, Australia}
\acmDOI{10.1145/3696410.3714605}
\acmISBN{979-8-4007-1274-6/25/04}


%%
%% Submission ID.
%% Use this when submitting an article to a sponsored event. You'll
%% receive a unique submission ID from the organizers
%% of the event, and this ID should be used as the parameter to this command.
%%\acmSubmissionID{123-A56-BU3}

%%
%% For managing citations, it is recommended to use bibliography
%% files in BibTeX format.
%%
%% You can then either use BibTeX with the ACM-Reference-Format style,
%% or BibLaTeX with the acmnumeric or acmauthoryear sytles, that include
%% support for advanced citation of software artefact from the
%% biblatex-software package, also separately available on CTAN.
%%
%% Look at the sample-*-biblatex.tex files for templates showcasing
%% the biblatex styles.
%%

%%
%% The majority of ACM publications use numbered citations and
%% references.  The command \citestyle{authoryear} switches to the
%% "author year" style.
%%
%% If you are preparing content for an event
%% sponsored by ACM SIGGRAPH, you must use the "author year" style of
%% citations and references.
%% Uncommenting
%% the next command will enable that style.
%%\citestyle{acmauthoryear}


%%
%% end of the preamble, start of the body of the document source.
\begin{document}

%%
%% The "title" command has an optional parameter,
%% allowing the author to define a "short title" to be used in page headers.
\title{Aggregate to Adapt: Node-Centric Aggregation for Multi-Source-Free Graph Domain Adaptation}

%%
%% The "author" command and its associated commands are used to define
%% the authors and their affiliations.
%% Of note is the shared affiliation of the first two authors, and the
%% "authornote" and "authornotemark" commands
%% used to denote shared contribution to the research.
\author{Zhen Zhang}
\email{zhen@nus.edu.sg}
\affiliation{%
  \institution{National University of Singapore}
  \city{Singapore}
  \country{Singapore}
}

\author{Bingsheng He}
\email{hebs@comp.nus.edu.sg}
\affiliation{%
  \institution{National University of Singapore}
  \city{Singapore}
  \country{Singapore}
}

%%
%% By default, the full list of authors will be used in the page
%% headers. Often, this list is too long, and will overlap
%% other information printed in the page headers. This command allows
%% the author to define a more concise list
%% of authors' names for this purpose.

%\renewcommand{\shortauthors}{Trovato et al.}

%%
%% The abstract is a short summary of the work to be presented in the
%% article.
\begin{abstract}
Unsupervised graph domain adaptation (UGDA) focuses on transferring knowledge from labeled source graph to unlabeled target graph under domain discrepancies. Most existing UGDA methods are designed to adapt information from a single source domain, which cannot effectively exploit the complementary knowledge from multiple source domains. Furthermore, their assumptions that the labeled source graphs are accessible throughout the training procedure might not be practical due to privacy, regulation, and storage concerns. In this paper, we investigate multi-source-free unsupervised graph domain adaptation, i.e., adapting knowledge from multiple source domains to an unlabeled target domain without utilizing labeled source graphs but relying solely on source pre-trained models. Unlike previous multi-source domain adaptation approaches that aggregate predictions at model level, we introduce a novel model named GraphATA which conducts adaptation at node granularity. Specifically, we parameterize each node with its own graph convolutional matrix by automatically aggregating weight matrices from multiple source models according to its local context, thus realizing dynamic adaptation over graph structured data. We also demonstrate the capability of GraphATA to generalize to both model-centric and layer-centric methods. Comprehensive experiments on various public datasets show that our GraphATA can consistently surpass recent state-of-the-art baselines with different gains.
\end{abstract}

%%
%% The code below is generated by the tool at http://dl.acm.org/ccs.cfm.
%% Please copy and paste the code instead of the example below.
%%

\begin{CCSXML}
<ccs2012>
   <concept>
       <concept_id>10010147</concept_id>
       <concept_desc>Computing methodologies</concept_desc>
       <concept_significance>500</concept_significance>
       </concept>
   <concept>
       <concept_id>10010147.10010257</concept_id>
       <concept_desc>Computing methodologies~Machine learning</concept_desc>
       <concept_significance>500</concept_significance>
    </concept>
    <concept>
       <concept_id>10010147.10010178</concept_id>
       <concept_desc>Computing methodologies~Artificial intelligence</concept_desc>
       <concept_significance>500</concept_significance>
       </concept>
 </ccs2012>
\end{CCSXML}

\ccsdesc[500]{Computing methodologies}
\ccsdesc[500]{Computing methodologies~Machine learning}
\ccsdesc[500]{Computing methodologies~Artificial intelligence}

%%
%% Keywords. The author(s) should pick words that accurately describe
%% the work being presented. Separate the keywords with commas.
\keywords{Unsupervised Graph Domain Adaptation; Graph Neural Networks; Unsupervised Learning}
%% A "teaser" image appears between the author and affiliation
%% information and the body of the document, and typically spans the
%% page.


%%
%% This command processes the author and affiliation and title
%% information and builds the first part of the formatted document.
\maketitle

\section{Introduction}
Web data is inherently complex, characterized by diverse entities and intricate relationships, making it challenging to mine meaningful insights. Graph algorithms play a pivotal role in numerous web applications, enabling more efficient representation \cite{wu2019simplifying,brockschmidt2020gnn}, analysis \cite{cui2022braingb}, and decision-making \cite{he2020lightgcn,gu2022self}, etc. While graph neural networks (GNNs) \cite{velivckovic2017graph,kipf2016semi,hamilton2017inductive,liu2021node,xu2018powerful} have achieved remarkable success across diverse tasks including node classification \cite{velivckovic2017graph,kipf2016semi,wu2019simplifying}, traffic forecasting \cite{zhang2021traffic,zhang2020spatio}, molecular property prediction \cite{stark20223d,li2022kpgt} and web-scale recommendation \cite{ying2018graph,fan2019graph}, these GNN models exhibit substantial performance deterioration when applied to graphs with domain discrepancies \cite{wu2020unsupervised}. To mitigate this gap and eliminate the need for label annotations, unsupervised graph domain adaptation \cite{wu2020unsupervised,you2022graph,wu2023non} has been proposed to adapt the model by transferring knowledge from labeled source graph to unlabeled target graph. Existing graph domain adaptation approaches either employ adversarial training to learn domain-invariant representations \cite{wu2020unsupervised,shen2020adversarial} or explicitly minimize the domain distribution discrepancy \cite{wu2023non,shen2020network} to improve their generalization capability.

However, the above mentioned methods assume that the knowledge is specifically transferred from a single labeled source domain to an unlabeled target domain. Whereas, in the real world scenarios, data are often collected from multiple domains, which provides a range of complementary knowledge from different perspectives. This could significantly benefit target domains that do not strictly align with any single available source domain. For example, social networks might come from different countries and platforms with linguistic diversity. If the source networks are popular for a particular language like English or Spanish and the target network involves a mix of different languages, the adaptation can be tailored to target distribution by aggregating knowledge from multiple sources. To this end, Multi-Source Domain Adaptation (MSDA) \cite{guo2018multi,peng2019moment,zhao2018adversarial} is introduced to learn from multiple source domains, allowing it to obtain complementary knowledge from various source domains and making it more resilient to domain shifts.

Unfortunately, recent MSDA approaches require labeled source data during the adaptation procedure, which might be impractical due to privacy as well as security concerns, especially when source data containing sensitive information, e.g., financial transactions \cite{li2021causal} and medical diagnosis \cite{dong2020can}, etc. Therefore, it is imperative to investigate Multi-Source-Free Domain Adaptation (MSFDA) by relying solely on source pre-trained models without access to any labeled source data \cite{ahmed2021unsupervised,dong2021confident,shen2023balancing}. A simple yet straightforward solution for addressing MSFDA is to employ existing single-source-free domain adaptation methods \cite{liang2020we,liang2021source,yang2021exploiting} to adapt each source model individually, then the predictions from different source models are averaged to generate the final prediction. Nonetheless, it ignores the transferability of different source domains, since they may contribute differently to the target domain.

\begin{figure}
\includegraphics[width=0.35\textwidth]{graph/intro-eps-converted-to.pdf}
\caption{A toy example, where GNN 1 excels in modeling shared interests, whereas GNN 2 is good at capturing geographical proximity. If node B has mixed connection types, simply combining the predictions from GNN 1 and GNN 2 is ineffective, as neither of the source pre-trained GNNs performs well in this scenario.}
\label{fig:intro}
\vspace{-0.2in}
\end{figure}

There are some recent studies that automatically assign weights to source predictions \cite{ahmed2021unsupervised,dong2021confident,shen2023balancing}, where a larger value indicates higher transferability. Nevertheless, these aforementioned methods are designed for independent and identically distributed (i.e., iid) data, while the existence of non-iid graph-structured data poses great challenges to MSFDA that remain unexplored. In graphs, nodes are interconnected with each other through edges, forming complicated graph structure. Existing model-centric adaptation approaches, which learn a weight for each model, might not be adequate to capture the complementary semantics encoded by each model, leading to inaccurate combination of predictions. The main reason is that different nodes are associated with distinct local neighborhoods, thus globally aggregating source model predictions ignores the fine-grained node level disparity. For instance, source models are trained on two different social networks, e.g., one's connections emphasizing shared interests and the other one's links indicating geographical proximity. Then, we want to adapt these source models to classify node in target network, where neighboring connections might arise from shared interests as well as geographical proximity. As shown in Figure \ref{fig:intro}, the combination of model level predictions fails to adapt to different local patterns in the target network and results in sub-optimal performance. No matter how the predictions are merged, the outcome remains inaccurate because the individual predictions themselves are flawed. Thus, more devotion is required to effectively handle the graph domain adaptation task with fine-grained information. 

To tackle the aforementioned key challenges, we introduce a novel framework named GraphATA ({\it \textbf{\underline{A}}ggregate \textbf{\underline{T}}o \textbf{\underline{A}}dapt}), {\it which performs node-centric adaptation through dynamically parameterizing each node with a unique graph convolutional matrix}. Instead of globally aggregating source model predictions, we conduct fine-grained adaptation by taking each node's local context information into consideration. At each layer, we generate a personalized graph convolutional matrix for each node by automatically aggregating source models' weight matrices based on its local neighborhood. Therefore, different nodes could have distinct optimal weight matrices, which is flexible to adapt to diverse patterns. Furthermore, sparse constraints are employed to filter out irrelevant information, since not all the source models are useful during the adaptation procedure. We have carried out extensive experiments including node as well as graph classification, and the experimental results demonstrate that our proposed GraphATA outperforms recent state-of-the-art baselines over widely used datasets.

In summary, the main contributions of this paper are as follows:
\begin{itemize}
    \item To the best of our knowledge, we are the first to investigate the problem of multi-source-free unsupervised graph domain adaptation, which is a practical yet unexplored setting within the graph neural network community.
    \item We propose a node-centric adaptation framework that parameterizes each node with a personalized graph convolutional matrix according to its local context information, which enables a more generalizable model.
    \item Extensive experimental results show that GraphATA could achieve state-of-the-art performance across various public datasets with thorough ablation studies further validating the effectiveness of our node-centric adaptation.
\end{itemize}

\section{Related Work}
\textbf{Graph Neural Networks.} With the remarkable success in various graph related tasks, graph neural networks have garnered continuous attention from both academia and industry.. Different types of graph neural networks have been designed following the message passing paradigm, which can be categorized into spectral methods \cite{defferrard2016convolutional,kipf2016semi,bianchi2021graph} and spatial methods \cite{velivckovic2017graph,wu2019simplifying,hamilton2017inductive}. Among them, GCN \cite{kipf2016semi} performs convolution by approximating the Chebyshev polynomial \cite{defferrard2016convolutional} using its truncated first-order graph filter. GAT \cite{velivckovic2017graph} utilizes an attention mechanism to learn different weights for dynamically aggregating node's neighborhood representations. GraphSAGE \cite{hamilton2017inductive} introduces an inductive framework that generates representations by sampling and aggregating local representations. For more details, please refer to comprehensive surveys on graph neural networks \cite{zhou2022graph,wu2020comprehensive}. Despite their success, the performance of GNNs depends on high-quality labeled data, which can be challenging for graph-structured data. To address this issue, adapting models trained on label-rich source domains to unlabeled target domains has emerged as a promising solution.

\textbf{Unsupervised Domain Adaptation.} The goal of domain adaptation is to transfer knowledge from labeled source domains to unlabeled target domains. One key challenge lies in how to mitigate the domain shifts between source and target domains \cite{liu2024rethinking,liu2024revisiting}. To reduce the distribution discrepancy, most methods focus on learning domain invariant representations, which involve either explicit or implicit constraints. For example, some works \cite{long2015learning,zellinger2017central} employ maximum mean discrepancy or central moment discrepancy to directly reduce the divergence between source and target distributions. Other studies \cite{long2018conditional,hoffman2018cycada} utilize adversarial training to make the domain discriminator unable to differentiate source and target representations. Recently, there have been endeavors dedicated to unsupervised domain adaptation for non-iid graph-structured data. Particularly, UDAGCN \cite{wu2020unsupervised} follows the adversarial training framework to learn domain invariant representations on graphs. GRADE \cite{wu2023non} introduces the metric of graph subtree discrepancy to minimize the distribution shift between source and target graphs. SpecReg \cite{you2022graph} designs spectral regularization for theory-grounded graph domain adaptation. Liu et al. \cite{liu2023structural} proposes an edge re-weighting strategy to reduce the conditional structure shift. Mao et al. \cite{mao2021source} preserves target graph structural proximity and Zhang et al. \cite{zhang2024collaborate} conducts collaborative adaptation in the scenario of single source-free graph domain adaptation. However, these methods cannot address the multi-source-free graph domain adaptation problem since they require labeled data or are unable to adapt complementary knowledge from multiple source domains.

\textbf{Multi-Source-Free Domain Adaptation.} MSFDA extends domain adaptation by transferring knowledge from multiple source pre-trained models without accessing any source domain data. To capture the relationship among different source domains, various domain weighting strategies are utilized to estimate the contribution of each source domain to the target domain, including uniform weights, wasserstein distance-based weights and source domain accuracy-based weights \cite{peng2019moment,zhao2020multi,wang2019tmda,zhu2019aligning}. Due to the absence of source data, the above strategies are not applicable in the MSFDA setting. Towards this end, DECISION \cite{ahmed2021unsupervised} and CAiDA \cite{dong2021confident} aggregate multiple source model predictions and construct pseudo labels for model adaptation. Shen et al. \cite{shen2023balancing} propose to balance the bias-variance trade-off through domain aggregation, selective pseudo-labeling and joint feature alignment. Nonetheless, all these models are designed for independent and identically distributed data (iid), which are not suitable for non-iid graph structured data. Moreover, aggregating model level predictions is insufficient to capture the highly diverse graph patterns, since the global weights cannot adequately reflect the importance of each node's local context. In contrast, our model performs adaptation at node granularity with aggregating weight matrices from multiple source models according to its local context.

\section{Problem Statement}
\label{sec:problem}

\textbf{Notations and Problem Definition.} In multi-source-free unsupervised graph domain adaptation, the goal is to jointly adapt multiple source pre-trained graph neural network models to a target graph without any labels. In this paper, we focus on adapting classification models with $K$ categories. Formally, let $\mathcal{G}=(\mathcal{V},\mathcal{E},\mathbf{X})$ denote the unlabeled target graph, where $\mathcal{V}$ and $\mathcal{E}$ are the node set and edge set respectively. $\mathbf{X} \in \mathbb{R}^{n \times d}$ indicates the node feature matrix, with $n$ representing the number of nodes and $d$ denoting the dimension of node features. Given a set of source pre-trained GNN models $\{\Phi_1, \Phi_2, \cdots, \Phi_m\}$, where the $i$-th model is trained using the graph from $i$-th source domain, we decompose each source model $\Phi_i$ into two basic components, i.e., the feature extractor $\phi_i: \mathcal{G} \rightarrow \mathbb{R}^{n \times d}$ encoding graph $\mathcal{G}$ into node representation space and the classifier $\psi_i: \mathbb{R}^{n \times d} \rightarrow \mathbb{R}^{n \times K} or \ \mathbb{R}^{K}$ projecting node or graph representations into corresponding class labels. Hence, the source model $\Phi_i$ can be expressed as $\Phi_i = \phi_i \circ \psi_i$. Our ultimate problem can beformulated as follows:

{\it Given $m$ source trained graph neural network models $\{\Phi_1,\cdots,\Phi_m\}$ and an unlabeled graph $\mathcal{G}$ (node level task) or a set of unlabeled graphs $\{\mathcal{G}_1, \cdots, \mathcal{G}_n\}$ (graph level task) from target domain, our goal is to build a target model $\Phi_t$ that aggregates knowledge from multiple source models to achieve accurate predictions in target domain under distribution shifts.}

\textbf{Message Passing GNN Revisiting.} Most GNNs adopt the message passing framework \cite{kipf2016semi,hamilton2017inductive,velivckovic2017graph}, where each node iteratively aggregates representations from its local neighborhood. Specifically, the node $v$'s representation at layer $l$ can be calculated as follows:
\begin{equation}
    \mathbf{h}^{l} _v = \sigma(\textsc{Agg}(\{\mathbf{h}_v^{l-1}\} \cup \{\mathbf{h}_u^{l-1}, \forall u \in \mathcal{N}(v)\}) \cdot \mathbf{W}^l),
\end{equation}
where $\sigma(\cdot)$ is the activation function and $\textsc{Agg}(\cdot)$ represents the permutation-invariant aggregation function that aggregates message from its neighbors $\mathcal{N}(v)$. $\mathbf{W}^l$ denotes the convolutional matrix at layer $l$. The aggregation process in mainstream GNNs can be generalized as a weighted summation. For example, GCN \cite{kipf2016semi} aggregates neighborhood representations using fixed weights inversely proportional to node degrees. GraphSAGE \cite{hamilton2017inductive} utilizes a mean pooling aggregator, while GAT \cite{velivckovic2017graph} employs an attention mechanism for learnable weighted aggregation. For graph classification task, we simply use global mean pooling and max pooling to assemble all the node representations in the graph. Advanced techniques like hierarchical graph pooling can also be utilized in this scenario \cite{ying2018hierarchical}. 

\begin{figure*}
    \centering
    \includegraphics[width=\textwidth]{graph/model-GraphATA-eps-converted-to.pdf}
    \caption{An illustrative comparison between existing model-centric methods and our proposed node-centric framework. (a) The target prediction is the weighted combination of source models' predictions. (b) GraphATA performs fine-grained adaptation by considering each node's unique characteristic. The grey box with dash lines shows the personalized convolutional matrix for each node at layer $l$.}
    \label{fig:model}
    \vspace{-0.2in}
\end{figure*}

\section{The Proposed GraphATA Model}
\label{sec:model}
Figure \ref{fig:model} provides a comparison between existing model-centric methods and our proposed node-centric framework. {\it Specifically, model-centric adaptation approaches allocate a weight to each model, implying that all the nodes in the target graph share the same weight within each model}. Hence, it fails to reflect the unique characteristic of each individual target node, since the same model may exhibit varying capabilities when encoding different nodes. {\it In contrast, our node-centric adaptation framework GraphATA takes node disparity into consideration and parameterizes a unique convolutional matrix for each node to achieve fine-grained personalized adaptation}. Particularly, each node derives its own convolutional matrix by automatically aggregating matrices from multiple source GNN models based on its local neighborhood, which results in more generalizable model. Subsequently, we will elaborate the details of the proposed modules.

\begin{figure}
\includegraphics[width=0.40\textwidth]{graph/local-neighborhood.pdf}
\caption{Node homophily ratio distributions.}
\label{fig:homoratio}
\vspace{-0.1in}
\end{figure}

\textbf{Node Neighborhood Disparity.} We start by investigating the local context of each node within the graphs. Different nodes typically exhibit diverse structural patterns as they are not uniformly distributed across the graph. To characterize this property, we conduct a thorough examination of the node's homophilic and heterophilic patterns through the lens of node homophily ratio, which is a widely adopted metric that quantifies the proportion of a node's neighbors having the same class label \cite{li2022finding,pei2020geom,mao2023demystifying}. It is formally defined as follows:
\begin{equation}
    h_v = \frac{|\{u \in \mathcal{N}(v): y_u = y_v\}|}{|\mathcal{N}(v)|},
\end{equation}
where $\mathcal{N}(v)$ represents node $v$'s neighbors set and $y_v$ indicates the class label for node $v$. Figure \ref{fig:homoratio} demonstrates the node homophily ratio distributions on three social graphs from Twitch datasets (Section \ref{sec:datasets}). We can observe that {\it (1) all three graphs manifest a mixture of homophilic as well as heterophilic patterns; (2) the patterns' distributions vary significantly across different graphs}. Thus, existing model-centric methods \cite{ahmed2021unsupervised,dong2021confident} overlook each node's neighborhood disparity and the allocated weights might be sub-optimal. The above observations motivate us to perform fine-grained node-centric adaptation.

\textbf{Node-Centric Adaptation.} In the above investigation, we recognize the necessity of adapting to the local context of each individual node. To achieve this goal, we propose to assign distinct matrices to different nodes by aggregating convolutional matrices from the source pre-trained models, rather than aggregating model predictions. Specifically, different pre-trained models in the source domains have encapsulated different semantic information, which demonstrate varying capabilities in encoding the local context of each target node. For each node $v$, we utilize a straightforward yet effective way to represent its local contextual information at layer $l$ as follows:
\begin{equation}
    \mathbf{c}_v^l = \textsc{Mean}(\{\mathbf{h}_u^{l-1}, \forall u \in \mathcal{N}(v)\}),
\end{equation}
where we adopt mean operation to pool its neighbor's representation $\mathbf{h}_u^{l-1}$ from previous layer and $\mathbf{c}_v^l \in \mathbb{R}^{d_{l-1}}$. More alternative options are presented at Appendix \ref{ablation-appendix}.

After having obtained the local context $\mathbf{c}_v^l$, we generate a personalized graph convolutional matrix for node $v$ as follows:
\begin{equation}
    \mathbf{W}_v^l = \sum_{i=1}^m\alpha_{vi}^l \mathbf{\Lambda}(\mathbf{c}_v^l) \mathbf{W}_{i}^l + \lambda \mathbf{W}_g^l,
    \label{eq:graphmatrix}
\end{equation}
where $\mathbf{W}_i^l \in \mathbb{R}^{d_{l-1} \times d_l}$ represents the convolutional matrix from the $i$-th source pre-trained GNN model at layer $l$ and $\mathbf{\Lambda}(\mathbf{c}_v^l)$ is the $d_{l-1} \times d_{l-1}$ diagonal matrix with its elements setting as $\mathbf{c}_v^l$. The attentive coefficient $\alpha_{vi}$ characterizes the importance of each source domain model when adapting to node $v$. We further incorporate a global parameter $\mathbf{W}_g^l$ shared by all the nodes in the $l$-th layer to capture the global general patterns and $\lambda$ is a trade-off parameter. Therefore, our derived personalized $\mathbf{W}_v^l$ considers not only local but also global aspects of the graph, making it more adaptable to different types of distribution shifts.

\textbf{Sparse Attention Selection.} In Equation (\ref{eq:graphmatrix}), although $\mathbf{W}_v^l$ automatically aggregates the convolutional matrices from multiple source models according to its local context, we posit that not all the source domain models are useful, which is known as ``negative transfer'' \cite{wang2019characterizing,cao2018partial}. To combat this issue, we aim to filter out detrimental models and preserve a sparse mixture of effective models via attention coefficients. Particularly, we utilize a shared linear transformation parametrized by $\mathbf{a}^l \in \mathbb{R}^{d_l}$ to quantify the trustworthy and reliability of each model when adapting to the target node's local contextual information $\mathbf{c}_v^l$. At each layer, the attention score can be calculated as follows:
\begin{equation}
    \alpha_{vi} = {\rm Attention}(\mathbf{a}, \mathbf{c}_v, \mathbf{W}_i) = \mathbf{a}^{\top}(\mathbf{W}_i^{\top}\mathbf{c}_v),
\end{equation}
where the superscripts are omitted for simplicity. Additionally, we normalize the scores to ensure that $\alpha_{vi} \in [0,1]$ and $\sum_{i=1}^m\alpha_{vi}=1$. One commonly utilized approach is to employ the softmax function; however, it always produces non-zero values, which fails to yield the desired selective results. 

Inspired by recent successes on sparse activation functions, we choose to adopt the sparsemax function \cite{martins2016softmax}, which preserves the crucial properties of the softmax function and generates sparse distributions. It projects the input onto the probability simplex as follows:
\begin{equation}
    {\rm sparsemax}(\bm{\alpha}) = \mathop{\arg\min}\limits_{\bm{x} \in \Delta^{m-1}} \Vert \bm{x} - \bm{\alpha} \Vert^2,
    \label{eq:sparsemax}
\end{equation}
where the simplex $\Delta^{m-1} = \{\bm{x} \in \mathbb{R}^{m}| \mathbf{1}^{\top}\bm{x}=1, \bm{x} \geq \mathbf{0}\}$. Its closed-form solution can be formulated as follows:
\begin{equation}
    {\rm sprasemax}_i(\bm{\alpha}) = [{\alpha}_i - \tau(\bm{\alpha})]_{+},
    \label{sparseterm}
\end{equation}
where $[x]_{+} = \max\{0,x\}$ and $\tau(\cdot)$ is the threshold function that satisfies $\sum_{j}[\alpha_j - \tau(\bm{\alpha})]_{+} = 1$. To compute $\tau(\bm{\alpha})$, we first sort $\bm{\alpha}$ in descending order: $\alpha_1 \geq \alpha_2 \geq \cdots \geq \alpha_m$, and define $\eta = \max \{ 1 \leq j \leq m| \alpha_j > \frac{1}{j}(\sum_{i=1}^j\alpha_i - 1)\}$. Then, we have $\tau(\bm{\alpha}) = \frac{\sum_{i=1}^{\eta}\alpha_i-1}{\eta}$. The sprasemax function truncates the values below the threshold to zero and shifts the remaining values by this threshold. Detailed proof is provided in Appendix \ref{sec:proof}.

\textbf{Model Optimization.} To optimize the model's parameters, we leverage predictions from the nearest neighbors to generate pseudo labels. For the stability of the learning procedure, we maintain a target representation bank $\mathcal{R} = [\tilde{\mathbf{h}}_1,\cdots,\tilde{\mathbf{h}}_n]$ and a prediction bank $\mathcal{P} = [\tilde{\mathbf{p}}_1,\cdots,\tilde{\mathbf{p}}_n]$ through a momentum updating manner as follows:
\begin{equation}
    \tilde{\mathbf{h}}_i = (1-\gamma) \tilde{\mathbf{h}}_i + \gamma \mathbf{h}_i, \ \tilde{\mathbf{p}}_i = (1-\gamma) \tilde{\mathbf{p}}_i + \gamma \mathbf{p}_i,
\end{equation}
where $\gamma$ denotes the smoothing parameter setting as 0.9 by default. $\mathbf{h}_i \in \mathbb{R}^{d}$ and $\mathbf{p}_i \in \mathbb{R}^K$ are the outputs of feature extractor $\phi_t$ and classifier $\psi_t$, respectively. Then, for each target representation $\mathbf{h}_i$, we extract $r$ nearest neighbors from representation memory bank $\mathcal{R}$ according to their cosine similarities. With the nearest neighborhood information, the pseudo label distribution of sample $i$ can be obtained by aggregating the predicted class distributions of these nearest neighbors in memory bank $\mathcal{P}$ as follows:
\begin{equation}
    \hat{\mathbf{y}}_i = \mathbbm{1}[\mathop{\arg\max}\limits_{k}(\frac{1}{|\mathcal{S}(i)|}\sum_{j \in \mathcal{S}(i)}\tilde{\mathbf{p}}_j)],
\end{equation}
where $\mathbbm{1}[\cdot]$ represents the one-hot transformation function and $\mathcal{S}(i)$ is a set of $r$ nearest neighbors' indices for sample $i$. Thus, we could update the model's parameters by minimizing the cross entropy loss between the generated pseudo labels and the predicted class distributions as follows:
\begin{equation}
    \mathcal{L}_{cls} = -\frac{1}{n}\sum_{i=1}^n\sum_{k=1}^K \hat{\mathbf{y}}_{i,k}{\rm log}(\mathbf{p}_{i,k}).
\end{equation}
Additionally, we further encourage the prediction to be individually certain and globally diverse \cite{liang2020we} to avoid the degenerated prediction. Therefore, we minimize the entropy for each individual sample while maximizing the entropy for each class, which is expressed as follows:
\begin{equation}
    \mathcal{L}_{reg} = [\frac{1}{n}\sum_{i=1}^n\mathcal{H}(\mathbf{p}_i)] - \mathcal{H}(\frac{1}{n}\sum_{i=1}^n \mathbf{p}_i).
\end{equation}
Among them, $\mathcal{H}(\mathbf{p}_i) = -\sum_{k=1}^K \mathbf{p}_{i,k} {\rm log} (\mathbf{p}_{i,k})$ denotes the entropy function. Finally, we can obtain the overall objective function as follows:
\begin{equation}
    \mathcal{L} = \mathcal{L}_{cls} + \mathcal{L}_{reg}.
    \label{loss}
\end{equation}

\textbf{Model Analysis.} We discuss how our GraphATA generalizes to existing state-of-the-art methods. {\it (1) Relation with layer-centric approaches.} In particular, when setting $\mathbf{c}_v = \mathbf{1}$ and $\mathbf{W}_g = \mathbf{0}$, we suppress the awareness of each node's local contextual information, thus every node will have the same matrix expressed as $\mathbf{W}_{1,\cdots, n}^l = \sum_{i=1}^m\alpha_i\mathbf{W}_i^l$ within each layer. It essentially performs a weighted combination of the node representations propagated at each layer. Taking GCN \cite{kipf2016semi} as an example, we have $\mathbf{H}^l = \sigma(\tilde{\mathbf{A}}\mathbf{H}^{l-1}\sum_{i=1}^m\alpha_i\mathbf{W}_i^l) = \sum_{i=1}^m\alpha_i\sigma(\tilde{\mathbf{A}}\mathbf{H}^{l-1}\mathbf{W}_i^l)$, where $\sigma(\cdot)$ is the ReLU activation function and $\tilde{\textbf{A}}$ indicates the normalized adjacent matrix with self-loops. {\it (2) Relation with model-centric methods.} If we further restrict the information aggregation to the last layer $L$, i.e., the allocated weights are only employed for aggregating the predictions from each model and there is no information fusion in the intermediate layers, the simplified GraphATA degenerates to model-centric methods. {\it In summary, the design of GraphATA enjoys various benefits by taking each node's local context into consideration, and the current layer-centric as well as model-centric approaches are its special cases}.

\section{Experiments}
\label{sec:exp}

\begin{table}
    \caption{Dataset Statistics.}
    \label{overalldatasets}
    \centering
    \small
    \begin{tabular}{ccccc}
        \toprule[0.9pt]
        Datasets & \#Nodes & \#Edges  & \#Feat  & \#Class \\ 
        \midrule[0.7pt]
         CSBM &  8,000$\sim$8,000 & 607,699$\sim$752,776 & 128 & 4 \\
         Twitch  & 1,912$\sim$9,498 & 31,299$\sim$153,138 &  3,170   &  2   \\
         Citation  & 5,484$\sim$9,360 & 8,117$\sim$15,556  &  6,775   & 5  \\ 
        \midrule[0.7pt]
        Proteins & $\sim$39.06 & $\sim$72.82 & 4 & 2  \\
         Mutagenicity  & $\sim$30.32 &  $\sim$30.77 & 14    & 2   \\
         Frankenstein & $\sim$16.90 & $\sim$17.88  &  780  & 2  \\
        \bottomrule[0.9pt]
    \end{tabular}
\end{table}

\subsection{Datasets}
\label{sec:datasets}
To fully validate the effectiveness of our proposed GraphATA, we perform node and graph classification tasks from various domains. The summary of dataset statistics is presented in Table \ref{overalldatasets} and the details are described as follows:

{\it \textbf{CSBM}} is a synthetic dataset, which is composed of four graphs generated by a 4-class contextual stochastic block model \cite{deshpande2018contextual}. Each class contains 2,000 nodes in each graph. To synthesize different conditional structural shift, we fix the intra-class edge probability $p$ and vary the inter-class probability $q$ to generate different graphs. The node attributes are sampled from multivariate normal distributions with different mean vectors. The detailed process is described in Appendix \ref{sec:dataset-appendix}.

{\it \textbf{Twitch}}\footnote{https://snap.stanford.edu/data/twitch-social-networks.html} \cite{rozemberczki2019multi} consists of six social networks from different regions, i.e., Germany (DE), England (EN), Spain (ES), France (F), Portugal (P) and Russia (R). The nodes represent users, while the edges denote their friendships. We construct node attributes from various factors such as users' gaming activities, preferences, geographic locations and streaming habits, etc. All the nodes are classified into two categories based on whether they use explicit language. 

{\it \textbf{Citation}} \cite{tang2008arnetminer} contains three research paper citation networks from different platforms and time periods. Particularly, DBLPv7 (D) is extracted from the DBLP database spanning the years 2004 to 2008; ACMv9 (A) comprises papers from ACM database between years 2000 and 2010; Citationv1 (C) is derived from MAG database prior to the year 2008. We categorize each paper into one of the five classes, i.e., DB, AI, CV, IS and Networking. 

For graph classification task, we utilize three widely adopted datasets from TUdatasets\footnote{https://chrsmrrs.github.io/datasets/docs/datasets/} \cite{morris2020tudataset}, i.e., {\it \textbf{Proteins}}, {\it \textbf{Mutagenicity}} and {\it \textbf{Frankenstein}}. To differentiate the distribution shifts in the datasets, we partition each dataset into four disjoint groups based on their density. Specifically, we first sort all the graphs in each dataset by their density in an ascending order, and then divide them into four equally disjoint groups.

\subsection{Baselines}
\label{sec:baselines}
{\it \textbf{Source-needed.}} Approaches in this category leverage the labeled source domains' samples to explicitly address the distribution shifts. We consider two multi-source-needed models MDAN \cite{zhao2018adversarial}, M$^3$SDA \cite{peng2019moment} and three single-source-needed models UDAGCN \cite{wu2020unsupervised}, GRADE \cite{wu2023non} and SpecReg \cite{you2022graph} as our baselines. For single-source-needed methods, we merge all the samples from different source domains into a single unified source domain.

{\it \textbf{No-adaptation.}} This group of baselines include widely used graph neural network models like GCN \cite{kipf2016semi}, GraphSAGE \cite{hamilton2017inductive}, GAT \cite{velivckovic2017graph} and GIN \cite{xu2018powerful}. The model is trained on each labeled source domain and then directly evaluated on the target domain. We output final predictions by taking an average of soft predictions from all the source models.

{\it \textbf{Single-source-free.}} We also extend existing single-source-free models including SHOT \cite{liang2020we}, BNM \cite{cui2020towards}, ATDOC \cite{liang2021domain}, NRC \cite{yang2021exploiting}, JMDS \cite{lee2022confidence}, GT\textsc{rans} \cite{jin2022empowering}, SOGA \cite{mao2021source}, GraphCTA \cite{zhang2024collaborate} and TPDS \cite{tang2024source} to work in the scenario of multi-source-free domain adaptation. To achieve this goal, we utilize ensemble averaging to integrate soft predictions from all adapted source models.

{\it \textbf{Multi-source-free.}} Methods in this classes are recent state-of-the-art multi-source-free domain adaptation baselines such as DECISION \cite{ahmed2021unsupervised}, CAiDA \cite{dong2021confident} and MSFDA \cite{shen2023balancing}. They automatically assign suitable weights to each model's predictions for final predictions. These models are originally designed for i.i.d images and we replace its backbone to adapt them for graph structured data.

\textbf{Experimental Settings.} Following recent works \cite{wu2020unsupervised,yin2023coco}, we randomly partition the samples in each source domain into training set (80\%), validation set (10\%) and test set (10\%), respectively. The source model is first trained using the training set and its hyper-parameters are fine-tuned on the validation set. Then, we conduct sanity check on the test set to ensure that it is well-trained on the labeled source domain. The final performance is evaluated on the entire target domain. For baseline comparisons, we use the authors' publicly available code and maintain the same graph neural network backbone with identical layers. The node representation dimension is set as 128 for node classification and 64 for graph classification tasks. We implement our proposed GraphATA with Pytorch Geometric \cite{fey2019fast} and the parameters are optimized with Adam \cite{kingma2014adam}. The optimal learning rate and weight decay are searched in the set of $\{0.1, 0.01, 0.001, 1e^{-4}\}$. We set the smoothing parameter $\gamma$ for the memory banks to 0.9 by default and search for the optimal trade-off hyperparameter $\lambda$ within the range $[0, 1]$. Our source code and datasets are
available at \href{https://github.com/cszhangzhen/GraphATA}{\color{blue}{https://github.com/cszhangzhen/GraphATA}}\footnote{DOI for the artifact https://doi.org/10.5281/zenodo.14777073}.

\begin{table*}
    \centering
    \caption{Average node and graph classification performance in terms of accuracy with standard deviation (\%). OOM means out-of-memory. Some of the models are specifically designed for node classification task; therefore, we denote them with `-' for graph classification task.}
    \label{results}
    \resizebox{1.0\textwidth}{!}
    {
    \begin{tabular}{lccccccccc}
        \toprule[0.9pt]
         & \multicolumn{6}{c}{Node Classification} & \multicolumn{3}{c}{Graph Classification} \\ 
         \cmidrule[0.7pt](lr){2-7} \cmidrule[0.7pt](lr){8-10} \cmidrule[0.7pt](lr){8-10}
         \morecmidrules
         \cmidrule[0.7pt](lr){2-7} \cmidrule[0.7pt](lr){8-10} \cmidrule[0.7pt](lr){8-10}
         & CSBM & \multicolumn{2}{c}{Twitch} & \multicolumn{3}{c}{Citation} & Proteins & Mutagenicity & Frankenstein \\
         \cmidrule[0.7pt](lr){2-2}  \cmidrule[0.7pt](lr){3-4} \cmidrule[0.7pt](lr){5-7} \cmidrule[0.7pt](lr){8-10} 
         & C1,C2,C3$\rightarrow$C4 & R,P,F,ES$\rightarrow$DE & R,P,F,ES$\rightarrow$EN &  A,C$\rightarrow$D & C,D $\rightarrow$ A & A,D $\rightarrow$ C & P1,P2,P3$\rightarrow$P4 & M1,M2,M3$\rightarrow$M4 & F1,F2,F3$\rightarrow$F4  \\
        \midrule[0.7pt]
        MDAN \cite{zhao2018adversarial}  & 76.49$\pm$0.39 & 61.78$\pm$0.33 & 49.52$\pm$0.35 & 70.38$\pm$0.17 & 65.31$\pm$0.09 & 73.92$\pm$0.13 & 48.56$\pm$1.34 & 63.85$\pm$3.11 & 49.02$\pm$1.28\\
        M$^3$SDA \cite{peng2019moment} & OOM & 59.75$\pm$0.64 & 53.71$\pm$0.65 & 70.22$\pm$0.16 & 64.71$\pm$0.33 & 71.30$\pm$0.16 & 52.15$\pm$1.28 & 69.24$\pm$1.46 & 48.48$\pm$3.67\\
        UDAGCN \cite{wu2020unsupervised} & 72.18$\pm$0.12 & 43.34$\pm$0.30 & 48.88$\pm$0.22 & 70.54$\pm$0.04 & 61.67$\pm$0.01 & 69.72$\pm$0.03 & - & - & -\\
        GRADE \cite{wu2023non}  & 78.12$\pm$0.21 & 53.52$\pm$0.07 & 46.80$\pm$0.04 & 74.37$\pm$0.49 & 70.92$\pm$0.04 & 79.48$\pm$0.05 & - & - & -\\
        SpecReg \cite{you2022graph}  & 79.14$\pm$0.38 & 42.85$\pm$2.72 & 47.21$\pm$1.34 & 76.42$\pm$0.66 & 72.69$\pm$0.51 & 78.67$\pm$2.46 & - & - & -\\
        \midrule[0.7pt]
        GCN \cite{kipf2016semi}  & 73.18$\pm$0.45 & 53.57$\pm$0.49 & 47.76$\pm$0.11 & 70.92$\pm$0.15 & 64.64$\pm$0.12 & 72.98$\pm$0.18 & 47.48$\pm$2.01 & 68.09$\pm$1.44 & 46.40$\pm$1.76\\ 
        SAGE \cite{hamilton2017inductive}  & 76.91$\pm$0.78 & 42.24$\pm$0.43 & 45.89$\pm$0.15 & 68.92$\pm$0.28 & 61.25$\pm$0.38 & 67.77$\pm$0.17 & 51.65$\pm$1.44 & 66.78$\pm$1.69 & 49.24$\pm$0.42\\ 
        GAT \cite{velivckovic2017graph}  & 71.59$\pm$0.36 & 39.56$\pm$0.32 & 45.44$\pm$0.93 & 63.85$\pm$1.08 & 56.12$\pm$1.51 & 62.73$\pm$1.09 & 46.04$\pm$1.87 & 65.33$\pm$2.36 & 47.25$\pm$1.83\\
        GIN \cite{xu2018powerful} & 76.92$\pm$0.25 & 40.75$\pm$0.61 & 45.43$\pm$0.26 & 67.02$\pm$0.36 & 59.50$\pm$0.25 & 70.34$\pm$0.23 & 40.79$\pm$4.67 & 67.42$\pm$1.69 &46.07$\pm$1.91\\
        \midrule[0.7pt]
        SHOT \cite{liang2020we}  & 83.82$\pm$0.25 & 64.01$\pm$0.09 & 57.97$\pm$0.07 & 75.34$\pm$0.13 & 68.71$\pm$0.41 & 77.92$\pm$0.05 & 49.56$\pm$2.33 & 60.36$\pm$1.67 & 48.45$\pm$1.38\\ 
        BNM \cite{cui2020towards}   & 81.79$\pm$0.47 & 64.11$\pm$0.23 & 57.79$\pm$0.20 & 75.17$\pm$0.16 & 68.81$\pm$0.12 & 77.38$\pm$0.11 & 49.13$\pm$6.02 & 60.18$\pm$2.28 & 48.80$\pm$0.68\\ 
        ATDOC \cite{liang2021domain}  & 64.72$\pm$0.33 & 57.92$\pm$0.97 & 50.94$\pm$2.80 & 72.67$\pm$0.63 & 65.52$\pm$1.16 & 76.12$\pm$0.29 & 52.01$\pm$2.28 & 56.75$\pm$4.21 & 45.49$\pm$3.30\\ 
        NRC \cite{yang2021exploiting} & 84.42$\pm$0.16 & 63.76$\pm$0.09 & 57.66$\pm$0.05 & 73.13$\pm$0.08 & 69.52$\pm$0.25 & 77.51$\pm$0.22 & 52.30$\pm$3.56 & 60.55$\pm$1.15 & 47.60$\pm$1.06\\ 
        JMDS \cite{lee2022confidence}  & 63.74$\pm$0.39 & 64.00$\pm$0.05 & 46.78$\pm$0.17 & 72.21$\pm$0.37 & 65.26$\pm$0.18 & 74.34$\pm$0.29 & 49.74$\pm$2.00 & 64.61$\pm$0.30 & 51.82$\pm$5.57\\
        GT\textsc{rans}  \cite{jin2022empowering}  & 64.81$\pm$0.89 & 62.54$\pm$0.02 & 57.29$\pm$0.07 & 73.67$\pm$0.65 & 69.59$\pm$2.06 & 78.74$\pm$0.43 & - & - & - \\ 
        SOGA \cite{mao2021source}  & 65.50$\pm$0.55 & 58.24$\pm$0.85 & 46.98$\pm$0.48 & 73.38$\pm$0.17 & 66.96$\pm$0.33 & 78.06$\pm$0.23 & - & - & - \\ 
        GraphCTA \cite{zhang2024collaborate}  & 83.21$\pm$0.43 & 62.70$\pm$0.24 & 56.28$\pm$0.16 & 75.53$\pm$0.30 & 70.91$\pm$0.63 & 79.59$\pm$0.22 & - & - & - \\ 
        TPDS \cite{tang2024source}  & 84.03$\pm$0.23 & 63.14$\pm$0.10 & 57.83$\pm$0.14 & 71.63$\pm$0.12 & 68.45$\pm$0.23 & 75.87$\pm$0.21 & - & - & - \\ 
        \midrule[0.7pt]
         DECISION \cite{ahmed2021unsupervised} & 88.02$\pm$0.28 & 63.92$\pm$0.26 & 57.92$\pm$0.12 & 76.02$\pm$0.67 & 70.40$\pm$0.31 & 79.39$\pm$0.35 & 50.21$\pm$0.74 & 57.89$\pm$2.16 & 48.50$\pm$1.87\\ 
        CAiDA \cite{dong2021confident}  & 87.96$\pm$0.94 & 63.73$\pm$0.49 & 57.73$\pm$0.45 & 75.75$\pm$0.42 & 70.25$\pm$0.54 & 79.70$\pm$0.74 & 50.93$\pm$3.08 & 53.74$\pm$5.27 & 46.25$\pm$2.66\\ 
        MSFDA \cite{shen2023balancing} & 88.94$\pm$0.62 & 54.42$\pm$5.50 & 55.77$\pm$0.58 & 76.03$\pm$1.27 & 68.60$\pm$2.94 & 78.63$\pm$0.92 & 49.64$\pm$1.62 & 62.21$\pm$4.00 & 50.59$\pm$1.32\\ 
        \midrule[0.7pt]
        GraphATA & \textbf{90.14$\pm$0.36} & \textbf{66.71$\pm$0.39} & \textbf{59.56$\pm$0.14} & \textbf{78.45$\pm$0.87} & \textbf{73.17$\pm$0.52} & \textbf{82.33$\pm$0.75} & \textbf{56.47$\pm$1.48} & \textbf{71.26$\pm$2.33} & \textbf{54.15$\pm$1.29}\\ 
        \bottomrule[0.9pt]
    \end{tabular}
    }
    %\vspace{-0.2in}
\end{table*}

\subsection{Results and Analyses}
We show the results of node classification and graph classification in Table \ref{results}. Additional experiments on large-scale datasets are presented in Table \ref{arxiv} and Table \ref{triangle} in Appendix \ref{ablation-appendix}. Each experiment is repeated five times, and we report the mean accuracy along with the standard deviation. Overall, our key observations are as follows.

First, our proposed GraphATA surpasses all the baselines across various adaptation tasks with different margins. For instance, we achieve 12.20\% average relative gains in the scenario of A,D$\rightarrow$C compared with the naive no-adaptation method GCN. This implies that simply taking an average of the source model predictions cannot obtain satisfied performance, which is because different domains might contribute differently to the target domain. Therefore, it is important to aggregate information from multiple source domains with suitable weights. We also notice that GAT exhibits relatively poorer performance within this group. The reason can be attributed to the distribution shifts between source and target domains, as the optimal attention weights in source domains become less suitable for the target domain. 

Second, when further compared with source-need methods that utilize labeled source data during the training process, our model can still outperform them by significant margins. Meanwhile, single-source-needed baselines, which consolidate all the samples into one large source domain, occasionally beat approaches specifically designed for multi-source domain adaptation like MDAN and M$^3$SDA in several settings. It justifies the necessity of aggregating rich information from multiple source domains, since they may contain complementary information for the target domain. 

Third, all the multi-source extensions of single-source-free models demonstrate superior performance compared with non-adapted graph neural networks, even though they utilize the same ensemble strategy. These results suggest that domain adaptation is a promising way to mitigate the distribution shifts across different domains. However, there does not exist a clear winner that consistently outperforms the others within this category, because taking average of the predictions might be sub-optimal in some scenarios. 

Finally, our GraphATA consistently exceeds the strongest baselines tailored for multi-source-free domain adaptation, such as DECISION, CAiDA and MSFDA. This stems from the fact that our model conducts fine-grained adaptation by comprehensively capturing each node's local context information, while existing model-centric approaches only aggregate information at the prediction level and overlook the fine-grained information. In challenging datasets with significant domain shifts, such as the Frankenstein and Protein datasets, traditional multi-source-free models struggle due to the likelihood of negative transfer. In contrast, our proposed GraphATA could filter out irrelevant models and reduce the impact of negative transfer, leading to more precise adaptation.

\subsection{Ablation Studies}

\begin{table}
\small
\centering
    \caption{GraphATA results with different components.}
        \begin{tabular}{l|c|c|c}
           \hline
           Models & A,C$\rightarrow$D & C,D$\rightarrow$A  &  A,D$\rightarrow$C \\ 
           \hline
           GraphATA & 78.45$\pm$0.87 & 73.17$\pm$0.52 & 82.33$\pm$0.75 \\ 
           GraphATA$_{\rm softmax}$ & 73.99$\pm$1.61 & 71.13$\pm$0.85 & 80.50$\pm$0.50  \\ 
           GraphATA$_{\rm MC}$ & 74.97$\pm$0.65 & 70.23$\pm$0.69 & 79.70$\pm$0.81 \\
           GraphATA$_{\rm LC}$ & 74.60$\pm$0.97 & 68.91$\pm$0.58  & 77.38$\pm$0.61 \\ 
           \hline
        \end{tabular}
        \label{ablation}
\end{table}

\begin{figure*}[!htb]\small
\centering
\subfigure[\scriptsize{Number of layers}]{
\label{fig:num_layers}
\centering
\includegraphics[width=0.225\textwidth]{graph/layers-eps-converted-to.pdf}
}
\subfigure[\scriptsize{Trade-off param $\lambda$}]{
\label{fig:lambda}
\centering
\includegraphics[width=0.225\textwidth]{graph/lambdas-eps-converted-to.pdf}
}
\subfigure[\scriptsize{Attention at Layer 1}]{
\label{fig:att-1}
\centering
\includegraphics[width=0.225\textwidth]{graph/attlayer1-eps-converted-to.pdf}
}
\subfigure[\scriptsize{Attention at Layer 2}]{
\label{fig:att-2}
\centering
\includegraphics[width=0.225\textwidth]{graph/attlayer2-eps-converted-to.pdf}
}
\caption{Hyper-parameter sensitivity analysis and attention weights visualization.}
\label{hyper-vis}
\end{figure*}

\textbf{The Effect of Different Modules.} To fully investigate the contribution of each component in our proposed GraphATA model, we conduct a series of ablation studies on citation datasets. We first show the rationality and effectiveness of utilizing sparse attention to selectively aggregate convolutional matrices from multiple source pre-trained models. When replacing the sparsemax function with softmax function in Eq. (\ref{eq:sparsemax}) (termed as GraphATA$_{\rm softmax}$), its performance degrades $4.46\%$ and $2.04\%$ in Table \ref{ablation}, respectively. This indicates that not all of the source models are useful, and filtering out irrelevant information would be beneficial. We further degenerate Eq. (\ref{eq:graphmatrix}) to model-centric method (restricting the information aggregation to the last layer) and layer-centric method (setting $\mathbf{c}_v = \mathbf{1}$, $\mathbf{W}_g = \mathbf{0}$), which are denoted as GraphATA$_{\rm MC}$ and GraphATA$_{\rm LC}$. When compared with GraphATA, their performance decreases about $2.93\% \sim 4.26\%$. This justifies the advantages of conducting fine-grained node-centric adaptation. More ablation studies can be found at Appendix \ref{ablation-appendix}.

\textbf{Hyperparameter Analysis and Attention Visualization.} We also show the impacts of several key hyper-parameters in Figure \ref{fig:num_layers} and Figure \ref{fig:lambda}. Particularly, when setting number of layers $L=2$ and $\lambda=0.2$, our model could always obtain the satisfied performance. To demonstrate the uniqueness of each node's graph convolutional matrices, we randomly sample a graph with $11$ nodes and $11$ edges from the Mutagenicity graph classification dataset. The two-layer target model is optimized in the setting of M1,M2,M3$\rightarrow$M4. Then, we plot the attention weights for each node at each layer in Figure \ref{fig:att-1} and Figure \ref{fig:att-2}. As we can see, when aggregating convolutional matrices from source domains, distinct nodes have different inclinations both within each layer and across different layers. For instance, our model mainly aggregates information from SM2 and SM3 at layer 1, while it integrates information from SM1 and SM2 at layer 2. Both two layers do not use all of the three pre-trained models. We also note that node 10 and node 11 consistently utilize SM2's convolutional matrix across both layers. In contrast, the remaining nodes assign different weights to SM2 in layer 2 compared with layer 1. This highlights different source models indeed play distinct roles in modeling different nodes in the graph, therefore it is necessary to take fine-grained node-wise adaptation into consideration to effectively address the distribution shifts problem. By tailoring the adaptation to the unique characteristics of each node, we can more accurately align with the target graph's local structures, leading to more robust generalization.

\textbf{The Effect of Different Loss Functions and GNN Architectures.} Our GraphATA can also seamlessly integrate with various loss functions. To show the effectiveness of our proposed neighborhood consistency loss function, we replace it with three widely adopted loss functions from existing domain adaptation methods including SHOT \cite{liang2020we}, BNM \cite{cui2020towards} and CAiDA \cite{dong2021confident}. Specifically, SHOT employs self-clustering to generate pseudo labels, which overlooks its local neighborhood information. BNM adopts nuclear norm maximization to improve the model's  discriminability and diversity, while CAiDA utilizes various strategies to select confident anchors and then construct pseudo labels through them. The results are shown in Table \ref{losses} and we can conclude that our model consistently outperforms these variants with different gains. Our strategy does not require complicated operations and has fewer hyperparameters. Moreover, when removing the regularization term $\mathcal{L}_{\rm reg}$, its performance decreases a little bit, which indicates the entropy constraints could help reduce noises in the predictions. We also investigate the transferability of different widely used graph neural network architectures, such as GCN \cite{kipf2016semi}, GraphSAGE \cite{hamilton2017inductive}, GAT \cite{velivckovic2017graph} and GIN \cite{xu2018powerful}. Their results are demonstrated in Table \ref{architecture}. Surprisingly, we observe that the simplest architecture GCN performs best among all the architectures, which is consistent with the results of no-adaptation methods.

\begin{table}
\centering
\caption{GraphATA results with different loss functions.}
        \begin{tabular}{l|c|c|c}
           \hline
           Models & A,C$\rightarrow$D & C,D$\rightarrow$A  &  A,D$\rightarrow$C \\ 
           \hline
           GraphATA & 78.45$\pm$0.87 & 73.17$\pm$0.52 & 82.33$\pm$0.75 \\ 
           GraphATA$_{\rm w/o \mathcal{L}_{\rm reg}}$ & 74.37$\pm$1.20 & 69.30$\pm$1.52 & 80.02$\pm$0.45  \\ 
           GraphATA+SHOT & 74.78$\pm$1.07 & 69.77$\pm$0.44 & 78.03$\pm$0.19 \\
           GraphATA+BNM & 75.90$\pm$0.18 & 69.09$\pm$0.12  & 77.77$\pm$0.40 \\ 
           GraphATA+CAiDA & 73.70$\pm$0.29 & 68.90$\pm$0.27  & 76.98$\pm$0.98 \\ 
           \hline
        \end{tabular}
        \label{losses}
\end{table}

\begin{table}
\centering
    \caption{GraphATA results with different GNN architectures.}
        \begin{tabular}{l|c|c|c}
           \hline
           Architectures & A,D$\rightarrow$C & C,D$\rightarrow$A & A,C$\rightarrow$D  \\ 
           \hline
           GraphATA$_{\rm GCN}$ & 82.33$\pm$0.75 & 73.17$\pm$0.52 & 78.45$\pm$0.87 \\ 
           GraphATA$_{\rm SAGE}$ & 79.41$\pm$0.27 & 69.47$\pm$0.86 & 73.83$\pm$0.86 \\
           GraphATA$_{\rm GAT}$ & 77.90$\pm$0.95 & 69.48$\pm$0.68 & 71.81$\pm$0.99 \\ 
           GraphATA$_{\rm GIN}$ & 77.06$\pm$0.33 & 65.77$\pm$0.25 & 72.10$\pm$1.29 \\ 
           \hline
        \end{tabular}
        \label{architecture}
        \vspace{-0.1in}
\end{table}

\textbf{Embedding Visualization.} For a more intuitive grasp of the acquired target node representations, we project them into 2-D space via t-SNE \cite{van2008visualizing}. The scatter plots of MDAN \cite{zhao2018adversarial}, GRADE \cite{wu2023non}, DECISION \cite{ahmed2021unsupervised} and GraphATA are presented in Figure \ref{visualization}, where different colors indicate different different classes. Among them, two source-needed representatives MDAN and GRADE can not generate satisfactory visualizations, since there are no clear boundaries among these clusters, and nodes from different clusters are intertwined with each other. On the contrary, DECISION and our proposed GraphATA can cluster nodes together within the same classes, which validates the importance of distinguishing the contributions from different source domains. Furthermore, our GraphATA produces more compact clusters with clear boundaries.

\begin{figure}[!htb]\small
\centering
\subfigure[\scriptsize{MDAN}]{
\label{fig:MDAN}
\centering
\includegraphics[width=0.225\textwidth]{graph/MDAN-eps-converted-to.pdf}
}
\subfigure[\scriptsize{GRADE}]{
\label{fig:GRADE}
\centering
\includegraphics[width=0.225\textwidth]{graph/GRADE-eps-converted-to.pdf}
}
\subfigure[\scriptsize{DECISION}]{
\label{fig:DECISION}
\centering
\includegraphics[width=0.225\textwidth]{graph/DECISION-eps-converted-to.pdf}
}
\subfigure[\scriptsize{GraphATA}]{
\label{fig:GraphATA}
\centering
\includegraphics[width=0.225\textwidth]{graph/GraphATA-eps-converted-to.pdf}
}
\caption{Node embedding visualizations in target graph, where colors correspond to different classes in citation networks (C,A$\rightarrow$D).}
\label{visualization}
\vspace{-0.2in}
\end{figure}

\section{Conclusion}
\label{sec:impact}
We investigate an important yet unexplored problem: unsupervised multi-source-free graph domain adaptation, which adapts multiple source pre-trained models without accessing the labeled source data. More specifically, we propose to perform node-centric instead of model-centric adaptation by parameterizing each node with its own graph convolutional matrix according to its local context information. The whole framework can be applied to various graph neural network architectures and downstream tasks including node as well as graph classification. We also illustrate that GraphATA can generalize to existing model-centric and layer-centric methods. Comprehensive experiments are conducted to show the effectiveness of our proposed GraphATA. For future work, it would be interesting to extend our model to more complex adaptation tasks like open-set graph domain adaptation and graph domain out-of-distribution, etc. 

\begin{acks}
This research is supported by the National Research Foundation, Singapore under its Industry Alignment Fund – Pre-positioning (IAF-PP) Funding Initiative and NUS Artificial Intelligence Institute Seed Funding. Any opinions, findings and conclusions or recommendations expressed in this material are those of the author(s) and do not reflect the views of National Research Foundation, Singapore. 
\end{acks}


%%
%% The next two lines define the bibliography style to be used, and
%% the bibliography file.
\bibliographystyle{ACM-Reference-Format}
\bibliography{reference}


%%
%% If your work has an appendix, this is the place to put it.
\appendix

\section{Proof for Equation (\ref{sparseterm})}
\label{sec:proof}
To summarize, ${\rm sparsemax}(\cdot)$ considers the euclidean projection of the input vector $\bm{\alpha}$ onto the probability simplex, which can be defined as the following optimization problem:
\begin{equation}
    \mathop{\arg\min}\limits_{\bm{x} \in \Delta^{m-1}} \Vert \bm{x} - \bm{\alpha} \Vert^2, \  s.t., \ \mathbf{1}^{\top}\bm{x}=1, \ \bm{x} \geq \mathbf{0}.
    \label{proof}
\end{equation}
Then, the Lagrangian of the optimization problem in Eq. (\ref{proof}) is:
\begin{equation}
    \mathcal{L}(\bm{x}, \bm{\mu}, \omega) = \frac{1}{2} \Vert \bm{x} - \bm{\alpha} \Vert^2 - \bm{\mu}^\top\bm{x} + \omega(\mathbf{1}^{\top}\bm{x} - 1). 
\end{equation}
The optimal $(\bm{x}^{*}, \bm{\mu}^{*}, \omega^{*})$ must satisfy the following KarushKuhn-Tucker conditions:
\begin{equation}
    \bm{x}^{*} - \bm{\alpha} - \bm{\mu}^{*} + \omega^{*}\mathbf{1} = 0,
    \label{condition1}
\end{equation}
\begin{equation}
    \mathbf{1}^{\top}\bm{x}^{*}=1, \ \bm{x}^{*} \geq 0, \ \bm{\mu}^{*} \geq 0,
    \label{condition2}
\end{equation}
\begin{equation}
    {x}^{*}_i{\mu}^{*}_i = 0, \ \forall i \in \{1, \cdots, m\}.
    \label{condition3}
\end{equation}
If for $\forall i \in \{1, \cdots, m\}$, we have $x_i^{*} > 0$, then from Eq. (\ref{condition3}) we must satisfy $\mu_i^{*} = 0$. Thus, from Eq. (\ref{condition1}), we can get $x_i^{*} = \alpha_i - \omega^{*}$. Let $S(\bm{\alpha}) = \{j \in \{1,\cdots,m\}|x_j^{*} > 0\}$. From Eq. (\ref{condition2}), we obtain $\sum_{j \in S(\bm{\alpha})}(\alpha_j - \omega^{*}) = 1$, which yields $\omega^{*} = \tau(\bm{\alpha})$ in Eq. (\ref{sparseterm}). Again, from Eq. (\ref{condition3}), we have that $\mu_i^{*} > 0$ implies $x_i^{*} = 0$, which from Eq. (\ref{condition1}) implies $\mu_i^{*} = \omega^{*} - \alpha_i^{*} \geq 0$, i.e., $\alpha_i^{*} \leq \omega^{*}$ for $i \notin S(\bm{\alpha})$. That's to say, if the element $\alpha_i$ less than threshold $\omega^{*}$, then $\mu_i^{*}$ will larger than 0, and output $x_i$ must be reset to 0 to satisfy Eq. (\ref{condition3}). Thus, we can generate the sparse values and have the property of sum-to-one.

\section{Datasets Details}
\label{sec:dataset-appendix}
In this section, we present the detailed information for experimental datasets including data processing and dataset splits. Specifically, we employ three types of graphs for the node classification task, which involve synthetic, social and citation networks. For synthetic datasets, contextual stochastic block models with different intra-class probability $p$ and inter-class probability $q$ are utilized to synthesize varying degrees of conditional structural shifts. Particularly, we fix intra-class probability $p=0.04$ and vary inter-class probability $q$ from $\{0.012, 0.014, 0.016, 0.018\}$ to generate C1, C2, C3 and C4. As for node attributes, we construct a multivariate normal distribution for each class, where the mean vectors are set as $\{-2.0, -2/3, 2/3, 2\}$ with 128-dimension for each class and the covariance matrix is fixed as identity matrix. Then, each class's node attributes are sampled from those multivariate normal distributions. For Twitch datasets, we use their default splits, and different sub-datasets are constructed from distinct regions, which encompasses domain level distribution shifts across different datasets. For Citation dataset, the graphs are extracted from different platforms and periods, thus it contains both domain level and temporal level distribution shifts. For graph classification task, we employ three TUdatasets: Proteins, Mutagenicity, and Frankenstein, partitioning each dataset into four equally sized disjoint groups based on density shifts. The detailed information is presented in Table \ref{overalldatasets}.

\textbf{Ethical Use of Data and Informed Consent.} All of our datasets are synthetic or publicly available, and do not involve human participants and subjects.

\begin{table*}
    \caption{Comparisons of time and space complexity.}
    \label{time-space}
    \centering
    \small
    \begin{tabular}{ccc}
        \toprule[0.9pt]
         & DECISION & GraphATA \\ 
        \midrule[0.7pt]
         Time  &  $\mathcal{O}(Lmnd^2 + Lmed + mnd + mnKd)$ & $\mathcal{O}(Lnd^2 + Led + mnd + nmlog(m) + dnlog(n))$  \\
         Space  & $\mathcal{O}(m|G| + mnd + mnK)$ & $\mathcal{O}(m|G| + nd + nK + |S|)$   \\
        \bottomrule[0.9pt]
    \end{tabular}
\end{table*}

\section{Time and Space Complexity Comparisons}
\label{sec:complexity-appendix}

\textbf{Complexity Analysis.} Suppose that we have a graph with $n$ nodes and $e$ edges, the node representation dimension is set as $d$ and the graph neural network has $L$ layers. Calculating the local contextual information in each layer has the cost of $\mathcal{O}(ed)$. Then, if we have $m$ source models from different domains, the time complexity of generating sparse attention weights for each node is $\mathcal{O}(md + m{\rm log}(m))$. Over $L$ layers, the feature encoder has the time complexity of $\mathcal{O}(Lnd^2 + Led)$. Computing pseudo labels involves obtaining nearest neighbors, which takes $\mathcal{O}(dn{\rm log}(n))$ using k-d tree. Thus, the overall time complexity of our model falls within the same range as that of vanilla graph neural network.

We compare our proposed model with DECISION \cite{ahmed2021unsupervised}, a representative model-centric multi-source-free domain adaptation method. Specifically, given a graph with $n$ nodes and $e$ edges, the node representation dimension is set as $d$ and GNN has $L$ layers. $K$ is the number of categories. Then, if we have $m$ source models from different domains, the feature encoder has the time complexity of $\mathcal{O}(Lmnd^2 + Lmed)$. The time complexity of calculating cluster centroids for $m$ models is $\mathcal{O}(mnd)$. Computing the pseudo-label of each sample by assigning it to its nearest cluster centroid has a time complexity of $\mathcal{O}(mnKd)$ for $m$ models. Thus, the overall time complexity is $\mathcal{O}(Lmnd^2 + Lmed + mnd + mnKd)$. Meanwhile, to store $m$ models’ predictions and node representations, it requires a space complexity of $\mathcal{O}(mnd + mnK)$. The time complexity of our proposed GraphATA has been discussed in the end of Section \ref{sec:model}. For ease of comparison, we present the time and space complexity of DECISION and GraphATA in Table \ref{time-space}. Among them, $|G|$ refers to the model parameters of the Graph Neural Network (GNN), while $|S|$ represents the additional parameters of our model, such as $W_g^l$ and $a^l$. Our model utilizes aggregated weight matrices to perform graph convolution once, while DECISION performs graph convolution $m$ times and then aggregates their predictions. Similarly, GraphATA maintains one node representation bank and one prediction bank, while DECISION stores them $m$ times. Thus, GraphATA has lower time and space complexity compared with DECISION. It’s worth noting that other baselines like CAiDA \cite{dong2021confident} and MSFDA \cite{shen2023balancing} exhibit higher time complexity compared to DECISION, because they utilize more complicated strategies to generate pseudo-labels. In summary, our model demonstrates the lowest time and space complexity among the compared multi-source-free methods.


\section{More Ablation Studies and Experiments}
\label{ablation-appendix}

\begin{figure}
    \centering
    \includegraphics[width=0.225\textwidth]{graph/dim-eps-converted-to.pdf}
    \includegraphics[width=0.225\textwidth]{graph/neighbors-eps-converted-to.pdf}
    \caption{Hyper-parameter sensitivity analysis.}
    \label{hyper-parameter}
\end{figure}

\begin{table}
\centering
\caption{GraphATA results with different local contexts.}
        \begin{tabular}{l|c|c|c}
           \hline
           Context & A,C$\rightarrow$D & C,D$\rightarrow$A & A,D$\rightarrow$C  \\ 
           \hline
           $\mathbf{c}_{max}$ & 75.67$\pm$1.21 & 71.66$\pm$1.15 & 78.09$\pm$2.01 \\ 
           $\mathbf{c}_{min}$ & 74.63$\pm$2.16 & 70.40$\pm$1.07 & 79.93$\pm$1.18 \\
           $\mathbf{c}_{sum}$ & 72.50$\pm$1.44 & 70.01$\pm$2.75 & 80.10$\pm$1.02 \\ 
           $\mathbf{c}_{mean}$ & 78.45$\pm$0.87 & 73.17$\pm$0.52 & 82.33$\pm$0.75 \\ 
           \hline
        \end{tabular}
        \label{context}
\end{table}

\textbf{Hyperparameter Analyses.}  
We present the sensitivities of node representation dimension and number of nearest neighbors in Figure \ref{hyper-parameter}. Particularly, node dimension $d=128$ and $r=40$, our model could always obtain the satisfied performance. As we can see, accuracy improves consistently as the node representation dimension increases from $32$ to $128$, then slightly drops at $256$. For number of nearest neighbors, the accuracy remains relatively stable, fluctuating between $75\%$ and $80\%$, with a slight dip at $20$ neighbors, then recovering toward $40$ neighbors. This is because too few nearest neighbors could not provide sufficient supervision information, while too many nearest neighbors might introduce noises into the generation process. While there are fluctuations, they remain within a reasonable range, as our sensitivity analysis covering a wide range of nearest neighbor values.

\textbf{The Effect of Different Aggregation Strategies for Local Contexts.} The mean operation is chosen for its simplicity in aggregating information from neighboring nodes. It provides a straightforward way to capture the average characteristics of the neighborhood, which is widely adopted in many graph-based learning models. While it is true that the mean operation can sometimes result in similar $\mathbf{c}$ values for nodes with different types of neighbors, our ablation studies demonstrate that our model maintains high performance when compared to other aggregation strategies such as max, min and sum, as shown in the Table \ref{context}. These results highlight the robustness of our mean aggregation approach despite its simplicity.

\begin{table}
\centering
\caption{GraphATA results on ogbn-arxiv datasets.}
        \begin{tabular}{lcc}
           \hline
           Methods & 2016-2018 & 2018-2020   \\ 
           \hline
           GCN \cite{kipf2016semi} & 55.57$\pm$0.09 & 53.03$\pm$0.16  \\ 
           SOGA \cite{mao2021source} & 58.10$\pm$0.23 & 52.28$\pm$0.12  \\
           DECISION \cite{ahmed2021unsupervised} & 59.53$\pm$0.17 & 57.55$\pm$0.34  \\ 
           CAiDA \cite{dong2021confident} & 58.42$\pm$0.14 & 56.19$\pm$0.38  \\ 
           MSFDA \cite{shen2023balancing} & 61.78$\pm$0.87 & 59.91$\pm$0.20  \\ 
           GraphATA & \textbf{63.55$\pm$0.94} & \textbf{60.85$\pm$0.13}  \\ 
           \hline
        \end{tabular}
        \label{arxiv}
\end{table}

\begin{table}
\centering
\caption{GraphATA results on TRIANGLE datasets.}
        \begin{tabular}{lcc}
           \hline
           Methods & T1,T2,T4$\rightarrow$T3 & T1,T2,T3$\rightarrow$T4   \\ 
           \hline
           DECISION \cite{ahmed2021unsupervised} & 31.90$\pm$0.61 & 19.40$\pm$0.23  \\ 
           CAiDA \cite{dong2021confident} & 40.23$\pm$0.39 & 17.05$\pm$0.77  \\ 
           MSFDA \cite{shen2023balancing} & 39.46$\pm$0.59 & 19.04$\pm$1.46  \\ 
           GraphATA & \textbf{43.08$\pm$0.77} & \textbf{22.49$\pm$0.34}  \\ 
           \hline
        \end{tabular}
        \label{triangle}
        \vspace{-0.2in}
\end{table}

\begin{table*}[ht]
    \centering
    \caption{Average node and graph classification performance in terms of accuracy with standard deviation (\%).}
    \label{results-ab}
    %\small
    \begin{tabular}{lcccccc}
        \toprule[0.9pt]
        Models & C1,C2,C4 & C1,C3,C4 & C2,C3,C4& P1,P2,P4 & P1,P3,P4 & P2,P3,P4  \\
         & $\rightarrow$ C3 & $\rightarrow$ C2 & $\rightarrow$ C1& $\rightarrow$ P3 & $\rightarrow$ P2& $\rightarrow$P1 \\
        \midrule[0.7pt]
         MDAN & 89.65$\pm$0.15 & 91.88$\pm$0.31 & 91.33$\pm$0.28 & 67.45$\pm$0.17 & \textbf{77.66$\pm$0.18} & 54.10$\pm$0.25 \\ 
         GCN & 86.14$\pm$0.16 & 87.75$\pm$0.08 & 76.46$\pm$0.12 & 63.44$\pm$1.07 & 72.30$\pm$0.71 & 55.57$\pm$1.34 \\ 
         DECISION & 91.05$\pm$0.74 & 92.15$\pm$0.81 & 92.05$\pm$0.56 & 65.23$\pm$1.43 & 70.32$\pm$0.89 & 71.04$\pm$0.93 \\ 
        CAiDA  & 90.31$\pm$0.19 & 91.37$\pm$0.20 & 91.61$\pm$0.56 & 64.69$\pm$0.18 & 71.40$\pm$0.53 & 67.62$\pm$0.67  \\ 
        MSFDA & 92.87$\pm$0.49 & 92.75$\pm$0.28 & 93.31$\pm$0.14 & 67.02$\pm$1.17 & 72.48$\pm$0.89 & 56.51$\pm$0.53  \\ 
        \midrule[0.7pt]
        GraphATA & \textbf{93.49$\pm$0.71} & \textbf{93.85$\pm$0.42} & \textbf{94.62$\pm$0.84} & \textbf{68.48$\pm$0.16} & 74.19$\pm$0.13 & \textbf{72.47$\pm$0.85} \\ 
        \bottomrule[0.9pt]
        \toprule[0.9pt]
         & M1,M2,M4 & M1,M3,M4 & M2,M3,M4& F1,F2,F4 & F1,F3,F4 & F2,F3,F4  \\
         & $\rightarrow$ M3 & $\rightarrow$ M2 & $\rightarrow$ M1& $\rightarrow$ F3 & $\rightarrow$ F2& $\rightarrow$F1 \\
        \midrule[0.7pt]
        MDAN & 76.91$\pm$0.78 & \textbf{82.05$\pm$1.15} & 70.89$\pm$0.23 & 50.18$\pm$0.46 & 48.48$\pm$0.23 & 58.90$\pm$0.32 \\ 
        GCN & 78.24$\pm$0.92 & 77.30$\pm$1.42 & 71.54$\pm$0.96 & 55.29$\pm$0.69 & 52.76$\pm$0.36 & 56.13$\pm$1.06 \\ 
        DECISION & 68.89$\pm$1.79 & 64.21$\pm$1.84 & 58.16$\pm$0.51 & 54.33$\pm$1.24 & 51.75$\pm$0.46 & 53.82$\pm$0.69 \\ 
        CAiDA  & 66.35$\pm$1.65 & 69.28$\pm$1.39 & 63.05$\pm$0.50 & 53.92$\pm$1.47 & 48.00$\pm$0.55 & 56.54$\pm$2.02  \\ 
        MSFDA  & 76.63$\pm$0.50 & 74.21$\pm$1.89 & 65.21$\pm$1.64 & 51.15$\pm$0.89 & 48.52$\pm$0.96 & 53.69$\pm$0.36  \\ 
        \midrule[0.7pt]
        GraphATA & \textbf{80.62$\pm$0.33} & 78.54$\pm$0.17 & \textbf{72.67$\pm$0.32} & \textbf{57.46$\pm$0.64} & \textbf{54.78$\pm$0.83} & \textbf{60.45$\pm$0.22} \\ 
        \bottomrule[0.9pt]
        \toprule[0.9pt]
         & R,P,F,EN, & R,P,F,EN, & R,P,F,DE, & P,F,DE,EN,  & R,F,DE,EN, & R,P,DE,EN,  \\
         & ES$\rightarrow$ DE & DE$\rightarrow$ ES & ES$\rightarrow$ EN & ES$\rightarrow$ R & ES$\rightarrow$ P & ES$\rightarrow$F \\
        \midrule[0.7pt]
        MDAN & 58.60$\pm$0.23 & 70.83$\pm$0.10 & 50.46$\pm$0.58 & 73.94$\pm$0.12 & 65.74$\pm$0.31 & 63.20$\pm$0.15 \\ 
        GCN & 47.08$\pm$0.33 & 71.32$\pm$0.20 & 48.85$\pm$0.21 & 69.61$\pm$0.30 & 68.04$\pm$0.50 & 64.90$\pm$0.63 \\ 
         DECISION & 60.90$\pm$0.98 & 61.86$\pm$0.65 & 58.36$\pm$0.54 & 66.60$\pm$0.86 & 67.01$\pm$0.15 & 77.26$\pm$0.32 \\ 
        CAiDA  & 53.79$\pm$0.84 & 68.13$\pm$0.70 & 58.49$\pm$0.56 & 69.63$\pm$0.14 & 68.34$\pm$0.27 & 72.60$\pm$0.64  \\ 
        MSFDA  & 59.40$\pm$1.93 & 70.74$\pm$0.75 & 54.68$\pm$1.00 & 75.41$\pm$0.68 & 65.08$\pm$0.54 & 78.06$\pm$1.80  \\ 
        \midrule[0.7pt]
        GraphATA & \textbf{62.49$\pm$0.12} & \textbf{72.55$\pm$0.38} & \textbf{59.57$\pm$0.61} & \textbf{77.50$\pm$0.15} & \textbf{70.58$\pm$0.51} & \textbf{80.21$\pm$0.17} \\ 
        \bottomrule[0.9pt]
        \bottomrule[0.9pt]
    \end{tabular}
\end{table*}

\textbf{Additonal Experimental Results.} We conduct experiments on a larger citation dataset \textbf{ogbn-arxiv} for node classification task, which contains $169,343$ nodes and $1,166,243$ edges from $40$ classes. The dataset is chronologically divided into five groups according to the publication years of the papers.{\it We construct three source graphs encompassing papers published before 2011, during the periods 2011-2014 and 2014-2016, while the two target graphs are derived from the periods 2016-2018 and 2018-2020}. The results are presented in Table \ref{arxiv}. As demonstrated in the table, our proposed GraphATA consistently exhibits effective performance across various adaptation scenarios within this large-scale citation dataset.

We also choose the \textbf{TRIANGLE} dataset, a large-scale dataset from TUDataset for graph classification task, which consists of 45000 graphs across 10 classes. Then, we partition it into four equally size disjoint groups based on density shift (i.e., T1,T2,T3,T4) and compare our model with 3 recent multi-source-free baselines. The results are demonstrated in Table \ref{triangle}. As shown in the table, our proposed model consistently demonstrates strong performance across a range of adaptation scenarios within this large-scale dataset.

Finally, Table \ref{results-ab} presents all the adaptation results on social datasets and TUDatasets, which further verify the effectiveness of our proposed GraphATA under different settings.

\begin{table}
\centering
\caption{GPU memory and time in C,D$\rightarrow$A.}
        \begin{tabular}{lcc}
           \hline
           Methods & GPU & Time  \\ 
           \hline
           MDAN \cite{zhao2018adversarial} & 12800MB & 0.1075s  \\ 
           M$3$SDA \cite{peng2019moment} & 17688MB & 0.1198s  \\ 
           DECISION \cite{ahmed2021unsupervised} & 6920MB	 & 1.5050s  \\ 
           CAiDA \cite{dong2021confident} & 6880MB & 3.6579s \\ 
           MSFDA \cite{shen2023balancing} & 10080MB & 9.1350s  \\ 
           GraphATA & 5930MB & 0.0893s  \\ 
           \hline
        \end{tabular}
        \label{cite-gpu-time}
\end{table}

\begin{table}
\centering
\caption{GPU memory and time in P1,P2,P3$\rightarrow$P4.}
        \begin{tabular}{lcc}
           \hline
           Methods & GPU & Time   \\ 
           \hline
           MDAN \cite{zhao2018adversarial} & 756MB & 0.0401s  \\ 
           M$3$SDA \cite{peng2019moment} & 3898MB	 & 0.1144s  \\ 
           DECISION \cite{ahmed2021unsupervised} & 674MB & 0.0428s \\ 
           CAiDA \cite{dong2021confident} & 668MB & 0.0468s  \\ 
           MSFDA \cite{shen2023balancing} & 684MB & 9.3613s  \\ 
           GraphATA & 596MB & 0.0380s \\ 
           \hline
        \end{tabular}
        \label{tri-gpu-time}
\end{table}

\textbf{GPU Consumption and Training Time per Iteration.} We measured the GPU consumption and training time per epoch for our proposed GraphATA and compared it with representative methods as follows. GCN is trained independently on each labeled source domain and then directly evaluated on the target domain without any adaptation process. Therefore, we do not report the GPU consumption and training time for GCN. We also do not report the results of single-source-free models, as they require adapting each of the $m$ source models to the target domain individually. Instead, we focus on reporting the adaptation time for source-needed as well as multi-source-free models to provide a meaningful comparison of their performance in adapting to the target domain. The results are shown in Table \ref{cite-gpu-time} and Table \ref{tri-gpu-time}, which is consistent with our analyses in previous sections.

\end{document}
\endinput
%%
%% End of file `sample-sigconf.tex'.
