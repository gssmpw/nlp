



\section{Cost Analysis}\label{sec:exp:cost}

\sssec{Method}.
We did a cost analysis to show the gap between the large search space and the search efficiency of the \sysname.
We selected Llama-2 models (7B, 13B, and 70B) with 64, 256, 1024, and 4096 GPUs.
Then, for all the settings, we implemented \sysname\ on it and recorded the searched strategy number along with the end-to-end time (search time and simulation time)


\sssec{Result}. As shown in Table \ref{tab:exp:cost}, the number of explored strategies grows exponentially with model size. For smaller models like Llama-7B, even with 4096 GPUs, the search space remains relatively small. However, for larger models such as Llama-70B, the search space nearly triples compared to Llama-7B under the same GPU configuration. The end-to-end time reveals that the simulation phase is the main bottleneck, which may take 1 minute to execute on average. While the search time only takes less than 1 second to execute on average. This highlights the need for optimizing the simulation process, particularly in large-scale settings, while \sysnameâ€™s search algorithm remains efficient and scalable across different configurations.


