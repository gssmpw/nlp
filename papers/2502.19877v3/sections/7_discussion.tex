\section{DISCUSSION AND FUTURE WORK}

% This work focuses on joint attention in parent-child interactions, exploring the potential and limitations of MLLMs in detecting and analysing this critical concept. Additionally, our findings provide insights that may inform future research on other important concepts in parent-child interactions, such as imitation and joint intention.

% Our analysis highlights a notable gap between the results generated by MLLMs and the judgments of SLPss. For example, despite models like GPT-4o demonstrating high parent-child interaction description accuracy, their joint-attention temporal grounding performance remains low. This discrepancy suggests that MLLMs struggle with the deeper contextual understanding required to align their outputs with human-level expertise. Factors such as limited Eye-Contact Sensitivity and Accuracy likely contribute to this gap, as these elements play a critical role in understanding joint attention events. These observations highlight the need for further research to investigate and bridge this gap, offering a reference point for others exploring the alignment of MLLMs with professional expert reasoning.

This work focuses on joint attention in parent-child interactions, exploring the potential and limitations of MLLMs in detecting and analysing this critical concept. Additionally, our findings provide insights that may inform future research on other important aspects of parent-child interactions, such as imitation and joint intention.

\subsection{Towards better Human-Centered AI for Joint Attention}
Our results highlight significant gaps in MLLMs' sensitivity and accuracy regarding eye contact information, a critical element in understanding joint attention. For example, determining what a child is looking at often requires precise gaze estimation and object detection, areas where traditional computer vision methods excel~\cite{ke2024tail, ke2025detection, cyu2025identifying}. A potential direction for researchers is to explore how eye contact information can be effectively integrated into MLLMs by combining these conventional approaches with multimodal capabilities. Another challenge is improving MLLMs' performance on complex tasks like temporal grounding for joint attention, which requires a deeper contextual and sequential understanding of interactions.

\subsection{Need for Dataset Diversification}
Our findings emphasize the critical need to diversify datasets to advance parent-child interaction research. Currently, available datasets are primarily focused on specific, fixed scenarios, limiting their generalizability. To address this, researchers should prioritize collecting data from a broader range of parent-child interaction contexts. For example, beyond the fixed scenarios we collected, datasets capturing interactions during free activities within a room or other everyday environments could provide richer insights. This would not only support research on joint attention but also facilitate analysis of other key components, such as joint intention and imitation. Moreover, addressing the scarcity of "poor" joint attention segments in existing datasets is crucial for enabling more robust model training and evaluation. Expanding the variety and scope of datasets will be instrumental in enhancing the effectiveness and applicability of computational models in this domain.
% Our findings also underline the importance of diversifying datasets to support parent-child interaction research. Beyond joint attention, key components such as joint intention and imitation also require datasets with expert annotations to advance analysis. Additionally, there is a need for more diverse video data on parent-child interactions, addressing the current scarcity of "poor" joint attention segments. Expanding the variety and scope of datasets is crucial to enable more robust training and evaluation of models.

By addressing these challenges and advancing both dataset development and model capabilities, future research can better align MLLMs with expert-level reasoning in parent-child interaction analysis.