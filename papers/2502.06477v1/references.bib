@inproceedings{abboudExactWeightSubgraphs2013,
  title = {Exact {{Weight Subgraphs}} and the K-{{Sum Conjecture}}},
  booktitle = {Automata, {{Languages}}, and {{Programming}}},
  author = {Abboud, Amir and Lewi, Kevin},
  year = {2013},
  series = {Lecture {{Notes}} in {{Computer Science}}},
  pages = {1--12},
  publisher = {Springer},
  address = {Berlin, Heidelberg},
  doi = {10.1007/978-3-642-39206-1_1},
  abstract = {We consider the Exact-Weight-H problem of finding a (not necessarily induced) subgraph H of weight 0 in an edge-weighted graph G. We show that for every H, the complexity of this problem is strongly related to that of the infamous k-sum problem. In particular, we show that under the k-sum Conjecture, we can achieve tight upper and lower bounds for the Exact-Weight-H problem for various subgraphs H such as matching, star, path, and cycle.},
  isbn = {978-3-642-39206-1},
  langid = {english},
  keywords = {Edge Deletion,Edge Weight,Full Version,Small Subgraph,Subgraph Problem},
  file = {/Users/sebastian/Zotero/storage/GYHDMNHI/Abboud and Lewi - 2013 - Exact Weight Subgraphs and the k-Sum Conjecture.pdf}
}

@incollection{abu-sbeihFixedPointTheory2014,
  title = {Fixed {{Point Theory}} in {{Ordered Sets}} from the {{Metric Point}} of {{View}}},
  booktitle = {Topics in {{Fixed Point Theory}}},
  author = {{Abu-Sbeih}, M. Z. and Khamsi, M. A.},
  year = {2014},
  pages = {223--236},
  publisher = {Springer International Publishing},
  address = {Cham},
  doi = {10.1007/978-3-319-01586-6_6},
  urldate = {2023-09-14},
  isbn = {978-3-319-01585-9 978-3-319-01586-6},
  langid = {english},
  file = {/Users/sebastian/Zotero/storage/ZAG8EU68/Abu-Sbeih and Khamsi - 2014 - Fixed Point Theory in Ordered Sets from the Metric.pdf}
}

@article{agarwalAlgorithmsCenterTverberg2008,
  title = {Algorithms for Center and {{Tverberg}} Points},
  author = {Agarwal, Pankaj K. and Sharir, Micha and Welzl, Emo},
  year = {2008},
  month = dec,
  journal = {ACM Trans. Algorithms},
  volume = {5},
  number = {1},
  pages = {5:1--5:20},
  issn = {1549-6325},
  doi = {10.1145/1435375.1435380},
  urldate = {2024-11-06},
  abstract = {Given a set S of n points in R3, a point x in R3 is called center point of S if every closed halfspace whose bounding hyperplane passes through x contains at least {$\lceil$}n/4{$\rceil$} points from S. We present a near-quadratic algorithm for computing the center region, that is the set of all center points, of a set of n points in R3. This is nearly tight in the worst case since the center region can have {\textohm}(n2) complexity.We then consider sets S of 3n points in the plane which are the union of three disjoint sets consisting respectively of n red, n blue, and n green points. A point x in R2 is called a colored Tverberg point of S if there is a partition of S into n triples with one point of each color, so that x lies in all triangles spanned by these triples. We present a first polynomial-time algorithm for recognizing whether a given point is a colored Tverberg point of such a 3-colored set S.},
  file = {/Users/sebastian/Zotero/storage/XRCUMRAC/Agarwal et al. - 2008 - Algorithms for center and Tverberg points.pdf}
}

@misc{agrawalImpossibilityDerandomizingIsolation2020,
  title = {Impossibility of {{Derandomizing}} the {{Isolation Lemma}} for All {{Families}}},
  author = {Agrawal, Manindra and Gurjar, Rohit and Thierauf, Thomas},
  year = {2020},
  month = jul,
  number = {TR20-098},
  eprint = {TR20-098},
  publisher = {Electronic Colloquium on Computational Complexity},
  issn = {1433-8092},
  urldate = {2024-04-05},
  abstract = {The Isolation Lemma states that when random weights are assigned to the elements of a finite set E, then in any given family of subsets of E, exactly one set has the minimum weight, with high probability. In this note, we present two proofs for the fact that it is impossible to efficiently derandomize the Isolation Lemma for arbitrary families. The first proof is from Chari, Rohatgi and Srinivasan and uses the potential method. An alternate proof is due to the first author of this note. It uses the polynomial method. However, it is not written anywhere. The main purpose of this note is to present that proof. Additionally we show that the above lower bounds are almost tight with respect to various parameters.},
  archiveprefix = {Electronic Colloquium on Computational Complexity},
  langid = {english},
  keywords = {deradomization,Isolation Lemma,polynomial method},
  file = {/Users/sebastian/Zotero/storage/FL6MRCUU/Agrawal et al. - 2020 - Impossibility of Derandomizing the Isolation Lemma.pdf}
}

@article{agrawalPRIMES2004,
  title = {{{PRIMES}} Is in {{P}}},
  author = {Agrawal, Manindra and Kayal, Neeraj and Saxena, Nitin},
  year = {2004},
  journal = {Annals of Mathematics. Second Series},
  volume = {160},
  number = {2},
  pages = {781--793},
  issn = {0003-486X,1939-8980},
  doi = {10.4007/annals.2004.160.781},
  mrnumber = {2123939},
  file = {/Users/sebastian/Zotero/storage/L9DG47QE/Agrawal et al. - 2004 - PRIMES is in P.pdf;/Users/sebastian/Zotero/storage/NLBJFW3U/article.html}
}

@article{aichholzerSuperlinearLowerBound2020,
  title = {A Superlinear Lower Bound on the Number of 5-Holes},
  author = {Aichholzer, Oswin and Balko, Martin and Hackl, Thomas and Kyn{\v c}l, Jan and Parada, Irene and Scheucher, Manfred and Valtr, Pavel and Vogtenhuber, Birgit},
  year = {2020},
  month = jul,
  journal = {Journal of Combinatorial Theory, Series A},
  volume = {173},
  pages = {105236},
  issn = {0097-3165},
  doi = {10.1016/j.jcta.2020.105236},
  urldate = {2023-08-10},
  abstract = {Let P be a finite set of points in the plane in general position, that is, no three points of P are on a common line. We say that a set H of five points from P is a 5-hole in P if H is the vertex set of a convex 5-gon containing no other points of P. For a positive integer n, let h5(n) be the minimum number of 5-holes among all sets of n points in the plane in general position. Despite many efforts in the last 30 years, the best known asymptotic lower and upper bounds for h5(n) have been of order {\textohm}(n) and O(n2), respectively. We show that h5(n)={\textohm}(nlog4/5⁡n), obtaining the first superlinear lower bound on h5(n). The following structural result, which might be of independent interest, is a crucial step in the proof of this lower bound. If a finite set P of points in the plane in general position is partitioned by a line {$\ell$} into two subsets, each of size at least 5 and not in convex position, then {$\ell$} intersects the convex hull of some 5-hole in P. The proof of this result is computer-assisted.},
  langid = {english},
  keywords = {-Hole,Empty -gon,Empty pentagon,Erdos-Szekeres type problem,Planar point set},
  file = {/Users/sebastian/Zotero/storage/I5SC83BF/Aichholzer et al. - 2020 - A superlinear lower bound on the number of 5-holes.pdf}
}

@article{ailonAggregatingInconsistentInformation2008,
  title = {Aggregating Inconsistent Information: {{Ranking}} and Clustering},
  shorttitle = {Aggregating Inconsistent Information},
  author = {Ailon, Nir and Charikar, Moses and Newman, Alantha},
  year = {2008},
  month = nov,
  journal = {Journal of the ACM},
  volume = {55},
  number = {5},
  pages = {23:1--23:27},
  issn = {0004-5411},
  doi = {10.1145/1411509.1411513},
  urldate = {2023-08-10},
  abstract = {We address optimization problems in which we are given contradictory pieces of input information and the goal is to find a globally consistent solution that minimizes the extent of disagreement with the respective inputs. Specifically, the problems we address are rank aggregation, the feedback arc set problem on tournaments, and correlation and consensus clustering. We show that for all these problems (and various weighted versions of them), we can obtain improved approximation factors using essentially the same remarkably simple algorithm. Additionally, we almost settle a long-standing conjecture of Bang-Jensen and Thomassen and show that unless NP{$\subseteq$}BPP, there is no polynomial time algorithm for the problem of minimum feedback arc set in tournaments.},
  keywords = {consensus clustering,correlation clustering,minimum feedback arc-set,Rank aggregation,tournaments},
  file = {/Users/sebastian/Zotero/storage/KJLPS84P/Ailon et al. - 2008 - Aggregating inconsistent information Ranking and .pdf}
}

@article{ailonImprovedApproximationAlgorithms2012,
  title = {Improved {{Approximation Algorithms}} for {{Bipartite Correlation Clustering}}},
  author = {Ailon, Nir and {Avigdor-Elgrabli}, Noa and Liberty, Edo and {van Zuylen}, Anke},
  year = {2012},
  month = jan,
  journal = {SIAM Journal on Computing},
  volume = {41},
  number = {5},
  pages = {1110--1121},
  publisher = {{Society for Industrial and Applied Mathematics}},
  issn = {0097-5397},
  doi = {10.1137/110848712},
  urldate = {2023-08-10},
  abstract = {Correlation clustering aims at the detection of data points that appear as hyperplanes in the data space and, thus, exhibit common correlations between different subsets of features. Recently proposed methods for correlation clustering usually suffer from several severe drawbacks including poor robustness against noise or parameter settings, incomplete results (i.e. missed clusters), poor usability due to complex input parameters, and poor scalability. In this paper, we propose the novel correlation clustering algorithm COPAC (COrrelation PArtition Clustering) that aims at improved robustness, completeness, usability, and efficiency. Our experimental evaluation empirically shows that COPAC is superior over existing state-of-the-art correlation clustering methods in terms of runtime, accuracy, and completeness of the results.},
  file = {/Users/sebastian/Zotero/storage/UCS5A3ZY/Ailon et al. - 2012 - Improved Approximation Algorithms for Bipartite Co.pdf}
}

@inproceedings{akmalFasterDetoursUndirected2023,
  title = {Faster {{Detours}} in {{Undirected Graphs}}},
  booktitle = {31st {{Annual European Symposium}} on {{Algorithms}} ({{ESA}} 2023)},
  author = {Akmal, Shyan and Vassilevska Williams, Virginia and Williams, Ryan and Xu, Zixuan},
  year = {2023},
  pages = {7:1-7:17},
  publisher = {Schloss Dagstuhl -- Leibniz-Zentrum f{\"u}r Informatik},
  doi = {10.4230/LIPIcs.ESA.2023.7},
  urldate = {2024-11-18},
  abstract = {The k-Detour problem is a basic path-finding problem: given a graph G on n vertices, with specified nodes s and t, and a positive integer k, the goal is to determine if G has an st-path of length exactly dist(s,t) + k, where dist(s,t) is the length of a shortest path from s to t. The k-Detour problem is NP-hard when k is part of the input, so researchers have sought efficient parameterized algorithms for this task, running in f(k)poly(n) time, for f({$\cdot$}) as slow-growing as possible. We present faster algorithms for k-Detour in undirected graphs, running in 1.853{\textasciicircum}k poly(n) randomized and 4.082{\textasciicircum}kpoly(n) deterministic time. The previous fastest algorithms for this problem took 2.746{\textasciicircum}k poly(n) randomized and 6.523{\textasciicircum}k poly(n) deterministic time [Bez{\'a}kov{\'a}-Curticapean-Dell-Fomin, ICALP 2017]. Our algorithms use the fact that detecting a path of a given length in an undirected graph is easier if we are promised that the path belongs to what we call a "bipartitioned" subgraph, where the nodes are split into two parts and the path must satisfy constraints on those parts. Previously, this idea was used to obtain the fastest known algorithm for finding paths of length k in undirected graphs [Bj{\"o}rklund-Husfeldt-Kaski-Koivisto, JCSS 2017], intuitively by looking for paths of length k in randomly bipartitioned subgraphs. Our algorithms for k-Detour stem from a new application of this idea, which does not involve choosing the bipartitioned subgraphs randomly. Our work has direct implications for the k-Longest Detour problem, another related path-finding problem. In this problem, we are given the same input as in k-Detour, but are now tasked with determining if G has an st-path of length at least dist(s,t)+k. Our results for k-Detour imply that we can solve k-Longest Detour in 3.432{\textasciicircum}k poly(n) randomized and 16.661{\textasciicircum}k poly(n) deterministic time. The previous fastest algorithms for this problem took 7.539{\textasciicircum}k poly(n) randomized and 42.549{\textasciicircum}k poly(n) deterministic time [Fomin et al., STACS 2022].},
  copyright = {https://creativecommons.org/licenses/by/4.0/legalcode},
  langid = {english},
  file = {/Users/sebastian/Zotero/storage/9IFJNX5E/Akmal et al. - 2023 - Faster Detours in Undirected Graphs.pdf}
}

@article{alonsoBirkhoffOrthogonalityIsosceles2012,
  title = {On {{Birkhoff}} Orthogonality and Isosceles Orthogonality in Normed Linear Spaces},
  author = {Alonso, Javier and Martini, Horst and Wu, Senlin},
  year = {2012},
  month = feb,
  journal = {Aequationes mathematicae},
  volume = {83},
  number = {1},
  pages = {153--189},
  issn = {1420-8903},
  doi = {10.1007/s00010-011-0092-z},
  urldate = {2024-11-27},
  abstract = {We survey mainly recent results on the two most important orthogonality types in normed linear spaces, namely on Birkhoff orthogonality and on isosceles (or James) orthogonality. We lay special emphasis on their fundamental properties, on their differences and connections, and on geometric results and problems inspired by the respective theoretical framework. At the beginning we also present other interesting types of orthogonality. This survey can also be taken as an update of existing related representations.},
  langid = {english},
  keywords = {46B20,46C15,52A21,Birkhoff orthogonality,bisectors,inner product space,isosceles orthogonality,James orthogonality,Minkowski space,Real normed linear space,Zindler curves},
  file = {/Users/sebastian/Zotero/storage/BGQM2SFS/Alonso et al. - 2012 - On Birkhoff orthogonality and isosceles orthogonality in normed linear spaces.pdf}
}

@inproceedings{amanatidisImprovedEnvyFreeCake2018,
  title = {An {{Improved Envy-Free Cake Cutting Protocol}} for {{Four Agents}}},
  booktitle = {Algorithmic {{Game Theory}}},
  author = {Amanatidis, Georgios and Christodoulou, George and Fearnley, John and Markakis, Evangelos and Psomas, Christos-Alexandros and Vakaliou, Eftychia},
  year = {2018},
  pages = {87--99},
  publisher = {Springer International Publishing},
  address = {Cham},
  doi = {10.1007/978-3-319-99660-8_9},
  abstract = {We consider the classic cake-cutting problem of producing envy-free allocations, restricted to the case of four agents. The problem asks for a partition of the cake to four agents, so that every agent finds her piece at least as valuable as every other agent's piece. The problem has had an interesting history so far. Although the case of three agents is solvable with less than 15 queries, for four agents no bounded procedure was known until the recent breakthroughs of Aziz and Mackenzie~[2, 3]. The main drawback of these new algorithms, however, is that they are quite complicated and with a very high query complexity. With four agents, the number of queries required is close to 600. In this work we provide an improved algorithm for four agents, which reduces the current complexity by a factor of 3.4. Our algorithm builds on the approach of [3] by incorporating new insights and simplifying several steps. Overall, this yields an easier to grasp procedure with lower complexity.},
  isbn = {978-3-319-99660-8},
  langid = {english},
  file = {/Users/sebastian/Zotero/storage/776B5PFH/Amanatidis et al. - 2018 - An Improved Envy-Free Cake Cutting Protocol for Fo.pdf}
}

@book{aroraComputationalComplexityModern2009,
  title = {Computational Complexity: A Modern Approach},
  shorttitle = {Computational Complexity},
  author = {Arora, Sanjeev and Barak, Boaz},
  year = {2009},
  publisher = {Cambridge University Press},
  address = {Cambridge ; New York},
  isbn = {978-0-521-42426-4},
  lccn = {QA267.7 .A76 2009},
  keywords = {Computational complexity},
  annotation = {OCLC: ocn286431654},
  file = {/Users/sebastian/Zotero/storage/5X3DRA9A/Arora and Barak - 2009 - Computational complexity a modern approach.pdf}
}

@article{aroraMultiplicativeWeightsUpdate2012,
  title = {The {{Multiplicative Weights Update Method}}: A {{Meta-Algorithm}} and {{Applications}}},
  shorttitle = {The {{Multiplicative Weights Update Method}}},
  author = {Arora, Sanjeev and Hazan, Elad and Kale, Satyen},
  year = {2012},
  month = may,
  journal = {Theory of Computing},
  volume = {8},
  number = {6},
  pages = {121--164},
  publisher = {Theory of Computing},
  doi = {10.4086/toc.2012.v008a006},
  urldate = {2025-01-15},
  keywords = {algorithms,game theory,machine learning},
  file = {/Users/sebastian/Zotero/storage/3IKEQ33E/Arora et al. - 2012 - The Multiplicative Weights Update Method a Meta-Algorithm and Applications.pdf;/Users/sebastian/Zotero/storage/R7W8L8DA/v008a006.html}
}

@article{aroraSubexponentialAlgorithmsUnique2015,
  title = {Subexponential {{Algorithms}} for {{Unique Games}} and {{Related Problems}}},
  author = {Arora, Sanjeev and Barak, Boaz and Steurer, David},
  year = {2015},
  month = nov,
  journal = {Journal of the ACM},
  volume = {62},
  number = {5},
  pages = {1--25},
  issn = {0004-5411, 1557-735X},
  doi = {10.1145/2775105},
  urldate = {2023-09-09},
  abstract = {Subexponential time approximation algorithms are presented for the U               nique               G               ames               and S               mall               -S               et               E               xpansion               problems. Specifically, for some absolute constant               c               , the following two algorithms are presented.                                         (1) An exp(               kn               {$\epsilon$}               )-time algorithm that, given as input a               k               -alphabet unique game on               n               variables that has an assignment satisfying 1-{$\epsilon$}               c               fraction of its constraints, outputs an assignment satisfying 1-{$\epsilon$} fraction of the constraints.                                         (2) An exp(               n               {$\epsilon$}               /{$\delta$})-time algorithm that, given as input an               n               -vertex regular graph that has a set               S               of {$\delta$}               n               vertices with edge expansion at most                                {$\epsilon$}                 c                              , outputs a set               S'               of at most {$\delta$}               n               vertices with edge expansion at most {$\epsilon$}.                                         subexponential algorithm is also presented with improved approximation to M               ax               C               ut               , S               parsest               C               ut               , and V               ertex               C               over               on some interesting subclasses of instances. These instances are graphs with low               threshold rank               , an interesting new graph parameter highlighted by this work.                                         Khot's Unique Games Conjecture (UGC) states that it is               NP               -hard to achieve approximation guarantees such as ours for U               nique               G               ames               . While the results here stop short of refuting the UGC, they do suggest that U               nique               G               ames               are significantly easier than               NP               -hard problems such as M               ax               3-S               at               , M               ax               3-               Lin               , L               abel               C               over               , and more, which are believed not to have a subexponential algorithm achieving a nontrivial approximation ratio.                                         Of special interest in these algorithms is a new notion of graph decomposition that may have other applications. Namely, it is shown for every {$\epsilon$} {$>$}0 and every regular               n               -vertex graph               G               , by changing at most {$\delta$} fraction of               G               's edges, one can break               G               into disjoint parts so that the stochastic adjacency matrix of the induced graph on each part has at most               n               {$\epsilon$}               eigenvalues larger than 1-{$\eta$}, where {$\eta$} depends polynomially on {$\epsilon$}. The subexponential algorithm combines this decomposition with previous algorithms for U               nique               G               ames               on graphs with few large eigenvalues [Kolla and Tulsiani 2007; Kolla 2010].},
  langid = {english}
}

@misc{asadiDeterministicSubexponentialAlgorithm2024,
  title = {Deterministic {{Sub-exponential Algorithm}} for {{Discounted-sum Games}} with {{Unary Weights}}},
  author = {Asadi, Ali and Chatterjee, Krishnendu and Saona, Raimundo and Svoboda, Jakub},
  year = {2024},
  month = may,
  number = {arXiv:2405.02479},
  eprint = {2405.02479},
  primaryclass = {cs},
  publisher = {arXiv},
  doi = {10.48550/arXiv.2405.02479},
  urldate = {2024-05-22},
  abstract = {Turn-based discounted-sum games are two-player zero-sum games played on finite directed graphs. The vertices of the graph are partitioned between player 1 and player 2. Plays are infinite walks on the graph where the next vertex is decided by a player that owns the current vertex. Each edge is assigned an integer weight and the payoff of a play is the discounted-sum of the weights of the play. The goal of player 1 is to maximize the discounted-sum payoff against the adversarial player 2. These games lie in NP and coNP and are among the rare combinatorial problems that belong to this complexity class and the existence of a polynomial-time algorithm is a major open question. Since breaking the general exponential barrier has been a challenging problem, faster parameterized algorithms have been considered. If the discount factor is expressed in unary, then discounted-sum games can be solved in polynomial time. However, if the discount factor is arbitrary (or expressed in binary), but the weights are in unary, none of the existing approaches yield a sub-exponential bound. Our main result is a new analysis technique for a classical algorithm (namely, the strategy iteration algorithm) that present a new runtime bound which is \$n{\textasciicircum}\{O ( W{\textasciicircum}\{1/4\} {\textbackslash}sqrt\{n\} )\}\$, for game graphs with \$n\$ vertices and maximum absolute weight of at most \$W\$. In particular, our result yields a deterministic sub-exponential bound for games with weights that are constant or represented in unary.},
  archiveprefix = {arXiv},
  keywords = {Computer Science - Computer Science and Game Theory},
  file = {/Users/sebastian/Zotero/storage/7MXSDMGY/Asadi et al. - 2024 - Deterministic Sub-exponential Algorithm for Discou.pdf;/Users/sebastian/Zotero/storage/9GCGDCEV/2405.html}
}

@inproceedings{asterisBipartiteCorrelationClustering2016,
  title = {Bipartite {{Correlation Clustering}}: {{Maximizing Agreements}}},
  shorttitle = {Bipartite {{Correlation Clustering}}},
  booktitle = {Proceedings of the 19th {{International Conference}} on {{Artificial Intelligence}} and {{Statistics}}},
  author = {Asteris, Megasthenis and Kyrillidis, Anastasios and Papailiopoulos, Dimitris and Dimakis, Alexandros},
  year = {2016},
  month = may,
  pages = {121--129},
  publisher = {PMLR},
  issn = {1938-7228},
  urldate = {2023-08-10},
  abstract = {In Bipartite Correlation Clustering (BCC)  we are given a complete bipartite graph G with '+' and '-' edges, and we seek a vertex clustering that maximizes the number of agreements: the number of all '+' edges within clusters plus all '-' edges cut across clusters. BCC is known to be NP-hard [5].  We present a novel approximation algorithm for k-BCC, a variant of BCC with an upper bound k on the number of clusters. Our algorithm outputs a k-clustering that provably achieves a number of agreements within a multiplicative (1-{$\delta$})-factor from the optimal, for any desired accuracy {$\delta$}. It relies on solving a combinatorially constrained bilinear maximization on the bi-adjacency matrix of G. It runs in time exponential in k and 1/{$\delta$}, but linear in the size of the input.  Further, we show that, in the (unconstrained) BCC setting, an (1-{$\delta$})-approximation can be achieved by O(1/{$\delta$}) clusters regardless of the size of the graph. In turn, our k-BCC algorithm implies an Efficient PTAS for the BCC objective of maximizing agreements.},
  langid = {english},
  file = {/Users/sebastian/Zotero/storage/YK4RZ38N/Asteris et al. - 2016 - Bipartite Correlation Clustering Maximizing Agree.pdf}
}

@article{aszalosCorrelationClusteringLet2019,
  title = {Correlation Clustering: {{Let}} All the Flowers Bloom!},
  shorttitle = {Correlation Clustering},
  author = {Aszal{\'o}s, L{\'a}szl{\'o} and Bak{\'o}, M{\'a}ria},
  year = {2019},
  journal = {Annals of Computer Science and Information Systems},
  volume = {Vol. 20},
  doi = {10.15439/2019F93},
  urldate = {2023-08-10},
  langid = {english},
  file = {/Users/sebastian/Zotero/storage/SRIP84H9/Aszalós and Bakó - 2019 - Correlation clustering Let all the flowers bloom!.pdf}
}

@incollection{augerFindingOptimalStrategies2014,
  title = {Finding {{Optimal Strategies}} of {{Almost Acyclic Simple Stochastic Games}}},
  booktitle = {Theory and {{Applications}} of {{Models}} of {{Computation}}},
  author = {Auger, David and Coucheney, Pierre and Strozecki, Yann},
  year = {2014},
  volume = {8402},
  pages = {67--85},
  publisher = {Springer International Publishing},
  address = {Cham},
  doi = {10.1007/978-3-319-06089-7_6},
  urldate = {2023-09-09},
  isbn = {978-3-319-06088-0 978-3-319-06089-7},
  file = {/Users/sebastian/Zotero/storage/XZ4V6W6B/978-3-319-06089-7_6.pdf}
}

@inproceedings{augerGeneralizedARRIVALProblem2023,
  title = {Generalized {{ARRIVAL Problem}} for~{{Rotor Walks}} in~{{Path Multigraphs}}},
  booktitle = {Reachability {{Problems}}},
  author = {Auger, David and Coucheney, Pierre and Duhaz{\'e}, Loric and Etse, Kossi Roland},
  year = {2023},
  pages = {183--198},
  publisher = {Springer Nature Switzerland},
  address = {Cham},
  doi = {10.1007/978-3-031-45286-4_14},
  abstract = {Rotor walks are cellular automata that determine deterministic traversals of particles in a directed multigraph using simple local rules, yet they can generate complex behaviors. Furthermore, these trajectories exhibit statistical properties similar to random walks.},
  isbn = {978-3-031-45286-4},
  langid = {english},
  keywords = {cellular automata,discrete harmonic function,Rotor walks},
  file = {/Users/sebastian/Zotero/storage/KYI7PG8E/Auger et al. - 2023 - Generalized ARRIVAL Problem for Rotor Walks in Pat.pdf}
}

@article{augerPolynomialTimeAlgorithm2022,
  title = {Polynomial {{Time Algorithm}} for {{ARRIVAL}} on {{Tree-Like Multigraphs}}},
  author = {Auger, David and Coucheney, Pierre and Duhaz{\'e}, Loric},
  year = {2022},
  journal = {LIPIcs, Volume 241, MFCS 2022},
  volume = {241},
  pages = {12:1-12:14},
  publisher = {Schloss Dagstuhl -- Leibniz-Zentrum f{\"u}r Informatik},
  issn = {1868-8969},
  doi = {10.4230/LIPICS.MFCS.2022.12},
  urldate = {2025-02-05},
  abstract = {A rotor walk in a directed graph can be thought of as a deterministic version of a Markov Chain, where a pebble moves from vertex to vertex following a simple rule until a terminal vertex, or sink, has been reached. The ARRIVAL problem, as defined by Dohrau et al. [8], consists in determining which sink will be reached. While the walk itself can take an exponential number of steps, this problem belongs to the complexity class NP {$\cap$} co-NP without being known to be in P. In this work, we define a class of directed graphs, namely tree-like multigraphs, which are multigraphs having the global shape of an undirected tree. We prove that in this class, ARRIVAL can be solved in almost linear time, while the number of steps of a rotor walk can still be exponential. Then, we give an application of this result to solve some deterministic analogs of stochastic models (e.g., Markovian decision processes, Stochastic Games).},
  collaborator = {Szeider, Stefan and Ganian, Robert and Silva, Alexandra},
  copyright = {Creative Commons Attribution 4.0 International license, info:eu-repo/semantics/openAccess},
  langid = {english},
  keywords = {Game Theory,Mathematics of computing,Reachability Problem,Rotor Walk,Rotor-routing,Tree-like Multigraph},
  file = {/Users/sebastian/Zotero/storage/FFAVGRS2/Auger et al. - 2022 - Polynomial Time Algorithm for ARRIVAL on Tree-Like Multigraphs.pdf}
}

@article{augerSolvingSimpleStochastic2019,
  title = {Solving {{Simple Stochastic Games}} with {{Few Random Nodes Faster Using Bland}}'s {{Rule}}},
  author = {Auger, David and Coucheney, Pierre and Strozecki, Yann},
  year = {2019},
  pages = {16 pages},
  doi = {10.4230/LIPICS.STACS.2019.9},
  urldate = {2023-09-09},
  collaborator = {Wagner, Michael},
  copyright = {Creative Commons Attribution 3.0 Unported license (CC-BY 3.0)},
  langid = {english},
  file = {/Users/sebastian/Zotero/storage/26VJQ6RE/LIPIcs-STACS-2019-9.pdf}
}

@article{avsecBaseresolutionModelsTranscriptionfactor2021,
  title = {Base-Resolution Models of Transcription-Factor Binding Reveal Soft Motif Syntax},
  author = {Avsec, {\v Z}iga and Weilert, Melanie and Shrikumar, Avanti and Krueger, Sabrina and Alexandari, Amr and Dalal, Khyati and Fropf, Robin and McAnany, Charles and Gagneur, Julien and Kundaje, Anshul and Zeitlinger, Julia},
  year = {2021},
  month = mar,
  journal = {Nature Genetics},
  volume = {53},
  number = {3},
  pages = {354--366},
  publisher = {Nature Publishing Group},
  issn = {1546-1718},
  doi = {10.1038/s41588-021-00782-6},
  urldate = {2023-08-10},
  abstract = {The arrangement (syntax) of transcription factor (TF) binding motifs is an important part of the cis-regulatory code, yet remains elusive. We introduce a deep learning model, BPNet, that uses DNA sequence to predict base-resolution chromatin immunoprecipitation (ChIP)--nexus binding profiles of pluripotency TFs. We develop interpretation tools to learn predictive motif representations and identify soft syntax rules for cooperative TF binding interactions. Strikingly, Nanog preferentially binds with helical periodicity, and TFs often cooperate in a directional manner, which we validate using clustered regularly interspaced short palindromic repeat (CRISPR)-induced point mutations. Our model represents a powerful general approach to uncover the motifs and syntax of cis-regulatory sequences in genomics data.},
  copyright = {2021 The Author(s), under exclusive licence to Springer Nature America, Inc.},
  langid = {english},
  keywords = {Chromatin immunoprecipitation,Computational biology and bioinformatics,Genomics},
  file = {/Users/sebastian/Zotero/storage/2EC2WMIQ/Avsec et al. - 2021 - Base-resolution models of transcription-factor bin.pdf}
}

@article{banach1922operations,
  title = {Sur Les Op{\'e}rations Dans Les Ensembles Abstraits et Leur Application Aux {\'E}quations Int{\'e}grales},
  author = {Banach, Stefan},
  year = {1922},
  journal = {Fundamenta mathematicae},
  volume = {3},
  number = {1},
  pages = {133--181},
  publisher = {Polska Akademia Nauk. Instytut Matematyczny PAN},
  doi = {10.4064/fm-3-1-133-181}
}

@article{baranyPlanarPointSets2005,
  title = {Planar Point Sets with a Small Number of Empty Convex Polygons},
  author = {B{\'a}r{\'a}ny, Imre and Valtr, P{\'a}vel},
  year = {2005},
  month = jul,
  journal = {Studia Scientiarum Mathematicarum Hungarica},
  volume = {41},
  number = {2},
  pages = {243--269},
  publisher = {Akad{\'e}miai Kiad{\'o}},
  issn = {0081-6906, 1588-2896},
  doi = {10.1556/sscmath.41.2004.2.4},
  urldate = {2023-08-10},
  abstract = {A subset A of a finite set P of points in the plane is called an empty polygon, if each point of A is a vertex of the convex hull of A and the convex hull of A contains no other points of P. We construct a set of n points in general position in the plane with only {\texttildelow}1.62n2 empty triangles, {\texttildelow}1.94n2 empty quadrilaterals, {\texttildelow}1.02n2 empty pentagons, and {\texttildelow}0.2n2 empty hexagons.},
  chapter = {Studia Scientiarum Mathematicarum Hungarica},
  langid = {english}
}

@article{basuCenterpointsLinkOptimization2017,
  title = {Centerpoints: {{A Link}} between {{Optimization}} and {{Convex Geometry}}},
  shorttitle = {Centerpoints},
  author = {Basu, Amitabh and Oertel, Timm},
  year = {2017},
  month = jan,
  journal = {SIAM Journal on Optimization},
  volume = {27},
  number = {2},
  pages = {866--889},
  publisher = {{Society for Industrial and Applied Mathematics}},
  issn = {1052-6234},
  doi = {10.1137/16M1092908},
  urldate = {2024-11-06},
  abstract = {We show that maximal S-free convex sets are polyhedra when S is the set of integral points in some rational polyhedron of Rn. This result extends a theorem of Lov{\'a}sz characterizing maximal lattice-free convex sets. Our theorem has implications in integer programming. In particular, we show that maximal S-free convex sets are in one-to-one correspondence with minimal inequalities.},
  file = {/Users/sebastian/Zotero/storage/MHMYEVRX/Basu and Oertel - 2017 - Centerpoints A Link between Optimization and Convex Geometry.pdf}
}

@misc{batziouMonotoneContractions2024,
  title = {Monotone {{Contractions}}},
  author = {Batziou, Eleni and Fearnley, John and Gordon, Spencer and Mehta, Ruta and Savani, Rahul},
  year = {2024},
  month = nov,
  number = {arXiv:2411.10107},
  eprint = {2411.10107},
  publisher = {arXiv},
  doi = {10.48550/arXiv.2411.10107},
  urldate = {2024-11-18},
  abstract = {We study functions \$f : [0, 1]{\textasciicircum}d {\textbackslash}rightarrow [0, 1]{\textasciicircum}d\$ that are both monotone and contracting, and we consider the problem of finding an \${\textbackslash}varepsilon\$-approximate fixed point of \$f\$. We show that the problem lies in the complexity class UEOPL. We give an algorithm that finds an \${\textbackslash}varepsilon\$-approximate fixed point of a three-dimensional monotone contraction using \$O({\textbackslash}log (1/{\textbackslash}varepsilon))\$ queries to \$f\$. We also give a decomposition theorem that allows us to use this result to obtain an algorithm that finds an \${\textbackslash}varepsilon\$-approximate fixed point of a \$d\$-dimensional monotone contraction using \$O((c {\textbackslash}cdot {\textbackslash}log (1/{\textbackslash}varepsilon)){\textasciicircum}\{{\textbackslash}lceil d / 3 {\textbackslash}rceil\})\$ queries to \$f\$ for some constant \$c\$. Moreover, each step of both of our algorithms takes time that is polynomial in the representation of \$f\$. These results are strictly better than the best-known results for functions that are only monotone, or only contracting. All of our results also apply to Shapley stochastic games, which are known to be reducible to the monotone contraction problem. Thus we put Shapley games in UEOPL, and we give a faster algorithm for approximating the value of a Shapley game.},
  archiveprefix = {arXiv},
  keywords = {Computer Science - Computational Complexity},
  file = {/Users/sebastian/Zotero/storage/MND77PAV/Batziou et al. - 2024 - Monotone Contractions.pdf;/Users/sebastian/Zotero/storage/Y6GQJ67P/2411.html}
}

@article{beameRelativeComplexityNP1998,
  title = {The {{Relative Complexity}} of {{NP Search Problems}}},
  author = {Beame, Paul and Cook, Stephen and Edmonds, Jeff and Impagliazzo, Russell and Pitassi, Toniann},
  year = {1998},
  month = aug,
  journal = {J. Comput. Syst. Sci.},
  volume = {57},
  number = {1},
  pages = {3--19},
  issn = {0022-0000},
  doi = {10.1006/jcss.1998.1575},
  urldate = {2025-01-16},
  abstract = {Papadimitriou introduced several classes of NP search problems based on combinatorial principles which guarantee the existence of solutions to the problems. Many interesting search problems not known to be solvable in polynomial time are contained in these classes, and a number of them are complete problems. We consider the question of the relative complexity of these search problem classes. We prove several separations which show that in a generic relativized world the search classes are distinct and there is a standard search problem in each of them that is not computationally equivalent to any decision problem. (Naturally, absolute separations would imply thatP NP.) Our separation proofs have interesting combinatorial content and go to the heart of the combinatorial principles on which the classes are based. We derive one result via new lower bounds on the degrees of poly- nomials asserted to exist by Hilbert's nullstellensatz over finite fields.},
  file = {/Users/sebastian/Zotero/storage/WB23GLXZ/Beame et al. - 1998 - The Relative Complexity of NP Search Problems.pdf}
}

@inproceedings{beierFusionMovesCorrelation2015,
  title = {Fusion {{Moves}} for {{Correlation Clustering}}},
  booktitle = {Proceedings of the {{IEEE Conference}} on {{Computer Vision}} and {{Pattern Recognition}}},
  author = {Beier, Thorsten and Hamprecht, Fred A. and Kappes, Jorg H.},
  year = {2015},
  pages = {3507--3516},
  urldate = {2023-08-10},
  file = {/Users/sebastian/Zotero/storage/GIJFTUAD/Beier et al. - 2015 - Fusion Moves for Correlation Clustering.pdf}
}

@article{ben-dorClusteringGeneExpression1999,
  title = {Clustering Gene Expression Patterns},
  author = {{Ben-Dor}, A and Shamir, R and Yakhini, Z},
  year = {1999},
  month = sep,
  journal = {Journal of computational biology},
  volume = {6},
  number = {3-4},
  pages = {281--297},
  issn = {1557-8666},
  doi = {10.1089/106652799318274},
  urldate = {2023-08-10},
  abstract = {Recent advances in biotechnology allow researchers to measure expression levels for thousands of genes simultaneously, across different conditions and over time. Analysis of data produced by such experiments offers potential insight into gene function and regulatory mechanisms. A key step in the analysis of gene expression data is the detection of groups of genes that manifest similar expression patterns. The corresponding algorithmic problem is to cluster multicondition gene expression patterns. In this paper we describe a novel clustering algorithm that was developed for analysis of gene expression data. We define an appropriate stochastic error model on the input, and prove that under the conditions of the model, the algorithm recovers the cluster structure with high probability. The running time of the algorithm on an n-gene dataset is O[n2[log(n)]c]. We also present a practical heuristic based on the same algorithmic ideas. The heuristic was implemented and its performance is demonstrated on simulated data and on real gene expression data, with very promising results.},
  langid = {english},
  pmid = {10582567}
}

@article{ben-eliezerDoesPriorKnowledge,
  title = {Does {{Prior Knowledge Help Detect Collisions}}?},
  author = {{Ben-Eliezer}, Omri and Grossman, Tomer and Naor, Moni},
  abstract = {Suppose you are given a function f : [n] {$\rightarrow$} [n] via (black-box) query access to the function. You are looking to find something local, like a collision (a pair x ̸= y s.t. f (x) = f (y)). The question is whether knowing the `shape' of the function helps you or not (by shape we mean that some permutation of the function is known). Our goal in this work is to characterize all local properties for which knowing the shape may help, compared to an algorithm that does not know the shape.},
  langid = {english},
  file = {/Users/sebastian/Zotero/storage/7B6YI7A4/Ben-Eliezer et al. - Does Prior Knowledge Help Detect Collisions.pdf}
}

@misc{bentertPackingShortCycles2024,
  title = {Packing {{Short Cycles}}},
  author = {Bentert, Matthias and Fomin, Fedor V. and Golovach, Petr A. and Korhonen, Tuukka and Lochet, William and Panolan, Fahad and Ramanujan, M. S. and Saurabh, Saket and Simonov, Kirill},
  year = {2024},
  month = oct,
  number = {arXiv:2410.18878},
  eprint = {2410.18878},
  publisher = {arXiv},
  doi = {10.48550/arXiv.2410.18878},
  urldate = {2024-10-25},
  abstract = {Cycle packing is a fundamental problem in optimization, graph theory, and algorithms. Motivated by recent advancements in finding vertex-disjoint paths between a specified set of vertices that either minimize the total length of the paths [Bj{\textbackslash}"orklund, Husfeldt, ICALP 2014; Mari, Mukherjee, Pilipczuk, and Sankowski, SODA 2024] or request the paths to be shortest [Lochet, SODA 2021], we consider the following cycle packing problems: Min-Sum Cycle Packing and Shortest Cycle Packing. In Min-Sum Cycle Packing, we try to find, in a weighted undirected graph, \$k\$ vertex-disjoint cycles of minimum total weight. Our first main result is an algorithm that, for any fixed \$k\$, solves the problem in polynomial time. We complement this result by establishing the W[1]-hardness of Min-Sum Cycle Packing parameterized by \$k\$. The same results hold for the version of the problem where the task is to find \$k\$ edge-disjoint cycles. Our second main result concerns Shortest Cycle Packing, which is a special case of Min-Sum Cycle Packing that asks to find a packing of \$k\$ shortest cycles in a graph. We prove this problem to be fixed-parameter tractable (FPT) when parameterized by \$k\$ on weighted planar graphs. We also obtain a polynomial kernel for the edge-disjoint variant of the problem on planar graphs. Deciding whether Min-Sum Cycle Packing is FPT on planar graphs and whether Shortest Cycle Packing is FPT on general graphs remain challenging open questions.},
  archiveprefix = {arXiv},
  keywords = {Computer Science - Data Structures and Algorithms},
  file = {/Users/sebastian/Zotero/storage/ZK2BN5SD/Bentert et al. - 2024 - Packing Short Cycles.pdf;/Users/sebastian/Zotero/storage/DB7V5XHQ/2410.html}
}

@article{bertsimasSolvingConvexPrograms2004,
  title = {Solving Convex Programs by Random Walks},
  author = {Bertsimas, Dimitris and Vempala, Santosh},
  year = {2004},
  month = jul,
  journal = {J. ACM},
  volume = {51},
  number = {4},
  pages = {540--556},
  issn = {0004-5411},
  doi = {10.1145/1008731.1008733},
  urldate = {2025-01-15},
  abstract = {Minimizing a convex function over a convex set in n-dimensional space is a basic, general problem with many interesting special cases. Here, we present a simple new algorithm for convex optimization based on sampling by a random walk. It extends naturally to minimizing quasi-convex functions and to other generalizations.},
  file = {/Users/sebastian/Zotero/storage/LSHGN5N8/Bertsimas and Vempala - 2004 - Solving convex programs by random walks.pdf}
}

@book{bishopPatternRecognitionMachine2006,
  title = {Pattern Recognition and Machine Learning},
  author = {Bishop, Christopher M.},
  year = {2006},
  series = {Information Science and Statistics},
  publisher = {Springer},
  address = {New York},
  isbn = {978-0-387-31073-2},
  lccn = {Q327 .B52 2006},
  keywords = {Machine learning,Pattern perception},
  file = {/Users/sebastian/Zotero/storage/AIYWV7LA/Bishop - 2006 - Pattern recognition and machine learning.pdf}
}

@article{bjorklundCombinatorialStructureRandomized2005,
  title = {Combinatorial Structure and Randomized Subexponential Algorithms for Infinite Games},
  author = {Bj{\"o}rklund, Henrik and Vorobyov, Sergei},
  year = {2005},
  month = dec,
  journal = {Theoretical Computer Science},
  volume = {349},
  number = {3},
  pages = {347--360},
  issn = {0304-3975},
  doi = {10.1016/j.tcs.2005.07.041},
  urldate = {2024-09-05},
  abstract = {The complexity of solving infinite games, including parity, mean payoff, and simple stochastic, is an important open problem in verification, automata, and complexity theory. In this paper, we develop an abstract setting for studying and solving such games, based on function optimization over certain discrete structures. We introduce new classes of recursively local-global (RLG) and partial recursively local-global (PRLG) functions, and show that strategy evaluation functions for simple stochastic, mean payoff, and parity games belong to these classes. In this setting, we suggest randomized subexponential algorithms appropriate for RLG- and PRLG-function optimization. We show that the subexponential algorithms for combinatorial linear programming, due to Kalai and Matou{\v s}ek, Sharir, Welzl, can be adapted for optimizing the RLG- and PRLG-functions.},
  keywords = {Combinatorial linear programming,Completely unimodal functions,Mean payoff games,Parity games,Pseudo-Boolean optimization,Randomized algorithms,Simple stochastic games},
  file = {/Users/sebastian/Zotero/storage/EAMSJQVY/Björklund and Vorobyov - 2005 - Combinatorial structure and randomized subexponent.pdf;/Users/sebastian/Zotero/storage/B2QGQCRC/S0304397505005761.html}
}

@techreport{bjorklundRandomizedSubexponentialAlgorithms2004,
  title = {Randomized Subexponential Algorithms for Infinite Games},
  author = {Bj{\"o}rklund, Henrik and Sandberg, Sven and Vorobyov, Sergei},
  year = {2004},
  month = apr,
  number = {2004-011},
  institution = {Department of Information Technology, Uppsala University},
  abstract = {The complexity of solving infinite games, including parity, mean payoff, and simple stochastic games, is an important open problem in verification, automata theory, and complexity theory. In this paper we develop an abstract setting for studying and solving such games, as well as related problems, based on function optimization over certain discrete structures. We introduce new classes of completely local-global (CLG) and recursively local-global (RLG) functions, and show that strategy evaluation functions for parity and simple stochastic games belong to these classes. We also establish a relation to the previously well-studied completely unimodal (CU) and local-global functions. A number of nice properties of CLG-functions are proved. In this setting, we survey several randomized optimization algorithms appropriate for CU-, CLG-, and RLG-functions. We show that the subexponential algorithms for linear programming by Kalai and Matousek, Sharir, and Welzl, can be adapted to optimizing the functions we study, with preserved subexponential expected running time. We examine the relations to two other abstract frameworks for subexponential optimization, the LP-type problems of Matousek, Sharir, Welzl, and the abstract optimization problems of G{\"a}rtner. The applicability of our abstract optimization approach to parity games builds upon a discrete strategy evaluation measure. We also consider local search type algorithms, and settle two nontrivial, but still exponential, upper bounds. As applications we address some complexity-theoretic issues including non-PLS-completeness of the problems studied.},
  file = {/Users/sebastian/Zotero/storage/TFC4BPN2/2004-011.pdf}
}

@inproceedings{bjorklundShortestCycleSpecified2012,
  title = {Shortest {{Cycle Through Specified Elements}}},
  booktitle = {Proceedings of the {{Twenty-Third Annual ACM-SIAM Symposium}} on {{Discrete Algorithms}}},
  author = {Bj{\"o}rklund, Andreas and Husfeldt, Thore and Taslaman, Nina},
  year = {2012},
  month = jan,
  pages = {1747--1753},
  publisher = {{Society for Industrial and Applied Mathematics}},
  doi = {10.1137/1.9781611973099.139},
  urldate = {2024-05-02},
  abstract = {We give a randomized algorithm that finds a shortest simple cycle through a given set of k vertices or edges in an n-vertex undirected graph in time 2knO(1).},
  isbn = {978-1-61197-210-8 978-1-61197-309-9},
  langid = {english},
  file = {/Users/sebastian/Zotero/storage/ZLGRGS6I/Björklund et al. - 2012 - Shortest Cycle Through Specified Elements.pdf}
}

@inproceedings{bjorklundShortestEvenCycle2022,
  title = {The Shortest Even Cycle Problem Is Tractable},
  booktitle = {Proceedings of the 54th {{Annual ACM SIGACT Symposium}} on {{Theory}} of {{Computing}}},
  author = {Bj{\"o}rklund, Andreas and Husfeldt, Thore and Kaski, Petteri},
  year = {2022},
  month = jun,
  series = {{{STOC}} 2022},
  pages = {117--130},
  publisher = {Association for Computing Machinery},
  address = {New York, NY, USA},
  doi = {10.1145/3519935.3520030},
  urldate = {2023-09-11},
  abstract = {Given a directed graph as input, we show how to efficiently find a shortest (directed, simple) cycle on an even number of vertices. As far as we know, no polynomial-time algorithm was previously known for this problem. In fact, finding any even cycle in a directed graph in polynomial time was open for more than two decades until Robertson, Seymour, and Thomas (Ann. of Math. (2) 1999) and, independently, McCuaig (Electron. J. Combin. 2004; announced jointly at STOC 1997) gave an efficiently testable structural characterisation of even-cycle-free directed graphs. Methodologically, our algorithm relies on the standard framework of algebraic fingerprinting and randomized polynomial identity testing over a finite field, and in fact relies on a generating polynomial implicit in a paper of Vazirani and Yannakakis (Discrete Appl. Math. 1989) that enumerates weighted cycle covers by the parity of their number of cycles as a difference of a permanent and a determinant polynomial. The need to work with the permanent---known to be \#P-hard apart from a very restricted choice of coefficient rings (Valiant, Theoret. Comput. Sci. 1979)---is where our main technical contribution occurs. We design a family of finite commutative rings of characteristic 4 that simultaneously (i) give a nondegenerate representation for the generating polynomial identity via the permanent and the determinant, (ii) support efficient permanent computations by extension of Valiant's techniques, and (iii) enable emulation of finite-field arithmetic in characteristic 2. Here our work is foreshadowed by that of Bj{\"o}rklund and Husfeldt (SIAM J. Comput. 2019), who used a considerably less efficient commutative ring design---in particular, one lacking finite-field emulation---to obtain a polynomial-time algorithm for the shortest two disjoint paths problem in undirected graphs. Building on work of Gilbert and Tarjan (Numer. Math. 1978) as well as Alon and Yuster (J. ACM 2013), we also show how ideas from the nested dissection technique for solving linear equation systems---introduced by George (SIAM J. Numer. Anal. 1973) for symmetric positive definite real matrices---leads to faster algorithm designs in our present finite-ring randomized context when we have control on the separator structure of the input graph; for example, this happens when the input has bounded genus.},
  isbn = {978-1-4503-9264-8},
  keywords = {directed graph,parity cycle cover,permanent,polynomial-time algorithm,shortest even cycle,shortest two disjoint paths},
  file = {/Users/sebastian/Zotero/storage/SA52BDFP/Björklund et al. - 2022 - The shortest even cycle problem is tractable.pdf}
}

@inproceedings{bjorklundShortestTwoDisjoint2014,
  title = {Shortest {{Two Disjoint Paths}} in {{Polynomial Time}}},
  booktitle = {Automata, {{Languages}}, and {{Programming}}},
  author = {Bj{\"o}rklund, Andreas and Husfeldt, Thore},
  year = {2014},
  pages = {211--222},
  publisher = {Springer},
  address = {Berlin, Heidelberg},
  doi = {10.1007/978-3-662-43948-7_18},
  abstract = {Given an undirected graph and two pairs of vertices (si,ti) for i\,{$\in$}\,\{1,2\} we show that there is a polynomial time Monte Carlo algorithm that finds disjoint paths of smallest total length joining siand tifor i\,{$\in$}\,\{1,2\} respectively, or concludes that there most likely are no such paths at all. Our algorithm applies to both the vertex- and edge-disjoint versions of the problem.},
  isbn = {978-3-662-43948-7},
  langid = {english},
  keywords = {Laplace Expansion,Polynomial Time,Quotient Ring,Ring Element,Terminal Vertex},
  file = {/Users/sebastian/Zotero/storage/2EM9MG23/Björklund and Husfeldt - 2014 - Shortest Two Disjoint Paths in Polynomial Time.pdf}
}

@misc{blancoComplexityPOrderCone2025,
  title = {On the {{Complexity}} of P-{{Order Cone Programs}}},
  author = {Blanco, V{\'i}ctor and Magron, Victor and {Mart{\'i}nez-Ant{\'o}n}, Miguel},
  year = {2025},
  month = jan,
  number = {arXiv:2501.09828},
  eprint = {2501.09828},
  primaryclass = {math},
  publisher = {arXiv},
  doi = {10.48550/arXiv.2501.09828},
  urldate = {2025-01-20},
  abstract = {This manuscript explores novel complexity results for the feasibility problem over \$p\$-order cones, extending the foundational work of Porkolab and Khachiyan. By leveraging the intrinsic structure of \$p\$-order cones, we derive refined complexity bounds that surpass those obtained via standard semidefinite programming reformulations. Our analysis not only improves theoretical bounds but also provides practical insights into the computational efficiency of solving such problems. In addition to establishing complexity results, we derive explicit bounds for solutions when the feasibility problem admits one. For infeasible instances, we analyze their discrepancy quantifying the degree of infeasibility. Finally, we examine specific cases of interest, highlighting scenarios where the geometry of \$p\$-order cones or problem structure yields further computational simplifications. These findings contribute to both the theoretical understanding and practical tractability of optimization problems involving \$p\$-order cones.},
  archiveprefix = {arXiv},
  keywords = {Computer Science - Computational Complexity,Mathematics - Optimization and Control},
  file = {/Users/sebastian/Zotero/storage/NAZSVSM2/Blanco et al. - 2025 - On the Complexity of p-Order Cone Programs.pdf;/Users/sebastian/Zotero/storage/RMSDK2DC/2501.html}
}

@article{bodlaenderTouristGuideTreewidth1992,
  title = {A Tourist Guide through Treewidth},
  author = {Bodlaender, H. L.},
  year = {1992},
  journal = {Technical report RUU-CS},
  pages = {92},
  urldate = {2023-08-10},
  abstract = {A short overview is given of many recent results in algorithmic graph theory that deal with the notions treewidth, and pathwidth. We discuss algorithms that find tree-decompositions, algorithms that use tree-decompositions to solve hard problems efficiently, graph minor theory, and some applications. The paper contains an extensive bibliography.},
  copyright = {Utrecht},
  isbn = {9781018742304},
  langid = {english},
  annotation = {Accepted: 2001-06-26T09:17:02Z},
  file = {/Users/sebastian/Zotero/storage/C3NFC692/Bodlaender - 1992 - A tourist guide through treewidth.pdf}
}

@book{bonchiCorrelationClustering2022,
  title = {Correlation {{Clustering}}},
  author = {Bonchi, Francesco and {Garc{\'i}a-Soriano}, David and Gullo, Francesco},
  year = {2022},
  series = {Synthesis {{Lectures}} on {{Data Mining}} and {{Knowledge Discovery}}},
  publisher = {Springer International Publishing},
  address = {Cham},
  doi = {10.1007/978-3-031-79210-6},
  urldate = {2023-08-10},
  isbn = {978-3-031-79198-7 978-3-031-79210-6},
  langid = {english},
  file = {/Users/sebastian/Zotero/storage/G5R5S5HW/Bonchi et al. - 2022 - Correlation Clustering.pdf}
}

@misc{bonnetAnsweringRelatedQuestions2025,
  title = {Answering {{Related Questions}}},
  author = {Bonnet, {\'E}douard},
  year = {2025},
  month = jan,
  number = {arXiv:2501.10633},
  eprint = {2501.10633},
  primaryclass = {cs},
  publisher = {arXiv},
  doi = {10.48550/arXiv.2501.10633},
  urldate = {2025-01-22},
  abstract = {We introduce the meta-problem Sidestep\$({\textbackslash}Pi, {\textbackslash}mathsf\{dist\}, d)\$ for a problem \${\textbackslash}Pi\$, a metric \${\textbackslash}mathsf\{dist\}\$ over its inputs, and a map \$d: {\textbackslash}mathbb N {\textbackslash}to {\textbackslash}mathbb R\_+ {\textbackslash}cup {\textbackslash}\{{\textbackslash}infty{\textbackslash}\}\$. A solution to Sidestep\$({\textbackslash}Pi, {\textbackslash}mathsf\{dist\}, d)\$ on an input \$I\$ of \${\textbackslash}Pi\$ is a pair \$(J, {\textbackslash}Pi(J))\$ such that \${\textbackslash}mathsf\{dist\}(I,J) {\textbackslash}leqslant d({\textbar}I{\textbar})\$ and \${\textbackslash}Pi(J)\$ is a correct answer to \${\textbackslash}Pi\$ on input \$J\$. This formalizes the notion of answering a related question (or sidestepping the question), for which we give some practical and theoretical motivations, and compare it to the neighboring concepts of smoothed analysis, planted problems, and edition problems. Informally, we call hardness radius the ``largest'' \$d\$ such that Sidestep\$({\textbackslash}Pi, {\textbackslash}mathsf\{dist\}, d)\$ is NP-hard. This framework calls for establishing the hardness radius of problems \${\textbackslash}Pi\$ of interest for the relevant distances \${\textbackslash}mathsf\{dist\}\$. We exemplify it with graph problems and two distances \${\textbackslash}mathsf\{dist\}\_{\textbackslash}Delta\$ and \${\textbackslash}mathsf\{dist\}\_e\$ (the edge edit distance) such that \${\textbackslash}mathsf\{dist\}\_{\textbackslash}Delta(G,H)\$ (resp. \${\textbackslash}mathsf\{dist\}\_e(G,H)\$) is the maximum degree (resp. number of edges) of the symmetric difference of \$G\$ and \$H\$ if these graphs are on the same vertex set, and \$+{\textbackslash}infty\$ otherwise. We show that the decision problems Independent Set, Clique, Vertex Cover, Coloring, Clique Cover have hardness radius \$n{\textasciicircum}\{{\textbackslash}frac\{1\}\{2\}-o(1)\}\$ for \${\textbackslash}mathsf\{dist\}\_{\textbackslash}Delta\$, and \$n{\textasciicircum}\{{\textbackslash}frac\{4\}\{3\}-o(1)\}\$ for \${\textbackslash}mathsf\{dist\}\_e\$, that Hamiltonian Cycle has hardness radius 0 for \${\textbackslash}mathsf\{dist\}\_{\textbackslash}Delta\$, and somewhere between \$n{\textasciicircum}\{{\textbackslash}frac\{1\}\{2\}-o(1)\}\$ and \$n/3\$ for \${\textbackslash}mathsf\{dist\}\_e\$, and that Dominating Set has hardness radius \$n{\textasciicircum}\{1-o(1)\}\$ for \${\textbackslash}mathsf\{dist\}\_e\$. We leave several open questions.},
  archiveprefix = {arXiv},
  keywords = {Computer Science - Computational Complexity,Computer Science - Data Structures and Algorithms,Computer Science - Discrete Mathematics,Mathematics - Combinatorics},
  file = {/Users/sebastian/Zotero/storage/KTK98AEX/Bonnet - 2025 - Answering Related Questions.pdf;/Users/sebastian/Zotero/storage/ZV8VFIEA/2501.html}
}

@phdthesis{borzechowskiComplexityClassUnique,
  title = {The {{Complexity Class Unique End}} of {{Potential Line}}},
  author = {Borzechowski, Michaela},
  langid = {english},
  file = {/Users/sebastian/Zotero/storage/3GHJ3UVZ/Borzechowski - The Complexity Class Unique End of Potential Line.pdf}
}

@misc{borzechowskiTwoChoicesAre2024,
  title = {Two {{Choices}} Are {{Enough}} for {{P-LCPs}}, {{USOs}}, and {{Colorful Tangents}}},
  author = {Borzechowski, Michaela and Fearnley, John and Gordon, Spencer and Savani, Rahul and Schnider, Patrick and Weber, Simon},
  year = {2024},
  month = feb,
  number = {arXiv:2402.07683},
  eprint = {2402.07683},
  primaryclass = {cs, math},
  publisher = {arXiv},
  doi = {10.48550/arXiv.2402.07683},
  urldate = {2024-04-24},
  abstract = {We provide polynomial-time reductions between three search problems from three distinct areas: the P-matrix linear complementarity problem (P-LCP), finding the sink of a unique sink orientation (USO), and a variant of the \${\textbackslash}alpha\$-Ham Sandwich problem. For all three settings, we show that "two choices are enough", meaning that the general non-binary version of the problem can be reduced in polynomial time to the binary version. This specifically means that generalized P-LCPs are equivalent to P-LCPs, and grid USOs are equivalent to cube USOs. These results are obtained by showing that both the P-LCP and our \${\textbackslash}alpha\$-Ham Sandwich variant are equivalent to a new problem we introduce, P-Lin-Bellman. This problem can be seen as a new tool for formulating problems as P-LCPs.},
  archiveprefix = {arXiv},
  keywords = {Computer Science - Computational Complexity,Computer Science - Computational Geometry,Mathematics - Optimization and Control},
  file = {/Users/sebastian/Zotero/storage/B4VUTVPR/Borzechowski et al. - 2024 - Two Choices are Enough for P-LCPs, USOs, and Color.pdf;/Users/sebastian/Zotero/storage/DUIKWA7U/2402.html}
}

@book{boydConvexOptimization2004,
  title = {Convex Optimization},
  author = {Boyd, Stephen P. and Vandenberghe, Lieven},
  year = {2004},
  publisher = {Cambridge University Press},
  address = {Cambridge, UK ; New York},
  isbn = {978-0-521-83378-3},
  lccn = {QA402.5 .B69 2004},
  keywords = {Convex functions,Mathematical optimization},
  file = {/Users/sebastian/Zotero/storage/NDNKWG9C/Boyd and Vandenberghe - 2004 - Convex optimization.pdf}
}

@article{branzeiQueryComplexityCake2022,
  title = {The {{Query Complexity}} of {{Cake Cutting}}},
  author = {Branzei, Simina and Nisan, Noam},
  year = {2022},
  month = dec,
  journal = {Advances in Neural Information Processing Systems},
  volume = {35},
  pages = {37905--37919},
  urldate = {2024-06-21},
  langid = {english},
  file = {/Users/sebastian/Zotero/storage/JMWNEA8U/Branzei and Nisan - 2022 - The Query Complexity of Cake Cutting.pdf}
}

@misc{branzeiRandomizedLowerBounds2024,
  title = {Randomized {{Lower Bounds}} for {{Tarski Fixed Points}} in {{High Dimensions}}},
  author = {Br{\^a}nzei, Simina and Phillips, Reed and Recker, Nicholas},
  year = {2024},
  month = sep,
  number = {arXiv:2409.03751},
  eprint = {2409.03751},
  primaryclass = {cs},
  publisher = {arXiv},
  urldate = {2024-09-06},
  abstract = {The Knaster-Tarski theorem, also known as Tarski's theorem, guarantees that every monotone function defined on a complete lattice has a fixed point. We analyze the query complexity of finding such a fixed point on the k-dimensional grid of side length n under the {$\leq$} relation. Specifically, there is an unknown monotone function f : \{0, 1, . . . , n - 1\}k {$\rightarrow$} \{0, 1, . . . , n - 1\}k and an algorithm must query a vertex v to learn f (v).},
  archiveprefix = {arXiv},
  langid = {english},
  keywords = {Computer Science - Computational Complexity,Computer Science - Computer Science and Game Theory},
  file = {/Users/sebastian/Zotero/storage/4UG8ENIQ/Brânzei et al. - 2024 - Randomized Lower Bounds for Tarski Fixed Points in.pdf}
}

@article{brouwerUeberAbbildungMannigfaltigkeiten1911,
  title = {{{\"U}ber Abbildung von Mannigfaltigkeiten}},
  author = {Brouwer, L. E. J.},
  year = {1911},
  month = mar,
  journal = {Mathematische Annalen},
  volume = {71},
  number = {1},
  pages = {97--115},
  issn = {1432-1807},
  doi = {10.1007/BF01456931},
  urldate = {2025-01-20},
  langid = {ngerman},
  file = {/Users/sebastian/Zotero/storage/CTZH4LDF/Brouwer - 1911 - Über Abbildung von Mannigfaltigkeiten.pdf}
}

@misc{brunelGeneralizationGrunbaumsInequality2024,
  title = {A Generalization of {{Gr{\"u}nbaum}}'s Inequality in {{RCD}}\$(0,{{N}})\$-Spaces},
  author = {Brunel, Victor-Emmanuel and Ohta, Shin-ichi and Serres, Jordan},
  year = {2024},
  month = aug,
  number = {arXiv:2408.15030},
  eprint = {2408.15030},
  primaryclass = {math},
  publisher = {arXiv},
  doi = {10.48550/arXiv.2408.15030},
  urldate = {2025-01-15},
  abstract = {We generalize Gr{\textbackslash}"unbaum's classical inequality in convex geometry to curved spaces with nonnegative Ricci curvature, precisely, to \${\textbackslash}mathrm\{RCD\}(0,N)\$-spaces with \$N {\textbackslash}in (1,{\textbackslash}infty)\$ as well as weighted Riemannian manifolds of \${\textbackslash}mathrm\{Ric\}\_N {\textbackslash}ge 0\$ for \$N {\textbackslash}in (-{\textbackslash}infty,-1) {\textbackslash}cup {\textbackslash}\{{\textbackslash}infty{\textbackslash}\}\$. Our formulation makes use of the isometric splitting theorem; given a convex set \${\textbackslash}Omega\$ and the Busemann function associated with any straight line, the volume of the intersection of \${\textbackslash}Omega\$ and any sublevel set of the Busemann function that contains a barycenter of \${\textbackslash}Omega\$ is bounded from below in terms of \$N\$. We also extend this inequality beyond uniform distributions on convex sets. Moreover, we establish some rigidity results by using the localization method, and the stability problem is also studied.},
  archiveprefix = {arXiv},
  keywords = {Mathematics - Metric Geometry,Mathematics - Probability,Mathematics - Statistics Theory,Statistics - Statistics Theory},
  file = {/Users/sebastian/Zotero/storage/WZL4HHFT/Brunel et al. - 2024 - A generalization of Grünbaum's inequality in RCD$(0,N)$-spaces.pdf;/Users/sebastian/Zotero/storage/KFWB4A8Y/2408.html}
}

@article{bubeckConvexOptimizationAlgorithms2015,
  title = {Convex {{Optimization}}: {{Algorithms}} and {{Complexity}}},
  shorttitle = {Convex {{Optimization}}},
  author = {Bubeck, S{\'e}bastien},
  year = {2015},
  month = nov,
  journal = {Found. Trends Mach. Learn.},
  volume = {8},
  number = {3-4},
  pages = {231--357},
  issn = {1935-8237},
  doi = {10.1561/2200000050},
  urldate = {2025-01-15},
  abstract = {This monograph presents the main complexity theorems in convex optimization and their corresponding algorithms. Starting from the fundamental theory of black-box optimization, the material progresses towards recent advances in structural optimization and stochastic optimization. Our presentation of black-box optimization, strongly influenced by the seminal book of Nesterov, includes the analysis of cutting plane methods, as well as accelerated gradient descent schemes. We also pay special attention to non-Euclidean settings relevant algorithms include Frank-Wolfe, mirror descent, and dual averaging and discuss their relevance in machine learning. We provide a gentle introduction to structural optimization with FISTA to optimize a sum of a smooth and a simple non-smooth term, saddle-point mirror prox Nemirovski's alternative to Nesterov's smoothing, and a concise description of interior point methods. In stochastic optimization we discuss stochastic gradient descent, mini-batches, random coordinate descent, and sublinear algorithms. We also briefly touch upon convex relaxation of combinatorial problems and the use of randomness to round solutions, as well as random walks based methods.},
  file = {/Users/sebastian/Zotero/storage/3MCTZ85C/Bubeck - 2015 - Convex Optimization Algorithms and Complexity.pdf}
}

@inproceedings{buresh-oppenheimRelativizedNPSearch2004,
  title = {Relativized {{NP}} Search Problems and Propositional Proof Systems},
  booktitle = {Proceedings. 19th {{IEEE Annual Conference}} on {{Computational Complexity}}, 2004.},
  author = {{Buresh-Oppenheim}, J. and Morioka, T.},
  year = {2004},
  pages = {54--67},
  publisher = {IEEE},
  address = {Amherst, MA, USA},
  doi = {10.1109/CCC.2004.1313795},
  urldate = {2025-01-15},
  abstract = {An NP search problem is the problem of finding a witness to a given NP predicate, and TFNP is the class of total NP search problems. TFNP contains a number of subclasses containing natural problems; for example, PLS is the class of efficient local search heuristics. These classes are characterized by the combinatorial principle that guarantees the existence of a solution; for example, PLS is the class of such problems whose totality is assured by the principle ``every dag with at least one edge has a sink.'' We show many strong connections between these search classes and the computational power---in particular the proof complexity---of their underlying principles. These connections, along with lower bounds in the propositional proof systems Nullstellensatz and bounded-depth LK, allow us to prove several new relative separations among PLS, and Papadimitriou's classes PPP, PPA, PPAD, and PPADS.},
  isbn = {978-0-7695-2120-6},
  langid = {english},
  file = {/Users/sebastian/Zotero/storage/ZMTNN4E7/Buresh-Oppenheim and Morioka - 2004 - Relativized NP search problems and propositional proof systems.pdf}
}

@article{bussFragmentsApproximateCounting2014,
  title = {Fragments of {{Approximate Counting}}},
  author = {Buss, Samuel R. and Ko{\l}odziejczyk, Leszek Aleksander and Thapen, Neil},
  year = {2014},
  journal = {The Journal of Symbolic Logic},
  volume = {79},
  number = {2},
  eprint = {43303745},
  eprinttype = {jstor},
  pages = {496--525},
  publisher = {Association for Symbolic Logic, Cambridge University Press},
  issn = {0022-4812},
  urldate = {2024-06-10},
  abstract = {We study the long-standing open problem of giving \${\textbackslash}forall {\textbackslash}Sigma \_1{\textasciicircum}b\$ separations for fragments of bounded arithmetic in the relativized setting. Rather than considering the usual fragments defined by the amount of induction they allow, we study Je{\v r}{\'a}bek's theories for approximate counting and their subtheories. We show that the \${\textbackslash}forall {\textbackslash}Sigma \_1{\textasciicircum}b\$ Herbrandized ordering principle is unprovable in a fragment of bounded arithmetic that includes the injective weak pigeonhole principle for polynomial time functions, and also in a fragment that includes the surjective weak pigeonhole principle for FPNP functions. We further give new propositional translations, in terms of random resolution refutations, for the consequences of \$T\_2{\textasciicircum}1\$ augmented with the surjective weak pigeonhole principle for polynomial time functions.},
  file = {/Users/sebastian/Zotero/storage/55722I4U/Buss et al. - 2014 - Fragments of Approximate Counting.pdf}
}

@article{bussPropositionalProofsReductions2012,
  title = {Propositional Proofs and Reductions between {{NP}} Search Problems},
  author = {Buss, Samuel R. and Johnson, Alan S.},
  year = {2012},
  month = sep,
  journal = {Annals of Pure and Applied Logic},
  volume = {163},
  number = {9},
  pages = {1163--1182},
  issn = {0168-0072},
  doi = {10.1016/j.apal.2012.01.015},
  urldate = {2023-10-30},
  abstract = {Total NP search problems (TFNP problems) typically have their totality guaranteed by some combinatorial property. This paper proves that, if there is a polynomial time Turing reduction between two TFNP problems, then there are quasipolynomial size, polylogarithmic height, constant depth, free-cut free propositional (Frege) proofs of the combinatorial property associated with the first TFNP problem from the property associated with the second problem. In addition, they have Nullstellensatz derivations of polylogarithmic degree. These results extend the previous work of Buresh-Oppenheim and Morioka first by applying to Turing reductions in place of many-one reductions and second by giving tight bounds on the height of the Frege proofs. As a corollary, PLS-complete problems are not polynomial time Turing reducible to PPA problems relative to a generic oracle. We establish a converse construction as well, by showing that a polynomial time Turing reduction can be obtained from a family of quasipolynomial size, polylogarithmic depth, propositional proofs which are based on ``decision tree'' substitutions. This establishes the optimality of our constructions, and partially resolves an open question posed by Buresh-Oppenheim and Morioka. We observe that the classes PPA, PPAD, PPADS, and PLS are closed under Turing reductions, and give an example of a TFNP class that is not closed under Turing reductions.},
  keywords = {Nullstellensatz,Polynomial time reducibility,Propositional proofs,Search problems},
  file = {/Users/sebastian/Zotero/storage/YWFDAU6W/Buss and Johnson - 2012 - Propositional proofs and reductions between NP sea.pdf}
}

@inproceedings{caludeDecidingParityGames2017,
  title = {Deciding Parity Games in Quasipolynomial Time},
  booktitle = {{{STOC}} '17: {{Symposium}} on {{Theory}} of {{Computing}}},
  author = {Calude, Cristian S. and Jain, Sanjay and Khoussainov, Bakhadyr and Li, Wei and Stephan, Frank},
  year = {2017},
  month = jun,
  pages = {252--263},
  publisher = {ACM},
  address = {Montreal Canada},
  doi = {10.1145/3055399.3055409},
  urldate = {2023-10-01},
  isbn = {978-1-4503-4528-6},
  langid = {english},
  file = {/Users/sebastian/Zotero/storage/GGJVKSUP/3055399.3055409.pdf}
}

@article{chanRotorRoutingSpanningTrees2015,
  title = {Rotor-{{Routing}} and {{Spanning Trees}} on {{Planar Graphs}}},
  author = {Chan, Melody and Church, Thomas and Grochow, Joshua A.},
  year = {2015},
  month = jan,
  journal = {International Mathematics Research Notices},
  volume = {2015},
  number = {11},
  pages = {3225--3244},
  issn = {1687-0247, 1073-7928},
  doi = {10.1093/imrn/rnu025},
  urldate = {2024-07-15},
  langid = {english},
  file = {/Users/sebastian/Zotero/storage/VUYLGIRP/Chan et al. - 2015 - Rotor-Routing and Spanning Trees on Planar Graphs.pdf}
}

@article{chanSandpilesSpanningTrees2015,
  title = {Sandpiles, {{Spanning Trees}}, and {{Plane Duality}}},
  author = {Chan, Melody and Glass, Darren and Macauley, Matthew and Perkinson, David and Werner, Caryn and Yang, Qiaoyu},
  year = {2015},
  month = jan,
  journal = {SIAM Journal on Discrete Mathematics},
  volume = {29},
  number = {1},
  pages = {461--471},
  issn = {0895-4801, 1095-7146},
  doi = {10.1137/140982015},
  urldate = {2024-07-15},
  langid = {english},
  file = {/Users/sebastian/Zotero/storage/5YUCXWLT/Chan et al. - 2015 - Sandpiles, Spanning Trees, and Plane Duality.pdf}
}

@incollection{chatterjeeFasterAlgorithmTurnbased2023,
  title = {Faster {{Algorithm}} for {{Turn-based Stochastic Games}} with {{Bounded Treewidth}}},
  booktitle = {Proceedings of the 2023 {{Annual ACM-SIAM Symposium}} on {{Discrete Algorithms}} ({{SODA}})},
  author = {Chatterjee, Krishnendu and Meggendorfer, Tobias and Saona, Raimundo and Svoboda, Jakub},
  year = {2023},
  month = jan,
  series = {Proceedings},
  pages = {4590--4605},
  publisher = {{Society for Industrial and Applied Mathematics}},
  doi = {10.1137/1.9781611977554.ch173},
  urldate = {2023-09-19},
  abstract = {Turn-based stochastic games (aka simple stochastic games) are two-player zero-sum games played on directed graphs with probabilistic transitions. The goal of player-max is to maximize the probability to reach a target state against the adversarial player-min. These games lie in NP {$\cap$} coNP and are among the rare combinatorial problems that belong to this complexity class for which the existence of polynomial-time algorithm is a major open question. While randomized sub-exponential time algorithm exists, all known deterministic algorithms require exponential time in the worst-case. An important open question has been whether faster algorithms can be obtained parametrized by the treewidth of the game graph. Even deterministic sub-exponential time algorithm for constant treewidth turn-based stochastic games has remain elusive. In this work our main result is a deterministic algorithm to solve turn-based stochastic games that, given a game with n states, treewidth at most t, and the bit-complexity of the probabilistic transition function log D, has running time O ((tn2 log D)t log n). In particular, our algorithm is quasi-polynomial time for games with constant or poly-logarithmic treewidth.},
  file = {/Users/sebastian/Zotero/storage/4JIQNQGJ/Chatterjee et al. - 2023 - Faster Algorithm for Turn-based Stochastic Games w.pdf}
}

@misc{chatterjeeLinearEquationsMin2024,
  title = {Linear {{Equations}} with {{Min}} and {{Max Operators}}: {{Computational Complexity}}},
  shorttitle = {Linear {{Equations}} with {{Min}} and {{Max Operators}}},
  author = {Chatterjee, Krishnendu and Luo, Ruichen and Saona, Raimundo and Svoboda, Jakub},
  year = {2024},
  month = dec,
  number = {arXiv:2412.12228},
  eprint = {2412.12228},
  primaryclass = {cs},
  publisher = {arXiv},
  doi = {10.48550/arXiv.2412.12228},
  urldate = {2025-01-20},
  abstract = {We consider a class of optimization problems defined by a system of linear equations with min and max operators. This class of optimization problems has been studied under restrictive conditions, such as, (C1) the halting or stability condition; (C2) the non-negative coefficients condition; (C3) the sum up to 1 condition; and (C4) the only min or only max oerator condition. Several seminal results in the literature focus on special cases. For example, turn-based stochastic games correspond to conditions C2 and C3; and Markov decision process to conditions C2, C3, and C4. However, the systematic computational complexity study of all the cases has not been explored, which we address in this work. Some highlights of our results are: with conditions C2 and C4, and with conditions C3 and C4, the problem is NP-complete, whereas with condition C1 only, the problem is in UP intersects coUP. Finally, we establish the computational complexity of the decision problem of checking the respective conditions.},
  archiveprefix = {arXiv},
  keywords = {Computer Science - Artificial Intelligence,Computer Science - Computational Complexity,Mathematics - Optimization and Control},
  file = {/Users/sebastian/Zotero/storage/RI6E4Q9M/Chatterjee et al. - 2024 - Linear Equations with Min and Max Operators Computational Complexity.pdf;/Users/sebastian/Zotero/storage/G5788SLG/2412.html}
}

@inproceedings{chatterjeePolynomialInvariantGeneration2020,
  title = {Polynomial Invariant Generation for Non-Deterministic Recursive Programs},
  booktitle = {Proceedings of the 41st {{ACM SIGPLAN Conference}} on {{Programming Language Design}} and {{Implementation}}},
  author = {Chatterjee, Krishnendu and Fu, Hongfei and Goharshady, Amir Kafshdar and Goharshady, Ehsan Kafshdar},
  year = {2020},
  month = jun,
  pages = {672--687},
  publisher = {ACM},
  address = {London UK},
  doi = {10.1145/3385412.3385969},
  urldate = {2023-08-10},
  isbn = {978-1-4503-7613-6},
  langid = {english},
  file = {/Users/sebastian/Zotero/storage/9IDF5AMK/Chatterjee et al. - 2020 - Polynomial invariant generation for non-determinis.pdf}
}

@inproceedings{chatterjeeReductionParityGames2011a,
  title = {A {{Reduction}} from {{Parity Games}} to {{Simple Stochastic Games}}},
  booktitle = {International {{Symposium}} on {{Games}}, {{Automata}}, {{Logics}}, and {{Formal Verification}}, {{GandALF}}},
  author = {Chatterjee, Krishnendu and Fijalkow, Nathana{\"e}l},
  year = {2011},
  address = {NA, Italy},
  doi = {10.4204/EPTCS.54.6},
  urldate = {2025-02-05},
  keywords = {conference},
  file = {/Users/sebastian/Zotero/storage/KXQ74ELC/Chatterjee and Fijalkow - 2011 - A Reduction from Parity Games to Simple Stochastic Games.pdf;/Users/sebastian/Zotero/storage/FICR5Y2M/hal-03410691.html}
}

@inproceedings{chawlaOptimalLPRounding2015,
  title = {Near {{Optimal LP Rounding Algorithm}} for {{CorrelationClustering}} on {{Complete}} and {{Complete}} K-Partite {{Graphs}}},
  booktitle = {Proceedings of the Forty-Seventh Annual {{ACM}} Symposium on {{Theory}} of {{Computing}}},
  author = {Chawla, Shuchi and Makarychev, Konstantin and Schramm, Tselil and Yaroslavtsev, Grigory},
  year = {2015},
  month = jun,
  pages = {219--228},
  publisher = {ACM},
  address = {Portland Oregon USA},
  doi = {10.1145/2746539.2746604},
  urldate = {2023-08-10},
  isbn = {978-1-4503-3536-2},
  langid = {english},
  file = {/Users/sebastian/Zotero/storage/BRF482MG/Chawla et al. - 2015 - Near Optimal LP Rounding Algorithm for Correlation.pdf}
}

@incollection{chenComplexity2DDiscrete2006,
  title = {On the {{Complexity}} of {{2D Discrete Fixed Point Problem}}},
  booktitle = {Automata, {{Languages}} and {{Programming}}},
  author = {Chen, Xi and Deng, Xiaotie},
  year = {2006},
  volume = {4051},
  pages = {489--500},
  publisher = {Springer Berlin Heidelberg},
  address = {Berlin, Heidelberg},
  doi = {10.1007/11786986_43},
  urldate = {2023-11-06},
  isbn = {978-3-540-35904-3 978-3-540-35905-0},
  file = {/Users/sebastian/Zotero/storage/7XVLZZTZ/11786986_43.pdf}
}

@inproceedings{chenComputingFixedPoint2024,
  title = {Computing a {{Fixed Point}} of {{Contraction Maps}} in {{Polynomial Queries}}},
  booktitle = {Proceedings of the 56th {{Annual ACM Symposium}} on {{Theory}} of {{Computing}}},
  author = {Chen, Xi and Li, Yuhao and Yannakakis, Mihalis},
  year = {2024},
  month = jun,
  series = {{{STOC}} 2024},
  pages = {1364--1373},
  publisher = {Association for Computing Machinery},
  address = {New York, NY, USA},
  doi = {10.1145/3618260.3649623},
  urldate = {2024-06-25},
  abstract = {We give an algorithm for finding an {\cyrchar\cyrie}-fixed point of a contraction map f:[0,1]k{$\mapsto$}[0,1]k under the {$\ell\infty$}-norm with query complexity O (k2log(1/{\cyrchar\cyrie} ) ).},
  isbn = {9798400703836},
  file = {/Users/sebastian/Zotero/storage/UH5CJYKB/Chen et al. - 2024 - Computing a Fixed Point of Contraction Maps in Pol.pdf}
}

@article{chengDivideandmergeMethodologyClustering2006,
  title = {A Divide-and-Merge Methodology for Clustering},
  author = {Cheng, David and Kannan, Ravi and Vempala, Santosh and Wang, Grant},
  year = {2006},
  month = dec,
  journal = {ACM Transactions on Database Systems},
  volume = {31},
  number = {4},
  pages = {1499--1525},
  issn = {0362-5915},
  doi = {10.1145/1189769.1189779},
  urldate = {2023-08-10},
  abstract = {We present a divide-and-merge methodology for clustering a set of objects that combines a top-down ``divide'' phase with a bottom-up ``merge'' phase. In contrast, previous algorithms use either top-down or bottom-up methods to construct a hierarchical clustering or produce a flat clustering using local search (e.g., k-means). For the divide phase, which produces a tree whose leaves are the elements of the set, we suggest an efficient spectral algorithm. When the data is in the form of a sparse document-term matrix, we show how to modify the algorithm so that it maintains sparsity and runs in linear space. The merge phase quickly finds the optimal partition that respects the tree for many natural objective functions, for example, k-means, min-diameter, min-sum, correlation clustering, etc. We present a thorough experimental evaluation of the methodology. We describe the implementation of a meta-search engine that uses this methodology to cluster results from web searches. We also give comparative empirical results on several real datasets.},
  keywords = {Clustering,data mining,information retrieval},
  file = {/Users/sebastian/Zotero/storage/7MPB97K4/Cheng et al. - 2006 - A divide-and-merge methodology for clustering.pdf}
}

@inproceedings{chenImprovedUpperBounds2022,
  title = {Improved {{Upper Bounds}} for {{Finding Tarski Fixed Points}}},
  booktitle = {Proceedings of the 23rd {{ACM Conference}} on {{Economics}} and {{Computation}}},
  author = {Chen, Xi and Li, Yuhao},
  year = {2022},
  month = jul,
  series = {{{EC}} '22},
  pages = {1108--1118},
  publisher = {Association for Computing Machinery},
  address = {New York, NY, USA},
  doi = {10.1145/3490486.3538297},
  urldate = {2024-04-09},
  abstract = {We study the query complexity of finding a Tarski fixed point over the k-dimensional grid \{1,...,n\}k. Improving on the previous best upper bound of O(log{$\lceil$}2k/3{$\rceil$}n)[7], we give a new algorithm with query complexity O(log{$\lceil$}(k+1)/2{$\rceil$}n). This is based on a novel decomposition theorem about a weaker variant of the Tarski fixed point problem, where the input consists of a monotone function f:[n]k{$\rightarrow$}[n]k and a monotone sign function b:[n]k{$\rightarrow$} \{-1,0,1\} and the goal is to find a point x {$\in$} [n]k that satisfies either f(x) ≼ x and b(x) {$\leq$} 0 or f(x) ≽ x and b(x) {$\geq$} 0.},
  isbn = {978-1-4503-9150-4},
  keywords = {query complexity,supermodular games,Tarski fixed points},
  file = {/Users/sebastian/Zotero/storage/L3429ZPK/Chen and Li - 2022 - Improved Upper Bounds for Finding Tarski Fixed Poi.pdf}
}

@misc{chenNewWaysStudying2023,
  title = {New Ways of Studying the {{BPP}} = {{P}} Conjecture},
  author = {Chen, Lijie and Tell, Roei},
  year = {2023},
  month = jun,
  number = {TR23-094},
  eprint = {TR23-094},
  publisher = {Electronic Colloquium on Computational Complexity},
  issn = {1433-8092},
  urldate = {2024-10-25},
  abstract = {What's new in the world of derandomization? Questions about pseudorandomness and derandomization have been driving progress in complexity theory for many decades. In this survey we will describe new approaches to the = conjecture from recent years, as well as new questions, algorithmic approaches, and ways of thinking. For example: Do we really need pseudorandom generators for derandomization, or can we get away with weaker objects? Can we prove free lunch theorems, eliminating randomness with zero computational overhead? What hardness assumptions are necessary and sufficient for derandomization? And how do new advances in this area interact with progress in cryptography and in interactive proof systems? Note: A version of this text originally appeared as an ACM SIGACT News Complexity Theory Column.},
  archiveprefix = {Electronic Colloquium on Computational Complexity},
  langid = {english},
  file = {/Users/sebastian/Zotero/storage/VJZTPDBE/Chen and Tell - 2023 - New ways of studying the BPP = P conjecture.pdf}
}

@inproceedings{chenReducingTarskiUnique2023a,
  title = {Reducing {{Tarski}} to {{Unique Tarski}} ({{In}} the {{Black-Box Model}})},
  booktitle = {38th {{Computational Complexity Conference}} ({{CCC}} 2023)},
  author = {Chen, Xi and Li, Yuhao and Yannakakis, Mihalis},
  year = {2023},
  series = {Leibniz {{International Proceedings}} in {{Informatics}} ({{LIPIcs}})},
  volume = {264},
  pages = {21:1--21:23},
  publisher = {Schloss Dagstuhl -- Leibniz-Zentrum f{\"u}r Informatik},
  address = {Dagstuhl, Germany},
  issn = {1868-8969},
  doi = {10.4230/LIPIcs.CCC.2023.21},
  urldate = {2025-01-17},
  isbn = {978-3-95977-282-2},
  keywords = {Query complexity,Tarski fixed point,TFNP},
  file = {/Users/sebastian/Zotero/storage/T4NA9AXS/Chen et al. - 2023 - Reducing Tarski to Unique Tarski (In the Black-Box Model).pdf;/Users/sebastian/Zotero/storage/YJL8IPL7/LIPIcs.CCC.2023.html}
}

@article{cheongFindingShortestEven2022,
  title = {Finding a Shortest Even Hole in Polynomial Time},
  author = {Cheong, Hou-Teng and Lu, Hsueh-I},
  year = {2022},
  journal = {Journal of Graph Theory},
  volume = {99},
  number = {3},
  pages = {425--434},
  issn = {1097-0118},
  doi = {10.1002/jgt.22748},
  urldate = {2023-09-11},
  abstract = {An even (respectively, odd) hole in a graph is an induced cycle with even (respectively, odd) length that is at least four. Bienstock proved that detecting an even (respectively, odd) hole containing a given vertex is NP-complete. Conforti, Cornu{\'e}jols, Kapoor, and Vu{\v s}kovi{\'c} gave the first known polynomial-time algorithm to determine whether a graph contains even holes. Chudnovsky, Kawarabayashi, and Seymour estimated that Conforti et al.'s algorithm runs in O ( n 40 ) time on an n-vertex graph and reduced the required time to O ( n 31 ). Subsequently, da Silva and Vu{\v s}kovi{\'c}, Chang and Lu, and Lai, Lu, and Thorup improved the time to O ( n 19 ), O ( n 11 ), and O ( n 9 ), respectively. The tractability of determining whether a graph contains odd holes has been open for decades until the algorithm of Chudnovsky, Scott, Seymour, and Spirkl that runs in O ( n 9 ) time, which Lai et al. also reduced to O ( n 8 ). By extending Chudnovsky et al.'s techniques for detecting odd holes, Chudnovsky, Scott, and Seymour (respectively) ensured the tractability of finding a long (respectively, shortest) odd hole. They also ensured the NP-hardness of finding a longest odd hole, whose reduction also works for finding a longest even hole. Recently, Cook and Seymour ensured the tractability of finding a long even hole. An intriguing missing piece is the tractability of finding a shortest even hole, left open for 16 years by, for example, Chudnovsky et al. and Johnson. We resolve this open problem by augmenting Chudnovsky et al.'s even-hole detection algorithm into the first known polynomial-time algorithm, running in O ( n 31 ) time, for finding a shortest even hole in an n-vertex graph that contains even holes.},
  copyright = {{\copyright} 2021 Wiley Periodicals LLC},
  langid = {english},
  keywords = {data structure,induced subgraph,polynomial-time algorithm,shortest even hole},
  file = {/Users/sebastian/Zotero/storage/2V4DDXDF/Cheong and Lu - 2022 - Finding a shortest even hole in polynomial time.pdf;/Users/sebastian/Zotero/storage/AE33BU93/jgt.html}
}

@article{chiangPredictionClusteringSigned2014,
  title = {Prediction and Clustering in Signed Networks: A Local to Global Perspective},
  shorttitle = {Prediction and Clustering in Signed Networks},
  author = {Chiang, Kai-Yang and Hsieh, Cho-Jui and Natarajan, Nagarajan and Dhillon, Inderjit S. and Tewari, Ambuj},
  year = {2014},
  month = jan,
  journal = {The Journal of Machine Learning Research},
  volume = {15},
  number = {1},
  pages = {1177--1213},
  issn = {1532-4435},
  abstract = {The study of social networks is a burgeoning research area. However, most existing work is on networks that simply encode whether relationships exist or not. In contrast, relationships in signed networks can be positive ("like", "trust") or negative ("dislike", "distrust"). The theory of social balance shows that signed networks tend to conform to some local patterns that, in turn, induce certain global characteristics. In this paper, we exploit both local as well as global aspects of social balance theory for two fundamental problems in the analysis of signed networks: sign prediction and clustering. Local patterns of social balance have been used in the past for sign prediction. We define more general measures of social imbalance (MOIs) based on l-cycles in the network and give a simple sign prediction rule. Interestingly, by examining measures of social imbalance, we show that the classic Katz measure, which is used widely in unsigned link prediction, also has a balance theoretic interpretation when applied to signed networks. Motivated by the global structure of balanced networks, we propose an effective low rank modeling approach for both sign prediction and clustering. We provide theoretical performance guarantees for our low-rank matrix completion approach via convex relaxations, scale it up to large problem sizes using a matrix factorization based algorithm, and provide extensive experimental validation including comparisons with local approaches. Our experimental results indicate that, by adopting a more global viewpoint of social balance, we get significant performance and computational gains in prediction and clustering tasks on signed networks. Our work therefore highlights the usefulness of the global aspect of balance theory for the analysis of signed networks.},
  keywords = {balance theory,graph clustering,low rank model,matrix completion,sign prediction,signed networks},
  file = {/Users/sebastian/Zotero/storage/E95U5YBK/Chiang et al. - 2014 - Prediction and clustering in signed networks a lo.pdf}
}

@misc{chiuImprovedAlgorithmsRecognizing2022,
  title = {Improved {{Algorithms}} for {{Recognizing Perfect Graphs}} and {{Finding Shortest Odd}} and {{Even Holes}}},
  author = {Chiu, Yung-Chung and Lai, Kai-Yuan and Lu, Hsueh-I.},
  year = {2022},
  month = jul,
  number = {arXiv:2207.07613},
  eprint = {2207.07613},
  primaryclass = {cs, math},
  publisher = {arXiv},
  doi = {10.48550/arXiv.2207.07613},
  urldate = {2023-09-11},
  abstract = {Various classes of induced subgraphs are involved in the deepest results of graph theory and graph algorithms. A prominent example concerns the \{{\textbackslash}em perfection\} of \$G\$ that the chromatic number of each induced subgraph \$H\$ of \$G\$ equals the clique number of \$H\$. The seminal Strong Perfect Graph Theorem confirms that the perfection of \$G\$ can be determined by detecting odd holes in \$G\$ and its complement. Chudnovsky et al. show in 2005 an \$O(n{\textasciicircum}9)\$ algorithm for recognizing perfect graphs, which can be implemented to run in \$O(n{\textasciicircum}\{6+{\textbackslash}omega\})\$ time for the exponent \${\textbackslash}omega{$<$}2.373\$ of square-matrix multiplication. We show the following improved algorithms. 1. The tractability of detecting odd holes was open for decades until the major breakthrough of Chudnovsky et al. in 2020. Their \$O(n{\textasciicircum}9)\$ algorithm is later implemented by Lai et al. to run in \$O(n{\textasciicircum}8)\$ time, leading to the best formerly known algorithm for recognizing perfect graphs. Our first result is an \$O(n{\textasciicircum}7)\$ algorithm for detecting odd holes, implying an \$O(n{\textasciicircum}7)\$ algorithm for recognizing perfect graphs. 2. Chudnovsky et al. extend in 2021 the \$O(n{\textasciicircum}9)\$ algorithms for detecting odd holes (2020) and recognizing perfect graphs (2005) into the first polynomial algorithm for obtaining a shortest odd hole, which runs in \$O(n{\textasciicircum}\{14\})\$ time. We reduce the time for finding a shortest odd hole to \$O(n{\textasciicircum}\{13\})\$. 3. Conforti et al. show in 1997 the first polynomial algorithm for detecting even holes, running in about \$O(n{\textasciicircum}\{40\})\$ time. It then takes a line of intensive efforts in the literature to bring down the complexity to \$O(n{\textasciicircum}\{31\})\$, \$O(n{\textasciicircum}\{19\})\$, \$O(n{\textasciicircum}\{11\})\$, and finally \$O(n{\textasciicircum}9)\$. On the other hand, the tractability of finding a shortest even hole has been open for 16 years until the very recent \$O(n{\textasciicircum}\{31\})\$ algorithm of Cheong and Lu in 2022. We improve the time of finding a shortest even hole to \$O(n{\textasciicircum}\{23\})\$.},
  archiveprefix = {arXiv},
  keywords = {05C38 05C10 05C85 68P05,Computer Science - Data Structures and Algorithms,F.2.2,G.2.2,Mathematics - Combinatorics},
  file = {/Users/sebastian/Zotero/storage/SLAMNK5F/Chiu et al. - 2022 - Improved Algorithms for Recognizing Perfect Graphs.pdf;/Users/sebastian/Zotero/storage/ZPYQM2Y4/2207.html}
}

@inproceedings{choudhuriFindingNashEquilibrium2019,
  title = {Finding a {{Nash}} Equilibrium Is No Easier than Breaking {{Fiat-Shamir}}},
  booktitle = {Proceedings of the 51st {{Annual ACM SIGACT Symposium}} on {{Theory}} of {{Computing}}},
  author = {Choudhuri, Arka Rai and Hub{\'a}{\v c}ek, Pavel and Kamath, Chethan and Pietrzak, Krzysztof and Rosen, Alon and Rothblum, Guy N.},
  year = {2019},
  month = jun,
  series = {{{STOC}} 2019},
  pages = {1103--1114},
  publisher = {Association for Computing Machinery},
  address = {New York, NY, USA},
  doi = {10.1145/3313276.3316400},
  urldate = {2024-06-12},
  abstract = {The Fiat-Shamir heuristic transforms a public-coin interactive proof into a non-interactive argument, by replacing the verifier with a cryptographic hash function that is applied to the protocol's transcript. Constructing hash functions for which this transformation is sound is a central and long-standing open question in cryptography. We show that solving the END-OF-METERED-LINE problem is no easier than breaking the soundness of the Fiat-Shamir transformation when applied to the sumcheck protocol. In particular, if the transformed protocol is sound, then any hard problem in \#P gives rise to a hard distribution in the class CLS, which is contained in PPAD. Our result opens up the possibility of sampling moderately-sized games for which it is hard to find a Nash equilibrium, by reducing the inversion of appropriately chosen one-way functions to \#SAT. Our main technical contribution is a stateful incrementally verifiable procedure that, given a SAT instance over n variables, counts the number of satisfying assignments. This is accomplished via an exponential sequence of small steps, each computable in time poly(n). Incremental verifiability means that each intermediate state includes a sumcheck-based proof of its correctness, and the proof can be updated and verified in time poly(n).},
  isbn = {978-1-4503-6705-9},
  keywords = {Fiat-Shamir transformation,Nash Equilibrium,PPAD,TFNP},
  file = {/Users/sebastian/Zotero/storage/GWQKCFDE/Choudhuri et al. - 2019 - Finding a Nash equilibrium is no easier than break.pdf}
}

@article{chudnovskyFindingShortestOdd2021,
  title = {Finding a {{Shortest Odd Hole}}},
  author = {Chudnovsky, Maria and Scott, Alex and Seymour, Paul},
  year = {2021},
  month = apr,
  journal = {ACM Transactions on Algorithms},
  volume = {17},
  number = {2},
  pages = {1--21},
  issn = {1549-6325, 1549-6333},
  doi = {10.1145/3447869},
  urldate = {2023-09-11},
  abstract = {An odd hole in a graph is an induced cycle with odd length greater than 3. In an earlier paper (with Sophie Spirkl), solving a longstanding open problem, we gave a polynomial-time algorithm to test if a graph has an odd hole. We subsequently showed that, for every               t               , there is a polynomial-time algorithm to test whether a graph contains an odd hole of length at least               t               . In this article, we give an algorithm that finds a shortest odd hole, if one exists.},
  langid = {english},
  file = {/Users/sebastian/Zotero/storage/8IECSY5X/Chudnovsky et al. - 2021 - Finding a Shortest Odd Hole.pdf}
}

@inproceedings{cisneros-velardeContractionTheoryApproach2022,
  title = {A {{Contraction Theory Approach}} to {{Optimization Algorithms}} from {{Acceleration Flows}}},
  booktitle = {Proceedings of {{The}} 25th {{International Conference}} on {{Artificial Intelligence}} and {{Statistics}}},
  author = {{Cisneros-Velarde}, Pedro and Bullo, Francesco},
  year = {2022},
  month = may,
  pages = {1321--1335},
  publisher = {PMLR},
  issn = {2640-3498},
  urldate = {2024-11-08},
  abstract = {Much recent interest has focused on the design of optimization algorithms from the discretization of an associated optimization flow, i.e., a system of differential equations (ODEs) whose trajectories solve an associated optimization problem. Such a design approach poses an important problem: how to find a principled methodology to design and discretize appropriate ODEs. This paper aims to provide a solution to this problem through the use of contraction theory. We first introduce general mathematical results that explain how contraction theory guarantees the stability of the implicit and explicit Euler integration methods. Then, we propose a novel system of ODEs, namely the Accelerated-Contracting-Nesterov flow, and use contraction theory to establish it is an optimization flow with exponential convergence rate, from which the linear convergence rate of its associated optimization algorithm is immediately established. Remarkably, a simple explicit Euler discretization of this flow corresponds to the Nesterov acceleration method. Finally, we present how our approach leads to performance guarantees in the design of optimization algorithms for time-varying optimization problems.},
  langid = {english},
  file = {/Users/sebastian/Zotero/storage/PESR2HCX/Cisneros-Velarde and Bullo - 2022 - A Contraction Theory Approach to Optimization Algorithms from Acceleration Flows.pdf}
}

@inproceedings{clarksonApproximatingCenterPoints1993,
  title = {Approximating Center Points with Iterated Radon Points},
  booktitle = {Proceedings of the Ninth Annual Symposium on {{Computational}} Geometry},
  author = {Clarkson, K. L. and Eppstein, David and Miller, Gary L. and Sturtivant, Carl and Teng, Shang-Hua},
  year = {1993},
  month = jul,
  series = {{{SCG}} '93},
  pages = {91--98},
  publisher = {Association for Computing Machinery},
  address = {New York, NY, USA},
  doi = {10.1145/160985.161004},
  urldate = {2024-11-06},
  abstract = {We describe a practical and provably good algorithm for approximating center points in any number of dimensions. Here c is a center point of a point set P in {$\mathbb{R}$}d if every closed halfspace containing c contains at least {\textbar}P{\textbar}/(d+1) points of P. Our algorithm has a small constant factor and is the first approximate center point algorithm whose complexity is subexponential in d. Moreover, it can be optimally parallelized to require O(log2 d loglog n) time. Our algorithm has been used in mesh partitioning methods, and has the potential to improve results in practice for constructing weak {$\varepsilon$}-nets and other geometric algorithms. We derive a variant of our algorithm with a time bound fully polynomial in d, and show how to combine our approach with previous techniques to compute high quality center points more quickly.},
  isbn = {978-0-89791-582-3},
  file = {/Users/sebastian/Zotero/storage/IR6VIVEG/Clarkson et al. - 1993 - Approximating center points with iterated radon points.pdf}
}

@inproceedings{cohen-addadFittingMetricsUltrametrics2022,
  title = {Fitting {{Metrics}} and {{Ultrametrics}} with {{Minimum Disagreements}}},
  booktitle = {2022 {{IEEE}} 63rd {{Annual Symposium}} on {{Foundations}} of {{Computer Science}} ({{FOCS}})},
  author = {{Cohen-Addad}, Vincent and Fan, Chenglin and Lee, Euiwoong and De Mesmay, Arnaud},
  year = {2022},
  month = oct,
  pages = {301--311},
  issn = {2575-8454},
  doi = {10.1109/FOCS54457.2022.00035},
  abstract = {Given x{\i}n({\textbackslash}mathbbR\_{\textbackslash}geqslant 0)(\_2{\textasciicircum}[n]) recording pairwise distances, the Metric Violation Distance problem asks to compute the {\textbackslash}ell{$_0$} distance between x and the metric cone; i.e., modify the minimum number of entries of x to make it a metric. Due to its large number of applications in various data analysis and optimization tasks, this problem has been actively studied recently. We present an O({\textbackslash}log n)-approximation algorithm for METRIC VIOLATION Distance, exponentially improving the previous best approximation ratio of O(OPT{\textasciicircum}1/3) of Fan, Raichel, and Van Buskirk [SODA, 2018]. Furthermore, a major strength of our algorithm is its simplicity and running time. We also study the related problem of Ultrametric Violation Distance, where the goal is to compute the {\textbackslash}ell{$_0$} distance to the cone of ultrametrics, and achieve a constant factor approximation algorithm. The ULTRAMETRIC VIOLATION DISTANCE problem can be regarded as an extension of the problem of fitting ultrametrics studied by Ailon and Charikar [SIAM J. Computing, 2011] and by Cohen-Addad, Das, Kipouridis, Parotsidis, and Thorup [FOCS, 2021] from {\textbackslash}ell{$_1$} norm to {\textbackslash}ell{$_0$} norm. We show that this problem can be favorably interpreted as an instance of CORRELATION CLUSTERING with an additional hierarchical structure, which we solve using a new O(1)-approximation algorithm for correlation clustering that has the structural property that it outputs a refinement of the optimum clusters. An algorithm satisfying such a property can be considered of independent interest. We also provide an O({\textbackslash}log n{\textbackslash}log{\textbackslash}log n) approximation algorithm for weighted instances. Finally, we investigate the complementary version of these problems where one aims at choosing a maximum number of entries of x forming an (ultra-)metric. In stark contrast with the minimization versions, we prove that these maximization versions are hard to approximate within any constant factor assuming the Unique Games Conjecture.},
  keywords = {Approximation,Approximation algorithms,Clustering algorithms,Correlation,Fitting,Games,Measurement,Metric Violation Distance,Minimization,Ultrametric},
  file = {/Users/sebastian/Zotero/storage/T73HWEQH/Cohen-Addad et al. - 2022 - Fitting Metrics and Ultrametrics with Minimum Disa.pdf}
}

@inproceedings{colemanLocalSearch2Approximation2CorrelationClustering2008,
  title = {A {{Local-Search}} 2-{{Approximation}} for 2-{{Correlation-Clustering}}},
  booktitle = {Algorithms - {{ESA}} 2008},
  author = {Coleman, Tom and Saunderson, James and Wirth, Anthony},
  year = {2008},
  series = {Lecture {{Notes}} in {{Computer Science}}},
  pages = {308--319},
  publisher = {Springer},
  address = {Berlin, Heidelberg},
  doi = {10.1007/978-3-540-87744-8_26},
  abstract = {CorrelationClustering is now an established problem in the algorithms and constrained clustering communities. With the requirement that at most two clusters be formed, the minimisation problem is related to the study of signed graphs in the social psychology community, and has applications in statistical mechanics and biological networks.},
  isbn = {978-3-540-87744-8},
  langid = {english},
  file = {/Users/sebastian/Zotero/storage/2Y2ZE4WC/Coleman et al. - 2008 - A Local-Search 2-Approximation for 2-Correlation-C.pdf}
}

@article{condonAlgorithmsSimpleStochastic1993,
  title = {On Algorithms for Simple Stochastic Games},
  author = {Condon, Anne},
  year = {1993},
  month = oct,
  journal = {Advances in Computational Complexity Theory},
  pages = {51--71},
  publisher = {American Mathematical Society},
  doi = {10.1090/dimacs/013/04},
  urldate = {2023-11-24},
  file = {/Users/sebastian/Zotero/storage/TQDRCCZI/Cai - 1993 - Advances in Computational Complexity Theory.pdf}
}

@article{condonComplexityStochasticGames1992,
  title = {The {{Complexity}} of {{Stochastic Games}}},
  author = {Condon, Anne},
  year = {1992},
  month = feb,
  journal = {Information and Computation},
  volume = {96},
  number = {2},
  pages = {203--224},
  issn = {0890-5401},
  doi = {10.1016/0890-5401(92)90048-K},
  urldate = {2023-11-24},
  abstract = {We consider the complexity of stochastic games---simple games of chance played by two players. We show that the problem of deciding which player has the greatest chance of winning the game is in the class NP {$\frown$} co-NP.},
  file = {/Users/sebastian/Zotero/storage/AXGMGD9U/Condon - 1992 - The complexity of stochastic games.pdf}
}

@book{cookCombinatorialOptimization1997,
  title = {Combinatorial {{Optimization}}},
  author = {Cook, William J. and Cunningham, William H. and Pulleyblank, William R. and Schrijver, Alexander},
  year = {1997},
  month = nov,
  edition = {1},
  publisher = {Wiley},
  doi = {10.1002/9781118033142},
  urldate = {2024-04-18},
  isbn = {978-0-471-55894-1 978-1-118-03314-2},
  langid = {english},
  file = {/Users/sebastian/Zotero/storage/HERALPLH/Graham et al. - WILEY-INTERSCIENCE SERIES IN DISCRETE MATHEMATICS .pdf}
}

@article{coriSandpileGroupDual2000,
  title = {On the {{Sandpile Group}} of {{Dual Graphs}}},
  author = {Cori, Robert and Rossin, Dominique},
  year = {2000},
  month = may,
  journal = {European Journal of Combinatorics},
  volume = {21},
  number = {4},
  pages = {447--459},
  issn = {0195-6698},
  doi = {10.1006/eujc.1999.0366},
  urldate = {2024-07-15},
  abstract = {The group of recurrent configurations in the sandpile model, introduced by Dhar , may be considered as a finite abelian group associated with any graph G; we call it the sandpile group of G. The aim of this paper is to prove that the sandpile group of planar graph is isomorphic to that of its dual. A combinatorial point of view on the subject is also developed.},
  file = {/Users/sebastian/Zotero/storage/CGEBLJ6L/Cori and Rossin - 2000 - On the Sandpile Group of Dual Graphs.pdf}
}

@book{cottleLinearComplementarityProblem2009,
  title = {The {{Linear Complementarity Problem}}},
  author = {Cottle, Richard W. and Pang, Jong-Shi and Stone, Richard E.},
  year = {2009},
  month = jan,
  series = {Classics in {{Applied Mathematics}}},
  publisher = {{Society for Industrial and Applied Mathematics}},
  doi = {10.1137/1.9780898719000},
  urldate = {2023-11-13},
  isbn = {978-0-89871-686-3},
  keywords = {algorithms,complementarity,equilibrium,matrices,optimization},
  file = {/Users/sebastian/Zotero/storage/WUL2XRUI/CottlePangStone2008.pdf}
}

@article{csehComplexityCakeCutting2020,
  title = {The {{Complexity}} of {{Cake Cutting}} with {{Unequal Shares}}},
  author = {Cseh, {\'A}gnes and Fleiner, Tam{\'a}s},
  year = {2020},
  month = jun,
  journal = {ACM Transactions on Algorithms},
  volume = {16},
  number = {3},
  pages = {29:1--29:21},
  issn = {1549-6325},
  doi = {10.1145/3380742},
  urldate = {2024-06-21},
  abstract = {An unceasing problem of our prevailing society is the fair division of goods. The problem of proportional cake cutting focuses on dividing a heterogeneous and divisible resource, the cake, among n players who value pieces according to their own measure function. The goal is to assign each player a not necessarily connected part of the cake that the player evaluates at least as much as her proportional share. In this article, we investigate the problem of proportional division with unequal shares, where each player is entitled to receive a predetermined portion of the cake. Our main contribution is threefold. First we present a protocol for integer demands, which delivers a proportional solution in fewer queries than all known protocols. By giving a matching lower bound, we then show that our protocol is asymptotically the fastest possible. Finally, we turn to irrational demands and solve the proportional cake cutting problem by reducing it to the same problem with integer demands only. All results remain valid in a highly general cake cutting model, which can be of independent interest.},
  keywords = {Cake cutting,fair division,proportional division,unequal shares},
  file = {/Users/sebastian/Zotero/storage/U3UC2VUM/Cseh and Fleiner - 2020 - The Complexity of Cake Cutting with Unequal Shares.pdf}
}

@book{cyganParameterizedAlgorithms2015,
  title = {Parameterized {{Algorithms}}},
  author = {Cygan, Marek and Fomin, Fedor V. and Kowalik, {\L}ukasz and Lokshtanov, Daniel and Marx, D{\'a}niel and Pilipczuk, Marcin and Pilipczuk, Micha{\l} and Saurabh, Saket},
  year = {2015},
  publisher = {Springer International Publishing},
  address = {Cham},
  doi = {10.1007/978-3-319-21275-3},
  urldate = {2024-11-21},
  copyright = {https://www.springernature.com/gp/researchers/text-and-data-mining},
  isbn = {978-3-319-21274-6 978-3-319-21275-3},
  langid = {english},
  file = {/Users/sebastian/Zotero/storage/WM45LW8V/Cygan et al. - 2015 - Parameterized Algorithms.pdf}
}

@incollection{czerwinskiUniversalTreesGrow2019,
  title = {Universal Trees Grow inside Separating Automata: {{Quasi-polynomial}} Lower Bounds for Parity Games},
  shorttitle = {Universal Trees Grow inside Separating Automata},
  booktitle = {Proceedings of the 2019 {{Annual ACM-SIAM Symposium}} on {{Discrete Algorithms}} ({{SODA}})},
  author = {Czerwi{\'n}ski, Wojciech and Daviaud, Laure and Fijalkow, Nathana{\"e}l and Jurdzi{\'n}ski, Marcin and Lazi{\'c}, Ranko and Parys, Pawe{\l}},
  year = {2019},
  month = jan,
  series = {Proceedings},
  pages = {2333--2349},
  publisher = {{Society for Industrial and Applied Mathematics}},
  doi = {10.1137/1.9781611975482.142},
  urldate = {2024-06-11},
  abstract = {Several distinct techniques have been proposed to design quasi-polynomial algorithms for solving parity games since the breakthrough result of Calude, Jain, Khoussainov, Li, and Stephan (2017): play summaries, progress measures and register games. We argue that all those techniques can be viewed as instances of the separation approach to solving parity games, a key technical component of which is constructing (explicitly or implicitly) an automaton that separates languages of words encoding plays that are (decisively) won by either of the two players. Our main technical result is a quasi-polynomial lower bound on the size of such separating automata that nearly matches the current best upper bounds. This forms a barrier that all existing approaches must overcome in the ongoing quest for a polynomial-time algorithm for solving parity games. The key and fundamental concept that we introduce and study is a universal ordered tree. The technical highlights are a quasi-polynomial lower bound on the size of universal ordered trees and a proof that every separating safety automaton has a universal tree hidden in its state space.},
  file = {/Users/sebastian/Zotero/storage/L7A4FXMW/Czerwiński et al. - 2019 - Universal trees grow inside separating automata Q.pdf}
}

@inproceedings{daiNewResultsSimple2009,
  title = {New {{Results}} on {{Simple Stochastic Games}}},
  booktitle = {Algorithms and {{Computation}}},
  author = {Dai, Decheng and Ge, Rong},
  year = {2009},
  pages = {1014--1023},
  publisher = {Springer},
  address = {Berlin, Heidelberg},
  doi = {10.1007/978-3-642-10631-6_102},
  abstract = {We study the problem of solving simple stochastic games, and give both an interesting new algorithm and a hardness result. We show a reduction from fine approximation of simple stochastic games to coarse approximation of a polynomial sized game, which can be viewed as an evidence showing the hardness to approximate the value of simple stochastic games. We also present a randomized algorithm that runs in \$\{{\textbackslash}tilde\{O\}\}({\textbackslash}sqrt\{{\textbar}V\_\{{\textbackslash}mbox\{R\}\}{\textbar}!\})\$time, where \${\textbar}V\_\{{\textbackslash}mbox\{R\}\}{\textbar}\$is the number of RANDOM vertices and \$\{{\textbackslash}tilde\{O\}\}\$ignores polynomial terms. This algorithm is the fastest known algorithm when \${\textbar}V\_\{{\textbackslash}mbox\{R\}\}{\textbar} = {\textbackslash}omega({\textbackslash}log n)\$and \${\textbar}V\_\{{\textbackslash}mbox\{R\}\}{\textbar} = o({\textbackslash}sqrt\{{\textbackslash}min\{{\textbar}V\_\{{\textbackslash}mbox\{min\}\}{\textbar}, {\textbar}V\_\{{\textbackslash}mbox\{max\}\}{\textbar}\}\})\$and it works for general (non-stopping) simple stochastic games.},
  isbn = {978-3-642-10631-6},
  langid = {english},
  keywords = {Main Lemma,Optimal Strategy,Outgoing Edge,Polynomial Time,Stochastic Game},
  file = {/Users/sebastian/Zotero/storage/XEGDYX2V/Dai and Ge - 2009 - New Results on Simple Stochastic Games.pdf}
}

@article{dangComplexityExpandedTarskis2018,
  title = {On the Complexity of an Expanded {{Tarski}}'s Fixed Point Problem under the Componentwise Ordering},
  author = {Dang, Chuangyin and Ye, Yinyu},
  year = {2018},
  month = jul,
  journal = {Theoretical Computer Science},
  volume = {732},
  pages = {26--45},
  issn = {0304-3975},
  doi = {10.1016/j.tcs.2018.04.021},
  urldate = {2025-01-15},
  abstract = {Let {$\Pi$} be a finite lattice of integer points in a box of Rn and f an increasing mapping in terms of the componentwise ordering from {$\Pi$} to itself. The well-known Tarski's fixed point theorem asserts that f has a fixed point in {$\Pi$}. A simple expansion of f from {$\Pi$} to a larger lattice C of integer points in a box of Rn yields that the smallest point in C is always a fixed point of f (an expanded Tarski's fixed point problem). By introducing an integer labeling rule and applying a cubic triangulation of the Euclidean space, we prove in this paper that the expanded Tarski's fixed point problem is in the class PPA when f is given as an oracle. It is shown in this paper that Nash equilibria of a bimatrix game can be reformulated as fixed points different from the smallest point in C of an increasing mapping from C to itself. This implies that the expanded Tarski's fixed point problem has at least the same complexity as that of the Nash equilibrium problem. As a byproduct, we also present a homotopy-like simplicial method to compute a Tarski fixed point of f. The method starts from an arbitrary lattice point and follows a finite simplicial path to a fixed point of f.},
  keywords = {Componentwise ordering,Fixed point,Increasing mapping,Integer labeling,Lattice,PPA,Simplicial method,Tarski's fixed point theorem,Triangulation},
  file = {/Users/sebastian/Zotero/storage/H552N53B/S0304397518302433.html}
}

@misc{dangComputationsComplexitiesTarski2020,
  title = {Computations and {{Complexities}} of {{Tarski}}'s {{Fixed Points}} and {{Supermodular Games}}},
  author = {Dang, Chuangyin and Qi, Qi and Ye, Yinyu},
  year = {2020},
  month = may,
  number = {arXiv:2005.09836},
  eprint = {2005.09836},
  primaryclass = {cs, econ},
  publisher = {arXiv},
  doi = {10.48550/arXiv.2005.09836},
  urldate = {2023-10-30},
  abstract = {We consider two models of computation for Tarski's order preserving function f related to fixed points in a complete lattice: the oracle function model and the polynomial function model. In both models, we find the first polynomial time algorithm for finding a Tarski's fixed point. In addition, we provide a matching oracle bound for determining the uniqueness in the oracle function model and prove it is Co-NP hard in the polynomial function model. The existence of the pure Nash equilibrium in supermodular games is proved by Tarski's fixed point theorem. Exploring the difference between supermodular games and Tarski's fixed point, we also develop the computational results for finding one pure Nash equilibrium and determining the uniqueness of the equilibrium in supermodular games.},
  archiveprefix = {arXiv},
  keywords = {Computer Science - Computational Complexity,Computer Science - Computer Science and Game Theory,Economics - Theoretical Economics},
  file = {/Users/sebastian/Zotero/storage/KZ5QLY8L/Dang et al. - 2020 - Computations and Complexities of Tarski's Fixed Po.pdf;/Users/sebastian/Zotero/storage/Q6YXW3Y5/2005.html}
}

@incollection{daskalakisContinuousLocalSearch2011,
  title = {Continuous {{Local Search}}},
  booktitle = {Proceedings of the 2011 {{Annual ACM-SIAM Symposium}} on {{Discrete Algorithms}} ({{SODA}})},
  author = {Daskalakis, Constantinos and Papadimitriou, Christos},
  year = {2011},
  month = jan,
  series = {Proceedings},
  pages = {790--804},
  publisher = {{Society for Industrial and Applied Mathematics}},
  doi = {10.1137/1.9781611973082.62},
  urldate = {2024-06-12},
  abstract = {We introduce CLS, for continuous local search, a class of polynomial-time checkable total functions that lies at the intersection of PPAD and PLS, and captures a particularly benign kind of local optimization in which the domain is continuous, as opposed to combinatorial, and the functions involved are continuous. We show that this class contains several well known intriguing problems which were heretofore known to lie in the intersection of PLS and PPAD but were otherwise unclassifiable: Finding fixpoints of contraction maps, the linear complementarity problem for P matrices, finding a stationary point of a low-degree polynomial objective, the simple stochastic games of Shapley and Condon, and finding a mixed Nash equilibrium in congestion, implicit congestion, and network coordination games. The last four problems belong to CCLS, for convex CLS, another subclass of PPAD {$\cap$} PLS seeking the componentwise local minimum of a componentwise convex function. It is open whether any or all of these problems are complete for the corresponding classes.},
  isbn = {978-0-89871-993-2},
  file = {/Users/sebastian/Zotero/storage/KRLHDTV6/Daskalakis and Papadimitriou - 2011 - Continuous Local Search.pdf}
}

@inproceedings{daskalakisConverseBanachFixed2018,
  title = {A Converse to {{Banach}}'s Fixed Point Theorem and Its {{CLS-completeness}}},
  booktitle = {Proceedings of the 50th {{Annual ACM SIGACT Symposium}} on {{Theory}} of {{Computing}}},
  author = {Daskalakis, Constantinos and Tzamos, Christos and Zampetakis, Manolis},
  year = {2018},
  month = jun,
  series = {{{STOC}} 2018},
  pages = {44--50},
  publisher = {Association for Computing Machinery},
  address = {New York, NY, USA},
  doi = {10.1145/3188745.3188968},
  urldate = {2024-06-20},
  abstract = {Banach's fixed point theorem for contraction maps has been widely used to analyze the convergence of iterative methods in non-convex problems. It is a common experience, however, that iterative maps fail to be globally contracting under the natural metric in their domain, making the applicability of Banach's theorem limited. We explore how generally we can apply Banach's fixed point theorem to establish the convergence of iterative methods when pairing it with carefully designed metrics. Our first result is a strong converse of Banach's theorem, showing that it is a universal analysis tool for establishing global convergence of iterative methods to unique fixed points, and for bounding their convergence rate. In other words, we show that, whenever an iterative map globally converges to a unique fixed point, there exists a metric under which the iterative map is contracting and which can be used to bound the number of iterations until convergence. We illustrate our approach in the widely used power method, providing a new way of bounding its convergence rate through contraction arguments. We next consider the computational complexity of Banach's fixed point theorem. Making the proof of our converse theorem constructive, we show that computing a fixed point whose existence is guaranteed by Banach's fixed point theorem is CLS-complete. We thus provide the first natural complete problem for the class CLS, which was defined in [DP11] to capture the complexity of problems such as P-matrix LCP, computing KKT-points, and finding mixed Nash equilibria in congestion and network coordination games.},
  isbn = {978-1-4503-5559-9},
  keywords = {Banach's Theorem,Bessaga's Theorem,CLS-completeness,contraction maps,power method},
  file = {/Users/sebastian/Zotero/storage/UKH5H4CE/Daskalakis et al. - 2018 - A converse to Banach's fixed point theorem and its.pdf}
}

@article{davydovNonEuclideanMonotoneOperator2024,
  title = {Non-{{Euclidean Monotone Operator Theory}} and {{Applications}}},
  author = {Davydov, Alexander and Jafarpour, Saber and Proskurnikov, Anton V. and Bullo, Francesco},
  year = {2024},
  journal = {Journal of Machine Learning Research},
  volume = {25},
  number = {307},
  pages = {1--33},
  issn = {1533-7928},
  urldate = {2025-01-15},
  abstract = {While monotone operator theory is often studied on Hilbert spaces, many interesting problems in machine learning and optimization arise naturally in finite-dimensional vector spaces endowed with non-Euclidean norms, such as diagonally-weighted {$\ell$}1{$\ell$}1{\textbackslash}ell\_\{1\} or {$\ell\infty\ell\infty\backslash$}ell\_\{{\textbackslash}infty\} norms. This paper provides a natural generalization of monotone operator theory to finite-dimensional non-Euclidean spaces. The key tools are weak pairings and logarithmic norms. We show that the resolvent and reflected resolvent operators of non-Euclidean monotone mappings exhibit similar properties to their counterparts in Hilbert spaces. Furthermore, classical iterative methods and splitting methods for finding zeros of monotone operators are shown to converge in the non-Euclidean case. We apply our theory to equilibrium computation and Lipschitz constant estimation of recurrent neural networks, obtaining novel iterations and tighter upper bounds via forward-backward splitting.},
  file = {/Users/sebastian/Zotero/storage/5ADFAILC/Davydov et al. - 2024 - Non-Euclidean Monotone Operator Theory and Applications.pdf}
}

@article{deloera2019mentionofbrouwer,
  title = {The Discrete yet Ubiquitous Theorems of {{Carath{\'e}odory, Helly, Sperner, Tucker, and Tverberg}}},
  author = {Loera, Jes{\'u}s A. De and Goaoc, Xavier and Meunier, Fr{\'e}d{\'e}ric and Mustafa, Nabil H.},
  year = {2019},
  journal = {Bulletin of the American Mathematical Society},
  volume = {56},
  pages = {415--511},
  doi = {10.1090/bull/1653}
}

@article{demontjoyeRecursiveAlgorithmSolving2021,
  title = {A {{Recursive Algorithm}} for {{Solving Simple Stochastic Games}}},
  author = {{de Montjoye}, Xavier Badin},
  year = {2021},
  publisher = {arXiv},
  doi = {10.48550/ARXIV.2110.01030},
  urldate = {2023-08-10},
  abstract = {We present two recursive strategy improvement algorithms for solving simple stochastic games. First we present an algorithm for solving SSGs of degree \$d\$ that uses at most \$O{\textbackslash}left({\textbackslash}left{\textbackslash}lfloor(d+1){\textasciicircum}2/2{\textbackslash}right{\textbackslash}rfloor{\textasciicircum}\{n/2\}{\textbackslash}right)\$ iterations, with \$n\$ the number of MAX vertices. Then, we focus on binary SSG and propose an algorithm that has complexity \$O{\textbackslash}left({$\varphi$}{\textasciicircum}nPoly(N){\textbackslash}right)\$ where \${$\varphi$}= (1 + {\textbackslash}sqrt\{5\})/2\$ is the golden ratio. To the best of our knowledge, this is the first deterministic strategy improvement algorithm that visits \$2{\textasciicircum}\{cn\}\$ strategies with \$c \&lt; 1\$.},
  copyright = {Creative Commons Attribution 4.0 International},
  keywords = {Computer Science and Game Theory (cs.GT),Data Structures and Algorithms (cs.DS),FOS: Computer and information sciences},
  file = {/Users/sebastian/Zotero/storage/3DHXF4FH/2110.01030.pdf}
}

@phdthesis{demontjoyeStrategyImprovementMethod,
  title = {Strategy Improvement Method for Solving Simple Stochastic Games},
  author = {{de Montjoye}, Xavier Badin},
  abstract = {A Stochastic Game is played by two players, MAX and MIN, by moving a token on a set of states. At each step, both players simultaneously choose an action which moves the token to a new state according to a probability distribution dependent on both actions. In addition, player MIN has to pay to player MAX a value depending on the new state. This continues until the token ends in a sink, in which case the game stops. Hence, this is a zero-sum game where MAX seeks to maximise its expected value gained during the game and MIN tries to minimise it. Those games were introduced by Shapley in 1953 who proved that there exists a pair of memoryless optimal strategies for the players and thus an optimal expected gain.},
  langid = {english},
  file = {/Users/sebastian/Zotero/storage/7J4GVIAS/de Montjoye - Strategy improvement method for solving simple sto.pdf}
}

@article{dengAlgorithmicSolutionsEnvyFree2012,
  title = {Algorithmic {{Solutions}} for {{Envy-Free Cake Cutting}}},
  author = {Deng, Xiaotie and Qi, Qi and Saberi, Amin},
  year = {2012},
  month = dec,
  journal = {Operations Research},
  volume = {60},
  number = {6},
  pages = {1461--1476},
  publisher = {INFORMS},
  issn = {0030-364X},
  doi = {10.1287/opre.1120.1116},
  urldate = {2024-05-03},
  abstract = {We study the problem of finding an envy-free allocation of a cake to d + 1 players using d cuts. Two models are considered, namely, the oracle-function model and the polynomial-time function model. In the oracle-function model, we are interested in the number of times an algorithm has to query the players about their preferences to find an allocation with the envy less than {$\epsilon$}. We derive a matching lower and upper bound of {\texttheta}(1/{$\epsilon$})d - 1 for players with Lipschitz utilities and any d {$>$} 1. In the polynomial-time function model, where the utility functions are given explicitly by polynomial-time algorithms, we show that the envy-free cake-cutting problem has the same complexity as finding a Brouwer's fixed point, or, more formally, it is PPAD-complete. On the flip side, for monotone utility functions, we propose a fully polynomial-time algorithm (FPTAS) to find an approximate envy-free allocation of a cake among three people using two cuts.},
  keywords = {cake cutting,envy-free,fair division,fixed point,FPTAS,PPAD},
  file = {/Users/sebastian/Zotero/storage/WNNNEEAV/Deng et al. - 2012 - Algorithmic Solutions for Envy-Free Cake Cutting.pdf}
}

@misc{dengComplexityEnvyFreeCake2009,
  title = {On the {{Complexity}} of {{Envy-Free Cake Cutting}}},
  author = {Deng, Xiaotie and Qi, Qi and Saberi, Amin},
  year = {2009},
  month = jul,
  number = {arXiv:0907.1334},
  eprint = {0907.1334},
  primaryclass = {cs},
  publisher = {arXiv},
  doi = {10.48550/arXiv.0907.1334},
  urldate = {2024-06-21},
  abstract = {We study the envy-free cake-cutting problem for \$d+1\$ players with \$d\$ cuts, for both the oracle function model and the polynomial time function model. For the former, we derive a \${\textbackslash}theta((\{1{\textbackslash}over{\textbackslash}epsilon\}){\textasciicircum}\{d-1\})\$ time matching bound for the query complexity of \$d+1\$ player cake cutting with Lipschitz utilities for any \$d{$>$} 1\$. When the utility functions are given by a polynomial time algorithm, we prove the problem to be PPAD-complete. For measurable utility functions, we find a fully polynomial-time algorithm for finding an approximate envy-free allocation of a cake among three people using two cuts.},
  archiveprefix = {arXiv},
  keywords = {Computer Science - Computer Science and Game Theory},
  file = {/Users/sebastian/Zotero/storage/ZWR4RPYD/Deng et al. - 2009 - On the Complexity of Envy-Free Cake Cutting.pdf;/Users/sebastian/Zotero/storage/FI3MI6SI/0907.html}
}

@misc{dippelOneRemainsSettle2023,
  title = {One n {{Remains}} to {{Settle}} the {{Tree Conjecture}}},
  author = {Dippel, Jack and Vetta, Adrian},
  year = {2023},
  month = oct,
  number = {arXiv:2310.08663},
  eprint = {2310.08663},
  primaryclass = {cs, math},
  urldate = {2024-03-11},
  abstract = {In the famous network creation game of Fabrikant et al. a set of agents play a game to build a connected graph. The \$n\$ agents form the vertex set \$V\$ of the graph and each vertex \$v{\textbackslash}in V\$ buys a set \$E\_v\$ of edges inducing a graph \$G=(V,{\textbackslash}bigcup{\textbackslash}limits\_\{v{\textbackslash}in V\} E\_v)\$. The private objective of each vertex is to minimize the sum of its building cost (the cost of the edges it buys) plus its connection cost (the total distance from itself to every other vertex). Given a cost of \${\textbackslash}alpha\$ for each individual edge, a long-standing conjecture, called the tree conjecture, states that if \${\textbackslash}alpha {$>$} n\$ then every Nash equilibrium graph in the game is a spanning tree. After a plethora of work, it is known that the conjecture holds for any \${\textbackslash}alpha{$>$}3n-3\$. In this paper we prove the tree conjecture holds for \${\textbackslash}alpha{$>$}2n\$. This reduces by half the open range for \${\textbackslash}alpha\$ with only \$[n, 2n)\$ remaining in order to settle the conjecture.},
  archiveprefix = {arXiv},
  file = {/Users/sebastian/Zotero/storage/HR45PBH9/Dippel and Vetta - 2023 - One n Remains to Settle the Tree Conjecture.pdf}
}

@article{disserExponentialLowerBound2023,
  title = {An Exponential Lower Bound for {{Zadeh}}'s Pivot Rule},
  author = {Disser, Yann and Friedmann, Oliver and Hopp, Alexander V.},
  year = {2023},
  month = may,
  journal = {Mathematical Programming},
  volume = {199},
  number = {1},
  pages = {865--936},
  issn = {1436-4646},
  doi = {10.1007/s10107-022-01848-x},
  urldate = {2024-03-17},
  abstract = {The question whether the Simplex Algorithm admits an efficient pivot rule remains one of the most important open questions in discrete optimization. While many natural, deterministic pivot rules are known to yield exponential running times, the random-facet rule was shown to have a subexponential running time. For a long time, Zadeh's rule remained the most prominent candidate for the first deterministic pivot rule with subexponential running time. We present a lower bound construction that shows that Zadeh's rule is in fact exponential in the worst case. Our construction is based on a close relation to the Strategy Improvement Algorithm for Parity Games and the Policy Iteration Algorithm for Markov Decision Processes, and we also obtain exponential lower bounds for Zadeh's rule in these contexts.},
  langid = {english},
  keywords = {68Q25,90C05,90C40,Lower bound,Markov decision processes,Parity games,Policy iteration,Simplex method,Strategy improvement,Zadeh's rule},
  file = {/Users/sebastian/Zotero/storage/JYM3BVL7/Disser et al. - 2023 - An exponential lower bound for Zadeh’s pivot rule.pdf}
}

@article{disserSimplexAlgorithmNPMighty2018,
  title = {The {{Simplex Algorithm Is NP-Mighty}}},
  author = {Disser, Yann and Skutella, Martin},
  year = {2018},
  month = nov,
  journal = {ACM Trans. Algorithms},
  volume = {15},
  number = {1},
  pages = {5:1--5:19},
  issn = {1549-6325},
  doi = {10.1145/3280847},
  urldate = {2024-07-15},
  abstract = {We show that the Simplex Method, the Network Simplex Method---both with Dantzig's original pivot rule---and the Successive Shortest Path Algorithm are NP-mighty. That is, each of these algorithms can be used to solve, with polynomial overhead, any problem in\&nbsp;NP implicitly during the algorithm's execution. This result casts a more favorable light on these algorithms' exponential worst-case running times. Furthermore, as a consequence of our approach, we obtain several novel hardness results. For example, for a given input to the Simplex Algorithm, deciding whether a given variable ever enters the basis during the algorithm's execution and determining the number of iterations needed are both NP-hard problems. Finally, we close a long-standing open problem in the area of network flows over time by showing that earliest arrival flows are NP-hard to obtain.},
  file = {/Users/sebastian/Zotero/storage/Y9WSHC9T/Disser and Skutella - 2018 - The Simplex Algorithm Is NP-Mighty.pdf}
}

@incollection{dohrauARRIVALZeroPlayerGraph2017,
  title = {{{ARRIVAL}}: {{A Zero-Player Graph Game}} in {{NP}} {$\cap$} {{coNP}}},
  shorttitle = {{{ARRIVAL}}},
  booktitle = {A {{Journey Through Discrete Mathematics}}: {{A Tribute}} to {{Ji{\v r}{\'i} Matou{\v s}ek}}},
  author = {Dohrau, J{\'e}r{\^o}me and G{\"a}rtner, Bernd and Kohler, Manuel and Matou{\v s}ek, Ji{\v r}{\'i} and Welzl, Emo},
  year = {2017},
  pages = {367--374},
  publisher = {Springer International Publishing},
  address = {Cham},
  doi = {10.1007/978-3-319-44479-6_14},
  urldate = {2023-11-13},
  abstract = {Suppose that a train is running along a railway network, starting from a designated origin, with the goal of reaching a designated destination. The network, however, is of a special nature: every time the train traverses a switch, the switch will change its position immediately afterwards. Hence, the next time the train traverses the same switch, the other direction will be taken, so that directions alternate with each traversal of the switch.},
  isbn = {978-3-319-44479-6},
  langid = {english},
  file = {/Users/sebastian/Zotero/storage/M3RUR6EK/Dohrau et al. - 2017 - ARRIVAL A Zero-Player Graph Game in NP ∩ coNP.pdf}
}

@article{doi:10.1137/0209017,
  title = {Voronoui Diagrams in \${{L}}\_1 ({{L}}\_{$\infty$})\$ Metrics with 2-Dimensional Storage Applications},
  author = {Lee, D. T. and Wong, C. K.},
  year = {1980},
  journal = {SIAM Journal on Computing},
  volume = {9},
  number = {1},
  eprint = {https://doi.org/10.1137/0209017},
  pages = {200--211},
  doi = {10.1137/0209017},
  abstract = {In this paper we study the problem of scheduling the read/write head movement to handle a batch of \$nI/O\$ requests in a 2-dimensional secondary storage device in minimum time. Two models of storage systems are assumed in which the access time of a record (being proportional to the ``distance'' between the position of the record and that of the read/write head) is measured in terms of \$L\_1 \$ and \$L\_{$\infty\$$} metrics, respectively. The scheduling problem, referred to as the Open Path Problem (OPP), is equivalent to finding a shortest Hamiltonian path with a specified end point in a complete graph with n vertices. We first show in this paper that there exists a natural isometry between the \$L\_1 \$ and \$L\_{$\infty\$$} metrics. Consequently, the existence of a polynomial time algorithm for the OPP in one metric implies the existence of a polynomial time algorithm for the same problem in the other metric. Based on a result by Garey, Graham and Johnson, it is easy to show that the OPP in \$L\_1 \$ (hence in \$L\_{$\infty\$$}) metric is \$NP\$-complete. A heuristic to solve the OPP is therefore presented. It is based on a geometric structure called the Voronoi diagram in \$L\_1 \$ metric. An optimal (worst-case) algorithm of time complexity \$O(nn)\$ for constructing the diagram for a set of n points in a plane is described. Using this diagram one can build a near-optimal path through each point either by constructing a minimum spanning tree or by the closest insertion method.Both algorithms are shown to take \$O(nn)\$ time which is the time for the construction of the diagram and yield an approximate solution within a factor of 2. The bound is also shown to be tight in the worse case. For the average case, simulation results show that the minimum spanning tree approach is better than the closest insertion method. As expected, they are far better than the sequential one in which the request is processed one at a time on the first-come--first-served basis.},
  file = {/Users/sebastian/Zotero/storage/C9C4SXCU/LEEr and Wong - VORONOI DIAGRAMS IN L1 (L) METRICS WITH 2-DIMENSIONAL STORAGE APPLICATIONS.pdf}
}

@book{dongKrasnoselskiiMannIterativeMethod2022,
  title = {The {{Krasnosel}}'ski{\u \i}-{{Mann Iterative Method}}: {{Recent Progress}} and {{Applications}}},
  shorttitle = {The {{Krasnosel}}'ski{\u \i}-{{Mann Iterative Method}}},
  author = {Dong, Qiao-Li and Cho, Yeol Je and He, Songnian and Pardalos, Panos M. and Rassias, Themistocles M.},
  year = {2022},
  series = {{{SpringerBriefs}} in {{Optimization}}},
  publisher = {Springer International Publishing},
  address = {Cham},
  doi = {10.1007/978-3-030-91654-1},
  urldate = {2024-06-11},
  copyright = {https://www.springer.com/tdm},
  isbn = {978-3-030-91653-4 978-3-030-91654-1},
  langid = {english},
  keywords = {Convex Optimization Problems,Krasnoselskii-Mann Iterative Method,Nonexpansive Mappings,Nonlinear Mappings,Optimization Algorithms},
  file = {/Users/sebastian/Zotero/storage/39D3S44R/Dong et al. - 2022 - The Krasnosel'skiĭ-Mann Iterative Method Recent P.pdf}
}

@misc{dongPolytopesBoundedIntegral2023,
  title = {Polytopes with {{Bounded Integral Slack Matrices Have Sub-Exponential Extension Complexity}}},
  author = {Dong, Sally and Rothvoss, Thomas},
  year = {2023},
  month = dec,
  number = {arXiv:2307.16159},
  eprint = {2307.16159},
  primaryclass = {cs, math},
  publisher = {arXiv},
  doi = {10.48550/arXiv.2307.16159},
  urldate = {2024-02-14},
  abstract = {We show that any bounded integral function \$f : A {\textbackslash}times B {\textbackslash}mapsto {\textbackslash}\{0,1, {\textbackslash}dots, {\textbackslash}Delta{\textbackslash}\}\$ with rank \$r\$ has deterministic communication complexity \${\textbackslash}Delta{\textasciicircum}\{O({\textbackslash}Delta)\} {\textbackslash}cdot {\textbackslash}sqrt\{r\} {\textbackslash}cdot {\textbackslash}log{\textasciicircum}2 r\$, where the rank of \$f\$ is defined to be the rank of the \$A {\textbackslash}times B\$ matrix whose entries are the function values. As a corollary, we show that any \$n\$-dimensional polytope that admits a slack matrix with entries from \${\textbackslash}\{0,1,{\textbackslash}dots,{\textbackslash}Delta{\textbackslash}\}\$ has extension complexity at most \${\textbackslash}exp({\textbackslash}Delta{\textasciicircum}\{O({\textbackslash}Delta)\} {\textbackslash}cdot {\textbackslash}sqrt\{n\} {\textbackslash}cdot {\textbackslash}log{\textasciicircum}2 n)\$.},
  archiveprefix = {arXiv},
  keywords = {Computer Science - Discrete Mathematics,Mathematics - Combinatorics},
  file = {/Users/sebastian/Zotero/storage/8JWFWUYJ/Dong and Rothvoss - 2023 - Polytopes with Bounded Integral Slack Matrices Hav.pdf;/Users/sebastian/Zotero/storage/DH2ALBPP/2307.html}
}

@inproceedings{durrApproximationAlgorithmExact2023,
  title = {An {{Approximation Algorithm}} for the {{Exact Matching Problem}} in {{Bipartite Graphs}}},
  booktitle = {Approximation, {{Randomization}}, and {{Combinatorial Optimization}}. {{Algorithms}} and {{Techniques}} ({{APPROX}}/{{RANDOM}} 2023)},
  author = {D{\"u}rr, Anita and El Maalouly, Nicolas and Wulf, Lasse},
  year = {2023},
  series = {Leibniz {{International Proceedings}} in {{Informatics}} ({{LIPIcs}})},
  volume = {275},
  pages = {18:1--18:21},
  publisher = {Schloss Dagstuhl -- Leibniz-Zentrum f{\"u}r Informatik},
  address = {Dagstuhl, Germany},
  issn = {1868-8969},
  doi = {10.4230/LIPIcs.APPROX/RANDOM.2023.18},
  urldate = {2023-09-21},
  isbn = {978-3-95977-296-9},
  keywords = {Approximation Algorithms,Bounded Color Matching,Exact Matching,Perfect Matching,Red-Blue Matching},
  file = {/Users/sebastian/Zotero/storage/5K24MNIS/Dürr et al. - 2023 - An Approximation Algorithm for the Exact Matching .pdf;/Users/sebastian/Zotero/storage/BMHYPNX8/18843.html}
}

@article{echeniqueShortConstructiveProof2005,
  title = {A Short and Constructive Proof of {{Tarski}}'s Fixed-Point Theorem},
  author = {Echenique, Federico},
  year = {2005},
  month = jun,
  journal = {International Journal of Game Theory},
  volume = {33},
  number = {2},
  pages = {215--218},
  publisher = {Springer Verlag},
  issn = {0020-7276},
  urldate = {2023-08-10},
  abstract = {I give short and constructive proofs of Tarski's fixed-point theorem, and of Zhou's extension of Tarski's fixed-point theorem to set-valued maps.},
  copyright = {other},
  langid = {english},
  file = {/Users/sebastian/Zotero/storage/DSR8UR8A/Echenique - 2005 - A short and constructive proof of Tarski’s fixed-p.pdf;/Users/sebastian/Zotero/storage/PYXLMXEG/20278.html}
}

@article{edmonds1965maximum,
  title = {Maximum Matching and a Polyhedron with 0, 1-Vertices},
  author = {Edmonds, Jack},
  year = {1965},
  journal = {Journal of Research of the National Bureau of Standards B},
  volume = {69},
  pages = {125--130},
  keywords = {blossom matching}
}

@article{edmondsPathsTreesFlowers1965,
  title = {Paths, {{Trees}}, and {{Flowers}}},
  author = {Edmonds, Jack},
  year = {1965},
  month = jan,
  journal = {Canadian Journal of Mathematics},
  volume = {17},
  pages = {449--467},
  issn = {0008-414X, 1496-4279},
  doi = {10.4153/CJM-1965-045-4},
  urldate = {2024-04-05},
  abstract = {A graph G for purposes here is a finite set of elements called vertices and a finite set of elements called edges such that each edge meets exactly two vertices, called the end-points of the edge. An edge is said to join its end-points.A matching in G is a subset of its edges such that no two meet the same vertex. We describe an efficient algorithm for finding in a given graph a matching of maximum cardinality. This problem was posed and partly solved by C. Berge; see Sections 3.7 and 3.8.},
  langid = {english},
  file = {/Users/sebastian/Zotero/storage/27H8L6Q2/Edmonds - 1965 - Paths, Trees, and Flowers.pdf}
}

@article{edwardsuRentalHarmonySperners1999,
  title = {Rental {{Harmony}}: {{Sperner}}'s {{Lemma}} in {{Fair Division}}},
  shorttitle = {Rental {{Harmony}}},
  author = {Edward Su, Francis},
  year = {1999},
  month = dec,
  journal = {The American Mathematical Monthly},
  volume = {106},
  number = {10},
  pages = {930--942},
  publisher = {Taylor \& Francis},
  issn = {0002-9890},
  doi = {10.1080/00029890.1999.12005142},
  urldate = {2024-04-26},
  file = {/Users/sebastian/Zotero/storage/B5279MNL/Edward Su - 1999 - Rental Harmony Sperner's Lemma in Fair Division.pdf}
}

@book{einsiedlerFunctionalAnalysisSpectral2017,
  title = {Functional {{Analysis}}, {{Spectral Theory}}, and {{Applications}}},
  author = {Einsiedler, Manfred and Ward, Thomas},
  year = {2017},
  series = {Graduate {{Texts}} in {{Mathematics}}},
  volume = {276},
  publisher = {Springer International Publishing},
  address = {Cham},
  doi = {10.1007/978-3-319-58540-6},
  urldate = {2024-12-02},
  copyright = {http://www.springer.com/tdm},
  isbn = {978-3-319-58539-0 978-3-319-58540-6},
  langid = {english},
  file = {/Users/sebastian/Zotero/storage/WHV2EEWA/Einsiedler and Ward - 2017 - Functional Analysis, Spectral Theory, and Applications.pdf}
}

@article{eisentrautValueIterationSimple2022,
  title = {Value Iteration for Simple Stochastic Games: {{Stopping}} Criterion and Learning Algorithm},
  shorttitle = {Value Iteration for Simple Stochastic Games},
  author = {Eisentraut, Julia and Kelmendi, Edon and K{\v r}et{\'i}nsk{\'y}, Jan and Weininger, Maximilian},
  year = {2022},
  month = may,
  journal = {Information and Computation},
  volume = {285},
  pages = {104886},
  issn = {08905401},
  doi = {10.1016/j.ic.2022.104886},
  urldate = {2023-09-09},
  langid = {english},
  file = {/Users/sebastian/Zotero/storage/PJZ8PIRG/main.pdf}
}

@inproceedings{elmaaloulyExactMatchingAlgorithms2023,
  title = {Exact {{Matching}}: {{Algorithms}} and {{Related Problems}}},
  shorttitle = {Exact {{Matching}}},
  booktitle = {40th {{International Symposium}} on {{Theoretical Aspects}} of {{Computer Science}} ({{STACS}} 2023)},
  author = {El Maalouly, Nicolas},
  year = {2023},
  publisher = {Schloss Dagstuhl -- Leibniz-Zentrum f{\"u}r Informatik},
  doi = {10.4230/LIPIcs.STACS.2023.29},
  urldate = {2024-09-25},
  abstract = {In 1982, Papadimitriou and Yannakakis introduced the Exact Matching (EM) problem where given an edge colored graph, with colors red and blue, and an integer k, the goal is to decide whether or not the graph contains a perfect matching with exactly k red edges. Although they conjectured it to be NP-complete, soon after it was shown to be solvable in randomized polynomial time in the seminal work of Mulmuley et al., placing it in the complexity class RP. Since then, all attempts at finding a deterministic algorithm for EM have failed, thus leaving it as one of the few natural combinatorial problems in RP but not known to be contained in P, and making it an interesting instance for testing the hypothesis RP = P. Progress has been lacking even on very restrictive classes of graphs despite the problem being quite well known as evidenced by the number of works citing it.  In this paper we aim to gain more insight into EM by studying a new optimization problem we call Top-k Perfect Matching (TkPM) which we show to be polynomially equivalent to EM. By virtue of being an optimization problem, it is more natural to approximate TkPM so we provide approximation algorithms for it. Some of the approximation algorithms rely on a relaxation of EM on bipartite graphs where the output is required to be a perfect matching with a number of red edges differing from k by at most k/2, which is of independent interest and generalizes to the Exact Weight Perfect Matching (EWPM) problem. We also consider parameterized algorithms and show that TkPM can be solved in FPT time parameterized by k and the independence number of the graph. This result again relies on new tools developed for EM which are also of independent interest.},
  copyright = {https://creativecommons.org/licenses/by/4.0/legalcode},
  langid = {english},
  file = {/Users/sebastian/Zotero/storage/FCL7E5AC/El Maalouly - 2023 - Exact Matching Algorithms and Related Problems.pdf}
}

@inproceedings{elmaaloulyExactMatchingCorrect2023,
  title = {Exact {{Matching}}: {{Correct Parity}} and {{FPT Parameterized}} by {{Independence Number}}},
  shorttitle = {Exact {{Matching}}},
  booktitle = {34th {{International Symposium}} on {{Algorithms}} and {{Computation}} ({{ISAAC}} 2023)},
  author = {El Maalouly, Nicolas and Steiner, Raphael and Wulf, Lasse},
  year = {2023},
  publisher = {Schloss Dagstuhl -- Leibniz-Zentrum f{\"u}r Informatik},
  doi = {10.4230/LIPIcs.ISAAC.2023.28},
  urldate = {2024-04-05},
  abstract = {Given an integer k and a graph where every edge is colored either red or blue, the goal of the exact matching problem is to find a perfect matching with the property that exactly k of its edges are red. Soon after Papadimitriou and Yannakakis (JACM 1982) introduced the problem, a randomized polynomial-time algorithm solving the problem was described by Mulmuley et al. (Combinatorica 1987). Despite a lot of effort, it is still not known today whether a deterministic polynomial-time algorithm exists. This makes the exact matching problem an important candidate to test the popular conjecture that the complexity classes P and RP are equal. In a recent article (MFCS 2022), progress was made towards this goal by showing that for bipartite graphs of bounded bipartite independence number, a polynomial time algorithm exists. In terms of parameterized complexity, this algorithm was an XP-algorithm parameterized by the bipartite independence number. In this article, we introduce novel algorithmic techniques that allow us to obtain an FPT-algorithm. If the input is a general graph we show that one can at least compute a perfect matching M which has the correct number of red edges modulo 2, in polynomial time. This is motivated by our last result, in which we prove that an FPT algorithm for general graphs, parameterized by the independence number, reduces to the problem of finding in polynomial time a perfect matching M with at most k red edges and the correct number of red edges modulo 2.},
  copyright = {https://creativecommons.org/licenses/by/4.0/legalcode},
  langid = {english},
  file = {/Users/sebastian/Zotero/storage/JITVKPFP/El Maalouly et al. - 2023 - Exact Matching Correct Parity and FPT Parameteriz.pdf}
}

@inproceedings{elmaaloulyExactMatchingGraphs2022,
  title = {Exact {{Matching}} in {{Graphs}} of {{Bounded Independence Number}}},
  booktitle = {47th {{International Symposium}} on {{Mathematical Foundations}} of {{Computer Science}} ({{MFCS}} 2022)},
  author = {El Maalouly, Nicolas and Steiner, Raphael},
  year = {2022},
  publisher = {Schloss Dagstuhl -- Leibniz-Zentrum f{\"u}r Informatik},
  doi = {10.4230/LIPIcs.MFCS.2022.46},
  urldate = {2024-04-05},
  abstract = {In the Exact Matching Problem (EM), we are given a graph equipped with a fixed coloring of its edges with two colors (red and blue), as well as a positive integer k. The task is then to decide whether the given graph contains a perfect matching exactly k of whose edges have color red. EM generalizes several important algorithmic problems such as perfect matching and restricted minimum weight spanning tree problems. When introducing the problem in 1982, Papadimitriou and Yannakakis conjectured EM to be NP-complete. Later however, Mulmuley et al. presented a randomized polynomial time algorithm for EM, which puts EM in RP. Given that to decide whether or not RP=P represents a big open challenge in complexity theory, this makes it unlikely for EM to be NP-complete, and in fact indicates the possibility of a deterministic polynomial time algorithm. EM remains one of the few natural combinatorial problems in RP which are not known to be contained in P, making it an interesting instance for testing the hypothesis RP=P.  Despite EM being quite well-known, attempts to devise deterministic polynomial algorithms have remained illusive during the last 40 years and progress has been lacking even for very restrictive classes of input graphs. In this paper we push the frontier of positive results forward by proving that EM can be solved in deterministic polynomial time for input graphs of bounded independence number, and for bipartite input graphs of bounded bipartite independence number. This generalizes previous positive results for complete (bipartite) graphs which were the only known results for EM on dense graphs.},
  copyright = {https://creativecommons.org/licenses/by/4.0/legalcode},
  langid = {english},
  file = {/Users/sebastian/Zotero/storage/AS7IJ62W/El Maalouly and Steiner - 2022 - Exact Matching in Graphs of Bounded Independence N.pdf}
}

@inproceedings{elmaaloulyExactMatchingProblem2024,
  title = {On the {{Exact Matching Problem}} in {{Dense Graphs}}},
  booktitle = {41st {{International Symposium}} on {{Theoretical Aspects}} of {{Computer Science}} ({{STACS}} 2024)},
  author = {El Maalouly, Nicolas and Haslebacher, Sebastian and Wulf, Lasse},
  year = {2024},
  publisher = {Schloss Dagstuhl -- Leibniz-Zentrum f{\"u}r Informatik},
  doi = {10.4230/LIPIcs.STACS.2024.33},
  urldate = {2024-09-02},
  abstract = {In the Exact Matching problem, we are given a graph whose edges are colored red or blue and the task is to decide for a given integer k, if there is a perfect matching with exactly k red edges. Since 1987 it is known that the Exact Matching Problem can be solved in randomized polynomial time. Despite numerous efforts, it is still not known today whether a deterministic polynomial-time algorithm exists as well. In this paper, we make substantial progress by solving the problem for a multitude of different classes of dense graphs. We solve the Exact Matching problem in deterministic polynomial time for complete r-partite graphs, for unit interval graphs, for bipartite unit interval graphs, for graphs of bounded neighborhood diversity, for chain graphs, and for graphs without a complete bipartite t-hole. We solve the problem in quasi-polynomial time for Erd{\H o}s-R{\'e}nyi random graphs G(n, 1/2). We also reprove an earlier result for bounded independence number/bipartite independence number. We use two main tools to obtain these results: A local search algorithm as well as a generalization of an earlier result by Karzanov.},
  copyright = {https://creativecommons.org/licenses/by/4.0/legalcode},
  langid = {english},
  file = {/Users/sebastian/Zotero/storage/W6X93W6M/El Maalouly et al. - 2024 - On the Exact Matching Problem in Dense Graphs.pdf}
}

@misc{elmaaloulyExactMatchingTopk2022,
  title = {Exact {{Matching}} and the {{Top-k Perfect Matching Problem}}},
  author = {El Maalouly, Nicolas and Wulf, Lasse},
  year = {2022},
  month = sep,
  number = {arXiv:2209.09661},
  eprint = {2209.09661},
  primaryclass = {cs},
  publisher = {arXiv},
  doi = {10.48550/arXiv.2209.09661},
  urldate = {2024-04-05},
  abstract = {The aim of this note is to provide a reduction of the Exact Matching problem to the Top-\$k\$ Perfect Matching Problem. Together with earlier work by El Maalouly, this shows that the two problems are polynomial-time equivalent. The Exact Matching Problem is a well-known 40 years old problem for which a randomized, but no deterministic poly-time algorithm has been discovered. The Top-\$k\$ Perfect Matching Problem is the problem of finding a perfect matching which maximizes the total weight of the \$k\$ heaviest edges contained in it.},
  archiveprefix = {arXiv},
  keywords = {Computer Science - Data Structures and Algorithms},
  file = {/Users/sebastian/Zotero/storage/3ZNZJF2Q/Maalouly and Wulf - 2022 - Exact Matching and the Top-k Perfect Matching Prob.pdf;/Users/sebastian/Zotero/storage/QENIEBK4/2209.html}
}

@inproceedings{elsnerBoundingComparingMethods2009,
  title = {Bounding and Comparing Methods for Correlation Clustering beyond {{ILP}}},
  booktitle = {Proceedings of the {{Workshop}} on {{Integer Linear Programming}} for {{Natural Langauge Processing}}},
  author = {Elsner, Micha and Schudy, Warren},
  year = {2009},
  month = jun,
  series = {{{ILP}} '09},
  pages = {19--27},
  publisher = {Association for Computational Linguistics},
  address = {USA},
  urldate = {2023-08-10},
  abstract = {We evaluate several heuristic solvers for correlation clustering, the NP-hard problem of partitioning a dataset given pairwise affinities between all points. We experiment on two practical tasks, document clustering and chat disentanglement, to which ILP does not scale. On these datasets, we show that the clustering objective often, but not always, correlates with external metrics, and that local search always improves over greedy solutions. We use semi-definite programming (SDP) to provide a tighter bound, showing that simple algorithms are already close to optimality.},
  isbn = {978-1-932432-35-0},
  file = {/Users/sebastian/Zotero/storage/2KM4RSFZ/Elsner and Schudy - 2009 - Bounding and comparing methods for correlation clu.pdf}
}

@article{eppsteinFindingShortestPaths1998,
  title = {Finding the k {{Shortest Paths}}},
  author = {Eppstein, David},
  year = {1998},
  month = jan,
  journal = {SIAM Journal on Computing},
  volume = {28},
  number = {2},
  pages = {652--673},
  publisher = {{Society for Industrial and Applied Mathematics}},
  issn = {0097-5397},
  doi = {10.1137/S0097539795290477},
  urldate = {2024-09-20},
  abstract = {It is proven that if the shortest paths on the surface of a convex polyhedron are grouped into equivalence classes according to the sequences of edges that they cross, then the resulting number of equivalence classes is \$O(n{\textasciicircum}\{4\})\$, where n is the number of vertices of the polyhedron. In fact, the more general result that any family of pseudosegments (a set of open simple curves on the plane such that two curves intersect each other in at most one point) lying on a planar subdivision defined by n other pseudosegments can give rise to at most \$O(n{\textasciicircum}\{4\})\$ edge sequences is also proven. This bound is shown to be asymptotically tight, by giving an example of a family of polyhedra with \${\textbackslash}Omega (n{\textasciicircum}\{4\})\$ shortest path equivalence classes.},
  file = {/Users/sebastian/Zotero/storage/WU8J28D7/Eppstein - 1998 - Finding the k Shortest Paths.pdf}
}

@article{erdosCombinatorialProblemGeometry1935,
  title = {A Combinatorial Problem in Geometry},
  author = {Erd{\"o}s, P. and Szekeres, G.},
  year = {1935},
  journal = {Compositio Mathematica},
  volume = {2},
  pages = {463--470},
  publisher = {Johnson Reprint Corporation},
  issn = {0010-437X},
  urldate = {2023-08-10},
  langid = {english},
  file = {/Users/sebastian/Zotero/storage/UEATYD2V/88611.html}
}

@article{erdosExtremumProblemsElementary1960,
  title = {On Some Extremum Problems in Elementary Geometry},
  author = {Erd{\H o}s, P and Szekeres, G},
  year = {1960},
  journal = {Ann. Univ. Sci. Budapest. E{\"o}tv{\"o}s Sect. Math},
  volume = {3--4},
  pages = {53--62},
  langid = {english},
  file = {/Users/sebastian/Zotero/storage/3MWRXEAQ/Erdős and Szekeres - ON SOME E X T R E M U M PROBLEMS IN E L E M E N T .pdf}
}

@article{erdosMoreProblemsElementary1978,
  title = {Some More Problems on Elementary Geometry},
  author = {Erd{\"o}s, Paul},
  year = {1978},
  journal = {Aust. Math. Soc. Gaz.},
  volume = {5},
  pages = {52--54}
}

@article{etessamiComplexityNashEquilibria2010,
  title = {On the {{Complexity}} of {{Nash Equilibria}} and {{Other Fixed Points}}},
  author = {Etessami, Kousha and Yannakakis, Mihalis},
  year = {2010},
  month = jan,
  journal = {SIAM Journal on Computing},
  volume = {39},
  number = {6},
  pages = {2531--2597},
  issn = {0097-5397, 1095-7111},
  doi = {10.1137/080720826},
  urldate = {2024-06-11},
  langid = {english},
  file = {/Users/sebastian/Zotero/storage/MA4UTC9S/Etessami and Yannakakis - 2010 - On the Complexity of Nash Equilibria and Other Fix.pdf}
}

@inproceedings{etessamiPolynomialTimeAlgorithms2012,
  title = {Polynomial {{Time Algorithms}} for {{Branching Markov Decision Processes}} and {{Probabilistic Min}}({{Max}}) {{Polynomial Bellman Equations}}},
  booktitle = {Automata, {{Languages}}, and {{Programming}}},
  author = {Etessami, Kousha and Stewart, Alistair and Yannakakis, Mihalis},
  year = {2012},
  pages = {314--326},
  publisher = {Springer},
  address = {Berlin, Heidelberg},
  doi = {10.1007/978-3-642-31594-7_27},
  abstract = {We show that one can approximate the least fixed point solution for a multivariate system of monotone probabilistic max (min) polynomial equations, in time polynomial in both the encoding size of the system of equations and in log(1/{$\varepsilon$}), where {$\varepsilon$}\,{$>$}\,0 is the desired additive error bound of the solution. (The model of computation is the standard Turing machine model.)},
  isbn = {978-3-642-31594-7},
  langid = {english},
  keywords = {Bellman Equation,Full Version,Markov Decision Process,Optimal Policy,Stochastic Game},
  file = {/Users/sebastian/Zotero/storage/HKZ9RKM4/Etessami et al. - 2012 - Polynomial Time Algorithms for Branching Markov De.pdf;/Users/sebastian/Zotero/storage/KU3FZTAS/Etessami et al. - 2012 - Polynomial Time Algorithms for Branching Markov De.pdf}
}

@article{etessamiRecursiveMarkovDecision2015,
  title = {Recursive {{Markov Decision Processes}} and {{Recursive Stochastic Games}}},
  author = {Etessami, Kousha and Yannakakis, Mihalis},
  year = {2015},
  month = may,
  journal = {Journal of the ACM},
  volume = {62},
  number = {2},
  pages = {11:1--11:69},
  issn = {0004-5411},
  doi = {10.1145/2699431},
  urldate = {2024-06-12},
  abstract = {We introduce Recursive Markov Decision Processes (RMDPs) and Recursive Simple Stochastic Games (RSSGs), which are classes of (finitely presented) countable-state MDPs and zero-sum turn-based (perfect information) stochastic games. They extend standard finite-state MDPs and stochastic games with a recursion feature. We study the decidability and computational complexity of these games under termination objectives for the two players: one player's goal is to maximize the probability of termination at a given exit, while the other player's goal is to minimize this probability. In the quantitative termination problems, given an RMDP (or RSSG) and probability p, we wish to decide whether the value of such a termination game is at least p (or at most p); in the qualitative termination problem we wish to decide whether the value is 1. The important 1-exit subclasses of these models, 1-RMDPs and 1-RSSGs, correspond in a precise sense to controlled and game versions of classic stochastic models, including multitype Branching Processes and Stochastic Context-Free Grammars, where the objective of the players is to maximize or minimize the probability of termination (extinction). We provide a number of upper and lower bounds for qualitative and quantitative termination problems for RMDPs and RSSGs. We show both problems are undecidable for multi-exit RMDPs, but are decidable for 1-RMDPs and 1-RSSGs. Specifically, the quantitative termination problem is decidable in PSPACE for both 1-RMDPs and 1-RSSGs, and is at least as hard as the square root sum problem, a well-known open problem in numerical computation. We show that the qualitative termination problem for 1-RMDPs (i.e., a controlled version of branching processes) can be solved in polynomial time both for maximizing and minimizing 1-RMDPs. The qualitative problem for 1-RSSGs is in NP {$\cap$} coNP, and is at least as hard as the quantitative termination problem for Condon's finite-state simple stochastic games, whose complexity remains a well known open problem. Finally, we show that even for 1-RMDPs, more general (qualitative and quantitative) model-checking problems with respect to linear-time temporal properties are undecidable even for a fixed property.},
  keywords = {Markov decision processes,multitype branching processes,Recursive stochastic processes,stochastic context-free grammars,stochastic games},
  file = {/Users/sebastian/Zotero/storage/3KZ9EF99/Etessami and Yannakakis - 2015 - Recursive Markov Decision Processes and Recursive .pdf}
}

@article{etessamiRecursiveStochasticGames2019,
  title = {Recursive Stochastic Games with Positive Rewards},
  author = {Etessami, Kousha and Wojtczak, Dominik and Yannakakis, Mihalis},
  year = {2019},
  month = jul,
  journal = {Theoretical Computer Science},
  volume = {777},
  pages = {308--328},
  issn = {03043975},
  doi = {10.1016/j.tcs.2018.12.018},
  urldate = {2023-09-09},
  langid = {english},
  file = {/Users/sebastian/Zotero/storage/RWU3G6S7/main.pdf}
}

@inproceedings{etessamiTarskiTheoremSupermodular2020,
  title = {Tarski's {{Theorem}}, {{Supermodular Games}}, and the {{Complexity}} of {{Equilibria}}},
  booktitle = {11th {{Innovations}} in {{Theoretical Computer Science Conference}} ({{ITCS}} 2020)},
  author = {Etessami, Kousha and Papadimitriou, Christos and Rubinstein, Aviad and Yannakakis, Mihalis},
  year = {2020},
  series = {Leibniz {{International Proceedings}} in {{Informatics}} ({{LIPIcs}})},
  volume = {151},
  pages = {18:1--18:19},
  publisher = {Schloss Dagstuhl--Leibniz-Zentrum fuer Informatik},
  address = {Dagstuhl, Germany},
  issn = {1868-8969},
  doi = {10.4230/LIPIcs.ITCS.2020.18},
  urldate = {2023-08-26},
  isbn = {978-3-95977-134-4},
  keywords = {computational complexity,fixed points,lattices,monotone functions,Nash equilibria,PLS,PPAD,stochastic,supermodular games,Tarski's theorem},
  file = {/Users/sebastian/Zotero/storage/4AKKVCQH/Etessami et al. - 2020 - Tarski’s Theorem, Supermodular Games, and the Comp.pdf;/Users/sebastian/Zotero/storage/J6FM42HM/1909.03210v1.pdf}
}

@article{farrellCoEulerianGraphs2016,
  title = {{{CoEulerian}} Graphs},
  author = {Farrell, Matthew and Levine, Lionel},
  year = {2016},
  month = jul,
  journal = {Proceedings of the American Mathematical Society},
  volume = {144},
  number = {7},
  pages = {2847--2860},
  issn = {0002-9939, 1088-6826},
  doi = {10.1090/proc/12952},
  urldate = {2024-07-15},
  abstract = {Advancing research. Creating connections.},
  langid = {english},
  keywords = {Chip-firing,critical group,Eulerian digraph,Laplacian lattice,oriented spanning tree,period vector,Pham index,sandpile group},
  file = {/Users/sebastian/Zotero/storage/X2F5N3VM/Farrell and Levine - 2016 - CoEulerian graphs.pdf}
}

@article{fearnleyComplexityGradientDescent2022,
  title = {The {{Complexity}} of {{Gradient Descent}}: {{CLS}} = {{PPAD}} {$\cap$} {{PLS}}},
  shorttitle = {The {{Complexity}} of {{Gradient Descent}}},
  author = {Fearnley, John and Goldberg, Paul and Hollender, Alexandros and Savani, Rahul},
  year = {2022},
  month = dec,
  journal = {Journal of the ACM},
  volume = {70},
  number = {1},
  pages = {7:1--7:74},
  issn = {0004-5411},
  doi = {10.1145/3568163},
  urldate = {2024-04-24},
  abstract = {We study search problems that can be solved by performing Gradient Descent on a bounded convex polytopal domain and show that this class is equal to the intersection of two well-known classes: PPAD and PLS. As our main underlying technical contribution, we show that computing a Karush-Kuhn-Tucker (KKT) point of a continuously differentiable function over the domain [0,1]2 is PPAD {$\cap$} PLS-complete. This is the first non-artificial problem to be shown complete for this class. Our results also imply that the class CLS (Continuous Local Search) -- which was defined by Daskalakis and Papadimitriou as a more ``natural'' counterpart to PPAD {$\cap$} PLS and contains many interesting problems -- is itself equal to PPAD {$\cap$} PLS.},
  keywords = {computational complexity,continuous optimization,TFNP},
  file = {/Users/sebastian/Zotero/storage/DHCL8UKW/Fearnley et al. - 2022 - The Complexity of Gradient Descent CLS = PPAD ∩ P.pdf}
}

@article{fearnleyFasterAlgorithmFinding2022,
  title = {A {{Faster Algorithm}} for {{Finding Tarski Fixed Points}}},
  author = {Fearnley, John and P{\'a}lv{\"o}lgyi, D{\"o}m{\"o}t{\"o}r and Savani, Rahul},
  year = {2022},
  month = jul,
  journal = {ACM Transactions on Algorithms},
  volume = {18},
  number = {3},
  pages = {1--23},
  issn = {1549-6325, 1549-6333},
  doi = {10.1145/3524044},
  urldate = {2023-08-10},
  abstract = {Dang et~al. have given an algorithm that can find a Tarski fixed point in a               k               -dimensional lattice of width               n               using               O               (log                                k                              n               ) queries~[               2               ]. Multiple authors have conjectured that this algorithm is optimal~[               2               ,               7               ], and indeed this has been proven for two-dimensional instances~[               7               ]. We show that these conjectures are false in dimension three or higher by giving an               O               (log               2               n               ) query algorithm for the three-dimensional Tarski problem. We also give a new decomposition theorem for               k               -dimensional Tarski problems which, in combination with our new algorithm for three dimensions, gives an               O               (log               2               {$\lceil$}k/3{$\rceil$}               n               ) query algorithm for the               k               -dimensional problem.},
  langid = {english},
  file = {/Users/sebastian/Zotero/storage/EN4VWQHC/Fearnley et al. - 2022 - A Faster Algorithm for Finding Tarski Fixed Points.pdf}
}

@inproceedings{fearnleyOrderedApproachSolving2017,
  title = {An Ordered Approach to Solving Parity Games in Quasi Polynomial Time and Quasi Linear Space},
  booktitle = {Proceedings of the 24th {{ACM SIGSOFT International SPIN Symposium}} on {{Model Checking}} of {{Software}}},
  author = {Fearnley, John and Jain, Sanjay and Schewe, Sven and Stephan, Frank and Wojtczak, Dominik},
  year = {2017},
  month = jul,
  series = {{{SPIN}} 2017},
  pages = {112--121},
  publisher = {Association for Computing Machinery},
  address = {New York, NY, USA},
  doi = {10.1145/3092282.3092286},
  urldate = {2024-06-11},
  abstract = {Parity games play an important role in model checking and synthesis. In their paper, Calude et al. have recently shown that these games can be solved in quasi-polynomial time. We show that their algorithm can be implemented efficiently: we use their data structure as a progress measure, allowing for a backward implementation instead of a complete unravelling of the game. To achieve this, a number of changes have to be made to their techniques, where the main one is to add power to the antagonistic player that allows for determining her rational move without changing the outcome of the game. We provide a first implementation for a quasi-polynomial algorithm, test it on small examples, and provide a number of side results, including minor algorithmic improvements, a quasi bi-linear complexity in the number of states and edges for a fixed number of colours, and matching lower bounds for the algorithm of Calude et al.},
  isbn = {978-1-4503-5077-8},
  keywords = {model checking games,parity games,synthesis},
  file = {/Users/sebastian/Zotero/storage/MBI9FRP5/Fearnley et al. - 2017 - An ordered approach to solving parity games in qua.pdf}
}

@article{fearnleyReachabilitySwitchingGames2021,
  title = {Reachability {{Switching Games}}},
  author = {Fearnley, John and Gairing, Martin and Mnich, Matthias and Savani, Rahul},
  year = {2021},
  month = apr,
  journal = {Logical Methods in Computer Science},
  volume = {Volume 17, Issue 2},
  publisher = {Episciences.org},
  issn = {1860-5974},
  doi = {10.23638/LMCS-17(2:10)2021},
  urldate = {2025-02-05},
  abstract = {We study the problem of deciding the winner of reachability switching games for zero-, one-, and two-player variants. Switching games provide a deterministic analogue of stochastic games. We show that the zero-player case is NL-hard, the one-player case is NP-complete, and that the two-player case is PSPACE-hard and in EXPTIME. For the zero-player case, we also show P-hardness for a succinctly-represented model that maintains the upper bound of NP \${\textbackslash}cap\$ coNP. For the one- and two-player cases, our results hold in both the natural, explicit model and succinctly-represented model. Our results show that the switching variant of a game is harder in complexity-theoretic terms than the corresponding stochastic version.},
  file = {/Users/sebastian/Zotero/storage/IPNJ6FSG/Fearnley et al. - 2021 - Reachability Switching Games.pdf}
}

@misc{fearnleySuperUniqueTarski2024,
  title = {Super {{Unique Tarski}} Is in {{UEOPL}}},
  author = {Fearnley, John and Savani, Rahul},
  year = {2024},
  month = nov,
  number = {arXiv:2411.05666},
  eprint = {2411.05666},
  primaryclass = {cs},
  publisher = {arXiv},
  urldate = {2024-11-12},
  abstract = {We define the Super-Unique-Tarski problem, which is a Tarski instance in which all slices are required to have a unique fixed point. We show that Super-Unique-Tarski lies in UEOPL under promise-preserving reductions.},
  archiveprefix = {arXiv},
  langid = {english},
  keywords = {Computer Science - Computational Complexity},
  file = {/Users/sebastian/Zotero/storage/V5HPL4XX/Fearnley and Savani - 2024 - Super Unique Tarski is in UEOPL.pdf}
}

@article{fearnleyUniqueEndPotential2020,
  title = {Unique {{End}} of {{Potential Line}}},
  author = {Fearnley, John and Gordon, Spencer and Mehta, Ruta and Savani, Rahul},
  year = {2020},
  month = dec,
  journal = {Journal of Computer and System Sciences},
  volume = {114},
  pages = {1--35},
  issn = {00220000},
  doi = {10.1016/j.jcss.2020.05.007},
  urldate = {2023-09-13},
  langid = {english},
  file = {/Users/sebastian/Zotero/storage/AEXNQB3N/main.pdf}
}

@inproceedings{fennerBipartitePerfectMatching2016,
  title = {Bipartite Perfect Matching Is in Quasi-{{NC}}},
  booktitle = {Proceedings of the Forty-Eighth Annual {{ACM}} Symposium on {{Theory}} of {{Computing}}},
  author = {Fenner, Stephen and Gurjar, Rohit and Thierauf, Thomas},
  year = {2016},
  month = jun,
  series = {{{STOC}} '16},
  pages = {754--763},
  publisher = {Association for Computing Machinery},
  address = {New York, NY, USA},
  doi = {10.1145/2897518.2897564},
  urldate = {2024-04-05},
  abstract = {We show that the bipartite perfect matching problem is in quasi- NC2. That is, it has uniform circuits of quasi-polynomial size nO(logn), and O(log2 n) depth. Previously, only an exponential upper bound was known on the size of such circuits with poly-logarithmic depth. We obtain our result by an almost complete derandomization of the famous Isolation Lemma when applied to yield an efficient randomized parallel algorithm for the bipartite perfect matching problem.},
  isbn = {978-1-4503-4132-5},
  keywords = {Derandomization,Graph Matching,Parallel complexity,quasi-NC},
  file = {/Users/sebastian/Zotero/storage/TWEAHDBJ/Fenner et al. - 2016 - Bipartite perfect matching is in quasi-NC.pdf}
}

@article{fennerDeterministicParallelAlgorithm2019,
  title = {A Deterministic Parallel Algorithm for Bipartite Perfect Matching},
  author = {Fenner, Stephen and Gurjar, Rohit and Thierauf, Thomas},
  year = {2019},
  month = feb,
  journal = {Communications of the ACM},
  volume = {62},
  number = {3},
  pages = {109--115},
  issn = {0001-0782},
  doi = {10.1145/3306208},
  urldate = {2024-02-21},
  abstract = {A fundamental quest in the theory of computing is to understand the power of randomness. It is not known whether every problem with an efficient randomized algorithm also has one that does not use randomness. One of the extensively studied problems under this theme is that of perfect matching. The perfect matching problem has a randomized parallel (NC) algorithm based on the Isolation Lemma of Mulmuley, Vazirani, and Vazirani. It is a long-standing open question whether this algorithm can be derandomized. In this article, we give an almost complete derandomization of the Isolation Lemma for perfect matchings in bipartite graphs. This gives us a deterministic parallel (quasi-NC) algorithm for the bipartite perfect matching problem. Derandomization of the Isolation Lemma means that we deterministically construct a weight assignment so that the minimum weight perfect matching is unique. We present three different ways of doing this construction with a common main idea.},
  file = {/Users/sebastian/Zotero/storage/GEPZ5B26/Fenner et al. - 2019 - A deterministic parallel algorithm for bipartite p.pdf}
}

@article{fleinerFixedPointApproachStable2003,
  title = {A {{Fixed-Point Approach}} to {{Stable Matchings}} and {{Some Applications}}},
  author = {Fleiner, Tam{\'a}s},
  year = {2003},
  journal = {Mathematics of Operations Research},
  volume = {28},
  number = {1},
  eprint = {4126993},
  eprinttype = {jstor},
  pages = {103--126},
  publisher = {INFORMS},
  issn = {0364-765X},
  urldate = {2025-01-15},
  abstract = {We describe a fixed-point based approach to the theory of bipartite stable matchings. By this, we provide a common framework that links together seemingly distant results, like the stable marriage theorem of Gale and Shapley, the Mendelsohn-Dulmage theorem, the Kundu-Lawler theorem, Tarski's fixed-point theorem, the Cantor-Bernstein theorem, Pym's linking theorem, or the monochromatic path theorem of Sands et al. In this framework, we formulate a matroid-generalization of the stable marriage theorem and study the lattice structure of generalized stable matchings. Based on the theory of lattice polyhedra and blocking polyhedra, we extend results of Vande Vate and Rothblum on the bipartite stable matching polytope.}
}

@inproceedings{flemingBlackBoxPPPNot2024a,
  title = {Black-{{Box PPP Is Not Turing-Closed}}},
  booktitle = {Proceedings of the 56th {{Annual ACM Symposium}} on {{Theory}} of {{Computing}}},
  author = {Fleming, Noah and Grosser, Stefan and Pitassi, Toniann and Robere, Robert},
  year = {2024},
  month = jun,
  series = {{{STOC}} 2024},
  pages = {1405--1414},
  publisher = {Association for Computing Machinery},
  address = {New York, NY, USA},
  doi = {10.1145/3618260.3649769},
  urldate = {2025-01-16},
  abstract = {The complexity class PPP contains all total search problems many-one reducible to the Pigeon problem, where we are given a succinct encoding of a function mapping n+1 pigeons to n holes, and must output two pigeons that collide in a hole.  PPP is one of the ``original five'' syntactically-defined subclasses of TFNP, and has been extensively studied due to the strong connections between its defining problem --- the pigeonhole principle --- and problems in cryptography, extremal combinatorics, proof complexity, and other fields.  However, despite its importance, PPP appears to be less robust than the other important TFNP subclasses.  In particular, unlike all other major TFNP subclasses, it was conjectured by Buss and Johnson that PPP is not closed under Turing reductions, and they called for a black-box separation in order to provide evidence for this conjecture. The question of whether PPP contains its Turing closure was further highlighted by Daskalakis in his recent IMU Abacus Medal Lecture.   In this work we prove that PPP is indeed not Turing-closed in the black-box setting, affirmatively resolving the above conjecture and providing strong evidence that PPP is not Turing-closed. In fact, we are able to separate PPP from its non-adaptive Turing closure, in which all calls to the Pigeon oracle must be made in parallel. This differentiates PPP from all other important TFNP subclasses, and especially from its closely-related subclass PWPP --- defined by reducibility to the weak pigeonhole principle --- which is known to be non-adaptively Turing-closed.  Our proof requires developing new tools for PPP lower bounds, and creates new connections between PPP and the theory of pseudoexpectation operators used for Sherali-Adams and Sum-of-Squares lower bounds.  In particular, we introduce a new type of pseudoexpectation operator that is precisely tailored for lower bounds against black-box PPP, which may be of independent interest.},
  isbn = {9798400703836},
  file = {/Users/sebastian/Zotero/storage/JQGET4NS/Fleming et al. - 2024 - Black-Box PPP Is Not Turing-Closed.pdf}
}

@article{floydAlgorithm97Shortest1962,
  title = {Algorithm 97: {{Shortest}} Path},
  shorttitle = {Algorithm 97},
  author = {Floyd, Robert W.},
  year = {1962},
  month = jun,
  journal = {Communications of the ACM},
  volume = {5},
  number = {6},
  pages = {345},
  issn = {0001-0782},
  doi = {10.1145/367766.368168},
  urldate = {2024-04-05},
  file = {/Users/sebastian/Zotero/storage/53RJBFJ6/Floyd - 1962 - Algorithm 97 Shortest path.pdf}
}

@article{fominDetoursDirectedGraphs2023,
  title = {Detours in Directed Graphs},
  author = {Fomin, Fedor V. and Golovach, Petr A. and Lochet, William and Sagunov, Danil and Saurabh, Saket and Simonov, Kirill},
  year = {2023},
  month = nov,
  journal = {Journal of Computer and System Sciences},
  volume = {137},
  pages = {66--86},
  issn = {00220000},
  doi = {10.1016/j.jcss.2023.05.001},
  urldate = {2024-11-21},
  langid = {english},
  file = {/Users/sebastian/Zotero/storage/9R3LQJP9/Fomin et al. - 2023 - Detours in directed graphs.pdf}
}

@article{fominLongDirectedStpath2018,
  title = {Long Directed (s,t)-Path: {{FPT}} Algorithm},
  shorttitle = {Long Directed (s,t)-Path},
  author = {Fomin, Fedor V. and Lokshtanov, Daniel and Panolan, Fahad and Saurabh, Saket and Zehavi, Meirav},
  year = {2018},
  month = dec,
  journal = {Information Processing Letters},
  volume = {140},
  pages = {8--12},
  issn = {00200190},
  doi = {10.1016/j.ipl.2018.04.018},
  urldate = {2024-11-21},
  langid = {english},
  file = {/Users/sebastian/Zotero/storage/LRJPT4M7/Fomin et al. - 2018 - Long directed (s,t)-path FPT algorithm.pdf}
}

@article{foniokPivotingLinearComplementarity2009,
  title = {Pivoting in {{Linear Complementarity}}: {{Two~Polynomial-Time Cases}}},
  shorttitle = {Pivoting in {{Linear Complementarity}}},
  author = {Foniok, Jan and Fukuda, Komei and G{\"a}rtner, Bernd and L{\"u}thi, Hans-Jakob},
  year = {2009},
  month = sep,
  journal = {Discrete \& Computational Geometry},
  volume = {42},
  number = {2},
  pages = {187--205},
  issn = {1432-0444},
  doi = {10.1007/s00454-009-9182-2},
  urldate = {2024-07-18},
  abstract = {We study the behavior of simple principal pivoting methods for the P-matrix linear complementarity problem (P-LCP). We solve an open problem of Morris by showing that Murty's least-index pivot rule (under any fixed index order) leads to a quadratic number of iterations on Morris's highly cyclic P-LCP examples. We then show that on K-matrix LCP instances, all pivot rules require only a linear number of iterations. As the main tool, we employ unique-sink orientations of cubes, a useful combinatorial abstraction of the P-LCP.},
  langid = {english},
  keywords = {Computational complexity,K-matrix,Linear complementarity,P-matrix,Pivoting algorithm,Unique-sink orientation},
  file = {/Users/sebastian/Zotero/storage/8ZVZLPW6/Foniok et al. - 2009 - Pivoting in Linear Complementarity Two Polynomial.pdf}
}

@article{fortuneDirectedSubgraphHomeomorphism1980,
  title = {The Directed Subgraph Homeomorphism Problem},
  author = {Fortune, Steven and Hopcroft, John and Wyllie, James},
  year = {1980},
  month = feb,
  journal = {Theoretical Computer Science},
  volume = {10},
  number = {2},
  pages = {111--121},
  issn = {0304-3975},
  doi = {10.1016/0304-3975(80)90009-2},
  urldate = {2024-11-21},
  abstract = {The set of pattern graphs for which the fixed directed subgraph homeomorphism problem is NP-complete is characterized. A polynomial time algorithm is given for the remaining cases. The restricted problem where the input graph is a directed acyclic graph is in polynomial time for all pattern graphs and an algorithm is given.},
  file = {/Users/sebastian/Zotero/storage/KF82WCG5/Fortune et al. - 1980 - The directed subgraph homeomorphism problem.pdf}
}

@article{friedlBlackBoxComplexitySperner2009,
  title = {On the {{Black-Box Complexity}} of {{Sperner}}'s {{Lemma}}},
  author = {Friedl, Katalin and Ivanyos, G{\'a}bor and Santha, Miklos and Verhoeven, Yves F.},
  year = {2009},
  month = oct,
  journal = {Theory of Computing Systems},
  volume = {45},
  number = {3},
  pages = {629--646},
  issn = {1432-4350, 1433-0490},
  doi = {10.1007/s00224-008-9121-2},
  urldate = {2024-03-11},
  langid = {english},
  file = {/Users/sebastian/Zotero/storage/L5TP8SCG/s00224-008-9121-2.pdf}
}

@inproceedings{friedrichCoverTimeDeterministic2010,
  title = {The {{Cover Time}} of {{Deterministic Random Walks}}},
  booktitle = {Computing and {{Combinatorics}}},
  author = {Friedrich, Tobias and Sauerwald, Thomas},
  year = {2010},
  pages = {130--139},
  publisher = {Springer},
  address = {Berlin, Heidelberg},
  doi = {10.1007/978-3-642-14031-0_16},
  abstract = {The rotor router model is a popular deterministic analogue of a random walk on a graph. Instead of moving to a random neighbor, the neighbors are served in a fixed order. We examine how fast this ``deterministic random walk'' covers all vertices (or all edges). We present general techniques to derive upper bounds for the vertex and edge cover time and derive matching lower bounds for several important graph classes. Depending on the topology, the deterministic random walk can be asymptotically faster, slower or equally fast compared to the classical random walk.},
  isbn = {978-3-642-14031-0},
  langid = {english},
  file = {/Users/sebastian/Zotero/storage/XTDCJE72/Friedrich and Sauerwald - 2010 - The Cover Time of Deterministic Random Walks.pdf}
}

@article{galluccioTheoryPfaffianOrientations1999,
  title = {On the {{Theory}} of {{Pfaffian Orientations}}. {{I}}. {{Perfect Matchings}} and {{Permanents}}},
  author = {Galluccio, Anna and Loebl, Martin},
  year = {1999},
  journal = {The Electronic Journal of Combinatorics},
  pages = {R6-R6},
  issn = {1077-8926},
  doi = {10.37236/1438},
  urldate = {2024-04-05},
  abstract = {Kasteleyn stated that the generating function of the perfect matchings of a graph of genus ggg may be written as a linear combination of 4g4g4{\textasciicircum}g Pfaffians. Here we prove this statement. As a consequence we present a combinatorial way to compute the permanent of a square matrix.},
  copyright = {Copyright (c)},
  langid = {english},
  file = {/Users/sebastian/Zotero/storage/ENYL94EH/Galluccio and Loebl - 1999 - On the Theory of Pfaffian Orientations. I. Perfect.pdf}
}

@article{ganianSolvingIntegerLinear2019,
  title = {Solving {{Integer Linear Programs}} by {{Exploiting Variable-Constraint Interactions}}: {{A Survey}}},
  shorttitle = {Solving {{Integer Linear Programs}} by {{Exploiting Variable-Constraint Interactions}}},
  author = {Ganian, Robert and Ordyniak, Sebastian},
  year = {2019},
  month = nov,
  journal = {Algorithms},
  volume = {12},
  number = {12},
  pages = {248},
  issn = {1999-4893},
  doi = {10.3390/a12120248},
  urldate = {2023-08-10},
  abstract = {Integer Linear Programming (ILP) is among the most successful and general paradigms for solving computationally intractable optimization problems in computer science. ILP is NP-complete, and until recently we have lacked a systematic study of the complexity of ILP through the lens of variable-constraint interactions. This changed drastically in recent years thanks to a series of results that together lay out a detailed complexity landscape for the problem centered around the structure of graphical representations of instances. The aim of this survey is to summarize these recent developments, put them into context and a unified format, and make them more approachable for experts from many diverse backgrounds.},
  langid = {english},
  file = {/Users/sebastian/Zotero/storage/4R7XXFNS/Ganian and Ordyniak - 2019 - Solving Integer Linear Programs by Exploiting Vari.pdf}
}

@inproceedings{gartnerARRIVALNextStop2018,
  title = {{{ARRIVAL}}: {{Next Stop}} in {{CLS}}},
  shorttitle = {{{ARRIVAL}}},
  booktitle = {45th {{International Colloquium}} on {{Automata}}, {{Languages}}, and {{Programming}} ({{ICALP}} 2018)},
  author = {G{\"a}rtner, Bernd and Hansen, Thomas Dueholm and Hub{\'a}cek, Pavel and Kr{\'a}l, Karel and Mosaad, Hagar and Sl{\'i}vov{\'a}, Veronika},
  year = {2018},
  series = {Leibniz {{International Proceedings}} in {{Informatics}} ({{LIPIcs}})},
  volume = {107},
  pages = {60:1--60:13},
  publisher = {Schloss Dagstuhl--Leibniz-Zentrum fuer Informatik},
  address = {Dagstuhl, Germany},
  issn = {1868-8969},
  doi = {10.4230/LIPIcs.ICALP.2018.60},
  urldate = {2023-09-20},
  isbn = {978-3-95977-076-7},
  keywords = {CLS,switch graphs,UP n coUP,zero-player game},
  file = {/Users/sebastian/Zotero/storage/VGEWQJ37/Gärtner et al. - 2018 - ARRIVAL Next Stop in CLS.pdf;/Users/sebastian/Zotero/storage/XZCBN6I6/9064.html}
}

@article{gartnerRandomFacetSimplex2002,
  title = {The {{Random}}-{{Facet}} Simplex Algorithm on Combinatorial Cubes},
  author = {G{\"a}rtner, Bernd},
  year = {2002},
  month = may,
  journal = {Random Structures \& Algorithms},
  volume = {20},
  number = {3},
  pages = {353--381},
  issn = {1042-9832, 1098-2418},
  doi = {10.1002/rsa.10034},
  urldate = {2024-03-17},
  abstract = {Abstract                            The R               ANDOM               -F               ACET               algorithm is a randomized variant of the simplex method which is known to solve any linear program with               n               variables and               m               constraints using an expected number of pivot steps which is               subexponential               in both               n               and               m.               This is the theoretically fastest simplex algorithm known to date if               m {$\approx$} n;               it provably beats most of the classical deterministic variants which require exp({\textohm}(               n               )) pivot steps in the worst case. R               ANDOM               -F               ACET               has independently been discovered and analyzed ten years ago by Kalai as a variant of the primal simplex method, and by Matou{\u s}ek, Sharir, and Welzl in a dual form. The essential ideas and results connected to R               ANDOM               -F               ACET               can be presented in a particularly simple and instructive way for the case of linear programs over               combinatorial               n               -               cubes.               I derive an explicit upper bound of                              on the expected number of pivot steps in this case, using a new technique of ``fingerprinting'' pivot steps. This bound also holds for               generalized               linear programs, similar flavors of which have been introduced and studied by several researchers. I then review an interesting class of generalized linear programs, due to Matou{\u s}ek, showing that R               ANDOM               -F               ACET               may indeed require an expected number of                                \${\textbackslash}exp {\textbackslash}bigl({\textbackslash}Omega{\textbackslash}bigl({\textbackslash}sqrt n{\textbackslash}bigr){\textbackslash}bigr)\$                                               pivot steps in the worst case. The main new result of the paper is a proof that all actual linear programs in Matou{\u s}ek's class are solved by R               ANDOM               -F               ACET               with an expected polynomial number of                                \$O {\textbackslash}bigl(n{\textasciicircum}2 {\textbackslash}bigr)\$                                               pivot steps. This proof exploits a combinatorial property of linear programming which has only recently been discovered by Holt and Klee. The result establishes the first scenario in which an algorithm that works for generalized linear programs ``recognizes'' proper linear programs. Thus, despite Matou{\u s}ek's worst-case result, the question remains open whether R               ANDOM               -F               ACET               (or any other simplex variant) is a polynomial-time algorithm for linear programming. Finally, I briefly discuss extensions of the combinatorial cube results to the general case. {\copyright} 2002 Wiley Periodicals, Inc. Random Struct. Alg., 20:353--381, 2002},
  langid = {english},
  file = {/Users/sebastian/Zotero/storage/UH3JNZNS/Gärtner - 2002 - The Random‐Facet simplex algorithm on combinatoria.pdf}
}

@inproceedings{gartnerSimpleStochasticGames2005,
  title = {Simple {{Stochastic Games}} and {{P-Matrix Generalized Linear Complementarity Problems}}},
  booktitle = {Fundamentals of {{Computation Theory}}},
  author = {G{\"a}rtner, Bernd and R{\"u}st, Leo},
  year = {2005},
  series = {Lecture {{Notes}} in {{Computer Science}}},
  pages = {209--220},
  publisher = {Springer},
  address = {Berlin, Heidelberg},
  doi = {10.1007/11537311_19},
  abstract = {We show that the problem of finding optimal strategies for both players in a simple stochastic game reduces to the generalized linear complementarity problem (GLCP) with a P-matrix, a well-studied problem whose hardness would imply NP = co--NP. This makes the rich GLCP theory and numerous existing algorithms available for simple stochastic games. As a special case, we get a reduction from binary simple stochastic games to the P-matrix linear complementarity problem (LCP).},
  isbn = {978-3-540-31873-6},
  langid = {english},
  keywords = {Average Vertex,Linear Complementarity Problem,Outgoing Edge,Principal Submatrix,Stochastic Game},
  file = {/Users/sebastian/Zotero/storage/ERCFZ6JB/Gärtner and Rüst - 2005 - Simple Stochastic Games and P-Matrix Generalized L.pdf}
}

@article{gartnerSubexponentialAlgorithmAbstract1995,
  title = {A {{Subexponential Algorithm}} for {{Abstract Optimization Problems}}},
  author = {G{\"a}rtner, Bernd},
  year = {1995},
  month = oct,
  journal = {SIAM Journal on Computing},
  volume = {24},
  number = {5},
  pages = {1018--1035},
  issn = {0097-5397, 1095-7111},
  doi = {10.1137/S0097539793250287},
  urldate = {2023-08-10},
  langid = {english},
  file = {/Users/sebastian/Zotero/storage/KAYVQ8XE/Gärtner - 1995 - A Subexponential Algorithm for Abstract Optimizati.pdf}
}

@inproceedings{gartnerSubexponentialAlgorithmARRIVAL2021,
  title = {A {{Subexponential Algorithm}} for {{ARRIVAL}}},
  booktitle = {48th International Colloquium on Automata, Languages, and Programming ({{ICALP}} 2021)},
  author = {G{\"a}rtner, Bernd and Haslebacher, Sebastian and Hoang, Hung P.},
  year = {2021},
  series = {Leibniz International Proceedings in Informatics (Lipics)},
  volume = {198},
  pages = {69:1--69:14},
  publisher = {Schloss Dagstuhl -- Leibniz-Zentrum f{\"u}r Informatik},
  address = {Dagstuhl, Germany},
  doi = {10.4230/LIPIcs.ICALP.2021.69},
  isbn = {978-3-95977-195-5},
  file = {/Users/sebastian/Zotero/storage/EJ3F67LY/Gärtner et al. - 2021 - A Subexponential Algorithm for ARRIVAL.pdf}
}

@article{gartnerUniqueSinkOrientations2008,
  title = {Unique {{Sink Orientations}} of {{Grids}}},
  author = {G{\"a}rtner, Bernd and Jr. Morris, Walter D. and R{\"u}st, Leo},
  year = {2008},
  month = jun,
  journal = {Algorithmica},
  volume = {51},
  number = {2},
  pages = {200--235},
  issn = {1432-0541},
  doi = {10.1007/s00453-007-9090-x},
  urldate = {2023-10-20},
  abstract = {We introduce unique sink orientations of grids as digraph models for many well-studied problems, including linear programming over products of simplices, generalized linear complementarity problems over P-matrices (PGLCP), and simple stochastic games.},
  langid = {english},
  keywords = {Generalized linear complementarity problem,Holt Klee condition,Linear programming,Sink finding algorithm,Unique sink orientation},
  file = {/Users/sebastian/Zotero/storage/HWIGC5VQ/Gärtner et al. - 2008 - Unique Sink Orientations of Grids.pdf}
}

@article{geelenComputingGirthCogirth2018,
  title = {Computing {{Girth}} and {{Cogirth}} in {{Perturbed Graphic Matroids}}},
  author = {Geelen, Jim and Kapadia, Rohan},
  year = {2018},
  month = feb,
  journal = {Combinatorica},
  volume = {38},
  number = {1},
  pages = {167--191},
  issn = {0209-9683},
  doi = {10.1007/s00493-016-3445-3},
  urldate = {2024-09-04},
  abstract = {We give polynomial-time randomized algorithms for computing the girth and the cogirth of binary matroids that are low-rank perturbations of graphic matroids.},
  file = {/Users/sebastian/Zotero/storage/DZ3SLMQY/Geelen and Kapadia - 2018 - Computing Girth and Cogirth in Perturbed Graphic M.pdf}
}

@inproceedings{gimbertSolvingSimpleStochastic2008,
  title = {Solving {{Simple Stochastic Games}}},
  booktitle = {Logic and {{Theory}} of {{Algorithms}}},
  author = {Gimbert, Hugo and Horn, Florian},
  year = {2008},
  pages = {206--209},
  publisher = {Springer},
  address = {Berlin, Heidelberg},
  doi = {10.1007/978-3-540-69407-6_24},
  abstract = {We present a new algorithm for solving Simple Stochastic Games (SSGs), which is fixed parameter tractable when parametrized with the number of random vertices. This algorithm is based on an exhaustive search of a special kind of positional optimal strategies, the f-strategies. The running time is , where and are respectively the number of vertices, random vertices and edges, and the maximum bit-length of a transition probability. Our algorithm improves existing algorithms for solving SSGs in three aspects. First, our algorithm performs well on SSGs with few random vertices, second it does not rely on linear or quadratic programming, third it applies to all SSGs, not only stopping SSGs.},
  isbn = {978-3-540-69407-6},
  langid = {english},
  keywords = {Initial Vertex,Markov Decision Process,Quadratic Program,Stochastic Game,Target Vertex},
  file = {/Users/sebastian/Zotero/storage/5H68WMJJ/Gimbert and Horn - 2008 - Solving Simple Stochastic Games.pdf;/Users/sebastian/Zotero/storage/AH6E7QHT/SSG_gimbert_horn.pdf}
}

@article{goldbergContiguousCakeCutting2020,
  title = {Contiguous {{Cake Cutting}}: {{Hardness Results}} and {{Approximation Algorithms}}},
  shorttitle = {Contiguous {{Cake Cutting}}},
  author = {Goldberg, Paul and Hollender, Alexandros and Suksompong, Warut},
  year = {2020},
  month = sep,
  journal = {Journal of Artificial Intelligence Research},
  volume = {69},
  pages = {109--141},
  issn = {1076-9757},
  doi = {10.1613/jair.1.12222},
  urldate = {2024-06-21},
  abstract = {We study the fair allocation of a cake, which serves as a metaphor for a divisible resource, under the requirement that each agent should receive a contiguous piece of the cake. While it is known that no finite envy-free algorithm exists in this setting, we exhibit efficient algorithms that produce allocations with low envy among the agents. We then establish NP-hardness results for various decision problems on the existence of envy-free allocations, such as when we fix the ordering of the agents or constrain the positions of certain cuts. In addition, we consider a discretized setting where indivisible items lie on a line and show a number of hardness results extending and strengthening those from prior work. Finally, we investigate connections between approximate and exact envy-freeness, as well as between continuous and discrete cake cutting.},
  copyright = {Copyright (c)},
  langid = {english},
  keywords = {game theory,mathematical foundations,multiagent systems,preferences},
  file = {/Users/sebastian/Zotero/storage/CWMU7X9U/Goldberg et al. - 2020 - Contiguous Cake Cutting Hardness Results and Appr.pdf}
}

@inproceedings{goldbergTFNPUpdate2017,
  title = {{{TFNP}}: {{An Update}}},
  shorttitle = {{{TFNP}}},
  booktitle = {Algorithms and {{Complexity}}},
  author = {Goldberg, Paul W. and Papadimitriou, Christos H.},
  year = {2017},
  pages = {3--9},
  publisher = {Springer International Publishing},
  address = {Cham},
  doi = {10.1007/978-3-319-57586-5_1},
  abstract = {The class TFNP was introduced a quarter of a century ago to capture problems in NP that have a witness for all inputs. A decade ago, this line of research culminated in the proof that the Nash equilibrium problem is complete for the subclass PPAD. Here we review some interesting developments since.},
  isbn = {978-3-319-57586-5},
  langid = {english},
  keywords = {Complete Problem,Nash Equilibrium,Nash Equilibrium Problem,Proof System,Total Problem},
  file = {/Users/sebastian/Zotero/storage/NX7P4WAP/Goldberg and Papadimitriou - 2017 - TFNP An Update.pdf}
}

@misc{goldreichDefiningPPTsearchProblems2024,
  title = {On Defining {{PPT-search}} Problems},
  author = {Goldreich, Oded},
  year = {2024},
  month = oct,
  number = {TR24-161},
  eprint = {TR24-161},
  publisher = {Electronic Colloquium on Computational Complexity},
  issn = {1433-8092},
  urldate = {2024-10-25},
  abstract = {We propose a new definition of the class of search problems that correspond to BPP. Specifically, a problem in this class is specified by a polynomial-time approximable function q:0101[01]~ that associates, with each possible solution y to an instance x, a quality q(xy)~.Intuitively, quality 1 corresponds to perfectly valid solutions, quality 0 corresponds to perfectly invalid solutions, but the quality of other solutions can be anywhere in-between.The class of PPT-search problems contains q if there exists a PPT algorithm that, on input x, finds a solution with value close to maxyq(xy)~.  We relate this definition to previously studied definitions of ``BPP-search problems'' and articulate our preference for it. More importantly, we show that any PPT-search problem can be reduced in deterministic polynomial-time to a promise problem in promise-BPP.},
  archiveprefix = {Electronic Colloquium on Computational Complexity},
  langid = {english},
  keywords = {BPP,Probabilistic polynomial-time,promise problems,search problems},
  file = {/Users/sebastian/Zotero/storage/28QNJDQA/Goldreich - 2024 - On defining PPT-search problems.pdf}
}

@inproceedings{goosFurtherCollapsesTFNP2022,
  title = {Further Collapses in {{TFNP}}},
  booktitle = {Proceedings of the 37th {{Computational Complexity Conference}}},
  author = {G{\"o}{\"o}s, Mika and Hollender, Alexandros and Jain, Siddhartha and Maystre, Gilbert and Pires, William and Robere, Robert and Tao, Ran},
  year = {2022},
  month = sep,
  series = {{{CCC}} '22},
  pages = {1--15},
  publisher = {Schloss Dagstuhl--Leibniz-Zentrum fuer Informatik},
  address = {Dagstuhl, DEU},
  doi = {10.4230/LIPIcs.CCC.2022.33},
  urldate = {2023-09-15},
  abstract = {We show EOPL = PLS {$\cap$} PPAD. Here the class EOPL consists of all total search problems that reduce to the End-of-Potential-Line problem, which was introduced in the works by Hub{\'a}{\v c}ek and Yogev (SICOMP 2020) and Fearnley et al. (JCSS 2020). In particular, our result yields a new simpler proof of the breakthrough collapse CLS = PLS {$\cap$} PPAD by Fearnley et al. (STOC 2021). We also prove a companion result SOPL = PLS {$\cap$} PPADS, where SOPL is the class associated with the Sink-of-Potential-Line problem.},
  isbn = {978-3-95977-241-9},
  keywords = {EOPL,PLS,PPAD,TFNP},
  file = {/Users/sebastian/Zotero/storage/V5TAD2MP/Göös et al. - 2022 - Further collapses in TFNP.pdf}
}

@article{goosSeparationsProofComplexity2024,
  title = {Separations in {{Proof Complexity}} and {{TFNP}}},
  author = {G{\"o}{\"o}s, Mika and Hollender, Alexandros and Jain, Siddhartha and Maystre, Gilbert and Pires, William and Robere, Robert and Tao, Ran},
  year = {2024},
  month = aug,
  journal = {J. ACM},
  volume = {71},
  number = {4},
  pages = {26:1--26:45},
  issn = {0004-5411},
  doi = {10.1145/3663758},
  urldate = {2025-01-16},
  abstract = {It is well-known that Resolution proofs can be efficiently simulated by Sherali--Adams\&nbsp;(SA) proofs. We show, however, that any such simulation needs to exploit huge coefficients: Resolution cannot be efficiently simulated by SA when the coefficients are written in unary. We also show that Reversible Resolution (a variant of MaxSAT Resolution) cannot be efficiently simulated by Nullstellensatz (NS).These results have consequences for total NP search problems. First, we characterise the classes PPADS, PPAD, SOPL by unary-SA, unary-NS, and Reversible Resolution, respectively. Second, we show that, relative to an oracle,  {\textbackslash}(\{{\textbackslash}text\{ PLS\}\} {\textbackslash}not{\textbackslash}subseteq \{{\textbackslash}text\{ PPP\}\}{\textbackslash}) ,  {\textbackslash}(\{{\textbackslash}text\{ SOPL\}\} {\textbackslash}not{\textbackslash}subseteq \{{\textbackslash}text\{ PPA\}\}{\textbackslash}) , and  {\textbackslash}(\{{\textbackslash}text\{ EOPL\}\} {\textbackslash}not{\textbackslash}subseteq \{{\textbackslash}text\{ UEOPL\}\}{\textbackslash}) . In particular, together with prior work, this gives a complete picture of the black-box relationships between all classical TFNP classes introduced in the 1990s.},
  file = {/Users/sebastian/Zotero/storage/DS57ZTMB/Göös et al. - 2024 - Separations in Proof Complexity and TFNP.pdf}
}

@book{grotschelGeometricAlgorithmsCombinatorial1993,
  title = {Geometric {{Algorithms}} and {{Combinatorial Optimization}}},
  author = {Gr{\"o}tschel, Martin and Lov{\'a}sz, L{\'a}szl{\'o} and Schrijver, Alexander},
  year = {1993},
  series = {Algorithms and {{Combinatorics}}},
  volume = {2},
  publisher = {Springer},
  address = {Berlin, Heidelberg},
  doi = {10.1007/978-3-642-78240-4},
  urldate = {2025-01-15},
  copyright = {http://www.springer.com/tdm},
  isbn = {978-3-642-78242-8 978-3-642-78240-4},
  keywords = {algorithms,Basis Reduction in Lattices,Basisreduktion bei Gittern,combinatorial optimization,combinatorics,Convexity,Ellipsoid Method,Ellipsoidmethode,Kombinatorische Optimierung,Konvexitat,Lattice,Linear Programming,Lineares Programmieren,operations resear},
  file = {/Users/sebastian/Zotero/storage/M8IGTUEC/Grötschel et al. - 1993 - Geometric Algorithms and Combinatorial Optimization.pdf}
}

@inproceedings{groverBirkhoffJamesOrthogonality2021,
  title = {Birkhoff--{{James Orthogonality}} and {{Applications}}: {{A Survey}}},
  shorttitle = {Birkhoff--{{James Orthogonality}} and {{Applications}}},
  booktitle = {Operator {{Theory}}, {{Functional Analysis}} and {{Applications}}},
  author = {Grover, Priyanka and Singla, Sushil},
  year = {2021},
  pages = {293--315},
  publisher = {Springer International Publishing},
  address = {Cham},
  doi = {10.1007/978-3-030-51945-2_15},
  abstract = {In the last few decades, the concept of Birkhoff--James orthogonality has been used in several applications. In this survey article, the results known on the necessary and sufficient conditions for Birkhoff--James orthogonality in certain Banach spaces are mentioned. Their applications in studying the geometry of normed spaces are given. The connections between this concept of orthogonality, and the Gateaux derivative and the subdifferential set of the norm function are provided. Several interesting distance formulas can be obtained using the characterizations of Birkhoff--James orthogonality, which are also mentioned. In the end, some new results are obtained.},
  isbn = {978-3-030-51945-2},
  langid = {english},
  keywords = {41A50,46B20,46L05,46L08; Secondary 46G05,47B47,Conditional expectation,Cyclic representation,Faces of unit ball,Gateaux differentiability,Norm-parallelism,Orthogonality,Primary 15A60,Smooth point,State on a C
-algebra,Subdifferential set,Tangent hyperplane},
  file = {/Users/sebastian/Zotero/storage/SWJ8BXFF/Grover and Singla - 2021 - Birkhoff–James Orthogonality and Applications A Survey.pdf}
}

@article{grunbaumPartitionsMassdistributionsConvex1960,
  title = {Partitions of Mass-Distributions and of Convex Bodies by Hyperplanes.},
  author = {Gr{\"u}nbaum, B.},
  year = {1960},
  month = jan,
  journal = {Pacific Journal of Mathematics},
  volume = {10},
  number = {4},
  pages = {1257--1261},
  publisher = {Pacific Journal of Mathematics, A Non-profit Corporation},
  issn = {0030-8730},
  urldate = {2025-01-20},
  abstract = {Pacific Journal of Mathematics},
  keywords = {52.40,53.90},
  file = {/Users/sebastian/Zotero/storage/43HK2QNU/Grünbaum - 1960 - Partitions of mass-distributions and of convex bodies by hyperplanes..pdf}
}

@article{gurjarExactPerfectMatching2017,
  title = {Exact {{Perfect Matching}} in {{Complete Graphs}}},
  author = {Gurjar, Rohit and Korwar, Arpita and Messner, Jochen and Thierauf, Thomas},
  year = {2017},
  month = apr,
  journal = {ACM Transactions on Computation Theory},
  volume = {9},
  number = {2},
  pages = {8:1--8:20},
  issn = {1942-3454},
  doi = {10.1145/3041402},
  urldate = {2024-04-05},
  abstract = {A red-blue graph is a graph where every edge is colored either red or blue. The exact perfect matching problem asks for a perfect matching in a red-blue graph that has exactly a given number of red edges. We show that for complete and bipartite complete graphs, the exact perfect matching problem is logspace equivalent to the perfect matching problem. Hence, an efficient parallel algorithm for perfect matching would carry over to the exact perfect matching problem for this class of graphs. We also report some progress in extending the result to arbitrary graphs.},
  keywords = {complete graphs,computational complexity,exact perfect matching,Perfect matching},
  file = {/Users/sebastian/Zotero/storage/5V44NXH8/Gurjar et al. - 2017 - Exact Perfect Matching in Complete Graphs.pdf}
}

@inproceedings{gurjarPlanarizingGadgetsPerfect2012,
  title = {Planarizing {{Gadgets}} for {{Perfect Matching Do Not Exist}}},
  booktitle = {Mathematical {{Foundations}} of {{Computer Science}} 2012},
  author = {Gurjar, Rohit and Korwar, Arpita and Messner, Jochen and Straub, Simon and Thierauf, Thomas},
  year = {2012},
  pages = {478--490},
  publisher = {Springer},
  address = {Berlin, Heidelberg},
  doi = {10.1007/978-3-642-32589-2_43},
  abstract = {To reduce a graph problem to its planar version, a standard technique is to replace crossings in a drawing of the input graph by planarizing gadgets. We show unconditionally that such a reduction is not possible for the perfect matching problem and also extend this to some other problems related to perfect matching. We further show that there is no planarizing gadget for the Hamiltonian cycle problem.},
  isbn = {978-3-642-32589-2},
  langid = {english},
  keywords = {Chordal Graph,Hamiltonian Cycle,Perfect Match,Planar Graph,Planar Version},
  file = {/Users/sebastian/Zotero/storage/8FYS26VB/Gurjar et al. - 2012 - Planarizing Gadgets for Perfect Matching Do Not Ex.pdf}
}

@phdthesis{halmanDiscreteLexicographicHelly,
  title = {Discrete and {{Lexicographic Helly Theorems}} and Their {{Relations}} to {{LP-Type Problems}}},
  author = {Halman, Nir},
  langid = {english},
  file = {/Users/sebastian/Zotero/storage/BRXN2F8R/Halman - Discrete and Lexicographic Helly Theorems and thei.pdf}
}

@article{halmanSimpleStochasticGames2007,
  title = {Simple {{Stochastic Games}}, {{Parity Games}}, {{Mean Payoff Games}} and {{Discounted Payoff Games Are All LP-Type Problems}}},
  author = {Halman, Nir},
  year = {2007},
  month = sep,
  journal = {Algorithmica},
  volume = {49},
  number = {1},
  pages = {37--50},
  issn = {1432-0541},
  doi = {10.1007/s00453-007-0175-3},
  urldate = {2024-02-17},
  abstract = {We show that a Simple Stochastic Game (SSG) can be formulated as an LP-type problem. Using this formulation, and the known algorithm of Sharir and Welzl [SW] for LP-type problems, we obtain the first stronglysubexponential solution for SSGs (a strongly subexponential algorithm has only been known for binary SSGs [L]). Using known reductions between various games, we achieve the first strongly subexponential solutions for Discounted and Mean Payoff Games. We also give alternative simple proofs for the best known upper bounds for Parity Games and binary SSGs. To the best of our knowledge, the LP-type framework has been used so far only in order to yield linear or close to linear time algorithms for various problems in computational geometry and location theory. Our approach demonstrates the applicability of the LP-type framework in other fields, and for achieving subexponential algorithms.},
  langid = {english},
  keywords = {Average Vertex,Basis Computation,Linear Time Algorithm,Optimal Strategy,Outgoing Edge},
  file = {/Users/sebastian/Zotero/storage/95C9HQNH/Halman - 2007 - Simple Stochastic Games, Parity Games, Mean Payoff.pdf}
}

@inproceedings{hansenImprovedVersionRandomFacet2015a,
  title = {An {{Improved Version}} of the {{Random-Facet Pivoting Rule}} for the {{Simplex Algorithm}}},
  booktitle = {Proceedings of the Forty-Seventh Annual {{ACM}} Symposium on {{Theory}} of {{Computing}}},
  author = {Hansen, Thomas Dueholm and Zwick, Uri},
  year = {2015},
  month = jun,
  pages = {209--218},
  publisher = {ACM},
  address = {Portland Oregon USA},
  doi = {10.1145/2746539.2746557},
  urldate = {2024-03-18},
  abstract = {Optimization Problems (AOPs). His main motivation was obtaining subexponential combinatorial algorithms for non basis-regular LP-type problems (see [23, 46]) such as computing the minimum enclosing ball of a set of points in Rd and computing the distance between two convex polyhedra. Our pivoting rule is a slightly improved version of G{\textasciidieresis}artner's algorithm, tuned for linear programs and other basis-regular LP-type problems.},
  isbn = {978-1-4503-3536-2},
  langid = {english},
  file = {/Users/sebastian/Zotero/storage/75I6YJNY/Hansen and Zwick - 2015 - An Improved Version of the Random-Facet Pivoting R.pdf}
}

@article{hansenStayinaSetGameStationary2019,
  title = {A {{Stay-in-a-Set Game}} without a {{Stationary Equilibrium}}},
  author = {Hansen, Kristoffer Arnsfelt and Raskin, Mikhail},
  year = {2019},
  month = sep,
  journal = {Electronic Proceedings in Theoretical Computer Science},
  volume = {305},
  eprint = {1903.11935},
  primaryclass = {cs, math},
  pages = {83--90},
  issn = {2075-2180},
  doi = {10.4204/EPTCS.305.6},
  urldate = {2024-06-12},
  abstract = {We give an example of a finite-state two-player turn-based stochastic game with safety objectives for both players which has no stationary Nash equilibrium. This answers an open question of Secchi and Sudderth.},
  archiveprefix = {arXiv},
  keywords = {Computer Science - Computer Science and Game Theory,Mathematics - Optimization and Control},
  file = {/Users/sebastian/Zotero/storage/VCWTH9UZ/Hansen and Raskin - 2019 - A Stay-in-a-Set Game without a Stationary Equilibr.pdf;/Users/sebastian/Zotero/storage/TIHMZPFU/1903.html}
}

@article{hansenStrategyIterationStrongly2013,
  title = {Strategy {{Iteration Is Strongly Polynomial}} for 2-{{Player Turn-Based Stochastic Games}} with a {{Constant Discount Factor}}},
  author = {Hansen, Thomas Dueholm and Miltersen, Peter Bro and Zwick, Uri},
  year = {2013},
  month = feb,
  journal = {Journal of the ACM},
  volume = {60},
  number = {1},
  pages = {1:1--1:16},
  issn = {0004-5411},
  doi = {10.1145/2432622.2432623},
  urldate = {2023-11-28},
  abstract = {Ye [2011] showed recently that the simplex method with Dantzig's pivoting rule, as well as Howard's policy iteration algorithm, solve discounted Markov decision processes (MDPs), with a constant discount factor, in strongly polynomial time. More precisely, Ye showed that both algorithms terminate after at most O(mn1-{$\gamma$} log n1-{$\gamma$}) iterations, where n is the number of states, m is the total number of actions in the MDP, and 0 {$<$} {$\gamma$} {$<$} 1 is the discount factor. We improve Ye's analysis in two respects. First, we improve the bound given by Ye and show that Howard's policy iteration algorithm actually terminates after at most O(m1-{$\gamma$} log n1-{$\gamma$}) iterations. Second, and more importantly, we show that the same bound applies to the number of iterations performed by the strategy iteration (or strategy improvement) algorithm, a generalization of Howard's policy iteration algorithm used for solving 2-player turn-based stochastic games with discounted zero-sum rewards. This provides the first strongly polynomial algorithm for solving these games, solving a long standing open problem. Combined with other recent results, this provides a complete characterization of the complexity the standard strategy iteration algorithm for 2-player turn-based stochastic games; it is strongly polynomial for a fixed discount factor, and exponential otherwise.},
  keywords = {Markov decision processes,policy iteration,strategy iteration,strongly polynomial algorithms,turn-based stochastic games},
  file = {/Users/sebastian/Zotero/storage/L2N27T69/Hansen et al. - 2013 - Strategy Iteration Is Strongly Polynomial for 2-Pl.pdf}
}

@misc{har-peledJourneyCenterPoint2019,
  title = {Journey to the {{Center}} of the {{Point Set}}},
  author = {{Har-Peled}, Sariel and Jones, Mitchell},
  year = {2019},
  month = feb,
  number = {arXiv:1712.02949},
  eprint = {1712.02949},
  publisher = {arXiv},
  doi = {10.48550/arXiv.1712.02949},
  urldate = {2024-11-06},
  abstract = {\${\textbackslash}renewcommand\{{\textbackslash}Re\}\{{\textbackslash}mathbb\{R\}\} {\textbackslash}newcommand\{{\textbackslash}eps\}\{{\textbackslash}varepsilon\} {\textbackslash}newcommand\{{\textbackslash}Net\}\{S\} {\textbackslash}newcommand\{{\textbackslash}tldO\}\{\{{\textbackslash}widetilde\{O\}\}\} {\textbackslash}newcommand\{{\textbackslash}body\}\{C\} \$ We revisit an algorithm of Clarkson etal [CEMST96], that computes (roughly) a \$1/(4d{\textasciicircum}2)\$-centerpoint in \${\textbackslash}tldO(d{\textasciicircum}9)\$ time, for a point set in \${\textbackslash}Re{\textasciicircum}d\$, where \${\textbackslash}tldO\$ hides polylogarithmic terms. We present an improved algorithm that computes (roughly) a \$1/d{\textasciicircum}2\$-centerpoint with running time \${\textbackslash}tldO(d{\textasciicircum}7)\$. While the improvements are (arguably) mild, it is the first progress on this well known problem in over twenty years. The new algorithm is simpler, and the running time bound follows by a simple random walk argument, which we believe to be of independent interest. We also present several new applications of the improved centerpoint algorithm.},
  archiveprefix = {arXiv},
  keywords = {Computer Science - Computational Geometry},
  file = {/Users/sebastian/Zotero/storage/K2W4M847/Har-Peled and Jones - 2019 - Journey to the Center of the Point Set.pdf;/Users/sebastian/Zotero/storage/I3T3I5GS/1712.html}
}

@article{harborthKonvexeFunfeckeEbenen1978,
  title = {Konvexe {{F{\"u}nfecke}} in Ebenen {{Punktmengen}}.},
  author = {Harborth, Heiko},
  year = {1978},
  journal = {Elemente der Mathematik},
  volume = {33},
  pages = {116--118},
  urldate = {2023-08-10},
  langid = {english},
  file = {/Users/sebastian/Zotero/storage/KLM7U5LI/GDZPPN002079801.html}
}

@misc{harrisFasterAlgorithmVertex2024,
  title = {A Faster Algorithm for {{Vertex Cover}} Parameterized by Solution Size},
  author = {Harris, David G. and Narayanaswamy, N. S.},
  year = {2024},
  month = jan,
  number = {arXiv:2205.08022},
  eprint = {2205.08022},
  primaryclass = {cs, math},
  urldate = {2024-03-11},
  abstract = {We describe a new algorithm for vertex cover with runtime \$O{\textasciicircum}*(1.25284{\textasciicircum}k)\$, where \$k\$ is the size of the desired solution and \$O{\textasciicircum}*\$ hides polynomial factors in the input size. This improves over previous runtime of \$O{\textasciicircum}*(1.2738{\textasciicircum}k)\$ due to Chen, Kanj, \& Xia (2010) standing for more than a decade. The key to our algorithm is to use a potential function which simultaneously tracks \$k\$ as well as the optimal value \${\textbackslash}lambda\$ of the vertex cover LP relaxation. This approach also allows us to make use of prior algorithms for Maximum Independent Set in bounded-degree graphs and Above-Guarantee Vertex Cover. The main step in the algorithm is to branch on high-degree vertices, while ensuring that both \$k\$ and \${\textbackslash}mu = k - {\textbackslash}lambda\$ are decreased at each step. There can be local obstructions in the graph that prevent \${\textbackslash}mu\$ from decreasing in this process; we develop a number of novel branching steps to handle these situations.},
  archiveprefix = {arXiv},
  file = {/Users/sebastian/Zotero/storage/FF3Z6EU8/Harris and Narayanaswamy - 2024 - A faster algorithm for Vertex Cover parameterized by solution size.pdf}
}

@incollection{hatzelSimplerFasterAlgorithms2023,
  title = {Simpler and Faster Algorithms for Detours in Planar Digraphs},
  booktitle = {2023 {{Symposium}} on {{Simplicity}} in {{Algorithms}} ({{SOSA}})},
  author = {Hatzel, Meike and Majewski, Konrad and Pilipczuk, Micha{\l} and Soko{\l}owski, Marek},
  year = {2023},
  month = jan,
  series = {Proceedings},
  pages = {156--165},
  publisher = {{Society for Industrial and Applied Mathematics}},
  doi = {10.1137/1.9781611977585.ch15},
  urldate = {2024-09-20},
  abstract = {In the DIRECTED DETOUR problem one is given a digraph G and a pair of vertices s and t, and the task is to decide whether there is a directed simple path from s to t in G whose length is larger than distG (s, t). The more general parameterized variant, DIRECTED LONG DETOUR, asks for a simple s-to-t path of length at least distG (s, t) + k, for a given parameter k. Surprisingly, it is still unknown whether DIRECTED DETOUR is polynomial-time solvable on general digraphs. However, for planar digraphs, Wu and Wang [Networks, '15] proposed an O(n3)-time algorithm for DIRECTED DETOUR, while Fomin et al. [STACS 2022] gave a 2O({$\kappa$}) {$\cdot$} nO(1)-time fpt algorithm for DIRECTED LONG DETOUR. The algorithm of Wu and Wang relies on a nontrivial analysis of how short detours may look like in a plane embedding, while the algorithm of Fomin et al. is based on a reduction to the 3-DISJOINT PATHS problem on planar digraphs. This latter problem is solvable in polynomial time using the algebraic machinery of Schrijver [SIAM J. Comp., '94], but the degree of the obtained polynomial factor is huge.In this paper we propose two simple algorithms: we show how to solve, in planar digraphs, DIRECTED DETOUR in time O(n2) and DIRECTED LONG DETOUR in time 2O(k) {$\cdot$} n4 log n. In both cases, the idea is to reduce to the 2-DISJOINT PATHS problem in a planar digraph, and to observe that the obtained instances of this problem have a certain topological structure that makes them amenable to a direct greedy strategy.* This work is a part of project BOBR (KM, MP, MS) that has received funding from the European Research Council (ERC) under the European Union's Horizon 2020 research and innovation programme (grant agreement No. 948057). M. Hatzel was supported by the Federal Ministry of Education and Research (BMBF) and by a fellowship within the IFI programme of the German Academic Exchange Service (DAAD).},
  file = {/Users/sebastian/Zotero/storage/FVT8UNAX/Hatzel et al. - 2023 - Simpler and faster algorithms for detours in plana.pdf}
}

@article{haverkortLimit$$L_p$$VoronoiDiagrams2024,
  title = {The {{Limit}} of \$\${{L}}\_p\$\${{Voronoi Diagrams}} as \$\$p{\textbackslash}rightarrow 0\$\$is the {{Bounding-Box-Area Voronoi Diagram}}},
  author = {Haverkort, Herman and Klein, Rolf},
  year = {2024},
  month = oct,
  journal = {Discrete \& Computational Geometry},
  volume = {72},
  number = {3},
  pages = {1284--1303},
  issn = {1432-0444},
  doi = {10.1007/s00454-023-00599-6},
  urldate = {2024-11-26},
  abstract = {We consider the Voronoi diagram of points in the real plane when the distance between two points a and b is given by \$\$L\_p(a-b)\$\$where \$\$L\_p((x,y)) = ({\textbar}x{\textbar}{\textasciicircum}p+{\textbar}y{\textbar}{\textasciicircum}p){\textasciicircum}\{1/p\}.\$\$We prove that the Voronoi diagram has a limit as p converges to zero from above or from below: it is the diagram that corresponds to the distance function \$\$L\_*((x,y)) = {\textbar}xy{\textbar}\$\$. In this diagram, the bisector of two points in general position consists of a line and two branches of a hyperbola that split the plane into three faces per point. We propose to name \$\$L\_*\$\$as defined above the geometric \$\$L\_0\$\$distance.},
  langid = {english},
  keywords = {51-04,51B20,68U05,Geometric L0L_0 distance,Hyperbola,LpL_p norm,Voronoi diagram},
  file = {/Users/sebastian/Zotero/storage/TLMTUZQA/Haverkort and Klein - 2024 - The Limit of $$L_p$$Voronoi Diagrams as $$prightarrow 0$$is the Bounding-Box-Area Voronoi Diagram.pdf}
}

@misc{heidrich4approximationAlgorithmMin2023,
  title = {A 4-Approximation Algorithm for Min Max Correlation Clustering},
  author = {Heidrich, Holger and Irmai, Jannik and Andres, Bjoern},
  year = {2023},
  month = oct,
  number = {arXiv:2310.09196},
  eprint = {2310.09196},
  primaryclass = {cs},
  publisher = {arXiv},
  doi = {10.48550/arXiv.2310.09196},
  urldate = {2023-10-16},
  abstract = {We introduce a lower bounding technique for the min max correlation clustering problem and, based on this technique, a combinatorial 4-approximation algorithm for complete graphs. This improves upon the previous best known approximation guarantees of 5, using a linear program formulation (Kalhan et al., 2019), and 4, for a combinatorial algorithm (Davies et al., 2023). We extend this algorithm by a greedy joining heuristic and show empirically that it improves the state of the art in solution quality and runtime on several benchmark datasets.},
  archiveprefix = {arXiv},
  keywords = {Computer Science - Data Structures and Algorithms,Computer Science - Discrete Mathematics,Computer Science - Machine Learning},
  file = {/Users/sebastian/Zotero/storage/4IADS9BA/Heidrich et al. - 2023 - A 4-approximation algorithm for min max correlatio.pdf;/Users/sebastian/Zotero/storage/3XAQL8PI/2310.html}
}

@article{heProjectionContractionMethod1992,
  title = {A Projection and Contraction Method for a Class of Linear Complementarity Problems and Its Application in Convex Quadratic Programming},
  author = {He, Bingsheng},
  year = {1992},
  month = may,
  journal = {Applied Mathematics and Optimization},
  volume = {25},
  number = {3},
  pages = {247--262},
  issn = {1432-0606},
  doi = {10.1007/BF01182323},
  urldate = {2024-11-08},
  abstract = {In this paper we propose a new iterative method for solving a class of linear complementarity problems:u {$\geq$} 0,Mu + q {$\geq$} 0, uT(Mu + q)=0, where M is a givenl {\texttimes}l positive semidefinite matrix (not necessarily symmetric) andq is a givenl-vector. The method makes two matrix-vector multiplications and a trivial projection onto the nonnegative orthant at each iteration, and the Euclidean distance of the iterates to the solution set monotonously converges to zero. The main advantages of the method presented are its simplicity, robustness, and ability to handle large problems with any start point. It is pointed out that the method may be used to solve general convex quadratic programming problems. Preliminary numerical experiments indicate that this method may be very efficient for large sparse problems.},
  langid = {english},
  keywords = {Convex quadratic programming,Fejer-contraction,Linear complementarity problem,Linear programming,Projection},
  file = {/Users/sebastian/Zotero/storage/6YWLI5YL/He - 1992 - A projection and contraction method for a class of linear complementarity problems and its applicati.pdf}
}

@phdthesis{hoangTwoCombinatorialReconfiguration2022,
  type = {Doctoral {{Thesis}}},
  title = {On {{Two Combinatorial Reconfiguration Problems}}: {{Reachability}} and {{Hamiltonicity}}},
  shorttitle = {On {{Two Combinatorial Reconfiguration Problems}}},
  author = {Hoang, Hung P.},
  year = {2022},
  doi = {10.3929/ethz-b-000572947},
  urldate = {2024-04-25},
  copyright = {http://rightsstatements.org/page/InC-NC/1.0/},
  langid = {english},
  school = {ETH Zurich},
  annotation = {Accepted: 2022-09-29T06:35:39Z},
  file = {/Users/sebastian/Zotero/storage/EHF5QUH5/Hoang - 2022 - On Two Combinatorial Reconfiguration Problems Rea.pdf}
}

@inproceedings{hollenderEnvyFreeCakeCuttingFour2023,
  title = {Envy-{{Free Cake-Cutting}} for {{Four Agents}}},
  booktitle = {2023 {{IEEE}} 64th {{Annual Symposium}} on {{Foundations}} of {{Computer Science}} ({{FOCS}})},
  author = {Hollender, Alexandros and Rubinstein, Aviad},
  year = {2023},
  month = nov,
  pages = {113--122},
  publisher = {IEEE},
  address = {Santa Cruz, CA, USA},
  doi = {10.1109/FOCS57990.2023.00015},
  urldate = {2024-04-25},
  abstract = {In the envy-free cake-cutting problem we are given a resource, usually called a cake and represented as the [0, 1] interval, and a set of n agents with heterogeneous preferences over pieces of the cake. The goal is to divide the cake among the n agents such that no agent is envious of any other agent. Even under a very general preferences model, this fundamental fair division problem is known to always admit an exact solution where each agent obtains a connected piece of the cake; we study the complexity of finding an approximate solution, i.e., a connected {$\varepsilon$}-envy-free allocation.},
  copyright = {https://doi.org/10.15223/policy-029},
  isbn = {9798350318944},
  langid = {english},
  keywords = {Additives,Approximation algorithms,cake cutting,Closed box,communication complexity,Complexity theory,Computational modeling,Computer science,envy-free,PPAD,query complexity,Resource management},
  file = {/Users/sebastian/Zotero/storage/RZYWSX56/Hollender and Rubinstein - 2023 - Envy-Free Cake-Cutting for Four Agents.pdf;/Users/sebastian/Zotero/storage/ALF9ME27/10353201.html}
}

@phdthesis{hollenderStructuralResultsTotal2021,
  type = {{{http://purl.org/dc/dcmitype/Text}}},
  title = {Structural Results for Total Search Complexity Classes with Applications to Game Theory and Optimisation},
  author = {Hollender, A.},
  year = {2021},
  urldate = {2023-09-15},
  abstract = {{$<$}p{$>$}While the celebrated theory of NP-completeness has been very successful in explaining the intractability of many interesting problems, there still remain many natural and seemingly hard problems that are not known to be NP-hard. Several of these problems lie in the class of total NP search problems (TFNP), namely the class of NP search problems that always have a solution. Importantly, these problems cannot be NP-hard unless NP = co-NP. Notable examples of TFNP problems include FACTORING (given a natural number, compute its prime factorisation) and NASH (given a game, compute a mixed Nash equilibrium). In order to shed light on the complexity of these problems, researchers have attempted to classify them in various subclasses of TFNP such as PPAD, PPA, PPP, PLS, and CLS. A celebrated result in this line of research is the PPAD-completeness of NASH, yielding strong evidence that the problem is not polynomial-time solvable.{$<$}/p{$>$} {$<$}p{$>$}In this thesis we provide new structural results for TFNP subclasses and show how they can be used to classify natural problems arising from application areas such as game theory and optimisation. In the first part of this work, we construct more powerful tools for proving membership in PPAD, as well as PPAD-hardness. We directly apply these tools to show that the Hairy Ball theorem from topology ("you can't comb a hairy ball flat without creating a cowlick"), as well as the equilibrium computation problem in First Price Auctions with subjective priors, are both PPAD-complete.{$<$}/p{$>$} {$<$}p{$>$}In the second part of this thesis, we present our main result: the collapse CLS = PPAD {$\cap$} PLS. We prove this surprising collapse by exhibiting the first non-artificial PPAD {$\cap$} PLS-complete problem - a problem arising naturally from the famous gradient descent algorithm. Our result puts PPAD {$\cap$} PLS on the map as a TFNP subclass that captures the complexity of natural problems.{$<$}/p{$>$} {$<$}p{$>$}In the third and final part, we provide various structural results for the classes PPA-k (corresponding to arguments modulo k), including the first topological characterisations of these classes. As a direct application, we prove that NECKLACE-SPLITTING with k thieves - a notorious problem in combinatorics and fair division - lies in PPA-k under Turing reductions.{$<$}/p{$>$}},
  langid = {english},
  school = {University of Oxford},
  file = {/Users/sebastian/Zotero/storage/D6BEVDF6/Hollender - 2021 - Structural results for total search complexity cla.pdf}
}

@incollection{holroydChipFiringRotorRoutingDirected2008,
  title = {Chip-{{Firing}} and {{Rotor-Routing}} on {{Directed Graphs}}},
  booktitle = {In and {{Out}} of {{Equilibrium}} 2},
  author = {Holroyd, Alexander E. and Levine, Lionel and M{\'e}sz{\'a}ros, Karola and Peres, Yuyal and Propp, James and Wilson, David B.},
  year = {2008},
  pages = {331--364},
  publisher = {Birkh{\"a}user},
  address = {Basel},
  doi = {10.1007/978-3-7643-8786-0_17},
  urldate = {2024-05-02},
  abstract = {We give a rigorous and self-contained survey of the abelian sandpile model and rotor-router model on finite directed graphs, highlighting the connections between them. We present several intriguing open problems.},
  isbn = {978-3-7643-8786-0},
  langid = {english},
  keywords = {Abelian sandpile model,chip firing,Eulerian walkers,Primary: 82C20,rotor-router model,secondary: 20K01 05C25},
  file = {/Users/sebastian/Zotero/storage/Y7BLWDIY/Holroyd et al. - 2008 - Chip-Firing and Rotor-Routing on Directed Graphs.pdf}
}

@article{hooryExpanderGraphsTheir2006,
  title = {Expander Graphs and Their Applications},
  author = {Hoory, Shlomo and Linial, Nathan and Wigderson, Avi},
  year = {2006},
  month = aug,
  journal = {Bulletin of the American Mathematical Society},
  volume = {43},
  number = {04},
  pages = {439--562},
  issn = {0273-0979},
  doi = {10.1090/S0273-0979-06-01126-8},
  urldate = {2023-08-10},
  langid = {english},
  file = {/Users/sebastian/Zotero/storage/NBBENZRH/Hoory et al. - 2006 - Expander graphs and their applications.pdf}
}

@article{hortonSetsNoEmpty1983,
  title = {Sets with {{No Empty Convex}} 7-{{Gons}}},
  author = {Horton, J. D.},
  year = {1983},
  month = dec,
  journal = {Canadian Mathematical Bulletin},
  volume = {26},
  number = {4},
  pages = {482--484},
  issn = {0008-4395, 1496-4287},
  doi = {10.4153/CMB-1983-077-8},
  urldate = {2023-08-10},
  abstract = {Abstract                            Erd{\"o}s has defined g(n) as the smallest integer such that any set of g(n) points in the plane, no three collinear, contains the vertex set of a convex               n               -gon whose interior contains no point of this set. Arbitrarily large sets containing no empty convex 7-gon are constructed, showing that g(n) does not exist for n{$\geq$}l. Whether g(6) exists is unknown.},
  langid = {english},
  file = {/Users/sebastian/Zotero/storage/FG726ZDY/Horton - 1983 - Sets with No Empty Convex 7-Gons.pdf}
}

@article{horvathBisectorsMinkowskiNormed2000,
  title = {On {{Bisectors}} in {{Minkowski Normed Spaces}}},
  author = {Horv{\'a}th, {\'A}. G.},
  year = {2000},
  month = nov,
  journal = {Acta Mathematica Hungarica},
  volume = {89},
  number = {3},
  pages = {233--246},
  issn = {1588-2632},
  doi = {10.1023/A:1010611925838},
  urldate = {2024-11-27},
  abstract = {We discuss the concept of the bisector of a segment in a Minkowski normed n-space, and prove that if the unit ball K of the space is strictly convex then all bisectors are topological images of a hyperplane of the embedding Euclidean n-space. The converse statement is not true. We give an example in the three-space showing that all bisectors are topological planes, however K contains segments on its boundary. Strict convexity ensures the normality of Dirichlet-Voronoi-type K-subdivision of any point lattice.},
  langid = {english},
  keywords = {Converse Statement,Normed Space,Point Lattice,Strict Convexity,Unit Ball},
  file = {/Users/sebastian/Zotero/storage/PHSMEBD6/Horváth - 2000 - On Bisectors in Minkowski Normed Spaces.pdf}
}

@article{huangApproximatingFixedPoints1999,
  title = {Approximating {{Fixed Points}} of {{Weakly Contracting Mappings}}},
  author = {Huang, Z and Khachiyan, L and Sikorski, K},
  year = {1999},
  month = jun,
  journal = {Journal of Complexity},
  volume = {15},
  number = {2},
  pages = {200--213},
  issn = {0885-064X},
  doi = {10.1006/jcom.1999.0504},
  urldate = {2024-06-17},
  abstract = {We consider the problem of approximating fixed points of contractive functions whose contraction factor is close to 1. In a previous paper (1993, K. Sikorski et al., J. Complexity9, 181--200), we proved that for the absolute error criterion, the upper bound on the number of function evaluations to compute {$\varepsilon$}-approximations is O(n3(ln(1/{$\varepsilon$})+ln(1/(1-q))+ln~n)) in the worst case, where 0},
  file = {/Users/sebastian/Zotero/storage/DSCES778/Huang et al. - 1999 - Approximating Fixed Points of Weakly Contracting M.pdf;/Users/sebastian/Zotero/storage/6Q98ZIKA/S0885064X99905046.html}
}

@article{hubacekHardnessContinuousLocal2020,
  title = {Hardness of {{Continuous Local Search}}: {{Query Complexity}} and {{Cryptographic Lower Bounds}}},
  shorttitle = {Hardness of {{Continuous Local Search}}},
  author = {Hub{\'a}{\v c}ek, Pavel and Yogev, Eylon},
  year = {2020},
  month = jan,
  journal = {SIAM Journal on Computing},
  volume = {49},
  number = {6},
  pages = {1128--1172},
  publisher = {{Society for Industrial and Applied Mathematics}},
  issn = {0097-5397},
  doi = {10.1137/17M1118014},
  urldate = {2024-09-30},
  abstract = {Local search proved to be an extremely useful tool when facing hard optimization problems (e.g., via the simplex algorithm, simulated annealing, or genetic algorithms). Although powerful, it has its limitations: there are functions for which exponentially many queries are needed to find a local optimum. In many contexts the optimization problem is defined by a continuous function, which might offer an advantage when performing the local search. This leads us to study the following natural question: How hard is continuous local search? The computational complexity of such search problems is captured by the complexity class CLS (Daskalakis and Papadimitriou SODA'11) which is contained in the intersection of PLS and PPAD, two important subclasses of TFNP (the class of NP search problems with a guaranteed solution).In this work, we show the first hardness results for CLS (the smallest non-trivial class among the currently defined subclasses of TFNP). Our hardness results are in terms of black-box (where only oracle access to the function is given) and white-box (where the function is represented succinctly by a circuit). In the black-box case, we show instances for which any (computationally unbounded) randomized algorithm must perform exponentially many queries in order to find a local optimum. In the white-box case, we show hardness for computationally bounded algorithms under cryptographic assumptions. Our results demonstrate a strong conceptual barrier precluding design of efficient algorithms for solving local search problems even over continuous domains.As our main technical contribution we introduce a new total search problem which we call End-OF-Metered-Line. The special structure of End-OF-Metered-Line enables us to: (1) show that it is contained in CLS, and (2) prove hardness for it both in the black-box and the white-box setting.},
  file = {/Users/sebastian/Zotero/storage/WGEPVB6V/Hubáček and Yogev - 2020 - Hardness of Continuous Local Search Query Complex.pdf}
}

@inproceedings{ibsen-jensenSolvingSimpleStochastic2012,
  title = {Solving {{Simple Stochastic Games}} with {{Few Coin Toss Positions}}},
  booktitle = {Algorithms -- {{ESA}} 2012},
  author = {{Ibsen-Jensen}, Rasmus and Miltersen, Peter Bro},
  year = {2012},
  pages = {636--647},
  publisher = {Springer},
  address = {Berlin, Heidelberg},
  doi = {10.1007/978-3-642-33090-2_55},
  abstract = {Gimbert and Horn gave an algorithm for solving simple stochastic games with running time O(r! n) where n is the number of positions of the simple stochastic game and r is the number of its coin toss positions. Chatterjee et al. pointed out that a variant of strategy iteration can be implemented to solve this problem in time 4rnO(1). In this paper, we show that an algorithm combining value iteration with retrograde analysis achieves a time bound of O(r 2r(r logr\,+\,n)), thus improving both time bounds. We also improve the analysis of Chatterjee et al. and show that their algorithm in fact has complexity 2rnO(1).},
  isbn = {978-3-642-33090-2},
  langid = {english},
  keywords = {Danish National Research Foundation,Goal Position,Positional Strategy,Stochastic Game,Strategy Iteration},
  file = {/Users/sebastian/Zotero/storage/F57389E7/Ibsen-Jensen and Miltersen - 2012 - Solving Simple Stochastic Games with Few Coin Toss.pdf}
}

@article{igarashiHowCutDiscrete2023,
  title = {How to {{Cut}} a {{Discrete Cake Fairly}}},
  author = {Igarashi, Ayumi},
  year = {2023},
  month = jun,
  journal = {Proceedings of the AAAI Conference on Artificial Intelligence},
  volume = {37},
  number = {5},
  pages = {5681--5688},
  issn = {2374-3468},
  doi = {10.1609/aaai.v37i5.25705},
  urldate = {2024-06-21},
  abstract = {Cake-cutting is a fundamental model of dividing a heterogeneous resource, such as land, broadcast time, and advertisement space. In this study, we consider the problem of dividing indivisible goods fairly under the connectivity constraints of a path. We prove that a connected division of indivisible items satisfying a discrete counterpart of envy-freeness, called envy-freeness up to one good (EF1), always exists for any number of agents n with monotone valuations. Our result settles an open question raised by Bil{\`o} et al. (2019), who proved that an EF1 connected division always exists for four agents with monotone valuations. Moreover, the proof can be extended to show the following (1) ``secretive" and (2) ``extra" versions: (1) for n agents with monotone valuations, the path can be divided into n connected bundles such that an EF1 assignment of the remaining bundles can be made to the other agents for any selection made by the ``secretive agent''; (2) for n+1 agents with monotone valuations, the path can be divided into n connected bundles such that when any ``extra agent'' leaves, an EF1 assignment of the bundles can be made to the remaining agents.},
  copyright = {Copyright (c) 2023 Association for the Advancement of Artificial Intelligence},
  langid = {english},
  keywords = {GTEP: Social Choice / Voting},
  file = {/Users/sebastian/Zotero/storage/HJ3YTHYN/Igarashi - 2023 - How to Cut a Discrete Cake Fairly.pdf}
}

@inproceedings{ilevv.LocalSearchGraph2016,
  title = {A Local Search for a Graph Correlation Clustering},
  author = {Il'ev V. and Navrotskaya, A.},
  year = {2016},
  urldate = {2023-08-10},
  langid = {english}
}

@phdthesis{ishizuka2022tfnpFixpoints,
  title = {On {{TFNP}} Classes: {{Approaches}} from Fixed Point Theory and Algorithmic Game Theory},
  author = {Ishizuka, Takashi},
  year = {2022},
  school = {Kyushu University}
}

@book{IterativeApproximationFixed2007,
  title = {Iterative {{Approximation}} of {{Fixed Points}}},
  year = {2007},
  series = {Lecture {{Notes}} in {{Mathematics}}},
  volume = {1912},
  publisher = {Springer},
  address = {Berlin, Heidelberg},
  doi = {10.1007/978-3-540-72234-2},
  urldate = {2024-06-17},
  copyright = {http://www.springer.com/tdm},
  isbn = {978-3-540-72233-5},
  langid = {english},
  keywords = {calculus,convergence theorems,equation,fixed points,iterative methods,nonlinear contractive type operators,rate of convergence,theorem},
  file = {/Users/sebastian/Zotero/storage/C2TGB4G2/2007 - Iterative Approximation of Fixed Points.pdf}
}

@misc{ivanovSpernerLemma2022,
  title = {Beyond {{Sperner}}'s Lemma},
  author = {Ivanov, Nikolai V.},
  year = {2022},
  month = jul,
  number = {arXiv:1902.00827},
  eprint = {1902.00827},
  primaryclass = {math},
  publisher = {arXiv},
  doi = {10.48550/arXiv.1902.00827},
  urldate = {2024-03-18},
  abstract = {In 1967 Herbert Scarf suggested a new proof of Brouwer's fixed point theorem based on a combinatorial analogue of Sperner's lemma. Scarf presented his arguments in very geometric language, even purely combinatorial ones. Recently H. Petri and M. Voorneveld published an almost geometry-free version of Scarf's proof. Their version eliminated even only implicitly geometric aspects of Scarf's proof, namely, the structure of an abstract simplicial complex behind the combinatorial arguments. The present paper is devoted to a proof of Scarf's analogue of Sperner's lemma in the abstract setting of a collection of linear orders on a finite set. This proof partially follows the proof by Petri and Voorneveld, but restores the implicit geometry to its rightful place. We also deduce Brouwer's fixed point theorem from this analogue and discuss various versions of Scarf's proof.},
  archiveprefix = {arXiv},
  keywords = {55M20 55M25 (Primary) 05E45 06A99 (Secondary),Mathematics - Algebraic Topology},
  file = {/Users/sebastian/Zotero/storage/UFABCNPL/Ivanov - 2022 - Beyond Sperner's lemma.pdf;/Users/sebastian/Zotero/storage/37QWGW6A/1902.html}
}

@article{jacobLongDirectedDetours2024,
  title = {Long Directed Detours: {{Reduction}} to 2-{{Disjoint Paths}}},
  shorttitle = {Long Directed Detours},
  author = {Jacob, Ashwin and W{\l}odarczyk, Micha{\l} and Zehavi, Meirav},
  year = {2024},
  month = aug,
  journal = {Information Processing Letters},
  volume = {186},
  pages = {106491},
  issn = {00200190},
  doi = {10.1016/j.ipl.2024.106491},
  urldate = {2024-11-18},
  langid = {english},
  file = {/Users/sebastian/Zotero/storage/XRBURG9G/Jacob et al. - 2024 - Long directed detours Reduction to 2-Disjoint Paths.pdf}
}

@inproceedings{jadhavComputingCenterpointFinite1993,
  title = {Computing a Centerpoint of a Finite Planar Set of Points in Linear Time},
  booktitle = {Proceedings of the Ninth Annual Symposium on {{Computational}} Geometry},
  author = {Jadhav, Shreesh and Mukhopadhyay, Asish},
  year = {1993},
  month = jul,
  series = {{{SCG}} '93},
  pages = {83--90},
  publisher = {Association for Computing Machinery},
  address = {New York, NY, USA},
  doi = {10.1145/160985.161003},
  urldate = {2024-11-06},
  abstract = {The notion of a centerpoint of a finite set of points in two and higher dimensions is a generalisation of the concept of the median of a (finite) set of points on the real line. In this paper, we present an algorithm for computing a centerpoint of a set of n points in the plane. The algorithm has complexity O(n) which significantly improves the O(n log3 n) complexity of the previously best known algorithm. We use suitable modifications of the ham-sandwich-cut algorithm and the prune-and-search technique to achieve this improvement.},
  isbn = {978-0-89791-582-3},
  file = {/Users/sebastian/Zotero/storage/PGMMSU9A/Jadhav and Mukhopadhyay - 1993 - Computing a centerpoint of a finite planar set of points in linear time.pdf}
}

@article{jafarovFourAlgorithmsCorrelation2022,
  title = {Four {{Algorithms}} for {{Correlation Clustering}}: {{A Survey}}},
  shorttitle = {Four {{Algorithms}} for {{Correlation Clustering}}},
  author = {Jafarov, Jafar},
  year = {2022},
  publisher = {arXiv},
  doi = {10.48550/ARXIV.2208.12636},
  urldate = {2023-08-10},
  abstract = {In the Correlation Clustering problem, we are given a set of objects with pairwise similarity information. Our aim is to partition these objects into clusters that match this information as closely as possible. More specifically, the pairwise information is given as a weighted graph \$G\$ with its edges labelled as ``similar" or ``dissimilar" by a binary classifier. The goal is to produce a clustering that minimizes the weight of ``disagreements": the sum of the weights of similar edges across clusters and dissimilar edges within clusters. In this exposition we focus on the case when \$G\$ is complete and unweighted. We explore four approximation algorithms for the Correlation Clustering problem under this assumption. In particular, we describe the following algorithms: (i) the \$17429-\$approximation algorithm by Bansal, Blum, and Chawla, (ii) the \$4-\$approximation algorithm by Charikar, Guruswami, and Wirth (iii) the \$3-\$approximation algorithm by Ailon, Charikar, and Newman (iv) the \$2.06-\$approximation algorithm by Chawla, Makarychev, Schramm, and Yaroslavtsev.},
  copyright = {arXiv.org perpetual, non-exclusive license},
  keywords = {Data Structures and Algorithms (cs.DS),FOS: Computer and information sciences,Machine Learning (cs.LG)}
}

@misc{jainPigeonholePrinciplesRamsey2024,
  title = {On {{Pigeonhole Principles}} and {{Ramsey}} in {{TFNP}}},
  author = {Jain, Siddhartha and Li, Jiawei and Robere, Robert and Xun, Zhiyang},
  year = {2024},
  month = aug,
  number = {arXiv:2401.12604},
  eprint = {2401.12604},
  primaryclass = {cs},
  publisher = {arXiv},
  doi = {10.48550/arXiv.2401.12604},
  urldate = {2025-01-16},
  abstract = {We show that the TFNP problem RAMSEY is not black-box reducible to PIGEON, refuting a conjecture of Goldberg and Papadimitriou in the black-box setting. We prove this by giving reductions to RAMSEY from a new family of TFNP problems that correspond to generalized versions of the pigeonhole principle, and then proving that these generalized versions cannot be reduced to PIGEON. Formally, we define t-PPP as the class of total NP-search problems reducible to finding a t-collision in a mapping from (t-1)N+1 pigeons to N holes. These classes are closely related to multi-collision resistant hash functions in cryptography. We show that the generalized pigeonhole classes form a hierarchy as t increases, and also give a natural condition on the parameters t1, t2 that captures exactly when t1-PPP and t2-PPP collapse in the black-box setting. Finally, we prove other inclusion and separation results between these generalized PIGEON problems and other previously studied TFNP subclasses, such as PLS, PPA and PLC. Our separation results rely on new lower bounds in propositional proof complexity based on pseudoexpectation operators, which may be of independent interest.},
  archiveprefix = {arXiv},
  keywords = {Computer Science - Computational Complexity},
  file = {/Users/sebastian/Zotero/storage/LWRS7QQ2/Jain et al. - 2024 - On Pigeonhole Principles and Ramsey in TFNP.pdf;/Users/sebastian/Zotero/storage/FE68VJLM/2401.html}
}

@incollection{jiaExactBipartiteMatching2023,
  title = {The {{Exact Bipartite Matching Polytope Has Exponential Extension Complexity}}},
  booktitle = {Proceedings of the 2023 {{Annual ACM-SIAM Symposium}} on {{Discrete Algorithms}} ({{SODA}})},
  author = {Jia, Xinrui and Svensson, Ola and Yuan, Weiqiang},
  year = {2023},
  month = jan,
  series = {Proceedings},
  pages = {1635--1654},
  publisher = {{Society for Industrial and Applied Mathematics}},
  doi = {10.1137/1.9781611977554.ch61},
  urldate = {2024-04-05},
  abstract = {Given a graph with edges colored red or blue and an integer k, the exact perfect matching problem asks if there exists a perfect matching with exactly k red edges. There exists a randomized polylogarithmic-time parallel algorithm to solve this problem, dating back to the eighties, but no deterministic polynomial-time algorithm is known, even for bipartite graphs. In this paper we show that there is no sub-exponential sized linear program that can describe the convex hull of exact matchings in bipartite graphs. In fact, we prove something stronger, that there is no sub-exponential sized linear program to describe the convex hull of perfect matchings with an odd number of red edges.},
  file = {/Users/sebastian/Zotero/storage/9IL7VBM5/Jia et al. - 2023 - The Exact Bipartite Matching Polytope Has Exponent.pdf}
}

@incollection{johnsonBasicConceptsGeometry2001,
  title = {Basic {{Concepts}} in the {{Geometry}} of {{Banach Spaces}}},
  booktitle = {Handbook of the {{Geometry}} of {{Banach Spaces}}},
  author = {Johnson, William B. and Lindenstrauss, Joram},
  year = {2001},
  volume = {1},
  pages = {1--84},
  publisher = {Elsevier},
  doi = {10.1016/S1874-5849(01)80003-6},
  urldate = {2024-11-26},
  copyright = {https://www.elsevier.com/tdm/userlicense/1.0/},
  isbn = {978-0-444-82842-2},
  langid = {english},
  file = {/Users/sebastian/Zotero/storage/SHEEY4VY/Johnson and Lindenstrauss - 2001 - Basic Concepts in the Geometry of Banach Spaces.pdf}
}

@article{johnsonEfficientAlgorithmsShortest1977,
  title = {Efficient {{Algorithms}} for {{Shortest Paths}} in {{Sparse Networks}}},
  author = {Johnson, Donald B.},
  year = {1977},
  month = jan,
  journal = {Journal of the ACM},
  volume = {24},
  number = {1},
  pages = {1--13},
  issn = {0004-5411},
  doi = {10.1145/321992.321993},
  urldate = {2024-04-05},
  abstract = {Algorithms for finding shortest paths are presented which are faster than algorithms previously known on networks which are relatively sparse in arcs. Known results which the results of this paper extend are surveyed briefly and analyzed. A new implementation for priority queues is employed, and a class of ``arc set partition'' algorithms is introduced. For the single source problem on networks with nonnegative arcs a running time of O(min(n1+1/k + e, n + e) log n)) is achieved, where there are n nodes and e arcs, and k is a fixed integer satisfying k {$>$} 0. This bound is O(e) on dense networks. For the single source and all pairs problem on unrestricted networks the running time is O(min(n2+1/k + ne, n2 log n + ne log n).},
  file = {/Users/sebastian/Zotero/storage/SVF36RAM/Johnson - 1977 - Efficient Algorithms for Shortest Paths in Sparse .pdf}
}

@inproceedings{jurdzinskiSmallProgressMeasures2000,
  title = {Small {{Progress Measures}} for {{Solving Parity Games}}},
  booktitle = {{{STACS}} 2000},
  author = {Jurdzi{\'n}ski, Marcin},
  year = {2000},
  pages = {290--301},
  publisher = {Springer},
  address = {Berlin, Heidelberg},
  doi = {10.1007/3-540-46541-3_24},
  abstract = {In this paper we develop a new algorithm for deciding the winner in parity games, and hence also for the modal {$\mu$}-calculus model checking. The design and analysis of the algorithm is based on a notion of game progress measures: they are witnesses for winning strategies in parity games. We characterize game progress measures as pre-fixed points of certain monotone operators on a complete lattice. As a result we get the existence of the least game progress measures and a straightforward way to compute them. The worst-case running time of our algorithm matches the best worst-case running time bounds known so far for the problem, achieved by the algorithms due to Browne et al., and Seidl. Our algorithm has better space complexity: it works in small polynomial space; the other two algorithms have exponential worst-case space complexity.},
  isbn = {978-3-540-46541-6},
  langid = {english},
  keywords = {Complete Lattice,Kripke Structure,Model Check,Monotone Operator,Winning Strategy},
  file = {/Users/sebastian/Zotero/storage/C2PD38WF/Jurdziński - 2000 - Small Progress Measures for Solving Parity Games.pdf}
}

@inproceedings{jurdzinskiSuccinctProgressMeasures2017,
  title = {Succinct Progress Measures for Solving Parity Games},
  booktitle = {2017 32nd {{Annual ACM}}/{{IEEE Symposium}} on {{Logic}} in {{Computer Science}} ({{LICS}})},
  author = {Jurdzi{\'n}ski, Marcin and Lazi{\'c}, Ranko},
  year = {2017},
  month = jun,
  pages = {1--9},
  doi = {10.1109/LICS.2017.8005092},
  urldate = {2024-06-11},
  abstract = {The recent breakthrough paper by Calude et al. has given the first algorithm for solving parity games in quasi-polynomial time, where previously the best algorithms were mildly subexponential. We devise an alternative quasi-polynomial time algorithm based on progress measures, which allows us to reduce the space required from quasi-polynomial to nearly linear. Our key technical tools are a novel concept of ordered tree coding, and a succinct tree coding result that we prove using bounded adaptive multi-counters, both of which are interesting in their own right.},
  file = {/Users/sebastian/Zotero/storage/UVFAKWZI/Jurdziński and Lazić - 2017 - Succinct progress measures for solving parity game.pdf;/Users/sebastian/Zotero/storage/56XRY4YM/8005092.html}
}

@misc{juttnerShortestOddPaths2023,
  title = {Shortest {{Odd Paths}} in {{Undirected Graphs}} with {{Conservative Weight Functions}}},
  author = {J{\"u}ttner, Alp{\'a}r and Kir{\'a}ly, Csaba and {Mendoza-Cadena}, Lydia Mirabel and Pap, Gyula and Schlotter, Ildik{\'o} and Yamaguchi, Yutaro},
  year = {2023},
  month = aug,
  number = {arXiv:2308.12653},
  eprint = {2308.12653},
  primaryclass = {cs, math},
  publisher = {arXiv},
  doi = {10.48550/arXiv.2308.12653},
  urldate = {2024-04-05},
  abstract = {We consider the Shortest Odd Path problem, where given an undirected graph \$G\$, a weight function on its edges, and two vertices \$s\$ and \$t\$ in \$G\$, the aim is to find an \$(s,t)\$-path with odd length and, among all such paths, of minimum weight. For the case when the weight function is conservative, i.e., when every cycle has non-negative total weight, the complexity of the Shortest Odd Path problem had been open for 20 years, and was recently shown to be NP-hard. We give a polynomial-time algorithm for the special case when the weight function is conservative and the set \$E{\textasciicircum}-\$ of negative-weight edges forms a single tree. Our algorithm exploits the strong connection between Shortest Odd Path and the problem of finding two internally vertex-disjoint paths between two terminals in an undirected edge-weighted graph. It also relies on solving an intermediary problem variant called Shortest Parity-Constrained Odd Path where for certain edges we have parity constraints on their position along the path. Also, we exhibit two FPT algorithms for solving Shortest Odd Path in graphs with conservative weight functions. The first FPT algorithm is parameterized by \${\textbar}E{\textasciicircum}-{\textbar}\$, the number of negative edges, or more generally, by the maximum size of a matching in the subgraph of \$G\$ spanned by \$E{\textasciicircum}-\$. Our second FPT algorithm is parameterized by the treewidth of \$G\$.},
  archiveprefix = {arXiv},
  keywords = {Computer Science - Data Structures and Algorithms,Mathematics - Optimization and Control},
  file = {/Users/sebastian/Zotero/storage/VY5GAVIG/Jüttner et al. - 2023 - Shortest Odd Paths in Undirected Graphs with Conse.pdf;/Users/sebastian/Zotero/storage/9CLUE9JH/2308.html}
}

@article{kabanetsDerandomizingPolynomialIdentity2004,
  title = {Derandomizing {{Polynomial Identity Tests Means Proving Circuit Lower Bounds}}},
  author = {Kabanets, Valentine and Impagliazzo, Russell},
  year = {2004},
  month = dec,
  journal = {computational complexity},
  volume = {13},
  number = {1},
  pages = {1--46},
  issn = {1420-8954},
  doi = {10.1007/s00037-004-0182-6},
  urldate = {2024-04-05},
  abstract = {We show that derandomizing Polynomial Identity Testing is essentially equivalent to proving arithmetic circuit lower bounds for NEXP. More precisely, we prove that if one can test in polynomial time (or even nondeterministic subexponential time, infinitely often) whether a given arithmetic circuit over integers computes an identically zero polynomial, then either (i)\% MathType!Translator!2!1!AMS LaTeX.tdl!TeX -- AMS-LaTeX!\% MathType!MTEF!2!1!+-\% feaafiart1ev1aqatCvAUfeBSjuyZL2yd9gzLbvyNv2CaerbuLwBLn\% hiov2DGi1BTfMBaeXatLxBI9gBaerbd9wDYLwzYbItLDharqqtubsr\% 4rNCHbGeaGqiVu0Je9sqqrpepC0xbbL8F4rqqrFfpeea0xe9Lq-Jc9\% vqaqpepm0xbba9pwe9Q8fs0-yqaqpepae9pg0FirpepeKkFr0xfr-x\% fr-xb9adbaqaaeGaciGaaiaabeqaamaabaabaaGcbaGaaeOtaiaabw\% eacaqGybGaaeiuaiabgsOillaabcfaruqtLrxyqXwDZj0BSrwldfgC\% ZbacfaGaa83laiaabchacaqGVbGaaeiBaiaabMhacaqGGaGaae4Bai\% aabkhaaaa!4992!\$\$\{{\textbackslash}text\{NEXP\}\} {\textbackslash}not{\textbackslash}subset \{{\textbackslash}text\{P\}\}/\{{\textbackslash}text\{poly or\}\}\$\$(ii) Permanent is not computable by polynomial-size arithmetic circuits. We also prove a (partial) converse: If Permanent requires superpolynomial-size arithmetic circuits, then one can test in subexponential time whether a given arithmetic circuit of polynomially bounded degree computes an identically zero polynomial.},
  langid = {english},
  keywords = {68Q10,68Q15,68Q17,circuit lower bounds,derandomization,hardness-randomness tradeoffs,polynomial identity testing},
  file = {/Users/sebastian/Zotero/storage/PCF4PIRX/Kabanets and Impagliazzo - 2004 - Derandomizing Polynomial Identity Tests Means Prov.pdf}
}

@inproceedings{kalaiSubexponentialRandomizedSimplex1992,
  title = {A Subexponential Randomized Simplex Algorithm (Extended Abstract)},
  booktitle = {Proceedings of the Twenty-Fourth Annual {{ACM}} Symposium on {{Theory}} of Computing  - {{STOC}} '92},
  author = {Kalai, Gil},
  year = {1992},
  pages = {475--482},
  publisher = {ACM Press},
  address = {Victoria, British Columbia, Canada},
  doi = {10.1145/129712.129759},
  urldate = {2024-04-24},
  isbn = {978-0-89791-511-3},
  langid = {english},
  file = {/Users/sebastian/Zotero/storage/9KA4SZIX/Kalai - 1992 - A subexponential randomized simplex algorithm (ext.pdf}
}

@article{kaoQuadraticAlgorithmFinding2011,
  title = {A {{Quadratic Algorithm}} for {{Finding Next-to-Shortest Paths}} in {{Graphs}}},
  author = {Kao, Kuo-Hua and Chang, Jou-Ming and Wang, Yue-Li and Juan, Justie Su-Tzu},
  year = {2011},
  month = oct,
  journal = {Algorithmica},
  volume = {61},
  number = {2},
  pages = {402--418},
  issn = {1432-0541},
  doi = {10.1007/s00453-010-9402-4},
  urldate = {2024-09-20},
  abstract = {Given an edge-weighted undirected graph G and two prescribed vertices u and v, a next-to-shortest (u,v)-path is a shortest (u,v)-path amongst all (u,v)-paths having length strictly greater than the length of a shortest (u,v)-path. In this paper, we deal with the problem of computing a next-to-shortest (u,v)-path. We propose an \$\{{\textbackslash}mathcal\{O\}\}(n{\textasciicircum}\{2\})\$time algorithm for solving this problem, which significantly improves the bound of a previous one in \$\{{\textbackslash}mathcal\{O\}\}(n{\textasciicircum}\{3\})\$time where n is the number of vertices in~G.},
  langid = {english},
  keywords = {Graph algorithms,Next-to-shortest paths,Strictly-second-shortest paths},
  file = {/Users/sebastian/Zotero/storage/Y23PY6ZZ/Kao et al. - 2011 - A Quadratic Algorithm for Finding Next-to-Shortest.pdf}
}

@inproceedings{karpinskiLinearTimeApproximation2009,
  title = {Linear Time Approximation Schemes for the {{Gale-Berlekamp}} Game and Related Minimization Problems},
  booktitle = {Proceedings of the Forty-First Annual {{ACM}} Symposium on {{Theory}} of Computing},
  author = {Karpinski, Marek and Schudy, Warren},
  year = {2009},
  month = may,
  pages = {313--322},
  publisher = {ACM},
  address = {Bethesda MD USA},
  doi = {10.1145/1536414.1536458},
  urldate = {2023-08-10},
  isbn = {978-1-60558-506-2},
  langid = {english},
  file = {/Users/sebastian/Zotero/storage/73M5LSNN/Karpinski and Schudy - 2009 - Linear time approximation schemes for the Gale-Ber.pdf}
}

@article{karthikc.s.DidTrainReach2017,
  title = {Did the {{Train Reach}} Its {{Destination}}: {{The Complexity}} of {{Finding}} a {{Witness}}},
  shorttitle = {Did the Train Reach Its Destination},
  author = {{Karthik C. S.}},
  year = {2017},
  month = may,
  journal = {Information Processing Letters},
  volume = {121},
  pages = {17--21},
  issn = {0020-0190},
  doi = {10.1016/j.ipl.2017.01.004},
  urldate = {2025-01-24},
  abstract = {Recently, Dohrau et al. studied a zero-player game on switch graphs and proved that deciding the termination of the game is in NP{$\cap$}coNP. In this short paper, we show that the search version of this game on switch graphs, i.e., the task of finding a witness of termination (or of non-termination) is in PLS.},
  keywords = {Cellular automaton,Combinatorial problems,PLS,Switch graphs},
  file = {/Users/sebastian/Zotero/storage/MSQCTFYI/Karthik C. S. - 2017 - Did the train reach its destination The complexity of finding a witness.pdf;/Users/sebastian/Zotero/storage/DS8PFPZF/S0020019017300042.html}
}

@article{karzanovMaximumMatchingGiven1987,
  title = {Maximum Matching of given Weight in Complete and Complete Bipartite Graphs},
  author = {Karzanov, A. V.},
  year = {1987},
  month = jan,
  journal = {Cybernetics},
  volume = {23},
  number = {1},
  pages = {8--13},
  issn = {1573-8337},
  doi = {10.1007/BF01068796},
  urldate = {2024-04-05},
  langid = {english},
  keywords = {Artificial Intelligence,Bipartite Graph,Maximum Match,Operating System,System Theory},
  file = {/Users/sebastian/Zotero/storage/IU779638/Karzanov - 1987 - Maximum matching of given weight in complete and c.pdf}
}

@article{khoslaComparativeStudyUnsupervised2020,
  title = {A {{Comparative Study}} for {{Unsupervised Network Representation Learning}}},
  author = {Khosla, Megha and Setty, Vinay and Anand, Avishek},
  year = {2020},
  journal = {IEEE Transactions on Knowledge and Data Engineering},
  pages = {1--1},
  issn = {1041-4347, 1558-2191, 2326-3865},
  doi = {10.1109/TKDE.2019.2951398},
  urldate = {2023-08-10},
  file = {/Users/sebastian/Zotero/storage/8FGMSRMU/Khosla et al. - 2020 - A Comparative Study for Unsupervised Network Repre.pdf}
}

@article{kireevaRandomizedMatrixComputations2023,
  title = {Randomized Matrix Computations: {{Themes}} and Variations},
  shorttitle = {Randomized Matrix Computations},
  author = {Kireeva, Anastasia and Tropp, Joel A.},
  year = {2023},
  month = jul,
  eprint = {2402.17873},
  primaryclass = {math},
  doi = {10.7907/7yade-5k351},
  urldate = {2025-01-17},
  abstract = {This short course offers a new perspective on randomized algorithms for matrix computations. It explores the distinct ways in which probability can be used to design algorithms for numerical linear algebra. Each design template is illustrated by its application to several computational problems. This treatment establishes conceptual foundations for randomized numerical linear algebra, and it forges links between algorithms that may initially seem unrelated.},
  archiveprefix = {arXiv},
  keywords = {Computer Science - Numerical Analysis,Mathematics - Numerical Analysis,Mathematics - Probability},
  file = {/Users/sebastian/Zotero/storage/AEW4BG9R/Kireeva and Tropp - 2023 - Randomized matrix computations Themes and variations.pdf}
}

@book{korteCombinatorialOptimizationTheory2018,
  title = {Combinatorial {{Optimization}}: {{Theory}} and {{Algorithms}}},
  shorttitle = {Combinatorial {{Optimization}}},
  author = {Korte, Bernhard and Vygen, Jens},
  year = {2018},
  series = {Algorithms and {{Combinatorics}}},
  volume = {21},
  publisher = {Springer},
  address = {Berlin, Heidelberg},
  doi = {10.1007/978-3-662-56039-6},
  urldate = {2024-04-23},
  copyright = {https://www.springer.com/tdm},
  isbn = {978-3-662-56038-9 978-3-662-56039-6},
  langid = {english},
  keywords = {approximation algorithms,combinatorial optimization,combinatorics,discrete algorithms,facility location,graphs,integer linear programming,matching,mathematical programming,matroids,network design,network flows,traveling salesman problem},
  file = {/Users/sebastian/Zotero/storage/2AHL65T6/Korte and Vygen - 2018 - Combinatorial Optimization Theory and Algorithms.pdf}
}

@article{koshelevErdosSzekeresProblem2007,
  title = {On the {{Erd{\"o}s-Szekeres}} Problem},
  author = {Koshelev, V. A.},
  year = {2007},
  month = aug,
  journal = {Doklady Mathematics},
  volume = {76},
  number = {1},
  pages = {603--605},
  issn = {1064-5624, 1531-8362},
  doi = {10.1134/S106456240704031X},
  urldate = {2023-08-10},
  langid = {english}
}

@book{Krajíček_2019,
  title = {Proof Complexity},
  author = {Kraj{\'i}{\v c}ek, Jan},
  year = {2019},
  series = {Encyclopedia of Mathematics and Its Applications},
  publisher = {Cambridge University Press},
  address = {Cambridge},
  file = {/Users/sebastian/Zotero/storage/E7SHA5BZ/Krajíček - 2019 - Proof complexity.pdf}
}

@article{krasikovFindingNextshortestPaths2004,
  title = {Finding Next-to-Shortest Paths in a Graph},
  author = {Krasikov, I. and Noble, S. D.},
  year = {2004},
  month = nov,
  journal = {Information Processing Letters},
  volume = {92},
  number = {3},
  pages = {117--119},
  issn = {0020-0190},
  doi = {10.1016/j.ipl.2004.06.020},
  urldate = {2024-09-20},
  abstract = {We study the problem of finding the next-to-shortest paths in a graph. A next-to-shortest (u,v)-path is a shortest (u,v)-path amongst (u,v)-paths with length strictly greater than the length of the shortest (u,v)-path. In contrast to the situation in directed graphs, where the problem has been shown to be NP-hard, providing edges of length zero are allowed, we prove the somewhat surprising result that there is a polynomial time algorithm for the undirected version of the problem.},
  keywords = {Computational complexity,Graph algorithms,Shortest paths},
  file = {/Users/sebastian/Zotero/storage/V9LAIH9Q/Krasikov and Noble - 2004 - Finding next-to-shortest paths in a graph.pdf}
}

@incollection{krauseSubmodularFunctionMaximization2014,
  title = {Submodular {{Function Maximization}}},
  booktitle = {Tractability: {{Practical Approaches}} to {{Hard Problems}}},
  author = {Krause, Andreas and Golovin, Daniel},
  year = {2014},
  pages = {71--104},
  publisher = {Cambridge University Press},
  address = {Cambridge},
  doi = {10.1017/CBO9781139177801.004},
  urldate = {2025-01-15},
  abstract = {In this chapter we will introduce submodularity and some of its generalizations, illustrate how it arises in various applications, and discuss algorithms for optimizing submodular functions.Submodularity is a property of set functions with deep theoretical consequences and far-reaching applications. At first glance it seems very similar to concavity, in other ways it resembles convexity. It appears in a wide variety of applications: in Computer Science it has recently been identified and utilized in domains such as viral marketing [39], information gathering [44], image segmentation [10, 40, 36], document summarization [56], and speeding up satisfiability solvers [73]. Our emphasis in this chapter is on maximization; there are many important results and applications related to minimizing submodular functions that we do not cover.As a concrete running example, we will consider the problem of deploying sensors in a drinking water distribution network (see Figure 3.1) in order to detect contamination. In this domain, we may have a model of how contaminants, accidentally or maliciously introduced into the network, spread over time. Such a model then allows to quantify the benefit f(A) of deploying sensors at a particular set A of locations (junctions or pipes in the network) in terms of the detection performance (such as average time to detection).Based on this notion of utility, we then wish to find an optimal subset A {$\subseteq$} V of locations maximizing the utility, maxAf(A), subject to some constraints (such as bounded cost). This application requires solving a difficult real-world optimization problem, that can be handled with the techniques discussed in this chapter (Krause et al. [49] show in detail how submodular optimization can be applied in this domain.)},
  isbn = {978-1-107-02519-6},
  file = {/Users/sebastian/Zotero/storage/N7EWK6RF/Krause and Golovin - 2014 - Submodular Function Maximization.pdf;/Users/sebastian/Zotero/storage/MI22QNZJ/C1925D301CBF7D7BBC55E44644A1ABA1.html}
}

@article{kretinskyComparisonAlgorithmsSimple2022,
  title = {Comparison of Algorithms for Simple Stochastic Games},
  author = {K{\v r}et{\'i}nsk{\'y}, Jan and Ramneantu, Emanuel and Slivinskiy, Alexander and Weininger, Maximilian},
  year = {2022},
  month = nov,
  journal = {Information and Computation},
  series = {Special {{Issue}} on 11th {{Int}}. {{Symp}}. on {{Games}}, {{Automata}}, {{Logics}} and {{Formal Verification}}},
  volume = {289},
  pages = {104885},
  issn = {0890-5401},
  doi = {10.1016/j.ic.2022.104885},
  urldate = {2024-04-24},
  abstract = {Simple stochastic games are turn-based 2{$\frac{1}{2}$}-player zero-sum graph games with a reachability objective. The problem is to compute the winning probabilities as well as the optimal strategies of both players. In this paper, we compare the three known classes of algorithms -- value iteration, strategy iteration and quadratic programming -- both theoretically and practically. Further, we suggest several improvements for all algorithms, including the first approach based on quadratic programming that avoids transforming the stochastic game to a stopping one. Our extensive experiments show that these improvements can lead to significant speed-ups. We implemented all algorithms in PRISM-games 3.0, thereby providing the first implementation of quadratic programming for solving simple stochastic games.},
  keywords = {Algorithms,Formal methods,Probabilistic verification,Quadratic programming,Stochastic games,Strategy iteration,Value iteration},
  file = {/Users/sebastian/Zotero/storage/E8ZDNQCW/Křetínský et al. - 2022 - Comparison of algorithms for simple stochastic gam.pdf}
}

@article{ladnerStructurePolynomialTime1975,
  title = {On the {{Structure}} of {{Polynomial Time Reducibility}}},
  author = {Ladner, Richard E.},
  year = {1975},
  month = jan,
  journal = {Journal of the ACM},
  volume = {22},
  number = {1},
  pages = {155--171},
  issn = {0004-5411},
  doi = {10.1145/321864.321877},
  urldate = {2024-04-24},
  file = {/Users/sebastian/Zotero/storage/PXER3D7Z/Ladner - 1975 - On the Structure of Polynomial Time Reducibility.pdf}
}

@article{lalgudiComputingStrictlysecondShortest1997,
  title = {Computing Strictly-Second Shortest Paths},
  author = {Lalgudi, Kumar N. and Papaefthymiou, Marios C.},
  year = {1997},
  month = aug,
  journal = {Information Processing Letters},
  volume = {63},
  number = {4},
  pages = {177--181},
  issn = {0020-0190},
  doi = {10.1016/S0020-0190(97)00122-1},
  urldate = {2024-09-20},
  abstract = {We investigate the problem of computing the strictly-second shortest path connecting a given pair of vertices in a directed graph. We show that this problem is intractable when the path is restricted to be simple. When cycles are allowed, we give an algorithm that solves it in asymptotically the same number of steps as it takes to compute the shortest path between the given vertex pair.},
  keywords = {-shortest paths,Algorithms,Shortest paths},
  file = {/Users/sebastian/Zotero/storage/U25TGRP7/Lalgudi and Papaefthymiou - 1997 - Computing strictly-second shortest paths.pdf}
}

@article{leeTwoDimensionalVoronoiDiagrams1980,
  title = {Two-{{Dimensional Voronoi Diagrams}} in the {{Lp-Metric}}},
  author = {Lee, D. T.},
  year = {1980},
  month = oct,
  journal = {J. ACM},
  volume = {27},
  number = {4},
  pages = {604--618},
  issn = {0004-5411},
  doi = {10.1145/322217.322219},
  urldate = {2024-11-26},
  file = {/Users/sebastian/Zotero/storage/2GQXUNPF/Lee - 1980 - Two-Dimensional Voronoi Diagrams in the Lp-Metric.pdf}
}

@article{lehtinenRecursiveApproachSolving2022,
  title = {A {{Recursive Approach}} to {{Solving Parity Games}} in {{Quasipolynomial Time}}},
  author = {Lehtinen, Karoliina and Parys, Pawe{\l} and Schewe, Sven and Wojtczak, Dominik},
  year = {2022},
  month = jan,
  journal = {Logical Methods in Computer Science},
  volume = {Volume 18, Issue 1},
  publisher = {Episciences.org},
  issn = {1860-5974},
  doi = {10.46298/lmcs-18(1:8)2022},
  urldate = {2024-06-11},
  abstract = {Zielonka's classic recursive algorithm for solving parity games is perhaps the simplest among the many existing parity game algorithms. However, its complexity is exponential, while currently the state-of-the-art algorithms have quasipolynomial complexity. Here, we present a modification of Zielonka's classic algorithm that brings its complexity down to \$n{\textasciicircum}\{O{\textbackslash}left({\textbackslash}log{\textbackslash}left(1+{\textbackslash}frac\{d\}\{{\textbackslash}log n\}{\textbackslash}right){\textbackslash}right)\}\$, for parity games of size \$n\$ with \$d\$ priorities, in line with previous quasipolynomial-time solutions.},
  file = {/Users/sebastian/Zotero/storage/X2F2MHXS/Lehtinen et al. - 2022 - A Recursive Approach to Solving Parity Games in Qu.pdf}
}

@article{lenstraIntegerProgrammingFixed1983,
  title = {Integer {{Programming}} with a {{Fixed Number}} of {{Variables}}},
  author = {Lenstra, H. W.},
  year = {1983},
  month = nov,
  journal = {Mathematics of Operations Research},
  volume = {8},
  number = {4},
  pages = {538--548},
  issn = {0364-765X, 1526-5471},
  doi = {10.1287/moor.8.4.538},
  urldate = {2023-08-10},
  abstract = {It is shown that the integer linear programming problem with a fixed number of variables is polynomially solvable. The proof depends on methods from geometry of numbers.},
  langid = {english},
  file = {/Users/sebastian/Zotero/storage/TVGV3S9Z/Lenstra - 1983 - Integer Programming with a Fixed Number of Variabl.pdf}
}

@inproceedings{leskovecSignedNetworksSocial2010,
  title = {Signed Networks in Social Media},
  booktitle = {Proceedings of the {{SIGCHI Conference}} on {{Human Factors}} in {{Computing Systems}}},
  author = {Leskovec, Jure and Huttenlocher, Daniel and Kleinberg, Jon},
  year = {2010},
  month = apr,
  pages = {1361--1370},
  publisher = {ACM},
  address = {Atlanta Georgia USA},
  doi = {10.1145/1753326.1753532},
  urldate = {2023-08-10},
  isbn = {978-1-60558-929-9},
  langid = {english},
  file = {/Users/sebastian/Zotero/storage/7R86KP67/Leskovec et al. - 2010 - Signed networks in social media.pdf}
}

@article{liImprovedAlgorithmFinding2006,
  title = {Improved Algorithm for Finding Next-to-Shortest Paths},
  author = {Li, Shisheng and Sun, Guangzhong and Chen, Guoliang},
  year = {2006},
  month = sep,
  journal = {Information Processing Letters},
  volume = {99},
  number = {5},
  pages = {192--194},
  issn = {0020-0190},
  doi = {10.1016/j.ipl.2006.04.013},
  urldate = {2024-09-20},
  abstract = {We study the problem of finding the next-to-shortest paths in a weighted undirected graph. A next-to-shortest (u,v)-path is a shortest (u,v)-path amongst (u,v)-paths with length strictly greater than the length of the shortest (u,v)-path. The first polynomial algorithm for this problem was presented in [I. Krasikov, S.D. Noble, Finding next-to-shortest paths in a graph, Inform. Process. Lett. 92 (2004) 117--119]. We improve the upper bound from O(n3m) to O(n3).},
  keywords = {Computational complexity,Graph algorithms,Shortest paths}
}

@inproceedings{liIntersectionClassesTFNP2024,
  title = {Intersection {{Classes}} in {{TFNP}} and {{Proof Complexity}}},
  booktitle = {{{DROPS-IDN}}/v2/Document/10.4230/{{LIPIcs}}.{{ITCS}}.2024.74},
  author = {Li, Yuhao and Pires, William and Robere, Robert},
  year = {2024},
  publisher = {Schloss Dagstuhl -- Leibniz-Zentrum f{\"u}r Informatik},
  doi = {10.4230/LIPIcs.ITCS.2024.74},
  urldate = {2024-06-17},
  abstract = {A recent breakthrough in the theory of total NP search problems (TFNP) by Fearnley, Goldberg, Hollender, and Savani has shown that CLS = PLS {$\cap$} PPAD, or, in other words, the class of problems reducible to gradient descent are exactly those problems in the intersection of the complexity classes PLS and PPAD. Since this result, two more intersection theorems have been discovered in this theory: EOPL = PLS {$\cap$} PPAD and SOPL = PLS {$\cap$} PPADS. It is natural to wonder if this exhausts the list of intersection classes in TFNP, or, if other intersections exist. In this work, we completely classify all intersection classes involved among the classical TFNP classes PLS, PPAD, and PPA, giving new complete problems for the newly-introduced intersections. Following the close links between the theory of TFNP and propositional proof complexity, we develop new proof systems - each of which is a generalization of the classical Resolution proof system - that characterize all of the classes, in the sense that a query total search problem is in the intersection class if and only if a tautology associated with the search problem has a short proof in the proof system. We complement these new characterizations with black-box separations between all of the newly introduced classes and prior classes, thus giving strong evidence that no further collapse occurs. Finally, we characterize arbitrary intersections and joins of the PPA\_q classes for q {$\geq$} 2 in terms of the Nullstellensatz proof systems.},
  copyright = {https://creativecommons.org/licenses/by/4.0/legalcode},
  langid = {english},
  file = {/Users/sebastian/Zotero/storage/A2FJQBXL/Li et al. - 2024 - Intersection Classes in TFNP and Proof Complexity.pdf}
}

@article{lingasIterativeMergingHeuristics2014,
  title = {Iterative Merging Heuristics for Correlation Clustering},
  author = {Lingas, Andrzej and Persson, Mia and Sledneu, Dzmitry},
  year = {2014},
  journal = {International Journal of Metaheuristics},
  volume = {3},
  number = {2},
  pages = {105},
  issn = {1755-2176, 1755-2184},
  doi = {10.1504/IJMHEUR.2014.063141},
  urldate = {2023-08-10},
  langid = {english}
}

@inproceedings{liTotalNPSearch2024a,
  title = {Total {{NP Search Problems}} with {{Abundant Solutions}}},
  booktitle = {15th {{Innovations}} in {{Theoretical Computer Science Conference}} ({{ITCS}} 2024)},
  author = {Li, Jiawei},
  year = {2024},
  series = {Leibniz {{International Proceedings}} in {{Informatics}} ({{LIPIcs}})},
  volume = {287},
  pages = {75:1--75:23},
  publisher = {Schloss Dagstuhl -- Leibniz-Zentrum f{\"u}r Informatik},
  address = {Dagstuhl, Germany},
  issn = {1868-8969},
  doi = {10.4230/LIPIcs.ITCS.2024.75},
  urldate = {2025-01-16},
  isbn = {978-3-95977-309-6},
  keywords = {Pigeonhole Principle,TFNP},
  file = {/Users/sebastian/Zotero/storage/W8FVEYUE/Li - 2024 - Total NP Search Problems with Abundant Solutions.pdf;/Users/sebastian/Zotero/storage/RH69YNL2/LIPIcs.ITCS.2024.html}
}

@article{lovaszMatchingStructureMatching1987,
  title = {Matching Structure and the Matching Lattice},
  author = {Lov{\'a}sz, L{\'a}szl{\'o}},
  year = {1987},
  month = oct,
  journal = {Journal of Combinatorial Theory, Series B},
  volume = {43},
  number = {2},
  pages = {187--222},
  issn = {0095-8956},
  doi = {10.1016/0095-8956(87)90021-9},
  urldate = {2024-01-05},
  abstract = {The matching polyhedron, i.e., the convex hull of (incidence vectors of) perfect matchings of a graph was characterized by Edmonds; this result is the key to a large part of polyhedral combinatorics and is used in many combinatorial algorithms. The linear hull of perfect matchings was characterized by Naddef, and by Edmonds, Lov{\'a}sz, and Pulleyblank. In this paper we describe the lattice generated by these vectors, i.e., the set of all integer linear combinations of perfect matchings. It turns out that the Petersen graph is, in a sense, the only difficult example. Our results also imply a characterization of the linear hull of perfect matchings over fields of characteristic different from 0. The main method is a decomposition theory developed by Kotzig, Lov{\'a}sz, and Plummer, which breaks down every graph into a number of graphs called bricks with very good matching properties. The number of Petersen graphs among these bricks will turn out to be an essential parameter of the matching lattice. Some refinements of the decomposition theory are also given. Among others, we show that the list of bricks obtained during the decomposition procedure is independent of the special choices made during the procedure.},
  file = {/Users/sebastian/Zotero/storage/SQEU74IJ/0095895687900219.html}
}

@article{ludwigHellysTheoremIts1963,
  title = {Helly's Theorem and Its Relatives},
  author = {Ludwig, Danzer and Branko, Gr{\"u}nbaum and Victor, Klee},
  year = {1963},
  journal = {Proceedings of Symposia in Pure Mathematics},
  pages = {101--180},
  publisher = {American Mathematical Society},
  issn = {0082-0717},
  doi = {10.1090/pspum/007/0157289},
  urldate = {2024-11-06},
  file = {/Users/sebastian/Zotero/storage/TBA9ZCEZ/Ludwig et al. - 1963 - Helly’s theorem and its relatives.pdf}
}

@article{ludwigSubexponentialRandomizedAlgorithm1995,
  title = {A {{Subexponential Randomized Algorithm}} for the {{Simple Stochastic Game Problem}}},
  author = {Ludwig, W.},
  year = {1995},
  month = feb,
  journal = {Information and Computation},
  volume = {117},
  number = {1},
  pages = {151--155},
  issn = {08905401},
  doi = {10.1006/inco.1995.1035},
  urldate = {2023-08-10},
  langid = {english},
  file = {/Users/sebastian/Zotero/storage/DZCTLRDZ/1-s2.0-S0890540185710358-main.pdf}
}

@misc{manuellSimpleLowerBound2021,
  title = {A Simple Lower Bound for {{ARRIVAL}}},
  author = {Manuell, Graham},
  year = {2021},
  month = aug,
  journal = {arXiv.org},
  urldate = {2025-01-24},
  abstract = {The ARRIVIAL problem introduced by Dohrau, G{\textbackslash}"artner, Kohler, Matou{\textbackslash}v\{s\}ek and Welzl concerns a train moving on a directed graph proceeding along outward edges according to the position of 'switches' at each vertex, which in turn are toggled whenever the train passes through them. The problem asks whether the train every reaches a designated destination vertex. It is known that ARRIVAL is contained in UP \${\textbackslash}cap\$ coUP, while the previously best published lower bound is that it is NL-hard. In this note we provide a simple reduction to the \${\textbackslash}mathsf\{DIGICOMP\}\_{\textbackslash}mathsf\{EXP\}\$ problem considered by Aaronson. It follows in particular that ARRIVAL is both CC-hard and PL-hard.},
  howpublished = {https://arxiv.org/abs/2108.06273v1},
  langid = {english},
  file = {/Users/sebastian/Zotero/storage/XTKKUBFU/Manuell - 2021 - A simple lower bound for ARRIVAL.pdf}
}

@article{martiniGeometryMinkowskiSpaces2001,
  title = {The Geometry of {{Minkowski}} Spaces --- {{A}} Survey. {{Part I}}},
  author = {Martini, Horst and Swanepoel, Konrad J. and Wei{\ss}, Gunter},
  year = {2001},
  month = jan,
  journal = {Expositiones Mathematicae},
  volume = {19},
  number = {2},
  pages = {97--142},
  issn = {0723-0869},
  doi = {10.1016/S0723-0869(01)80025-6},
  urldate = {2024-11-26},
  abstract = {We survey elementary results in Minkowski spaces (i.e. finite dimensional Banach spaces) that deserve to be collected together, and give simple proofs for some of them. We place special emphasis on planar results. Many of these results have often been rediscovered as lemmas to other results. In Part I we cover the following topics: The triangle inequality and consequences such as the monotonicity lemma, geometric characterizations of strict convexity, normality (Birkhoff orthogonality), conjugate diameters and Radon curves, equilateral triangles and the affine regular hexagon construction, equilateral sets, circles: intersection, circumscribed, characterizations, circumference and area, inscribed equilateral polygons.},
  file = {/Users/sebastian/Zotero/storage/KDDEZVQC/Martini et al. - 2001 - The geometry of Minkowski spaces — A survey. Part I.pdf}
}

@article{martiniGeometryMinkowskiSpaces2004,
  title = {The Geometry of Minkowski Spaces --- {{A}} Survey. {{Part II}}},
  author = {Martini, H. and Swanepoel, K. J.},
  year = {2004},
  month = jan,
  journal = {Expositiones Mathematicae},
  volume = {22},
  number = {2},
  pages = {93--144},
  issn = {0723-0869},
  doi = {10.1016/S0723-0869(04)80009-4},
  urldate = {2024-11-26},
  abstract = {In this second part of a series of surveys on the geometry of finite dimensional Banach spaces (Minkowski spaces) we discuss results that refer to the following three topics: bodies of constant Minkowski width, generalized convexity notions that are important for Minkowski spaces, and bisectors as well as Voronoi diagrams in Minkowski spaces.},
  keywords = {bisectors,bodies of constant width,finite dimensional normed spaces,generalized convexity,Minkowski Geometry,Minkowski spaces,Voronoi diagrams},
  file = {/Users/sebastian/Zotero/storage/8U58SHW2/Martini and Swanepoel - 2004 - The geometry of minkowski spaces — A survey. Part II.pdf}
}

@inproceedings{mathieuAnotherAlgorithmDense2008,
  title = {Yet Another Algorithm for Dense Max Cut: Go Greedy},
  shorttitle = {Yet Another Algorithm for Dense Max Cut},
  booktitle = {Proceedings of the Nineteenth Annual {{ACM-SIAM}} Symposium on {{Discrete}} Algorithms},
  author = {Mathieu, Claire and Schudy, Warren},
  year = {2008},
  month = jan,
  series = {{{SODA}} '08},
  pages = {176--182},
  publisher = {{Society for Industrial and Applied Mathematics}},
  address = {USA},
  urldate = {2023-08-10},
  abstract = {We study dense instances of MaxCut and its generalizations. Following a long list of existing, diverse and often sophisticated approximation schemes, we propose taking the na{\"i}ve greedy approach; we prove that when the vertices are considered in random order, our algorithms are still approximation schemes. Our algorithms may be simple, but the analysis is not. It relies on smoothing the vertices defining the partial cuts and on proving certain martingale properties. We also give a simpler proof of the result from Alon, Fernandez de la Vega, Kannan, and Karpinski [1] that dense problems have sample complexity {\~O} (1/{$\varepsilon$}4). Like previous work, our results generalize to dense maximum constraint satisfaction problems.},
  file = {/Users/sebastian/Zotero/storage/55N5JVAQ/Mathieu and Schudy - 2008 - Yet another algorithm for dense max cut go greedy.pdf}
}

@article{matousekIntersectionGraphsSegments2014,
  title = {Intersection Graphs of Segments and \${\textbackslash}exists{\textbackslash}mathbb\{\vphantom\}{{R}}\vphantom\{\}\$},
  author = {Matousek, Jiri},
  year = {2014},
  publisher = {arXiv},
  doi = {10.48550/ARXIV.1406.2636},
  urldate = {2023-08-10},
  abstract = {A graph \$G\$ with vertex set \${\textbackslash}\{v\_1,v\_2,{\textbackslash}ldots,v\_n{\textbackslash}\}\$ is an intersection graph of segments if there are segments \$s\_1,{\textbackslash}ldots,s\_n\$ in the plane such that \$s\_i\$ and \$s\_j\$ have a common point if and only if \${\textbackslash}\{v\_i,v\_j{\textbackslash}\}\$ is an edge of{\textasciitilde}\$G\$. In this expository paper, we consider the algorithmic problem of testing whether a given abstract graph is an intersection graph of segments. It turned out that this problem is complete for an interesting recently introduced class of computational problems, denoted by \${\textbackslash}exists{\textbackslash}mathbb\{R\}\$. This class consists of problems that can be reduced, in polynomial time, to solvability of a system of polynomial inequalities in several variables over the reals. We discuss some subtleties in the definition of \${\textbackslash}exists{\textbackslash}mathbb\{R\}\$, and we provide a complete and streamlined account of a proof of the \${\textbackslash}exists{\textbackslash}mathbb\{R\}\$-completeness of the recognition problem for segment intersection graphs. Along the way, we establish \${\textbackslash}exists{\textbackslash}mathbb\{R\}\$-completeness of several other problems. We also present a decision algorithm, due to Muchnik, for the first-order theory of the reals.},
  copyright = {arXiv.org perpetual, non-exclusive license},
  keywords = {68R10 68Q17 05C62 52C30 52C45,Combinatorics (math.CO),Computational Geometry (cs.CG),FOS: Computer and information sciences,FOS: Mathematics}
}

@book{matousekLecturesDiscreteGeometry2002,
  title = {Lectures on {{Discrete Geometry}}},
  year = {2002},
  series = {Graduate {{Texts}} in {{Mathematics}}},
  volume = {212},
  publisher = {Springer},
  address = {New York, NY},
  doi = {10.1007/978-1-4613-0039-7},
  urldate = {2024-11-06},
  copyright = {http://www.springer.com/tdm},
  isbn = {978-0-387-95374-8 978-1-4613-0039-7},
  keywords = {Dimension,discrete geometry,Discrete Geometry,geometry,mathematics},
  file = {/Users/sebastian/Zotero/storage/GRQGNTUA/Matoušek - 2002 - Lectures on Discrete Geometry.pdf}
}

@article{matousekNumberUniqueSinkOrientations2006,
  title = {The {{Number Of Unique-Sink Orientations}} of the {{Hypercube}}*},
  author = {Matou{\v s}ek, Ji{\v r}{\'i}},
  year = {2006},
  month = feb,
  journal = {Combinatorica},
  volume = {26},
  number = {1},
  pages = {91--99},
  issn = {1439-6912},
  doi = {10.1007/s00493-006-0007-0},
  urldate = {2024-05-06},
  abstract = {Let Qddenote the graph of the d-dimensional cube. A unique-sink orientation (USO) is an orientation of Qdsuch that every face of Qnhas exactly one sink (vertex of out degree 0); it does not have to be acyclic. USO have been studied as an abstract model for many geometric optimization problems, such as linear programming, finding the smallest enclosing ball of a given point set, certain classes of convex programming, and certain linear complementarity problems. It is shown that the number of USO is \$\$d{\textasciicircum}\{\{{\textbackslash}Theta \{{\textbackslash}left( \{2{\textasciicircum}\{d\} \} {\textbackslash}right)\}\}\} \$\$.},
  langid = {english},
  keywords = {05C30,90C60},
  file = {/Users/sebastian/Zotero/storage/V95VGG6C/Matoušek - 2006 - The Number Of Unique-Sink Orientations of the Hype.pdf}
}

@inproceedings{matousekSubexponentialBoundLinear1992,
  title = {A Subexponential Bound for Linear Programming},
  booktitle = {Proceedings of the Eighth Annual Symposium on {{Computational}} Geometry},
  author = {Matou{\v s}ek, Ji{\v r}{\'i} and Sharir, Micha and Welzl, Emo},
  year = {1992},
  month = jul,
  series = {{{SCG}} '92},
  pages = {1--8},
  publisher = {Association for Computing Machinery},
  address = {New York, NY, USA},
  doi = {10.1145/142675.142678},
  urldate = {2024-04-24},
  abstract = {We present a simple randomized algorithm which solves linear programs with n constraints and d variables in expected O(nde(d ln(n+1))1/4) time in the unit cost model (where we count the number of arithmetic operations on the numbers in the input). The expectation is over the internal randomizations performed by the algorithm, and holds for any input. The algorithm is presented in an abstract framework, which facilitates its application to several other related problems. The algorithm has been presented in a previous work by the authors [ShW], but its analysis and the subexponential complexity bound are new.},
  isbn = {978-0-89791-517-5},
  keywords = {combinatorial optimization,computational geometry,linear programming,randomized incremental algorithms},
  file = {/Users/sebastian/Zotero/storage/2FSTGGVY/Matoušek et al. - 1992 - A subexponential bound for linear programming.pdf}
}

@book{matousekUnderstandingUsingLinear2007,
  title = {Understanding and Using Linear Programming},
  author = {Matou{\v s}ek, Ji{\v r}{\'i} and G{\"a}rtner, Bernd},
  year = {2007},
  series = {Universitext},
  publisher = {Springer},
  address = {Berlin ; New York},
  isbn = {978-3-540-30697-9 978-3-540-30717-4},
  langid = {english},
  lccn = {T57.74 .M374 2007},
  keywords = {Linear programming},
  file = {/Users/sebastian/Zotero/storage/9HXTWJGP/Matoušek and Gärtner - 2007 - Understanding and using linear programming.pdf}
}

@book{matousekUsingBorsukUlam2008,
  title = {Using the {{Borsuk}}--{{Ulam Theorem}}},
  author = {Matou{\v s}ek, Ji{\v r}{\'i}},
  year = {2008},
  publisher = {Springer},
  address = {Berlin, Heidelberg},
  doi = {10.1007/978-3-540-76649-0},
  urldate = {2023-10-05},
  isbn = {978-3-540-00362-5 978-3-540-76649-0},
  langid = {english},
  keywords = {algebra,algebraic topology,applications of algebraic topology,combinatorial geometry,combinatorics,Combinatorics,computer,computer science,discrete geometry,geometry,homology,Homotopy,mathematics,proof,theorem,theoretical computer science,topology},
  file = {/Users/sebastian/Zotero/storage/Q63J9S8R/Matoušek - 2008 - Using the Borsuk–Ulam Theorem.pdf}
}

@book{mclennanAdvancedFixedPoint2018,
  title = {Advanced {{Fixed Point Theory}} for {{Economics}}},
  author = {McLennan, Andrew},
  year = {2018},
  publisher = {Springer Singapore},
  address = {Singapore},
  doi = {10.1007/978-981-13-0710-2},
  urldate = {2024-06-11},
  copyright = {http://www.springer.com/tdm},
  isbn = {9789811307096 9789811307102},
  langid = {english},
  file = {/Users/sebastian/Zotero/storage/2SZVDT2K/McLennan - 2018 - Advanced Fixed Point Theory for Economics.pdf}
}

@article{mcshaneExtensionRangeFunctions1934,
  title = {Extension of Range of Functions},
  author = {McShane, E. J.},
  year = {1934},
  month = dec,
  journal = {Bulletin of the American Mathematical Society},
  volume = {40},
  number = {12},
  pages = {837--842},
  publisher = {American Mathematical Society},
  issn = {0002-9904, 1936-881X},
  urldate = {2025-01-20},
  abstract = {Bulletin (New Series) of the American Mathematical Society},
  file = {/Users/sebastian/Zotero/storage/DW7R8FRK/McShane - 1934 - Extension of range of functions.pdf}
}

@techreport{megiddo1988note,
  title = {A {{Note}} on the {{Complexity}} of {{P-Matrix Lcp}} and {{Computing}} an {{Equilibrium}}},
  author = {Megiddo, Nimrod},
  year = {1988},
  institution = {Citeseer},
  file = {/Users/sebastian/Zotero/storage/7FE3K7TD/Megiddo - 1988 - A Note on the Complexity of P-Matrix Lcp and Compu.pdf}
}

@article{megiddoTotalFunctionsExistence1991,
  title = {On Total Functions, Existence Theorems and Computational Complexity},
  author = {Megiddo, Nimrod and Papadimitriou, Christos H.},
  year = {1991},
  month = apr,
  journal = {Theoretical Computer Science},
  volume = {81},
  number = {2},
  pages = {317--324},
  issn = {0304-3975},
  doi = {10.1016/0304-3975(91)90200-L},
  urldate = {2024-06-26},
  abstract = {Nondeterministic multivalued functions with values that are polynomially verifiable and guaranteed to exist form an interesting complexity class between P and NP. We show that this class, which we call TFNP, contains a host of important problems, whose membership in P is currently not known. These include, besides factoring, local optimization, Brouwer's fixed points, a computational version of Sperner's Lemma, bimatrix equilibria in games, and linear complementarity for P-matrices.},
  file = {/Users/sebastian/Zotero/storage/ZQ4VQFD7/Megiddo and Papadimitriou - 1991 - On total functions, existence theorems and computa.pdf;/Users/sebastian/Zotero/storage/HSQ7JZMD/030439759190200L.html}
}

@incollection{meunierRainbowEndLine2017,
  title = {The {{Rainbow}} at the {{End}} of the {{Line}} ? {{A PPAD Formulation}} of the {{Colorful Carath{\'e}odory Theorem}} with {{Applications}}},
  shorttitle = {The {{Rainbow}} at the {{End}} of the {{Line}} ?},
  booktitle = {Proceedings of the 2017 {{Annual ACM-SIAM Symposium}} on {{Discrete Algorithms}} ({{SODA}})},
  author = {Meunier, Fr{\'e}d{\'e}ric and Mulzer, Wolfgang and Sarrabezolles, Pauline and Stein, Yannik},
  year = {2017},
  month = jan,
  series = {Proceedings},
  pages = {1342--1351},
  publisher = {{Society for Industrial and Applied Mathematics}},
  doi = {10.1137/1.9781611974782.87},
  urldate = {2024-04-26},
  abstract = {Let C1,{\dots}, Cd+i be d + 1 point sets in {$\mathbb{R}$}d, each containing the origin in its convex hull. A subset C of  is called a colorful choice (or rainbow) for C1,{\dots}, Cd+1, if it contains exactly one point from each set Ci. The colorful Carath{\'e}odory theorem states that there always exists a colorful choice for C1,{\dots}, Cd+1 that has the origin in its convex hull. This theorem is very general and can be used to prove several other existence theorems in high-dimensional discrete geometry, such as the centerpoint theorem or Tverberg's theorem. The colorful Carath{\'e}odory problem (ColorfulCarath{\'e}odory) is the computational problem of finding such a colorful choice. Despite several efforts in the past, the computational complexity of ColorfulCarath{\'e}odory in arbitrary dimension is still open. We show that ColorfulCarath{\'e}odory lies in the intersection of the complexity classes PPAD and PLS. This makes it one of the few geometric problems in PPAD and PLS that are not known to be solvable in polynomial time. Moreover, it implies that the problem of computing centerpoints, computing Tverberg partitions, and computing points with large simplicial depth is contained in PPAD {$\Pi$} PLS. This is the first nontrivial upper bound on the complexity of these problems. Finally, we show that our PPAD formulation leads to a polynomial-time algorithm for a special case of ColorfulCarath{\'e}odory in which we have only two color classes C1 and C2 in d dimensions, each with the origin in its convex hull, and we would like to find a set with half the points from each color class that contains the origin in its convex hull.},
  file = {/Users/sebastian/Zotero/storage/72XQCR8S/Meunier et al. - 2017 - The Rainbow at the End of the Line  A PPAD Formul.pdf}
}

@inproceedings{millerApproximateCenterPoints2009,
  title = {Approximate Center Points with Proofs},
  booktitle = {Proceedings of the Twenty-Fifth Annual Symposium on {{Computational}} Geometry},
  author = {Miller, Gary L. and Sheehy, Donald R.},
  year = {2009},
  month = jun,
  series = {{{SCG}} '09},
  pages = {153--158},
  publisher = {Association for Computing Machinery},
  address = {New York, NY, USA},
  doi = {10.1145/1542362.1542395},
  urldate = {2024-11-01},
  abstract = {We present the Iterated-Tverberg algorithm, the first deterministic algorithm for computing an approximate centerpoint of a set S {$\in$} Rd with running time sub-exponential in d. The algorithm is a derandomization of the Iterated-Radon algorithm of Clarkson et al and is guaranteed to terminate with an O(1/d2)-center. Moreover, it returns a polynomial-time checkable proof of the approximation guarantee, despite the coNP-Completenes of testing centerpoints in general. We also explore the use of higher order Tverberg partitions to improve the runtime of the deterministic algorithm and improve the approximation guarantee for the randomized algorithm. In particular, we show how to improve the O(1/d2)-center of the Iterated-Radon algorithm to O(1/dr/(r-1)) for a cost of O((rd)d) in time for any integer r.},
  isbn = {978-1-60558-501-7},
  file = {/Users/sebastian/Zotero/storage/VAPKL2WX/Miller and Sheehy - 2009 - Approximate center points with proofs.pdf}
}

@article{monienComplexityDeterminingShortest1983,
  title = {The Complexity of Determining a Shortest Cycle of Even Length},
  author = {Monien, B.},
  year = {1983},
  month = dec,
  journal = {Computing},
  volume = {31},
  number = {4},
  pages = {355--369},
  issn = {1436-5057},
  doi = {10.1007/BF02251238},
  urldate = {2024-04-05},
  abstract = {We study the problem of determining a shortest cycle of even length (or of odd length, respectively). For cycles of odd length we get the same complexity as for determining a shortest cycle of a graph i. e. 0 ({\textbar}V{\textbar}{$\cdot\vert$}E{\textbar}) in the case of unweighted graphs and 0 ({\textbar}V{\textbar}3) in the case of weighted graphs. The main contribution of this paper is an algorithm computing the shortest cycle of even length of an unweighted undirected graph within essentially 0 ({\textbar}V{\textbar}2) time.},
  langid = {english},
  keywords = {68 C 25,68 E 10,efficient algorithms,Shortest cycles},
  file = {/Users/sebastian/Zotero/storage/ZU87IKLJ/Monien - 1983 - The complexity of determining a shortest cycle of .pdf}
}

@article{moriokaClassificationSearchProblems2001,
  title = {Classification of Search Problems and Their Definability in Bounded Arithmetic},
  author = {Morioka, Tsuyoshi},
  year = {2001},
  urldate = {2025-01-15},
  abstract = {We present a new framework for the study of search problems and their definability in bounded arithmetic. We identify two notions of complexity of search problems: verification complexity and computational complexity. Notions of exact solvability and exact reducibility are developed, and exact {$<$}math{$>$} {$<$}f{$>$} {$<$}g{$>$}S{$<$}/g{$>$}\textsuperscript{{$<$}mit{$>$}b{$<$}/mit{$>$}}{$<$}inf{$>$}i{$<$}/inf{$><$}/f{$>$} {$<$}/math{$>$}-definability of search problems in bounded arithmetic is introduced. We specify a new machine model called the oblivious witness-oracle Turing machines. Based on work of Buss and Krajicek, we present a type-2 search problem ITERATION (ITER) that characterizes the class PLS and the exactly {$<$}math{$>$} {$<$}f{$>$} {$<$}g{$>$}S{$<$}/g{$>$}\textsuperscript{{$<$}mit{$>$}b{$<$}/mit{$>$}}{$<$}inf{$>$}1{$<$}/inf{$><$}/f{$>$} {$<$}/math{$>$}-definable search problems of the theory {$<$}math{$>$} {$<$}f{$>$} {$<$}rm{$>$}T\textsuperscript{1}{$<$}inf{$>$}2{$<$}/inf{$><$}/rm{$><$}/f{$>$} {$<$}/math{$>$}. We show that the type-2 problems of Beame et al. are not Turing reducible to ITER. The separations of the corresponding type-2 classes and the unprovability of certain combinatorial principles in a relativized version of {$<$}math{$>$} {$<$}f{$>$} {$<$}rm{$>$}T\textsuperscript{1}{$<$}inf{$>$}2{$<$}/inf{$><$}/rm{$><$}/f{$>$} {$<$}/math{$>$} are obtained as corollaries. We also present the first characterization of the exactly {$<$}math{$>$} {$<$}f{$>$} {$<$}g{$>$}S{$<$}/g{$>$}\textsuperscript{{$<$}mit{$>$}b{$<$}/mit{$>$}}{$<$}inf{$>$}2{$<$}/inf{$><$}/f{$>$} {$<$}/math{$>$}-definable search problems of {$<$}math{$>$} {$<$}f{$>$} {$<$}rm{$>$}S\textsuperscript{1}{$<$}inf{$>$}2{$<$}/inf{$><$}/rm{$><$}/f{$>$} {$<$}/math{$>$} and {$<$}math{$>$} {$<$}f{$>$} {$<$}rm{$>$}T\textsuperscript{1}{$<$}inf{$>$}2{$<$}/inf{$><$}/rm{$><$}/f{$>$} {$<$}/math{$>$}.},
  langid = {english},
  file = {/Users/sebastian/Zotero/storage/7XD77D3B/Morioka - 2001 - Classification of search problems and their definability in bounded arithmetic.pdf}
}

@article{mulmuleyMatchingEasyMatrix1987,
  title = {Matching Is as Easy as Matrix Inversion},
  author = {Mulmuley, Ketan and Vazirani, Umesh V. and Vazirani, Vijay V.},
  year = {1987},
  month = mar,
  journal = {Combinatorica},
  volume = {7},
  number = {1},
  pages = {105--113},
  issn = {1439-6912},
  doi = {10.1007/BF02579206},
  urldate = {2024-04-05},
  abstract = {We present a new algorithm for finding a maximum matching in a general graph. The special feature of our algorithm is that its only computationally non-trivial step is the inversion of a single integer matrix. Since this step can be parallelized, we get a simple parallel (RNC2) algorithm. At the heart of our algorithm lies a probabilistic lemma, the isolating lemma. We show other applications of this lemma to parallel computation and randomized reductions.},
  langid = {english},
  keywords = {05 C 25,68 E 10},
  file = {/Users/sebastian/Zotero/storage/C597J3H5/Mulmuley et al. - 1987 - Matching is as easy as matrix inversion.pdf}
}

@misc{murakamiFPTAlgorithmExact2024,
  title = {An {{FPT Algorithm}} for the {{Exact Matching Problem}} and {{NP-hardness}} of {{Related Problems}}},
  author = {Murakami, Hitoshi and Yamaguchi, Yutaro},
  year = {2024},
  month = may,
  number = {arXiv:2405.02829},
  eprint = {2405.02829},
  primaryclass = {cs, math},
  publisher = {arXiv},
  doi = {10.48550/arXiv.2405.02829},
  urldate = {2024-09-04},
  abstract = {The exact matching problem is a constrained variant of the maximum matching problem: given a graph with each edge having a weight \$0\$ or \$1\$ and an integer \$k\$, the goal is to find a perfect matching of weight exactly \$k\$. Mulmuley, Vazirani, and Vazirani (1987) proposed a randomized polynomial-time algorithm for this problem, and it is still open whether it can be derandomized. Very recently, El Maalouly, Steiner, and Wulf (2023) showed that for bipartite graphs there exists a deterministic FPT algorithm parameterized by the (bipartite) independence number. In this paper, by extending a part of their work, we propose a deterministic FPT algorithm in general parameterized by the minimum size of an odd cycle transversal in addition to the (bipartite) independence number. We also consider a relaxed problem called the correct parity matching problem, and show that a slight generalization of an equivalent problem is NP-hard.},
  archiveprefix = {arXiv},
  keywords = {Computer Science - Data Structures and Algorithms,Mathematics - Combinatorics},
  file = {/Users/sebastian/Zotero/storage/TJHEN2DC/Murakami and Yamaguchi - 2024 - An FPT Algorithm for the Exact Matching Problem an.pdf;/Users/sebastian/Zotero/storage/AR3M9FD8/2405.html}
}

@phdthesis{mustafa:tel-01062825,
  type = {Accreditation to Supervise Research},
  title = {Approximations of Points: {{Combinatorics}} and Algorithms},
  author = {Mustafa, Nabil},
  year = {2013},
  month = dec,
  hal_id = {tel-01062825},
  hal_version = {v1},
  school = {Universit{\'e} Paris-Est},
  keywords = {approximation algorithms,combinatorics,computational geometry,discrete mathematics,geometric algorithms,statistics},
  file = {/Users/sebastian/Zotero/storage/YG9JX5PE/thesis.pdf}
}

@book{netzerGeometryLinearMatrix2023,
  title = {Geometry of {{Linear Matrix Inequalities}}: {{A Course}} in {{Convexity}} and {{Real Algebraic Geometry}} with a {{View Towards Optimization}}},
  shorttitle = {Geometry of {{Linear Matrix Inequalities}}},
  author = {Netzer, Tim and Plaumann, Daniel},
  year = {2023},
  series = {Compact {{Textbooks}} in {{Mathematics}}},
  publisher = {Springer International Publishing},
  address = {Cham},
  doi = {10.1007/978-3-031-26455-9},
  urldate = {2024-02-09},
  isbn = {978-3-031-26454-2 978-3-031-26455-9},
  langid = {english},
  keywords = {Convex Geometry,Convex Optimization,Eigenvalues,Extended Formulations,Hyperbolic Polynomials,Matrices,Non-commutative Geometry,Polynomial Optimization,Real Algebraic Curves,Real Algebraic Geometry,Semidefinitie Programming,Sums of Squares},
  file = {/Users/sebastian/Zotero/storage/2D4MGJA3/Netzer and Plaumann - 2023 - Geometry of Linear Matrix Inequalities A Course i.pdf}
}

@misc{nietertMoserAlgorithmLovasz,
  title = {Moser's {{Algorithm}} and the {{Lov{\'a}sz Local Lemma}}},
  author = {Nietert, Sloan},
  urldate = {2023-08-11},
  langid = {american},
  file = {/Users/sebastian/Zotero/storage/LKBFL6G3/mosers-algorithm-and-the-lovász-local-lemma.html}
}

@book{nisanAlgorithmicGameTheory2007,
  title = {Algorithmic {{Game Theory}}},
  year = {2007},
  publisher = {Cambridge University Press},
  address = {Cambridge},
  doi = {10.1017/CBO9780511800481},
  urldate = {2024-06-25},
  abstract = {In recent years game theory has had a substantial impact on computer science, especially on Internet- and e-commerce-related issues. Algorithmic Game Theory, first published in 2007, develops the central ideas and results of this exciting area in a clear and succinct manner. More than 40 of the top researchers in this field have written chapters that go from the foundations to the state of the art. Basic chapters on algorithmic methods for equilibria, mechanism design and combinatorial auctions are followed by chapters on important game theory applications such as incentives and pricing, cost sharing, information markets and cryptography and security. This definitive work will set the tone of research for the next few years and beyond. Students, researchers, and practitioners alike need to learn more about these fascinating theoretical developments and their widespread practical application.},
  isbn = {978-0-521-87282-9},
  file = {/Users/sebastian/Zotero/storage/M95E6NBX/Nisan et al. - 2007 - Algorithmic Game Theory.pdf;/Users/sebastian/Zotero/storage/5MG5RIZS/0092C07CA8B724E1B1BE2238DDD66B38.html}
}

@article{overmarsFindingSetsPoints2002,
  title = {Finding {{Sets}} of {{Points}} without {{Empty Convex}} 6-{{Gons}}},
  author = {Overmars, Mark},
  year = {2002},
  month = dec,
  journal = {Discrete and Computational Geometry},
  volume = {29},
  number = {1},
  pages = {153--158},
  issn = {01795376},
  doi = {10.1007/s00454-002-2829-x},
  urldate = {2023-08-10},
  file = {/Users/sebastian/Zotero/storage/CUY37IBB/Overmars - 2002 - Finding Sets of Points without Empty Convex 6-Gons.pdf}
}

@incollection{palvolgyi2DTUCKERPPADComplete2009,
  title = {{{2D-TUCKER Is PPAD-Complete}}},
  booktitle = {Internet and {{Network Economics}}},
  author = {P{\'a}lv{\"o}lgyi, D{\"o}m{\"o}t{\"o}r},
  year = {2009},
  volume = {5929},
  pages = {569--574},
  publisher = {Springer Berlin Heidelberg},
  address = {Berlin, Heidelberg},
  doi = {10.1007/978-3-642-10841-9_57},
  urldate = {2023-11-06},
  isbn = {978-3-642-10840-2 978-3-642-10841-9},
  file = {/Users/sebastian/Zotero/storage/2DSYHCR7/978-3-642-10841-9_57.pdf}
}

@article{pandaEquidistantSetsNormed1974,
  title = {On Equidistant Sets in Normed Linear Spaces},
  author = {Panda, B. B. and Kapoor, O. P.},
  year = {1974},
  month = dec,
  journal = {Bulletin of the Australian Mathematical Society},
  volume = {11},
  number = {3},
  pages = {443--454},
  issn = {1755-1633, 0004-9727},
  doi = {10.1017/S0004972700044075},
  urldate = {2024-11-26},
  abstract = {In this note some results concerning the equidistant set E(-x, x) and the kernel M{\texttheta} of the metric projection PM, where M is a Chebyshev subspace of a normed linear space X, have been obtained. In particular, when X = lp (1 {$<$} p {$<$} {$\infty$}), it has been proved that every equidistant set is closed in the bw-topology of the space. In c0 no equidistant set has this property.},
  langid = {english},
  file = {/Users/sebastian/Zotero/storage/9G383FEK/Panda and Kapoor - 1974 - On equidistant sets in normed linear spaces.pdf}
}

@article{pandoveCorrelationBasedRecommendation2021,
  title = {A {{Correlation Based Recommendation System}} for {{Large Data Sets}}},
  author = {Pandove, Divya and Malhi, Avleen},
  year = {2021},
  month = dec,
  journal = {Journal of Grid Computing},
  volume = {19},
  number = {4},
  pages = {42},
  issn = {1570-7873, 1572-9184},
  doi = {10.1007/s10723-021-09585-9},
  urldate = {2023-08-10},
  abstract = {Abstract                            Correlation determination brings out relationships in data that had not been seen before and it is imperative to successfully use the power of correlations for data mining. In this paper, we have used the concepts of correlations to cluster data, and merged it with recommendation algorithms. We have proposed two correlation clustering algorithms (RBACC and LGBACC), that are based on finding Spearman's rank correlation coefficient among data points, and using dimensionality reduction approach (PCA) along with graph theory respectively, to produce high quality hierarchical clusters. Both these algorithms have been tested on real life data (New York yellow cabs dataset taken from               http://www.nyc.gov               ), using distributed and parallel computing (Spark and R). They are found to be scalable and perform better than the existing hierarchical clustering algorithms. These two approaches have been used to replace similarity measures in recommendation algorithms and generate a correlation clustering based recommendation system model. We have combined the power of correlation analysis with that of prediction analysis to propose a better recommendation system. It is found that this model makes better quality recommendations as compared to the random recommendation model. This model has been validated using a real time, large data set (MovieLens dataset, taken from               http://grouplens.org/datasets/movielens/latest               ). The results show that combining correlated points with the predictive power of recommendation algorithms, produce better quality recommendations which are faster to compute. LGBACC has approximately 25\% better prediction capability but at the same time takes significantly more prediction time compared to RBACC.},
  langid = {english},
  file = {/Users/sebastian/Zotero/storage/Z9RRMBJY/Pandove and Malhi - 2021 - A Correlation Based Recommendation System for Larg.pdf}
}

@article{papadimitriouComplexityParityArgument1994,
  title = {On the Complexity of the Parity Argument and Other Inefficient Proofs of Existence},
  author = {Papadimitriou, Christos H.},
  year = {1994},
  month = jun,
  journal = {Journal of Computer and System Sciences},
  volume = {48},
  number = {3},
  pages = {498--532},
  issn = {00220000},
  doi = {10.1016/S0022-0000(05)80063-7},
  urldate = {2023-09-14},
  langid = {english},
  file = {/Users/sebastian/Zotero/storage/C7R3R22D/main.pdf}
}

@article{papadimitriouComplexityRestrictedSpanning1982,
  title = {The Complexity of Restricted Spanning Tree Problems},
  author = {Papadimitriou, Christos H. and Yannakakis, Mihalis},
  year = {1982},
  month = apr,
  journal = {Journal of the ACM},
  volume = {29},
  number = {2},
  pages = {285--309},
  issn = {0004-5411},
  doi = {10.1145/322307.322309},
  urldate = {2024-04-05},
  file = {/Users/sebastian/Zotero/storage/29G75NCD/Papadimitriou and Yannakakis - 1982 - The complexity of restricted spanning tree problem.pdf}
}

@article{parikhProximalAlgorithms2014,
  title = {Proximal {{Algorithms}}},
  author = {Parikh, Neal and Boyd, Stephen},
  year = {2014},
  month = jan,
  journal = {Found. Trends Optim.},
  volume = {1},
  number = {3},
  pages = {127--239},
  issn = {2167-3888},
  doi = {10.1561/2400000003},
  urldate = {2025-01-15},
  abstract = {This monograph is about a class of optimization algorithms called proximal algorithms. Much like Newton's method is a standard tool for solving unconstrained smooth optimization problems of modest size, proximal algorithms can be viewed as an analogous tool for nonsmooth, constrained, large-scale, or distributed versions of these problems. They are very generally applicable, but are especially well-suited to problems of substantial recent interest involving large or high-dimensional datasets. Proximal methods sit at a higher level of abstraction than classical algorithms like Newton's method: the base operation is evaluating the proximal operator of a function, which itself involves solving a small convex optimization problem. These subproblems, which generalize the problem of projecting a point onto a convex set, often admit closed-form solutions or can be solved very quickly with standard or simple specialized methods. Here, we discuss the many different interpretations of proximal operators and algorithms, describe their connections to many other topics in optimization and applied mathematics, survey some popular algorithms, and provide a large number of examples of proximal operators that commonly arise in practice.}
}

@article{parysParityGamesZielonka2019,
  title = {Parity {{Games}}: {{Zielonka}}'s {{Algorithm}} in {{Quasi-Polynomial Time}}},
  shorttitle = {Parity {{Games}}},
  author = {Parys, Pawel},
  year = {2019},
  pages = {13 pages},
  doi = {10.4230/LIPICS.MFCS.2019.10},
  urldate = {2023-10-01},
  collaborator = {Wagner, Michael},
  copyright = {Creative Commons Attribution 3.0 Unported license (CC-BY 3.0)},
  langid = {english},
  file = {/Users/sebastian/Zotero/storage/I3DY2T33/LIPIcs-MFCS-2019-10.pdf}
}

@inproceedings{pasarkarExtremalCombinatoricsIterated2023,
  title = {Extremal {{Combinatorics}}, {{Iterated Pigeonhole Arguments}} and {{Generalizations}} of {{PPP}}},
  booktitle = {{{DROPS-IDN}}/v2/Document/10.4230/{{LIPIcs}}.{{ITCS}}.2023.88},
  author = {Pasarkar, Amol and Papadimitriou, Christos and Yannakakis, Mihalis},
  year = {2023},
  publisher = {Schloss Dagstuhl -- Leibniz-Zentrum f{\"u}r Informatik},
  doi = {10.4230/LIPIcs.ITCS.2023.88},
  urldate = {2024-06-17},
  abstract = {We study the complexity of computational problems arising from existence theorems in extremal combinatorics. For some of these problems, a solution is guaranteed to exist based on an iterated application of the Pigeonhole Principle. This results in the definition of a new complexity class within TFNP, which we call PLC (for "polynomial long choice"). PLC includes all of PPP, as well as numerous previously unclassified total problems, including search problems related to Ramsey's theorem, the Sunflower theorem, the Erd{\H o}s-Ko-Rado lemma, and K{\"o}nig's lemma. Whether the first two of these four problems are PLC-complete is an important open question which we pursue; in contrast, we show that the latter two are PPP-complete. Finally, we reframe PPP as an optimization problem, and define a hierarchy of such problems related to Tur{\`a}n's theorem.},
  copyright = {https://creativecommons.org/licenses/by/4.0/legalcode},
  langid = {english},
  file = {/Users/sebastian/Zotero/storage/UL5L49SU/Pasarkar et al. - 2023 - Extremal Combinatorics, Iterated Pigeonhole Argume.pdf}
}

@misc{paulTreelayoutBasedGraph2024,
  title = {Tree-Layout Based Graph Classes: Proper Chordal Graphs},
  shorttitle = {Tree-Layout Based Graph Classes},
  author = {Paul, Christophe and Protopapas, Evangelos},
  year = {2024},
  month = jan,
  number = {arXiv:2211.07550},
  eprint = {2211.07550},
  primaryclass = {cs},
  urldate = {2024-03-11},
  abstract = {Many standard graph classes are known to be characterized by means of layouts (a permutation of its vertices) excluding some patterns. Important such graph classes are among others: proper interval graphs, interval graphs, chordal graphs, permutation graphs, (co-)comparability graphs. For example, a graph \$G=(V,E)\$ is a proper interval graph if and only if \$G\$ has a layout \$L\$ such that for every triple of vertices such that \$x{\textbackslash}prec\_L y{\textbackslash}prec\_L z\$, if \$xz{\textbackslash}in E\$, then \$xy{\textbackslash}in E\$ and \$yz{\textbackslash}in E\$. Such a triple \$x\$, \$y\$, \$z\$ is called an indifference triple and layouts excluding indifference triples are known as indifference layouts. In this paper, we investigate the concept of tree-layouts. A tree-layout \$T\_G=(T,r,{\textbackslash}rho\_G)\$ of a graph \$G=(V,E)\$ is a tree \$T\$ rooted at some node \$r\$ and equipped with a one-to-one mapping \${\textbackslash}rho\_G\$ between \$V\$ and the nodes of \$T\$ such that for every edge \$xy{\textbackslash}in E\$, either \$x\$ is an ancestor of \$y\$ or \$y\$ is an ancestor of \$x\$. Clearly, layouts are tree-layouts. Excluding a pattern in a tree-layout is defined similarly as excluding a pattern in a layout, but now using the ancestor relation. Unexplored graph classes can be defined by means of tree-layouts excluding some patterns. As a proof of concept, we show that excluding non-indifference triples in tree-layouts yields a natural notion of proper chordal graphs. We characterize proper chordal graphs and position them in the hierarchy of known subclasses of chordal graphs. We also provide a canonical representation of proper chordal graphs that encodes all the indifference tree-layouts rooted at some vertex. Based on this result, we first design a polynomial time recognition algorithm for proper chordal graphs. We then show that the problem of testing isomorphism between two proper chordal graphs is in P, whereas this problem is known to be GI-complete on chordal graphs.},
  archiveprefix = {arXiv},
  file = {/Users/sebastian/Zotero/storage/DWP4G3B8/Paul and Protopapas - 2024 - Tree-layout based graph classes proper chordal graphs.pdf}
}

@article{phamOrbitsRotorrouterOperation2015,
  title = {Orbits of Rotor-Router Operation and Stationary Distribution of Random Walks on Directed Graphs},
  author = {Pham, Trung Van},
  year = {2015},
  month = sep,
  journal = {Advances in Applied Mathematics},
  volume = {70},
  pages = {45--53},
  issn = {0196-8858},
  doi = {10.1016/j.aam.2015.06.006},
  urldate = {2024-05-02},
  abstract = {The rotor-router model is a popular deterministic analogue of random walk. In this paper we prove that all orbits of the rotor-router operation have the same size on a strongly connected directed graph (digraph) and give a formula for the size. By using this formula we address the following open question about orbits of the rotor-router operation: Is there an infinite family of non-Eulerian strongly connected digraphs such that the rotor-router operation on each digraph has a single orbit? It turns out that on a strongly connected digraph the stationary distribution of the simple random walk coincides with the frequency of vertices in a rotor walk. In this common aspect a rotor walk simulates a random walk. This gives one similarity between two models on (finite) digraphs.},
  keywords = {Eulerian walker,Oriented spanning tree,Random walk,Recurrent state,Rotor-router model,Spanning tree,Stationary distribution},
  file = {/Users/sebastian/Zotero/storage/J38ED8UU/Pham - 2015 - Orbits of rotor-router operation and stationary di.pdf;/Users/sebastian/Zotero/storage/KTLPQ7GP/S0196885815000718.html}
}

@article{priezzhevEulerianWalkersModel1996,
  title = {Eulerian {{Walkers}} as a {{Model}} of {{Self-Organized Criticality}}},
  author = {Priezzhev, V. B. and Dhar, Deepak and Dhar, Abhishek and Krishnamurthy, Supriya},
  year = {1996},
  month = dec,
  journal = {Physical Review Letters},
  volume = {77},
  number = {25},
  pages = {5079--5082},
  publisher = {American Physical Society},
  doi = {10.1103/PhysRevLett.77.5079},
  urldate = {2024-08-19},
  abstract = {We propose a new model of self-organized criticality. A particle is dropped at random on a lattice and moves along directions specified by arrows at each site. As it moves, it changes the direction of the arrows according to fixed rules. On closed graphs these walks generate Euler circuits. On open graphs, the particle eventually leaves the system, and a new particle is then added. The operators corresponding to particle addition generate an Abelian group, same as the group for the Abelian sandpile model on the graph. We determine the critical steady state and some critical exponents exactly, using this equivalence.},
  file = {/Users/sebastian/Zotero/storage/G9XUK8D9/Priezzhev et al. - 1996 - Eulerian Walkers as a Model of Self-Organized Crit.pdf;/Users/sebastian/Zotero/storage/ZR93URJD/PhysRevLett.77.html}
}

@misc{proskurnikovRegularPairingsNonquadratic2024,
  title = {Regular {{Pairings}} for {{Non-quadratic Lyapunov Functions}} and {{Contraction Analysis}}},
  author = {Proskurnikov, Anton V. and Bullo, Francesco},
  year = {2024},
  month = aug,
  number = {arXiv:2408.17350},
  eprint = {2408.17350},
  primaryclass = {math},
  publisher = {arXiv},
  doi = {10.48550/arXiv.2408.17350},
  urldate = {2025-01-15},
  abstract = {Recent studies on stability and contractivity have highlighted the importance of semi-inner products, which we refer to as ``pairings'', associated with general norms. A pairing is a binary operation that relates the derivative of a curve's norm to the radius-vector of the curve and its tangent. This relationship, known as the curve norm derivative formula, is crucial when using the norm as a Lyapunov function. Another important property of the pairing, used in stability and contraction criteria, is the so-called Lumer inequality, which relates the pairing to the induced logarithmic norm. We prove that the curve norm derivative formula and Lumer's inequality are, in fact, equivalent to each other and to several simpler properties. We then introduce and characterize regular pairings that satisfy all of these properties. Our results unify several independent theories of pairings (semi-inner products) developed in previous work on functional analysis and control theory. Additionally, we introduce the polyhedral max pairing and develop computational tools for polyhedral norms, advancing contraction theory in non-Euclidean spaces.},
  archiveprefix = {arXiv},
  keywords = {Computer Science - Systems and Control,Electrical Engineering and Systems Science - Systems and Control,Mathematics - Dynamical Systems,Mathematics - Functional Analysis,Mathematics - Optimization and Control},
  file = {/Users/sebastian/Zotero/storage/HITB7Y7P/Proskurnikov and Bullo - 2024 - Regular Pairings for Non-quadratic Lyapunov Functions and Contraction Analysis.pdf;/Users/sebastian/Zotero/storage/2SLNN6UV/2408.html}
}

@inproceedings{rademacherApproximatingCentroidHard2007,
  title = {Approximating the Centroid Is Hard},
  booktitle = {Proceedings of the Twenty-Third Annual Symposium on {{Computational}} Geometry},
  author = {Rademacher, Luis A.},
  year = {2007},
  month = jun,
  series = {{{SCG}} '07},
  pages = {302--305},
  publisher = {Association for Computing Machinery},
  address = {New York, NY, USA},
  doi = {10.1145/1247069.1247123},
  urldate = {2025-01-20},
  abstract = {Consider the problem of computing the centroid of a convex body in n-dimensional Euclidean space. We prove that if the body is a polytope given as an intersection of half-spaces, then computing the centroid exactly is \#P-hard, even for order polytopes, a special case of 0-1 polytopes. We also prove that if the body is given by a membership oracle, then for any deterministic algorithm that makes a polynomial number of queries there exists a body satisfying a roundedness condition such that the output of the algorithm is outside a ball of radius sigma/100 around the centroid, where sigma{\textasciicircum}2 is the minimum eigenvalue of the inertia matrix of the body.},
  isbn = {978-1-59593-705-6},
  file = {/Users/sebastian/Zotero/storage/B3BE75CV/Rademacher - 2007 - Approximating the centroid is hard.pdf}
}

@article{radoTheoremGeneralMeasure1946,
  title = {A {{Theorem}} on {{General Measure}}},
  author = {Rado, R.},
  year = {1946},
  journal = {Journal of the London Mathematical Society},
  volume = {s1-21},
  number = {4},
  pages = {291--300},
  issn = {1469-7750},
  doi = {10.1112/jlms/s1-21.4.291},
  urldate = {2024-11-06},
  copyright = {{\copyright} 1946 London Mathematical Society},
  langid = {english},
  file = {/Users/sebastian/Zotero/storage/BWWWUKZA/Rado - 1946 - A Theorem on General Measure.pdf;/Users/sebastian/Zotero/storage/SM2DHM7I/s1-21.4.html}
}

@inproceedings{reingoldPseudorandomWalksRegular2006,
  title = {Pseudorandom Walks on Regular Digraphs and the {{RL}} vs. {{L}} Problem},
  booktitle = {Proceedings of the Thirty-Eighth Annual {{ACM}} Symposium on {{Theory}} of {{Computing}}},
  author = {Reingold, Omer and Trevisan, Luca and Vadhan, Salil},
  year = {2006},
  month = may,
  series = {{{STOC}} '06},
  pages = {457--466},
  publisher = {Association for Computing Machinery},
  address = {New York, NY, USA},
  doi = {10.1145/1132516.1132583},
  urldate = {2024-05-02},
  abstract = {We revisit the general RL vs. L question, obtaining the following results. Generalizing Reingold's techniques to directed graphs, we present a deterministic, log-space algorithm that given a regular directed graph G (or, more generally, a digraph with Eulerian connected components) and two vertices s and t, finds a path between s and t if one exists. If we restrict ourselves to directed graphs that are regular and consistently labelled, then we are able to produce pseudorandom walks for such graphs in logarithmic space (this result already found an independent application). We prove that if (2) could be generalized to all regular directed graphs (including ones that are not consistently labelled) then L=RL. We do so by exhibiting a new complete promise problem for RL, and showing that such a problem can be solved in deterministic logarithmic space given a log-space pseudorandom walk generator for regular directed graphs.},
  isbn = {978-1-59593-134-4},
  keywords = {derandomization,expander graphs,mixing time,space-bounded computation,universal traversal sequence,zig-zag product},
  file = {/Users/sebastian/Zotero/storage/8755RN8Z/Reingold et al. - 2006 - Pseudorandom walks on regular digraphs and the RL .pdf}
}

@article{rhodesGeometricDualityTwo1970,
  title = {A {{Geometric Duality}} for {{Two Metrics}} for the {{Co-Ordinate Plane}}},
  author = {Rhodes, Frank},
  year = {1970},
  journal = {The Mathematical Gazette},
  volume = {54},
  number = {387},
  eprint = {3613151},
  eprinttype = {jstor},
  pages = {19--23},
  publisher = {Mathematical Association},
  issn = {0025-5572},
  doi = {10.2307/3613151},
  urldate = {2024-11-26}
}

@article{robbinsTheoremGraphsApplication1939,
  title = {A {{Theorem}} on {{Graphs}}, with an {{Application}} to a {{Problem}} of {{Traffic Control}}},
  author = {Robbins, H. E.},
  year = {1939},
  month = may,
  journal = {The American Mathematical Monthly},
  volume = {46},
  number = {5},
  eprint = {2303897},
  eprinttype = {jstor},
  pages = {281},
  issn = {00029890},
  doi = {10.2307/2303897},
  urldate = {2023-08-10}
}

@article{ryuPRIMERMONOTONEOPERATOR,
  title = {A {{PRIMER ON MONOTONE OPERATOR METHODS}}},
  author = {Ryu, Ernest K and Boyd, Stephen},
  abstract = {This tutorial paper presents the basic notation and results of monotone operators and operator splitting methods, with a focus on convex optimization. A very wide variety of algorithms, ranging from classical to recently developed, can be derived in a uniform way. The approach is to pose the original problem to be solved as one of finding a zero of an appropriate monotone operator; this problem in turn is then posed as one of finding a fixed point of a related operator, which is done using the fixed point iteration. A few basic convergence results then tell us conditions under which the method converges, and, in some cases, how fast. This approach can be traced back to the 1960s and 1970s, and is still an active area of research. This primer is a self-contained gentle introduction to the topic.},
  langid = {english},
  file = {/Users/sebastian/Zotero/storage/YQDT2T49/Ryu and Boyd - A PRIMER ON MONOTONE OPERATOR METHODS.pdf}
}

@inproceedings{saberiCuttingCakeFive2009,
  title = {Cutting a {{Cake}} for {{Five People}}},
  booktitle = {Algorithmic {{Aspects}} in {{Information}} and {{Management}}},
  author = {Saberi, Amin and Wang, Ying},
  year = {2009},
  pages = {292--300},
  publisher = {Springer},
  address = {Berlin, Heidelberg},
  doi = {10.1007/978-3-642-02158-9_25},
  abstract = {Given a heterogeneous cake and 5 players, we give the first bounded algorithm for computing an envy-free division of the cake, such that each person thinks he gets the largest piece. The case with 4 players was solved in a famous paper by Brams et al. in 1997. Our algorithm can be discretized to obtain an {$\varepsilon$} envy-free division in \$O(\{{\textbackslash}rm polylog\} {\textbackslash}left( 1 / {\textbackslash}epsilon {\textbackslash}right))\$time. The algorithm is based on augmenting the irrevocable advantage graph in a new way.},
  isbn = {978-3-642-02158-9},
  langid = {english},
  file = {/Users/sebastian/Zotero/storage/5K5TDKMJ/Saberi and Wang - 2009 - Cutting a Cake for Five People.pdf}
}

@misc{schlotterOddPathsCycles2023,
  title = {Odd {{Paths}}, {{Cycles}} and {{T-joins}}: {{Connections}} and {{Algorithms}}},
  shorttitle = {Odd {{Paths}}, {{Cycles}} and \${{T}}\$-Joins},
  author = {Schlotter, Ildik{\'o} and Seb{\H o}, Andr{\'a}s},
  year = {2023},
  month = jun,
  number = {arXiv:2211.12862},
  eprint = {2211.12862},
  primaryclass = {cs, math},
  publisher = {arXiv},
  doi = {10.48550/arXiv.2211.12862},
  urldate = {2024-04-05},
  abstract = {Minimizing the weight of an edge set satisfying parity constraints is a challenging branch of combinatorial optimization as witnessed by the binary hypergraph chapter of Alexander Schrijver's book ``Combinatorial Optimization" (Chapter 80). This area contains relevant graph theory problems including open cases of the Max Cut problem and some multiflow problems. We clarify the interconnections between some of these problems and establish three levels of difficulties. On the one hand, we prove that the Shortest Odd Path problem in undirected graphs without cycles of negative total weight and several related problems are NP-hard, settling a long-standing open question asked by Lov{\textbackslash}'asz (Open Problem 27 in Schrijver's book ``Combinatorial Optimization''). On the other hand, we provide an efficient algorithm to the closely related and well-studied Minimum-weight Odd \$T\$-Join problem for non-negative weights: our algorithm runs in FPT time parameterized by \$c\$, where \$c\$ is the number of connected components in some efficiently computed minimum-weight \$T\$-join. If negative weights are also allowed, then finding a minimum-weight odd \${\textbackslash}\{s,t{\textbackslash}\}\$-join is equivalent to the Minimum-weight Odd \$T\$-Join problem for arbitrary weights, whose complexity is still only conjectured to be polynomial-time solvable. The analogous problems for digraphs are also considered.},
  archiveprefix = {arXiv},
  keywords = {68Q17 (Primary) 05C85 05C12 68R10 68Q25 (Secondary),Computer Science - Computational Complexity,F.2.2,G.2.1,G.2.2,Mathematics - Combinatorics},
  file = {/Users/sebastian/Zotero/storage/MGJISP5N/Schlotter and Sebő - 2023 - Odd Paths, Cycles and $T$-joins Connections and A.pdf;/Users/sebastian/Zotero/storage/YHVUP7G4/2211.html}
}

@misc{schlotterShortestTwoDisjoint2024,
  title = {Shortest Two Disjoint Paths in Conservative Graphs},
  author = {Schlotter, Ildik{\'o}},
  year = {2024},
  month = jan,
  number = {arXiv:2307.12602},
  eprint = {2307.12602},
  primaryclass = {cs},
  urldate = {2024-03-11},
  abstract = {We consider the following problem that we call the Shortest Two Disjoint Paths problem: given an undirected graph \$G=(V,E)\$ with edge weights \$w:E {\textbackslash}rightarrow {\textbackslash}mathbb\{R\}\$, two terminals \$s\$ and \$t\$ in \$G\$, find two internally vertex-disjoint paths between \$s\$ and \$t\$ with minimum total weight. As shown recently by Schlotter and Seb{\textbackslash}H\{o\} (2022), this problem becomes NP-hard if edges can have negative weights, even if the weight function is conservative, there are no cycles in \$G\$ with negative total weight. We propose a polynomial-time algorithm that solves the Shortest Two Disjoint Paths problem for conservative weights in the case when the negative-weight edges form a constant number of trees in \$G\$.},
  archiveprefix = {arXiv},
  file = {/Users/sebastian/Zotero/storage/SJUQKIVM/Schlotter - 2024 - Shortest two disjoint paths in conservative graphs.pdf}
}

@inproceedings{schurrFindingSinkTakes2002,
  title = {Finding the {{Sink Takes Some Time}}},
  booktitle = {Algorithms --- {{ESA}} 2002},
  author = {Schurr, Ingo and Szab{\'o}, Tibor},
  year = {2002},
  series = {Lecture {{Notes}} in {{Computer Science}}},
  pages = {833--844},
  publisher = {Springer},
  address = {Berlin, Heidelberg},
  doi = {10.1007/3-540-45749-6_72},
  abstract = {We give a worst-case {\textohm}(n2/log n )lower bound on the number of vertex evaluations a deterministic algorithm needs to perform in order to find the (unique)sink of a unique sink oriented n-dimensional cube. We consider the problem in the vertex-oracle model, introduced in [17]. In this model one can access the orientation implicitly, in each vertex evaluation an oracle discloses the orientation of the edges incident to the queried vertex.An important feature of the model is that the access is indeed arbitrary, the algorithm does not have to proceed on a directed path in a simplex-like fashion, but could ``jump around''.Our result is the first super-linear lower bound on the problem. The strategy we describe works even for acyclic orientations.We also give improved lower bounds for small values of n and fast algorithms in a couple of important special classes of orientations to demonstrate the difficulty of the lower bound problem.},
  isbn = {978-3-540-45749-7},
  langid = {english},
  keywords = {Deterministic Algorithm,German Science Foundation,Journal Version,Linear Complementarity Problem,Uniform Orientation},
  file = {/Users/sebastian/Zotero/storage/APV33SD2/Schurr and Szabó - 2002 - Finding the Sink Takes Some Time.pdf}
}

@article{schwartzFastProbabilisticAlgorithms1980,
  title = {Fast {{Probabilistic Algorithms}} for {{Verification}} of {{Polynomial Identities}}},
  author = {Schwartz, J. T.},
  year = {1980},
  month = oct,
  journal = {Journal of the ACM},
  volume = {27},
  number = {4},
  pages = {701--717},
  issn = {0004-5411},
  doi = {10.1145/322217.322225},
  urldate = {2024-04-05},
  file = {/Users/sebastian/Zotero/storage/B2RVKD4P/Schwartz - 1980 - Fast Probabilistic Algorithms for Verification of .pdf}
}

@book{shalev-shwartzUnderstandingMachineLearning2014,
  title = {Understanding Machine Learning: From Theory to Algorithms},
  shorttitle = {Understanding Machine Learning},
  author = {{Shalev-Shwartz}, Shai and {Ben-David}, Shai},
  year = {2014},
  publisher = {Cambridge University Press},
  address = {New York, NY, USA},
  abstract = {"Machine learning is one of the fastest growing areas of computer science, with far-reaching applications. The aim of this textbook is to introduce machine learning, and the algorithmic paradigms it offers, in a principled way. The book provides an extensive theoretical account of the fundamental ideas underlying machine learning and the mathematical derivations that transform these principles into practical algorithms. Following a presentation of the basics of the field, the book covers a wide array of central topics that have not been addressed by previous textbooks. These include a discussion of the computational complexity of learning and the concepts of convexity and stability; important algorithmic paradigms including stochastic gradient descent, neural networks, and structured output learning; and emerging theoretical concepts such as the PAC-Bayes approach and compression-based bounds. Designed for an advanced undergraduate or beginning graduate course, the text makes the fundamentals and algorithms of machine learning accessible to students and non-expert readers in statistics, computer science, mathematics, and engineering"--},
  isbn = {978-1-107-05713-5},
  lccn = {Q325.5 .S475 2014},
  keywords = {Algorithms,COMPUTERS / Computer Vision & Pattern Recognition,Machine learning}
}

@article{shapley1953stochastic,
  title = {Stochastic Games},
  author = {Shapley, L. S.},
  year = {1953},
  journal = {Proceedings of the national academy of sciences},
  volume = {39},
  number = {10},
  pages = {1095--1100},
  publisher = {National Acad Sciences},
  file = {/Users/sebastian/Zotero/storage/NGI4K4XD/1953 - Stochastic Games.pdf}
}

@article{shellmanAlgorithm825Deepcut2003,
  title = {Algorithm 825: {{A}} Deep-Cut Bisection Envelope Algorithm for Fixed Points},
  shorttitle = {Algorithm 825},
  author = {Shellman, Spencer and Sikorski, K.},
  year = {2003},
  month = sep,
  journal = {ACM Transactions on Mathematical Software},
  volume = {29},
  number = {3},
  pages = {309--325},
  issn = {0098-3500},
  doi = {10.1145/838250.838255},
  urldate = {2024-06-18},
  abstract = {We present the BEDFix (Bisection Envelope Deep-cut Fixed point) algorithm for the problem of approximating a fixed point of a function of two variables. The function must be Lipschitz continuous with constant 1 with respect to the infinity norm; such functions are commonly found in economics and game theory. The computed approximation satisfies a residual criterion given a specified error tolerance. The BEDFix algorithm improves the BEFix algorithm presented in Shellman and Sikorski [2002] by utilizing "deep cuts," that is, eliminating additional segments of the feasible domain which cannot contain a fixed point. The upper bound on the number of required function evaluations is the same for BEDFix and BEFix, but our numerical tests indicate that BEDFix significantly improves the average-case performance. In addition, we show how BEDFix may be used to solve the absolute criterion fixed point problem with significantly better performance than the simple iteration method, when the Lipschitz constant is less than but close to 1. BEDFix is highly efficient when used to compute residual solutions for bivariate functions, having a bound on function evaluations that is twice the logarithm of the reciprocal of the tolerance. In the tests described in this article, the number of evaluations performed by the method averaged 31 percent of this worst-case bound. BEDFix works for nonsmooth continuous functions, unlike methods that require gradient information; also, it handles functions with minimum Lipschitz constants equal to 1, whereas the complexity of simple iteration approaches infinity as the minimum Lipschitz constant approaches 1. When BEDFix is used to compute absolute criterion solutions, the worst-case complexity depends on the logarithm of the reciprocal of 1-q, where q is the Lipschitz constant, as well as on the logarithm of the reciprocal of the tolerance.},
  keywords = {economics,Fixed points,game theory,nonlinear partial differential equations},
  file = {/Users/sebastian/Zotero/storage/UN88LHT8/Shellman and Sikorski - 2003 - Algorithm 825 A deep-cut bisection envelope algor.pdf}
}

@article{shellmanRecursiveAlgorithmInfinitynorm2003,
  title = {A Recursive Algorithm for the Infinity-Norm Fixed Point Problem},
  author = {Shellman, Spencer and Sikorski, K.},
  year = {2003},
  month = dec,
  journal = {Journal of Complexity},
  volume = {19},
  number = {6},
  pages = {799--834},
  issn = {0885-064X},
  doi = {10.1016/j.jco.2003.06.001},
  urldate = {2025-01-14},
  abstract = {We present the PFix algorithm for the fixed point problem f(x)=x on a nonempty domain [a,b], where d⩾1, a,b{$\in$}Rd, and f is a Lipschitz continuous function with respect to the infinity norm, with constant q{$\leq$}1. The computed approximation {\~x} satisfies the residual criterion {\textbar}{\textbar}f({\~x})-{\~x}{\textbar}{\textbar}{$\infty\leq\varepsilon$}, where {$\varepsilon>$}0. In general, the algorithm requires no more than {$\sum$}i=1dsi function component evaluations, where s{$\equiv\lceil$}max(1,log2({\textbar}{\textbar}b-a{\textbar}{\textbar}{$\infty$}/{$\varepsilon$})){$\rceil$}+1. This upper bound has order O({$\lceil$}log2d(1/{$\varepsilon$}){$\rceil$}) as {$\varepsilon\rightarrow$}0. For the domain [0,1]d with {$\varepsilon<$}0.5 we prove a stronger result, i.e., an upper bound on the number of function component evaluations is (d+r-1r-1)+2(d+rr+1), where r{$\equiv\lceil$}log2(1/{$\varepsilon$}){$\rceil$}. This bound approaches O(rd/d!) as r{$\rightarrow\infty$}({$\varepsilon\rightarrow$}0) and O(dr+1/(r+1)!) as d{$\rightarrow\infty$}. We show that when q{$<$}1 the algorithm can also compute an approximation {\~x} satisfying the absolute criterion {\textbar}{\textbar}{\~x}-x{$\ast\vert\vert\infty\leq\varepsilon$}, where x{$\ast$} is the unique fixed point of f. The complexity in this case resembles the complexity of the residual criterion problem, but with tolerance {$\varepsilon$}(1-q) instead of {$\varepsilon$}. We show that when q{$>$}1 the absolute criterion problem has infinite worst-case complexity when information consists of function evaluations. Finally, we report several numerical tests in which the actual number of evaluations is usually much smaller than the upper complexity bound.},
  keywords = {Bisection algorithm,Computational complexity,Fixed point,Lipschitz functional},
  file = {/Users/sebastian/Zotero/storage/TTG7R8SN/S0885064X03000682.html}
}

@article{shellmanTwoDimensionalBisectionEnvelope2002,
  title = {A {{Two-Dimensional Bisection Envelope Algorithm}} for {{Fixed Points}}},
  author = {Shellman, Spencer and Sikorski, K.},
  year = {2002},
  month = jun,
  journal = {Journal of Complexity},
  volume = {18},
  number = {2},
  pages = {641--659},
  issn = {0885-064X},
  doi = {10.1006/jcom.2001.0625},
  urldate = {2024-06-18},
  abstract = {In this paper we present a new algorithm for the two-dimensional fixed point problem f(x)=x on the domain 0, 1] 0, 1], where f is a Lipschitz continuous function with respect to the infinity norm, with constant 1. The computed approximation x satisfies f(x) x {$\infty$} for a specified tolerance {$<$}0.5. The upper bound on the number of required function evaluations is given by 2 log2(1/ ) +1. Similar bounds were derived for the case of the 2-norm by Z. Huang et al. (1999, J. Complexity15, 200 213), our bound is the first for the infinity norm case.},
  file = {/Users/sebastian/Zotero/storage/VAI3KQTA/Shellman and Sikorski - 2002 - A Two-Dimensional Bisection Envelope Algorithm for.pdf}
}

@article{sikorskiComputationalComplexityFixed2009,
  title = {Computational Complexity of Fixed Points},
  author = {Sikorski, Krzysztof},
  year = {2009},
  month = dec,
  journal = {Journal of Fixed Point Theory and Applications},
  volume = {6},
  number = {2},
  pages = {249--283},
  issn = {1661-7746},
  doi = {10.1007/s11784-009-0128-3},
  urldate = {2025-01-14},
  abstract = {A review of computational complexity results for approximating fixed points of Lipschitz functions is presented. Univariate and multivariate results are summarized for the second and infinity norm cases as well as the absolute, residual and relative error criteria. Contractive, nonexpansive, directionally nonexpansive, and expansive classes of functions are considered and optimal or nearly optimal algorithms exhibited. Some numerical experiments are summarized. A literature devoted to the complexity aspects of fixed point problems is listed.},
  langid = {english},
  keywords = {Computational complexity,economics,fixed points,game theory,Primary 47H10 65M10,Secondary 65Y20 68Q25},
  file = {/Users/sebastian/Zotero/storage/BV9RLBVH/Sikorski - 2009 - Computational complexity of fixed points.pdf}
}

@article{sikorskiEllipsoidAlgorithmComputation1993,
  title = {An {{Ellipsoid Algorithm}} for the {{Computation}} of {{Fixed Points}}},
  author = {Sikorski, K. and Tsay, C.W. and Wo{\'z}niakowski, H.},
  year = {1993},
  month = mar,
  journal = {Journal of Complexity},
  volume = {9},
  number = {1},
  pages = {181--200},
  issn = {0885-064X},
  doi = {10.1006/jcom.1993.1013},
  urldate = {2024-06-18},
  abstract = {We consider the problem of approximating fixed points of contractive functions with using the absolute error criterion. It was proven in (A. S. Nemirovsky, 1991. J. Complexity, 7, 121-130) that it is impossible to essentially improve the efficiency of the simple iteration whenever the dimension of the domain of contractive functions is large. However, for a moderate dimension we exhibit a fixed point ellipsoid algorithm which is much more efficient than the simple iteration for mildly contractive functions. This algorithm is based on Khachiyan s construction of minimal volume ellipsoids used for solving linear programming.},
  file = {/Users/sebastian/Zotero/storage/6WJUWPHZ/1-s2.0-S0885064X83710137-main.pdf}
}

@book{stanleyCatalanNumbers2015,
  title = {Catalan Numbers},
  author = {Stanley, Richard P.},
  year = {2015},
  publisher = {Cambridge University Press},
  address = {Cambridge},
  abstract = {Catalan numbers are probably the most ubiquitous sequence of numbers in mathematics. This book gives for the first time a comprehensive collection of their properties and applications to combinatorics, algebra, analysis, number theory, probability theory, geometry, topology, and other areas. Following an introduction to the basic properties of Catalan numbers, the book presents 214 different kinds of objects counted by them in the form of exercises with solutions. The reader can try solving the exercises or simply browse through them. Some 68 additional exercises with prescribed difficulty levels present various properties of Catalan numbers and related numbers, such as Fuss-Catalan numbers, Motzkin numbers, Schr{\"o}der numbers, Narayana numbers, super Catalan numbers, q-Catalan numbers and (q, t)-Catalan numbers. The book ends with a history of Catalan numbers by Igor Pak and a glossary of key terms. Whether your interest in mathematics is recreation or research, you will find plenty of fascinating and stimulating facts here},
  isbn = {978-1-139-87149-5},
  langid = {english},
  annotation = {OCLC: 906944017}
}

@article{stickneyDigraphModelsBardType1978,
  title = {Digraph {{Models}} of {{Bard-Type Algorithms}} for the {{Linear Complementarity Problem}}},
  author = {Stickney, Alan and Watson, Layne},
  year = {1978},
  month = nov,
  journal = {Math. Oper. Res.},
  volume = {3},
  number = {4},
  pages = {322--333},
  issn = {0364-765X},
  doi = {10.1287/moor.3.4.322},
  urldate = {2024-07-18},
  abstract = {For M {$\in$} En{\texttimes}n and q {$\in$} En, the linear complementarity problem is to find vectors w, z {$\in$} En such that w-Mz = q, w {$\geq$} 0, z {$\geq$} 0, wtz = 0. A family of algorithms based on complementary pivoting for solving this problem is modelled by digraphs. These digraphs show that such algorithms can cycle even for symmetric, positive deFinite M, and provide some insight into the algorithms' behavior. For a P-matrix M, it is proved that if the solution to the complementarity problem can be obtained by k principal pivots, then it can be obtained by k Bard-type pivots. Furthermore, the digraphs provide simple geometric proofs of some of Murty's algebraic results. The digraphs, apart from their use as models, also raise some interesting graph-theoretic questions.},
  file = {/Users/sebastian/Zotero/storage/ZI2H5X28/Stickney and Watson - 1978 - Digraph Models of Bard-Type Algorithms for the Lin.pdf}
}

@article{sukErdosSzekeresConvexPolygon2016,
  title = {On the {{Erd{\H o}s-Szekeres}} Convex Polygon Problem},
  author = {Suk, Andrew},
  year = {2016},
  month = sep,
  journal = {Journal of the American Mathematical Society},
  volume = {30},
  number = {4},
  pages = {1047--1053},
  issn = {0894-0347, 1088-6834},
  doi = {10.1090/jams/869},
  urldate = {2023-08-10},
  abstract = {Let                                                                                               E                       S                       (                       n                       )                                          ES(n)                                                                  be the smallest integer such that any set of                                                                                               E                       S                       (                       n                       )                                          ES(n)                                                                  points in the plane in general position contains                                                                        n                     n                                                                  points in convex position. In their seminal 1935 paper, Erd{\H o}s and Szekeres showed that                                                                                               E                       S                       (                       n                       )                                                {$\leq$}                                                                                                                                                                                       (                                                                                                                                               2                               n                                                                -                                                                                               4                                                                                         n                                                                -                                                                                               2                                                                                                                                               )                                                                                                                               +                       1                       =                                                4                                                    n                                                        -                                                                                   o                           (                           n                           )                                                                                          ES(n) {\textbackslash}leq \{2n - 4{\textbackslash}choose n-2\} + 1 = 4{\textasciicircum}\{n -o(n)\}                                                                  . In 1960, they showed that                                                                                               E                       S                       (                       n                       )                                                {$\geq$}                                                                                                2                                                    n                                                        -                                                                                   2                                                                       +                       1                                          ES(n) {\textbackslash}geq 2{\textasciicircum}\{n-2\} + 1                                                                  and conjectured this to be optimal. In this paper, we nearly settle the Erd{\H o}s-Szekeres conjecture by showing that                                                                                               E                       S                       (                       n                       )                       =                                                2                                                    n                           +                           o                           (                           n                           )                                                                                          ES(n) =2{\textasciicircum}\{n +o(n)\}                                                                  .},
  langid = {english},
  file = {/Users/sebastian/Zotero/storage/TE5HGFQR/Suk - 2016 - On the Erdős-Szekeres convex polygon problem.pdf}
}

@article{suurballeDisjointPathsNetwork1974,
  title = {Disjoint Paths in a Network},
  author = {Suurballe, J. W.},
  year = {1974},
  month = jan,
  journal = {Networks},
  volume = {4},
  number = {2},
  pages = {125--145},
  issn = {0028-3045, 1097-0037},
  doi = {10.1002/net.3230040204},
  urldate = {2024-04-05},
  abstract = {Routes between two given nodes of a netuork are called diversified if they are node-dis j o i n t , except a t the terminals. Diversified routes are required for r e l i a b i l i t y i n c o m n i c a tion, and an additional c r i t e r i o n i s that t h e i r total cost, assumed to be the sum of individual arc lengths or costs, i s minimwn. An algorithm and related theory i s described f o r a general nwnber K of node-disjoint paths with m i n i m total length. The algorithm applies shortest path labeling algorithms fdliar i n the literature. K node-disjoint p a t h s are found i n K i t e r a t i o n s of a single shortest path algorithm.},
  copyright = {http://onlinelibrary.wiley.com/termsAndConditions\#vor},
  langid = {english},
  file = {/Users/sebastian/Zotero/storage/E2L6KVAK/Suurballe - 1974 - Disjoint paths in a network.pdf}
}

@inproceedings{svenssonLinearComplementarityPMatrices2007,
  title = {Linear {{Complementarity}} and {{P-Matrices}} for {{Stochastic Games}}},
  booktitle = {Perspectives of {{Systems Informatics}}},
  author = {Svensson, Ola and Vorobyov, Sergei},
  year = {2007},
  pages = {409--423},
  publisher = {Springer},
  address = {Berlin, Heidelberg},
  doi = {10.1007/978-3-540-70881-0_35},
  abstract = {We define the first nontrivial polynomially recognizable subclass of P-matrix Generalized Linear Complementarity Problems (GLCPs) with a subexponential pivot rule. No such classes/rules were previously known. We show that a subclass of Shapley turn-based stochastic games, subsuming Condon's simple stochastic games, is reducible to the new class of GLCPs. Based on this we suggest the new strongly subexponential combinatorial algorithms for these games.},
  isbn = {978-3-540-70881-0},
  langid = {english},
  keywords = {Diagonal Dominance,Inductive Hypothesis,Linear Complementarity Problem,Linear Programming Problem,Stochastic Game},
  file = {/Users/sebastian/Zotero/storage/7ULCJ6IL/Svensson and Vorobyov - 2007 - Linear Complementarity and P-Matrices for Stochastic Games.pdf}
}

@inproceedings{svenssonMatchingProblemGeneral2017,
  title = {The {{Matching Problem}} in {{General Graphs Is}} in {{Quasi-NC}}},
  booktitle = {2017 {{IEEE}} 58th {{Annual Symposium}} on {{Foundations}} of {{Computer Science}} ({{FOCS}})},
  author = {Svensson, Ola and Tarnawski, Jakub},
  year = {2017},
  month = oct,
  pages = {696--707},
  publisher = {IEEE},
  address = {Berkeley, CA},
  doi = {10.1109/FOCS.2017.70},
  urldate = {2024-02-23},
  isbn = {978-1-5386-3464-6},
  file = {/Users/sebastian/Zotero/storage/84PEDHMZ/1704.01929.pdf}
}

@inproceedings{szaboUniqueSinkOrientations2001,
  title = {Unique Sink Orientations of Cubes},
  booktitle = {Proceedings 42nd {{IEEE Symposium}} on {{Foundations}} of {{Computer Science}}},
  author = {Szabo, T. and Welzl, E.},
  year = {2001},
  pages = {547--555},
  publisher = {IEEE},
  address = {Newport Beach, CA, USA},
  doi = {10.1109/SFCS.2001.959931},
  urldate = {2024-07-03},
  abstract = {Suppose we are given (the edge graph of) an {\`O}dimensional hypercube with its edges oriented so that every face has a unique sink. Such an orientation is called a unique sink orientation, and we are interested in finding the unique sink of the whole cube, when the orientation is given implicitly. The basic operation available is the socalled vertex evaluation, where we can access an arbitrary vertex of the cube, for which we obtain the orientations of the incident edges.},
  copyright = {https://doi.org/10.15223/policy-029},
  isbn = {978-0-7695-1390-4},
  langid = {english},
  keywords = {Artificial intelligence,Character generation,Combinatorial mathematics,Computational geometry,Computer science,Cost accounting,Hypercubes,Labeling,Lattices,Radio access networks},
  file = {/Users/sebastian/Zotero/storage/FG69FTRX/Szabo and Welzl - 2001 - Unique sink orientations of cubes.pdf;/Users/sebastian/Zotero/storage/HK7JDP9F/Szabo and Welzl - 2001 - Unique sink orientations of cubes.pdf;/Users/sebastian/Zotero/storage/V8Y2RMG6/959931.html}
}

@article{tarskiLatticetheoreticalFixpointTheorem1955,
  title = {A Lattice-Theoretical Fixpoint Theorem and Its Applications.},
  author = {Tarski, Alfred},
  year = {1955},
  journal = {Pacific J. Math.},
  volume = {5},
  number = {4},
  pages = {285--309},
  urldate = {2023-08-10},
  langid = {english},
  file = {/Users/sebastian/Zotero/storage/UMVN9QTQ/1103044538.html}
}

@misc{tellDefiningPPTsearchProblems2024,
  title = {On Defining {{PPT-search}} Problems and {{PPT-optimization}} Problems},
  author = {Tell, Roei},
  year = {2024},
  month = oct,
  number = {TR24-163},
  eprint = {TR24-163},
  publisher = {Electronic Colloquium on Computational Complexity},
  issn = {1433-8092},
  urldate = {2024-10-25},
  abstract = {This note revisits the study of search problems that are solvable in probabilistic polynomial time. Previously, Goldreich (2011) introduced a class called ``-search'', and studied search-to-decision reductions for problems in this class. In Goldreich's original formulation, the definition of what counts as ``successfully solving'' a -search problem is implicit, and this opens the door to multiple possible interpretations. We suggest two approaches: 1. We propose *our preferred definition* for the notion of solving -search problems. The resulting class of search problems is useful, since it captures natural problems of interest, and since it has valuable technical properties. However, the a-priori rationale for studying the class is not fully satisfying. 2. We propose an *alternative formulation* of the class of search problems solvable in ppt, which is focused on optimization (i.e., finding a solution of best quality). The resulting class has a clearer meaning, and it turns out to be *computationally equivalent* to the class resulting from our aforementioned definition of -search (under deterministic polynomial-time reductions). The optimization-based definition seems cleaner and more appealing. However, since the two classes above are computationally equivalent, it can be useful to use whichever definition is technically more convenient in the relevant context. *On the companion paper.* This paper presents my perspective on a joint project conducted together with Oded Goldreich, whereas Oded's perspective is presented in the companion paper (Goldreich, 2024). The technical contents of both papers has significant overlap, and both papers propose the same definition that is referred to in the current text as -optimization (i.e., Definition 5).},
  archiveprefix = {Electronic Colloquium on Computational Complexity},
  langid = {english},
  file = {/Users/sebastian/Zotero/storage/J5WZDJPL/Tell - 2024 - On defining PPT-search problems and PPT-optimization problems.pdf}
}

@article{thielNonConvexOptimization2019,
  title = {A {{Non}}--{{Convex Optimization Approach}} to {{Correlation Clustering}}},
  author = {Thiel, Erik and Chehreghani, Morteza Haghir and Dubhashi, Devdatt},
  year = {2019},
  month = jul,
  journal = {Proceedings of the AAAI Conference on Artificial Intelligence},
  volume = {33},
  number = {01},
  pages = {5159--5166},
  issn = {2374-3468, 2159-5399},
  doi = {10.1609/aaai.v33i01.33015159},
  urldate = {2023-08-10},
  abstract = {We develop a non-convex optimization approach to correlation clustering using the Frank-Wolfe (FW) framework. We show that the basic approach leads to a simple and natural local search algorithm with guaranteed convergence. This algorithm already beats alternative algorithms by substantial margins in both running time and quality of the clustering. Using ideas from FW algorithms, we develop subsampling and variance reduction paradigms for this approach. This yields both a practical improvement of the algorithm and some interesting further directions to investigate. We demonstrate the performance on both synthetic and real world data sets.},
  file = {/Users/sebastian/Zotero/storage/D74G886T/Thiel et al. - 2019 - A Non–Convex Optimization Approach to Correlation .pdf}
}

@incollection{tholeyFindingDisjointPaths2005,
  title = {Finding {{Disjoint Paths}} on {{Directed Acyclic Graphs}}},
  booktitle = {Graph-{{Theoretic Concepts}} in {{Computer Science}}},
  author = {Tholey, Torsten},
  year = {2005},
  volume = {3787},
  pages = {319--330},
  publisher = {Springer Berlin Heidelberg},
  address = {Berlin, Heidelberg},
  doi = {10.1007/11604686_28},
  urldate = {2024-11-21},
  abstract = {Given k + 1 pairs of vertices (s1, s2), (u1, v1), . . . , (uk, vk) of a directed acyclic graph, we show that a modified version of a data structure of Suurballe and Tarjan can output, for each pair (ul, vl) with 1 {$\leq$} l {$\leq$} k, a tuple (s1, t1, s2, t2) with \{t1, t2\} = \{ul, vl\} in constant time such that there are two disjoint paths p1, from s1 to t1, and p2, from s2 to t2, if such a tuple exists. Disjoint can mean vertex- as well as edgedisjoint. As an application we show that the presented data structure can be used to improve the previous best known running time O(mn) for the so called 2-disjoint paths problem on directed acyclic graphs to O(m(log2+m/n n) + n log3 n). In this problem, given a tuple (s1, s2, t1, t2) of four vertices, we want to construct two disjoint paths p1, from s1 to t1, and p2, from s2 to t2, if such paths exist.},
  isbn = {978-3-540-31000-6 978-3-540-31468-4},
  langid = {english},
  file = {/Users/sebastian/Zotero/storage/QHGVDTMI/Tholey - 2005 - Finding Disjoint Paths on Directed Acyclic Graphs.pdf}
}

@article{thomassenEvenCyclesDirected1985,
  title = {Even {{Cycles}} in {{Directed Graphs}}},
  author = {Thomassen, Carsten},
  year = {1985},
  month = mar,
  journal = {European Journal of Combinatorics},
  volume = {6},
  number = {1},
  pages = {85--89},
  issn = {0195-6698},
  doi = {10.1016/S0195-6698(85)80025-1},
  urldate = {2024-04-05},
  abstract = {We discuss the complexity of finding a cycle of even length in a digraph. In particular, we observe that finding a cycle of prescribed parity through a prescribed edge is NP-complete. Also, we settle a problem of Lov{\'a}sz [11] and disprove a conjecture of Seymour [15] by describing, for each natural number k, a digraph of minimum outdegree k and with no even cycle. We prove that a digraph of order n and minimum outdegree [log2n] + 1 contains, for each edge set E, a cycle containing an even number of edges of E and we show that this is best possible. A modification of the construction yields counterexamples to Hamidoune's conjecture [5] on local connectivity in digraphs of large indegrees and outdegrees.},
  file = {/Users/sebastian/Zotero/storage/NECC5HPV/Thomassen - 1985 - Even Cycles in Directed Graphs.pdf}
}

@phdthesis{thomasUniqueSinkOrientations2017,
  title = {Unique {{Sink Orientations}}: {{Complexity}}, {{Structure}} and {{Algorithms}}},
  author = {Thomas, Antonios},
  year = {2017},
  school = {ETH Zurich},
  file = {/Users/sebastian/Zotero/storage/Y9YXKWDB/thesis.pdf}
}

@book{Thompson_1996,
  title = {Minkowski Geometry},
  author = {Thompson, A. C.},
  year = {1996},
  series = {Encyclopedia of Mathematics and Its Applications},
  publisher = {Cambridge University Press},
  address = {Cambridge},
  file = {/Users/sebastian/Zotero/storage/ZB6E6X6I/minkowsky geometry.pdf}
}

@misc{tipleaLowWeightPolynomial2024,
  title = {On the {{Low Weight Polynomial Multiple Problem}}},
  author = {{\c T}iplea, Ferucio Lauren{\c t}iu and L{\u a}z{\u a}rescu, Simona-Maria},
  year = {2024},
  month = oct,
  number = {arXiv:2410.10224},
  eprint = {2410.10224},
  publisher = {arXiv},
  doi = {10.48550/arXiv.2410.10224},
  urldate = {2024-10-25},
  abstract = {Finding a low-weight multiple (LWPM) of a given polynomial is very useful in the cryptanalysis of stream ciphers and arithmetic in finite fields. There is no known deterministic polynomial time complexity algorithm for solving this problem, and the most efficient algorithms are based on a time/memory trade-off. The widespread perception is that this problem is difficult. In this paper, we establish a relationship between the LWPM problem and the MAX-SAT problem of determining an assignment that maximizes the number of valid clauses of a system of affine Boolean clauses. This relationship shows that any algorithm that can compute the optimum of a MAX-SAT instance can also compute the optimum of an equivalent LWPM instance. It also confirms the perception that the LWPM problem is difficult.},
  archiveprefix = {arXiv},
  keywords = {Computer Science - Computational Complexity},
  file = {/Users/sebastian/Zotero/storage/JA5WGAWH/Ţiplea and Lăzărescu - 2024 - On the Low Weight Polynomial Multiple Problem.pdf;/Users/sebastian/Zotero/storage/SA7L7657/2410.html}
}

@inproceedings{tomassoClusterBoostingData2022,
  title = {Cluster Boosting and Data Discovery in Social Networks},
  booktitle = {Proceedings of the 37th {{ACM}}/{{SIGAPP Symposium}} on {{Applied Computing}}},
  author = {Tomasso, Maria and Rusnak, Lucas J. and Te{\v s}i{\'c}, Jelena},
  year = {2022},
  month = apr,
  pages = {1801--1803},
  publisher = {ACM},
  address = {Virtual Event},
  doi = {10.1145/3477314.3507243},
  urldate = {2023-08-10},
  isbn = {978-1-4503-8713-2},
  langid = {english}
}

@article{tothmereszAlgorithmicAspectsRotorrouting2018,
  title = {Algorithmic Aspects of Rotor-Routing and the Notion of Linear Equivalence},
  author = {T{\'o}thm{\'e}r{\'e}sz, Lilla},
  year = {2018},
  month = feb,
  journal = {Discrete Applied Mathematics},
  volume = {236},
  pages = {428--437},
  issn = {0166-218X},
  doi = {10.1016/j.dam.2017.11.008},
  urldate = {2024-05-02},
  abstract = {We define the analogue of linear equivalence of graph divisors for the rotor-router model, and use it to prove polynomial time computability of some problems related to rotor-routing. Using the connection between linear equivalence for chip-firing and for rotor-routing, we give a simple proof for the fact that the number of rotor-router unicycle-orbits equals the order of the Picard group. We also show that the rotor-router action of the Picard group on the set of spanning in-arborescences can be interpreted in terms of the linear equivalence.},
  keywords = {Linear equivalence,Picard group,Polynomial time decidability,Rotor-routing},
  file = {/Users/sebastian/Zotero/storage/CKW5TMYH/Tóthmérész - 2018 - Algorithmic aspects of rotor-routing and the notio.pdf}
}

@article{tothmereszRotorroutingReachabilityEasy2022,
  title = {Rotor-Routing Reachability Is Easy, Chip-Firing Reachability Is Hard},
  author = {T{\'o}thm{\'e}r{\'e}sz, Lilla},
  year = {2022},
  month = mar,
  journal = {European Journal of Combinatorics},
  volume = {101},
  pages = {103466},
  issn = {0195-6698},
  doi = {10.1016/j.ejc.2021.103466},
  urldate = {2024-05-02},
  abstract = {Chip-firing and rotor-routing are two well-studied examples of abelian networks. We study the complexity of their respective reachability problems. We show that the rotor-routing reachability problem is decidable in polynomial time, and we give a simple characterization of when a chip-and-rotor configuration is reachable from another one. For chip-firing, it has been known that the reachability problem is in P if we have a class of graphs whose period length is polynomial (for example, Eulerian digraphs). Here we show that in the general case, chip-firing reachability is hard in the sense that if the chip-firing reachability problem were in P for general digraphs, then the polynomial hierarchy would collapse to NP. We encode graphs by their adjacency matrix, and we encode ribbon structures ``succinctly'', only remembering the number of consecutive parallel edges.},
  file = {/Users/sebastian/Zotero/storage/3PY9SVPL/Tóthmérész - 2022 - Rotor-routing reachability is easy, chip-firing re.pdf;/Users/sebastian/Zotero/storage/ALHEMMAL/S0195669821001608.html}
}

@article{vanmechelenBenchmarkingClusterAnalysis2018,
  title = {Benchmarking in Cluster Analysis: {{A}} White Paper},
  shorttitle = {Benchmarking in Cluster Analysis},
  author = {Van Mechelen, Iven and Boulesteix, Anne-Laure and Dangl, Rainer and Dean, Nema and Guyon, Isabelle and Hennig, Christian and Leisch, Friedrich and Steinley, Douglas},
  year = {2018},
  publisher = {arXiv},
  doi = {10.48550/ARXIV.1809.10496},
  urldate = {2023-08-10},
  abstract = {Note: A revised version of this is now published. Please cite and read (it's open access): Van Mechelen, I., Boulesteix, A.-L., Dangl, R., Dean, N., Hennig, C., Leisch, F., Steinley, D., Warrens, M. J. (2023). A white paper on good research practices in benchmarking: The case of cluster analysis. WIREs Data Mining and Knowledge Discovery, e1511. https://doi.org/10.1002/widm.1511 To achieve scientific progress in terms of building a cumulative body of knowledge, careful attention to benchmarking is of the utmost importance. This means that proposals of new methods of data pre-processing, new data-analytic techniques, and new methods of output post-processing, should be extensively and carefully compared with existing alternatives, and that existing methods should be subjected to neutral comparison studies. To date, benchmarking and recommendations for benchmarking have been frequently seen in the context of supervised learning. Unfortunately, there has been a dearth of guidelines for benchmarking in an unsupervised setting, with the area of clustering as an important subdomain. To address this problem, discussion is given to the theoretical conceptual underpinnings of benchmarking in the field of cluster analysis by means of simulated as well as empirical data. Subsequently, the practicalities of how to address benchmarking questions in clustering are dealt with, and foundational recommendations are made.},
  copyright = {arXiv.org perpetual, non-exclusive license},
  keywords = {62H30,FOS: Computer and information sciences,Other Statistics (stat.OT)}
}

@article{vanzuylenDeterministicPivotingAlgorithms2009,
  title = {Deterministic {{Pivoting Algorithms}} for {{Constrained Ranking}} and {{Clustering Problems}}},
  author = {Van Zuylen, Anke and Williamson, David P.},
  year = {2009},
  month = aug,
  journal = {Mathematics of Operations Research},
  volume = {34},
  number = {3},
  pages = {594--620},
  issn = {0364-765X, 1526-5471},
  doi = {10.1287/moor.1090.0385},
  urldate = {2023-08-10},
  abstract = {We consider ranking and clustering problems related to the aggregation of inconsistent information, in particular, rank aggregation, (weighted) feedback arc set in tournaments, consensus and correlation clustering, and hierarchical clustering. Ailon et al. [Ailon, N., M. Charikar, A. Newman. 2005. Aggregating inconsistent information: Ranking and clustering. Proc. 37th Annual ACM Sympos. Theory Comput. (STOC '05), 684--693], Ailon and Charikar [Ailon, N., M. Charikar. 2005. Fitting tree metrics: Hierarchical clustering and phylogeny. Proc. 46th Annual IEEE Sympos. Foundations Comput. Sci. (FOCS '05), 73--82], and Ailon [Ailon, N. 2007. Aggregation of partial rankings, p-ratings and top-m lists. Proc. 18th Annual ACM-SIAM Sympos. Discrete Algorithms (SODA '07), 415--424] proposed randomized constant factor approximation algorithms for these problems, which recursively generate a solution by choosing a random vertex as ``pivot'' and dividing the remaining vertices into two groups based on the pivot vertex.             In this paper, we answer an open question in these works by giving deterministic approximation algorithms for these problems. The analysis of our algorithms is simpler than the analysis of the randomized algorithms. In addition, we consider the problem of finding minimum-cost rankings and clusterings that must obey certain constraints (e.g., an input partial order in the case of ranking problems), which were introduced by Hegde and Jain [Hegde, R., K. Jain. 2006. Personal communication]. We show that the first type of algorithms we propose can also handle these constrained problems. In addition, we show that in the case of a rank aggregation or consensus clustering problem, if the input rankings or clusterings obey the constraints, then we can always ensure that the output of any algorithm obeys the constraints without increasing the objective value of the solution.},
  langid = {english}
}

@inproceedings{vaswaniAttentionAllYou2017,
  title = {Attention Is {{All}} You {{Need}}},
  booktitle = {Advances in {{Neural Information Processing Systems}}},
  author = {Vaswani, Ashish and Shazeer, Noam and Parmar, Niki and Uszkoreit, Jakob and Jones, Llion and Gomez, Aidan N and Kaiser, {\L}ukasz and Polosukhin, Illia},
  year = {2017},
  volume = {30},
  publisher = {Curran Associates, Inc.},
  urldate = {2023-08-10},
  abstract = {The dominant sequence transduction models are based on complex recurrent orconvolutional neural networks in an encoder and decoder configuration. The best performing such models also connect the encoder and decoder through an attentionm echanisms.  We propose a novel, simple network architecture based solely onan attention mechanism, dispensing with recurrence and convolutions entirely.Experiments on two machine translation tasks show these models to be superiorin quality while being more parallelizable and requiring significantly less timeto train. Our single model with 165 million parameters, achieves 27.5 BLEU onEnglish-to-German translation, improving over the existing best ensemble result by over 1 BLEU. On English-to-French translation, we outperform the previoussingle state-of-the-art with model by 0.7 BLEU, achieving a BLEU score of 41.1.},
  file = {/Users/sebastian/Zotero/storage/KAJCTFJF/Vaswani et al. - 2017 - Attention is All you Need.pdf}
}

@inproceedings{vaziraniNCAlgorithmsComputing1988,
  title = {{{NC}} Algorithms for Computing the Number of Perfect Matchings in {{K3}},3-Free Graphs and Related Problems},
  booktitle = {{{SWAT}} 88},
  author = {Vazirani, Vijay V.},
  year = {1988},
  pages = {233--242},
  publisher = {Springer},
  address = {Berlin, Heidelberg},
  doi = {10.1007/3-540-19487-8_27},
  abstract = {We show that the problem of computing the number of perfect matchings in K3,3-free graphs is in NC. This stands in striking contrast with the \#P-completeness of counting the number of perfect matchings in arbitrary graphs. As corollaries we obtain NC algorithms for checking if a given K3,3-free graph has a perfect matching and if it has an EXACT MATCHING. Our result also opens up the possibility of obtaining an NC algorithm for finding a perfect matching in K3,3-free graphs.},
  isbn = {978-3-540-39288-0},
  langid = {english},
  keywords = {Decomposition Tree,Parallel Algorithm,Perfect Match,Planar Graph,Polynomial Time Algorithm},
  file = {/Users/sebastian/Zotero/storage/CRAFFR8H/Vazirani - 1988 - NC algorithms for computing the number of perfect .pdf}
}

@article{verbargApproximateCenterPoints1997,
  title = {Approximate Center Points in Dense Point Sets},
  author = {Verbarg, Knut},
  year = {1997},
  month = mar,
  journal = {Information Processing Letters},
  volume = {61},
  number = {5},
  pages = {271--278},
  issn = {0020-0190},
  doi = {10.1016/S0020-0190(97)00017-3},
  urldate = {2024-11-06},
  abstract = {The notion of center points is one way to generalize the median of a finite ordered point set to higher dimensions. A set P of n points in d-dimensional Euclidean space Ed is {$\delta$}-dense, if the ratio of the largest to the smallest distance between any two points of P is bounded by {$\delta$}n1d, with some constant {$\delta$}. We describe a simple, yet efficient algorithm to compute an approximate center point for a {$\delta$}-dense set P in time O(dn). The quality of the approximation depends on {$\delta$} and exponentially on the dimension d, where the absolute value of the exponent is in {\textohm}(d log d). We also present an iteration method with a linear rate of convergence, which computes an improved 1(2(d - 1)({$\delta$} + 1)d)-center point for sufficiently large n.},
  keywords = {Center point,Cluster analysis,Computational geometry,Density},
  file = {/Users/sebastian/Zotero/storage/EEWY7XW2/S0020019097000173.html}
}

@article{vonstengelZeroSumGamesLinear2023,
  title = {Zero-{{Sum Games}} and {{Linear Programming Duality}}},
  author = {{von Stengel}, Bernhard},
  year = {2023},
  month = jul,
  journal = {Mathematics of Operations Research},
  publisher = {INFORMS},
  issn = {0364-765X},
  doi = {10.1287/moor.2022.0149},
  urldate = {2023-10-26},
  abstract = {The minimax theorem for zero-sum games is easily proved from the strong duality theorem of linear programming. For the converse direction, the standard proof by Dantzig is known to be incomplete. We explain and combine classical theorems about solving linear equations with nonnegative variables to give a correct alternative proof more directly than Adler. We also extend Dantzig's game so that any max-min strategy gives either an optimal LP solution or shows that none exists.},
  keywords = {lemma of Farkas,linear programming duality,minimax theorem,Primary: 91A05,secondary: 90C05,zero-sum game},
  file = {/Users/sebastian/Zotero/storage/EM724CSD/von Stengel - 2023 - Zero-Sum Games and Linear Programming Duality.pdf}
}

@book{wainwrightHighDimensionalStatisticsNonAsymptotic2019,
  title = {High-{{Dimensional Statistics}}: {{A Non-Asymptotic Viewpoint}}},
  shorttitle = {High-{{Dimensional Statistics}}},
  author = {Wainwright, Martin J.},
  year = {2019},
  month = feb,
  edition = {1},
  publisher = {Cambridge University Press},
  doi = {10.1017/9781108627771},
  urldate = {2023-08-10},
  isbn = {978-1-108-62777-1 978-1-108-49802-9},
  file = {/Users/sebastian/Zotero/storage/IE5I6SXX/Wainwright - 2019 - High-Dimensional Statistics A Non-Asymptotic View.pdf}
}

@article{warshallTheoremBooleanMatrices1962,
  title = {A {{Theorem}} on {{Boolean Matrices}}},
  author = {Warshall, Stephen},
  year = {1962},
  month = jan,
  journal = {Journal of the ACM},
  volume = {9},
  number = {1},
  pages = {11--12},
  issn = {0004-5411},
  doi = {10.1145/321105.321107},
  urldate = {2024-04-05},
  file = {/Users/sebastian/Zotero/storage/2B4J4H87/Warshall - 1962 - A Theorem on Boolean Matrices.pdf}
}

@article{websterRecursiveArrivalProblem2023,
  title = {The {{Recursive Arrival Problem}}},
  author = {Webster, Thomas},
  year = {2023},
  month = sep,
  journal = {Electronic Proceedings in Theoretical Computer Science},
  volume = {390},
  eprint = {2310.01004},
  primaryclass = {cs},
  pages = {168--184},
  issn = {2075-2180},
  doi = {10.4204/EPTCS.390.11},
  urldate = {2025-01-24},
  abstract = {We study an extension of the Arrival problem, called Recursive Arrival, inspired by Recursive State Machines, which allows for a family of switching graphs that can call each other in a recursive way. We study the computational complexity of deciding whether a Recursive Arrival instance terminates at a given target vertex. We show this problem is contained in NP {\textbackslash}cap coNP, and we show that a search version of the problem lies in UEOPL, and hence in EOPL = PLS {\textbackslash}cap PPAD. Furthermore, we show P-hardness of the Recursive Arrival decision problem. By contrast, the current best-known hardness result for Arrival is PL-hardness.},
  archiveprefix = {arXiv},
  keywords = {Computer Science - Computational Complexity},
  file = {/Users/sebastian/Zotero/storage/N6CLGY57/Webster - 2023 - The Recursive Arrival Problem.pdf;/Users/sebastian/Zotero/storage/7VEC7FRH/2310.html}
}

@inproceedings{websterStochasticArrivalProblem2022,
  title = {The {{Stochastic Arrival Problem}}},
  booktitle = {Reachability {{Problems}}},
  author = {Webster, Thomas},
  year = {2022},
  pages = {93--107},
  publisher = {Springer International Publishing},
  address = {Cham},
  doi = {10.1007/978-3-031-19135-0_7},
  abstract = {We study a new modification of the Arrival problem, which allows for nodes that exhibit random as well as controlled behaviour, in addition to switching nodes. We study the computational complexity of these extensions, building on existing work on Reachability Switching Games. In particular, we show for versions of the arrival problem involving just switching and random nodes it is PP-hard to decide if their value is greater than a half and we give a PSPACE decision algorithm.},
  isbn = {978-3-031-19135-0},
  langid = {english},
  keywords = {Arrival,Markov chains,MDPs,Reachability Switching Games,Simple stochastic games},
  file = {/Users/sebastian/Zotero/storage/G993WH5U/Webster - 2022 - The Stochastic Arrival Problem.pdf}
}

@article{williamsonhokeCompletelyUnimodalNumberings1988,
  title = {Completely Unimodal Numberings of a Simple Polytope},
  author = {Williamson Hoke, Kathy},
  year = {1988},
  month = may,
  journal = {Discrete Applied Mathematics},
  volume = {20},
  number = {1},
  pages = {69--81},
  issn = {0166-218X},
  doi = {10.1016/0166-218X(88)90042-X},
  urldate = {2024-08-26},
  abstract = {A completely unimodal numbering of the m vertices of a simple d-dimensional polytope is a numbering 0, 1, {\dots},m-1 of the vertices such that on every k-dimensional face (2{$\leq$}k{$\leq$}d) there is exactly one local minimum (a vertex with no lower-numbered neighbors on that face). Such numberings are abstract objective functions in the sense of Adler and Saigal [1]. It is shown that a completely unimodal numbering of the vertices of a simple polytope induces a shelling of the facets of the dual simplicial polytope. The h-vector of the dual simplicial polytope is interpreted in terms of the numbering (with respect to using a local-improvement algorithm to locate the vertex numbered 0). In the case that the polytope is combinatorially equivalent to a d-dimensional cube, a `successor-tuple' for each vertex is defined which carries the crucial information of the numbering for local-improvement algorithms. Combinatorial properties of these d-tuples are studied. Finally the running time of one particular local-improvement algorithm, the Random Algorithm, is studied for completely unimodal numberings of the d-cube. It is shown that for a certain class of numberings (which includes the example of Klee and Minty [8] showing that the simplex algorithm is not polynomial and all Hamiltonian saddle-free injective pseudo-Boolean functions [6]) this algorithm has expected running time that is at worst quadratic in the dimension d.},
  file = {/Users/sebastian/Zotero/storage/M9F27GDV/0166218X8890042X.html}
}

@misc{wuLinearTimeAlgorithm2012,
  title = {A Linear Time Algorithm for the Next-to-Shortest Path Problem on Undirected Graphs with Nonnegative Edge Lengths},
  author = {Wu, Bang Ye and Guo, Jun-Lin and Wang, Yue-Li},
  year = {2012},
  month = mar,
  number = {arXiv:1203.5235},
  eprint = {1203.5235},
  primaryclass = {cs},
  publisher = {arXiv},
  doi = {10.48550/arXiv.1203.5235},
  urldate = {2024-09-20},
  abstract = {For two vertices \$s\$ and \$t\$ in a graph \$G=(V,E)\$, the next-to-shortest path is an \$st\$-path which length is minimum amongst all \$st\$-paths strictly longer than the shortest path length. In this paper we show that, when the graph is undirected and all edge lengths are nonnegative, the problem can be solved in linear time if the distances from \$s\$ and \$t\$ to all other vertices are given. This result generalizes the previous work (DOI 10.1007/s00453-011-9601-7) to allowing zero-length edges.},
  archiveprefix = {arXiv},
  keywords = {68R10 68W05,Computer Science - Data Structures and Algorithms},
  file = {/Users/sebastian/Zotero/storage/QNJP8SBG/Wu et al. - 2012 - A linear time algorithm for the next-to-shortest p.pdf;/Users/sebastian/Zotero/storage/FVNDQNDT/1203.html}
}

@article{wuNexttoshortestPathProblem2015,
  title = {The Next-to-shortest Path Problem on Directed Graphs with Positive Edge Weights},
  author = {Wu, Bang Ye and Wang, Hung-Lung},
  year = {2015},
  month = may,
  journal = {Networks},
  volume = {65},
  number = {3},
  pages = {205--211},
  issn = {0028-3045, 1097-0037},
  doi = {10.1002/net.21598},
  urldate = {2024-09-20},
  abstract = {Given an edge-weighted graph               G               and two distinct vertices               s               and               t               of               G               , the next-to-shortest path problem asks for a path from               s               to               t               of minimum length among all paths from               s               to               t               except the shortest ones. In this article, we consider the version where               G               is directed and all edge weights are positive. Some properties of the requested path are derived when               G               is an arbitrary digraph. In addition, if               G               is planar, an                              -time algorithm is proposed, where               n               is the number of vertices of               G               . {\copyright} 2015 Wiley Periodicals, Inc. NETWORKS, Vol. 65(3), 205--211 2015},
  copyright = {http://onlinelibrary.wiley.com/termsAndConditions\#vor},
  langid = {english},
  file = {/Users/sebastian/Zotero/storage/NYC29TTG/Wu and Wang - 2015 - The next‐to‐shortest path problem on directed grap.pdf}
}

@article{wuSimplerMoreEfficient2013,
  title = {A {{Simpler}} and {{More Efficient Algorithm}} for the {{Next-to-Shortest Path Problem}}},
  author = {Wu, Bang Ye},
  year = {2013},
  month = feb,
  journal = {Algorithmica},
  volume = {65},
  number = {2},
  pages = {467--479},
  issn = {1432-0541},
  doi = {10.1007/s00453-011-9601-7},
  urldate = {2024-09-20},
  abstract = {Given an undirected graph G=(V,E) with positive edge lengths and two vertices s and t, the next-to-shortest path problem is to find an st-path which length is minimum amongst all st-paths strictly longer than the shortest path length. In this paper we show that the problem can be solved in linear time if the distances from s and t to all other vertices are given. Particularly our new algorithm runs in O({\textbar}V{\textbar}log{\textbar}V{\textbar}+{\textbar}E{\textbar}) time for general graphs, which improves the previous result of O({\textbar}V{\textbar}2) time and takes only linear time for unweighted graphs, planar graphs, and graphs with positive integer edge lengths.},
  langid = {english},
  keywords = {Algorithm,Next-to-shortest path,Shortest path,Time complexity},
  file = {/Users/sebastian/Zotero/storage/G3VHLBY2/Wu - 2013 - A Simpler and More Efficient Algorithm for the Nex.pdf}
}

@article{yiMatchingsColoredBipartite2002,
  title = {Matchings in Colored Bipartite Networks},
  author = {Yi, Tongnyoul and Murty, Katta G. and Spera, Cosimo},
  year = {2002},
  month = sep,
  journal = {Discrete Applied Mathematics},
  volume = {121},
  number = {1-3},
  pages = {261--277},
  issn = {0166-218X},
  doi = {10.1016/S0166-218X(01)00300-6},
  urldate = {2024-04-05},
  abstract = {In K(n,n) with edges colored either red or blue, we show that the problem of finding a solution matching, a perfect matching consisting of exactly r red edges, and (n - r) blue edges for specified 0 {$\leq$} r {$\leq$} n, is a nontrivial integer program. We present an alternative, logically simpler proof of a theorem in (Kibernetika 1 (1987) 7-11) which establishes necessary and sufficient conditions for the existance of a solution matching, and a new O(n2.5) algorithm. This shows that the problem of finding an assignment of specified cost r in an assignment problem on the complete bipartite graph with a 0-1 cost matrix is efficiently solvable.},
  keywords = {0-1 cost matrix,assignment problem,extreme point with specified objective value},
  file = {/Users/sebastian/Zotero/storage/JVQVM24E/Yi et al. - 2002 - Matchings in colored bipartite networks.pdf}
}

@article{yusterAlmostExactMatchings2012,
  title = {Almost {{Exact Matchings}}},
  author = {Yuster, Raphael},
  year = {2012},
  month = jun,
  journal = {Algorithmica},
  volume = {63},
  number = {1-2},
  pages = {39--50},
  issn = {0178-4617},
  abstract = {In the exact matching problem we are given a graph G, some of whose edges are colored red, and a positive integer k. The goal is to determine if G has a perfect matching, exactly k edges of which are red. More generally if the matching number of G is m=m(G), the goal is to find a matching with m edges, exactly k edges of which are red, or determine that no such matching exists. This problem is one of the few remaining problems that have efficient randomized algorithms (in fact, this problem is in RNC), but for which no polynomial time deterministic algorithm is known. Our first result shows that, in a sense, this problem is as close to being in P as one can get. We give a polynomial time deterministic algorithm that either correctly decides that no maximum matching has exactly k red edges, or exhibits a matching with m(G){\'z}1 edges having exactly k red edges. Hence, the additive error is one. We also present an efficient algorithm for the exact matching problem in families of graphs for which this problem is known to be tractable. We show how to count the number of exact perfect matchings in K3,3-minor free graphs (these include all planar graphs as well as many others) in O(n3.19) worst case time. Our algorithm can also count the number of perfect matchings in K3,3-minor free graphs in O(n2.19) time.},
  keywords = {Approximation,Exact matching,Matching}
}

@article{yusterFindingEvenCycles1997,
  title = {Finding {{Even Cycles Even Faster}}},
  author = {Yuster, Raphael and Zwick, Uri},
  year = {1997},
  month = may,
  journal = {SIAM Journal on Discrete Mathematics},
  volume = {10},
  number = {2},
  pages = {209--222},
  publisher = {{Society for Industrial and Applied Mathematics}},
  issn = {0895-4801},
  doi = {10.1137/S0895480194274133},
  urldate = {2024-04-05},
  abstract = {Let G=(V,E) be an unweighted undirected graph on n vertices. A simple argument shows that computing all distances in G with an additive one-sided error of at most 1 is as hard as Boolean matrix multiplication. Building on recent work of Aingworth et al. [SIAM J. Comput., 28 (1999), pp. 1167--1181], we describe an \${\textbackslash}Ot({\textbackslash}min{\textbackslash}\{n{\textasciicircum}\{3/2\}m{\textasciicircum}\{1/2\},n{\textasciicircum}\{7/3\}{\textbackslash}\})\$-time algorithm APASP2  for computing all distances in G with an additive one-sided error of at most 2. Algorithm APASP2  is simple, easy to implement, and faster than the fastest known matrix-multiplication algorithm. Furthermore, for every even k{$>$}2, we describe an \$\{{\textbackslash}tilde\{O\}\}({\textbackslash}min{\textbackslash}\{n{\textasciicircum}\{2-\{2\}/\{(k+2)\}\}m{\textasciicircum}\{\{2\}/\{(k+2)\}\}, n{\textasciicircum}\{2+\{2\}/\{(3k-2)\}\}{\textbackslash}\})\$-time algorithm APASPk  for computing all distances in G with an additive one-sided error of at most k. We also give an \$\{{\textbackslash}tilde\{O\}\}(n{\textasciicircum}2)\$-time algorithm \$\{{\textbackslash}bf APASP\}\_{\textbackslash}infty\$ for producing stretch 3 estimated distances in an unweighted and undirected graph on n vertices. No constant stretch factor was previously achieved in \$\{{\textbackslash}tilde\{O\}\}(n{\textasciicircum}2)\$ time.We say that a weighted graph F=(V,E')  k-emulates an unweighted graph G=(V,E) if for every \$u,v{\textbackslash}in V\$ we have \${\textbackslash}delta\_G(u,v){\textbackslash}le {\textbackslash}delta\_F(u,v){\textbackslash}le {\textbackslash}delta\_G(u,v)+k\$. We show that every unweighted graph on n vertices has a 2-emulator with \$\{{\textbackslash}tilde\{O\}\}(n{\textasciicircum}\{3/2\})\$ edges and a 4-emulator with \$\{{\textbackslash}tilde\{O\}\}(n{\textasciicircum}\{4/3\})\$ edges. These results are asymptotically tight.Finally, we show that any  weighted undirected graph on n vertices has a 3-spanner with \$\{{\textbackslash}tilde\{O\}\}(n{\textasciicircum}\{3/2\})\$ edges and that such a 3-spanner can be built in \$\{{\textbackslash}tilde\{O\}\}(mn{\textasciicircum}\{1/2\})\$ time. We also describe an \$\{{\textbackslash}tilde\{O\}\}(n(m{\textasciicircum}\{2/3\}+n))\$-time algorithm for estimating all distances in a  weighted undirected graph on n vertices with a stretch factor of at most 3.},
  file = {/Users/sebastian/Zotero/storage/NZ6ZT56U/Yuster and Zwick - 1997 - Finding Even Cycles Even Faster.pdf}
}

@article{zhangNextShortestPathUndirected2012,
  title = {The {{Next-to-Shortest Path}} in {{Undirected Graphs}} with {{Nonnegative Weights}}},
  author = {Zhang, Cong and Nagamochi, Hiroshi},
  year = {2012},
  journal = {Theory of Computing},
  volume = {128},
  abstract = {Given an edge-weighted undirected graph and two vertices s and t, the next-to-shortest path problem is to find an st-path whose length is minimum among all st-paths of lengths strictly larger than the shortest path length. The problem is shown to be polynomially solvable if all edge weights are positive, while the complexity status for the nonnegative weight case was open. In this paper we show that the problem in undirected graphs admits a polynomial-time algorithm even if all edge weights are nonnegative, solving the open problem. To solve the problem, we introduce a common generalization of the undirected graph version and the acyclic digraph version of the k vertex-disjoint paths problem.},
  langid = {english},
  file = {/Users/sebastian/Zotero/storage/EHJV73UL/Zhang and Nagamochi - 2012 - The Next-to-Shortest Path in Undirected Graphs wit.pdf}
}

@inproceedings{zippelProbabilisticAlgorithmsSparse1979,
  title = {Probabilistic Algorithms for Sparse Polynomials},
  booktitle = {Proceedings of the {{International Symposiumon}} on {{Symbolic}} and {{Algebraic Computation}}},
  author = {Zippel, Richard},
  year = {1979},
  month = jun,
  series = {{{EUROSAM}} '79},
  pages = {216--226},
  publisher = {Springer-Verlag},
  address = {Berlin, Heidelberg},
  urldate = {2024-04-05},
  isbn = {978-3-540-09519-4}
}

@article{zuallaertSpliceRoverInterpretableConvolutional2018,
  title = {{{SpliceRover}}: Interpretable Convolutional Neural Networks for Improved Splice Site Prediction},
  shorttitle = {{{SpliceRover}}},
  author = {Zuallaert, Jasper and Godin, Fr{\'e}deric and Kim, Mijung and Soete, Arne and Saeys, Yvan and De Neve, Wesley},
  year = {2018},
  month = dec,
  journal = {Bioinformatics},
  volume = {34},
  number = {24},
  pages = {4180--4188},
  issn = {1367-4803, 1367-4811},
  doi = {10.1093/bioinformatics/bty497},
  urldate = {2023-08-10},
  abstract = {Abstract                            Motivation               During the last decade, improvements in high-throughput sequencing have generated a wealth of genomic data. Functionally interpreting these sequences and finding the biological signals that are hallmarks of gene function and regulation is currently mostly done using automated genome annotation platforms, which mainly rely on integrated machine learning frameworks to identify different functional sites of interest, including splice sites. Splicing is an essential step in the gene regulation process, and the correct identification of splice sites is a major cornerstone in a genome annotation system.                                         Results               In this paper, we present SpliceRover, a predictive deep learning approach that outperforms the state-of-the-art in splice site prediction. SpliceRover uses convolutional neural networks (CNNs), which have been shown to obtain cutting edge performance on a wide variety of prediction tasks. We adapted this approach to deal with genomic sequence inputs, and show it consistently outperforms already existing approaches, with relative improvements in prediction effectiveness of up to 80.9\% when measured in terms of false discovery rate. However, a major criticism of CNNs concerns their `black box' nature, as mechanisms to obtain insight into their reasoning processes are limited. To facilitate interpretability of the SpliceRover models, we introduce an approach to visualize the biologically relevant information learnt. We show that our visualization approach is able to recover features known to be important for splice site prediction (binding motifs around the splice site, presence of polypyrimidine tracts and branch points), as well as reveal new features (e.g. several types of exclusion patterns near splice sites).                                         Availability and implementation               SpliceRover is available as a web service. The prediction tool and instructions can be found at http://bioit2.irc.ugent.be/splicerover/.                                         Supplementary information               Supplementary data are available at Bioinformatics online.},
  langid = {english},
  file = {/Users/sebastian/Zotero/storage/DXG85GRY/Zuallaert et al. - 2018 - SpliceRover interpretable convolutional neural ne.pdf}
}
